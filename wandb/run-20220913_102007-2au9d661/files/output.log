/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0341607332229614, disc_loss = 0.7128903865814209
Trained batch 1 in epoch 0, gen_loss = 0.9766749143600464, disc_loss = 0.7868185043334961
Trained batch 2 in epoch 0, gen_loss = 0.9258075952529907, disc_loss = 0.6694286863009135
Trained batch 3 in epoch 0, gen_loss = 0.8502924591302872, disc_loss = 0.5881789922714233
Trained batch 4 in epoch 0, gen_loss = 0.8321390867233276, disc_loss = 0.5354968428611755
Trained batch 5 in epoch 0, gen_loss = 0.8081226944923401, disc_loss = 0.49447140097618103
Trained batch 6 in epoch 0, gen_loss = 0.8198733755520412, disc_loss = 0.46350019744464327
Trained batch 7 in epoch 0, gen_loss = 0.8151831403374672, disc_loss = 0.4272917713969946
Trained batch 8 in epoch 0, gen_loss = 0.8043420182334052, disc_loss = 0.3974599656131532
Trained batch 9 in epoch 0, gen_loss = 0.7934063076972961, disc_loss = 0.37413096278905866
Trained batch 10 in epoch 0, gen_loss = 0.7971071763472124, disc_loss = 0.35645904730666766
Trained batch 11 in epoch 0, gen_loss = 0.7967420419057211, disc_loss = 0.3405972843368848
Trained batch 12 in epoch 0, gen_loss = 0.7856769240819491, disc_loss = 0.33210237553486455
Trained batch 13 in epoch 0, gen_loss = 0.7921447711331504, disc_loss = 0.3241398110985756
Trained batch 14 in epoch 0, gen_loss = 0.7745229681332906, disc_loss = 0.3230373273293177
Trained batch 15 in epoch 0, gen_loss = 0.7668871209025383, disc_loss = 0.3240342056378722
Trained batch 16 in epoch 0, gen_loss = 0.7666802756926593, disc_loss = 0.32730573854025674
Trained batch 17 in epoch 0, gen_loss = 0.7715016139878167, disc_loss = 0.32447365671396255
Trained batch 18 in epoch 0, gen_loss = 0.7668546877409282, disc_loss = 0.31906209729219737
Trained batch 19 in epoch 0, gen_loss = 0.7645822644233704, disc_loss = 0.3129279248416424
Trained batch 20 in epoch 0, gen_loss = 0.7649363307725816, disc_loss = 0.3075496760152635
Trained batch 21 in epoch 0, gen_loss = 0.7628419588912617, disc_loss = 0.3033152093941515
Trained batch 22 in epoch 0, gen_loss = 0.7606409451235896, disc_loss = 0.3021118116119634
Trained batch 23 in epoch 0, gen_loss = 0.7583641136686007, disc_loss = 0.30028111673891544
Trained batch 24 in epoch 0, gen_loss = 0.7588550424575806, disc_loss = 0.2993306714296341
Trained batch 25 in epoch 0, gen_loss = 0.7593359901354864, disc_loss = 0.29772291561731923
Trained batch 26 in epoch 0, gen_loss = 0.7595262350859465, disc_loss = 0.2938055986607516
Trained batch 27 in epoch 0, gen_loss = 0.7607781844479697, disc_loss = 0.2902760739837374
Trained batch 28 in epoch 0, gen_loss = 0.75946189206222, disc_loss = 0.2866662971932313
Trained batch 29 in epoch 0, gen_loss = 0.761009814341863, disc_loss = 0.2823331912358602
Trained batch 30 in epoch 0, gen_loss = 0.7615484191525367, disc_loss = 0.2784406619687234
Trained batch 31 in epoch 0, gen_loss = 0.7608201205730438, disc_loss = 0.2754029920324683
Trained batch 32 in epoch 0, gen_loss = 0.7646917809139598, disc_loss = 0.2734130115220041
Trained batch 33 in epoch 0, gen_loss = 0.7623627764337203, disc_loss = 0.27326204320963693
Trained batch 34 in epoch 0, gen_loss = 0.7651368396622794, disc_loss = 0.2736225707190377
Trained batch 35 in epoch 0, gen_loss = 0.7712499813901054, disc_loss = 0.280041194624371
Trained batch 36 in epoch 0, gen_loss = 0.7727789008939588, disc_loss = 0.2818431975068273
Trained batch 37 in epoch 0, gen_loss = 0.7701168844574376, disc_loss = 0.2810005624043314
Trained batch 38 in epoch 0, gen_loss = 0.7682826106364911, disc_loss = 0.2793887280500852
Trained batch 39 in epoch 0, gen_loss = 0.7688631132245064, disc_loss = 0.27744428180158137
Trained batch 40 in epoch 0, gen_loss = 0.7683722885643564, disc_loss = 0.2766043939968435
Trained batch 41 in epoch 0, gen_loss = 0.7683411297344026, disc_loss = 0.2758465547646795
Trained batch 42 in epoch 0, gen_loss = 0.7661457727121752, disc_loss = 0.27428524473378824
Trained batch 43 in epoch 0, gen_loss = 0.7713055840947411, disc_loss = 0.275707622482018
Trained batch 44 in epoch 0, gen_loss = 0.7685252361827426, disc_loss = 0.27857465777132245
Trained batch 45 in epoch 0, gen_loss = 0.7659939372021219, disc_loss = 0.2773140480984812
Trained batch 46 in epoch 0, gen_loss = 0.7666613624451009, disc_loss = 0.27741246210767867
Trained batch 47 in epoch 0, gen_loss = 0.7667582059899966, disc_loss = 0.2765273867795865
Trained batch 48 in epoch 0, gen_loss = 0.7633985706738063, disc_loss = 0.27556902170181274
Trained batch 49 in epoch 0, gen_loss = 0.7619189012050629, disc_loss = 0.2745659339427948
Trained batch 50 in epoch 0, gen_loss = 0.7597900231679281, disc_loss = 0.2734722208743002
Trained batch 51 in epoch 0, gen_loss = 0.7583600236819341, disc_loss = 0.27247455486884486
Trained batch 52 in epoch 0, gen_loss = 0.7584845884790961, disc_loss = 0.27168021674426096
Trained batch 53 in epoch 0, gen_loss = 0.75785333359683, disc_loss = 0.270867099640546
Trained batch 54 in epoch 0, gen_loss = 0.7554344133897262, disc_loss = 0.2704504831270738
Trained batch 55 in epoch 0, gen_loss = 0.7544291296175548, disc_loss = 0.2696826285017388
Trained batch 56 in epoch 0, gen_loss = 0.7531788641946358, disc_loss = 0.26921923040297996
Trained batch 57 in epoch 0, gen_loss = 0.7523203111928085, disc_loss = 0.26940719295164633
Trained batch 58 in epoch 0, gen_loss = 0.7486574003251932, disc_loss = 0.2701280685299534
Trained batch 59 in epoch 0, gen_loss = 0.7479994277159373, disc_loss = 0.26911289170384406
Trained batch 60 in epoch 0, gen_loss = 0.7466191219501808, disc_loss = 0.26863827788438954
Trained batch 61 in epoch 0, gen_loss = 0.746093443324489, disc_loss = 0.2680644046875738
Trained batch 62 in epoch 0, gen_loss = 0.7452454216896541, disc_loss = 0.26778298569104025
Trained batch 63 in epoch 0, gen_loss = 0.7445433316752315, disc_loss = 0.26700641866773367
Trained batch 64 in epoch 0, gen_loss = 0.7428992317273067, disc_loss = 0.26638844311237336
Trained batch 65 in epoch 0, gen_loss = 0.7413628579992236, disc_loss = 0.2655785758838509
Trained batch 66 in epoch 0, gen_loss = 0.7399473652910831, disc_loss = 0.2649876731100367
Trained batch 67 in epoch 0, gen_loss = 0.7386461294749204, disc_loss = 0.2645372919300023
Trained batch 68 in epoch 0, gen_loss = 0.7372369178827258, disc_loss = 0.26403937629167584
Trained batch 69 in epoch 0, gen_loss = 0.7367950899260385, disc_loss = 0.2633559586746352
Trained batch 70 in epoch 0, gen_loss = 0.7377901664921935, disc_loss = 0.2634631477191415
Trained batch 71 in epoch 0, gen_loss = 0.7356109867493311, disc_loss = 0.2640045837809642
Trained batch 72 in epoch 0, gen_loss = 0.7350273418099913, disc_loss = 0.2633396581019441
Trained batch 73 in epoch 0, gen_loss = 0.7344012800100688, disc_loss = 0.2639349560077126
Trained batch 74 in epoch 0, gen_loss = 0.7311316760381062, disc_loss = 0.26449832300345105
Trained batch 75 in epoch 0, gen_loss = 0.7313009484818107, disc_loss = 0.2639074262819792
Trained batch 76 in epoch 0, gen_loss = 0.7293851437506738, disc_loss = 0.26387576313761923
Trained batch 77 in epoch 0, gen_loss = 0.7299049580708529, disc_loss = 0.26383177439371747
Trained batch 78 in epoch 0, gen_loss = 0.7282198509083518, disc_loss = 0.26342851904374137
Trained batch 79 in epoch 0, gen_loss = 0.727003988623619, disc_loss = 0.26348253563046453
Trained batch 80 in epoch 0, gen_loss = 0.7281393828215422, disc_loss = 0.26391251109264513
Trained batch 81 in epoch 0, gen_loss = 0.7265557850279459, disc_loss = 0.2634578234538799
Trained batch 82 in epoch 0, gen_loss = 0.7258220990020109, disc_loss = 0.2632126064903765
Trained batch 83 in epoch 0, gen_loss = 0.7248217740229198, disc_loss = 0.26273458397814203
Trained batch 84 in epoch 0, gen_loss = 0.7235693559927099, disc_loss = 0.2621695620172164
Trained batch 85 in epoch 0, gen_loss = 0.7220700826755789, disc_loss = 0.2620117030171461
Trained batch 86 in epoch 0, gen_loss = 0.723101302124988, disc_loss = 0.2616292632174218
Trained batch 87 in epoch 0, gen_loss = 0.7206663502888246, disc_loss = 0.26163634014400566
Trained batch 88 in epoch 0, gen_loss = 0.7192304013820177, disc_loss = 0.2612887242536866
Trained batch 89 in epoch 0, gen_loss = 0.7185640248987409, disc_loss = 0.2609070231517156
Trained batch 90 in epoch 0, gen_loss = 0.7179493170518142, disc_loss = 0.2604829334950709
Trained batch 91 in epoch 0, gen_loss = 0.7169971245786418, disc_loss = 0.2600398837872174
Trained batch 92 in epoch 0, gen_loss = 0.7157738708680675, disc_loss = 0.25978731756569234
Trained batch 93 in epoch 0, gen_loss = 0.7154495842913364, disc_loss = 0.2594069063346437
Trained batch 94 in epoch 0, gen_loss = 0.7136733211969074, disc_loss = 0.25894842508592103
Trained batch 95 in epoch 0, gen_loss = 0.7138887848705053, disc_loss = 0.25924983543033403
Trained batch 96 in epoch 0, gen_loss = 0.7111838524489059, disc_loss = 0.2599467344812511
Trained batch 97 in epoch 0, gen_loss = 0.7113332033765559, disc_loss = 0.2599991266520656
Trained batch 98 in epoch 0, gen_loss = 0.7112909293535984, disc_loss = 0.2596224012097927
Trained batch 99 in epoch 0, gen_loss = 0.710840422809124, disc_loss = 0.2595779259502888
Trained batch 100 in epoch 0, gen_loss = 0.7101330665668638, disc_loss = 0.259301946747421
Trained batch 101 in epoch 0, gen_loss = 0.7104619983948913, disc_loss = 0.2589381528543491
Trained batch 102 in epoch 0, gen_loss = 0.7090943163459741, disc_loss = 0.2585407816669316
Trained batch 103 in epoch 0, gen_loss = 0.7083815694428407, disc_loss = 0.2580360679958875
Trained batch 104 in epoch 0, gen_loss = 0.7083776544956933, disc_loss = 0.25780842886084604
Trained batch 105 in epoch 0, gen_loss = 0.7063665620560916, disc_loss = 0.2579440990427755
Trained batch 106 in epoch 0, gen_loss = 0.7057997489643988, disc_loss = 0.2579482098884672
Trained batch 107 in epoch 0, gen_loss = 0.7064504777943647, disc_loss = 0.2581762763913031
Trained batch 108 in epoch 0, gen_loss = 0.7063349736939877, disc_loss = 0.258182504445041
Trained batch 109 in epoch 0, gen_loss = 0.7058441091667522, disc_loss = 0.2578155768188563
Trained batch 110 in epoch 0, gen_loss = 0.7056046391392613, disc_loss = 0.2573983279971389
Trained batch 111 in epoch 0, gen_loss = 0.7050645654754979, disc_loss = 0.2569404309615493
Trained batch 112 in epoch 0, gen_loss = 0.7048581917728998, disc_loss = 0.25666649098944877
Trained batch 113 in epoch 0, gen_loss = 0.7031498661166743, disc_loss = 0.2562202399498538
Trained batch 114 in epoch 0, gen_loss = 0.7033886634785196, disc_loss = 0.2559261381626129
Trained batch 115 in epoch 0, gen_loss = 0.7026835479613008, disc_loss = 0.2555842634675832
Trained batch 116 in epoch 0, gen_loss = 0.7021331914469727, disc_loss = 0.2550150265551021
Trained batch 117 in epoch 0, gen_loss = 0.7014818151118392, disc_loss = 0.2545454247018038
Trained batch 118 in epoch 0, gen_loss = 0.701390730733631, disc_loss = 0.25409422501796436
Trained batch 119 in epoch 0, gen_loss = 0.7013614291946093, disc_loss = 0.2538792684674263
Trained batch 120 in epoch 0, gen_loss = 0.7016139488574887, disc_loss = 0.2538541269696448
Trained batch 121 in epoch 0, gen_loss = 0.7008338922359905, disc_loss = 0.2538965713293826
Trained batch 122 in epoch 0, gen_loss = 0.7011592921202745, disc_loss = 0.25327249658786183
Trained batch 123 in epoch 0, gen_loss = 0.7013008551251504, disc_loss = 0.25282467925740826
Trained batch 124 in epoch 0, gen_loss = 0.700459861278534, disc_loss = 0.25256932282447814
Trained batch 125 in epoch 0, gen_loss = 0.7009576213738274, disc_loss = 0.2525904308708887
Trained batch 126 in epoch 0, gen_loss = 0.700596772310302, disc_loss = 0.2517925597081973
Trained batch 127 in epoch 0, gen_loss = 0.6996635003015399, disc_loss = 0.25177817163057625
Trained batch 128 in epoch 0, gen_loss = 0.7007378746372784, disc_loss = 0.2518244619055312
Trained batch 129 in epoch 0, gen_loss = 0.7002644855242509, disc_loss = 0.25157819298597484
Trained batch 130 in epoch 0, gen_loss = 0.6988063381828424, disc_loss = 0.25153246817698005
Trained batch 131 in epoch 0, gen_loss = 0.6982332373207266, disc_loss = 0.25116122073747893
Trained batch 132 in epoch 0, gen_loss = 0.6986194477045446, disc_loss = 0.25119589269161224
Trained batch 133 in epoch 0, gen_loss = 0.6978778594465398, disc_loss = 0.2510034865630207
Trained batch 134 in epoch 0, gen_loss = 0.6972916762034098, disc_loss = 0.25104852859620697
Trained batch 135 in epoch 0, gen_loss = 0.6975437876056222, disc_loss = 0.2508792368804707
Trained batch 136 in epoch 0, gen_loss = 0.6962437081511004, disc_loss = 0.2506398739170854
Trained batch 137 in epoch 0, gen_loss = 0.6954090189242709, disc_loss = 0.2503429848862731
Trained batch 138 in epoch 0, gen_loss = 0.6955845639002409, disc_loss = 0.24984774068533946
Trained batch 139 in epoch 0, gen_loss = 0.6946995313678469, disc_loss = 0.24933760953801018
Trained batch 140 in epoch 0, gen_loss = 0.6941740377574948, disc_loss = 0.248809407788811
Trained batch 141 in epoch 0, gen_loss = 0.6943959883401092, disc_loss = 0.24873218402056627
Trained batch 142 in epoch 0, gen_loss = 0.6934810405844575, disc_loss = 0.2485300276454512
Trained batch 143 in epoch 0, gen_loss = 0.6934154609011279, disc_loss = 0.24832638373805416
Trained batch 144 in epoch 0, gen_loss = 0.6926354482256133, disc_loss = 0.2479967809956649
Trained batch 145 in epoch 0, gen_loss = 0.6921641112190403, disc_loss = 0.24779278254264023
Trained batch 146 in epoch 0, gen_loss = 0.6924503518610584, disc_loss = 0.24757827372372557
Trained batch 147 in epoch 0, gen_loss = 0.6921646357388109, disc_loss = 0.2470903427818337
Trained batch 148 in epoch 0, gen_loss = 0.6915013714124693, disc_loss = 0.24654428840883627
Trained batch 149 in epoch 0, gen_loss = 0.6913941891988119, disc_loss = 0.24620402644077938
Trained batch 150 in epoch 0, gen_loss = 0.6898055118046059, disc_loss = 0.24608064210967512
Trained batch 151 in epoch 0, gen_loss = 0.6903227271610185, disc_loss = 0.24670423626115448
Trained batch 152 in epoch 0, gen_loss = 0.6901872853438059, disc_loss = 0.247022944143395
Trained batch 153 in epoch 0, gen_loss = 0.6895179425354128, disc_loss = 0.24677495716454148
Trained batch 154 in epoch 0, gen_loss = 0.6904093751984258, disc_loss = 0.24643258356278944
Trained batch 155 in epoch 0, gen_loss = 0.6913841284620457, disc_loss = 0.247072261877549
Trained batch 156 in epoch 0, gen_loss = 0.6904457760084967, disc_loss = 0.24770517523880978
Trained batch 157 in epoch 0, gen_loss = 0.6908385544260846, disc_loss = 0.2484130772608745
Trained batch 158 in epoch 0, gen_loss = 0.6908024468886778, disc_loss = 0.2489143709341685
Trained batch 159 in epoch 0, gen_loss = 0.6906331649050117, disc_loss = 0.24892610609531401
Trained batch 160 in epoch 0, gen_loss = 0.6897355468006607, disc_loss = 0.24865474667608367
Trained batch 161 in epoch 0, gen_loss = 0.689100973216104, disc_loss = 0.24842225364696832
Trained batch 162 in epoch 0, gen_loss = 0.6886638591260267, disc_loss = 0.24803094830981062
Trained batch 163 in epoch 0, gen_loss = 0.6885271208678804, disc_loss = 0.2476153717171855
Trained batch 164 in epoch 0, gen_loss = 0.6884368826042522, disc_loss = 0.24719285531477495
Trained batch 165 in epoch 0, gen_loss = 0.6884407083313149, disc_loss = 0.24688133399888693
Trained batch 166 in epoch 0, gen_loss = 0.687821054351544, disc_loss = 0.24665815798108448
Trained batch 167 in epoch 0, gen_loss = 0.6871372087015992, disc_loss = 0.24621794709847086
Trained batch 168 in epoch 0, gen_loss = 0.6868311133257736, disc_loss = 0.24606816902668519
Trained batch 169 in epoch 0, gen_loss = 0.6865608459009843, disc_loss = 0.24598886107697207
Trained batch 170 in epoch 0, gen_loss = 0.6860962755847395, disc_loss = 0.24537284959826552
Trained batch 171 in epoch 0, gen_loss = 0.6864712451433026, disc_loss = 0.2451014496212782
Trained batch 172 in epoch 0, gen_loss = 0.6870530755878184, disc_loss = 0.24450629329405768
Trained batch 173 in epoch 0, gen_loss = 0.6867395778154505, disc_loss = 0.24449723599285916
Trained batch 174 in epoch 0, gen_loss = 0.6897128263541631, disc_loss = 0.2457722442490714
Trained batch 175 in epoch 0, gen_loss = 0.6886677821590141, disc_loss = 0.24677158451893114
Trained batch 176 in epoch 0, gen_loss = 0.6885921239516156, disc_loss = 0.24650449890874873
Trained batch 177 in epoch 0, gen_loss = 0.6889811484666353, disc_loss = 0.24639321763194008
Trained batch 178 in epoch 0, gen_loss = 0.6886801931112172, disc_loss = 0.2460204767448276
Trained batch 179 in epoch 0, gen_loss = 0.6880076188180182, disc_loss = 0.24578871213727527
Trained batch 180 in epoch 0, gen_loss = 0.687892837254382, disc_loss = 0.24553078363613529
Trained batch 181 in epoch 0, gen_loss = 0.688241646348775, disc_loss = 0.24511669420606488
Trained batch 182 in epoch 0, gen_loss = 0.6877517109034491, disc_loss = 0.24467566023107434
Trained batch 183 in epoch 0, gen_loss = 0.6871533376043257, disc_loss = 0.2442066015108772
Trained batch 184 in epoch 0, gen_loss = 0.6866530941950308, disc_loss = 0.24379709709335018
Trained batch 185 in epoch 0, gen_loss = 0.6859620458656742, disc_loss = 0.24338368751028533
Trained batch 186 in epoch 0, gen_loss = 0.6856519020496206, disc_loss = 0.24307493658308038
Trained batch 187 in epoch 0, gen_loss = 0.685028057307639, disc_loss = 0.2427867077132489
Trained batch 188 in epoch 0, gen_loss = 0.6851838488112051, disc_loss = 0.24247309754765223
Trained batch 189 in epoch 0, gen_loss = 0.6846634452280246, disc_loss = 0.24237122865099656
Trained batch 190 in epoch 0, gen_loss = 0.6840564663185499, disc_loss = 0.24206550848421626
Trained batch 191 in epoch 0, gen_loss = 0.6837197314016521, disc_loss = 0.24149376821393767
Trained batch 192 in epoch 0, gen_loss = 0.6841971659598572, disc_loss = 0.2410073305041061
Trained batch 193 in epoch 0, gen_loss = 0.6837562523859063, disc_loss = 0.24079619255877033
Trained batch 194 in epoch 0, gen_loss = 0.68401904855019, disc_loss = 0.24059485219992124
Trained batch 195 in epoch 0, gen_loss = 0.6840017430332243, disc_loss = 0.24006237796678834
Trained batch 196 in epoch 0, gen_loss = 0.6838269574085468, disc_loss = 0.2394823332879749
Trained batch 197 in epoch 0, gen_loss = 0.683527386098197, disc_loss = 0.2389656301550191
Trained batch 198 in epoch 0, gen_loss = 0.6831872782216, disc_loss = 0.2384453558891862
Trained batch 199 in epoch 0, gen_loss = 0.6829158501327037, disc_loss = 0.23812950275838374
Trained batch 200 in epoch 0, gen_loss = 0.6834802513395376, disc_loss = 0.2377551256572429
Trained batch 201 in epoch 0, gen_loss = 0.6826415166701421, disc_loss = 0.23764710652061027
Trained batch 202 in epoch 0, gen_loss = 0.6834317561734486, disc_loss = 0.23723456307585017
Trained batch 203 in epoch 0, gen_loss = 0.6831173848579911, disc_loss = 0.23666597417026175
Trained batch 204 in epoch 0, gen_loss = 0.6826993949529602, disc_loss = 0.2360817014807608
Trained batch 205 in epoch 0, gen_loss = 0.6827478048581521, disc_loss = 0.2358726213496287
Trained batch 206 in epoch 0, gen_loss = 0.6831323177630199, disc_loss = 0.235783108730535
Trained batch 207 in epoch 0, gen_loss = 0.6835638059733006, disc_loss = 0.23527700622351125
Trained batch 208 in epoch 0, gen_loss = 0.6838579441656907, disc_loss = 0.23445190196972715
Trained batch 209 in epoch 0, gen_loss = 0.6835301494314557, disc_loss = 0.2343191527894565
Trained batch 210 in epoch 0, gen_loss = 0.6863591912515921, disc_loss = 0.23619987790900948
Trained batch 211 in epoch 0, gen_loss = 0.6863966076722685, disc_loss = 0.23598044063403922
Trained batch 212 in epoch 0, gen_loss = 0.6859126618490533, disc_loss = 0.23659590579254527
Trained batch 213 in epoch 0, gen_loss = 0.6858024041507845, disc_loss = 0.23665589435356799
Trained batch 214 in epoch 0, gen_loss = 0.6855584875095723, disc_loss = 0.23631675638431726
Trained batch 215 in epoch 0, gen_loss = 0.6853062498072783, disc_loss = 0.23606512150554745
Trained batch 216 in epoch 0, gen_loss = 0.6851390335142338, disc_loss = 0.23578669597750984
Trained batch 217 in epoch 0, gen_loss = 0.6852864482260626, disc_loss = 0.23524937433523868
Trained batch 218 in epoch 0, gen_loss = 0.685122873821215, disc_loss = 0.2347446820915562
Trained batch 219 in epoch 0, gen_loss = 0.6851294919848442, disc_loss = 0.23422776359048755
Trained batch 220 in epoch 0, gen_loss = 0.6851656465239115, disc_loss = 0.2335781649227056
Trained batch 221 in epoch 0, gen_loss = 0.6852840197247427, disc_loss = 0.23284569906221853
Trained batch 222 in epoch 0, gen_loss = 0.6857122018465547, disc_loss = 0.23213620156450657
Trained batch 223 in epoch 0, gen_loss = 0.6869655928707549, disc_loss = 0.23128890488961978
Trained batch 224 in epoch 0, gen_loss = 0.6866585115591685, disc_loss = 0.23107303788264594
Trained batch 225 in epoch 0, gen_loss = 0.6882347115109452, disc_loss = 0.23103506062014967
Trained batch 226 in epoch 0, gen_loss = 0.687488776077783, disc_loss = 0.23089273093424179
Trained batch 227 in epoch 0, gen_loss = 0.6883008282696992, disc_loss = 0.23088844862292734
Trained batch 228 in epoch 0, gen_loss = 0.6877429986364456, disc_loss = 0.230663488232673
Trained batch 229 in epoch 0, gen_loss = 0.6874912799700447, disc_loss = 0.23039424675314324
Trained batch 230 in epoch 0, gen_loss = 0.68785119508252, disc_loss = 0.22988395931529793
Trained batch 231 in epoch 0, gen_loss = 0.6869304466607242, disc_loss = 0.22977547607673654
Trained batch 232 in epoch 0, gen_loss = 0.6877500687290159, disc_loss = 0.2294910139216374
Trained batch 233 in epoch 0, gen_loss = 0.6878089674262919, disc_loss = 0.22891047093858066
Trained batch 234 in epoch 0, gen_loss = 0.6876668261720779, disc_loss = 0.22846776075819705
Trained batch 235 in epoch 0, gen_loss = 0.6875317236882145, disc_loss = 0.2279909818543721
Trained batch 236 in epoch 0, gen_loss = 0.6879197991598508, disc_loss = 0.22779550573116616
Trained batch 237 in epoch 0, gen_loss = 0.6875582581558147, disc_loss = 0.22749608777025165
Trained batch 238 in epoch 0, gen_loss = 0.6870272051090974, disc_loss = 0.22719802601442177
Trained batch 239 in epoch 0, gen_loss = 0.6888258766382933, disc_loss = 0.22719812557722133
Trained batch 240 in epoch 0, gen_loss = 0.6877612906867537, disc_loss = 0.22720842060335444
Trained batch 241 in epoch 0, gen_loss = 0.6877733025669066, disc_loss = 0.2269240312647721
Trained batch 242 in epoch 0, gen_loss = 0.6878234775959219, disc_loss = 0.22676627506567126
Trained batch 243 in epoch 0, gen_loss = 0.6880313311932517, disc_loss = 0.2261192557081336
Trained batch 244 in epoch 0, gen_loss = 0.6875435495863156, disc_loss = 0.22617054116360996
Trained batch 245 in epoch 0, gen_loss = 0.6874115673022542, disc_loss = 0.22567942438692581
Trained batch 246 in epoch 0, gen_loss = 0.6889516884981379, disc_loss = 0.2253372717784484
Trained batch 247 in epoch 0, gen_loss = 0.6884617036388766, disc_loss = 0.22520208608118758
Trained batch 248 in epoch 0, gen_loss = 0.6889175516534521, disc_loss = 0.22454172899445377
Trained batch 249 in epoch 0, gen_loss = 0.6890972118377685, disc_loss = 0.22413513121008874
Trained batch 250 in epoch 0, gen_loss = 0.6889608659117346, disc_loss = 0.22437225831338609
Trained batch 251 in epoch 0, gen_loss = 0.6885305091975227, disc_loss = 0.22398100571618193
Trained batch 252 in epoch 0, gen_loss = 0.6881930246183523, disc_loss = 0.2237320080870696
Trained batch 253 in epoch 0, gen_loss = 0.6893722424356956, disc_loss = 0.22427364682236056
Trained batch 254 in epoch 0, gen_loss = 0.6887887433463452, disc_loss = 0.22440762370824813
Trained batch 255 in epoch 0, gen_loss = 0.6883393046446145, disc_loss = 0.2244609938643407
Trained batch 256 in epoch 0, gen_loss = 0.6881808255896958, disc_loss = 0.224489260827289
Trained batch 257 in epoch 0, gen_loss = 0.6881844438323679, disc_loss = 0.224512224020653
Trained batch 258 in epoch 0, gen_loss = 0.6875908252815482, disc_loss = 0.224392148144687
Trained batch 259 in epoch 0, gen_loss = 0.6877797252856768, disc_loss = 0.22430382368083185
Trained batch 260 in epoch 0, gen_loss = 0.6874906112407816, disc_loss = 0.22383084219534277
Trained batch 261 in epoch 0, gen_loss = 0.687192463692818, disc_loss = 0.2239627310337911
Trained batch 262 in epoch 0, gen_loss = 0.687614994357294, disc_loss = 0.2239682822852987
Trained batch 263 in epoch 0, gen_loss = 0.6876382145917777, disc_loss = 0.22357918104777733
Trained batch 264 in epoch 0, gen_loss = 0.6874097124585565, disc_loss = 0.22335382753385688
Trained batch 265 in epoch 0, gen_loss = 0.6879551679568183, disc_loss = 0.2233472261157699
Trained batch 266 in epoch 0, gen_loss = 0.68735695421026, disc_loss = 0.22302231133988734
Trained batch 267 in epoch 0, gen_loss = 0.6876386048188851, disc_loss = 0.2226095719735569
Trained batch 268 in epoch 0, gen_loss = 0.687343162231729, disc_loss = 0.22214265818600318
Trained batch 269 in epoch 0, gen_loss = 0.6872749878300561, disc_loss = 0.22202517911791803
Trained batch 270 in epoch 0, gen_loss = 0.687128086151672, disc_loss = 0.2216170103842482
Trained batch 271 in epoch 0, gen_loss = 0.6868020561249817, disc_loss = 0.2213065177476143
Trained batch 272 in epoch 0, gen_loss = 0.6875025651830456, disc_loss = 0.2213809772670924
Trained batch 273 in epoch 0, gen_loss = 0.6869121781230842, disc_loss = 0.22122487597113108
Trained batch 274 in epoch 0, gen_loss = 0.6869590317119252, disc_loss = 0.22070301074873316
Trained batch 275 in epoch 0, gen_loss = 0.6879148332105167, disc_loss = 0.2208465011385472
Trained batch 276 in epoch 0, gen_loss = 0.6870414252100439, disc_loss = 0.22132004950773845
Trained batch 277 in epoch 0, gen_loss = 0.6872139820735231, disc_loss = 0.22147145425137
Trained batch 278 in epoch 0, gen_loss = 0.6883377549255193, disc_loss = 0.2229573971001051
Trained batch 279 in epoch 0, gen_loss = 0.6889643301921231, disc_loss = 0.2238508269989065
Trained batch 280 in epoch 0, gen_loss = 0.6889506708896881, disc_loss = 0.2237710493262128
Trained batch 281 in epoch 0, gen_loss = 0.6890196029810195, disc_loss = 0.22354801905387683
Trained batch 282 in epoch 0, gen_loss = 0.6888416604313328, disc_loss = 0.22334298594153812
Trained batch 283 in epoch 0, gen_loss = 0.6886204929209091, disc_loss = 0.22324440867023568
Trained batch 284 in epoch 0, gen_loss = 0.688584194580714, disc_loss = 0.2231865839738595
Trained batch 285 in epoch 0, gen_loss = 0.6881616989840994, disc_loss = 0.2232265870210591
Trained batch 286 in epoch 0, gen_loss = 0.6878409554941729, disc_loss = 0.22296210643202585
Trained batch 287 in epoch 0, gen_loss = 0.6880547113509642, disc_loss = 0.22275602411375278
Trained batch 288 in epoch 0, gen_loss = 0.687726195192667, disc_loss = 0.2225364232403597
Trained batch 289 in epoch 0, gen_loss = 0.6872842101187542, disc_loss = 0.22215121881715183
Trained batch 290 in epoch 0, gen_loss = 0.6875731501587478, disc_loss = 0.22173800670199378
Trained batch 291 in epoch 0, gen_loss = 0.687631866192981, disc_loss = 0.22128740703202274
Trained batch 292 in epoch 0, gen_loss = 0.687549639785656, disc_loss = 0.2212957139206421
Trained batch 293 in epoch 0, gen_loss = 0.6869946115073704, disc_loss = 0.2211817985996097
Trained batch 294 in epoch 0, gen_loss = 0.6871059838998116, disc_loss = 0.22099382897554817
Trained batch 295 in epoch 0, gen_loss = 0.6874835816388195, disc_loss = 0.220700822468545
Trained batch 296 in epoch 0, gen_loss = 0.6871496586486546, disc_loss = 0.22076625645361364
Trained batch 297 in epoch 0, gen_loss = 0.6874345463994366, disc_loss = 0.22050330557879186
Trained batch 298 in epoch 0, gen_loss = 0.6870729718917987, disc_loss = 0.2201747698927404
Trained batch 299 in epoch 0, gen_loss = 0.6865196093916893, disc_loss = 0.22015291919310886
Trained batch 300 in epoch 0, gen_loss = 0.68681977525898, disc_loss = 0.22008577815916056
Trained batch 301 in epoch 0, gen_loss = 0.6866396303405825, disc_loss = 0.2198522352915726
Trained batch 302 in epoch 0, gen_loss = 0.6863594304020255, disc_loss = 0.21957112829087197
Trained batch 303 in epoch 0, gen_loss = 0.6873995180388814, disc_loss = 0.21920750701898023
Trained batch 304 in epoch 0, gen_loss = 0.6871490823440864, disc_loss = 0.21908972429447487
Trained batch 305 in epoch 0, gen_loss = 0.6871460400570452, disc_loss = 0.21867602109129913
Trained batch 306 in epoch 0, gen_loss = 0.6875408477231811, disc_loss = 0.2183817936174256
Trained batch 307 in epoch 0, gen_loss = 0.6866712654372314, disc_loss = 0.21845598315650766
Trained batch 308 in epoch 0, gen_loss = 0.6874560951993689, disc_loss = 0.21895828235496595
Trained batch 309 in epoch 0, gen_loss = 0.6872329774402803, disc_loss = 0.21882586426311923
Trained batch 310 in epoch 0, gen_loss = 0.687112361384358, disc_loss = 0.21872372244906962
Trained batch 311 in epoch 0, gen_loss = 0.6871252567149125, disc_loss = 0.218302777944467
Trained batch 312 in epoch 0, gen_loss = 0.6871781736707535, disc_loss = 0.21791236559613444
Trained batch 313 in epoch 0, gen_loss = 0.6877106372148368, disc_loss = 0.21755260898239293
Trained batch 314 in epoch 0, gen_loss = 0.68765723922896, disc_loss = 0.2170482522438443
Trained batch 315 in epoch 0, gen_loss = 0.6877289475708068, disc_loss = 0.21665330070860778
Trained batch 316 in epoch 0, gen_loss = 0.6873369828947711, disc_loss = 0.21626045129464627
Trained batch 317 in epoch 0, gen_loss = 0.687915046728632, disc_loss = 0.21594343870971938
Trained batch 318 in epoch 0, gen_loss = 0.6877433099903657, disc_loss = 0.21568399506583108
Trained batch 319 in epoch 0, gen_loss = 0.6878986195661128, disc_loss = 0.2152798736700788
Trained batch 320 in epoch 0, gen_loss = 0.6879431424296905, disc_loss = 0.21504748946873942
Trained batch 321 in epoch 0, gen_loss = 0.6873912780736544, disc_loss = 0.21513749920525907
Trained batch 322 in epoch 0, gen_loss = 0.688432409575111, disc_loss = 0.2153805878370908
Trained batch 323 in epoch 0, gen_loss = 0.6892774821615514, disc_loss = 0.21491715788013405
Trained batch 324 in epoch 0, gen_loss = 0.6888998969701621, disc_loss = 0.21488327267078253
Trained batch 325 in epoch 0, gen_loss = 0.6888691189647452, disc_loss = 0.2144455399615633
Trained batch 326 in epoch 0, gen_loss = 0.6894116090889736, disc_loss = 0.21431851437150157
Trained batch 327 in epoch 0, gen_loss = 0.6899469828278553, disc_loss = 0.21394636388868093
Trained batch 328 in epoch 0, gen_loss = 0.6896831671336502, disc_loss = 0.2135488469051735
Trained batch 329 in epoch 0, gen_loss = 0.6903206492012197, disc_loss = 0.21297711175725315
Trained batch 330 in epoch 0, gen_loss = 0.6906111574425078, disc_loss = 0.21251227756191238
Trained batch 331 in epoch 0, gen_loss = 0.6905641062970621, disc_loss = 0.2122445345059576
Trained batch 332 in epoch 0, gen_loss = 0.6909859161656182, disc_loss = 0.21174817847775984
Trained batch 333 in epoch 0, gen_loss = 0.6911857762558018, disc_loss = 0.21123178402508447
Trained batch 334 in epoch 0, gen_loss = 0.6913745146189163, disc_loss = 0.21081602343205197
Trained batch 335 in epoch 0, gen_loss = 0.6930955988133237, disc_loss = 0.21079953854149652
Trained batch 336 in epoch 0, gen_loss = 0.6921970616992927, disc_loss = 0.2113454049723969
Trained batch 337 in epoch 0, gen_loss = 0.6923149468807074, disc_loss = 0.21123829621755513
Trained batch 338 in epoch 0, gen_loss = 0.6923129288671994, disc_loss = 0.2110700919498912
Trained batch 339 in epoch 0, gen_loss = 0.6921967980616233, disc_loss = 0.21075081278515212
Trained batch 340 in epoch 0, gen_loss = 0.6917777258105292, disc_loss = 0.2107008349183193
Trained batch 341 in epoch 0, gen_loss = 0.6922919860883066, disc_loss = 0.21088455971439332
Trained batch 342 in epoch 0, gen_loss = 0.6923526505513372, disc_loss = 0.210543128789427
Trained batch 343 in epoch 0, gen_loss = 0.6924027002654797, disc_loss = 0.21017213920564498
Trained batch 344 in epoch 0, gen_loss = 0.6924791217714116, disc_loss = 0.2097887722802335
Trained batch 345 in epoch 0, gen_loss = 0.6935094008383723, disc_loss = 0.2095270112609071
Trained batch 346 in epoch 0, gen_loss = 0.6934516927179067, disc_loss = 0.20934725208181126
Trained batch 347 in epoch 0, gen_loss = 0.6934049087523044, disc_loss = 0.20890546596512713
Trained batch 348 in epoch 0, gen_loss = 0.6943463697645248, disc_loss = 0.20843403620970966
Trained batch 349 in epoch 0, gen_loss = 0.694905795114381, disc_loss = 0.20796702168881892
Trained batch 350 in epoch 0, gen_loss = 0.6947062074119209, disc_loss = 0.20761075718832492
Trained batch 351 in epoch 0, gen_loss = 0.6953954565423456, disc_loss = 0.20710174303332513
Trained batch 352 in epoch 0, gen_loss = 0.6960769605535285, disc_loss = 0.20657496850293858
Trained batch 353 in epoch 0, gen_loss = 0.6961979745639919, disc_loss = 0.20628460496137876
Trained batch 354 in epoch 0, gen_loss = 0.697132246007382, disc_loss = 0.20575171681776852
Trained batch 355 in epoch 0, gen_loss = 0.6972853937343265, disc_loss = 0.20538135391942572
Trained batch 356 in epoch 0, gen_loss = 0.6978506425014731, disc_loss = 0.204894078232828
Trained batch 357 in epoch 0, gen_loss = 0.6981827177981424, disc_loss = 0.2044489629067189
Trained batch 358 in epoch 0, gen_loss = 0.6981714677511816, disc_loss = 0.20414014307984402
Trained batch 359 in epoch 0, gen_loss = 0.6980103733638923, disc_loss = 0.20375221535149549
Trained batch 360 in epoch 0, gen_loss = 0.6990203324942708, disc_loss = 0.20375997346111283
Trained batch 361 in epoch 0, gen_loss = 0.6987154086156445, disc_loss = 0.20378501649472594
Trained batch 362 in epoch 0, gen_loss = 0.6988991910268453, disc_loss = 0.20333079595539524
Trained batch 363 in epoch 0, gen_loss = 0.6995798721909523, disc_loss = 0.20289118468229259
Trained batch 364 in epoch 0, gen_loss = 0.7003266596630828, disc_loss = 0.20238665139226064
Trained batch 365 in epoch 0, gen_loss = 0.7003392744096902, disc_loss = 0.20216417928414593
Trained batch 366 in epoch 0, gen_loss = 0.7003617904653991, disc_loss = 0.20174987110682338
Trained batch 367 in epoch 0, gen_loss = 0.7016290048056323, disc_loss = 0.20173693177006816
Trained batch 368 in epoch 0, gen_loss = 0.7010738952211572, disc_loss = 0.20189051007029163
Trained batch 369 in epoch 0, gen_loss = 0.701646745446566, disc_loss = 0.2014167531468981
Trained batch 370 in epoch 0, gen_loss = 0.7022143310774369, disc_loss = 0.20090255282839353
Trained batch 371 in epoch 0, gen_loss = 0.7029271253174351, disc_loss = 0.20043356281014219
Trained batch 372 in epoch 0, gen_loss = 0.703197297957244, disc_loss = 0.19996359437983732
Trained batch 373 in epoch 0, gen_loss = 0.703321543208418, disc_loss = 0.1995189566125366
Trained batch 374 in epoch 0, gen_loss = 0.7043710876305898, disc_loss = 0.19920196560025216
Trained batch 375 in epoch 0, gen_loss = 0.7046505896810521, disc_loss = 0.19872334917531687
Trained batch 376 in epoch 0, gen_loss = 0.7050759785213269, disc_loss = 0.19823695068304434
Trained batch 377 in epoch 0, gen_loss = 0.7054301622525725, disc_loss = 0.19775544268833029
Trained batch 378 in epoch 0, gen_loss = 0.7059370431075939, disc_loss = 0.1972616165311206
Trained batch 379 in epoch 0, gen_loss = 0.7065136060118675, disc_loss = 0.19677954887922264
Trained batch 380 in epoch 0, gen_loss = 0.7063430942731892, disc_loss = 0.19658408041437234
Trained batch 381 in epoch 0, gen_loss = 0.7076694320165674, disc_loss = 0.1964452906355691
Trained batch 382 in epoch 0, gen_loss = 0.7073227329758378, disc_loss = 0.19631069248138536
Trained batch 383 in epoch 0, gen_loss = 0.7078627224545926, disc_loss = 0.19615578328618236
Trained batch 384 in epoch 0, gen_loss = 0.7074737956771603, disc_loss = 0.1967750924288646
Trained batch 385 in epoch 0, gen_loss = 0.70742271006725, disc_loss = 0.19663400588306199
Trained batch 386 in epoch 0, gen_loss = 0.7084133374752616, disc_loss = 0.19632193793901254
Trained batch 387 in epoch 0, gen_loss = 0.7091901492058617, disc_loss = 0.1959166011902667
Trained batch 388 in epoch 0, gen_loss = 0.7091345455315549, disc_loss = 0.1955656044324022
Trained batch 389 in epoch 0, gen_loss = 0.7093141227960587, disc_loss = 0.19514863008919817
Trained batch 390 in epoch 0, gen_loss = 0.7089938330071052, disc_loss = 0.19502868592176978
Trained batch 391 in epoch 0, gen_loss = 0.7088082228236052, disc_loss = 0.19485677051956632
Trained batch 392 in epoch 0, gen_loss = 0.7092694146487549, disc_loss = 0.1949367928449017
Trained batch 393 in epoch 0, gen_loss = 0.7097811356262507, disc_loss = 0.19451754855294592
Trained batch 394 in epoch 0, gen_loss = 0.7092592796947382, disc_loss = 0.19460740599875587
Trained batch 395 in epoch 0, gen_loss = 0.708918435781291, disc_loss = 0.19442566208814205
Trained batch 396 in epoch 0, gen_loss = 0.709071223096223, disc_loss = 0.19417155653435353
Trained batch 397 in epoch 0, gen_loss = 0.7095107737947349, disc_loss = 0.19393199318364712
Trained batch 398 in epoch 0, gen_loss = 0.7098047622015005, disc_loss = 0.19360937091538258
Trained batch 399 in epoch 0, gen_loss = 0.7110069432109595, disc_loss = 0.19320262591587378
Trained batch 400 in epoch 0, gen_loss = 0.710719096467382, disc_loss = 0.19316194612681495
Trained batch 401 in epoch 0, gen_loss = 0.711501787625142, disc_loss = 0.19277187675209856
Trained batch 402 in epoch 0, gen_loss = 0.7122316449954551, disc_loss = 0.1924781312463486
Trained batch 403 in epoch 0, gen_loss = 0.7122429542169713, disc_loss = 0.19212593337622388
Trained batch 404 in epoch 0, gen_loss = 0.7122263249791698, disc_loss = 0.19196727636649652
Trained batch 405 in epoch 0, gen_loss = 0.7123852653309629, disc_loss = 0.19165766573387194
Trained batch 406 in epoch 0, gen_loss = 0.7125780531903156, disc_loss = 0.19122325077295962
Trained batch 407 in epoch 0, gen_loss = 0.7125820499278751, disc_loss = 0.1908613229923717
Trained batch 408 in epoch 0, gen_loss = 0.713067919161617, disc_loss = 0.1904530553283821
Trained batch 409 in epoch 0, gen_loss = 0.7138534737069432, disc_loss = 0.19011775573442985
Trained batch 410 in epoch 0, gen_loss = 0.7137898223388514, disc_loss = 0.18977460466606266
Trained batch 411 in epoch 0, gen_loss = 0.7139413445753958, disc_loss = 0.18937885416536004
Trained batch 412 in epoch 0, gen_loss = 0.7144984707561013, disc_loss = 0.18894830758324835
Trained batch 413 in epoch 0, gen_loss = 0.714428030854262, disc_loss = 0.18869748555915655
Trained batch 414 in epoch 0, gen_loss = 0.7155512358050748, disc_loss = 0.18849099884370724
Trained batch 415 in epoch 0, gen_loss = 0.715930200755023, disc_loss = 0.18806156919722875
Trained batch 416 in epoch 0, gen_loss = 0.7158869638574495, disc_loss = 0.18772486992832496
Trained batch 417 in epoch 0, gen_loss = 0.7166074433822951, disc_loss = 0.18730483170482887
Trained batch 418 in epoch 0, gen_loss = 0.717426274656396, disc_loss = 0.186986413939916
Trained batch 419 in epoch 0, gen_loss = 0.7177581797753062, disc_loss = 0.1865687605769684
Trained batch 420 in epoch 0, gen_loss = 0.7179059582339896, disc_loss = 0.1862088267950257
Trained batch 421 in epoch 0, gen_loss = 0.7181977823871006, disc_loss = 0.185827363196372
Trained batch 422 in epoch 0, gen_loss = 0.718534997098553, disc_loss = 0.18541912624423104
Trained batch 423 in epoch 0, gen_loss = 0.7190015326552796, disc_loss = 0.18502148374352814
Trained batch 424 in epoch 0, gen_loss = 0.7185662156694076, disc_loss = 0.18494488789754757
Trained batch 425 in epoch 0, gen_loss = 0.7197639155136027, disc_loss = 0.1854225484907907
Trained batch 426 in epoch 0, gen_loss = 0.7201152545088069, disc_loss = 0.18503769228902298
Trained batch 427 in epoch 0, gen_loss = 0.7201937155049538, disc_loss = 0.18467419312083136
Trained batch 428 in epoch 0, gen_loss = 0.7200074586973879, disc_loss = 0.18452222615324118
Trained batch 429 in epoch 0, gen_loss = 0.7205279910980269, disc_loss = 0.1845878844127752
Trained batch 430 in epoch 0, gen_loss = 0.7204514304197581, disc_loss = 0.18428476288344217
Trained batch 431 in epoch 0, gen_loss = 0.7200670383732628, disc_loss = 0.1842394889789392
Trained batch 432 in epoch 0, gen_loss = 0.7203437558635553, disc_loss = 0.18409917879135587
Trained batch 433 in epoch 0, gen_loss = 0.7202020024511672, disc_loss = 0.18377600074209238
Trained batch 434 in epoch 0, gen_loss = 0.7204259050988603, disc_loss = 0.18348519084868076
Trained batch 435 in epoch 0, gen_loss = 0.7197678805491247, disc_loss = 0.18388782464258305
Trained batch 436 in epoch 0, gen_loss = 0.7202853602730164, disc_loss = 0.18394110062387634
Trained batch 437 in epoch 0, gen_loss = 0.7201169802717966, disc_loss = 0.1837422312131007
Trained batch 438 in epoch 0, gen_loss = 0.7201444184861585, disc_loss = 0.18361437428055294
Trained batch 439 in epoch 0, gen_loss = 0.7197802115570415, disc_loss = 0.18356582223099063
Trained batch 440 in epoch 0, gen_loss = 0.7205430207068688, disc_loss = 0.18331786485435336
Trained batch 441 in epoch 0, gen_loss = 0.7202067265952874, disc_loss = 0.18340684940861496
Trained batch 442 in epoch 0, gen_loss = 0.7208930901157129, disc_loss = 0.18308387801437964
Trained batch 443 in epoch 0, gen_loss = 0.7213354726900926, disc_loss = 0.18276038106849735
Trained batch 444 in epoch 0, gen_loss = 0.7222049454624733, disc_loss = 0.1824137805134393
Trained batch 445 in epoch 0, gen_loss = 0.7229236125144188, disc_loss = 0.18203499711707502
Trained batch 446 in epoch 0, gen_loss = 0.7230751291750794, disc_loss = 0.1817416174762301
Trained batch 447 in epoch 0, gen_loss = 0.7231160581910184, disc_loss = 0.18143050281755027
Trained batch 448 in epoch 0, gen_loss = 0.7236447218797255, disc_loss = 0.18106382916617167
Trained batch 449 in epoch 0, gen_loss = 0.7241745744811164, disc_loss = 0.1808631870874928
Trained batch 450 in epoch 0, gen_loss = 0.7254221790910031, disc_loss = 0.18053446799937942
Trained batch 451 in epoch 0, gen_loss = 0.7259603192848442, disc_loss = 0.18026306452765337
Trained batch 452 in epoch 0, gen_loss = 0.7269666850172132, disc_loss = 0.1800826663998414
Trained batch 453 in epoch 0, gen_loss = 0.7283072327202113, disc_loss = 0.1798465495194731
Trained batch 454 in epoch 0, gen_loss = 0.729590515775995, disc_loss = 0.17987813986223805
Trained batch 455 in epoch 0, gen_loss = 0.7307565444917009, disc_loss = 0.17986142031415447
Trained batch 456 in epoch 0, gen_loss = 0.7312760037457656, disc_loss = 0.1795386716425908
Trained batch 457 in epoch 0, gen_loss = 0.732206936226141, disc_loss = 0.179218579431402
Trained batch 458 in epoch 0, gen_loss = 0.7329437166517336, disc_loss = 0.17886629731298986
Trained batch 459 in epoch 0, gen_loss = 0.733886206150055, disc_loss = 0.17852114659086193
Trained batch 460 in epoch 0, gen_loss = 0.7346034218070305, disc_loss = 0.17816163622117612
Trained batch 461 in epoch 0, gen_loss = 0.7349489660232098, disc_loss = 0.1778153342666564
Trained batch 462 in epoch 0, gen_loss = 0.7354006961663907, disc_loss = 0.1774650772965109
Trained batch 463 in epoch 0, gen_loss = 0.7364106785891384, disc_loss = 0.17711201284064687
Trained batch 464 in epoch 0, gen_loss = 0.7373302968599463, disc_loss = 0.1767547788579137
Trained batch 465 in epoch 0, gen_loss = 0.738181288278154, disc_loss = 0.1763894399927825
Trained batch 466 in epoch 0, gen_loss = 0.7387446924501619, disc_loss = 0.1760368607798691
Trained batch 467 in epoch 0, gen_loss = 0.7396723017988042, disc_loss = 0.17567896834399518
Trained batch 468 in epoch 0, gen_loss = 0.7403858169309621, disc_loss = 0.1753188192860277
Trained batch 469 in epoch 0, gen_loss = 0.7409521507455947, disc_loss = 0.17498791612526204
Trained batch 470 in epoch 0, gen_loss = 0.741723479105915, disc_loss = 0.1746406890115762
Trained batch 471 in epoch 0, gen_loss = 0.74217162799027, disc_loss = 0.17429426791722555
Trained batch 472 in epoch 0, gen_loss = 0.7433168106804943, disc_loss = 0.17399014802905582
Trained batch 473 in epoch 0, gen_loss = 0.7439249864610439, disc_loss = 0.17364033203737078
Trained batch 474 in epoch 0, gen_loss = 0.7440221763912, disc_loss = 0.17331204849050233
Trained batch 475 in epoch 0, gen_loss = 0.7442029733367327, disc_loss = 0.17297995343663486
Trained batch 476 in epoch 0, gen_loss = 0.7453577462232338, disc_loss = 0.17265292862723083
Trained batch 477 in epoch 0, gen_loss = 0.746352404106611, disc_loss = 0.17231017998789894
Trained batch 478 in epoch 0, gen_loss = 0.7472317620707454, disc_loss = 0.17196532466209694
Trained batch 479 in epoch 0, gen_loss = 0.7480456991742055, disc_loss = 0.1716556012921501
Trained batch 480 in epoch 0, gen_loss = 0.7487370386688724, disc_loss = 0.1713237384810517
Trained batch 481 in epoch 0, gen_loss = 0.7493812334240719, disc_loss = 0.17098915951009608
Trained batch 482 in epoch 0, gen_loss = 0.7502930439530445, disc_loss = 0.17065199648895865
Trained batch 483 in epoch 0, gen_loss = 0.7510266236283563, disc_loss = 0.17031265342461854
Trained batch 484 in epoch 0, gen_loss = 0.7517806595133752, disc_loss = 0.169976126239395
Trained batch 485 in epoch 0, gen_loss = 0.7524761154082577, disc_loss = 0.16963737053171934
Trained batch 486 in epoch 0, gen_loss = 0.7532243744548586, disc_loss = 0.16929813804299987
Trained batch 487 in epoch 0, gen_loss = 0.7538581149744206, disc_loss = 0.16896200019934932
Trained batch 488 in epoch 0, gen_loss = 0.7543434665246975, disc_loss = 0.16862621354910493
Trained batch 489 in epoch 0, gen_loss = 0.7550705328279612, disc_loss = 0.1683013526304644
Trained batch 490 in epoch 0, gen_loss = 0.7554212119088882, disc_loss = 0.16796609027123424
Trained batch 491 in epoch 0, gen_loss = 0.7560063481815462, disc_loss = 0.1676360271938289
Trained batch 492 in epoch 0, gen_loss = 0.7566126812302316, disc_loss = 0.1673057945619921
Trained batch 493 in epoch 0, gen_loss = 0.7572450102099523, disc_loss = 0.16699104980510934
Trained batch 494 in epoch 0, gen_loss = 0.7578351121960264, disc_loss = 0.16666437740099024
Trained batch 495 in epoch 0, gen_loss = 0.7582905996711023, disc_loss = 0.1663438831413758
Trained batch 496 in epoch 0, gen_loss = 0.7587337502291505, disc_loss = 0.16601762116954136
Trained batch 497 in epoch 0, gen_loss = 0.7591830690701803, disc_loss = 0.1656963451083817
Trained batch 498 in epoch 0, gen_loss = 0.7594710182331368, disc_loss = 0.16537595252442977
Trained batch 499 in epoch 0, gen_loss = 0.7596235892772675, disc_loss = 0.16509035156993196
Trained batch 500 in epoch 0, gen_loss = 0.7596883394285114, disc_loss = 0.16479378703660044
Trained batch 501 in epoch 0, gen_loss = 0.7604592317841442, disc_loss = 0.16451325527980434
Trained batch 502 in epoch 0, gen_loss = 0.7614182332164013, disc_loss = 0.16427494204051377
Trained batch 503 in epoch 0, gen_loss = 0.7619621546732055, disc_loss = 0.16397859699172262
Trained batch 504 in epoch 0, gen_loss = 0.7622832984027296, disc_loss = 0.16368590117303083
Trained batch 505 in epoch 0, gen_loss = 0.762642480050151, disc_loss = 0.1633821607548044
Trained batch 506 in epoch 0, gen_loss = 0.7630306019115259, disc_loss = 0.1630682536071126
Trained batch 507 in epoch 0, gen_loss = 0.7635557003847258, disc_loss = 0.16276372648275084
Trained batch 508 in epoch 0, gen_loss = 0.7638102445480631, disc_loss = 0.16249247679481382
Trained batch 509 in epoch 0, gen_loss = 0.7642704398024316, disc_loss = 0.16218818927905065
Trained batch 510 in epoch 0, gen_loss = 0.76487775324842, disc_loss = 0.16195368322766152
Trained batch 511 in epoch 0, gen_loss = 0.7649657195433974, disc_loss = 0.16166538731113178
Trained batch 512 in epoch 0, gen_loss = 0.7645163395483824, disc_loss = 0.1616235505004339
Trained batch 513 in epoch 0, gen_loss = 0.7653220007159831, disc_loss = 0.16151292608092369
Trained batch 514 in epoch 0, gen_loss = 0.7660605035939263, disc_loss = 0.16124482558615216
Trained batch 515 in epoch 0, gen_loss = 0.7664533975974533, disc_loss = 0.16094665402634964
Trained batch 516 in epoch 0, gen_loss = 0.7664888817060386, disc_loss = 0.16068837295261137
Trained batch 517 in epoch 0, gen_loss = 0.7668344408388764, disc_loss = 0.1603889944086671
Trained batch 518 in epoch 0, gen_loss = 0.7671466712088024, disc_loss = 0.1600959883066996
Trained batch 519 in epoch 0, gen_loss = 0.7674799715097134, disc_loss = 0.15980183846415738
Trained batch 520 in epoch 0, gen_loss = 0.7674907239979837, disc_loss = 0.15954057647374723
Trained batch 521 in epoch 0, gen_loss = 0.7679948653754604, disc_loss = 0.1592698026679535
Trained batch 522 in epoch 0, gen_loss = 0.7684191175902095, disc_loss = 0.15897615795579328
Trained batch 523 in epoch 0, gen_loss = 0.7689429473785954, disc_loss = 0.15868378193819724
Trained batch 524 in epoch 0, gen_loss = 0.7693833162671043, disc_loss = 0.1583902073043975
Trained batch 525 in epoch 0, gen_loss = 0.7698927780067966, disc_loss = 0.1581027155070116
Trained batch 526 in epoch 0, gen_loss = 0.7702440855851436, disc_loss = 0.15781535594936186
Trained batch 527 in epoch 0, gen_loss = 0.7706525400280952, disc_loss = 0.15753057381009444
Trained batch 528 in epoch 0, gen_loss = 0.77100378635475, disc_loss = 0.1572504613406794
Trained batch 529 in epoch 0, gen_loss = 0.7713661936094176, disc_loss = 0.15696435017766044
Trained batch 530 in epoch 0, gen_loss = 0.7717087924368189, disc_loss = 0.15668000163301726
Trained batch 531 in epoch 0, gen_loss = 0.772023770594059, disc_loss = 0.15639517206087694
Trained batch 532 in epoch 0, gen_loss = 0.7723629068702068, disc_loss = 0.15610872050284236
Trained batch 533 in epoch 0, gen_loss = 0.7727807420916325, disc_loss = 0.15582359105100932
Trained batch 534 in epoch 0, gen_loss = 0.7731712548532219, disc_loss = 0.15554012343304877
Trained batch 535 in epoch 0, gen_loss = 0.7734004786210273, disc_loss = 0.15526496803426226
Trained batch 536 in epoch 0, gen_loss = 0.7736789779512132, disc_loss = 0.15498622123835334
Trained batch 537 in epoch 0, gen_loss = 0.7740333382746544, disc_loss = 0.15470768941036636
Trained batch 538 in epoch 0, gen_loss = 0.7742289630955358, disc_loss = 0.15443927341387892
Trained batch 539 in epoch 0, gen_loss = 0.7744828585121367, disc_loss = 0.1541631693693085
Trained batch 540 in epoch 0, gen_loss = 0.7748103704778633, disc_loss = 0.15388518219767225
Trained batch 541 in epoch 0, gen_loss = 0.7752222302215126, disc_loss = 0.15361087480723185
Trained batch 542 in epoch 0, gen_loss = 0.7756928018882568, disc_loss = 0.15333385722545315
Trained batch 543 in epoch 0, gen_loss = 0.77598824932733, disc_loss = 0.15305774228096092
Trained batch 544 in epoch 0, gen_loss = 0.7763986697984397, disc_loss = 0.15278371521015438
Trained batch 545 in epoch 0, gen_loss = 0.776692964109309, disc_loss = 0.15250994538079823
Trained batch 546 in epoch 0, gen_loss = 0.7770595924292012, disc_loss = 0.15226229408354083
Trained batch 547 in epoch 0, gen_loss = 0.7771415761569991, disc_loss = 0.1520075095353485
Trained batch 548 in epoch 0, gen_loss = 0.7774681033115353, disc_loss = 0.15174427759988007
Trained batch 549 in epoch 0, gen_loss = 0.7777830836989663, disc_loss = 0.15147690052335913
Trained batch 550 in epoch 0, gen_loss = 0.7781685595071034, disc_loss = 0.15120967102495653
Trained batch 551 in epoch 0, gen_loss = 0.7785387503496115, disc_loss = 0.15094253369413005
Trained batch 552 in epoch 0, gen_loss = 0.7787189352145893, disc_loss = 0.15067579653021454
Trained batch 553 in epoch 0, gen_loss = 0.7789999979282545, disc_loss = 0.15041215282096612
Trained batch 554 in epoch 0, gen_loss = 0.7790876170536419, disc_loss = 0.15015061153140893
Trained batch 555 in epoch 0, gen_loss = 0.7792913238350436, disc_loss = 0.14988636616290807
Trained batch 556 in epoch 0, gen_loss = 0.7794345396853435, disc_loss = 0.14962392221154774
Trained batch 557 in epoch 0, gen_loss = 0.7795332448029604, disc_loss = 0.14936129488159425
Trained batch 558 in epoch 0, gen_loss = 0.7796621548681651, disc_loss = 0.14911116717994707
Trained batch 559 in epoch 0, gen_loss = 0.7798329035086291, disc_loss = 0.1488635839333126
Trained batch 560 in epoch 0, gen_loss = 0.7803357150040421, disc_loss = 0.14863666827348848
Trained batch 561 in epoch 0, gen_loss = 0.7797617183673424, disc_loss = 0.14882424313722517
Trained batch 562 in epoch 0, gen_loss = 0.7805731835416113, disc_loss = 0.14915300457453814
Trained batch 563 in epoch 0, gen_loss = 0.7810231659640657, disc_loss = 0.14891550004530157
Trained batch 564 in epoch 0, gen_loss = 0.7813779530272019, disc_loss = 0.14866572582921161
Trained batch 565 in epoch 0, gen_loss = 0.7812548382964657, disc_loss = 0.1484687962300266
Trained batch 566 in epoch 0, gen_loss = 0.7817092667181025, disc_loss = 0.1482188871908092
Trained batch 567 in epoch 0, gen_loss = 0.7822204675053207, disc_loss = 0.14796686224913239
Trained batch 568 in epoch 0, gen_loss = 0.7826372393405291, disc_loss = 0.14771727149977115
Trained batch 569 in epoch 0, gen_loss = 0.7829622567745678, disc_loss = 0.14746293773948166
Trained batch 570 in epoch 0, gen_loss = 0.7832123738454227, disc_loss = 0.14721794150021064
Trained batch 571 in epoch 0, gen_loss = 0.7834608735112877, disc_loss = 0.14697558256362767
Trained batch 572 in epoch 0, gen_loss = 0.7833334056702792, disc_loss = 0.14679297658592058
Trained batch 573 in epoch 0, gen_loss = 0.7836215414028965, disc_loss = 0.14656444503203722
Trained batch 574 in epoch 0, gen_loss = 0.7843249361411385, disc_loss = 0.14638015695766587
Trained batch 575 in epoch 0, gen_loss = 0.7846883465018537, disc_loss = 0.14613560996602043
Trained batch 576 in epoch 0, gen_loss = 0.7849253922236028, disc_loss = 0.14589586177238778
Trained batch 577 in epoch 0, gen_loss = 0.785155730676486, disc_loss = 0.14565715681202387
Trained batch 578 in epoch 0, gen_loss = 0.7852544329532893, disc_loss = 0.14541519108061102
Trained batch 579 in epoch 0, gen_loss = 0.7854626733681251, disc_loss = 0.1451776162074911
Trained batch 580 in epoch 0, gen_loss = 0.785197355045509, disc_loss = 0.14500425546590348
Trained batch 581 in epoch 0, gen_loss = 0.7856230782889009, disc_loss = 0.14479117505404382
Trained batch 582 in epoch 0, gen_loss = 0.7855196654489887, disc_loss = 0.14467335423641545
Trained batch 583 in epoch 0, gen_loss = 0.7859107050789546, disc_loss = 0.1445117207807776
Trained batch 584 in epoch 0, gen_loss = 0.7859845068719652, disc_loss = 0.14431342849324846
Trained batch 585 in epoch 0, gen_loss = 0.7854312651189927, disc_loss = 0.1442845395345832
Trained batch 586 in epoch 0, gen_loss = 0.7853363853906244, disc_loss = 0.14419120456190426
Trained batch 587 in epoch 0, gen_loss = 0.7855670723785348, disc_loss = 0.14401136019360591
Trained batch 588 in epoch 0, gen_loss = 0.7857978145618795, disc_loss = 0.14378523468419416
Trained batch 589 in epoch 0, gen_loss = 0.7858069754253, disc_loss = 0.14356495920623952
Trained batch 590 in epoch 0, gen_loss = 0.7854784756344184, disc_loss = 0.14362776688656215
Trained batch 591 in epoch 0, gen_loss = 0.7859602887686845, disc_loss = 0.1437677371616922
Trained batch 592 in epoch 0, gen_loss = 0.7859165667482412, disc_loss = 0.14357963381028888
Trained batch 593 in epoch 0, gen_loss = 0.785689533057839, disc_loss = 0.1434096760231757
Trained batch 594 in epoch 0, gen_loss = 0.7852949101383947, disc_loss = 0.14344605843677427
Trained batch 595 in epoch 0, gen_loss = 0.7851039931278101, disc_loss = 0.1433436462804894
Trained batch 596 in epoch 0, gen_loss = 0.7853314581029179, disc_loss = 0.14329905790616906
Trained batch 597 in epoch 0, gen_loss = 0.7848332118629213, disc_loss = 0.1437306398145051
Trained batch 598 in epoch 0, gen_loss = 0.7845225515270073, disc_loss = 0.14381489314516704
Trained batch 599 in epoch 0, gen_loss = 0.7843072726329168, disc_loss = 0.14392746366676876
Trained batch 600 in epoch 0, gen_loss = 0.7841957238271907, disc_loss = 0.1441401895054286
Trained batch 601 in epoch 0, gen_loss = 0.784111732660338, disc_loss = 0.1444796712653699
Trained batch 602 in epoch 0, gen_loss = 0.784120954783204, disc_loss = 0.14471929620566837
Trained batch 603 in epoch 0, gen_loss = 0.7837401744940423, disc_loss = 0.14484101753575504
Trained batch 604 in epoch 0, gen_loss = 0.7834473550812272, disc_loss = 0.1450676816319354
Trained batch 605 in epoch 0, gen_loss = 0.7831350985926764, disc_loss = 0.14504090209818896
Trained batch 606 in epoch 0, gen_loss = 0.7827590206113246, disc_loss = 0.14524541775729735
Trained batch 607 in epoch 0, gen_loss = 0.7825418572480741, disc_loss = 0.14517134562935863
Trained batch 608 in epoch 0, gen_loss = 0.7825079032744484, disc_loss = 0.1450437113336075
Trained batch 609 in epoch 0, gen_loss = 0.7827052442753901, disc_loss = 0.14487834707261293
Trained batch 610 in epoch 0, gen_loss = 0.7826812399975016, disc_loss = 0.14466342613910388
Trained batch 611 in epoch 0, gen_loss = 0.7827494940142227, disc_loss = 0.1444585673625922
Trained batch 612 in epoch 0, gen_loss = 0.7826707297981661, disc_loss = 0.14431484192298333
Trained batch 613 in epoch 0, gen_loss = 0.7832912471667175, disc_loss = 0.14421017837281422
Trained batch 614 in epoch 0, gen_loss = 0.7837529588521012, disc_loss = 0.1439960101782155
Trained batch 615 in epoch 0, gen_loss = 0.7838551499820375, disc_loss = 0.14380217549752433
Trained batch 616 in epoch 0, gen_loss = 0.7841012055715441, disc_loss = 0.143587905004533
Trained batch 617 in epoch 0, gen_loss = 0.7840038247671713, disc_loss = 0.14339223103469664
Trained batch 618 in epoch 0, gen_loss = 0.7846947429831078, disc_loss = 0.1432072108905606
Trained batch 619 in epoch 0, gen_loss = 0.785332551790822, disc_loss = 0.14301598374544072
Trained batch 620 in epoch 0, gen_loss = 0.7855959994397493, disc_loss = 0.1428158254225419
Trained batch 621 in epoch 0, gen_loss = 0.7856526386316183, disc_loss = 0.14283754571432314
Trained batch 622 in epoch 0, gen_loss = 0.7854768411879746, disc_loss = 0.14272125993622092
Trained batch 623 in epoch 0, gen_loss = 0.7850924699734418, disc_loss = 0.14270859546265385
Trained batch 624 in epoch 0, gen_loss = 0.7847198715209961, disc_loss = 0.1426058063533157
Trained batch 625 in epoch 0, gen_loss = 0.785474043113355, disc_loss = 0.14297941032188613
Trained batch 626 in epoch 0, gen_loss = 0.785200055706444, disc_loss = 0.14299765961471964
Trained batch 627 in epoch 0, gen_loss = 0.7846879689556778, disc_loss = 0.14316153199119777
Trained batch 628 in epoch 0, gen_loss = 0.7844587642172373, disc_loss = 0.14319893789095642
Trained batch 629 in epoch 0, gen_loss = 0.7846296895117987, disc_loss = 0.14322523638155193
Trained batch 630 in epoch 0, gen_loss = 0.7849727347611247, disc_loss = 0.1431961667686317
Trained batch 631 in epoch 0, gen_loss = 0.784880786191059, disc_loss = 0.14301579945118026
Trained batch 632 in epoch 0, gen_loss = 0.7848672974166147, disc_loss = 0.14285880309238289
Trained batch 633 in epoch 0, gen_loss = 0.7847902874465245, disc_loss = 0.1426958616449107
Trained batch 634 in epoch 0, gen_loss = 0.7845208545369426, disc_loss = 0.14256544462478477
Trained batch 635 in epoch 0, gen_loss = 0.7846820802433686, disc_loss = 0.1424900631522086
Trained batch 636 in epoch 0, gen_loss = 0.7848552521581366, disc_loss = 0.14242027083220285
Trained batch 637 in epoch 0, gen_loss = 0.7842258356488236, disc_loss = 0.1428477049751943
Trained batch 638 in epoch 0, gen_loss = 0.7843169550847187, disc_loss = 0.14276504592062012
Trained batch 639 in epoch 0, gen_loss = 0.7843872583005578, disc_loss = 0.14267446177218518
Trained batch 640 in epoch 0, gen_loss = 0.7842012279770117, disc_loss = 0.1426812551197176
Trained batch 641 in epoch 0, gen_loss = 0.7842643470314804, disc_loss = 0.14258040704458336
Trained batch 642 in epoch 0, gen_loss = 0.7846707679899076, disc_loss = 0.14243761883667652
Trained batch 643 in epoch 0, gen_loss = 0.784708898398817, disc_loss = 0.1422457037206525
Trained batch 644 in epoch 0, gen_loss = 0.7848374876403069, disc_loss = 0.14204666414659095
Trained batch 645 in epoch 0, gen_loss = 0.7850956784405575, disc_loss = 0.1418354526409395
Trained batch 646 in epoch 0, gen_loss = 0.7853331942186105, disc_loss = 0.1416302285235594
Trained batch 647 in epoch 0, gen_loss = 0.7856832614375485, disc_loss = 0.14141986919761015
Trained batch 648 in epoch 0, gen_loss = 0.7859219456398616, disc_loss = 0.14121446205993313
Trained batch 649 in epoch 0, gen_loss = 0.7861236336139532, disc_loss = 0.141009430831943
Trained batch 650 in epoch 0, gen_loss = 0.7863347718517901, disc_loss = 0.14080370801712705
Trained batch 651 in epoch 0, gen_loss = 0.7865951605643963, disc_loss = 0.14060002212459793
Trained batch 652 in epoch 0, gen_loss = 0.7866934943619037, disc_loss = 0.1403937408744085
Trained batch 653 in epoch 0, gen_loss = 0.786919293463777, disc_loss = 0.14018677898778065
Trained batch 654 in epoch 0, gen_loss = 0.787112199486667, disc_loss = 0.13998349130701074
Trained batch 655 in epoch 0, gen_loss = 0.7875159232445607, disc_loss = 0.13978112478514781
Trained batch 656 in epoch 0, gen_loss = 0.7877775786764909, disc_loss = 0.1395804335010951
Trained batch 657 in epoch 0, gen_loss = 0.7880710610231005, disc_loss = 0.13937543465233604
Trained batch 658 in epoch 0, gen_loss = 0.7879627941682233, disc_loss = 0.13926078873398193
Trained batch 659 in epoch 0, gen_loss = 0.7880159199689374, disc_loss = 0.1392969556734897
Trained batch 660 in epoch 0, gen_loss = 0.7881335467776445, disc_loss = 0.13912073456197582
Trained batch 661 in epoch 0, gen_loss = 0.7883331515907881, disc_loss = 0.13892806711672803
Trained batch 662 in epoch 0, gen_loss = 0.7882515415436901, disc_loss = 0.13877857012110925
Trained batch 663 in epoch 0, gen_loss = 0.788053546459919, disc_loss = 0.1389621311482407
Trained batch 664 in epoch 0, gen_loss = 0.7881316284039863, disc_loss = 0.13889775283781713
Trained batch 665 in epoch 0, gen_loss = 0.7883706321497937, disc_loss = 0.13873095897987048
Trained batch 666 in epoch 0, gen_loss = 0.7887220829055048, disc_loss = 0.13853489881837977
Trained batch 667 in epoch 0, gen_loss = 0.7887475226007535, disc_loss = 0.13834906954486983
Trained batch 668 in epoch 0, gen_loss = 0.7888312693935873, disc_loss = 0.1382164274066024
Trained batch 669 in epoch 0, gen_loss = 0.7888804017163035, disc_loss = 0.1380338330937327
Trained batch 670 in epoch 0, gen_loss = 0.788802214200024, disc_loss = 0.1378708024042202
Trained batch 671 in epoch 0, gen_loss = 0.788654816603022, disc_loss = 0.13778229356622823
Trained batch 672 in epoch 0, gen_loss = 0.7891295657203952, disc_loss = 0.13801527689252585
Trained batch 673 in epoch 0, gen_loss = 0.7885967045580244, disc_loss = 0.1384687277958908
Trained batch 674 in epoch 0, gen_loss = 0.7886038559454459, disc_loss = 0.13830753303270926
Trained batch 675 in epoch 0, gen_loss = 0.7889851135967751, disc_loss = 0.13830443677807933
Trained batch 676 in epoch 0, gen_loss = 0.7888791155251653, disc_loss = 0.13817485151200265
Trained batch 677 in epoch 0, gen_loss = 0.7883420921972016, disc_loss = 0.13827348193929842
Trained batch 678 in epoch 0, gen_loss = 0.7885711394546661, disc_loss = 0.13827019268255927
Trained batch 679 in epoch 0, gen_loss = 0.7883349870495936, disc_loss = 0.13817517728962497
Trained batch 680 in epoch 0, gen_loss = 0.7881188832453169, disc_loss = 0.13812123236886434
Trained batch 681 in epoch 0, gen_loss = 0.7883507293427795, disc_loss = 0.13813062187023406
Trained batch 682 in epoch 0, gen_loss = 0.7880052980444616, disc_loss = 0.13819447404154103
Trained batch 683 in epoch 0, gen_loss = 0.7876481723628546, disc_loss = 0.1381810351730357
Trained batch 684 in epoch 0, gen_loss = 0.7884234998783056, disc_loss = 0.1387040258109923
Trained batch 685 in epoch 0, gen_loss = 0.7887131809406308, disc_loss = 0.13855993327428112
Trained batch 686 in epoch 0, gen_loss = 0.7882668686138664, disc_loss = 0.13877757899009038
Trained batch 687 in epoch 0, gen_loss = 0.7879510770097028, disc_loss = 0.13878702893237269
Trained batch 688 in epoch 0, gen_loss = 0.7878729586417859, disc_loss = 0.13869677191020324
Trained batch 689 in epoch 0, gen_loss = 0.7877892911866091, disc_loss = 0.13866866663995914
Trained batch 690 in epoch 0, gen_loss = 0.7876317160778211, disc_loss = 0.13864035851607845
Trained batch 691 in epoch 0, gen_loss = 0.7874338346495794, disc_loss = 0.13856169680500877
Trained batch 692 in epoch 0, gen_loss = 0.7875270374323554, disc_loss = 0.13844034077920836
Trained batch 693 in epoch 0, gen_loss = 0.7875122458429776, disc_loss = 0.13829532501882247
Trained batch 694 in epoch 0, gen_loss = 0.7873159845527128, disc_loss = 0.13816027574328263
Trained batch 695 in epoch 0, gen_loss = 0.7871210084821301, disc_loss = 0.13806811900543123
Trained batch 696 in epoch 0, gen_loss = 0.7875065385782223, disc_loss = 0.13796395755578714
Trained batch 697 in epoch 0, gen_loss = 0.7874404972894143, disc_loss = 0.13781078508354586
Trained batch 698 in epoch 0, gen_loss = 0.7875076348604222, disc_loss = 0.13765264329972154
Trained batch 699 in epoch 0, gen_loss = 0.7874005454352924, disc_loss = 0.13750592010128976
Trained batch 700 in epoch 0, gen_loss = 0.7869643679954186, disc_loss = 0.13746431168898166
Trained batch 701 in epoch 0, gen_loss = 0.787587381963037, disc_loss = 0.13814945057057046
Trained batch 702 in epoch 0, gen_loss = 0.7876748939920455, disc_loss = 0.13826189912719172
Trained batch 703 in epoch 0, gen_loss = 0.7874090027656745, disc_loss = 0.13832786057801885
Trained batch 704 in epoch 0, gen_loss = 0.787263485683617, disc_loss = 0.13821993088977186
Trained batch 705 in epoch 0, gen_loss = 0.7872762601115548, disc_loss = 0.1380471949951681
Trained batch 706 in epoch 0, gen_loss = 0.7874752262441238, disc_loss = 0.13790421010340173
Trained batch 707 in epoch 0, gen_loss = 0.7875774658921748, disc_loss = 0.1378010670568315
Trained batch 708 in epoch 0, gen_loss = 0.7875106125775783, disc_loss = 0.13765167310467444
Trained batch 709 in epoch 0, gen_loss = 0.7875524073839187, disc_loss = 0.13748078098632133
Trained batch 710 in epoch 0, gen_loss = 0.7874059991075352, disc_loss = 0.13759726082674278
Trained batch 711 in epoch 0, gen_loss = 0.7870046935473265, disc_loss = 0.13756566463343098
Trained batch 712 in epoch 0, gen_loss = 0.786668750756586, disc_loss = 0.13755765367138656
Trained batch 713 in epoch 0, gen_loss = 0.7867188465778902, disc_loss = 0.13772604643746802
Trained batch 714 in epoch 0, gen_loss = 0.7862219665850793, disc_loss = 0.1378410360407918
Trained batch 715 in epoch 0, gen_loss = 0.7864077930760117, disc_loss = 0.13780445231979338
Trained batch 716 in epoch 0, gen_loss = 0.7863170164150174, disc_loss = 0.1378117311058106
Trained batch 717 in epoch 0, gen_loss = 0.7858642817041668, disc_loss = 0.13793430256386208
Trained batch 718 in epoch 0, gen_loss = 0.7858077265291121, disc_loss = 0.13810459240495132
Trained batch 719 in epoch 0, gen_loss = 0.7855803147786193, disc_loss = 0.13813798236175595
Trained batch 720 in epoch 0, gen_loss = 0.7855235833400827, disc_loss = 0.13808682328445293
Trained batch 721 in epoch 0, gen_loss = 0.7854239906795798, disc_loss = 0.13799874859164182
Trained batch 722 in epoch 0, gen_loss = 0.7850343609746561, disc_loss = 0.13793636544190224
Trained batch 723 in epoch 0, gen_loss = 0.7850082957118915, disc_loss = 0.13780712193291048
Trained batch 724 in epoch 0, gen_loss = 0.7847767311129077, disc_loss = 0.1377786436269124
Trained batch 725 in epoch 0, gen_loss = 0.7851468461768358, disc_loss = 0.13792145269706116
Trained batch 726 in epoch 0, gen_loss = 0.7851023050089158, disc_loss = 0.13780346035251478
Trained batch 727 in epoch 0, gen_loss = 0.7846538720058871, disc_loss = 0.13811934463056777
Trained batch 728 in epoch 0, gen_loss = 0.7847330034678528, disc_loss = 0.13815544748043868
Trained batch 729 in epoch 0, gen_loss = 0.7844574790294856, disc_loss = 0.1381649863437354
Trained batch 730 in epoch 0, gen_loss = 0.784400859952136, disc_loss = 0.1381838043438839
Trained batch 731 in epoch 0, gen_loss = 0.7841995048229812, disc_loss = 0.1380946639663784
Trained batch 732 in epoch 0, gen_loss = 0.7837640306064897, disc_loss = 0.13811982064291906
Trained batch 733 in epoch 0, gen_loss = 0.7839009024872767, disc_loss = 0.13828161358865035
Trained batch 734 in epoch 0, gen_loss = 0.7835321668459445, disc_loss = 0.13829528067013894
Trained batch 735 in epoch 0, gen_loss = 0.7831960847277356, disc_loss = 0.1382506059020196
Trained batch 736 in epoch 0, gen_loss = 0.7831510071272443, disc_loss = 0.13818640116345657
Trained batch 737 in epoch 0, gen_loss = 0.7830071306729381, disc_loss = 0.13831936954716245
Trained batch 738 in epoch 0, gen_loss = 0.7825510512750107, disc_loss = 0.13838945703262134
Trained batch 739 in epoch 0, gen_loss = 0.7823882589871819, disc_loss = 0.1383926296861515
Trained batch 740 in epoch 0, gen_loss = 0.7822333463692633, disc_loss = 0.13833433959800273
Trained batch 741 in epoch 0, gen_loss = 0.7819640268935669, disc_loss = 0.13837518401455254
Trained batch 742 in epoch 0, gen_loss = 0.7816432862471122, disc_loss = 0.13833972824766258
Trained batch 743 in epoch 0, gen_loss = 0.7815158109591213, disc_loss = 0.13835851939286165
Trained batch 744 in epoch 0, gen_loss = 0.7811883118728663, disc_loss = 0.13833739790571667
Trained batch 745 in epoch 0, gen_loss = 0.7810323277123812, disc_loss = 0.1384010818008528
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.8159689903259277, disc_loss = 0.12991604208946228
Trained batch 1 in epoch 1, gen_loss = 0.6640336513519287, disc_loss = 0.23339323699474335
Trained batch 2 in epoch 1, gen_loss = 0.6007556319236755, disc_loss = 0.22047832608222961
Trained batch 3 in epoch 1, gen_loss = 0.6607619673013687, disc_loss = 0.21345586702227592
Trained batch 4 in epoch 1, gen_loss = 0.6346174955368042, disc_loss = 0.21360945403575898
Trained batch 5 in epoch 1, gen_loss = 0.6530172725518545, disc_loss = 0.2110081116358439
Trained batch 6 in epoch 1, gen_loss = 0.6757374916757856, disc_loss = 0.19446597461189544
Trained batch 7 in epoch 1, gen_loss = 0.6535400375723839, disc_loss = 0.19171420019119978
Trained batch 8 in epoch 1, gen_loss = 0.6760947638087802, disc_loss = 0.17873132311635548
Trained batch 9 in epoch 1, gen_loss = 0.6861958682537079, disc_loss = 0.17017941400408745
Trained batch 10 in epoch 1, gen_loss = 0.6720337000760165, disc_loss = 0.16878408125855707
Trained batch 11 in epoch 1, gen_loss = 0.6885801355044047, disc_loss = 0.15696668609355888
Trained batch 12 in epoch 1, gen_loss = 0.6946775500590985, disc_loss = 0.15507879151174656
Trained batch 13 in epoch 1, gen_loss = 0.6778416974203927, disc_loss = 0.1584960433787533
Trained batch 14 in epoch 1, gen_loss = 0.6730069160461426, disc_loss = 0.15671792613963287
Trained batch 15 in epoch 1, gen_loss = 0.6920761168003082, disc_loss = 0.16268738533835858
Trained batch 16 in epoch 1, gen_loss = 0.6845639137660756, disc_loss = 0.16375268897151246
Trained batch 17 in epoch 1, gen_loss = 0.6790710157818265, disc_loss = 0.16334980798678267
Trained batch 18 in epoch 1, gen_loss = 0.675573069798319, disc_loss = 0.16169207101981892
Trained batch 19 in epoch 1, gen_loss = 0.6825526267290115, disc_loss = 0.16918306117877363
Trained batch 20 in epoch 1, gen_loss = 0.6829319142159962, disc_loss = 0.16713782213628292
Trained batch 21 in epoch 1, gen_loss = 0.6695690520785071, disc_loss = 0.17254800611937587
Trained batch 22 in epoch 1, gen_loss = 0.676203648681226, disc_loss = 0.16941583990726783
Trained batch 23 in epoch 1, gen_loss = 0.6746673720578352, disc_loss = 0.17003725150910518
Trained batch 24 in epoch 1, gen_loss = 0.6757996785640716, disc_loss = 0.16921053223311902
Trained batch 25 in epoch 1, gen_loss = 0.6755864975544122, disc_loss = 0.16589836167314878
Trained batch 26 in epoch 1, gen_loss = 0.6736194237514779, disc_loss = 0.1635116947883809
Trained batch 27 in epoch 1, gen_loss = 0.6715217413646835, disc_loss = 0.1664837105864925
Trained batch 28 in epoch 1, gen_loss = 0.6673388902483315, disc_loss = 0.16570731862608729
Trained batch 29 in epoch 1, gen_loss = 0.6710233857234319, disc_loss = 0.1626954463000099
Trained batch 30 in epoch 1, gen_loss = 0.676608940286021, disc_loss = 0.16179403632638917
Trained batch 31 in epoch 1, gen_loss = 0.6731132613494992, disc_loss = 0.16026063676690683
Trained batch 32 in epoch 1, gen_loss = 0.6702729111368005, disc_loss = 0.15824832332630953
Trained batch 33 in epoch 1, gen_loss = 0.6786440794958788, disc_loss = 0.15723464698256814
Trained batch 34 in epoch 1, gen_loss = 0.6762055218219757, disc_loss = 0.1560060443090541
Trained batch 35 in epoch 1, gen_loss = 0.6769683385888735, disc_loss = 0.15430268867769176
Trained batch 36 in epoch 1, gen_loss = 0.6756785777775017, disc_loss = 0.15268941399817532
Trained batch 37 in epoch 1, gen_loss = 0.6769619795836901, disc_loss = 0.1504807222732588
Trained batch 38 in epoch 1, gen_loss = 0.6776254796064817, disc_loss = 0.14867818388992396
Trained batch 39 in epoch 1, gen_loss = 0.67929722443223, disc_loss = 0.14679515059106052
Trained batch 40 in epoch 1, gen_loss = 0.6823877292435344, disc_loss = 0.14452836149167725
Trained batch 41 in epoch 1, gen_loss = 0.6859789966117769, disc_loss = 0.14142807196116164
Trained batch 42 in epoch 1, gen_loss = 0.6841265122557796, disc_loss = 0.1401413493291583
Trained batch 43 in epoch 1, gen_loss = 0.6902242025191133, disc_loss = 0.1402964359572665
Trained batch 44 in epoch 1, gen_loss = 0.6902000738514794, disc_loss = 0.1383029236147801
Trained batch 45 in epoch 1, gen_loss = 0.6879012474547261, disc_loss = 0.13723179653448903
Trained batch 46 in epoch 1, gen_loss = 0.6897033751010895, disc_loss = 0.13594993223693777
Trained batch 47 in epoch 1, gen_loss = 0.696471211190025, disc_loss = 0.13543027689835677
Trained batch 48 in epoch 1, gen_loss = 0.6939523323458068, disc_loss = 0.13549452826228678
Trained batch 49 in epoch 1, gen_loss = 0.6940427213907242, disc_loss = 0.13405389118939637
Trained batch 50 in epoch 1, gen_loss = 0.6984995328912548, disc_loss = 0.13871361275075697
Trained batch 51 in epoch 1, gen_loss = 0.6945238898579891, disc_loss = 0.13912437100393268
Trained batch 52 in epoch 1, gen_loss = 0.692921019387695, disc_loss = 0.13810365510014994
Trained batch 53 in epoch 1, gen_loss = 0.6984192105355086, disc_loss = 0.13681798348962157
Trained batch 54 in epoch 1, gen_loss = 0.6978201990777796, disc_loss = 0.13602952648970215
Trained batch 55 in epoch 1, gen_loss = 0.7011004340435777, disc_loss = 0.13451289967633784
Trained batch 56 in epoch 1, gen_loss = 0.6988853650134906, disc_loss = 0.13501221983971304
Trained batch 57 in epoch 1, gen_loss = 0.7015531705371265, disc_loss = 0.13484204711456751
Trained batch 58 in epoch 1, gen_loss = 0.7012864487656092, disc_loss = 0.13556476994970088
Trained batch 59 in epoch 1, gen_loss = 0.7006957625349363, disc_loss = 0.13676921846345066
Trained batch 60 in epoch 1, gen_loss = 0.6995514450503177, disc_loss = 0.13766844274445636
Trained batch 61 in epoch 1, gen_loss = 0.6989504901632186, disc_loss = 0.13743288571675938
Trained batch 62 in epoch 1, gen_loss = 0.7031195206301553, disc_loss = 0.1360531955780018
Trained batch 63 in epoch 1, gen_loss = 0.7003346490673721, disc_loss = 0.1360285191622097
Trained batch 64 in epoch 1, gen_loss = 0.7005637200979086, disc_loss = 0.1349496346540176
Trained batch 65 in epoch 1, gen_loss = 0.7021461829091563, disc_loss = 0.13527573377006885
Trained batch 66 in epoch 1, gen_loss = 0.7023243632779193, disc_loss = 0.13392144144137405
Trained batch 67 in epoch 1, gen_loss = 0.6993845354984788, disc_loss = 0.13400505255798206
Trained batch 68 in epoch 1, gen_loss = 0.7026413614335267, disc_loss = 0.13592826620932075
Trained batch 69 in epoch 1, gen_loss = 0.7006974820579801, disc_loss = 0.13687419500201942
Trained batch 70 in epoch 1, gen_loss = 0.6989246409543803, disc_loss = 0.13693601724652338
Trained batch 71 in epoch 1, gen_loss = 0.6974942812489139, disc_loss = 0.13684546360228625
Trained batch 72 in epoch 1, gen_loss = 0.6977510007276927, disc_loss = 0.137519746942267
Trained batch 73 in epoch 1, gen_loss = 0.6963865454937961, disc_loss = 0.13708217696261568
Trained batch 74 in epoch 1, gen_loss = 0.6971383972962697, disc_loss = 0.13790187291800976
Trained batch 75 in epoch 1, gen_loss = 0.697015859970921, disc_loss = 0.13687309144849055
Trained batch 76 in epoch 1, gen_loss = 0.6975848461900439, disc_loss = 0.13660350376619146
Trained batch 77 in epoch 1, gen_loss = 0.6997748945768063, disc_loss = 0.13548523295097625
Trained batch 78 in epoch 1, gen_loss = 0.6979372663588463, disc_loss = 0.1358415487493518
Trained batch 79 in epoch 1, gen_loss = 0.6976681742817163, disc_loss = 0.1363316185073927
Trained batch 80 in epoch 1, gen_loss = 0.6979418923089533, disc_loss = 0.13597228371158795
Trained batch 81 in epoch 1, gen_loss = 0.6969136221379768, disc_loss = 0.135117597718973
Trained batch 82 in epoch 1, gen_loss = 0.6956390821071993, disc_loss = 0.13516914685178233
Trained batch 83 in epoch 1, gen_loss = 0.6980681848667917, disc_loss = 0.13432780850589984
Trained batch 84 in epoch 1, gen_loss = 0.7020587055122152, disc_loss = 0.1331009585848626
Trained batch 85 in epoch 1, gen_loss = 0.7031660915114158, disc_loss = 0.13186696767373834
Trained batch 86 in epoch 1, gen_loss = 0.7013083439448784, disc_loss = 0.13171646210910945
Trained batch 87 in epoch 1, gen_loss = 0.6979250559075312, disc_loss = 0.13249693647958338
Trained batch 88 in epoch 1, gen_loss = 0.7040621192937486, disc_loss = 0.13619607224474461
Trained batch 89 in epoch 1, gen_loss = 0.7019848581817415, disc_loss = 0.1359232543864184
Trained batch 90 in epoch 1, gen_loss = 0.699544315482234, disc_loss = 0.13623165026061482
Trained batch 91 in epoch 1, gen_loss = 0.699741131261639, disc_loss = 0.13636933111221247
Trained batch 92 in epoch 1, gen_loss = 0.6990201598213565, disc_loss = 0.13614117856868493
Trained batch 93 in epoch 1, gen_loss = 0.6993696103070645, disc_loss = 0.1365507482650115
Trained batch 94 in epoch 1, gen_loss = 0.697330893027155, disc_loss = 0.1363708099840503
Trained batch 95 in epoch 1, gen_loss = 0.698092084688445, disc_loss = 0.13626738643506542
Trained batch 96 in epoch 1, gen_loss = 0.6998617197434926, disc_loss = 0.1359109754683738
Trained batch 97 in epoch 1, gen_loss = 0.6976640796174809, disc_loss = 0.13778941567074887
Trained batch 98 in epoch 1, gen_loss = 0.6988296731553897, disc_loss = 0.13862176034411397
Trained batch 99 in epoch 1, gen_loss = 0.6986717575788498, disc_loss = 0.13894218018278479
Trained batch 100 in epoch 1, gen_loss = 0.698261537174187, disc_loss = 0.13939198901378871
Trained batch 101 in epoch 1, gen_loss = 0.6970756427914488, disc_loss = 0.13980414709258898
Trained batch 102 in epoch 1, gen_loss = 0.6957224005634345, disc_loss = 0.13978503273745763
Trained batch 103 in epoch 1, gen_loss = 0.6977438559898963, disc_loss = 0.1412364982892401
Trained batch 104 in epoch 1, gen_loss = 0.6968824363890148, disc_loss = 0.14153377475837867
Trained batch 105 in epoch 1, gen_loss = 0.6962913533426681, disc_loss = 0.14087827494895122
Trained batch 106 in epoch 1, gen_loss = 0.6945730107966984, disc_loss = 0.14137507395418447
Trained batch 107 in epoch 1, gen_loss = 0.6940180510282516, disc_loss = 0.14158446843632394
Trained batch 108 in epoch 1, gen_loss = 0.6944830516062745, disc_loss = 0.14084711334232344
Trained batch 109 in epoch 1, gen_loss = 0.6944450605999339, disc_loss = 0.14094809149815277
Trained batch 110 in epoch 1, gen_loss = 0.6939763432150489, disc_loss = 0.1403848253492568
Trained batch 111 in epoch 1, gen_loss = 0.6942017812814031, disc_loss = 0.13947889716031828
Trained batch 112 in epoch 1, gen_loss = 0.6939751975304258, disc_loss = 0.13939070123025274
Trained batch 113 in epoch 1, gen_loss = 0.6952925313983047, disc_loss = 0.13910998052737691
Trained batch 114 in epoch 1, gen_loss = 0.6944179032159888, disc_loss = 0.13871128366369267
Trained batch 115 in epoch 1, gen_loss = 0.6936969895815027, disc_loss = 0.13833564598562903
Trained batch 116 in epoch 1, gen_loss = 0.6934935837729365, disc_loss = 0.13851456829688996
Trained batch 117 in epoch 1, gen_loss = 0.692971063367391, disc_loss = 0.13827894718023176
Trained batch 118 in epoch 1, gen_loss = 0.6924413873367951, disc_loss = 0.13802830037512198
Trained batch 119 in epoch 1, gen_loss = 0.6941382070382436, disc_loss = 0.14015858373604714
Trained batch 120 in epoch 1, gen_loss = 0.6931448445832433, disc_loss = 0.14024444923482157
Trained batch 121 in epoch 1, gen_loss = 0.6925467487241401, disc_loss = 0.1402175342358771
Trained batch 122 in epoch 1, gen_loss = 0.6923457989847757, disc_loss = 0.14056798223618086
Trained batch 123 in epoch 1, gen_loss = 0.691818910741037, disc_loss = 0.14030917170607754
Trained batch 124 in epoch 1, gen_loss = 0.6930234704017639, disc_loss = 0.13973518015444278
Trained batch 125 in epoch 1, gen_loss = 0.6926211941809881, disc_loss = 0.13937624427120363
Trained batch 126 in epoch 1, gen_loss = 0.6924475816291148, disc_loss = 0.13888382085958334
Trained batch 127 in epoch 1, gen_loss = 0.6950756162405014, disc_loss = 0.13855295286339242
Trained batch 128 in epoch 1, gen_loss = 0.6948554206264111, disc_loss = 0.13792573433918084
Trained batch 129 in epoch 1, gen_loss = 0.6958237001529106, disc_loss = 0.13756170185426106
Trained batch 130 in epoch 1, gen_loss = 0.6952153703638615, disc_loss = 0.1373063085159955
Trained batch 131 in epoch 1, gen_loss = 0.6964843629887609, disc_loss = 0.13766663401585186
Trained batch 132 in epoch 1, gen_loss = 0.6953064512489433, disc_loss = 0.1378542608756544
Trained batch 133 in epoch 1, gen_loss = 0.6944358264332386, disc_loss = 0.13817169866177129
Trained batch 134 in epoch 1, gen_loss = 0.6956669432145578, disc_loss = 0.13799503300752905
Trained batch 135 in epoch 1, gen_loss = 0.69722410554395, disc_loss = 0.13751511236050112
Trained batch 136 in epoch 1, gen_loss = 0.6964170075681088, disc_loss = 0.13745217399168624
Trained batch 137 in epoch 1, gen_loss = 0.6967291512351105, disc_loss = 0.13862233483435019
Trained batch 138 in epoch 1, gen_loss = 0.6947649481485216, disc_loss = 0.13936844021885944
Trained batch 139 in epoch 1, gen_loss = 0.694241926074028, disc_loss = 0.13920354421383568
Trained batch 140 in epoch 1, gen_loss = 0.6957156827263798, disc_loss = 0.1394776027015549
Trained batch 141 in epoch 1, gen_loss = 0.6947654221259373, disc_loss = 0.1397763610699437
Trained batch 142 in epoch 1, gen_loss = 0.6954368402907899, disc_loss = 0.13942519813723914
Trained batch 143 in epoch 1, gen_loss = 0.6955204187995858, disc_loss = 0.1391730880131945
Trained batch 144 in epoch 1, gen_loss = 0.694896792132279, disc_loss = 0.13909092857662975
Trained batch 145 in epoch 1, gen_loss = 0.6959657379209179, disc_loss = 0.1393421712165622
Trained batch 146 in epoch 1, gen_loss = 0.695536999880862, disc_loss = 0.13903635247376095
Trained batch 147 in epoch 1, gen_loss = 0.6945207239808263, disc_loss = 0.13891461656454043
Trained batch 148 in epoch 1, gen_loss = 0.6938773705655297, disc_loss = 0.13892459773127264
Trained batch 149 in epoch 1, gen_loss = 0.6941911661624909, disc_loss = 0.13844681058079003
Trained batch 150 in epoch 1, gen_loss = 0.6952689155837558, disc_loss = 0.13847517556455358
Trained batch 151 in epoch 1, gen_loss = 0.6954481887974238, disc_loss = 0.137690748749791
Trained batch 152 in epoch 1, gen_loss = 0.6947586774046904, disc_loss = 0.13789447004985966
Trained batch 153 in epoch 1, gen_loss = 0.69628268983457, disc_loss = 0.13740645269198076
Trained batch 154 in epoch 1, gen_loss = 0.6969043589407398, disc_loss = 0.13673134667258108
Trained batch 155 in epoch 1, gen_loss = 0.6964202825075541, disc_loss = 0.13646161661316186
Trained batch 156 in epoch 1, gen_loss = 0.6964207481426797, disc_loss = 0.13676794945814047
Trained batch 157 in epoch 1, gen_loss = 0.695980146338668, disc_loss = 0.13659805644162093
Trained batch 158 in epoch 1, gen_loss = 0.6964168556081424, disc_loss = 0.13615731079623383
Trained batch 159 in epoch 1, gen_loss = 0.6981689255684614, disc_loss = 0.13564347773790358
Trained batch 160 in epoch 1, gen_loss = 0.697598824219674, disc_loss = 0.13574755543507405
Trained batch 161 in epoch 1, gen_loss = 0.6967492835757173, disc_loss = 0.13542906631842072
Trained batch 162 in epoch 1, gen_loss = 0.6967380503935316, disc_loss = 0.13550841410650066
Trained batch 163 in epoch 1, gen_loss = 0.6971265895337593, disc_loss = 0.13515062284905735
Trained batch 164 in epoch 1, gen_loss = 0.6967526591185368, disc_loss = 0.13541735573248428
Trained batch 165 in epoch 1, gen_loss = 0.6950939229453903, disc_loss = 0.13589876836322876
Trained batch 166 in epoch 1, gen_loss = 0.6960762121720229, disc_loss = 0.13564962862494462
Trained batch 167 in epoch 1, gen_loss = 0.6966952557365099, disc_loss = 0.13538463990248384
Trained batch 168 in epoch 1, gen_loss = 0.6965468201411547, disc_loss = 0.13495992512039884
Trained batch 169 in epoch 1, gen_loss = 0.6959051914074842, disc_loss = 0.1349903147010242
Trained batch 170 in epoch 1, gen_loss = 0.6967128762724804, disc_loss = 0.1352140193271358
Trained batch 171 in epoch 1, gen_loss = 0.697428087162417, disc_loss = 0.13525023077462994
Trained batch 172 in epoch 1, gen_loss = 0.6961852494691838, disc_loss = 0.13585264326175514
Trained batch 173 in epoch 1, gen_loss = 0.6957213655970562, disc_loss = 0.13567714243270884
Trained batch 174 in epoch 1, gen_loss = 0.6971053719520569, disc_loss = 0.13642986352954592
Trained batch 175 in epoch 1, gen_loss = 0.6962480981918898, disc_loss = 0.1366787626069378
Trained batch 176 in epoch 1, gen_loss = 0.6963089569813787, disc_loss = 0.13696035140820143
Trained batch 177 in epoch 1, gen_loss = 0.6965336645587107, disc_loss = 0.13682361235946752
Trained batch 178 in epoch 1, gen_loss = 0.6966282562170615, disc_loss = 0.13677935872497504
Trained batch 179 in epoch 1, gen_loss = 0.6968505723608864, disc_loss = 0.13684894173509546
Trained batch 180 in epoch 1, gen_loss = 0.6962025751725086, disc_loss = 0.13692925092429745
Trained batch 181 in epoch 1, gen_loss = 0.6960256934820951, disc_loss = 0.13663927346959218
Trained batch 182 in epoch 1, gen_loss = 0.6959260822645302, disc_loss = 0.1363856663795117
Trained batch 183 in epoch 1, gen_loss = 0.697052691941676, disc_loss = 0.13590773318529778
Trained batch 184 in epoch 1, gen_loss = 0.6979000336415059, disc_loss = 0.13537327888849618
Trained batch 185 in epoch 1, gen_loss = 0.6972099420844867, disc_loss = 0.13535444550616768
Trained batch 186 in epoch 1, gen_loss = 0.697047327929002, disc_loss = 0.13505301763985883
Trained batch 187 in epoch 1, gen_loss = 0.697476031932425, disc_loss = 0.13468889044003285
Trained batch 188 in epoch 1, gen_loss = 0.6983828002182895, disc_loss = 0.13438165511088396
Trained batch 189 in epoch 1, gen_loss = 0.699025761453729, disc_loss = 0.13386007227787847
Trained batch 190 in epoch 1, gen_loss = 0.698518774896392, disc_loss = 0.13369497186772486
Trained batch 191 in epoch 1, gen_loss = 0.6984207533920804, disc_loss = 0.13321783300489187
Trained batch 192 in epoch 1, gen_loss = 0.6995534186536166, disc_loss = 0.13293957347388094
Trained batch 193 in epoch 1, gen_loss = 0.7004753722972477, disc_loss = 0.13282400911155434
Trained batch 194 in epoch 1, gen_loss = 0.7016398506286817, disc_loss = 0.13230892675809372
Trained batch 195 in epoch 1, gen_loss = 0.7011912611066079, disc_loss = 0.13264941085814214
Trained batch 196 in epoch 1, gen_loss = 0.7006429458027563, disc_loss = 0.13250838163389167
Trained batch 197 in epoch 1, gen_loss = 0.7018728626496864, disc_loss = 0.13246011244829256
Trained batch 198 in epoch 1, gen_loss = 0.7035077813282684, disc_loss = 0.13250399459546536
Trained batch 199 in epoch 1, gen_loss = 0.7032896122336387, disc_loss = 0.13196644531562923
Trained batch 200 in epoch 1, gen_loss = 0.7036119082673865, disc_loss = 0.13154086967309317
Trained batch 201 in epoch 1, gen_loss = 0.7035458040709542, disc_loss = 0.13115704469013922
Trained batch 202 in epoch 1, gen_loss = 0.7053019847775915, disc_loss = 0.13121654720876016
Trained batch 203 in epoch 1, gen_loss = 0.7052220427522472, disc_loss = 0.13099582533479906
Trained batch 204 in epoch 1, gen_loss = 0.7051552996402833, disc_loss = 0.13086858780645744
Trained batch 205 in epoch 1, gen_loss = 0.704837283752497, disc_loss = 0.13049897618447115
Trained batch 206 in epoch 1, gen_loss = 0.7055195872334467, disc_loss = 0.13054993131382453
Trained batch 207 in epoch 1, gen_loss = 0.7061136920864766, disc_loss = 0.13034091024802855
Trained batch 208 in epoch 1, gen_loss = 0.7066657277955963, disc_loss = 0.12979694350698348
Trained batch 209 in epoch 1, gen_loss = 0.7057976935591016, disc_loss = 0.12982386469486215
Trained batch 210 in epoch 1, gen_loss = 0.7061319246676296, disc_loss = 0.1299947937200137
Trained batch 211 in epoch 1, gen_loss = 0.7064537597152422, disc_loss = 0.12954631266799174
Trained batch 212 in epoch 1, gen_loss = 0.7051350916495346, disc_loss = 0.12957472107569937
Trained batch 213 in epoch 1, gen_loss = 0.7061372705709155, disc_loss = 0.12925549472952
Trained batch 214 in epoch 1, gen_loss = 0.7065396569495977, disc_loss = 0.128842101384734
Trained batch 215 in epoch 1, gen_loss = 0.7066893881117856, disc_loss = 0.12846394442021847
Trained batch 216 in epoch 1, gen_loss = 0.705994496697105, disc_loss = 0.12815157768707122
Trained batch 217 in epoch 1, gen_loss = 0.7068241533883121, disc_loss = 0.12866086856282632
Trained batch 218 in epoch 1, gen_loss = 0.7053116162618002, disc_loss = 0.1287620461728747
Trained batch 219 in epoch 1, gen_loss = 0.7068831844763322, disc_loss = 0.1288782838562673
Trained batch 220 in epoch 1, gen_loss = 0.7056058637157285, disc_loss = 0.12908400630586828
Trained batch 221 in epoch 1, gen_loss = 0.7053963888335872, disc_loss = 0.12914484157017223
Trained batch 222 in epoch 1, gen_loss = 0.7057700063615636, disc_loss = 0.12919682860708556
Trained batch 223 in epoch 1, gen_loss = 0.7058162455047879, disc_loss = 0.12908328216456408
Trained batch 224 in epoch 1, gen_loss = 0.7062617691357931, disc_loss = 0.12878049790859222
Trained batch 225 in epoch 1, gen_loss = 0.7066537962023136, disc_loss = 0.12848114515695952
Trained batch 226 in epoch 1, gen_loss = 0.7056507418334221, disc_loss = 0.12873869317087308
Trained batch 227 in epoch 1, gen_loss = 0.706199671615634, disc_loss = 0.12836203993739267
Trained batch 228 in epoch 1, gen_loss = 0.7062455249145041, disc_loss = 0.12811826200399337
Trained batch 229 in epoch 1, gen_loss = 0.7062810529833254, disc_loss = 0.12803506949997467
Trained batch 230 in epoch 1, gen_loss = 0.7070234025711621, disc_loss = 0.1277798374719692
Trained batch 231 in epoch 1, gen_loss = 0.7063403363371717, disc_loss = 0.1279948870651424
Trained batch 232 in epoch 1, gen_loss = 0.7063011286596372, disc_loss = 0.1277181166723818
Trained batch 233 in epoch 1, gen_loss = 0.7064373918578156, disc_loss = 0.12786723674935663
Trained batch 234 in epoch 1, gen_loss = 0.707614297816094, disc_loss = 0.12796623340629518
Trained batch 235 in epoch 1, gen_loss = 0.7071445273645853, disc_loss = 0.12780263579561044
Trained batch 236 in epoch 1, gen_loss = 0.7064570379659596, disc_loss = 0.12760342313330383
Trained batch 237 in epoch 1, gen_loss = 0.7067448837416512, disc_loss = 0.1273697532807328
Trained batch 238 in epoch 1, gen_loss = 0.7064242263219347, disc_loss = 0.12715627931089582
Trained batch 239 in epoch 1, gen_loss = 0.7075305936237176, disc_loss = 0.12824100813207526
Trained batch 240 in epoch 1, gen_loss = 0.7070647700693597, disc_loss = 0.1283575506471252
Trained batch 241 in epoch 1, gen_loss = 0.7062693824452803, disc_loss = 0.1285795507690877
Trained batch 242 in epoch 1, gen_loss = 0.7063909999627636, disc_loss = 0.1290372546164342
Trained batch 243 in epoch 1, gen_loss = 0.7059114704855153, disc_loss = 0.1289828522130847
Trained batch 244 in epoch 1, gen_loss = 0.705504521788383, disc_loss = 0.12912091331518427
Trained batch 245 in epoch 1, gen_loss = 0.7061680337277855, disc_loss = 0.12882563864009652
Trained batch 246 in epoch 1, gen_loss = 0.7062801262627729, disc_loss = 0.12877324795131742
Trained batch 247 in epoch 1, gen_loss = 0.7056628073896131, disc_loss = 0.12885377146003227
Trained batch 248 in epoch 1, gen_loss = 0.706462484526347, disc_loss = 0.12897117051434326
Trained batch 249 in epoch 1, gen_loss = 0.7067969558238983, disc_loss = 0.12893626247346401
Trained batch 250 in epoch 1, gen_loss = 0.7060152285127526, disc_loss = 0.12895674812069452
Trained batch 251 in epoch 1, gen_loss = 0.7063938641831988, disc_loss = 0.1291195091954063
Trained batch 252 in epoch 1, gen_loss = 0.7056945489329312, disc_loss = 0.12961704250086437
Trained batch 253 in epoch 1, gen_loss = 0.7057997230000383, disc_loss = 0.12942374334853934
Trained batch 254 in epoch 1, gen_loss = 0.7066417394899854, disc_loss = 0.12921720960853147
Trained batch 255 in epoch 1, gen_loss = 0.7057212463114411, disc_loss = 0.12953913696401287
Trained batch 256 in epoch 1, gen_loss = 0.7054417300317074, disc_loss = 0.12961789288699396
Trained batch 257 in epoch 1, gen_loss = 0.705713629953621, disc_loss = 0.12944178273107193
Trained batch 258 in epoch 1, gen_loss = 0.7059594491734008, disc_loss = 0.12948438331024528
Trained batch 259 in epoch 1, gen_loss = 0.7058038133841295, disc_loss = 0.12938264790349283
Trained batch 260 in epoch 1, gen_loss = 0.7052757283280179, disc_loss = 0.12914801989878275
Trained batch 261 in epoch 1, gen_loss = 0.7055864648054574, disc_loss = 0.12876293097999486
Trained batch 262 in epoch 1, gen_loss = 0.705885530424662, disc_loss = 0.1287594577616272
Trained batch 263 in epoch 1, gen_loss = 0.7054421960404424, disc_loss = 0.12868030516741177
Trained batch 264 in epoch 1, gen_loss = 0.704788755920698, disc_loss = 0.12863934004222446
Trained batch 265 in epoch 1, gen_loss = 0.7052877045663676, disc_loss = 0.12866580187294044
Trained batch 266 in epoch 1, gen_loss = 0.705461939399162, disc_loss = 0.12862074601879056
Trained batch 267 in epoch 1, gen_loss = 0.7058171129493571, disc_loss = 0.12854893636931455
Trained batch 268 in epoch 1, gen_loss = 0.7056807492302253, disc_loss = 0.1282645987630666
Trained batch 269 in epoch 1, gen_loss = 0.706733398967319, disc_loss = 0.1278554919348271
Trained batch 270 in epoch 1, gen_loss = 0.7064931148532572, disc_loss = 0.12781344680631074
Trained batch 271 in epoch 1, gen_loss = 0.7080313350786182, disc_loss = 0.1278180765631773
Trained batch 272 in epoch 1, gen_loss = 0.7087292326239002, disc_loss = 0.12744180948879474
Trained batch 273 in epoch 1, gen_loss = 0.7088657191199977, disc_loss = 0.1272338096963337
Trained batch 274 in epoch 1, gen_loss = 0.7095631855184381, disc_loss = 0.12692861950532958
Trained batch 275 in epoch 1, gen_loss = 0.7109663007052048, disc_loss = 0.12655111325337834
Trained batch 276 in epoch 1, gen_loss = 0.7119837865932753, disc_loss = 0.12613879157640442
Trained batch 277 in epoch 1, gen_loss = 0.7121052967129852, disc_loss = 0.12592956713206477
Trained batch 278 in epoch 1, gen_loss = 0.7133524633650284, disc_loss = 0.12553976544289178
Trained batch 279 in epoch 1, gen_loss = 0.71463618768113, disc_loss = 0.12515549629128406
Trained batch 280 in epoch 1, gen_loss = 0.7153938527209055, disc_loss = 0.12476003420575658
Trained batch 281 in epoch 1, gen_loss = 0.7158174969203083, disc_loss = 0.12434955323379196
Trained batch 282 in epoch 1, gen_loss = 0.716324802843505, disc_loss = 0.12396429998095908
Trained batch 283 in epoch 1, gen_loss = 0.7167462714960877, disc_loss = 0.12360071039653685
Trained batch 284 in epoch 1, gen_loss = 0.7171887456325062, disc_loss = 0.12320461529715543
Trained batch 285 in epoch 1, gen_loss = 0.7178847527170514, disc_loss = 0.1228228027059638
Trained batch 286 in epoch 1, gen_loss = 0.7187156725012882, disc_loss = 0.12286399882156986
Trained batch 287 in epoch 1, gen_loss = 0.7182844527479675, disc_loss = 0.1228775225883712
Trained batch 288 in epoch 1, gen_loss = 0.7189166956294367, disc_loss = 0.12254578776490008
Trained batch 289 in epoch 1, gen_loss = 0.7189618579272566, disc_loss = 0.1224935989345199
Trained batch 290 in epoch 1, gen_loss = 0.720991259997653, disc_loss = 0.1223402895014157
Trained batch 291 in epoch 1, gen_loss = 0.7223792239411236, disc_loss = 0.12201429218729984
Trained batch 292 in epoch 1, gen_loss = 0.7227301967835671, disc_loss = 0.121659957390571
Trained batch 293 in epoch 1, gen_loss = 0.7222598730301371, disc_loss = 0.1217191494893612
Trained batch 294 in epoch 1, gen_loss = 0.7240782636707112, disc_loss = 0.12153835158668837
Trained batch 295 in epoch 1, gen_loss = 0.7256778192681235, disc_loss = 0.12122362197968303
Trained batch 296 in epoch 1, gen_loss = 0.7251921077368637, disc_loss = 0.12111553223960428
Trained batch 297 in epoch 1, gen_loss = 0.7264724653839265, disc_loss = 0.12095690958964445
Trained batch 298 in epoch 1, gen_loss = 0.7272154926057643, disc_loss = 0.12059439805625972
Trained batch 299 in epoch 1, gen_loss = 0.7279806353648504, disc_loss = 0.12028856480804583
Trained batch 300 in epoch 1, gen_loss = 0.727971171025818, disc_loss = 0.12003433152080276
Trained batch 301 in epoch 1, gen_loss = 0.7280211719061365, disc_loss = 0.11982776905218794
Trained batch 302 in epoch 1, gen_loss = 0.7288477023442587, disc_loss = 0.11948668668138804
Trained batch 303 in epoch 1, gen_loss = 0.7296021939500382, disc_loss = 0.1191599280787877
Trained batch 304 in epoch 1, gen_loss = 0.7298975702191962, disc_loss = 0.11880817712574708
Trained batch 305 in epoch 1, gen_loss = 0.7301177238327226, disc_loss = 0.11848659493832611
Trained batch 306 in epoch 1, gen_loss = 0.7304982746851172, disc_loss = 0.11836323384134893
Trained batch 307 in epoch 1, gen_loss = 0.7295726598663763, disc_loss = 0.11901195443465144
Trained batch 308 in epoch 1, gen_loss = 0.7299521875034258, disc_loss = 0.11879065275361043
Trained batch 309 in epoch 1, gen_loss = 0.7304595494462598, disc_loss = 0.11893422718370153
Trained batch 310 in epoch 1, gen_loss = 0.7300844831673662, disc_loss = 0.11874944535218826
Trained batch 311 in epoch 1, gen_loss = 0.7298449475604755, disc_loss = 0.11868105411457901
Trained batch 312 in epoch 1, gen_loss = 0.7299667306411, disc_loss = 0.1184688495001949
Trained batch 313 in epoch 1, gen_loss = 0.7310530360147451, disc_loss = 0.1181977179530225
Trained batch 314 in epoch 1, gen_loss = 0.7313875280675434, disc_loss = 0.1179346469363996
Trained batch 315 in epoch 1, gen_loss = 0.7309648346485971, disc_loss = 0.1178940186053043
Trained batch 316 in epoch 1, gen_loss = 0.7313097020617043, disc_loss = 0.11768915456622744
Trained batch 317 in epoch 1, gen_loss = 0.7323554091670978, disc_loss = 0.11751729392288428
Trained batch 318 in epoch 1, gen_loss = 0.7328105825802376, disc_loss = 0.11717668736242576
Trained batch 319 in epoch 1, gen_loss = 0.7330340112559497, disc_loss = 0.1168584554863628
Trained batch 320 in epoch 1, gen_loss = 0.7333629035689749, disc_loss = 0.11654385980624833
Trained batch 321 in epoch 1, gen_loss = 0.7334827668733478, disc_loss = 0.11621289664405103
Trained batch 322 in epoch 1, gen_loss = 0.7332815325850672, disc_loss = 0.11618836917236862
Trained batch 323 in epoch 1, gen_loss = 0.7338752033717838, disc_loss = 0.11600130418154561
Trained batch 324 in epoch 1, gen_loss = 0.7342600476741791, disc_loss = 0.11582468777894973
Trained batch 325 in epoch 1, gen_loss = 0.7338278402397238, disc_loss = 0.11576892120158014
Trained batch 326 in epoch 1, gen_loss = 0.7347789250929421, disc_loss = 0.11545627066916829
Trained batch 327 in epoch 1, gen_loss = 0.7352992031814122, disc_loss = 0.11514864959072595
Trained batch 328 in epoch 1, gen_loss = 0.7355109968627478, disc_loss = 0.11493059542698157
Trained batch 329 in epoch 1, gen_loss = 0.7354949222369628, disc_loss = 0.1147294055614056
Trained batch 330 in epoch 1, gen_loss = 0.7358185313079292, disc_loss = 0.1145020882990155
Trained batch 331 in epoch 1, gen_loss = 0.7363673948559416, disc_loss = 0.11447122166247432
Trained batch 332 in epoch 1, gen_loss = 0.7361760970887479, disc_loss = 0.11428065446426382
Trained batch 333 in epoch 1, gen_loss = 0.7358386624537542, disc_loss = 0.11414551126497413
Trained batch 334 in epoch 1, gen_loss = 0.7364648083252693, disc_loss = 0.11422429550161113
Trained batch 335 in epoch 1, gen_loss = 0.7369331501956496, disc_loss = 0.11393163889269567
Trained batch 336 in epoch 1, gen_loss = 0.7368220730245291, disc_loss = 0.11370079802454225
Trained batch 337 in epoch 1, gen_loss = 0.7367668923365294, disc_loss = 0.11341717059465026
Trained batch 338 in epoch 1, gen_loss = 0.7376421070204372, disc_loss = 0.11313029038541261
Trained batch 339 in epoch 1, gen_loss = 0.738335448766456, disc_loss = 0.1128331504543038
Trained batch 340 in epoch 1, gen_loss = 0.7388694023281948, disc_loss = 0.1126220272826659
Trained batch 341 in epoch 1, gen_loss = 0.7390640223758262, disc_loss = 0.11236700351344563
Trained batch 342 in epoch 1, gen_loss = 0.7396400827186795, disc_loss = 0.11212565001024276
Trained batch 343 in epoch 1, gen_loss = 0.740677010267973, disc_loss = 0.1119115285542902
Trained batch 344 in epoch 1, gen_loss = 0.741207947679188, disc_loss = 0.11164562108831994
Trained batch 345 in epoch 1, gen_loss = 0.7416818570022639, disc_loss = 0.11136623962130936
Trained batch 346 in epoch 1, gen_loss = 0.7424685110791616, disc_loss = 0.11108826900368035
Trained batch 347 in epoch 1, gen_loss = 0.7432700194332792, disc_loss = 0.11081974788290587
Trained batch 348 in epoch 1, gen_loss = 0.7441796820109075, disc_loss = 0.11061426984108878
Trained batch 349 in epoch 1, gen_loss = 0.7444922701801573, disc_loss = 0.1104079030853297
Trained batch 350 in epoch 1, gen_loss = 0.7453945004872108, disc_loss = 0.11013927775835804
Trained batch 351 in epoch 1, gen_loss = 0.7462069862098857, disc_loss = 0.10987465958566066
Trained batch 352 in epoch 1, gen_loss = 0.7468063474208032, disc_loss = 0.10960306401599315
Trained batch 353 in epoch 1, gen_loss = 0.748017926758292, disc_loss = 0.10935496222911834
Trained batch 354 in epoch 1, gen_loss = 0.7485291139340736, disc_loss = 0.10913864841920809
Trained batch 355 in epoch 1, gen_loss = 0.7491825356074934, disc_loss = 0.10886515237213101
Trained batch 356 in epoch 1, gen_loss = 0.7496025397830984, disc_loss = 0.1086048919796234
Trained batch 357 in epoch 1, gen_loss = 0.7500916958354705, disc_loss = 0.10834172402388889
Trained batch 358 in epoch 1, gen_loss = 0.7507976037048032, disc_loss = 0.10807546161758534
Trained batch 359 in epoch 1, gen_loss = 0.7516348871092001, disc_loss = 0.10783235853434436
Trained batch 360 in epoch 1, gen_loss = 0.7522793365152258, disc_loss = 0.10757248153151568
Trained batch 361 in epoch 1, gen_loss = 0.7532377161538404, disc_loss = 0.1073482957159205
Trained batch 362 in epoch 1, gen_loss = 0.7537111343595279, disc_loss = 0.1070835148664217
Trained batch 363 in epoch 1, gen_loss = 0.7541853242686817, disc_loss = 0.10691637485441598
Trained batch 364 in epoch 1, gen_loss = 0.7546406624251849, disc_loss = 0.10668398810882275
Trained batch 365 in epoch 1, gen_loss = 0.7550658029122431, disc_loss = 0.10644952550306509
Trained batch 366 in epoch 1, gen_loss = 0.7556081153553903, disc_loss = 0.10618576244260781
Trained batch 367 in epoch 1, gen_loss = 0.7563327503107165, disc_loss = 0.10592998754810137
Trained batch 368 in epoch 1, gen_loss = 0.7573108825741744, disc_loss = 0.1056638966190823
Trained batch 369 in epoch 1, gen_loss = 0.757885438928733, disc_loss = 0.10539806112143639
Trained batch 370 in epoch 1, gen_loss = 0.7586134314697708, disc_loss = 0.10514267817430821
Trained batch 371 in epoch 1, gen_loss = 0.7590094102166032, disc_loss = 0.10488197683376731
Trained batch 372 in epoch 1, gen_loss = 0.7593647125738875, disc_loss = 0.1046328301099566
Trained batch 373 in epoch 1, gen_loss = 0.7599808043815235, disc_loss = 0.1044184776286988
Trained batch 374 in epoch 1, gen_loss = 0.7602683432102203, disc_loss = 0.10416428828239441
Trained batch 375 in epoch 1, gen_loss = 0.7606732714524929, disc_loss = 0.10391710196532547
Trained batch 376 in epoch 1, gen_loss = 0.76109153735859, disc_loss = 0.10367413741889699
Trained batch 377 in epoch 1, gen_loss = 0.7614263588631595, disc_loss = 0.10345616151958152
Trained batch 378 in epoch 1, gen_loss = 0.7617952058529162, disc_loss = 0.10320410048613683
Trained batch 379 in epoch 1, gen_loss = 0.7620081237272213, disc_loss = 0.10294625303757034
Trained batch 380 in epoch 1, gen_loss = 0.7623305082164724, disc_loss = 0.10268792532765725
Trained batch 381 in epoch 1, gen_loss = 0.7629182868446979, disc_loss = 0.10243937575516744
Trained batch 382 in epoch 1, gen_loss = 0.763311390543731, disc_loss = 0.10223249759884945
Trained batch 383 in epoch 1, gen_loss = 0.7634978195807586, disc_loss = 0.10206002461200114
Trained batch 384 in epoch 1, gen_loss = 0.7643050584700201, disc_loss = 0.10186071939185842
Trained batch 385 in epoch 1, gen_loss = 0.7644728651472942, disc_loss = 0.1016497197971134
Trained batch 386 in epoch 1, gen_loss = 0.7649337950448966, disc_loss = 0.10149927970589902
Trained batch 387 in epoch 1, gen_loss = 0.7660422055530793, disc_loss = 0.10129120394337884
Trained batch 388 in epoch 1, gen_loss = 0.7666683712624646, disc_loss = 0.10108094622685088
Trained batch 389 in epoch 1, gen_loss = 0.7665610130780782, disc_loss = 0.10096814583222835
Trained batch 390 in epoch 1, gen_loss = 0.7665725032539319, disc_loss = 0.10081835792821539
Trained batch 391 in epoch 1, gen_loss = 0.7665813927899818, disc_loss = 0.10059508344405615
Trained batch 392 in epoch 1, gen_loss = 0.7677120890174507, disc_loss = 0.10041339838588208
Trained batch 393 in epoch 1, gen_loss = 0.7683075358571135, disc_loss = 0.10018933409834423
Trained batch 394 in epoch 1, gen_loss = 0.7689403157445449, disc_loss = 0.09996662600366753
Trained batch 395 in epoch 1, gen_loss = 0.769267271489206, disc_loss = 0.0997601740810117
Trained batch 396 in epoch 1, gen_loss = 0.7695481282487624, disc_loss = 0.0995237179586115
Trained batch 397 in epoch 1, gen_loss = 0.769482518485443, disc_loss = 0.09935626834420365
Trained batch 398 in epoch 1, gen_loss = 0.7698169808489338, disc_loss = 0.09912568912549612
Trained batch 399 in epoch 1, gen_loss = 0.7699894084781408, disc_loss = 0.09890679658506997
Trained batch 400 in epoch 1, gen_loss = 0.7696320453932755, disc_loss = 0.09882341398790181
Trained batch 401 in epoch 1, gen_loss = 0.7705118314395496, disc_loss = 0.0987338216810844
Trained batch 402 in epoch 1, gen_loss = 0.7715350255628969, disc_loss = 0.09865399813464387
Trained batch 403 in epoch 1, gen_loss = 0.7717195943293005, disc_loss = 0.09842518524446589
Trained batch 404 in epoch 1, gen_loss = 0.7718119585219725, disc_loss = 0.09821034963185221
Trained batch 405 in epoch 1, gen_loss = 0.7720814038233217, disc_loss = 0.09798565222491772
Trained batch 406 in epoch 1, gen_loss = 0.77225757604442, disc_loss = 0.09779672383236944
Trained batch 407 in epoch 1, gen_loss = 0.7726065454383692, disc_loss = 0.09757190815848756
Trained batch 408 in epoch 1, gen_loss = 0.7730736492752738, disc_loss = 0.09734959440638281
Trained batch 409 in epoch 1, gen_loss = 0.77343227129157, disc_loss = 0.09712485523053968
Trained batch 410 in epoch 1, gen_loss = 0.773620918936973, disc_loss = 0.09689715594832769
Trained batch 411 in epoch 1, gen_loss = 0.7738088999413749, disc_loss = 0.09666973116889017
Trained batch 412 in epoch 1, gen_loss = 0.7741105145894298, disc_loss = 0.09644370870642166
Trained batch 413 in epoch 1, gen_loss = 0.7744467230378718, disc_loss = 0.09621824404271995
Trained batch 414 in epoch 1, gen_loss = 0.7747167603797224, disc_loss = 0.0959983460969819
Trained batch 415 in epoch 1, gen_loss = 0.7752110445871949, disc_loss = 0.0957956241422485
Trained batch 416 in epoch 1, gen_loss = 0.7754343787400271, disc_loss = 0.09557419123934309
Trained batch 417 in epoch 1, gen_loss = 0.7756600675828149, disc_loss = 0.09536480413400011
Trained batch 418 in epoch 1, gen_loss = 0.7762048164102513, disc_loss = 0.09521768633265111
Trained batch 419 in epoch 1, gen_loss = 0.7764767118153117, disc_loss = 0.09502096361026079
Trained batch 420 in epoch 1, gen_loss = 0.776464120438433, disc_loss = 0.09481950777565126
Trained batch 421 in epoch 1, gen_loss = 0.7764531853498441, disc_loss = 0.0946395104851406
Trained batch 422 in epoch 1, gen_loss = 0.7766978797760415, disc_loss = 0.09442543341606485
Trained batch 423 in epoch 1, gen_loss = 0.7771463761773875, disc_loss = 0.09421446059450489
Trained batch 424 in epoch 1, gen_loss = 0.776511063786114, disc_loss = 0.09433937995913712
Trained batch 425 in epoch 1, gen_loss = 0.7762573075266511, disc_loss = 0.09435134235181422
Trained batch 426 in epoch 1, gen_loss = 0.777006886812228, disc_loss = 0.09465842749170994
Trained batch 427 in epoch 1, gen_loss = 0.777249799501673, disc_loss = 0.09446634675939698
Trained batch 428 in epoch 1, gen_loss = 0.7764573595323763, disc_loss = 0.09484668784570774
Trained batch 429 in epoch 1, gen_loss = 0.7762314593376115, disc_loss = 0.09474017780306641
Trained batch 430 in epoch 1, gen_loss = 0.776702100812974, disc_loss = 0.0948524165054753
Trained batch 431 in epoch 1, gen_loss = 0.7765524767477203, disc_loss = 0.0948771768226935
Trained batch 432 in epoch 1, gen_loss = 0.7762539606309102, disc_loss = 0.09502012371171618
Trained batch 433 in epoch 1, gen_loss = 0.7760645236974487, disc_loss = 0.09518185045842666
Trained batch 434 in epoch 1, gen_loss = 0.775634951358554, disc_loss = 0.09524056323076031
Trained batch 435 in epoch 1, gen_loss = 0.7757324866882158, disc_loss = 0.09535032791809665
Trained batch 436 in epoch 1, gen_loss = 0.7754444115085515, disc_loss = 0.09547697813186189
Trained batch 437 in epoch 1, gen_loss = 0.7751768214381449, disc_loss = 0.09534283129436699
Trained batch 438 in epoch 1, gen_loss = 0.775019456626071, disc_loss = 0.09526531567111832
Trained batch 439 in epoch 1, gen_loss = 0.7758456549183889, disc_loss = 0.09532851562359032
Trained batch 440 in epoch 1, gen_loss = 0.7754471178362969, disc_loss = 0.09549218195684829
Trained batch 441 in epoch 1, gen_loss = 0.775151455766475, disc_loss = 0.09547911553140055
Trained batch 442 in epoch 1, gen_loss = 0.7756772298979705, disc_loss = 0.09587692577784994
Trained batch 443 in epoch 1, gen_loss = 0.7752952942842836, disc_loss = 0.09596336323312728
Trained batch 444 in epoch 1, gen_loss = 0.7749581440780939, disc_loss = 0.09592641475610435
Trained batch 445 in epoch 1, gen_loss = 0.7749294835756713, disc_loss = 0.0958735068394456
Trained batch 446 in epoch 1, gen_loss = 0.7751747770464127, disc_loss = 0.0959940610294099
Trained batch 447 in epoch 1, gen_loss = 0.774647959840617, disc_loss = 0.09622863961963699
Trained batch 448 in epoch 1, gen_loss = 0.774694919387057, disc_loss = 0.09613087769122773
Trained batch 449 in epoch 1, gen_loss = 0.7747830007473627, disc_loss = 0.09648519372722755
Trained batch 450 in epoch 1, gen_loss = 0.774342649725747, disc_loss = 0.09658556954342533
Trained batch 451 in epoch 1, gen_loss = 0.7737587501121833, disc_loss = 0.09679536464514903
Trained batch 452 in epoch 1, gen_loss = 0.7736189802882424, disc_loss = 0.09676835167007912
Trained batch 453 in epoch 1, gen_loss = 0.7739362502019311, disc_loss = 0.09692196625885903
Trained batch 454 in epoch 1, gen_loss = 0.7733355453381172, disc_loss = 0.09706763630825002
Trained batch 455 in epoch 1, gen_loss = 0.7734886387591822, disc_loss = 0.09712273598875311
Trained batch 456 in epoch 1, gen_loss = 0.7732473553792131, disc_loss = 0.09716873367304793
Trained batch 457 in epoch 1, gen_loss = 0.7729340957632231, disc_loss = 0.09709198311668735
Trained batch 458 in epoch 1, gen_loss = 0.772826019390476, disc_loss = 0.09703221336800467
Trained batch 459 in epoch 1, gen_loss = 0.7728376488970674, disc_loss = 0.09706422096148701
Trained batch 460 in epoch 1, gen_loss = 0.7727095621139005, disc_loss = 0.09691550626233623
Trained batch 461 in epoch 1, gen_loss = 0.7728605291673115, disc_loss = 0.09677857033116138
Trained batch 462 in epoch 1, gen_loss = 0.7724994787258412, disc_loss = 0.09666573665744461
Trained batch 463 in epoch 1, gen_loss = 0.7723167847585062, disc_loss = 0.09661449738406849
Trained batch 464 in epoch 1, gen_loss = 0.7722995663842848, disc_loss = 0.0968988463998602
Trained batch 465 in epoch 1, gen_loss = 0.7719697752096111, disc_loss = 0.09684213638543492
Trained batch 466 in epoch 1, gen_loss = 0.7717088003357677, disc_loss = 0.09682329708153913
Trained batch 467 in epoch 1, gen_loss = 0.7720550082814999, disc_loss = 0.09688489490067267
Trained batch 468 in epoch 1, gen_loss = 0.7723430507599927, disc_loss = 0.09729040769099602
Trained batch 469 in epoch 1, gen_loss = 0.7716558883164791, disc_loss = 0.09755076468733952
Trained batch 470 in epoch 1, gen_loss = 0.77111496116705, disc_loss = 0.09791294253538037
Trained batch 471 in epoch 1, gen_loss = 0.7714986553005243, disc_loss = 0.09820490252271974
Trained batch 472 in epoch 1, gen_loss = 0.7715464589081658, disc_loss = 0.0984160614767984
Trained batch 473 in epoch 1, gen_loss = 0.7713393240161083, disc_loss = 0.09902362771408892
Trained batch 474 in epoch 1, gen_loss = 0.7711480196526176, disc_loss = 0.09909922280544906
Trained batch 475 in epoch 1, gen_loss = 0.7710104585320008, disc_loss = 0.0995748542134744
Trained batch 476 in epoch 1, gen_loss = 0.7704548371537926, disc_loss = 0.09977849468977368
Trained batch 477 in epoch 1, gen_loss = 0.7700332600826, disc_loss = 0.09989824732833748
Trained batch 478 in epoch 1, gen_loss = 0.7699879597646956, disc_loss = 0.10034284416327569
Trained batch 479 in epoch 1, gen_loss = 0.769733575793604, disc_loss = 0.10035434412566246
Trained batch 480 in epoch 1, gen_loss = 0.7696871842391277, disc_loss = 0.10028560522298974
Trained batch 481 in epoch 1, gen_loss = 0.7694072663413044, disc_loss = 0.10024637142263924
Trained batch 482 in epoch 1, gen_loss = 0.7692856474569372, disc_loss = 0.1003684073018477
Trained batch 483 in epoch 1, gen_loss = 0.76905825752611, disc_loss = 0.10038809925423596
Trained batch 484 in epoch 1, gen_loss = 0.7687518931541246, disc_loss = 0.10043605360893783
Trained batch 485 in epoch 1, gen_loss = 0.7685649621265905, disc_loss = 0.10030419438446914
Trained batch 486 in epoch 1, gen_loss = 0.7685497074523746, disc_loss = 0.1003310124497876
Trained batch 487 in epoch 1, gen_loss = 0.7684648570100792, disc_loss = 0.10022965259038935
Trained batch 488 in epoch 1, gen_loss = 0.7684566703432665, disc_loss = 0.10008761069569774
Trained batch 489 in epoch 1, gen_loss = 0.7681498410142198, disc_loss = 0.10006947154701896
Trained batch 490 in epoch 1, gen_loss = 0.7677549875802275, disc_loss = 0.10014132429208311
Trained batch 491 in epoch 1, gen_loss = 0.7680301882508325, disc_loss = 0.10066491340398713
Trained batch 492 in epoch 1, gen_loss = 0.7677563604791072, disc_loss = 0.10066502135479351
Trained batch 493 in epoch 1, gen_loss = 0.7675151774878444, disc_loss = 0.1006547664381707
Trained batch 494 in epoch 1, gen_loss = 0.7673928827348382, disc_loss = 0.10056596539792313
Trained batch 495 in epoch 1, gen_loss = 0.7677941878115938, disc_loss = 0.10050084616100761
Trained batch 496 in epoch 1, gen_loss = 0.767677730657685, disc_loss = 0.10048120701170228
Trained batch 497 in epoch 1, gen_loss = 0.767608700207917, disc_loss = 0.10039015698487903
Trained batch 498 in epoch 1, gen_loss = 0.7679325922099287, disc_loss = 0.10021608538005523
Trained batch 499 in epoch 1, gen_loss = 0.7676178042292595, disc_loss = 0.10015310846408829
Trained batch 500 in epoch 1, gen_loss = 0.767594293741409, disc_loss = 0.1001910044567217
Trained batch 501 in epoch 1, gen_loss = 0.767355538756249, disc_loss = 0.10015737640984965
Trained batch 502 in epoch 1, gen_loss = 0.7672678713888582, disc_loss = 0.10003302684914743
Trained batch 503 in epoch 1, gen_loss = 0.7674847194954516, disc_loss = 0.0999241005347502
Trained batch 504 in epoch 1, gen_loss = 0.7671926200389863, disc_loss = 0.09983820031618348
Trained batch 505 in epoch 1, gen_loss = 0.7669738528167778, disc_loss = 0.09969565228663989
Trained batch 506 in epoch 1, gen_loss = 0.7671979605211073, disc_loss = 0.09956234437597207
Trained batch 507 in epoch 1, gen_loss = 0.7666319412743952, disc_loss = 0.09962000005363347
Trained batch 508 in epoch 1, gen_loss = 0.7672237355723128, disc_loss = 0.09958003109827827
Trained batch 509 in epoch 1, gen_loss = 0.7670924094377779, disc_loss = 0.09942574245882604
Trained batch 510 in epoch 1, gen_loss = 0.7670903422827823, disc_loss = 0.09931285623707052
Trained batch 511 in epoch 1, gen_loss = 0.7672944334335625, disc_loss = 0.09921343750966116
Trained batch 512 in epoch 1, gen_loss = 0.7669682599182946, disc_loss = 0.09933719359706819
Trained batch 513 in epoch 1, gen_loss = 0.7674980380423801, disc_loss = 0.09987483044374183
Trained batch 514 in epoch 1, gen_loss = 0.7675992002764952, disc_loss = 0.099747926891483
Trained batch 515 in epoch 1, gen_loss = 0.7672638012919315, disc_loss = 0.09982622821784629
Trained batch 516 in epoch 1, gen_loss = 0.7667789958431827, disc_loss = 0.10008864401392926
Trained batch 517 in epoch 1, gen_loss = 0.7669275422584136, disc_loss = 0.10010214034660313
Trained batch 518 in epoch 1, gen_loss = 0.7668847524361804, disc_loss = 0.10004087917727413
Trained batch 519 in epoch 1, gen_loss = 0.7666332988784863, disc_loss = 0.09997030453389295
Trained batch 520 in epoch 1, gen_loss = 0.7665419163264606, disc_loss = 0.09997351094141903
Trained batch 521 in epoch 1, gen_loss = 0.7664861121853649, disc_loss = 0.09989529029310991
Trained batch 522 in epoch 1, gen_loss = 0.7661098053760784, disc_loss = 0.09990475244640264
Trained batch 523 in epoch 1, gen_loss = 0.7660139939029709, disc_loss = 0.09993936894026066
Trained batch 524 in epoch 1, gen_loss = 0.7663325267746335, disc_loss = 0.10010879467418861
Trained batch 525 in epoch 1, gen_loss = 0.7661641713784222, disc_loss = 0.10004058635143825
Trained batch 526 in epoch 1, gen_loss = 0.7662725151150683, disc_loss = 0.10005904996168553
Trained batch 527 in epoch 1, gen_loss = 0.7659594194229805, disc_loss = 0.10006501750489627
Trained batch 528 in epoch 1, gen_loss = 0.7660147885744423, disc_loss = 0.09993766776870563
Trained batch 529 in epoch 1, gen_loss = 0.7664422555914465, disc_loss = 0.10000442001256951
Trained batch 530 in epoch 1, gen_loss = 0.7664009973603229, disc_loss = 0.10002092557359424
Trained batch 531 in epoch 1, gen_loss = 0.7664718949481061, disc_loss = 0.10000992676066375
Trained batch 532 in epoch 1, gen_loss = 0.7667986817699883, disc_loss = 0.09987551953222455
Trained batch 533 in epoch 1, gen_loss = 0.7671946502580178, disc_loss = 0.09974914696547185
Trained batch 534 in epoch 1, gen_loss = 0.7676044481937017, disc_loss = 0.09962997814753555
Trained batch 535 in epoch 1, gen_loss = 0.767727711196266, disc_loss = 0.09948042483171518
Trained batch 536 in epoch 1, gen_loss = 0.7679542950189757, disc_loss = 0.09931338777517626
Trained batch 537 in epoch 1, gen_loss = 0.7680514735138549, disc_loss = 0.09915994820886094
Trained batch 538 in epoch 1, gen_loss = 0.7684312711620154, disc_loss = 0.09899197734420659
Trained batch 539 in epoch 1, gen_loss = 0.7685854103830125, disc_loss = 0.09882421542295358
Trained batch 540 in epoch 1, gen_loss = 0.7688984419193373, disc_loss = 0.09864932143597652
Trained batch 541 in epoch 1, gen_loss = 0.7693132421627256, disc_loss = 0.09850900145840395
Trained batch 542 in epoch 1, gen_loss = 0.7697998880242335, disc_loss = 0.09835661779514566
Trained batch 543 in epoch 1, gen_loss = 0.7698918507598779, disc_loss = 0.09819174665993641
Trained batch 544 in epoch 1, gen_loss = 0.7700965714017186, disc_loss = 0.09802258212093708
Trained batch 545 in epoch 1, gen_loss = 0.7701135057232755, disc_loss = 0.09788218933974663
Trained batch 546 in epoch 1, gen_loss = 0.7702418414286765, disc_loss = 0.09772415608857202
Trained batch 547 in epoch 1, gen_loss = 0.7704508410100519, disc_loss = 0.09761649006374357
Trained batch 548 in epoch 1, gen_loss = 0.7705192875340988, disc_loss = 0.09746234771924497
Trained batch 549 in epoch 1, gen_loss = 0.7709646978161552, disc_loss = 0.09730769635813141
Trained batch 550 in epoch 1, gen_loss = 0.7711678110536343, disc_loss = 0.09714127561633565
Trained batch 551 in epoch 1, gen_loss = 0.7713937346917995, disc_loss = 0.0969776807844713
Trained batch 552 in epoch 1, gen_loss = 0.77158669343262, disc_loss = 0.09682664737251889
Trained batch 553 in epoch 1, gen_loss = 0.7718516231013549, disc_loss = 0.0966647670546291
Trained batch 554 in epoch 1, gen_loss = 0.7714272065205617, disc_loss = 0.09675879424882566
Trained batch 555 in epoch 1, gen_loss = 0.7721182463838042, disc_loss = 0.09700077094209696
Trained batch 556 in epoch 1, gen_loss = 0.7724850092156785, disc_loss = 0.09685272593979173
Trained batch 557 in epoch 1, gen_loss = 0.7723055654956449, disc_loss = 0.09684839298886891
Trained batch 558 in epoch 1, gen_loss = 0.7725631074316813, disc_loss = 0.0967102547526886
Trained batch 559 in epoch 1, gen_loss = 0.7724472585533346, disc_loss = 0.0966001743180511
Trained batch 560 in epoch 1, gen_loss = 0.7730150884697994, disc_loss = 0.09653806671750882
Trained batch 561 in epoch 1, gen_loss = 0.7733884596951915, disc_loss = 0.09638644191411612
Trained batch 562 in epoch 1, gen_loss = 0.7732990369280108, disc_loss = 0.09633953676089234
Trained batch 563 in epoch 1, gen_loss = 0.7738014819985586, disc_loss = 0.09640405271557351
Trained batch 564 in epoch 1, gen_loss = 0.7737043792167596, disc_loss = 0.09632337049795398
Trained batch 565 in epoch 1, gen_loss = 0.7739805562336116, disc_loss = 0.0961746915038708
Trained batch 566 in epoch 1, gen_loss = 0.7741695856921887, disc_loss = 0.09602411297918667
Trained batch 567 in epoch 1, gen_loss = 0.7744238510937758, disc_loss = 0.09586456047844889
Trained batch 568 in epoch 1, gen_loss = 0.7746958189982731, disc_loss = 0.09571372928475938
Trained batch 569 in epoch 1, gen_loss = 0.7749086482483044, disc_loss = 0.09562975042785535
Trained batch 570 in epoch 1, gen_loss = 0.7749297920542715, disc_loss = 0.09549077755882487
Trained batch 571 in epoch 1, gen_loss = 0.7751797550208085, disc_loss = 0.09534980815882514
Trained batch 572 in epoch 1, gen_loss = 0.7755089547829687, disc_loss = 0.09519764907978293
Trained batch 573 in epoch 1, gen_loss = 0.7758666442038705, disc_loss = 0.09504698445081049
Trained batch 574 in epoch 1, gen_loss = 0.7761159639773162, disc_loss = 0.09489279498103197
Trained batch 575 in epoch 1, gen_loss = 0.7765178639027808, disc_loss = 0.0947587052542076
Trained batch 576 in epoch 1, gen_loss = 0.7762427284564675, disc_loss = 0.09471490033224315
Trained batch 577 in epoch 1, gen_loss = 0.7767667145465073, disc_loss = 0.09458037902025834
Trained batch 578 in epoch 1, gen_loss = 0.7773911110889521, disc_loss = 0.09445781960949906
Trained batch 579 in epoch 1, gen_loss = 0.7777883015829942, disc_loss = 0.09430831576063266
Trained batch 580 in epoch 1, gen_loss = 0.7780741641935917, disc_loss = 0.09428013734585203
Trained batch 581 in epoch 1, gen_loss = 0.778021460955905, disc_loss = 0.09423803069902412
Trained batch 582 in epoch 1, gen_loss = 0.778275034644387, disc_loss = 0.09410846647790491
Trained batch 583 in epoch 1, gen_loss = 0.7784284126676925, disc_loss = 0.09397018144317035
Trained batch 584 in epoch 1, gen_loss = 0.7791079009700025, disc_loss = 0.09386609801982776
Trained batch 585 in epoch 1, gen_loss = 0.7797604154401265, disc_loss = 0.09373505829011786
Trained batch 586 in epoch 1, gen_loss = 0.7801367592770968, disc_loss = 0.0935912307711188
Trained batch 587 in epoch 1, gen_loss = 0.7804121187552303, disc_loss = 0.09345210824822246
Trained batch 588 in epoch 1, gen_loss = 0.7805249880246679, disc_loss = 0.09332198152557357
Trained batch 589 in epoch 1, gen_loss = 0.7807002788883145, disc_loss = 0.09317809198469997
Trained batch 590 in epoch 1, gen_loss = 0.7808004008533588, disc_loss = 0.09305202228871258
Trained batch 591 in epoch 1, gen_loss = 0.7810198891203146, disc_loss = 0.09290095422427938
Trained batch 592 in epoch 1, gen_loss = 0.7811808546920249, disc_loss = 0.09274973397372482
Trained batch 593 in epoch 1, gen_loss = 0.7815166865334366, disc_loss = 0.09260239733205888
Trained batch 594 in epoch 1, gen_loss = 0.7817090191760985, disc_loss = 0.0924573753713904
Trained batch 595 in epoch 1, gen_loss = 0.7819349738775484, disc_loss = 0.09233082083933643
Trained batch 596 in epoch 1, gen_loss = 0.7819882955782776, disc_loss = 0.09218400432197829
Trained batch 597 in epoch 1, gen_loss = 0.7821765420428886, disc_loss = 0.0920444977120107
Trained batch 598 in epoch 1, gen_loss = 0.7823215891204414, disc_loss = 0.09193272202023817
Trained batch 599 in epoch 1, gen_loss = 0.7826113800207773, disc_loss = 0.09178759872719335
Trained batch 600 in epoch 1, gen_loss = 0.7828126486248264, disc_loss = 0.09164806629357528
Trained batch 601 in epoch 1, gen_loss = 0.7830414274998282, disc_loss = 0.09150652070815962
Trained batch 602 in epoch 1, gen_loss = 0.7833776989979531, disc_loss = 0.09136056005190224
Trained batch 603 in epoch 1, gen_loss = 0.7836033737422615, disc_loss = 0.09121474028497145
Trained batch 604 in epoch 1, gen_loss = 0.7838382650012813, disc_loss = 0.0910769087824324
Trained batch 605 in epoch 1, gen_loss = 0.7839847237560222, disc_loss = 0.09093341806814345
Trained batch 606 in epoch 1, gen_loss = 0.7841577927598843, disc_loss = 0.09079180523535295
Trained batch 607 in epoch 1, gen_loss = 0.7843724397060118, disc_loss = 0.09064900246908349
Trained batch 608 in epoch 1, gen_loss = 0.7846674118527442, disc_loss = 0.09050691530356193
Trained batch 609 in epoch 1, gen_loss = 0.7848617050491395, disc_loss = 0.09036253769500334
Trained batch 610 in epoch 1, gen_loss = 0.7849562431513385, disc_loss = 0.0902242890418905
Trained batch 611 in epoch 1, gen_loss = 0.7853698235711241, disc_loss = 0.09013336799274886
Trained batch 612 in epoch 1, gen_loss = 0.7854820100946099, disc_loss = 0.08999512351891345
Trained batch 613 in epoch 1, gen_loss = 0.7855781798254007, disc_loss = 0.0898589462266343
Trained batch 614 in epoch 1, gen_loss = 0.7856935167700294, disc_loss = 0.08972601110675955
Trained batch 615 in epoch 1, gen_loss = 0.7857665762111739, disc_loss = 0.08960879104840871
Trained batch 616 in epoch 1, gen_loss = 0.7859796695230072, disc_loss = 0.08946848838971973
Trained batch 617 in epoch 1, gen_loss = 0.7862150540822532, disc_loss = 0.08932988889911739
Trained batch 618 in epoch 1, gen_loss = 0.7861558278851054, disc_loss = 0.08921341403005328
Trained batch 619 in epoch 1, gen_loss = 0.7869410052414864, disc_loss = 0.08911911135862371
Trained batch 620 in epoch 1, gen_loss = 0.7875455528641668, disc_loss = 0.08899303690017457
Trained batch 621 in epoch 1, gen_loss = 0.7878368817916637, disc_loss = 0.08886881363974926
Trained batch 622 in epoch 1, gen_loss = 0.7881118440895938, disc_loss = 0.08874909048728094
Trained batch 623 in epoch 1, gen_loss = 0.7884016134417974, disc_loss = 0.08861588535178154
Trained batch 624 in epoch 1, gen_loss = 0.7886094377517701, disc_loss = 0.08848661676310003
Trained batch 625 in epoch 1, gen_loss = 0.7885214573087783, disc_loss = 0.0884126371197468
Trained batch 626 in epoch 1, gen_loss = 0.7883284071035552, disc_loss = 0.08833769139346549
Trained batch 627 in epoch 1, gen_loss = 0.7886071926469256, disc_loss = 0.08827555883982795
Trained batch 628 in epoch 1, gen_loss = 0.7891046038113642, disc_loss = 0.08820880618685226
Trained batch 629 in epoch 1, gen_loss = 0.7888421815539163, disc_loss = 0.08824998189673006
Trained batch 630 in epoch 1, gen_loss = 0.7888713560278178, disc_loss = 0.08816383266858402
Trained batch 631 in epoch 1, gen_loss = 0.7890465511362764, disc_loss = 0.08805880603591228
Trained batch 632 in epoch 1, gen_loss = 0.7892552944721204, disc_loss = 0.08796387535628773
Trained batch 633 in epoch 1, gen_loss = 0.7891562318764275, disc_loss = 0.08787528035555575
Trained batch 634 in epoch 1, gen_loss = 0.7895521230584993, disc_loss = 0.08779073862952921
Trained batch 635 in epoch 1, gen_loss = 0.7896086655135425, disc_loss = 0.0876721584310597
Trained batch 636 in epoch 1, gen_loss = 0.7897254191163571, disc_loss = 0.08755216537828571
Trained batch 637 in epoch 1, gen_loss = 0.7896072247932697, disc_loss = 0.08746423106604083
Trained batch 638 in epoch 1, gen_loss = 0.7896803142692375, disc_loss = 0.0873578423528505
Trained batch 639 in epoch 1, gen_loss = 0.7896806144155561, disc_loss = 0.08730713917138928
Trained batch 640 in epoch 1, gen_loss = 0.789955780770217, disc_loss = 0.08718561451967846
Trained batch 641 in epoch 1, gen_loss = 0.7902342321531052, disc_loss = 0.08705839469435558
Trained batch 642 in epoch 1, gen_loss = 0.7904165857131151, disc_loss = 0.0869518999458605
Trained batch 643 in epoch 1, gen_loss = 0.7906916013785771, disc_loss = 0.08684505730461017
Trained batch 644 in epoch 1, gen_loss = 0.791119990053103, disc_loss = 0.08672415201711042
Trained batch 645 in epoch 1, gen_loss = 0.7912955708548012, disc_loss = 0.08659885303678147
Trained batch 646 in epoch 1, gen_loss = 0.7916498479002962, disc_loss = 0.08647953378435345
Trained batch 647 in epoch 1, gen_loss = 0.7920063009232651, disc_loss = 0.08635839868881624
Trained batch 648 in epoch 1, gen_loss = 0.7920217780376252, disc_loss = 0.08626562267798753
Trained batch 649 in epoch 1, gen_loss = 0.7920726545040424, disc_loss = 0.0861515103176666
Trained batch 650 in epoch 1, gen_loss = 0.7921868258723832, disc_loss = 0.08603640291060159
Trained batch 651 in epoch 1, gen_loss = 0.7924078573112839, disc_loss = 0.08591222614042769
Trained batch 652 in epoch 1, gen_loss = 0.7929555758217758, disc_loss = 0.08580674628219404
Trained batch 653 in epoch 1, gen_loss = 0.7933055286378307, disc_loss = 0.08568813405690333
Trained batch 654 in epoch 1, gen_loss = 0.7933026745119167, disc_loss = 0.08557448433747672
Trained batch 655 in epoch 1, gen_loss = 0.7935217951492566, disc_loss = 0.0854550042489924
Trained batch 656 in epoch 1, gen_loss = 0.7937963457049482, disc_loss = 0.08533742310956993
Trained batch 657 in epoch 1, gen_loss = 0.793880684035165, disc_loss = 0.0852145954020361
Trained batch 658 in epoch 1, gen_loss = 0.7940042366207279, disc_loss = 0.08509075164841559
Trained batch 659 in epoch 1, gen_loss = 0.7942262189857887, disc_loss = 0.08497299770648224
Trained batch 660 in epoch 1, gen_loss = 0.7943961218157262, disc_loss = 0.08485189408772595
Trained batch 661 in epoch 1, gen_loss = 0.7945722593641713, disc_loss = 0.08472884570640932
Trained batch 662 in epoch 1, gen_loss = 0.7948449321462019, disc_loss = 0.08461239225607574
Trained batch 663 in epoch 1, gen_loss = 0.7950603299471269, disc_loss = 0.08449883402657628
Trained batch 664 in epoch 1, gen_loss = 0.7951092245883511, disc_loss = 0.08438101589182546
Trained batch 665 in epoch 1, gen_loss = 0.7952169125323539, disc_loss = 0.08426204411202466
Trained batch 666 in epoch 1, gen_loss = 0.7950848518819108, disc_loss = 0.08418792146230131
Trained batch 667 in epoch 1, gen_loss = 0.794956382074042, disc_loss = 0.08411958760862144
Trained batch 668 in epoch 1, gen_loss = 0.7951801076241851, disc_loss = 0.08406620446115075
Trained batch 669 in epoch 1, gen_loss = 0.7953791318544701, disc_loss = 0.08402303530827665
Trained batch 670 in epoch 1, gen_loss = 0.7947998850782653, disc_loss = 0.08418680156925318
Trained batch 671 in epoch 1, gen_loss = 0.794959749228188, disc_loss = 0.0841812668829031
Trained batch 672 in epoch 1, gen_loss = 0.7945658472459348, disc_loss = 0.08434082291097302
Trained batch 673 in epoch 1, gen_loss = 0.7946471195192648, disc_loss = 0.084258316943176
Trained batch 674 in epoch 1, gen_loss = 0.7943748046733715, disc_loss = 0.0842079616934751
Trained batch 675 in epoch 1, gen_loss = 0.7944678711820636, disc_loss = 0.08415582710112439
Trained batch 676 in epoch 1, gen_loss = 0.7947186336383509, disc_loss = 0.08411494377990868
Trained batch 677 in epoch 1, gen_loss = 0.794590576296359, disc_loss = 0.08405361979118765
Trained batch 678 in epoch 1, gen_loss = 0.794356453664524, disc_loss = 0.08405020609888933
Trained batch 679 in epoch 1, gen_loss = 0.7945753107176108, disc_loss = 0.08433713580598123
Trained batch 680 in epoch 1, gen_loss = 0.7943011548550644, disc_loss = 0.08433154499583581
Trained batch 681 in epoch 1, gen_loss = 0.7944477114859214, disc_loss = 0.08423606412726949
Trained batch 682 in epoch 1, gen_loss = 0.7945390527803413, disc_loss = 0.08415952272949083
Trained batch 683 in epoch 1, gen_loss = 0.7943533899491293, disc_loss = 0.08412650075491943
Trained batch 684 in epoch 1, gen_loss = 0.7941881877662491, disc_loss = 0.08414325668870805
Trained batch 685 in epoch 1, gen_loss = 0.7943042763468128, disc_loss = 0.08405331520495377
Trained batch 686 in epoch 1, gen_loss = 0.7940270905064356, disc_loss = 0.08403860296534843
Trained batch 687 in epoch 1, gen_loss = 0.7941572866294273, disc_loss = 0.08408557748602065
Trained batch 688 in epoch 1, gen_loss = 0.7937563970057816, disc_loss = 0.08412627024131358
Trained batch 689 in epoch 1, gen_loss = 0.7935826630696007, disc_loss = 0.08407585316816804
Trained batch 690 in epoch 1, gen_loss = 0.7939463538992422, disc_loss = 0.08408716643820807
Trained batch 691 in epoch 1, gen_loss = 0.7942694450561711, disc_loss = 0.08404557459558376
Trained batch 692 in epoch 1, gen_loss = 0.7938924520390719, disc_loss = 0.08414369345169574
Trained batch 693 in epoch 1, gen_loss = 0.7936354374851204, disc_loss = 0.08414323410986835
Trained batch 694 in epoch 1, gen_loss = 0.7935503619180309, disc_loss = 0.08420420608402852
Trained batch 695 in epoch 1, gen_loss = 0.7936658002007967, disc_loss = 0.08415804045367183
Trained batch 696 in epoch 1, gen_loss = 0.7935158374319802, disc_loss = 0.08410395350383389
Trained batch 697 in epoch 1, gen_loss = 0.7938441126086992, disc_loss = 0.0840459111694348
Trained batch 698 in epoch 1, gen_loss = 0.793817043219172, disc_loss = 0.0840111193750107
Trained batch 699 in epoch 1, gen_loss = 0.7935291004180908, disc_loss = 0.08405397568330435
Trained batch 700 in epoch 1, gen_loss = 0.7932584683667236, disc_loss = 0.08405317257612827
Trained batch 701 in epoch 1, gen_loss = 0.793474565289299, disc_loss = 0.08399886074257043
Trained batch 702 in epoch 1, gen_loss = 0.7935484584161262, disc_loss = 0.0839163451571452
Trained batch 703 in epoch 1, gen_loss = 0.7936958350579847, disc_loss = 0.08391616518764006
Trained batch 704 in epoch 1, gen_loss = 0.7932159350273457, disc_loss = 0.08414521811179923
Trained batch 705 in epoch 1, gen_loss = 0.7934035399649029, disc_loss = 0.08405077387941552
Trained batch 706 in epoch 1, gen_loss = 0.7934862619748041, disc_loss = 0.08402039781061318
Trained batch 707 in epoch 1, gen_loss = 0.7935153540581633, disc_loss = 0.084044239322305
Trained batch 708 in epoch 1, gen_loss = 0.793242072521043, disc_loss = 0.08403351802243594
Trained batch 709 in epoch 1, gen_loss = 0.7930793590948615, disc_loss = 0.08398069946233078
Trained batch 710 in epoch 1, gen_loss = 0.7930849389017215, disc_loss = 0.08394060882414874
Trained batch 711 in epoch 1, gen_loss = 0.7931558433710859, disc_loss = 0.08393670593583276
Trained batch 712 in epoch 1, gen_loss = 0.7929722556392408, disc_loss = 0.08389274688890834
Trained batch 713 in epoch 1, gen_loss = 0.7929339206853167, disc_loss = 0.08384590921173503
Trained batch 714 in epoch 1, gen_loss = 0.7931458799989073, disc_loss = 0.08387617899879969
Trained batch 715 in epoch 1, gen_loss = 0.7931879206909148, disc_loss = 0.08379291759331726
Trained batch 716 in epoch 1, gen_loss = 0.7928568162179891, disc_loss = 0.0838784241865063
Trained batch 717 in epoch 1, gen_loss = 0.792729673362376, disc_loss = 0.08379548082866221
Trained batch 718 in epoch 1, gen_loss = 0.7932051732742406, disc_loss = 0.08382699759230174
Trained batch 719 in epoch 1, gen_loss = 0.7929384862383206, disc_loss = 0.08381003535048674
Trained batch 720 in epoch 1, gen_loss = 0.7933135374905167, disc_loss = 0.08375699945658331
Trained batch 721 in epoch 1, gen_loss = 0.7931327418607358, disc_loss = 0.08370292963172435
Trained batch 722 in epoch 1, gen_loss = 0.7936187987505647, disc_loss = 0.08369722386743528
Trained batch 723 in epoch 1, gen_loss = 0.7931791629580504, disc_loss = 0.0838568309950385
Trained batch 724 in epoch 1, gen_loss = 0.7928958568901852, disc_loss = 0.08406750941488507
Trained batch 725 in epoch 1, gen_loss = 0.7926396477977763, disc_loss = 0.08415452174787197
Trained batch 726 in epoch 1, gen_loss = 0.7925323949719394, disc_loss = 0.08424858069860798
Trained batch 727 in epoch 1, gen_loss = 0.7925294166082865, disc_loss = 0.0842011360196361
Trained batch 728 in epoch 1, gen_loss = 0.7926164521274907, disc_loss = 0.0841789442029576
Trained batch 729 in epoch 1, gen_loss = 0.792743420519241, disc_loss = 0.08409187351704307
Trained batch 730 in epoch 1, gen_loss = 0.7927032093506016, disc_loss = 0.08400590099023576
Trained batch 731 in epoch 1, gen_loss = 0.7925047319117791, disc_loss = 0.08414409479509297
Trained batch 732 in epoch 1, gen_loss = 0.7923288747038068, disc_loss = 0.08423002414808115
Trained batch 733 in epoch 1, gen_loss = 0.7923228092674338, disc_loss = 0.08429786856178377
Trained batch 734 in epoch 1, gen_loss = 0.7922909724469087, disc_loss = 0.0842557804712861
Trained batch 735 in epoch 1, gen_loss = 0.7919798775211625, disc_loss = 0.08430862335555266
Trained batch 736 in epoch 1, gen_loss = 0.792098299619139, disc_loss = 0.0842466408293947
Trained batch 737 in epoch 1, gen_loss = 0.7924131910975386, disc_loss = 0.0842515535915755
Trained batch 738 in epoch 1, gen_loss = 0.7927166123512794, disc_loss = 0.08427218929927478
Trained batch 739 in epoch 1, gen_loss = 0.792703208085653, disc_loss = 0.08421933495320028
Trained batch 740 in epoch 1, gen_loss = 0.7925477657723523, disc_loss = 0.08415638374299184
Trained batch 741 in epoch 1, gen_loss = 0.7926291393623198, disc_loss = 0.08408042743225956
Trained batch 742 in epoch 1, gen_loss = 0.7928584910337568, disc_loss = 0.0840105591470333
Trained batch 743 in epoch 1, gen_loss = 0.7928247529492584, disc_loss = 0.0839219800292349
Trained batch 744 in epoch 1, gen_loss = 0.7930288435628751, disc_loss = 0.08383751804752888
Trained batch 745 in epoch 1, gen_loss = 0.7933101608510311, disc_loss = 0.08374656935256154
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.9025158882141113, disc_loss = 0.011572166346013546
Trained batch 1 in epoch 2, gen_loss = 0.9503512680530548, disc_loss = 0.021204771008342505
Trained batch 2 in epoch 2, gen_loss = 0.9225568572680155, disc_loss = 0.022011397096017998
Trained batch 3 in epoch 2, gen_loss = 0.9427369683980942, disc_loss = 0.02022812608629465
Trained batch 4 in epoch 2, gen_loss = 0.9517590641975403, disc_loss = 0.022755345702171324
Trained batch 5 in epoch 2, gen_loss = 0.9716285367806753, disc_loss = 0.021660012503465016
Trained batch 6 in epoch 2, gen_loss = 0.9642025658062526, disc_loss = 0.02157874751303877
Trained batch 7 in epoch 2, gen_loss = 0.9491544142365456, disc_loss = 0.019690148474182934
Trained batch 8 in epoch 2, gen_loss = 0.9456634124120077, disc_loss = 0.018253905439956322
Trained batch 9 in epoch 2, gen_loss = 0.946913993358612, disc_loss = 0.017017714539542796
Trained batch 10 in epoch 2, gen_loss = 0.9376629536802118, disc_loss = 0.01621052457697012
Trained batch 11 in epoch 2, gen_loss = 0.9350527673959732, disc_loss = 0.015397042656938234
Trained batch 12 in epoch 2, gen_loss = 0.9309960649563715, disc_loss = 0.01622253728027527
Trained batch 13 in epoch 2, gen_loss = 0.9263856453554971, disc_loss = 0.015952250388051783
Trained batch 14 in epoch 2, gen_loss = 0.9178750157356262, disc_loss = 0.016128491734464963
Trained batch 15 in epoch 2, gen_loss = 0.9124771133065224, disc_loss = 0.015984166064299643
Trained batch 16 in epoch 2, gen_loss = 0.9246999446083518, disc_loss = 0.016201963648200035
Trained batch 17 in epoch 2, gen_loss = 0.9289226730664571, disc_loss = 0.015958006390266948
Trained batch 18 in epoch 2, gen_loss = 0.930593656866174, disc_loss = 0.01577471211356552
Trained batch 19 in epoch 2, gen_loss = 0.9260585099458695, disc_loss = 0.015223887702450156
Trained batch 20 in epoch 2, gen_loss = 0.9187976803098407, disc_loss = 0.015182345617739927
Trained batch 21 in epoch 2, gen_loss = 0.9193498844450171, disc_loss = 0.014860191255469214
Trained batch 22 in epoch 2, gen_loss = 0.9206905131754668, disc_loss = 0.014535247105295244
Trained batch 23 in epoch 2, gen_loss = 0.9203526874383291, disc_loss = 0.014259892515838146
Trained batch 24 in epoch 2, gen_loss = 0.9169195556640625, disc_loss = 0.014322845339775086
Trained batch 25 in epoch 2, gen_loss = 0.9071084948686453, disc_loss = 0.015556628171067972
Trained batch 26 in epoch 2, gen_loss = 0.9119423539550217, disc_loss = 0.017700911534053308
Trained batch 27 in epoch 2, gen_loss = 0.9124646016529628, disc_loss = 0.017407932185700963
Trained batch 28 in epoch 2, gen_loss = 0.9172019794069487, disc_loss = 0.017741411217841608
Trained batch 29 in epoch 2, gen_loss = 0.9088586668173472, disc_loss = 0.018250965885818003
Trained batch 30 in epoch 2, gen_loss = 0.9009990788275196, disc_loss = 0.019517296444504492
Trained batch 31 in epoch 2, gen_loss = 0.9039800632745028, disc_loss = 0.020555538299959153
Trained batch 32 in epoch 2, gen_loss = 0.8935064420555577, disc_loss = 0.024101503588484997
Trained batch 33 in epoch 2, gen_loss = 0.8895299943054423, disc_loss = 0.02551736348472974
Trained batch 34 in epoch 2, gen_loss = 0.8851218598229544, disc_loss = 0.02623460308781692
Trained batch 35 in epoch 2, gen_loss = 0.8762211799621582, disc_loss = 0.028720304732107453
Trained batch 36 in epoch 2, gen_loss = 0.8782798406240102, disc_loss = 0.03484702548263846
Trained batch 37 in epoch 2, gen_loss = 0.8799550392125782, disc_loss = 0.03431172394438794
Trained batch 38 in epoch 2, gen_loss = 0.8765067121921442, disc_loss = 0.03400640132335516
Trained batch 39 in epoch 2, gen_loss = 0.8720963016152382, disc_loss = 0.03517528921365738
Trained batch 40 in epoch 2, gen_loss = 0.8717762042836446, disc_loss = 0.03478011102756349
Trained batch 41 in epoch 2, gen_loss = 0.8720493983654749, disc_loss = 0.034321264762963564
Trained batch 42 in epoch 2, gen_loss = 0.872444230456685, disc_loss = 0.0337579736572712
Trained batch 43 in epoch 2, gen_loss = 0.8653659834103151, disc_loss = 0.0355698931327259
Trained batch 44 in epoch 2, gen_loss = 0.8761421746677822, disc_loss = 0.036486087346242535
Trained batch 45 in epoch 2, gen_loss = 0.8801914310973623, disc_loss = 0.03628881593518283
Trained batch 46 in epoch 2, gen_loss = 0.8789665432686501, disc_loss = 0.03648210826151548
Trained batch 47 in epoch 2, gen_loss = 0.8813667930662632, disc_loss = 0.03750827491361027
Trained batch 48 in epoch 2, gen_loss = 0.8855048332895551, disc_loss = 0.038998378345704805
Trained batch 49 in epoch 2, gen_loss = 0.8876917886734009, disc_loss = 0.0390526127256453
Trained batch 50 in epoch 2, gen_loss = 0.8892689358954337, disc_loss = 0.0385603896506569
Trained batch 51 in epoch 2, gen_loss = 0.8884481008236225, disc_loss = 0.04359795301794433
Trained batch 52 in epoch 2, gen_loss = 0.8829093991585497, disc_loss = 0.04492880999690519
Trained batch 53 in epoch 2, gen_loss = 0.8775723951834219, disc_loss = 0.04649543463838873
Trained batch 54 in epoch 2, gen_loss = 0.8793839411302047, disc_loss = 0.0461460250175812
Trained batch 55 in epoch 2, gen_loss = 0.8827334770134517, disc_loss = 0.04611403633108629
Trained batch 56 in epoch 2, gen_loss = 0.8829227968266136, disc_loss = 0.045458882638629065
Trained batch 57 in epoch 2, gen_loss = 0.8815712199128908, disc_loss = 0.04500278629812187
Trained batch 58 in epoch 2, gen_loss = 0.8805452332658282, disc_loss = 0.04432390459765822
Trained batch 59 in epoch 2, gen_loss = 0.8807051648696264, disc_loss = 0.04366806383865575
Trained batch 60 in epoch 2, gen_loss = 0.8804050341981356, disc_loss = 0.04307832929198859
Trained batch 61 in epoch 2, gen_loss = 0.8816783726215363, disc_loss = 0.04417056295900575
Trained batch 62 in epoch 2, gen_loss = 0.8780448938172961, disc_loss = 0.0449427506398587
Trained batch 63 in epoch 2, gen_loss = 0.8799700113013387, disc_loss = 0.04444446299748961
Trained batch 64 in epoch 2, gen_loss = 0.8832928538322449, disc_loss = 0.04412180668172928
Trained batch 65 in epoch 2, gen_loss = 0.8839157070174362, disc_loss = 0.04381856848626877
Trained batch 66 in epoch 2, gen_loss = 0.8818377825751234, disc_loss = 0.04370528460938984
Trained batch 67 in epoch 2, gen_loss = 0.8815761962357689, disc_loss = 0.04315151337205487
Trained batch 68 in epoch 2, gen_loss = 0.8769729966702668, disc_loss = 0.04373760637489782
Trained batch 69 in epoch 2, gen_loss = 0.8769446057932717, disc_loss = 0.04379898179322481
Trained batch 70 in epoch 2, gen_loss = 0.8784885347728998, disc_loss = 0.04486598565020192
Trained batch 71 in epoch 2, gen_loss = 0.8743713522950808, disc_loss = 0.04575456645236247
Trained batch 72 in epoch 2, gen_loss = 0.8709206287175009, disc_loss = 0.046018416521279776
Trained batch 73 in epoch 2, gen_loss = 0.8700957878215893, disc_loss = 0.04652086693189434
Trained batch 74 in epoch 2, gen_loss = 0.8690342219670614, disc_loss = 0.04634130251904329
Trained batch 75 in epoch 2, gen_loss = 0.8663320329628492, disc_loss = 0.04649463352306109
Trained batch 76 in epoch 2, gen_loss = 0.8668868828129459, disc_loss = 0.04680915561492567
Trained batch 77 in epoch 2, gen_loss = 0.8662188733235384, disc_loss = 0.04661921743685619
Trained batch 78 in epoch 2, gen_loss = 0.8634544180918343, disc_loss = 0.04677330473838728
Trained batch 79 in epoch 2, gen_loss = 0.8616181410849094, disc_loss = 0.04677578953560442
Trained batch 80 in epoch 2, gen_loss = 0.8645197307621991, disc_loss = 0.04676603256828255
Trained batch 81 in epoch 2, gen_loss = 0.8603580179737835, disc_loss = 0.04789370205253363
Trained batch 82 in epoch 2, gen_loss = 0.8571754464183945, disc_loss = 0.04805127452744777
Trained batch 83 in epoch 2, gen_loss = 0.8585299430858522, disc_loss = 0.05224521478105869
Trained batch 84 in epoch 2, gen_loss = 0.8539241503266727, disc_loss = 0.05509249447461437
Trained batch 85 in epoch 2, gen_loss = 0.8519622579563496, disc_loss = 0.05519621154336735
Trained batch 86 in epoch 2, gen_loss = 0.8510723257886952, disc_loss = 0.05746677836895674
Trained batch 87 in epoch 2, gen_loss = 0.8485126813704317, disc_loss = 0.05786336393264884
Trained batch 88 in epoch 2, gen_loss = 0.8459170715192731, disc_loss = 0.05823996656814988
Trained batch 89 in epoch 2, gen_loss = 0.84498237768809, disc_loss = 0.05813804974572526
Trained batch 90 in epoch 2, gen_loss = 0.8449616785887833, disc_loss = 0.05845723024845778
Trained batch 91 in epoch 2, gen_loss = 0.8434231073960013, disc_loss = 0.05862173796428934
Trained batch 92 in epoch 2, gen_loss = 0.8405282670451749, disc_loss = 0.059008619657927947
Trained batch 93 in epoch 2, gen_loss = 0.8392477384273042, disc_loss = 0.05923797992712006
Trained batch 94 in epoch 2, gen_loss = 0.8392208488363969, disc_loss = 0.05926741567489348
Trained batch 95 in epoch 2, gen_loss = 0.8376027314613262, disc_loss = 0.05887302183934177
Trained batch 96 in epoch 2, gen_loss = 0.8355046627447777, disc_loss = 0.058763987912806036
Trained batch 97 in epoch 2, gen_loss = 0.8336167998459875, disc_loss = 0.05899282778632276
Trained batch 98 in epoch 2, gen_loss = 0.8340106630566144, disc_loss = 0.05927555148273406
Trained batch 99 in epoch 2, gen_loss = 0.8323261040449143, disc_loss = 0.05955482242628932
Trained batch 100 in epoch 2, gen_loss = 0.8328115296835946, disc_loss = 0.059327098494856664
Trained batch 101 in epoch 2, gen_loss = 0.830153177766239, disc_loss = 0.05974052753299475
Trained batch 102 in epoch 2, gen_loss = 0.8309681097280632, disc_loss = 0.059650443331564516
Trained batch 103 in epoch 2, gen_loss = 0.8331588329030917, disc_loss = 0.061441444917223774
Trained batch 104 in epoch 2, gen_loss = 0.8298865355196453, disc_loss = 0.0634818643863712
Trained batch 105 in epoch 2, gen_loss = 0.8277215347537454, disc_loss = 0.06422664441238597
Trained batch 106 in epoch 2, gen_loss = 0.828605956841852, disc_loss = 0.06509794564656565
Trained batch 107 in epoch 2, gen_loss = 0.8294714316725731, disc_loss = 0.0650215302594006
Trained batch 108 in epoch 2, gen_loss = 0.826213042123602, disc_loss = 0.06670151027175811
Trained batch 109 in epoch 2, gen_loss = 0.825833654945547, disc_loss = 0.06660640387033874
Trained batch 110 in epoch 2, gen_loss = 0.8263746516124623, disc_loss = 0.06633676888907815
Trained batch 111 in epoch 2, gen_loss = 0.8258069641888142, disc_loss = 0.06643695828305292
Trained batch 112 in epoch 2, gen_loss = 0.8253566475041145, disc_loss = 0.06660476536283978
Trained batch 113 in epoch 2, gen_loss = 0.8269201104055371, disc_loss = 0.06626950944528769
Trained batch 114 in epoch 2, gen_loss = 0.825286591053009, disc_loss = 0.0664569543917542
Trained batch 115 in epoch 2, gen_loss = 0.8245270683847624, disc_loss = 0.06625508525055544
Trained batch 116 in epoch 2, gen_loss = 0.8261070149576563, disc_loss = 0.06589004824049452
Trained batch 117 in epoch 2, gen_loss = 0.8257894152301853, disc_loss = 0.06555061642143686
Trained batch 118 in epoch 2, gen_loss = 0.8239001997378694, disc_loss = 0.06553185317947083
Trained batch 119 in epoch 2, gen_loss = 0.8258203099171321, disc_loss = 0.06628634488830963
Trained batch 120 in epoch 2, gen_loss = 0.8238177693579808, disc_loss = 0.06651315585640837
Trained batch 121 in epoch 2, gen_loss = 0.8232415836365496, disc_loss = 0.0665355639257392
Trained batch 122 in epoch 2, gen_loss = 0.8217647424558314, disc_loss = 0.06701476102679725
Trained batch 123 in epoch 2, gen_loss = 0.8208039028029288, disc_loss = 0.06704979251709677
Trained batch 124 in epoch 2, gen_loss = 0.8208169503211975, disc_loss = 0.06741146755218506
Trained batch 125 in epoch 2, gen_loss = 0.8203978656776367, disc_loss = 0.06710421622154258
Trained batch 126 in epoch 2, gen_loss = 0.81822703438481, disc_loss = 0.0674893367654226
Trained batch 127 in epoch 2, gen_loss = 0.817124679684639, disc_loss = 0.06787206095759757
Trained batch 128 in epoch 2, gen_loss = 0.8161071686781654, disc_loss = 0.06798921568795692
Trained batch 129 in epoch 2, gen_loss = 0.815684895332043, disc_loss = 0.06788356668100907
Trained batch 130 in epoch 2, gen_loss = 0.8161010077891458, disc_loss = 0.06767726348329137
Trained batch 131 in epoch 2, gen_loss = 0.8145501256892176, disc_loss = 0.0677396950283737
Trained batch 132 in epoch 2, gen_loss = 0.814395052597935, disc_loss = 0.06801810216410716
Trained batch 133 in epoch 2, gen_loss = 0.8147137018282022, disc_loss = 0.06789538678504638
Trained batch 134 in epoch 2, gen_loss = 0.8131312189278779, disc_loss = 0.0684901901141361
Trained batch 135 in epoch 2, gen_loss = 0.8129254917011541, disc_loss = 0.06810140830245526
Trained batch 136 in epoch 2, gen_loss = 0.8133468240717031, disc_loss = 0.06795463647122366
Trained batch 137 in epoch 2, gen_loss = 0.8119370501110519, disc_loss = 0.06786489069623791
Trained batch 138 in epoch 2, gen_loss = 0.8143468619250566, disc_loss = 0.06785538008691167
Trained batch 139 in epoch 2, gen_loss = 0.8138975633042199, disc_loss = 0.06832821378484369
Trained batch 140 in epoch 2, gen_loss = 0.812207521698999, disc_loss = 0.06881956575134544
Trained batch 141 in epoch 2, gen_loss = 0.8105330068460652, disc_loss = 0.06910387278390183
Trained batch 142 in epoch 2, gen_loss = 0.8113284494493391, disc_loss = 0.06993324084246492
Trained batch 143 in epoch 2, gen_loss = 0.8114553391933441, disc_loss = 0.0696091335396179
Trained batch 144 in epoch 2, gen_loss = 0.8093470133584121, disc_loss = 0.07006580728138315
Trained batch 145 in epoch 2, gen_loss = 0.8086035623125833, disc_loss = 0.06987567453913085
Trained batch 146 in epoch 2, gen_loss = 0.8086406876440762, disc_loss = 0.06980515969600402
Trained batch 147 in epoch 2, gen_loss = 0.8080720841079145, disc_loss = 0.07006858776298326
Trained batch 148 in epoch 2, gen_loss = 0.8071905670550046, disc_loss = 0.06993734457798852
Trained batch 149 in epoch 2, gen_loss = 0.805517764488856, disc_loss = 0.07013146133472523
Trained batch 150 in epoch 2, gen_loss = 0.8075932639324113, disc_loss = 0.07148871784227968
Trained batch 151 in epoch 2, gen_loss = 0.8074041361871519, disc_loss = 0.0713756636495849
Trained batch 152 in epoch 2, gen_loss = 0.806620116716896, disc_loss = 0.07152453290140318
Trained batch 153 in epoch 2, gen_loss = 0.8055971868626484, disc_loss = 0.07142121691934088
Trained batch 154 in epoch 2, gen_loss = 0.8055596697715021, disc_loss = 0.07158108275503881
Trained batch 155 in epoch 2, gen_loss = 0.8067030876110761, disc_loss = 0.07148206409496757
Trained batch 156 in epoch 2, gen_loss = 0.8056445372332434, disc_loss = 0.0714727921446987
Trained batch 157 in epoch 2, gen_loss = 0.8042499536200415, disc_loss = 0.07190567201970122
Trained batch 158 in epoch 2, gen_loss = 0.8055065150530833, disc_loss = 0.07180178834347979
Trained batch 159 in epoch 2, gen_loss = 0.8074627496302128, disc_loss = 0.07197025757050142
Trained batch 160 in epoch 2, gen_loss = 0.8080142751243544, disc_loss = 0.0717845879240621
Trained batch 161 in epoch 2, gen_loss = 0.8078041371004081, disc_loss = 0.07174360911925266
Trained batch 162 in epoch 2, gen_loss = 0.8080305365697007, disc_loss = 0.0714769785412433
Trained batch 163 in epoch 2, gen_loss = 0.8080651916381789, disc_loss = 0.07126963525874222
Trained batch 164 in epoch 2, gen_loss = 0.8096704862334512, disc_loss = 0.07094449605228323
Trained batch 165 in epoch 2, gen_loss = 0.8113134442323662, disc_loss = 0.07086601434836545
Trained batch 166 in epoch 2, gen_loss = 0.8118350537951121, disc_loss = 0.07051099934420008
Trained batch 167 in epoch 2, gen_loss = 0.8110077682705152, disc_loss = 0.07038385770837999
Trained batch 168 in epoch 2, gen_loss = 0.8115350089129612, disc_loss = 0.0700172173167915
Trained batch 169 in epoch 2, gen_loss = 0.8124208583551294, disc_loss = 0.06966235421269255
Trained batch 170 in epoch 2, gen_loss = 0.8136499206922208, disc_loss = 0.0693491198264106
Trained batch 171 in epoch 2, gen_loss = 0.8137025077675664, disc_loss = 0.06902418027870184
Trained batch 172 in epoch 2, gen_loss = 0.8143378671883159, disc_loss = 0.06869410470967864
Trained batch 173 in epoch 2, gen_loss = 0.8144856763297114, disc_loss = 0.06833431228791931
Trained batch 174 in epoch 2, gen_loss = 0.8146445005280631, disc_loss = 0.06798308693936893
Trained batch 175 in epoch 2, gen_loss = 0.8156071911481294, disc_loss = 0.06769219316034154
Trained batch 176 in epoch 2, gen_loss = 0.8161283997492602, disc_loss = 0.06733501275296265
Trained batch 177 in epoch 2, gen_loss = 0.8165593582592653, disc_loss = 0.0670056754325548
Trained batch 178 in epoch 2, gen_loss = 0.8170628481071088, disc_loss = 0.0667124731861596
Trained batch 179 in epoch 2, gen_loss = 0.8172638220919504, disc_loss = 0.06640718329387406
Trained batch 180 in epoch 2, gen_loss = 0.8170612273295281, disc_loss = 0.0661555820540911
Trained batch 181 in epoch 2, gen_loss = 0.8177865409589076, disc_loss = 0.0658229299703265
Trained batch 182 in epoch 2, gen_loss = 0.8181991883314372, disc_loss = 0.0655041282075391
Trained batch 183 in epoch 2, gen_loss = 0.8190344730797021, disc_loss = 0.06522837634775383
Trained batch 184 in epoch 2, gen_loss = 0.8196132366721695, disc_loss = 0.0649089291062508
Trained batch 185 in epoch 2, gen_loss = 0.8199036566800969, disc_loss = 0.06463422721141689
Trained batch 186 in epoch 2, gen_loss = 0.8198912513447317, disc_loss = 0.0643272943879393
Trained batch 187 in epoch 2, gen_loss = 0.8200795257345159, disc_loss = 0.06402939178317071
Trained batch 188 in epoch 2, gen_loss = 0.8206483617661491, disc_loss = 0.0637190521290654
Trained batch 189 in epoch 2, gen_loss = 0.8214854836463928, disc_loss = 0.06342067085451593
Trained batch 190 in epoch 2, gen_loss = 0.821857956379496, disc_loss = 0.06312357385628198
Trained batch 191 in epoch 2, gen_loss = 0.8222410200784603, disc_loss = 0.06281558096331234
Trained batch 192 in epoch 2, gen_loss = 0.8227914318519552, disc_loss = 0.06254316308086863
Trained batch 193 in epoch 2, gen_loss = 0.8231043259507602, disc_loss = 0.06235390508393805
Trained batch 194 in epoch 2, gen_loss = 0.8232972728900421, disc_loss = 0.06214652656076046
Trained batch 195 in epoch 2, gen_loss = 0.8232826906807569, disc_loss = 0.06192877974684293
Trained batch 196 in epoch 2, gen_loss = 0.8234284795480331, disc_loss = 0.06165062453181762
Trained batch 197 in epoch 2, gen_loss = 0.8237513815513765, disc_loss = 0.06138674213522763
Trained batch 198 in epoch 2, gen_loss = 0.823509163592928, disc_loss = 0.06170726652215024
Trained batch 199 in epoch 2, gen_loss = 0.8240284872055054, disc_loss = 0.061460164473392066
Trained batch 200 in epoch 2, gen_loss = 0.8248634302794043, disc_loss = 0.06121214374955466
Trained batch 201 in epoch 2, gen_loss = 0.8262333651580432, disc_loss = 0.060999465954148825
Trained batch 202 in epoch 2, gen_loss = 0.8271770882489059, disc_loss = 0.060737279840180736
Trained batch 203 in epoch 2, gen_loss = 0.8276831124927483, disc_loss = 0.06048842616306216
Trained batch 204 in epoch 2, gen_loss = 0.827991955745511, disc_loss = 0.06023311394198639
Trained batch 205 in epoch 2, gen_loss = 0.8280547463778153, disc_loss = 0.05996821125860787
Trained batch 206 in epoch 2, gen_loss = 0.8290512711529571, disc_loss = 0.05987686535640471
Trained batch 207 in epoch 2, gen_loss = 0.8286607325650178, disc_loss = 0.05978467001561792
Trained batch 208 in epoch 2, gen_loss = 0.8291238694670098, disc_loss = 0.059519721114892135
Trained batch 209 in epoch 2, gen_loss = 0.8296344822361356, disc_loss = 0.0592554218002728
Trained batch 210 in epoch 2, gen_loss = 0.8308678924754898, disc_loss = 0.05903124031103194
Trained batch 211 in epoch 2, gen_loss = 0.832108845969416, disc_loss = 0.05881597989519952
Trained batch 212 in epoch 2, gen_loss = 0.831786615188133, disc_loss = 0.05871253282688733
Trained batch 213 in epoch 2, gen_loss = 0.8307547457864352, disc_loss = 0.05870067819552583
Trained batch 214 in epoch 2, gen_loss = 0.8321017087892044, disc_loss = 0.05851235031475161
Trained batch 215 in epoch 2, gen_loss = 0.8329816554431562, disc_loss = 0.05838239740114659
Trained batch 216 in epoch 2, gen_loss = 0.8334538994296905, disc_loss = 0.05816649853290501
Trained batch 217 in epoch 2, gen_loss = 0.8337291082657805, disc_loss = 0.05798071602342326
Trained batch 218 in epoch 2, gen_loss = 0.8340264741144224, disc_loss = 0.0577731148582207
Trained batch 219 in epoch 2, gen_loss = 0.8345030987804586, disc_loss = 0.05753404810093343
Trained batch 220 in epoch 2, gen_loss = 0.834672398966362, disc_loss = 0.0573318875963669
Trained batch 221 in epoch 2, gen_loss = 0.8350018061496116, disc_loss = 0.057117575062187134
Trained batch 222 in epoch 2, gen_loss = 0.8354454815655011, disc_loss = 0.05688447543240315
Trained batch 223 in epoch 2, gen_loss = 0.8359175460147006, disc_loss = 0.056667064021374766
Trained batch 224 in epoch 2, gen_loss = 0.8364055177900527, disc_loss = 0.056434617307451036
Trained batch 225 in epoch 2, gen_loss = 0.8362707408656062, disc_loss = 0.05623390135742658
Trained batch 226 in epoch 2, gen_loss = 0.8364267393881004, disc_loss = 0.056018468899250294
Trained batch 227 in epoch 2, gen_loss = 0.8369445249176862, disc_loss = 0.05634321985161749
Trained batch 228 in epoch 2, gen_loss = 0.8366034075162296, disc_loss = 0.05621416277483952
Trained batch 229 in epoch 2, gen_loss = 0.8360064887482187, disc_loss = 0.056106587430543226
Trained batch 230 in epoch 2, gen_loss = 0.8358523894698073, disc_loss = 0.05589913028127058
Trained batch 231 in epoch 2, gen_loss = 0.836365170776844, disc_loss = 0.05571019262525028
Trained batch 232 in epoch 2, gen_loss = 0.836893535478944, disc_loss = 0.055499892961633567
Trained batch 233 in epoch 2, gen_loss = 0.837120974675203, disc_loss = 0.055281425269049965
Trained batch 234 in epoch 2, gen_loss = 0.837214118622719, disc_loss = 0.05506550934997962
Trained batch 235 in epoch 2, gen_loss = 0.8377953277806104, disc_loss = 0.05485668311968951
Trained batch 236 in epoch 2, gen_loss = 0.8378334417624815, disc_loss = 0.05464061568117846
Trained batch 237 in epoch 2, gen_loss = 0.8380229202639154, disc_loss = 0.05444241700764401
Trained batch 238 in epoch 2, gen_loss = 0.8382469490482218, disc_loss = 0.05423110952039705
Trained batch 239 in epoch 2, gen_loss = 0.8387265014151732, disc_loss = 0.05402101285581011
Trained batch 240 in epoch 2, gen_loss = 0.8388975702875383, disc_loss = 0.053833499229107344
Trained batch 241 in epoch 2, gen_loss = 0.8394678954250556, disc_loss = 0.05364803063456154
Trained batch 242 in epoch 2, gen_loss = 0.8396832491635295, disc_loss = 0.053440460523230184
Trained batch 243 in epoch 2, gen_loss = 0.8394625748767227, disc_loss = 0.053236571323798325
Trained batch 244 in epoch 2, gen_loss = 0.8391330655740232, disc_loss = 0.05312771651209617
Trained batch 245 in epoch 2, gen_loss = 0.8391345710289188, disc_loss = 0.052989406859487054
Trained batch 246 in epoch 2, gen_loss = 0.8397295354348928, disc_loss = 0.05279761456473455
Trained batch 247 in epoch 2, gen_loss = 0.8401935927329525, disc_loss = 0.052603956922182754
Trained batch 248 in epoch 2, gen_loss = 0.8405873368542836, disc_loss = 0.05240915707465875
Trained batch 249 in epoch 2, gen_loss = 0.840568085193634, disc_loss = 0.05222810246422887
Trained batch 250 in epoch 2, gen_loss = 0.8407759044274866, disc_loss = 0.052090387906419094
Trained batch 251 in epoch 2, gen_loss = 0.8405841016580188, disc_loss = 0.05191890205374904
Trained batch 252 in epoch 2, gen_loss = 0.841442031351474, disc_loss = 0.051894205188003216
Trained batch 253 in epoch 2, gen_loss = 0.8404843816607017, disc_loss = 0.05200300747382007
Trained batch 254 in epoch 2, gen_loss = 0.8406355168305192, disc_loss = 0.05196466247605927
Trained batch 255 in epoch 2, gen_loss = 0.8402869247365743, disc_loss = 0.05182588250681874
Trained batch 256 in epoch 2, gen_loss = 0.8404914101274097, disc_loss = 0.05164643929698704
Trained batch 257 in epoch 2, gen_loss = 0.8402096936407015, disc_loss = 0.05155079623020088
Trained batch 258 in epoch 2, gen_loss = 0.8403045990752437, disc_loss = 0.051384709527334885
Trained batch 259 in epoch 2, gen_loss = 0.8404439841325466, disc_loss = 0.05125021025753365
Trained batch 260 in epoch 2, gen_loss = 0.8403953247600131, disc_loss = 0.05116217724365179
Trained batch 261 in epoch 2, gen_loss = 0.8415712184123411, disc_loss = 0.05113254437393701
Trained batch 262 in epoch 2, gen_loss = 0.8416473969760503, disc_loss = 0.05097208333913478
Trained batch 263 in epoch 2, gen_loss = 0.8417764793742787, disc_loss = 0.05080902485430918
Trained batch 264 in epoch 2, gen_loss = 0.8418640120974127, disc_loss = 0.05066680928938232
Trained batch 265 in epoch 2, gen_loss = 0.841800138018185, disc_loss = 0.05061477590422321
Trained batch 266 in epoch 2, gen_loss = 0.8421574643488681, disc_loss = 0.050447921167487066
Trained batch 267 in epoch 2, gen_loss = 0.8436289247292191, disc_loss = 0.05039472794577257
Trained batch 268 in epoch 2, gen_loss = 0.8446945368578886, disc_loss = 0.050338886512034886
Trained batch 269 in epoch 2, gen_loss = 0.8447696646054585, disc_loss = 0.05017805965617299
Trained batch 270 in epoch 2, gen_loss = 0.8444538584934389, disc_loss = 0.050038148339741566
Trained batch 271 in epoch 2, gen_loss = 0.844475506202263, disc_loss = 0.049870131936211905
Trained batch 272 in epoch 2, gen_loss = 0.844353199441791, disc_loss = 0.04972667868109249
Trained batch 273 in epoch 2, gen_loss = 0.8448642616289376, disc_loss = 0.04958627577089317
Trained batch 274 in epoch 2, gen_loss = 0.8450599785284563, disc_loss = 0.049422715020112015
Trained batch 275 in epoch 2, gen_loss = 0.8453990581674852, disc_loss = 0.04925822659625091
Trained batch 276 in epoch 2, gen_loss = 0.8456498238153837, disc_loss = 0.04909732461392557
Trained batch 277 in epoch 2, gen_loss = 0.8460052562274522, disc_loss = 0.04894483976213516
Trained batch 278 in epoch 2, gen_loss = 0.846211148846534, disc_loss = 0.04878328084832184
Trained batch 279 in epoch 2, gen_loss = 0.8463348128965923, disc_loss = 0.048810883729519056
Trained batch 280 in epoch 2, gen_loss = 0.8464108658855072, disc_loss = 0.048689586377215446
Trained batch 281 in epoch 2, gen_loss = 0.8460975217481032, disc_loss = 0.04854733388745457
Trained batch 282 in epoch 2, gen_loss = 0.8461867507691939, disc_loss = 0.0483948891528293
Trained batch 283 in epoch 2, gen_loss = 0.8462084080551712, disc_loss = 0.04824957333695353
Trained batch 284 in epoch 2, gen_loss = 0.8464939169716417, disc_loss = 0.04809368393432937
Trained batch 285 in epoch 2, gen_loss = 0.8466930987534823, disc_loss = 0.047949029489296614
Trained batch 286 in epoch 2, gen_loss = 0.8467632841565468, disc_loss = 0.04779421069938365
Trained batch 287 in epoch 2, gen_loss = 0.8468210931039519, disc_loss = 0.04764415590115176
Trained batch 288 in epoch 2, gen_loss = 0.8469342310948356, disc_loss = 0.04749355703885554
Trained batch 289 in epoch 2, gen_loss = 0.8468631912922037, disc_loss = 0.04734763028340992
Trained batch 290 in epoch 2, gen_loss = 0.847052715078662, disc_loss = 0.04773179513939954
Trained batch 291 in epoch 2, gen_loss = 0.8459704395842879, disc_loss = 0.04834311831126959
Trained batch 292 in epoch 2, gen_loss = 0.8452570995779981, disc_loss = 0.04828351266195826
Trained batch 293 in epoch 2, gen_loss = 0.844737789257854, disc_loss = 0.04855960169664527
Trained batch 294 in epoch 2, gen_loss = 0.8442076287027133, disc_loss = 0.048567106921257354
Trained batch 295 in epoch 2, gen_loss = 0.8443443755040297, disc_loss = 0.0488688169051956
Trained batch 296 in epoch 2, gen_loss = 0.8436812160392402, disc_loss = 0.048947528110478415
Trained batch 297 in epoch 2, gen_loss = 0.8438087651793589, disc_loss = 0.04900699759436609
Trained batch 298 in epoch 2, gen_loss = 0.843198318146543, disc_loss = 0.04907824752469201
Trained batch 299 in epoch 2, gen_loss = 0.8429408891995748, disc_loss = 0.04908219225006178
Trained batch 300 in epoch 2, gen_loss = 0.8432888935174657, disc_loss = 0.04909839330664975
Trained batch 301 in epoch 2, gen_loss = 0.8428734118575292, disc_loss = 0.049063677010619824
Trained batch 302 in epoch 2, gen_loss = 0.8418888475241835, disc_loss = 0.05020435098420349
Trained batch 303 in epoch 2, gen_loss = 0.8405917561367938, disc_loss = 0.05061682703901744
Trained batch 304 in epoch 2, gen_loss = 0.8397002767343991, disc_loss = 0.05070660180778655
Trained batch 305 in epoch 2, gen_loss = 0.8395235145014096, disc_loss = 0.05073017958670343
Trained batch 306 in epoch 2, gen_loss = 0.8397489417259391, disc_loss = 0.05087719232083605
Trained batch 307 in epoch 2, gen_loss = 0.8400626109017955, disc_loss = 0.05080046886865461
Trained batch 308 in epoch 2, gen_loss = 0.8404278921077938, disc_loss = 0.050685211451736226
Trained batch 309 in epoch 2, gen_loss = 0.8404742167842003, disc_loss = 0.05056663618438066
Trained batch 310 in epoch 2, gen_loss = 0.8402754599258447, disc_loss = 0.050444438097507385
Trained batch 311 in epoch 2, gen_loss = 0.8406039327383041, disc_loss = 0.05032982453569555
Trained batch 312 in epoch 2, gen_loss = 0.8410029795984871, disc_loss = 0.050233645878654844
Trained batch 313 in epoch 2, gen_loss = 0.8411639630794525, disc_loss = 0.050115690711191645
Trained batch 314 in epoch 2, gen_loss = 0.8412550258258032, disc_loss = 0.04999302024805238
Trained batch 315 in epoch 2, gen_loss = 0.8413616718747948, disc_loss = 0.0498533395370999
Trained batch 316 in epoch 2, gen_loss = 0.8416413980703624, disc_loss = 0.0497128755898635
Trained batch 317 in epoch 2, gen_loss = 0.8421978041435938, disc_loss = 0.049607547857423766
Trained batch 318 in epoch 2, gen_loss = 0.8425150420224778, disc_loss = 0.04947604549549473
Trained batch 319 in epoch 2, gen_loss = 0.8425298662856221, disc_loss = 0.04934922805041424
Trained batch 320 in epoch 2, gen_loss = 0.8432703614234924, disc_loss = 0.04922583332137318
Trained batch 321 in epoch 2, gen_loss = 0.8431769263300096, disc_loss = 0.049107412708581925
Trained batch 322 in epoch 2, gen_loss = 0.8433887281284982, disc_loss = 0.049003809418719575
Trained batch 323 in epoch 2, gen_loss = 0.8436492188477221, disc_loss = 0.048890953204439334
Trained batch 324 in epoch 2, gen_loss = 0.8437452983856201, disc_loss = 0.04879740020331855
Trained batch 325 in epoch 2, gen_loss = 0.843579346416918, disc_loss = 0.04866216245801559
Trained batch 326 in epoch 2, gen_loss = 0.843603935810404, disc_loss = 0.04853347933777132
Trained batch 327 in epoch 2, gen_loss = 0.843688902876726, disc_loss = 0.048403400088030075
Trained batch 328 in epoch 2, gen_loss = 0.8435835662583812, disc_loss = 0.04828314131089008
Trained batch 329 in epoch 2, gen_loss = 0.8439631947965333, disc_loss = 0.04815245149727685
Trained batch 330 in epoch 2, gen_loss = 0.8439538700342899, disc_loss = 0.04803659274873079
Trained batch 331 in epoch 2, gen_loss = 0.8444479903183788, disc_loss = 0.04791338188385771
Trained batch 332 in epoch 2, gen_loss = 0.8446571300695608, disc_loss = 0.047787653200479376
Trained batch 333 in epoch 2, gen_loss = 0.8442940740528221, disc_loss = 0.04767614256933577
Trained batch 334 in epoch 2, gen_loss = 0.8448429990170607, disc_loss = 0.047553570578986806
Trained batch 335 in epoch 2, gen_loss = 0.8448569694800037, disc_loss = 0.04746327319645345
Trained batch 336 in epoch 2, gen_loss = 0.8444869942764146, disc_loss = 0.04741689546147047
Trained batch 337 in epoch 2, gen_loss = 0.8444878353169684, disc_loss = 0.04732679467050348
Trained batch 338 in epoch 2, gen_loss = 0.8446102212663948, disc_loss = 0.04742760212809001
Trained batch 339 in epoch 2, gen_loss = 0.8448861697140861, disc_loss = 0.04733626806820907
Trained batch 340 in epoch 2, gen_loss = 0.8442370447595099, disc_loss = 0.047493921799716315
Trained batch 341 in epoch 2, gen_loss = 0.843694498838737, disc_loss = 0.04759186736583078
Trained batch 342 in epoch 2, gen_loss = 0.8443421662375113, disc_loss = 0.047529029862890045
Trained batch 343 in epoch 2, gen_loss = 0.8450435938876729, disc_loss = 0.047510660837572286
Trained batch 344 in epoch 2, gen_loss = 0.8444006835204968, disc_loss = 0.04755194590939884
Trained batch 345 in epoch 2, gen_loss = 0.8445744922739922, disc_loss = 0.04744302098049831
Trained batch 346 in epoch 2, gen_loss = 0.8439480308496986, disc_loss = 0.04752099724360326
Trained batch 347 in epoch 2, gen_loss = 0.844175089536042, disc_loss = 0.047560951211516496
Trained batch 348 in epoch 2, gen_loss = 0.8437708874145005, disc_loss = 0.04750319079223775
Trained batch 349 in epoch 2, gen_loss = 0.8442585401875632, disc_loss = 0.047392120517657274
Trained batch 350 in epoch 2, gen_loss = 0.8439413983258087, disc_loss = 0.047348625052513346
Trained batch 351 in epoch 2, gen_loss = 0.844408385286277, disc_loss = 0.047478334498671095
Trained batch 352 in epoch 2, gen_loss = 0.8435255471437578, disc_loss = 0.047772156435431694
Trained batch 353 in epoch 2, gen_loss = 0.8429890830638045, disc_loss = 0.04799460816147111
Trained batch 354 in epoch 2, gen_loss = 0.8429453737299207, disc_loss = 0.04792153045312095
Trained batch 355 in epoch 2, gen_loss = 0.8429540988434566, disc_loss = 0.04812556778517646
Trained batch 356 in epoch 2, gen_loss = 0.8426452915207678, disc_loss = 0.04813638472660896
Trained batch 357 in epoch 2, gen_loss = 0.8422031217780193, disc_loss = 0.04806705364143195
Trained batch 358 in epoch 2, gen_loss = 0.8416622003805007, disc_loss = 0.04800212192011888
Trained batch 359 in epoch 2, gen_loss = 0.8418656365738975, disc_loss = 0.04788806303598297
Trained batch 360 in epoch 2, gen_loss = 0.8424173005730161, disc_loss = 0.047793851408803024
Trained batch 361 in epoch 2, gen_loss = 0.8422625132357877, disc_loss = 0.047752711316699274
Trained batch 362 in epoch 2, gen_loss = 0.842246048542422, disc_loss = 0.047819807932432484
Trained batch 363 in epoch 2, gen_loss = 0.8417670034117751, disc_loss = 0.047828495289470266
Trained batch 364 in epoch 2, gen_loss = 0.8416748695177575, disc_loss = 0.04775465535676132
Trained batch 365 in epoch 2, gen_loss = 0.8414693951932459, disc_loss = 0.04765364600159737
Trained batch 366 in epoch 2, gen_loss = 0.8415858674114342, disc_loss = 0.047862539328609364
Trained batch 367 in epoch 2, gen_loss = 0.8408266200643518, disc_loss = 0.048354662339197996
Trained batch 368 in epoch 2, gen_loss = 0.8400301660302532, disc_loss = 0.048454680408762524
Trained batch 369 in epoch 2, gen_loss = 0.8402431670072916, disc_loss = 0.049023825405291405
Trained batch 370 in epoch 2, gen_loss = 0.8403379041550937, disc_loss = 0.049193855557676074
Trained batch 371 in epoch 2, gen_loss = 0.839606128392681, disc_loss = 0.04942577095108948
Trained batch 372 in epoch 2, gen_loss = 0.8393379112670633, disc_loss = 0.04946002011791611
Trained batch 373 in epoch 2, gen_loss = 0.8394570846289875, disc_loss = 0.04936902600223508
Trained batch 374 in epoch 2, gen_loss = 0.8391856954892476, disc_loss = 0.04931582783845564
Trained batch 375 in epoch 2, gen_loss = 0.8388706618484031, disc_loss = 0.0493951642686412
Trained batch 376 in epoch 2, gen_loss = 0.8388392930005526, disc_loss = 0.049437072248487125
Trained batch 377 in epoch 2, gen_loss = 0.8390960483639328, disc_loss = 0.049329365551269676
Trained batch 378 in epoch 2, gen_loss = 0.8385262943823922, disc_loss = 0.049382324152967665
Trained batch 379 in epoch 2, gen_loss = 0.8385233601457194, disc_loss = 0.049315490977421994
Trained batch 380 in epoch 2, gen_loss = 0.8387511954532834, disc_loss = 0.0492738366067126
Trained batch 381 in epoch 2, gen_loss = 0.8388736302627943, disc_loss = 0.04920149336298391
Trained batch 382 in epoch 2, gen_loss = 0.8381060707351247, disc_loss = 0.049278110646893206
Trained batch 383 in epoch 2, gen_loss = 0.8384253460293015, disc_loss = 0.04925034979229773
Trained batch 384 in epoch 2, gen_loss = 0.83771240324169, disc_loss = 0.04942598505635056
Trained batch 385 in epoch 2, gen_loss = 0.8380072780841373, disc_loss = 0.04956950079541113
Trained batch 386 in epoch 2, gen_loss = 0.8372368070198276, disc_loss = 0.049724247549042026
Trained batch 387 in epoch 2, gen_loss = 0.8373828293736448, disc_loss = 0.050104033991036766
Trained batch 388 in epoch 2, gen_loss = 0.8371959953810685, disc_loss = 0.050058852461619174
Trained batch 389 in epoch 2, gen_loss = 0.8365416714778313, disc_loss = 0.05024581929035962
Trained batch 390 in epoch 2, gen_loss = 0.8359073365435881, disc_loss = 0.05019873143602496
Trained batch 391 in epoch 2, gen_loss = 0.8362894236129157, disc_loss = 0.05014528074879104
Trained batch 392 in epoch 2, gen_loss = 0.8361867725394154, disc_loss = 0.05015962046888626
Trained batch 393 in epoch 2, gen_loss = 0.8356172412180053, disc_loss = 0.050155941143438104
Trained batch 394 in epoch 2, gen_loss = 0.8355748212790187, disc_loss = 0.050129247269935055
Trained batch 395 in epoch 2, gen_loss = 0.8352169906250154, disc_loss = 0.05017132143845142
Trained batch 396 in epoch 2, gen_loss = 0.8353470967758813, disc_loss = 0.05015227544093293
Trained batch 397 in epoch 2, gen_loss = 0.8352926117391443, disc_loss = 0.05006233516825485
Trained batch 398 in epoch 2, gen_loss = 0.8351660326011199, disc_loss = 0.04999140543772146
Trained batch 399 in epoch 2, gen_loss = 0.8350539343059062, disc_loss = 0.04993575177795719
Trained batch 400 in epoch 2, gen_loss = 0.8347606098562702, disc_loss = 0.050041569472915326
Trained batch 401 in epoch 2, gen_loss = 0.8348448814740822, disc_loss = 0.049946370953346475
Trained batch 402 in epoch 2, gen_loss = 0.8346359743078057, disc_loss = 0.04987592120405296
Trained batch 403 in epoch 2, gen_loss = 0.8349750046387757, disc_loss = 0.049872602904930084
Trained batch 404 in epoch 2, gen_loss = 0.8354036058908627, disc_loss = 0.04977454469240282
Trained batch 405 in epoch 2, gen_loss = 0.8346164164872005, disc_loss = 0.05007169872529236
Trained batch 406 in epoch 2, gen_loss = 0.8343579073502918, disc_loss = 0.050904102529071876
Trained batch 407 in epoch 2, gen_loss = 0.8337632017392739, disc_loss = 0.050986283145475146
Trained batch 408 in epoch 2, gen_loss = 0.8334106090307819, disc_loss = 0.05104508533024099
Trained batch 409 in epoch 2, gen_loss = 0.8336011238214446, disc_loss = 0.051123891277352305
Trained batch 410 in epoch 2, gen_loss = 0.8340465007327189, disc_loss = 0.051202352733720646
Trained batch 411 in epoch 2, gen_loss = 0.8337312308908666, disc_loss = 0.05133227739670739
Trained batch 412 in epoch 2, gen_loss = 0.8333333929860852, disc_loss = 0.051565369773209635
Trained batch 413 in epoch 2, gen_loss = 0.8336329203872865, disc_loss = 0.051638340547676354
Trained batch 414 in epoch 2, gen_loss = 0.8329498957438641, disc_loss = 0.05178340175862323
Trained batch 415 in epoch 2, gen_loss = 0.8330093984707043, disc_loss = 0.05172496021427483
Trained batch 416 in epoch 2, gen_loss = 0.8332233446107494, disc_loss = 0.05181495249617568
Trained batch 417 in epoch 2, gen_loss = 0.8336039616160416, disc_loss = 0.051865667097479924
Trained batch 418 in epoch 2, gen_loss = 0.8332346982204829, disc_loss = 0.05189404209135522
Trained batch 419 in epoch 2, gen_loss = 0.8327791374354135, disc_loss = 0.05194689064852095
Trained batch 420 in epoch 2, gen_loss = 0.8329385492127751, disc_loss = 0.051942148625810855
Trained batch 421 in epoch 2, gen_loss = 0.8327530886607147, disc_loss = 0.05227035579053129
Trained batch 422 in epoch 2, gen_loss = 0.8324607581111556, disc_loss = 0.052210090388532894
Trained batch 423 in epoch 2, gen_loss = 0.8320860809312677, disc_loss = 0.05225837971512141
Trained batch 424 in epoch 2, gen_loss = 0.8320299560883466, disc_loss = 0.052323126382577946
Trained batch 425 in epoch 2, gen_loss = 0.8315030571440576, disc_loss = 0.05242943878453925
Trained batch 426 in epoch 2, gen_loss = 0.8314542722925369, disc_loss = 0.05240656224524371
Trained batch 427 in epoch 2, gen_loss = 0.8319567305462383, disc_loss = 0.05248228998617574
Trained batch 428 in epoch 2, gen_loss = 0.8315655602997555, disc_loss = 0.05255075144833323
Trained batch 429 in epoch 2, gen_loss = 0.8310799964638643, disc_loss = 0.052688179825172696
Trained batch 430 in epoch 2, gen_loss = 0.8316454088051745, disc_loss = 0.05275925798741388
Trained batch 431 in epoch 2, gen_loss = 0.8313933139046034, disc_loss = 0.052767668196961666
Trained batch 432 in epoch 2, gen_loss = 0.8308582227444814, disc_loss = 0.05286556226093812
Trained batch 433 in epoch 2, gen_loss = 0.8309747560233015, disc_loss = 0.053013647483202544
Trained batch 434 in epoch 2, gen_loss = 0.8308950848963069, disc_loss = 0.05298673809591638
Trained batch 435 in epoch 2, gen_loss = 0.8308970818825818, disc_loss = 0.053017824334455566
Trained batch 436 in epoch 2, gen_loss = 0.8305709105607301, disc_loss = 0.05307514828446511
Trained batch 437 in epoch 2, gen_loss = 0.8302585301606078, disc_loss = 0.0530596367146216
Trained batch 438 in epoch 2, gen_loss = 0.8304480057642509, disc_loss = 0.053087112998191036
Trained batch 439 in epoch 2, gen_loss = 0.8301723994991996, disc_loss = 0.05313749928186139
Trained batch 440 in epoch 2, gen_loss = 0.8307320306630902, disc_loss = 0.05336791288916469
Trained batch 441 in epoch 2, gen_loss = 0.8302096365803507, disc_loss = 0.0535393659867203
Trained batch 442 in epoch 2, gen_loss = 0.8306725972393028, disc_loss = 0.05368224501296558
Trained batch 443 in epoch 2, gen_loss = 0.8303586815123085, disc_loss = 0.05368030804727512
Trained batch 444 in epoch 2, gen_loss = 0.8296904095103231, disc_loss = 0.05382096906548387
Trained batch 445 in epoch 2, gen_loss = 0.8300654551373469, disc_loss = 0.05394993862920261
Trained batch 446 in epoch 2, gen_loss = 0.829584938967788, disc_loss = 0.05399917742972923
Trained batch 447 in epoch 2, gen_loss = 0.8290091630603585, disc_loss = 0.05420751484000773
Trained batch 448 in epoch 2, gen_loss = 0.8290626660221669, disc_loss = 0.05429824994397837
Trained batch 449 in epoch 2, gen_loss = 0.8292272786299387, disc_loss = 0.05424620965443965
Trained batch 450 in epoch 2, gen_loss = 0.8294217342019345, disc_loss = 0.05419762261746711
Trained batch 451 in epoch 2, gen_loss = 0.8289265962301102, disc_loss = 0.05435575430427752
Trained batch 452 in epoch 2, gen_loss = 0.8288724332982078, disc_loss = 0.054364765167265114
Trained batch 453 in epoch 2, gen_loss = 0.8285726442736151, disc_loss = 0.05429854385692232
Trained batch 454 in epoch 2, gen_loss = 0.8286068415903783, disc_loss = 0.05425866782245646
Trained batch 455 in epoch 2, gen_loss = 0.8284753061700285, disc_loss = 0.05422610386525967
Trained batch 456 in epoch 2, gen_loss = 0.8289036482116064, disc_loss = 0.05426320274405312
Trained batch 457 in epoch 2, gen_loss = 0.8287290708206626, disc_loss = 0.05424493310238971
Trained batch 458 in epoch 2, gen_loss = 0.8284111534588218, disc_loss = 0.054536911264804554
Trained batch 459 in epoch 2, gen_loss = 0.8285539939351704, disc_loss = 0.05444722281637318
Trained batch 460 in epoch 2, gen_loss = 0.8281389077935457, disc_loss = 0.0544614652308096
Trained batch 461 in epoch 2, gen_loss = 0.8281635725911045, disc_loss = 0.054601045760318025
Trained batch 462 in epoch 2, gen_loss = 0.8279885999842287, disc_loss = 0.05453987299669816
Trained batch 463 in epoch 2, gen_loss = 0.8275005051801945, disc_loss = 0.05458401916659004
Trained batch 464 in epoch 2, gen_loss = 0.827616859251453, disc_loss = 0.054615112970412896
Trained batch 465 in epoch 2, gen_loss = 0.8272587342323663, disc_loss = 0.05459495513877819
Trained batch 466 in epoch 2, gen_loss = 0.827059020194558, disc_loss = 0.05473282488064972
Trained batch 467 in epoch 2, gen_loss = 0.8269904990736235, disc_loss = 0.05465195688536454
Trained batch 468 in epoch 2, gen_loss = 0.8270843050627312, disc_loss = 0.05469423285407473
Trained batch 469 in epoch 2, gen_loss = 0.8273576690795573, disc_loss = 0.05459922624583495
Trained batch 470 in epoch 2, gen_loss = 0.8272861300506916, disc_loss = 0.054541507490165134
Trained batch 471 in epoch 2, gen_loss = 0.8268178340237019, disc_loss = 0.054555419630714364
Trained batch 472 in epoch 2, gen_loss = 0.8270112134941536, disc_loss = 0.054630748773521365
Trained batch 473 in epoch 2, gen_loss = 0.8267802000045776, disc_loss = 0.054558469602967834
Trained batch 474 in epoch 2, gen_loss = 0.8261842288469013, disc_loss = 0.054794833236128875
Trained batch 475 in epoch 2, gen_loss = 0.8266103690912744, disc_loss = 0.05505345998079508
Trained batch 476 in epoch 2, gen_loss = 0.8265580478704201, disc_loss = 0.055161925824944794
Trained batch 477 in epoch 2, gen_loss = 0.826444704662307, disc_loss = 0.055204966779170896
Trained batch 478 in epoch 2, gen_loss = 0.8257425294912931, disc_loss = 0.055589448387923186
Trained batch 479 in epoch 2, gen_loss = 0.8256576023374994, disc_loss = 0.05565123194780123
Trained batch 480 in epoch 2, gen_loss = 0.8257605664571457, disc_loss = 0.055716974013572146
Trained batch 481 in epoch 2, gen_loss = 0.8259589443933915, disc_loss = 0.05566133703230745
Trained batch 482 in epoch 2, gen_loss = 0.8261166526540713, disc_loss = 0.05561645716905023
Trained batch 483 in epoch 2, gen_loss = 0.8255763052046792, disc_loss = 0.055708626831192834
Trained batch 484 in epoch 2, gen_loss = 0.8255527141782426, disc_loss = 0.05570277145334049
Trained batch 485 in epoch 2, gen_loss = 0.8260226258893072, disc_loss = 0.05567057402335
Trained batch 486 in epoch 2, gen_loss = 0.8260318211583876, disc_loss = 0.05562600888095765
Trained batch 487 in epoch 2, gen_loss = 0.8256743393349842, disc_loss = 0.055592878415825636
Trained batch 488 in epoch 2, gen_loss = 0.8266584482539163, disc_loss = 0.05581649843791923
Trained batch 489 in epoch 2, gen_loss = 0.8261114467771686, disc_loss = 0.05589622731976287
Trained batch 490 in epoch 2, gen_loss = 0.8258602421905261, disc_loss = 0.05601752163935263
Trained batch 491 in epoch 2, gen_loss = 0.8254084255758339, disc_loss = 0.056018447699839234
Trained batch 492 in epoch 2, gen_loss = 0.825441175191446, disc_loss = 0.05613576728070408
Trained batch 493 in epoch 2, gen_loss = 0.8249671211247502, disc_loss = 0.056400581168271
Trained batch 494 in epoch 2, gen_loss = 0.8247050435254069, disc_loss = 0.05640612717934254
Trained batch 495 in epoch 2, gen_loss = 0.8251295349891147, disc_loss = 0.05643582152486253
Trained batch 496 in epoch 2, gen_loss = 0.8253034410222435, disc_loss = 0.056349842690617234
Trained batch 497 in epoch 2, gen_loss = 0.8254674521675072, disc_loss = 0.056283334149964094
Trained batch 498 in epoch 2, gen_loss = 0.825179239970171, disc_loss = 0.056279479732684684
Trained batch 499 in epoch 2, gen_loss = 0.8250049630999565, disc_loss = 0.05627016084594652
Trained batch 500 in epoch 2, gen_loss = 0.824943811653141, disc_loss = 0.056420871649149384
Trained batch 501 in epoch 2, gen_loss = 0.8242758680506056, disc_loss = 0.05661695719876538
Trained batch 502 in epoch 2, gen_loss = 0.8241634595820728, disc_loss = 0.056705244544201026
Trained batch 503 in epoch 2, gen_loss = 0.824085738864683, disc_loss = 0.056971835526397514
Trained batch 504 in epoch 2, gen_loss = 0.8239961486641724, disc_loss = 0.05693480647537894
Trained batch 505 in epoch 2, gen_loss = 0.8233942150951845, disc_loss = 0.057172133259221235
Trained batch 506 in epoch 2, gen_loss = 0.8237227309032304, disc_loss = 0.05772702061549138
Trained batch 507 in epoch 2, gen_loss = 0.823429265066864, disc_loss = 0.05774551181912818
Trained batch 508 in epoch 2, gen_loss = 0.8229211684177339, disc_loss = 0.05789417863461191
Trained batch 509 in epoch 2, gen_loss = 0.8231388126518212, disc_loss = 0.0579850202896541
Trained batch 510 in epoch 2, gen_loss = 0.8228523348058973, disc_loss = 0.05811896158333088
Trained batch 511 in epoch 2, gen_loss = 0.8229323299019597, disc_loss = 0.058072134786471
Trained batch 512 in epoch 2, gen_loss = 0.8230111659967412, disc_loss = 0.05801406477262097
Trained batch 513 in epoch 2, gen_loss = 0.8227040109583376, disc_loss = 0.05794539752258676
Trained batch 514 in epoch 2, gen_loss = 0.8224519109841689, disc_loss = 0.057934595430631515
Trained batch 515 in epoch 2, gen_loss = 0.822513967925726, disc_loss = 0.05789636343658014
Trained batch 516 in epoch 2, gen_loss = 0.8224542825203569, disc_loss = 0.05786284337016597
Trained batch 517 in epoch 2, gen_loss = 0.8225379383126741, disc_loss = 0.057795164394228354
Trained batch 518 in epoch 2, gen_loss = 0.8223142307502915, disc_loss = 0.057874100960643965
Trained batch 519 in epoch 2, gen_loss = 0.8226289031024162, disc_loss = 0.05780418835750494
Trained batch 520 in epoch 2, gen_loss = 0.8223726300383255, disc_loss = 0.057761107494110765
Trained batch 521 in epoch 2, gen_loss = 0.8222182598036368, disc_loss = 0.05767861981671018
Trained batch 522 in epoch 2, gen_loss = 0.8226491269258422, disc_loss = 0.057720057277657076
Trained batch 523 in epoch 2, gen_loss = 0.8226457567501614, disc_loss = 0.05767049607314269
Trained batch 524 in epoch 2, gen_loss = 0.8226580549989427, disc_loss = 0.057616158670169254
Trained batch 525 in epoch 2, gen_loss = 0.8229015742078027, disc_loss = 0.05759518132093557
Trained batch 526 in epoch 2, gen_loss = 0.8233874559515567, disc_loss = 0.057865919834674394
Trained batch 527 in epoch 2, gen_loss = 0.8228555747844053, disc_loss = 0.05818747994657535
Trained batch 528 in epoch 2, gen_loss = 0.8223732552704153, disc_loss = 0.05829187642055826
Trained batch 529 in epoch 2, gen_loss = 0.822044097758689, disc_loss = 0.058397408395144595
Trained batch 530 in epoch 2, gen_loss = 0.822028625090019, disc_loss = 0.058730398506020846
Trained batch 531 in epoch 2, gen_loss = 0.821513309346554, disc_loss = 0.05902080403429043
Trained batch 532 in epoch 2, gen_loss = 0.8211656156333258, disc_loss = 0.05910576535013153
Trained batch 533 in epoch 2, gen_loss = 0.8212805047128977, disc_loss = 0.05936097854893124
Trained batch 534 in epoch 2, gen_loss = 0.8213747052945823, disc_loss = 0.05931490671159438
Trained batch 535 in epoch 2, gen_loss = 0.8211669608839413, disc_loss = 0.05934242513890851
Trained batch 536 in epoch 2, gen_loss = 0.8206652876274102, disc_loss = 0.0594990692605235
Trained batch 537 in epoch 2, gen_loss = 0.8203858734839025, disc_loss = 0.05946128288773841
Trained batch 538 in epoch 2, gen_loss = 0.8205615991453514, disc_loss = 0.05947111397316413
Trained batch 539 in epoch 2, gen_loss = 0.8200678630559533, disc_loss = 0.059509572369063755
Trained batch 540 in epoch 2, gen_loss = 0.8199858321169609, disc_loss = 0.059442479855014274
Trained batch 541 in epoch 2, gen_loss = 0.8199059419416413, disc_loss = 0.05944837776495563
Trained batch 542 in epoch 2, gen_loss = 0.819767576060901, disc_loss = 0.05955213836212445
Trained batch 543 in epoch 2, gen_loss = 0.8195069857927806, disc_loss = 0.05959273675783633
Trained batch 544 in epoch 2, gen_loss = 0.8191966066119868, disc_loss = 0.05959229464813588
Trained batch 545 in epoch 2, gen_loss = 0.8190594876096362, disc_loss = 0.05955315653137494
Trained batch 546 in epoch 2, gen_loss = 0.8194878305660959, disc_loss = 0.05960826253240938
Trained batch 547 in epoch 2, gen_loss = 0.8194095671285678, disc_loss = 0.05955344615597618
Trained batch 548 in epoch 2, gen_loss = 0.8190254949589679, disc_loss = 0.059575620125589014
Trained batch 549 in epoch 2, gen_loss = 0.819094171794978, disc_loss = 0.05972438022790646
Trained batch 550 in epoch 2, gen_loss = 0.8191986974808785, disc_loss = 0.05964035174501772
Trained batch 551 in epoch 2, gen_loss = 0.8188669510401677, disc_loss = 0.05966276505521661
Trained batch 552 in epoch 2, gen_loss = 0.8194680250035918, disc_loss = 0.06046932475063714
Trained batch 553 in epoch 2, gen_loss = 0.8192467099385141, disc_loss = 0.06042541961046104
Trained batch 554 in epoch 2, gen_loss = 0.818800998109955, disc_loss = 0.060670247561138896
Trained batch 555 in epoch 2, gen_loss = 0.8185484273720989, disc_loss = 0.06067832687445883
Trained batch 556 in epoch 2, gen_loss = 0.8186977832599859, disc_loss = 0.060843142075129725
Trained batch 557 in epoch 2, gen_loss = 0.8184590333785635, disc_loss = 0.060980057358444674
Trained batch 558 in epoch 2, gen_loss = 0.8181407985299133, disc_loss = 0.06106856748693305
Trained batch 559 in epoch 2, gen_loss = 0.8177700973515, disc_loss = 0.06105717776601003
Trained batch 560 in epoch 2, gen_loss = 0.8183773048952514, disc_loss = 0.06122196817134778
Trained batch 561 in epoch 2, gen_loss = 0.8184112245183822, disc_loss = 0.06115703195046793
Trained batch 562 in epoch 2, gen_loss = 0.8185087165548789, disc_loss = 0.061142236336347765
Trained batch 563 in epoch 2, gen_loss = 0.8183858396208032, disc_loss = 0.06113231956673099
Trained batch 564 in epoch 2, gen_loss = 0.8182182854783219, disc_loss = 0.061114640676919206
Trained batch 565 in epoch 2, gen_loss = 0.8184387387424813, disc_loss = 0.06103056172927506
Trained batch 566 in epoch 2, gen_loss = 0.8187945732679317, disc_loss = 0.06098116869870672
Trained batch 567 in epoch 2, gen_loss = 0.8189805922898609, disc_loss = 0.0609142215964286
Trained batch 568 in epoch 2, gen_loss = 0.8190830196458552, disc_loss = 0.060833835353590354
Trained batch 569 in epoch 2, gen_loss = 0.8191170683555435, disc_loss = 0.06076160637098119
Trained batch 570 in epoch 2, gen_loss = 0.8192376371753612, disc_loss = 0.06068016398141907
Trained batch 571 in epoch 2, gen_loss = 0.8192763105034828, disc_loss = 0.06059987572228562
Trained batch 572 in epoch 2, gen_loss = 0.8196519408862628, disc_loss = 0.06076017469549665
Trained batch 573 in epoch 2, gen_loss = 0.8194031628685962, disc_loss = 0.060824743002727756
Trained batch 574 in epoch 2, gen_loss = 0.8195016349398572, disc_loss = 0.06076520867443279
Trained batch 575 in epoch 2, gen_loss = 0.8196709796061946, disc_loss = 0.06071319983513806
Trained batch 576 in epoch 2, gen_loss = 0.8199659022446109, disc_loss = 0.060652561225497406
Trained batch 577 in epoch 2, gen_loss = 0.8199534400214786, disc_loss = 0.060584617525284344
Trained batch 578 in epoch 2, gen_loss = 0.8198912393346763, disc_loss = 0.060517467231455936
Trained batch 579 in epoch 2, gen_loss = 0.820108826766754, disc_loss = 0.06043674067618197
Trained batch 580 in epoch 2, gen_loss = 0.8205276249095208, disc_loss = 0.06036930641667555
Trained batch 581 in epoch 2, gen_loss = 0.8209627290669176, disc_loss = 0.06030380934328033
Trained batch 582 in epoch 2, gen_loss = 0.8211346073890836, disc_loss = 0.060234901664209896
Trained batch 583 in epoch 2, gen_loss = 0.8212378029647756, disc_loss = 0.060161849835884365
Trained batch 584 in epoch 2, gen_loss = 0.8213465434363765, disc_loss = 0.060068141646348897
Trained batch 585 in epoch 2, gen_loss = 0.8214373411070365, disc_loss = 0.05997557527228312
Trained batch 586 in epoch 2, gen_loss = 0.821626883704577, disc_loss = 0.059933826934587486
Trained batch 587 in epoch 2, gen_loss = 0.8216478088173736, disc_loss = 0.05984716830247709
Trained batch 588 in epoch 2, gen_loss = 0.8215604489748264, disc_loss = 0.0597907423997592
Trained batch 589 in epoch 2, gen_loss = 0.821697065941358, disc_loss = 0.05970095978631496
Trained batch 590 in epoch 2, gen_loss = 0.8219385357375072, disc_loss = 0.05963513393596433
Trained batch 591 in epoch 2, gen_loss = 0.8220071776996594, disc_loss = 0.05955186579809084
Trained batch 592 in epoch 2, gen_loss = 0.8220939437715843, disc_loss = 0.05946014990792947
Trained batch 593 in epoch 2, gen_loss = 0.8222874487790998, disc_loss = 0.05937114886912872
Trained batch 594 in epoch 2, gen_loss = 0.8223881996479355, disc_loss = 0.059282746331515805
Trained batch 595 in epoch 2, gen_loss = 0.822355323639892, disc_loss = 0.05919272584751586
Trained batch 596 in epoch 2, gen_loss = 0.8224205468068371, disc_loss = 0.05919533231922767
Trained batch 597 in epoch 2, gen_loss = 0.8224280255793728, disc_loss = 0.059124300377459006
Trained batch 598 in epoch 2, gen_loss = 0.8225896197786315, disc_loss = 0.05903584729119799
Trained batch 599 in epoch 2, gen_loss = 0.8226527725160122, disc_loss = 0.05894911460462026
Trained batch 600 in epoch 2, gen_loss = 0.8228843651972277, disc_loss = 0.05899195239054792
Trained batch 601 in epoch 2, gen_loss = 0.8227155655622482, disc_loss = 0.05898426042326673
Trained batch 602 in epoch 2, gen_loss = 0.8229443136831224, disc_loss = 0.05890024264395595
Trained batch 603 in epoch 2, gen_loss = 0.8230477274944451, disc_loss = 0.05882194617320629
Trained batch 604 in epoch 2, gen_loss = 0.8231531974205301, disc_loss = 0.05873377399696114
Trained batch 605 in epoch 2, gen_loss = 0.8233344564245085, disc_loss = 0.05865078218467226
Trained batch 606 in epoch 2, gen_loss = 0.8233974608891879, disc_loss = 0.05856067569093254
Trained batch 607 in epoch 2, gen_loss = 0.823550804910299, disc_loss = 0.058473511266224944
Trained batch 608 in epoch 2, gen_loss = 0.8235898831697129, disc_loss = 0.05840843017151876
Trained batch 609 in epoch 2, gen_loss = 0.823778215734685, disc_loss = 0.05832382652366564
Trained batch 610 in epoch 2, gen_loss = 0.8238055342640698, disc_loss = 0.058247008218023005
Trained batch 611 in epoch 2, gen_loss = 0.8239642286709711, disc_loss = 0.05816773632640214
Trained batch 612 in epoch 2, gen_loss = 0.8242450034151653, disc_loss = 0.05808359109887741
Trained batch 613 in epoch 2, gen_loss = 0.8245345596284742, disc_loss = 0.05800411007966215
Trained batch 614 in epoch 2, gen_loss = 0.8247114838138828, disc_loss = 0.05792592746220771
Trained batch 615 in epoch 2, gen_loss = 0.8245734773189216, disc_loss = 0.05784813340113788
Trained batch 616 in epoch 2, gen_loss = 0.8246539567915702, disc_loss = 0.05776196914027646
Trained batch 617 in epoch 2, gen_loss = 0.8247326891688467, disc_loss = 0.057681379603556564
Trained batch 618 in epoch 2, gen_loss = 0.8249054798113125, disc_loss = 0.0575929497355845
Trained batch 619 in epoch 2, gen_loss = 0.8251831678132857, disc_loss = 0.057534172512485736
Trained batch 620 in epoch 2, gen_loss = 0.8251915794351826, disc_loss = 0.057459266331787676
Trained batch 621 in epoch 2, gen_loss = 0.8253134119644809, disc_loss = 0.05737827679664915
Trained batch 622 in epoch 2, gen_loss = 0.8255293272184522, disc_loss = 0.05729393153914802
Trained batch 623 in epoch 2, gen_loss = 0.825698653044991, disc_loss = 0.05721150108319051
Trained batch 624 in epoch 2, gen_loss = 0.8257952408313751, disc_loss = 0.057129440388455986
Trained batch 625 in epoch 2, gen_loss = 0.8258440411224152, disc_loss = 0.05705255845943972
Trained batch 626 in epoch 2, gen_loss = 0.8259152186829508, disc_loss = 0.056970547247110634
Trained batch 627 in epoch 2, gen_loss = 0.8264044078577096, disc_loss = 0.056906304699976804
Trained batch 628 in epoch 2, gen_loss = 0.8265579644655764, disc_loss = 0.05682858196457342
Trained batch 629 in epoch 2, gen_loss = 0.8268393347660701, disc_loss = 0.056745177275678585
Trained batch 630 in epoch 2, gen_loss = 0.8270173649496965, disc_loss = 0.05666239470023538
Trained batch 631 in epoch 2, gen_loss = 0.827179870886516, disc_loss = 0.056578516680894635
Trained batch 632 in epoch 2, gen_loss = 0.8273023971919953, disc_loss = 0.056493101772112184
Trained batch 633 in epoch 2, gen_loss = 0.8273968215714493, disc_loss = 0.05641656848991272
Trained batch 634 in epoch 2, gen_loss = 0.8274335634520673, disc_loss = 0.056333033005362305
Trained batch 635 in epoch 2, gen_loss = 0.8275059481742997, disc_loss = 0.056283153128977165
Trained batch 636 in epoch 2, gen_loss = 0.8275646835425211, disc_loss = 0.056205908029180844
Trained batch 637 in epoch 2, gen_loss = 0.8277338725926361, disc_loss = 0.05612509375544656
Trained batch 638 in epoch 2, gen_loss = 0.8279900188457239, disc_loss = 0.05604744205835781
Trained batch 639 in epoch 2, gen_loss = 0.8280255634803325, disc_loss = 0.05596636914669943
Trained batch 640 in epoch 2, gen_loss = 0.8281075168232463, disc_loss = 0.05588682806853048
Trained batch 641 in epoch 2, gen_loss = 0.8280810806145921, disc_loss = 0.05580305590147785
Trained batch 642 in epoch 2, gen_loss = 0.82815413336917, disc_loss = 0.05572271763497723
Trained batch 643 in epoch 2, gen_loss = 0.8282497830179908, disc_loss = 0.05564453816569196
Trained batch 644 in epoch 2, gen_loss = 0.8284111892068109, disc_loss = 0.055563693672288646
Trained batch 645 in epoch 2, gen_loss = 0.8285220155129123, disc_loss = 0.05548350700795731
Trained batch 646 in epoch 2, gen_loss = 0.828498299422183, disc_loss = 0.05540184272774186
Trained batch 647 in epoch 2, gen_loss = 0.8286137701828539, disc_loss = 0.05532100724514838
Trained batch 648 in epoch 2, gen_loss = 0.8287936657070195, disc_loss = 0.05524545788258395
Trained batch 649 in epoch 2, gen_loss = 0.8289979340938421, disc_loss = 0.055179070494710825
Trained batch 650 in epoch 2, gen_loss = 0.8290812458768602, disc_loss = 0.05510468085399455
Trained batch 651 in epoch 2, gen_loss = 0.8293213455315016, disc_loss = 0.05502591473107552
Trained batch 652 in epoch 2, gen_loss = 0.8295227826371857, disc_loss = 0.05495911406903638
Trained batch 653 in epoch 2, gen_loss = 0.8296456645479261, disc_loss = 0.054918241520506256
Trained batch 654 in epoch 2, gen_loss = 0.8295166538416884, disc_loss = 0.054883410060735605
Trained batch 655 in epoch 2, gen_loss = 0.8294936529837731, disc_loss = 0.054832463068944376
Trained batch 656 in epoch 2, gen_loss = 0.8297659442214298, disc_loss = 0.05476070888329133
Trained batch 657 in epoch 2, gen_loss = 0.8300355700464597, disc_loss = 0.054693594821205074
Trained batch 658 in epoch 2, gen_loss = 0.8302160208883705, disc_loss = 0.05461679845384134
Trained batch 659 in epoch 2, gen_loss = 0.8302104235146985, disc_loss = 0.05453993644085572
Trained batch 660 in epoch 2, gen_loss = 0.8304064900990513, disc_loss = 0.0544873058370423
Trained batch 661 in epoch 2, gen_loss = 0.8303548112466617, disc_loss = 0.05441111281058354
Trained batch 662 in epoch 2, gen_loss = 0.8303530255324161, disc_loss = 0.054341957581315194
Trained batch 663 in epoch 2, gen_loss = 0.8305183179137936, disc_loss = 0.054264795478343605
Trained batch 664 in epoch 2, gen_loss = 0.8306572357962902, disc_loss = 0.05418787751682943
Trained batch 665 in epoch 2, gen_loss = 0.8308622953859536, disc_loss = 0.05411012468904301
Trained batch 666 in epoch 2, gen_loss = 0.8309798766558675, disc_loss = 0.05403607000207258
Trained batch 667 in epoch 2, gen_loss = 0.8311013623536704, disc_loss = 0.05395914505035087
Trained batch 668 in epoch 2, gen_loss = 0.8311771078227347, disc_loss = 0.05388206145649578
Trained batch 669 in epoch 2, gen_loss = 0.8312946129645874, disc_loss = 0.05380831475077725
Trained batch 670 in epoch 2, gen_loss = 0.831418455935093, disc_loss = 0.05373300508916622
Trained batch 671 in epoch 2, gen_loss = 0.8315565938662205, disc_loss = 0.05365651455178436
Trained batch 672 in epoch 2, gen_loss = 0.8315509205675763, disc_loss = 0.05358104729218156
Trained batch 673 in epoch 2, gen_loss = 0.8316553313318276, disc_loss = 0.053509033598400965
Trained batch 674 in epoch 2, gen_loss = 0.8316764727786735, disc_loss = 0.05343430570602693
Trained batch 675 in epoch 2, gen_loss = 0.8319007503474958, disc_loss = 0.05336288950776615
Trained batch 676 in epoch 2, gen_loss = 0.8321008600811839, disc_loss = 0.05329100399531226
Trained batch 677 in epoch 2, gen_loss = 0.8321290965189273, disc_loss = 0.053217697863887366
Trained batch 678 in epoch 2, gen_loss = 0.8322661896956336, disc_loss = 0.05314365938643271
Trained batch 679 in epoch 2, gen_loss = 0.8323945883004105, disc_loss = 0.053077449311967936
Trained batch 680 in epoch 2, gen_loss = 0.8324564100624706, disc_loss = 0.053003155689607215
Trained batch 681 in epoch 2, gen_loss = 0.8325331772614784, disc_loss = 0.05293055794296016
Trained batch 682 in epoch 2, gen_loss = 0.8321222279378995, disc_loss = 0.05312519811883318
Trained batch 683 in epoch 2, gen_loss = 0.8324768786803324, disc_loss = 0.05316571290135024
Trained batch 684 in epoch 2, gen_loss = 0.8322791090411862, disc_loss = 0.053182195486963124
Trained batch 685 in epoch 2, gen_loss = 0.8321165515886452, disc_loss = 0.053164958194612304
Trained batch 686 in epoch 2, gen_loss = 0.8322268421212659, disc_loss = 0.0531123860964885
Trained batch 687 in epoch 2, gen_loss = 0.8321094423272583, disc_loss = 0.053162972173087714
Trained batch 688 in epoch 2, gen_loss = 0.831757551743088, disc_loss = 0.05317569743126836
Trained batch 689 in epoch 2, gen_loss = 0.831716329075288, disc_loss = 0.05316340684236122
Trained batch 690 in epoch 2, gen_loss = 0.8314014897073919, disc_loss = 0.05361265675757786
Trained batch 691 in epoch 2, gen_loss = 0.8310133848834589, disc_loss = 0.05370501293820959
Trained batch 692 in epoch 2, gen_loss = 0.8312504011573214, disc_loss = 0.05402721628690512
Trained batch 693 in epoch 2, gen_loss = 0.8311849158761824, disc_loss = 0.0540201104865396
Trained batch 694 in epoch 2, gen_loss = 0.830983487779288, disc_loss = 0.05401592976748675
Trained batch 695 in epoch 2, gen_loss = 0.8312329079142247, disc_loss = 0.05397256622833585
Trained batch 696 in epoch 2, gen_loss = 0.831099560347999, disc_loss = 0.053953396598374205
Trained batch 697 in epoch 2, gen_loss = 0.8309695695481533, disc_loss = 0.053973126074067054
Trained batch 698 in epoch 2, gen_loss = 0.8308884705681999, disc_loss = 0.05393320668284889
Trained batch 699 in epoch 2, gen_loss = 0.8307880422472954, disc_loss = 0.053982534545274186
Trained batch 700 in epoch 2, gen_loss = 0.8305978494857075, disc_loss = 0.05400171609012179
Trained batch 701 in epoch 2, gen_loss = 0.8302442837729413, disc_loss = 0.05406845245142852
Trained batch 702 in epoch 2, gen_loss = 0.8304184606963846, disc_loss = 0.05434463374352461
Trained batch 703 in epoch 2, gen_loss = 0.8299433932724324, disc_loss = 0.054409286566541676
Trained batch 704 in epoch 2, gen_loss = 0.8298197242385107, disc_loss = 0.054434260756028356
Trained batch 705 in epoch 2, gen_loss = 0.8297697032139592, disc_loss = 0.054487891567451485
Trained batch 706 in epoch 2, gen_loss = 0.8297937740868186, disc_loss = 0.05446336194813578
Trained batch 707 in epoch 2, gen_loss = 0.8293219824968758, disc_loss = 0.05459361071770716
Trained batch 708 in epoch 2, gen_loss = 0.8290147515715262, disc_loss = 0.054645661762173385
Trained batch 709 in epoch 2, gen_loss = 0.8291055378779559, disc_loss = 0.05461694120567187
Trained batch 710 in epoch 2, gen_loss = 0.8291669969987936, disc_loss = 0.054605658755227715
Trained batch 711 in epoch 2, gen_loss = 0.8288220527131905, disc_loss = 0.054616365852187584
Trained batch 712 in epoch 2, gen_loss = 0.8290994286035589, disc_loss = 0.05458866247187563
Trained batch 713 in epoch 2, gen_loss = 0.8287132871585066, disc_loss = 0.05463366695002755
Trained batch 714 in epoch 2, gen_loss = 0.8285641410967687, disc_loss = 0.05483834431246184
Trained batch 715 in epoch 2, gen_loss = 0.8282296565990874, disc_loss = 0.05484412810680659
Trained batch 716 in epoch 2, gen_loss = 0.8283535744189551, disc_loss = 0.05481002959708529
Trained batch 717 in epoch 2, gen_loss = 0.8280603928818344, disc_loss = 0.0548271191261662
Trained batch 718 in epoch 2, gen_loss = 0.8279685628430734, disc_loss = 0.054810068214840676
Trained batch 719 in epoch 2, gen_loss = 0.8281603661676248, disc_loss = 0.0550732974878176
Trained batch 720 in epoch 2, gen_loss = 0.8278977451807252, disc_loss = 0.05509042384228236
Trained batch 721 in epoch 2, gen_loss = 0.8274945550678179, disc_loss = 0.05528452674441628
Trained batch 722 in epoch 2, gen_loss = 0.8273441429619638, disc_loss = 0.05528531537679788
Trained batch 723 in epoch 2, gen_loss = 0.827503657143419, disc_loss = 0.055324627177529964
Trained batch 724 in epoch 2, gen_loss = 0.8273204265791795, disc_loss = 0.05529447865222806
Trained batch 725 in epoch 2, gen_loss = 0.8273373635347224, disc_loss = 0.05527609380278942
Trained batch 726 in epoch 2, gen_loss = 0.8271776155723666, disc_loss = 0.0552850552758348
Trained batch 727 in epoch 2, gen_loss = 0.8271626650795831, disc_loss = 0.05522575163746836
Trained batch 728 in epoch 2, gen_loss = 0.8271860367476694, disc_loss = 0.055178351412541314
Trained batch 729 in epoch 2, gen_loss = 0.8270428579147547, disc_loss = 0.05515395481847482
Trained batch 730 in epoch 2, gen_loss = 0.827028000240613, disc_loss = 0.0551667519244359
Trained batch 731 in epoch 2, gen_loss = 0.8271902644894814, disc_loss = 0.05516800152416509
Trained batch 732 in epoch 2, gen_loss = 0.8266532365004005, disc_loss = 0.05550851940563632
Trained batch 733 in epoch 2, gen_loss = 0.8269905814195524, disc_loss = 0.055628495421247905
Trained batch 734 in epoch 2, gen_loss = 0.8268183900385487, disc_loss = 0.0556311258080029
Trained batch 735 in epoch 2, gen_loss = 0.8266966035994499, disc_loss = 0.05584337435119897
Trained batch 736 in epoch 2, gen_loss = 0.8263916253558331, disc_loss = 0.055873487982203936
Trained batch 737 in epoch 2, gen_loss = 0.8263008663163276, disc_loss = 0.055879706898918705
Trained batch 738 in epoch 2, gen_loss = 0.8261817681611956, disc_loss = 0.05583167795554378
Trained batch 739 in epoch 2, gen_loss = 0.8262383296683028, disc_loss = 0.055842449854291674
Trained batch 740 in epoch 2, gen_loss = 0.826164460777432, disc_loss = 0.05580096721602667
Trained batch 741 in epoch 2, gen_loss = 0.8261717572366453, disc_loss = 0.05578465776918381
Trained batch 742 in epoch 2, gen_loss = 0.8260220965498389, disc_loss = 0.055734103383536515
Trained batch 743 in epoch 2, gen_loss = 0.8260705803510964, disc_loss = 0.055684063354224184
Trained batch 744 in epoch 2, gen_loss = 0.8261925488510388, disc_loss = 0.05565230445467536
Trained batch 745 in epoch 2, gen_loss = 0.8261166345977272, disc_loss = 0.05561176172973233
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.7925102710723877, disc_loss = 0.03718563914299011
Trained batch 1 in epoch 3, gen_loss = 0.8092564344406128, disc_loss = 0.04856269806623459
Trained batch 2 in epoch 3, gen_loss = 0.8621886372566223, disc_loss = 0.040635855247577034
Trained batch 3 in epoch 3, gen_loss = 0.8137702196836472, disc_loss = 0.053977672941982746
Trained batch 4 in epoch 3, gen_loss = 0.804775059223175, disc_loss = 0.04675442688167095
Trained batch 5 in epoch 3, gen_loss = 0.7909052670001984, disc_loss = 0.04508744521687428
Trained batch 6 in epoch 3, gen_loss = 0.8096329314368111, disc_loss = 0.042581251955458095
Trained batch 7 in epoch 3, gen_loss = 0.8232520967721939, disc_loss = 0.04014027095399797
Trained batch 8 in epoch 3, gen_loss = 0.8367193407482572, disc_loss = 0.04282215382489893
Trained batch 9 in epoch 3, gen_loss = 0.7995492994785309, disc_loss = 0.073425985686481
Trained batch 10 in epoch 3, gen_loss = 0.8081850463693793, disc_loss = 0.07275348681617867
Trained batch 11 in epoch 3, gen_loss = 0.8138513018687566, disc_loss = 0.07131054423128565
Trained batch 12 in epoch 3, gen_loss = 0.7927471903654245, disc_loss = 0.07197035433581242
Trained batch 13 in epoch 3, gen_loss = 0.808989154441016, disc_loss = 0.08161188489092248
Trained batch 14 in epoch 3, gen_loss = 0.7947043617566426, disc_loss = 0.08587646918992202
Trained batch 15 in epoch 3, gen_loss = 0.8020376600325108, disc_loss = 0.08356548787560314
Trained batch 16 in epoch 3, gen_loss = 0.7973664928885067, disc_loss = 0.08025982208988246
Trained batch 17 in epoch 3, gen_loss = 0.800926407178243, disc_loss = 0.07665196723408169
Trained batch 18 in epoch 3, gen_loss = 0.7983384069643522, disc_loss = 0.07360932819153133
Trained batch 19 in epoch 3, gen_loss = 0.8011088818311691, disc_loss = 0.08146132938563824
Trained batch 20 in epoch 3, gen_loss = 0.7959072958855402, disc_loss = 0.08772592069137664
Trained batch 21 in epoch 3, gen_loss = 0.7851807447997007, disc_loss = 0.090725011784922
Trained batch 22 in epoch 3, gen_loss = 0.7845707224762958, disc_loss = 0.09240697874971059
Trained batch 23 in epoch 3, gen_loss = 0.7797041063507398, disc_loss = 0.09111678771053751
Trained batch 24 in epoch 3, gen_loss = 0.769943962097168, disc_loss = 0.09087353155016899
Trained batch 25 in epoch 3, gen_loss = 0.7671836660458491, disc_loss = 0.092681099445774
Trained batch 26 in epoch 3, gen_loss = 0.770612272951338, disc_loss = 0.09058557740516132
Trained batch 27 in epoch 3, gen_loss = 0.76445714703628, disc_loss = 0.09424018021672964
Trained batch 28 in epoch 3, gen_loss = 0.7617796022316505, disc_loss = 0.09308114866244382
Trained batch 29 in epoch 3, gen_loss = 0.765534637371699, disc_loss = 0.09103097617626191
Trained batch 30 in epoch 3, gen_loss = 0.7640967638261856, disc_loss = 0.08988834316692045
Trained batch 31 in epoch 3, gen_loss = 0.7591351680457592, disc_loss = 0.09040272678248584
Trained batch 32 in epoch 3, gen_loss = 0.7659247806577971, disc_loss = 0.09251411281751865
Trained batch 33 in epoch 3, gen_loss = 0.7702545646358939, disc_loss = 0.09138355327441412
Trained batch 34 in epoch 3, gen_loss = 0.7610435145241874, disc_loss = 0.09253876177327973
Trained batch 35 in epoch 3, gen_loss = 0.7623108625411987, disc_loss = 0.09267447754326794
Trained batch 36 in epoch 3, gen_loss = 0.7627728001491444, disc_loss = 0.09292389845123163
Trained batch 37 in epoch 3, gen_loss = 0.760548859834671, disc_loss = 0.093631581550366
Trained batch 38 in epoch 3, gen_loss = 0.7607554227877886, disc_loss = 0.0920296970468301
Trained batch 39 in epoch 3, gen_loss = 0.7705532014369965, disc_loss = 0.09269331563264131
Trained batch 40 in epoch 3, gen_loss = 0.7647156671779912, disc_loss = 0.09362656368715007
Trained batch 41 in epoch 3, gen_loss = 0.7658541018054599, disc_loss = 0.09300948484312921
Trained batch 42 in epoch 3, gen_loss = 0.7683569400809532, disc_loss = 0.09314773456994878
Trained batch 43 in epoch 3, gen_loss = 0.7608994943174449, disc_loss = 0.09669354930520058
Trained batch 44 in epoch 3, gen_loss = 0.7656159023443858, disc_loss = 0.09494993272754881
Trained batch 45 in epoch 3, gen_loss = 0.7689587441475495, disc_loss = 0.09375681614746219
Trained batch 46 in epoch 3, gen_loss = 0.7668764889240265, disc_loss = 0.09327231268299387
Trained batch 47 in epoch 3, gen_loss = 0.770126818989714, disc_loss = 0.09160466769632573
Trained batch 48 in epoch 3, gen_loss = 0.7685703325028322, disc_loss = 0.09080206851798053
Trained batch 49 in epoch 3, gen_loss = 0.766293471455574, disc_loss = 0.09093035986647009
Trained batch 50 in epoch 3, gen_loss = 0.767744372288386, disc_loss = 0.08951225535323222
Trained batch 51 in epoch 3, gen_loss = 0.7668654248118401, disc_loss = 0.0882607635576278
Trained batch 52 in epoch 3, gen_loss = 0.7694580256938934, disc_loss = 0.08976477583132263
Trained batch 53 in epoch 3, gen_loss = 0.7653889573282666, disc_loss = 0.09068348343242649
Trained batch 54 in epoch 3, gen_loss = 0.7671153875914487, disc_loss = 0.09023659732192754
Trained batch 55 in epoch 3, gen_loss = 0.7680865584739617, disc_loss = 0.08979591901879758
Trained batch 56 in epoch 3, gen_loss = 0.7661667032199994, disc_loss = 0.08872881023572725
Trained batch 57 in epoch 3, gen_loss = 0.7657715508650089, disc_loss = 0.08799512448303144
Trained batch 58 in epoch 3, gen_loss = 0.7674595718666658, disc_loss = 0.08718125567913561
Trained batch 59 in epoch 3, gen_loss = 0.7654508466521899, disc_loss = 0.08716200746906301
Trained batch 60 in epoch 3, gen_loss = 0.7634049199643682, disc_loss = 0.0873599348772989
Trained batch 61 in epoch 3, gen_loss = 0.7621982900365707, disc_loss = 0.08697547038055715
Trained batch 62 in epoch 3, gen_loss = 0.7646339729664817, disc_loss = 0.08586945705529717
Trained batch 63 in epoch 3, gen_loss = 0.7681315639056265, disc_loss = 0.08477940685406793
Trained batch 64 in epoch 3, gen_loss = 0.7719733407864204, disc_loss = 0.08377547818594254
Trained batch 65 in epoch 3, gen_loss = 0.7768106826327064, disc_loss = 0.08313894315594525
Trained batch 66 in epoch 3, gen_loss = 0.7759500461727825, disc_loss = 0.08319216364744439
Trained batch 67 in epoch 3, gen_loss = 0.7729584824512986, disc_loss = 0.08300904073642895
Trained batch 68 in epoch 3, gen_loss = 0.7756694913774297, disc_loss = 0.08228511113565469
Trained batch 69 in epoch 3, gen_loss = 0.7752113729715348, disc_loss = 0.08179263944870659
Trained batch 70 in epoch 3, gen_loss = 0.7784142003092968, disc_loss = 0.08163062759845609
Trained batch 71 in epoch 3, gen_loss = 0.7782480224139161, disc_loss = 0.08080384371957432
Trained batch 72 in epoch 3, gen_loss = 0.7768894568698047, disc_loss = 0.08037805025248904
Trained batch 73 in epoch 3, gen_loss = 0.7784278533748679, disc_loss = 0.07951633243292973
Trained batch 74 in epoch 3, gen_loss = 0.7810407237211863, disc_loss = 0.07877778394768635
Trained batch 75 in epoch 3, gen_loss = 0.7824141104754648, disc_loss = 0.07866343516415279
Trained batch 76 in epoch 3, gen_loss = 0.78008837707631, disc_loss = 0.07911488291650236
Trained batch 77 in epoch 3, gen_loss = 0.7844324665956008, disc_loss = 0.07902985461390553
Trained batch 78 in epoch 3, gen_loss = 0.7851420833340174, disc_loss = 0.07816888355426019
Trained batch 79 in epoch 3, gen_loss = 0.7836892452090979, disc_loss = 0.07772204420762137
Trained batch 80 in epoch 3, gen_loss = 0.7839721739292145, disc_loss = 0.07739237011812719
Trained batch 81 in epoch 3, gen_loss = 0.7853265073968143, disc_loss = 0.07658225175265859
Trained batch 82 in epoch 3, gen_loss = 0.7841393340782947, disc_loss = 0.07616364879600973
Trained batch 83 in epoch 3, gen_loss = 0.7887911622722944, disc_loss = 0.07570435714331411
Trained batch 84 in epoch 3, gen_loss = 0.7892564727979547, disc_loss = 0.07498712627326741
Trained batch 85 in epoch 3, gen_loss = 0.790774712382361, disc_loss = 0.0744179242702071
Trained batch 86 in epoch 3, gen_loss = 0.7918028560863144, disc_loss = 0.07367197289292154
Trained batch 87 in epoch 3, gen_loss = 0.7912078706378286, disc_loss = 0.0732205487914722
Trained batch 88 in epoch 3, gen_loss = 0.7913319518726863, disc_loss = 0.0728656898849131
Trained batch 89 in epoch 3, gen_loss = 0.7895572122600344, disc_loss = 0.07249369321184027
Trained batch 90 in epoch 3, gen_loss = 0.7892009861521668, disc_loss = 0.07243205449328972
Trained batch 91 in epoch 3, gen_loss = 0.7917058872787849, disc_loss = 0.07261076664714061
Trained batch 92 in epoch 3, gen_loss = 0.7887924694886772, disc_loss = 0.0730493841592663
Trained batch 93 in epoch 3, gen_loss = 0.7864535238514555, disc_loss = 0.07324151066627274
Trained batch 94 in epoch 3, gen_loss = 0.7892964265848461, disc_loss = 0.07726544304505775
Trained batch 95 in epoch 3, gen_loss = 0.7882211683318019, disc_loss = 0.07834328872074063
Trained batch 96 in epoch 3, gen_loss = 0.7855929385141, disc_loss = 0.07947740425384536
Trained batch 97 in epoch 3, gen_loss = 0.7856552573491116, disc_loss = 0.07982830556907825
Trained batch 98 in epoch 3, gen_loss = 0.7846639020876451, disc_loss = 0.07952441649530272
Trained batch 99 in epoch 3, gen_loss = 0.7867251440882683, disc_loss = 0.0795208658836782
Trained batch 100 in epoch 3, gen_loss = 0.785159285410796, disc_loss = 0.0800913766137149
Trained batch 101 in epoch 3, gen_loss = 0.7829785122006547, disc_loss = 0.080258868251215
Trained batch 102 in epoch 3, gen_loss = 0.7872500243117508, disc_loss = 0.08078222517466661
Trained batch 103 in epoch 3, gen_loss = 0.7869882678183225, disc_loss = 0.0803998085276152
Trained batch 104 in epoch 3, gen_loss = 0.7863526369844164, disc_loss = 0.08038066943131741
Trained batch 105 in epoch 3, gen_loss = 0.7850313076995453, disc_loss = 0.08104735027717531
Trained batch 106 in epoch 3, gen_loss = 0.7855594289080005, disc_loss = 0.08087316836082489
Trained batch 107 in epoch 3, gen_loss = 0.785077144978223, disc_loss = 0.08038683834106282
Trained batch 108 in epoch 3, gen_loss = 0.7852133591787531, disc_loss = 0.07990266972247066
Trained batch 109 in epoch 3, gen_loss = 0.7842660375616767, disc_loss = 0.08004338018257509
Trained batch 110 in epoch 3, gen_loss = 0.785446912587226, disc_loss = 0.07943679534133759
Trained batch 111 in epoch 3, gen_loss = 0.7845508873994861, disc_loss = 0.07904787641850167
Trained batch 112 in epoch 3, gen_loss = 0.7835939988098314, disc_loss = 0.07884068154952431
Trained batch 113 in epoch 3, gen_loss = 0.7857399658675779, disc_loss = 0.07922458198542397
Trained batch 114 in epoch 3, gen_loss = 0.7856775675130927, disc_loss = 0.07878292799805818
Trained batch 115 in epoch 3, gen_loss = 0.7872260837205525, disc_loss = 0.07833990026747101
Trained batch 116 in epoch 3, gen_loss = 0.7860138352610108, disc_loss = 0.0785687764087676
Trained batch 117 in epoch 3, gen_loss = 0.7853479792000884, disc_loss = 0.07824914507031189
Trained batch 118 in epoch 3, gen_loss = 0.7865179579298035, disc_loss = 0.07862157433317239
Trained batch 119 in epoch 3, gen_loss = 0.7856930159032345, disc_loss = 0.07828958328658094
Trained batch 120 in epoch 3, gen_loss = 0.7873937829959491, disc_loss = 0.0777428025564502
Trained batch 121 in epoch 3, gen_loss = 0.7875882565486626, disc_loss = 0.07747447918947847
Trained batch 122 in epoch 3, gen_loss = 0.7865343677803753, disc_loss = 0.07758601452791836
Trained batch 123 in epoch 3, gen_loss = 0.7855550980856342, disc_loss = 0.07738930077832792
Trained batch 124 in epoch 3, gen_loss = 0.7872736575603485, disc_loss = 0.08096598286181689
Trained batch 125 in epoch 3, gen_loss = 0.786837313619871, disc_loss = 0.08056605853406447
Trained batch 126 in epoch 3, gen_loss = 0.7845991232733088, disc_loss = 0.08120129566170334
Trained batch 127 in epoch 3, gen_loss = 0.7850466773379594, disc_loss = 0.0809261564645567
Trained batch 128 in epoch 3, gen_loss = 0.7845277224862298, disc_loss = 0.08072904235315184
Trained batch 129 in epoch 3, gen_loss = 0.784863977936598, disc_loss = 0.08093905618700843
Trained batch 130 in epoch 3, gen_loss = 0.7833835971719436, disc_loss = 0.08218786687028544
Trained batch 131 in epoch 3, gen_loss = 0.7847640489538511, disc_loss = 0.08282480138410447
Trained batch 132 in epoch 3, gen_loss = 0.7858405989363677, disc_loss = 0.08254533399008494
Trained batch 133 in epoch 3, gen_loss = 0.7841662330858743, disc_loss = 0.08285407942316647
Trained batch 134 in epoch 3, gen_loss = 0.7827509074299424, disc_loss = 0.08320289196929447
Trained batch 135 in epoch 3, gen_loss = 0.783706481623299, disc_loss = 0.08418106450014473
Trained batch 136 in epoch 3, gen_loss = 0.7838710631332259, disc_loss = 0.08414895373675292
Trained batch 137 in epoch 3, gen_loss = 0.7821455958528795, disc_loss = 0.08518659235045746
Trained batch 138 in epoch 3, gen_loss = 0.781626904396702, disc_loss = 0.08504212661746809
Trained batch 139 in epoch 3, gen_loss = 0.7826665326952934, disc_loss = 0.08499266247797226
Trained batch 140 in epoch 3, gen_loss = 0.783267024349659, disc_loss = 0.08496650871787723
Trained batch 141 in epoch 3, gen_loss = 0.7817448375510497, disc_loss = 0.08547597103686609
Trained batch 142 in epoch 3, gen_loss = 0.7812278268637357, disc_loss = 0.08540995505644933
Trained batch 143 in epoch 3, gen_loss = 0.7814783468428586, disc_loss = 0.08525183065406357
Trained batch 144 in epoch 3, gen_loss = 0.779729618080731, disc_loss = 0.08554565056773095
Trained batch 145 in epoch 3, gen_loss = 0.7803139219137087, disc_loss = 0.08558028464983791
Trained batch 146 in epoch 3, gen_loss = 0.7801209256357077, disc_loss = 0.08604154526097636
Trained batch 147 in epoch 3, gen_loss = 0.7793850417475443, disc_loss = 0.08601172236297783
Trained batch 148 in epoch 3, gen_loss = 0.7788700607399013, disc_loss = 0.0857398184016347
Trained batch 149 in epoch 3, gen_loss = 0.7776226379474004, disc_loss = 0.0856360510053734
Trained batch 150 in epoch 3, gen_loss = 0.7787144888710502, disc_loss = 0.08580392535578533
Trained batch 151 in epoch 3, gen_loss = 0.7796523498469278, disc_loss = 0.08556104537810345
Trained batch 152 in epoch 3, gen_loss = 0.7791161862463732, disc_loss = 0.08528120748187397
Trained batch 153 in epoch 3, gen_loss = 0.7776600999104513, disc_loss = 0.08554341199553826
Trained batch 154 in epoch 3, gen_loss = 0.7794924614890929, disc_loss = 0.08544626433642641
Trained batch 155 in epoch 3, gen_loss = 0.7803769170855864, disc_loss = 0.08515439164012861
Trained batch 156 in epoch 3, gen_loss = 0.7800797560032765, disc_loss = 0.0847417000550658
Trained batch 157 in epoch 3, gen_loss = 0.7800362791064419, disc_loss = 0.0843966880377052
Trained batch 158 in epoch 3, gen_loss = 0.7811839428712737, disc_loss = 0.0842926094378784
Trained batch 159 in epoch 3, gen_loss = 0.7806723745539784, disc_loss = 0.0839085235085804
Trained batch 160 in epoch 3, gen_loss = 0.7807163816431294, disc_loss = 0.08348734916899331
Trained batch 161 in epoch 3, gen_loss = 0.7809690036523489, disc_loss = 0.08305263306577633
Trained batch 162 in epoch 3, gen_loss = 0.7823529702388435, disc_loss = 0.08281731892354284
Trained batch 163 in epoch 3, gen_loss = 0.7833270625006862, disc_loss = 0.08327796622520177
Trained batch 164 in epoch 3, gen_loss = 0.782427886579976, disc_loss = 0.08324750191108747
Trained batch 165 in epoch 3, gen_loss = 0.7814512976321829, disc_loss = 0.08362679810723267
Trained batch 166 in epoch 3, gen_loss = 0.7830503277792902, disc_loss = 0.08372102359945546
Trained batch 167 in epoch 3, gen_loss = 0.7843961976468563, disc_loss = 0.08349400868506304
Trained batch 168 in epoch 3, gen_loss = 0.7848706751532809, disc_loss = 0.08330626692071821
Trained batch 169 in epoch 3, gen_loss = 0.7843115219298531, disc_loss = 0.08333437152426032
Trained batch 170 in epoch 3, gen_loss = 0.7860284703865386, disc_loss = 0.08308372146597034
Trained batch 171 in epoch 3, gen_loss = 0.788362615503544, disc_loss = 0.08293498039982
Trained batch 172 in epoch 3, gen_loss = 0.7883046853404514, disc_loss = 0.08271253075601392
Trained batch 173 in epoch 3, gen_loss = 0.7895805988161043, disc_loss = 0.08232660737723627
Trained batch 174 in epoch 3, gen_loss = 0.7905890963758742, disc_loss = 0.08192939151610647
Trained batch 175 in epoch 3, gen_loss = 0.7900143599306996, disc_loss = 0.08162516687827354
Trained batch 176 in epoch 3, gen_loss = 0.7893067071330075, disc_loss = 0.08185972469085354
Trained batch 177 in epoch 3, gen_loss = 0.7894894780402772, disc_loss = 0.08146983336427072
Trained batch 178 in epoch 3, gen_loss = 0.7894417508687387, disc_loss = 0.08121198667057233
Trained batch 179 in epoch 3, gen_loss = 0.7902187534504467, disc_loss = 0.0808754906937894
Trained batch 180 in epoch 3, gen_loss = 0.7903937820900869, disc_loss = 0.08054296362074864
Trained batch 181 in epoch 3, gen_loss = 0.7901263572685011, disc_loss = 0.08029760449490213
Trained batch 182 in epoch 3, gen_loss = 0.7911546772620717, disc_loss = 0.07993532167086022
Trained batch 183 in epoch 3, gen_loss = 0.7916923643130324, disc_loss = 0.0796768311360527
Trained batch 184 in epoch 3, gen_loss = 0.790821184822031, disc_loss = 0.07942944152431713
Trained batch 185 in epoch 3, gen_loss = 0.7904549713737221, disc_loss = 0.07912723695538858
Trained batch 186 in epoch 3, gen_loss = 0.7911187278076927, disc_loss = 0.0789560401652825
Trained batch 187 in epoch 3, gen_loss = 0.7910700679776517, disc_loss = 0.07865851332354261
Trained batch 188 in epoch 3, gen_loss = 0.7914606085214665, disc_loss = 0.0782826163796166
Trained batch 189 in epoch 3, gen_loss = 0.7911964167105524, disc_loss = 0.07797018493231582
Trained batch 190 in epoch 3, gen_loss = 0.7922811369309251, disc_loss = 0.07762991584086527
Trained batch 191 in epoch 3, gen_loss = 0.7916367456006507, disc_loss = 0.07733955338820427
Trained batch 192 in epoch 3, gen_loss = 0.7932569509651994, disc_loss = 0.07752567027584491
Trained batch 193 in epoch 3, gen_loss = 0.7927640029757294, disc_loss = 0.07742183090706077
Trained batch 194 in epoch 3, gen_loss = 0.7931825348964104, disc_loss = 0.07722856833909948
Trained batch 195 in epoch 3, gen_loss = 0.793419502371428, disc_loss = 0.07689949700713386
Trained batch 196 in epoch 3, gen_loss = 0.7926633662076166, disc_loss = 0.0768746268264193
Trained batch 197 in epoch 3, gen_loss = 0.7931628213687376, disc_loss = 0.07662200697961104
Trained batch 198 in epoch 3, gen_loss = 0.7928230629194921, disc_loss = 0.0765921080733027
Trained batch 199 in epoch 3, gen_loss = 0.792567433565855, disc_loss = 0.07645233668154106
Trained batch 200 in epoch 3, gen_loss = 0.7936360105056668, disc_loss = 0.07927074131152745
Trained batch 201 in epoch 3, gen_loss = 0.7919553586161963, disc_loss = 0.07963852355450318
Trained batch 202 in epoch 3, gen_loss = 0.7911612996326879, disc_loss = 0.07947070745916422
Trained batch 203 in epoch 3, gen_loss = 0.7906483064095179, disc_loss = 0.07987213773680303
Trained batch 204 in epoch 3, gen_loss = 0.7900125872798083, disc_loss = 0.07979623624237209
Trained batch 205 in epoch 3, gen_loss = 0.7899840210826652, disc_loss = 0.07978912815225572
Trained batch 206 in epoch 3, gen_loss = 0.7893084964314521, disc_loss = 0.07982782760167108
Trained batch 207 in epoch 3, gen_loss = 0.7889628673975284, disc_loss = 0.07973240462552685
Trained batch 208 in epoch 3, gen_loss = 0.7898576675989981, disc_loss = 0.0794816634118664
Trained batch 209 in epoch 3, gen_loss = 0.7896038330736614, disc_loss = 0.07920013375890751
Trained batch 210 in epoch 3, gen_loss = 0.7894284298634642, disc_loss = 0.07888195699222068
Trained batch 211 in epoch 3, gen_loss = 0.7883516645656442, disc_loss = 0.07886208541348647
Trained batch 212 in epoch 3, gen_loss = 0.7883105597025911, disc_loss = 0.07933545871878243
Trained batch 213 in epoch 3, gen_loss = 0.787742569903347, disc_loss = 0.07904413605552758
Trained batch 214 in epoch 3, gen_loss = 0.7872656575469084, disc_loss = 0.0791391090100068
Trained batch 215 in epoch 3, gen_loss = 0.7868288992731659, disc_loss = 0.0790648959357188
Trained batch 216 in epoch 3, gen_loss = 0.7869173771774713, disc_loss = 0.07888410686974495
Trained batch 217 in epoch 3, gen_loss = 0.7868059917327461, disc_loss = 0.07872369335408946
Trained batch 218 in epoch 3, gen_loss = 0.7877180576324463, disc_loss = 0.07905447901732642
Trained batch 219 in epoch 3, gen_loss = 0.7865116588094018, disc_loss = 0.07920514491005716
Trained batch 220 in epoch 3, gen_loss = 0.7852657523629892, disc_loss = 0.07957578888921514
Trained batch 221 in epoch 3, gen_loss = 0.7861061713717006, disc_loss = 0.07969491214172596
Trained batch 222 in epoch 3, gen_loss = 0.7856448183145224, disc_loss = 0.07958361082355338
Trained batch 223 in epoch 3, gen_loss = 0.7871607951819897, disc_loss = 0.07958579974989075
Trained batch 224 in epoch 3, gen_loss = 0.7861789809332953, disc_loss = 0.07959955162679155
Trained batch 225 in epoch 3, gen_loss = 0.7864725689972396, disc_loss = 0.0793062215485503
Trained batch 226 in epoch 3, gen_loss = 0.786516158066132, disc_loss = 0.07913700083172204
Trained batch 227 in epoch 3, gen_loss = 0.7875092573333204, disc_loss = 0.07897520474395142
Trained batch 228 in epoch 3, gen_loss = 0.7872582543885344, disc_loss = 0.07884467034254988
Trained batch 229 in epoch 3, gen_loss = 0.7877224593058877, disc_loss = 0.07854336654645917
Trained batch 230 in epoch 3, gen_loss = 0.7887816101441651, disc_loss = 0.07849173956385358
Trained batch 231 in epoch 3, gen_loss = 0.7893005144493334, disc_loss = 0.07818267211229701
Trained batch 232 in epoch 3, gen_loss = 0.7889095821094103, disc_loss = 0.07809190541034157
Trained batch 233 in epoch 3, gen_loss = 0.7889619867006937, disc_loss = 0.0778216229707926
Trained batch 234 in epoch 3, gen_loss = 0.7890172884819355, disc_loss = 0.07762093732054247
Trained batch 235 in epoch 3, gen_loss = 0.7889611981177734, disc_loss = 0.07752171535463215
Trained batch 236 in epoch 3, gen_loss = 0.7894351922510042, disc_loss = 0.07725290159738077
Trained batch 237 in epoch 3, gen_loss = 0.7892331007648917, disc_loss = 0.07710182811759662
Trained batch 238 in epoch 3, gen_loss = 0.7894193639815104, disc_loss = 0.07682467456400457
Trained batch 239 in epoch 3, gen_loss = 0.7890438442428906, disc_loss = 0.07684933340060525
Trained batch 240 in epoch 3, gen_loss = 0.7888532822557505, disc_loss = 0.07666972134440087
Trained batch 241 in epoch 3, gen_loss = 0.7885684100064364, disc_loss = 0.07649644201213479
Trained batch 242 in epoch 3, gen_loss = 0.7888004892647512, disc_loss = 0.07636786168134568
Trained batch 243 in epoch 3, gen_loss = 0.7894853431670392, disc_loss = 0.07610163993591473
Trained batch 244 in epoch 3, gen_loss = 0.790242959285269, disc_loss = 0.07584491441482488
Trained batch 245 in epoch 3, gen_loss = 0.7904592754879618, disc_loss = 0.07565548759506546
Trained batch 246 in epoch 3, gen_loss = 0.7906983197941954, disc_loss = 0.07541639805179436
Trained batch 247 in epoch 3, gen_loss = 0.7912811670572527, disc_loss = 0.07514583271169555
Trained batch 248 in epoch 3, gen_loss = 0.7908346605109402, disc_loss = 0.07511723017409803
Trained batch 249 in epoch 3, gen_loss = 0.7914058775901794, disc_loss = 0.07486381297744811
Trained batch 250 in epoch 3, gen_loss = 0.7917678275431295, disc_loss = 0.07461274105617666
Trained batch 251 in epoch 3, gen_loss = 0.7911329742461916, disc_loss = 0.07486006631405048
Trained batch 252 in epoch 3, gen_loss = 0.7915616808201484, disc_loss = 0.07465319581911439
Trained batch 253 in epoch 3, gen_loss = 0.792318280052951, disc_loss = 0.07449807090809436
Trained batch 254 in epoch 3, gen_loss = 0.7934936287356358, disc_loss = 0.07443328758920817
Trained batch 255 in epoch 3, gen_loss = 0.793399891583249, disc_loss = 0.07428350711961684
Trained batch 256 in epoch 3, gen_loss = 0.7933411816214773, disc_loss = 0.0741822498140255
Trained batch 257 in epoch 3, gen_loss = 0.7942043408867001, disc_loss = 0.07395050209557075
Trained batch 258 in epoch 3, gen_loss = 0.7941411901624966, disc_loss = 0.07385884872439918
Trained batch 259 in epoch 3, gen_loss = 0.7940743356943131, disc_loss = 0.07380061473231762
Trained batch 260 in epoch 3, gen_loss = 0.795124126348459, disc_loss = 0.07375285788564104
Trained batch 261 in epoch 3, gen_loss = 0.7959033150709313, disc_loss = 0.0735675250624399
Trained batch 262 in epoch 3, gen_loss = 0.7951431401328896, disc_loss = 0.07351258083887596
Trained batch 263 in epoch 3, gen_loss = 0.7952935101859497, disc_loss = 0.07352534157866047
Trained batch 264 in epoch 3, gen_loss = 0.7948079455573603, disc_loss = 0.07360229577763744
Trained batch 265 in epoch 3, gen_loss = 0.7953689703367707, disc_loss = 0.07354798634130423
Trained batch 266 in epoch 3, gen_loss = 0.7965435682611073, disc_loss = 0.07340570113513521
Trained batch 267 in epoch 3, gen_loss = 0.7956652521197476, disc_loss = 0.0735319606636637
Trained batch 268 in epoch 3, gen_loss = 0.7957726448885127, disc_loss = 0.07335794178879781
Trained batch 269 in epoch 3, gen_loss = 0.7974581906089077, disc_loss = 0.07385941701596258
Trained batch 270 in epoch 3, gen_loss = 0.7974342877574513, disc_loss = 0.0737449908440046
Trained batch 271 in epoch 3, gen_loss = 0.7963104275438715, disc_loss = 0.07371757985332378
Trained batch 272 in epoch 3, gen_loss = 0.7954850438095274, disc_loss = 0.0737309974188415
Trained batch 273 in epoch 3, gen_loss = 0.7961142381829936, disc_loss = 0.07380839826600341
Trained batch 274 in epoch 3, gen_loss = 0.7960336497696964, disc_loss = 0.07361920529976487
Trained batch 275 in epoch 3, gen_loss = 0.7955614279793657, disc_loss = 0.0736081705722229
Trained batch 276 in epoch 3, gen_loss = 0.7957389441853396, disc_loss = 0.07361645517628707
Trained batch 277 in epoch 3, gen_loss = 0.7959554149306935, disc_loss = 0.07349732843656495
Trained batch 278 in epoch 3, gen_loss = 0.7958587686861714, disc_loss = 0.0734139953099031
Trained batch 279 in epoch 3, gen_loss = 0.7959530335451875, disc_loss = 0.07331279739571203
Trained batch 280 in epoch 3, gen_loss = 0.7957446245324145, disc_loss = 0.07318545092937945
Trained batch 281 in epoch 3, gen_loss = 0.7961685062511593, disc_loss = 0.07298025561674953
Trained batch 282 in epoch 3, gen_loss = 0.7965651271410629, disc_loss = 0.07282562136103797
Trained batch 283 in epoch 3, gen_loss = 0.7978477277596232, disc_loss = 0.0726988581943811
Trained batch 284 in epoch 3, gen_loss = 0.7976997372351194, disc_loss = 0.07251377867926892
Trained batch 285 in epoch 3, gen_loss = 0.7972913302116461, disc_loss = 0.07241032882333062
Trained batch 286 in epoch 3, gen_loss = 0.7973805613011018, disc_loss = 0.0722121243358619
Trained batch 287 in epoch 3, gen_loss = 0.7978799915355113, disc_loss = 0.07201338611614322
Trained batch 288 in epoch 3, gen_loss = 0.7989867947299588, disc_loss = 0.07186670674036892
Trained batch 289 in epoch 3, gen_loss = 0.7994175928420034, disc_loss = 0.07166910919296587
Trained batch 290 in epoch 3, gen_loss = 0.7992675819552642, disc_loss = 0.07175312398795256
Trained batch 291 in epoch 3, gen_loss = 0.798584048368343, disc_loss = 0.07169025285609627
Trained batch 292 in epoch 3, gen_loss = 0.7984084660893007, disc_loss = 0.07154738346318183
Trained batch 293 in epoch 3, gen_loss = 0.7990886065221968, disc_loss = 0.07147835952952047
Trained batch 294 in epoch 3, gen_loss = 0.798794699826483, disc_loss = 0.07137041417881847
Trained batch 295 in epoch 3, gen_loss = 0.7993809249554131, disc_loss = 0.07121489936567692
Trained batch 296 in epoch 3, gen_loss = 0.7997535275489794, disc_loss = 0.07100333434118818
Trained batch 297 in epoch 3, gen_loss = 0.8001886673221652, disc_loss = 0.07084640034399427
Trained batch 298 in epoch 3, gen_loss = 0.7998348118668814, disc_loss = 0.07084802776282298
Trained batch 299 in epoch 3, gen_loss = 0.7994016455610593, disc_loss = 0.07083457555777083
Trained batch 300 in epoch 3, gen_loss = 0.8001063700728243, disc_loss = 0.07065668021579369
Trained batch 301 in epoch 3, gen_loss = 0.8002882681737672, disc_loss = 0.07044760444639436
Trained batch 302 in epoch 3, gen_loss = 0.8006893521291588, disc_loss = 0.07044288664502968
Trained batch 303 in epoch 3, gen_loss = 0.8003449039043564, disc_loss = 0.07035660582876421
Trained batch 304 in epoch 3, gen_loss = 0.8000907216892867, disc_loss = 0.07022106369316089
Trained batch 305 in epoch 3, gen_loss = 0.8002753291839089, disc_loss = 0.07012389519014488
Trained batch 306 in epoch 3, gen_loss = 0.7995731278234662, disc_loss = 0.0701290923003896
Trained batch 307 in epoch 3, gen_loss = 0.8002395114147818, disc_loss = 0.07042993742113861
Trained batch 308 in epoch 3, gen_loss = 0.7993797248042517, disc_loss = 0.07049639681263746
Trained batch 309 in epoch 3, gen_loss = 0.7990511447191239, disc_loss = 0.07043856022158457
Trained batch 310 in epoch 3, gen_loss = 0.8002481819924051, disc_loss = 0.0708152130994814
Trained batch 311 in epoch 3, gen_loss = 0.7999952174723148, disc_loss = 0.07065364294864523
Trained batch 312 in epoch 3, gen_loss = 0.7993479217774571, disc_loss = 0.07090703287599281
Trained batch 313 in epoch 3, gen_loss = 0.7993839198047188, disc_loss = 0.0707349197458547
Trained batch 314 in epoch 3, gen_loss = 0.7995256475985997, disc_loss = 0.07077793293588218
Trained batch 315 in epoch 3, gen_loss = 0.7997403217456008, disc_loss = 0.07058758058443759
Trained batch 316 in epoch 3, gen_loss = 0.7993562241269963, disc_loss = 0.07065093024613259
Trained batch 317 in epoch 3, gen_loss = 0.7993265618130846, disc_loss = 0.07048748381166432
Trained batch 318 in epoch 3, gen_loss = 0.7993471109568139, disc_loss = 0.07030830363272966
Trained batch 319 in epoch 3, gen_loss = 0.7996961916796863, disc_loss = 0.07013429466460366
Trained batch 320 in epoch 3, gen_loss = 0.8000894921405293, disc_loss = 0.06993923897091937
Trained batch 321 in epoch 3, gen_loss = 0.8002593029544961, disc_loss = 0.06977680004172906
Trained batch 322 in epoch 3, gen_loss = 0.800191073318015, disc_loss = 0.06966049189826376
Trained batch 323 in epoch 3, gen_loss = 0.8003940193189515, disc_loss = 0.06948859274479342
Trained batch 324 in epoch 3, gen_loss = 0.8005066377383012, disc_loss = 0.06946177267111264
Trained batch 325 in epoch 3, gen_loss = 0.8006009976008187, disc_loss = 0.06927815493927594
Trained batch 326 in epoch 3, gen_loss = 0.8004831597892517, disc_loss = 0.06922004252831689
Trained batch 327 in epoch 3, gen_loss = 0.7999796388534511, disc_loss = 0.06916278936309604
Trained batch 328 in epoch 3, gen_loss = 0.7996847123179393, disc_loss = 0.06902866012849887
Trained batch 329 in epoch 3, gen_loss = 0.8000578893856569, disc_loss = 0.06900736374046766
Trained batch 330 in epoch 3, gen_loss = 0.799641638634068, disc_loss = 0.06894831326185216
Trained batch 331 in epoch 3, gen_loss = 0.8009699966354542, disc_loss = 0.06892779523910708
Trained batch 332 in epoch 3, gen_loss = 0.8005012999604773, disc_loss = 0.0688782102923404
Trained batch 333 in epoch 3, gen_loss = 0.8006242113020605, disc_loss = 0.06876414643968651
Trained batch 334 in epoch 3, gen_loss = 0.8002560806808187, disc_loss = 0.06876928630604673
Trained batch 335 in epoch 3, gen_loss = 0.7996167550306945, disc_loss = 0.06872588489204645
Trained batch 336 in epoch 3, gen_loss = 0.8005989463640604, disc_loss = 0.06868274739835666
Trained batch 337 in epoch 3, gen_loss = 0.800178447683182, disc_loss = 0.06865895463473345
Trained batch 338 in epoch 3, gen_loss = 0.8012306443182065, disc_loss = 0.06882195639531169
Trained batch 339 in epoch 3, gen_loss = 0.8017577629755525, disc_loss = 0.06895992597017218
Trained batch 340 in epoch 3, gen_loss = 0.8011281774365657, disc_loss = 0.06911559830094713
Trained batch 341 in epoch 3, gen_loss = 0.8014050245459317, disc_loss = 0.0689648126867431
Trained batch 342 in epoch 3, gen_loss = 0.8016109161578532, disc_loss = 0.06879938310745333
Trained batch 343 in epoch 3, gen_loss = 0.8016961689085461, disc_loss = 0.06900275153714384
Trained batch 344 in epoch 3, gen_loss = 0.8018403005772743, disc_loss = 0.06888038001522638
Trained batch 345 in epoch 3, gen_loss = 0.8015974733354039, disc_loss = 0.0688494195666358
Trained batch 346 in epoch 3, gen_loss = 0.8029337895534912, disc_loss = 0.068878756825321
Trained batch 347 in epoch 3, gen_loss = 0.802355208701786, disc_loss = 0.06881744813323877
Trained batch 348 in epoch 3, gen_loss = 0.8023901490393204, disc_loss = 0.06884280603411033
Trained batch 349 in epoch 3, gen_loss = 0.8033034868751253, disc_loss = 0.06872709113572326
Trained batch 350 in epoch 3, gen_loss = 0.8028432727709115, disc_loss = 0.06873054493568902
Trained batch 351 in epoch 3, gen_loss = 0.802074305628511, disc_loss = 0.06882126259998503
Trained batch 352 in epoch 3, gen_loss = 0.8020802993781169, disc_loss = 0.06875884768265503
Trained batch 353 in epoch 3, gen_loss = 0.8026530868084417, disc_loss = 0.06860513329284929
Trained batch 354 in epoch 3, gen_loss = 0.8027735850340884, disc_loss = 0.0685720403298316
Trained batch 355 in epoch 3, gen_loss = 0.8020335485258799, disc_loss = 0.06873478881460143
Trained batch 356 in epoch 3, gen_loss = 0.802303018940597, disc_loss = 0.06860726483489703
Trained batch 357 in epoch 3, gen_loss = 0.8025348665161506, disc_loss = 0.06855708538871987
Trained batch 358 in epoch 3, gen_loss = 0.8027288262060426, disc_loss = 0.06839623281727013
Trained batch 359 in epoch 3, gen_loss = 0.8027350482841332, disc_loss = 0.06825124194793818
Trained batch 360 in epoch 3, gen_loss = 0.8025694065972379, disc_loss = 0.06816048806383587
Trained batch 361 in epoch 3, gen_loss = 0.803144905201638, disc_loss = 0.06800840283327257
Trained batch 362 in epoch 3, gen_loss = 0.8033638881421943, disc_loss = 0.06795190453026495
Trained batch 363 in epoch 3, gen_loss = 0.8029053808077351, disc_loss = 0.06789153871372096
Trained batch 364 in epoch 3, gen_loss = 0.8025374774246999, disc_loss = 0.06790787620240286
Trained batch 365 in epoch 3, gen_loss = 0.8030530874683557, disc_loss = 0.06782577207943048
Trained batch 366 in epoch 3, gen_loss = 0.8031900676946874, disc_loss = 0.06767748740605746
Trained batch 367 in epoch 3, gen_loss = 0.8036750193037416, disc_loss = 0.06756682223488536
Trained batch 368 in epoch 3, gen_loss = 0.8036998007194136, disc_loss = 0.06741995782639357
Trained batch 369 in epoch 3, gen_loss = 0.8047521147373561, disc_loss = 0.06738016835187335
Trained batch 370 in epoch 3, gen_loss = 0.8052478243880516, disc_loss = 0.0673401677087351
Trained batch 371 in epoch 3, gen_loss = 0.8052748857486632, disc_loss = 0.0672217813415593
Trained batch 372 in epoch 3, gen_loss = 0.8052343325864214, disc_loss = 0.06709659284095582
Trained batch 373 in epoch 3, gen_loss = 0.8053459328285513, disc_loss = 0.06698452388210331
Trained batch 374 in epoch 3, gen_loss = 0.8053626816272735, disc_loss = 0.0668702092692256
Trained batch 375 in epoch 3, gen_loss = 0.8059075740265086, disc_loss = 0.06687150143849802
Trained batch 376 in epoch 3, gen_loss = 0.8060307557291947, disc_loss = 0.0667311036168778
Trained batch 377 in epoch 3, gen_loss = 0.805390351269611, disc_loss = 0.06681054633692222
Trained batch 378 in epoch 3, gen_loss = 0.8054358980429204, disc_loss = 0.06675401067798638
Trained batch 379 in epoch 3, gen_loss = 0.8054704216750045, disc_loss = 0.06674102724431769
Trained batch 380 in epoch 3, gen_loss = 0.8052666344511228, disc_loss = 0.06664356444363441
Trained batch 381 in epoch 3, gen_loss = 0.8046473727332359, disc_loss = 0.06658714781247119
Trained batch 382 in epoch 3, gen_loss = 0.8049303462082039, disc_loss = 0.06647566911903047
Trained batch 383 in epoch 3, gen_loss = 0.8057152992890527, disc_loss = 0.06638862116718276
Trained batch 384 in epoch 3, gen_loss = 0.805965330461403, disc_loss = 0.06623956210330709
Trained batch 385 in epoch 3, gen_loss = 0.8063262059435325, disc_loss = 0.06611070240041907
Trained batch 386 in epoch 3, gen_loss = 0.8063441350940586, disc_loss = 0.06602175482272024
Trained batch 387 in epoch 3, gen_loss = 0.8066718325633364, disc_loss = 0.06587195069020249
Trained batch 388 in epoch 3, gen_loss = 0.8069830784301218, disc_loss = 0.06571887232420684
Trained batch 389 in epoch 3, gen_loss = 0.8069238979847003, disc_loss = 0.0655919530452826
Trained batch 390 in epoch 3, gen_loss = 0.8071169645127738, disc_loss = 0.06545621834819199
Trained batch 391 in epoch 3, gen_loss = 0.8073014003433743, disc_loss = 0.0653273039996358
Trained batch 392 in epoch 3, gen_loss = 0.8076407948068081, disc_loss = 0.0651778001184208
Trained batch 393 in epoch 3, gen_loss = 0.8080976663658461, disc_loss = 0.06503739224411169
Trained batch 394 in epoch 3, gen_loss = 0.8083468465110923, disc_loss = 0.06489182006143317
Trained batch 395 in epoch 3, gen_loss = 0.8083928357621636, disc_loss = 0.064783966507424
Trained batch 396 in epoch 3, gen_loss = 0.8083910330266736, disc_loss = 0.06463852979979415
Trained batch 397 in epoch 3, gen_loss = 0.8084441803058787, disc_loss = 0.06451459948895452
Trained batch 398 in epoch 3, gen_loss = 0.8087878868842783, disc_loss = 0.06455036158554424
Trained batch 399 in epoch 3, gen_loss = 0.8085457732528448, disc_loss = 0.06451395794865675
Trained batch 400 in epoch 3, gen_loss = 0.8085825326585413, disc_loss = 0.06442162432728749
Trained batch 401 in epoch 3, gen_loss = 0.8092005349955156, disc_loss = 0.06428941032172769
Trained batch 402 in epoch 3, gen_loss = 0.8097044429915123, disc_loss = 0.06417605226452719
Trained batch 403 in epoch 3, gen_loss = 0.8099927466252063, disc_loss = 0.06404601293961786
Trained batch 404 in epoch 3, gen_loss = 0.8098513082957562, disc_loss = 0.06393565099663388
Trained batch 405 in epoch 3, gen_loss = 0.8099043789902344, disc_loss = 0.06380756892002384
Trained batch 406 in epoch 3, gen_loss = 0.8101179026415073, disc_loss = 0.06369538316777759
Trained batch 407 in epoch 3, gen_loss = 0.8104808182254726, disc_loss = 0.06357803344886348
Trained batch 408 in epoch 3, gen_loss = 0.8108453649326175, disc_loss = 0.06345355769273231
Trained batch 409 in epoch 3, gen_loss = 0.8113018173270109, disc_loss = 0.06353668664900086
Trained batch 410 in epoch 3, gen_loss = 0.8112416242015913, disc_loss = 0.06342445147493424
Trained batch 411 in epoch 3, gen_loss = 0.8113155043096218, disc_loss = 0.06331032580465476
Trained batch 412 in epoch 3, gen_loss = 0.8113385565200094, disc_loss = 0.06317441149323853
Trained batch 413 in epoch 3, gen_loss = 0.8113791705761555, disc_loss = 0.06306551397409164
Trained batch 414 in epoch 3, gen_loss = 0.8118906304778823, disc_loss = 0.06300196612298668
Trained batch 415 in epoch 3, gen_loss = 0.812308678475137, disc_loss = 0.06286666698109072
Trained batch 416 in epoch 3, gen_loss = 0.8124312263169735, disc_loss = 0.06274684603221053
Trained batch 417 in epoch 3, gen_loss = 0.8127092246376156, disc_loss = 0.06260833516716957
Trained batch 418 in epoch 3, gen_loss = 0.8128119318041426, disc_loss = 0.062474363829122595
Trained batch 419 in epoch 3, gen_loss = 0.8130359918588683, disc_loss = 0.06234564063072737
Trained batch 420 in epoch 3, gen_loss = 0.8132226194593516, disc_loss = 0.06223174072514485
Trained batch 421 in epoch 3, gen_loss = 0.8136506183028787, disc_loss = 0.062104894703483626
Trained batch 422 in epoch 3, gen_loss = 0.8135563831943711, disc_loss = 0.06204544278037851
Trained batch 423 in epoch 3, gen_loss = 0.8136232555053144, disc_loss = 0.06194149373639551
Trained batch 424 in epoch 3, gen_loss = 0.8145746161657221, disc_loss = 0.061979089496547686
Trained batch 425 in epoch 3, gen_loss = 0.8151662756159832, disc_loss = 0.061866617662080084
Trained batch 426 in epoch 3, gen_loss = 0.8148478955658593, disc_loss = 0.06180458621555979
Trained batch 427 in epoch 3, gen_loss = 0.8152905501355635, disc_loss = 0.0616892949976114
Trained batch 428 in epoch 3, gen_loss = 0.8156797328056433, disc_loss = 0.06158807907700712
Trained batch 429 in epoch 3, gen_loss = 0.8161048963319424, disc_loss = 0.061459296828049216
Trained batch 430 in epoch 3, gen_loss = 0.8165168183447313, disc_loss = 0.06133225299158672
Trained batch 431 in epoch 3, gen_loss = 0.8166419702961489, disc_loss = 0.061212080515731404
Trained batch 432 in epoch 3, gen_loss = 0.8168159097639572, disc_loss = 0.061099830767522643
Trained batch 433 in epoch 3, gen_loss = 0.8170710230065931, disc_loss = 0.06098772815218376
Trained batch 434 in epoch 3, gen_loss = 0.8172429686990278, disc_loss = 0.060858511601456965
Trained batch 435 in epoch 3, gen_loss = 0.8172517219951393, disc_loss = 0.06072796710954825
Trained batch 436 in epoch 3, gen_loss = 0.8172518718024413, disc_loss = 0.06061118424740072
Trained batch 437 in epoch 3, gen_loss = 0.8174305396945509, disc_loss = 0.060486302257102983
Trained batch 438 in epoch 3, gen_loss = 0.8175780238893418, disc_loss = 0.06039269483310928
Trained batch 439 in epoch 3, gen_loss = 0.817626316235824, disc_loss = 0.06029056867859749
Trained batch 440 in epoch 3, gen_loss = 0.8175003234626484, disc_loss = 0.06017661978366052
Trained batch 441 in epoch 3, gen_loss = 0.8176963245032599, disc_loss = 0.06011057436588427
Trained batch 442 in epoch 3, gen_loss = 0.8181872590535382, disc_loss = 0.06000282934028025
Trained batch 443 in epoch 3, gen_loss = 0.8185128574301531, disc_loss = 0.05988468867328085
Trained batch 444 in epoch 3, gen_loss = 0.8188356144374676, disc_loss = 0.059766227864984714
Trained batch 445 in epoch 3, gen_loss = 0.8189427066143318, disc_loss = 0.05964477208021176
Trained batch 446 in epoch 3, gen_loss = 0.8190545096360063, disc_loss = 0.05952755768285435
Trained batch 447 in epoch 3, gen_loss = 0.819223585205951, disc_loss = 0.059409276230975853
Trained batch 448 in epoch 3, gen_loss = 0.8194134590487703, disc_loss = 0.05928447808477123
Trained batch 449 in epoch 3, gen_loss = 0.8195666728417078, disc_loss = 0.05916217527145313
Trained batch 450 in epoch 3, gen_loss = 0.8198437207686134, disc_loss = 0.05904043196677798
Trained batch 451 in epoch 3, gen_loss = 0.8201692614012059, disc_loss = 0.0589218778583114
Trained batch 452 in epoch 3, gen_loss = 0.8202879582151409, disc_loss = 0.058807910321317367
Trained batch 453 in epoch 3, gen_loss = 0.8204082524330081, disc_loss = 0.05915710065177424
Trained batch 454 in epoch 3, gen_loss = 0.8198557287127107, disc_loss = 0.05919496277244864
Trained batch 455 in epoch 3, gen_loss = 0.8194712138358962, disc_loss = 0.05917887291830164
Trained batch 456 in epoch 3, gen_loss = 0.8195009511330978, disc_loss = 0.05906655776968605
Trained batch 457 in epoch 3, gen_loss = 0.8198606049780242, disc_loss = 0.05895414885222977
Trained batch 458 in epoch 3, gen_loss = 0.8198406670997346, disc_loss = 0.05884350605982646
Trained batch 459 in epoch 3, gen_loss = 0.8200714354281841, disc_loss = 0.05873007937132017
Trained batch 460 in epoch 3, gen_loss = 0.8202060306537694, disc_loss = 0.05861792717646169
Trained batch 461 in epoch 3, gen_loss = 0.8201032211899242, disc_loss = 0.058548230127516115
Trained batch 462 in epoch 3, gen_loss = 0.8203265264662501, disc_loss = 0.05844608095090346
Trained batch 463 in epoch 3, gen_loss = 0.8204350878067058, disc_loss = 0.05833657121020851
Trained batch 464 in epoch 3, gen_loss = 0.8204431271681222, disc_loss = 0.05825241575197827
Trained batch 465 in epoch 3, gen_loss = 0.8204984533812355, disc_loss = 0.058191022913615206
Trained batch 466 in epoch 3, gen_loss = 0.8208214748467316, disc_loss = 0.05808631723000802
Trained batch 467 in epoch 3, gen_loss = 0.8210440988087246, disc_loss = 0.05798311904271762
Trained batch 468 in epoch 3, gen_loss = 0.8210913298099534, disc_loss = 0.05787368909890718
Trained batch 469 in epoch 3, gen_loss = 0.8214235426897698, disc_loss = 0.05777657330828778
Trained batch 470 in epoch 3, gen_loss = 0.8216854133297177, disc_loss = 0.057672793176143794
Trained batch 471 in epoch 3, gen_loss = 0.8219742658153429, disc_loss = 0.057563510987812934
Trained batch 472 in epoch 3, gen_loss = 0.8216427204850865, disc_loss = 0.05768303345912481
Trained batch 473 in epoch 3, gen_loss = 0.8222357485490509, disc_loss = 0.05763563538512474
Trained batch 474 in epoch 3, gen_loss = 0.822575922953455, disc_loss = 0.057700710026057145
Trained batch 475 in epoch 3, gen_loss = 0.8224485532200637, disc_loss = 0.057708380802558
Trained batch 476 in epoch 3, gen_loss = 0.8225033032694202, disc_loss = 0.05761498105429128
Trained batch 477 in epoch 3, gen_loss = 0.8226778396876786, disc_loss = 0.057509891829106596
Trained batch 478 in epoch 3, gen_loss = 0.8230950687399488, disc_loss = 0.05742391572180272
Trained batch 479 in epoch 3, gen_loss = 0.8230605393027266, disc_loss = 0.05734570381852488
Trained batch 480 in epoch 3, gen_loss = 0.8231744409970583, disc_loss = 0.057325022229285844
Trained batch 481 in epoch 3, gen_loss = 0.8232132315759342, disc_loss = 0.05722824422858996
Trained batch 482 in epoch 3, gen_loss = 0.8228037577608357, disc_loss = 0.057228787289257496
Trained batch 483 in epoch 3, gen_loss = 0.8226539072049551, disc_loss = 0.05713119567371905
Trained batch 484 in epoch 3, gen_loss = 0.8226024123196749, disc_loss = 0.05704239365865582
Trained batch 485 in epoch 3, gen_loss = 0.8233844794240999, disc_loss = 0.05787373550519838
Trained batch 486 in epoch 3, gen_loss = 0.8232779475330572, disc_loss = 0.057856011915821924
Trained batch 487 in epoch 3, gen_loss = 0.8225870436576547, disc_loss = 0.058194888101081504
Trained batch 488 in epoch 3, gen_loss = 0.8222923712740159, disc_loss = 0.05823196045833436
Trained batch 489 in epoch 3, gen_loss = 0.8227619438755269, disc_loss = 0.05833892939536243
Trained batch 490 in epoch 3, gen_loss = 0.8231507716984953, disc_loss = 0.058518696358226346
Trained batch 491 in epoch 3, gen_loss = 0.8229533462989621, disc_loss = 0.05860904230342466
Trained batch 492 in epoch 3, gen_loss = 0.8223027041669307, disc_loss = 0.05892646383932408
Trained batch 493 in epoch 3, gen_loss = 0.8225310174559775, disc_loss = 0.05901218964510903
Trained batch 494 in epoch 3, gen_loss = 0.8221593341442069, disc_loss = 0.05902692112845905
Trained batch 495 in epoch 3, gen_loss = 0.8223275376423713, disc_loss = 0.05902174148415666
Trained batch 496 in epoch 3, gen_loss = 0.8223457049795799, disc_loss = 0.05904928607007927
Trained batch 497 in epoch 3, gen_loss = 0.8219821011445608, disc_loss = 0.05905390052259507
Trained batch 498 in epoch 3, gen_loss = 0.8218387820438775, disc_loss = 0.059335075246024584
Trained batch 499 in epoch 3, gen_loss = 0.8214305914640426, disc_loss = 0.05935202348418534
Trained batch 500 in epoch 3, gen_loss = 0.8211589198626444, disc_loss = 0.05929398000009819
Trained batch 501 in epoch 3, gen_loss = 0.8210044909283459, disc_loss = 0.05927212558783205
Trained batch 502 in epoch 3, gen_loss = 0.82068859156273, disc_loss = 0.05931271605423205
Trained batch 503 in epoch 3, gen_loss = 0.821180954812065, disc_loss = 0.059349544466443596
Trained batch 504 in epoch 3, gen_loss = 0.8213322901489711, disc_loss = 0.05924543371553173
Trained batch 505 in epoch 3, gen_loss = 0.8208417648618872, disc_loss = 0.05938791373759331
Trained batch 506 in epoch 3, gen_loss = 0.8206057205237816, disc_loss = 0.05941368230017861
Trained batch 507 in epoch 3, gen_loss = 0.8211440603564105, disc_loss = 0.05942447693820486
Trained batch 508 in epoch 3, gen_loss = 0.8215489602978899, disc_loss = 0.05938894675462735
Trained batch 509 in epoch 3, gen_loss = 0.8217087549321792, disc_loss = 0.05929854515501681
Trained batch 510 in epoch 3, gen_loss = 0.8216811725304785, disc_loss = 0.0592324186787155
Trained batch 511 in epoch 3, gen_loss = 0.8212259827414528, disc_loss = 0.0592643373493047
Trained batch 512 in epoch 3, gen_loss = 0.8213654266231009, disc_loss = 0.059166018558814974
Trained batch 513 in epoch 3, gen_loss = 0.8212123311447262, disc_loss = 0.05925117816471636
Trained batch 514 in epoch 3, gen_loss = 0.8215621601030665, disc_loss = 0.059227335576004195
Trained batch 515 in epoch 3, gen_loss = 0.8212382637484129, disc_loss = 0.059190309014489025
Trained batch 516 in epoch 3, gen_loss = 0.821352453019679, disc_loss = 0.05909602890039724
Trained batch 517 in epoch 3, gen_loss = 0.8215093518316056, disc_loss = 0.05899626024168085
Trained batch 518 in epoch 3, gen_loss = 0.8215782061247927, disc_loss = 0.05893822260531157
Trained batch 519 in epoch 3, gen_loss = 0.8218347842876728, disc_loss = 0.05888747193922217
Trained batch 520 in epoch 3, gen_loss = 0.8218388461334463, disc_loss = 0.05881016595993413
Trained batch 521 in epoch 3, gen_loss = 0.8219548856618304, disc_loss = 0.058720968806423905
Trained batch 522 in epoch 3, gen_loss = 0.8218552920376138, disc_loss = 0.058676638492662636
Trained batch 523 in epoch 3, gen_loss = 0.8223070397631813, disc_loss = 0.058601410522744174
Trained batch 524 in epoch 3, gen_loss = 0.822218299025581, disc_loss = 0.05870489695597263
Trained batch 525 in epoch 3, gen_loss = 0.8222925179131584, disc_loss = 0.05861747334622725
Trained batch 526 in epoch 3, gen_loss = 0.8221747851462247, disc_loss = 0.05853257993098341
Trained batch 527 in epoch 3, gen_loss = 0.8219436383382841, disc_loss = 0.058490014941939575
Trained batch 528 in epoch 3, gen_loss = 0.8222244814573479, disc_loss = 0.058397999276285584
Trained batch 529 in epoch 3, gen_loss = 0.8220623885685543, disc_loss = 0.058362692116566424
Trained batch 530 in epoch 3, gen_loss = 0.8218507997958224, disc_loss = 0.05831715503879411
Trained batch 531 in epoch 3, gen_loss = 0.8220868029988798, disc_loss = 0.05824374681674784
Trained batch 532 in epoch 3, gen_loss = 0.822172255945474, disc_loss = 0.0582073484329021
Trained batch 533 in epoch 3, gen_loss = 0.8218999973843607, disc_loss = 0.05816024127119824
Trained batch 534 in epoch 3, gen_loss = 0.8214443723732066, disc_loss = 0.05819380210590697
Trained batch 535 in epoch 3, gen_loss = 0.8218040639784798, disc_loss = 0.05816625289049055
Trained batch 536 in epoch 3, gen_loss = 0.821645138982954, disc_loss = 0.05812641902994954
Trained batch 537 in epoch 3, gen_loss = 0.8217867305952377, disc_loss = 0.05806160032347565
Trained batch 538 in epoch 3, gen_loss = 0.8220488493208098, disc_loss = 0.058006613551602734
Trained batch 539 in epoch 3, gen_loss = 0.8218603301931311, disc_loss = 0.057964476684315334
Trained batch 540 in epoch 3, gen_loss = 0.8214362676835545, disc_loss = 0.057994842078268195
Trained batch 541 in epoch 3, gen_loss = 0.821626219802237, disc_loss = 0.05795341089189163
Trained batch 542 in epoch 3, gen_loss = 0.8215273051191649, disc_loss = 0.05794556024887395
Trained batch 543 in epoch 3, gen_loss = 0.821881855783217, disc_loss = 0.057858193877002445
Trained batch 544 in epoch 3, gen_loss = 0.82198735420857, disc_loss = 0.057769221679196445
Trained batch 545 in epoch 3, gen_loss = 0.8222598978232988, disc_loss = 0.05769397946067782
Trained batch 546 in epoch 3, gen_loss = 0.8224368915915271, disc_loss = 0.05760296696024032
Trained batch 547 in epoch 3, gen_loss = 0.8223639485174722, disc_loss = 0.05753666967031185
Trained batch 548 in epoch 3, gen_loss = 0.8225336931442302, disc_loss = 0.05744490933134636
Trained batch 549 in epoch 3, gen_loss = 0.822754951173609, disc_loss = 0.057382766165855255
Trained batch 550 in epoch 3, gen_loss = 0.8228783474427169, disc_loss = 0.05728979840597472
Trained batch 551 in epoch 3, gen_loss = 0.8224851141373316, disc_loss = 0.05729392108649178
Trained batch 552 in epoch 3, gen_loss = 0.822660171101796, disc_loss = 0.057200593678499646
Trained batch 553 in epoch 3, gen_loss = 0.8230195553294157, disc_loss = 0.05740758304951531
Trained batch 554 in epoch 3, gen_loss = 0.8228190651885025, disc_loss = 0.05742112534070337
Trained batch 555 in epoch 3, gen_loss = 0.822651552425014, disc_loss = 0.05740852174583635
Trained batch 556 in epoch 3, gen_loss = 0.8229408499582451, disc_loss = 0.05736254054979426
Trained batch 557 in epoch 3, gen_loss = 0.8233776938530707, disc_loss = 0.0573815825799193
Trained batch 558 in epoch 3, gen_loss = 0.8232629132825274, disc_loss = 0.0573264927851546
Trained batch 559 in epoch 3, gen_loss = 0.823398793382304, disc_loss = 0.057238170211868625
Trained batch 560 in epoch 3, gen_loss = 0.8235124377218372, disc_loss = 0.05716877716216599
Trained batch 561 in epoch 3, gen_loss = 0.8236446130318149, disc_loss = 0.05707648856021809
Trained batch 562 in epoch 3, gen_loss = 0.8239833307096844, disc_loss = 0.056986396849406866
Trained batch 563 in epoch 3, gen_loss = 0.8242581147462764, disc_loss = 0.056923270626786225
Trained batch 564 in epoch 3, gen_loss = 0.824465673159709, disc_loss = 0.05683103497840662
Trained batch 565 in epoch 3, gen_loss = 0.8244763393705389, disc_loss = 0.05675535675059254
Trained batch 566 in epoch 3, gen_loss = 0.8244609181002124, disc_loss = 0.056661028930312926
Trained batch 567 in epoch 3, gen_loss = 0.8244896421969776, disc_loss = 0.05660774864700728
Trained batch 568 in epoch 3, gen_loss = 0.824824194497509, disc_loss = 0.056521826675358135
Trained batch 569 in epoch 3, gen_loss = 0.8250977635383606, disc_loss = 0.0564301218604669
Trained batch 570 in epoch 3, gen_loss = 0.8251949809687359, disc_loss = 0.05633773877376759
Trained batch 571 in epoch 3, gen_loss = 0.8252490919369918, disc_loss = 0.05624688821771488
Trained batch 572 in epoch 3, gen_loss = 0.8252897799327111, disc_loss = 0.056155469160068645
Trained batch 573 in epoch 3, gen_loss = 0.8253543367576931, disc_loss = 0.05608257584197557
Trained batch 574 in epoch 3, gen_loss = 0.8255201485882635, disc_loss = 0.05600215020103623
Trained batch 575 in epoch 3, gen_loss = 0.8254993221619062, disc_loss = 0.05592940994999177
Trained batch 576 in epoch 3, gen_loss = 0.8256882208058904, disc_loss = 0.05584999933827546
Trained batch 577 in epoch 3, gen_loss = 0.8258532112444973, disc_loss = 0.0557645812721691
Trained batch 578 in epoch 3, gen_loss = 0.8261501066425304, disc_loss = 0.05568244326127844
Trained batch 579 in epoch 3, gen_loss = 0.826087665352328, disc_loss = 0.05559836014149839
Trained batch 580 in epoch 3, gen_loss = 0.8263768353683814, disc_loss = 0.055512645917026114
Trained batch 581 in epoch 3, gen_loss = 0.8263139440021974, disc_loss = 0.05556600427141419
Trained batch 582 in epoch 3, gen_loss = 0.8262983372444559, disc_loss = 0.05550158667493145
Trained batch 583 in epoch 3, gen_loss = 0.8263504350022094, disc_loss = 0.05545166755383771
Trained batch 584 in epoch 3, gen_loss = 0.826477913876884, disc_loss = 0.05537491235285042
Trained batch 585 in epoch 3, gen_loss = 0.8267012276136835, disc_loss = 0.05529466016995228
Trained batch 586 in epoch 3, gen_loss = 0.8270162730850596, disc_loss = 0.05527744892694284
Trained batch 587 in epoch 3, gen_loss = 0.8271361693841259, disc_loss = 0.055198715626322316
Trained batch 588 in epoch 3, gen_loss = 0.827309186976713, disc_loss = 0.05512257584636313
Trained batch 589 in epoch 3, gen_loss = 0.8276501080747378, disc_loss = 0.05504327599409084
Trained batch 590 in epoch 3, gen_loss = 0.8275539976892939, disc_loss = 0.0549875582712537
Trained batch 591 in epoch 3, gen_loss = 0.8277640392047327, disc_loss = 0.05490619539184106
Trained batch 592 in epoch 3, gen_loss = 0.8280398036537042, disc_loss = 0.05488389429893866
Trained batch 593 in epoch 3, gen_loss = 0.8279652535313308, disc_loss = 0.05483455497258804
Trained batch 594 in epoch 3, gen_loss = 0.8277012855064969, disc_loss = 0.05481228443105243
Trained batch 595 in epoch 3, gen_loss = 0.8277198838307553, disc_loss = 0.0547392435872696
Trained batch 596 in epoch 3, gen_loss = 0.8283783946205024, disc_loss = 0.05471803860581313
Trained batch 597 in epoch 3, gen_loss = 0.8289173038109489, disc_loss = 0.05466757324659717
Trained batch 598 in epoch 3, gen_loss = 0.828987400002392, disc_loss = 0.054609658888841235
Trained batch 599 in epoch 3, gen_loss = 0.8293290410439174, disc_loss = 0.05453948311701728
Trained batch 600 in epoch 3, gen_loss = 0.8294565239285867, disc_loss = 0.054477130196533
Trained batch 601 in epoch 3, gen_loss = 0.829695502685946, disc_loss = 0.05472773559077448
Trained batch 602 in epoch 3, gen_loss = 0.8292748723457108, disc_loss = 0.05483016325276697
Trained batch 603 in epoch 3, gen_loss = 0.8290030780612239, disc_loss = 0.054802334792248976
Trained batch 604 in epoch 3, gen_loss = 0.829490597977126, disc_loss = 0.054777080786206626
Trained batch 605 in epoch 3, gen_loss = 0.8294616009142532, disc_loss = 0.05471163369114311
Trained batch 606 in epoch 3, gen_loss = 0.8294922917639403, disc_loss = 0.05464667530041464
Trained batch 607 in epoch 3, gen_loss = 0.8294678754908474, disc_loss = 0.05458718358951094
Trained batch 608 in epoch 3, gen_loss = 0.8294564124398631, disc_loss = 0.0545135543827726
Trained batch 609 in epoch 3, gen_loss = 0.8293427134146456, disc_loss = 0.054470336026909046
Trained batch 610 in epoch 3, gen_loss = 0.8295041860223011, disc_loss = 0.05439950693010028
Trained batch 611 in epoch 3, gen_loss = 0.8296914823304594, disc_loss = 0.05432271729778876
Trained batch 612 in epoch 3, gen_loss = 0.8296845060382737, disc_loss = 0.05434822330067503
Trained batch 613 in epoch 3, gen_loss = 0.8292840704661627, disc_loss = 0.05462079399366975
Trained batch 614 in epoch 3, gen_loss = 0.8294321817111193, disc_loss = 0.05462128278965933
Trained batch 615 in epoch 3, gen_loss = 0.8299800739079327, disc_loss = 0.05458998404384301
Trained batch 616 in epoch 3, gen_loss = 0.8303803001655752, disc_loss = 0.054535168339687023
Trained batch 617 in epoch 3, gen_loss = 0.8303780024298573, disc_loss = 0.05446249496193247
Trained batch 618 in epoch 3, gen_loss = 0.8299009194281645, disc_loss = 0.05466591665537814
Trained batch 619 in epoch 3, gen_loss = 0.8300333594122241, disc_loss = 0.054595253405146184
Trained batch 620 in epoch 3, gen_loss = 0.830201361682296, disc_loss = 0.054578709488452656
Trained batch 621 in epoch 3, gen_loss = 0.8303008530875877, disc_loss = 0.05450394126201809
Trained batch 622 in epoch 3, gen_loss = 0.830524655253317, disc_loss = 0.05444538828925817
Trained batch 623 in epoch 3, gen_loss = 0.8304188296389885, disc_loss = 0.05438313971442254
Trained batch 624 in epoch 3, gen_loss = 0.8302473366737366, disc_loss = 0.05432242012955248
Trained batch 625 in epoch 3, gen_loss = 0.8300722646065795, disc_loss = 0.05429869919707374
Trained batch 626 in epoch 3, gen_loss = 0.8303733222792593, disc_loss = 0.054298801288570155
Trained batch 627 in epoch 3, gen_loss = 0.8303378439822774, disc_loss = 0.05422386265349438
Trained batch 628 in epoch 3, gen_loss = 0.830545258351464, disc_loss = 0.054145753288505356
Trained batch 629 in epoch 3, gen_loss = 0.8299864813448891, disc_loss = 0.0542174913103707
Trained batch 630 in epoch 3, gen_loss = 0.8299240117594482, disc_loss = 0.054150482141907236
Trained batch 631 in epoch 3, gen_loss = 0.8300805199372617, disc_loss = 0.05408707158632659
Trained batch 632 in epoch 3, gen_loss = 0.8304393675654985, disc_loss = 0.05417809714371924
Trained batch 633 in epoch 3, gen_loss = 0.8303289645665828, disc_loss = 0.05414635845649494
Trained batch 634 in epoch 3, gen_loss = 0.8298467351695684, disc_loss = 0.0542457665995086
Trained batch 635 in epoch 3, gen_loss = 0.829661582907041, disc_loss = 0.05420835983153116
Trained batch 636 in epoch 3, gen_loss = 0.8298741166408246, disc_loss = 0.05426570609777733
Trained batch 637 in epoch 3, gen_loss = 0.8297046599530128, disc_loss = 0.05424282502866172
Trained batch 638 in epoch 3, gen_loss = 0.8303064543503178, disc_loss = 0.05421822501021453
Trained batch 639 in epoch 3, gen_loss = 0.8304907785728574, disc_loss = 0.054158033248313586
Trained batch 640 in epoch 3, gen_loss = 0.8303323189107564, disc_loss = 0.05410678486641955
Trained batch 641 in epoch 3, gen_loss = 0.8304530731242765, disc_loss = 0.054083143150204696
Trained batch 642 in epoch 3, gen_loss = 0.830133755322007, disc_loss = 0.05407170142687301
Trained batch 643 in epoch 3, gen_loss = 0.8301487524316918, disc_loss = 0.054003653515300926
Trained batch 644 in epoch 3, gen_loss = 0.830252043498579, disc_loss = 0.05394908725717213
Trained batch 645 in epoch 3, gen_loss = 0.8303286162876862, disc_loss = 0.05387783408325004
Trained batch 646 in epoch 3, gen_loss = 0.8303528871197237, disc_loss = 0.05381060919617886
Trained batch 647 in epoch 3, gen_loss = 0.8303569030982477, disc_loss = 0.05374224529347244
Trained batch 648 in epoch 3, gen_loss = 0.8301927468442403, disc_loss = 0.05369271071037946
Trained batch 649 in epoch 3, gen_loss = 0.8302849435806274, disc_loss = 0.05368362760851876
Trained batch 650 in epoch 3, gen_loss = 0.8300556659515369, disc_loss = 0.05365589337127309
Trained batch 651 in epoch 3, gen_loss = 0.8300112182377306, disc_loss = 0.05365829355407655
Trained batch 652 in epoch 3, gen_loss = 0.8304240440701635, disc_loss = 0.05366916593932939
Trained batch 653 in epoch 3, gen_loss = 0.8301319463537373, disc_loss = 0.05365956355340562
Trained batch 654 in epoch 3, gen_loss = 0.8303572773933411, disc_loss = 0.05359229038768085
Trained batch 655 in epoch 3, gen_loss = 0.8305259028040781, disc_loss = 0.05353325730858359
Trained batch 656 in epoch 3, gen_loss = 0.8306078293007803, disc_loss = 0.053508035361956766
Trained batch 657 in epoch 3, gen_loss = 0.8303031395996233, disc_loss = 0.05349887093340859
Trained batch 658 in epoch 3, gen_loss = 0.8300981762195755, disc_loss = 0.05345431023859595
Trained batch 659 in epoch 3, gen_loss = 0.8303110633835648, disc_loss = 0.053396894342167246
Trained batch 660 in epoch 3, gen_loss = 0.8307090178921075, disc_loss = 0.053369988516500044
Trained batch 661 in epoch 3, gen_loss = 0.8308081424308328, disc_loss = 0.05330276057747364
Trained batch 662 in epoch 3, gen_loss = 0.8305207040514881, disc_loss = 0.053295554900485716
Trained batch 663 in epoch 3, gen_loss = 0.8306278145636421, disc_loss = 0.05322894722143334
Trained batch 664 in epoch 3, gen_loss = 0.8304580198194748, disc_loss = 0.05320439513429607
Trained batch 665 in epoch 3, gen_loss = 0.8305927505185297, disc_loss = 0.05313832173088996
Trained batch 666 in epoch 3, gen_loss = 0.830899804160334, disc_loss = 0.05309353438289794
Trained batch 667 in epoch 3, gen_loss = 0.8307670701942044, disc_loss = 0.05304966716780355
Trained batch 668 in epoch 3, gen_loss = 0.8307454153026701, disc_loss = 0.05299676552252017
Trained batch 669 in epoch 3, gen_loss = 0.8306910261289397, disc_loss = 0.052964745073773856
Trained batch 670 in epoch 3, gen_loss = 0.8307741144019694, disc_loss = 0.05290070857579269
Trained batch 671 in epoch 3, gen_loss = 0.8309296006780296, disc_loss = 0.052844364614256414
Trained batch 672 in epoch 3, gen_loss = 0.8309197300079142, disc_loss = 0.052783429773142466
Trained batch 673 in epoch 3, gen_loss = 0.8305814994018227, disc_loss = 0.05277038806771655
Trained batch 674 in epoch 3, gen_loss = 0.8303141137405678, disc_loss = 0.05278410469043862
Trained batch 675 in epoch 3, gen_loss = 0.8310835713289193, disc_loss = 0.05298087793400996
Trained batch 676 in epoch 3, gen_loss = 0.8312184617825766, disc_loss = 0.05291395848018545
Trained batch 677 in epoch 3, gen_loss = 0.8312926404068252, disc_loss = 0.052852376248443
Trained batch 678 in epoch 3, gen_loss = 0.8308429624089787, disc_loss = 0.053067779711300896
Trained batch 679 in epoch 3, gen_loss = 0.8312229825293317, disc_loss = 0.05301649666576208
Trained batch 680 in epoch 3, gen_loss = 0.831300966452572, disc_loss = 0.052965488850662865
Trained batch 681 in epoch 3, gen_loss = 0.8310873738307057, disc_loss = 0.05295655722600132
Trained batch 682 in epoch 3, gen_loss = 0.8310972388457414, disc_loss = 0.052911695073485525
Trained batch 683 in epoch 3, gen_loss = 0.8312639023302592, disc_loss = 0.052986977629742055
Trained batch 684 in epoch 3, gen_loss = 0.8312241291477732, disc_loss = 0.052963787798232735
Trained batch 685 in epoch 3, gen_loss = 0.8309436796705507, disc_loss = 0.05295057922470011
Trained batch 686 in epoch 3, gen_loss = 0.8309985154580861, disc_loss = 0.052898913879134576
Trained batch 687 in epoch 3, gen_loss = 0.8310069635856984, disc_loss = 0.053063537207700115
Trained batch 688 in epoch 3, gen_loss = 0.8306716509239075, disc_loss = 0.053146855337599344
Trained batch 689 in epoch 3, gen_loss = 0.8302891929944356, disc_loss = 0.05326994583786775
Trained batch 690 in epoch 3, gen_loss = 0.8305491604094223, disc_loss = 0.053377770304925166
Trained batch 691 in epoch 3, gen_loss = 0.8305646014006841, disc_loss = 0.053433425506143536
Trained batch 692 in epoch 3, gen_loss = 0.8303396051580255, disc_loss = 0.053417885412286
Trained batch 693 in epoch 3, gen_loss = 0.8302819648977658, disc_loss = 0.053397253002389
Trained batch 694 in epoch 3, gen_loss = 0.8298214614820137, disc_loss = 0.053533953532455957
Trained batch 695 in epoch 3, gen_loss = 0.8299402549177751, disc_loss = 0.053503966887264734
Trained batch 696 in epoch 3, gen_loss = 0.8301808023384346, disc_loss = 0.05351053830603648
Trained batch 697 in epoch 3, gen_loss = 0.8300500147492974, disc_loss = 0.05348337556663794
Trained batch 698 in epoch 3, gen_loss = 0.8300225597423886, disc_loss = 0.05346707886422002
Trained batch 699 in epoch 3, gen_loss = 0.8299235269853047, disc_loss = 0.053450511142811075
Trained batch 700 in epoch 3, gen_loss = 0.8300635885240008, disc_loss = 0.05346719022759219
Trained batch 701 in epoch 3, gen_loss = 0.8300319751273533, disc_loss = 0.053418533013870895
Trained batch 702 in epoch 3, gen_loss = 0.8296862636317909, disc_loss = 0.05345209553582093
Trained batch 703 in epoch 3, gen_loss = 0.8300790533592756, disc_loss = 0.05355718518330832
Trained batch 704 in epoch 3, gen_loss = 0.8300794869449967, disc_loss = 0.05351795461920506
Trained batch 705 in epoch 3, gen_loss = 0.8297709533918343, disc_loss = 0.05352528106451573
Trained batch 706 in epoch 3, gen_loss = 0.8295980418756963, disc_loss = 0.05352007690652457
Trained batch 707 in epoch 3, gen_loss = 0.8302158297455243, disc_loss = 0.05366060404221417
Trained batch 708 in epoch 3, gen_loss = 0.8298411566884965, disc_loss = 0.053818156012387784
Trained batch 709 in epoch 3, gen_loss = 0.8296489487231617, disc_loss = 0.053773490538571396
Trained batch 710 in epoch 3, gen_loss = 0.8299607821490024, disc_loss = 0.0537578674493706
Trained batch 711 in epoch 3, gen_loss = 0.8300050331300564, disc_loss = 0.053692531319703966
Trained batch 712 in epoch 3, gen_loss = 0.8299703944113946, disc_loss = 0.05362787527988337
Trained batch 713 in epoch 3, gen_loss = 0.829875722485764, disc_loss = 0.053605248658860453
Trained batch 714 in epoch 3, gen_loss = 0.8297620459870025, disc_loss = 0.053545882154607795
Trained batch 715 in epoch 3, gen_loss = 0.829582705844048, disc_loss = 0.05379804511269679
Trained batch 716 in epoch 3, gen_loss = 0.8292789826665796, disc_loss = 0.05384372720576698
Trained batch 717 in epoch 3, gen_loss = 0.829077879034377, disc_loss = 0.053899738608475536
Trained batch 718 in epoch 3, gen_loss = 0.8287474691287533, disc_loss = 0.05393130600909665
Trained batch 719 in epoch 3, gen_loss = 0.8288677756985029, disc_loss = 0.053865577477457315
Trained batch 720 in epoch 3, gen_loss = 0.8288371958117544, disc_loss = 0.05383017603417758
Trained batch 721 in epoch 3, gen_loss = 0.8288600051832331, disc_loss = 0.05379140932774661
Trained batch 722 in epoch 3, gen_loss = 0.8288303114071921, disc_loss = 0.05376124289820684
Trained batch 723 in epoch 3, gen_loss = 0.8287256521414657, disc_loss = 0.05371149686500893
Trained batch 724 in epoch 3, gen_loss = 0.8285178339070287, disc_loss = 0.05367379013095693
Trained batch 725 in epoch 3, gen_loss = 0.8287483235364447, disc_loss = 0.05364709533013393
Trained batch 726 in epoch 3, gen_loss = 0.8290182989925925, disc_loss = 0.053605376344694255
Trained batch 727 in epoch 3, gen_loss = 0.8289387464359567, disc_loss = 0.05355999800715606
Trained batch 728 in epoch 3, gen_loss = 0.8287873525678375, disc_loss = 0.05358867040408624
Trained batch 729 in epoch 3, gen_loss = 0.8289921599708191, disc_loss = 0.0535283498902971
Trained batch 730 in epoch 3, gen_loss = 0.8291734027308088, disc_loss = 0.0535012599308217
Trained batch 731 in epoch 3, gen_loss = 0.8292097304362417, disc_loss = 0.053440703518365516
Trained batch 732 in epoch 3, gen_loss = 0.8291753754934542, disc_loss = 0.053401455183108154
Trained batch 733 in epoch 3, gen_loss = 0.8285813919123902, disc_loss = 0.053603565783813416
Trained batch 734 in epoch 3, gen_loss = 0.8288259544745594, disc_loss = 0.05359968423089456
Trained batch 735 in epoch 3, gen_loss = 0.8290597982299717, disc_loss = 0.053555982988694704
Trained batch 736 in epoch 3, gen_loss = 0.8286668486397819, disc_loss = 0.05359657991486709
Trained batch 737 in epoch 3, gen_loss = 0.8286201432549211, disc_loss = 0.05360794808560362
Trained batch 738 in epoch 3, gen_loss = 0.8285646238168941, disc_loss = 0.05356073145772279
Trained batch 739 in epoch 3, gen_loss = 0.8285338928167885, disc_loss = 0.053522034036310236
Trained batch 740 in epoch 3, gen_loss = 0.8282294343759817, disc_loss = 0.05355472656252182
Trained batch 741 in epoch 3, gen_loss = 0.8283261431436333, disc_loss = 0.05349865888535344
Trained batch 742 in epoch 3, gen_loss = 0.8279886843779527, disc_loss = 0.05349618129709217
Trained batch 743 in epoch 3, gen_loss = 0.8281309847790067, disc_loss = 0.05350355178985234
Trained batch 744 in epoch 3, gen_loss = 0.8278465774635341, disc_loss = 0.05349610792816736
Trained batch 745 in epoch 3, gen_loss = 0.8278860407843986, disc_loss = 0.053451686796991915
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.5707346796989441, disc_loss = 0.11358854919672012
Trained batch 1 in epoch 4, gen_loss = 0.7994519174098969, disc_loss = 0.06628040503710508
Trained batch 2 in epoch 4, gen_loss = 0.8649025360743204, disc_loss = 0.060338376089930534
Trained batch 3 in epoch 4, gen_loss = 0.8290004730224609, disc_loss = 0.05178538849577308
Trained batch 4 in epoch 4, gen_loss = 0.8131198883056641, disc_loss = 0.05390664003789425
Trained batch 5 in epoch 4, gen_loss = 0.826399584611257, disc_loss = 0.05106203599522511
Trained batch 6 in epoch 4, gen_loss = 0.7968918085098267, disc_loss = 0.05594003812542984
Trained batch 7 in epoch 4, gen_loss = 0.7893330082297325, disc_loss = 0.05557116097770631
Trained batch 8 in epoch 4, gen_loss = 0.8087991012467278, disc_loss = 0.0521068185981777
Trained batch 9 in epoch 4, gen_loss = 0.8525778830051423, disc_loss = 0.0667649308219552
Trained batch 10 in epoch 4, gen_loss = 0.8425310416655107, disc_loss = 0.06320707940242508
Trained batch 11 in epoch 4, gen_loss = 0.8145545721054077, disc_loss = 0.06916537042707205
Trained batch 12 in epoch 4, gen_loss = 0.8059139710206252, disc_loss = 0.0690104769399533
Trained batch 13 in epoch 4, gen_loss = 0.8106229560715812, disc_loss = 0.0671027172356844
Trained batch 14 in epoch 4, gen_loss = 0.8034018794695537, disc_loss = 0.06537163133422534
Trained batch 15 in epoch 4, gen_loss = 0.8046011663973331, disc_loss = 0.06235582067165524
Trained batch 16 in epoch 4, gen_loss = 0.8177127873196322, disc_loss = 0.0605176920619081
Trained batch 17 in epoch 4, gen_loss = 0.8224381042851342, disc_loss = 0.05833380400306649
Trained batch 18 in epoch 4, gen_loss = 0.8230657765739843, disc_loss = 0.06017553276921574
Trained batch 19 in epoch 4, gen_loss = 0.8135914742946625, disc_loss = 0.06188637260347605
Trained batch 20 in epoch 4, gen_loss = 0.8059129118919373, disc_loss = 0.06178844418554079
Trained batch 21 in epoch 4, gen_loss = 0.8125582066449252, disc_loss = 0.06099510243670507
Trained batch 22 in epoch 4, gen_loss = 0.8105800592381022, disc_loss = 0.06133543457026067
Trained batch 23 in epoch 4, gen_loss = 0.8145879084865252, disc_loss = 0.06148954962069789
Trained batch 24 in epoch 4, gen_loss = 0.8130047917366028, disc_loss = 0.061136792302131655
Trained batch 25 in epoch 4, gen_loss = 0.8060579552100255, disc_loss = 0.0639906176007711
Trained batch 26 in epoch 4, gen_loss = 0.8116867453963669, disc_loss = 0.0759592448119764
Trained batch 27 in epoch 4, gen_loss = 0.8126241862773895, disc_loss = 0.0744035838704024
Trained batch 28 in epoch 4, gen_loss = 0.8027330678084801, disc_loss = 0.07670390284780798
Trained batch 29 in epoch 4, gen_loss = 0.8092017809549967, disc_loss = 0.0770721409469843
Trained batch 30 in epoch 4, gen_loss = 0.8087902357501369, disc_loss = 0.07660393404864496
Trained batch 31 in epoch 4, gen_loss = 0.8081591054797173, disc_loss = 0.07491771411150694
Trained batch 32 in epoch 4, gen_loss = 0.8018247268416665, disc_loss = 0.07438142597675323
Trained batch 33 in epoch 4, gen_loss = 0.8047593849546769, disc_loss = 0.07495737996171503
Trained batch 34 in epoch 4, gen_loss = 0.8054033534867423, disc_loss = 0.07359257776822363
Trained batch 35 in epoch 4, gen_loss = 0.8082656330532498, disc_loss = 0.07198002983609007
Trained batch 36 in epoch 4, gen_loss = 0.8104637088002385, disc_loss = 0.07021891242648298
Trained batch 37 in epoch 4, gen_loss = 0.8127322855748629, disc_loss = 0.07003120016796809
Trained batch 38 in epoch 4, gen_loss = 0.8096267397587116, disc_loss = 0.06937547684766543
Trained batch 39 in epoch 4, gen_loss = 0.8064910754561424, disc_loss = 0.07180607884656638
Trained batch 40 in epoch 4, gen_loss = 0.8000350434605669, disc_loss = 0.07388119588083611
Trained batch 41 in epoch 4, gen_loss = 0.8017070350192842, disc_loss = 0.0728501366850521
Trained batch 42 in epoch 4, gen_loss = 0.8009478394375291, disc_loss = 0.0715517521034493
Trained batch 43 in epoch 4, gen_loss = 0.807694978334687, disc_loss = 0.07284607549875298
Trained batch 44 in epoch 4, gen_loss = 0.802385143438975, disc_loss = 0.07422827860961358
Trained batch 45 in epoch 4, gen_loss = 0.8059576153755188, disc_loss = 0.07313336490693947
Trained batch 46 in epoch 4, gen_loss = 0.8098604349379844, disc_loss = 0.07241563738739872
Trained batch 47 in epoch 4, gen_loss = 0.8069848579665025, disc_loss = 0.07180702843470499
Trained batch 48 in epoch 4, gen_loss = 0.8131497599640671, disc_loss = 0.07094050998970562
Trained batch 49 in epoch 4, gen_loss = 0.8157750713825226, disc_loss = 0.07003487812355161
Trained batch 50 in epoch 4, gen_loss = 0.8168774293918236, disc_loss = 0.06894819569938324
Trained batch 51 in epoch 4, gen_loss = 0.8118538524095829, disc_loss = 0.06996164155694154
Trained batch 52 in epoch 4, gen_loss = 0.8153909501039757, disc_loss = 0.07172529399394989
Trained batch 53 in epoch 4, gen_loss = 0.8145830741635075, disc_loss = 0.07084153564991774
Trained batch 54 in epoch 4, gen_loss = 0.8118325894529169, disc_loss = 0.071053599904884
Trained batch 55 in epoch 4, gen_loss = 0.8113482743501663, disc_loss = 0.07173450756818056
Trained batch 56 in epoch 4, gen_loss = 0.8124526948259588, disc_loss = 0.07232463882680525
Trained batch 57 in epoch 4, gen_loss = 0.808972435778585, disc_loss = 0.07385598765365009
Trained batch 58 in epoch 4, gen_loss = 0.808153123168622, disc_loss = 0.0744818879638688
Trained batch 59 in epoch 4, gen_loss = 0.8061896026134491, disc_loss = 0.07823181164761385
Trained batch 60 in epoch 4, gen_loss = 0.8065017911254383, disc_loss = 0.07750037062119265
Trained batch 61 in epoch 4, gen_loss = 0.8035289106830474, disc_loss = 0.07755694520329276
Trained batch 62 in epoch 4, gen_loss = 0.8045479343051002, disc_loss = 0.07756014907407383
Trained batch 63 in epoch 4, gen_loss = 0.8085999228060246, disc_loss = 0.0767996423819568
Trained batch 64 in epoch 4, gen_loss = 0.8083525896072388, disc_loss = 0.07611878815178688
Trained batch 65 in epoch 4, gen_loss = 0.8060073599670873, disc_loss = 0.07568377405969483
Trained batch 66 in epoch 4, gen_loss = 0.8068335483323282, disc_loss = 0.07493814156015417
Trained batch 67 in epoch 4, gen_loss = 0.8065591805121478, disc_loss = 0.07409320516950067
Trained batch 68 in epoch 4, gen_loss = 0.8107369274332903, disc_loss = 0.07326462354672991
Trained batch 69 in epoch 4, gen_loss = 0.8101614083562578, disc_loss = 0.07258241328277758
Trained batch 70 in epoch 4, gen_loss = 0.8100532209369499, disc_loss = 0.07202237133513874
Trained batch 71 in epoch 4, gen_loss = 0.8139170855283737, disc_loss = 0.0713850965257734
Trained batch 72 in epoch 4, gen_loss = 0.815836054005035, disc_loss = 0.07052439058276072
Trained batch 73 in epoch 4, gen_loss = 0.8162567309431128, disc_loss = 0.06968380261615321
Trained batch 74 in epoch 4, gen_loss = 0.8162779664993286, disc_loss = 0.06916860409080983
Trained batch 75 in epoch 4, gen_loss = 0.8164204398268148, disc_loss = 0.06847284663174498
Trained batch 76 in epoch 4, gen_loss = 0.8158429613361111, disc_loss = 0.06776222208055196
Trained batch 77 in epoch 4, gen_loss = 0.8152568676532843, disc_loss = 0.06737320143013047
Trained batch 78 in epoch 4, gen_loss = 0.8132709566550919, disc_loss = 0.06755134132042338
Trained batch 79 in epoch 4, gen_loss = 0.8124365769326687, disc_loss = 0.06700282477540895
Trained batch 80 in epoch 4, gen_loss = 0.8183251361788055, disc_loss = 0.06751943985575143
Trained batch 81 in epoch 4, gen_loss = 0.8201654306272181, disc_loss = 0.06707124524499948
Trained batch 82 in epoch 4, gen_loss = 0.8169930282845554, disc_loss = 0.06783239062067616
Trained batch 83 in epoch 4, gen_loss = 0.8150335578691392, disc_loss = 0.06769709443185656
Trained batch 84 in epoch 4, gen_loss = 0.8188300413243911, disc_loss = 0.06945928049219005
Trained batch 85 in epoch 4, gen_loss = 0.8207171455372212, disc_loss = 0.06878736879416676
Trained batch 86 in epoch 4, gen_loss = 0.8184941753573801, disc_loss = 0.06899669239747114
Trained batch 87 in epoch 4, gen_loss = 0.8165384415875782, disc_loss = 0.06893316652117805
Trained batch 88 in epoch 4, gen_loss = 0.8184298571575893, disc_loss = 0.06838624535149403
Trained batch 89 in epoch 4, gen_loss = 0.8191012475225661, disc_loss = 0.0680859559112125
Trained batch 90 in epoch 4, gen_loss = 0.8188011253273094, disc_loss = 0.0676654451577873
Trained batch 91 in epoch 4, gen_loss = 0.8171763744043268, disc_loss = 0.06761799562398506
Trained batch 92 in epoch 4, gen_loss = 0.8177498297024799, disc_loss = 0.06699438096695048
Trained batch 93 in epoch 4, gen_loss = 0.8181382113314689, disc_loss = 0.06636279697549786
Trained batch 94 in epoch 4, gen_loss = 0.81485419147893, disc_loss = 0.0669950861973982
Trained batch 95 in epoch 4, gen_loss = 0.8162452653050423, disc_loss = 0.06645604615914635
Trained batch 96 in epoch 4, gen_loss = 0.8172191922197637, disc_loss = 0.0658248578121444
Trained batch 97 in epoch 4, gen_loss = 0.8178643383541886, disc_loss = 0.0652521213906228
Trained batch 98 in epoch 4, gen_loss = 0.8180797961023119, disc_loss = 0.06467555881468486
Trained batch 99 in epoch 4, gen_loss = 0.8204189735651016, disc_loss = 0.06420755468774587
Trained batch 100 in epoch 4, gen_loss = 0.8201767194389117, disc_loss = 0.06362638121821207
Trained batch 101 in epoch 4, gen_loss = 0.8208584399784312, disc_loss = 0.06305446163933798
Trained batch 102 in epoch 4, gen_loss = 0.8198730795128831, disc_loss = 0.06289592828800522
Trained batch 103 in epoch 4, gen_loss = 0.8192374190458884, disc_loss = 0.06241895950202329
Trained batch 104 in epoch 4, gen_loss = 0.8197500773838589, disc_loss = 0.06189319087369811
Trained batch 105 in epoch 4, gen_loss = 0.8204163830235319, disc_loss = 0.06281847682922094
Trained batch 106 in epoch 4, gen_loss = 0.818034691231273, disc_loss = 0.06289651321908721
Trained batch 107 in epoch 4, gen_loss = 0.8163879922142735, disc_loss = 0.062995848698645
Trained batch 108 in epoch 4, gen_loss = 0.8175395584981376, disc_loss = 0.06295878878034172
Trained batch 109 in epoch 4, gen_loss = 0.8162283794446425, disc_loss = 0.06340509849939156
Trained batch 110 in epoch 4, gen_loss = 0.8177998898265598, disc_loss = 0.06306656552814283
Trained batch 111 in epoch 4, gen_loss = 0.8199202051120145, disc_loss = 0.06324443648918532
Trained batch 112 in epoch 4, gen_loss = 0.8181465067694672, disc_loss = 0.06347153212594907
Trained batch 113 in epoch 4, gen_loss = 0.8177730493378221, disc_loss = 0.06306177443465251
Trained batch 114 in epoch 4, gen_loss = 0.8186158708904101, disc_loss = 0.06256283032100486
Trained batch 115 in epoch 4, gen_loss = 0.8184307304949596, disc_loss = 0.06237001963971375
Trained batch 116 in epoch 4, gen_loss = 0.818549308511946, disc_loss = 0.0620228381962794
Trained batch 117 in epoch 4, gen_loss = 0.8199631657640812, disc_loss = 0.06158421095066025
Trained batch 118 in epoch 4, gen_loss = 0.8204323173571033, disc_loss = 0.061308762211227365
Trained batch 119 in epoch 4, gen_loss = 0.8196867595116297, disc_loss = 0.06104910891735926
Trained batch 120 in epoch 4, gen_loss = 0.8215897851739048, disc_loss = 0.061873918318397496
Trained batch 121 in epoch 4, gen_loss = 0.8194797224685794, disc_loss = 0.06232813644589337
Trained batch 122 in epoch 4, gen_loss = 0.8192435270402489, disc_loss = 0.06285223688521399
Trained batch 123 in epoch 4, gen_loss = 0.816597577785292, disc_loss = 0.06299761883659108
Trained batch 124 in epoch 4, gen_loss = 0.816946679353714, disc_loss = 0.062661207344383
Trained batch 125 in epoch 4, gen_loss = 0.8172181444981742, disc_loss = 0.06339881098681381
Trained batch 126 in epoch 4, gen_loss = 0.817872776994555, disc_loss = 0.06327064563776916
Trained batch 127 in epoch 4, gen_loss = 0.8158132394310087, disc_loss = 0.0637173388931842
Trained batch 128 in epoch 4, gen_loss = 0.8140621210715567, disc_loss = 0.06380447109641377
Trained batch 129 in epoch 4, gen_loss = 0.8144923336230792, disc_loss = 0.06345884484382203
Trained batch 130 in epoch 4, gen_loss = 0.8174430411735564, disc_loss = 0.06490043607248946
Trained batch 131 in epoch 4, gen_loss = 0.8164528064203985, disc_loss = 0.06488317391962152
Trained batch 132 in epoch 4, gen_loss = 0.8151251366712097, disc_loss = 0.06516221473413639
Trained batch 133 in epoch 4, gen_loss = 0.814679665574387, disc_loss = 0.06514110023836925
Trained batch 134 in epoch 4, gen_loss = 0.8167608916759491, disc_loss = 0.06531301711651462
Trained batch 135 in epoch 4, gen_loss = 0.8169316528912853, disc_loss = 0.06494148988756077
Trained batch 136 in epoch 4, gen_loss = 0.8158232402192415, disc_loss = 0.06475671884828131
Trained batch 137 in epoch 4, gen_loss = 0.8149323491514593, disc_loss = 0.06450955056504387
Trained batch 138 in epoch 4, gen_loss = 0.8142466225641237, disc_loss = 0.06409641353266059
Trained batch 139 in epoch 4, gen_loss = 0.8157704572592462, disc_loss = 0.06407261957148357
Trained batch 140 in epoch 4, gen_loss = 0.8160923658110572, disc_loss = 0.06369295354324875
Trained batch 141 in epoch 4, gen_loss = 0.8154329378420199, disc_loss = 0.06384280300371244
Trained batch 142 in epoch 4, gen_loss = 0.8144541480741301, disc_loss = 0.06377958613154772
Trained batch 143 in epoch 4, gen_loss = 0.8159146054337422, disc_loss = 0.06342265294450852
Trained batch 144 in epoch 4, gen_loss = 0.8157856334900034, disc_loss = 0.06390635746306386
Trained batch 145 in epoch 4, gen_loss = 0.8152293107689244, disc_loss = 0.06357398407202061
Trained batch 146 in epoch 4, gen_loss = 0.8136319220066071, disc_loss = 0.06376237363941005
Trained batch 147 in epoch 4, gen_loss = 0.8166363277548069, disc_loss = 0.06389465895355553
Trained batch 148 in epoch 4, gen_loss = 0.8163062356062384, disc_loss = 0.06360798951663427
Trained batch 149 in epoch 4, gen_loss = 0.8160756228367487, disc_loss = 0.06329023183633883
Trained batch 150 in epoch 4, gen_loss = 0.8162252936536902, disc_loss = 0.06291063859540698
Trained batch 151 in epoch 4, gen_loss = 0.8161718443428215, disc_loss = 0.06257882177535641
Trained batch 152 in epoch 4, gen_loss = 0.8170764436519223, disc_loss = 0.06244586493357334
Trained batch 153 in epoch 4, gen_loss = 0.817312977337218, disc_loss = 0.06225874420110281
Trained batch 154 in epoch 4, gen_loss = 0.8169073933555234, disc_loss = 0.062100429400320976
Trained batch 155 in epoch 4, gen_loss = 0.8164277888643436, disc_loss = 0.06183023965702607
Trained batch 156 in epoch 4, gen_loss = 0.8189328667844177, disc_loss = 0.06316178946927854
Trained batch 157 in epoch 4, gen_loss = 0.8173593775003771, disc_loss = 0.0635579412779476
Trained batch 158 in epoch 4, gen_loss = 0.8166988149004163, disc_loss = 0.06326825704730157
Trained batch 159 in epoch 4, gen_loss = 0.8156470408663153, disc_loss = 0.0631984359701164
Trained batch 160 in epoch 4, gen_loss = 0.8152567953426645, disc_loss = 0.0630753688537371
Trained batch 161 in epoch 4, gen_loss = 0.8145380735765269, disc_loss = 0.06311578040275677
Trained batch 162 in epoch 4, gen_loss = 0.8146920158453514, disc_loss = 0.06384722206261625
Trained batch 163 in epoch 4, gen_loss = 0.8143821567660425, disc_loss = 0.06365818247517072
Trained batch 164 in epoch 4, gen_loss = 0.8143562690778212, disc_loss = 0.06401120694071957
Trained batch 165 in epoch 4, gen_loss = 0.8126985813120762, disc_loss = 0.06451094122491328
Trained batch 166 in epoch 4, gen_loss = 0.8119143931094758, disc_loss = 0.06498454875887154
Trained batch 167 in epoch 4, gen_loss = 0.8130511781644254, disc_loss = 0.06527159047046942
Trained batch 168 in epoch 4, gen_loss = 0.8130761277393477, disc_loss = 0.06527244624786475
Trained batch 169 in epoch 4, gen_loss = 0.8127288550138474, disc_loss = 0.06503929181353134
Trained batch 170 in epoch 4, gen_loss = 0.8113908162939618, disc_loss = 0.06500538496289686
Trained batch 171 in epoch 4, gen_loss = 0.8113899218828179, disc_loss = 0.06468765126801161
Trained batch 172 in epoch 4, gen_loss = 0.8109210483256103, disc_loss = 0.06454709395120255
Trained batch 173 in epoch 4, gen_loss = 0.8107800327840893, disc_loss = 0.06424711133492575
Trained batch 174 in epoch 4, gen_loss = 0.8119113739899226, disc_loss = 0.06412896691156285
Trained batch 175 in epoch 4, gen_loss = 0.8115170511671088, disc_loss = 0.06387542542175982
Trained batch 176 in epoch 4, gen_loss = 0.8114987269969983, disc_loss = 0.06369117927858553
Trained batch 177 in epoch 4, gen_loss = 0.8117965843235508, disc_loss = 0.06380395070660148
Trained batch 178 in epoch 4, gen_loss = 0.8107636529307126, disc_loss = 0.0639957468696563
Trained batch 179 in epoch 4, gen_loss = 0.8112034805946879, disc_loss = 0.06372475182223651
Trained batch 180 in epoch 4, gen_loss = 0.8116836213604521, disc_loss = 0.06356990268423084
Trained batch 181 in epoch 4, gen_loss = 0.8115198659700352, disc_loss = 0.06336468500136347
Trained batch 182 in epoch 4, gen_loss = 0.810950229891011, disc_loss = 0.06319272741064673
Trained batch 183 in epoch 4, gen_loss = 0.8117838714109815, disc_loss = 0.0630188742450074
Trained batch 184 in epoch 4, gen_loss = 0.8108446300029755, disc_loss = 0.06326559498100667
Trained batch 185 in epoch 4, gen_loss = 0.8114758000899387, disc_loss = 0.06315346911389341
Trained batch 186 in epoch 4, gen_loss = 0.8117829263210297, disc_loss = 0.06287977361384241
Trained batch 187 in epoch 4, gen_loss = 0.8107271192872778, disc_loss = 0.06284670227583736
Trained batch 188 in epoch 4, gen_loss = 0.8104583956892528, disc_loss = 0.06386716243017602
Trained batch 189 in epoch 4, gen_loss = 0.8094505841794767, disc_loss = 0.06390389479500683
Trained batch 190 in epoch 4, gen_loss = 0.8087389926323716, disc_loss = 0.06392220919707994
Trained batch 191 in epoch 4, gen_loss = 0.8100573148888847, disc_loss = 0.06463818951548699
Trained batch 192 in epoch 4, gen_loss = 0.809136206776367, disc_loss = 0.06481152356944862
Trained batch 193 in epoch 4, gen_loss = 0.8083436988370934, disc_loss = 0.06483407530779998
Trained batch 194 in epoch 4, gen_loss = 0.8093001422209617, disc_loss = 0.06482958095387006
Trained batch 195 in epoch 4, gen_loss = 0.808216032781163, disc_loss = 0.06483186497257984
Trained batch 196 in epoch 4, gen_loss = 0.8092043640347302, disc_loss = 0.0646618040288009
Trained batch 197 in epoch 4, gen_loss = 0.8081105988134037, disc_loss = 0.06481063481646054
Trained batch 198 in epoch 4, gen_loss = 0.8086550797349844, disc_loss = 0.06453043133507122
Trained batch 199 in epoch 4, gen_loss = 0.8099356584250927, disc_loss = 0.06494683095254004
Trained batch 200 in epoch 4, gen_loss = 0.8090851145300699, disc_loss = 0.06499580609894808
Trained batch 201 in epoch 4, gen_loss = 0.8093803824469594, disc_loss = 0.06475775493401112
Trained batch 202 in epoch 4, gen_loss = 0.8091120389588361, disc_loss = 0.06451484576564998
Trained batch 203 in epoch 4, gen_loss = 0.8101089303107822, disc_loss = 0.06425729353327815
Trained batch 204 in epoch 4, gen_loss = 0.8094863291193799, disc_loss = 0.06423181918245263
Trained batch 205 in epoch 4, gen_loss = 0.8111607795490802, disc_loss = 0.06407620708539503
Trained batch 206 in epoch 4, gen_loss = 0.8114084355209185, disc_loss = 0.06402005557114808
Trained batch 207 in epoch 4, gen_loss = 0.810511068512614, disc_loss = 0.06414734242179503
Trained batch 208 in epoch 4, gen_loss = 0.8094721281072169, disc_loss = 0.06409353995918515
Trained batch 209 in epoch 4, gen_loss = 0.8105527158294406, disc_loss = 0.06402735507470511
Trained batch 210 in epoch 4, gen_loss = 0.8116007909108113, disc_loss = 0.06390448722776502
Trained batch 211 in epoch 4, gen_loss = 0.8121812302830085, disc_loss = 0.0636618697866446
Trained batch 212 in epoch 4, gen_loss = 0.8121912444421383, disc_loss = 0.06358867209894417
Trained batch 213 in epoch 4, gen_loss = 0.8115962564109642, disc_loss = 0.0635356841930928
Trained batch 214 in epoch 4, gen_loss = 0.8113597436006679, disc_loss = 0.06334947350673205
Trained batch 215 in epoch 4, gen_loss = 0.8122130686210262, disc_loss = 0.06373024058821439
Trained batch 216 in epoch 4, gen_loss = 0.8122384524839814, disc_loss = 0.06361400400833463
Trained batch 217 in epoch 4, gen_loss = 0.813060929879136, disc_loss = 0.06340102907355635
Trained batch 218 in epoch 4, gen_loss = 0.8129043681164311, disc_loss = 0.06326732352018764
Trained batch 219 in epoch 4, gen_loss = 0.8152897188609297, disc_loss = 0.06331584822301838
Trained batch 220 in epoch 4, gen_loss = 0.8164230562173403, disc_loss = 0.06333682254142216
Trained batch 221 in epoch 4, gen_loss = 0.8158481825847883, disc_loss = 0.06347862949494172
Trained batch 222 in epoch 4, gen_loss = 0.8161421900640154, disc_loss = 0.063274368572763
Trained batch 223 in epoch 4, gen_loss = 0.8160859017765948, disc_loss = 0.06308896030947965
Trained batch 224 in epoch 4, gen_loss = 0.8164574150244395, disc_loss = 0.06284046975895763
Trained batch 225 in epoch 4, gen_loss = 0.8173484758729428, disc_loss = 0.06259468246243102
Trained batch 226 in epoch 4, gen_loss = 0.8169723364487619, disc_loss = 0.06243741724615515
Trained batch 227 in epoch 4, gen_loss = 0.8174192535511234, disc_loss = 0.062213339710101616
Trained batch 228 in epoch 4, gen_loss = 0.8174592637859578, disc_loss = 0.06203205556319986
Trained batch 229 in epoch 4, gen_loss = 0.8179926705101263, disc_loss = 0.061826408150322414
Trained batch 230 in epoch 4, gen_loss = 0.8177817005873759, disc_loss = 0.06163079509092293
Trained batch 231 in epoch 4, gen_loss = 0.819024303221497, disc_loss = 0.06158677027520627
Trained batch 232 in epoch 4, gen_loss = 0.8196536032682836, disc_loss = 0.061361523878724664
Trained batch 233 in epoch 4, gen_loss = 0.8197888453037311, disc_loss = 0.061158942104452566
Trained batch 234 in epoch 4, gen_loss = 0.8198695341323284, disc_loss = 0.06095447581301027
Trained batch 235 in epoch 4, gen_loss = 0.8200816621972342, disc_loss = 0.06074990897036899
Trained batch 236 in epoch 4, gen_loss = 0.8200611428117953, disc_loss = 0.0605114968513229
Trained batch 237 in epoch 4, gen_loss = 0.8204272934118239, disc_loss = 0.06027602654991343
Trained batch 238 in epoch 4, gen_loss = 0.8206746427334503, disc_loss = 0.060049138789817255
Trained batch 239 in epoch 4, gen_loss = 0.8210702902326982, disc_loss = 0.06002548555649507
Trained batch 240 in epoch 4, gen_loss = 0.820947623970103, disc_loss = 0.059856858048433464
Trained batch 241 in epoch 4, gen_loss = 0.8208141254245742, disc_loss = 0.059695550407983425
Trained batch 242 in epoch 4, gen_loss = 0.8200505499731857, disc_loss = 0.05959144800924408
Trained batch 243 in epoch 4, gen_loss = 0.8203309533781693, disc_loss = 0.05940574327613548
Trained batch 244 in epoch 4, gen_loss = 0.8211264759910349, disc_loss = 0.0595643256334778
Trained batch 245 in epoch 4, gen_loss = 0.8221606955053361, disc_loss = 0.05937004429136774
Trained batch 246 in epoch 4, gen_loss = 0.8211781345157005, disc_loss = 0.05952913534869006
Trained batch 247 in epoch 4, gen_loss = 0.8210030530969943, disc_loss = 0.05939798722336549
Trained batch 248 in epoch 4, gen_loss = 0.8218429975480919, disc_loss = 0.05924632821987611
Trained batch 249 in epoch 4, gen_loss = 0.8231166673898697, disc_loss = 0.0592343003731221
Trained batch 250 in epoch 4, gen_loss = 0.8225626979928568, disc_loss = 0.059183855305436954
Trained batch 251 in epoch 4, gen_loss = 0.8231414146130047, disc_loss = 0.05900770148062812
Trained batch 252 in epoch 4, gen_loss = 0.822064691028105, disc_loss = 0.05914135895882965
Trained batch 253 in epoch 4, gen_loss = 0.8232308693054154, disc_loss = 0.05905519470051811
Trained batch 254 in epoch 4, gen_loss = 0.8233757665344313, disc_loss = 0.058943522854835964
Trained batch 255 in epoch 4, gen_loss = 0.8232675170293078, disc_loss = 0.05881075727120333
Trained batch 256 in epoch 4, gen_loss = 0.822953604886504, disc_loss = 0.05868776969734855
Trained batch 257 in epoch 4, gen_loss = 0.8227776227764381, disc_loss = 0.058540048339411385
Trained batch 258 in epoch 4, gen_loss = 0.8235037808942979, disc_loss = 0.05842045834288001
Trained batch 259 in epoch 4, gen_loss = 0.8236996493660487, disc_loss = 0.05830427323862051
Trained batch 260 in epoch 4, gen_loss = 0.8240970986327906, disc_loss = 0.05845876953161368
Trained batch 261 in epoch 4, gen_loss = 0.8228927260364285, disc_loss = 0.05867475614072542
Trained batch 262 in epoch 4, gen_loss = 0.8220614730858531, disc_loss = 0.058644101620357866
Trained batch 263 in epoch 4, gen_loss = 0.8217695726815498, disc_loss = 0.058705985124547486
Trained batch 264 in epoch 4, gen_loss = 0.8223221896954303, disc_loss = 0.05864654249634664
Trained batch 265 in epoch 4, gen_loss = 0.823135495746046, disc_loss = 0.058509080637512464
Trained batch 266 in epoch 4, gen_loss = 0.8223353453566519, disc_loss = 0.05868689979737004
Trained batch 267 in epoch 4, gen_loss = 0.8220649525078375, disc_loss = 0.05864051957579969
Trained batch 268 in epoch 4, gen_loss = 0.8231555727556292, disc_loss = 0.05848603506077455
Trained batch 269 in epoch 4, gen_loss = 0.8238210805036403, disc_loss = 0.05835843594158413
Trained batch 270 in epoch 4, gen_loss = 0.8242988218020689, disc_loss = 0.05816282598109318
Trained batch 271 in epoch 4, gen_loss = 0.8240022515768514, disc_loss = 0.05822992721497191
Trained batch 272 in epoch 4, gen_loss = 0.8233486880094577, disc_loss = 0.058174501840134354
Trained batch 273 in epoch 4, gen_loss = 0.8227794430334202, disc_loss = 0.05806923798543748
Trained batch 274 in epoch 4, gen_loss = 0.8232767205888575, disc_loss = 0.05788911285217513
Trained batch 275 in epoch 4, gen_loss = 0.8231273599076963, disc_loss = 0.05783246270806083
Trained batch 276 in epoch 4, gen_loss = 0.8229234942675497, disc_loss = 0.05838937435588305
Trained batch 277 in epoch 4, gen_loss = 0.8227325177235569, disc_loss = 0.05838719327438274
Trained batch 278 in epoch 4, gen_loss = 0.8225773753444781, disc_loss = 0.05826681169537714
Trained batch 279 in epoch 4, gen_loss = 0.8224303829882826, disc_loss = 0.058135037551567494
Trained batch 280 in epoch 4, gen_loss = 0.8227933669641773, disc_loss = 0.05806513079127224
Trained batch 281 in epoch 4, gen_loss = 0.8229483183182723, disc_loss = 0.05794771803800571
Trained batch 282 in epoch 4, gen_loss = 0.8227592952049242, disc_loss = 0.05784005750885542
Trained batch 283 in epoch 4, gen_loss = 0.823095445586762, disc_loss = 0.057682066331092845
Trained batch 284 in epoch 4, gen_loss = 0.8234752296355733, disc_loss = 0.0575059118533605
Trained batch 285 in epoch 4, gen_loss = 0.8237677838627275, disc_loss = 0.057327002648368375
Trained batch 286 in epoch 4, gen_loss = 0.8234415250580486, disc_loss = 0.057163284124501494
Trained batch 287 in epoch 4, gen_loss = 0.8242352808722191, disc_loss = 0.05700636869490457
Trained batch 288 in epoch 4, gen_loss = 0.824359847909439, disc_loss = 0.057333916963874056
Trained batch 289 in epoch 4, gen_loss = 0.8239631586033722, disc_loss = 0.05724139584485313
Trained batch 290 in epoch 4, gen_loss = 0.823121757953847, disc_loss = 0.057375146002473495
Trained batch 291 in epoch 4, gen_loss = 0.823277147563353, disc_loss = 0.05731867956418595
Trained batch 292 in epoch 4, gen_loss = 0.8242865828320435, disc_loss = 0.05734600613383201
Trained batch 293 in epoch 4, gen_loss = 0.8242513765485919, disc_loss = 0.05720232980528555
Trained batch 294 in epoch 4, gen_loss = 0.8242160878949246, disc_loss = 0.05704012399192079
Trained batch 295 in epoch 4, gen_loss = 0.8243937996795049, disc_loss = 0.05781102701203545
Trained batch 296 in epoch 4, gen_loss = 0.8234020677279141, disc_loss = 0.05796186748565949
Trained batch 297 in epoch 4, gen_loss = 0.8224138920539178, disc_loss = 0.05815700056256364
Trained batch 298 in epoch 4, gen_loss = 0.8227497932304906, disc_loss = 0.058705030822111016
Trained batch 299 in epoch 4, gen_loss = 0.8219838175177574, disc_loss = 0.05885266564475993
Trained batch 300 in epoch 4, gen_loss = 0.8220233771690103, disc_loss = 0.05878974858399146
Trained batch 301 in epoch 4, gen_loss = 0.8225106447935104, disc_loss = 0.05878965992986268
Trained batch 302 in epoch 4, gen_loss = 0.8225085043867822, disc_loss = 0.05867197527780686
Trained batch 303 in epoch 4, gen_loss = 0.8224624176754763, disc_loss = 0.05859608642793702
Trained batch 304 in epoch 4, gen_loss = 0.8222496600424657, disc_loss = 0.05844625687135047
Trained batch 305 in epoch 4, gen_loss = 0.8220739472730487, disc_loss = 0.05865180943453429
Trained batch 306 in epoch 4, gen_loss = 0.8214304065665515, disc_loss = 0.05859568485146819
Trained batch 307 in epoch 4, gen_loss = 0.8213426396250725, disc_loss = 0.05858323423724089
Trained batch 308 in epoch 4, gen_loss = 0.8214825982993474, disc_loss = 0.058441468963586395
Trained batch 309 in epoch 4, gen_loss = 0.8214099586971344, disc_loss = 0.05831601821607159
Trained batch 310 in epoch 4, gen_loss = 0.8216434217917574, disc_loss = 0.05822692544370219
Trained batch 311 in epoch 4, gen_loss = 0.8212781933446726, disc_loss = 0.05818106017959041
Trained batch 312 in epoch 4, gen_loss = 0.8213475452253993, disc_loss = 0.058259294496271936
Trained batch 313 in epoch 4, gen_loss = 0.8214760683714204, disc_loss = 0.058112536186269326
Trained batch 314 in epoch 4, gen_loss = 0.8219017217083583, disc_loss = 0.05795636089548232
Trained batch 315 in epoch 4, gen_loss = 0.8221875852610492, disc_loss = 0.05784117754643099
Trained batch 316 in epoch 4, gen_loss = 0.8225428314427096, disc_loss = 0.057727540152776126
Trained batch 317 in epoch 4, gen_loss = 0.8228952495744394, disc_loss = 0.05757639160578918
Trained batch 318 in epoch 4, gen_loss = 0.8229464340172591, disc_loss = 0.05742582466838689
Trained batch 319 in epoch 4, gen_loss = 0.8229017409496009, disc_loss = 0.05730953787569888
Trained batch 320 in epoch 4, gen_loss = 0.823043211134052, disc_loss = 0.05714590048469673
Trained batch 321 in epoch 4, gen_loss = 0.822984324941724, disc_loss = 0.05698130807336073
Trained batch 322 in epoch 4, gen_loss = 0.8230834296059683, disc_loss = 0.056881061325501366
Trained batch 323 in epoch 4, gen_loss = 0.8232641108793977, disc_loss = 0.05672903698265414
Trained batch 324 in epoch 4, gen_loss = 0.8230797786896046, disc_loss = 0.05658102640309013
Trained batch 325 in epoch 4, gen_loss = 0.823046389075876, disc_loss = 0.05644362060884528
Trained batch 326 in epoch 4, gen_loss = 0.8232157378933116, disc_loss = 0.05628493539732667
Trained batch 327 in epoch 4, gen_loss = 0.8237261067985034, disc_loss = 0.05614809809031147
Trained batch 328 in epoch 4, gen_loss = 0.8242246121802228, disc_loss = 0.05600246314757636
Trained batch 329 in epoch 4, gen_loss = 0.8241910144235148, disc_loss = 0.055850397650096
Trained batch 330 in epoch 4, gen_loss = 0.8241277310963484, disc_loss = 0.055695550395260224
Trained batch 331 in epoch 4, gen_loss = 0.8241897728967379, disc_loss = 0.05554478179175317
Trained batch 332 in epoch 4, gen_loss = 0.8240959582565067, disc_loss = 0.055387801956385374
Trained batch 333 in epoch 4, gen_loss = 0.824481835889959, disc_loss = 0.05533150587269958
Trained batch 334 in epoch 4, gen_loss = 0.8244341998847563, disc_loss = 0.05519743372561104
Trained batch 335 in epoch 4, gen_loss = 0.8245046540562596, disc_loss = 0.055051633870572825
Trained batch 336 in epoch 4, gen_loss = 0.8247874054604539, disc_loss = 0.05511994629363234
Trained batch 337 in epoch 4, gen_loss = 0.8246877035622061, disc_loss = 0.05500259105882128
Trained batch 338 in epoch 4, gen_loss = 0.8244582447154684, disc_loss = 0.05491260614295581
Trained batch 339 in epoch 4, gen_loss = 0.8245149111923049, disc_loss = 0.054772778671673114
Trained batch 340 in epoch 4, gen_loss = 0.8246637176383625, disc_loss = 0.05462837396489997
Trained batch 341 in epoch 4, gen_loss = 0.8248483447129267, disc_loss = 0.05450870755417218
Trained batch 342 in epoch 4, gen_loss = 0.8243558897742724, disc_loss = 0.05448903342975037
Trained batch 343 in epoch 4, gen_loss = 0.8237326568815597, disc_loss = 0.05445646134822434
Trained batch 344 in epoch 4, gen_loss = 0.8244839375433715, disc_loss = 0.05448149749064359
Trained batch 345 in epoch 4, gen_loss = 0.8247124903291636, disc_loss = 0.05437794649392108
Trained batch 346 in epoch 4, gen_loss = 0.8247292363849772, disc_loss = 0.054257964395974315
Trained batch 347 in epoch 4, gen_loss = 0.8252323830778572, disc_loss = 0.054164312413262056
Trained batch 348 in epoch 4, gen_loss = 0.8258639480972017, disc_loss = 0.05408633403469379
Trained batch 349 in epoch 4, gen_loss = 0.8253884793179376, disc_loss = 0.05407273397115724
Trained batch 350 in epoch 4, gen_loss = 0.8257605036948821, disc_loss = 0.05397540615059626
Trained batch 351 in epoch 4, gen_loss = 0.8258853641931306, disc_loss = 0.05416532813052816
Trained batch 352 in epoch 4, gen_loss = 0.8261604909349771, disc_loss = 0.054121879694545405
Trained batch 353 in epoch 4, gen_loss = 0.8253065511836843, disc_loss = 0.05423462489556711
Trained batch 354 in epoch 4, gen_loss = 0.8252566481140298, disc_loss = 0.05415177164520596
Trained batch 355 in epoch 4, gen_loss = 0.8251860080642647, disc_loss = 0.05407354608439746
Trained batch 356 in epoch 4, gen_loss = 0.8257935270040977, disc_loss = 0.05397978178499376
Trained batch 357 in epoch 4, gen_loss = 0.826245432542689, disc_loss = 0.05390312873586679
Trained batch 358 in epoch 4, gen_loss = 0.8258302081428198, disc_loss = 0.05381060646675672
Trained batch 359 in epoch 4, gen_loss = 0.8256983338958688, disc_loss = 0.05368635779660609
Trained batch 360 in epoch 4, gen_loss = 0.8252184776553156, disc_loss = 0.053638740084095346
Trained batch 361 in epoch 4, gen_loss = 0.8253768722820018, disc_loss = 0.05352106196445655
Trained batch 362 in epoch 4, gen_loss = 0.8252980117134483, disc_loss = 0.05338821649941367
Trained batch 363 in epoch 4, gen_loss = 0.8252394732374412, disc_loss = 0.053343669403917514
Trained batch 364 in epoch 4, gen_loss = 0.8251365118647275, disc_loss = 0.053237475880919254
Trained batch 365 in epoch 4, gen_loss = 0.825381321578078, disc_loss = 0.05348626336673162
Trained batch 366 in epoch 4, gen_loss = 0.8246925962880781, disc_loss = 0.054317023389406846
Trained batch 367 in epoch 4, gen_loss = 0.8248651914460503, disc_loss = 0.05433325889348255
Trained batch 368 in epoch 4, gen_loss = 0.8251988337776526, disc_loss = 0.05432524940700631
Trained batch 369 in epoch 4, gen_loss = 0.8247174742254051, disc_loss = 0.05433848224127212
Trained batch 370 in epoch 4, gen_loss = 0.8244343548611489, disc_loss = 0.05424287269328723
Trained batch 371 in epoch 4, gen_loss = 0.8248289252320925, disc_loss = 0.054182052369459825
Trained batch 372 in epoch 4, gen_loss = 0.8248195263879229, disc_loss = 0.05407712997833701
Trained batch 373 in epoch 4, gen_loss = 0.8250111858634388, disc_loss = 0.05397182904721741
Trained batch 374 in epoch 4, gen_loss = 0.8248195553620656, disc_loss = 0.05397459003825982
Trained batch 375 in epoch 4, gen_loss = 0.8252813716993687, disc_loss = 0.05444019233827737
Trained batch 376 in epoch 4, gen_loss = 0.8241870243606264, disc_loss = 0.05512439534166921
Trained batch 377 in epoch 4, gen_loss = 0.8236045611913873, disc_loss = 0.05514245103335097
Trained batch 378 in epoch 4, gen_loss = 0.8228954487236949, disc_loss = 0.055390578633208704
Trained batch 379 in epoch 4, gen_loss = 0.8236043646147376, disc_loss = 0.0556577376384092
Trained batch 380 in epoch 4, gen_loss = 0.8229709449089732, disc_loss = 0.05581249796792748
Trained batch 381 in epoch 4, gen_loss = 0.8226690684001483, disc_loss = 0.055808524864467336
Trained batch 382 in epoch 4, gen_loss = 0.8223169883299746, disc_loss = 0.055887669689622624
Trained batch 383 in epoch 4, gen_loss = 0.8220229184565445, disc_loss = 0.05605921402942234
Trained batch 384 in epoch 4, gen_loss = 0.8219635577944966, disc_loss = 0.055959037444614744
Trained batch 385 in epoch 4, gen_loss = 0.8223995754755841, disc_loss = 0.055936422956615224
Trained batch 386 in epoch 4, gen_loss = 0.8222870041233624, disc_loss = 0.05583972569545418
Trained batch 387 in epoch 4, gen_loss = 0.8219600341369196, disc_loss = 0.055922304798570494
Trained batch 388 in epoch 4, gen_loss = 0.8213836840308417, disc_loss = 0.05594745740907358
Trained batch 389 in epoch 4, gen_loss = 0.8215773310416784, disc_loss = 0.055828823770085974
Trained batch 390 in epoch 4, gen_loss = 0.8213467357103782, disc_loss = 0.0559180443034605
Trained batch 391 in epoch 4, gen_loss = 0.8211633170745811, disc_loss = 0.0558881007838158
Trained batch 392 in epoch 4, gen_loss = 0.8216769758981602, disc_loss = 0.05586310022963216
Trained batch 393 in epoch 4, gen_loss = 0.8220692812488769, disc_loss = 0.05573674412396959
Trained batch 394 in epoch 4, gen_loss = 0.8215164163444616, disc_loss = 0.05584812567958349
Trained batch 395 in epoch 4, gen_loss = 0.8215141258757523, disc_loss = 0.055766380161536164
Trained batch 396 in epoch 4, gen_loss = 0.8221260352759278, disc_loss = 0.055692749609349654
Trained batch 397 in epoch 4, gen_loss = 0.8222887849987451, disc_loss = 0.05559604467084659
Trained batch 398 in epoch 4, gen_loss = 0.8220639956326115, disc_loss = 0.05551229731032723
Trained batch 399 in epoch 4, gen_loss = 0.8222075663506985, disc_loss = 0.05546006958000362
Trained batch 400 in epoch 4, gen_loss = 0.8225580575757491, disc_loss = 0.055589334802362986
Trained batch 401 in epoch 4, gen_loss = 0.8224723247153249, disc_loss = 0.05552038168117626
Trained batch 402 in epoch 4, gen_loss = 0.8221790194511414, disc_loss = 0.05558587747069062
Trained batch 403 in epoch 4, gen_loss = 0.8222879736435296, disc_loss = 0.05548079788804718
Trained batch 404 in epoch 4, gen_loss = 0.8228207733896044, disc_loss = 0.05538242121031623
Trained batch 405 in epoch 4, gen_loss = 0.8231741280978536, disc_loss = 0.05552519859947962
Trained batch 406 in epoch 4, gen_loss = 0.8227354460910732, disc_loss = 0.05559025370087978
Trained batch 407 in epoch 4, gen_loss = 0.823153953926236, disc_loss = 0.05551474730657669
Trained batch 408 in epoch 4, gen_loss = 0.8228713083092333, disc_loss = 0.05567902036257143
Trained batch 409 in epoch 4, gen_loss = 0.8227302687924083, disc_loss = 0.05561486336561601
Trained batch 410 in epoch 4, gen_loss = 0.8224327545386452, disc_loss = 0.05557275851939209
Trained batch 411 in epoch 4, gen_loss = 0.8220662516586988, disc_loss = 0.05554873805755334
Trained batch 412 in epoch 4, gen_loss = 0.8222314187169941, disc_loss = 0.05549684370085416
Trained batch 413 in epoch 4, gen_loss = 0.821837537098622, disc_loss = 0.05554080496492665
Trained batch 414 in epoch 4, gen_loss = 0.8228377636656704, disc_loss = 0.056213800638285745
Trained batch 415 in epoch 4, gen_loss = 0.8230236464968095, disc_loss = 0.056103627844444975
Trained batch 416 in epoch 4, gen_loss = 0.8225819847280744, disc_loss = 0.05616166276691986
Trained batch 417 in epoch 4, gen_loss = 0.822754053407879, disc_loss = 0.05610377170617857
Trained batch 418 in epoch 4, gen_loss = 0.8228932570728311, disc_loss = 0.055993997900877904
Trained batch 419 in epoch 4, gen_loss = 0.822939058428719, disc_loss = 0.055908529028030375
Trained batch 420 in epoch 4, gen_loss = 0.8231117859872107, disc_loss = 0.055797859475529815
Trained batch 421 in epoch 4, gen_loss = 0.8232846560918889, disc_loss = 0.05570190982072133
Trained batch 422 in epoch 4, gen_loss = 0.8234124979792475, disc_loss = 0.05562351050898961
Trained batch 423 in epoch 4, gen_loss = 0.8236310281000048, disc_loss = 0.05551863136209266
Trained batch 424 in epoch 4, gen_loss = 0.8239701165872462, disc_loss = 0.05541599106043577
Trained batch 425 in epoch 4, gen_loss = 0.8242436962228425, disc_loss = 0.05531549043822247
Trained batch 426 in epoch 4, gen_loss = 0.8244459535533986, disc_loss = 0.05519803606662943
Trained batch 427 in epoch 4, gen_loss = 0.8245794933254473, disc_loss = 0.055082758751515054
Trained batch 428 in epoch 4, gen_loss = 0.8246334473014155, disc_loss = 0.05497535838938746
Trained batch 429 in epoch 4, gen_loss = 0.8247591835121776, disc_loss = 0.054866179024670704
Trained batch 430 in epoch 4, gen_loss = 0.8249633353713494, disc_loss = 0.054749282898074514
Trained batch 431 in epoch 4, gen_loss = 0.8251377650433116, disc_loss = 0.05465005708134009
Trained batch 432 in epoch 4, gen_loss = 0.8252942944784363, disc_loss = 0.05454432331326721
Trained batch 433 in epoch 4, gen_loss = 0.8254194078357538, disc_loss = 0.05450155808534559
Trained batch 434 in epoch 4, gen_loss = 0.8258009739305782, disc_loss = 0.05439725226412217
Trained batch 435 in epoch 4, gen_loss = 0.8257894470877604, disc_loss = 0.05434028297842164
Trained batch 436 in epoch 4, gen_loss = 0.8263061950899644, disc_loss = 0.05424957763130864
Trained batch 437 in epoch 4, gen_loss = 0.8272647377290682, disc_loss = 0.05420757176728758
Trained batch 438 in epoch 4, gen_loss = 0.8274868912740286, disc_loss = 0.05411859909560455
Trained batch 439 in epoch 4, gen_loss = 0.8272247458046132, disc_loss = 0.0540588262131099
Trained batch 440 in epoch 4, gen_loss = 0.8277018251332566, disc_loss = 0.053968872697580425
Trained batch 441 in epoch 4, gen_loss = 0.8281972971976612, disc_loss = 0.05392578965668225
Trained batch 442 in epoch 4, gen_loss = 0.828305837263103, disc_loss = 0.053838162882669786
Trained batch 443 in epoch 4, gen_loss = 0.8285929772767935, disc_loss = 0.05373526469443564
Trained batch 444 in epoch 4, gen_loss = 0.82890777427159, disc_loss = 0.05363561249013697
Trained batch 445 in epoch 4, gen_loss = 0.8293146215746755, disc_loss = 0.05353395475258407
Trained batch 446 in epoch 4, gen_loss = 0.8296326120161104, disc_loss = 0.05342312582603904
Trained batch 447 in epoch 4, gen_loss = 0.8297039359541876, disc_loss = 0.053352674294728786
Trained batch 448 in epoch 4, gen_loss = 0.8303781048226728, disc_loss = 0.05326196445123124
Trained batch 449 in epoch 4, gen_loss = 0.830606503089269, disc_loss = 0.053159852180009085
Trained batch 450 in epoch 4, gen_loss = 0.8307903328385956, disc_loss = 0.05306255003693462
Trained batch 451 in epoch 4, gen_loss = 0.8309527901949081, disc_loss = 0.0529808072791542
Trained batch 452 in epoch 4, gen_loss = 0.8311918622610585, disc_loss = 0.052879044664797537
Trained batch 453 in epoch 4, gen_loss = 0.8308422200480222, disc_loss = 0.052813911357164255
Trained batch 454 in epoch 4, gen_loss = 0.8308313264951601, disc_loss = 0.0527174716897227
Trained batch 455 in epoch 4, gen_loss = 0.830607049690004, disc_loss = 0.05269174707702182
Trained batch 456 in epoch 4, gen_loss = 0.8309696889288838, disc_loss = 0.05260734845572345
Trained batch 457 in epoch 4, gen_loss = 0.831077259050186, disc_loss = 0.052525583571270434
Trained batch 458 in epoch 4, gen_loss = 0.8314554445883807, disc_loss = 0.052436899294374686
Trained batch 459 in epoch 4, gen_loss = 0.8315383370803751, disc_loss = 0.05234585552597824
Trained batch 460 in epoch 4, gen_loss = 0.8311089819010323, disc_loss = 0.0524199665029111
Trained batch 461 in epoch 4, gen_loss = 0.8316320238949416, disc_loss = 0.052411987724435796
Trained batch 462 in epoch 4, gen_loss = 0.8317098774611307, disc_loss = 0.052309117384544586
Trained batch 463 in epoch 4, gen_loss = 0.831904907807194, disc_loss = 0.05223182783309563
Trained batch 464 in epoch 4, gen_loss = 0.8312719923193737, disc_loss = 0.05231476365438392
Trained batch 465 in epoch 4, gen_loss = 0.8315210316825834, disc_loss = 0.05224318293326978
Trained batch 466 in epoch 4, gen_loss = 0.8315700969042563, disc_loss = 0.05219256744881577
Trained batch 467 in epoch 4, gen_loss = 0.8320686995473683, disc_loss = 0.0521357525836549
Trained batch 468 in epoch 4, gen_loss = 0.8318453061301062, disc_loss = 0.052078362004255564
Trained batch 469 in epoch 4, gen_loss = 0.8315932344883046, disc_loss = 0.05202163762829088
Trained batch 470 in epoch 4, gen_loss = 0.8316814995621926, disc_loss = 0.05195068284244358
Trained batch 471 in epoch 4, gen_loss = 0.8319781819137476, disc_loss = 0.052236120005422354
Trained batch 472 in epoch 4, gen_loss = 0.831295216436366, disc_loss = 0.052460178789972126
Trained batch 473 in epoch 4, gen_loss = 0.8303794796708264, disc_loss = 0.05269365282414898
Trained batch 474 in epoch 4, gen_loss = 0.8307770163134525, disc_loss = 0.05332340233616139
Trained batch 475 in epoch 4, gen_loss = 0.8311807652231024, disc_loss = 0.053357709553327505
Trained batch 476 in epoch 4, gen_loss = 0.8307336661300819, disc_loss = 0.05355849469459344
Trained batch 477 in epoch 4, gen_loss = 0.8309970289842853, disc_loss = 0.05353619264454335
Trained batch 478 in epoch 4, gen_loss = 0.8309032293600429, disc_loss = 0.05348481872704246
Trained batch 479 in epoch 4, gen_loss = 0.8306204788386822, disc_loss = 0.053485220983081186
Trained batch 480 in epoch 4, gen_loss = 0.8303268318860297, disc_loss = 0.05351916908358152
Trained batch 481 in epoch 4, gen_loss = 0.8302617474957621, disc_loss = 0.05345955156601378
Trained batch 482 in epoch 4, gen_loss = 0.8301271139711573, disc_loss = 0.05337498106417202
Trained batch 483 in epoch 4, gen_loss = 0.8299513280637993, disc_loss = 0.053311047690712716
Trained batch 484 in epoch 4, gen_loss = 0.8300889734140376, disc_loss = 0.05322079836707754
Trained batch 485 in epoch 4, gen_loss = 0.830085165461395, disc_loss = 0.053128144726801066
Trained batch 486 in epoch 4, gen_loss = 0.829579742047821, disc_loss = 0.05312952703320148
Trained batch 487 in epoch 4, gen_loss = 0.8297738854269512, disc_loss = 0.053315896674471557
Trained batch 488 in epoch 4, gen_loss = 0.8295688331736621, disc_loss = 0.053285916413967106
Trained batch 489 in epoch 4, gen_loss = 0.8296425057917225, disc_loss = 0.053189931239704696
Trained batch 490 in epoch 4, gen_loss = 0.8296196029773798, disc_loss = 0.053095558043683135
Trained batch 491 in epoch 4, gen_loss = 0.8295351069390289, disc_loss = 0.05300705530302129
Trained batch 492 in epoch 4, gen_loss = 0.8290666683934039, disc_loss = 0.053044146008064126
Trained batch 493 in epoch 4, gen_loss = 0.8290782649266092, disc_loss = 0.053137747504887915
Trained batch 494 in epoch 4, gen_loss = 0.829210636471257, disc_loss = 0.05309101040051742
Trained batch 495 in epoch 4, gen_loss = 0.8290234548189948, disc_loss = 0.05302103686018757
Trained batch 496 in epoch 4, gen_loss = 0.8287652074930894, disc_loss = 0.0530197264109429
Trained batch 497 in epoch 4, gen_loss = 0.8289166848104162, disc_loss = 0.05294386690003745
Trained batch 498 in epoch 4, gen_loss = 0.8288969567161285, disc_loss = 0.05289804212233884
Trained batch 499 in epoch 4, gen_loss = 0.82936032807827, disc_loss = 0.052832698890939354
Trained batch 500 in epoch 4, gen_loss = 0.829292823811491, disc_loss = 0.05278608254054766
Trained batch 501 in epoch 4, gen_loss = 0.8291070709427989, disc_loss = 0.052700195548707154
Trained batch 502 in epoch 4, gen_loss = 0.8291941593228941, disc_loss = 0.052639034032362475
Trained batch 503 in epoch 4, gen_loss = 0.828813791629814, disc_loss = 0.0526829127846877
Trained batch 504 in epoch 4, gen_loss = 0.8290803464332429, disc_loss = 0.05259500616183965
Trained batch 505 in epoch 4, gen_loss = 0.8290293147205835, disc_loss = 0.052526437121594376
Trained batch 506 in epoch 4, gen_loss = 0.8288808917623065, disc_loss = 0.05264897407188688
Trained batch 507 in epoch 4, gen_loss = 0.8290729923980442, disc_loss = 0.052566220877530774
Trained batch 508 in epoch 4, gen_loss = 0.8297981576507358, disc_loss = 0.05258755493828613
Trained batch 509 in epoch 4, gen_loss = 0.8294476441308564, disc_loss = 0.05262946671641925
Trained batch 510 in epoch 4, gen_loss = 0.8296268192755966, disc_loss = 0.05256526733141706
Trained batch 511 in epoch 4, gen_loss = 0.8295696134446189, disc_loss = 0.05249673344587791
Trained batch 512 in epoch 4, gen_loss = 0.8296920985971046, disc_loss = 0.05240978689984097
Trained batch 513 in epoch 4, gen_loss = 0.8299477903991358, disc_loss = 0.052431093175544
Trained batch 514 in epoch 4, gen_loss = 0.8298706278060246, disc_loss = 0.05236715011262488
Trained batch 515 in epoch 4, gen_loss = 0.8296103090509888, disc_loss = 0.05232540094438045
Trained batch 516 in epoch 4, gen_loss = 0.8295218273564972, disc_loss = 0.05228302399925095
Trained batch 517 in epoch 4, gen_loss = 0.8297267755256196, disc_loss = 0.05222428138601561
Trained batch 518 in epoch 4, gen_loss = 0.8304707357419479, disc_loss = 0.05233668497366999
Trained batch 519 in epoch 4, gen_loss = 0.8300700092544923, disc_loss = 0.05239510712607835
Trained batch 520 in epoch 4, gen_loss = 0.829896936604249, disc_loss = 0.05236025929143527
Trained batch 521 in epoch 4, gen_loss = 0.8298043693162472, disc_loss = 0.05231876320373338
Trained batch 522 in epoch 4, gen_loss = 0.8294660978973709, disc_loss = 0.052310061003535586
Trained batch 523 in epoch 4, gen_loss = 0.8292893508008419, disc_loss = 0.052381400873827685
Trained batch 524 in epoch 4, gen_loss = 0.8291953236716134, disc_loss = 0.05234258407815581
Trained batch 525 in epoch 4, gen_loss = 0.8291618404732911, disc_loss = 0.05233921028652402
Trained batch 526 in epoch 4, gen_loss = 0.8287377961446484, disc_loss = 0.05235830872749072
Trained batch 527 in epoch 4, gen_loss = 0.8288989704892491, disc_loss = 0.05232117212356322
Trained batch 528 in epoch 4, gen_loss = 0.8289649271334052, disc_loss = 0.05225882186802608
Trained batch 529 in epoch 4, gen_loss = 0.829108857433751, disc_loss = 0.05217409734965636
Trained batch 530 in epoch 4, gen_loss = 0.8292541858615624, disc_loss = 0.0521038835350838
Trained batch 531 in epoch 4, gen_loss = 0.8291998278153571, disc_loss = 0.05204875082306256
Trained batch 532 in epoch 4, gen_loss = 0.8295509735817758, disc_loss = 0.05200896676940805
Trained batch 533 in epoch 4, gen_loss = 0.8291502575972554, disc_loss = 0.052176348229326056
Trained batch 534 in epoch 4, gen_loss = 0.8290154953983343, disc_loss = 0.052104060102045255
Trained batch 535 in epoch 4, gen_loss = 0.8291493977850942, disc_loss = 0.05215706572079086
Trained batch 536 in epoch 4, gen_loss = 0.8293536072336761, disc_loss = 0.05209499171690485
Trained batch 537 in epoch 4, gen_loss = 0.8290726789532984, disc_loss = 0.0520894937225891
Trained batch 538 in epoch 4, gen_loss = 0.82927653199003, disc_loss = 0.05202801371553087
Trained batch 539 in epoch 4, gen_loss = 0.8293111513058344, disc_loss = 0.05197709258732006
Trained batch 540 in epoch 4, gen_loss = 0.8294152068783307, disc_loss = 0.0520503610147029
Trained batch 541 in epoch 4, gen_loss = 0.8292033469984892, disc_loss = 0.052051350399611236
Trained batch 542 in epoch 4, gen_loss = 0.8288965949696072, disc_loss = 0.05202402840033997
Trained batch 543 in epoch 4, gen_loss = 0.8286063742330846, disc_loss = 0.05203645225179464
Trained batch 544 in epoch 4, gen_loss = 0.8290095234135969, disc_loss = 0.052241899969415105
Trained batch 545 in epoch 4, gen_loss = 0.8292611940003141, disc_loss = 0.052171619804303127
Trained batch 546 in epoch 4, gen_loss = 0.8287093903072573, disc_loss = 0.052451284167269956
Trained batch 547 in epoch 4, gen_loss = 0.8285432573217545, disc_loss = 0.05246178582599591
Trained batch 548 in epoch 4, gen_loss = 0.8282509306089474, disc_loss = 0.05247099421161799
Trained batch 549 in epoch 4, gen_loss = 0.8285747391527349, disc_loss = 0.052414118824526665
Trained batch 550 in epoch 4, gen_loss = 0.8282991359973776, disc_loss = 0.05260666373343006
Trained batch 551 in epoch 4, gen_loss = 0.8280196749213813, disc_loss = 0.052639571019360606
Trained batch 552 in epoch 4, gen_loss = 0.8278902480227176, disc_loss = 0.052591987500711604
Trained batch 553 in epoch 4, gen_loss = 0.8281581968822204, disc_loss = 0.05285430427334718
Trained batch 554 in epoch 4, gen_loss = 0.8274311949540903, disc_loss = 0.05306023898375061
Trained batch 555 in epoch 4, gen_loss = 0.8273221605973278, disc_loss = 0.0530245299157921
Trained batch 556 in epoch 4, gen_loss = 0.827594547340215, disc_loss = 0.05297144028630703
Trained batch 557 in epoch 4, gen_loss = 0.8275753690136803, disc_loss = 0.053007486857987916
Trained batch 558 in epoch 4, gen_loss = 0.8269850182511939, disc_loss = 0.05321439531296891
Trained batch 559 in epoch 4, gen_loss = 0.8272870148399046, disc_loss = 0.05323810472036712
Trained batch 560 in epoch 4, gen_loss = 0.8278703242805977, disc_loss = 0.05337425594677926
Trained batch 561 in epoch 4, gen_loss = 0.8274751133235748, disc_loss = 0.05353393070018615
Trained batch 562 in epoch 4, gen_loss = 0.8274824453607122, disc_loss = 0.053470753666781036
Trained batch 563 in epoch 4, gen_loss = 0.8275848211231807, disc_loss = 0.05340462024835539
Trained batch 564 in epoch 4, gen_loss = 0.8280983096202917, disc_loss = 0.053429385071076384
Trained batch 565 in epoch 4, gen_loss = 0.8279836620648421, disc_loss = 0.05341592918202781
Trained batch 566 in epoch 4, gen_loss = 0.827436877148492, disc_loss = 0.053571259455896615
Trained batch 567 in epoch 4, gen_loss = 0.827410769347154, disc_loss = 0.05357573465460544
Trained batch 568 in epoch 4, gen_loss = 0.8274739361081684, disc_loss = 0.05349454647568439
Trained batch 569 in epoch 4, gen_loss = 0.827216468516149, disc_loss = 0.05345230336350046
Trained batch 570 in epoch 4, gen_loss = 0.8271943174707075, disc_loss = 0.05338807613303438
Trained batch 571 in epoch 4, gen_loss = 0.8273897214265137, disc_loss = 0.053345267848157275
Trained batch 572 in epoch 4, gen_loss = 0.8277723266504198, disc_loss = 0.05344905011050312
Trained batch 573 in epoch 4, gen_loss = 0.8273966074093709, disc_loss = 0.05357783578355709
Trained batch 574 in epoch 4, gen_loss = 0.8273625001181727, disc_loss = 0.053535463588069314
Trained batch 575 in epoch 4, gen_loss = 0.8274120194320049, disc_loss = 0.05354227388064222
Trained batch 576 in epoch 4, gen_loss = 0.8273979832952523, disc_loss = 0.05348761023491931
Trained batch 577 in epoch 4, gen_loss = 0.8277498762603449, disc_loss = 0.053432295609678056
Trained batch 578 in epoch 4, gen_loss = 0.8279217483157321, disc_loss = 0.05335330785877861
Trained batch 579 in epoch 4, gen_loss = 0.8282586448665323, disc_loss = 0.05328305393200496
Trained batch 580 in epoch 4, gen_loss = 0.8279417228473033, disc_loss = 0.05334365623081407
Trained batch 581 in epoch 4, gen_loss = 0.828372396400704, disc_loss = 0.05327980832238378
Trained batch 582 in epoch 4, gen_loss = 0.8281959618855504, disc_loss = 0.05324857976562367
Trained batch 583 in epoch 4, gen_loss = 0.8284622384362841, disc_loss = 0.05317703641517318
Trained batch 584 in epoch 4, gen_loss = 0.8287273918971038, disc_loss = 0.05309819761408954
Trained batch 585 in epoch 4, gen_loss = 0.8287647105626279, disc_loss = 0.053126499872120675
Trained batch 586 in epoch 4, gen_loss = 0.8285189651244746, disc_loss = 0.053108902855933324
Trained batch 587 in epoch 4, gen_loss = 0.8284126310831025, disc_loss = 0.05307690956515773
Trained batch 588 in epoch 4, gen_loss = 0.828721671385757, disc_loss = 0.05306369369985545
Trained batch 589 in epoch 4, gen_loss = 0.828152822437933, disc_loss = 0.05338001829745658
Trained batch 590 in epoch 4, gen_loss = 0.8284795806694354, disc_loss = 0.053336236539238496
Trained batch 591 in epoch 4, gen_loss = 0.828808657019525, disc_loss = 0.05332406606632159
Trained batch 592 in epoch 4, gen_loss = 0.8291290013424261, disc_loss = 0.05326761115769562
Trained batch 593 in epoch 4, gen_loss = 0.8286194376873247, disc_loss = 0.05331068664243577
Trained batch 594 in epoch 4, gen_loss = 0.8286876120487181, disc_loss = 0.05351166610112962
Trained batch 595 in epoch 4, gen_loss = 0.828491912292154, disc_loss = 0.05350107417266891
Trained batch 596 in epoch 4, gen_loss = 0.8281185600026768, disc_loss = 0.05354593452253384
Trained batch 597 in epoch 4, gen_loss = 0.8282479409589416, disc_loss = 0.05361562325809163
Trained batch 598 in epoch 4, gen_loss = 0.8280094423158738, disc_loss = 0.05366226397796794
Trained batch 599 in epoch 4, gen_loss = 0.8280230605602265, disc_loss = 0.053618825098189216
Trained batch 600 in epoch 4, gen_loss = 0.8276184411493197, disc_loss = 0.05375251766083492
Trained batch 601 in epoch 4, gen_loss = 0.8278556337388251, disc_loss = 0.053795895908968494
Trained batch 602 in epoch 4, gen_loss = 0.8275928088088533, disc_loss = 0.05389984700346912
Trained batch 603 in epoch 4, gen_loss = 0.827626752340241, disc_loss = 0.05398266673217596
Trained batch 604 in epoch 4, gen_loss = 0.8271846733802606, disc_loss = 0.054286140272747876
Trained batch 605 in epoch 4, gen_loss = 0.8275250414810559, disc_loss = 0.05440032577584728
Trained batch 606 in epoch 4, gen_loss = 0.8273036287486848, disc_loss = 0.05453816480486603
Trained batch 607 in epoch 4, gen_loss = 0.8267782213852594, disc_loss = 0.05474803157573517
Trained batch 608 in epoch 4, gen_loss = 0.8265019570078168, disc_loss = 0.05472301050855462
Trained batch 609 in epoch 4, gen_loss = 0.8265092319152394, disc_loss = 0.05481053225726622
Trained batch 610 in epoch 4, gen_loss = 0.8266395714786361, disc_loss = 0.054812350282948556
Trained batch 611 in epoch 4, gen_loss = 0.8261751264723298, disc_loss = 0.054936304775194504
Trained batch 612 in epoch 4, gen_loss = 0.8261457981137622, disc_loss = 0.054909817705790814
Trained batch 613 in epoch 4, gen_loss = 0.8259559154316346, disc_loss = 0.05491424372710943
Trained batch 614 in epoch 4, gen_loss = 0.8259548542945365, disc_loss = 0.05494752659697116
Trained batch 615 in epoch 4, gen_loss = 0.8259523453844058, disc_loss = 0.05500048106421366
Trained batch 616 in epoch 4, gen_loss = 0.8258327070859108, disc_loss = 0.05496462007812443
Trained batch 617 in epoch 4, gen_loss = 0.8259560013473227, disc_loss = 0.05491467292381384
Trained batch 618 in epoch 4, gen_loss = 0.8262081549703015, disc_loss = 0.054843644686765454
Trained batch 619 in epoch 4, gen_loss = 0.8262262428960493, disc_loss = 0.05484672353242434
Trained batch 620 in epoch 4, gen_loss = 0.8262393906496573, disc_loss = 0.054875491680382436
Trained batch 621 in epoch 4, gen_loss = 0.8261168145865107, disc_loss = 0.054890790731134044
Trained batch 622 in epoch 4, gen_loss = 0.8263486519479828, disc_loss = 0.05483726378422631
Trained batch 623 in epoch 4, gen_loss = 0.8260476311238912, disc_loss = 0.05480988502639752
Trained batch 624 in epoch 4, gen_loss = 0.8264825333595276, disc_loss = 0.055135050462186336
Trained batch 625 in epoch 4, gen_loss = 0.8261220259978749, disc_loss = 0.05515148284615943
Trained batch 626 in epoch 4, gen_loss = 0.8257985077976611, disc_loss = 0.05524519550357091
Trained batch 627 in epoch 4, gen_loss = 0.8260473864283532, disc_loss = 0.055676803833680455
Trained batch 628 in epoch 4, gen_loss = 0.825347397446822, disc_loss = 0.05599617644025099
Trained batch 629 in epoch 4, gen_loss = 0.8255312674102329, disc_loss = 0.05609739111618153
Trained batch 630 in epoch 4, gen_loss = 0.82528559421964, disc_loss = 0.05612099035930851
Trained batch 631 in epoch 4, gen_loss = 0.8251007048861135, disc_loss = 0.05612352344095471
Trained batch 632 in epoch 4, gen_loss = 0.8249571931211492, disc_loss = 0.056129388397892034
Trained batch 633 in epoch 4, gen_loss = 0.8249654191243536, disc_loss = 0.05610019053635114
Trained batch 634 in epoch 4, gen_loss = 0.8245856370043567, disc_loss = 0.0561955364245012
Trained batch 635 in epoch 4, gen_loss = 0.824796828786907, disc_loss = 0.05618343985955811
Trained batch 636 in epoch 4, gen_loss = 0.8247887636746866, disc_loss = 0.05616427532702778
Trained batch 637 in epoch 4, gen_loss = 0.8245998110423641, disc_loss = 0.05612533406842044
Trained batch 638 in epoch 4, gen_loss = 0.8244238215526318, disc_loss = 0.056110989126043044
Trained batch 639 in epoch 4, gen_loss = 0.8243029857520014, disc_loss = 0.05610997096373467
Trained batch 640 in epoch 4, gen_loss = 0.8239290255373242, disc_loss = 0.05623840238875746
Trained batch 641 in epoch 4, gen_loss = 0.8242181649553442, disc_loss = 0.0562465173465046
Trained batch 642 in epoch 4, gen_loss = 0.8242104651861205, disc_loss = 0.056242279260829205
Trained batch 643 in epoch 4, gen_loss = 0.8240183144345047, disc_loss = 0.0562062693618076
Trained batch 644 in epoch 4, gen_loss = 0.8237459854100102, disc_loss = 0.05615872392329828
Trained batch 645 in epoch 4, gen_loss = 0.8240969150151262, disc_loss = 0.056200556542101564
Trained batch 646 in epoch 4, gen_loss = 0.8239208355292655, disc_loss = 0.05620421192117922
Trained batch 647 in epoch 4, gen_loss = 0.8236472593321477, disc_loss = 0.05630624976532281
Trained batch 648 in epoch 4, gen_loss = 0.8238074334542079, disc_loss = 0.05625040581068153
Trained batch 649 in epoch 4, gen_loss = 0.8236666970528089, disc_loss = 0.05623708202718542
Trained batch 650 in epoch 4, gen_loss = 0.8238531342391411, disc_loss = 0.0561792459124313
Trained batch 651 in epoch 4, gen_loss = 0.8236559851129363, disc_loss = 0.05612971498116714
Trained batch 652 in epoch 4, gen_loss = 0.8239527780556934, disc_loss = 0.05606132778260646
Trained batch 653 in epoch 4, gen_loss = 0.8240669651771539, disc_loss = 0.05598671584310357
Trained batch 654 in epoch 4, gen_loss = 0.8237324046269628, disc_loss = 0.056009426614170084
Trained batch 655 in epoch 4, gen_loss = 0.8241134447204631, disc_loss = 0.05616474105400124
Trained batch 656 in epoch 4, gen_loss = 0.8242312770909552, disc_loss = 0.05610514560408176
Trained batch 657 in epoch 4, gen_loss = 0.8237930899967176, disc_loss = 0.05620168945553931
Trained batch 658 in epoch 4, gen_loss = 0.8236771698515404, disc_loss = 0.05615614133650983
Trained batch 659 in epoch 4, gen_loss = 0.8234497581015934, disc_loss = 0.05620878973877001
Trained batch 660 in epoch 4, gen_loss = 0.8233817011884409, disc_loss = 0.05615247825566403
Trained batch 661 in epoch 4, gen_loss = 0.8233818373561266, disc_loss = 0.05617478649762214
Trained batch 662 in epoch 4, gen_loss = 0.823136163288292, disc_loss = 0.05615343769371712
Trained batch 663 in epoch 4, gen_loss = 0.8233006755899952, disc_loss = 0.05619055716144145
Trained batch 664 in epoch 4, gen_loss = 0.822690213846981, disc_loss = 0.056403408564375083
Trained batch 665 in epoch 4, gen_loss = 0.822655239396983, disc_loss = 0.05640331531074961
Trained batch 666 in epoch 4, gen_loss = 0.8227024018943221, disc_loss = 0.056474850961946876
Trained batch 667 in epoch 4, gen_loss = 0.8224543041722503, disc_loss = 0.05643074914414302
Trained batch 668 in epoch 4, gen_loss = 0.8222353919471861, disc_loss = 0.056464066303659494
Trained batch 669 in epoch 4, gen_loss = 0.8222940100217933, disc_loss = 0.0565086345904187
Trained batch 670 in epoch 4, gen_loss = 0.8218102192203618, disc_loss = 0.05663689445279505
Trained batch 671 in epoch 4, gen_loss = 0.8219416874150435, disc_loss = 0.0565705848393485
Trained batch 672 in epoch 4, gen_loss = 0.8221326500487363, disc_loss = 0.05659393034944585
Trained batch 673 in epoch 4, gen_loss = 0.8221996364678402, disc_loss = 0.05652549749624415
Trained batch 674 in epoch 4, gen_loss = 0.8219629526138306, disc_loss = 0.05647853513075798
Trained batch 675 in epoch 4, gen_loss = 0.821964966563078, disc_loss = 0.05641718015981254
Trained batch 676 in epoch 4, gen_loss = 0.8223090545993788, disc_loss = 0.05635439878621275
Trained batch 677 in epoch 4, gen_loss = 0.8225757876152837, disc_loss = 0.05630694299587392
Trained batch 678 in epoch 4, gen_loss = 0.8223826057429868, disc_loss = 0.05628904018932419
Trained batch 679 in epoch 4, gen_loss = 0.8221338628846057, disc_loss = 0.05626403916805216
Trained batch 680 in epoch 4, gen_loss = 0.8226248606186081, disc_loss = 0.056340166831884135
Trained batch 681 in epoch 4, gen_loss = 0.8224467338005469, disc_loss = 0.05629153273346946
Trained batch 682 in epoch 4, gen_loss = 0.8225545932049283, disc_loss = 0.056327919420509395
Trained batch 683 in epoch 4, gen_loss = 0.8224853820096679, disc_loss = 0.05627843773888413
Trained batch 684 in epoch 4, gen_loss = 0.8221570475258096, disc_loss = 0.05628044489757532
Trained batch 685 in epoch 4, gen_loss = 0.8222092557752793, disc_loss = 0.05622714547828687
Trained batch 686 in epoch 4, gen_loss = 0.8225600572826214, disc_loss = 0.056229598522647195
Trained batch 687 in epoch 4, gen_loss = 0.8226216114017852, disc_loss = 0.05616167103424993
Trained batch 688 in epoch 4, gen_loss = 0.8223816257602764, disc_loss = 0.0561593670542629
Trained batch 689 in epoch 4, gen_loss = 0.8221984316473422, disc_loss = 0.05610567375788114
Trained batch 690 in epoch 4, gen_loss = 0.8219881002533798, disc_loss = 0.056162164749391646
Trained batch 691 in epoch 4, gen_loss = 0.8223290091994181, disc_loss = 0.056147736321591014
Trained batch 692 in epoch 4, gen_loss = 0.8224334758081477, disc_loss = 0.05609496628252781
Trained batch 693 in epoch 4, gen_loss = 0.8223958312606262, disc_loss = 0.056041414231485995
Trained batch 694 in epoch 4, gen_loss = 0.8222116230203094, disc_loss = 0.05602911776333726
Trained batch 695 in epoch 4, gen_loss = 0.8223314352076629, disc_loss = 0.056049488947175485
Trained batch 696 in epoch 4, gen_loss = 0.8223021120217815, disc_loss = 0.05598852684096015
Trained batch 697 in epoch 4, gen_loss = 0.8221160858271799, disc_loss = 0.05598563213170877
Trained batch 698 in epoch 4, gen_loss = 0.8221204217752504, disc_loss = 0.0559658021093193
Trained batch 699 in epoch 4, gen_loss = 0.8218943819829396, disc_loss = 0.05597185294077332
Trained batch 700 in epoch 4, gen_loss = 0.8222095659387945, disc_loss = 0.05623706896323046
Trained batch 701 in epoch 4, gen_loss = 0.822527897239071, disc_loss = 0.0561912143503467
Trained batch 702 in epoch 4, gen_loss = 0.8222537779197584, disc_loss = 0.05620535609152057
Trained batch 703 in epoch 4, gen_loss = 0.8221952408044175, disc_loss = 0.05623994776992318
Trained batch 704 in epoch 4, gen_loss = 0.8223284234391882, disc_loss = 0.0561821415683532
Trained batch 705 in epoch 4, gen_loss = 0.8221077301009181, disc_loss = 0.05617330546052889
Trained batch 706 in epoch 4, gen_loss = 0.8224298016522528, disc_loss = 0.05653885858201934
Trained batch 707 in epoch 4, gen_loss = 0.8221833711795214, disc_loss = 0.056562765136408476
Trained batch 708 in epoch 4, gen_loss = 0.8217440156741607, disc_loss = 0.05662277568728047
Trained batch 709 in epoch 4, gen_loss = 0.8216877889465278, disc_loss = 0.05660748043963292
Trained batch 710 in epoch 4, gen_loss = 0.8217826859525152, disc_loss = 0.05656288444285927
Trained batch 711 in epoch 4, gen_loss = 0.8218292408947194, disc_loss = 0.05650233065649302
Trained batch 712 in epoch 4, gen_loss = 0.8218059679401873, disc_loss = 0.05643800381756535
Trained batch 713 in epoch 4, gen_loss = 0.8215160192060871, disc_loss = 0.05644892108188394
Trained batch 714 in epoch 4, gen_loss = 0.8214200259088636, disc_loss = 0.056414136734068185
Trained batch 715 in epoch 4, gen_loss = 0.8218124637890128, disc_loss = 0.05643835773642107
Trained batch 716 in epoch 4, gen_loss = 0.8219339145942379, disc_loss = 0.05640129913670768
Trained batch 717 in epoch 4, gen_loss = 0.8216858707098575, disc_loss = 0.056384182572079444
Trained batch 718 in epoch 4, gen_loss = 0.8213386306842279, disc_loss = 0.05642167267212139
Trained batch 719 in epoch 4, gen_loss = 0.8213682226008839, disc_loss = 0.056354571491505745
Trained batch 720 in epoch 4, gen_loss = 0.8218232611512013, disc_loss = 0.05647969533768114
Trained batch 721 in epoch 4, gen_loss = 0.8217969118227919, disc_loss = 0.056518459321745255
Trained batch 722 in epoch 4, gen_loss = 0.8215350332266728, disc_loss = 0.05658084516417374
Trained batch 723 in epoch 4, gen_loss = 0.8215708785294169, disc_loss = 0.05654199910543097
Trained batch 724 in epoch 4, gen_loss = 0.8212071460690992, disc_loss = 0.05654680746189993
Trained batch 725 in epoch 4, gen_loss = 0.821161884414263, disc_loss = 0.056527117588595785
Trained batch 726 in epoch 4, gen_loss = 0.8212041677766194, disc_loss = 0.05655664423649728
Trained batch 727 in epoch 4, gen_loss = 0.821632383288918, disc_loss = 0.05652488586761487
Trained batch 728 in epoch 4, gen_loss = 0.8217065527278864, disc_loss = 0.056489591759505624
Trained batch 729 in epoch 4, gen_loss = 0.8215862017788299, disc_loss = 0.05650077359431921
Trained batch 730 in epoch 4, gen_loss = 0.8217284348366525, disc_loss = 0.05643294856306446
Trained batch 731 in epoch 4, gen_loss = 0.8217551591780667, disc_loss = 0.05637059321746617
Trained batch 732 in epoch 4, gen_loss = 0.8218550197424375, disc_loss = 0.05631004164559515
Trained batch 733 in epoch 4, gen_loss = 0.821621649352991, disc_loss = 0.05631777570501721
Trained batch 734 in epoch 4, gen_loss = 0.8217826187205153, disc_loss = 0.05626150793807746
Trained batch 735 in epoch 4, gen_loss = 0.8220601106953361, disc_loss = 0.05628868079498795
Trained batch 736 in epoch 4, gen_loss = 0.8220799492528028, disc_loss = 0.056250774431114405
Trained batch 737 in epoch 4, gen_loss = 0.8219636173913796, disc_loss = 0.05623297714300171
Trained batch 738 in epoch 4, gen_loss = 0.8220008162426207, disc_loss = 0.056194749487505996
Trained batch 739 in epoch 4, gen_loss = 0.8220531411267615, disc_loss = 0.056176520578840095
Trained batch 740 in epoch 4, gen_loss = 0.8221546737288656, disc_loss = 0.05614455931791068
Trained batch 741 in epoch 4, gen_loss = 0.8218524253593301, disc_loss = 0.056201938456275836
Trained batch 742 in epoch 4, gen_loss = 0.8219085882040565, disc_loss = 0.056284452718964616
Trained batch 743 in epoch 4, gen_loss = 0.82202702135809, disc_loss = 0.056315975791339075
Trained batch 744 in epoch 4, gen_loss = 0.8218470786241877, disc_loss = 0.056315977098232745
Trained batch 745 in epoch 4, gen_loss = 0.8219202044182744, disc_loss = 0.05626094862556549
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.7009854316711426, disc_loss = 0.0412147119641304
Trained batch 1 in epoch 5, gen_loss = 0.6480453610420227, disc_loss = 0.09568827971816063
Trained batch 2 in epoch 5, gen_loss = 0.8076247771581014, disc_loss = 0.12565606087446213
Trained batch 3 in epoch 5, gen_loss = 0.7503789961338043, disc_loss = 0.13782634399831295
Trained batch 4 in epoch 5, gen_loss = 0.7925383567810058, disc_loss = 0.12572898864746093
Trained batch 5 in epoch 5, gen_loss = 0.79588054617246, disc_loss = 0.1113414317369461
Trained batch 6 in epoch 5, gen_loss = 0.7794066071510315, disc_loss = 0.10477727438722338
Trained batch 7 in epoch 5, gen_loss = 0.7988036796450615, disc_loss = 0.10008489806205034
Trained batch 8 in epoch 5, gen_loss = 0.8012238409784105, disc_loss = 0.09133487111992306
Trained batch 9 in epoch 5, gen_loss = 0.7898208320140838, disc_loss = 0.08522096499800683
Trained batch 10 in epoch 5, gen_loss = 0.8063980937004089, disc_loss = 0.0782361099157821
Trained batch 11 in epoch 5, gen_loss = 0.8062097777922949, disc_loss = 0.07355921785347164
Trained batch 12 in epoch 5, gen_loss = 0.804466596016517, disc_loss = 0.0723695199793348
Trained batch 13 in epoch 5, gen_loss = 0.8007317653724125, disc_loss = 0.06974737885008965
Trained batch 14 in epoch 5, gen_loss = 0.8019095659255981, disc_loss = 0.06648860741406679
Trained batch 15 in epoch 5, gen_loss = 0.8092075437307358, disc_loss = 0.06308567809173837
Trained batch 16 in epoch 5, gen_loss = 0.8219544817419613, disc_loss = 0.07526814504800473
Trained batch 17 in epoch 5, gen_loss = 0.8129795293013254, disc_loss = 0.07704695360735059
Trained batch 18 in epoch 5, gen_loss = 0.8036596869167528, disc_loss = 0.07602962660358141
Trained batch 19 in epoch 5, gen_loss = 0.8068374425172806, disc_loss = 0.0740847506094724
Trained batch 20 in epoch 5, gen_loss = 0.810326874256134, disc_loss = 0.07469545486604884
Trained batch 21 in epoch 5, gen_loss = 0.8180612840435721, disc_loss = 0.07580442290583794
Trained batch 22 in epoch 5, gen_loss = 0.8181005742238916, disc_loss = 0.07776297827291748
Trained batch 23 in epoch 5, gen_loss = 0.8081083645423254, disc_loss = 0.08039815727776538
Trained batch 24 in epoch 5, gen_loss = 0.8083656573295593, disc_loss = 0.07862610880285502
Trained batch 25 in epoch 5, gen_loss = 0.8079704848619608, disc_loss = 0.0780448062846867
Trained batch 26 in epoch 5, gen_loss = 0.8043050368626913, disc_loss = 0.07936672235114707
Trained batch 27 in epoch 5, gen_loss = 0.8030041541372027, disc_loss = 0.07844938660439636
Trained batch 28 in epoch 5, gen_loss = 0.7947922369529461, disc_loss = 0.07979062896478793
Trained batch 29 in epoch 5, gen_loss = 0.7891178448994954, disc_loss = 0.08031695339207848
Trained batch 30 in epoch 5, gen_loss = 0.8004588542446014, disc_loss = 0.08342140050785195
Trained batch 31 in epoch 5, gen_loss = 0.7958704084157944, disc_loss = 0.08349680996616371
Trained batch 32 in epoch 5, gen_loss = 0.7933271798220548, disc_loss = 0.08287009102941463
Trained batch 33 in epoch 5, gen_loss = 0.8022832870483398, disc_loss = 0.09030169470454841
Trained batch 34 in epoch 5, gen_loss = 0.7987421699932643, disc_loss = 0.0898444929559316
Trained batch 35 in epoch 5, gen_loss = 0.7990835789177153, disc_loss = 0.0884613004875266
Trained batch 36 in epoch 5, gen_loss = 0.7940537945644276, disc_loss = 0.08821426525812696
Trained batch 37 in epoch 5, gen_loss = 0.7942347667719188, disc_loss = 0.0862113067537154
Trained batch 38 in epoch 5, gen_loss = 0.797532795331417, disc_loss = 0.08469375062924929
Trained batch 39 in epoch 5, gen_loss = 0.7945672512054444, disc_loss = 0.08373997856397182
Trained batch 40 in epoch 5, gen_loss = 0.7953811040738734, disc_loss = 0.08600917397203242
Trained batch 41 in epoch 5, gen_loss = 0.797731400955291, disc_loss = 0.08977619818012629
Trained batch 42 in epoch 5, gen_loss = 0.7885150514369788, disc_loss = 0.0948585418464486
Trained batch 43 in epoch 5, gen_loss = 0.7850164100527763, disc_loss = 0.09429048097015104
Trained batch 44 in epoch 5, gen_loss = 0.7870258920722537, disc_loss = 0.09480303519715866
Trained batch 45 in epoch 5, gen_loss = 0.7853951486556426, disc_loss = 0.09402540360536912
Trained batch 46 in epoch 5, gen_loss = 0.7809377319001137, disc_loss = 0.0943543216847676
Trained batch 47 in epoch 5, gen_loss = 0.7785678102324406, disc_loss = 0.09350259774752583
Trained batch 48 in epoch 5, gen_loss = 0.7743472998239556, disc_loss = 0.09292550417309513
Trained batch 49 in epoch 5, gen_loss = 0.7807869213819504, disc_loss = 0.09379112722352147
Trained batch 50 in epoch 5, gen_loss = 0.7790052955057106, disc_loss = 0.09245783172766953
Trained batch 51 in epoch 5, gen_loss = 0.7769510098374807, disc_loss = 0.09149145257945818
Trained batch 52 in epoch 5, gen_loss = 0.7775030636562491, disc_loss = 0.0906395236873683
Trained batch 53 in epoch 5, gen_loss = 0.7752997350913508, disc_loss = 0.09010660919119362
Trained batch 54 in epoch 5, gen_loss = 0.7803868212483146, disc_loss = 0.08886265973137183
Trained batch 55 in epoch 5, gen_loss = 0.7815177924931049, disc_loss = 0.08744474197737873
Trained batch 56 in epoch 5, gen_loss = 0.7795072956043377, disc_loss = 0.08645290848717355
Trained batch 57 in epoch 5, gen_loss = 0.782776248352281, disc_loss = 0.08561300505594961
Trained batch 58 in epoch 5, gen_loss = 0.783402933407638, disc_loss = 0.08553831020401696
Trained batch 59 in epoch 5, gen_loss = 0.7853491937120756, disc_loss = 0.08460328979417682
Trained batch 60 in epoch 5, gen_loss = 0.7821904054430665, disc_loss = 0.08536466885907729
Trained batch 61 in epoch 5, gen_loss = 0.7805385767452179, disc_loss = 0.08562490743614974
Trained batch 62 in epoch 5, gen_loss = 0.7802920459754883, disc_loss = 0.08498910758348685
Trained batch 63 in epoch 5, gen_loss = 0.7830658261664212, disc_loss = 0.08427056591608562
Trained batch 64 in epoch 5, gen_loss = 0.7829952611373021, disc_loss = 0.08411602816329553
Trained batch 65 in epoch 5, gen_loss = 0.7797971101421298, disc_loss = 0.08433929224018798
Trained batch 66 in epoch 5, gen_loss = 0.7803561024701418, disc_loss = 0.08320589649921922
Trained batch 67 in epoch 5, gen_loss = 0.781753754352822, disc_loss = 0.0823596421190921
Trained batch 68 in epoch 5, gen_loss = 0.7832329899504564, disc_loss = 0.08132969520554162
Trained batch 69 in epoch 5, gen_loss = 0.7858832346541541, disc_loss = 0.08036385014919298
Trained batch 70 in epoch 5, gen_loss = 0.7830349345442275, disc_loss = 0.08085882271521948
Trained batch 71 in epoch 5, gen_loss = 0.7859040891958607, disc_loss = 0.08035243505663756
Trained batch 72 in epoch 5, gen_loss = 0.7854973204331855, disc_loss = 0.07955714939034557
Trained batch 73 in epoch 5, gen_loss = 0.7866695728656408, disc_loss = 0.07856608506266934
Trained batch 74 in epoch 5, gen_loss = 0.7906794766585032, disc_loss = 0.07815246817345421
Trained batch 75 in epoch 5, gen_loss = 0.7917886717539084, disc_loss = 0.07802503111796748
Trained batch 76 in epoch 5, gen_loss = 0.7923654762955455, disc_loss = 0.07729207948696884
Trained batch 77 in epoch 5, gen_loss = 0.7922177142821826, disc_loss = 0.07693932766023164
Trained batch 78 in epoch 5, gen_loss = 0.7930199085157129, disc_loss = 0.07620779723754223
Trained batch 79 in epoch 5, gen_loss = 0.795368118956685, disc_loss = 0.0754959974612575
Trained batch 80 in epoch 5, gen_loss = 0.7968519738426915, disc_loss = 0.07484279993208653
Trained batch 81 in epoch 5, gen_loss = 0.7989305392271135, disc_loss = 0.0747918218272034
Trained batch 82 in epoch 5, gen_loss = 0.7982784613787409, disc_loss = 0.07424400916816778
Trained batch 83 in epoch 5, gen_loss = 0.7978994083546457, disc_loss = 0.07368068241270348
Trained batch 84 in epoch 5, gen_loss = 0.7979036993840162, disc_loss = 0.07329025154056794
Trained batch 85 in epoch 5, gen_loss = 0.798079996954563, disc_loss = 0.0728336134221578
Trained batch 86 in epoch 5, gen_loss = 0.800793252114592, disc_loss = 0.0722749322256737
Trained batch 87 in epoch 5, gen_loss = 0.803611792285334, disc_loss = 0.07166891730792652
Trained batch 88 in epoch 5, gen_loss = 0.8045372068881989, disc_loss = 0.07103386721730734
Trained batch 89 in epoch 5, gen_loss = 0.8039193878571192, disc_loss = 0.07047087044662072
Trained batch 90 in epoch 5, gen_loss = 0.8071701719865694, disc_loss = 0.07027571447255028
Trained batch 91 in epoch 5, gen_loss = 0.8069260842774225, disc_loss = 0.06967815941543845
Trained batch 92 in epoch 5, gen_loss = 0.8076409931464862, disc_loss = 0.06903220619505612
Trained batch 93 in epoch 5, gen_loss = 0.809095377300648, disc_loss = 0.06850858976410583
Trained batch 94 in epoch 5, gen_loss = 0.810223533918983, disc_loss = 0.06788793525315429
Trained batch 95 in epoch 5, gen_loss = 0.8101267886037627, disc_loss = 0.0672870073710025
Trained batch 96 in epoch 5, gen_loss = 0.8102373551462114, disc_loss = 0.0675844200886786
Trained batch 97 in epoch 5, gen_loss = 0.8091924959907726, disc_loss = 0.06744235288826939
Trained batch 98 in epoch 5, gen_loss = 0.80984238151348, disc_loss = 0.06685665196673286
Trained batch 99 in epoch 5, gen_loss = 0.8086919769644737, disc_loss = 0.06640626705717295
Trained batch 100 in epoch 5, gen_loss = 0.8092412373217026, disc_loss = 0.06584096555644185
Trained batch 101 in epoch 5, gen_loss = 0.8130212592727998, disc_loss = 0.06991645382881603
Trained batch 102 in epoch 5, gen_loss = 0.8115508460882798, disc_loss = 0.06986250051577549
Trained batch 103 in epoch 5, gen_loss = 0.8101698249005355, disc_loss = 0.0700942319056664
Trained batch 104 in epoch 5, gen_loss = 0.8088704265299298, disc_loss = 0.06987910617941193
Trained batch 105 in epoch 5, gen_loss = 0.8116943462277358, disc_loss = 0.07041096778252637
Trained batch 106 in epoch 5, gen_loss = 0.811126464716742, disc_loss = 0.07045404020714287
Trained batch 107 in epoch 5, gen_loss = 0.8095317292544577, disc_loss = 0.0707100291037932
Trained batch 108 in epoch 5, gen_loss = 0.8108605088990762, disc_loss = 0.07016167389399824
Trained batch 109 in epoch 5, gen_loss = 0.8142688672650944, disc_loss = 0.0701280926735225
Trained batch 110 in epoch 5, gen_loss = 0.8135943764501864, disc_loss = 0.06966815341415035
Trained batch 111 in epoch 5, gen_loss = 0.8133977260440588, disc_loss = 0.06913645420406413
Trained batch 112 in epoch 5, gen_loss = 0.8141084590316874, disc_loss = 0.06861909729865405
Trained batch 113 in epoch 5, gen_loss = 0.8148626964866069, disc_loss = 0.06822235003652934
Trained batch 114 in epoch 5, gen_loss = 0.8158729519533074, disc_loss = 0.06778133874759078
Trained batch 115 in epoch 5, gen_loss = 0.8161676472117161, disc_loss = 0.06729602411084262
Trained batch 116 in epoch 5, gen_loss = 0.8164388911846356, disc_loss = 0.06682830371965583
Trained batch 117 in epoch 5, gen_loss = 0.8172830724615162, disc_loss = 0.06635821405877122
Trained batch 118 in epoch 5, gen_loss = 0.8184085100137887, disc_loss = 0.06587534028833278
Trained batch 119 in epoch 5, gen_loss = 0.8178425612548987, disc_loss = 0.065501208017425
Trained batch 120 in epoch 5, gen_loss = 0.817457661402127, disc_loss = 0.0650213097052818
Trained batch 121 in epoch 5, gen_loss = 0.817567311105181, disc_loss = 0.06455610979913322
Trained batch 122 in epoch 5, gen_loss = 0.8185306024260637, disc_loss = 0.06407814427104787
Trained batch 123 in epoch 5, gen_loss = 0.8194494509408551, disc_loss = 0.06362412675028487
Trained batch 124 in epoch 5, gen_loss = 0.8189698736667633, disc_loss = 0.06324585216119885
Trained batch 125 in epoch 5, gen_loss = 0.8193667547570335, disc_loss = 0.06310567932779945
Trained batch 126 in epoch 5, gen_loss = 0.8193037291680734, disc_loss = 0.06265884905129554
Trained batch 127 in epoch 5, gen_loss = 0.8199078438337892, disc_loss = 0.062379926752328174
Trained batch 128 in epoch 5, gen_loss = 0.8200954917327378, disc_loss = 0.06199937813027307
Trained batch 129 in epoch 5, gen_loss = 0.821262380022269, disc_loss = 0.06155266948760702
Trained batch 130 in epoch 5, gen_loss = 0.8213923516619297, disc_loss = 0.061135965434990766
Trained batch 131 in epoch 5, gen_loss = 0.8225031018708692, disc_loss = 0.06071469692908453
Trained batch 132 in epoch 5, gen_loss = 0.8238703211895505, disc_loss = 0.06133479190836275
Trained batch 133 in epoch 5, gen_loss = 0.8234253207694239, disc_loss = 0.060989485984084324
Trained batch 134 in epoch 5, gen_loss = 0.8228415239740301, disc_loss = 0.060689180413330046
Trained batch 135 in epoch 5, gen_loss = 0.8229684459374231, disc_loss = 0.0603701787562493
Trained batch 136 in epoch 5, gen_loss = 0.8233777573944008, disc_loss = 0.059988456315965985
Trained batch 137 in epoch 5, gen_loss = 0.8249556830395823, disc_loss = 0.05972261411691274
Trained batch 138 in epoch 5, gen_loss = 0.8251628972214761, disc_loss = 0.059346613996802904
Trained batch 139 in epoch 5, gen_loss = 0.824535987845489, disc_loss = 0.05899245363127972
Trained batch 140 in epoch 5, gen_loss = 0.8248644921373813, disc_loss = 0.05867511273777865
Trained batch 141 in epoch 5, gen_loss = 0.8249510079622269, disc_loss = 0.05838965610797766
Trained batch 142 in epoch 5, gen_loss = 0.8252225228539714, disc_loss = 0.05805943118265042
Trained batch 143 in epoch 5, gen_loss = 0.8264179575360484, disc_loss = 0.05799257875575373
Trained batch 144 in epoch 5, gen_loss = 0.8248707641815317, disc_loss = 0.058226868266175534
Trained batch 145 in epoch 5, gen_loss = 0.8237784947842768, disc_loss = 0.05846656360089371
Trained batch 146 in epoch 5, gen_loss = 0.8245824747750549, disc_loss = 0.05825512490051539
Trained batch 147 in epoch 5, gen_loss = 0.8263224445887514, disc_loss = 0.058200054109801315
Trained batch 148 in epoch 5, gen_loss = 0.8279189857460508, disc_loss = 0.058156201340908174
Trained batch 149 in epoch 5, gen_loss = 0.8276418592532476, disc_loss = 0.058024374755720295
Trained batch 150 in epoch 5, gen_loss = 0.8268431569172057, disc_loss = 0.05794803690880734
Trained batch 151 in epoch 5, gen_loss = 0.8274355415058764, disc_loss = 0.05761511132157849
Trained batch 152 in epoch 5, gen_loss = 0.8273861262143827, disc_loss = 0.057300690923713975
Trained batch 153 in epoch 5, gen_loss = 0.8283765465021133, disc_loss = 0.05761361828182715
Trained batch 154 in epoch 5, gen_loss = 0.8283559747280613, disc_loss = 0.057278024570475664
Trained batch 155 in epoch 5, gen_loss = 0.8263990288743606, disc_loss = 0.05777006099322954
Trained batch 156 in epoch 5, gen_loss = 0.8255018088847969, disc_loss = 0.05773293444957987
Trained batch 157 in epoch 5, gen_loss = 0.8266353375172313, disc_loss = 0.057751436160783036
Trained batch 158 in epoch 5, gen_loss = 0.825515330400107, disc_loss = 0.057718486082886565
Trained batch 159 in epoch 5, gen_loss = 0.8265417406335474, disc_loss = 0.0575070842722198
Trained batch 160 in epoch 5, gen_loss = 0.8270727116498888, disc_loss = 0.05746134699999083
Trained batch 161 in epoch 5, gen_loss = 0.827659139846578, disc_loss = 0.05714639519157325
Trained batch 162 in epoch 5, gen_loss = 0.8260194247851342, disc_loss = 0.05727605255709196
Trained batch 163 in epoch 5, gen_loss = 0.8260690360897924, disc_loss = 0.05712705238710907
Trained batch 164 in epoch 5, gen_loss = 0.8263144791126251, disc_loss = 0.0571462546926782
Trained batch 165 in epoch 5, gen_loss = 0.8268434773367571, disc_loss = 0.05688472826830504
Trained batch 166 in epoch 5, gen_loss = 0.8251416881284314, disc_loss = 0.05714098474256204
Trained batch 167 in epoch 5, gen_loss = 0.8244184260921819, disc_loss = 0.057026895902319144
Trained batch 168 in epoch 5, gen_loss = 0.8262895971712981, disc_loss = 0.05725014807942968
Trained batch 169 in epoch 5, gen_loss = 0.8265969625290702, disc_loss = 0.0570195266730426
Trained batch 170 in epoch 5, gen_loss = 0.8261631286283683, disc_loss = 0.05682907840345948
Trained batch 171 in epoch 5, gen_loss = 0.8249732770545538, disc_loss = 0.056822596884029374
Trained batch 172 in epoch 5, gen_loss = 0.8259883500592557, disc_loss = 0.05660693497919192
Trained batch 173 in epoch 5, gen_loss = 0.8276351095958688, disc_loss = 0.056445606242886734
Trained batch 174 in epoch 5, gen_loss = 0.8287412747314998, disc_loss = 0.05651966973873122
Trained batch 175 in epoch 5, gen_loss = 0.8282609488815069, disc_loss = 0.05652884444465268
Trained batch 176 in epoch 5, gen_loss = 0.8267664139890402, disc_loss = 0.05732040578436296
Trained batch 177 in epoch 5, gen_loss = 0.8271205527394005, disc_loss = 0.05774783886958625
Trained batch 178 in epoch 5, gen_loss = 0.8274429269010128, disc_loss = 0.05752361158699879
Trained batch 179 in epoch 5, gen_loss = 0.8274300666318999, disc_loss = 0.057306351892960565
Trained batch 180 in epoch 5, gen_loss = 0.8278904094551149, disc_loss = 0.05704813351525374
Trained batch 181 in epoch 5, gen_loss = 0.8266315019720203, disc_loss = 0.05713121187463812
Trained batch 182 in epoch 5, gen_loss = 0.8263362227567558, disc_loss = 0.057735717399910985
Trained batch 183 in epoch 5, gen_loss = 0.8261030058821907, disc_loss = 0.05754389324093885
Trained batch 184 in epoch 5, gen_loss = 0.8262166411490054, disc_loss = 0.057271206373902594
Trained batch 185 in epoch 5, gen_loss = 0.8266621996318141, disc_loss = 0.05719222794837689
Trained batch 186 in epoch 5, gen_loss = 0.8258189264147039, disc_loss = 0.057216380384158
Trained batch 187 in epoch 5, gen_loss = 0.8257861113611688, disc_loss = 0.05787510640344563
Trained batch 188 in epoch 5, gen_loss = 0.8248346320220402, disc_loss = 0.05809240517694326
Trained batch 189 in epoch 5, gen_loss = 0.8256919473409653, disc_loss = 0.05791372898475904
Trained batch 190 in epoch 5, gen_loss = 0.8258245954026726, disc_loss = 0.057722899258253774
Trained batch 191 in epoch 5, gen_loss = 0.8261667696448664, disc_loss = 0.05753302218605919
Trained batch 192 in epoch 5, gen_loss = 0.8251149896821828, disc_loss = 0.05755493071393491
Trained batch 193 in epoch 5, gen_loss = 0.8245008196105662, disc_loss = 0.05762088509545345
Trained batch 194 in epoch 5, gen_loss = 0.824433342157266, disc_loss = 0.057491438219753596
Trained batch 195 in epoch 5, gen_loss = 0.8264949584797937, disc_loss = 0.05744866935099114
Trained batch 196 in epoch 5, gen_loss = 0.8263947142259723, disc_loss = 0.057317866697945266
Trained batch 197 in epoch 5, gen_loss = 0.8272295324790357, disc_loss = 0.05707794841792849
Trained batch 198 in epoch 5, gen_loss = 0.8276336676810854, disc_loss = 0.05682220383448966
Trained batch 199 in epoch 5, gen_loss = 0.8264732708036899, disc_loss = 0.05686497791204601
Trained batch 200 in epoch 5, gen_loss = 0.8281787973434771, disc_loss = 0.057027779913400835
Trained batch 201 in epoch 5, gen_loss = 0.8273950002276071, disc_loss = 0.05694950599278702
Trained batch 202 in epoch 5, gen_loss = 0.826955002663758, disc_loss = 0.05688011815560422
Trained batch 203 in epoch 5, gen_loss = 0.8267910546239685, disc_loss = 0.05676351131999171
Trained batch 204 in epoch 5, gen_loss = 0.826381697451196, disc_loss = 0.05665126258007637
Trained batch 205 in epoch 5, gen_loss = 0.8250593003428098, disc_loss = 0.05695568152151785
Trained batch 206 in epoch 5, gen_loss = 0.8261127418653976, disc_loss = 0.057951669874578574
Trained batch 207 in epoch 5, gen_loss = 0.8270282761122172, disc_loss = 0.0577387625638109
Trained batch 208 in epoch 5, gen_loss = 0.8270957844964625, disc_loss = 0.05759133645400191
Trained batch 209 in epoch 5, gen_loss = 0.8262128899494807, disc_loss = 0.0576862368998783
Trained batch 210 in epoch 5, gen_loss = 0.8260961924966478, disc_loss = 0.05748351069246706
Trained batch 211 in epoch 5, gen_loss = 0.826614464650739, disc_loss = 0.05726810366372174
Trained batch 212 in epoch 5, gen_loss = 0.8273948457599246, disc_loss = 0.057095890287572226
Trained batch 213 in epoch 5, gen_loss = 0.8275557988993475, disc_loss = 0.056936884359848276
Trained batch 214 in epoch 5, gen_loss = 0.8276082375714945, disc_loss = 0.05671462989303955
Trained batch 215 in epoch 5, gen_loss = 0.8274850096139643, disc_loss = 0.05647939091324116
Trained batch 216 in epoch 5, gen_loss = 0.8279384733070426, disc_loss = 0.05641039206393166
Trained batch 217 in epoch 5, gen_loss = 0.8279316328260877, disc_loss = 0.05623115063858552
Trained batch 218 in epoch 5, gen_loss = 0.8280082085089052, disc_loss = 0.056013599459132916
Trained batch 219 in epoch 5, gen_loss = 0.8286179709163579, disc_loss = 0.05579941800626164
Trained batch 220 in epoch 5, gen_loss = 0.8295165741335753, disc_loss = 0.055616137757054554
Trained batch 221 in epoch 5, gen_loss = 0.8299056969515912, disc_loss = 0.05542861422322489
Trained batch 222 in epoch 5, gen_loss = 0.8293344729951679, disc_loss = 0.05524552063473538
Trained batch 223 in epoch 5, gen_loss = 0.8294993619035397, disc_loss = 0.05501857934619433
Trained batch 224 in epoch 5, gen_loss = 0.8299238227473364, disc_loss = 0.054795387904677126
Trained batch 225 in epoch 5, gen_loss = 0.8303139538100336, disc_loss = 0.054585276571292
Trained batch 226 in epoch 5, gen_loss = 0.830585176855457, disc_loss = 0.054386448947967146
Trained batch 227 in epoch 5, gen_loss = 0.8307661167100856, disc_loss = 0.05416672887370448
Trained batch 228 in epoch 5, gen_loss = 0.8309293905980722, disc_loss = 0.053979975954267526
Trained batch 229 in epoch 5, gen_loss = 0.8310089522081873, disc_loss = 0.05375931866001338
Trained batch 230 in epoch 5, gen_loss = 0.8307818939417472, disc_loss = 0.05356359257749826
Trained batch 231 in epoch 5, gen_loss = 0.8316038267622734, disc_loss = 0.05336625728423001
Trained batch 232 in epoch 5, gen_loss = 0.8318758858887423, disc_loss = 0.05318146428920712
Trained batch 233 in epoch 5, gen_loss = 0.8316649283863541, disc_loss = 0.053001800298284836
Trained batch 234 in epoch 5, gen_loss = 0.8319996213659328, disc_loss = 0.05279163731103565
Trained batch 235 in epoch 5, gen_loss = 0.8324324790451486, disc_loss = 0.052593009437876356
Trained batch 236 in epoch 5, gen_loss = 0.8328812085877993, disc_loss = 0.0524311611597831
Trained batch 237 in epoch 5, gen_loss = 0.8332096417160595, disc_loss = 0.052241164633315525
Trained batch 238 in epoch 5, gen_loss = 0.8334916594387597, disc_loss = 0.05203768052745252
Trained batch 239 in epoch 5, gen_loss = 0.8337306416283051, disc_loss = 0.0518387005761421
Trained batch 240 in epoch 5, gen_loss = 0.833648840545124, disc_loss = 0.05166763387798212
Trained batch 241 in epoch 5, gen_loss = 0.8339462860310374, disc_loss = 0.051474772128161074
Trained batch 242 in epoch 5, gen_loss = 0.8342769529839111, disc_loss = 0.05127989824999262
Trained batch 243 in epoch 5, gen_loss = 0.8349876932677676, disc_loss = 0.05109455501927887
Trained batch 244 in epoch 5, gen_loss = 0.8353404396650742, disc_loss = 0.050898569863175556
Trained batch 245 in epoch 5, gen_loss = 0.8355646919671113, disc_loss = 0.05074570825365107
Trained batch 246 in epoch 5, gen_loss = 0.8355871418468382, disc_loss = 0.05057078971987522
Trained batch 247 in epoch 5, gen_loss = 0.8357818067794845, disc_loss = 0.05037809517741534
Trained batch 248 in epoch 5, gen_loss = 0.8359003254926827, disc_loss = 0.05019104240432262
Trained batch 249 in epoch 5, gen_loss = 0.8360132986307144, disc_loss = 0.05001364074461162
Trained batch 250 in epoch 5, gen_loss = 0.8362963723233972, disc_loss = 0.049833459245315584
Trained batch 251 in epoch 5, gen_loss = 0.836456726113009, disc_loss = 0.049652002694543514
Trained batch 252 in epoch 5, gen_loss = 0.8368413016023372, disc_loss = 0.04947546649569638
Trained batch 253 in epoch 5, gen_loss = 0.8374483365946868, disc_loss = 0.04929280830327216
Trained batch 254 in epoch 5, gen_loss = 0.8373939290934918, disc_loss = 0.049113586406205216
Trained batch 255 in epoch 5, gen_loss = 0.8377581766108051, disc_loss = 0.04895198058329697
Trained batch 256 in epoch 5, gen_loss = 0.837912303116535, disc_loss = 0.048831110369008224
Trained batch 257 in epoch 5, gen_loss = 0.8382831960916519, disc_loss = 0.048860432094598345
Trained batch 258 in epoch 5, gen_loss = 0.8382315915293675, disc_loss = 0.04868451526755302
Trained batch 259 in epoch 5, gen_loss = 0.8380061765129749, disc_loss = 0.04851372955152049
Trained batch 260 in epoch 5, gen_loss = 0.8379788555176322, disc_loss = 0.048344915315251924
Trained batch 261 in epoch 5, gen_loss = 0.8382839047499285, disc_loss = 0.04818761660113134
Trained batch 262 in epoch 5, gen_loss = 0.8383488320805728, disc_loss = 0.04801715132798079
Trained batch 263 in epoch 5, gen_loss = 0.8386425720245549, disc_loss = 0.047855520811439914
Trained batch 264 in epoch 5, gen_loss = 0.8391863237012107, disc_loss = 0.04768888148180438
Trained batch 265 in epoch 5, gen_loss = 0.8392637507583862, disc_loss = 0.04753193814006347
Trained batch 266 in epoch 5, gen_loss = 0.8394992870561192, disc_loss = 0.047367109456675105
Trained batch 267 in epoch 5, gen_loss = 0.8399651867907438, disc_loss = 0.0472053938559187
Trained batch 268 in epoch 5, gen_loss = 0.8402858455163396, disc_loss = 0.04704643157397338
Trained batch 269 in epoch 5, gen_loss = 0.8404831777016322, disc_loss = 0.046887303493848
Trained batch 270 in epoch 5, gen_loss = 0.8403940404253253, disc_loss = 0.046730318311189484
Trained batch 271 in epoch 5, gen_loss = 0.8406023103743792, disc_loss = 0.046606714455479314
Trained batch 272 in epoch 5, gen_loss = 0.8406797696600904, disc_loss = 0.04645258543890093
Trained batch 273 in epoch 5, gen_loss = 0.8410616905367287, disc_loss = 0.04631244365200672
Trained batch 274 in epoch 5, gen_loss = 0.8412845001437447, disc_loss = 0.046165940991856835
Trained batch 275 in epoch 5, gen_loss = 0.8436342798497366, disc_loss = 0.04628766518410133
Trained batch 276 in epoch 5, gen_loss = 0.8443819375890257, disc_loss = 0.046157612018152695
Trained batch 277 in epoch 5, gen_loss = 0.8438024723486934, disc_loss = 0.046163541559639164
Trained batch 278 in epoch 5, gen_loss = 0.8436373458327359, disc_loss = 0.0460716199904253
Trained batch 279 in epoch 5, gen_loss = 0.8439568854868412, disc_loss = 0.045942704525909255
Trained batch 280 in epoch 5, gen_loss = 0.8443364213582035, disc_loss = 0.045817132117856436
Trained batch 281 in epoch 5, gen_loss = 0.845826783818556, disc_loss = 0.04582366412703661
Trained batch 282 in epoch 5, gen_loss = 0.8460283735405009, disc_loss = 0.045684466938168966
Trained batch 283 in epoch 5, gen_loss = 0.8460013630314612, disc_loss = 0.04557544448491658
Trained batch 284 in epoch 5, gen_loss = 0.8465567725792266, disc_loss = 0.04548265582702139
Trained batch 285 in epoch 5, gen_loss = 0.8468389510066359, disc_loss = 0.045379578536441485
Trained batch 286 in epoch 5, gen_loss = 0.8473750488891003, disc_loss = 0.0452442900748203
Trained batch 287 in epoch 5, gen_loss = 0.8472379784410199, disc_loss = 0.04510477799663527
Trained batch 288 in epoch 5, gen_loss = 0.8474073423440068, disc_loss = 0.04496700216123389
Trained batch 289 in epoch 5, gen_loss = 0.8474528124620174, disc_loss = 0.044835000645754665
Trained batch 290 in epoch 5, gen_loss = 0.8479801097891175, disc_loss = 0.044738139425919636
Trained batch 291 in epoch 5, gen_loss = 0.847970952011951, disc_loss = 0.04460314462879953
Trained batch 292 in epoch 5, gen_loss = 0.8483509806846189, disc_loss = 0.04446430047401847
Trained batch 293 in epoch 5, gen_loss = 0.8482846975529275, disc_loss = 0.04432761000443985
Trained batch 294 in epoch 5, gen_loss = 0.8484656433937914, disc_loss = 0.044264987284728025
Trained batch 295 in epoch 5, gen_loss = 0.8485118216155348, disc_loss = 0.044134446410336405
Trained batch 296 in epoch 5, gen_loss = 0.848758378113159, disc_loss = 0.04400535774815464
Trained batch 297 in epoch 5, gen_loss = 0.8488740740006402, disc_loss = 0.04387108489070963
Trained batch 298 in epoch 5, gen_loss = 0.8486969410177059, disc_loss = 0.04379310450800087
Trained batch 299 in epoch 5, gen_loss = 0.8488354242841403, disc_loss = 0.04365898952819407
Trained batch 300 in epoch 5, gen_loss = 0.84868896690714, disc_loss = 0.043532785507803935
Trained batch 301 in epoch 5, gen_loss = 0.8490565214922886, disc_loss = 0.04339815995159454
Trained batch 302 in epoch 5, gen_loss = 0.8490876092178987, disc_loss = 0.043263641236774106
Trained batch 303 in epoch 5, gen_loss = 0.8491462952408352, disc_loss = 0.043148784826227804
Trained batch 304 in epoch 5, gen_loss = 0.8492652653670701, disc_loss = 0.04301755135863653
Trained batch 305 in epoch 5, gen_loss = 0.8493713708290087, disc_loss = 0.04295616480750123
Trained batch 306 in epoch 5, gen_loss = 0.8493433618972667, disc_loss = 0.042825481515371695
Trained batch 307 in epoch 5, gen_loss = 0.8494557365775108, disc_loss = 0.04269336206406089
Trained batch 308 in epoch 5, gen_loss = 0.8493413380241702, disc_loss = 0.04258121159545547
Trained batch 309 in epoch 5, gen_loss = 0.8496582189875265, disc_loss = 0.042458025405874414
Trained batch 310 in epoch 5, gen_loss = 0.8499317446130649, disc_loss = 0.042360209025161105
Trained batch 311 in epoch 5, gen_loss = 0.8502045805828694, disc_loss = 0.04225630735909829
Trained batch 312 in epoch 5, gen_loss = 0.8503239647077676, disc_loss = 0.04213476364840024
Trained batch 313 in epoch 5, gen_loss = 0.8503369579839098, disc_loss = 0.04201004765616362
Trained batch 314 in epoch 5, gen_loss = 0.8506931022046105, disc_loss = 0.04188744278314213
Trained batch 315 in epoch 5, gen_loss = 0.850618232748931, disc_loss = 0.04176224780908515
Trained batch 316 in epoch 5, gen_loss = 0.8506971177430559, disc_loss = 0.04163973469196081
Trained batch 317 in epoch 5, gen_loss = 0.8509280723783205, disc_loss = 0.04152208725180852
Trained batch 318 in epoch 5, gen_loss = 0.8511390204900484, disc_loss = 0.041399046629054186
Trained batch 319 in epoch 5, gen_loss = 0.8512476806528866, disc_loss = 0.04127754128057859
Trained batch 320 in epoch 5, gen_loss = 0.851532982238728, disc_loss = 0.04116622526329185
Trained batch 321 in epoch 5, gen_loss = 0.8516911585693774, disc_loss = 0.041045325505257996
Trained batch 322 in epoch 5, gen_loss = 0.8517648667189359, disc_loss = 0.04150219879043937
Trained batch 323 in epoch 5, gen_loss = 0.8514925198238573, disc_loss = 0.041497778059069616
Trained batch 324 in epoch 5, gen_loss = 0.8510608061460349, disc_loss = 0.041472756304563235
Trained batch 325 in epoch 5, gen_loss = 0.8509907880626573, disc_loss = 0.041394199093980885
Trained batch 326 in epoch 5, gen_loss = 0.8506040132920677, disc_loss = 0.04141194140182563
Trained batch 327 in epoch 5, gen_loss = 0.8505702508477176, disc_loss = 0.04131431946681426
Trained batch 328 in epoch 5, gen_loss = 0.8505380841192866, disc_loss = 0.04126652935732122
Trained batch 329 in epoch 5, gen_loss = 0.8514535917477174, disc_loss = 0.041192281046515386
Trained batch 330 in epoch 5, gen_loss = 0.8513581384524838, disc_loss = 0.041114698164868436
Trained batch 331 in epoch 5, gen_loss = 0.8517480918980507, disc_loss = 0.04101294530513528
Trained batch 332 in epoch 5, gen_loss = 0.8514590853148395, disc_loss = 0.04093141725507786
Trained batch 333 in epoch 5, gen_loss = 0.851556302812285, disc_loss = 0.04083677042836134
Trained batch 334 in epoch 5, gen_loss = 0.8511818739015664, disc_loss = 0.04083545743487775
Trained batch 335 in epoch 5, gen_loss = 0.8516280682136615, disc_loss = 0.04079802175831338
Trained batch 336 in epoch 5, gen_loss = 0.8520905280856067, disc_loss = 0.04076727333296234
Trained batch 337 in epoch 5, gen_loss = 0.8515537838787722, disc_loss = 0.040758753642467394
Trained batch 338 in epoch 5, gen_loss = 0.8515493452197331, disc_loss = 0.040671908552827075
Trained batch 339 in epoch 5, gen_loss = 0.8522814488586258, disc_loss = 0.040605846869841436
Trained batch 340 in epoch 5, gen_loss = 0.8529775304353832, disc_loss = 0.04056759884982449
Trained batch 341 in epoch 5, gen_loss = 0.8533334199622361, disc_loss = 0.0404882319387299
Trained batch 342 in epoch 5, gen_loss = 0.8527370499278644, disc_loss = 0.04051461977729406
Trained batch 343 in epoch 5, gen_loss = 0.853004404192054, disc_loss = 0.040417400460154206
Trained batch 344 in epoch 5, gen_loss = 0.8527891216934591, disc_loss = 0.04032863449588742
Trained batch 345 in epoch 5, gen_loss = 0.853294722520547, disc_loss = 0.04024605166148179
Trained batch 346 in epoch 5, gen_loss = 0.8534962343379469, disc_loss = 0.04041236962771489
Trained batch 347 in epoch 5, gen_loss = 0.8532173106896466, disc_loss = 0.040417965111488624
Trained batch 348 in epoch 5, gen_loss = 0.8529822782834826, disc_loss = 0.040345342045938086
Trained batch 349 in epoch 5, gen_loss = 0.8525290868112019, disc_loss = 0.04033184678493334
Trained batch 350 in epoch 5, gen_loss = 0.8525504290717959, disc_loss = 0.040232533954503144
Trained batch 351 in epoch 5, gen_loss = 0.8525853393260728, disc_loss = 0.04014460377022095
Trained batch 352 in epoch 5, gen_loss = 0.853412258979619, disc_loss = 0.0401349882997583
Trained batch 353 in epoch 5, gen_loss = 0.8539496117224128, disc_loss = 0.04007796298825619
Trained batch 354 in epoch 5, gen_loss = 0.8534741044883997, disc_loss = 0.04009299199228031
Trained batch 355 in epoch 5, gen_loss = 0.8538991647322526, disc_loss = 0.04000438081840932
Trained batch 356 in epoch 5, gen_loss = 0.8540425481749516, disc_loss = 0.03991317525649501
Trained batch 357 in epoch 5, gen_loss = 0.8542000635542684, disc_loss = 0.03982044734365135
Trained batch 358 in epoch 5, gen_loss = 0.8544621421932178, disc_loss = 0.03974780194723361
Trained batch 359 in epoch 5, gen_loss = 0.8542896327873071, disc_loss = 0.03967252400406222
Trained batch 360 in epoch 5, gen_loss = 0.8547709606525971, disc_loss = 0.0395912474306388
Trained batch 361 in epoch 5, gen_loss = 0.8551989685929282, disc_loss = 0.0395646919091155
Trained batch 362 in epoch 5, gen_loss = 0.8551822977125152, disc_loss = 0.03949098492531265
Trained batch 363 in epoch 5, gen_loss = 0.8554511151307231, disc_loss = 0.03941931183370608
Trained batch 364 in epoch 5, gen_loss = 0.8558427883337622, disc_loss = 0.03932562132289454
Trained batch 365 in epoch 5, gen_loss = 0.8560533400604634, disc_loss = 0.03923703432070407
Trained batch 366 in epoch 5, gen_loss = 0.85659906333084, disc_loss = 0.039158781779148395
Trained batch 367 in epoch 5, gen_loss = 0.8565941384143155, disc_loss = 0.039074350109845196
Trained batch 368 in epoch 5, gen_loss = 0.8564849719607087, disc_loss = 0.03900682123764077
Trained batch 369 in epoch 5, gen_loss = 0.8570525745282302, disc_loss = 0.03897796175757272
Trained batch 370 in epoch 5, gen_loss = 0.8574686904319856, disc_loss = 0.038903040010005115
Trained batch 371 in epoch 5, gen_loss = 0.8577887475971253, disc_loss = 0.03882040649149267
Trained batch 372 in epoch 5, gen_loss = 0.8576851433627407, disc_loss = 0.038763011687737325
Trained batch 373 in epoch 5, gen_loss = 0.8573566154840796, disc_loss = 0.03870408397782992
Trained batch 374 in epoch 5, gen_loss = 0.8573506073156992, disc_loss = 0.038628625379875305
Trained batch 375 in epoch 5, gen_loss = 0.8572855302469528, disc_loss = 0.038539011902646456
Trained batch 376 in epoch 5, gen_loss = 0.8576856831814945, disc_loss = 0.0384503481483497
Trained batch 377 in epoch 5, gen_loss = 0.8577400479840223, disc_loss = 0.03839607717575279
Trained batch 378 in epoch 5, gen_loss = 0.8580880029063112, disc_loss = 0.03830918038109106
Trained batch 379 in epoch 5, gen_loss = 0.8577850538649057, disc_loss = 0.03825710531949115
Trained batch 380 in epoch 5, gen_loss = 0.8578554713350581, disc_loss = 0.03817663791716549
Trained batch 381 in epoch 5, gen_loss = 0.8577227697790605, disc_loss = 0.03810712786974064
Trained batch 382 in epoch 5, gen_loss = 0.858151824215996, disc_loss = 0.038148488646966475
Trained batch 383 in epoch 5, gen_loss = 0.8578774186316878, disc_loss = 0.038081966075575714
Trained batch 384 in epoch 5, gen_loss = 0.8576715098573016, disc_loss = 0.03800211749281492
Trained batch 385 in epoch 5, gen_loss = 0.8577354209873961, disc_loss = 0.037913865575668226
Trained batch 386 in epoch 5, gen_loss = 0.8581473647932057, disc_loss = 0.03785248598606068
Trained batch 387 in epoch 5, gen_loss = 0.8583612508841396, disc_loss = 0.0377666743012558
Trained batch 388 in epoch 5, gen_loss = 0.858484576707634, disc_loss = 0.0376969213079144
Trained batch 389 in epoch 5, gen_loss = 0.8588138050757922, disc_loss = 0.03764016069053935
Trained batch 390 in epoch 5, gen_loss = 0.8589112933182046, disc_loss = 0.0375736999686312
Trained batch 391 in epoch 5, gen_loss = 0.8595037035339949, disc_loss = 0.037494063415987496
Trained batch 392 in epoch 5, gen_loss = 0.8603262113402514, disc_loss = 0.03742355787735575
Trained batch 393 in epoch 5, gen_loss = 0.8607376421314811, disc_loss = 0.03734962912193655
Trained batch 394 in epoch 5, gen_loss = 0.8611959986294372, disc_loss = 0.037268776451885886
Trained batch 395 in epoch 5, gen_loss = 0.8615816657741865, disc_loss = 0.03719002112447557
Trained batch 396 in epoch 5, gen_loss = 0.8619016514767327, disc_loss = 0.037120555155096525
Trained batch 397 in epoch 5, gen_loss = 0.861876977673128, disc_loss = 0.037048136273132234
Trained batch 398 in epoch 5, gen_loss = 0.8619604077106132, disc_loss = 0.03696782761346782
Trained batch 399 in epoch 5, gen_loss = 0.8626849969476461, disc_loss = 0.036922866403474475
Trained batch 400 in epoch 5, gen_loss = 0.8627644642778762, disc_loss = 0.03684990343224359
Trained batch 401 in epoch 5, gen_loss = 0.8629542364558177, disc_loss = 0.03678134914003405
Trained batch 402 in epoch 5, gen_loss = 0.8634465481004407, disc_loss = 0.03670257868108896
Trained batch 403 in epoch 5, gen_loss = 0.864003362705802, disc_loss = 0.036625276060917845
Trained batch 404 in epoch 5, gen_loss = 0.8644124473318642, disc_loss = 0.03655212820898512
Trained batch 405 in epoch 5, gen_loss = 0.8646006539390592, disc_loss = 0.03647254182087725
Trained batch 406 in epoch 5, gen_loss = 0.8649346701782518, disc_loss = 0.03639445177288566
Trained batch 407 in epoch 5, gen_loss = 0.8652009520606667, disc_loss = 0.03631311129634816
Trained batch 408 in epoch 5, gen_loss = 0.8651877416520947, disc_loss = 0.036254443032985834
Trained batch 409 in epoch 5, gen_loss = 0.8654157235128124, disc_loss = 0.03617860344636095
Trained batch 410 in epoch 5, gen_loss = 0.8657609428077429, disc_loss = 0.036755576299802556
Trained batch 411 in epoch 5, gen_loss = 0.8654207929390149, disc_loss = 0.03690049378257878
Trained batch 412 in epoch 5, gen_loss = 0.8654025821218191, disc_loss = 0.03687582810445447
Trained batch 413 in epoch 5, gen_loss = 0.8661987173240542, disc_loss = 0.03684392512116833
Trained batch 414 in epoch 5, gen_loss = 0.8668511344007699, disc_loss = 0.0368496994841395
Trained batch 415 in epoch 5, gen_loss = 0.8669353969251881, disc_loss = 0.03678702790113256
Trained batch 416 in epoch 5, gen_loss = 0.8670368068081011, disc_loss = 0.03674315170349209
Trained batch 417 in epoch 5, gen_loss = 0.8670016476554734, disc_loss = 0.03674164443426101
Trained batch 418 in epoch 5, gen_loss = 0.8676200565261887, disc_loss = 0.03668933634108337
Trained batch 419 in epoch 5, gen_loss = 0.8680254792173704, disc_loss = 0.03663858903760445
Trained batch 420 in epoch 5, gen_loss = 0.8681889666939008, disc_loss = 0.03657025603451401
Trained batch 421 in epoch 5, gen_loss = 0.8681862717979892, disc_loss = 0.03650615582633234
Trained batch 422 in epoch 5, gen_loss = 0.86843239295849, disc_loss = 0.03646212922195611
Trained batch 423 in epoch 5, gen_loss = 0.8686895324795876, disc_loss = 0.0363907069401631
Trained batch 424 in epoch 5, gen_loss = 0.86880568132681, disc_loss = 0.03631679485332878
Trained batch 425 in epoch 5, gen_loss = 0.8689127297888339, disc_loss = 0.03624054715922758
Trained batch 426 in epoch 5, gen_loss = 0.8689646101807543, disc_loss = 0.03616432746080572
Trained batch 427 in epoch 5, gen_loss = 0.8692178906542118, disc_loss = 0.03609035189304866
Trained batch 428 in epoch 5, gen_loss = 0.8694122551065503, disc_loss = 0.036014222862884956
Trained batch 429 in epoch 5, gen_loss = 0.8696332689634589, disc_loss = 0.03601822821412582
Trained batch 430 in epoch 5, gen_loss = 0.8697085072850407, disc_loss = 0.03595409144889434
Trained batch 431 in epoch 5, gen_loss = 0.8695532797525326, disc_loss = 0.03592914823362931
Trained batch 432 in epoch 5, gen_loss = 0.8697652069993713, disc_loss = 0.03585701631371353
Trained batch 433 in epoch 5, gen_loss = 0.8697714598909501, disc_loss = 0.03578410091249847
Trained batch 434 in epoch 5, gen_loss = 0.8699221843275531, disc_loss = 0.03571498163697449
Trained batch 435 in epoch 5, gen_loss = 0.8698006156797803, disc_loss = 0.03564434917056249
Trained batch 436 in epoch 5, gen_loss = 0.8700182103046836, disc_loss = 0.03557213282402289
Trained batch 437 in epoch 5, gen_loss = 0.8697445005450619, disc_loss = 0.03551126582086614
Trained batch 438 in epoch 5, gen_loss = 0.8693595067650962, disc_loss = 0.03557523858631645
Trained batch 439 in epoch 5, gen_loss = 0.869578279080716, disc_loss = 0.0355107215100857
Trained batch 440 in epoch 5, gen_loss = 0.8696940966339068, disc_loss = 0.03545240418565229
Trained batch 441 in epoch 5, gen_loss = 0.8702100544358811, disc_loss = 0.03542483224780025
Trained batch 442 in epoch 5, gen_loss = 0.870654983862259, disc_loss = 0.03538975713440295
Trained batch 443 in epoch 5, gen_loss = 0.8706013869729128, disc_loss = 0.03532267980401295
Trained batch 444 in epoch 5, gen_loss = 0.8706485826647683, disc_loss = 0.03525569972038018
Trained batch 445 in epoch 5, gen_loss = 0.8706051510144777, disc_loss = 0.03518840099732922
Trained batch 446 in epoch 5, gen_loss = 0.8704044094155032, disc_loss = 0.03514097398511599
Trained batch 447 in epoch 5, gen_loss = 0.8704137786823724, disc_loss = 0.03516529036538226
Trained batch 448 in epoch 5, gen_loss = 0.8698864907756415, disc_loss = 0.035192983229654966
Trained batch 449 in epoch 5, gen_loss = 0.8694686785671446, disc_loss = 0.03520945560652763
Trained batch 450 in epoch 5, gen_loss = 0.8697146035218715, disc_loss = 0.03517908735991664
Trained batch 451 in epoch 5, gen_loss = 0.8696104274254984, disc_loss = 0.03512772284005151
Trained batch 452 in epoch 5, gen_loss = 0.8697234390192474, disc_loss = 0.03508099177225223
Trained batch 453 in epoch 5, gen_loss = 0.8698729962635671, disc_loss = 0.03503794473799003
Trained batch 454 in epoch 5, gen_loss = 0.8695177703768342, disc_loss = 0.035029237910306876
Trained batch 455 in epoch 5, gen_loss = 0.8693675488364279, disc_loss = 0.03504331426729709
Trained batch 456 in epoch 5, gen_loss = 0.8692020564554035, disc_loss = 0.035128747563935504
Trained batch 457 in epoch 5, gen_loss = 0.8690182572499113, disc_loss = 0.03507247817749361
Trained batch 458 in epoch 5, gen_loss = 0.8694016993824952, disc_loss = 0.03502577527280094
Trained batch 459 in epoch 5, gen_loss = 0.8695607765213303, disc_loss = 0.03497510893199512
Trained batch 460 in epoch 5, gen_loss = 0.8697515456510987, disc_loss = 0.03491342578986316
Trained batch 461 in epoch 5, gen_loss = 0.869632559872809, disc_loss = 0.03485083255717265
Trained batch 462 in epoch 5, gen_loss = 0.8696874289353002, disc_loss = 0.03478543373120478
Trained batch 463 in epoch 5, gen_loss = 0.8697934591950014, disc_loss = 0.03472353237960086
Trained batch 464 in epoch 5, gen_loss = 0.8699309053600476, disc_loss = 0.03465587922411981
Trained batch 465 in epoch 5, gen_loss = 0.8698412271400378, disc_loss = 0.03459284845549741
Trained batch 466 in epoch 5, gen_loss = 0.86968237499864, disc_loss = 0.03455389608585174
Trained batch 467 in epoch 5, gen_loss = 0.8690788082969494, disc_loss = 0.03457284208564247
Trained batch 468 in epoch 5, gen_loss = 0.8689527587214513, disc_loss = 0.03450978982067709
Trained batch 469 in epoch 5, gen_loss = 0.86962742012866, disc_loss = 0.034557364146383676
Trained batch 470 in epoch 5, gen_loss = 0.8702782189390462, disc_loss = 0.034545024301789524
Trained batch 471 in epoch 5, gen_loss = 0.8698416989359815, disc_loss = 0.03458743169361141
Trained batch 472 in epoch 5, gen_loss = 0.8700971324272438, disc_loss = 0.034551285343622715
Trained batch 473 in epoch 5, gen_loss = 0.8701854742403272, disc_loss = 0.03449816370573492
Trained batch 474 in epoch 5, gen_loss = 0.8701806720306999, disc_loss = 0.03444167976463704
Trained batch 475 in epoch 5, gen_loss = 0.8702213124943381, disc_loss = 0.03442227846048694
Trained batch 476 in epoch 5, gen_loss = 0.8702808850341373, disc_loss = 0.03437780890080773
Trained batch 477 in epoch 5, gen_loss = 0.8702425858839785, disc_loss = 0.034324145600663415
Trained batch 478 in epoch 5, gen_loss = 0.8700697351721483, disc_loss = 0.03430206915956683
Trained batch 479 in epoch 5, gen_loss = 0.8698132598772645, disc_loss = 0.03429486288756986
Trained batch 480 in epoch 5, gen_loss = 0.869759874445485, disc_loss = 0.03423425035789346
Trained batch 481 in epoch 5, gen_loss = 0.8694316661333148, disc_loss = 0.03422600358069577
Trained batch 482 in epoch 5, gen_loss = 0.8701480612868354, disc_loss = 0.03438662868195578
Trained batch 483 in epoch 5, gen_loss = 0.8698456508438449, disc_loss = 0.03434079408131863
Trained batch 484 in epoch 5, gen_loss = 0.8695320535566389, disc_loss = 0.03440776992560431
Trained batch 485 in epoch 5, gen_loss = 0.869282164507442, disc_loss = 0.03439384377551928
Trained batch 486 in epoch 5, gen_loss = 0.8691869147381989, disc_loss = 0.03435763604872051
Trained batch 487 in epoch 5, gen_loss = 0.8686956235009139, disc_loss = 0.034442285288098555
Trained batch 488 in epoch 5, gen_loss = 0.8692712417531355, disc_loss = 0.03458285810004973
Trained batch 489 in epoch 5, gen_loss = 0.8690746834691689, disc_loss = 0.034547267670325024
Trained batch 490 in epoch 5, gen_loss = 0.8690315343576148, disc_loss = 0.034493321449023555
Trained batch 491 in epoch 5, gen_loss = 0.869372149490244, disc_loss = 0.03445365352648863
Trained batch 492 in epoch 5, gen_loss = 0.8692981731939993, disc_loss = 0.03440169658385308
Trained batch 493 in epoch 5, gen_loss = 0.8686344787056147, disc_loss = 0.03462504958290878
Trained batch 494 in epoch 5, gen_loss = 0.8688772868026386, disc_loss = 0.03461547087962655
Trained batch 495 in epoch 5, gen_loss = 0.8687762736432976, disc_loss = 0.03469872710927795
Trained batch 496 in epoch 5, gen_loss = 0.8687454484238232, disc_loss = 0.03465265279094233
Trained batch 497 in epoch 5, gen_loss = 0.8685708963368313, disc_loss = 0.03460716049282262
Trained batch 498 in epoch 5, gen_loss = 0.8682766152407698, disc_loss = 0.03456833780806638
Trained batch 499 in epoch 5, gen_loss = 0.8679353435635566, disc_loss = 0.0348474558130838
Trained batch 500 in epoch 5, gen_loss = 0.8674394682852807, disc_loss = 0.03488036437553099
Trained batch 501 in epoch 5, gen_loss = 0.8668293928601353, disc_loss = 0.0350309357522946
Trained batch 502 in epoch 5, gen_loss = 0.8669111393910516, disc_loss = 0.035017244642318986
Trained batch 503 in epoch 5, gen_loss = 0.8667372332087585, disc_loss = 0.03512747077842332
Trained batch 504 in epoch 5, gen_loss = 0.8662972009418034, disc_loss = 0.035087348045412414
Trained batch 505 in epoch 5, gen_loss = 0.8660726644422697, disc_loss = 0.035084050447356116
Trained batch 506 in epoch 5, gen_loss = 0.8657514511128149, disc_loss = 0.03506102484257807
Trained batch 507 in epoch 5, gen_loss = 0.866012644990692, disc_loss = 0.035034071988202485
Trained batch 508 in epoch 5, gen_loss = 0.8659914875428663, disc_loss = 0.03499973876436546
Trained batch 509 in epoch 5, gen_loss = 0.8659163489645603, disc_loss = 0.03494693806404065
Trained batch 510 in epoch 5, gen_loss = 0.8656311141884724, disc_loss = 0.03494767375962914
Trained batch 511 in epoch 5, gen_loss = 0.8654736446333118, disc_loss = 0.034894193853233446
Trained batch 512 in epoch 5, gen_loss = 0.8655845582717576, disc_loss = 0.0348363189915373
Trained batch 513 in epoch 5, gen_loss = 0.8651980191237267, disc_loss = 0.0350104676507928
Trained batch 514 in epoch 5, gen_loss = 0.8650871780890863, disc_loss = 0.03508059954026587
Trained batch 515 in epoch 5, gen_loss = 0.8649543791200763, disc_loss = 0.035060740564679074
Trained batch 516 in epoch 5, gen_loss = 0.8644590818789757, disc_loss = 0.035162499658601284
Trained batch 517 in epoch 5, gen_loss = 0.8648174704847188, disc_loss = 0.035260036405675745
Trained batch 518 in epoch 5, gen_loss = 0.8644042248785611, disc_loss = 0.03531938270658527
Trained batch 519 in epoch 5, gen_loss = 0.8647582078782412, disc_loss = 0.035495215616314316
Trained batch 520 in epoch 5, gen_loss = 0.8642960754214231, disc_loss = 0.035589275832936855
Trained batch 521 in epoch 5, gen_loss = 0.863887925657276, disc_loss = 0.035631599609019286
Trained batch 522 in epoch 5, gen_loss = 0.8640530954469459, disc_loss = 0.035641081023509
Trained batch 523 in epoch 5, gen_loss = 0.8640272244811058, disc_loss = 0.035604431497853764
Trained batch 524 in epoch 5, gen_loss = 0.863983724968774, disc_loss = 0.03560041490543101
Trained batch 525 in epoch 5, gen_loss = 0.864061097965041, disc_loss = 0.03555979919416242
Trained batch 526 in epoch 5, gen_loss = 0.8639530419059225, disc_loss = 0.03560659924629842
Trained batch 527 in epoch 5, gen_loss = 0.8641155038706281, disc_loss = 0.035652819383716575
Trained batch 528 in epoch 5, gen_loss = 0.8636766617487419, disc_loss = 0.03571293494375405
Trained batch 529 in epoch 5, gen_loss = 0.8637385057390861, disc_loss = 0.035682754891151386
Trained batch 530 in epoch 5, gen_loss = 0.8635136354328773, disc_loss = 0.03568714663251294
Trained batch 531 in epoch 5, gen_loss = 0.8635719345140278, disc_loss = 0.03572392537690965
Trained batch 532 in epoch 5, gen_loss = 0.8634511557238187, disc_loss = 0.03607744714952865
Trained batch 533 in epoch 5, gen_loss = 0.8632968083191453, disc_loss = 0.03603839879630531
Trained batch 534 in epoch 5, gen_loss = 0.8634585735396804, disc_loss = 0.03599904665558068
Trained batch 535 in epoch 5, gen_loss = 0.8632409268461946, disc_loss = 0.03596522268420433
Trained batch 536 in epoch 5, gen_loss = 0.8633105975178589, disc_loss = 0.03592389185125532
Trained batch 537 in epoch 5, gen_loss = 0.8630924636435775, disc_loss = 0.035904310366266914
Trained batch 538 in epoch 5, gen_loss = 0.8628758434793724, disc_loss = 0.03587176966574216
Trained batch 539 in epoch 5, gen_loss = 0.8629887772379098, disc_loss = 0.035817414930486985
Trained batch 540 in epoch 5, gen_loss = 0.8630694820237468, disc_loss = 0.03577840478803322
Trained batch 541 in epoch 5, gen_loss = 0.8632168142448052, disc_loss = 0.0357291006093941
Trained batch 542 in epoch 5, gen_loss = 0.8631192890868881, disc_loss = 0.035689969399161844
Trained batch 543 in epoch 5, gen_loss = 0.8633815991856596, disc_loss = 0.0356392628947266
Trained batch 544 in epoch 5, gen_loss = 0.8639157089071536, disc_loss = 0.03562529834132607
Trained batch 545 in epoch 5, gen_loss = 0.8639110849126355, disc_loss = 0.03556727995923737
Trained batch 546 in epoch 5, gen_loss = 0.8639411363457848, disc_loss = 0.03553218794245974
Trained batch 547 in epoch 5, gen_loss = 0.8638393713066178, disc_loss = 0.03548747530490853
Trained batch 548 in epoch 5, gen_loss = 0.8640310566173443, disc_loss = 0.03543700091837683
Trained batch 549 in epoch 5, gen_loss = 0.8642143271727996, disc_loss = 0.0354112286624414
Trained batch 550 in epoch 5, gen_loss = 0.8640443683211471, disc_loss = 0.035385419389388495
Trained batch 551 in epoch 5, gen_loss = 0.8643192026386226, disc_loss = 0.035341713752553704
Trained batch 552 in epoch 5, gen_loss = 0.8645210492998955, disc_loss = 0.035298612941760454
Trained batch 553 in epoch 5, gen_loss = 0.8645317289265485, disc_loss = 0.03524249407676274
Trained batch 554 in epoch 5, gen_loss = 0.8643827290685328, disc_loss = 0.03521031782509306
Trained batch 555 in epoch 5, gen_loss = 0.8642845137192191, disc_loss = 0.03516489262868509
Trained batch 556 in epoch 5, gen_loss = 0.8646778568652203, disc_loss = 0.03513282308935169
Trained batch 557 in epoch 5, gen_loss = 0.8648777663387278, disc_loss = 0.03508806502234565
Trained batch 558 in epoch 5, gen_loss = 0.864816006426308, disc_loss = 0.03503110427501043
Trained batch 559 in epoch 5, gen_loss = 0.864899300837091, disc_loss = 0.03499549789412413
Trained batch 560 in epoch 5, gen_loss = 0.8648625675475958, disc_loss = 0.03495577871492348
Trained batch 561 in epoch 5, gen_loss = 0.8650691823709054, disc_loss = 0.03500103758228777
Trained batch 562 in epoch 5, gen_loss = 0.8647246008762034, disc_loss = 0.035073361919901694
Trained batch 563 in epoch 5, gen_loss = 0.8652320600887562, disc_loss = 0.035189062528269276
Trained batch 564 in epoch 5, gen_loss = 0.8652806007229121, disc_loss = 0.035150048604432854
Trained batch 565 in epoch 5, gen_loss = 0.8649912689789445, disc_loss = 0.03516022525949884
Trained batch 566 in epoch 5, gen_loss = 0.8650563680410805, disc_loss = 0.0351117510842143
Trained batch 567 in epoch 5, gen_loss = 0.8652742335599073, disc_loss = 0.03507250767655369
Trained batch 568 in epoch 5, gen_loss = 0.8651254848038584, disc_loss = 0.0350472872020261
Trained batch 569 in epoch 5, gen_loss = 0.8651481559924912, disc_loss = 0.03500183582052654
Trained batch 570 in epoch 5, gen_loss = 0.8651715568715345, disc_loss = 0.034963265849577485
Trained batch 571 in epoch 5, gen_loss = 0.8651799398598138, disc_loss = 0.03491039546833445
Trained batch 572 in epoch 5, gen_loss = 0.8653437508234387, disc_loss = 0.03485985686734358
Trained batch 573 in epoch 5, gen_loss = 0.8652248573116309, disc_loss = 0.03480745024227891
Trained batch 574 in epoch 5, gen_loss = 0.86525080198827, disc_loss = 0.03477056122708904
Trained batch 575 in epoch 5, gen_loss = 0.8653827505703602, disc_loss = 0.034726007046426983
Trained batch 576 in epoch 5, gen_loss = 0.8654088210088542, disc_loss = 0.03467836880054086
Trained batch 577 in epoch 5, gen_loss = 0.8655671709858422, disc_loss = 0.03462492151405005
Trained batch 578 in epoch 5, gen_loss = 0.8655239599459323, disc_loss = 0.034633487393831854
Trained batch 579 in epoch 5, gen_loss = 0.865492022191656, disc_loss = 0.03458966568658321
Trained batch 580 in epoch 5, gen_loss = 0.8654119454952608, disc_loss = 0.03455863904733717
Trained batch 581 in epoch 5, gen_loss = 0.8655411314820916, disc_loss = 0.034505874306584396
Trained batch 582 in epoch 5, gen_loss = 0.8658243144253719, disc_loss = 0.03446414805773013
Trained batch 583 in epoch 5, gen_loss = 0.865969697855515, disc_loss = 0.03442211747600072
Trained batch 584 in epoch 5, gen_loss = 0.8658645225895776, disc_loss = 0.0343791180019641
Trained batch 585 in epoch 5, gen_loss = 0.8660142885031553, disc_loss = 0.03433388155891398
Trained batch 586 in epoch 5, gen_loss = 0.8662078426785932, disc_loss = 0.03428762368191497
Trained batch 587 in epoch 5, gen_loss = 0.8657219837210617, disc_loss = 0.03436752104795962
Trained batch 588 in epoch 5, gen_loss = 0.8660440756125037, disc_loss = 0.03432952177652327
Trained batch 589 in epoch 5, gen_loss = 0.8664114028215408, disc_loss = 0.03442185814255627
Trained batch 590 in epoch 5, gen_loss = 0.8661240215733168, disc_loss = 0.03443396584542118
Trained batch 591 in epoch 5, gen_loss = 0.8657804767324312, disc_loss = 0.034469945206797706
Trained batch 592 in epoch 5, gen_loss = 0.8658464643947189, disc_loss = 0.034433122735288355
Trained batch 593 in epoch 5, gen_loss = 0.8659127000907455, disc_loss = 0.03438979907506945
Trained batch 594 in epoch 5, gen_loss = 0.8663924597391561, disc_loss = 0.03439568622084726
Trained batch 595 in epoch 5, gen_loss = 0.8666759392859151, disc_loss = 0.03434758516959846
Trained batch 596 in epoch 5, gen_loss = 0.8664205976367196, disc_loss = 0.03436906131411867
Trained batch 597 in epoch 5, gen_loss = 0.8667896491129662, disc_loss = 0.03433824745614244
Trained batch 598 in epoch 5, gen_loss = 0.8666109962634531, disc_loss = 0.03432779376222465
Trained batch 599 in epoch 5, gen_loss = 0.8665956718226274, disc_loss = 0.03428638767140607
Trained batch 600 in epoch 5, gen_loss = 0.8668034454054523, disc_loss = 0.03425149041880387
Trained batch 601 in epoch 5, gen_loss = 0.8669024755887415, disc_loss = 0.03421079899892954
Trained batch 602 in epoch 5, gen_loss = 0.8663544143313793, disc_loss = 0.0343251068972879
Trained batch 603 in epoch 5, gen_loss = 0.8667810348584163, disc_loss = 0.03432313749714699
Trained batch 604 in epoch 5, gen_loss = 0.8665358804966793, disc_loss = 0.03438004098586307
Trained batch 605 in epoch 5, gen_loss = 0.8669134663178188, disc_loss = 0.034370952888265895
Trained batch 606 in epoch 5, gen_loss = 0.8671936167425536, disc_loss = 0.034339422053201785
Trained batch 607 in epoch 5, gen_loss = 0.867290233654019, disc_loss = 0.03431725616897702
Trained batch 608 in epoch 5, gen_loss = 0.8672597793424853, disc_loss = 0.03427905415005872
Trained batch 609 in epoch 5, gen_loss = 0.8672834298161209, disc_loss = 0.0342345298412943
Trained batch 610 in epoch 5, gen_loss = 0.8672044134276589, disc_loss = 0.03420634458981662
Trained batch 611 in epoch 5, gen_loss = 0.867377759633111, disc_loss = 0.03416074546102702
Trained batch 612 in epoch 5, gen_loss = 0.8674678959523678, disc_loss = 0.03411527459097944
Trained batch 613 in epoch 5, gen_loss = 0.86755864671659, disc_loss = 0.034073550972317006
Trained batch 614 in epoch 5, gen_loss = 0.8675151908785347, disc_loss = 0.03403688980175591
Trained batch 615 in epoch 5, gen_loss = 0.8675227604999944, disc_loss = 0.03403013604375618
Trained batch 616 in epoch 5, gen_loss = 0.8676553843376895, disc_loss = 0.03398317935524849
Trained batch 617 in epoch 5, gen_loss = 0.8675998626306991, disc_loss = 0.03397991094198741
Trained batch 618 in epoch 5, gen_loss = 0.8675719232378175, disc_loss = 0.03395693799817817
Trained batch 619 in epoch 5, gen_loss = 0.8678838207356392, disc_loss = 0.03393068236464094
Trained batch 620 in epoch 5, gen_loss = 0.8680414690391645, disc_loss = 0.033889870302550695
Trained batch 621 in epoch 5, gen_loss = 0.8682284910483375, disc_loss = 0.03384110634589502
Trained batch 622 in epoch 5, gen_loss = 0.8682426896849184, disc_loss = 0.033797401576833634
Trained batch 623 in epoch 5, gen_loss = 0.8677737706651291, disc_loss = 0.033893993262422435
Trained batch 624 in epoch 5, gen_loss = 0.8676776711940766, disc_loss = 0.03384830872118473
Trained batch 625 in epoch 5, gen_loss = 0.8679723897204993, disc_loss = 0.033845037016601034
Trained batch 626 in epoch 5, gen_loss = 0.8680896416330262, disc_loss = 0.03424725838100606
Trained batch 627 in epoch 5, gen_loss = 0.8678130362728599, disc_loss = 0.03426923714044273
Trained batch 628 in epoch 5, gen_loss = 0.8675177077894559, disc_loss = 0.034277559851780416
Trained batch 629 in epoch 5, gen_loss = 0.8671668210199901, disc_loss = 0.03428409781070456
Trained batch 630 in epoch 5, gen_loss = 0.8678372192023862, disc_loss = 0.03431892331553809
Trained batch 631 in epoch 5, gen_loss = 0.8680743271885794, disc_loss = 0.03428840516223513
Trained batch 632 in epoch 5, gen_loss = 0.8682209063574413, disc_loss = 0.03425491194418774
Trained batch 633 in epoch 5, gen_loss = 0.8682532278991272, disc_loss = 0.034225537719304915
Trained batch 634 in epoch 5, gen_loss = 0.8681170550387676, disc_loss = 0.034195305487713004
Trained batch 635 in epoch 5, gen_loss = 0.8678449049779454, disc_loss = 0.034197686086320934
Trained batch 636 in epoch 5, gen_loss = 0.8680752499417944, disc_loss = 0.03415167838001691
Trained batch 637 in epoch 5, gen_loss = 0.8680309630393235, disc_loss = 0.034106345852358166
Trained batch 638 in epoch 5, gen_loss = 0.867966073266404, disc_loss = 0.0340723269225531
Trained batch 639 in epoch 5, gen_loss = 0.8678088913206011, disc_loss = 0.034048925093520664
Trained batch 640 in epoch 5, gen_loss = 0.8680054481706455, disc_loss = 0.034013065135370876
Trained batch 641 in epoch 5, gen_loss = 0.8675834469241888, disc_loss = 0.034030735071290084
Trained batch 642 in epoch 5, gen_loss = 0.8677235766202444, disc_loss = 0.03403473894211752
Trained batch 643 in epoch 5, gen_loss = 0.8677200269162285, disc_loss = 0.03401292000842275
Trained batch 644 in epoch 5, gen_loss = 0.8676224175811738, disc_loss = 0.033970842231065036
Trained batch 645 in epoch 5, gen_loss = 0.8678029398707783, disc_loss = 0.033934123344840514
Trained batch 646 in epoch 5, gen_loss = 0.8674970087257013, disc_loss = 0.03395211565707
Trained batch 647 in epoch 5, gen_loss = 0.867556507618707, disc_loss = 0.03396665965232791
Trained batch 648 in epoch 5, gen_loss = 0.8671629956488617, disc_loss = 0.034051989465636215
Trained batch 649 in epoch 5, gen_loss = 0.8670731526613236, disc_loss = 0.034011901134911635
Trained batch 650 in epoch 5, gen_loss = 0.8672520213870591, disc_loss = 0.03415823831922516
Trained batch 651 in epoch 5, gen_loss = 0.8672760060868381, disc_loss = 0.03413531344963889
Trained batch 652 in epoch 5, gen_loss = 0.8668338193188765, disc_loss = 0.03428936920486744
Trained batch 653 in epoch 5, gen_loss = 0.866589528112601, disc_loss = 0.034308728271389
Trained batch 654 in epoch 5, gen_loss = 0.8664314868340965, disc_loss = 0.03428797304616061
Trained batch 655 in epoch 5, gen_loss = 0.8665751599956576, disc_loss = 0.03446096212747961
Trained batch 656 in epoch 5, gen_loss = 0.8669983188039092, disc_loss = 0.034447061288478124
Trained batch 657 in epoch 5, gen_loss = 0.8670606032965031, disc_loss = 0.0344030248761279
Trained batch 658 in epoch 5, gen_loss = 0.8669294510064972, disc_loss = 0.034389320772977856
Trained batch 659 in epoch 5, gen_loss = 0.86672990931706, disc_loss = 0.03437113679000035
Trained batch 660 in epoch 5, gen_loss = 0.8668185291690653, disc_loss = 0.03433259641159884
Trained batch 661 in epoch 5, gen_loss = 0.8667794596122471, disc_loss = 0.0343059365281672
Trained batch 662 in epoch 5, gen_loss = 0.8667908554073552, disc_loss = 0.03425913165129586
Trained batch 663 in epoch 5, gen_loss = 0.8668171508035746, disc_loss = 0.03421328097991421
Trained batch 664 in epoch 5, gen_loss = 0.8666885705370652, disc_loss = 0.03416795529761261
Trained batch 665 in epoch 5, gen_loss = 0.8666218042642146, disc_loss = 0.03412716420697378
Trained batch 666 in epoch 5, gen_loss = 0.8666452177907752, disc_loss = 0.03408420604068613
Trained batch 667 in epoch 5, gen_loss = 0.8666563899128022, disc_loss = 0.03404817159125905
Trained batch 668 in epoch 5, gen_loss = 0.8667850210616763, disc_loss = 0.03400667877631159
Trained batch 669 in epoch 5, gen_loss = 0.8667642678342649, disc_loss = 0.03396731619306131
Trained batch 670 in epoch 5, gen_loss = 0.8667935635311593, disc_loss = 0.03392437916532181
Trained batch 671 in epoch 5, gen_loss = 0.8668351225288851, disc_loss = 0.033880263829598245
Trained batch 672 in epoch 5, gen_loss = 0.866891105718811, disc_loss = 0.03383890197115547
Trained batch 673 in epoch 5, gen_loss = 0.8669396714481472, disc_loss = 0.03379401499654224
Trained batch 674 in epoch 5, gen_loss = 0.8669510318173302, disc_loss = 0.03374795017798466
Trained batch 675 in epoch 5, gen_loss = 0.8669603563536553, disc_loss = 0.033701787368992354
Trained batch 676 in epoch 5, gen_loss = 0.8670487125215713, disc_loss = 0.03365658290486128
Trained batch 677 in epoch 5, gen_loss = 0.8670032943508267, disc_loss = 0.033610398339239504
Trained batch 678 in epoch 5, gen_loss = 0.8669309768392341, disc_loss = 0.03356540132113712
Trained batch 679 in epoch 5, gen_loss = 0.8670171186766203, disc_loss = 0.03353982116164202
Trained batch 680 in epoch 5, gen_loss = 0.866987537313663, disc_loss = 0.033494314788765495
Trained batch 681 in epoch 5, gen_loss = 0.8668704651230591, disc_loss = 0.0334524913469761
Trained batch 682 in epoch 5, gen_loss = 0.866938282551563, disc_loss = 0.03343385175459556
Trained batch 683 in epoch 5, gen_loss = 0.8668737461605267, disc_loss = 0.033397290178939526
Trained batch 684 in epoch 5, gen_loss = 0.8669381344840474, disc_loss = 0.03335416444278166
Trained batch 685 in epoch 5, gen_loss = 0.866943498698685, disc_loss = 0.033308557574447166
Trained batch 686 in epoch 5, gen_loss = 0.866984905591004, disc_loss = 0.033276919995704354
Trained batch 687 in epoch 5, gen_loss = 0.8668907071182201, disc_loss = 0.03323584942446296
Trained batch 688 in epoch 5, gen_loss = 0.8669401108353508, disc_loss = 0.033208742393424036
Trained batch 689 in epoch 5, gen_loss = 0.8669010713912438, disc_loss = 0.033184277675573484
Trained batch 690 in epoch 5, gen_loss = 0.8669004256145654, disc_loss = 0.033149507305451416
Trained batch 691 in epoch 5, gen_loss = 0.8670518384072822, disc_loss = 0.03310613677065787
Trained batch 692 in epoch 5, gen_loss = 0.8672455794797487, disc_loss = 0.033071660096347225
Trained batch 693 in epoch 5, gen_loss = 0.8673871198631501, disc_loss = 0.03303880010421525
Trained batch 694 in epoch 5, gen_loss = 0.8673653775410687, disc_loss = 0.03299503624070731
Trained batch 695 in epoch 5, gen_loss = 0.8672196474140403, disc_loss = 0.03296575899504864
Trained batch 696 in epoch 5, gen_loss = 0.8671534741711582, disc_loss = 0.03292784124373631
Trained batch 697 in epoch 5, gen_loss = 0.8671320468016546, disc_loss = 0.03288672911170016
Trained batch 698 in epoch 5, gen_loss = 0.8672847072027613, disc_loss = 0.03284479711552514
Trained batch 699 in epoch 5, gen_loss = 0.8674486146228654, disc_loss = 0.03281117231485301
Trained batch 700 in epoch 5, gen_loss = 0.8674314233358849, disc_loss = 0.03276834990556874
Trained batch 701 in epoch 5, gen_loss = 0.8674254883982857, disc_loss = 0.032728303544570896
Trained batch 702 in epoch 5, gen_loss = 0.8674594730689889, disc_loss = 0.032688526590030166
Trained batch 703 in epoch 5, gen_loss = 0.8675045194527642, disc_loss = 0.03264748094774073
Trained batch 704 in epoch 5, gen_loss = 0.8676233424785289, disc_loss = 0.0326080388003128
Trained batch 705 in epoch 5, gen_loss = 0.8676992434871096, disc_loss = 0.03256520867003418
Trained batch 706 in epoch 5, gen_loss = 0.867814649323257, disc_loss = 0.032522376383361015
Trained batch 707 in epoch 5, gen_loss = 0.8678705004059662, disc_loss = 0.03248037102120523
Trained batch 708 in epoch 5, gen_loss = 0.8679086451217721, disc_loss = 0.03243753972249198
Trained batch 709 in epoch 5, gen_loss = 0.8679602732540856, disc_loss = 0.03239430811413577
Trained batch 710 in epoch 5, gen_loss = 0.8680718348750586, disc_loss = 0.03236476359980603
Trained batch 711 in epoch 5, gen_loss = 0.8679516482470411, disc_loss = 0.032335583335102606
Trained batch 712 in epoch 5, gen_loss = 0.8675942987328994, disc_loss = 0.03254774119313101
Trained batch 713 in epoch 5, gen_loss = 0.867952558131111, disc_loss = 0.03254745828629542
Trained batch 714 in epoch 5, gen_loss = 0.8681336903488719, disc_loss = 0.03253066901873042
Trained batch 715 in epoch 5, gen_loss = 0.8682649145995438, disc_loss = 0.032499767356037094
Trained batch 716 in epoch 5, gen_loss = 0.8683384645683496, disc_loss = 0.03246589507414041
Trained batch 717 in epoch 5, gen_loss = 0.8684457441309369, disc_loss = 0.03243474566447743
Trained batch 718 in epoch 5, gen_loss = 0.8683854421504847, disc_loss = 0.03242352627533823
Trained batch 719 in epoch 5, gen_loss = 0.8683919007165565, disc_loss = 0.03251116076975854
Trained batch 720 in epoch 5, gen_loss = 0.8686136922872678, disc_loss = 0.03247338267632253
Trained batch 721 in epoch 5, gen_loss = 0.8684484327516397, disc_loss = 0.032477924118458276
Trained batch 722 in epoch 5, gen_loss = 0.8683773251572421, disc_loss = 0.03243789900181864
Trained batch 723 in epoch 5, gen_loss = 0.868398290106934, disc_loss = 0.03239887542842543
Trained batch 724 in epoch 5, gen_loss = 0.8685695915797661, disc_loss = 0.03236261973221754
Trained batch 725 in epoch 5, gen_loss = 0.8686244144173693, disc_loss = 0.032324111465616125
Trained batch 726 in epoch 5, gen_loss = 0.8686136841528025, disc_loss = 0.032285434443073184
Trained batch 727 in epoch 5, gen_loss = 0.8687664425553201, disc_loss = 0.032252361999880935
Trained batch 728 in epoch 5, gen_loss = 0.8686798176075369, disc_loss = 0.03223578455514276
Trained batch 729 in epoch 5, gen_loss = 0.8688213017297117, disc_loss = 0.03220430756791508
Trained batch 730 in epoch 5, gen_loss = 0.868951150110417, disc_loss = 0.03216808685069718
Trained batch 731 in epoch 5, gen_loss = 0.869061567540703, disc_loss = 0.03212901926535828
Trained batch 732 in epoch 5, gen_loss = 0.8691335716075168, disc_loss = 0.03209175045333935
Trained batch 733 in epoch 5, gen_loss = 0.869054668808828, disc_loss = 0.0320578586267008
Trained batch 734 in epoch 5, gen_loss = 0.8690708966887727, disc_loss = 0.03202777620100854
Trained batch 735 in epoch 5, gen_loss = 0.868770995096344, disc_loss = 0.0322399994765874
Trained batch 736 in epoch 5, gen_loss = 0.868887703203605, disc_loss = 0.032231036782153506
Trained batch 737 in epoch 5, gen_loss = 0.8685164779101607, disc_loss = 0.03226597385662722
Trained batch 738 in epoch 5, gen_loss = 0.8680211931104105, disc_loss = 0.032354340235751844
Trained batch 739 in epoch 5, gen_loss = 0.8679262919603168, disc_loss = 0.03235895284451544
Trained batch 740 in epoch 5, gen_loss = 0.8680634935777358, disc_loss = 0.03235282129438421
Trained batch 741 in epoch 5, gen_loss = 0.86817231119643, disc_loss = 0.032354566465681696
Trained batch 742 in epoch 5, gen_loss = 0.8680809183926153, disc_loss = 0.03232374835839623
Trained batch 743 in epoch 5, gen_loss = 0.8675287897468255, disc_loss = 0.032492856929449226
Trained batch 744 in epoch 5, gen_loss = 0.867299019690328, disc_loss = 0.032593713234485
Trained batch 745 in epoch 5, gen_loss = 0.8675620205520624, disc_loss = 0.03259444485316128
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.742275595664978, disc_loss = 0.02407815121114254
Trained batch 1 in epoch 6, gen_loss = 0.6717215776443481, disc_loss = 0.04728360380977392
Trained batch 2 in epoch 6, gen_loss = 0.7629260420799255, disc_loss = 0.03949414131542047
Trained batch 3 in epoch 6, gen_loss = 0.7959453016519547, disc_loss = 0.04221459059044719
Trained batch 4 in epoch 6, gen_loss = 0.7589914679527283, disc_loss = 0.04929565005004406
Trained batch 5 in epoch 6, gen_loss = 0.8332537313302358, disc_loss = 0.047780112363398075
Trained batch 6 in epoch 6, gen_loss = 0.8421971031597683, disc_loss = 0.04205711452024324
Trained batch 7 in epoch 6, gen_loss = 0.8324531987309456, disc_loss = 0.03947719931602478
Trained batch 8 in epoch 6, gen_loss = 0.852414243751102, disc_loss = 0.0357584570431047
Trained batch 9 in epoch 6, gen_loss = 0.8739414393901825, disc_loss = 0.03577359598129988
Trained batch 10 in epoch 6, gen_loss = 0.8649126237088983, disc_loss = 0.03435461612587625
Trained batch 11 in epoch 6, gen_loss = 0.8547182480494181, disc_loss = 0.032712165266275406
Trained batch 12 in epoch 6, gen_loss = 0.8486877817374009, disc_loss = 0.03148086712910579
Trained batch 13 in epoch 6, gen_loss = 0.8511467107704708, disc_loss = 0.034945640712976456
Trained batch 14 in epoch 6, gen_loss = 0.8395368377367656, disc_loss = 0.03522398496667544
Trained batch 15 in epoch 6, gen_loss = 0.841568112373352, disc_loss = 0.033317913475912064
Trained batch 16 in epoch 6, gen_loss = 0.8507953391355627, disc_loss = 0.03555209425223224
Trained batch 17 in epoch 6, gen_loss = 0.8323225577672323, disc_loss = 0.043259399787833296
Trained batch 18 in epoch 6, gen_loss = 0.8376027596624274, disc_loss = 0.04196289755207928
Trained batch 19 in epoch 6, gen_loss = 0.8376602113246918, disc_loss = 0.04166110218502581
Trained batch 20 in epoch 6, gen_loss = 0.8344693638029552, disc_loss = 0.041134550147468134
Trained batch 21 in epoch 6, gen_loss = 0.8334562941031023, disc_loss = 0.03984431575306437
Trained batch 22 in epoch 6, gen_loss = 0.8368509463641954, disc_loss = 0.03886025560938794
Trained batch 23 in epoch 6, gen_loss = 0.8366075331966082, disc_loss = 0.03746397269424051
Trained batch 24 in epoch 6, gen_loss = 0.8397214269638061, disc_loss = 0.037068079002201555
Trained batch 25 in epoch 6, gen_loss = 0.8327485185403091, disc_loss = 0.037563025700644806
Trained batch 26 in epoch 6, gen_loss = 0.8391871496483132, disc_loss = 0.03668849359921835
Trained batch 27 in epoch 6, gen_loss = 0.8395063153335026, disc_loss = 0.035589157071496756
Trained batch 28 in epoch 6, gen_loss = 0.8486227578130262, disc_loss = 0.035424524468594586
Trained batch 29 in epoch 6, gen_loss = 0.8423051436742147, disc_loss = 0.03520616535097361
Trained batch 30 in epoch 6, gen_loss = 0.8404200846149076, disc_loss = 0.0344994840242209
Trained batch 31 in epoch 6, gen_loss = 0.8431185483932495, disc_loss = 0.033759075071429834
Trained batch 32 in epoch 6, gen_loss = 0.843842423323429, disc_loss = 0.03557917348701845
Trained batch 33 in epoch 6, gen_loss = 0.8349277342067045, disc_loss = 0.03863781523507308
Trained batch 34 in epoch 6, gen_loss = 0.8322807601519994, disc_loss = 0.039413118016506946
Trained batch 35 in epoch 6, gen_loss = 0.8318154712518057, disc_loss = 0.03890118300397363
Trained batch 36 in epoch 6, gen_loss = 0.8355100573720159, disc_loss = 0.03932896123041172
Trained batch 37 in epoch 6, gen_loss = 0.8404097306100946, disc_loss = 0.04443551077948589
Trained batch 38 in epoch 6, gen_loss = 0.8329911950307015, disc_loss = 0.04605230295027678
Trained batch 39 in epoch 6, gen_loss = 0.8290901526808738, disc_loss = 0.04616864535491914
Trained batch 40 in epoch 6, gen_loss = 0.831489260603742, disc_loss = 0.04819282187466941
Trained batch 41 in epoch 6, gen_loss = 0.824282590832029, disc_loss = 0.049704750445449634
Trained batch 42 in epoch 6, gen_loss = 0.818782017674557, disc_loss = 0.050492408555434194
Trained batch 43 in epoch 6, gen_loss = 0.8193286833438006, disc_loss = 0.05509112832475115
Trained batch 44 in epoch 6, gen_loss = 0.8200384444660611, disc_loss = 0.05415557865053415
Trained batch 45 in epoch 6, gen_loss = 0.815834694582483, disc_loss = 0.055132738213338285
Trained batch 46 in epoch 6, gen_loss = 0.8118128332685917, disc_loss = 0.05707766648698995
Trained batch 47 in epoch 6, gen_loss = 0.8180845541258653, disc_loss = 0.061891124836013965
Trained batch 48 in epoch 6, gen_loss = 0.8171955626838061, disc_loss = 0.060989346070101064
Trained batch 49 in epoch 6, gen_loss = 0.8117642605304718, disc_loss = 0.06262400472536683
Trained batch 50 in epoch 6, gen_loss = 0.8134249425401875, disc_loss = 0.06186483999458598
Trained batch 51 in epoch 6, gen_loss = 0.8131530078557822, disc_loss = 0.06138432106504647
Trained batch 52 in epoch 6, gen_loss = 0.81218210706171, disc_loss = 0.06119622847170762
Trained batch 53 in epoch 6, gen_loss = 0.8090450068314871, disc_loss = 0.06132205156609416
Trained batch 54 in epoch 6, gen_loss = 0.8116860162128102, disc_loss = 0.06121686028147286
Trained batch 55 in epoch 6, gen_loss = 0.8120566202061517, disc_loss = 0.060315679176710546
Trained batch 56 in epoch 6, gen_loss = 0.8134114982789022, disc_loss = 0.059649815407107794
Trained batch 57 in epoch 6, gen_loss = 0.8126044900252901, disc_loss = 0.058884732023780716
Trained batch 58 in epoch 6, gen_loss = 0.8115201087321265, disc_loss = 0.058350323636274216
Trained batch 59 in epoch 6, gen_loss = 0.8132064312696456, disc_loss = 0.057521791802719234
Trained batch 60 in epoch 6, gen_loss = 0.8168736197909371, disc_loss = 0.056753587664761504
Trained batch 61 in epoch 6, gen_loss = 0.8206919306708921, disc_loss = 0.05609044548304331
Trained batch 62 in epoch 6, gen_loss = 0.8209564411450946, disc_loss = 0.05544666775930968
Trained batch 63 in epoch 6, gen_loss = 0.8217930840328336, disc_loss = 0.05496152823616285
Trained batch 64 in epoch 6, gen_loss = 0.8186501145362854, disc_loss = 0.054967680415855
Trained batch 65 in epoch 6, gen_loss = 0.8175412371303096, disc_loss = 0.05482690664234035
Trained batch 66 in epoch 6, gen_loss = 0.8152282344761179, disc_loss = 0.055997237299026836
Trained batch 67 in epoch 6, gen_loss = 0.8181628164123086, disc_loss = 0.05641301585744847
Trained batch 68 in epoch 6, gen_loss = 0.8174655618874923, disc_loss = 0.05582392033513473
Trained batch 69 in epoch 6, gen_loss = 0.8179079507078443, disc_loss = 0.05515495240688324
Trained batch 70 in epoch 6, gen_loss = 0.8173566175178743, disc_loss = 0.054762156549054135
Trained batch 71 in epoch 6, gen_loss = 0.8166191056370735, disc_loss = 0.05458075553178787
Trained batch 72 in epoch 6, gen_loss = 0.8169234786948113, disc_loss = 0.05406265236335258
Trained batch 73 in epoch 6, gen_loss = 0.8174354184318233, disc_loss = 0.05403315577958081
Trained batch 74 in epoch 6, gen_loss = 0.8211471406618754, disc_loss = 0.053827286809682844
Trained batch 75 in epoch 6, gen_loss = 0.8225059368108448, disc_loss = 0.05327343097642848
Trained batch 76 in epoch 6, gen_loss = 0.8201490919311325, disc_loss = 0.05351868755631633
Trained batch 77 in epoch 6, gen_loss = 0.819329023361206, disc_loss = 0.05305335226540382
Trained batch 78 in epoch 6, gen_loss = 0.8203176999393897, disc_loss = 0.05265328924678549
Trained batch 79 in epoch 6, gen_loss = 0.8177928164601326, disc_loss = 0.052999220741912725
Trained batch 80 in epoch 6, gen_loss = 0.8191591486518766, disc_loss = 0.05285048130669712
Trained batch 81 in epoch 6, gen_loss = 0.8217633133981286, disc_loss = 0.05236016212758131
Trained batch 82 in epoch 6, gen_loss = 0.8210428579744086, disc_loss = 0.052085349123072194
Trained batch 83 in epoch 6, gen_loss = 0.8204010043825422, disc_loss = 0.051668529254606084
Trained batch 84 in epoch 6, gen_loss = 0.82222099163953, disc_loss = 0.051142856358167
Trained batch 85 in epoch 6, gen_loss = 0.8245997622955678, disc_loss = 0.050726384227705555
Trained batch 86 in epoch 6, gen_loss = 0.8270321755573667, disc_loss = 0.050391230603744244
Trained batch 87 in epoch 6, gen_loss = 0.8281196057796478, disc_loss = 0.04987633860119703
Trained batch 88 in epoch 6, gen_loss = 0.827758709366402, disc_loss = 0.04939824246979329
Trained batch 89 in epoch 6, gen_loss = 0.8295396162403954, disc_loss = 0.04889592014046179
Trained batch 90 in epoch 6, gen_loss = 0.830886694756183, disc_loss = 0.04917562588189657
Trained batch 91 in epoch 6, gen_loss = 0.83033587038517, disc_loss = 0.048868580954149365
Trained batch 92 in epoch 6, gen_loss = 0.8309311148940876, disc_loss = 0.04847390600229784
Trained batch 93 in epoch 6, gen_loss = 0.8321285539485038, disc_loss = 0.04800844870190671
Trained batch 94 in epoch 6, gen_loss = 0.8334175743554768, disc_loss = 0.04759551437669679
Trained batch 95 in epoch 6, gen_loss = 0.8341067340224981, disc_loss = 0.047297605876034744
Trained batch 96 in epoch 6, gen_loss = 0.8335243186999842, disc_loss = 0.04707949814031419
Trained batch 97 in epoch 6, gen_loss = 0.8321693040886704, disc_loss = 0.04679599244679723
Trained batch 98 in epoch 6, gen_loss = 0.8318729189911274, disc_loss = 0.04640165787905154
Trained batch 99 in epoch 6, gen_loss = 0.8305529421567917, disc_loss = 0.046313507817685604
Trained batch 100 in epoch 6, gen_loss = 0.8320134990286119, disc_loss = 0.04594384880718028
Trained batch 101 in epoch 6, gen_loss = 0.8326283693313599, disc_loss = 0.04675307192419674
Trained batch 102 in epoch 6, gen_loss = 0.8289350146807514, disc_loss = 0.04830123059162237
Trained batch 103 in epoch 6, gen_loss = 0.829354317428974, disc_loss = 0.0479348171233701
Trained batch 104 in epoch 6, gen_loss = 0.8300053605011531, disc_loss = 0.047822517520260246
Trained batch 105 in epoch 6, gen_loss = 0.8296754981549281, disc_loss = 0.047980383961057325
Trained batch 106 in epoch 6, gen_loss = 0.8282544643522423, disc_loss = 0.04784192340709617
Trained batch 107 in epoch 6, gen_loss = 0.8299463543075102, disc_loss = 0.04754539649002254
Trained batch 108 in epoch 6, gen_loss = 0.8291650291429747, disc_loss = 0.0471995871411551
Trained batch 109 in epoch 6, gen_loss = 0.8280097433111885, disc_loss = 0.047741374305703424
Trained batch 110 in epoch 6, gen_loss = 0.8259843397247899, disc_loss = 0.04800241608340461
Trained batch 111 in epoch 6, gen_loss = 0.8242904940353972, disc_loss = 0.04823368648067117
Trained batch 112 in epoch 6, gen_loss = 0.8252246561831078, disc_loss = 0.048560043615577496
Trained batch 113 in epoch 6, gen_loss = 0.8261915395657221, disc_loss = 0.04953498497866748
Trained batch 114 in epoch 6, gen_loss = 0.8254586802876513, disc_loss = 0.04977968477684518
Trained batch 115 in epoch 6, gen_loss = 0.8231819916901917, disc_loss = 0.0500073797743896
Trained batch 116 in epoch 6, gen_loss = 0.8211407027183435, disc_loss = 0.0503711969169796
Trained batch 117 in epoch 6, gen_loss = 0.8215515540312912, disc_loss = 0.05142328446194277
Trained batch 118 in epoch 6, gen_loss = 0.8198099624709922, disc_loss = 0.052628696215252915
Trained batch 119 in epoch 6, gen_loss = 0.8185000556210676, disc_loss = 0.05388762863973776
Trained batch 120 in epoch 6, gen_loss = 0.8201651472198076, disc_loss = 0.05535571548071774
Trained batch 121 in epoch 6, gen_loss = 0.8205765155983753, disc_loss = 0.05507713481478515
Trained batch 122 in epoch 6, gen_loss = 0.8186041894482403, disc_loss = 0.055228132890855396
Trained batch 123 in epoch 6, gen_loss = 0.8164961825936071, disc_loss = 0.05564962440140305
Trained batch 124 in epoch 6, gen_loss = 0.8179235532283783, disc_loss = 0.05591962943971157
Trained batch 125 in epoch 6, gen_loss = 0.8178378241875816, disc_loss = 0.05558648182907038
Trained batch 126 in epoch 6, gen_loss = 0.819433389920888, disc_loss = 0.055350887442491656
Trained batch 127 in epoch 6, gen_loss = 0.8193683146964759, disc_loss = 0.05511763497634092
Trained batch 128 in epoch 6, gen_loss = 0.820602993401446, disc_loss = 0.054807054795786854
Trained batch 129 in epoch 6, gen_loss = 0.8182811189156313, disc_loss = 0.05515303944882292
Trained batch 130 in epoch 6, gen_loss = 0.8173673205248272, disc_loss = 0.05515258390285814
Trained batch 131 in epoch 6, gen_loss = 0.8197950104420836, disc_loss = 0.05586368072015995
Trained batch 132 in epoch 6, gen_loss = 0.8198097928574211, disc_loss = 0.05563381963402481
Trained batch 133 in epoch 6, gen_loss = 0.8187089391163925, disc_loss = 0.05571405160755141
Trained batch 134 in epoch 6, gen_loss = 0.8186073384903095, disc_loss = 0.05570309089703692
Trained batch 135 in epoch 6, gen_loss = 0.8170655271147981, disc_loss = 0.0558948815896121
Trained batch 136 in epoch 6, gen_loss = 0.8182199743107288, disc_loss = 0.05555633480667415
Trained batch 137 in epoch 6, gen_loss = 0.8201090013203414, disc_loss = 0.055674912522722414
Trained batch 138 in epoch 6, gen_loss = 0.8218383662563433, disc_loss = 0.05536107048928309
Trained batch 139 in epoch 6, gen_loss = 0.8220882762755667, disc_loss = 0.055014573353608806
Trained batch 140 in epoch 6, gen_loss = 0.82082640046769, disc_loss = 0.055291450506485734
Trained batch 141 in epoch 6, gen_loss = 0.8226451640817481, disc_loss = 0.05517714281409034
Trained batch 142 in epoch 6, gen_loss = 0.8202639586858816, disc_loss = 0.05569197122541653
Trained batch 143 in epoch 6, gen_loss = 0.8213895354419947, disc_loss = 0.0556110896965644
Trained batch 144 in epoch 6, gen_loss = 0.8224941255717442, disc_loss = 0.05543029693372804
Trained batch 145 in epoch 6, gen_loss = 0.8223979295524833, disc_loss = 0.05512089289610006
Trained batch 146 in epoch 6, gen_loss = 0.8198353299478285, disc_loss = 0.0560882286878214
Trained batch 147 in epoch 6, gen_loss = 0.8217485591366485, disc_loss = 0.05637595845021408
Trained batch 148 in epoch 6, gen_loss = 0.821456031511294, disc_loss = 0.05616488091135085
Trained batch 149 in epoch 6, gen_loss = 0.8216392739613851, disc_loss = 0.055854244017973544
Trained batch 150 in epoch 6, gen_loss = 0.8204411461653299, disc_loss = 0.056150461550160555
Trained batch 151 in epoch 6, gen_loss = 0.8211698045856074, disc_loss = 0.055885665887648144
Trained batch 152 in epoch 6, gen_loss = 0.8217596033819361, disc_loss = 0.05572621233067384
Trained batch 153 in epoch 6, gen_loss = 0.8217288379545336, disc_loss = 0.05548894109942212
Trained batch 154 in epoch 6, gen_loss = 0.8211326637575703, disc_loss = 0.055288412599193475
Trained batch 155 in epoch 6, gen_loss = 0.8211830609884018, disc_loss = 0.054982590718935125
Trained batch 156 in epoch 6, gen_loss = 0.821336911742095, disc_loss = 0.05482950409470945
Trained batch 157 in epoch 6, gen_loss = 0.8210409989085379, disc_loss = 0.0548706542659268
Trained batch 158 in epoch 6, gen_loss = 0.821082092306149, disc_loss = 0.05495789191691474
Trained batch 159 in epoch 6, gen_loss = 0.8214618198573589, disc_loss = 0.05467240424186457
Trained batch 160 in epoch 6, gen_loss = 0.8210291558911341, disc_loss = 0.054648798471027465
Trained batch 161 in epoch 6, gen_loss = 0.8214843549110271, disc_loss = 0.05439645655878624
Trained batch 162 in epoch 6, gen_loss = 0.8232914227649478, disc_loss = 0.0542742238048624
Trained batch 163 in epoch 6, gen_loss = 0.8241406101279143, disc_loss = 0.05582981076511759
Trained batch 164 in epoch 6, gen_loss = 0.8223484263275609, disc_loss = 0.0568255714535939
Trained batch 165 in epoch 6, gen_loss = 0.8220234509692135, disc_loss = 0.05670259717055204
Trained batch 166 in epoch 6, gen_loss = 0.8212058562004637, disc_loss = 0.056771856529113957
Trained batch 167 in epoch 6, gen_loss = 0.822064068700586, disc_loss = 0.05655570187705702
Trained batch 168 in epoch 6, gen_loss = 0.8215292716872763, disc_loss = 0.056630513650095145
Trained batch 169 in epoch 6, gen_loss = 0.82236068704549, disc_loss = 0.0564180101350169
Trained batch 170 in epoch 6, gen_loss = 0.8223395009486996, disc_loss = 0.05639274037383192
Trained batch 171 in epoch 6, gen_loss = 0.8221645680970924, disc_loss = 0.056168190574511716
Trained batch 172 in epoch 6, gen_loss = 0.8228845968411836, disc_loss = 0.055890859005100636
Trained batch 173 in epoch 6, gen_loss = 0.8231923737745176, disc_loss = 0.05571725264716165
Trained batch 174 in epoch 6, gen_loss = 0.8225874369485038, disc_loss = 0.05555356894486717
Trained batch 175 in epoch 6, gen_loss = 0.8221191276203502, disc_loss = 0.055555690167238936
Trained batch 176 in epoch 6, gen_loss = 0.8224425730058702, disc_loss = 0.05534183059550696
Trained batch 177 in epoch 6, gen_loss = 0.8215543041738231, disc_loss = 0.05554524560333387
Trained batch 178 in epoch 6, gen_loss = 0.8214982201933195, disc_loss = 0.05532738618687961
Trained batch 179 in epoch 6, gen_loss = 0.8221066650417116, disc_loss = 0.055095527944568956
Trained batch 180 in epoch 6, gen_loss = 0.8221074790585765, disc_loss = 0.05488185852364694
Trained batch 181 in epoch 6, gen_loss = 0.8232924106356861, disc_loss = 0.05465603794564831
Trained batch 182 in epoch 6, gen_loss = 0.8232070331365033, disc_loss = 0.05449195780989821
Trained batch 183 in epoch 6, gen_loss = 0.8225154092778331, disc_loss = 0.054378563181355435
Trained batch 184 in epoch 6, gen_loss = 0.8228335006816967, disc_loss = 0.054184582998120304
Trained batch 185 in epoch 6, gen_loss = 0.8233556510299764, disc_loss = 0.05403108915604491
Trained batch 186 in epoch 6, gen_loss = 0.8230119462319236, disc_loss = 0.053877052504888036
Trained batch 187 in epoch 6, gen_loss = 0.8233016599366005, disc_loss = 0.05374883973049594
Trained batch 188 in epoch 6, gen_loss = 0.8246412059617421, disc_loss = 0.05357296417698895
Trained batch 189 in epoch 6, gen_loss = 0.8254217470947065, disc_loss = 0.0536781496490891
Trained batch 190 in epoch 6, gen_loss = 0.82583090148047, disc_loss = 0.05353626074191398
Trained batch 191 in epoch 6, gen_loss = 0.8263430859272679, disc_loss = 0.05336388281769663
Trained batch 192 in epoch 6, gen_loss = 0.8261731137265813, disc_loss = 0.05314045549741912
Trained batch 193 in epoch 6, gen_loss = 0.8263571210128745, disc_loss = 0.052910630627218444
Trained batch 194 in epoch 6, gen_loss = 0.8266806110357627, disc_loss = 0.05266438279157648
Trained batch 195 in epoch 6, gen_loss = 0.8262266349427554, disc_loss = 0.05256917825377337
Trained batch 196 in epoch 6, gen_loss = 0.827182054822215, disc_loss = 0.05254514189909784
Trained batch 197 in epoch 6, gen_loss = 0.8271631264325344, disc_loss = 0.05241522104291226
Trained batch 198 in epoch 6, gen_loss = 0.825671750995981, disc_loss = 0.05271528576776834
Trained batch 199 in epoch 6, gen_loss = 0.8268959048390389, disc_loss = 0.05273751757806167
Trained batch 200 in epoch 6, gen_loss = 0.827304295936034, disc_loss = 0.05251998681139516
Trained batch 201 in epoch 6, gen_loss = 0.8280593121405875, disc_loss = 0.052335589978899255
Trained batch 202 in epoch 6, gen_loss = 0.8282605157109905, disc_loss = 0.05211372214961302
Trained batch 203 in epoch 6, gen_loss = 0.8283079888890771, disc_loss = 0.05196621628962092
Trained batch 204 in epoch 6, gen_loss = 0.8288256275944593, disc_loss = 0.051753273594942764
Trained batch 205 in epoch 6, gen_loss = 0.8291457257803204, disc_loss = 0.051526187552880603
Trained batch 206 in epoch 6, gen_loss = 0.829659250335417, disc_loss = 0.051303157263439925
Trained batch 207 in epoch 6, gen_loss = 0.8295658740859765, disc_loss = 0.05108163569373293
Trained batch 208 in epoch 6, gen_loss = 0.829857748661315, disc_loss = 0.05086337466630639
Trained batch 209 in epoch 6, gen_loss = 0.8301991176037561, disc_loss = 0.05067588589375927
Trained batch 210 in epoch 6, gen_loss = 0.8300536664741299, disc_loss = 0.05045683155613135
Trained batch 211 in epoch 6, gen_loss = 0.8300667998363387, disc_loss = 0.05024628914708166
Trained batch 212 in epoch 6, gen_loss = 0.8304567152345684, disc_loss = 0.05002618223065816
Trained batch 213 in epoch 6, gen_loss = 0.8307920293273213, disc_loss = 0.04981263436781782
Trained batch 214 in epoch 6, gen_loss = 0.8310346187547196, disc_loss = 0.04961003487994678
Trained batch 215 in epoch 6, gen_loss = 0.8315074603866648, disc_loss = 0.0494749010982492
Trained batch 216 in epoch 6, gen_loss = 0.8316240280454609, disc_loss = 0.04926819544530169
Trained batch 217 in epoch 6, gen_loss = 0.8312576530723397, disc_loss = 0.049075178574522905
Trained batch 218 in epoch 6, gen_loss = 0.831177471979568, disc_loss = 0.04892539331098363
Trained batch 219 in epoch 6, gen_loss = 0.8315747521140359, disc_loss = 0.04872736680554226
Trained batch 220 in epoch 6, gen_loss = 0.8325863040949963, disc_loss = 0.04853406996567358
Trained batch 221 in epoch 6, gen_loss = 0.8328478438360197, disc_loss = 0.04835048317804362
Trained batch 222 in epoch 6, gen_loss = 0.833129114634253, disc_loss = 0.04818050840957249
Trained batch 223 in epoch 6, gen_loss = 0.831920312717557, disc_loss = 0.04898054768377084
Trained batch 224 in epoch 6, gen_loss = 0.831444587972429, disc_loss = 0.048870036985932126
Trained batch 225 in epoch 6, gen_loss = 0.8315767746056075, disc_loss = 0.04880664982540384
Trained batch 226 in epoch 6, gen_loss = 0.8325217531641149, disc_loss = 0.04877182019419049
Trained batch 227 in epoch 6, gen_loss = 0.8316553339623568, disc_loss = 0.04873782528968724
Trained batch 228 in epoch 6, gen_loss = 0.8314546817775377, disc_loss = 0.04927427548097699
Trained batch 229 in epoch 6, gen_loss = 0.8295376333205596, disc_loss = 0.05079681117229325
Trained batch 230 in epoch 6, gen_loss = 0.8307229219835042, disc_loss = 0.05084154471347826
Trained batch 231 in epoch 6, gen_loss = 0.8313329069521921, disc_loss = 0.05093790806231795
Trained batch 232 in epoch 6, gen_loss = 0.8319788461335227, disc_loss = 0.05082298092875837
Trained batch 233 in epoch 6, gen_loss = 0.831920183239839, disc_loss = 0.05073334031806001
Trained batch 234 in epoch 6, gen_loss = 0.8318556538287629, disc_loss = 0.05057996383749266
Trained batch 235 in epoch 6, gen_loss = 0.83163650902146, disc_loss = 0.050430847749200855
Trained batch 236 in epoch 6, gen_loss = 0.8317627646500552, disc_loss = 0.050263066696521794
Trained batch 237 in epoch 6, gen_loss = 0.8319172707675886, disc_loss = 0.050224569480388795
Trained batch 238 in epoch 6, gen_loss = 0.8315165909513769, disc_loss = 0.05005142548137099
Trained batch 239 in epoch 6, gen_loss = 0.8301521463940541, disc_loss = 0.050653566236724144
Trained batch 240 in epoch 6, gen_loss = 0.8296655793654968, disc_loss = 0.05054453001705412
Trained batch 241 in epoch 6, gen_loss = 0.8296661506260722, disc_loss = 0.05047746955836577
Trained batch 242 in epoch 6, gen_loss = 0.8297231316321181, disc_loss = 0.05034902533458799
Trained batch 243 in epoch 6, gen_loss = 0.830528447984672, disc_loss = 0.05021451965840839
Trained batch 244 in epoch 6, gen_loss = 0.8310515932890834, disc_loss = 0.050064537829092266
Trained batch 245 in epoch 6, gen_loss = 0.8309286434233674, disc_loss = 0.049956488812046985
Trained batch 246 in epoch 6, gen_loss = 0.8301421209626835, disc_loss = 0.04992176918407171
Trained batch 247 in epoch 6, gen_loss = 0.8304469646705736, disc_loss = 0.04994512846854876
Trained batch 248 in epoch 6, gen_loss = 0.8295566127242813, disc_loss = 0.04994381220925255
Trained batch 249 in epoch 6, gen_loss = 0.8298755277395249, disc_loss = 0.05004114671330899
Trained batch 250 in epoch 6, gen_loss = 0.8298691189384081, disc_loss = 0.049896775016679884
Trained batch 251 in epoch 6, gen_loss = 0.8292049525512589, disc_loss = 0.04981883454398947
Trained batch 252 in epoch 6, gen_loss = 0.829066790257518, disc_loss = 0.04966261481825748
Trained batch 253 in epoch 6, gen_loss = 0.8293510087597089, disc_loss = 0.04974520549189124
Trained batch 254 in epoch 6, gen_loss = 0.8297141684036629, disc_loss = 0.04958073775758784
Trained batch 255 in epoch 6, gen_loss = 0.8293429060140625, disc_loss = 0.04953680181552045
Trained batch 256 in epoch 6, gen_loss = 0.8298866810269857, disc_loss = 0.049402769143124206
Trained batch 257 in epoch 6, gen_loss = 0.8302363865366278, disc_loss = 0.049267009535060774
Trained batch 258 in epoch 6, gen_loss = 0.8311445415019989, disc_loss = 0.04922861680586222
Trained batch 259 in epoch 6, gen_loss = 0.8306031911418988, disc_loss = 0.04922377803774837
Trained batch 260 in epoch 6, gen_loss = 0.8302511882279567, disc_loss = 0.0491232015183588
Trained batch 261 in epoch 6, gen_loss = 0.8307917678856668, disc_loss = 0.0489841919411898
Trained batch 262 in epoch 6, gen_loss = 0.8306613359387837, disc_loss = 0.048890164099853244
Trained batch 263 in epoch 6, gen_loss = 0.8303414864296262, disc_loss = 0.04876731228079845
Trained batch 264 in epoch 6, gen_loss = 0.8304623962573285, disc_loss = 0.04864951788869528
Trained batch 265 in epoch 6, gen_loss = 0.8306786091928196, disc_loss = 0.048506047365717814
Trained batch 266 in epoch 6, gen_loss = 0.8299318914779563, disc_loss = 0.04847190976892825
Trained batch 267 in epoch 6, gen_loss = 0.8301469195467323, disc_loss = 0.048470521219762794
Trained batch 268 in epoch 6, gen_loss = 0.8295789377618457, disc_loss = 0.04848825169786063
Trained batch 269 in epoch 6, gen_loss = 0.8304823408524196, disc_loss = 0.04844934231067007
Trained batch 270 in epoch 6, gen_loss = 0.83082494447592, disc_loss = 0.0482975673506112
Trained batch 271 in epoch 6, gen_loss = 0.830707422183717, disc_loss = 0.04819935708399177
Trained batch 272 in epoch 6, gen_loss = 0.8300507807687962, disc_loss = 0.048204833964882045
Trained batch 273 in epoch 6, gen_loss = 0.8311651772173652, disc_loss = 0.048247814425743135
Trained batch 274 in epoch 6, gen_loss = 0.8308643357320266, disc_loss = 0.04821958542124114
Trained batch 275 in epoch 6, gen_loss = 0.8307643440970476, disc_loss = 0.04815780975015672
Trained batch 276 in epoch 6, gen_loss = 0.831284673097762, disc_loss = 0.04818205426729516
Trained batch 277 in epoch 6, gen_loss = 0.8313664672829264, disc_loss = 0.048118965870285364
Trained batch 278 in epoch 6, gen_loss = 0.8310386689119441, disc_loss = 0.04809113021349154
Trained batch 279 in epoch 6, gen_loss = 0.8306782857647964, disc_loss = 0.048101305438571475
Trained batch 280 in epoch 6, gen_loss = 0.8319824309323606, disc_loss = 0.048348042765115236
Trained batch 281 in epoch 6, gen_loss = 0.8317574675835616, disc_loss = 0.04825216771106744
Trained batch 282 in epoch 6, gen_loss = 0.8311879326303098, disc_loss = 0.04848078244971276
Trained batch 283 in epoch 6, gen_loss = 0.8311632186384268, disc_loss = 0.04834224228520917
Trained batch 284 in epoch 6, gen_loss = 0.8305318233213926, disc_loss = 0.048358992015812216
Trained batch 285 in epoch 6, gen_loss = 0.8309199192098804, disc_loss = 0.048315463625904095
Trained batch 286 in epoch 6, gen_loss = 0.8300082186165587, disc_loss = 0.04833278741333828
Trained batch 287 in epoch 6, gen_loss = 0.8300351886492636, disc_loss = 0.048198620891424876
Trained batch 288 in epoch 6, gen_loss = 0.8306379034651192, disc_loss = 0.048089412687939294
Trained batch 289 in epoch 6, gen_loss = 0.8308378831065935, disc_loss = 0.04795223597421086
Trained batch 290 in epoch 6, gen_loss = 0.8309619003759626, disc_loss = 0.04793634838776669
Trained batch 291 in epoch 6, gen_loss = 0.8306833006543656, disc_loss = 0.04791634839445939
Trained batch 292 in epoch 6, gen_loss = 0.8313350200449647, disc_loss = 0.04789408534978208
Trained batch 293 in epoch 6, gen_loss = 0.8316673465123793, disc_loss = 0.04780854769668789
Trained batch 294 in epoch 6, gen_loss = 0.8314043270329298, disc_loss = 0.0477550263713919
Trained batch 295 in epoch 6, gen_loss = 0.8323138576705713, disc_loss = 0.047711803385125776
Trained batch 296 in epoch 6, gen_loss = 0.8316409036968694, disc_loss = 0.04791226103409548
Trained batch 297 in epoch 6, gen_loss = 0.8318812786132698, disc_loss = 0.04802223395840609
Trained batch 298 in epoch 6, gen_loss = 0.8328803413887088, disc_loss = 0.04838457704446961
Trained batch 299 in epoch 6, gen_loss = 0.8323147520422935, disc_loss = 0.04861648386577144
Trained batch 300 in epoch 6, gen_loss = 0.8325449118384491, disc_loss = 0.04903722334996584
Trained batch 301 in epoch 6, gen_loss = 0.8316131270681786, disc_loss = 0.04935769204725666
Trained batch 302 in epoch 6, gen_loss = 0.8311199690445815, disc_loss = 0.04942071355077078
Trained batch 303 in epoch 6, gen_loss = 0.8305383047187015, disc_loss = 0.04971730959904993
Trained batch 304 in epoch 6, gen_loss = 0.8310159197596253, disc_loss = 0.050467620089986044
Trained batch 305 in epoch 6, gen_loss = 0.8299768947892718, disc_loss = 0.05069756520884659
Trained batch 306 in epoch 6, gen_loss = 0.829926510490113, disc_loss = 0.05081575575848914
Trained batch 307 in epoch 6, gen_loss = 0.8294029321956944, disc_loss = 0.051363918358042784
Trained batch 308 in epoch 6, gen_loss = 0.8286930119142564, disc_loss = 0.05151432153051508
Trained batch 309 in epoch 6, gen_loss = 0.8287670713278555, disc_loss = 0.052011529460639486
Trained batch 310 in epoch 6, gen_loss = 0.827734475446284, disc_loss = 0.052463806407238654
Trained batch 311 in epoch 6, gen_loss = 0.8279854606550473, disc_loss = 0.05240793222522674
Trained batch 312 in epoch 6, gen_loss = 0.8275699258421938, disc_loss = 0.05250579477793659
Trained batch 313 in epoch 6, gen_loss = 0.8276038225858834, disc_loss = 0.05237880618694078
Trained batch 314 in epoch 6, gen_loss = 0.8274962859494346, disc_loss = 0.0523052818740585
Trained batch 315 in epoch 6, gen_loss = 0.826887498456466, disc_loss = 0.0522956999536026
Trained batch 316 in epoch 6, gen_loss = 0.826823720326559, disc_loss = 0.052274391198331015
Trained batch 317 in epoch 6, gen_loss = 0.8262475293199971, disc_loss = 0.0523101052045295
Trained batch 318 in epoch 6, gen_loss = 0.8264388183254433, disc_loss = 0.05228695493165205
Trained batch 319 in epoch 6, gen_loss = 0.8267745644785464, disc_loss = 0.052163479857699716
Trained batch 320 in epoch 6, gen_loss = 0.8263763899558059, disc_loss = 0.05209941960903134
Trained batch 321 in epoch 6, gen_loss = 0.8259107130839958, disc_loss = 0.05218991448290022
Trained batch 322 in epoch 6, gen_loss = 0.826228808969167, disc_loss = 0.05247614480448373
Trained batch 323 in epoch 6, gen_loss = 0.8254681841274838, disc_loss = 0.052564933191105306
Trained batch 324 in epoch 6, gen_loss = 0.8253543133919056, disc_loss = 0.05248409359715879
Trained batch 325 in epoch 6, gen_loss = 0.8251559737087028, disc_loss = 0.052427806305139116
Trained batch 326 in epoch 6, gen_loss = 0.8254641233416508, disc_loss = 0.052382262522605354
Trained batch 327 in epoch 6, gen_loss = 0.8253424148552302, disc_loss = 0.053027333330402784
Trained batch 328 in epoch 6, gen_loss = 0.8244317533578553, disc_loss = 0.05338493184509226
Trained batch 329 in epoch 6, gen_loss = 0.8240168057607882, disc_loss = 0.05335368665542002
Trained batch 330 in epoch 6, gen_loss = 0.8245803992013556, disc_loss = 0.053353644943348724
Trained batch 331 in epoch 6, gen_loss = 0.8240402095827711, disc_loss = 0.053367902605418474
Trained batch 332 in epoch 6, gen_loss = 0.8237966192556215, disc_loss = 0.053372641932359105
Trained batch 333 in epoch 6, gen_loss = 0.8235964529707046, disc_loss = 0.053305257253298634
Trained batch 334 in epoch 6, gen_loss = 0.823754618861782, disc_loss = 0.05346683340161038
Trained batch 335 in epoch 6, gen_loss = 0.8237296286970377, disc_loss = 0.053344156359560746
Trained batch 336 in epoch 6, gen_loss = 0.8229343403871406, disc_loss = 0.05345345844475978
Trained batch 337 in epoch 6, gen_loss = 0.8233363565784939, disc_loss = 0.05335399770169635
Trained batch 338 in epoch 6, gen_loss = 0.8232710323678357, disc_loss = 0.05322190727914922
Trained batch 339 in epoch 6, gen_loss = 0.8238093843354898, disc_loss = 0.05313206622308558
Trained batch 340 in epoch 6, gen_loss = 0.8233135843381854, disc_loss = 0.05309828709950261
Trained batch 341 in epoch 6, gen_loss = 0.8230643369126738, disc_loss = 0.05299556788468287
Trained batch 342 in epoch 6, gen_loss = 0.8223752988496953, disc_loss = 0.05297827459369452
Trained batch 343 in epoch 6, gen_loss = 0.8236258770664071, disc_loss = 0.053199343550490046
Trained batch 344 in epoch 6, gen_loss = 0.8237844283166139, disc_loss = 0.053068845243314684
Trained batch 345 in epoch 6, gen_loss = 0.8240255991675262, disc_loss = 0.05297274099369506
Trained batch 346 in epoch 6, gen_loss = 0.8241795870859272, disc_loss = 0.0528389271342005
Trained batch 347 in epoch 6, gen_loss = 0.8243104112388073, disc_loss = 0.05280777621925969
Trained batch 348 in epoch 6, gen_loss = 0.8240159258972266, disc_loss = 0.05275867572441206
Trained batch 349 in epoch 6, gen_loss = 0.8234070131608419, disc_loss = 0.052769404494735814
Trained batch 350 in epoch 6, gen_loss = 0.8229445360834442, disc_loss = 0.05274547038379621
Trained batch 351 in epoch 6, gen_loss = 0.8233272171663967, disc_loss = 0.05261638595931634
Trained batch 352 in epoch 6, gen_loss = 0.8242181950689376, disc_loss = 0.05256776064673898
Trained batch 353 in epoch 6, gen_loss = 0.8248649646165007, disc_loss = 0.05247100157923681
Trained batch 354 in epoch 6, gen_loss = 0.8248237812183272, disc_loss = 0.052355009453161294
Trained batch 355 in epoch 6, gen_loss = 0.8248974696806307, disc_loss = 0.05223297474976483
Trained batch 356 in epoch 6, gen_loss = 0.8247481683890024, disc_loss = 0.052121091625556684
Trained batch 357 in epoch 6, gen_loss = 0.8240879323728924, disc_loss = 0.052266959935379886
Trained batch 358 in epoch 6, gen_loss = 0.8248029348743992, disc_loss = 0.052396471227563315
Trained batch 359 in epoch 6, gen_loss = 0.825157218757603, disc_loss = 0.05231031158408667
Trained batch 360 in epoch 6, gen_loss = 0.8247820156267806, disc_loss = 0.05227043485550153
Trained batch 361 in epoch 6, gen_loss = 0.8243942516778714, disc_loss = 0.05241478695238307
Trained batch 362 in epoch 6, gen_loss = 0.8244765845047869, disc_loss = 0.05230341167137868
Trained batch 363 in epoch 6, gen_loss = 0.8251440593010777, disc_loss = 0.052312053534698644
Trained batch 364 in epoch 6, gen_loss = 0.8246884717516703, disc_loss = 0.05232466667418508
Trained batch 365 in epoch 6, gen_loss = 0.8247927302708391, disc_loss = 0.05220551139362095
Trained batch 366 in epoch 6, gen_loss = 0.8249079745049698, disc_loss = 0.05225603765559355
Trained batch 367 in epoch 6, gen_loss = 0.8242610185204641, disc_loss = 0.052358548034807544
Trained batch 368 in epoch 6, gen_loss = 0.8241372236875983, disc_loss = 0.05229520865307167
Trained batch 369 in epoch 6, gen_loss = 0.8244741912629153, disc_loss = 0.05222354685774425
Trained batch 370 in epoch 6, gen_loss = 0.8245000179726479, disc_loss = 0.052138642264238866
Trained batch 371 in epoch 6, gen_loss = 0.8236229720134889, disc_loss = 0.05212640803825531
Trained batch 372 in epoch 6, gen_loss = 0.8235438233566028, disc_loss = 0.052023599193314084
Trained batch 373 in epoch 6, gen_loss = 0.8240219618388038, disc_loss = 0.05209353940130615
Trained batch 374 in epoch 6, gen_loss = 0.8237371431191762, disc_loss = 0.051985555673018095
Trained batch 375 in epoch 6, gen_loss = 0.8231995106536023, disc_loss = 0.05193584060056155
Trained batch 376 in epoch 6, gen_loss = 0.8234450087465089, disc_loss = 0.051817539853935654
Trained batch 377 in epoch 6, gen_loss = 0.8238576971506947, disc_loss = 0.05172141940670492
Trained batch 378 in epoch 6, gen_loss = 0.824267689895504, disc_loss = 0.05166170478424937
Trained batch 379 in epoch 6, gen_loss = 0.8240785365826205, disc_loss = 0.05164382104504559
Trained batch 380 in epoch 6, gen_loss = 0.8242133922307823, disc_loss = 0.05157060283382871
Trained batch 381 in epoch 6, gen_loss = 0.8247617168732339, disc_loss = 0.05157725042626944
Trained batch 382 in epoch 6, gen_loss = 0.8244753318884976, disc_loss = 0.05149839175244983
Trained batch 383 in epoch 6, gen_loss = 0.8239161188248545, disc_loss = 0.051523981234519546
Trained batch 384 in epoch 6, gen_loss = 0.8240574283259255, disc_loss = 0.05154815282031604
Trained batch 385 in epoch 6, gen_loss = 0.8242109004852067, disc_loss = 0.051435653884518755
Trained batch 386 in epoch 6, gen_loss = 0.8240385972714239, disc_loss = 0.05133734052358267
Trained batch 387 in epoch 6, gen_loss = 0.8240631712005311, disc_loss = 0.051224863405709066
Trained batch 388 in epoch 6, gen_loss = 0.8244349701392314, disc_loss = 0.05111207079877335
Trained batch 389 in epoch 6, gen_loss = 0.8245660961438448, disc_loss = 0.050996822952770464
Trained batch 390 in epoch 6, gen_loss = 0.8254761649367145, disc_loss = 0.05101255318233291
Trained batch 391 in epoch 6, gen_loss = 0.826076191831, disc_loss = 0.05091065821553847
Trained batch 392 in epoch 6, gen_loss = 0.8261120373207801, disc_loss = 0.050841026328641535
Trained batch 393 in epoch 6, gen_loss = 0.8259503684824493, disc_loss = 0.05082298437816559
Trained batch 394 in epoch 6, gen_loss = 0.8256233460541013, disc_loss = 0.05080959141266214
Trained batch 395 in epoch 6, gen_loss = 0.8264872592055437, disc_loss = 0.05089071228208886
Trained batch 396 in epoch 6, gen_loss = 0.8267505554017852, disc_loss = 0.05078595942203002
Trained batch 397 in epoch 6, gen_loss = 0.8271202305004225, disc_loss = 0.05072772705836231
Trained batch 398 in epoch 6, gen_loss = 0.827173921473343, disc_loss = 0.05086882691421922
Trained batch 399 in epoch 6, gen_loss = 0.8264266536384821, disc_loss = 0.05129162053402979
Trained batch 400 in epoch 6, gen_loss = 0.8259988316425362, disc_loss = 0.051330000392632774
Trained batch 401 in epoch 6, gen_loss = 0.8256446831113663, disc_loss = 0.051344434307327505
Trained batch 402 in epoch 6, gen_loss = 0.8260385243975495, disc_loss = 0.051487464502236575
Trained batch 403 in epoch 6, gen_loss = 0.8259812908449976, disc_loss = 0.05140116557969924
Trained batch 404 in epoch 6, gen_loss = 0.8256193690093947, disc_loss = 0.05137238976959553
Trained batch 405 in epoch 6, gen_loss = 0.8256017347715171, disc_loss = 0.05140359941789688
Trained batch 406 in epoch 6, gen_loss = 0.8260339638378462, disc_loss = 0.051306268582990075
Trained batch 407 in epoch 6, gen_loss = 0.8256466409885416, disc_loss = 0.051332074320788366
Trained batch 408 in epoch 6, gen_loss = 0.8253752544777317, disc_loss = 0.05130257780212809
Trained batch 409 in epoch 6, gen_loss = 0.8252043791660448, disc_loss = 0.05148178433783625
Trained batch 410 in epoch 6, gen_loss = 0.8257214568392204, disc_loss = 0.051394722393290154
Trained batch 411 in epoch 6, gen_loss = 0.8251381382635496, disc_loss = 0.05142236703348988
Trained batch 412 in epoch 6, gen_loss = 0.8251247985455372, disc_loss = 0.05132125272329888
Trained batch 413 in epoch 6, gen_loss = 0.825061636198546, disc_loss = 0.051246371204011
Trained batch 414 in epoch 6, gen_loss = 0.8250204517898789, disc_loss = 0.051202235607071274
Trained batch 415 in epoch 6, gen_loss = 0.8253602059558034, disc_loss = 0.05110269274770802
Trained batch 416 in epoch 6, gen_loss = 0.8255194746475998, disc_loss = 0.05100147708037721
Trained batch 417 in epoch 6, gen_loss = 0.8262972869513708, disc_loss = 0.05095439096389151
Trained batch 418 in epoch 6, gen_loss = 0.8264248993487802, disc_loss = 0.050870330253535954
Trained batch 419 in epoch 6, gen_loss = 0.8267700574937321, disc_loss = 0.05078841002181261
Trained batch 420 in epoch 6, gen_loss = 0.8268668741483304, disc_loss = 0.050690136525244615
Trained batch 421 in epoch 6, gen_loss = 0.8265958734174476, disc_loss = 0.050660696757352644
Trained batch 422 in epoch 6, gen_loss = 0.8268632881043932, disc_loss = 0.05056473595226716
Trained batch 423 in epoch 6, gen_loss = 0.8269621290547667, disc_loss = 0.050537850980686444
Trained batch 424 in epoch 6, gen_loss = 0.8271336192944471, disc_loss = 0.050429479860536315
Trained batch 425 in epoch 6, gen_loss = 0.8275783041693235, disc_loss = 0.050378042377614604
Trained batch 426 in epoch 6, gen_loss = 0.8276595825752553, disc_loss = 0.05031856756157894
Trained batch 427 in epoch 6, gen_loss = 0.8284336202473284, disc_loss = 0.050287327785197226
Trained batch 428 in epoch 6, gen_loss = 0.8286332895844688, disc_loss = 0.05018804917960821
Trained batch 429 in epoch 6, gen_loss = 0.8287285772173903, disc_loss = 0.050089079239622275
Trained batch 430 in epoch 6, gen_loss = 0.829033423811543, disc_loss = 0.04999000107677191
Trained batch 431 in epoch 6, gen_loss = 0.8296573882991517, disc_loss = 0.04991612199282153
Trained batch 432 in epoch 6, gen_loss = 0.8297004751327682, disc_loss = 0.04991083375853648
Trained batch 433 in epoch 6, gen_loss = 0.8294684883498926, disc_loss = 0.04991778783330668
Trained batch 434 in epoch 6, gen_loss = 0.8296959787264637, disc_loss = 0.04981967060526983
Trained batch 435 in epoch 6, gen_loss = 0.8302169177647031, disc_loss = 0.04973979827941506
Trained batch 436 in epoch 6, gen_loss = 0.8303079813105018, disc_loss = 0.04963999853396971
Trained batch 437 in epoch 6, gen_loss = 0.8301571297999386, disc_loss = 0.04955419674292462
Trained batch 438 in epoch 6, gen_loss = 0.8304807130323727, disc_loss = 0.049749644756940846
Trained batch 439 in epoch 6, gen_loss = 0.8298382612114603, disc_loss = 0.05016754395698875
Trained batch 440 in epoch 6, gen_loss = 0.8299798255199208, disc_loss = 0.050092625728958284
Trained batch 441 in epoch 6, gen_loss = 0.8304269090631968, disc_loss = 0.050112338053437615
Trained batch 442 in epoch 6, gen_loss = 0.8304896734772632, disc_loss = 0.05002349900537954
Trained batch 443 in epoch 6, gen_loss = 0.8306484221740886, disc_loss = 0.049933532273359095
Trained batch 444 in epoch 6, gen_loss = 0.8304736241195979, disc_loss = 0.04983963479936709
Trained batch 445 in epoch 6, gen_loss = 0.8307017536307664, disc_loss = 0.04977279385675012
Trained batch 446 in epoch 6, gen_loss = 0.8304927017731422, disc_loss = 0.04972738457554055
Trained batch 447 in epoch 6, gen_loss = 0.8305893121952457, disc_loss = 0.04963548100775889
Trained batch 448 in epoch 6, gen_loss = 0.8309064078038945, disc_loss = 0.04958199790288966
Trained batch 449 in epoch 6, gen_loss = 0.8308508914709091, disc_loss = 0.04954725979258203
Trained batch 450 in epoch 6, gen_loss = 0.8311131371230613, disc_loss = 0.04945199291465469
Trained batch 451 in epoch 6, gen_loss = 0.8315430571679521, disc_loss = 0.05032006905782984
Trained batch 452 in epoch 6, gen_loss = 0.8309506241717349, disc_loss = 0.050542986591471974
Trained batch 453 in epoch 6, gen_loss = 0.8305406291448072, disc_loss = 0.050555942612412974
Trained batch 454 in epoch 6, gen_loss = 0.8311310893231696, disc_loss = 0.05070732755760488
Trained batch 455 in epoch 6, gen_loss = 0.8306787346669456, disc_loss = 0.05123248476516701
Trained batch 456 in epoch 6, gen_loss = 0.8302470190650264, disc_loss = 0.0512514063997777
Trained batch 457 in epoch 6, gen_loss = 0.830148918594856, disc_loss = 0.05117936143153408
Trained batch 458 in epoch 6, gen_loss = 0.8301320262334445, disc_loss = 0.05113275009836425
Trained batch 459 in epoch 6, gen_loss = 0.8302755995289139, disc_loss = 0.05105871564617542
Trained batch 460 in epoch 6, gen_loss = 0.8303646696751651, disc_loss = 0.05104798505157475
Trained batch 461 in epoch 6, gen_loss = 0.8303238975924331, disc_loss = 0.05096274709834987
Trained batch 462 in epoch 6, gen_loss = 0.8306242216611784, disc_loss = 0.050890106791791304
Trained batch 463 in epoch 6, gen_loss = 0.8305037202120855, disc_loss = 0.05080406925317847
Trained batch 464 in epoch 6, gen_loss = 0.8305817588042187, disc_loss = 0.0507182838490373
Trained batch 465 in epoch 6, gen_loss = 0.8306811242784041, disc_loss = 0.0506176124836514
Trained batch 466 in epoch 6, gen_loss = 0.8307252031705109, disc_loss = 0.05052720309919189
Trained batch 467 in epoch 6, gen_loss = 0.8308552981823938, disc_loss = 0.05043189035644994
Trained batch 468 in epoch 6, gen_loss = 0.8311987466522371, disc_loss = 0.050349146015505226
Trained batch 469 in epoch 6, gen_loss = 0.8313841283955472, disc_loss = 0.05025509905882497
Trained batch 470 in epoch 6, gen_loss = 0.8315500469597535, disc_loss = 0.05015595012439332
Trained batch 471 in epoch 6, gen_loss = 0.8316875886235197, disc_loss = 0.05007965080153939
Trained batch 472 in epoch 6, gen_loss = 0.8315613507342389, disc_loss = 0.05000613152884325
Trained batch 473 in epoch 6, gen_loss = 0.8316255174734422, disc_loss = 0.04993964663661529
Trained batch 474 in epoch 6, gen_loss = 0.8317431870887154, disc_loss = 0.049842872898535506
Trained batch 475 in epoch 6, gen_loss = 0.8319414482772851, disc_loss = 0.04974911619464969
Trained batch 476 in epoch 6, gen_loss = 0.8322956861315034, disc_loss = 0.04965899189869703
Trained batch 477 in epoch 6, gen_loss = 0.832488602736505, disc_loss = 0.04958709983874081
Trained batch 478 in epoch 6, gen_loss = 0.8323686732006471, disc_loss = 0.049502416197424425
Trained batch 479 in epoch 6, gen_loss = 0.8325777343784769, disc_loss = 0.04942477059133429
Trained batch 480 in epoch 6, gen_loss = 0.8325455491731172, disc_loss = 0.04934092554778805
Trained batch 481 in epoch 6, gen_loss = 0.832565906693332, disc_loss = 0.04926432439471939
Trained batch 482 in epoch 6, gen_loss = 0.8328055610444481, disc_loss = 0.04917354687352281
Trained batch 483 in epoch 6, gen_loss = 0.8330464372334402, disc_loss = 0.04908181915650421
Trained batch 484 in epoch 6, gen_loss = 0.8330239801677232, disc_loss = 0.048998120601394586
Trained batch 485 in epoch 6, gen_loss = 0.8331612989367772, disc_loss = 0.048911149148377034
Trained batch 486 in epoch 6, gen_loss = 0.8334713677973228, disc_loss = 0.048826993801162503
Trained batch 487 in epoch 6, gen_loss = 0.833573720555325, disc_loss = 0.048731662671284016
Trained batch 488 in epoch 6, gen_loss = 0.833757362909356, disc_loss = 0.04863930315518245
Trained batch 489 in epoch 6, gen_loss = 0.8338455226348371, disc_loss = 0.04854638011869499
Trained batch 490 in epoch 6, gen_loss = 0.8340902874158987, disc_loss = 0.04848585557239984
Trained batch 491 in epoch 6, gen_loss = 0.834462617168097, disc_loss = 0.04841111362126194
Trained batch 492 in epoch 6, gen_loss = 0.8342837346132097, disc_loss = 0.048343536376473296
Trained batch 493 in epoch 6, gen_loss = 0.8343163332355167, disc_loss = 0.04825788713013188
Trained batch 494 in epoch 6, gen_loss = 0.8345054523511366, disc_loss = 0.048171424890652
Trained batch 495 in epoch 6, gen_loss = 0.8346567224230497, disc_loss = 0.048111803163567765
Trained batch 496 in epoch 6, gen_loss = 0.8349251200855378, disc_loss = 0.048033543383155464
Trained batch 497 in epoch 6, gen_loss = 0.8351940477349193, disc_loss = 0.0479619216690977
Trained batch 498 in epoch 6, gen_loss = 0.8351197027132841, disc_loss = 0.04787965579927042
Trained batch 499 in epoch 6, gen_loss = 0.8351683170199394, disc_loss = 0.047801059442106636
Trained batch 500 in epoch 6, gen_loss = 0.8351674374349103, disc_loss = 0.04771355364031108
Trained batch 501 in epoch 6, gen_loss = 0.8352418420205553, disc_loss = 0.04762538648683548
Trained batch 502 in epoch 6, gen_loss = 0.8352562024982028, disc_loss = 0.04756502637585947
Trained batch 503 in epoch 6, gen_loss = 0.8354025246013724, disc_loss = 0.04748056241401678
Trained batch 504 in epoch 6, gen_loss = 0.8356456111563314, disc_loss = 0.047412252688485354
Trained batch 505 in epoch 6, gen_loss = 0.8359388226694741, disc_loss = 0.047343487178137446
Trained batch 506 in epoch 6, gen_loss = 0.8360416051551435, disc_loss = 0.047261491674595535
Trained batch 507 in epoch 6, gen_loss = 0.8359138624757294, disc_loss = 0.04720182253705983
Trained batch 508 in epoch 6, gen_loss = 0.8361392278216911, disc_loss = 0.047114706732705965
Trained batch 509 in epoch 6, gen_loss = 0.8364080905329947, disc_loss = 0.04705001584838565
Trained batch 510 in epoch 6, gen_loss = 0.8365466419148119, disc_loss = 0.046964098480685
Trained batch 511 in epoch 6, gen_loss = 0.8366362560191192, disc_loss = 0.04688385131703399
Trained batch 512 in epoch 6, gen_loss = 0.8369458870232453, disc_loss = 0.046824587779537165
Trained batch 513 in epoch 6, gen_loss = 0.8368401843402172, disc_loss = 0.046747182109048914
Trained batch 514 in epoch 6, gen_loss = 0.8365869239117335, disc_loss = 0.046686361998645134
Trained batch 515 in epoch 6, gen_loss = 0.836636776436669, disc_loss = 0.0466120750074773
Trained batch 516 in epoch 6, gen_loss = 0.8368025452647956, disc_loss = 0.04661939477339041
Trained batch 517 in epoch 6, gen_loss = 0.8365269600769728, disc_loss = 0.04664873882398211
Trained batch 518 in epoch 6, gen_loss = 0.8363510796904334, disc_loss = 0.04664290593470481
Trained batch 519 in epoch 6, gen_loss = 0.8363559254660056, disc_loss = 0.04660140306491835
Trained batch 520 in epoch 6, gen_loss = 0.8369279456344538, disc_loss = 0.04660086304882466
Trained batch 521 in epoch 6, gen_loss = 0.8365863266461654, disc_loss = 0.046607474083708904
Trained batch 522 in epoch 6, gen_loss = 0.8365234623789559, disc_loss = 0.04669098172561189
Trained batch 523 in epoch 6, gen_loss = 0.8359511856928127, disc_loss = 0.046763103523732426
Trained batch 524 in epoch 6, gen_loss = 0.8358311478864578, disc_loss = 0.046696284529531285
Trained batch 525 in epoch 6, gen_loss = 0.8359357588304767, disc_loss = 0.046625938766703234
Trained batch 526 in epoch 6, gen_loss = 0.8362031469874409, disc_loss = 0.046598055434415024
Trained batch 527 in epoch 6, gen_loss = 0.8362004894085906, disc_loss = 0.04652745123673936
Trained batch 528 in epoch 6, gen_loss = 0.8363058038041813, disc_loss = 0.04645357216534069
Trained batch 529 in epoch 6, gen_loss = 0.8361212786076204, disc_loss = 0.04639410825340815
Trained batch 530 in epoch 6, gen_loss = 0.8356841667336035, disc_loss = 0.046390340472317236
Trained batch 531 in epoch 6, gen_loss = 0.8360996994196921, disc_loss = 0.046388256339062205
Trained batch 532 in epoch 6, gen_loss = 0.8363704045650883, disc_loss = 0.04631234505379793
Trained batch 533 in epoch 6, gen_loss = 0.8363580871722225, disc_loss = 0.04628814802041159
Trained batch 534 in epoch 6, gen_loss = 0.8361147341884185, disc_loss = 0.046282120409343284
Trained batch 535 in epoch 6, gen_loss = 0.8359922809498523, disc_loss = 0.04621922061431097
Trained batch 536 in epoch 6, gen_loss = 0.8362762470152125, disc_loss = 0.04615308006521266
Trained batch 537 in epoch 6, gen_loss = 0.8366383189494725, disc_loss = 0.04610070071034272
Trained batch 538 in epoch 6, gen_loss = 0.8372269587415048, disc_loss = 0.04605531290947617
Trained batch 539 in epoch 6, gen_loss = 0.8374438572261068, disc_loss = 0.046024314759092196
Trained batch 540 in epoch 6, gen_loss = 0.8375982733068096, disc_loss = 0.04615416747213181
Trained batch 541 in epoch 6, gen_loss = 0.8375417888714378, disc_loss = 0.04614765469562194
Trained batch 542 in epoch 6, gen_loss = 0.837254200466869, disc_loss = 0.04613221378081082
Trained batch 543 in epoch 6, gen_loss = 0.8374813749619267, disc_loss = 0.046058068363516426
Trained batch 544 in epoch 6, gen_loss = 0.8376924602810396, disc_loss = 0.04598872335884002
Trained batch 545 in epoch 6, gen_loss = 0.8379490561646856, disc_loss = 0.04593078992517167
Trained batch 546 in epoch 6, gen_loss = 0.837920008073995, disc_loss = 0.04585411253349491
Trained batch 547 in epoch 6, gen_loss = 0.8380547157713096, disc_loss = 0.04579428425160692
Trained batch 548 in epoch 6, gen_loss = 0.8381312708277086, disc_loss = 0.04572267328577289
Trained batch 549 in epoch 6, gen_loss = 0.8382734059745616, disc_loss = 0.0456555159305307
Trained batch 550 in epoch 6, gen_loss = 0.8382176376622299, disc_loss = 0.04559113133272761
Trained batch 551 in epoch 6, gen_loss = 0.8383517571441506, disc_loss = 0.045515496504790004
Trained batch 552 in epoch 6, gen_loss = 0.8385534737575766, disc_loss = 0.045443522060966995
Trained batch 553 in epoch 6, gen_loss = 0.838650990855823, disc_loss = 0.04536787521964887
Trained batch 554 in epoch 6, gen_loss = 0.8388956346490362, disc_loss = 0.04529388208982644
Trained batch 555 in epoch 6, gen_loss = 0.8391001300095654, disc_loss = 0.04521733018479196
Trained batch 556 in epoch 6, gen_loss = 0.8393547633927001, disc_loss = 0.04515045451307987
Trained batch 557 in epoch 6, gen_loss = 0.8395003667334929, disc_loss = 0.04507520282223794
Trained batch 558 in epoch 6, gen_loss = 0.839737809141548, disc_loss = 0.044999892273601245
Trained batch 559 in epoch 6, gen_loss = 0.8398948732763529, disc_loss = 0.04492418149311561
Trained batch 560 in epoch 6, gen_loss = 0.8399215302896584, disc_loss = 0.04485348205633276
Trained batch 561 in epoch 6, gen_loss = 0.8400655294970686, disc_loss = 0.044778123217903316
Trained batch 562 in epoch 6, gen_loss = 0.8402292732129512, disc_loss = 0.04470476715744442
Trained batch 563 in epoch 6, gen_loss = 0.8402528953573383, disc_loss = 0.0446422459930842
Trained batch 564 in epoch 6, gen_loss = 0.8401862526889395, disc_loss = 0.04457294781552216
Trained batch 565 in epoch 6, gen_loss = 0.8402082118149781, disc_loss = 0.044500714380215106
Trained batch 566 in epoch 6, gen_loss = 0.8402335118679773, disc_loss = 0.044429842131360184
Trained batch 567 in epoch 6, gen_loss = 0.8404531613726851, disc_loss = 0.04436036169653575
Trained batch 568 in epoch 6, gen_loss = 0.8406289130292165, disc_loss = 0.04428955610523979
Trained batch 569 in epoch 6, gen_loss = 0.84064116901473, disc_loss = 0.044215197486623205
Trained batch 570 in epoch 6, gen_loss = 0.8406955737052991, disc_loss = 0.044142324529627366
Trained batch 571 in epoch 6, gen_loss = 0.8407941518442614, disc_loss = 0.04406854821453718
Trained batch 572 in epoch 6, gen_loss = 0.8409809113901116, disc_loss = 0.043997893600365434
Trained batch 573 in epoch 6, gen_loss = 0.8410638155941349, disc_loss = 0.04393737191838969
Trained batch 574 in epoch 6, gen_loss = 0.8411819081202797, disc_loss = 0.043868860401132186
Trained batch 575 in epoch 6, gen_loss = 0.8411479769791994, disc_loss = 0.043800788231844
Trained batch 576 in epoch 6, gen_loss = 0.8413621798235168, disc_loss = 0.04372989451286723
Trained batch 577 in epoch 6, gen_loss = 0.8416695361215764, disc_loss = 0.04366401698163172
Trained batch 578 in epoch 6, gen_loss = 0.8418025917442763, disc_loss = 0.0436009475953285
Trained batch 579 in epoch 6, gen_loss = 0.8418573088173209, disc_loss = 0.04353458042304706
Trained batch 580 in epoch 6, gen_loss = 0.8420404243489756, disc_loss = 0.043468801188483036
Trained batch 581 in epoch 6, gen_loss = 0.8422803404097704, disc_loss = 0.04339857285048595
Trained batch 582 in epoch 6, gen_loss = 0.8424143531003497, disc_loss = 0.04333005889077666
Trained batch 583 in epoch 6, gen_loss = 0.8426297456536391, disc_loss = 0.04326295987336118
Trained batch 584 in epoch 6, gen_loss = 0.8427926283106845, disc_loss = 0.04319433514028788
Trained batch 585 in epoch 6, gen_loss = 0.8429302774090002, disc_loss = 0.04312655149717456
Trained batch 586 in epoch 6, gen_loss = 0.8429702615311442, disc_loss = 0.04305880599983633
Trained batch 587 in epoch 6, gen_loss = 0.8431082825575557, disc_loss = 0.0429964450054935
Trained batch 588 in epoch 6, gen_loss = 0.8431150407762803, disc_loss = 0.04295384361138267
Trained batch 589 in epoch 6, gen_loss = 0.8431780806537402, disc_loss = 0.04288507261218787
Trained batch 590 in epoch 6, gen_loss = 0.8434074696046245, disc_loss = 0.042816708712994596
Trained batch 591 in epoch 6, gen_loss = 0.8434680751147302, disc_loss = 0.04274898550018504
Trained batch 592 in epoch 6, gen_loss = 0.8436806683898174, disc_loss = 0.04268150036160412
Trained batch 593 in epoch 6, gen_loss = 0.8438279645310508, disc_loss = 0.042616439448208594
Trained batch 594 in epoch 6, gen_loss = 0.8440055779549254, disc_loss = 0.042553645194343785
Trained batch 595 in epoch 6, gen_loss = 0.8440547158954127, disc_loss = 0.04248572112843957
Trained batch 596 in epoch 6, gen_loss = 0.8441393069386283, disc_loss = 0.04241978478231085
Trained batch 597 in epoch 6, gen_loss = 0.8442350920526479, disc_loss = 0.042351536841145766
Trained batch 598 in epoch 6, gen_loss = 0.8442048006045798, disc_loss = 0.042292314369926455
Trained batch 599 in epoch 6, gen_loss = 0.8441752201815447, disc_loss = 0.042225852972478606
Trained batch 600 in epoch 6, gen_loss = 0.8444018937684533, disc_loss = 0.04217398287430127
Trained batch 601 in epoch 6, gen_loss = 0.8445181156016663, disc_loss = 0.04210710927222908
Trained batch 602 in epoch 6, gen_loss = 0.8445658539954702, disc_loss = 0.04203993379088987
Trained batch 603 in epoch 6, gen_loss = 0.8446545682304742, disc_loss = 0.04197458081627388
Trained batch 604 in epoch 6, gen_loss = 0.8447224721928274, disc_loss = 0.041908009577935085
Trained batch 605 in epoch 6, gen_loss = 0.8449242654511637, disc_loss = 0.04184421050464489
Trained batch 606 in epoch 6, gen_loss = 0.8448959719113502, disc_loss = 0.041779394639169576
Trained batch 607 in epoch 6, gen_loss = 0.844852906553761, disc_loss = 0.04171643572561535
Trained batch 608 in epoch 6, gen_loss = 0.8448744393236727, disc_loss = 0.04165154617575681
Trained batch 609 in epoch 6, gen_loss = 0.8448477026380476, disc_loss = 0.04158792051574459
Trained batch 610 in epoch 6, gen_loss = 0.8449030257578567, disc_loss = 0.04152477221466668
Trained batch 611 in epoch 6, gen_loss = 0.8451046243894333, disc_loss = 0.04146489088619097
Trained batch 612 in epoch 6, gen_loss = 0.8450471442344721, disc_loss = 0.0414009398465891
Trained batch 613 in epoch 6, gen_loss = 0.8449901675847921, disc_loss = 0.04134097284958197
Trained batch 614 in epoch 6, gen_loss = 0.845062092406963, disc_loss = 0.041276772321595594
Trained batch 615 in epoch 6, gen_loss = 0.8452667499614226, disc_loss = 0.04121413920018006
Trained batch 616 in epoch 6, gen_loss = 0.8452653430366053, disc_loss = 0.04115035928573725
Trained batch 617 in epoch 6, gen_loss = 0.8454338832484094, disc_loss = 0.0410896207604928
Trained batch 618 in epoch 6, gen_loss = 0.8456916188481166, disc_loss = 0.04102704977268362
Trained batch 619 in epoch 6, gen_loss = 0.8458415686603515, disc_loss = 0.04096321856636825
Trained batch 620 in epoch 6, gen_loss = 0.8458728451947659, disc_loss = 0.040902191115244804
Trained batch 621 in epoch 6, gen_loss = 0.8459883684418209, disc_loss = 0.04084057876277997
Trained batch 622 in epoch 6, gen_loss = 0.8459081419685296, disc_loss = 0.040782464620504784
Trained batch 623 in epoch 6, gen_loss = 0.8458174160944346, disc_loss = 0.0407198722530619
Trained batch 624 in epoch 6, gen_loss = 0.8458933496952057, disc_loss = 0.04065775978695601
Trained batch 625 in epoch 6, gen_loss = 0.8459800553683656, disc_loss = 0.04059761685126583
Trained batch 626 in epoch 6, gen_loss = 0.8460793061214581, disc_loss = 0.040536843087454366
Trained batch 627 in epoch 6, gen_loss = 0.8462209933597571, disc_loss = 0.04047831311873101
Trained batch 628 in epoch 6, gen_loss = 0.8463210047997048, disc_loss = 0.040417166656462125
Trained batch 629 in epoch 6, gen_loss = 0.8464037659149322, disc_loss = 0.04035781670661111
Trained batch 630 in epoch 6, gen_loss = 0.8463635103166008, disc_loss = 0.040298369713681094
Trained batch 631 in epoch 6, gen_loss = 0.8464400344351425, disc_loss = 0.04023722366557333
Trained batch 632 in epoch 6, gen_loss = 0.8465035180627453, disc_loss = 0.04017666830202361
Trained batch 633 in epoch 6, gen_loss = 0.8466076063526917, disc_loss = 0.04012883018628086
Trained batch 634 in epoch 6, gen_loss = 0.8466118145646073, disc_loss = 0.040074408586562325
Trained batch 635 in epoch 6, gen_loss = 0.8466677760834214, disc_loss = 0.040015125093116194
Trained batch 636 in epoch 6, gen_loss = 0.846838777396518, disc_loss = 0.03995591993907867
Trained batch 637 in epoch 6, gen_loss = 0.84685943684421, disc_loss = 0.03989894878754953
Trained batch 638 in epoch 6, gen_loss = 0.8469854149740067, disc_loss = 0.03984137132150997
Trained batch 639 in epoch 6, gen_loss = 0.8471061839256435, disc_loss = 0.03978833181445225
Trained batch 640 in epoch 6, gen_loss = 0.847156182884612, disc_loss = 0.039729449220761576
Trained batch 641 in epoch 6, gen_loss = 0.8472160816285469, disc_loss = 0.03968175289397363
Trained batch 642 in epoch 6, gen_loss = 0.8472323095538938, disc_loss = 0.03962466902368229
Trained batch 643 in epoch 6, gen_loss = 0.8473471766395598, disc_loss = 0.039565870989372906
Trained batch 644 in epoch 6, gen_loss = 0.8474839181401009, disc_loss = 0.039538004670775846
Trained batch 645 in epoch 6, gen_loss = 0.8474606219736784, disc_loss = 0.039479379878983464
Trained batch 646 in epoch 6, gen_loss = 0.8476178588509744, disc_loss = 0.039421238207223736
Trained batch 647 in epoch 6, gen_loss = 0.8476496987780671, disc_loss = 0.03936789513484397
Trained batch 648 in epoch 6, gen_loss = 0.8476167419015534, disc_loss = 0.039309508140121394
Trained batch 649 in epoch 6, gen_loss = 0.8476010874143014, disc_loss = 0.03925084867980331
Trained batch 650 in epoch 6, gen_loss = 0.8476174062206632, disc_loss = 0.03919530878796281
Trained batch 651 in epoch 6, gen_loss = 0.8476553547876012, disc_loss = 0.039146148826801244
Trained batch 652 in epoch 6, gen_loss = 0.84769779585222, disc_loss = 0.03908839586364165
Trained batch 653 in epoch 6, gen_loss = 0.8477782021513044, disc_loss = 0.039035736286438805
Trained batch 654 in epoch 6, gen_loss = 0.8478044783341065, disc_loss = 0.03897842574413183
Trained batch 655 in epoch 6, gen_loss = 0.8477579669163722, disc_loss = 0.03892136409807036
Trained batch 656 in epoch 6, gen_loss = 0.8478270090969005, disc_loss = 0.03886507453820052
Trained batch 657 in epoch 6, gen_loss = 0.8479360541764726, disc_loss = 0.03880822759384918
Trained batch 658 in epoch 6, gen_loss = 0.8479818735661745, disc_loss = 0.03875241710766245
Trained batch 659 in epoch 6, gen_loss = 0.8480367343985673, disc_loss = 0.03869649957473898
Trained batch 660 in epoch 6, gen_loss = 0.8481046144882958, disc_loss = 0.03864082377513169
Trained batch 661 in epoch 6, gen_loss = 0.8481516919557421, disc_loss = 0.038584975800420696
Trained batch 662 in epoch 6, gen_loss = 0.8481153036224717, disc_loss = 0.0385296307131929
Trained batch 663 in epoch 6, gen_loss = 0.8481963909264788, disc_loss = 0.03847373823399644
Trained batch 664 in epoch 6, gen_loss = 0.8482981357807503, disc_loss = 0.03841826869524959
Trained batch 665 in epoch 6, gen_loss = 0.848305543040012, disc_loss = 0.03836324756060288
Trained batch 666 in epoch 6, gen_loss = 0.8483292355440903, disc_loss = 0.0383087483310103
Trained batch 667 in epoch 6, gen_loss = 0.8483800105973632, disc_loss = 0.03825373593320468
Trained batch 668 in epoch 6, gen_loss = 0.8483759697153608, disc_loss = 0.03819994772791373
Trained batch 669 in epoch 6, gen_loss = 0.8486286534747081, disc_loss = 0.03814776060171425
Trained batch 670 in epoch 6, gen_loss = 0.8485895641781, disc_loss = 0.03809326495898918
Trained batch 671 in epoch 6, gen_loss = 0.8486431028605217, disc_loss = 0.03804410254642356
Trained batch 672 in epoch 6, gen_loss = 0.8487321023689514, disc_loss = 0.03800491694420476
Trained batch 673 in epoch 6, gen_loss = 0.8487950799107905, disc_loss = 0.03795230503985796
Trained batch 674 in epoch 6, gen_loss = 0.8488261482009182, disc_loss = 0.037900213586442445
Trained batch 675 in epoch 6, gen_loss = 0.848897751046003, disc_loss = 0.037846674390079334
Trained batch 676 in epoch 6, gen_loss = 0.8490198730453958, disc_loss = 0.03779348822350461
Trained batch 677 in epoch 6, gen_loss = 0.8491135070369659, disc_loss = 0.037740336073449864
Trained batch 678 in epoch 6, gen_loss = 0.8489787349908096, disc_loss = 0.03768822118853917
Trained batch 679 in epoch 6, gen_loss = 0.8490637069677606, disc_loss = 0.03763630695997135
Trained batch 680 in epoch 6, gen_loss = 0.8490776883085394, disc_loss = 0.03758376535772183
Trained batch 681 in epoch 6, gen_loss = 0.8491790980275425, disc_loss = 0.037530821724863085
Trained batch 682 in epoch 6, gen_loss = 0.8492117170271727, disc_loss = 0.03747887319904284
Trained batch 683 in epoch 6, gen_loss = 0.8492784303618454, disc_loss = 0.03742626965762802
Trained batch 684 in epoch 6, gen_loss = 0.8492995192969802, disc_loss = 0.0373735529498068
Trained batch 685 in epoch 6, gen_loss = 0.8492405378523096, disc_loss = 0.037325646823819225
Trained batch 686 in epoch 6, gen_loss = 0.8494238432231082, disc_loss = 0.03727489213064025
Trained batch 687 in epoch 6, gen_loss = 0.8492731351058843, disc_loss = 0.03722219576728855
Trained batch 688 in epoch 6, gen_loss = 0.8492988754166574, disc_loss = 0.03717202510913166
Trained batch 689 in epoch 6, gen_loss = 0.8492828038723572, disc_loss = 0.03711978976270589
Trained batch 690 in epoch 6, gen_loss = 0.8493134687761149, disc_loss = 0.03706803261662945
Trained batch 691 in epoch 6, gen_loss = 0.8493326175850251, disc_loss = 0.03701907880769133
Trained batch 692 in epoch 6, gen_loss = 0.8494089585964126, disc_loss = 0.03696761844265792
Trained batch 693 in epoch 6, gen_loss = 0.8493248404188871, disc_loss = 0.03691813073681952
Trained batch 694 in epoch 6, gen_loss = 0.8493744939780064, disc_loss = 0.03686706530292043
Trained batch 695 in epoch 6, gen_loss = 0.8494567755053098, disc_loss = 0.036816247290631904
Trained batch 696 in epoch 6, gen_loss = 0.8495032076257544, disc_loss = 0.03676518072090893
Trained batch 697 in epoch 6, gen_loss = 0.8496901789589393, disc_loss = 0.036724072964101455
Trained batch 698 in epoch 6, gen_loss = 0.8496929378553862, disc_loss = 0.03667821673621745
Trained batch 699 in epoch 6, gen_loss = 0.849839480306421, disc_loss = 0.03662917303852737
Trained batch 700 in epoch 6, gen_loss = 0.8498611106256956, disc_loss = 0.036580024144284094
Trained batch 701 in epoch 6, gen_loss = 0.8498899046427164, disc_loss = 0.03652989544588648
Trained batch 702 in epoch 6, gen_loss = 0.8500768315486854, disc_loss = 0.036482263228936836
Trained batch 703 in epoch 6, gen_loss = 0.8500707595270466, disc_loss = 0.036432542432521586
Trained batch 704 in epoch 6, gen_loss = 0.8501827565913505, disc_loss = 0.03638532699353279
Trained batch 705 in epoch 6, gen_loss = 0.8502737664889344, disc_loss = 0.03633786885812483
Trained batch 706 in epoch 6, gen_loss = 0.8503401917227592, disc_loss = 0.036289320474383824
Trained batch 707 in epoch 6, gen_loss = 0.8503660647630018, disc_loss = 0.036242911575189767
Trained batch 708 in epoch 6, gen_loss = 0.8504293830421646, disc_loss = 0.036200887088306585
Trained batch 709 in epoch 6, gen_loss = 0.8505098297142647, disc_loss = 0.03615756959172333
Trained batch 710 in epoch 6, gen_loss = 0.8505560409922137, disc_loss = 0.03610902461606443
Trained batch 711 in epoch 6, gen_loss = 0.8505500714514362, disc_loss = 0.03606759184913244
Trained batch 712 in epoch 6, gen_loss = 0.850887585029027, disc_loss = 0.036054376818254054
Trained batch 713 in epoch 6, gen_loss = 0.8508729375794488, disc_loss = 0.036007199399088474
Trained batch 714 in epoch 6, gen_loss = 0.8506233250761366, disc_loss = 0.03599731184304464
Trained batch 715 in epoch 6, gen_loss = 0.850718853735058, disc_loss = 0.03596699201581901
Trained batch 716 in epoch 6, gen_loss = 0.8507932631956151, disc_loss = 0.03592286535653687
Trained batch 717 in epoch 6, gen_loss = 0.8504730620341049, disc_loss = 0.035934831550660025
Trained batch 718 in epoch 6, gen_loss = 0.8505406972844677, disc_loss = 0.035892250630790844
Trained batch 719 in epoch 6, gen_loss = 0.8508496933099297, disc_loss = 0.03593693716086111
Trained batch 720 in epoch 6, gen_loss = 0.8508278446868786, disc_loss = 0.03589442993166124
Trained batch 721 in epoch 6, gen_loss = 0.8504420439209635, disc_loss = 0.03595708384693902
Trained batch 722 in epoch 6, gen_loss = 0.8505393032133991, disc_loss = 0.03592228838632252
Trained batch 723 in epoch 6, gen_loss = 0.8508252999976854, disc_loss = 0.03588748384490275
Trained batch 724 in epoch 6, gen_loss = 0.8504781010644189, disc_loss = 0.03597339230156022
Trained batch 725 in epoch 6, gen_loss = 0.8504968470696247, disc_loss = 0.03593686466812754
Trained batch 726 in epoch 6, gen_loss = 0.8507696458611232, disc_loss = 0.03591080654865359
Trained batch 727 in epoch 6, gen_loss = 0.8510346729922426, disc_loss = 0.03591299118716551
Trained batch 728 in epoch 6, gen_loss = 0.8510596584145425, disc_loss = 0.03587332653154495
Trained batch 729 in epoch 6, gen_loss = 0.8507597658323915, disc_loss = 0.03588407542923312
Trained batch 730 in epoch 6, gen_loss = 0.8508202634578528, disc_loss = 0.035847452644828234
Trained batch 731 in epoch 6, gen_loss = 0.8509903380372486, disc_loss = 0.03581424825808893
Trained batch 732 in epoch 6, gen_loss = 0.8510758490956009, disc_loss = 0.03581703661977203
Trained batch 733 in epoch 6, gen_loss = 0.8510933742942213, disc_loss = 0.03578133048849404
Trained batch 734 in epoch 6, gen_loss = 0.8511408744620628, disc_loss = 0.03574015348373602
Trained batch 735 in epoch 6, gen_loss = 0.8511788882720082, disc_loss = 0.035699081742400864
Trained batch 736 in epoch 6, gen_loss = 0.8511332599003893, disc_loss = 0.03566568690428594
Trained batch 737 in epoch 6, gen_loss = 0.8512297437846822, disc_loss = 0.035674874434660275
Trained batch 738 in epoch 6, gen_loss = 0.8510456651005597, disc_loss = 0.035655044889895446
Trained batch 739 in epoch 6, gen_loss = 0.8513547336330285, disc_loss = 0.03563534853636992
Trained batch 740 in epoch 6, gen_loss = 0.851537917105936, disc_loss = 0.035670637643101716
Trained batch 741 in epoch 6, gen_loss = 0.8514331467951726, disc_loss = 0.035635393183029475
Trained batch 742 in epoch 6, gen_loss = 0.8514122203654267, disc_loss = 0.03559955680403798
Trained batch 743 in epoch 6, gen_loss = 0.8514252905483528, disc_loss = 0.03555971508209158
Trained batch 744 in epoch 6, gen_loss = 0.8514742919662655, disc_loss = 0.035518795133555846
Trained batch 745 in epoch 6, gen_loss = 0.8515393660071708, disc_loss = 0.03548205307489461
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9237414598464966, disc_loss = 0.00312882661819458
Trained batch 1 in epoch 7, gen_loss = 0.9317476749420166, disc_loss = 0.006255116779357195
Trained batch 2 in epoch 7, gen_loss = 0.9142065445582072, disc_loss = 0.0049414542348434525
Trained batch 3 in epoch 7, gen_loss = 0.8994680941104889, disc_loss = 0.004198158800136298
Trained batch 4 in epoch 7, gen_loss = 0.8848201394081116, disc_loss = 0.0037935307249426843
Trained batch 5 in epoch 7, gen_loss = 0.8765929539998373, disc_loss = 0.0034783235363041363
Trained batch 6 in epoch 7, gen_loss = 0.8688333886010307, disc_loss = 0.003362703902114715
Trained batch 7 in epoch 7, gen_loss = 0.8824977800250053, disc_loss = 0.0038112103065941483
Trained batch 8 in epoch 7, gen_loss = 0.8792562219831679, disc_loss = 0.003933025498150123
Trained batch 9 in epoch 7, gen_loss = 0.8847390830516815, disc_loss = 0.004223956144414842
Trained batch 10 in epoch 7, gen_loss = 0.880296913060275, disc_loss = 0.004255453907799992
Trained batch 11 in epoch 7, gen_loss = 0.8760264962911606, disc_loss = 0.004202961223199964
Trained batch 12 in epoch 7, gen_loss = 0.876561531653771, disc_loss = 0.00425915215880825
Trained batch 13 in epoch 7, gen_loss = 0.8748149020331246, disc_loss = 0.004151200060732663
Trained batch 14 in epoch 7, gen_loss = 0.8759703914324443, disc_loss = 0.004036055381099383
Trained batch 15 in epoch 7, gen_loss = 0.8779213391244411, disc_loss = 0.0043652281747199595
Trained batch 16 in epoch 7, gen_loss = 0.8786321668063893, disc_loss = 0.004677613101461355
Trained batch 17 in epoch 7, gen_loss = 0.8824336462550693, disc_loss = 0.004970962336907784
Trained batch 18 in epoch 7, gen_loss = 0.8792170348920321, disc_loss = 0.005336024308283078
Trained batch 19 in epoch 7, gen_loss = 0.8771915972232819, disc_loss = 0.005446881614625454
Trained batch 20 in epoch 7, gen_loss = 0.8770607113838196, disc_loss = 0.005277852899217535
Trained batch 21 in epoch 7, gen_loss = 0.880275544795123, disc_loss = 0.005263322789687663
Trained batch 22 in epoch 7, gen_loss = 0.8820124735002932, disc_loss = 0.005105612875448297
Trained batch 23 in epoch 7, gen_loss = 0.8807927320400873, disc_loss = 0.005102489682030864
Trained batch 24 in epoch 7, gen_loss = 0.8768453502655029, disc_loss = 0.005221592034213245
Trained batch 25 in epoch 7, gen_loss = 0.8733409964121305, disc_loss = 0.006017638079356402
Trained batch 26 in epoch 7, gen_loss = 0.8802032073338827, disc_loss = 0.0061160297331365725
Trained batch 27 in epoch 7, gen_loss = 0.8868412843772343, disc_loss = 0.006232356848028887
Trained batch 28 in epoch 7, gen_loss = 0.8929639396996334, disc_loss = 0.006255716241992496
Trained batch 29 in epoch 7, gen_loss = 0.8970493197441101, disc_loss = 0.006329165829811245
Trained batch 30 in epoch 7, gen_loss = 0.8969716987302226, disc_loss = 0.006204151830095197
Trained batch 31 in epoch 7, gen_loss = 0.8977480754256248, disc_loss = 0.0060846976448374335
Trained batch 32 in epoch 7, gen_loss = 0.8975644436749545, disc_loss = 0.00841973279250052
Trained batch 33 in epoch 7, gen_loss = 0.8939933426239911, disc_loss = 0.008658923403880395
Trained batch 34 in epoch 7, gen_loss = 0.8886703048433576, disc_loss = 0.009569025229263518
Trained batch 35 in epoch 7, gen_loss = 0.8930422829257118, disc_loss = 0.009673595483440699
Trained batch 36 in epoch 7, gen_loss = 0.8936557898650298, disc_loss = 0.009621215307757863
Trained batch 37 in epoch 7, gen_loss = 0.8932084221588937, disc_loss = 0.00953295313765442
Trained batch 38 in epoch 7, gen_loss = 0.8908366453953278, disc_loss = 0.009493962852642514
Trained batch 39 in epoch 7, gen_loss = 0.8928065359592438, disc_loss = 0.009341961823520251
Trained batch 40 in epoch 7, gen_loss = 0.8920195364370579, disc_loss = 0.009195497688246755
Trained batch 41 in epoch 7, gen_loss = 0.8943230382033757, disc_loss = 0.009216560979395928
Trained batch 42 in epoch 7, gen_loss = 0.8919616951498874, disc_loss = 0.009116779631112031
Trained batch 43 in epoch 7, gen_loss = 0.891295235265385, disc_loss = 0.009181426380316472
Trained batch 44 in epoch 7, gen_loss = 0.8915405167473687, disc_loss = 0.009078947659064498
Trained batch 45 in epoch 7, gen_loss = 0.8922314229218856, disc_loss = 0.009084868262542168
Trained batch 46 in epoch 7, gen_loss = 0.8915482112701903, disc_loss = 0.009047740176221
Trained batch 47 in epoch 7, gen_loss = 0.8923011583586534, disc_loss = 0.008935679810141059
Trained batch 48 in epoch 7, gen_loss = 0.8897075373299268, disc_loss = 0.009440322589528347
Trained batch 49 in epoch 7, gen_loss = 0.8936078751087189, disc_loss = 0.009662627365905792
Trained batch 50 in epoch 7, gen_loss = 0.8949807496631846, disc_loss = 0.00965232790365596
Trained batch 51 in epoch 7, gen_loss = 0.8976436864871246, disc_loss = 0.009665663347382529
Trained batch 52 in epoch 7, gen_loss = 0.8971894653338306, disc_loss = 0.009839273982611045
Trained batch 53 in epoch 7, gen_loss = 0.8953029965912854, disc_loss = 0.009780912877802082
Trained batch 54 in epoch 7, gen_loss = 0.8951733101497997, disc_loss = 0.009776458459567617
Trained batch 55 in epoch 7, gen_loss = 0.8906315426741328, disc_loss = 0.01081736084181882
Trained batch 56 in epoch 7, gen_loss = 0.894885143689942, disc_loss = 0.017734506847581974
Trained batch 57 in epoch 7, gen_loss = 0.8915931037787733, disc_loss = 0.018940808486337935
Trained batch 58 in epoch 7, gen_loss = 0.8909085524284234, disc_loss = 0.019171742984819842
Trained batch 59 in epoch 7, gen_loss = 0.888170846303304, disc_loss = 0.019767800262585903
Trained batch 60 in epoch 7, gen_loss = 0.8835476304663986, disc_loss = 0.020442319188465473
Trained batch 61 in epoch 7, gen_loss = 0.8824747647008588, disc_loss = 0.020774839966062216
Trained batch 62 in epoch 7, gen_loss = 0.8799794609584506, disc_loss = 0.02089005635703899
Trained batch 63 in epoch 7, gen_loss = 0.8776990110054612, disc_loss = 0.020852632480455213
Trained batch 64 in epoch 7, gen_loss = 0.8758162828592154, disc_loss = 0.020919686794066084
Trained batch 65 in epoch 7, gen_loss = 0.8777837825543953, disc_loss = 0.0208033878924184
Trained batch 66 in epoch 7, gen_loss = 0.8790361854567457, disc_loss = 0.0206800416727036
Trained batch 67 in epoch 7, gen_loss = 0.8773585233618232, disc_loss = 0.020571222770205864
Trained batch 68 in epoch 7, gen_loss = 0.8758142003114673, disc_loss = 0.020830776510368763
Trained batch 69 in epoch 7, gen_loss = 0.8743215194770269, disc_loss = 0.020697025776774222
Trained batch 70 in epoch 7, gen_loss = 0.8751663532055599, disc_loss = 0.020479183127565807
Trained batch 71 in epoch 7, gen_loss = 0.877328984439373, disc_loss = 0.02181181938471531
Trained batch 72 in epoch 7, gen_loss = 0.8739818612190142, disc_loss = 0.02284721535955849
Trained batch 73 in epoch 7, gen_loss = 0.8708156266727963, disc_loss = 0.023291163607437566
Trained batch 74 in epoch 7, gen_loss = 0.8662772369384766, disc_loss = 0.024174592949760456
Trained batch 75 in epoch 7, gen_loss = 0.8627544782663646, disc_loss = 0.024404426897251
Trained batch 76 in epoch 7, gen_loss = 0.8650066109446736, disc_loss = 0.027428906418491977
Trained batch 77 in epoch 7, gen_loss = 0.8604454069565504, disc_loss = 0.02963395794787898
Trained batch 78 in epoch 7, gen_loss = 0.8603958019727393, disc_loss = 0.03057453796249826
Trained batch 79 in epoch 7, gen_loss = 0.8609747298061847, disc_loss = 0.030672589789901394
Trained batch 80 in epoch 7, gen_loss = 0.8579630093809999, disc_loss = 0.03163363233375375
Trained batch 81 in epoch 7, gen_loss = 0.8556563643420615, disc_loss = 0.03170918442291867
Trained batch 82 in epoch 7, gen_loss = 0.8541679030441376, disc_loss = 0.033821422883017684
Trained batch 83 in epoch 7, gen_loss = 0.8518236499457132, disc_loss = 0.03432657530425959
Trained batch 84 in epoch 7, gen_loss = 0.8485772308181314, disc_loss = 0.03509940597749151
Trained batch 85 in epoch 7, gen_loss = 0.8468441207741582, disc_loss = 0.0351827108737103
Trained batch 86 in epoch 7, gen_loss = 0.8475672602653503, disc_loss = 0.03562876544277259
Trained batch 87 in epoch 7, gen_loss = 0.8483344628052278, disc_loss = 0.03539993884491692
Trained batch 88 in epoch 7, gen_loss = 0.8441522683990136, disc_loss = 0.03825607861972968
Trained batch 89 in epoch 7, gen_loss = 0.8444702731238471, disc_loss = 0.03810650846636337
Trained batch 90 in epoch 7, gen_loss = 0.8450843017179888, disc_loss = 0.038718030671589077
Trained batch 91 in epoch 7, gen_loss = 0.8444238816914351, disc_loss = 0.03856320290082215
Trained batch 92 in epoch 7, gen_loss = 0.8450959510700677, disc_loss = 0.038616853091435165
Trained batch 93 in epoch 7, gen_loss = 0.8447411542243146, disc_loss = 0.03835034833730575
Trained batch 94 in epoch 7, gen_loss = 0.8436991503364162, disc_loss = 0.038109196169841056
Trained batch 95 in epoch 7, gen_loss = 0.8441933753589789, disc_loss = 0.03827791800358682
Trained batch 96 in epoch 7, gen_loss = 0.8430207605214463, disc_loss = 0.03827312895572101
Trained batch 97 in epoch 7, gen_loss = 0.8409813095112236, disc_loss = 0.03856716661984861
Trained batch 98 in epoch 7, gen_loss = 0.8436386597276938, disc_loss = 0.0389456733875447
Trained batch 99 in epoch 7, gen_loss = 0.8411469370126724, disc_loss = 0.039821719821775334
Trained batch 100 in epoch 7, gen_loss = 0.8417071133556933, disc_loss = 0.04013510601304582
Trained batch 101 in epoch 7, gen_loss = 0.8415272609860289, disc_loss = 0.039878150444779104
Trained batch 102 in epoch 7, gen_loss = 0.8412610766957107, disc_loss = 0.039649985365578636
Trained batch 103 in epoch 7, gen_loss = 0.8400302196924503, disc_loss = 0.03955467392426307
Trained batch 104 in epoch 7, gen_loss = 0.8408931346166701, disc_loss = 0.03926622205569098
Trained batch 105 in epoch 7, gen_loss = 0.8403651590617198, disc_loss = 0.039093169450698385
Trained batch 106 in epoch 7, gen_loss = 0.8419595344044338, disc_loss = 0.03892290544865879
Trained batch 107 in epoch 7, gen_loss = 0.8426409076761316, disc_loss = 0.03861276178159406
Trained batch 108 in epoch 7, gen_loss = 0.8396172528966851, disc_loss = 0.039842972041688726
Trained batch 109 in epoch 7, gen_loss = 0.8430180815133181, disc_loss = 0.039981793278870595
Trained batch 110 in epoch 7, gen_loss = 0.845130598759866, disc_loss = 0.04100308695342392
Trained batch 111 in epoch 7, gen_loss = 0.8443077190646103, disc_loss = 0.04097702567586176
Trained batch 112 in epoch 7, gen_loss = 0.8435129518002535, disc_loss = 0.04075890156930823
Trained batch 113 in epoch 7, gen_loss = 0.8439476876928095, disc_loss = 0.04235195744835788
Trained batch 114 in epoch 7, gen_loss = 0.8405043337656104, disc_loss = 0.04366651265375802
Trained batch 115 in epoch 7, gen_loss = 0.8398445171528849, disc_loss = 0.043651089751651384
Trained batch 116 in epoch 7, gen_loss = 0.8411228386764853, disc_loss = 0.04390889938431195
Trained batch 117 in epoch 7, gen_loss = 0.8409439451613668, disc_loss = 0.044156161504916025
Trained batch 118 in epoch 7, gen_loss = 0.839500318555271, disc_loss = 0.0450412038480863
Trained batch 119 in epoch 7, gen_loss = 0.8390822912255923, disc_loss = 0.045457650694879705
Trained batch 120 in epoch 7, gen_loss = 0.8378634906012165, disc_loss = 0.04568815899893549
Trained batch 121 in epoch 7, gen_loss = 0.8370348596182026, disc_loss = 0.04569083687822625
Trained batch 122 in epoch 7, gen_loss = 0.8380043385474663, disc_loss = 0.04550144840050792
Trained batch 123 in epoch 7, gen_loss = 0.8376137234510914, disc_loss = 0.0452467194249508
Trained batch 124 in epoch 7, gen_loss = 0.8366372790336609, disc_loss = 0.0452018437506631
Trained batch 125 in epoch 7, gen_loss = 0.8378739896274748, disc_loss = 0.04498188037680285
Trained batch 126 in epoch 7, gen_loss = 0.8394274627129863, disc_loss = 0.04474762092091466
Trained batch 127 in epoch 7, gen_loss = 0.839724475517869, disc_loss = 0.044489011529549316
Trained batch 128 in epoch 7, gen_loss = 0.8408671894738841, disc_loss = 0.045249098851417674
Trained batch 129 in epoch 7, gen_loss = 0.840715296451862, disc_loss = 0.045026357798801306
Trained batch 130 in epoch 7, gen_loss = 0.84016522196413, disc_loss = 0.04497228478675153
Trained batch 131 in epoch 7, gen_loss = 0.8398771448568865, disc_loss = 0.0447117979188492
Trained batch 132 in epoch 7, gen_loss = 0.8398385379547463, disc_loss = 0.04441507641467637
Trained batch 133 in epoch 7, gen_loss = 0.8413528550916644, disc_loss = 0.04428361203789072
Trained batch 134 in epoch 7, gen_loss = 0.8413995424906413, disc_loss = 0.0440613914600194
Trained batch 135 in epoch 7, gen_loss = 0.8404561609906309, disc_loss = 0.044153020379085584
Trained batch 136 in epoch 7, gen_loss = 0.84083578621384, disc_loss = 0.04389155598061608
Trained batch 137 in epoch 7, gen_loss = 0.8423385689224022, disc_loss = 0.04372284105604352
Trained batch 138 in epoch 7, gen_loss = 0.8437156016878087, disc_loss = 0.04738140993721435
Trained batch 139 in epoch 7, gen_loss = 0.8413040850843702, disc_loss = 0.04840510016989096
Trained batch 140 in epoch 7, gen_loss = 0.8406986623791093, disc_loss = 0.04846790774167244
Trained batch 141 in epoch 7, gen_loss = 0.8404449619038005, disc_loss = 0.04837782859792408
Trained batch 142 in epoch 7, gen_loss = 0.840828573787129, disc_loss = 0.04822331821054246
Trained batch 143 in epoch 7, gen_loss = 0.840763552321328, disc_loss = 0.04800732237587605
Trained batch 144 in epoch 7, gen_loss = 0.8394740828152361, disc_loss = 0.04802059793668189
Trained batch 145 in epoch 7, gen_loss = 0.8376530612984748, disc_loss = 0.04825524930054424
Trained batch 146 in epoch 7, gen_loss = 0.8389297464266926, disc_loss = 0.04825781714440431
Trained batch 147 in epoch 7, gen_loss = 0.8375543098191958, disc_loss = 0.048633214719499135
Trained batch 148 in epoch 7, gen_loss = 0.8396123591685455, disc_loss = 0.048639857207874976
Trained batch 149 in epoch 7, gen_loss = 0.8402302670478821, disc_loss = 0.04841781149695938
Trained batch 150 in epoch 7, gen_loss = 0.8398968395807885, disc_loss = 0.04818325940386966
Trained batch 151 in epoch 7, gen_loss = 0.8379734821225467, disc_loss = 0.048267457846362195
Trained batch 152 in epoch 7, gen_loss = 0.8378568050128962, disc_loss = 0.048946372060610435
Trained batch 153 in epoch 7, gen_loss = 0.8371293320284261, disc_loss = 0.04871920020056453
Trained batch 154 in epoch 7, gen_loss = 0.8352597882670741, disc_loss = 0.049128396548480995
Trained batch 155 in epoch 7, gen_loss = 0.8348052539886572, disc_loss = 0.04894360915820401
Trained batch 156 in epoch 7, gen_loss = 0.8341573195852292, disc_loss = 0.048929349125576484
Trained batch 157 in epoch 7, gen_loss = 0.8340354459949687, disc_loss = 0.04874797588983504
Trained batch 158 in epoch 7, gen_loss = 0.8337237711222667, disc_loss = 0.04850181181396727
Trained batch 159 in epoch 7, gen_loss = 0.8332384299486876, disc_loss = 0.04825495914919884
Trained batch 160 in epoch 7, gen_loss = 0.8325391878252444, disc_loss = 0.048060006344176086
Trained batch 161 in epoch 7, gen_loss = 0.8322251946837814, disc_loss = 0.04802125703074889
Trained batch 162 in epoch 7, gen_loss = 0.8305734249711768, disc_loss = 0.04808279532907771
Trained batch 163 in epoch 7, gen_loss = 0.8311857308556394, disc_loss = 0.04785572882051716
Trained batch 164 in epoch 7, gen_loss = 0.8326874613761902, disc_loss = 0.04788890132525315
Trained batch 165 in epoch 7, gen_loss = 0.8311112368681345, disc_loss = 0.04815801070702924
Trained batch 166 in epoch 7, gen_loss = 0.8313968435019076, disc_loss = 0.04816764045832957
Trained batch 167 in epoch 7, gen_loss = 0.8318334594368935, disc_loss = 0.04793368871226752
Trained batch 168 in epoch 7, gen_loss = 0.8302189838251418, disc_loss = 0.04861966892319164
Trained batch 169 in epoch 7, gen_loss = 0.8311671965262469, disc_loss = 0.04842776025385213
Trained batch 170 in epoch 7, gen_loss = 0.8316012802179794, disc_loss = 0.048267714007300115
Trained batch 171 in epoch 7, gen_loss = 0.8327706774999929, disc_loss = 0.0481143728214002
Trained batch 172 in epoch 7, gen_loss = 0.8329797418131305, disc_loss = 0.04787396586088281
Trained batch 173 in epoch 7, gen_loss = 0.8334715482832371, disc_loss = 0.04764018020787993
Trained batch 174 in epoch 7, gen_loss = 0.8341030485289438, disc_loss = 0.04828178424188601
Trained batch 175 in epoch 7, gen_loss = 0.833542924374342, disc_loss = 0.04818219721478685
Trained batch 176 in epoch 7, gen_loss = 0.8326133661350962, disc_loss = 0.048204921504961445
Trained batch 177 in epoch 7, gen_loss = 0.8317946359682619, disc_loss = 0.0483988555536731
Trained batch 178 in epoch 7, gen_loss = 0.8324776571556176, disc_loss = 0.04837975351662797
Trained batch 179 in epoch 7, gen_loss = 0.832586008310318, disc_loss = 0.04923129218643428
Trained batch 180 in epoch 7, gen_loss = 0.8311846493357453, disc_loss = 0.04952855087438526
Trained batch 181 in epoch 7, gen_loss = 0.8299777255608485, disc_loss = 0.04951260957654545
Trained batch 182 in epoch 7, gen_loss = 0.8297300231261332, disc_loss = 0.0495011133117642
Trained batch 183 in epoch 7, gen_loss = 0.8298334042015283, disc_loss = 0.04939187650439714
Trained batch 184 in epoch 7, gen_loss = 0.8283505948814186, disc_loss = 0.04988719209135082
Trained batch 185 in epoch 7, gen_loss = 0.8290668110693654, disc_loss = 0.049965891749873474
Trained batch 186 in epoch 7, gen_loss = 0.8289996073207754, disc_loss = 0.04976082807668251
Trained batch 187 in epoch 7, gen_loss = 0.8284732242848011, disc_loss = 0.04983302545944288
Trained batch 188 in epoch 7, gen_loss = 0.8290345482725315, disc_loss = 0.049619760224472474
Trained batch 189 in epoch 7, gen_loss = 0.8287964008356395, disc_loss = 0.04954080995184516
Trained batch 190 in epoch 7, gen_loss = 0.8279594847669152, disc_loss = 0.04956734529391653
Trained batch 191 in epoch 7, gen_loss = 0.8276439188048244, disc_loss = 0.049379550544472295
Trained batch 192 in epoch 7, gen_loss = 0.8282678698628677, disc_loss = 0.04915963361157982
Trained batch 193 in epoch 7, gen_loss = 0.8292887336814526, disc_loss = 0.0489994540370127
Trained batch 194 in epoch 7, gen_loss = 0.8287474451920925, disc_loss = 0.04883134112729189
Trained batch 195 in epoch 7, gen_loss = 0.8291258796745417, disc_loss = 0.04883658501844644
Trained batch 196 in epoch 7, gen_loss = 0.8282495495026487, disc_loss = 0.048952258440788814
Trained batch 197 in epoch 7, gen_loss = 0.8277777869894047, disc_loss = 0.04887954645961843
Trained batch 198 in epoch 7, gen_loss = 0.829930242881104, disc_loss = 0.049434561636322295
Trained batch 199 in epoch 7, gen_loss = 0.829174522459507, disc_loss = 0.04964028559450526
Trained batch 200 in epoch 7, gen_loss = 0.8282133667030145, disc_loss = 0.04990782206750646
Trained batch 201 in epoch 7, gen_loss = 0.8280290365219116, disc_loss = 0.049823753036083746
Trained batch 202 in epoch 7, gen_loss = 0.8279961271239031, disc_loss = 0.04987637043341058
Trained batch 203 in epoch 7, gen_loss = 0.8278768471643037, disc_loss = 0.04985492429798743
Trained batch 204 in epoch 7, gen_loss = 0.8271756965939592, disc_loss = 0.04992210237911289
Trained batch 205 in epoch 7, gen_loss = 0.8281066339571499, disc_loss = 0.04993389628079349
Trained batch 206 in epoch 7, gen_loss = 0.8278547079090911, disc_loss = 0.05003907237987029
Trained batch 207 in epoch 7, gen_loss = 0.8283881267102865, disc_loss = 0.05000179821385805
Trained batch 208 in epoch 7, gen_loss = 0.8279028226884358, disc_loss = 0.05030370647874193
Trained batch 209 in epoch 7, gen_loss = 0.8273062547047932, disc_loss = 0.05031525696505837
Trained batch 210 in epoch 7, gen_loss = 0.8269869665398982, disc_loss = 0.05019915243224528
Trained batch 211 in epoch 7, gen_loss = 0.8281887274868084, disc_loss = 0.05008221904248579
Trained batch 212 in epoch 7, gen_loss = 0.8287509690987672, disc_loss = 0.04996815911317113
Trained batch 213 in epoch 7, gen_loss = 0.828180658761586, disc_loss = 0.04986017245079051
Trained batch 214 in epoch 7, gen_loss = 0.8285180807113648, disc_loss = 0.049671407050972935
Trained batch 215 in epoch 7, gen_loss = 0.8290436748001311, disc_loss = 0.04950382596547974
Trained batch 216 in epoch 7, gen_loss = 0.8284721693135626, disc_loss = 0.049350126262878664
Trained batch 217 in epoch 7, gen_loss = 0.827725472253397, disc_loss = 0.049477227773931765
Trained batch 218 in epoch 7, gen_loss = 0.8280604446315329, disc_loss = 0.049359052325598896
Trained batch 219 in epoch 7, gen_loss = 0.8288111968473955, disc_loss = 0.04926205420369198
Trained batch 220 in epoch 7, gen_loss = 0.8280701904275298, disc_loss = 0.04920083116497676
Trained batch 221 in epoch 7, gen_loss = 0.826951677466298, disc_loss = 0.04927977171846087
Trained batch 222 in epoch 7, gen_loss = 0.8282171608086659, disc_loss = 0.04916948591924853
Trained batch 223 in epoch 7, gen_loss = 0.8295921111213309, disc_loss = 0.04941648761086981
Trained batch 224 in epoch 7, gen_loss = 0.8288657342063056, disc_loss = 0.04937175691800399
Trained batch 225 in epoch 7, gen_loss = 0.8292544267873848, disc_loss = 0.04918139033582045
Trained batch 226 in epoch 7, gen_loss = 0.8290992124490276, disc_loss = 0.049128120769705574
Trained batch 227 in epoch 7, gen_loss = 0.8281424050791222, disc_loss = 0.049077314860289586
Trained batch 228 in epoch 7, gen_loss = 0.8277782688494854, disc_loss = 0.04889952962024455
Trained batch 229 in epoch 7, gen_loss = 0.8282786465209463, disc_loss = 0.04886573599702071
Trained batch 230 in epoch 7, gen_loss = 0.8285285077053747, disc_loss = 0.04872229520797939
Trained batch 231 in epoch 7, gen_loss = 0.828652715117767, disc_loss = 0.048651456010451635
Trained batch 232 in epoch 7, gen_loss = 0.8285134979583675, disc_loss = 0.04861161190778609
Trained batch 233 in epoch 7, gen_loss = 0.8288733332585065, disc_loss = 0.048447929231676824
Trained batch 234 in epoch 7, gen_loss = 0.8280049866818368, disc_loss = 0.048516387734661236
Trained batch 235 in epoch 7, gen_loss = 0.8286187219417701, disc_loss = 0.0485727579645631
Trained batch 236 in epoch 7, gen_loss = 0.8285698415357855, disc_loss = 0.048453708399845606
Trained batch 237 in epoch 7, gen_loss = 0.8289192990094674, disc_loss = 0.048271526303240136
Trained batch 238 in epoch 7, gen_loss = 0.8295527614310196, disc_loss = 0.04825482222350961
Trained batch 239 in epoch 7, gen_loss = 0.8295950539410114, disc_loss = 0.048173112494502374
Trained batch 240 in epoch 7, gen_loss = 0.8290849503639822, disc_loss = 0.04800701531131377
Trained batch 241 in epoch 7, gen_loss = 0.8285444901009237, disc_loss = 0.047979499007986995
Trained batch 242 in epoch 7, gen_loss = 0.8275944097542468, disc_loss = 0.0479634595529939
Trained batch 243 in epoch 7, gen_loss = 0.8287876429127865, disc_loss = 0.04800012478935074
Trained batch 244 in epoch 7, gen_loss = 0.8293600882802691, disc_loss = 0.04796829056612463
Trained batch 245 in epoch 7, gen_loss = 0.8289112833941855, disc_loss = 0.04786417619902565
Trained batch 246 in epoch 7, gen_loss = 0.8291633392152516, disc_loss = 0.0476996393234239
Trained batch 247 in epoch 7, gen_loss = 0.8282789958100165, disc_loss = 0.04775868842778202
Trained batch 248 in epoch 7, gen_loss = 0.8284974012030176, disc_loss = 0.04781358398685987
Trained batch 249 in epoch 7, gen_loss = 0.8288344900608062, disc_loss = 0.04768003921071067
Trained batch 250 in epoch 7, gen_loss = 0.8294575114649131, disc_loss = 0.04755650082857263
Trained batch 251 in epoch 7, gen_loss = 0.8289965930439177, disc_loss = 0.04749275190203214
Trained batch 252 in epoch 7, gen_loss = 0.8283271815465845, disc_loss = 0.04768508863258047
Trained batch 253 in epoch 7, gen_loss = 0.8286070351994882, disc_loss = 0.04754558690928114
Trained batch 254 in epoch 7, gen_loss = 0.8292810606021507, disc_loss = 0.04795372759165498
Trained batch 255 in epoch 7, gen_loss = 0.8286291647236794, disc_loss = 0.04801610637377962
Trained batch 256 in epoch 7, gen_loss = 0.8278236878521248, disc_loss = 0.04809547277894016
Trained batch 257 in epoch 7, gen_loss = 0.8281572622846264, disc_loss = 0.048049882630539636
Trained batch 258 in epoch 7, gen_loss = 0.8288986388320628, disc_loss = 0.04800113169593255
Trained batch 259 in epoch 7, gen_loss = 0.8287786580049075, disc_loss = 0.04828162565693044
Trained batch 260 in epoch 7, gen_loss = 0.827876291055789, disc_loss = 0.048527328645849736
Trained batch 261 in epoch 7, gen_loss = 0.8282846869858167, disc_loss = 0.04847873177047009
Trained batch 262 in epoch 7, gen_loss = 0.8284261206257026, disc_loss = 0.0487297050245
Trained batch 263 in epoch 7, gen_loss = 0.8279499088724455, disc_loss = 0.04870031244751193
Trained batch 264 in epoch 7, gen_loss = 0.8267239190497488, disc_loss = 0.04923524790364405
Trained batch 265 in epoch 7, gen_loss = 0.827521743855082, disc_loss = 0.04951514363773797
Trained batch 266 in epoch 7, gen_loss = 0.8279840383636817, disc_loss = 0.04954696298630957
Trained batch 267 in epoch 7, gen_loss = 0.8275969597830701, disc_loss = 0.049475980844824755
Trained batch 268 in epoch 7, gen_loss = 0.8280668398261514, disc_loss = 0.049326300481247774
Trained batch 269 in epoch 7, gen_loss = 0.827505577714355, disc_loss = 0.04938022474870431
Trained batch 270 in epoch 7, gen_loss = 0.8286253132503411, disc_loss = 0.049349011474020946
Trained batch 271 in epoch 7, gen_loss = 0.8275346344008165, disc_loss = 0.04956385046663105
Trained batch 272 in epoch 7, gen_loss = 0.827665253218277, disc_loss = 0.04940157243171741
Trained batch 273 in epoch 7, gen_loss = 0.8283693083446392, disc_loss = 0.049390393588437026
Trained batch 274 in epoch 7, gen_loss = 0.8284618249806491, disc_loss = 0.049382392344573006
Trained batch 275 in epoch 7, gen_loss = 0.8283152258482532, disc_loss = 0.049307891876737085
Trained batch 276 in epoch 7, gen_loss = 0.8279561150805614, disc_loss = 0.04956533605886778
Trained batch 277 in epoch 7, gen_loss = 0.8272032793477285, disc_loss = 0.04972914782588926
Trained batch 278 in epoch 7, gen_loss = 0.8269963879739085, disc_loss = 0.04959913329212963
Trained batch 279 in epoch 7, gen_loss = 0.8283484105552946, disc_loss = 0.0505142900498218
Trained batch 280 in epoch 7, gen_loss = 0.8271365331161065, disc_loss = 0.050859501612293155
Trained batch 281 in epoch 7, gen_loss = 0.8269523206754779, disc_loss = 0.05077878954524755
Trained batch 282 in epoch 7, gen_loss = 0.8276498543078824, disc_loss = 0.05125252632037555
Trained batch 283 in epoch 7, gen_loss = 0.827217236580983, disc_loss = 0.05131463762282551
Trained batch 284 in epoch 7, gen_loss = 0.826196126979694, disc_loss = 0.05162949173245579
Trained batch 285 in epoch 7, gen_loss = 0.8260168231033779, disc_loss = 0.05199142710274815
Trained batch 286 in epoch 7, gen_loss = 0.825681875599386, disc_loss = 0.05218328497306045
Trained batch 287 in epoch 7, gen_loss = 0.8250048175040219, disc_loss = 0.05224068429904744
Trained batch 288 in epoch 7, gen_loss = 0.8244908031295327, disc_loss = 0.05229580060177673
Trained batch 289 in epoch 7, gen_loss = 0.8254143852612068, disc_loss = 0.053099004956813335
Trained batch 290 in epoch 7, gen_loss = 0.8241366337459931, disc_loss = 0.053599827817666805
Trained batch 291 in epoch 7, gen_loss = 0.8233424558827321, disc_loss = 0.05365644263347598
Trained batch 292 in epoch 7, gen_loss = 0.8230312308964062, disc_loss = 0.054107057515916386
Trained batch 293 in epoch 7, gen_loss = 0.8227225897871718, disc_loss = 0.05409375699213231
Trained batch 294 in epoch 7, gen_loss = 0.8217871836686539, disc_loss = 0.055012904935106
Trained batch 295 in epoch 7, gen_loss = 0.8219136914892776, disc_loss = 0.05493600195237574
Trained batch 296 in epoch 7, gen_loss = 0.8212855886730682, disc_loss = 0.05519788947484773
Trained batch 297 in epoch 7, gen_loss = 0.8208049208725858, disc_loss = 0.05523640079300338
Trained batch 298 in epoch 7, gen_loss = 0.8210311726383541, disc_loss = 0.055206018403860864
Trained batch 299 in epoch 7, gen_loss = 0.8205986568331718, disc_loss = 0.055125071922084316
Trained batch 300 in epoch 7, gen_loss = 0.820503485262196, disc_loss = 0.05500343045957721
Trained batch 301 in epoch 7, gen_loss = 0.8213111696061709, disc_loss = 0.05501537303793374
Trained batch 302 in epoch 7, gen_loss = 0.8217045793635617, disc_loss = 0.05485784656809268
Trained batch 303 in epoch 7, gen_loss = 0.8214640777165952, disc_loss = 0.054727150467729906
Trained batch 304 in epoch 7, gen_loss = 0.8211350004203984, disc_loss = 0.05463978437836602
Trained batch 305 in epoch 7, gen_loss = 0.8211306359838036, disc_loss = 0.054494699007098024
Trained batch 306 in epoch 7, gen_loss = 0.8212691705661799, disc_loss = 0.054332212481650766
Trained batch 307 in epoch 7, gen_loss = 0.8221763369518441, disc_loss = 0.05425640409124422
Trained batch 308 in epoch 7, gen_loss = 0.8221740538441248, disc_loss = 0.054229555868929476
Trained batch 309 in epoch 7, gen_loss = 0.8218122813970812, disc_loss = 0.05422031580838525
Trained batch 310 in epoch 7, gen_loss = 0.8222243154355567, disc_loss = 0.0541189119666725
Trained batch 311 in epoch 7, gen_loss = 0.8224242418431319, disc_loss = 0.053980861596825816
Trained batch 312 in epoch 7, gen_loss = 0.8227261958982998, disc_loss = 0.053884641178467044
Trained batch 313 in epoch 7, gen_loss = 0.8230332399060012, disc_loss = 0.05372809409942466
Trained batch 314 in epoch 7, gen_loss = 0.8233540891654908, disc_loss = 0.0536118354711179
Trained batch 315 in epoch 7, gen_loss = 0.8235884888828555, disc_loss = 0.053475428428987185
Trained batch 316 in epoch 7, gen_loss = 0.8238007028584224, disc_loss = 0.05333999357860512
Trained batch 317 in epoch 7, gen_loss = 0.8239108617388228, disc_loss = 0.053211592135250965
Trained batch 318 in epoch 7, gen_loss = 0.8240645115838903, disc_loss = 0.05306681982923276
Trained batch 319 in epoch 7, gen_loss = 0.8242658750154078, disc_loss = 0.05291450007825915
Trained batch 320 in epoch 7, gen_loss = 0.8244669696437978, disc_loss = 0.05323394328084516
Trained batch 321 in epoch 7, gen_loss = 0.8245998372017227, disc_loss = 0.053112224616784234
Trained batch 322 in epoch 7, gen_loss = 0.8242359732511243, disc_loss = 0.053077068069197195
Trained batch 323 in epoch 7, gen_loss = 0.8240575980809, disc_loss = 0.052932508773081303
Trained batch 324 in epoch 7, gen_loss = 0.8244602066736955, disc_loss = 0.05285068710298779
Trained batch 325 in epoch 7, gen_loss = 0.824389714313431, disc_loss = 0.0527043741262815
Trained batch 326 in epoch 7, gen_loss = 0.8243475797890888, disc_loss = 0.05258100346017014
Trained batch 327 in epoch 7, gen_loss = 0.8243478853709814, disc_loss = 0.05245173955087766
Trained batch 328 in epoch 7, gen_loss = 0.8249181709209836, disc_loss = 0.052378260242146944
Trained batch 329 in epoch 7, gen_loss = 0.8243949892846021, disc_loss = 0.052407300605255204
Trained batch 330 in epoch 7, gen_loss = 0.8255924475337083, disc_loss = 0.0523875758049762
Trained batch 331 in epoch 7, gen_loss = 0.8262034334152578, disc_loss = 0.052355059532305584
Trained batch 332 in epoch 7, gen_loss = 0.8256917426715026, disc_loss = 0.052369533154579276
Trained batch 333 in epoch 7, gen_loss = 0.8257175342230025, disc_loss = 0.0522434554557026
Trained batch 334 in epoch 7, gen_loss = 0.825953649140116, disc_loss = 0.05212209627567443
Trained batch 335 in epoch 7, gen_loss = 0.8258087674954108, disc_loss = 0.05198992823196542
Trained batch 336 in epoch 7, gen_loss = 0.8259588908901554, disc_loss = 0.051860681536347666
Trained batch 337 in epoch 7, gen_loss = 0.8259529779119604, disc_loss = 0.0517319632041786
Trained batch 338 in epoch 7, gen_loss = 0.8257380580655945, disc_loss = 0.0516220566663468
Trained batch 339 in epoch 7, gen_loss = 0.8261089208371499, disc_loss = 0.051489972175605705
Trained batch 340 in epoch 7, gen_loss = 0.8264263841238889, disc_loss = 0.05135377086978952
Trained batch 341 in epoch 7, gen_loss = 0.8266571084832588, disc_loss = 0.05121838645798519
Trained batch 342 in epoch 7, gen_loss = 0.8271494555577592, disc_loss = 0.051098934110354516
Trained batch 343 in epoch 7, gen_loss = 0.8275856198093225, disc_loss = 0.050972341539860744
Trained batch 344 in epoch 7, gen_loss = 0.8269434375175532, disc_loss = 0.051056737594805876
Trained batch 345 in epoch 7, gen_loss = 0.8271461000849056, disc_loss = 0.05097947941690608
Trained batch 346 in epoch 7, gen_loss = 0.8278822100987009, disc_loss = 0.05092009922566016
Trained batch 347 in epoch 7, gen_loss = 0.8280356823541652, disc_loss = 0.050816892808498604
Trained batch 348 in epoch 7, gen_loss = 0.8275215196233766, disc_loss = 0.05089565264201192
Trained batch 349 in epoch 7, gen_loss = 0.8274619569948741, disc_loss = 0.05082985039434529
Trained batch 350 in epoch 7, gen_loss = 0.8272548167624025, disc_loss = 0.051272431968583956
Trained batch 351 in epoch 7, gen_loss = 0.8274250317534263, disc_loss = 0.051144640250144716
Trained batch 352 in epoch 7, gen_loss = 0.8271806755923684, disc_loss = 0.051098755471442665
Trained batch 353 in epoch 7, gen_loss = 0.8277565398290332, disc_loss = 0.05101826566299108
Trained batch 354 in epoch 7, gen_loss = 0.8268589923919086, disc_loss = 0.05121821719451322
Trained batch 355 in epoch 7, gen_loss = 0.8265349011910096, disc_loss = 0.051263306648640504
Trained batch 356 in epoch 7, gen_loss = 0.8282979757678943, disc_loss = 0.05145279201515885
Trained batch 357 in epoch 7, gen_loss = 0.8287343160566671, disc_loss = 0.051334257412236184
Trained batch 358 in epoch 7, gen_loss = 0.8296347196553743, disc_loss = 0.0512852641500268
Trained batch 359 in epoch 7, gen_loss = 0.8294018279347155, disc_loss = 0.05121421262705957
Trained batch 360 in epoch 7, gen_loss = 0.8293695130341601, disc_loss = 0.051098799642879736
Trained batch 361 in epoch 7, gen_loss = 0.8300244298593774, disc_loss = 0.05102741331902708
Trained batch 362 in epoch 7, gen_loss = 0.8301722209479855, disc_loss = 0.05090318874490624
Trained batch 363 in epoch 7, gen_loss = 0.8302526558329771, disc_loss = 0.050786406838317186
Trained batch 364 in epoch 7, gen_loss = 0.8303980774258914, disc_loss = 0.05067333102717434
Trained batch 365 in epoch 7, gen_loss = 0.8304515545322595, disc_loss = 0.050560730731158
Trained batch 366 in epoch 7, gen_loss = 0.8303788443189876, disc_loss = 0.0504434933376496
Trained batch 367 in epoch 7, gen_loss = 0.8304456981789806, disc_loss = 0.05032070004919027
Trained batch 368 in epoch 7, gen_loss = 0.8310432341202165, disc_loss = 0.05024309226199429
Trained batch 369 in epoch 7, gen_loss = 0.8310365023645194, disc_loss = 0.050161742419319075
Trained batch 370 in epoch 7, gen_loss = 0.8311193231141792, disc_loss = 0.050040187118662836
Trained batch 371 in epoch 7, gen_loss = 0.8313148924580185, disc_loss = 0.049916642081175217
Trained batch 372 in epoch 7, gen_loss = 0.8316305616106489, disc_loss = 0.04992967123326773
Trained batch 373 in epoch 7, gen_loss = 0.8314004906199195, disc_loss = 0.04988286677495213
Trained batch 374 in epoch 7, gen_loss = 0.8312112667560577, disc_loss = 0.04983684324628363
Trained batch 375 in epoch 7, gen_loss = 0.8310784577847795, disc_loss = 0.04974962274470872
Trained batch 376 in epoch 7, gen_loss = 0.8314540873946182, disc_loss = 0.04965085693510294
Trained batch 377 in epoch 7, gen_loss = 0.8318790617600951, disc_loss = 0.049572960273104
Trained batch 378 in epoch 7, gen_loss = 0.8319650758696735, disc_loss = 0.04961402779279183
Trained batch 379 in epoch 7, gen_loss = 0.8318284498233545, disc_loss = 0.04951435595070698
Trained batch 380 in epoch 7, gen_loss = 0.8308567766911714, disc_loss = 0.049923077469210084
Trained batch 381 in epoch 7, gen_loss = 0.8303793207669133, disc_loss = 0.05002546795011201
Trained batch 382 in epoch 7, gen_loss = 0.8302860954878536, disc_loss = 0.050318727108367836
Trained batch 383 in epoch 7, gen_loss = 0.830871085713928, disc_loss = 0.05029406900969965
Trained batch 384 in epoch 7, gen_loss = 0.8314517260371864, disc_loss = 0.05022680383907365
Trained batch 385 in epoch 7, gen_loss = 0.8314526356718083, disc_loss = 0.050128875077410165
Trained batch 386 in epoch 7, gen_loss = 0.8314269692552798, disc_loss = 0.050064657479392254
Trained batch 387 in epoch 7, gen_loss = 0.8319617731823135, disc_loss = 0.04999504739943095
Trained batch 388 in epoch 7, gen_loss = 0.8318837538629694, disc_loss = 0.04993574455252353
Trained batch 389 in epoch 7, gen_loss = 0.8313657975349671, disc_loss = 0.04995213320914608
Trained batch 390 in epoch 7, gen_loss = 0.8317007360708378, disc_loss = 0.04987397288714233
Trained batch 391 in epoch 7, gen_loss = 0.8314746910972255, disc_loss = 0.049806585748340196
Trained batch 392 in epoch 7, gen_loss = 0.8317068658257258, disc_loss = 0.049694643708114196
Trained batch 393 in epoch 7, gen_loss = 0.8327068511755938, disc_loss = 0.04979848290047831
Trained batch 394 in epoch 7, gen_loss = 0.8322034957288187, disc_loss = 0.049965471947931134
Trained batch 395 in epoch 7, gen_loss = 0.832048440596672, disc_loss = 0.04987752164221331
Trained batch 396 in epoch 7, gen_loss = 0.8314282665174614, disc_loss = 0.0498881918751759
Trained batch 397 in epoch 7, gen_loss = 0.8327950957282704, disc_loss = 0.05004371299634187
Trained batch 398 in epoch 7, gen_loss = 0.8325523888706264, disc_loss = 0.049994444230951854
Trained batch 399 in epoch 7, gen_loss = 0.8328749916702509, disc_loss = 0.04992000826547155
Trained batch 400 in epoch 7, gen_loss = 0.8323252728009164, disc_loss = 0.0499341761094734
Trained batch 401 in epoch 7, gen_loss = 0.8323390714416457, disc_loss = 0.0498348986026275
Trained batch 402 in epoch 7, gen_loss = 0.8330494800661101, disc_loss = 0.05012960757779433
Trained batch 403 in epoch 7, gen_loss = 0.8332607875218486, disc_loss = 0.05003729930273165
Trained batch 404 in epoch 7, gen_loss = 0.8331195467048221, disc_loss = 0.04993365867506069
Trained batch 405 in epoch 7, gen_loss = 0.8329577681613086, disc_loss = 0.04983278688443641
Trained batch 406 in epoch 7, gen_loss = 0.832860180215695, disc_loss = 0.04976113381451202
Trained batch 407 in epoch 7, gen_loss = 0.8329076457987813, disc_loss = 0.04967695937232872
Trained batch 408 in epoch 7, gen_loss = 0.8326249341947234, disc_loss = 0.04959514694917983
Trained batch 409 in epoch 7, gen_loss = 0.8320893666366251, disc_loss = 0.04964019883020849
Trained batch 410 in epoch 7, gen_loss = 0.8328024431011682, disc_loss = 0.04998744090304114
Trained batch 411 in epoch 7, gen_loss = 0.8325501827215686, disc_loss = 0.04993908338896361
Trained batch 412 in epoch 7, gen_loss = 0.8329910659761175, disc_loss = 0.0499008514957286
Trained batch 413 in epoch 7, gen_loss = 0.8322030135254929, disc_loss = 0.05012051377963986
Trained batch 414 in epoch 7, gen_loss = 0.8323616129088115, disc_loss = 0.05026582195956529
Trained batch 415 in epoch 7, gen_loss = 0.8316767689270469, disc_loss = 0.05038498695005099
Trained batch 416 in epoch 7, gen_loss = 0.831328782746546, disc_loss = 0.05038780134927249
Trained batch 417 in epoch 7, gen_loss = 0.8318320281054985, disc_loss = 0.0503608453052417
Trained batch 418 in epoch 7, gen_loss = 0.8323923909152038, disc_loss = 0.05030529523020508
Trained batch 419 in epoch 7, gen_loss = 0.8319393940624736, disc_loss = 0.050292793919964295
Trained batch 420 in epoch 7, gen_loss = 0.8314882417047958, disc_loss = 0.0503654338150106
Trained batch 421 in epoch 7, gen_loss = 0.8320917280223132, disc_loss = 0.05058683625502971
Trained batch 422 in epoch 7, gen_loss = 0.8320440044780714, disc_loss = 0.05051198378166769
Trained batch 423 in epoch 7, gen_loss = 0.8318378501483854, disc_loss = 0.050459680614503157
Trained batch 424 in epoch 7, gen_loss = 0.8319363319873809, disc_loss = 0.05036993849940379
Trained batch 425 in epoch 7, gen_loss = 0.8315287345032177, disc_loss = 0.05036532661266529
Trained batch 426 in epoch 7, gen_loss = 0.8314631568045471, disc_loss = 0.05027326277268514
Trained batch 427 in epoch 7, gen_loss = 0.8308688487822764, disc_loss = 0.05030853338414481
Trained batch 428 in epoch 7, gen_loss = 0.8308730006634772, disc_loss = 0.05021037587202382
Trained batch 429 in epoch 7, gen_loss = 0.8304109452075736, disc_loss = 0.05020516037773124
Trained batch 430 in epoch 7, gen_loss = 0.8313741609972757, disc_loss = 0.05029835204000686
Trained batch 431 in epoch 7, gen_loss = 0.8314610637586426, disc_loss = 0.050252026683463354
Trained batch 432 in epoch 7, gen_loss = 0.8319055798009691, disc_loss = 0.05016374180774155
Trained batch 433 in epoch 7, gen_loss = 0.8316440777981886, disc_loss = 0.0500826252174289
Trained batch 434 in epoch 7, gen_loss = 0.831119203636016, disc_loss = 0.050106546939243615
Trained batch 435 in epoch 7, gen_loss = 0.8308967076447031, disc_loss = 0.050039589910505236
Trained batch 436 in epoch 7, gen_loss = 0.8311301898765345, disc_loss = 0.05001666456662349
Trained batch 437 in epoch 7, gen_loss = 0.8317441543623737, disc_loss = 0.049941138752691495
Trained batch 438 in epoch 7, gen_loss = 0.8318296142075219, disc_loss = 0.04984115102463073
Trained batch 439 in epoch 7, gen_loss = 0.8317003605717962, disc_loss = 0.049833267886159854
Trained batch 440 in epoch 7, gen_loss = 0.8315065805198384, disc_loss = 0.04975418055186137
Trained batch 441 in epoch 7, gen_loss = 0.8311013321126748, disc_loss = 0.049894516484030184
Trained batch 442 in epoch 7, gen_loss = 0.8311863493838644, disc_loss = 0.04981008297043724
Trained batch 443 in epoch 7, gen_loss = 0.8307198153825494, disc_loss = 0.04998882011398212
Trained batch 444 in epoch 7, gen_loss = 0.8303288365348002, disc_loss = 0.050081579459653226
Trained batch 445 in epoch 7, gen_loss = 0.8312521544138947, disc_loss = 0.05037600622797435
Trained batch 446 in epoch 7, gen_loss = 0.8314975770127854, disc_loss = 0.05029111109404164
Trained batch 447 in epoch 7, gen_loss = 0.8308717186030533, disc_loss = 0.05046418457771194
Trained batch 448 in epoch 7, gen_loss = 0.830901580756916, disc_loss = 0.05038188634267106
Trained batch 449 in epoch 7, gen_loss = 0.830732957985666, disc_loss = 0.050347894810191876
Trained batch 450 in epoch 7, gen_loss = 0.8305955434717783, disc_loss = 0.05027182783829275
Trained batch 451 in epoch 7, gen_loss = 0.8305840942580088, disc_loss = 0.0502896937451519
Trained batch 452 in epoch 7, gen_loss = 0.8305937843212229, disc_loss = 0.050368458200420844
Trained batch 453 in epoch 7, gen_loss = 0.8302459613735981, disc_loss = 0.05038836118708763
Trained batch 454 in epoch 7, gen_loss = 0.8297274013797006, disc_loss = 0.05051343083550519
Trained batch 455 in epoch 7, gen_loss = 0.8303479649649378, disc_loss = 0.05056177794840391
Trained batch 456 in epoch 7, gen_loss = 0.830689168276359, disc_loss = 0.05051771481597849
Trained batch 457 in epoch 7, gen_loss = 0.8300234882982537, disc_loss = 0.05060403005399957
Trained batch 458 in epoch 7, gen_loss = 0.8301361055805273, disc_loss = 0.050552545723298356
Trained batch 459 in epoch 7, gen_loss = 0.8309036640369374, disc_loss = 0.05052049721555744
Trained batch 460 in epoch 7, gen_loss = 0.8309000008406194, disc_loss = 0.05044488433810101
Trained batch 461 in epoch 7, gen_loss = 0.83046332072644, disc_loss = 0.05051832426328301
Trained batch 462 in epoch 7, gen_loss = 0.8300261705405769, disc_loss = 0.05056652775437613
Trained batch 463 in epoch 7, gen_loss = 0.8305057140131449, disc_loss = 0.051008592531584795
Trained batch 464 in epoch 7, gen_loss = 0.8306230432884667, disc_loss = 0.05091700803173045
Trained batch 465 in epoch 7, gen_loss = 0.8303501752441022, disc_loss = 0.050892977716746966
Trained batch 466 in epoch 7, gen_loss = 0.8297325627323903, disc_loss = 0.05098390184483457
Trained batch 467 in epoch 7, gen_loss = 0.8297882084535737, disc_loss = 0.051000196830236204
Trained batch 468 in epoch 7, gen_loss = 0.8299525519296813, disc_loss = 0.05095600073204946
Trained batch 469 in epoch 7, gen_loss = 0.8297186743071738, disc_loss = 0.0508919735748737
Trained batch 470 in epoch 7, gen_loss = 0.8293072370586881, disc_loss = 0.05168693095585035
Trained batch 471 in epoch 7, gen_loss = 0.828885459609456, disc_loss = 0.05170214220105031
Trained batch 472 in epoch 7, gen_loss = 0.8286568378167223, disc_loss = 0.05169406605428616
Trained batch 473 in epoch 7, gen_loss = 0.8288162461941755, disc_loss = 0.0516091327309188
Trained batch 474 in epoch 7, gen_loss = 0.8286097327659004, disc_loss = 0.05160318833555242
Trained batch 475 in epoch 7, gen_loss = 0.8288208101602161, disc_loss = 0.05168000212014543
Trained batch 476 in epoch 7, gen_loss = 0.8280981407350464, disc_loss = 0.05195148499410178
Trained batch 477 in epoch 7, gen_loss = 0.8277810750271984, disc_loss = 0.0519307133633055
Trained batch 478 in epoch 7, gen_loss = 0.8276979549319361, disc_loss = 0.05193644993921979
Trained batch 479 in epoch 7, gen_loss = 0.8272439926241835, disc_loss = 0.05217885792687108
Trained batch 480 in epoch 7, gen_loss = 0.8268625627808165, disc_loss = 0.052214722841515314
Trained batch 481 in epoch 7, gen_loss = 0.8275604453942588, disc_loss = 0.052562999868759674
Trained batch 482 in epoch 7, gen_loss = 0.8275461506029094, disc_loss = 0.0524804858313912
Trained batch 483 in epoch 7, gen_loss = 0.8270709361296055, disc_loss = 0.052543695809460084
Trained batch 484 in epoch 7, gen_loss = 0.8267034235074348, disc_loss = 0.05253556625864747
Trained batch 485 in epoch 7, gen_loss = 0.8267876321273576, disc_loss = 0.0524441409760745
Trained batch 486 in epoch 7, gen_loss = 0.8271481451679794, disc_loss = 0.05237160234600191
Trained batch 487 in epoch 7, gen_loss = 0.8273242351095207, disc_loss = 0.05230865021523462
Trained batch 488 in epoch 7, gen_loss = 0.8271269926873697, disc_loss = 0.05228141565109148
Trained batch 489 in epoch 7, gen_loss = 0.8267706276810899, disc_loss = 0.052285732930687695
Trained batch 490 in epoch 7, gen_loss = 0.8271861180147183, disc_loss = 0.05275555154666221
Trained batch 491 in epoch 7, gen_loss = 0.8264411621825482, disc_loss = 0.05312218725405883
Trained batch 492 in epoch 7, gen_loss = 0.8263651937185872, disc_loss = 0.05312095355156537
Trained batch 493 in epoch 7, gen_loss = 0.8267719281709146, disc_loss = 0.05305793321986498
Trained batch 494 in epoch 7, gen_loss = 0.8267416786063801, disc_loss = 0.05327355207033418
Trained batch 495 in epoch 7, gen_loss = 0.8264688409023708, disc_loss = 0.05337151967767333
Trained batch 496 in epoch 7, gen_loss = 0.8260302598207769, disc_loss = 0.05344891104537064
Trained batch 497 in epoch 7, gen_loss = 0.8255820601699821, disc_loss = 0.05352029071332528
Trained batch 498 in epoch 7, gen_loss = 0.8257567731435886, disc_loss = 0.05352232610561394
Trained batch 499 in epoch 7, gen_loss = 0.8258359908461571, disc_loss = 0.05345998207596131
Trained batch 500 in epoch 7, gen_loss = 0.8258470522310444, disc_loss = 0.05338821115605198
Trained batch 501 in epoch 7, gen_loss = 0.8258189413533268, disc_loss = 0.053319409060379144
Trained batch 502 in epoch 7, gen_loss = 0.8256252089859714, disc_loss = 0.053262067334050645
Trained batch 503 in epoch 7, gen_loss = 0.825751744506378, disc_loss = 0.05325558610257715
Trained batch 504 in epoch 7, gen_loss = 0.8256207850309882, disc_loss = 0.053195742957782705
Trained batch 505 in epoch 7, gen_loss = 0.8256037086248398, disc_loss = 0.05310410039205833
Trained batch 506 in epoch 7, gen_loss = 0.8253271282894842, disc_loss = 0.05319845488711023
Trained batch 507 in epoch 7, gen_loss = 0.8258093266388563, disc_loss = 0.05317841630495945
Trained batch 508 in epoch 7, gen_loss = 0.8257302408251173, disc_loss = 0.053087158030043546
Trained batch 509 in epoch 7, gen_loss = 0.8256785221543966, disc_loss = 0.05302141473158354
Trained batch 510 in epoch 7, gen_loss = 0.8256388489164251, disc_loss = 0.052948159300776856
Trained batch 511 in epoch 7, gen_loss = 0.8258543585543521, disc_loss = 0.052870296336777756
Trained batch 512 in epoch 7, gen_loss = 0.8257676921276553, disc_loss = 0.052805166468469035
Trained batch 513 in epoch 7, gen_loss = 0.8257899491355577, disc_loss = 0.052713905629866796
Trained batch 514 in epoch 7, gen_loss = 0.8256249523278579, disc_loss = 0.0530004724555025
Trained batch 515 in epoch 7, gen_loss = 0.8255075517204381, disc_loss = 0.05292834370607301
Trained batch 516 in epoch 7, gen_loss = 0.8256005012435654, disc_loss = 0.05284352731378479
Trained batch 517 in epoch 7, gen_loss = 0.8249887113520538, disc_loss = 0.05289558059123298
Trained batch 518 in epoch 7, gen_loss = 0.8247355239354577, disc_loss = 0.05291613442253551
Trained batch 519 in epoch 7, gen_loss = 0.825511078708447, disc_loss = 0.05296287805652425
Trained batch 520 in epoch 7, gen_loss = 0.8259187591853846, disc_loss = 0.05290576516388738
Trained batch 521 in epoch 7, gen_loss = 0.8260113679700427, disc_loss = 0.05283931470801697
Trained batch 522 in epoch 7, gen_loss = 0.8258858931110192, disc_loss = 0.05282265602510394
Trained batch 523 in epoch 7, gen_loss = 0.8252311225497085, disc_loss = 0.05293520697137476
Trained batch 524 in epoch 7, gen_loss = 0.8251297907034556, disc_loss = 0.053561627957304674
Trained batch 525 in epoch 7, gen_loss = 0.8254083718523779, disc_loss = 0.05350295887722637
Trained batch 526 in epoch 7, gen_loss = 0.8253581516543648, disc_loss = 0.05344660507371045
Trained batch 527 in epoch 7, gen_loss = 0.825181892367475, disc_loss = 0.053428684537886344
Trained batch 528 in epoch 7, gen_loss = 0.8251318016101823, disc_loss = 0.05339097471785378
Trained batch 529 in epoch 7, gen_loss = 0.8250922159766251, disc_loss = 0.05333473105005533
Trained batch 530 in epoch 7, gen_loss = 0.8254332658597978, disc_loss = 0.053255006180078196
Trained batch 531 in epoch 7, gen_loss = 0.8259271651618463, disc_loss = 0.05318903013441494
Trained batch 532 in epoch 7, gen_loss = 0.8260167374731676, disc_loss = 0.0531338951491452
Trained batch 533 in epoch 7, gen_loss = 0.8261443410584989, disc_loss = 0.0530595481833914
Trained batch 534 in epoch 7, gen_loss = 0.8258276763920472, disc_loss = 0.052993336360179166
Trained batch 535 in epoch 7, gen_loss = 0.8258651822471796, disc_loss = 0.05291304704859165
Trained batch 536 in epoch 7, gen_loss = 0.8261139433366183, disc_loss = 0.05282947477460553
Trained batch 537 in epoch 7, gen_loss = 0.8259810462427848, disc_loss = 0.05302343216528216
Trained batch 538 in epoch 7, gen_loss = 0.8259954019579242, disc_loss = 0.05295436893108583
Trained batch 539 in epoch 7, gen_loss = 0.8255914366355649, disc_loss = 0.052987134996672264
Trained batch 540 in epoch 7, gen_loss = 0.8260401423999871, disc_loss = 0.052907632676111586
Trained batch 541 in epoch 7, gen_loss = 0.8265513527547301, disc_loss = 0.052846203422615465
Trained batch 542 in epoch 7, gen_loss = 0.8267782955648271, disc_loss = 0.05276297814102113
Trained batch 543 in epoch 7, gen_loss = 0.8268027290811434, disc_loss = 0.05269670211354798
Trained batch 544 in epoch 7, gen_loss = 0.8270539478971324, disc_loss = 0.05261162355085066
Trained batch 545 in epoch 7, gen_loss = 0.8272721912070509, disc_loss = 0.05254203344174173
Trained batch 546 in epoch 7, gen_loss = 0.8276085034693835, disc_loss = 0.05245533797628599
Trained batch 547 in epoch 7, gen_loss = 0.8279462183152673, disc_loss = 0.052375451805466024
Trained batch 548 in epoch 7, gen_loss = 0.8279994576897994, disc_loss = 0.052296994173626175
Trained batch 549 in epoch 7, gen_loss = 0.8281964457576925, disc_loss = 0.05221351383867758
Trained batch 550 in epoch 7, gen_loss = 0.8283215112673176, disc_loss = 0.05213365970815814
Trained batch 551 in epoch 7, gen_loss = 0.8287282165517842, disc_loss = 0.05204795718220893
Trained batch 552 in epoch 7, gen_loss = 0.8289108495707969, disc_loss = 0.05196081212183686
Trained batch 553 in epoch 7, gen_loss = 0.829097276291262, disc_loss = 0.051897658998212214
Trained batch 554 in epoch 7, gen_loss = 0.8290637907144186, disc_loss = 0.05185782225563417
Trained batch 555 in epoch 7, gen_loss = 0.8293445022950927, disc_loss = 0.0517828181089093
Trained batch 556 in epoch 7, gen_loss = 0.829869382738853, disc_loss = 0.05172418637758813
Trained batch 557 in epoch 7, gen_loss = 0.8299748810495527, disc_loss = 0.05164825936297863
Trained batch 558 in epoch 7, gen_loss = 0.8301853346163557, disc_loss = 0.051588818610625836
Trained batch 559 in epoch 7, gen_loss = 0.83007276670209, disc_loss = 0.051570673373186895
Trained batch 560 in epoch 7, gen_loss = 0.8303222955335695, disc_loss = 0.051487789040061176
Trained batch 561 in epoch 7, gen_loss = 0.8308238475666352, disc_loss = 0.05151822694119072
Trained batch 562 in epoch 7, gen_loss = 0.8304119007943155, disc_loss = 0.05161091072967054
Trained batch 563 in epoch 7, gen_loss = 0.8303682985352286, disc_loss = 0.05159069923085412
Trained batch 564 in epoch 7, gen_loss = 0.8309310669920086, disc_loss = 0.05157582339587564
Trained batch 565 in epoch 7, gen_loss = 0.831481016303541, disc_loss = 0.05154432290930518
Trained batch 566 in epoch 7, gen_loss = 0.8313431461757242, disc_loss = 0.0515200701931071
Trained batch 567 in epoch 7, gen_loss = 0.8312374014984554, disc_loss = 0.051460536623752384
Trained batch 568 in epoch 7, gen_loss = 0.8317279303953811, disc_loss = 0.051390621229074895
Trained batch 569 in epoch 7, gen_loss = 0.8320398758900793, disc_loss = 0.051331878173075156
Trained batch 570 in epoch 7, gen_loss = 0.8320835693600717, disc_loss = 0.051256073831870905
Trained batch 571 in epoch 7, gen_loss = 0.8322637546416762, disc_loss = 0.051197671853095435
Trained batch 572 in epoch 7, gen_loss = 0.832384193702934, disc_loss = 0.05119777454634605
Trained batch 573 in epoch 7, gen_loss = 0.8318073526803624, disc_loss = 0.0513100333790496
Trained batch 574 in epoch 7, gen_loss = 0.8318388438743094, disc_loss = 0.051262944237653006
Trained batch 575 in epoch 7, gen_loss = 0.8320193159807887, disc_loss = 0.05136858560722936
Trained batch 576 in epoch 7, gen_loss = 0.831852627327372, disc_loss = 0.051329697100356855
Trained batch 577 in epoch 7, gen_loss = 0.8317594325563075, disc_loss = 0.05130579767673789
Trained batch 578 in epoch 7, gen_loss = 0.8318735896923382, disc_loss = 0.05123153689742854
Trained batch 579 in epoch 7, gen_loss = 0.8319994986571114, disc_loss = 0.0511572461067458
Trained batch 580 in epoch 7, gen_loss = 0.8321989155574838, disc_loss = 0.051081094548399535
Trained batch 581 in epoch 7, gen_loss = 0.8316822107817299, disc_loss = 0.05119388305747728
Trained batch 582 in epoch 7, gen_loss = 0.8322214958087044, disc_loss = 0.051344558095605806
Trained batch 583 in epoch 7, gen_loss = 0.8320777199345909, disc_loss = 0.05131770615933992
Trained batch 584 in epoch 7, gen_loss = 0.8323268878663707, disc_loss = 0.05127270352632667
Trained batch 585 in epoch 7, gen_loss = 0.8326726198298126, disc_loss = 0.05120413763501837
Trained batch 586 in epoch 7, gen_loss = 0.8327901391296614, disc_loss = 0.051125196291624014
Trained batch 587 in epoch 7, gen_loss = 0.8329510929531792, disc_loss = 0.05104887714909649
Trained batch 588 in epoch 7, gen_loss = 0.8332023940891887, disc_loss = 0.05098525612201567
Trained batch 589 in epoch 7, gen_loss = 0.8331207289028976, disc_loss = 0.050905726560967646
Trained batch 590 in epoch 7, gen_loss = 0.832916473323722, disc_loss = 0.05087319532840303
Trained batch 591 in epoch 7, gen_loss = 0.8330036762699082, disc_loss = 0.05079897253823662
Trained batch 592 in epoch 7, gen_loss = 0.8328206025026299, disc_loss = 0.05073375382533683
Trained batch 593 in epoch 7, gen_loss = 0.83300005170432, disc_loss = 0.05066659020848716
Trained batch 594 in epoch 7, gen_loss = 0.8332940370595756, disc_loss = 0.05060748279294265
Trained batch 595 in epoch 7, gen_loss = 0.8332532302745237, disc_loss = 0.05053105711254866
Trained batch 596 in epoch 7, gen_loss = 0.8331078231534367, disc_loss = 0.05049380809485981
Trained batch 597 in epoch 7, gen_loss = 0.8328328294598538, disc_loss = 0.05050778748715969
Trained batch 598 in epoch 7, gen_loss = 0.8328584301750329, disc_loss = 0.05045618503980295
Trained batch 599 in epoch 7, gen_loss = 0.8334576039016247, disc_loss = 0.050498533413240995
Trained batch 600 in epoch 7, gen_loss = 0.8338044886283589, disc_loss = 0.05046846437095176
Trained batch 601 in epoch 7, gen_loss = 0.8340312563798752, disc_loss = 0.05039405178389299
Trained batch 602 in epoch 7, gen_loss = 0.8339774377804688, disc_loss = 0.05032735231589637
Trained batch 603 in epoch 7, gen_loss = 0.8338955633391608, disc_loss = 0.05025429621671129
Trained batch 604 in epoch 7, gen_loss = 0.8338240574706685, disc_loss = 0.050179858682561695
Trained batch 605 in epoch 7, gen_loss = 0.8339533373565957, disc_loss = 0.05010222968097512
Trained batch 606 in epoch 7, gen_loss = 0.8340858490600618, disc_loss = 0.05002514486714332
Trained batch 607 in epoch 7, gen_loss = 0.8341622629546022, disc_loss = 0.049949870898815696
Trained batch 608 in epoch 7, gen_loss = 0.8343185646878479, disc_loss = 0.049944941248639206
Trained batch 609 in epoch 7, gen_loss = 0.8342488725165852, disc_loss = 0.04987086855756791
Trained batch 610 in epoch 7, gen_loss = 0.8342737037987249, disc_loss = 0.049794573556142516
Trained batch 611 in epoch 7, gen_loss = 0.8340990637349927, disc_loss = 0.04971903125893209
Trained batch 612 in epoch 7, gen_loss = 0.8340849849664368, disc_loss = 0.049642076166794856
Trained batch 613 in epoch 7, gen_loss = 0.8343700429224424, disc_loss = 0.0495687501396186
Trained batch 614 in epoch 7, gen_loss = 0.8343091967144632, disc_loss = 0.04949339527837417
Trained batch 615 in epoch 7, gen_loss = 0.834276584884176, disc_loss = 0.04942103652997916
Trained batch 616 in epoch 7, gen_loss = 0.834277834894205, disc_loss = 0.04934692759700029
Trained batch 617 in epoch 7, gen_loss = 0.8342725604193882, disc_loss = 0.04928016182902483
Trained batch 618 in epoch 7, gen_loss = 0.8343158948305928, disc_loss = 0.049211969517693466
Trained batch 619 in epoch 7, gen_loss = 0.8343827013527193, disc_loss = 0.04914153847644376
Trained batch 620 in epoch 7, gen_loss = 0.8345759314711351, disc_loss = 0.04906900818313467
Trained batch 621 in epoch 7, gen_loss = 0.8346587124840623, disc_loss = 0.04899342045681312
Trained batch 622 in epoch 7, gen_loss = 0.8347170910234436, disc_loss = 0.048925043656087124
Trained batch 623 in epoch 7, gen_loss = 0.8347702661099342, disc_loss = 0.048852125539269764
Trained batch 624 in epoch 7, gen_loss = 0.8348687524318695, disc_loss = 0.048778294370509685
Trained batch 625 in epoch 7, gen_loss = 0.8349507362983478, disc_loss = 0.04870349614038177
Trained batch 626 in epoch 7, gen_loss = 0.8349877611586922, disc_loss = 0.048631872707922935
Trained batch 627 in epoch 7, gen_loss = 0.8350382239860334, disc_loss = 0.04856460918335001
Trained batch 628 in epoch 7, gen_loss = 0.8351084328891742, disc_loss = 0.04849252691185205
Trained batch 629 in epoch 7, gen_loss = 0.8353035710633747, disc_loss = 0.04842056047951152
Trained batch 630 in epoch 7, gen_loss = 0.8353405216511003, disc_loss = 0.04834893069221902
Trained batch 631 in epoch 7, gen_loss = 0.8354665775182126, disc_loss = 0.048276219267768
Trained batch 632 in epoch 7, gen_loss = 0.8355480734300086, disc_loss = 0.04820509652822686
Trained batch 633 in epoch 7, gen_loss = 0.8356847374315142, disc_loss = 0.04813774368392997
Trained batch 634 in epoch 7, gen_loss = 0.8356753880114067, disc_loss = 0.04807276138284163
Trained batch 635 in epoch 7, gen_loss = 0.8357708569873804, disc_loss = 0.04803030836339542
Trained batch 636 in epoch 7, gen_loss = 0.8356159563809399, disc_loss = 0.04796714781219903
Trained batch 637 in epoch 7, gen_loss = 0.8355723891792626, disc_loss = 0.04790851340295607
Trained batch 638 in epoch 7, gen_loss = 0.8357421793568303, disc_loss = 0.04784047103750028
Trained batch 639 in epoch 7, gen_loss = 0.8359689525794238, disc_loss = 0.04777059268762969
Trained batch 640 in epoch 7, gen_loss = 0.836011573184113, disc_loss = 0.047713743113947514
Trained batch 641 in epoch 7, gen_loss = 0.8361115481159026, disc_loss = 0.04766046438845617
Trained batch 642 in epoch 7, gen_loss = 0.8361361130121893, disc_loss = 0.047605532672854424
Trained batch 643 in epoch 7, gen_loss = 0.8361174636838599, disc_loss = 0.04753684194600181
Trained batch 644 in epoch 7, gen_loss = 0.8361510431581689, disc_loss = 0.047471253291790395
Trained batch 645 in epoch 7, gen_loss = 0.8362448060014299, disc_loss = 0.04740216030869719
Trained batch 646 in epoch 7, gen_loss = 0.8362689919689155, disc_loss = 0.04733249408115922
Trained batch 647 in epoch 7, gen_loss = 0.8362662829458714, disc_loss = 0.04726631648857923
Trained batch 648 in epoch 7, gen_loss = 0.8363128461988387, disc_loss = 0.04719899570406522
Trained batch 649 in epoch 7, gen_loss = 0.8364236170053482, disc_loss = 0.04713445699218517
Trained batch 650 in epoch 7, gen_loss = 0.8363463880920556, disc_loss = 0.04706621694163249
Trained batch 651 in epoch 7, gen_loss = 0.8363586286185709, disc_loss = 0.046996634454070735
Trained batch 652 in epoch 7, gen_loss = 0.8363082882182339, disc_loss = 0.04692862495501165
Trained batch 653 in epoch 7, gen_loss = 0.8363788699793888, disc_loss = 0.04686360617701551
Trained batch 654 in epoch 7, gen_loss = 0.8365077293101157, disc_loss = 0.04679467015853507
Trained batch 655 in epoch 7, gen_loss = 0.8366119365048844, disc_loss = 0.04672997877539119
Trained batch 656 in epoch 7, gen_loss = 0.8366932858524438, disc_loss = 0.04666182894526897
Trained batch 657 in epoch 7, gen_loss = 0.8367693947350725, disc_loss = 0.04659634903954387
Trained batch 658 in epoch 7, gen_loss = 0.8368445668759584, disc_loss = 0.04652867258659936
Trained batch 659 in epoch 7, gen_loss = 0.8368928064451073, disc_loss = 0.04646179027710759
Trained batch 660 in epoch 7, gen_loss = 0.8369743360964506, disc_loss = 0.04639858030238571
Trained batch 661 in epoch 7, gen_loss = 0.8369412758469221, disc_loss = 0.04633081600817731
Trained batch 662 in epoch 7, gen_loss = 0.8369844469099922, disc_loss = 0.046266692643669095
Trained batch 663 in epoch 7, gen_loss = 0.8370525783533791, disc_loss = 0.04620056989738095
Trained batch 664 in epoch 7, gen_loss = 0.8371379833024247, disc_loss = 0.04613705196442377
Trained batch 665 in epoch 7, gen_loss = 0.8372471352686753, disc_loss = 0.04607039584754477
Trained batch 666 in epoch 7, gen_loss = 0.8373159704984039, disc_loss = 0.046003825426544305
Trained batch 667 in epoch 7, gen_loss = 0.8374131967475315, disc_loss = 0.045942176595744316
Trained batch 668 in epoch 7, gen_loss = 0.8374973417486667, disc_loss = 0.04587564342575195
Trained batch 669 in epoch 7, gen_loss = 0.8376617402727924, disc_loss = 0.045811014643126625
Trained batch 670 in epoch 7, gen_loss = 0.8376810248224995, disc_loss = 0.0457482339018656
Trained batch 671 in epoch 7, gen_loss = 0.837745195476427, disc_loss = 0.04568297167636393
Trained batch 672 in epoch 7, gen_loss = 0.8377879412974858, disc_loss = 0.04561971906551131
Trained batch 673 in epoch 7, gen_loss = 0.8378241155462378, disc_loss = 0.045554182808279706
Trained batch 674 in epoch 7, gen_loss = 0.8378211697384164, disc_loss = 0.04549162711603222
Trained batch 675 in epoch 7, gen_loss = 0.837718940301407, disc_loss = 0.045426040291979074
Trained batch 676 in epoch 7, gen_loss = 0.8378235046673385, disc_loss = 0.045362299352201964
Trained batch 677 in epoch 7, gen_loss = 0.8377773541528567, disc_loss = 0.04529944961446895
Trained batch 678 in epoch 7, gen_loss = 0.8377973501829757, disc_loss = 0.04523660803374194
Trained batch 679 in epoch 7, gen_loss = 0.8378502932103241, disc_loss = 0.04517429275814827
Trained batch 680 in epoch 7, gen_loss = 0.8379392963936676, disc_loss = 0.04511185866615102
Trained batch 681 in epoch 7, gen_loss = 0.8381354963936763, disc_loss = 0.045050258559101095
Trained batch 682 in epoch 7, gen_loss = 0.8382354318048385, disc_loss = 0.04499192935336888
Trained batch 683 in epoch 7, gen_loss = 0.8381890795297093, disc_loss = 0.044932854389063796
Trained batch 684 in epoch 7, gen_loss = 0.8383825912527795, disc_loss = 0.04487222971217911
Trained batch 685 in epoch 7, gen_loss = 0.8383488569506403, disc_loss = 0.0448106229060897
Trained batch 686 in epoch 7, gen_loss = 0.8383462390438091, disc_loss = 0.04474885280893402
Trained batch 687 in epoch 7, gen_loss = 0.8383832760588374, disc_loss = 0.0446870113312819
Trained batch 688 in epoch 7, gen_loss = 0.8383823928621926, disc_loss = 0.044625983230839925
Trained batch 689 in epoch 7, gen_loss = 0.8384818615688794, disc_loss = 0.04456353918278077
Trained batch 690 in epoch 7, gen_loss = 0.8386924007608301, disc_loss = 0.044504433622659226
Trained batch 691 in epoch 7, gen_loss = 0.8387879258549282, disc_loss = 0.0444423726351388
Trained batch 692 in epoch 7, gen_loss = 0.8389099748189659, disc_loss = 0.044382281575558916
Trained batch 693 in epoch 7, gen_loss = 0.8390368307787678, disc_loss = 0.044320755890639024
Trained batch 694 in epoch 7, gen_loss = 0.8391522748436001, disc_loss = 0.04426089909359839
Trained batch 695 in epoch 7, gen_loss = 0.8390887933301514, disc_loss = 0.04420113515248656
Trained batch 696 in epoch 7, gen_loss = 0.8391283201093824, disc_loss = 0.04413998706922352
Trained batch 697 in epoch 7, gen_loss = 0.8390859039687154, disc_loss = 0.04407913497693164
Trained batch 698 in epoch 7, gen_loss = 0.839142194164328, disc_loss = 0.044023162485813144
Trained batch 699 in epoch 7, gen_loss = 0.8392267271876335, disc_loss = 0.04397006529682715
Trained batch 700 in epoch 7, gen_loss = 0.8392657700091728, disc_loss = 0.04390909786209246
Trained batch 701 in epoch 7, gen_loss = 0.8393192129512118, disc_loss = 0.04384944165749688
Trained batch 702 in epoch 7, gen_loss = 0.8394816813309535, disc_loss = 0.04379442026312059
Trained batch 703 in epoch 7, gen_loss = 0.839645212135193, disc_loss = 0.04373503186682435
Trained batch 704 in epoch 7, gen_loss = 0.83960306225939, disc_loss = 0.0436763722748423
Trained batch 705 in epoch 7, gen_loss = 0.8396269204174155, disc_loss = 0.0436176457077927
Trained batch 706 in epoch 7, gen_loss = 0.8397287276627488, disc_loss = 0.04355761762547058
Trained batch 707 in epoch 7, gen_loss = 0.8399358595074233, disc_loss = 0.04349880160630344
Trained batch 708 in epoch 7, gen_loss = 0.8400020576246366, disc_loss = 0.04343956773864218
Trained batch 709 in epoch 7, gen_loss = 0.8400107935700618, disc_loss = 0.043380585354326526
Trained batch 710 in epoch 7, gen_loss = 0.8400506950212766, disc_loss = 0.043323538096657
Trained batch 711 in epoch 7, gen_loss = 0.8401303465865301, disc_loss = 0.04327102325640206
Trained batch 712 in epoch 7, gen_loss = 0.8401388246330941, disc_loss = 0.04321475159935261
Trained batch 713 in epoch 7, gen_loss = 0.8401659063013995, disc_loss = 0.043156419085183494
Trained batch 714 in epoch 7, gen_loss = 0.8401579097851173, disc_loss = 0.04309802024081427
Trained batch 715 in epoch 7, gen_loss = 0.8403212220392413, disc_loss = 0.043040982104659696
Trained batch 716 in epoch 7, gen_loss = 0.8404329435346516, disc_loss = 0.042983256445384505
Trained batch 717 in epoch 7, gen_loss = 0.8404593738755808, disc_loss = 0.04292775575729206
Trained batch 718 in epoch 7, gen_loss = 0.8405125053684966, disc_loss = 0.04287025403724893
Trained batch 719 in epoch 7, gen_loss = 0.8405540095021328, disc_loss = 0.042814278135968685
Trained batch 720 in epoch 7, gen_loss = 0.8406611181247913, disc_loss = 0.04275723132815073
Trained batch 721 in epoch 7, gen_loss = 0.8407264014607981, disc_loss = 0.04269967465229343
Trained batch 722 in epoch 7, gen_loss = 0.8406551207002267, disc_loss = 0.04264901275553304
Trained batch 723 in epoch 7, gen_loss = 0.8406761055246242, disc_loss = 0.04259361391173141
Trained batch 724 in epoch 7, gen_loss = 0.8407599548224746, disc_loss = 0.042538220473597274
Trained batch 725 in epoch 7, gen_loss = 0.8408295115245603, disc_loss = 0.04248184512931207
Trained batch 726 in epoch 7, gen_loss = 0.8408504387125516, disc_loss = 0.04242525403029151
Trained batch 727 in epoch 7, gen_loss = 0.8409826220473745, disc_loss = 0.042368513191532044
Trained batch 728 in epoch 7, gen_loss = 0.8410470867107925, disc_loss = 0.042312918776398416
Trained batch 729 in epoch 7, gen_loss = 0.8411057187678063, disc_loss = 0.04225921830583415
Trained batch 730 in epoch 7, gen_loss = 0.8410284910172673, disc_loss = 0.04220320722604204
Trained batch 731 in epoch 7, gen_loss = 0.8411260740271683, disc_loss = 0.042153390839790084
Trained batch 732 in epoch 7, gen_loss = 0.8411274954453009, disc_loss = 0.042098450128371497
Trained batch 733 in epoch 7, gen_loss = 0.8412863252841809, disc_loss = 0.04204285419555584
Trained batch 734 in epoch 7, gen_loss = 0.8414006358506728, disc_loss = 0.04198766191898636
Trained batch 735 in epoch 7, gen_loss = 0.8414711513678017, disc_loss = 0.0419326806021791
Trained batch 736 in epoch 7, gen_loss = 0.8415322262121508, disc_loss = 0.04187808749964145
Trained batch 737 in epoch 7, gen_loss = 0.8416477589184029, disc_loss = 0.04182679149707739
Trained batch 738 in epoch 7, gen_loss = 0.8416712981357626, disc_loss = 0.04177186719103463
Trained batch 739 in epoch 7, gen_loss = 0.8417694978214599, disc_loss = 0.04171779008308501
Trained batch 740 in epoch 7, gen_loss = 0.8418197855856093, disc_loss = 0.04166583748966048
Trained batch 741 in epoch 7, gen_loss = 0.8418891578109438, disc_loss = 0.04161230930754152
Trained batch 742 in epoch 7, gen_loss = 0.8419655711060418, disc_loss = 0.0415583510153324
Trained batch 743 in epoch 7, gen_loss = 0.842070531340376, disc_loss = 0.041504354787907836
Trained batch 744 in epoch 7, gen_loss = 0.8421273268709246, disc_loss = 0.041450050915278897
Trained batch 745 in epoch 7, gen_loss = 0.8422890094186282, disc_loss = 0.0413971526022993
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9627474546432495, disc_loss = 0.0025163586251437664
Trained batch 1 in epoch 8, gen_loss = 0.9138073921203613, disc_loss = 0.0020644990727305412
Trained batch 2 in epoch 8, gen_loss = 0.9027391672134399, disc_loss = 0.0018215651313463848
Trained batch 3 in epoch 8, gen_loss = 0.8903395533561707, disc_loss = 0.001698419509921223
Trained batch 4 in epoch 8, gen_loss = 0.8869343638420105, disc_loss = 0.0026707418728619814
Trained batch 5 in epoch 8, gen_loss = 0.8859454095363617, disc_loss = 0.002683345810510218
Trained batch 6 in epoch 8, gen_loss = 0.8978572658130101, disc_loss = 0.002696172899699637
Trained batch 7 in epoch 8, gen_loss = 0.8982790932059288, disc_loss = 0.002489037753548473
Trained batch 8 in epoch 8, gen_loss = 0.9010410772429572, disc_loss = 0.002363428576952881
Trained batch 9 in epoch 8, gen_loss = 0.905012583732605, disc_loss = 0.0022668695077300073
Trained batch 10 in epoch 8, gen_loss = 0.9055348255417563, disc_loss = 0.002196254928342321
Trained batch 11 in epoch 8, gen_loss = 0.8981195141871771, disc_loss = 0.0022466833664414785
Trained batch 12 in epoch 8, gen_loss = 0.896642606991988, disc_loss = 0.0021685261834556093
Trained batch 13 in epoch 8, gen_loss = 0.8910305542605264, disc_loss = 0.0022391644389634685
Trained batch 14 in epoch 8, gen_loss = 0.8962050636609395, disc_loss = 0.002223969165546199
Trained batch 15 in epoch 8, gen_loss = 0.9006974510848522, disc_loss = 0.00251347560697468
Trained batch 16 in epoch 8, gen_loss = 0.8961799039560205, disc_loss = 0.002469391870202825
Trained batch 17 in epoch 8, gen_loss = 0.8969724078973135, disc_loss = 0.0025592863676138222
Trained batch 18 in epoch 8, gen_loss = 0.8974472754880002, disc_loss = 0.0025195847265422344
Trained batch 19 in epoch 8, gen_loss = 0.8976803302764893, disc_loss = 0.0024754271842539312
Trained batch 20 in epoch 8, gen_loss = 0.8947332643327259, disc_loss = 0.002480482394319205
Trained batch 21 in epoch 8, gen_loss = 0.8959347957914526, disc_loss = 0.0024707865245132284
Trained batch 22 in epoch 8, gen_loss = 0.8965134491091189, disc_loss = 0.0024175745050382356
Trained batch 23 in epoch 8, gen_loss = 0.8981393252809843, disc_loss = 0.002384471352949428
Trained batch 24 in epoch 8, gen_loss = 0.8983174037933349, disc_loss = 0.0023348198225721715
Trained batch 25 in epoch 8, gen_loss = 0.8965487434313848, disc_loss = 0.002311335800466343
Trained batch 26 in epoch 8, gen_loss = 0.8959578143225776, disc_loss = 0.0023153454401633805
Trained batch 27 in epoch 8, gen_loss = 0.8964016352381025, disc_loss = 0.002283162682683074
Trained batch 28 in epoch 8, gen_loss = 0.8954071258676464, disc_loss = 0.003181970240708826
Trained batch 29 in epoch 8, gen_loss = 0.8933759649594625, disc_loss = 0.0031739829302144546
Trained batch 30 in epoch 8, gen_loss = 0.8891554340239494, disc_loss = 0.003147861413327196
Trained batch 31 in epoch 8, gen_loss = 0.8888143487274647, disc_loss = 0.0031999941893445794
Trained batch 32 in epoch 8, gen_loss = 0.8894529631643584, disc_loss = 0.0031591400144283066
Trained batch 33 in epoch 8, gen_loss = 0.8896943541134105, disc_loss = 0.003106823286918156
Trained batch 34 in epoch 8, gen_loss = 0.8911756770951408, disc_loss = 0.0030779275843607528
Trained batch 35 in epoch 8, gen_loss = 0.894805423087544, disc_loss = 0.0030584190390072763
Trained batch 36 in epoch 8, gen_loss = 0.8958515186567564, disc_loss = 0.0030233345806246273
Trained batch 37 in epoch 8, gen_loss = 0.8942223363801053, disc_loss = 0.0029997972949211927
Trained batch 38 in epoch 8, gen_loss = 0.8940618206293155, disc_loss = 0.0029523939145012544
Trained batch 39 in epoch 8, gen_loss = 0.8950201109051704, disc_loss = 0.003001336642773822
Trained batch 40 in epoch 8, gen_loss = 0.893793267447774, disc_loss = 0.002973867793249466
Trained batch 41 in epoch 8, gen_loss = 0.8938440992718651, disc_loss = 0.0029841071643334416
Trained batch 42 in epoch 8, gen_loss = 0.8965899528459061, disc_loss = 0.0030140239057715895
Trained batch 43 in epoch 8, gen_loss = 0.8962495056065646, disc_loss = 0.0030087773418265647
Trained batch 44 in epoch 8, gen_loss = 0.8955348438686794, disc_loss = 0.0029735228926357294
Trained batch 45 in epoch 8, gen_loss = 0.8951436060926189, disc_loss = 0.0029987492952900734
Trained batch 46 in epoch 8, gen_loss = 0.8970704890312032, disc_loss = 0.002968668120298931
Trained batch 47 in epoch 8, gen_loss = 0.8970486149191856, disc_loss = 0.003207542637634712
Trained batch 48 in epoch 8, gen_loss = 0.8981629597897433, disc_loss = 0.003214561926885223
Trained batch 49 in epoch 8, gen_loss = 0.898778133392334, disc_loss = 0.0032261739717796443
Trained batch 50 in epoch 8, gen_loss = 0.8976656268624699, disc_loss = 0.0032302947833622786
Trained batch 51 in epoch 8, gen_loss = 0.8969220713927195, disc_loss = 0.0032004614700921453
Trained batch 52 in epoch 8, gen_loss = 0.8962881666309429, disc_loss = 0.0031674810013083638
Trained batch 53 in epoch 8, gen_loss = 0.8953849132414218, disc_loss = 0.003133916770349498
Trained batch 54 in epoch 8, gen_loss = 0.8956215424971147, disc_loss = 0.0031802778216925534
Trained batch 55 in epoch 8, gen_loss = 0.8968435813273702, disc_loss = 0.0031486709735223223
Trained batch 56 in epoch 8, gen_loss = 0.8968968380961502, disc_loss = 0.0031270224748081283
Trained batch 57 in epoch 8, gen_loss = 0.8977772172155052, disc_loss = 0.003097592262904449
Trained batch 58 in epoch 8, gen_loss = 0.8984085685115749, disc_loss = 0.0030667683764723903
Trained batch 59 in epoch 8, gen_loss = 0.899757961432139, disc_loss = 0.003080930952758839
Trained batch 60 in epoch 8, gen_loss = 0.8988005411429484, disc_loss = 0.00305179700438605
Trained batch 61 in epoch 8, gen_loss = 0.8987430362932144, disc_loss = 0.0030990508084575976
Trained batch 62 in epoch 8, gen_loss = 0.8978865458851769, disc_loss = 0.0030773382796536364
Trained batch 63 in epoch 8, gen_loss = 0.8975631445646286, disc_loss = 0.003053511754842475
Trained batch 64 in epoch 8, gen_loss = 0.8974559820615329, disc_loss = 0.0030232236720621588
Trained batch 65 in epoch 8, gen_loss = 0.8982412778969967, disc_loss = 0.0029949189629405737
Trained batch 66 in epoch 8, gen_loss = 0.8990670282449296, disc_loss = 0.0029721754940171072
Trained batch 67 in epoch 8, gen_loss = 0.8985976489151225, disc_loss = 0.0029664817317525912
Trained batch 68 in epoch 8, gen_loss = 0.8977591455846593, disc_loss = 0.0029534179990625253
Trained batch 69 in epoch 8, gen_loss = 0.8973915951592581, disc_loss = 0.0029619088479583815
Trained batch 70 in epoch 8, gen_loss = 0.8970423231662159, disc_loss = 0.0029478965992842552
Trained batch 71 in epoch 8, gen_loss = 0.896532772315873, disc_loss = 0.0029394898366364134
Trained batch 72 in epoch 8, gen_loss = 0.8973607788347218, disc_loss = 0.00293748441936882
Trained batch 73 in epoch 8, gen_loss = 0.8988555782550091, disc_loss = 0.002953733180687335
Trained batch 74 in epoch 8, gen_loss = 0.8996529865264893, disc_loss = 0.002940272969814638
Trained batch 75 in epoch 8, gen_loss = 0.9006213279146897, disc_loss = 0.0029801162109881836
Trained batch 76 in epoch 8, gen_loss = 0.8990844132064225, disc_loss = 0.0030463068616008024
Trained batch 77 in epoch 8, gen_loss = 0.8989885457051106, disc_loss = 0.003104754110189298
Trained batch 78 in epoch 8, gen_loss = 0.9003187093553664, disc_loss = 0.0031837271246469663
Trained batch 79 in epoch 8, gen_loss = 0.9022664897143841, disc_loss = 0.0031823695011553355
Trained batch 80 in epoch 8, gen_loss = 0.9019681009245507, disc_loss = 0.003198092034443017
Trained batch 81 in epoch 8, gen_loss = 0.9013170687163748, disc_loss = 0.003190918401076754
Trained batch 82 in epoch 8, gen_loss = 0.9017608172922249, disc_loss = 0.003173417180316545
Trained batch 83 in epoch 8, gen_loss = 0.9014371016195842, disc_loss = 0.0031493854185100645
Trained batch 84 in epoch 8, gen_loss = 0.9012154375805574, disc_loss = 0.0031515592859838815
Trained batch 85 in epoch 8, gen_loss = 0.9008626113104266, disc_loss = 0.0031333204228864158
Trained batch 86 in epoch 8, gen_loss = 0.9003487243049446, disc_loss = 0.0031111658839830035
Trained batch 87 in epoch 8, gen_loss = 0.9001294672489166, disc_loss = 0.0030957399153108286
Trained batch 88 in epoch 8, gen_loss = 0.8998851548419909, disc_loss = 0.0030726689670046562
Trained batch 89 in epoch 8, gen_loss = 0.8995441052648756, disc_loss = 0.0030613008951250876
Trained batch 90 in epoch 8, gen_loss = 0.8999054661163917, disc_loss = 0.0030403219235058013
Trained batch 91 in epoch 8, gen_loss = 0.8993837995373685, disc_loss = 0.0030221369107375326
Trained batch 92 in epoch 8, gen_loss = 0.898918394760419, disc_loss = 0.003007183419740809
Trained batch 93 in epoch 8, gen_loss = 0.8983650321656085, disc_loss = 0.002993717545673172
Trained batch 94 in epoch 8, gen_loss = 0.8982395680327164, disc_loss = 0.00299527282753077
Trained batch 95 in epoch 8, gen_loss = 0.8983571926752726, disc_loss = 0.00298252312616872
Trained batch 96 in epoch 8, gen_loss = 0.8983316138847587, disc_loss = 0.0029792658271767278
Trained batch 97 in epoch 8, gen_loss = 0.8985205852255529, disc_loss = 0.002961473462257382
Trained batch 98 in epoch 8, gen_loss = 0.8978731541922598, disc_loss = 0.002972621187294899
Trained batch 99 in epoch 8, gen_loss = 0.8974803477525711, disc_loss = 0.002954837590223178
Trained batch 100 in epoch 8, gen_loss = 0.8974870165975968, disc_loss = 0.0029643987579787575
Trained batch 101 in epoch 8, gen_loss = 0.8971691826979319, disc_loss = 0.0029650740382517232
Trained batch 102 in epoch 8, gen_loss = 0.8983267215849127, disc_loss = 0.0030842477656918966
Trained batch 103 in epoch 8, gen_loss = 0.8981571661738249, disc_loss = 0.003075609047440454
Trained batch 104 in epoch 8, gen_loss = 0.8980831889879136, disc_loss = 0.0030640326185329327
Trained batch 105 in epoch 8, gen_loss = 0.8981117949170886, disc_loss = 0.003065717614141627
Trained batch 106 in epoch 8, gen_loss = 0.8990071549593845, disc_loss = 0.0030685011090745575
Trained batch 107 in epoch 8, gen_loss = 0.8993130386979492, disc_loss = 0.0030881171944740883
Trained batch 108 in epoch 8, gen_loss = 0.8994307665649904, disc_loss = 0.0030736079730025127
Trained batch 109 in epoch 8, gen_loss = 0.899625152349472, disc_loss = 0.003078071696853096
Trained batch 110 in epoch 8, gen_loss = 0.8988342376442643, disc_loss = 0.0031665686920687957
Trained batch 111 in epoch 8, gen_loss = 0.8991345608873027, disc_loss = 0.003199688612117565
Trained batch 112 in epoch 8, gen_loss = 0.9003357059132736, disc_loss = 0.0032404120146107356
Trained batch 113 in epoch 8, gen_loss = 0.9004416617385128, disc_loss = 0.003235700476930983
Trained batch 114 in epoch 8, gen_loss = 0.8991036855656168, disc_loss = 0.003419856308028102
Trained batch 115 in epoch 8, gen_loss = 0.9001241629493648, disc_loss = 0.003437908352272392
Trained batch 116 in epoch 8, gen_loss = 0.9009409735345433, disc_loss = 0.003436286474028841
Trained batch 117 in epoch 8, gen_loss = 0.9013870105905047, disc_loss = 0.0034504520205654583
Trained batch 118 in epoch 8, gen_loss = 0.9021625453684511, disc_loss = 0.0034843515311250416
Trained batch 119 in epoch 8, gen_loss = 0.902352100610733, disc_loss = 0.003487916929104055
Trained batch 120 in epoch 8, gen_loss = 0.9009830133974059, disc_loss = 0.003751621529660072
Trained batch 121 in epoch 8, gen_loss = 0.9030308879789759, disc_loss = 0.0038431450423066977
Trained batch 122 in epoch 8, gen_loss = 0.9040212660301022, disc_loss = 0.003881314006535624
Trained batch 123 in epoch 8, gen_loss = 0.9046590885808391, disc_loss = 0.0038861905453696608
Trained batch 124 in epoch 8, gen_loss = 0.9051129760742187, disc_loss = 0.003916447604075074
Trained batch 125 in epoch 8, gen_loss = 0.9051597260293507, disc_loss = 0.003909341087343083
Trained batch 126 in epoch 8, gen_loss = 0.9046597846849697, disc_loss = 0.0039275680745651164
Trained batch 127 in epoch 8, gen_loss = 0.904616798274219, disc_loss = 0.003949681371523184
Trained batch 128 in epoch 8, gen_loss = 0.9045762253362079, disc_loss = 0.003944997015127609
Trained batch 129 in epoch 8, gen_loss = 0.9046064124657558, disc_loss = 0.003932057441068957
Trained batch 130 in epoch 8, gen_loss = 0.9045746735944092, disc_loss = 0.003935661826296958
Trained batch 131 in epoch 8, gen_loss = 0.9043450233611193, disc_loss = 0.003917424771123368
Trained batch 132 in epoch 8, gen_loss = 0.9039723707320995, disc_loss = 0.003897900075154533
Trained batch 133 in epoch 8, gen_loss = 0.9039476109084799, disc_loss = 0.0038774294306093185
Trained batch 134 in epoch 8, gen_loss = 0.9044652422269185, disc_loss = 0.0038670104497146827
Trained batch 135 in epoch 8, gen_loss = 0.9042743063148331, disc_loss = 0.0038676125850008033
Trained batch 136 in epoch 8, gen_loss = 0.9041848274043006, disc_loss = 0.0038726110925666824
Trained batch 137 in epoch 8, gen_loss = 0.903818595668544, disc_loss = 0.0038615248344865613
Trained batch 138 in epoch 8, gen_loss = 0.903744694569128, disc_loss = 0.003845043853930325
Trained batch 139 in epoch 8, gen_loss = 0.9036771531615938, disc_loss = 0.0038357298804580103
Trained batch 140 in epoch 8, gen_loss = 0.9034450286669089, disc_loss = 0.003826064531565875
Trained batch 141 in epoch 8, gen_loss = 0.9028151266171899, disc_loss = 0.0038156025275640506
Trained batch 142 in epoch 8, gen_loss = 0.9032593161076099, disc_loss = 0.0038012564491636896
Trained batch 143 in epoch 8, gen_loss = 0.9031168069276545, disc_loss = 0.0037910416916323206
Trained batch 144 in epoch 8, gen_loss = 0.9028280574699928, disc_loss = 0.003785064617364571
Trained batch 145 in epoch 8, gen_loss = 0.9025740096830341, disc_loss = 0.0037692066438317503
Trained batch 146 in epoch 8, gen_loss = 0.9020729742082608, disc_loss = 0.0037519140707544326
Trained batch 147 in epoch 8, gen_loss = 0.9027619720310778, disc_loss = 0.003773081852626559
Trained batch 148 in epoch 8, gen_loss = 0.9022562287797864, disc_loss = 0.0037586758430459655
Trained batch 149 in epoch 8, gen_loss = 0.9019297488530477, disc_loss = 0.00377126811305061
Trained batch 150 in epoch 8, gen_loss = 0.901840337064882, disc_loss = 0.003760770445115963
Trained batch 151 in epoch 8, gen_loss = 0.9016541501409129, disc_loss = 0.0037573159995525586
Trained batch 152 in epoch 8, gen_loss = 0.9015226005728728, disc_loss = 0.0037778274763339
Trained batch 153 in epoch 8, gen_loss = 0.9011571612450984, disc_loss = 0.003767898734870621
Trained batch 154 in epoch 8, gen_loss = 0.9006309224713234, disc_loss = 0.003752369939860317
Trained batch 155 in epoch 8, gen_loss = 0.9001145741114249, disc_loss = 0.003736397402229695
Trained batch 156 in epoch 8, gen_loss = 0.8997654428907261, disc_loss = 0.0037215911511889405
Trained batch 157 in epoch 8, gen_loss = 0.8999110528185398, disc_loss = 0.0037086743476824197
Trained batch 158 in epoch 8, gen_loss = 0.8999028723194914, disc_loss = 0.0037023246488914643
Trained batch 159 in epoch 8, gen_loss = 0.8993105910718441, disc_loss = 0.003688632704142947
Trained batch 160 in epoch 8, gen_loss = 0.8993758363012941, disc_loss = 0.003698952254544226
Trained batch 161 in epoch 8, gen_loss = 0.8994896743032668, disc_loss = 0.003693726242887845
Trained batch 162 in epoch 8, gen_loss = 0.8996021645200765, disc_loss = 0.003692511613395042
Trained batch 163 in epoch 8, gen_loss = 0.8981086284649081, disc_loss = 0.003787131453353185
Trained batch 164 in epoch 8, gen_loss = 0.8984483487678296, disc_loss = 0.0037947606224792473
Trained batch 165 in epoch 8, gen_loss = 0.8989472227642336, disc_loss = 0.0038116227243522025
Trained batch 166 in epoch 8, gen_loss = 0.8990838449158355, disc_loss = 0.0038055574987083673
Trained batch 167 in epoch 8, gen_loss = 0.8991444054104033, disc_loss = 0.003812370005540461
Trained batch 168 in epoch 8, gen_loss = 0.8991656042415009, disc_loss = 0.0038063312913759573
Trained batch 169 in epoch 8, gen_loss = 0.8989299444591298, disc_loss = 0.003839953969616224
Trained batch 170 in epoch 8, gen_loss = 0.8995532292371605, disc_loss = 0.0038777275735305417
Trained batch 171 in epoch 8, gen_loss = 0.9002303086047949, disc_loss = 0.004114059284654295
Trained batch 172 in epoch 8, gen_loss = 0.8994102533153027, disc_loss = 0.004126870439447075
Trained batch 173 in epoch 8, gen_loss = 0.8989472539945581, disc_loss = 0.004131177437609468
Trained batch 174 in epoch 8, gen_loss = 0.8979359558650426, disc_loss = 0.004156080625419106
Trained batch 175 in epoch 8, gen_loss = 0.8972950171340596, disc_loss = 0.004150101153010672
Trained batch 176 in epoch 8, gen_loss = 0.8969104970242344, disc_loss = 0.004138046408619332
Trained batch 177 in epoch 8, gen_loss = 0.8970743849706114, disc_loss = 0.004125789804593398
Trained batch 178 in epoch 8, gen_loss = 0.8971887257512056, disc_loss = 0.0041230053474408624
Trained batch 179 in epoch 8, gen_loss = 0.8971505181656944, disc_loss = 0.00411051175582947
Trained batch 180 in epoch 8, gen_loss = 0.8971891261596048, disc_loss = 0.0041355575854216
Trained batch 181 in epoch 8, gen_loss = 0.8970042784790416, disc_loss = 0.0041363110579038555
Trained batch 182 in epoch 8, gen_loss = 0.8966580254784047, disc_loss = 0.004166354632636156
Trained batch 183 in epoch 8, gen_loss = 0.8976916959104331, disc_loss = 0.0041960532227834765
Trained batch 184 in epoch 8, gen_loss = 0.8976432242908994, disc_loss = 0.004194462747388595
Trained batch 185 in epoch 8, gen_loss = 0.8958979861069751, disc_loss = 0.004452040423989617
Trained batch 186 in epoch 8, gen_loss = 0.8961540329902568, disc_loss = 0.004467168282518253
Trained batch 187 in epoch 8, gen_loss = 0.8957503545791545, disc_loss = 0.0044925578181295
Trained batch 188 in epoch 8, gen_loss = 0.8965638510133854, disc_loss = 0.0046715583164422285
Trained batch 189 in epoch 8, gen_loss = 0.8965750251945697, disc_loss = 0.004664431552794811
Trained batch 190 in epoch 8, gen_loss = 0.8953348619775622, disc_loss = 0.004855825035486624
Trained batch 191 in epoch 8, gen_loss = 0.8952581562722722, disc_loss = 0.0048765305170187885
Trained batch 192 in epoch 8, gen_loss = 0.8946134979243106, disc_loss = 0.004953376467489285
Trained batch 193 in epoch 8, gen_loss = 0.894436671869042, disc_loss = 0.0049606478717850195
Trained batch 194 in epoch 8, gen_loss = 0.8950561281962273, disc_loss = 0.004959052248308674
Trained batch 195 in epoch 8, gen_loss = 0.8954155515043103, disc_loss = 0.004973975638621391
Trained batch 196 in epoch 8, gen_loss = 0.8952534026300847, disc_loss = 0.005001066234861004
Trained batch 197 in epoch 8, gen_loss = 0.8952654512843701, disc_loss = 0.005010305514625001
Trained batch 198 in epoch 8, gen_loss = 0.8943074495349098, disc_loss = 0.0051656458585349905
Trained batch 199 in epoch 8, gen_loss = 0.8954024544358253, disc_loss = 0.005371210161829367
Trained batch 200 in epoch 8, gen_loss = 0.8943751039196602, disc_loss = 0.005612151554799569
Trained batch 201 in epoch 8, gen_loss = 0.8957051319060939, disc_loss = 0.005819735805374929
Trained batch 202 in epoch 8, gen_loss = 0.8964045021334305, disc_loss = 0.006214799732199223
Trained batch 203 in epoch 8, gen_loss = 0.8968100930545845, disc_loss = 0.0062060648513793506
Trained batch 204 in epoch 8, gen_loss = 0.8957356394791022, disc_loss = 0.006365126245314392
Trained batch 205 in epoch 8, gen_loss = 0.8948984122970729, disc_loss = 0.006389565477645007
Trained batch 206 in epoch 8, gen_loss = 0.8940567325278757, disc_loss = 0.006497669471247833
Trained batch 207 in epoch 8, gen_loss = 0.8950682844106967, disc_loss = 0.006558097676203873
Trained batch 208 in epoch 8, gen_loss = 0.8943633890608281, disc_loss = 0.007939878183875999
Trained batch 209 in epoch 8, gen_loss = 0.8938157586824327, disc_loss = 0.00804776729505864
Trained batch 210 in epoch 8, gen_loss = 0.8921761868689297, disc_loss = 0.008370417052156059
Trained batch 211 in epoch 8, gen_loss = 0.8907417162971677, disc_loss = 0.008808949989714782
Trained batch 212 in epoch 8, gen_loss = 0.8896909843028431, disc_loss = 0.009084461432851047
Trained batch 213 in epoch 8, gen_loss = 0.8891261777031088, disc_loss = 0.009371334522588301
Trained batch 214 in epoch 8, gen_loss = 0.8892142864160759, disc_loss = 0.009610528803192252
Trained batch 215 in epoch 8, gen_loss = 0.8890193764258314, disc_loss = 0.009657187776476214
Trained batch 216 in epoch 8, gen_loss = 0.8889052546518739, disc_loss = 0.009652336330844028
Trained batch 217 in epoch 8, gen_loss = 0.888110166022537, disc_loss = 0.009864690808639135
Trained batch 218 in epoch 8, gen_loss = 0.8881034105335741, disc_loss = 0.00993588827146413
Trained batch 219 in epoch 8, gen_loss = 0.8866735772653059, disc_loss = 0.010377557525961575
Trained batch 220 in epoch 8, gen_loss = 0.8871372722392707, disc_loss = 0.010399068820572614
Trained batch 221 in epoch 8, gen_loss = 0.8875885506470998, disc_loss = 0.010745775601658802
Trained batch 222 in epoch 8, gen_loss = 0.8873519475150001, disc_loss = 0.010785160370112602
Trained batch 223 in epoch 8, gen_loss = 0.8862863419843572, disc_loss = 0.011167063037906442
Trained batch 224 in epoch 8, gen_loss = 0.8868864221043057, disc_loss = 0.011208353838365938
Trained batch 225 in epoch 8, gen_loss = 0.8876930340728929, disc_loss = 0.011409627126356734
Trained batch 226 in epoch 8, gen_loss = 0.8872756829345804, disc_loss = 0.011443515559494298
Trained batch 227 in epoch 8, gen_loss = 0.8866577399404425, disc_loss = 0.011645739833750812
Trained batch 228 in epoch 8, gen_loss = 0.8864021210170729, disc_loss = 0.011725118213971694
Trained batch 229 in epoch 8, gen_loss = 0.886344747957976, disc_loss = 0.01170098979289279
Trained batch 230 in epoch 8, gen_loss = 0.8861907751529248, disc_loss = 0.011675257357724365
Trained batch 231 in epoch 8, gen_loss = 0.8858453934562618, disc_loss = 0.011654698134375864
Trained batch 232 in epoch 8, gen_loss = 0.8855927773299647, disc_loss = 0.011629425787642726
Trained batch 233 in epoch 8, gen_loss = 0.8855330984816592, disc_loss = 0.011641731683729997
Trained batch 234 in epoch 8, gen_loss = 0.8857872095513851, disc_loss = 0.011617222132081998
Trained batch 235 in epoch 8, gen_loss = 0.8864378050222235, disc_loss = 0.011602631455358371
Trained batch 236 in epoch 8, gen_loss = 0.8857815459307739, disc_loss = 0.01164956590581198
Trained batch 237 in epoch 8, gen_loss = 0.8865255615791353, disc_loss = 0.011662411942741513
Trained batch 238 in epoch 8, gen_loss = 0.8870959259476123, disc_loss = 0.012538933020794304
Trained batch 239 in epoch 8, gen_loss = 0.8855648035804431, disc_loss = 0.013419641159513655
Trained batch 240 in epoch 8, gen_loss = 0.8842069128242271, disc_loss = 0.013823862122835522
Trained batch 241 in epoch 8, gen_loss = 0.8846505887744841, disc_loss = 0.014107810049548683
Trained batch 242 in epoch 8, gen_loss = 0.8844342631567653, disc_loss = 0.014184732780573361
Trained batch 243 in epoch 8, gen_loss = 0.8842560480364033, disc_loss = 0.014249767261732858
Trained batch 244 in epoch 8, gen_loss = 0.8831587370561094, disc_loss = 0.01445156549559716
Trained batch 245 in epoch 8, gen_loss = 0.8835506322907238, disc_loss = 0.014452257739735873
Trained batch 246 in epoch 8, gen_loss = 0.8838977360049722, disc_loss = 0.014432929638162376
Trained batch 247 in epoch 8, gen_loss = 0.8844419775470611, disc_loss = 0.014426270061390354
Trained batch 248 in epoch 8, gen_loss = 0.8841992197745296, disc_loss = 0.014397331882814267
Trained batch 249 in epoch 8, gen_loss = 0.8839038269519806, disc_loss = 0.014361643276177347
Trained batch 250 in epoch 8, gen_loss = 0.883549010848619, disc_loss = 0.014376622234170596
Trained batch 251 in epoch 8, gen_loss = 0.8835162775857108, disc_loss = 0.014340405813455286
Trained batch 252 in epoch 8, gen_loss = 0.8833918109712865, disc_loss = 0.014311010565557204
Trained batch 253 in epoch 8, gen_loss = 0.882859054512865, disc_loss = 0.014304420730194414
Trained batch 254 in epoch 8, gen_loss = 0.882477058616339, disc_loss = 0.014338670827119666
Trained batch 255 in epoch 8, gen_loss = 0.8830335917882621, disc_loss = 0.014390772407750774
Trained batch 256 in epoch 8, gen_loss = 0.8818346266616643, disc_loss = 0.014814322614129126
Trained batch 257 in epoch 8, gen_loss = 0.8806453605954961, disc_loss = 0.015216888609890964
Trained batch 258 in epoch 8, gen_loss = 0.8804057189856717, disc_loss = 0.01536815069367728
Trained batch 259 in epoch 8, gen_loss = 0.8813579130631227, disc_loss = 0.015842781497989424
Trained batch 260 in epoch 8, gen_loss = 0.8812644579858159, disc_loss = 0.016004310580955326
Trained batch 261 in epoch 8, gen_loss = 0.8805268102019798, disc_loss = 0.016040981721438696
Trained batch 262 in epoch 8, gen_loss = 0.879868300695383, disc_loss = 0.01614215422843091
Trained batch 263 in epoch 8, gen_loss = 0.8803504344188806, disc_loss = 0.016153947742140823
Trained batch 264 in epoch 8, gen_loss = 0.8813227194660115, disc_loss = 0.01625853529076953
Trained batch 265 in epoch 8, gen_loss = 0.8815235630013889, disc_loss = 0.01622927941196367
Trained batch 266 in epoch 8, gen_loss = 0.8814152702410123, disc_loss = 0.016204369529098105
Trained batch 267 in epoch 8, gen_loss = 0.8808399732433149, disc_loss = 0.016257289761448027
Trained batch 268 in epoch 8, gen_loss = 0.8819520260764764, disc_loss = 0.01634018915899264
Trained batch 269 in epoch 8, gen_loss = 0.882057398336905, disc_loss = 0.01630354208647515
Trained batch 270 in epoch 8, gen_loss = 0.8819404299408747, disc_loss = 0.0162885371360213
Trained batch 271 in epoch 8, gen_loss = 0.8816628863706308, disc_loss = 0.016250746880199157
Trained batch 272 in epoch 8, gen_loss = 0.8803439526767521, disc_loss = 0.016640537395397878
Trained batch 273 in epoch 8, gen_loss = 0.8805465476356283, disc_loss = 0.016668991866371982
Trained batch 274 in epoch 8, gen_loss = 0.8809625114094127, disc_loss = 0.016750733223320408
Trained batch 275 in epoch 8, gen_loss = 0.8812623982844145, disc_loss = 0.016717905085027705
Trained batch 276 in epoch 8, gen_loss = 0.8811350703669799, disc_loss = 0.016691923491986272
Trained batch 277 in epoch 8, gen_loss = 0.8800995851592194, disc_loss = 0.017045240984097283
Trained batch 278 in epoch 8, gen_loss = 0.880618465844021, disc_loss = 0.017325986217620607
Trained batch 279 in epoch 8, gen_loss = 0.8804380080529621, disc_loss = 0.01729644457892781
Trained batch 280 in epoch 8, gen_loss = 0.8810364466120764, disc_loss = 0.01742808229879897
Trained batch 281 in epoch 8, gen_loss = 0.881011093339176, disc_loss = 0.0173911718091868
Trained batch 282 in epoch 8, gen_loss = 0.8801117520450282, disc_loss = 0.017573222966351325
Trained batch 283 in epoch 8, gen_loss = 0.8793958929223074, disc_loss = 0.01779582952296781
Trained batch 284 in epoch 8, gen_loss = 0.8786041038078174, disc_loss = 0.018000902236324914
Trained batch 285 in epoch 8, gen_loss = 0.8792029706748216, disc_loss = 0.018221848625592053
Trained batch 286 in epoch 8, gen_loss = 0.8790759658148896, disc_loss = 0.018203651117978663
Trained batch 287 in epoch 8, gen_loss = 0.8782129749241803, disc_loss = 0.018286976039235014
Trained batch 288 in epoch 8, gen_loss = 0.8776252434740429, disc_loss = 0.018304355565787238
Trained batch 289 in epoch 8, gen_loss = 0.8777071118354798, disc_loss = 0.018304055846488938
Trained batch 290 in epoch 8, gen_loss = 0.8775760480218736, disc_loss = 0.01841254663634469
Trained batch 291 in epoch 8, gen_loss = 0.8766235276444317, disc_loss = 0.01861918623932344
Trained batch 292 in epoch 8, gen_loss = 0.8769684411559903, disc_loss = 0.018628003540585525
Trained batch 293 in epoch 8, gen_loss = 0.8769249573451321, disc_loss = 0.018583926330257183
Trained batch 294 in epoch 8, gen_loss = 0.8766936805288671, disc_loss = 0.01858699462155543
Trained batch 295 in epoch 8, gen_loss = 0.8767512974304121, disc_loss = 0.018548193196545833
Trained batch 296 in epoch 8, gen_loss = 0.8763534101572904, disc_loss = 0.018592232516073066
Trained batch 297 in epoch 8, gen_loss = 0.8757973291329889, disc_loss = 0.018665605266078456
Trained batch 298 in epoch 8, gen_loss = 0.8771350337908819, disc_loss = 0.019198925770900172
Trained batch 299 in epoch 8, gen_loss = 0.877567018866539, disc_loss = 0.019185852856220056
Trained batch 300 in epoch 8, gen_loss = 0.8768135521102981, disc_loss = 0.019417502160069603
Trained batch 301 in epoch 8, gen_loss = 0.875713194640267, disc_loss = 0.01959523881881171
Trained batch 302 in epoch 8, gen_loss = 0.8763210657406169, disc_loss = 0.019629530498770253
Trained batch 303 in epoch 8, gen_loss = 0.876494067475984, disc_loss = 0.019891685353573656
Trained batch 304 in epoch 8, gen_loss = 0.8755993684784311, disc_loss = 0.020210082084703884
Trained batch 305 in epoch 8, gen_loss = 0.8747821997583302, disc_loss = 0.020339906252951064
Trained batch 306 in epoch 8, gen_loss = 0.8755535929909747, disc_loss = 0.02036878977544266
Trained batch 307 in epoch 8, gen_loss = 0.875620607818876, disc_loss = 0.02048042410600616
Trained batch 308 in epoch 8, gen_loss = 0.8754224105946069, disc_loss = 0.020453783979603242
Trained batch 309 in epoch 8, gen_loss = 0.8750012878448733, disc_loss = 0.02051119912911447
Trained batch 310 in epoch 8, gen_loss = 0.8753259670696074, disc_loss = 0.020474066760936015
Trained batch 311 in epoch 8, gen_loss = 0.8748666347983556, disc_loss = 0.020520566055963103
Trained batch 312 in epoch 8, gen_loss = 0.8755114830720919, disc_loss = 0.0205548432314941
Trained batch 313 in epoch 8, gen_loss = 0.8756201310901884, disc_loss = 0.02051111747685725
Trained batch 314 in epoch 8, gen_loss = 0.8751876042002723, disc_loss = 0.020550425011398536
Trained batch 315 in epoch 8, gen_loss = 0.8746738492310802, disc_loss = 0.020598717933502993
Trained batch 316 in epoch 8, gen_loss = 0.8744524282987938, disc_loss = 0.02205760805567944
Trained batch 317 in epoch 8, gen_loss = 0.8735822722222071, disc_loss = 0.02235826791729778
Trained batch 318 in epoch 8, gen_loss = 0.8728674969703053, disc_loss = 0.022547672748664937
Trained batch 319 in epoch 8, gen_loss = 0.8724750276654959, disc_loss = 0.022583337515970924
Trained batch 320 in epoch 8, gen_loss = 0.8721763824005364, disc_loss = 0.022544943031962278
Trained batch 321 in epoch 8, gen_loss = 0.8717792559854732, disc_loss = 0.022549941896472518
Trained batch 322 in epoch 8, gen_loss = 0.8719306601090328, disc_loss = 0.02256596646410047
Trained batch 323 in epoch 8, gen_loss = 0.8716559560946476, disc_loss = 0.022548531030482946
Trained batch 324 in epoch 8, gen_loss = 0.8715983585210947, disc_loss = 0.02252103502718875
Trained batch 325 in epoch 8, gen_loss = 0.8714552130435873, disc_loss = 0.022485251650585583
Trained batch 326 in epoch 8, gen_loss = 0.8715548132537702, disc_loss = 0.02244026488795398
Trained batch 327 in epoch 8, gen_loss = 0.8712830934219244, disc_loss = 0.022428438638865084
Trained batch 328 in epoch 8, gen_loss = 0.87147660367757, disc_loss = 0.022374858667134196
Trained batch 329 in epoch 8, gen_loss = 0.8709159598206029, disc_loss = 0.022331938314759596
Trained batch 330 in epoch 8, gen_loss = 0.8711227156964674, disc_loss = 0.022357622648974784
Trained batch 331 in epoch 8, gen_loss = 0.8711526268217937, disc_loss = 0.02230559504402981
Trained batch 332 in epoch 8, gen_loss = 0.8706298236016397, disc_loss = 0.022325465523472823
Trained batch 333 in epoch 8, gen_loss = 0.8705312595395984, disc_loss = 0.022280952203767877
Trained batch 334 in epoch 8, gen_loss = 0.8704651672448684, disc_loss = 0.02223029986037803
Trained batch 335 in epoch 8, gen_loss = 0.870521659652392, disc_loss = 0.02218828980680666
Trained batch 336 in epoch 8, gen_loss = 0.8704630658251595, disc_loss = 0.0221332693175421
Trained batch 337 in epoch 8, gen_loss = 0.8705257891550572, disc_loss = 0.022077906721811633
Trained batch 338 in epoch 8, gen_loss = 0.8706119661837552, disc_loss = 0.022022523507228598
Trained batch 339 in epoch 8, gen_loss = 0.8706146511961432, disc_loss = 0.021990955382010298
Trained batch 340 in epoch 8, gen_loss = 0.8709912994040772, disc_loss = 0.021937066749218973
Trained batch 341 in epoch 8, gen_loss = 0.8708802832846056, disc_loss = 0.02188712139804548
Trained batch 342 in epoch 8, gen_loss = 0.8712601712076726, disc_loss = 0.021859898899869216
Trained batch 343 in epoch 8, gen_loss = 0.8715019733753315, disc_loss = 0.02181403400636343
Trained batch 344 in epoch 8, gen_loss = 0.8715014526809471, disc_loss = 0.021761025528194033
Trained batch 345 in epoch 8, gen_loss = 0.8710256716764042, disc_loss = 0.021805113770277645
Trained batch 346 in epoch 8, gen_loss = 0.8707814783459095, disc_loss = 0.0217825627076555
Trained batch 347 in epoch 8, gen_loss = 0.8712820790964981, disc_loss = 0.021764811703094935
Trained batch 348 in epoch 8, gen_loss = 0.8714101664657921, disc_loss = 0.021726254978881653
Trained batch 349 in epoch 8, gen_loss = 0.87161569748606, disc_loss = 0.021742984782239155
Trained batch 350 in epoch 8, gen_loss = 0.871234680342878, disc_loss = 0.021767078733676646
Trained batch 351 in epoch 8, gen_loss = 0.871861257167025, disc_loss = 0.021739199494980065
Trained batch 352 in epoch 8, gen_loss = 0.8711801689677469, disc_loss = 0.021895121869422687
Trained batch 353 in epoch 8, gen_loss = 0.8711475058127258, disc_loss = 0.02184425101754924
Trained batch 354 in epoch 8, gen_loss = 0.8705773655797394, disc_loss = 0.02191915225539304
Trained batch 355 in epoch 8, gen_loss = 0.8714605144570383, disc_loss = 0.021934231355383447
Trained batch 356 in epoch 8, gen_loss = 0.8717967819432918, disc_loss = 0.021901000514809116
Trained batch 357 in epoch 8, gen_loss = 0.8713720937014958, disc_loss = 0.021876360304710876
Trained batch 358 in epoch 8, gen_loss = 0.8704842861980449, disc_loss = 0.02220070310141943
Trained batch 359 in epoch 8, gen_loss = 0.8712434055076705, disc_loss = 0.022288204894478744
Trained batch 360 in epoch 8, gen_loss = 0.8716817775591589, disc_loss = 0.024220425005450102
Trained batch 361 in epoch 8, gen_loss = 0.8712139183974398, disc_loss = 0.024516822100689027
Trained batch 362 in epoch 8, gen_loss = 0.8702598826615935, disc_loss = 0.025151800148101835
Trained batch 363 in epoch 8, gen_loss = 0.8695509348596845, disc_loss = 0.025291856152522326
Trained batch 364 in epoch 8, gen_loss = 0.8697430947055556, disc_loss = 0.025413926986160955
Trained batch 365 in epoch 8, gen_loss = 0.8693121977842571, disc_loss = 0.02555314626460742
Trained batch 366 in epoch 8, gen_loss = 0.8688868038985644, disc_loss = 0.025661654871246428
Trained batch 367 in epoch 8, gen_loss = 0.868746518926776, disc_loss = 0.025629623924032785
Trained batch 368 in epoch 8, gen_loss = 0.8681084339211627, disc_loss = 0.025653837596351498
Trained batch 369 in epoch 8, gen_loss = 0.8686822383790402, disc_loss = 0.02607136757326992
Trained batch 370 in epoch 8, gen_loss = 0.8679896861395103, disc_loss = 0.026161731694601578
Trained batch 371 in epoch 8, gen_loss = 0.866970819170757, disc_loss = 0.026476417737637436
Trained batch 372 in epoch 8, gen_loss = 0.866941550142324, disc_loss = 0.026809727697540822
Trained batch 373 in epoch 8, gen_loss = 0.8661834082820199, disc_loss = 0.027126220378023695
Trained batch 374 in epoch 8, gen_loss = 0.8660450507799784, disc_loss = 0.0271954610341539
Trained batch 375 in epoch 8, gen_loss = 0.8656393005809886, disc_loss = 0.02717165036580248
Trained batch 376 in epoch 8, gen_loss = 0.8652607893437858, disc_loss = 0.027131451322852735
Trained batch 377 in epoch 8, gen_loss = 0.8646361315376544, disc_loss = 0.027130543928785576
Trained batch 378 in epoch 8, gen_loss = 0.86523975593119, disc_loss = 0.027133184226505007
Trained batch 379 in epoch 8, gen_loss = 0.8653646963207345, disc_loss = 0.027078556296979323
Trained batch 380 in epoch 8, gen_loss = 0.8655798693341533, disc_loss = 0.027018714645447264
Trained batch 381 in epoch 8, gen_loss = 0.8652854039094835, disc_loss = 0.027062237494946968
Trained batch 382 in epoch 8, gen_loss = 0.8652717552048108, disc_loss = 0.027011678676308173
Trained batch 383 in epoch 8, gen_loss = 0.8656813683919609, disc_loss = 0.026967604220772046
Trained batch 384 in epoch 8, gen_loss = 0.8660187157717618, disc_loss = 0.026911789053664
Trained batch 385 in epoch 8, gen_loss = 0.8661287535039872, disc_loss = 0.026869579648401185
Trained batch 386 in epoch 8, gen_loss = 0.8661777985496423, disc_loss = 0.02681334951509859
Trained batch 387 in epoch 8, gen_loss = 0.8658122208315072, disc_loss = 0.02681571816408661
Trained batch 388 in epoch 8, gen_loss = 0.8657905483920041, disc_loss = 0.026763133664560387
Trained batch 389 in epoch 8, gen_loss = 0.8661697752964802, disc_loss = 0.02674308085205177
Trained batch 390 in epoch 8, gen_loss = 0.8658966920564851, disc_loss = 0.026687210414420497
Trained batch 391 in epoch 8, gen_loss = 0.8656654794301305, disc_loss = 0.02663236290836536
Trained batch 392 in epoch 8, gen_loss = 0.8652418574304072, disc_loss = 0.026667760782839573
Trained batch 393 in epoch 8, gen_loss = 0.8653066610624343, disc_loss = 0.02660897186884023
Trained batch 394 in epoch 8, gen_loss = 0.8656091593488863, disc_loss = 0.026571452749091423
Trained batch 395 in epoch 8, gen_loss = 0.8659905454125068, disc_loss = 0.026543215977267897
Trained batch 396 in epoch 8, gen_loss = 0.8660808827174401, disc_loss = 0.026489247070034257
Trained batch 397 in epoch 8, gen_loss = 0.865905259272561, disc_loss = 0.026439642852485817
Trained batch 398 in epoch 8, gen_loss = 0.8657706780242442, disc_loss = 0.02638521244256923
Trained batch 399 in epoch 8, gen_loss = 0.8657789571583271, disc_loss = 0.026346141280955634
Trained batch 400 in epoch 8, gen_loss = 0.8659729526524532, disc_loss = 0.02629786761340562
Trained batch 401 in epoch 8, gen_loss = 0.8659164594180548, disc_loss = 0.0262384257124116
Trained batch 402 in epoch 8, gen_loss = 0.8657231174095097, disc_loss = 0.026195937590835335
Trained batch 403 in epoch 8, gen_loss = 0.8660789925863247, disc_loss = 0.026157787169956852
Trained batch 404 in epoch 8, gen_loss = 0.8660072991877427, disc_loss = 0.026106413006552576
Trained batch 405 in epoch 8, gen_loss = 0.8658988025094488, disc_loss = 0.02630084670800257
Trained batch 406 in epoch 8, gen_loss = 0.8655314149669113, disc_loss = 0.026335282973185437
Trained batch 407 in epoch 8, gen_loss = 0.865020370074347, disc_loss = 0.02636112543347967
Trained batch 408 in epoch 8, gen_loss = 0.8645988039690591, disc_loss = 0.026552603562979577
Trained batch 409 in epoch 8, gen_loss = 0.8643046262787609, disc_loss = 0.026626709761188888
Trained batch 410 in epoch 8, gen_loss = 0.8639644326374769, disc_loss = 0.026658048362690964
Trained batch 411 in epoch 8, gen_loss = 0.8645993103680102, disc_loss = 0.026773542078727296
Trained batch 412 in epoch 8, gen_loss = 0.8646820353538014, disc_loss = 0.026746185039808256
Trained batch 413 in epoch 8, gen_loss = 0.8644147031549094, disc_loss = 0.02676405789047156
Trained batch 414 in epoch 8, gen_loss = 0.8646758159959173, disc_loss = 0.026717108293963843
Trained batch 415 in epoch 8, gen_loss = 0.864822786874496, disc_loss = 0.026676938583617672
Trained batch 416 in epoch 8, gen_loss = 0.8645488938553442, disc_loss = 0.026691319667723038
Trained batch 417 in epoch 8, gen_loss = 0.8641804371153909, disc_loss = 0.0266719239387376
Trained batch 418 in epoch 8, gen_loss = 0.8644601009910602, disc_loss = 0.026656998958225254
Trained batch 419 in epoch 8, gen_loss = 0.8643270709684917, disc_loss = 0.026620194505501005
Trained batch 420 in epoch 8, gen_loss = 0.8650766725778013, disc_loss = 0.026633434992000424
Trained batch 421 in epoch 8, gen_loss = 0.8649709260011736, disc_loss = 0.02658799457169575
Trained batch 422 in epoch 8, gen_loss = 0.8643830449586782, disc_loss = 0.02709249152205268
Trained batch 423 in epoch 8, gen_loss = 0.8639495478204962, disc_loss = 0.027109779581155208
Trained batch 424 in epoch 8, gen_loss = 0.8636207553919624, disc_loss = 0.027067540650639463
Trained batch 425 in epoch 8, gen_loss = 0.8638627482971675, disc_loss = 0.027127534810217544
Trained batch 426 in epoch 8, gen_loss = 0.8638054963018074, disc_loss = 0.027090745196139018
Trained batch 427 in epoch 8, gen_loss = 0.8635730132042805, disc_loss = 0.02704624757366516
Trained batch 428 in epoch 8, gen_loss = 0.863341101538607, disc_loss = 0.027039626492773527
Trained batch 429 in epoch 8, gen_loss = 0.8625836560892505, disc_loss = 0.02723545721991984
Trained batch 430 in epoch 8, gen_loss = 0.8625458330953204, disc_loss = 0.027201857818657933
Trained batch 431 in epoch 8, gen_loss = 0.8631931594400494, disc_loss = 0.02772273253800382
Trained batch 432 in epoch 8, gen_loss = 0.862297235749335, disc_loss = 0.028293473885865672
Trained batch 433 in epoch 8, gen_loss = 0.8628437517013418, disc_loss = 0.02887196185964284
Trained batch 434 in epoch 8, gen_loss = 0.8624018364254086, disc_loss = 0.029162892659633666
Trained batch 435 in epoch 8, gen_loss = 0.8617932314582921, disc_loss = 0.02933958876309831
Trained batch 436 in epoch 8, gen_loss = 0.861550791244485, disc_loss = 0.02933433073417239
Trained batch 437 in epoch 8, gen_loss = 0.861295022852889, disc_loss = 0.02937962653510885
Trained batch 438 in epoch 8, gen_loss = 0.8610510957132439, disc_loss = 0.029413565402481374
Trained batch 439 in epoch 8, gen_loss = 0.8605683671479876, disc_loss = 0.0294596126165495
Trained batch 440 in epoch 8, gen_loss = 0.8605113282901089, disc_loss = 0.029446050004142413
Trained batch 441 in epoch 8, gen_loss = 0.8605557767109634, disc_loss = 0.029541625867795823
Trained batch 442 in epoch 8, gen_loss = 0.8602594063863259, disc_loss = 0.029506672988382943
Trained batch 443 in epoch 8, gen_loss = 0.8601104125112027, disc_loss = 0.029455919637814635
Trained batch 444 in epoch 8, gen_loss = 0.8596233301618126, disc_loss = 0.029469064268377726
Trained batch 445 in epoch 8, gen_loss = 0.8593688412765751, disc_loss = 0.029431794478762645
Trained batch 446 in epoch 8, gen_loss = 0.8596675009935494, disc_loss = 0.029921134401496158
Trained batch 447 in epoch 8, gen_loss = 0.859047631001366, disc_loss = 0.030159438483159256
Trained batch 448 in epoch 8, gen_loss = 0.8583702484191393, disc_loss = 0.030258293660826368
Trained batch 449 in epoch 8, gen_loss = 0.8581777903106478, disc_loss = 0.030230361700264944
Trained batch 450 in epoch 8, gen_loss = 0.8578069779005918, disc_loss = 0.030440851596871727
Trained batch 451 in epoch 8, gen_loss = 0.857519523034581, disc_loss = 0.03048763035660593
Trained batch 452 in epoch 8, gen_loss = 0.857417398928017, disc_loss = 0.030474903782578822
Trained batch 453 in epoch 8, gen_loss = 0.8576266373700507, disc_loss = 0.030471849834776202
Trained batch 454 in epoch 8, gen_loss = 0.8575988481987964, disc_loss = 0.030427588097710203
Trained batch 455 in epoch 8, gen_loss = 0.8574139071268994, disc_loss = 0.030382212236106983
Trained batch 456 in epoch 8, gen_loss = 0.8573068657510912, disc_loss = 0.03039150370521312
Trained batch 457 in epoch 8, gen_loss = 0.8568767411349643, disc_loss = 0.030429871615599922
Trained batch 458 in epoch 8, gen_loss = 0.8565242988481501, disc_loss = 0.030402699117153105
Trained batch 459 in epoch 8, gen_loss = 0.8571108361301215, disc_loss = 0.030921382798165406
Trained batch 460 in epoch 8, gen_loss = 0.8567102783543428, disc_loss = 0.03101692132251802
Trained batch 461 in epoch 8, gen_loss = 0.8567820513274247, disc_loss = 0.03097611281605542
Trained batch 462 in epoch 8, gen_loss = 0.8565280905423875, disc_loss = 0.030940770166553958
Trained batch 463 in epoch 8, gen_loss = 0.8565601004480288, disc_loss = 0.031035225257349745
Trained batch 464 in epoch 8, gen_loss = 0.8563225662195554, disc_loss = 0.03101257524523203
Trained batch 465 in epoch 8, gen_loss = 0.8566068412792017, disc_loss = 0.031188852042799153
Trained batch 466 in epoch 8, gen_loss = 0.8562720913830866, disc_loss = 0.031223327101944153
Trained batch 467 in epoch 8, gen_loss = 0.8562105220989285, disc_loss = 0.031236043435712464
Trained batch 468 in epoch 8, gen_loss = 0.8559033153280775, disc_loss = 0.03123780981456833
Trained batch 469 in epoch 8, gen_loss = 0.8553677851215322, disc_loss = 0.031252692605150824
Trained batch 470 in epoch 8, gen_loss = 0.855583043931143, disc_loss = 0.03124926208109138
Trained batch 471 in epoch 8, gen_loss = 0.8557704346791163, disc_loss = 0.031230185256868413
Trained batch 472 in epoch 8, gen_loss = 0.8558566078197124, disc_loss = 0.03118947620974188
Trained batch 473 in epoch 8, gen_loss = 0.8559164316216602, disc_loss = 0.03114280109843907
Trained batch 474 in epoch 8, gen_loss = 0.855870938865762, disc_loss = 0.03111352578295689
Trained batch 475 in epoch 8, gen_loss = 0.855681209065834, disc_loss = 0.031335895048540494
Trained batch 476 in epoch 8, gen_loss = 0.8557380003624242, disc_loss = 0.03134573947353214
Trained batch 477 in epoch 8, gen_loss = 0.8549368802972418, disc_loss = 0.031473025240230074
Trained batch 478 in epoch 8, gen_loss = 0.8550907398315462, disc_loss = 0.03143370318827307
Trained batch 479 in epoch 8, gen_loss = 0.8554293585320314, disc_loss = 0.0313917090233493
Trained batch 480 in epoch 8, gen_loss = 0.8551630388922107, disc_loss = 0.031427291023453964
Trained batch 481 in epoch 8, gen_loss = 0.8552108646923081, disc_loss = 0.031395595413497436
Trained batch 482 in epoch 8, gen_loss = 0.855513256282293, disc_loss = 0.03139761182928832
Trained batch 483 in epoch 8, gen_loss = 0.8552347307116532, disc_loss = 0.03183843380259735
Trained batch 484 in epoch 8, gen_loss = 0.8547103650791129, disc_loss = 0.031998299093936214
Trained batch 485 in epoch 8, gen_loss = 0.8544311322302485, disc_loss = 0.031983013480418813
Trained batch 486 in epoch 8, gen_loss = 0.8544278159523402, disc_loss = 0.03242435329737146
Trained batch 487 in epoch 8, gen_loss = 0.8541545506383552, disc_loss = 0.03241333220493751
Trained batch 488 in epoch 8, gen_loss = 0.8538449686972885, disc_loss = 0.03253935638658992
Trained batch 489 in epoch 8, gen_loss = 0.8532349142493034, disc_loss = 0.032676844406226764
Trained batch 490 in epoch 8, gen_loss = 0.8532804012784162, disc_loss = 0.03266182925093107
Trained batch 491 in epoch 8, gen_loss = 0.8530105863644825, disc_loss = 0.03292401926308053
Trained batch 492 in epoch 8, gen_loss = 0.8530505954856563, disc_loss = 0.03311326677493494
Trained batch 493 in epoch 8, gen_loss = 0.8531599157010978, disc_loss = 0.033181032574045574
Trained batch 494 in epoch 8, gen_loss = 0.8531349493999674, disc_loss = 0.0331700144476737
Trained batch 495 in epoch 8, gen_loss = 0.8530826342682685, disc_loss = 0.03314606413609469
Trained batch 496 in epoch 8, gen_loss = 0.8527841177025072, disc_loss = 0.03315569851004052
Trained batch 497 in epoch 8, gen_loss = 0.8529429428548698, disc_loss = 0.033185438160414256
Trained batch 498 in epoch 8, gen_loss = 0.8529601014687686, disc_loss = 0.033144495788707824
Trained batch 499 in epoch 8, gen_loss = 0.8531893821954727, disc_loss = 0.03309855211619288
Trained batch 500 in epoch 8, gen_loss = 0.8531394071445731, disc_loss = 0.03307669100531948
Trained batch 501 in epoch 8, gen_loss = 0.85291216264208, disc_loss = 0.03307919834361994
Trained batch 502 in epoch 8, gen_loss = 0.8524424328244704, disc_loss = 0.033119480420926044
Trained batch 503 in epoch 8, gen_loss = 0.8527604384081704, disc_loss = 0.03319328939930225
Trained batch 504 in epoch 8, gen_loss = 0.8526325811253916, disc_loss = 0.03316163321551267
Trained batch 505 in epoch 8, gen_loss = 0.852320446680657, disc_loss = 0.03315500812439373
Trained batch 506 in epoch 8, gen_loss = 0.8526099688672926, disc_loss = 0.03312493107305505
Trained batch 507 in epoch 8, gen_loss = 0.8526183694131731, disc_loss = 0.03317590566502342
Trained batch 508 in epoch 8, gen_loss = 0.8525301244966174, disc_loss = 0.03314239296180238
Trained batch 509 in epoch 8, gen_loss = 0.8525308854439679, disc_loss = 0.03308926283144483
Trained batch 510 in epoch 8, gen_loss = 0.852179639493416, disc_loss = 0.03309828754507166
Trained batch 511 in epoch 8, gen_loss = 0.8521327378693968, disc_loss = 0.03304644522177114
Trained batch 512 in epoch 8, gen_loss = 0.8518086297702604, disc_loss = 0.03301646723275819
Trained batch 513 in epoch 8, gen_loss = 0.8519325553211257, disc_loss = 0.032988691030265874
Trained batch 514 in epoch 8, gen_loss = 0.852022142549163, disc_loss = 0.03298733716342345
Trained batch 515 in epoch 8, gen_loss = 0.8521292135697003, disc_loss = 0.032942773351922285
Trained batch 516 in epoch 8, gen_loss = 0.8517171305890702, disc_loss = 0.03295013886053166
Trained batch 517 in epoch 8, gen_loss = 0.8518938845649189, disc_loss = 0.03293835806469775
Trained batch 518 in epoch 8, gen_loss = 0.8519305259506137, disc_loss = 0.03290249855367033
Trained batch 519 in epoch 8, gen_loss = 0.8523312882735179, disc_loss = 0.032865172998908045
Trained batch 520 in epoch 8, gen_loss = 0.8518174165956347, disc_loss = 0.03291642213429748
Trained batch 521 in epoch 8, gen_loss = 0.8518590968230675, disc_loss = 0.032863139976850815
Trained batch 522 in epoch 8, gen_loss = 0.8521842537145086, disc_loss = 0.0328230759508224
Trained batch 523 in epoch 8, gen_loss = 0.8523526215598783, disc_loss = 0.03286347782349513
Trained batch 524 in epoch 8, gen_loss = 0.8524775404021854, disc_loss = 0.03281932810498845
Trained batch 525 in epoch 8, gen_loss = 0.8521218400717688, disc_loss = 0.03281257273151252
Trained batch 526 in epoch 8, gen_loss = 0.8514183364398565, disc_loss = 0.033198576299491314
Trained batch 527 in epoch 8, gen_loss = 0.8519098136122479, disc_loss = 0.03324651418193808
Trained batch 528 in epoch 8, gen_loss = 0.8517630222501736, disc_loss = 0.03328001637818091
Trained batch 529 in epoch 8, gen_loss = 0.8514772190800253, disc_loss = 0.033274571807563026
Trained batch 530 in epoch 8, gen_loss = 0.8516369168480012, disc_loss = 0.0332720158455048
Trained batch 531 in epoch 8, gen_loss = 0.8510794854141716, disc_loss = 0.03333113257006455
Trained batch 532 in epoch 8, gen_loss = 0.8506542823887229, disc_loss = 0.033402194294337655
Trained batch 533 in epoch 8, gen_loss = 0.8512225626001644, disc_loss = 0.03373631981396803
Trained batch 534 in epoch 8, gen_loss = 0.8513356029987336, disc_loss = 0.03369278708890638
Trained batch 535 in epoch 8, gen_loss = 0.8511504997401985, disc_loss = 0.03366454738216586
Trained batch 536 in epoch 8, gen_loss = 0.8511270139803434, disc_loss = 0.033646289379729626
Trained batch 537 in epoch 8, gen_loss = 0.850769088558548, disc_loss = 0.03371713493542129
Trained batch 538 in epoch 8, gen_loss = 0.850688113075904, disc_loss = 0.03374315746705668
Trained batch 539 in epoch 8, gen_loss = 0.850772764009458, disc_loss = 0.03389936280867982
Trained batch 540 in epoch 8, gen_loss = 0.8502626172826383, disc_loss = 0.0340677005868894
Trained batch 541 in epoch 8, gen_loss = 0.849862244571267, disc_loss = 0.034066589173733695
Trained batch 542 in epoch 8, gen_loss = 0.8497027600557984, disc_loss = 0.03405499723388318
Trained batch 543 in epoch 8, gen_loss = 0.849533314268817, disc_loss = 0.034068065054324345
Trained batch 544 in epoch 8, gen_loss = 0.8495695219674242, disc_loss = 0.03403855957210474
Trained batch 545 in epoch 8, gen_loss = 0.8490911137599212, disc_loss = 0.03413581515102896
Trained batch 546 in epoch 8, gen_loss = 0.849459716835667, disc_loss = 0.034500726315633855
Trained batch 547 in epoch 8, gen_loss = 0.8494214560754978, disc_loss = 0.03452082587334661
Trained batch 548 in epoch 8, gen_loss = 0.8486865919035858, disc_loss = 0.034691324134362364
Trained batch 549 in epoch 8, gen_loss = 0.8483583567901091, disc_loss = 0.03468836971219968
Trained batch 550 in epoch 8, gen_loss = 0.8481363352868172, disc_loss = 0.034723005660669284
Trained batch 551 in epoch 8, gen_loss = 0.8483878802238167, disc_loss = 0.034780853656559266
Trained batch 552 in epoch 8, gen_loss = 0.8487728364752171, disc_loss = 0.03473864594359914
Trained batch 553 in epoch 8, gen_loss = 0.8483153638103809, disc_loss = 0.03485411278052854
Trained batch 554 in epoch 8, gen_loss = 0.8484575699578535, disc_loss = 0.03488880419633813
Trained batch 555 in epoch 8, gen_loss = 0.84822616393832, disc_loss = 0.0348787588903198
Trained batch 556 in epoch 8, gen_loss = 0.8480538364693764, disc_loss = 0.035006056570646954
Trained batch 557 in epoch 8, gen_loss = 0.8481889990388706, disc_loss = 0.03495396411557111
Trained batch 558 in epoch 8, gen_loss = 0.8482267921107399, disc_loss = 0.03490995254104354
Trained batch 559 in epoch 8, gen_loss = 0.8483327770339592, disc_loss = 0.034881670103641224
Trained batch 560 in epoch 8, gen_loss = 0.8485535844868305, disc_loss = 0.03483396407578691
Trained batch 561 in epoch 8, gen_loss = 0.8483585897183503, disc_loss = 0.03480854248246874
Trained batch 562 in epoch 8, gen_loss = 0.8485777201809214, disc_loss = 0.0347737800023894
Trained batch 563 in epoch 8, gen_loss = 0.848371961596587, disc_loss = 0.03473605598894391
Trained batch 564 in epoch 8, gen_loss = 0.8484011905910694, disc_loss = 0.034878176070782724
Trained batch 565 in epoch 8, gen_loss = 0.8479439178646243, disc_loss = 0.03496326557722588
Trained batch 566 in epoch 8, gen_loss = 0.8480949101729788, disc_loss = 0.034916328229305765
Trained batch 567 in epoch 8, gen_loss = 0.8479543924856354, disc_loss = 0.03510652822163612
Trained batch 568 in epoch 8, gen_loss = 0.8477860470752515, disc_loss = 0.035100363521478245
Trained batch 569 in epoch 8, gen_loss = 0.8475718767496577, disc_loss = 0.03513321722857654
Trained batch 570 in epoch 8, gen_loss = 0.8471988568477163, disc_loss = 0.03517419260872721
Trained batch 571 in epoch 8, gen_loss = 0.847502899492954, disc_loss = 0.03516474485941153
Trained batch 572 in epoch 8, gen_loss = 0.8477905561682649, disc_loss = 0.03514101243062663
Trained batch 573 in epoch 8, gen_loss = 0.8477907861462869, disc_loss = 0.035120829257575426
Trained batch 574 in epoch 8, gen_loss = 0.8478397897533748, disc_loss = 0.03507611199322602
Trained batch 575 in epoch 8, gen_loss = 0.8479190789059632, disc_loss = 0.035021622255751735
Trained batch 576 in epoch 8, gen_loss = 0.848189506776618, disc_loss = 0.035129870093981226
Trained batch 577 in epoch 8, gen_loss = 0.8477847126012855, disc_loss = 0.03518591223527906
Trained batch 578 in epoch 8, gen_loss = 0.8476701994942878, disc_loss = 0.03513615126222926
Trained batch 579 in epoch 8, gen_loss = 0.848000239863478, disc_loss = 0.03510547778529019
Trained batch 580 in epoch 8, gen_loss = 0.8478933506598776, disc_loss = 0.035063654443620994
Trained batch 581 in epoch 8, gen_loss = 0.847715721046392, disc_loss = 0.03503764925414178
Trained batch 582 in epoch 8, gen_loss = 0.8477417056290608, disc_loss = 0.035022706163593445
Trained batch 583 in epoch 8, gen_loss = 0.8473709605838338, disc_loss = 0.03505321847847408
Trained batch 584 in epoch 8, gen_loss = 0.847540429361865, disc_loss = 0.03501812291220149
Trained batch 585 in epoch 8, gen_loss = 0.8480510710144206, disc_loss = 0.03514945949785373
Trained batch 586 in epoch 8, gen_loss = 0.8477852435392254, disc_loss = 0.035162907293275814
Trained batch 587 in epoch 8, gen_loss = 0.8475848399356108, disc_loss = 0.03516558314741709
Trained batch 588 in epoch 8, gen_loss = 0.8475535063164749, disc_loss = 0.03511700775048969
Trained batch 589 in epoch 8, gen_loss = 0.8478763533345723, disc_loss = 0.03508043184647558
Trained batch 590 in epoch 8, gen_loss = 0.8476224372733869, disc_loss = 0.03526705757134898
Trained batch 591 in epoch 8, gen_loss = 0.8473542571772594, disc_loss = 0.03525373008931244
Trained batch 592 in epoch 8, gen_loss = 0.8473359098623414, disc_loss = 0.03520825059501797
Trained batch 593 in epoch 8, gen_loss = 0.8477688393107167, disc_loss = 0.035189227946964954
Trained batch 594 in epoch 8, gen_loss = 0.8477743945702785, disc_loss = 0.03530634047753107
Trained batch 595 in epoch 8, gen_loss = 0.847278976150407, disc_loss = 0.03564337518139611
Trained batch 596 in epoch 8, gen_loss = 0.8473811368746573, disc_loss = 0.03566864961828456
Trained batch 597 in epoch 8, gen_loss = 0.8472070719386423, disc_loss = 0.03571459278736862
Trained batch 598 in epoch 8, gen_loss = 0.8471527136924469, disc_loss = 0.03576795961078138
Trained batch 599 in epoch 8, gen_loss = 0.8469713614881038, disc_loss = 0.035792434609417494
Trained batch 600 in epoch 8, gen_loss = 0.8468562882771706, disc_loss = 0.03576667334368381
Trained batch 601 in epoch 8, gen_loss = 0.8468503661428971, disc_loss = 0.035751881260050467
Trained batch 602 in epoch 8, gen_loss = 0.8471815232712634, disc_loss = 0.03572978335046588
Trained batch 603 in epoch 8, gen_loss = 0.847052450853073, disc_loss = 0.03581787706221707
Trained batch 604 in epoch 8, gen_loss = 0.8469189433519505, disc_loss = 0.03581143344814065
Trained batch 605 in epoch 8, gen_loss = 0.8470956624636162, disc_loss = 0.03585845948137011
Trained batch 606 in epoch 8, gen_loss = 0.8469973004728408, disc_loss = 0.03582682792224677
Trained batch 607 in epoch 8, gen_loss = 0.8468526492483521, disc_loss = 0.035796704134937546
Trained batch 608 in epoch 8, gen_loss = 0.8468462428925269, disc_loss = 0.03575484381953471
Trained batch 609 in epoch 8, gen_loss = 0.8470447687340564, disc_loss = 0.03570919560352493
Trained batch 610 in epoch 8, gen_loss = 0.8467374412303276, disc_loss = 0.035697714477067176
Trained batch 611 in epoch 8, gen_loss = 0.8472351142101817, disc_loss = 0.035720955399002004
Trained batch 612 in epoch 8, gen_loss = 0.8472273871424147, disc_loss = 0.03624976035108756
Trained batch 613 in epoch 8, gen_loss = 0.8464576194263048, disc_loss = 0.03669996490567037
Trained batch 614 in epoch 8, gen_loss = 0.8463350896912861, disc_loss = 0.03667598346861579
Trained batch 615 in epoch 8, gen_loss = 0.8464105432103206, disc_loss = 0.03668632458815315
Trained batch 616 in epoch 8, gen_loss = 0.8465484334352144, disc_loss = 0.036644779421567214
Trained batch 617 in epoch 8, gen_loss = 0.8466859013324417, disc_loss = 0.03659835766848707
Trained batch 618 in epoch 8, gen_loss = 0.8467379930716532, disc_loss = 0.03654667008058837
Trained batch 619 in epoch 8, gen_loss = 0.8468458466952847, disc_loss = 0.036494671239051965
Trained batch 620 in epoch 8, gen_loss = 0.8466879083338567, disc_loss = 0.03647442803727148
Trained batch 621 in epoch 8, gen_loss = 0.8465094388106245, disc_loss = 0.03643223330029661
Trained batch 622 in epoch 8, gen_loss = 0.8466198706512084, disc_loss = 0.0363866023246175
Trained batch 623 in epoch 8, gen_loss = 0.8466175137422024, disc_loss = 0.03645967801201504
Trained batch 624 in epoch 8, gen_loss = 0.846306877708435, disc_loss = 0.03649809245280922
Trained batch 625 in epoch 8, gen_loss = 0.8456956902251076, disc_loss = 0.03664326552746478
Trained batch 626 in epoch 8, gen_loss = 0.8461942286772781, disc_loss = 0.03665765542262182
Trained batch 627 in epoch 8, gen_loss = 0.8463582652769271, disc_loss = 0.03663308277635711
Trained batch 628 in epoch 8, gen_loss = 0.8463696661169844, disc_loss = 0.03658908182371627
Trained batch 629 in epoch 8, gen_loss = 0.8462065603051867, disc_loss = 0.03655864857691562
Trained batch 630 in epoch 8, gen_loss = 0.8461746295733988, disc_loss = 0.03651508359015637
Trained batch 631 in epoch 8, gen_loss = 0.8462973125750506, disc_loss = 0.03649490205622632
Trained batch 632 in epoch 8, gen_loss = 0.8462042943184598, disc_loss = 0.036459811680286676
Trained batch 633 in epoch 8, gen_loss = 0.8457864025601829, disc_loss = 0.036850557437428044
Trained batch 634 in epoch 8, gen_loss = 0.8456381667317368, disc_loss = 0.03683258080745013
Trained batch 635 in epoch 8, gen_loss = 0.8455162187979656, disc_loss = 0.036821269176522585
Trained batch 636 in epoch 8, gen_loss = 0.8454525225577961, disc_loss = 0.036811610573779914
Trained batch 637 in epoch 8, gen_loss = 0.8456372444906205, disc_loss = 0.03678139172849131
Trained batch 638 in epoch 8, gen_loss = 0.84580286175992, disc_loss = 0.03685940908018867
Trained batch 639 in epoch 8, gen_loss = 0.8455161112360656, disc_loss = 0.036870069590440833
Trained batch 640 in epoch 8, gen_loss = 0.8454823766409328, disc_loss = 0.03685124186318013
Trained batch 641 in epoch 8, gen_loss = 0.8453291590525726, disc_loss = 0.037117882360083364
Trained batch 642 in epoch 8, gen_loss = 0.8450139697009631, disc_loss = 0.03721232686016541
Trained batch 643 in epoch 8, gen_loss = 0.8449286389054719, disc_loss = 0.03718330290115016
Trained batch 644 in epoch 8, gen_loss = 0.8447279697240785, disc_loss = 0.03720095526795228
Trained batch 645 in epoch 8, gen_loss = 0.8447768630996209, disc_loss = 0.03734502940901466
Trained batch 646 in epoch 8, gen_loss = 0.8446207768766, disc_loss = 0.03733959590902457
Trained batch 647 in epoch 8, gen_loss = 0.844767963812675, disc_loss = 0.037309294464109743
Trained batch 648 in epoch 8, gen_loss = 0.8448377873386917, disc_loss = 0.03727109692179998
Trained batch 649 in epoch 8, gen_loss = 0.8444179212130033, disc_loss = 0.03756793284466347
Trained batch 650 in epoch 8, gen_loss = 0.8445701550595038, disc_loss = 0.037528171278064223
Trained batch 651 in epoch 8, gen_loss = 0.8442367845517726, disc_loss = 0.03751969099311912
Trained batch 652 in epoch 8, gen_loss = 0.8440798463536623, disc_loss = 0.03748248315239425
Trained batch 653 in epoch 8, gen_loss = 0.8438271613113741, disc_loss = 0.037482448408895655
Trained batch 654 in epoch 8, gen_loss = 0.8440745443788193, disc_loss = 0.03756484781420356
Trained batch 655 in epoch 8, gen_loss = 0.8437600956275696, disc_loss = 0.03757933759742428
Trained batch 656 in epoch 8, gen_loss = 0.843764579550135, disc_loss = 0.03753408784779636
Trained batch 657 in epoch 8, gen_loss = 0.8438106292468074, disc_loss = 0.03749365758081462
Trained batch 658 in epoch 8, gen_loss = 0.8435794885675896, disc_loss = 0.03750605625665728
Trained batch 659 in epoch 8, gen_loss = 0.8436349375681443, disc_loss = 0.03747075871162286
Trained batch 660 in epoch 8, gen_loss = 0.8436040519405602, disc_loss = 0.037442229214404765
Trained batch 661 in epoch 8, gen_loss = 0.8438856960063255, disc_loss = 0.03740530352852395
Trained batch 662 in epoch 8, gen_loss = 0.8441271366576804, disc_loss = 0.037357842889972605
Trained batch 663 in epoch 8, gen_loss = 0.8442578782518226, disc_loss = 0.037345029060597
Trained batch 664 in epoch 8, gen_loss = 0.8440970924563874, disc_loss = 0.037329022609103556
Trained batch 665 in epoch 8, gen_loss = 0.843897617794014, disc_loss = 0.03736833055670074
Trained batch 666 in epoch 8, gen_loss = 0.8439500649114777, disc_loss = 0.03734178382608721
Trained batch 667 in epoch 8, gen_loss = 0.8442503266527267, disc_loss = 0.037325420891266586
Trained batch 668 in epoch 8, gen_loss = 0.8441253590476887, disc_loss = 0.03729025224573153
Trained batch 669 in epoch 8, gen_loss = 0.8439985375795791, disc_loss = 0.03725267280511725
Trained batch 670 in epoch 8, gen_loss = 0.8437334980410364, disc_loss = 0.037321423408374105
Trained batch 671 in epoch 8, gen_loss = 0.843867461951006, disc_loss = 0.03728323457159734
Trained batch 672 in epoch 8, gen_loss = 0.8437328064069706, disc_loss = 0.03726544779348969
Trained batch 673 in epoch 8, gen_loss = 0.844278523936116, disc_loss = 0.03729866781287194
Trained batch 674 in epoch 8, gen_loss = 0.8445250018437703, disc_loss = 0.03727070838661382
Trained batch 675 in epoch 8, gen_loss = 0.8443907522238218, disc_loss = 0.0372533773629342
Trained batch 676 in epoch 8, gen_loss = 0.8442480604616894, disc_loss = 0.03722127591001153
Trained batch 677 in epoch 8, gen_loss = 0.8442013179306436, disc_loss = 0.037179982355949645
Trained batch 678 in epoch 8, gen_loss = 0.8449150062274512, disc_loss = 0.03721409497901918
Trained batch 679 in epoch 8, gen_loss = 0.8452557821484173, disc_loss = 0.03718884494737722
Trained batch 680 in epoch 8, gen_loss = 0.8451677527546707, disc_loss = 0.0371752791602449
Trained batch 681 in epoch 8, gen_loss = 0.8449687056702253, disc_loss = 0.037152278944754376
Trained batch 682 in epoch 8, gen_loss = 0.8451024331425154, disc_loss = 0.03710624404861094
Trained batch 683 in epoch 8, gen_loss = 0.8449764627287959, disc_loss = 0.03723353180695292
Trained batch 684 in epoch 8, gen_loss = 0.8450169604190074, disc_loss = 0.03719168350909476
Trained batch 685 in epoch 8, gen_loss = 0.844814912310147, disc_loss = 0.03716232377931247
Trained batch 686 in epoch 8, gen_loss = 0.8447298542901418, disc_loss = 0.0371381259157988
Trained batch 687 in epoch 8, gen_loss = 0.844468234323485, disc_loss = 0.03721897803662551
Trained batch 688 in epoch 8, gen_loss = 0.844854752885932, disc_loss = 0.03727904002517408
Trained batch 689 in epoch 8, gen_loss = 0.8448542552581731, disc_loss = 0.0372850856092502
Trained batch 690 in epoch 8, gen_loss = 0.8448791635881802, disc_loss = 0.037241419127302625
Trained batch 691 in epoch 8, gen_loss = 0.8445970801948812, disc_loss = 0.03726242928371382
Trained batch 692 in epoch 8, gen_loss = 0.8445530889010189, disc_loss = 0.03721577631246465
Trained batch 693 in epoch 8, gen_loss = 0.8446666011720981, disc_loss = 0.03717030859881105
Trained batch 694 in epoch 8, gen_loss = 0.8445102528702441, disc_loss = 0.03720534416753129
Trained batch 695 in epoch 8, gen_loss = 0.8444280636379089, disc_loss = 0.03719857966376137
Trained batch 696 in epoch 8, gen_loss = 0.8442786232470781, disc_loss = 0.037193744805129714
Trained batch 697 in epoch 8, gen_loss = 0.8446676997537258, disc_loss = 0.0371972978682815
Trained batch 698 in epoch 8, gen_loss = 0.84495483788639, disc_loss = 0.03717078275156496
Trained batch 699 in epoch 8, gen_loss = 0.8449919319152832, disc_loss = 0.03714542839908972
Trained batch 700 in epoch 8, gen_loss = 0.8449092264182217, disc_loss = 0.037102067677341345
Trained batch 701 in epoch 8, gen_loss = 0.8447781995660559, disc_loss = 0.03709172030699909
Trained batch 702 in epoch 8, gen_loss = 0.8450851261530967, disc_loss = 0.0370547677768503
Trained batch 703 in epoch 8, gen_loss = 0.8450258137150244, disc_loss = 0.037024575325631304
Trained batch 704 in epoch 8, gen_loss = 0.8449300294226788, disc_loss = 0.03699425155369578
Trained batch 705 in epoch 8, gen_loss = 0.8448779761115822, disc_loss = 0.03721748687961421
Trained batch 706 in epoch 8, gen_loss = 0.844675498349326, disc_loss = 0.03720424721864496
Trained batch 707 in epoch 8, gen_loss = 0.8447304226584353, disc_loss = 0.037172346615619266
Trained batch 708 in epoch 8, gen_loss = 0.8448881589307099, disc_loss = 0.03716738937437083
Trained batch 709 in epoch 8, gen_loss = 0.8446246506462635, disc_loss = 0.03717084831630313
Trained batch 710 in epoch 8, gen_loss = 0.8449498255712238, disc_loss = 0.037439298574025476
Trained batch 711 in epoch 8, gen_loss = 0.8445366349782837, disc_loss = 0.03763445464958269
Trained batch 712 in epoch 8, gen_loss = 0.8442093312823923, disc_loss = 0.037734490773884834
Trained batch 713 in epoch 8, gen_loss = 0.8443748617038673, disc_loss = 0.03791992660874047
Trained batch 714 in epoch 8, gen_loss = 0.8443426789103688, disc_loss = 0.03795995937653824
Trained batch 715 in epoch 8, gen_loss = 0.8442670321664331, disc_loss = 0.037929957418106806
Trained batch 716 in epoch 8, gen_loss = 0.8443687673725676, disc_loss = 0.03793406672288652
Trained batch 717 in epoch 8, gen_loss = 0.8438758056475923, disc_loss = 0.03817140664626432
Trained batch 718 in epoch 8, gen_loss = 0.8438620754674346, disc_loss = 0.0382437622242624
Trained batch 719 in epoch 8, gen_loss = 0.8438728922771083, disc_loss = 0.03823812238438728
Trained batch 720 in epoch 8, gen_loss = 0.8434205748833168, disc_loss = 0.03836860393830181
Trained batch 721 in epoch 8, gen_loss = 0.843458054716237, disc_loss = 0.03836871753543502
Trained batch 722 in epoch 8, gen_loss = 0.8437910610049921, disc_loss = 0.03840926165671898
Trained batch 723 in epoch 8, gen_loss = 0.8435509951569099, disc_loss = 0.038447751872336684
Trained batch 724 in epoch 8, gen_loss = 0.8435774575430771, disc_loss = 0.03841539656839751
Trained batch 725 in epoch 8, gen_loss = 0.8433317538792109, disc_loss = 0.03841127203322034
Trained batch 726 in epoch 8, gen_loss = 0.8437030267846634, disc_loss = 0.038407970461008
Trained batch 727 in epoch 8, gen_loss = 0.8439981315162156, disc_loss = 0.03837371656222136
Trained batch 728 in epoch 8, gen_loss = 0.8438240566861973, disc_loss = 0.03836088869062767
Trained batch 729 in epoch 8, gen_loss = 0.8437345637850565, disc_loss = 0.03833285113190594
Trained batch 730 in epoch 8, gen_loss = 0.843858284271856, disc_loss = 0.03834378568770264
Trained batch 731 in epoch 8, gen_loss = 0.8439194042174543, disc_loss = 0.03835470909589922
Trained batch 732 in epoch 8, gen_loss = 0.8442665592222227, disc_loss = 0.038325176093064114
Trained batch 733 in epoch 8, gen_loss = 0.8440861092113994, disc_loss = 0.03832409248467819
Trained batch 734 in epoch 8, gen_loss = 0.8439431729770842, disc_loss = 0.03831365699753114
Trained batch 735 in epoch 8, gen_loss = 0.8442051434160575, disc_loss = 0.03828728913725607
Trained batch 736 in epoch 8, gen_loss = 0.8444931258825304, disc_loss = 0.038378670407595614
Trained batch 737 in epoch 8, gen_loss = 0.8441002780021367, disc_loss = 0.038453293969630084
Trained batch 738 in epoch 8, gen_loss = 0.8438091082082549, disc_loss = 0.03853570891724438
Trained batch 739 in epoch 8, gen_loss = 0.8437888408834869, disc_loss = 0.03852479502690855
Trained batch 740 in epoch 8, gen_loss = 0.8436436494674117, disc_loss = 0.03851119787356842
Trained batch 741 in epoch 8, gen_loss = 0.8436627474756575, disc_loss = 0.03849388276461532
Trained batch 742 in epoch 8, gen_loss = 0.8442819404088633, disc_loss = 0.038585256429484384
Trained batch 743 in epoch 8, gen_loss = 0.8442489500007322, disc_loss = 0.038549103535353756
Trained batch 744 in epoch 8, gen_loss = 0.8440139392878385, disc_loss = 0.03855715676698359
Trained batch 745 in epoch 8, gen_loss = 0.8441863902132888, disc_loss = 0.038558105937200264
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8061618804931641, disc_loss = 0.02625862881541252
Trained batch 1 in epoch 9, gen_loss = 0.7459238767623901, disc_loss = 0.021422643214464188
Trained batch 2 in epoch 9, gen_loss = 0.7528503934542338, disc_loss = 0.03068036089340846
Trained batch 3 in epoch 9, gen_loss = 0.805430069565773, disc_loss = 0.025342733599245548
Trained batch 4 in epoch 9, gen_loss = 0.7945388197898865, disc_loss = 0.025787417963147163
Trained batch 5 in epoch 9, gen_loss = 0.8367409408092499, disc_loss = 0.02459901322921117
Trained batch 6 in epoch 9, gen_loss = 0.8121035354478019, disc_loss = 0.02471220227224486
Trained batch 7 in epoch 9, gen_loss = 0.8203630968928337, disc_loss = 0.02241019339999184
Trained batch 8 in epoch 9, gen_loss = 0.8474801050292121, disc_loss = 0.03518776755986942
Trained batch 9 in epoch 9, gen_loss = 0.8571040451526641, disc_loss = 0.03270807131193578
Trained batch 10 in epoch 9, gen_loss = 0.8448135256767273, disc_loss = 0.03083644616840915
Trained batch 11 in epoch 9, gen_loss = 0.8341082185506821, disc_loss = 0.03077973343897611
Trained batch 12 in epoch 9, gen_loss = 0.8297005295753479, disc_loss = 0.02981601909805949
Trained batch 13 in epoch 9, gen_loss = 0.8296315329415458, disc_loss = 0.029240128018760254
Trained batch 14 in epoch 9, gen_loss = 0.8300953308741251, disc_loss = 0.030752844704935948
Trained batch 15 in epoch 9, gen_loss = 0.8270156607031822, disc_loss = 0.029446505155647174
Trained batch 16 in epoch 9, gen_loss = 0.8163826185114244, disc_loss = 0.0310602763612919
Trained batch 17 in epoch 9, gen_loss = 0.8114165431923337, disc_loss = 0.032471140562039286
Trained batch 18 in epoch 9, gen_loss = 0.8255146522271005, disc_loss = 0.03834586034185792
Trained batch 19 in epoch 9, gen_loss = 0.8263011366128922, disc_loss = 0.03699069775175303
Trained batch 20 in epoch 9, gen_loss = 0.817817557425726, disc_loss = 0.03625613732618235
Trained batch 21 in epoch 9, gen_loss = 0.8176290203224529, disc_loss = 0.0350675719409165
Trained batch 22 in epoch 9, gen_loss = 0.8210782901100491, disc_loss = 0.03382338366835662
Trained batch 23 in epoch 9, gen_loss = 0.8293748398621877, disc_loss = 0.03289447528853392
Trained batch 24 in epoch 9, gen_loss = 0.8213987302780151, disc_loss = 0.03369646882638335
Trained batch 25 in epoch 9, gen_loss = 0.8273648161154527, disc_loss = 0.03414835299078662
Trained batch 26 in epoch 9, gen_loss = 0.8299670440179331, disc_loss = 0.033242721714217355
Trained batch 27 in epoch 9, gen_loss = 0.8213070247854505, disc_loss = 0.036090397591968734
Trained batch 28 in epoch 9, gen_loss = 0.8254654469161198, disc_loss = 0.03881340954003149
Trained batch 29 in epoch 9, gen_loss = 0.8333409210046132, disc_loss = 0.038812113103146355
Trained batch 30 in epoch 9, gen_loss = 0.8325164644948898, disc_loss = 0.03807998615347089
Trained batch 31 in epoch 9, gen_loss = 0.8255847413092852, disc_loss = 0.040011896038777195
Trained batch 32 in epoch 9, gen_loss = 0.8302966247905385, disc_loss = 0.041823516952607664
Trained batch 33 in epoch 9, gen_loss = 0.8345585851108327, disc_loss = 0.04088804075110923
Trained batch 34 in epoch 9, gen_loss = 0.8367867537907192, disc_loss = 0.0400624292104372
Trained batch 35 in epoch 9, gen_loss = 0.8379039035903083, disc_loss = 0.04029229178559035
Trained batch 36 in epoch 9, gen_loss = 0.8321965868408615, disc_loss = 0.0412075746980672
Trained batch 37 in epoch 9, gen_loss = 0.8287321689881777, disc_loss = 0.040789647701833597
Trained batch 38 in epoch 9, gen_loss = 0.8364890737411304, disc_loss = 0.04083751971857288
Trained batch 39 in epoch 9, gen_loss = 0.839008092880249, disc_loss = 0.039958578103687616
Trained batch 40 in epoch 9, gen_loss = 0.839559265753118, disc_loss = 0.03914720185737058
Trained batch 41 in epoch 9, gen_loss = 0.8400322397549947, disc_loss = 0.038765143359168655
Trained batch 42 in epoch 9, gen_loss = 0.8394187175950338, disc_loss = 0.0383700383393917
Trained batch 43 in epoch 9, gen_loss = 0.8402070985598997, disc_loss = 0.03761611984704028
Trained batch 44 in epoch 9, gen_loss = 0.844333475165897, disc_loss = 0.03712588854961925
Trained batch 45 in epoch 9, gen_loss = 0.846750452466633, disc_loss = 0.036607841070255505
Trained batch 46 in epoch 9, gen_loss = 0.848479355903382, disc_loss = 0.03600329222117967
Trained batch 47 in epoch 9, gen_loss = 0.849445336808761, disc_loss = 0.03533457165273527
Trained batch 48 in epoch 9, gen_loss = 0.8541861298132916, disc_loss = 0.03486032428562033
Trained batch 49 in epoch 9, gen_loss = 0.855042679309845, disc_loss = 0.03427557172253728
Trained batch 50 in epoch 9, gen_loss = 0.8536170230192297, disc_loss = 0.03401331422740922
Trained batch 51 in epoch 9, gen_loss = 0.8553622685945951, disc_loss = 0.03345763423623374
Trained batch 52 in epoch 9, gen_loss = 0.856945313372702, disc_loss = 0.033103223011459945
Trained batch 53 in epoch 9, gen_loss = 0.8558732547141887, disc_loss = 0.032597110968910985
Trained batch 54 in epoch 9, gen_loss = 0.8562080231579867, disc_loss = 0.0321867559613152
Trained batch 55 in epoch 9, gen_loss = 0.8576433296714511, disc_loss = 0.03174178517656401
Trained batch 56 in epoch 9, gen_loss = 0.8570470977247807, disc_loss = 0.03141487764782811
Trained batch 57 in epoch 9, gen_loss = 0.8597147958032016, disc_loss = 0.031151834192910587
Trained batch 58 in epoch 9, gen_loss = 0.8622121285584013, disc_loss = 0.031008774154203927
Trained batch 59 in epoch 9, gen_loss = 0.8618565698464712, disc_loss = 0.030656417389400302
Trained batch 60 in epoch 9, gen_loss = 0.8615558245142952, disc_loss = 0.030629469623758655
Trained batch 61 in epoch 9, gen_loss = 0.8578709536983121, disc_loss = 0.031253342328953646
Trained batch 62 in epoch 9, gen_loss = 0.8623868321615552, disc_loss = 0.031095042314735196
Trained batch 63 in epoch 9, gen_loss = 0.8637021882459521, disc_loss = 0.031157800192886498
Trained batch 64 in epoch 9, gen_loss = 0.8652647981276879, disc_loss = 0.030832623640218607
Trained batch 65 in epoch 9, gen_loss = 0.8645333783193068, disc_loss = 0.03053064687375092
Trained batch 66 in epoch 9, gen_loss = 0.8627216353345273, disc_loss = 0.03033108990500445
Trained batch 67 in epoch 9, gen_loss = 0.8639099571634742, disc_loss = 0.02995385621975669
Trained batch 68 in epoch 9, gen_loss = 0.8643803544666456, disc_loss = 0.029610394864626553
Trained batch 69 in epoch 9, gen_loss = 0.8635438748768398, disc_loss = 0.029366703278252058
Trained batch 70 in epoch 9, gen_loss = 0.865125726646101, disc_loss = 0.029066367822528725
Trained batch 71 in epoch 9, gen_loss = 0.8670980549520917, disc_loss = 0.028781566755949624
Trained batch 72 in epoch 9, gen_loss = 0.8676561362122837, disc_loss = 0.028529113426498356
Trained batch 73 in epoch 9, gen_loss = 0.8668133568119358, disc_loss = 0.028231401241862693
Trained batch 74 in epoch 9, gen_loss = 0.866912145614624, disc_loss = 0.028084479986379543
Trained batch 75 in epoch 9, gen_loss = 0.8655754594426406, disc_loss = 0.027803555406679056
Trained batch 76 in epoch 9, gen_loss = 0.863339762409012, disc_loss = 0.027791244721693264
Trained batch 77 in epoch 9, gen_loss = 0.8616095116505256, disc_loss = 0.027541100674380477
Trained batch 78 in epoch 9, gen_loss = 0.8633256071730505, disc_loss = 0.02727543432383409
Trained batch 79 in epoch 9, gen_loss = 0.8642063073813915, disc_loss = 0.027120739821111784
Trained batch 80 in epoch 9, gen_loss = 0.862806600553018, disc_loss = 0.026914110953379193
Trained batch 81 in epoch 9, gen_loss = 0.8621043293941312, disc_loss = 0.02670026170203417
Trained batch 82 in epoch 9, gen_loss = 0.8631717526769064, disc_loss = 0.026460049421447945
Trained batch 83 in epoch 9, gen_loss = 0.86172673531941, disc_loss = 0.026281135982745105
Trained batch 84 in epoch 9, gen_loss = 0.8605519287726459, disc_loss = 0.02614154212505502
Trained batch 85 in epoch 9, gen_loss = 0.8613615819188052, disc_loss = 0.026003043356806387
Trained batch 86 in epoch 9, gen_loss = 0.8605176450192243, disc_loss = 0.026929056544884526
Trained batch 87 in epoch 9, gen_loss = 0.8589903664859858, disc_loss = 0.02680302254157141
Trained batch 88 in epoch 9, gen_loss = 0.8602110428756542, disc_loss = 0.026608439732677815
Trained batch 89 in epoch 9, gen_loss = 0.8622721367412143, disc_loss = 0.02645021331910458
Trained batch 90 in epoch 9, gen_loss = 0.8604918056791955, disc_loss = 0.026497930846084934
Trained batch 91 in epoch 9, gen_loss = 0.8598746663850286, disc_loss = 0.02633889595998208
Trained batch 92 in epoch 9, gen_loss = 0.8601701842841282, disc_loss = 0.02652017421199269
Trained batch 93 in epoch 9, gen_loss = 0.8583285998790822, disc_loss = 0.026727466878699178
Trained batch 94 in epoch 9, gen_loss = 0.8601389244983071, disc_loss = 0.02670473293156216
Trained batch 95 in epoch 9, gen_loss = 0.8599427019556364, disc_loss = 0.02651838608532368
Trained batch 96 in epoch 9, gen_loss = 0.8607787612787227, disc_loss = 0.02630516845425687
Trained batch 97 in epoch 9, gen_loss = 0.8600192015268364, disc_loss = 0.02612422664212633
Trained batch 98 in epoch 9, gen_loss = 0.8616291868566263, disc_loss = 0.025952532473537657
Trained batch 99 in epoch 9, gen_loss = 0.8604033976793289, disc_loss = 0.026057423688471318
Trained batch 100 in epoch 9, gen_loss = 0.8629907906645595, disc_loss = 0.026302565405569453
Trained batch 101 in epoch 9, gen_loss = 0.8643446956195083, disc_loss = 0.029333126859045495
Trained batch 102 in epoch 9, gen_loss = 0.8616243375157847, disc_loss = 0.029901808941537895
Trained batch 103 in epoch 9, gen_loss = 0.857620823268707, disc_loss = 0.03219249246355433
Trained batch 104 in epoch 9, gen_loss = 0.8613859647796267, disc_loss = 0.034241422620557606
Trained batch 105 in epoch 9, gen_loss = 0.8607504193512898, disc_loss = 0.034543370195436025
Trained batch 106 in epoch 9, gen_loss = 0.8587419658063729, disc_loss = 0.03471326977710858
Trained batch 107 in epoch 9, gen_loss = 0.8587601521500835, disc_loss = 0.03454998665040842
Trained batch 108 in epoch 9, gen_loss = 0.8582458435942274, disc_loss = 0.03440621961762599
Trained batch 109 in epoch 9, gen_loss = 0.8579419835047288, disc_loss = 0.03417847612026063
Trained batch 110 in epoch 9, gen_loss = 0.8584186413266637, disc_loss = 0.033996372324255134
Trained batch 111 in epoch 9, gen_loss = 0.8584797520722661, disc_loss = 0.03373923881528234
Trained batch 112 in epoch 9, gen_loss = 0.8581537272022889, disc_loss = 0.03349711033062334
Trained batch 113 in epoch 9, gen_loss = 0.8585077095450017, disc_loss = 0.037519662453090415
Trained batch 114 in epoch 9, gen_loss = 0.8561846992243891, disc_loss = 0.03807140698089548
Trained batch 115 in epoch 9, gen_loss = 0.8544339126554029, disc_loss = 0.03800020899206143
Trained batch 116 in epoch 9, gen_loss = 0.8517012107066619, disc_loss = 0.0384363609039758
Trained batch 117 in epoch 9, gen_loss = 0.8523103039143449, disc_loss = 0.03849672070720186
Trained batch 118 in epoch 9, gen_loss = 0.8533296254502625, disc_loss = 0.03834105891120784
Trained batch 119 in epoch 9, gen_loss = 0.8504607950647672, disc_loss = 0.03898442854018261
Trained batch 120 in epoch 9, gen_loss = 0.8494437632481914, disc_loss = 0.03920461108892664
Trained batch 121 in epoch 9, gen_loss = 0.8487899015184308, disc_loss = 0.03920373831280186
Trained batch 122 in epoch 9, gen_loss = 0.8470726614075947, disc_loss = 0.0394003679370129
Trained batch 123 in epoch 9, gen_loss = 0.8488084048994126, disc_loss = 0.039548674605846885
Trained batch 124 in epoch 9, gen_loss = 0.8464450922012329, disc_loss = 0.03983796376734972
Trained batch 125 in epoch 9, gen_loss = 0.8451694883997478, disc_loss = 0.040090876978836835
Trained batch 126 in epoch 9, gen_loss = 0.8434202525559373, disc_loss = 0.04042348383713191
Trained batch 127 in epoch 9, gen_loss = 0.8450132315047085, disc_loss = 0.04061738815653371
Trained batch 128 in epoch 9, gen_loss = 0.8447208834248919, disc_loss = 0.04041372835202966
Trained batch 129 in epoch 9, gen_loss = 0.844407510298949, disc_loss = 0.04020710186316417
Trained batch 130 in epoch 9, gen_loss = 0.8460723894243022, disc_loss = 0.04008305465219585
Trained batch 131 in epoch 9, gen_loss = 0.8474913785854975, disc_loss = 0.04000617738700274
Trained batch 132 in epoch 9, gen_loss = 0.8478881331314718, disc_loss = 0.039768969976252184
Trained batch 133 in epoch 9, gen_loss = 0.847175635508637, disc_loss = 0.03955768807721672
Trained batch 134 in epoch 9, gen_loss = 0.846427501572503, disc_loss = 0.03943123676710659
Trained batch 135 in epoch 9, gen_loss = 0.846127903636764, disc_loss = 0.039237832267056495
Trained batch 136 in epoch 9, gen_loss = 0.8456882151373981, disc_loss = 0.040309755960955235
Trained batch 137 in epoch 9, gen_loss = 0.8437901372494905, disc_loss = 0.04061109351291173
Trained batch 138 in epoch 9, gen_loss = 0.8424502585431655, disc_loss = 0.041009735986054376
Trained batch 139 in epoch 9, gen_loss = 0.8415050025497164, disc_loss = 0.04104337569858347
Trained batch 140 in epoch 9, gen_loss = 0.8411027797570465, disc_loss = 0.04097864330343321
Trained batch 141 in epoch 9, gen_loss = 0.8430737680952314, disc_loss = 0.041009746386971274
Trained batch 142 in epoch 9, gen_loss = 0.8418895631403356, disc_loss = 0.040942376153869225
Trained batch 143 in epoch 9, gen_loss = 0.8403403150538603, disc_loss = 0.041670335094547935
Trained batch 144 in epoch 9, gen_loss = 0.8399786143467344, disc_loss = 0.042339767412892707
Trained batch 145 in epoch 9, gen_loss = 0.8403616523089474, disc_loss = 0.0421228670030322
Trained batch 146 in epoch 9, gen_loss = 0.8407744899088022, disc_loss = 0.04189385237412996
Trained batch 147 in epoch 9, gen_loss = 0.8407287259359617, disc_loss = 0.044202367164748346
Trained batch 148 in epoch 9, gen_loss = 0.8381268142053745, disc_loss = 0.04547524389079553
Trained batch 149 in epoch 9, gen_loss = 0.8382995931307474, disc_loss = 0.04526794866348306
Trained batch 150 in epoch 9, gen_loss = 0.838759526906424, disc_loss = 0.045024330215836995
Trained batch 151 in epoch 9, gen_loss = 0.8393479746423269, disc_loss = 0.044816373467543406
Trained batch 152 in epoch 9, gen_loss = 0.8390761808632246, disc_loss = 0.044625932935114
Trained batch 153 in epoch 9, gen_loss = 0.8397227219946972, disc_loss = 0.04448194206728564
Trained batch 154 in epoch 9, gen_loss = 0.8393337630456493, disc_loss = 0.04424887485802174
Trained batch 155 in epoch 9, gen_loss = 0.8388946572175393, disc_loss = 0.04401914801639624
Trained batch 156 in epoch 9, gen_loss = 0.8387272794535205, disc_loss = 0.0438435155613597
Trained batch 157 in epoch 9, gen_loss = 0.8386955446080316, disc_loss = 0.04366107289148848
Trained batch 158 in epoch 9, gen_loss = 0.8386023580653112, disc_loss = 0.04341132661222287
Trained batch 159 in epoch 9, gen_loss = 0.8388161417096853, disc_loss = 0.04319297788897529
Trained batch 160 in epoch 9, gen_loss = 0.8391804891343443, disc_loss = 0.042955776939735464
Trained batch 161 in epoch 9, gen_loss = 0.839271914075922, disc_loss = 0.04272662135944874
Trained batch 162 in epoch 9, gen_loss = 0.8396353663111026, disc_loss = 0.04248945073915954
Trained batch 163 in epoch 9, gen_loss = 0.8399128005272005, disc_loss = 0.04226494460400739
Trained batch 164 in epoch 9, gen_loss = 0.8399022806774487, disc_loss = 0.042088933952265616
Trained batch 165 in epoch 9, gen_loss = 0.8396102466497076, disc_loss = 0.04199283045761467
Trained batch 166 in epoch 9, gen_loss = 0.84068344560212, disc_loss = 0.04188206645487222
Trained batch 167 in epoch 9, gen_loss = 0.8408439893807683, disc_loss = 0.04174027473033805
Trained batch 168 in epoch 9, gen_loss = 0.8413866229311249, disc_loss = 0.04152810478516849
Trained batch 169 in epoch 9, gen_loss = 0.8422275672940647, disc_loss = 0.04132828565095278
Trained batch 170 in epoch 9, gen_loss = 0.8423894832008764, disc_loss = 0.0411433656890577
Trained batch 171 in epoch 9, gen_loss = 0.8422520780979201, disc_loss = 0.04093860666440843
Trained batch 172 in epoch 9, gen_loss = 0.8434291516425293, disc_loss = 0.04075529710039755
Trained batch 173 in epoch 9, gen_loss = 0.8433384186234968, disc_loss = 0.040571231453882896
Trained batch 174 in epoch 9, gen_loss = 0.8434534137589591, disc_loss = 0.040370188022830655
Trained batch 175 in epoch 9, gen_loss = 0.843319892544638, disc_loss = 0.04019491871109825
Trained batch 176 in epoch 9, gen_loss = 0.8429426254525696, disc_loss = 0.04003735768245691
Trained batch 177 in epoch 9, gen_loss = 0.8427688610017969, disc_loss = 0.039886643903413684
Trained batch 178 in epoch 9, gen_loss = 0.8429108338649046, disc_loss = 0.03974930074992043
Trained batch 179 in epoch 9, gen_loss = 0.8434131387207243, disc_loss = 0.039598902012221514
Trained batch 180 in epoch 9, gen_loss = 0.8440058975588551, disc_loss = 0.039408255216681
Trained batch 181 in epoch 9, gen_loss = 0.842805150773499, disc_loss = 0.039401362550311854
Trained batch 182 in epoch 9, gen_loss = 0.8437171630520638, disc_loss = 0.03933610896646081
Trained batch 183 in epoch 9, gen_loss = 0.8447258533990901, disc_loss = 0.0391585639217342
Trained batch 184 in epoch 9, gen_loss = 0.8453514604955106, disc_loss = 0.039014487202606495
Trained batch 185 in epoch 9, gen_loss = 0.8437390740840666, disc_loss = 0.03928009960650196
Trained batch 186 in epoch 9, gen_loss = 0.843589958341364, disc_loss = 0.03913303115280634
Trained batch 187 in epoch 9, gen_loss = 0.8445093045209316, disc_loss = 0.03905585890962802
Trained batch 188 in epoch 9, gen_loss = 0.8446841239929199, disc_loss = 0.038888979370572736
Trained batch 189 in epoch 9, gen_loss = 0.8444984536421927, disc_loss = 0.03874509626950481
Trained batch 190 in epoch 9, gen_loss = 0.844809726894838, disc_loss = 0.03865265304281215
Trained batch 191 in epoch 9, gen_loss = 0.8452709062645832, disc_loss = 0.0384755307653298
Trained batch 192 in epoch 9, gen_loss = 0.8448232418514904, disc_loss = 0.0383300317615425
Trained batch 193 in epoch 9, gen_loss = 0.8450134943441018, disc_loss = 0.03817078898680041
Trained batch 194 in epoch 9, gen_loss = 0.8459885670588567, disc_loss = 0.03803014387734807
Trained batch 195 in epoch 9, gen_loss = 0.8467851056128132, disc_loss = 0.037895241003882675
Trained batch 196 in epoch 9, gen_loss = 0.8460439377024694, disc_loss = 0.03776381078984607
Trained batch 197 in epoch 9, gen_loss = 0.8471107175855925, disc_loss = 0.038153958603307
Trained batch 198 in epoch 9, gen_loss = 0.845593379969573, disc_loss = 0.0390101955880659
Trained batch 199 in epoch 9, gen_loss = 0.8463616460561753, disc_loss = 0.038941509604919704
Trained batch 200 in epoch 9, gen_loss = 0.8467326956008797, disc_loss = 0.03879513041769613
Trained batch 201 in epoch 9, gen_loss = 0.8469309299299033, disc_loss = 0.03862536056105527
Trained batch 202 in epoch 9, gen_loss = 0.8470171860286168, disc_loss = 0.03845844547415675
Trained batch 203 in epoch 9, gen_loss = 0.8474356885634217, disc_loss = 0.038301163067694245
Trained batch 204 in epoch 9, gen_loss = 0.8480145143299568, disc_loss = 0.03817901004151237
Trained batch 205 in epoch 9, gen_loss = 0.8482359766381459, disc_loss = 0.03802037568428346
Trained batch 206 in epoch 9, gen_loss = 0.8481878500053848, disc_loss = 0.03788144691455839
Trained batch 207 in epoch 9, gen_loss = 0.8478904082798041, disc_loss = 0.037744600363881685
Trained batch 208 in epoch 9, gen_loss = 0.8482647923191199, disc_loss = 0.03759600184679602
Trained batch 209 in epoch 9, gen_loss = 0.8488186492806389, disc_loss = 0.037442503559092684
Trained batch 210 in epoch 9, gen_loss = 0.8488576725760907, disc_loss = 0.03728091876216727
Trained batch 211 in epoch 9, gen_loss = 0.8488279167773589, disc_loss = 0.03719545796816676
Trained batch 212 in epoch 9, gen_loss = 0.8488908790646584, disc_loss = 0.03711483198733992
Trained batch 213 in epoch 9, gen_loss = 0.8484965752218371, disc_loss = 0.03708419846653695
Trained batch 214 in epoch 9, gen_loss = 0.848584609253462, disc_loss = 0.036956289212414346
Trained batch 215 in epoch 9, gen_loss = 0.8479416138596005, disc_loss = 0.036905945857547015
Trained batch 216 in epoch 9, gen_loss = 0.8482881410880023, disc_loss = 0.03676510420370383
Trained batch 217 in epoch 9, gen_loss = 0.8491133741282542, disc_loss = 0.03665483001418788
Trained batch 218 in epoch 9, gen_loss = 0.8502440686639585, disc_loss = 0.03726013266847184
Trained batch 219 in epoch 9, gen_loss = 0.8495659866116264, disc_loss = 0.037273518081796776
Trained batch 220 in epoch 9, gen_loss = 0.8483408066482027, disc_loss = 0.03761634084067362
Trained batch 221 in epoch 9, gen_loss = 0.848343660971066, disc_loss = 0.03750255044553899
Trained batch 222 in epoch 9, gen_loss = 0.8487703845639935, disc_loss = 0.037377812904869565
Trained batch 223 in epoch 9, gen_loss = 0.849060658365488, disc_loss = 0.03727086560372429
Trained batch 224 in epoch 9, gen_loss = 0.8485326512654623, disc_loss = 0.03759150763456192
Trained batch 225 in epoch 9, gen_loss = 0.8500571082123612, disc_loss = 0.03755396527168135
Trained batch 226 in epoch 9, gen_loss = 0.8489969076038982, disc_loss = 0.03799563739961628
Trained batch 227 in epoch 9, gen_loss = 0.8492763173161891, disc_loss = 0.03784965074992853
Trained batch 228 in epoch 9, gen_loss = 0.8496820905843676, disc_loss = 0.03773966841867364
Trained batch 229 in epoch 9, gen_loss = 0.8504423131113467, disc_loss = 0.03780330267593102
Trained batch 230 in epoch 9, gen_loss = 0.8500490214401509, disc_loss = 0.03779845470582736
Trained batch 231 in epoch 9, gen_loss = 0.8501795042177727, disc_loss = 0.03768027240133459
Trained batch 232 in epoch 9, gen_loss = 0.8498495456486812, disc_loss = 0.037564384837958625
Trained batch 233 in epoch 9, gen_loss = 0.8505575241696122, disc_loss = 0.037431988848222054
Trained batch 234 in epoch 9, gen_loss = 0.8509277493395704, disc_loss = 0.03729148249815595
Trained batch 235 in epoch 9, gen_loss = 0.8511385288784059, disc_loss = 0.03714692627446789
Trained batch 236 in epoch 9, gen_loss = 0.8510060448686785, disc_loss = 0.03711675375578179
Trained batch 237 in epoch 9, gen_loss = 0.8512590041681498, disc_loss = 0.03699685698238147
Trained batch 238 in epoch 9, gen_loss = 0.8511975115811975, disc_loss = 0.036857531638816
Trained batch 239 in epoch 9, gen_loss = 0.852369021375974, disc_loss = 0.036845662921162634
Trained batch 240 in epoch 9, gen_loss = 0.8522580832366626, disc_loss = 0.03671807540228969
Trained batch 241 in epoch 9, gen_loss = 0.8531718135865267, disc_loss = 0.03711203850078404
Trained batch 242 in epoch 9, gen_loss = 0.8525932791792317, disc_loss = 0.03718593904706401
Trained batch 243 in epoch 9, gen_loss = 0.8519488399634596, disc_loss = 0.03712483745385114
Trained batch 244 in epoch 9, gen_loss = 0.8516912496819788, disc_loss = 0.03699684756503878
Trained batch 245 in epoch 9, gen_loss = 0.8520789674627103, disc_loss = 0.037009526141616324
Trained batch 246 in epoch 9, gen_loss = 0.852082136188924, disc_loss = 0.03688313419787356
Trained batch 247 in epoch 9, gen_loss = 0.8520787971154336, disc_loss = 0.03675020199115088
Trained batch 248 in epoch 9, gen_loss = 0.852358616738913, disc_loss = 0.03662192707144502
Trained batch 249 in epoch 9, gen_loss = 0.8526037814617157, disc_loss = 0.036483848488889636
Trained batch 250 in epoch 9, gen_loss = 0.8527538092487836, disc_loss = 0.03635742367371412
Trained batch 251 in epoch 9, gen_loss = 0.8528921060145848, disc_loss = 0.036226829952774715
Trained batch 252 in epoch 9, gen_loss = 0.8528012779390388, disc_loss = 0.036162399973079795
Trained batch 253 in epoch 9, gen_loss = 0.8528481057779057, disc_loss = 0.03607730219034317
Trained batch 254 in epoch 9, gen_loss = 0.8528898073177712, disc_loss = 0.0359438166771011
Trained batch 255 in epoch 9, gen_loss = 0.8529654273297638, disc_loss = 0.03581540787308768
Trained batch 256 in epoch 9, gen_loss = 0.8532144793740506, disc_loss = 0.03569050414255795
Trained batch 257 in epoch 9, gen_loss = 0.8533189312894215, disc_loss = 0.035577937258522985
Trained batch 258 in epoch 9, gen_loss = 0.8532421480734836, disc_loss = 0.03546791545449825
Trained batch 259 in epoch 9, gen_loss = 0.8531993489999038, disc_loss = 0.035346818799511175
Trained batch 260 in epoch 9, gen_loss = 0.8523107173342358, disc_loss = 0.03536355218375494
Trained batch 261 in epoch 9, gen_loss = 0.8526477724996232, disc_loss = 0.03527132184813439
Trained batch 262 in epoch 9, gen_loss = 0.852842496601801, disc_loss = 0.035177346922726345
Trained batch 263 in epoch 9, gen_loss = 0.8526349964015412, disc_loss = 0.035060226033568724
Trained batch 264 in epoch 9, gen_loss = 0.8531072722291047, disc_loss = 0.03495261386774902
Trained batch 265 in epoch 9, gen_loss = 0.8535070784558031, disc_loss = 0.034837946694876464
Trained batch 266 in epoch 9, gen_loss = 0.8532908125763082, disc_loss = 0.034757090725479056
Trained batch 267 in epoch 9, gen_loss = 0.8539729454179308, disc_loss = 0.03467676255490575
Trained batch 268 in epoch 9, gen_loss = 0.8549043545049363, disc_loss = 0.03459917596060104
Trained batch 269 in epoch 9, gen_loss = 0.8551636711314873, disc_loss = 0.03448344926539532
Trained batch 270 in epoch 9, gen_loss = 0.8544633249954984, disc_loss = 0.03448110595568877
Trained batch 271 in epoch 9, gen_loss = 0.8546564826632247, disc_loss = 0.03438088609511718
Trained batch 272 in epoch 9, gen_loss = 0.8545565934844943, disc_loss = 0.0345234970192019
Trained batch 273 in epoch 9, gen_loss = 0.8536836572372131, disc_loss = 0.03455143502869228
Trained batch 274 in epoch 9, gen_loss = 0.8537554955482483, disc_loss = 0.034555438249795276
Trained batch 275 in epoch 9, gen_loss = 0.8544220032467358, disc_loss = 0.03450467324886552
Trained batch 276 in epoch 9, gen_loss = 0.8542972775142545, disc_loss = 0.03443201557760016
Trained batch 277 in epoch 9, gen_loss = 0.8539772558984139, disc_loss = 0.03433637456757371
Trained batch 278 in epoch 9, gen_loss = 0.8526642801086535, disc_loss = 0.03462641279373358
Trained batch 279 in epoch 9, gen_loss = 0.8533499666622707, disc_loss = 0.034598432219354436
Trained batch 280 in epoch 9, gen_loss = 0.8541920028123143, disc_loss = 0.034575162552383285
Trained batch 281 in epoch 9, gen_loss = 0.8549000198114003, disc_loss = 0.03453127605632502
Trained batch 282 in epoch 9, gen_loss = 0.8546867183156233, disc_loss = 0.034451970426602675
Trained batch 283 in epoch 9, gen_loss = 0.8543185272686918, disc_loss = 0.034380919907510965
Trained batch 284 in epoch 9, gen_loss = 0.8542027904276263, disc_loss = 0.03432370933148553
Trained batch 285 in epoch 9, gen_loss = 0.8541152391817186, disc_loss = 0.03424133836874621
Trained batch 286 in epoch 9, gen_loss = 0.8553726999186473, disc_loss = 0.03428505672359326
Trained batch 287 in epoch 9, gen_loss = 0.8562592270059718, disc_loss = 0.03427654445032305
Trained batch 288 in epoch 9, gen_loss = 0.8563056381928467, disc_loss = 0.03462509607016447
Trained batch 289 in epoch 9, gen_loss = 0.8559003386004218, disc_loss = 0.034628859827905124
Trained batch 290 in epoch 9, gen_loss = 0.8553847732003202, disc_loss = 0.03460420674926048
Trained batch 291 in epoch 9, gen_loss = 0.8552212151762557, disc_loss = 0.03455035749915349
Trained batch 292 in epoch 9, gen_loss = 0.8548643222847896, disc_loss = 0.03455941463381993
Trained batch 293 in epoch 9, gen_loss = 0.8547684550285339, disc_loss = 0.03449347423671485
Trained batch 294 in epoch 9, gen_loss = 0.8544922737751977, disc_loss = 0.03442093396354151
Trained batch 295 in epoch 9, gen_loss = 0.8537482659558993, disc_loss = 0.03446245052288538
Trained batch 296 in epoch 9, gen_loss = 0.8545581644231622, disc_loss = 0.034450570928083374
Trained batch 297 in epoch 9, gen_loss = 0.8541511369231564, disc_loss = 0.03441242125250974
Trained batch 298 in epoch 9, gen_loss = 0.853230519637615, disc_loss = 0.034649462122189806
Trained batch 299 in epoch 9, gen_loss = 0.8542461305856704, disc_loss = 0.035051055318520714
Trained batch 300 in epoch 9, gen_loss = 0.853985576336566, disc_loss = 0.035092317202960785
Trained batch 301 in epoch 9, gen_loss = 0.8536627705128778, disc_loss = 0.03521667032684539
Trained batch 302 in epoch 9, gen_loss = 0.8537653849856688, disc_loss = 0.03516032202891612
Trained batch 303 in epoch 9, gen_loss = 0.853408641721073, disc_loss = 0.035123637372683
Trained batch 304 in epoch 9, gen_loss = 0.8532945335888472, disc_loss = 0.03510846117984687
Trained batch 305 in epoch 9, gen_loss = 0.8534297592499677, disc_loss = 0.03502650541980794
Trained batch 306 in epoch 9, gen_loss = 0.8527524265481905, disc_loss = 0.03510765315197311
Trained batch 307 in epoch 9, gen_loss = 0.8535215548880688, disc_loss = 0.03518415778322
Trained batch 308 in epoch 9, gen_loss = 0.8539715671616465, disc_loss = 0.03513646040271522
Trained batch 309 in epoch 9, gen_loss = 0.8545532628413169, disc_loss = 0.035049446078107484
Trained batch 310 in epoch 9, gen_loss = 0.8544351266894693, disc_loss = 0.03501575503129979
Trained batch 311 in epoch 9, gen_loss = 0.8536078861126533, disc_loss = 0.03515591465894921
Trained batch 312 in epoch 9, gen_loss = 0.8537641445668741, disc_loss = 0.03511444473945604
Trained batch 313 in epoch 9, gen_loss = 0.853928591415381, disc_loss = 0.03504436745554517
Trained batch 314 in epoch 9, gen_loss = 0.854146256900969, disc_loss = 0.034953824348659034
Trained batch 315 in epoch 9, gen_loss = 0.8540660323975962, disc_loss = 0.03494619508642303
Trained batch 316 in epoch 9, gen_loss = 0.853712221801469, disc_loss = 0.03492550834593266
Trained batch 317 in epoch 9, gen_loss = 0.8531476720324103, disc_loss = 0.035084366242682456
Trained batch 318 in epoch 9, gen_loss = 0.8535088024169301, disc_loss = 0.035039884386420674
Trained batch 319 in epoch 9, gen_loss = 0.8543212663382291, disc_loss = 0.03521778213980724
Trained batch 320 in epoch 9, gen_loss = 0.8534957530713898, disc_loss = 0.03525753120305684
Trained batch 321 in epoch 9, gen_loss = 0.853348319945128, disc_loss = 0.03520473829826329
Trained batch 322 in epoch 9, gen_loss = 0.8527678005835589, disc_loss = 0.03528699620292398
Trained batch 323 in epoch 9, gen_loss = 0.8539813376135297, disc_loss = 0.03543762959335804
Trained batch 324 in epoch 9, gen_loss = 0.8530356368651757, disc_loss = 0.03552301246457948
Trained batch 325 in epoch 9, gen_loss = 0.8533434454648773, disc_loss = 0.03543476431639122
Trained batch 326 in epoch 9, gen_loss = 0.8528158471489536, disc_loss = 0.03538767773364685
Trained batch 327 in epoch 9, gen_loss = 0.8532035452563588, disc_loss = 0.035319458654224194
Trained batch 328 in epoch 9, gen_loss = 0.8532824606880953, disc_loss = 0.0352702375315979
Trained batch 329 in epoch 9, gen_loss = 0.8536047368338614, disc_loss = 0.035202742820238754
Trained batch 330 in epoch 9, gen_loss = 0.8531734757913203, disc_loss = 0.035176817874291916
Trained batch 331 in epoch 9, gen_loss = 0.8526579364236578, disc_loss = 0.035179585381831795
Trained batch 332 in epoch 9, gen_loss = 0.8535004728907222, disc_loss = 0.03516069677233271
Trained batch 333 in epoch 9, gen_loss = 0.8537704619818819, disc_loss = 0.03509154280126207
Trained batch 334 in epoch 9, gen_loss = 0.8542128032712794, disc_loss = 0.03538784298058877
Trained batch 335 in epoch 9, gen_loss = 0.8536575645917938, disc_loss = 0.03541259709371453
Trained batch 336 in epoch 9, gen_loss = 0.853262443393911, disc_loss = 0.03535549311749416
Trained batch 337 in epoch 9, gen_loss = 0.8528761884869909, disc_loss = 0.035315551327337574
Trained batch 338 in epoch 9, gen_loss = 0.8527683046011798, disc_loss = 0.035243765932472096
Trained batch 339 in epoch 9, gen_loss = 0.8532522126155742, disc_loss = 0.035153914099860496
Trained batch 340 in epoch 9, gen_loss = 0.8536560893757952, disc_loss = 0.03507166312627844
Trained batch 341 in epoch 9, gen_loss = 0.853499124273222, disc_loss = 0.03498426377596279
Trained batch 342 in epoch 9, gen_loss = 0.8533965686319869, disc_loss = 0.03510946699461571
Trained batch 343 in epoch 9, gen_loss = 0.8532732220929723, disc_loss = 0.035072725124760035
Trained batch 344 in epoch 9, gen_loss = 0.8531287758246712, disc_loss = 0.035057039212678436
Trained batch 345 in epoch 9, gen_loss = 0.8536833702139772, disc_loss = 0.03498743602002007
Trained batch 346 in epoch 9, gen_loss = 0.8546000727659, disc_loss = 0.03499029653471618
Trained batch 347 in epoch 9, gen_loss = 0.8544724646998548, disc_loss = 0.03495005006974178
Trained batch 348 in epoch 9, gen_loss = 0.8547685264174781, disc_loss = 0.03486890261685929
Trained batch 349 in epoch 9, gen_loss = 0.8541522913319723, disc_loss = 0.03524488605758441
Trained batch 350 in epoch 9, gen_loss = 0.8548064223381868, disc_loss = 0.035233697927612655
Trained batch 351 in epoch 9, gen_loss = 0.8550498275594278, disc_loss = 0.03515221982789543
Trained batch 352 in epoch 9, gen_loss = 0.8546280014953938, disc_loss = 0.035135627710379175
Trained batch 353 in epoch 9, gen_loss = 0.855282863823034, disc_loss = 0.035078063327687564
Trained batch 354 in epoch 9, gen_loss = 0.855579763566944, disc_loss = 0.03500093327061286
Trained batch 355 in epoch 9, gen_loss = 0.855745550956619, disc_loss = 0.034937071519134714
Trained batch 356 in epoch 9, gen_loss = 0.8556015840431556, disc_loss = 0.034861574084458856
Trained batch 357 in epoch 9, gen_loss = 0.8559735615493199, disc_loss = 0.03477567236795085
Trained batch 358 in epoch 9, gen_loss = 0.8560446558888576, disc_loss = 0.03469256168778747
Trained batch 359 in epoch 9, gen_loss = 0.8561058145430352, disc_loss = 0.03462169017552191
Trained batch 360 in epoch 9, gen_loss = 0.8560438025691173, disc_loss = 0.03453511800526685
Trained batch 361 in epoch 9, gen_loss = 0.8561476124913653, disc_loss = 0.034456825648557954
Trained batch 362 in epoch 9, gen_loss = 0.856380981354674, disc_loss = 0.034409350849631606
Trained batch 363 in epoch 9, gen_loss = 0.8562234631934009, disc_loss = 0.03432382193360744
Trained batch 364 in epoch 9, gen_loss = 0.8562543041085544, disc_loss = 0.03424909760575895
Trained batch 365 in epoch 9, gen_loss = 0.8561495663038369, disc_loss = 0.03455502292220201
Trained batch 366 in epoch 9, gen_loss = 0.856014425488194, disc_loss = 0.03450029387712296
Trained batch 367 in epoch 9, gen_loss = 0.8556746799984704, disc_loss = 0.034443852858005455
Trained batch 368 in epoch 9, gen_loss = 0.8557689711653443, disc_loss = 0.034376868793266374
Trained batch 369 in epoch 9, gen_loss = 0.8558194469761204, disc_loss = 0.034308456603714545
Trained batch 370 in epoch 9, gen_loss = 0.8556956213439572, disc_loss = 0.034257717485190686
Trained batch 371 in epoch 9, gen_loss = 0.8558506899943916, disc_loss = 0.034218038086183566
Trained batch 372 in epoch 9, gen_loss = 0.8558084244063329, disc_loss = 0.03414161013122199
Trained batch 373 in epoch 9, gen_loss = 0.8557086845132756, disc_loss = 0.03407997995263892
Trained batch 374 in epoch 9, gen_loss = 0.8562606913248698, disc_loss = 0.03401314925588667
Trained batch 375 in epoch 9, gen_loss = 0.8559468990944802, disc_loss = 0.03410468717598594
Trained batch 376 in epoch 9, gen_loss = 0.8563865872213632, disc_loss = 0.03403898206445579
Trained batch 377 in epoch 9, gen_loss = 0.8572480038360313, disc_loss = 0.03403143326951457
Trained batch 378 in epoch 9, gen_loss = 0.8577341879263403, disc_loss = 0.03395886532286561
Trained batch 379 in epoch 9, gen_loss = 0.8579446290668689, disc_loss = 0.03388480861659015
Trained batch 380 in epoch 9, gen_loss = 0.8579212240972544, disc_loss = 0.03382481571245362
Trained batch 381 in epoch 9, gen_loss = 0.8573490453016072, disc_loss = 0.033937547211437755
Trained batch 382 in epoch 9, gen_loss = 0.8571786633048294, disc_loss = 0.03389563996225654
Trained batch 383 in epoch 9, gen_loss = 0.8582004369236529, disc_loss = 0.034031924880764564
Trained batch 384 in epoch 9, gen_loss = 0.8581883853132074, disc_loss = 0.03396538076740871
Trained batch 385 in epoch 9, gen_loss = 0.8583634883319776, disc_loss = 0.0338898959896561
Trained batch 386 in epoch 9, gen_loss = 0.8584622685299363, disc_loss = 0.03381788288243115
Trained batch 387 in epoch 9, gen_loss = 0.8580579402827725, disc_loss = 0.033812728810685776
Trained batch 388 in epoch 9, gen_loss = 0.8583976771960222, disc_loss = 0.03376071450209537
Trained batch 389 in epoch 9, gen_loss = 0.8578476377022572, disc_loss = 0.03378550566147822
Trained batch 390 in epoch 9, gen_loss = 0.858103010355664, disc_loss = 0.03388593914856672
Trained batch 391 in epoch 9, gen_loss = 0.858450535000587, disc_loss = 0.033836545925753726
Trained batch 392 in epoch 9, gen_loss = 0.8586010975388777, disc_loss = 0.03389242553962608
Trained batch 393 in epoch 9, gen_loss = 0.8581166222010772, disc_loss = 0.03389188619791459
Trained batch 394 in epoch 9, gen_loss = 0.8579098530962498, disc_loss = 0.03383766360333355
Trained batch 395 in epoch 9, gen_loss = 0.857463937064614, disc_loss = 0.03380082064541057
Trained batch 396 in epoch 9, gen_loss = 0.8577289866560353, disc_loss = 0.0337295037962881
Trained batch 397 in epoch 9, gen_loss = 0.8579910180377002, disc_loss = 0.03368457522531082
Trained batch 398 in epoch 9, gen_loss = 0.8580878191723262, disc_loss = 0.03362758353733012
Trained batch 399 in epoch 9, gen_loss = 0.8581766383349896, disc_loss = 0.033565738440374845
Trained batch 400 in epoch 9, gen_loss = 0.8583734444251976, disc_loss = 0.03350839907584475
Trained batch 401 in epoch 9, gen_loss = 0.8582390938232194, disc_loss = 0.033438295141599184
Trained batch 402 in epoch 9, gen_loss = 0.8587135046942358, disc_loss = 0.03340458658422175
Trained batch 403 in epoch 9, gen_loss = 0.8583929301193445, disc_loss = 0.033388011242230745
Trained batch 404 in epoch 9, gen_loss = 0.8584170367982652, disc_loss = 0.033322519738296114
Trained batch 405 in epoch 9, gen_loss = 0.8584259842416923, disc_loss = 0.0332669181493455
Trained batch 406 in epoch 9, gen_loss = 0.8584387223316352, disc_loss = 0.033232891610057005
Trained batch 407 in epoch 9, gen_loss = 0.858468707577855, disc_loss = 0.0332043731120625
Trained batch 408 in epoch 9, gen_loss = 0.8586909316279777, disc_loss = 0.03360995303550257
Trained batch 409 in epoch 9, gen_loss = 0.8578416370764012, disc_loss = 0.03389798016912054
Trained batch 410 in epoch 9, gen_loss = 0.8574820250780333, disc_loss = 0.03386214711145926
Trained batch 411 in epoch 9, gen_loss = 0.8577595288024366, disc_loss = 0.03386233183973496
Trained batch 412 in epoch 9, gen_loss = 0.8577476568141226, disc_loss = 0.03387262385629442
Trained batch 413 in epoch 9, gen_loss = 0.8577481156961929, disc_loss = 0.03383943061333078
Trained batch 414 in epoch 9, gen_loss = 0.8573510158492859, disc_loss = 0.03384578768220023
Trained batch 415 in epoch 9, gen_loss = 0.8574847700790718, disc_loss = 0.03378122515893595
Trained batch 416 in epoch 9, gen_loss = 0.8579598518012524, disc_loss = 0.03375266515761525
Trained batch 417 in epoch 9, gen_loss = 0.8578244711508591, disc_loss = 0.033691407655339026
Trained batch 418 in epoch 9, gen_loss = 0.8581382071772737, disc_loss = 0.033641431059995064
Trained batch 419 in epoch 9, gen_loss = 0.8583828642254784, disc_loss = 0.03359189904239472
Trained batch 420 in epoch 9, gen_loss = 0.8584804306970356, disc_loss = 0.033544663312754235
Trained batch 421 in epoch 9, gen_loss = 0.8583350708416853, disc_loss = 0.033503871640053653
Trained batch 422 in epoch 9, gen_loss = 0.8584088598582762, disc_loss = 0.03344950528570999
Trained batch 423 in epoch 9, gen_loss = 0.8587641396893645, disc_loss = 0.03342443934305712
Trained batch 424 in epoch 9, gen_loss = 0.8589920993412242, disc_loss = 0.03336175507865846
Trained batch 425 in epoch 9, gen_loss = 0.8588240356512473, disc_loss = 0.033331573857191266
Trained batch 426 in epoch 9, gen_loss = 0.8589077076811422, disc_loss = 0.033276357685283385
Trained batch 427 in epoch 9, gen_loss = 0.8589638818368733, disc_loss = 0.033347078019679115
Trained batch 428 in epoch 9, gen_loss = 0.8583779355862757, disc_loss = 0.03340259908550877
Trained batch 429 in epoch 9, gen_loss = 0.8584790116132692, disc_loss = 0.03334963336576123
Trained batch 430 in epoch 9, gen_loss = 0.8583505745553638, disc_loss = 0.03330344668905015
Trained batch 431 in epoch 9, gen_loss = 0.8585958954084802, disc_loss = 0.033253212066483684
Trained batch 432 in epoch 9, gen_loss = 0.858864984941813, disc_loss = 0.03322591533181075
Trained batch 433 in epoch 9, gen_loss = 0.8587928289367307, disc_loss = 0.033174747364565486
Trained batch 434 in epoch 9, gen_loss = 0.8587281856043586, disc_loss = 0.03316813062865758
Trained batch 435 in epoch 9, gen_loss = 0.8588566862115072, disc_loss = 0.03313370977705686
Trained batch 436 in epoch 9, gen_loss = 0.8587178081887811, disc_loss = 0.03308793088875166
Trained batch 437 in epoch 9, gen_loss = 0.8587971520206156, disc_loss = 0.033027584837286066
Trained batch 438 in epoch 9, gen_loss = 0.8589099190772802, disc_loss = 0.03297185186341252
Trained batch 439 in epoch 9, gen_loss = 0.8591976126486605, disc_loss = 0.0329390381087168
Trained batch 440 in epoch 9, gen_loss = 0.8589886049835049, disc_loss = 0.032910879038785354
Trained batch 441 in epoch 9, gen_loss = 0.8589801491655376, disc_loss = 0.03284633313400494
Trained batch 442 in epoch 9, gen_loss = 0.8586418764585835, disc_loss = 0.032853642688290496
Trained batch 443 in epoch 9, gen_loss = 0.8585988147570206, disc_loss = 0.03280283145654762
Trained batch 444 in epoch 9, gen_loss = 0.8586732130372122, disc_loss = 0.032739091936101236
Trained batch 445 in epoch 9, gen_loss = 0.859097937030108, disc_loss = 0.032689478348067756
Trained batch 446 in epoch 9, gen_loss = 0.8594782600466837, disc_loss = 0.032705701362045786
Trained batch 447 in epoch 9, gen_loss = 0.8596799215301871, disc_loss = 0.03265209836484116
Trained batch 448 in epoch 9, gen_loss = 0.8595197236617583, disc_loss = 0.032595575304353454
Trained batch 449 in epoch 9, gen_loss = 0.8594782072967954, disc_loss = 0.03253249710787916
Trained batch 450 in epoch 9, gen_loss = 0.859580214166324, disc_loss = 0.03247477983727539
Trained batch 451 in epoch 9, gen_loss = 0.8596797544608074, disc_loss = 0.03241021618034806
Trained batch 452 in epoch 9, gen_loss = 0.8596361186067526, disc_loss = 0.03234445327475552
Trained batch 453 in epoch 9, gen_loss = 0.8596341414336066, disc_loss = 0.03273842771720174
Trained batch 454 in epoch 9, gen_loss = 0.8593269565603235, disc_loss = 0.032725188819241226
Trained batch 455 in epoch 9, gen_loss = 0.8588580439488093, disc_loss = 0.03270546691196056
Trained batch 456 in epoch 9, gen_loss = 0.8586488744362178, disc_loss = 0.0326694633024062
Trained batch 457 in epoch 9, gen_loss = 0.8584757205180206, disc_loss = 0.03262096727988784
Trained batch 458 in epoch 9, gen_loss = 0.8582197845891151, disc_loss = 0.03258106887111266
Trained batch 459 in epoch 9, gen_loss = 0.8582071383362231, disc_loss = 0.032548579706749674
Trained batch 460 in epoch 9, gen_loss = 0.8577409084086305, disc_loss = 0.032536575889392655
Trained batch 461 in epoch 9, gen_loss = 0.8576457666886317, disc_loss = 0.03248769196014432
Trained batch 462 in epoch 9, gen_loss = 0.8579997332770675, disc_loss = 0.03243809424242162
Trained batch 463 in epoch 9, gen_loss = 0.8578410614924185, disc_loss = 0.032389028615555086
Trained batch 464 in epoch 9, gen_loss = 0.8583249354875216, disc_loss = 0.032400386988295504
Trained batch 465 in epoch 9, gen_loss = 0.8580543203159463, disc_loss = 0.03239599133635843
Trained batch 466 in epoch 9, gen_loss = 0.8580287808524465, disc_loss = 0.032366655475302444
Trained batch 467 in epoch 9, gen_loss = 0.858242181249154, disc_loss = 0.03231033912917567
Trained batch 468 in epoch 9, gen_loss = 0.8578979324684468, disc_loss = 0.03238816066100987
Trained batch 469 in epoch 9, gen_loss = 0.8581165055011181, disc_loss = 0.03236230297975163
Trained batch 470 in epoch 9, gen_loss = 0.8586736064554527, disc_loss = 0.03234088431199471
Trained batch 471 in epoch 9, gen_loss = 0.8579441922701011, disc_loss = 0.03248173586473706
Trained batch 472 in epoch 9, gen_loss = 0.8577783808395676, disc_loss = 0.032578889312553386
Trained batch 473 in epoch 9, gen_loss = 0.857463834154958, disc_loss = 0.03257384486074013
Trained batch 474 in epoch 9, gen_loss = 0.8579849009764822, disc_loss = 0.032603856435437735
Trained batch 475 in epoch 9, gen_loss = 0.858361029574851, disc_loss = 0.03256028646479964
Trained batch 476 in epoch 9, gen_loss = 0.8579722148067547, disc_loss = 0.03256161552385292
Trained batch 477 in epoch 9, gen_loss = 0.8576532467638598, disc_loss = 0.03254611896999788
Trained batch 478 in epoch 9, gen_loss = 0.8573514223098755, disc_loss = 0.03254295544580232
Trained batch 479 in epoch 9, gen_loss = 0.8578529713054498, disc_loss = 0.032566051010993156
Trained batch 480 in epoch 9, gen_loss = 0.8578072552125816, disc_loss = 0.032552132739737755
Trained batch 481 in epoch 9, gen_loss = 0.8576393074267138, disc_loss = 0.032535591016376694
Trained batch 482 in epoch 9, gen_loss = 0.8574147334256774, disc_loss = 0.032501110213656384
Trained batch 483 in epoch 9, gen_loss = 0.8574490720821806, disc_loss = 0.03270834110617592
Trained batch 484 in epoch 9, gen_loss = 0.8570952447419314, disc_loss = 0.03275786742385592
Trained batch 485 in epoch 9, gen_loss = 0.8567415179048546, disc_loss = 0.032745030429310054
Trained batch 486 in epoch 9, gen_loss = 0.8568272361765162, disc_loss = 0.03269962982171324
Trained batch 487 in epoch 9, gen_loss = 0.8571167604112234, disc_loss = 0.03264656856791574
Trained batch 488 in epoch 9, gen_loss = 0.8571997564019357, disc_loss = 0.032593071213609145
Trained batch 489 in epoch 9, gen_loss = 0.8572724556436344, disc_loss = 0.0326959189830576
Trained batch 490 in epoch 9, gen_loss = 0.8569370389227469, disc_loss = 0.03272210260001514
Trained batch 491 in epoch 9, gen_loss = 0.8564750375301857, disc_loss = 0.032716676941599576
Trained batch 492 in epoch 9, gen_loss = 0.8561419043047674, disc_loss = 0.03272804262779623
Trained batch 493 in epoch 9, gen_loss = 0.8563328253836767, disc_loss = 0.03271067684736887
Trained batch 494 in epoch 9, gen_loss = 0.8565739265596024, disc_loss = 0.0326990966849744
Trained batch 495 in epoch 9, gen_loss = 0.8560724052931031, disc_loss = 0.033948733201419425
Trained batch 496 in epoch 9, gen_loss = 0.855647619941105, disc_loss = 0.03399494872803255
Trained batch 497 in epoch 9, gen_loss = 0.8553182474341259, disc_loss = 0.034000378184817194
Trained batch 498 in epoch 9, gen_loss = 0.8551953672646043, disc_loss = 0.03406329879318858
Trained batch 499 in epoch 9, gen_loss = 0.8547928016185761, disc_loss = 0.03406718330876902
Trained batch 500 in epoch 9, gen_loss = 0.8547278596255594, disc_loss = 0.034022552956233985
Trained batch 501 in epoch 9, gen_loss = 0.854674544111191, disc_loss = 0.03414207588615957
Trained batch 502 in epoch 9, gen_loss = 0.854808042466522, disc_loss = 0.03410399217893616
Trained batch 503 in epoch 9, gen_loss = 0.8548058703068703, disc_loss = 0.0340511985331042
Trained batch 504 in epoch 9, gen_loss = 0.8550299371823226, disc_loss = 0.0339943031637496
Trained batch 505 in epoch 9, gen_loss = 0.8551598267828523, disc_loss = 0.034035170487157644
Trained batch 506 in epoch 9, gen_loss = 0.8546291412216201, disc_loss = 0.03417325172622925
Trained batch 507 in epoch 9, gen_loss = 0.8545867414690378, disc_loss = 0.03411573629256147
Trained batch 508 in epoch 9, gen_loss = 0.8547425329802313, disc_loss = 0.0340629560193175
Trained batch 509 in epoch 9, gen_loss = 0.8549198716294532, disc_loss = 0.03400718146140742
Trained batch 510 in epoch 9, gen_loss = 0.855322586346979, disc_loss = 0.033961511897324145
Trained batch 511 in epoch 9, gen_loss = 0.8553095328388736, disc_loss = 0.033922926665127306
Trained batch 512 in epoch 9, gen_loss = 0.8554018177019458, disc_loss = 0.03386762105228042
Trained batch 513 in epoch 9, gen_loss = 0.8555584789945921, disc_loss = 0.033809646328545176
Trained batch 514 in epoch 9, gen_loss = 0.8557484432331567, disc_loss = 0.03375249431938729
Trained batch 515 in epoch 9, gen_loss = 0.855747322472491, disc_loss = 0.03370505031117043
Trained batch 516 in epoch 9, gen_loss = 0.8560109918998334, disc_loss = 0.033655486602383
Trained batch 517 in epoch 9, gen_loss = 0.8560607193979978, disc_loss = 0.03359598450679116
Trained batch 518 in epoch 9, gen_loss = 0.8561869037403996, disc_loss = 0.03364574424707131
Trained batch 519 in epoch 9, gen_loss = 0.8558023262482423, disc_loss = 0.03365132387440938
Trained batch 520 in epoch 9, gen_loss = 0.8554090213409541, disc_loss = 0.03370423039382113
Trained batch 521 in epoch 9, gen_loss = 0.8555964430173238, disc_loss = 0.03366319234286688
Trained batch 522 in epoch 9, gen_loss = 0.8557772761777072, disc_loss = 0.03361183077356926
Trained batch 523 in epoch 9, gen_loss = 0.8557041529708236, disc_loss = 0.03356206744735108
Trained batch 524 in epoch 9, gen_loss = 0.8558445978164673, disc_loss = 0.033507200285260164
Trained batch 525 in epoch 9, gen_loss = 0.8558005944404312, disc_loss = 0.03345764914400054
Trained batch 526 in epoch 9, gen_loss = 0.8557032543522584, disc_loss = 0.03342827288098139
Trained batch 527 in epoch 9, gen_loss = 0.8561988393917228, disc_loss = 0.033449403625898856
Trained batch 528 in epoch 9, gen_loss = 0.8563423839543853, disc_loss = 0.033397182271180284
Trained batch 529 in epoch 9, gen_loss = 0.8561489869963448, disc_loss = 0.033404544978138974
Trained batch 530 in epoch 9, gen_loss = 0.8558010693548314, disc_loss = 0.03344861929271574
Trained batch 531 in epoch 9, gen_loss = 0.8558949618635321, disc_loss = 0.03339819300174013
Trained batch 532 in epoch 9, gen_loss = 0.8565134900372203, disc_loss = 0.03349835051950521
Trained batch 533 in epoch 9, gen_loss = 0.8563722900013798, disc_loss = 0.03347449801593656
Trained batch 534 in epoch 9, gen_loss = 0.856631109090609, disc_loss = 0.03344691444066501
Trained batch 535 in epoch 9, gen_loss = 0.8567438108929947, disc_loss = 0.03340194904360114
Trained batch 536 in epoch 9, gen_loss = 0.8566754440355567, disc_loss = 0.03336325970528651
Trained batch 537 in epoch 9, gen_loss = 0.8566447726855934, disc_loss = 0.03335052822217982
Trained batch 538 in epoch 9, gen_loss = 0.856753477470773, disc_loss = 0.033835820336212755
Trained batch 539 in epoch 9, gen_loss = 0.8560826512398543, disc_loss = 0.03429396361612749
Trained batch 540 in epoch 9, gen_loss = 0.8556223097438072, disc_loss = 0.03466628058839335
Trained batch 541 in epoch 9, gen_loss = 0.8552441518904979, disc_loss = 0.03480011406973197
Trained batch 542 in epoch 9, gen_loss = 0.854977848560551, disc_loss = 0.034878499360847706
Trained batch 543 in epoch 9, gen_loss = 0.854535761891919, disc_loss = 0.034956864883390476
Trained batch 544 in epoch 9, gen_loss = 0.8542605614443438, disc_loss = 0.03498189012614002
Trained batch 545 in epoch 9, gen_loss = 0.854017048965007, disc_loss = 0.03500578704719933
Trained batch 546 in epoch 9, gen_loss = 0.8537747509082885, disc_loss = 0.03511494461538941
Trained batch 547 in epoch 9, gen_loss = 0.8534583096956685, disc_loss = 0.03514434775952793
Trained batch 548 in epoch 9, gen_loss = 0.8531364901686844, disc_loss = 0.03513113715735099
Trained batch 549 in epoch 9, gen_loss = 0.8529503341154618, disc_loss = 0.035332334188067104
Trained batch 550 in epoch 9, gen_loss = 0.8526297296023845, disc_loss = 0.03534157685479132
Trained batch 551 in epoch 9, gen_loss = 0.8524357735894729, disc_loss = 0.035333312795652695
Trained batch 552 in epoch 9, gen_loss = 0.8523857579524435, disc_loss = 0.035293382977322416
Trained batch 553 in epoch 9, gen_loss = 0.8520708015249094, disc_loss = 0.035340968992675414
Trained batch 554 in epoch 9, gen_loss = 0.8521696062775346, disc_loss = 0.0353050023258605
Trained batch 555 in epoch 9, gen_loss = 0.8526044901755216, disc_loss = 0.035282565499387894
Trained batch 556 in epoch 9, gen_loss = 0.8530052095598122, disc_loss = 0.03536688654534719
Trained batch 557 in epoch 9, gen_loss = 0.8525382527100143, disc_loss = 0.03537345358244007
Trained batch 558 in epoch 9, gen_loss = 0.8517584388072674, disc_loss = 0.03572887233966605
Trained batch 559 in epoch 9, gen_loss = 0.8518510683306626, disc_loss = 0.03578056643600576
Trained batch 560 in epoch 9, gen_loss = 0.8518902468171349, disc_loss = 0.03578237269269618
Trained batch 561 in epoch 9, gen_loss = 0.851399820682417, disc_loss = 0.035822295021179576
Trained batch 562 in epoch 9, gen_loss = 0.8513526675120975, disc_loss = 0.03582366052799946
Trained batch 563 in epoch 9, gen_loss = 0.8514085848492088, disc_loss = 0.035778731369439855
Trained batch 564 in epoch 9, gen_loss = 0.8516062453784774, disc_loss = 0.035768242652602165
Trained batch 565 in epoch 9, gen_loss = 0.8513383907479869, disc_loss = 0.03573517545863539
Trained batch 566 in epoch 9, gen_loss = 0.8512134443725438, disc_loss = 0.03576691507573718
Trained batch 567 in epoch 9, gen_loss = 0.851301515081399, disc_loss = 0.03573376722846994
Trained batch 568 in epoch 9, gen_loss = 0.8514376550860481, disc_loss = 0.035702933625257546
Trained batch 569 in epoch 9, gen_loss = 0.852013926861579, disc_loss = 0.03581208098892188
Trained batch 570 in epoch 9, gen_loss = 0.8520356007507511, disc_loss = 0.035760228302747325
Trained batch 571 in epoch 9, gen_loss = 0.8516893574407884, disc_loss = 0.0357974991731515
Trained batch 572 in epoch 9, gen_loss = 0.8515536974445895, disc_loss = 0.03575501613153135
Trained batch 573 in epoch 9, gen_loss = 0.851892293330269, disc_loss = 0.03575410338310129
Trained batch 574 in epoch 9, gen_loss = 0.8518934393965679, disc_loss = 0.03572916050401071
Trained batch 575 in epoch 9, gen_loss = 0.8517892551090982, disc_loss = 0.03571359242859115
Trained batch 576 in epoch 9, gen_loss = 0.8518998454513748, disc_loss = 0.03566300768269617
Trained batch 577 in epoch 9, gen_loss = 0.8519915365017822, disc_loss = 0.03565424254041642
Trained batch 578 in epoch 9, gen_loss = 0.8519198357132433, disc_loss = 0.0356086119784232
Trained batch 579 in epoch 9, gen_loss = 0.8518855477201528, disc_loss = 0.035559581057971405
Trained batch 580 in epoch 9, gen_loss = 0.8520904940500111, disc_loss = 0.03551588811480445
Trained batch 581 in epoch 9, gen_loss = 0.8520543228105172, disc_loss = 0.03547671350212032
Trained batch 582 in epoch 9, gen_loss = 0.8516979132671912, disc_loss = 0.03558047849359071
Trained batch 583 in epoch 9, gen_loss = 0.8525845907526474, disc_loss = 0.03575620226153772
Trained batch 584 in epoch 9, gen_loss = 0.8528693809468522, disc_loss = 0.0357273579790042
Trained batch 585 in epoch 9, gen_loss = 0.8530026239950096, disc_loss = 0.03594907448204304
Trained batch 586 in epoch 9, gen_loss = 0.8526501794689965, disc_loss = 0.03598912194802773
Trained batch 587 in epoch 9, gen_loss = 0.8524600054536547, disc_loss = 0.035975986980788764
Trained batch 588 in epoch 9, gen_loss = 0.8525917451126669, disc_loss = 0.03592966524140944
Trained batch 589 in epoch 9, gen_loss = 0.8527847953772141, disc_loss = 0.035928477915161745
Trained batch 590 in epoch 9, gen_loss = 0.8525943404123465, disc_loss = 0.035888263237128404
Trained batch 591 in epoch 9, gen_loss = 0.8523180514976785, disc_loss = 0.0358905070366942
Trained batch 592 in epoch 9, gen_loss = 0.8525533961606468, disc_loss = 0.035850821449272145
Trained batch 593 in epoch 9, gen_loss = 0.8524991839823096, disc_loss = 0.03582528269903026
Trained batch 594 in epoch 9, gen_loss = 0.8531639527873832, disc_loss = 0.0358464540553694
Trained batch 595 in epoch 9, gen_loss = 0.8532865280472992, disc_loss = 0.035823277410294785
Trained batch 596 in epoch 9, gen_loss = 0.8534386100082142, disc_loss = 0.03578173498805594
Trained batch 597 in epoch 9, gen_loss = 0.8535738724928635, disc_loss = 0.03573719915594395
Trained batch 598 in epoch 9, gen_loss = 0.8535082155157608, disc_loss = 0.03570982147294263
Trained batch 599 in epoch 9, gen_loss = 0.8533609802524249, disc_loss = 0.03566245920490473
Trained batch 600 in epoch 9, gen_loss = 0.8531977968684052, disc_loss = 0.03563143359264746
Trained batch 601 in epoch 9, gen_loss = 0.8533757365621205, disc_loss = 0.03566549847558438
Trained batch 602 in epoch 9, gen_loss = 0.8532541293409927, disc_loss = 0.03563178096670861
Trained batch 603 in epoch 9, gen_loss = 0.8533286769066425, disc_loss = 0.03558315470080749
Trained batch 604 in epoch 9, gen_loss = 0.852979506047304, disc_loss = 0.03557226183585638
Trained batch 605 in epoch 9, gen_loss = 0.8530817516762824, disc_loss = 0.03553410203322129
Trained batch 606 in epoch 9, gen_loss = 0.8530857914558548, disc_loss = 0.03565420604984489
Trained batch 607 in epoch 9, gen_loss = 0.8528886590349046, disc_loss = 0.03570745181365821
Trained batch 608 in epoch 9, gen_loss = 0.8523285664948337, disc_loss = 0.03591522409875796
Trained batch 609 in epoch 9, gen_loss = 0.8522732623287889, disc_loss = 0.0358915418142178
Trained batch 610 in epoch 9, gen_loss = 0.8521307864868114, disc_loss = 0.035924633333852755
Trained batch 611 in epoch 9, gen_loss = 0.8517288787692201, disc_loss = 0.03602463717334995
Trained batch 612 in epoch 9, gen_loss = 0.8519342646707718, disc_loss = 0.0360716005291966
Trained batch 613 in epoch 9, gen_loss = 0.8517295724988372, disc_loss = 0.036061938718592305
Trained batch 614 in epoch 9, gen_loss = 0.8515799370238452, disc_loss = 0.03604405182527333
Trained batch 615 in epoch 9, gen_loss = 0.8516846187896543, disc_loss = 0.03602937022647397
Trained batch 616 in epoch 9, gen_loss = 0.8518462104774178, disc_loss = 0.035997882120105976
Trained batch 617 in epoch 9, gen_loss = 0.8519068617843887, disc_loss = 0.035960010720061254
Trained batch 618 in epoch 9, gen_loss = 0.8518576746225742, disc_loss = 0.03591480433507574
Trained batch 619 in epoch 9, gen_loss = 0.8514544973450322, disc_loss = 0.03594642479813868
Trained batch 620 in epoch 9, gen_loss = 0.8516649719021746, disc_loss = 0.03610564925484419
Trained batch 621 in epoch 9, gen_loss = 0.8512921412849733, disc_loss = 0.036106863062098093
Trained batch 622 in epoch 9, gen_loss = 0.8509472109150159, disc_loss = 0.03612855363810617
Trained batch 623 in epoch 9, gen_loss = 0.8506094117004138, disc_loss = 0.036116782638530895
Trained batch 624 in epoch 9, gen_loss = 0.851076885509491, disc_loss = 0.03624928860962391
Trained batch 625 in epoch 9, gen_loss = 0.8511940596012262, disc_loss = 0.036200130173859126
Trained batch 626 in epoch 9, gen_loss = 0.8506757010493362, disc_loss = 0.03637998425171516
Trained batch 627 in epoch 9, gen_loss = 0.8505513997404439, disc_loss = 0.03637354663175762
Trained batch 628 in epoch 9, gen_loss = 0.8505072833434197, disc_loss = 0.036532501170385055
Trained batch 629 in epoch 9, gen_loss = 0.850418837392141, disc_loss = 0.0365237264465245
Trained batch 630 in epoch 9, gen_loss = 0.8506958219215345, disc_loss = 0.03652532238117678
Trained batch 631 in epoch 9, gen_loss = 0.8507475935017006, disc_loss = 0.036475636597716875
Trained batch 632 in epoch 9, gen_loss = 0.8507582624376667, disc_loss = 0.036461689127653275
Trained batch 633 in epoch 9, gen_loss = 0.8507900556743333, disc_loss = 0.03641200910780685
Trained batch 634 in epoch 9, gen_loss = 0.8509667120580598, disc_loss = 0.03636244009285579
Trained batch 635 in epoch 9, gen_loss = 0.8510966046051409, disc_loss = 0.036312227307982836
Trained batch 636 in epoch 9, gen_loss = 0.8509914628003419, disc_loss = 0.03627511380485945
Trained batch 637 in epoch 9, gen_loss = 0.8508765059391906, disc_loss = 0.03623732332604409
Trained batch 638 in epoch 9, gen_loss = 0.8507696254898871, disc_loss = 0.0362830379407952
Trained batch 639 in epoch 9, gen_loss = 0.8507620486430824, disc_loss = 0.036239512172323886
Trained batch 640 in epoch 9, gen_loss = 0.8506703061544207, disc_loss = 0.0362013285455124
Trained batch 641 in epoch 9, gen_loss = 0.850904724029737, disc_loss = 0.03616128986153021
Trained batch 642 in epoch 9, gen_loss = 0.8509071005818262, disc_loss = 0.03612613258303996
Trained batch 643 in epoch 9, gen_loss = 0.8508376373637537, disc_loss = 0.03607811442047057
Trained batch 644 in epoch 9, gen_loss = 0.8510770119437876, disc_loss = 0.036035251325039666
Trained batch 645 in epoch 9, gen_loss = 0.850844388314445, disc_loss = 0.03601426356933411
Trained batch 646 in epoch 9, gen_loss = 0.8511673732555631, disc_loss = 0.03598011212014641
Trained batch 647 in epoch 9, gen_loss = 0.8513656894181981, disc_loss = 0.03605660747371637
Trained batch 648 in epoch 9, gen_loss = 0.8510984066638447, disc_loss = 0.036099453915186076
Trained batch 649 in epoch 9, gen_loss = 0.8507946637960581, disc_loss = 0.03615603437289022
Trained batch 650 in epoch 9, gen_loss = 0.8508336448815927, disc_loss = 0.036187765848738486
Trained batch 651 in epoch 9, gen_loss = 0.8508881654110423, disc_loss = 0.03618299800036989
Trained batch 652 in epoch 9, gen_loss = 0.8511062543753642, disc_loss = 0.03623176792887529
Trained batch 653 in epoch 9, gen_loss = 0.8505583369494942, disc_loss = 0.036404314653845415
Trained batch 654 in epoch 9, gen_loss = 0.8507491759216512, disc_loss = 0.036362163329369014
Trained batch 655 in epoch 9, gen_loss = 0.8505723293325523, disc_loss = 0.03633525936861477
Trained batch 656 in epoch 9, gen_loss = 0.8506046339892179, disc_loss = 0.03629836397631097
Trained batch 657 in epoch 9, gen_loss = 0.8510407943584274, disc_loss = 0.03629746497042568
Trained batch 658 in epoch 9, gen_loss = 0.8509521569847518, disc_loss = 0.03627639745569849
Trained batch 659 in epoch 9, gen_loss = 0.8509990898497177, disc_loss = 0.03623110708484257
Trained batch 660 in epoch 9, gen_loss = 0.8510218839331583, disc_loss = 0.03618411061462471
Trained batch 661 in epoch 9, gen_loss = 0.8509214126541536, disc_loss = 0.03613775543196076
Trained batch 662 in epoch 9, gen_loss = 0.8508495923530642, disc_loss = 0.03611101343915945
Trained batch 663 in epoch 9, gen_loss = 0.8507128267672407, disc_loss = 0.036103307957486085
Trained batch 664 in epoch 9, gen_loss = 0.8505893719375581, disc_loss = 0.03607569878108632
Trained batch 665 in epoch 9, gen_loss = 0.8510687839430016, disc_loss = 0.036171615303440895
Trained batch 666 in epoch 9, gen_loss = 0.8510732722693476, disc_loss = 0.036145256020301865
Trained batch 667 in epoch 9, gen_loss = 0.8506909967985695, disc_loss = 0.036168724421863474
Trained batch 668 in epoch 9, gen_loss = 0.8507937806336869, disc_loss = 0.03613115364396095
Trained batch 669 in epoch 9, gen_loss = 0.8512631804640614, disc_loss = 0.036142431873021956
Trained batch 670 in epoch 9, gen_loss = 0.8513220080053753, disc_loss = 0.03610142837896188
Trained batch 671 in epoch 9, gen_loss = 0.8512884228978128, disc_loss = 0.03605995677935425
Trained batch 672 in epoch 9, gen_loss = 0.8513420864961831, disc_loss = 0.036014556358215495
Trained batch 673 in epoch 9, gen_loss = 0.8512741920237018, disc_loss = 0.03664208095705894
Trained batch 674 in epoch 9, gen_loss = 0.8509261472578402, disc_loss = 0.036748628267949376
Trained batch 675 in epoch 9, gen_loss = 0.8506319791343085, disc_loss = 0.036788921609669706
Trained batch 676 in epoch 9, gen_loss = 0.8506694028877614, disc_loss = 0.03675086851516516
Trained batch 677 in epoch 9, gen_loss = 0.8506854547951426, disc_loss = 0.036750130593683296
Trained batch 678 in epoch 9, gen_loss = 0.8507231452415899, disc_loss = 0.036712345429209224
Trained batch 679 in epoch 9, gen_loss = 0.8508793147609515, disc_loss = 0.036665341472390166
Trained batch 680 in epoch 9, gen_loss = 0.8507467019487933, disc_loss = 0.03666392445260667
Trained batch 681 in epoch 9, gen_loss = 0.8505959340816369, disc_loss = 0.036641548325572586
Trained batch 682 in epoch 9, gen_loss = 0.8506284024059162, disc_loss = 0.03661827625854058
Trained batch 683 in epoch 9, gen_loss = 0.8505390342651752, disc_loss = 0.036579730303015846
Trained batch 684 in epoch 9, gen_loss = 0.8504654120789827, disc_loss = 0.036541662863489706
Trained batch 685 in epoch 9, gen_loss = 0.8502157458671675, disc_loss = 0.03653974872172074
Trained batch 686 in epoch 9, gen_loss = 0.8502708575871314, disc_loss = 0.03654306805238475
Trained batch 687 in epoch 9, gen_loss = 0.8503935029946788, disc_loss = 0.03650548229965944
Trained batch 688 in epoch 9, gen_loss = 0.8505856735180355, disc_loss = 0.036484391759021316
Trained batch 689 in epoch 9, gen_loss = 0.8508147635753603, disc_loss = 0.0364450095795041
Trained batch 690 in epoch 9, gen_loss = 0.850347148483638, disc_loss = 0.03655841897070602
Trained batch 691 in epoch 9, gen_loss = 0.850122335458422, disc_loss = 0.03654755653902307
Trained batch 692 in epoch 9, gen_loss = 0.8503420617415275, disc_loss = 0.03662927933427012
Trained batch 693 in epoch 9, gen_loss = 0.850202572062311, disc_loss = 0.036598916596971905
Trained batch 694 in epoch 9, gen_loss = 0.8502818859309601, disc_loss = 0.03655503219087347
Trained batch 695 in epoch 9, gen_loss = 0.84995679441711, disc_loss = 0.036611791544904314
Trained batch 696 in epoch 9, gen_loss = 0.8497826660979256, disc_loss = 0.036618717672193754
Trained batch 697 in epoch 9, gen_loss = 0.8495702533035361, disc_loss = 0.036616357550409255
Trained batch 698 in epoch 9, gen_loss = 0.8497394417573795, disc_loss = 0.03665846724793294
Trained batch 699 in epoch 9, gen_loss = 0.8502812111803464, disc_loss = 0.03674737883465631
Trained batch 700 in epoch 9, gen_loss = 0.8497660478494646, disc_loss = 0.036887217414022004
Trained batch 701 in epoch 9, gen_loss = 0.8500497825549879, disc_loss = 0.03688541667116673
Trained batch 702 in epoch 9, gen_loss = 0.8501310816106213, disc_loss = 0.03684417443061155
Trained batch 703 in epoch 9, gen_loss = 0.8499646596187218, disc_loss = 0.036811489232191394
Trained batch 704 in epoch 9, gen_loss = 0.8499003470789456, disc_loss = 0.036809539928345396
Trained batch 705 in epoch 9, gen_loss = 0.849766708256165, disc_loss = 0.03680771981463596
Trained batch 706 in epoch 9, gen_loss = 0.8498388213096278, disc_loss = 0.03677212278710354
Trained batch 707 in epoch 9, gen_loss = 0.8499136031263292, disc_loss = 0.036737609904596194
Trained batch 708 in epoch 9, gen_loss = 0.8501878663666326, disc_loss = 0.03680290588360327
Trained batch 709 in epoch 9, gen_loss = 0.8499115558157504, disc_loss = 0.036823724931709365
Trained batch 710 in epoch 9, gen_loss = 0.8495553502637458, disc_loss = 0.03693707036601089
Trained batch 711 in epoch 9, gen_loss = 0.8495944497709194, disc_loss = 0.036917069626009366
Trained batch 712 in epoch 9, gen_loss = 0.8497217664126762, disc_loss = 0.036932284393848075
Trained batch 713 in epoch 9, gen_loss = 0.8498997744642386, disc_loss = 0.03689467757079406
Trained batch 714 in epoch 9, gen_loss = 0.849691241396057, disc_loss = 0.036897655840884974
Trained batch 715 in epoch 9, gen_loss = 0.8496501042439951, disc_loss = 0.03690201858729748
Trained batch 716 in epoch 9, gen_loss = 0.8498322408817802, disc_loss = 0.036863152827480435
Trained batch 717 in epoch 9, gen_loss = 0.8502031038813604, disc_loss = 0.03684317020305061
Trained batch 718 in epoch 9, gen_loss = 0.8500391624981902, disc_loss = 0.03686774070912218
Trained batch 719 in epoch 9, gen_loss = 0.8501710830877225, disc_loss = 0.036822918326490456
Trained batch 720 in epoch 9, gen_loss = 0.850304416619789, disc_loss = 0.036801489116559415
Trained batch 721 in epoch 9, gen_loss = 0.8501136133297659, disc_loss = 0.03688131729682644
Trained batch 722 in epoch 9, gen_loss = 0.8497350898933279, disc_loss = 0.03691010326301656
Trained batch 723 in epoch 9, gen_loss = 0.8497170638395937, disc_loss = 0.036866428064264725
Trained batch 724 in epoch 9, gen_loss = 0.8500318315522424, disc_loss = 0.03683329559220322
Trained batch 725 in epoch 9, gen_loss = 0.850098857004452, disc_loss = 0.036791341419052076
Trained batch 726 in epoch 9, gen_loss = 0.8502855773559135, disc_loss = 0.03674772688593751
Trained batch 727 in epoch 9, gen_loss = 0.8502090423071123, disc_loss = 0.036712513465157984
Trained batch 728 in epoch 9, gen_loss = 0.8499889458403175, disc_loss = 0.03671030890431628
Trained batch 729 in epoch 9, gen_loss = 0.8502283672355626, disc_loss = 0.03667363066302791
Trained batch 730 in epoch 9, gen_loss = 0.8501536875107056, disc_loss = 0.036633428786250616
Trained batch 731 in epoch 9, gen_loss = 0.8504020019225735, disc_loss = 0.03675147738750474
Trained batch 732 in epoch 9, gen_loss = 0.8503214461985584, disc_loss = 0.03676512068338275
Trained batch 733 in epoch 9, gen_loss = 0.8499878057423339, disc_loss = 0.03677712880678942
Trained batch 734 in epoch 9, gen_loss = 0.8496564774691653, disc_loss = 0.03685071309584947
Trained batch 735 in epoch 9, gen_loss = 0.8499072871535368, disc_loss = 0.036849025387630754
Trained batch 736 in epoch 9, gen_loss = 0.8497894778746601, disc_loss = 0.036846566084757185
Trained batch 737 in epoch 9, gen_loss = 0.8495824128227828, disc_loss = 0.03685259146030316
Trained batch 738 in epoch 9, gen_loss = 0.8495820154598505, disc_loss = 0.036912026605915395
Trained batch 739 in epoch 9, gen_loss = 0.8492843103167173, disc_loss = 0.036961003839717926
Trained batch 740 in epoch 9, gen_loss = 0.8490198544564679, disc_loss = 0.03698181559415924
Trained batch 741 in epoch 9, gen_loss = 0.8487858232060532, disc_loss = 0.03701529629664079
Trained batch 742 in epoch 9, gen_loss = 0.8492372109382984, disc_loss = 0.037143173740366985
Trained batch 743 in epoch 9, gen_loss = 0.8491263064726066, disc_loss = 0.037178060639479385
Trained batch 744 in epoch 9, gen_loss = 0.8486895636824153, disc_loss = 0.03731548063982053
Trained batch 745 in epoch 9, gen_loss = 0.8488596472040258, disc_loss = 0.03728888230897666
Testing Epoch 9
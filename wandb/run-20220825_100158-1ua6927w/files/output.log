
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5428950786590576, disc_loss = 0.6554039120674133
Trained batch 1 in epoch 0, gen_loss = 0.4836190640926361, disc_loss = 0.7151933908462524
Trained batch 2 in epoch 0, gen_loss = 0.4886498848597209, disc_loss = 0.6130625307559967
Trained batch 3 in epoch 0, gen_loss = 0.4686916396021843, disc_loss = 0.5565460547804832
Trained batch 4 in epoch 0, gen_loss = 0.46403502225875853, disc_loss = 0.5060598433017731
Trained batch 5 in epoch 0, gen_loss = 0.4533145527044932, disc_loss = 0.4751281887292862
Trained batch 6 in epoch 0, gen_loss = 0.4515707194805145, disc_loss = 0.44770040256636484
Trained batch 7 in epoch 0, gen_loss = 0.4552311487495899, disc_loss = 0.4138874989002943
Trained batch 8 in epoch 0, gen_loss = 0.4512527618143294, disc_loss = 0.3873674836423662
Trained batch 9 in epoch 0, gen_loss = 0.45037923753261566, disc_loss = 0.36281704902648926
Trained batch 10 in epoch 0, gen_loss = 0.4471378272229975, disc_loss = 0.34015731378035113
Trained batch 11 in epoch 0, gen_loss = 0.4450482130050659, disc_loss = 0.32100533818205196
Trained batch 12 in epoch 0, gen_loss = 0.4461484459730295, disc_loss = 0.30456180297411406
Trained batch 13 in epoch 0, gen_loss = 0.44262186118534635, disc_loss = 0.29492580039160593
Trained batch 14 in epoch 0, gen_loss = 0.44067310094833373, disc_loss = 0.2821642597516378
Trained batch 15 in epoch 0, gen_loss = 0.4413267429918051, disc_loss = 0.2731187529861927
Trained batch 16 in epoch 0, gen_loss = 0.44604094764765573, disc_loss = 0.2681922649635988
Trained batch 17 in epoch 0, gen_loss = 0.44141293399863774, disc_loss = 0.2637496524386936
Trained batch 18 in epoch 0, gen_loss = 0.4429164324936114, disc_loss = 0.2600818864609066
Trained batch 19 in epoch 0, gen_loss = 0.4443972513079643, disc_loss = 0.25274363085627555
Trained batch 20 in epoch 0, gen_loss = 0.44457460443178815, disc_loss = 0.24600301753906978
Trained batch 21 in epoch 0, gen_loss = 0.445022929798473, disc_loss = 0.24295819415287537
Trained batch 22 in epoch 0, gen_loss = 0.4445373752842779, disc_loss = 0.2476047931805901
Trained batch 23 in epoch 0, gen_loss = 0.44589930896957714, disc_loss = 0.24262825337549052
Trained batch 24 in epoch 0, gen_loss = 0.4446603000164032, disc_loss = 0.23731408774852752
Trained batch 25 in epoch 0, gen_loss = 0.4456531130350553, disc_loss = 0.23321712188995802
Trained batch 26 in epoch 0, gen_loss = 0.44665534849520083, disc_loss = 0.2274830871158176
Trained batch 27 in epoch 0, gen_loss = 0.4479859875781195, disc_loss = 0.22225171034889563
Trained batch 28 in epoch 0, gen_loss = 0.45114036058557444, disc_loss = 0.21767883953349343
Trained batch 29 in epoch 0, gen_loss = 0.4519978394110998, disc_loss = 0.21231230547030766
Trained batch 30 in epoch 0, gen_loss = 0.4509296369168066, disc_loss = 0.207753230727488
Trained batch 31 in epoch 0, gen_loss = 0.4492708873003721, disc_loss = 0.20439260872080922
Trained batch 32 in epoch 0, gen_loss = 0.4509044379898996, disc_loss = 0.2017309774052013
Trained batch 33 in epoch 0, gen_loss = 0.45339156424298005, disc_loss = 0.19980704258469975
Trained batch 34 in epoch 0, gen_loss = 0.4542713599545615, disc_loss = 0.19776053386075157
Trained batch 35 in epoch 0, gen_loss = 0.4534333108199967, disc_loss = 0.19657122840483984
Trained batch 36 in epoch 0, gen_loss = 0.4563513615646878, disc_loss = 0.1940477570971927
Trained batch 37 in epoch 0, gen_loss = 0.4570547687379937, disc_loss = 0.19239941200143412
Trained batch 38 in epoch 0, gen_loss = 0.4569305808116228, disc_loss = 0.1952183601947931
Trained batch 39 in epoch 0, gen_loss = 0.4582027971744537, disc_loss = 0.19501596689224243
Trained batch 40 in epoch 0, gen_loss = 0.4567366053418415, disc_loss = 0.194423860166131
Trained batch 41 in epoch 0, gen_loss = 0.45616389101459864, disc_loss = 0.19846856310254052
Trained batch 42 in epoch 0, gen_loss = 0.4571370135906131, disc_loss = 0.19560629112082858
Trained batch 43 in epoch 0, gen_loss = 0.45732632211663504, disc_loss = 0.1936700457537716
Trained batch 44 in epoch 0, gen_loss = 0.4559255758921305, disc_loss = 0.19134463320175807
Trained batch 45 in epoch 0, gen_loss = 0.45523127200810803, disc_loss = 0.18817454657476881
Trained batch 46 in epoch 0, gen_loss = 0.455885925825606, disc_loss = 0.18509499031178495
Trained batch 47 in epoch 0, gen_loss = 0.45675071763495606, disc_loss = 0.18314036323378483
Trained batch 48 in epoch 0, gen_loss = 0.45888108319165755, disc_loss = 0.18123249086190243
Trained batch 49 in epoch 0, gen_loss = 0.45981158554553986, disc_loss = 0.18171179100871085
Trained batch 50 in epoch 0, gen_loss = 0.4581100479060528, disc_loss = 0.1833740956350869
Trained batch 51 in epoch 0, gen_loss = 0.45758996044213957, disc_loss = 0.18206189572811127
Trained batch 52 in epoch 0, gen_loss = 0.4555180050292105, disc_loss = 0.18108227399160276
Trained batch 53 in epoch 0, gen_loss = 0.4543396626357679, disc_loss = 0.18385454736374043
Trained batch 54 in epoch 0, gen_loss = 0.4542162358760834, disc_loss = 0.18202351602641018
Trained batch 55 in epoch 0, gen_loss = 0.4551420642861298, disc_loss = 0.18061895588678972
Trained batch 56 in epoch 0, gen_loss = 0.4570891214044471, disc_loss = 0.17863995804075608
Trained batch 57 in epoch 0, gen_loss = 0.45699061401959123, disc_loss = 0.17735925239735637
Trained batch 58 in epoch 0, gen_loss = 0.4568095606262401, disc_loss = 0.17636148353754463
Trained batch 59 in epoch 0, gen_loss = 0.4575662488738696, disc_loss = 0.17518693084518114
Trained batch 60 in epoch 0, gen_loss = 0.45740124290106726, disc_loss = 0.17311919969124873
Trained batch 61 in epoch 0, gen_loss = 0.45802493970240316, disc_loss = 0.17294872347866336
Trained batch 62 in epoch 0, gen_loss = 0.45816179353093345, disc_loss = 0.17850470223597117
Trained batch 63 in epoch 0, gen_loss = 0.4583527687937021, disc_loss = 0.17728276166599244
Trained batch 64 in epoch 0, gen_loss = 0.4572570997935075, disc_loss = 0.17611484882923273
Trained batch 65 in epoch 0, gen_loss = 0.45622769404541363, disc_loss = 0.1763949077011961
Trained batch 66 in epoch 0, gen_loss = 0.4569008835216067, disc_loss = 0.175148503326658
Trained batch 67 in epoch 0, gen_loss = 0.4558719111716046, disc_loss = 0.17419306155951583
Trained batch 68 in epoch 0, gen_loss = 0.45566779375076294, disc_loss = 0.17287716172311618
Trained batch 69 in epoch 0, gen_loss = 0.45599795750209265, disc_loss = 0.171585251390934
Trained batch 70 in epoch 0, gen_loss = 0.45572023618389185, disc_loss = 0.17008886486291885
Trained batch 71 in epoch 0, gen_loss = 0.45462577210532296, disc_loss = 0.16928662711547482
Trained batch 72 in epoch 0, gen_loss = 0.45474911225985176, disc_loss = 0.17008675879811588
Trained batch 73 in epoch 0, gen_loss = 0.4530608082139814, disc_loss = 0.1717494663757247
Trained batch 74 in epoch 0, gen_loss = 0.45342856804529824, disc_loss = 0.17146737496058145
Trained batch 75 in epoch 0, gen_loss = 0.45362910942027446, disc_loss = 0.1705599248801407
Trained batch 76 in epoch 0, gen_loss = 0.4544382629456458, disc_loss = 0.1700300138879132
Trained batch 77 in epoch 0, gen_loss = 0.45441047083108854, disc_loss = 0.16983476682351187
Trained batch 78 in epoch 0, gen_loss = 0.4554876817178123, disc_loss = 0.16923781984214542
Trained batch 79 in epoch 0, gen_loss = 0.45556926243007184, disc_loss = 0.17085736114531755
Trained batch 80 in epoch 0, gen_loss = 0.45480023195714125, disc_loss = 0.174597258001198
Trained batch 81 in epoch 0, gen_loss = 0.45468290477264217, disc_loss = 0.17552807400139367
Trained batch 82 in epoch 0, gen_loss = 0.45491932673626634, disc_loss = 0.1778317429574139
Trained batch 83 in epoch 0, gen_loss = 0.45431220602421535, disc_loss = 0.17952185141898336
Trained batch 84 in epoch 0, gen_loss = 0.4542638410540188, disc_loss = 0.18017202194999246
Trained batch 85 in epoch 0, gen_loss = 0.4539918937655382, disc_loss = 0.18013886795487516
Trained batch 86 in epoch 0, gen_loss = 0.45387062053570804, disc_loss = 0.17990747590859732
Trained batch 87 in epoch 0, gen_loss = 0.4523305364630439, disc_loss = 0.18030278774147684
Trained batch 88 in epoch 0, gen_loss = 0.4516467699843846, disc_loss = 0.180687932318516
Trained batch 89 in epoch 0, gen_loss = 0.45117945008807714, disc_loss = 0.18124773767259386
Trained batch 90 in epoch 0, gen_loss = 0.4508194347004314, disc_loss = 0.18133550161843773
Trained batch 91 in epoch 0, gen_loss = 0.4502317367688469, disc_loss = 0.1818238778606705
Trained batch 92 in epoch 0, gen_loss = 0.4513485970035676, disc_loss = 0.18240521511723917
Trained batch 93 in epoch 0, gen_loss = 0.4512688936071193, disc_loss = 0.18334509432315826
Trained batch 94 in epoch 0, gen_loss = 0.45038776585930274, disc_loss = 0.18397559272615532
Trained batch 95 in epoch 0, gen_loss = 0.45091393900414306, disc_loss = 0.18399998623256883
Trained batch 96 in epoch 0, gen_loss = 0.4512542753489976, disc_loss = 0.1857210423835774
Trained batch 97 in epoch 0, gen_loss = 0.4505633644911708, disc_loss = 0.18654527971330953
Trained batch 98 in epoch 0, gen_loss = 0.4503814261971098, disc_loss = 0.18639964964052644
Trained batch 99 in epoch 0, gen_loss = 0.4508228388428688, disc_loss = 0.18604519933462144
Trained batch 100 in epoch 0, gen_loss = 0.4501757533243387, disc_loss = 0.18611022195603588
Trained batch 101 in epoch 0, gen_loss = 0.44900574257560805, disc_loss = 0.18689540510668473
Trained batch 102 in epoch 0, gen_loss = 0.4487903268591871, disc_loss = 0.18646049152300195
Trained batch 103 in epoch 0, gen_loss = 0.44832939912493414, disc_loss = 0.18874374891702944
Trained batch 104 in epoch 0, gen_loss = 0.4480787021773202, disc_loss = 0.1902045244262332
Trained batch 105 in epoch 0, gen_loss = 0.44808523216337526, disc_loss = 0.1906088541420001
Trained batch 106 in epoch 0, gen_loss = 0.4475709319671738, disc_loss = 0.1906282024405827
Trained batch 107 in epoch 0, gen_loss = 0.4475854706984979, disc_loss = 0.19075985418425667
Trained batch 108 in epoch 0, gen_loss = 0.44725293303848407, disc_loss = 0.19070980226227996
Trained batch 109 in epoch 0, gen_loss = 0.4472917424006896, disc_loss = 0.19030146354978736
Trained batch 110 in epoch 0, gen_loss = 0.44797672210512934, disc_loss = 0.19018158209216487
Trained batch 111 in epoch 0, gen_loss = 0.4475259647837707, disc_loss = 0.1903856499120593
Trained batch 112 in epoch 0, gen_loss = 0.4465430376276506, disc_loss = 0.1907026853445357
Trained batch 113 in epoch 0, gen_loss = 0.4454225557937957, disc_loss = 0.19075554269447662
Trained batch 114 in epoch 0, gen_loss = 0.44475196211234386, disc_loss = 0.19124948239844777
Trained batch 115 in epoch 0, gen_loss = 0.445008189256849, disc_loss = 0.1919286920335786
Trained batch 116 in epoch 0, gen_loss = 0.4452730852823991, disc_loss = 0.19187408736628345
Trained batch 117 in epoch 0, gen_loss = 0.44485855860225226, disc_loss = 0.1917017064357208
Trained batch 118 in epoch 0, gen_loss = 0.4451175652632192, disc_loss = 0.19139403680793377
Trained batch 119 in epoch 0, gen_loss = 0.44495211939016976, disc_loss = 0.1917173143476248
Trained batch 120 in epoch 0, gen_loss = 0.4453637730484166, disc_loss = 0.19223256877138595
Trained batch 121 in epoch 0, gen_loss = 0.4447872389535435, disc_loss = 0.19199526542034306
Trained batch 122 in epoch 0, gen_loss = 0.44455935170010824, disc_loss = 0.19196313534810291
Trained batch 123 in epoch 0, gen_loss = 0.4443538864293406, disc_loss = 0.1918385186262669
Trained batch 124 in epoch 0, gen_loss = 0.4434774465560913, disc_loss = 0.19238123095035553
Trained batch 125 in epoch 0, gen_loss = 0.44328992896609837, disc_loss = 0.19436844107177523
Trained batch 126 in epoch 0, gen_loss = 0.4431612608939644, disc_loss = 0.19488358837882364
Trained batch 127 in epoch 0, gen_loss = 0.44319559331052005, disc_loss = 0.19524259702302516
Trained batch 128 in epoch 0, gen_loss = 0.44338450136110763, disc_loss = 0.19544046909310098
Trained batch 129 in epoch 0, gen_loss = 0.4426633947170698, disc_loss = 0.19536177825469236
Trained batch 130 in epoch 0, gen_loss = 0.44232439448815264, disc_loss = 0.19541478452791694
Trained batch 131 in epoch 0, gen_loss = 0.44188789255691296, disc_loss = 0.19542165326349664
Trained batch 132 in epoch 0, gen_loss = 0.44205604504821894, disc_loss = 0.19502521928091696
Trained batch 133 in epoch 0, gen_loss = 0.44148210424985457, disc_loss = 0.19530931226353146
Trained batch 134 in epoch 0, gen_loss = 0.44081149564849004, disc_loss = 0.19594718350304496
Trained batch 135 in epoch 0, gen_loss = 0.4406397176139495, disc_loss = 0.19619017324465163
Trained batch 136 in epoch 0, gen_loss = 0.44021062389777527, disc_loss = 0.19659488033639252
Trained batch 137 in epoch 0, gen_loss = 0.43937729471835535, disc_loss = 0.19661235928103543
Trained batch 138 in epoch 0, gen_loss = 0.4391675154082209, disc_loss = 0.19671285023792184
Trained batch 139 in epoch 0, gen_loss = 0.4389381151114191, disc_loss = 0.19715225717851093
Trained batch 140 in epoch 0, gen_loss = 0.4386955315762378, disc_loss = 0.1982310431223389
Trained batch 141 in epoch 0, gen_loss = 0.43862058201306303, disc_loss = 0.19808666082754942
Trained batch 142 in epoch 0, gen_loss = 0.4382661112121769, disc_loss = 0.1989004435864362
Trained batch 143 in epoch 0, gen_loss = 0.4381280251675182, disc_loss = 0.19958301085150904
Trained batch 144 in epoch 0, gen_loss = 0.4382281691863619, disc_loss = 0.19961320017946177
Trained batch 145 in epoch 0, gen_loss = 0.4378004055725385, disc_loss = 0.19956543847714384
Trained batch 146 in epoch 0, gen_loss = 0.4377746176557476, disc_loss = 0.19954252689063143
Trained batch 147 in epoch 0, gen_loss = 0.4374548964001037, disc_loss = 0.19971608038286906
Trained batch 148 in epoch 0, gen_loss = 0.4370790912000925, disc_loss = 0.19989010211605354
Trained batch 149 in epoch 0, gen_loss = 0.43697473684946697, disc_loss = 0.19997313757737478
Trained batch 150 in epoch 0, gen_loss = 0.43680192421603675, disc_loss = 0.2001826972361432
Trained batch 151 in epoch 0, gen_loss = 0.43647674431926325, disc_loss = 0.2002563741254179
Trained batch 152 in epoch 0, gen_loss = 0.4358312123351627, disc_loss = 0.20052680022576275
Trained batch 153 in epoch 0, gen_loss = 0.435632773614549, disc_loss = 0.20124681797120478
Trained batch 154 in epoch 0, gen_loss = 0.43536889072387447, disc_loss = 0.2012936209478686
Trained batch 155 in epoch 0, gen_loss = 0.4354576986187544, disc_loss = 0.2014133034226222
Trained batch 156 in epoch 0, gen_loss = 0.43483806301833716, disc_loss = 0.201642346325194
Trained batch 157 in epoch 0, gen_loss = 0.43431037834173514, disc_loss = 0.20159103438446793
Trained batch 158 in epoch 0, gen_loss = 0.43391444323197853, disc_loss = 0.20172301553330332
Trained batch 159 in epoch 0, gen_loss = 0.4336387157440186, disc_loss = 0.20184835018590092
Trained batch 160 in epoch 0, gen_loss = 0.4329610970449744, disc_loss = 0.20219877112356033
Trained batch 161 in epoch 0, gen_loss = 0.43256112730797425, disc_loss = 0.20279830924154799
Trained batch 162 in epoch 0, gen_loss = 0.43228738585864107, disc_loss = 0.20284899429309589
Trained batch 163 in epoch 0, gen_loss = 0.43163548809726066, disc_loss = 0.20295678169989004
Trained batch 164 in epoch 0, gen_loss = 0.43130011973959026, disc_loss = 0.20319012240930037
Trained batch 165 in epoch 0, gen_loss = 0.43069440970219763, disc_loss = 0.20332470446465964
Trained batch 166 in epoch 0, gen_loss = 0.4302888976599642, disc_loss = 0.20354172587394714
Trained batch 167 in epoch 0, gen_loss = 0.43011159396597315, disc_loss = 0.2036769948899746
Trained batch 168 in epoch 0, gen_loss = 0.4296581260198672, disc_loss = 0.20365086294842896
Trained batch 169 in epoch 0, gen_loss = 0.4293528588379131, disc_loss = 0.20349082000115337
Trained batch 170 in epoch 0, gen_loss = 0.4287541463361149, disc_loss = 0.20367418534574452
Trained batch 171 in epoch 0, gen_loss = 0.4284978637168574, disc_loss = 0.20365368072376694
Trained batch 172 in epoch 0, gen_loss = 0.42818335318840994, disc_loss = 0.20387505158523603
Trained batch 173 in epoch 0, gen_loss = 0.4276840770724176, disc_loss = 0.20425701501040622
Trained batch 174 in epoch 0, gen_loss = 0.4271190585408892, disc_loss = 0.20451227051871163
Trained batch 175 in epoch 0, gen_loss = 0.42669831825928256, disc_loss = 0.20454113778065552
Trained batch 176 in epoch 0, gen_loss = 0.42625424417398744, disc_loss = 0.20467139763683923
Trained batch 177 in epoch 0, gen_loss = 0.42594618676753526, disc_loss = 0.2045653270704023
Trained batch 178 in epoch 0, gen_loss = 0.4260289164561799, disc_loss = 0.20432423271613415
Trained batch 179 in epoch 0, gen_loss = 0.42582492844925984, disc_loss = 0.2043653331696987
Trained batch 180 in epoch 0, gen_loss = 0.42556755993906303, disc_loss = 0.20449920723122128
Trained batch 181 in epoch 0, gen_loss = 0.4250146535399196, disc_loss = 0.20470241080601137
Trained batch 182 in epoch 0, gen_loss = 0.42457680672895715, disc_loss = 0.2053691828674306
Trained batch 183 in epoch 0, gen_loss = 0.42399568450839625, disc_loss = 0.2054586456683667
Trained batch 184 in epoch 0, gen_loss = 0.42349372973313204, disc_loss = 0.20569661509346318
Trained batch 185 in epoch 0, gen_loss = 0.4233726080386869, disc_loss = 0.20611995610819067
Trained batch 186 in epoch 0, gen_loss = 0.4231716864568027, disc_loss = 0.20604587429985005
Trained batch 187 in epoch 0, gen_loss = 0.422759177361397, disc_loss = 0.20608634779110868
Trained batch 188 in epoch 0, gen_loss = 0.4220833587583411, disc_loss = 0.2061676929394404
Trained batch 189 in epoch 0, gen_loss = 0.4220415756890648, disc_loss = 0.2061111239226241
Trained batch 190 in epoch 0, gen_loss = 0.42158617508348994, disc_loss = 0.2060772036226632
Trained batch 191 in epoch 0, gen_loss = 0.42129382118582726, disc_loss = 0.2060532122850418
Trained batch 192 in epoch 0, gen_loss = 0.4210722851012037, disc_loss = 0.20605433898268585
Trained batch 193 in epoch 0, gen_loss = 0.4210152483170794, disc_loss = 0.20582047711635373
Trained batch 194 in epoch 0, gen_loss = 0.4206810365884732, disc_loss = 0.20607660756661342
Trained batch 195 in epoch 0, gen_loss = 0.42037418393456205, disc_loss = 0.20614711735017446
Trained batch 196 in epoch 0, gen_loss = 0.4204538491776752, disc_loss = 0.2059330260995681
Trained batch 197 in epoch 0, gen_loss = 0.42033594620950293, disc_loss = 0.20601527761630337
Trained batch 198 in epoch 0, gen_loss = 0.4198514041888654, disc_loss = 0.20649159725886493
Trained batch 199 in epoch 0, gen_loss = 0.41957487508654595, disc_loss = 0.20646654598414899
Trained batch 200 in epoch 0, gen_loss = 0.419151498014061, disc_loss = 0.2064920387309582
Trained batch 201 in epoch 0, gen_loss = 0.41890635953681304, disc_loss = 0.20656178699861658
Trained batch 202 in epoch 0, gen_loss = 0.41882139767332033, disc_loss = 0.2066192958742527
Trained batch 203 in epoch 0, gen_loss = 0.4186982157475808, disc_loss = 0.20658869793017706
Trained batch 204 in epoch 0, gen_loss = 0.41856816062113134, disc_loss = 0.2065831769530366
Trained batch 205 in epoch 0, gen_loss = 0.41843299032415, disc_loss = 0.20660637297387263
Trained batch 206 in epoch 0, gen_loss = 0.4182810288120583, disc_loss = 0.20671397267620345
Trained batch 207 in epoch 0, gen_loss = 0.4180125314742327, disc_loss = 0.2066623606504156
Trained batch 208 in epoch 0, gen_loss = 0.418019370171442, disc_loss = 0.20649896790251207
Trained batch 209 in epoch 0, gen_loss = 0.4176099073319208, disc_loss = 0.2067682546519098
Trained batch 210 in epoch 0, gen_loss = 0.4177374801647042, disc_loss = 0.20830792944295712
Trained batch 211 in epoch 0, gen_loss = 0.41737673979885176, disc_loss = 0.20828100047865003
Trained batch 212 in epoch 0, gen_loss = 0.4170788893117591, disc_loss = 0.20824314527948137
Trained batch 213 in epoch 0, gen_loss = 0.4168769555671193, disc_loss = 0.20825940252185982
Trained batch 214 in epoch 0, gen_loss = 0.416476611342541, disc_loss = 0.20842131729735885
Trained batch 215 in epoch 0, gen_loss = 0.4162195929222637, disc_loss = 0.20868412232785313
Trained batch 216 in epoch 0, gen_loss = 0.4155780429938971, disc_loss = 0.20876835128678703
Trained batch 217 in epoch 0, gen_loss = 0.4152302978509063, disc_loss = 0.2087608589491713
Trained batch 218 in epoch 0, gen_loss = 0.41501280338796853, disc_loss = 0.2088983861142642
Trained batch 219 in epoch 0, gen_loss = 0.41456711170348254, disc_loss = 0.20898704318837685
Trained batch 220 in epoch 0, gen_loss = 0.41450539231300354, disc_loss = 0.20902971599706158
Trained batch 221 in epoch 0, gen_loss = 0.4140578359365463, disc_loss = 0.20911453805259755
Trained batch 222 in epoch 0, gen_loss = 0.4139335710104271, disc_loss = 0.2093140947310914
Trained batch 223 in epoch 0, gen_loss = 0.41415238979139496, disc_loss = 0.20988676623840416
Trained batch 224 in epoch 0, gen_loss = 0.41399087468783063, disc_loss = 0.2098970107899772
Trained batch 225 in epoch 0, gen_loss = 0.413515498284745, disc_loss = 0.21003565066947347
Trained batch 226 in epoch 0, gen_loss = 0.41331429024624927, disc_loss = 0.21006649686639003
Trained batch 227 in epoch 0, gen_loss = 0.4130289294479186, disc_loss = 0.21020428816738881
Trained batch 228 in epoch 0, gen_loss = 0.4127851673869587, disc_loss = 0.21024195882430763
Trained batch 229 in epoch 0, gen_loss = 0.41233860811461576, disc_loss = 0.21012798016485962
Trained batch 230 in epoch 0, gen_loss = 0.412101562276031, disc_loss = 0.21000126533178023
Trained batch 231 in epoch 0, gen_loss = 0.41170268647115804, disc_loss = 0.20996496511687493
Trained batch 232 in epoch 0, gen_loss = 0.4118005578354193, disc_loss = 0.2097810495948587
Trained batch 233 in epoch 0, gen_loss = 0.4117493584879443, disc_loss = 0.20961356818930715
Trained batch 234 in epoch 0, gen_loss = 0.4115673203417595, disc_loss = 0.20958051516654644
Trained batch 235 in epoch 0, gen_loss = 0.4115195617837421, disc_loss = 0.20965662257651152
Trained batch 236 in epoch 0, gen_loss = 0.4112327903634888, disc_loss = 0.20976008644586877
Trained batch 237 in epoch 0, gen_loss = 0.41110829307752494, disc_loss = 0.20973368114283106
Trained batch 238 in epoch 0, gen_loss = 0.4112506139727317, disc_loss = 0.20955831785082318
Trained batch 239 in epoch 0, gen_loss = 0.4109805238743623, disc_loss = 0.20981098636984824
Trained batch 240 in epoch 0, gen_loss = 0.4112260090612277, disc_loss = 0.20991061009559395
Trained batch 241 in epoch 0, gen_loss = 0.41095937431351215, disc_loss = 0.2099104983624348
Trained batch 242 in epoch 0, gen_loss = 0.41076568725668355, disc_loss = 0.20982745860093904
Trained batch 243 in epoch 0, gen_loss = 0.41066299623153246, disc_loss = 0.20994959411318184
Trained batch 244 in epoch 0, gen_loss = 0.41041166307974836, disc_loss = 0.2100184079943871
Trained batch 245 in epoch 0, gen_loss = 0.409998005362061, disc_loss = 0.21015861987825332
Trained batch 246 in epoch 0, gen_loss = 0.4100175148803695, disc_loss = 0.21025485693201845
Trained batch 247 in epoch 0, gen_loss = 0.4097830399630531, disc_loss = 0.210358266508387
Trained batch 248 in epoch 0, gen_loss = 0.41003159993144883, disc_loss = 0.2103714415107865
Trained batch 249 in epoch 0, gen_loss = 0.40995337891578676, disc_loss = 0.2103488517999649
Trained batch 250 in epoch 0, gen_loss = 0.40987871676327226, disc_loss = 0.21022257410672557
Trained batch 251 in epoch 0, gen_loss = 0.4096715615855323, disc_loss = 0.2102132153416437
Trained batch 252 in epoch 0, gen_loss = 0.4093570377044527, disc_loss = 0.21012051185600372
Trained batch 253 in epoch 0, gen_loss = 0.4091836855871471, disc_loss = 0.20987263122412164
Trained batch 254 in epoch 0, gen_loss = 0.4091668072868796, disc_loss = 0.20962900127850326
Trained batch 255 in epoch 0, gen_loss = 0.40898609382566065, disc_loss = 0.2095396188669838
Trained batch 256 in epoch 0, gen_loss = 0.40884631872177124, disc_loss = 0.21005342031035443
Trained batch 257 in epoch 0, gen_loss = 0.4087230142696883, disc_loss = 0.21015101584584214
Trained batch 258 in epoch 0, gen_loss = 0.40840865504787693, disc_loss = 0.21019581748481883
Trained batch 259 in epoch 0, gen_loss = 0.4079406139942316, disc_loss = 0.21026483825766124
Trained batch 260 in epoch 0, gen_loss = 0.4072894088609922, disc_loss = 0.21027246854086032
Trained batch 261 in epoch 0, gen_loss = 0.40726698605158856, disc_loss = 0.21011233449209737
Trained batch 262 in epoch 0, gen_loss = 0.4070556203448727, disc_loss = 0.20988856239010625
Trained batch 263 in epoch 0, gen_loss = 0.4068032131727898, disc_loss = 0.20974363426141668
Trained batch 264 in epoch 0, gen_loss = 0.4066608026342572, disc_loss = 0.2096750891433572
Trained batch 265 in epoch 0, gen_loss = 0.4067663718435101, disc_loss = 0.2095125929305428
Trained batch 266 in epoch 0, gen_loss = 0.4064761703826961, disc_loss = 0.20960714174120615
Trained batch 267 in epoch 0, gen_loss = 0.40656026986552707, disc_loss = 0.2099962314563011
Trained batch 268 in epoch 0, gen_loss = 0.40640390716963987, disc_loss = 0.20995505536355938
Trained batch 269 in epoch 0, gen_loss = 0.4061114611449065, disc_loss = 0.20994641063389954
Trained batch 270 in epoch 0, gen_loss = 0.4057791244059911, disc_loss = 0.2098819124632656
Trained batch 271 in epoch 0, gen_loss = 0.4054257438025054, disc_loss = 0.20983842283706455
Trained batch 272 in epoch 0, gen_loss = 0.4051587171170301, disc_loss = 0.20971183915496308
Trained batch 273 in epoch 0, gen_loss = 0.40455472164780554, disc_loss = 0.2097192047721278
Trained batch 274 in epoch 0, gen_loss = 0.40447380694476043, disc_loss = 0.2097028293392875
Trained batch 275 in epoch 0, gen_loss = 0.4044760156800781, disc_loss = 0.21009725796571677
Trained batch 276 in epoch 0, gen_loss = 0.4043684819114768, disc_loss = 0.21015081896248278
Trained batch 277 in epoch 0, gen_loss = 0.4042749803700893, disc_loss = 0.21009594110919416
Trained batch 278 in epoch 0, gen_loss = 0.4041566450322401, disc_loss = 0.2100946373409695
Trained batch 279 in epoch 0, gen_loss = 0.4039932283971991, disc_loss = 0.21010629662445612
Trained batch 280 in epoch 0, gen_loss = 0.4037103422808053, disc_loss = 0.2101059798880404
Trained batch 281 in epoch 0, gen_loss = 0.40342856267242566, disc_loss = 0.21034943803827813
Trained batch 282 in epoch 0, gen_loss = 0.40291317549695393, disc_loss = 0.2103105280087609
Trained batch 283 in epoch 0, gen_loss = 0.40298616088611977, disc_loss = 0.210163247942085
Trained batch 284 in epoch 0, gen_loss = 0.4032344012929682, disc_loss = 0.2100025961273595
Trained batch 285 in epoch 0, gen_loss = 0.40286977422404124, disc_loss = 0.2099577952827607
Trained batch 286 in epoch 0, gen_loss = 0.40258863371008363, disc_loss = 0.2099923665930585
Trained batch 287 in epoch 0, gen_loss = 0.4023330067801807, disc_loss = 0.21000518277287483
Trained batch 288 in epoch 0, gen_loss = 0.40196677341180687, disc_loss = 0.20997923246510714
Trained batch 289 in epoch 0, gen_loss = 0.4017615847546479, disc_loss = 0.2100343373828921
Trained batch 290 in epoch 0, gen_loss = 0.4016659179913629, disc_loss = 0.2099411852171331
Trained batch 291 in epoch 0, gen_loss = 0.4015003834685234, disc_loss = 0.20990857471750207
Trained batch 292 in epoch 0, gen_loss = 0.40114130898547257, disc_loss = 0.20996672576197992
Trained batch 293 in epoch 0, gen_loss = 0.40093719046943044, disc_loss = 0.2098200100721145
Trained batch 294 in epoch 0, gen_loss = 0.4006803881313841, disc_loss = 0.20974638396400516
Trained batch 295 in epoch 0, gen_loss = 0.4005236604527847, disc_loss = 0.2097153166762075
Trained batch 296 in epoch 0, gen_loss = 0.40024631743880634, disc_loss = 0.2095594557146432
Trained batch 297 in epoch 0, gen_loss = 0.4000196529914869, disc_loss = 0.20957134354034526
Trained batch 298 in epoch 0, gen_loss = 0.39998814981916675, disc_loss = 0.20970847166102866
Trained batch 299 in epoch 0, gen_loss = 0.39989769548177717, disc_loss = 0.20974976499875386
Trained batch 300 in epoch 0, gen_loss = 0.4000719180732866, disc_loss = 0.20945911302519002
Trained batch 301 in epoch 0, gen_loss = 0.4001572054150878, disc_loss = 0.20914217987597383
Trained batch 302 in epoch 0, gen_loss = 0.4001760022474988, disc_loss = 0.2086517841312358
Trained batch 303 in epoch 0, gen_loss = 0.3999792196248707, disc_loss = 0.20882264514894863
Trained batch 304 in epoch 0, gen_loss = 0.3999784881951379, disc_loss = 0.20938745766389566
Trained batch 305 in epoch 0, gen_loss = 0.39981039891055986, disc_loss = 0.21006104077389037
Trained batch 306 in epoch 0, gen_loss = 0.4000120225092487, disc_loss = 0.21404972157959828
Trained batch 307 in epoch 0, gen_loss = 0.4004104613483726, disc_loss = 0.21789341023216
Trained batch 308 in epoch 0, gen_loss = 0.4003864805482352, disc_loss = 0.2188071103157735
Trained batch 309 in epoch 0, gen_loss = 0.4004305108900993, disc_loss = 0.21929147897228118
Trained batch 310 in epoch 0, gen_loss = 0.40018448904396253, disc_loss = 0.21957813294370843
Trained batch 311 in epoch 0, gen_loss = 0.4000002813453858, disc_loss = 0.2197151703712268
Trained batch 312 in epoch 0, gen_loss = 0.399889307566725, disc_loss = 0.21978750034643058
Trained batch 313 in epoch 0, gen_loss = 0.39965035002322713, disc_loss = 0.21983465101498706
Trained batch 314 in epoch 0, gen_loss = 0.39931308371680124, disc_loss = 0.2198461122456051
Trained batch 315 in epoch 0, gen_loss = 0.39916631249310097, disc_loss = 0.21983848163221456
Trained batch 316 in epoch 0, gen_loss = 0.3991041421326177, disc_loss = 0.21980846567484857
Trained batch 317 in epoch 0, gen_loss = 0.39917373057431393, disc_loss = 0.21982849464289048
Trained batch 318 in epoch 0, gen_loss = 0.3989201421647984, disc_loss = 0.21988199100038475
Trained batch 319 in epoch 0, gen_loss = 0.39863762715831397, disc_loss = 0.21996619901619852
Trained batch 320 in epoch 0, gen_loss = 0.3987485484170765, disc_loss = 0.22003773277236666
Trained batch 321 in epoch 0, gen_loss = 0.39845326959346394, disc_loss = 0.22008161741939392
Trained batch 322 in epoch 0, gen_loss = 0.39851100692069935, disc_loss = 0.22008627934537067
Trained batch 323 in epoch 0, gen_loss = 0.3983719570585239, disc_loss = 0.22004468725235374
Trained batch 324 in epoch 0, gen_loss = 0.39819964427214405, disc_loss = 0.22008311450481416
Trained batch 325 in epoch 0, gen_loss = 0.39810530064296135, disc_loss = 0.2203121952758245
Trained batch 326 in epoch 0, gen_loss = 0.39793449284833504, disc_loss = 0.2204305623922873
Trained batch 327 in epoch 0, gen_loss = 0.39771581713746235, disc_loss = 0.22048343336436807
Trained batch 328 in epoch 0, gen_loss = 0.397623491595219, disc_loss = 0.22051048813257537
Trained batch 329 in epoch 0, gen_loss = 0.39769455709240653, disc_loss = 0.22050871975494155
Trained batch 330 in epoch 0, gen_loss = 0.3975448621904022, disc_loss = 0.2205474789499156
Trained batch 331 in epoch 0, gen_loss = 0.397375650614141, disc_loss = 0.22058467171996474
Trained batch 332 in epoch 0, gen_loss = 0.396985025198252, disc_loss = 0.22069203835707885
Trained batch 333 in epoch 0, gen_loss = 0.39675515916890014, disc_loss = 0.22081945899003994
Trained batch 334 in epoch 0, gen_loss = 0.396592094738092, disc_loss = 0.2209081407803208
Trained batch 335 in epoch 0, gen_loss = 0.3963935151696205, disc_loss = 0.22100565174505823
Trained batch 336 in epoch 0, gen_loss = 0.39630015977058636, disc_loss = 0.22108239846342748
Trained batch 337 in epoch 0, gen_loss = 0.3960632918149056, disc_loss = 0.22118610443448175
Trained batch 338 in epoch 0, gen_loss = 0.39575013553498417, disc_loss = 0.22127071576835836
Trained batch 339 in epoch 0, gen_loss = 0.3955622715985074, disc_loss = 0.22136426287538866
Trained batch 340 in epoch 0, gen_loss = 0.39538654947210966, disc_loss = 0.22142181499612645
Trained batch 341 in epoch 0, gen_loss = 0.3952115033453668, disc_loss = 0.22148248710130392
Trained batch 342 in epoch 0, gen_loss = 0.3950374832827565, disc_loss = 0.22153348543032264
Trained batch 343 in epoch 0, gen_loss = 0.39484570703880734, disc_loss = 0.22153913727853186
Trained batch 344 in epoch 0, gen_loss = 0.39471145695534304, disc_loss = 0.22153703894304191
Trained batch 345 in epoch 0, gen_loss = 0.39459812115727133, disc_loss = 0.22155472571622428
Trained batch 346 in epoch 0, gen_loss = 0.3946404215753594, disc_loss = 0.221534788866208
Trained batch 347 in epoch 0, gen_loss = 0.394708514213562, disc_loss = 0.22154001540493692
Trained batch 348 in epoch 0, gen_loss = 0.39478184944579114, disc_loss = 0.22152903099627072
Trained batch 349 in epoch 0, gen_loss = 0.39454707179750714, disc_loss = 0.22158328597034727
Trained batch 350 in epoch 0, gen_loss = 0.39433228171449103, disc_loss = 0.2215914460498723
Trained batch 351 in epoch 0, gen_loss = 0.3940565998411991, disc_loss = 0.22164402978325431
Trained batch 352 in epoch 0, gen_loss = 0.393822793835621, disc_loss = 0.22169719969922355
Trained batch 353 in epoch 0, gen_loss = 0.3935920752711215, disc_loss = 0.2217306637831327
Trained batch 354 in epoch 0, gen_loss = 0.3933871069424589, disc_loss = 0.2217650082329629
Trained batch 355 in epoch 0, gen_loss = 0.39334668738118717, disc_loss = 0.22177688714660956
Trained batch 356 in epoch 0, gen_loss = 0.39321486714507353, disc_loss = 0.22179168830064833
Trained batch 357 in epoch 0, gen_loss = 0.3932115730293636, disc_loss = 0.2217516175278738
Trained batch 358 in epoch 0, gen_loss = 0.39295076875633517, disc_loss = 0.221723410952058
Trained batch 359 in epoch 0, gen_loss = 0.39282189226812786, disc_loss = 0.2216842844668362
Trained batch 360 in epoch 0, gen_loss = 0.39275938280731687, disc_loss = 0.2217449438538908
Trained batch 361 in epoch 0, gen_loss = 0.3928928152138357, disc_loss = 0.22194526776753737
Trained batch 362 in epoch 0, gen_loss = 0.3929405693508705, disc_loss = 0.22201728426720485
Trained batch 363 in epoch 0, gen_loss = 0.39269314730887883, disc_loss = 0.2220727800504192
Trained batch 364 in epoch 0, gen_loss = 0.39270657782685264, disc_loss = 0.22222638856874755
Trained batch 365 in epoch 0, gen_loss = 0.3926402593408126, disc_loss = 0.22222411095118913
Trained batch 366 in epoch 0, gen_loss = 0.3923688746115817, disc_loss = 0.22222879837579235
Trained batch 367 in epoch 0, gen_loss = 0.39214203158474487, disc_loss = 0.22225509122337983
Trained batch 368 in epoch 0, gen_loss = 0.39194232928074474, disc_loss = 0.22221499931844593
Trained batch 369 in epoch 0, gen_loss = 0.3920080834949339, disc_loss = 0.2221143864296578
Trained batch 370 in epoch 0, gen_loss = 0.3918189193521227, disc_loss = 0.22211839712533668
Trained batch 371 in epoch 0, gen_loss = 0.3918239660160516, disc_loss = 0.2221542351668881
Trained batch 372 in epoch 0, gen_loss = 0.3917259694583934, disc_loss = 0.2221924850352648
Trained batch 373 in epoch 0, gen_loss = 0.3915295478972522, disc_loss = 0.22224053095050036
Trained batch 374 in epoch 0, gen_loss = 0.3914166518052419, disc_loss = 0.2222524832089742
Trained batch 375 in epoch 0, gen_loss = 0.39116991747249946, disc_loss = 0.2222111867938904
Trained batch 376 in epoch 0, gen_loss = 0.3910637295530709, disc_loss = 0.22213701109354944
Trained batch 377 in epoch 0, gen_loss = 0.39096871775294106, disc_loss = 0.22209035431739516
Trained batch 378 in epoch 0, gen_loss = 0.39084612631231624, disc_loss = 0.22207325276252776
Trained batch 379 in epoch 0, gen_loss = 0.39092491833787213, disc_loss = 0.22197291564784552
Trained batch 380 in epoch 0, gen_loss = 0.3906680243065351, disc_loss = 0.2219690375049596
Trained batch 381 in epoch 0, gen_loss = 0.3904238361962803, disc_loss = 0.22220304994526957
Trained batch 382 in epoch 0, gen_loss = 0.3904630435197845, disc_loss = 0.2223034952001223
Trained batch 383 in epoch 0, gen_loss = 0.39036062693533796, disc_loss = 0.22229915511949608
Trained batch 384 in epoch 0, gen_loss = 0.39027004628986506, disc_loss = 0.22227265219409745
Trained batch 385 in epoch 0, gen_loss = 0.39002602852379104, disc_loss = 0.22224494421111488
Trained batch 386 in epoch 0, gen_loss = 0.39010397192735696, disc_loss = 0.22216945536222876
Trained batch 387 in epoch 0, gen_loss = 0.3899516585407798, disc_loss = 0.22216856095594228
Trained batch 388 in epoch 0, gen_loss = 0.38986928512014274, disc_loss = 0.22242527817086266
Trained batch 389 in epoch 0, gen_loss = 0.38971941814972805, disc_loss = 0.2223756499015368
Trained batch 390 in epoch 0, gen_loss = 0.3896457507177387, disc_loss = 0.22234097153634366
Trained batch 391 in epoch 0, gen_loss = 0.38943337200551614, disc_loss = 0.22228146245589062
Trained batch 392 in epoch 0, gen_loss = 0.38937699756852845, disc_loss = 0.22216571484509923
Trained batch 393 in epoch 0, gen_loss = 0.3892893471996191, disc_loss = 0.22208329585149203
Trained batch 394 in epoch 0, gen_loss = 0.3891456911835489, disc_loss = 0.2221060822658901
Trained batch 395 in epoch 0, gen_loss = 0.38891340671765684, disc_loss = 0.22222162681547078
Trained batch 396 in epoch 0, gen_loss = 0.3889259737294627, disc_loss = 0.22219694141176546
Trained batch 397 in epoch 0, gen_loss = 0.3887100719177543, disc_loss = 0.22214862359828086
Trained batch 398 in epoch 0, gen_loss = 0.38879099652581944, disc_loss = 0.2221173561904066
Trained batch 399 in epoch 0, gen_loss = 0.3888138718158007, disc_loss = 0.22226744309067725
Trained batch 400 in epoch 0, gen_loss = 0.38871309138890214, disc_loss = 0.2224318567208221
Trained batch 401 in epoch 0, gen_loss = 0.38878847814317957, disc_loss = 0.22235756979059818
Trained batch 402 in epoch 0, gen_loss = 0.38858690281068126, disc_loss = 0.22245662997733276
Trained batch 403 in epoch 0, gen_loss = 0.38845003868388656, disc_loss = 0.22255672853772002
Trained batch 404 in epoch 0, gen_loss = 0.3881691687636905, disc_loss = 0.22257042151910286
Trained batch 405 in epoch 0, gen_loss = 0.3879878229548778, disc_loss = 0.22253840765342336
Trained batch 406 in epoch 0, gen_loss = 0.3878827054026086, disc_loss = 0.22247809435284402
Trained batch 407 in epoch 0, gen_loss = 0.3877488403928046, disc_loss = 0.22238327219497925
Trained batch 408 in epoch 0, gen_loss = 0.3876260213717855, disc_loss = 0.22230241092463868
Trained batch 409 in epoch 0, gen_loss = 0.38750361654816606, disc_loss = 0.22218721672529126
Trained batch 410 in epoch 0, gen_loss = 0.3874627754200984, disc_loss = 0.22203094031833964
Trained batch 411 in epoch 0, gen_loss = 0.3873910807724138, disc_loss = 0.22192866604739023
Trained batch 412 in epoch 0, gen_loss = 0.3872517540726188, disc_loss = 0.2220184392054491
Trained batch 413 in epoch 0, gen_loss = 0.3872230678508823, disc_loss = 0.2224209570294417
Trained batch 414 in epoch 0, gen_loss = 0.3871751910232636, disc_loss = 0.22234567834670285
Trained batch 415 in epoch 0, gen_loss = 0.3871380522703895, disc_loss = 0.22224524126459771
Trained batch 416 in epoch 0, gen_loss = 0.3870429023564291, disc_loss = 0.22222623304068614
Trained batch 417 in epoch 0, gen_loss = 0.3870435806980544, disc_loss = 0.2221450041712186
Trained batch 418 in epoch 0, gen_loss = 0.38695824907332443, disc_loss = 0.2221745864303698
Trained batch 419 in epoch 0, gen_loss = 0.38699338464509875, disc_loss = 0.22203877298604874
Trained batch 420 in epoch 0, gen_loss = 0.3869092985456743, disc_loss = 0.2220886539393536
Trained batch 421 in epoch 0, gen_loss = 0.3867975935269306, disc_loss = 0.22217530400549632
Trained batch 422 in epoch 0, gen_loss = 0.38676343960401294, disc_loss = 0.22218866050947925
Trained batch 423 in epoch 0, gen_loss = 0.3866178852347833, disc_loss = 0.2221847726207859
Trained batch 424 in epoch 0, gen_loss = 0.38667025867630456, disc_loss = 0.2222527062892914
Trained batch 425 in epoch 0, gen_loss = 0.38673800467885155, disc_loss = 0.22219008063906234
Trained batch 426 in epoch 0, gen_loss = 0.38679000553816767, disc_loss = 0.22204894158963018
Trained batch 427 in epoch 0, gen_loss = 0.3867310754885183, disc_loss = 0.2218713433803799
Trained batch 428 in epoch 0, gen_loss = 0.38656956151926714, disc_loss = 0.22179501460287676
Trained batch 429 in epoch 0, gen_loss = 0.3864334265853083, disc_loss = 0.2219300676570382
Trained batch 430 in epoch 0, gen_loss = 0.3864187259408548, disc_loss = 0.22211087106137153
Trained batch 431 in epoch 0, gen_loss = 0.3864764204869668, disc_loss = 0.22230761729318788
Trained batch 432 in epoch 0, gen_loss = 0.3864459841411053, disc_loss = 0.2222215757634293
Trained batch 433 in epoch 0, gen_loss = 0.3862133323459581, disc_loss = 0.22225585439100792
Trained batch 434 in epoch 0, gen_loss = 0.38605244803702693, disc_loss = 0.2221972628228966
Trained batch 435 in epoch 0, gen_loss = 0.38599594292837547, disc_loss = 0.222135666826176
Trained batch 436 in epoch 0, gen_loss = 0.38592770784343133, disc_loss = 0.2220096603138223
Trained batch 437 in epoch 0, gen_loss = 0.385748191919501, disc_loss = 0.22190993568396458
Trained batch 438 in epoch 0, gen_loss = 0.38572261117585427, disc_loss = 0.22186097573989616
Trained batch 439 in epoch 0, gen_loss = 0.3857532235031778, disc_loss = 0.22191122936254198
Trained batch 440 in epoch 0, gen_loss = 0.3856536009414396, disc_loss = 0.22180543431078767
Trained batch 441 in epoch 0, gen_loss = 0.38588828482239496, disc_loss = 0.22162380929176623
Trained batch 442 in epoch 0, gen_loss = 0.3857341365001541, disc_loss = 0.22162060863411992
Trained batch 443 in epoch 0, gen_loss = 0.3857176843527201, disc_loss = 0.2215952341285375
Trained batch 444 in epoch 0, gen_loss = 0.3856832950972439, disc_loss = 0.2214757082167636
Trained batch 445 in epoch 0, gen_loss = 0.3855781364066718, disc_loss = 0.22129466304463655
Trained batch 446 in epoch 0, gen_loss = 0.38568680405083383, disc_loss = 0.2210553352131406
Trained batch 447 in epoch 0, gen_loss = 0.3857364961877465, disc_loss = 0.22085846291988023
Trained batch 448 in epoch 0, gen_loss = 0.38566945350515286, disc_loss = 0.22061142441557352
Trained batch 449 in epoch 0, gen_loss = 0.3856374168395996, disc_loss = 0.22034119957023196
Trained batch 450 in epoch 0, gen_loss = 0.38552481762057134, disc_loss = 0.2200387562986488
Trained batch 451 in epoch 0, gen_loss = 0.3855499879712552, disc_loss = 0.21968194002499886
Trained batch 452 in epoch 0, gen_loss = 0.38546660470120425, disc_loss = 0.21947170837595237
Trained batch 453 in epoch 0, gen_loss = 0.38532327771974556, disc_loss = 0.21957055942898018
Trained batch 454 in epoch 0, gen_loss = 0.3852457767659491, disc_loss = 0.22044803311045352
Trained batch 455 in epoch 0, gen_loss = 0.38514568584791403, disc_loss = 0.22047063352932272
Trained batch 456 in epoch 0, gen_loss = 0.38542314046582193, disc_loss = 0.22042626208529953
Trained batch 457 in epoch 0, gen_loss = 0.38524888124007844, disc_loss = 0.22073175358752756
Trained batch 458 in epoch 0, gen_loss = 0.38518756712443947, disc_loss = 0.22075660907397604
Trained batch 459 in epoch 0, gen_loss = 0.3851652480337931, disc_loss = 0.2207384991985948
Trained batch 460 in epoch 0, gen_loss = 0.385041021990414, disc_loss = 0.22080453448886467
Trained batch 461 in epoch 0, gen_loss = 0.38516716181715843, disc_loss = 0.2206740848703947
Trained batch 462 in epoch 0, gen_loss = 0.3858434210971931, disc_loss = 0.22043381638615744
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.33917003870010376, disc_loss = 0.21648484468460083
Trained batch 1 in epoch 1, gen_loss = 0.3881060779094696, disc_loss = 0.20419710874557495
Trained batch 2 in epoch 1, gen_loss = 0.39121554295221966, disc_loss = 0.18906388680140176
Trained batch 3 in epoch 1, gen_loss = 0.3682125136256218, disc_loss = 0.18927910923957825
Trained batch 4 in epoch 1, gen_loss = 0.35600945353507996, disc_loss = 0.19442449510097504
Trained batch 5 in epoch 1, gen_loss = 0.34530582030614215, disc_loss = 0.19578455885251364
Trained batch 6 in epoch 1, gen_loss = 0.34417945572308134, disc_loss = 0.2084523524556841
Trained batch 7 in epoch 1, gen_loss = 0.33762744441628456, disc_loss = 0.20308122225105762
Trained batch 8 in epoch 1, gen_loss = 0.34112724992964005, disc_loss = 0.20016316407256657
Trained batch 9 in epoch 1, gen_loss = 0.3421219766139984, disc_loss = 0.19839721471071242
Trained batch 10 in epoch 1, gen_loss = 0.34446409886533563, disc_loss = 0.19642207432876935
Trained batch 11 in epoch 1, gen_loss = 0.34327786415815353, disc_loss = 0.20329724376400313
Trained batch 12 in epoch 1, gen_loss = 0.34310153126716614, disc_loss = 0.2001212640450551
Trained batch 13 in epoch 1, gen_loss = 0.34428716770240236, disc_loss = 0.20103718021086284
Trained batch 14 in epoch 1, gen_loss = 0.3428811490535736, disc_loss = 0.20245640377203625
Trained batch 15 in epoch 1, gen_loss = 0.3466228824108839, disc_loss = 0.2005887683480978
Trained batch 16 in epoch 1, gen_loss = 0.3471439217819887, disc_loss = 0.2005137108704623
Trained batch 17 in epoch 1, gen_loss = 0.35187200208504993, disc_loss = 0.20078774872753355
Trained batch 18 in epoch 1, gen_loss = 0.34988021380022954, disc_loss = 0.198895936733798
Trained batch 19 in epoch 1, gen_loss = 0.35626606494188306, disc_loss = 0.1966550014913082
Trained batch 20 in epoch 1, gen_loss = 0.3585066795349121, disc_loss = 0.19488918213617235
Trained batch 21 in epoch 1, gen_loss = 0.35381032255562866, disc_loss = 0.1943879113955931
Trained batch 22 in epoch 1, gen_loss = 0.35009551696155383, disc_loss = 0.1946998750386031
Trained batch 23 in epoch 1, gen_loss = 0.35247329001625377, disc_loss = 0.19435300988455614
Trained batch 24 in epoch 1, gen_loss = 0.35413737654685973, disc_loss = 0.19158067643642426
Trained batch 25 in epoch 1, gen_loss = 0.3534127129958226, disc_loss = 0.19162504546917403
Trained batch 26 in epoch 1, gen_loss = 0.35408497518963283, disc_loss = 0.20009705589877236
Trained batch 27 in epoch 1, gen_loss = 0.3548790706055505, disc_loss = 0.2006749122270516
Trained batch 28 in epoch 1, gen_loss = 0.3561453192398466, disc_loss = 0.1998555202936304
Trained batch 29 in epoch 1, gen_loss = 0.3597495247920354, disc_loss = 0.19892412722110747
Trained batch 30 in epoch 1, gen_loss = 0.3585266740091385, disc_loss = 0.19879903331879648
Trained batch 31 in epoch 1, gen_loss = 0.35758985858410597, disc_loss = 0.20265461783856153
Trained batch 32 in epoch 1, gen_loss = 0.3559141926693194, disc_loss = 0.2051184872786204
Trained batch 33 in epoch 1, gen_loss = 0.3567540680660921, disc_loss = 0.20307729919167125
Trained batch 34 in epoch 1, gen_loss = 0.356388669354575, disc_loss = 0.2037483411175864
Trained batch 35 in epoch 1, gen_loss = 0.3550722756319576, disc_loss = 0.20386488404538897
Trained batch 36 in epoch 1, gen_loss = 0.3550636631411475, disc_loss = 0.20316746065745483
Trained batch 37 in epoch 1, gen_loss = 0.355033582762668, disc_loss = 0.2041412254697398
Trained batch 38 in epoch 1, gen_loss = 0.35320469431388074, disc_loss = 0.20438298544822595
Trained batch 39 in epoch 1, gen_loss = 0.3539022319018841, disc_loss = 0.2047871995717287
Trained batch 40 in epoch 1, gen_loss = 0.3523067955563708, disc_loss = 0.20430335511521594
Trained batch 41 in epoch 1, gen_loss = 0.3521535176606405, disc_loss = 0.20448691575300126
Trained batch 42 in epoch 1, gen_loss = 0.3501217968242113, disc_loss = 0.20462614193905232
Trained batch 43 in epoch 1, gen_loss = 0.3511407984928651, disc_loss = 0.2031455287201838
Trained batch 44 in epoch 1, gen_loss = 0.35162856181462604, disc_loss = 0.201983505487442
Trained batch 45 in epoch 1, gen_loss = 0.35198063111823535, disc_loss = 0.20289902972138446
Trained batch 46 in epoch 1, gen_loss = 0.3513733300756901, disc_loss = 0.20179513540673763
Trained batch 47 in epoch 1, gen_loss = 0.3515300427873929, disc_loss = 0.2006188544134299
Trained batch 48 in epoch 1, gen_loss = 0.3518021550713753, disc_loss = 0.19901108756965522
Trained batch 49 in epoch 1, gen_loss = 0.35224500477313997, disc_loss = 0.20030357494950293
Trained batch 50 in epoch 1, gen_loss = 0.351457312410953, disc_loss = 0.2016731040442691
Trained batch 51 in epoch 1, gen_loss = 0.35311733530117917, disc_loss = 0.19983351302261537
Trained batch 52 in epoch 1, gen_loss = 0.35447553193794107, disc_loss = 0.19840448209137287
Trained batch 53 in epoch 1, gen_loss = 0.35286270468323316, disc_loss = 0.19729517000140967
Trained batch 54 in epoch 1, gen_loss = 0.35308981266888706, disc_loss = 0.1968694420023398
Trained batch 55 in epoch 1, gen_loss = 0.353023672742503, disc_loss = 0.1963499602196472
Trained batch 56 in epoch 1, gen_loss = 0.35335054157073037, disc_loss = 0.19485841534639659
Trained batch 57 in epoch 1, gen_loss = 0.35485618330281354, disc_loss = 0.19458890860450678
Trained batch 58 in epoch 1, gen_loss = 0.3548286466275231, disc_loss = 0.194483878501391
Trained batch 59 in epoch 1, gen_loss = 0.3541649748881658, disc_loss = 0.19506095126271247
Trained batch 60 in epoch 1, gen_loss = 0.3552131872685229, disc_loss = 0.19555912960748204
Trained batch 61 in epoch 1, gen_loss = 0.35478121955548564, disc_loss = 0.19680086571362712
Trained batch 62 in epoch 1, gen_loss = 0.3553270636096833, disc_loss = 0.1969866140021218
Trained batch 63 in epoch 1, gen_loss = 0.3547734175808728, disc_loss = 0.19612736720591784
Trained batch 64 in epoch 1, gen_loss = 0.3553692116187169, disc_loss = 0.19790916672119727
Trained batch 65 in epoch 1, gen_loss = 0.3562391540317824, disc_loss = 0.2020938044244593
Trained batch 66 in epoch 1, gen_loss = 0.35558043131187783, disc_loss = 0.2021664392147491
Trained batch 67 in epoch 1, gen_loss = 0.3544284455916461, disc_loss = 0.20443957101772814
Trained batch 68 in epoch 1, gen_loss = 0.3539949400701385, disc_loss = 0.20410608057526575
Trained batch 69 in epoch 1, gen_loss = 0.3544264248439244, disc_loss = 0.20429463386535646
Trained batch 70 in epoch 1, gen_loss = 0.35514817481309596, disc_loss = 0.20405976726135738
Trained batch 71 in epoch 1, gen_loss = 0.35548947544561493, disc_loss = 0.20311437153981793
Trained batch 72 in epoch 1, gen_loss = 0.35501790618243284, disc_loss = 0.20288981354399904
Trained batch 73 in epoch 1, gen_loss = 0.3550650022319845, disc_loss = 0.2024757286181321
Trained batch 74 in epoch 1, gen_loss = 0.35519279559453326, disc_loss = 0.20283239444096884
Trained batch 75 in epoch 1, gen_loss = 0.35505946098189606, disc_loss = 0.2029133439064026
Trained batch 76 in epoch 1, gen_loss = 0.35451716958702384, disc_loss = 0.20242317465992718
Trained batch 77 in epoch 1, gen_loss = 0.35462969579757786, disc_loss = 0.2022251479136638
Trained batch 78 in epoch 1, gen_loss = 0.35509163329872906, disc_loss = 0.20196695757817618
Trained batch 79 in epoch 1, gen_loss = 0.354888204112649, disc_loss = 0.20218920148909092
Trained batch 80 in epoch 1, gen_loss = 0.35440314184000465, disc_loss = 0.20228479986573444
Trained batch 81 in epoch 1, gen_loss = 0.3546047461468999, disc_loss = 0.20225418359041214
Trained batch 82 in epoch 1, gen_loss = 0.3539639452853835, disc_loss = 0.20249776793531624
Trained batch 83 in epoch 1, gen_loss = 0.3543090043323381, disc_loss = 0.20161842004883856
Trained batch 84 in epoch 1, gen_loss = 0.35387816218768847, disc_loss = 0.20097214597112992
Trained batch 85 in epoch 1, gen_loss = 0.35405769805575527, disc_loss = 0.20028539920269056
Trained batch 86 in epoch 1, gen_loss = 0.3542372067084258, disc_loss = 0.19962311219209913
Trained batch 87 in epoch 1, gen_loss = 0.3537611063908447, disc_loss = 0.19869755030694333
Trained batch 88 in epoch 1, gen_loss = 0.35394539491514143, disc_loss = 0.19805841608328767
Trained batch 89 in epoch 1, gen_loss = 0.3542541762193044, disc_loss = 0.19701419588592317
Trained batch 90 in epoch 1, gen_loss = 0.3542565582217751, disc_loss = 0.19633112913304632
Trained batch 91 in epoch 1, gen_loss = 0.35454748344162235, disc_loss = 0.1960969144559425
Trained batch 92 in epoch 1, gen_loss = 0.35396743621877447, disc_loss = 0.19617785849878866
Trained batch 93 in epoch 1, gen_loss = 0.354991780633622, disc_loss = 0.1962038387960576
Trained batch 94 in epoch 1, gen_loss = 0.35559333562850953, disc_loss = 0.19636965127367723
Trained batch 95 in epoch 1, gen_loss = 0.3559199444328745, disc_loss = 0.1960511926251153
Trained batch 96 in epoch 1, gen_loss = 0.35594379809713855, disc_loss = 0.19534217297416373
Trained batch 97 in epoch 1, gen_loss = 0.35568026985440937, disc_loss = 0.19739897427510242
Trained batch 98 in epoch 1, gen_loss = 0.35573130364369865, disc_loss = 0.1972481104159596
Trained batch 99 in epoch 1, gen_loss = 0.35647489458322523, disc_loss = 0.19692515924572945
Trained batch 100 in epoch 1, gen_loss = 0.35650877875856835, disc_loss = 0.19749135088802564
Trained batch 101 in epoch 1, gen_loss = 0.3562982488496631, disc_loss = 0.19699875294577843
Trained batch 102 in epoch 1, gen_loss = 0.35565888708077587, disc_loss = 0.19643928819489712
Trained batch 103 in epoch 1, gen_loss = 0.3555749717813272, disc_loss = 0.19650559070018622
Trained batch 104 in epoch 1, gen_loss = 0.3565825110390073, disc_loss = 0.19645811248393286
Trained batch 105 in epoch 1, gen_loss = 0.3563515394926071, disc_loss = 0.19557490811314224
Trained batch 106 in epoch 1, gen_loss = 0.3564390721165131, disc_loss = 0.1951443999309406
Trained batch 107 in epoch 1, gen_loss = 0.35641460010298975, disc_loss = 0.19572611960271993
Trained batch 108 in epoch 1, gen_loss = 0.3563363721611303, disc_loss = 0.19506925993829693
Trained batch 109 in epoch 1, gen_loss = 0.3555900741707195, disc_loss = 0.19452011361718177
Trained batch 110 in epoch 1, gen_loss = 0.35608661738601893, disc_loss = 0.19505046475846488
Trained batch 111 in epoch 1, gen_loss = 0.3569367812680347, disc_loss = 0.19582671266315238
Trained batch 112 in epoch 1, gen_loss = 0.3567109722479255, disc_loss = 0.1957727163634469
Trained batch 113 in epoch 1, gen_loss = 0.3569398713216447, disc_loss = 0.19520449422692
Trained batch 114 in epoch 1, gen_loss = 0.3573950757151065, disc_loss = 0.19485810496236966
Trained batch 115 in epoch 1, gen_loss = 0.35778656884514054, disc_loss = 0.194287633523345
Trained batch 116 in epoch 1, gen_loss = 0.3586415093169253, disc_loss = 0.19361583793010467
Trained batch 117 in epoch 1, gen_loss = 0.35901495208174494, disc_loss = 0.1930906519420066
Trained batch 118 in epoch 1, gen_loss = 0.359008179742749, disc_loss = 0.1928014193638032
Trained batch 119 in epoch 1, gen_loss = 0.3602094419300556, disc_loss = 0.1922985214119156
Trained batch 120 in epoch 1, gen_loss = 0.3604355193366689, disc_loss = 0.19232396233426638
Trained batch 121 in epoch 1, gen_loss = 0.3601848436672179, disc_loss = 0.1935829557478428
Trained batch 122 in epoch 1, gen_loss = 0.360082019393037, disc_loss = 0.19354847721694932
Trained batch 123 in epoch 1, gen_loss = 0.35936038820974286, disc_loss = 0.19378614635957825
Trained batch 124 in epoch 1, gen_loss = 0.35931433486938474, disc_loss = 0.19379377955198288
Trained batch 125 in epoch 1, gen_loss = 0.35926781476490083, disc_loss = 0.1938213005307175
Trained batch 126 in epoch 1, gen_loss = 0.3594015322801635, disc_loss = 0.19562288150777968
Trained batch 127 in epoch 1, gen_loss = 0.358874925179407, disc_loss = 0.1955377136473544
Trained batch 128 in epoch 1, gen_loss = 0.35852729650430903, disc_loss = 0.19533956276122913
Trained batch 129 in epoch 1, gen_loss = 0.3584344737804853, disc_loss = 0.19498860383263
Trained batch 130 in epoch 1, gen_loss = 0.3585109492294661, disc_loss = 0.19440655472851892
Trained batch 131 in epoch 1, gen_loss = 0.35851399758548447, disc_loss = 0.19377836923707614
Trained batch 132 in epoch 1, gen_loss = 0.3584253622176952, disc_loss = 0.1932171518753346
Trained batch 133 in epoch 1, gen_loss = 0.35875780613564734, disc_loss = 0.19272212934360575
Trained batch 134 in epoch 1, gen_loss = 0.35875751221621477, disc_loss = 0.1923192653942991
Trained batch 135 in epoch 1, gen_loss = 0.3592489686082391, disc_loss = 0.19218149666181383
Trained batch 136 in epoch 1, gen_loss = 0.3593434180221418, disc_loss = 0.19175080405752154
Trained batch 137 in epoch 1, gen_loss = 0.35963825535946997, disc_loss = 0.1913350757373416
Trained batch 138 in epoch 1, gen_loss = 0.3591246739994708, disc_loss = 0.1906138409277518
Trained batch 139 in epoch 1, gen_loss = 0.35871566981077196, disc_loss = 0.1906898904591799
Trained batch 140 in epoch 1, gen_loss = 0.35973375507280336, disc_loss = 0.19028604469189409
Trained batch 141 in epoch 1, gen_loss = 0.359771105605112, disc_loss = 0.19099233031902516
Trained batch 142 in epoch 1, gen_loss = 0.35987329524713796, disc_loss = 0.19098948968665583
Trained batch 143 in epoch 1, gen_loss = 0.3596672827584876, disc_loss = 0.19013113792364797
Trained batch 144 in epoch 1, gen_loss = 0.359818252201738, disc_loss = 0.1897936939679343
Trained batch 145 in epoch 1, gen_loss = 0.35982975731157274, disc_loss = 0.18936940502018146
Trained batch 146 in epoch 1, gen_loss = 0.3598694821604255, disc_loss = 0.18877118760022987
Trained batch 147 in epoch 1, gen_loss = 0.36015807817111145, disc_loss = 0.1882895470370312
Trained batch 148 in epoch 1, gen_loss = 0.359979809730645, disc_loss = 0.1881125714854906
Trained batch 149 in epoch 1, gen_loss = 0.36060610274473825, disc_loss = 0.1886820945640405
Trained batch 150 in epoch 1, gen_loss = 0.36017577794213956, disc_loss = 0.18904795754232154
Trained batch 151 in epoch 1, gen_loss = 0.360686045140028, disc_loss = 0.18864753994306452
Trained batch 152 in epoch 1, gen_loss = 0.3608155869970135, disc_loss = 0.19014547419509079
Trained batch 153 in epoch 1, gen_loss = 0.36126365812567923, disc_loss = 0.19107135699747443
Trained batch 154 in epoch 1, gen_loss = 0.36097138427918957, disc_loss = 0.19119128253190748
Trained batch 155 in epoch 1, gen_loss = 0.3607725182022804, disc_loss = 0.19135011059160417
Trained batch 156 in epoch 1, gen_loss = 0.360901272220976, disc_loss = 0.1913935716269882
Trained batch 157 in epoch 1, gen_loss = 0.36073051355307617, disc_loss = 0.19118827821899065
Trained batch 158 in epoch 1, gen_loss = 0.360746793402066, disc_loss = 0.19128576216270338
Trained batch 159 in epoch 1, gen_loss = 0.360684903524816, disc_loss = 0.19147045533172785
Trained batch 160 in epoch 1, gen_loss = 0.3605179660808966, disc_loss = 0.1916043979133138
Trained batch 161 in epoch 1, gen_loss = 0.36044063575473834, disc_loss = 0.1917239266137282
Trained batch 162 in epoch 1, gen_loss = 0.3606782391027439, disc_loss = 0.1920120472465556
Trained batch 163 in epoch 1, gen_loss = 0.3609933178962731, disc_loss = 0.19164728732189026
Trained batch 164 in epoch 1, gen_loss = 0.3615783098972205, disc_loss = 0.191156978950356
Trained batch 165 in epoch 1, gen_loss = 0.3616136799016631, disc_loss = 0.19109152984547328
Trained batch 166 in epoch 1, gen_loss = 0.36154076760400555, disc_loss = 0.19179051677266995
Trained batch 167 in epoch 1, gen_loss = 0.36162691687544185, disc_loss = 0.19141844615695022
Trained batch 168 in epoch 1, gen_loss = 0.361809983937698, disc_loss = 0.1912427265086823
Trained batch 169 in epoch 1, gen_loss = 0.36165351990391226, disc_loss = 0.1911738254568156
Trained batch 170 in epoch 1, gen_loss = 0.36159147627172417, disc_loss = 0.19143858334125832
Trained batch 171 in epoch 1, gen_loss = 0.3618055327340614, disc_loss = 0.19152933930934862
Trained batch 172 in epoch 1, gen_loss = 0.3616556497667566, disc_loss = 0.19138724300902704
Trained batch 173 in epoch 1, gen_loss = 0.36168485331809386, disc_loss = 0.19123226695362178
Trained batch 174 in epoch 1, gen_loss = 0.3624007662705013, disc_loss = 0.19124183016163962
Trained batch 175 in epoch 1, gen_loss = 0.3621144685894251, disc_loss = 0.19112160945819182
Trained batch 176 in epoch 1, gen_loss = 0.3623230265358747, disc_loss = 0.19198037784988597
Trained batch 177 in epoch 1, gen_loss = 0.36249217558442876, disc_loss = 0.1921151621957843
Trained batch 178 in epoch 1, gen_loss = 0.3622028817677631, disc_loss = 0.19176972961292588
Trained batch 179 in epoch 1, gen_loss = 0.36228622843821845, disc_loss = 0.19161983182032902
Trained batch 180 in epoch 1, gen_loss = 0.3622684193908839, disc_loss = 0.19154606537265673
Trained batch 181 in epoch 1, gen_loss = 0.36234559462620664, disc_loss = 0.1914320442375246
Trained batch 182 in epoch 1, gen_loss = 0.3621077338854472, disc_loss = 0.1913455618860943
Trained batch 183 in epoch 1, gen_loss = 0.36202643827899644, disc_loss = 0.19090174608256505
Trained batch 184 in epoch 1, gen_loss = 0.36215495886029425, disc_loss = 0.1909060818118018
Trained batch 185 in epoch 1, gen_loss = 0.3621498847840935, disc_loss = 0.19055992973748073
Trained batch 186 in epoch 1, gen_loss = 0.36206554665284996, disc_loss = 0.19020570049630128
Trained batch 187 in epoch 1, gen_loss = 0.3621441314512111, disc_loss = 0.1900931773509117
Trained batch 188 in epoch 1, gen_loss = 0.36228549212375016, disc_loss = 0.1900827976919356
Trained batch 189 in epoch 1, gen_loss = 0.3623083660477086, disc_loss = 0.19074588394478748
Trained batch 190 in epoch 1, gen_loss = 0.36234784516364493, disc_loss = 0.19078742685430336
Trained batch 191 in epoch 1, gen_loss = 0.36234205309301615, disc_loss = 0.19072713772766292
Trained batch 192 in epoch 1, gen_loss = 0.3625479970571291, disc_loss = 0.1909070596330524
Trained batch 193 in epoch 1, gen_loss = 0.36258086147382085, disc_loss = 0.19060759169539226
Trained batch 194 in epoch 1, gen_loss = 0.36270591097000315, disc_loss = 0.19051109239076958
Trained batch 195 in epoch 1, gen_loss = 0.3627181886410227, disc_loss = 0.19043156116896745
Trained batch 196 in epoch 1, gen_loss = 0.3623980928193494, disc_loss = 0.1907817551175955
Trained batch 197 in epoch 1, gen_loss = 0.36249597566296354, disc_loss = 0.19104745675518056
Trained batch 198 in epoch 1, gen_loss = 0.3621364941249541, disc_loss = 0.19076376928755986
Trained batch 199 in epoch 1, gen_loss = 0.3621070685982704, disc_loss = 0.1908598679304123
Trained batch 200 in epoch 1, gen_loss = 0.36198695115189056, disc_loss = 0.19056314318927367
Trained batch 201 in epoch 1, gen_loss = 0.3621964107940693, disc_loss = 0.1899274875880173
Trained batch 202 in epoch 1, gen_loss = 0.36247088873914896, disc_loss = 0.1898314620877428
Trained batch 203 in epoch 1, gen_loss = 0.36233950976063223, disc_loss = 0.18984909441468178
Trained batch 204 in epoch 1, gen_loss = 0.36249117502352085, disc_loss = 0.18981592391685742
Trained batch 205 in epoch 1, gen_loss = 0.3625045718209257, disc_loss = 0.18948048857736935
Trained batch 206 in epoch 1, gen_loss = 0.3623813328823606, disc_loss = 0.18958529828179285
Trained batch 207 in epoch 1, gen_loss = 0.3621684324282866, disc_loss = 0.1893658891427689
Trained batch 208 in epoch 1, gen_loss = 0.36221597069188166, disc_loss = 0.18907256508201503
Trained batch 209 in epoch 1, gen_loss = 0.362101236695335, disc_loss = 0.18896206927796205
Trained batch 210 in epoch 1, gen_loss = 0.36231217254394604, disc_loss = 0.1887646041174918
Trained batch 211 in epoch 1, gen_loss = 0.36172956607814105, disc_loss = 0.18954219885240747
Trained batch 212 in epoch 1, gen_loss = 0.3617512369659585, disc_loss = 0.1895029995887772
Trained batch 213 in epoch 1, gen_loss = 0.36157949143481033, disc_loss = 0.18941589519729682
Trained batch 214 in epoch 1, gen_loss = 0.3615189643793328, disc_loss = 0.1893424313948598
Trained batch 215 in epoch 1, gen_loss = 0.3614092812769943, disc_loss = 0.18909160266802819
Trained batch 216 in epoch 1, gen_loss = 0.36166071136426264, disc_loss = 0.18927902846773098
Trained batch 217 in epoch 1, gen_loss = 0.36188835725871793, disc_loss = 0.18937254175885554
Trained batch 218 in epoch 1, gen_loss = 0.3618649501506596, disc_loss = 0.18942458953147065
Trained batch 219 in epoch 1, gen_loss = 0.36195447187532076, disc_loss = 0.18922618483616546
Trained batch 220 in epoch 1, gen_loss = 0.36214147393520063, disc_loss = 0.18919684624982097
Trained batch 221 in epoch 1, gen_loss = 0.3619808457993172, disc_loss = 0.18894705329056796
Trained batch 222 in epoch 1, gen_loss = 0.361898118872279, disc_loss = 0.18917712200048792
Trained batch 223 in epoch 1, gen_loss = 0.36186766531318426, disc_loss = 0.18940231601508067
Trained batch 224 in epoch 1, gen_loss = 0.361686436202791, disc_loss = 0.18948862471514277
Trained batch 225 in epoch 1, gen_loss = 0.3617934893190333, disc_loss = 0.19002618263187135
Trained batch 226 in epoch 1, gen_loss = 0.3624901606122828, disc_loss = 0.1897862708351948
Trained batch 227 in epoch 1, gen_loss = 0.3624574404798056, disc_loss = 0.19028859021828362
Trained batch 228 in epoch 1, gen_loss = 0.3622759717260386, disc_loss = 0.19015227796664405
Trained batch 229 in epoch 1, gen_loss = 0.362433381313863, disc_loss = 0.1903569108604089
Trained batch 230 in epoch 1, gen_loss = 0.3623633843995792, disc_loss = 0.19007386607460644
Trained batch 231 in epoch 1, gen_loss = 0.3623295105222998, disc_loss = 0.18982055755974403
Trained batch 232 in epoch 1, gen_loss = 0.36203252386637513, disc_loss = 0.18980360611505775
Trained batch 233 in epoch 1, gen_loss = 0.36174254272228634, disc_loss = 0.1895700043433497
Trained batch 234 in epoch 1, gen_loss = 0.36164639224397377, disc_loss = 0.18925401297338465
Trained batch 235 in epoch 1, gen_loss = 0.3621236195756217, disc_loss = 0.18888107467821594
Trained batch 236 in epoch 1, gen_loss = 0.3621168273662213, disc_loss = 0.1883285842710155
Trained batch 237 in epoch 1, gen_loss = 0.36211490393185813, disc_loss = 0.1878054373498474
Trained batch 238 in epoch 1, gen_loss = 0.36174804919933173, disc_loss = 0.18746377981295145
Trained batch 239 in epoch 1, gen_loss = 0.3619987736145655, disc_loss = 0.1872457297363629
Trained batch 240 in epoch 1, gen_loss = 0.3618393499574226, disc_loss = 0.1874629875405448
Trained batch 241 in epoch 1, gen_loss = 0.36157548784717053, disc_loss = 0.18778823554700563
Trained batch 242 in epoch 1, gen_loss = 0.361453464369715, disc_loss = 0.1877284938385212
Trained batch 243 in epoch 1, gen_loss = 0.36161542598341334, disc_loss = 0.18802807582389625
Trained batch 244 in epoch 1, gen_loss = 0.361324635695438, disc_loss = 0.18836268410086632
Trained batch 245 in epoch 1, gen_loss = 0.361281645976431, disc_loss = 0.18844112697837315
Trained batch 246 in epoch 1, gen_loss = 0.36151337249558946, disc_loss = 0.18842069097315733
Trained batch 247 in epoch 1, gen_loss = 0.36120324906322265, disc_loss = 0.1884034748129066
Trained batch 248 in epoch 1, gen_loss = 0.36127545651661824, disc_loss = 0.1881793556532946
Trained batch 249 in epoch 1, gen_loss = 0.3612948062419891, disc_loss = 0.18782170225679876
Trained batch 250 in epoch 1, gen_loss = 0.3613852374107239, disc_loss = 0.18751832223924034
Trained batch 251 in epoch 1, gen_loss = 0.36143129011468283, disc_loss = 0.1870758096938805
Trained batch 252 in epoch 1, gen_loss = 0.36148553438808606, disc_loss = 0.1872225359465058
Trained batch 253 in epoch 1, gen_loss = 0.3615488926256735, disc_loss = 0.1881366564972898
Trained batch 254 in epoch 1, gen_loss = 0.361935390327491, disc_loss = 0.18792183859383357
Trained batch 255 in epoch 1, gen_loss = 0.36218206910416484, disc_loss = 0.18763774719263893
Trained batch 256 in epoch 1, gen_loss = 0.3618769501897611, disc_loss = 0.1877972962994288
Trained batch 257 in epoch 1, gen_loss = 0.36206247813479847, disc_loss = 0.1876796258599028
Trained batch 258 in epoch 1, gen_loss = 0.3618212305440866, disc_loss = 0.1874827840239615
Trained batch 259 in epoch 1, gen_loss = 0.36197021924532374, disc_loss = 0.18735999526599278
Trained batch 260 in epoch 1, gen_loss = 0.36215795570863163, disc_loss = 0.18759707922394248
Trained batch 261 in epoch 1, gen_loss = 0.3621494472026825, disc_loss = 0.18796666289274475
Trained batch 262 in epoch 1, gen_loss = 0.3620513489491133, disc_loss = 0.1879766486415165
Trained batch 263 in epoch 1, gen_loss = 0.3618272003350836, disc_loss = 0.18792318607765165
Trained batch 264 in epoch 1, gen_loss = 0.3621780317909313, disc_loss = 0.18760273092479077
Trained batch 265 in epoch 1, gen_loss = 0.36223524708048743, disc_loss = 0.1875917057373694
Trained batch 266 in epoch 1, gen_loss = 0.36199794547834646, disc_loss = 0.18765767037254594
Trained batch 267 in epoch 1, gen_loss = 0.3619121640031017, disc_loss = 0.1873613433189579
Trained batch 268 in epoch 1, gen_loss = 0.36175304529392144, disc_loss = 0.1874492659915557
Trained batch 269 in epoch 1, gen_loss = 0.3615543991327286, disc_loss = 0.18747459044335066
Trained batch 270 in epoch 1, gen_loss = 0.36171058612116147, disc_loss = 0.18721075544333107
Trained batch 271 in epoch 1, gen_loss = 0.3617170976803583, disc_loss = 0.1869342888787608
Trained batch 272 in epoch 1, gen_loss = 0.3619185380446605, disc_loss = 0.1865038252384453
Trained batch 273 in epoch 1, gen_loss = 0.3619041425468278, disc_loss = 0.18619318612354951
Trained batch 274 in epoch 1, gen_loss = 0.36188205112110483, disc_loss = 0.18592484919862315
Trained batch 275 in epoch 1, gen_loss = 0.36176207823597867, disc_loss = 0.18562205817442443
Trained batch 276 in epoch 1, gen_loss = 0.3617037339976548, disc_loss = 0.18543308834790753
Trained batch 277 in epoch 1, gen_loss = 0.3616059142694199, disc_loss = 0.18528077200644735
Trained batch 278 in epoch 1, gen_loss = 0.3616309857069378, disc_loss = 0.18504507857037703
Trained batch 279 in epoch 1, gen_loss = 0.36187592915126254, disc_loss = 0.18509835825700846
Trained batch 280 in epoch 1, gen_loss = 0.3617868316343246, disc_loss = 0.1856403831405784
Trained batch 281 in epoch 1, gen_loss = 0.36218250960322984, disc_loss = 0.18549594559198154
Trained batch 282 in epoch 1, gen_loss = 0.3622792768604764, disc_loss = 0.18528075772913521
Trained batch 283 in epoch 1, gen_loss = 0.36227402731146613, disc_loss = 0.18527659824983755
Trained batch 284 in epoch 1, gen_loss = 0.362272625534158, disc_loss = 0.1850979730094734
Trained batch 285 in epoch 1, gen_loss = 0.3621143723701264, disc_loss = 0.18488585369309762
Trained batch 286 in epoch 1, gen_loss = 0.36212513567263244, disc_loss = 0.1845074499915078
Trained batch 287 in epoch 1, gen_loss = 0.36236232405321467, disc_loss = 0.18401188766842502
Trained batch 288 in epoch 1, gen_loss = 0.36243628053104177, disc_loss = 0.1835013901795483
Trained batch 289 in epoch 1, gen_loss = 0.3625997393295683, disc_loss = 0.1829740261594797
Trained batch 290 in epoch 1, gen_loss = 0.36257740773286196, disc_loss = 0.18270420980770974
Trained batch 291 in epoch 1, gen_loss = 0.36294370910076246, disc_loss = 0.18315946886137333
Trained batch 292 in epoch 1, gen_loss = 0.3626707282692906, disc_loss = 0.1831120189927747
Trained batch 293 in epoch 1, gen_loss = 0.36270203375491966, disc_loss = 0.18292727208613943
Trained batch 294 in epoch 1, gen_loss = 0.3626276852720875, disc_loss = 0.1836018620279886
Trained batch 295 in epoch 1, gen_loss = 0.3624308882532893, disc_loss = 0.1838328018155251
Trained batch 296 in epoch 1, gen_loss = 0.36243663331876297, disc_loss = 0.18371168018541353
Trained batch 297 in epoch 1, gen_loss = 0.3624811922543801, disc_loss = 0.1837626023955593
Trained batch 298 in epoch 1, gen_loss = 0.36267671906031096, disc_loss = 0.1836144566710378
Trained batch 299 in epoch 1, gen_loss = 0.3628274233142535, disc_loss = 0.1836704629038771
Trained batch 300 in epoch 1, gen_loss = 0.36296733005894377, disc_loss = 0.1834129252381301
Trained batch 301 in epoch 1, gen_loss = 0.36305383528699936, disc_loss = 0.18326286580536935
Trained batch 302 in epoch 1, gen_loss = 0.36300954743973884, disc_loss = 0.18313364732531037
Trained batch 303 in epoch 1, gen_loss = 0.36317416143260506, disc_loss = 0.18306361152300318
Trained batch 304 in epoch 1, gen_loss = 0.3632339843961059, disc_loss = 0.1828275306669415
Trained batch 305 in epoch 1, gen_loss = 0.36318796152382893, disc_loss = 0.18269089262421226
Trained batch 306 in epoch 1, gen_loss = 0.3630936341875928, disc_loss = 0.1824885874331386
Trained batch 307 in epoch 1, gen_loss = 0.3630482059988109, disc_loss = 0.18271957131030112
Trained batch 308 in epoch 1, gen_loss = 0.3629092075485242, disc_loss = 0.1824387967658853
Trained batch 309 in epoch 1, gen_loss = 0.36290573670018106, disc_loss = 0.18219253371559804
Trained batch 310 in epoch 1, gen_loss = 0.3630326316479318, disc_loss = 0.18191215916988934
Trained batch 311 in epoch 1, gen_loss = 0.3628980876543583, disc_loss = 0.18167238681314465
Trained batch 312 in epoch 1, gen_loss = 0.36285982050073035, disc_loss = 0.18143815531755408
Trained batch 313 in epoch 1, gen_loss = 0.3627266796531191, disc_loss = 0.18114927070583128
Trained batch 314 in epoch 1, gen_loss = 0.3628452659599365, disc_loss = 0.18098403273357286
Trained batch 315 in epoch 1, gen_loss = 0.3628572616961938, disc_loss = 0.18072074426550278
Trained batch 316 in epoch 1, gen_loss = 0.36277913050696675, disc_loss = 0.18040998102597633
Trained batch 317 in epoch 1, gen_loss = 0.36277164790615346, disc_loss = 0.18087920186888873
Trained batch 318 in epoch 1, gen_loss = 0.362723749446271, disc_loss = 0.18068418447453774
Trained batch 319 in epoch 1, gen_loss = 0.3627932034432888, disc_loss = 0.18040083650266753
Trained batch 320 in epoch 1, gen_loss = 0.3630115120581749, disc_loss = 0.18033794184850754
Trained batch 321 in epoch 1, gen_loss = 0.36329796345707793, disc_loss = 0.18065908897135938
Trained batch 322 in epoch 1, gen_loss = 0.3632600066647072, disc_loss = 0.1814112562121068
Trained batch 323 in epoch 1, gen_loss = 0.36330626748594236, disc_loss = 0.18163671531932957
Trained batch 324 in epoch 1, gen_loss = 0.3631656989684472, disc_loss = 0.1818374690069602
Trained batch 325 in epoch 1, gen_loss = 0.3631515545896226, disc_loss = 0.18183663198324435
Trained batch 326 in epoch 1, gen_loss = 0.3631850216731384, disc_loss = 0.18170044955082626
Trained batch 327 in epoch 1, gen_loss = 0.36302474177465205, disc_loss = 0.1814928211885073
Trained batch 328 in epoch 1, gen_loss = 0.36315762887972103, disc_loss = 0.18123649145649198
Trained batch 329 in epoch 1, gen_loss = 0.36308985316392145, disc_loss = 0.18128025494515895
Trained batch 330 in epoch 1, gen_loss = 0.36331987669100574, disc_loss = 0.18146241709499922
Trained batch 331 in epoch 1, gen_loss = 0.3632913353931473, disc_loss = 0.18139495587268148
Trained batch 332 in epoch 1, gen_loss = 0.3635184171500507, disc_loss = 0.18120429325882378
Trained batch 333 in epoch 1, gen_loss = 0.3635418757707059, disc_loss = 0.18096502753208854
Trained batch 334 in epoch 1, gen_loss = 0.3634708226616703, disc_loss = 0.1807101617886949
Trained batch 335 in epoch 1, gen_loss = 0.36369370704605464, disc_loss = 0.1804740386017199
Trained batch 336 in epoch 1, gen_loss = 0.36344844341631816, disc_loss = 0.18025372598530276
Trained batch 337 in epoch 1, gen_loss = 0.3633740707438373, disc_loss = 0.17997332908124966
Trained batch 338 in epoch 1, gen_loss = 0.36349580236944123, disc_loss = 0.17977465626544656
Trained batch 339 in epoch 1, gen_loss = 0.3634583252317765, disc_loss = 0.1797799619133858
Trained batch 340 in epoch 1, gen_loss = 0.36327067288485443, disc_loss = 0.1798473831124145
Trained batch 341 in epoch 1, gen_loss = 0.36331783121789407, disc_loss = 0.17987966671455324
Trained batch 342 in epoch 1, gen_loss = 0.3634038663987863, disc_loss = 0.179815897082709
Trained batch 343 in epoch 1, gen_loss = 0.3634964487580366, disc_loss = 0.17961532450389378
Trained batch 344 in epoch 1, gen_loss = 0.363485069119412, disc_loss = 0.17942096207668815
Trained batch 345 in epoch 1, gen_loss = 0.36380341132252203, disc_loss = 0.17947621562792732
Trained batch 346 in epoch 1, gen_loss = 0.363875384633067, disc_loss = 0.17909897315270276
Trained batch 347 in epoch 1, gen_loss = 0.36383828614977587, disc_loss = 0.17879549451386448
Trained batch 348 in epoch 1, gen_loss = 0.3637993907860152, disc_loss = 0.17861872114091684
Trained batch 349 in epoch 1, gen_loss = 0.3641213942425592, disc_loss = 0.17818141893616746
Trained batch 350 in epoch 1, gen_loss = 0.36435839890414834, disc_loss = 0.17776074776282677
Trained batch 351 in epoch 1, gen_loss = 0.3644981506195935, disc_loss = 0.17753767988390542
Trained batch 352 in epoch 1, gen_loss = 0.3644106109486761, disc_loss = 0.1773513582120874
Trained batch 353 in epoch 1, gen_loss = 0.36446823381771476, disc_loss = 0.1769478587738875
Trained batch 354 in epoch 1, gen_loss = 0.36446294725780753, disc_loss = 0.17677372872409686
Trained batch 355 in epoch 1, gen_loss = 0.3649550293771069, disc_loss = 0.1773302678353666
Trained batch 356 in epoch 1, gen_loss = 0.36486752135079115, disc_loss = 0.17769664503028748
Trained batch 357 in epoch 1, gen_loss = 0.3650800630699989, disc_loss = 0.17773879333997572
Trained batch 358 in epoch 1, gen_loss = 0.36514512227438284, disc_loss = 0.17752588015246856
Trained batch 359 in epoch 1, gen_loss = 0.3649361727966203, disc_loss = 0.17776629349423778
Trained batch 360 in epoch 1, gen_loss = 0.3651259843662505, disc_loss = 0.17766301903533144
Trained batch 361 in epoch 1, gen_loss = 0.36516338677366794, disc_loss = 0.1776790254188506
Trained batch 362 in epoch 1, gen_loss = 0.3649621714245189, disc_loss = 0.17760882479428589
Trained batch 363 in epoch 1, gen_loss = 0.3650103965467149, disc_loss = 0.1780220791697502
Trained batch 364 in epoch 1, gen_loss = 0.36507013750402895, disc_loss = 0.17791990621449197
Trained batch 365 in epoch 1, gen_loss = 0.3651923604838835, disc_loss = 0.17769217613290567
Trained batch 366 in epoch 1, gen_loss = 0.36506203523448766, disc_loss = 0.1775200784571814
Trained batch 367 in epoch 1, gen_loss = 0.36521179893094563, disc_loss = 0.1774145218381739
Trained batch 368 in epoch 1, gen_loss = 0.3654293480927382, disc_loss = 0.1772813540365961
Trained batch 369 in epoch 1, gen_loss = 0.3653950799961348, disc_loss = 0.17713451951339437
Trained batch 370 in epoch 1, gen_loss = 0.3654026162592227, disc_loss = 0.1770246557670462
Trained batch 371 in epoch 1, gen_loss = 0.36528796374156913, disc_loss = 0.17690198405856086
Trained batch 372 in epoch 1, gen_loss = 0.3653361391445906, disc_loss = 0.1767093856436957
Trained batch 373 in epoch 1, gen_loss = 0.36515480263985417, disc_loss = 0.17649854859088193
Trained batch 374 in epoch 1, gen_loss = 0.36506223432223, disc_loss = 0.17628613660732906
Trained batch 375 in epoch 1, gen_loss = 0.3651163493223647, disc_loss = 0.17604658443559992
Trained batch 376 in epoch 1, gen_loss = 0.36515995211879515, disc_loss = 0.17618574332495268
Trained batch 377 in epoch 1, gen_loss = 0.3652509635403043, disc_loss = 0.17592670366404548
Trained batch 378 in epoch 1, gen_loss = 0.3652157303840315, disc_loss = 0.17593021293743305
Trained batch 379 in epoch 1, gen_loss = 0.3655380478030757, disc_loss = 0.17647428042010257
Trained batch 380 in epoch 1, gen_loss = 0.36542903078509753, disc_loss = 0.17635772422229837
Trained batch 381 in epoch 1, gen_loss = 0.3653615521198792, disc_loss = 0.17628882821473776
Trained batch 382 in epoch 1, gen_loss = 0.36530278455806464, disc_loss = 0.17604059432256317
Trained batch 383 in epoch 1, gen_loss = 0.3655096684427311, disc_loss = 0.1758337645054174
Trained batch 384 in epoch 1, gen_loss = 0.3653705698329133, disc_loss = 0.175644372442326
Trained batch 385 in epoch 1, gen_loss = 0.36522317836012863, disc_loss = 0.1755131301059933
Trained batch 386 in epoch 1, gen_loss = 0.3653318852725263, disc_loss = 0.17536339962744282
Trained batch 387 in epoch 1, gen_loss = 0.36541738107646865, disc_loss = 0.17534782985206118
Trained batch 388 in epoch 1, gen_loss = 0.36521202954044685, disc_loss = 0.17541833855882097
Trained batch 389 in epoch 1, gen_loss = 0.3654231484883871, disc_loss = 0.17526700403063725
Trained batch 390 in epoch 1, gen_loss = 0.3651953850255903, disc_loss = 0.17548184525555052
Trained batch 391 in epoch 1, gen_loss = 0.3651636072567531, disc_loss = 0.17530135833183114
Trained batch 392 in epoch 1, gen_loss = 0.36515623664734626, disc_loss = 0.1750622257855709
Trained batch 393 in epoch 1, gen_loss = 0.36510438067356343, disc_loss = 0.17493167814567004
Trained batch 394 in epoch 1, gen_loss = 0.3650172500670711, disc_loss = 0.17488405847851235
Trained batch 395 in epoch 1, gen_loss = 0.3650965754582424, disc_loss = 0.17485042119568045
Trained batch 396 in epoch 1, gen_loss = 0.3651543548635632, disc_loss = 0.17482317777664896
Trained batch 397 in epoch 1, gen_loss = 0.36549344456675065, disc_loss = 0.17471352275741758
Trained batch 398 in epoch 1, gen_loss = 0.3656905900714989, disc_loss = 0.17453705961991073
Trained batch 399 in epoch 1, gen_loss = 0.3656022285670042, disc_loss = 0.17439815770834685
Trained batch 400 in epoch 1, gen_loss = 0.3656320533996211, disc_loss = 0.17417436992364035
Trained batch 401 in epoch 1, gen_loss = 0.36578445840830826, disc_loss = 0.17404700808264129
Trained batch 402 in epoch 1, gen_loss = 0.3657559850079842, disc_loss = 0.17383011007131477
Trained batch 403 in epoch 1, gen_loss = 0.3657576534712669, disc_loss = 0.17353392207976615
Trained batch 404 in epoch 1, gen_loss = 0.3657745214156163, disc_loss = 0.17328964985079234
Trained batch 405 in epoch 1, gen_loss = 0.3658511786918922, disc_loss = 0.17307149037131536
Trained batch 406 in epoch 1, gen_loss = 0.3658998528774599, disc_loss = 0.1727923638294897
Trained batch 407 in epoch 1, gen_loss = 0.3660201489487115, disc_loss = 0.17248156794584266
Trained batch 408 in epoch 1, gen_loss = 0.36596870903280954, disc_loss = 0.17222769569359664
Trained batch 409 in epoch 1, gen_loss = 0.3659507337139874, disc_loss = 0.17190546913117896
Trained batch 410 in epoch 1, gen_loss = 0.36597047111703823, disc_loss = 0.17152607728276228
Trained batch 411 in epoch 1, gen_loss = 0.3660028318612321, disc_loss = 0.171196190992967
Trained batch 412 in epoch 1, gen_loss = 0.3661122092611853, disc_loss = 0.17083768909188218
Trained batch 413 in epoch 1, gen_loss = 0.36629081369886074, disc_loss = 0.17045296264299448
Trained batch 414 in epoch 1, gen_loss = 0.3661807605301041, disc_loss = 0.1702169177761997
Trained batch 415 in epoch 1, gen_loss = 0.3663900991042073, disc_loss = 0.170185724631525
Trained batch 416 in epoch 1, gen_loss = 0.3665929132942959, disc_loss = 0.16984399586773033
Trained batch 417 in epoch 1, gen_loss = 0.36668965384435426, disc_loss = 0.1695253390408874
Trained batch 418 in epoch 1, gen_loss = 0.3664990708338617, disc_loss = 0.1693270464821192
Trained batch 419 in epoch 1, gen_loss = 0.36668538600206374, disc_loss = 0.1690604154464035
Trained batch 420 in epoch 1, gen_loss = 0.3667925364755961, disc_loss = 0.16880356279730513
Trained batch 421 in epoch 1, gen_loss = 0.3670979048968491, disc_loss = 0.16843531129140213
Trained batch 422 in epoch 1, gen_loss = 0.3670997415310384, disc_loss = 0.1683285745415599
Trained batch 423 in epoch 1, gen_loss = 0.3670807939093068, disc_loss = 0.16848571774470708
Trained batch 424 in epoch 1, gen_loss = 0.36689352968159844, disc_loss = 0.16884737821405424
Trained batch 425 in epoch 1, gen_loss = 0.3668334661095355, disc_loss = 0.16869669194451312
Trained batch 426 in epoch 1, gen_loss = 0.3671364955237654, disc_loss = 0.168920285530842
Trained batch 427 in epoch 1, gen_loss = 0.36711756084288394, disc_loss = 0.16882608869443777
Trained batch 428 in epoch 1, gen_loss = 0.3671767032229817, disc_loss = 0.1687238042574975
Trained batch 429 in epoch 1, gen_loss = 0.36737098063147344, disc_loss = 0.16859296460007858
Trained batch 430 in epoch 1, gen_loss = 0.36727889003167297, disc_loss = 0.16846372709412932
Trained batch 431 in epoch 1, gen_loss = 0.3671507378005319, disc_loss = 0.16841392509027006
Trained batch 432 in epoch 1, gen_loss = 0.36712938099755427, disc_loss = 0.1683893921283906
Trained batch 433 in epoch 1, gen_loss = 0.3672449473411806, disc_loss = 0.16823835621377634
Trained batch 434 in epoch 1, gen_loss = 0.3672426051106946, disc_loss = 0.16792808445919863
Trained batch 435 in epoch 1, gen_loss = 0.36723040187851, disc_loss = 0.16781883921106816
Trained batch 436 in epoch 1, gen_loss = 0.3674620321058845, disc_loss = 0.16759149079132202
Trained batch 437 in epoch 1, gen_loss = 0.36779399991851963, disc_loss = 0.16734059777782728
Trained batch 438 in epoch 1, gen_loss = 0.3677985742179028, disc_loss = 0.16731032077647356
Trained batch 439 in epoch 1, gen_loss = 0.36790026866576886, disc_loss = 0.1671047351767563
Trained batch 440 in epoch 1, gen_loss = 0.36786323954729266, disc_loss = 0.1669248882660013
Trained batch 441 in epoch 1, gen_loss = 0.36785239999380587, disc_loss = 0.16722881694733086
Trained batch 442 in epoch 1, gen_loss = 0.3681915030387939, disc_loss = 0.16704082933231415
Trained batch 443 in epoch 1, gen_loss = 0.36837576349844803, disc_loss = 0.1668310247818931
Trained batch 444 in epoch 1, gen_loss = 0.3684642876132151, disc_loss = 0.1665897827825687
Trained batch 445 in epoch 1, gen_loss = 0.36854419506451475, disc_loss = 0.16650747197300128
Trained batch 446 in epoch 1, gen_loss = 0.3684962352516934, disc_loss = 0.16621226467550534
Trained batch 447 in epoch 1, gen_loss = 0.3683060208734657, disc_loss = 0.1664210099115735
Trained batch 448 in epoch 1, gen_loss = 0.36852112930176784, disc_loss = 0.16640340082372285
Trained batch 449 in epoch 1, gen_loss = 0.3685191150506337, disc_loss = 0.16638377535881269
Trained batch 450 in epoch 1, gen_loss = 0.36856605426435196, disc_loss = 0.16626529068688134
Trained batch 451 in epoch 1, gen_loss = 0.3684988133938967, disc_loss = 0.16657138266600668
Trained batch 452 in epoch 1, gen_loss = 0.36844773541223136, disc_loss = 0.16691087512196623
Trained batch 453 in epoch 1, gen_loss = 0.3683922307869411, disc_loss = 0.16689354818240465
Trained batch 454 in epoch 1, gen_loss = 0.3682348071873843, disc_loss = 0.1671297823355257
Trained batch 455 in epoch 1, gen_loss = 0.36828538919227166, disc_loss = 0.16716318630017013
Trained batch 456 in epoch 1, gen_loss = 0.36821323900567104, disc_loss = 0.16715926871200945
Trained batch 457 in epoch 1, gen_loss = 0.36822513233886534, disc_loss = 0.16714001199897524
Trained batch 458 in epoch 1, gen_loss = 0.3681463124575438, disc_loss = 0.1670687411950337
Trained batch 459 in epoch 1, gen_loss = 0.36813128344390705, disc_loss = 0.1669082708677034
Trained batch 460 in epoch 1, gen_loss = 0.36815671477297124, disc_loss = 0.16679124674939605
Trained batch 461 in epoch 1, gen_loss = 0.36812392715767867, disc_loss = 0.1666205978903968
Trained batch 462 in epoch 1, gen_loss = 0.3680347945082522, disc_loss = 0.16794538440194873
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.31689736247062683, disc_loss = 0.1405649036169052
Trained batch 1 in epoch 2, gen_loss = 0.3293032646179199, disc_loss = 0.16177939623594284
Trained batch 2 in epoch 2, gen_loss = 0.3496154546737671, disc_loss = 0.14206746965646744
Trained batch 3 in epoch 2, gen_loss = 0.3590718135237694, disc_loss = 0.12671218812465668
Trained batch 4 in epoch 2, gen_loss = 0.368145489692688, disc_loss = 0.12053261697292328
Trained batch 5 in epoch 2, gen_loss = 0.3624464174111684, disc_loss = 0.10992760583758354
Trained batch 6 in epoch 2, gen_loss = 0.3565192903791155, disc_loss = 0.10639234845127378
Trained batch 7 in epoch 2, gen_loss = 0.354351282119751, disc_loss = 0.10354667156934738
Trained batch 8 in epoch 2, gen_loss = 0.36453932854864335, disc_loss = 0.10070546219746272
Trained batch 9 in epoch 2, gen_loss = 0.3611943513154984, disc_loss = 0.09392312467098236
Trained batch 10 in epoch 2, gen_loss = 0.35841527581214905, disc_loss = 0.09206603535196999
Trained batch 11 in epoch 2, gen_loss = 0.3588329677780469, disc_loss = 0.08771151925126712
Trained batch 12 in epoch 2, gen_loss = 0.3649108043083778, disc_loss = 0.08818449309239021
Trained batch 13 in epoch 2, gen_loss = 0.3690095969608852, disc_loss = 0.08676616528204509
Trained batch 14 in epoch 2, gen_loss = 0.37269626259803773, disc_loss = 0.08693666060765584
Trained batch 15 in epoch 2, gen_loss = 0.37420543655753136, disc_loss = 0.08645676681771874
Trained batch 16 in epoch 2, gen_loss = 0.37286362227271586, disc_loss = 0.08523490236086004
Trained batch 17 in epoch 2, gen_loss = 0.3674099991718928, disc_loss = 0.09583062016301686
Trained batch 18 in epoch 2, gen_loss = 0.37187971253144114, disc_loss = 0.09682166968521319
Trained batch 19 in epoch 2, gen_loss = 0.3728342428803444, disc_loss = 0.09420771636068821
Trained batch 20 in epoch 2, gen_loss = 0.3707061821506137, disc_loss = 0.09364087631305058
Trained batch 21 in epoch 2, gen_loss = 0.3662940033457496, disc_loss = 0.09592244875701991
Trained batch 22 in epoch 2, gen_loss = 0.3703636954660001, disc_loss = 0.09711534335561421
Trained batch 23 in epoch 2, gen_loss = 0.37056051070491475, disc_loss = 0.09655819926410913
Trained batch 24 in epoch 2, gen_loss = 0.36995180606842043, disc_loss = 0.09953807443380355
Trained batch 25 in epoch 2, gen_loss = 0.3691225762550647, disc_loss = 0.09956012924130146
Trained batch 26 in epoch 2, gen_loss = 0.3701541070584898, disc_loss = 0.09861977012069137
Trained batch 27 in epoch 2, gen_loss = 0.3724754218544279, disc_loss = 0.09945285027580601
Trained batch 28 in epoch 2, gen_loss = 0.3731039361707095, disc_loss = 0.09801763874189608
Trained batch 29 in epoch 2, gen_loss = 0.3734320431947708, disc_loss = 0.09891452230513095
Trained batch 30 in epoch 2, gen_loss = 0.3759722978838028, disc_loss = 0.0970416137528035
Trained batch 31 in epoch 2, gen_loss = 0.37743344716727734, disc_loss = 0.09539517865050584
Trained batch 32 in epoch 2, gen_loss = 0.3758341877749472, disc_loss = 0.09440363751667918
Trained batch 33 in epoch 2, gen_loss = 0.3736022272530724, disc_loss = 0.09396621924551095
Trained batch 34 in epoch 2, gen_loss = 0.3774955119405474, disc_loss = 0.09213744652058398
Trained batch 35 in epoch 2, gen_loss = 0.37727003296216327, disc_loss = 0.09112308769383365
Trained batch 36 in epoch 2, gen_loss = 0.37899483619509516, disc_loss = 0.09230471155732065
Trained batch 37 in epoch 2, gen_loss = 0.3796603452218206, disc_loss = 0.09138543114654328
Trained batch 38 in epoch 2, gen_loss = 0.38027068743338954, disc_loss = 0.09264340915550025
Trained batch 39 in epoch 2, gen_loss = 0.37749287858605385, disc_loss = 0.09391038375906646
Trained batch 40 in epoch 2, gen_loss = 0.37739360913997744, disc_loss = 0.094431770602014
Trained batch 41 in epoch 2, gen_loss = 0.3773367525566192, disc_loss = 0.09514290976914622
Trained batch 42 in epoch 2, gen_loss = 0.37634067687877387, disc_loss = 0.0947390141095533
Trained batch 43 in epoch 2, gen_loss = 0.3760024214332754, disc_loss = 0.09459004496139559
Trained batch 44 in epoch 2, gen_loss = 0.37562510437435576, disc_loss = 0.09426107352806462
Trained batch 45 in epoch 2, gen_loss = 0.3759093660375346, disc_loss = 0.09397933530904677
Trained batch 46 in epoch 2, gen_loss = 0.37769073882001514, disc_loss = 0.09307297806632012
Trained batch 47 in epoch 2, gen_loss = 0.37772655424972373, disc_loss = 0.09195656457450241
Trained batch 48 in epoch 2, gen_loss = 0.37658990341789866, disc_loss = 0.09302197704661866
Trained batch 49 in epoch 2, gen_loss = 0.3751677614450455, disc_loss = 0.09987675819545984
Trained batch 50 in epoch 2, gen_loss = 0.3761264506508322, disc_loss = 0.09955385491690215
Trained batch 51 in epoch 2, gen_loss = 0.3751794793284856, disc_loss = 0.098864768882497
Trained batch 52 in epoch 2, gen_loss = 0.37573936862765617, disc_loss = 0.09895047591120568
Trained batch 53 in epoch 2, gen_loss = 0.37464522377208426, disc_loss = 0.09853676116714875
Trained batch 54 in epoch 2, gen_loss = 0.37623742114413866, disc_loss = 0.0974606698548252
Trained batch 55 in epoch 2, gen_loss = 0.3765854478946754, disc_loss = 0.09735916677995451
Trained batch 56 in epoch 2, gen_loss = 0.37720310322025363, disc_loss = 0.09856027276500275
Trained batch 57 in epoch 2, gen_loss = 0.3769984923560044, disc_loss = 0.09878166755340223
Trained batch 58 in epoch 2, gen_loss = 0.3783502093816208, disc_loss = 0.09793826157890134
Trained batch 59 in epoch 2, gen_loss = 0.3783574427167575, disc_loss = 0.10129652696972093
Trained batch 60 in epoch 2, gen_loss = 0.3791756874225179, disc_loss = 0.10264738444544252
Trained batch 61 in epoch 2, gen_loss = 0.3791474320234791, disc_loss = 0.10159725110016522
Trained batch 62 in epoch 2, gen_loss = 0.3785742095538548, disc_loss = 0.10402610912800782
Trained batch 63 in epoch 2, gen_loss = 0.37875027069821954, disc_loss = 0.10412641338189133
Trained batch 64 in epoch 2, gen_loss = 0.37863742938408484, disc_loss = 0.10379620334849908
Trained batch 65 in epoch 2, gen_loss = 0.3791728195818988, disc_loss = 0.10347935289257404
Trained batch 66 in epoch 2, gen_loss = 0.3794578594058307, disc_loss = 0.10293197901502474
Trained batch 67 in epoch 2, gen_loss = 0.38037191769656015, disc_loss = 0.10216792713960304
Trained batch 68 in epoch 2, gen_loss = 0.38010303740916046, disc_loss = 0.10128902867976305
Trained batch 69 in epoch 2, gen_loss = 0.38056846261024474, disc_loss = 0.10079261402466468
Trained batch 70 in epoch 2, gen_loss = 0.3816838272860352, disc_loss = 0.1000289049419299
Trained batch 71 in epoch 2, gen_loss = 0.38076255429122186, disc_loss = 0.10122876523786949
Trained batch 72 in epoch 2, gen_loss = 0.38237754735228136, disc_loss = 0.10489532956215616
Trained batch 73 in epoch 2, gen_loss = 0.3819810119835106, disc_loss = 0.10498827758773759
Trained batch 74 in epoch 2, gen_loss = 0.3824657924969991, disc_loss = 0.10610915087163449
Trained batch 75 in epoch 2, gen_loss = 0.3824381012665598, disc_loss = 0.10766151961625407
Trained batch 76 in epoch 2, gen_loss = 0.38343165524594197, disc_loss = 0.10817008651793003
Trained batch 77 in epoch 2, gen_loss = 0.38208902455293214, disc_loss = 0.10898238976891989
Trained batch 78 in epoch 2, gen_loss = 0.3819143187396134, disc_loss = 0.11016543947537488
Trained batch 79 in epoch 2, gen_loss = 0.38258604258298873, disc_loss = 0.11028951110783965
Trained batch 80 in epoch 2, gen_loss = 0.3826496464970671, disc_loss = 0.11080308683952432
Trained batch 81 in epoch 2, gen_loss = 0.3825013619370577, disc_loss = 0.11289379439066823
Trained batch 82 in epoch 2, gen_loss = 0.3824466290962265, disc_loss = 0.11269940384270916
Trained batch 83 in epoch 2, gen_loss = 0.3821978349061239, disc_loss = 0.1127916313929572
Trained batch 84 in epoch 2, gen_loss = 0.3805019613574533, disc_loss = 0.11302173209979254
Trained batch 85 in epoch 2, gen_loss = 0.3802198428054189, disc_loss = 0.11235708260345598
Trained batch 86 in epoch 2, gen_loss = 0.38021089290750437, disc_loss = 0.11267498069196596
Trained batch 87 in epoch 2, gen_loss = 0.380132969468832, disc_loss = 0.11258653307926249
Trained batch 88 in epoch 2, gen_loss = 0.3790483655554525, disc_loss = 0.11261780051451721
Trained batch 89 in epoch 2, gen_loss = 0.37942633430163064, disc_loss = 0.11223592561566167
Trained batch 90 in epoch 2, gen_loss = 0.37948621825857476, disc_loss = 0.11292774944596894
Trained batch 91 in epoch 2, gen_loss = 0.3793897100764772, disc_loss = 0.11215581589013986
Trained batch 92 in epoch 2, gen_loss = 0.38022351425181156, disc_loss = 0.11140379447850489
Trained batch 93 in epoch 2, gen_loss = 0.38003404438495636, disc_loss = 0.11039914446387519
Trained batch 94 in epoch 2, gen_loss = 0.3802577417147787, disc_loss = 0.10956428513715141
Trained batch 95 in epoch 2, gen_loss = 0.3807065722843011, disc_loss = 0.10860775651720662
Trained batch 96 in epoch 2, gen_loss = 0.38014448733673883, disc_loss = 0.10793770834342721
Trained batch 97 in epoch 2, gen_loss = 0.38089026206610155, disc_loss = 0.10755616320031029
Trained batch 98 in epoch 2, gen_loss = 0.3814863083940564, disc_loss = 0.10681179060478403
Trained batch 99 in epoch 2, gen_loss = 0.3820919719338417, disc_loss = 0.10582731256261468
Trained batch 100 in epoch 2, gen_loss = 0.3820029340758182, disc_loss = 0.1059682094999174
Trained batch 101 in epoch 2, gen_loss = 0.3833441848264021, disc_loss = 0.10632919448920909
Trained batch 102 in epoch 2, gen_loss = 0.382977613256973, disc_loss = 0.10652969359845213
Trained batch 103 in epoch 2, gen_loss = 0.3830011790761581, disc_loss = 0.1064314901148184
Trained batch 104 in epoch 2, gen_loss = 0.3829024394353231, disc_loss = 0.10628450826874801
Trained batch 105 in epoch 2, gen_loss = 0.3832042459047066, disc_loss = 0.10591104537037746
Trained batch 106 in epoch 2, gen_loss = 0.3839084581236973, disc_loss = 0.1058685435765536
Trained batch 107 in epoch 2, gen_loss = 0.3838361788679052, disc_loss = 0.1053448307879821
Trained batch 108 in epoch 2, gen_loss = 0.3836842195703349, disc_loss = 0.10469544731900779
Trained batch 109 in epoch 2, gen_loss = 0.3845675809816881, disc_loss = 0.1046998404474421
Trained batch 110 in epoch 2, gen_loss = 0.38468072704366735, disc_loss = 0.10458389399489304
Trained batch 111 in epoch 2, gen_loss = 0.3849417958408594, disc_loss = 0.10428875350459878
Trained batch 112 in epoch 2, gen_loss = 0.38436132959559954, disc_loss = 0.104420125665786
Trained batch 113 in epoch 2, gen_loss = 0.38375775306894067, disc_loss = 0.10611694546318368
Trained batch 114 in epoch 2, gen_loss = 0.3846490116223045, disc_loss = 0.1066333080601433
Trained batch 115 in epoch 2, gen_loss = 0.3848013423126319, disc_loss = 0.1062443744680234
Trained batch 116 in epoch 2, gen_loss = 0.38506322207613886, disc_loss = 0.10581173711161837
Trained batch 117 in epoch 2, gen_loss = 0.385509841522928, disc_loss = 0.10549881759147017
Trained batch 118 in epoch 2, gen_loss = 0.3857152562181489, disc_loss = 0.10520572792895201
Trained batch 119 in epoch 2, gen_loss = 0.3859252149860064, disc_loss = 0.10479478021152318
Trained batch 120 in epoch 2, gen_loss = 0.3860289883022466, disc_loss = 0.10460418947656785
Trained batch 121 in epoch 2, gen_loss = 0.3868048498865034, disc_loss = 0.10441897307201976
Trained batch 122 in epoch 2, gen_loss = 0.3863651575596352, disc_loss = 0.10446680262987691
Trained batch 123 in epoch 2, gen_loss = 0.3865271811523745, disc_loss = 0.10540021804251498
Trained batch 124 in epoch 2, gen_loss = 0.38728676438331605, disc_loss = 0.1070402249544859
Trained batch 125 in epoch 2, gen_loss = 0.38679856227503884, disc_loss = 0.106624620138771
Trained batch 126 in epoch 2, gen_loss = 0.3868442051053986, disc_loss = 0.10660659675816382
Trained batch 127 in epoch 2, gen_loss = 0.3874123494606465, disc_loss = 0.10651436269108672
Trained batch 128 in epoch 2, gen_loss = 0.3872482448585274, disc_loss = 0.10618760703896829
Trained batch 129 in epoch 2, gen_loss = 0.3873939750286249, disc_loss = 0.10569179463558472
Trained batch 130 in epoch 2, gen_loss = 0.38762794855896754, disc_loss = 0.10562763708636506
Trained batch 131 in epoch 2, gen_loss = 0.38745969104947464, disc_loss = 0.10520221861643773
Trained batch 132 in epoch 2, gen_loss = 0.38790384764061836, disc_loss = 0.10472390135484082
Trained batch 133 in epoch 2, gen_loss = 0.3883305220906414, disc_loss = 0.10486446266799275
Trained batch 134 in epoch 2, gen_loss = 0.38769607808854845, disc_loss = 0.10482083565934941
Trained batch 135 in epoch 2, gen_loss = 0.38758788652279796, disc_loss = 0.10484400376513162
Trained batch 136 in epoch 2, gen_loss = 0.38714467369726974, disc_loss = 0.10589559306900431
Trained batch 137 in epoch 2, gen_loss = 0.3876365408085395, disc_loss = 0.10768671923627456
Trained batch 138 in epoch 2, gen_loss = 0.38687239040573723, disc_loss = 0.10771358990036756
Trained batch 139 in epoch 2, gen_loss = 0.38679537836994443, disc_loss = 0.1079882341969226
Trained batch 140 in epoch 2, gen_loss = 0.386817326148351, disc_loss = 0.10779130840607991
Trained batch 141 in epoch 2, gen_loss = 0.3871457723664566, disc_loss = 0.10804896183889097
Trained batch 142 in epoch 2, gen_loss = 0.38614074635755763, disc_loss = 0.10853708948340866
Trained batch 143 in epoch 2, gen_loss = 0.38621241754541796, disc_loss = 0.10837563056136584
Trained batch 144 in epoch 2, gen_loss = 0.3865042188044252, disc_loss = 0.10824574197417704
Trained batch 145 in epoch 2, gen_loss = 0.38651175133577764, disc_loss = 0.10823890588514201
Trained batch 146 in epoch 2, gen_loss = 0.38659103012003865, disc_loss = 0.10804741906927151
Trained batch 147 in epoch 2, gen_loss = 0.3865132610741499, disc_loss = 0.107550070356779
Trained batch 148 in epoch 2, gen_loss = 0.386663028357813, disc_loss = 0.10719378041290997
Trained batch 149 in epoch 2, gen_loss = 0.3868989345431328, disc_loss = 0.10706430543214082
Trained batch 150 in epoch 2, gen_loss = 0.3876527509349861, disc_loss = 0.1073524799839353
Trained batch 151 in epoch 2, gen_loss = 0.3874831067300157, disc_loss = 0.1069783948631467
Trained batch 152 in epoch 2, gen_loss = 0.38733923931916553, disc_loss = 0.10687402337546052
Trained batch 153 in epoch 2, gen_loss = 0.38785680015752844, disc_loss = 0.10651207680197118
Trained batch 154 in epoch 2, gen_loss = 0.3878796524578525, disc_loss = 0.10941379891047555
Trained batch 155 in epoch 2, gen_loss = 0.38759364732182944, disc_loss = 0.10965299886914018
Trained batch 156 in epoch 2, gen_loss = 0.38755619611330094, disc_loss = 0.11010308643197937
Trained batch 157 in epoch 2, gen_loss = 0.38727468846342233, disc_loss = 0.1104290111320494
Trained batch 158 in epoch 2, gen_loss = 0.38740831098091677, disc_loss = 0.11016490974656816
Trained batch 159 in epoch 2, gen_loss = 0.38733422523364425, disc_loss = 0.1099487212835811
Trained batch 160 in epoch 2, gen_loss = 0.38793419764278836, disc_loss = 0.10951244533756134
Trained batch 161 in epoch 2, gen_loss = 0.38821385202952374, disc_loss = 0.10946366980809856
Trained batch 162 in epoch 2, gen_loss = 0.3886779061307205, disc_loss = 0.10913453414533401
Trained batch 163 in epoch 2, gen_loss = 0.3890175376905174, disc_loss = 0.10886801691816711
Trained batch 164 in epoch 2, gen_loss = 0.38894264562563463, disc_loss = 0.10876616744155233
Trained batch 165 in epoch 2, gen_loss = 0.3887494101402271, disc_loss = 0.10865776930902019
Trained batch 166 in epoch 2, gen_loss = 0.3884506786833266, disc_loss = 0.10837713295515783
Trained batch 167 in epoch 2, gen_loss = 0.3884656128606626, disc_loss = 0.10818318252096928
Trained batch 168 in epoch 2, gen_loss = 0.3890528175428774, disc_loss = 0.10788398223912575
Trained batch 169 in epoch 2, gen_loss = 0.3889313684666858, disc_loss = 0.1076406048172537
Trained batch 170 in epoch 2, gen_loss = 0.3895066074634853, disc_loss = 0.10800993169129591
Trained batch 171 in epoch 2, gen_loss = 0.38986682865855304, disc_loss = 0.10795166513471063
Trained batch 172 in epoch 2, gen_loss = 0.38918432843133893, disc_loss = 0.10836611753814138
Trained batch 173 in epoch 2, gen_loss = 0.3885091559469015, disc_loss = 0.10866138618439436
Trained batch 174 in epoch 2, gen_loss = 0.388705215879849, disc_loss = 0.11052575695727553
Trained batch 175 in epoch 2, gen_loss = 0.3879548298533667, disc_loss = 0.11106234243859282
Trained batch 176 in epoch 2, gen_loss = 0.38751843630594046, disc_loss = 0.11119529138724346
Trained batch 177 in epoch 2, gen_loss = 0.3872254667489716, disc_loss = 0.11153049320191814
Trained batch 178 in epoch 2, gen_loss = 0.3870848666189769, disc_loss = 0.11184354423019806
Trained batch 179 in epoch 2, gen_loss = 0.38676181212067606, disc_loss = 0.11185235415274898
Trained batch 180 in epoch 2, gen_loss = 0.38645173296414687, disc_loss = 0.11176523596089519
Trained batch 181 in epoch 2, gen_loss = 0.38665717406259786, disc_loss = 0.11154060398361512
Trained batch 182 in epoch 2, gen_loss = 0.38687807753112147, disc_loss = 0.11134740348925681
Trained batch 183 in epoch 2, gen_loss = 0.38684707758543285, disc_loss = 0.11120566544527917
Trained batch 184 in epoch 2, gen_loss = 0.38731278914052086, disc_loss = 0.11133969954743579
Trained batch 185 in epoch 2, gen_loss = 0.3871456867744846, disc_loss = 0.11198055484802813
Trained batch 186 in epoch 2, gen_loss = 0.38724217320827237, disc_loss = 0.11184049326986234
Trained batch 187 in epoch 2, gen_loss = 0.3877683320736631, disc_loss = 0.11177951918835653
Trained batch 188 in epoch 2, gen_loss = 0.38766060564568433, disc_loss = 0.11156361756067742
Trained batch 189 in epoch 2, gen_loss = 0.3875854932163891, disc_loss = 0.11162137401927459
Trained batch 190 in epoch 2, gen_loss = 0.3879973538102904, disc_loss = 0.11149007266299575
Trained batch 191 in epoch 2, gen_loss = 0.38815995235927403, disc_loss = 0.11236863766680472
Trained batch 192 in epoch 2, gen_loss = 0.3881763305534353, disc_loss = 0.11244229467614636
Trained batch 193 in epoch 2, gen_loss = 0.3885618810033061, disc_loss = 0.11230462863465253
Trained batch 194 in epoch 2, gen_loss = 0.3886412798594206, disc_loss = 0.11200838917149947
Trained batch 195 in epoch 2, gen_loss = 0.38843763399184966, disc_loss = 0.11190537864114253
Trained batch 196 in epoch 2, gen_loss = 0.38843947263235973, disc_loss = 0.11186431377634481
Trained batch 197 in epoch 2, gen_loss = 0.38846815196853696, disc_loss = 0.11192584875971079
Trained batch 198 in epoch 2, gen_loss = 0.3881909542497079, disc_loss = 0.11240344291468661
Trained batch 199 in epoch 2, gen_loss = 0.38849230878055097, disc_loss = 0.11298579688183963
Trained batch 200 in epoch 2, gen_loss = 0.38816119122564496, disc_loss = 0.1136951312626624
Trained batch 201 in epoch 2, gen_loss = 0.38801635602618206, disc_loss = 0.11396801850693945
Trained batch 202 in epoch 2, gen_loss = 0.38823248915778, disc_loss = 0.11383901172193694
Trained batch 203 in epoch 2, gen_loss = 0.3882521626849969, disc_loss = 0.11407987893029463
Trained batch 204 in epoch 2, gen_loss = 0.38855267726793524, disc_loss = 0.11428399117799794
Trained batch 205 in epoch 2, gen_loss = 0.3885645764400658, disc_loss = 0.11403275558779251
Trained batch 206 in epoch 2, gen_loss = 0.38808270518618504, disc_loss = 0.11400932932929428
Trained batch 207 in epoch 2, gen_loss = 0.38803738463096893, disc_loss = 0.11387399038693939
Trained batch 208 in epoch 2, gen_loss = 0.38826044973289, disc_loss = 0.11367127505180083
Trained batch 209 in epoch 2, gen_loss = 0.38805228847832907, disc_loss = 0.11354011835619097
Trained batch 210 in epoch 2, gen_loss = 0.38773367451548013, disc_loss = 0.1135439921735446
Trained batch 211 in epoch 2, gen_loss = 0.38797896840381174, disc_loss = 0.1133025266880275
Trained batch 212 in epoch 2, gen_loss = 0.38763836089154363, disc_loss = 0.11307765782194239
Trained batch 213 in epoch 2, gen_loss = 0.38737559993968945, disc_loss = 0.11291750827717169
Trained batch 214 in epoch 2, gen_loss = 0.38756035781183906, disc_loss = 0.11288084225772425
Trained batch 215 in epoch 2, gen_loss = 0.38748378962002417, disc_loss = 0.1126744097046968
Trained batch 216 in epoch 2, gen_loss = 0.3875617972030068, disc_loss = 0.11233205958548505
Trained batch 217 in epoch 2, gen_loss = 0.3876680310029502, disc_loss = 0.11203323173926237
Trained batch 218 in epoch 2, gen_loss = 0.38764706750710803, disc_loss = 0.11203141033343256
Trained batch 219 in epoch 2, gen_loss = 0.3871848719363863, disc_loss = 0.11212536170232025
Trained batch 220 in epoch 2, gen_loss = 0.38728111975602975, disc_loss = 0.11189003727858153
Trained batch 221 in epoch 2, gen_loss = 0.38760772260191206, disc_loss = 0.1119505083859638
Trained batch 222 in epoch 2, gen_loss = 0.38758465707836665, disc_loss = 0.11216437002234662
Trained batch 223 in epoch 2, gen_loss = 0.3877617218531668, disc_loss = 0.1119431484839879
Trained batch 224 in epoch 2, gen_loss = 0.38804131117131974, disc_loss = 0.11314944347573651
Trained batch 225 in epoch 2, gen_loss = 0.3881018270565345, disc_loss = 0.11286756754811622
Trained batch 226 in epoch 2, gen_loss = 0.38800597880117693, disc_loss = 0.11419756391335951
Trained batch 227 in epoch 2, gen_loss = 0.3880373323826413, disc_loss = 0.11434081395303733
Trained batch 228 in epoch 2, gen_loss = 0.38790320354517893, disc_loss = 0.11419669323190071
Trained batch 229 in epoch 2, gen_loss = 0.38780765915694443, disc_loss = 0.11427029496787683
Trained batch 230 in epoch 2, gen_loss = 0.3877685972493448, disc_loss = 0.11411243308641952
Trained batch 231 in epoch 2, gen_loss = 0.3876922133796174, disc_loss = 0.11385559951404817
Trained batch 232 in epoch 2, gen_loss = 0.38774746483743444, disc_loss = 0.1138569681861242
Trained batch 233 in epoch 2, gen_loss = 0.3873948517900247, disc_loss = 0.11440398294924416
Trained batch 234 in epoch 2, gen_loss = 0.3873904804600046, disc_loss = 0.11414981914803068
Trained batch 235 in epoch 2, gen_loss = 0.3876739448031126, disc_loss = 0.11409091806607478
Trained batch 236 in epoch 2, gen_loss = 0.3873454293998485, disc_loss = 0.11412707099274493
Trained batch 237 in epoch 2, gen_loss = 0.3874593128551956, disc_loss = 0.1139810433329529
Trained batch 238 in epoch 2, gen_loss = 0.3876871231584868, disc_loss = 0.11373456775612163
Trained batch 239 in epoch 2, gen_loss = 0.38752578975011903, disc_loss = 0.11362627076450735
Trained batch 240 in epoch 2, gen_loss = 0.3875171260838687, disc_loss = 0.11374136133900074
Trained batch 241 in epoch 2, gen_loss = 0.3874959804671855, disc_loss = 0.11394301016068409
Trained batch 242 in epoch 2, gen_loss = 0.38736453045297553, disc_loss = 0.11368121831474726
Trained batch 243 in epoch 2, gen_loss = 0.387099912970281, disc_loss = 0.11353825972430774
Trained batch 244 in epoch 2, gen_loss = 0.38682649676897085, disc_loss = 0.1133120881887723
Trained batch 245 in epoch 2, gen_loss = 0.38671200855718396, disc_loss = 0.11314726338487088
Trained batch 246 in epoch 2, gen_loss = 0.3869818553388843, disc_loss = 0.11287021521584466
Trained batch 247 in epoch 2, gen_loss = 0.3871490417589103, disc_loss = 0.11258523287101378
Trained batch 248 in epoch 2, gen_loss = 0.38733423982997495, disc_loss = 0.11218778507028478
Trained batch 249 in epoch 2, gen_loss = 0.3874396511912346, disc_loss = 0.11206707506626844
Trained batch 250 in epoch 2, gen_loss = 0.3873593243825958, disc_loss = 0.11200786876933745
Trained batch 251 in epoch 2, gen_loss = 0.38755812643775867, disc_loss = 0.11187408993848497
Trained batch 252 in epoch 2, gen_loss = 0.3875657310009945, disc_loss = 0.1119730212162488
Trained batch 253 in epoch 2, gen_loss = 0.38791372568353893, disc_loss = 0.11213990575890606
Trained batch 254 in epoch 2, gen_loss = 0.3880439047135559, disc_loss = 0.11182556395583293
Trained batch 255 in epoch 2, gen_loss = 0.3878209762624465, disc_loss = 0.11172303258354077
Trained batch 256 in epoch 2, gen_loss = 0.38790786132970206, disc_loss = 0.11168944963946184
Trained batch 257 in epoch 2, gen_loss = 0.3881587607338447, disc_loss = 0.1113687433634502
Trained batch 258 in epoch 2, gen_loss = 0.3878863034446267, disc_loss = 0.11162790390716787
Trained batch 259 in epoch 2, gen_loss = 0.38813447510966886, disc_loss = 0.11156687297356817
Trained batch 260 in epoch 2, gen_loss = 0.38825249506367576, disc_loss = 0.11164619024999982
Trained batch 261 in epoch 2, gen_loss = 0.38804379384253773, disc_loss = 0.11194963288983999
Trained batch 262 in epoch 2, gen_loss = 0.3878834794342744, disc_loss = 0.11192154707989085
Trained batch 263 in epoch 2, gen_loss = 0.3878244367625677, disc_loss = 0.11215390484413189
Trained batch 264 in epoch 2, gen_loss = 0.38773469638149693, disc_loss = 0.11189037985256257
Trained batch 265 in epoch 2, gen_loss = 0.3874891571196398, disc_loss = 0.1120456771056791
Trained batch 266 in epoch 2, gen_loss = 0.38798469935686847, disc_loss = 0.11212627770386162
Trained batch 267 in epoch 2, gen_loss = 0.3874320006971039, disc_loss = 0.11403332547103959
Trained batch 268 in epoch 2, gen_loss = 0.3873836787549093, disc_loss = 0.11397350925024335
Trained batch 269 in epoch 2, gen_loss = 0.3874903060219906, disc_loss = 0.11400336788070423
Trained batch 270 in epoch 2, gen_loss = 0.3875295923974681, disc_loss = 0.1140242185361161
Trained batch 271 in epoch 2, gen_loss = 0.3876509614398374, disc_loss = 0.11401042185367688
Trained batch 272 in epoch 2, gen_loss = 0.38755538704849424, disc_loss = 0.11397602124610445
Trained batch 273 in epoch 2, gen_loss = 0.38758616187494166, disc_loss = 0.11386522829505431
Trained batch 274 in epoch 2, gen_loss = 0.38742945416407154, disc_loss = 0.11393999467519196
Trained batch 275 in epoch 2, gen_loss = 0.3873639527330364, disc_loss = 0.11398928266261583
Trained batch 276 in epoch 2, gen_loss = 0.387583898346777, disc_loss = 0.11382065250097845
Trained batch 277 in epoch 2, gen_loss = 0.3878824039221668, disc_loss = 0.11357887517392849
Trained batch 278 in epoch 2, gen_loss = 0.3879248003699019, disc_loss = 0.11336756523658512
Trained batch 279 in epoch 2, gen_loss = 0.38802468750093666, disc_loss = 0.11329091044275888
Trained batch 280 in epoch 2, gen_loss = 0.38777732154440625, disc_loss = 0.11308306641876698
Trained batch 281 in epoch 2, gen_loss = 0.38812524709084356, disc_loss = 0.11279366734100783
Trained batch 282 in epoch 2, gen_loss = 0.3880398089704581, disc_loss = 0.1125356062206805
Trained batch 283 in epoch 2, gen_loss = 0.3881558561304086, disc_loss = 0.11224927488898098
Trained batch 284 in epoch 2, gen_loss = 0.38835406256349464, disc_loss = 0.11204178234594955
Trained batch 285 in epoch 2, gen_loss = 0.38837751105323537, disc_loss = 0.11203020733579264
Trained batch 286 in epoch 2, gen_loss = 0.38819081427120583, disc_loss = 0.11210686140385447
Trained batch 287 in epoch 2, gen_loss = 0.3885142401171227, disc_loss = 0.11272752559873173
Trained batch 288 in epoch 2, gen_loss = 0.38822390180351823, disc_loss = 0.11267883705046144
Trained batch 289 in epoch 2, gen_loss = 0.38804815848325863, disc_loss = 0.1125889155435665
Trained batch 290 in epoch 2, gen_loss = 0.38786475257980046, disc_loss = 0.11279236994478915
Trained batch 291 in epoch 2, gen_loss = 0.38796007801612764, disc_loss = 0.11263714889574745
Trained batch 292 in epoch 2, gen_loss = 0.388122481850227, disc_loss = 0.11249622352319569
Trained batch 293 in epoch 2, gen_loss = 0.38824022318027457, disc_loss = 0.11295729942087616
Trained batch 294 in epoch 2, gen_loss = 0.38791516892990824, disc_loss = 0.11358363826017258
Trained batch 295 in epoch 2, gen_loss = 0.3881870274104782, disc_loss = 0.1133718917687499
Trained batch 296 in epoch 2, gen_loss = 0.38851107988092637, disc_loss = 0.11323194624072173
Trained batch 297 in epoch 2, gen_loss = 0.3884002095800918, disc_loss = 0.11322134035020667
Trained batch 298 in epoch 2, gen_loss = 0.3882842692344085, disc_loss = 0.11314559881777866
Trained batch 299 in epoch 2, gen_loss = 0.38850465004642804, disc_loss = 0.11317927074308197
Trained batch 300 in epoch 2, gen_loss = 0.38809236017770543, disc_loss = 0.11349510024626587
Trained batch 301 in epoch 2, gen_loss = 0.38824634732592184, disc_loss = 0.1133987759455841
Trained batch 302 in epoch 2, gen_loss = 0.3881415695738871, disc_loss = 0.11341072952762099
Trained batch 303 in epoch 2, gen_loss = 0.38803639924643857, disc_loss = 0.11352639306508201
Trained batch 304 in epoch 2, gen_loss = 0.38797085045791063, disc_loss = 0.11365566673215295
Trained batch 305 in epoch 2, gen_loss = 0.38783034170959513, disc_loss = 0.1137096971894304
Trained batch 306 in epoch 2, gen_loss = 0.3878852612906248, disc_loss = 0.11354899430095373
Trained batch 307 in epoch 2, gen_loss = 0.38785103732695825, disc_loss = 0.11356988248669288
Trained batch 308 in epoch 2, gen_loss = 0.38785440959398026, disc_loss = 0.11328907018002954
Trained batch 309 in epoch 2, gen_loss = 0.3876459342337424, disc_loss = 0.1134937298994872
Trained batch 310 in epoch 2, gen_loss = 0.3880895210903174, disc_loss = 0.11434647260036115
Trained batch 311 in epoch 2, gen_loss = 0.3878037878431571, disc_loss = 0.11430432030166952
Trained batch 312 in epoch 2, gen_loss = 0.38783542726176995, disc_loss = 0.11466309988793855
Trained batch 313 in epoch 2, gen_loss = 0.38773402642862054, disc_loss = 0.11507510591986453
Trained batch 314 in epoch 2, gen_loss = 0.3876680280008013, disc_loss = 0.11511141349162374
Trained batch 315 in epoch 2, gen_loss = 0.3878189551207838, disc_loss = 0.11500797082398888
Trained batch 316 in epoch 2, gen_loss = 0.3878611064389677, disc_loss = 0.11505113157799192
Trained batch 317 in epoch 2, gen_loss = 0.3877680430528503, disc_loss = 0.11499568760254474
Trained batch 318 in epoch 2, gen_loss = 0.3877828087085467, disc_loss = 0.11488395367623497
Trained batch 319 in epoch 2, gen_loss = 0.38767620981670914, disc_loss = 0.11468476561130955
Trained batch 320 in epoch 2, gen_loss = 0.38770728815938826, disc_loss = 0.11451226843062591
Trained batch 321 in epoch 2, gen_loss = 0.3875050656266094, disc_loss = 0.11429957576929042
Trained batch 322 in epoch 2, gen_loss = 0.3874854402553186, disc_loss = 0.11409817519525625
Trained batch 323 in epoch 2, gen_loss = 0.38753835797125913, disc_loss = 0.11382582875681513
Trained batch 324 in epoch 2, gen_loss = 0.387531027839734, disc_loss = 0.11364596962928772
Trained batch 325 in epoch 2, gen_loss = 0.38754512502189065, disc_loss = 0.1139857838490258
Trained batch 326 in epoch 2, gen_loss = 0.38738827316221475, disc_loss = 0.11397632949669427
Trained batch 327 in epoch 2, gen_loss = 0.3870365383875806, disc_loss = 0.11413998163600521
Trained batch 328 in epoch 2, gen_loss = 0.38706783841627346, disc_loss = 0.11400765341375374
Trained batch 329 in epoch 2, gen_loss = 0.3871732660766804, disc_loss = 0.11391526966383964
Trained batch 330 in epoch 2, gen_loss = 0.3871777113920972, disc_loss = 0.1137633419108895
Trained batch 331 in epoch 2, gen_loss = 0.3870690517486578, disc_loss = 0.11377314208860857
Trained batch 332 in epoch 2, gen_loss = 0.38732935864109175, disc_loss = 0.11361480354367792
Trained batch 333 in epoch 2, gen_loss = 0.3871662988366481, disc_loss = 0.11349232755824477
Trained batch 334 in epoch 2, gen_loss = 0.3874246326400273, disc_loss = 0.11328444148399937
Trained batch 335 in epoch 2, gen_loss = 0.38760860818659976, disc_loss = 0.11303011329090666
Trained batch 336 in epoch 2, gen_loss = 0.38745202840435755, disc_loss = 0.11280905951687774
Trained batch 337 in epoch 2, gen_loss = 0.3872539243666378, disc_loss = 0.11308267574823468
Trained batch 338 in epoch 2, gen_loss = 0.38687566375486265, disc_loss = 0.11341692805070441
Trained batch 339 in epoch 2, gen_loss = 0.3870500522063059, disc_loss = 0.11327253456282264
Trained batch 340 in epoch 2, gen_loss = 0.38703160311294793, disc_loss = 0.113228392882868
Trained batch 341 in epoch 2, gen_loss = 0.3873196780594469, disc_loss = 0.11309909706183693
Trained batch 342 in epoch 2, gen_loss = 0.38703668990739926, disc_loss = 0.1134531441370009
Trained batch 343 in epoch 2, gen_loss = 0.38725313020133695, disc_loss = 0.11368288787428377
Trained batch 344 in epoch 2, gen_loss = 0.3872820981602738, disc_loss = 0.11380701042387796
Trained batch 345 in epoch 2, gen_loss = 0.38717555659527036, disc_loss = 0.11365936023608453
Trained batch 346 in epoch 2, gen_loss = 0.3870889826621377, disc_loss = 0.11346612088060173
Trained batch 347 in epoch 2, gen_loss = 0.38702456254897444, disc_loss = 0.11338297871808553
Trained batch 348 in epoch 2, gen_loss = 0.3870770640479118, disc_loss = 0.11357837269632386
Trained batch 349 in epoch 2, gen_loss = 0.3871457528642246, disc_loss = 0.11376151922558035
Trained batch 350 in epoch 2, gen_loss = 0.3871902408677968, disc_loss = 0.11347495950227789
Trained batch 351 in epoch 2, gen_loss = 0.3869624042629518, disc_loss = 0.1135049542221664
Trained batch 352 in epoch 2, gen_loss = 0.38703079234608173, disc_loss = 0.11337733225469548
Trained batch 353 in epoch 2, gen_loss = 0.38705949430580194, disc_loss = 0.11334109827244686
Trained batch 354 in epoch 2, gen_loss = 0.3871491950582451, disc_loss = 0.11329040897774025
Trained batch 355 in epoch 2, gen_loss = 0.3870606766909026, disc_loss = 0.11321318807771032
Trained batch 356 in epoch 2, gen_loss = 0.3869295655762782, disc_loss = 0.1134700740606678
Trained batch 357 in epoch 2, gen_loss = 0.3872401134511612, disc_loss = 0.11407125259453026
Trained batch 358 in epoch 2, gen_loss = 0.38710866677561845, disc_loss = 0.11400514815137579
Trained batch 359 in epoch 2, gen_loss = 0.3869193967431784, disc_loss = 0.1143153860233724
Trained batch 360 in epoch 2, gen_loss = 0.38722996884270716, disc_loss = 0.11422990185113165
Trained batch 361 in epoch 2, gen_loss = 0.3870998435339875, disc_loss = 0.11445115561190561
Trained batch 362 in epoch 2, gen_loss = 0.3871700228820491, disc_loss = 0.11441740587600006
Trained batch 363 in epoch 2, gen_loss = 0.38726809100954085, disc_loss = 0.1144798157409161
Trained batch 364 in epoch 2, gen_loss = 0.3872354609100786, disc_loss = 0.11441517056871767
Trained batch 365 in epoch 2, gen_loss = 0.3872172828010523, disc_loss = 0.1142304793936633
Trained batch 366 in epoch 2, gen_loss = 0.38727758240147575, disc_loss = 0.11438949428478444
Trained batch 367 in epoch 2, gen_loss = 0.3870275653493793, disc_loss = 0.11442012949239301
Trained batch 368 in epoch 2, gen_loss = 0.3869428670584025, disc_loss = 0.11422486688063396
Trained batch 369 in epoch 2, gen_loss = 0.38687933059157553, disc_loss = 0.11419001356572718
Trained batch 370 in epoch 2, gen_loss = 0.3866733954039545, disc_loss = 0.11439621338063495
Trained batch 371 in epoch 2, gen_loss = 0.38674157405252096, disc_loss = 0.11419967249516517
Trained batch 372 in epoch 2, gen_loss = 0.3866469702276404, disc_loss = 0.11420763873223005
Trained batch 373 in epoch 2, gen_loss = 0.3866057699934684, disc_loss = 0.11417367444796996
Trained batch 374 in epoch 2, gen_loss = 0.3866816961367925, disc_loss = 0.11405184471607208
Trained batch 375 in epoch 2, gen_loss = 0.3869981766143378, disc_loss = 0.11384872506630231
Trained batch 376 in epoch 2, gen_loss = 0.38711850226557853, disc_loss = 0.11364246044179489
Trained batch 377 in epoch 2, gen_loss = 0.38707135306306617, disc_loss = 0.11375734534252573
Trained batch 378 in epoch 2, gen_loss = 0.38730763158414483, disc_loss = 0.11422000932544077
Trained batch 379 in epoch 2, gen_loss = 0.38717582221878205, disc_loss = 0.11421515832802183
Trained batch 380 in epoch 2, gen_loss = 0.38690916450787094, disc_loss = 0.11446750043766706
Trained batch 381 in epoch 2, gen_loss = 0.3872924202477745, disc_loss = 0.11549016635338362
Trained batch 382 in epoch 2, gen_loss = 0.3871317219874255, disc_loss = 0.11547801588168344
Trained batch 383 in epoch 2, gen_loss = 0.386842354782857, disc_loss = 0.11551675993056658
Trained batch 384 in epoch 2, gen_loss = 0.386714482423547, disc_loss = 0.11594950828652878
Trained batch 385 in epoch 2, gen_loss = 0.3867470562998495, disc_loss = 0.11583074638764784
Trained batch 386 in epoch 2, gen_loss = 0.3868458115084227, disc_loss = 0.11567929753845976
Trained batch 387 in epoch 2, gen_loss = 0.3868201919975354, disc_loss = 0.1155461780630897
Trained batch 388 in epoch 2, gen_loss = 0.3867354239397, disc_loss = 0.11549639963283943
Trained batch 389 in epoch 2, gen_loss = 0.38677758593589834, disc_loss = 0.11529659362366566
Trained batch 390 in epoch 2, gen_loss = 0.3866714895762446, disc_loss = 0.11503397448517172
Trained batch 391 in epoch 2, gen_loss = 0.3866797438157456, disc_loss = 0.11484267943709785
Trained batch 392 in epoch 2, gen_loss = 0.3866442317953547, disc_loss = 0.11465251435343242
Trained batch 393 in epoch 2, gen_loss = 0.38664474134063964, disc_loss = 0.11442776117946593
Trained batch 394 in epoch 2, gen_loss = 0.38656297329860395, disc_loss = 0.11424565792460985
Trained batch 395 in epoch 2, gen_loss = 0.38680180798124786, disc_loss = 0.1141060535805394
Trained batch 396 in epoch 2, gen_loss = 0.38673256014846735, disc_loss = 0.11407607253312464
Trained batch 397 in epoch 2, gen_loss = 0.3868664254120846, disc_loss = 0.11396479492436103
Trained batch 398 in epoch 2, gen_loss = 0.3868797631714876, disc_loss = 0.11393559001442186
Trained batch 399 in epoch 2, gen_loss = 0.3870372583344579, disc_loss = 0.11385959090664982
Trained batch 400 in epoch 2, gen_loss = 0.3872230806181258, disc_loss = 0.11367693314900125
Trained batch 401 in epoch 2, gen_loss = 0.38725529970666067, disc_loss = 0.11347590735302636
Trained batch 402 in epoch 2, gen_loss = 0.387555439441139, disc_loss = 0.11322502993398506
Trained batch 403 in epoch 2, gen_loss = 0.38753983684548055, disc_loss = 0.11302979697132169
Trained batch 404 in epoch 2, gen_loss = 0.3876958050477652, disc_loss = 0.11298313758071558
Trained batch 405 in epoch 2, gen_loss = 0.3876902226523813, disc_loss = 0.11319715646210268
Trained batch 406 in epoch 2, gen_loss = 0.3878866523797155, disc_loss = 0.11321243443308943
Trained batch 407 in epoch 2, gen_loss = 0.3877787887684855, disc_loss = 0.11319172556749453
Trained batch 408 in epoch 2, gen_loss = 0.3877928943024871, disc_loss = 0.11303763456806577
Trained batch 409 in epoch 2, gen_loss = 0.387933198380761, disc_loss = 0.11341305684934302
Trained batch 410 in epoch 2, gen_loss = 0.3876737345671712, disc_loss = 0.11365367389689687
Trained batch 411 in epoch 2, gen_loss = 0.38762121412505224, disc_loss = 0.11355456425039803
Trained batch 412 in epoch 2, gen_loss = 0.3876229075412773, disc_loss = 0.1136437016325049
Trained batch 413 in epoch 2, gen_loss = 0.38757946738154414, disc_loss = 0.11356935991145274
Trained batch 414 in epoch 2, gen_loss = 0.38747618280979523, disc_loss = 0.11362819907715521
Trained batch 415 in epoch 2, gen_loss = 0.3877152548744701, disc_loss = 0.11389442475046962
Trained batch 416 in epoch 2, gen_loss = 0.387761393646828, disc_loss = 0.11398045957195672
Trained batch 417 in epoch 2, gen_loss = 0.3878784961463732, disc_loss = 0.11384609852289183
Trained batch 418 in epoch 2, gen_loss = 0.38807687266487495, disc_loss = 0.1136530903401409
Trained batch 419 in epoch 2, gen_loss = 0.3881071127241566, disc_loss = 0.11348035520918312
Trained batch 420 in epoch 2, gen_loss = 0.38819584770751964, disc_loss = 0.11347340841085214
Trained batch 421 in epoch 2, gen_loss = 0.38826509141385274, disc_loss = 0.11349362303542582
Trained batch 422 in epoch 2, gen_loss = 0.38818608196210075, disc_loss = 0.11347750138412131
Trained batch 423 in epoch 2, gen_loss = 0.38811871968209743, disc_loss = 0.11330613146869922
Trained batch 424 in epoch 2, gen_loss = 0.388081302187022, disc_loss = 0.11326940242858494
Trained batch 425 in epoch 2, gen_loss = 0.38832703677001695, disc_loss = 0.1131169228713977
Trained batch 426 in epoch 2, gen_loss = 0.38826909832289963, disc_loss = 0.11299658598120933
Trained batch 427 in epoch 2, gen_loss = 0.3880802095980845, disc_loss = 0.11319369281354909
Trained batch 428 in epoch 2, gen_loss = 0.388123254016007, disc_loss = 0.1133265642748846
Trained batch 429 in epoch 2, gen_loss = 0.3880804889770441, disc_loss = 0.11311658199356739
Trained batch 430 in epoch 2, gen_loss = 0.38800313297806094, disc_loss = 0.11332474041756095
Trained batch 431 in epoch 2, gen_loss = 0.3881754810680394, disc_loss = 0.11358495206244427
Trained batch 432 in epoch 2, gen_loss = 0.3881548510619179, disc_loss = 0.11365824061559887
Trained batch 433 in epoch 2, gen_loss = 0.38813657636329324, disc_loss = 0.11350153678865064
Trained batch 434 in epoch 2, gen_loss = 0.3882471548757334, disc_loss = 0.11330591552815904
Trained batch 435 in epoch 2, gen_loss = 0.38810923534932484, disc_loss = 0.11323637528550051
Trained batch 436 in epoch 2, gen_loss = 0.3880310123722395, disc_loss = 0.11327766389660622
Trained batch 437 in epoch 2, gen_loss = 0.38813591911776424, disc_loss = 0.11372560221429694
Trained batch 438 in epoch 2, gen_loss = 0.3880813882467687, disc_loss = 0.11361309866885526
Trained batch 439 in epoch 2, gen_loss = 0.3881171537732536, disc_loss = 0.11349287136796524
Trained batch 440 in epoch 2, gen_loss = 0.38807644004048675, disc_loss = 0.11338750810664393
Trained batch 441 in epoch 2, gen_loss = 0.3880154215709656, disc_loss = 0.11317818718477747
Trained batch 442 in epoch 2, gen_loss = 0.388061384954248, disc_loss = 0.11307547791833668
Trained batch 443 in epoch 2, gen_loss = 0.38815050367433745, disc_loss = 0.11305120163219604
Trained batch 444 in epoch 2, gen_loss = 0.3881727740670858, disc_loss = 0.11291979514062404
Trained batch 445 in epoch 2, gen_loss = 0.38826182080357596, disc_loss = 0.11279607671542687
Trained batch 446 in epoch 2, gen_loss = 0.38817683705680855, disc_loss = 0.11276651659284528
Trained batch 447 in epoch 2, gen_loss = 0.38823538469815894, disc_loss = 0.11257375361414493
Trained batch 448 in epoch 2, gen_loss = 0.38831741291457134, disc_loss = 0.11248719400595583
Trained batch 449 in epoch 2, gen_loss = 0.38806842072142494, disc_loss = 0.11278392285522487
Trained batch 450 in epoch 2, gen_loss = 0.38821129692499495, disc_loss = 0.1127912486612202
Trained batch 451 in epoch 2, gen_loss = 0.38831856645709645, disc_loss = 0.11268405648014318
Trained batch 452 in epoch 2, gen_loss = 0.3880450999565735, disc_loss = 0.11264947922304108
Trained batch 453 in epoch 2, gen_loss = 0.3878264589653666, disc_loss = 0.11266190015879103
Trained batch 454 in epoch 2, gen_loss = 0.387800955084654, disc_loss = 0.11245148730065141
Trained batch 455 in epoch 2, gen_loss = 0.3877339167357014, disc_loss = 0.11236535706720724
Trained batch 456 in epoch 2, gen_loss = 0.38759875887723666, disc_loss = 0.11245554644426971
Trained batch 457 in epoch 2, gen_loss = 0.38788674000699447, disc_loss = 0.11248647149522102
Trained batch 458 in epoch 2, gen_loss = 0.38792602523090014, disc_loss = 0.11247053009930649
Trained batch 459 in epoch 2, gen_loss = 0.3879658328126306, disc_loss = 0.1124368375369712
Trained batch 460 in epoch 2, gen_loss = 0.3880085743107144, disc_loss = 0.11237374233756692
Trained batch 461 in epoch 2, gen_loss = 0.388008193955535, disc_loss = 0.11219147361363425
Trained batch 462 in epoch 2, gen_loss = 0.3879296915126928, disc_loss = 0.11360300022537456
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.39094996452331543, disc_loss = 0.1770041584968567
Trained batch 1 in epoch 3, gen_loss = 0.4009837359189987, disc_loss = 0.12654484808444977
Trained batch 2 in epoch 3, gen_loss = 0.40817806124687195, disc_loss = 0.11303120603164037
Trained batch 3 in epoch 3, gen_loss = 0.3903094604611397, disc_loss = 0.11563728377223015
Trained batch 4 in epoch 3, gen_loss = 0.3942019581794739, disc_loss = 0.10437611937522888
Trained batch 5 in epoch 3, gen_loss = 0.3951789041360219, disc_loss = 0.09311988080541293
Trained batch 6 in epoch 3, gen_loss = 0.38868232710020884, disc_loss = 0.0903696141072682
Trained batch 7 in epoch 3, gen_loss = 0.38882507011294365, disc_loss = 0.08454872807487845
Trained batch 8 in epoch 3, gen_loss = 0.3885501292016771, disc_loss = 0.07914911790026559
Trained batch 9 in epoch 3, gen_loss = 0.3882475644350052, disc_loss = 0.07321475669741631
Trained batch 10 in epoch 3, gen_loss = 0.3921583972193978, disc_loss = 0.06882186843590303
Trained batch 11 in epoch 3, gen_loss = 0.39096207916736603, disc_loss = 0.06598253268748522
Trained batch 12 in epoch 3, gen_loss = 0.38738170724648696, disc_loss = 0.06513109430670738
Trained batch 13 in epoch 3, gen_loss = 0.3877735265663692, disc_loss = 0.0652240054415805
Trained batch 14 in epoch 3, gen_loss = 0.38987139066060383, disc_loss = 0.061629921197891235
Trained batch 15 in epoch 3, gen_loss = 0.3929407261312008, disc_loss = 0.06239019753411412
Trained batch 16 in epoch 3, gen_loss = 0.3911849891438204, disc_loss = 0.06112825958167806
Trained batch 17 in epoch 3, gen_loss = 0.3886508213149177, disc_loss = 0.05917108327978187
Trained batch 18 in epoch 3, gen_loss = 0.39255737787798833, disc_loss = 0.056962176177062486
Trained batch 19 in epoch 3, gen_loss = 0.3984711244702339, disc_loss = 0.057856792397797105
Trained batch 20 in epoch 3, gen_loss = 0.39976872148967924, disc_loss = 0.05678191266599156
Trained batch 21 in epoch 3, gen_loss = 0.40132189609787683, disc_loss = 0.05762423456392505
Trained batch 22 in epoch 3, gen_loss = 0.39639461558798084, disc_loss = 0.06274354797990425
Trained batch 23 in epoch 3, gen_loss = 0.3989103212952614, disc_loss = 0.062343996639053025
Trained batch 24 in epoch 3, gen_loss = 0.39964011669158933, disc_loss = 0.06067387983202934
Trained batch 25 in epoch 3, gen_loss = 0.3989006384060933, disc_loss = 0.05903890327765392
Trained batch 26 in epoch 3, gen_loss = 0.4004585157941889, disc_loss = 0.059824040366543665
Trained batch 27 in epoch 3, gen_loss = 0.4007565772959164, disc_loss = 0.05830982912864004
Trained batch 28 in epoch 3, gen_loss = 0.39907868052351064, disc_loss = 0.05736241553877962
Trained batch 29 in epoch 3, gen_loss = 0.40147435466448467, disc_loss = 0.056692335133751236
Trained batch 30 in epoch 3, gen_loss = 0.3996996062417184, disc_loss = 0.058174492731209726
Trained batch 31 in epoch 3, gen_loss = 0.39794020634144545, disc_loss = 0.06022728083189577
Trained batch 32 in epoch 3, gen_loss = 0.3995741271611416, disc_loss = 0.06224005635489117
Trained batch 33 in epoch 3, gen_loss = 0.3973530899075901, disc_loss = 0.07032140508732375
Trained batch 34 in epoch 3, gen_loss = 0.3997955645833697, disc_loss = 0.06915455854364803
Trained batch 35 in epoch 3, gen_loss = 0.4003153873814477, disc_loss = 0.06998646062695318
Trained batch 36 in epoch 3, gen_loss = 0.40260162224640716, disc_loss = 0.06990011086737788
Trained batch 37 in epoch 3, gen_loss = 0.4034582698031476, disc_loss = 0.0695797948068694
Trained batch 38 in epoch 3, gen_loss = 0.4019184846144456, disc_loss = 0.07155720259134586
Trained batch 39 in epoch 3, gen_loss = 0.4018570467829704, disc_loss = 0.07052351217716932
Trained batch 40 in epoch 3, gen_loss = 0.40508903817432684, disc_loss = 0.06999599642869903
Trained batch 41 in epoch 3, gen_loss = 0.406501320146379, disc_loss = 0.06909346695811976
Trained batch 42 in epoch 3, gen_loss = 0.4053356231645096, disc_loss = 0.06853714810554372
Trained batch 43 in epoch 3, gen_loss = 0.4042429449883374, disc_loss = 0.07037614912471989
Trained batch 44 in epoch 3, gen_loss = 0.4046860376993815, disc_loss = 0.07571695397297541
Trained batch 45 in epoch 3, gen_loss = 0.4016670532848524, disc_loss = 0.07575593289473782
Trained batch 46 in epoch 3, gen_loss = 0.4000794513428465, disc_loss = 0.0756476935237012
Trained batch 47 in epoch 3, gen_loss = 0.3975606095045805, disc_loss = 0.07620642225568493
Trained batch 48 in epoch 3, gen_loss = 0.3960136704298915, disc_loss = 0.08110422032828234
Trained batch 49 in epoch 3, gen_loss = 0.39649883806705477, disc_loss = 0.08414078459143638
Trained batch 50 in epoch 3, gen_loss = 0.3972879309280246, disc_loss = 0.08405713751619938
Trained batch 51 in epoch 3, gen_loss = 0.39743141715343183, disc_loss = 0.08382783873149982
Trained batch 52 in epoch 3, gen_loss = 0.39586981568696367, disc_loss = 0.08292216695142242
Trained batch 53 in epoch 3, gen_loss = 0.3958797758376157, disc_loss = 0.08593816130801483
Trained batch 54 in epoch 3, gen_loss = 0.39471411325714806, disc_loss = 0.08949763083999807
Trained batch 55 in epoch 3, gen_loss = 0.3935723267495632, disc_loss = 0.08862813861508455
Trained batch 56 in epoch 3, gen_loss = 0.39316113633021976, disc_loss = 0.08818114660026734
Trained batch 57 in epoch 3, gen_loss = 0.39458462801472893, disc_loss = 0.08735502170848436
Trained batch 58 in epoch 3, gen_loss = 0.39420069981429534, disc_loss = 0.08739839538426722
Trained batch 59 in epoch 3, gen_loss = 0.39420213450988134, disc_loss = 0.0863894281598429
Trained batch 60 in epoch 3, gen_loss = 0.39329705717133695, disc_loss = 0.08661599961094192
Trained batch 61 in epoch 3, gen_loss = 0.3937439529165145, disc_loss = 0.0861041132781294
Trained batch 62 in epoch 3, gen_loss = 0.3936806746891567, disc_loss = 0.08753091194445178
Trained batch 63 in epoch 3, gen_loss = 0.39451846573501825, disc_loss = 0.0887761882331688
Trained batch 64 in epoch 3, gen_loss = 0.3935506577675159, disc_loss = 0.08873042180561103
Trained batch 65 in epoch 3, gen_loss = 0.39378551958185254, disc_loss = 0.08842398443569739
Trained batch 66 in epoch 3, gen_loss = 0.39432813961114455, disc_loss = 0.08828949853221872
Trained batch 67 in epoch 3, gen_loss = 0.3936993348247865, disc_loss = 0.08746508763664786
Trained batch 68 in epoch 3, gen_loss = 0.39443002619605133, disc_loss = 0.08677198022496009
Trained batch 69 in epoch 3, gen_loss = 0.39567932443959375, disc_loss = 0.0859425824135542
Trained batch 70 in epoch 3, gen_loss = 0.3959984615655013, disc_loss = 0.08633897217436576
Trained batch 71 in epoch 3, gen_loss = 0.39644818546043503, disc_loss = 0.08921924611139628
Trained batch 72 in epoch 3, gen_loss = 0.39627050292002014, disc_loss = 0.088576546219522
Trained batch 73 in epoch 3, gen_loss = 0.39626003962916295, disc_loss = 0.08870160322938417
Trained batch 74 in epoch 3, gen_loss = 0.394914212624232, disc_loss = 0.08852981830636661
Trained batch 75 in epoch 3, gen_loss = 0.3958903527573535, disc_loss = 0.0878679451385611
Trained batch 76 in epoch 3, gen_loss = 0.39656023932741835, disc_loss = 0.08709305125687804
Trained batch 77 in epoch 3, gen_loss = 0.3972009588510562, disc_loss = 0.08668225924842633
Trained batch 78 in epoch 3, gen_loss = 0.39704726768445364, disc_loss = 0.08583404300616512
Trained batch 79 in epoch 3, gen_loss = 0.3971546933054924, disc_loss = 0.08492360354866832
Trained batch 80 in epoch 3, gen_loss = 0.3973684550067525, disc_loss = 0.0841333474503991
Trained batch 81 in epoch 3, gen_loss = 0.39848228743890435, disc_loss = 0.08331615257463078
Trained batch 82 in epoch 3, gen_loss = 0.3976371794579977, disc_loss = 0.08345816111618495
Trained batch 83 in epoch 3, gen_loss = 0.3984768819950876, disc_loss = 0.08356530820241287
Trained batch 84 in epoch 3, gen_loss = 0.3987181516254649, disc_loss = 0.0828467429999043
Trained batch 85 in epoch 3, gen_loss = 0.3995144717222036, disc_loss = 0.0822794754491296
Trained batch 86 in epoch 3, gen_loss = 0.39902111785165195, disc_loss = 0.08344147756867025
Trained batch 87 in epoch 3, gen_loss = 0.40111958303234796, disc_loss = 0.0840505011041056
Trained batch 88 in epoch 3, gen_loss = 0.40045469128683714, disc_loss = 0.08357341914029603
Trained batch 89 in epoch 3, gen_loss = 0.39913235008716585, disc_loss = 0.08333000714580217
Trained batch 90 in epoch 3, gen_loss = 0.399983144395954, disc_loss = 0.0825566853509172
Trained batch 91 in epoch 3, gen_loss = 0.4004686685359996, disc_loss = 0.08215470500695317
Trained batch 92 in epoch 3, gen_loss = 0.4008037342179206, disc_loss = 0.08272047358895501
Trained batch 93 in epoch 3, gen_loss = 0.4008063461552275, disc_loss = 0.08201891300763856
Trained batch 94 in epoch 3, gen_loss = 0.40139063941804987, disc_loss = 0.08132548722389497
Trained batch 95 in epoch 3, gen_loss = 0.40087758873899776, disc_loss = 0.0812119787830549
Trained batch 96 in epoch 3, gen_loss = 0.40158021941627425, disc_loss = 0.08214989187407125
Trained batch 97 in epoch 3, gen_loss = 0.40118941026074545, disc_loss = 0.08504959429633252
Trained batch 98 in epoch 3, gen_loss = 0.4009131397863831, disc_loss = 0.08515765711740413
Trained batch 99 in epoch 3, gen_loss = 0.40068409979343417, disc_loss = 0.08589161625131965
Trained batch 100 in epoch 3, gen_loss = 0.40114199082450114, disc_loss = 0.08561943971210777
Trained batch 101 in epoch 3, gen_loss = 0.4013417722547756, disc_loss = 0.0855921883610826
Trained batch 102 in epoch 3, gen_loss = 0.4005183959470212, disc_loss = 0.08594579826497915
Trained batch 103 in epoch 3, gen_loss = 0.40141066450339097, disc_loss = 0.0857195164829206
Trained batch 104 in epoch 3, gen_loss = 0.4017200214522226, disc_loss = 0.084989795088768
Trained batch 105 in epoch 3, gen_loss = 0.40125772132063814, disc_loss = 0.08429520986622797
Trained batch 106 in epoch 3, gen_loss = 0.4008476583757133, disc_loss = 0.08382901101956301
Trained batch 107 in epoch 3, gen_loss = 0.4015329673334404, disc_loss = 0.08319086736689012
Trained batch 108 in epoch 3, gen_loss = 0.40140653914267865, disc_loss = 0.08292485383945868
Trained batch 109 in epoch 3, gen_loss = 0.4010484597899697, disc_loss = 0.0822304806037044
Trained batch 110 in epoch 3, gen_loss = 0.400616436122774, disc_loss = 0.08177600345817639
Trained batch 111 in epoch 3, gen_loss = 0.40100385727626936, disc_loss = 0.08113707878510468
Trained batch 112 in epoch 3, gen_loss = 0.40127151624291346, disc_loss = 0.08118269873156617
Trained batch 113 in epoch 3, gen_loss = 0.40098575986268226, disc_loss = 0.080879609872538
Trained batch 114 in epoch 3, gen_loss = 0.40066099503765934, disc_loss = 0.0806484832752334
Trained batch 115 in epoch 3, gen_loss = 0.4010418648349828, disc_loss = 0.0806958435849961
Trained batch 116 in epoch 3, gen_loss = 0.4013439844816159, disc_loss = 0.08014948139540277
Trained batch 117 in epoch 3, gen_loss = 0.40084909054182344, disc_loss = 0.08057297193603116
Trained batch 118 in epoch 3, gen_loss = 0.4023079478941044, disc_loss = 0.08125152002566126
Trained batch 119 in epoch 3, gen_loss = 0.4023002192378044, disc_loss = 0.08073620922320211
Trained batch 120 in epoch 3, gen_loss = 0.40184560984619394, disc_loss = 0.08037103018684943
Trained batch 121 in epoch 3, gen_loss = 0.4027745518528047, disc_loss = 0.08001923123298244
Trained batch 122 in epoch 3, gen_loss = 0.4030127583480463, disc_loss = 0.0795895368867834
Trained batch 123 in epoch 3, gen_loss = 0.4026816845420868, disc_loss = 0.07933133777846853
Trained batch 124 in epoch 3, gen_loss = 0.4021123216152191, disc_loss = 0.07895384472981096
Trained batch 125 in epoch 3, gen_loss = 0.40195767013799577, disc_loss = 0.07842305674040247
Trained batch 126 in epoch 3, gen_loss = 0.40255117205184276, disc_loss = 0.07807113234995036
Trained batch 127 in epoch 3, gen_loss = 0.40273947129026055, disc_loss = 0.07768161394415074
Trained batch 128 in epoch 3, gen_loss = 0.4035850111828294, disc_loss = 0.07727100896872868
Trained batch 129 in epoch 3, gen_loss = 0.40315533807644477, disc_loss = 0.07684120215260638
Trained batch 130 in epoch 3, gen_loss = 0.4032941683558107, disc_loss = 0.0763333221108347
Trained batch 131 in epoch 3, gen_loss = 0.40326485444198956, disc_loss = 0.07597252139186655
Trained batch 132 in epoch 3, gen_loss = 0.4028666991936533, disc_loss = 0.07546428466019661
Trained batch 133 in epoch 3, gen_loss = 0.4028045713011898, disc_loss = 0.07525438707975197
Trained batch 134 in epoch 3, gen_loss = 0.4027571896711985, disc_loss = 0.07505385382790808
Trained batch 135 in epoch 3, gen_loss = 0.4031136993537931, disc_loss = 0.07457560571663849
Trained batch 136 in epoch 3, gen_loss = 0.403513597745965, disc_loss = 0.0741652635837069
Trained batch 137 in epoch 3, gen_loss = 0.4035898084225862, disc_loss = 0.07375289527766839
Trained batch 138 in epoch 3, gen_loss = 0.40360272380945494, disc_loss = 0.07335132128297747
Trained batch 139 in epoch 3, gen_loss = 0.40343976723296304, disc_loss = 0.07292681382636407
Trained batch 140 in epoch 3, gen_loss = 0.40395696492905314, disc_loss = 0.07262715523903991
Trained batch 141 in epoch 3, gen_loss = 0.4040036889868723, disc_loss = 0.07232137559257237
Trained batch 142 in epoch 3, gen_loss = 0.40428959031205075, disc_loss = 0.07194045078908126
Trained batch 143 in epoch 3, gen_loss = 0.40479158237576485, disc_loss = 0.0717263580526277
Trained batch 144 in epoch 3, gen_loss = 0.4050890252507966, disc_loss = 0.0713203213049163
Trained batch 145 in epoch 3, gen_loss = 0.40526345780451006, disc_loss = 0.07088398704088408
Trained batch 146 in epoch 3, gen_loss = 0.4053085320660857, disc_loss = 0.07046092206890993
Trained batch 147 in epoch 3, gen_loss = 0.40451420924148046, disc_loss = 0.07050666994906056
Trained batch 148 in epoch 3, gen_loss = 0.4049274317370165, disc_loss = 0.07090320679727917
Trained batch 149 in epoch 3, gen_loss = 0.40461257537206013, disc_loss = 0.07055222430887322
Trained batch 150 in epoch 3, gen_loss = 0.40462312911519943, disc_loss = 0.07022070787563328
Trained batch 151 in epoch 3, gen_loss = 0.4043316535259548, disc_loss = 0.07019616910072632
Trained batch 152 in epoch 3, gen_loss = 0.4043586924185161, disc_loss = 0.07093962161722624
Trained batch 153 in epoch 3, gen_loss = 0.4046125721621823, disc_loss = 0.07078638301811532
Trained batch 154 in epoch 3, gen_loss = 0.4047778521814654, disc_loss = 0.07046426470060983
Trained batch 155 in epoch 3, gen_loss = 0.40500048853648013, disc_loss = 0.07018807408913301
Trained batch 156 in epoch 3, gen_loss = 0.4054844639483531, disc_loss = 0.0698472697934385
Trained batch 157 in epoch 3, gen_loss = 0.40521308081814006, disc_loss = 0.06957656269173927
Trained batch 158 in epoch 3, gen_loss = 0.40586412121664805, disc_loss = 0.06950264762934742
Trained batch 159 in epoch 3, gen_loss = 0.40603742133826015, disc_loss = 0.06912243358965497
Trained batch 160 in epoch 3, gen_loss = 0.4062593594100905, disc_loss = 0.06908473832625317
Trained batch 161 in epoch 3, gen_loss = 0.4062304309120885, disc_loss = 0.0687103177173592
Trained batch 162 in epoch 3, gen_loss = 0.4059517189768926, disc_loss = 0.0684766405764853
Trained batch 163 in epoch 3, gen_loss = 0.40531599503464816, disc_loss = 0.06876713157597385
Trained batch 164 in epoch 3, gen_loss = 0.40562987237265613, disc_loss = 0.06928463146711389
Trained batch 165 in epoch 3, gen_loss = 0.4057112729333969, disc_loss = 0.06933761452863285
Trained batch 166 in epoch 3, gen_loss = 0.40589688530939066, disc_loss = 0.06902161688672122
Trained batch 167 in epoch 3, gen_loss = 0.4059627776344617, disc_loss = 0.06869333645694756
Trained batch 168 in epoch 3, gen_loss = 0.4061686955612792, disc_loss = 0.06852483172134975
Trained batch 169 in epoch 3, gen_loss = 0.40587553767596973, disc_loss = 0.06866446475169677
Trained batch 170 in epoch 3, gen_loss = 0.40637245617414774, disc_loss = 0.06847238046394889
Trained batch 171 in epoch 3, gen_loss = 0.4064288737122403, disc_loss = 0.06838956460367542
Trained batch 172 in epoch 3, gen_loss = 0.4059690219818512, disc_loss = 0.06965990978524605
Trained batch 173 in epoch 3, gen_loss = 0.4061311236743269, disc_loss = 0.06972052176461566
Trained batch 174 in epoch 3, gen_loss = 0.40604169743401664, disc_loss = 0.06960654588948403
Trained batch 175 in epoch 3, gen_loss = 0.4057220254432071, disc_loss = 0.06935272567154077
Trained batch 176 in epoch 3, gen_loss = 0.4055596374522495, disc_loss = 0.06916144423155209
Trained batch 177 in epoch 3, gen_loss = 0.40536425974261897, disc_loss = 0.0691715482271831
Trained batch 178 in epoch 3, gen_loss = 0.4052859290019094, disc_loss = 0.06897470530112113
Trained batch 179 in epoch 3, gen_loss = 0.405295982129044, disc_loss = 0.06865357937963887
Trained batch 180 in epoch 3, gen_loss = 0.405551549314794, disc_loss = 0.06839004910463539
Trained batch 181 in epoch 3, gen_loss = 0.4055072021680874, disc_loss = 0.06804936752235005
Trained batch 182 in epoch 3, gen_loss = 0.40508174586817214, disc_loss = 0.06774503203831572
Trained batch 183 in epoch 3, gen_loss = 0.4053349872322186, disc_loss = 0.06764378128876991
Trained batch 184 in epoch 3, gen_loss = 0.405852648213103, disc_loss = 0.06763597559183836
Trained batch 185 in epoch 3, gen_loss = 0.4057846248790782, disc_loss = 0.06732493324545763
Trained batch 186 in epoch 3, gen_loss = 0.40590109034655564, disc_loss = 0.06716544983938416
Trained batch 187 in epoch 3, gen_loss = 0.4061083432207716, disc_loss = 0.0668835022209331
Trained batch 188 in epoch 3, gen_loss = 0.4062762459119161, disc_loss = 0.06662769101205326
Trained batch 189 in epoch 3, gen_loss = 0.40603428733976266, disc_loss = 0.06636668561320556
Trained batch 190 in epoch 3, gen_loss = 0.40622128148353537, disc_loss = 0.06604504428257806
Trained batch 191 in epoch 3, gen_loss = 0.4061867790296674, disc_loss = 0.06576313391754714
Trained batch 192 in epoch 3, gen_loss = 0.40607076049468677, disc_loss = 0.06554527106873421
Trained batch 193 in epoch 3, gen_loss = 0.40627527482730824, disc_loss = 0.06539113321293567
Trained batch 194 in epoch 3, gen_loss = 0.40580265537286414, disc_loss = 0.06516571343900301
Trained batch 195 in epoch 3, gen_loss = 0.4061283688155972, disc_loss = 0.06517259370801705
Trained batch 196 in epoch 3, gen_loss = 0.4062561501706312, disc_loss = 0.0648812135979344
Trained batch 197 in epoch 3, gen_loss = 0.4060131221106558, disc_loss = 0.06465309251786558
Trained batch 198 in epoch 3, gen_loss = 0.4058580380588321, disc_loss = 0.06444296973930606
Trained batch 199 in epoch 3, gen_loss = 0.4061917816102505, disc_loss = 0.06419017522828653
Trained batch 200 in epoch 3, gen_loss = 0.40626997126275627, disc_loss = 0.0639755120477755
Trained batch 201 in epoch 3, gen_loss = 0.40630331414170784, disc_loss = 0.06380255639525408
Trained batch 202 in epoch 3, gen_loss = 0.40659429507302536, disc_loss = 0.06362270769603513
Trained batch 203 in epoch 3, gen_loss = 0.4065775418398427, disc_loss = 0.06338970726766788
Trained batch 204 in epoch 3, gen_loss = 0.40647532154874105, disc_loss = 0.06315342967693761
Trained batch 205 in epoch 3, gen_loss = 0.40635297801888104, disc_loss = 0.06288614414984957
Trained batch 206 in epoch 3, gen_loss = 0.40655474616709536, disc_loss = 0.06262083546649935
Trained batch 207 in epoch 3, gen_loss = 0.4065732609194059, disc_loss = 0.0623817047117672
Trained batch 208 in epoch 3, gen_loss = 0.40668309276754205, disc_loss = 0.06214109846751727
Trained batch 209 in epoch 3, gen_loss = 0.4062732910826093, disc_loss = 0.06207090111759802
Trained batch 210 in epoch 3, gen_loss = 0.40571089011233, disc_loss = 0.06263847563689424
Trained batch 211 in epoch 3, gen_loss = 0.40624382726426395, disc_loss = 0.06358326162554254
Trained batch 212 in epoch 3, gen_loss = 0.40609364666289566, disc_loss = 0.06335741864132559
Trained batch 213 in epoch 3, gen_loss = 0.40594039913092816, disc_loss = 0.0637108961612021
Trained batch 214 in epoch 3, gen_loss = 0.405804595143296, disc_loss = 0.06350531876303775
Trained batch 215 in epoch 3, gen_loss = 0.40627437733389715, disc_loss = 0.06335340579324919
Trained batch 216 in epoch 3, gen_loss = 0.40608073146112506, disc_loss = 0.06309782794552259
Trained batch 217 in epoch 3, gen_loss = 0.4058098626246146, disc_loss = 0.06285131544327585
Trained batch 218 in epoch 3, gen_loss = 0.40587316446652694, disc_loss = 0.06261600715801392
Trained batch 219 in epoch 3, gen_loss = 0.4062160928140987, disc_loss = 0.06245189186566594
Trained batch 220 in epoch 3, gen_loss = 0.4064277328247398, disc_loss = 0.062298016759621745
Trained batch 221 in epoch 3, gen_loss = 0.4063388631419019, disc_loss = 0.062108012480527025
Trained batch 222 in epoch 3, gen_loss = 0.4061686844301865, disc_loss = 0.061880573423604396
Trained batch 223 in epoch 3, gen_loss = 0.40634851516889675, disc_loss = 0.06178022318428183
Trained batch 224 in epoch 3, gen_loss = 0.40606591648525664, disc_loss = 0.061744521105041104
Trained batch 225 in epoch 3, gen_loss = 0.40623880738178186, disc_loss = 0.06156196966314013
Trained batch 226 in epoch 3, gen_loss = 0.40620447281698824, disc_loss = 0.06162730936116912
Trained batch 227 in epoch 3, gen_loss = 0.40612674687515227, disc_loss = 0.06270916616388907
Trained batch 228 in epoch 3, gen_loss = 0.4064292570649276, disc_loss = 0.06283674542243109
Trained batch 229 in epoch 3, gen_loss = 0.40661588065002274, disc_loss = 0.06303465466986856
Trained batch 230 in epoch 3, gen_loss = 0.4062934156620141, disc_loss = 0.06344366457627772
Trained batch 231 in epoch 3, gen_loss = 0.40647374543136566, disc_loss = 0.06343332299328377
Trained batch 232 in epoch 3, gen_loss = 0.4062336151180349, disc_loss = 0.06341303629368991
Trained batch 233 in epoch 3, gen_loss = 0.4063505583848709, disc_loss = 0.06318919333772591
Trained batch 234 in epoch 3, gen_loss = 0.40625734658951457, disc_loss = 0.06306645696031603
Trained batch 235 in epoch 3, gen_loss = 0.4063908020823689, disc_loss = 0.06304759425071652
Trained batch 236 in epoch 3, gen_loss = 0.40638753721482646, disc_loss = 0.06303316244918397
Trained batch 237 in epoch 3, gen_loss = 0.40636357552364094, disc_loss = 0.06286897173957477
Trained batch 238 in epoch 3, gen_loss = 0.4066060197902025, disc_loss = 0.06263546170822684
Trained batch 239 in epoch 3, gen_loss = 0.4066930482784907, disc_loss = 0.062398935491607216
Trained batch 240 in epoch 3, gen_loss = 0.40646768036719677, disc_loss = 0.062288745010804954
Trained batch 241 in epoch 3, gen_loss = 0.4064862505217229, disc_loss = 0.06222306451498538
Trained batch 242 in epoch 3, gen_loss = 0.40683265600675417, disc_loss = 0.062141102016232755
Trained batch 243 in epoch 3, gen_loss = 0.4065004714199754, disc_loss = 0.062192502639592306
Trained batch 244 in epoch 3, gen_loss = 0.40669981837272645, disc_loss = 0.0620446319273692
Trained batch 245 in epoch 3, gen_loss = 0.4068438340493334, disc_loss = 0.0618705392220792
Trained batch 246 in epoch 3, gen_loss = 0.4068617365862194, disc_loss = 0.061726447528507186
Trained batch 247 in epoch 3, gen_loss = 0.40675446030593687, disc_loss = 0.06154474677074881
Trained batch 248 in epoch 3, gen_loss = 0.4069307069462466, disc_loss = 0.06135652768780967
Trained batch 249 in epoch 3, gen_loss = 0.4071388040781021, disc_loss = 0.061156902933493254
Trained batch 250 in epoch 3, gen_loss = 0.4068154495550817, disc_loss = 0.06106173547830774
Trained batch 251 in epoch 3, gen_loss = 0.4066902362401523, disc_loss = 0.06169012467753852
Trained batch 252 in epoch 3, gen_loss = 0.4070401863147148, disc_loss = 0.06245401284653738
Trained batch 253 in epoch 3, gen_loss = 0.40691358508087516, disc_loss = 0.06251703549770447
Trained batch 254 in epoch 3, gen_loss = 0.4067318499088287, disc_loss = 0.06252521119610059
Trained batch 255 in epoch 3, gen_loss = 0.4063671202166006, disc_loss = 0.06263623306040245
Trained batch 256 in epoch 3, gen_loss = 0.4066097874353832, disc_loss = 0.06253049969999301
Trained batch 257 in epoch 3, gen_loss = 0.4066406066796576, disc_loss = 0.0623605684864573
Trained batch 258 in epoch 3, gen_loss = 0.4063915443466437, disc_loss = 0.06253016211674998
Trained batch 259 in epoch 3, gen_loss = 0.40624673527020677, disc_loss = 0.0625483852542507
Trained batch 260 in epoch 3, gen_loss = 0.4063647518441138, disc_loss = 0.06260387917224075
Trained batch 261 in epoch 3, gen_loss = 0.4060497584233757, disc_loss = 0.06269074192462588
Trained batch 262 in epoch 3, gen_loss = 0.4060168749026019, disc_loss = 0.06265833398270573
Trained batch 263 in epoch 3, gen_loss = 0.4060115719383413, disc_loss = 0.06297039276757983
Trained batch 264 in epoch 3, gen_loss = 0.4057772842218291, disc_loss = 0.06315064693994399
Trained batch 265 in epoch 3, gen_loss = 0.40598208249959733, disc_loss = 0.06303714279652595
Trained batch 266 in epoch 3, gen_loss = 0.40608004516876595, disc_loss = 0.06285495332124807
Trained batch 267 in epoch 3, gen_loss = 0.4062670065618273, disc_loss = 0.0626977332746054
Trained batch 268 in epoch 3, gen_loss = 0.4062627368921684, disc_loss = 0.06258645006472792
Trained batch 269 in epoch 3, gen_loss = 0.4062914516086932, disc_loss = 0.06270890369217981
Trained batch 270 in epoch 3, gen_loss = 0.4063255123766586, disc_loss = 0.06292536976571947
Trained batch 271 in epoch 3, gen_loss = 0.4062694554381511, disc_loss = 0.06308836792082087
Trained batch 272 in epoch 3, gen_loss = 0.4063369625217312, disc_loss = 0.0629441473759274
Trained batch 273 in epoch 3, gen_loss = 0.40646173440626937, disc_loss = 0.06303035985358929
Trained batch 274 in epoch 3, gen_loss = 0.4062385341254148, disc_loss = 0.06323856893757528
Trained batch 275 in epoch 3, gen_loss = 0.406510584704254, disc_loss = 0.06357980847014519
Trained batch 276 in epoch 3, gen_loss = 0.4065990578181477, disc_loss = 0.0636810258061151
Trained batch 277 in epoch 3, gen_loss = 0.40647368872766015, disc_loss = 0.0636372450394087
Trained batch 278 in epoch 3, gen_loss = 0.40681279068779347, disc_loss = 0.0637935169231427
Trained batch 279 in epoch 3, gen_loss = 0.40689959419625144, disc_loss = 0.06365945990629761
Trained batch 280 in epoch 3, gen_loss = 0.4067353443955187, disc_loss = 0.06367536206825825
Trained batch 281 in epoch 3, gen_loss = 0.40650273806659887, disc_loss = 0.06353440326770622
Trained batch 282 in epoch 3, gen_loss = 0.4063795684925659, disc_loss = 0.06357172266629528
Trained batch 283 in epoch 3, gen_loss = 0.40621377947464793, disc_loss = 0.06363487383514695
Trained batch 284 in epoch 3, gen_loss = 0.40628298050478884, disc_loss = 0.06351277955170524
Trained batch 285 in epoch 3, gen_loss = 0.4062963005129274, disc_loss = 0.06340407080121234
Trained batch 286 in epoch 3, gen_loss = 0.4062387123963559, disc_loss = 0.0633871470844107
Trained batch 287 in epoch 3, gen_loss = 0.40662297637512285, disc_loss = 0.06329459566525959
Trained batch 288 in epoch 3, gen_loss = 0.4065066000582025, disc_loss = 0.06314661693001959
Trained batch 289 in epoch 3, gen_loss = 0.40640227938520496, disc_loss = 0.0630879795515974
Trained batch 290 in epoch 3, gen_loss = 0.4066130992063542, disc_loss = 0.06311001342039593
Trained batch 291 in epoch 3, gen_loss = 0.40673283426320717, disc_loss = 0.06311233640386889
Trained batch 292 in epoch 3, gen_loss = 0.4067884006191032, disc_loss = 0.06293078474287236
Trained batch 293 in epoch 3, gen_loss = 0.40701551907727507, disc_loss = 0.06289400567528697
Trained batch 294 in epoch 3, gen_loss = 0.4070063129319983, disc_loss = 0.06288514468597911
Trained batch 295 in epoch 3, gen_loss = 0.4069664707860431, disc_loss = 0.0628442913718597
Trained batch 296 in epoch 3, gen_loss = 0.40702523737644103, disc_loss = 0.06270873289937874
Trained batch 297 in epoch 3, gen_loss = 0.4068290636243436, disc_loss = 0.0625218564953855
Trained batch 298 in epoch 3, gen_loss = 0.4068491302405711, disc_loss = 0.06233672464864459
Trained batch 299 in epoch 3, gen_loss = 0.4070471613605817, disc_loss = 0.06221643656337013
Trained batch 300 in epoch 3, gen_loss = 0.40699030691603094, disc_loss = 0.0620463772868719
Trained batch 301 in epoch 3, gen_loss = 0.40685764231429195, disc_loss = 0.06190996622783903
Trained batch 302 in epoch 3, gen_loss = 0.40672075433699606, disc_loss = 0.06172967429361967
Trained batch 303 in epoch 3, gen_loss = 0.40655449473936306, disc_loss = 0.061551083354156856
Trained batch 304 in epoch 3, gen_loss = 0.40648378925245315, disc_loss = 0.06137007305123767
Trained batch 305 in epoch 3, gen_loss = 0.4064310785212548, disc_loss = 0.06132784945999875
Trained batch 306 in epoch 3, gen_loss = 0.4068072438240051, disc_loss = 0.061313018081436715
Trained batch 307 in epoch 3, gen_loss = 0.4069297899092947, disc_loss = 0.0611380751912978
Trained batch 308 in epoch 3, gen_loss = 0.40669134741462165, disc_loss = 0.06102829233782432
Trained batch 309 in epoch 3, gen_loss = 0.40680340576556423, disc_loss = 0.060976699957503905
Trained batch 310 in epoch 3, gen_loss = 0.40660616927974863, disc_loss = 0.060836565805078034
Trained batch 311 in epoch 3, gen_loss = 0.4066890264168764, disc_loss = 0.06071334425509215
Trained batch 312 in epoch 3, gen_loss = 0.4067207060682888, disc_loss = 0.06057826314305964
Trained batch 313 in epoch 3, gen_loss = 0.40689601032597245, disc_loss = 0.060462143321100406
Trained batch 314 in epoch 3, gen_loss = 0.40684068903090465, disc_loss = 0.060485727637119235
Trained batch 315 in epoch 3, gen_loss = 0.4074013683992096, disc_loss = 0.06049892742664235
Trained batch 316 in epoch 3, gen_loss = 0.40754619466393527, disc_loss = 0.06033953136914301
Trained batch 317 in epoch 3, gen_loss = 0.4074775862431376, disc_loss = 0.06017599539368548
Trained batch 318 in epoch 3, gen_loss = 0.40740182098923805, disc_loss = 0.06014816471022265
Trained batch 319 in epoch 3, gen_loss = 0.407573361042887, disc_loss = 0.060006354479992294
Trained batch 320 in epoch 3, gen_loss = 0.4073720125023078, disc_loss = 0.059897234482034996
Trained batch 321 in epoch 3, gen_loss = 0.40765215993297765, disc_loss = 0.05980946064452346
Trained batch 322 in epoch 3, gen_loss = 0.40786550187105, disc_loss = 0.059673874628882934
Trained batch 323 in epoch 3, gen_loss = 0.40777045902278686, disc_loss = 0.06003406172888468
Trained batch 324 in epoch 3, gen_loss = 0.4080885367210095, disc_loss = 0.06044984948606445
Trained batch 325 in epoch 3, gen_loss = 0.4081588456052944, disc_loss = 0.06031440173710005
Trained batch 326 in epoch 3, gen_loss = 0.407994991595592, disc_loss = 0.060336609184457164
Trained batch 327 in epoch 3, gen_loss = 0.4078082146077621, disc_loss = 0.06032251611369003
Trained batch 328 in epoch 3, gen_loss = 0.40781235930405124, disc_loss = 0.060308126697322426
Trained batch 329 in epoch 3, gen_loss = 0.40799975395202637, disc_loss = 0.06018804918381978
Trained batch 330 in epoch 3, gen_loss = 0.40806001829956956, disc_loss = 0.060138474940252
Trained batch 331 in epoch 3, gen_loss = 0.4080526797347758, disc_loss = 0.06053944105276816
Trained batch 332 in epoch 3, gen_loss = 0.40802253482936024, disc_loss = 0.06133055814902659
Trained batch 333 in epoch 3, gen_loss = 0.40795637319187916, disc_loss = 0.06131160864188241
Trained batch 334 in epoch 3, gen_loss = 0.40763329400945064, disc_loss = 0.06142417041640451
Trained batch 335 in epoch 3, gen_loss = 0.4075951487535522, disc_loss = 0.06139453721559784
Trained batch 336 in epoch 3, gen_loss = 0.40735933414552616, disc_loss = 0.06162271862407422
Trained batch 337 in epoch 3, gen_loss = 0.40753467548528366, disc_loss = 0.06154433446495446
Trained batch 338 in epoch 3, gen_loss = 0.4075521832018827, disc_loss = 0.06139935355682948
Trained batch 339 in epoch 3, gen_loss = 0.4074853074901244, disc_loss = 0.06125197835020064
Trained batch 340 in epoch 3, gen_loss = 0.40737649938228193, disc_loss = 0.06115146808167837
Trained batch 341 in epoch 3, gen_loss = 0.40752976252670176, disc_loss = 0.06101741100258428
Trained batch 342 in epoch 3, gen_loss = 0.407621282530248, disc_loss = 0.06090668614807134
Trained batch 343 in epoch 3, gen_loss = 0.40740150689732196, disc_loss = 0.060784338268202315
Trained batch 344 in epoch 3, gen_loss = 0.40716722875401595, disc_loss = 0.06086158040721995
Trained batch 345 in epoch 3, gen_loss = 0.40740429442052895, disc_loss = 0.06173390069185094
Trained batch 346 in epoch 3, gen_loss = 0.4072493583565143, disc_loss = 0.06173133953026246
Trained batch 347 in epoch 3, gen_loss = 0.40722325058846637, disc_loss = 0.06161301514406785
Trained batch 348 in epoch 3, gen_loss = 0.4073186557750647, disc_loss = 0.06153895841367052
Trained batch 349 in epoch 3, gen_loss = 0.4071554911136627, disc_loss = 0.061572100359148216
Trained batch 350 in epoch 3, gen_loss = 0.407124524102931, disc_loss = 0.061447319353100154
Trained batch 351 in epoch 3, gen_loss = 0.40713306922804227, disc_loss = 0.06131333220797718
Trained batch 352 in epoch 3, gen_loss = 0.40706041244204255, disc_loss = 0.0611923497299487
Trained batch 353 in epoch 3, gen_loss = 0.40694444184586154, disc_loss = 0.061108082450010766
Trained batch 354 in epoch 3, gen_loss = 0.40675391193846583, disc_loss = 0.0609747120782628
Trained batch 355 in epoch 3, gen_loss = 0.406907058582547, disc_loss = 0.06088956860495794
Trained batch 356 in epoch 3, gen_loss = 0.4066444454239864, disc_loss = 0.060808440035141235
Trained batch 357 in epoch 3, gen_loss = 0.40663461586949545, disc_loss = 0.06068489798500759
Trained batch 358 in epoch 3, gen_loss = 0.4067063786525248, disc_loss = 0.06061508253470976
Trained batch 359 in epoch 3, gen_loss = 0.4068211733467049, disc_loss = 0.06065594075997877
Trained batch 360 in epoch 3, gen_loss = 0.4065915057203446, disc_loss = 0.060750260228069286
Trained batch 361 in epoch 3, gen_loss = 0.4066856931586292, disc_loss = 0.0606280828514831
Trained batch 362 in epoch 3, gen_loss = 0.40666424825828595, disc_loss = 0.06051320586348409
Trained batch 363 in epoch 3, gen_loss = 0.4068635697220708, disc_loss = 0.06047165608366153
Trained batch 364 in epoch 3, gen_loss = 0.4069557159730833, disc_loss = 0.06034371384279164
Trained batch 365 in epoch 3, gen_loss = 0.4068465412803035, disc_loss = 0.060281867536721254
Trained batch 366 in epoch 3, gen_loss = 0.40700845927893303, disc_loss = 0.060236593996420784
Trained batch 367 in epoch 3, gen_loss = 0.4071215545029744, disc_loss = 0.0600940836492278
Trained batch 368 in epoch 3, gen_loss = 0.40706836611920905, disc_loss = 0.05999314300413054
Trained batch 369 in epoch 3, gen_loss = 0.40712309044760625, disc_loss = 0.05985587022040744
Trained batch 370 in epoch 3, gen_loss = 0.4072248413556348, disc_loss = 0.059740614991966444
Trained batch 371 in epoch 3, gen_loss = 0.4071153102702992, disc_loss = 0.05959671049038329
Trained batch 372 in epoch 3, gen_loss = 0.40725172444898383, disc_loss = 0.05947834725963606
Trained batch 373 in epoch 3, gen_loss = 0.4072239842006867, disc_loss = 0.059343609114720385
Trained batch 374 in epoch 3, gen_loss = 0.40748506450653077, disc_loss = 0.05926888236651818
Trained batch 375 in epoch 3, gen_loss = 0.40728386895770724, disc_loss = 0.05928414607509733
Trained batch 376 in epoch 3, gen_loss = 0.4075190280255335, disc_loss = 0.05960100813366137
Trained batch 377 in epoch 3, gen_loss = 0.4075863042048046, disc_loss = 0.0596579697559632
Trained batch 378 in epoch 3, gen_loss = 0.4074240723197253, disc_loss = 0.05955323938889758
Trained batch 379 in epoch 3, gen_loss = 0.4074308505968044, disc_loss = 0.05947685397818293
Trained batch 380 in epoch 3, gen_loss = 0.40732191874599205, disc_loss = 0.059495743914089336
Trained batch 381 in epoch 3, gen_loss = 0.40734117294793354, disc_loss = 0.0593803514438774
Trained batch 382 in epoch 3, gen_loss = 0.4072225612853277, disc_loss = 0.05930804352302775
Trained batch 383 in epoch 3, gen_loss = 0.40741116064600646, disc_loss = 0.059203609048078455
Trained batch 384 in epoch 3, gen_loss = 0.40757112758500236, disc_loss = 0.05907577558771356
Trained batch 385 in epoch 3, gen_loss = 0.40755591970033594, disc_loss = 0.05894039092595096
Trained batch 386 in epoch 3, gen_loss = 0.4074135380351882, disc_loss = 0.05880134727430436
Trained batch 387 in epoch 3, gen_loss = 0.40744460673676325, disc_loss = 0.05868197980663288
Trained batch 388 in epoch 3, gen_loss = 0.40743753306356983, disc_loss = 0.05867619677698168
Trained batch 389 in epoch 3, gen_loss = 0.4075949039214697, disc_loss = 0.05870958380639935
Trained batch 390 in epoch 3, gen_loss = 0.40769291091757964, disc_loss = 0.058580950443225595
Trained batch 391 in epoch 3, gen_loss = 0.4076383286440859, disc_loss = 0.05849348944469298
Trained batch 392 in epoch 3, gen_loss = 0.4075969116378377, disc_loss = 0.05837986534627263
Trained batch 393 in epoch 3, gen_loss = 0.4075477104350395, disc_loss = 0.05825773011514832
Trained batch 394 in epoch 3, gen_loss = 0.40755275676522074, disc_loss = 0.05815082875705218
Trained batch 395 in epoch 3, gen_loss = 0.40748824337215134, disc_loss = 0.0580412965089158
Trained batch 396 in epoch 3, gen_loss = 0.4072875124531369, disc_loss = 0.05791390043277509
Trained batch 397 in epoch 3, gen_loss = 0.40737210573563026, disc_loss = 0.05778783041955763
Trained batch 398 in epoch 3, gen_loss = 0.40734772193700747, disc_loss = 0.05769178478332017
Trained batch 399 in epoch 3, gen_loss = 0.40754300601780413, disc_loss = 0.057656052072998135
Trained batch 400 in epoch 3, gen_loss = 0.407498312412652, disc_loss = 0.057675134434720075
Trained batch 401 in epoch 3, gen_loss = 0.4075844785319039, disc_loss = 0.05778354815721734
Trained batch 402 in epoch 3, gen_loss = 0.4074024990681679, disc_loss = 0.057949926285882004
Trained batch 403 in epoch 3, gen_loss = 0.40738492407421073, disc_loss = 0.0581426590953096
Trained batch 404 in epoch 3, gen_loss = 0.4071472731637366, disc_loss = 0.0582513147275205
Trained batch 405 in epoch 3, gen_loss = 0.40715358527423123, disc_loss = 0.058151178784539986
Trained batch 406 in epoch 3, gen_loss = 0.40723204795792883, disc_loss = 0.05818608682144991
Trained batch 407 in epoch 3, gen_loss = 0.40714238993093077, disc_loss = 0.05811599313564526
Trained batch 408 in epoch 3, gen_loss = 0.4071098163833245, disc_loss = 0.05824631711463547
Trained batch 409 in epoch 3, gen_loss = 0.40734397434606784, disc_loss = 0.05863930008987465
Trained batch 410 in epoch 3, gen_loss = 0.40721962718777993, disc_loss = 0.05874547297293615
Trained batch 411 in epoch 3, gen_loss = 0.4073374833441475, disc_loss = 0.05875315058081257
Trained batch 412 in epoch 3, gen_loss = 0.4072907985555635, disc_loss = 0.05865852867386171
Trained batch 413 in epoch 3, gen_loss = 0.40726444794647937, disc_loss = 0.05861597728425106
Trained batch 414 in epoch 3, gen_loss = 0.4071954414787063, disc_loss = 0.058570384797471835
Trained batch 415 in epoch 3, gen_loss = 0.4073006057968506, disc_loss = 0.05881837002995711
Trained batch 416 in epoch 3, gen_loss = 0.407466565247634, disc_loss = 0.059213918030744404
Trained batch 417 in epoch 3, gen_loss = 0.4073250078413475, disc_loss = 0.05909264312932295
Trained batch 418 in epoch 3, gen_loss = 0.40724151629536703, disc_loss = 0.05938392156303854
Trained batch 419 in epoch 3, gen_loss = 0.40726647802761623, disc_loss = 0.059795979629935964
Trained batch 420 in epoch 3, gen_loss = 0.40710527717076117, disc_loss = 0.06002294313551907
Trained batch 421 in epoch 3, gen_loss = 0.40697141810898535, disc_loss = 0.06000691742119843
Trained batch 422 in epoch 3, gen_loss = 0.40703500740353377, disc_loss = 0.06015740338290203
Trained batch 423 in epoch 3, gen_loss = 0.40712206388981836, disc_loss = 0.06006408918359018
Trained batch 424 in epoch 3, gen_loss = 0.4069805812134462, disc_loss = 0.06009083507472978
Trained batch 425 in epoch 3, gen_loss = 0.4070367223360169, disc_loss = 0.060125072812442906
Trained batch 426 in epoch 3, gen_loss = 0.4070276060344464, disc_loss = 0.060026303206328346
Trained batch 427 in epoch 3, gen_loss = 0.4070188402433262, disc_loss = 0.06004773084918542
Trained batch 428 in epoch 3, gen_loss = 0.40694229176272323, disc_loss = 0.060041685597341514
Trained batch 429 in epoch 3, gen_loss = 0.4069581069918566, disc_loss = 0.05997833284917613
Trained batch 430 in epoch 3, gen_loss = 0.4069710976839619, disc_loss = 0.05990728307861117
Trained batch 431 in epoch 3, gen_loss = 0.40689411421340926, disc_loss = 0.05985705020483928
Trained batch 432 in epoch 3, gen_loss = 0.40683509364689746, disc_loss = 0.05988512419413681
Trained batch 433 in epoch 3, gen_loss = 0.406753372761511, disc_loss = 0.05980062557487375
Trained batch 434 in epoch 3, gen_loss = 0.4067940008366245, disc_loss = 0.059726243297002095
Trained batch 435 in epoch 3, gen_loss = 0.406782624166493, disc_loss = 0.05960915574094776
Trained batch 436 in epoch 3, gen_loss = 0.40699543553304346, disc_loss = 0.05962832822534735
Trained batch 437 in epoch 3, gen_loss = 0.4068413022310222, disc_loss = 0.059836317225865444
Trained batch 438 in epoch 3, gen_loss = 0.4070846634600863, disc_loss = 0.06020851173397824
Trained batch 439 in epoch 3, gen_loss = 0.40697785223072225, disc_loss = 0.06011293496386233
Trained batch 440 in epoch 3, gen_loss = 0.4069393711025212, disc_loss = 0.06008205194313442
Trained batch 441 in epoch 3, gen_loss = 0.40693119559352753, disc_loss = 0.05998323118415286
Trained batch 442 in epoch 3, gen_loss = 0.4068068820251568, disc_loss = 0.05988591824265083
Trained batch 443 in epoch 3, gen_loss = 0.4068627740751516, disc_loss = 0.05980429877443155
Trained batch 444 in epoch 3, gen_loss = 0.40679857429493677, disc_loss = 0.05970485652221388
Trained batch 445 in epoch 3, gen_loss = 0.40678192260821305, disc_loss = 0.05960605685878963
Trained batch 446 in epoch 3, gen_loss = 0.406717580970235, disc_loss = 0.05952326971537515
Trained batch 447 in epoch 3, gen_loss = 0.4066012032063944, disc_loss = 0.059445177843112366
Trained batch 448 in epoch 3, gen_loss = 0.4067007648387306, disc_loss = 0.05938064842744168
Trained batch 449 in epoch 3, gen_loss = 0.40654538412888847, disc_loss = 0.05930068987732132
Trained batch 450 in epoch 3, gen_loss = 0.4067632179963351, disc_loss = 0.059198749443710244
Trained batch 451 in epoch 3, gen_loss = 0.4067593817557909, disc_loss = 0.05909255056320566
Trained batch 452 in epoch 3, gen_loss = 0.4067453397951905, disc_loss = 0.058985026995291644
Trained batch 453 in epoch 3, gen_loss = 0.4067088123328885, disc_loss = 0.058912239880567735
Trained batch 454 in epoch 3, gen_loss = 0.4067107916533292, disc_loss = 0.05885704227897164
Trained batch 455 in epoch 3, gen_loss = 0.4066496618876332, disc_loss = 0.058762009249460935
Trained batch 456 in epoch 3, gen_loss = 0.406706522734473, disc_loss = 0.058647188342724574
Trained batch 457 in epoch 3, gen_loss = 0.4067903774013686, disc_loss = 0.05854220797844622
Trained batch 458 in epoch 3, gen_loss = 0.4068365898267376, disc_loss = 0.05843328308488581
Trained batch 459 in epoch 3, gen_loss = 0.406742381012958, disc_loss = 0.05835360940647028
Trained batch 460 in epoch 3, gen_loss = 0.4067654266403968, disc_loss = 0.058242746086391156
Trained batch 461 in epoch 3, gen_loss = 0.4067565332372467, disc_loss = 0.05813007158211138
Trained batch 462 in epoch 3, gen_loss = 0.4065255629578625, disc_loss = 0.05820871791329645
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.43995508551597595, disc_loss = 0.03674325346946716
Trained batch 1 in epoch 4, gen_loss = 0.3983471244573593, disc_loss = 0.041896600276231766
Trained batch 2 in epoch 4, gen_loss = 0.39570143818855286, disc_loss = 0.03407981743415197
Trained batch 3 in epoch 4, gen_loss = 0.39341065287590027, disc_loss = 0.04002196714282036
Trained batch 4 in epoch 4, gen_loss = 0.39557411670684817, disc_loss = 0.03598871901631355
Trained batch 5 in epoch 4, gen_loss = 0.3740217139323552, disc_loss = 0.0862721111625433
Trained batch 6 in epoch 4, gen_loss = 0.38982074175562176, disc_loss = 0.10058437979647092
Trained batch 7 in epoch 4, gen_loss = 0.3913707919418812, disc_loss = 0.09271208988502622
Trained batch 8 in epoch 4, gen_loss = 0.3867792586485545, disc_loss = 0.08974576534496413
Trained batch 9 in epoch 4, gen_loss = 0.3864978730678558, disc_loss = 0.08458616770803928
Trained batch 10 in epoch 4, gen_loss = 0.3942794718525626, disc_loss = 0.08195474743843079
Trained batch 11 in epoch 4, gen_loss = 0.3933931464950244, disc_loss = 0.07691743597388268
Trained batch 12 in epoch 4, gen_loss = 0.395338610960887, disc_loss = 0.07620076433970378
Trained batch 13 in epoch 4, gen_loss = 0.393836755837713, disc_loss = 0.07283190983746733
Trained batch 14 in epoch 4, gen_loss = 0.3977417310078939, disc_loss = 0.07107450067996979
Trained batch 15 in epoch 4, gen_loss = 0.3959751557558775, disc_loss = 0.07141875987872481
Trained batch 16 in epoch 4, gen_loss = 0.4030841255889219, disc_loss = 0.07015219681403216
Trained batch 17 in epoch 4, gen_loss = 0.40698206093576217, disc_loss = 0.06678181772844659
Trained batch 18 in epoch 4, gen_loss = 0.40835288323854146, disc_loss = 0.06406239018236336
Trained batch 19 in epoch 4, gen_loss = 0.40865776091814043, disc_loss = 0.06160894017666578
Trained batch 20 in epoch 4, gen_loss = 0.4076559940973918, disc_loss = 0.05989312416031247
Trained batch 21 in epoch 4, gen_loss = 0.40877053141593933, disc_loss = 0.0578915285454555
Trained batch 22 in epoch 4, gen_loss = 0.410134001918461, disc_loss = 0.056039173965868744
Trained batch 23 in epoch 4, gen_loss = 0.4096800511082013, disc_loss = 0.05451780014360944
Trained batch 24 in epoch 4, gen_loss = 0.4117865824699402, disc_loss = 0.05314168095588684
Trained batch 25 in epoch 4, gen_loss = 0.41106103933774507, disc_loss = 0.0517019907442423
Trained batch 26 in epoch 4, gen_loss = 0.41029487274311205, disc_loss = 0.05041033857398563
Trained batch 27 in epoch 4, gen_loss = 0.40924059812511715, disc_loss = 0.048939496711162586
Trained batch 28 in epoch 4, gen_loss = 0.4092035499112359, disc_loss = 0.04769838848632985
Trained batch 29 in epoch 4, gen_loss = 0.41005017757415774, disc_loss = 0.04645790609841546
Trained batch 30 in epoch 4, gen_loss = 0.4103012979030609, disc_loss = 0.045373333648087516
Trained batch 31 in epoch 4, gen_loss = 0.4086992144584656, disc_loss = 0.04454847375745885
Trained batch 32 in epoch 4, gen_loss = 0.40892076221379364, disc_loss = 0.04341343795937119
Trained batch 33 in epoch 4, gen_loss = 0.4109083677039427, disc_loss = 0.04251000739853172
Trained batch 34 in epoch 4, gen_loss = 0.4109115191868373, disc_loss = 0.04145298355392047
Trained batch 35 in epoch 4, gen_loss = 0.4122487852970759, disc_loss = 0.04043413093313575
Trained batch 36 in epoch 4, gen_loss = 0.4126465803868062, disc_loss = 0.039805893156979535
Trained batch 37 in epoch 4, gen_loss = 0.41148911181249115, disc_loss = 0.0391131792413561
Trained batch 38 in epoch 4, gen_loss = 0.4114481439957252, disc_loss = 0.03840807744134695
Trained batch 39 in epoch 4, gen_loss = 0.4103100888431072, disc_loss = 0.03766755347605795
Trained batch 40 in epoch 4, gen_loss = 0.41097834342863504, disc_loss = 0.03702861654413182
Trained batch 41 in epoch 4, gen_loss = 0.4111462945029849, disc_loss = 0.03649883823735373
Trained batch 42 in epoch 4, gen_loss = 0.4122388251992159, disc_loss = 0.03585053044696187
Trained batch 43 in epoch 4, gen_loss = 0.41269478879191657, disc_loss = 0.035175307145850224
Trained batch 44 in epoch 4, gen_loss = 0.41248058610492283, disc_loss = 0.034516580226934615
Trained batch 45 in epoch 4, gen_loss = 0.4125070416409036, disc_loss = 0.033878188964951296
Trained batch 46 in epoch 4, gen_loss = 0.4113977716324177, disc_loss = 0.0333111347789143
Trained batch 47 in epoch 4, gen_loss = 0.41010893632968265, disc_loss = 0.03279632661724463
Trained batch 48 in epoch 4, gen_loss = 0.41044579172620965, disc_loss = 0.03223603834607163
Trained batch 49 in epoch 4, gen_loss = 0.40975657761096956, disc_loss = 0.031754787005484106
Trained batch 50 in epoch 4, gen_loss = 0.4091562529404958, disc_loss = 0.03153287546307433
Trained batch 51 in epoch 4, gen_loss = 0.40957351659352964, disc_loss = 0.031061421220119182
Trained batch 52 in epoch 4, gen_loss = 0.4105944700960843, disc_loss = 0.030625419304618297
Trained batch 53 in epoch 4, gen_loss = 0.41201857449831786, disc_loss = 0.030175570743503393
Trained batch 54 in epoch 4, gen_loss = 0.4120252983136611, disc_loss = 0.029714104880324818
Trained batch 55 in epoch 4, gen_loss = 0.4120945387652942, disc_loss = 0.029273234548911984
Trained batch 56 in epoch 4, gen_loss = 0.4123676492456804, disc_loss = 0.02900233367261918
Trained batch 57 in epoch 4, gen_loss = 0.4127896654194799, disc_loss = 0.02891737944446504
Trained batch 58 in epoch 4, gen_loss = 0.4124205642837589, disc_loss = 0.02893295179326403
Trained batch 59 in epoch 4, gen_loss = 0.4116575981179873, disc_loss = 0.028707652034548423
Trained batch 60 in epoch 4, gen_loss = 0.4122615275812931, disc_loss = 0.028503023019274237
Trained batch 61 in epoch 4, gen_loss = 0.4121196832387678, disc_loss = 0.02828596201124451
Trained batch 62 in epoch 4, gen_loss = 0.4113956330314515, disc_loss = 0.02857266679140074
Trained batch 63 in epoch 4, gen_loss = 0.4123536804690957, disc_loss = 0.030345468134328257
Trained batch 64 in epoch 4, gen_loss = 0.41261765865179206, disc_loss = 0.030037493337518893
Trained batch 65 in epoch 4, gen_loss = 0.4127481277241851, disc_loss = 0.031023178383651557
Trained batch 66 in epoch 4, gen_loss = 0.4127127323577653, disc_loss = 0.030658120838508232
Trained batch 67 in epoch 4, gen_loss = 0.41259768473751407, disc_loss = 0.03027962529620923
Trained batch 68 in epoch 4, gen_loss = 0.4129708478416222, disc_loss = 0.0299312562978678
Trained batch 69 in epoch 4, gen_loss = 0.4134495407342911, disc_loss = 0.029746126430109144
Trained batch 70 in epoch 4, gen_loss = 0.4137090343824575, disc_loss = 0.029440458857415006
Trained batch 71 in epoch 4, gen_loss = 0.41331136268046165, disc_loss = 0.029105035284171916
Trained batch 72 in epoch 4, gen_loss = 0.4135998401739826, disc_loss = 0.02881107217798086
Trained batch 73 in epoch 4, gen_loss = 0.4139160683026185, disc_loss = 0.028481827520236775
Trained batch 74 in epoch 4, gen_loss = 0.41321754574775693, disc_loss = 0.028156515912463268
Trained batch 75 in epoch 4, gen_loss = 0.41265772047795746, disc_loss = 0.02788961277416858
Trained batch 76 in epoch 4, gen_loss = 0.41204097789603394, disc_loss = 0.02764861366118897
Trained batch 77 in epoch 4, gen_loss = 0.4115539407118773, disc_loss = 0.027332091029399097
Trained batch 78 in epoch 4, gen_loss = 0.41091687958451767, disc_loss = 0.02707686301768769
Trained batch 79 in epoch 4, gen_loss = 0.4094281531870365, disc_loss = 0.027154211542801933
Trained batch 80 in epoch 4, gen_loss = 0.40961304086226, disc_loss = 0.026972323673328868
Trained batch 81 in epoch 4, gen_loss = 0.410863178895741, disc_loss = 0.026786569886409293
Trained batch 82 in epoch 4, gen_loss = 0.41133976952139156, disc_loss = 0.026649178965129406
Trained batch 83 in epoch 4, gen_loss = 0.41213037960586096, disc_loss = 0.02666488099688043
Trained batch 84 in epoch 4, gen_loss = 0.41211721055647904, disc_loss = 0.026557435889673582
Trained batch 85 in epoch 4, gen_loss = 0.41129619021748387, disc_loss = 0.026833161977011452
Trained batch 86 in epoch 4, gen_loss = 0.41120851176908646, disc_loss = 0.027193709528180718
Trained batch 87 in epoch 4, gen_loss = 0.41086830977689137, disc_loss = 0.0269689613011327
Trained batch 88 in epoch 4, gen_loss = 0.41127815641713944, disc_loss = 0.02674089153977425
Trained batch 89 in epoch 4, gen_loss = 0.4109659029377831, disc_loss = 0.027033619867223833
Trained batch 90 in epoch 4, gen_loss = 0.4111367627814576, disc_loss = 0.027078107076154632
Trained batch 91 in epoch 4, gen_loss = 0.4112473778102709, disc_loss = 0.026883571170796844
Trained batch 92 in epoch 4, gen_loss = 0.4106380061436725, disc_loss = 0.027356421880383966
Trained batch 93 in epoch 4, gen_loss = 0.4109911947174275, disc_loss = 0.02831207687887264
Trained batch 94 in epoch 4, gen_loss = 0.4114099392765447, disc_loss = 0.028109953420138674
Trained batch 95 in epoch 4, gen_loss = 0.41134832861522835, disc_loss = 0.02799415466627882
Trained batch 96 in epoch 4, gen_loss = 0.41066302835326834, disc_loss = 0.02776332173170042
Trained batch 97 in epoch 4, gen_loss = 0.41039315535097703, disc_loss = 0.027535111353523573
Trained batch 98 in epoch 4, gen_loss = 0.410199786677505, disc_loss = 0.027301370796531138
Trained batch 99 in epoch 4, gen_loss = 0.409769866168499, disc_loss = 0.0273513750359416
Trained batch 100 in epoch 4, gen_loss = 0.4096847155896744, disc_loss = 0.027155715792375332
Trained batch 101 in epoch 4, gen_loss = 0.40916479831817104, disc_loss = 0.026947267650279636
Trained batch 102 in epoch 4, gen_loss = 0.40984024295529115, disc_loss = 0.026789661555650456
Trained batch 103 in epoch 4, gen_loss = 0.4100179483111088, disc_loss = 0.02663718343515379
Trained batch 104 in epoch 4, gen_loss = 0.4106034102894011, disc_loss = 0.0265027784298928
Trained batch 105 in epoch 4, gen_loss = 0.41132616350110973, disc_loss = 0.026317221626533934
Trained batch 106 in epoch 4, gen_loss = 0.41099794250782407, disc_loss = 0.026119617201283436
Trained batch 107 in epoch 4, gen_loss = 0.4100139383916502, disc_loss = 0.026213947230846517
Trained batch 108 in epoch 4, gen_loss = 0.4105583637132557, disc_loss = 0.02607839965953603
Trained batch 109 in epoch 4, gen_loss = 0.41088955185630105, disc_loss = 0.025913070468232036
Trained batch 110 in epoch 4, gen_loss = 0.4109844415037482, disc_loss = 0.025839052024624637
Trained batch 111 in epoch 4, gen_loss = 0.4112012881253447, disc_loss = 0.025692622480814213
Trained batch 112 in epoch 4, gen_loss = 0.4109442410743342, disc_loss = 0.02636683907409289
Trained batch 113 in epoch 4, gen_loss = 0.41075812646171506, disc_loss = 0.026646735314116404
Trained batch 114 in epoch 4, gen_loss = 0.4116587615531424, disc_loss = 0.02685350721054103
Trained batch 115 in epoch 4, gen_loss = 0.41095859942765073, disc_loss = 0.0276123573401429
Trained batch 116 in epoch 4, gen_loss = 0.41094523107903635, disc_loss = 0.027459838033582155
Trained batch 117 in epoch 4, gen_loss = 0.4115503768799669, disc_loss = 0.027545679198830563
Trained batch 118 in epoch 4, gen_loss = 0.411279007667253, disc_loss = 0.0273562918002365
Trained batch 119 in epoch 4, gen_loss = 0.410749019185702, disc_loss = 0.02723540090955794
Trained batch 120 in epoch 4, gen_loss = 0.4101048887761171, disc_loss = 0.027151232770036074
Trained batch 121 in epoch 4, gen_loss = 0.4098305487241901, disc_loss = 0.0270196335909308
Trained batch 122 in epoch 4, gen_loss = 0.4095414644334374, disc_loss = 0.026850671166690383
Trained batch 123 in epoch 4, gen_loss = 0.40924320081549304, disc_loss = 0.026765090518540913
Trained batch 124 in epoch 4, gen_loss = 0.4090749731063843, disc_loss = 0.026593225784599783
Trained batch 125 in epoch 4, gen_loss = 0.409270479565575, disc_loss = 0.026424677739481605
Trained batch 126 in epoch 4, gen_loss = 0.40916103312349694, disc_loss = 0.026293151733267496
Trained batch 127 in epoch 4, gen_loss = 0.40914697013795376, disc_loss = 0.02623664492421085
Trained batch 128 in epoch 4, gen_loss = 0.4090236411538235, disc_loss = 0.026335416325591793
Trained batch 129 in epoch 4, gen_loss = 0.4090649442030833, disc_loss = 0.026351338245261174
Trained batch 130 in epoch 4, gen_loss = 0.40842751555770407, disc_loss = 0.0263188099488616
Trained batch 131 in epoch 4, gen_loss = 0.4091981522964709, disc_loss = 0.0262630672095287
Trained batch 132 in epoch 4, gen_loss = 0.4095853479733144, disc_loss = 0.026144180663938362
Trained batch 133 in epoch 4, gen_loss = 0.4096769194549589, disc_loss = 0.026001164411653333
Trained batch 134 in epoch 4, gen_loss = 0.4095150353731932, disc_loss = 0.025908967383481838
Trained batch 135 in epoch 4, gen_loss = 0.4106538999168312, disc_loss = 0.02616149978712201
Trained batch 136 in epoch 4, gen_loss = 0.4101658180682328, disc_loss = 0.026329618899056512
Trained batch 137 in epoch 4, gen_loss = 0.41006656660549884, disc_loss = 0.026378185960693634
Trained batch 138 in epoch 4, gen_loss = 0.4099968879771747, disc_loss = 0.026281245856833974
Trained batch 139 in epoch 4, gen_loss = 0.4098391526511737, disc_loss = 0.026249798280852183
Trained batch 140 in epoch 4, gen_loss = 0.409511979801435, disc_loss = 0.02612311776780279
Trained batch 141 in epoch 4, gen_loss = 0.4095369506050164, disc_loss = 0.026008467078471268
Trained batch 142 in epoch 4, gen_loss = 0.4094386129946142, disc_loss = 0.02586542515709371
Trained batch 143 in epoch 4, gen_loss = 0.40926464481486213, disc_loss = 0.02580554281788257
Trained batch 144 in epoch 4, gen_loss = 0.40963429767509985, disc_loss = 0.025682186344959612
Trained batch 145 in epoch 4, gen_loss = 0.40943821958483084, disc_loss = 0.025596432206029557
Trained batch 146 in epoch 4, gen_loss = 0.40905316549093546, disc_loss = 0.025748299647021255
Trained batch 147 in epoch 4, gen_loss = 0.4093036450244285, disc_loss = 0.025979988198299463
Trained batch 148 in epoch 4, gen_loss = 0.40930311511826994, disc_loss = 0.026216949214346256
Trained batch 149 in epoch 4, gen_loss = 0.40873855133851367, disc_loss = 0.029026001912231248
Trained batch 150 in epoch 4, gen_loss = 0.40931912427706435, disc_loss = 0.029040050905641934
Trained batch 151 in epoch 4, gen_loss = 0.4096592474532755, disc_loss = 0.02935925889208815
Trained batch 152 in epoch 4, gen_loss = 0.40924061825072844, disc_loss = 0.029266947183417144
Trained batch 153 in epoch 4, gen_loss = 0.4087560817405775, disc_loss = 0.02961758436792373
Trained batch 154 in epoch 4, gen_loss = 0.40855547593485925, disc_loss = 0.02979381709029117
Trained batch 155 in epoch 4, gen_loss = 0.4083351928454179, disc_loss = 0.02978741580274147
Trained batch 156 in epoch 4, gen_loss = 0.40830413228387286, disc_loss = 0.029741040386473107
Trained batch 157 in epoch 4, gen_loss = 0.40870268906973584, disc_loss = 0.029627262658875764
Trained batch 158 in epoch 4, gen_loss = 0.408973144285334, disc_loss = 0.029585980672576704
Trained batch 159 in epoch 4, gen_loss = 0.40863690469413994, disc_loss = 0.029472196192364207
Trained batch 160 in epoch 4, gen_loss = 0.40864373104912893, disc_loss = 0.029352036411787227
Trained batch 161 in epoch 4, gen_loss = 0.4087502124868793, disc_loss = 0.029309366642853912
Trained batch 162 in epoch 4, gen_loss = 0.4081247132614346, disc_loss = 0.029349498459326526
Trained batch 163 in epoch 4, gen_loss = 0.40831690208940974, disc_loss = 0.029395751640904785
Trained batch 164 in epoch 4, gen_loss = 0.40761263785940227, disc_loss = 0.030390206145856417
Trained batch 165 in epoch 4, gen_loss = 0.4078948167433222, disc_loss = 0.031730758214189886
Trained batch 166 in epoch 4, gen_loss = 0.40743436945412687, disc_loss = 0.03314959367982553
Trained batch 167 in epoch 4, gen_loss = 0.40754559813510804, disc_loss = 0.034198268701965434
Trained batch 168 in epoch 4, gen_loss = 0.4079718364060983, disc_loss = 0.035808340142089765
Trained batch 169 in epoch 4, gen_loss = 0.4075205738053602, disc_loss = 0.036136096746058145
Trained batch 170 in epoch 4, gen_loss = 0.4075903908202523, disc_loss = 0.03619473992590928
Trained batch 171 in epoch 4, gen_loss = 0.40779261550931045, disc_loss = 0.036483993133811586
Trained batch 172 in epoch 4, gen_loss = 0.4071431855934893, disc_loss = 0.037334751302774756
Trained batch 173 in epoch 4, gen_loss = 0.40705557338807774, disc_loss = 0.037587306309684085
Trained batch 174 in epoch 4, gen_loss = 0.4067561752455575, disc_loss = 0.03786614340064781
Trained batch 175 in epoch 4, gen_loss = 0.4062918781895529, disc_loss = 0.03922611380535686
Trained batch 176 in epoch 4, gen_loss = 0.4060476195004027, disc_loss = 0.03955634484214887
Trained batch 177 in epoch 4, gen_loss = 0.4056008605474836, disc_loss = 0.039925484748013065
Trained batch 178 in epoch 4, gen_loss = 0.40613756166490095, disc_loss = 0.04033723547170199
Trained batch 179 in epoch 4, gen_loss = 0.4065334561798308, disc_loss = 0.040253697695314054
Trained batch 180 in epoch 4, gen_loss = 0.40655692703816115, disc_loss = 0.04017421700708691
Trained batch 181 in epoch 4, gen_loss = 0.4061080187886626, disc_loss = 0.040312171378940505
Trained batch 182 in epoch 4, gen_loss = 0.4061731803612631, disc_loss = 0.04050296209905235
Trained batch 183 in epoch 4, gen_loss = 0.4063224698538366, disc_loss = 0.04035330075598524
Trained batch 184 in epoch 4, gen_loss = 0.40626867558505086, disc_loss = 0.04074217739288469
Trained batch 185 in epoch 4, gen_loss = 0.40660205291163537, disc_loss = 0.04128576508442801
Trained batch 186 in epoch 4, gen_loss = 0.4061333071739278, disc_loss = 0.04120302789739985
Trained batch 187 in epoch 4, gen_loss = 0.405606579590351, disc_loss = 0.041159893244881424
Trained batch 188 in epoch 4, gen_loss = 0.4057030488574316, disc_loss = 0.04109425612887929
Trained batch 189 in epoch 4, gen_loss = 0.4059577753669337, disc_loss = 0.04094243193486411
Trained batch 190 in epoch 4, gen_loss = 0.40557047646707267, disc_loss = 0.04085549147292503
Trained batch 191 in epoch 4, gen_loss = 0.4054609043523669, disc_loss = 0.04070702068808411
Trained batch 192 in epoch 4, gen_loss = 0.40574968092799807, disc_loss = 0.04059611972894307
Trained batch 193 in epoch 4, gen_loss = 0.4057324828253579, disc_loss = 0.04043377844434347
Trained batch 194 in epoch 4, gen_loss = 0.4052770637548887, disc_loss = 0.04030015024189384
Trained batch 195 in epoch 4, gen_loss = 0.4055213361066215, disc_loss = 0.04021896338042784
Trained batch 196 in epoch 4, gen_loss = 0.40576567565124044, disc_loss = 0.04004403051972238
Trained batch 197 in epoch 4, gen_loss = 0.4052252462415984, disc_loss = 0.04014026115394451
Trained batch 198 in epoch 4, gen_loss = 0.4049990496144223, disc_loss = 0.04019481604029635
Trained batch 199 in epoch 4, gen_loss = 0.4051575592160225, disc_loss = 0.04010071083437652
Trained batch 200 in epoch 4, gen_loss = 0.40497649872480934, disc_loss = 0.039967340676679244
Trained batch 201 in epoch 4, gen_loss = 0.4054429224222013, disc_loss = 0.03982964736215844
Trained batch 202 in epoch 4, gen_loss = 0.40508317800578225, disc_loss = 0.039752196355406284
Trained batch 203 in epoch 4, gen_loss = 0.4053158928074089, disc_loss = 0.03976592969368486
Trained batch 204 in epoch 4, gen_loss = 0.40525521228953104, disc_loss = 0.03975386416039816
Trained batch 205 in epoch 4, gen_loss = 0.405157686147875, disc_loss = 0.040012432425056844
Trained batch 206 in epoch 4, gen_loss = 0.4047883399154829, disc_loss = 0.0401966324534969
Trained batch 207 in epoch 4, gen_loss = 0.40501809034209985, disc_loss = 0.040043540191478454
Trained batch 208 in epoch 4, gen_loss = 0.405221397226507, disc_loss = 0.03994874549254276
Trained batch 209 in epoch 4, gen_loss = 0.40493514906792416, disc_loss = 0.03983731021483739
Trained batch 210 in epoch 4, gen_loss = 0.40491996246491563, disc_loss = 0.03971354656309878
Trained batch 211 in epoch 4, gen_loss = 0.4047179645243681, disc_loss = 0.03955379996299392
Trained batch 212 in epoch 4, gen_loss = 0.4045877890407759, disc_loss = 0.039396222324455984
Trained batch 213 in epoch 4, gen_loss = 0.40458325136487727, disc_loss = 0.03924452452093502
Trained batch 214 in epoch 4, gen_loss = 0.40478159688239873, disc_loss = 0.03908729111169313
Trained batch 215 in epoch 4, gen_loss = 0.40463431772810443, disc_loss = 0.038983534588219806
Trained batch 216 in epoch 4, gen_loss = 0.40460870301668544, disc_loss = 0.038843596532237006
Trained batch 217 in epoch 4, gen_loss = 0.40478057503153425, disc_loss = 0.03872111542022215
Trained batch 218 in epoch 4, gen_loss = 0.4049465518836017, disc_loss = 0.03864332973812473
Trained batch 219 in epoch 4, gen_loss = 0.405184505879879, disc_loss = 0.038503585042516615
Trained batch 220 in epoch 4, gen_loss = 0.40495046743979823, disc_loss = 0.03834873690518521
Trained batch 221 in epoch 4, gen_loss = 0.4050516816409859, disc_loss = 0.0382530066826557
Trained batch 222 in epoch 4, gen_loss = 0.40469805074379583, disc_loss = 0.03824700586990591
Trained batch 223 in epoch 4, gen_loss = 0.40489224690411774, disc_loss = 0.0386431417240861
Trained batch 224 in epoch 4, gen_loss = 0.404847278992335, disc_loss = 0.03907988235147463
Trained batch 225 in epoch 4, gen_loss = 0.40479595431711823, disc_loss = 0.039014048097589245
Trained batch 226 in epoch 4, gen_loss = 0.40486730247867264, disc_loss = 0.038865152293085924
Trained batch 227 in epoch 4, gen_loss = 0.40486727733361094, disc_loss = 0.03872890086852733
Trained batch 228 in epoch 4, gen_loss = 0.40486838906092415, disc_loss = 0.03857898036034282
Trained batch 229 in epoch 4, gen_loss = 0.40456125256807907, disc_loss = 0.03845345718664644
Trained batch 230 in epoch 4, gen_loss = 0.40464333964116644, disc_loss = 0.03832583509393649
Trained batch 231 in epoch 4, gen_loss = 0.40421370558183767, disc_loss = 0.038297222487644514
Trained batch 232 in epoch 4, gen_loss = 0.403822494295022, disc_loss = 0.03840644479541372
Trained batch 233 in epoch 4, gen_loss = 0.4039465713704753, disc_loss = 0.03848174279038277
Trained batch 234 in epoch 4, gen_loss = 0.40405235227118147, disc_loss = 0.038391428656796824
Trained batch 235 in epoch 4, gen_loss = 0.4044316846687915, disc_loss = 0.03830265740950797
Trained batch 236 in epoch 4, gen_loss = 0.40446115193990717, disc_loss = 0.03816288250070144
Trained batch 237 in epoch 4, gen_loss = 0.40501274706936685, disc_loss = 0.038033088894185274
Trained batch 238 in epoch 4, gen_loss = 0.40507420373761005, disc_loss = 0.03798234416561583
Trained batch 239 in epoch 4, gen_loss = 0.4051640839626392, disc_loss = 0.038330045534530656
Trained batch 240 in epoch 4, gen_loss = 0.4053249033902196, disc_loss = 0.03883684850664987
Trained batch 241 in epoch 4, gen_loss = 0.4051050585656127, disc_loss = 0.03872503680254002
Trained batch 242 in epoch 4, gen_loss = 0.40515651195137586, disc_loss = 0.038703832114230334
Trained batch 243 in epoch 4, gen_loss = 0.40527556555681543, disc_loss = 0.03859537403045803
Trained batch 244 in epoch 4, gen_loss = 0.4053606763177989, disc_loss = 0.03845805676691994
Trained batch 245 in epoch 4, gen_loss = 0.4053340253791189, disc_loss = 0.038323310148955236
Trained batch 246 in epoch 4, gen_loss = 0.4053312826011828, disc_loss = 0.0381954857751516
Trained batch 247 in epoch 4, gen_loss = 0.40532515270094716, disc_loss = 0.038101923034241
Trained batch 248 in epoch 4, gen_loss = 0.4053422220978871, disc_loss = 0.03834087447820598
Trained batch 249 in epoch 4, gen_loss = 0.4053194417953491, disc_loss = 0.03859429816715419
Trained batch 250 in epoch 4, gen_loss = 0.4054203842028204, disc_loss = 0.03847834936332002
Trained batch 251 in epoch 4, gen_loss = 0.40574465183511615, disc_loss = 0.03834892603723953
Trained batch 252 in epoch 4, gen_loss = 0.4053622101370996, disc_loss = 0.03827771133459781
Trained batch 253 in epoch 4, gen_loss = 0.40545828347131024, disc_loss = 0.03816242969418898
Trained batch 254 in epoch 4, gen_loss = 0.40517904933761145, disc_loss = 0.03806791487606425
Trained batch 255 in epoch 4, gen_loss = 0.4050517693394795, disc_loss = 0.037969687467921176
Trained batch 256 in epoch 4, gen_loss = 0.4047329696004029, disc_loss = 0.037885168387920595
Trained batch 257 in epoch 4, gen_loss = 0.40482001861398537, disc_loss = 0.03778830526735951
Trained batch 258 in epoch 4, gen_loss = 0.404783573274907, disc_loss = 0.037676176324155916
Trained batch 259 in epoch 4, gen_loss = 0.404995464361631, disc_loss = 0.037574847674785326
Trained batch 260 in epoch 4, gen_loss = 0.40474062541435507, disc_loss = 0.037642663924587295
Trained batch 261 in epoch 4, gen_loss = 0.4046240185053294, disc_loss = 0.03777971844018245
Trained batch 262 in epoch 4, gen_loss = 0.40421374238489244, disc_loss = 0.0381499166572077
Trained batch 263 in epoch 4, gen_loss = 0.4044349691407247, disc_loss = 0.03809736044124954
Trained batch 264 in epoch 4, gen_loss = 0.40451532366140835, disc_loss = 0.03801219628702076
Trained batch 265 in epoch 4, gen_loss = 0.404498004263505, disc_loss = 0.03797289288840852
Trained batch 266 in epoch 4, gen_loss = 0.4043871358539281, disc_loss = 0.0379686302519386
Trained batch 267 in epoch 4, gen_loss = 0.40469859518221957, disc_loss = 0.03784905335997968
Trained batch 268 in epoch 4, gen_loss = 0.4047808931884269, disc_loss = 0.037737413176221146
Trained batch 269 in epoch 4, gen_loss = 0.4050629147776851, disc_loss = 0.0376237958755896
Trained batch 270 in epoch 4, gen_loss = 0.405024639574804, disc_loss = 0.037520880719846134
Trained batch 271 in epoch 4, gen_loss = 0.40512695864719506, disc_loss = 0.03756463959956925
Trained batch 272 in epoch 4, gen_loss = 0.4049268090899611, disc_loss = 0.03802348356250496
Trained batch 273 in epoch 4, gen_loss = 0.4053564757978829, disc_loss = 0.038546331548030034
Trained batch 274 in epoch 4, gen_loss = 0.40534491073001516, disc_loss = 0.03852983940223401
Trained batch 275 in epoch 4, gen_loss = 0.4053930546278539, disc_loss = 0.03845246278755097
Trained batch 276 in epoch 4, gen_loss = 0.40549679794466453, disc_loss = 0.038340991890790876
Trained batch 277 in epoch 4, gen_loss = 0.40539429159901985, disc_loss = 0.03828230990338133
Trained batch 278 in epoch 4, gen_loss = 0.4056161686938296, disc_loss = 0.038168427721333546
Trained batch 279 in epoch 4, gen_loss = 0.4051488632602351, disc_loss = 0.03843049793836794
Trained batch 280 in epoch 4, gen_loss = 0.40506528609588055, disc_loss = 0.03897229895936955
Trained batch 281 in epoch 4, gen_loss = 0.40513888392465336, disc_loss = 0.0388837766021173
Trained batch 282 in epoch 4, gen_loss = 0.4052059798906212, disc_loss = 0.03879855471817849
Trained batch 283 in epoch 4, gen_loss = 0.40503728956403867, disc_loss = 0.03874537517959383
Trained batch 284 in epoch 4, gen_loss = 0.4051798295556453, disc_loss = 0.038641872962838726
Trained batch 285 in epoch 4, gen_loss = 0.4050182039504285, disc_loss = 0.03864189704971297
Trained batch 286 in epoch 4, gen_loss = 0.40522953992521304, disc_loss = 0.03897679759390678
Trained batch 287 in epoch 4, gen_loss = 0.40514763682666755, disc_loss = 0.03970065178711795
Trained batch 288 in epoch 4, gen_loss = 0.40535672055396244, disc_loss = 0.03960336644885656
Trained batch 289 in epoch 4, gen_loss = 0.405429584918351, disc_loss = 0.0399878216008174
Trained batch 290 in epoch 4, gen_loss = 0.4052667007413517, disc_loss = 0.04059607254603679
Trained batch 291 in epoch 4, gen_loss = 0.4053842163045112, disc_loss = 0.04071050265497745
Trained batch 292 in epoch 4, gen_loss = 0.40532295400778995, disc_loss = 0.04061721904209653
Trained batch 293 in epoch 4, gen_loss = 0.4054482355207002, disc_loss = 0.0405643241049177
Trained batch 294 in epoch 4, gen_loss = 0.4055137346356602, disc_loss = 0.040460418249969765
Trained batch 295 in epoch 4, gen_loss = 0.40549344559376305, disc_loss = 0.04035187466699328
Trained batch 296 in epoch 4, gen_loss = 0.4056318529727884, disc_loss = 0.04045672985013286
Trained batch 297 in epoch 4, gen_loss = 0.4056626664312094, disc_loss = 0.040487032152412325
Trained batch 298 in epoch 4, gen_loss = 0.4055480884269727, disc_loss = 0.04040879302075675
Trained batch 299 in epoch 4, gen_loss = 0.4055540485183398, disc_loss = 0.04042473182703058
Trained batch 300 in epoch 4, gen_loss = 0.4057596729839363, disc_loss = 0.04033519501838078
Trained batch 301 in epoch 4, gen_loss = 0.4060244585899328, disc_loss = 0.04026082455680169
Trained batch 302 in epoch 4, gen_loss = 0.4064021224629368, disc_loss = 0.04016260820265749
Trained batch 303 in epoch 4, gen_loss = 0.4063428527626552, disc_loss = 0.04010751583356116
Trained batch 304 in epoch 4, gen_loss = 0.40651369817921373, disc_loss = 0.0400335630035547
Trained batch 305 in epoch 4, gen_loss = 0.406317637344591, disc_loss = 0.039940646517827035
Trained batch 306 in epoch 4, gen_loss = 0.4059425867147477, disc_loss = 0.04000428826502655
Trained batch 307 in epoch 4, gen_loss = 0.4063516968449989, disc_loss = 0.03998728228624088
Trained batch 308 in epoch 4, gen_loss = 0.4063798574953789, disc_loss = 0.04009175504645194
Trained batch 309 in epoch 4, gen_loss = 0.40622759951699167, disc_loss = 0.04069389630289328
Trained batch 310 in epoch 4, gen_loss = 0.40660709018109314, disc_loss = 0.04080803861536109
Trained batch 311 in epoch 4, gen_loss = 0.4067570058008035, disc_loss = 0.04073033754367572
Trained batch 312 in epoch 4, gen_loss = 0.4067040592336807, disc_loss = 0.040627005849235925
Trained batch 313 in epoch 4, gen_loss = 0.4067419235873374, disc_loss = 0.04057941678021649
Trained batch 314 in epoch 4, gen_loss = 0.40657226887960285, disc_loss = 0.040519193403186306
Trained batch 315 in epoch 4, gen_loss = 0.40678494574525687, disc_loss = 0.04057933411065819
Trained batch 316 in epoch 4, gen_loss = 0.4066702508211888, disc_loss = 0.04046855872197294
Trained batch 317 in epoch 4, gen_loss = 0.40653094452507094, disc_loss = 0.04059441416354487
Trained batch 318 in epoch 4, gen_loss = 0.40653117743779127, disc_loss = 0.040518065867799574
Trained batch 319 in epoch 4, gen_loss = 0.40644347919151186, disc_loss = 0.04044914564001374
Trained batch 320 in epoch 4, gen_loss = 0.40631959195077605, disc_loss = 0.04037017941567757
Trained batch 321 in epoch 4, gen_loss = 0.40625966761423193, disc_loss = 0.04035240488115305
Trained batch 322 in epoch 4, gen_loss = 0.4061862964748229, disc_loss = 0.0402643278056623
Trained batch 323 in epoch 4, gen_loss = 0.4063158520945796, disc_loss = 0.04022823589750462
Trained batch 324 in epoch 4, gen_loss = 0.4063389530548683, disc_loss = 0.04014255350312362
Trained batch 325 in epoch 4, gen_loss = 0.40613364569979943, disc_loss = 0.04053744829996872
Trained batch 326 in epoch 4, gen_loss = 0.406138984252918, disc_loss = 0.041193418737375594
Trained batch 327 in epoch 4, gen_loss = 0.4059206034715583, disc_loss = 0.04161724648949486
Trained batch 328 in epoch 4, gen_loss = 0.4060362123609676, disc_loss = 0.04155919750399412
Trained batch 329 in epoch 4, gen_loss = 0.40609745292952565, disc_loss = 0.04148807722341382
Trained batch 330 in epoch 4, gen_loss = 0.4062040338343364, disc_loss = 0.041380399237372814
Trained batch 331 in epoch 4, gen_loss = 0.406248643096671, disc_loss = 0.04136475861347449
Trained batch 332 in epoch 4, gen_loss = 0.40637539904396813, disc_loss = 0.04125882609252323
Trained batch 333 in epoch 4, gen_loss = 0.4065484377795351, disc_loss = 0.04117459397969355
Trained batch 334 in epoch 4, gen_loss = 0.4066451081589087, disc_loss = 0.04117629257962108
Trained batch 335 in epoch 4, gen_loss = 0.4064131605305842, disc_loss = 0.04139609511947215
Trained batch 336 in epoch 4, gen_loss = 0.4062883175622108, disc_loss = 0.041585874366532535
Trained batch 337 in epoch 4, gen_loss = 0.4064759946257405, disc_loss = 0.041710070440457506
Trained batch 338 in epoch 4, gen_loss = 0.40626733791863323, disc_loss = 0.04184340618710119
Trained batch 339 in epoch 4, gen_loss = 0.406272633636699, disc_loss = 0.04195934831137386
Trained batch 340 in epoch 4, gen_loss = 0.4063552765727393, disc_loss = 0.041890929184056534
Trained batch 341 in epoch 4, gen_loss = 0.40612942677492286, disc_loss = 0.04201631506289524
Trained batch 342 in epoch 4, gen_loss = 0.4059796050929467, disc_loss = 0.04207479237081923
Trained batch 343 in epoch 4, gen_loss = 0.4059281220962835, disc_loss = 0.041995154646344394
Trained batch 344 in epoch 4, gen_loss = 0.40574221464170923, disc_loss = 0.041935915312311355
Trained batch 345 in epoch 4, gen_loss = 0.40598521394536674, disc_loss = 0.04194699857260149
Trained batch 346 in epoch 4, gen_loss = 0.4059827889420457, disc_loss = 0.042093960634065036
Trained batch 347 in epoch 4, gen_loss = 0.405815737685938, disc_loss = 0.042341643287372055
Trained batch 348 in epoch 4, gen_loss = 0.40578559237428247, disc_loss = 0.04228721260303968
Trained batch 349 in epoch 4, gen_loss = 0.40577269077301026, disc_loss = 0.04232938769805644
Trained batch 350 in epoch 4, gen_loss = 0.40579455072044307, disc_loss = 0.04233042805712999
Trained batch 351 in epoch 4, gen_loss = 0.4057918603278019, disc_loss = 0.042280141191440634
Trained batch 352 in epoch 4, gen_loss = 0.40582175860999326, disc_loss = 0.04220251536271179
Trained batch 353 in epoch 4, gen_loss = 0.40590248328481016, disc_loss = 0.04212163164711815
Trained batch 354 in epoch 4, gen_loss = 0.4057678080780405, disc_loss = 0.04233555404574309
Trained batch 355 in epoch 4, gen_loss = 0.4057909912440214, disc_loss = 0.042826206382793074
Trained batch 356 in epoch 4, gen_loss = 0.40597894086557273, disc_loss = 0.04273210527083161
Trained batch 357 in epoch 4, gen_loss = 0.40570641363133264, disc_loss = 0.0431841034819398
Trained batch 358 in epoch 4, gen_loss = 0.4057820123052199, disc_loss = 0.044119192682943384
Trained batch 359 in epoch 4, gen_loss = 0.40554459111558067, disc_loss = 0.044262636148939945
Trained batch 360 in epoch 4, gen_loss = 0.40547192542506716, disc_loss = 0.044279263998508206
Trained batch 361 in epoch 4, gen_loss = 0.40555317049527034, disc_loss = 0.04426324561634487
Trained batch 362 in epoch 4, gen_loss = 0.4054427045107545, disc_loss = 0.044382076891339266
Trained batch 363 in epoch 4, gen_loss = 0.4052811055393009, disc_loss = 0.04439355826624516
Trained batch 364 in epoch 4, gen_loss = 0.4055455547489532, disc_loss = 0.044441050868991715
Trained batch 365 in epoch 4, gen_loss = 0.4052831182877223, disc_loss = 0.04454270339713437
Trained batch 366 in epoch 4, gen_loss = 0.40541669295984, disc_loss = 0.044536361888264195
Trained batch 367 in epoch 4, gen_loss = 0.40540860204592993, disc_loss = 0.044462578458478674
Trained batch 368 in epoch 4, gen_loss = 0.4055770306890896, disc_loss = 0.044414662512468533
Trained batch 369 in epoch 4, gen_loss = 0.4053389781230205, disc_loss = 0.04490361127222108
Trained batch 370 in epoch 4, gen_loss = 0.4055000370082187, disc_loss = 0.045385402711384464
Trained batch 371 in epoch 4, gen_loss = 0.40546116913839053, disc_loss = 0.04530654753613416
Trained batch 372 in epoch 4, gen_loss = 0.40532378241140143, disc_loss = 0.04535120969448468
Trained batch 373 in epoch 4, gen_loss = 0.40552564236250793, disc_loss = 0.045490669814949446
Trained batch 374 in epoch 4, gen_loss = 0.40536841622988384, disc_loss = 0.04543946029866735
Trained batch 375 in epoch 4, gen_loss = 0.4051861024283348, disc_loss = 0.04551379604666355
Trained batch 376 in epoch 4, gen_loss = 0.40516258535081573, disc_loss = 0.04545136792733475
Trained batch 377 in epoch 4, gen_loss = 0.40545193795804624, disc_loss = 0.04538712989189046
Trained batch 378 in epoch 4, gen_loss = 0.405476010333265, disc_loss = 0.04538047577728736
Trained batch 379 in epoch 4, gen_loss = 0.4054960279872543, disc_loss = 0.04543333642405311
Trained batch 380 in epoch 4, gen_loss = 0.4054888696495316, disc_loss = 0.04548366953132386
Trained batch 381 in epoch 4, gen_loss = 0.4052534598798652, disc_loss = 0.045472502363455625
Trained batch 382 in epoch 4, gen_loss = 0.40534290017720614, disc_loss = 0.04553352740493557
Trained batch 383 in epoch 4, gen_loss = 0.4051482106248538, disc_loss = 0.045563562759828834
Trained batch 384 in epoch 4, gen_loss = 0.4049701024959614, disc_loss = 0.04550463988917408
Trained batch 385 in epoch 4, gen_loss = 0.40504946324182917, disc_loss = 0.045435238929967266
Trained batch 386 in epoch 4, gen_loss = 0.40502244357298817, disc_loss = 0.04537612054549947
Trained batch 387 in epoch 4, gen_loss = 0.4049927561553483, disc_loss = 0.045474117459758115
Trained batch 388 in epoch 4, gen_loss = 0.40494927265956654, disc_loss = 0.04540241775067001
Trained batch 389 in epoch 4, gen_loss = 0.405002562663494, disc_loss = 0.04533099836956423
Trained batch 390 in epoch 4, gen_loss = 0.4052415744727835, disc_loss = 0.04524021554390526
Trained batch 391 in epoch 4, gen_loss = 0.40524066939037673, disc_loss = 0.04518115573339354
Trained batch 392 in epoch 4, gen_loss = 0.4050793712982391, disc_loss = 0.04511874637971739
Trained batch 393 in epoch 4, gen_loss = 0.4051432756300505, disc_loss = 0.045037988841599846
Trained batch 394 in epoch 4, gen_loss = 0.40530231889290147, disc_loss = 0.04494058833445741
Trained batch 395 in epoch 4, gen_loss = 0.40532703419225385, disc_loss = 0.0448474009636545
Trained batch 396 in epoch 4, gen_loss = 0.40532797432366185, disc_loss = 0.044745594108247334
Trained batch 397 in epoch 4, gen_loss = 0.40552147444169123, disc_loss = 0.04465006068161684
Trained batch 398 in epoch 4, gen_loss = 0.40579623671103837, disc_loss = 0.04459198773430105
Trained batch 399 in epoch 4, gen_loss = 0.4056469777226448, disc_loss = 0.04452634632587433
Trained batch 400 in epoch 4, gen_loss = 0.40565242426948356, disc_loss = 0.04444737810446437
Trained batch 401 in epoch 4, gen_loss = 0.4054681205779166, disc_loss = 0.044394967326922205
Trained batch 402 in epoch 4, gen_loss = 0.4056349403361233, disc_loss = 0.044310193568948775
Trained batch 403 in epoch 4, gen_loss = 0.4058409272739203, disc_loss = 0.04423476350355414
Trained batch 404 in epoch 4, gen_loss = 0.4059033254046499, disc_loss = 0.04414451573457983
Trained batch 405 in epoch 4, gen_loss = 0.40594456054894207, disc_loss = 0.044048949814598844
Trained batch 406 in epoch 4, gen_loss = 0.40584211955785165, disc_loss = 0.0439615175791579
Trained batch 407 in epoch 4, gen_loss = 0.40581389385111194, disc_loss = 0.043880507822477204
Trained batch 408 in epoch 4, gen_loss = 0.4058614015433491, disc_loss = 0.043792545164691644
Trained batch 409 in epoch 4, gen_loss = 0.4056786861361527, disc_loss = 0.043702937430906585
Trained batch 410 in epoch 4, gen_loss = 0.4057784851305096, disc_loss = 0.04364363516062281
Trained batch 411 in epoch 4, gen_loss = 0.40578102284264794, disc_loss = 0.043548500569971296
Trained batch 412 in epoch 4, gen_loss = 0.4056249285437004, disc_loss = 0.04353888371404594
Trained batch 413 in epoch 4, gen_loss = 0.4057931727257328, disc_loss = 0.04379628428397475
Trained batch 414 in epoch 4, gen_loss = 0.40582757714283035, disc_loss = 0.043733183759073896
Trained batch 415 in epoch 4, gen_loss = 0.4058955955104186, disc_loss = 0.043720777171144545
Trained batch 416 in epoch 4, gen_loss = 0.405853488033624, disc_loss = 0.04365766001753598
Trained batch 417 in epoch 4, gen_loss = 0.4059430637428065, disc_loss = 0.043567659244226495
Trained batch 418 in epoch 4, gen_loss = 0.40608238832478305, disc_loss = 0.043540341330598815
Trained batch 419 in epoch 4, gen_loss = 0.40624984013182774, disc_loss = 0.04351476654410362
Trained batch 420 in epoch 4, gen_loss = 0.4062272800827253, disc_loss = 0.04348340042979587
Trained batch 421 in epoch 4, gen_loss = 0.40604368664359597, disc_loss = 0.043708282130024444
Trained batch 422 in epoch 4, gen_loss = 0.4060610155828174, disc_loss = 0.043713923323520816
Trained batch 423 in epoch 4, gen_loss = 0.4061391849141076, disc_loss = 0.0436332814158204
Trained batch 424 in epoch 4, gen_loss = 0.4059471351960126, disc_loss = 0.04356297246673528
Trained batch 425 in epoch 4, gen_loss = 0.40605200267453706, disc_loss = 0.043482638753408416
Trained batch 426 in epoch 4, gen_loss = 0.4059878324596887, disc_loss = 0.043427265445490214
Trained batch 427 in epoch 4, gen_loss = 0.4058870231019002, disc_loss = 0.04340264118259129
Trained batch 428 in epoch 4, gen_loss = 0.4058817683399974, disc_loss = 0.043499209531658874
Trained batch 429 in epoch 4, gen_loss = 0.40583032944867775, disc_loss = 0.0434429812115119
Trained batch 430 in epoch 4, gen_loss = 0.4059043344793076, disc_loss = 0.04336645054196606
Trained batch 431 in epoch 4, gen_loss = 0.40595076764347376, disc_loss = 0.04328908456955105
Trained batch 432 in epoch 4, gen_loss = 0.406092767902665, disc_loss = 0.043211444623028436
Trained batch 433 in epoch 4, gen_loss = 0.4062709967661563, disc_loss = 0.04315812459584618
Trained batch 434 in epoch 4, gen_loss = 0.4062470049008556, disc_loss = 0.043072695562337664
Trained batch 435 in epoch 4, gen_loss = 0.4061945818979806, disc_loss = 0.04306909026163673
Trained batch 436 in epoch 4, gen_loss = 0.4063053117464009, disc_loss = 0.04303241686818767
Trained batch 437 in epoch 4, gen_loss = 0.4064670601800152, disc_loss = 0.04296548515196771
Trained batch 438 in epoch 4, gen_loss = 0.40660034415390606, disc_loss = 0.042901025462369506
Trained batch 439 in epoch 4, gen_loss = 0.4065914208238775, disc_loss = 0.04281553911278024
Trained batch 440 in epoch 4, gen_loss = 0.40663440136952733, disc_loss = 0.042730865835332546
Trained batch 441 in epoch 4, gen_loss = 0.40659957159967985, disc_loss = 0.04265490163336782
Trained batch 442 in epoch 4, gen_loss = 0.40666420458401836, disc_loss = 0.042606417392433094
Trained batch 443 in epoch 4, gen_loss = 0.406671185549852, disc_loss = 0.04252469542054543
Trained batch 444 in epoch 4, gen_loss = 0.40677320823240815, disc_loss = 0.042444710786129984
Trained batch 445 in epoch 4, gen_loss = 0.4067196305423574, disc_loss = 0.042369037669260604
Trained batch 446 in epoch 4, gen_loss = 0.4066463266176399, disc_loss = 0.04228818813605563
Trained batch 447 in epoch 4, gen_loss = 0.40665206213348676, disc_loss = 0.042202925422835894
Trained batch 448 in epoch 4, gen_loss = 0.406536704381484, disc_loss = 0.0421294747407907
Trained batch 449 in epoch 4, gen_loss = 0.40646328051884967, disc_loss = 0.04205132380645308
Trained batch 450 in epoch 4, gen_loss = 0.4064488218655343, disc_loss = 0.041988020293009846
Trained batch 451 in epoch 4, gen_loss = 0.4063858478206449, disc_loss = 0.041908041056888425
Trained batch 452 in epoch 4, gen_loss = 0.40611500350581625, disc_loss = 0.04186703452005752
Trained batch 453 in epoch 4, gen_loss = 0.4060736804018987, disc_loss = 0.041924269088351125
Trained batch 454 in epoch 4, gen_loss = 0.4060357648592729, disc_loss = 0.041877061417223985
Trained batch 455 in epoch 4, gen_loss = 0.40580688501920614, disc_loss = 0.04215567388465595
Trained batch 456 in epoch 4, gen_loss = 0.40590601526934417, disc_loss = 0.04314710339429407
Trained batch 457 in epoch 4, gen_loss = 0.40594573820001695, disc_loss = 0.043185670304978385
Trained batch 458 in epoch 4, gen_loss = 0.4058520900398038, disc_loss = 0.04321088783305
Trained batch 459 in epoch 4, gen_loss = 0.4057431014335674, disc_loss = 0.04319341221783796
Trained batch 460 in epoch 4, gen_loss = 0.4057595197782082, disc_loss = 0.04312019309719899
Trained batch 461 in epoch 4, gen_loss = 0.4056948475636445, disc_loss = 0.04305810351287583
Trained batch 462 in epoch 4, gen_loss = 0.40544059293316453, disc_loss = 0.04319895289588888
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.3428654372692108, disc_loss = 0.12449401617050171
Trained batch 1 in epoch 5, gen_loss = 0.4471439868211746, disc_loss = 0.08758642338216305
Trained batch 2 in epoch 5, gen_loss = 0.4255591730276744, disc_loss = 0.0627139750868082
Trained batch 3 in epoch 5, gen_loss = 0.41003017127513885, disc_loss = 0.051758354995399714
Trained batch 4 in epoch 5, gen_loss = 0.40351983308792116, disc_loss = 0.04579003974795341
Trained batch 5 in epoch 5, gen_loss = 0.39338678618272144, disc_loss = 0.05821882747113705
Trained batch 6 in epoch 5, gen_loss = 0.40152136768613544, disc_loss = 0.0982024504670075
Trained batch 7 in epoch 5, gen_loss = 0.39904141053557396, disc_loss = 0.0925383074209094
Trained batch 8 in epoch 5, gen_loss = 0.39618151386578876, disc_loss = 0.09839128040605122
Trained batch 9 in epoch 5, gen_loss = 0.3992844343185425, disc_loss = 0.0921695128083229
Trained batch 10 in epoch 5, gen_loss = 0.400501164523038, disc_loss = 0.0930122963406823
Trained batch 11 in epoch 5, gen_loss = 0.4036273832122485, disc_loss = 0.08717565579960744
Trained batch 12 in epoch 5, gen_loss = 0.40110562627132124, disc_loss = 0.08130547046088256
Trained batch 13 in epoch 5, gen_loss = 0.3998923216547285, disc_loss = 0.07590840121598116
Trained batch 14 in epoch 5, gen_loss = 0.40039510329564415, disc_loss = 0.07160397497937084
Trained batch 15 in epoch 5, gen_loss = 0.40376419574022293, disc_loss = 0.0676578143320512
Trained batch 16 in epoch 5, gen_loss = 0.40531952942118926, disc_loss = 0.06505819582654272
Trained batch 17 in epoch 5, gen_loss = 0.4049725615315967, disc_loss = 0.06273815074625115
Trained batch 18 in epoch 5, gen_loss = 0.4054898462797466, disc_loss = 0.059666601891972516
Trained batch 19 in epoch 5, gen_loss = 0.4087790310382843, disc_loss = 0.05708709522150457
Trained batch 20 in epoch 5, gen_loss = 0.4074308517433348, disc_loss = 0.05482732469127292
Trained batch 21 in epoch 5, gen_loss = 0.4060349613428116, disc_loss = 0.05342687471685084
Trained batch 22 in epoch 5, gen_loss = 0.40520592098650726, disc_loss = 0.05177440154163734
Trained batch 23 in epoch 5, gen_loss = 0.40360141545534134, disc_loss = 0.05045121597747008
Trained batch 24 in epoch 5, gen_loss = 0.4029562997817993, disc_loss = 0.04956790864467621
Trained batch 25 in epoch 5, gen_loss = 0.40221965312957764, disc_loss = 0.047866463356723
Trained batch 26 in epoch 5, gen_loss = 0.40572616789076066, disc_loss = 0.047704467049765366
Trained batch 27 in epoch 5, gen_loss = 0.40531132157359806, disc_loss = 0.046371171034739485
Trained batch 28 in epoch 5, gen_loss = 0.4035101152699569, disc_loss = 0.04502830248133376
Trained batch 29 in epoch 5, gen_loss = 0.4034021417299906, disc_loss = 0.04373562576559683
Trained batch 30 in epoch 5, gen_loss = 0.4028711722743127, disc_loss = 0.04272684919077062
Trained batch 31 in epoch 5, gen_loss = 0.40350612811744213, disc_loss = 0.04175209558161441
Trained batch 32 in epoch 5, gen_loss = 0.4062783998070341, disc_loss = 0.040679698062101095
Trained batch 33 in epoch 5, gen_loss = 0.4079123796785579, disc_loss = 0.039634925463949054
Trained batch 34 in epoch 5, gen_loss = 0.40935428312846595, disc_loss = 0.03931245014869741
Trained batch 35 in epoch 5, gen_loss = 0.41050056450896794, disc_loss = 0.03864197517072575
Trained batch 36 in epoch 5, gen_loss = 0.40953374231183853, disc_loss = 0.038016244177580684
Trained batch 37 in epoch 5, gen_loss = 0.4095086596514049, disc_loss = 0.03734844840915972
Trained batch 38 in epoch 5, gen_loss = 0.40819946848429167, disc_loss = 0.036539789277296036
Trained batch 39 in epoch 5, gen_loss = 0.40760936960577965, disc_loss = 0.0358525276533328
Trained batch 40 in epoch 5, gen_loss = 0.4092654331428249, disc_loss = 0.035656429452412736
Trained batch 41 in epoch 5, gen_loss = 0.4120206045252936, disc_loss = 0.03492739553829389
Trained batch 42 in epoch 5, gen_loss = 0.4127325588880583, disc_loss = 0.03533130300469523
Trained batch 43 in epoch 5, gen_loss = 0.4143627983602611, disc_loss = 0.034927091783505275
Trained batch 44 in epoch 5, gen_loss = 0.4138764195972019, disc_loss = 0.03497455671636595
Trained batch 45 in epoch 5, gen_loss = 0.4153794866541158, disc_loss = 0.03473737249758257
Trained batch 46 in epoch 5, gen_loss = 0.41531093450302775, disc_loss = 0.03410238615098469
Trained batch 47 in epoch 5, gen_loss = 0.41547216785450775, disc_loss = 0.03356274253261896
Trained batch 48 in epoch 5, gen_loss = 0.4153936803340912, disc_loss = 0.03308609452060595
Trained batch 49 in epoch 5, gen_loss = 0.41499786376953124, disc_loss = 0.03254427370615304
Trained batch 50 in epoch 5, gen_loss = 0.4148762091702106, disc_loss = 0.03211603139289746
Trained batch 51 in epoch 5, gen_loss = 0.41537886227552706, disc_loss = 0.031594459674894236
Trained batch 52 in epoch 5, gen_loss = 0.4151909132048769, disc_loss = 0.031213752828749282
Trained batch 53 in epoch 5, gen_loss = 0.41562720029442396, disc_loss = 0.030714214813930017
Trained batch 54 in epoch 5, gen_loss = 0.4157541795210405, disc_loss = 0.030275896784256805
Trained batch 55 in epoch 5, gen_loss = 0.4158634782901832, disc_loss = 0.029794789393365915
Trained batch 56 in epoch 5, gen_loss = 0.41661847056004037, disc_loss = 0.029708298486902526
Trained batch 57 in epoch 5, gen_loss = 0.4158799149866762, disc_loss = 0.02927875265093713
Trained batch 58 in epoch 5, gen_loss = 0.4151531917563939, disc_loss = 0.02895210092981993
Trained batch 59 in epoch 5, gen_loss = 0.4146850307782491, disc_loss = 0.028588576467397313
Trained batch 60 in epoch 5, gen_loss = 0.4149067460513506, disc_loss = 0.028203975691719622
Trained batch 61 in epoch 5, gen_loss = 0.4151079563363906, disc_loss = 0.027828718595687422
Trained batch 62 in epoch 5, gen_loss = 0.4152206934633709, disc_loss = 0.02753333632080328
Trained batch 63 in epoch 5, gen_loss = 0.41415015887469053, disc_loss = 0.02757374063367024
Trained batch 64 in epoch 5, gen_loss = 0.41484344005584717, disc_loss = 0.02740550866493812
Trained batch 65 in epoch 5, gen_loss = 0.41432458568703046, disc_loss = 0.027726102620363235
Trained batch 66 in epoch 5, gen_loss = 0.41277928227808935, disc_loss = 0.02814518304458305
Trained batch 67 in epoch 5, gen_loss = 0.4130508080124855, disc_loss = 0.027863007915370604
Trained batch 68 in epoch 5, gen_loss = 0.4128035864104395, disc_loss = 0.027580561953178352
Trained batch 69 in epoch 5, gen_loss = 0.41334146644387926, disc_loss = 0.02746371270290443
Trained batch 70 in epoch 5, gen_loss = 0.41330436081953453, disc_loss = 0.027152880540930888
Trained batch 71 in epoch 5, gen_loss = 0.41286471113562584, disc_loss = 0.026898781005810533
Trained batch 72 in epoch 5, gen_loss = 0.41254434397775835, disc_loss = 0.026655245878516812
Trained batch 73 in epoch 5, gen_loss = 0.4128785326674178, disc_loss = 0.02636544990378457
Trained batch 74 in epoch 5, gen_loss = 0.4134068206946055, disc_loss = 0.026071039624512196
Trained batch 75 in epoch 5, gen_loss = 0.4137741727264304, disc_loss = 0.02580548650094945
Trained batch 76 in epoch 5, gen_loss = 0.4142960875065296, disc_loss = 0.02553699307700063
Trained batch 77 in epoch 5, gen_loss = 0.41434905926386517, disc_loss = 0.025266206912839644
Trained batch 78 in epoch 5, gen_loss = 0.4138091481939147, disc_loss = 0.024995114159169076
Trained batch 79 in epoch 5, gen_loss = 0.4130667891353369, disc_loss = 0.02473298803670332
Trained batch 80 in epoch 5, gen_loss = 0.4133408341878726, disc_loss = 0.024970005312359628
Trained batch 81 in epoch 5, gen_loss = 0.41399661433405993, disc_loss = 0.025433878607411937
Trained batch 82 in epoch 5, gen_loss = 0.41444332951522733, disc_loss = 0.02528662341141916
Trained batch 83 in epoch 5, gen_loss = 0.41421769311030704, disc_loss = 0.025338092985163842
Trained batch 84 in epoch 5, gen_loss = 0.4142961372347439, disc_loss = 0.025200593088041335
Trained batch 85 in epoch 5, gen_loss = 0.4147353238144586, disc_loss = 0.02495994362546954
Trained batch 86 in epoch 5, gen_loss = 0.41490557036180603, disc_loss = 0.024869181344221378
Trained batch 87 in epoch 5, gen_loss = 0.41475070267915726, disc_loss = 0.024789861699735575
Trained batch 88 in epoch 5, gen_loss = 0.4147899164242691, disc_loss = 0.024612374289819362
Trained batch 89 in epoch 5, gen_loss = 0.41432901720205945, disc_loss = 0.024520311132073404
Trained batch 90 in epoch 5, gen_loss = 0.41431838470500904, disc_loss = 0.02429938162830505
Trained batch 91 in epoch 5, gen_loss = 0.4154088523076928, disc_loss = 0.024118512605681368
Trained batch 92 in epoch 5, gen_loss = 0.4147365234231436, disc_loss = 0.023949466926115815
Trained batch 93 in epoch 5, gen_loss = 0.4144174272709705, disc_loss = 0.023780348928684882
Trained batch 94 in epoch 5, gen_loss = 0.4142246861206858, disc_loss = 0.023599910299832882
Trained batch 95 in epoch 5, gen_loss = 0.4145008617391189, disc_loss = 0.023413625317819726
Trained batch 96 in epoch 5, gen_loss = 0.41471243242627565, disc_loss = 0.02322392726854719
Trained batch 97 in epoch 5, gen_loss = 0.4133859961008539, disc_loss = 0.023275495606607625
Trained batch 98 in epoch 5, gen_loss = 0.41318279173639083, disc_loss = 0.023565494544766467
Trained batch 99 in epoch 5, gen_loss = 0.41318911880254744, disc_loss = 0.02337444827426225
Trained batch 100 in epoch 5, gen_loss = 0.4123007371874139, disc_loss = 0.023693840844685784
Trained batch 101 in epoch 5, gen_loss = 0.4119153867165248, disc_loss = 0.023988579860979728
Trained batch 102 in epoch 5, gen_loss = 0.4121528004558341, disc_loss = 0.024562403925884407
Trained batch 103 in epoch 5, gen_loss = 0.4119791411436521, disc_loss = 0.024394887781594522
Trained batch 104 in epoch 5, gen_loss = 0.4112276451928275, disc_loss = 0.025117099848354148
Trained batch 105 in epoch 5, gen_loss = 0.41142463262351053, disc_loss = 0.026016998820815165
Trained batch 106 in epoch 5, gen_loss = 0.4120292128803574, disc_loss = 0.02599028889176862
Trained batch 107 in epoch 5, gen_loss = 0.41190280903268744, disc_loss = 0.025859882602364652
Trained batch 108 in epoch 5, gen_loss = 0.4122471954297582, disc_loss = 0.025671446965067485
Trained batch 109 in epoch 5, gen_loss = 0.4121637888930061, disc_loss = 0.025574141143905847
Trained batch 110 in epoch 5, gen_loss = 0.41256901568120663, disc_loss = 0.025499884018187854
Trained batch 111 in epoch 5, gen_loss = 0.412357588697757, disc_loss = 0.025657978852645362
Trained batch 112 in epoch 5, gen_loss = 0.4121372306768873, disc_loss = 0.025889902692947504
Trained batch 113 in epoch 5, gen_loss = 0.41139850255690125, disc_loss = 0.026079191756843215
Trained batch 114 in epoch 5, gen_loss = 0.41107754577761113, disc_loss = 0.02589482741592371
Trained batch 115 in epoch 5, gen_loss = 0.41145081612570533, disc_loss = 0.026181158790332747
Trained batch 116 in epoch 5, gen_loss = 0.41097783864053905, disc_loss = 0.02615849874738572
Trained batch 117 in epoch 5, gen_loss = 0.41063464470839095, disc_loss = 0.026491683895968027
Trained batch 118 in epoch 5, gen_loss = 0.41121891741993044, disc_loss = 0.027610438558891292
Trained batch 119 in epoch 5, gen_loss = 0.41101856852571167, disc_loss = 0.027578503300901502
Trained batch 120 in epoch 5, gen_loss = 0.4103466875789579, disc_loss = 0.027955937395565025
Trained batch 121 in epoch 5, gen_loss = 0.4102383019005666, disc_loss = 0.02916222472186582
Trained batch 122 in epoch 5, gen_loss = 0.4098964040356923, disc_loss = 0.02933503557526605
Trained batch 123 in epoch 5, gen_loss = 0.4094781257933186, disc_loss = 0.02928813009507834
Trained batch 124 in epoch 5, gen_loss = 0.40947502660751345, disc_loss = 0.029199242237955333
Trained batch 125 in epoch 5, gen_loss = 0.4096862311874117, disc_loss = 0.029272582237830476
Trained batch 126 in epoch 5, gen_loss = 0.4096737722242911, disc_loss = 0.02909966795448595
Trained batch 127 in epoch 5, gen_loss = 0.40928298025391996, disc_loss = 0.029208915886556497
Trained batch 128 in epoch 5, gen_loss = 0.40967912752498953, disc_loss = 0.030081077597948702
Trained batch 129 in epoch 5, gen_loss = 0.4085517759506519, disc_loss = 0.03249629666813864
Trained batch 130 in epoch 5, gen_loss = 0.40831248086827404, disc_loss = 0.03599706087048159
Trained batch 131 in epoch 5, gen_loss = 0.40736315060745587, disc_loss = 0.037546924791637466
Trained batch 132 in epoch 5, gen_loss = 0.4071921544863765, disc_loss = 0.03756102588713953
Trained batch 133 in epoch 5, gen_loss = 0.40777209245446905, disc_loss = 0.037613079837982115
Trained batch 134 in epoch 5, gen_loss = 0.4075460010104709, disc_loss = 0.037864007328257517
Trained batch 135 in epoch 5, gen_loss = 0.4078749920077184, disc_loss = 0.0381249084157924
Trained batch 136 in epoch 5, gen_loss = 0.4073949867356433, disc_loss = 0.037991113794192566
Trained batch 137 in epoch 5, gen_loss = 0.40699179319367895, disc_loss = 0.03824073173092219
Trained batch 138 in epoch 5, gen_loss = 0.4074310338754448, disc_loss = 0.03828790531621026
Trained batch 139 in epoch 5, gen_loss = 0.40729185704674037, disc_loss = 0.038135406744134216
Trained batch 140 in epoch 5, gen_loss = 0.4069808245973384, disc_loss = 0.03808551937909731
Trained batch 141 in epoch 5, gen_loss = 0.4070513044864359, disc_loss = 0.03788858887241025
Trained batch 142 in epoch 5, gen_loss = 0.4070128950622532, disc_loss = 0.03767498124755554
Trained batch 143 in epoch 5, gen_loss = 0.40682971932821804, disc_loss = 0.03745502058882266
Trained batch 144 in epoch 5, gen_loss = 0.4068207892878302, disc_loss = 0.0372507875977919
Trained batch 145 in epoch 5, gen_loss = 0.40706993292455806, disc_loss = 0.03711820619614565
Trained batch 146 in epoch 5, gen_loss = 0.4069383195062884, disc_loss = 0.03707195478839939
Trained batch 147 in epoch 5, gen_loss = 0.40681859387739283, disc_loss = 0.0370658948967183
Trained batch 148 in epoch 5, gen_loss = 0.4070693036453836, disc_loss = 0.03705999412692633
Trained batch 149 in epoch 5, gen_loss = 0.4065789089600245, disc_loss = 0.03691042669117451
Trained batch 150 in epoch 5, gen_loss = 0.40699839730136445, disc_loss = 0.03687628570771375
Trained batch 151 in epoch 5, gen_loss = 0.4071152255331215, disc_loss = 0.0366704960378181
Trained batch 152 in epoch 5, gen_loss = 0.4070207061720829, disc_loss = 0.03650672038030975
Trained batch 153 in epoch 5, gen_loss = 0.40669523334348356, disc_loss = 0.036305600490009825
Trained batch 154 in epoch 5, gen_loss = 0.406752428700847, disc_loss = 0.036142818800984855
Trained batch 155 in epoch 5, gen_loss = 0.40699408451716107, disc_loss = 0.035936583881266415
Trained batch 156 in epoch 5, gen_loss = 0.4071638299401399, disc_loss = 0.03576933235155454
Trained batch 157 in epoch 5, gen_loss = 0.4069424275356003, disc_loss = 0.035613832597420375
Trained batch 158 in epoch 5, gen_loss = 0.407120943256894, disc_loss = 0.035444979037527205
Trained batch 159 in epoch 5, gen_loss = 0.4073862604796886, disc_loss = 0.035287268858519384
Trained batch 160 in epoch 5, gen_loss = 0.4075879473123491, disc_loss = 0.03515413553043274
Trained batch 161 in epoch 5, gen_loss = 0.4075115908075262, disc_loss = 0.034988719662421466
Trained batch 162 in epoch 5, gen_loss = 0.4076597494947398, disc_loss = 0.034805603699610096
Trained batch 163 in epoch 5, gen_loss = 0.407418128739043, disc_loss = 0.03465534411881846
Trained batch 164 in epoch 5, gen_loss = 0.40796633326646053, disc_loss = 0.03455501691240705
Trained batch 165 in epoch 5, gen_loss = 0.408047966389771, disc_loss = 0.03437674912085465
Trained batch 166 in epoch 5, gen_loss = 0.4078105472162098, disc_loss = 0.03422939215513493
Trained batch 167 in epoch 5, gen_loss = 0.4082356042095593, disc_loss = 0.03406650776742026
Trained batch 168 in epoch 5, gen_loss = 0.40813445339541465, disc_loss = 0.03389483396812568
Trained batch 169 in epoch 5, gen_loss = 0.40819911430863776, disc_loss = 0.03371600610587527
Trained batch 170 in epoch 5, gen_loss = 0.40820424912268655, disc_loss = 0.033558852480430355
Trained batch 171 in epoch 5, gen_loss = 0.4083450313570888, disc_loss = 0.03343869293065265
Trained batch 172 in epoch 5, gen_loss = 0.40840757926764515, disc_loss = 0.03328098867605359
Trained batch 173 in epoch 5, gen_loss = 0.4084998369216919, disc_loss = 0.03311992343782779
Trained batch 174 in epoch 5, gen_loss = 0.4084348428249359, disc_loss = 0.033055528703012635
Trained batch 175 in epoch 5, gen_loss = 0.40876987237821927, disc_loss = 0.032945933352245695
Trained batch 176 in epoch 5, gen_loss = 0.4091234254298237, disc_loss = 0.03292016687376772
Trained batch 177 in epoch 5, gen_loss = 0.40936134939783075, disc_loss = 0.03292405136777193
Trained batch 178 in epoch 5, gen_loss = 0.40888426190648, disc_loss = 0.032765885679748474
Trained batch 179 in epoch 5, gen_loss = 0.4086908969614241, disc_loss = 0.03271884022073613
Trained batch 180 in epoch 5, gen_loss = 0.4091850410508846, disc_loss = 0.0325788925504775
Trained batch 181 in epoch 5, gen_loss = 0.409425397168149, disc_loss = 0.032431236596184444
Trained batch 182 in epoch 5, gen_loss = 0.40949805968446157, disc_loss = 0.0323028196606154
Trained batch 183 in epoch 5, gen_loss = 0.4091152090417302, disc_loss = 0.032219468555210726
Trained batch 184 in epoch 5, gen_loss = 0.40921676996591927, disc_loss = 0.03212200573368652
Trained batch 185 in epoch 5, gen_loss = 0.4094463320829535, disc_loss = 0.03197991363303636
Trained batch 186 in epoch 5, gen_loss = 0.40967323212700096, disc_loss = 0.031845493628120516
Trained batch 187 in epoch 5, gen_loss = 0.40969042321468924, disc_loss = 0.03171430025596489
Trained batch 188 in epoch 5, gen_loss = 0.40974127899402035, disc_loss = 0.031574917363406965
Trained batch 189 in epoch 5, gen_loss = 0.4098690672924644, disc_loss = 0.03147555796282464
Trained batch 190 in epoch 5, gen_loss = 0.40963339197073934, disc_loss = 0.031340143436088146
Trained batch 191 in epoch 5, gen_loss = 0.40986917400732636, disc_loss = 0.03132944650375672
Trained batch 192 in epoch 5, gen_loss = 0.4094272107657991, disc_loss = 0.03160600699339583
Trained batch 193 in epoch 5, gen_loss = 0.4096356720961246, disc_loss = 0.03151120913944678
Trained batch 194 in epoch 5, gen_loss = 0.4094332076036013, disc_loss = 0.03143067018200572
Trained batch 195 in epoch 5, gen_loss = 0.4097368276240874, disc_loss = 0.03130585977532046
Trained batch 196 in epoch 5, gen_loss = 0.409769971812437, disc_loss = 0.03118302078615061
Trained batch 197 in epoch 5, gen_loss = 0.4098972011395175, disc_loss = 0.031045864717188208
Trained batch 198 in epoch 5, gen_loss = 0.4100023439182109, disc_loss = 0.03091418409214622
Trained batch 199 in epoch 5, gen_loss = 0.41035807609558106, disc_loss = 0.030775219781789927
Trained batch 200 in epoch 5, gen_loss = 0.41034201291663136, disc_loss = 0.030641714625282965
Trained batch 201 in epoch 5, gen_loss = 0.41013825721669905, disc_loss = 0.030592240019710643
Trained batch 202 in epoch 5, gen_loss = 0.40984362128920154, disc_loss = 0.030521616527783166
Trained batch 203 in epoch 5, gen_loss = 0.4096026186849557, disc_loss = 0.03056642114111752
Trained batch 204 in epoch 5, gen_loss = 0.4097151971444851, disc_loss = 0.0304380966077854
Trained batch 205 in epoch 5, gen_loss = 0.4093119674226613, disc_loss = 0.030449925338650503
Trained batch 206 in epoch 5, gen_loss = 0.4095681770412242, disc_loss = 0.03035078580594725
Trained batch 207 in epoch 5, gen_loss = 0.4097378935951453, disc_loss = 0.03027982731313946
Trained batch 208 in epoch 5, gen_loss = 0.4098342292046433, disc_loss = 0.03017557888741841
Trained batch 209 in epoch 5, gen_loss = 0.4097747903494608, disc_loss = 0.030090679183957122
Trained batch 210 in epoch 5, gen_loss = 0.4097080311221534, disc_loss = 0.03001595010442474
Trained batch 211 in epoch 5, gen_loss = 0.4096307740458902, disc_loss = 0.029903394416115194
Trained batch 212 in epoch 5, gen_loss = 0.4094708713007645, disc_loss = 0.02978161922240621
Trained batch 213 in epoch 5, gen_loss = 0.4093493748212529, disc_loss = 0.029660964304163494
Trained batch 214 in epoch 5, gen_loss = 0.4091092147106348, disc_loss = 0.029557254295362982
Trained batch 215 in epoch 5, gen_loss = 0.4093526287211312, disc_loss = 0.029513321963518305
Trained batch 216 in epoch 5, gen_loss = 0.4089277066668058, disc_loss = 0.029826725107802224
Trained batch 217 in epoch 5, gen_loss = 0.408970797007237, disc_loss = 0.030519026724638743
Trained batch 218 in epoch 5, gen_loss = 0.40889597850847464, disc_loss = 0.030566405683551748
Trained batch 219 in epoch 5, gen_loss = 0.40899791040203787, disc_loss = 0.03068980634720488
Trained batch 220 in epoch 5, gen_loss = 0.40946105729400845, disc_loss = 0.030630239846007858
Trained batch 221 in epoch 5, gen_loss = 0.40924628844132294, disc_loss = 0.0306536587592852
Trained batch 222 in epoch 5, gen_loss = 0.4091020169012215, disc_loss = 0.030545808600403804
Trained batch 223 in epoch 5, gen_loss = 0.40895578052316395, disc_loss = 0.03064371711142095
Trained batch 224 in epoch 5, gen_loss = 0.4090124050776164, disc_loss = 0.03058847171564897
Trained batch 225 in epoch 5, gen_loss = 0.40899461468236636, disc_loss = 0.030602806527991737
Trained batch 226 in epoch 5, gen_loss = 0.4089511059191784, disc_loss = 0.03062477521598339
Trained batch 227 in epoch 5, gen_loss = 0.40859265703904, disc_loss = 0.030534790493874697
Trained batch 228 in epoch 5, gen_loss = 0.40929191992272457, disc_loss = 0.03045549655259957
Trained batch 229 in epoch 5, gen_loss = 0.40910857747430385, disc_loss = 0.030387652908330377
Trained batch 230 in epoch 5, gen_loss = 0.40881277498228724, disc_loss = 0.030298726883156477
Trained batch 231 in epoch 5, gen_loss = 0.40884912309461624, disc_loss = 0.030219520169213927
Trained batch 232 in epoch 5, gen_loss = 0.4088343716997957, disc_loss = 0.030110742497086014
Trained batch 233 in epoch 5, gen_loss = 0.40876973006460404, disc_loss = 0.030021976731303666
Trained batch 234 in epoch 5, gen_loss = 0.40845958818780614, disc_loss = 0.02998077125546146
Trained batch 235 in epoch 5, gen_loss = 0.4086068522627071, disc_loss = 0.029941232058109116
Trained batch 236 in epoch 5, gen_loss = 0.4085614962919855, disc_loss = 0.02985222311493968
Trained batch 237 in epoch 5, gen_loss = 0.4085164112704141, disc_loss = 0.029769943440098222
Trained batch 238 in epoch 5, gen_loss = 0.4083610917733803, disc_loss = 0.029688762204729362
Trained batch 239 in epoch 5, gen_loss = 0.40852247141301634, disc_loss = 0.029610944958403707
Trained batch 240 in epoch 5, gen_loss = 0.4086339304308674, disc_loss = 0.029503451071919186
Trained batch 241 in epoch 5, gen_loss = 0.4088028931666997, disc_loss = 0.02939999008778298
Trained batch 242 in epoch 5, gen_loss = 0.408708838646304, disc_loss = 0.029316582313619954
Trained batch 243 in epoch 5, gen_loss = 0.40876191011706337, disc_loss = 0.029234144454020398
Trained batch 244 in epoch 5, gen_loss = 0.4088424428385131, disc_loss = 0.029141380477278513
Trained batch 245 in epoch 5, gen_loss = 0.4087346255536971, disc_loss = 0.029042092209674297
Trained batch 246 in epoch 5, gen_loss = 0.4089514480428657, disc_loss = 0.028968512564181134
Trained batch 247 in epoch 5, gen_loss = 0.4092330407471426, disc_loss = 0.02890024772533516
Trained batch 248 in epoch 5, gen_loss = 0.409185305058238, disc_loss = 0.028808664729684054
Trained batch 249 in epoch 5, gen_loss = 0.40922765409946443, disc_loss = 0.028775208418257533
Trained batch 250 in epoch 5, gen_loss = 0.4092696740095359, disc_loss = 0.028718738275880656
Trained batch 251 in epoch 5, gen_loss = 0.4094602721078055, disc_loss = 0.028627280069197278
Trained batch 252 in epoch 5, gen_loss = 0.4092825453271979, disc_loss = 0.028541654592247407
Trained batch 253 in epoch 5, gen_loss = 0.40927404059669165, disc_loss = 0.028473669025995657
Trained batch 254 in epoch 5, gen_loss = 0.4093269316589131, disc_loss = 0.02837878370054943
Trained batch 255 in epoch 5, gen_loss = 0.4092038460075855, disc_loss = 0.02829115828990325
Trained batch 256 in epoch 5, gen_loss = 0.4093833438153397, disc_loss = 0.028226298659655775
Trained batch 257 in epoch 5, gen_loss = 0.40957223029099693, disc_loss = 0.028139113785171983
Trained batch 258 in epoch 5, gen_loss = 0.4094642736736872, disc_loss = 0.028046030417250102
Trained batch 259 in epoch 5, gen_loss = 0.40951183140277864, disc_loss = 0.027970325032499833
Trained batch 260 in epoch 5, gen_loss = 0.40956177839374175, disc_loss = 0.027875695074283984
Trained batch 261 in epoch 5, gen_loss = 0.40948087090754326, disc_loss = 0.02778772150258754
Trained batch 262 in epoch 5, gen_loss = 0.4093094706082072, disc_loss = 0.02769926808838212
Trained batch 263 in epoch 5, gen_loss = 0.4093121142324173, disc_loss = 0.027618489967249898
Trained batch 264 in epoch 5, gen_loss = 0.4092625767554877, disc_loss = 0.02754470425359202
Trained batch 265 in epoch 5, gen_loss = 0.40904026069587335, disc_loss = 0.027499832085130693
Trained batch 266 in epoch 5, gen_loss = 0.40882762965191616, disc_loss = 0.027409103227263032
Trained batch 267 in epoch 5, gen_loss = 0.409143023748896, disc_loss = 0.027361954450294542
Trained batch 268 in epoch 5, gen_loss = 0.40924787554599096, disc_loss = 0.027276069447779026
Trained batch 269 in epoch 5, gen_loss = 0.40926210670559493, disc_loss = 0.027194585477829807
Trained batch 270 in epoch 5, gen_loss = 0.4092636009423935, disc_loss = 0.027108597034774033
Trained batch 271 in epoch 5, gen_loss = 0.4095133469604394, disc_loss = 0.027038001275607657
Trained batch 272 in epoch 5, gen_loss = 0.409533726863372, disc_loss = 0.02696731968376881
Trained batch 273 in epoch 5, gen_loss = 0.40955350455576484, disc_loss = 0.02687955716366533
Trained batch 274 in epoch 5, gen_loss = 0.40983871644193476, disc_loss = 0.026814509054476566
Trained batch 275 in epoch 5, gen_loss = 0.4098563320610834, disc_loss = 0.026732081020979778
Trained batch 276 in epoch 5, gen_loss = 0.4099996067341484, disc_loss = 0.026675644270161215
Trained batch 277 in epoch 5, gen_loss = 0.41007523731790857, disc_loss = 0.02659578389226854
Trained batch 278 in epoch 5, gen_loss = 0.4097088186544329, disc_loss = 0.02652466156783657
Trained batch 279 in epoch 5, gen_loss = 0.40983173102140424, disc_loss = 0.026446308403475477
Trained batch 280 in epoch 5, gen_loss = 0.4096236150459887, disc_loss = 0.02636665321084475
Trained batch 281 in epoch 5, gen_loss = 0.40958659424849436, disc_loss = 0.02629588733605565
Trained batch 282 in epoch 5, gen_loss = 0.4095078756236356, disc_loss = 0.026224201992680666
Trained batch 283 in epoch 5, gen_loss = 0.4093237957904037, disc_loss = 0.026159407197117384
Trained batch 284 in epoch 5, gen_loss = 0.4093674699465434, disc_loss = 0.02609618402886809
Trained batch 285 in epoch 5, gen_loss = 0.4093572373365189, disc_loss = 0.02602241220200187
Trained batch 286 in epoch 5, gen_loss = 0.4092879164509657, disc_loss = 0.025955689897377836
Trained batch 287 in epoch 5, gen_loss = 0.4093005996611383, disc_loss = 0.02593962830239131
Trained batch 288 in epoch 5, gen_loss = 0.4092645566768712, disc_loss = 0.025897880324894065
Trained batch 289 in epoch 5, gen_loss = 0.40947708569723984, disc_loss = 0.025865976568632598
Trained batch 290 in epoch 5, gen_loss = 0.4096521698322493, disc_loss = 0.02581325662562374
Trained batch 291 in epoch 5, gen_loss = 0.40950538391528063, disc_loss = 0.02575335736635256
Trained batch 292 in epoch 5, gen_loss = 0.40986860886775595, disc_loss = 0.025679702439850814
Trained batch 293 in epoch 5, gen_loss = 0.4098140566932912, disc_loss = 0.025608102851198848
Trained batch 294 in epoch 5, gen_loss = 0.40992621223805314, disc_loss = 0.025533483455241736
Trained batch 295 in epoch 5, gen_loss = 0.40972265631363197, disc_loss = 0.025468078583504097
Trained batch 296 in epoch 5, gen_loss = 0.40983195959116875, disc_loss = 0.025393414670156208
Trained batch 297 in epoch 5, gen_loss = 0.4098658063667733, disc_loss = 0.02531966657202766
Trained batch 298 in epoch 5, gen_loss = 0.40968735600793643, disc_loss = 0.025247533343900556
Trained batch 299 in epoch 5, gen_loss = 0.4096285504102707, disc_loss = 0.025179532389932622
Trained batch 300 in epoch 5, gen_loss = 0.4097520676364138, disc_loss = 0.025110084123358724
Trained batch 301 in epoch 5, gen_loss = 0.40971836506925674, disc_loss = 0.02504760572387658
Trained batch 302 in epoch 5, gen_loss = 0.40972826465128276, disc_loss = 0.024977254678983943
Trained batch 303 in epoch 5, gen_loss = 0.4097224268081941, disc_loss = 0.024915393776609562
Trained batch 304 in epoch 5, gen_loss = 0.4100498346031689, disc_loss = 0.024853564750739052
Trained batch 305 in epoch 5, gen_loss = 0.4098917699717229, disc_loss = 0.024782982294210325
Trained batch 306 in epoch 5, gen_loss = 0.40975800243961696, disc_loss = 0.024728486519185553
Trained batch 307 in epoch 5, gen_loss = 0.4098092917498056, disc_loss = 0.02467120293521794
Trained batch 308 in epoch 5, gen_loss = 0.4097551134411957, disc_loss = 0.024603294481411818
Trained batch 309 in epoch 5, gen_loss = 0.40963038859828826, disc_loss = 0.024533248267647238
Trained batch 310 in epoch 5, gen_loss = 0.4096486311633487, disc_loss = 0.02446708584599604
Trained batch 311 in epoch 5, gen_loss = 0.4095602548466279, disc_loss = 0.024422264808657557
Trained batch 312 in epoch 5, gen_loss = 0.40939472268183774, disc_loss = 0.02435485984514149
Trained batch 313 in epoch 5, gen_loss = 0.40971054402506274, disc_loss = 0.02428934442481489
Trained batch 314 in epoch 5, gen_loss = 0.409768654713555, disc_loss = 0.024221838378746596
Trained batch 315 in epoch 5, gen_loss = 0.40996338974071456, disc_loss = 0.024156490445455325
Trained batch 316 in epoch 5, gen_loss = 0.4100886663239837, disc_loss = 0.024115558923736263
Trained batch 317 in epoch 5, gen_loss = 0.40995472810178435, disc_loss = 0.02405326402418128
Trained batch 318 in epoch 5, gen_loss = 0.41011136546030313, disc_loss = 0.023995566609546215
Trained batch 319 in epoch 5, gen_loss = 0.41018968671560285, disc_loss = 0.023948952845239548
Trained batch 320 in epoch 5, gen_loss = 0.4103160630505404, disc_loss = 0.023919652632475363
Trained batch 321 in epoch 5, gen_loss = 0.4104976283837549, disc_loss = 0.023897905193373377
Trained batch 322 in epoch 5, gen_loss = 0.41069641137270735, disc_loss = 0.02383266618163916
Trained batch 323 in epoch 5, gen_loss = 0.4108030883434378, disc_loss = 0.023785108003339925
Trained batch 324 in epoch 5, gen_loss = 0.4106581358726208, disc_loss = 0.023720827104810337
Trained batch 325 in epoch 5, gen_loss = 0.41046789937589795, disc_loss = 0.02366121514611792
Trained batch 326 in epoch 5, gen_loss = 0.4103197228471073, disc_loss = 0.023599989290010264
Trained batch 327 in epoch 5, gen_loss = 0.41040472204728823, disc_loss = 0.02354585951571807
Trained batch 328 in epoch 5, gen_loss = 0.4104125475267509, disc_loss = 0.023485182953636108
Trained batch 329 in epoch 5, gen_loss = 0.41032230158646904, disc_loss = 0.023426372970623725
Trained batch 330 in epoch 5, gen_loss = 0.4103270670978684, disc_loss = 0.023366651161548506
Trained batch 331 in epoch 5, gen_loss = 0.4102310871323907, disc_loss = 0.023318837962045997
Trained batch 332 in epoch 5, gen_loss = 0.4100661454079029, disc_loss = 0.023259770362875663
Trained batch 333 in epoch 5, gen_loss = 0.4100452799818473, disc_loss = 0.0232076651338644
Trained batch 334 in epoch 5, gen_loss = 0.41028439295825675, disc_loss = 0.02315765085227009
Trained batch 335 in epoch 5, gen_loss = 0.41017110734468415, disc_loss = 0.02310037687337691
Trained batch 336 in epoch 5, gen_loss = 0.4101559558678805, disc_loss = 0.023041600125181305
Trained batch 337 in epoch 5, gen_loss = 0.4098950388163505, disc_loss = 0.02300286100014559
Trained batch 338 in epoch 5, gen_loss = 0.40993200396366175, disc_loss = 0.023048228602087165
Trained batch 339 in epoch 5, gen_loss = 0.40992797350182253, disc_loss = 0.023003304908599923
Trained batch 340 in epoch 5, gen_loss = 0.40999417535720334, disc_loss = 0.023043784616061668
Trained batch 341 in epoch 5, gen_loss = 0.41001708012575294, disc_loss = 0.022996157847551837
Trained batch 342 in epoch 5, gen_loss = 0.410231216742763, disc_loss = 0.022990804305435878
Trained batch 343 in epoch 5, gen_loss = 0.4103830540769322, disc_loss = 0.02293611260612907
Trained batch 344 in epoch 5, gen_loss = 0.4105435297972914, disc_loss = 0.022882207435812207
Trained batch 345 in epoch 5, gen_loss = 0.41037542377248665, disc_loss = 0.0228353503948842
Trained batch 346 in epoch 5, gen_loss = 0.4101729735689136, disc_loss = 0.022778739596472822
Trained batch 347 in epoch 5, gen_loss = 0.41008927073629425, disc_loss = 0.022733084838061284
Trained batch 348 in epoch 5, gen_loss = 0.4101638864821896, disc_loss = 0.022697360147415184
Trained batch 349 in epoch 5, gen_loss = 0.410227267571858, disc_loss = 0.022655656270549766
Trained batch 350 in epoch 5, gen_loss = 0.41022738975677053, disc_loss = 0.02259955652511846
Trained batch 351 in epoch 5, gen_loss = 0.4102521265264262, disc_loss = 0.022546261037033135
Trained batch 352 in epoch 5, gen_loss = 0.41024564616065523, disc_loss = 0.022493090146820115
Trained batch 353 in epoch 5, gen_loss = 0.4102199567576586, disc_loss = 0.02245857855857555
Trained batch 354 in epoch 5, gen_loss = 0.41034074820263283, disc_loss = 0.022428390649999953
Trained batch 355 in epoch 5, gen_loss = 0.41042456524760534, disc_loss = 0.02237670442607421
Trained batch 356 in epoch 5, gen_loss = 0.41056416106491195, disc_loss = 0.02233245223760605
Trained batch 357 in epoch 5, gen_loss = 0.4105683088136119, disc_loss = 0.022290938273696593
Trained batch 358 in epoch 5, gen_loss = 0.4103391092467773, disc_loss = 0.022246056469805892
Trained batch 359 in epoch 5, gen_loss = 0.41034034457471635, disc_loss = 0.022234359132643374
Trained batch 360 in epoch 5, gen_loss = 0.41052132382617434, disc_loss = 0.022342344666018546
Trained batch 361 in epoch 5, gen_loss = 0.4104348654081808, disc_loss = 0.02229791320860386
Trained batch 362 in epoch 5, gen_loss = 0.41023303211227924, disc_loss = 0.02236570542057355
Trained batch 363 in epoch 5, gen_loss = 0.41031683080798975, disc_loss = 0.022345674382829733
Trained batch 364 in epoch 5, gen_loss = 0.41039931912944744, disc_loss = 0.02236292134102893
Trained batch 365 in epoch 5, gen_loss = 0.4102649911016714, disc_loss = 0.022428067273821663
Trained batch 366 in epoch 5, gen_loss = 0.41031940537187644, disc_loss = 0.02242511983869511
Trained batch 367 in epoch 5, gen_loss = 0.41061688805727853, disc_loss = 0.022483254458917225
Trained batch 368 in epoch 5, gen_loss = 0.410437208607914, disc_loss = 0.022529188997861816
Trained batch 369 in epoch 5, gen_loss = 0.4102555119508022, disc_loss = 0.022857201441719724
Trained batch 370 in epoch 5, gen_loss = 0.4102937266672397, disc_loss = 0.02337729286231763
Trained batch 371 in epoch 5, gen_loss = 0.41001732567305205, disc_loss = 0.023427270182598662
Trained batch 372 in epoch 5, gen_loss = 0.40996007825030717, disc_loss = 0.023465577712726976
Trained batch 373 in epoch 5, gen_loss = 0.40991224515884317, disc_loss = 0.023633970027381088
Trained batch 374 in epoch 5, gen_loss = 0.4096894418398539, disc_loss = 0.024330948720375698
Trained batch 375 in epoch 5, gen_loss = 0.4094959652011699, disc_loss = 0.024914540082929617
Trained batch 376 in epoch 5, gen_loss = 0.4094896938661682, disc_loss = 0.026366835613228598
Trained batch 377 in epoch 5, gen_loss = 0.4092957654958049, disc_loss = 0.02711280065751265
Trained batch 378 in epoch 5, gen_loss = 0.4088794615778256, disc_loss = 0.028114130017703944
Trained batch 379 in epoch 5, gen_loss = 0.4088900851575952, disc_loss = 0.02920922986966999
Trained batch 380 in epoch 5, gen_loss = 0.4087337526905881, disc_loss = 0.030056488844431604
Trained batch 381 in epoch 5, gen_loss = 0.4085419490075236, disc_loss = 0.030652503975476895
Trained batch 382 in epoch 5, gen_loss = 0.40822217156308127, disc_loss = 0.030989454762509226
Trained batch 383 in epoch 5, gen_loss = 0.4081147617350022, disc_loss = 0.03130569670853826
Trained batch 384 in epoch 5, gen_loss = 0.40800749388608065, disc_loss = 0.03149084492356746
Trained batch 385 in epoch 5, gen_loss = 0.40771383587560506, disc_loss = 0.031576981555689804
Trained batch 386 in epoch 5, gen_loss = 0.4076174791007079, disc_loss = 0.03159514753970989
Trained batch 387 in epoch 5, gen_loss = 0.4075844202613093, disc_loss = 0.031615149306575045
Trained batch 388 in epoch 5, gen_loss = 0.40743112295942624, disc_loss = 0.031599518246852955
Trained batch 389 in epoch 5, gen_loss = 0.407296956043977, disc_loss = 0.031548307645015226
Trained batch 390 in epoch 5, gen_loss = 0.40711493450967245, disc_loss = 0.03151678774610657
Trained batch 391 in epoch 5, gen_loss = 0.4069509307796858, disc_loss = 0.03148182518590165
Trained batch 392 in epoch 5, gen_loss = 0.40698124957448656, disc_loss = 0.031453253488049254
Trained batch 393 in epoch 5, gen_loss = 0.40705376001178917, disc_loss = 0.03150585276750743
Trained batch 394 in epoch 5, gen_loss = 0.40698948487450803, disc_loss = 0.03159102478736563
Trained batch 395 in epoch 5, gen_loss = 0.406829490580342, disc_loss = 0.03229982336286945
Trained batch 396 in epoch 5, gen_loss = 0.40692776096257516, disc_loss = 0.033363254285729504
Trained batch 397 in epoch 5, gen_loss = 0.40697943857267277, disc_loss = 0.033825817400935904
Trained batch 398 in epoch 5, gen_loss = 0.4067290705397613, disc_loss = 0.03446195879600998
Trained batch 399 in epoch 5, gen_loss = 0.40649377010762694, disc_loss = 0.03498813366517425
Trained batch 400 in epoch 5, gen_loss = 0.4063673849563646, disc_loss = 0.03526130331647664
Trained batch 401 in epoch 5, gen_loss = 0.4062754241981317, disc_loss = 0.035350418153835175
Trained batch 402 in epoch 5, gen_loss = 0.40613201415864175, disc_loss = 0.03541528964160985
Trained batch 403 in epoch 5, gen_loss = 0.4060336105009117, disc_loss = 0.035463708074818745
Trained batch 404 in epoch 5, gen_loss = 0.4058635902993473, disc_loss = 0.035514311952355465
Trained batch 405 in epoch 5, gen_loss = 0.40578867825381276, disc_loss = 0.03564513184754132
Trained batch 406 in epoch 5, gen_loss = 0.40570013463057814, disc_loss = 0.03579538335671296
Trained batch 407 in epoch 5, gen_loss = 0.4055779655190075, disc_loss = 0.03597775209402921
Trained batch 408 in epoch 5, gen_loss = 0.4054944527615545, disc_loss = 0.03636197773124886
Trained batch 409 in epoch 5, gen_loss = 0.40532953971769753, disc_loss = 0.03662307362367467
Trained batch 410 in epoch 5, gen_loss = 0.4053881922487505, disc_loss = 0.036582059614414714
Trained batch 411 in epoch 5, gen_loss = 0.40546416831248017, disc_loss = 0.036620962786153684
Trained batch 412 in epoch 5, gen_loss = 0.4053818188048448, disc_loss = 0.03660718612282674
Trained batch 413 in epoch 5, gen_loss = 0.405309683314844, disc_loss = 0.03657388190428416
Trained batch 414 in epoch 5, gen_loss = 0.4054710179208273, disc_loss = 0.03650988317263055
Trained batch 415 in epoch 5, gen_loss = 0.4056318379365481, disc_loss = 0.036438843379773274
Trained batch 416 in epoch 5, gen_loss = 0.4056630970762788, disc_loss = 0.036374113032241445
Trained batch 417 in epoch 5, gen_loss = 0.4054266567292966, disc_loss = 0.03631049500105448
Trained batch 418 in epoch 5, gen_loss = 0.4055017502467217, disc_loss = 0.036251309960147006
Trained batch 419 in epoch 5, gen_loss = 0.405510160114084, disc_loss = 0.03619470260039504
Trained batch 420 in epoch 5, gen_loss = 0.4055298877583547, disc_loss = 0.03614293431615426
Trained batch 421 in epoch 5, gen_loss = 0.4055831087002822, disc_loss = 0.03608570068796558
Trained batch 422 in epoch 5, gen_loss = 0.4053962443455455, disc_loss = 0.03603528329142618
Trained batch 423 in epoch 5, gen_loss = 0.40551433480292, disc_loss = 0.03600597139206311
Trained batch 424 in epoch 5, gen_loss = 0.40545140988686507, disc_loss = 0.035947662356364374
Trained batch 425 in epoch 5, gen_loss = 0.40543999897202415, disc_loss = 0.03589142565265683
Trained batch 426 in epoch 5, gen_loss = 0.4055349426889308, disc_loss = 0.03584781424436866
Trained batch 427 in epoch 5, gen_loss = 0.4053597480197933, disc_loss = 0.0358020372908545
Trained batch 428 in epoch 5, gen_loss = 0.40547853492912433, disc_loss = 0.03584201844183333
Trained batch 429 in epoch 5, gen_loss = 0.4053464618533157, disc_loss = 0.03581015373320254
Trained batch 430 in epoch 5, gen_loss = 0.405154622762773, disc_loss = 0.035761250015521065
Trained batch 431 in epoch 5, gen_loss = 0.4051457833222769, disc_loss = 0.03570795088415724
Trained batch 432 in epoch 5, gen_loss = 0.4051159720084959, disc_loss = 0.035637430966063886
Trained batch 433 in epoch 5, gen_loss = 0.40503283957457215, disc_loss = 0.03558667061940556
Trained batch 434 in epoch 5, gen_loss = 0.4050359865714764, disc_loss = 0.03553076417816953
Trained batch 435 in epoch 5, gen_loss = 0.40492398517394285, disc_loss = 0.035493752087141735
Trained batch 436 in epoch 5, gen_loss = 0.405051331839245, disc_loss = 0.03543587433157203
Trained batch 437 in epoch 5, gen_loss = 0.40501086420664506, disc_loss = 0.03538361384924586
Trained batch 438 in epoch 5, gen_loss = 0.4051121700733289, disc_loss = 0.03533378213427638
Trained batch 439 in epoch 5, gen_loss = 0.40515920499509034, disc_loss = 0.035365773454858834
Trained batch 440 in epoch 5, gen_loss = 0.40489989350171857, disc_loss = 0.036135686891968624
Trained batch 441 in epoch 5, gen_loss = 0.4048483991380191, disc_loss = 0.03700073352146776
Trained batch 442 in epoch 5, gen_loss = 0.40471235502923314, disc_loss = 0.03712574426719654
Trained batch 443 in epoch 5, gen_loss = 0.40437427330929954, disc_loss = 0.03733547060930816
Trained batch 444 in epoch 5, gen_loss = 0.4042890872848168, disc_loss = 0.037423006609458936
Trained batch 445 in epoch 5, gen_loss = 0.4042189534202285, disc_loss = 0.037427495167937315
Trained batch 446 in epoch 5, gen_loss = 0.403888383701077, disc_loss = 0.03750497176597349
Trained batch 447 in epoch 5, gen_loss = 0.40394568050812396, disc_loss = 0.03754273497387268
Trained batch 448 in epoch 5, gen_loss = 0.4038911035039643, disc_loss = 0.037579738795300965
Trained batch 449 in epoch 5, gen_loss = 0.40385517934958143, disc_loss = 0.03763597400341597
Trained batch 450 in epoch 5, gen_loss = 0.4038783576826827, disc_loss = 0.03763458542959422
Trained batch 451 in epoch 5, gen_loss = 0.4041274209069995, disc_loss = 0.03765134253452606
Trained batch 452 in epoch 5, gen_loss = 0.4039821391863539, disc_loss = 0.03766079944050634
Trained batch 453 in epoch 5, gen_loss = 0.4039639759693902, disc_loss = 0.03762050508111223
Trained batch 454 in epoch 5, gen_loss = 0.4039105176925659, disc_loss = 0.0375679869153588
Trained batch 455 in epoch 5, gen_loss = 0.40394582011197744, disc_loss = 0.037508525202467446
Trained batch 456 in epoch 5, gen_loss = 0.40394158495072463, disc_loss = 0.03745076791393515
Trained batch 457 in epoch 5, gen_loss = 0.4040126016436706, disc_loss = 0.03740090514760969
Trained batch 458 in epoch 5, gen_loss = 0.4039824015434531, disc_loss = 0.0373324177122405
Trained batch 459 in epoch 5, gen_loss = 0.40398169658754185, disc_loss = 0.037282463735090976
Trained batch 460 in epoch 5, gen_loss = 0.4038710883796344, disc_loss = 0.03730349128443643
Trained batch 461 in epoch 5, gen_loss = 0.4040417116441768, disc_loss = 0.037742227014533176
Trained batch 462 in epoch 5, gen_loss = 0.40364078459677893, disc_loss = 0.03774349784607281
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.2790115773677826, disc_loss = 0.21942466497421265
Trained batch 1 in epoch 6, gen_loss = 0.37332580983638763, disc_loss = 0.1198071101680398
Trained batch 2 in epoch 6, gen_loss = 0.38340307275454205, disc_loss = 0.09508665464818478
Trained batch 3 in epoch 6, gen_loss = 0.38364797830581665, disc_loss = 0.07300987292546779
Trained batch 4 in epoch 6, gen_loss = 0.38399508595466614, disc_loss = 0.0650980913080275
Trained batch 5 in epoch 6, gen_loss = 0.38329219321409863, disc_loss = 0.05629110188844303
Trained batch 6 in epoch 6, gen_loss = 0.3879056785787855, disc_loss = 0.05241499954302396
Trained batch 7 in epoch 6, gen_loss = 0.3953538089990616, disc_loss = 0.046551032399293035
Trained batch 8 in epoch 6, gen_loss = 0.40268827146954006, disc_loss = 0.043104450373599924
Trained batch 9 in epoch 6, gen_loss = 0.4109875589609146, disc_loss = 0.03980590985156596
Trained batch 10 in epoch 6, gen_loss = 0.4151784506711093, disc_loss = 0.03650472867725925
Trained batch 11 in epoch 6, gen_loss = 0.41690437495708466, disc_loss = 0.03390268434304744
Trained batch 12 in epoch 6, gen_loss = 0.417933830848107, disc_loss = 0.0315581036086839
Trained batch 13 in epoch 6, gen_loss = 0.4177648254803249, disc_loss = 0.029761343163305094
Trained batch 14 in epoch 6, gen_loss = 0.4196374734242757, disc_loss = 0.02842269530519843
Trained batch 15 in epoch 6, gen_loss = 0.42115413025021553, disc_loss = 0.027192227280465886
Trained batch 16 in epoch 6, gen_loss = 0.4206353303264169, disc_loss = 0.02602380856542903
Trained batch 17 in epoch 6, gen_loss = 0.4193022284242842, disc_loss = 0.024760839244764712
Trained batch 18 in epoch 6, gen_loss = 0.4184428312276539, disc_loss = 0.02375791302735084
Trained batch 19 in epoch 6, gen_loss = 0.4180454686284065, disc_loss = 0.02274325306061655
Trained batch 20 in epoch 6, gen_loss = 0.41183158329554964, disc_loss = 0.02184800495437923
Trained batch 21 in epoch 6, gen_loss = 0.412903368473053, disc_loss = 0.021123768761754036
Trained batch 22 in epoch 6, gen_loss = 0.41481211004049884, disc_loss = 0.020569739944261055
Trained batch 23 in epoch 6, gen_loss = 0.4128412182132403, disc_loss = 0.019877289635284495
Trained batch 24 in epoch 6, gen_loss = 0.41231173753738404, disc_loss = 0.01919949097558856
Trained batch 26 in epoch 6, gen_loss = 0.41159073842896354, disc_loss = 0.01834759662893635
Trained batch 27 in epoch 6, gen_loss = 0.41165262141398024, disc_loss = 0.017936651594936848
Trained batch 28 in epoch 6, gen_loss = 0.4106232513641489, disc_loss = 0.017426969057976686
Trained batch 29 in epoch 6, gen_loss = 0.4085138668616613, disc_loss = 0.01691833989849935
Trained batch 30 in epoch 6, gen_loss = 0.4072228112528401, disc_loss = 0.016460493184445847
Trained batch 31 in epoch 6, gen_loss = 0.4061825070530176, disc_loss = 0.016020863804442342
Trained batch 32 in epoch 6, gen_loss = 0.40537197481502185, disc_loss = 0.015710480236025018
Trained batch 33 in epoch 6, gen_loss = 0.40692035415593314, disc_loss = 0.015343957635409692
Trained batch 34 in epoch 6, gen_loss = 0.40571505767958504, disc_loss = 0.014986962638795375
Trained batch 35 in epoch 6, gen_loss = 0.4048968412809902, disc_loss = 0.014636824722401798
Trained batch 36 in epoch 6, gen_loss = 0.4034836541961979, disc_loss = 0.014296577110685207
Trained batch 37 in epoch 6, gen_loss = 0.4034341636456941, disc_loss = 0.014023564339272286
Trained batch 38 in epoch 6, gen_loss = 0.40182394629869705, disc_loss = 0.013793605367820233
Trained batch 39 in epoch 6, gen_loss = 0.40365024134516714, disc_loss = 0.013563123706262559
Trained batch 40 in epoch 6, gen_loss = 0.403115476050028, disc_loss = 0.013390624214236329
Trained batch 41 in epoch 6, gen_loss = 0.402994169365792, disc_loss = 0.013177845383151657
Trained batch 42 in epoch 6, gen_loss = 0.40280450845873633, disc_loss = 0.013010051058128823
Trained batch 43 in epoch 6, gen_loss = 0.40286029197952966, disc_loss = 0.012814514360136607
Trained batch 44 in epoch 6, gen_loss = 0.4034066836039225, disc_loss = 0.012672819155785773
Trained batch 45 in epoch 6, gen_loss = 0.40353905441968335, disc_loss = 0.012453851553247026
Trained batch 46 in epoch 6, gen_loss = 0.4035230557969276, disc_loss = 0.012243004372105636
Trained batch 47 in epoch 6, gen_loss = 0.4033246462543805, disc_loss = 0.012047215544347031
Trained batch 48 in epoch 6, gen_loss = 0.4035961536728606, disc_loss = 0.011909755626313237
Trained batch 49 in epoch 6, gen_loss = 0.4038987421989441, disc_loss = 0.011930554243735968
Trained batch 50 in epoch 6, gen_loss = 0.40413109286158694, disc_loss = 0.011739477638483924
Trained batch 51 in epoch 6, gen_loss = 0.40401670852532756, disc_loss = 0.011582110981600216
Trained batch 52 in epoch 6, gen_loss = 0.4049345440459701, disc_loss = 0.01140757470022676
Trained batch 53 in epoch 6, gen_loss = 0.4042679441195947, disc_loss = 0.011275075074216281
Trained batch 54 in epoch 6, gen_loss = 0.4046265948902477, disc_loss = 0.01125588978386738
Trained batch 55 in epoch 6, gen_loss = 0.40340733741010937, disc_loss = 0.011147134105807968
Trained batch 56 in epoch 6, gen_loss = 0.40342764634835093, disc_loss = 0.011065663328688396
Trained batch 57 in epoch 6, gen_loss = 0.4036756769336503, disc_loss = 0.010965602135221506
Trained batch 58 in epoch 6, gen_loss = 0.40425628322665974, disc_loss = 0.010866651990277282
Trained batch 59 in epoch 6, gen_loss = 0.4045598149299622, disc_loss = 0.010754312473970155
Trained batch 60 in epoch 6, gen_loss = 0.40489141032344006, disc_loss = 0.010676593542648632
Trained batch 61 in epoch 6, gen_loss = 0.40547930569418017, disc_loss = 0.010652413103549231
Trained batch 62 in epoch 6, gen_loss = 0.4055287502114735, disc_loss = 0.010568627917636481
Trained batch 63 in epoch 6, gen_loss = 0.40565093141049147, disc_loss = 0.010443624487379566
Trained batch 64 in epoch 6, gen_loss = 0.40503805325581477, disc_loss = 0.010330624459311367
Trained batch 65 in epoch 6, gen_loss = 0.4052389544067961, disc_loss = 0.010208378295470593
Trained batch 66 in epoch 6, gen_loss = 0.40534464992694, disc_loss = 0.01008732989082919
Trained batch 67 in epoch 6, gen_loss = 0.4056529288782793, disc_loss = 0.010013357301324825
Trained batch 68 in epoch 6, gen_loss = 0.40678660118061566, disc_loss = 0.009954658670998786
Trained batch 69 in epoch 6, gen_loss = 0.4072189497096198, disc_loss = 0.00989775901460754
Trained batch 70 in epoch 6, gen_loss = 0.40688884300245365, disc_loss = 0.009944345005197634
Trained batch 71 in epoch 6, gen_loss = 0.4060287939177619, disc_loss = 0.009850726039278217
Trained batch 72 in epoch 6, gen_loss = 0.4063246217492509, disc_loss = 0.009905420999642308
Trained batch 73 in epoch 6, gen_loss = 0.4084308880406457, disc_loss = 0.010040730807451985
Trained batch 74 in epoch 6, gen_loss = 0.4087772329648336, disc_loss = 0.010004431335255503
Trained batch 75 in epoch 6, gen_loss = 0.40835850254485484, disc_loss = 0.010049822976150992
Trained batch 76 in epoch 6, gen_loss = 0.40894858519752303, disc_loss = 0.010068972670630394
Trained batch 77 in epoch 6, gen_loss = 0.4097607433795929, disc_loss = 0.010018221595181296
Trained batch 78 in epoch 6, gen_loss = 0.4086173293711264, disc_loss = 0.010013435534024728
Trained batch 79 in epoch 6, gen_loss = 0.40843977965414524, disc_loss = 0.009945738120586611
Trained batch 80 in epoch 6, gen_loss = 0.40904902749591404, disc_loss = 0.009961895360093977
Trained batch 81 in epoch 6, gen_loss = 0.4098248743429417, disc_loss = 0.010360923473632372
Trained batch 82 in epoch 6, gen_loss = 0.41059275025344755, disc_loss = 0.011048771073503128
Trained batch 83 in epoch 6, gen_loss = 0.4108907222038224, disc_loss = 0.011302051791322551
Trained batch 84 in epoch 6, gen_loss = 0.41039403606863584, disc_loss = 0.01129224890130846
Trained batch 85 in epoch 6, gen_loss = 0.4093614958746489, disc_loss = 0.01312129799720593
Trained batch 86 in epoch 6, gen_loss = 0.4102131001565648, disc_loss = 0.014629242687496817
Trained batch 87 in epoch 6, gen_loss = 0.41014198383147066, disc_loss = 0.01487736685720103
Trained batch 88 in epoch 6, gen_loss = 0.4094155400656582, disc_loss = 0.01575355518745321
Trained batch 89 in epoch 6, gen_loss = 0.409877797961235, disc_loss = 0.016486776974569593
Trained batch 90 in epoch 6, gen_loss = 0.4100155777983613, disc_loss = 0.01643109019937833
Trained batch 91 in epoch 6, gen_loss = 0.409657284617424, disc_loss = 0.016650025543007676
Trained batch 92 in epoch 6, gen_loss = 0.40987088859722176, disc_loss = 0.016917432680906307
Trained batch 93 in epoch 6, gen_loss = 0.40960437091107066, disc_loss = 0.017131157152533057
Trained batch 94 in epoch 6, gen_loss = 0.40946956872940066, disc_loss = 0.01702127625038357
Trained batch 95 in epoch 6, gen_loss = 0.4099982865154743, disc_loss = 0.016981437091696232
Trained batch 96 in epoch 6, gen_loss = 0.40980179531058086, disc_loss = 0.01690211319652645
Trained batch 97 in epoch 6, gen_loss = 0.40980574640692496, disc_loss = 0.016967808635316182
Trained batch 98 in epoch 6, gen_loss = 0.4095831546518538, disc_loss = 0.01738385212457165
Trained batch 99 in epoch 6, gen_loss = 0.4084679424762726, disc_loss = 0.017616643568035214
Trained batch 100 in epoch 6, gen_loss = 0.4082677995804513, disc_loss = 0.017512738716207666
Trained batch 101 in epoch 6, gen_loss = 0.4087926923644309, disc_loss = 0.017394469587552343
Trained batch 102 in epoch 6, gen_loss = 0.40910444126545803, disc_loss = 0.017277454792350096
Trained batch 103 in epoch 6, gen_loss = 0.408410981297493, disc_loss = 0.01736263307303978
Trained batch 104 in epoch 6, gen_loss = 0.40843669857297626, disc_loss = 0.017389724614276063
Trained batch 105 in epoch 6, gen_loss = 0.4080654441748025, disc_loss = 0.017982287189642072
Trained batch 106 in epoch 6, gen_loss = 0.40861347624074634, disc_loss = 0.01918115511876052
Trained batch 107 in epoch 6, gen_loss = 0.4083148000968827, disc_loss = 0.01913384323793084
Trained batch 108 in epoch 6, gen_loss = 0.40679494230025404, disc_loss = 0.0208786411890162
Trained batch 109 in epoch 6, gen_loss = 0.40684557990594344, disc_loss = 0.02181395309003578
Trained batch 110 in epoch 6, gen_loss = 0.40715845640715176, disc_loss = 0.0218811620945564
Trained batch 111 in epoch 6, gen_loss = 0.4068141406668084, disc_loss = 0.021946504127949344
Trained batch 112 in epoch 6, gen_loss = 0.4065912985696202, disc_loss = 0.022046342077953494
Trained batch 113 in epoch 6, gen_loss = 0.40644417023449614, disc_loss = 0.02228446021929318
Trained batch 114 in epoch 6, gen_loss = 0.40653412627137225, disc_loss = 0.022257429132561967
Trained batch 115 in epoch 6, gen_loss = 0.40591585610447256, disc_loss = 0.022330722753520542
Trained batch 116 in epoch 6, gen_loss = 0.40577850866521525, disc_loss = 0.02239847471181335
Trained batch 117 in epoch 6, gen_loss = 0.4053723183223757, disc_loss = 0.022388206161479702
Trained batch 118 in epoch 6, gen_loss = 0.40536427873523295, disc_loss = 0.022363934977011394
Trained batch 119 in epoch 6, gen_loss = 0.4051344705124696, disc_loss = 0.022580739636517442
Trained batch 120 in epoch 6, gen_loss = 0.40568616789234574, disc_loss = 0.023052899026473568
Trained batch 121 in epoch 6, gen_loss = 0.40570068359375, disc_loss = 0.022948608808143096
Trained batch 122 in epoch 6, gen_loss = 0.406088587229814, disc_loss = 0.022932705111665334
Trained batch 123 in epoch 6, gen_loss = 0.4062190156790518, disc_loss = 0.022870965825859457
Trained batch 124 in epoch 6, gen_loss = 0.4066048216819763, disc_loss = 0.022730729458853603
Trained batch 125 in epoch 6, gen_loss = 0.4061256975881637, disc_loss = 0.022607725965494794
Trained batch 126 in epoch 6, gen_loss = 0.4055378821891124, disc_loss = 0.022457102711466472
Trained batch 127 in epoch 6, gen_loss = 0.40538589959032834, disc_loss = 0.02234442277585913
Trained batch 128 in epoch 6, gen_loss = 0.4057176288708236, disc_loss = 0.022205559455594697
Trained batch 129 in epoch 6, gen_loss = 0.4054532039623994, disc_loss = 0.02207484325358214
Trained batch 130 in epoch 6, gen_loss = 0.406076020184364, disc_loss = 0.021983824981348092
Trained batch 131 in epoch 6, gen_loss = 0.40599547258832236, disc_loss = 0.021862410878494495
Trained batch 132 in epoch 6, gen_loss = 0.40569611061784555, disc_loss = 0.021782271726813195
Trained batch 133 in epoch 6, gen_loss = 0.40528439252234216, disc_loss = 0.02190759321570452
Trained batch 134 in epoch 6, gen_loss = 0.4048988033224035, disc_loss = 0.02246949054059331
Trained batch 135 in epoch 6, gen_loss = 0.40568194757489595, disc_loss = 0.02281699378406355
Trained batch 136 in epoch 6, gen_loss = 0.4063445151287274, disc_loss = 0.022702159885194723
Trained batch 137 in epoch 6, gen_loss = 0.40663194526796753, disc_loss = 0.02264233613960391
Trained batch 138 in epoch 6, gen_loss = 0.4064838045792614, disc_loss = 0.022504126400144087
Trained batch 139 in epoch 6, gen_loss = 0.40643460771867207, disc_loss = 0.02236741640372202
Trained batch 140 in epoch 6, gen_loss = 0.40649468890318635, disc_loss = 0.0222340484384236
Trained batch 141 in epoch 6, gen_loss = 0.4063438802537784, disc_loss = 0.022114648331205924
Trained batch 142 in epoch 6, gen_loss = 0.4059939388628606, disc_loss = 0.022000165973705323
Trained batch 143 in epoch 6, gen_loss = 0.4056840058830049, disc_loss = 0.02204276881820988
Trained batch 144 in epoch 6, gen_loss = 0.4056755859276344, disc_loss = 0.02191371781558826
Trained batch 145 in epoch 6, gen_loss = 0.40598338985279814, disc_loss = 0.021849610396239855
Trained batch 146 in epoch 6, gen_loss = 0.405876216637034, disc_loss = 0.021728343615422443
Trained batch 147 in epoch 6, gen_loss = 0.40591799649032384, disc_loss = 0.021635693076343554
Trained batch 148 in epoch 6, gen_loss = 0.4062397203989477, disc_loss = 0.021524007066509268
Trained batch 149 in epoch 6, gen_loss = 0.40617614448070527, disc_loss = 0.021463583325967192
Trained batch 150 in epoch 6, gen_loss = 0.4069495495186736, disc_loss = 0.021350760200979892
Trained batch 151 in epoch 6, gen_loss = 0.4069532759879765, disc_loss = 0.021256786063436027
Trained batch 152 in epoch 6, gen_loss = 0.40691545527744916, disc_loss = 0.0211961054535327
Trained batch 153 in epoch 6, gen_loss = 0.4069846220217742, disc_loss = 0.021174969275590854
Trained batch 154 in epoch 6, gen_loss = 0.40705519357035236, disc_loss = 0.021136358082895317
Trained batch 155 in epoch 6, gen_loss = 0.4072457158412689, disc_loss = 0.02104230261204812
Trained batch 156 in epoch 6, gen_loss = 0.40747594643550317, disc_loss = 0.020950993250130088
Trained batch 157 in epoch 6, gen_loss = 0.4073323756456375, disc_loss = 0.020851073721777413
Trained batch 158 in epoch 6, gen_loss = 0.407194399796192, disc_loss = 0.02076915359276833
Trained batch 159 in epoch 6, gen_loss = 0.4069560024887323, disc_loss = 0.020691484102280812
Trained batch 160 in epoch 6, gen_loss = 0.40727752558192853, disc_loss = 0.02058675268560833
Trained batch 161 in epoch 6, gen_loss = 0.40699363012372713, disc_loss = 0.020558537731384052
Trained batch 162 in epoch 6, gen_loss = 0.407178122207431, disc_loss = 0.020492415475241978
Trained batch 163 in epoch 6, gen_loss = 0.40707425845832357, disc_loss = 0.02039708116477946
Trained batch 164 in epoch 6, gen_loss = 0.40726815263430277, disc_loss = 0.020301112730168935
Trained batch 165 in epoch 6, gen_loss = 0.407099916094757, disc_loss = 0.02023894938427102
Trained batch 166 in epoch 6, gen_loss = 0.40669652730404976, disc_loss = 0.02017026256859124
Trained batch 167 in epoch 6, gen_loss = 0.40638260827178047, disc_loss = 0.020312693042104087
Trained batch 168 in epoch 6, gen_loss = 0.40619554339781316, disc_loss = 0.02096259609944898
Trained batch 169 in epoch 6, gen_loss = 0.4065484855104895, disc_loss = 0.02284968353479224
Trained batch 170 in epoch 6, gen_loss = 0.40590760425517436, disc_loss = 0.023201464893220114
Trained batch 171 in epoch 6, gen_loss = 0.4053323298346165, disc_loss = 0.0235207115765661
Trained batch 172 in epoch 6, gen_loss = 0.40498679445658115, disc_loss = 0.023534747341249374
Trained batch 173 in epoch 6, gen_loss = 0.40520361425547763, disc_loss = 0.023650059064357788
Trained batch 174 in epoch 6, gen_loss = 0.4045699722426278, disc_loss = 0.024058066005153315
Trained batch 175 in epoch 6, gen_loss = 0.4043733480979096, disc_loss = 0.025576166379985145
Trained batch 176 in epoch 6, gen_loss = 0.4035262598493005, disc_loss = 0.02678080761310576
Trained batch 177 in epoch 6, gen_loss = 0.4036307288019845, disc_loss = 0.027867701192375985
Trained batch 178 in epoch 6, gen_loss = 0.4032340953802929, disc_loss = 0.02930804828504444
Trained batch 179 in epoch 6, gen_loss = 0.4030886948108673, disc_loss = 0.03106061062361631
Trained batch 180 in epoch 6, gen_loss = 0.402932896139872, disc_loss = 0.032194799476030454
Trained batch 181 in epoch 6, gen_loss = 0.40270619569243965, disc_loss = 0.03375791913348731
Trained batch 182 in epoch 6, gen_loss = 0.4025634116813785, disc_loss = 0.03549336246596497
Trained batch 183 in epoch 6, gen_loss = 0.4021795907098314, disc_loss = 0.03617154887330759
Trained batch 184 in epoch 6, gen_loss = 0.4017375072917423, disc_loss = 0.036850780404701425
Trained batch 185 in epoch 6, gen_loss = 0.4012384424286504, disc_loss = 0.03735422719049678
Trained batch 186 in epoch 6, gen_loss = 0.4007692796023772, disc_loss = 0.03810951790528342
Trained batch 187 in epoch 6, gen_loss = 0.40084972977638245, disc_loss = 0.039155493386367216
Trained batch 188 in epoch 6, gen_loss = 0.40016121271426086, disc_loss = 0.0395315667101867
Trained batch 189 in epoch 6, gen_loss = 0.40002205952217706, disc_loss = 0.04006631985600842
Trained batch 190 in epoch 6, gen_loss = 0.399871331234877, disc_loss = 0.04074223541913076
Trained batch 191 in epoch 6, gen_loss = 0.4001828700614472, disc_loss = 0.04104844627727289
Trained batch 192 in epoch 6, gen_loss = 0.3996174005029115, disc_loss = 0.0414987881209489
Trained batch 193 in epoch 6, gen_loss = 0.39982406318802194, disc_loss = 0.04216923710131615
Trained batch 194 in epoch 6, gen_loss = 0.3990754171823844, disc_loss = 0.04269169522688175
Trained batch 195 in epoch 6, gen_loss = 0.3990403581030515, disc_loss = 0.04278238010782825
Trained batch 196 in epoch 6, gen_loss = 0.39885186846486204, disc_loss = 0.04279572378163259
Trained batch 197 in epoch 6, gen_loss = 0.39851582486822146, disc_loss = 0.04308930104786549
Trained batch 198 in epoch 6, gen_loss = 0.3984587038282174, disc_loss = 0.04302099494534971
Trained batch 199 in epoch 6, gen_loss = 0.39851766064763067, disc_loss = 0.04307228737976402
Trained batch 200 in epoch 6, gen_loss = 0.3984756490484399, disc_loss = 0.043075151959276615
Trained batch 201 in epoch 6, gen_loss = 0.3985876587062779, disc_loss = 0.04307903363692141
Trained batch 202 in epoch 6, gen_loss = 0.398428801538909, disc_loss = 0.04307775599010325
Trained batch 203 in epoch 6, gen_loss = 0.39843802387807886, disc_loss = 0.0431954731352116
Trained batch 204 in epoch 6, gen_loss = 0.39803820790314093, disc_loss = 0.044125938410984306
Trained batch 205 in epoch 6, gen_loss = 0.398434313466248, disc_loss = 0.04614489966352443
Trained batch 206 in epoch 6, gen_loss = 0.39860141680436434, disc_loss = 0.04649773419605217
Trained batch 207 in epoch 6, gen_loss = 0.39836246233720046, disc_loss = 0.04666993687771118
Trained batch 208 in epoch 6, gen_loss = 0.39837921179082403, disc_loss = 0.04664983993850684
Trained batch 209 in epoch 6, gen_loss = 0.39854022704419634, disc_loss = 0.046561587491028365
Trained batch 210 in epoch 6, gen_loss = 0.3984743376478765, disc_loss = 0.04644959830012508
Trained batch 211 in epoch 6, gen_loss = 0.3984949552225617, disc_loss = 0.046340182849715625
Trained batch 212 in epoch 6, gen_loss = 0.39856496607193925, disc_loss = 0.046175989899521985
Trained batch 213 in epoch 6, gen_loss = 0.3984193700217755, disc_loss = 0.04601632896375572
Trained batch 214 in epoch 6, gen_loss = 0.3983463079430336, disc_loss = 0.04588965102597031
Trained batch 215 in epoch 6, gen_loss = 0.3986144910256068, disc_loss = 0.04585695462905009
Trained batch 216 in epoch 6, gen_loss = 0.3980879997877481, disc_loss = 0.046618935111309254
Trained batch 217 in epoch 6, gen_loss = 0.3983567321519239, disc_loss = 0.047245062985927413
Trained batch 218 in epoch 6, gen_loss = 0.3981455776789417, disc_loss = 0.047155393912673815
Trained batch 219 in epoch 6, gen_loss = 0.39797424050894653, disc_loss = 0.04719576224769381
Trained batch 220 in epoch 6, gen_loss = 0.39779112956642565, disc_loss = 0.04705731645310761
Trained batch 221 in epoch 6, gen_loss = 0.397870748429685, disc_loss = 0.04697131532084969
Trained batch 222 in epoch 6, gen_loss = 0.39749651612722287, disc_loss = 0.046997952341799515
Trained batch 223 in epoch 6, gen_loss = 0.3976236726822598, disc_loss = 0.04686090217520749
Trained batch 224 in epoch 6, gen_loss = 0.3977746017773946, disc_loss = 0.046685969821280905
Trained batch 225 in epoch 6, gen_loss = 0.397660135959102, disc_loss = 0.04661947558840028
Trained batch 226 in epoch 6, gen_loss = 0.39766195652768477, disc_loss = 0.046680073175858296
Trained batch 227 in epoch 6, gen_loss = 0.39741399126094684, disc_loss = 0.04703460763649721
Trained batch 228 in epoch 6, gen_loss = 0.39789188038313755, disc_loss = 0.04709809319844152
Trained batch 229 in epoch 6, gen_loss = 0.3978717591451562, disc_loss = 0.04697379783281813
Trained batch 230 in epoch 6, gen_loss = 0.3979724383715427, disc_loss = 0.04684361686438193
Trained batch 231 in epoch 6, gen_loss = 0.397979603887632, disc_loss = 0.04670091878606713
Trained batch 232 in epoch 6, gen_loss = 0.39800281368611706, disc_loss = 0.04653262973727075
Trained batch 233 in epoch 6, gen_loss = 0.3980884693371944, disc_loss = 0.046472991331138164
Trained batch 234 in epoch 6, gen_loss = 0.39809454857034887, disc_loss = 0.04635962394482278
Trained batch 235 in epoch 6, gen_loss = 0.3979943293636128, disc_loss = 0.0462318475958023
Trained batch 236 in epoch 6, gen_loss = 0.39822423533548285, disc_loss = 0.04609928061627638
Trained batch 237 in epoch 6, gen_loss = 0.39821124302238975, disc_loss = 0.04597189610808337
Trained batch 238 in epoch 6, gen_loss = 0.3981818723878102, disc_loss = 0.04585325343058947
Trained batch 239 in epoch 6, gen_loss = 0.39823902087907, disc_loss = 0.04568721715865346
Trained batch 240 in epoch 6, gen_loss = 0.3979243972489448, disc_loss = 0.04553857438567701
Trained batch 241 in epoch 6, gen_loss = 0.3978833965033539, disc_loss = 0.04538032118315724
Trained batch 242 in epoch 6, gen_loss = 0.39811053442856903, disc_loss = 0.04527416841966318
Trained batch 243 in epoch 6, gen_loss = 0.397949646730892, disc_loss = 0.04510490926265045
Trained batch 244 in epoch 6, gen_loss = 0.3981589762531981, disc_loss = 0.04494784592213679
Trained batch 245 in epoch 6, gen_loss = 0.398169629215225, disc_loss = 0.04496482911905864
Trained batch 246 in epoch 6, gen_loss = 0.39856909064628815, disc_loss = 0.04516629664310318
Trained batch 247 in epoch 6, gen_loss = 0.3986117176471218, disc_loss = 0.04506167001090944
Trained batch 248 in epoch 6, gen_loss = 0.3984844177123533, disc_loss = 0.045057714561441815
Trained batch 249 in epoch 6, gen_loss = 0.3991999702453613, disc_loss = 0.04501218218356371
Trained batch 250 in epoch 6, gen_loss = 0.39956668660460243, disc_loss = 0.04488082246417068
Trained batch 251 in epoch 6, gen_loss = 0.3996094601258399, disc_loss = 0.04473102282887945
Trained batch 252 in epoch 6, gen_loss = 0.3996194894370354, disc_loss = 0.04467580821770041
Trained batch 253 in epoch 6, gen_loss = 0.39982915593413854, disc_loss = 0.04464068452416971
Trained batch 254 in epoch 6, gen_loss = 0.4000703328964757, disc_loss = 0.04485262487193241
Trained batch 255 in epoch 6, gen_loss = 0.39997266908176243, disc_loss = 0.04475882523729524
Trained batch 256 in epoch 6, gen_loss = 0.39987418449806333, disc_loss = 0.04462403666539705
Trained batch 257 in epoch 6, gen_loss = 0.3996030100325281, disc_loss = 0.04448193827708966
Trained batch 258 in epoch 6, gen_loss = 0.39959196913196315, disc_loss = 0.04437361327341567
Trained batch 259 in epoch 6, gen_loss = 0.39967333513956804, disc_loss = 0.044219649713844636
Trained batch 260 in epoch 6, gen_loss = 0.39950671164012047, disc_loss = 0.04407803546565931
Trained batch 261 in epoch 6, gen_loss = 0.39937275420618423, disc_loss = 0.043964429858019786
Trained batch 262 in epoch 6, gen_loss = 0.3996617778172511, disc_loss = 0.04382554554653145
Trained batch 263 in epoch 6, gen_loss = 0.39973083827080147, disc_loss = 0.043684472548634265
Trained batch 264 in epoch 6, gen_loss = 0.3998399254286064, disc_loss = 0.04358144912095565
Trained batch 265 in epoch 6, gen_loss = 0.40007175068209944, disc_loss = 0.04354438018333867
Trained batch 266 in epoch 6, gen_loss = 0.40019211920906095, disc_loss = 0.043414783967512374
Trained batch 267 in epoch 6, gen_loss = 0.39995407290867907, disc_loss = 0.04326871789665198
Trained batch 268 in epoch 6, gen_loss = 0.4001677149290489, disc_loss = 0.04315134241560744
Trained batch 269 in epoch 6, gen_loss = 0.4003015524811215, disc_loss = 0.04303709129733896
Trained batch 270 in epoch 6, gen_loss = 0.40008496149439654, disc_loss = 0.04301350694871422
Trained batch 271 in epoch 6, gen_loss = 0.39980876215678807, disc_loss = 0.04301541837391115
Trained batch 272 in epoch 6, gen_loss = 0.3998173713247418, disc_loss = 0.043021113954607275
Trained batch 273 in epoch 6, gen_loss = 0.3997381410024462, disc_loss = 0.04294039304776076
Trained batch 274 in epoch 6, gen_loss = 0.39999605200507427, disc_loss = 0.042922542256049134
Trained batch 275 in epoch 6, gen_loss = 0.40017751032027643, disc_loss = 0.04282516803747664
Trained batch 276 in epoch 6, gen_loss = 0.39992554211444376, disc_loss = 0.04275372386187153
Trained batch 277 in epoch 6, gen_loss = 0.39969791086028805, disc_loss = 0.04262288681084036
Trained batch 278 in epoch 6, gen_loss = 0.3999059331673448, disc_loss = 0.04250088625330491
Trained batch 279 in epoch 6, gen_loss = 0.40011925388659747, disc_loss = 0.042369423146426145
Trained batch 280 in epoch 6, gen_loss = 0.4002329818506682, disc_loss = 0.042256826128863674
Trained batch 281 in epoch 6, gen_loss = 0.4002315629247232, disc_loss = 0.04212369654056821
Trained batch 282 in epoch 6, gen_loss = 0.4001859880378305, disc_loss = 0.04204652576078743
Trained batch 283 in epoch 6, gen_loss = 0.40007259780672233, disc_loss = 0.0420518484881515
Trained batch 284 in epoch 6, gen_loss = 0.40036994176998475, disc_loss = 0.04193634942271992
Trained batch 285 in epoch 6, gen_loss = 0.4005577168264589, disc_loss = 0.04203980077233921
Trained batch 286 in epoch 6, gen_loss = 0.40042531594166775, disc_loss = 0.042375857975879096
Trained batch 287 in epoch 6, gen_loss = 0.40044299761454266, disc_loss = 0.04246136708954711
Trained batch 288 in epoch 6, gen_loss = 0.40050674258218916, disc_loss = 0.04237414165448307
Trained batch 289 in epoch 6, gen_loss = 0.40059947381759514, disc_loss = 0.042263934374305194
Trained batch 290 in epoch 6, gen_loss = 0.4004576242051993, disc_loss = 0.042181990527039026
Trained batch 291 in epoch 6, gen_loss = 0.4002469148333759, disc_loss = 0.042143452260324295
Trained batch 292 in epoch 6, gen_loss = 0.4000463316871851, disc_loss = 0.042017311207416114
Trained batch 293 in epoch 6, gen_loss = 0.39991784521511625, disc_loss = 0.041894335055812484
Trained batch 294 in epoch 6, gen_loss = 0.400001439906783, disc_loss = 0.04182185080786378
Trained batch 295 in epoch 6, gen_loss = 0.3996087693282076, disc_loss = 0.041850609739462065
Trained batch 296 in epoch 6, gen_loss = 0.3998198156003599, disc_loss = 0.04175388831206243
Trained batch 297 in epoch 6, gen_loss = 0.39992230160524384, disc_loss = 0.041720160308150234
Trained batch 298 in epoch 6, gen_loss = 0.3999127526347055, disc_loss = 0.041618517372620144
Trained batch 299 in epoch 6, gen_loss = 0.39972140302260717, disc_loss = 0.041509169631948076
Trained batch 300 in epoch 6, gen_loss = 0.3996366638677857, disc_loss = 0.04143401404898428
Trained batch 301 in epoch 6, gen_loss = 0.39970740942370814, disc_loss = 0.041335437462251906
Trained batch 302 in epoch 6, gen_loss = 0.39984903319834086, disc_loss = 0.041245782010183474
Trained batch 303 in epoch 6, gen_loss = 0.39978254851149886, disc_loss = 0.04113476698617696
Trained batch 304 in epoch 6, gen_loss = 0.3997153089671838, disc_loss = 0.041060378680341555
Trained batch 305 in epoch 6, gen_loss = 0.39955250344245263, disc_loss = 0.041005759667361676
Trained batch 306 in epoch 6, gen_loss = 0.39955545267763665, disc_loss = 0.04108172972119301
Trained batch 307 in epoch 6, gen_loss = 0.3995016474615444, disc_loss = 0.04099414016531369
Trained batch 308 in epoch 6, gen_loss = 0.3994357191436113, disc_loss = 0.041072807099947456
Trained batch 309 in epoch 6, gen_loss = 0.39962164019384694, disc_loss = 0.04099906776400824
Trained batch 310 in epoch 6, gen_loss = 0.3994596247887688, disc_loss = 0.04100610981500705
Trained batch 311 in epoch 6, gen_loss = 0.3993756960217769, disc_loss = 0.04089280931153693
Trained batch 312 in epoch 6, gen_loss = 0.39954684555720976, disc_loss = 0.040872637948658044
Trained batch 313 in epoch 6, gen_loss = 0.39967561071845376, disc_loss = 0.040755476414042105
Trained batch 314 in epoch 6, gen_loss = 0.3995620878915938, disc_loss = 0.04067949088260768
Trained batch 315 in epoch 6, gen_loss = 0.3996542132919348, disc_loss = 0.040565095688628997
Trained batch 316 in epoch 6, gen_loss = 0.39988834906827764, disc_loss = 0.04049336078814716
Trained batch 317 in epoch 6, gen_loss = 0.39974728170430884, disc_loss = 0.04044460949821854
Trained batch 318 in epoch 6, gen_loss = 0.39949796603391163, disc_loss = 0.04053648908660516
Trained batch 319 in epoch 6, gen_loss = 0.39918441539630295, disc_loss = 0.04082114095217548
Trained batch 320 in epoch 6, gen_loss = 0.39918615940575286, disc_loss = 0.04079500711711582
Trained batch 321 in epoch 6, gen_loss = 0.398956889321345, disc_loss = 0.040892918871842925
Trained batch 322 in epoch 6, gen_loss = 0.3991643504092568, disc_loss = 0.04112414725632306
Trained batch 323 in epoch 6, gen_loss = 0.399005197448495, disc_loss = 0.04152291287081661
Trained batch 324 in epoch 6, gen_loss = 0.39915385209597076, disc_loss = 0.04144527801527427
Trained batch 325 in epoch 6, gen_loss = 0.3993799112325797, disc_loss = 0.04153905150143464
Trained batch 326 in epoch 6, gen_loss = 0.3992943289812187, disc_loss = 0.04160434932131833
Trained batch 327 in epoch 6, gen_loss = 0.3994176543158729, disc_loss = 0.04150197306852334
Trained batch 328 in epoch 6, gen_loss = 0.39965880252307673, disc_loss = 0.041435394979628386
Trained batch 329 in epoch 6, gen_loss = 0.3996211939688885, disc_loss = 0.041342098731547594
Trained batch 330 in epoch 6, gen_loss = 0.39941716185149106, disc_loss = 0.04124019716041911
Trained batch 331 in epoch 6, gen_loss = 0.39939071444502794, disc_loss = 0.04118289699895779
Trained batch 332 in epoch 6, gen_loss = 0.39926840745292985, disc_loss = 0.04108483211889684
Trained batch 333 in epoch 6, gen_loss = 0.3991882478940987, disc_loss = 0.040971015292794226
Trained batch 334 in epoch 6, gen_loss = 0.3990548173883068, disc_loss = 0.04086954318848786
Trained batch 335 in epoch 6, gen_loss = 0.3992965425409022, disc_loss = 0.04086180316101361
Trained batch 336 in epoch 6, gen_loss = 0.39919701881861475, disc_loss = 0.04086556260056727
Trained batch 337 in epoch 6, gen_loss = 0.3993250918106215, disc_loss = 0.04076210562464886
Trained batch 338 in epoch 6, gen_loss = 0.39941551296760197, disc_loss = 0.04065515111120841
Trained batch 339 in epoch 6, gen_loss = 0.3996085551731727, disc_loss = 0.04061696629916482
Trained batch 340 in epoch 6, gen_loss = 0.39964390465241373, disc_loss = 0.0405141374306573
Trained batch 341 in epoch 6, gen_loss = 0.39943363216885347, disc_loss = 0.04062660975103969
Trained batch 342 in epoch 6, gen_loss = 0.39946335571500374, disc_loss = 0.04071128153196012
Trained batch 343 in epoch 6, gen_loss = 0.39958335719136306, disc_loss = 0.040621314626890996
Trained batch 344 in epoch 6, gen_loss = 0.3995684383572012, disc_loss = 0.04072142186831089
Trained batch 345 in epoch 6, gen_loss = 0.39981268837272776, disc_loss = 0.04089622511366931
Trained batch 346 in epoch 6, gen_loss = 0.3998913352702468, disc_loss = 0.04081846519859148
Trained batch 347 in epoch 6, gen_loss = 0.3996038955004736, disc_loss = 0.0408392142271623
Trained batch 348 in epoch 6, gen_loss = 0.39958582677608917, disc_loss = 0.04076861085925241
Trained batch 349 in epoch 6, gen_loss = 0.3995869015795844, disc_loss = 0.040666316440328955
Trained batch 350 in epoch 6, gen_loss = 0.3994700634411597, disc_loss = 0.0405796612082235
Trained batch 351 in epoch 6, gen_loss = 0.39943376141176984, disc_loss = 0.04049333710017064
Trained batch 352 in epoch 6, gen_loss = 0.3992780848873236, disc_loss = 0.040409496809928426
Trained batch 353 in epoch 6, gen_loss = 0.39908631760521796, disc_loss = 0.040316025395009475
Trained batch 354 in epoch 6, gen_loss = 0.399030039595886, disc_loss = 0.04026628861754713
Trained batch 355 in epoch 6, gen_loss = 0.3988924558075626, disc_loss = 0.04020346299316106
Trained batch 356 in epoch 6, gen_loss = 0.3991205830033086, disc_loss = 0.04011018162577593
Trained batch 357 in epoch 6, gen_loss = 0.39940446007518127, disc_loss = 0.04002612316460666
Trained batch 358 in epoch 6, gen_loss = 0.39954858362508683, disc_loss = 0.039932392284658044
Trained batch 359 in epoch 6, gen_loss = 0.399762872275379, disc_loss = 0.03983252553476228
Trained batch 360 in epoch 6, gen_loss = 0.3997038579713605, disc_loss = 0.039733741992253845
Trained batch 361 in epoch 6, gen_loss = 0.3997622757985447, disc_loss = 0.03964588460538186
Trained batch 362 in epoch 6, gen_loss = 0.39955399499451816, disc_loss = 0.039544188694582004
Trained batch 363 in epoch 6, gen_loss = 0.3996704705468901, disc_loss = 0.03945911589723367
Trained batch 364 in epoch 6, gen_loss = 0.3998941505608493, disc_loss = 0.039389543513422956
Trained batch 365 in epoch 6, gen_loss = 0.3998805405012245, disc_loss = 0.03929321833789511
Trained batch 366 in epoch 6, gen_loss = 0.3999021548666161, disc_loss = 0.03925060032681646
Trained batch 367 in epoch 6, gen_loss = 0.40000438811662403, disc_loss = 0.03915791476965356
Trained batch 368 in epoch 6, gen_loss = 0.4002722084199187, disc_loss = 0.039072369780583274
Trained batch 369 in epoch 6, gen_loss = 0.40022751028473313, disc_loss = 0.038986395193716966
Trained batch 370 in epoch 6, gen_loss = 0.4001787830234538, disc_loss = 0.03889614067133265
Trained batch 371 in epoch 6, gen_loss = 0.4002344228567616, disc_loss = 0.03881018236404665
Trained batch 372 in epoch 6, gen_loss = 0.40003094844140574, disc_loss = 0.038726694236482034
Trained batch 373 in epoch 6, gen_loss = 0.3998394475423078, disc_loss = 0.03865344388495115
Trained batch 374 in epoch 6, gen_loss = 0.39991463875770566, disc_loss = 0.03860571836307645
Trained batch 375 in epoch 6, gen_loss = 0.400102001793207, disc_loss = 0.03854670490886263
Trained batch 376 in epoch 6, gen_loss = 0.4000256103451119, disc_loss = 0.03845592445523456
Trained batch 377 in epoch 6, gen_loss = 0.4001736739482829, disc_loss = 0.0383935536038643
Trained batch 378 in epoch 6, gen_loss = 0.4000908826775161, disc_loss = 0.038316199739063084
Trained batch 379 in epoch 6, gen_loss = 0.40018448445357774, disc_loss = 0.03823084404054833
Trained batch 380 in epoch 6, gen_loss = 0.40017161704110976, disc_loss = 0.03815751439424872
Trained batch 381 in epoch 6, gen_loss = 0.4000920836682095, disc_loss = 0.0380753873559739
Trained batch 382 in epoch 6, gen_loss = 0.4000297610504509, disc_loss = 0.037994027324993525
Trained batch 383 in epoch 6, gen_loss = 0.399983545144399, disc_loss = 0.03795058926092073
Trained batch 384 in epoch 6, gen_loss = 0.4001468118135031, disc_loss = 0.03789425938595812
Trained batch 385 in epoch 6, gen_loss = 0.4002272474333412, disc_loss = 0.03780594409305911
Trained batch 386 in epoch 6, gen_loss = 0.4003818836015016, disc_loss = 0.03772256984640134
Trained batch 387 in epoch 6, gen_loss = 0.40041420416733653, disc_loss = 0.037641773962286136
Trained batch 388 in epoch 6, gen_loss = 0.4006865946983004, disc_loss = 0.0375600439061801
Trained batch 389 in epoch 6, gen_loss = 0.40093636711438496, disc_loss = 0.037487561976274425
Trained batch 390 in epoch 6, gen_loss = 0.4009023195947223, disc_loss = 0.0374079293939416
Trained batch 391 in epoch 6, gen_loss = 0.40097296078290257, disc_loss = 0.037343204721727655
Trained batch 392 in epoch 6, gen_loss = 0.40112553229768766, disc_loss = 0.03730010285525661
Trained batch 393 in epoch 6, gen_loss = 0.4011983939536332, disc_loss = 0.037219005665826956
Trained batch 394 in epoch 6, gen_loss = 0.40126514125473894, disc_loss = 0.03714413140263833
Trained batch 395 in epoch 6, gen_loss = 0.40126490291922984, disc_loss = 0.03712429201778382
Trained batch 396 in epoch 6, gen_loss = 0.4014493379394714, disc_loss = 0.037046502194759114
Trained batch 397 in epoch 6, gen_loss = 0.4015051966636025, disc_loss = 0.03699029395040873
Trained batch 398 in epoch 6, gen_loss = 0.40155003483134105, disc_loss = 0.03708056751510273
Trained batch 399 in epoch 6, gen_loss = 0.4014893067628145, disc_loss = 0.037991892553982325
Trained batch 400 in epoch 6, gen_loss = 0.40150610244184953, disc_loss = 0.038008339580571156
Trained batch 401 in epoch 6, gen_loss = 0.40165514769542277, disc_loss = 0.038033664447199834
Trained batch 402 in epoch 6, gen_loss = 0.40149620071829994, disc_loss = 0.03807404852546197
Trained batch 403 in epoch 6, gen_loss = 0.4016464803330969, disc_loss = 0.03801054748911687
Trained batch 404 in epoch 6, gen_loss = 0.4014356674235544, disc_loss = 0.03796176893671078
Trained batch 405 in epoch 6, gen_loss = 0.401481883132399, disc_loss = 0.03799543030424676
Trained batch 406 in epoch 6, gen_loss = 0.4014226187944998, disc_loss = 0.037924850149611035
Trained batch 407 in epoch 6, gen_loss = 0.40121279817585853, disc_loss = 0.038272106422535965
Trained batch 408 in epoch 6, gen_loss = 0.4014851021008853, disc_loss = 0.039443774541047534
Trained batch 409 in epoch 6, gen_loss = 0.4015838393350927, disc_loss = 0.039435979865332385
Trained batch 410 in epoch 6, gen_loss = 0.4016698408155836, disc_loss = 0.03955500092133064
Trained batch 411 in epoch 6, gen_loss = 0.4014968982020628, disc_loss = 0.039516263456621833
Trained batch 412 in epoch 6, gen_loss = 0.40144524144202687, disc_loss = 0.03954446512910359
Trained batch 413 in epoch 6, gen_loss = 0.4014543837683212, disc_loss = 0.03954197450682683
Trained batch 414 in epoch 6, gen_loss = 0.401392890315458, disc_loss = 0.03968811996157719
Trained batch 415 in epoch 6, gen_loss = 0.40140304084007555, disc_loss = 0.03968025683570886
Trained batch 416 in epoch 6, gen_loss = 0.40137579315286176, disc_loss = 0.03962097397214807
Trained batch 417 in epoch 6, gen_loss = 0.4014410836417139, disc_loss = 0.0395595532419766
Trained batch 418 in epoch 6, gen_loss = 0.4013570199291575, disc_loss = 0.03953284773639979
Trained batch 419 in epoch 6, gen_loss = 0.4013588846439407, disc_loss = 0.039513419992623054
Trained batch 420 in epoch 6, gen_loss = 0.4014986260061876, disc_loss = 0.03943667417965086
Trained batch 421 in epoch 6, gen_loss = 0.40148002008126243, disc_loss = 0.039353191576152156
Trained batch 422 in epoch 6, gen_loss = 0.4015318778107916, disc_loss = 0.03929277488699812
Trained batch 423 in epoch 6, gen_loss = 0.40144160579679145, disc_loss = 0.03921057056264407
Trained batch 424 in epoch 6, gen_loss = 0.40121091898749855, disc_loss = 0.03913716862690361
Trained batch 425 in epoch 6, gen_loss = 0.4012762277338986, disc_loss = 0.03906231977213874
Trained batch 426 in epoch 6, gen_loss = 0.4011016415488804, disc_loss = 0.03898551140309898
Trained batch 427 in epoch 6, gen_loss = 0.4009723643136916, disc_loss = 0.03890373733353792
Trained batch 428 in epoch 6, gen_loss = 0.40097003827839744, disc_loss = 0.03882936421740531
Trained batch 429 in epoch 6, gen_loss = 0.4010126548451047, disc_loss = 0.038751410866741005
Trained batch 430 in epoch 6, gen_loss = 0.4009705857998257, disc_loss = 0.03867705783746238
Trained batch 431 in epoch 6, gen_loss = 0.4011646770630722, disc_loss = 0.038636361812004236
Trained batch 432 in epoch 6, gen_loss = 0.4011127950137537, disc_loss = 0.03864570482801775
Trained batch 433 in epoch 6, gen_loss = 0.401323240610861, disc_loss = 0.03877384075948599
Trained batch 434 in epoch 6, gen_loss = 0.4012911134752734, disc_loss = 0.03869618652120832
Trained batch 435 in epoch 6, gen_loss = 0.40110730359313684, disc_loss = 0.03871930396844368
Trained batch 436 in epoch 6, gen_loss = 0.40115124287267023, disc_loss = 0.03866125399926656
Trained batch 437 in epoch 6, gen_loss = 0.40125720386635766, disc_loss = 0.03859830680292644
Trained batch 438 in epoch 6, gen_loss = 0.4010989139862104, disc_loss = 0.03853233792746953
Trained batch 439 in epoch 6, gen_loss = 0.40115765671838416, disc_loss = 0.0384560046818065
Trained batch 440 in epoch 6, gen_loss = 0.4011143252017006, disc_loss = 0.038402949328388586
Trained batch 441 in epoch 6, gen_loss = 0.4011510247153934, disc_loss = 0.038388789742573995
Trained batch 442 in epoch 6, gen_loss = 0.40115544731407077, disc_loss = 0.038341337072286694
Trained batch 443 in epoch 6, gen_loss = 0.4012050521266353, disc_loss = 0.03826660493562871
Trained batch 444 in epoch 6, gen_loss = 0.4011772246842974, disc_loss = 0.03819435352009585
Trained batch 445 in epoch 6, gen_loss = 0.40129684005350275, disc_loss = 0.03817649727067054
Trained batch 446 in epoch 6, gen_loss = 0.4012706106407797, disc_loss = 0.038210349771562936
Trained batch 447 in epoch 6, gen_loss = 0.4013878605993731, disc_loss = 0.03816648151665244
Trained batch 448 in epoch 6, gen_loss = 0.40153084738482875, disc_loss = 0.038104888941068
Trained batch 449 in epoch 6, gen_loss = 0.4014591807789273, disc_loss = 0.03806333988646252
Trained batch 450 in epoch 6, gen_loss = 0.40147978820716196, disc_loss = 0.03801438559472412
Trained batch 451 in epoch 6, gen_loss = 0.4015895188909716, disc_loss = 0.03794854998627711
Trained batch 452 in epoch 6, gen_loss = 0.4014878627611838, disc_loss = 0.03787517349881266
Trained batch 453 in epoch 6, gen_loss = 0.4014336208152351, disc_loss = 0.037862795372780755
Trained batch 454 in epoch 6, gen_loss = 0.40178236136069667, disc_loss = 0.03787612975268
Trained batch 455 in epoch 6, gen_loss = 0.4018813308916594, disc_loss = 0.037806609915589845
Trained batch 456 in epoch 6, gen_loss = 0.4018286357692869, disc_loss = 0.03773651739808627
Trained batch 457 in epoch 6, gen_loss = 0.40181549583199766, disc_loss = 0.03769255147110183
Trained batch 458 in epoch 6, gen_loss = 0.4017909854845284, disc_loss = 0.037626579183220765
Trained batch 459 in epoch 6, gen_loss = 0.40180641931036243, disc_loss = 0.03755636386340484
Trained batch 460 in epoch 6, gen_loss = 0.40176278669508314, disc_loss = 0.03748576578667989
Trained batch 461 in epoch 6, gen_loss = 0.40176995150196604, disc_loss = 0.03742794846577643
Trained batch 462 in epoch 6, gen_loss = 0.4012926516986048, disc_loss = 0.037565008715523276
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4647020101547241, disc_loss = 0.012330155819654465
Trained batch 1 in epoch 7, gen_loss = 0.447299525141716, disc_loss = 0.012379046995192766
Trained batch 2 in epoch 7, gen_loss = 0.4467108945051829, disc_loss = 0.013047784877320131
Trained batch 3 in epoch 7, gen_loss = 0.43367966264486313, disc_loss = 0.014742845436558127
Trained batch 4 in epoch 7, gen_loss = 0.4242970824241638, disc_loss = 0.014585454948246479
Trained batch 5 in epoch 7, gen_loss = 0.41473933557669324, disc_loss = 0.01578141888603568
Trained batch 6 in epoch 7, gen_loss = 0.41710072330066134, disc_loss = 0.014548067402626787
Trained batch 7 in epoch 7, gen_loss = 0.419501680880785, disc_loss = 0.016062123817391694
Trained batch 8 in epoch 7, gen_loss = 0.4177621569898393, disc_loss = 0.017991758986479707
Trained batch 9 in epoch 7, gen_loss = 0.40898759961128234, disc_loss = 0.017912208568304777
Trained batch 10 in epoch 7, gen_loss = 0.4104050506245006, disc_loss = 0.02087477281350981
Trained batch 11 in epoch 7, gen_loss = 0.40034253150224686, disc_loss = 0.021915519842877984
Trained batch 12 in epoch 7, gen_loss = 0.3990784241602971, disc_loss = 0.023448857478797436
Trained batch 13 in epoch 7, gen_loss = 0.3987732210329601, disc_loss = 0.024165939473147904
Trained batch 14 in epoch 7, gen_loss = 0.4009216109911601, disc_loss = 0.0230983542278409
Trained batch 15 in epoch 7, gen_loss = 0.4060189314186573, disc_loss = 0.024735419254284352
Trained batch 16 in epoch 7, gen_loss = 0.4017421988879933, disc_loss = 0.0444807096329682
Trained batch 17 in epoch 7, gen_loss = 0.4065529704093933, disc_loss = 0.051065830876015954
Trained batch 18 in epoch 7, gen_loss = 0.40999813926847356, disc_loss = 0.055290918748237584
Trained batch 19 in epoch 7, gen_loss = 0.409317284822464, disc_loss = 0.05476045361720026
Trained batch 20 in epoch 7, gen_loss = 0.40470050204367863, disc_loss = 0.0547936081088015
Trained batch 21 in epoch 7, gen_loss = 0.40418463945388794, disc_loss = 0.0544828032143414
Trained batch 22 in epoch 7, gen_loss = 0.40444699059362, disc_loss = 0.06576293492284806
Trained batch 23 in epoch 7, gen_loss = 0.3969763157268365, disc_loss = 0.07846559130121022
Trained batch 24 in epoch 7, gen_loss = 0.3934686028957367, disc_loss = 0.0811924622580409
Trained batch 25 in epoch 7, gen_loss = 0.39183781353326946, disc_loss = 0.08548024737347777
Trained batch 26 in epoch 7, gen_loss = 0.3911670943101247, disc_loss = 0.08846664742601139
Trained batch 27 in epoch 7, gen_loss = 0.3869048697607858, disc_loss = 0.09089321360391166
Trained batch 28 in epoch 7, gen_loss = 0.3849657332075053, disc_loss = 0.09004322962899661
Trained batch 29 in epoch 7, gen_loss = 0.3847665160894394, disc_loss = 0.08858813652768731
Trained batch 30 in epoch 7, gen_loss = 0.3867094622504327, disc_loss = 0.08799574413006345
Trained batch 31 in epoch 7, gen_loss = 0.3864236446097493, disc_loss = 0.08731302604428492
Trained batch 32 in epoch 7, gen_loss = 0.38551489873365924, disc_loss = 0.09077432873009732
Trained batch 33 in epoch 7, gen_loss = 0.3853403215899187, disc_loss = 0.0906565420274787
Trained batch 34 in epoch 7, gen_loss = 0.3865896395274571, disc_loss = 0.09084120634943246
Trained batch 35 in epoch 7, gen_loss = 0.38441867050197387, disc_loss = 0.09541895889884068
Trained batch 36 in epoch 7, gen_loss = 0.38360859252311086, disc_loss = 0.09634274231723032
Trained batch 37 in epoch 7, gen_loss = 0.38307163903587743, disc_loss = 0.09527214300377589
Trained batch 38 in epoch 7, gen_loss = 0.38334873165839756, disc_loss = 0.09389729336954844
Trained batch 39 in epoch 7, gen_loss = 0.3832589566707611, disc_loss = 0.09187000198289752
Trained batch 40 in epoch 7, gen_loss = 0.38375317178121426, disc_loss = 0.09005923169415171
Trained batch 41 in epoch 7, gen_loss = 0.385036153452737, disc_loss = 0.08806966837229473
Trained batch 42 in epoch 7, gen_loss = 0.384669843108155, disc_loss = 0.08642878086674352
Trained batch 43 in epoch 7, gen_loss = 0.38484359126199374, disc_loss = 0.0855771574742076
Trained batch 44 in epoch 7, gen_loss = 0.3867564585473802, disc_loss = 0.08541005508353312
Trained batch 45 in epoch 7, gen_loss = 0.3863572789275128, disc_loss = 0.08536310078900146
Trained batch 46 in epoch 7, gen_loss = 0.38703776039975757, disc_loss = 0.08474622831303388
Trained batch 47 in epoch 7, gen_loss = 0.38891823465625447, disc_loss = 0.08334526161585624
Trained batch 48 in epoch 7, gen_loss = 0.38791737021232137, disc_loss = 0.08241190021971659
Trained batch 49 in epoch 7, gen_loss = 0.38933670103549955, disc_loss = 0.08092385230585933
Trained batch 50 in epoch 7, gen_loss = 0.3916416863600413, disc_loss = 0.07955020319159124
Trained batch 51 in epoch 7, gen_loss = 0.39209566895778364, disc_loss = 0.07817277348098847
Trained batch 52 in epoch 7, gen_loss = 0.39177428045362794, disc_loss = 0.07678911235745785
Trained batch 53 in epoch 7, gen_loss = 0.3916662456812682, disc_loss = 0.07552951119012302
Trained batch 54 in epoch 7, gen_loss = 0.391420596296137, disc_loss = 0.07441443154080347
Trained batch 55 in epoch 7, gen_loss = 0.39195525805865017, disc_loss = 0.07324544189032167
Trained batch 56 in epoch 7, gen_loss = 0.39316021611816004, disc_loss = 0.07228534235700704
Trained batch 57 in epoch 7, gen_loss = 0.39290213276600017, disc_loss = 0.07129302961302214
Trained batch 58 in epoch 7, gen_loss = 0.3930623187857159, disc_loss = 0.07021640452666808
Trained batch 59 in epoch 7, gen_loss = 0.3936241865158081, disc_loss = 0.06919125614998241
Trained batch 60 in epoch 7, gen_loss = 0.39385661189673377, disc_loss = 0.06827834984440295
Trained batch 61 in epoch 7, gen_loss = 0.3941214757580911, disc_loss = 0.06729761803252322
Trained batch 62 in epoch 7, gen_loss = 0.39547855418825906, disc_loss = 0.06633434345620493
Trained batch 63 in epoch 7, gen_loss = 0.39535772521048784, disc_loss = 0.06538400590943638
Trained batch 64 in epoch 7, gen_loss = 0.3956525559608753, disc_loss = 0.06443652744906453
Trained batch 65 in epoch 7, gen_loss = 0.3953711367917783, disc_loss = 0.06353424120496845
Trained batch 66 in epoch 7, gen_loss = 0.394254503410254, disc_loss = 0.06334294815923074
Trained batch 67 in epoch 7, gen_loss = 0.39474839235053344, disc_loss = 0.0639861192458364
Trained batch 68 in epoch 7, gen_loss = 0.39412398441978125, disc_loss = 0.06348828726407627
Trained batch 69 in epoch 7, gen_loss = 0.3935656385762351, disc_loss = 0.0627241665031761
Trained batch 70 in epoch 7, gen_loss = 0.3931895154462734, disc_loss = 0.061947213433368106
Trained batch 71 in epoch 7, gen_loss = 0.3930311095383432, disc_loss = 0.061216404014784426
Trained batch 72 in epoch 7, gen_loss = 0.39288061081546627, disc_loss = 0.06047084898215859
Trained batch 73 in epoch 7, gen_loss = 0.39219785824015335, disc_loss = 0.059817514118008515
Trained batch 74 in epoch 7, gen_loss = 0.3926383086045583, disc_loss = 0.059084257818758486
Trained batch 75 in epoch 7, gen_loss = 0.39316726319099726, disc_loss = 0.0583460559811149
Trained batch 76 in epoch 7, gen_loss = 0.3932443992658095, disc_loss = 0.0576509899677491
Trained batch 77 in epoch 7, gen_loss = 0.39243597671007496, disc_loss = 0.057204233846651055
Trained batch 78 in epoch 7, gen_loss = 0.3929822426053542, disc_loss = 0.0568641951908888
Trained batch 79 in epoch 7, gen_loss = 0.3932785462588072, disc_loss = 0.05712182433926501
Trained batch 80 in epoch 7, gen_loss = 0.39364941436567424, disc_loss = 0.05691751833706175
Trained batch 81 in epoch 7, gen_loss = 0.3937432762326264, disc_loss = 0.05633609697063703
Trained batch 82 in epoch 7, gen_loss = 0.39423605153359564, disc_loss = 0.05613253746428583
Trained batch 83 in epoch 7, gen_loss = 0.3944465823116757, disc_loss = 0.05561756424140185
Trained batch 84 in epoch 7, gen_loss = 0.3944135332808775, disc_loss = 0.055204642821541604
Trained batch 85 in epoch 7, gen_loss = 0.3945067479859951, disc_loss = 0.05475854944589353
Trained batch 86 in epoch 7, gen_loss = 0.39407411354711686, disc_loss = 0.054267350889357
Trained batch 87 in epoch 7, gen_loss = 0.39395881071686745, disc_loss = 0.05374858043135398
Trained batch 88 in epoch 7, gen_loss = 0.39355567298578414, disc_loss = 0.05327174042906152
Trained batch 89 in epoch 7, gen_loss = 0.39268842505084145, disc_loss = 0.052830445626750586
Trained batch 90 in epoch 7, gen_loss = 0.39370508049870584, disc_loss = 0.05243563947298533
Trained batch 91 in epoch 7, gen_loss = 0.39414903391962464, disc_loss = 0.05232781208747917
Trained batch 92 in epoch 7, gen_loss = 0.39397529248268376, disc_loss = 0.05206621348637567
Trained batch 93 in epoch 7, gen_loss = 0.3933392306591602, disc_loss = 0.05170733303802603
Trained batch 94 in epoch 7, gen_loss = 0.3932079126960353, disc_loss = 0.05120936757149665
Trained batch 95 in epoch 7, gen_loss = 0.392561137676239, disc_loss = 0.05098460431812176
Trained batch 96 in epoch 7, gen_loss = 0.3935552429907101, disc_loss = 0.05185726918184112
Trained batch 97 in epoch 7, gen_loss = 0.3928014812420826, disc_loss = 0.055533464347031346
Trained batch 98 in epoch 7, gen_loss = 0.3928855404709325, disc_loss = 0.05742676724971394
Trained batch 99 in epoch 7, gen_loss = 0.39300850629806516, disc_loss = 0.058159582200460136
Trained batch 100 in epoch 7, gen_loss = 0.39253246695688454, disc_loss = 0.05888230128139995
Trained batch 101 in epoch 7, gen_loss = 0.39247886047643776, disc_loss = 0.05927443025432819
Trained batch 102 in epoch 7, gen_loss = 0.39236963547549203, disc_loss = 0.059144858483369776
Trained batch 103 in epoch 7, gen_loss = 0.39267641592484254, disc_loss = 0.058912760501978204
Trained batch 104 in epoch 7, gen_loss = 0.39233316835902987, disc_loss = 0.05865215353579039
Trained batch 105 in epoch 7, gen_loss = 0.39219039903496794, disc_loss = 0.05860618202736215
Trained batch 106 in epoch 7, gen_loss = 0.39227533758243666, disc_loss = 0.058723387417218116
Trained batch 107 in epoch 7, gen_loss = 0.3920971053066077, disc_loss = 0.062026504664336915
Trained batch 108 in epoch 7, gen_loss = 0.39233107003596945, disc_loss = 0.06219075267724351
Trained batch 109 in epoch 7, gen_loss = 0.39257038181478326, disc_loss = 0.062200779700651763
Trained batch 110 in epoch 7, gen_loss = 0.39255612927514155, disc_loss = 0.061895948822131834
Trained batch 111 in epoch 7, gen_loss = 0.39250734475042137, disc_loss = 0.06148592413852124
Trained batch 112 in epoch 7, gen_loss = 0.3924147919215987, disc_loss = 0.061024372198050264
Trained batch 113 in epoch 7, gen_loss = 0.3923830515459964, disc_loss = 0.060538223576977065
Trained batch 114 in epoch 7, gen_loss = 0.3922679235105929, disc_loss = 0.060231705099020316
Trained batch 115 in epoch 7, gen_loss = 0.3922071862837364, disc_loss = 0.05986799700346229
Trained batch 116 in epoch 7, gen_loss = 0.3927913481353695, disc_loss = 0.05942179038961474
Trained batch 117 in epoch 7, gen_loss = 0.3931835831727012, disc_loss = 0.059031318312794984
Trained batch 118 in epoch 7, gen_loss = 0.39267737424674154, disc_loss = 0.05859477454483384
Trained batch 119 in epoch 7, gen_loss = 0.39290729562441506, disc_loss = 0.058194489020388575
Trained batch 120 in epoch 7, gen_loss = 0.3928327747612945, disc_loss = 0.05778529764006823
Trained batch 121 in epoch 7, gen_loss = 0.3929485612716831, disc_loss = 0.057744199238320595
Trained batch 122 in epoch 7, gen_loss = 0.39286330972260575, disc_loss = 0.05923625437270214
Trained batch 123 in epoch 7, gen_loss = 0.3933196199997779, disc_loss = 0.0596495958518297
Trained batch 124 in epoch 7, gen_loss = 0.3935162217617035, disc_loss = 0.05939338482543826
Trained batch 125 in epoch 7, gen_loss = 0.39308865510282065, disc_loss = 0.05943703960021219
Trained batch 126 in epoch 7, gen_loss = 0.393569179172591, disc_loss = 0.059157877980812096
Trained batch 127 in epoch 7, gen_loss = 0.3939464879222214, disc_loss = 0.05887452681417926
Trained batch 128 in epoch 7, gen_loss = 0.39393217364947003, disc_loss = 0.05845826330356473
Trained batch 129 in epoch 7, gen_loss = 0.39364487872673914, disc_loss = 0.05808900938942455
Trained batch 130 in epoch 7, gen_loss = 0.39362390418999066, disc_loss = 0.05772574134668662
Trained batch 131 in epoch 7, gen_loss = 0.3932155937407956, disc_loss = 0.05733212733034496
Trained batch 132 in epoch 7, gen_loss = 0.39337392767569174, disc_loss = 0.0569373494805418
Trained batch 133 in epoch 7, gen_loss = 0.39380695837647167, disc_loss = 0.05653478248642563
Trained batch 134 in epoch 7, gen_loss = 0.3931181697933762, disc_loss = 0.05649495714309591
Trained batch 135 in epoch 7, gen_loss = 0.393321480602026, disc_loss = 0.056441963338704014
Trained batch 136 in epoch 7, gen_loss = 0.3928845152802711, disc_loss = 0.05609908965450242
Trained batch 137 in epoch 7, gen_loss = 0.3928507229556208, disc_loss = 0.05603338361285843
Trained batch 138 in epoch 7, gen_loss = 0.3928950133083536, disc_loss = 0.05579779501133364
Trained batch 139 in epoch 7, gen_loss = 0.3935810055051531, disc_loss = 0.05547216348682663
Trained batch 140 in epoch 7, gen_loss = 0.39379712833580394, disc_loss = 0.0551792292802839
Trained batch 141 in epoch 7, gen_loss = 0.3935080882109387, disc_loss = 0.054954792225313645
Trained batch 142 in epoch 7, gen_loss = 0.3938495985694698, disc_loss = 0.055469331543215296
Trained batch 143 in epoch 7, gen_loss = 0.393920518250929, disc_loss = 0.055278878772191495
Trained batch 144 in epoch 7, gen_loss = 0.39370057973368416, disc_loss = 0.05501899474846392
Trained batch 145 in epoch 7, gen_loss = 0.3936467436078477, disc_loss = 0.054798537989670076
Trained batch 146 in epoch 7, gen_loss = 0.3941571566523338, disc_loss = 0.05451811468355408
Trained batch 147 in epoch 7, gen_loss = 0.39418849228201686, disc_loss = 0.05439245553271895
Trained batch 148 in epoch 7, gen_loss = 0.3942602286802842, disc_loss = 0.05426920893845842
Trained batch 149 in epoch 7, gen_loss = 0.3940514987707138, disc_loss = 0.05394394201226532
Trained batch 150 in epoch 7, gen_loss = 0.3936851004891048, disc_loss = 0.05367468281753904
Trained batch 151 in epoch 7, gen_loss = 0.3936578858839838, disc_loss = 0.05352324693721082
Trained batch 152 in epoch 7, gen_loss = 0.39367277871549516, disc_loss = 0.053198385653481665
Trained batch 153 in epoch 7, gen_loss = 0.3936907138143267, disc_loss = 0.05294360976224741
Trained batch 154 in epoch 7, gen_loss = 0.39404674941493617, disc_loss = 0.05276525021650858
Trained batch 155 in epoch 7, gen_loss = 0.39424466972167677, disc_loss = 0.05253347756717211
Trained batch 156 in epoch 7, gen_loss = 0.3938041498326951, disc_loss = 0.052239546865212975
Trained batch 157 in epoch 7, gen_loss = 0.3944208489943154, disc_loss = 0.05195908879572408
Trained batch 158 in epoch 7, gen_loss = 0.39439484983120326, disc_loss = 0.051661800767394635
Trained batch 159 in epoch 7, gen_loss = 0.394685822725296, disc_loss = 0.05137577772984514
Trained batch 160 in epoch 7, gen_loss = 0.39453793534580966, disc_loss = 0.051130727073756155
Trained batch 161 in epoch 7, gen_loss = 0.3948025810129849, disc_loss = 0.05084289239725259
Trained batch 162 in epoch 7, gen_loss = 0.39498846881960065, disc_loss = 0.050555850032065634
Trained batch 163 in epoch 7, gen_loss = 0.39514234207752275, disc_loss = 0.05026599116021449
Trained batch 164 in epoch 7, gen_loss = 0.39533576820835925, disc_loss = 0.04998613906121164
Trained batch 165 in epoch 7, gen_loss = 0.39535049842782766, disc_loss = 0.04972482919805201
Trained batch 166 in epoch 7, gen_loss = 0.39489286459848555, disc_loss = 0.049465869425121184
Trained batch 167 in epoch 7, gen_loss = 0.3956146573736554, disc_loss = 0.04920298750844917
Trained batch 168 in epoch 7, gen_loss = 0.3960182259421377, disc_loss = 0.04973865968875102
Trained batch 169 in epoch 7, gen_loss = 0.39574192552005544, disc_loss = 0.05105025210034321
Trained batch 170 in epoch 7, gen_loss = 0.3958163805175246, disc_loss = 0.05081978071568131
Trained batch 171 in epoch 7, gen_loss = 0.3960880593851555, disc_loss = 0.050757364776028796
Trained batch 172 in epoch 7, gen_loss = 0.3959911372620246, disc_loss = 0.05105764401075295
Trained batch 173 in epoch 7, gen_loss = 0.39563344573152476, disc_loss = 0.05146775034459672
Trained batch 174 in epoch 7, gen_loss = 0.39603830780301774, disc_loss = 0.05124644088425807
Trained batch 175 in epoch 7, gen_loss = 0.3960343590852889, disc_loss = 0.05104663494487547
Trained batch 176 in epoch 7, gen_loss = 0.39591768872266436, disc_loss = 0.0522686972172331
Trained batch 177 in epoch 7, gen_loss = 0.39575763666227964, disc_loss = 0.052736538185036916
Trained batch 178 in epoch 7, gen_loss = 0.39559215606923875, disc_loss = 0.05381305691104528
Trained batch 179 in epoch 7, gen_loss = 0.39511468691958324, disc_loss = 0.054910411939231886
Trained batch 180 in epoch 7, gen_loss = 0.3947556035294717, disc_loss = 0.05566731408670627
Trained batch 181 in epoch 7, gen_loss = 0.3946002921560308, disc_loss = 0.05605234361796097
Trained batch 182 in epoch 7, gen_loss = 0.39419556901754577, disc_loss = 0.056362410717201036
Trained batch 183 in epoch 7, gen_loss = 0.39461226016283035, disc_loss = 0.05722150927834699
Trained batch 184 in epoch 7, gen_loss = 0.39481782703786283, disc_loss = 0.057299647424873465
Trained batch 185 in epoch 7, gen_loss = 0.39499014872376637, disc_loss = 0.05740661354815607
Trained batch 186 in epoch 7, gen_loss = 0.39443160107429015, disc_loss = 0.057524081264786864
Trained batch 187 in epoch 7, gen_loss = 0.39462658683670326, disc_loss = 0.05726335235831744
Trained batch 188 in epoch 7, gen_loss = 0.3949368026836839, disc_loss = 0.05708132804957805
Trained batch 189 in epoch 7, gen_loss = 0.39513530574346845, disc_loss = 0.05687836639485077
Trained batch 190 in epoch 7, gen_loss = 0.3947700124760573, disc_loss = 0.05679245156123844
Trained batch 191 in epoch 7, gen_loss = 0.39502798734853667, disc_loss = 0.05692142686166335
Trained batch 192 in epoch 7, gen_loss = 0.3949207075210433, disc_loss = 0.056845545821818354
Trained batch 193 in epoch 7, gen_loss = 0.395089049161095, disc_loss = 0.0566874526431496
Trained batch 194 in epoch 7, gen_loss = 0.3952754433338459, disc_loss = 0.05684229301240964
Trained batch 195 in epoch 7, gen_loss = 0.3955402149229634, disc_loss = 0.05661121341019717
Trained batch 196 in epoch 7, gen_loss = 0.395360027472985, disc_loss = 0.05637884396719297
Trained batch 197 in epoch 7, gen_loss = 0.3952777438392543, disc_loss = 0.05618364846032828
Trained batch 198 in epoch 7, gen_loss = 0.3955193167954833, disc_loss = 0.055923151774285126
Trained batch 199 in epoch 7, gen_loss = 0.3955583313107491, disc_loss = 0.055667800467927006
Trained batch 200 in epoch 7, gen_loss = 0.3955509033962269, disc_loss = 0.0554434751827659
Trained batch 201 in epoch 7, gen_loss = 0.39577973272540784, disc_loss = 0.05521342508485633
Trained batch 202 in epoch 7, gen_loss = 0.3959133707243821, disc_loss = 0.05498873238942673
Trained batch 203 in epoch 7, gen_loss = 0.39610476236717373, disc_loss = 0.054792920568063126
Trained batch 204 in epoch 7, gen_loss = 0.3958304360145476, disc_loss = 0.0545558747426584
Trained batch 205 in epoch 7, gen_loss = 0.39604523083538684, disc_loss = 0.054545086932829716
Trained batch 206 in epoch 7, gen_loss = 0.3960408073116616, disc_loss = 0.05461937668485846
Trained batch 207 in epoch 7, gen_loss = 0.3959597051143646, disc_loss = 0.054396818877788834
Trained batch 208 in epoch 7, gen_loss = 0.3958983004948739, disc_loss = 0.054185767384005365
Trained batch 209 in epoch 7, gen_loss = 0.3960450772728239, disc_loss = 0.05394783065033456
Trained batch 210 in epoch 7, gen_loss = 0.39608126073651967, disc_loss = 0.053726002589415456
Trained batch 211 in epoch 7, gen_loss = 0.3962952226119221, disc_loss = 0.05359497630116442
Trained batch 212 in epoch 7, gen_loss = 0.39641287139323955, disc_loss = 0.0533651411074253
Trained batch 213 in epoch 7, gen_loss = 0.39628901701664254, disc_loss = 0.05315794760282978
Trained batch 214 in epoch 7, gen_loss = 0.3966746800167616, disc_loss = 0.05294752204357538
Trained batch 215 in epoch 7, gen_loss = 0.39674922037455773, disc_loss = 0.052720655616010643
Trained batch 216 in epoch 7, gen_loss = 0.3972064532717252, disc_loss = 0.052505487977411204
Trained batch 217 in epoch 7, gen_loss = 0.3972712473584971, disc_loss = 0.052280538424917866
Trained batch 218 in epoch 7, gen_loss = 0.3973063253648749, disc_loss = 0.05207376489543343
Trained batch 219 in epoch 7, gen_loss = 0.39726556404070423, disc_loss = 0.05185801818204874
Trained batch 220 in epoch 7, gen_loss = 0.3971747942100283, disc_loss = 0.05163610319088622
Trained batch 221 in epoch 7, gen_loss = 0.3969980279604594, disc_loss = 0.051422435888886314
Trained batch 222 in epoch 7, gen_loss = 0.39693047006033993, disc_loss = 0.05120798568617168
Trained batch 223 in epoch 7, gen_loss = 0.39707896752016886, disc_loss = 0.05100190955584237
Trained batch 224 in epoch 7, gen_loss = 0.3972305874029795, disc_loss = 0.05079735132658647
Trained batch 225 in epoch 7, gen_loss = 0.39711220799821667, disc_loss = 0.050592532506072485
Trained batch 226 in epoch 7, gen_loss = 0.3973497527811496, disc_loss = 0.050423117577086
Trained batch 227 in epoch 7, gen_loss = 0.3972234098534835, disc_loss = 0.05021853126144331
Trained batch 228 in epoch 7, gen_loss = 0.3972345395379712, disc_loss = 0.05001272986882964
Trained batch 229 in epoch 7, gen_loss = 0.39732033649216525, disc_loss = 0.04981690924614668
Trained batch 230 in epoch 7, gen_loss = 0.3973914568042342, disc_loss = 0.04961986455953482
Trained batch 231 in epoch 7, gen_loss = 0.3973667425071371, disc_loss = 0.04944034250742146
Trained batch 232 in epoch 7, gen_loss = 0.3971691736591732, disc_loss = 0.0492513308125696
Trained batch 233 in epoch 7, gen_loss = 0.39755007879346865, disc_loss = 0.04906464326314819
Trained batch 234 in epoch 7, gen_loss = 0.39781694589777195, disc_loss = 0.04892178330808244
Trained batch 235 in epoch 7, gen_loss = 0.397715682953091, disc_loss = 0.04874236805175068
Trained batch 236 in epoch 7, gen_loss = 0.3977270787778283, disc_loss = 0.048601942875654384
Trained batch 237 in epoch 7, gen_loss = 0.39744661635711415, disc_loss = 0.048519056157342026
Trained batch 238 in epoch 7, gen_loss = 0.397448731017412, disc_loss = 0.048339577532026556
Trained batch 239 in epoch 7, gen_loss = 0.3976016158858935, disc_loss = 0.048212772817350924
Trained batch 240 in epoch 7, gen_loss = 0.39766516997111784, disc_loss = 0.048048169100927615
Trained batch 241 in epoch 7, gen_loss = 0.3975466967614229, disc_loss = 0.04789366859804131
Trained batch 242 in epoch 7, gen_loss = 0.3976796995465157, disc_loss = 0.04772402521667412
Trained batch 243 in epoch 7, gen_loss = 0.3974631922166856, disc_loss = 0.04757739055031514
Trained batch 244 in epoch 7, gen_loss = 0.3974167887045413, disc_loss = 0.047421879309932795
Trained batch 245 in epoch 7, gen_loss = 0.39744194506145103, disc_loss = 0.04724107439652449
Trained batch 246 in epoch 7, gen_loss = 0.39711178048902196, disc_loss = 0.047066746477550464
Trained batch 247 in epoch 7, gen_loss = 0.39709413376065994, disc_loss = 0.046910706526344464
Trained batch 248 in epoch 7, gen_loss = 0.3974139501292064, disc_loss = 0.046733548468255615
Trained batch 249 in epoch 7, gen_loss = 0.3972804834842682, disc_loss = 0.04656265863403678
Trained batch 250 in epoch 7, gen_loss = 0.3975908420237887, disc_loss = 0.046418913020436985
Trained batch 251 in epoch 7, gen_loss = 0.39745793361512444, disc_loss = 0.04625852423949197
Trained batch 252 in epoch 7, gen_loss = 0.3974213498854354, disc_loss = 0.04609405030514824
Trained batch 253 in epoch 7, gen_loss = 0.3972277655376224, disc_loss = 0.045953245780350066
Trained batch 254 in epoch 7, gen_loss = 0.3975782452845106, disc_loss = 0.04579914719706365
Trained batch 255 in epoch 7, gen_loss = 0.3973299094941467, disc_loss = 0.04565667268798279
Trained batch 256 in epoch 7, gen_loss = 0.3971828787011395, disc_loss = 0.04549841091928257
Trained batch 257 in epoch 7, gen_loss = 0.3969385716342187, disc_loss = 0.045339740749607366
Trained batch 258 in epoch 7, gen_loss = 0.3971020872758622, disc_loss = 0.045199614235750155
Trained batch 259 in epoch 7, gen_loss = 0.3972209821526821, disc_loss = 0.04505158798733296
Trained batch 260 in epoch 7, gen_loss = 0.3972211981413465, disc_loss = 0.04490652513579676
Trained batch 261 in epoch 7, gen_loss = 0.3973286428296839, disc_loss = 0.04476216578152287
Trained batch 262 in epoch 7, gen_loss = 0.3973403117502597, disc_loss = 0.04460999843604268
Trained batch 263 in epoch 7, gen_loss = 0.3973232760573878, disc_loss = 0.04445162132050785
Trained batch 264 in epoch 7, gen_loss = 0.39771408809805814, disc_loss = 0.04432454254161918
Trained batch 265 in epoch 7, gen_loss = 0.3978147770005061, disc_loss = 0.04417352557455407
Trained batch 266 in epoch 7, gen_loss = 0.39791536945082273, disc_loss = 0.04403677477051368
Trained batch 267 in epoch 7, gen_loss = 0.3978586518275204, disc_loss = 0.04388425889800289
Trained batch 268 in epoch 7, gen_loss = 0.3978680265880429, disc_loss = 0.04373391063409584
Trained batch 269 in epoch 7, gen_loss = 0.39762522302292014, disc_loss = 0.043597989200821356
Trained batch 270 in epoch 7, gen_loss = 0.3977123847526818, disc_loss = 0.04346223701929117
Trained batch 271 in epoch 7, gen_loss = 0.39765428039519224, disc_loss = 0.043370880014502775
Trained batch 272 in epoch 7, gen_loss = 0.3975974717637995, disc_loss = 0.043234846816524425
Trained batch 273 in epoch 7, gen_loss = 0.3975781572126124, disc_loss = 0.04328743966524047
Trained batch 274 in epoch 7, gen_loss = 0.3974522920088335, disc_loss = 0.043298656167462465
Trained batch 275 in epoch 7, gen_loss = 0.3976137495559195, disc_loss = 0.04316434391480668
Trained batch 276 in epoch 7, gen_loss = 0.3975579173771483, disc_loss = 0.043055692416134994
Trained batch 277 in epoch 7, gen_loss = 0.3975415455994846, disc_loss = 0.042938055287168875
Trained batch 278 in epoch 7, gen_loss = 0.3976084159480201, disc_loss = 0.042857567800582794
Trained batch 279 in epoch 7, gen_loss = 0.3978454400386129, disc_loss = 0.042789565263748434
Trained batch 280 in epoch 7, gen_loss = 0.3978460617761171, disc_loss = 0.042672220833791796
Trained batch 281 in epoch 7, gen_loss = 0.3973058024619488, disc_loss = 0.04280003521290892
Trained batch 282 in epoch 7, gen_loss = 0.3974115048196206, disc_loss = 0.0435935301688095
Trained batch 283 in epoch 7, gen_loss = 0.39723936227005974, disc_loss = 0.0437000951521479
Trained batch 284 in epoch 7, gen_loss = 0.3972355102237902, disc_loss = 0.04359767972328292
Trained batch 285 in epoch 7, gen_loss = 0.39758443165492346, disc_loss = 0.0435106223326997
Trained batch 286 in epoch 7, gen_loss = 0.3978704301322379, disc_loss = 0.043407393552083846
Trained batch 287 in epoch 7, gen_loss = 0.3977415811063515, disc_loss = 0.04333411030125313
Trained batch 288 in epoch 7, gen_loss = 0.39780181945401494, disc_loss = 0.043510758802198055
Trained batch 289 in epoch 7, gen_loss = 0.3977285564973437, disc_loss = 0.04405996660493186
Trained batch 290 in epoch 7, gen_loss = 0.39816232040985344, disc_loss = 0.0443171301378174
Trained batch 291 in epoch 7, gen_loss = 0.3983726482072922, disc_loss = 0.04426205525420326
Trained batch 292 in epoch 7, gen_loss = 0.39835937712786545, disc_loss = 0.0441401360068572
Trained batch 293 in epoch 7, gen_loss = 0.39823703974688135, disc_loss = 0.04402275401291114
Trained batch 294 in epoch 7, gen_loss = 0.39799985037011615, disc_loss = 0.04389958380311096
Trained batch 295 in epoch 7, gen_loss = 0.39765990676509366, disc_loss = 0.043818621945762505
Trained batch 296 in epoch 7, gen_loss = 0.3978766927414069, disc_loss = 0.043792598964709176
Trained batch 297 in epoch 7, gen_loss = 0.3978358038119822, disc_loss = 0.04370685745477551
Trained batch 298 in epoch 7, gen_loss = 0.3976616199598663, disc_loss = 0.043610374433109944
Trained batch 299 in epoch 7, gen_loss = 0.3978527644276619, disc_loss = 0.043481025710546725
Trained batch 300 in epoch 7, gen_loss = 0.3980666051473332, disc_loss = 0.04334907614830201
Trained batch 301 in epoch 7, gen_loss = 0.39802272598080285, disc_loss = 0.04323256041913213
Trained batch 302 in epoch 7, gen_loss = 0.39804149893644225, disc_loss = 0.04311173453100223
Trained batch 303 in epoch 7, gen_loss = 0.39807548168066303, disc_loss = 0.04300100749318708
Trained batch 304 in epoch 7, gen_loss = 0.3980427270052863, disc_loss = 0.04290101805656049
Trained batch 305 in epoch 7, gen_loss = 0.3981114615217533, disc_loss = 0.04286910290601572
Trained batch 306 in epoch 7, gen_loss = 0.39808474825725493, disc_loss = 0.042756276535088684
Trained batch 307 in epoch 7, gen_loss = 0.3980777290734378, disc_loss = 0.0426392315655596
Trained batch 308 in epoch 7, gen_loss = 0.39838082485600196, disc_loss = 0.04254096089922567
Trained batch 309 in epoch 7, gen_loss = 0.39829129913160877, disc_loss = 0.042455496373886785
Trained batch 310 in epoch 7, gen_loss = 0.3983735101974279, disc_loss = 0.042348722240758814
Trained batch 311 in epoch 7, gen_loss = 0.3984755420914063, disc_loss = 0.042247971202670716
Trained batch 312 in epoch 7, gen_loss = 0.39850152529085786, disc_loss = 0.04217471900550773
Trained batch 313 in epoch 7, gen_loss = 0.39861622025632554, disc_loss = 0.04206035641440232
Trained batch 314 in epoch 7, gen_loss = 0.39864214450593977, disc_loss = 0.04199030416396757
Trained batch 315 in epoch 7, gen_loss = 0.39831260271087476, disc_loss = 0.04189487200604657
Trained batch 316 in epoch 7, gen_loss = 0.3984692751985243, disc_loss = 0.041834574820744076
Trained batch 317 in epoch 7, gen_loss = 0.39873056413617525, disc_loss = 0.041743742134392775
Trained batch 318 in epoch 7, gen_loss = 0.3988851634873118, disc_loss = 0.04162643979840728
Trained batch 319 in epoch 7, gen_loss = 0.39884983357042075, disc_loss = 0.04157651616624207
Trained batch 320 in epoch 7, gen_loss = 0.3988849997891815, disc_loss = 0.04178866433382986
Trained batch 321 in epoch 7, gen_loss = 0.3990215608236953, disc_loss = 0.04168855514368679
Trained batch 322 in epoch 7, gen_loss = 0.3988297298412205, disc_loss = 0.041914044078525975
Trained batch 323 in epoch 7, gen_loss = 0.3992167511655961, disc_loss = 0.041972853241195145
Trained batch 324 in epoch 7, gen_loss = 0.3991810484115894, disc_loss = 0.04216609663473299
Trained batch 325 in epoch 7, gen_loss = 0.3989498698455424, disc_loss = 0.042276125924770314
Trained batch 326 in epoch 7, gen_loss = 0.39873042966976807, disc_loss = 0.04228349963974903
Trained batch 327 in epoch 7, gen_loss = 0.39875846483358524, disc_loss = 0.04232540548134527
Trained batch 328 in epoch 7, gen_loss = 0.39862431617493327, disc_loss = 0.04246097398669909
Trained batch 329 in epoch 7, gen_loss = 0.39878789249694707, disc_loss = 0.04258996989705007
Trained batch 330 in epoch 7, gen_loss = 0.3985565325464727, disc_loss = 0.043111382258403205
Trained batch 331 in epoch 7, gen_loss = 0.39843189438064414, disc_loss = 0.04310734880630892
Trained batch 332 in epoch 7, gen_loss = 0.3984542195503418, disc_loss = 0.04311942107564359
Trained batch 333 in epoch 7, gen_loss = 0.3984518428584059, disc_loss = 0.04327597930639826
Trained batch 334 in epoch 7, gen_loss = 0.3985066171012708, disc_loss = 0.04328942915855615
Trained batch 335 in epoch 7, gen_loss = 0.398423432150767, disc_loss = 0.04320671384491669
Trained batch 336 in epoch 7, gen_loss = 0.3984517031501238, disc_loss = 0.04310079900207943
Trained batch 337 in epoch 7, gen_loss = 0.39847261798099654, disc_loss = 0.043004563479882685
Trained batch 338 in epoch 7, gen_loss = 0.39857849619381547, disc_loss = 0.04298651028784393
Trained batch 339 in epoch 7, gen_loss = 0.3985618106582586, disc_loss = 0.04289832400253919
Trained batch 340 in epoch 7, gen_loss = 0.3986801149383668, disc_loss = 0.04279068320691913
Trained batch 341 in epoch 7, gen_loss = 0.3987415925278301, disc_loss = 0.04267955653584557
Trained batch 342 in epoch 7, gen_loss = 0.3987501970011708, disc_loss = 0.04256543577526514
Trained batch 343 in epoch 7, gen_loss = 0.3987950144638849, disc_loss = 0.04246717043962806
Trained batch 344 in epoch 7, gen_loss = 0.39866488981938014, disc_loss = 0.04236449084069202
Trained batch 345 in epoch 7, gen_loss = 0.39872096272217744, disc_loss = 0.04232649403796504
Trained batch 346 in epoch 7, gen_loss = 0.39839643677991815, disc_loss = 0.042327175650917405
Trained batch 347 in epoch 7, gen_loss = 0.3984839379273612, disc_loss = 0.042248608762580346
Trained batch 348 in epoch 7, gen_loss = 0.3985473594727011, disc_loss = 0.04217810563097326
Trained batch 349 in epoch 7, gen_loss = 0.3985555499792099, disc_loss = 0.042087635383276
Trained batch 350 in epoch 7, gen_loss = 0.3988218722689865, disc_loss = 0.04198765681334837
Trained batch 351 in epoch 7, gen_loss = 0.39871032595295797, disc_loss = 0.04188551827444991
Trained batch 352 in epoch 7, gen_loss = 0.3986293393221523, disc_loss = 0.041776301046416546
Trained batch 353 in epoch 7, gen_loss = 0.3987845423194648, disc_loss = 0.04167925553280587
Trained batch 354 in epoch 7, gen_loss = 0.39879988700571195, disc_loss = 0.04158016887139267
Trained batch 355 in epoch 7, gen_loss = 0.39878376715638664, disc_loss = 0.04148481783765797
Trained batch 356 in epoch 7, gen_loss = 0.39897339709666596, disc_loss = 0.04137954856360368
Trained batch 357 in epoch 7, gen_loss = 0.3993324841367466, disc_loss = 0.04128456750348752
Trained batch 358 in epoch 7, gen_loss = 0.3993001579408194, disc_loss = 0.041177439646702
Trained batch 359 in epoch 7, gen_loss = 0.39936444022589257, disc_loss = 0.041071434296383005
Trained batch 360 in epoch 7, gen_loss = 0.39949288369876196, disc_loss = 0.040969463772787984
Trained batch 361 in epoch 7, gen_loss = 0.39926516614566193, disc_loss = 0.04086562282359485
Trained batch 362 in epoch 7, gen_loss = 0.39920010300707226, disc_loss = 0.04076381146487044
Trained batch 363 in epoch 7, gen_loss = 0.39905229407352405, disc_loss = 0.040661074667606135
Trained batch 364 in epoch 7, gen_loss = 0.3990703982033142, disc_loss = 0.04055599275313011
Trained batch 365 in epoch 7, gen_loss = 0.39921280798690567, disc_loss = 0.04045373030118848
Trained batch 366 in epoch 7, gen_loss = 0.39923818925096166, disc_loss = 0.04035473104353172
Trained batch 367 in epoch 7, gen_loss = 0.39925925547014113, disc_loss = 0.0402517379520957
Trained batch 368 in epoch 7, gen_loss = 0.39917179893671983, disc_loss = 0.0401550118381102
Trained batch 369 in epoch 7, gen_loss = 0.399145127873163, disc_loss = 0.04005434981144562
Trained batch 370 in epoch 7, gen_loss = 0.39910334637865547, disc_loss = 0.03995574598835726
Trained batch 371 in epoch 7, gen_loss = 0.39910920637269176, disc_loss = 0.0398650345247319
Trained batch 372 in epoch 7, gen_loss = 0.39909820566228504, disc_loss = 0.03980799911958203
Trained batch 373 in epoch 7, gen_loss = 0.39920501801419384, disc_loss = 0.039718278165767215
Trained batch 374 in epoch 7, gen_loss = 0.39900853617986043, disc_loss = 0.03962434964751204
Trained batch 375 in epoch 7, gen_loss = 0.3988640341669955, disc_loss = 0.039542081291500004
Trained batch 376 in epoch 7, gen_loss = 0.39885019710588837, disc_loss = 0.03944413310388691
Trained batch 377 in epoch 7, gen_loss = 0.39913326162825186, disc_loss = 0.03935457511359047
Trained batch 378 in epoch 7, gen_loss = 0.39923334208201605, disc_loss = 0.03926260206703401
Trained batch 379 in epoch 7, gen_loss = 0.39923180726013685, disc_loss = 0.03916890696610177
Trained batch 380 in epoch 7, gen_loss = 0.39920273251107985, disc_loss = 0.03907311198746497
Trained batch 381 in epoch 7, gen_loss = 0.3992643301711657, disc_loss = 0.03897955697102969
Trained batch 382 in epoch 7, gen_loss = 0.3992050106469396, disc_loss = 0.038894142195650475
Trained batch 383 in epoch 7, gen_loss = 0.39911401737481356, disc_loss = 0.038801804454730394
Trained batch 384 in epoch 7, gen_loss = 0.3989675946049876, disc_loss = 0.03872094141597581
Trained batch 385 in epoch 7, gen_loss = 0.39897707567931456, disc_loss = 0.03863333793021642
Trained batch 386 in epoch 7, gen_loss = 0.39910137368419063, disc_loss = 0.03854123430954682
Trained batch 387 in epoch 7, gen_loss = 0.3989625512478278, disc_loss = 0.03846262329313232
Trained batch 388 in epoch 7, gen_loss = 0.3989886125899219, disc_loss = 0.03838275088976523
Trained batch 389 in epoch 7, gen_loss = 0.3990606733621695, disc_loss = 0.03829179668488602
Trained batch 390 in epoch 7, gen_loss = 0.39912214463629075, disc_loss = 0.03822190155063177
Trained batch 391 in epoch 7, gen_loss = 0.39921793235199793, disc_loss = 0.038150465204998166
Trained batch 392 in epoch 7, gen_loss = 0.39916601792243295, disc_loss = 0.0380915611136335
Trained batch 393 in epoch 7, gen_loss = 0.39904924478325143, disc_loss = 0.03800846021835158
Trained batch 394 in epoch 7, gen_loss = 0.3988472909867009, disc_loss = 0.03792029611200472
Trained batch 395 in epoch 7, gen_loss = 0.39891902756209324, disc_loss = 0.03783247039319402
Trained batch 396 in epoch 7, gen_loss = 0.398943255620279, disc_loss = 0.03774643247778192
Trained batch 397 in epoch 7, gen_loss = 0.39907328851857976, disc_loss = 0.03766606888036482
Trained batch 398 in epoch 7, gen_loss = 0.3991602578557524, disc_loss = 0.03758817151384918
Trained batch 399 in epoch 7, gen_loss = 0.39922021798789503, disc_loss = 0.03750972510664724
Trained batch 400 in epoch 7, gen_loss = 0.39917597724612514, disc_loss = 0.037427695623675636
Trained batch 401 in epoch 7, gen_loss = 0.39916082089813193, disc_loss = 0.03735723499607165
Trained batch 402 in epoch 7, gen_loss = 0.39913272946407424, disc_loss = 0.03734949741641951
Trained batch 403 in epoch 7, gen_loss = 0.39927615520387594, disc_loss = 0.03730588992550453
Trained batch 404 in epoch 7, gen_loss = 0.3992661663043646, disc_loss = 0.03722616416390663
Trained batch 405 in epoch 7, gen_loss = 0.3995314735203541, disc_loss = 0.0371519133983079
Trained batch 406 in epoch 7, gen_loss = 0.39970530009386873, disc_loss = 0.03707527259424219
Trained batch 407 in epoch 7, gen_loss = 0.3998298548600253, disc_loss = 0.03699423117659
Trained batch 408 in epoch 7, gen_loss = 0.39987217068380715, disc_loss = 0.03691902322339436
Trained batch 409 in epoch 7, gen_loss = 0.3998390473970553, disc_loss = 0.036837985213255375
Trained batch 410 in epoch 7, gen_loss = 0.39989245503488247, disc_loss = 0.03675990820343441
Trained batch 411 in epoch 7, gen_loss = 0.399931700628938, disc_loss = 0.03667663486541059
Trained batch 412 in epoch 7, gen_loss = 0.3998710856599323, disc_loss = 0.036593095905127195
Trained batch 413 in epoch 7, gen_loss = 0.3999314133239829, disc_loss = 0.0365126523035151
Trained batch 414 in epoch 7, gen_loss = 0.39975727631385066, disc_loss = 0.036437208269980835
Trained batch 415 in epoch 7, gen_loss = 0.39981595147401094, disc_loss = 0.03636166539497655
Trained batch 416 in epoch 7, gen_loss = 0.39978350230829895, disc_loss = 0.03630521683283686
Trained batch 417 in epoch 7, gen_loss = 0.3997464470173183, disc_loss = 0.036245700597437765
Trained batch 418 in epoch 7, gen_loss = 0.39974110429497495, disc_loss = 0.03618592459670666
Trained batch 419 in epoch 7, gen_loss = 0.3999565414019993, disc_loss = 0.036110304386377155
Trained batch 420 in epoch 7, gen_loss = 0.39995932748935004, disc_loss = 0.036034087818049586
Trained batch 421 in epoch 7, gen_loss = 0.40014074735731875, disc_loss = 0.03597224910657464
Trained batch 422 in epoch 7, gen_loss = 0.4000873708696794, disc_loss = 0.0359061474908566
Trained batch 423 in epoch 7, gen_loss = 0.39992348139859596, disc_loss = 0.03586088839362657
Trained batch 424 in epoch 7, gen_loss = 0.40005776244051316, disc_loss = 0.03610871064038399
Trained batch 425 in epoch 7, gen_loss = 0.3998956632026484, disc_loss = 0.03666636468175834
Trained batch 426 in epoch 7, gen_loss = 0.39994094766833466, disc_loss = 0.03724314849681943
Trained batch 427 in epoch 7, gen_loss = 0.39975256716536584, disc_loss = 0.037240065901353085
Trained batch 428 in epoch 7, gen_loss = 0.39967374201421135, disc_loss = 0.03736747365981115
Trained batch 429 in epoch 7, gen_loss = 0.3994869005541469, disc_loss = 0.03732561354882755
Trained batch 430 in epoch 7, gen_loss = 0.39942619536426394, disc_loss = 0.0372847793359102
Trained batch 431 in epoch 7, gen_loss = 0.3994936637442421, disc_loss = 0.037233970120993304
Trained batch 432 in epoch 7, gen_loss = 0.39942717504005787, disc_loss = 0.037283239298442045
Trained batch 433 in epoch 7, gen_loss = 0.3994701326854767, disc_loss = 0.037564827302526596
Trained batch 434 in epoch 7, gen_loss = 0.39956633380089684, disc_loss = 0.03807244433743087
Trained batch 435 in epoch 7, gen_loss = 0.3994103672854397, disc_loss = 0.03827998564320129
Trained batch 436 in epoch 7, gen_loss = 0.39944834369543764, disc_loss = 0.03842057941696719
Trained batch 437 in epoch 7, gen_loss = 0.39941860422423986, disc_loss = 0.0385561483974896
Trained batch 438 in epoch 7, gen_loss = 0.39913094016576955, disc_loss = 0.038537617265257416
Trained batch 439 in epoch 7, gen_loss = 0.39924478578296574, disc_loss = 0.038609167113794356
Trained batch 440 in epoch 7, gen_loss = 0.3993110750673039, disc_loss = 0.03859979384093041
Trained batch 441 in epoch 7, gen_loss = 0.39948515223162206, disc_loss = 0.038564112730117776
Trained batch 442 in epoch 7, gen_loss = 0.39944220625250926, disc_loss = 0.03851743462667895
Trained batch 443 in epoch 7, gen_loss = 0.39953224327381665, disc_loss = 0.03847157146083191
Trained batch 444 in epoch 7, gen_loss = 0.39965055598301835, disc_loss = 0.038428141697299446
Trained batch 445 in epoch 7, gen_loss = 0.39957687439138045, disc_loss = 0.0383897519272631
Trained batch 446 in epoch 7, gen_loss = 0.3996822944690184, disc_loss = 0.03834112398732679
Trained batch 447 in epoch 7, gen_loss = 0.39977692287149175, disc_loss = 0.03828366848704588
Trained batch 448 in epoch 7, gen_loss = 0.3998239623146227, disc_loss = 0.038223935813354724
Trained batch 449 in epoch 7, gen_loss = 0.39980352176560296, disc_loss = 0.038157959811699886
Trained batch 450 in epoch 7, gen_loss = 0.39970515704736476, disc_loss = 0.03814376713842269
Trained batch 451 in epoch 7, gen_loss = 0.39993930245395254, disc_loss = 0.038084001502380664
Trained batch 452 in epoch 7, gen_loss = 0.3998265680229953, disc_loss = 0.038100057755952606
Trained batch 453 in epoch 7, gen_loss = 0.39993628209645526, disc_loss = 0.03815344639793285
Trained batch 454 in epoch 7, gen_loss = 0.3998456551478459, disc_loss = 0.03809650080779997
Trained batch 455 in epoch 7, gen_loss = 0.39969095640015184, disc_loss = 0.03822791018153606
Trained batch 456 in epoch 7, gen_loss = 0.3997923124019114, disc_loss = 0.03879135100963715
Trained batch 457 in epoch 7, gen_loss = 0.399830964519988, disc_loss = 0.038729787563730245
Trained batch 458 in epoch 7, gen_loss = 0.3997453336232628, disc_loss = 0.038717084054476006
Trained batch 459 in epoch 7, gen_loss = 0.3997423924181772, disc_loss = 0.03864736707486293
Trained batch 460 in epoch 7, gen_loss = 0.3995924455612704, disc_loss = 0.038582744843017415
Trained batch 461 in epoch 7, gen_loss = 0.39952590964831314, disc_loss = 0.03851024218324926
Trained batch 462 in epoch 7, gen_loss = 0.39934114072286797, disc_loss = 0.038536614234022167
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.451978474855423, disc_loss = 0.055434562265872955
Trained batch 1 in epoch 8, gen_loss = 0.4228338748216629, disc_loss = 0.03171570273116231
Trained batch 2 in epoch 8, gen_loss = 0.39963798721631366, disc_loss = 0.023427332285791636
Trained batch 3 in epoch 8, gen_loss = 0.4045748934149742, disc_loss = 0.021532934973947704
Trained batch 4 in epoch 8, gen_loss = 0.4227685511112213, disc_loss = 0.02049670135602355
Trained batch 5 in epoch 8, gen_loss = 0.4110039174556732, disc_loss = 0.018722887383773923
Trained batch 6 in epoch 8, gen_loss = 0.41584002120154245, disc_loss = 0.01651990254010473
Trained batch 7 in epoch 8, gen_loss = 0.4034319035708904, disc_loss = 0.015299262362532318
Trained batch 8 in epoch 8, gen_loss = 0.40423432654804653, disc_loss = 0.014020509759171141
Trained batch 9 in epoch 8, gen_loss = 0.39883665442466737, disc_loss = 0.013471651589497924
Trained batch 10 in epoch 8, gen_loss = 0.40112031318924646, disc_loss = 0.01256122842261737
Trained batch 11 in epoch 8, gen_loss = 0.4014483839273453, disc_loss = 0.01280073910796394
Trained batch 12 in epoch 8, gen_loss = 0.402404574247507, disc_loss = 0.013381910546181293
Trained batch 13 in epoch 8, gen_loss = 0.3933979272842407, disc_loss = 0.01911105598056955
Trained batch 14 in epoch 8, gen_loss = 0.4032191514968872, disc_loss = 0.053956720822801195
Trained batch 15 in epoch 8, gen_loss = 0.39765704050660133, disc_loss = 0.05469948015525006
Trained batch 16 in epoch 8, gen_loss = 0.39188402014620166, disc_loss = 0.054581512724432873
Trained batch 17 in epoch 8, gen_loss = 0.3904239485661189, disc_loss = 0.052765571900332965
Trained batch 18 in epoch 8, gen_loss = 0.39282093393175227, disc_loss = 0.05119515002067936
Trained batch 19 in epoch 8, gen_loss = 0.3919582337141037, disc_loss = 0.04982058561872691
Trained batch 20 in epoch 8, gen_loss = 0.390412137621925, disc_loss = 0.05122719605320266
Trained batch 21 in epoch 8, gen_loss = 0.39089214530858124, disc_loss = 0.0597007678271356
Trained batch 22 in epoch 8, gen_loss = 0.38967251518498297, disc_loss = 0.061953340272378664
Trained batch 23 in epoch 8, gen_loss = 0.3878496165076892, disc_loss = 0.062275216972921044
Trained batch 24 in epoch 8, gen_loss = 0.38922225952148437, disc_loss = 0.0604299203120172
Trained batch 25 in epoch 8, gen_loss = 0.39163714761917406, disc_loss = 0.058582202692587786
Trained batch 26 in epoch 8, gen_loss = 0.38872119784355164, disc_loss = 0.057214565178448404
Trained batch 27 in epoch 8, gen_loss = 0.38915508879082544, disc_loss = 0.056744606782948334
Trained batch 28 in epoch 8, gen_loss = 0.38819438938436834, disc_loss = 0.055082838709369815
Trained batch 29 in epoch 8, gen_loss = 0.38721179167429604, disc_loss = 0.05353242222530146
Trained batch 30 in epoch 8, gen_loss = 0.3900441921526386, disc_loss = 0.05220828801693936
Trained batch 31 in epoch 8, gen_loss = 0.3896927712485194, disc_loss = 0.050956601175130345
Trained batch 32 in epoch 8, gen_loss = 0.38877011067939526, disc_loss = 0.04975520925257693
Trained batch 33 in epoch 8, gen_loss = 0.39044036058818593, disc_loss = 0.04849832528270781
Trained batch 34 in epoch 8, gen_loss = 0.3890251466206142, disc_loss = 0.04877440675294825
Trained batch 35 in epoch 8, gen_loss = 0.3939264532592561, disc_loss = 0.052988689405740134
Trained batch 36 in epoch 8, gen_loss = 0.39409580424025253, disc_loss = 0.05237332380351585
Trained batch 37 in epoch 8, gen_loss = 0.3938287245599847, disc_loss = 0.05302134245683096
Trained batch 38 in epoch 8, gen_loss = 0.39429921217453784, disc_loss = 0.05449571375711224
Trained batch 39 in epoch 8, gen_loss = 0.3947212420403957, disc_loss = 0.05363198156701401
Trained batch 40 in epoch 8, gen_loss = 0.39296810874124855, disc_loss = 0.05345423911448296
Trained batch 41 in epoch 8, gen_loss = 0.3937205331666129, disc_loss = 0.052584517669553556
Trained batch 42 in epoch 8, gen_loss = 0.39493172321208686, disc_loss = 0.05332749987800801
Trained batch 43 in epoch 8, gen_loss = 0.3940317617221312, disc_loss = 0.06020048845940354
Trained batch 44 in epoch 8, gen_loss = 0.3956346962187025, disc_loss = 0.0629557825728423
Trained batch 45 in epoch 8, gen_loss = 0.39685833842858026, disc_loss = 0.06266026135088633
Trained batch 46 in epoch 8, gen_loss = 0.39705082393707114, disc_loss = 0.06179587238844722
Trained batch 47 in epoch 8, gen_loss = 0.3973743263632059, disc_loss = 0.060674715311809756
Trained batch 48 in epoch 8, gen_loss = 0.3992040923663548, disc_loss = 0.059609855819797636
Trained batch 49 in epoch 8, gen_loss = 0.3998411512374878, disc_loss = 0.0586914402525872
Trained batch 50 in epoch 8, gen_loss = 0.39880117832445633, disc_loss = 0.057753763499432335
Trained batch 51 in epoch 8, gen_loss = 0.3999361109275084, disc_loss = 0.05676666667792373
Trained batch 52 in epoch 8, gen_loss = 0.400931180085776, disc_loss = 0.05608547534266452
Trained batch 53 in epoch 8, gen_loss = 0.40140288240379757, disc_loss = 0.056958581139850945
Trained batch 54 in epoch 8, gen_loss = 0.39898424636233937, disc_loss = 0.05864855876531113
Trained batch 55 in epoch 8, gen_loss = 0.39941265167934553, disc_loss = 0.05794180868958522
Trained batch 56 in epoch 8, gen_loss = 0.4004367203043218, disc_loss = 0.05863871221969787
Trained batch 57 in epoch 8, gen_loss = 0.4001565683504631, disc_loss = 0.05832839223299304
Trained batch 58 in epoch 8, gen_loss = 0.40060799152164134, disc_loss = 0.0579721197028155
Trained batch 59 in epoch 8, gen_loss = 0.39991755535205203, disc_loss = 0.05740463341741512
Trained batch 60 in epoch 8, gen_loss = 0.4001138332437296, disc_loss = 0.05667284340979379
Trained batch 61 in epoch 8, gen_loss = 0.3994920998811722, disc_loss = 0.05603076922406833
Trained batch 62 in epoch 8, gen_loss = 0.3989412169607859, disc_loss = 0.055313254477426646
Trained batch 63 in epoch 8, gen_loss = 0.3984464379027486, disc_loss = 0.054522235615877435
Trained batch 64 in epoch 8, gen_loss = 0.39740814429063065, disc_loss = 0.05380032858453118
Trained batch 65 in epoch 8, gen_loss = 0.3969258828596635, disc_loss = 0.05329076318550065
Trained batch 66 in epoch 8, gen_loss = 0.3970113312130544, disc_loss = 0.052894623970974296
Trained batch 67 in epoch 8, gen_loss = 0.3981003809501143, disc_loss = 0.052216286442297345
Trained batch 68 in epoch 8, gen_loss = 0.39917140292084735, disc_loss = 0.05155957926172709
Trained batch 69 in epoch 8, gen_loss = 0.3995565806116377, disc_loss = 0.051052559473152674
Trained batch 70 in epoch 8, gen_loss = 0.4002644033499167, disc_loss = 0.05040329682942427
Trained batch 71 in epoch 8, gen_loss = 0.4000333460668723, disc_loss = 0.04985892317361302
Trained batch 72 in epoch 8, gen_loss = 0.40103427228862293, disc_loss = 0.04930975918390163
Trained batch 73 in epoch 8, gen_loss = 0.401833120632816, disc_loss = 0.04905840799816557
Trained batch 74 in epoch 8, gen_loss = 0.40090728203455606, disc_loss = 0.04846677089730898
Trained batch 75 in epoch 8, gen_loss = 0.4003290259524396, disc_loss = 0.04795673504275711
Trained batch 76 in epoch 8, gen_loss = 0.400354396987271, disc_loss = 0.04739540640579222
Trained batch 77 in epoch 8, gen_loss = 0.4002441947276776, disc_loss = 0.04719934831612194
Trained batch 78 in epoch 8, gen_loss = 0.39971086722386034, disc_loss = 0.04682546150811677
Trained batch 79 in epoch 8, gen_loss = 0.400230298936367, disc_loss = 0.04629451428190805
Trained batch 80 in epoch 8, gen_loss = 0.3994371556205514, disc_loss = 0.045787027594345955
Trained batch 81 in epoch 8, gen_loss = 0.400340571272664, disc_loss = 0.045636479589497535
Trained batch 82 in epoch 8, gen_loss = 0.3994749407452273, disc_loss = 0.046034531381699335
Trained batch 83 in epoch 8, gen_loss = 0.3997387598667826, disc_loss = 0.046283761177965926
Trained batch 84 in epoch 8, gen_loss = 0.3999403487233555, disc_loss = 0.046143639049328423
Trained batch 85 in epoch 8, gen_loss = 0.4005951212589131, disc_loss = 0.04597291987670889
Trained batch 86 in epoch 8, gen_loss = 0.401171556149406, disc_loss = 0.045869375359609554
Trained batch 87 in epoch 8, gen_loss = 0.4012579701163552, disc_loss = 0.045466216519178655
Trained batch 88 in epoch 8, gen_loss = 0.4015668433034018, disc_loss = 0.04523875918553284
Trained batch 89 in epoch 8, gen_loss = 0.4014525529411104, disc_loss = 0.045666744337520666
Trained batch 90 in epoch 8, gen_loss = 0.40064304968812964, disc_loss = 0.047480319089327865
Trained batch 91 in epoch 8, gen_loss = 0.40221314423758053, disc_loss = 0.047943310108562204
Trained batch 92 in epoch 8, gen_loss = 0.4024533949872499, disc_loss = 0.04755139243238235
Trained batch 93 in epoch 8, gen_loss = 0.4020005832327173, disc_loss = 0.04714962790046442
Trained batch 94 in epoch 8, gen_loss = 0.4024722648294348, disc_loss = 0.0467685499424605
Trained batch 95 in epoch 8, gen_loss = 0.4017722165832917, disc_loss = 0.04746751385876754
Trained batch 96 in epoch 8, gen_loss = 0.40292083664038747, disc_loss = 0.04972557546378872
Trained batch 97 in epoch 8, gen_loss = 0.4026561038834708, disc_loss = 0.049565659641117164
Trained batch 98 in epoch 8, gen_loss = 0.40229467460603424, disc_loss = 0.04952815411650021
Trained batch 99 in epoch 8, gen_loss = 0.40141810566186903, disc_loss = 0.05037285144906491
Trained batch 100 in epoch 8, gen_loss = 0.4013601104811867, disc_loss = 0.05226141475786519
Trained batch 101 in epoch 8, gen_loss = 0.40195804133134727, disc_loss = 0.05384972716645137
Trained batch 102 in epoch 8, gen_loss = 0.40212348045654667, disc_loss = 0.053665818262266594
Trained batch 103 in epoch 8, gen_loss = 0.4023038154611221, disc_loss = 0.053388723866261825
Trained batch 104 in epoch 8, gen_loss = 0.4017742545831771, disc_loss = 0.05333935676497363
Trained batch 105 in epoch 8, gen_loss = 0.40194150917934923, disc_loss = 0.05424314569945465
Trained batch 106 in epoch 8, gen_loss = 0.40123873949050903, disc_loss = 0.05560072004429509
Trained batch 107 in epoch 8, gen_loss = 0.40115370270278716, disc_loss = 0.05539710907248297
Trained batch 108 in epoch 8, gen_loss = 0.4012897561449523, disc_loss = 0.0551915256725197
Trained batch 109 in epoch 8, gen_loss = 0.4014620396223935, disc_loss = 0.055125804562968284
Trained batch 110 in epoch 8, gen_loss = 0.4019075656259382, disc_loss = 0.05470671499282256
Trained batch 111 in epoch 8, gen_loss = 0.4019686454640968, disc_loss = 0.05447459059152087
Trained batch 112 in epoch 8, gen_loss = 0.40233565405406785, disc_loss = 0.054059078723225185
Trained batch 113 in epoch 8, gen_loss = 0.40159181074092265, disc_loss = 0.05363580089046113
Trained batch 114 in epoch 8, gen_loss = 0.40200826396112854, disc_loss = 0.05333096531989134
Trained batch 115 in epoch 8, gen_loss = 0.40171738020304976, disc_loss = 0.05300259459683479
Trained batch 116 in epoch 8, gen_loss = 0.4014345759000534, disc_loss = 0.05259483757739266
Trained batch 117 in epoch 8, gen_loss = 0.40123245221073345, disc_loss = 0.05237515401331929
Trained batch 118 in epoch 8, gen_loss = 0.40094980572452066, disc_loss = 0.05211730720475316
Trained batch 119 in epoch 8, gen_loss = 0.4007994122803211, disc_loss = 0.05193901299110924
Trained batch 120 in epoch 8, gen_loss = 0.40075940952813327, disc_loss = 0.0517761187727971
Trained batch 121 in epoch 8, gen_loss = 0.4011841648426212, disc_loss = 0.05164144140454467
Trained batch 122 in epoch 8, gen_loss = 0.40094752694533126, disc_loss = 0.051322680598927466
Trained batch 123 in epoch 8, gen_loss = 0.4015948320588758, disc_loss = 0.050959923443564724
Trained batch 124 in epoch 8, gen_loss = 0.40118128681182863, disc_loss = 0.05068282881751657
Trained batch 125 in epoch 8, gen_loss = 0.4016040691307613, disc_loss = 0.050564208500353355
Trained batch 126 in epoch 8, gen_loss = 0.4018835261112123, disc_loss = 0.050492681625233155
Trained batch 127 in epoch 8, gen_loss = 0.4013230598066002, disc_loss = 0.050995384579437086
Trained batch 128 in epoch 8, gen_loss = 0.4016389779804289, disc_loss = 0.05068851038163831
Trained batch 129 in epoch 8, gen_loss = 0.40170685442594384, disc_loss = 0.05132743900713439
Trained batch 130 in epoch 8, gen_loss = 0.4009500669159052, disc_loss = 0.05191474494289692
Trained batch 131 in epoch 8, gen_loss = 0.40086181010260724, disc_loss = 0.05157804145534156
Trained batch 132 in epoch 8, gen_loss = 0.4008253266040544, disc_loss = 0.0513279248463144
Trained batch 133 in epoch 8, gen_loss = 0.40101000066123793, disc_loss = 0.05105873167431399
Trained batch 134 in epoch 8, gen_loss = 0.40075468553437127, disc_loss = 0.05080310789937222
Trained batch 135 in epoch 8, gen_loss = 0.40060001677450013, disc_loss = 0.050525806878474265
Trained batch 136 in epoch 8, gen_loss = 0.4002951927428698, disc_loss = 0.050310916294527316
Trained batch 137 in epoch 8, gen_loss = 0.4007894584666128, disc_loss = 0.04997952994418101
Trained batch 138 in epoch 8, gen_loss = 0.4012576420958951, disc_loss = 0.049752773375337504
Trained batch 139 in epoch 8, gen_loss = 0.4020200808133398, disc_loss = 0.049421533942222595
Trained batch 140 in epoch 8, gen_loss = 0.402427649667077, disc_loss = 0.049118022850536285
Trained batch 141 in epoch 8, gen_loss = 0.40261016492272766, disc_loss = 0.048843200921907394
Trained batch 142 in epoch 8, gen_loss = 0.4026853081646499, disc_loss = 0.048557662522303056
Trained batch 143 in epoch 8, gen_loss = 0.4025947896556722, disc_loss = 0.04824186831117711
Trained batch 144 in epoch 8, gen_loss = 0.40213729656975844, disc_loss = 0.047944371068272096
Trained batch 145 in epoch 8, gen_loss = 0.4022586074185698, disc_loss = 0.04771851098215948
Trained batch 146 in epoch 8, gen_loss = 0.40167331959114594, disc_loss = 0.04781022397357793
Trained batch 147 in epoch 8, gen_loss = 0.4021817274593018, disc_loss = 0.047918807041856484
Trained batch 148 in epoch 8, gen_loss = 0.4020808221109761, disc_loss = 0.047639503565635656
Trained batch 149 in epoch 8, gen_loss = 0.40277237236499785, disc_loss = 0.04736880504215757
Trained batch 150 in epoch 8, gen_loss = 0.40258128931190795, disc_loss = 0.04728021779227139
Trained batch 151 in epoch 8, gen_loss = 0.40300419260012477, disc_loss = 0.04708542964592772
Trained batch 152 in epoch 8, gen_loss = 0.4030851328295041, disc_loss = 0.047129354792726195
Trained batch 153 in epoch 8, gen_loss = 0.4024279849095778, disc_loss = 0.04710255031679551
Trained batch 154 in epoch 8, gen_loss = 0.40251233789228624, disc_loss = 0.04707513142136797
Trained batch 155 in epoch 8, gen_loss = 0.40250841126992154, disc_loss = 0.047263813593114413
Trained batch 156 in epoch 8, gen_loss = 0.4019776937688232, disc_loss = 0.047259667811167846
Trained batch 157 in epoch 8, gen_loss = 0.4022045490107959, disc_loss = 0.04704598728213695
Trained batch 158 in epoch 8, gen_loss = 0.40239478300952314, disc_loss = 0.046796440668169806
Trained batch 159 in epoch 8, gen_loss = 0.4025435533374548, disc_loss = 0.04662731783464551
Trained batch 160 in epoch 8, gen_loss = 0.40262445659370893, disc_loss = 0.04681887199974948
Trained batch 161 in epoch 8, gen_loss = 0.40267699975290416, disc_loss = 0.04676347032741264
Trained batch 162 in epoch 8, gen_loss = 0.40230567305365955, disc_loss = 0.046627007070585993
Trained batch 163 in epoch 8, gen_loss = 0.40186874859216737, disc_loss = 0.04652873066640118
Trained batch 164 in epoch 8, gen_loss = 0.40167652531103654, disc_loss = 0.046485475010492584
Trained batch 165 in epoch 8, gen_loss = 0.40169048255466555, disc_loss = 0.04629730933110218
Trained batch 166 in epoch 8, gen_loss = 0.40177632573835864, disc_loss = 0.04610724884369773
Trained batch 167 in epoch 8, gen_loss = 0.40181626485926764, disc_loss = 0.04587538187514015
Trained batch 168 in epoch 8, gen_loss = 0.40161134293798867, disc_loss = 0.045674347971736855
Trained batch 169 in epoch 8, gen_loss = 0.401773722206845, disc_loss = 0.04545431851738078
Trained batch 170 in epoch 8, gen_loss = 0.40185115996160004, disc_loss = 0.045345277849541246
Trained batch 171 in epoch 8, gen_loss = 0.4013320216259291, disc_loss = 0.045534451765571395
Trained batch 172 in epoch 8, gen_loss = 0.40128140763051245, disc_loss = 0.045931691112739675
Trained batch 173 in epoch 8, gen_loss = 0.4016933874494728, disc_loss = 0.04574032044626944
Trained batch 174 in epoch 8, gen_loss = 0.40167223504611427, disc_loss = 0.04581629138173802
Trained batch 175 in epoch 8, gen_loss = 0.4018732984973626, disc_loss = 0.045738449598006395
Trained batch 176 in epoch 8, gen_loss = 0.40209456099628726, disc_loss = 0.04550802507990245
Trained batch 177 in epoch 8, gen_loss = 0.4025154281198309, disc_loss = 0.04529277398250997
Trained batch 178 in epoch 8, gen_loss = 0.4022868899992724, disc_loss = 0.04519533654987063
Trained batch 179 in epoch 8, gen_loss = 0.4024784295095338, disc_loss = 0.045073192977967365
Trained batch 180 in epoch 8, gen_loss = 0.40260606608996735, disc_loss = 0.04484485249544458
Trained batch 181 in epoch 8, gen_loss = 0.40249138382764965, disc_loss = 0.04461731883482291
Trained batch 182 in epoch 8, gen_loss = 0.40234770638043765, disc_loss = 0.044451666110363164
Trained batch 183 in epoch 8, gen_loss = 0.4024463148544664, disc_loss = 0.04427313136503748
Trained batch 184 in epoch 8, gen_loss = 0.40243320481197253, disc_loss = 0.0440849557518959
Trained batch 185 in epoch 8, gen_loss = 0.40238921921099385, disc_loss = 0.043888099511624666
Trained batch 186 in epoch 8, gen_loss = 0.40226707563680764, disc_loss = 0.04371552391445892
Trained batch 187 in epoch 8, gen_loss = 0.40201387823896206, disc_loss = 0.0438612294383347
Trained batch 188 in epoch 8, gen_loss = 0.4023887729518628, disc_loss = 0.04395202905057915
Trained batch 189 in epoch 8, gen_loss = 0.402843944963656, disc_loss = 0.0437578339913958
Trained batch 190 in epoch 8, gen_loss = 0.40260622373426147, disc_loss = 0.04367421026200212
Trained batch 191 in epoch 8, gen_loss = 0.4029511013068259, disc_loss = 0.04347470520588104
Trained batch 192 in epoch 8, gen_loss = 0.40252666847075824, disc_loss = 0.043288957494084235
Trained batch 193 in epoch 8, gen_loss = 0.4025688132981664, disc_loss = 0.04311633494817028
Trained batch 194 in epoch 8, gen_loss = 0.4023789298840058, disc_loss = 0.0429424523232648
Trained batch 195 in epoch 8, gen_loss = 0.40211539685117953, disc_loss = 0.0427748030360446
Trained batch 196 in epoch 8, gen_loss = 0.4017444505606811, disc_loss = 0.04259925152454053
Trained batch 197 in epoch 8, gen_loss = 0.40222089850541315, disc_loss = 0.04259202763146599
Trained batch 198 in epoch 8, gen_loss = 0.40198475092499697, disc_loss = 0.04253465074100461
Trained batch 199 in epoch 8, gen_loss = 0.40209365710616113, disc_loss = 0.04241028186166659
Trained batch 200 in epoch 8, gen_loss = 0.4022020933343403, disc_loss = 0.04228711818849937
Trained batch 201 in epoch 8, gen_loss = 0.40214655437681934, disc_loss = 0.042096492949651905
Trained batch 202 in epoch 8, gen_loss = 0.4018836276871817, disc_loss = 0.04191371529211699
Trained batch 203 in epoch 8, gen_loss = 0.4020364036162694, disc_loss = 0.041734849246602285
Trained batch 204 in epoch 8, gen_loss = 0.40254107422944974, disc_loss = 0.04155766200047077
Trained batch 205 in epoch 8, gen_loss = 0.4023540365753822, disc_loss = 0.04137421093510409
Trained batch 206 in epoch 8, gen_loss = 0.4026921525381614, disc_loss = 0.04120133643753934
Trained batch 207 in epoch 8, gen_loss = 0.4027206569623489, disc_loss = 0.04103804843124145
Trained batch 208 in epoch 8, gen_loss = 0.40272747400845066, disc_loss = 0.04091406977650794
Trained batch 209 in epoch 8, gen_loss = 0.402910335007168, disc_loss = 0.040753963308054066
Trained batch 210 in epoch 8, gen_loss = 0.40294737428850474, disc_loss = 0.04057915422677005
Trained batch 211 in epoch 8, gen_loss = 0.4029693343448189, disc_loss = 0.040486116072092695
Trained batch 212 in epoch 8, gen_loss = 0.40282768990512186, disc_loss = 0.04032351944525617
Trained batch 213 in epoch 8, gen_loss = 0.4028338802473567, disc_loss = 0.04017536496203915
Trained batch 214 in epoch 8, gen_loss = 0.4027458146561024, disc_loss = 0.04001317534942266
Trained batch 215 in epoch 8, gen_loss = 0.4028819577285537, disc_loss = 0.03988093217507143
Trained batch 216 in epoch 8, gen_loss = 0.40252572284316135, disc_loss = 0.040162013564687994
Trained batch 217 in epoch 8, gen_loss = 0.4027713131193721, disc_loss = 0.04061247531854368
Trained batch 218 in epoch 8, gen_loss = 0.40270783408591737, disc_loss = 0.04046766943464132
Trained batch 219 in epoch 8, gen_loss = 0.40236626768654044, disc_loss = 0.040439378169619226
Trained batch 220 in epoch 8, gen_loss = 0.4023814670640419, disc_loss = 0.040279388596299544
Trained batch 221 in epoch 8, gen_loss = 0.40210357013049425, disc_loss = 0.040140105163896676
Trained batch 222 in epoch 8, gen_loss = 0.4020564119110193, disc_loss = 0.04001246393562165
Trained batch 223 in epoch 8, gen_loss = 0.40226806367614437, disc_loss = 0.04004028723076252
Trained batch 224 in epoch 8, gen_loss = 0.4021646049287584, disc_loss = 0.039879028488778404
Trained batch 225 in epoch 8, gen_loss = 0.402300134564923, disc_loss = 0.03972778514241882
Trained batch 226 in epoch 8, gen_loss = 0.40227703310319507, disc_loss = 0.03960730783263886
Trained batch 227 in epoch 8, gen_loss = 0.402252059364528, disc_loss = 0.03949324784212207
Trained batch 228 in epoch 8, gen_loss = 0.4022064525227359, disc_loss = 0.039394409725174113
Trained batch 229 in epoch 8, gen_loss = 0.4021107746207196, disc_loss = 0.03939348202522682
Trained batch 230 in epoch 8, gen_loss = 0.4019494757249758, disc_loss = 0.03932936317025325
Trained batch 231 in epoch 8, gen_loss = 0.4017757281404117, disc_loss = 0.039703771359576236
Trained batch 232 in epoch 8, gen_loss = 0.40229486920291263, disc_loss = 0.039841316176714305
Trained batch 233 in epoch 8, gen_loss = 0.4024910663182919, disc_loss = 0.04061514650208828
Trained batch 234 in epoch 8, gen_loss = 0.40205347905767724, disc_loss = 0.040828992410543115
Trained batch 235 in epoch 8, gen_loss = 0.4018767095975957, disc_loss = 0.04083740466542668
Trained batch 236 in epoch 8, gen_loss = 0.4018899936716265, disc_loss = 0.040853339298490735
Trained batch 237 in epoch 8, gen_loss = 0.4020582162031606, disc_loss = 0.040997133238100204
Trained batch 238 in epoch 8, gen_loss = 0.40170564586647384, disc_loss = 0.04211041339084693
Trained batch 239 in epoch 8, gen_loss = 0.4014626937607924, disc_loss = 0.043292940982306995
Trained batch 240 in epoch 8, gen_loss = 0.40120192137991245, disc_loss = 0.04358966885080476
Trained batch 241 in epoch 8, gen_loss = 0.40095491350189716, disc_loss = 0.04371327224903363
Trained batch 242 in epoch 8, gen_loss = 0.4007039050506466, disc_loss = 0.043783704915041785
Trained batch 243 in epoch 8, gen_loss = 0.40108967511380306, disc_loss = 0.04413453842223179
Trained batch 244 in epoch 8, gen_loss = 0.4008754282581563, disc_loss = 0.04556170517996866
Trained batch 245 in epoch 8, gen_loss = 0.40080087008030435, disc_loss = 0.045920063673359594
Trained batch 246 in epoch 8, gen_loss = 0.4008646512079818, disc_loss = 0.04626279603312855
Trained batch 247 in epoch 8, gen_loss = 0.4010718378328508, disc_loss = 0.04643448879341445
Trained batch 248 in epoch 8, gen_loss = 0.40088428981811647, disc_loss = 0.046419548177455805
Trained batch 249 in epoch 8, gen_loss = 0.4009221309423447, disc_loss = 0.046401392579078674
Trained batch 250 in epoch 8, gen_loss = 0.40069636310714174, disc_loss = 0.046350735755436925
Trained batch 251 in epoch 8, gen_loss = 0.40072729391238043, disc_loss = 0.04676952318007511
Trained batch 252 in epoch 8, gen_loss = 0.4007057805541947, disc_loss = 0.04753566440562957
Trained batch 253 in epoch 8, gen_loss = 0.400900736451149, disc_loss = 0.047466910048204615
Trained batch 254 in epoch 8, gen_loss = 0.4012853202866573, disc_loss = 0.04739662874124798
Trained batch 255 in epoch 8, gen_loss = 0.40144717402290553, disc_loss = 0.047270857845433056
Trained batch 256 in epoch 8, gen_loss = 0.40121354585955576, disc_loss = 0.04715641229938904
Trained batch 257 in epoch 8, gen_loss = 0.4010362630897714, disc_loss = 0.04701742010061131
Trained batch 258 in epoch 8, gen_loss = 0.40084460067012595, disc_loss = 0.04713236974933433
Trained batch 259 in epoch 8, gen_loss = 0.4007514958198254, disc_loss = 0.047379448666022374
Trained batch 260 in epoch 8, gen_loss = 0.4005383202856071, disc_loss = 0.04751985063383862
Trained batch 261 in epoch 8, gen_loss = 0.40061092376708984, disc_loss = 0.04769564553640271
Trained batch 262 in epoch 8, gen_loss = 0.4006378238192076, disc_loss = 0.04763452194546112
Trained batch 263 in epoch 8, gen_loss = 0.40067991986870766, disc_loss = 0.04747762172976791
Trained batch 264 in epoch 8, gen_loss = 0.4007796527079816, disc_loss = 0.047440047495348275
Trained batch 265 in epoch 8, gen_loss = 0.4007468613466822, disc_loss = 0.04772293112849943
Trained batch 266 in epoch 8, gen_loss = 0.4008606987053089, disc_loss = 0.04771566641087947
Trained batch 267 in epoch 8, gen_loss = 0.40118804062480357, disc_loss = 0.0476520274619836
Trained batch 268 in epoch 8, gen_loss = 0.40091525588780086, disc_loss = 0.04790260891004233
Trained batch 269 in epoch 8, gen_loss = 0.4011141717433929, disc_loss = 0.048118107286454354
Trained batch 270 in epoch 8, gen_loss = 0.4010753509523244, disc_loss = 0.04798946745789909
Trained batch 271 in epoch 8, gen_loss = 0.4010102289783604, disc_loss = 0.04788941856103895
Trained batch 272 in epoch 8, gen_loss = 0.4010182043789944, disc_loss = 0.04789246348902965
Trained batch 273 in epoch 8, gen_loss = 0.4011467798565426, disc_loss = 0.04818056945614245
Trained batch 274 in epoch 8, gen_loss = 0.40067396207289263, disc_loss = 0.048394690728323024
Trained batch 275 in epoch 8, gen_loss = 0.40052588845508685, disc_loss = 0.048451033437732556
Trained batch 276 in epoch 8, gen_loss = 0.40050646824096514, disc_loss = 0.04831620136995393
Trained batch 277 in epoch 8, gen_loss = 0.40053395605344566, disc_loss = 0.048177030021257755
Trained batch 278 in epoch 8, gen_loss = 0.40077512153160616, disc_loss = 0.04805931032344859
Trained batch 279 in epoch 8, gen_loss = 0.4007591491299016, disc_loss = 0.04790626750992877
Trained batch 280 in epoch 8, gen_loss = 0.4008094370365143, disc_loss = 0.04782114244891443
Trained batch 281 in epoch 8, gen_loss = 0.40103173319329605, disc_loss = 0.04785108387285302
Trained batch 282 in epoch 8, gen_loss = 0.40104832581833477, disc_loss = 0.04773313857865102
Trained batch 283 in epoch 8, gen_loss = 0.4008013684774788, disc_loss = 0.04797215193418235
Trained batch 284 in epoch 8, gen_loss = 0.40092418999002694, disc_loss = 0.04887013487975325
Trained batch 285 in epoch 8, gen_loss = 0.40043402385044763, disc_loss = 0.04962520687222168
Trained batch 286 in epoch 8, gen_loss = 0.4004430284898871, disc_loss = 0.049663910054916494
Trained batch 287 in epoch 8, gen_loss = 0.40044468744761413, disc_loss = 0.04963065146067594
Trained batch 288 in epoch 8, gen_loss = 0.4001895517213947, disc_loss = 0.049885438133198706
Trained batch 289 in epoch 8, gen_loss = 0.39995529672195174, disc_loss = 0.04984312566511076
Trained batch 290 in epoch 8, gen_loss = 0.3998808155149938, disc_loss = 0.04976841686709538
Trained batch 291 in epoch 8, gen_loss = 0.3998956759906795, disc_loss = 0.04988054747131895
Trained batch 292 in epoch 8, gen_loss = 0.3996867973853297, disc_loss = 0.04978929753431179
Trained batch 293 in epoch 8, gen_loss = 0.4000551306268796, disc_loss = 0.05017177748880317
Trained batch 294 in epoch 8, gen_loss = 0.3999147571749606, disc_loss = 0.05013988621343495
Trained batch 295 in epoch 8, gen_loss = 0.3997959454317351, disc_loss = 0.05003529275780091
Trained batch 296 in epoch 8, gen_loss = 0.399797703782316, disc_loss = 0.049991227394778924
Trained batch 297 in epoch 8, gen_loss = 0.39976310169936824, disc_loss = 0.049894989246265
Trained batch 298 in epoch 8, gen_loss = 0.3997869181593126, disc_loss = 0.0497574635180193
Trained batch 299 in epoch 8, gen_loss = 0.39975293189287187, disc_loss = 0.04965472625258068
Trained batch 300 in epoch 8, gen_loss = 0.39995635219190606, disc_loss = 0.049573985206897674
Trained batch 301 in epoch 8, gen_loss = 0.39977196066190074, disc_loss = 0.04950863628383011
Trained batch 302 in epoch 8, gen_loss = 0.3995243550920644, disc_loss = 0.04945502034004274
Trained batch 303 in epoch 8, gen_loss = 0.39950677419179365, disc_loss = 0.04942723440533308
Trained batch 304 in epoch 8, gen_loss = 0.3997328622419326, disc_loss = 0.049282883666455744
Trained batch 305 in epoch 8, gen_loss = 0.3997475752253938, disc_loss = 0.04967020383542951
Trained batch 306 in epoch 8, gen_loss = 0.399871364284416, disc_loss = 0.049941228438739084
Trained batch 307 in epoch 8, gen_loss = 0.39986835226610107, disc_loss = 0.04988611999645152
Trained batch 308 in epoch 8, gen_loss = 0.3995216698129586, disc_loss = 0.05006289291331201
Trained batch 309 in epoch 8, gen_loss = 0.39978839572398894, disc_loss = 0.049958593942104806
Trained batch 310 in epoch 8, gen_loss = 0.3998217473459397, disc_loss = 0.049831218056237005
Trained batch 311 in epoch 8, gen_loss = 0.39995404437948495, disc_loss = 0.049692744348878756
Trained batch 312 in epoch 8, gen_loss = 0.39998856977151986, disc_loss = 0.04954736916788708
Trained batch 313 in epoch 8, gen_loss = 0.4001088420486754, disc_loss = 0.04943010050975451
Trained batch 314 in epoch 8, gen_loss = 0.40005898381036425, disc_loss = 0.04934280890941856
Trained batch 315 in epoch 8, gen_loss = 0.399897385247146, disc_loss = 0.04933149212104846
Trained batch 316 in epoch 8, gen_loss = 0.39996434705866624, disc_loss = 0.04934504516687162
Trained batch 317 in epoch 8, gen_loss = 0.39988721494779644, disc_loss = 0.04923003884003082
Trained batch 318 in epoch 8, gen_loss = 0.3998584942571048, disc_loss = 0.04915335309782232
Trained batch 319 in epoch 8, gen_loss = 0.40002225851640105, disc_loss = 0.049032096676819494
Trained batch 320 in epoch 8, gen_loss = 0.4000488632007551, disc_loss = 0.04899392947351496
Trained batch 321 in epoch 8, gen_loss = 0.3999451172092687, disc_loss = 0.04894676282336669
Trained batch 322 in epoch 8, gen_loss = 0.40007377575056474, disc_loss = 0.04883435090726974
Trained batch 323 in epoch 8, gen_loss = 0.4000400913718306, disc_loss = 0.04872781183875315
Trained batch 324 in epoch 8, gen_loss = 0.39999575147261984, disc_loss = 0.04859070226693383
Trained batch 325 in epoch 8, gen_loss = 0.3996953742087253, disc_loss = 0.04848379081406522
Trained batch 326 in epoch 8, gen_loss = 0.3995622982490318, disc_loss = 0.048366003765209095
Trained batch 327 in epoch 8, gen_loss = 0.3995880175654481, disc_loss = 0.04824108883267178
Trained batch 328 in epoch 8, gen_loss = 0.3999596176538786, disc_loss = 0.04812544996858685
Trained batch 329 in epoch 8, gen_loss = 0.3999255533471252, disc_loss = 0.04801937124240353
Trained batch 330 in epoch 8, gen_loss = 0.39987718032566083, disc_loss = 0.04797409139883077
Trained batch 331 in epoch 8, gen_loss = 0.40004028344010734, disc_loss = 0.047988431420210885
Trained batch 332 in epoch 8, gen_loss = 0.4000690575834509, disc_loss = 0.047886840209040465
Trained batch 333 in epoch 8, gen_loss = 0.4000884052700625, disc_loss = 0.04776212166085795
Trained batch 334 in epoch 8, gen_loss = 0.40011993699999, disc_loss = 0.04765639460937523
Trained batch 335 in epoch 8, gen_loss = 0.4002310384419702, disc_loss = 0.047529267926057356
Trained batch 336 in epoch 8, gen_loss = 0.4003475041347017, disc_loss = 0.047406479047517394
Trained batch 337 in epoch 8, gen_loss = 0.4002744461128698, disc_loss = 0.04731944961109634
Trained batch 338 in epoch 8, gen_loss = 0.40031603822665934, disc_loss = 0.04724287321917427
Trained batch 339 in epoch 8, gen_loss = 0.40052635152550303, disc_loss = 0.047167255921179756
Trained batch 340 in epoch 8, gen_loss = 0.40020444989204407, disc_loss = 0.047074040523634626
Trained batch 341 in epoch 8, gen_loss = 0.4001675534840913, disc_loss = 0.046980381104550516
Trained batch 342 in epoch 8, gen_loss = 0.40014069864075663, disc_loss = 0.04687756086012712
Trained batch 343 in epoch 8, gen_loss = 0.4001546604342239, disc_loss = 0.04675820709725972
Trained batch 344 in epoch 8, gen_loss = 0.4003246720286383, disc_loss = 0.04663653292463742
Trained batch 345 in epoch 8, gen_loss = 0.4004875650640168, disc_loss = 0.04651398689760638
Trained batch 346 in epoch 8, gen_loss = 0.4005444466380633, disc_loss = 0.046408890169489625
Trained batch 347 in epoch 8, gen_loss = 0.400292471136855, disc_loss = 0.04630309655384599
Trained batch 348 in epoch 8, gen_loss = 0.4004133662214252, disc_loss = 0.046179651358114145
Trained batch 349 in epoch 8, gen_loss = 0.40043782276766643, disc_loss = 0.04605614420425679
Trained batch 350 in epoch 8, gen_loss = 0.40039028070251487, disc_loss = 0.04594013659400266
Trained batch 351 in epoch 8, gen_loss = 0.40023714905096724, disc_loss = 0.045819655558840496
Trained batch 352 in epoch 8, gen_loss = 0.4002834513741242, disc_loss = 0.045700424239329636
Trained batch 353 in epoch 8, gen_loss = 0.40021521627566237, disc_loss = 0.04558443011502909
Trained batch 354 in epoch 8, gen_loss = 0.4002216440691075, disc_loss = 0.04546495614061788
Trained batch 355 in epoch 8, gen_loss = 0.4001783739482419, disc_loss = 0.045355946907977666
Trained batch 356 in epoch 8, gen_loss = 0.40025294820467633, disc_loss = 0.04526464063974217
Trained batch 357 in epoch 8, gen_loss = 0.4002247148885407, disc_loss = 0.045163281047950865
Trained batch 358 in epoch 8, gen_loss = 0.4001833782388639, disc_loss = 0.045050996427701835
Trained batch 359 in epoch 8, gen_loss = 0.4002766561177042, disc_loss = 0.0449390913948365
Trained batch 360 in epoch 8, gen_loss = 0.40040524877669736, disc_loss = 0.044825050358755975
Trained batch 361 in epoch 8, gen_loss = 0.40065215577407437, disc_loss = 0.0447132429667589
Trained batch 362 in epoch 8, gen_loss = 0.4007099604146868, disc_loss = 0.044606861684692016
Trained batch 363 in epoch 8, gen_loss = 0.40068872633216146, disc_loss = 0.04449449727889969
Trained batch 364 in epoch 8, gen_loss = 0.40070361731803583, disc_loss = 0.04441640236325664
Trained batch 365 in epoch 8, gen_loss = 0.40090926537096827, disc_loss = 0.04433048036982575
Trained batch 366 in epoch 8, gen_loss = 0.4008814261297439, disc_loss = 0.04422944713617378
Trained batch 367 in epoch 8, gen_loss = 0.40099957318085694, disc_loss = 0.04412351301036087
Trained batch 368 in epoch 8, gen_loss = 0.40105740059682027, disc_loss = 0.04410403374668342
Trained batch 369 in epoch 8, gen_loss = 0.40136416401412034, disc_loss = 0.04403239129539076
Trained batch 370 in epoch 8, gen_loss = 0.4013611797213233, disc_loss = 0.04392112377338172
Trained batch 371 in epoch 8, gen_loss = 0.4012803799042138, disc_loss = 0.04381627329595147
Trained batch 372 in epoch 8, gen_loss = 0.4014287797119918, disc_loss = 0.04371026206147375
Trained batch 373 in epoch 8, gen_loss = 0.40123145138834887, disc_loss = 0.04364220282426452
Trained batch 374 in epoch 8, gen_loss = 0.40149500711758934, disc_loss = 0.04364631490285198
Trained batch 375 in epoch 8, gen_loss = 0.40139615876560514, disc_loss = 0.04382656312899347
Trained batch 376 in epoch 8, gen_loss = 0.4014931516400699, disc_loss = 0.044252148084589514
Trained batch 377 in epoch 8, gen_loss = 0.40128392564556586, disc_loss = 0.04427779419963598
Trained batch 378 in epoch 8, gen_loss = 0.40122275797547013, disc_loss = 0.04420998274154548
Trained batch 379 in epoch 8, gen_loss = 0.40113763487652726, disc_loss = 0.044152112627450966
Trained batch 380 in epoch 8, gen_loss = 0.4012362171658694, disc_loss = 0.044236956568791716
Trained batch 381 in epoch 8, gen_loss = 0.40109145750550074, disc_loss = 0.045060121760269654
Trained batch 382 in epoch 8, gen_loss = 0.4011323581943313, disc_loss = 0.045463798512940544
Trained batch 383 in epoch 8, gen_loss = 0.40116783099559444, disc_loss = 0.045620613992165694
Trained batch 384 in epoch 8, gen_loss = 0.40108343277658737, disc_loss = 0.045719413970923654
Trained batch 385 in epoch 8, gen_loss = 0.4008057940500388, disc_loss = 0.0457618788374501
Trained batch 386 in epoch 8, gen_loss = 0.40090287625019555, disc_loss = 0.04601304284934657
Trained batch 387 in epoch 8, gen_loss = 0.40066113338335274, disc_loss = 0.046248927538417584
Trained batch 388 in epoch 8, gen_loss = 0.40066910333988903, disc_loss = 0.04618537888424064
Trained batch 389 in epoch 8, gen_loss = 0.40072045364441017, disc_loss = 0.04637172117900963
Trained batch 390 in epoch 8, gen_loss = 0.40061795848714726, disc_loss = 0.04663488001007673
Trained batch 391 in epoch 8, gen_loss = 0.40065009565073617, disc_loss = 0.046619396075862934
Trained batch 392 in epoch 8, gen_loss = 0.4006271887068227, disc_loss = 0.046535419919895384
Trained batch 393 in epoch 8, gen_loss = 0.40027336859461016, disc_loss = 0.04647051894134336
Trained batch 394 in epoch 8, gen_loss = 0.4001465362838552, disc_loss = 0.046416607964783904
Trained batch 395 in epoch 8, gen_loss = 0.40010485308940963, disc_loss = 0.04639490676286508
Trained batch 396 in epoch 8, gen_loss = 0.4001371640552501, disc_loss = 0.04637471185199522
Trained batch 397 in epoch 8, gen_loss = 0.40013468969407395, disc_loss = 0.046288956484368926
Trained batch 398 in epoch 8, gen_loss = 0.4000016707077361, disc_loss = 0.04620948007545039
Trained batch 399 in epoch 8, gen_loss = 0.399926031306386, disc_loss = 0.04610815024585463
Trained batch 400 in epoch 8, gen_loss = 0.4001561296996928, disc_loss = 0.04604212630498328
Trained batch 401 in epoch 8, gen_loss = 0.4001045363459421, disc_loss = 0.04594693780501387
Trained batch 402 in epoch 8, gen_loss = 0.3999308519268746, disc_loss = 0.04590734277410483
Trained batch 403 in epoch 8, gen_loss = 0.3999911374827423, disc_loss = 0.04586051307194451
Trained batch 404 in epoch 8, gen_loss = 0.4000128440650893, disc_loss = 0.04577955204165644
Trained batch 405 in epoch 8, gen_loss = 0.3998745069127952, disc_loss = 0.04572468971962045
Trained batch 406 in epoch 8, gen_loss = 0.3997739500729985, disc_loss = 0.04564952358823151
Trained batch 407 in epoch 8, gen_loss = 0.3997159388427641, disc_loss = 0.045602890293059105
Trained batch 408 in epoch 8, gen_loss = 0.39974106975755946, disc_loss = 0.04551141758729456
Trained batch 409 in epoch 8, gen_loss = 0.3997411764976455, disc_loss = 0.04543498166178058
Trained batch 410 in epoch 8, gen_loss = 0.39977655097515913, disc_loss = 0.04533524487004446
Trained batch 411 in epoch 8, gen_loss = 0.3997232836571712, disc_loss = 0.0452495995248912
Trained batch 412 in epoch 8, gen_loss = 0.39977200534961416, disc_loss = 0.04515899716454759
Trained batch 413 in epoch 8, gen_loss = 0.3996377715454009, disc_loss = 0.04505844918250642
Trained batch 414 in epoch 8, gen_loss = 0.3996878249099456, disc_loss = 0.045038505761424104
Trained batch 415 in epoch 8, gen_loss = 0.39971106291676944, disc_loss = 0.04498099948642238
Trained batch 416 in epoch 8, gen_loss = 0.39964756512527555, disc_loss = 0.04492851377216925
Trained batch 417 in epoch 8, gen_loss = 0.39964234700613616, disc_loss = 0.0448579830685675
Trained batch 418 in epoch 8, gen_loss = 0.3996854299292644, disc_loss = 0.044808346285820366
Trained batch 419 in epoch 8, gen_loss = 0.39980702556314923, disc_loss = 0.044755826275130466
Trained batch 420 in epoch 8, gen_loss = 0.399814726833493, disc_loss = 0.04469219338250592
Trained batch 421 in epoch 8, gen_loss = 0.39996260058540867, disc_loss = 0.044596290060261626
Trained batch 422 in epoch 8, gen_loss = 0.40001084752398464, disc_loss = 0.044506592452570125
Trained batch 423 in epoch 8, gen_loss = 0.4000909315105879, disc_loss = 0.04444442930706021
Trained batch 424 in epoch 8, gen_loss = 0.4000904954180998, disc_loss = 0.044358961285256286
Trained batch 425 in epoch 8, gen_loss = 0.39988276285464774, disc_loss = 0.04431296359122394
Trained batch 426 in epoch 8, gen_loss = 0.39983962800798706, disc_loss = 0.04427384575654423
Trained batch 427 in epoch 8, gen_loss = 0.3997489319087189, disc_loss = 0.04419132082823177
Trained batch 428 in epoch 8, gen_loss = 0.39976061029589816, disc_loss = 0.044113227425659804
Trained batch 429 in epoch 8, gen_loss = 0.3996632004200026, disc_loss = 0.044078897036135545
Trained batch 430 in epoch 8, gen_loss = 0.3995064442367952, disc_loss = 0.0439923930612853
Trained batch 431 in epoch 8, gen_loss = 0.39958931650552487, disc_loss = 0.043916854098723784
Trained batch 432 in epoch 8, gen_loss = 0.3998056312906825, disc_loss = 0.04383835360928338
Trained batch 433 in epoch 8, gen_loss = 0.3997886259846973, disc_loss = 0.043793982037553386
Trained batch 434 in epoch 8, gen_loss = 0.39966249116535846, disc_loss = 0.043705197977137636
Trained batch 435 in epoch 8, gen_loss = 0.39969755599804974, disc_loss = 0.04361459117814249
Trained batch 436 in epoch 8, gen_loss = 0.3998116123867253, disc_loss = 0.04352862627332864
Trained batch 437 in epoch 8, gen_loss = 0.39973483904855983, disc_loss = 0.04345327571404409
Trained batch 438 in epoch 8, gen_loss = 0.39985518832956196, disc_loss = 0.04336197130012926
Trained batch 439 in epoch 8, gen_loss = 0.3998856625096364, disc_loss = 0.043305083471138706
Trained batch 440 in epoch 8, gen_loss = 0.3999444119243665, disc_loss = 0.04323261943825282
Trained batch 441 in epoch 8, gen_loss = 0.39988184609024774, disc_loss = 0.0431685284237331
Trained batch 442 in epoch 8, gen_loss = 0.39987602056283716, disc_loss = 0.04312438533471111
Trained batch 443 in epoch 8, gen_loss = 0.4000236277241965, disc_loss = 0.04304185163477218
Trained batch 444 in epoch 8, gen_loss = 0.4001108404625668, disc_loss = 0.042952579582172835
Trained batch 445 in epoch 8, gen_loss = 0.4001338439805625, disc_loss = 0.04286979729384852
Trained batch 446 in epoch 8, gen_loss = 0.40013408420869967, disc_loss = 0.0427847024401279
Trained batch 447 in epoch 8, gen_loss = 0.40017745550721884, disc_loss = 0.04269634269024079
Trained batch 448 in epoch 8, gen_loss = 0.40009609150196235, disc_loss = 0.04261415184709868
Trained batch 449 in epoch 8, gen_loss = 0.40015283392535317, disc_loss = 0.042529425365436406
Trained batch 450 in epoch 8, gen_loss = 0.4001219032080369, disc_loss = 0.04245218432750016
Trained batch 451 in epoch 8, gen_loss = 0.40012777207699496, disc_loss = 0.04237824028658689
Trained batch 452 in epoch 8, gen_loss = 0.4001115401322742, disc_loss = 0.042295310917674314
Trained batch 453 in epoch 8, gen_loss = 0.40024424032492784, disc_loss = 0.04221663904470691
Trained batch 454 in epoch 8, gen_loss = 0.4000944592140533, disc_loss = 0.042135733201240116
Trained batch 455 in epoch 8, gen_loss = 0.40004945833954897, disc_loss = 0.04206621832839262
Trained batch 456 in epoch 8, gen_loss = 0.40015137867280637, disc_loss = 0.04198156230822124
Trained batch 457 in epoch 8, gen_loss = 0.4001569531239797, disc_loss = 0.04190384689769321
Trained batch 458 in epoch 8, gen_loss = 0.40018669770693727, disc_loss = 0.041970595527209
Trained batch 459 in epoch 8, gen_loss = 0.40000270916068037, disc_loss = 0.0422620291664751
Trained batch 460 in epoch 8, gen_loss = 0.40012701356747143, disc_loss = 0.04229365500577053
Trained batch 461 in epoch 8, gen_loss = 0.4001379285281871, disc_loss = 0.04226262005926936
Trained batch 462 in epoch 8, gen_loss = 0.40057701245754895, disc_loss = 0.04301926071683174
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.4222903549671173, disc_loss = 0.1116509884595871
Trained batch 1 in epoch 9, gen_loss = 0.41803716123104095, disc_loss = 0.08650707826018333
Trained batch 2 in epoch 9, gen_loss = 0.42483870188395184, disc_loss = 0.10906944423913956
Trained batch 3 in epoch 9, gen_loss = 0.3914583623409271, disc_loss = 0.17465105466544628
Trained batch 4 in epoch 9, gen_loss = 0.3875786066055298, disc_loss = 0.15919485241174697
Trained batch 5 in epoch 9, gen_loss = 0.3882189889748891, disc_loss = 0.14735248312354088
Trained batch 6 in epoch 9, gen_loss = 0.3882172022547041, disc_loss = 0.13233929393546923
Trained batch 7 in epoch 9, gen_loss = 0.37383371219038963, disc_loss = 0.12143891025334597
Trained batch 8 in epoch 9, gen_loss = 0.3663119243250953, disc_loss = 0.11163353009356393
Trained batch 9 in epoch 9, gen_loss = 0.3696267157793045, disc_loss = 0.10153741827234626
Trained batch 10 in epoch 9, gen_loss = 0.3722691075368361, disc_loss = 0.0937616556713527
Trained batch 11 in epoch 9, gen_loss = 0.3775365973512332, disc_loss = 0.09799515603420635
Trained batch 12 in epoch 9, gen_loss = 0.3895963911826794, disc_loss = 0.11950199786000527
Trained batch 13 in epoch 9, gen_loss = 0.38903304508754183, disc_loss = 0.11467222969180771
Trained batch 14 in epoch 9, gen_loss = 0.3849397222201029, disc_loss = 0.11046999835719665
Trained batch 15 in epoch 9, gen_loss = 0.3890353627502918, disc_loss = 0.10606381896650419
Trained batch 16 in epoch 9, gen_loss = 0.39107384401209216, disc_loss = 0.1076102821594652
Trained batch 17 in epoch 9, gen_loss = 0.38655176593197715, disc_loss = 0.10562570594872038
Trained batch 18 in epoch 9, gen_loss = 0.385310245187659, disc_loss = 0.11062390430781402
Trained batch 19 in epoch 9, gen_loss = 0.3887565016746521, disc_loss = 0.1312150943558663
Trained batch 20 in epoch 9, gen_loss = 0.38385245771635146, disc_loss = 0.13071065036846058
Trained batch 21 in epoch 9, gen_loss = 0.3812087652358142, disc_loss = 0.13005462860349903
Trained batch 22 in epoch 9, gen_loss = 0.386496241973794, disc_loss = 0.1274320035767944
Trained batch 23 in epoch 9, gen_loss = 0.3871209993958473, disc_loss = 0.12311534921173006
Trained batch 24 in epoch 9, gen_loss = 0.3892437994480133, disc_loss = 0.12167095389217138
Trained batch 25 in epoch 9, gen_loss = 0.3911597258769549, disc_loss = 0.11940497213688034
Trained batch 26 in epoch 9, gen_loss = 0.39147959483994377, disc_loss = 0.11611423306856994
Trained batch 27 in epoch 9, gen_loss = 0.39330205002001356, disc_loss = 0.11223051979738687
Trained batch 28 in epoch 9, gen_loss = 0.3939720546377116, disc_loss = 0.10931021325161745
Trained batch 29 in epoch 9, gen_loss = 0.3935176263252894, disc_loss = 0.10709337607646982
Trained batch 30 in epoch 9, gen_loss = 0.3935223837052622, disc_loss = 0.10867485130626348
Trained batch 31 in epoch 9, gen_loss = 0.39236137457191944, disc_loss = 0.1135973466152791
Trained batch 32 in epoch 9, gen_loss = 0.39461044018918817, disc_loss = 0.1159005898022742
Trained batch 33 in epoch 9, gen_loss = 0.39400767140528736, disc_loss = 0.11367086794994333
Trained batch 34 in epoch 9, gen_loss = 0.3918449912752424, disc_loss = 0.11238869612238236
Trained batch 35 in epoch 9, gen_loss = 0.3924899092978901, disc_loss = 0.1097282318967498
Trained batch 36 in epoch 9, gen_loss = 0.3938230880208918, disc_loss = 0.10768888415013617
Trained batch 37 in epoch 9, gen_loss = 0.39428971315685074, disc_loss = 0.10537677589117696
Trained batch 38 in epoch 9, gen_loss = 0.3935408813831134, disc_loss = 0.10381002215525278
Trained batch 39 in epoch 9, gen_loss = 0.39459251537919043, disc_loss = 0.10223547879140824
Trained batch 40 in epoch 9, gen_loss = 0.39577477806951944, disc_loss = 0.09990224144535094
Trained batch 41 in epoch 9, gen_loss = 0.39544946593897684, disc_loss = 0.09816511407760638
Trained batch 42 in epoch 9, gen_loss = 0.3961801196253577, disc_loss = 0.0962513012724907
Trained batch 43 in epoch 9, gen_loss = 0.39520302618091757, disc_loss = 0.09440889700569889
Trained batch 44 in epoch 9, gen_loss = 0.39611546132299635, disc_loss = 0.09629266775316662
Trained batch 45 in epoch 9, gen_loss = 0.3951450560403907, disc_loss = 0.10678110676615135
Trained batch 46 in epoch 9, gen_loss = 0.39541804283223253, disc_loss = 0.10540011327000375
Trained batch 47 in epoch 9, gen_loss = 0.3971369719753663, disc_loss = 0.10477685082393388
Trained batch 48 in epoch 9, gen_loss = 0.3980517819219706, disc_loss = 0.10283985604741136
Trained batch 49 in epoch 9, gen_loss = 0.3978071063756943, disc_loss = 0.10202943570911885
Trained batch 50 in epoch 9, gen_loss = 0.39667636097646225, disc_loss = 0.10059167514098626
Trained batch 51 in epoch 9, gen_loss = 0.39672531244846493, disc_loss = 0.10001655506829803
Trained batch 52 in epoch 9, gen_loss = 0.3966048680386453, disc_loss = 0.09927986720401161
Trained batch 53 in epoch 9, gen_loss = 0.3977229192301079, disc_loss = 0.09977515610969728
Trained batch 54 in epoch 9, gen_loss = 0.3973678399216045, disc_loss = 0.09897379986941815
Trained batch 55 in epoch 9, gen_loss = 0.3965994268655777, disc_loss = 0.09743333922233433
Trained batch 56 in epoch 9, gen_loss = 0.3965217858030085, disc_loss = 0.09589331141231876
Trained batch 57 in epoch 9, gen_loss = 0.3966790149951803, disc_loss = 0.09476736449668634
Trained batch 58 in epoch 9, gen_loss = 0.3965152764724473, disc_loss = 0.09456383189091742
Trained batch 59 in epoch 9, gen_loss = 0.397160534063975, disc_loss = 0.09313217514815429
Trained batch 60 in epoch 9, gen_loss = 0.39891528790114356, disc_loss = 0.09297900562953265
Trained batch 61 in epoch 9, gen_loss = 0.39712756920245385, disc_loss = 0.09253135409146067
Trained batch 62 in epoch 9, gen_loss = 0.39630388220151264, disc_loss = 0.09205780641013195
Trained batch 63 in epoch 9, gen_loss = 0.39788357447832823, disc_loss = 0.09148467612976674
Trained batch 64 in epoch 9, gen_loss = 0.39886092085104724, disc_loss = 0.09039473323008189
Trained batch 65 in epoch 9, gen_loss = 0.3991635658524253, disc_loss = 0.08939060539176519
Trained batch 66 in epoch 9, gen_loss = 0.39837614680404093, disc_loss = 0.08819415004673734
Trained batch 67 in epoch 9, gen_loss = 0.39795665486770515, disc_loss = 0.0873417561627267
Trained batch 68 in epoch 9, gen_loss = 0.3968325101810953, disc_loss = 0.08723915971653617
Trained batch 69 in epoch 9, gen_loss = 0.3951051392725536, disc_loss = 0.08829634198918938
Trained batch 70 in epoch 9, gen_loss = 0.39605474220195286, disc_loss = 0.08828944029470145
Trained batch 71 in epoch 9, gen_loss = 0.3965343377656407, disc_loss = 0.08716041453751838
Trained batch 72 in epoch 9, gen_loss = 0.3963588782369274, disc_loss = 0.0861180000619529
Trained batch 73 in epoch 9, gen_loss = 0.39586100103081884, disc_loss = 0.08509369422304067
Trained batch 74 in epoch 9, gen_loss = 0.39561065236727394, disc_loss = 0.08402918289725979
Trained batch 75 in epoch 9, gen_loss = 0.39584930711670924, disc_loss = 0.08299935880533763
Trained batch 76 in epoch 9, gen_loss = 0.3957892397007385, disc_loss = 0.08200720541009848
Trained batch 77 in epoch 9, gen_loss = 0.3954925999427453, disc_loss = 0.08115030844839147
Trained batch 78 in epoch 9, gen_loss = 0.395278121474423, disc_loss = 0.0807296159394274
Trained batch 79 in epoch 9, gen_loss = 0.3960295967757702, disc_loss = 0.07983423430123367
Trained batch 80 in epoch 9, gen_loss = 0.3962274186405135, disc_loss = 0.08112456121217505
Trained batch 81 in epoch 9, gen_loss = 0.3952137620710745, disc_loss = 0.08458143123425543
Trained batch 82 in epoch 9, gen_loss = 0.3953939406986696, disc_loss = 0.08678774854886424
Trained batch 83 in epoch 9, gen_loss = 0.3949726653240976, disc_loss = 0.086117280320087
Trained batch 84 in epoch 9, gen_loss = 0.39500345587730407, disc_loss = 0.08603887963930473
Trained batch 85 in epoch 9, gen_loss = 0.39526190002297246, disc_loss = 0.08522487430140203
Trained batch 86 in epoch 9, gen_loss = 0.39563071248175086, disc_loss = 0.08449324642725546
Trained batch 87 in epoch 9, gen_loss = 0.3953129622069272, disc_loss = 0.08383239452748305
Trained batch 88 in epoch 9, gen_loss = 0.39426438694589594, disc_loss = 0.08415614598524872
Trained batch 89 in epoch 9, gen_loss = 0.39376346634493936, disc_loss = 0.08385008050439259
Trained batch 90 in epoch 9, gen_loss = 0.3941843752022628, disc_loss = 0.08437122722350798
Trained batch 91 in epoch 9, gen_loss = 0.3939022467188213, disc_loss = 0.08675200142391512
Trained batch 92 in epoch 9, gen_loss = 0.3944894908576883, disc_loss = 0.086505318906719
Trained batch 93 in epoch 9, gen_loss = 0.3959521454699496, disc_loss = 0.08617979936559308
Trained batch 94 in epoch 9, gen_loss = 0.3961500287055969, disc_loss = 0.08552181531037939
Trained batch 95 in epoch 9, gen_loss = 0.39586163374284905, disc_loss = 0.08602596693769253
Trained batch 96 in epoch 9, gen_loss = 0.396698573200973, disc_loss = 0.08635547932371804
Trained batch 97 in epoch 9, gen_loss = 0.39672772373471943, disc_loss = 0.08603208822350265
Trained batch 98 in epoch 9, gen_loss = 0.39574939102837536, disc_loss = 0.0868507689006175
Trained batch 99 in epoch 9, gen_loss = 0.39628720462322237, disc_loss = 0.08608102537225931
Trained batch 100 in epoch 9, gen_loss = 0.39639833451497675, disc_loss = 0.08643092989165446
Trained batch 101 in epoch 9, gen_loss = 0.3957456175018759, disc_loss = 0.08597428482665005
Trained batch 102 in epoch 9, gen_loss = 0.3953123480370901, disc_loss = 0.08550411212773433
Trained batch 103 in epoch 9, gen_loss = 0.3957426565197798, disc_loss = 0.08492198707804513
Trained batch 104 in epoch 9, gen_loss = 0.39623788992563885, disc_loss = 0.08447051090410068
Trained batch 105 in epoch 9, gen_loss = 0.3957246418269175, disc_loss = 0.08392116469155364
Trained batch 106 in epoch 9, gen_loss = 0.39587297534274163, disc_loss = 0.08327095096965677
Trained batch 107 in epoch 9, gen_loss = 0.3955361826552285, disc_loss = 0.08259595835288228
Trained batch 108 in epoch 9, gen_loss = 0.3955268345841574, disc_loss = 0.08189669534683637
Trained batch 109 in epoch 9, gen_loss = 0.3955853147940202, disc_loss = 0.08139358756809749
Trained batch 110 in epoch 9, gen_loss = 0.39607513756365387, disc_loss = 0.08144084167423414
Trained batch 111 in epoch 9, gen_loss = 0.39595670545739786, disc_loss = 0.0810516375973488
Trained batch 112 in epoch 9, gen_loss = 0.39549104460572776, disc_loss = 0.08062437893328282
Trained batch 113 in epoch 9, gen_loss = 0.39612127657522234, disc_loss = 0.08013260540585115
Trained batch 114 in epoch 9, gen_loss = 0.3962899511275084, disc_loss = 0.07959692711010576
Trained batch 115 in epoch 9, gen_loss = 0.39616452619947234, disc_loss = 0.07895968043534406
Trained batch 116 in epoch 9, gen_loss = 0.3960684280619662, disc_loss = 0.07835606763410008
Trained batch 117 in epoch 9, gen_loss = 0.3958268211049549, disc_loss = 0.07774663531079383
Trained batch 118 in epoch 9, gen_loss = 0.3959485317478661, disc_loss = 0.0771681818985889
Trained batch 119 in epoch 9, gen_loss = 0.3964387945830822, disc_loss = 0.07660801804934939
Trained batch 120 in epoch 9, gen_loss = 0.39654274641974896, disc_loss = 0.07601452929406496
Trained batch 121 in epoch 9, gen_loss = 0.39701303546545935, disc_loss = 0.07560260692748745
Trained batch 122 in epoch 9, gen_loss = 0.39731519009039656, disc_loss = 0.07634440210943179
Trained batch 123 in epoch 9, gen_loss = 0.39637703063987917, disc_loss = 0.07871586109526575
Trained batch 124 in epoch 9, gen_loss = 0.3967100269794464, disc_loss = 0.07833952952548862
Trained batch 125 in epoch 9, gen_loss = 0.39692411559914786, disc_loss = 0.07845385574794833
Trained batch 126 in epoch 9, gen_loss = 0.3969025311507578, disc_loss = 0.07869921590560885
Trained batch 127 in epoch 9, gen_loss = 0.3962300391867757, disc_loss = 0.07821174316268298
Trained batch 128 in epoch 9, gen_loss = 0.3961155393788981, disc_loss = 0.07788141867030383
Trained batch 129 in epoch 9, gen_loss = 0.3961385623766826, disc_loss = 0.07737852996573426
Trained batch 130 in epoch 9, gen_loss = 0.39614384001447955, disc_loss = 0.07749552663259265
Trained batch 131 in epoch 9, gen_loss = 0.3963002194509362, disc_loss = 0.07964165454772724
Trained batch 132 in epoch 9, gen_loss = 0.39614374319413553, disc_loss = 0.07950201406164613
Trained batch 133 in epoch 9, gen_loss = 0.39559044789022474, disc_loss = 0.07965590337416463
Trained batch 134 in epoch 9, gen_loss = 0.3960939758353763, disc_loss = 0.08042083768587974
Trained batch 135 in epoch 9, gen_loss = 0.3961460241938339, disc_loss = 0.08045040426762118
Trained batch 136 in epoch 9, gen_loss = 0.3964843908800696, disc_loss = 0.07995446173501385
Trained batch 137 in epoch 9, gen_loss = 0.39616671355738153, disc_loss = 0.08033840785113473
Trained batch 138 in epoch 9, gen_loss = 0.3955358875741204, disc_loss = 0.08315537661220208
Trained batch 139 in epoch 9, gen_loss = 0.39523676399673735, disc_loss = 0.0833657807570749
Trained batch 140 in epoch 9, gen_loss = 0.3956337110370609, disc_loss = 0.08376531736555358
Trained batch 141 in epoch 9, gen_loss = 0.3957239177445291, disc_loss = 0.0840526914755276
Trained batch 142 in epoch 9, gen_loss = 0.3953181730283724, disc_loss = 0.08416730447157801
Trained batch 143 in epoch 9, gen_loss = 0.3943227839966615, disc_loss = 0.0838639713183511
Trained batch 144 in epoch 9, gen_loss = 0.3940228295737299, disc_loss = 0.0834908420701736
Trained batch 145 in epoch 9, gen_loss = 0.3939108654652556, disc_loss = 0.083043433920391
Trained batch 146 in epoch 9, gen_loss = 0.39409715423778613, disc_loss = 0.08266852796394504
Trained batch 147 in epoch 9, gen_loss = 0.3943533228861319, disc_loss = 0.0822263013703648
Trained batch 148 in epoch 9, gen_loss = 0.39458663911627445, disc_loss = 0.0820140412121061
Trained batch 149 in epoch 9, gen_loss = 0.3950340853134791, disc_loss = 0.08177553755852084
Trained batch 150 in epoch 9, gen_loss = 0.39555665692746245, disc_loss = 0.08136710628484752
Trained batch 151 in epoch 9, gen_loss = 0.39568062714840235, disc_loss = 0.08096407039250296
Trained batch 152 in epoch 9, gen_loss = 0.3959836396906111, disc_loss = 0.08048159393841048
Trained batch 153 in epoch 9, gen_loss = 0.3954742208316729, disc_loss = 0.08015580841509456
Trained batch 154 in epoch 9, gen_loss = 0.3952038034316032, disc_loss = 0.07969767501457564
Trained batch 155 in epoch 9, gen_loss = 0.3948547450395731, disc_loss = 0.07925510943497126
Trained batch 156 in epoch 9, gen_loss = 0.3945614612026579, disc_loss = 0.07882511937563681
Trained batch 157 in epoch 9, gen_loss = 0.39425226913977274, disc_loss = 0.079001448426655
Trained batch 158 in epoch 9, gen_loss = 0.39445778352659455, disc_loss = 0.08126940464882075
Trained batch 159 in epoch 9, gen_loss = 0.3945864222943783, disc_loss = 0.08107212529575918
Trained batch 160 in epoch 9, gen_loss = 0.39428888714831806, disc_loss = 0.08101795677685682
Trained batch 161 in epoch 9, gen_loss = 0.3940777808059881, disc_loss = 0.08064010494710579
Trained batch 162 in epoch 9, gen_loss = 0.3943310034421324, disc_loss = 0.08039865923039843
Trained batch 163 in epoch 9, gen_loss = 0.39381644711261843, disc_loss = 0.08057576696467926
Trained batch 164 in epoch 9, gen_loss = 0.39442355072859564, disc_loss = 0.08029359300536189
Trained batch 165 in epoch 9, gen_loss = 0.3948255657072527, disc_loss = 0.07992352991005833
Trained batch 166 in epoch 9, gen_loss = 0.394460291741137, disc_loss = 0.0795189051353512
Trained batch 167 in epoch 9, gen_loss = 0.39406957388633773, disc_loss = 0.07923744649105217
Trained batch 168 in epoch 9, gen_loss = 0.3939469521920356, disc_loss = 0.07879835014788092
Trained batch 169 in epoch 9, gen_loss = 0.3944685599383186, disc_loss = 0.0784025113837903
Trained batch 170 in epoch 9, gen_loss = 0.3948753050893371, disc_loss = 0.0780418693218707
Trained batch 171 in epoch 9, gen_loss = 0.3952424910872482, disc_loss = 0.07766137416420374
Trained batch 172 in epoch 9, gen_loss = 0.39515049454104695, disc_loss = 0.07731123014778502
Trained batch 173 in epoch 9, gen_loss = 0.39500589343323106, disc_loss = 0.07692838651021065
Trained batch 174 in epoch 9, gen_loss = 0.394783798626491, disc_loss = 0.07651482792305095
Trained batch 175 in epoch 9, gen_loss = 0.39470778761262243, disc_loss = 0.07644935491473669
Trained batch 176 in epoch 9, gen_loss = 0.3950405893689495, disc_loss = 0.07687160319590804
Trained batch 177 in epoch 9, gen_loss = 0.3948755070064845, disc_loss = 0.07670657488967428
Trained batch 178 in epoch 9, gen_loss = 0.3951037061614031, disc_loss = 0.07649046001050559
Trained batch 179 in epoch 9, gen_loss = 0.3951518722706371, disc_loss = 0.0762655700608674
Trained batch 180 in epoch 9, gen_loss = 0.3948439405767957, disc_loss = 0.07606816462122769
Trained batch 181 in epoch 9, gen_loss = 0.39525073078962475, disc_loss = 0.07610614599332541
Trained batch 182 in epoch 9, gen_loss = 0.39526904231863597, disc_loss = 0.07575284029596327
Trained batch 183 in epoch 9, gen_loss = 0.39528640602593834, disc_loss = 0.0761009438884566
Trained batch 184 in epoch 9, gen_loss = 0.39582795694067674, disc_loss = 0.07677610431470581
Trained batch 185 in epoch 9, gen_loss = 0.3959617433688974, disc_loss = 0.07661860327546795
Trained batch 186 in epoch 9, gen_loss = 0.39523643876779524, disc_loss = 0.07714785830202428
Trained batch 187 in epoch 9, gen_loss = 0.3955619281276743, disc_loss = 0.07705682309522749
Trained batch 188 in epoch 9, gen_loss = 0.39572807626118733, disc_loss = 0.07677781224625294
Trained batch 189 in epoch 9, gen_loss = 0.3957859572611357, disc_loss = 0.07642352920221655
Trained batch 190 in epoch 9, gen_loss = 0.3956676818313399, disc_loss = 0.07611117134582622
Trained batch 191 in epoch 9, gen_loss = 0.3957896010639767, disc_loss = 0.07585598116080898
Trained batch 192 in epoch 9, gen_loss = 0.3955613556921173, disc_loss = 0.07565968461489121
Trained batch 193 in epoch 9, gen_loss = 0.3953471345078085, disc_loss = 0.07559598215193171
Trained batch 194 in epoch 9, gen_loss = 0.3950728679314638, disc_loss = 0.07552429780555077
Trained batch 195 in epoch 9, gen_loss = 0.3949157857165045, disc_loss = 0.07541593277294721
Trained batch 196 in epoch 9, gen_loss = 0.3953225152746675, disc_loss = 0.07506220224715278
Trained batch 197 in epoch 9, gen_loss = 0.3956201360984282, disc_loss = 0.07473663155535104
Trained batch 198 in epoch 9, gen_loss = 0.39538829036094436, disc_loss = 0.07443846902580717
Trained batch 199 in epoch 9, gen_loss = 0.3955031441152096, disc_loss = 0.0741201999410987
Trained batch 200 in epoch 9, gen_loss = 0.3955445341506408, disc_loss = 0.07382711872866202
Trained batch 201 in epoch 9, gen_loss = 0.3957219780376642, disc_loss = 0.07350447187476819
Trained batch 202 in epoch 9, gen_loss = 0.3960066533147408, disc_loss = 0.07317613708681148
Trained batch 203 in epoch 9, gen_loss = 0.3959953903275378, disc_loss = 0.07285140244993289
Trained batch 204 in epoch 9, gen_loss = 0.39621764697679657, disc_loss = 0.07256791530086136
Trained batch 205 in epoch 9, gen_loss = 0.39629548701267797, disc_loss = 0.07227304128667755
Trained batch 206 in epoch 9, gen_loss = 0.3960543719754703, disc_loss = 0.07199875957553009
Trained batch 207 in epoch 9, gen_loss = 0.39599658806736654, disc_loss = 0.07173179741277216
Trained batch 208 in epoch 9, gen_loss = 0.3960393357790258, disc_loss = 0.07149012774701395
Trained batch 209 in epoch 9, gen_loss = 0.39628885970229194, disc_loss = 0.07116665877401829
Trained batch 210 in epoch 9, gen_loss = 0.39628269604597044, disc_loss = 0.07088076553673824
Trained batch 211 in epoch 9, gen_loss = 0.3963688555753456, disc_loss = 0.0706233634560738
Trained batch 212 in epoch 9, gen_loss = 0.3962153327856825, disc_loss = 0.07030816313574537
Trained batch 213 in epoch 9, gen_loss = 0.3964874106589879, disc_loss = 0.0700587962012059
Trained batch 214 in epoch 9, gen_loss = 0.39629195817681245, disc_loss = 0.06978519952552784
Trained batch 215 in epoch 9, gen_loss = 0.3966333700550927, disc_loss = 0.06948811867321772
Trained batch 216 in epoch 9, gen_loss = 0.3967472979549988, disc_loss = 0.06921525420041644
Trained batch 217 in epoch 9, gen_loss = 0.396850003971966, disc_loss = 0.06897224780116572
Trained batch 218 in epoch 9, gen_loss = 0.39708165109974064, disc_loss = 0.06896223049912789
Trained batch 219 in epoch 9, gen_loss = 0.39718538143418053, disc_loss = 0.06887906923868947
Trained batch 220 in epoch 9, gen_loss = 0.39705248911995694, disc_loss = 0.06862314552705044
Trained batch 221 in epoch 9, gen_loss = 0.3971807104241741, disc_loss = 0.06843272337232725
Trained batch 222 in epoch 9, gen_loss = 0.39720975737935227, disc_loss = 0.06815683686032457
Trained batch 223 in epoch 9, gen_loss = 0.39739236222313984, disc_loss = 0.06787531147399152
Trained batch 224 in epoch 9, gen_loss = 0.3978067311975691, disc_loss = 0.06761032432835135
Trained batch 225 in epoch 9, gen_loss = 0.39781539603672195, disc_loss = 0.06737302216614671
Trained batch 226 in epoch 9, gen_loss = 0.3976878647237097, disc_loss = 0.0671601640850322
Trained batch 227 in epoch 9, gen_loss = 0.3977965605363511, disc_loss = 0.06692145839680738
Trained batch 228 in epoch 9, gen_loss = 0.39817421248906565, disc_loss = 0.06682528522552915
Trained batch 229 in epoch 9, gen_loss = 0.3980402446311453, disc_loss = 0.06683870728593319
Trained batch 230 in epoch 9, gen_loss = 0.3981076646676827, disc_loss = 0.06659096868575684
Trained batch 231 in epoch 9, gen_loss = 0.3982232729422635, disc_loss = 0.06637066394463985
Trained batch 232 in epoch 9, gen_loss = 0.398114108476516, disc_loss = 0.06610080014210785
Trained batch 233 in epoch 9, gen_loss = 0.3981277817844326, disc_loss = 0.06583867999963844
Trained batch 234 in epoch 9, gen_loss = 0.39800785779953, disc_loss = 0.06558945975761782
Trained batch 235 in epoch 9, gen_loss = 0.39788605247513725, disc_loss = 0.0653624738491598
Trained batch 236 in epoch 9, gen_loss = 0.3980910443555454, disc_loss = 0.06513871128163949
Trained batch 237 in epoch 9, gen_loss = 0.39813029290247365, disc_loss = 0.0648930479220639
Trained batch 238 in epoch 9, gen_loss = 0.3982020642717513, disc_loss = 0.0646640968345355
Trained batch 239 in epoch 9, gen_loss = 0.39841257184743883, disc_loss = 0.06444135886267759
Trained batch 240 in epoch 9, gen_loss = 0.3982626288758274, disc_loss = 0.06420787856856137
Trained batch 241 in epoch 9, gen_loss = 0.3982854774914497, disc_loss = 0.06401414852319978
Trained batch 242 in epoch 9, gen_loss = 0.3980915299904199, disc_loss = 0.06378288667288766
Trained batch 243 in epoch 9, gen_loss = 0.39816463714251754, disc_loss = 0.06354566965992639
Trained batch 244 in epoch 9, gen_loss = 0.3981525110955141, disc_loss = 0.06333137996760863
Trained batch 245 in epoch 9, gen_loss = 0.398232962905876, disc_loss = 0.06311077094349132
Trained batch 246 in epoch 9, gen_loss = 0.3984139751084903, disc_loss = 0.06315980221027968
Trained batch 247 in epoch 9, gen_loss = 0.39836170740665927, disc_loss = 0.06351224197668114
Trained batch 248 in epoch 9, gen_loss = 0.3984711840449567, disc_loss = 0.0638571724755667
Trained batch 249 in epoch 9, gen_loss = 0.3984538332223892, disc_loss = 0.0638509073536843
Trained batch 250 in epoch 9, gen_loss = 0.39846773890860054, disc_loss = 0.06373378095510175
Trained batch 251 in epoch 9, gen_loss = 0.39831597972956917, disc_loss = 0.06366625425058402
Trained batch 252 in epoch 9, gen_loss = 0.3984093535323388, disc_loss = 0.06344948143039356
Trained batch 253 in epoch 9, gen_loss = 0.39839795888878227, disc_loss = 0.06328402070409259
Trained batch 254 in epoch 9, gen_loss = 0.3986356791327981, disc_loss = 0.06317716254944018
Trained batch 255 in epoch 9, gen_loss = 0.3987048286944628, disc_loss = 0.06307917877893487
Trained batch 256 in epoch 9, gen_loss = 0.398756136922057, disc_loss = 0.06300370635261854
Trained batch 257 in epoch 9, gen_loss = 0.3986900930487832, disc_loss = 0.06297893807212569
Trained batch 258 in epoch 9, gen_loss = 0.3986328846009081, disc_loss = 0.06312464467612991
Trained batch 259 in epoch 9, gen_loss = 0.39873154300909774, disc_loss = 0.0632053355131155
Trained batch 260 in epoch 9, gen_loss = 0.39847884038855746, disc_loss = 0.06329765370101365
Trained batch 261 in epoch 9, gen_loss = 0.39852978425626534, disc_loss = 0.06314201449854513
Trained batch 262 in epoch 9, gen_loss = 0.3986007989359446, disc_loss = 0.06301016122024831
Trained batch 263 in epoch 9, gen_loss = 0.3987924056974324, disc_loss = 0.0629751507958369
Trained batch 264 in epoch 9, gen_loss = 0.3988189330640829, disc_loss = 0.06278062309402059
Trained batch 265 in epoch 9, gen_loss = 0.3991814659054118, disc_loss = 0.06338629898040983
Trained batch 266 in epoch 9, gen_loss = 0.39883447608697725, disc_loss = 0.06401613280560807
Trained batch 267 in epoch 9, gen_loss = 0.3986871232514951, disc_loss = 0.06435055289688561
Trained batch 268 in epoch 9, gen_loss = 0.39847715946821477, disc_loss = 0.06417242656929287
Trained batch 269 in epoch 9, gen_loss = 0.3981991242479395, disc_loss = 0.06469776636437961
Trained batch 270 in epoch 9, gen_loss = 0.3984645549001729, disc_loss = 0.06627817562441049
Trained batch 271 in epoch 9, gen_loss = 0.3982937889283194, disc_loss = 0.06651137249290888
Trained batch 272 in epoch 9, gen_loss = 0.3981090526441078, disc_loss = 0.06679257532690853
Trained batch 273 in epoch 9, gen_loss = 0.39809172823481315, disc_loss = 0.06685804364094715
Trained batch 274 in epoch 9, gen_loss = 0.39801586671309036, disc_loss = 0.06685309508138082
Trained batch 275 in epoch 9, gen_loss = 0.3977366423477297, disc_loss = 0.06688320394301706
Trained batch 276 in epoch 9, gen_loss = 0.3976434305686813, disc_loss = 0.06704725293335018
Trained batch 277 in epoch 9, gen_loss = 0.3973643957710952, disc_loss = 0.0679008692231619
Trained batch 278 in epoch 9, gen_loss = 0.39727432999132356, disc_loss = 0.0680221222311018
Trained batch 279 in epoch 9, gen_loss = 0.39707906852875435, disc_loss = 0.06792211317557044
Trained batch 280 in epoch 9, gen_loss = 0.3968862687565678, disc_loss = 0.06825765498559193
Trained batch 281 in epoch 9, gen_loss = 0.39692201999062343, disc_loss = 0.06932934049140424
Trained batch 282 in epoch 9, gen_loss = 0.39669470725969375, disc_loss = 0.06940187532750909
Trained batch 283 in epoch 9, gen_loss = 0.39673014195032524, disc_loss = 0.06965307217635687
Trained batch 284 in epoch 9, gen_loss = 0.3964108769308057, disc_loss = 0.0697931894918152
Trained batch 285 in epoch 9, gen_loss = 0.3964355982892163, disc_loss = 0.06973713076790677
Trained batch 286 in epoch 9, gen_loss = 0.3959518457123627, disc_loss = 0.06991888224942291
Trained batch 287 in epoch 9, gen_loss = 0.39598357905116344, disc_loss = 0.07026706677829174
Trained batch 288 in epoch 9, gen_loss = 0.39596070189377014, disc_loss = 0.07013967760055484
Trained batch 289 in epoch 9, gen_loss = 0.39580338062911197, disc_loss = 0.070168673560216
Trained batch 290 in epoch 9, gen_loss = 0.39586909530089076, disc_loss = 0.07018413495022766
Trained batch 291 in epoch 9, gen_loss = 0.39566700578960656, disc_loss = 0.07003422901002461
Trained batch 292 in epoch 9, gen_loss = 0.39549379188046113, disc_loss = 0.06991847391389691
Trained batch 293 in epoch 9, gen_loss = 0.39555801066006124, disc_loss = 0.07010672117748178
Trained batch 294 in epoch 9, gen_loss = 0.3953606343875497, disc_loss = 0.07041604390557286
Trained batch 295 in epoch 9, gen_loss = 0.39521340270702904, disc_loss = 0.07037018068808105
Trained batch 296 in epoch 9, gen_loss = 0.39499880809976595, disc_loss = 0.07035110028372821
Trained batch 297 in epoch 9, gen_loss = 0.3951474732200571, disc_loss = 0.07031789317495821
Trained batch 298 in epoch 9, gen_loss = 0.39505328791197325, disc_loss = 0.07029435435235251
Trained batch 299 in epoch 9, gen_loss = 0.39487910012404126, disc_loss = 0.0700900040489311
Trained batch 300 in epoch 9, gen_loss = 0.3949501379779803, disc_loss = 0.0698987042819122
Trained batch 301 in epoch 9, gen_loss = 0.39492631047371995, disc_loss = 0.06979722897090412
Trained batch 302 in epoch 9, gen_loss = 0.39498168003834516, disc_loss = 0.0695925851678322
Trained batch 303 in epoch 9, gen_loss = 0.3951567973157293, disc_loss = 0.06942551494361587
Trained batch 304 in epoch 9, gen_loss = 0.39490171534116153, disc_loss = 0.06932384149003469
Trained batch 305 in epoch 9, gen_loss = 0.3946618143639533, disc_loss = 0.0691800785625317
Trained batch 306 in epoch 9, gen_loss = 0.39472106060298334, disc_loss = 0.06900777898467955
Trained batch 307 in epoch 9, gen_loss = 0.3947447388396635, disc_loss = 0.06880053012123839
Trained batch 308 in epoch 9, gen_loss = 0.3945706649698486, disc_loss = 0.06867337329644697
Trained batch 309 in epoch 9, gen_loss = 0.3946098606432638, disc_loss = 0.06876905787916433
Trained batch 310 in epoch 9, gen_loss = 0.394639102209036, disc_loss = 0.06864191546521099
Trained batch 311 in epoch 9, gen_loss = 0.3947293526278092, disc_loss = 0.06844231170954373
Trained batch 312 in epoch 9, gen_loss = 0.394598468138387, disc_loss = 0.06829704343528746
Trained batch 313 in epoch 9, gen_loss = 0.39428982859963824, disc_loss = 0.06820849234766214
Trained batch 314 in epoch 9, gen_loss = 0.3945051212159414, disc_loss = 0.06818453955005795
Trained batch 315 in epoch 9, gen_loss = 0.39465440149548686, disc_loss = 0.06800958761043517
Trained batch 316 in epoch 9, gen_loss = 0.39479130478311414, disc_loss = 0.06782400764801101
Trained batch 317 in epoch 9, gen_loss = 0.3946836139983351, disc_loss = 0.06771357438773057
Trained batch 318 in epoch 9, gen_loss = 0.3947499613029456, disc_loss = 0.06816362883154081
Trained batch 319 in epoch 9, gen_loss = 0.3945928554981947, disc_loss = 0.06842950127756922
Trained batch 320 in epoch 9, gen_loss = 0.3948701712015633, disc_loss = 0.06941803455834401
Trained batch 321 in epoch 9, gen_loss = 0.39470866294751256, disc_loss = 0.0696214094732003
Trained batch 322 in epoch 9, gen_loss = 0.3943832705818094, disc_loss = 0.07087594230771757
Trained batch 323 in epoch 9, gen_loss = 0.39418178392045294, disc_loss = 0.07146333246980506
Trained batch 324 in epoch 9, gen_loss = 0.3939155041254484, disc_loss = 0.07172997677985292
Trained batch 325 in epoch 9, gen_loss = 0.39375179576361835, disc_loss = 0.0719247227406095
Trained batch 326 in epoch 9, gen_loss = 0.3936510498006045, disc_loss = 0.07203778765087418
Trained batch 327 in epoch 9, gen_loss = 0.39344134890451665, disc_loss = 0.07229681607625424
Trained batch 328 in epoch 9, gen_loss = 0.3932284508070322, disc_loss = 0.0724920629931325
Trained batch 329 in epoch 9, gen_loss = 0.3930345071987672, disc_loss = 0.07297937756432503
Trained batch 330 in epoch 9, gen_loss = 0.3930738982477217, disc_loss = 0.07316437579010504
Trained batch 331 in epoch 9, gen_loss = 0.3932155192077878, disc_loss = 0.07358420729294914
Trained batch 332 in epoch 9, gen_loss = 0.39315368919759186, disc_loss = 0.07364363112981927
Trained batch 333 in epoch 9, gen_loss = 0.3932079000922734, disc_loss = 0.07348793962953645
Trained batch 334 in epoch 9, gen_loss = 0.393068995226675, disc_loss = 0.07338528819243187
Trained batch 335 in epoch 9, gen_loss = 0.39331259658294065, disc_loss = 0.07322832437958346
Trained batch 336 in epoch 9, gen_loss = 0.3932853012127409, disc_loss = 0.07328347321627357
Trained batch 337 in epoch 9, gen_loss = 0.3933911171890575, disc_loss = 0.07347653007559125
Trained batch 338 in epoch 9, gen_loss = 0.3932240462057007, disc_loss = 0.073447950353302
Trained batch 339 in epoch 9, gen_loss = 0.39322439852882834, disc_loss = 0.07357003282728221
Trained batch 340 in epoch 9, gen_loss = 0.39294895870594687, disc_loss = 0.07378191404082864
Trained batch 341 in epoch 9, gen_loss = 0.39305733118140906, disc_loss = 0.07375125793266323
Trained batch 342 in epoch 9, gen_loss = 0.39308908121231345, disc_loss = 0.07357117534634106
Trained batch 343 in epoch 9, gen_loss = 0.39290570467710495, disc_loss = 0.07353297644700899
Trained batch 344 in epoch 9, gen_loss = 0.39283256427101465, disc_loss = 0.07337909629568458
Trained batch 345 in epoch 9, gen_loss = 0.39280719107630624, disc_loss = 0.07318870474805118
Trained batch 346 in epoch 9, gen_loss = 0.39273853922096386, disc_loss = 0.0730095775985838
Trained batch 347 in epoch 9, gen_loss = 0.3928634776123639, disc_loss = 0.07284551083335075
Trained batch 348 in epoch 9, gen_loss = 0.3927169776065302, disc_loss = 0.07283264050062714
Trained batch 349 in epoch 9, gen_loss = 0.3929239282437733, disc_loss = 0.07343965072184801
Trained batch 350 in epoch 9, gen_loss = 0.3929032761486847, disc_loss = 0.0733518961052864
Trained batch 351 in epoch 9, gen_loss = 0.3928027326579798, disc_loss = 0.07322424530072814
Trained batch 352 in epoch 9, gen_loss = 0.39270360147311395, disc_loss = 0.07341150038746362
Trained batch 353 in epoch 9, gen_loss = 0.3924238648960146, disc_loss = 0.07343019833946127
Trained batch 354 in epoch 9, gen_loss = 0.3923131324875523, disc_loss = 0.07326103381182945
Trained batch 355 in epoch 9, gen_loss = 0.3921784065412671, disc_loss = 0.07311881261909109
Trained batch 356 in epoch 9, gen_loss = 0.392244811902861, disc_loss = 0.0729435966650144
Trained batch 357 in epoch 9, gen_loss = 0.39212588299919104, disc_loss = 0.07291776302931362
Trained batch 358 in epoch 9, gen_loss = 0.39232615748819866, disc_loss = 0.07322006719316612
Trained batch 359 in epoch 9, gen_loss = 0.3923901841872268, disc_loss = 0.0730502305397143
Trained batch 360 in epoch 9, gen_loss = 0.3922194567743761, disc_loss = 0.07303534704583008
Trained batch 361 in epoch 9, gen_loss = 0.3921153604654976, disc_loss = 0.07285258168282595
Trained batch 362 in epoch 9, gen_loss = 0.39227520376854363, disc_loss = 0.07275803640135885
Trained batch 363 in epoch 9, gen_loss = 0.39201731185664185, disc_loss = 0.07275269007064648
Trained batch 364 in epoch 9, gen_loss = 0.3921183810658651, disc_loss = 0.07267704117685965
Trained batch 365 in epoch 9, gen_loss = 0.3920698225335345, disc_loss = 0.07257347934131252
Trained batch 366 in epoch 9, gen_loss = 0.3920491004834708, disc_loss = 0.07255259553625246
Trained batch 367 in epoch 9, gen_loss = 0.3921043108338895, disc_loss = 0.07239313859178725
Trained batch 368 in epoch 9, gen_loss = 0.3924335063634526, disc_loss = 0.0722517750344585
Trained batch 369 in epoch 9, gen_loss = 0.3924821380827878, disc_loss = 0.0720987701511665
Trained batch 370 in epoch 9, gen_loss = 0.3926902525026522, disc_loss = 0.07200576159902258
Trained batch 371 in epoch 9, gen_loss = 0.3925480858613086, disc_loss = 0.07195248176163484
Trained batch 372 in epoch 9, gen_loss = 0.3926153879702571, disc_loss = 0.07179286562895087
Trained batch 373 in epoch 9, gen_loss = 0.39261029652733215, disc_loss = 0.07184476570978282
Trained batch 374 in epoch 9, gen_loss = 0.39237355438868204, disc_loss = 0.07221627301226059
Trained batch 375 in epoch 9, gen_loss = 0.3925047802956814, disc_loss = 0.0723418974481087
Trained batch 376 in epoch 9, gen_loss = 0.39248543432283783, disc_loss = 0.07267236759248795
Trained batch 377 in epoch 9, gen_loss = 0.39257803551419074, disc_loss = 0.07275517525585004
Trained batch 378 in epoch 9, gen_loss = 0.3927480664133711, disc_loss = 0.07260867188829624
Trained batch 379 in epoch 9, gen_loss = 0.39275334932302175, disc_loss = 0.07244553978211786
Trained batch 380 in epoch 9, gen_loss = 0.392869512240092, disc_loss = 0.07228957999771427
Trained batch 381 in epoch 9, gen_loss = 0.3929779723832745, disc_loss = 0.0721183948582087
Trained batch 382 in epoch 9, gen_loss = 0.39293799543505237, disc_loss = 0.07213497784489635
Trained batch 383 in epoch 9, gen_loss = 0.3931536949239671, disc_loss = 0.07203063439737889
Trained batch 384 in epoch 9, gen_loss = 0.39308895894459317, disc_loss = 0.07189941910010847
Trained batch 385 in epoch 9, gen_loss = 0.3931668149066095, disc_loss = 0.07181476854352484
Trained batch 386 in epoch 9, gen_loss = 0.3930247512282635, disc_loss = 0.07186791823108414
Trained batch 387 in epoch 9, gen_loss = 0.3930599212492864, disc_loss = 0.07179392290123998
Trained batch 388 in epoch 9, gen_loss = 0.39298573151652183, disc_loss = 0.0716427491156619
Trained batch 389 in epoch 9, gen_loss = 0.3930363336434731, disc_loss = 0.07147856551365783
Trained batch 390 in epoch 9, gen_loss = 0.39311848134945726, disc_loss = 0.0713104866504612
Trained batch 391 in epoch 9, gen_loss = 0.3930353936644233, disc_loss = 0.07118642345493735
Trained batch 392 in epoch 9, gen_loss = 0.3929722386462088, disc_loss = 0.07107137278333761
Trained batch 393 in epoch 9, gen_loss = 0.39297476289841127, disc_loss = 0.07102362662293774
Trained batch 394 in epoch 9, gen_loss = 0.39303541862511937, disc_loss = 0.07094167310720946
Trained batch 395 in epoch 9, gen_loss = 0.39323128579240857, disc_loss = 0.07078757973486614
Trained batch 396 in epoch 9, gen_loss = 0.39316670037336854, disc_loss = 0.0706255883881611
Trained batch 397 in epoch 9, gen_loss = 0.3930885660738202, disc_loss = 0.07048443446389807
Trained batch 398 in epoch 9, gen_loss = 0.3929993370571232, disc_loss = 0.07032645672891186
Trained batch 399 in epoch 9, gen_loss = 0.39313195236027243, disc_loss = 0.07017913176561706
Trained batch 400 in epoch 9, gen_loss = 0.39303960474649274, disc_loss = 0.07001944278318091
Trained batch 401 in epoch 9, gen_loss = 0.39307356251412956, disc_loss = 0.06985853285649189
Trained batch 402 in epoch 9, gen_loss = 0.3929400313137187, disc_loss = 0.0697319675456483
Trained batch 403 in epoch 9, gen_loss = 0.39314270897371933, disc_loss = 0.06961366786773658
Trained batch 404 in epoch 9, gen_loss = 0.39307507431065597, disc_loss = 0.0695284132408783
Trained batch 405 in epoch 9, gen_loss = 0.39283596742622956, disc_loss = 0.06967627145051773
Trained batch 406 in epoch 9, gen_loss = 0.3928848787666246, disc_loss = 0.06954343358960909
Trained batch 407 in epoch 9, gen_loss = 0.3929448006492035, disc_loss = 0.06941652358806345
Trained batch 408 in epoch 9, gen_loss = 0.392995317655554, disc_loss = 0.06926034177336979
Trained batch 409 in epoch 9, gen_loss = 0.3928680128440624, disc_loss = 0.06913365037521212
Trained batch 410 in epoch 9, gen_loss = 0.3928447351983574, disc_loss = 0.06900940420799447
Trained batch 411 in epoch 9, gen_loss = 0.39278013396610334, disc_loss = 0.0688669448605404
Trained batch 412 in epoch 9, gen_loss = 0.3929588101966618, disc_loss = 0.0687217254430669
Trained batch 413 in epoch 9, gen_loss = 0.3931291491369118, disc_loss = 0.06858209170994983
Trained batch 414 in epoch 9, gen_loss = 0.39321074363697006, disc_loss = 0.06844294252749308
Trained batch 415 in epoch 9, gen_loss = 0.3933099949589142, disc_loss = 0.06829068234835106
Trained batch 416 in epoch 9, gen_loss = 0.39338536235354216, disc_loss = 0.06814951230313995
Trained batch 417 in epoch 9, gen_loss = 0.3933596531882811, disc_loss = 0.06801956995394812
Trained batch 418 in epoch 9, gen_loss = 0.3934866325809734, disc_loss = 0.06792766058501878
Trained batch 419 in epoch 9, gen_loss = 0.39368584234090076, disc_loss = 0.06786432473787239
Trained batch 420 in epoch 9, gen_loss = 0.393693526751072, disc_loss = 0.06771405020423428
Trained batch 421 in epoch 9, gen_loss = 0.39363995173248634, disc_loss = 0.0676038742144879
Trained batch 422 in epoch 9, gen_loss = 0.3935243171016657, disc_loss = 0.06760705477749625
Trained batch 423 in epoch 9, gen_loss = 0.3935925909230169, disc_loss = 0.06782398663267915
Trained batch 424 in epoch 9, gen_loss = 0.393727604711757, disc_loss = 0.06768790920210235
Trained batch 425 in epoch 9, gen_loss = 0.39333512063877124, disc_loss = 0.06769123738369262
Trained batch 426 in epoch 9, gen_loss = 0.3934430835258207, disc_loss = 0.06756968804323213
Trained batch 427 in epoch 9, gen_loss = 0.39357650008435563, disc_loss = 0.06744146055463597
Trained batch 428 in epoch 9, gen_loss = 0.39348765207337333, disc_loss = 0.06738106939411942
Trained batch 429 in epoch 9, gen_loss = 0.3935578109220017, disc_loss = 0.06724738518295939
Trained batch 430 in epoch 9, gen_loss = 0.3936988172011143, disc_loss = 0.06710507592787046
Trained batch 431 in epoch 9, gen_loss = 0.3936046844141351, disc_loss = 0.06703472638468223
Trained batch 432 in epoch 9, gen_loss = 0.3936093209384495, disc_loss = 0.06693102274838551
Trained batch 433 in epoch 9, gen_loss = 0.3937347843762367, disc_loss = 0.06679294928522085
Trained batch 434 in epoch 9, gen_loss = 0.3938306108973492, disc_loss = 0.0666534461380764
Trained batch 435 in epoch 9, gen_loss = 0.393902068838067, disc_loss = 0.06653525230021926
Trained batch 436 in epoch 9, gen_loss = 0.39400827468669114, disc_loss = 0.0664442963344077
Trained batch 437 in epoch 9, gen_loss = 0.3941654266287747, disc_loss = 0.06648558475604477
Trained batch 438 in epoch 9, gen_loss = 0.3941132905542986, disc_loss = 0.06643467379950309
Trained batch 439 in epoch 9, gen_loss = 0.3939576335928657, disc_loss = 0.06634376162070442
Trained batch 440 in epoch 9, gen_loss = 0.3941382210270888, disc_loss = 0.06621821704500117
Trained batch 441 in epoch 9, gen_loss = 0.39415967477932234, disc_loss = 0.06609171979567584
Trained batch 442 in epoch 9, gen_loss = 0.3941278330493996, disc_loss = 0.0659860642227443
Trained batch 443 in epoch 9, gen_loss = 0.3939740485301963, disc_loss = 0.06586532840538803
Trained batch 444 in epoch 9, gen_loss = 0.39395694980460605, disc_loss = 0.06574321014367128
Trained batch 445 in epoch 9, gen_loss = 0.393841748748125, disc_loss = 0.06565761118667877
Trained batch 446 in epoch 9, gen_loss = 0.39389719132342327, disc_loss = 0.06552767006355344
Trained batch 447 in epoch 9, gen_loss = 0.3940271060647709, disc_loss = 0.06544617937990031
Trained batch 448 in epoch 9, gen_loss = 0.3939853581394544, disc_loss = 0.0653377205604285
Trained batch 449 in epoch 9, gen_loss = 0.3941014199786716, disc_loss = 0.06520657500148648
Trained batch 450 in epoch 9, gen_loss = 0.3940856523497935, disc_loss = 0.06509979847847523
Trained batch 451 in epoch 9, gen_loss = 0.3942597544035025, disc_loss = 0.06496828257011464
Trained batch 452 in epoch 9, gen_loss = 0.3943937723473471, disc_loss = 0.06485454333847426
Trained batch 453 in epoch 9, gen_loss = 0.3944351199833832, disc_loss = 0.06478381833361076
Trained batch 454 in epoch 9, gen_loss = 0.394657044161807, disc_loss = 0.06513521006781157
Trained batch 455 in epoch 9, gen_loss = 0.39451166516856145, disc_loss = 0.06530562151333709
Trained batch 456 in epoch 9, gen_loss = 0.39460704010998915, disc_loss = 0.06527540440155556
Trained batch 457 in epoch 9, gen_loss = 0.39464826940449044, disc_loss = 0.06519763217933931
Trained batch 458 in epoch 9, gen_loss = 0.3947406367019371, disc_loss = 0.0651030419404519
Trained batch 459 in epoch 9, gen_loss = 0.39472331981296127, disc_loss = 0.06522439752563672
Trained batch 460 in epoch 9, gen_loss = 0.3948726447828421, disc_loss = 0.06599786414092088
Trained batch 461 in epoch 9, gen_loss = 0.3946572949876001, disc_loss = 0.06601899806148014
Trained batch 462 in epoch 9, gen_loss = 0.39463393309718847, disc_loss = 0.065933257891529
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.3083953559398651, disc_loss = 0.08697061240673065
Trained batch 1 in epoch 10, gen_loss = 0.3483438640832901, disc_loss = 0.09684799984097481
Trained batch 2 in epoch 10, gen_loss = 0.3621196548144023, disc_loss = 0.10600205510854721
Trained batch 3 in epoch 10, gen_loss = 0.36228547990322113, disc_loss = 0.10738112032413483
Trained batch 4 in epoch 10, gen_loss = 0.36068102717399597, disc_loss = 0.09755857810378074
Trained batch 5 in epoch 10, gen_loss = 0.3672068268060684, disc_loss = 0.09165332652628422
Trained batch 6 in epoch 10, gen_loss = 0.3637722645487104, disc_loss = 0.09744019966040339
Trained batch 7 in epoch 10, gen_loss = 0.36696353182196617, disc_loss = 0.11250710813328624
Trained batch 8 in epoch 10, gen_loss = 0.3718579676416185, disc_loss = 0.11210397589537832
Trained batch 9 in epoch 10, gen_loss = 0.37420895993709563, disc_loss = 0.10476676449179649
Trained batch 10 in epoch 10, gen_loss = 0.3756689483469183, disc_loss = 0.0974050411446528
Trained batch 11 in epoch 10, gen_loss = 0.3734062487880389, disc_loss = 0.10022135482480128
Trained batch 12 in epoch 10, gen_loss = 0.3767156990674826, disc_loss = 0.10604963308343521
Trained batch 13 in epoch 10, gen_loss = 0.37278543199811665, disc_loss = 0.1056044019226517
Trained batch 14 in epoch 10, gen_loss = 0.3753328263759613, disc_loss = 0.10065354605515799
Trained batch 15 in epoch 10, gen_loss = 0.38070475682616234, disc_loss = 0.09600443253293633
Trained batch 16 in epoch 10, gen_loss = 0.3805209731354433, disc_loss = 0.09923119623871411
Trained batch 17 in epoch 10, gen_loss = 0.3807363510131836, disc_loss = 0.10142900504999691
Trained batch 18 in epoch 10, gen_loss = 0.37845135676233393, disc_loss = 0.10101599128622758
Trained batch 19 in epoch 10, gen_loss = 0.3800207942724228, disc_loss = 0.09918155148625374
Trained batch 20 in epoch 10, gen_loss = 0.3771950928937821, disc_loss = 0.09715652146509715
Trained batch 21 in epoch 10, gen_loss = 0.3791169117797505, disc_loss = 0.09678725458004257
Trained batch 22 in epoch 10, gen_loss = 0.3783198776452438, disc_loss = 0.09643751771553703
Trained batch 23 in epoch 10, gen_loss = 0.38231710344552994, disc_loss = 0.09363792029519875
Trained batch 24 in epoch 10, gen_loss = 0.38321868896484373, disc_loss = 0.09030250009149313
Trained batch 25 in epoch 10, gen_loss = 0.38403914868831635, disc_loss = 0.0876504578627646
Trained batch 26 in epoch 10, gen_loss = 0.38581585773715266, disc_loss = 0.08819242625462788
Trained batch 27 in epoch 10, gen_loss = 0.3850183231489999, disc_loss = 0.09537386445195548
Trained batch 28 in epoch 10, gen_loss = 0.38635307653196926, disc_loss = 0.10631746956115139
Trained batch 29 in epoch 10, gen_loss = 0.3899862011273702, disc_loss = 0.10353957666084171
Trained batch 30 in epoch 10, gen_loss = 0.38971899690166595, disc_loss = 0.1015347825483449
Trained batch 31 in epoch 10, gen_loss = 0.38985801581293344, disc_loss = 0.09948022643220611
Trained batch 32 in epoch 10, gen_loss = 0.3925087542244882, disc_loss = 0.09678315777670253
Trained batch 33 in epoch 10, gen_loss = 0.39100906252861023, disc_loss = 0.09433836298172965
Trained batch 34 in epoch 10, gen_loss = 0.3900739925248282, disc_loss = 0.09201854305075748
Trained batch 35 in epoch 10, gen_loss = 0.3884076517489221, disc_loss = 0.08991320847740604
Trained batch 36 in epoch 10, gen_loss = 0.39024123227274093, disc_loss = 0.08822613438541019
Trained batch 37 in epoch 10, gen_loss = 0.3913583943718358, disc_loss = 0.08751859915393748
Trained batch 38 in epoch 10, gen_loss = 0.3890603398665404, disc_loss = 0.08779730540342055
Trained batch 39 in epoch 10, gen_loss = 0.39028315544128417, disc_loss = 0.08802627387922257
Trained batch 40 in epoch 10, gen_loss = 0.38887562402864784, disc_loss = 0.08737080660080765
Trained batch 41 in epoch 10, gen_loss = 0.3900730510552724, disc_loss = 0.08649498195431772
Trained batch 42 in epoch 10, gen_loss = 0.39011524721633556, disc_loss = 0.08521612211628708
Trained batch 43 in epoch 10, gen_loss = 0.3906074789437381, disc_loss = 0.08405003474432636
Trained batch 44 in epoch 10, gen_loss = 0.39123990933100383, disc_loss = 0.08310286665542257
Trained batch 45 in epoch 10, gen_loss = 0.39164357211278833, disc_loss = 0.08177882661719037
Trained batch 46 in epoch 10, gen_loss = 0.3919990531941678, disc_loss = 0.0801450680505405
Trained batch 47 in epoch 10, gen_loss = 0.39131137418250245, disc_loss = 0.07870701015538846
Trained batch 48 in epoch 10, gen_loss = 0.38916277824615947, disc_loss = 0.07730220636466936
Trained batch 49 in epoch 10, gen_loss = 0.3904747998714447, disc_loss = 0.07601079413667321
Trained batch 50 in epoch 10, gen_loss = 0.38962528635473814, disc_loss = 0.07465795039509733
Trained batch 51 in epoch 10, gen_loss = 0.3887771236208769, disc_loss = 0.07407734298612922
Trained batch 52 in epoch 10, gen_loss = 0.390342172024385, disc_loss = 0.07444022088926637
Trained batch 53 in epoch 10, gen_loss = 0.3901907762995473, disc_loss = 0.07467581937951898
Trained batch 54 in epoch 10, gen_loss = 0.39225029240955006, disc_loss = 0.07346991811116987
Trained batch 55 in epoch 10, gen_loss = 0.3924511005835874, disc_loss = 0.07234235241776332
Trained batch 56 in epoch 10, gen_loss = 0.39215089302313955, disc_loss = 0.07227563728137236
Trained batch 57 in epoch 10, gen_loss = 0.39366632031983345, disc_loss = 0.07423758867260968
Trained batch 58 in epoch 10, gen_loss = 0.3913483958123094, disc_loss = 0.08024444570764899
Trained batch 59 in epoch 10, gen_loss = 0.3923119013508161, disc_loss = 0.08149314573189864
Trained batch 60 in epoch 10, gen_loss = 0.39190306184721774, disc_loss = 0.08276960254478895
Trained batch 61 in epoch 10, gen_loss = 0.39181748032569885, disc_loss = 0.08336134652246631
Trained batch 62 in epoch 10, gen_loss = 0.3911721370522938, disc_loss = 0.08298269086443479
Trained batch 63 in epoch 10, gen_loss = 0.39158074418082833, disc_loss = 0.08202465344947996
Trained batch 64 in epoch 10, gen_loss = 0.3903524944415459, disc_loss = 0.0813466291086605
Trained batch 65 in epoch 10, gen_loss = 0.3908720955704198, disc_loss = 0.08060849515128542
Trained batch 66 in epoch 10, gen_loss = 0.3910083503865484, disc_loss = 0.08087854499497743
Trained batch 67 in epoch 10, gen_loss = 0.39101167987374696, disc_loss = 0.0822168423260069
Trained batch 68 in epoch 10, gen_loss = 0.39248198918674304, disc_loss = 0.08283029410961097
Trained batch 69 in epoch 10, gen_loss = 0.3914863875934056, disc_loss = 0.08231583791784942
Trained batch 70 in epoch 10, gen_loss = 0.3909415997249979, disc_loss = 0.08155063285925229
Trained batch 71 in epoch 10, gen_loss = 0.3917885228163666, disc_loss = 0.08136283904443392
Trained batch 72 in epoch 10, gen_loss = 0.39068008408154525, disc_loss = 0.08325763544935273
Trained batch 73 in epoch 10, gen_loss = 0.3907740027517886, disc_loss = 0.08489236827763552
Trained batch 74 in epoch 10, gen_loss = 0.38951611797014873, disc_loss = 0.085292101384451
Trained batch 75 in epoch 10, gen_loss = 0.3884521420848997, disc_loss = 0.08626014021788969
Trained batch 76 in epoch 10, gen_loss = 0.38830887458541175, disc_loss = 0.08535259974781763
Trained batch 77 in epoch 10, gen_loss = 0.3880704813278638, disc_loss = 0.08444133750163019
Trained batch 78 in epoch 10, gen_loss = 0.38836032303073736, disc_loss = 0.08390620761680641
Trained batch 79 in epoch 10, gen_loss = 0.3877195347100496, disc_loss = 0.08505255221971311
Trained batch 80 in epoch 10, gen_loss = 0.3887275380116922, disc_loss = 0.08758200480269245
Trained batch 81 in epoch 10, gen_loss = 0.3883323716681178, disc_loss = 0.08682913274685966
Trained batch 82 in epoch 10, gen_loss = 0.3877755198852125, disc_loss = 0.08615168281101498
Trained batch 83 in epoch 10, gen_loss = 0.3881233040065992, disc_loss = 0.08519331002718813
Trained batch 84 in epoch 10, gen_loss = 0.3879180760944591, disc_loss = 0.08425670653472052
Trained batch 85 in epoch 10, gen_loss = 0.3878638650788817, disc_loss = 0.08371265507086592
Trained batch 86 in epoch 10, gen_loss = 0.3865155187146417, disc_loss = 0.08534357068931749
Trained batch 87 in epoch 10, gen_loss = 0.3863045292144472, disc_loss = 0.08516244765434583
Trained batch 88 in epoch 10, gen_loss = 0.38562715187501373, disc_loss = 0.08492712799480624
Trained batch 89 in epoch 10, gen_loss = 0.3846876223882039, disc_loss = 0.08505488970937829
Trained batch 90 in epoch 10, gen_loss = 0.3853286033148294, disc_loss = 0.0857007933094852
Trained batch 91 in epoch 10, gen_loss = 0.3849490667166917, disc_loss = 0.08706489000368216
Trained batch 92 in epoch 10, gen_loss = 0.38588279966385136, disc_loss = 0.08709338937775903
Trained batch 93 in epoch 10, gen_loss = 0.3856463153311547, disc_loss = 0.08742487713436972
Trained batch 94 in epoch 10, gen_loss = 0.3852395318056408, disc_loss = 0.08718149502712645
Trained batch 95 in epoch 10, gen_loss = 0.385638306538264, disc_loss = 0.08659466776589397
Trained batch 96 in epoch 10, gen_loss = 0.3856896499997562, disc_loss = 0.08609819137155242
Trained batch 97 in epoch 10, gen_loss = 0.386075961346529, disc_loss = 0.08534165142503168
Trained batch 98 in epoch 10, gen_loss = 0.3857723323985784, disc_loss = 0.08478811424169125
Trained batch 99 in epoch 10, gen_loss = 0.38539330184459686, disc_loss = 0.08403529648203403
Trained batch 100 in epoch 10, gen_loss = 0.3853244451012942, disc_loss = 0.08364781579187158
Trained batch 101 in epoch 10, gen_loss = 0.3861263499540441, disc_loss = 0.08376976106699337
Trained batch 102 in epoch 10, gen_loss = 0.3853899202879193, disc_loss = 0.0838185500000938
Trained batch 103 in epoch 10, gen_loss = 0.385687552105922, disc_loss = 0.0830676091539387
Trained batch 104 in epoch 10, gen_loss = 0.38636397265252614, disc_loss = 0.08242134526815442
Trained batch 105 in epoch 10, gen_loss = 0.38679129981769705, disc_loss = 0.08186354019397975
Trained batch 106 in epoch 10, gen_loss = 0.3866081402123531, disc_loss = 0.08130987638294279
Trained batch 107 in epoch 10, gen_loss = 0.38615504017582647, disc_loss = 0.08074784857065727
Trained batch 108 in epoch 10, gen_loss = 0.38617084059146567, disc_loss = 0.08005316581987186
Trained batch 109 in epoch 10, gen_loss = 0.38726673017848623, disc_loss = 0.07948220716789364
Trained batch 110 in epoch 10, gen_loss = 0.38791049493325724, disc_loss = 0.07885026427506057
Trained batch 111 in epoch 10, gen_loss = 0.3880523017474583, disc_loss = 0.07841048279078677
Trained batch 112 in epoch 10, gen_loss = 0.3882017568149398, disc_loss = 0.0780509494294503
Trained batch 113 in epoch 10, gen_loss = 0.388673348384991, disc_loss = 0.07847301219998483
Trained batch 114 in epoch 10, gen_loss = 0.38816304103187893, disc_loss = 0.07836294008175963
Trained batch 115 in epoch 10, gen_loss = 0.388584339156233, disc_loss = 0.07776422813887997
Trained batch 116 in epoch 10, gen_loss = 0.3891354918989361, disc_loss = 0.0772844328919155
Trained batch 117 in epoch 10, gen_loss = 0.3894721724219241, disc_loss = 0.07682075559051108
Trained batch 118 in epoch 10, gen_loss = 0.3898856629844473, disc_loss = 0.07622951148625683
Trained batch 119 in epoch 10, gen_loss = 0.39040553470452627, disc_loss = 0.07567807663387309
Trained batch 120 in epoch 10, gen_loss = 0.390737131607434, disc_loss = 0.07610096595411704
Trained batch 121 in epoch 10, gen_loss = 0.3907113644431849, disc_loss = 0.07773859314162468
Trained batch 122 in epoch 10, gen_loss = 0.3911144595320632, disc_loss = 0.07839514718701442
Trained batch 123 in epoch 10, gen_loss = 0.3911944659006211, disc_loss = 0.07834610442871288
Trained batch 124 in epoch 10, gen_loss = 0.3909036238193512, disc_loss = 0.07829481760412454
Trained batch 125 in epoch 10, gen_loss = 0.39099803212143125, disc_loss = 0.07792033674195409
Trained batch 126 in epoch 10, gen_loss = 0.3907183878065094, disc_loss = 0.07766377936872676
Trained batch 127 in epoch 10, gen_loss = 0.3910945076495409, disc_loss = 0.07721626607963117
Trained batch 128 in epoch 10, gen_loss = 0.391406014677166, disc_loss = 0.07677062630451234
Trained batch 129 in epoch 10, gen_loss = 0.39117984702953923, disc_loss = 0.07682720916345716
Trained batch 130 in epoch 10, gen_loss = 0.3914337911223637, disc_loss = 0.07736327596549086
Trained batch 131 in epoch 10, gen_loss = 0.3907149504079963, disc_loss = 0.07762951963355369
Trained batch 132 in epoch 10, gen_loss = 0.39067342518863823, disc_loss = 0.0772271824972634
Trained batch 133 in epoch 10, gen_loss = 0.39086224183217805, disc_loss = 0.07678714901236679
Trained batch 134 in epoch 10, gen_loss = 0.39070829881562125, disc_loss = 0.07631608249826563
Trained batch 135 in epoch 10, gen_loss = 0.39083705316571626, disc_loss = 0.07594579076805316
Trained batch 136 in epoch 10, gen_loss = 0.3906427804570999, disc_loss = 0.07575308324184514
Trained batch 137 in epoch 10, gen_loss = 0.39063562733539636, disc_loss = 0.07549724017229417
Trained batch 138 in epoch 10, gen_loss = 0.3905897170519657, disc_loss = 0.07505175795593708
Trained batch 139 in epoch 10, gen_loss = 0.39102683407919747, disc_loss = 0.0745588135340118
Trained batch 140 in epoch 10, gen_loss = 0.390779566468922, disc_loss = 0.07420514480058923
Trained batch 141 in epoch 10, gen_loss = 0.3913180515379973, disc_loss = 0.0741611396808597
Trained batch 142 in epoch 10, gen_loss = 0.3917647510558575, disc_loss = 0.07377004350854696
Trained batch 143 in epoch 10, gen_loss = 0.39217247689763707, disc_loss = 0.07374007724057366
Trained batch 144 in epoch 10, gen_loss = 0.39281952997733804, disc_loss = 0.07424067488454025
Trained batch 145 in epoch 10, gen_loss = 0.3930906973881264, disc_loss = 0.07385218146971542
Trained batch 146 in epoch 10, gen_loss = 0.3931976560832692, disc_loss = 0.07372467390572031
Trained batch 147 in epoch 10, gen_loss = 0.3936839272847047, disc_loss = 0.07425683997005124
Trained batch 148 in epoch 10, gen_loss = 0.39295507417429215, disc_loss = 0.07614227667788431
Trained batch 149 in epoch 10, gen_loss = 0.3937337205807368, disc_loss = 0.0764675198836873
Trained batch 150 in epoch 10, gen_loss = 0.3936558509899291, disc_loss = 0.07645084865280236
Trained batch 151 in epoch 10, gen_loss = 0.3933627377999456, disc_loss = 0.07635235022692206
Trained batch 152 in epoch 10, gen_loss = 0.3926539160067739, disc_loss = 0.07697525368151224
Trained batch 153 in epoch 10, gen_loss = 0.39299469683077426, disc_loss = 0.0773340626287141
Trained batch 154 in epoch 10, gen_loss = 0.39285782998608004, disc_loss = 0.07714228445904389
Trained batch 155 in epoch 10, gen_loss = 0.3929211147702657, disc_loss = 0.07676429307171836
Trained batch 156 in epoch 10, gen_loss = 0.3929823783172923, disc_loss = 0.07635204321675144
Trained batch 157 in epoch 10, gen_loss = 0.3928812242384198, disc_loss = 0.07592161920782226
Trained batch 158 in epoch 10, gen_loss = 0.3927563100865802, disc_loss = 0.07558052283096707
Trained batch 159 in epoch 10, gen_loss = 0.3929543660953641, disc_loss = 0.0751621864939807
Trained batch 160 in epoch 10, gen_loss = 0.39288850397056674, disc_loss = 0.07488539735989078
Trained batch 161 in epoch 10, gen_loss = 0.39271049201488495, disc_loss = 0.07557941876340335
Trained batch 162 in epoch 10, gen_loss = 0.39344040948920456, disc_loss = 0.07716056023170155
Trained batch 163 in epoch 10, gen_loss = 0.39286370775321633, disc_loss = 0.07718439313594433
Trained batch 164 in epoch 10, gen_loss = 0.3927076321659666, disc_loss = 0.07960019711913033
Trained batch 165 in epoch 10, gen_loss = 0.3924848543233182, disc_loss = 0.07969052025610693
Trained batch 166 in epoch 10, gen_loss = 0.3928406475903745, disc_loss = 0.0797401491279329
Trained batch 167 in epoch 10, gen_loss = 0.39262723869511057, disc_loss = 0.07943875223697562
Trained batch 168 in epoch 10, gen_loss = 0.3925349528972919, disc_loss = 0.07913406614004773
Trained batch 169 in epoch 10, gen_loss = 0.39253710683654336, disc_loss = 0.07873066835488905
Trained batch 170 in epoch 10, gen_loss = 0.392639655641645, disc_loss = 0.078423004507561
Trained batch 171 in epoch 10, gen_loss = 0.39257749568584355, disc_loss = 0.07845966866359028
Trained batch 172 in epoch 10, gen_loss = 0.3924978794045531, disc_loss = 0.07819782890583997
Trained batch 173 in epoch 10, gen_loss = 0.39232163456664687, disc_loss = 0.07794180989597292
Trained batch 174 in epoch 10, gen_loss = 0.39250176906585693, disc_loss = 0.07773813109046647
Trained batch 175 in epoch 10, gen_loss = 0.39193764312023466, disc_loss = 0.07778881081454032
Trained batch 176 in epoch 10, gen_loss = 0.3922792556932417, disc_loss = 0.07780441622602316
Trained batch 177 in epoch 10, gen_loss = 0.3920637337344416, disc_loss = 0.07748135419698494
Trained batch 178 in epoch 10, gen_loss = 0.39217966978110413, disc_loss = 0.07707733561040303
Trained batch 179 in epoch 10, gen_loss = 0.39254677212900585, disc_loss = 0.07697473716818624
Trained batch 180 in epoch 10, gen_loss = 0.39265817173278134, disc_loss = 0.07682873952866259
Trained batch 181 in epoch 10, gen_loss = 0.39245081193499515, disc_loss = 0.07643010249555848
Trained batch 182 in epoch 10, gen_loss = 0.39240367735018494, disc_loss = 0.07609918312795583
Trained batch 183 in epoch 10, gen_loss = 0.3926295140839141, disc_loss = 0.07598074746530746
Trained batch 184 in epoch 10, gen_loss = 0.39289033541808255, disc_loss = 0.07561735220102442
Trained batch 185 in epoch 10, gen_loss = 0.39286631521999194, disc_loss = 0.07533278615934955
Trained batch 186 in epoch 10, gen_loss = 0.39331844050616505, disc_loss = 0.07567556548295891
Trained batch 187 in epoch 10, gen_loss = 0.39309148839179503, disc_loss = 0.07626819090689829
Trained batch 188 in epoch 10, gen_loss = 0.39342997329575674, disc_loss = 0.07607124226719693
Trained batch 189 in epoch 10, gen_loss = 0.3934388667345047, disc_loss = 0.07580802047772235
Trained batch 190 in epoch 10, gen_loss = 0.3932732624533289, disc_loss = 0.07548677660183523
Trained batch 191 in epoch 10, gen_loss = 0.392848485459884, disc_loss = 0.07512634163382852
Trained batch 192 in epoch 10, gen_loss = 0.3927650579825584, disc_loss = 0.07502409780320803
Trained batch 193 in epoch 10, gen_loss = 0.39260269609308734, disc_loss = 0.07477573192313544
Trained batch 194 in epoch 10, gen_loss = 0.3926443089277316, disc_loss = 0.07442008739050765
Trained batch 195 in epoch 10, gen_loss = 0.39276057740255277, disc_loss = 0.07416896623492773
Trained batch 196 in epoch 10, gen_loss = 0.39261997638620094, disc_loss = 0.0738643758391328
Trained batch 197 in epoch 10, gen_loss = 0.3925001008643044, disc_loss = 0.07370726775255694
Trained batch 198 in epoch 10, gen_loss = 0.39237417557730747, disc_loss = 0.07401141288208228
Trained batch 199 in epoch 10, gen_loss = 0.3927043929696083, disc_loss = 0.07395792063092813
Trained batch 200 in epoch 10, gen_loss = 0.39291971195396497, disc_loss = 0.07367456928405225
Trained batch 201 in epoch 10, gen_loss = 0.39295764341212736, disc_loss = 0.07337461751516872
Trained batch 202 in epoch 10, gen_loss = 0.39307514434964785, disc_loss = 0.07312349788156416
Trained batch 203 in epoch 10, gen_loss = 0.39297694230780883, disc_loss = 0.07279146851186513
Trained batch 204 in epoch 10, gen_loss = 0.3932547051732133, disc_loss = 0.0726304512879834
Trained batch 205 in epoch 10, gen_loss = 0.392821422769028, disc_loss = 0.07259210632679966
Trained batch 206 in epoch 10, gen_loss = 0.3924665050806055, disc_loss = 0.07230985650999679
Trained batch 207 in epoch 10, gen_loss = 0.39305120362685275, disc_loss = 0.07207405492394733
Trained batch 208 in epoch 10, gen_loss = 0.39314179058280285, disc_loss = 0.07200701212572852
Trained batch 209 in epoch 10, gen_loss = 0.3932499058189846, disc_loss = 0.07188955176887768
Trained batch 210 in epoch 10, gen_loss = 0.3930197440052485, disc_loss = 0.07185706203600382
Trained batch 211 in epoch 10, gen_loss = 0.3933831641696534, disc_loss = 0.0720673370095989
Trained batch 212 in epoch 10, gen_loss = 0.39342255225763634, disc_loss = 0.07191439487582221
Trained batch 213 in epoch 10, gen_loss = 0.3933595398040575, disc_loss = 0.07162310894160906
Trained batch 214 in epoch 10, gen_loss = 0.39356426388718363, disc_loss = 0.0713356148494884
Trained batch 215 in epoch 10, gen_loss = 0.3935364030853466, disc_loss = 0.07109613237574834
Trained batch 216 in epoch 10, gen_loss = 0.3937938799781184, disc_loss = 0.07082031645344287
Trained batch 217 in epoch 10, gen_loss = 0.393576371560403, disc_loss = 0.07066503379476863
Trained batch 218 in epoch 10, gen_loss = 0.3937779047173452, disc_loss = 0.07073750252065729
Trained batch 219 in epoch 10, gen_loss = 0.3935426262291995, disc_loss = 0.07067678533917801
Trained batch 220 in epoch 10, gen_loss = 0.3940325713804944, disc_loss = 0.07040338029419135
Trained batch 221 in epoch 10, gen_loss = 0.39386497894385913, disc_loss = 0.07011413357958936
Trained batch 222 in epoch 10, gen_loss = 0.39385527920295305, disc_loss = 0.06986057857101607
Trained batch 223 in epoch 10, gen_loss = 0.3940553577350719, disc_loss = 0.06957489429415935
Trained batch 224 in epoch 10, gen_loss = 0.3938880896568298, disc_loss = 0.06932893020618293
Trained batch 225 in epoch 10, gen_loss = 0.39356315017273996, disc_loss = 0.06922822599958596
Trained batch 226 in epoch 10, gen_loss = 0.3940003211015122, disc_loss = 0.06971390790917341
Trained batch 227 in epoch 10, gen_loss = 0.39400206780747365, disc_loss = 0.07005174068546151
Trained batch 228 in epoch 10, gen_loss = 0.3942162270889532, disc_loss = 0.0697922222824629
Trained batch 229 in epoch 10, gen_loss = 0.3944906813942868, disc_loss = 0.06977389442086544
Trained batch 230 in epoch 10, gen_loss = 0.3946567182933097, disc_loss = 0.06965979211459751
Trained batch 231 in epoch 10, gen_loss = 0.3948664328661458, disc_loss = 0.06940821943009787
Trained batch 232 in epoch 10, gen_loss = 0.3948687133359295, disc_loss = 0.069246193204203
Trained batch 233 in epoch 10, gen_loss = 0.39497016535864937, disc_loss = 0.06915599484450351
Trained batch 234 in epoch 10, gen_loss = 0.3945428394256754, disc_loss = 0.06933813019992506
Trained batch 235 in epoch 10, gen_loss = 0.3947513638916662, disc_loss = 0.07019328427998255
Trained batch 236 in epoch 10, gen_loss = 0.39460259424483224, disc_loss = 0.07005104278941257
Trained batch 237 in epoch 10, gen_loss = 0.39438575806737947, disc_loss = 0.07002396331591328
Trained batch 238 in epoch 10, gen_loss = 0.39465641501558374, disc_loss = 0.06982756078157527
Trained batch 239 in epoch 10, gen_loss = 0.39455214912692704, disc_loss = 0.07044344680422607
Trained batch 240 in epoch 10, gen_loss = 0.3941851828355512, disc_loss = 0.07144983056584892
Trained batch 241 in epoch 10, gen_loss = 0.3942201854276263, disc_loss = 0.0713066874275923
Trained batch 242 in epoch 10, gen_loss = 0.3941262575333992, disc_loss = 0.07115435739212628
Trained batch 243 in epoch 10, gen_loss = 0.39420948214218265, disc_loss = 0.07095822549356362
Trained batch 244 in epoch 10, gen_loss = 0.3939208767852005, disc_loss = 0.0708379470059002
Trained batch 245 in epoch 10, gen_loss = 0.39371480059817554, disc_loss = 0.07066985730997975
Trained batch 246 in epoch 10, gen_loss = 0.3936718023016385, disc_loss = 0.07060793083847354
Trained batch 247 in epoch 10, gen_loss = 0.39355712720463354, disc_loss = 0.07125148452976118
Trained batch 248 in epoch 10, gen_loss = 0.3937481165411003, disc_loss = 0.07219723165671091
Trained batch 249 in epoch 10, gen_loss = 0.39352982604503634, disc_loss = 0.07280888729728759
Trained batch 250 in epoch 10, gen_loss = 0.39323383059159694, disc_loss = 0.07297354467042473
Trained batch 251 in epoch 10, gen_loss = 0.3933728088935216, disc_loss = 0.07309027680838924
Trained batch 252 in epoch 10, gen_loss = 0.3932850206557941, disc_loss = 0.07315764148634943
Trained batch 253 in epoch 10, gen_loss = 0.3930959470394089, disc_loss = 0.07362216293965797
Trained batch 254 in epoch 10, gen_loss = 0.3931930865727219, disc_loss = 0.07338340591602757
Trained batch 255 in epoch 10, gen_loss = 0.39313092234078795, disc_loss = 0.0734419344462367
Trained batch 256 in epoch 10, gen_loss = 0.3932912582785239, disc_loss = 0.07327146953740067
Trained batch 257 in epoch 10, gen_loss = 0.39311737954154496, disc_loss = 0.0734309062105423
Trained batch 258 in epoch 10, gen_loss = 0.39321349543954415, disc_loss = 0.07380458955117232
Trained batch 259 in epoch 10, gen_loss = 0.39289418951823163, disc_loss = 0.07384809414103914
Trained batch 260 in epoch 10, gen_loss = 0.3928149113024788, disc_loss = 0.07366372058453516
Trained batch 261 in epoch 10, gen_loss = 0.39313066153580906, disc_loss = 0.0735865185296746
Trained batch 262 in epoch 10, gen_loss = 0.3930586071068796, disc_loss = 0.07342219169467631
Trained batch 263 in epoch 10, gen_loss = 0.39306473291733046, disc_loss = 0.07325740948241825
Trained batch 264 in epoch 10, gen_loss = 0.39318059784061504, disc_loss = 0.07317972224873473
Trained batch 265 in epoch 10, gen_loss = 0.39337671105574845, disc_loss = 0.07316241704130587
Trained batch 266 in epoch 10, gen_loss = 0.3935258218858126, disc_loss = 0.0730210962314647
Trained batch 267 in epoch 10, gen_loss = 0.3935210105420938, disc_loss = 0.07290715003671097
Trained batch 268 in epoch 10, gen_loss = 0.39388248767551437, disc_loss = 0.07300266730997254
Trained batch 269 in epoch 10, gen_loss = 0.3938615532936873, disc_loss = 0.0729284857382515
Trained batch 270 in epoch 10, gen_loss = 0.39383767429752986, disc_loss = 0.07268248307535845
Trained batch 271 in epoch 10, gen_loss = 0.39388809243545814, disc_loss = 0.07254135752651457
Trained batch 272 in epoch 10, gen_loss = 0.39387216170628864, disc_loss = 0.07240583459870556
Trained batch 273 in epoch 10, gen_loss = 0.3939044907362792, disc_loss = 0.07224477665247328
Trained batch 274 in epoch 10, gen_loss = 0.3940806289152666, disc_loss = 0.07206419568339532
Trained batch 275 in epoch 10, gen_loss = 0.3941043074364248, disc_loss = 0.07186448535092337
Trained batch 276 in epoch 10, gen_loss = 0.39416967595957675, disc_loss = 0.0716830911904923
Trained batch 277 in epoch 10, gen_loss = 0.3943322483155367, disc_loss = 0.07144130733393454
Trained batch 278 in epoch 10, gen_loss = 0.39410820817007386, disc_loss = 0.07121616050327284
Trained batch 279 in epoch 10, gen_loss = 0.39413524365850855, disc_loss = 0.07099394867296464
Trained batch 280 in epoch 10, gen_loss = 0.39433875722393025, disc_loss = 0.07096566848317658
Trained batch 281 in epoch 10, gen_loss = 0.3942717011515976, disc_loss = 0.07104807616383207
Trained batch 282 in epoch 10, gen_loss = 0.39422724430215655, disc_loss = 0.07082361399357343
Trained batch 283 in epoch 10, gen_loss = 0.39428116055861323, disc_loss = 0.07078251458251927
Trained batch 284 in epoch 10, gen_loss = 0.3938851973466706, disc_loss = 0.07072588161385635
Trained batch 285 in epoch 10, gen_loss = 0.3939681494986261, disc_loss = 0.07052067387034999
Trained batch 286 in epoch 10, gen_loss = 0.3940581254635123, disc_loss = 0.07029660734857468
Trained batch 287 in epoch 10, gen_loss = 0.3940222706231806, disc_loss = 0.07006920428991886
Trained batch 288 in epoch 10, gen_loss = 0.39427405616403866, disc_loss = 0.06986717713004216
Trained batch 289 in epoch 10, gen_loss = 0.394418387988518, disc_loss = 0.06965566670104605
Trained batch 290 in epoch 10, gen_loss = 0.3942568023589878, disc_loss = 0.06944281994317149
Trained batch 291 in epoch 10, gen_loss = 0.39453655644638896, disc_loss = 0.06922255601089652
Trained batch 292 in epoch 10, gen_loss = 0.3944640891950692, disc_loss = 0.06903761867656287
Trained batch 293 in epoch 10, gen_loss = 0.39446913506708986, disc_loss = 0.06886205867370021
Trained batch 294 in epoch 10, gen_loss = 0.39439269203250693, disc_loss = 0.06864347071623651
Trained batch 295 in epoch 10, gen_loss = 0.3943144631748264, disc_loss = 0.06842537647478182
Trained batch 296 in epoch 10, gen_loss = 0.39407927590588526, disc_loss = 0.06825045978819783
Trained batch 297 in epoch 10, gen_loss = 0.3940986735908777, disc_loss = 0.06804068664388868
Trained batch 298 in epoch 10, gen_loss = 0.3940535013292944, disc_loss = 0.06784616210451194
Trained batch 299 in epoch 10, gen_loss = 0.39424571216106413, disc_loss = 0.0677095118816942
Trained batch 300 in epoch 10, gen_loss = 0.39398660622165843, disc_loss = 0.0679063828340252
Trained batch 301 in epoch 10, gen_loss = 0.3946158065898529, disc_loss = 0.06821170810992454
Trained batch 302 in epoch 10, gen_loss = 0.39471529350422396, disc_loss = 0.06805985215928394
Trained batch 303 in epoch 10, gen_loss = 0.39495923644617986, disc_loss = 0.06789546133031284
Trained batch 304 in epoch 10, gen_loss = 0.3951051399356029, disc_loss = 0.06774985293445529
Trained batch 305 in epoch 10, gen_loss = 0.3950685153599658, disc_loss = 0.06755270790978292
Trained batch 306 in epoch 10, gen_loss = 0.39511154868703713, disc_loss = 0.06744905872155187
Trained batch 307 in epoch 10, gen_loss = 0.3951215891094951, disc_loss = 0.06728228104494319
Trained batch 308 in epoch 10, gen_loss = 0.3951641009656357, disc_loss = 0.06707657465988523
Trained batch 309 in epoch 10, gen_loss = 0.39528086954547514, disc_loss = 0.06689585879174692
Trained batch 310 in epoch 10, gen_loss = 0.39515041701280035, disc_loss = 0.06678638577766692
Trained batch 311 in epoch 10, gen_loss = 0.3952445174830082, disc_loss = 0.06661194360976179
Trained batch 312 in epoch 10, gen_loss = 0.39517190709662514, disc_loss = 0.06642598516423814
Trained batch 313 in epoch 10, gen_loss = 0.39521520902776414, disc_loss = 0.0663331672356458
Trained batch 314 in epoch 10, gen_loss = 0.3950870823292505, disc_loss = 0.06669571241659542
Trained batch 315 in epoch 10, gen_loss = 0.39526511530710173, disc_loss = 0.06697029995737903
Trained batch 316 in epoch 10, gen_loss = 0.3952840450058224, disc_loss = 0.06678640787939215
Trained batch 317 in epoch 10, gen_loss = 0.39517272090387046, disc_loss = 0.06660248412539796
Trained batch 318 in epoch 10, gen_loss = 0.39511521492258506, disc_loss = 0.06653299464823731
Trained batch 319 in epoch 10, gen_loss = 0.39532671235501765, disc_loss = 0.06636610772256972
Trained batch 320 in epoch 10, gen_loss = 0.3954608784843457, disc_loss = 0.06619961242513539
Trained batch 321 in epoch 10, gen_loss = 0.39541898908452217, disc_loss = 0.06612816844742907
Trained batch 322 in epoch 10, gen_loss = 0.39541957566612645, disc_loss = 0.06596696553982495
Trained batch 323 in epoch 10, gen_loss = 0.39532682713535094, disc_loss = 0.06579196568791192
Trained batch 324 in epoch 10, gen_loss = 0.3955443450120779, disc_loss = 0.06567965560950911
Trained batch 325 in epoch 10, gen_loss = 0.39552123131561867, disc_loss = 0.06553194931411167
Trained batch 326 in epoch 10, gen_loss = 0.3959078773263762, disc_loss = 0.0654890405353079
Trained batch 327 in epoch 10, gen_loss = 0.395937240886979, disc_loss = 0.0653079595521842
Trained batch 328 in epoch 10, gen_loss = 0.39590333198341554, disc_loss = 0.06517901751821391
Trained batch 329 in epoch 10, gen_loss = 0.39596406934839307, disc_loss = 0.06507085277416715
Trained batch 330 in epoch 10, gen_loss = 0.3960411457676902, disc_loss = 0.06502702447453519
Trained batch 331 in epoch 10, gen_loss = 0.39606014495513525, disc_loss = 0.06485449205046093
Trained batch 332 in epoch 10, gen_loss = 0.395807273842551, disc_loss = 0.06492750056775974
Trained batch 333 in epoch 10, gen_loss = 0.39618826171238264, disc_loss = 0.06540942634734699
Trained batch 334 in epoch 10, gen_loss = 0.3962580898804451, disc_loss = 0.06526386493038552
Trained batch 335 in epoch 10, gen_loss = 0.3961159864529258, disc_loss = 0.06519509852902654
Trained batch 336 in epoch 10, gen_loss = 0.39602527491062967, disc_loss = 0.06508788528219307
Trained batch 337 in epoch 10, gen_loss = 0.3959113863798288, disc_loss = 0.06492607061442583
Trained batch 338 in epoch 10, gen_loss = 0.3957829031444932, disc_loss = 0.06477037963256856
Trained batch 339 in epoch 10, gen_loss = 0.3957397609949112, disc_loss = 0.06479946345173042
Trained batch 340 in epoch 10, gen_loss = 0.3958088857861908, disc_loss = 0.06534490274276333
Trained batch 341 in epoch 10, gen_loss = 0.3955504622375756, disc_loss = 0.06596494920154194
Trained batch 342 in epoch 10, gen_loss = 0.3955026941466262, disc_loss = 0.06621965310745398
Trained batch 343 in epoch 10, gen_loss = 0.39537443220615387, disc_loss = 0.06633074853303951
Trained batch 344 in epoch 10, gen_loss = 0.3951279949450838, disc_loss = 0.06644882698934795
Trained batch 345 in epoch 10, gen_loss = 0.39513916948627187, disc_loss = 0.0664003137916305
Trained batch 346 in epoch 10, gen_loss = 0.3951568454074585, disc_loss = 0.06638364295102119
Trained batch 347 in epoch 10, gen_loss = 0.395197957240302, disc_loss = 0.06633267512989241
Trained batch 348 in epoch 10, gen_loss = 0.3951932597467756, disc_loss = 0.06628535068687319
Trained batch 349 in epoch 10, gen_loss = 0.3950417256355286, disc_loss = 0.06628065815860672
Trained batch 350 in epoch 10, gen_loss = 0.39511346163233463, disc_loss = 0.06676133643395328
Trained batch 351 in epoch 10, gen_loss = 0.39514850672673096, disc_loss = 0.06662161624858114
Trained batch 352 in epoch 10, gen_loss = 0.39510668961927503, disc_loss = 0.06694051532454726
Trained batch 353 in epoch 10, gen_loss = 0.39513341930963225, disc_loss = 0.06747634643504638
Trained batch 354 in epoch 10, gen_loss = 0.395009729392092, disc_loss = 0.0674460361003351
Trained batch 355 in epoch 10, gen_loss = 0.395003485880541, disc_loss = 0.06770606789858279
Trained batch 356 in epoch 10, gen_loss = 0.3950289459455581, disc_loss = 0.06754537544888901
Trained batch 357 in epoch 10, gen_loss = 0.3949109084446337, disc_loss = 0.06747691385713328
Trained batch 358 in epoch 10, gen_loss = 0.394909246718319, disc_loss = 0.06733971996450781
Trained batch 359 in epoch 10, gen_loss = 0.39483782351017, disc_loss = 0.06722390964083995
Trained batch 360 in epoch 10, gen_loss = 0.39482868848745184, disc_loss = 0.0671176363719199
Trained batch 361 in epoch 10, gen_loss = 0.39477063114471855, disc_loss = 0.06707449079727888
Trained batch 362 in epoch 10, gen_loss = 0.3946192686551202, disc_loss = 0.06724419368215459
Trained batch 363 in epoch 10, gen_loss = 0.3947240115849526, disc_loss = 0.0672087661121143
Trained batch 364 in epoch 10, gen_loss = 0.3945875058435414, disc_loss = 0.06719317084484516
Trained batch 365 in epoch 10, gen_loss = 0.394728965283743, disc_loss = 0.06709071989629234
Trained batch 366 in epoch 10, gen_loss = 0.3947843115888435, disc_loss = 0.06694848613549602
Trained batch 367 in epoch 10, gen_loss = 0.3946674289586751, disc_loss = 0.0668066227239172
Trained batch 368 in epoch 10, gen_loss = 0.39448249679270797, disc_loss = 0.06666930746110433
Trained batch 369 in epoch 10, gen_loss = 0.394478621434521, disc_loss = 0.0665482761476793
Trained batch 370 in epoch 10, gen_loss = 0.3945619451871137, disc_loss = 0.06639883866423184
Trained batch 371 in epoch 10, gen_loss = 0.3944514285652868, disc_loss = 0.06628625640540474
Trained batch 372 in epoch 10, gen_loss = 0.39426179761541436, disc_loss = 0.06623210934622478
Trained batch 373 in epoch 10, gen_loss = 0.3944166803104992, disc_loss = 0.06618454464571799
Trained batch 374 in epoch 10, gen_loss = 0.3947272993723551, disc_loss = 0.06608624007180333
Trained batch 375 in epoch 10, gen_loss = 0.3948332856785744, disc_loss = 0.06594390759338684
Trained batch 376 in epoch 10, gen_loss = 0.39500339728451533, disc_loss = 0.06585733952563977
Trained batch 377 in epoch 10, gen_loss = 0.39518329485383613, disc_loss = 0.06587735642728312
Trained batch 378 in epoch 10, gen_loss = 0.39501304267893367, disc_loss = 0.0658061998812752
Trained batch 379 in epoch 10, gen_loss = 0.394929207626142, disc_loss = 0.06580632115640726
Trained batch 380 in epoch 10, gen_loss = 0.3953721518591633, disc_loss = 0.06645981351822966
Trained batch 381 in epoch 10, gen_loss = 0.3955921086809398, disc_loss = 0.06633415240282436
Trained batch 382 in epoch 10, gen_loss = 0.39550118728032624, disc_loss = 0.06649182744046998
Trained batch 383 in epoch 10, gen_loss = 0.39569789489420754, disc_loss = 0.06688061623693405
Trained batch 384 in epoch 10, gen_loss = 0.3954790619286624, disc_loss = 0.06681932152261014
Trained batch 385 in epoch 10, gen_loss = 0.39535261211926453, disc_loss = 0.06687046040616774
Trained batch 386 in epoch 10, gen_loss = 0.39536594890192805, disc_loss = 0.06681520758841658
Trained batch 387 in epoch 10, gen_loss = 0.3953053920539384, disc_loss = 0.06705474276839726
Trained batch 388 in epoch 10, gen_loss = 0.39511873981027185, disc_loss = 0.06725295707176422
Trained batch 389 in epoch 10, gen_loss = 0.394992601336577, disc_loss = 0.06714031947896075
Trained batch 390 in epoch 10, gen_loss = 0.3951264065702248, disc_loss = 0.06707591429481383
Trained batch 391 in epoch 10, gen_loss = 0.39507279560274006, disc_loss = 0.06706946118311881
Trained batch 392 in epoch 10, gen_loss = 0.3949615530688647, disc_loss = 0.06732758560571014
Trained batch 393 in epoch 10, gen_loss = 0.39507916070483057, disc_loss = 0.06728787312099739
Trained batch 394 in epoch 10, gen_loss = 0.3949272608455223, disc_loss = 0.06719590248540044
Trained batch 395 in epoch 10, gen_loss = 0.39487128877880595, disc_loss = 0.06705061103466597
Trained batch 396 in epoch 10, gen_loss = 0.39505450701533396, disc_loss = 0.06701201768075901
Trained batch 397 in epoch 10, gen_loss = 0.39500748122756807, disc_loss = 0.06688709219978495
Trained batch 398 in epoch 10, gen_loss = 0.3949412086553741, disc_loss = 0.0667821281626914
Trained batch 399 in epoch 10, gen_loss = 0.39493285067379474, disc_loss = 0.06664196710451506
Trained batch 400 in epoch 10, gen_loss = 0.39495337923566004, disc_loss = 0.06651985300054537
Trained batch 401 in epoch 10, gen_loss = 0.39484388503565715, disc_loss = 0.0664991873874797
Trained batch 402 in epoch 10, gen_loss = 0.3949136283646151, disc_loss = 0.0663678913594457
Trained batch 403 in epoch 10, gen_loss = 0.39504421384322763, disc_loss = 0.06656199027807222
Trained batch 404 in epoch 10, gen_loss = 0.3950891814114135, disc_loss = 0.06654775997991731
Trained batch 405 in epoch 10, gen_loss = 0.3951270872442593, disc_loss = 0.0664309200640364
Trained batch 406 in epoch 10, gen_loss = 0.39524885894918327, disc_loss = 0.06630934790321408
Trained batch 407 in epoch 10, gen_loss = 0.39535819899802116, disc_loss = 0.06616284147215386
Trained batch 408 in epoch 10, gen_loss = 0.3954278307905407, disc_loss = 0.06601626006089388
Trained batch 409 in epoch 10, gen_loss = 0.39531889914012536, disc_loss = 0.06590535351779403
Trained batch 410 in epoch 10, gen_loss = 0.3954250131645342, disc_loss = 0.06579413774837978
Trained batch 411 in epoch 10, gen_loss = 0.3953973489623625, disc_loss = 0.06564998969399524
Trained batch 412 in epoch 10, gen_loss = 0.3954373366463271, disc_loss = 0.06554181915290708
Trained batch 413 in epoch 10, gen_loss = 0.39553581286167755, disc_loss = 0.06545540519004715
Trained batch 414 in epoch 10, gen_loss = 0.39557036771831744, disc_loss = 0.06534255591770971
Trained batch 415 in epoch 10, gen_loss = 0.3953113186244781, disc_loss = 0.06523778760590805
Trained batch 416 in epoch 10, gen_loss = 0.3952015599758505, disc_loss = 0.06528336940695056
Trained batch 417 in epoch 10, gen_loss = 0.3953029497673637, disc_loss = 0.06538526280716275
Trained batch 418 in epoch 10, gen_loss = 0.3954051524614093, disc_loss = 0.06525658390224691
Trained batch 419 in epoch 10, gen_loss = 0.3955613094426337, disc_loss = 0.06512366632842237
Trained batch 420 in epoch 10, gen_loss = 0.3954303359475668, disc_loss = 0.0650089037341382
Trained batch 421 in epoch 10, gen_loss = 0.39542426571461825, disc_loss = 0.06490865815651573
Trained batch 422 in epoch 10, gen_loss = 0.39547441367843755, disc_loss = 0.06476511278830416
Trained batch 423 in epoch 10, gen_loss = 0.39541030696259355, disc_loss = 0.06478374176504934
Trained batch 424 in epoch 10, gen_loss = 0.39538542537128224, disc_loss = 0.06470501224893857
Trained batch 425 in epoch 10, gen_loss = 0.3953703286502283, disc_loss = 0.06457266139037067
Trained batch 426 in epoch 10, gen_loss = 0.39531951095795465, disc_loss = 0.06443942407586675
Trained batch 427 in epoch 10, gen_loss = 0.3952653371842108, disc_loss = 0.06436570246799667
Trained batch 428 in epoch 10, gen_loss = 0.39520306291280094, disc_loss = 0.06425709942125635
Trained batch 429 in epoch 10, gen_loss = 0.39505884682023246, disc_loss = 0.06417726678557174
Trained batch 430 in epoch 10, gen_loss = 0.39516023873176487, disc_loss = 0.06410772175357403
Trained batch 431 in epoch 10, gen_loss = 0.3952624389418849, disc_loss = 0.06404446058527187
Trained batch 432 in epoch 10, gen_loss = 0.3952059818057485, disc_loss = 0.06401812529522607
Trained batch 433 in epoch 10, gen_loss = 0.3950038491168879, disc_loss = 0.06390546454108119
Trained batch 434 in epoch 10, gen_loss = 0.3951807067997154, disc_loss = 0.06379916977522702
Trained batch 435 in epoch 10, gen_loss = 0.39529097380988093, disc_loss = 0.06366317267337421
Trained batch 436 in epoch 10, gen_loss = 0.3951738887984365, disc_loss = 0.0635443388024085
Trained batch 437 in epoch 10, gen_loss = 0.39531531154292904, disc_loss = 0.0634256154926043
Trained batch 438 in epoch 10, gen_loss = 0.39527818920400526, disc_loss = 0.063530910848205
Trained batch 439 in epoch 10, gen_loss = 0.39512434669516305, disc_loss = 0.06427763224134898
Trained batch 440 in epoch 10, gen_loss = 0.39516253961997777, disc_loss = 0.06427807824964933
Trained batch 441 in epoch 10, gen_loss = 0.3951234760866985, disc_loss = 0.06427133864959138
Trained batch 442 in epoch 10, gen_loss = 0.3951732330612889, disc_loss = 0.06429815000873354
Trained batch 443 in epoch 10, gen_loss = 0.3952548315261935, disc_loss = 0.06431271175556053
Trained batch 444 in epoch 10, gen_loss = 0.3951008707619785, disc_loss = 0.06425410545420614
Trained batch 445 in epoch 10, gen_loss = 0.39514614655030683, disc_loss = 0.0642770700472002
Trained batch 446 in epoch 10, gen_loss = 0.3952084705733613, disc_loss = 0.06425339251369137
Trained batch 447 in epoch 10, gen_loss = 0.39517221060980645, disc_loss = 0.06412549704483743
Trained batch 448 in epoch 10, gen_loss = 0.3951826515734063, disc_loss = 0.06400280975672377
Trained batch 449 in epoch 10, gen_loss = 0.39511475788222417, disc_loss = 0.06389462393501566
Trained batch 450 in epoch 10, gen_loss = 0.39493740840656, disc_loss = 0.06398010554882448
Trained batch 451 in epoch 10, gen_loss = 0.3949729005715488, disc_loss = 0.06454486238658923
Trained batch 452 in epoch 10, gen_loss = 0.39498301169467026, disc_loss = 0.06455748181514623
Trained batch 453 in epoch 10, gen_loss = 0.39483713138733667, disc_loss = 0.06461585301901768
Trained batch 454 in epoch 10, gen_loss = 0.3948294601597629, disc_loss = 0.06474924888564171
Trained batch 455 in epoch 10, gen_loss = 0.39481017366051674, disc_loss = 0.06469524342448271
Trained batch 456 in epoch 10, gen_loss = 0.39481591858801224, disc_loss = 0.06459040048733941
Trained batch 457 in epoch 10, gen_loss = 0.3946810449965656, disc_loss = 0.06446216562579846
Trained batch 458 in epoch 10, gen_loss = 0.3946881302691233, disc_loss = 0.06439158152930909
Trained batch 459 in epoch 10, gen_loss = 0.3947904575130214, disc_loss = 0.0643535713756295
Trained batch 460 in epoch 10, gen_loss = 0.3948581291124257, disc_loss = 0.06430102701030203
Trained batch 461 in epoch 10, gen_loss = 0.39497406877480545, disc_loss = 0.0642147432998613
Trained batch 462 in epoch 10, gen_loss = 0.3953715800981542, disc_loss = 0.06452469023741123
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.3296754062175751, disc_loss = 0.0680086761713028
Trained batch 1 in epoch 11, gen_loss = 0.3450865149497986, disc_loss = 0.046611081808805466
Trained batch 2 in epoch 11, gen_loss = 0.38369014859199524, disc_loss = 0.05139413351813952
Trained batch 3 in epoch 11, gen_loss = 0.4029930308461189, disc_loss = 0.04275774536654353
Trained batch 4 in epoch 11, gen_loss = 0.4096358954906464, disc_loss = 0.035755620896816255
Trained batch 5 in epoch 11, gen_loss = 0.4046928485234578, disc_loss = 0.05235357706745466
Trained batch 6 in epoch 11, gen_loss = 0.41527722563062397, disc_loss = 0.11382411739655904
Trained batch 7 in epoch 11, gen_loss = 0.4083726927638054, disc_loss = 0.10612238058820367
Trained batch 8 in epoch 11, gen_loss = 0.39959460828039384, disc_loss = 0.10300897186001141
Trained batch 9 in epoch 11, gen_loss = 0.3961530864238739, disc_loss = 0.09532890766859055
Trained batch 10 in epoch 11, gen_loss = 0.39959821646863763, disc_loss = 0.08880017714744265
Trained batch 11 in epoch 11, gen_loss = 0.4012606094280879, disc_loss = 0.0860527022741735
Trained batch 12 in epoch 11, gen_loss = 0.3996248749586252, disc_loss = 0.08044868542884405
Trained batch 13 in epoch 11, gen_loss = 0.4027552604675293, disc_loss = 0.07589719371337976
Trained batch 14 in epoch 11, gen_loss = 0.4029933472474416, disc_loss = 0.07275807540863752
Trained batch 15 in epoch 11, gen_loss = 0.39947768300771713, disc_loss = 0.07053753460058942
Trained batch 16 in epoch 11, gen_loss = 0.40159791883300333, disc_loss = 0.06785012217348113
Trained batch 17 in epoch 11, gen_loss = 0.3991972870296902, disc_loss = 0.0646937847033971
Trained batch 18 in epoch 11, gen_loss = 0.3954492619163112, disc_loss = 0.0619383432265175
Trained batch 19 in epoch 11, gen_loss = 0.3980893909931183, disc_loss = 0.062471744557842615
Trained batch 20 in epoch 11, gen_loss = 0.3978234018598284, disc_loss = 0.06580000987187737
Trained batch 21 in epoch 11, gen_loss = 0.4019096547907049, disc_loss = 0.06599917241626164
Trained batch 22 in epoch 11, gen_loss = 0.4008150515349015, disc_loss = 0.06352231955236715
Trained batch 23 in epoch 11, gen_loss = 0.4038926189144452, disc_loss = 0.061745501162173845
Trained batch 24 in epoch 11, gen_loss = 0.40209705352783204, disc_loss = 0.060530416257679465
Trained batch 25 in epoch 11, gen_loss = 0.40295153856277466, disc_loss = 0.05841336707369639
Trained batch 26 in epoch 11, gen_loss = 0.40358062585194904, disc_loss = 0.05653261248436239
Trained batch 27 in epoch 11, gen_loss = 0.40512214601039886, disc_loss = 0.055052568071654866
Trained batch 28 in epoch 11, gen_loss = 0.4058095309241065, disc_loss = 0.05351896317483022
Trained batch 29 in epoch 11, gen_loss = 0.4082217792669932, disc_loss = 0.05220503692204754
Trained batch 30 in epoch 11, gen_loss = 0.4083988118556238, disc_loss = 0.05333898177430514
Trained batch 31 in epoch 11, gen_loss = 0.4095913553610444, disc_loss = 0.05525596495135687
Trained batch 32 in epoch 11, gen_loss = 0.40800581646688056, disc_loss = 0.055293194808517444
Trained batch 33 in epoch 11, gen_loss = 0.41009672687334175, disc_loss = 0.054824499824248696
Trained batch 34 in epoch 11, gen_loss = 0.4113772639206478, disc_loss = 0.053735735879412716
Trained batch 35 in epoch 11, gen_loss = 0.4096560287806723, disc_loss = 0.05544972261931333
Trained batch 36 in epoch 11, gen_loss = 0.40890902522447947, disc_loss = 0.05756963192913178
Trained batch 37 in epoch 11, gen_loss = 0.40882250980327006, disc_loss = 0.056733181577567994
Trained batch 38 in epoch 11, gen_loss = 0.4088727151736235, disc_loss = 0.05666434170248417
Trained batch 39 in epoch 11, gen_loss = 0.4088333174586296, disc_loss = 0.05712893044110388
Trained batch 40 in epoch 11, gen_loss = 0.40860849836977514, disc_loss = 0.05917673428520197
Trained batch 41 in epoch 11, gen_loss = 0.406096474755378, disc_loss = 0.05918446127768783
Trained batch 42 in epoch 11, gen_loss = 0.4068920556889024, disc_loss = 0.05884532740902762
Trained batch 43 in epoch 11, gen_loss = 0.40504545853896573, disc_loss = 0.06027463863773102
Trained batch 44 in epoch 11, gen_loss = 0.4063603315088484, disc_loss = 0.06000340297404263
Trained batch 45 in epoch 11, gen_loss = 0.4062750650488812, disc_loss = 0.05907847989431542
Trained batch 46 in epoch 11, gen_loss = 0.40629062056541443, disc_loss = 0.05815576260632023
Trained batch 47 in epoch 11, gen_loss = 0.4062676305572192, disc_loss = 0.057486108834079154
Trained batch 48 in epoch 11, gen_loss = 0.40744716476420967, disc_loss = 0.057133721928967506
Trained batch 49 in epoch 11, gen_loss = 0.406168914437294, disc_loss = 0.0567132362164557
Trained batch 50 in epoch 11, gen_loss = 0.4067238206956901, disc_loss = 0.05579159874469042
Trained batch 51 in epoch 11, gen_loss = 0.40675521470033205, disc_loss = 0.055313468749563284
Trained batch 52 in epoch 11, gen_loss = 0.406880037402207, disc_loss = 0.05498623361213589
Trained batch 53 in epoch 11, gen_loss = 0.40587287534166266, disc_loss = 0.054648305444667734
Trained batch 54 in epoch 11, gen_loss = 0.4066704040223902, disc_loss = 0.05409674060276964
Trained batch 55 in epoch 11, gen_loss = 0.40737936698964666, disc_loss = 0.05329514387995005
Trained batch 56 in epoch 11, gen_loss = 0.4075168041806472, disc_loss = 0.0532650126046256
Trained batch 57 in epoch 11, gen_loss = 0.40589303240693847, disc_loss = 0.057709732895781254
Trained batch 58 in epoch 11, gen_loss = 0.40659816941972504, disc_loss = 0.05893675370489137
Trained batch 59 in epoch 11, gen_loss = 0.40730942934751513, disc_loss = 0.05860306664059559
Trained batch 60 in epoch 11, gen_loss = 0.40641069167950117, disc_loss = 0.059790875762701035
Trained batch 61 in epoch 11, gen_loss = 0.4060279991357557, disc_loss = 0.05909565292418965
Trained batch 62 in epoch 11, gen_loss = 0.4066309990390899, disc_loss = 0.059159604182082506
Trained batch 63 in epoch 11, gen_loss = 0.4054451286792755, disc_loss = 0.06009658458060585
Trained batch 64 in epoch 11, gen_loss = 0.4056779838525332, disc_loss = 0.05953073131923492
Trained batch 65 in epoch 11, gen_loss = 0.40502508571653656, disc_loss = 0.059108542137299526
Trained batch 66 in epoch 11, gen_loss = 0.40338870215771805, disc_loss = 0.059143594869259575
Trained batch 67 in epoch 11, gen_loss = 0.40335195906022014, disc_loss = 0.05897353269050226
Trained batch 68 in epoch 11, gen_loss = 0.4034811828447425, disc_loss = 0.058210907767162375
Trained batch 69 in epoch 11, gen_loss = 0.403018262556621, disc_loss = 0.057919207022392324
Trained batch 70 in epoch 11, gen_loss = 0.4010438381786078, disc_loss = 0.057841502149707416
Trained batch 71 in epoch 11, gen_loss = 0.4021047080556552, disc_loss = 0.05850026437676408
Trained batch 72 in epoch 11, gen_loss = 0.4016886051387003, disc_loss = 0.05908718258014893
Trained batch 73 in epoch 11, gen_loss = 0.40187863320917694, disc_loss = 0.05838235845864826
Trained batch 74 in epoch 11, gen_loss = 0.4023040262858073, disc_loss = 0.057862204170475405
Trained batch 75 in epoch 11, gen_loss = 0.40260085071388046, disc_loss = 0.057910378048147415
Trained batch 76 in epoch 11, gen_loss = 0.40316619114442304, disc_loss = 0.05920868609463433
Trained batch 77 in epoch 11, gen_loss = 0.40187106682704044, disc_loss = 0.06019723969989289
Trained batch 78 in epoch 11, gen_loss = 0.40231644880922535, disc_loss = 0.06158435533907783
Trained batch 79 in epoch 11, gen_loss = 0.4023933012038469, disc_loss = 0.061205275316024196
Trained batch 80 in epoch 11, gen_loss = 0.4011694479871679, disc_loss = 0.06161882282798121
Trained batch 81 in epoch 11, gen_loss = 0.4006859765547078, disc_loss = 0.06096447566410572
Trained batch 82 in epoch 11, gen_loss = 0.4006580459066184, disc_loss = 0.06044982650306031
Trained batch 83 in epoch 11, gen_loss = 0.4005014569986434, disc_loss = 0.060102962739100416
Trained batch 84 in epoch 11, gen_loss = 0.4002316629185396, disc_loss = 0.059625223569352834
Trained batch 85 in epoch 11, gen_loss = 0.39961406519246656, disc_loss = 0.05953059114277536
Trained batch 86 in epoch 11, gen_loss = 0.3992950039348383, disc_loss = 0.0612942678586248
Trained batch 87 in epoch 11, gen_loss = 0.3985459940000014, disc_loss = 0.06452279836891896
Trained batch 88 in epoch 11, gen_loss = 0.39866747849442985, disc_loss = 0.06556314157238335
Trained batch 89 in epoch 11, gen_loss = 0.39850548174646166, disc_loss = 0.06638613966707554
Trained batch 90 in epoch 11, gen_loss = 0.3984358415498838, disc_loss = 0.06806187440671928
Trained batch 91 in epoch 11, gen_loss = 0.3994034515774768, disc_loss = 0.06847839780738982
Trained batch 92 in epoch 11, gen_loss = 0.39812497329968277, disc_loss = 0.07024959717646882
Trained batch 93 in epoch 11, gen_loss = 0.3982991658626719, disc_loss = 0.07117587893190695
Trained batch 94 in epoch 11, gen_loss = 0.39839446074084234, disc_loss = 0.07071935438894128
Trained batch 95 in epoch 11, gen_loss = 0.3976656636223197, disc_loss = 0.07078989756701048
Trained batch 96 in epoch 11, gen_loss = 0.39781064501742724, disc_loss = 0.07021375511744127
Trained batch 97 in epoch 11, gen_loss = 0.3973664699160323, disc_loss = 0.07015569390710064
Trained batch 98 in epoch 11, gen_loss = 0.39801013499799404, disc_loss = 0.07018524201850247
Trained batch 99 in epoch 11, gen_loss = 0.3972180312871933, disc_loss = 0.07093840811867266
Trained batch 100 in epoch 11, gen_loss = 0.3976756307748285, disc_loss = 0.07124972517260968
Trained batch 101 in epoch 11, gen_loss = 0.3977103192432254, disc_loss = 0.07068825958241873
Trained batch 102 in epoch 11, gen_loss = 0.39798117783463116, disc_loss = 0.07019613474806391
Trained batch 103 in epoch 11, gen_loss = 0.3985139446762892, disc_loss = 0.06979985577681173
Trained batch 104 in epoch 11, gen_loss = 0.3987938764549437, disc_loss = 0.06974067900418526
Trained batch 105 in epoch 11, gen_loss = 0.3984308602674952, disc_loss = 0.0699720224497383
Trained batch 106 in epoch 11, gen_loss = 0.39840995764063897, disc_loss = 0.06972013866076264
Trained batch 107 in epoch 11, gen_loss = 0.3984086113395514, disc_loss = 0.06997207586256857
Trained batch 108 in epoch 11, gen_loss = 0.39720467389176745, disc_loss = 0.07144647091199909
Trained batch 109 in epoch 11, gen_loss = 0.3972586450251666, disc_loss = 0.07104923209937458
Trained batch 110 in epoch 11, gen_loss = 0.3975752809563199, disc_loss = 0.07054006906964623
Trained batch 111 in epoch 11, gen_loss = 0.39731498940714766, disc_loss = 0.07008041502558626
Trained batch 112 in epoch 11, gen_loss = 0.39714294408274964, disc_loss = 0.07027310747405992
Trained batch 113 in epoch 11, gen_loss = 0.39652407796759354, disc_loss = 0.06976994719732095
Trained batch 114 in epoch 11, gen_loss = 0.3965347626934881, disc_loss = 0.0701242543230562
Trained batch 115 in epoch 11, gen_loss = 0.39560851608884745, disc_loss = 0.07054208403308715
Trained batch 116 in epoch 11, gen_loss = 0.39602498238922185, disc_loss = 0.07082046152482557
Trained batch 117 in epoch 11, gen_loss = 0.3950731009244919, disc_loss = 0.07107419032461436
Trained batch 118 in epoch 11, gen_loss = 0.39530582137468484, disc_loss = 0.07106235270787563
Trained batch 119 in epoch 11, gen_loss = 0.3953563171128432, disc_loss = 0.07101124156809722
Trained batch 120 in epoch 11, gen_loss = 0.3959874227519863, disc_loss = 0.07056980482725934
Trained batch 121 in epoch 11, gen_loss = 0.39647708564508155, disc_loss = 0.07008392340503633
Trained batch 122 in epoch 11, gen_loss = 0.3966777908608196, disc_loss = 0.06961235811752153
Trained batch 123 in epoch 11, gen_loss = 0.3966524545704165, disc_loss = 0.06924620464879779
Trained batch 124 in epoch 11, gen_loss = 0.3963677897453308, disc_loss = 0.06878415920212864
Trained batch 125 in epoch 11, gen_loss = 0.39576353109072127, disc_loss = 0.06889197717065967
Trained batch 126 in epoch 11, gen_loss = 0.3956035830843167, disc_loss = 0.07088729353826934
Trained batch 127 in epoch 11, gen_loss = 0.39581228140741587, disc_loss = 0.07156321419824963
Trained batch 128 in epoch 11, gen_loss = 0.39572604751402096, disc_loss = 0.07140653645764142
Trained batch 129 in epoch 11, gen_loss = 0.39529030643976654, disc_loss = 0.07148003528396098
Trained batch 130 in epoch 11, gen_loss = 0.39444767587057505, disc_loss = 0.0712126394101056
Trained batch 131 in epoch 11, gen_loss = 0.3942819499608242, disc_loss = 0.07108319227964702
Trained batch 132 in epoch 11, gen_loss = 0.39357199368620277, disc_loss = 0.07201367934913676
Trained batch 133 in epoch 11, gen_loss = 0.39407460880813316, disc_loss = 0.07437261142906969
Trained batch 134 in epoch 11, gen_loss = 0.39448655468446236, disc_loss = 0.07396485175316532
Trained batch 135 in epoch 11, gen_loss = 0.39427150720182585, disc_loss = 0.07431541727376445
Trained batch 136 in epoch 11, gen_loss = 0.3944142269392083, disc_loss = 0.0742742978750191
Trained batch 137 in epoch 11, gen_loss = 0.39444093686946924, disc_loss = 0.07392097606350655
Trained batch 138 in epoch 11, gen_loss = 0.3940968676436719, disc_loss = 0.0735324511485402
Trained batch 139 in epoch 11, gen_loss = 0.3935944797737258, disc_loss = 0.07311064814150865
Trained batch 140 in epoch 11, gen_loss = 0.3935635732420793, disc_loss = 0.07275888374313078
Trained batch 141 in epoch 11, gen_loss = 0.3934469378330338, disc_loss = 0.07282562032145198
Trained batch 142 in epoch 11, gen_loss = 0.39306178293028077, disc_loss = 0.07308842625039128
Trained batch 143 in epoch 11, gen_loss = 0.3933543215195338, disc_loss = 0.07266950253203201
Trained batch 144 in epoch 11, gen_loss = 0.3935965716838837, disc_loss = 0.07239665767049482
Trained batch 145 in epoch 11, gen_loss = 0.39348960616817213, disc_loss = 0.07198462994730942
Trained batch 146 in epoch 11, gen_loss = 0.39333116278356434, disc_loss = 0.07165070505001817
Trained batch 147 in epoch 11, gen_loss = 0.39427104753416936, disc_loss = 0.07125286166744961
Trained batch 148 in epoch 11, gen_loss = 0.39453767950102786, disc_loss = 0.07090954772890515
Trained batch 149 in epoch 11, gen_loss = 0.3946026887496312, disc_loss = 0.07060773828687768
Trained batch 150 in epoch 11, gen_loss = 0.3943873154406516, disc_loss = 0.0707671867208617
Trained batch 151 in epoch 11, gen_loss = 0.393749344113626, disc_loss = 0.07134466382098924
Trained batch 152 in epoch 11, gen_loss = 0.3941059926756067, disc_loss = 0.07162166385929666
Trained batch 153 in epoch 11, gen_loss = 0.39400223632911585, disc_loss = 0.07125016969822154
Trained batch 154 in epoch 11, gen_loss = 0.3935582282081727, disc_loss = 0.07101735679673091
Trained batch 155 in epoch 11, gen_loss = 0.39350529397145295, disc_loss = 0.0706815558205096
Trained batch 156 in epoch 11, gen_loss = 0.3935620558869307, disc_loss = 0.0702935701123421
Trained batch 157 in epoch 11, gen_loss = 0.39305935347382026, disc_loss = 0.06992623971221096
Trained batch 158 in epoch 11, gen_loss = 0.3933342110435918, disc_loss = 0.06967716926193368
Trained batch 159 in epoch 11, gen_loss = 0.39335149955004456, disc_loss = 0.06930996909795795
Trained batch 160 in epoch 11, gen_loss = 0.39286025858813933, disc_loss = 0.069110603589472
Trained batch 161 in epoch 11, gen_loss = 0.3928157271426401, disc_loss = 0.06893333729735955
Trained batch 162 in epoch 11, gen_loss = 0.392863209262216, disc_loss = 0.06858746863135988
Trained batch 163 in epoch 11, gen_loss = 0.3927296928879691, disc_loss = 0.06875197744144626
Trained batch 164 in epoch 11, gen_loss = 0.3931725095618855, disc_loss = 0.07101811197953242
Trained batch 165 in epoch 11, gen_loss = 0.39348701037556294, disc_loss = 0.07084111925719463
Trained batch 166 in epoch 11, gen_loss = 0.39277400977597265, disc_loss = 0.07147498939933623
Trained batch 167 in epoch 11, gen_loss = 0.3925871176733857, disc_loss = 0.0712416545693053
Trained batch 168 in epoch 11, gen_loss = 0.3925772311066735, disc_loss = 0.07119429140412331
Trained batch 169 in epoch 11, gen_loss = 0.39247185693067665, disc_loss = 0.07120516495505239
Trained batch 170 in epoch 11, gen_loss = 0.39236617541452595, disc_loss = 0.07088743981616626
Trained batch 171 in epoch 11, gen_loss = 0.3924169174807016, disc_loss = 0.07058762722421265
Trained batch 172 in epoch 11, gen_loss = 0.39228267769593034, disc_loss = 0.07031589145960578
Trained batch 173 in epoch 11, gen_loss = 0.3921243865257022, disc_loss = 0.07009591267379964
Trained batch 174 in epoch 11, gen_loss = 0.392124388217926, disc_loss = 0.0698486299094345
Trained batch 175 in epoch 11, gen_loss = 0.39221090264618397, disc_loss = 0.06961548457779414
Trained batch 176 in epoch 11, gen_loss = 0.39165619520817774, disc_loss = 0.0697497833483342
Trained batch 177 in epoch 11, gen_loss = 0.3920648752638463, disc_loss = 0.07049801696897641
Trained batch 178 in epoch 11, gen_loss = 0.39199888073532274, disc_loss = 0.07017723032060033
Trained batch 179 in epoch 11, gen_loss = 0.39180668824248843, disc_loss = 0.07034878141194996
Trained batch 180 in epoch 11, gen_loss = 0.39205847919316583, disc_loss = 0.07017636731606573
Trained batch 181 in epoch 11, gen_loss = 0.3921424800550545, disc_loss = 0.06982965652759258
Trained batch 182 in epoch 11, gen_loss = 0.39185218716579706, disc_loss = 0.06957601512593975
Trained batch 183 in epoch 11, gen_loss = 0.3918266840603041, disc_loss = 0.06934145087902636
Trained batch 184 in epoch 11, gen_loss = 0.39185741269910657, disc_loss = 0.06941748868573357
Trained batch 185 in epoch 11, gen_loss = 0.39146606704240205, disc_loss = 0.0692988369033061
Trained batch 186 in epoch 11, gen_loss = 0.39128156731472935, disc_loss = 0.06900960755818349
Trained batch 187 in epoch 11, gen_loss = 0.3913969632158888, disc_loss = 0.06876593957001224
Trained batch 188 in epoch 11, gen_loss = 0.3914054081868873, disc_loss = 0.06893611539687429
Trained batch 189 in epoch 11, gen_loss = 0.39130754031633075, disc_loss = 0.06898806057870388
Trained batch 190 in epoch 11, gen_loss = 0.3914906911512944, disc_loss = 0.06867895777098328
Trained batch 191 in epoch 11, gen_loss = 0.3911580063092212, disc_loss = 0.06847657393761135
Trained batch 192 in epoch 11, gen_loss = 0.39159402729933745, disc_loss = 0.06816861645313742
Trained batch 193 in epoch 11, gen_loss = 0.3917967452830875, disc_loss = 0.06792119923095728
Trained batch 194 in epoch 11, gen_loss = 0.39165814228546925, disc_loss = 0.06770227067172527
Trained batch 195 in epoch 11, gen_loss = 0.39136792065537707, disc_loss = 0.06741784637964958
Trained batch 196 in epoch 11, gen_loss = 0.3908747542025474, disc_loss = 0.06727679411828669
Trained batch 197 in epoch 11, gen_loss = 0.39096239781138875, disc_loss = 0.06759499530354986
Trained batch 198 in epoch 11, gen_loss = 0.3905567141933058, disc_loss = 0.06811253177516874
Trained batch 199 in epoch 11, gen_loss = 0.39077659711241725, disc_loss = 0.06902502057608217
Trained batch 200 in epoch 11, gen_loss = 0.3907404837027118, disc_loss = 0.06884600811021689
Trained batch 201 in epoch 11, gen_loss = 0.3903741621144927, disc_loss = 0.06893196410158335
Trained batch 202 in epoch 11, gen_loss = 0.39010247235814927, disc_loss = 0.06886773954232779
Trained batch 203 in epoch 11, gen_loss = 0.3906295831296958, disc_loss = 0.06861058051478774
Trained batch 204 in epoch 11, gen_loss = 0.3909237988111449, disc_loss = 0.06833522322065219
Trained batch 205 in epoch 11, gen_loss = 0.39105896319000466, disc_loss = 0.06805277184935883
Trained batch 206 in epoch 11, gen_loss = 0.39083559184834576, disc_loss = 0.06783431555607901
Trained batch 207 in epoch 11, gen_loss = 0.3907881791775043, disc_loss = 0.06764556947074687
Trained batch 208 in epoch 11, gen_loss = 0.3910019761352448, disc_loss = 0.06791105602186119
Trained batch 209 in epoch 11, gen_loss = 0.39079809458482834, disc_loss = 0.06930384401320702
Trained batch 210 in epoch 11, gen_loss = 0.39099905671666585, disc_loss = 0.06957090585558759
Trained batch 211 in epoch 11, gen_loss = 0.39073372857188277, disc_loss = 0.06949935079868531
Trained batch 212 in epoch 11, gen_loss = 0.3903670238217278, disc_loss = 0.06956786560463094
Trained batch 213 in epoch 11, gen_loss = 0.39011703445532614, disc_loss = 0.06946970488893513
Trained batch 214 in epoch 11, gen_loss = 0.39029254469760627, disc_loss = 0.06926741689703492
Trained batch 215 in epoch 11, gen_loss = 0.3899005158907837, disc_loss = 0.06927429415130366
Trained batch 216 in epoch 11, gen_loss = 0.39006627759625834, disc_loss = 0.0690164924964034
Trained batch 217 in epoch 11, gen_loss = 0.3900191138643737, disc_loss = 0.06901815989473407
Trained batch 218 in epoch 11, gen_loss = 0.3897285390662276, disc_loss = 0.06906939945587692
Trained batch 219 in epoch 11, gen_loss = 0.3897817029194398, disc_loss = 0.06882410364394838
Trained batch 220 in epoch 11, gen_loss = 0.3898497570424058, disc_loss = 0.06888866775176104
Trained batch 221 in epoch 11, gen_loss = 0.38983012937210704, disc_loss = 0.0686319692706404
Trained batch 222 in epoch 11, gen_loss = 0.3893080131889993, disc_loss = 0.06880977279986902
Trained batch 223 in epoch 11, gen_loss = 0.389685883851988, disc_loss = 0.06874778934538231
Trained batch 224 in epoch 11, gen_loss = 0.38992783943812054, disc_loss = 0.0685630184536179
Trained batch 225 in epoch 11, gen_loss = 0.38987208309426774, disc_loss = 0.06898963162510664
Trained batch 226 in epoch 11, gen_loss = 0.3902377718608285, disc_loss = 0.06887882376409706
Trained batch 227 in epoch 11, gen_loss = 0.3903581127524376, disc_loss = 0.0686357174918317
Trained batch 228 in epoch 11, gen_loss = 0.39026073480277085, disc_loss = 0.06841422513322538
Trained batch 229 in epoch 11, gen_loss = 0.39004673374735793, disc_loss = 0.0686342347899209
Trained batch 230 in epoch 11, gen_loss = 0.39027955212118304, disc_loss = 0.06886457774417225
Trained batch 231 in epoch 11, gen_loss = 0.3904874778256334, disc_loss = 0.06860895857921448
Trained batch 232 in epoch 11, gen_loss = 0.39023164349564154, disc_loss = 0.0685808292945823
Trained batch 233 in epoch 11, gen_loss = 0.3901813664497473, disc_loss = 0.06831953564109519
Trained batch 234 in epoch 11, gen_loss = 0.3903879171990334, disc_loss = 0.06811780096725263
Trained batch 235 in epoch 11, gen_loss = 0.39061687116400673, disc_loss = 0.0678560652797726
Trained batch 236 in epoch 11, gen_loss = 0.3903771420068379, disc_loss = 0.06771694819879116
Trained batch 237 in epoch 11, gen_loss = 0.3905962760708913, disc_loss = 0.06770717839225188
Trained batch 238 in epoch 11, gen_loss = 0.3905241899659943, disc_loss = 0.06843289537900848
Trained batch 239 in epoch 11, gen_loss = 0.39065701750417553, disc_loss = 0.06893033122760243
Trained batch 240 in epoch 11, gen_loss = 0.39069056919006884, disc_loss = 0.0687995525791901
Trained batch 241 in epoch 11, gen_loss = 0.3907710854425903, disc_loss = 0.06860854361814346
Trained batch 242 in epoch 11, gen_loss = 0.3907249737914207, disc_loss = 0.06839967590139666
Trained batch 243 in epoch 11, gen_loss = 0.3908195691030534, disc_loss = 0.06819893315732174
Trained batch 244 in epoch 11, gen_loss = 0.39083449840545653, disc_loss = 0.0679542691750946
Trained batch 245 in epoch 11, gen_loss = 0.3909382926739328, disc_loss = 0.06782379742083329
Trained batch 246 in epoch 11, gen_loss = 0.3910605603384103, disc_loss = 0.06764403622227944
Trained batch 247 in epoch 11, gen_loss = 0.39110891905523115, disc_loss = 0.06792814155567377
Trained batch 248 in epoch 11, gen_loss = 0.39094141053866194, disc_loss = 0.06838530939573564
Trained batch 249 in epoch 11, gen_loss = 0.3905083240270615, disc_loss = 0.06868240687437356
Trained batch 250 in epoch 11, gen_loss = 0.39064389312884723, disc_loss = 0.06871296925678018
Trained batch 251 in epoch 11, gen_loss = 0.3906694289947313, disc_loss = 0.06854675875954508
Trained batch 252 in epoch 11, gen_loss = 0.3904530237550321, disc_loss = 0.06835016944140138
Trained batch 253 in epoch 11, gen_loss = 0.3902115624720656, disc_loss = 0.06821217674094684
Trained batch 254 in epoch 11, gen_loss = 0.3903746761527716, disc_loss = 0.0681891706808671
Trained batch 255 in epoch 11, gen_loss = 0.3903983634663746, disc_loss = 0.06800954762911715
Trained batch 256 in epoch 11, gen_loss = 0.3902073753019251, disc_loss = 0.06808395228794403
Trained batch 257 in epoch 11, gen_loss = 0.3904005194357199, disc_loss = 0.06818055020926823
Trained batch 258 in epoch 11, gen_loss = 0.3904077500450105, disc_loss = 0.06797425456265972
Trained batch 259 in epoch 11, gen_loss = 0.39051403472056756, disc_loss = 0.06776799805856382
Trained batch 260 in epoch 11, gen_loss = 0.3902076657476096, disc_loss = 0.06775897624099562
Trained batch 261 in epoch 11, gen_loss = 0.39043541753110084, disc_loss = 0.06762788979201542
Trained batch 262 in epoch 11, gen_loss = 0.3901848881416901, disc_loss = 0.06745708370297977
Trained batch 263 in epoch 11, gen_loss = 0.39045425301248377, disc_loss = 0.06723661407313282
Trained batch 264 in epoch 11, gen_loss = 0.39036975626675585, disc_loss = 0.0670184427995305
Trained batch 265 in epoch 11, gen_loss = 0.3902753923172341, disc_loss = 0.06696425595572848
Trained batch 266 in epoch 11, gen_loss = 0.3902709744173043, disc_loss = 0.06713892350824417
Trained batch 267 in epoch 11, gen_loss = 0.3900089694270447, disc_loss = 0.06742470376645285
Trained batch 268 in epoch 11, gen_loss = 0.3900538322872389, disc_loss = 0.0674362399920018
Trained batch 269 in epoch 11, gen_loss = 0.3903360418699406, disc_loss = 0.0672773194068146
Trained batch 270 in epoch 11, gen_loss = 0.3902999357323805, disc_loss = 0.06705709912975721
Trained batch 271 in epoch 11, gen_loss = 0.3901983318740831, disc_loss = 0.06685387879192337
Trained batch 272 in epoch 11, gen_loss = 0.3903882121428465, disc_loss = 0.06662892644556287
Trained batch 273 in epoch 11, gen_loss = 0.3905331081282483, disc_loss = 0.06643733115234568
Trained batch 274 in epoch 11, gen_loss = 0.39033642010255293, disc_loss = 0.0662506076575003
Trained batch 275 in epoch 11, gen_loss = 0.39022448356600775, disc_loss = 0.06603638234588763
Trained batch 276 in epoch 11, gen_loss = 0.3900331640716925, disc_loss = 0.06582862946342691
Trained batch 277 in epoch 11, gen_loss = 0.39018923001323674, disc_loss = 0.06561105234695853
Trained batch 278 in epoch 11, gen_loss = 0.3903449846424937, disc_loss = 0.06544092011814903
Trained batch 279 in epoch 11, gen_loss = 0.39002241109098706, disc_loss = 0.06586904890303101
Trained batch 280 in epoch 11, gen_loss = 0.390273331111012, disc_loss = 0.06613035757240451
Trained batch 281 in epoch 11, gen_loss = 0.39035075501347266, disc_loss = 0.06601747087077468
Trained batch 282 in epoch 11, gen_loss = 0.3901172483557105, disc_loss = 0.06610984377589327
Trained batch 283 in epoch 11, gen_loss = 0.39014082013721196, disc_loss = 0.06589121007832738
Trained batch 284 in epoch 11, gen_loss = 0.3901815320316114, disc_loss = 0.0657056685439066
Trained batch 285 in epoch 11, gen_loss = 0.39015982201049376, disc_loss = 0.0655334439239354
Trained batch 286 in epoch 11, gen_loss = 0.39050357869277846, disc_loss = 0.06532322622361862
Trained batch 287 in epoch 11, gen_loss = 0.3903955811013778, disc_loss = 0.06518539545585453
Trained batch 288 in epoch 11, gen_loss = 0.3903501138967626, disc_loss = 0.0650104943737001
Trained batch 289 in epoch 11, gen_loss = 0.39050919002500073, disc_loss = 0.06497744021070158
Trained batch 290 in epoch 11, gen_loss = 0.3901807242857222, disc_loss = 0.06495749879839648
Trained batch 291 in epoch 11, gen_loss = 0.3902973805184234, disc_loss = 0.06476718732889436
Trained batch 292 in epoch 11, gen_loss = 0.390453792167605, disc_loss = 0.06458395164707872
Trained batch 293 in epoch 11, gen_loss = 0.39055812338582513, disc_loss = 0.0643868711982936
Trained batch 294 in epoch 11, gen_loss = 0.3904558264603049, disc_loss = 0.06420898658965352
Trained batch 295 in epoch 11, gen_loss = 0.3902433082662724, disc_loss = 0.06411831734569844
Trained batch 296 in epoch 11, gen_loss = 0.3900764692913402, disc_loss = 0.06440275405009939
Trained batch 297 in epoch 11, gen_loss = 0.39027351260985305, disc_loss = 0.06436027498171984
Trained batch 298 in epoch 11, gen_loss = 0.39017306323035505, disc_loss = 0.06418433567558891
Trained batch 299 in epoch 11, gen_loss = 0.3899697076280912, disc_loss = 0.0641428148886189
Trained batch 300 in epoch 11, gen_loss = 0.3901961079467571, disc_loss = 0.06405105113989343
Trained batch 301 in epoch 11, gen_loss = 0.39029225272848117, disc_loss = 0.06386134024734134
Trained batch 302 in epoch 11, gen_loss = 0.39001940038337957, disc_loss = 0.06381356580914443
Trained batch 303 in epoch 11, gen_loss = 0.39008845712401363, disc_loss = 0.06384991271127212
Trained batch 304 in epoch 11, gen_loss = 0.3901816065194177, disc_loss = 0.06380150500135344
Trained batch 305 in epoch 11, gen_loss = 0.3902224077313554, disc_loss = 0.06360763238189024
Trained batch 306 in epoch 11, gen_loss = 0.39038664490858194, disc_loss = 0.06362147920337241
Trained batch 307 in epoch 11, gen_loss = 0.3900223296958131, disc_loss = 0.06432491593976057
Trained batch 308 in epoch 11, gen_loss = 0.3902045033124658, disc_loss = 0.0649612929331422
Trained batch 309 in epoch 11, gen_loss = 0.3903408944606781, disc_loss = 0.06477528781509928
Trained batch 310 in epoch 11, gen_loss = 0.3904591270773357, disc_loss = 0.06464228044650323
Trained batch 311 in epoch 11, gen_loss = 0.39043640479063374, disc_loss = 0.06455610781902066
Trained batch 312 in epoch 11, gen_loss = 0.3903576592667796, disc_loss = 0.06447739397940307
Trained batch 313 in epoch 11, gen_loss = 0.39055729159124336, disc_loss = 0.06437818145907372
Trained batch 314 in epoch 11, gen_loss = 0.390632340643141, disc_loss = 0.06421910689493257
Trained batch 315 in epoch 11, gen_loss = 0.3906494520510299, disc_loss = 0.06417247448617569
Trained batch 316 in epoch 11, gen_loss = 0.3908937979571827, disc_loss = 0.06461555215350884
Trained batch 317 in epoch 11, gen_loss = 0.3908902551018217, disc_loss = 0.06570671300356914
Trained batch 318 in epoch 11, gen_loss = 0.39079310172777565, disc_loss = 0.06572529625258522
Trained batch 319 in epoch 11, gen_loss = 0.390880211815238, disc_loss = 0.06586732334253612
Trained batch 320 in epoch 11, gen_loss = 0.39081709927116226, disc_loss = 0.06580167341066344
Trained batch 321 in epoch 11, gen_loss = 0.3907489208331019, disc_loss = 0.0660013246960267
Trained batch 322 in epoch 11, gen_loss = 0.3906725633993237, disc_loss = 0.0659079617047942
Trained batch 323 in epoch 11, gen_loss = 0.3905586720800694, disc_loss = 0.06580028120847994
Trained batch 324 in epoch 11, gen_loss = 0.3903716381696554, disc_loss = 0.06595061940785785
Trained batch 325 in epoch 11, gen_loss = 0.3904726515335539, disc_loss = 0.0658345036108641
Trained batch 326 in epoch 11, gen_loss = 0.3906214285516593, disc_loss = 0.06587913319246348
Trained batch 327 in epoch 11, gen_loss = 0.3904329378430436, disc_loss = 0.06635703629297318
Trained batch 328 in epoch 11, gen_loss = 0.3905767254010522, disc_loss = 0.06644705514420718
Trained batch 329 in epoch 11, gen_loss = 0.390733578710845, disc_loss = 0.06629701676834938
Trained batch 330 in epoch 11, gen_loss = 0.3906710128049476, disc_loss = 0.06613255192995567
Trained batch 331 in epoch 11, gen_loss = 0.3906741301158825, disc_loss = 0.06605216080788523
Trained batch 332 in epoch 11, gen_loss = 0.3907180309474647, disc_loss = 0.0659268679189588
Trained batch 333 in epoch 11, gen_loss = 0.39100931486683693, disc_loss = 0.06583449447354647
Trained batch 334 in epoch 11, gen_loss = 0.3912446091424173, disc_loss = 0.0658315146800631
Trained batch 335 in epoch 11, gen_loss = 0.39094449757110505, disc_loss = 0.06578977945831693
Trained batch 336 in epoch 11, gen_loss = 0.3910428074241038, disc_loss = 0.0658301274977536
Trained batch 337 in epoch 11, gen_loss = 0.39095659236583485, disc_loss = 0.065773099064331
Trained batch 338 in epoch 11, gen_loss = 0.3911052369965916, disc_loss = 0.06566477650886396
Trained batch 339 in epoch 11, gen_loss = 0.39131968389539157, disc_loss = 0.06551084783174754
Trained batch 340 in epoch 11, gen_loss = 0.3916846562690399, disc_loss = 0.0653526182696114
Trained batch 341 in epoch 11, gen_loss = 0.3918258479812689, disc_loss = 0.06517970985705741
Trained batch 342 in epoch 11, gen_loss = 0.3919216972224566, disc_loss = 0.06507042507605719
Trained batch 343 in epoch 11, gen_loss = 0.39221196422396704, disc_loss = 0.06504031110468299
Trained batch 344 in epoch 11, gen_loss = 0.39185740800871366, disc_loss = 0.06519921806411466
Trained batch 345 in epoch 11, gen_loss = 0.3919695694150263, disc_loss = 0.0657903205366493
Trained batch 346 in epoch 11, gen_loss = 0.3918267390569967, disc_loss = 0.06567785767596805
Trained batch 347 in epoch 11, gen_loss = 0.3919101479923588, disc_loss = 0.0656686067559767
Trained batch 348 in epoch 11, gen_loss = 0.3918748193962185, disc_loss = 0.06562611663495231
Trained batch 349 in epoch 11, gen_loss = 0.3917884644440242, disc_loss = 0.06547589220904879
Trained batch 350 in epoch 11, gen_loss = 0.39168148952671605, disc_loss = 0.06535706918240868
Trained batch 351 in epoch 11, gen_loss = 0.3918142534623092, disc_loss = 0.0652422650150997
Trained batch 352 in epoch 11, gen_loss = 0.39188511437464707, disc_loss = 0.06535231014159601
Trained batch 353 in epoch 11, gen_loss = 0.39168369930006014, disc_loss = 0.06596950355569943
Trained batch 354 in epoch 11, gen_loss = 0.39168986308742576, disc_loss = 0.06627406740534893
Trained batch 355 in epoch 11, gen_loss = 0.3916136911243535, disc_loss = 0.06624896385120961
Trained batch 356 in epoch 11, gen_loss = 0.39151126655543883, disc_loss = 0.06625915725952854
Trained batch 357 in epoch 11, gen_loss = 0.3913809745338376, disc_loss = 0.06625971714471722
Trained batch 358 in epoch 11, gen_loss = 0.3915618565089191, disc_loss = 0.06612068603287417
Trained batch 359 in epoch 11, gen_loss = 0.39153104656272464, disc_loss = 0.06599881192410571
Trained batch 360 in epoch 11, gen_loss = 0.3914012884169074, disc_loss = 0.06590828177495923
Trained batch 361 in epoch 11, gen_loss = 0.39172195894283485, disc_loss = 0.06694298935025025
Trained batch 362 in epoch 11, gen_loss = 0.3915065232223059, disc_loss = 0.06700854019592863
Trained batch 363 in epoch 11, gen_loss = 0.39154821175795335, disc_loss = 0.06696109349614235
Trained batch 364 in epoch 11, gen_loss = 0.39155390074808305, disc_loss = 0.06699381902150503
Trained batch 365 in epoch 11, gen_loss = 0.39155138817315543, disc_loss = 0.06693096596065684
Trained batch 366 in epoch 11, gen_loss = 0.39148087925417224, disc_loss = 0.06689203983015439
Trained batch 367 in epoch 11, gen_loss = 0.3915802897966426, disc_loss = 0.06677549889908456
Trained batch 368 in epoch 11, gen_loss = 0.3916000090640412, disc_loss = 0.06669423337218157
Trained batch 369 in epoch 11, gen_loss = 0.39142161124461405, disc_loss = 0.06664562894635506
Trained batch 370 in epoch 11, gen_loss = 0.3913405160055649, disc_loss = 0.06675215977974577
Trained batch 371 in epoch 11, gen_loss = 0.39147800535604516, disc_loss = 0.06765928008012793
Trained batch 372 in epoch 11, gen_loss = 0.39127408323594776, disc_loss = 0.06752102498224768
Trained batch 373 in epoch 11, gen_loss = 0.39127442734764223, disc_loss = 0.06770824204462973
Trained batch 374 in epoch 11, gen_loss = 0.39138032428423564, disc_loss = 0.06773023934910695
Trained batch 375 in epoch 11, gen_loss = 0.3913615492588662, disc_loss = 0.06761853522967864
Trained batch 376 in epoch 11, gen_loss = 0.39134472189594643, disc_loss = 0.067647427767614
Trained batch 377 in epoch 11, gen_loss = 0.39137828925614637, disc_loss = 0.06772419155166341
Trained batch 378 in epoch 11, gen_loss = 0.3912110337324067, disc_loss = 0.06818394488003843
Trained batch 379 in epoch 11, gen_loss = 0.3914204116714628, disc_loss = 0.06820437681959256
Trained batch 380 in epoch 11, gen_loss = 0.39127249910136847, disc_loss = 0.06814755582717538
Trained batch 381 in epoch 11, gen_loss = 0.3911487310344636, disc_loss = 0.06800723764606562
Trained batch 382 in epoch 11, gen_loss = 0.3911474636578373, disc_loss = 0.06786540238668184
Trained batch 383 in epoch 11, gen_loss = 0.3909040552874406, disc_loss = 0.06789761438752369
Trained batch 384 in epoch 11, gen_loss = 0.3910718162338455, disc_loss = 0.06826141657090032
Trained batch 385 in epoch 11, gen_loss = 0.3912738058233508, disc_loss = 0.0681690222057731
Trained batch 386 in epoch 11, gen_loss = 0.3912636945722023, disc_loss = 0.06805529699056802
Trained batch 387 in epoch 11, gen_loss = 0.3912052458401808, disc_loss = 0.06793373931660172
Trained batch 388 in epoch 11, gen_loss = 0.39120155304746945, disc_loss = 0.06796218928878596
Trained batch 389 in epoch 11, gen_loss = 0.3911492645740509, disc_loss = 0.067912148961272
Trained batch 390 in epoch 11, gen_loss = 0.3911324189142193, disc_loss = 0.0679735538580686
Trained batch 391 in epoch 11, gen_loss = 0.39122262505852445, disc_loss = 0.0679344767704606
Trained batch 392 in epoch 11, gen_loss = 0.3913375795949203, disc_loss = 0.06784967769117452
Trained batch 393 in epoch 11, gen_loss = 0.3915190904727442, disc_loss = 0.06778403456667959
Trained batch 394 in epoch 11, gen_loss = 0.3917273479926435, disc_loss = 0.06765831986182852
Trained batch 395 in epoch 11, gen_loss = 0.39179686900943217, disc_loss = 0.06750564778110746
Trained batch 396 in epoch 11, gen_loss = 0.39182095954039836, disc_loss = 0.06735598906330408
Trained batch 397 in epoch 11, gen_loss = 0.3917963396963762, disc_loss = 0.06720027378783679
Trained batch 398 in epoch 11, gen_loss = 0.3916917058608885, disc_loss = 0.06706170476552911
Trained batch 399 in epoch 11, gen_loss = 0.39169864155352113, disc_loss = 0.06699309429386631
Trained batch 400 in epoch 11, gen_loss = 0.3917043852687179, disc_loss = 0.06686270098780234
Trained batch 401 in epoch 11, gen_loss = 0.39168684266099885, disc_loss = 0.06686295594195303
Trained batch 402 in epoch 11, gen_loss = 0.3918262711973403, disc_loss = 0.06737143669517771
Trained batch 403 in epoch 11, gen_loss = 0.3919409466261911, disc_loss = 0.06725445991188361
Trained batch 404 in epoch 11, gen_loss = 0.3916515036129657, disc_loss = 0.06720614691069465
Trained batch 405 in epoch 11, gen_loss = 0.3916357862097876, disc_loss = 0.06709537447976141
Trained batch 406 in epoch 11, gen_loss = 0.39177060998628416, disc_loss = 0.06717400956001929
Trained batch 407 in epoch 11, gen_loss = 0.3916444611169544, disc_loss = 0.06747993045513902
Trained batch 408 in epoch 11, gen_loss = 0.39182285363341895, disc_loss = 0.06735489236231902
Trained batch 409 in epoch 11, gen_loss = 0.39195525515370255, disc_loss = 0.06742026472645925
Trained batch 410 in epoch 11, gen_loss = 0.39183041388100953, disc_loss = 0.06737042643773367
Trained batch 411 in epoch 11, gen_loss = 0.3917097793620767, disc_loss = 0.06725828527038899
Trained batch 412 in epoch 11, gen_loss = 0.3919065935271127, disc_loss = 0.06715880201105705
Trained batch 413 in epoch 11, gen_loss = 0.3919995218371424, disc_loss = 0.067055179681269
Trained batch 414 in epoch 11, gen_loss = 0.3919798631265939, disc_loss = 0.06697615324239056
Trained batch 415 in epoch 11, gen_loss = 0.3918093591928482, disc_loss = 0.0671449804056185
Trained batch 416 in epoch 11, gen_loss = 0.39171597182893636, disc_loss = 0.0670647226760892
Trained batch 417 in epoch 11, gen_loss = 0.39183145134072556, disc_loss = 0.06693146655193427
Trained batch 418 in epoch 11, gen_loss = 0.39170427503050936, disc_loss = 0.06681376953691529
Trained batch 419 in epoch 11, gen_loss = 0.39172036740041916, disc_loss = 0.06668133546509558
Trained batch 420 in epoch 11, gen_loss = 0.39180287463931174, disc_loss = 0.06661355488152727
Trained batch 421 in epoch 11, gen_loss = 0.39148197736220336, disc_loss = 0.06701563983511233
Trained batch 422 in epoch 11, gen_loss = 0.39162083001846965, disc_loss = 0.06714041516774864
Trained batch 423 in epoch 11, gen_loss = 0.391733927827961, disc_loss = 0.06700714187309989
Trained batch 424 in epoch 11, gen_loss = 0.39172703799079445, disc_loss = 0.06688842543346041
Trained batch 425 in epoch 11, gen_loss = 0.39169544548216, disc_loss = 0.06676774954711887
Trained batch 426 in epoch 11, gen_loss = 0.39175475055495806, disc_loss = 0.06672898290866432
Trained batch 427 in epoch 11, gen_loss = 0.3916027292469952, disc_loss = 0.06692578970828902
Trained batch 428 in epoch 11, gen_loss = 0.3917099579230889, disc_loss = 0.06685261574241665
Trained batch 429 in epoch 11, gen_loss = 0.39179333247417625, disc_loss = 0.06689657160015994
Trained batch 430 in epoch 11, gen_loss = 0.39183125791859463, disc_loss = 0.06678034030246763
Trained batch 431 in epoch 11, gen_loss = 0.3919553101338722, disc_loss = 0.06716554132893819
Trained batch 432 in epoch 11, gen_loss = 0.3917575964476165, disc_loss = 0.06827644102585095
Trained batch 433 in epoch 11, gen_loss = 0.3918077409404763, disc_loss = 0.06828108032058049
Trained batch 434 in epoch 11, gen_loss = 0.39192362927842417, disc_loss = 0.06825749096942359
Trained batch 435 in epoch 11, gen_loss = 0.39202462287124146, disc_loss = 0.06818246441987266
Trained batch 436 in epoch 11, gen_loss = 0.3920164687955407, disc_loss = 0.06810717868194564
Trained batch 437 in epoch 11, gen_loss = 0.39198481465039187, disc_loss = 0.06806445036287585
Trained batch 438 in epoch 11, gen_loss = 0.3918862492864387, disc_loss = 0.06801485305478062
Trained batch 439 in epoch 11, gen_loss = 0.392004069685936, disc_loss = 0.06814581615934995
Trained batch 440 in epoch 11, gen_loss = 0.3918830895640142, disc_loss = 0.06856813979104938
Trained batch 441 in epoch 11, gen_loss = 0.3919699894626755, disc_loss = 0.06870776721238415
Trained batch 442 in epoch 11, gen_loss = 0.3920129012846247, disc_loss = 0.0685989804835002
Trained batch 443 in epoch 11, gen_loss = 0.39209210349095835, disc_loss = 0.06853416633397878
Trained batch 444 in epoch 11, gen_loss = 0.39210097253992315, disc_loss = 0.06840511088500197
Trained batch 445 in epoch 11, gen_loss = 0.39214293638686964, disc_loss = 0.0683018756182572
Trained batch 446 in epoch 11, gen_loss = 0.3919643030337306, disc_loss = 0.06823291073467841
Trained batch 447 in epoch 11, gen_loss = 0.39195085869037677, disc_loss = 0.06821328980939663
Trained batch 448 in epoch 11, gen_loss = 0.39184894069265946, disc_loss = 0.06820691440602918
Trained batch 449 in epoch 11, gen_loss = 0.3917037871148851, disc_loss = 0.06811361442216568
Trained batch 450 in epoch 11, gen_loss = 0.39196351256444556, disc_loss = 0.06802399763982007
Trained batch 451 in epoch 11, gen_loss = 0.39197330579029777, disc_loss = 0.06800881103381712
Trained batch 452 in epoch 11, gen_loss = 0.39194869475385735, disc_loss = 0.06809477359426534
Trained batch 453 in epoch 11, gen_loss = 0.39194392829739577, disc_loss = 0.06829806186857794
Trained batch 454 in epoch 11, gen_loss = 0.39203443540321603, disc_loss = 0.06838764475638068
Trained batch 455 in epoch 11, gen_loss = 0.39220088256294267, disc_loss = 0.06825576927880511
Trained batch 456 in epoch 11, gen_loss = 0.3922963316513621, disc_loss = 0.06815410409269435
Trained batch 457 in epoch 11, gen_loss = 0.3923125745948225, disc_loss = 0.06804634351486658
Trained batch 458 in epoch 11, gen_loss = 0.3922266231642829, disc_loss = 0.06791902842986233
Trained batch 459 in epoch 11, gen_loss = 0.39220784060333086, disc_loss = 0.06779034822652845
Trained batch 460 in epoch 11, gen_loss = 0.3921903616177027, disc_loss = 0.0676967527236539
Trained batch 461 in epoch 11, gen_loss = 0.3919713201718929, disc_loss = 0.06759676264873121
Trained batch 462 in epoch 11, gen_loss = 0.3920858279675181, disc_loss = 0.06762272163171555
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.38767340779304504, disc_loss = 0.21873782575130463
Trained batch 1 in epoch 12, gen_loss = 0.3834296762943268, disc_loss = 0.15732528641819954
Trained batch 2 in epoch 12, gen_loss = 0.3701704939206441, disc_loss = 0.12255406379699707
Trained batch 3 in epoch 12, gen_loss = 0.38488128036260605, disc_loss = 0.10275638476014137
Trained batch 4 in epoch 12, gen_loss = 0.3968288481235504, disc_loss = 0.08603110983967781
Trained batch 5 in epoch 12, gen_loss = 0.387034073472023, disc_loss = 0.08393227371076743
Trained batch 6 in epoch 12, gen_loss = 0.39020090443747385, disc_loss = 0.08519300445914268
Trained batch 7 in epoch 12, gen_loss = 0.3978891968727112, disc_loss = 0.07781536295078695
Trained batch 8 in epoch 12, gen_loss = 0.385022845533159, disc_loss = 0.09241641871631145
Trained batch 9 in epoch 12, gen_loss = 0.4009174704551697, disc_loss = 0.10618970673531294
Trained batch 10 in epoch 12, gen_loss = 0.39703323624350806, disc_loss = 0.097110868092965
Trained batch 11 in epoch 12, gen_loss = 0.39617780844370526, disc_loss = 0.09091322395640115
Trained batch 12 in epoch 12, gen_loss = 0.3960359257001143, disc_loss = 0.08553141090445794
Trained batch 13 in epoch 12, gen_loss = 0.3930871146065848, disc_loss = 0.08141044959692019
Trained batch 14 in epoch 12, gen_loss = 0.39829418460528054, disc_loss = 0.07843949006249508
Trained batch 15 in epoch 12, gen_loss = 0.39591019228100777, disc_loss = 0.07466630398994312
Trained batch 16 in epoch 12, gen_loss = 0.39621417837984424, disc_loss = 0.07483375373789493
Trained batch 17 in epoch 12, gen_loss = 0.3967032978932063, disc_loss = 0.08366682665008637
Trained batch 18 in epoch 12, gen_loss = 0.39198161583197744, disc_loss = 0.09133763567201401
Trained batch 19 in epoch 12, gen_loss = 0.3976553604006767, disc_loss = 0.09594776886515319
Trained batch 20 in epoch 12, gen_loss = 0.3961072109994434, disc_loss = 0.09542878499875466
Trained batch 21 in epoch 12, gen_loss = 0.39565332504836, disc_loss = 0.0941241775978018
Trained batch 22 in epoch 12, gen_loss = 0.39409735798835754, disc_loss = 0.09672342755062424
Trained batch 23 in epoch 12, gen_loss = 0.3940324919919173, disc_loss = 0.09944516913189243
Trained batch 24 in epoch 12, gen_loss = 0.39513144493103025, disc_loss = 0.096616519279778
Trained batch 25 in epoch 12, gen_loss = 0.39151804263775164, disc_loss = 0.09491987658951145
Trained batch 26 in epoch 12, gen_loss = 0.39408120623341314, disc_loss = 0.10446980612835398
Trained batch 27 in epoch 12, gen_loss = 0.39264736218111856, disc_loss = 0.10900603304617107
Trained batch 28 in epoch 12, gen_loss = 0.3903565262926036, disc_loss = 0.1065987962908272
Trained batch 29 in epoch 12, gen_loss = 0.3904882073402405, disc_loss = 0.10834399042651058
Trained batch 30 in epoch 12, gen_loss = 0.39118246686074043, disc_loss = 0.10597153395534523
Trained batch 31 in epoch 12, gen_loss = 0.3898584032431245, disc_loss = 0.10637716136989184
Trained batch 32 in epoch 12, gen_loss = 0.39194018551797577, disc_loss = 0.10517544437651381
Trained batch 33 in epoch 12, gen_loss = 0.3874504276934792, disc_loss = 0.10429065589628675
Trained batch 34 in epoch 12, gen_loss = 0.3877812325954437, disc_loss = 0.10278169494122266
Trained batch 35 in epoch 12, gen_loss = 0.3878118975294961, disc_loss = 0.1002416458601753
Trained batch 36 in epoch 12, gen_loss = 0.3884825633989798, disc_loss = 0.09848225157003145
Trained batch 37 in epoch 12, gen_loss = 0.39048286174473007, disc_loss = 0.09729681350290775
Trained batch 38 in epoch 12, gen_loss = 0.3896668354670207, disc_loss = 0.09927438992338303
Trained batch 39 in epoch 12, gen_loss = 0.3894460588693619, disc_loss = 0.10403537666425108
Trained batch 40 in epoch 12, gen_loss = 0.3886929575989886, disc_loss = 0.10189923276079864
Trained batch 41 in epoch 12, gen_loss = 0.38623986499650137, disc_loss = 0.10335666610903683
Trained batch 42 in epoch 12, gen_loss = 0.3866605093312818, disc_loss = 0.1070499062798051
Trained batch 43 in epoch 12, gen_loss = 0.3852353881705891, disc_loss = 0.10551270575855266
Trained batch 44 in epoch 12, gen_loss = 0.38504032029045954, disc_loss = 0.10464978089763058
Trained batch 45 in epoch 12, gen_loss = 0.38486990138240484, disc_loss = 0.1031498562787538
Trained batch 46 in epoch 12, gen_loss = 0.38474101398853544, disc_loss = 0.10143690730663056
Trained batch 47 in epoch 12, gen_loss = 0.38581008402009803, disc_loss = 0.09970285169159372
Trained batch 48 in epoch 12, gen_loss = 0.3848135672053512, disc_loss = 0.09991021058997329
Trained batch 49 in epoch 12, gen_loss = 0.38568703770637514, disc_loss = 0.10125668942928315
Trained batch 50 in epoch 12, gen_loss = 0.38468939241241007, disc_loss = 0.10266518885014105
Trained batch 51 in epoch 12, gen_loss = 0.38382795739632386, disc_loss = 0.10167654947592662
Trained batch 52 in epoch 12, gen_loss = 0.3846161742255373, disc_loss = 0.100284440056333
Trained batch 53 in epoch 12, gen_loss = 0.38466533466621683, disc_loss = 0.09873112232458812
Trained batch 54 in epoch 12, gen_loss = 0.3837707362391732, disc_loss = 0.09766550412909551
Trained batch 55 in epoch 12, gen_loss = 0.38466555305889677, disc_loss = 0.09603810228873044
Trained batch 56 in epoch 12, gen_loss = 0.3853611235033002, disc_loss = 0.09453894425052822
Trained batch 57 in epoch 12, gen_loss = 0.3858659616832075, disc_loss = 0.09376833040331459
Trained batch 58 in epoch 12, gen_loss = 0.3840368435544483, disc_loss = 0.09327161544144659
Trained batch 59 in epoch 12, gen_loss = 0.3846536492307981, disc_loss = 0.09188829770622155
Trained batch 60 in epoch 12, gen_loss = 0.3853026638265516, disc_loss = 0.09078392155895956
Trained batch 61 in epoch 12, gen_loss = 0.3860293242239183, disc_loss = 0.08970797805476093
Trained batch 62 in epoch 12, gen_loss = 0.3867004986793276, disc_loss = 0.08852843118328897
Trained batch 63 in epoch 12, gen_loss = 0.38805883657187223, disc_loss = 0.08726367106282851
Trained batch 64 in epoch 12, gen_loss = 0.3886960025017078, disc_loss = 0.08635266992764977
Trained batch 65 in epoch 12, gen_loss = 0.3893879105647405, disc_loss = 0.08565924059119866
Trained batch 66 in epoch 12, gen_loss = 0.39001119892988634, disc_loss = 0.08447896855980602
Trained batch 67 in epoch 12, gen_loss = 0.3897606629659148, disc_loss = 0.08331903400283087
Trained batch 68 in epoch 12, gen_loss = 0.3896884080292522, disc_loss = 0.08229824796696936
Trained batch 69 in epoch 12, gen_loss = 0.3906782686710358, disc_loss = 0.08218753480219415
Trained batch 70 in epoch 12, gen_loss = 0.38925117338207404, disc_loss = 0.0841201234635123
Trained batch 71 in epoch 12, gen_loss = 0.38915372225973344, disc_loss = 0.08560126206268454
Trained batch 72 in epoch 12, gen_loss = 0.38946410809477716, disc_loss = 0.08459204969902152
Trained batch 73 in epoch 12, gen_loss = 0.3896571317234555, disc_loss = 0.08359931060742284
Trained batch 74 in epoch 12, gen_loss = 0.38854545990626016, disc_loss = 0.08273626077920199
Trained batch 75 in epoch 12, gen_loss = 0.38914606641781957, disc_loss = 0.08187118651786525
Trained batch 76 in epoch 12, gen_loss = 0.3890938704664057, disc_loss = 0.08093103109677503
Trained batch 77 in epoch 12, gen_loss = 0.38949084740418655, disc_loss = 0.08016782396067029
Trained batch 78 in epoch 12, gen_loss = 0.3893661023695258, disc_loss = 0.07953050222153528
Trained batch 79 in epoch 12, gen_loss = 0.38935248032212255, disc_loss = 0.07908546797698364
Trained batch 80 in epoch 12, gen_loss = 0.3877527596038065, disc_loss = 0.07991791492397035
Trained batch 81 in epoch 12, gen_loss = 0.38804378596747796, disc_loss = 0.08176044796071039
Trained batch 82 in epoch 12, gen_loss = 0.38925604935151986, disc_loss = 0.08137555333998907
Trained batch 83 in epoch 12, gen_loss = 0.3888381038393293, disc_loss = 0.08348224528266915
Trained batch 84 in epoch 12, gen_loss = 0.38750912091311285, disc_loss = 0.08418711619999479
Trained batch 85 in epoch 12, gen_loss = 0.38708646006362385, disc_loss = 0.08386628164065092
Trained batch 86 in epoch 12, gen_loss = 0.3872788616980629, disc_loss = 0.08304124666998784
Trained batch 87 in epoch 12, gen_loss = 0.3878854601220651, disc_loss = 0.08290812956296247
Trained batch 88 in epoch 12, gen_loss = 0.38707187269510845, disc_loss = 0.08311703440136789
Trained batch 89 in epoch 12, gen_loss = 0.38732244703504776, disc_loss = 0.08225267748865817
Trained batch 90 in epoch 12, gen_loss = 0.38784078451303333, disc_loss = 0.08183264998453003
Trained batch 91 in epoch 12, gen_loss = 0.3875373093330342, disc_loss = 0.08202721198777789
Trained batch 92 in epoch 12, gen_loss = 0.38721690479145254, disc_loss = 0.08137088020642598
Trained batch 93 in epoch 12, gen_loss = 0.38818705906259254, disc_loss = 0.08163722239910289
Trained batch 94 in epoch 12, gen_loss = 0.38701494179273904, disc_loss = 0.08374973410054257
Trained batch 95 in epoch 12, gen_loss = 0.3878099173307419, disc_loss = 0.08385577735801537
Trained batch 96 in epoch 12, gen_loss = 0.3874693878532685, disc_loss = 0.0831546276116494
Trained batch 97 in epoch 12, gen_loss = 0.38705384913755925, disc_loss = 0.08279180887858478
Trained batch 98 in epoch 12, gen_loss = 0.3869552437705223, disc_loss = 0.08240699015482507
Trained batch 99 in epoch 12, gen_loss = 0.38693067610263826, disc_loss = 0.08188389282673597
Trained batch 100 in epoch 12, gen_loss = 0.3874640665432014, disc_loss = 0.08224339963923587
Trained batch 101 in epoch 12, gen_loss = 0.38710234358030204, disc_loss = 0.08285268838060837
Trained batch 102 in epoch 12, gen_loss = 0.38686510399707313, disc_loss = 0.08237004334342132
Trained batch 103 in epoch 12, gen_loss = 0.387775104206342, disc_loss = 0.08260104357479857
Trained batch 104 in epoch 12, gen_loss = 0.38776935424123493, disc_loss = 0.08216774339477222
Trained batch 105 in epoch 12, gen_loss = 0.3879638207408617, disc_loss = 0.08152598491430564
Trained batch 106 in epoch 12, gen_loss = 0.3881925492086143, disc_loss = 0.08090099929962481
Trained batch 107 in epoch 12, gen_loss = 0.38875184180559935, disc_loss = 0.08027082998133092
Trained batch 108 in epoch 12, gen_loss = 0.38891192778534844, disc_loss = 0.08039004607724214
Trained batch 109 in epoch 12, gen_loss = 0.3883228570222855, disc_loss = 0.08089947062967853
Trained batch 110 in epoch 12, gen_loss = 0.3881061214047509, disc_loss = 0.08033243015509199
Trained batch 111 in epoch 12, gen_loss = 0.38788295031658243, disc_loss = 0.0797107819817029
Trained batch 112 in epoch 12, gen_loss = 0.3878320215550144, disc_loss = 0.07908376130745211
Trained batch 113 in epoch 12, gen_loss = 0.38776946459945877, disc_loss = 0.07846034426862995
Trained batch 114 in epoch 12, gen_loss = 0.38729973616807356, disc_loss = 0.07811336200684309
Trained batch 115 in epoch 12, gen_loss = 0.387133844453713, disc_loss = 0.07748378909610469
Trained batch 116 in epoch 12, gen_loss = 0.3873276478714413, disc_loss = 0.07702694177372843
Trained batch 117 in epoch 12, gen_loss = 0.387568870338343, disc_loss = 0.0764796072459322
Trained batch 118 in epoch 12, gen_loss = 0.38715956691934283, disc_loss = 0.07603393070900641
Trained batch 119 in epoch 12, gen_loss = 0.38700104629000026, disc_loss = 0.07575488213139275
Trained batch 120 in epoch 12, gen_loss = 0.38722725200258995, disc_loss = 0.07530904996924656
Trained batch 121 in epoch 12, gen_loss = 0.3874684103199693, disc_loss = 0.07492381970963029
Trained batch 122 in epoch 12, gen_loss = 0.38754185476923375, disc_loss = 0.07553669836038981
Trained batch 123 in epoch 12, gen_loss = 0.3872345347077616, disc_loss = 0.07558327650410994
Trained batch 124 in epoch 12, gen_loss = 0.38766855239868164, disc_loss = 0.07513917145133019
Trained batch 125 in epoch 12, gen_loss = 0.38822831733832286, disc_loss = 0.07464301175186558
Trained batch 126 in epoch 12, gen_loss = 0.38890565849664643, disc_loss = 0.07413056014677671
Trained batch 127 in epoch 12, gen_loss = 0.38918463746085763, disc_loss = 0.07366371372336289
Trained batch 128 in epoch 12, gen_loss = 0.3890962367371995, disc_loss = 0.07316489713338688
Trained batch 129 in epoch 12, gen_loss = 0.3894549106176083, disc_loss = 0.07269954000098201
Trained batch 130 in epoch 12, gen_loss = 0.38963140149152914, disc_loss = 0.07223033787725308
Trained batch 131 in epoch 12, gen_loss = 0.3889689217462684, disc_loss = 0.07227811738707576
Trained batch 132 in epoch 12, gen_loss = 0.38936187763859453, disc_loss = 0.07412087247195773
Trained batch 133 in epoch 12, gen_loss = 0.389306623544266, disc_loss = 0.0741693417180274
Trained batch 134 in epoch 12, gen_loss = 0.38897241442291824, disc_loss = 0.07406798514916942
Trained batch 135 in epoch 12, gen_loss = 0.3894934807630146, disc_loss = 0.0739309424192042
Trained batch 136 in epoch 12, gen_loss = 0.3894657892902402, disc_loss = 0.07372977439803581
Trained batch 137 in epoch 12, gen_loss = 0.38952378518339514, disc_loss = 0.0732993111419289
Trained batch 138 in epoch 12, gen_loss = 0.38957706436836465, disc_loss = 0.07283018544155488
Trained batch 139 in epoch 12, gen_loss = 0.39003795576947076, disc_loss = 0.07238384578377008
Trained batch 140 in epoch 12, gen_loss = 0.3900197518210039, disc_loss = 0.07204926242483846
Trained batch 141 in epoch 12, gen_loss = 0.3900318592786789, disc_loss = 0.07193244276174778
Trained batch 142 in epoch 12, gen_loss = 0.39048037745735864, disc_loss = 0.07213008436341803
Trained batch 143 in epoch 12, gen_loss = 0.39067018487387234, disc_loss = 0.07211419579107314
Trained batch 144 in epoch 12, gen_loss = 0.3908937298018357, disc_loss = 0.07173445319821095
Trained batch 145 in epoch 12, gen_loss = 0.39101696014404297, disc_loss = 0.07129859435691001
Trained batch 146 in epoch 12, gen_loss = 0.3913888106135284, disc_loss = 0.07094190414158666
Trained batch 147 in epoch 12, gen_loss = 0.39130940670902664, disc_loss = 0.07066402778130125
Trained batch 148 in epoch 12, gen_loss = 0.3915102513844535, disc_loss = 0.0702919667186653
Trained batch 149 in epoch 12, gen_loss = 0.39184285044670103, disc_loss = 0.0699374710706373
Trained batch 150 in epoch 12, gen_loss = 0.39240258813693824, disc_loss = 0.06971251112809837
Trained batch 151 in epoch 12, gen_loss = 0.39257017817152173, disc_loss = 0.06985128305141668
Trained batch 152 in epoch 12, gen_loss = 0.39298493527119455, disc_loss = 0.0696886255545846
Trained batch 153 in epoch 12, gen_loss = 0.3928961210049592, disc_loss = 0.06928310528784604
Trained batch 154 in epoch 12, gen_loss = 0.3928048151154672, disc_loss = 0.06890063617498644
Trained batch 155 in epoch 12, gen_loss = 0.39331563409322345, disc_loss = 0.06859215255826712
Trained batch 156 in epoch 12, gen_loss = 0.3928897386523569, disc_loss = 0.06882185102173477
Trained batch 157 in epoch 12, gen_loss = 0.3930120243679119, disc_loss = 0.06879796910606607
Trained batch 158 in epoch 12, gen_loss = 0.3935469630754219, disc_loss = 0.06850247544312627
Trained batch 159 in epoch 12, gen_loss = 0.39319346733391286, disc_loss = 0.06837260033935308
Trained batch 160 in epoch 12, gen_loss = 0.3932600958006723, disc_loss = 0.06804495905265674
Trained batch 161 in epoch 12, gen_loss = 0.3935353564627377, disc_loss = 0.06765626608911487
Trained batch 162 in epoch 12, gen_loss = 0.393020168769579, disc_loss = 0.06739826108460412
Trained batch 163 in epoch 12, gen_loss = 0.39298815643642004, disc_loss = 0.06704717417383885
Trained batch 164 in epoch 12, gen_loss = 0.3932951520789753, disc_loss = 0.06668717929754744
Trained batch 165 in epoch 12, gen_loss = 0.3928012169269194, disc_loss = 0.06637114608177848
Trained batch 166 in epoch 12, gen_loss = 0.3926051533864644, disc_loss = 0.06609320448443828
Trained batch 167 in epoch 12, gen_loss = 0.39244248771241735, disc_loss = 0.06585972891133722
Trained batch 168 in epoch 12, gen_loss = 0.39223934154538714, disc_loss = 0.06551253982439373
Trained batch 169 in epoch 12, gen_loss = 0.3918125957250595, disc_loss = 0.06604095514973297
Trained batch 170 in epoch 12, gen_loss = 0.39238009536475466, disc_loss = 0.06801839348756605
Trained batch 171 in epoch 12, gen_loss = 0.39283029353895854, disc_loss = 0.068186646690159
Trained batch 172 in epoch 12, gen_loss = 0.39262571706937227, disc_loss = 0.06832155384489394
Trained batch 173 in epoch 12, gen_loss = 0.3921703401653246, disc_loss = 0.06838106194339778
Trained batch 174 in epoch 12, gen_loss = 0.392558274269104, disc_loss = 0.06805583609534162
Trained batch 175 in epoch 12, gen_loss = 0.3924105893820524, disc_loss = 0.06860121555986222
Trained batch 176 in epoch 12, gen_loss = 0.3921378195959296, disc_loss = 0.06857518671280415
Trained batch 177 in epoch 12, gen_loss = 0.39186202743080223, disc_loss = 0.06909355894254332
Trained batch 178 in epoch 12, gen_loss = 0.39221506178712046, disc_loss = 0.07005337401496133
Trained batch 179 in epoch 12, gen_loss = 0.392172243197759, disc_loss = 0.06971122256687118
Trained batch 180 in epoch 12, gen_loss = 0.3918000988209445, disc_loss = 0.06986319317446393
Trained batch 181 in epoch 12, gen_loss = 0.39194118206972606, disc_loss = 0.06952713206308064
Trained batch 182 in epoch 12, gen_loss = 0.39192573310898954, disc_loss = 0.0695840799570328
Trained batch 183 in epoch 12, gen_loss = 0.391689356578433, disc_loss = 0.06965245696736257
Trained batch 184 in epoch 12, gen_loss = 0.3920660795392217, disc_loss = 0.06945450909536433
Trained batch 185 in epoch 12, gen_loss = 0.3923321720412982, disc_loss = 0.06916009072434678
Trained batch 186 in epoch 12, gen_loss = 0.3921400303827888, disc_loss = 0.06888717610667892
Trained batch 187 in epoch 12, gen_loss = 0.3918386349018584, disc_loss = 0.06892998443738102
Trained batch 188 in epoch 12, gen_loss = 0.3919721584786814, disc_loss = 0.07000349287101358
Trained batch 189 in epoch 12, gen_loss = 0.39167784609292683, disc_loss = 0.06988543374463915
Trained batch 190 in epoch 12, gen_loss = 0.39149578453982686, disc_loss = 0.06991718647543205
Trained batch 191 in epoch 12, gen_loss = 0.39157587724427384, disc_loss = 0.06972960550046992
Trained batch 192 in epoch 12, gen_loss = 0.39148796423111554, disc_loss = 0.06940465204784443
Trained batch 193 in epoch 12, gen_loss = 0.3913567390331288, disc_loss = 0.06912174968759424
Trained batch 194 in epoch 12, gen_loss = 0.3913548882190998, disc_loss = 0.06905509124581631
Trained batch 195 in epoch 12, gen_loss = 0.3914119549551789, disc_loss = 0.06886517478875359
Trained batch 196 in epoch 12, gen_loss = 0.3914570455926324, disc_loss = 0.06856046928575045
Trained batch 197 in epoch 12, gen_loss = 0.39138262455511574, disc_loss = 0.06829033991923988
Trained batch 198 in epoch 12, gen_loss = 0.39144031576175786, disc_loss = 0.06809500127974617
Trained batch 199 in epoch 12, gen_loss = 0.3913568753004074, disc_loss = 0.06786258058156819
Trained batch 200 in epoch 12, gen_loss = 0.39140538611815345, disc_loss = 0.06775968178495098
Trained batch 201 in epoch 12, gen_loss = 0.3908853967591087, disc_loss = 0.06834318202523755
Trained batch 202 in epoch 12, gen_loss = 0.39101720179243044, disc_loss = 0.06961484144675761
Trained batch 203 in epoch 12, gen_loss = 0.39113328459800456, disc_loss = 0.0693130861447357
Trained batch 204 in epoch 12, gen_loss = 0.39113147694890094, disc_loss = 0.06917222474315544
Trained batch 205 in epoch 12, gen_loss = 0.39129220889609995, disc_loss = 0.06889133277864566
Trained batch 206 in epoch 12, gen_loss = 0.39108540556856974, disc_loss = 0.06866145363878369
Trained batch 207 in epoch 12, gen_loss = 0.3912565087756285, disc_loss = 0.06848534221241537
Trained batch 208 in epoch 12, gen_loss = 0.39111312054561087, disc_loss = 0.06866083047731499
Trained batch 209 in epoch 12, gen_loss = 0.3910607445807684, disc_loss = 0.07031979702324384
Trained batch 210 in epoch 12, gen_loss = 0.3908246765487002, disc_loss = 0.07077640478203506
Trained batch 211 in epoch 12, gen_loss = 0.3906698575559652, disc_loss = 0.07079475140638368
Trained batch 212 in epoch 12, gen_loss = 0.39062069321462245, disc_loss = 0.07108412052946331
Trained batch 213 in epoch 12, gen_loss = 0.39046420337997867, disc_loss = 0.07103208814112243
Trained batch 214 in epoch 12, gen_loss = 0.39000440794368124, disc_loss = 0.0711359087421104
Trained batch 215 in epoch 12, gen_loss = 0.39032456265003596, disc_loss = 0.07086848360658796
Trained batch 216 in epoch 12, gen_loss = 0.3900184857955177, disc_loss = 0.07066888874611273
Trained batch 217 in epoch 12, gen_loss = 0.39043921382602204, disc_loss = 0.070441619869014
Trained batch 218 in epoch 12, gen_loss = 0.39030024490944326, disc_loss = 0.07022204290922374
Trained batch 219 in epoch 12, gen_loss = 0.3901359651576389, disc_loss = 0.07032872441817414
Trained batch 220 in epoch 12, gen_loss = 0.390388606225743, disc_loss = 0.07049969624205413
Trained batch 221 in epoch 12, gen_loss = 0.39006953048813453, disc_loss = 0.07059358677885554
Trained batch 222 in epoch 12, gen_loss = 0.39023086816206104, disc_loss = 0.07105925438649986
Trained batch 223 in epoch 12, gen_loss = 0.3903191950438278, disc_loss = 0.07084321989012617
Trained batch 224 in epoch 12, gen_loss = 0.39008310715357464, disc_loss = 0.07086215648386214
Trained batch 225 in epoch 12, gen_loss = 0.39008102480289153, disc_loss = 0.07058004068985449
Trained batch 226 in epoch 12, gen_loss = 0.39020069987238243, disc_loss = 0.0703373102159424
Trained batch 227 in epoch 12, gen_loss = 0.3905167573115282, disc_loss = 0.07020154080288321
Trained batch 228 in epoch 12, gen_loss = 0.39047300646398786, disc_loss = 0.07020030132856822
Trained batch 229 in epoch 12, gen_loss = 0.39045303839704265, disc_loss = 0.07017258157467712
Trained batch 230 in epoch 12, gen_loss = 0.39026117208716155, disc_loss = 0.07022305956569971
Trained batch 231 in epoch 12, gen_loss = 0.39051985509436704, disc_loss = 0.07012387035526978
Trained batch 232 in epoch 12, gen_loss = 0.390793623586581, disc_loss = 0.06986233668377854
Trained batch 233 in epoch 12, gen_loss = 0.3905983043786807, disc_loss = 0.06993017466261219
Trained batch 234 in epoch 12, gen_loss = 0.39066676243822623, disc_loss = 0.069829727689478
Trained batch 235 in epoch 12, gen_loss = 0.39078429366572426, disc_loss = 0.06962788982269497
Trained batch 236 in epoch 12, gen_loss = 0.3907596616050865, disc_loss = 0.06940554327209665
Trained batch 237 in epoch 12, gen_loss = 0.3907216217587976, disc_loss = 0.06941311258212232
Trained batch 238 in epoch 12, gen_loss = 0.39101808976428776, disc_loss = 0.06927974420408699
Trained batch 239 in epoch 12, gen_loss = 0.39116790505747, disc_loss = 0.06902271481230855
Trained batch 240 in epoch 12, gen_loss = 0.39099174107258744, disc_loss = 0.06877575186371061
Trained batch 241 in epoch 12, gen_loss = 0.3911614596597419, disc_loss = 0.06852002551948483
Trained batch 242 in epoch 12, gen_loss = 0.3911329466129036, disc_loss = 0.06830028703229295
Trained batch 243 in epoch 12, gen_loss = 0.39133297847431214, disc_loss = 0.06808168193340668
Trained batch 244 in epoch 12, gen_loss = 0.3910998394294661, disc_loss = 0.06784142240577815
Trained batch 245 in epoch 12, gen_loss = 0.3912459481053236, disc_loss = 0.06766985596831494
Trained batch 246 in epoch 12, gen_loss = 0.3912484550524337, disc_loss = 0.06763047215939774
Trained batch 247 in epoch 12, gen_loss = 0.3911998703354789, disc_loss = 0.06742711566508777
Trained batch 248 in epoch 12, gen_loss = 0.391216017275929, disc_loss = 0.06722314117184605
Trained batch 249 in epoch 12, gen_loss = 0.391343133687973, disc_loss = 0.06702501282840967
Trained batch 250 in epoch 12, gen_loss = 0.391542532885692, disc_loss = 0.06680616392453471
Trained batch 251 in epoch 12, gen_loss = 0.3918869655047144, disc_loss = 0.06660398131694704
Trained batch 252 in epoch 12, gen_loss = 0.39229631412170624, disc_loss = 0.06637294771216015
Trained batch 253 in epoch 12, gen_loss = 0.3922551133501248, disc_loss = 0.06616741659369056
Trained batch 254 in epoch 12, gen_loss = 0.3927482471746557, disc_loss = 0.06596252458790938
Trained batch 255 in epoch 12, gen_loss = 0.39244788873475045, disc_loss = 0.06581499631283805
Trained batch 256 in epoch 12, gen_loss = 0.39276374430044153, disc_loss = 0.06570963684744872
Trained batch 257 in epoch 12, gen_loss = 0.39288232053897176, disc_loss = 0.06550967173881886
Trained batch 258 in epoch 12, gen_loss = 0.39284510076276125, disc_loss = 0.06545245201905837
Trained batch 259 in epoch 12, gen_loss = 0.3933596628216597, disc_loss = 0.06525329974694893
Trained batch 260 in epoch 12, gen_loss = 0.3936988089048086, disc_loss = 0.06507921120387385
Trained batch 261 in epoch 12, gen_loss = 0.3936110203730241, disc_loss = 0.0649278430367699
Trained batch 262 in epoch 12, gen_loss = 0.39365738573636394, disc_loss = 0.06473539929001276
Trained batch 263 in epoch 12, gen_loss = 0.39364972992828395, disc_loss = 0.06467284195153325
Trained batch 264 in epoch 12, gen_loss = 0.39379091397771293, disc_loss = 0.06446835927594945
Trained batch 265 in epoch 12, gen_loss = 0.3939012020154107, disc_loss = 0.06427530550460954
Trained batch 266 in epoch 12, gen_loss = 0.394349327248134, disc_loss = 0.06405010998025816
Trained batch 267 in epoch 12, gen_loss = 0.3943282395823678, disc_loss = 0.06382508696936098
Trained batch 268 in epoch 12, gen_loss = 0.3942156331025092, disc_loss = 0.06362406340372302
Trained batch 269 in epoch 12, gen_loss = 0.39457563768934323, disc_loss = 0.06340412948608261
Trained batch 270 in epoch 12, gen_loss = 0.3944855205907153, disc_loss = 0.06325523069942872
Trained batch 271 in epoch 12, gen_loss = 0.39467636616352725, disc_loss = 0.06320109674347538
Trained batch 272 in epoch 12, gen_loss = 0.3946304242689531, disc_loss = 0.0629977339140102
Trained batch 273 in epoch 12, gen_loss = 0.3947210438060064, disc_loss = 0.06278682227610155
Trained batch 274 in epoch 12, gen_loss = 0.39486882773312654, disc_loss = 0.06267143937759101
Trained batch 275 in epoch 12, gen_loss = 0.3951762182557065, disc_loss = 0.06262046432179952
Trained batch 276 in epoch 12, gen_loss = 0.39499953927115844, disc_loss = 0.0629831818125752
Trained batch 277 in epoch 12, gen_loss = 0.39514437628735744, disc_loss = 0.06328192963047127
Trained batch 278 in epoch 12, gen_loss = 0.3950663163029592, disc_loss = 0.0631406738240886
Trained batch 279 in epoch 12, gen_loss = 0.3947022058069706, disc_loss = 0.06348833675978573
Trained batch 280 in epoch 12, gen_loss = 0.39492412086483425, disc_loss = 0.0641801556666776
Trained batch 281 in epoch 12, gen_loss = 0.394869697749192, disc_loss = 0.0641087058490697
Trained batch 282 in epoch 12, gen_loss = 0.39481821571980263, disc_loss = 0.06406178370253068
Trained batch 283 in epoch 12, gen_loss = 0.3948077996012191, disc_loss = 0.06408192107247346
Trained batch 284 in epoch 12, gen_loss = 0.39511626781078807, disc_loss = 0.06419049728939538
Trained batch 285 in epoch 12, gen_loss = 0.3948967942407915, disc_loss = 0.06485529897907111
Trained batch 286 in epoch 12, gen_loss = 0.3948669709810397, disc_loss = 0.06538875419273324
Trained batch 287 in epoch 12, gen_loss = 0.39509018427795833, disc_loss = 0.06541188907269518
Trained batch 288 in epoch 12, gen_loss = 0.39486293180178605, disc_loss = 0.06559530607018632
Trained batch 289 in epoch 12, gen_loss = 0.39461909388673716, disc_loss = 0.06547466070824784
Trained batch 290 in epoch 12, gen_loss = 0.3945898342992842, disc_loss = 0.06546597660333558
Trained batch 291 in epoch 12, gen_loss = 0.3943792409072184, disc_loss = 0.0657485695053466
Trained batch 292 in epoch 12, gen_loss = 0.39447960908502444, disc_loss = 0.06614964301602552
Trained batch 293 in epoch 12, gen_loss = 0.39450771954594827, disc_loss = 0.06594495477588834
Trained batch 294 in epoch 12, gen_loss = 0.3944646568621619, disc_loss = 0.06580663597826862
Trained batch 295 in epoch 12, gen_loss = 0.3942457827160487, disc_loss = 0.06564241151618017
Trained batch 296 in epoch 12, gen_loss = 0.3942311546617887, disc_loss = 0.06547803680494
Trained batch 297 in epoch 12, gen_loss = 0.39437880202027775, disc_loss = 0.06537751740097825
Trained batch 298 in epoch 12, gen_loss = 0.394339454512931, disc_loss = 0.06535942447963591
Trained batch 299 in epoch 12, gen_loss = 0.394622732202212, disc_loss = 0.06580402477721994
Trained batch 300 in epoch 12, gen_loss = 0.3943701893388235, disc_loss = 0.06694908676888682
Trained batch 301 in epoch 12, gen_loss = 0.39440025833268827, disc_loss = 0.06701631093203454
Trained batch 302 in epoch 12, gen_loss = 0.394056511003979, disc_loss = 0.06708480763593351
Trained batch 303 in epoch 12, gen_loss = 0.39404669992233576, disc_loss = 0.0672134597652506
Trained batch 304 in epoch 12, gen_loss = 0.39390331907350506, disc_loss = 0.06743136570239287
Trained batch 305 in epoch 12, gen_loss = 0.3939324719648735, disc_loss = 0.0678309150492115
Trained batch 306 in epoch 12, gen_loss = 0.3936836537010118, disc_loss = 0.06849785619081644
Trained batch 307 in epoch 12, gen_loss = 0.3937207425569559, disc_loss = 0.06839269201661304
Trained batch 308 in epoch 12, gen_loss = 0.39362934222113355, disc_loss = 0.06832688071909677
Trained batch 309 in epoch 12, gen_loss = 0.39373461517595476, disc_loss = 0.06825601096009655
Trained batch 310 in epoch 12, gen_loss = 0.39361972115047494, disc_loss = 0.06837822657776248
Trained batch 311 in epoch 12, gen_loss = 0.3933432723085086, disc_loss = 0.06833495873471317
Trained batch 312 in epoch 12, gen_loss = 0.39362979030456785, disc_loss = 0.06991926631027351
Trained batch 313 in epoch 12, gen_loss = 0.3936979574192861, disc_loss = 0.0698213958734599
Trained batch 314 in epoch 12, gen_loss = 0.39374030468955873, disc_loss = 0.06982948355864556
Trained batch 315 in epoch 12, gen_loss = 0.39375881662097156, disc_loss = 0.0697716937755541
Trained batch 316 in epoch 12, gen_loss = 0.39387415739640075, disc_loss = 0.06962176713554853
Trained batch 317 in epoch 12, gen_loss = 0.3939663200820767, disc_loss = 0.0694380171235311
Trained batch 318 in epoch 12, gen_loss = 0.39365039508918237, disc_loss = 0.06934592352383026
Trained batch 319 in epoch 12, gen_loss = 0.3938859769143164, disc_loss = 0.06918746870142059
Trained batch 320 in epoch 12, gen_loss = 0.39403980951814266, disc_loss = 0.0690619177061693
Trained batch 321 in epoch 12, gen_loss = 0.39371855714306325, disc_loss = 0.06945009148167736
Trained batch 322 in epoch 12, gen_loss = 0.3941357622943796, disc_loss = 0.07049806501742326
Trained batch 323 in epoch 12, gen_loss = 0.3940931705780971, disc_loss = 0.07084245642109624
Trained batch 324 in epoch 12, gen_loss = 0.393765240082374, disc_loss = 0.07118849170107681
Trained batch 325 in epoch 12, gen_loss = 0.3938405939772085, disc_loss = 0.07118626485473013
Trained batch 326 in epoch 12, gen_loss = 0.3937025262492877, disc_loss = 0.07112030120244654
Trained batch 327 in epoch 12, gen_loss = 0.393455703720087, disc_loss = 0.07094716663236685
Trained batch 328 in epoch 12, gen_loss = 0.39322635096619557, disc_loss = 0.07084859208781329
Trained batch 329 in epoch 12, gen_loss = 0.39323869753967633, disc_loss = 0.07066806899736437
Trained batch 330 in epoch 12, gen_loss = 0.39318846440747424, disc_loss = 0.07061955369404008
Trained batch 331 in epoch 12, gen_loss = 0.39291933071182433, disc_loss = 0.07089560264118397
Trained batch 332 in epoch 12, gen_loss = 0.39314889102368744, disc_loss = 0.07211688018331232
Trained batch 333 in epoch 12, gen_loss = 0.393144815803288, disc_loss = 0.0722129169668902
Trained batch 334 in epoch 12, gen_loss = 0.39298280397457863, disc_loss = 0.07259869064593605
Trained batch 335 in epoch 12, gen_loss = 0.39316652200761293, disc_loss = 0.07272097786092975
Trained batch 336 in epoch 12, gen_loss = 0.3929716387559115, disc_loss = 0.0726473451010297
Trained batch 337 in epoch 12, gen_loss = 0.3927496684020793, disc_loss = 0.0726970982353462
Trained batch 338 in epoch 12, gen_loss = 0.3926430860627717, disc_loss = 0.07266721517949264
Trained batch 339 in epoch 12, gen_loss = 0.392513866547276, disc_loss = 0.07274566162993912
Trained batch 340 in epoch 12, gen_loss = 0.39253014361054317, disc_loss = 0.07263810940897994
Trained batch 341 in epoch 12, gen_loss = 0.3924668911430571, disc_loss = 0.07275701605657671
Trained batch 342 in epoch 12, gen_loss = 0.39249065275094946, disc_loss = 0.07315694121032976
Trained batch 343 in epoch 12, gen_loss = 0.3925513564500698, disc_loss = 0.07313306163522675
Trained batch 344 in epoch 12, gen_loss = 0.3924582480520442, disc_loss = 0.07299155899107564
Trained batch 345 in epoch 12, gen_loss = 0.3922820533114362, disc_loss = 0.07306964447347696
Trained batch 346 in epoch 12, gen_loss = 0.3924747929621155, disc_loss = 0.07359856858336895
Trained batch 347 in epoch 12, gen_loss = 0.3923279306498067, disc_loss = 0.07351868711585907
Trained batch 348 in epoch 12, gen_loss = 0.3923613175450902, disc_loss = 0.07336952361774586
Trained batch 349 in epoch 12, gen_loss = 0.39230001994541713, disc_loss = 0.07333546208018171
Trained batch 350 in epoch 12, gen_loss = 0.39242407373892957, disc_loss = 0.07344313559753879
Trained batch 351 in epoch 12, gen_loss = 0.3924053225835616, disc_loss = 0.07341117762751476
Trained batch 352 in epoch 12, gen_loss = 0.3925229762667637, disc_loss = 0.07340977401683693
Trained batch 353 in epoch 12, gen_loss = 0.3926540542457063, disc_loss = 0.07364513770884987
Trained batch 354 in epoch 12, gen_loss = 0.39260959297838344, disc_loss = 0.07357617596256166
Trained batch 355 in epoch 12, gen_loss = 0.3926173564088479, disc_loss = 0.07339359275287728
Trained batch 356 in epoch 12, gen_loss = 0.3926266037783369, disc_loss = 0.07320768603238509
Trained batch 357 in epoch 12, gen_loss = 0.3927578669686557, disc_loss = 0.07308587125520737
Trained batch 358 in epoch 12, gen_loss = 0.39255816715673486, disc_loss = 0.0733012380370284
Trained batch 359 in epoch 12, gen_loss = 0.39274444853266083, disc_loss = 0.07415250706965
Trained batch 360 in epoch 12, gen_loss = 0.39278180703231835, disc_loss = 0.073992855568904
Trained batch 361 in epoch 12, gen_loss = 0.39251288557579506, disc_loss = 0.07400045954578592
Trained batch 362 in epoch 12, gen_loss = 0.39248161457130076, disc_loss = 0.07385583871593263
Trained batch 363 in epoch 12, gen_loss = 0.39239988164914835, disc_loss = 0.07371664849675394
Trained batch 364 in epoch 12, gen_loss = 0.39257023065057517, disc_loss = 0.07363709519642775
Trained batch 365 in epoch 12, gen_loss = 0.39242490165220584, disc_loss = 0.07357606160533335
Trained batch 366 in epoch 12, gen_loss = 0.3924831928284357, disc_loss = 0.07346562523590223
Trained batch 367 in epoch 12, gen_loss = 0.3926757063878619, disc_loss = 0.07331329231902087
Trained batch 368 in epoch 12, gen_loss = 0.3925416086747394, disc_loss = 0.07327706173004275
Trained batch 369 in epoch 12, gen_loss = 0.3924685483043258, disc_loss = 0.07322529377226995
Trained batch 370 in epoch 12, gen_loss = 0.39221442862341027, disc_loss = 0.07332320589725319
Trained batch 371 in epoch 12, gen_loss = 0.3923542497939961, disc_loss = 0.07382888485169319
Trained batch 372 in epoch 12, gen_loss = 0.39220435034493656, disc_loss = 0.07376543699199428
Trained batch 373 in epoch 12, gen_loss = 0.39206767568295015, disc_loss = 0.07370070783473691
Trained batch 374 in epoch 12, gen_loss = 0.3918063530921936, disc_loss = 0.07372026808125277
Trained batch 375 in epoch 12, gen_loss = 0.3917045502903614, disc_loss = 0.07385244338458621
Trained batch 376 in epoch 12, gen_loss = 0.39164101231635723, disc_loss = 0.07384540752349644
Trained batch 377 in epoch 12, gen_loss = 0.39184872277830013, disc_loss = 0.07369819026324582
Trained batch 378 in epoch 12, gen_loss = 0.3918837995359325, disc_loss = 0.0735994625577364
Trained batch 379 in epoch 12, gen_loss = 0.3917594337933942, disc_loss = 0.0735914374462721
Trained batch 380 in epoch 12, gen_loss = 0.391886442899704, disc_loss = 0.07341181978356005
Trained batch 381 in epoch 12, gen_loss = 0.39205765575950685, disc_loss = 0.07342035813605735
Trained batch 382 in epoch 12, gen_loss = 0.3917880105754414, disc_loss = 0.07363882414478683
Trained batch 383 in epoch 12, gen_loss = 0.39184559889448184, disc_loss = 0.07361415157295899
Trained batch 384 in epoch 12, gen_loss = 0.3917377267565046, disc_loss = 0.0734487218510166
Trained batch 385 in epoch 12, gen_loss = 0.3916232925622574, disc_loss = 0.07331612380884993
Trained batch 386 in epoch 12, gen_loss = 0.39157276590973217, disc_loss = 0.07364577196420528
Trained batch 387 in epoch 12, gen_loss = 0.3918058027311699, disc_loss = 0.07434679017601457
Trained batch 388 in epoch 12, gen_loss = 0.3917665165157122, disc_loss = 0.07417879922011422
Trained batch 389 in epoch 12, gen_loss = 0.39162286214339426, disc_loss = 0.07414968183729798
Trained batch 390 in epoch 12, gen_loss = 0.391607194224282, disc_loss = 0.07401230161392684
Trained batch 391 in epoch 12, gen_loss = 0.3916169072748447, disc_loss = 0.0738781370805833
Trained batch 392 in epoch 12, gen_loss = 0.3915142774885241, disc_loss = 0.07377020412707659
Trained batch 393 in epoch 12, gen_loss = 0.39156370417115655, disc_loss = 0.07363627249608998
Trained batch 394 in epoch 12, gen_loss = 0.39166990895814535, disc_loss = 0.07353630977847814
Trained batch 395 in epoch 12, gen_loss = 0.39161327029719495, disc_loss = 0.07366724232284616
Trained batch 396 in epoch 12, gen_loss = 0.39171930021543044, disc_loss = 0.07429723605755201
Trained batch 397 in epoch 12, gen_loss = 0.39167568349658544, disc_loss = 0.0741779381291117
Trained batch 398 in epoch 12, gen_loss = 0.391610558618579, disc_loss = 0.07410821286356893
Trained batch 399 in epoch 12, gen_loss = 0.39162265054881573, disc_loss = 0.07410694902238901
Trained batch 400 in epoch 12, gen_loss = 0.39153006977571214, disc_loss = 0.0741210467596666
Trained batch 401 in epoch 12, gen_loss = 0.3915474567543808, disc_loss = 0.0740084186311005
Trained batch 402 in epoch 12, gen_loss = 0.39154195371395895, disc_loss = 0.07391444568189494
Trained batch 403 in epoch 12, gen_loss = 0.39146681911874526, disc_loss = 0.07394689388312677
Trained batch 404 in epoch 12, gen_loss = 0.3913746459984485, disc_loss = 0.07412670542095086
Trained batch 405 in epoch 12, gen_loss = 0.3914347119225657, disc_loss = 0.07426873778435746
Trained batch 406 in epoch 12, gen_loss = 0.3913003446429016, disc_loss = 0.07426355367684302
Trained batch 407 in epoch 12, gen_loss = 0.391216194001483, disc_loss = 0.07410706374645873
Trained batch 408 in epoch 12, gen_loss = 0.3913423135548757, disc_loss = 0.07410068348594338
Trained batch 409 in epoch 12, gen_loss = 0.39130797865914135, disc_loss = 0.07407690471481168
Trained batch 410 in epoch 12, gen_loss = 0.3914033877878584, disc_loss = 0.07392066746095871
Trained batch 411 in epoch 12, gen_loss = 0.3914146319176387, disc_loss = 0.07391393246090727
Trained batch 412 in epoch 12, gen_loss = 0.39135909780463063, disc_loss = 0.07388256040072524
Trained batch 413 in epoch 12, gen_loss = 0.3913120767776517, disc_loss = 0.07373257222695609
Trained batch 414 in epoch 12, gen_loss = 0.3912824775081083, disc_loss = 0.07360035266491573
Trained batch 415 in epoch 12, gen_loss = 0.39128151514495796, disc_loss = 0.07346278019059145
Trained batch 416 in epoch 12, gen_loss = 0.39136596063344026, disc_loss = 0.07330305245146602
Trained batch 417 in epoch 12, gen_loss = 0.39124235275544617, disc_loss = 0.07320649398470734
Trained batch 418 in epoch 12, gen_loss = 0.3912641970809718, disc_loss = 0.0731288653666149
Trained batch 419 in epoch 12, gen_loss = 0.39117216780072167, disc_loss = 0.07303523767817145
Trained batch 420 in epoch 12, gen_loss = 0.3911173718134185, disc_loss = 0.07300981806398694
Trained batch 421 in epoch 12, gen_loss = 0.39118918479901355, disc_loss = 0.07289505585911132
Trained batch 422 in epoch 12, gen_loss = 0.3910992270243083, disc_loss = 0.07332514189613046
Trained batch 423 in epoch 12, gen_loss = 0.39103541474016207, disc_loss = 0.07338585859364478
Trained batch 424 in epoch 12, gen_loss = 0.39112045933218564, disc_loss = 0.07327888409168842
Trained batch 425 in epoch 12, gen_loss = 0.39084094580910017, disc_loss = 0.07394508833115912
Trained batch 426 in epoch 12, gen_loss = 0.3908764119728946, disc_loss = 0.07398176658407848
Trained batch 427 in epoch 12, gen_loss = 0.39081367557850955, disc_loss = 0.07391898742404758
Trained batch 428 in epoch 12, gen_loss = 0.3907694476884562, disc_loss = 0.0738862711422814
Trained batch 429 in epoch 12, gen_loss = 0.39089377626430155, disc_loss = 0.07377699734155782
Trained batch 430 in epoch 12, gen_loss = 0.3908488478710369, disc_loss = 0.07366010474242063
Trained batch 431 in epoch 12, gen_loss = 0.39090833888837584, disc_loss = 0.07354344028054685
Trained batch 432 in epoch 12, gen_loss = 0.3909537850709215, disc_loss = 0.07340305634262363
Trained batch 433 in epoch 12, gen_loss = 0.39106102452574787, disc_loss = 0.07327733431086544
Trained batch 434 in epoch 12, gen_loss = 0.3912371512117057, disc_loss = 0.07313595686867919
Trained batch 435 in epoch 12, gen_loss = 0.39140188926403674, disc_loss = 0.07301162372486358
Trained batch 436 in epoch 12, gen_loss = 0.3912314800566885, disc_loss = 0.07290830136195797
Trained batch 437 in epoch 12, gen_loss = 0.3912743936934972, disc_loss = 0.07279979545127635
Trained batch 438 in epoch 12, gen_loss = 0.39134759158914345, disc_loss = 0.07272775755009289
Trained batch 439 in epoch 12, gen_loss = 0.391296251592311, disc_loss = 0.07278372906518846
Trained batch 440 in epoch 12, gen_loss = 0.39144160505595393, disc_loss = 0.07276261643857153
Trained batch 441 in epoch 12, gen_loss = 0.3914476229189748, disc_loss = 0.07265367852344823
Trained batch 442 in epoch 12, gen_loss = 0.39148098660914676, disc_loss = 0.07256867031411228
Trained batch 443 in epoch 12, gen_loss = 0.3912932227055232, disc_loss = 0.07256433090377548
Trained batch 444 in epoch 12, gen_loss = 0.39150408211718785, disc_loss = 0.0728770677413624
Trained batch 445 in epoch 12, gen_loss = 0.39155108652040027, disc_loss = 0.07273196732999147
Trained batch 446 in epoch 12, gen_loss = 0.3914970188866259, disc_loss = 0.07274309087334246
Trained batch 447 in epoch 12, gen_loss = 0.3913983624162419, disc_loss = 0.07259294081502178
Trained batch 448 in epoch 12, gen_loss = 0.39149459234059253, disc_loss = 0.07254618091170649
Trained batch 449 in epoch 12, gen_loss = 0.39138796382480195, disc_loss = 0.07240558215261747
Trained batch 450 in epoch 12, gen_loss = 0.3912394341502644, disc_loss = 0.07272010081769803
Trained batch 451 in epoch 12, gen_loss = 0.3913476113724498, disc_loss = 0.07295441793935142
Trained batch 452 in epoch 12, gen_loss = 0.39111772113814786, disc_loss = 0.07283534282236617
Trained batch 453 in epoch 12, gen_loss = 0.39113371914441364, disc_loss = 0.07272549914678206
Trained batch 454 in epoch 12, gen_loss = 0.391170030439293, disc_loss = 0.07262648829913974
Trained batch 455 in epoch 12, gen_loss = 0.3912496902702147, disc_loss = 0.0724875609949027
Trained batch 456 in epoch 12, gen_loss = 0.391257955939295, disc_loss = 0.0724675509405141
Trained batch 457 in epoch 12, gen_loss = 0.39117768088022176, disc_loss = 0.07262100186148114
Trained batch 458 in epoch 12, gen_loss = 0.39124760044685897, disc_loss = 0.07267282498556074
Trained batch 459 in epoch 12, gen_loss = 0.39132725738960766, disc_loss = 0.07263333766225158
Trained batch 460 in epoch 12, gen_loss = 0.39123613340477104, disc_loss = 0.07301480396965886
Trained batch 461 in epoch 12, gen_loss = 0.39120808114737143, disc_loss = 0.07309764861865009
Trained batch 462 in epoch 12, gen_loss = 0.390871506433765, disc_loss = 0.07300683192568821
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.4260462820529938, disc_loss = 0.01443745382130146
Trained batch 1 in epoch 13, gen_loss = 0.3984757959842682, disc_loss = 0.011587942019104958
Trained batch 2 in epoch 13, gen_loss = 0.389222115278244, disc_loss = 0.014555849755803743
Trained batch 3 in epoch 13, gen_loss = 0.3908672332763672, disc_loss = 0.01682342030107975
Trained batch 4 in epoch 13, gen_loss = 0.4005782961845398, disc_loss = 0.01654897294938564
Trained batch 5 in epoch 13, gen_loss = 0.40023812154928845, disc_loss = 0.015281205686430136
Trained batch 6 in epoch 13, gen_loss = 0.4017356421266283, disc_loss = 0.015282552423221725
Trained batch 7 in epoch 13, gen_loss = 0.39569394662976265, disc_loss = 0.017116297036409378
Trained batch 8 in epoch 13, gen_loss = 0.3989630805121528, disc_loss = 0.018240459056364164
Trained batch 9 in epoch 13, gen_loss = 0.401977601647377, disc_loss = 0.019716070406138896
Trained batch 10 in epoch 13, gen_loss = 0.4116117222742601, disc_loss = 0.037541634487834846
Trained batch 11 in epoch 13, gen_loss = 0.40716463575760525, disc_loss = 0.055079359405984483
Trained batch 12 in epoch 13, gen_loss = 0.407648341013835, disc_loss = 0.05448678666009353
Trained batch 13 in epoch 13, gen_loss = 0.4100693868739264, disc_loss = 0.052435399033129215
Trained batch 14 in epoch 13, gen_loss = 0.4076911985874176, disc_loss = 0.050234000633160275
Trained batch 15 in epoch 13, gen_loss = 0.4053658954799175, disc_loss = 0.049562291940674186
Trained batch 16 in epoch 13, gen_loss = 0.402420476955526, disc_loss = 0.04752604877028395
Trained batch 17 in epoch 13, gen_loss = 0.40600050654676223, disc_loss = 0.04553190670493576
Trained batch 18 in epoch 13, gen_loss = 0.4039444813602849, disc_loss = 0.044598628521749846
Trained batch 19 in epoch 13, gen_loss = 0.40571795105934144, disc_loss = 0.050413083750754595
Trained batch 20 in epoch 13, gen_loss = 0.3993987881001972, disc_loss = 0.05195777623781136
Trained batch 21 in epoch 13, gen_loss = 0.39632895724339917, disc_loss = 0.05177009791474451
Trained batch 22 in epoch 13, gen_loss = 0.39790046085482056, disc_loss = 0.05272284061040567
Trained batch 23 in epoch 13, gen_loss = 0.39774564901987713, disc_loss = 0.051606529857963324
Trained batch 24 in epoch 13, gen_loss = 0.3960048806667328, disc_loss = 0.05156362503767013
Trained batch 25 in epoch 13, gen_loss = 0.3999720811843872, disc_loss = 0.05862078500481752
Trained batch 26 in epoch 13, gen_loss = 0.3974681893984477, disc_loss = 0.061616679860485926
Trained batch 27 in epoch 13, gen_loss = 0.399492546916008, disc_loss = 0.06176176480948925
Trained batch 28 in epoch 13, gen_loss = 0.3977119018291605, disc_loss = 0.06046817014957297
Trained batch 29 in epoch 13, gen_loss = 0.3973820646603902, disc_loss = 0.06000677968064944
Trained batch 30 in epoch 13, gen_loss = 0.39828055039528876, disc_loss = 0.05878415000775168
Trained batch 31 in epoch 13, gen_loss = 0.39602951519191265, disc_loss = 0.05864414159441367
Trained batch 32 in epoch 13, gen_loss = 0.3936055067813758, disc_loss = 0.06052251933424762
Trained batch 33 in epoch 13, gen_loss = 0.3930441816063488, disc_loss = 0.06556972384671955
Trained batch 34 in epoch 13, gen_loss = 0.3941055144582476, disc_loss = 0.06704713877822671
Trained batch 35 in epoch 13, gen_loss = 0.392507650785976, disc_loss = 0.06571428493286173
Trained batch 36 in epoch 13, gen_loss = 0.393571096497613, disc_loss = 0.06410558047276493
Trained batch 37 in epoch 13, gen_loss = 0.39399977028369904, disc_loss = 0.06274042167014589
Trained batch 38 in epoch 13, gen_loss = 0.39434171487123537, disc_loss = 0.06161241105590493
Trained batch 39 in epoch 13, gen_loss = 0.3931066207587719, disc_loss = 0.061211832019034774
Trained batch 40 in epoch 13, gen_loss = 0.3947535280774279, disc_loss = 0.0714160765112355
Trained batch 41 in epoch 13, gen_loss = 0.3931677902028674, disc_loss = 0.07006021798588336
Trained batch 42 in epoch 13, gen_loss = 0.392359102881232, disc_loss = 0.07260351572835515
Trained batch 43 in epoch 13, gen_loss = 0.39188292012973264, disc_loss = 0.07302454195450991
Trained batch 44 in epoch 13, gen_loss = 0.39349546697404647, disc_loss = 0.0735390290307502
Trained batch 45 in epoch 13, gen_loss = 0.39203674767328345, disc_loss = 0.07503679407881977
Trained batch 46 in epoch 13, gen_loss = 0.39285244776847517, disc_loss = 0.07425934295269086
Trained batch 47 in epoch 13, gen_loss = 0.3932902316252391, disc_loss = 0.07282293309496406
Trained batch 48 in epoch 13, gen_loss = 0.3928899771096755, disc_loss = 0.07188602975018475
Trained batch 49 in epoch 13, gen_loss = 0.39255052447319033, disc_loss = 0.07080332991667092
Trained batch 50 in epoch 13, gen_loss = 0.3933066351740968, disc_loss = 0.06980901676248394
Trained batch 51 in epoch 13, gen_loss = 0.3941438455994313, disc_loss = 0.06880225338794005
Trained batch 52 in epoch 13, gen_loss = 0.3936799050502057, disc_loss = 0.06832409703682335
Trained batch 53 in epoch 13, gen_loss = 0.39226824707455105, disc_loss = 0.06929220091034141
Trained batch 54 in epoch 13, gen_loss = 0.39094116850332783, disc_loss = 0.07006752244620161
Trained batch 55 in epoch 13, gen_loss = 0.3918648229113647, disc_loss = 0.07158622861607
Trained batch 56 in epoch 13, gen_loss = 0.3922011120277539, disc_loss = 0.07060503826492973
Trained batch 57 in epoch 13, gen_loss = 0.39016178712762634, disc_loss = 0.07142352657232048
Trained batch 58 in epoch 13, gen_loss = 0.3900978408627591, disc_loss = 0.07185779395907865
Trained batch 59 in epoch 13, gen_loss = 0.39037353148063025, disc_loss = 0.07075978543919821
Trained batch 60 in epoch 13, gen_loss = 0.3907262042897647, disc_loss = 0.06972370649397862
Trained batch 61 in epoch 13, gen_loss = 0.39097541859073026, disc_loss = 0.06883646484704749
Trained batch 62 in epoch 13, gen_loss = 0.3895138880563161, disc_loss = 0.06834115806434836
Trained batch 63 in epoch 13, gen_loss = 0.3892812831327319, disc_loss = 0.06746236450271681
Trained batch 64 in epoch 13, gen_loss = 0.38992887781216545, disc_loss = 0.06656690159669289
Trained batch 65 in epoch 13, gen_loss = 0.3890682675621726, disc_loss = 0.06766604395075278
Trained batch 66 in epoch 13, gen_loss = 0.3898161365025079, disc_loss = 0.06788810431512433
Trained batch 67 in epoch 13, gen_loss = 0.38949519352001305, disc_loss = 0.06866851777714841
Trained batch 68 in epoch 13, gen_loss = 0.3905953017697818, disc_loss = 0.06956459085146587
Trained batch 69 in epoch 13, gen_loss = 0.39028739077704294, disc_loss = 0.06866713701747358
Trained batch 70 in epoch 13, gen_loss = 0.3898791414751133, disc_loss = 0.06831059330077448
Trained batch 71 in epoch 13, gen_loss = 0.39017828843659824, disc_loss = 0.06764276823054792
Trained batch 72 in epoch 13, gen_loss = 0.3901379267646842, disc_loss = 0.06767917608791223
Trained batch 73 in epoch 13, gen_loss = 0.3918180558327082, disc_loss = 0.07038156235766774
Trained batch 74 in epoch 13, gen_loss = 0.3912327619393667, disc_loss = 0.0724858543338875
Trained batch 75 in epoch 13, gen_loss = 0.39140977357563217, disc_loss = 0.07191557511319652
Trained batch 76 in epoch 13, gen_loss = 0.3923317492008209, disc_loss = 0.07140723689060126
Trained batch 77 in epoch 13, gen_loss = 0.3918656798509451, disc_loss = 0.07105451235428262
Trained batch 78 in epoch 13, gen_loss = 0.3920834984960435, disc_loss = 0.07084049695301094
Trained batch 79 in epoch 13, gen_loss = 0.39113376177847387, disc_loss = 0.07035614611231722
Trained batch 80 in epoch 13, gen_loss = 0.3905618503505801, disc_loss = 0.07036670992426851
Trained batch 81 in epoch 13, gen_loss = 0.39042475419800454, disc_loss = 0.0726952427918682
Trained batch 82 in epoch 13, gen_loss = 0.3901395093963807, disc_loss = 0.07396814824609332
Trained batch 83 in epoch 13, gen_loss = 0.390350379049778, disc_loss = 0.0743194432275015
Trained batch 84 in epoch 13, gen_loss = 0.39074733467663036, disc_loss = 0.0744561049484593
Trained batch 85 in epoch 13, gen_loss = 0.3907085275927255, disc_loss = 0.07489877190375917
Trained batch 86 in epoch 13, gen_loss = 0.3911129880225521, disc_loss = 0.07427322775146913
Trained batch 87 in epoch 13, gen_loss = 0.3914212327111851, disc_loss = 0.07352926482086662
Trained batch 88 in epoch 13, gen_loss = 0.39149687129460026, disc_loss = 0.07310163641474053
Trained batch 89 in epoch 13, gen_loss = 0.39113203353352016, disc_loss = 0.0729420825994263
Trained batch 90 in epoch 13, gen_loss = 0.3917791532291161, disc_loss = 0.07248927457872165
Trained batch 91 in epoch 13, gen_loss = 0.3916560907078826, disc_loss = 0.0727028717317254
Trained batch 92 in epoch 13, gen_loss = 0.39270326751534657, disc_loss = 0.07315212369505916
Trained batch 93 in epoch 13, gen_loss = 0.3924924439572273, disc_loss = 0.07307339960491245
Trained batch 94 in epoch 13, gen_loss = 0.39241145974711367, disc_loss = 0.07240192483816492
Trained batch 95 in epoch 13, gen_loss = 0.392569853613774, disc_loss = 0.0716976020776201
Trained batch 96 in epoch 13, gen_loss = 0.3929482133118148, disc_loss = 0.07108592290968932
Trained batch 97 in epoch 13, gen_loss = 0.39293150269255345, disc_loss = 0.07047971563261686
Trained batch 98 in epoch 13, gen_loss = 0.3933680069566977, disc_loss = 0.06982879081947936
Trained batch 99 in epoch 13, gen_loss = 0.39331285625696183, disc_loss = 0.0692632205132395
Trained batch 100 in epoch 13, gen_loss = 0.392902005131882, disc_loss = 0.06873078241317283
Trained batch 101 in epoch 13, gen_loss = 0.39353928700381635, disc_loss = 0.06827463442459702
Trained batch 102 in epoch 13, gen_loss = 0.39441810938918476, disc_loss = 0.06815138953801209
Trained batch 103 in epoch 13, gen_loss = 0.39394591777370525, disc_loss = 0.0682023723806756
Trained batch 104 in epoch 13, gen_loss = 0.3936691948345729, disc_loss = 0.06963628235140017
Trained batch 105 in epoch 13, gen_loss = 0.3943893392131014, disc_loss = 0.0730287378109148
Trained batch 106 in epoch 13, gen_loss = 0.3947113175815511, disc_loss = 0.07242490531371854
Trained batch 107 in epoch 13, gen_loss = 0.3941551016436683, disc_loss = 0.07229600418186574
Trained batch 108 in epoch 13, gen_loss = 0.3942422784796549, disc_loss = 0.07207945521510796
Trained batch 109 in epoch 13, gen_loss = 0.39496238367124037, disc_loss = 0.07153631222688339
Trained batch 110 in epoch 13, gen_loss = 0.39490841476766914, disc_loss = 0.07114622992807412
Trained batch 111 in epoch 13, gen_loss = 0.3949073223131044, disc_loss = 0.07082281909450623
Trained batch 112 in epoch 13, gen_loss = 0.3952848431283394, disc_loss = 0.07087398177853464
Trained batch 113 in epoch 13, gen_loss = 0.39492950523108766, disc_loss = 0.07104498490266371
Trained batch 114 in epoch 13, gen_loss = 0.39523907277895054, disc_loss = 0.07179800572440675
Trained batch 115 in epoch 13, gen_loss = 0.39439329710499993, disc_loss = 0.07226897495927224
Trained batch 116 in epoch 13, gen_loss = 0.3942758084362389, disc_loss = 0.0722659555876739
Trained batch 117 in epoch 13, gen_loss = 0.3940166674428067, disc_loss = 0.07181172634048735
Trained batch 118 in epoch 13, gen_loss = 0.3932676999007954, disc_loss = 0.07127761200633871
Trained batch 119 in epoch 13, gen_loss = 0.3930545628070831, disc_loss = 0.07089088175756236
Trained batch 120 in epoch 13, gen_loss = 0.392210950289876, disc_loss = 0.07039055951740131
Trained batch 121 in epoch 13, gen_loss = 0.39300323070072735, disc_loss = 0.07030803120893533
Trained batch 122 in epoch 13, gen_loss = 0.393060281993897, disc_loss = 0.0703743380320266
Trained batch 123 in epoch 13, gen_loss = 0.3925587957905185, disc_loss = 0.07049710667061229
Trained batch 124 in epoch 13, gen_loss = 0.3928224711418152, disc_loss = 0.07038793319463729
Trained batch 125 in epoch 13, gen_loss = 0.39282613188501386, disc_loss = 0.07069219849885457
Trained batch 126 in epoch 13, gen_loss = 0.3929749708476029, disc_loss = 0.07074305731949844
Trained batch 127 in epoch 13, gen_loss = 0.39216751302592456, disc_loss = 0.071236617048271
Trained batch 128 in epoch 13, gen_loss = 0.392559723567593, disc_loss = 0.07184266177720802
Trained batch 129 in epoch 13, gen_loss = 0.39266910667602833, disc_loss = 0.07134594119225557
Trained batch 130 in epoch 13, gen_loss = 0.3918902939967527, disc_loss = 0.07231684078867653
Trained batch 131 in epoch 13, gen_loss = 0.39198752266891074, disc_loss = 0.0722688920654808
Trained batch 132 in epoch 13, gen_loss = 0.3919225207396916, disc_loss = 0.07198258305906802
Trained batch 133 in epoch 13, gen_loss = 0.3918954169572289, disc_loss = 0.0715079262658064
Trained batch 134 in epoch 13, gen_loss = 0.3916343320299078, disc_loss = 0.07114676329548712
Trained batch 135 in epoch 13, gen_loss = 0.39103104042656284, disc_loss = 0.07073300500975593
Trained batch 136 in epoch 13, gen_loss = 0.39076708268075094, disc_loss = 0.07040667215049484
Trained batch 137 in epoch 13, gen_loss = 0.3913856276135514, disc_loss = 0.0700930005573816
Trained batch 138 in epoch 13, gen_loss = 0.3912276104628611, disc_loss = 0.0703277054624699
Trained batch 139 in epoch 13, gen_loss = 0.3908748667154993, disc_loss = 0.07127019321945097
Trained batch 140 in epoch 13, gen_loss = 0.3913901040317319, disc_loss = 0.07178753726052266
Trained batch 141 in epoch 13, gen_loss = 0.3910090556027184, disc_loss = 0.07153107840436655
Trained batch 142 in epoch 13, gen_loss = 0.3906857694362427, disc_loss = 0.07174395374510881
Trained batch 143 in epoch 13, gen_loss = 0.3912309809691376, disc_loss = 0.07190411134959301
Trained batch 144 in epoch 13, gen_loss = 0.39157052492273264, disc_loss = 0.07149998800636366
Trained batch 145 in epoch 13, gen_loss = 0.39120480622330756, disc_loss = 0.07105875530675666
Trained batch 146 in epoch 13, gen_loss = 0.39088908648815285, disc_loss = 0.0712630379767645
Trained batch 147 in epoch 13, gen_loss = 0.3916645176910065, disc_loss = 0.07186955404845444
Trained batch 148 in epoch 13, gen_loss = 0.3914565960032828, disc_loss = 0.07215886793080592
Trained batch 149 in epoch 13, gen_loss = 0.3906226708491643, disc_loss = 0.07548671767115593
Trained batch 150 in epoch 13, gen_loss = 0.39065214695519956, disc_loss = 0.07542585344701414
Trained batch 151 in epoch 13, gen_loss = 0.3914960360056476, disc_loss = 0.07583439158961962
Trained batch 152 in epoch 13, gen_loss = 0.39132456257452375, disc_loss = 0.07576493022878186
Trained batch 153 in epoch 13, gen_loss = 0.3911807333881205, disc_loss = 0.07537661330750237
Trained batch 154 in epoch 13, gen_loss = 0.390689080953598, disc_loss = 0.07513215025105784
Trained batch 155 in epoch 13, gen_loss = 0.39134432719304013, disc_loss = 0.07500820903059764
Trained batch 156 in epoch 13, gen_loss = 0.3912301232480699, disc_loss = 0.07552254323367101
Trained batch 157 in epoch 13, gen_loss = 0.3914170235018187, disc_loss = 0.075350764643731
Trained batch 158 in epoch 13, gen_loss = 0.3918912838090141, disc_loss = 0.07506882865567627
Trained batch 159 in epoch 13, gen_loss = 0.39180247150361536, disc_loss = 0.07481549901422113
Trained batch 160 in epoch 13, gen_loss = 0.3921010434997748, disc_loss = 0.0744884124615733
Trained batch 161 in epoch 13, gen_loss = 0.39211700580738207, disc_loss = 0.07410750429456432
Trained batch 162 in epoch 13, gen_loss = 0.3916453170630098, disc_loss = 0.07410289591144016
Trained batch 163 in epoch 13, gen_loss = 0.39137651698618403, disc_loss = 0.07595530585613011
Trained batch 164 in epoch 13, gen_loss = 0.3915350950125492, disc_loss = 0.0760738723375129
Trained batch 165 in epoch 13, gen_loss = 0.3915959713329752, disc_loss = 0.07619550112208509
Trained batch 166 in epoch 13, gen_loss = 0.3914668178130053, disc_loss = 0.07638017518144703
Trained batch 167 in epoch 13, gen_loss = 0.3914984769764401, disc_loss = 0.07625934846943155
Trained batch 168 in epoch 13, gen_loss = 0.390923796320808, disc_loss = 0.0766772940126661
Trained batch 169 in epoch 13, gen_loss = 0.3914661382927614, disc_loss = 0.0775618596276378
Trained batch 170 in epoch 13, gen_loss = 0.3910836619243287, disc_loss = 0.07728992012051637
Trained batch 171 in epoch 13, gen_loss = 0.39143431533214657, disc_loss = 0.07697312197604672
Trained batch 172 in epoch 13, gen_loss = 0.3913679419225351, disc_loss = 0.0767047091661764
Trained batch 173 in epoch 13, gen_loss = 0.3914108790200332, disc_loss = 0.07654947988239341
Trained batch 174 in epoch 13, gen_loss = 0.3914655009337834, disc_loss = 0.07680952744292362
Trained batch 175 in epoch 13, gen_loss = 0.3914875239133835, disc_loss = 0.07813045525902206
Trained batch 176 in epoch 13, gen_loss = 0.39196686354060634, disc_loss = 0.07821462079777387
Trained batch 177 in epoch 13, gen_loss = 0.3921677332915617, disc_loss = 0.07813725548827749
Trained batch 178 in epoch 13, gen_loss = 0.39232200517334753, disc_loss = 0.07777713961358176
Trained batch 179 in epoch 13, gen_loss = 0.39232825189828874, disc_loss = 0.07752367868605588
Trained batch 180 in epoch 13, gen_loss = 0.3924017718154422, disc_loss = 0.07717365130411656
Trained batch 181 in epoch 13, gen_loss = 0.3923063925006887, disc_loss = 0.07680488496527567
Trained batch 182 in epoch 13, gen_loss = 0.39203772779370916, disc_loss = 0.07654926424103031
Trained batch 183 in epoch 13, gen_loss = 0.39235177215026773, disc_loss = 0.07622194274976525
Trained batch 184 in epoch 13, gen_loss = 0.3916780623229774, disc_loss = 0.07629374137802704
Trained batch 185 in epoch 13, gen_loss = 0.39182976849617496, disc_loss = 0.07623780111191414
Trained batch 186 in epoch 13, gen_loss = 0.3916564317629299, disc_loss = 0.07600644777683332
Trained batch 187 in epoch 13, gen_loss = 0.39121272573445703, disc_loss = 0.07570987625760918
Trained batch 188 in epoch 13, gen_loss = 0.3916722739499713, disc_loss = 0.0754047519374619
Trained batch 189 in epoch 13, gen_loss = 0.39132380250253174, disc_loss = 0.07512086774957807
Trained batch 190 in epoch 13, gen_loss = 0.391341023264131, disc_loss = 0.07515416688319901
Trained batch 191 in epoch 13, gen_loss = 0.3910853136330843, disc_loss = 0.07581545629849036
Trained batch 192 in epoch 13, gen_loss = 0.3913762025882543, disc_loss = 0.07599998435362633
Trained batch 193 in epoch 13, gen_loss = 0.39166312779962403, disc_loss = 0.07564841410068353
Trained batch 194 in epoch 13, gen_loss = 0.3913807830749414, disc_loss = 0.0753423383172888
Trained batch 195 in epoch 13, gen_loss = 0.3910191015017276, disc_loss = 0.07511049027706744
Trained batch 196 in epoch 13, gen_loss = 0.390860705962641, disc_loss = 0.07486732062519656
Trained batch 197 in epoch 13, gen_loss = 0.3907264395795687, disc_loss = 0.07537991839997245
Trained batch 198 in epoch 13, gen_loss = 0.3902688325949051, disc_loss = 0.0756128673399588
Trained batch 199 in epoch 13, gen_loss = 0.39044693738222125, disc_loss = 0.07526714448817075
Trained batch 200 in epoch 13, gen_loss = 0.3901656510224983, disc_loss = 0.0754136406533902
Trained batch 201 in epoch 13, gen_loss = 0.3898200553537595, disc_loss = 0.07532656470332111
Trained batch 202 in epoch 13, gen_loss = 0.3897561837593323, disc_loss = 0.07504854899982513
Trained batch 203 in epoch 13, gen_loss = 0.38974114054558323, disc_loss = 0.07475237016949583
Trained batch 204 in epoch 13, gen_loss = 0.389849955570407, disc_loss = 0.07445865253940588
Trained batch 205 in epoch 13, gen_loss = 0.38996321946671864, disc_loss = 0.07423340337061622
Trained batch 206 in epoch 13, gen_loss = 0.3897862494855687, disc_loss = 0.07432100050385304
Trained batch 207 in epoch 13, gen_loss = 0.390290171194535, disc_loss = 0.07454851262110214
Trained batch 208 in epoch 13, gen_loss = 0.3903233465965855, disc_loss = 0.07423257089830472
Trained batch 209 in epoch 13, gen_loss = 0.39013550338290987, disc_loss = 0.07420791486899057
Trained batch 210 in epoch 13, gen_loss = 0.3904002506586048, disc_loss = 0.07391459961373235
Trained batch 211 in epoch 13, gen_loss = 0.39060618067687414, disc_loss = 0.07358976595876913
Trained batch 212 in epoch 13, gen_loss = 0.39076177684913777, disc_loss = 0.073268261528246
Trained batch 213 in epoch 13, gen_loss = 0.39094963196282073, disc_loss = 0.07297382173433065
Trained batch 214 in epoch 13, gen_loss = 0.391187506359677, disc_loss = 0.0726734074742295
Trained batch 215 in epoch 13, gen_loss = 0.39130356369747055, disc_loss = 0.07236577652791445
Trained batch 216 in epoch 13, gen_loss = 0.3909996971831344, disc_loss = 0.07205266931656457
Trained batch 217 in epoch 13, gen_loss = 0.39073974003485584, disc_loss = 0.07175074728342508
Trained batch 218 in epoch 13, gen_loss = 0.3907046662345869, disc_loss = 0.07158282681976415
Trained batch 219 in epoch 13, gen_loss = 0.3906811138445681, disc_loss = 0.07132797502827916
Trained batch 220 in epoch 13, gen_loss = 0.39026064112175646, disc_loss = 0.07111941124586497
Trained batch 221 in epoch 13, gen_loss = 0.39025937665153193, disc_loss = 0.07107269581038135
Trained batch 222 in epoch 13, gen_loss = 0.38995381828915376, disc_loss = 0.0709007429334882
Trained batch 223 in epoch 13, gen_loss = 0.39016916256930145, disc_loss = 0.07063451334501483
Trained batch 224 in epoch 13, gen_loss = 0.39014851795302496, disc_loss = 0.07049162189165752
Trained batch 225 in epoch 13, gen_loss = 0.39016091348850623, disc_loss = 0.07021184956275783
Trained batch 226 in epoch 13, gen_loss = 0.39019234983931556, disc_loss = 0.07002560665527367
Trained batch 227 in epoch 13, gen_loss = 0.390400241864355, disc_loss = 0.07107188979882681
Trained batch 228 in epoch 13, gen_loss = 0.3901119302453953, disc_loss = 0.07201815128944586
Trained batch 229 in epoch 13, gen_loss = 0.3902743013008781, disc_loss = 0.07236093874696804
Trained batch 230 in epoch 13, gen_loss = 0.39047059868321277, disc_loss = 0.07242281092290496
Trained batch 231 in epoch 13, gen_loss = 0.3900623211059077, disc_loss = 0.07242603371208854
Trained batch 232 in epoch 13, gen_loss = 0.3897981871351152, disc_loss = 0.07243286827059518
Trained batch 233 in epoch 13, gen_loss = 0.38982789371258175, disc_loss = 0.07222142110331956
Trained batch 234 in epoch 13, gen_loss = 0.3900192893565969, disc_loss = 0.07196655983620502
Trained batch 235 in epoch 13, gen_loss = 0.3899365164718385, disc_loss = 0.07183844125750712
Trained batch 236 in epoch 13, gen_loss = 0.38982690424355776, disc_loss = 0.07171427364213558
Trained batch 237 in epoch 13, gen_loss = 0.3900275999257545, disc_loss = 0.07172308063932828
Trained batch 238 in epoch 13, gen_loss = 0.3898052645527668, disc_loss = 0.07180351689146154
Trained batch 239 in epoch 13, gen_loss = 0.3899983597298463, disc_loss = 0.07169651008831958
Trained batch 240 in epoch 13, gen_loss = 0.39011047390981335, disc_loss = 0.07144484941797385
Trained batch 241 in epoch 13, gen_loss = 0.3902480629357425, disc_loss = 0.07121880475647194
Trained batch 242 in epoch 13, gen_loss = 0.3902059578846512, disc_loss = 0.07100340308537209
Trained batch 243 in epoch 13, gen_loss = 0.39050648080520944, disc_loss = 0.07099338030045638
Trained batch 244 in epoch 13, gen_loss = 0.39118038221281404, disc_loss = 0.07121916609455128
Trained batch 245 in epoch 13, gen_loss = 0.39110177755355835, disc_loss = 0.07101930111525505
Trained batch 246 in epoch 13, gen_loss = 0.39085080483664386, disc_loss = 0.07122995342440934
Trained batch 247 in epoch 13, gen_loss = 0.3910258282576838, disc_loss = 0.07180608715862036
Trained batch 248 in epoch 13, gen_loss = 0.39105614936016647, disc_loss = 0.07169013400094576
Trained batch 249 in epoch 13, gen_loss = 0.3908671832084656, disc_loss = 0.07144509372487665
Trained batch 250 in epoch 13, gen_loss = 0.3906193539440869, disc_loss = 0.07121115445022089
Trained batch 251 in epoch 13, gen_loss = 0.390469643095183, disc_loss = 0.07151708802178738
Trained batch 252 in epoch 13, gen_loss = 0.3905191423864704, disc_loss = 0.07270940611131578
Trained batch 253 in epoch 13, gen_loss = 0.3905633626960394, disc_loss = 0.07265720726174163
Trained batch 254 in epoch 13, gen_loss = 0.39021904106233635, disc_loss = 0.07257436027421671
Trained batch 255 in epoch 13, gen_loss = 0.3899646832142025, disc_loss = 0.07300377268984448
Trained batch 256 in epoch 13, gen_loss = 0.39021304400514534, disc_loss = 0.07411537680354563
Trained batch 257 in epoch 13, gen_loss = 0.39039228983627733, disc_loss = 0.07420298444150492
Trained batch 258 in epoch 13, gen_loss = 0.39031842995334315, disc_loss = 0.07456171384591853
Trained batch 259 in epoch 13, gen_loss = 0.39023946133943704, disc_loss = 0.07457341799655785
Trained batch 260 in epoch 13, gen_loss = 0.39008184079922936, disc_loss = 0.07439439001553817
Trained batch 261 in epoch 13, gen_loss = 0.39001567548012916, disc_loss = 0.07429507450122415
Trained batch 262 in epoch 13, gen_loss = 0.38994589572623656, disc_loss = 0.07410210304443828
Trained batch 263 in epoch 13, gen_loss = 0.3900921073826877, disc_loss = 0.07395263920735681
Trained batch 264 in epoch 13, gen_loss = 0.3900298200688272, disc_loss = 0.07399791972535961
Trained batch 265 in epoch 13, gen_loss = 0.3899822989128586, disc_loss = 0.07391210641235785
Trained batch 266 in epoch 13, gen_loss = 0.39015131976720546, disc_loss = 0.0742178995315725
Trained batch 267 in epoch 13, gen_loss = 0.39002452968661466, disc_loss = 0.0746660251587407
Trained batch 268 in epoch 13, gen_loss = 0.3901699094524171, disc_loss = 0.07441393714086551
Trained batch 269 in epoch 13, gen_loss = 0.39038399590386286, disc_loss = 0.07447538217357187
Trained batch 270 in epoch 13, gen_loss = 0.3904228873578385, disc_loss = 0.07453347851326379
Trained batch 271 in epoch 13, gen_loss = 0.39053683519801674, disc_loss = 0.07430917292196468
Trained batch 272 in epoch 13, gen_loss = 0.39038566115138296, disc_loss = 0.0741455515440649
Trained batch 273 in epoch 13, gen_loss = 0.39031066674820697, disc_loss = 0.07400369593010277
Trained batch 274 in epoch 13, gen_loss = 0.3903512229702689, disc_loss = 0.0744407271576876
Trained batch 275 in epoch 13, gen_loss = 0.3899608616163765, disc_loss = 0.07561354677064641
Trained batch 276 in epoch 13, gen_loss = 0.3899524205428168, disc_loss = 0.07577766045517816
Trained batch 277 in epoch 13, gen_loss = 0.38989493100763223, disc_loss = 0.07599892223876961
Trained batch 278 in epoch 13, gen_loss = 0.38976217512588773, disc_loss = 0.07602197933761824
Trained batch 279 in epoch 13, gen_loss = 0.3895706814314638, disc_loss = 0.0759985811792181
Trained batch 280 in epoch 13, gen_loss = 0.38953506638995267, disc_loss = 0.07587596824975996
Trained batch 281 in epoch 13, gen_loss = 0.3894106418105727, disc_loss = 0.07579239955046445
Trained batch 282 in epoch 13, gen_loss = 0.38954920903532747, disc_loss = 0.07565393103220806
Trained batch 283 in epoch 13, gen_loss = 0.389421316309714, disc_loss = 0.07566020083384142
Trained batch 284 in epoch 13, gen_loss = 0.38967517718934175, disc_loss = 0.07549650332351264
Trained batch 285 in epoch 13, gen_loss = 0.3895585199336072, disc_loss = 0.07527378365443042
Trained batch 286 in epoch 13, gen_loss = 0.38944023847579956, disc_loss = 0.07505914019680344
Trained batch 287 in epoch 13, gen_loss = 0.3892811554380589, disc_loss = 0.07493965587572246
Trained batch 288 in epoch 13, gen_loss = 0.38933015746228833, disc_loss = 0.0747374347733353
Trained batch 289 in epoch 13, gen_loss = 0.389110984165093, disc_loss = 0.07488662960039902
Trained batch 290 in epoch 13, gen_loss = 0.3889159260132059, disc_loss = 0.07600925017717931
Trained batch 291 in epoch 13, gen_loss = 0.38908746318049625, disc_loss = 0.0759309366431521
Trained batch 292 in epoch 13, gen_loss = 0.38919285438166545, disc_loss = 0.07571907175399693
Trained batch 293 in epoch 13, gen_loss = 0.38907961729837925, disc_loss = 0.07565468195414006
Trained batch 294 in epoch 13, gen_loss = 0.38905859044042684, disc_loss = 0.07556256915016447
Trained batch 295 in epoch 13, gen_loss = 0.3889234860402507, disc_loss = 0.07542236571395267
Trained batch 296 in epoch 13, gen_loss = 0.38910169523171706, disc_loss = 0.07527407817385764
Trained batch 297 in epoch 13, gen_loss = 0.38902293915716596, disc_loss = 0.0751446035156189
Trained batch 298 in epoch 13, gen_loss = 0.38918662858647246, disc_loss = 0.07510897050452821
Trained batch 299 in epoch 13, gen_loss = 0.38899245431025825, disc_loss = 0.0754679352712507
Trained batch 300 in epoch 13, gen_loss = 0.3891558915475674, disc_loss = 0.07532110420888
Trained batch 301 in epoch 13, gen_loss = 0.3892295388196478, disc_loss = 0.07519410221701772
Trained batch 302 in epoch 13, gen_loss = 0.3891757744373662, disc_loss = 0.07498982219062376
Trained batch 303 in epoch 13, gen_loss = 0.3893138879027806, disc_loss = 0.07483342724184408
Trained batch 304 in epoch 13, gen_loss = 0.3894873749037258, disc_loss = 0.07461937937854987
Trained batch 305 in epoch 13, gen_loss = 0.38958905403520544, disc_loss = 0.07440870277297507
Trained batch 306 in epoch 13, gen_loss = 0.3893527343917747, disc_loss = 0.0744019516482828
Trained batch 307 in epoch 13, gen_loss = 0.3892186143762105, disc_loss = 0.0743294141766337
Trained batch 308 in epoch 13, gen_loss = 0.38941237822319696, disc_loss = 0.07416009955548208
Trained batch 309 in epoch 13, gen_loss = 0.3894880808168842, disc_loss = 0.07421393473332207
Trained batch 310 in epoch 13, gen_loss = 0.38941114853432707, disc_loss = 0.0743478975210854
Trained batch 311 in epoch 13, gen_loss = 0.3897335533148203, disc_loss = 0.07456674003669132
Trained batch 312 in epoch 13, gen_loss = 0.3896966093835739, disc_loss = 0.07436514510877264
Trained batch 313 in epoch 13, gen_loss = 0.3897909504023327, disc_loss = 0.07427151498361045
Trained batch 314 in epoch 13, gen_loss = 0.39004027493416316, disc_loss = 0.07408501220393986
Trained batch 315 in epoch 13, gen_loss = 0.3899759169243559, disc_loss = 0.07397465547694106
Trained batch 316 in epoch 13, gen_loss = 0.3898206305240607, disc_loss = 0.07397411230875162
Trained batch 317 in epoch 13, gen_loss = 0.3899270546323848, disc_loss = 0.07378556310644362
Trained batch 318 in epoch 13, gen_loss = 0.39000499117710746, disc_loss = 0.07381427900713859
Trained batch 319 in epoch 13, gen_loss = 0.3899715348146856, disc_loss = 0.0739282342910883
Trained batch 320 in epoch 13, gen_loss = 0.3899931393308432, disc_loss = 0.07372740541680534
Trained batch 321 in epoch 13, gen_loss = 0.3900706907792121, disc_loss = 0.07385854017400177
Trained batch 322 in epoch 13, gen_loss = 0.38984359519400463, disc_loss = 0.07494984195068848
Trained batch 323 in epoch 13, gen_loss = 0.38975223889689387, disc_loss = 0.07488422433092592
Trained batch 324 in epoch 13, gen_loss = 0.39000189441900984, disc_loss = 0.07506710562998285
Trained batch 325 in epoch 13, gen_loss = 0.39018615202669715, disc_loss = 0.0749151892545833
Trained batch 326 in epoch 13, gen_loss = 0.3902634390450399, disc_loss = 0.07495540711282545
Trained batch 327 in epoch 13, gen_loss = 0.3902054192816339, disc_loss = 0.07486179885993961
Trained batch 328 in epoch 13, gen_loss = 0.390647666613744, disc_loss = 0.07513084144141853
Trained batch 329 in epoch 13, gen_loss = 0.3904526541630427, disc_loss = 0.07526541326731218
Trained batch 330 in epoch 13, gen_loss = 0.3903800512908809, disc_loss = 0.07509336516323001
Trained batch 331 in epoch 13, gen_loss = 0.39060614141355077, disc_loss = 0.07495054690004607
Trained batch 332 in epoch 13, gen_loss = 0.3906755374000595, disc_loss = 0.07505079897892503
Trained batch 333 in epoch 13, gen_loss = 0.39089435321128296, disc_loss = 0.0756562493147585
Trained batch 334 in epoch 13, gen_loss = 0.39081176047894495, disc_loss = 0.07585021288398264
Trained batch 335 in epoch 13, gen_loss = 0.3909981491132861, disc_loss = 0.07568999898060047
Trained batch 336 in epoch 13, gen_loss = 0.3909848622469237, disc_loss = 0.0756610042238691
Trained batch 337 in epoch 13, gen_loss = 0.3910231937670849, disc_loss = 0.07555006426130835
Trained batch 338 in epoch 13, gen_loss = 0.3908527837214568, disc_loss = 0.07554301878184652
Trained batch 339 in epoch 13, gen_loss = 0.3908583057277343, disc_loss = 0.0755422064637327
Trained batch 340 in epoch 13, gen_loss = 0.39062108715608324, disc_loss = 0.07534940109405219
Trained batch 341 in epoch 13, gen_loss = 0.3907649585029535, disc_loss = 0.07517960273976607
Trained batch 342 in epoch 13, gen_loss = 0.3907077481899595, disc_loss = 0.07515602192431471
Trained batch 343 in epoch 13, gen_loss = 0.39095692752405653, disc_loss = 0.07573493977949067
Trained batch 344 in epoch 13, gen_loss = 0.39090788278026856, disc_loss = 0.07563533816027684
Trained batch 345 in epoch 13, gen_loss = 0.3907449810491132, disc_loss = 0.07558078885837485
Trained batch 346 in epoch 13, gen_loss = 0.390805386157132, disc_loss = 0.0755962181785372
Trained batch 347 in epoch 13, gen_loss = 0.39078400549532355, disc_loss = 0.07549376360370895
Trained batch 348 in epoch 13, gen_loss = 0.39083046583528164, disc_loss = 0.07531465393461735
Trained batch 349 in epoch 13, gen_loss = 0.39098459243774414, disc_loss = 0.07513277734895903
Trained batch 350 in epoch 13, gen_loss = 0.39094802278738755, disc_loss = 0.07498337560733966
Trained batch 351 in epoch 13, gen_loss = 0.39097065859558905, disc_loss = 0.0748648340271426
Trained batch 352 in epoch 13, gen_loss = 0.3910032335151694, disc_loss = 0.07486169104445883
Trained batch 353 in epoch 13, gen_loss = 0.39117445413675683, disc_loss = 0.07499241152131078
Trained batch 354 in epoch 13, gen_loss = 0.3910276564913736, disc_loss = 0.0748112059618071
Trained batch 355 in epoch 13, gen_loss = 0.3909149558356639, disc_loss = 0.07486967259123294
Trained batch 356 in epoch 13, gen_loss = 0.3909588172322228, disc_loss = 0.07475773554102254
Trained batch 357 in epoch 13, gen_loss = 0.39105700197832544, disc_loss = 0.07459677034838115
Trained batch 358 in epoch 13, gen_loss = 0.3910020849664895, disc_loss = 0.07456427900909257
Trained batch 359 in epoch 13, gen_loss = 0.3909840957985984, disc_loss = 0.07439855712647032
Trained batch 360 in epoch 13, gen_loss = 0.3907238928565028, disc_loss = 0.07430632008817512
Trained batch 361 in epoch 13, gen_loss = 0.39084698687930136, disc_loss = 0.074332364344743
Trained batch 362 in epoch 13, gen_loss = 0.3909644775154177, disc_loss = 0.07428922046350506
Trained batch 363 in epoch 13, gen_loss = 0.3912407983462889, disc_loss = 0.07460636027275001
Trained batch 364 in epoch 13, gen_loss = 0.39130055063391384, disc_loss = 0.0745904249470834
Trained batch 365 in epoch 13, gen_loss = 0.391509104377585, disc_loss = 0.07443212820446027
Trained batch 366 in epoch 13, gen_loss = 0.39159495799677896, disc_loss = 0.0742716772332077
Trained batch 367 in epoch 13, gen_loss = 0.3917711397390003, disc_loss = 0.07411149310317579
Trained batch 368 in epoch 13, gen_loss = 0.3918493638032174, disc_loss = 0.0739334399438385
Trained batch 369 in epoch 13, gen_loss = 0.39191901506604376, disc_loss = 0.07376277751188624
Trained batch 370 in epoch 13, gen_loss = 0.3917177892277504, disc_loss = 0.07368429642135524
Trained batch 371 in epoch 13, gen_loss = 0.3919005108776913, disc_loss = 0.07359868919311632
Trained batch 372 in epoch 13, gen_loss = 0.3918886694447924, disc_loss = 0.07357120454366302
Trained batch 373 in epoch 13, gen_loss = 0.3919270101556166, disc_loss = 0.07344606969341197
Trained batch 374 in epoch 13, gen_loss = 0.3916385610898336, disc_loss = 0.07330861715351542
Trained batch 375 in epoch 13, gen_loss = 0.3916254976486906, disc_loss = 0.07340109805908411
Trained batch 376 in epoch 13, gen_loss = 0.39161722753345174, disc_loss = 0.07427965248724945
Trained batch 377 in epoch 13, gen_loss = 0.3915101275557563, disc_loss = 0.0741900994513854
Trained batch 378 in epoch 13, gen_loss = 0.39143675180412535, disc_loss = 0.07451884307846977
Trained batch 379 in epoch 13, gen_loss = 0.39141915832695207, disc_loss = 0.07447352982738889
Trained batch 380 in epoch 13, gen_loss = 0.39123492994959275, disc_loss = 0.07450116058967989
Trained batch 381 in epoch 13, gen_loss = 0.39137086529694304, disc_loss = 0.07445244246201482
Trained batch 382 in epoch 13, gen_loss = 0.3916509181027624, disc_loss = 0.0744108655246816
Trained batch 383 in epoch 13, gen_loss = 0.39143815357238054, disc_loss = 0.07507941090807435
Trained batch 384 in epoch 13, gen_loss = 0.3912644344490844, disc_loss = 0.07510890820269267
Trained batch 385 in epoch 13, gen_loss = 0.39083873592510127, disc_loss = 0.07519505600387066
Trained batch 386 in epoch 13, gen_loss = 0.39098251766936726, disc_loss = 0.07549908713772123
Trained batch 387 in epoch 13, gen_loss = 0.390734968034877, disc_loss = 0.07588549494892166
Trained batch 388 in epoch 13, gen_loss = 0.3908509068133592, disc_loss = 0.0757897081737021
Trained batch 389 in epoch 13, gen_loss = 0.39092990297537583, disc_loss = 0.07579997130192052
Trained batch 390 in epoch 13, gen_loss = 0.3907962584739451, disc_loss = 0.0759159407144903
Trained batch 391 in epoch 13, gen_loss = 0.39086269070299307, disc_loss = 0.07600810922259389
Trained batch 392 in epoch 13, gen_loss = 0.39063211153178423, disc_loss = 0.076097889558078
Trained batch 393 in epoch 13, gen_loss = 0.39089939088990844, disc_loss = 0.07619517799443211
Trained batch 394 in epoch 13, gen_loss = 0.39086755423606195, disc_loss = 0.07616083678447559
Trained batch 395 in epoch 13, gen_loss = 0.3909250417291516, disc_loss = 0.07598829525640478
Trained batch 396 in epoch 13, gen_loss = 0.3909967351019833, disc_loss = 0.07582695160872803
Trained batch 397 in epoch 13, gen_loss = 0.39091273251190856, disc_loss = 0.07586765622406562
Trained batch 398 in epoch 13, gen_loss = 0.3908083910930127, disc_loss = 0.07605719771632985
Trained batch 399 in epoch 13, gen_loss = 0.3907934761047363, disc_loss = 0.0760349846992176
Trained batch 400 in epoch 13, gen_loss = 0.39053309127279645, disc_loss = 0.07591739844442566
Trained batch 401 in epoch 13, gen_loss = 0.39067821805156877, disc_loss = 0.07576136126655585
Trained batch 402 in epoch 13, gen_loss = 0.3906779443803555, disc_loss = 0.07564674035551272
Trained batch 403 in epoch 13, gen_loss = 0.39056224154658836, disc_loss = 0.07557779835135962
Trained batch 404 in epoch 13, gen_loss = 0.3905260403951009, disc_loss = 0.0755225574862166
Trained batch 405 in epoch 13, gen_loss = 0.3906950856664498, disc_loss = 0.07541136535026793
Trained batch 406 in epoch 13, gen_loss = 0.3907386916861194, disc_loss = 0.07564718874528345
Trained batch 407 in epoch 13, gen_loss = 0.39074719996721136, disc_loss = 0.07631486474979195
Trained batch 408 in epoch 13, gen_loss = 0.39057353342949325, disc_loss = 0.07622265214246213
Trained batch 409 in epoch 13, gen_loss = 0.39081834925384057, disc_loss = 0.07671715627742431
Trained batch 410 in epoch 13, gen_loss = 0.3907698759052295, disc_loss = 0.07668167759308596
Trained batch 411 in epoch 13, gen_loss = 0.3906463540873481, disc_loss = 0.07667068421537762
Trained batch 412 in epoch 13, gen_loss = 0.390844695576744, disc_loss = 0.07656644451258293
Trained batch 413 in epoch 13, gen_loss = 0.3909616019702764, disc_loss = 0.07640087770878513
Trained batch 414 in epoch 13, gen_loss = 0.390966716444636, disc_loss = 0.07630950879328043
Trained batch 415 in epoch 13, gen_loss = 0.3907390756245989, disc_loss = 0.07639210620030869
Trained batch 416 in epoch 13, gen_loss = 0.39089092197749825, disc_loss = 0.07638821490801317
Trained batch 417 in epoch 13, gen_loss = 0.3907595283249349, disc_loss = 0.07635226026600735
Trained batch 418 in epoch 13, gen_loss = 0.39091427862501943, disc_loss = 0.07634307812957142
Trained batch 419 in epoch 13, gen_loss = 0.39085187841029395, disc_loss = 0.07623718339129396
Trained batch 420 in epoch 13, gen_loss = 0.3910426687174908, disc_loss = 0.07628887335077424
Trained batch 421 in epoch 13, gen_loss = 0.391275166900237, disc_loss = 0.07634743086671483
Trained batch 422 in epoch 13, gen_loss = 0.3914258664663238, disc_loss = 0.07634463774956252
Trained batch 423 in epoch 13, gen_loss = 0.3915186341641084, disc_loss = 0.07626938084382037
Trained batch 424 in epoch 13, gen_loss = 0.3913117247469285, disc_loss = 0.07662618685185033
Trained batch 425 in epoch 13, gen_loss = 0.3914942056500296, disc_loss = 0.07695412669798683
Trained batch 426 in epoch 13, gen_loss = 0.39149775263576375, disc_loss = 0.07679993406143171
Trained batch 427 in epoch 13, gen_loss = 0.39129980521224367, disc_loss = 0.07678370971437196
Trained batch 428 in epoch 13, gen_loss = 0.39126574131714437, disc_loss = 0.07672986452357022
Trained batch 429 in epoch 13, gen_loss = 0.39123059830000234, disc_loss = 0.07665452784642057
Trained batch 430 in epoch 13, gen_loss = 0.39137078175135387, disc_loss = 0.07657097604043626
Trained batch 431 in epoch 13, gen_loss = 0.3915321833143632, disc_loss = 0.07643351339868752
Trained batch 432 in epoch 13, gen_loss = 0.39158991929014614, disc_loss = 0.07656747596467443
Trained batch 433 in epoch 13, gen_loss = 0.39142607949021774, disc_loss = 0.07662365324516278
Trained batch 434 in epoch 13, gen_loss = 0.3914101942517291, disc_loss = 0.07655797759927381
Trained batch 435 in epoch 13, gen_loss = 0.39145224445730176, disc_loss = 0.07684371980876926
Trained batch 436 in epoch 13, gen_loss = 0.3912190871326001, disc_loss = 0.07734880395110023
Trained batch 437 in epoch 13, gen_loss = 0.39130089619116154, disc_loss = 0.07752066120807269
Trained batch 438 in epoch 13, gen_loss = 0.39128692213929595, disc_loss = 0.07748832431322723
Trained batch 439 in epoch 13, gen_loss = 0.39122316634113136, disc_loss = 0.07749722513518381
Trained batch 440 in epoch 13, gen_loss = 0.3912693313460231, disc_loss = 0.0773614373241811
Trained batch 441 in epoch 13, gen_loss = 0.3914103270655844, disc_loss = 0.07729360173726076
Trained batch 442 in epoch 13, gen_loss = 0.39127701527647185, disc_loss = 0.07752733089715141
Trained batch 443 in epoch 13, gen_loss = 0.39136735202224404, disc_loss = 0.07789607700862426
Trained batch 444 in epoch 13, gen_loss = 0.39138426231534296, disc_loss = 0.0777615276353664
Trained batch 445 in epoch 13, gen_loss = 0.39133563210076816, disc_loss = 0.07798267644412414
Trained batch 446 in epoch 13, gen_loss = 0.39135197105023684, disc_loss = 0.07837797962108281
Trained batch 447 in epoch 13, gen_loss = 0.3911397402573909, disc_loss = 0.07847900055743853
Trained batch 448 in epoch 13, gen_loss = 0.39106955281344713, disc_loss = 0.07850220712225361
Trained batch 449 in epoch 13, gen_loss = 0.39092149297396345, disc_loss = 0.07839730081355406
Trained batch 450 in epoch 13, gen_loss = 0.39078710143952045, disc_loss = 0.07839409602979433
Trained batch 451 in epoch 13, gen_loss = 0.3910811860608844, disc_loss = 0.07840140184399927
Trained batch 452 in epoch 13, gen_loss = 0.39104287849356795, disc_loss = 0.07848719414426364
Trained batch 453 in epoch 13, gen_loss = 0.390729822842035, disc_loss = 0.07924291111491949
Trained batch 454 in epoch 13, gen_loss = 0.39065422939730216, disc_loss = 0.07917595562105487
Trained batch 455 in epoch 13, gen_loss = 0.3905269811420064, disc_loss = 0.07923690906803434
Trained batch 456 in epoch 13, gen_loss = 0.3903981039638853, disc_loss = 0.07927895342947455
Trained batch 457 in epoch 13, gen_loss = 0.3902673733676885, disc_loss = 0.07955041512192174
Trained batch 458 in epoch 13, gen_loss = 0.39016036536698767, disc_loss = 0.07947561246990216
Trained batch 459 in epoch 13, gen_loss = 0.39031834064618404, disc_loss = 0.07996947420254835
Trained batch 460 in epoch 13, gen_loss = 0.39019228178611803, disc_loss = 0.08012429265903386
Trained batch 461 in epoch 13, gen_loss = 0.39018311657946864, disc_loss = 0.07999721152437811
Trained batch 462 in epoch 13, gen_loss = 0.38968653214158044, disc_loss = 0.08079190982594185
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.38074731826782227, disc_loss = 0.030562084168195724
Trained batch 1 in epoch 14, gen_loss = 0.3869492709636688, disc_loss = 0.027985451743006706
Trained batch 2 in epoch 14, gen_loss = 0.38746410608291626, disc_loss = 0.042899624754985176
Trained batch 3 in epoch 14, gen_loss = 0.3754470646381378, disc_loss = 0.06619633082300425
Trained batch 4 in epoch 14, gen_loss = 0.3739651024341583, disc_loss = 0.07874387875199318
Trained batch 5 in epoch 14, gen_loss = 0.36220472554365796, disc_loss = 0.0785385463386774
Trained batch 6 in epoch 14, gen_loss = 0.35867961815425325, disc_loss = 0.07525979567851339
Trained batch 7 in epoch 14, gen_loss = 0.36226528882980347, disc_loss = 0.07436198415234685
Trained batch 8 in epoch 14, gen_loss = 0.36031372017330593, disc_loss = 0.069668374541733
Trained batch 9 in epoch 14, gen_loss = 0.3608699917793274, disc_loss = 0.06721815504133702
Trained batch 10 in epoch 14, gen_loss = 0.3620897992090745, disc_loss = 0.07038649544119835
Trained batch 11 in epoch 14, gen_loss = 0.36104919761419296, disc_loss = 0.07431965414434671
Trained batch 12 in epoch 14, gen_loss = 0.3633975042746617, disc_loss = 0.07683337279237233
Trained batch 13 in epoch 14, gen_loss = 0.3685870149305889, disc_loss = 0.07366672291287354
Trained batch 14 in epoch 14, gen_loss = 0.3678202191988627, disc_loss = 0.07138889282941818
Trained batch 15 in epoch 14, gen_loss = 0.36751815117895603, disc_loss = 0.06976608536206186
Trained batch 16 in epoch 14, gen_loss = 0.3696664869785309, disc_loss = 0.0674621323671411
Trained batch 17 in epoch 14, gen_loss = 0.3688135991493861, disc_loss = 0.06655312484751146
Trained batch 18 in epoch 14, gen_loss = 0.36938590281888056, disc_loss = 0.06519775651395321
Trained batch 19 in epoch 14, gen_loss = 0.36797637343406675, disc_loss = 0.06703390264883638
Trained batch 20 in epoch 14, gen_loss = 0.3673653134277889, disc_loss = 0.07519930184242271
Trained batch 21 in epoch 14, gen_loss = 0.37024102292277594, disc_loss = 0.07579591709443113
Trained batch 22 in epoch 14, gen_loss = 0.37432056147119275, disc_loss = 0.07361400265084661
Trained batch 23 in epoch 14, gen_loss = 0.377377413213253, disc_loss = 0.07149224627452593
Trained batch 24 in epoch 14, gen_loss = 0.3766869127750397, disc_loss = 0.07000764019787312
Trained batch 25 in epoch 14, gen_loss = 0.3773188086656424, disc_loss = 0.0682002126884002
Trained batch 26 in epoch 14, gen_loss = 0.37851661995605185, disc_loss = 0.0662975741757287
Trained batch 27 in epoch 14, gen_loss = 0.37794735708406996, disc_loss = 0.06430081191605755
Trained batch 28 in epoch 14, gen_loss = 0.37597533238345177, disc_loss = 0.06231254315132211
Trained batch 29 in epoch 14, gen_loss = 0.37586283683776855, disc_loss = 0.06108638322912156
Trained batch 30 in epoch 14, gen_loss = 0.3764980339234875, disc_loss = 0.06040390702565351
Trained batch 31 in epoch 14, gen_loss = 0.37826635129749775, disc_loss = 0.059698635843233205
Trained batch 32 in epoch 14, gen_loss = 0.37879800615888654, disc_loss = 0.05978626702827486
Trained batch 33 in epoch 14, gen_loss = 0.3803190737962723, disc_loss = 0.0625864623580128
Trained batch 34 in epoch 14, gen_loss = 0.38034265552248275, disc_loss = 0.06733821046405605
Trained batch 35 in epoch 14, gen_loss = 0.3820483328567611, disc_loss = 0.06887722130502677
Trained batch 36 in epoch 14, gen_loss = 0.38347301612029205, disc_loss = 0.06731860517096278
Trained batch 37 in epoch 14, gen_loss = 0.3839779119742544, disc_loss = 0.06591205074647932
Trained batch 38 in epoch 14, gen_loss = 0.3826192900156363, disc_loss = 0.06586292645153709
Trained batch 39 in epoch 14, gen_loss = 0.38550354540348053, disc_loss = 0.06524159220280126
Trained batch 40 in epoch 14, gen_loss = 0.38435795467074324, disc_loss = 0.06459763447367926
Trained batch 41 in epoch 14, gen_loss = 0.3836720557439895, disc_loss = 0.06467010330275766
Trained batch 42 in epoch 14, gen_loss = 0.38421127269434374, disc_loss = 0.06422819718068769
Trained batch 43 in epoch 14, gen_loss = 0.38474151356653735, disc_loss = 0.06651286544828591
Trained batch 44 in epoch 14, gen_loss = 0.384062612719006, disc_loss = 0.07299797834000654
Trained batch 45 in epoch 14, gen_loss = 0.38373494213042053, disc_loss = 0.07496020231274483
Trained batch 46 in epoch 14, gen_loss = 0.38535597222916623, disc_loss = 0.07388768088508477
Trained batch 47 in epoch 14, gen_loss = 0.3824556351949771, disc_loss = 0.07470086446846835
Trained batch 48 in epoch 14, gen_loss = 0.38254132745217306, disc_loss = 0.07363604219174202
Trained batch 49 in epoch 14, gen_loss = 0.3831051415205002, disc_loss = 0.07450322327204048
Trained batch 50 in epoch 14, gen_loss = 0.38081448744325075, disc_loss = 0.07807966362794533
Trained batch 51 in epoch 14, gen_loss = 0.38051560234565, disc_loss = 0.07728017419755745
Trained batch 52 in epoch 14, gen_loss = 0.3809078302023546, disc_loss = 0.07621340971123779
Trained batch 53 in epoch 14, gen_loss = 0.38124910328123307, disc_loss = 0.07571284415165859
Trained batch 54 in epoch 14, gen_loss = 0.38103110140020197, disc_loss = 0.07575690120627934
Trained batch 55 in epoch 14, gen_loss = 0.38123956163014683, disc_loss = 0.07675246013760832
Trained batch 56 in epoch 14, gen_loss = 0.3812108217624196, disc_loss = 0.07939166324866707
Trained batch 57 in epoch 14, gen_loss = 0.38170793652534485, disc_loss = 0.07880826144286528
Trained batch 58 in epoch 14, gen_loss = 0.3816325068473816, disc_loss = 0.07856437833032619
Trained batch 59 in epoch 14, gen_loss = 0.3798554494976997, disc_loss = 0.07756001695524901
Trained batch 60 in epoch 14, gen_loss = 0.37961604849236913, disc_loss = 0.07668853478628349
Trained batch 61 in epoch 14, gen_loss = 0.37973498577071774, disc_loss = 0.076356761104938
Trained batch 62 in epoch 14, gen_loss = 0.37999008950733004, disc_loss = 0.07699730123821942
Trained batch 63 in epoch 14, gen_loss = 0.3795733591541648, disc_loss = 0.0771422084144433
Trained batch 64 in epoch 14, gen_loss = 0.38091588478821975, disc_loss = 0.07642891393401302
Trained batch 65 in epoch 14, gen_loss = 0.38003366914662445, disc_loss = 0.07580953360196542
Trained batch 66 in epoch 14, gen_loss = 0.37878526502580784, disc_loss = 0.07595182430527325
Trained batch 67 in epoch 14, gen_loss = 0.378933162373655, disc_loss = 0.0749652224853087
Trained batch 68 in epoch 14, gen_loss = 0.3786534977995831, disc_loss = 0.07540590825585136
Trained batch 69 in epoch 14, gen_loss = 0.37935735753604344, disc_loss = 0.07679837986693851
Trained batch 70 in epoch 14, gen_loss = 0.3800106665617983, disc_loss = 0.07599561784127859
Trained batch 71 in epoch 14, gen_loss = 0.38134313374757767, disc_loss = 0.075327973081989
Trained batch 72 in epoch 14, gen_loss = 0.3814942436675503, disc_loss = 0.07545559801646087
Trained batch 73 in epoch 14, gen_loss = 0.382065414174183, disc_loss = 0.07482950393790128
Trained batch 74 in epoch 14, gen_loss = 0.381586678425471, disc_loss = 0.07398494747156899
Trained batch 75 in epoch 14, gen_loss = 0.3816542433280694, disc_loss = 0.07311307947077837
Trained batch 76 in epoch 14, gen_loss = 0.3816177392160738, disc_loss = 0.07269868316951317
Trained batch 77 in epoch 14, gen_loss = 0.3821961203446755, disc_loss = 0.07248666624013239
Trained batch 78 in epoch 14, gen_loss = 0.38338314468347573, disc_loss = 0.07238097026166093
Trained batch 79 in epoch 14, gen_loss = 0.3835233561694622, disc_loss = 0.07168234721175396
Trained batch 80 in epoch 14, gen_loss = 0.3840605480435454, disc_loss = 0.07095256279349144
Trained batch 81 in epoch 14, gen_loss = 0.3851114704114635, disc_loss = 0.07089752710151781
Trained batch 82 in epoch 14, gen_loss = 0.38467793292309865, disc_loss = 0.07112129640215671
Trained batch 83 in epoch 14, gen_loss = 0.3850184753537178, disc_loss = 0.07052076370122709
Trained batch 84 in epoch 14, gen_loss = 0.3857248762074639, disc_loss = 0.06979343170738396
Trained batch 85 in epoch 14, gen_loss = 0.38554661807625795, disc_loss = 0.06923092137697305
Trained batch 86 in epoch 14, gen_loss = 0.38614509777091016, disc_loss = 0.06874720153302469
Trained batch 87 in epoch 14, gen_loss = 0.3860120705582879, disc_loss = 0.06816769468026575
Trained batch 88 in epoch 14, gen_loss = 0.3854612721486038, disc_loss = 0.06762463030708807
Trained batch 89 in epoch 14, gen_loss = 0.38541170292430454, disc_loss = 0.06855317876260314
Trained batch 90 in epoch 14, gen_loss = 0.38696548964951066, disc_loss = 0.0703224345765353
Trained batch 91 in epoch 14, gen_loss = 0.3874843962814497, disc_loss = 0.06973626169517798
Trained batch 92 in epoch 14, gen_loss = 0.38757901069938494, disc_loss = 0.06938999022547436
Trained batch 93 in epoch 14, gen_loss = 0.38726895033045017, disc_loss = 0.06884807001977683
Trained batch 94 in epoch 14, gen_loss = 0.3873374716231697, disc_loss = 0.06897756789173735
Trained batch 95 in epoch 14, gen_loss = 0.3875966363896926, disc_loss = 0.06889168272512809
Trained batch 96 in epoch 14, gen_loss = 0.38757749992547574, disc_loss = 0.06860210357195477
Trained batch 97 in epoch 14, gen_loss = 0.3883262027283104, disc_loss = 0.068810896705646
Trained batch 98 in epoch 14, gen_loss = 0.388737751678987, disc_loss = 0.06871049213834633
Trained batch 99 in epoch 14, gen_loss = 0.38934435427188874, disc_loss = 0.06822051758412272
Trained batch 100 in epoch 14, gen_loss = 0.38904516266124084, disc_loss = 0.06785875000520655
Trained batch 101 in epoch 14, gen_loss = 0.38887564516534995, disc_loss = 0.06741119419480217
Trained batch 102 in epoch 14, gen_loss = 0.38886521597510404, disc_loss = 0.06752265391654326
Trained batch 103 in epoch 14, gen_loss = 0.38930651574180675, disc_loss = 0.06809422927639949
Trained batch 104 in epoch 14, gen_loss = 0.3888404701437269, disc_loss = 0.06802255396420757
Trained batch 105 in epoch 14, gen_loss = 0.38964084184394693, disc_loss = 0.06750253070022841
Trained batch 106 in epoch 14, gen_loss = 0.3901920170984536, disc_loss = 0.06750417864994607
Trained batch 107 in epoch 14, gen_loss = 0.3900680735155388, disc_loss = 0.06797940755280217
Trained batch 108 in epoch 14, gen_loss = 0.39066152780427843, disc_loss = 0.06995069764024757
Trained batch 109 in epoch 14, gen_loss = 0.3899366015737707, disc_loss = 0.07182852004824036
Trained batch 110 in epoch 14, gen_loss = 0.3896336123213038, disc_loss = 0.07130132621858974
Trained batch 111 in epoch 14, gen_loss = 0.39047656234885963, disc_loss = 0.0719459529791493
Trained batch 112 in epoch 14, gen_loss = 0.38971759523965616, disc_loss = 0.07258758192420402
Trained batch 113 in epoch 14, gen_loss = 0.38948165037130056, disc_loss = 0.0724766036422041
Trained batch 114 in epoch 14, gen_loss = 0.38890084080074144, disc_loss = 0.07232657511840047
Trained batch 115 in epoch 14, gen_loss = 0.38946138836186506, disc_loss = 0.07187100523552889
Trained batch 116 in epoch 14, gen_loss = 0.3887169086016141, disc_loss = 0.07148641530567637
Trained batch 117 in epoch 14, gen_loss = 0.389116444577605, disc_loss = 0.07111842290624597
Trained batch 118 in epoch 14, gen_loss = 0.38872575183876423, disc_loss = 0.07112117948699273
Trained batch 119 in epoch 14, gen_loss = 0.38903362130125363, disc_loss = 0.07077011797809973
Trained batch 120 in epoch 14, gen_loss = 0.389067948603433, disc_loss = 0.07051127157289504
Trained batch 121 in epoch 14, gen_loss = 0.38895851056106756, disc_loss = 0.07020502946278477
Trained batch 122 in epoch 14, gen_loss = 0.389389979887784, disc_loss = 0.06987258273638725
Trained batch 123 in epoch 14, gen_loss = 0.3889279855835822, disc_loss = 0.06969166192181048
Trained batch 124 in epoch 14, gen_loss = 0.3891397249698639, disc_loss = 0.06924933286383748
Trained batch 125 in epoch 14, gen_loss = 0.38961323480757454, disc_loss = 0.068880008640773
Trained batch 126 in epoch 14, gen_loss = 0.3895891630274104, disc_loss = 0.06851084291656304
Trained batch 127 in epoch 14, gen_loss = 0.3897488806396723, disc_loss = 0.06844334966808674
Trained batch 128 in epoch 14, gen_loss = 0.390628362810889, disc_loss = 0.06858223144239349
Trained batch 129 in epoch 14, gen_loss = 0.3905517949507787, disc_loss = 0.07009689187845931
Trained batch 130 in epoch 14, gen_loss = 0.3908732633554298, disc_loss = 0.07011460978182331
Trained batch 131 in epoch 14, gen_loss = 0.39073300632563507, disc_loss = 0.06981282889010441
Trained batch 132 in epoch 14, gen_loss = 0.391069868005308, disc_loss = 0.06968339061000406
Trained batch 133 in epoch 14, gen_loss = 0.3913319657987623, disc_loss = 0.06951125457173964
Trained batch 134 in epoch 14, gen_loss = 0.3918335799817686, disc_loss = 0.06971309346802257
Trained batch 135 in epoch 14, gen_loss = 0.3916775956749916, disc_loss = 0.06951881733188844
Trained batch 136 in epoch 14, gen_loss = 0.39151031126941205, disc_loss = 0.06928377249448077
Trained batch 137 in epoch 14, gen_loss = 0.3917236220145571, disc_loss = 0.07037356511041847
Trained batch 138 in epoch 14, gen_loss = 0.39114626534551167, disc_loss = 0.07107587559684682
Trained batch 139 in epoch 14, gen_loss = 0.39149738528898786, disc_loss = 0.07100081027685
Trained batch 140 in epoch 14, gen_loss = 0.3915442074021549, disc_loss = 0.07057196416079681
Trained batch 141 in epoch 14, gen_loss = 0.3914403791578723, disc_loss = 0.07018513645989899
Trained batch 142 in epoch 14, gen_loss = 0.391422622895741, disc_loss = 0.06982864943899579
Trained batch 143 in epoch 14, gen_loss = 0.3911693714972999, disc_loss = 0.06953113984329523
Trained batch 144 in epoch 14, gen_loss = 0.3913153617546476, disc_loss = 0.06919587811069755
Trained batch 145 in epoch 14, gen_loss = 0.39076906340579465, disc_loss = 0.0691839240344675
Trained batch 146 in epoch 14, gen_loss = 0.3906446514891929, disc_loss = 0.06955981712319514
Trained batch 147 in epoch 14, gen_loss = 0.39057233426216487, disc_loss = 0.06969629914336209
Trained batch 148 in epoch 14, gen_loss = 0.3908162703050063, disc_loss = 0.06958836858667083
Trained batch 149 in epoch 14, gen_loss = 0.39081478893756866, disc_loss = 0.0698772118644168
Trained batch 150 in epoch 14, gen_loss = 0.3908361459015221, disc_loss = 0.07004272421229853
Trained batch 151 in epoch 14, gen_loss = 0.39092327830822843, disc_loss = 0.06972897646176678
Trained batch 152 in epoch 14, gen_loss = 0.3911207836437849, disc_loss = 0.06948325741926537
Trained batch 153 in epoch 14, gen_loss = 0.3902903785566231, disc_loss = 0.0702554778310821
Trained batch 154 in epoch 14, gen_loss = 0.3908317938927681, disc_loss = 0.07409720202427238
Trained batch 155 in epoch 14, gen_loss = 0.39074714424518436, disc_loss = 0.07537362870509522
Trained batch 156 in epoch 14, gen_loss = 0.39016134382053547, disc_loss = 0.07564044860339943
Trained batch 157 in epoch 14, gen_loss = 0.3896951279308222, disc_loss = 0.07621352674286294
Trained batch 158 in epoch 14, gen_loss = 0.38945628130960763, disc_loss = 0.07629558348255057
Trained batch 159 in epoch 14, gen_loss = 0.389700036495924, disc_loss = 0.07605043195944745
Trained batch 160 in epoch 14, gen_loss = 0.38947135098972674, disc_loss = 0.07572692887487341
Trained batch 161 in epoch 14, gen_loss = 0.38913763912371646, disc_loss = 0.07546385035298213
Trained batch 162 in epoch 14, gen_loss = 0.3894638046165185, disc_loss = 0.07516165688188255
Trained batch 163 in epoch 14, gen_loss = 0.3891502140862186, disc_loss = 0.07500446138324261
Trained batch 164 in epoch 14, gen_loss = 0.3890770881464987, disc_loss = 0.07473741352388805
Trained batch 165 in epoch 14, gen_loss = 0.38888178424662856, disc_loss = 0.07468001883622842
Trained batch 166 in epoch 14, gen_loss = 0.38884774599960464, disc_loss = 0.07449093490314787
Trained batch 167 in epoch 14, gen_loss = 0.3886478105116458, disc_loss = 0.07426185728815783
Trained batch 168 in epoch 14, gen_loss = 0.38907075016456244, disc_loss = 0.07404067539527306
Trained batch 169 in epoch 14, gen_loss = 0.3884984470465604, disc_loss = 0.07395420304828268
Trained batch 170 in epoch 14, gen_loss = 0.3887755520511092, disc_loss = 0.07454153157127967
Trained batch 171 in epoch 14, gen_loss = 0.3884675951544629, disc_loss = 0.07546318108270075
Trained batch 172 in epoch 14, gen_loss = 0.388522398265111, disc_loss = 0.07574198035674029
Trained batch 173 in epoch 14, gen_loss = 0.3887404378118186, disc_loss = 0.07565332820970865
Trained batch 174 in epoch 14, gen_loss = 0.38868284429822647, disc_loss = 0.07534951925543802
Trained batch 175 in epoch 14, gen_loss = 0.38833087259395555, disc_loss = 0.07545089328248816
Trained batch 176 in epoch 14, gen_loss = 0.38866297336621475, disc_loss = 0.07582625902736675
Trained batch 177 in epoch 14, gen_loss = 0.3887849595774426, disc_loss = 0.0756194083192752
Trained batch 178 in epoch 14, gen_loss = 0.3885272916135841, disc_loss = 0.07543997404389291
Trained batch 179 in epoch 14, gen_loss = 0.3886836792031924, disc_loss = 0.07525324664440834
Trained batch 180 in epoch 14, gen_loss = 0.3886846364861694, disc_loss = 0.07491630761632027
Trained batch 181 in epoch 14, gen_loss = 0.3885743274138524, disc_loss = 0.07458380538366408
Trained batch 182 in epoch 14, gen_loss = 0.38835258594627586, disc_loss = 0.07439446386428235
Trained batch 183 in epoch 14, gen_loss = 0.3883195129101691, disc_loss = 0.0741876641556661
Trained batch 184 in epoch 14, gen_loss = 0.38793687111622577, disc_loss = 0.07427446604832201
Trained batch 185 in epoch 14, gen_loss = 0.3882522103927469, disc_loss = 0.074012882469262
Trained batch 186 in epoch 14, gen_loss = 0.38846008121011094, disc_loss = 0.07414765817606274
Trained batch 187 in epoch 14, gen_loss = 0.38856183499731917, disc_loss = 0.0740646898890152
Trained batch 188 in epoch 14, gen_loss = 0.38892150130221453, disc_loss = 0.07385519255573551
Trained batch 189 in epoch 14, gen_loss = 0.38915626971345196, disc_loss = 0.07350202476311671
Trained batch 190 in epoch 14, gen_loss = 0.3892747135686625, disc_loss = 0.07319871957428481
Trained batch 191 in epoch 14, gen_loss = 0.3894674588615696, disc_loss = 0.07333487312037808
Trained batch 192 in epoch 14, gen_loss = 0.3889683325982464, disc_loss = 0.07375179154923851
Trained batch 193 in epoch 14, gen_loss = 0.3894445731775048, disc_loss = 0.07404657592516892
Trained batch 194 in epoch 14, gen_loss = 0.38970600336025923, disc_loss = 0.07372925367492895
Trained batch 195 in epoch 14, gen_loss = 0.3899961924370454, disc_loss = 0.07346664065000963
Trained batch 196 in epoch 14, gen_loss = 0.3906298765373714, disc_loss = 0.07328143558904604
Trained batch 197 in epoch 14, gen_loss = 0.39064600100420943, disc_loss = 0.07320464816358355
Trained batch 198 in epoch 14, gen_loss = 0.3906888990246471, disc_loss = 0.07302401624807162
Trained batch 199 in epoch 14, gen_loss = 0.3911193118989468, disc_loss = 0.07282767342403532
Trained batch 200 in epoch 14, gen_loss = 0.39069950728867187, disc_loss = 0.07301418870613349
Trained batch 201 in epoch 14, gen_loss = 0.39050365674613724, disc_loss = 0.07389621593353182
Trained batch 202 in epoch 14, gen_loss = 0.3903376295648772, disc_loss = 0.07369259390704737
Trained batch 203 in epoch 14, gen_loss = 0.3898088144613247, disc_loss = 0.07359576975817189
Trained batch 204 in epoch 14, gen_loss = 0.3900406455121389, disc_loss = 0.07334193338344737
Trained batch 205 in epoch 14, gen_loss = 0.3899155413930856, disc_loss = 0.07319146486957676
Trained batch 206 in epoch 14, gen_loss = 0.3899795148107741, disc_loss = 0.07307763205130319
Trained batch 207 in epoch 14, gen_loss = 0.38953121866171175, disc_loss = 0.0728547687893017
Trained batch 208 in epoch 14, gen_loss = 0.38955041167268345, disc_loss = 0.07297287590837365
Trained batch 209 in epoch 14, gen_loss = 0.38943431831541514, disc_loss = 0.07308092041029816
Trained batch 210 in epoch 14, gen_loss = 0.3895894170372407, disc_loss = 0.07286808528535739
Trained batch 211 in epoch 14, gen_loss = 0.3899154121864517, disc_loss = 0.072849001050136
Trained batch 212 in epoch 14, gen_loss = 0.3893039408424091, disc_loss = 0.07348361466202377
Trained batch 213 in epoch 14, gen_loss = 0.38934038885842975, disc_loss = 0.07366958652213912
Trained batch 214 in epoch 14, gen_loss = 0.3897757135158361, disc_loss = 0.07338593256508195
Trained batch 215 in epoch 14, gen_loss = 0.3898981381897573, disc_loss = 0.07308427850646829
Trained batch 216 in epoch 14, gen_loss = 0.38979096937289437, disc_loss = 0.07279550054535476
Trained batch 217 in epoch 14, gen_loss = 0.3900295128242685, disc_loss = 0.07298377467695316
Trained batch 218 in epoch 14, gen_loss = 0.3900268699752686, disc_loss = 0.072882277580599
Trained batch 219 in epoch 14, gen_loss = 0.39020037718794565, disc_loss = 0.07277375653132119
Trained batch 220 in epoch 14, gen_loss = 0.38949784204970656, disc_loss = 0.07325751719178793
Trained batch 221 in epoch 14, gen_loss = 0.3895999586528486, disc_loss = 0.07334434620717221
Trained batch 222 in epoch 14, gen_loss = 0.3897549167876821, disc_loss = 0.07310823533650605
Trained batch 223 in epoch 14, gen_loss = 0.38940197854701963, disc_loss = 0.0731881819208086
Trained batch 224 in epoch 14, gen_loss = 0.38955845620897084, disc_loss = 0.07407002497464418
Trained batch 225 in epoch 14, gen_loss = 0.3893804663577966, disc_loss = 0.07399198688583168
Trained batch 226 in epoch 14, gen_loss = 0.3892694375588505, disc_loss = 0.07375630728555803
Trained batch 227 in epoch 14, gen_loss = 0.3891714428339088, disc_loss = 0.07358045013735823
Trained batch 228 in epoch 14, gen_loss = 0.3888942012360002, disc_loss = 0.07359608588536884
Trained batch 229 in epoch 14, gen_loss = 0.38924295681974164, disc_loss = 0.07409305206864425
Trained batch 230 in epoch 14, gen_loss = 0.3888739775785636, disc_loss = 0.0747669136345193
Trained batch 231 in epoch 14, gen_loss = 0.3888600281086461, disc_loss = 0.07451944747249242
Trained batch 232 in epoch 14, gen_loss = 0.3889997578485841, disc_loss = 0.07447401508129334
Trained batch 233 in epoch 14, gen_loss = 0.388766289394126, disc_loss = 0.07426407928857157
Trained batch 234 in epoch 14, gen_loss = 0.3889401727534355, disc_loss = 0.07407892926972597
Trained batch 235 in epoch 14, gen_loss = 0.3890135987835415, disc_loss = 0.07386796548567964
Trained batch 236 in epoch 14, gen_loss = 0.38892019134533556, disc_loss = 0.07368717161459133
Trained batch 237 in epoch 14, gen_loss = 0.38857629018671375, disc_loss = 0.07358515922747114
Trained batch 238 in epoch 14, gen_loss = 0.38855937684430236, disc_loss = 0.07341934338009383
Trained batch 239 in epoch 14, gen_loss = 0.3882951603581508, disc_loss = 0.07345876951003447
Trained batch 240 in epoch 14, gen_loss = 0.3885436218803849, disc_loss = 0.07327027547393473
Trained batch 241 in epoch 14, gen_loss = 0.38851452403324693, disc_loss = 0.0730327585411897
Trained batch 242 in epoch 14, gen_loss = 0.3883274976363398, disc_loss = 0.07285807049093546
Trained batch 243 in epoch 14, gen_loss = 0.38804555024768483, disc_loss = 0.07258728137583334
Trained batch 244 in epoch 14, gen_loss = 0.3876690493554485, disc_loss = 0.07302182423407022
Trained batch 245 in epoch 14, gen_loss = 0.38817007718532065, disc_loss = 0.07373561392295955
Trained batch 246 in epoch 14, gen_loss = 0.38824581388037216, disc_loss = 0.07365700092943393
Trained batch 247 in epoch 14, gen_loss = 0.388351681492021, disc_loss = 0.07500927351723094
Trained batch 248 in epoch 14, gen_loss = 0.38865046891342686, disc_loss = 0.07607794152273531
Trained batch 249 in epoch 14, gen_loss = 0.3887491663694382, disc_loss = 0.07610114559717476
Trained batch 250 in epoch 14, gen_loss = 0.38890276332775436, disc_loss = 0.0768009114034652
Trained batch 251 in epoch 14, gen_loss = 0.3891997155216005, disc_loss = 0.07839006360154599
Trained batch 252 in epoch 14, gen_loss = 0.38933779081337067, disc_loss = 0.08060631812863023
Trained batch 253 in epoch 14, gen_loss = 0.38942834852248664, disc_loss = 0.08087890997243033
Trained batch 254 in epoch 14, gen_loss = 0.38915866134213467, disc_loss = 0.0809886718515818
Trained batch 255 in epoch 14, gen_loss = 0.38901230483315885, disc_loss = 0.08089202291921538
Trained batch 256 in epoch 14, gen_loss = 0.38913884190733794, disc_loss = 0.08078245843438149
Trained batch 257 in epoch 14, gen_loss = 0.3893257585144782, disc_loss = 0.08070695589570863
Trained batch 258 in epoch 14, gen_loss = 0.38899095339204354, disc_loss = 0.08085871794401277
Trained batch 259 in epoch 14, gen_loss = 0.388510246689503, disc_loss = 0.08182833233597474
Trained batch 260 in epoch 14, gen_loss = 0.3886079458212944, disc_loss = 0.0820552835051841
Trained batch 261 in epoch 14, gen_loss = 0.3886616620171161, disc_loss = 0.08197172569246067
Trained batch 262 in epoch 14, gen_loss = 0.3884552007845599, disc_loss = 0.08197118789701237
Trained batch 263 in epoch 14, gen_loss = 0.38847195718324545, disc_loss = 0.08189621491703403
Trained batch 264 in epoch 14, gen_loss = 0.38845308074411355, disc_loss = 0.0817303610596595
Trained batch 265 in epoch 14, gen_loss = 0.38822492228862937, disc_loss = 0.08178744014331553
Trained batch 266 in epoch 14, gen_loss = 0.3883119233315357, disc_loss = 0.08173288469296995
Trained batch 267 in epoch 14, gen_loss = 0.38810968966181597, disc_loss = 0.0818502171566265
Trained batch 268 in epoch 14, gen_loss = 0.38791178205642557, disc_loss = 0.08224030966493111
Trained batch 269 in epoch 14, gen_loss = 0.3878235543215716, disc_loss = 0.08300456926399083
Trained batch 270 in epoch 14, gen_loss = 0.3876710619873666, disc_loss = 0.08327745019571643
Trained batch 271 in epoch 14, gen_loss = 0.38769358736188975, disc_loss = 0.08338937379919704
Trained batch 272 in epoch 14, gen_loss = 0.38762720720671906, disc_loss = 0.08333448107924053
Trained batch 273 in epoch 14, gen_loss = 0.38770320630856675, disc_loss = 0.08324553050868974
Trained batch 274 in epoch 14, gen_loss = 0.38752791892398486, disc_loss = 0.08313942749561234
Trained batch 275 in epoch 14, gen_loss = 0.3876162371125774, disc_loss = 0.08323181871547485
Trained batch 276 in epoch 14, gen_loss = 0.38757079667563044, disc_loss = 0.08408081130921465
Trained batch 277 in epoch 14, gen_loss = 0.38736308714468703, disc_loss = 0.08410989399496868
Trained batch 278 in epoch 14, gen_loss = 0.38740949754646603, disc_loss = 0.08407184340253365
Trained batch 279 in epoch 14, gen_loss = 0.3876059570482799, disc_loss = 0.0839821931656583
Trained batch 280 in epoch 14, gen_loss = 0.38750788134612224, disc_loss = 0.08377720784972624
Trained batch 281 in epoch 14, gen_loss = 0.38736304387133175, disc_loss = 0.08394839781904527
Trained batch 282 in epoch 14, gen_loss = 0.3876905704555579, disc_loss = 0.0851640325687931
Trained batch 283 in epoch 14, gen_loss = 0.38752092987718717, disc_loss = 0.08525709079375202
Trained batch 284 in epoch 14, gen_loss = 0.3872831768111179, disc_loss = 0.08525808715800706
Trained batch 285 in epoch 14, gen_loss = 0.3873111046069152, disc_loss = 0.08509292217277616
Trained batch 286 in epoch 14, gen_loss = 0.3873762843500862, disc_loss = 0.08484056744990605
Trained batch 287 in epoch 14, gen_loss = 0.3871552407120665, disc_loss = 0.08465230925260887
Trained batch 288 in epoch 14, gen_loss = 0.38709736117854665, disc_loss = 0.08465799093600943
Trained batch 289 in epoch 14, gen_loss = 0.38722056941739447, disc_loss = 0.08448631194227471
Trained batch 290 in epoch 14, gen_loss = 0.3871381410823245, disc_loss = 0.08430441132109753
Trained batch 291 in epoch 14, gen_loss = 0.3870990169170785, disc_loss = 0.08427611719147136
Trained batch 292 in epoch 14, gen_loss = 0.38722208986510187, disc_loss = 0.0844239665897811
Trained batch 293 in epoch 14, gen_loss = 0.3870392586706447, disc_loss = 0.08441375977625805
Trained batch 294 in epoch 14, gen_loss = 0.38696976607128725, disc_loss = 0.08425077057080502
Trained batch 295 in epoch 14, gen_loss = 0.38730780589016706, disc_loss = 0.08440971493916083
Trained batch 296 in epoch 14, gen_loss = 0.3871979442509738, disc_loss = 0.08458359297270877
Trained batch 297 in epoch 14, gen_loss = 0.3874747553127724, disc_loss = 0.08439912013053244
Trained batch 298 in epoch 14, gen_loss = 0.3872109935634511, disc_loss = 0.08446169012758793
Trained batch 299 in epoch 14, gen_loss = 0.38672649666666986, disc_loss = 0.08496748068525145
Trained batch 300 in epoch 14, gen_loss = 0.38703113571551945, disc_loss = 0.08479003567230019
Trained batch 301 in epoch 14, gen_loss = 0.38696531147159485, disc_loss = 0.08476557938955626
Trained batch 302 in epoch 14, gen_loss = 0.38679861761752526, disc_loss = 0.08471289347002756
Trained batch 303 in epoch 14, gen_loss = 0.3868537937830153, disc_loss = 0.0845064987033287
Trained batch 304 in epoch 14, gen_loss = 0.386859128465418, disc_loss = 0.08442109046870323
Trained batch 305 in epoch 14, gen_loss = 0.38667651090551824, disc_loss = 0.08434230837137043
Trained batch 306 in epoch 14, gen_loss = 0.3867325082372765, disc_loss = 0.0841099476845213
Trained batch 307 in epoch 14, gen_loss = 0.38695184136559435, disc_loss = 0.08386075066844026
Trained batch 308 in epoch 14, gen_loss = 0.3869181434024113, disc_loss = 0.08363994927835744
Trained batch 309 in epoch 14, gen_loss = 0.3867715271730577, disc_loss = 0.08355818992450594
Trained batch 310 in epoch 14, gen_loss = 0.386618002674204, disc_loss = 0.08340141038976347
Trained batch 311 in epoch 14, gen_loss = 0.38649186401221997, disc_loss = 0.08326938509111269
Trained batch 312 in epoch 14, gen_loss = 0.3864362680207426, disc_loss = 0.08320551388971388
Trained batch 313 in epoch 14, gen_loss = 0.3865536389172457, disc_loss = 0.08336170470478475
Trained batch 314 in epoch 14, gen_loss = 0.3864819088152477, disc_loss = 0.08382168943949399
Trained batch 315 in epoch 14, gen_loss = 0.3867722841663451, disc_loss = 0.08358394357381695
Trained batch 316 in epoch 14, gen_loss = 0.38689104968252996, disc_loss = 0.08349588847563423
Trained batch 317 in epoch 14, gen_loss = 0.3870270699731209, disc_loss = 0.08328089519087577
Trained batch 318 in epoch 14, gen_loss = 0.38678340912799475, disc_loss = 0.08339659337590807
Trained batch 319 in epoch 14, gen_loss = 0.38689591982401905, disc_loss = 0.08355318457324756
Trained batch 320 in epoch 14, gen_loss = 0.38667101201795717, disc_loss = 0.08365590060768051
Trained batch 321 in epoch 14, gen_loss = 0.38657706813967746, disc_loss = 0.08348782701122788
Trained batch 322 in epoch 14, gen_loss = 0.38676065727837683, disc_loss = 0.08330859940343366
Trained batch 323 in epoch 14, gen_loss = 0.3868110854592588, disc_loss = 0.08313861314385532
Trained batch 324 in epoch 14, gen_loss = 0.38692044281042537, disc_loss = 0.08296070493614445
Trained batch 325 in epoch 14, gen_loss = 0.3868455048993321, disc_loss = 0.08290627233518368
Trained batch 326 in epoch 14, gen_loss = 0.38694215609210714, disc_loss = 0.08276875365371687
Trained batch 327 in epoch 14, gen_loss = 0.387088923964922, disc_loss = 0.08262404723791406
Trained batch 328 in epoch 14, gen_loss = 0.3869010543841359, disc_loss = 0.08250832921573412
Trained batch 329 in epoch 14, gen_loss = 0.3870452590512507, disc_loss = 0.08246361705135893
Trained batch 330 in epoch 14, gen_loss = 0.3871239604276473, disc_loss = 0.08237908130477878
Trained batch 331 in epoch 14, gen_loss = 0.3871383180909128, disc_loss = 0.08224759186219693
Trained batch 332 in epoch 14, gen_loss = 0.38723385633828045, disc_loss = 0.08201988917487385
Trained batch 333 in epoch 14, gen_loss = 0.38759261311706666, disc_loss = 0.0818387496516577
Trained batch 334 in epoch 14, gen_loss = 0.3875272506653373, disc_loss = 0.08170259964249249
Trained batch 335 in epoch 14, gen_loss = 0.38740574209285633, disc_loss = 0.08156531886336216
Trained batch 336 in epoch 14, gen_loss = 0.3874755720621754, disc_loss = 0.08137550596451769
Trained batch 337 in epoch 14, gen_loss = 0.38774724961561563, disc_loss = 0.08117473816096826
Trained batch 338 in epoch 14, gen_loss = 0.38760437071323395, disc_loss = 0.08123672569643124
Trained batch 339 in epoch 14, gen_loss = 0.38777039064203994, disc_loss = 0.08174754598807982
Trained batch 340 in epoch 14, gen_loss = 0.3879078186589602, disc_loss = 0.08247744380100426
Trained batch 341 in epoch 14, gen_loss = 0.3876206991181039, disc_loss = 0.08253654910180695
Trained batch 342 in epoch 14, gen_loss = 0.38798407228451776, disc_loss = 0.08333882683638277
Trained batch 343 in epoch 14, gen_loss = 0.38777519766847757, disc_loss = 0.08326829695494758
Trained batch 344 in epoch 14, gen_loss = 0.3878547312124916, disc_loss = 0.08313104050989815
Trained batch 345 in epoch 14, gen_loss = 0.3879282013270896, disc_loss = 0.08298007203023773
Trained batch 346 in epoch 14, gen_loss = 0.3882048516950278, disc_loss = 0.08291540749140235
Trained batch 347 in epoch 14, gen_loss = 0.3882024071082987, disc_loss = 0.08346647209482504
Trained batch 348 in epoch 14, gen_loss = 0.38839062121843543, disc_loss = 0.08414122792238364
Trained batch 349 in epoch 14, gen_loss = 0.38854421015296664, disc_loss = 0.08418403963026191
Trained batch 350 in epoch 14, gen_loss = 0.3883341254926475, disc_loss = 0.08432155734119125
Trained batch 351 in epoch 14, gen_loss = 0.38813749357888644, disc_loss = 0.08418596890590958
Trained batch 352 in epoch 14, gen_loss = 0.38812225985290644, disc_loss = 0.08400191778908074
Trained batch 353 in epoch 14, gen_loss = 0.38832736760377884, disc_loss = 0.08398841783051816
Trained batch 354 in epoch 14, gen_loss = 0.388297797214817, disc_loss = 0.0839347003277024
Trained batch 355 in epoch 14, gen_loss = 0.3882608154600256, disc_loss = 0.0837754692236129
Trained batch 356 in epoch 14, gen_loss = 0.38826414036984536, disc_loss = 0.08371430357490309
Trained batch 357 in epoch 14, gen_loss = 0.3883142804716552, disc_loss = 0.08377044953473495
Trained batch 358 in epoch 14, gen_loss = 0.388360036656385, disc_loss = 0.08398807934591739
Trained batch 359 in epoch 14, gen_loss = 0.3883073134968678, disc_loss = 0.08445447407688739
Trained batch 360 in epoch 14, gen_loss = 0.38842446359075666, disc_loss = 0.08450223395724747
Trained batch 361 in epoch 14, gen_loss = 0.38843007859110174, disc_loss = 0.08438323960557209
Trained batch 362 in epoch 14, gen_loss = 0.38851274196930824, disc_loss = 0.08439076586803498
Trained batch 363 in epoch 14, gen_loss = 0.38855485810519574, disc_loss = 0.08432948649323617
Trained batch 364 in epoch 14, gen_loss = 0.388441192573064, disc_loss = 0.08418127987916543
Trained batch 365 in epoch 14, gen_loss = 0.3881655357004515, disc_loss = 0.08425407147905255
Trained batch 366 in epoch 14, gen_loss = 0.3882912679572846, disc_loss = 0.0845568726557416
Trained batch 367 in epoch 14, gen_loss = 0.3882328582441677, disc_loss = 0.08444389767322244
Trained batch 368 in epoch 14, gen_loss = 0.38818401594956714, disc_loss = 0.08475262501723761
Trained batch 369 in epoch 14, gen_loss = 0.38829154714539243, disc_loss = 0.08510594711941037
Trained batch 370 in epoch 14, gen_loss = 0.38839738087030756, disc_loss = 0.08495752530604239
Trained batch 371 in epoch 14, gen_loss = 0.3882193058649058, disc_loss = 0.08492412238997678
Trained batch 372 in epoch 14, gen_loss = 0.3881974496326881, disc_loss = 0.08479150134106304
Trained batch 373 in epoch 14, gen_loss = 0.3882108338296732, disc_loss = 0.08460340090718539
Trained batch 374 in epoch 14, gen_loss = 0.3883374981482824, disc_loss = 0.08453046446666121
Trained batch 375 in epoch 14, gen_loss = 0.38815130527190705, disc_loss = 0.08442261511524346
Trained batch 376 in epoch 14, gen_loss = 0.38790412421093695, disc_loss = 0.0842487070751463
Trained batch 377 in epoch 14, gen_loss = 0.3879899908862417, disc_loss = 0.08405766087318105
Trained batch 378 in epoch 14, gen_loss = 0.3880203590779946, disc_loss = 0.08387837136940819
Trained batch 379 in epoch 14, gen_loss = 0.3877027731584875, disc_loss = 0.08386735024641415
Trained batch 380 in epoch 14, gen_loss = 0.38781554386841033, disc_loss = 0.08368569591603293
Trained batch 381 in epoch 14, gen_loss = 0.38784246720100574, disc_loss = 0.08351416346197704
Trained batch 382 in epoch 14, gen_loss = 0.3878002901690436, disc_loss = 0.08338621197093288
Trained batch 383 in epoch 14, gen_loss = 0.3877238694500799, disc_loss = 0.08340046689287799
Trained batch 384 in epoch 14, gen_loss = 0.38803845887834376, disc_loss = 0.0840625634695125
Trained batch 385 in epoch 14, gen_loss = 0.38784289819434514, disc_loss = 0.08399467620578802
Trained batch 386 in epoch 14, gen_loss = 0.387887460124277, disc_loss = 0.08454444298511059
Trained batch 387 in epoch 14, gen_loss = 0.38803797510942234, disc_loss = 0.08440782933030277
Trained batch 388 in epoch 14, gen_loss = 0.38809148201139543, disc_loss = 0.08438981526141033
Trained batch 389 in epoch 14, gen_loss = 0.38811744073262583, disc_loss = 0.0842069735428175
Trained batch 390 in epoch 14, gen_loss = 0.38800565296274314, disc_loss = 0.08418256215050893
Trained batch 391 in epoch 14, gen_loss = 0.38788662892671266, disc_loss = 0.0840547310143272
Trained batch 392 in epoch 14, gen_loss = 0.3879893085049612, disc_loss = 0.08405110102653997
Trained batch 393 in epoch 14, gen_loss = 0.38796945631050217, disc_loss = 0.0839550504898227
Trained batch 394 in epoch 14, gen_loss = 0.38800127359130715, disc_loss = 0.08377927628145376
Trained batch 395 in epoch 14, gen_loss = 0.38811355516916574, disc_loss = 0.08359542757277424
Trained batch 396 in epoch 14, gen_loss = 0.3878963664361752, disc_loss = 0.0837541388204645
Trained batch 397 in epoch 14, gen_loss = 0.38822182844481873, disc_loss = 0.08442211717521612
Trained batch 398 in epoch 14, gen_loss = 0.3883474144645801, disc_loss = 0.08424371297594935
Trained batch 399 in epoch 14, gen_loss = 0.388349339030683, disc_loss = 0.08413480168790556
Trained batch 400 in epoch 14, gen_loss = 0.3882872328125033, disc_loss = 0.08402037821789075
Trained batch 401 in epoch 14, gen_loss = 0.3883962559685185, disc_loss = 0.0838312586892248
Trained batch 402 in epoch 14, gen_loss = 0.38831103095789404, disc_loss = 0.08365659999589507
Trained batch 403 in epoch 14, gen_loss = 0.38833395476536, disc_loss = 0.08350952955926445
Trained batch 404 in epoch 14, gen_loss = 0.38842339747481874, disc_loss = 0.0833318852175625
Trained batch 405 in epoch 14, gen_loss = 0.3884685312218854, disc_loss = 0.08321241602379591
Trained batch 406 in epoch 14, gen_loss = 0.3883015703437369, disc_loss = 0.08312129268779692
Trained batch 407 in epoch 14, gen_loss = 0.38828657490803914, disc_loss = 0.08316942236007319
Trained batch 408 in epoch 14, gen_loss = 0.3880823088814402, disc_loss = 0.08331816234628153
Trained batch 409 in epoch 14, gen_loss = 0.3881680711376958, disc_loss = 0.08319684747810953
Trained batch 410 in epoch 14, gen_loss = 0.38829983611321506, disc_loss = 0.08303411774124289
Trained batch 411 in epoch 14, gen_loss = 0.388267478426394, disc_loss = 0.08284738056872547
Trained batch 412 in epoch 14, gen_loss = 0.38825966843536924, disc_loss = 0.08267943536610169
Trained batch 413 in epoch 14, gen_loss = 0.3882886068040622, disc_loss = 0.08252629454040693
Trained batch 414 in epoch 14, gen_loss = 0.38835057074046997, disc_loss = 0.0823479104798332
Trained batch 415 in epoch 14, gen_loss = 0.3883328211063949, disc_loss = 0.08223850410454012
Trained batch 416 in epoch 14, gen_loss = 0.38835682932564397, disc_loss = 0.08229764184313748
Trained batch 417 in epoch 14, gen_loss = 0.38827073898469433, disc_loss = 0.08299667858429538
Trained batch 418 in epoch 14, gen_loss = 0.3884725951565194, disc_loss = 0.08297546598771342
Trained batch 419 in epoch 14, gen_loss = 0.38863700965330716, disc_loss = 0.08292506165647258
Trained batch 420 in epoch 14, gen_loss = 0.3883875733387442, disc_loss = 0.08293150875589096
Trained batch 421 in epoch 14, gen_loss = 0.3883778009722583, disc_loss = 0.08297839549467215
Trained batch 422 in epoch 14, gen_loss = 0.38831965942332086, disc_loss = 0.08306360086778412
Trained batch 423 in epoch 14, gen_loss = 0.3884853648619269, disc_loss = 0.0831280050783875
Trained batch 424 in epoch 14, gen_loss = 0.38829536497592926, disc_loss = 0.08304224546012633
Trained batch 425 in epoch 14, gen_loss = 0.38829066527421485, disc_loss = 0.08288462138778482
Trained batch 426 in epoch 14, gen_loss = 0.3883142493996743, disc_loss = 0.08274198227629624
Trained batch 427 in epoch 14, gen_loss = 0.3883957902195855, disc_loss = 0.08259432204176506
Trained batch 428 in epoch 14, gen_loss = 0.3883981686997247, disc_loss = 0.08246829741610548
Trained batch 429 in epoch 14, gen_loss = 0.3884558854754581, disc_loss = 0.08235737417694615
Trained batch 430 in epoch 14, gen_loss = 0.3884898934107092, disc_loss = 0.08220153743306093
Trained batch 431 in epoch 14, gen_loss = 0.38848787459924267, disc_loss = 0.08212315114064107
Trained batch 432 in epoch 14, gen_loss = 0.3885823390844512, disc_loss = 0.08201106275188765
Trained batch 433 in epoch 14, gen_loss = 0.38870486256576353, disc_loss = 0.08203943649388437
Trained batch 434 in epoch 14, gen_loss = 0.38871635304785324, disc_loss = 0.08189276440668551
Trained batch 435 in epoch 14, gen_loss = 0.3886902822061963, disc_loss = 0.08172618586745181
Trained batch 436 in epoch 14, gen_loss = 0.38868661156644535, disc_loss = 0.08177211317308332
Trained batch 437 in epoch 14, gen_loss = 0.38869882068813666, disc_loss = 0.08215222435527095
Trained batch 438 in epoch 14, gen_loss = 0.388601822400962, disc_loss = 0.08221677409968677
Trained batch 439 in epoch 14, gen_loss = 0.38867929642173377, disc_loss = 0.08205213425363499
Trained batch 440 in epoch 14, gen_loss = 0.38871606484967836, disc_loss = 0.08210296018784043
Trained batch 441 in epoch 14, gen_loss = 0.38843394091091543, disc_loss = 0.08262003174923967
Trained batch 442 in epoch 14, gen_loss = 0.38825702038225685, disc_loss = 0.08268511099068124
Trained batch 443 in epoch 14, gen_loss = 0.38822152220585326, disc_loss = 0.08254958428799065
Trained batch 444 in epoch 14, gen_loss = 0.3880507050270445, disc_loss = 0.08258858401474825
Trained batch 445 in epoch 14, gen_loss = 0.3880774768010918, disc_loss = 0.08285725134792382
Trained batch 446 in epoch 14, gen_loss = 0.38800769607626084, disc_loss = 0.08302216399856895
Trained batch 447 in epoch 14, gen_loss = 0.38813815635096816, disc_loss = 0.08290803102032182
Trained batch 448 in epoch 14, gen_loss = 0.3879300921757131, disc_loss = 0.08277334272550349
Trained batch 449 in epoch 14, gen_loss = 0.3880657853351699, disc_loss = 0.0827036422956735
Trained batch 450 in epoch 14, gen_loss = 0.3880790970608295, disc_loss = 0.08263349664932378
Trained batch 451 in epoch 14, gen_loss = 0.38794654769311965, disc_loss = 0.08249669254703892
Trained batch 452 in epoch 14, gen_loss = 0.387871198471282, disc_loss = 0.0823606694328946
Trained batch 453 in epoch 14, gen_loss = 0.38797765724065547, disc_loss = 0.08233372106151204
Trained batch 454 in epoch 14, gen_loss = 0.3880336609843013, disc_loss = 0.08259686078200792
Trained batch 455 in epoch 14, gen_loss = 0.3879694478880418, disc_loss = 0.08253953947885811
Trained batch 456 in epoch 14, gen_loss = 0.3880234610134454, disc_loss = 0.08241804636692877
Trained batch 457 in epoch 14, gen_loss = 0.3879533487831661, disc_loss = 0.08238751971260462
Trained batch 458 in epoch 14, gen_loss = 0.38810850069543634, disc_loss = 0.08223710236827435
Trained batch 459 in epoch 14, gen_loss = 0.38837697917352554, disc_loss = 0.08240481391650341
Trained batch 460 in epoch 14, gen_loss = 0.3882764826433778, disc_loss = 0.08276614459603217
Trained batch 461 in epoch 14, gen_loss = 0.38810519670898264, disc_loss = 0.08262118181209704
Trained batch 462 in epoch 14, gen_loss = 0.3885492244433636, disc_loss = 0.08251284147445796
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.46684759855270386, disc_loss = 0.0384865403175354
Trained batch 1 in epoch 15, gen_loss = 0.44226667284965515, disc_loss = 0.024014585185796022
Trained batch 2 in epoch 15, gen_loss = 0.41229310631752014, disc_loss = 0.0280858442808191
Trained batch 3 in epoch 15, gen_loss = 0.4093470722436905, disc_loss = 0.024477571016177535
Trained batch 4 in epoch 15, gen_loss = 0.3924392879009247, disc_loss = 0.02936361264437437
Trained batch 5 in epoch 15, gen_loss = 0.38173190255959827, disc_loss = 0.0682753409879903
Trained batch 6 in epoch 15, gen_loss = 0.3743588370936258, disc_loss = 0.10712144936301879
Trained batch 7 in epoch 15, gen_loss = 0.3819021098315716, disc_loss = 0.10309028986375779
Trained batch 8 in epoch 15, gen_loss = 0.39900310503111946, disc_loss = 0.09811906340635485
Trained batch 9 in epoch 15, gen_loss = 0.3914790630340576, disc_loss = 0.10222846260294319
Trained batch 10 in epoch 15, gen_loss = 0.3909377401525324, disc_loss = 0.09509317703883756
Trained batch 11 in epoch 15, gen_loss = 0.38732046137253445, disc_loss = 0.0885324024129659
Trained batch 12 in epoch 15, gen_loss = 0.3829939571710733, disc_loss = 0.08936057805728453
Trained batch 13 in epoch 15, gen_loss = 0.38448273071220945, disc_loss = 0.08949338638090662
Trained batch 14 in epoch 15, gen_loss = 0.3745748281478882, disc_loss = 0.10786775443702937
Trained batch 15 in epoch 15, gen_loss = 0.37824921682477, disc_loss = 0.1084517696290277
Trained batch 16 in epoch 15, gen_loss = 0.37982236287173105, disc_loss = 0.10758687506484635
Trained batch 17 in epoch 15, gen_loss = 0.3822511268986596, disc_loss = 0.10481153009459376
Trained batch 18 in epoch 15, gen_loss = 0.3847641725289194, disc_loss = 0.10161926572848308
Trained batch 19 in epoch 15, gen_loss = 0.38151898980140686, disc_loss = 0.09999666712246835
Trained batch 20 in epoch 15, gen_loss = 0.37962548505692256, disc_loss = 0.09947759423050143
Trained batch 21 in epoch 15, gen_loss = 0.37462525611574, disc_loss = 0.10262722399255092
Trained batch 22 in epoch 15, gen_loss = 0.3760769587496053, disc_loss = 0.1008260466725282
Trained batch 23 in epoch 15, gen_loss = 0.3737473177413146, disc_loss = 0.10038161863728116
Trained batch 24 in epoch 15, gen_loss = 0.37566879391670227, disc_loss = 0.09747973214834929
Trained batch 25 in epoch 15, gen_loss = 0.37734185273830706, disc_loss = 0.09535221250441211
Trained batch 26 in epoch 15, gen_loss = 0.3769161844695056, disc_loss = 0.09345119760406238
Trained batch 27 in epoch 15, gen_loss = 0.3769114336797169, disc_loss = 0.10054659959860146
Trained batch 28 in epoch 15, gen_loss = 0.3801295366780511, disc_loss = 0.10977963342106548
Trained batch 29 in epoch 15, gen_loss = 0.38016461531321205, disc_loss = 0.10683531590426962
Trained batch 30 in epoch 15, gen_loss = 0.37996572352224783, disc_loss = 0.10539065640900404
Trained batch 31 in epoch 15, gen_loss = 0.37958185374736786, disc_loss = 0.10303227361873724
Trained batch 32 in epoch 15, gen_loss = 0.38045036792755127, disc_loss = 0.10114052713933316
Trained batch 33 in epoch 15, gen_loss = 0.37925638170803294, disc_loss = 0.09903648246408385
Trained batch 34 in epoch 15, gen_loss = 0.3800350291388375, disc_loss = 0.09702035654336214
Trained batch 35 in epoch 15, gen_loss = 0.3786253904302915, disc_loss = 0.09546399093233049
Trained batch 36 in epoch 15, gen_loss = 0.3785797027317253, disc_loss = 0.09616421059881514
Trained batch 37 in epoch 15, gen_loss = 0.3757644444704056, disc_loss = 0.09879890493558426
Trained batch 38 in epoch 15, gen_loss = 0.3764914793845935, disc_loss = 0.09792036828226768
Trained batch 39 in epoch 15, gen_loss = 0.3751745030283928, disc_loss = 0.09613793331664056
Trained batch 40 in epoch 15, gen_loss = 0.37633517311840525, disc_loss = 0.09463252933559621
Trained batch 41 in epoch 15, gen_loss = 0.3780657918680282, disc_loss = 0.09378044934765924
Trained batch 42 in epoch 15, gen_loss = 0.3794426072475522, disc_loss = 0.092306905426085
Trained batch 43 in epoch 15, gen_loss = 0.37862322479486465, disc_loss = 0.09209874549626627
Trained batch 44 in epoch 15, gen_loss = 0.38055222166909114, disc_loss = 0.09469432837019363
Trained batch 45 in epoch 15, gen_loss = 0.3798815957877947, disc_loss = 0.09379759104922414
Trained batch 46 in epoch 15, gen_loss = 0.3788523185760417, disc_loss = 0.09240220976557503
Trained batch 47 in epoch 15, gen_loss = 0.37942978739738464, disc_loss = 0.09204917430179194
Trained batch 48 in epoch 15, gen_loss = 0.3792767871399315, disc_loss = 0.09191284129129988
Trained batch 49 in epoch 15, gen_loss = 0.380567792057991, disc_loss = 0.09128220213577151
Trained batch 50 in epoch 15, gen_loss = 0.3795595356062347, disc_loss = 0.09015714039332141
Trained batch 51 in epoch 15, gen_loss = 0.379654073371337, disc_loss = 0.08906647045380221
Trained batch 52 in epoch 15, gen_loss = 0.3786704365937215, disc_loss = 0.08991644600019702
Trained batch 53 in epoch 15, gen_loss = 0.379739076451019, disc_loss = 0.08952755838011701
Trained batch 54 in epoch 15, gen_loss = 0.380493872274052, disc_loss = 0.0889635740864006
Trained batch 55 in epoch 15, gen_loss = 0.3799712727112429, disc_loss = 0.08800784317177854
Trained batch 56 in epoch 15, gen_loss = 0.3793111051383771, disc_loss = 0.08805568011379555
Trained batch 57 in epoch 15, gen_loss = 0.37914064423791294, disc_loss = 0.08744504012103224
Trained batch 58 in epoch 15, gen_loss = 0.3793652052596464, disc_loss = 0.08660935728921224
Trained batch 59 in epoch 15, gen_loss = 0.37941505908966067, disc_loss = 0.08625325018850466
Trained batch 60 in epoch 15, gen_loss = 0.37909665948054827, disc_loss = 0.08582098914890504
Trained batch 61 in epoch 15, gen_loss = 0.37971141886326576, disc_loss = 0.085392574494284
Trained batch 62 in epoch 15, gen_loss = 0.38088025980525547, disc_loss = 0.08433685941059911
Trained batch 63 in epoch 15, gen_loss = 0.3813310544937849, disc_loss = 0.08365822483028751
Trained batch 64 in epoch 15, gen_loss = 0.38076541698895966, disc_loss = 0.08264090107897153
Trained batch 65 in epoch 15, gen_loss = 0.3808757762114207, disc_loss = 0.08184047013690526
Trained batch 66 in epoch 15, gen_loss = 0.3810133418040489, disc_loss = 0.08087803663880523
Trained batch 67 in epoch 15, gen_loss = 0.3808672086280935, disc_loss = 0.08049072112942882
Trained batch 68 in epoch 15, gen_loss = 0.3804401742375415, disc_loss = 0.08327541064363027
Trained batch 69 in epoch 15, gen_loss = 0.3817846540893827, disc_loss = 0.08694571944485818
Trained batch 70 in epoch 15, gen_loss = 0.3808049177619773, disc_loss = 0.08654134066014642
Trained batch 71 in epoch 15, gen_loss = 0.38023435448606807, disc_loss = 0.08605964752172844
Trained batch 72 in epoch 15, gen_loss = 0.38049552375323153, disc_loss = 0.08515921986521516
Trained batch 73 in epoch 15, gen_loss = 0.3805216824686205, disc_loss = 0.08462299976648914
Trained batch 74 in epoch 15, gen_loss = 0.3812272397677104, disc_loss = 0.08391067178299029
Trained batch 75 in epoch 15, gen_loss = 0.3803299638001542, disc_loss = 0.0834526535442197
Trained batch 76 in epoch 15, gen_loss = 0.380902080179809, disc_loss = 0.08249234958467158
Trained batch 77 in epoch 15, gen_loss = 0.38094711265502834, disc_loss = 0.08188223274042591
Trained batch 78 in epoch 15, gen_loss = 0.38110638457008555, disc_loss = 0.08296617175912178
Trained batch 79 in epoch 15, gen_loss = 0.3805989842861891, disc_loss = 0.08374807153595612
Trained batch 80 in epoch 15, gen_loss = 0.3812300941826385, disc_loss = 0.08368234280036924
Trained batch 81 in epoch 15, gen_loss = 0.38100576982265566, disc_loss = 0.08281541798581801
Trained batch 82 in epoch 15, gen_loss = 0.38189569905579807, disc_loss = 0.08192911114633443
Trained batch 83 in epoch 15, gen_loss = 0.38273939348402475, disc_loss = 0.08118992115903113
Trained batch 84 in epoch 15, gen_loss = 0.3836440114413991, disc_loss = 0.08042219624142437
Trained batch 85 in epoch 15, gen_loss = 0.382904659870059, disc_loss = 0.07976969705114878
Trained batch 86 in epoch 15, gen_loss = 0.38243122073425645, disc_loss = 0.08022222035275452
Trained batch 87 in epoch 15, gen_loss = 0.3822961070320823, disc_loss = 0.07980775571724569
Trained batch 88 in epoch 15, gen_loss = 0.38220735279361856, disc_loss = 0.07921808289384909
Trained batch 89 in epoch 15, gen_loss = 0.38224136299557154, disc_loss = 0.07877125641744998
Trained batch 90 in epoch 15, gen_loss = 0.382474232178468, disc_loss = 0.07975662246878658
Trained batch 91 in epoch 15, gen_loss = 0.38224156136098114, disc_loss = 0.08254377026637287
Trained batch 92 in epoch 15, gen_loss = 0.3818695596469346, disc_loss = 0.0828238081647664
Trained batch 93 in epoch 15, gen_loss = 0.3826535635806145, disc_loss = 0.08453957959415113
Trained batch 94 in epoch 15, gen_loss = 0.38163087462124073, disc_loss = 0.08566991593688726
Trained batch 95 in epoch 15, gen_loss = 0.3809909550473094, disc_loss = 0.08587718290315631
Trained batch 96 in epoch 15, gen_loss = 0.3808672707719901, disc_loss = 0.08581856101482492
Trained batch 97 in epoch 15, gen_loss = 0.3798464320752086, disc_loss = 0.08570976639926738
Trained batch 98 in epoch 15, gen_loss = 0.38000731847502967, disc_loss = 0.08516288617381243
Trained batch 99 in epoch 15, gen_loss = 0.37969838052988053, disc_loss = 0.08496630758978427
Trained batch 100 in epoch 15, gen_loss = 0.37943236485566245, disc_loss = 0.08481998344200968
Trained batch 101 in epoch 15, gen_loss = 0.38088366739890156, disc_loss = 0.08715097490223307
Trained batch 102 in epoch 15, gen_loss = 0.38131370185648356, disc_loss = 0.08701811927072342
Trained batch 103 in epoch 15, gen_loss = 0.3810815123411325, disc_loss = 0.0865464506115621
Trained batch 104 in epoch 15, gen_loss = 0.38130099234126863, disc_loss = 0.08583922220305318
Trained batch 105 in epoch 15, gen_loss = 0.3818095509173735, disc_loss = 0.08527575042274482
Trained batch 106 in epoch 15, gen_loss = 0.38172576583434487, disc_loss = 0.08463123624395823
Trained batch 107 in epoch 15, gen_loss = 0.38211857085978546, disc_loss = 0.08408262634960313
Trained batch 108 in epoch 15, gen_loss = 0.3821695947318996, disc_loss = 0.0835505490439064
Trained batch 109 in epoch 15, gen_loss = 0.3825966536998749, disc_loss = 0.08288498474285007
Trained batch 110 in epoch 15, gen_loss = 0.3827631803783211, disc_loss = 0.08254454047461082
Trained batch 111 in epoch 15, gen_loss = 0.38220279796847273, disc_loss = 0.08409616242196145
Trained batch 112 in epoch 15, gen_loss = 0.38309286996326614, disc_loss = 0.08589358796752923
Trained batch 113 in epoch 15, gen_loss = 0.3834981795465737, disc_loss = 0.08530386982551008
Trained batch 114 in epoch 15, gen_loss = 0.38318975438242375, disc_loss = 0.08673067922987368
Trained batch 115 in epoch 15, gen_loss = 0.3837431877337653, disc_loss = 0.08634245643745465
Trained batch 116 in epoch 15, gen_loss = 0.3839960062605703, disc_loss = 0.08584181216951364
Trained batch 117 in epoch 15, gen_loss = 0.384003156575106, disc_loss = 0.08536897516825188
Trained batch 118 in epoch 15, gen_loss = 0.3836817273071834, disc_loss = 0.08487544929561745
Trained batch 119 in epoch 15, gen_loss = 0.3832970085243384, disc_loss = 0.08447108027370026
Trained batch 120 in epoch 15, gen_loss = 0.3835243691097606, disc_loss = 0.08437929186231095
Trained batch 121 in epoch 15, gen_loss = 0.3833113752427648, disc_loss = 0.08503083421344884
Trained batch 122 in epoch 15, gen_loss = 0.38298641181573634, disc_loss = 0.08592081264539705
Trained batch 123 in epoch 15, gen_loss = 0.38342855390041103, disc_loss = 0.08648207760415971
Trained batch 124 in epoch 15, gen_loss = 0.3837739324569702, disc_loss = 0.08594026108831167
Trained batch 125 in epoch 15, gen_loss = 0.3837244915110724, disc_loss = 0.08589850918256811
Trained batch 126 in epoch 15, gen_loss = 0.38398690768114224, disc_loss = 0.08537647403101986
Trained batch 127 in epoch 15, gen_loss = 0.3845577829051763, disc_loss = 0.08508504507335601
Trained batch 128 in epoch 15, gen_loss = 0.38456146638522776, disc_loss = 0.08507368724446657
Trained batch 129 in epoch 15, gen_loss = 0.3848318595152635, disc_loss = 0.08463304097979114
Trained batch 130 in epoch 15, gen_loss = 0.38498893084416863, disc_loss = 0.08440934693910011
Trained batch 131 in epoch 15, gen_loss = 0.38399337728818256, disc_loss = 0.08476465864981891
Trained batch 132 in epoch 15, gen_loss = 0.3847902466479997, disc_loss = 0.08523081067277301
Trained batch 133 in epoch 15, gen_loss = 0.3847898249305896, disc_loss = 0.08481318544624235
Trained batch 134 in epoch 15, gen_loss = 0.3850675485752247, disc_loss = 0.0842439626240068
Trained batch 135 in epoch 15, gen_loss = 0.3848930457059075, disc_loss = 0.08377311423913959
Trained batch 136 in epoch 15, gen_loss = 0.38471933851276874, disc_loss = 0.08333223536066765
Trained batch 137 in epoch 15, gen_loss = 0.384602719243022, disc_loss = 0.08308491267371869
Trained batch 138 in epoch 15, gen_loss = 0.38429885866830676, disc_loss = 0.08481284573995809
Trained batch 139 in epoch 15, gen_loss = 0.3851952048284667, disc_loss = 0.08628956659563951
Trained batch 140 in epoch 15, gen_loss = 0.3846219560356005, disc_loss = 0.08604509129803231
Trained batch 141 in epoch 15, gen_loss = 0.3840130091133252, disc_loss = 0.08610249851161325
Trained batch 142 in epoch 15, gen_loss = 0.38442299749467757, disc_loss = 0.0860072320678851
Trained batch 143 in epoch 15, gen_loss = 0.38457711910208064, disc_loss = 0.08583070529210898
Trained batch 144 in epoch 15, gen_loss = 0.38470259144388397, disc_loss = 0.0853357397469467
Trained batch 145 in epoch 15, gen_loss = 0.38455448718103646, disc_loss = 0.08506263743397104
Trained batch 146 in epoch 15, gen_loss = 0.38469584336897145, disc_loss = 0.08488244595652332
Trained batch 147 in epoch 15, gen_loss = 0.38540483608439163, disc_loss = 0.0845195961851828
Trained batch 148 in epoch 15, gen_loss = 0.38564808216671015, disc_loss = 0.08427825827001525
Trained batch 149 in epoch 15, gen_loss = 0.3858128559589386, disc_loss = 0.08382794226830205
Trained batch 150 in epoch 15, gen_loss = 0.3852661392151915, disc_loss = 0.08354919031879168
Trained batch 151 in epoch 15, gen_loss = 0.38496958268316167, disc_loss = 0.08396843524870316
Trained batch 152 in epoch 15, gen_loss = 0.38585345963247464, disc_loss = 0.08498238989462455
Trained batch 153 in epoch 15, gen_loss = 0.3858204067914517, disc_loss = 0.08452009752562101
Trained batch 154 in epoch 15, gen_loss = 0.3855317586852658, disc_loss = 0.08445516977939875
Trained batch 155 in epoch 15, gen_loss = 0.3862783723534682, disc_loss = 0.08675104684721774
Trained batch 156 in epoch 15, gen_loss = 0.3861307086078984, disc_loss = 0.08666071522933473
Trained batch 157 in epoch 15, gen_loss = 0.3856517197210578, disc_loss = 0.08832274112685383
Trained batch 158 in epoch 15, gen_loss = 0.3861621385850247, disc_loss = 0.08819337713432575
Trained batch 159 in epoch 15, gen_loss = 0.385936820320785, disc_loss = 0.08855485980748198
Trained batch 160 in epoch 15, gen_loss = 0.38565130429978695, disc_loss = 0.08826224345667577
Trained batch 161 in epoch 15, gen_loss = 0.3855703224738439, disc_loss = 0.08797195067997148
Trained batch 162 in epoch 15, gen_loss = 0.3856043822926246, disc_loss = 0.08789446617996582
Trained batch 163 in epoch 15, gen_loss = 0.3855667128795531, disc_loss = 0.088073798676771
Trained batch 164 in epoch 15, gen_loss = 0.38592214331482394, disc_loss = 0.08794281583730922
Trained batch 165 in epoch 15, gen_loss = 0.38529856700495063, disc_loss = 0.08769446702853563
Trained batch 166 in epoch 15, gen_loss = 0.3857023846246525, disc_loss = 0.08741637477149328
Trained batch 167 in epoch 15, gen_loss = 0.38579602397623514, disc_loss = 0.08734582011432697
Trained batch 168 in epoch 15, gen_loss = 0.3855602238657912, disc_loss = 0.08782498548964601
Trained batch 169 in epoch 15, gen_loss = 0.38597636135185465, disc_loss = 0.0877313882276854
Trained batch 170 in epoch 15, gen_loss = 0.385941135255914, disc_loss = 0.08737937763485817
Trained batch 171 in epoch 15, gen_loss = 0.3855918540164482, disc_loss = 0.08720893464267773
Trained batch 172 in epoch 15, gen_loss = 0.38599410498073333, disc_loss = 0.08722899186107293
Trained batch 173 in epoch 15, gen_loss = 0.38557865376445066, disc_loss = 0.08732751469481094
Trained batch 174 in epoch 15, gen_loss = 0.385818601676396, disc_loss = 0.08720699203333684
Trained batch 175 in epoch 15, gen_loss = 0.38576331175863743, disc_loss = 0.08714831581826067
Trained batch 176 in epoch 15, gen_loss = 0.3856741299400222, disc_loss = 0.08812534417115193
Trained batch 177 in epoch 15, gen_loss = 0.3861959139617641, disc_loss = 0.08839173970241727
Trained batch 178 in epoch 15, gen_loss = 0.38598329095201117, disc_loss = 0.08808739099901315
Trained batch 179 in epoch 15, gen_loss = 0.38589668919642767, disc_loss = 0.08781089542123179
Trained batch 180 in epoch 15, gen_loss = 0.3857639296937384, disc_loss = 0.08745211601072089
Trained batch 181 in epoch 15, gen_loss = 0.38575120941623225, disc_loss = 0.08708489384850139
Trained batch 182 in epoch 15, gen_loss = 0.3858335451350186, disc_loss = 0.08676526566733266
Trained batch 183 in epoch 15, gen_loss = 0.3858346783596536, disc_loss = 0.08635772803656595
Trained batch 184 in epoch 15, gen_loss = 0.3854650840565965, disc_loss = 0.08619458323495613
Trained batch 185 in epoch 15, gen_loss = 0.38519561515059525, disc_loss = 0.08585686533541609
Trained batch 186 in epoch 15, gen_loss = 0.38521501820355175, disc_loss = 0.08550110284517952
Trained batch 187 in epoch 15, gen_loss = 0.3846958447644051, disc_loss = 0.08562952332059912
Trained batch 188 in epoch 15, gen_loss = 0.38492390308430585, disc_loss = 0.08545396552376804
Trained batch 189 in epoch 15, gen_loss = 0.3853420420696861, disc_loss = 0.08552543050854614
Trained batch 190 in epoch 15, gen_loss = 0.3851209685440463, disc_loss = 0.08600026221351005
Trained batch 191 in epoch 15, gen_loss = 0.3854250533816715, disc_loss = 0.08559002155864921
Trained batch 192 in epoch 15, gen_loss = 0.3855916202994826, disc_loss = 0.085293824625216
Trained batch 193 in epoch 15, gen_loss = 0.3860501627024916, disc_loss = 0.08494084609730035
Trained batch 194 in epoch 15, gen_loss = 0.3862882877007509, disc_loss = 0.08454935262218499
Trained batch 195 in epoch 15, gen_loss = 0.3864184701625182, disc_loss = 0.08414510632770097
Trained batch 196 in epoch 15, gen_loss = 0.38647162445305566, disc_loss = 0.0837511719029567
Trained batch 197 in epoch 15, gen_loss = 0.3868103034869589, disc_loss = 0.08336884281927287
Trained batch 198 in epoch 15, gen_loss = 0.38678283547636255, disc_loss = 0.08300134308879549
Trained batch 199 in epoch 15, gen_loss = 0.3863109867274761, disc_loss = 0.08289289043750614
Trained batch 200 in epoch 15, gen_loss = 0.3862676294288825, disc_loss = 0.08397050121734242
Trained batch 201 in epoch 15, gen_loss = 0.3867961879413907, disc_loss = 0.08399410300085892
Trained batch 202 in epoch 15, gen_loss = 0.3867822337913983, disc_loss = 0.08369170680293456
Trained batch 203 in epoch 15, gen_loss = 0.3868793750218317, disc_loss = 0.08339510365462333
Trained batch 204 in epoch 15, gen_loss = 0.3865935593116574, disc_loss = 0.08311396615988598
Trained batch 205 in epoch 15, gen_loss = 0.38653267500469984, disc_loss = 0.08277475705948993
Trained batch 206 in epoch 15, gen_loss = 0.3867239066656085, disc_loss = 0.08249064569545973
Trained batch 207 in epoch 15, gen_loss = 0.3865156537638261, disc_loss = 0.0821727540729066
Trained batch 208 in epoch 15, gen_loss = 0.3862379853520097, disc_loss = 0.08186006146309335
Trained batch 209 in epoch 15, gen_loss = 0.38629551728566486, disc_loss = 0.0819161829449946
Trained batch 210 in epoch 15, gen_loss = 0.38588721153295436, disc_loss = 0.08278824748709727
Trained batch 211 in epoch 15, gen_loss = 0.3860508854377945, disc_loss = 0.08259235749038744
Trained batch 212 in epoch 15, gen_loss = 0.3864480177281608, disc_loss = 0.08240229865107598
Trained batch 213 in epoch 15, gen_loss = 0.3865521068327895, disc_loss = 0.08226106533014746
Trained batch 214 in epoch 15, gen_loss = 0.38641415668088336, disc_loss = 0.08207744021661753
Trained batch 215 in epoch 15, gen_loss = 0.3860542020863957, disc_loss = 0.08252317521772864
Trained batch 216 in epoch 15, gen_loss = 0.3864215028725462, disc_loss = 0.08280582349610081
Trained batch 217 in epoch 15, gen_loss = 0.3867131109357974, disc_loss = 0.08250242994175455
Trained batch 218 in epoch 15, gen_loss = 0.38660848290408584, disc_loss = 0.08253583076865026
Trained batch 219 in epoch 15, gen_loss = 0.3869852124290033, disc_loss = 0.0829844104591757
Trained batch 220 in epoch 15, gen_loss = 0.3867795294765973, disc_loss = 0.08301703766308624
Trained batch 221 in epoch 15, gen_loss = 0.3866299645857768, disc_loss = 0.0827438906212715
Trained batch 222 in epoch 15, gen_loss = 0.38645277643417564, disc_loss = 0.08256995629920152
Trained batch 223 in epoch 15, gen_loss = 0.38629284128546715, disc_loss = 0.08294895017336655
Trained batch 224 in epoch 15, gen_loss = 0.38653911259439255, disc_loss = 0.08272966852204668
Trained batch 225 in epoch 15, gen_loss = 0.38653298289374965, disc_loss = 0.08277080290893142
Trained batch 226 in epoch 15, gen_loss = 0.38688101038533684, disc_loss = 0.08261026437537917
Trained batch 227 in epoch 15, gen_loss = 0.3870515180261512, disc_loss = 0.08242024463732123
Trained batch 228 in epoch 15, gen_loss = 0.38735663305203466, disc_loss = 0.08212628129332868
Trained batch 229 in epoch 15, gen_loss = 0.3872833464456641, disc_loss = 0.08202630877494813
Trained batch 230 in epoch 15, gen_loss = 0.38717806777912817, disc_loss = 0.08190185471853137
Trained batch 231 in epoch 15, gen_loss = 0.3874662021367714, disc_loss = 0.08162627513680992
Trained batch 232 in epoch 15, gen_loss = 0.3876146864737564, disc_loss = 0.08136340766313761
Trained batch 233 in epoch 15, gen_loss = 0.3873039601195572, disc_loss = 0.08174181361802113
Trained batch 234 in epoch 15, gen_loss = 0.3870638809305556, disc_loss = 0.08170888859857904
Trained batch 235 in epoch 15, gen_loss = 0.38769064919423246, disc_loss = 0.08163536016403114
Trained batch 236 in epoch 15, gen_loss = 0.38792006828613923, disc_loss = 0.081388400796848
Trained batch 237 in epoch 15, gen_loss = 0.38787399595525085, disc_loss = 0.08128791925411265
Trained batch 238 in epoch 15, gen_loss = 0.38811147025938314, disc_loss = 0.08105030719767554
Trained batch 239 in epoch 15, gen_loss = 0.3882387374838193, disc_loss = 0.08091949845353762
Trained batch 240 in epoch 15, gen_loss = 0.38827782337596306, disc_loss = 0.08089176420106928
Trained batch 241 in epoch 15, gen_loss = 0.38826617241398365, disc_loss = 0.08147689761701694
Trained batch 242 in epoch 15, gen_loss = 0.3882759820531916, disc_loss = 0.08139500837512467
Trained batch 243 in epoch 15, gen_loss = 0.3880736650746377, disc_loss = 0.08115904413346874
Trained batch 244 in epoch 15, gen_loss = 0.3879550862069033, disc_loss = 0.08125881228824051
Trained batch 245 in epoch 15, gen_loss = 0.38822664017599773, disc_loss = 0.08155569032864357
Trained batch 246 in epoch 15, gen_loss = 0.38792965853745154, disc_loss = 0.08255489911084715
Trained batch 247 in epoch 15, gen_loss = 0.3882124062267042, disc_loss = 0.08275490931625809
Trained batch 248 in epoch 15, gen_loss = 0.3883141069766508, disc_loss = 0.08264349269340315
Trained batch 249 in epoch 15, gen_loss = 0.38818389546871185, disc_loss = 0.08256632590293884
Trained batch 250 in epoch 15, gen_loss = 0.38802589470171833, disc_loss = 0.08241711500512651
Trained batch 251 in epoch 15, gen_loss = 0.3880646319852935, disc_loss = 0.08236756302889377
Trained batch 252 in epoch 15, gen_loss = 0.3883770995224889, disc_loss = 0.08229808653649605
Trained batch 253 in epoch 15, gen_loss = 0.3885524007748431, disc_loss = 0.08202462044258521
Trained batch 254 in epoch 15, gen_loss = 0.38862746135861265, disc_loss = 0.08197410465309433
Trained batch 255 in epoch 15, gen_loss = 0.3887051835190505, disc_loss = 0.08232514108385658
Trained batch 256 in epoch 15, gen_loss = 0.3882920855678009, disc_loss = 0.08271360758996427
Trained batch 257 in epoch 15, gen_loss = 0.3884793653968693, disc_loss = 0.08250983151816582
Trained batch 258 in epoch 15, gen_loss = 0.3885759161245869, disc_loss = 0.0822218189835836
Trained batch 259 in epoch 15, gen_loss = 0.3887585121851701, disc_loss = 0.08194164129045721
Trained batch 260 in epoch 15, gen_loss = 0.38862633682302133, disc_loss = 0.08172892556094004
Trained batch 261 in epoch 15, gen_loss = 0.38863250863461096, disc_loss = 0.08155406777967365
Trained batch 262 in epoch 15, gen_loss = 0.38879822630846, disc_loss = 0.08127448206746193
Trained batch 263 in epoch 15, gen_loss = 0.38898141998233215, disc_loss = 0.08098404999878822
Trained batch 264 in epoch 15, gen_loss = 0.3888356235792052, disc_loss = 0.08079733036036761
Trained batch 265 in epoch 15, gen_loss = 0.38858145912338915, disc_loss = 0.08074188274436427
Trained batch 266 in epoch 15, gen_loss = 0.38841168275486665, disc_loss = 0.08061234152104971
Trained batch 267 in epoch 15, gen_loss = 0.38832598535427404, disc_loss = 0.08052768214925457
Trained batch 268 in epoch 15, gen_loss = 0.3882712680832604, disc_loss = 0.0806694850464071
Trained batch 269 in epoch 15, gen_loss = 0.3883047021097607, disc_loss = 0.08046789012711357
Trained batch 270 in epoch 15, gen_loss = 0.38869530479406517, disc_loss = 0.08066204034231905
Trained batch 271 in epoch 15, gen_loss = 0.38873502601157217, disc_loss = 0.08077162159743774
Trained batch 272 in epoch 15, gen_loss = 0.38825603620909943, disc_loss = 0.08130904334177683
Trained batch 273 in epoch 15, gen_loss = 0.38871297773218505, disc_loss = 0.08141305700733062
Trained batch 274 in epoch 15, gen_loss = 0.38883005738258364, disc_loss = 0.08137005649507045
Trained batch 275 in epoch 15, gen_loss = 0.3886912126040113, disc_loss = 0.08142217365430965
Trained batch 276 in epoch 15, gen_loss = 0.38855084368037834, disc_loss = 0.08120216961129693
Trained batch 277 in epoch 15, gen_loss = 0.38841857841546584, disc_loss = 0.08179109237364514
Trained batch 278 in epoch 15, gen_loss = 0.3882402122875268, disc_loss = 0.08280087328485904
Trained batch 279 in epoch 15, gen_loss = 0.38837775705116134, disc_loss = 0.08288430288833167
Trained batch 280 in epoch 15, gen_loss = 0.38799197510468153, disc_loss = 0.08272797552689751
Trained batch 281 in epoch 15, gen_loss = 0.38828508851798715, disc_loss = 0.08256081154186887
Trained batch 282 in epoch 15, gen_loss = 0.38829987282887785, disc_loss = 0.08237110184959726
Trained batch 283 in epoch 15, gen_loss = 0.3880385621122911, disc_loss = 0.08254069143670126
Trained batch 284 in epoch 15, gen_loss = 0.38812413675743235, disc_loss = 0.0825643265587196
Trained batch 285 in epoch 15, gen_loss = 0.3878816802810122, disc_loss = 0.08237768763064088
Trained batch 286 in epoch 15, gen_loss = 0.38801146207786186, disc_loss = 0.08219136968774247
Trained batch 287 in epoch 15, gen_loss = 0.3876056724952327, disc_loss = 0.08231904555577785
Trained batch 288 in epoch 15, gen_loss = 0.3878414954693672, disc_loss = 0.08285341539442745
Trained batch 289 in epoch 15, gen_loss = 0.38767496203554086, disc_loss = 0.0826327487697889
Trained batch 290 in epoch 15, gen_loss = 0.3875413241050497, disc_loss = 0.08248762911844909
Trained batch 291 in epoch 15, gen_loss = 0.3874530774885661, disc_loss = 0.08262669157287846
Trained batch 292 in epoch 15, gen_loss = 0.3876844413654796, disc_loss = 0.0830217015519484
Trained batch 293 in epoch 15, gen_loss = 0.3875862825281766, disc_loss = 0.08295242838105377
Trained batch 294 in epoch 15, gen_loss = 0.3874975086268732, disc_loss = 0.0828576759009038
Trained batch 295 in epoch 15, gen_loss = 0.3879075293001291, disc_loss = 0.08294873893563007
Trained batch 296 in epoch 15, gen_loss = 0.3877869261434985, disc_loss = 0.08295139572536102
Trained batch 297 in epoch 15, gen_loss = 0.38785729352259796, disc_loss = 0.08309636637568474
Trained batch 298 in epoch 15, gen_loss = 0.38786872075154233, disc_loss = 0.08358909007797273
Trained batch 299 in epoch 15, gen_loss = 0.3875548450152079, disc_loss = 0.08376813761889934
Trained batch 300 in epoch 15, gen_loss = 0.38766454878043494, disc_loss = 0.0836607922499758
Trained batch 301 in epoch 15, gen_loss = 0.3876925959492361, disc_loss = 0.08348267159073164
Trained batch 302 in epoch 15, gen_loss = 0.38753157086891704, disc_loss = 0.08360124604389219
Trained batch 303 in epoch 15, gen_loss = 0.3877042947631133, disc_loss = 0.08392198546789587
Trained batch 304 in epoch 15, gen_loss = 0.3876971838904209, disc_loss = 0.08383816994848799
Trained batch 305 in epoch 15, gen_loss = 0.38777997524909724, disc_loss = 0.08362262674722991
Trained batch 306 in epoch 15, gen_loss = 0.38781616567400456, disc_loss = 0.08336718829427557
Trained batch 307 in epoch 15, gen_loss = 0.38762905235801426, disc_loss = 0.08313457066096462
Trained batch 308 in epoch 15, gen_loss = 0.38748000383762865, disc_loss = 0.08292671724020663
Trained batch 309 in epoch 15, gen_loss = 0.38762106126354584, disc_loss = 0.08270459985060076
Trained batch 310 in epoch 15, gen_loss = 0.3875362312487084, disc_loss = 0.08251036787435556
Trained batch 311 in epoch 15, gen_loss = 0.3873530634893821, disc_loss = 0.08233088619099596
Trained batch 312 in epoch 15, gen_loss = 0.38760956398214397, disc_loss = 0.08237726371080731
Trained batch 313 in epoch 15, gen_loss = 0.38767319955643575, disc_loss = 0.08219595471171627
Trained batch 314 in epoch 15, gen_loss = 0.3877158122403281, disc_loss = 0.08203369046132716
Trained batch 315 in epoch 15, gen_loss = 0.38783744703742523, disc_loss = 0.08184695637584487
Trained batch 316 in epoch 15, gen_loss = 0.38784544983120744, disc_loss = 0.08163737536228793
Trained batch 317 in epoch 15, gen_loss = 0.387799267873824, disc_loss = 0.08146267750962351
Trained batch 318 in epoch 15, gen_loss = 0.3879744713209266, disc_loss = 0.08135711569864548
Trained batch 319 in epoch 15, gen_loss = 0.38793497467413546, disc_loss = 0.08130830053705722
Trained batch 320 in epoch 15, gen_loss = 0.38788934947917025, disc_loss = 0.08131712426741917
Trained batch 321 in epoch 15, gen_loss = 0.3876399768065222, disc_loss = 0.08181802301395753
Trained batch 322 in epoch 15, gen_loss = 0.3880478586574826, disc_loss = 0.08209763335831025
Trained batch 323 in epoch 15, gen_loss = 0.3880585730075836, disc_loss = 0.08192330534443443
Trained batch 324 in epoch 15, gen_loss = 0.38789426198372473, disc_loss = 0.08222062761966999
Trained batch 325 in epoch 15, gen_loss = 0.3877476448296038, disc_loss = 0.08234392876731106
Trained batch 326 in epoch 15, gen_loss = 0.38783412460887107, disc_loss = 0.08217841246669445
Trained batch 327 in epoch 15, gen_loss = 0.3876719800073926, disc_loss = 0.08219379944181661
Trained batch 328 in epoch 15, gen_loss = 0.38765220149309804, disc_loss = 0.08237796105829416
Trained batch 329 in epoch 15, gen_loss = 0.38762040147275634, disc_loss = 0.08242460567165505
Trained batch 330 in epoch 15, gen_loss = 0.38755149468554473, disc_loss = 0.0822870704455138
Trained batch 331 in epoch 15, gen_loss = 0.38740194570946407, disc_loss = 0.08220299646393003
Trained batch 332 in epoch 15, gen_loss = 0.38766903768072614, disc_loss = 0.08228894518884095
Trained batch 333 in epoch 15, gen_loss = 0.3876900802293937, disc_loss = 0.08210598553592216
Trained batch 334 in epoch 15, gen_loss = 0.3874347516849859, disc_loss = 0.08193183608575544
Trained batch 335 in epoch 15, gen_loss = 0.38743355346932296, disc_loss = 0.08175693037143598
Trained batch 336 in epoch 15, gen_loss = 0.38742855553810956, disc_loss = 0.08183387009764106
Trained batch 337 in epoch 15, gen_loss = 0.38761442494110243, disc_loss = 0.08243785119069928
Trained batch 338 in epoch 15, gen_loss = 0.38752983400603663, disc_loss = 0.08274222725238596
Trained batch 339 in epoch 15, gen_loss = 0.3878158840186456, disc_loss = 0.0826249941252172
Trained batch 340 in epoch 15, gen_loss = 0.38777630079177117, disc_loss = 0.08242003049133373
Trained batch 341 in epoch 15, gen_loss = 0.3877353666470065, disc_loss = 0.08226373606247075
Trained batch 342 in epoch 15, gen_loss = 0.387782769543784, disc_loss = 0.08210719236425251
Trained batch 343 in epoch 15, gen_loss = 0.38766628200578135, disc_loss = 0.0819627856916943
Trained batch 344 in epoch 15, gen_loss = 0.38752595799556677, disc_loss = 0.08186258393731238
Trained batch 345 in epoch 15, gen_loss = 0.3876616032309615, disc_loss = 0.08191715530523588
Trained batch 346 in epoch 15, gen_loss = 0.3875019620749724, disc_loss = 0.08180938581385856
Trained batch 347 in epoch 15, gen_loss = 0.38752167594843895, disc_loss = 0.08178593134561062
Trained batch 348 in epoch 15, gen_loss = 0.3874629465249343, disc_loss = 0.08223722394513111
Trained batch 349 in epoch 15, gen_loss = 0.387696875674384, disc_loss = 0.08248792739585042
Trained batch 350 in epoch 15, gen_loss = 0.38791327598767406, disc_loss = 0.0822762920523853
Trained batch 351 in epoch 15, gen_loss = 0.387907360765067, disc_loss = 0.08210328456532973
Trained batch 352 in epoch 15, gen_loss = 0.38788099751594046, disc_loss = 0.08192527038506932
Trained batch 353 in epoch 15, gen_loss = 0.38775519395278674, disc_loss = 0.08177045993980463
Trained batch 354 in epoch 15, gen_loss = 0.38785765120680904, disc_loss = 0.08157363557322345
Trained batch 355 in epoch 15, gen_loss = 0.3877623477176334, disc_loss = 0.08156949669133161
Trained batch 356 in epoch 15, gen_loss = 0.38774675723551366, disc_loss = 0.08157381885202408
Trained batch 357 in epoch 15, gen_loss = 0.3878951700373069, disc_loss = 0.0822112606292039
Trained batch 358 in epoch 15, gen_loss = 0.3877828502223352, disc_loss = 0.08207918249309312
Trained batch 359 in epoch 15, gen_loss = 0.38782167492641345, disc_loss = 0.08228221422113065
Trained batch 360 in epoch 15, gen_loss = 0.3879138838881601, disc_loss = 0.08264836803377913
Trained batch 361 in epoch 15, gen_loss = 0.3877375182690541, disc_loss = 0.08270545371998493
Trained batch 362 in epoch 15, gen_loss = 0.38785690143088664, disc_loss = 0.08259445078127066
Trained batch 363 in epoch 15, gen_loss = 0.3879978339914437, disc_loss = 0.08245303087540298
Trained batch 364 in epoch 15, gen_loss = 0.3879084630371773, disc_loss = 0.08234420110254663
Trained batch 365 in epoch 15, gen_loss = 0.3876241988660208, disc_loss = 0.08244205325017454
Trained batch 366 in epoch 15, gen_loss = 0.3878106404227847, disc_loss = 0.08275354689885468
Trained batch 367 in epoch 15, gen_loss = 0.38781732830988325, disc_loss = 0.0830793943352309
Trained batch 368 in epoch 15, gen_loss = 0.38788216829622985, disc_loss = 0.0831368032888305
Trained batch 369 in epoch 15, gen_loss = 0.38782427705623007, disc_loss = 0.08301343636687945
Trained batch 370 in epoch 15, gen_loss = 0.3876410720322653, disc_loss = 0.08293863986129307
Trained batch 371 in epoch 15, gen_loss = 0.3876397134636038, disc_loss = 0.08296744409017265
Trained batch 372 in epoch 15, gen_loss = 0.387560383883622, disc_loss = 0.0828720350842174
Trained batch 373 in epoch 15, gen_loss = 0.3876398118900105, disc_loss = 0.0826999191020461
Trained batch 374 in epoch 15, gen_loss = 0.38774567953745526, disc_loss = 0.08252971358845632
Trained batch 375 in epoch 15, gen_loss = 0.38785061311531577, disc_loss = 0.08236265879748587
Trained batch 376 in epoch 15, gen_loss = 0.38800571024892183, disc_loss = 0.08227743032272282
Trained batch 377 in epoch 15, gen_loss = 0.388150177383549, disc_loss = 0.08211119113509696
Trained batch 378 in epoch 15, gen_loss = 0.38808072478286826, disc_loss = 0.08197964202258785
Trained batch 379 in epoch 15, gen_loss = 0.3880962912189333, disc_loss = 0.0821460849875094
Trained batch 380 in epoch 15, gen_loss = 0.38814663323830434, disc_loss = 0.08201444027040965
Trained batch 381 in epoch 15, gen_loss = 0.38811840725506785, disc_loss = 0.08201046870455769
Trained batch 382 in epoch 15, gen_loss = 0.38790903927140696, disc_loss = 0.08234814409769624
Trained batch 383 in epoch 15, gen_loss = 0.3881131251497815, disc_loss = 0.08270123602172437
Trained batch 384 in epoch 15, gen_loss = 0.38819130496545273, disc_loss = 0.08252580076843113
Trained batch 385 in epoch 15, gen_loss = 0.3881934600944964, disc_loss = 0.0825804350173844
Trained batch 386 in epoch 15, gen_loss = 0.38823184994764104, disc_loss = 0.08255872571268132
Trained batch 387 in epoch 15, gen_loss = 0.38782178756502483, disc_loss = 0.08280166601474137
Trained batch 388 in epoch 15, gen_loss = 0.3880576987805894, disc_loss = 0.0829167721702078
Trained batch 389 in epoch 15, gen_loss = 0.38808078246238903, disc_loss = 0.08278426627318064
Trained batch 390 in epoch 15, gen_loss = 0.38804717304761455, disc_loss = 0.08294199506187683
Trained batch 391 in epoch 15, gen_loss = 0.38818944230371594, disc_loss = 0.08328392748169754
Trained batch 392 in epoch 15, gen_loss = 0.3882736184518149, disc_loss = 0.08320412693815377
Trained batch 393 in epoch 15, gen_loss = 0.3882848323904318, disc_loss = 0.08308706963009338
Trained batch 394 in epoch 15, gen_loss = 0.38820321167571636, disc_loss = 0.08303418879078914
Trained batch 395 in epoch 15, gen_loss = 0.38814687661149283, disc_loss = 0.08303237178673346
Trained batch 396 in epoch 15, gen_loss = 0.38818068047915055, disc_loss = 0.08304297849911287
Trained batch 397 in epoch 15, gen_loss = 0.3884170692619966, disc_loss = 0.08301355630795859
Trained batch 398 in epoch 15, gen_loss = 0.3883023439045239, disc_loss = 0.0833940529976423
Trained batch 399 in epoch 15, gen_loss = 0.38858203195035457, disc_loss = 0.08363751613534987
Trained batch 400 in epoch 15, gen_loss = 0.38878286813857255, disc_loss = 0.08360753647815854
Trained batch 401 in epoch 15, gen_loss = 0.3886585560307574, disc_loss = 0.08400542814451367
Trained batch 402 in epoch 15, gen_loss = 0.388797898890067, disc_loss = 0.08382322093837019
Trained batch 403 in epoch 15, gen_loss = 0.38892203222702043, disc_loss = 0.08376080676507537
Trained batch 404 in epoch 15, gen_loss = 0.3889717717965444, disc_loss = 0.08360105440204527
Trained batch 405 in epoch 15, gen_loss = 0.3888760088699792, disc_loss = 0.08371263665371928
Trained batch 406 in epoch 15, gen_loss = 0.38888528664809185, disc_loss = 0.08381698480109324
Trained batch 407 in epoch 15, gen_loss = 0.38900696252490957, disc_loss = 0.08363819772870663
Trained batch 408 in epoch 15, gen_loss = 0.3889025434450882, disc_loss = 0.08401599738173059
Trained batch 409 in epoch 15, gen_loss = 0.3890842830989419, disc_loss = 0.08448408144730621
Trained batch 410 in epoch 15, gen_loss = 0.388917010195934, disc_loss = 0.08439353088918539
Trained batch 411 in epoch 15, gen_loss = 0.3890042429410138, disc_loss = 0.08430164136914807
Trained batch 412 in epoch 15, gen_loss = 0.3890353070332987, disc_loss = 0.0841920743617466
Trained batch 413 in epoch 15, gen_loss = 0.3889432213300668, disc_loss = 0.08412360258238472
Trained batch 414 in epoch 15, gen_loss = 0.3891332160277539, disc_loss = 0.08398042021835425
Trained batch 415 in epoch 15, gen_loss = 0.38897943611328417, disc_loss = 0.08403901817151703
Trained batch 416 in epoch 15, gen_loss = 0.3889862951471937, disc_loss = 0.0839792232674589
Trained batch 417 in epoch 15, gen_loss = 0.38912262065273723, disc_loss = 0.08382606347710893
Trained batch 418 in epoch 15, gen_loss = 0.3888514182732612, disc_loss = 0.08381801820526828
Trained batch 419 in epoch 15, gen_loss = 0.3889318457671574, disc_loss = 0.0837012744020848
Trained batch 420 in epoch 15, gen_loss = 0.3890286310976305, disc_loss = 0.08355143144195833
Trained batch 421 in epoch 15, gen_loss = 0.38884597769563234, disc_loss = 0.08354287668709506
Trained batch 422 in epoch 15, gen_loss = 0.3890609791938295, disc_loss = 0.08340044387442282
Trained batch 423 in epoch 15, gen_loss = 0.38907725532662196, disc_loss = 0.08325561555102468
Trained batch 424 in epoch 15, gen_loss = 0.3889306750718285, disc_loss = 0.08324047636459855
Trained batch 425 in epoch 15, gen_loss = 0.38891990944533283, disc_loss = 0.08323981250011026
Trained batch 426 in epoch 15, gen_loss = 0.38903434361730305, disc_loss = 0.08348686861384669
Trained batch 427 in epoch 15, gen_loss = 0.3889541697000789, disc_loss = 0.08415242685788424
Trained batch 428 in epoch 15, gen_loss = 0.3890426482631888, disc_loss = 0.08409342885295272
Trained batch 429 in epoch 15, gen_loss = 0.3891537142354389, disc_loss = 0.08392689158316961
Trained batch 430 in epoch 15, gen_loss = 0.38919858976749144, disc_loss = 0.08376422165536479
Trained batch 431 in epoch 15, gen_loss = 0.3891558658193659, disc_loss = 0.08363463700947317
Trained batch 432 in epoch 15, gen_loss = 0.3891964956739483, disc_loss = 0.08353056568291047
Trained batch 433 in epoch 15, gen_loss = 0.3894316910461347, disc_loss = 0.08337411434874625
Trained batch 434 in epoch 15, gen_loss = 0.3894189842816057, disc_loss = 0.08326084278309825
Trained batch 435 in epoch 15, gen_loss = 0.3893235141257627, disc_loss = 0.08321459935080909
Trained batch 436 in epoch 15, gen_loss = 0.3892797400804079, disc_loss = 0.08310652232049054
Trained batch 437 in epoch 15, gen_loss = 0.3891788573433819, disc_loss = 0.08300665155537937
Trained batch 438 in epoch 15, gen_loss = 0.3890683565433042, disc_loss = 0.08306009125745174
Trained batch 439 in epoch 15, gen_loss = 0.38919668766585264, disc_loss = 0.08318631000689823
Trained batch 440 in epoch 15, gen_loss = 0.3893396204291017, disc_loss = 0.0830156405069897
Trained batch 441 in epoch 15, gen_loss = 0.38929691101630887, disc_loss = 0.08303782680784078
Trained batch 442 in epoch 15, gen_loss = 0.3893390593894717, disc_loss = 0.08305026030558967
Trained batch 443 in epoch 15, gen_loss = 0.38913403572262945, disc_loss = 0.08291639196938155
Trained batch 444 in epoch 15, gen_loss = 0.3890893132499095, disc_loss = 0.08276591179787778
Trained batch 445 in epoch 15, gen_loss = 0.38908548880318355, disc_loss = 0.08271932754991368
Trained batch 446 in epoch 15, gen_loss = 0.38928235157224156, disc_loss = 0.08263735568371729
Trained batch 447 in epoch 15, gen_loss = 0.38915997204769937, disc_loss = 0.08255560400305383
Trained batch 448 in epoch 15, gen_loss = 0.3891383386932662, disc_loss = 0.08249789430139656
Trained batch 449 in epoch 15, gen_loss = 0.38936847752994963, disc_loss = 0.08243023531511426
Trained batch 450 in epoch 15, gen_loss = 0.38944439401647735, disc_loss = 0.0822859465923086
Trained batch 451 in epoch 15, gen_loss = 0.38925490159112797, disc_loss = 0.08226776328885647
Trained batch 452 in epoch 15, gen_loss = 0.3893808321842295, disc_loss = 0.08222746809381194
Trained batch 453 in epoch 15, gen_loss = 0.38926803665276666, disc_loss = 0.08211001544362057
Trained batch 454 in epoch 15, gen_loss = 0.3892729953750149, disc_loss = 0.08229888887809855
Trained batch 455 in epoch 15, gen_loss = 0.3893525256660947, disc_loss = 0.0822841945868149
Trained batch 456 in epoch 15, gen_loss = 0.3893942219292831, disc_loss = 0.08215094185118406
Trained batch 457 in epoch 15, gen_loss = 0.38921233341423184, disc_loss = 0.0822034244604539
Trained batch 458 in epoch 15, gen_loss = 0.38945990976165323, disc_loss = 0.0824833683089266
Trained batch 459 in epoch 15, gen_loss = 0.38939885853425316, disc_loss = 0.08234537574462593
Trained batch 460 in epoch 15, gen_loss = 0.3893158634934663, disc_loss = 0.0823886630644541
Trained batch 461 in epoch 15, gen_loss = 0.38945686933282136, disc_loss = 0.08240485739857926
Trained batch 462 in epoch 15, gen_loss = 0.38994447703495394, disc_loss = 0.08234048055657879
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.34526702761650085, disc_loss = 0.13143093883991241
Trained batch 1 in epoch 16, gen_loss = 0.3869916945695877, disc_loss = 0.08097903430461884
Trained batch 2 in epoch 16, gen_loss = 0.39104482531547546, disc_loss = 0.059496499598026276
Trained batch 3 in epoch 16, gen_loss = 0.39706742763519287, disc_loss = 0.04868121491745114
Trained batch 4 in epoch 16, gen_loss = 0.39540990591049197, disc_loss = 0.04272021949291229
Trained batch 5 in epoch 16, gen_loss = 0.3867795467376709, disc_loss = 0.0431199756761392
Trained batch 6 in epoch 16, gen_loss = 0.37609638060842243, disc_loss = 0.0613861009478569
Trained batch 7 in epoch 16, gen_loss = 0.38989704474806786, disc_loss = 0.10439423937350512
Trained batch 8 in epoch 16, gen_loss = 0.3901526265674167, disc_loss = 0.09648793356286155
Trained batch 9 in epoch 16, gen_loss = 0.3848979949951172, disc_loss = 0.10681563094258309
Trained batch 10 in epoch 16, gen_loss = 0.38919888030398975, disc_loss = 0.10388518260283904
Trained batch 11 in epoch 16, gen_loss = 0.3914352183540662, disc_loss = 0.09811167418956757
Trained batch 12 in epoch 16, gen_loss = 0.3902593507216527, disc_loss = 0.0928661129795588
Trained batch 13 in epoch 16, gen_loss = 0.38510289575372425, disc_loss = 0.09073346853256226
Trained batch 14 in epoch 16, gen_loss = 0.38484785954157513, disc_loss = 0.08704326997200648
Trained batch 15 in epoch 16, gen_loss = 0.38347216323018074, disc_loss = 0.08569427020847797
Trained batch 16 in epoch 16, gen_loss = 0.3830995524630827, disc_loss = 0.10388185522135567
Trained batch 17 in epoch 16, gen_loss = 0.37635524902078843, disc_loss = 0.11004225661357243
Trained batch 18 in epoch 16, gen_loss = 0.3781623793275733, disc_loss = 0.1189241244604713
Trained batch 19 in epoch 16, gen_loss = 0.37834803462028505, disc_loss = 0.12108234241604805
Trained batch 20 in epoch 16, gen_loss = 0.37389397621154785, disc_loss = 0.11877399612040747
Trained batch 21 in epoch 16, gen_loss = 0.3714335845275359, disc_loss = 0.12031684544953433
Trained batch 22 in epoch 16, gen_loss = 0.3697456471298052, disc_loss = 0.1169718662681787
Trained batch 23 in epoch 16, gen_loss = 0.3701729215681553, disc_loss = 0.11362687591463327
Trained batch 24 in epoch 16, gen_loss = 0.37129446625709533, disc_loss = 0.11119308039546012
Trained batch 25 in epoch 16, gen_loss = 0.36984597834256977, disc_loss = 0.11091353529347824
Trained batch 26 in epoch 16, gen_loss = 0.3697525616045351, disc_loss = 0.1090424498198209
Trained batch 27 in epoch 16, gen_loss = 0.36934234095471247, disc_loss = 0.10613029875925609
Trained batch 28 in epoch 16, gen_loss = 0.3663444847896181, disc_loss = 0.10545039947690635
Trained batch 29 in epoch 16, gen_loss = 0.3681668281555176, disc_loss = 0.10265283000965914
Trained batch 30 in epoch 16, gen_loss = 0.37082442737394766, disc_loss = 0.10058604889819699
Trained batch 31 in epoch 16, gen_loss = 0.37080943677574396, disc_loss = 0.1004924465669319
Trained batch 32 in epoch 16, gen_loss = 0.3690962005745281, disc_loss = 0.10126428565744197
Trained batch 33 in epoch 16, gen_loss = 0.3715379536151886, disc_loss = 0.10715769702459083
Trained batch 34 in epoch 16, gen_loss = 0.3707830233233316, disc_loss = 0.1079337821475097
Trained batch 35 in epoch 16, gen_loss = 0.37107078979412716, disc_loss = 0.10606941404855913
Trained batch 36 in epoch 16, gen_loss = 0.3719369398581015, disc_loss = 0.10361268612984065
Trained batch 37 in epoch 16, gen_loss = 0.3732354397836484, disc_loss = 0.10147763122069209
Trained batch 38 in epoch 16, gen_loss = 0.3727607597143222, disc_loss = 0.09998138688313656
Trained batch 39 in epoch 16, gen_loss = 0.3735653065145016, disc_loss = 0.0997636292129755
Trained batch 40 in epoch 16, gen_loss = 0.3713379560447321, disc_loss = 0.10332508603247201
Trained batch 41 in epoch 16, gen_loss = 0.3736590303125836, disc_loss = 0.10253527015447617
Trained batch 42 in epoch 16, gen_loss = 0.3742909424526747, disc_loss = 0.10279870327821998
Trained batch 43 in epoch 16, gen_loss = 0.37383706258101895, disc_loss = 0.1051844312724742
Trained batch 44 in epoch 16, gen_loss = 0.3745225489139557, disc_loss = 0.10460498515102598
Trained batch 45 in epoch 16, gen_loss = 0.37518145467924036, disc_loss = 0.10298439633587132
Trained batch 46 in epoch 16, gen_loss = 0.37590958590203144, disc_loss = 0.10130090821296611
Trained batch 47 in epoch 16, gen_loss = 0.3754375409334898, disc_loss = 0.10003381160398324
Trained batch 48 in epoch 16, gen_loss = 0.37562782302194714, disc_loss = 0.09870044233239426
Trained batch 49 in epoch 16, gen_loss = 0.3754860103130341, disc_loss = 0.09703029939904809
Trained batch 50 in epoch 16, gen_loss = 0.374940177973579, disc_loss = 0.09892871897375467
Trained batch 51 in epoch 16, gen_loss = 0.3733512581540988, disc_loss = 0.10671807805864283
Trained batch 52 in epoch 16, gen_loss = 0.37378409279967256, disc_loss = 0.10758956628939453
Trained batch 53 in epoch 16, gen_loss = 0.3740391057950479, disc_loss = 0.10856157080787751
Trained batch 54 in epoch 16, gen_loss = 0.3743345840410753, disc_loss = 0.10843259781937707
Trained batch 55 in epoch 16, gen_loss = 0.37252951732703615, disc_loss = 0.10861523856874555
Trained batch 56 in epoch 16, gen_loss = 0.3726619482040405, disc_loss = 0.10872803035339243
Trained batch 57 in epoch 16, gen_loss = 0.37361332928312235, disc_loss = 0.10883909394836118
Trained batch 58 in epoch 16, gen_loss = 0.37430358034069255, disc_loss = 0.10772484422550868
Trained batch 59 in epoch 16, gen_loss = 0.3747864971558253, disc_loss = 0.1071681728741775
Trained batch 60 in epoch 16, gen_loss = 0.3747539173384182, disc_loss = 0.10643613175107319
Trained batch 61 in epoch 16, gen_loss = 0.3744137743788381, disc_loss = 0.10654667532071471
Trained batch 62 in epoch 16, gen_loss = 0.37534030798881773, disc_loss = 0.10592504444399051
Trained batch 63 in epoch 16, gen_loss = 0.37562799034640193, disc_loss = 0.1057460794254439
Trained batch 64 in epoch 16, gen_loss = 0.3762466719517341, disc_loss = 0.10488800746030533
Trained batch 65 in epoch 16, gen_loss = 0.3772862558112, disc_loss = 0.10357535061793345
Trained batch 66 in epoch 16, gen_loss = 0.37867852244804157, disc_loss = 0.10264754658147915
Trained batch 67 in epoch 16, gen_loss = 0.37794069858158336, disc_loss = 0.10152813297805979
Trained batch 68 in epoch 16, gen_loss = 0.37836777472841565, disc_loss = 0.10027200060532145
Trained batch 69 in epoch 16, gen_loss = 0.3774415011916842, disc_loss = 0.09965608419318284
Trained batch 70 in epoch 16, gen_loss = 0.3789092885776305, disc_loss = 0.09911760626177132
Trained batch 71 in epoch 16, gen_loss = 0.3786994657582707, disc_loss = 0.0984000851943468
Trained batch 72 in epoch 16, gen_loss = 0.3778758763450466, disc_loss = 0.10190445170674013
Trained batch 73 in epoch 16, gen_loss = 0.37993054494664474, disc_loss = 0.10336508366556184
Trained batch 74 in epoch 16, gen_loss = 0.3802474292119344, disc_loss = 0.10268828279028336
Trained batch 75 in epoch 16, gen_loss = 0.38054403035264267, disc_loss = 0.10232785467891709
Trained batch 76 in epoch 16, gen_loss = 0.3812534464644147, disc_loss = 0.10166902260782269
Trained batch 77 in epoch 16, gen_loss = 0.3809829919766157, disc_loss = 0.10074664304892604
Trained batch 78 in epoch 16, gen_loss = 0.3805029445056674, disc_loss = 0.10072117267011464
Trained batch 79 in epoch 16, gen_loss = 0.3810114610940218, disc_loss = 0.09977139356778934
Trained batch 80 in epoch 16, gen_loss = 0.3813008103105757, disc_loss = 0.09939340815913898
Trained batch 81 in epoch 16, gen_loss = 0.3814127870449206, disc_loss = 0.09911498837400137
Trained batch 82 in epoch 16, gen_loss = 0.3821052912488041, disc_loss = 0.09825541163199997
Trained batch 83 in epoch 16, gen_loss = 0.3825849365620386, disc_loss = 0.09756654801423706
Trained batch 84 in epoch 16, gen_loss = 0.38268249490681816, disc_loss = 0.09798651967635925
Trained batch 85 in epoch 16, gen_loss = 0.38403860531574074, disc_loss = 0.09974646203349842
Trained batch 86 in epoch 16, gen_loss = 0.3842565530333026, disc_loss = 0.09879359366350818
Trained batch 87 in epoch 16, gen_loss = 0.3845026425339959, disc_loss = 0.09800153698729859
Trained batch 88 in epoch 16, gen_loss = 0.3839065737268898, disc_loss = 0.0974769044688411
Trained batch 89 in epoch 16, gen_loss = 0.3842419985267851, disc_loss = 0.09714612678314248
Trained batch 90 in epoch 16, gen_loss = 0.38403721170111016, disc_loss = 0.0963699309319094
Trained batch 91 in epoch 16, gen_loss = 0.38353432002274884, disc_loss = 0.09656093019546698
Trained batch 92 in epoch 16, gen_loss = 0.38325709136583475, disc_loss = 0.09681784931410065
Trained batch 93 in epoch 16, gen_loss = 0.3829492127641718, disc_loss = 0.096369672418037
Trained batch 94 in epoch 16, gen_loss = 0.38242937891106854, disc_loss = 0.09605286334102091
Trained batch 95 in epoch 16, gen_loss = 0.38241625918696326, disc_loss = 0.0955397495708894
Trained batch 96 in epoch 16, gen_loss = 0.3828537995667802, disc_loss = 0.09566914141370156
Trained batch 97 in epoch 16, gen_loss = 0.38306172252917775, disc_loss = 0.09640150316705813
Trained batch 98 in epoch 16, gen_loss = 0.38457982437779203, disc_loss = 0.09653230603182256
Trained batch 99 in epoch 16, gen_loss = 0.3853373810648918, disc_loss = 0.09575394564308226
Trained batch 100 in epoch 16, gen_loss = 0.38433995931455406, disc_loss = 0.0972641730902366
Trained batch 101 in epoch 16, gen_loss = 0.38460151003856285, disc_loss = 0.09717369978955272
Trained batch 102 in epoch 16, gen_loss = 0.3838929510811, disc_loss = 0.09632237771869574
Trained batch 103 in epoch 16, gen_loss = 0.383901498065545, disc_loss = 0.09558097727131099
Trained batch 104 in epoch 16, gen_loss = 0.3836028959069933, disc_loss = 0.09518032019869202
Trained batch 105 in epoch 16, gen_loss = 0.38376928865909576, disc_loss = 0.0953641725299915
Trained batch 106 in epoch 16, gen_loss = 0.3831078256959113, disc_loss = 0.0968733664132028
Trained batch 107 in epoch 16, gen_loss = 0.383511472079489, disc_loss = 0.09631524306584012
Trained batch 108 in epoch 16, gen_loss = 0.3829242343749475, disc_loss = 0.09616076162751389
Trained batch 109 in epoch 16, gen_loss = 0.38351684510707856, disc_loss = 0.09720983812585474
Trained batch 110 in epoch 16, gen_loss = 0.3824666236434971, disc_loss = 0.09898012885739943
Trained batch 111 in epoch 16, gen_loss = 0.38238505247448173, disc_loss = 0.0986425633725178
Trained batch 112 in epoch 16, gen_loss = 0.3822447697145749, disc_loss = 0.09874065595357555
Trained batch 113 in epoch 16, gen_loss = 0.3822372411949593, disc_loss = 0.09875081864332683
Trained batch 114 in epoch 16, gen_loss = 0.3820321938265925, disc_loss = 0.09907107151558865
Trained batch 115 in epoch 16, gen_loss = 0.3823231538308078, disc_loss = 0.09840989128108425
Trained batch 116 in epoch 16, gen_loss = 0.38239479599854886, disc_loss = 0.09776300022330804
Trained batch 117 in epoch 16, gen_loss = 0.3823808487189018, disc_loss = 0.09736090111625144
Trained batch 118 in epoch 16, gen_loss = 0.38223526633086324, disc_loss = 0.09800343549645998
Trained batch 119 in epoch 16, gen_loss = 0.38328467930356663, disc_loss = 0.10057056592001269
Trained batch 120 in epoch 16, gen_loss = 0.3835843015800823, disc_loss = 0.10003146660814355
Trained batch 121 in epoch 16, gen_loss = 0.3835155995654278, disc_loss = 0.09959819139607373
Trained batch 122 in epoch 16, gen_loss = 0.3832846116728899, disc_loss = 0.09938589098098559
Trained batch 123 in epoch 16, gen_loss = 0.3837193541469113, disc_loss = 0.09976817543558296
Trained batch 124 in epoch 16, gen_loss = 0.3838156487941742, disc_loss = 0.09918366726487875
Trained batch 125 in epoch 16, gen_loss = 0.3840582515039141, disc_loss = 0.09875849944110664
Trained batch 126 in epoch 16, gen_loss = 0.38385722252327625, disc_loss = 0.09821786367019096
Trained batch 127 in epoch 16, gen_loss = 0.3838212245609611, disc_loss = 0.09782411398919066
Trained batch 128 in epoch 16, gen_loss = 0.3838946588279665, disc_loss = 0.09879835593232582
Trained batch 129 in epoch 16, gen_loss = 0.384261791064189, disc_loss = 0.09930376819549845
Trained batch 130 in epoch 16, gen_loss = 0.38377016282263604, disc_loss = 0.09894568432577466
Trained batch 131 in epoch 16, gen_loss = 0.3838571867708004, disc_loss = 0.0985113514629616
Trained batch 132 in epoch 16, gen_loss = 0.3836086656814231, disc_loss = 0.09812842056687389
Trained batch 133 in epoch 16, gen_loss = 0.3835055794733674, disc_loss = 0.0975386417165065
Trained batch 134 in epoch 16, gen_loss = 0.3835027975064737, disc_loss = 0.09738516130795082
Trained batch 135 in epoch 16, gen_loss = 0.38379767602857423, disc_loss = 0.09741649751359706
Trained batch 136 in epoch 16, gen_loss = 0.38375921558289633, disc_loss = 0.09708909858290078
Trained batch 137 in epoch 16, gen_loss = 0.38347943321518274, disc_loss = 0.09696902944098997
Trained batch 138 in epoch 16, gen_loss = 0.38329348975805927, disc_loss = 0.09713190353790419
Trained batch 139 in epoch 16, gen_loss = 0.3829830267599651, disc_loss = 0.09793071022390255
Trained batch 140 in epoch 16, gen_loss = 0.38266271902314314, disc_loss = 0.09838894156884428
Trained batch 141 in epoch 16, gen_loss = 0.382923401997123, disc_loss = 0.09808022042893817
Trained batch 142 in epoch 16, gen_loss = 0.38284949114272643, disc_loss = 0.09786943066865206
Trained batch 143 in epoch 16, gen_loss = 0.38291828023890656, disc_loss = 0.09750249117173047
Trained batch 144 in epoch 16, gen_loss = 0.3824771075413145, disc_loss = 0.09733897118090555
Trained batch 145 in epoch 16, gen_loss = 0.38278543540876203, disc_loss = 0.09800048682149755
Trained batch 146 in epoch 16, gen_loss = 0.3826839901557585, disc_loss = 0.09763905653717364
Trained batch 147 in epoch 16, gen_loss = 0.3824492475470981, disc_loss = 0.09726489812915994
Trained batch 148 in epoch 16, gen_loss = 0.3829206116247497, disc_loss = 0.09817385937918553
Trained batch 149 in epoch 16, gen_loss = 0.3826217406988144, disc_loss = 0.1005868310170869
Trained batch 150 in epoch 16, gen_loss = 0.38238863479222684, disc_loss = 0.10013160952644436
Trained batch 151 in epoch 16, gen_loss = 0.38302331849148397, disc_loss = 0.10036940376985033
Trained batch 152 in epoch 16, gen_loss = 0.3829782215598362, disc_loss = 0.10014444063082824
Trained batch 153 in epoch 16, gen_loss = 0.3822510912046804, disc_loss = 0.10051002788248581
Trained batch 154 in epoch 16, gen_loss = 0.3821594313267739, disc_loss = 0.10010115751215527
Trained batch 155 in epoch 16, gen_loss = 0.3822322766750287, disc_loss = 0.09983682479016864
Trained batch 156 in epoch 16, gen_loss = 0.3822426670675824, disc_loss = 0.09951133024137301
Trained batch 157 in epoch 16, gen_loss = 0.38208921649787997, disc_loss = 0.09925800311390924
Trained batch 158 in epoch 16, gen_loss = 0.38196975536316446, disc_loss = 0.09906001065113822
Trained batch 159 in epoch 16, gen_loss = 0.3827120209112763, disc_loss = 0.09912305930047297
Trained batch 160 in epoch 16, gen_loss = 0.3829456749169723, disc_loss = 0.0991779836935934
Trained batch 161 in epoch 16, gen_loss = 0.38285777193528636, disc_loss = 0.09905223593828671
Trained batch 162 in epoch 16, gen_loss = 0.38288007685743225, disc_loss = 0.09871484395802203
Trained batch 163 in epoch 16, gen_loss = 0.3837308013221113, disc_loss = 0.09884922448886423
Trained batch 164 in epoch 16, gen_loss = 0.3833583223097252, disc_loss = 0.09877991768333948
Trained batch 165 in epoch 16, gen_loss = 0.3833733547523797, disc_loss = 0.09863375631688409
Trained batch 166 in epoch 16, gen_loss = 0.38388423594885956, disc_loss = 0.0988563267224117
Trained batch 167 in epoch 16, gen_loss = 0.38358987938790096, disc_loss = 0.09849993748745571
Trained batch 168 in epoch 16, gen_loss = 0.38337548244634323, disc_loss = 0.09801837782645544
Trained batch 169 in epoch 16, gen_loss = 0.383301037199357, disc_loss = 0.09776497025809744
Trained batch 170 in epoch 16, gen_loss = 0.3833877902630477, disc_loss = 0.09740316907586584
Trained batch 171 in epoch 16, gen_loss = 0.383552581245123, disc_loss = 0.09704587184607463
Trained batch 172 in epoch 16, gen_loss = 0.3836125207774212, disc_loss = 0.09662341688775775
Trained batch 173 in epoch 16, gen_loss = 0.38352839682979145, disc_loss = 0.09636715181364582
Trained batch 174 in epoch 16, gen_loss = 0.38398661511284965, disc_loss = 0.09613208764897925
Trained batch 175 in epoch 16, gen_loss = 0.38410600867461075, disc_loss = 0.09566380289404398
Trained batch 176 in epoch 16, gen_loss = 0.38395967035643797, disc_loss = 0.09529719402287472
Trained batch 177 in epoch 16, gen_loss = 0.383914155739077, disc_loss = 0.09479317986772637
Trained batch 178 in epoch 16, gen_loss = 0.3837893378801186, disc_loss = 0.09459202933286488
Trained batch 179 in epoch 16, gen_loss = 0.3838837145103349, disc_loss = 0.09464149360234539
Trained batch 180 in epoch 16, gen_loss = 0.38418388580749047, disc_loss = 0.09436632389233586
Trained batch 181 in epoch 16, gen_loss = 0.38462196634365964, disc_loss = 0.09397777844384149
Trained batch 182 in epoch 16, gen_loss = 0.38474672185918674, disc_loss = 0.09413193979509216
Trained batch 183 in epoch 16, gen_loss = 0.38518181281245273, disc_loss = 0.09589321707861255
Trained batch 184 in epoch 16, gen_loss = 0.3848616964108235, disc_loss = 0.0956274289839171
Trained batch 185 in epoch 16, gen_loss = 0.3844980493348132, disc_loss = 0.09573663365576536
Trained batch 186 in epoch 16, gen_loss = 0.3845177670532369, disc_loss = 0.09559296779732972
Trained batch 187 in epoch 16, gen_loss = 0.3846820302783175, disc_loss = 0.09516112381552762
Trained batch 188 in epoch 16, gen_loss = 0.3843849755468823, disc_loss = 0.09487114633832659
Trained batch 189 in epoch 16, gen_loss = 0.38465332012427483, disc_loss = 0.09453972660397228
Trained batch 190 in epoch 16, gen_loss = 0.3842320226874027, disc_loss = 0.09507200749912811
Trained batch 191 in epoch 16, gen_loss = 0.38448959464828175, disc_loss = 0.09664684770784031
Trained batch 192 in epoch 16, gen_loss = 0.3845494584098381, disc_loss = 0.09658293236877016
Trained batch 193 in epoch 16, gen_loss = 0.3844022110258181, disc_loss = 0.0968006425681188
Trained batch 194 in epoch 16, gen_loss = 0.38459800084431967, disc_loss = 0.09644994783477906
Trained batch 195 in epoch 16, gen_loss = 0.3848008116593166, disc_loss = 0.09649150778672524
Trained batch 196 in epoch 16, gen_loss = 0.38469250598534716, disc_loss = 0.09627441227965548
Trained batch 197 in epoch 16, gen_loss = 0.38462499160357194, disc_loss = 0.09594646004038025
Trained batch 198 in epoch 16, gen_loss = 0.38465633793691895, disc_loss = 0.09585547404148471
Trained batch 199 in epoch 16, gen_loss = 0.3850110152363777, disc_loss = 0.09548829501494766
Trained batch 200 in epoch 16, gen_loss = 0.3844529835145865, disc_loss = 0.09637139187152706
Trained batch 201 in epoch 16, gen_loss = 0.38474684422559075, disc_loss = 0.09706610454117308
Trained batch 202 in epoch 16, gen_loss = 0.3852729676979516, disc_loss = 0.09676435973330084
Trained batch 203 in epoch 16, gen_loss = 0.3851049349588506, disc_loss = 0.09649662359380255
Trained batch 204 in epoch 16, gen_loss = 0.38516164843629047, disc_loss = 0.09628833590484247
Trained batch 205 in epoch 16, gen_loss = 0.38492714114559506, disc_loss = 0.09721041912014045
Trained batch 206 in epoch 16, gen_loss = 0.38518113430571443, disc_loss = 0.09734687569060764
Trained batch 207 in epoch 16, gen_loss = 0.38549519401903337, disc_loss = 0.0972302990177503
Trained batch 208 in epoch 16, gen_loss = 0.385153208765687, disc_loss = 0.09693648124283011
Trained batch 209 in epoch 16, gen_loss = 0.3849718882924035, disc_loss = 0.09732034997571082
Trained batch 210 in epoch 16, gen_loss = 0.3851512469951575, disc_loss = 0.09783217759352725
Trained batch 211 in epoch 16, gen_loss = 0.3849792777086204, disc_loss = 0.09763979013868661
Trained batch 212 in epoch 16, gen_loss = 0.38511358250474703, disc_loss = 0.0973638027661563
Trained batch 213 in epoch 16, gen_loss = 0.38517399550041304, disc_loss = 0.0971679353964663
Trained batch 214 in epoch 16, gen_loss = 0.38511073173478594, disc_loss = 0.09698888638684916
Trained batch 215 in epoch 16, gen_loss = 0.3853013176057074, disc_loss = 0.09703399458279212
Trained batch 216 in epoch 16, gen_loss = 0.38520524304033976, disc_loss = 0.09711315912035753
Trained batch 217 in epoch 16, gen_loss = 0.3853579408258473, disc_loss = 0.09683135290279848
Trained batch 218 in epoch 16, gen_loss = 0.38566213887031764, disc_loss = 0.09643540601565005
Trained batch 219 in epoch 16, gen_loss = 0.3856967503374273, disc_loss = 0.09620732057585635
Trained batch 220 in epoch 16, gen_loss = 0.38547520791243645, disc_loss = 0.09595397612442393
Trained batch 221 in epoch 16, gen_loss = 0.38534565404191745, disc_loss = 0.09614249545795557
Trained batch 222 in epoch 16, gen_loss = 0.3851122870840834, disc_loss = 0.09697540330328883
Trained batch 223 in epoch 16, gen_loss = 0.3854614505544305, disc_loss = 0.09706953881790728
Trained batch 224 in epoch 16, gen_loss = 0.385563802851571, disc_loss = 0.09689141235831711
Trained batch 225 in epoch 16, gen_loss = 0.3854876725019607, disc_loss = 0.0966120201278379
Trained batch 226 in epoch 16, gen_loss = 0.38548241811701905, disc_loss = 0.09635361003800241
Trained batch 227 in epoch 16, gen_loss = 0.38549599574323284, disc_loss = 0.09600049651456638
Trained batch 228 in epoch 16, gen_loss = 0.385663008195344, disc_loss = 0.09569612332095095
Trained batch 229 in epoch 16, gen_loss = 0.38568737467993863, disc_loss = 0.09547112561033472
Trained batch 230 in epoch 16, gen_loss = 0.3857338060806324, disc_loss = 0.0954911471727542
Trained batch 231 in epoch 16, gen_loss = 0.38561425396594506, disc_loss = 0.09607564493740813
Trained batch 232 in epoch 16, gen_loss = 0.3858019488308051, disc_loss = 0.0957853305293447
Trained batch 233 in epoch 16, gen_loss = 0.3860541894140407, disc_loss = 0.09568916568054985
Trained batch 234 in epoch 16, gen_loss = 0.3858719162484433, disc_loss = 0.0958388962129012
Trained batch 235 in epoch 16, gen_loss = 0.3861166724966744, disc_loss = 0.09549336034362599
Trained batch 236 in epoch 16, gen_loss = 0.3860812257613814, disc_loss = 0.09542068383235972
Trained batch 237 in epoch 16, gen_loss = 0.38598515957343477, disc_loss = 0.09557810065751317
Trained batch 238 in epoch 16, gen_loss = 0.3859958378091517, disc_loss = 0.09538414662851948
Trained batch 239 in epoch 16, gen_loss = 0.38632689068714776, disc_loss = 0.09557164044429858
Trained batch 240 in epoch 16, gen_loss = 0.3861433305928321, disc_loss = 0.09548197875255371
Trained batch 241 in epoch 16, gen_loss = 0.3862956390400563, disc_loss = 0.09523374330221622
Trained batch 242 in epoch 16, gen_loss = 0.3862545451019036, disc_loss = 0.09500441220378189
Trained batch 243 in epoch 16, gen_loss = 0.38643975018477833, disc_loss = 0.09495452988404231
Trained batch 244 in epoch 16, gen_loss = 0.386406660931451, disc_loss = 0.0947756830526858
Trained batch 245 in epoch 16, gen_loss = 0.3860862698496842, disc_loss = 0.09474475857445865
Trained batch 246 in epoch 16, gen_loss = 0.3864362292926804, disc_loss = 0.0952606716981301
Trained batch 247 in epoch 16, gen_loss = 0.38654597079561603, disc_loss = 0.09494714760371754
Trained batch 248 in epoch 16, gen_loss = 0.38620270184244976, disc_loss = 0.09499636495927251
Trained batch 249 in epoch 16, gen_loss = 0.38667732787132264, disc_loss = 0.09518995362520218
Trained batch 250 in epoch 16, gen_loss = 0.3865183238014282, disc_loss = 0.09506544031469945
Trained batch 251 in epoch 16, gen_loss = 0.38611244197402683, disc_loss = 0.09491533188829346
Trained batch 252 in epoch 16, gen_loss = 0.38642489709872974, disc_loss = 0.09468492251552141
Trained batch 253 in epoch 16, gen_loss = 0.38663998492590085, disc_loss = 0.09529458477682486
Trained batch 254 in epoch 16, gen_loss = 0.38654867492470085, disc_loss = 0.09533710750002487
Trained batch 255 in epoch 16, gen_loss = 0.38662309665232897, disc_loss = 0.0950072681880556
Trained batch 256 in epoch 16, gen_loss = 0.38671086919910713, disc_loss = 0.09484306651852474
Trained batch 257 in epoch 16, gen_loss = 0.38643738431061886, disc_loss = 0.09546083386612031
Trained batch 258 in epoch 16, gen_loss = 0.3865518779368014, disc_loss = 0.096231104683807
Trained batch 259 in epoch 16, gen_loss = 0.3867985563782545, disc_loss = 0.09626624218832988
Trained batch 260 in epoch 16, gen_loss = 0.38657263423747945, disc_loss = 0.09625214039993926
Trained batch 261 in epoch 16, gen_loss = 0.38626816493409283, disc_loss = 0.09622257264003954
Trained batch 262 in epoch 16, gen_loss = 0.38603358293667495, disc_loss = 0.09621738830843353
Trained batch 263 in epoch 16, gen_loss = 0.386247991951126, disc_loss = 0.09630011901202978
Trained batch 264 in epoch 16, gen_loss = 0.38633768952117775, disc_loss = 0.0963350661661265
Trained batch 265 in epoch 16, gen_loss = 0.38677830635605004, disc_loss = 0.09615172672652661
Trained batch 266 in epoch 16, gen_loss = 0.3869149414787578, disc_loss = 0.09593515187390288
Trained batch 267 in epoch 16, gen_loss = 0.3864836344745622, disc_loss = 0.09573762040974489
Trained batch 268 in epoch 16, gen_loss = 0.3862246613963386, disc_loss = 0.09547519413788966
Trained batch 269 in epoch 16, gen_loss = 0.38623672282254257, disc_loss = 0.09557263971202903
Trained batch 270 in epoch 16, gen_loss = 0.38649627973232764, disc_loss = 0.0955316631254015
Trained batch 271 in epoch 16, gen_loss = 0.38656499192995186, disc_loss = 0.09523693004431312
Trained batch 272 in epoch 16, gen_loss = 0.3865180041763809, disc_loss = 0.0950640698915327
Trained batch 273 in epoch 16, gen_loss = 0.38651474026867944, disc_loss = 0.09477913818818375
Trained batch 274 in epoch 16, gen_loss = 0.38649447506124324, disc_loss = 0.09448482969606464
Trained batch 275 in epoch 16, gen_loss = 0.3863790976828423, disc_loss = 0.09426983414501276
Trained batch 276 in epoch 16, gen_loss = 0.3865315525755555, disc_loss = 0.09427034831689907
Trained batch 277 in epoch 16, gen_loss = 0.38633742081604416, disc_loss = 0.09541751882195365
Trained batch 278 in epoch 16, gen_loss = 0.38677098578022373, disc_loss = 0.09565259231501476
Trained batch 279 in epoch 16, gen_loss = 0.3868277122931821, disc_loss = 0.09550282820460519
Trained batch 280 in epoch 16, gen_loss = 0.38659244531838494, disc_loss = 0.09561635647631943
Trained batch 281 in epoch 16, gen_loss = 0.38656596057381193, disc_loss = 0.0953906986116042
Trained batch 282 in epoch 16, gen_loss = 0.3867021583204977, disc_loss = 0.09519689524539683
Trained batch 283 in epoch 16, gen_loss = 0.3867039187273509, disc_loss = 0.09533113217256753
Trained batch 284 in epoch 16, gen_loss = 0.3870403189408152, disc_loss = 0.09551643595556941
Trained batch 285 in epoch 16, gen_loss = 0.3870193302839786, disc_loss = 0.09533312145320998
Trained batch 286 in epoch 16, gen_loss = 0.38676993429453116, disc_loss = 0.09559024008192148
Trained batch 287 in epoch 16, gen_loss = 0.3867684291261766, disc_loss = 0.09546853658523308
Trained batch 288 in epoch 16, gen_loss = 0.38677442537872025, disc_loss = 0.09528061663441902
Trained batch 289 in epoch 16, gen_loss = 0.3865988413835394, disc_loss = 0.09527660288109348
Trained batch 290 in epoch 16, gen_loss = 0.3866835195583986, disc_loss = 0.09500387183284943
Trained batch 291 in epoch 16, gen_loss = 0.3866158538076976, disc_loss = 0.09477251813721473
Trained batch 292 in epoch 16, gen_loss = 0.3862912943745636, disc_loss = 0.09483772162475175
Trained batch 293 in epoch 16, gen_loss = 0.38623196555643663, disc_loss = 0.09534733830856121
Trained batch 294 in epoch 16, gen_loss = 0.3866645204818855, disc_loss = 0.09549981115417461
Trained batch 295 in epoch 16, gen_loss = 0.38667144263918335, disc_loss = 0.09525547298992909
Trained batch 296 in epoch 16, gen_loss = 0.3866338590379516, disc_loss = 0.09521622525885551
Trained batch 297 in epoch 16, gen_loss = 0.38680641633152163, disc_loss = 0.09494705427900557
Trained batch 298 in epoch 16, gen_loss = 0.3870398070301898, disc_loss = 0.09471210308784127
Trained batch 299 in epoch 16, gen_loss = 0.3870938366651535, disc_loss = 0.09471173124698301
Trained batch 300 in epoch 16, gen_loss = 0.3869016877440519, disc_loss = 0.09539567639252969
Trained batch 301 in epoch 16, gen_loss = 0.3871846597715719, disc_loss = 0.09522531482249202
Trained batch 302 in epoch 16, gen_loss = 0.38738953663964476, disc_loss = 0.09495920088855249
Trained batch 303 in epoch 16, gen_loss = 0.38731210982721104, disc_loss = 0.09505318775221608
Trained batch 304 in epoch 16, gen_loss = 0.3868902955876022, disc_loss = 0.09571582482913966
Trained batch 305 in epoch 16, gen_loss = 0.38697873075413547, disc_loss = 0.09582117544121894
Trained batch 306 in epoch 16, gen_loss = 0.3873230447015856, disc_loss = 0.09653920181253349
Trained batch 307 in epoch 16, gen_loss = 0.3871624804549403, disc_loss = 0.09654908548351135
Trained batch 308 in epoch 16, gen_loss = 0.3871121584018843, disc_loss = 0.09652439655259878
Trained batch 309 in epoch 16, gen_loss = 0.3870621991734351, disc_loss = 0.09647430920252396
Trained batch 310 in epoch 16, gen_loss = 0.3872384784497632, disc_loss = 0.0966165680348442
Trained batch 311 in epoch 16, gen_loss = 0.3868931667544903, disc_loss = 0.09659377909086359
Trained batch 312 in epoch 16, gen_loss = 0.3867021436318041, disc_loss = 0.09653982923279841
Trained batch 313 in epoch 16, gen_loss = 0.3866406100191129, disc_loss = 0.09644748145643219
Trained batch 314 in epoch 16, gen_loss = 0.3867430856303563, disc_loss = 0.09631006597940411
Trained batch 315 in epoch 16, gen_loss = 0.38679831380708307, disc_loss = 0.09607971273067914
Trained batch 316 in epoch 16, gen_loss = 0.3869221630720686, disc_loss = 0.09613799277622523
Trained batch 317 in epoch 16, gen_loss = 0.38728413763661057, disc_loss = 0.09623373580698229
Trained batch 318 in epoch 16, gen_loss = 0.38735263119670665, disc_loss = 0.09616079419372504
Trained batch 319 in epoch 16, gen_loss = 0.3874364424496889, disc_loss = 0.09614262389659416
Trained batch 320 in epoch 16, gen_loss = 0.38729985722128846, disc_loss = 0.09647415740548915
Trained batch 321 in epoch 16, gen_loss = 0.3873305024567598, disc_loss = 0.09661109458296473
Trained batch 322 in epoch 16, gen_loss = 0.3872454914699767, disc_loss = 0.09639280170329123
Trained batch 323 in epoch 16, gen_loss = 0.3870080314852573, disc_loss = 0.09643213863392579
Trained batch 324 in epoch 16, gen_loss = 0.3871868592959184, disc_loss = 0.09641325878122678
Trained batch 325 in epoch 16, gen_loss = 0.3871251002776842, disc_loss = 0.09621643792392194
Trained batch 326 in epoch 16, gen_loss = 0.3872214678777467, disc_loss = 0.09613703882509689
Trained batch 327 in epoch 16, gen_loss = 0.3872982610653086, disc_loss = 0.09598502297261048
Trained batch 328 in epoch 16, gen_loss = 0.3876004234454552, disc_loss = 0.09659779641075246
Trained batch 329 in epoch 16, gen_loss = 0.3874967875805768, disc_loss = 0.09653894798265714
Trained batch 330 in epoch 16, gen_loss = 0.38746138092614374, disc_loss = 0.0963636645934688
Trained batch 331 in epoch 16, gen_loss = 0.387631497379527, disc_loss = 0.09615044958092811
Trained batch 332 in epoch 16, gen_loss = 0.3875428554532048, disc_loss = 0.09597511507022578
Trained batch 333 in epoch 16, gen_loss = 0.3873945259583924, disc_loss = 0.09643080828622162
Trained batch 334 in epoch 16, gen_loss = 0.3876545976346998, disc_loss = 0.09675439696536581
Trained batch 335 in epoch 16, gen_loss = 0.38765896218163626, disc_loss = 0.0966729478539145
Trained batch 336 in epoch 16, gen_loss = 0.38738782027354934, disc_loss = 0.09672638886948103
Trained batch 337 in epoch 16, gen_loss = 0.3873386814220417, disc_loss = 0.09655623592315077
Trained batch 338 in epoch 16, gen_loss = 0.3870915538441818, disc_loss = 0.09662166341402978
Trained batch 339 in epoch 16, gen_loss = 0.3869693621993065, disc_loss = 0.0971605501438984
Trained batch 340 in epoch 16, gen_loss = 0.38716532643939044, disc_loss = 0.09709859836322209
Trained batch 341 in epoch 16, gen_loss = 0.38724251901894285, disc_loss = 0.09697766248300149
Trained batch 342 in epoch 16, gen_loss = 0.38687804819196026, disc_loss = 0.09699796095935753
Trained batch 343 in epoch 16, gen_loss = 0.3869022934069467, disc_loss = 0.09679309138757458
Trained batch 344 in epoch 16, gen_loss = 0.38692057625107146, disc_loss = 0.09665988253672486
Trained batch 345 in epoch 16, gen_loss = 0.3868248274905144, disc_loss = 0.09663332707781581
Trained batch 346 in epoch 16, gen_loss = 0.386837597710942, disc_loss = 0.09664909607899894
Trained batch 347 in epoch 16, gen_loss = 0.38687051584323245, disc_loss = 0.09655266824371085
Trained batch 348 in epoch 16, gen_loss = 0.3870107673300713, disc_loss = 0.09663960819845129
Trained batch 349 in epoch 16, gen_loss = 0.38716023768697466, disc_loss = 0.09692964183166623
Trained batch 350 in epoch 16, gen_loss = 0.38725098390185253, disc_loss = 0.09670281436485358
Trained batch 351 in epoch 16, gen_loss = 0.3873270364816893, disc_loss = 0.09657420599780214
Trained batch 352 in epoch 16, gen_loss = 0.38748901103103467, disc_loss = 0.09633221856658757
Trained batch 353 in epoch 16, gen_loss = 0.38736527122683445, disc_loss = 0.0961577833424938
Trained batch 354 in epoch 16, gen_loss = 0.3871461451893121, disc_loss = 0.09602564094247112
Trained batch 355 in epoch 16, gen_loss = 0.3871343268939618, disc_loss = 0.09586232446992163
Trained batch 356 in epoch 16, gen_loss = 0.38712829109333474, disc_loss = 0.09587724693119526
Trained batch 357 in epoch 16, gen_loss = 0.386932325013523, disc_loss = 0.09608866526698434
Trained batch 358 in epoch 16, gen_loss = 0.38722655841235, disc_loss = 0.09599147586043001
Trained batch 359 in epoch 16, gen_loss = 0.38740771404571006, disc_loss = 0.09577938307387134
Trained batch 360 in epoch 16, gen_loss = 0.3874853225295894, disc_loss = 0.09573954784948575
Trained batch 361 in epoch 16, gen_loss = 0.3877460169528729, disc_loss = 0.09553626064952071
Trained batch 362 in epoch 16, gen_loss = 0.387807010126508, disc_loss = 0.09587107139534366
Trained batch 363 in epoch 16, gen_loss = 0.3877154848241544, disc_loss = 0.09604421025142074
Trained batch 364 in epoch 16, gen_loss = 0.3878094820943597, disc_loss = 0.09593992386880802
Trained batch 365 in epoch 16, gen_loss = 0.3877134012882827, disc_loss = 0.09570745335474529
Trained batch 366 in epoch 16, gen_loss = 0.3879557494733899, disc_loss = 0.09548671716920605
Trained batch 367 in epoch 16, gen_loss = 0.3879187384053417, disc_loss = 0.09532336219284765
Trained batch 368 in epoch 16, gen_loss = 0.38794508988295145, disc_loss = 0.09542637204039629
Trained batch 369 in epoch 16, gen_loss = 0.3877792726497392, disc_loss = 0.09586600690224284
Trained batch 370 in epoch 16, gen_loss = 0.3880490705652057, disc_loss = 0.09576050273200493
Trained batch 371 in epoch 16, gen_loss = 0.3881502556864933, disc_loss = 0.09566592984652568
Trained batch 372 in epoch 16, gen_loss = 0.3878726725923472, disc_loss = 0.09554834103326615
Trained batch 373 in epoch 16, gen_loss = 0.38775918572981727, disc_loss = 0.09564247240068362
Trained batch 374 in epoch 16, gen_loss = 0.38790461770693463, disc_loss = 0.09661671390881141
Trained batch 375 in epoch 16, gen_loss = 0.3877640446608371, disc_loss = 0.0965007079562093
Trained batch 376 in epoch 16, gen_loss = 0.3875839026442257, disc_loss = 0.09640214435845139
Trained batch 377 in epoch 16, gen_loss = 0.3876539959951683, disc_loss = 0.09626346215280512
Trained batch 378 in epoch 16, gen_loss = 0.3875494942973346, disc_loss = 0.09626234106296835
Trained batch 379 in epoch 16, gen_loss = 0.3874931973846335, disc_loss = 0.0961374573090947
Trained batch 380 in epoch 16, gen_loss = 0.38752955988323284, disc_loss = 0.09615531202718576
Trained batch 381 in epoch 16, gen_loss = 0.3873269032901494, disc_loss = 0.09662491253562544
Trained batch 382 in epoch 16, gen_loss = 0.38727247310369506, disc_loss = 0.09643829822802902
Trained batch 383 in epoch 16, gen_loss = 0.38731667182097834, disc_loss = 0.09645232764645091
Trained batch 384 in epoch 16, gen_loss = 0.38734065317488336, disc_loss = 0.09629397725855762
Trained batch 385 in epoch 16, gen_loss = 0.38738275500776853, disc_loss = 0.0962372987067877
Trained batch 386 in epoch 16, gen_loss = 0.3873725394099874, disc_loss = 0.09615958567458453
Trained batch 387 in epoch 16, gen_loss = 0.38740333523025217, disc_loss = 0.09609075256181669
Trained batch 388 in epoch 16, gen_loss = 0.3874813610146775, disc_loss = 0.09603336362220864
Trained batch 389 in epoch 16, gen_loss = 0.3874308039744695, disc_loss = 0.09592919176539931
Trained batch 390 in epoch 16, gen_loss = 0.3873771280431382, disc_loss = 0.09580460612607353
Trained batch 391 in epoch 16, gen_loss = 0.3875172283424407, disc_loss = 0.0957762919133529
Trained batch 392 in epoch 16, gen_loss = 0.3874426073852083, disc_loss = 0.09560636385242069
Trained batch 393 in epoch 16, gen_loss = 0.3874225724620867, disc_loss = 0.09555422987193248
Trained batch 394 in epoch 16, gen_loss = 0.3875116827367227, disc_loss = 0.09547855966972021
Trained batch 395 in epoch 16, gen_loss = 0.3876351204634917, disc_loss = 0.09532294095719629
Trained batch 396 in epoch 16, gen_loss = 0.38772157757948866, disc_loss = 0.09535603145235957
Trained batch 397 in epoch 16, gen_loss = 0.3876471607828859, disc_loss = 0.09515899616111088
Trained batch 398 in epoch 16, gen_loss = 0.387748081209068, disc_loss = 0.09508638701782116
Trained batch 399 in epoch 16, gen_loss = 0.3878982267528772, disc_loss = 0.09492365285987034
Trained batch 400 in epoch 16, gen_loss = 0.3876055357908073, disc_loss = 0.09537263775936461
Trained batch 401 in epoch 16, gen_loss = 0.3876636138009788, disc_loss = 0.09569765549773972
Trained batch 402 in epoch 16, gen_loss = 0.3874547289263818, disc_loss = 0.09570469095535743
Trained batch 403 in epoch 16, gen_loss = 0.3875975740870627, disc_loss = 0.09561487256162016
Trained batch 404 in epoch 16, gen_loss = 0.3875180299635287, disc_loss = 0.09547602188669974
Trained batch 405 in epoch 16, gen_loss = 0.38751432240890166, disc_loss = 0.09537781771556864
Trained batch 406 in epoch 16, gen_loss = 0.38737161666228087, disc_loss = 0.09542989881173765
Trained batch 407 in epoch 16, gen_loss = 0.38756315760752735, disc_loss = 0.09534457772650629
Trained batch 408 in epoch 16, gen_loss = 0.38739854323251904, disc_loss = 0.09564196339564758
Trained batch 409 in epoch 16, gen_loss = 0.3876256956559856, disc_loss = 0.0957238610674877
Trained batch 410 in epoch 16, gen_loss = 0.3876345974830525, disc_loss = 0.09560768734301166
Trained batch 411 in epoch 16, gen_loss = 0.38751182003507334, disc_loss = 0.09558054291444279
Trained batch 412 in epoch 16, gen_loss = 0.38752651726939774, disc_loss = 0.09545086839486626
Trained batch 413 in epoch 16, gen_loss = 0.3873522581829541, disc_loss = 0.09536817183286167
Trained batch 414 in epoch 16, gen_loss = 0.3874047763376351, disc_loss = 0.09529156285641065
Trained batch 415 in epoch 16, gen_loss = 0.387420875665087, disc_loss = 0.09521558172687386
Trained batch 416 in epoch 16, gen_loss = 0.38716435868391313, disc_loss = 0.09540192962666567
Trained batch 417 in epoch 16, gen_loss = 0.38737027874688784, disc_loss = 0.09637281674062878
Trained batch 418 in epoch 16, gen_loss = 0.38728050386137497, disc_loss = 0.09645972179742375
Trained batch 419 in epoch 16, gen_loss = 0.3871306547096797, disc_loss = 0.09651789001100475
Trained batch 420 in epoch 16, gen_loss = 0.38698234396705716, disc_loss = 0.09638605499750716
Trained batch 421 in epoch 16, gen_loss = 0.38712697190131057, disc_loss = 0.09635832144159347
Trained batch 422 in epoch 16, gen_loss = 0.3871416986411345, disc_loss = 0.0962376153078943
Trained batch 423 in epoch 16, gen_loss = 0.3872800567099508, disc_loss = 0.09606316011565966
Trained batch 424 in epoch 16, gen_loss = 0.3872239168251262, disc_loss = 0.09593381537014947
Trained batch 425 in epoch 16, gen_loss = 0.38710755221720594, disc_loss = 0.09575708982853892
Trained batch 426 in epoch 16, gen_loss = 0.3871088509537297, disc_loss = 0.09557607996144465
Trained batch 427 in epoch 16, gen_loss = 0.38709730209312704, disc_loss = 0.09539341196095763
Trained batch 428 in epoch 16, gen_loss = 0.38702544542181466, disc_loss = 0.09545660705581342
Trained batch 429 in epoch 16, gen_loss = 0.3870712152054144, disc_loss = 0.09616489762786863
Trained batch 430 in epoch 16, gen_loss = 0.38692372525651053, disc_loss = 0.09630775827430448
Trained batch 431 in epoch 16, gen_loss = 0.38674888194159224, disc_loss = 0.09653474972367769
Trained batch 432 in epoch 16, gen_loss = 0.38681849782241134, disc_loss = 0.09660152126292915
Trained batch 433 in epoch 16, gen_loss = 0.3868477048549784, disc_loss = 0.0965593779858734
Trained batch 434 in epoch 16, gen_loss = 0.3867933949519848, disc_loss = 0.09647559618427493
Trained batch 435 in epoch 16, gen_loss = 0.38667400960528525, disc_loss = 0.09632579974804518
Trained batch 436 in epoch 16, gen_loss = 0.38668902965104823, disc_loss = 0.09617071924198342
Trained batch 437 in epoch 16, gen_loss = 0.38652460998323956, disc_loss = 0.09616393806650962
Trained batch 438 in epoch 16, gen_loss = 0.38641983073773306, disc_loss = 0.09674231443078955
Trained batch 439 in epoch 16, gen_loss = 0.3862081049518152, disc_loss = 0.09683285108132457
Trained batch 440 in epoch 16, gen_loss = 0.3861509924437724, disc_loss = 0.09666540827433201
Trained batch 441 in epoch 16, gen_loss = 0.386158800435282, disc_loss = 0.09658902241928477
Trained batch 442 in epoch 16, gen_loss = 0.3861088707673092, disc_loss = 0.09655062298229465
Trained batch 443 in epoch 16, gen_loss = 0.38619613050072044, disc_loss = 0.09640010686901708
Trained batch 444 in epoch 16, gen_loss = 0.3863034052795239, disc_loss = 0.09621600464111968
Trained batch 445 in epoch 16, gen_loss = 0.3862802423703831, disc_loss = 0.09609405583422213
Trained batch 446 in epoch 16, gen_loss = 0.38630647640633636, disc_loss = 0.09600133181943389
Trained batch 447 in epoch 16, gen_loss = 0.3863804818663214, disc_loss = 0.09603119829262141
Trained batch 448 in epoch 16, gen_loss = 0.3861785697644962, disc_loss = 0.09634179724608538
Trained batch 449 in epoch 16, gen_loss = 0.3863168967432446, disc_loss = 0.09659417822750078
Trained batch 450 in epoch 16, gen_loss = 0.386309757399189, disc_loss = 0.09645681537299555
Trained batch 451 in epoch 16, gen_loss = 0.38624857952900693, disc_loss = 0.09635923740008961
Trained batch 452 in epoch 16, gen_loss = 0.38621975103224615, disc_loss = 0.09632495326703419
Trained batch 453 in epoch 16, gen_loss = 0.3860226900435754, disc_loss = 0.09619607702348923
Trained batch 454 in epoch 16, gen_loss = 0.3860515056730627, disc_loss = 0.09606201645232491
Trained batch 455 in epoch 16, gen_loss = 0.38606144729674907, disc_loss = 0.09589451295936383
Trained batch 456 in epoch 16, gen_loss = 0.38609141796109975, disc_loss = 0.09585196362845029
Trained batch 457 in epoch 16, gen_loss = 0.3859905165225658, disc_loss = 0.09603464540996991
Trained batch 458 in epoch 16, gen_loss = 0.38614521995349127, disc_loss = 0.0960638523852546
Trained batch 459 in epoch 16, gen_loss = 0.38607605941917583, disc_loss = 0.09595503367524108
Trained batch 460 in epoch 16, gen_loss = 0.3860518812745357, disc_loss = 0.09591581839906484
Trained batch 461 in epoch 16, gen_loss = 0.38632577715756056, disc_loss = 0.0957364632619053
Trained batch 462 in epoch 16, gen_loss = 0.38665518731071935, disc_loss = 0.0955656792296672
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.4168604016304016, disc_loss = 0.03767331689596176
Trained batch 1 in epoch 17, gen_loss = 0.38732656836509705, disc_loss = 0.026731183752417564
Trained batch 2 in epoch 17, gen_loss = 0.3836706876754761, disc_loss = 0.08592771366238594
Trained batch 3 in epoch 17, gen_loss = 0.38909417390823364, disc_loss = 0.09559775236994028
Trained batch 4 in epoch 17, gen_loss = 0.3995470225811005, disc_loss = 0.07993585057556629
Trained batch 5 in epoch 17, gen_loss = 0.3928528328736623, disc_loss = 0.07369115607192119
Trained batch 6 in epoch 17, gen_loss = 0.3907438814640045, disc_loss = 0.065455183918987
Trained batch 7 in epoch 17, gen_loss = 0.39597679674625397, disc_loss = 0.0629265052266419
Trained batch 8 in epoch 17, gen_loss = 0.39488210280736286, disc_loss = 0.06132498507698377
Trained batch 9 in epoch 17, gen_loss = 0.3941490650177002, disc_loss = 0.06128790229558945
Trained batch 10 in epoch 17, gen_loss = 0.38857157122005115, disc_loss = 0.057374486699700356
Trained batch 11 in epoch 17, gen_loss = 0.38917118807633716, disc_loss = 0.05815227562561631
Trained batch 12 in epoch 17, gen_loss = 0.3900616902571458, disc_loss = 0.06441686230783279
Trained batch 13 in epoch 17, gen_loss = 0.3950004811797823, disc_loss = 0.06528905712600265
Trained batch 14 in epoch 17, gen_loss = 0.38954346974690757, disc_loss = 0.06461927803854148
Trained batch 15 in epoch 17, gen_loss = 0.388659343123436, disc_loss = 0.06736906769219786
Trained batch 16 in epoch 17, gen_loss = 0.3847785679733052, disc_loss = 0.06638082894770538
Trained batch 17 in epoch 17, gen_loss = 0.385439223713345, disc_loss = 0.06627946295258072
Trained batch 18 in epoch 17, gen_loss = 0.3889023567500867, disc_loss = 0.0759654832317641
Trained batch 19 in epoch 17, gen_loss = 0.38928136229515076, disc_loss = 0.07540973415598273
Trained batch 20 in epoch 17, gen_loss = 0.3877364524773189, disc_loss = 0.07509215770378
Trained batch 21 in epoch 17, gen_loss = 0.38966903767802497, disc_loss = 0.0798388065092943
Trained batch 22 in epoch 17, gen_loss = 0.39080498270366504, disc_loss = 0.08098115569547466
Trained batch 23 in epoch 17, gen_loss = 0.392841350287199, disc_loss = 0.07849049816528957
Trained batch 24 in epoch 17, gen_loss = 0.39085492610931394, disc_loss = 0.07687619924545289
Trained batch 25 in epoch 17, gen_loss = 0.3899128677753302, disc_loss = 0.07676673279358791
Trained batch 26 in epoch 17, gen_loss = 0.390062282482783, disc_loss = 0.07639875897654781
Trained batch 27 in epoch 17, gen_loss = 0.38936510256358553, disc_loss = 0.07785432147128242
Trained batch 28 in epoch 17, gen_loss = 0.3893009352272955, disc_loss = 0.07640498401275997
Trained batch 29 in epoch 17, gen_loss = 0.3895516445239385, disc_loss = 0.0750097422550122
Trained batch 30 in epoch 17, gen_loss = 0.3866756337304269, disc_loss = 0.08059897381932504
Trained batch 31 in epoch 17, gen_loss = 0.3871906455606222, disc_loss = 0.08746957441326231
Trained batch 32 in epoch 17, gen_loss = 0.3849216672507199, disc_loss = 0.08741076595403931
Trained batch 33 in epoch 17, gen_loss = 0.3862418532371521, disc_loss = 0.08659340452183695
Trained batch 34 in epoch 17, gen_loss = 0.38502353770392284, disc_loss = 0.08526889884046146
Trained batch 35 in epoch 17, gen_loss = 0.38654904067516327, disc_loss = 0.08349341702544028
Trained batch 36 in epoch 17, gen_loss = 0.38417235822290985, disc_loss = 0.08326047749535458
Trained batch 37 in epoch 17, gen_loss = 0.38555979493417236, disc_loss = 0.08611761278619892
Trained batch 38 in epoch 17, gen_loss = 0.38369983205428493, disc_loss = 0.08648192815673657
Trained batch 39 in epoch 17, gen_loss = 0.3850286014378071, disc_loss = 0.08542395168915391
Trained batch 40 in epoch 17, gen_loss = 0.38471579624385366, disc_loss = 0.08694536811331423
Trained batch 41 in epoch 17, gen_loss = 0.3841830257858549, disc_loss = 0.08895718350651718
Trained batch 42 in epoch 17, gen_loss = 0.3862613314806029, disc_loss = 0.09139826729200608
Trained batch 43 in epoch 17, gen_loss = 0.3858836862173947, disc_loss = 0.09021275270391595
Trained batch 44 in epoch 17, gen_loss = 0.3835504127873315, disc_loss = 0.09173274719052844
Trained batch 45 in epoch 17, gen_loss = 0.3844012248775233, disc_loss = 0.09125459923044495
Trained batch 46 in epoch 17, gen_loss = 0.3841003160527412, disc_loss = 0.090353195971631
Trained batch 47 in epoch 17, gen_loss = 0.3851020398239295, disc_loss = 0.08869978315973033
Trained batch 48 in epoch 17, gen_loss = 0.38638967458082707, disc_loss = 0.08766655239979831
Trained batch 49 in epoch 17, gen_loss = 0.3859833747148514, disc_loss = 0.08956952165812254
Trained batch 50 in epoch 17, gen_loss = 0.38784414588236343, disc_loss = 0.09455726788762737
Trained batch 51 in epoch 17, gen_loss = 0.38727908638807446, disc_loss = 0.09475396469665262
Trained batch 52 in epoch 17, gen_loss = 0.3881377066081425, disc_loss = 0.09404902613528494
Trained batch 53 in epoch 17, gen_loss = 0.3872724225123723, disc_loss = 0.09318310867443129
Trained batch 54 in epoch 17, gen_loss = 0.38652139793742785, disc_loss = 0.09398736239156939
Trained batch 55 in epoch 17, gen_loss = 0.38670587220362257, disc_loss = 0.09301764714265508
Trained batch 56 in epoch 17, gen_loss = 0.3872907747302139, disc_loss = 0.0921016201180847
Trained batch 57 in epoch 17, gen_loss = 0.3885209719682562, disc_loss = 0.09152202760993407
Trained batch 58 in epoch 17, gen_loss = 0.38948446108123, disc_loss = 0.09054494273485773
Trained batch 59 in epoch 17, gen_loss = 0.39023298770189285, disc_loss = 0.09023904517913858
Trained batch 60 in epoch 17, gen_loss = 0.38967613411731405, disc_loss = 0.09101829754158122
Trained batch 61 in epoch 17, gen_loss = 0.38991574029768666, disc_loss = 0.09108860373136497
Trained batch 62 in epoch 17, gen_loss = 0.3894736970227862, disc_loss = 0.09046493662846466
Trained batch 63 in epoch 17, gen_loss = 0.38797713769599795, disc_loss = 0.08947016907040961
Trained batch 64 in epoch 17, gen_loss = 0.38867226059620197, disc_loss = 0.08952655141743329
Trained batch 65 in epoch 17, gen_loss = 0.38786966105302173, disc_loss = 0.08993061149323528
Trained batch 66 in epoch 17, gen_loss = 0.3880943740481761, disc_loss = 0.0894895508162566
Trained batch 67 in epoch 17, gen_loss = 0.3874886702088749, disc_loss = 0.08882012993426007
Trained batch 68 in epoch 17, gen_loss = 0.38696446582890937, disc_loss = 0.08824056168289288
Trained batch 69 in epoch 17, gen_loss = 0.3883363170283181, disc_loss = 0.08810938115098647
Trained batch 70 in epoch 17, gen_loss = 0.3883963688998155, disc_loss = 0.08823166575125406
Trained batch 71 in epoch 17, gen_loss = 0.3882804289460182, disc_loss = 0.08754152708893849
Trained batch 72 in epoch 17, gen_loss = 0.3877637284259274, disc_loss = 0.08730142111953808
Trained batch 73 in epoch 17, gen_loss = 0.38792506182515946, disc_loss = 0.08637045804612539
Trained batch 74 in epoch 17, gen_loss = 0.3876891287167867, disc_loss = 0.08582551839450996
Trained batch 75 in epoch 17, gen_loss = 0.38814872738562134, disc_loss = 0.08481800820874541
Trained batch 76 in epoch 17, gen_loss = 0.38690267212979207, disc_loss = 0.08479934930801392
Trained batch 77 in epoch 17, gen_loss = 0.387819400200477, disc_loss = 0.08815378561998025
Trained batch 78 in epoch 17, gen_loss = 0.38729544606389876, disc_loss = 0.08744091125605982
Trained batch 79 in epoch 17, gen_loss = 0.38628285229206083, disc_loss = 0.08667103503830731
Trained batch 80 in epoch 17, gen_loss = 0.38602840606077216, disc_loss = 0.08620044474064568
Trained batch 81 in epoch 17, gen_loss = 0.38621918529998966, disc_loss = 0.08669727036684025
Trained batch 82 in epoch 17, gen_loss = 0.3866056588040777, disc_loss = 0.08631173395607845
Trained batch 83 in epoch 17, gen_loss = 0.38686061792430426, disc_loss = 0.08649671592173122
Trained batch 84 in epoch 17, gen_loss = 0.38697124684558193, disc_loss = 0.08640039554413627
Trained batch 85 in epoch 17, gen_loss = 0.3875046209540478, disc_loss = 0.08740179024116937
Trained batch 86 in epoch 17, gen_loss = 0.38697872696251706, disc_loss = 0.0889932351379559
Trained batch 87 in epoch 17, gen_loss = 0.38703832910819486, disc_loss = 0.0884893499314785
Trained batch 88 in epoch 17, gen_loss = 0.3874529975183894, disc_loss = 0.08777322561553355
Trained batch 89 in epoch 17, gen_loss = 0.38756253752443526, disc_loss = 0.08692971772203843
Trained batch 90 in epoch 17, gen_loss = 0.3867278436383048, disc_loss = 0.08631253195414831
Trained batch 91 in epoch 17, gen_loss = 0.38656651746967563, disc_loss = 0.08548239289539987
Trained batch 92 in epoch 17, gen_loss = 0.38667007671889436, disc_loss = 0.08494186079910686
Trained batch 93 in epoch 17, gen_loss = 0.38692972000609055, disc_loss = 0.08454049052670598
Trained batch 94 in epoch 17, gen_loss = 0.38688600220178304, disc_loss = 0.08396765961262741
Trained batch 95 in epoch 17, gen_loss = 0.38698754490663606, disc_loss = 0.08363790809138057
Trained batch 96 in epoch 17, gen_loss = 0.3862361256609258, disc_loss = 0.08369982295391179
Trained batch 97 in epoch 17, gen_loss = 0.38624171821438535, disc_loss = 0.08298337540342188
Trained batch 98 in epoch 17, gen_loss = 0.3872500916924139, disc_loss = 0.0825304136225822
Trained batch 99 in epoch 17, gen_loss = 0.3866391694545746, disc_loss = 0.08357399226166308
Trained batch 100 in epoch 17, gen_loss = 0.38782545186505457, disc_loss = 0.08443771554433768
Trained batch 101 in epoch 17, gen_loss = 0.38743260210635616, disc_loss = 0.0839242658066545
Trained batch 102 in epoch 17, gen_loss = 0.38740678088178915, disc_loss = 0.08435773593599646
Trained batch 103 in epoch 17, gen_loss = 0.38710572112065095, disc_loss = 0.08387594746175007
Trained batch 104 in epoch 17, gen_loss = 0.38727916819708685, disc_loss = 0.08360942872684626
Trained batch 105 in epoch 17, gen_loss = 0.38644558669261214, disc_loss = 0.0843000417698245
Trained batch 106 in epoch 17, gen_loss = 0.38705704033931837, disc_loss = 0.08573170341377225
Trained batch 107 in epoch 17, gen_loss = 0.38684603019996927, disc_loss = 0.08549438483357706
Trained batch 108 in epoch 17, gen_loss = 0.38624186800160537, disc_loss = 0.08530588165233167
Trained batch 109 in epoch 17, gen_loss = 0.3857922125946392, disc_loss = 0.08476453261788595
Trained batch 110 in epoch 17, gen_loss = 0.3854047245270497, disc_loss = 0.0845844181220945
Trained batch 111 in epoch 17, gen_loss = 0.3852969032845327, disc_loss = 0.08664432268622997
Trained batch 112 in epoch 17, gen_loss = 0.38493146437459286, disc_loss = 0.0887951910973782
Trained batch 113 in epoch 17, gen_loss = 0.38519697937003355, disc_loss = 0.08862324915989711
Trained batch 114 in epoch 17, gen_loss = 0.38495407078577126, disc_loss = 0.08824387747470451
Trained batch 115 in epoch 17, gen_loss = 0.38456812783561906, disc_loss = 0.08785126118214223
Trained batch 116 in epoch 17, gen_loss = 0.38379735136643434, disc_loss = 0.08785241228552201
Trained batch 117 in epoch 17, gen_loss = 0.3839505696195667, disc_loss = 0.08719841704182958
Trained batch 118 in epoch 17, gen_loss = 0.3840099027176865, disc_loss = 0.08664495387591985
Trained batch 119 in epoch 17, gen_loss = 0.3848571921388308, disc_loss = 0.08607083715032786
Trained batch 120 in epoch 17, gen_loss = 0.3851708259956896, disc_loss = 0.08568390262551791
Trained batch 121 in epoch 17, gen_loss = 0.3849144189572725, disc_loss = 0.0852811432779446
Trained batch 122 in epoch 17, gen_loss = 0.38507379264366337, disc_loss = 0.08489389993946969
Trained batch 123 in epoch 17, gen_loss = 0.38530523089631913, disc_loss = 0.08497569839950771
Trained batch 124 in epoch 17, gen_loss = 0.38426092004776, disc_loss = 0.08520990113168955
Trained batch 125 in epoch 17, gen_loss = 0.38434339752272956, disc_loss = 0.08504387184179255
Trained batch 126 in epoch 17, gen_loss = 0.38516121304879974, disc_loss = 0.08580237900559592
Trained batch 127 in epoch 17, gen_loss = 0.38481463585048914, disc_loss = 0.0860500655035139
Trained batch 128 in epoch 17, gen_loss = 0.3851830520371134, disc_loss = 0.08548467034517332
Trained batch 129 in epoch 17, gen_loss = 0.3856266287656931, disc_loss = 0.08493338827616893
Trained batch 130 in epoch 17, gen_loss = 0.38545524141260684, disc_loss = 0.08454142344532577
Trained batch 131 in epoch 17, gen_loss = 0.38564326117436093, disc_loss = 0.08419583248200291
Trained batch 132 in epoch 17, gen_loss = 0.38559183814471826, disc_loss = 0.0843301230719439
Trained batch 133 in epoch 17, gen_loss = 0.38595372905482106, disc_loss = 0.08630834487892354
Trained batch 134 in epoch 17, gen_loss = 0.38565606982619677, disc_loss = 0.08587029199633334
Trained batch 135 in epoch 17, gen_loss = 0.3852505120722687, disc_loss = 0.08632265139535508
Trained batch 136 in epoch 17, gen_loss = 0.38578270538880005, disc_loss = 0.08706207223997935
Trained batch 137 in epoch 17, gen_loss = 0.38570881343406177, disc_loss = 0.08689826898330795
Trained batch 138 in epoch 17, gen_loss = 0.38515823414857436, disc_loss = 0.08663621918707014
Trained batch 139 in epoch 17, gen_loss = 0.3850502522928374, disc_loss = 0.0864997253753245
Trained batch 140 in epoch 17, gen_loss = 0.3849118992369226, disc_loss = 0.08659968936010033
Trained batch 141 in epoch 17, gen_loss = 0.38494473716742555, disc_loss = 0.08643911347370332
Trained batch 142 in epoch 17, gen_loss = 0.3851850143262556, disc_loss = 0.08603639614123565
Trained batch 143 in epoch 17, gen_loss = 0.3857318258119954, disc_loss = 0.08569574987308846
Trained batch 144 in epoch 17, gen_loss = 0.38612195397245475, disc_loss = 0.0852938688263811
Trained batch 145 in epoch 17, gen_loss = 0.38587145915586657, disc_loss = 0.08490069071468834
Trained batch 146 in epoch 17, gen_loss = 0.38575090822719393, disc_loss = 0.08507362822843652
Trained batch 147 in epoch 17, gen_loss = 0.38617879091887863, disc_loss = 0.0854203615815857
Trained batch 148 in epoch 17, gen_loss = 0.3856057246659426, disc_loss = 0.08493559241244857
Trained batch 149 in epoch 17, gen_loss = 0.38598212043444313, disc_loss = 0.08543345837543408
Trained batch 150 in epoch 17, gen_loss = 0.3866028560707901, disc_loss = 0.08531329444060658
Trained batch 151 in epoch 17, gen_loss = 0.3871561469216096, disc_loss = 0.08501862230906754
Trained batch 152 in epoch 17, gen_loss = 0.38717324476616055, disc_loss = 0.08458942765357837
Trained batch 153 in epoch 17, gen_loss = 0.38699009937125367, disc_loss = 0.08458927066924123
Trained batch 154 in epoch 17, gen_loss = 0.38775833076046357, disc_loss = 0.08433518487839929
Trained batch 155 in epoch 17, gen_loss = 0.3876900472320043, disc_loss = 0.08389659943536688
Trained batch 156 in epoch 17, gen_loss = 0.3878017193192889, disc_loss = 0.08343220661115494
Trained batch 157 in epoch 17, gen_loss = 0.3874065487445155, disc_loss = 0.08327430795548083
Trained batch 158 in epoch 17, gen_loss = 0.3877222657953418, disc_loss = 0.08413784850224759
Trained batch 159 in epoch 17, gen_loss = 0.3870679706335068, disc_loss = 0.08437800582032651
Trained batch 160 in epoch 17, gen_loss = 0.38743910304507856, disc_loss = 0.08416029692899367
Trained batch 161 in epoch 17, gen_loss = 0.387699591708772, disc_loss = 0.08378882216358627
Trained batch 162 in epoch 17, gen_loss = 0.3878451785061257, disc_loss = 0.08375461680666069
Trained batch 163 in epoch 17, gen_loss = 0.3875832114277816, disc_loss = 0.08367069326795457
Trained batch 164 in epoch 17, gen_loss = 0.3879145167090676, disc_loss = 0.08340871325044921
Trained batch 165 in epoch 17, gen_loss = 0.38829614868365137, disc_loss = 0.08421111591609128
Trained batch 166 in epoch 17, gen_loss = 0.3879198644332543, disc_loss = 0.08383234405142818
Trained batch 167 in epoch 17, gen_loss = 0.3876515410485722, disc_loss = 0.0840638996811495
Trained batch 168 in epoch 17, gen_loss = 0.3880961759555975, disc_loss = 0.08400534805373328
Trained batch 169 in epoch 17, gen_loss = 0.3880284442621119, disc_loss = 0.08362228491288774
Trained batch 170 in epoch 17, gen_loss = 0.387548735092955, disc_loss = 0.08378580628692756
Trained batch 171 in epoch 17, gen_loss = 0.38775690714287203, disc_loss = 0.08455606513158527
Trained batch 172 in epoch 17, gen_loss = 0.3876031664754614, disc_loss = 0.0844878152744963
Trained batch 173 in epoch 17, gen_loss = 0.3878111995157154, disc_loss = 0.0843299725574666
Trained batch 174 in epoch 17, gen_loss = 0.38814651812825884, disc_loss = 0.08472693432654653
Trained batch 175 in epoch 17, gen_loss = 0.3879684548486363, disc_loss = 0.0845661061942916
Trained batch 176 in epoch 17, gen_loss = 0.38763765847615606, disc_loss = 0.08455034149652821
Trained batch 177 in epoch 17, gen_loss = 0.38784919846593663, disc_loss = 0.08417570678873008
Trained batch 178 in epoch 17, gen_loss = 0.3879233302350817, disc_loss = 0.084632406063253
Trained batch 179 in epoch 17, gen_loss = 0.3874766677618027, disc_loss = 0.0848658114257786
Trained batch 180 in epoch 17, gen_loss = 0.38747214859361806, disc_loss = 0.08462868307753163
Trained batch 181 in epoch 17, gen_loss = 0.3874733765701671, disc_loss = 0.08437694621446369
Trained batch 182 in epoch 17, gen_loss = 0.3878226386067646, disc_loss = 0.08401189024860416
Trained batch 183 in epoch 17, gen_loss = 0.3873625677888808, disc_loss = 0.08472392445875575
Trained batch 184 in epoch 17, gen_loss = 0.38752119782808664, disc_loss = 0.08553077583578793
Trained batch 185 in epoch 17, gen_loss = 0.3875386660457939, disc_loss = 0.08516349351053597
Trained batch 186 in epoch 17, gen_loss = 0.3870105485227656, disc_loss = 0.08516310358589346
Trained batch 187 in epoch 17, gen_loss = 0.38713030421987493, disc_loss = 0.08521918690902122
Trained batch 188 in epoch 17, gen_loss = 0.3870757318362988, disc_loss = 0.08514781414516388
Trained batch 189 in epoch 17, gen_loss = 0.38711683891321486, disc_loss = 0.08489005232327863
Trained batch 190 in epoch 17, gen_loss = 0.3870792079970475, disc_loss = 0.08463292334872391
Trained batch 191 in epoch 17, gen_loss = 0.38713961203272146, disc_loss = 0.08437612342337768
Trained batch 192 in epoch 17, gen_loss = 0.3870964487290753, disc_loss = 0.08414669053078933
Trained batch 193 in epoch 17, gen_loss = 0.38720294418408696, disc_loss = 0.08403939834421444
Trained batch 194 in epoch 17, gen_loss = 0.3871425005105826, disc_loss = 0.08406543070689226
Trained batch 195 in epoch 17, gen_loss = 0.38703441133304517, disc_loss = 0.08401338892931841
Trained batch 196 in epoch 17, gen_loss = 0.38726651759317077, disc_loss = 0.08371126650818411
Trained batch 197 in epoch 17, gen_loss = 0.3871224235103588, disc_loss = 0.08336819459994634
Trained batch 198 in epoch 17, gen_loss = 0.38681445004952014, disc_loss = 0.08321226498664323
Trained batch 199 in epoch 17, gen_loss = 0.3870235954225063, disc_loss = 0.0828990453388542
Trained batch 200 in epoch 17, gen_loss = 0.3868986678064166, disc_loss = 0.08260613091438268
Trained batch 201 in epoch 17, gen_loss = 0.386979948323552, disc_loss = 0.082719009526369
Trained batch 202 in epoch 17, gen_loss = 0.38731299025084587, disc_loss = 0.08329421425871368
Trained batch 203 in epoch 17, gen_loss = 0.3878064358643457, disc_loss = 0.08402027917441492
Trained batch 204 in epoch 17, gen_loss = 0.3877075958542707, disc_loss = 0.08383850036416111
Trained batch 205 in epoch 17, gen_loss = 0.3875613467207233, disc_loss = 0.08347015396592397
Trained batch 206 in epoch 17, gen_loss = 0.3876117493795312, disc_loss = 0.08328134903981202
Trained batch 207 in epoch 17, gen_loss = 0.38753829065423745, disc_loss = 0.08329960613404043
Trained batch 208 in epoch 17, gen_loss = 0.3876646045577583, disc_loss = 0.08381795942890302
Trained batch 209 in epoch 17, gen_loss = 0.38746720992383504, disc_loss = 0.08431497084065562
Trained batch 210 in epoch 17, gen_loss = 0.3878292706905383, disc_loss = 0.08408433665914275
Trained batch 211 in epoch 17, gen_loss = 0.387627919608692, disc_loss = 0.0837884329891992
Trained batch 212 in epoch 17, gen_loss = 0.38801554838816327, disc_loss = 0.08355932990570024
Trained batch 213 in epoch 17, gen_loss = 0.3882502023583261, disc_loss = 0.0836902365924042
Trained batch 214 in epoch 17, gen_loss = 0.38874920648197797, disc_loss = 0.08359106371915617
Trained batch 215 in epoch 17, gen_loss = 0.3891483118964566, disc_loss = 0.08336369715699996
Trained batch 216 in epoch 17, gen_loss = 0.3895144106880311, disc_loss = 0.08312856407690158
Trained batch 217 in epoch 17, gen_loss = 0.3895230172970973, disc_loss = 0.0829119588154445
Trained batch 218 in epoch 17, gen_loss = 0.38938200609869067, disc_loss = 0.08287156296715345
Trained batch 219 in epoch 17, gen_loss = 0.3894649662754752, disc_loss = 0.08323266189545393
Trained batch 220 in epoch 17, gen_loss = 0.38932224986779745, disc_loss = 0.08329783927868395
Trained batch 221 in epoch 17, gen_loss = 0.3890275055760736, disc_loss = 0.08303677587694414
Trained batch 222 in epoch 17, gen_loss = 0.38886579804356325, disc_loss = 0.08290888552842118
Trained batch 223 in epoch 17, gen_loss = 0.389191597700119, disc_loss = 0.08259939632262103
Trained batch 224 in epoch 17, gen_loss = 0.38910981827312047, disc_loss = 0.0828304461348388
Trained batch 225 in epoch 17, gen_loss = 0.38953397877975904, disc_loss = 0.08431119040330559
Trained batch 226 in epoch 17, gen_loss = 0.38917227647378055, disc_loss = 0.08398384886428648
Trained batch 227 in epoch 17, gen_loss = 0.38872151129078447, disc_loss = 0.08368507595406029
Trained batch 228 in epoch 17, gen_loss = 0.38868509968295367, disc_loss = 0.08349401589206473
Trained batch 229 in epoch 17, gen_loss = 0.3886640724928483, disc_loss = 0.08374665143859128
Trained batch 230 in epoch 17, gen_loss = 0.3887436616988409, disc_loss = 0.08368220139149722
Trained batch 231 in epoch 17, gen_loss = 0.3885563260008549, disc_loss = 0.08359425159267567
Trained batch 232 in epoch 17, gen_loss = 0.38853081638720927, disc_loss = 0.0833769625236676
Trained batch 233 in epoch 17, gen_loss = 0.3886578840832425, disc_loss = 0.08330805094228086
Trained batch 234 in epoch 17, gen_loss = 0.38864333071607227, disc_loss = 0.0832170964000707
Trained batch 235 in epoch 17, gen_loss = 0.3886240057773509, disc_loss = 0.08317033000195682
Trained batch 236 in epoch 17, gen_loss = 0.3885159227163983, disc_loss = 0.08325632153086773
Trained batch 237 in epoch 17, gen_loss = 0.38859657968292716, disc_loss = 0.08324202063235164
Trained batch 238 in epoch 17, gen_loss = 0.38832503357691744, disc_loss = 0.08317896643474261
Trained batch 239 in epoch 17, gen_loss = 0.3886405609548092, disc_loss = 0.08311893670664479
Trained batch 240 in epoch 17, gen_loss = 0.3886701071410753, disc_loss = 0.0828432800688808
Trained batch 241 in epoch 17, gen_loss = 0.38836177333819966, disc_loss = 0.0832624304346925
Trained batch 242 in epoch 17, gen_loss = 0.38822153284225935, disc_loss = 0.08315015301384308
Trained batch 243 in epoch 17, gen_loss = 0.38795683276457865, disc_loss = 0.08303051282361638
Trained batch 244 in epoch 17, gen_loss = 0.38805941221665363, disc_loss = 0.08283636338096492
Trained batch 245 in epoch 17, gen_loss = 0.3878414142664855, disc_loss = 0.08301997505037523
Trained batch 246 in epoch 17, gen_loss = 0.38852209781828195, disc_loss = 0.08383124480815793
Trained batch 247 in epoch 17, gen_loss = 0.38844386968881855, disc_loss = 0.08373005145169314
Trained batch 248 in epoch 17, gen_loss = 0.388619059539703, disc_loss = 0.08350291911766951
Trained batch 249 in epoch 17, gen_loss = 0.3888069064617157, disc_loss = 0.08373564944416284
Trained batch 250 in epoch 17, gen_loss = 0.3887071911082325, disc_loss = 0.08452431398232382
Trained batch 251 in epoch 17, gen_loss = 0.38874431805951254, disc_loss = 0.08520092469980083
Trained batch 252 in epoch 17, gen_loss = 0.3885634336546947, disc_loss = 0.08493834816420032
Trained batch 253 in epoch 17, gen_loss = 0.388328715689539, disc_loss = 0.08494614234824818
Trained batch 254 in epoch 17, gen_loss = 0.3883972054603053, disc_loss = 0.08471287365491484
Trained batch 255 in epoch 17, gen_loss = 0.3884738921187818, disc_loss = 0.08441629457956878
Trained batch 256 in epoch 17, gen_loss = 0.388549359276137, disc_loss = 0.08428827930488243
Trained batch 257 in epoch 17, gen_loss = 0.3885589423336724, disc_loss = 0.08457156749398903
Trained batch 258 in epoch 17, gen_loss = 0.3886976266229475, disc_loss = 0.08449668272553033
Trained batch 259 in epoch 17, gen_loss = 0.38861857709976344, disc_loss = 0.08428412908688188
Trained batch 260 in epoch 17, gen_loss = 0.388407647038785, disc_loss = 0.08409955564500957
Trained batch 261 in epoch 17, gen_loss = 0.38833443467853634, disc_loss = 0.08390535997895111
Trained batch 262 in epoch 17, gen_loss = 0.38832430989116773, disc_loss = 0.08371251656500332
Trained batch 263 in epoch 17, gen_loss = 0.38835889665466367, disc_loss = 0.08343146209407484
Trained batch 264 in epoch 17, gen_loss = 0.38820041035706143, disc_loss = 0.08336838282785326
Trained batch 265 in epoch 17, gen_loss = 0.38828982009475393, disc_loss = 0.08322724180394098
Trained batch 266 in epoch 17, gen_loss = 0.3882266456045015, disc_loss = 0.08330296176705468
Trained batch 267 in epoch 17, gen_loss = 0.3880223085853591, disc_loss = 0.08305295342718487
Trained batch 268 in epoch 17, gen_loss = 0.38824406266212463, disc_loss = 0.08316209391590387
Trained batch 269 in epoch 17, gen_loss = 0.38836722936895157, disc_loss = 0.08295003184013897
Trained batch 270 in epoch 17, gen_loss = 0.38795077327872557, disc_loss = 0.08345223966009942
Trained batch 271 in epoch 17, gen_loss = 0.3880130605881705, disc_loss = 0.08372700978618335
Trained batch 272 in epoch 17, gen_loss = 0.38791325753861733, disc_loss = 0.08349406109242649
Trained batch 273 in epoch 17, gen_loss = 0.3879823375792399, disc_loss = 0.08323183645541868
Trained batch 274 in epoch 17, gen_loss = 0.3878685760498047, disc_loss = 0.08305334750224244
Trained batch 275 in epoch 17, gen_loss = 0.38738966387683066, disc_loss = 0.08287848314216388
Trained batch 276 in epoch 17, gen_loss = 0.38760887801862365, disc_loss = 0.0827005980099259
Trained batch 277 in epoch 17, gen_loss = 0.3875830172420406, disc_loss = 0.08266920714954035
Trained batch 278 in epoch 17, gen_loss = 0.38737714856756206, disc_loss = 0.08307093030048741
Trained batch 279 in epoch 17, gen_loss = 0.38754917606711387, disc_loss = 0.08321489793514567
Trained batch 280 in epoch 17, gen_loss = 0.38732029778677374, disc_loss = 0.0832826207289174
Trained batch 281 in epoch 17, gen_loss = 0.3872020569042111, disc_loss = 0.0833495064367745
Trained batch 282 in epoch 17, gen_loss = 0.38740911268935185, disc_loss = 0.08316521378819808
Trained batch 283 in epoch 17, gen_loss = 0.38712150036868914, disc_loss = 0.08302372593668775
Trained batch 284 in epoch 17, gen_loss = 0.38739735797831887, disc_loss = 0.08319960737829668
Trained batch 285 in epoch 17, gen_loss = 0.3871509938181697, disc_loss = 0.08331396536888568
Trained batch 286 in epoch 17, gen_loss = 0.3873982190670452, disc_loss = 0.08324422185611019
Trained batch 287 in epoch 17, gen_loss = 0.3877108742793401, disc_loss = 0.08344851278363624
Trained batch 288 in epoch 17, gen_loss = 0.3875699958999264, disc_loss = 0.08346631678923397
Trained batch 289 in epoch 17, gen_loss = 0.38787766027039494, disc_loss = 0.0835861402017803
Trained batch 290 in epoch 17, gen_loss = 0.3876884917622989, disc_loss = 0.08334807544959472
Trained batch 291 in epoch 17, gen_loss = 0.3876276291804771, disc_loss = 0.08430208684557615
Trained batch 292 in epoch 17, gen_loss = 0.38780068944338647, disc_loss = 0.0846870901164799
Trained batch 293 in epoch 17, gen_loss = 0.38794690330012316, disc_loss = 0.08451680502328439
Trained batch 294 in epoch 17, gen_loss = 0.3877107194924759, disc_loss = 0.08451355607643471
Trained batch 295 in epoch 17, gen_loss = 0.38758622331393733, disc_loss = 0.08430484739899938
Trained batch 296 in epoch 17, gen_loss = 0.38736369914880103, disc_loss = 0.0841272083089157
Trained batch 297 in epoch 17, gen_loss = 0.3873093586240039, disc_loss = 0.08421186448681174
Trained batch 298 in epoch 17, gen_loss = 0.3872006281363127, disc_loss = 0.0840658334280087
Trained batch 299 in epoch 17, gen_loss = 0.3873022222518921, disc_loss = 0.08391913215008874
Trained batch 300 in epoch 17, gen_loss = 0.38775488645135364, disc_loss = 0.08371803519374806
Trained batch 301 in epoch 17, gen_loss = 0.3877719673297263, disc_loss = 0.08365688866177043
Trained batch 302 in epoch 17, gen_loss = 0.38807044810194385, disc_loss = 0.08346014464636742
Trained batch 303 in epoch 17, gen_loss = 0.3881608146781984, disc_loss = 0.08390410212297483
Trained batch 304 in epoch 17, gen_loss = 0.3879824583647681, disc_loss = 0.08479030852618276
Trained batch 305 in epoch 17, gen_loss = 0.38803187450941873, disc_loss = 0.0846054833534545
Trained batch 306 in epoch 17, gen_loss = 0.388408331704062, disc_loss = 0.0850701169034994
Trained batch 307 in epoch 17, gen_loss = 0.38844309156978285, disc_loss = 0.08517523088444073
Trained batch 308 in epoch 17, gen_loss = 0.3884088404741874, disc_loss = 0.08520258035100876
Trained batch 309 in epoch 17, gen_loss = 0.38875708445425955, disc_loss = 0.08543545717012978
Trained batch 310 in epoch 17, gen_loss = 0.3885330911426299, disc_loss = 0.08539449835908854
Trained batch 311 in epoch 17, gen_loss = 0.3882832908286498, disc_loss = 0.08540790607161725
Trained batch 312 in epoch 17, gen_loss = 0.38822388477599656, disc_loss = 0.08592185904435552
Trained batch 313 in epoch 17, gen_loss = 0.3881364448624811, disc_loss = 0.08633482544297341
Trained batch 314 in epoch 17, gen_loss = 0.3885821939460815, disc_loss = 0.0861506988811824
Trained batch 315 in epoch 17, gen_loss = 0.3888075220622594, disc_loss = 0.08603052443329574
Trained batch 316 in epoch 17, gen_loss = 0.3887575626937373, disc_loss = 0.0858965002746565
Trained batch 317 in epoch 17, gen_loss = 0.3883740576745579, disc_loss = 0.08606265719288832
Trained batch 318 in epoch 17, gen_loss = 0.38841512135951123, disc_loss = 0.08597235138408349
Trained batch 319 in epoch 17, gen_loss = 0.3883755893446505, disc_loss = 0.08602929771586787
Trained batch 320 in epoch 17, gen_loss = 0.38852046267637214, disc_loss = 0.08614937812264
Trained batch 321 in epoch 17, gen_loss = 0.3885564003486811, disc_loss = 0.08592390618720873
Trained batch 322 in epoch 17, gen_loss = 0.38848411280304285, disc_loss = 0.08584505262216639
Trained batch 323 in epoch 17, gen_loss = 0.3886415557360943, disc_loss = 0.0856659963387812
Trained batch 324 in epoch 17, gen_loss = 0.3886380999821883, disc_loss = 0.08564733212097334
Trained batch 325 in epoch 17, gen_loss = 0.3883756206262331, disc_loss = 0.0862635346672332
Trained batch 326 in epoch 17, gen_loss = 0.3883648285078346, disc_loss = 0.0863623515665759
Trained batch 327 in epoch 17, gen_loss = 0.38827818141477866, disc_loss = 0.08614059414135337
Trained batch 328 in epoch 17, gen_loss = 0.38828357483478304, disc_loss = 0.08597844611785423
Trained batch 329 in epoch 17, gen_loss = 0.38814189352772455, disc_loss = 0.08599472778821082
Trained batch 330 in epoch 17, gen_loss = 0.388358470626468, disc_loss = 0.08598848242380197
Trained batch 331 in epoch 17, gen_loss = 0.38836633243474616, disc_loss = 0.08587365497902305
Trained batch 332 in epoch 17, gen_loss = 0.3881898330854582, disc_loss = 0.08576106183040696
Trained batch 333 in epoch 17, gen_loss = 0.38785390671855674, disc_loss = 0.08581397982738065
Trained batch 334 in epoch 17, gen_loss = 0.388014804160417, disc_loss = 0.08569348671598666
Trained batch 335 in epoch 17, gen_loss = 0.38813696721834795, disc_loss = 0.08564448497712701
Trained batch 336 in epoch 17, gen_loss = 0.3878795164098372, disc_loss = 0.08584122080355883
Trained batch 337 in epoch 17, gen_loss = 0.38814256556288024, disc_loss = 0.08572119794312048
Trained batch 338 in epoch 17, gen_loss = 0.388117259582587, disc_loss = 0.08556261807295513
Trained batch 339 in epoch 17, gen_loss = 0.3880745437215356, disc_loss = 0.08574019056087469
Trained batch 340 in epoch 17, gen_loss = 0.38800875409956903, disc_loss = 0.08574594814286642
Trained batch 341 in epoch 17, gen_loss = 0.38797254032558864, disc_loss = 0.08557633893041496
Trained batch 342 in epoch 17, gen_loss = 0.3880681211329758, disc_loss = 0.08542582443467295
Trained batch 343 in epoch 17, gen_loss = 0.3881369579670041, disc_loss = 0.08525785586937483
Trained batch 344 in epoch 17, gen_loss = 0.3882205310939015, disc_loss = 0.08507993067142325
Trained batch 345 in epoch 17, gen_loss = 0.38814834096183665, disc_loss = 0.08493210635056471
Trained batch 346 in epoch 17, gen_loss = 0.3884055701215947, disc_loss = 0.08500792647870284
Trained batch 347 in epoch 17, gen_loss = 0.38849853844135657, disc_loss = 0.08589604556100207
Trained batch 348 in epoch 17, gen_loss = 0.3885382534268934, disc_loss = 0.08573591536482032
Trained batch 349 in epoch 17, gen_loss = 0.3886751266036715, disc_loss = 0.08588209959279214
Trained batch 350 in epoch 17, gen_loss = 0.3884464785074576, disc_loss = 0.08607076641511799
Trained batch 351 in epoch 17, gen_loss = 0.3885745687240904, disc_loss = 0.08589967176984911
Trained batch 352 in epoch 17, gen_loss = 0.38853065184088, disc_loss = 0.08577980503978118
Trained batch 353 in epoch 17, gen_loss = 0.38852809807338284, disc_loss = 0.08562967650287148
Trained batch 354 in epoch 17, gen_loss = 0.3886679743377256, disc_loss = 0.08556658201391848
Trained batch 355 in epoch 17, gen_loss = 0.3887803844186697, disc_loss = 0.08549076322664957
Trained batch 356 in epoch 17, gen_loss = 0.38864423530776293, disc_loss = 0.08553206561399358
Trained batch 357 in epoch 17, gen_loss = 0.38872473216589604, disc_loss = 0.08565103820155702
Trained batch 358 in epoch 17, gen_loss = 0.38866976277077764, disc_loss = 0.08589534618967008
Trained batch 359 in epoch 17, gen_loss = 0.3886466807789273, disc_loss = 0.08572116109490809
Trained batch 360 in epoch 17, gen_loss = 0.388760373698047, disc_loss = 0.08557119098984717
Trained batch 361 in epoch 17, gen_loss = 0.3887612888826191, disc_loss = 0.08547849712625805
Trained batch 362 in epoch 17, gen_loss = 0.38861583078859924, disc_loss = 0.08550771428708284
Trained batch 363 in epoch 17, gen_loss = 0.38895269532452575, disc_loss = 0.08573134290822014
Trained batch 364 in epoch 17, gen_loss = 0.3890623836484674, disc_loss = 0.08561926110813471
Trained batch 365 in epoch 17, gen_loss = 0.38899333335337094, disc_loss = 0.0854824258783028
Trained batch 366 in epoch 17, gen_loss = 0.38894971279422336, disc_loss = 0.08550081352578928
Trained batch 367 in epoch 17, gen_loss = 0.388892082416493, disc_loss = 0.08561184849721663
Trained batch 368 in epoch 17, gen_loss = 0.38887342560258986, disc_loss = 0.08551352507709892
Trained batch 369 in epoch 17, gen_loss = 0.38885134659908915, disc_loss = 0.0853802829200553
Trained batch 370 in epoch 17, gen_loss = 0.38880580760076683, disc_loss = 0.08530839640305772
Trained batch 371 in epoch 17, gen_loss = 0.3887802353629502, disc_loss = 0.085255839503921
Trained batch 372 in epoch 17, gen_loss = 0.3886247796603246, disc_loss = 0.08515216573203936
Trained batch 373 in epoch 17, gen_loss = 0.38840065601675267, disc_loss = 0.08497403697783058
Trained batch 374 in epoch 17, gen_loss = 0.3885648170312246, disc_loss = 0.08523368319123983
Trained batch 375 in epoch 17, gen_loss = 0.3882642737094392, disc_loss = 0.08635838448931958
Trained batch 376 in epoch 17, gen_loss = 0.38816775085122895, disc_loss = 0.08647172228341789
Trained batch 377 in epoch 17, gen_loss = 0.3882468668399034, disc_loss = 0.08680295404391708
Trained batch 378 in epoch 17, gen_loss = 0.38811062736372837, disc_loss = 0.08699938816345225
Trained batch 379 in epoch 17, gen_loss = 0.3879393043486696, disc_loss = 0.0871201417580443
Trained batch 380 in epoch 17, gen_loss = 0.3880266243704348, disc_loss = 0.08716241149305123
Trained batch 381 in epoch 17, gen_loss = 0.38816533584869345, disc_loss = 0.0870745801708188
Trained batch 382 in epoch 17, gen_loss = 0.3881279181095701, disc_loss = 0.08694911161899645
Trained batch 383 in epoch 17, gen_loss = 0.38815026078373194, disc_loss = 0.08695017790159909
Trained batch 384 in epoch 17, gen_loss = 0.38826082186265426, disc_loss = 0.08725178182947559
Trained batch 385 in epoch 17, gen_loss = 0.3882983086794769, disc_loss = 0.08716253589095616
Trained batch 386 in epoch 17, gen_loss = 0.38832329925948644, disc_loss = 0.08706639914289695
Trained batch 387 in epoch 17, gen_loss = 0.3882441082105194, disc_loss = 0.08692086246776749
Trained batch 388 in epoch 17, gen_loss = 0.3885052618606538, disc_loss = 0.08678703979950561
Trained batch 389 in epoch 17, gen_loss = 0.3886012968344566, disc_loss = 0.08665286628051828
Trained batch 390 in epoch 17, gen_loss = 0.3886912342380075, disc_loss = 0.0864639549856753
Trained batch 391 in epoch 17, gen_loss = 0.3888128218146003, disc_loss = 0.08630488996336959
Trained batch 392 in epoch 17, gen_loss = 0.38881558255688226, disc_loss = 0.08614608296607894
Trained batch 393 in epoch 17, gen_loss = 0.38877350833210245, disc_loss = 0.08610558702709711
Trained batch 394 in epoch 17, gen_loss = 0.38858379268948035, disc_loss = 0.08638245870795432
Trained batch 395 in epoch 17, gen_loss = 0.3887799796883506, disc_loss = 0.08671206999758277
Trained batch 396 in epoch 17, gen_loss = 0.38864797751609265, disc_loss = 0.08686121007056921
Trained batch 397 in epoch 17, gen_loss = 0.38852305380842794, disc_loss = 0.08677724000047798
Trained batch 398 in epoch 17, gen_loss = 0.3884949288272619, disc_loss = 0.08676852894606148
Trained batch 399 in epoch 17, gen_loss = 0.3883492641896009, disc_loss = 0.0869462513178587
Trained batch 400 in epoch 17, gen_loss = 0.38845866703035825, disc_loss = 0.08725648055647377
Trained batch 401 in epoch 17, gen_loss = 0.3883848351922201, disc_loss = 0.08714302307671279
Trained batch 402 in epoch 17, gen_loss = 0.38833104232996335, disc_loss = 0.08702782664457266
Trained batch 403 in epoch 17, gen_loss = 0.38843022397544125, disc_loss = 0.08699347557370911
Trained batch 404 in epoch 17, gen_loss = 0.3885360163670999, disc_loss = 0.08688844177458022
Trained batch 405 in epoch 17, gen_loss = 0.38858014558042797, disc_loss = 0.08710688664554962
Trained batch 406 in epoch 17, gen_loss = 0.38881226451449663, disc_loss = 0.08759611687584064
Trained batch 407 in epoch 17, gen_loss = 0.3886088744974604, disc_loss = 0.08768649559979345
Trained batch 408 in epoch 17, gen_loss = 0.38865894224941, disc_loss = 0.08755916069218465
Trained batch 409 in epoch 17, gen_loss = 0.3887481136292946, disc_loss = 0.08743167420531192
Trained batch 410 in epoch 17, gen_loss = 0.3886419418664454, disc_loss = 0.08728585109440949
Trained batch 411 in epoch 17, gen_loss = 0.3887001429367991, disc_loss = 0.08713612734855523
Trained batch 412 in epoch 17, gen_loss = 0.38881751360962524, disc_loss = 0.08697509849511682
Trained batch 413 in epoch 17, gen_loss = 0.38863331921722577, disc_loss = 0.08690242578190017
Trained batch 414 in epoch 17, gen_loss = 0.38843207215688313, disc_loss = 0.08689701579600932
Trained batch 415 in epoch 17, gen_loss = 0.3885528531212073, disc_loss = 0.08700015772886288
Trained batch 416 in epoch 17, gen_loss = 0.388530202477956, disc_loss = 0.08691671564817714
Trained batch 417 in epoch 17, gen_loss = 0.38852582187458656, disc_loss = 0.08683577993590581
Trained batch 418 in epoch 17, gen_loss = 0.38843798672953767, disc_loss = 0.08677927901643842
Trained batch 419 in epoch 17, gen_loss = 0.3885160282254219, disc_loss = 0.08723285798692987
Trained batch 420 in epoch 17, gen_loss = 0.38822875205524743, disc_loss = 0.08775961148660993
Trained batch 421 in epoch 17, gen_loss = 0.3881098026347951, disc_loss = 0.08762415228367416
Trained batch 422 in epoch 17, gen_loss = 0.38818807100291514, disc_loss = 0.08761784490682273
Trained batch 423 in epoch 17, gen_loss = 0.388246246033682, disc_loss = 0.08754623792011221
Trained batch 424 in epoch 17, gen_loss = 0.3879554339016185, disc_loss = 0.08798759528819253
Trained batch 425 in epoch 17, gen_loss = 0.38799346584669303, disc_loss = 0.08800847732195272
Trained batch 426 in epoch 17, gen_loss = 0.3879677242920047, disc_loss = 0.08783095853023702
Trained batch 427 in epoch 17, gen_loss = 0.38809518307168905, disc_loss = 0.0876485367270761
Trained batch 428 in epoch 17, gen_loss = 0.3880918821393749, disc_loss = 0.08751062664587597
Trained batch 429 in epoch 17, gen_loss = 0.3879606979530911, disc_loss = 0.08744020601951105
Trained batch 430 in epoch 17, gen_loss = 0.38805854604028495, disc_loss = 0.0877119576009617
Trained batch 431 in epoch 17, gen_loss = 0.38789030640489525, disc_loss = 0.08789128714879216
Trained batch 432 in epoch 17, gen_loss = 0.38783149548546, disc_loss = 0.0877626794444152
Trained batch 433 in epoch 17, gen_loss = 0.38783794511023756, disc_loss = 0.08759919570304008
Trained batch 434 in epoch 17, gen_loss = 0.38787034140236076, disc_loss = 0.08746818610220805
Trained batch 435 in epoch 17, gen_loss = 0.38771627221359023, disc_loss = 0.08747195286266164
Trained batch 436 in epoch 17, gen_loss = 0.3877894797232386, disc_loss = 0.08773688628877464
Trained batch 437 in epoch 17, gen_loss = 0.3878166398637371, disc_loss = 0.08760967391828016
Trained batch 438 in epoch 17, gen_loss = 0.3879274321987308, disc_loss = 0.08745740834784807
Trained batch 439 in epoch 17, gen_loss = 0.38779095926068047, disc_loss = 0.0873834777327085
Trained batch 440 in epoch 17, gen_loss = 0.38787688135830456, disc_loss = 0.0874139839432745
Trained batch 441 in epoch 17, gen_loss = 0.38789284384358524, disc_loss = 0.0873748616302782
Trained batch 442 in epoch 17, gen_loss = 0.3879429799573954, disc_loss = 0.08726261157130415
Trained batch 443 in epoch 17, gen_loss = 0.38818990613694665, disc_loss = 0.08710312869752178
Trained batch 444 in epoch 17, gen_loss = 0.3880773359470153, disc_loss = 0.08700481038331316
Trained batch 445 in epoch 17, gen_loss = 0.3881479567209167, disc_loss = 0.08689282174251406
Trained batch 446 in epoch 17, gen_loss = 0.38809421585176884, disc_loss = 0.08680666461003574
Trained batch 447 in epoch 17, gen_loss = 0.3881956475919911, disc_loss = 0.08678552893772055
Trained batch 448 in epoch 17, gen_loss = 0.3881714225877367, disc_loss = 0.08683571111170248
Trained batch 449 in epoch 17, gen_loss = 0.3884472183386485, disc_loss = 0.08687772215654453
Trained batch 450 in epoch 17, gen_loss = 0.388560377177008, disc_loss = 0.08670357662457519
Trained batch 451 in epoch 17, gen_loss = 0.3885259014447178, disc_loss = 0.08664541271828378
Trained batch 452 in epoch 17, gen_loss = 0.38844648753570404, disc_loss = 0.08664146900201673
Trained batch 453 in epoch 17, gen_loss = 0.3882480552543102, disc_loss = 0.08674378980911185
Trained batch 454 in epoch 17, gen_loss = 0.3883413931170663, disc_loss = 0.08675018549579513
Trained batch 455 in epoch 17, gen_loss = 0.3884164214526352, disc_loss = 0.08661872259414706
Trained batch 456 in epoch 17, gen_loss = 0.38837603960569367, disc_loss = 0.08647278490673987
Trained batch 457 in epoch 17, gen_loss = 0.38842306757858225, disc_loss = 0.08633821904781279
Trained batch 458 in epoch 17, gen_loss = 0.3885227163892426, disc_loss = 0.08628042023385467
Trained batch 459 in epoch 17, gen_loss = 0.3884917713377787, disc_loss = 0.0862311419322277
Trained batch 460 in epoch 17, gen_loss = 0.3886674716260583, disc_loss = 0.08608787527223019
Trained batch 461 in epoch 17, gen_loss = 0.3884975274145861, disc_loss = 0.08602013035971688
Trained batch 462 in epoch 17, gen_loss = 0.3883083996324766, disc_loss = 0.08593003006277859
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.3179778754711151, disc_loss = 0.16122578084468842
Trained batch 1 in epoch 18, gen_loss = 0.3604385405778885, disc_loss = 0.15623097866773605
Trained batch 2 in epoch 18, gen_loss = 0.34998146692911786, disc_loss = 0.12234323968489964
Trained batch 3 in epoch 18, gen_loss = 0.34775132685899734, disc_loss = 0.11868789419531822
Trained batch 4 in epoch 18, gen_loss = 0.37418429255485536, disc_loss = 0.11988858133554459
Trained batch 5 in epoch 18, gen_loss = 0.37217555443445843, disc_loss = 0.11179594571391742
Trained batch 6 in epoch 18, gen_loss = 0.36523060287748066, disc_loss = 0.10087148791977338
Trained batch 7 in epoch 18, gen_loss = 0.36708397790789604, disc_loss = 0.09118012525141239
Trained batch 8 in epoch 18, gen_loss = 0.3653741214010451, disc_loss = 0.08576427648464839
Trained batch 9 in epoch 18, gen_loss = 0.37251815795898435, disc_loss = 0.08488037958741187
Trained batch 10 in epoch 18, gen_loss = 0.37971612540158356, disc_loss = 0.0811104445972226
Trained batch 11 in epoch 18, gen_loss = 0.38618551194667816, disc_loss = 0.07782924175262451
Trained batch 12 in epoch 18, gen_loss = 0.3832211494445801, disc_loss = 0.07774075865745544
Trained batch 13 in epoch 18, gen_loss = 0.3834606877395085, disc_loss = 0.0747929537402732
Trained batch 14 in epoch 18, gen_loss = 0.38322850068410236, disc_loss = 0.07120447133978208
Trained batch 15 in epoch 18, gen_loss = 0.3889732342213392, disc_loss = 0.06809704517945647
Trained batch 16 in epoch 18, gen_loss = 0.3859800240572761, disc_loss = 0.07129358500242233
Trained batch 17 in epoch 18, gen_loss = 0.3850829303264618, disc_loss = 0.0703001394867897
Trained batch 18 in epoch 18, gen_loss = 0.3858343880427511, disc_loss = 0.06774045487767771
Trained batch 19 in epoch 18, gen_loss = 0.38991775214672086, disc_loss = 0.06467769292648881
Trained batch 20 in epoch 18, gen_loss = 0.3882353277433486, disc_loss = 0.06400612650793933
Trained batch 21 in epoch 18, gen_loss = 0.3901473974639719, disc_loss = 0.06413328256034716
Trained batch 22 in epoch 18, gen_loss = 0.39473332529482635, disc_loss = 0.0637244914010491
Trained batch 23 in epoch 18, gen_loss = 0.3915581579009692, disc_loss = 0.06222367393396174
Trained batch 24 in epoch 18, gen_loss = 0.39309936881065366, disc_loss = 0.06015628760680556
Trained batch 25 in epoch 18, gen_loss = 0.3911405240113919, disc_loss = 0.060638647580232755
Trained batch 26 in epoch 18, gen_loss = 0.394468159587295, disc_loss = 0.06427325451470635
Trained batch 27 in epoch 18, gen_loss = 0.3952565225107329, disc_loss = 0.062230328347400894
Trained batch 28 in epoch 18, gen_loss = 0.3928392005377802, disc_loss = 0.06212383352926579
Trained batch 29 in epoch 18, gen_loss = 0.3926132619380951, disc_loss = 0.06058249223666887
Trained batch 30 in epoch 18, gen_loss = 0.39111755067302334, disc_loss = 0.05889648299724344
Trained batch 31 in epoch 18, gen_loss = 0.39237180817872286, disc_loss = 0.05837794781837147
Trained batch 32 in epoch 18, gen_loss = 0.3929114919720274, disc_loss = 0.0591325743377886
Trained batch 33 in epoch 18, gen_loss = 0.39415572145405936, disc_loss = 0.059232737581409955
Trained batch 34 in epoch 18, gen_loss = 0.3934893650668008, disc_loss = 0.05800262815984232
Trained batch 35 in epoch 18, gen_loss = 0.3934921208355162, disc_loss = 0.056605131740474865
Trained batch 36 in epoch 18, gen_loss = 0.39379878301878235, disc_loss = 0.055740889476461185
Trained batch 37 in epoch 18, gen_loss = 0.39474159792849894, disc_loss = 0.05493613578820307
Trained batch 38 in epoch 18, gen_loss = 0.3977956588451679, disc_loss = 0.054043807196789063
Trained batch 39 in epoch 18, gen_loss = 0.3974559858441353, disc_loss = 0.05398524283664301
Trained batch 40 in epoch 18, gen_loss = 0.4010421880861608, disc_loss = 0.05524959025631954
Trained batch 41 in epoch 18, gen_loss = 0.39950567129112424, disc_loss = 0.05718548588144282
Trained batch 42 in epoch 18, gen_loss = 0.39983602387960565, disc_loss = 0.05769535423754606
Trained batch 43 in epoch 18, gen_loss = 0.3993607265028087, disc_loss = 0.05668323244687847
Trained batch 44 in epoch 18, gen_loss = 0.39913996126916673, disc_loss = 0.0558204358133177
Trained batch 45 in epoch 18, gen_loss = 0.39829843394134357, disc_loss = 0.054779335441391755
Trained batch 46 in epoch 18, gen_loss = 0.3978275352335991, disc_loss = 0.05399839016311663
Trained batch 47 in epoch 18, gen_loss = 0.3970044447729985, disc_loss = 0.05432245623281536
Trained batch 48 in epoch 18, gen_loss = 0.3966384864583307, disc_loss = 0.055761872268072804
Trained batch 49 in epoch 18, gen_loss = 0.3964206022024155, disc_loss = 0.05526922195218503
Trained batch 50 in epoch 18, gen_loss = 0.39651885044340995, disc_loss = 0.05431518133948831
Trained batch 51 in epoch 18, gen_loss = 0.39656436386016697, disc_loss = 0.05419725158180182
Trained batch 52 in epoch 18, gen_loss = 0.3976103882744627, disc_loss = 0.057273622461647355
Trained batch 53 in epoch 18, gen_loss = 0.3963149890855507, disc_loss = 0.06309741521599116
Trained batch 54 in epoch 18, gen_loss = 0.397603437575427, disc_loss = 0.06352510567415845
Trained batch 55 in epoch 18, gen_loss = 0.3968183563223907, disc_loss = 0.06274818402848073
Trained batch 56 in epoch 18, gen_loss = 0.3960341633411876, disc_loss = 0.06211984680410017
Trained batch 57 in epoch 18, gen_loss = 0.3963907170912315, disc_loss = 0.06135080433611212
Trained batch 58 in epoch 18, gen_loss = 0.3973334921618639, disc_loss = 0.06115221421597367
Trained batch 59 in epoch 18, gen_loss = 0.39618505189816156, disc_loss = 0.0614351462572813
Trained batch 60 in epoch 18, gen_loss = 0.3949834147437674, disc_loss = 0.06431109751345682
Trained batch 61 in epoch 18, gen_loss = 0.397654241131198, disc_loss = 0.07130645131391863
Trained batch 62 in epoch 18, gen_loss = 0.39886736444064547, disc_loss = 0.0726847652168501
Trained batch 63 in epoch 18, gen_loss = 0.39853705232962966, disc_loss = 0.07358438044320792
Trained batch 64 in epoch 18, gen_loss = 0.39869926938643824, disc_loss = 0.0734153172144523
Trained batch 65 in epoch 18, gen_loss = 0.398909639228474, disc_loss = 0.07364701931223724
Trained batch 66 in epoch 18, gen_loss = 0.3998280634630972, disc_loss = 0.07293847725907368
Trained batch 67 in epoch 18, gen_loss = 0.3994891612845309, disc_loss = 0.07229468062081758
Trained batch 68 in epoch 18, gen_loss = 0.39983393921368365, disc_loss = 0.07169450271496738
Trained batch 69 in epoch 18, gen_loss = 0.399781887446131, disc_loss = 0.0716329869681171
Trained batch 70 in epoch 18, gen_loss = 0.3994008155775742, disc_loss = 0.07150499074077102
Trained batch 71 in epoch 18, gen_loss = 0.39983951672911644, disc_loss = 0.0706707743099994
Trained batch 72 in epoch 18, gen_loss = 0.39871673183898404, disc_loss = 0.07130389058426635
Trained batch 73 in epoch 18, gen_loss = 0.3967074759908625, disc_loss = 0.07246184630973919
Trained batch 74 in epoch 18, gen_loss = 0.39735277732213337, disc_loss = 0.0726599101225535
Trained batch 75 in epoch 18, gen_loss = 0.3972802699396485, disc_loss = 0.07218168264156893
Trained batch 76 in epoch 18, gen_loss = 0.39663468281944075, disc_loss = 0.07316367618449322
Trained batch 77 in epoch 18, gen_loss = 0.3969068087828465, disc_loss = 0.0745338302774307
Trained batch 78 in epoch 18, gen_loss = 0.39656858466848544, disc_loss = 0.07392984477779534
Trained batch 79 in epoch 18, gen_loss = 0.3962642062455416, disc_loss = 0.07343283230438828
Trained batch 80 in epoch 18, gen_loss = 0.3963798299247836, disc_loss = 0.0727756076986775
Trained batch 81 in epoch 18, gen_loss = 0.3970044844034242, disc_loss = 0.07195458142086864
Trained batch 82 in epoch 18, gen_loss = 0.39760076496974533, disc_loss = 0.07126878314169056
Trained batch 83 in epoch 18, gen_loss = 0.39645432042224066, disc_loss = 0.07103095660429626
Trained batch 84 in epoch 18, gen_loss = 0.39788006999913383, disc_loss = 0.07106643788078253
Trained batch 85 in epoch 18, gen_loss = 0.39799451446810435, disc_loss = 0.07042890345287878
Trained batch 86 in epoch 18, gen_loss = 0.3975254276703144, disc_loss = 0.06988853023483835
Trained batch 87 in epoch 18, gen_loss = 0.3974867605350234, disc_loss = 0.06976049448448149
Trained batch 88 in epoch 18, gen_loss = 0.39748436949226296, disc_loss = 0.07142645208520836
Trained batch 89 in epoch 18, gen_loss = 0.39607425332069396, disc_loss = 0.0715938730786244
Trained batch 90 in epoch 18, gen_loss = 0.3966106258250855, disc_loss = 0.0708701446150931
Trained batch 91 in epoch 18, gen_loss = 0.39700886121262674, disc_loss = 0.0703084176234172
Trained batch 92 in epoch 18, gen_loss = 0.3969405097987062, disc_loss = 0.0697226346850956
Trained batch 93 in epoch 18, gen_loss = 0.3968148076153816, disc_loss = 0.0693918498223053
Trained batch 94 in epoch 18, gen_loss = 0.39789464379611766, disc_loss = 0.06918487332663253
Trained batch 95 in epoch 18, gen_loss = 0.39773312862962484, disc_loss = 0.06932060354059406
Trained batch 96 in epoch 18, gen_loss = 0.3966428293395288, disc_loss = 0.07099253318954221
Trained batch 97 in epoch 18, gen_loss = 0.39656679149793117, disc_loss = 0.07052798044145564
Trained batch 98 in epoch 18, gen_loss = 0.39633775780899355, disc_loss = 0.07009469958097496
Trained batch 99 in epoch 18, gen_loss = 0.3959713104367256, disc_loss = 0.07074254296254366
Trained batch 100 in epoch 18, gen_loss = 0.3952176842359033, disc_loss = 0.0723843315551703
Trained batch 101 in epoch 18, gen_loss = 0.3961035767022301, disc_loss = 0.07190428052882791
Trained batch 102 in epoch 18, gen_loss = 0.3968072035937633, disc_loss = 0.07154923561255186
Trained batch 103 in epoch 18, gen_loss = 0.3969954275167905, disc_loss = 0.07124474371980447
Trained batch 104 in epoch 18, gen_loss = 0.39720971697852725, disc_loss = 0.0708073842161823
Trained batch 105 in epoch 18, gen_loss = 0.3970065493628664, disc_loss = 0.07107132059557117
Trained batch 106 in epoch 18, gen_loss = 0.3981376602270893, disc_loss = 0.07263342386424959
Trained batch 107 in epoch 18, gen_loss = 0.39832056120589926, disc_loss = 0.07262377459469631
Trained batch 108 in epoch 18, gen_loss = 0.3979516682821676, disc_loss = 0.07741079162891715
Trained batch 109 in epoch 18, gen_loss = 0.39814447191628544, disc_loss = 0.07719415417364375
Trained batch 110 in epoch 18, gen_loss = 0.3984914274366052, disc_loss = 0.07750856437980458
Trained batch 111 in epoch 18, gen_loss = 0.3978692955736603, disc_loss = 0.07797471012703941
Trained batch 112 in epoch 18, gen_loss = 0.397807309585335, disc_loss = 0.0774337371720611
Trained batch 113 in epoch 18, gen_loss = 0.3976400217466187, disc_loss = 0.0769931048996289
Trained batch 114 in epoch 18, gen_loss = 0.3979108144407687, disc_loss = 0.07686585940663582
Trained batch 115 in epoch 18, gen_loss = 0.397954273069727, disc_loss = 0.07864845982062277
Trained batch 116 in epoch 18, gen_loss = 0.397388856125693, disc_loss = 0.08028119396115853
Trained batch 117 in epoch 18, gen_loss = 0.3975027180829291, disc_loss = 0.08032579133997403
Trained batch 118 in epoch 18, gen_loss = 0.3974869414037015, disc_loss = 0.0801081070872102
Trained batch 119 in epoch 18, gen_loss = 0.39708627834916116, disc_loss = 0.08012953190676247
Trained batch 120 in epoch 18, gen_loss = 0.3969248934718203, disc_loss = 0.07985736680224784
Trained batch 121 in epoch 18, gen_loss = 0.39676618649334205, disc_loss = 0.07960444598336566
Trained batch 122 in epoch 18, gen_loss = 0.3963639903359297, disc_loss = 0.07932003267578841
Trained batch 123 in epoch 18, gen_loss = 0.39587389677762985, disc_loss = 0.07956891934642749
Trained batch 124 in epoch 18, gen_loss = 0.39644764685630796, disc_loss = 0.07928145421668888
Trained batch 125 in epoch 18, gen_loss = 0.39589924708245294, disc_loss = 0.079048593672702
Trained batch 126 in epoch 18, gen_loss = 0.3957031493581186, disc_loss = 0.07919279932902437
Trained batch 127 in epoch 18, gen_loss = 0.39579871762543917, disc_loss = 0.07966816513726371
Trained batch 128 in epoch 18, gen_loss = 0.395437991896341, disc_loss = 0.08000234584865529
Trained batch 129 in epoch 18, gen_loss = 0.39621167595569906, disc_loss = 0.0800813820033979
Trained batch 130 in epoch 18, gen_loss = 0.3957860999889956, disc_loss = 0.07977756227629672
Trained batch 131 in epoch 18, gen_loss = 0.3956274679212859, disc_loss = 0.08081804166166959
Trained batch 132 in epoch 18, gen_loss = 0.3960177098449908, disc_loss = 0.08351081672397659
Trained batch 133 in epoch 18, gen_loss = 0.39571824758800106, disc_loss = 0.08345249785569066
Trained batch 134 in epoch 18, gen_loss = 0.3951337359569691, disc_loss = 0.08357328922591276
Trained batch 135 in epoch 18, gen_loss = 0.3947312917341204, disc_loss = 0.08393086828222937
Trained batch 136 in epoch 18, gen_loss = 0.3946674002783142, disc_loss = 0.08426881408536413
Trained batch 137 in epoch 18, gen_loss = 0.3947645052187685, disc_loss = 0.08523517702301235
Trained batch 138 in epoch 18, gen_loss = 0.3944134954497111, disc_loss = 0.08535784810928883
Trained batch 139 in epoch 18, gen_loss = 0.3942743850605828, disc_loss = 0.08509326751144337
Trained batch 140 in epoch 18, gen_loss = 0.39395178801624486, disc_loss = 0.08533952499786061
Trained batch 141 in epoch 18, gen_loss = 0.3935163304419585, disc_loss = 0.08526971026874659
Trained batch 142 in epoch 18, gen_loss = 0.393786373463544, disc_loss = 0.08499061095795327
Trained batch 143 in epoch 18, gen_loss = 0.39374949410557747, disc_loss = 0.08464934988296591
Trained batch 144 in epoch 18, gen_loss = 0.39362043183425377, disc_loss = 0.08426961785439273
Trained batch 145 in epoch 18, gen_loss = 0.3938871442455135, disc_loss = 0.08418945906594498
Trained batch 146 in epoch 18, gen_loss = 0.3933366151894031, disc_loss = 0.08428236922933435
Trained batch 147 in epoch 18, gen_loss = 0.39366964633400375, disc_loss = 0.08446101803722716
Trained batch 148 in epoch 18, gen_loss = 0.3931444545320216, disc_loss = 0.08398118357942909
Trained batch 149 in epoch 18, gen_loss = 0.3933267285426458, disc_loss = 0.08477531455767652
Trained batch 150 in epoch 18, gen_loss = 0.39366142935310766, disc_loss = 0.08518725616660043
Trained batch 151 in epoch 18, gen_loss = 0.39356277039960813, disc_loss = 0.08474246601537361
Trained batch 152 in epoch 18, gen_loss = 0.3929088213085349, disc_loss = 0.08540501979064026
Trained batch 153 in epoch 18, gen_loss = 0.39313364164395764, disc_loss = 0.08618780305645392
Trained batch 154 in epoch 18, gen_loss = 0.39293818473815917, disc_loss = 0.08600080785071176
Trained batch 155 in epoch 18, gen_loss = 0.39258571236561507, disc_loss = 0.08628969241041116
Trained batch 156 in epoch 18, gen_loss = 0.3922488110460294, disc_loss = 0.0858176108775957
Trained batch 157 in epoch 18, gen_loss = 0.39261153132855137, disc_loss = 0.08548759942273079
Trained batch 158 in epoch 18, gen_loss = 0.3925745833969716, disc_loss = 0.08519887827840522
Trained batch 159 in epoch 18, gen_loss = 0.3925741992890835, disc_loss = 0.0847659965598723
Trained batch 160 in epoch 18, gen_loss = 0.39230655864899205, disc_loss = 0.08457701563869852
Trained batch 161 in epoch 18, gen_loss = 0.3924521088232229, disc_loss = 0.08513812765329616
Trained batch 162 in epoch 18, gen_loss = 0.3921147323459204, disc_loss = 0.08516367491437522
Trained batch 163 in epoch 18, gen_loss = 0.3917323516272917, disc_loss = 0.08483820997757792
Trained batch 164 in epoch 18, gen_loss = 0.39159832181352555, disc_loss = 0.08448565520741272
Trained batch 165 in epoch 18, gen_loss = 0.39211153948163413, disc_loss = 0.08503478890879596
Trained batch 166 in epoch 18, gen_loss = 0.39190008968650225, disc_loss = 0.08609609974793599
Trained batch 167 in epoch 18, gen_loss = 0.3917919702473141, disc_loss = 0.08604066596931911
Trained batch 168 in epoch 18, gen_loss = 0.3922109237084022, disc_loss = 0.08600205394367759
Trained batch 169 in epoch 18, gen_loss = 0.3916467198554207, disc_loss = 0.0857738357009914
Trained batch 170 in epoch 18, gen_loss = 0.39128766736091924, disc_loss = 0.08550517729140426
Trained batch 171 in epoch 18, gen_loss = 0.3912538537798926, disc_loss = 0.08520898350438666
Trained batch 172 in epoch 18, gen_loss = 0.39123296272547947, disc_loss = 0.08528777915779824
Trained batch 173 in epoch 18, gen_loss = 0.39136863525571497, disc_loss = 0.08497532947128103
Trained batch 174 in epoch 18, gen_loss = 0.3917619638783591, disc_loss = 0.08480065664808666
Trained batch 175 in epoch 18, gen_loss = 0.3915279753167521, disc_loss = 0.08465864978974093
Trained batch 176 in epoch 18, gen_loss = 0.39156812176866046, disc_loss = 0.08435995863897905
Trained batch 177 in epoch 18, gen_loss = 0.392285962620478, disc_loss = 0.08402639063169363
Trained batch 178 in epoch 18, gen_loss = 0.39235137178245205, disc_loss = 0.0840671450060964
Trained batch 179 in epoch 18, gen_loss = 0.3917749846975009, disc_loss = 0.08569158097056465
Trained batch 180 in epoch 18, gen_loss = 0.39196515033916873, disc_loss = 0.08617673868580994
Trained batch 181 in epoch 18, gen_loss = 0.39257436253867306, disc_loss = 0.0859773284781233
Trained batch 182 in epoch 18, gen_loss = 0.39228409968438693, disc_loss = 0.08565071537388397
Trained batch 183 in epoch 18, gen_loss = 0.3921470982225045, disc_loss = 0.08547851640437527
Trained batch 184 in epoch 18, gen_loss = 0.3921909987926483, disc_loss = 0.08544286274779085
Trained batch 185 in epoch 18, gen_loss = 0.3920025275920027, disc_loss = 0.08521581992697251
Trained batch 186 in epoch 18, gen_loss = 0.3919478812638451, disc_loss = 0.0850475856282295
Trained batch 187 in epoch 18, gen_loss = 0.3922378573011845, disc_loss = 0.08506109639556404
Trained batch 188 in epoch 18, gen_loss = 0.39197330452777723, disc_loss = 0.08504633139079762
Trained batch 189 in epoch 18, gen_loss = 0.3915079171720304, disc_loss = 0.08524741588013345
Trained batch 190 in epoch 18, gen_loss = 0.39235934708755055, disc_loss = 0.08559976949926992
Trained batch 191 in epoch 18, gen_loss = 0.39212844319020707, disc_loss = 0.08554492621866909
Trained batch 192 in epoch 18, gen_loss = 0.39206361631655323, disc_loss = 0.08564936654121069
Trained batch 193 in epoch 18, gen_loss = 0.39224531432402504, disc_loss = 0.0853780171877138
Trained batch 194 in epoch 18, gen_loss = 0.3924931714167962, disc_loss = 0.08531426075511636
Trained batch 195 in epoch 18, gen_loss = 0.3926010800867665, disc_loss = 0.08544484855445596
Trained batch 196 in epoch 18, gen_loss = 0.39260140651373693, disc_loss = 0.08534831567643787
Trained batch 197 in epoch 18, gen_loss = 0.39212019214726457, disc_loss = 0.08608361795271813
Trained batch 198 in epoch 18, gen_loss = 0.3925652354206871, disc_loss = 0.08742453138011709
Trained batch 199 in epoch 18, gen_loss = 0.39245784357190133, disc_loss = 0.0873432497563772
Trained batch 200 in epoch 18, gen_loss = 0.39230297127766395, disc_loss = 0.08711662370276022
Trained batch 201 in epoch 18, gen_loss = 0.3926541405444098, disc_loss = 0.08729828020677634
Trained batch 202 in epoch 18, gen_loss = 0.39251281343070155, disc_loss = 0.0879701877751484
Trained batch 203 in epoch 18, gen_loss = 0.3925577640241268, disc_loss = 0.08812254112825602
Trained batch 204 in epoch 18, gen_loss = 0.39211045518154053, disc_loss = 0.0879688305712146
Trained batch 205 in epoch 18, gen_loss = 0.39209495224420304, disc_loss = 0.08792442914089459
Trained batch 206 in epoch 18, gen_loss = 0.3921568598148327, disc_loss = 0.08774671077971226
Trained batch 207 in epoch 18, gen_loss = 0.39219421363220763, disc_loss = 0.08761670100816096
Trained batch 208 in epoch 18, gen_loss = 0.39249466167112285, disc_loss = 0.0873282880335155
Trained batch 209 in epoch 18, gen_loss = 0.39265283331984563, disc_loss = 0.08704429047758735
Trained batch 210 in epoch 18, gen_loss = 0.39266194099498586, disc_loss = 0.0869297094850567
Trained batch 211 in epoch 18, gen_loss = 0.39261474657171175, disc_loss = 0.08682641930623367
Trained batch 212 in epoch 18, gen_loss = 0.39298850451836564, disc_loss = 0.08660328623230958
Trained batch 213 in epoch 18, gen_loss = 0.3929029183688565, disc_loss = 0.0864205142705066
Trained batch 214 in epoch 18, gen_loss = 0.3928342693073805, disc_loss = 0.08675697274982583
Trained batch 215 in epoch 18, gen_loss = 0.3930166861801236, disc_loss = 0.08662478428083921
Trained batch 216 in epoch 18, gen_loss = 0.39274036156417036, disc_loss = 0.08636949732170059
Trained batch 217 in epoch 18, gen_loss = 0.39222293586359114, disc_loss = 0.0863445656728683
Trained batch 218 in epoch 18, gen_loss = 0.3923947578423644, disc_loss = 0.08597986984224013
Trained batch 219 in epoch 18, gen_loss = 0.3924136848612265, disc_loss = 0.08577966428234834
Trained batch 220 in epoch 18, gen_loss = 0.39235502899502195, disc_loss = 0.08549736380130389
Trained batch 221 in epoch 18, gen_loss = 0.3924201192619564, disc_loss = 0.08551266501439517
Trained batch 222 in epoch 18, gen_loss = 0.39233838790200753, disc_loss = 0.08584428088104712
Trained batch 223 in epoch 18, gen_loss = 0.39207600123648134, disc_loss = 0.08576792206440587
Trained batch 224 in epoch 18, gen_loss = 0.3923037972715166, disc_loss = 0.08577801801057325
Trained batch 225 in epoch 18, gen_loss = 0.3919834229534706, disc_loss = 0.08560400209554463
Trained batch 226 in epoch 18, gen_loss = 0.39196261763572693, disc_loss = 0.08528295227650569
Trained batch 227 in epoch 18, gen_loss = 0.3921262701613861, disc_loss = 0.08518804148403242
Trained batch 228 in epoch 18, gen_loss = 0.39187132193011487, disc_loss = 0.08493029173487984
Trained batch 229 in epoch 18, gen_loss = 0.39186783510705697, disc_loss = 0.0847777870706404
Trained batch 230 in epoch 18, gen_loss = 0.39188010648731547, disc_loss = 0.08452763506997522
Trained batch 231 in epoch 18, gen_loss = 0.3918965916181433, disc_loss = 0.08424377313951545
Trained batch 232 in epoch 18, gen_loss = 0.39160968919680356, disc_loss = 0.08399009269106605
Trained batch 233 in epoch 18, gen_loss = 0.3913814103246754, disc_loss = 0.08396715173521677
Trained batch 234 in epoch 18, gen_loss = 0.3915931855110412, disc_loss = 0.08456524901607253
Trained batch 235 in epoch 18, gen_loss = 0.3911933994899362, disc_loss = 0.08448854230257477
Trained batch 236 in epoch 18, gen_loss = 0.39120255064863696, disc_loss = 0.08437310832941645
Trained batch 237 in epoch 18, gen_loss = 0.39110482590539114, disc_loss = 0.08470722796011936
Trained batch 238 in epoch 18, gen_loss = 0.3911415253723017, disc_loss = 0.08452681016574408
Trained batch 239 in epoch 18, gen_loss = 0.3912610540787379, disc_loss = 0.08430251523580713
Trained batch 240 in epoch 18, gen_loss = 0.3914726110662167, disc_loss = 0.0840630641775167
Trained batch 241 in epoch 18, gen_loss = 0.39134804756680797, disc_loss = 0.08380615886893462
Trained batch 242 in epoch 18, gen_loss = 0.39093980462953387, disc_loss = 0.08388988569631804
Trained batch 243 in epoch 18, gen_loss = 0.39092867674886206, disc_loss = 0.08413374937162353
Trained batch 244 in epoch 18, gen_loss = 0.3912289199780445, disc_loss = 0.08384748777298599
Trained batch 245 in epoch 18, gen_loss = 0.3911820171567483, disc_loss = 0.08367993875891273
Trained batch 246 in epoch 18, gen_loss = 0.39108457027176613, disc_loss = 0.08342187353390974
Trained batch 247 in epoch 18, gen_loss = 0.39114045219555976, disc_loss = 0.08315134361844449
Trained batch 248 in epoch 18, gen_loss = 0.39125236785076706, disc_loss = 0.0829124149312845
Trained batch 249 in epoch 18, gen_loss = 0.39140824449062345, disc_loss = 0.08264203050173818
Trained batch 250 in epoch 18, gen_loss = 0.3915833632547067, disc_loss = 0.0824918792753729
Trained batch 251 in epoch 18, gen_loss = 0.3917353336536695, disc_loss = 0.0825743339161226
Trained batch 252 in epoch 18, gen_loss = 0.3914399812579626, disc_loss = 0.08303066868180402
Trained batch 253 in epoch 18, gen_loss = 0.3915807261007039, disc_loss = 0.08310445513407605
Trained batch 254 in epoch 18, gen_loss = 0.3911706135553472, disc_loss = 0.08288566482746426
Trained batch 255 in epoch 18, gen_loss = 0.3907708991318941, disc_loss = 0.08261025522915588
Trained batch 256 in epoch 18, gen_loss = 0.3909330620839902, disc_loss = 0.08233759018270016
Trained batch 257 in epoch 18, gen_loss = 0.39100371959597563, disc_loss = 0.08208501996840675
Trained batch 258 in epoch 18, gen_loss = 0.3907387590316272, disc_loss = 0.08190780246098127
Trained batch 259 in epoch 18, gen_loss = 0.3911172916109745, disc_loss = 0.08199733814690262
Trained batch 260 in epoch 18, gen_loss = 0.3912005488443192, disc_loss = 0.0819088342578161
Trained batch 261 in epoch 18, gen_loss = 0.3912794724220538, disc_loss = 0.08177889570174383
Trained batch 262 in epoch 18, gen_loss = 0.3914003104764699, disc_loss = 0.08150057122996608
Trained batch 263 in epoch 18, gen_loss = 0.39133174311030994, disc_loss = 0.08124512044014409
Trained batch 264 in epoch 18, gen_loss = 0.3915896771089086, disc_loss = 0.08098619536162828
Trained batch 265 in epoch 18, gen_loss = 0.391638995337307, disc_loss = 0.08088931409971215
Trained batch 266 in epoch 18, gen_loss = 0.3915385540281789, disc_loss = 0.08071535373148456
Trained batch 267 in epoch 18, gen_loss = 0.39144464248596733, disc_loss = 0.08055404652389628
Trained batch 268 in epoch 18, gen_loss = 0.39200583033845326, disc_loss = 0.08049654978116261
Trained batch 269 in epoch 18, gen_loss = 0.39226697506728, disc_loss = 0.08027384764928784
Trained batch 270 in epoch 18, gen_loss = 0.3922209375678833, disc_loss = 0.08006268203072937
Trained batch 271 in epoch 18, gen_loss = 0.39215905263143425, disc_loss = 0.07998887144939919
Trained batch 272 in epoch 18, gen_loss = 0.39182267029643497, disc_loss = 0.07988899286611231
Trained batch 273 in epoch 18, gen_loss = 0.3916886941577396, disc_loss = 0.07968832596110004
Trained batch 274 in epoch 18, gen_loss = 0.3914608110081066, disc_loss = 0.07945924769917673
Trained batch 275 in epoch 18, gen_loss = 0.39163363865320233, disc_loss = 0.07928637129193901
Trained batch 276 in epoch 18, gen_loss = 0.3917098485390632, disc_loss = 0.07902602218629436
Trained batch 277 in epoch 18, gen_loss = 0.39191534997319144, disc_loss = 0.07882160472971715
Trained batch 278 in epoch 18, gen_loss = 0.3920710275891007, disc_loss = 0.07857392331765543
Trained batch 279 in epoch 18, gen_loss = 0.3918446289641517, disc_loss = 0.07831408093084714
Trained batch 280 in epoch 18, gen_loss = 0.39193077698296924, disc_loss = 0.07810881765380343
Trained batch 281 in epoch 18, gen_loss = 0.391805740218636, disc_loss = 0.07799544936732937
Trained batch 282 in epoch 18, gen_loss = 0.39196123503964697, disc_loss = 0.07776807208443488
Trained batch 283 in epoch 18, gen_loss = 0.3920457596090478, disc_loss = 0.07754888576389828
Trained batch 284 in epoch 18, gen_loss = 0.3920357710436771, disc_loss = 0.07742754526174905
Trained batch 285 in epoch 18, gen_loss = 0.39207201341649034, disc_loss = 0.07719101792305604
Trained batch 286 in epoch 18, gen_loss = 0.391921892502582, disc_loss = 0.07743158317674016
Trained batch 287 in epoch 18, gen_loss = 0.3918904047459364, disc_loss = 0.07763710906793778
Trained batch 288 in epoch 18, gen_loss = 0.3919344004050258, disc_loss = 0.07748273940866485
Trained batch 289 in epoch 18, gen_loss = 0.3917195510247658, disc_loss = 0.0779965728296545
Trained batch 290 in epoch 18, gen_loss = 0.3920887583719496, disc_loss = 0.07806688734359041
Trained batch 291 in epoch 18, gen_loss = 0.3922748356445195, disc_loss = 0.07783361697850162
Trained batch 292 in epoch 18, gen_loss = 0.3923034471659937, disc_loss = 0.07767724236886656
Trained batch 293 in epoch 18, gen_loss = 0.39253152704157795, disc_loss = 0.07745712820035057
Trained batch 294 in epoch 18, gen_loss = 0.39263170583773466, disc_loss = 0.07725853548085286
Trained batch 295 in epoch 18, gen_loss = 0.39266977076594894, disc_loss = 0.07717209550350704
Trained batch 296 in epoch 18, gen_loss = 0.39258607619940633, disc_loss = 0.07739968542072308
Trained batch 297 in epoch 18, gen_loss = 0.3923989383366284, disc_loss = 0.07758957236980232
Trained batch 298 in epoch 18, gen_loss = 0.39238978588461476, disc_loss = 0.07738595781692095
Trained batch 299 in epoch 18, gen_loss = 0.39202801446119945, disc_loss = 0.07764654223496716
Trained batch 300 in epoch 18, gen_loss = 0.3920474520751408, disc_loss = 0.0782280248896129
Trained batch 301 in epoch 18, gen_loss = 0.39206451187465363, disc_loss = 0.07817538575398804
Trained batch 302 in epoch 18, gen_loss = 0.39186452324240906, disc_loss = 0.07834649203412801
Trained batch 303 in epoch 18, gen_loss = 0.39193793474451494, disc_loss = 0.07930036633594059
Trained batch 304 in epoch 18, gen_loss = 0.39209424892409905, disc_loss = 0.07912157911379807
Trained batch 305 in epoch 18, gen_loss = 0.3919021226222219, disc_loss = 0.07934352527281233
Trained batch 306 in epoch 18, gen_loss = 0.3918764705766684, disc_loss = 0.07937127997922781
Trained batch 307 in epoch 18, gen_loss = 0.3918637128232361, disc_loss = 0.07928612982467204
Trained batch 308 in epoch 18, gen_loss = 0.3915332987856325, disc_loss = 0.07982538490402467
Trained batch 309 in epoch 18, gen_loss = 0.3915179064196925, disc_loss = 0.08021158320649016
Trained batch 310 in epoch 18, gen_loss = 0.3916778577868961, disc_loss = 0.0800574647616056
Trained batch 311 in epoch 18, gen_loss = 0.39177849248815805, disc_loss = 0.07994374560598189
Trained batch 312 in epoch 18, gen_loss = 0.39161074256744627, disc_loss = 0.07989583773234972
Trained batch 313 in epoch 18, gen_loss = 0.39172590367353644, disc_loss = 0.08050903793614192
Trained batch 314 in epoch 18, gen_loss = 0.39166001015239293, disc_loss = 0.08084239847958088
Trained batch 315 in epoch 18, gen_loss = 0.3914602683692039, disc_loss = 0.08073811033221928
Trained batch 316 in epoch 18, gen_loss = 0.3915063088248581, disc_loss = 0.0809825612555261
Trained batch 317 in epoch 18, gen_loss = 0.39138146719467715, disc_loss = 0.0809124255693465
Trained batch 318 in epoch 18, gen_loss = 0.39126118578507235, disc_loss = 0.08081012440489191
Trained batch 319 in epoch 18, gen_loss = 0.3911618006415665, disc_loss = 0.08072703153011389
Trained batch 320 in epoch 18, gen_loss = 0.39102156362800955, disc_loss = 0.08060860082019712
Trained batch 321 in epoch 18, gen_loss = 0.3907272369595048, disc_loss = 0.0806235612560966
Trained batch 322 in epoch 18, gen_loss = 0.39093394877371773, disc_loss = 0.08050564585985967
Trained batch 323 in epoch 18, gen_loss = 0.39075463237585845, disc_loss = 0.08085922753714302
Trained batch 324 in epoch 18, gen_loss = 0.3906347885498634, disc_loss = 0.08103853944975596
Trained batch 325 in epoch 18, gen_loss = 0.3908097865574199, disc_loss = 0.08093145035458671
Trained batch 326 in epoch 18, gen_loss = 0.3905779388519602, disc_loss = 0.08109772759589398
Trained batch 327 in epoch 18, gen_loss = 0.3904009824845849, disc_loss = 0.08104421251180877
Trained batch 328 in epoch 18, gen_loss = 0.390610803949072, disc_loss = 0.08090870002550739
Trained batch 329 in epoch 18, gen_loss = 0.3906996959989721, disc_loss = 0.08078571490830544
Trained batch 330 in epoch 18, gen_loss = 0.39040949220383636, disc_loss = 0.08092735186106668
Trained batch 331 in epoch 18, gen_loss = 0.3904518989554371, disc_loss = 0.08097763456606183
Trained batch 332 in epoch 18, gen_loss = 0.39041685252576264, disc_loss = 0.08077823549688042
Trained batch 333 in epoch 18, gen_loss = 0.390143070213809, disc_loss = 0.08075854436544601
Trained batch 334 in epoch 18, gen_loss = 0.390125000387875, disc_loss = 0.08055441167427978
Trained batch 335 in epoch 18, gen_loss = 0.3900197757674115, disc_loss = 0.08042273889129449
Trained batch 336 in epoch 18, gen_loss = 0.38962945227099455, disc_loss = 0.08058478461318713
Trained batch 337 in epoch 18, gen_loss = 0.3899704232018375, disc_loss = 0.08092112038229432
Trained batch 338 in epoch 18, gen_loss = 0.3899811775283476, disc_loss = 0.08071673801031436
Trained batch 339 in epoch 18, gen_loss = 0.38975434504887635, disc_loss = 0.0806147277026492
Trained batch 340 in epoch 18, gen_loss = 0.38966560258893324, disc_loss = 0.08047907588637469
Trained batch 341 in epoch 18, gen_loss = 0.3895731042003074, disc_loss = 0.08044693657137149
Trained batch 342 in epoch 18, gen_loss = 0.3893872827030827, disc_loss = 0.08036144923842335
Trained batch 343 in epoch 18, gen_loss = 0.38954827752570775, disc_loss = 0.08020921346060066
Trained batch 344 in epoch 18, gen_loss = 0.38963565722755766, disc_loss = 0.08006345216670761
Trained batch 345 in epoch 18, gen_loss = 0.38948359758178625, disc_loss = 0.08013518871147336
Trained batch 346 in epoch 18, gen_loss = 0.38965466369469504, disc_loss = 0.07997088389798612
Trained batch 347 in epoch 18, gen_loss = 0.3897744593606598, disc_loss = 0.0798254619545207
Trained batch 348 in epoch 18, gen_loss = 0.3897617665949387, disc_loss = 0.07973374577404606
Trained batch 349 in epoch 18, gen_loss = 0.38985571341855185, disc_loss = 0.07958654361111778
Trained batch 350 in epoch 18, gen_loss = 0.38997880099845406, disc_loss = 0.07941612435711755
Trained batch 351 in epoch 18, gen_loss = 0.38996692348948936, disc_loss = 0.079423747215928
Trained batch 352 in epoch 18, gen_loss = 0.3900253435032226, disc_loss = 0.07922694058270952
Trained batch 353 in epoch 18, gen_loss = 0.39020363506624256, disc_loss = 0.07923944541489926
Trained batch 354 in epoch 18, gen_loss = 0.3907074108929701, disc_loss = 0.07969015029482018
Trained batch 355 in epoch 18, gen_loss = 0.39091416866926665, disc_loss = 0.07976757706498748
Trained batch 356 in epoch 18, gen_loss = 0.3910806802641444, disc_loss = 0.07963675130889111
Trained batch 357 in epoch 18, gen_loss = 0.39124186112228054, disc_loss = 0.07943768479585564
Trained batch 358 in epoch 18, gen_loss = 0.39116559478565843, disc_loss = 0.07925601999604852
Trained batch 359 in epoch 18, gen_loss = 0.3911285517116388, disc_loss = 0.07908955520381117
Trained batch 360 in epoch 18, gen_loss = 0.3910453416964354, disc_loss = 0.07893101005992978
Trained batch 361 in epoch 18, gen_loss = 0.39113578085082673, disc_loss = 0.07885704403331513
Trained batch 362 in epoch 18, gen_loss = 0.39128593226109654, disc_loss = 0.07883817720747766
Trained batch 363 in epoch 18, gen_loss = 0.39122350882370394, disc_loss = 0.0787668051888941
Trained batch 364 in epoch 18, gen_loss = 0.39138415031237145, disc_loss = 0.0786775447300648
Trained batch 365 in epoch 18, gen_loss = 0.3915603363611659, disc_loss = 0.0786897264232686
Trained batch 366 in epoch 18, gen_loss = 0.3914988113196734, disc_loss = 0.07871323594270269
Trained batch 367 in epoch 18, gen_loss = 0.39154575765132904, disc_loss = 0.078685644464871
Trained batch 368 in epoch 18, gen_loss = 0.3913764626514621, disc_loss = 0.07852994250562698
Trained batch 369 in epoch 18, gen_loss = 0.3913066052907222, disc_loss = 0.0783593438792269
Trained batch 370 in epoch 18, gen_loss = 0.39156274228404475, disc_loss = 0.07817205746289131
Trained batch 371 in epoch 18, gen_loss = 0.3914316446390203, disc_loss = 0.0780575484793473
Trained batch 372 in epoch 18, gen_loss = 0.3915490129358327, disc_loss = 0.07802280688523527
Trained batch 373 in epoch 18, gen_loss = 0.3914694033842036, disc_loss = 0.07811884427403304
Trained batch 374 in epoch 18, gen_loss = 0.3915097147623698, disc_loss = 0.07812733013182878
Trained batch 375 in epoch 18, gen_loss = 0.39122887534346984, disc_loss = 0.07812021352459696
Trained batch 376 in epoch 18, gen_loss = 0.391265784160528, disc_loss = 0.07794684521725466
Trained batch 377 in epoch 18, gen_loss = 0.391361102540657, disc_loss = 0.07778725768907596
Trained batch 378 in epoch 18, gen_loss = 0.39127544968298056, disc_loss = 0.07777363391922379
Trained batch 379 in epoch 18, gen_loss = 0.39117135429068617, disc_loss = 0.07796149790826204
Trained batch 380 in epoch 18, gen_loss = 0.39141376429968305, disc_loss = 0.07817538422617934
Trained batch 381 in epoch 18, gen_loss = 0.391447911633871, disc_loss = 0.07800756197871338
Trained batch 382 in epoch 18, gen_loss = 0.3912933705369735, disc_loss = 0.07822758389281853
Trained batch 383 in epoch 18, gen_loss = 0.3914283695630729, disc_loss = 0.07826536781309794
Trained batch 384 in epoch 18, gen_loss = 0.39128108372936, disc_loss = 0.07811414686503348
Trained batch 385 in epoch 18, gen_loss = 0.39132116881676904, disc_loss = 0.07804904325136558
Trained batch 386 in epoch 18, gen_loss = 0.3912765561610229, disc_loss = 0.07787414764605212
Trained batch 387 in epoch 18, gen_loss = 0.3913217584804161, disc_loss = 0.07771979061857864
Trained batch 388 in epoch 18, gen_loss = 0.3914274516632747, disc_loss = 0.07760863574724501
Trained batch 389 in epoch 18, gen_loss = 0.3913636455169091, disc_loss = 0.07754764262443552
Trained batch 390 in epoch 18, gen_loss = 0.39124535142308303, disc_loss = 0.07752042372122674
Trained batch 391 in epoch 18, gen_loss = 0.39106603255685496, disc_loss = 0.07742469118936557
Trained batch 392 in epoch 18, gen_loss = 0.3910920535031772, disc_loss = 0.07733231246158595
Trained batch 393 in epoch 18, gen_loss = 0.3910858069125771, disc_loss = 0.07732068062499922
Trained batch 394 in epoch 18, gen_loss = 0.39109907203082794, disc_loss = 0.07717769136298684
Trained batch 395 in epoch 18, gen_loss = 0.39106025757512664, disc_loss = 0.07706271472970268
Trained batch 396 in epoch 18, gen_loss = 0.3908820655243823, disc_loss = 0.07710144835611059
Trained batch 397 in epoch 18, gen_loss = 0.3910603635574705, disc_loss = 0.07701741464801096
Trained batch 398 in epoch 18, gen_loss = 0.3910880460774988, disc_loss = 0.0769256170078141
Trained batch 399 in epoch 18, gen_loss = 0.3910280277580023, disc_loss = 0.07705281988484786
Trained batch 400 in epoch 18, gen_loss = 0.3910638765058018, disc_loss = 0.07688002726132807
Trained batch 401 in epoch 18, gen_loss = 0.3911771509629577, disc_loss = 0.07675379979660485
Trained batch 402 in epoch 18, gen_loss = 0.39117048788011516, disc_loss = 0.07658462363431605
Trained batch 403 in epoch 18, gen_loss = 0.3911167115415677, disc_loss = 0.07643118792324152
Trained batch 404 in epoch 18, gen_loss = 0.39108207880714796, disc_loss = 0.07630315426001211
Trained batch 405 in epoch 18, gen_loss = 0.3908205684182679, disc_loss = 0.07626299283196553
Trained batch 406 in epoch 18, gen_loss = 0.390737297493937, disc_loss = 0.07626121227814832
Trained batch 407 in epoch 18, gen_loss = 0.39082123879708497, disc_loss = 0.07612652215860127
Trained batch 408 in epoch 18, gen_loss = 0.39075830199899186, disc_loss = 0.07637427260183836
Trained batch 409 in epoch 18, gen_loss = 0.39091205647805843, disc_loss = 0.07659363031796203
Trained batch 410 in epoch 18, gen_loss = 0.39100627184204234, disc_loss = 0.07647523900534767
Trained batch 411 in epoch 18, gen_loss = 0.39099356922709827, disc_loss = 0.0763394037302294
Trained batch 412 in epoch 18, gen_loss = 0.3911449810350201, disc_loss = 0.07620237090514373
Trained batch 413 in epoch 18, gen_loss = 0.39095954201071736, disc_loss = 0.07627412596951433
Trained batch 414 in epoch 18, gen_loss = 0.3910233113421015, disc_loss = 0.07677276952483927
Trained batch 415 in epoch 18, gen_loss = 0.39102735750090617, disc_loss = 0.07662690038425633
Trained batch 416 in epoch 18, gen_loss = 0.3910122372263627, disc_loss = 0.07655644744447024
Trained batch 417 in epoch 18, gen_loss = 0.3910828415286598, disc_loss = 0.07643722940423486
Trained batch 418 in epoch 18, gen_loss = 0.39093747720798044, disc_loss = 0.07639592354961611
Trained batch 419 in epoch 18, gen_loss = 0.39104267905155815, disc_loss = 0.07630970283588838
Trained batch 420 in epoch 18, gen_loss = 0.3910853590223399, disc_loss = 0.07620967773946263
Trained batch 421 in epoch 18, gen_loss = 0.39085974992733996, disc_loss = 0.07624146089584553
Trained batch 422 in epoch 18, gen_loss = 0.39095535733457437, disc_loss = 0.07632551504074471
Trained batch 423 in epoch 18, gen_loss = 0.39082606987289664, disc_loss = 0.07625762365960498
Trained batch 424 in epoch 18, gen_loss = 0.3907237629329457, disc_loss = 0.0762491103108315
Trained batch 425 in epoch 18, gen_loss = 0.3907354474767273, disc_loss = 0.07663493641726497
Trained batch 426 in epoch 18, gen_loss = 0.3904268183250338, disc_loss = 0.07681872096977063
Trained batch 427 in epoch 18, gen_loss = 0.3903308405636627, disc_loss = 0.07682157666248347
Trained batch 428 in epoch 18, gen_loss = 0.3904912013273973, disc_loss = 0.0769616272322191
Trained batch 429 in epoch 18, gen_loss = 0.39040854725726815, disc_loss = 0.07705521351159658
Trained batch 430 in epoch 18, gen_loss = 0.39056829219627826, disc_loss = 0.07694932037700841
Trained batch 431 in epoch 18, gen_loss = 0.3906371306490015, disc_loss = 0.07688236801186576
Trained batch 432 in epoch 18, gen_loss = 0.39055015508076885, disc_loss = 0.07717329613632129
Trained batch 433 in epoch 18, gen_loss = 0.39052673508220004, disc_loss = 0.07769213533372304
Trained batch 434 in epoch 18, gen_loss = 0.390313786062701, disc_loss = 0.07791014607224998
Trained batch 435 in epoch 18, gen_loss = 0.39043816206378673, disc_loss = 0.0778813078004115
Trained batch 436 in epoch 18, gen_loss = 0.3903503139040836, disc_loss = 0.07781140141197623
Trained batch 437 in epoch 18, gen_loss = 0.39025016013345765, disc_loss = 0.07771109721355446
Trained batch 438 in epoch 18, gen_loss = 0.39026881425147175, disc_loss = 0.0777234405190058
Trained batch 439 in epoch 18, gen_loss = 0.3903216811066324, disc_loss = 0.07767988276371562
Trained batch 440 in epoch 18, gen_loss = 0.39038411769466874, disc_loss = 0.07758506881432131
Trained batch 441 in epoch 18, gen_loss = 0.3903544920736848, disc_loss = 0.07748629600947461
Trained batch 442 in epoch 18, gen_loss = 0.39039514450940804, disc_loss = 0.07769817096847646
Trained batch 443 in epoch 18, gen_loss = 0.3903498133426314, disc_loss = 0.0780818328106155
Trained batch 444 in epoch 18, gen_loss = 0.3903157473280189, disc_loss = 0.07804762901675501
Trained batch 445 in epoch 18, gen_loss = 0.39042871375254984, disc_loss = 0.0780148989596141
Trained batch 446 in epoch 18, gen_loss = 0.3903861693887903, disc_loss = 0.0780344824942133
Trained batch 447 in epoch 18, gen_loss = 0.39030022473473636, disc_loss = 0.07795625319496528
Trained batch 448 in epoch 18, gen_loss = 0.39022036543933214, disc_loss = 0.07782439573694909
Trained batch 449 in epoch 18, gen_loss = 0.3902416878276401, disc_loss = 0.07770254221020473
Trained batch 450 in epoch 18, gen_loss = 0.39024124659614395, disc_loss = 0.07759563797287758
Trained batch 451 in epoch 18, gen_loss = 0.39019874964667633, disc_loss = 0.07750229115301199
Trained batch 452 in epoch 18, gen_loss = 0.3902979579324491, disc_loss = 0.07765458405601729
Trained batch 453 in epoch 18, gen_loss = 0.39020197277289653, disc_loss = 0.07819264808604043
Trained batch 454 in epoch 18, gen_loss = 0.3905640267408811, disc_loss = 0.07838555642987018
Trained batch 455 in epoch 18, gen_loss = 0.3903951112899864, disc_loss = 0.07834297931434489
Trained batch 456 in epoch 18, gen_loss = 0.3906047104876203, disc_loss = 0.07832005037773294
Trained batch 457 in epoch 18, gen_loss = 0.390549043901102, disc_loss = 0.07827639521006088
Trained batch 458 in epoch 18, gen_loss = 0.3906672370329921, disc_loss = 0.07820706129325695
Trained batch 459 in epoch 18, gen_loss = 0.3905742740501528, disc_loss = 0.07810558161455328
Trained batch 460 in epoch 18, gen_loss = 0.39043602799903804, disc_loss = 0.07833163627502135
Trained batch 461 in epoch 18, gen_loss = 0.3904741816706472, disc_loss = 0.07843952609661531
Trained batch 462 in epoch 18, gen_loss = 0.3909111115638947, disc_loss = 0.079216858736173
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.21904823184013367, disc_loss = 0.2953936755657196
Trained batch 1 in epoch 19, gen_loss = 0.2944646626710892, disc_loss = 0.18384163826704025
Trained batch 2 in epoch 19, gen_loss = 0.31625030438105267, disc_loss = 0.152492826183637
Trained batch 3 in epoch 19, gen_loss = 0.3192896544933319, disc_loss = 0.14361166208982468
Trained batch 4 in epoch 19, gen_loss = 0.3302079975605011, disc_loss = 0.132833032310009
Trained batch 5 in epoch 19, gen_loss = 0.3390745172897975, disc_loss = 0.139096616456906
Trained batch 6 in epoch 19, gen_loss = 0.33664532218660626, disc_loss = 0.12199336370187146
Trained batch 7 in epoch 19, gen_loss = 0.3372096046805382, disc_loss = 0.11499672732315958
Trained batch 8 in epoch 19, gen_loss = 0.34059133132298786, disc_loss = 0.10761475707921717
Trained batch 9 in epoch 19, gen_loss = 0.34808156490325926, disc_loss = 0.10147058609873057
Trained batch 10 in epoch 19, gen_loss = 0.3554766828363592, disc_loss = 0.09721762636168436
Trained batch 11 in epoch 19, gen_loss = 0.3546200493971507, disc_loss = 0.09219323952371876
Trained batch 12 in epoch 19, gen_loss = 0.3550814940379216, disc_loss = 0.09935940558520648
Trained batch 13 in epoch 19, gen_loss = 0.3578329639775412, disc_loss = 0.10002024192363024
Trained batch 14 in epoch 19, gen_loss = 0.365634423494339, disc_loss = 0.09462834671139717
Trained batch 15 in epoch 19, gen_loss = 0.3615544755011797, disc_loss = 0.09709577239118516
Trained batch 16 in epoch 19, gen_loss = 0.3661938257077161, disc_loss = 0.09773228733855135
Trained batch 17 in epoch 19, gen_loss = 0.3682124978966183, disc_loss = 0.09314707252714369
Trained batch 18 in epoch 19, gen_loss = 0.3651968585817437, disc_loss = 0.08944209292531013
Trained batch 19 in epoch 19, gen_loss = 0.36638828963041303, disc_loss = 0.08755416218191385
Trained batch 20 in epoch 19, gen_loss = 0.36489059527715045, disc_loss = 0.08624114663827986
Trained batch 21 in epoch 19, gen_loss = 0.36462050676345825, disc_loss = 0.09499332647431981
Trained batch 22 in epoch 19, gen_loss = 0.3706083375474681, disc_loss = 0.098566433009894
Trained batch 23 in epoch 19, gen_loss = 0.37073112775882083, disc_loss = 0.09503963240422308
Trained batch 24 in epoch 19, gen_loss = 0.3705101418495178, disc_loss = 0.09249054856598377
Trained batch 25 in epoch 19, gen_loss = 0.3690089789720682, disc_loss = 0.09010471525387122
Trained batch 26 in epoch 19, gen_loss = 0.37337377777806036, disc_loss = 0.08830960046637941
Trained batch 27 in epoch 19, gen_loss = 0.3738013729453087, disc_loss = 0.08681684938658561
Trained batch 28 in epoch 19, gen_loss = 0.37312285242409543, disc_loss = 0.08925936184823513
Trained batch 29 in epoch 19, gen_loss = 0.37447800238927204, disc_loss = 0.08925864466776451
Trained batch 30 in epoch 19, gen_loss = 0.37646822198744745, disc_loss = 0.08689019811009208
Trained batch 31 in epoch 19, gen_loss = 0.3786012325435877, disc_loss = 0.08490844391053542
Trained batch 32 in epoch 19, gen_loss = 0.3810594388932893, disc_loss = 0.08309717165927093
Trained batch 33 in epoch 19, gen_loss = 0.3807673261446111, disc_loss = 0.08126342806088574
Trained batch 34 in epoch 19, gen_loss = 0.38108303461756027, disc_loss = 0.07949634162443024
Trained batch 35 in epoch 19, gen_loss = 0.380480046901438, disc_loss = 0.07878803699794742
Trained batch 36 in epoch 19, gen_loss = 0.379811732350169, disc_loss = 0.0780704649719032
Trained batch 37 in epoch 19, gen_loss = 0.380295435848989, disc_loss = 0.07851845084836609
Trained batch 38 in epoch 19, gen_loss = 0.38073629370102513, disc_loss = 0.07822734098403882
Trained batch 39 in epoch 19, gen_loss = 0.3818843483924866, disc_loss = 0.07734230570495129
Trained batch 40 in epoch 19, gen_loss = 0.38159789326714305, disc_loss = 0.07803752836657733
Trained batch 41 in epoch 19, gen_loss = 0.3827936372586659, disc_loss = 0.08091027786334355
Trained batch 42 in epoch 19, gen_loss = 0.38324508556099823, disc_loss = 0.08038889911285667
Trained batch 43 in epoch 19, gen_loss = 0.3835552029988982, disc_loss = 0.07944655630060217
Trained batch 44 in epoch 19, gen_loss = 0.3833465463585324, disc_loss = 0.07977659727136294
Trained batch 45 in epoch 19, gen_loss = 0.3825980884873349, disc_loss = 0.08112973031466422
Trained batch 46 in epoch 19, gen_loss = 0.3853642223997319, disc_loss = 0.0824192596718352
Trained batch 47 in epoch 19, gen_loss = 0.3860206001748641, disc_loss = 0.0813598462070028
Trained batch 48 in epoch 19, gen_loss = 0.38490499464833006, disc_loss = 0.08050166024845473
Trained batch 49 in epoch 19, gen_loss = 0.3849536293745041, disc_loss = 0.0800402508676052
Trained batch 50 in epoch 19, gen_loss = 0.38561804680263295, disc_loss = 0.07878627438171237
Trained batch 51 in epoch 19, gen_loss = 0.38401287966049635, disc_loss = 0.07793102785944939
Trained batch 52 in epoch 19, gen_loss = 0.38434823222880093, disc_loss = 0.0771268792450428
Trained batch 53 in epoch 19, gen_loss = 0.3842694455826724, disc_loss = 0.07604696498148972
Trained batch 54 in epoch 19, gen_loss = 0.38351711901751434, disc_loss = 0.07605784487995235
Trained batch 55 in epoch 19, gen_loss = 0.3857753127813339, disc_loss = 0.07550800059522901
Trained batch 56 in epoch 19, gen_loss = 0.38584720251853005, disc_loss = 0.0744204445039494
Trained batch 57 in epoch 19, gen_loss = 0.38587429194614803, disc_loss = 0.07406750870547418
Trained batch 58 in epoch 19, gen_loss = 0.3855531185360278, disc_loss = 0.07310202739880246
Trained batch 59 in epoch 19, gen_loss = 0.38579317380984623, disc_loss = 0.07205371724752088
Trained batch 60 in epoch 19, gen_loss = 0.38534936601998376, disc_loss = 0.07165907156943786
Trained batch 61 in epoch 19, gen_loss = 0.3847689095043367, disc_loss = 0.07070249446757859
Trained batch 62 in epoch 19, gen_loss = 0.38483630475543795, disc_loss = 0.0696908701211214
Trained batch 63 in epoch 19, gen_loss = 0.3844299395568669, disc_loss = 0.06915530594415031
Trained batch 64 in epoch 19, gen_loss = 0.38537549376487734, disc_loss = 0.07151433719465365
Trained batch 65 in epoch 19, gen_loss = 0.385963499546051, disc_loss = 0.07064129691570997
Trained batch 66 in epoch 19, gen_loss = 0.3851245881906196, disc_loss = 0.07083422621128274
Trained batch 67 in epoch 19, gen_loss = 0.38497477638370853, disc_loss = 0.07014024553491789
Trained batch 68 in epoch 19, gen_loss = 0.3855085351328919, disc_loss = 0.06935762716592223
Trained batch 69 in epoch 19, gen_loss = 0.38511394560337064, disc_loss = 0.07014682968812329
Trained batch 70 in epoch 19, gen_loss = 0.3839547747457531, disc_loss = 0.071589156513063
Trained batch 71 in epoch 19, gen_loss = 0.3846522577934795, disc_loss = 0.07083109854203132
Trained batch 72 in epoch 19, gen_loss = 0.3853720969533267, disc_loss = 0.07054639679111846
Trained batch 73 in epoch 19, gen_loss = 0.3849740121010187, disc_loss = 0.06994146289857658
Trained batch 74 in epoch 19, gen_loss = 0.38476381421089173, disc_loss = 0.06928664629658063
Trained batch 75 in epoch 19, gen_loss = 0.3852308882694495, disc_loss = 0.06878441361416328
Trained batch 76 in epoch 19, gen_loss = 0.38564970199163856, disc_loss = 0.0684849341678155
Trained batch 77 in epoch 19, gen_loss = 0.3864200397943839, disc_loss = 0.0678337360612857
Trained batch 78 in epoch 19, gen_loss = 0.387012191211121, disc_loss = 0.067365867734144
Trained batch 79 in epoch 19, gen_loss = 0.38786766566336156, disc_loss = 0.06670959196053446
Trained batch 80 in epoch 19, gen_loss = 0.38670460677441254, disc_loss = 0.06702877594916909
Trained batch 81 in epoch 19, gen_loss = 0.38758718713027673, disc_loss = 0.06857648632693582
Trained batch 82 in epoch 19, gen_loss = 0.3874885935381234, disc_loss = 0.0681001465677856
Trained batch 83 in epoch 19, gen_loss = 0.38683741149448214, disc_loss = 0.0685466611979618
Trained batch 84 in epoch 19, gen_loss = 0.3871064750587239, disc_loss = 0.0693827610462904
Trained batch 85 in epoch 19, gen_loss = 0.38698795091274174, disc_loss = 0.06893526777884988
Trained batch 86 in epoch 19, gen_loss = 0.3863325307424041, disc_loss = 0.06945932851354966
Trained batch 87 in epoch 19, gen_loss = 0.3868399831381711, disc_loss = 0.06895470909181643
Trained batch 88 in epoch 19, gen_loss = 0.38642310158590254, disc_loss = 0.06949232437051414
Trained batch 89 in epoch 19, gen_loss = 0.3854578716887368, disc_loss = 0.07021448779851198
Trained batch 90 in epoch 19, gen_loss = 0.3858554130727118, disc_loss = 0.06974819930945779
Trained batch 91 in epoch 19, gen_loss = 0.3855549625080565, disc_loss = 0.06942693105615351
Trained batch 92 in epoch 19, gen_loss = 0.38592711443542155, disc_loss = 0.06937911627834202
Trained batch 93 in epoch 19, gen_loss = 0.38584609012654486, disc_loss = 0.06880478283509295
Trained batch 94 in epoch 19, gen_loss = 0.3859156087825173, disc_loss = 0.06847530630858321
Trained batch 95 in epoch 19, gen_loss = 0.38613664358854294, disc_loss = 0.0680986950173974
Trained batch 96 in epoch 19, gen_loss = 0.3860601752074723, disc_loss = 0.06759516410913664
Trained batch 97 in epoch 19, gen_loss = 0.38578889929518406, disc_loss = 0.06756804153627279
Trained batch 98 in epoch 19, gen_loss = 0.38686709271536934, disc_loss = 0.06935115218764604
Trained batch 99 in epoch 19, gen_loss = 0.3861908382177353, disc_loss = 0.06946878045797349
Trained batch 100 in epoch 19, gen_loss = 0.3868123301775149, disc_loss = 0.06894080458891273
Trained batch 101 in epoch 19, gen_loss = 0.38676150902813555, disc_loss = 0.06837155669927597
Trained batch 102 in epoch 19, gen_loss = 0.38680176104156716, disc_loss = 0.06781811793379992
Trained batch 103 in epoch 19, gen_loss = 0.3868928568867537, disc_loss = 0.06736957670476001
Trained batch 104 in epoch 19, gen_loss = 0.3864035824934641, disc_loss = 0.06714587667513461
Trained batch 105 in epoch 19, gen_loss = 0.38611945481795185, disc_loss = 0.06671518444101203
Trained batch 106 in epoch 19, gen_loss = 0.38613934633887814, disc_loss = 0.06621106401538458
Trained batch 107 in epoch 19, gen_loss = 0.38625500627138, disc_loss = 0.06625315547851776
Trained batch 108 in epoch 19, gen_loss = 0.3860352495941547, disc_loss = 0.06789241485947042
Trained batch 109 in epoch 19, gen_loss = 0.38620804954658855, disc_loss = 0.06813722511076115
Trained batch 110 in epoch 19, gen_loss = 0.3868347594329903, disc_loss = 0.06784776867543524
Trained batch 111 in epoch 19, gen_loss = 0.38755327915506704, disc_loss = 0.06734714970558084
Trained batch 112 in epoch 19, gen_loss = 0.3876922217618048, disc_loss = 0.06682414654642344
Trained batch 113 in epoch 19, gen_loss = 0.3883293425304848, disc_loss = 0.06651653585498009
Trained batch 114 in epoch 19, gen_loss = 0.3887643230997998, disc_loss = 0.06607004942615395
Trained batch 115 in epoch 19, gen_loss = 0.3884350762798868, disc_loss = 0.06585305390462022
Trained batch 116 in epoch 19, gen_loss = 0.3884404805990366, disc_loss = 0.06554723366235311
Trained batch 117 in epoch 19, gen_loss = 0.3896801870758251, disc_loss = 0.06553997258040106
Trained batch 118 in epoch 19, gen_loss = 0.3903006009694909, disc_loss = 0.06522642915771037
Trained batch 119 in epoch 19, gen_loss = 0.39033536116282147, disc_loss = 0.06485314081267764
Trained batch 120 in epoch 19, gen_loss = 0.39007402205270186, disc_loss = 0.06501741865111038
Trained batch 121 in epoch 19, gen_loss = 0.39077972046664505, disc_loss = 0.06627603239364556
Trained batch 122 in epoch 19, gen_loss = 0.3913131450734487, disc_loss = 0.06591999804131626
Trained batch 123 in epoch 19, gen_loss = 0.3916323985303602, disc_loss = 0.06632683108440571
Trained batch 124 in epoch 19, gen_loss = 0.39198523306846617, disc_loss = 0.06590713544934988
Trained batch 125 in epoch 19, gen_loss = 0.39230137188283226, disc_loss = 0.06569447822957522
Trained batch 126 in epoch 19, gen_loss = 0.3928446828380344, disc_loss = 0.06523510521849779
Trained batch 127 in epoch 19, gen_loss = 0.39281874685548246, disc_loss = 0.06482615655113477
Trained batch 128 in epoch 19, gen_loss = 0.3922252673511357, disc_loss = 0.06555627524679483
Trained batch 129 in epoch 19, gen_loss = 0.3925224599929956, disc_loss = 0.06631400500639127
Trained batch 130 in epoch 19, gen_loss = 0.392317240019791, disc_loss = 0.06595588633292959
Trained batch 131 in epoch 19, gen_loss = 0.3920585269277746, disc_loss = 0.06557733430103822
Trained batch 132 in epoch 19, gen_loss = 0.3921781861244288, disc_loss = 0.06526983442499225
Trained batch 133 in epoch 19, gen_loss = 0.39208347784049474, disc_loss = 0.06487866757270783
Trained batch 134 in epoch 19, gen_loss = 0.39221698023654794, disc_loss = 0.06510201885054509
Trained batch 135 in epoch 19, gen_loss = 0.39149895310401917, disc_loss = 0.06548024247646989
Trained batch 136 in epoch 19, gen_loss = 0.39189016470943927, disc_loss = 0.06510008634985799
Trained batch 137 in epoch 19, gen_loss = 0.39193547894989234, disc_loss = 0.06470149918796791
Trained batch 138 in epoch 19, gen_loss = 0.3918438603123315, disc_loss = 0.0645346004087076
Trained batch 139 in epoch 19, gen_loss = 0.391582906459059, disc_loss = 0.0641815773743604
Trained batch 140 in epoch 19, gen_loss = 0.39116770282704777, disc_loss = 0.06386135009956276
Trained batch 141 in epoch 19, gen_loss = 0.39129761973736993, disc_loss = 0.0637081243806112
Trained batch 142 in epoch 19, gen_loss = 0.3910567022703744, disc_loss = 0.06458675708960403
Trained batch 143 in epoch 19, gen_loss = 0.3914517402235005, disc_loss = 0.06442292043680532
Trained batch 144 in epoch 19, gen_loss = 0.3918511865467861, disc_loss = 0.06434622462196597
Trained batch 145 in epoch 19, gen_loss = 0.3914175352005109, disc_loss = 0.06406559281000128
Trained batch 146 in epoch 19, gen_loss = 0.3913241608613202, disc_loss = 0.06388353983409145
Trained batch 147 in epoch 19, gen_loss = 0.3914112557430525, disc_loss = 0.06364139105268829
Trained batch 148 in epoch 19, gen_loss = 0.39196614511061034, disc_loss = 0.06330199077125363
Trained batch 149 in epoch 19, gen_loss = 0.3923152858018875, disc_loss = 0.06294254415978988
Trained batch 150 in epoch 19, gen_loss = 0.3922154372496321, disc_loss = 0.06262213683730325
Trained batch 151 in epoch 19, gen_loss = 0.3925173123808284, disc_loss = 0.062409159298496025
Trained batch 152 in epoch 19, gen_loss = 0.3926883639852985, disc_loss = 0.062438782779317276
Trained batch 153 in epoch 19, gen_loss = 0.39341671822907087, disc_loss = 0.0626134942709045
Trained batch 154 in epoch 19, gen_loss = 0.3932085633277893, disc_loss = 0.06227803875602061
Trained batch 155 in epoch 19, gen_loss = 0.3927570898563434, disc_loss = 0.06213654418929647
Trained batch 156 in epoch 19, gen_loss = 0.39330512171338317, disc_loss = 0.06190750910455634
Trained batch 157 in epoch 19, gen_loss = 0.39314166503616527, disc_loss = 0.06161738097479072
Trained batch 158 in epoch 19, gen_loss = 0.39320345138603785, disc_loss = 0.06173540857977837
Trained batch 159 in epoch 19, gen_loss = 0.39392166379839183, disc_loss = 0.061490763549227265
Trained batch 160 in epoch 19, gen_loss = 0.3940555927175913, disc_loss = 0.061328142314501434
Trained batch 161 in epoch 19, gen_loss = 0.394008050730199, disc_loss = 0.0611996452588542
Trained batch 162 in epoch 19, gen_loss = 0.39426994049475966, disc_loss = 0.06145355577346372
Trained batch 163 in epoch 19, gen_loss = 0.39440006780915143, disc_loss = 0.06116495763019818
Trained batch 164 in epoch 19, gen_loss = 0.3943073021643089, disc_loss = 0.061197883477716736
Trained batch 165 in epoch 19, gen_loss = 0.39400834976190546, disc_loss = 0.061429704169192946
Trained batch 166 in epoch 19, gen_loss = 0.39430889183889606, disc_loss = 0.06133041156087807
Trained batch 167 in epoch 19, gen_loss = 0.3944468175371488, disc_loss = 0.06128459213124145
Trained batch 168 in epoch 19, gen_loss = 0.3945785413479664, disc_loss = 0.06100905148764334
Trained batch 169 in epoch 19, gen_loss = 0.39450018142952636, disc_loss = 0.06083668671986636
Trained batch 170 in epoch 19, gen_loss = 0.39448187539452, disc_loss = 0.06107001860587918
Trained batch 171 in epoch 19, gen_loss = 0.3950756902611533, disc_loss = 0.0622350110044313
Trained batch 172 in epoch 19, gen_loss = 0.39530170308372187, disc_loss = 0.06200616366386069
Trained batch 173 in epoch 19, gen_loss = 0.3950804295553558, disc_loss = 0.06238548906156044
Trained batch 174 in epoch 19, gen_loss = 0.3952610421180725, disc_loss = 0.06249907675598349
Trained batch 175 in epoch 19, gen_loss = 0.39513525095852936, disc_loss = 0.062285347788763996
Trained batch 176 in epoch 19, gen_loss = 0.39496062434999285, disc_loss = 0.06223484954801993
Trained batch 177 in epoch 19, gen_loss = 0.39519583040408873, disc_loss = 0.06230880840147814
Trained batch 178 in epoch 19, gen_loss = 0.3955234455662733, disc_loss = 0.06213296593983746
Trained batch 179 in epoch 19, gen_loss = 0.3953297343518999, disc_loss = 0.06203054647064871
Trained batch 180 in epoch 19, gen_loss = 0.39532160907160513, disc_loss = 0.061835295278887724
Trained batch 181 in epoch 19, gen_loss = 0.39509160276297683, disc_loss = 0.06208392816012377
Trained batch 182 in epoch 19, gen_loss = 0.3946355801136767, disc_loss = 0.062364949778618055
Trained batch 183 in epoch 19, gen_loss = 0.39490910830057185, disc_loss = 0.06307560616456297
Trained batch 184 in epoch 19, gen_loss = 0.39490567220223916, disc_loss = 0.06292413728865417
Trained batch 185 in epoch 19, gen_loss = 0.3948514113823573, disc_loss = 0.0629217473850135
Trained batch 186 in epoch 19, gen_loss = 0.3950446495079102, disc_loss = 0.06327720470527276
Trained batch 187 in epoch 19, gen_loss = 0.39454958429361914, disc_loss = 0.06332247329756935
Trained batch 188 in epoch 19, gen_loss = 0.3947928221452804, disc_loss = 0.06307109842500674
Trained batch 189 in epoch 19, gen_loss = 0.3946707909044467, disc_loss = 0.0630446405689183
Trained batch 190 in epoch 19, gen_loss = 0.3944995882311417, disc_loss = 0.06280859942055497
Trained batch 191 in epoch 19, gen_loss = 0.39440950549518067, disc_loss = 0.06261735693745625
Trained batch 192 in epoch 19, gen_loss = 0.39451036907230635, disc_loss = 0.06233413829202788
Trained batch 193 in epoch 19, gen_loss = 0.3945584513784684, disc_loss = 0.06209510487033842
Trained batch 194 in epoch 19, gen_loss = 0.3946107437977424, disc_loss = 0.0620353671698234
Trained batch 195 in epoch 19, gen_loss = 0.39465369892363644, disc_loss = 0.06260960333391416
Trained batch 196 in epoch 19, gen_loss = 0.39514974833745037, disc_loss = 0.06248529602390558
Trained batch 197 in epoch 19, gen_loss = 0.3949849587498289, disc_loss = 0.062333461376979496
Trained batch 198 in epoch 19, gen_loss = 0.39539403502066534, disc_loss = 0.06224315357979518
Trained batch 199 in epoch 19, gen_loss = 0.39510309845209124, disc_loss = 0.06231940529309213
Trained batch 200 in epoch 19, gen_loss = 0.3953732827409583, disc_loss = 0.06297398087063535
Trained batch 201 in epoch 19, gen_loss = 0.3953821712201185, disc_loss = 0.06316032849879254
Trained batch 202 in epoch 19, gen_loss = 0.3951762744358608, disc_loss = 0.06312715000670238
Trained batch 203 in epoch 19, gen_loss = 0.39524872469551425, disc_loss = 0.0628866630140692
Trained batch 204 in epoch 19, gen_loss = 0.39497499393253793, disc_loss = 0.06262906634862103
Trained batch 205 in epoch 19, gen_loss = 0.3954465695955221, disc_loss = 0.062458905486335745
Trained batch 206 in epoch 19, gen_loss = 0.3957203413553284, disc_loss = 0.06239257838828984
Trained batch 207 in epoch 19, gen_loss = 0.39566799253225327, disc_loss = 0.06233973059212216
Trained batch 208 in epoch 19, gen_loss = 0.39543057628795864, disc_loss = 0.06298515111047542
Trained batch 209 in epoch 19, gen_loss = 0.3950944527274086, disc_loss = 0.06422939963550085
Trained batch 210 in epoch 19, gen_loss = 0.3952801039716079, disc_loss = 0.06425027121564647
Trained batch 211 in epoch 19, gen_loss = 0.3952801654923637, disc_loss = 0.06421498047135207
Trained batch 212 in epoch 19, gen_loss = 0.3952934637036122, disc_loss = 0.06428190684077185
Trained batch 213 in epoch 19, gen_loss = 0.3951108859521206, disc_loss = 0.06452801415836003
Trained batch 214 in epoch 19, gen_loss = 0.3952664904816206, disc_loss = 0.06522182984667461
Trained batch 215 in epoch 19, gen_loss = 0.3949158642854955, disc_loss = 0.06516079811155107
Trained batch 216 in epoch 19, gen_loss = 0.3948757498769716, disc_loss = 0.06493546727461062
Trained batch 217 in epoch 19, gen_loss = 0.3948593914782235, disc_loss = 0.06470046492737777
Trained batch 218 in epoch 19, gen_loss = 0.39500751941715745, disc_loss = 0.06448656806645736
Trained batch 219 in epoch 19, gen_loss = 0.3949024368416179, disc_loss = 0.0643953489436006
Trained batch 220 in epoch 19, gen_loss = 0.3944967016914851, disc_loss = 0.06435281103603306
Trained batch 221 in epoch 19, gen_loss = 0.3944187392522623, disc_loss = 0.06449221955142445
Trained batch 222 in epoch 19, gen_loss = 0.3943826989208102, disc_loss = 0.06442658691312032
Trained batch 223 in epoch 19, gen_loss = 0.3945513404905796, disc_loss = 0.06441952738428622
Trained batch 224 in epoch 19, gen_loss = 0.39479287624359133, disc_loss = 0.0647216387382812
Trained batch 225 in epoch 19, gen_loss = 0.3947483885340986, disc_loss = 0.06458578388561058
Trained batch 226 in epoch 19, gen_loss = 0.3945968254809863, disc_loss = 0.06475472612314681
Trained batch 227 in epoch 19, gen_loss = 0.39466664482627, disc_loss = 0.06476646221831049
Trained batch 228 in epoch 19, gen_loss = 0.39489114297529493, disc_loss = 0.06481530811377358
Trained batch 229 in epoch 19, gen_loss = 0.39491024535635244, disc_loss = 0.06466599243247638
Trained batch 230 in epoch 19, gen_loss = 0.3946342117342598, disc_loss = 0.06471949142053143
Trained batch 231 in epoch 19, gen_loss = 0.3949013267611635, disc_loss = 0.06498097741157459
Trained batch 232 in epoch 19, gen_loss = 0.3945088628279805, disc_loss = 0.06510482853590291
Trained batch 233 in epoch 19, gen_loss = 0.394729882860795, disc_loss = 0.06491537733226378
Trained batch 234 in epoch 19, gen_loss = 0.3947150335666981, disc_loss = 0.06467948683161051
Trained batch 235 in epoch 19, gen_loss = 0.39431831202769685, disc_loss = 0.0649081661515885
Trained batch 236 in epoch 19, gen_loss = 0.3947382668654124, disc_loss = 0.06470956109888569
Trained batch 237 in epoch 19, gen_loss = 0.39474770702233836, disc_loss = 0.0646354809223416
Trained batch 238 in epoch 19, gen_loss = 0.39416652244504025, disc_loss = 0.06495604145430246
Trained batch 239 in epoch 19, gen_loss = 0.3946531318128109, disc_loss = 0.06493003286498909
Trained batch 240 in epoch 19, gen_loss = 0.3946007414724817, disc_loss = 0.06502382468463103
Trained batch 241 in epoch 19, gen_loss = 0.39440793858086765, disc_loss = 0.06609932578376625
Trained batch 242 in epoch 19, gen_loss = 0.3943273053493029, disc_loss = 0.0660624563762987
Trained batch 243 in epoch 19, gen_loss = 0.3942497928367286, disc_loss = 0.06604839331989527
Trained batch 244 in epoch 19, gen_loss = 0.39406543714659553, disc_loss = 0.06594405173114976
Trained batch 245 in epoch 19, gen_loss = 0.39411877192617434, disc_loss = 0.06573668550094211
Trained batch 246 in epoch 19, gen_loss = 0.39443653110067856, disc_loss = 0.06552824560884643
Trained batch 247 in epoch 19, gen_loss = 0.39434902742505074, disc_loss = 0.06537331672640698
Trained batch 248 in epoch 19, gen_loss = 0.39417855339835445, disc_loss = 0.06549113045210939
Trained batch 249 in epoch 19, gen_loss = 0.39415519881248473, disc_loss = 0.06555188183858991
Trained batch 250 in epoch 19, gen_loss = 0.394389650379994, disc_loss = 0.06600708053243232
Trained batch 251 in epoch 19, gen_loss = 0.3943283101395955, disc_loss = 0.06588656936092155
Trained batch 252 in epoch 19, gen_loss = 0.39418876736531616, disc_loss = 0.06576171768056192
Trained batch 253 in epoch 19, gen_loss = 0.3940582519441139, disc_loss = 0.06555056657759457
Trained batch 254 in epoch 19, gen_loss = 0.3945274462886885, disc_loss = 0.06537764238230154
Trained batch 255 in epoch 19, gen_loss = 0.39425830193795264, disc_loss = 0.0654647742267116
Trained batch 256 in epoch 19, gen_loss = 0.39466951433786623, disc_loss = 0.06529894112410016
Trained batch 257 in epoch 19, gen_loss = 0.39473191793112794, disc_loss = 0.06512612761395384
Trained batch 258 in epoch 19, gen_loss = 0.39476998236648825, disc_loss = 0.065099292524648
Trained batch 259 in epoch 19, gen_loss = 0.39456610014805427, disc_loss = 0.06533456721271459
Trained batch 260 in epoch 19, gen_loss = 0.3946188885818496, disc_loss = 0.06514854098302651
Trained batch 261 in epoch 19, gen_loss = 0.3945629239537334, disc_loss = 0.06510530857241335
Trained batch 262 in epoch 19, gen_loss = 0.3942934787998635, disc_loss = 0.06511938222064265
Trained batch 263 in epoch 19, gen_loss = 0.3943396375486345, disc_loss = 0.06525547682505214
Trained batch 264 in epoch 19, gen_loss = 0.39444512061353, disc_loss = 0.06525986733020477
Trained batch 265 in epoch 19, gen_loss = 0.3943268319493846, disc_loss = 0.06505221561213634
Trained batch 266 in epoch 19, gen_loss = 0.3941733271218418, disc_loss = 0.06491057403134497
Trained batch 267 in epoch 19, gen_loss = 0.3943320735176997, disc_loss = 0.06555394796348775
Trained batch 268 in epoch 19, gen_loss = 0.3940615103368866, disc_loss = 0.06668858104091152
Trained batch 269 in epoch 19, gen_loss = 0.39410622506229964, disc_loss = 0.0668525405642059
Trained batch 270 in epoch 19, gen_loss = 0.39415080542933895, disc_loss = 0.06668815709568038
Trained batch 271 in epoch 19, gen_loss = 0.3941975168007262, disc_loss = 0.06654764628311728
Trained batch 272 in epoch 19, gen_loss = 0.39397062323032284, disc_loss = 0.06647660699246567
Trained batch 273 in epoch 19, gen_loss = 0.3941325277742678, disc_loss = 0.0665129252512307
Trained batch 274 in epoch 19, gen_loss = 0.3940049136768688, disc_loss = 0.06636329694227738
Trained batch 275 in epoch 19, gen_loss = 0.39390039811099786, disc_loss = 0.0662277508257092
Trained batch 276 in epoch 19, gen_loss = 0.39400804709871756, disc_loss = 0.06606698405360702
Trained batch 277 in epoch 19, gen_loss = 0.3939383637776478, disc_loss = 0.0659221745960468
Trained batch 278 in epoch 19, gen_loss = 0.3938397916841678, disc_loss = 0.06589133334496329
Trained batch 279 in epoch 19, gen_loss = 0.3935220987669059, disc_loss = 0.06645462701230177
Trained batch 280 in epoch 19, gen_loss = 0.39328355806153864, disc_loss = 0.06632574550224156
Trained batch 281 in epoch 19, gen_loss = 0.39327923795010183, disc_loss = 0.06619576455245837
Trained batch 282 in epoch 19, gen_loss = 0.39339524160004335, disc_loss = 0.0660225791534139
Trained batch 283 in epoch 19, gen_loss = 0.3934051811065472, disc_loss = 0.0660372712111599
Trained batch 284 in epoch 19, gen_loss = 0.39296118585686934, disc_loss = 0.06649580549514085
Trained batch 285 in epoch 19, gen_loss = 0.39320784025675765, disc_loss = 0.06648070857554049
Trained batch 286 in epoch 19, gen_loss = 0.39337010904887, disc_loss = 0.0663507959192119
Trained batch 287 in epoch 19, gen_loss = 0.39315532416933113, disc_loss = 0.06629252704765855
Trained batch 288 in epoch 19, gen_loss = 0.3932447977957016, disc_loss = 0.06614378813950661
Trained batch 289 in epoch 19, gen_loss = 0.3932610358657508, disc_loss = 0.06610658739147515
Trained batch 290 in epoch 19, gen_loss = 0.3932127594128507, disc_loss = 0.06595663362761953
Trained batch 291 in epoch 19, gen_loss = 0.3928559520473219, disc_loss = 0.06618495392676903
Trained batch 292 in epoch 19, gen_loss = 0.3930785731244006, disc_loss = 0.06605608524824572
Trained batch 293 in epoch 19, gen_loss = 0.39331291321994494, disc_loss = 0.06592767787020222
Trained batch 294 in epoch 19, gen_loss = 0.3933500136359263, disc_loss = 0.06572919844697088
Trained batch 295 in epoch 19, gen_loss = 0.39328060963669337, disc_loss = 0.06555913310699366
Trained batch 296 in epoch 19, gen_loss = 0.39319999641440934, disc_loss = 0.0654204191658834
Trained batch 297 in epoch 19, gen_loss = 0.3930244061770855, disc_loss = 0.06533515084559885
Trained batch 298 in epoch 19, gen_loss = 0.39312487262547213, disc_loss = 0.06524674775060203
Trained batch 299 in epoch 19, gen_loss = 0.39328368147214254, disc_loss = 0.065062836514165
Trained batch 300 in epoch 19, gen_loss = 0.3929346158258939, disc_loss = 0.0649692615265169
Trained batch 301 in epoch 19, gen_loss = 0.3930723276359356, disc_loss = 0.06480833159648622
Trained batch 302 in epoch 19, gen_loss = 0.39305495743704316, disc_loss = 0.06506150170988573
Trained batch 303 in epoch 19, gen_loss = 0.39282207896834925, disc_loss = 0.06514314419320344
Trained batch 304 in epoch 19, gen_loss = 0.3928669636366797, disc_loss = 0.06514515903030263
Trained batch 305 in epoch 19, gen_loss = 0.3929961313024845, disc_loss = 0.06500268924153513
Trained batch 306 in epoch 19, gen_loss = 0.3930932370769861, disc_loss = 0.06491257229073623
Trained batch 307 in epoch 19, gen_loss = 0.39307603897986476, disc_loss = 0.06502003532943207
Trained batch 308 in epoch 19, gen_loss = 0.3929183147485974, disc_loss = 0.06520866130668561
Trained batch 309 in epoch 19, gen_loss = 0.39296248362910363, disc_loss = 0.06507692015579632
Trained batch 310 in epoch 19, gen_loss = 0.39287088519123975, disc_loss = 0.06492603731332676
Trained batch 311 in epoch 19, gen_loss = 0.39290097575539196, disc_loss = 0.06479424469244595
Trained batch 312 in epoch 19, gen_loss = 0.3932016506172217, disc_loss = 0.06466201477990555
Trained batch 313 in epoch 19, gen_loss = 0.39301184436697867, disc_loss = 0.0649650618611912
Trained batch 314 in epoch 19, gen_loss = 0.393443425969472, disc_loss = 0.06519286270061182
Trained batch 315 in epoch 19, gen_loss = 0.39341973324742496, disc_loss = 0.06521459116565087
Trained batch 316 in epoch 19, gen_loss = 0.39338962541017625, disc_loss = 0.06505243984353655
Trained batch 317 in epoch 19, gen_loss = 0.3935039055609853, disc_loss = 0.06492358047819738
Trained batch 318 in epoch 19, gen_loss = 0.39339416303604746, disc_loss = 0.0648700096367108
Trained batch 319 in epoch 19, gen_loss = 0.3931953301653266, disc_loss = 0.06479336934862659
Trained batch 320 in epoch 19, gen_loss = 0.39314824277738175, disc_loss = 0.06466734855554743
Trained batch 321 in epoch 19, gen_loss = 0.3931094412662968, disc_loss = 0.06465097253575273
Trained batch 322 in epoch 19, gen_loss = 0.39320507996222553, disc_loss = 0.06475524471109681
Trained batch 323 in epoch 19, gen_loss = 0.39294980080039416, disc_loss = 0.06468896821348204
Trained batch 324 in epoch 19, gen_loss = 0.39300116685720593, disc_loss = 0.06459135297972422
Trained batch 325 in epoch 19, gen_loss = 0.39290942306533183, disc_loss = 0.06442983112543639
Trained batch 326 in epoch 19, gen_loss = 0.3928916644794861, disc_loss = 0.06432574056088924
Trained batch 327 in epoch 19, gen_loss = 0.39305247311911934, disc_loss = 0.0642452778169749
Trained batch 328 in epoch 19, gen_loss = 0.39310541142083955, disc_loss = 0.06431375050458683
Trained batch 329 in epoch 19, gen_loss = 0.3933767081210108, disc_loss = 0.06421128426198706
Trained batch 330 in epoch 19, gen_loss = 0.39342372285995597, disc_loss = 0.06418180546169014
Trained batch 331 in epoch 19, gen_loss = 0.393198704593871, disc_loss = 0.06454809027421007
Trained batch 332 in epoch 19, gen_loss = 0.3933867297552011, disc_loss = 0.06465649257439214
Trained batch 333 in epoch 19, gen_loss = 0.39318110316456434, disc_loss = 0.06455288949550804
Trained batch 334 in epoch 19, gen_loss = 0.3931532012882517, disc_loss = 0.06460604260105696
Trained batch 335 in epoch 19, gen_loss = 0.393145832809664, disc_loss = 0.06444371373037852
Trained batch 336 in epoch 19, gen_loss = 0.39327603976521364, disc_loss = 0.0643242366269275
Trained batch 337 in epoch 19, gen_loss = 0.39304470777864287, disc_loss = 0.06427140493695377
Trained batch 338 in epoch 19, gen_loss = 0.3929978277655126, disc_loss = 0.06428315639385959
Trained batch 339 in epoch 19, gen_loss = 0.3929700797971557, disc_loss = 0.06461367293206208
Trained batch 340 in epoch 19, gen_loss = 0.39317676573554794, disc_loss = 0.06521790557134012
Trained batch 341 in epoch 19, gen_loss = 0.39317857748583745, disc_loss = 0.06508462009025597
Trained batch 342 in epoch 19, gen_loss = 0.3929687580283807, disc_loss = 0.0650584654171161
Trained batch 343 in epoch 19, gen_loss = 0.39304259367460426, disc_loss = 0.0649060575930445
Trained batch 344 in epoch 19, gen_loss = 0.39284642416497934, disc_loss = 0.06503356357739455
Trained batch 345 in epoch 19, gen_loss = 0.3927021253143432, disc_loss = 0.06508512641545493
Trained batch 346 in epoch 19, gen_loss = 0.39265996320790447, disc_loss = 0.06498091616359156
Trained batch 347 in epoch 19, gen_loss = 0.3925653422015837, disc_loss = 0.06484402672269907
Trained batch 348 in epoch 19, gen_loss = 0.39248252649361903, disc_loss = 0.0648036466906098
Trained batch 349 in epoch 19, gen_loss = 0.3926355766398566, disc_loss = 0.06486260713211128
Trained batch 350 in epoch 19, gen_loss = 0.3926217389582229, disc_loss = 0.06489545460312794
Trained batch 351 in epoch 19, gen_loss = 0.3924911381168799, disc_loss = 0.06498010889415375
Trained batch 352 in epoch 19, gen_loss = 0.3925497066704477, disc_loss = 0.06495966848840795
Trained batch 353 in epoch 19, gen_loss = 0.3924601562952591, disc_loss = 0.06493244950506984
Trained batch 354 in epoch 19, gen_loss = 0.3927332990606066, disc_loss = 0.06502054970659
Trained batch 355 in epoch 19, gen_loss = 0.3926940644892414, disc_loss = 0.06550015642025163
Trained batch 356 in epoch 19, gen_loss = 0.39280842140275224, disc_loss = 0.06551718276714076
Trained batch 357 in epoch 19, gen_loss = 0.39290926526378656, disc_loss = 0.0654019408250571
Trained batch 358 in epoch 19, gen_loss = 0.3927254741570412, disc_loss = 0.06535101601527096
Trained batch 359 in epoch 19, gen_loss = 0.3925779973467191, disc_loss = 0.0653872936601854
Trained batch 360 in epoch 19, gen_loss = 0.3928407392673545, disc_loss = 0.0654243037486423
Trained batch 361 in epoch 19, gen_loss = 0.3929217745915302, disc_loss = 0.06531449980539841
Trained batch 362 in epoch 19, gen_loss = 0.3928056915929495, disc_loss = 0.06547469517457255
Trained batch 363 in epoch 19, gen_loss = 0.3927586254674, disc_loss = 0.06546031256912502
Trained batch 364 in epoch 19, gen_loss = 0.39291508736675734, disc_loss = 0.06530683515465831
Trained batch 365 in epoch 19, gen_loss = 0.39269299316601675, disc_loss = 0.06524087752526005
Trained batch 366 in epoch 19, gen_loss = 0.39280752728030854, disc_loss = 0.0651521136456395
Trained batch 367 in epoch 19, gen_loss = 0.39279761546007963, disc_loss = 0.06514111689909402
Trained batch 368 in epoch 19, gen_loss = 0.3928172224097782, disc_loss = 0.06528130991682209
Trained batch 369 in epoch 19, gen_loss = 0.39291931318270196, disc_loss = 0.06527489699876389
Trained batch 370 in epoch 19, gen_loss = 0.39309899239848567, disc_loss = 0.065130017092828
Trained batch 371 in epoch 19, gen_loss = 0.3929525713125865, disc_loss = 0.06510011289739401
Trained batch 372 in epoch 19, gen_loss = 0.3931916537457433, disc_loss = 0.06509308715478265
Trained batch 373 in epoch 19, gen_loss = 0.3932963184972498, disc_loss = 0.06504905771434227
Trained batch 374 in epoch 19, gen_loss = 0.39330002800623576, disc_loss = 0.06490940931687753
Trained batch 375 in epoch 19, gen_loss = 0.39334407480473216, disc_loss = 0.06493219134070852
Trained batch 376 in epoch 19, gen_loss = 0.39315770815474915, disc_loss = 0.06522793810201973
Trained batch 377 in epoch 19, gen_loss = 0.39336479601090546, disc_loss = 0.06529622658269194
Trained batch 378 in epoch 19, gen_loss = 0.3933509976694011, disc_loss = 0.06518538804641263
Trained batch 379 in epoch 19, gen_loss = 0.3933098552258391, disc_loss = 0.06511506176749735
Trained batch 380 in epoch 19, gen_loss = 0.3934682284596711, disc_loss = 0.06514140385938832
Trained batch 381 in epoch 19, gen_loss = 0.3935033920079626, disc_loss = 0.06502418519675497
Trained batch 382 in epoch 19, gen_loss = 0.3936748534985684, disc_loss = 0.064946501632525
Trained batch 383 in epoch 19, gen_loss = 0.3935494734129558, disc_loss = 0.06498258035329248
Trained batch 384 in epoch 19, gen_loss = 0.39357114743876764, disc_loss = 0.06498181442790604
Trained batch 385 in epoch 19, gen_loss = 0.3933081703328098, disc_loss = 0.0648385240271726
Trained batch 386 in epoch 19, gen_loss = 0.3934131119140359, disc_loss = 0.06471899861965608
Trained batch 387 in epoch 19, gen_loss = 0.3935401013370642, disc_loss = 0.06467867252589732
Trained batch 388 in epoch 19, gen_loss = 0.3934984040903861, disc_loss = 0.06464817102730351
Trained batch 389 in epoch 19, gen_loss = 0.3932823209426342, disc_loss = 0.06455766830641108
Trained batch 390 in epoch 19, gen_loss = 0.393297205953037, disc_loss = 0.06453056102547118
Trained batch 391 in epoch 19, gen_loss = 0.3933727148996324, disc_loss = 0.06446806292705314
Trained batch 392 in epoch 19, gen_loss = 0.39366097615572027, disc_loss = 0.06439041712916155
Trained batch 393 in epoch 19, gen_loss = 0.39356233444310684, disc_loss = 0.06440572210630109
Trained batch 394 in epoch 19, gen_loss = 0.39375256133984915, disc_loss = 0.0642765299688223
Trained batch 395 in epoch 19, gen_loss = 0.39372543433699947, disc_loss = 0.06415686925939011
Trained batch 396 in epoch 19, gen_loss = 0.3938043868211415, disc_loss = 0.06405600185461474
Trained batch 397 in epoch 19, gen_loss = 0.39396920298511656, disc_loss = 0.06401530318851371
Trained batch 398 in epoch 19, gen_loss = 0.3936946988852699, disc_loss = 0.06452089868121802
Trained batch 399 in epoch 19, gen_loss = 0.3940823090821505, disc_loss = 0.06498732558218762
Trained batch 400 in epoch 19, gen_loss = 0.3941114380621256, disc_loss = 0.06499982157726761
Trained batch 401 in epoch 19, gen_loss = 0.3940444577540924, disc_loss = 0.06541451035919993
Trained batch 402 in epoch 19, gen_loss = 0.3942562429691958, disc_loss = 0.066171320240769
Trained batch 403 in epoch 19, gen_loss = 0.3942679039174967, disc_loss = 0.06630120598618863
Trained batch 404 in epoch 19, gen_loss = 0.39415007424943244, disc_loss = 0.06673969378763879
Trained batch 405 in epoch 19, gen_loss = 0.3942158862287775, disc_loss = 0.06696679243781223
Trained batch 406 in epoch 19, gen_loss = 0.39425295723158255, disc_loss = 0.06705369526424264
Trained batch 407 in epoch 19, gen_loss = 0.39412986530977134, disc_loss = 0.06714630878174349
Trained batch 408 in epoch 19, gen_loss = 0.39406408839528895, disc_loss = 0.0672670729836326
Trained batch 409 in epoch 19, gen_loss = 0.39407640084987733, disc_loss = 0.0675592988979344
Trained batch 410 in epoch 19, gen_loss = 0.3940770643470931, disc_loss = 0.06773854007858357
Trained batch 411 in epoch 19, gen_loss = 0.39389623853477457, disc_loss = 0.06779638206522948
Trained batch 412 in epoch 19, gen_loss = 0.39380039444269915, disc_loss = 0.06775224952762338
Trained batch 413 in epoch 19, gen_loss = 0.39385744051080973, disc_loss = 0.06778257393057724
Trained batch 414 in epoch 19, gen_loss = 0.3936758294881108, disc_loss = 0.067940232541457
Trained batch 415 in epoch 19, gen_loss = 0.3937594364755429, disc_loss = 0.06786215915837182
Trained batch 416 in epoch 19, gen_loss = 0.39381785108317, disc_loss = 0.06773646007463943
Trained batch 417 in epoch 19, gen_loss = 0.3936385875255868, disc_loss = 0.06768947902567791
Trained batch 418 in epoch 19, gen_loss = 0.39366943206024624, disc_loss = 0.06764664552963577
Trained batch 419 in epoch 19, gen_loss = 0.39377529266334715, disc_loss = 0.06760318677961116
Trained batch 420 in epoch 19, gen_loss = 0.393724847151378, disc_loss = 0.06753437519692894
Trained batch 421 in epoch 19, gen_loss = 0.3938295327797885, disc_loss = 0.06762849750941823
Trained batch 422 in epoch 19, gen_loss = 0.39370841450161403, disc_loss = 0.06802382272168395
Trained batch 423 in epoch 19, gen_loss = 0.39381892487125575, disc_loss = 0.06794986966558082
Trained batch 424 in epoch 19, gen_loss = 0.3939221264334286, disc_loss = 0.06790822470451102
Trained batch 425 in epoch 19, gen_loss = 0.39391105723492975, disc_loss = 0.06793091083688775
Trained batch 426 in epoch 19, gen_loss = 0.39386372599724584, disc_loss = 0.06781719801227717
Trained batch 427 in epoch 19, gen_loss = 0.39397953777948275, disc_loss = 0.06792637947772708
Trained batch 428 in epoch 19, gen_loss = 0.39391422445401725, disc_loss = 0.06812118898669045
Trained batch 429 in epoch 19, gen_loss = 0.39395936082961946, disc_loss = 0.06817141610176064
Trained batch 430 in epoch 19, gen_loss = 0.3938514212029716, disc_loss = 0.0680913861642166
Trained batch 431 in epoch 19, gen_loss = 0.393733581804015, disc_loss = 0.06796945302954151
Trained batch 432 in epoch 19, gen_loss = 0.3935806694124367, disc_loss = 0.06786348335186825
Trained batch 433 in epoch 19, gen_loss = 0.3936647600429948, disc_loss = 0.06773284346311598
Trained batch 434 in epoch 19, gen_loss = 0.3937401396104659, disc_loss = 0.06760682947077286
Trained batch 435 in epoch 19, gen_loss = 0.39377632771336707, disc_loss = 0.06750769882437287
Trained batch 436 in epoch 19, gen_loss = 0.3938393723773738, disc_loss = 0.06746658355475017
Trained batch 437 in epoch 19, gen_loss = 0.3939513236148172, disc_loss = 0.06788196724299426
Trained batch 438 in epoch 19, gen_loss = 0.3936303409329851, disc_loss = 0.06817515258908544
Trained batch 439 in epoch 19, gen_loss = 0.3936497326601635, disc_loss = 0.06820192423395136
Trained batch 440 in epoch 19, gen_loss = 0.3935422333054532, disc_loss = 0.06817498821722948
Trained batch 441 in epoch 19, gen_loss = 0.39350131410279426, disc_loss = 0.06817130432611677
Trained batch 442 in epoch 19, gen_loss = 0.39357070540736006, disc_loss = 0.06819345536336942
Trained batch 443 in epoch 19, gen_loss = 0.3934638398858878, disc_loss = 0.0681358327803848
Trained batch 444 in epoch 19, gen_loss = 0.3933847511752268, disc_loss = 0.06805358269576277
Trained batch 445 in epoch 19, gen_loss = 0.3933839212618601, disc_loss = 0.06840086887035135
Trained batch 446 in epoch 19, gen_loss = 0.3932413477492279, disc_loss = 0.06929846806347503
Trained batch 447 in epoch 19, gen_loss = 0.39336725204650846, disc_loss = 0.06924683703774852
Trained batch 448 in epoch 19, gen_loss = 0.39340244714826145, disc_loss = 0.06924128087697953
Trained batch 449 in epoch 19, gen_loss = 0.39346509390407136, disc_loss = 0.06942093696859147
Trained batch 450 in epoch 19, gen_loss = 0.39338635697861735, disc_loss = 0.06947240073176023
Trained batch 451 in epoch 19, gen_loss = 0.39332380673262923, disc_loss = 0.06944772085191402
Trained batch 452 in epoch 19, gen_loss = 0.39321830520040413, disc_loss = 0.06946236510282057
Trained batch 453 in epoch 19, gen_loss = 0.393004909682904, disc_loss = 0.06942754868204636
Trained batch 454 in epoch 19, gen_loss = 0.393081527031385, disc_loss = 0.06931164653173515
Trained batch 455 in epoch 19, gen_loss = 0.39315251202175494, disc_loss = 0.06920370415032825
Trained batch 456 in epoch 19, gen_loss = 0.39333634492604946, disc_loss = 0.06916125948159778
Trained batch 457 in epoch 19, gen_loss = 0.39337981326351, disc_loss = 0.06909092656015439
Trained batch 458 in epoch 19, gen_loss = 0.39344637047231584, disc_loss = 0.06907703047760301
Trained batch 459 in epoch 19, gen_loss = 0.3935874276187109, disc_loss = 0.06967593603564994
Trained batch 460 in epoch 19, gen_loss = 0.3934659986330475, disc_loss = 0.06963692651152481
Trained batch 461 in epoch 19, gen_loss = 0.39360771086308866, disc_loss = 0.0696157371963967
Trained batch 462 in epoch 19, gen_loss = 0.39365445157879114, disc_loss = 0.0696502966086177
Testing Epoch 19
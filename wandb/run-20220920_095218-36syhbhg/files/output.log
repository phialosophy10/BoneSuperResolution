/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 2.0169832706451416, disc_loss = 0.8424338102340698
Trained batch 1 in epoch 0, gen_loss = 2.0542396306991577, disc_loss = 1.2472043633460999
Trained batch 2 in epoch 0, gen_loss = 1.8599263032277424, disc_loss = 1.0101718505223591
Trained batch 3 in epoch 0, gen_loss = 1.757493942975998, disc_loss = 0.9044723361730576
Trained batch 4 in epoch 0, gen_loss = 1.6527705192565918, disc_loss = 0.8067275643348694
Trained batch 5 in epoch 0, gen_loss = 1.5616491238276164, disc_loss = 0.7339906146128973
Trained batch 6 in epoch 0, gen_loss = 1.4898898601531982, disc_loss = 0.6743746101856232
Trained batch 7 in epoch 0, gen_loss = 1.4335113167762756, disc_loss = 0.6254940740764141
Trained batch 8 in epoch 0, gen_loss = 1.3880843321482341, disc_loss = 0.5850614011287689
Trained batch 9 in epoch 0, gen_loss = 1.3547727227211, disc_loss = 0.5496909886598587
Trained batch 10 in epoch 0, gen_loss = 1.3288553736426614, disc_loss = 0.5181231864474036
Trained batch 11 in epoch 0, gen_loss = 1.310167819261551, disc_loss = 0.4894418766101201
Trained batch 12 in epoch 0, gen_loss = 1.294285352413471, disc_loss = 0.4636602791456076
Trained batch 13 in epoch 0, gen_loss = 1.2833830969674247, disc_loss = 0.44131632149219513
Trained batch 14 in epoch 0, gen_loss = 1.2737654527028401, disc_loss = 0.42060454686482746
Trained batch 15 in epoch 0, gen_loss = 1.2671491205692291, disc_loss = 0.40208754409104586
Trained batch 16 in epoch 0, gen_loss = 1.2610017762464636, disc_loss = 0.3855363165631014
Trained batch 17 in epoch 0, gen_loss = 1.2556557191742792, disc_loss = 0.369843240827322
Trained batch 18 in epoch 0, gen_loss = 1.2525266534403752, disc_loss = 0.35534448215835973
Trained batch 19 in epoch 0, gen_loss = 1.2513080954551696, disc_loss = 0.3423520177602768
Trained batch 20 in epoch 0, gen_loss = 1.2504185494922457, disc_loss = 0.3312414912950425
Trained batch 21 in epoch 0, gen_loss = 1.2519478581168435, disc_loss = 0.32140105082230136
Trained batch 22 in epoch 0, gen_loss = 1.2520632018213687, disc_loss = 0.3131954488546952
Trained batch 23 in epoch 0, gen_loss = 1.2516491611798604, disc_loss = 0.30670424302419025
Trained batch 24 in epoch 0, gen_loss = 1.2525151824951173, disc_loss = 0.2993688291311264
Trained batch 25 in epoch 0, gen_loss = 1.2531503897446852, disc_loss = 0.2907791192141863
Trained batch 26 in epoch 0, gen_loss = 1.2539642210359927, disc_loss = 0.28349867269948675
Trained batch 27 in epoch 0, gen_loss = 1.2531770127160209, disc_loss = 0.27644434943795204
Trained batch 28 in epoch 0, gen_loss = 1.2530140712343414, disc_loss = 0.2691264781972458
Trained batch 29 in epoch 0, gen_loss = 1.2540812095006306, disc_loss = 0.26190353445708753
Trained batch 30 in epoch 0, gen_loss = 1.2552095228625881, disc_loss = 0.2550339731237581
Trained batch 31 in epoch 0, gen_loss = 1.2568283788859844, disc_loss = 0.24870466871652752
Trained batch 32 in epoch 0, gen_loss = 1.2571753227349483, disc_loss = 0.2425824644213373
Trained batch 33 in epoch 0, gen_loss = 1.2578270645702587, disc_loss = 0.23668455737916863
Trained batch 34 in epoch 0, gen_loss = 1.259836404664176, disc_loss = 0.2314029335975647
Trained batch 35 in epoch 0, gen_loss = 1.2605532540215387, disc_loss = 0.22617232458045086
Trained batch 36 in epoch 0, gen_loss = 1.2600279369869747, disc_loss = 0.22115610106974035
Trained batch 37 in epoch 0, gen_loss = 1.2624068573901528, disc_loss = 0.21643588799787195
Trained batch 38 in epoch 0, gen_loss = 1.2650559193048723, disc_loss = 0.21194638970952767
Trained batch 39 in epoch 0, gen_loss = 1.2648542463779449, disc_loss = 0.20763068227097392
Trained batch 40 in epoch 0, gen_loss = 1.2662047787410458, disc_loss = 0.20346366332435026
Trained batch 41 in epoch 0, gen_loss = 1.2687573631604512, disc_loss = 0.19991219939575308
Trained batch 42 in epoch 0, gen_loss = 1.2697619144306627, disc_loss = 0.1962080096262832
Trained batch 43 in epoch 0, gen_loss = 1.2688631036064841, disc_loss = 0.192512561482462
Trained batch 44 in epoch 0, gen_loss = 1.2702935881084867, disc_loss = 0.18888624525732464
Trained batch 45 in epoch 0, gen_loss = 1.2724104627319004, disc_loss = 0.18544756175707217
Trained batch 46 in epoch 0, gen_loss = 1.2734042380718475, disc_loss = 0.18224103962804408
Trained batch 47 in epoch 0, gen_loss = 1.2762030214071274, disc_loss = 0.17942176844614247
Trained batch 48 in epoch 0, gen_loss = 1.2755004070243057, disc_loss = 0.176919693925551
Trained batch 49 in epoch 0, gen_loss = 1.2767831659317017, disc_loss = 0.17497001864016057
Trained batch 50 in epoch 0, gen_loss = 1.2791515892627192, disc_loss = 0.1734321220394443
Trained batch 51 in epoch 0, gen_loss = 1.2795682159753947, disc_loss = 0.17171576483031878
Trained batch 52 in epoch 0, gen_loss = 1.2781526907435004, disc_loss = 0.16948646693578306
Trained batch 53 in epoch 0, gen_loss = 1.2779758506351047, disc_loss = 0.1669768772467419
Trained batch 54 in epoch 0, gen_loss = 1.2793648806485263, disc_loss = 0.1645109476013617
Trained batch 55 in epoch 0, gen_loss = 1.2794881931373052, disc_loss = 0.1620957870701594
Trained batch 56 in epoch 0, gen_loss = 1.2786943368744432, disc_loss = 0.15973581076321894
Trained batch 57 in epoch 0, gen_loss = 1.2780018921556144, disc_loss = 0.15743210086406306
Trained batch 58 in epoch 0, gen_loss = 1.279328978667825, disc_loss = 0.15537734837981604
Trained batch 59 in epoch 0, gen_loss = 1.2781298855940502, disc_loss = 0.15324285017947356
Trained batch 60 in epoch 0, gen_loss = 1.2785320106099864, disc_loss = 0.15127218484145696
Trained batch 61 in epoch 0, gen_loss = 1.275144963495193, disc_loss = 0.14941984517199378
Trained batch 62 in epoch 0, gen_loss = 1.2776038760230655, disc_loss = 0.1476094549492238
Trained batch 63 in epoch 0, gen_loss = 1.280240811407566, disc_loss = 0.14593990880530328
Trained batch 64 in epoch 0, gen_loss = 1.280532770890456, disc_loss = 0.1442821849997227
Trained batch 65 in epoch 0, gen_loss = 1.2789025378949714, disc_loss = 0.14259014848732587
Trained batch 66 in epoch 0, gen_loss = 1.2799737328913674, disc_loss = 0.1408479066649035
Trained batch 67 in epoch 0, gen_loss = 1.2810683653635138, disc_loss = 0.13912392632268808
Trained batch 68 in epoch 0, gen_loss = 1.2811711093653804, disc_loss = 0.1374545320868492
Trained batch 69 in epoch 0, gen_loss = 1.2806724054472787, disc_loss = 0.1357731316770826
Trained batch 70 in epoch 0, gen_loss = 1.2803288295235433, disc_loss = 0.1341172066372885
Trained batch 71 in epoch 0, gen_loss = 1.2801767422093286, disc_loss = 0.13252039031229085
Trained batch 72 in epoch 0, gen_loss = 1.2790833401353392, disc_loss = 0.13096270396386925
Trained batch 73 in epoch 0, gen_loss = 1.2797931368286546, disc_loss = 0.12950988370623137
Trained batch 74 in epoch 0, gen_loss = 1.2780008967717489, disc_loss = 0.1280682660639286
Trained batch 75 in epoch 0, gen_loss = 1.279000036026302, disc_loss = 0.1267069171820032
Trained batch 76 in epoch 0, gen_loss = 1.2786178434049928, disc_loss = 0.12541657374179982
Trained batch 77 in epoch 0, gen_loss = 1.2787702679634094, disc_loss = 0.12423285939850104
Trained batch 78 in epoch 0, gen_loss = 1.2792378030245817, disc_loss = 0.12305562940862359
Trained batch 79 in epoch 0, gen_loss = 1.2793476402759552, disc_loss = 0.12181885445024818
Trained batch 80 in epoch 0, gen_loss = 1.2778580939328228, disc_loss = 0.1205276208297338
Trained batch 81 in epoch 0, gen_loss = 1.2770400992253932, disc_loss = 0.11923983153637226
Trained batch 82 in epoch 0, gen_loss = 1.276808592210333, disc_loss = 0.117984560509044
Trained batch 83 in epoch 0, gen_loss = 1.277115518138522, disc_loss = 0.1167591178922781
Trained batch 84 in epoch 0, gen_loss = 1.2754367435679717, disc_loss = 0.11557868414503687
Trained batch 85 in epoch 0, gen_loss = 1.2751691285953966, disc_loss = 0.11441589194501556
Trained batch 86 in epoch 0, gen_loss = 1.2753948699468853, disc_loss = 0.11328341873983543
Trained batch 87 in epoch 0, gen_loss = 1.274890502745455, disc_loss = 0.11224984100342474
Trained batch 88 in epoch 0, gen_loss = 1.2703552219305145, disc_loss = 0.11144268548304445
Trained batch 89 in epoch 0, gen_loss = 1.2728139850828382, disc_loss = 0.11070789920373095
Trained batch 90 in epoch 0, gen_loss = 1.270527937910059, disc_loss = 0.1098670657560393
Trained batch 91 in epoch 0, gen_loss = 1.2694910000199857, disc_loss = 0.1090763152738952
Trained batch 92 in epoch 0, gen_loss = 1.270771547030377, disc_loss = 0.10846569298976852
Trained batch 93 in epoch 0, gen_loss = 1.2693437020829383, disc_loss = 0.1077816316540888
Trained batch 94 in epoch 0, gen_loss = 1.268998206289191, disc_loss = 0.10685112352826093
Trained batch 95 in epoch 0, gen_loss = 1.2688959116737049, disc_loss = 0.1060066645926175
Trained batch 96 in epoch 0, gen_loss = 1.268599574098882, disc_loss = 0.10510354734880407
Trained batch 97 in epoch 0, gen_loss = 1.2669328414663976, disc_loss = 0.10419655845937681
Trained batch 98 in epoch 0, gen_loss = 1.2657665411631267, disc_loss = 0.10328448087804848
Trained batch 99 in epoch 0, gen_loss = 1.2655086147785186, disc_loss = 0.10236580733209849
Trained batch 100 in epoch 0, gen_loss = 1.2646626411098065, disc_loss = 0.10145413649664951
Trained batch 101 in epoch 0, gen_loss = 1.2645941107880836, disc_loss = 0.10059255207249639
Trained batch 102 in epoch 0, gen_loss = 1.2622321427447125, disc_loss = 0.09976528843557372
Trained batch 103 in epoch 0, gen_loss = 1.2620176718785212, disc_loss = 0.09891139040701091
Trained batch 104 in epoch 0, gen_loss = 1.2617865505672636, disc_loss = 0.09807183789532808
Trained batch 105 in epoch 0, gen_loss = 1.261296659145715, disc_loss = 0.09725849243443248
Trained batch 106 in epoch 0, gen_loss = 1.2603668609512186, disc_loss = 0.09646211582819157
Trained batch 107 in epoch 0, gen_loss = 1.259867561084253, disc_loss = 0.09568763697623378
Trained batch 108 in epoch 0, gen_loss = 1.2585912330434956, disc_loss = 0.0949271022504486
Trained batch 109 in epoch 0, gen_loss = 1.2589323542334816, disc_loss = 0.09417647103863684
Trained batch 110 in epoch 0, gen_loss = 1.2575721203743875, disc_loss = 0.0934239550334242
Trained batch 111 in epoch 0, gen_loss = 1.25630299108369, disc_loss = 0.09268048714979418
Trained batch 112 in epoch 0, gen_loss = 1.2556531555884707, disc_loss = 0.09199759519897995
Trained batch 113 in epoch 0, gen_loss = 1.254303000475231, disc_loss = 0.09133568501688148
Trained batch 114 in epoch 0, gen_loss = 1.2532118113144584, disc_loss = 0.09070723515975734
Trained batch 115 in epoch 0, gen_loss = 1.2530041655589794, disc_loss = 0.0900894505180547
Trained batch 116 in epoch 0, gen_loss = 1.2518626522814107, disc_loss = 0.08946751464858778
Trained batch 117 in epoch 0, gen_loss = 1.2517117767010706, disc_loss = 0.08885617299257952
Trained batch 118 in epoch 0, gen_loss = 1.2508045495057307, disc_loss = 0.0882120422095436
Trained batch 119 in epoch 0, gen_loss = 1.2487755407889685, disc_loss = 0.08761456736829132
Trained batch 120 in epoch 0, gen_loss = 1.248725740377568, disc_loss = 0.08700053162164678
Trained batch 121 in epoch 0, gen_loss = 1.2494730431525434, disc_loss = 0.0864471880887009
Trained batch 122 in epoch 0, gen_loss = 1.2474874820166486, disc_loss = 0.08590884206104811
Trained batch 123 in epoch 0, gen_loss = 1.2464278099998352, disc_loss = 0.0853212355530911
Trained batch 124 in epoch 0, gen_loss = 1.2463472986221313, disc_loss = 0.08471578017622232
Trained batch 125 in epoch 0, gen_loss = 1.246368149916331, disc_loss = 0.08417166816070676
Trained batch 126 in epoch 0, gen_loss = 1.2444023222435179, disc_loss = 0.08361381241743725
Trained batch 127 in epoch 0, gen_loss = 1.2433992689475417, disc_loss = 0.08303690005413955
Trained batch 128 in epoch 0, gen_loss = 1.2429341595302257, disc_loss = 0.08246883041723523
Trained batch 129 in epoch 0, gen_loss = 1.2424114970060496, disc_loss = 0.08191599900332781
Trained batch 130 in epoch 0, gen_loss = 1.2417048889262077, disc_loss = 0.08135617119864426
Trained batch 131 in epoch 0, gen_loss = 1.240658627315001, disc_loss = 0.08079889110487068
Trained batch 132 in epoch 0, gen_loss = 1.2396702721602935, disc_loss = 0.0802609846556097
Trained batch 133 in epoch 0, gen_loss = 1.239496062940626, disc_loss = 0.07975581032571508
Trained batch 134 in epoch 0, gen_loss = 1.2377191243348298, disc_loss = 0.0792528849647001
Trained batch 135 in epoch 0, gen_loss = 1.236613408607595, disc_loss = 0.07873914172352456
Trained batch 136 in epoch 0, gen_loss = 1.2365937172061336, disc_loss = 0.07823921708104602
Trained batch 137 in epoch 0, gen_loss = 1.235674128152322, disc_loss = 0.07772387287484994
Trained batch 138 in epoch 0, gen_loss = 1.2347491430721695, disc_loss = 0.07720869022803448
Trained batch 139 in epoch 0, gen_loss = 1.2342817102159773, disc_loss = 0.07671160149787154
Trained batch 140 in epoch 0, gen_loss = 1.233460693494648, disc_loss = 0.0762250846819886
Trained batch 141 in epoch 0, gen_loss = 1.2319839949339209, disc_loss = 0.0757418105798498
Trained batch 142 in epoch 0, gen_loss = 1.2319742207760578, disc_loss = 0.07528946650950434
Trained batch 143 in epoch 0, gen_loss = 1.230985041293833, disc_loss = 0.07486136606247681
Trained batch 144 in epoch 0, gen_loss = 1.23053431428712, disc_loss = 0.07441998229458414
Trained batch 145 in epoch 0, gen_loss = 1.23020407353362, disc_loss = 0.07403020678113585
Trained batch 146 in epoch 0, gen_loss = 1.2267205715179443, disc_loss = 0.0737969867479639
Trained batch 147 in epoch 0, gen_loss = 1.2280807358187598, disc_loss = 0.0734483741878255
Trained batch 148 in epoch 0, gen_loss = 1.228668064879091, disc_loss = 0.07350318086327322
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.2810582220554352, disc_loss = 0.24268405139446259
Trained batch 1 in epoch 1, gen_loss = 0.6527183204889297, disc_loss = 0.26251276582479477
Trained batch 2 in epoch 1, gen_loss = 0.7395013074080149, disc_loss = 0.35785094400246936
Trained batch 3 in epoch 1, gen_loss = 0.832539401948452, disc_loss = 0.43318649753928185
Trained batch 4 in epoch 1, gen_loss = 0.9632074058055877, disc_loss = 0.48446235358715056
Trained batch 5 in epoch 1, gen_loss = 1.0162740896145503, disc_loss = 0.5024949784080187
Trained batch 6 in epoch 1, gen_loss = 1.0010150032384055, disc_loss = 0.4663057007959911
Trained batch 7 in epoch 1, gen_loss = 0.9703622125089169, disc_loss = 0.42425459437072277
Trained batch 8 in epoch 1, gen_loss = 0.9370634390248193, disc_loss = 0.3866297933790419
Trained batch 9 in epoch 1, gen_loss = 0.9215678125619888, disc_loss = 0.3540231868624687
Trained batch 10 in epoch 1, gen_loss = 0.9171588339588859, disc_loss = 0.3254366821863435
Trained batch 11 in epoch 1, gen_loss = 0.9210401798288027, disc_loss = 0.30101797450333834
Trained batch 12 in epoch 1, gen_loss = 0.9233455451635214, disc_loss = 0.2794319935716115
Trained batch 13 in epoch 1, gen_loss = 0.926660207765443, disc_loss = 0.2609219259715506
Trained batch 14 in epoch 1, gen_loss = 0.9301848471164703, disc_loss = 0.244492203493913
Trained batch 15 in epoch 1, gen_loss = 0.9345889072865248, disc_loss = 0.23021772573702037
Trained batch 16 in epoch 1, gen_loss = 0.9402940466123468, disc_loss = 0.2173457414678791
Trained batch 17 in epoch 1, gen_loss = 0.9459520098235872, disc_loss = 0.20577524338538447
Trained batch 18 in epoch 1, gen_loss = 0.9524235333267012, disc_loss = 0.1954202312289884
Trained batch 19 in epoch 1, gen_loss = 0.9582155093550682, disc_loss = 0.18624964277260006
Trained batch 20 in epoch 1, gen_loss = 0.9620375619048164, disc_loss = 0.17780839563125656
Trained batch 21 in epoch 1, gen_loss = 0.9662044684995305, disc_loss = 0.1702167462896217
Trained batch 22 in epoch 1, gen_loss = 0.9714618649171747, disc_loss = 0.16322006884476412
Trained batch 23 in epoch 1, gen_loss = 0.9759207951525847, disc_loss = 0.1568089705736687
Trained batch 24 in epoch 1, gen_loss = 0.9789305484294891, disc_loss = 0.1508521469309926
Trained batch 25 in epoch 1, gen_loss = 0.9848642796278, disc_loss = 0.14541914711634701
Trained batch 26 in epoch 1, gen_loss = 0.9876740806632571, disc_loss = 0.14036931287221335
Trained batch 27 in epoch 1, gen_loss = 0.9921915222491536, disc_loss = 0.13580223987810314
Trained batch 28 in epoch 1, gen_loss = 0.9954764791603746, disc_loss = 0.13146006441193409
Trained batch 29 in epoch 1, gen_loss = 0.9983938723802567, disc_loss = 0.12737874798476695
Trained batch 30 in epoch 1, gen_loss = 1.0018442128935168, disc_loss = 0.12356365442035659
Trained batch 31 in epoch 1, gen_loss = 1.0041045350953937, disc_loss = 0.11996687139617279
Trained batch 32 in epoch 1, gen_loss = 1.0073107797088046, disc_loss = 0.11655607246652697
Trained batch 33 in epoch 1, gen_loss = 1.0102411955595016, disc_loss = 0.11349766923333793
Trained batch 34 in epoch 1, gen_loss = 1.0118372636181967, disc_loss = 0.11053933104766267
Trained batch 35 in epoch 1, gen_loss = 1.0146418039997418, disc_loss = 0.10768287582322955
Trained batch 36 in epoch 1, gen_loss = 1.0170056264142733, disc_loss = 0.10498242709483649
Trained batch 37 in epoch 1, gen_loss = 1.0200398995688087, disc_loss = 0.10244356478123288
Trained batch 38 in epoch 1, gen_loss = 1.0227820101456764, disc_loss = 0.10002585409734494
Trained batch 39 in epoch 1, gen_loss = 1.0256927244365215, disc_loss = 0.09769823091337457
Trained batch 40 in epoch 1, gen_loss = 1.0277648866176605, disc_loss = 0.09555733909194426
Trained batch 41 in epoch 1, gen_loss = 1.0286573618650436, disc_loss = 0.0935064451879866
Trained batch 42 in epoch 1, gen_loss = 1.0302972980709963, disc_loss = 0.09154191562299464
Trained batch 43 in epoch 1, gen_loss = 1.032146575098688, disc_loss = 0.08964917991860685
Trained batch 44 in epoch 1, gen_loss = 1.0336847166220346, disc_loss = 0.08783007935724324
Trained batch 45 in epoch 1, gen_loss = 1.0361479073762894, disc_loss = 0.08607323387759211
Trained batch 46 in epoch 1, gen_loss = 1.0381331767173523, disc_loss = 0.08441263077622081
Trained batch 47 in epoch 1, gen_loss = 1.0409208207080762, disc_loss = 0.0828206979689033
Trained batch 48 in epoch 1, gen_loss = 1.0425733978651008, disc_loss = 0.08127810352728987
Trained batch 49 in epoch 1, gen_loss = 1.0460946267843247, disc_loss = 0.0798541661631316
Trained batch 50 in epoch 1, gen_loss = 1.0470518265284745, disc_loss = 0.07844334704728395
Trained batch 51 in epoch 1, gen_loss = 1.0488765004735727, disc_loss = 0.07711639053797206
Trained batch 52 in epoch 1, gen_loss = 1.0517892854393653, disc_loss = 0.07582601464687372
Trained batch 53 in epoch 1, gen_loss = 1.0525999085770712, disc_loss = 0.07460987239351703
Trained batch 54 in epoch 1, gen_loss = 1.0550525291399522, disc_loss = 0.07338080754164945
Trained batch 55 in epoch 1, gen_loss = 1.058286938816309, disc_loss = 0.07221679079313097
Trained batch 56 in epoch 1, gen_loss = 1.060534802968042, disc_loss = 0.07107571001867191
Trained batch 57 in epoch 1, gen_loss = 1.0616128809493164, disc_loss = 0.06996985354685578
Trained batch 58 in epoch 1, gen_loss = 1.0628834048570213, disc_loss = 0.06889728834789435
Trained batch 59 in epoch 1, gen_loss = 1.0665802255272865, disc_loss = 0.06787067278443525
Trained batch 60 in epoch 1, gen_loss = 1.0697623779539203, disc_loss = 0.06689269386506716
Trained batch 61 in epoch 1, gen_loss = 1.0705656154501824, disc_loss = 0.06593186852161682
Trained batch 62 in epoch 1, gen_loss = 1.0707041966536688, disc_loss = 0.06502490532806232
Trained batch 63 in epoch 1, gen_loss = 1.0738300527445972, disc_loss = 0.06413652710762108
Trained batch 64 in epoch 1, gen_loss = 1.0752296699927404, disc_loss = 0.06326253473615417
Trained batch 65 in epoch 1, gen_loss = 1.0769095253763776, disc_loss = 0.0624168681150133
Trained batch 66 in epoch 1, gen_loss = 1.0788903552204816, disc_loss = 0.06158466039420064
Trained batch 67 in epoch 1, gen_loss = 1.0800381666597199, disc_loss = 0.06076299601837116
Trained batch 68 in epoch 1, gen_loss = 1.081370137307955, disc_loss = 0.05996539918165924
Trained batch 69 in epoch 1, gen_loss = 1.082739538380078, disc_loss = 0.059207661589607594
Trained batch 70 in epoch 1, gen_loss = 1.0846222500566025, disc_loss = 0.058480450660515
Trained batch 71 in epoch 1, gen_loss = 1.0849686641660001, disc_loss = 0.057756224957605205
Trained batch 72 in epoch 1, gen_loss = 1.085942605995152, disc_loss = 0.05705758188021918
Trained batch 73 in epoch 1, gen_loss = 1.0874936786052343, disc_loss = 0.056396276375429856
Trained batch 74 in epoch 1, gen_loss = 1.0882204210758208, disc_loss = 0.05573448825627565
Trained batch 75 in epoch 1, gen_loss = 1.0885989034646435, disc_loss = 0.055095606691841235
Trained batch 76 in epoch 1, gen_loss = 1.089915988894252, disc_loss = 0.054470157250761986
Trained batch 77 in epoch 1, gen_loss = 1.091464054508087, disc_loss = 0.053884172143462375
Trained batch 78 in epoch 1, gen_loss = 1.0937083925627455, disc_loss = 0.05330284928926562
Trained batch 79 in epoch 1, gen_loss = 1.0943031024187804, disc_loss = 0.05272091247607023
Trained batch 80 in epoch 1, gen_loss = 1.0957590072979162, disc_loss = 0.05216764220622955
Trained batch 81 in epoch 1, gen_loss = 1.096821748265406, disc_loss = 0.05163151597058991
Trained batch 82 in epoch 1, gen_loss = 1.0969372079314956, disc_loss = 0.051093225154172944
Trained batch 83 in epoch 1, gen_loss = 1.098122235919748, disc_loss = 0.050558488095356596
Trained batch 84 in epoch 1, gen_loss = 1.0998675567262313, disc_loss = 0.050034034432952894
Trained batch 85 in epoch 1, gen_loss = 1.0998887402373692, disc_loss = 0.04952563690346514
Trained batch 86 in epoch 1, gen_loss = 1.101556685806691, disc_loss = 0.04909849214506732
Trained batch 87 in epoch 1, gen_loss = 1.1021373255009002, disc_loss = 0.048616984001868827
Trained batch 88 in epoch 1, gen_loss = 1.1018589704893949, disc_loss = 0.04814832332659136
Trained batch 89 in epoch 1, gen_loss = 1.1034535987509622, disc_loss = 0.04770262772734794
Trained batch 90 in epoch 1, gen_loss = 1.103920735828169, disc_loss = 0.04729115644183297
Trained batch 91 in epoch 1, gen_loss = 1.1040887453633805, disc_loss = 0.04688210501436792
Trained batch 92 in epoch 1, gen_loss = 1.1046816004860787, disc_loss = 0.04645739697040089
Trained batch 93 in epoch 1, gen_loss = 1.1063170341101098, disc_loss = 0.04604353380706558
Trained batch 94 in epoch 1, gen_loss = 1.1063376787461732, disc_loss = 0.04562868089170048
Trained batch 95 in epoch 1, gen_loss = 1.1074837145085137, disc_loss = 0.045211821983684786
Trained batch 96 in epoch 1, gen_loss = 1.108232481885202, disc_loss = 0.044850772481949366
Trained batch 97 in epoch 1, gen_loss = 1.1075793392195994, disc_loss = 0.04447577279346178
Trained batch 98 in epoch 1, gen_loss = 1.108009557230304, disc_loss = 0.04410919055549635
Trained batch 99 in epoch 1, gen_loss = 1.1091731569170953, disc_loss = 0.04374138500541449
Trained batch 100 in epoch 1, gen_loss = 1.1100970574534765, disc_loss = 0.04337565531714423
Trained batch 101 in epoch 1, gen_loss = 1.1108519116453095, disc_loss = 0.04300702411644891
Trained batch 102 in epoch 1, gen_loss = 1.1108542145455924, disc_loss = 0.04270121563696167
Trained batch 103 in epoch 1, gen_loss = 1.1115034059263194, disc_loss = 0.04236688267869445
Trained batch 104 in epoch 1, gen_loss = 1.1120803569044386, disc_loss = 0.042016370763026535
Trained batch 105 in epoch 1, gen_loss = 1.1132045093010057, disc_loss = 0.041677367482510094
Trained batch 106 in epoch 1, gen_loss = 1.1138199654137977, disc_loss = 0.041340950236734106
Trained batch 107 in epoch 1, gen_loss = 1.1140549985898867, disc_loss = 0.04101070792293521
Trained batch 108 in epoch 1, gen_loss = 1.1143874692807503, disc_loss = 0.04067497819645006
Trained batch 109 in epoch 1, gen_loss = 1.1148226117545907, disc_loss = 0.040372226137498565
Trained batch 110 in epoch 1, gen_loss = 1.115009228119979, disc_loss = 0.04005257621290045
Trained batch 111 in epoch 1, gen_loss = 1.1154526341706514, disc_loss = 0.03973524869486157
Trained batch 112 in epoch 1, gen_loss = 1.1168031784812962, disc_loss = 0.039437725830955055
Trained batch 113 in epoch 1, gen_loss = 1.1169665986508654, disc_loss = 0.039138521316967774
Trained batch 114 in epoch 1, gen_loss = 1.116687395002531, disc_loss = 0.038848672256521555
Trained batch 115 in epoch 1, gen_loss = 1.1169653696746662, disc_loss = 0.03855479878758819
Trained batch 116 in epoch 1, gen_loss = 1.1168064548928514, disc_loss = 0.038274810179813296
Trained batch 117 in epoch 1, gen_loss = 1.1179715948084654, disc_loss = 0.03799194873357981
Trained batch 118 in epoch 1, gen_loss = 1.1178762419384067, disc_loss = 0.03772336802985363
Trained batch 119 in epoch 1, gen_loss = 1.1178225822746755, disc_loss = 0.037454811308998616
Trained batch 120 in epoch 1, gen_loss = 1.118115902685922, disc_loss = 0.03717604197931191
Trained batch 121 in epoch 1, gen_loss = 1.1186918799505858, disc_loss = 0.03690775831184182
Trained batch 122 in epoch 1, gen_loss = 1.1197680775227585, disc_loss = 0.03665454343445902
Trained batch 123 in epoch 1, gen_loss = 1.1192677624283298, disc_loss = 0.03640440618619323
Trained batch 124 in epoch 1, gen_loss = 1.1205871684551238, disc_loss = 0.036165258452296255
Trained batch 125 in epoch 1, gen_loss = 1.1208151898213796, disc_loss = 0.035922799026593566
Trained batch 126 in epoch 1, gen_loss = 1.1202132830938956, disc_loss = 0.03568854748718734
Trained batch 127 in epoch 1, gen_loss = 1.1209006763529032, disc_loss = 0.03545866686181398
Trained batch 128 in epoch 1, gen_loss = 1.1217506105123565, disc_loss = 0.03522723105324562
Trained batch 129 in epoch 1, gen_loss = 1.121733785363344, disc_loss = 0.0350103483033868
Trained batch 130 in epoch 1, gen_loss = 1.121517546076811, disc_loss = 0.03478893442150518
Trained batch 131 in epoch 1, gen_loss = 1.1216116003466374, disc_loss = 0.034553480659131754
Trained batch 132 in epoch 1, gen_loss = 1.122835553454277, disc_loss = 0.03436681013414286
Trained batch 133 in epoch 1, gen_loss = 1.1220311119930069, disc_loss = 0.034175193618371416
Trained batch 134 in epoch 1, gen_loss = 1.12222641993452, disc_loss = 0.033977338706177695
Trained batch 135 in epoch 1, gen_loss = 1.1228162644102293, disc_loss = 0.033770786605172735
Trained batch 136 in epoch 1, gen_loss = 1.1228546998361602, disc_loss = 0.033560860341238063
Trained batch 137 in epoch 1, gen_loss = 1.1237334580957026, disc_loss = 0.033357475995612534
Trained batch 138 in epoch 1, gen_loss = 1.1237464815163785, disc_loss = 0.03317773087191389
Trained batch 139 in epoch 1, gen_loss = 1.1229306423238345, disc_loss = 0.0329981117542567
Trained batch 140 in epoch 1, gen_loss = 1.1233519668697465, disc_loss = 0.0327963282301335
Trained batch 141 in epoch 1, gen_loss = 1.124270768862375, disc_loss = 0.03260839077591581
Trained batch 142 in epoch 1, gen_loss = 1.1245245439606113, disc_loss = 0.03240639005195011
Trained batch 143 in epoch 1, gen_loss = 1.1239291154262092, disc_loss = 0.03223281655421791
Trained batch 144 in epoch 1, gen_loss = 1.124148919459047, disc_loss = 0.03205022025724937
Trained batch 145 in epoch 1, gen_loss = 1.1248892894754672, disc_loss = 0.03185755070873013
Trained batch 146 in epoch 1, gen_loss = 1.1248954386532712, disc_loss = 0.031665820470016426
Trained batch 147 in epoch 1, gen_loss = 1.125556897271324, disc_loss = 0.031493789179728844
Trained batch 148 in epoch 1, gen_loss = 1.1249340610616159, disc_loss = 0.031328330397755906
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.1691678762435913, disc_loss = 0.004823564551770687
Trained batch 1 in epoch 2, gen_loss = 1.1509474515914917, disc_loss = 0.004714190261438489
Trained batch 2 in epoch 2, gen_loss = 1.1633098125457764, disc_loss = 0.004654886666685343
Trained batch 3 in epoch 2, gen_loss = 1.147194504737854, disc_loss = 0.004518900881521404
Trained batch 4 in epoch 2, gen_loss = 1.1525597810745238, disc_loss = 0.004239428229629994
Trained batch 5 in epoch 2, gen_loss = 1.165128767490387, disc_loss = 0.0043197704168657465
Trained batch 6 in epoch 2, gen_loss = 1.1613227810178484, disc_loss = 0.004147219937294722
Trained batch 7 in epoch 2, gen_loss = 1.1450843513011932, disc_loss = 0.004318160703405738
Trained batch 8 in epoch 2, gen_loss = 1.1452371544308133, disc_loss = 0.004193649627268314
Trained batch 9 in epoch 2, gen_loss = 1.1533900380134583, disc_loss = 0.0042142637073993685
Trained batch 10 in epoch 2, gen_loss = 1.152854399247603, disc_loss = 0.0041553474835712804
Trained batch 11 in epoch 2, gen_loss = 1.1450208028157551, disc_loss = 0.0042293235698404414
Trained batch 12 in epoch 2, gen_loss = 1.138683823438791, disc_loss = 0.004264107278476541
Trained batch 13 in epoch 2, gen_loss = 1.1446082081113542, disc_loss = 0.004241969652606973
Trained batch 14 in epoch 2, gen_loss = 1.1480172077814739, disc_loss = 0.004242301437382897
Trained batch 15 in epoch 2, gen_loss = 1.1451506093144417, disc_loss = 0.004184127596090548
Trained batch 16 in epoch 2, gen_loss = 1.142789686427397, disc_loss = 0.00413923673605656
Trained batch 17 in epoch 2, gen_loss = 1.1415215465757582, disc_loss = 0.0040872908300823635
Trained batch 18 in epoch 2, gen_loss = 1.142977193782204, disc_loss = 0.004027732415124774
Trained batch 19 in epoch 2, gen_loss = 1.1394542455673218, disc_loss = 0.004012740799225867
Trained batch 20 in epoch 2, gen_loss = 1.1425959723336356, disc_loss = 0.0040264445401373365
Trained batch 21 in epoch 2, gen_loss = 1.142598493532701, disc_loss = 0.004006358519704504
Trained batch 22 in epoch 2, gen_loss = 1.1390279013177622, disc_loss = 0.004039193240358778
Trained batch 23 in epoch 2, gen_loss = 1.1371028274297714, disc_loss = 0.004017031305314352
Trained batch 24 in epoch 2, gen_loss = 1.137718358039856, disc_loss = 0.004016981143504381
Trained batch 25 in epoch 2, gen_loss = 1.1396507987609277, disc_loss = 0.004001600435003638
Trained batch 26 in epoch 2, gen_loss = 1.1386382623955056, disc_loss = 0.003975319055219491
Trained batch 27 in epoch 2, gen_loss = 1.1375497153827123, disc_loss = 0.003941765653767756
Trained batch 28 in epoch 2, gen_loss = 1.1366016659243354, disc_loss = 0.003904663042390141
Trained batch 29 in epoch 2, gen_loss = 1.1375163475672403, disc_loss = 0.003909030106539527
Trained batch 30 in epoch 2, gen_loss = 1.1368629317129813, disc_loss = 0.003889135715942229
Trained batch 31 in epoch 2, gen_loss = 1.1342396289110184, disc_loss = 0.0038908659771550447
Trained batch 32 in epoch 2, gen_loss = 1.135678464716131, disc_loss = 0.0038910114883699202
Trained batch 33 in epoch 2, gen_loss = 1.1365585151840658, disc_loss = 0.003887766307932051
Trained batch 34 in epoch 2, gen_loss = 1.1344455310276575, disc_loss = 0.0038954685375626598
Trained batch 35 in epoch 2, gen_loss = 1.1344192690319486, disc_loss = 0.003870053708346354
Trained batch 36 in epoch 2, gen_loss = 1.1343939239914353, disc_loss = 0.0038510225209835414
Trained batch 37 in epoch 2, gen_loss = 1.1345043872532092, disc_loss = 0.004002603604213188
Trained batch 38 in epoch 2, gen_loss = 1.1291141571142735, disc_loss = 0.004310215847232403
Trained batch 39 in epoch 2, gen_loss = 1.1327246755361557, disc_loss = 0.0046099503990262745
Trained batch 40 in epoch 2, gen_loss = 1.1309543470057046, disc_loss = 0.004659515691966545
Trained batch 41 in epoch 2, gen_loss = 1.130514539423443, disc_loss = 0.00462461403748464
Trained batch 42 in epoch 2, gen_loss = 1.132253186647282, disc_loss = 0.004659229705413413
Trained batch 43 in epoch 2, gen_loss = 1.1299169090661136, disc_loss = 0.004681143200617622
Trained batch 44 in epoch 2, gen_loss = 1.1299400117662217, disc_loss = 0.004677461149791877
Trained batch 45 in epoch 2, gen_loss = 1.1292743501455889, disc_loss = 0.004670061191300983
Trained batch 46 in epoch 2, gen_loss = 1.1297661700147263, disc_loss = 0.004659869509967084
Trained batch 47 in epoch 2, gen_loss = 1.1280682211120923, disc_loss = 0.004633059802775581
Trained batch 48 in epoch 2, gen_loss = 1.1274493081229073, disc_loss = 0.004602693990633196
Trained batch 49 in epoch 2, gen_loss = 1.1267870712280272, disc_loss = 0.004578029057011008
Trained batch 50 in epoch 2, gen_loss = 1.127150488834755, disc_loss = 0.004580629140357761
Trained batch 51 in epoch 2, gen_loss = 1.1261594387201161, disc_loss = 0.004568900545844092
Trained batch 52 in epoch 2, gen_loss = 1.1259507098287906, disc_loss = 0.004566482997516978
Trained batch 53 in epoch 2, gen_loss = 1.1244555093623974, disc_loss = 0.004559868938048129
Trained batch 54 in epoch 2, gen_loss = 1.1242370865561746, disc_loss = 0.00455085647885095
Trained batch 55 in epoch 2, gen_loss = 1.1243829407862254, disc_loss = 0.00456866662716493
Trained batch 56 in epoch 2, gen_loss = 1.122084037253731, disc_loss = 0.004618256181282432
Trained batch 57 in epoch 2, gen_loss = 1.1223576140814815, disc_loss = 0.004682039095345756
Trained batch 58 in epoch 2, gen_loss = 1.1217248995425337, disc_loss = 0.004744779942083662
Trained batch 59 in epoch 2, gen_loss = 1.1221169124046961, disc_loss = 0.004742025894423326
Trained batch 60 in epoch 2, gen_loss = 1.1210547675851916, disc_loss = 0.004727448966567878
Trained batch 61 in epoch 2, gen_loss = 1.121781111724915, disc_loss = 0.00471106275255161
Trained batch 62 in epoch 2, gen_loss = 1.1215852792300876, disc_loss = 0.004702614339452888
Trained batch 63 in epoch 2, gen_loss = 1.1203375710174441, disc_loss = 0.0047171247424557805
Trained batch 64 in epoch 2, gen_loss = 1.12037865290275, disc_loss = 0.004683065156523998
Trained batch 65 in epoch 2, gen_loss = 1.12168811397119, disc_loss = 0.004748893873483846
Trained batch 66 in epoch 2, gen_loss = 1.1189765681081743, disc_loss = 0.004784434880894512
Trained batch 67 in epoch 2, gen_loss = 1.1181846751886255, disc_loss = 0.004839956281049287
Trained batch 68 in epoch 2, gen_loss = 1.1167472929194353, disc_loss = 0.004903591993818249
Trained batch 69 in epoch 2, gen_loss = 1.1184169377599444, disc_loss = 0.005018085254622357
Trained batch 70 in epoch 2, gen_loss = 1.1144631815628268, disc_loss = 0.005223214849304985
Trained batch 71 in epoch 2, gen_loss = 1.1139669997824564, disc_loss = 0.0055036330724962884
Trained batch 72 in epoch 2, gen_loss = 1.1101291922673786, disc_loss = 0.006045193513472603
Trained batch 73 in epoch 2, gen_loss = 1.1171024675304826, disc_loss = 0.007436827844562563
Trained batch 74 in epoch 2, gen_loss = 1.1139646593729655, disc_loss = 0.007802596303323904
Trained batch 75 in epoch 2, gen_loss = 1.1105870628043224, disc_loss = 0.008850352556787823
Trained batch 76 in epoch 2, gen_loss = 1.1029534177346663, disc_loss = 0.011244923662539427
Trained batch 77 in epoch 2, gen_loss = 1.106122375298769, disc_loss = 0.014202124618280392
Trained batch 78 in epoch 2, gen_loss = 1.1082515573199792, disc_loss = 0.015104851025286355
Trained batch 79 in epoch 2, gen_loss = 1.1056043282151222, disc_loss = 0.015310367767233402
Trained batch 80 in epoch 2, gen_loss = 1.101109418604109, disc_loss = 0.015582378965193107
Trained batch 81 in epoch 2, gen_loss = 1.0997693044383352, disc_loss = 0.015634976838510936
Trained batch 82 in epoch 2, gen_loss = 1.0989365951124443, disc_loss = 0.015577874931854656
Trained batch 83 in epoch 2, gen_loss = 1.0987947583198547, disc_loss = 0.015480778545939497
Trained batch 84 in epoch 2, gen_loss = 1.0987815029480879, disc_loss = 0.015396374168203157
Trained batch 85 in epoch 2, gen_loss = 1.0981478843578072, disc_loss = 0.01530195458597222
Trained batch 86 in epoch 2, gen_loss = 1.0970922653702484, disc_loss = 0.015191278773648986
Trained batch 87 in epoch 2, gen_loss = 1.0962742431597277, disc_loss = 0.015078463401137427
Trained batch 88 in epoch 2, gen_loss = 1.095769793799754, disc_loss = 0.01496101382680321
Trained batch 89 in epoch 2, gen_loss = 1.0952852328618368, disc_loss = 0.014851732650357816
Trained batch 90 in epoch 2, gen_loss = 1.0951381476370843, disc_loss = 0.0147460983390664
Trained batch 91 in epoch 2, gen_loss = 1.0940691511268201, disc_loss = 0.014638798741583267
Trained batch 92 in epoch 2, gen_loss = 1.093033757901961, disc_loss = 0.014550669869828609
Trained batch 93 in epoch 2, gen_loss = 1.092313361294726, disc_loss = 0.014508696263061558
Trained batch 94 in epoch 2, gen_loss = 1.0924505641585902, disc_loss = 0.014435904301506909
Trained batch 95 in epoch 2, gen_loss = 1.0922518155227106, disc_loss = 0.014331378125158759
Trained batch 96 in epoch 2, gen_loss = 1.0912689032013883, disc_loss = 0.014224524892981826
Trained batch 97 in epoch 2, gen_loss = 1.0905444768010353, disc_loss = 0.014130669821775993
Trained batch 98 in epoch 2, gen_loss = 1.09018754838693, disc_loss = 0.01402867209599024
Trained batch 99 in epoch 2, gen_loss = 1.0902922058105469, disc_loss = 0.013940920284949244
Trained batch 100 in epoch 2, gen_loss = 1.0898300633572116, disc_loss = 0.013838533279808735
Trained batch 101 in epoch 2, gen_loss = 1.088759687016992, disc_loss = 0.013745960108387996
Trained batch 102 in epoch 2, gen_loss = 1.087829900598063, disc_loss = 0.013657228600740144
Trained batch 103 in epoch 2, gen_loss = 1.0874003280813878, disc_loss = 0.01355849748226599
Trained batch 104 in epoch 2, gen_loss = 1.087276306038811, disc_loss = 0.013462000196090057
Trained batch 105 in epoch 2, gen_loss = 1.0871268201549098, disc_loss = 0.01336926711231189
Trained batch 106 in epoch 2, gen_loss = 1.086278066456875, disc_loss = 0.013277634869495007
Trained batch 107 in epoch 2, gen_loss = 1.0855572466497068, disc_loss = 0.013180868829497032
Trained batch 108 in epoch 2, gen_loss = 1.085228713280564, disc_loss = 0.013085882510528515
Trained batch 109 in epoch 2, gen_loss = 1.0849891131574458, disc_loss = 0.012995788186195898
Trained batch 110 in epoch 2, gen_loss = 1.0847770566338892, disc_loss = 0.012911335491734717
Trained batch 111 in epoch 2, gen_loss = 1.0847121242965971, disc_loss = 0.012834324416222185
Trained batch 112 in epoch 2, gen_loss = 1.0839226525441734, disc_loss = 0.012755570242972632
Trained batch 113 in epoch 2, gen_loss = 1.083666430753574, disc_loss = 0.012670515807704967
Trained batch 114 in epoch 2, gen_loss = 1.083412724474202, disc_loss = 0.012597979532311792
Trained batch 115 in epoch 2, gen_loss = 1.0830594737981927, disc_loss = 0.012527638909824449
Trained batch 116 in epoch 2, gen_loss = 1.0820663367581165, disc_loss = 0.01246924358459874
Trained batch 117 in epoch 2, gen_loss = 1.0824687940589452, disc_loss = 0.012414285534266697
Trained batch 118 in epoch 2, gen_loss = 1.0820738773386018, disc_loss = 0.012347193031783114
Trained batch 119 in epoch 2, gen_loss = 1.0818341945608456, disc_loss = 0.012269221999061605
Trained batch 120 in epoch 2, gen_loss = 1.0812542423729068, disc_loss = 0.012209981187316012
Trained batch 121 in epoch 2, gen_loss = 1.0805046099131224, disc_loss = 0.012173583898998674
Trained batch 122 in epoch 2, gen_loss = 1.0811526174467754, disc_loss = 0.012111587748991522
Trained batch 123 in epoch 2, gen_loss = 1.0813847924432447, disc_loss = 0.012068181152215167
Trained batch 124 in epoch 2, gen_loss = 1.0804650077819824, disc_loss = 0.0120352814309299
Trained batch 125 in epoch 2, gen_loss = 1.0801668933459692, disc_loss = 0.011998526903519791
Trained batch 126 in epoch 2, gen_loss = 1.0804056623789269, disc_loss = 0.011941830191291927
Trained batch 127 in epoch 2, gen_loss = 1.0802013697102666, disc_loss = 0.011871801569213858
Trained batch 128 in epoch 2, gen_loss = 1.079860767652822, disc_loss = 0.01180768682253222
Trained batch 129 in epoch 2, gen_loss = 1.079897535764254, disc_loss = 0.011741475391989718
Trained batch 130 in epoch 2, gen_loss = 1.0791868453717415, disc_loss = 0.011678983901719783
Trained batch 131 in epoch 2, gen_loss = 1.0795306725935503, disc_loss = 0.011613872759467498
Trained batch 132 in epoch 2, gen_loss = 1.0795742640817971, disc_loss = 0.011570473040517112
Trained batch 133 in epoch 2, gen_loss = 1.0789314472853249, disc_loss = 0.011539951279592602
Trained batch 134 in epoch 2, gen_loss = 1.078702108948319, disc_loss = 0.011497119620994286
Trained batch 135 in epoch 2, gen_loss = 1.078281143132378, disc_loss = 0.011437050664372853
Trained batch 136 in epoch 2, gen_loss = 1.078105366142997, disc_loss = 0.011379854044924578
Trained batch 137 in epoch 2, gen_loss = 1.0779583670090938, disc_loss = 0.011317236411412234
Trained batch 138 in epoch 2, gen_loss = 1.0775826526202743, disc_loss = 0.01125498252867205
Trained batch 139 in epoch 2, gen_loss = 1.0777038191046033, disc_loss = 0.011194652563426643
Trained batch 140 in epoch 2, gen_loss = 1.0776523791306407, disc_loss = 0.011235162145160932
Trained batch 141 in epoch 2, gen_loss = 1.075892384623138, disc_loss = 0.011274787182526164
Trained batch 142 in epoch 2, gen_loss = 1.0753637643960805, disc_loss = 0.011259080163183641
Trained batch 143 in epoch 2, gen_loss = 1.0756986141204834, disc_loss = 0.011227256212603405
Trained batch 144 in epoch 2, gen_loss = 1.0750627945209372, disc_loss = 0.011205555962655565
Trained batch 145 in epoch 2, gen_loss = 1.0750614265873009, disc_loss = 0.011181955099782
Trained batch 146 in epoch 2, gen_loss = 1.0751481380592398, disc_loss = 0.011174766323054018
Trained batch 147 in epoch 2, gen_loss = 1.0743049870471697, disc_loss = 0.011152282195178338
Trained batch 148 in epoch 2, gen_loss = 1.075239762763849, disc_loss = 0.011132345030134256
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.033244013786316, disc_loss = 0.003920495044440031
Trained batch 1 in epoch 3, gen_loss = 1.0163128972053528, disc_loss = 0.004056128207594156
Trained batch 2 in epoch 3, gen_loss = 1.0429612000783284, disc_loss = 0.004279363434761763
Trained batch 3 in epoch 3, gen_loss = 1.0262204557657242, disc_loss = 0.004305695532821119
Trained batch 4 in epoch 3, gen_loss = 1.0395427346229553, disc_loss = 0.004136377014219761
Trained batch 5 in epoch 3, gen_loss = 1.0375549892584484, disc_loss = 0.004109545998896162
Trained batch 6 in epoch 3, gen_loss = 1.034190833568573, disc_loss = 0.0040629116951354915
Trained batch 7 in epoch 3, gen_loss = 1.035073347389698, disc_loss = 0.004026612004963681
Trained batch 8 in epoch 3, gen_loss = 1.027513066927592, disc_loss = 0.004047063722585638
Trained batch 9 in epoch 3, gen_loss = 1.0451331377029418, disc_loss = 0.004169919365085662
Trained batch 10 in epoch 3, gen_loss = 1.044346029108221, disc_loss = 0.004044762727889148
Trained batch 11 in epoch 3, gen_loss = 1.0474411348501842, disc_loss = 0.003958801312061648
Trained batch 12 in epoch 3, gen_loss = 1.045219925733713, disc_loss = 0.0038702375291345213
Trained batch 13 in epoch 3, gen_loss = 1.0394002965518407, disc_loss = 0.003935274318791926
Trained batch 14 in epoch 3, gen_loss = 1.043926231066386, disc_loss = 0.003933928643042843
Trained batch 15 in epoch 3, gen_loss = 1.039209995418787, disc_loss = 0.003962498667533509
Trained batch 16 in epoch 3, gen_loss = 1.0482058700393229, disc_loss = 0.004025626311297803
Trained batch 17 in epoch 3, gen_loss = 1.047569947110282, disc_loss = 0.003949137145860327
Trained batch 18 in epoch 3, gen_loss = 1.0459225585586147, disc_loss = 0.003936835319588059
Trained batch 19 in epoch 3, gen_loss = 1.0468747287988662, disc_loss = 0.00402227914892137
Trained batch 20 in epoch 3, gen_loss = 1.0442511609622411, disc_loss = 0.00395557393009464
Trained batch 21 in epoch 3, gen_loss = 1.0460861189798876, disc_loss = 0.003915868593718518
Trained batch 22 in epoch 3, gen_loss = 1.0457515016846035, disc_loss = 0.0038405988243934903
Trained batch 23 in epoch 3, gen_loss = 1.045934168001016, disc_loss = 0.003780496607456977
Trained batch 24 in epoch 3, gen_loss = 1.0439608263969422, disc_loss = 0.0037487930711358787
Trained batch 25 in epoch 3, gen_loss = 1.0473456451526055, disc_loss = 0.004419930628500879
Trained batch 26 in epoch 3, gen_loss = 1.0315116003707603, disc_loss = 0.006033573497983592
Trained batch 27 in epoch 3, gen_loss = 1.045683633003916, disc_loss = 0.006586172210518271
Trained batch 28 in epoch 3, gen_loss = 1.0539106480006515, disc_loss = 0.006741762088997097
Trained batch 29 in epoch 3, gen_loss = 1.0526197294394175, disc_loss = 0.006685552520987888
Trained batch 30 in epoch 3, gen_loss = 1.0493587774615134, disc_loss = 0.00664326268428516
Trained batch 31 in epoch 3, gen_loss = 1.0466865710914135, disc_loss = 0.006663872794888448
Trained batch 32 in epoch 3, gen_loss = 1.0458705100146206, disc_loss = 0.0066062605615253706
Trained batch 33 in epoch 3, gen_loss = 1.0474247967495638, disc_loss = 0.006507681977168164
Trained batch 34 in epoch 3, gen_loss = 1.0493010010038104, disc_loss = 0.006418984323473913
Trained batch 35 in epoch 3, gen_loss = 1.0475412723090913, disc_loss = 0.00634868770915394
Trained batch 36 in epoch 3, gen_loss = 1.0457030083682086, disc_loss = 0.0062812468905404616
Trained batch 37 in epoch 3, gen_loss = 1.0454541413407576, disc_loss = 0.006182031540543233
Trained batch 38 in epoch 3, gen_loss = 1.044980920278109, disc_loss = 0.006087971797499519
Trained batch 39 in epoch 3, gen_loss = 1.0441298723220824, disc_loss = 0.005985984147991985
Trained batch 40 in epoch 3, gen_loss = 1.0449928452328938, disc_loss = 0.00591198333947942
Trained batch 41 in epoch 3, gen_loss = 1.042639428660983, disc_loss = 0.005854890376905955
Trained batch 42 in epoch 3, gen_loss = 1.0433314733727033, disc_loss = 0.0057867693032549565
Trained batch 43 in epoch 3, gen_loss = 1.0433062396266244, disc_loss = 0.005700026554140178
Trained batch 44 in epoch 3, gen_loss = 1.042422933048672, disc_loss = 0.005652932496741414
Trained batch 45 in epoch 3, gen_loss = 1.0421489399412405, disc_loss = 0.005679685627515225
Trained batch 46 in epoch 3, gen_loss = 1.0384500457885417, disc_loss = 0.005769655093590313
Trained batch 47 in epoch 3, gen_loss = 1.040835402905941, disc_loss = 0.005761118921024415
Trained batch 48 in epoch 3, gen_loss = 1.0427514363308341, disc_loss = 0.005726473477231909
Trained batch 49 in epoch 3, gen_loss = 1.0425422596931457, disc_loss = 0.005666677923873067
Trained batch 50 in epoch 3, gen_loss = 1.0402103814424253, disc_loss = 0.005625069899228858
Trained batch 51 in epoch 3, gen_loss = 1.040640387397546, disc_loss = 0.005561542567402984
Trained batch 52 in epoch 3, gen_loss = 1.040934534567707, disc_loss = 0.005581908143248479
Trained batch 53 in epoch 3, gen_loss = 1.0388583651295415, disc_loss = 0.005564135727817538
Trained batch 54 in epoch 3, gen_loss = 1.0387912750244142, disc_loss = 0.005514885540204969
Trained batch 55 in epoch 3, gen_loss = 1.0389162238155092, disc_loss = 0.005469570905136477
Trained batch 56 in epoch 3, gen_loss = 1.0373220098646063, disc_loss = 0.005415192147586168
Trained batch 57 in epoch 3, gen_loss = 1.037845442007328, disc_loss = 0.0053842171087283
Trained batch 58 in epoch 3, gen_loss = 1.037100374698639, disc_loss = 0.005342474400649889
Trained batch 59 in epoch 3, gen_loss = 1.037868888179461, disc_loss = 0.0052985715252968175
Trained batch 60 in epoch 3, gen_loss = 1.037360665250997, disc_loss = 0.0052515058205692
Trained batch 61 in epoch 3, gen_loss = 1.0364687269733799, disc_loss = 0.005218623645393358
Trained batch 62 in epoch 3, gen_loss = 1.0353584980207777, disc_loss = 0.005186709664052441
Trained batch 63 in epoch 3, gen_loss = 1.036465303041041, disc_loss = 0.005173480254597962
Trained batch 64 in epoch 3, gen_loss = 1.0363647580146789, disc_loss = 0.005146201965040885
Trained batch 65 in epoch 3, gen_loss = 1.0347629668134632, disc_loss = 0.005107030748728324
Trained batch 66 in epoch 3, gen_loss = 1.0347708935168252, disc_loss = 0.005081806251946003
Trained batch 67 in epoch 3, gen_loss = 1.034692737109521, disc_loss = 0.005049996920313467
Trained batch 68 in epoch 3, gen_loss = 1.0337639995243237, disc_loss = 0.005021578288110702
Trained batch 69 in epoch 3, gen_loss = 1.0339944652148656, disc_loss = 0.004994606230008815
Trained batch 70 in epoch 3, gen_loss = 1.0338317877809766, disc_loss = 0.004962632081694376
Trained batch 71 in epoch 3, gen_loss = 1.033872092763583, disc_loss = 0.004924082413910785
Trained batch 72 in epoch 3, gen_loss = 1.03370328798686, disc_loss = 0.004884077274329858
Trained batch 73 in epoch 3, gen_loss = 1.0330360547916309, disc_loss = 0.004845013143494725
Trained batch 74 in epoch 3, gen_loss = 1.032629106839498, disc_loss = 0.0048080356574306884
Trained batch 75 in epoch 3, gen_loss = 1.031953563815669, disc_loss = 0.0047703315488577475
Trained batch 76 in epoch 3, gen_loss = 1.0311222246715002, disc_loss = 0.004736997693619848
Trained batch 77 in epoch 3, gen_loss = 1.0310221589528596, disc_loss = 0.004700492579454126
Trained batch 78 in epoch 3, gen_loss = 1.031015382537359, disc_loss = 0.004669676365366182
Trained batch 79 in epoch 3, gen_loss = 1.031170156598091, disc_loss = 0.004660011712985579
Trained batch 80 in epoch 3, gen_loss = 1.0287966065936618, disc_loss = 0.004702265812716458
Trained batch 81 in epoch 3, gen_loss = 1.0286886037849798, disc_loss = 0.004701268360893265
Trained batch 82 in epoch 3, gen_loss = 1.029124163719545, disc_loss = 0.00467996344851128
Trained batch 83 in epoch 3, gen_loss = 1.0286535826467333, disc_loss = 0.004651377932445723
Trained batch 84 in epoch 3, gen_loss = 1.0283154073883505, disc_loss = 0.004626371304723708
Trained batch 85 in epoch 3, gen_loss = 1.0285803363766781, disc_loss = 0.004602416000209835
Trained batch 86 in epoch 3, gen_loss = 1.0282171005490182, disc_loss = 0.004573883187700191
Trained batch 87 in epoch 3, gen_loss = 1.0285665623166345, disc_loss = 0.004571447068222121
Trained batch 88 in epoch 3, gen_loss = 1.0261024357227797, disc_loss = 0.004628834956890663
Trained batch 89 in epoch 3, gen_loss = 1.0280153685145907, disc_loss = 0.004668926120373524
Trained batch 90 in epoch 3, gen_loss = 1.0284022014219683, disc_loss = 0.004646217809979814
Trained batch 91 in epoch 3, gen_loss = 1.0274201391831688, disc_loss = 0.004662232581050257
Trained batch 92 in epoch 3, gen_loss = 1.0258860722664864, disc_loss = 0.004680573726223121
Trained batch 93 in epoch 3, gen_loss = 1.0259215812733833, disc_loss = 0.004666652962654591
Trained batch 94 in epoch 3, gen_loss = 1.0260206768387243, disc_loss = 0.004663307348413295
Trained batch 95 in epoch 3, gen_loss = 1.02568096977969, disc_loss = 0.004642358206183417
Trained batch 96 in epoch 3, gen_loss = 1.02460190684525, disc_loss = 0.004623438160837695
Trained batch 97 in epoch 3, gen_loss = 1.0249551169726314, disc_loss = 0.0046139924504262
Trained batch 98 in epoch 3, gen_loss = 1.0242535917445867, disc_loss = 0.004592023052585621
Trained batch 99 in epoch 3, gen_loss = 1.024004606604576, disc_loss = 0.0045647733192890885
Trained batch 100 in epoch 3, gen_loss = 1.0232793848113257, disc_loss = 0.004550664441309648
Trained batch 101 in epoch 3, gen_loss = 1.0231115397285013, disc_loss = 0.004524962824778449
Trained batch 102 in epoch 3, gen_loss = 1.0234592771067204, disc_loss = 0.004500311368723735
Trained batch 103 in epoch 3, gen_loss = 1.022903483074445, disc_loss = 0.0044835041794263255
Trained batch 104 in epoch 3, gen_loss = 1.0223955040886288, disc_loss = 0.0044602794605972515
Trained batch 105 in epoch 3, gen_loss = 1.0221838478772145, disc_loss = 0.0044349380043985425
Trained batch 106 in epoch 3, gen_loss = 1.0225445656018837, disc_loss = 0.0044247425165654065
Trained batch 107 in epoch 3, gen_loss = 1.0216743145827893, disc_loss = 0.004408557690179872
Trained batch 108 in epoch 3, gen_loss = 1.0212696506342758, disc_loss = 0.0043864492796908275
Trained batch 109 in epoch 3, gen_loss = 1.0218131910670887, disc_loss = 0.004374357200735672
Trained batch 110 in epoch 3, gen_loss = 1.021078466832101, disc_loss = 0.004501327996033135
Trained batch 111 in epoch 3, gen_loss = 1.0167732137654508, disc_loss = 0.004795888262119011
Trained batch 112 in epoch 3, gen_loss = 1.0181005143486292, disc_loss = 0.006978356293855911
Trained batch 113 in epoch 3, gen_loss = 1.0134300043185551, disc_loss = 0.007751604205144471
Trained batch 114 in epoch 3, gen_loss = 1.0144379468067832, disc_loss = 0.011015910969075301
Trained batch 115 in epoch 3, gen_loss = 1.013677128173154, disc_loss = 0.014642564666152385
Trained batch 116 in epoch 3, gen_loss = 1.0069987061950896, disc_loss = 0.017248852662025735
Trained batch 117 in epoch 3, gen_loss = 1.00419678943137, disc_loss = 0.019537523663129216
Trained batch 118 in epoch 3, gen_loss = 1.0019314550802487, disc_loss = 0.021164918292955567
Trained batch 119 in epoch 3, gen_loss = 0.9968043398112059, disc_loss = 0.022178726043784992
Trained batch 120 in epoch 3, gen_loss = 0.9916422471773526, disc_loss = 0.023030679478610226
Trained batch 121 in epoch 3, gen_loss = 0.9874938297711435, disc_loss = 0.02360102560821554
Trained batch 122 in epoch 3, gen_loss = 0.9843083810273224, disc_loss = 0.024047760601435614
Trained batch 123 in epoch 3, gen_loss = 0.9807620323713748, disc_loss = 0.024359888507939513
Trained batch 124 in epoch 3, gen_loss = 0.9792060757875443, disc_loss = 0.024517847439274192
Trained batch 125 in epoch 3, gen_loss = 0.9771854320452327, disc_loss = 0.02460534396647875
Trained batch 126 in epoch 3, gen_loss = 0.976952925089776, disc_loss = 0.0247929893694378
Trained batch 127 in epoch 3, gen_loss = 0.9740617672214285, disc_loss = 0.02549838777304103
Trained batch 128 in epoch 3, gen_loss = 0.977841507210288, disc_loss = 0.02695468000800515
Trained batch 129 in epoch 3, gen_loss = 0.9738515437795565, disc_loss = 0.028199641540861475
Trained batch 130 in epoch 3, gen_loss = 0.9728094913804805, disc_loss = 0.02876959174324026
Trained batch 131 in epoch 3, gen_loss = 0.9699229504348654, disc_loss = 0.028908595800837218
Trained batch 132 in epoch 3, gen_loss = 0.9680199503226388, disc_loss = 0.02889619633744478
Trained batch 133 in epoch 3, gen_loss = 0.9674050444320067, disc_loss = 0.028801971036982513
Trained batch 134 in epoch 3, gen_loss = 0.9667423607022674, disc_loss = 0.02869393886756842
Trained batch 135 in epoch 3, gen_loss = 0.9657166009659276, disc_loss = 0.028585614032207933
Trained batch 136 in epoch 3, gen_loss = 0.9656843639855838, disc_loss = 0.02849311065982456
Trained batch 137 in epoch 3, gen_loss = 0.9644761583295421, disc_loss = 0.028388912214195705
Trained batch 138 in epoch 3, gen_loss = 0.9642955824839983, disc_loss = 0.028270638914671627
Trained batch 139 in epoch 3, gen_loss = 0.9644781973745141, disc_loss = 0.02812955262239224
Trained batch 140 in epoch 3, gen_loss = 0.9647315733187588, disc_loss = 0.027980786178538455
Trained batch 141 in epoch 3, gen_loss = 0.9643776661283533, disc_loss = 0.02783575737816085
Trained batch 142 in epoch 3, gen_loss = 0.9640859078902465, disc_loss = 0.027685750847343694
Trained batch 143 in epoch 3, gen_loss = 0.9642014814954665, disc_loss = 0.027548221054732695
Trained batch 144 in epoch 3, gen_loss = 0.9643844256113315, disc_loss = 0.02751866180674526
Trained batch 145 in epoch 3, gen_loss = 0.9626017446591429, disc_loss = 0.02746534630598832
Trained batch 146 in epoch 3, gen_loss = 0.9622790413040693, disc_loss = 0.02736376937903261
Trained batch 147 in epoch 3, gen_loss = 0.9636526483337622, disc_loss = 0.027283314846745517
Trained batch 148 in epoch 3, gen_loss = 0.9638864699026082, disc_loss = 0.02715527310486158
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.8374756574630737, disc_loss = 0.009142443537712097
Trained batch 1 in epoch 4, gen_loss = 0.8611962795257568, disc_loss = 0.0075103216804564
Trained batch 2 in epoch 4, gen_loss = 0.9121255079905192, disc_loss = 0.009874221868813038
Trained batch 3 in epoch 4, gen_loss = 0.9161924123764038, disc_loss = 0.009380317060276866
Trained batch 4 in epoch 4, gen_loss = 0.907919991016388, disc_loss = 0.009012908674776554
Trained batch 5 in epoch 4, gen_loss = 0.9228674272696177, disc_loss = 0.008435637379686037
Trained batch 6 in epoch 4, gen_loss = 0.944716853754861, disc_loss = 0.008526268814291273
Trained batch 7 in epoch 4, gen_loss = 0.9373321384191513, disc_loss = 0.00817825976992026
Trained batch 8 in epoch 4, gen_loss = 0.9290766782230802, disc_loss = 0.007916010657532347
Trained batch 9 in epoch 4, gen_loss = 0.9349650859832763, disc_loss = 0.007901152921840548
Trained batch 10 in epoch 4, gen_loss = 0.9374975128607317, disc_loss = 0.007631692485037175
Trained batch 11 in epoch 4, gen_loss = 0.938712865114212, disc_loss = 0.007349942539197703
Trained batch 12 in epoch 4, gen_loss = 0.9460860399099497, disc_loss = 0.007263640694033641
Trained batch 13 in epoch 4, gen_loss = 0.9427510797977448, disc_loss = 0.007153185250769768
Trained batch 14 in epoch 4, gen_loss = 0.9473954558372497, disc_loss = 0.0070103272485236325
Trained batch 15 in epoch 4, gen_loss = 0.9453667514026165, disc_loss = 0.006923294422449544
Trained batch 16 in epoch 4, gen_loss = 0.9460883000317741, disc_loss = 0.006874685093541355
Trained batch 17 in epoch 4, gen_loss = 0.9507135815090604, disc_loss = 0.007099882052797411
Trained batch 18 in epoch 4, gen_loss = 0.9407461097365931, disc_loss = 0.007932502947943775
Trained batch 19 in epoch 4, gen_loss = 0.9484567195177078, disc_loss = 0.008151566772721709
Trained batch 20 in epoch 4, gen_loss = 0.9528109885397411, disc_loss = 0.00813190040311643
Trained batch 21 in epoch 4, gen_loss = 0.9547766772183505, disc_loss = 0.008118724916130304
Trained batch 22 in epoch 4, gen_loss = 0.9521695349527441, disc_loss = 0.008263993967810402
Trained batch 23 in epoch 4, gen_loss = 0.957512341439724, disc_loss = 0.008208141778595746
Trained batch 24 in epoch 4, gen_loss = 0.9615720200538636, disc_loss = 0.008127077389508486
Trained batch 25 in epoch 4, gen_loss = 0.9608374283863947, disc_loss = 0.008082838191722449
Trained batch 26 in epoch 4, gen_loss = 0.961879672827544, disc_loss = 0.007961553659428048
Trained batch 27 in epoch 4, gen_loss = 0.9654525518417358, disc_loss = 0.007934784782784325
Trained batch 28 in epoch 4, gen_loss = 0.9638298379963842, disc_loss = 0.00787594042525723
Trained batch 29 in epoch 4, gen_loss = 0.9668525020281474, disc_loss = 0.007749349266911547
Trained batch 30 in epoch 4, gen_loss = 0.9702845658025434, disc_loss = 0.007631005133472143
Trained batch 31 in epoch 4, gen_loss = 0.9721846766769886, disc_loss = 0.007784823726979084
Trained batch 32 in epoch 4, gen_loss = 0.9676545822259152, disc_loss = 0.007932751651175997
Trained batch 33 in epoch 4, gen_loss = 0.9721506132799036, disc_loss = 0.007849284132723422
Trained batch 34 in epoch 4, gen_loss = 0.9768679993493217, disc_loss = 0.007812877172338112
Trained batch 35 in epoch 4, gen_loss = 0.9771543277634515, disc_loss = 0.00776550583800094
Trained batch 36 in epoch 4, gen_loss = 0.9757876202866838, disc_loss = 0.00803554557716927
Trained batch 37 in epoch 4, gen_loss = 0.9740594343135232, disc_loss = 0.008348975489896378
Trained batch 38 in epoch 4, gen_loss = 0.9777507384618124, disc_loss = 0.008427436021753611
Trained batch 39 in epoch 4, gen_loss = 0.9841782003641129, disc_loss = 0.00853236709954217
Trained batch 40 in epoch 4, gen_loss = 0.9841969245817603, disc_loss = 0.008465375353741209
Trained batch 41 in epoch 4, gen_loss = 0.9834754850183215, disc_loss = 0.008367026790178247
Trained batch 42 in epoch 4, gen_loss = 0.9847827914149262, disc_loss = 0.008243400798460771
Trained batch 43 in epoch 4, gen_loss = 0.9870033033869483, disc_loss = 0.008132831405170939
Trained batch 44 in epoch 4, gen_loss = 0.9888687941763136, disc_loss = 0.008048418040076891
Trained batch 45 in epoch 4, gen_loss = 0.9879371925540592, disc_loss = 0.007987474091351032
Trained batch 46 in epoch 4, gen_loss = 0.9871662715648083, disc_loss = 0.007935671165506256
Trained batch 47 in epoch 4, gen_loss = 0.9907881307105223, disc_loss = 0.007887671682207534
Trained batch 48 in epoch 4, gen_loss = 0.9924967593076278, disc_loss = 0.007844635893647768
Trained batch 49 in epoch 4, gen_loss = 0.9904867613315582, disc_loss = 0.007901271898299455
Trained batch 50 in epoch 4, gen_loss = 0.9933429173394746, disc_loss = 0.00798291616214841
Trained batch 51 in epoch 4, gen_loss = 0.9931911791746433, disc_loss = 0.007923590305906076
Trained batch 52 in epoch 4, gen_loss = 0.9915030474932689, disc_loss = 0.00796391358071903
Trained batch 53 in epoch 4, gen_loss = 0.9947170968408938, disc_loss = 0.007911327157031607
Trained batch 54 in epoch 4, gen_loss = 0.9963271791284735, disc_loss = 0.007848517122593794
Trained batch 55 in epoch 4, gen_loss = 0.9955643106784139, disc_loss = 0.007797249775779035
Trained batch 56 in epoch 4, gen_loss = 0.9948521486499853, disc_loss = 0.007730324090899606
Trained batch 57 in epoch 4, gen_loss = 0.9956760601750736, disc_loss = 0.007654667205723195
Trained batch 58 in epoch 4, gen_loss = 0.9970013256800376, disc_loss = 0.007582716635917708
Trained batch 59 in epoch 4, gen_loss = 0.9983431110779445, disc_loss = 0.00751563572169592
Trained batch 60 in epoch 4, gen_loss = 0.9996221387972597, disc_loss = 0.0074557265892746995
Trained batch 61 in epoch 4, gen_loss = 0.9992063910730423, disc_loss = 0.007428520997505515
Trained batch 62 in epoch 4, gen_loss = 1.000031902676537, disc_loss = 0.007396333961791936
Trained batch 63 in epoch 4, gen_loss = 1.0008148942142725, disc_loss = 0.007394242238660809
Trained batch 64 in epoch 4, gen_loss = 0.9987585975573613, disc_loss = 0.007396905618504836
Trained batch 65 in epoch 4, gen_loss = 1.001171252041152, disc_loss = 0.007426817259384376
Trained batch 66 in epoch 4, gen_loss = 1.0002598148673327, disc_loss = 0.007464187977307323
Trained batch 67 in epoch 4, gen_loss = 1.0024225071949118, disc_loss = 0.007450632812619647
Trained batch 68 in epoch 4, gen_loss = 1.0031576804492786, disc_loss = 0.007392349450484566
Trained batch 69 in epoch 4, gen_loss = 1.0024370406355176, disc_loss = 0.00734760807827115
Trained batch 70 in epoch 4, gen_loss = 1.0035084796623446, disc_loss = 0.007295822626320829
Trained batch 71 in epoch 4, gen_loss = 1.0042749833729532, disc_loss = 0.007355660698117895
Trained batch 72 in epoch 4, gen_loss = 1.0011914666384867, disc_loss = 0.007528342848822271
Trained batch 73 in epoch 4, gen_loss = 1.0041545395915572, disc_loss = 0.0075395664489651855
Trained batch 74 in epoch 4, gen_loss = 1.0056018169720968, disc_loss = 0.007507575967659553
Trained batch 75 in epoch 4, gen_loss = 1.0045623630285263, disc_loss = 0.0074943735227478965
Trained batch 76 in epoch 4, gen_loss = 1.0041325301318973, disc_loss = 0.007436599540100856
Trained batch 77 in epoch 4, gen_loss = 1.0049232267416441, disc_loss = 0.007377762729540849
Trained batch 78 in epoch 4, gen_loss = 1.0055022865911074, disc_loss = 0.007314483081049557
Trained batch 79 in epoch 4, gen_loss = 1.0052652589976787, disc_loss = 0.007254650577669964
Trained batch 80 in epoch 4, gen_loss = 1.0051281915770636, disc_loss = 0.007192839816626575
Trained batch 81 in epoch 4, gen_loss = 1.005947677827463, disc_loss = 0.007140058013269814
Trained batch 82 in epoch 4, gen_loss = 1.0060333394142518, disc_loss = 0.007091258203678103
Trained batch 83 in epoch 4, gen_loss = 1.0066730216855095, disc_loss = 0.007045966866869657
Trained batch 84 in epoch 4, gen_loss = 1.0071539745611302, disc_loss = 0.006996874730376636
Trained batch 85 in epoch 4, gen_loss = 1.0073605713456175, disc_loss = 0.006946317710762107
Trained batch 86 in epoch 4, gen_loss = 1.0081075409363056, disc_loss = 0.006896896137930881
Trained batch 87 in epoch 4, gen_loss = 1.0080125189640305, disc_loss = 0.006849692811639133
Trained batch 88 in epoch 4, gen_loss = 1.0083359754487369, disc_loss = 0.006812017939440655
Trained batch 89 in epoch 4, gen_loss = 1.0082635356320275, disc_loss = 0.0067686861484415
Trained batch 90 in epoch 4, gen_loss = 1.0085671098677667, disc_loss = 0.0067190759492894775
Trained batch 91 in epoch 4, gen_loss = 1.0091603495504544, disc_loss = 0.006671485534120027
Trained batch 92 in epoch 4, gen_loss = 1.010036919065701, disc_loss = 0.006627259122568273
Trained batch 93 in epoch 4, gen_loss = 1.0098533585984657, disc_loss = 0.006931495444076334
Trained batch 94 in epoch 4, gen_loss = 1.0010777238168214, disc_loss = 0.009191470051576433
Trained batch 95 in epoch 4, gen_loss = 1.0110948051636417, disc_loss = 0.012906576164823491
Trained batch 96 in epoch 4, gen_loss = 1.006378526847387, disc_loss = 0.013570381777322631
Trained batch 97 in epoch 4, gen_loss = 1.001515461778154, disc_loss = 0.01416258077488794
Trained batch 98 in epoch 4, gen_loss = 0.9988331761625078, disc_loss = 0.014547574293865549
Trained batch 99 in epoch 4, gen_loss = 0.9966036549210548, disc_loss = 0.014868304512929172
Trained batch 100 in epoch 4, gen_loss = 0.9939067809298487, disc_loss = 0.015004863969446851
Trained batch 101 in epoch 4, gen_loss = 0.9928333773916843, disc_loss = 0.014979392890453193
Trained batch 102 in epoch 4, gen_loss = 0.992310891163002, disc_loss = 0.014913085674035173
Trained batch 103 in epoch 4, gen_loss = 0.9922381911713344, disc_loss = 0.014852681839749074
Trained batch 104 in epoch 4, gen_loss = 0.9911493150960832, disc_loss = 0.014772989385805669
Trained batch 105 in epoch 4, gen_loss = 0.9903821678094145, disc_loss = 0.01485107773871003
Trained batch 106 in epoch 4, gen_loss = 0.987361482649206, disc_loss = 0.014924856736194168
Trained batch 107 in epoch 4, gen_loss = 0.9880599293995787, disc_loss = 0.014894564814986315
Trained batch 108 in epoch 4, gen_loss = 0.9876336736963429, disc_loss = 0.014836764653050982
Trained batch 109 in epoch 4, gen_loss = 0.9870423195036975, disc_loss = 0.014881360791200265
Trained batch 110 in epoch 4, gen_loss = 0.9845389994952056, disc_loss = 0.014909926120208594
Trained batch 111 in epoch 4, gen_loss = 0.9854202491364309, disc_loss = 0.014885629300676686
Trained batch 112 in epoch 4, gen_loss = 0.9847912849050707, disc_loss = 0.01480837806902694
Trained batch 113 in epoch 4, gen_loss = 0.9830969355085439, disc_loss = 0.014741794122464694
Trained batch 114 in epoch 4, gen_loss = 0.9825438895951146, disc_loss = 0.014653865452450903
Trained batch 115 in epoch 4, gen_loss = 0.9824246962008805, disc_loss = 0.014563790030761397
Trained batch 116 in epoch 4, gen_loss = 0.9813001204250206, disc_loss = 0.014477035864534924
Trained batch 117 in epoch 4, gen_loss = 0.9815405271315979, disc_loss = 0.014388581818774721
Trained batch 118 in epoch 4, gen_loss = 0.9810553400957284, disc_loss = 0.014297146735587666
Trained batch 119 in epoch 4, gen_loss = 0.9806404498716196, disc_loss = 0.014228256394077713
Trained batch 120 in epoch 4, gen_loss = 0.978617561011275, disc_loss = 0.014169358357802525
Trained batch 121 in epoch 4, gen_loss = 0.9787497908854094, disc_loss = 0.014087216846538006
Trained batch 122 in epoch 4, gen_loss = 0.9789006450796515, disc_loss = 0.014004155900707938
Trained batch 123 in epoch 4, gen_loss = 0.9783760100122421, disc_loss = 0.013920809463372515
Trained batch 124 in epoch 4, gen_loss = 0.9771699120998383, disc_loss = 0.013843380717560649
Trained batch 125 in epoch 4, gen_loss = 0.9768779133520429, disc_loss = 0.013755457754808641
Trained batch 126 in epoch 4, gen_loss = 0.9762123403117413, disc_loss = 0.013667403425156014
Trained batch 127 in epoch 4, gen_loss = 0.9758020353037864, disc_loss = 0.013584236265160143
Trained batch 128 in epoch 4, gen_loss = 0.975477873585945, disc_loss = 0.013509737053351808
Trained batch 129 in epoch 4, gen_loss = 0.9747655380230683, disc_loss = 0.013431053014042287
Trained batch 130 in epoch 4, gen_loss = 0.9740466118313884, disc_loss = 0.013357344538485276
Trained batch 131 in epoch 4, gen_loss = 0.9744840302702152, disc_loss = 0.013278952274104637
Trained batch 132 in epoch 4, gen_loss = 0.9750021044024848, disc_loss = 0.013211279582316266
Trained batch 133 in epoch 4, gen_loss = 0.9736822338691399, disc_loss = 0.013152976680213391
Trained batch 134 in epoch 4, gen_loss = 0.9728181505644763, disc_loss = 0.01307970869044463
Trained batch 135 in epoch 4, gen_loss = 0.9724444573854699, disc_loss = 0.01300152822274386
Trained batch 136 in epoch 4, gen_loss = 0.9729893549080313, disc_loss = 0.012945277395447458
Trained batch 137 in epoch 4, gen_loss = 0.9718346602242925, disc_loss = 0.0129248998026647
Trained batch 138 in epoch 4, gen_loss = 0.9722034903310186, disc_loss = 0.012863842894410272
Trained batch 139 in epoch 4, gen_loss = 0.9726369693875313, disc_loss = 0.012800242874904402
Trained batch 140 in epoch 4, gen_loss = 0.9723881489418923, disc_loss = 0.013002247770865125
Trained batch 141 in epoch 4, gen_loss = 0.9669779786761378, disc_loss = 0.01383495728590224
Trained batch 142 in epoch 4, gen_loss = 0.9690315252417451, disc_loss = 0.014079231107802867
Trained batch 143 in epoch 4, gen_loss = 0.9694940783083439, disc_loss = 0.014065463344902836
Trained batch 144 in epoch 4, gen_loss = 0.9684982986285768, disc_loss = 0.01402827360314028
Trained batch 145 in epoch 4, gen_loss = 0.9674338392198902, disc_loss = 0.013972151715129819
Trained batch 146 in epoch 4, gen_loss = 0.9674568634454895, disc_loss = 0.01391755469890983
Trained batch 147 in epoch 4, gen_loss = 0.9675237101477545, disc_loss = 0.013859861860731366
Trained batch 148 in epoch 4, gen_loss = 0.967262628094462, disc_loss = 0.01380208031205623
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.918820321559906, disc_loss = 0.003946720622479916
Trained batch 1 in epoch 5, gen_loss = 0.8881793320178986, disc_loss = 0.003785889013670385
Trained batch 2 in epoch 5, gen_loss = 0.9071519573529562, disc_loss = 0.005057518603280187
Trained batch 3 in epoch 5, gen_loss = 0.8960562944412231, disc_loss = 0.005086059391032904
Trained batch 4 in epoch 5, gen_loss = 0.8940998315811157, disc_loss = 0.00473243254236877
Trained batch 5 in epoch 5, gen_loss = 0.9048097431659698, disc_loss = 0.004412142133029799
Trained batch 6 in epoch 5, gen_loss = 0.9242142864636013, disc_loss = 0.004335526576531785
Trained batch 7 in epoch 5, gen_loss = 0.9233704954385757, disc_loss = 0.005874897295143455
Trained batch 8 in epoch 5, gen_loss = 0.9074888229370117, disc_loss = 0.0074951124584509265
Trained batch 9 in epoch 5, gen_loss = 0.9169461131095886, disc_loss = 0.0072061531245708466
Trained batch 10 in epoch 5, gen_loss = 0.9248854572122748, disc_loss = 0.007164658766917207
Trained batch 11 in epoch 5, gen_loss = 0.9205420861641566, disc_loss = 0.007063630890722076
Trained batch 12 in epoch 5, gen_loss = 0.919651026909168, disc_loss = 0.006848158637204995
Trained batch 13 in epoch 5, gen_loss = 0.9316362696034568, disc_loss = 0.00663536527593221
Trained batch 14 in epoch 5, gen_loss = 0.9349692821502685, disc_loss = 0.0064252560492604974
Trained batch 15 in epoch 5, gen_loss = 0.9274157807230949, disc_loss = 0.006499339666333981
Trained batch 16 in epoch 5, gen_loss = 0.9331719805212582, disc_loss = 0.00648947899668094
Trained batch 17 in epoch 5, gen_loss = 0.9311773975690206, disc_loss = 0.006493326987967723
Trained batch 18 in epoch 5, gen_loss = 0.9357743451469823, disc_loss = 0.0064234175400710415
Trained batch 19 in epoch 5, gen_loss = 0.933798810839653, disc_loss = 0.006329968327190727
Trained batch 20 in epoch 5, gen_loss = 0.9385837401662555, disc_loss = 0.006177431427031046
Trained batch 21 in epoch 5, gen_loss = 0.9444669457999143, disc_loss = 0.006022372029044412
Trained batch 22 in epoch 5, gen_loss = 0.9454276302586431, disc_loss = 0.005870744525252477
Trained batch 23 in epoch 5, gen_loss = 0.9458990370233854, disc_loss = 0.005716689823505779
Trained batch 24 in epoch 5, gen_loss = 0.9477077937126159, disc_loss = 0.005603289101272822
Trained batch 25 in epoch 5, gen_loss = 0.9497303114487574, disc_loss = 0.005612792160648566
Trained batch 26 in epoch 5, gen_loss = 0.9465463051089534, disc_loss = 0.005616569374170568
Trained batch 27 in epoch 5, gen_loss = 0.948996976017952, disc_loss = 0.0055693713615515405
Trained batch 28 in epoch 5, gen_loss = 0.9498317221115375, disc_loss = 0.005570830809402055
Trained batch 29 in epoch 5, gen_loss = 0.95340589483579, disc_loss = 0.005596988461911678
Trained batch 30 in epoch 5, gen_loss = 0.9560099397936175, disc_loss = 0.005505905486643314
Trained batch 31 in epoch 5, gen_loss = 0.9579082857817411, disc_loss = 0.005781660933280364
Trained batch 32 in epoch 5, gen_loss = 0.9530346845135544, disc_loss = 0.006027278829027306
Trained batch 33 in epoch 5, gen_loss = 0.9554632008075714, disc_loss = 0.005951847620856236
Trained batch 34 in epoch 5, gen_loss = 0.9592392870358059, disc_loss = 0.005918264934527022
Trained batch 35 in epoch 5, gen_loss = 0.960133969783783, disc_loss = 0.00584790399686123
Trained batch 36 in epoch 5, gen_loss = 0.961327398145521, disc_loss = 0.005823168456806122
Trained batch 37 in epoch 5, gen_loss = 0.9625771014313949, disc_loss = 0.005832651195018307
Trained batch 38 in epoch 5, gen_loss = 0.9628956486017276, disc_loss = 0.005806768390660484
Trained batch 39 in epoch 5, gen_loss = 0.9639908358454704, disc_loss = 0.00572682149359025
Trained batch 40 in epoch 5, gen_loss = 0.9652161205687174, disc_loss = 0.005648508537333549
Trained batch 41 in epoch 5, gen_loss = 0.9653429545107342, disc_loss = 0.005604675976515171
Trained batch 42 in epoch 5, gen_loss = 0.9660121271776598, disc_loss = 0.005608549996734012
Trained batch 43 in epoch 5, gen_loss = 0.9661211412061345, disc_loss = 0.005565436117732051
Trained batch 44 in epoch 5, gen_loss = 0.966207836733924, disc_loss = 0.005508046219539311
Trained batch 45 in epoch 5, gen_loss = 0.9671240410079127, disc_loss = 0.005445633827627677
Trained batch 46 in epoch 5, gen_loss = 0.968665951109947, disc_loss = 0.005416895287666232
Trained batch 47 in epoch 5, gen_loss = 0.9688761954506239, disc_loss = 0.005376974416625065
Trained batch 48 in epoch 5, gen_loss = 0.9695550470936055, disc_loss = 0.005340372150459764
Trained batch 49 in epoch 5, gen_loss = 0.9708863854408264, disc_loss = 0.005343494205735624
Trained batch 50 in epoch 5, gen_loss = 0.9699185116618287, disc_loss = 0.005303894676377668
Trained batch 51 in epoch 5, gen_loss = 0.9705115316005853, disc_loss = 0.005247900620676004
Trained batch 52 in epoch 5, gen_loss = 0.9715793593874518, disc_loss = 0.005230810598663564
Trained batch 53 in epoch 5, gen_loss = 0.9715409565854956, disc_loss = 0.005179014906321687
Trained batch 54 in epoch 5, gen_loss = 0.9726149732416326, disc_loss = 0.005140322366390716
Trained batch 55 in epoch 5, gen_loss = 0.9735093797956195, disc_loss = 0.005099115573102608
Trained batch 56 in epoch 5, gen_loss = 0.9748208836505288, disc_loss = 0.005057207627319976
Trained batch 57 in epoch 5, gen_loss = 0.9756422659446453, disc_loss = 0.005003998325013652
Trained batch 58 in epoch 5, gen_loss = 0.9759185728380235, disc_loss = 0.004970823900016435
Trained batch 59 in epoch 5, gen_loss = 0.9755447149276734, disc_loss = 0.004940532819212725
Trained batch 60 in epoch 5, gen_loss = 0.9772187647272329, disc_loss = 0.004893309784076008
Trained batch 61 in epoch 5, gen_loss = 0.9783888786069809, disc_loss = 0.0049956147221007175
Trained batch 62 in epoch 5, gen_loss = 0.976185072982122, disc_loss = 0.005083150226652386
Trained batch 63 in epoch 5, gen_loss = 0.9765627635642886, disc_loss = 0.005097495912195882
Trained batch 64 in epoch 5, gen_loss = 0.9792632643993084, disc_loss = 0.005106625637899225
Trained batch 65 in epoch 5, gen_loss = 0.9805279437339667, disc_loss = 0.005091492986221882
Trained batch 66 in epoch 5, gen_loss = 0.9803131889941087, disc_loss = 0.005064496794826726
Trained batch 67 in epoch 5, gen_loss = 0.979786843937986, disc_loss = 0.005043030254241517
Trained batch 68 in epoch 5, gen_loss = 0.9798675075821255, disc_loss = 0.0050407869748069324
Trained batch 69 in epoch 5, gen_loss = 0.979665287051882, disc_loss = 0.00503305874299258
Trained batch 70 in epoch 5, gen_loss = 0.9802671041287166, disc_loss = 0.005005361417203512
Trained batch 71 in epoch 5, gen_loss = 0.9818027656939294, disc_loss = 0.004977351128925673
Trained batch 72 in epoch 5, gen_loss = 0.9820749816829211, disc_loss = 0.004934171031305745
Trained batch 73 in epoch 5, gen_loss = 0.9822211346110782, disc_loss = 0.004901395577345849
Trained batch 74 in epoch 5, gen_loss = 0.9829621760050455, disc_loss = 0.004865670044285556
Trained batch 75 in epoch 5, gen_loss = 0.9830227784420315, disc_loss = 0.004832175430094235
Trained batch 76 in epoch 5, gen_loss = 0.9843364683064547, disc_loss = 0.005024281383322721
Trained batch 77 in epoch 5, gen_loss = 0.9800064013554499, disc_loss = 0.005249761013636509
Trained batch 78 in epoch 5, gen_loss = 0.9812701457663427, disc_loss = 0.0052503341075056525
Trained batch 79 in epoch 5, gen_loss = 0.9830516457557679, disc_loss = 0.005332063387322705
Trained batch 80 in epoch 5, gen_loss = 0.9826702446113398, disc_loss = 0.005352987544208673
Trained batch 81 in epoch 5, gen_loss = 0.9822836140306984, disc_loss = 0.00534171354814955
Trained batch 82 in epoch 5, gen_loss = 0.9824909395482166, disc_loss = 0.00533062248092414
Trained batch 83 in epoch 5, gen_loss = 0.9832198967536291, disc_loss = 0.005315126450676914
Trained batch 84 in epoch 5, gen_loss = 0.9814824756454019, disc_loss = 0.005310587479513796
Trained batch 85 in epoch 5, gen_loss = 0.9839110201181367, disc_loss = 0.005361121141102685
Trained batch 86 in epoch 5, gen_loss = 0.9840364908349926, disc_loss = 0.005327321223689821
Trained batch 87 in epoch 5, gen_loss = 0.9827441065148874, disc_loss = 0.005312738113306378
Trained batch 88 in epoch 5, gen_loss = 0.9824521441138192, disc_loss = 0.005277250782230848
Trained batch 89 in epoch 5, gen_loss = 0.9824115057786306, disc_loss = 0.00525206441913421
Trained batch 90 in epoch 5, gen_loss = 0.9821504465826265, disc_loss = 0.005228444592321067
Trained batch 91 in epoch 5, gen_loss = 0.981724866706392, disc_loss = 0.005212309928459074
Trained batch 92 in epoch 5, gen_loss = 0.982003439498204, disc_loss = 0.005196226256278654
Trained batch 93 in epoch 5, gen_loss = 0.9812459818860317, disc_loss = 0.005173073852424847
Trained batch 94 in epoch 5, gen_loss = 0.9816904758152208, disc_loss = 0.00516050677427924
Trained batch 95 in epoch 5, gen_loss = 0.9814924032737812, disc_loss = 0.005126577761984663
Trained batch 96 in epoch 5, gen_loss = 0.981831333686396, disc_loss = 0.005118774834626652
Trained batch 97 in epoch 5, gen_loss = 0.9809476690632957, disc_loss = 0.005094187751136796
Trained batch 98 in epoch 5, gen_loss = 0.980580145060414, disc_loss = 0.005061942652441712
Trained batch 99 in epoch 5, gen_loss = 0.98072669506073, disc_loss = 0.005045479662949219
Trained batch 100 in epoch 5, gen_loss = 0.9819920912827595, disc_loss = 0.0050469697280187565
Trained batch 101 in epoch 5, gen_loss = 0.9812612971838783, disc_loss = 0.005021282135025032
Trained batch 102 in epoch 5, gen_loss = 0.9806066745693244, disc_loss = 0.005038714326818664
Trained batch 103 in epoch 5, gen_loss = 0.979566063445348, disc_loss = 0.005017340625412404
Trained batch 104 in epoch 5, gen_loss = 0.9802094181378682, disc_loss = 0.005000822451187386
Trained batch 105 in epoch 5, gen_loss = 0.9804863699202268, disc_loss = 0.004974652834034542
Trained batch 106 in epoch 5, gen_loss = 0.9805935849653227, disc_loss = 0.004979022048526905
Trained batch 107 in epoch 5, gen_loss = 0.9794756174087524, disc_loss = 0.004975227640157014
Trained batch 108 in epoch 5, gen_loss = 0.9790169536520582, disc_loss = 0.004953027345077776
Trained batch 109 in epoch 5, gen_loss = 0.9804735888134349, disc_loss = 0.0055584340197542175
Trained batch 110 in epoch 5, gen_loss = 0.9725597528992472, disc_loss = 0.007710857729024782
Trained batch 111 in epoch 5, gen_loss = 0.9749791538342834, disc_loss = 0.010611581242950965
Trained batch 112 in epoch 5, gen_loss = 0.9706217305058926, disc_loss = 0.011961957547953764
Trained batch 113 in epoch 5, gen_loss = 0.9674927039366019, disc_loss = 0.013489635915519963
Trained batch 114 in epoch 5, gen_loss = 0.9661856009908344, disc_loss = 0.01435859594595335
Trained batch 115 in epoch 5, gen_loss = 0.9627530380826572, disc_loss = 0.014950091237049743
Trained batch 116 in epoch 5, gen_loss = 0.9610756239575199, disc_loss = 0.015486866260608101
Trained batch 117 in epoch 5, gen_loss = 0.9577342838806621, disc_loss = 0.015752703291798106
Trained batch 118 in epoch 5, gen_loss = 0.9565973202971851, disc_loss = 0.015744640273746384
Trained batch 119 in epoch 5, gen_loss = 0.9564419161528349, disc_loss = 0.01576213187169439
Trained batch 120 in epoch 5, gen_loss = 0.9556476337111686, disc_loss = 0.015720543614203834
Trained batch 121 in epoch 5, gen_loss = 0.9553917100439306, disc_loss = 0.015726843468089145
Trained batch 122 in epoch 5, gen_loss = 0.9554907971523642, disc_loss = 0.01586759655369158
Trained batch 123 in epoch 5, gen_loss = 0.9540666218005842, disc_loss = 0.015950016047422504
Trained batch 124 in epoch 5, gen_loss = 0.953415430188179, disc_loss = 0.015880226933397353
Trained batch 125 in epoch 5, gen_loss = 0.9552099327482875, disc_loss = 0.0158607720125777
Trained batch 126 in epoch 5, gen_loss = 0.9545806267364757, disc_loss = 0.015776588820749674
Trained batch 127 in epoch 5, gen_loss = 0.9534546901704744, disc_loss = 0.015710024411419
Trained batch 128 in epoch 5, gen_loss = 0.9539037334133488, disc_loss = 0.015623443753660708
Trained batch 129 in epoch 5, gen_loss = 0.9542506466691311, disc_loss = 0.015548145478197302
Trained batch 130 in epoch 5, gen_loss = 0.9535315433758815, disc_loss = 0.015465573408598264
Trained batch 131 in epoch 5, gen_loss = 0.9528257703465043, disc_loss = 0.015375309989780582
Trained batch 132 in epoch 5, gen_loss = 0.9529686459249124, disc_loss = 0.015284806693890096
Trained batch 133 in epoch 5, gen_loss = 0.9531756929719626, disc_loss = 0.015193497300766575
Trained batch 134 in epoch 5, gen_loss = 0.9531032868005611, disc_loss = 0.015108691301645228
Trained batch 135 in epoch 5, gen_loss = 0.9527275458197383, disc_loss = 0.015039720761706121
Trained batch 136 in epoch 5, gen_loss = 0.9531906243875949, disc_loss = 0.015004961497327109
Trained batch 137 in epoch 5, gen_loss = 0.9523296439345332, disc_loss = 0.014952858381034077
Trained batch 138 in epoch 5, gen_loss = 0.9524100552574336, disc_loss = 0.014882555831954044
Trained batch 139 in epoch 5, gen_loss = 0.9523065121046135, disc_loss = 0.014815620549987736
Trained batch 140 in epoch 5, gen_loss = 0.9520800237325912, disc_loss = 0.014731811855734715
Trained batch 141 in epoch 5, gen_loss = 0.9523477345495157, disc_loss = 0.014653309426290102
Trained batch 142 in epoch 5, gen_loss = 0.95254866445398, disc_loss = 0.01457749882963701
Trained batch 143 in epoch 5, gen_loss = 0.9522366847635971, disc_loss = 0.014504167963524297
Trained batch 144 in epoch 5, gen_loss = 0.9529486303699428, disc_loss = 0.014549912230497033
Trained batch 145 in epoch 5, gen_loss = 0.9506179119830263, disc_loss = 0.014618645193316808
Trained batch 146 in epoch 5, gen_loss = 0.9489973460127707, disc_loss = 0.014617986249306625
Trained batch 147 in epoch 5, gen_loss = 0.9503287915643808, disc_loss = 0.014754773477073508
Trained batch 148 in epoch 5, gen_loss = 0.9480397302232333, disc_loss = 0.014889315277769311
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.1145992279052734, disc_loss = 0.010136933997273445
Trained batch 1 in epoch 6, gen_loss = 1.0887323021888733, disc_loss = 0.0079406569711864
Trained batch 2 in epoch 6, gen_loss = 1.0462971727053325, disc_loss = 0.007439160098632176
Trained batch 3 in epoch 6, gen_loss = 0.9866098910570145, disc_loss = 0.007132755941711366
Trained batch 4 in epoch 6, gen_loss = 0.9797235608100892, disc_loss = 0.006682820431888103
Trained batch 5 in epoch 6, gen_loss = 0.9856931467851003, disc_loss = 0.006984681977579991
Trained batch 6 in epoch 6, gen_loss = 0.9771010109356472, disc_loss = 0.0065116677433252335
Trained batch 7 in epoch 6, gen_loss = 0.9743936657905579, disc_loss = 0.007186895469203591
Trained batch 8 in epoch 6, gen_loss = 0.9537744985686408, disc_loss = 0.007889077688256899
Trained batch 9 in epoch 6, gen_loss = 0.953940337896347, disc_loss = 0.007516835816204548
Trained batch 10 in epoch 6, gen_loss = 0.9659458236260847, disc_loss = 0.007201543247157877
Trained batch 11 in epoch 6, gen_loss = 0.9690057883659998, disc_loss = 0.006798063579481095
Trained batch 12 in epoch 6, gen_loss = 0.9650731682777405, disc_loss = 0.006499021188714183
Trained batch 13 in epoch 6, gen_loss = 0.9621701581137521, disc_loss = 0.0062069500563666224
Trained batch 14 in epoch 6, gen_loss = 0.9589774052302042, disc_loss = 0.0060204205879320705
Trained batch 15 in epoch 6, gen_loss = 0.9612388797104359, disc_loss = 0.005865713115781546
Trained batch 16 in epoch 6, gen_loss = 0.960027649122126, disc_loss = 0.0056643920594497636
Trained batch 17 in epoch 6, gen_loss = 0.959319551785787, disc_loss = 0.00547866128747248
Trained batch 18 in epoch 6, gen_loss = 0.9564872446813082, disc_loss = 0.005312952445819974
Trained batch 19 in epoch 6, gen_loss = 0.955371755361557, disc_loss = 0.005155065294820816
Trained batch 20 in epoch 6, gen_loss = 0.9568941224189031, disc_loss = 0.00501171844301834
Trained batch 21 in epoch 6, gen_loss = 0.9569577168334614, disc_loss = 0.004865307651925832
Trained batch 22 in epoch 6, gen_loss = 0.957177063693171, disc_loss = 0.004745147003711242
Trained batch 23 in epoch 6, gen_loss = 0.958161490658919, disc_loss = 0.004679590371476176
Trained batch 24 in epoch 6, gen_loss = 0.9582666611671448, disc_loss = 0.0047383918100968
Trained batch 25 in epoch 6, gen_loss = 0.9587791516230657, disc_loss = 0.004854897274456631
Trained batch 26 in epoch 6, gen_loss = 0.9572582840919495, disc_loss = 0.004852072667778918
Trained batch 27 in epoch 6, gen_loss = 0.9576681618179593, disc_loss = 0.004800422229371699
Trained batch 28 in epoch 6, gen_loss = 0.9562427504309292, disc_loss = 0.004704474411294635
Trained batch 29 in epoch 6, gen_loss = 0.9557883858680725, disc_loss = 0.004638556542340666
Trained batch 30 in epoch 6, gen_loss = 0.9537929873312673, disc_loss = 0.004563800829102195
Trained batch 31 in epoch 6, gen_loss = 0.9552824422717094, disc_loss = 0.004502312021941179
Trained batch 32 in epoch 6, gen_loss = 0.9561106598738468, disc_loss = 0.0045054251448053756
Trained batch 33 in epoch 6, gen_loss = 0.9528639334089616, disc_loss = 0.004487869785139885
Trained batch 34 in epoch 6, gen_loss = 0.9534396546227591, disc_loss = 0.00443852033931762
Trained batch 35 in epoch 6, gen_loss = 0.9530056731568443, disc_loss = 0.004454811152148371
Trained batch 36 in epoch 6, gen_loss = 0.9531666330389075, disc_loss = 0.004403858505365615
Trained batch 37 in epoch 6, gen_loss = 0.9550366872235349, disc_loss = 0.004374865574247547
Trained batch 38 in epoch 6, gen_loss = 0.954181833144946, disc_loss = 0.004320371349772008
Trained batch 39 in epoch 6, gen_loss = 0.9532076984643936, disc_loss = 0.004825311413151212
Trained batch 40 in epoch 6, gen_loss = 0.9404005778998863, disc_loss = 0.006309966741288762
Trained batch 41 in epoch 6, gen_loss = 0.9485968188160941, disc_loss = 0.006944097293030825
Trained batch 42 in epoch 6, gen_loss = 0.9499458164669746, disc_loss = 0.007037252125460221
Trained batch 43 in epoch 6, gen_loss = 0.9475789713588628, disc_loss = 0.007180992749371481
Trained batch 44 in epoch 6, gen_loss = 0.9447831319438087, disc_loss = 0.007210248069734209
Trained batch 45 in epoch 6, gen_loss = 0.9470499164384344, disc_loss = 0.007138803968226294
Trained batch 46 in epoch 6, gen_loss = 0.9480210891429414, disc_loss = 0.007215288846674276
Trained batch 47 in epoch 6, gen_loss = 0.9469650418808063, disc_loss = 0.007243248093194173
Trained batch 48 in epoch 6, gen_loss = 0.9465555712884787, disc_loss = 0.007242628318561735
Trained batch 49 in epoch 6, gen_loss = 0.9473122984170914, disc_loss = 0.007180221418384463
Trained batch 50 in epoch 6, gen_loss = 0.9486156965003294, disc_loss = 0.007124749535019053
Trained batch 51 in epoch 6, gen_loss = 0.948007267828171, disc_loss = 0.007028387781107225
Trained batch 52 in epoch 6, gen_loss = 0.9479717494181867, disc_loss = 0.006945682313943387
Trained batch 53 in epoch 6, gen_loss = 0.948209990505819, disc_loss = 0.0068719424760072595
Trained batch 54 in epoch 6, gen_loss = 0.9479936962777918, disc_loss = 0.006801171717233956
Trained batch 55 in epoch 6, gen_loss = 0.9487621544727257, disc_loss = 0.0067444233053330594
Trained batch 56 in epoch 6, gen_loss = 0.9487069348494211, disc_loss = 0.006668693657654027
Trained batch 57 in epoch 6, gen_loss = 0.9490909006061226, disc_loss = 0.006609244065375292
Trained batch 58 in epoch 6, gen_loss = 0.9507742418070971, disc_loss = 0.0066202423255101355
Trained batch 59 in epoch 6, gen_loss = 0.9496901874740918, disc_loss = 0.006576244146951164
Trained batch 60 in epoch 6, gen_loss = 0.9479215882840704, disc_loss = 0.006542029296292267
Trained batch 61 in epoch 6, gen_loss = 0.9476740095884569, disc_loss = 0.006507531508818389
Trained batch 62 in epoch 6, gen_loss = 0.9498552845584022, disc_loss = 0.006469009859886553
Trained batch 63 in epoch 6, gen_loss = 0.9511625957675278, disc_loss = 0.0064095468314917525
Trained batch 64 in epoch 6, gen_loss = 0.9511365794218504, disc_loss = 0.006341042869294492
Trained batch 65 in epoch 6, gen_loss = 0.9509279985319484, disc_loss = 0.006279446860196803
Trained batch 66 in epoch 6, gen_loss = 0.9505737597372994, disc_loss = 0.006219342613328637
Trained batch 67 in epoch 6, gen_loss = 0.9512574861154837, disc_loss = 0.006167136117309222
Trained batch 68 in epoch 6, gen_loss = 0.951326157303824, disc_loss = 0.006127799110338632
Trained batch 69 in epoch 6, gen_loss = 0.9499547579458781, disc_loss = 0.006086221355612257
Trained batch 70 in epoch 6, gen_loss = 0.9508831144218713, disc_loss = 0.006025311045191237
Trained batch 71 in epoch 6, gen_loss = 0.9518651312424077, disc_loss = 0.00597169526736252
Trained batch 72 in epoch 6, gen_loss = 0.9521710574626923, disc_loss = 0.005925775948937421
Trained batch 73 in epoch 6, gen_loss = 0.9527559018618351, disc_loss = 0.005872782838933573
Trained batch 74 in epoch 6, gen_loss = 0.9527395260334015, disc_loss = 0.005823076032102108
Trained batch 75 in epoch 6, gen_loss = 0.9526909248609292, disc_loss = 0.0057979547663738855
Trained batch 76 in epoch 6, gen_loss = 0.9529146501770267, disc_loss = 0.005760671522516709
Trained batch 77 in epoch 6, gen_loss = 0.9528409918913474, disc_loss = 0.005709027635673873
Trained batch 78 in epoch 6, gen_loss = 0.9526187577579595, disc_loss = 0.005664378092211636
Trained batch 79 in epoch 6, gen_loss = 0.9527704771608114, disc_loss = 0.0056266437779413534
Trained batch 80 in epoch 6, gen_loss = 0.9534365612047689, disc_loss = 0.005614307780899567
Trained batch 81 in epoch 6, gen_loss = 0.953303848461407, disc_loss = 0.005588105564550837
Trained batch 82 in epoch 6, gen_loss = 0.9535579641899431, disc_loss = 0.0055601172715829435
Trained batch 83 in epoch 6, gen_loss = 0.9544020994078546, disc_loss = 0.005530581463106154
Trained batch 84 in epoch 6, gen_loss = 0.9545031999840455, disc_loss = 0.005493325704489561
Trained batch 85 in epoch 6, gen_loss = 0.9547190295402394, disc_loss = 0.0054562513900617525
Trained batch 86 in epoch 6, gen_loss = 0.9543784483410847, disc_loss = 0.0054142282025931385
Trained batch 87 in epoch 6, gen_loss = 0.9545935551551256, disc_loss = 0.005372148532346314
Trained batch 88 in epoch 6, gen_loss = 0.9550816681277886, disc_loss = 0.005330076813959422
Trained batch 89 in epoch 6, gen_loss = 0.9551543762286504, disc_loss = 0.005289297686734547
Trained batch 90 in epoch 6, gen_loss = 0.9555703483440063, disc_loss = 0.005252628292949809
Trained batch 91 in epoch 6, gen_loss = 0.9556120417040327, disc_loss = 0.005211646974835869
Trained batch 92 in epoch 6, gen_loss = 0.9554183351737197, disc_loss = 0.005172122631632593
Trained batch 93 in epoch 6, gen_loss = 0.9556072122873144, disc_loss = 0.005146978389560938
Trained batch 94 in epoch 6, gen_loss = 0.9557328365351024, disc_loss = 0.005122298589221349
Trained batch 95 in epoch 6, gen_loss = 0.9558542243515452, disc_loss = 0.005084323706493403
Trained batch 96 in epoch 6, gen_loss = 0.9554047483144347, disc_loss = 0.005053791279914146
Trained batch 97 in epoch 6, gen_loss = 0.9560632362049453, disc_loss = 0.005018334239436199
Trained batch 98 in epoch 6, gen_loss = 0.9562457447702234, disc_loss = 0.004984147159965953
Trained batch 99 in epoch 6, gen_loss = 0.9562541970610619, disc_loss = 0.004954680539667606
Trained batch 100 in epoch 6, gen_loss = 0.9567838562006997, disc_loss = 0.00492392488902822
Trained batch 101 in epoch 6, gen_loss = 0.9567787486548517, disc_loss = 0.004891764269867802
Trained batch 102 in epoch 6, gen_loss = 0.9566661996170155, disc_loss = 0.004860876233190371
Trained batch 103 in epoch 6, gen_loss = 0.956615898758173, disc_loss = 0.004833085508345483
Trained batch 104 in epoch 6, gen_loss = 0.956951348838352, disc_loss = 0.004799604065538872
Trained batch 105 in epoch 6, gen_loss = 0.9574125541268654, disc_loss = 0.004767880737693664
Trained batch 106 in epoch 6, gen_loss = 0.9577084921787833, disc_loss = 0.0047488695502316
Trained batch 107 in epoch 6, gen_loss = 0.9574754847972481, disc_loss = 0.004724220829774384
Trained batch 108 in epoch 6, gen_loss = 0.957377448267893, disc_loss = 0.00469734381516934
Trained batch 109 in epoch 6, gen_loss = 0.957530847733671, disc_loss = 0.004672567582350563
Trained batch 110 in epoch 6, gen_loss = 0.9578870220764263, disc_loss = 0.00464399414229299
Trained batch 111 in epoch 6, gen_loss = 0.9582803959825209, disc_loss = 0.004616903764794448
Trained batch 112 in epoch 6, gen_loss = 0.9584668961773931, disc_loss = 0.0045911365918056895
Trained batch 113 in epoch 6, gen_loss = 0.9586243130135954, disc_loss = 0.004571941144061847
Trained batch 114 in epoch 6, gen_loss = 0.9588320900564609, disc_loss = 0.0045517451656253444
Trained batch 115 in epoch 6, gen_loss = 0.9594047863421769, disc_loss = 0.0045441354299767004
Trained batch 116 in epoch 6, gen_loss = 0.9588865569004645, disc_loss = 0.004541744221336184
Trained batch 117 in epoch 6, gen_loss = 0.9588704076358827, disc_loss = 0.004519846580401695
Trained batch 118 in epoch 6, gen_loss = 0.9594930437933497, disc_loss = 0.004497232130814751
Trained batch 119 in epoch 6, gen_loss = 0.9597930861016114, disc_loss = 0.004475883382838219
Trained batch 120 in epoch 6, gen_loss = 0.959632818610215, disc_loss = 0.004456609114234851
Trained batch 121 in epoch 6, gen_loss = 0.9598888855000012, disc_loss = 0.00443348868704233
Trained batch 122 in epoch 6, gen_loss = 0.9601686197083171, disc_loss = 0.004408667248302723
Trained batch 123 in epoch 6, gen_loss = 0.9601320453709171, disc_loss = 0.0044089935498402245
Trained batch 124 in epoch 6, gen_loss = 0.9596742103099823, disc_loss = 0.004407619902864098
Trained batch 125 in epoch 6, gen_loss = 0.9599707531077522, disc_loss = 0.004398182840160434
Trained batch 126 in epoch 6, gen_loss = 0.9604311662865436, disc_loss = 0.004380764663366117
Trained batch 127 in epoch 6, gen_loss = 0.96081911935471, disc_loss = 0.004359807745458966
Trained batch 128 in epoch 6, gen_loss = 0.9607104356436766, disc_loss = 0.004347538807458251
Trained batch 129 in epoch 6, gen_loss = 0.9609511836217, disc_loss = 0.004347308224532753
Trained batch 130 in epoch 6, gen_loss = 0.9612837513439528, disc_loss = 0.004344528420998907
Trained batch 131 in epoch 6, gen_loss = 0.9612133600043528, disc_loss = 0.0043342947266699575
Trained batch 132 in epoch 6, gen_loss = 0.9614384700929312, disc_loss = 0.004356019092982817
Trained batch 133 in epoch 6, gen_loss = 0.9606663493522957, disc_loss = 0.004365997916302963
Trained batch 134 in epoch 6, gen_loss = 0.9608391922933084, disc_loss = 0.0043559908772025395
Trained batch 135 in epoch 6, gen_loss = 0.9614533591358101, disc_loss = 0.00433945314537542
Trained batch 136 in epoch 6, gen_loss = 0.9619618160446195, disc_loss = 0.0043331022845091716
Trained batch 137 in epoch 6, gen_loss = 0.9618084907963655, disc_loss = 0.004315562127832917
Trained batch 138 in epoch 6, gen_loss = 0.9619083196567975, disc_loss = 0.004296327446982693
Trained batch 139 in epoch 6, gen_loss = 0.9620967343449592, disc_loss = 0.004280806277945105
Trained batch 140 in epoch 6, gen_loss = 0.962513286805322, disc_loss = 0.0042631425539771395
Trained batch 141 in epoch 6, gen_loss = 0.9630145554391432, disc_loss = 0.004245924294440889
Trained batch 142 in epoch 6, gen_loss = 0.9629786975317068, disc_loss = 0.004236346480299856
Trained batch 143 in epoch 6, gen_loss = 0.9631474463062154, disc_loss = 0.0042251638806192204
Trained batch 144 in epoch 6, gen_loss = 0.9637452378355224, disc_loss = 0.004209027741232822
Trained batch 145 in epoch 6, gen_loss = 0.9639723017199399, disc_loss = 0.004190345225402805
Trained batch 146 in epoch 6, gen_loss = 0.9637779676589836, disc_loss = 0.004174715110740694
Trained batch 147 in epoch 6, gen_loss = 0.9638313210091075, disc_loss = 0.004159546272382392
Trained batch 148 in epoch 6, gen_loss = 0.964136893517219, disc_loss = 0.004152382862279129
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9390071630477905, disc_loss = 0.0015843678265810013
Trained batch 1 in epoch 7, gen_loss = 0.9492580890655518, disc_loss = 0.0016933990409597754
Trained batch 2 in epoch 7, gen_loss = 0.9630935788154602, disc_loss = 0.001827327146505316
Trained batch 3 in epoch 7, gen_loss = 0.975909486413002, disc_loss = 0.00246420776238665
Trained batch 4 in epoch 7, gen_loss = 0.9601493358612061, disc_loss = 0.002573015121743083
Trained batch 5 in epoch 7, gen_loss = 0.9586801330248514, disc_loss = 0.0027365124551579356
Trained batch 6 in epoch 7, gen_loss = 0.9699485983167376, disc_loss = 0.003002975967579654
Trained batch 7 in epoch 7, gen_loss = 0.9746756255626678, disc_loss = 0.0029095802747178823
Trained batch 8 in epoch 7, gen_loss = 0.9785581959618462, disc_loss = 0.0027741160528320405
Trained batch 9 in epoch 7, gen_loss = 0.9700796127319335, disc_loss = 0.0027510935789905487
Trained batch 10 in epoch 7, gen_loss = 0.9736160039901733, disc_loss = 0.002710060629231686
Trained batch 11 in epoch 7, gen_loss = 0.97447170317173, disc_loss = 0.0026851607156762234
Trained batch 12 in epoch 7, gen_loss = 0.974249202471513, disc_loss = 0.0027126741434375825
Trained batch 13 in epoch 7, gen_loss = 0.975841930934361, disc_loss = 0.002716519894810127
Trained batch 14 in epoch 7, gen_loss = 0.9833117246627807, disc_loss = 0.002735075005330145
Trained batch 15 in epoch 7, gen_loss = 0.9809508845210075, disc_loss = 0.0026887511703534983
Trained batch 16 in epoch 7, gen_loss = 0.9793653698528514, disc_loss = 0.0026866499375661507
Trained batch 17 in epoch 7, gen_loss = 0.9846807850731744, disc_loss = 0.002692106095815284
Trained batch 18 in epoch 7, gen_loss = 0.9847106180692974, disc_loss = 0.0026667918458482937
Trained batch 19 in epoch 7, gen_loss = 0.9849236965179443, disc_loss = 0.002625253010774031
Trained batch 20 in epoch 7, gen_loss = 0.9843236548560006, disc_loss = 0.0026943888127182922
Trained batch 21 in epoch 7, gen_loss = 0.9859801259907809, disc_loss = 0.0027538741229694674
Trained batch 22 in epoch 7, gen_loss = 0.9858884526335675, disc_loss = 0.002731239225755891
Trained batch 23 in epoch 7, gen_loss = 0.9834843476613363, disc_loss = 0.0026898359016437703
Trained batch 24 in epoch 7, gen_loss = 0.9831394696235657, disc_loss = 0.0026411109091714026
Trained batch 25 in epoch 7, gen_loss = 0.9850964844226837, disc_loss = 0.0026084579518423057
Trained batch 26 in epoch 7, gen_loss = 0.9866353781134994, disc_loss = 0.0025979201093798985
Trained batch 27 in epoch 7, gen_loss = 0.9900703196014676, disc_loss = 0.0025748446309340318
Trained batch 28 in epoch 7, gen_loss = 0.9909700216918156, disc_loss = 0.002551552458216661
Trained batch 29 in epoch 7, gen_loss = 0.9897122502326965, disc_loss = 0.002569882800647368
Trained batch 30 in epoch 7, gen_loss = 0.9888249654923716, disc_loss = 0.0025665668673032233
Trained batch 31 in epoch 7, gen_loss = 0.9922105018049479, disc_loss = 0.0025904008180077653
Trained batch 32 in epoch 7, gen_loss = 0.9901434056686632, disc_loss = 0.002578833595510911
Trained batch 33 in epoch 7, gen_loss = 0.9905460073667414, disc_loss = 0.0025594416827730395
Trained batch 34 in epoch 7, gen_loss = 0.9932391558374677, disc_loss = 0.0025451156310737134
Trained batch 35 in epoch 7, gen_loss = 0.9945919828282462, disc_loss = 0.0025220391107723117
Trained batch 36 in epoch 7, gen_loss = 0.9956931794011915, disc_loss = 0.00248756177245161
Trained batch 37 in epoch 7, gen_loss = 0.9960721746871346, disc_loss = 0.00245185709239817
Trained batch 38 in epoch 7, gen_loss = 0.996426950662564, disc_loss = 0.002465818531047075
Trained batch 39 in epoch 7, gen_loss = 0.995887690782547, disc_loss = 0.0024573558242991568
Trained batch 40 in epoch 7, gen_loss = 0.9959393376257362, disc_loss = 0.0024485778654130493
Trained batch 41 in epoch 7, gen_loss = 0.9969936339628129, disc_loss = 0.002425921338033818
Trained batch 42 in epoch 7, gen_loss = 0.9990657276885454, disc_loss = 0.002630232302688582
Trained batch 43 in epoch 7, gen_loss = 0.9950948587872765, disc_loss = 0.00280821536117318
Trained batch 44 in epoch 7, gen_loss = 0.9951987557941013, disc_loss = 0.002793709850973553
Trained batch 45 in epoch 7, gen_loss = 0.9990559686785159, disc_loss = 0.002815747329884249
Trained batch 46 in epoch 7, gen_loss = 1.0005308567209448, disc_loss = 0.002825240203318127
Trained batch 47 in epoch 7, gen_loss = 1.0008204206824303, disc_loss = 0.0028071874451901144
Trained batch 48 in epoch 7, gen_loss = 0.9988909363746643, disc_loss = 0.002830981642806104
Trained batch 49 in epoch 7, gen_loss = 1.0001307904720307, disc_loss = 0.002815381004475057
Trained batch 50 in epoch 7, gen_loss = 1.0008672627748227, disc_loss = 0.0028002053617919775
Trained batch 51 in epoch 7, gen_loss = 1.001919529758967, disc_loss = 0.0027901726336075137
Trained batch 52 in epoch 7, gen_loss = 1.0015019650729198, disc_loss = 0.0027750441145573583
Trained batch 53 in epoch 7, gen_loss = 1.0018287808806807, disc_loss = 0.0027903733835383145
Trained batch 54 in epoch 7, gen_loss = 1.0013386834751477, disc_loss = 0.002799870213493705
Trained batch 55 in epoch 7, gen_loss = 1.001964760678155, disc_loss = 0.0028056349463960423
Trained batch 56 in epoch 7, gen_loss = 1.0038226780138517, disc_loss = 0.00280088786313539
Trained batch 57 in epoch 7, gen_loss = 1.0031568130542492, disc_loss = 0.0027782292554861514
Trained batch 58 in epoch 7, gen_loss = 1.0030771999035852, disc_loss = 0.00275444219646565
Trained batch 59 in epoch 7, gen_loss = 1.0038402636845907, disc_loss = 0.0027379479336862764
Trained batch 60 in epoch 7, gen_loss = 1.0036204662479338, disc_loss = 0.002723957873789258
Trained batch 61 in epoch 7, gen_loss = 1.0040827931896332, disc_loss = 0.002713153518045381
Trained batch 62 in epoch 7, gen_loss = 1.0045886020811776, disc_loss = 0.0027060687416307037
Trained batch 63 in epoch 7, gen_loss = 1.0046609994024038, disc_loss = 0.002687888421860407
Trained batch 64 in epoch 7, gen_loss = 1.0040849548119766, disc_loss = 0.0026793736731633546
Trained batch 65 in epoch 7, gen_loss = 1.0046263165546185, disc_loss = 0.0026628351593954544
Trained batch 66 in epoch 7, gen_loss = 1.0053263164278288, disc_loss = 0.0026530248856644575
Trained batch 67 in epoch 7, gen_loss = 1.0053766588954365, disc_loss = 0.002634804124039981
Trained batch 68 in epoch 7, gen_loss = 1.0065407899842747, disc_loss = 0.002616386087881266
Trained batch 69 in epoch 7, gen_loss = 1.006973911183221, disc_loss = 0.002598612610849419
Trained batch 70 in epoch 7, gen_loss = 1.007012213619662, disc_loss = 0.0025811909327388438
Trained batch 71 in epoch 7, gen_loss = 1.0075680058863428, disc_loss = 0.0025612501889958773
Trained batch 72 in epoch 7, gen_loss = 1.0070931805323249, disc_loss = 0.002542274383738739
Trained batch 73 in epoch 7, gen_loss = 1.0081186995312974, disc_loss = 0.002532434185677384
Trained batch 74 in epoch 7, gen_loss = 1.0085103424390156, disc_loss = 0.002529205166113873
Trained batch 75 in epoch 7, gen_loss = 1.0077082357908551, disc_loss = 0.002523810218247634
Trained batch 76 in epoch 7, gen_loss = 1.0096347564226622, disc_loss = 0.002544278643311715
Trained batch 77 in epoch 7, gen_loss = 1.007992989741839, disc_loss = 0.0026252777450001584
Trained batch 78 in epoch 7, gen_loss = 1.0105906566487084, disc_loss = 0.00280162102772701
Trained batch 79 in epoch 7, gen_loss = 1.0070180483162403, disc_loss = 0.0031218218166031873
Trained batch 80 in epoch 7, gen_loss = 1.0115564553825944, disc_loss = 0.003306360893744837
Trained batch 81 in epoch 7, gen_loss = 1.0122038860146592, disc_loss = 0.003350904928349958
Trained batch 82 in epoch 7, gen_loss = 1.0106685865356262, disc_loss = 0.003417100085517818
Trained batch 83 in epoch 7, gen_loss = 1.0097789963086445, disc_loss = 0.003415773948377353
Trained batch 84 in epoch 7, gen_loss = 1.0105308308320886, disc_loss = 0.003567765887333628
Trained batch 85 in epoch 7, gen_loss = 1.0078736349593762, disc_loss = 0.0037054639501865345
Trained batch 86 in epoch 7, gen_loss = 1.0068705979434924, disc_loss = 0.0037461953416959137
Trained batch 87 in epoch 7, gen_loss = 1.0083216814832254, disc_loss = 0.0037935777151935986
Trained batch 88 in epoch 7, gen_loss = 1.00803581851252, disc_loss = 0.003784193648182358
Trained batch 89 in epoch 7, gen_loss = 1.008373604218165, disc_loss = 0.0037659681001160706
Trained batch 90 in epoch 7, gen_loss = 1.008668629022745, disc_loss = 0.0037579630401783754
Trained batch 91 in epoch 7, gen_loss = 1.0091124429650928, disc_loss = 0.0037550156412180513
Trained batch 92 in epoch 7, gen_loss = 1.0091540089217566, disc_loss = 0.0037432654237534893
Trained batch 93 in epoch 7, gen_loss = 1.0098034682426047, disc_loss = 0.00373003853143173
Trained batch 94 in epoch 7, gen_loss = 1.0094446583798058, disc_loss = 0.0037243874069597376
Trained batch 95 in epoch 7, gen_loss = 1.0115732699632645, disc_loss = 0.0037617712914652657
Trained batch 96 in epoch 7, gen_loss = 1.0098718755023997, disc_loss = 0.0037931075245237994
Trained batch 97 in epoch 7, gen_loss = 1.01245152159613, disc_loss = 0.0038597648642596087
Trained batch 98 in epoch 7, gen_loss = 1.0140083841603211, disc_loss = 0.00395504449790513
Trained batch 99 in epoch 7, gen_loss = 1.0119129103422164, disc_loss = 0.0041460369958076625
Trained batch 100 in epoch 7, gen_loss = 1.013151741854035, disc_loss = 0.004224422679393377
Trained batch 101 in epoch 7, gen_loss = 1.0146891854557336, disc_loss = 0.004256222215618062
Trained batch 102 in epoch 7, gen_loss = 1.014633550805953, disc_loss = 0.0042426542263676965
Trained batch 103 in epoch 7, gen_loss = 1.0141978836976564, disc_loss = 0.004239688928534564
Trained batch 104 in epoch 7, gen_loss = 1.0147487277076357, disc_loss = 0.00429216349785704
Trained batch 105 in epoch 7, gen_loss = 1.0140541634469662, disc_loss = 0.004286004413789103
Trained batch 106 in epoch 7, gen_loss = 1.0139383211314121, disc_loss = 0.004299397970915328
Trained batch 107 in epoch 7, gen_loss = 1.0138065367937088, disc_loss = 0.0043005286187744116
Trained batch 108 in epoch 7, gen_loss = 1.013662420828408, disc_loss = 0.0043086069069990735
Trained batch 109 in epoch 7, gen_loss = 1.0148915827274323, disc_loss = 0.004371813869908113
Trained batch 110 in epoch 7, gen_loss = 1.0124873180647154, disc_loss = 0.004467098435663895
Trained batch 111 in epoch 7, gen_loss = 1.015454259301935, disc_loss = 0.004568402596175604
Trained batch 112 in epoch 7, gen_loss = 1.0172275294244817, disc_loss = 0.004593878109791044
Trained batch 113 in epoch 7, gen_loss = 1.017185468422739, disc_loss = 0.004589461781729928
Trained batch 114 in epoch 7, gen_loss = 1.0166224987610526, disc_loss = 0.004579180935600205
Trained batch 115 in epoch 7, gen_loss = 1.0159846708692353, disc_loss = 0.004559348773909733
Trained batch 116 in epoch 7, gen_loss = 1.0160806780187492, disc_loss = 0.004574205932350686
Trained batch 117 in epoch 7, gen_loss = 1.0156648058002278, disc_loss = 0.0045581867442845165
Trained batch 118 in epoch 7, gen_loss = 1.0149779059305912, disc_loss = 0.004546798508371688
Trained batch 119 in epoch 7, gen_loss = 1.0150747060775758, disc_loss = 0.0045248226301434135
Trained batch 120 in epoch 7, gen_loss = 1.0153503486932802, disc_loss = 0.0044975233791503776
Trained batch 121 in epoch 7, gen_loss = 1.0152715200283489, disc_loss = 0.004471388616843424
Trained batch 122 in epoch 7, gen_loss = 1.0153112237046404, disc_loss = 0.004445238515916394
Trained batch 123 in epoch 7, gen_loss = 1.014926547485013, disc_loss = 0.004421812335720226
Trained batch 124 in epoch 7, gen_loss = 1.0150144171714783, disc_loss = 0.004396996376104653
Trained batch 125 in epoch 7, gen_loss = 1.0151951942178938, disc_loss = 0.004370469534363124
Trained batch 126 in epoch 7, gen_loss = 1.0153393515451687, disc_loss = 0.0043466663946888934
Trained batch 127 in epoch 7, gen_loss = 1.0151826776564121, disc_loss = 0.004325630218772858
Trained batch 128 in epoch 7, gen_loss = 1.0150239361349003, disc_loss = 0.0043079919865816945
Trained batch 129 in epoch 7, gen_loss = 1.0151730615359087, disc_loss = 0.004286015707139786
Trained batch 130 in epoch 7, gen_loss = 1.0150066027204498, disc_loss = 0.004261407839447146
Trained batch 131 in epoch 7, gen_loss = 1.0150282107519382, disc_loss = 0.004242219291027692
Trained batch 132 in epoch 7, gen_loss = 1.0150590090823353, disc_loss = 0.004220007142381168
Trained batch 133 in epoch 7, gen_loss = 1.0150868078665947, disc_loss = 0.004195946194891776
Trained batch 134 in epoch 7, gen_loss = 1.0152484942365576, disc_loss = 0.004171080925260429
Trained batch 135 in epoch 7, gen_loss = 1.0150135825662052, disc_loss = 0.004146039375508039
Trained batch 136 in epoch 7, gen_loss = 1.0147172425785205, disc_loss = 0.004126096586186956
Trained batch 137 in epoch 7, gen_loss = 1.01461358130842, disc_loss = 0.00410812976770103
Trained batch 138 in epoch 7, gen_loss = 1.0150632905445511, disc_loss = 0.00408626802553751
Trained batch 139 in epoch 7, gen_loss = 1.0151669412851334, disc_loss = 0.004064952615382416
Trained batch 140 in epoch 7, gen_loss = 1.0148299568933798, disc_loss = 0.004060282520553533
Trained batch 141 in epoch 7, gen_loss = 1.014476820616655, disc_loss = 0.004052961397666852
Trained batch 142 in epoch 7, gen_loss = 1.0145355171256967, disc_loss = 0.004041267694071769
Trained batch 143 in epoch 7, gen_loss = 1.014782603416178, disc_loss = 0.004029323586211022
Trained batch 144 in epoch 7, gen_loss = 1.0148601836171645, disc_loss = 0.0040125752397780785
Trained batch 145 in epoch 7, gen_loss = 1.0146575933449888, disc_loss = 0.003991526283629953
Trained batch 146 in epoch 7, gen_loss = 1.0146788281648338, disc_loss = 0.003975068171489604
Trained batch 147 in epoch 7, gen_loss = 1.014897855149733, disc_loss = 0.003959975928238065
Trained batch 148 in epoch 7, gen_loss = 1.0149837928330339, disc_loss = 0.003944891894817502
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9708607196807861, disc_loss = 0.003096652450039983
Trained batch 1 in epoch 8, gen_loss = 1.0221904516220093, disc_loss = 0.004267356474883854
Trained batch 2 in epoch 8, gen_loss = 1.0296842257181804, disc_loss = 0.004154124219591419
Trained batch 3 in epoch 8, gen_loss = 1.0527524650096893, disc_loss = 0.004222748044412583
Trained batch 4 in epoch 8, gen_loss = 1.0459430932998657, disc_loss = 0.003922938136383891
Trained batch 5 in epoch 8, gen_loss = 1.0825795531272888, disc_loss = 0.004745988757349551
Trained batch 6 in epoch 8, gen_loss = 1.06588191645486, disc_loss = 0.005742290556164724
Trained batch 7 in epoch 8, gen_loss = 1.0594584792852402, disc_loss = 0.006420670630177483
Trained batch 8 in epoch 8, gen_loss = 1.0559122165044148, disc_loss = 0.006251821785958277
Trained batch 9 in epoch 8, gen_loss = 1.0579537153244019, disc_loss = 0.005903674778528512
Trained batch 10 in epoch 8, gen_loss = 1.0498804504221135, disc_loss = 0.005633564073253761
Trained batch 11 in epoch 8, gen_loss = 1.045600801706314, disc_loss = 0.005273642367683351
Trained batch 12 in epoch 8, gen_loss = 1.0463601992680476, disc_loss = 0.004997891517212758
Trained batch 13 in epoch 8, gen_loss = 1.047198474407196, disc_loss = 0.004797512066683599
Trained batch 14 in epoch 8, gen_loss = 1.048435624440511, disc_loss = 0.004572701205809911
Trained batch 15 in epoch 8, gen_loss = 1.047728531062603, disc_loss = 0.004357477657322306
Trained batch 16 in epoch 8, gen_loss = 1.0450524722828585, disc_loss = 0.00419849342913093
Trained batch 17 in epoch 8, gen_loss = 1.043589883380466, disc_loss = 0.00404669870234405
Trained batch 18 in epoch 8, gen_loss = 1.0419179389351292, disc_loss = 0.003906785099963217
Trained batch 19 in epoch 8, gen_loss = 1.0428915202617646, disc_loss = 0.0037763888540212065
Trained batch 20 in epoch 8, gen_loss = 1.0418658710661388, disc_loss = 0.003686592409697672
Trained batch 21 in epoch 8, gen_loss = 1.0393876297907396, disc_loss = 0.003608853900170123
Trained batch 22 in epoch 8, gen_loss = 1.039643425008525, disc_loss = 0.0035102983035714083
Trained batch 23 in epoch 8, gen_loss = 1.038313366472721, disc_loss = 0.0034094554769884176
Trained batch 24 in epoch 8, gen_loss = 1.0383810114860534, disc_loss = 0.0033318193862214686
Trained batch 25 in epoch 8, gen_loss = 1.0375012182272398, disc_loss = 0.0032557248128936267
Trained batch 26 in epoch 8, gen_loss = 1.0371982278647247, disc_loss = 0.0032290290325397144
Trained batch 27 in epoch 8, gen_loss = 1.0367731217827116, disc_loss = 0.0031975818606692235
Trained batch 28 in epoch 8, gen_loss = 1.0370491845854397, disc_loss = 0.0031643245280880868
Trained batch 29 in epoch 8, gen_loss = 1.037185436487198, disc_loss = 0.003113045520149171
Trained batch 30 in epoch 8, gen_loss = 1.0360211345457262, disc_loss = 0.0030524599020399393
Trained batch 31 in epoch 8, gen_loss = 1.0359055008739233, disc_loss = 0.0030153004845487885
Trained batch 32 in epoch 8, gen_loss = 1.0348555337299, disc_loss = 0.0029527317471520014
Trained batch 33 in epoch 8, gen_loss = 1.0346236807458542, disc_loss = 0.002905735352268333
Trained batch 34 in epoch 8, gen_loss = 1.0352582028933934, disc_loss = 0.0028515404389638987
Trained batch 35 in epoch 8, gen_loss = 1.0350896169741948, disc_loss = 0.002794756534664581
Trained batch 36 in epoch 8, gen_loss = 1.0349478286665839, disc_loss = 0.0027449677282994664
Trained batch 37 in epoch 8, gen_loss = 1.0346590735410388, disc_loss = 0.0026985818863307174
Trained batch 38 in epoch 8, gen_loss = 1.0345690082281063, disc_loss = 0.002647821542221862
Trained batch 39 in epoch 8, gen_loss = 1.034454818069935, disc_loss = 0.002599079934589099
Trained batch 40 in epoch 8, gen_loss = 1.0345600421835737, disc_loss = 0.0025655816794691107
Trained batch 41 in epoch 8, gen_loss = 1.0328285637355985, disc_loss = 0.002533356887787314
Trained batch 42 in epoch 8, gen_loss = 1.0320382242979005, disc_loss = 0.0025013431941895464
Trained batch 43 in epoch 8, gen_loss = 1.0316391384059733, disc_loss = 0.0024695329153804446
Trained batch 44 in epoch 8, gen_loss = 1.0319300638304816, disc_loss = 0.002435055071125842
Trained batch 45 in epoch 8, gen_loss = 1.032653457444647, disc_loss = 0.002409823308445756
Trained batch 46 in epoch 8, gen_loss = 1.0325454181813178, disc_loss = 0.002394982223507968
Trained batch 47 in epoch 8, gen_loss = 1.031902153044939, disc_loss = 0.002369010596642814
Trained batch 48 in epoch 8, gen_loss = 1.030314719190403, disc_loss = 0.0023460334240534932
Trained batch 49 in epoch 8, gen_loss = 1.0313456094264983, disc_loss = 0.0023303955339360983
Trained batch 50 in epoch 8, gen_loss = 1.0306355415606032, disc_loss = 0.0023049001465551555
Trained batch 51 in epoch 8, gen_loss = 1.0305241713157067, disc_loss = 0.0022813689395731604
Trained batch 52 in epoch 8, gen_loss = 1.0305021573912423, disc_loss = 0.0022547942166708692
Trained batch 53 in epoch 8, gen_loss = 1.0307459279342934, disc_loss = 0.00226896825888953
Trained batch 54 in epoch 8, gen_loss = 1.0285835363648155, disc_loss = 0.002294350217562169
Trained batch 55 in epoch 8, gen_loss = 1.0277397281357221, disc_loss = 0.0022738914839075214
Trained batch 56 in epoch 8, gen_loss = 1.028048298860851, disc_loss = 0.002258178885217364
Trained batch 57 in epoch 8, gen_loss = 1.0278523841808582, disc_loss = 0.0022381276086952282
Trained batch 58 in epoch 8, gen_loss = 1.026969416666839, disc_loss = 0.002218958230144581
Trained batch 59 in epoch 8, gen_loss = 1.0256406843662262, disc_loss = 0.0022015445273912823
Trained batch 60 in epoch 8, gen_loss = 1.0252993028672015, disc_loss = 0.0021890612294302
Trained batch 61 in epoch 8, gen_loss = 1.0250520898449806, disc_loss = 0.0021673795962405783
Trained batch 62 in epoch 8, gen_loss = 1.024547655431051, disc_loss = 0.002157928741773561
Trained batch 63 in epoch 8, gen_loss = 1.0234822435304523, disc_loss = 0.002145738550098031
Trained batch 64 in epoch 8, gen_loss = 1.022992272560413, disc_loss = 0.0021319004116006767
Trained batch 65 in epoch 8, gen_loss = 1.022445374366009, disc_loss = 0.002113763026004149
Trained batch 66 in epoch 8, gen_loss = 1.0226423606943729, disc_loss = 0.002101189338727229
Trained batch 67 in epoch 8, gen_loss = 1.0226705889491474, disc_loss = 0.0020891976241460618
Trained batch 68 in epoch 8, gen_loss = 1.0216726021490234, disc_loss = 0.0020830822632769527
Trained batch 69 in epoch 8, gen_loss = 1.0212565881865365, disc_loss = 0.002068331405254347
Trained batch 70 in epoch 8, gen_loss = 1.021049632153041, disc_loss = 0.0020553806048988457
Trained batch 71 in epoch 8, gen_loss = 1.020575584636794, disc_loss = 0.0020448256481257784
Trained batch 72 in epoch 8, gen_loss = 1.0194864877282757, disc_loss = 0.0020308496178548835
Trained batch 73 in epoch 8, gen_loss = 1.0191022165723749, disc_loss = 0.002018314348911313
Trained batch 74 in epoch 8, gen_loss = 1.0188289634386698, disc_loss = 0.0020108839015786847
Trained batch 75 in epoch 8, gen_loss = 1.018015919547332, disc_loss = 0.002004431202198918
Trained batch 76 in epoch 8, gen_loss = 1.0179582323346819, disc_loss = 0.0019901238847523928
Trained batch 77 in epoch 8, gen_loss = 1.0177392806762304, disc_loss = 0.0019750937040393744
Trained batch 78 in epoch 8, gen_loss = 1.0177531121652337, disc_loss = 0.001963694767047993
Trained batch 79 in epoch 8, gen_loss = 1.0182447195053101, disc_loss = 0.0019637942299596035
Trained batch 80 in epoch 8, gen_loss = 1.0177129323099867, disc_loss = 0.0019553240322519416
Trained batch 81 in epoch 8, gen_loss = 1.0168445590065747, disc_loss = 0.0019484621745238944
Trained batch 82 in epoch 8, gen_loss = 1.0166903576218937, disc_loss = 0.0019408747811902717
Trained batch 83 in epoch 8, gen_loss = 1.0172915032931737, disc_loss = 0.0019900601889405933
Trained batch 84 in epoch 8, gen_loss = 1.0158456367604873, disc_loss = 0.0020415724309928275
Trained batch 85 in epoch 8, gen_loss = 1.0154983976552652, disc_loss = 0.002053431118838489
Trained batch 86 in epoch 8, gen_loss = 1.0164396646379055, disc_loss = 0.0020705449004154437
Trained batch 87 in epoch 8, gen_loss = 1.0161036232655698, disc_loss = 0.0020749757293908096
Trained batch 88 in epoch 8, gen_loss = 1.015361566891831, disc_loss = 0.0020680171254436287
Trained batch 89 in epoch 8, gen_loss = 1.0151394075817533, disc_loss = 0.0020576013756605487
Trained batch 90 in epoch 8, gen_loss = 1.0146320815924759, disc_loss = 0.002045855742295856
Trained batch 91 in epoch 8, gen_loss = 1.0143531049075334, disc_loss = 0.002037086496230863
Trained batch 92 in epoch 8, gen_loss = 1.0141392721924731, disc_loss = 0.0020275095788141093
Trained batch 93 in epoch 8, gen_loss = 1.014238529382868, disc_loss = 0.0020200608191674853
Trained batch 94 in epoch 8, gen_loss = 1.013806710745159, disc_loss = 0.0020114161319246416
Trained batch 95 in epoch 8, gen_loss = 1.013966957728068, disc_loss = 0.0020091110976257673
Trained batch 96 in epoch 8, gen_loss = 1.013257574789303, disc_loss = 0.0019996331959060325
Trained batch 97 in epoch 8, gen_loss = 1.0125884796891893, disc_loss = 0.0019915966264789507
Trained batch 98 in epoch 8, gen_loss = 1.012759713813512, disc_loss = 0.001991176776672629
Trained batch 99 in epoch 8, gen_loss = 1.0123571491241454, disc_loss = 0.001991630933480337
Trained batch 100 in epoch 8, gen_loss = 1.012280303652924, disc_loss = 0.0020043214905250926
Trained batch 101 in epoch 8, gen_loss = 1.0117638578601913, disc_loss = 0.002008133048566022
Trained batch 102 in epoch 8, gen_loss = 1.0114916279477981, disc_loss = 0.0020013428372285752
Trained batch 103 in epoch 8, gen_loss = 1.011712090900311, disc_loss = 0.001997374951875267
Trained batch 104 in epoch 8, gen_loss = 1.011268505028316, disc_loss = 0.002006811136379838
Trained batch 105 in epoch 8, gen_loss = 1.0111090765809112, disc_loss = 0.002004732829211104
Trained batch 106 in epoch 8, gen_loss = 1.0110417682433797, disc_loss = 0.001996567236720889
Trained batch 107 in epoch 8, gen_loss = 1.0105704146402854, disc_loss = 0.0019938485800392097
Trained batch 108 in epoch 8, gen_loss = 1.0106517207731895, disc_loss = 0.002017353289683751
Trained batch 109 in epoch 8, gen_loss = 1.0102222269231622, disc_loss = 0.0020266017072241415
Trained batch 110 in epoch 8, gen_loss = 1.0096785936269674, disc_loss = 0.002032543549330922
Trained batch 111 in epoch 8, gen_loss = 1.01012058449643, disc_loss = 0.002029934070638514
Trained batch 112 in epoch 8, gen_loss = 1.0094858597865146, disc_loss = 0.0020201221773961343
Trained batch 113 in epoch 8, gen_loss = 1.0097534876120717, disc_loss = 0.0020132245702195193
Trained batch 114 in epoch 8, gen_loss = 1.009438681602478, disc_loss = 0.00201769615219825
Trained batch 115 in epoch 8, gen_loss = 1.0087538484869332, disc_loss = 0.002021144590830302
Trained batch 116 in epoch 8, gen_loss = 1.0089791381460989, disc_loss = 0.0020176314432412768
Trained batch 117 in epoch 8, gen_loss = 1.0090226086519531, disc_loss = 0.0020422937863474808
Trained batch 118 in epoch 8, gen_loss = 1.007123653628245, disc_loss = 0.0020880352778109806
Trained batch 119 in epoch 8, gen_loss = 1.007911996046702, disc_loss = 0.0020999099040636795
Trained batch 120 in epoch 8, gen_loss = 1.0088115694109074, disc_loss = 0.002103567830564008
Trained batch 121 in epoch 8, gen_loss = 1.0081157205534763, disc_loss = 0.0021053484600938124
Trained batch 122 in epoch 8, gen_loss = 1.007376311755762, disc_loss = 0.002110189982553626
Trained batch 123 in epoch 8, gen_loss = 1.0076005540547832, disc_loss = 0.0021140923950776097
Trained batch 124 in epoch 8, gen_loss = 1.0078308253288268, disc_loss = 0.0021141277523711323
Trained batch 125 in epoch 8, gen_loss = 1.0077175796031952, disc_loss = 0.0021095151102007736
Trained batch 126 in epoch 8, gen_loss = 1.0080156180802293, disc_loss = 0.002104965347510682
Trained batch 127 in epoch 8, gen_loss = 1.0076449122279882, disc_loss = 0.0020998339659854537
Trained batch 128 in epoch 8, gen_loss = 1.0071904354317243, disc_loss = 0.0020953030731572313
Trained batch 129 in epoch 8, gen_loss = 1.0071066828874442, disc_loss = 0.002089189555352697
Trained batch 130 in epoch 8, gen_loss = 1.0070038965640178, disc_loss = 0.002084923693057121
Trained batch 131 in epoch 8, gen_loss = 1.0067987198179418, disc_loss = 0.0020828517427258757
Trained batch 132 in epoch 8, gen_loss = 1.006709387427882, disc_loss = 0.0020909557001721254
Trained batch 133 in epoch 8, gen_loss = 1.0061706602573395, disc_loss = 0.002091465021810258
Trained batch 134 in epoch 8, gen_loss = 1.0060932022553903, disc_loss = 0.002086239459027571
Trained batch 135 in epoch 8, gen_loss = 1.0059199661893004, disc_loss = 0.0020844736752812475
Trained batch 136 in epoch 8, gen_loss = 1.0055733088159213, disc_loss = 0.002082858960327767
Trained batch 137 in epoch 8, gen_loss = 1.0053981015647666, disc_loss = 0.0020892383527361612
Trained batch 138 in epoch 8, gen_loss = 1.00507392686048, disc_loss = 0.002089843326482734
Trained batch 139 in epoch 8, gen_loss = 1.0049432166985104, disc_loss = 0.0020932438533886205
Trained batch 140 in epoch 8, gen_loss = 1.0047339167155274, disc_loss = 0.002088132421717259
Trained batch 141 in epoch 8, gen_loss = 1.0043049991970332, disc_loss = 0.0020813994014530746
Trained batch 142 in epoch 8, gen_loss = 1.0044497401564272, disc_loss = 0.0020755294488964383
Trained batch 143 in epoch 8, gen_loss = 1.004539160264863, disc_loss = 0.0020680364994202843
Trained batch 144 in epoch 8, gen_loss = 1.0037084398598506, disc_loss = 0.0020637446580904313
Trained batch 145 in epoch 8, gen_loss = 1.0033138920999554, disc_loss = 0.0020593795064224366
Trained batch 146 in epoch 8, gen_loss = 1.003542647475288, disc_loss = 0.002056696109289975
Trained batch 147 in epoch 8, gen_loss = 1.003521922069627, disc_loss = 0.0020561835553962737
Trained batch 148 in epoch 8, gen_loss = 1.0030595656209345, disc_loss = 0.0020534858871688877
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.029425859451294, disc_loss = 0.0010737271513789892
Trained batch 1 in epoch 9, gen_loss = 1.0151531100273132, disc_loss = 0.0009119322057813406
Trained batch 2 in epoch 9, gen_loss = 1.0045889218648274, disc_loss = 0.0008892947031805912
Trained batch 3 in epoch 9, gen_loss = 0.9902079999446869, disc_loss = 0.0008785405370872468
Trained batch 4 in epoch 9, gen_loss = 0.9919253587722778, disc_loss = 0.000876561610493809
Trained batch 5 in epoch 9, gen_loss = 0.9924820959568024, disc_loss = 0.0008828003968422612
Trained batch 6 in epoch 9, gen_loss = 0.9896816611289978, disc_loss = 0.0009047055084790502
Trained batch 7 in epoch 9, gen_loss = 0.9930092468857765, disc_loss = 0.0009555123979225755
Trained batch 8 in epoch 9, gen_loss = 0.9856564998626709, disc_loss = 0.0010426304846381147
Trained batch 9 in epoch 9, gen_loss = 0.9861535727977753, disc_loss = 0.0010432601091451942
Trained batch 10 in epoch 9, gen_loss = 0.993109708482569, disc_loss = 0.0011379898589273746
Trained batch 11 in epoch 9, gen_loss = 0.9916903873284658, disc_loss = 0.001150764854780088
Trained batch 12 in epoch 9, gen_loss = 0.9864575862884521, disc_loss = 0.0012242667054614196
Trained batch 13 in epoch 9, gen_loss = 0.9936776501791817, disc_loss = 0.0013019073521718383
Trained batch 14 in epoch 9, gen_loss = 0.9947551886240641, disc_loss = 0.0012957934678221742
Trained batch 15 in epoch 9, gen_loss = 0.9934971034526825, disc_loss = 0.0012907089330838062
Trained batch 16 in epoch 9, gen_loss = 0.9922184803906609, disc_loss = 0.0012791645576191299
Trained batch 17 in epoch 9, gen_loss = 0.993232356177436, disc_loss = 0.0012601046118005696
Trained batch 18 in epoch 9, gen_loss = 0.9913665275824698, disc_loss = 0.0012792468187399209
Trained batch 19 in epoch 9, gen_loss = 0.9890958160161972, disc_loss = 0.001284391639637761
Trained batch 20 in epoch 9, gen_loss = 0.9869557874543327, disc_loss = 0.0012917502068116196
Trained batch 21 in epoch 9, gen_loss = 0.9907084405422211, disc_loss = 0.0013377425890542906
Trained batch 22 in epoch 9, gen_loss = 0.986503030942834, disc_loss = 0.001380370623614315
Trained batch 23 in epoch 9, gen_loss = 0.9870656679073969, disc_loss = 0.0013790453206941795
Trained batch 24 in epoch 9, gen_loss = 0.987212040424347, disc_loss = 0.001363803839776665
Trained batch 25 in epoch 9, gen_loss = 0.9875962780072138, disc_loss = 0.0013745330977074516
Trained batch 26 in epoch 9, gen_loss = 0.9873682039755362, disc_loss = 0.001394569091240151
Trained batch 27 in epoch 9, gen_loss = 0.987399582351957, disc_loss = 0.0013850183355056547
Trained batch 28 in epoch 9, gen_loss = 0.9857992344889147, disc_loss = 0.0013877164255345948
Trained batch 29 in epoch 9, gen_loss = 0.9882381995519002, disc_loss = 0.0014444332045968622
Trained batch 30 in epoch 9, gen_loss = 0.985661591252973, disc_loss = 0.0015115200996308799
Trained batch 31 in epoch 9, gen_loss = 0.9876349493861198, disc_loss = 0.0015312637351598823
Trained batch 32 in epoch 9, gen_loss = 0.9875987713987177, disc_loss = 0.0015430511204723382
Trained batch 33 in epoch 9, gen_loss = 0.9862367528326371, disc_loss = 0.0015459410171709297
Trained batch 34 in epoch 9, gen_loss = 0.9850873163768223, disc_loss = 0.0015314598617676113
Trained batch 35 in epoch 9, gen_loss = 0.9848649071322547, disc_loss = 0.0015109802593037279
Trained batch 36 in epoch 9, gen_loss = 0.9865076380807001, disc_loss = 0.0014993777180820503
Trained batch 37 in epoch 9, gen_loss = 0.9849987061400163, disc_loss = 0.0014882304868048155
Trained batch 38 in epoch 9, gen_loss = 0.9855931538801926, disc_loss = 0.0014833463072323073
Trained batch 39 in epoch 9, gen_loss = 0.9865341335535049, disc_loss = 0.001474796405818779
Trained batch 40 in epoch 9, gen_loss = 0.986015779216115, disc_loss = 0.0014666186762042344
Trained batch 41 in epoch 9, gen_loss = 0.9864819305283683, disc_loss = 0.001454023939524112
Trained batch 42 in epoch 9, gen_loss = 0.9867143270581268, disc_loss = 0.001446655013349427
Trained batch 43 in epoch 9, gen_loss = 0.9843623434955423, disc_loss = 0.0014665683834623037
Trained batch 44 in epoch 9, gen_loss = 0.9857115361425611, disc_loss = 0.0014852278490757776
Trained batch 45 in epoch 9, gen_loss = 0.9866401410621145, disc_loss = 0.001474676394339084
Trained batch 46 in epoch 9, gen_loss = 0.9837585877864918, disc_loss = 0.001484015499528973
Trained batch 47 in epoch 9, gen_loss = 0.9835139053563277, disc_loss = 0.0014675424766513363
Trained batch 48 in epoch 9, gen_loss = 0.9845080533806159, disc_loss = 0.001463201724952657
Trained batch 49 in epoch 9, gen_loss = 0.9840968012809753, disc_loss = 0.00145311594940722
Trained batch 50 in epoch 9, gen_loss = 0.9833943586723477, disc_loss = 0.0014461757199765713
Trained batch 51 in epoch 9, gen_loss = 0.9836789117409632, disc_loss = 0.0014388697678581453
Trained batch 52 in epoch 9, gen_loss = 0.98314708808683, disc_loss = 0.0014312791304205948
Trained batch 53 in epoch 9, gen_loss = 0.9831326968140073, disc_loss = 0.0014242371910734586
Trained batch 54 in epoch 9, gen_loss = 0.9834901170297102, disc_loss = 0.0014484658689153465
Trained batch 55 in epoch 9, gen_loss = 0.9820682353207043, disc_loss = 0.0014561808659761613
Trained batch 56 in epoch 9, gen_loss = 0.9811353976266426, disc_loss = 0.0014581198134181793
Trained batch 57 in epoch 9, gen_loss = 0.9821701584191158, disc_loss = 0.001464726262854348
Trained batch 58 in epoch 9, gen_loss = 0.9830974441463665, disc_loss = 0.0014777860438482742
Trained batch 59 in epoch 9, gen_loss = 0.9808809032042821, disc_loss = 0.0015262679778970778
Trained batch 60 in epoch 9, gen_loss = 0.9800396415053821, disc_loss = 0.0015334412493727735
Trained batch 61 in epoch 9, gen_loss = 0.9821958157324022, disc_loss = 0.0016223216286650108
Trained batch 62 in epoch 9, gen_loss = 0.9823473455413939, disc_loss = 0.0016162879580247497
Trained batch 63 in epoch 9, gen_loss = 0.9804379912093282, disc_loss = 0.0016406930735684
Trained batch 64 in epoch 9, gen_loss = 0.9812844890814562, disc_loss = 0.001639332097525207
Trained batch 65 in epoch 9, gen_loss = 0.9815682832038763, disc_loss = 0.0016429082906776757
Trained batch 66 in epoch 9, gen_loss = 0.981138686635601, disc_loss = 0.0016407975040848798
Trained batch 67 in epoch 9, gen_loss = 0.9799941822009928, disc_loss = 0.0016463032516185194
Trained batch 68 in epoch 9, gen_loss = 0.9808151696039282, disc_loss = 0.0016512424715430193
Trained batch 69 in epoch 9, gen_loss = 0.9807481919016157, disc_loss = 0.0016423001453014358
Trained batch 70 in epoch 9, gen_loss = 0.9803470129698095, disc_loss = 0.0016297995339108395
Trained batch 71 in epoch 9, gen_loss = 0.980096846818924, disc_loss = 0.0016206449096595559
Trained batch 72 in epoch 9, gen_loss = 0.978933431514322, disc_loss = 0.001616160604586085
Trained batch 73 in epoch 9, gen_loss = 0.9783365170697909, disc_loss = 0.0016035266980415563
Trained batch 74 in epoch 9, gen_loss = 0.9785450498263041, disc_loss = 0.001596027180397262
Trained batch 75 in epoch 9, gen_loss = 0.9780447475220028, disc_loss = 0.0015888589941345057
Trained batch 76 in epoch 9, gen_loss = 0.9778021078605157, disc_loss = 0.0015848022757110173
Trained batch 77 in epoch 9, gen_loss = 0.9769427142082117, disc_loss = 0.0015819186713391293
Trained batch 78 in epoch 9, gen_loss = 0.9767308272892916, disc_loss = 0.001575280419297375
Trained batch 79 in epoch 9, gen_loss = 0.9767427705228329, disc_loss = 0.0015657494564948137
Trained batch 80 in epoch 9, gen_loss = 0.9764419462945726, disc_loss = 0.0015562039341513114
Trained batch 81 in epoch 9, gen_loss = 0.9764703599418082, disc_loss = 0.0015509801472412285
Trained batch 82 in epoch 9, gen_loss = 0.976358654269253, disc_loss = 0.001551600941036076
Trained batch 83 in epoch 9, gen_loss = 0.9752919702302842, disc_loss = 0.0015583688197823773
Trained batch 84 in epoch 9, gen_loss = 0.9754806756973267, disc_loss = 0.0015651955892441467
Trained batch 85 in epoch 9, gen_loss = 0.9752850095893062, disc_loss = 0.001587964428540016
Trained batch 86 in epoch 9, gen_loss = 0.9732478994062577, disc_loss = 0.001615763884760311
Trained batch 87 in epoch 9, gen_loss = 0.9740437499501489, disc_loss = 0.001619740708768156
Trained batch 88 in epoch 9, gen_loss = 0.9745261253935568, disc_loss = 0.0016361096412142258
Trained batch 89 in epoch 9, gen_loss = 0.9744770063294305, disc_loss = 0.0016438248509075492
Trained batch 90 in epoch 9, gen_loss = 0.9743057581094595, disc_loss = 0.0016409179578269167
Trained batch 91 in epoch 9, gen_loss = 0.9739085338685823, disc_loss = 0.0016446887362373832
Trained batch 92 in epoch 9, gen_loss = 0.9734494288762411, disc_loss = 0.0016395778111082011
Trained batch 93 in epoch 9, gen_loss = 0.9733749304680114, disc_loss = 0.001631532441527444
Trained batch 94 in epoch 9, gen_loss = 0.9733176513722068, disc_loss = 0.0016255268900606194
Trained batch 95 in epoch 9, gen_loss = 0.9734790654232105, disc_loss = 0.0016312849111272953
Trained batch 96 in epoch 9, gen_loss = 0.9730859865847322, disc_loss = 0.0016423980393398977
Trained batch 97 in epoch 9, gen_loss = 0.9733429867394117, disc_loss = 0.001646722769079616
Trained batch 98 in epoch 9, gen_loss = 0.9734221341634037, disc_loss = 0.0016436210440735172
Trained batch 99 in epoch 9, gen_loss = 0.9730376499891281, disc_loss = 0.0016341852222103625
Trained batch 100 in epoch 9, gen_loss = 0.9726239330697768, disc_loss = 0.0016266522522195067
Trained batch 101 in epoch 9, gen_loss = 0.9720563865175434, disc_loss = 0.0016507596735084685
Trained batch 102 in epoch 9, gen_loss = 0.9710638251119447, disc_loss = 0.0016603575159289232
Trained batch 103 in epoch 9, gen_loss = 0.971059819826713, disc_loss = 0.0016763150090880047
Trained batch 104 in epoch 9, gen_loss = 0.9703469963300796, disc_loss = 0.001691296022008395
Trained batch 105 in epoch 9, gen_loss = 0.9706427348109911, disc_loss = 0.0016891761712580567
Trained batch 106 in epoch 9, gen_loss = 0.9709905525234258, disc_loss = 0.0016861595077414032
Trained batch 107 in epoch 9, gen_loss = 0.9714696390761269, disc_loss = 0.0016803408286284172
Trained batch 108 in epoch 9, gen_loss = 0.9719089811001349, disc_loss = 0.0016789128485887627
Trained batch 109 in epoch 9, gen_loss = 0.9706692256710746, disc_loss = 0.0017202499994627115
Trained batch 110 in epoch 9, gen_loss = 0.975358860449748, disc_loss = 0.003219703774005678
Trained batch 111 in epoch 9, gen_loss = 0.9668419991752931, disc_loss = 0.006529922937521145
Trained batch 112 in epoch 9, gen_loss = 0.9661245179914795, disc_loss = 0.009488876092564973
Trained batch 113 in epoch 9, gen_loss = 0.964701962314154, disc_loss = 0.012762465178782708
Trained batch 114 in epoch 9, gen_loss = 0.9607113016688306, disc_loss = 0.015708229277262706
Trained batch 115 in epoch 9, gen_loss = 0.9545856490731239, disc_loss = 0.017471664624814556
Trained batch 116 in epoch 9, gen_loss = 0.9500393026914352, disc_loss = 0.01865181614173194
Trained batch 117 in epoch 9, gen_loss = 0.9460272147493848, disc_loss = 0.019798150451329016
Trained batch 118 in epoch 9, gen_loss = 0.9408041889927968, disc_loss = 0.020789582258336905
Trained batch 119 in epoch 9, gen_loss = 0.9353921487927437, disc_loss = 0.02172149128697735
Trained batch 120 in epoch 9, gen_loss = 0.9309200664197118, disc_loss = 0.022487792663164592
Trained batch 121 in epoch 9, gen_loss = 0.9270184499318482, disc_loss = 0.023080981053606623
Trained batch 122 in epoch 9, gen_loss = 0.9230672625022206, disc_loss = 0.02372527625970164
Trained batch 123 in epoch 9, gen_loss = 0.9193180237085589, disc_loss = 0.024131216236010885
Trained batch 124 in epoch 9, gen_loss = 0.9161907815933228, disc_loss = 0.024542077667545528
Trained batch 125 in epoch 9, gen_loss = 0.9121406761899827, disc_loss = 0.024956965205048965
Trained batch 126 in epoch 9, gen_loss = 0.9117240814242776, disc_loss = 0.02578645657819483
Trained batch 127 in epoch 9, gen_loss = 0.907655076123774, disc_loss = 0.02719583287353089
Trained batch 128 in epoch 9, gen_loss = 0.9053129914195038, disc_loss = 0.029198044903356177
Trained batch 129 in epoch 9, gen_loss = 0.9053475457888384, disc_loss = 0.03324977750486981
Trained batch 130 in epoch 9, gen_loss = 0.90488725400153, disc_loss = 0.03569565060013507
Trained batch 131 in epoch 9, gen_loss = 0.9011139560377959, disc_loss = 0.036741409513827726
Trained batch 132 in epoch 9, gen_loss = 0.8973551421685326, disc_loss = 0.03754644393456988
Trained batch 133 in epoch 9, gen_loss = 0.8939704812729536, disc_loss = 0.03823721203770586
Trained batch 134 in epoch 9, gen_loss = 0.890585473731712, disc_loss = 0.03870664543118673
Trained batch 135 in epoch 9, gen_loss = 0.8900328300455037, disc_loss = 0.03933832504716359
Trained batch 136 in epoch 9, gen_loss = 0.8862528046117212, disc_loss = 0.0416514118177388
Trained batch 137 in epoch 9, gen_loss = 0.8862069817124933, disc_loss = 0.04319049823528115
Trained batch 138 in epoch 9, gen_loss = 0.8830276058732177, disc_loss = 0.04372890824879178
Trained batch 139 in epoch 9, gen_loss = 0.8803223695073809, disc_loss = 0.04413873404888104
Trained batch 140 in epoch 9, gen_loss = 0.8776214492659197, disc_loss = 0.044362349138043634
Trained batch 141 in epoch 9, gen_loss = 0.8746946298740279, disc_loss = 0.04447020963449228
Trained batch 142 in epoch 9, gen_loss = 0.87583730229131, disc_loss = 0.04467904771526728
Trained batch 143 in epoch 9, gen_loss = 0.8717070644100507, disc_loss = 0.045075511410686886
Trained batch 144 in epoch 9, gen_loss = 0.8715018564257129, disc_loss = 0.045437359867280286
Trained batch 145 in epoch 9, gen_loss = 0.8697124303203739, disc_loss = 0.04535490229099109
Trained batch 146 in epoch 9, gen_loss = 0.8694475520224798, disc_loss = 0.0451685147685455
Trained batch 147 in epoch 9, gen_loss = 0.8682177235951295, disc_loss = 0.0450010325290055
Trained batch 148 in epoch 9, gen_loss = 0.8697912116978792, disc_loss = 0.04497805242106356
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.2635166049003601, disc_loss = 0.11334057152271271
Trained batch 1 in epoch 10, gen_loss = 0.6849873960018158, disc_loss = 0.08861972019076347
Trained batch 2 in epoch 10, gen_loss = 0.7303607861200968, disc_loss = 0.06561491017540295
Trained batch 3 in epoch 10, gen_loss = 0.7284569442272186, disc_loss = 0.052953106351196766
Trained batch 4 in epoch 10, gen_loss = 0.7563297510147095, disc_loss = 0.044857711903750895
Trained batch 5 in epoch 10, gen_loss = 0.7775342067082723, disc_loss = 0.038341838866472244
Trained batch 6 in epoch 10, gen_loss = 0.8003395966121128, disc_loss = 0.03367117679278765
Trained batch 7 in epoch 10, gen_loss = 0.8204412162303925, disc_loss = 0.0300881426082924
Trained batch 8 in epoch 10, gen_loss = 0.8326120641496446, disc_loss = 0.027210774469292827
Trained batch 9 in epoch 10, gen_loss = 0.8378860175609588, disc_loss = 0.0257859047036618
Trained batch 10 in epoch 10, gen_loss = 0.8241768208417025, disc_loss = 0.02498352878981016
Trained batch 11 in epoch 10, gen_loss = 0.8493383526802063, disc_loss = 0.023858349188230932
Trained batch 12 in epoch 10, gen_loss = 0.85714302613185, disc_loss = 0.022544250859377477
Trained batch 13 in epoch 10, gen_loss = 0.8517281668526786, disc_loss = 0.022324074558647617
Trained batch 14 in epoch 10, gen_loss = 0.8726849397023518, disc_loss = 0.021580460450301566
Trained batch 15 in epoch 10, gen_loss = 0.8782861493527889, disc_loss = 0.020437805185792968
Trained batch 16 in epoch 10, gen_loss = 0.8742771043496973, disc_loss = 0.019693904391982976
Trained batch 17 in epoch 10, gen_loss = 0.8859712978204092, disc_loss = 0.019187068256239097
Trained batch 18 in epoch 10, gen_loss = 0.8829812501606188, disc_loss = 0.018648673633211536
Trained batch 19 in epoch 10, gen_loss = 0.8876417309045792, disc_loss = 0.017932946886867286
Trained batch 20 in epoch 10, gen_loss = 0.890936036904653, disc_loss = 0.01723079511984473
Trained batch 21 in epoch 10, gen_loss = 0.8967590738426555, disc_loss = 0.016598510079678486
Trained batch 22 in epoch 10, gen_loss = 0.8972986314607703, disc_loss = 0.01612619034257596
Trained batch 23 in epoch 10, gen_loss = 0.8956455315152804, disc_loss = 0.01571889210996839
Trained batch 24 in epoch 10, gen_loss = 0.8998482298851013, disc_loss = 0.015259646652266383
Trained batch 25 in epoch 10, gen_loss = 0.9001186696382669, disc_loss = 0.014819984198906101
Trained batch 26 in epoch 10, gen_loss = 0.904154709091893, disc_loss = 0.014428338950016984
Trained batch 27 in epoch 10, gen_loss = 0.90371102307524, disc_loss = 0.014104753067450864
Trained batch 28 in epoch 10, gen_loss = 0.9056924519867733, disc_loss = 0.013831786570492489
Trained batch 29 in epoch 10, gen_loss = 0.9063575188318889, disc_loss = 0.01377675007097423
Trained batch 30 in epoch 10, gen_loss = 0.9060384784975359, disc_loss = 0.01388157491061476
Trained batch 31 in epoch 10, gen_loss = 0.914798790588975, disc_loss = 0.01516767249268014
Trained batch 32 in epoch 10, gen_loss = 0.8980163633823395, disc_loss = 0.01801362166632757
Trained batch 33 in epoch 10, gen_loss = 0.9073128673960181, disc_loss = 0.024008661357905057
Trained batch 34 in epoch 10, gen_loss = 0.8974026909896305, disc_loss = 0.026699710810290916
Trained batch 35 in epoch 10, gen_loss = 0.8952567983004782, disc_loss = 0.02803079066021989
Trained batch 36 in epoch 10, gen_loss = 0.8914626925378233, disc_loss = 0.028025842712235613
Trained batch 37 in epoch 10, gen_loss = 0.8908347322752601, disc_loss = 0.027896041700028275
Trained batch 38 in epoch 10, gen_loss = 0.887096263659306, disc_loss = 0.02768389991699503
Trained batch 39 in epoch 10, gen_loss = 0.8911680363118648, disc_loss = 0.02749934607418254
Trained batch 40 in epoch 10, gen_loss = 0.8898511056492968, disc_loss = 0.0272779144096847
Trained batch 41 in epoch 10, gen_loss = 0.891337493345851, disc_loss = 0.026833379253124196
Trained batch 42 in epoch 10, gen_loss = 0.8942330680614294, disc_loss = 0.02639508077354972
Trained batch 43 in epoch 10, gen_loss = 0.8982441066340967, disc_loss = 0.02599358026319268
Trained batch 44 in epoch 10, gen_loss = 0.8982954482237498, disc_loss = 0.02573897781678372
Trained batch 45 in epoch 10, gen_loss = 0.903370241108148, disc_loss = 0.025339643268481545
Trained batch 46 in epoch 10, gen_loss = 0.9037061213178837, disc_loss = 0.0249522541193886
Trained batch 47 in epoch 10, gen_loss = 0.9029255962620178, disc_loss = 0.024592928142131616
Trained batch 48 in epoch 10, gen_loss = 0.9064600035852316, disc_loss = 0.024194016701028664
Trained batch 49 in epoch 10, gen_loss = 0.9083831292390824, disc_loss = 0.023826889218762515
Trained batch 50 in epoch 10, gen_loss = 0.9077263071256525, disc_loss = 0.02349072535905768
Trained batch 51 in epoch 10, gen_loss = 0.9109962267371324, disc_loss = 0.02310635873940415
Trained batch 52 in epoch 10, gen_loss = 0.9132269851441653, disc_loss = 0.022798485351058672
Trained batch 53 in epoch 10, gen_loss = 0.9145459759014624, disc_loss = 0.022493000107782858
Trained batch 54 in epoch 10, gen_loss = 0.9133801162242889, disc_loss = 0.02223186638544906
Trained batch 55 in epoch 10, gen_loss = 0.9208016443465438, disc_loss = 0.022164482590077177
Trained batch 56 in epoch 10, gen_loss = 0.9176017469481418, disc_loss = 0.022016219680377265
Trained batch 57 in epoch 10, gen_loss = 0.9173489927217878, disc_loss = 0.021733432687048256
Trained batch 58 in epoch 10, gen_loss = 0.9217792744353667, disc_loss = 0.021537568546452765
Trained batch 59 in epoch 10, gen_loss = 0.9202894275387128, disc_loss = 0.021322799132515988
Trained batch 60 in epoch 10, gen_loss = 0.9201731608539331, disc_loss = 0.021068555447959998
Trained batch 61 in epoch 10, gen_loss = 0.9228361869050611, disc_loss = 0.020820697221244053
Trained batch 62 in epoch 10, gen_loss = 0.9223131050193121, disc_loss = 0.02062796802067804
Trained batch 63 in epoch 10, gen_loss = 0.9248559041880071, disc_loss = 0.020391838865180034
Trained batch 64 in epoch 10, gen_loss = 0.9258085851485912, disc_loss = 0.02012206889115847
Trained batch 65 in epoch 10, gen_loss = 0.9256168030428163, disc_loss = 0.019878265045752578
Trained batch 66 in epoch 10, gen_loss = 0.9289803900825444, disc_loss = 0.019978574317282262
Trained batch 67 in epoch 10, gen_loss = 0.9213483035564423, disc_loss = 0.020767528912983835
Trained batch 68 in epoch 10, gen_loss = 0.9303602343020232, disc_loss = 0.02260083599232029
Trained batch 69 in epoch 10, gen_loss = 0.9257202352796282, disc_loss = 0.02280207022891513
Trained batch 70 in epoch 10, gen_loss = 0.9260780089338061, disc_loss = 0.02394068012223907
Trained batch 71 in epoch 10, gen_loss = 0.9168493863609102, disc_loss = 0.027149988771674946
Trained batch 72 in epoch 10, gen_loss = 0.9210395012816338, disc_loss = 0.030115114926832588
Trained batch 73 in epoch 10, gen_loss = 0.9160158215342341, disc_loss = 0.03091763163211982
Trained batch 74 in epoch 10, gen_loss = 0.9109182159105936, disc_loss = 0.03168234966074427
Trained batch 75 in epoch 10, gen_loss = 0.9086954515231284, disc_loss = 0.03199757166868566
Trained batch 76 in epoch 10, gen_loss = 0.9092330352052466, disc_loss = 0.03191336667068399
Trained batch 77 in epoch 10, gen_loss = 0.9047572796161358, disc_loss = 0.03210854536901491
Trained batch 78 in epoch 10, gen_loss = 0.9081441269645208, disc_loss = 0.03217341587584041
Trained batch 79 in epoch 10, gen_loss = 0.9050590425729752, disc_loss = 0.03214300521067344
Trained batch 80 in epoch 10, gen_loss = 0.9075959582387665, disc_loss = 0.03194336502893287
Trained batch 81 in epoch 10, gen_loss = 0.9095460917891526, disc_loss = 0.03169550877859498
Trained batch 82 in epoch 10, gen_loss = 0.9103391910173807, disc_loss = 0.031377463259296606
Trained batch 83 in epoch 10, gen_loss = 0.9111547413326445, disc_loss = 0.03108012315351516
Trained batch 84 in epoch 10, gen_loss = 0.9109949273221633, disc_loss = 0.030772472649593565
Trained batch 85 in epoch 10, gen_loss = 0.9122480327306792, disc_loss = 0.03046544486396881
Trained batch 86 in epoch 10, gen_loss = 0.9135221482693464, disc_loss = 0.030157956519517404
Trained batch 87 in epoch 10, gen_loss = 0.913445457816124, disc_loss = 0.029863986324264923
Trained batch 88 in epoch 10, gen_loss = 0.9137073078852022, disc_loss = 0.02959884853322017
Trained batch 89 in epoch 10, gen_loss = 0.9139278762870364, disc_loss = 0.029327668140952785
Trained batch 90 in epoch 10, gen_loss = 0.9154046675661108, disc_loss = 0.02906231596492804
Trained batch 91 in epoch 10, gen_loss = 0.9145860970020294, disc_loss = 0.028849183551400252
Trained batch 92 in epoch 10, gen_loss = 0.9175797995700631, disc_loss = 0.028655472271625074
Trained batch 93 in epoch 10, gen_loss = 0.9174245557886489, disc_loss = 0.0284078064364718
Trained batch 94 in epoch 10, gen_loss = 0.91660712769157, disc_loss = 0.028187788870969885
Trained batch 95 in epoch 10, gen_loss = 0.918993353843689, disc_loss = 0.027963133916879695
Trained batch 96 in epoch 10, gen_loss = 0.9195414332999396, disc_loss = 0.02771108896836408
Trained batch 97 in epoch 10, gen_loss = 0.9193522674696786, disc_loss = 0.027474961797136585
Trained batch 98 in epoch 10, gen_loss = 0.9200957080330512, disc_loss = 0.02722274029928476
Trained batch 99 in epoch 10, gen_loss = 0.9219312638044357, disc_loss = 0.027091185417957603
Trained batch 100 in epoch 10, gen_loss = 0.9194462010175875, disc_loss = 0.027058600240599105
Trained batch 101 in epoch 10, gen_loss = 0.9218335648377737, disc_loss = 0.026952961208664028
Trained batch 102 in epoch 10, gen_loss = 0.9213424446513352, disc_loss = 0.026741793975957388
Trained batch 103 in epoch 10, gen_loss = 0.9226439675459495, disc_loss = 0.02656901631361017
Trained batch 104 in epoch 10, gen_loss = 0.921377017952147, disc_loss = 0.02645639856124208
Trained batch 105 in epoch 10, gen_loss = 0.9238872117591355, disc_loss = 0.02629583190142546
Trained batch 106 in epoch 10, gen_loss = 0.9245408182946321, disc_loss = 0.026095848095333465
Trained batch 107 in epoch 10, gen_loss = 0.9243488394551806, disc_loss = 0.025902232030165142
Trained batch 108 in epoch 10, gen_loss = 0.9254387917868588, disc_loss = 0.025691745802760124
Trained batch 109 in epoch 10, gen_loss = 0.9264694967053153, disc_loss = 0.025703762607140974
Trained batch 110 in epoch 10, gen_loss = 0.923381460679544, disc_loss = 0.025954751113245078
Trained batch 111 in epoch 10, gen_loss = 0.9273547200219971, disc_loss = 0.02596025601295488
Trained batch 112 in epoch 10, gen_loss = 0.9279592300938294, disc_loss = 0.02580200837908593
Trained batch 113 in epoch 10, gen_loss = 0.9275202359023847, disc_loss = 0.025660474539587374
Trained batch 114 in epoch 10, gen_loss = 0.9282282989958058, disc_loss = 0.025475287210682165
Trained batch 115 in epoch 10, gen_loss = 0.9286724339271414, disc_loss = 0.02528073126249465
Trained batch 116 in epoch 10, gen_loss = 0.9285344012782105, disc_loss = 0.02510381750881863
Trained batch 117 in epoch 10, gen_loss = 0.9286677938396648, disc_loss = 0.024915362998322282
Trained batch 118 in epoch 10, gen_loss = 0.929406739082657, disc_loss = 0.024729763323973333
Trained batch 119 in epoch 10, gen_loss = 0.9308258563280105, disc_loss = 0.02455271505944741
Trained batch 120 in epoch 10, gen_loss = 0.9312286150356954, disc_loss = 0.024370733446495468
Trained batch 121 in epoch 10, gen_loss = 0.9315885847709218, disc_loss = 0.0241992336862003
Trained batch 122 in epoch 10, gen_loss = 0.9316272817976107, disc_loss = 0.02402094537127248
Trained batch 123 in epoch 10, gen_loss = 0.932351422406012, disc_loss = 0.023846835262262292
Trained batch 124 in epoch 10, gen_loss = 0.9331050143241882, disc_loss = 0.02367492510192096
Trained batch 125 in epoch 10, gen_loss = 0.9332780355498904, disc_loss = 0.02352041690721221
Trained batch 126 in epoch 10, gen_loss = 0.9333587176217808, disc_loss = 0.023370571641662105
Trained batch 127 in epoch 10, gen_loss = 0.9349592314101756, disc_loss = 0.023219817065182724
Trained batch 128 in epoch 10, gen_loss = 0.9358457100483798, disc_loss = 0.02306129835914214
Trained batch 129 in epoch 10, gen_loss = 0.9362379197890942, disc_loss = 0.022905901147840687
Trained batch 130 in epoch 10, gen_loss = 0.9370121250625785, disc_loss = 0.022750035804547084
Trained batch 131 in epoch 10, gen_loss = 0.9376505265633265, disc_loss = 0.022594638047104872
Trained batch 132 in epoch 10, gen_loss = 0.9378399938569033, disc_loss = 0.022445375022751495
Trained batch 133 in epoch 10, gen_loss = 0.9387478205695081, disc_loss = 0.022554876998678516
Trained batch 134 in epoch 10, gen_loss = 0.9355563048963194, disc_loss = 0.02285498669715943
Trained batch 135 in epoch 10, gen_loss = 0.9386319781050962, disc_loss = 0.022992618813398567
Trained batch 136 in epoch 10, gen_loss = 0.9380670877268714, disc_loss = 0.022908762212924278
Trained batch 137 in epoch 10, gen_loss = 0.9377374597217726, disc_loss = 0.022806205145636763
Trained batch 138 in epoch 10, gen_loss = 0.939445595947101, disc_loss = 0.022700772379531706
Trained batch 139 in epoch 10, gen_loss = 0.9405938080378942, disc_loss = 0.022579203785530157
Trained batch 140 in epoch 10, gen_loss = 0.9401078617319147, disc_loss = 0.022482107241525717
Trained batch 141 in epoch 10, gen_loss = 0.9407791818531466, disc_loss = 0.022348269239776362
Trained batch 142 in epoch 10, gen_loss = 0.9417944150371151, disc_loss = 0.022219967259862625
Trained batch 143 in epoch 10, gen_loss = 0.9428396510581175, disc_loss = 0.022090592841979943
Trained batch 144 in epoch 10, gen_loss = 0.9437970765705767, disc_loss = 0.021966351777443598
Trained batch 145 in epoch 10, gen_loss = 0.9437850766802487, disc_loss = 0.02183782576889514
Trained batch 146 in epoch 10, gen_loss = 0.9439838893559515, disc_loss = 0.02171124520451844
Trained batch 147 in epoch 10, gen_loss = 0.9444703649024706, disc_loss = 0.021588962874375284
Trained batch 148 in epoch 10, gen_loss = 0.944680105919806, disc_loss = 0.021476027718276385
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 1.0879929065704346, disc_loss = 0.003107050433754921
Trained batch 1 in epoch 11, gen_loss = 1.0537663102149963, disc_loss = 0.0029448734130710363
Trained batch 2 in epoch 11, gen_loss = 1.0079715251922607, disc_loss = 0.002854343969374895
Trained batch 3 in epoch 11, gen_loss = 0.9949841946363449, disc_loss = 0.0026457117637619376
Trained batch 4 in epoch 11, gen_loss = 1.0219212651252747, disc_loss = 0.0027818297035992145
Trained batch 5 in epoch 11, gen_loss = 1.0447804431120555, disc_loss = 0.00331589641670386
Trained batch 6 in epoch 11, gen_loss = 1.0355617148535592, disc_loss = 0.0032491648702749182
Trained batch 7 in epoch 11, gen_loss = 1.023026019334793, disc_loss = 0.0033172026451211423
Trained batch 8 in epoch 11, gen_loss = 1.01905937327279, disc_loss = 0.0032611781110366187
Trained batch 9 in epoch 11, gen_loss = 1.0302046954631805, disc_loss = 0.00355056244879961
Trained batch 10 in epoch 11, gen_loss = 1.027284318750555, disc_loss = 0.00355117274871604
Trained batch 11 in epoch 11, gen_loss = 1.0181460231542587, disc_loss = 0.003921469654111813
Trained batch 12 in epoch 11, gen_loss = 1.0294151993898244, disc_loss = 0.003908488666638732
Trained batch 13 in epoch 11, gen_loss = 1.03112159882273, disc_loss = 0.0038259627430566718
Trained batch 14 in epoch 11, gen_loss = 1.028326690196991, disc_loss = 0.0037803315557539464
Trained batch 15 in epoch 11, gen_loss = 1.0283044464886189, disc_loss = 0.0037557707400992513
Trained batch 16 in epoch 11, gen_loss = 1.027912760482115, disc_loss = 0.003649132079718744
Trained batch 17 in epoch 11, gen_loss = 1.0293021235201094, disc_loss = 0.003596450486737821
Trained batch 18 in epoch 11, gen_loss = 1.0325568757559125, disc_loss = 0.0035722317345636455
Trained batch 19 in epoch 11, gen_loss = 1.0299995601177216, disc_loss = 0.0035878237918950616
Trained batch 20 in epoch 11, gen_loss = 1.0256737697692144, disc_loss = 0.003622080343553708
Trained batch 21 in epoch 11, gen_loss = 1.0288130207495256, disc_loss = 0.003575629364191131
Trained batch 22 in epoch 11, gen_loss = 1.030465022377346, disc_loss = 0.003528965333395678
Trained batch 23 in epoch 11, gen_loss = 1.0307808021704357, disc_loss = 0.003583906509447843
Trained batch 24 in epoch 11, gen_loss = 1.0316727113723756, disc_loss = 0.0035940310545265674
Trained batch 25 in epoch 11, gen_loss = 1.031964783485119, disc_loss = 0.0036090108960007247
Trained batch 26 in epoch 11, gen_loss = 1.0282083771846913, disc_loss = 0.0036677938058144515
Trained batch 27 in epoch 11, gen_loss = 1.0306695167507445, disc_loss = 0.003635150713047811
Trained batch 28 in epoch 11, gen_loss = 1.0340084310235649, disc_loss = 0.003623182243057366
Trained batch 29 in epoch 11, gen_loss = 1.0349039057890574, disc_loss = 0.0035909147700294852
Trained batch 30 in epoch 11, gen_loss = 1.033677843309218, disc_loss = 0.0035442292404871795
Trained batch 31 in epoch 11, gen_loss = 1.0363484062254429, disc_loss = 0.00350451901613269
Trained batch 32 in epoch 11, gen_loss = 1.0372076937646577, disc_loss = 0.00346957707326069
Trained batch 33 in epoch 11, gen_loss = 1.0349538606755875, disc_loss = 0.0034489968983346924
Trained batch 34 in epoch 11, gen_loss = 1.0362273011888776, disc_loss = 0.0034008955183838095
Trained batch 35 in epoch 11, gen_loss = 1.037282384104199, disc_loss = 0.0033471265148061016
Trained batch 36 in epoch 11, gen_loss = 1.0375316690754246, disc_loss = 0.003299902580250558
Trained batch 37 in epoch 11, gen_loss = 1.0380430943087529, disc_loss = 0.0032635539996829863
Trained batch 38 in epoch 11, gen_loss = 1.0369812097304907, disc_loss = 0.003237124517536125
Trained batch 39 in epoch 11, gen_loss = 1.0365417569875717, disc_loss = 0.0032021206483477727
Trained batch 40 in epoch 11, gen_loss = 1.0378421777632179, disc_loss = 0.0031684856498386802
Trained batch 41 in epoch 11, gen_loss = 1.0395246091343107, disc_loss = 0.003134581119021667
Trained batch 42 in epoch 11, gen_loss = 1.039747152217599, disc_loss = 0.003093570890446562
Trained batch 43 in epoch 11, gen_loss = 1.0396669181910427, disc_loss = 0.00307014318108982
Trained batch 44 in epoch 11, gen_loss = 1.0391946262783474, disc_loss = 0.00306561853374458
Trained batch 45 in epoch 11, gen_loss = 1.0398208187974018, disc_loss = 0.0030657564031729557
Trained batch 46 in epoch 11, gen_loss = 1.0398581230894048, disc_loss = 0.0030616911727578398
Trained batch 47 in epoch 11, gen_loss = 1.0390492801864941, disc_loss = 0.0030491435536532663
Trained batch 48 in epoch 11, gen_loss = 1.0390538634086142, disc_loss = 0.003021813054778138
Trained batch 49 in epoch 11, gen_loss = 1.0394643664360046, disc_loss = 0.003000435153953731
Trained batch 50 in epoch 11, gen_loss = 1.039000955282473, disc_loss = 0.0029901166711294768
Trained batch 51 in epoch 11, gen_loss = 1.039336594251486, disc_loss = 0.00296483215284892
Trained batch 52 in epoch 11, gen_loss = 1.0399941565855495, disc_loss = 0.002956008674787744
Trained batch 53 in epoch 11, gen_loss = 1.0394198165999518, disc_loss = 0.002943071627265049
Trained batch 54 in epoch 11, gen_loss = 1.040039027820934, disc_loss = 0.0029503244525668298
Trained batch 55 in epoch 11, gen_loss = 1.0397596806287766, disc_loss = 0.002967503258592582
Trained batch 56 in epoch 11, gen_loss = 1.0399894086938155, disc_loss = 0.00295135590019064
Trained batch 57 in epoch 11, gen_loss = 1.0408538394960865, disc_loss = 0.002936452490695078
Trained batch 58 in epoch 11, gen_loss = 1.0406977059477467, disc_loss = 0.002909442133633262
Trained batch 59 in epoch 11, gen_loss = 1.0414743363857268, disc_loss = 0.0028775421902537345
Trained batch 60 in epoch 11, gen_loss = 1.0421695435633425, disc_loss = 0.002880261752937661
Trained batch 61 in epoch 11, gen_loss = 1.042702397992534, disc_loss = 0.002930079511697254
Trained batch 62 in epoch 11, gen_loss = 1.0414206063936626, disc_loss = 0.002943959744972369
Trained batch 63 in epoch 11, gen_loss = 1.0401315977796912, disc_loss = 0.0029475316987372935
Trained batch 64 in epoch 11, gen_loss = 1.04081351848749, disc_loss = 0.002940669344165004
Trained batch 65 in epoch 11, gen_loss = 1.040863054268288, disc_loss = 0.002915298012367478
Trained batch 66 in epoch 11, gen_loss = 1.0411961140917307, disc_loss = 0.002902741623875588
Trained batch 67 in epoch 11, gen_loss = 1.0415588345597773, disc_loss = 0.002883554497898063
Trained batch 68 in epoch 11, gen_loss = 1.0418480055919592, disc_loss = 0.0028623398713956494
Trained batch 69 in epoch 11, gen_loss = 1.0409857102802822, disc_loss = 0.002855387990296419
Trained batch 70 in epoch 11, gen_loss = 1.04242304009451, disc_loss = 0.0028485694759144958
Trained batch 71 in epoch 11, gen_loss = 1.0426958335770502, disc_loss = 0.002824422193548849
Trained batch 72 in epoch 11, gen_loss = 1.0404870077355268, disc_loss = 0.0028806070825850515
Trained batch 73 in epoch 11, gen_loss = 1.0405588576922546, disc_loss = 0.0029999662860850426
Trained batch 74 in epoch 11, gen_loss = 1.0394828740755717, disc_loss = 0.0030676569929346444
Trained batch 75 in epoch 11, gen_loss = 1.0406947331993204, disc_loss = 0.0030675732276377906
Trained batch 76 in epoch 11, gen_loss = 1.0414902304674123, disc_loss = 0.0030602931979342132
Trained batch 77 in epoch 11, gen_loss = 1.0409139685141735, disc_loss = 0.003095644999307413
Trained batch 78 in epoch 11, gen_loss = 1.0423774010018458, disc_loss = 0.003140770548754195
Trained batch 79 in epoch 11, gen_loss = 1.0412104584276676, disc_loss = 0.0031670060838223436
Trained batch 80 in epoch 11, gen_loss = 1.0414750671681063, disc_loss = 0.0031604019444964734
Trained batch 81 in epoch 11, gen_loss = 1.042193964487169, disc_loss = 0.003157643528893681
Trained batch 82 in epoch 11, gen_loss = 1.0427601660590573, disc_loss = 0.0031490437644365503
Trained batch 83 in epoch 11, gen_loss = 1.0432784096116112, disc_loss = 0.0031704930491590253
Trained batch 84 in epoch 11, gen_loss = 1.0410353120635538, disc_loss = 0.0032349407357875914
Trained batch 85 in epoch 11, gen_loss = 1.0430285424687142, disc_loss = 0.0032509716327821965
Trained batch 86 in epoch 11, gen_loss = 1.0434825591657353, disc_loss = 0.003247363304173381
Trained batch 87 in epoch 11, gen_loss = 1.0424775183200836, disc_loss = 0.003256648602969521
Trained batch 88 in epoch 11, gen_loss = 1.0421982400872734, disc_loss = 0.0032640837193100474
Trained batch 89 in epoch 11, gen_loss = 1.0428604907459682, disc_loss = 0.003258741306813641
Trained batch 90 in epoch 11, gen_loss = 1.0439563544241937, disc_loss = 0.003244268934365239
Trained batch 91 in epoch 11, gen_loss = 1.0445248497569042, disc_loss = 0.003226565260379373
Trained batch 92 in epoch 11, gen_loss = 1.0435804436283727, disc_loss = 0.003229426838437556
Trained batch 93 in epoch 11, gen_loss = 1.0435237795748609, disc_loss = 0.0032181027320590107
Trained batch 94 in epoch 11, gen_loss = 1.0442721705687674, disc_loss = 0.003239289207972194
Trained batch 95 in epoch 11, gen_loss = 1.0431411638855934, disc_loss = 0.0032470313235535286
Trained batch 96 in epoch 11, gen_loss = 1.0433868317259956, disc_loss = 0.003231026664299449
Trained batch 97 in epoch 11, gen_loss = 1.0439589437173338, disc_loss = 0.003217330960347792
Trained batch 98 in epoch 11, gen_loss = 1.044982935443069, disc_loss = 0.003263572407321948
Trained batch 99 in epoch 11, gen_loss = 1.0431080234050751, disc_loss = 0.003302390940953046
Trained batch 100 in epoch 11, gen_loss = 1.0434749586747425, disc_loss = 0.00329474366435984
Trained batch 101 in epoch 11, gen_loss = 1.043600714674183, disc_loss = 0.0032779121447318034
Trained batch 102 in epoch 11, gen_loss = 1.043678384382748, disc_loss = 0.003268644234020878
Trained batch 103 in epoch 11, gen_loss = 1.043970301747322, disc_loss = 0.0032550277963029938
Trained batch 104 in epoch 11, gen_loss = 1.0444413241885957, disc_loss = 0.0032384743492695546
Trained batch 105 in epoch 11, gen_loss = 1.0444115906391505, disc_loss = 0.003227039321571729
Trained batch 106 in epoch 11, gen_loss = 1.0438878714481248, disc_loss = 0.0032291108324566734
Trained batch 107 in epoch 11, gen_loss = 1.0445601873927646, disc_loss = 0.0032527638702756828
Trained batch 108 in epoch 11, gen_loss = 1.0439909816881932, disc_loss = 0.003244731297562702
Trained batch 109 in epoch 11, gen_loss = 1.0433963938192887, disc_loss = 0.0032376478722488337
Trained batch 110 in epoch 11, gen_loss = 1.043840344961699, disc_loss = 0.003220768379013952
Trained batch 111 in epoch 11, gen_loss = 1.043888621032238, disc_loss = 0.003206241247036295
Trained batch 112 in epoch 11, gen_loss = 1.0432038929610126, disc_loss = 0.003204756967550292
Trained batch 113 in epoch 11, gen_loss = 1.044012024737241, disc_loss = 0.0032028238025591954
Trained batch 114 in epoch 11, gen_loss = 1.0438604375590448, disc_loss = 0.003195729899301153
Trained batch 115 in epoch 11, gen_loss = 1.0440657919850842, disc_loss = 0.003194195823543223
Trained batch 116 in epoch 11, gen_loss = 1.0439534340149317, disc_loss = 0.003206521227884178
Trained batch 117 in epoch 11, gen_loss = 1.0433148630594804, disc_loss = 0.0032009674715651674
Trained batch 118 in epoch 11, gen_loss = 1.0430985378618, disc_loss = 0.0031839817020838626
Trained batch 119 in epoch 11, gen_loss = 1.0432671139637628, disc_loss = 0.0031755851339160773
Trained batch 120 in epoch 11, gen_loss = 1.0438395521857522, disc_loss = 0.003173362943805631
Trained batch 121 in epoch 11, gen_loss = 1.0440740184705766, disc_loss = 0.0031669305505795924
Trained batch 122 in epoch 11, gen_loss = 1.044116425320385, disc_loss = 0.0031579240249863605
Trained batch 123 in epoch 11, gen_loss = 1.0450496298651542, disc_loss = 0.0031579436702398405
Trained batch 124 in epoch 11, gen_loss = 1.0441059651374818, disc_loss = 0.003175543646328151
Trained batch 125 in epoch 11, gen_loss = 1.0462733360510024, disc_loss = 0.003244726559228545
Trained batch 126 in epoch 11, gen_loss = 1.044634260530547, disc_loss = 0.00331420228746903
Trained batch 127 in epoch 11, gen_loss = 1.0456322897225618, disc_loss = 0.003364460079865239
Trained batch 128 in epoch 11, gen_loss = 1.0453601641248362, disc_loss = 0.0033601185842958648
Trained batch 129 in epoch 11, gen_loss = 1.0446964639883776, disc_loss = 0.003396138589148625
Trained batch 130 in epoch 11, gen_loss = 1.0440171820516804, disc_loss = 0.003415150103116593
Trained batch 131 in epoch 11, gen_loss = 1.04557321378679, disc_loss = 0.0034338366072695476
Trained batch 132 in epoch 11, gen_loss = 1.0459603142917604, disc_loss = 0.0034256768894304792
Trained batch 133 in epoch 11, gen_loss = 1.0456256626257256, disc_loss = 0.0034098613081124623
Trained batch 134 in epoch 11, gen_loss = 1.0457277598204435, disc_loss = 0.0033939633233886625
Trained batch 135 in epoch 11, gen_loss = 1.0460314855856054, disc_loss = 0.003380205897402073
Trained batch 136 in epoch 11, gen_loss = 1.046035173165537, disc_loss = 0.0033666710479756017
Trained batch 137 in epoch 11, gen_loss = 1.0460821459258811, disc_loss = 0.0034184592676456964
Trained batch 138 in epoch 11, gen_loss = 1.0444431613675125, disc_loss = 0.003485799962219199
Trained batch 139 in epoch 11, gen_loss = 1.0460210621356965, disc_loss = 0.0035195191798266024
Trained batch 140 in epoch 11, gen_loss = 1.0463402600998575, disc_loss = 0.003506241656067048
Trained batch 141 in epoch 11, gen_loss = 1.0458698037644507, disc_loss = 0.0035093156251938306
Trained batch 142 in epoch 11, gen_loss = 1.0461800723642736, disc_loss = 0.0034999227162671987
Trained batch 143 in epoch 11, gen_loss = 1.046305121646987, disc_loss = 0.0034869204149193442
Trained batch 144 in epoch 11, gen_loss = 1.0470803211475241, disc_loss = 0.0034807761826006504
Trained batch 145 in epoch 11, gen_loss = 1.0463290071650728, disc_loss = 0.0034881676754544245
Trained batch 146 in epoch 11, gen_loss = 1.0460165889084745, disc_loss = 0.003484553632130023
Trained batch 147 in epoch 11, gen_loss = 1.0468751075300011, disc_loss = 0.0034814086912602587
Trained batch 148 in epoch 11, gen_loss = 1.0468487423538362, disc_loss = 0.003468591726116286
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 1.034513235092163, disc_loss = 0.004222852643579245
Trained batch 1 in epoch 12, gen_loss = 1.097764790058136, disc_loss = 0.003943536663427949
Trained batch 2 in epoch 12, gen_loss = 1.068633794784546, disc_loss = 0.003170047770254314
Trained batch 3 in epoch 12, gen_loss = 1.058098018169403, disc_loss = 0.0029197380936238915
Trained batch 4 in epoch 12, gen_loss = 1.0665722608566284, disc_loss = 0.002591471769846976
Trained batch 5 in epoch 12, gen_loss = 1.058880885442098, disc_loss = 0.0025449510236891606
Trained batch 6 in epoch 12, gen_loss = 1.0704575266156877, disc_loss = 0.0023926837935245465
Trained batch 7 in epoch 12, gen_loss = 1.0740434974431992, disc_loss = 0.0021890619609621353
Trained batch 8 in epoch 12, gen_loss = 1.0679078499476116, disc_loss = 0.002193909119038532
Trained batch 9 in epoch 12, gen_loss = 1.0628824472427367, disc_loss = 0.0021289962052833287
Trained batch 10 in epoch 12, gen_loss = 1.0757401314648716, disc_loss = 0.0026212137097238815
Trained batch 11 in epoch 12, gen_loss = 1.0446637173493702, disc_loss = 0.00442418275148763
Trained batch 12 in epoch 12, gen_loss = 1.091421594986549, disc_loss = 0.01605601327117676
Trained batch 13 in epoch 12, gen_loss = 1.0261067875794, disc_loss = 0.03353580251652082
Trained batch 14 in epoch 12, gen_loss = 1.0287335117657979, disc_loss = 0.04644712661004936
Trained batch 15 in epoch 12, gen_loss = 1.0300056599080563, disc_loss = 0.0644842689325742
Trained batch 16 in epoch 12, gen_loss = 1.0318169979488148, disc_loss = 0.08215513697702109
Trained batch 17 in epoch 12, gen_loss = 1.0150767465432484, disc_loss = 0.08562037559264961
Trained batch 18 in epoch 12, gen_loss = 0.9869648265211206, disc_loss = 0.0874334738779764
Trained batch 19 in epoch 12, gen_loss = 0.9716342017054558, disc_loss = 0.08908035162312444
Trained batch 20 in epoch 12, gen_loss = 0.9496773580710093, disc_loss = 0.08847827325475269
Trained batch 21 in epoch 12, gen_loss = 0.9442758953029459, disc_loss = 0.08734915103625761
Trained batch 22 in epoch 12, gen_loss = 0.9377867851568304, disc_loss = 0.08677027895591101
Trained batch 23 in epoch 12, gen_loss = 0.9286123203734556, disc_loss = 0.08456147899414646
Trained batch 24 in epoch 12, gen_loss = 0.9352140605449677, disc_loss = 0.08296700971899554
Trained batch 25 in epoch 12, gen_loss = 0.9251589465599793, disc_loss = 0.0818230136042425
Trained batch 26 in epoch 12, gen_loss = 0.9284616940551333, disc_loss = 0.07953925647005369
Trained batch 27 in epoch 12, gen_loss = 0.9334775943841253, disc_loss = 0.07738953425307825
Trained batch 28 in epoch 12, gen_loss = 0.9343282652312311, disc_loss = 0.07503565926514245
Trained batch 29 in epoch 12, gen_loss = 0.934943621357282, disc_loss = 0.07278104137900906
Trained batch 30 in epoch 12, gen_loss = 0.9394349253946735, disc_loss = 0.0705811385752543
Trained batch 31 in epoch 12, gen_loss = 0.9425681689754128, disc_loss = 0.06865084787386877
Trained batch 32 in epoch 12, gen_loss = 0.9430908804590051, disc_loss = 0.06684470412878771
Trained batch 33 in epoch 12, gen_loss = 0.9446343244875178, disc_loss = 0.0650337027190664
Trained batch 34 in epoch 12, gen_loss = 0.9475856500012534, disc_loss = 0.06335387440631166
Trained batch 35 in epoch 12, gen_loss = 0.9522791364126735, disc_loss = 0.062137139267482176
Trained batch 36 in epoch 12, gen_loss = 0.9498043793278772, disc_loss = 0.060701242854151675
Trained batch 37 in epoch 12, gen_loss = 0.9510392632923628, disc_loss = 0.059228931864613275
Trained batch 38 in epoch 12, gen_loss = 0.9553777277469635, disc_loss = 0.057871913517980524
Trained batch 39 in epoch 12, gen_loss = 0.9579672418534756, disc_loss = 0.056544090090028476
Trained batch 40 in epoch 12, gen_loss = 0.9582402146444088, disc_loss = 0.05526172559816254
Trained batch 41 in epoch 12, gen_loss = 0.9602022419373194, disc_loss = 0.05403196417388417
Trained batch 42 in epoch 12, gen_loss = 0.961631987677064, disc_loss = 0.052837289819699644
Trained batch 43 in epoch 12, gen_loss = 0.9640931317752058, disc_loss = 0.051698148884249596
Trained batch 44 in epoch 12, gen_loss = 0.9657728824350569, disc_loss = 0.05070470934604398
Trained batch 45 in epoch 12, gen_loss = 0.9656063324731329, disc_loss = 0.049716143695505984
Trained batch 46 in epoch 12, gen_loss = 0.9669513759460855, disc_loss = 0.048737429566631844
Trained batch 47 in epoch 12, gen_loss = 0.9685109835118055, disc_loss = 0.047780857061297866
Trained batch 48 in epoch 12, gen_loss = 0.9690284540458601, disc_loss = 0.04685741624847169
Trained batch 49 in epoch 12, gen_loss = 0.9720409876108169, disc_loss = 0.045960656706010926
Trained batch 50 in epoch 12, gen_loss = 0.9743662447321648, disc_loss = 0.04540185681795336
Trained batch 51 in epoch 12, gen_loss = 0.9692815800125782, disc_loss = 0.04519205390310022
Trained batch 52 in epoch 12, gen_loss = 0.9746905121038545, disc_loss = 0.044582102082028355
Trained batch 53 in epoch 12, gen_loss = 0.9791122923294703, disc_loss = 0.04387013761098152
Trained batch 54 in epoch 12, gen_loss = 0.9789946236393668, disc_loss = 0.04315607669996098
Trained batch 55 in epoch 12, gen_loss = 0.9793975550149169, disc_loss = 0.0424404240194625
Trained batch 56 in epoch 12, gen_loss = 0.9807855147018767, disc_loss = 0.04176558042251456
Trained batch 57 in epoch 12, gen_loss = 0.9823301110802025, disc_loss = 0.041128778857267304
Trained batch 58 in epoch 12, gen_loss = 0.982780420679157, disc_loss = 0.04055305159457375
Trained batch 59 in epoch 12, gen_loss = 0.9854027872284253, disc_loss = 0.03991980620097214
Trained batch 60 in epoch 12, gen_loss = 0.9877943333055152, disc_loss = 0.03931599017137234
Trained batch 61 in epoch 12, gen_loss = 0.9875373604797548, disc_loss = 0.038744355096564355
Trained batch 62 in epoch 12, gen_loss = 0.9871731121388693, disc_loss = 0.03820645522662542
Trained batch 63 in epoch 12, gen_loss = 0.9891801192425191, disc_loss = 0.037661646386368375
Trained batch 64 in epoch 12, gen_loss = 0.9901806680055765, disc_loss = 0.03710821739380033
Trained batch 65 in epoch 12, gen_loss = 0.9906994840412429, disc_loss = 0.03657532751711904
Trained batch 66 in epoch 12, gen_loss = 0.991995802121376, disc_loss = 0.03606617578510334
Trained batch 67 in epoch 12, gen_loss = 0.9938933108659351, disc_loss = 0.03557033754238065
Trained batch 68 in epoch 12, gen_loss = 0.9943630742853966, disc_loss = 0.03509108237567884
Trained batch 69 in epoch 12, gen_loss = 0.9939916861908776, disc_loss = 0.03462051942063096
Trained batch 70 in epoch 12, gen_loss = 0.9946187646456168, disc_loss = 0.034156176436226815
Trained batch 71 in epoch 12, gen_loss = 0.9957794691953394, disc_loss = 0.03376853109431169
Trained batch 72 in epoch 12, gen_loss = 0.9951900713247795, disc_loss = 0.03342630140473811
Trained batch 73 in epoch 12, gen_loss = 0.997314061264734, disc_loss = 0.03301769290575632
Trained batch 74 in epoch 12, gen_loss = 0.998931518793106, disc_loss = 0.03262871518808728
Trained batch 75 in epoch 12, gen_loss = 0.9982191241885486, disc_loss = 0.032274356798887696
Trained batch 76 in epoch 12, gen_loss = 0.9997873070178094, disc_loss = 0.031891843601123904
Trained batch 77 in epoch 12, gen_loss = 1.0021462574219093, disc_loss = 0.03156796646474574
Trained batch 78 in epoch 12, gen_loss = 1.0013657925249655, disc_loss = 0.031224373015545637
Trained batch 79 in epoch 12, gen_loss = 1.0035634737461805, disc_loss = 0.03088166328452644
Trained batch 80 in epoch 12, gen_loss = 1.0034446749422286, disc_loss = 0.03052765181084037
Trained batch 81 in epoch 12, gen_loss = 1.004078381308695, disc_loss = 0.030180707475221603
Trained batch 82 in epoch 12, gen_loss = 1.0047318809721844, disc_loss = 0.02987574086123404
Trained batch 83 in epoch 12, gen_loss = 1.0059843648757254, disc_loss = 0.029544184869293878
Trained batch 84 in epoch 12, gen_loss = 1.0066049775656531, disc_loss = 0.029225802545517904
Trained batch 85 in epoch 12, gen_loss = 1.0065786426150523, disc_loss = 0.028917801705172805
Trained batch 86 in epoch 12, gen_loss = 1.0088354667712902, disc_loss = 0.028621945656627287
Trained batch 87 in epoch 12, gen_loss = 1.010098866779696, disc_loss = 0.0283401734069974
Trained batch 88 in epoch 12, gen_loss = 1.0080630106202673, disc_loss = 0.028135179676078887
Trained batch 89 in epoch 12, gen_loss = 1.0120343893766404, disc_loss = 0.027956953270283216
Trained batch 90 in epoch 12, gen_loss = 1.0130789263562843, disc_loss = 0.02779419043492833
Trained batch 91 in epoch 12, gen_loss = 1.0092982406849447, disc_loss = 0.027860237071012227
Trained batch 92 in epoch 12, gen_loss = 1.0117019110469407, disc_loss = 0.02769871570623069
Trained batch 93 in epoch 12, gen_loss = 1.0123989851550852, disc_loss = 0.027455336229127655
Trained batch 94 in epoch 12, gen_loss = 1.012387785472368, disc_loss = 0.027250461155965335
Trained batch 95 in epoch 12, gen_loss = 1.013183098596831, disc_loss = 0.026994877063771128
Trained batch 96 in epoch 12, gen_loss = 1.0150544511288713, disc_loss = 0.02675340459117973
Trained batch 97 in epoch 12, gen_loss = 1.0168891892749437, disc_loss = 0.026516191495644232
Trained batch 98 in epoch 12, gen_loss = 1.0176983677377605, disc_loss = 0.02631249122681435
Trained batch 99 in epoch 12, gen_loss = 1.017435075342655, disc_loss = 0.026090120841399767
Trained batch 100 in epoch 12, gen_loss = 1.0186685232242736, disc_loss = 0.025855373234446574
Trained batch 101 in epoch 12, gen_loss = 1.0202979717184515, disc_loss = 0.025628611525890473
Trained batch 102 in epoch 12, gen_loss = 1.0209820909986218, disc_loss = 0.02539838296395175
Trained batch 103 in epoch 12, gen_loss = 1.0218217891569321, disc_loss = 0.02517744766877373
Trained batch 104 in epoch 12, gen_loss = 1.023004705849148, disc_loss = 0.02496311479148322
Trained batch 105 in epoch 12, gen_loss = 1.0237266199206405, disc_loss = 0.024750612170395953
Trained batch 106 in epoch 12, gen_loss = 1.0244365242597098, disc_loss = 0.02453051381646525
Trained batch 107 in epoch 12, gen_loss = 1.0254219795266788, disc_loss = 0.024329030010482745
Trained batch 108 in epoch 12, gen_loss = 1.026092711118383, disc_loss = 0.024127831709797605
Trained batch 109 in epoch 12, gen_loss = 1.0263922997496344, disc_loss = 0.023964660946512596
Trained batch 110 in epoch 12, gen_loss = 1.028474672689094, disc_loss = 0.023779381487648597
Trained batch 111 in epoch 12, gen_loss = 1.0295501641396965, disc_loss = 0.023582688618522037
Trained batch 112 in epoch 12, gen_loss = 1.0302488141882735, disc_loss = 0.02338953970249462
Trained batch 114 in epoch 12, gen_loss = 1.0331873284733815, disc_loss = 0.0230799146973447
Trained batch 115 in epoch 12, gen_loss = 1.0333810780068924, disc_loss = 0.022910938697068246
Trained batch 116 in epoch 12, gen_loss = 1.032545192883565, disc_loss = 0.02277751619834055
Trained batch 117 in epoch 12, gen_loss = 1.0348994219202106, disc_loss = 0.022638509399750886
Trained batch 118 in epoch 12, gen_loss = 1.035915549312319, disc_loss = 0.02248535831038206
Trained batch 119 in epoch 12, gen_loss = 1.0353204044202964, disc_loss = 0.022363478595798368
Trained batch 120 in epoch 12, gen_loss = 1.036315035475187, disc_loss = 0.02219548927137074
Trained batch 121 in epoch 12, gen_loss = 1.037572879527436, disc_loss = 0.022029217344529346
Trained batch 122 in epoch 12, gen_loss = 1.0385429066855734, disc_loss = 0.02194760373000404
Trained batch 123 in epoch 12, gen_loss = 1.0368123902909216, disc_loss = 0.021940561338616986
Trained batch 124 in epoch 12, gen_loss = 1.038947303056717, disc_loss = 0.021822324388194828
Trained batch 125 in epoch 12, gen_loss = 1.0404164481257636, disc_loss = 0.021673281655354898
Trained batch 126 in epoch 12, gen_loss = 1.040717293193021, disc_loss = 0.021532524643396212
Trained batch 127 in epoch 12, gen_loss = 1.0415097924415022, disc_loss = 0.02141437962791315
Trained batch 128 in epoch 12, gen_loss = 1.041278476169867, disc_loss = 0.021280169821355145
Trained batch 129 in epoch 12, gen_loss = 1.0418967130092474, disc_loss = 0.021142988360504836
Trained batch 130 in epoch 12, gen_loss = 1.0423973145830723, disc_loss = 0.021002384022194606
Trained batch 131 in epoch 12, gen_loss = 1.0436440428549594, disc_loss = 0.020867056395438725
Trained batch 132 in epoch 12, gen_loss = 1.0450126526499153, disc_loss = 0.02072825523564256
Trained batch 133 in epoch 12, gen_loss = 1.0454511769227128, disc_loss = 0.020586476335041366
Trained batch 134 in epoch 12, gen_loss = 1.0458656083654474, disc_loss = 0.020449766706830512
Trained batch 135 in epoch 12, gen_loss = 1.046457254930454, disc_loss = 0.020314238840964047
Trained batch 136 in epoch 12, gen_loss = 1.047768483414267, disc_loss = 0.02017883867761256
Trained batch 137 in epoch 12, gen_loss = 1.048161417029906, disc_loss = 0.02004684254812225
Trained batch 138 in epoch 12, gen_loss = 1.0489605950365821, disc_loss = 0.019919335745398975
Trained batch 139 in epoch 12, gen_loss = 1.0487601222736496, disc_loss = 0.019803323086567355
Trained batch 140 in epoch 12, gen_loss = 1.050507368982261, disc_loss = 0.019731471059490524
Trained batch 141 in epoch 12, gen_loss = 1.0502677721456743, disc_loss = 0.019621164540015817
Trained batch 142 in epoch 12, gen_loss = 1.0512157697360833, disc_loss = 0.019499126758664144
Trained batch 143 in epoch 12, gen_loss = 1.0514334640983078, disc_loss = 0.019378742989324058
Trained batch 144 in epoch 12, gen_loss = 1.0519195394269352, disc_loss = 0.019257918911070787
Trained batch 145 in epoch 12, gen_loss = 1.053228955766926, disc_loss = 0.019173899077418042
Trained batch 146 in epoch 12, gen_loss = 1.0528994735811843, disc_loss = 0.019078353760830526
Trained batch 147 in epoch 12, gen_loss = 1.0537872960841335, disc_loss = 0.01896196616478453
Trained batch 148 in epoch 12, gen_loss = 1.0543676416745922, disc_loss = 0.01884880529571287
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 1.133931040763855, disc_loss = 0.021807676181197166
Trained batch 1 in epoch 13, gen_loss = 0.8644317090511322, disc_loss = 0.03834072593599558
Trained batch 2 in epoch 13, gen_loss = 1.1373733480771382, disc_loss = 0.10159124496082465
Trained batch 3 in epoch 13, gen_loss = 1.033395141363144, disc_loss = 0.08839453803375363
Trained batch 4 in epoch 13, gen_loss = 1.027650570869446, disc_loss = 0.09827408231794835
Trained batch 5 in epoch 13, gen_loss = 0.9534276922543844, disc_loss = 0.1309615426386396
Trained batch 6 in epoch 13, gen_loss = 0.9759385074887957, disc_loss = 0.13580646711800778
Trained batch 7 in epoch 13, gen_loss = 0.9727300480008125, disc_loss = 0.12751249899156392
Trained batch 8 in epoch 13, gen_loss = 0.9457820256551107, disc_loss = 0.11981292586359713
Trained batch 9 in epoch 13, gen_loss = 0.9342352986335755, disc_loss = 0.11277636606246233
Trained batch 10 in epoch 13, gen_loss = 0.9223547740416094, disc_loss = 0.10491166348484429
Trained batch 11 in epoch 13, gen_loss = 0.922535315155983, disc_loss = 0.09769830123210947
Trained batch 12 in epoch 13, gen_loss = 0.9259195969654963, disc_loss = 0.0911175488995818
Trained batch 13 in epoch 13, gen_loss = 0.9398999299321856, disc_loss = 0.08499622218576926
Trained batch 14 in epoch 13, gen_loss = 0.9407305161158244, disc_loss = 0.07990881086637576
Trained batch 15 in epoch 13, gen_loss = 0.9448593705892563, disc_loss = 0.0752098880475387
Trained batch 16 in epoch 13, gen_loss = 0.9521296164568733, disc_loss = 0.07096022594829693
Trained batch 17 in epoch 13, gen_loss = 0.9620861013730367, disc_loss = 0.06719022120038669
Trained batch 18 in epoch 13, gen_loss = 0.9760279153522692, disc_loss = 0.06384410667478253
Trained batch 19 in epoch 13, gen_loss = 0.9811397433280945, disc_loss = 0.060845664353109896
Trained batch 20 in epoch 13, gen_loss = 0.9840854917253766, disc_loss = 0.05810204153836128
Trained batch 21 in epoch 13, gen_loss = 0.9864652373573997, disc_loss = 0.05556881802410565
Trained batch 22 in epoch 13, gen_loss = 0.9910350260527238, disc_loss = 0.05332883613427048
Trained batch 23 in epoch 13, gen_loss = 0.9963924189408621, disc_loss = 0.05118525713138903
Trained batch 24 in epoch 13, gen_loss = 1.0002550601959228, disc_loss = 0.04920946842059493
Trained batch 25 in epoch 13, gen_loss = 1.0026463728684645, disc_loss = 0.047392337932251394
Trained batch 26 in epoch 13, gen_loss = 1.0064038612224437, disc_loss = 0.045701637769255926
Trained batch 27 in epoch 13, gen_loss = 1.010053540979113, disc_loss = 0.04420080100784877
Trained batch 28 in epoch 13, gen_loss = 1.0137881204999726, disc_loss = 0.042747549809001646
Trained batch 29 in epoch 13, gen_loss = 1.018734625975291, disc_loss = 0.04139974834397435
Trained batch 30 in epoch 13, gen_loss = 1.0192553650948308, disc_loss = 0.04021325569239355
Trained batch 31 in epoch 13, gen_loss = 1.0208790451288223, disc_loss = 0.03905301305348985
Trained batch 32 in epoch 13, gen_loss = 1.0224539294387356, disc_loss = 0.037934259405698285
Trained batch 33 in epoch 13, gen_loss = 1.0236733871347763, disc_loss = 0.03688780264244141
Trained batch 34 in epoch 13, gen_loss = 1.0253229584012713, disc_loss = 0.03591114593270634
Trained batch 35 in epoch 13, gen_loss = 1.025658107466168, disc_loss = 0.03496441481143443
Trained batch 36 in epoch 13, gen_loss = 1.0264866899799656, disc_loss = 0.03409667544041735
Trained batch 37 in epoch 13, gen_loss = 1.0310995014090287, disc_loss = 0.03331771738655669
Trained batch 38 in epoch 13, gen_loss = 1.0304130865977361, disc_loss = 0.032551000461889766
Trained batch 39 in epoch 13, gen_loss = 1.0309877693653107, disc_loss = 0.03181688633630984
Trained batch 40 in epoch 13, gen_loss = 1.0313295794696342, disc_loss = 0.03109630030329998
Trained batch 41 in epoch 13, gen_loss = 1.0324807536034357, disc_loss = 0.030412243146981512
Trained batch 42 in epoch 13, gen_loss = 1.0329773259717365, disc_loss = 0.029747468338153043
Trained batch 43 in epoch 13, gen_loss = 1.0333844396201046, disc_loss = 0.029107976556670936
Trained batch 44 in epoch 13, gen_loss = 1.0347736861970689, disc_loss = 0.028505884110927582
Trained batch 45 in epoch 13, gen_loss = 1.0363102969915972, disc_loss = 0.02793732128591965
Trained batch 46 in epoch 13, gen_loss = 1.0356590468832787, disc_loss = 0.02739069039160584
Trained batch 47 in epoch 13, gen_loss = 1.0362872605522473, disc_loss = 0.026854620734714747
Trained batch 48 in epoch 13, gen_loss = 1.036667174222518, disc_loss = 0.026377081821140434
Trained batch 49 in epoch 13, gen_loss = 1.0392099022865295, disc_loss = 0.02588166788686067
Trained batch 50 in epoch 13, gen_loss = 1.0411443710327148, disc_loss = 0.02540118472796737
Trained batch 51 in epoch 13, gen_loss = 1.041206181049347, disc_loss = 0.024946033491197832
Trained batch 52 in epoch 13, gen_loss = 1.0406018855436794, disc_loss = 0.02450587454401308
Trained batch 53 in epoch 13, gen_loss = 1.0414188592522233, disc_loss = 0.024099106079019193
Trained batch 54 in epoch 13, gen_loss = 1.0413177663629705, disc_loss = 0.02369451502507383
Trained batch 55 in epoch 13, gen_loss = 1.042540437408856, disc_loss = 0.02330075087541315
Trained batch 56 in epoch 13, gen_loss = 1.0430943652203208, disc_loss = 0.022916232452221345
Trained batch 57 in epoch 13, gen_loss = 1.0436352738018693, disc_loss = 0.02255531566635031
Trained batch 58 in epoch 13, gen_loss = 1.0454440662416362, disc_loss = 0.022197504133238632
Trained batch 59 in epoch 13, gen_loss = 1.0457282265027363, disc_loss = 0.0218518121750094
Trained batch 60 in epoch 13, gen_loss = 1.046932249772744, disc_loss = 0.021516248068512708
Trained batch 61 in epoch 13, gen_loss = 1.0480330105750792, disc_loss = 0.021307102062799517
Trained batch 62 in epoch 13, gen_loss = 1.0452218396323067, disc_loss = 0.021159670999391922
Trained batch 63 in epoch 13, gen_loss = 1.0490510985255241, disc_loss = 0.02094663108800887
Trained batch 64 in epoch 13, gen_loss = 1.051155215043288, disc_loss = 0.020681053177955058
Trained batch 65 in epoch 13, gen_loss = 1.050578798308517, disc_loss = 0.020420280927227752
Trained batch 66 in epoch 13, gen_loss = 1.0502753898278991, disc_loss = 0.020160438009857465
Trained batch 67 in epoch 13, gen_loss = 1.0512665808200836, disc_loss = 0.01988139495198779
Trained batch 68 in epoch 13, gen_loss = 1.0518832949624546, disc_loss = 0.019611414513496708
Trained batch 69 in epoch 13, gen_loss = 1.0526734828948974, disc_loss = 0.019349989166948946
Trained batch 70 in epoch 13, gen_loss = 1.0526304463265648, disc_loss = 0.019094400430872092
Trained batch 71 in epoch 13, gen_loss = 1.0527267985873752, disc_loss = 0.01887182445918572
Trained batch 72 in epoch 13, gen_loss = 1.0535644684752372, disc_loss = 0.018744010703115124
Trained batch 73 in epoch 13, gen_loss = 1.0529138961353817, disc_loss = 0.018541705173226324
Trained batch 74 in epoch 13, gen_loss = 1.0538216177622477, disc_loss = 0.01833678480082502
Trained batch 75 in epoch 13, gen_loss = 1.053893688477968, disc_loss = 0.018129240303288066
Trained batch 76 in epoch 13, gen_loss = 1.05473619312435, disc_loss = 0.017931613343912963
Trained batch 77 in epoch 13, gen_loss = 1.054650604724884, disc_loss = 0.01773134660638439
Trained batch 78 in epoch 13, gen_loss = 1.0557351912124247, disc_loss = 0.017524473675632778
Trained batch 79 in epoch 13, gen_loss = 1.0575289607048035, disc_loss = 0.0173384039895609
Trained batch 80 in epoch 13, gen_loss = 1.056522786617279, disc_loss = 0.017199409309268734
Trained batch 81 in epoch 13, gen_loss = 1.0580129150937243, disc_loss = 0.017221271616929188
Trained batch 82 in epoch 13, gen_loss = 1.055461243692651, disc_loss = 0.017164364715207773
Trained batch 83 in epoch 13, gen_loss = 1.0575371462674368, disc_loss = 0.017012408712790125
Trained batch 84 in epoch 13, gen_loss = 1.0584536082604352, disc_loss = 0.01683990071144174
Trained batch 85 in epoch 13, gen_loss = 1.0587140966293425, disc_loss = 0.016674344016369
Trained batch 86 in epoch 13, gen_loss = 1.059683498979985, disc_loss = 0.01650832587553338
Trained batch 87 in epoch 13, gen_loss = 1.0595826540480962, disc_loss = 0.016372857964597642
Trained batch 88 in epoch 13, gen_loss = 1.0599456241961276, disc_loss = 0.016211720513117114
Trained batch 89 in epoch 13, gen_loss = 1.0600029912259843, disc_loss = 0.016043188129293007
Trained batch 90 in epoch 13, gen_loss = 1.06047699543146, disc_loss = 0.015888937061990273
Trained batch 91 in epoch 13, gen_loss = 1.0596122385367104, disc_loss = 0.015744862246640918
Trained batch 92 in epoch 13, gen_loss = 1.0603837486236327, disc_loss = 0.015594882283469922
Trained batch 93 in epoch 13, gen_loss = 1.0610814151611734, disc_loss = 0.015453723364539365
Trained batch 94 in epoch 13, gen_loss = 1.0613146813292251, disc_loss = 0.015310564702131638
Trained batch 95 in epoch 13, gen_loss = 1.0611519621064265, disc_loss = 0.015169474873497771
Trained batch 96 in epoch 13, gen_loss = 1.0620007730021919, disc_loss = 0.01502883843309486
Trained batch 97 in epoch 13, gen_loss = 1.063106575182506, disc_loss = 0.014899845579544045
Trained batch 98 in epoch 13, gen_loss = 1.062335036017678, disc_loss = 0.014781502858650956
Trained batch 99 in epoch 13, gen_loss = 1.0630726766586305, disc_loss = 0.014647978777065872
Trained batch 100 in epoch 13, gen_loss = 1.0633179799164876, disc_loss = 0.014522737260944772
Trained batch 101 in epoch 13, gen_loss = 1.063017066787271, disc_loss = 0.01439839027201136
Trained batch 102 in epoch 13, gen_loss = 1.063965326374017, disc_loss = 0.014277672887897318
Trained batch 103 in epoch 13, gen_loss = 1.063597859098361, disc_loss = 0.014157318081393337
Trained batch 104 in epoch 13, gen_loss = 1.063446653456915, disc_loss = 0.014036208196055321
Trained batch 105 in epoch 13, gen_loss = 1.0645965045353152, disc_loss = 0.013921606233607064
Trained batch 106 in epoch 13, gen_loss = 1.064852864942818, disc_loss = 0.013808191274118689
Trained batch 107 in epoch 13, gen_loss = 1.0650211705101862, disc_loss = 0.013700412024735232
Trained batch 108 in epoch 13, gen_loss = 1.0663014311309253, disc_loss = 0.013599761961446648
Trained batch 109 in epoch 13, gen_loss = 1.0651690277186308, disc_loss = 0.013589151003609665
Trained batch 110 in epoch 13, gen_loss = 1.0662385590441592, disc_loss = 0.013497414850831233
Trained batch 111 in epoch 13, gen_loss = 1.0668341198137827, disc_loss = 0.013432593794797347
Trained batch 112 in epoch 13, gen_loss = 1.065895279951855, disc_loss = 0.013442581448399058
Trained batch 113 in epoch 13, gen_loss = 1.0677025600483543, disc_loss = 0.013376078853310136
Trained batch 114 in epoch 13, gen_loss = 1.0685740854429162, disc_loss = 0.01328307447205905
Trained batch 115 in epoch 13, gen_loss = 1.06852266809036, disc_loss = 0.013192294521763086
Trained batch 116 in epoch 13, gen_loss = 1.0677988192973993, disc_loss = 0.01311532624810138
Trained batch 117 in epoch 13, gen_loss = 1.0680517069363997, disc_loss = 0.01302522327257636
Trained batch 118 in epoch 13, gen_loss = 1.0689505468897458, disc_loss = 0.012927981430054213
Trained batch 119 in epoch 13, gen_loss = 1.0688965330521265, disc_loss = 0.012831893112161197
Trained batch 120 in epoch 13, gen_loss = 1.0685556870846709, disc_loss = 0.012741220954320709
Trained batch 121 in epoch 13, gen_loss = 1.0693239315611418, disc_loss = 0.012649045286692496
Trained batch 122 in epoch 13, gen_loss = 1.0698486401782772, disc_loss = 0.012555958719250209
Trained batch 123 in epoch 13, gen_loss = 1.069618599068734, disc_loss = 0.012474216773332427
Trained batch 124 in epoch 13, gen_loss = 1.0700158910751343, disc_loss = 0.012385969534516334
Trained batch 125 in epoch 13, gen_loss = 1.0706282239111642, disc_loss = 0.012300523871090263
Trained batch 126 in epoch 13, gen_loss = 1.0704431177124263, disc_loss = 0.012211824219131211
Trained batch 127 in epoch 13, gen_loss = 1.0712133571505547, disc_loss = 0.012134573738876497
Trained batch 128 in epoch 13, gen_loss = 1.0710947217867357, disc_loss = 0.012052802110899442
Trained batch 129 in epoch 13, gen_loss = 1.0709717952288114, disc_loss = 0.011977629813079078
Trained batch 130 in epoch 13, gen_loss = 1.0711706303458177, disc_loss = 0.011905752479646156
Trained batch 131 in epoch 13, gen_loss = 1.0717654878442937, disc_loss = 0.011822682036312692
Trained batch 132 in epoch 13, gen_loss = 1.0720090866088867, disc_loss = 0.011743497614629735
Trained batch 133 in epoch 13, gen_loss = 1.072263240814209, disc_loss = 0.011667733240539014
Trained batch 134 in epoch 13, gen_loss = 1.072450379089073, disc_loss = 0.011590178976594298
Trained batch 135 in epoch 13, gen_loss = 1.0726136012988932, disc_loss = 0.01151321068070555
Trained batch 136 in epoch 13, gen_loss = 1.073222953037624, disc_loss = 0.011441219119647395
Trained batch 137 in epoch 13, gen_loss = 1.0734137434890305, disc_loss = 0.011368244934482906
Trained batch 138 in epoch 13, gen_loss = 1.073255675302135, disc_loss = 0.011300467474808206
Trained batch 139 in epoch 13, gen_loss = 1.073985856771469, disc_loss = 0.01123831056673745
Trained batch 140 in epoch 13, gen_loss = 1.0742665402432705, disc_loss = 0.011170631334027077
Trained batch 141 in epoch 13, gen_loss = 1.073946668228633, disc_loss = 0.011100553902535056
Trained batch 142 in epoch 13, gen_loss = 1.07433639372979, disc_loss = 0.011076262541493024
Trained batch 143 in epoch 13, gen_loss = 1.072834783958064, disc_loss = 0.011088595235681472
Trained batch 144 in epoch 13, gen_loss = 1.074852312844375, disc_loss = 0.01109258826854157
Trained batch 145 in epoch 13, gen_loss = 1.074406187828273, disc_loss = 0.011033744900487363
Trained batch 146 in epoch 13, gen_loss = 1.0747772779594473, disc_loss = 0.010975781091659958
Trained batch 147 in epoch 13, gen_loss = 1.074773903634097, disc_loss = 0.010911797288163388
Trained batch 148 in epoch 13, gen_loss = 1.0743962462316423, disc_loss = 0.01084810913221648
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 1.0441735982894897, disc_loss = 0.0013405638746917248
Trained batch 1 in epoch 14, gen_loss = 1.102289617061615, disc_loss = 0.002524985931813717
Trained batch 2 in epoch 14, gen_loss = 1.0726555188496907, disc_loss = 0.002360224180544416
Trained batch 3 in epoch 14, gen_loss = 1.0636053085327148, disc_loss = 0.0023789608385413885
Trained batch 4 in epoch 14, gen_loss = 1.0767691373825072, disc_loss = 0.0021505848038941623
Trained batch 5 in epoch 14, gen_loss = 1.0918803413709004, disc_loss = 0.0021871827775612473
Trained batch 6 in epoch 14, gen_loss = 1.0847759417125158, disc_loss = 0.0021592858912689345
Trained batch 7 in epoch 14, gen_loss = 1.081194892525673, disc_loss = 0.002031721145613119
Trained batch 8 in epoch 14, gen_loss = 1.0857861042022705, disc_loss = 0.0019150847801938653
Trained batch 9 in epoch 14, gen_loss = 1.0875336527824402, disc_loss = 0.0018142940592952073
Trained batch 10 in epoch 14, gen_loss = 1.0868350050666116, disc_loss = 0.0017613431078974497
Trained batch 11 in epoch 14, gen_loss = 1.0848124126593273, disc_loss = 0.001764249725965783
Trained batch 12 in epoch 14, gen_loss = 1.084532691882207, disc_loss = 0.0017712687661584753
Trained batch 13 in epoch 14, gen_loss = 1.0853274464607239, disc_loss = 0.001706633118114301
Trained batch 14 in epoch 14, gen_loss = 1.0839780728022257, disc_loss = 0.0016598980330551664
Trained batch 15 in epoch 14, gen_loss = 1.0864610597491264, disc_loss = 0.0016474092844873667
Trained batch 16 in epoch 14, gen_loss = 1.0846583632861866, disc_loss = 0.001629530671326553
Trained batch 17 in epoch 14, gen_loss = 1.090071764257219, disc_loss = 0.0017255412854461207
Trained batch 18 in epoch 14, gen_loss = 1.0870371241318553, disc_loss = 0.0017477853689342737
Trained batch 19 in epoch 14, gen_loss = 1.0882741928100585, disc_loss = 0.001697052363306284
Trained batch 20 in epoch 14, gen_loss = 1.0856681437719435, disc_loss = 0.0016738695114673604
Trained batch 21 in epoch 14, gen_loss = 1.0859811576929959, disc_loss = 0.0016764367041601376
Trained batch 22 in epoch 14, gen_loss = 1.0865967273712158, disc_loss = 0.0016620469826233127
Trained batch 23 in epoch 14, gen_loss = 1.088030939300855, disc_loss = 0.0016324245516443625
Trained batch 24 in epoch 14, gen_loss = 1.0916124725341796, disc_loss = 0.0016262696869671345
Trained batch 25 in epoch 14, gen_loss = 1.090308359036079, disc_loss = 0.001616925663816241
Trained batch 26 in epoch 14, gen_loss = 1.0897307793299358, disc_loss = 0.001653655432164669
Trained batch 27 in epoch 14, gen_loss = 1.0858941269772393, disc_loss = 0.0016570512587869807
Trained batch 28 in epoch 14, gen_loss = 1.0870486066259186, disc_loss = 0.0016483754152432084
Trained batch 29 in epoch 14, gen_loss = 1.0893952588240305, disc_loss = 0.001644242007751018
Trained batch 30 in epoch 14, gen_loss = 1.0893299175846962, disc_loss = 0.0016865120682444785
Trained batch 31 in epoch 14, gen_loss = 1.086701037362218, disc_loss = 0.0017046362081600819
Trained batch 32 in epoch 14, gen_loss = 1.0880929213581663, disc_loss = 0.0016930686683873787
Trained batch 33 in epoch 14, gen_loss = 1.0897693055517532, disc_loss = 0.0016913733321844654
Trained batch 34 in epoch 14, gen_loss = 1.0913412485803877, disc_loss = 0.0016822333081758449
Trained batch 35 in epoch 14, gen_loss = 1.0911607924434874, disc_loss = 0.0017015638780624915
Trained batch 36 in epoch 14, gen_loss = 1.0869270031516616, disc_loss = 0.001785669069913392
Trained batch 37 in epoch 14, gen_loss = 1.0898626336925907, disc_loss = 0.0018029490418389048
Trained batch 38 in epoch 14, gen_loss = 1.0917331392948444, disc_loss = 0.0017937888504746251
Trained batch 39 in epoch 14, gen_loss = 1.0918453857302666, disc_loss = 0.0018190680159023032
Trained batch 40 in epoch 14, gen_loss = 1.0943203394005938, disc_loss = 0.0018378626640386333
Trained batch 41 in epoch 14, gen_loss = 1.092170157602855, disc_loss = 0.0018968564940483443
Trained batch 42 in epoch 14, gen_loss = 1.093213520770849, disc_loss = 0.0018866348843804973
Trained batch 43 in epoch 14, gen_loss = 1.0937842984091153, disc_loss = 0.0018902425416110252
Trained batch 44 in epoch 14, gen_loss = 1.0916503840022618, disc_loss = 0.001889653966969086
Trained batch 45 in epoch 14, gen_loss = 1.0918076232723568, disc_loss = 0.001872818775313056
Trained batch 46 in epoch 14, gen_loss = 1.092360089433954, disc_loss = 0.0018808169419223324
Trained batch 47 in epoch 14, gen_loss = 1.0913857979079087, disc_loss = 0.0018899741844506934
Trained batch 48 in epoch 14, gen_loss = 1.0922169356930012, disc_loss = 0.0018768108174280853
Trained batch 49 in epoch 14, gen_loss = 1.0939253556728363, disc_loss = 0.001880198190920055
Trained batch 50 in epoch 14, gen_loss = 1.0922056191107805, disc_loss = 0.0019161694765310077
Trained batch 51 in epoch 14, gen_loss = 1.0929373697592661, disc_loss = 0.0022143291873642458
Trained batch 52 in epoch 14, gen_loss = 1.0873185677348443, disc_loss = 0.0024453374636271654
Trained batch 53 in epoch 14, gen_loss = 1.089840395583047, disc_loss = 0.0024649209679207867
Trained batch 54 in epoch 14, gen_loss = 1.092752696167339, disc_loss = 0.002490851791067557
Trained batch 55 in epoch 14, gen_loss = 1.0911014069403921, disc_loss = 0.0024863567502636996
Trained batch 56 in epoch 14, gen_loss = 1.0897960526901378, disc_loss = 0.002487452753835864
Trained batch 57 in epoch 14, gen_loss = 1.089997627611818, disc_loss = 0.0024593875689255394
Trained batch 58 in epoch 14, gen_loss = 1.0909331158056097, disc_loss = 0.0024527645663958105
Trained batch 59 in epoch 14, gen_loss = 1.0898199806610742, disc_loss = 0.0024541564411871756
Trained batch 60 in epoch 14, gen_loss = 1.089519685409108, disc_loss = 0.0024279422235491946
Trained batch 61 in epoch 14, gen_loss = 1.0894249494998687, disc_loss = 0.0024116840316808874
Trained batch 62 in epoch 14, gen_loss = 1.0904150718734378, disc_loss = 0.002394244698474982
Trained batch 63 in epoch 14, gen_loss = 1.0905585447326303, disc_loss = 0.0023806078997949953
Trained batch 64 in epoch 14, gen_loss = 1.0910869204081022, disc_loss = 0.0023578828254428048
Trained batch 65 in epoch 14, gen_loss = 1.091100429946726, disc_loss = 0.0023413555640162845
Trained batch 66 in epoch 14, gen_loss = 1.091224689092209, disc_loss = 0.0023458797568038326
Trained batch 67 in epoch 14, gen_loss = 1.0908898755031473, disc_loss = 0.002345796619706294
Trained batch 68 in epoch 14, gen_loss = 1.0909922114316968, disc_loss = 0.002335419962722538
Trained batch 69 in epoch 14, gen_loss = 1.0912028798035214, disc_loss = 0.002337624495183783
Trained batch 70 in epoch 14, gen_loss = 1.0920337060807457, disc_loss = 0.0023324053642720406
Trained batch 71 in epoch 14, gen_loss = 1.0911760007341702, disc_loss = 0.0023360346579769007
Trained batch 72 in epoch 14, gen_loss = 1.091830365461846, disc_loss = 0.0023132104327749105
Trained batch 73 in epoch 14, gen_loss = 1.092948102467769, disc_loss = 0.002321082143729704
Trained batch 74 in epoch 14, gen_loss = 1.0923521971702577, disc_loss = 0.0023078951006755234
Trained batch 75 in epoch 14, gen_loss = 1.0917700631053824, disc_loss = 0.0023027937583576298
Trained batch 76 in epoch 14, gen_loss = 1.0929989296120484, disc_loss = 0.0023150513456626372
Trained batch 77 in epoch 14, gen_loss = 1.0931331736919208, disc_loss = 0.002298208365503412
Trained batch 78 in epoch 14, gen_loss = 1.091322643092916, disc_loss = 0.002308857211654511
Trained batch 79 in epoch 14, gen_loss = 1.091885543614626, disc_loss = 0.0022970724923652595
Trained batch 80 in epoch 14, gen_loss = 1.0931332560233127, disc_loss = 0.002285644969684474
Trained batch 81 in epoch 14, gen_loss = 1.0928116389890996, disc_loss = 0.0022737156335696034
Trained batch 82 in epoch 14, gen_loss = 1.093403022691428, disc_loss = 0.00226688159472612
Trained batch 83 in epoch 14, gen_loss = 1.093332255880038, disc_loss = 0.0022774439227456846
Trained batch 84 in epoch 14, gen_loss = 1.0930578547365526, disc_loss = 0.002267411370378207
Trained batch 85 in epoch 14, gen_loss = 1.0925585315671078, disc_loss = 0.0022492639153253633
Trained batch 86 in epoch 14, gen_loss = 1.0927706429328041, disc_loss = 0.002233268187954037
Trained batch 87 in epoch 14, gen_loss = 1.0926307785240086, disc_loss = 0.002217151380715553
Trained batch 88 in epoch 14, gen_loss = 1.0926277965642093, disc_loss = 0.0021990505714241542
Trained batch 89 in epoch 14, gen_loss = 1.092379152112537, disc_loss = 0.002182500092830095
Trained batch 90 in epoch 14, gen_loss = 1.0923911732631726, disc_loss = 0.002166099518225375
Trained batch 91 in epoch 14, gen_loss = 1.0921431268038957, disc_loss = 0.002152639047657747
Trained batch 92 in epoch 14, gen_loss = 1.0914361329488858, disc_loss = 0.002138958612997686
Trained batch 93 in epoch 14, gen_loss = 1.0912705691570932, disc_loss = 0.0021244021853372612
Trained batch 94 in epoch 14, gen_loss = 1.0915105411880894, disc_loss = 0.0021110191451091517
Trained batch 95 in epoch 14, gen_loss = 1.0917186768104632, disc_loss = 0.002099813840080363
Trained batch 96 in epoch 14, gen_loss = 1.0917364905789955, disc_loss = 0.002085112755969359
Trained batch 97 in epoch 14, gen_loss = 1.0915761206831252, disc_loss = 0.0020726845060399144
Trained batch 98 in epoch 14, gen_loss = 1.0916763598268682, disc_loss = 0.002087137667753856
Trained batch 99 in epoch 14, gen_loss = 1.091064161658287, disc_loss = 0.0020982394332531838
Trained batch 100 in epoch 14, gen_loss = 1.0913248622771536, disc_loss = 0.002090961000384154
Trained batch 101 in epoch 14, gen_loss = 1.0917504166855532, disc_loss = 0.002086863988855233
Trained batch 102 in epoch 14, gen_loss = 1.0913551264596217, disc_loss = 0.0020830053259681875
Trained batch 103 in epoch 14, gen_loss = 1.091021930369047, disc_loss = 0.002082128918398387
Trained batch 104 in epoch 14, gen_loss = 1.091679619039808, disc_loss = 0.0020813919060553112
Trained batch 105 in epoch 14, gen_loss = 1.0913179556153856, disc_loss = 0.0020717130677405534
Trained batch 106 in epoch 14, gen_loss = 1.091254954583177, disc_loss = 0.0020589432254799196
Trained batch 107 in epoch 14, gen_loss = 1.091158386181902, disc_loss = 0.002045386239101558
Trained batch 108 in epoch 14, gen_loss = 1.0911035871287005, disc_loss = 0.00203346163557774
Trained batch 109 in epoch 14, gen_loss = 1.0905125850980932, disc_loss = 0.002031918357401578
Trained batch 110 in epoch 14, gen_loss = 1.0899614992442432, disc_loss = 0.0020268218028610826
Trained batch 111 in epoch 14, gen_loss = 1.090047906019858, disc_loss = 0.002019458974765647
Trained batch 112 in epoch 14, gen_loss = 1.090472400188446, disc_loss = 0.002008655117268353
Trained batch 113 in epoch 14, gen_loss = 1.0909927659913112, disc_loss = 0.0020032205732269702
Trained batch 114 in epoch 14, gen_loss = 1.0902365223221158, disc_loss = 0.0019971526890952625
Trained batch 115 in epoch 14, gen_loss = 1.0900819974726643, disc_loss = 0.0019845590080688545
Trained batch 116 in epoch 14, gen_loss = 1.0908986661169264, disc_loss = 0.001977579351255877
Trained batch 117 in epoch 14, gen_loss = 1.0909820941545196, disc_loss = 0.001965921389440201
Trained batch 118 in epoch 14, gen_loss = 1.0903579662827885, disc_loss = 0.0019568245874584784
Trained batch 119 in epoch 14, gen_loss = 1.0896374866366387, disc_loss = 0.001954209374283285
Trained batch 120 in epoch 14, gen_loss = 1.0892884716514712, disc_loss = 0.001949065954189686
Trained batch 121 in epoch 14, gen_loss = 1.0897705325337708, disc_loss = 0.0019401500576946762
Trained batch 122 in epoch 14, gen_loss = 1.0899256317596124, disc_loss = 0.0019295538820106749
Trained batch 123 in epoch 14, gen_loss = 1.0896734840446902, disc_loss = 0.0019197807667942176
Trained batch 124 in epoch 14, gen_loss = 1.0896439785957337, disc_loss = 0.0019104754300788044
Trained batch 125 in epoch 14, gen_loss = 1.089900704130294, disc_loss = 0.0018995294166314933
Trained batch 126 in epoch 14, gen_loss = 1.0898739883280175, disc_loss = 0.001889602813730383
Trained batch 127 in epoch 14, gen_loss = 1.0898199495859444, disc_loss = 0.0018790808808262227
Trained batch 128 in epoch 14, gen_loss = 1.0899735906327417, disc_loss = 0.0018684274260705525
Trained batch 129 in epoch 14, gen_loss = 1.0900557091602912, disc_loss = 0.0018637375404628423
Trained batch 130 in epoch 14, gen_loss = 1.0894111763430006, disc_loss = 0.0018570599650949923
Trained batch 131 in epoch 14, gen_loss = 1.0894797936533436, disc_loss = 0.001849225878355686
Trained batch 132 in epoch 14, gen_loss = 1.0896652815933514, disc_loss = 0.001839219853351999
Trained batch 133 in epoch 14, gen_loss = 1.089958502730327, disc_loss = 0.0018307907231423113
Trained batch 134 in epoch 14, gen_loss = 1.0900034820591962, disc_loss = 0.001822068478429207
Trained batch 135 in epoch 14, gen_loss = 1.089786860434448, disc_loss = 0.0018155598552445607
Trained batch 136 in epoch 14, gen_loss = 1.089548308918946, disc_loss = 0.0018073121140146778
Trained batch 137 in epoch 14, gen_loss = 1.0897491310817609, disc_loss = 0.001799092640293816
Trained batch 138 in epoch 14, gen_loss = 1.0898006232522375, disc_loss = 0.0017915803234749507
Trained batch 139 in epoch 14, gen_loss = 1.0899217022316796, disc_loss = 0.0017852531014276403
Trained batch 140 in epoch 14, gen_loss = 1.0903918772724503, disc_loss = 0.0017921905700407975
Trained batch 141 in epoch 14, gen_loss = 1.0902156229590025, disc_loss = 0.0017894425635999987
Trained batch 142 in epoch 14, gen_loss = 1.0902980078350415, disc_loss = 0.0017810947969197654
Trained batch 143 in epoch 14, gen_loss = 1.0904963368342981, disc_loss = 0.0017749157070486238
Trained batch 144 in epoch 14, gen_loss = 1.0902787960808853, disc_loss = 0.001769911282262283
Trained batch 145 in epoch 14, gen_loss = 1.0903150059588969, disc_loss = 0.0017614732779505063
Trained batch 146 in epoch 14, gen_loss = 1.0905701023380772, disc_loss = 0.0017544656028166464
Trained batch 147 in epoch 14, gen_loss = 1.090439741273184, disc_loss = 0.0017535831646307849
Trained batch 148 in epoch 14, gen_loss = 1.0902679978601084, disc_loss = 0.0017512275461551278
Testing Epoch 14

wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5099399089813232, disc_loss = 0.6652650833129883
Trained batch 1 in epoch 0, gen_loss = 0.5246374607086182, disc_loss = 1.0687836408615112
Trained batch 2 in epoch 0, gen_loss = 0.4992922345797221, disc_loss = 0.9186796347300211
Trained batch 3 in epoch 0, gen_loss = 0.4840197190642357, disc_loss = 0.8036992624402046
Trained batch 4 in epoch 0, gen_loss = 0.4900683701038361, disc_loss = 0.7234868705272675
Trained batch 5 in epoch 0, gen_loss = 0.4740268439054489, disc_loss = 0.6487222959597906
Trained batch 6 in epoch 0, gen_loss = 0.45705499393599375, disc_loss = 0.5865290101085391
Trained batch 7 in epoch 0, gen_loss = 0.45387277379631996, disc_loss = 0.5425473619252443
Trained batch 8 in epoch 0, gen_loss = 0.44705664118131, disc_loss = 0.49821904798348743
Trained batch 9 in epoch 0, gen_loss = 0.4426441162824631, disc_loss = 0.46075087785720825
Trained batch 10 in epoch 0, gen_loss = 0.4337367632172324, disc_loss = 0.42959919504143973
Trained batch 11 in epoch 0, gen_loss = 0.4333684593439102, disc_loss = 0.4066217460980018
Trained batch 12 in epoch 0, gen_loss = 0.43358822281544024, disc_loss = 0.3839352039190439
Trained batch 13 in epoch 0, gen_loss = 0.43078782302992685, disc_loss = 0.3644287788442203
Trained batch 14 in epoch 0, gen_loss = 0.428651495774587, disc_loss = 0.3463477740685145
Trained batch 15 in epoch 0, gen_loss = 0.43008051440119743, disc_loss = 0.3309529861435294
Trained batch 16 in epoch 0, gen_loss = 0.43168197484577403, disc_loss = 0.3159845637924531
Trained batch 17 in epoch 0, gen_loss = 0.4323413074016571, disc_loss = 0.3022768596808116
Trained batch 18 in epoch 0, gen_loss = 0.4336595001973604, disc_loss = 0.2905649280077533
Trained batch 19 in epoch 0, gen_loss = 0.4324519753456116, disc_loss = 0.2797622762620449
Trained batch 20 in epoch 0, gen_loss = 0.4352032797677176, disc_loss = 0.27197759314661935
Trained batch 21 in epoch 0, gen_loss = 0.43492687425830145, disc_loss = 0.2634482769803567
Trained batch 22 in epoch 0, gen_loss = 0.4318905550500621, disc_loss = 0.25516485358061997
Trained batch 23 in epoch 0, gen_loss = 0.43235990529259044, disc_loss = 0.2511903199677666
Trained batch 24 in epoch 0, gen_loss = 0.433506566286087, disc_loss = 0.2527077010273933
Trained batch 25 in epoch 0, gen_loss = 0.4298769109524213, disc_loss = 0.2471132269845559
Trained batch 26 in epoch 0, gen_loss = 0.4276938118316509, disc_loss = 0.24683213537489926
Trained batch 27 in epoch 0, gen_loss = 0.42887006593602045, disc_loss = 0.2446175337369953
Trained batch 28 in epoch 0, gen_loss = 0.43196837347129297, disc_loss = 0.24125403808108692
Trained batch 29 in epoch 0, gen_loss = 0.43228232860565186, disc_loss = 0.23574107016126314
Trained batch 30 in epoch 0, gen_loss = 0.43151633777926046, disc_loss = 0.23002128531375238
Trained batch 31 in epoch 0, gen_loss = 0.43220250122249126, disc_loss = 0.22424365009646863
Trained batch 32 in epoch 0, gen_loss = 0.43300308693539014, disc_loss = 0.21870061935800494
Trained batch 33 in epoch 0, gen_loss = 0.4324983051594566, disc_loss = 0.2138833979911664
Trained batch 34 in epoch 0, gen_loss = 0.4343754657677242, disc_loss = 0.209425202863557
Trained batch 35 in epoch 0, gen_loss = 0.43493789186080295, disc_loss = 0.20487434106568495
Trained batch 36 in epoch 0, gen_loss = 0.43737828650990046, disc_loss = 0.2006600377326076
Trained batch 37 in epoch 0, gen_loss = 0.43782260935557515, disc_loss = 0.19651153154279055
Trained batch 38 in epoch 0, gen_loss = 0.4411842983502608, disc_loss = 0.19294803188397333
Trained batch 39 in epoch 0, gen_loss = 0.44106633216142654, disc_loss = 0.18944842796772718
Trained batch 40 in epoch 0, gen_loss = 0.44071258059362084, disc_loss = 0.18591991975540068
Trained batch 41 in epoch 0, gen_loss = 0.44240952460538774, disc_loss = 0.18245214294819606
Trained batch 42 in epoch 0, gen_loss = 0.44351199546525644, disc_loss = 0.17937937916018243
Trained batch 43 in epoch 0, gen_loss = 0.4447466114705259, disc_loss = 0.17615658722140573
Trained batch 44 in epoch 0, gen_loss = 0.4467885421382056, disc_loss = 0.17304501334826153
Trained batch 45 in epoch 0, gen_loss = 0.447491406098656, disc_loss = 0.17030519295645796
Trained batch 46 in epoch 0, gen_loss = 0.4473972460056873, disc_loss = 0.16769351191977236
Trained batch 47 in epoch 0, gen_loss = 0.4464511914799611, disc_loss = 0.166098323961099
Trained batch 48 in epoch 0, gen_loss = 0.44675954568142795, disc_loss = 0.16449416139904333
Trained batch 49 in epoch 0, gen_loss = 0.44753633081912997, disc_loss = 0.16212271228432656
Trained batch 50 in epoch 0, gen_loss = 0.45025459516282174, disc_loss = 0.15999497794637493
Trained batch 51 in epoch 0, gen_loss = 0.4490975496860651, disc_loss = 0.1585224478577192
Trained batch 52 in epoch 0, gen_loss = 0.4501228377504169, disc_loss = 0.15630905231777228
Trained batch 53 in epoch 0, gen_loss = 0.45165390107366776, disc_loss = 0.15435037348005506
Trained batch 54 in epoch 0, gen_loss = 0.45143261606043034, disc_loss = 0.15221151343800804
Trained batch 55 in epoch 0, gen_loss = 0.45093430472271784, disc_loss = 0.15054464659520558
Trained batch 56 in epoch 0, gen_loss = 0.4508122927264163, disc_loss = 0.148744902328441
Trained batch 57 in epoch 0, gen_loss = 0.45206633621248704, disc_loss = 0.14690460328911914
Trained batch 58 in epoch 0, gen_loss = 0.452154913191068, disc_loss = 0.14532402119899201
Trained batch 59 in epoch 0, gen_loss = 0.45255159536997475, disc_loss = 0.14360905388991038
Trained batch 60 in epoch 0, gen_loss = 0.45348165172045346, disc_loss = 0.14210132179690188
Trained batch 61 in epoch 0, gen_loss = 0.4539486203462847, disc_loss = 0.1405162541496177
Trained batch 62 in epoch 0, gen_loss = 0.4547541874741751, disc_loss = 0.13947323881207951
Trained batch 63 in epoch 0, gen_loss = 0.4561533057130873, disc_loss = 0.13796516001457348
Trained batch 64 in epoch 0, gen_loss = 0.45754024386405945, disc_loss = 0.13638553521954097
Trained batch 65 in epoch 0, gen_loss = 0.4571482634002512, disc_loss = 0.1348252030033054
Trained batch 66 in epoch 0, gen_loss = 0.456708075395271, disc_loss = 0.13340723164268395
Trained batch 67 in epoch 0, gen_loss = 0.45667679301079583, disc_loss = 0.1319163822404602
Trained batch 68 in epoch 0, gen_loss = 0.4576349046783171, disc_loss = 0.1303854018881701
Trained batch 69 in epoch 0, gen_loss = 0.457416684286935, disc_loss = 0.12887117130947964
Trained batch 70 in epoch 0, gen_loss = 0.4575037351796325, disc_loss = 0.12776928618025613
Trained batch 71 in epoch 0, gen_loss = 0.4574533870650662, disc_loss = 0.126822518883273
Trained batch 72 in epoch 0, gen_loss = 0.4575118328610512, disc_loss = 0.12565526634148538
Trained batch 73 in epoch 0, gen_loss = 0.45771475619560964, disc_loss = 0.12450576037470554
Trained batch 74 in epoch 0, gen_loss = 0.4573155438899994, disc_loss = 0.12454351770381132
Trained batch 75 in epoch 0, gen_loss = 0.4568888772475092, disc_loss = 0.12523882294465838
Trained batch 76 in epoch 0, gen_loss = 0.45742508498105133, disc_loss = 0.12413903420137895
Trained batch 77 in epoch 0, gen_loss = 0.4577397585679323, disc_loss = 0.12330849819745009
Trained batch 78 in epoch 0, gen_loss = 0.45871894834916804, disc_loss = 0.12245902732674833
Trained batch 79 in epoch 0, gen_loss = 0.4586415342986584, disc_loss = 0.12138519503641873
Trained batch 80 in epoch 0, gen_loss = 0.45772583028416575, disc_loss = 0.12040407783179372
Trained batch 81 in epoch 0, gen_loss = 0.45778124724946373, disc_loss = 0.11940339196291638
Trained batch 82 in epoch 0, gen_loss = 0.45767029653112573, disc_loss = 0.11833145004887898
Trained batch 83 in epoch 0, gen_loss = 0.4571014039573215, disc_loss = 0.11734957436454438
Trained batch 84 in epoch 0, gen_loss = 0.4562924974104937, disc_loss = 0.11643605006530004
Trained batch 85 in epoch 0, gen_loss = 0.4562324236991794, disc_loss = 0.11550380144441544
Trained batch 86 in epoch 0, gen_loss = 0.4562406584449198, disc_loss = 0.11455192513250072
Trained batch 87 in epoch 0, gen_loss = 0.45757100968198344, disc_loss = 0.11373766217465428
Trained batch 88 in epoch 0, gen_loss = 0.4574296340513765, disc_loss = 0.11287905713229367
Trained batch 89 in epoch 0, gen_loss = 0.4578316460053126, disc_loss = 0.11214691878606876
Trained batch 90 in epoch 0, gen_loss = 0.458643274975347, disc_loss = 0.11163765697606973
Trained batch 91 in epoch 0, gen_loss = 0.4586580956111784, disc_loss = 0.11109437528268798
Trained batch 92 in epoch 0, gen_loss = 0.45916496842138227, disc_loss = 0.11039440199652667
Trained batch 93 in epoch 0, gen_loss = 0.45960833702949766, disc_loss = 0.10969880803864687
Trained batch 94 in epoch 0, gen_loss = 0.45991989154564705, disc_loss = 0.10909510299955544
Trained batch 95 in epoch 0, gen_loss = 0.460573458733658, disc_loss = 0.11086247191997245
Trained batch 96 in epoch 0, gen_loss = 0.45999716575612726, disc_loss = 0.11803330724924496
Trained batch 97 in epoch 0, gen_loss = 0.4596805973928802, disc_loss = 0.1187834886986078
Trained batch 98 in epoch 0, gen_loss = 0.4590719866030144, disc_loss = 0.11995484866201878
Trained batch 99 in epoch 0, gen_loss = 0.45838908821344376, disc_loss = 0.12084238631650805
Trained batch 100 in epoch 0, gen_loss = 0.45839399069842723, disc_loss = 0.12142903097711577
Trained batch 101 in epoch 0, gen_loss = 0.4579763552721809, disc_loss = 0.12193760522367324
Trained batch 102 in epoch 0, gen_loss = 0.4578055646813032, disc_loss = 0.1219645239304281
Trained batch 103 in epoch 0, gen_loss = 0.457993327998198, disc_loss = 0.12216204775568958
Trained batch 104 in epoch 0, gen_loss = 0.45745092715535846, disc_loss = 0.12232286431604908
Trained batch 105 in epoch 0, gen_loss = 0.4571392831375014, disc_loss = 0.12306569374324579
Trained batch 106 in epoch 0, gen_loss = 0.4567514724820574, disc_loss = 0.12479988546502367
Trained batch 107 in epoch 0, gen_loss = 0.4576700269072144, disc_loss = 0.1252511648495716
Trained batch 108 in epoch 0, gen_loss = 0.45751771221467114, disc_loss = 0.12551427487318123
Trained batch 109 in epoch 0, gen_loss = 0.45695711780678144, disc_loss = 0.12586983494799245
Trained batch 110 in epoch 0, gen_loss = 0.4569017930073781, disc_loss = 0.12687843244287883
Trained batch 111 in epoch 0, gen_loss = 0.45626864875001566, disc_loss = 0.12887771279617613
Trained batch 112 in epoch 0, gen_loss = 0.45645852611128207, disc_loss = 0.12871818348303832
Trained batch 113 in epoch 0, gen_loss = 0.4571001605506529, disc_loss = 0.12886316053111824
Trained batch 114 in epoch 0, gen_loss = 0.4569789637690005, disc_loss = 0.12977318813943345
Trained batch 115 in epoch 0, gen_loss = 0.4568247679492523, disc_loss = 0.13241775743342166
Trained batch 116 in epoch 0, gen_loss = 0.4567888514098958, disc_loss = 0.1346701574472026
Trained batch 117 in epoch 0, gen_loss = 0.457143975263935, disc_loss = 0.13484348241492347
Trained batch 118 in epoch 0, gen_loss = 0.45650676493885134, disc_loss = 0.13570480184833042
Trained batch 119 in epoch 0, gen_loss = 0.45566994945208233, disc_loss = 0.13623084734814864
Trained batch 120 in epoch 0, gen_loss = 0.45484739049407075, disc_loss = 0.13614479309209615
Trained batch 121 in epoch 0, gen_loss = 0.4555410337252695, disc_loss = 0.13571335050109468
Trained batch 122 in epoch 0, gen_loss = 0.45596477607401403, disc_loss = 0.13542558366387356
Trained batch 123 in epoch 0, gen_loss = 0.45568477242223676, disc_loss = 0.13501578952456195
Trained batch 124 in epoch 0, gen_loss = 0.45546942520141603, disc_loss = 0.13512634168565274
Trained batch 125 in epoch 0, gen_loss = 0.4550759160802478, disc_loss = 0.13821637522547492
Trained batch 126 in epoch 0, gen_loss = 0.45500322636656876, disc_loss = 0.13827694493426582
Trained batch 127 in epoch 0, gen_loss = 0.45461085229180753, disc_loss = 0.13867298779950943
Trained batch 128 in epoch 0, gen_loss = 0.45437164916548617, disc_loss = 0.1386225390890541
Trained batch 129 in epoch 0, gen_loss = 0.4543965825667748, disc_loss = 0.13828863024425048
Trained batch 130 in epoch 0, gen_loss = 0.453759694144926, disc_loss = 0.13807670918527906
Trained batch 131 in epoch 0, gen_loss = 0.45433367721059104, disc_loss = 0.13744408000881472
Trained batch 132 in epoch 0, gen_loss = 0.4540856606081912, disc_loss = 0.13674469159117766
Trained batch 133 in epoch 0, gen_loss = 0.4540866724590757, disc_loss = 0.1361855152688587
Trained batch 134 in epoch 0, gen_loss = 0.4534153854405438, disc_loss = 0.1359685023487718
Trained batch 135 in epoch 0, gen_loss = 0.45339027573080626, disc_loss = 0.1371431019677616
Trained batch 136 in epoch 0, gen_loss = 0.45263591713278833, disc_loss = 0.13768376441278163
Trained batch 137 in epoch 0, gen_loss = 0.452712910114855, disc_loss = 0.13756678851348333
Trained batch 138 in epoch 0, gen_loss = 0.4522504219048315, disc_loss = 0.1373356841102564
Trained batch 139 in epoch 0, gen_loss = 0.45155160427093505, disc_loss = 0.13698675056387272
Trained batch 140 in epoch 0, gen_loss = 0.4510214806448483, disc_loss = 0.13689509238915662
Trained batch 141 in epoch 0, gen_loss = 0.4511828057363, disc_loss = 0.13798350970667433
Trained batch 142 in epoch 0, gen_loss = 0.45062844069687635, disc_loss = 0.1378730382718198
Trained batch 143 in epoch 0, gen_loss = 0.45077652153041625, disc_loss = 0.13724315517012858
Trained batch 144 in epoch 0, gen_loss = 0.4505408237720358, disc_loss = 0.13754248258111806
Trained batch 145 in epoch 0, gen_loss = 0.45002147575763807, disc_loss = 0.1377706848059411
Trained batch 146 in epoch 0, gen_loss = 0.44996773791150985, disc_loss = 0.1378211624236131
Trained batch 147 in epoch 0, gen_loss = 0.449260217716565, disc_loss = 0.13736980870315754
Trained batch 148 in epoch 0, gen_loss = 0.4487458219464193, disc_loss = 0.13701140019267596
Trained batch 149 in epoch 0, gen_loss = 0.4486156352361043, disc_loss = 0.13660718767593305
Trained batch 150 in epoch 0, gen_loss = 0.44854224379488966, disc_loss = 0.1361725236480402
Trained batch 151 in epoch 0, gen_loss = 0.4489562572225144, disc_loss = 0.13572813961409816
Trained batch 152 in epoch 0, gen_loss = 0.4488077629235835, disc_loss = 0.13533568507656943
Trained batch 153 in epoch 0, gen_loss = 0.4491140463135459, disc_loss = 0.1347154311763195
Trained batch 154 in epoch 0, gen_loss = 0.4494852292922235, disc_loss = 0.1344253434409057
Trained batch 155 in epoch 0, gen_loss = 0.44911825293913865, disc_loss = 0.13517572120643961
Trained batch 156 in epoch 0, gen_loss = 0.4493904358642116, disc_loss = 0.13601190441400762
Trained batch 157 in epoch 0, gen_loss = 0.4492226414665391, disc_loss = 0.13616855924689694
Trained batch 158 in epoch 0, gen_loss = 0.4491981646549777, disc_loss = 0.13629618278886163
Trained batch 159 in epoch 0, gen_loss = 0.44952641129493714, disc_loss = 0.13625459905015305
Trained batch 160 in epoch 0, gen_loss = 0.4492863999760669, disc_loss = 0.13622534831534633
Trained batch 161 in epoch 0, gen_loss = 0.4491952843504188, disc_loss = 0.13670623561160433
Trained batch 162 in epoch 0, gen_loss = 0.4489726797203345, disc_loss = 0.13735378374762697
Trained batch 163 in epoch 0, gen_loss = 0.4485525592434697, disc_loss = 0.1379107583155174
Trained batch 164 in epoch 0, gen_loss = 0.44853474244926916, disc_loss = 0.1378849774711963
Trained batch 165 in epoch 0, gen_loss = 0.4482542019651597, disc_loss = 0.13783349322312208
Trained batch 166 in epoch 0, gen_loss = 0.44761121737029025, disc_loss = 0.1378985023360231
Trained batch 167 in epoch 0, gen_loss = 0.44752883307990576, disc_loss = 0.1377668607026516
Trained batch 168 in epoch 0, gen_loss = 0.4470183147481207, disc_loss = 0.13763292214265588
Trained batch 169 in epoch 0, gen_loss = 0.4473411398775437, disc_loss = 0.13736317925812566
Trained batch 170 in epoch 0, gen_loss = 0.44730320102290105, disc_loss = 0.13709978790877506
Trained batch 171 in epoch 0, gen_loss = 0.44702647071938184, disc_loss = 0.13823072167200057
Trained batch 172 in epoch 0, gen_loss = 0.4465025282664106, disc_loss = 0.14056222706042618
Trained batch 173 in epoch 0, gen_loss = 0.44647517560542316, disc_loss = 0.14088728755241495
Trained batch 174 in epoch 0, gen_loss = 0.446054824420384, disc_loss = 0.1411582298470395
Trained batch 175 in epoch 0, gen_loss = 0.44579550640826876, disc_loss = 0.14169864548073913
Trained batch 176 in epoch 0, gen_loss = 0.44533777270613417, disc_loss = 0.14182684268528795
Trained batch 177 in epoch 0, gen_loss = 0.44495776915148405, disc_loss = 0.14159782625358092
Trained batch 178 in epoch 0, gen_loss = 0.44482626878349474, disc_loss = 0.14127825626156518
Trained batch 179 in epoch 0, gen_loss = 0.4446871312128173, disc_loss = 0.14094367425681817
Trained batch 180 in epoch 0, gen_loss = 0.4446059274410016, disc_loss = 0.14086609297735586
Trained batch 181 in epoch 0, gen_loss = 0.44474508736159774, disc_loss = 0.14110023431111496
Trained batch 182 in epoch 0, gen_loss = 0.4444502427604029, disc_loss = 0.1412299391126535
Trained batch 183 in epoch 0, gen_loss = 0.4443298343407071, disc_loss = 0.14091820185801582
Trained batch 184 in epoch 0, gen_loss = 0.4443679107202066, disc_loss = 0.14099236796232495
Trained batch 185 in epoch 0, gen_loss = 0.443926995960615, disc_loss = 0.1411869430273611
Trained batch 186 in epoch 0, gen_loss = 0.4439210668604642, disc_loss = 0.14089901491322301
Trained batch 187 in epoch 0, gen_loss = 0.44396482249523733, disc_loss = 0.1405396827377696
Trained batch 188 in epoch 0, gen_loss = 0.4437140489696826, disc_loss = 0.14070923520971543
Trained batch 189 in epoch 0, gen_loss = 0.4435974447350753, disc_loss = 0.14230847183222833
Trained batch 190 in epoch 0, gen_loss = 0.44349331100573713, disc_loss = 0.14237035956253244
Trained batch 191 in epoch 0, gen_loss = 0.44362569817652303, disc_loss = 0.1420802275048724
Trained batch 192 in epoch 0, gen_loss = 0.4435389180875195, disc_loss = 0.14181307495759868
Trained batch 193 in epoch 0, gen_loss = 0.4433791485336638, disc_loss = 0.1415132089162764
Trained batch 194 in epoch 0, gen_loss = 0.4434580188531142, disc_loss = 0.14125160957949284
Trained batch 195 in epoch 0, gen_loss = 0.4436123146086323, disc_loss = 0.1411285058367161
Trained batch 196 in epoch 0, gen_loss = 0.4434480213271785, disc_loss = 0.14128637632478008
Trained batch 197 in epoch 0, gen_loss = 0.44366437603126874, disc_loss = 0.14202237370979004
Trained batch 198 in epoch 0, gen_loss = 0.4433189859641856, disc_loss = 0.14258662121716756
Trained batch 199 in epoch 0, gen_loss = 0.442951792627573, disc_loss = 0.14288704783655704
Trained batch 200 in epoch 0, gen_loss = 0.442151731074746, disc_loss = 0.14328168370571007
Trained batch 201 in epoch 0, gen_loss = 0.4416650303519598, disc_loss = 0.14380643908672108
Trained batch 202 in epoch 0, gen_loss = 0.44172740070690664, disc_loss = 0.14385887306055117
Trained batch 203 in epoch 0, gen_loss = 0.4414738175623557, disc_loss = 0.14407615934261211
Trained batch 204 in epoch 0, gen_loss = 0.4411449566120055, disc_loss = 0.14430214959855486
Trained batch 205 in epoch 0, gen_loss = 0.44092742491115644, disc_loss = 0.14433227292289144
Trained batch 206 in epoch 0, gen_loss = 0.44057395233624225, disc_loss = 0.14458593511099113
Trained batch 207 in epoch 0, gen_loss = 0.4407930030272557, disc_loss = 0.14470747443668258
Trained batch 208 in epoch 0, gen_loss = 0.4412550683797261, disc_loss = 0.14533538012163777
Trained batch 209 in epoch 0, gen_loss = 0.44080977553413025, disc_loss = 0.14606902912436498
Trained batch 210 in epoch 0, gen_loss = 0.4406565475802851, disc_loss = 0.1462596414866747
Trained batch 211 in epoch 0, gen_loss = 0.4403857749025777, disc_loss = 0.14655671916234325
Trained batch 212 in epoch 0, gen_loss = 0.4402819252070127, disc_loss = 0.14670001824731838
Trained batch 213 in epoch 0, gen_loss = 0.44024226974661107, disc_loss = 0.14682813101039033
Trained batch 214 in epoch 0, gen_loss = 0.4400628185549448, disc_loss = 0.14731987729495347
Trained batch 215 in epoch 0, gen_loss = 0.4398988116946485, disc_loss = 0.14842348532854682
Trained batch 216 in epoch 0, gen_loss = 0.44007593255987915, disc_loss = 0.14873743058109337
Trained batch 217 in epoch 0, gen_loss = 0.43994398934578677, disc_loss = 0.14888634540379866
Trained batch 218 in epoch 0, gen_loss = 0.43939500829400535, disc_loss = 0.14935835094518585
Trained batch 219 in epoch 0, gen_loss = 0.43920636488632725, disc_loss = 0.14943028689277443
Trained batch 220 in epoch 0, gen_loss = 0.4391384563025306, disc_loss = 0.15008079345713105
Trained batch 221 in epoch 0, gen_loss = 0.43874984925931637, disc_loss = 0.15032127017138508
Trained batch 222 in epoch 0, gen_loss = 0.4384611799577961, disc_loss = 0.15040642277842947
Trained batch 223 in epoch 0, gen_loss = 0.4378922698753221, disc_loss = 0.15125974694300176
Trained batch 224 in epoch 0, gen_loss = 0.43748637265629237, disc_loss = 0.15156833106444942
Trained batch 225 in epoch 0, gen_loss = 0.4373406766526467, disc_loss = 0.15153985754875218
Trained batch 226 in epoch 0, gen_loss = 0.4372225107075359, disc_loss = 0.1513955423501751
Trained batch 227 in epoch 0, gen_loss = 0.4372383544319554, disc_loss = 0.15150084056515703
Trained batch 228 in epoch 0, gen_loss = 0.43695202808192724, disc_loss = 0.15160664360498496
Trained batch 229 in epoch 0, gen_loss = 0.4363101464250813, disc_loss = 0.1517212632962543
Trained batch 230 in epoch 0, gen_loss = 0.435982443295516, disc_loss = 0.15196058719350405
Trained batch 231 in epoch 0, gen_loss = 0.4359847178746914, disc_loss = 0.1520038194199703
Trained batch 232 in epoch 0, gen_loss = 0.43573873633990473, disc_loss = 0.15209129386353645
Trained batch 233 in epoch 0, gen_loss = 0.43540470977114815, disc_loss = 0.15220436330438933
Trained batch 234 in epoch 0, gen_loss = 0.43496899376524256, disc_loss = 0.15270712544467854
Trained batch 235 in epoch 0, gen_loss = 0.4345235694515503, disc_loss = 0.15302382419832936
Trained batch 236 in epoch 0, gen_loss = 0.43411028863005496, disc_loss = 0.15348807490481858
Trained batch 237 in epoch 0, gen_loss = 0.43384602978950787, disc_loss = 0.15382953161107643
Trained batch 238 in epoch 0, gen_loss = 0.4337342109640273, disc_loss = 0.15411952303948512
Trained batch 239 in epoch 0, gen_loss = 0.43346317460139594, disc_loss = 0.1544479199141885
Trained batch 240 in epoch 0, gen_loss = 0.4331082367798105, disc_loss = 0.1546270910774153
Trained batch 241 in epoch 0, gen_loss = 0.4329283407404403, disc_loss = 0.1546952997619086
Trained batch 242 in epoch 0, gen_loss = 0.4325871530138416, disc_loss = 0.15477309021102303
Trained batch 243 in epoch 0, gen_loss = 0.4322033197176261, disc_loss = 0.15480625034752685
Trained batch 244 in epoch 0, gen_loss = 0.43171951612647697, disc_loss = 0.15517025976916965
Trained batch 245 in epoch 0, gen_loss = 0.4316279586495423, disc_loss = 0.15530258620809007
Trained batch 246 in epoch 0, gen_loss = 0.43142481564510204, disc_loss = 0.1553906697991044
Trained batch 247 in epoch 0, gen_loss = 0.4311712480360462, disc_loss = 0.15555141148938528
Trained batch 248 in epoch 0, gen_loss = 0.4311512146130144, disc_loss = 0.15588473714888096
Trained batch 249 in epoch 0, gen_loss = 0.43087577164173124, disc_loss = 0.156368207372725
Trained batch 250 in epoch 0, gen_loss = 0.4308755351490233, disc_loss = 0.15646434593871533
Trained batch 251 in epoch 0, gen_loss = 0.43090809999950347, disc_loss = 0.15652334208910665
Trained batch 252 in epoch 0, gen_loss = 0.43063601297823334, disc_loss = 0.15677135043847468
Trained batch 253 in epoch 0, gen_loss = 0.43038579481323874, disc_loss = 0.15693070813573487
Trained batch 254 in epoch 0, gen_loss = 0.430097963996962, disc_loss = 0.1570994860766565
Trained batch 255 in epoch 0, gen_loss = 0.42964631284121424, disc_loss = 0.15729095650749514
Trained batch 256 in epoch 0, gen_loss = 0.4292658950104324, disc_loss = 0.15739972492977108
Trained batch 257 in epoch 0, gen_loss = 0.4291945261548656, disc_loss = 0.1576565116311806
Trained batch 258 in epoch 0, gen_loss = 0.42914294460105157, disc_loss = 0.15825344090670002
Trained batch 259 in epoch 0, gen_loss = 0.4294667255419951, disc_loss = 0.15811396193189117
Trained batch 260 in epoch 0, gen_loss = 0.42926071350145156, disc_loss = 0.15827698769383275
Trained batch 261 in epoch 0, gen_loss = 0.4288297895029301, disc_loss = 0.15867545766372035
Trained batch 262 in epoch 0, gen_loss = 0.4284974026136072, disc_loss = 0.15880101531772334
Trained batch 263 in epoch 0, gen_loss = 0.42850235544822435, disc_loss = 0.15877096640708094
Trained batch 264 in epoch 0, gen_loss = 0.42855227263468615, disc_loss = 0.15868072839418673
Trained batch 265 in epoch 0, gen_loss = 0.42838896262018306, disc_loss = 0.15907046011880152
Trained batch 266 in epoch 0, gen_loss = 0.4282207451063149, disc_loss = 0.15912200022865547
Trained batch 267 in epoch 0, gen_loss = 0.42782533691445396, disc_loss = 0.15922671443185032
Trained batch 268 in epoch 0, gen_loss = 0.42748873262600384, disc_loss = 0.15925013512843825
Trained batch 269 in epoch 0, gen_loss = 0.4270717795248385, disc_loss = 0.15937023718186
Trained batch 270 in epoch 0, gen_loss = 0.42700275932730786, disc_loss = 0.15939181188733156
Trained batch 271 in epoch 0, gen_loss = 0.42734827462802916, disc_loss = 0.1593779913656523
Trained batch 272 in epoch 0, gen_loss = 0.427360814787966, disc_loss = 0.15960535355894775
Trained batch 273 in epoch 0, gen_loss = 0.4273274903097292, disc_loss = 0.16027144373251792
Trained batch 274 in epoch 0, gen_loss = 0.427114713083614, disc_loss = 0.16038221590220927
Trained batch 275 in epoch 0, gen_loss = 0.4268751210276631, disc_loss = 0.16059119095755875
Trained batch 276 in epoch 0, gen_loss = 0.4266786016927299, disc_loss = 0.1606916889938314
Trained batch 277 in epoch 0, gen_loss = 0.42663826755911327, disc_loss = 0.1608206399066521
Trained batch 278 in epoch 0, gen_loss = 0.42664925738047527, disc_loss = 0.16070418025777544
Trained batch 279 in epoch 0, gen_loss = 0.42640737827335085, disc_loss = 0.16081346409794475
Trained batch 280 in epoch 0, gen_loss = 0.42608058282913264, disc_loss = 0.16098291385136676
Trained batch 281 in epoch 0, gen_loss = 0.4262166183891026, disc_loss = 0.16086987525568153
Trained batch 282 in epoch 0, gen_loss = 0.4259932377102518, disc_loss = 0.16098487469969916
Trained batch 283 in epoch 0, gen_loss = 0.42588841967599494, disc_loss = 0.161057110908638
Trained batch 284 in epoch 0, gen_loss = 0.4255982194030494, disc_loss = 0.1613733818460452
Trained batch 285 in epoch 0, gen_loss = 0.42551142216979204, disc_loss = 0.1616434114496712
Trained batch 286 in epoch 0, gen_loss = 0.42580414887920076, disc_loss = 0.16172696518280158
Trained batch 287 in epoch 0, gen_loss = 0.4259274409463008, disc_loss = 0.1615953915558445
Trained batch 288 in epoch 0, gen_loss = 0.42563477725718674, disc_loss = 0.1616596789212066
Trained batch 289 in epoch 0, gen_loss = 0.4255265297560856, disc_loss = 0.16166082932132073
Trained batch 290 in epoch 0, gen_loss = 0.4255906393642688, disc_loss = 0.1615645899613391
Trained batch 291 in epoch 0, gen_loss = 0.42562459664393776, disc_loss = 0.16149348518747378
Trained batch 292 in epoch 0, gen_loss = 0.4254845186508556, disc_loss = 0.16175458901291617
Trained batch 293 in epoch 0, gen_loss = 0.4254314633859258, disc_loss = 0.16215535063854083
Trained batch 294 in epoch 0, gen_loss = 0.42538663441851987, disc_loss = 0.16261400962406297
Trained batch 295 in epoch 0, gen_loss = 0.4249332381059995, disc_loss = 0.16282699124358996
Trained batch 296 in epoch 0, gen_loss = 0.4248682846525301, disc_loss = 0.16300376721027524
Trained batch 297 in epoch 0, gen_loss = 0.42489981351282774, disc_loss = 0.16307895313698373
Trained batch 298 in epoch 0, gen_loss = 0.42470852517364016, disc_loss = 0.16312623779635166
Trained batch 299 in epoch 0, gen_loss = 0.4246796407302221, disc_loss = 0.16315860100711385
Trained batch 300 in epoch 0, gen_loss = 0.4243138251312547, disc_loss = 0.16310894284459246
Trained batch 301 in epoch 0, gen_loss = 0.42425890237290337, disc_loss = 0.16298940326919817
Trained batch 302 in epoch 0, gen_loss = 0.424082869940465, disc_loss = 0.16306914102052503
Trained batch 303 in epoch 0, gen_loss = 0.4238244000038034, disc_loss = 0.1632279486358656
Trained batch 304 in epoch 0, gen_loss = 0.42376626417285107, disc_loss = 0.16335148179262388
Trained batch 305 in epoch 0, gen_loss = 0.42383087509208256, disc_loss = 0.1636276111505877
Trained batch 306 in epoch 0, gen_loss = 0.42361273944183747, disc_loss = 0.16375061139731337
Trained batch 307 in epoch 0, gen_loss = 0.4233704577018688, disc_loss = 0.1638432546494553
Trained batch 308 in epoch 0, gen_loss = 0.4233242036069481, disc_loss = 0.16371825393470166
Trained batch 309 in epoch 0, gen_loss = 0.4231965838901458, disc_loss = 0.16379031676558717
Trained batch 310 in epoch 0, gen_loss = 0.4229758689449531, disc_loss = 0.16399577991300265
Trained batch 311 in epoch 0, gen_loss = 0.4229606482654046, disc_loss = 0.1639866363078069
Trained batch 312 in epoch 0, gen_loss = 0.42278814411010984, disc_loss = 0.16394605964255599
Trained batch 313 in epoch 0, gen_loss = 0.422821484648498, disc_loss = 0.16386796945148402
Trained batch 314 in epoch 0, gen_loss = 0.42285409389980255, disc_loss = 0.16404634286605177
Trained batch 315 in epoch 0, gen_loss = 0.42249128665727903, disc_loss = 0.16444033929559437
Trained batch 316 in epoch 0, gen_loss = 0.4222372248533772, disc_loss = 0.16476510994559396
Trained batch 317 in epoch 0, gen_loss = 0.422011765575259, disc_loss = 0.16482816662920532
Trained batch 318 in epoch 0, gen_loss = 0.42177901970555415, disc_loss = 0.1649045807639353
Trained batch 319 in epoch 0, gen_loss = 0.4215838016010821, disc_loss = 0.1649044882331509
Trained batch 320 in epoch 0, gen_loss = 0.4217637523869488, disc_loss = 0.16481752951870268
Trained batch 321 in epoch 0, gen_loss = 0.42139317030492035, disc_loss = 0.1646972962059312
Trained batch 322 in epoch 0, gen_loss = 0.4213672548809288, disc_loss = 0.16474388459633932
Trained batch 323 in epoch 0, gen_loss = 0.42129147549470264, disc_loss = 0.16473159311845162
Trained batch 324 in epoch 0, gen_loss = 0.4210988081418551, disc_loss = 0.16462940810391535
Trained batch 325 in epoch 0, gen_loss = 0.42083375384471167, disc_loss = 0.1645621169027101
Trained batch 326 in epoch 0, gen_loss = 0.42068995786004837, disc_loss = 0.16456109575289288
Trained batch 327 in epoch 0, gen_loss = 0.42061166965016505, disc_loss = 0.1650140151756293
Trained batch 328 in epoch 0, gen_loss = 0.42013001532540134, disc_loss = 0.16549468473573767
Trained batch 329 in epoch 0, gen_loss = 0.41970344140674126, disc_loss = 0.16564440847459164
Trained batch 330 in epoch 0, gen_loss = 0.4195755248343476, disc_loss = 0.16566763645505078
Trained batch 331 in epoch 0, gen_loss = 0.4193526299962078, disc_loss = 0.16586414305493236
Trained batch 332 in epoch 0, gen_loss = 0.41917108585526636, disc_loss = 0.16591595281642657
Trained batch 333 in epoch 0, gen_loss = 0.41896754173104633, disc_loss = 0.16593281909667268
Trained batch 334 in epoch 0, gen_loss = 0.41889683364042596, disc_loss = 0.16596292811654398
Trained batch 335 in epoch 0, gen_loss = 0.41893119817333563, disc_loss = 0.16576411537936933
Trained batch 336 in epoch 0, gen_loss = 0.41891967525114293, disc_loss = 0.1656856915639929
Trained batch 337 in epoch 0, gen_loss = 0.41868779900864034, disc_loss = 0.165984850514614
Trained batch 338 in epoch 0, gen_loss = 0.4182694458504342, disc_loss = 0.16627961672446898
Trained batch 339 in epoch 0, gen_loss = 0.4183767317849047, disc_loss = 0.16637531350750256
Trained batch 340 in epoch 0, gen_loss = 0.4183393088428855, disc_loss = 0.16625773223373722
Trained batch 341 in epoch 0, gen_loss = 0.4183015062620765, disc_loss = 0.16686612609991727
Trained batch 342 in epoch 0, gen_loss = 0.4186722661420138, disc_loss = 0.16710709116310316
Trained batch 343 in epoch 0, gen_loss = 0.41876117148718167, disc_loss = 0.16715649990256615
Trained batch 344 in epoch 0, gen_loss = 0.4186349530150925, disc_loss = 0.1674013749250899
Trained batch 345 in epoch 0, gen_loss = 0.418449054305264, disc_loss = 0.16746603863884432
Trained batch 346 in epoch 0, gen_loss = 0.41831950761742825, disc_loss = 0.167444022554872
Trained batch 347 in epoch 0, gen_loss = 0.41814963716542586, disc_loss = 0.167440101830824
Trained batch 348 in epoch 0, gen_loss = 0.4180879336715086, disc_loss = 0.16747052918980831
Trained batch 349 in epoch 0, gen_loss = 0.4179440907069615, disc_loss = 0.16747583115207298
Trained batch 350 in epoch 0, gen_loss = 0.4178628061401878, disc_loss = 0.1675073701272748
Trained batch 351 in epoch 0, gen_loss = 0.4176801405000416, disc_loss = 0.16754489635985176
Trained batch 352 in epoch 0, gen_loss = 0.41763724737059293, disc_loss = 0.1675867036713166
Trained batch 353 in epoch 0, gen_loss = 0.41764147074545843, disc_loss = 0.16754407497217594
Trained batch 354 in epoch 0, gen_loss = 0.41754893543015065, disc_loss = 0.16749174240714226
Trained batch 355 in epoch 0, gen_loss = 0.4174873242887218, disc_loss = 0.1675814135115217
Trained batch 356 in epoch 0, gen_loss = 0.417430420382684, disc_loss = 0.16804377382480296
Trained batch 357 in epoch 0, gen_loss = 0.41715141981007664, disc_loss = 0.1680914014421778
Trained batch 358 in epoch 0, gen_loss = 0.4170215983244702, disc_loss = 0.16810705156317163
Trained batch 359 in epoch 0, gen_loss = 0.4169033774899112, disc_loss = 0.16806133557628428
Trained batch 360 in epoch 0, gen_loss = 0.41701916438060455, disc_loss = 0.1679379341767848
Trained batch 361 in epoch 0, gen_loss = 0.4169693900406031, disc_loss = 0.16781335775303083
Trained batch 362 in epoch 0, gen_loss = 0.4168423404378339, disc_loss = 0.16777646810986285
Trained batch 363 in epoch 0, gen_loss = 0.41655777370209224, disc_loss = 0.16780814805303465
Trained batch 364 in epoch 0, gen_loss = 0.4166251769621078, disc_loss = 0.16777720213038463
Trained batch 365 in epoch 0, gen_loss = 0.4166609096071108, disc_loss = 0.16788337630591268
Trained batch 366 in epoch 0, gen_loss = 0.41655064408720677, disc_loss = 0.16780196445453557
Trained batch 367 in epoch 0, gen_loss = 0.4164637417896934, disc_loss = 0.16775328579419496
Trained batch 368 in epoch 0, gen_loss = 0.41647917322996186, disc_loss = 0.16816026855229846
Trained batch 369 in epoch 0, gen_loss = 0.4162214167214729, disc_loss = 0.16853906869183521
Trained batch 370 in epoch 0, gen_loss = 0.4160042597919783, disc_loss = 0.16845499278821874
Trained batch 371 in epoch 0, gen_loss = 0.4159451353774276, disc_loss = 0.1685299898838244
Trained batch 372 in epoch 0, gen_loss = 0.41580005097964495, disc_loss = 0.16877749400967407
Trained batch 373 in epoch 0, gen_loss = 0.4158421082292649, disc_loss = 0.16932071871398127
Trained batch 374 in epoch 0, gen_loss = 0.4157689825693766, disc_loss = 0.16933979112406572
Trained batch 375 in epoch 0, gen_loss = 0.41561084304084167, disc_loss = 0.16947079967568687
Trained batch 376 in epoch 0, gen_loss = 0.415421075387722, disc_loss = 0.16954543805663877
Trained batch 377 in epoch 0, gen_loss = 0.41509537469773067, disc_loss = 0.16960116702984407
Trained batch 378 in epoch 0, gen_loss = 0.4147329770008933, disc_loss = 0.16969194680472005
Trained batch 379 in epoch 0, gen_loss = 0.41473021679802946, disc_loss = 0.16963141104206442
Trained batch 380 in epoch 0, gen_loss = 0.4145755341516079, disc_loss = 0.16985134133614424
Trained batch 381 in epoch 0, gen_loss = 0.41440400301785996, disc_loss = 0.16986960530066522
Trained batch 382 in epoch 0, gen_loss = 0.4141273495422642, disc_loss = 0.1699673064860367
Trained batch 383 in epoch 0, gen_loss = 0.41417366980264586, disc_loss = 0.17009530665139513
Trained batch 384 in epoch 0, gen_loss = 0.41381873186532553, disc_loss = 0.17019711955897993
Trained batch 385 in epoch 0, gen_loss = 0.4135120847682261, disc_loss = 0.17052430623341255
Trained batch 386 in epoch 0, gen_loss = 0.4133167390059439, disc_loss = 0.1708476684207833
Trained batch 387 in epoch 0, gen_loss = 0.41333441804979265, disc_loss = 0.17074747574179597
Trained batch 388 in epoch 0, gen_loss = 0.4132340208730232, disc_loss = 0.17067763981694276
Trained batch 389 in epoch 0, gen_loss = 0.4130017870511764, disc_loss = 0.17082074275479103
Trained batch 390 in epoch 0, gen_loss = 0.41284671684970026, disc_loss = 0.17082035509616975
Trained batch 391 in epoch 0, gen_loss = 0.4129217737639437, disc_loss = 0.17067317946395855
Trained batch 392 in epoch 0, gen_loss = 0.4127041730110275, disc_loss = 0.17053078974267757
Trained batch 393 in epoch 0, gen_loss = 0.41232703626155853, disc_loss = 0.17070026928795323
Trained batch 394 in epoch 0, gen_loss = 0.41223046847536593, disc_loss = 0.1709241923510651
Trained batch 395 in epoch 0, gen_loss = 0.4123190776115716, disc_loss = 0.17083421479816538
Trained batch 396 in epoch 0, gen_loss = 0.4123773631881406, disc_loss = 0.1708087740836651
Trained batch 397 in epoch 0, gen_loss = 0.41241137413822826, disc_loss = 0.1706983255989962
Trained batch 398 in epoch 0, gen_loss = 0.41226549793903094, disc_loss = 0.17066581146254725
Trained batch 399 in epoch 0, gen_loss = 0.4122561477869749, disc_loss = 0.1705689919600263
Trained batch 400 in epoch 0, gen_loss = 0.4124197644039877, disc_loss = 0.1704404429762515
Trained batch 401 in epoch 0, gen_loss = 0.41228490067062096, disc_loss = 0.1708858761778889
Trained batch 402 in epoch 0, gen_loss = 0.41210734703700536, disc_loss = 0.17134494401477554
Trained batch 403 in epoch 0, gen_loss = 0.41212261741114137, disc_loss = 0.17133692823959015
Trained batch 404 in epoch 0, gen_loss = 0.4120951214690267, disc_loss = 0.1713663466412712
Trained batch 405 in epoch 0, gen_loss = 0.41210095496306864, disc_loss = 0.1713069291840413
Trained batch 406 in epoch 0, gen_loss = 0.41201940486413546, disc_loss = 0.17134326706006575
Trained batch 407 in epoch 0, gen_loss = 0.4119347434710054, disc_loss = 0.17168627995723748
Trained batch 408 in epoch 0, gen_loss = 0.4117807056618203, disc_loss = 0.17172491436136528
Trained batch 409 in epoch 0, gen_loss = 0.41159887808125195, disc_loss = 0.17179013194925175
Trained batch 410 in epoch 0, gen_loss = 0.41147274960856656, disc_loss = 0.1717523561423495
Trained batch 411 in epoch 0, gen_loss = 0.41138461868739823, disc_loss = 0.1716753766528394
Trained batch 412 in epoch 0, gen_loss = 0.4113522265782945, disc_loss = 0.17191803879747236
Trained batch 413 in epoch 0, gen_loss = 0.4112643993275177, disc_loss = 0.1717655677843281
Trained batch 414 in epoch 0, gen_loss = 0.4112401215426893, disc_loss = 0.17169457441083638
Trained batch 415 in epoch 0, gen_loss = 0.4111418037746961, disc_loss = 0.17181992764101148
Trained batch 416 in epoch 0, gen_loss = 0.411107427067608, disc_loss = 0.1717663717543264
Trained batch 417 in epoch 0, gen_loss = 0.41084540916972184, disc_loss = 0.1717542596740657
Trained batch 418 in epoch 0, gen_loss = 0.4109985358959735, disc_loss = 0.17163233825745758
Trained batch 419 in epoch 0, gen_loss = 0.4108440475804465, disc_loss = 0.1715578686667695
Trained batch 420 in epoch 0, gen_loss = 0.41091972950518557, disc_loss = 0.17160254175776965
Trained batch 421 in epoch 0, gen_loss = 0.41097091682149334, disc_loss = 0.17150034017913857
Trained batch 422 in epoch 0, gen_loss = 0.4108587563319691, disc_loss = 0.1713577691800276
Trained batch 423 in epoch 0, gen_loss = 0.4107067618729933, disc_loss = 0.17118371717789965
Trained batch 424 in epoch 0, gen_loss = 0.41056411385536196, disc_loss = 0.1713558717028183
Trained batch 425 in epoch 0, gen_loss = 0.41042720634892516, disc_loss = 0.1719753352243086
Trained batch 426 in epoch 0, gen_loss = 0.4103018679858929, disc_loss = 0.17252431859194675
Trained batch 427 in epoch 0, gen_loss = 0.4102363154709896, disc_loss = 0.17260534574373443
Trained batch 428 in epoch 0, gen_loss = 0.4099612103336619, disc_loss = 0.17265692569037555
Trained batch 429 in epoch 0, gen_loss = 0.40978979759438094, disc_loss = 0.17285585688037236
Trained batch 430 in epoch 0, gen_loss = 0.4097950548417607, disc_loss = 0.17281047519719933
Trained batch 431 in epoch 0, gen_loss = 0.4095787563947616, disc_loss = 0.172744113059404
Trained batch 432 in epoch 0, gen_loss = 0.4095132621413841, disc_loss = 0.1726876155238848
Trained batch 433 in epoch 0, gen_loss = 0.40923381524701274, disc_loss = 0.17264990835163038
Trained batch 434 in epoch 0, gen_loss = 0.4091224865666751, disc_loss = 0.17254540112254949
Trained batch 435 in epoch 0, gen_loss = 0.40888391380463174, disc_loss = 0.1725443449221688
Trained batch 436 in epoch 0, gen_loss = 0.40880039027408277, disc_loss = 0.1723991668137383
Trained batch 437 in epoch 0, gen_loss = 0.4086518778920718, disc_loss = 0.17233152747511454
Trained batch 438 in epoch 0, gen_loss = 0.4084626842875687, disc_loss = 0.17230515007633962
Trained batch 439 in epoch 0, gen_loss = 0.40840392884883014, disc_loss = 0.17217379405840555
Trained batch 440 in epoch 0, gen_loss = 0.4082364637970654, disc_loss = 0.17214530916322793
Trained batch 441 in epoch 0, gen_loss = 0.408174451187725, disc_loss = 0.1720853810034254
Trained batch 442 in epoch 0, gen_loss = 0.4081049545354822, disc_loss = 0.17188945421465499
Trained batch 443 in epoch 0, gen_loss = 0.4080368640857774, disc_loss = 0.17172870719973166
Trained batch 444 in epoch 0, gen_loss = 0.4079846783300464, disc_loss = 0.1715311569653535
Trained batch 445 in epoch 0, gen_loss = 0.40810527662525264, disc_loss = 0.1713467245553975
Trained batch 446 in epoch 0, gen_loss = 0.4080372056038321, disc_loss = 0.17117989095348773
Trained batch 447 in epoch 0, gen_loss = 0.4081263976570751, disc_loss = 0.17127787543410836
Trained batch 448 in epoch 0, gen_loss = 0.4081929886925194, disc_loss = 0.17204979515503802
Trained batch 449 in epoch 0, gen_loss = 0.40808997591336565, disc_loss = 0.17235263137767712
Trained batch 450 in epoch 0, gen_loss = 0.4079639049961403, disc_loss = 0.1725112928858155
Trained batch 451 in epoch 0, gen_loss = 0.4078821510867735, disc_loss = 0.1726527209311262
Trained batch 452 in epoch 0, gen_loss = 0.4076874775207595, disc_loss = 0.1727005685936602
Trained batch 453 in epoch 0, gen_loss = 0.40754430750918286, disc_loss = 0.17260830825202922
Trained batch 454 in epoch 0, gen_loss = 0.40753806488854544, disc_loss = 0.17250318897703848
Trained batch 455 in epoch 0, gen_loss = 0.40719381255800263, disc_loss = 0.17310003979180597
Trained batch 456 in epoch 0, gen_loss = 0.40717390107899837, disc_loss = 0.17333781827216727
Trained batch 457 in epoch 0, gen_loss = 0.4070571959669413, disc_loss = 0.17336140700319058
Trained batch 458 in epoch 0, gen_loss = 0.40686852259313877, disc_loss = 0.1734203966395333
Testing Epoch 0
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:15:09,710
------------------------------------------------------------
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.40801581740379333, disc_loss = 0.22753088176250458
Trained batch 1 in epoch 1, gen_loss = 0.4320172816514969, disc_loss = 0.17492283508181572
Trained batch 2 in epoch 1, gen_loss = 0.41408825914065045, disc_loss = 0.19962059209744135
Trained batch 3 in epoch 1, gen_loss = 0.3975604325532913, disc_loss = 0.19270079396665096
Trained batch 4 in epoch 1, gen_loss = 0.3833457469940186, disc_loss = 0.1965857520699501
Trained batch 5 in epoch 1, gen_loss = 0.36357708275318146, disc_loss = 0.19991704200704893
Trained batch 6 in epoch 1, gen_loss = 0.3672105755124773, disc_loss = 0.19265392741986684
Trained batch 7 in epoch 1, gen_loss = 0.37268372997641563, disc_loss = 0.19255203660577536
Trained batch 8 in epoch 1, gen_loss = 0.37776120172606575, disc_loss = 0.18600915124018988
Trained batch 9 in epoch 1, gen_loss = 0.3761517256498337, disc_loss = 0.17756617367267608
Trained batch 10 in epoch 1, gen_loss = 0.36939291791482404, disc_loss = 0.1758562665094029
Trained batch 11 in epoch 1, gen_loss = 0.37354730317989987, disc_loss = 0.16744288864235082
Trained batch 12 in epoch 1, gen_loss = 0.3794218645646022, disc_loss = 0.16025501432327124
Trained batch 13 in epoch 1, gen_loss = 0.37626532358782633, disc_loss = 0.15912714440907752
Trained batch 14 in epoch 1, gen_loss = 0.3771164655685425, disc_loss = 0.16065399199724198
Trained batch 15 in epoch 1, gen_loss = 0.3753733616322279, disc_loss = 0.16421906417235732
Trained batch 16 in epoch 1, gen_loss = 0.37642448264009815, disc_loss = 0.16569305474267287
Trained batch 17 in epoch 1, gen_loss = 0.37793828547000885, disc_loss = 0.16258957609534264
Trained batch 18 in epoch 1, gen_loss = 0.37643201257053177, disc_loss = 0.16216284232704262
Trained batch 19 in epoch 1, gen_loss = 0.38060789108276366, disc_loss = 0.16023449487984182
Trained batch 20 in epoch 1, gen_loss = 0.38695610421044485, disc_loss = 0.16200132206791923
Trained batch 21 in epoch 1, gen_loss = 0.38741499050097034, disc_loss = 0.15821024504574863
Trained batch 22 in epoch 1, gen_loss = 0.38618238335070404, disc_loss = 0.1547688919564952
Trained batch 23 in epoch 1, gen_loss = 0.38817564646402997, disc_loss = 0.15239776546756426
Trained batch 24 in epoch 1, gen_loss = 0.38630435466766355, disc_loss = 0.1513924902677536
Trained batch 25 in epoch 1, gen_loss = 0.39030221563119155, disc_loss = 0.1514836664383228
Trained batch 26 in epoch 1, gen_loss = 0.39107978343963623, disc_loss = 0.14858693325961078
Trained batch 27 in epoch 1, gen_loss = 0.38897381722927094, disc_loss = 0.1487193400306361
Trained batch 28 in epoch 1, gen_loss = 0.38849581110066383, disc_loss = 0.14860553525645157
Trained batch 29 in epoch 1, gen_loss = 0.38943876326084137, disc_loss = 0.14641660427053768
Trained batch 30 in epoch 1, gen_loss = 0.38953066352875004, disc_loss = 0.1456018664663838
Trained batch 31 in epoch 1, gen_loss = 0.38884999603033066, disc_loss = 0.14377972553484142
Trained batch 32 in epoch 1, gen_loss = 0.38804071961027203, disc_loss = 0.14491313176624704
Trained batch 33 in epoch 1, gen_loss = 0.3841122231062721, disc_loss = 0.14758297998239012
Trained batch 34 in epoch 1, gen_loss = 0.3856975751263755, disc_loss = 0.14632908701896669
Trained batch 35 in epoch 1, gen_loss = 0.3861674757467376, disc_loss = 0.14625308165947595
Trained batch 36 in epoch 1, gen_loss = 0.3852943858584842, disc_loss = 0.14942295728503047
Trained batch 37 in epoch 1, gen_loss = 0.386893735120171, disc_loss = 0.15009804697413193
Trained batch 38 in epoch 1, gen_loss = 0.38661872270779735, disc_loss = 0.14831856752817446
Trained batch 39 in epoch 1, gen_loss = 0.3853661611676216, disc_loss = 0.14855202306061982
Trained batch 40 in epoch 1, gen_loss = 0.3857591864539356, disc_loss = 0.15162233335942757
Trained batch 41 in epoch 1, gen_loss = 0.3858114807378678, disc_loss = 0.1512304571058069
Trained batch 42 in epoch 1, gen_loss = 0.384896399669869, disc_loss = 0.15138913777678512
Trained batch 43 in epoch 1, gen_loss = 0.3855434649369933, disc_loss = 0.15082083591683346
Trained batch 44 in epoch 1, gen_loss = 0.3851094749238756, disc_loss = 0.14986536486281288
Trained batch 45 in epoch 1, gen_loss = 0.38421812394390936, disc_loss = 0.14820197564752205
Trained batch 46 in epoch 1, gen_loss = 0.38449596407565667, disc_loss = 0.14766150380068638
Trained batch 47 in epoch 1, gen_loss = 0.3846232444047928, disc_loss = 0.1504876990802586
Trained batch 48 in epoch 1, gen_loss = 0.38620379932072696, disc_loss = 0.14997956445630717
Trained batch 49 in epoch 1, gen_loss = 0.3859016114473343, disc_loss = 0.1490521724522114
Trained batch 50 in epoch 1, gen_loss = 0.38483645869236366, disc_loss = 0.14803775750538883
Trained batch 51 in epoch 1, gen_loss = 0.3844544142484665, disc_loss = 0.14818388954378092
Trained batch 52 in epoch 1, gen_loss = 0.38283828238271317, disc_loss = 0.14982383304609442
Trained batch 53 in epoch 1, gen_loss = 0.38404366705152726, disc_loss = 0.15159511524769995
Trained batch 54 in epoch 1, gen_loss = 0.38427859328009867, disc_loss = 0.15157276595180685
Trained batch 55 in epoch 1, gen_loss = 0.38500174454280306, disc_loss = 0.15089895030749695
Trained batch 56 in epoch 1, gen_loss = 0.38483599926296036, disc_loss = 0.150261857399815
Trained batch 57 in epoch 1, gen_loss = 0.384492803750367, disc_loss = 0.14985565828352138
Trained batch 58 in epoch 1, gen_loss = 0.38492735311136406, disc_loss = 0.1495072943931919
Trained batch 59 in epoch 1, gen_loss = 0.384869829316934, disc_loss = 0.1487605421493451
Trained batch 60 in epoch 1, gen_loss = 0.3840534149623308, disc_loss = 0.14821181886020254
Trained batch 61 in epoch 1, gen_loss = 0.3838094751681051, disc_loss = 0.14868863876308164
Trained batch 62 in epoch 1, gen_loss = 0.38545997559078155, disc_loss = 0.15004575406275097
Trained batch 63 in epoch 1, gen_loss = 0.38601601123809814, disc_loss = 0.14943044318351895
Trained batch 64 in epoch 1, gen_loss = 0.3852463080332829, disc_loss = 0.14808532824883094
Trained batch 65 in epoch 1, gen_loss = 0.38594677050908405, disc_loss = 0.15084506074587503
Trained batch 66 in epoch 1, gen_loss = 0.3860013484954834, disc_loss = 0.15421878046064236
Trained batch 67 in epoch 1, gen_loss = 0.3851397659848718, disc_loss = 0.15626714203287573
Trained batch 68 in epoch 1, gen_loss = 0.38477324143699976, disc_loss = 0.1584143314672553
Trained batch 69 in epoch 1, gen_loss = 0.3852669073002679, disc_loss = 0.15878899289028986
Trained batch 70 in epoch 1, gen_loss = 0.38455707128618805, disc_loss = 0.15957315224157254
Trained batch 71 in epoch 1, gen_loss = 0.3833571531706386, disc_loss = 0.16075537953939703
Trained batch 72 in epoch 1, gen_loss = 0.3815068357611356, disc_loss = 0.16164560738491685
Trained batch 73 in epoch 1, gen_loss = 0.38155082029265325, disc_loss = 0.16174828603460983
Trained batch 74 in epoch 1, gen_loss = 0.38196489651997884, disc_loss = 0.16071092913548152
Trained batch 75 in epoch 1, gen_loss = 0.38114412481847565, disc_loss = 0.15963619172965227
Trained batch 76 in epoch 1, gen_loss = 0.38051492827279226, disc_loss = 0.16045839997468056
Trained batch 77 in epoch 1, gen_loss = 0.38039373893004197, disc_loss = 0.15943020973832178
Trained batch 78 in epoch 1, gen_loss = 0.3802980478805832, disc_loss = 0.15816630913486965
Trained batch 79 in epoch 1, gen_loss = 0.37975344955921175, disc_loss = 0.15677218083292246
Trained batch 80 in epoch 1, gen_loss = 0.38019533878491246, disc_loss = 0.15616506963600346
Trained batch 81 in epoch 1, gen_loss = 0.3795668820782406, disc_loss = 0.15744416343002784
Trained batch 82 in epoch 1, gen_loss = 0.3798811507512288, disc_loss = 0.1567562524094639
Trained batch 83 in epoch 1, gen_loss = 0.37962152489594053, disc_loss = 0.15671103500894137
Trained batch 84 in epoch 1, gen_loss = 0.3800577419645646, disc_loss = 0.15680834405562458
Trained batch 85 in epoch 1, gen_loss = 0.3790380185426668, disc_loss = 0.15627686999911486
Trained batch 86 in epoch 1, gen_loss = 0.37891726658262054, disc_loss = 0.1565912219470945
Trained batch 87 in epoch 1, gen_loss = 0.3776933161372488, disc_loss = 0.15789500361477787
Trained batch 88 in epoch 1, gen_loss = 0.3776279121972202, disc_loss = 0.15833272450090793
Trained batch 89 in epoch 1, gen_loss = 0.37806112898720634, disc_loss = 0.15784014041225117
Trained batch 90 in epoch 1, gen_loss = 0.37811867548869205, disc_loss = 0.157121082338003
Trained batch 91 in epoch 1, gen_loss = 0.377537885437841, disc_loss = 0.15615657644103403
Trained batch 92 in epoch 1, gen_loss = 0.37736546672800536, disc_loss = 0.15488564162965743
Trained batch 93 in epoch 1, gen_loss = 0.3768162397628135, disc_loss = 0.15429055377682474
Trained batch 94 in epoch 1, gen_loss = 0.3776615971013119, disc_loss = 0.1546638598959697
Trained batch 95 in epoch 1, gen_loss = 0.37783351851006347, disc_loss = 0.1542352334363386
Trained batch 96 in epoch 1, gen_loss = 0.378089959473954, disc_loss = 0.1537802572333321
Trained batch 97 in epoch 1, gen_loss = 0.37785542619471646, disc_loss = 0.15312042106323095
Trained batch 98 in epoch 1, gen_loss = 0.3785436132339516, disc_loss = 0.1520775979516482
Trained batch 99 in epoch 1, gen_loss = 0.37918006867170334, disc_loss = 0.15148013949394226
Trained batch 100 in epoch 1, gen_loss = 0.37982864486108914, disc_loss = 0.15211535178788818
Trained batch 101 in epoch 1, gen_loss = 0.3797629729789846, disc_loss = 0.15207367609528935
Trained batch 102 in epoch 1, gen_loss = 0.3792202886447166, disc_loss = 0.15162842981155636
Trained batch 103 in epoch 1, gen_loss = 0.37926555367616505, disc_loss = 0.1512059366617065
Trained batch 104 in epoch 1, gen_loss = 0.3792854993116288, disc_loss = 0.15128612369298935
Trained batch 105 in epoch 1, gen_loss = 0.3790270371257134, disc_loss = 0.15144553548603687
Trained batch 106 in epoch 1, gen_loss = 0.37991658967232034, disc_loss = 0.15177755872501392
Trained batch 107 in epoch 1, gen_loss = 0.3798900602592362, disc_loss = 0.1511722841748485
Trained batch 108 in epoch 1, gen_loss = 0.37952202011685854, disc_loss = 0.15076137402462303
Trained batch 109 in epoch 1, gen_loss = 0.3793203662742268, disc_loss = 0.15204331597143952
Trained batch 110 in epoch 1, gen_loss = 0.37952109258454125, disc_loss = 0.15164303504400425
Trained batch 111 in epoch 1, gen_loss = 0.3793709844882999, disc_loss = 0.1511613508420331
Trained batch 112 in epoch 1, gen_loss = 0.37881306367637835, disc_loss = 0.15099217287734545
Trained batch 113 in epoch 1, gen_loss = 0.37845439372355477, disc_loss = 0.15046903700159306
Trained batch 114 in epoch 1, gen_loss = 0.37823222460954087, disc_loss = 0.15131636987561764
Trained batch 115 in epoch 1, gen_loss = 0.3789205674467416, disc_loss = 0.15222985194674854
Trained batch 116 in epoch 1, gen_loss = 0.37873445387579435, disc_loss = 0.15235671044414878
Trained batch 117 in epoch 1, gen_loss = 0.3781016761973753, disc_loss = 0.15254840696767225
Trained batch 118 in epoch 1, gen_loss = 0.3772490199874429, disc_loss = 0.15250625292293163
Trained batch 119 in epoch 1, gen_loss = 0.37774193038543064, disc_loss = 0.152212767675519
Trained batch 120 in epoch 1, gen_loss = 0.3773326294973862, disc_loss = 0.1516285112574081
Trained batch 121 in epoch 1, gen_loss = 0.3766911344938591, disc_loss = 0.1513968994382952
Trained batch 122 in epoch 1, gen_loss = 0.37649352981792233, disc_loss = 0.15106222045615436
Trained batch 123 in epoch 1, gen_loss = 0.375910704655032, disc_loss = 0.15086496224807155
Trained batch 124 in epoch 1, gen_loss = 0.37583878087997435, disc_loss = 0.15166709864139558
Trained batch 125 in epoch 1, gen_loss = 0.3752302092219156, disc_loss = 0.1512412933839692
Trained batch 126 in epoch 1, gen_loss = 0.3751878787682751, disc_loss = 0.1508554183826672
Trained batch 127 in epoch 1, gen_loss = 0.37477995338849723, disc_loss = 0.15008890195167623
Trained batch 128 in epoch 1, gen_loss = 0.37535624148309693, disc_loss = 0.15002966675069906
Trained batch 129 in epoch 1, gen_loss = 0.3757518688073525, disc_loss = 0.15001673890421025
Trained batch 130 in epoch 1, gen_loss = 0.3756375781452383, disc_loss = 0.14943210914276028
Trained batch 131 in epoch 1, gen_loss = 0.3762270345380812, disc_loss = 0.150178403537156
Trained batch 132 in epoch 1, gen_loss = 0.37589223918161896, disc_loss = 0.14982983422346582
Trained batch 133 in epoch 1, gen_loss = 0.3762129636398002, disc_loss = 0.14908380634081897
Trained batch 134 in epoch 1, gen_loss = 0.3758336987760332, disc_loss = 0.14861060391973566
Trained batch 135 in epoch 1, gen_loss = 0.37508218143792715, disc_loss = 0.14849355038912856
Trained batch 136 in epoch 1, gen_loss = 0.37595772308154696, disc_loss = 0.1478954249054846
Trained batch 137 in epoch 1, gen_loss = 0.3760872632265091, disc_loss = 0.1473324766949467
Trained batch 138 in epoch 1, gen_loss = 0.37680832837983, disc_loss = 0.14672598735891657
Trained batch 139 in epoch 1, gen_loss = 0.37797092561210904, disc_loss = 0.14605241971356528
Trained batch 140 in epoch 1, gen_loss = 0.37865061899448965, disc_loss = 0.14583737123097087
Trained batch 141 in epoch 1, gen_loss = 0.37860132250147804, disc_loss = 0.14534485487031265
Trained batch 142 in epoch 1, gen_loss = 0.3795465028786159, disc_loss = 0.1446375683783651
Trained batch 143 in epoch 1, gen_loss = 0.37943827733397484, disc_loss = 0.14530695938608712
Trained batch 144 in epoch 1, gen_loss = 0.3795014036112818, disc_loss = 0.14654048994697375
Trained batch 145 in epoch 1, gen_loss = 0.3794970391956094, disc_loss = 0.14589226268844246
Trained batch 146 in epoch 1, gen_loss = 0.3794158693073558, disc_loss = 0.14721527819832167
Trained batch 147 in epoch 1, gen_loss = 0.3801496741739479, disc_loss = 0.14862125248623057
Trained batch 148 in epoch 1, gen_loss = 0.3800747758590135, disc_loss = 0.14828209246465024
Trained batch 149 in epoch 1, gen_loss = 0.3796981137990951, disc_loss = 0.14919260042409102
Trained batch 150 in epoch 1, gen_loss = 0.3795628103594117, disc_loss = 0.14895401848171722
Trained batch 151 in epoch 1, gen_loss = 0.37941636850959376, disc_loss = 0.14906777492969445
Trained batch 152 in epoch 1, gen_loss = 0.37938107657276726, disc_loss = 0.14897141145432696
Trained batch 153 in epoch 1, gen_loss = 0.3794840665219666, disc_loss = 0.1487376865289815
Trained batch 154 in epoch 1, gen_loss = 0.3792954796744931, disc_loss = 0.14895732068727094
Trained batch 155 in epoch 1, gen_loss = 0.3793778245647748, disc_loss = 0.14901703569847038
Trained batch 156 in epoch 1, gen_loss = 0.37869408157221074, disc_loss = 0.1492088893843684
Trained batch 157 in epoch 1, gen_loss = 0.3785435695059692, disc_loss = 0.14911600563062144
Trained batch 158 in epoch 1, gen_loss = 0.3781980727828524, disc_loss = 0.1491175356010596
Trained batch 159 in epoch 1, gen_loss = 0.37835970763117077, disc_loss = 0.14973328786436468
Trained batch 160 in epoch 1, gen_loss = 0.37809275562718786, disc_loss = 0.14948696377021925
Trained batch 161 in epoch 1, gen_loss = 0.37830373975965714, disc_loss = 0.14881832766588088
Trained batch 162 in epoch 1, gen_loss = 0.37797156652789904, disc_loss = 0.1484976361271428
Trained batch 163 in epoch 1, gen_loss = 0.3778462297305828, disc_loss = 0.14816983019160787
Trained batch 164 in epoch 1, gen_loss = 0.37755691174304845, disc_loss = 0.14800010705084513
Trained batch 165 in epoch 1, gen_loss = 0.3781682877655489, disc_loss = 0.14770017404962016
Trained batch 166 in epoch 1, gen_loss = 0.3780859985394392, disc_loss = 0.14725185834808263
Trained batch 167 in epoch 1, gen_loss = 0.37766401150396894, disc_loss = 0.1476300977214816
Trained batch 168 in epoch 1, gen_loss = 0.3783076490170857, disc_loss = 0.14844921506809058
Trained batch 169 in epoch 1, gen_loss = 0.3781889005618937, disc_loss = 0.1483278616605436
Trained batch 170 in epoch 1, gen_loss = 0.37792528721324187, disc_loss = 0.14855067416677
Trained batch 171 in epoch 1, gen_loss = 0.3782344108750654, disc_loss = 0.14832208143157322
Trained batch 172 in epoch 1, gen_loss = 0.3789625837968264, disc_loss = 0.1482990755554224
Trained batch 173 in epoch 1, gen_loss = 0.37919749319553375, disc_loss = 0.14808838401289506
Trained batch 174 in epoch 1, gen_loss = 0.37900878616741723, disc_loss = 0.14772000651274408
Trained batch 175 in epoch 1, gen_loss = 0.3788105550814759, disc_loss = 0.1476064309774136
Trained batch 176 in epoch 1, gen_loss = 0.3787816544037081, disc_loss = 0.14769949471462243
Trained batch 177 in epoch 1, gen_loss = 0.37845125158181353, disc_loss = 0.1481245599394099
Trained batch 178 in epoch 1, gen_loss = 0.3782455771329017, disc_loss = 0.14881673095196318
Trained batch 179 in epoch 1, gen_loss = 0.3782782380779584, disc_loss = 0.14879486724320384
Trained batch 180 in epoch 1, gen_loss = 0.37852507253378137, disc_loss = 0.1488717529120037
Trained batch 181 in epoch 1, gen_loss = 0.37820584564418586, disc_loss = 0.14906957841754614
Trained batch 182 in epoch 1, gen_loss = 0.377981425797353, disc_loss = 0.14984084427601002
Trained batch 183 in epoch 1, gen_loss = 0.3781392386426096, disc_loss = 0.15139627470837339
Trained batch 184 in epoch 1, gen_loss = 0.37820635599059027, disc_loss = 0.15134975191306424
Trained batch 185 in epoch 1, gen_loss = 0.3782339068830654, disc_loss = 0.15173506919014199
Trained batch 186 in epoch 1, gen_loss = 0.37788093137868584, disc_loss = 0.15188612950278477
Trained batch 187 in epoch 1, gen_loss = 0.3771755463106835, disc_loss = 0.15201465751817253
Trained batch 188 in epoch 1, gen_loss = 0.37703575745776846, disc_loss = 0.15206126819448496
Trained batch 189 in epoch 1, gen_loss = 0.37702388865383046, disc_loss = 0.15218105784764416
Trained batch 190 in epoch 1, gen_loss = 0.37693690122422124, disc_loss = 0.15189652712479312
Trained batch 191 in epoch 1, gen_loss = 0.37668669029759866, disc_loss = 0.15142316250906637
Trained batch 192 in epoch 1, gen_loss = 0.37676940364232336, disc_loss = 0.1512973413952274
Trained batch 193 in epoch 1, gen_loss = 0.3767616794127779, disc_loss = 0.15142292279711703
Trained batch 194 in epoch 1, gen_loss = 0.37674625768111303, disc_loss = 0.15124944024361098
Trained batch 195 in epoch 1, gen_loss = 0.37676438058213313, disc_loss = 0.15080319782148818
Trained batch 196 in epoch 1, gen_loss = 0.3768130108941025, disc_loss = 0.15052755982591415
Trained batch 197 in epoch 1, gen_loss = 0.37682787750405494, disc_loss = 0.15072495877893285
Trained batch 198 in epoch 1, gen_loss = 0.37690668092600665, disc_loss = 0.15132921608398908
Trained batch 199 in epoch 1, gen_loss = 0.37710764549672604, disc_loss = 0.15157333303242923
Trained batch 200 in epoch 1, gen_loss = 0.377024590005329, disc_loss = 0.15176671361597024
Trained batch 201 in epoch 1, gen_loss = 0.3768448421713149, disc_loss = 0.1518563984127918
Trained batch 202 in epoch 1, gen_loss = 0.3771399715410665, disc_loss = 0.15160607197895426
Trained batch 203 in epoch 1, gen_loss = 0.3774189178411867, disc_loss = 0.1514439519275637
Trained batch 204 in epoch 1, gen_loss = 0.37729162988139364, disc_loss = 0.15112708170966405
Trained batch 205 in epoch 1, gen_loss = 0.37759486672658366, disc_loss = 0.15187828101724096
Trained batch 206 in epoch 1, gen_loss = 0.37751755168760454, disc_loss = 0.15164637569212108
Trained batch 207 in epoch 1, gen_loss = 0.3776289807059444, disc_loss = 0.15148617850186732
Trained batch 208 in epoch 1, gen_loss = 0.37782315867084065, disc_loss = 0.15182769876062585
Trained batch 209 in epoch 1, gen_loss = 0.3777027414668174, disc_loss = 0.15183909173522678
Trained batch 210 in epoch 1, gen_loss = 0.3783210437585957, disc_loss = 0.15149225799534558
Trained batch 211 in epoch 1, gen_loss = 0.37842778854493825, disc_loss = 0.15188505335377073
Trained batch 212 in epoch 1, gen_loss = 0.37812892742839777, disc_loss = 0.15170304127422296
Trained batch 213 in epoch 1, gen_loss = 0.37791654558103777, disc_loss = 0.15139333385034143
Trained batch 214 in epoch 1, gen_loss = 0.3781347502802694, disc_loss = 0.15118412441292475
Trained batch 215 in epoch 1, gen_loss = 0.37800979483182784, disc_loss = 0.15094742196163646
Trained batch 216 in epoch 1, gen_loss = 0.3777032644929974, disc_loss = 0.15084206045085932
Trained batch 217 in epoch 1, gen_loss = 0.3777066685874528, disc_loss = 0.15098838197118644
Trained batch 218 in epoch 1, gen_loss = 0.37830786488644064, disc_loss = 0.1509749620268334
Trained batch 219 in epoch 1, gen_loss = 0.37860305763103747, disc_loss = 0.15056335815990513
Trained batch 220 in epoch 1, gen_loss = 0.3784199711019637, disc_loss = 0.15086037282962605
Trained batch 221 in epoch 1, gen_loss = 0.37861264188278904, disc_loss = 0.1511136267736957
Trained batch 222 in epoch 1, gen_loss = 0.3785829409756468, disc_loss = 0.15064656819663774
Trained batch 223 in epoch 1, gen_loss = 0.37839488305949737, disc_loss = 0.15049256588931062
Trained batch 224 in epoch 1, gen_loss = 0.3784435095389684, disc_loss = 0.15024125580986342
Trained batch 225 in epoch 1, gen_loss = 0.37859810420633416, disc_loss = 0.14988297469650222
Trained batch 226 in epoch 1, gen_loss = 0.3786504791827979, disc_loss = 0.14929271171008962
Trained batch 227 in epoch 1, gen_loss = 0.37867096935709316, disc_loss = 0.1497208500901858
Trained batch 228 in epoch 1, gen_loss = 0.37909437833134263, disc_loss = 0.150654800333831
Trained batch 229 in epoch 1, gen_loss = 0.3789063622770102, disc_loss = 0.15060660165289175
Trained batch 230 in epoch 1, gen_loss = 0.37874285515510675, disc_loss = 0.15050578697935327
Trained batch 231 in epoch 1, gen_loss = 0.37842689846353283, disc_loss = 0.1503428047330215
Trained batch 232 in epoch 1, gen_loss = 0.37884856133757744, disc_loss = 0.1500271159052337
Trained batch 233 in epoch 1, gen_loss = 0.3788806747040178, disc_loss = 0.15023235008757338
Trained batch 234 in epoch 1, gen_loss = 0.37869671703653135, disc_loss = 0.1500118904925407
Trained batch 235 in epoch 1, gen_loss = 0.37905379365813935, disc_loss = 0.1498552888821242
Trained batch 236 in epoch 1, gen_loss = 0.3793127113631003, disc_loss = 0.14990011520903826
Trained batch 237 in epoch 1, gen_loss = 0.37912605007906924, disc_loss = 0.14996705752085238
Trained batch 238 in epoch 1, gen_loss = 0.37928251136546354, disc_loss = 0.1506100964409038
Trained batch 239 in epoch 1, gen_loss = 0.3794331504032016, disc_loss = 0.15034417640417813
Trained batch 240 in epoch 1, gen_loss = 0.3796745752026926, disc_loss = 0.15016498565055522
Trained batch 241 in epoch 1, gen_loss = 0.3794206436877408, disc_loss = 0.1499031385914846
Trained batch 242 in epoch 1, gen_loss = 0.37923668619291284, disc_loss = 0.14955678039494855
Trained batch 243 in epoch 1, gen_loss = 0.3791103120587888, disc_loss = 0.1496403151665066
Trained batch 244 in epoch 1, gen_loss = 0.37958683499268125, disc_loss = 0.1502048704393056
Trained batch 245 in epoch 1, gen_loss = 0.37961955738019165, disc_loss = 0.14997385348367498
Trained batch 246 in epoch 1, gen_loss = 0.37941768023407896, disc_loss = 0.15002410448635156
Trained batch 247 in epoch 1, gen_loss = 0.3795503483063752, disc_loss = 0.14962856491066276
Trained batch 248 in epoch 1, gen_loss = 0.3796660694850975, disc_loss = 0.1492569140162334
Trained batch 249 in epoch 1, gen_loss = 0.379655227959156, disc_loss = 0.14953473663330077
Trained batch 250 in epoch 1, gen_loss = 0.37937378319373644, disc_loss = 0.14951954378312327
Trained batch 251 in epoch 1, gen_loss = 0.3793154480083594, disc_loss = 0.14923373538823353
Trained batch 252 in epoch 1, gen_loss = 0.3794199855549062, disc_loss = 0.14876864691496838
Trained batch 253 in epoch 1, gen_loss = 0.379515789097219, disc_loss = 0.14837721714705931
Trained batch 254 in epoch 1, gen_loss = 0.3795197558753631, disc_loss = 0.1478785079776072
Trained batch 255 in epoch 1, gen_loss = 0.37945820653112605, disc_loss = 0.1473680001363391
Trained batch 256 in epoch 1, gen_loss = 0.37926382864263736, disc_loss = 0.14707327200686884
Trained batch 257 in epoch 1, gen_loss = 0.3795161597835001, disc_loss = 0.14690531153491762
Trained batch 258 in epoch 1, gen_loss = 0.37954341059255786, disc_loss = 0.14653676275063204
Trained batch 259 in epoch 1, gen_loss = 0.3795127751162419, disc_loss = 0.14631165734563883
Trained batch 260 in epoch 1, gen_loss = 0.3797165492827865, disc_loss = 0.14609008663515935
Trained batch 261 in epoch 1, gen_loss = 0.37976612872977294, disc_loss = 0.14624059622581223
Trained batch 262 in epoch 1, gen_loss = 0.37987907038215446, disc_loss = 0.14631947689466604
Trained batch 263 in epoch 1, gen_loss = 0.3798578382102829, disc_loss = 0.14599993678204942
Trained batch 264 in epoch 1, gen_loss = 0.37972961771038344, disc_loss = 0.1458398386836052
Trained batch 265 in epoch 1, gen_loss = 0.3801907640986873, disc_loss = 0.1454747409552784
Trained batch 266 in epoch 1, gen_loss = 0.3803643890646067, disc_loss = 0.1451991864441709
Trained batch 267 in epoch 1, gen_loss = 0.38039150928605847, disc_loss = 0.14499529321858687
Trained batch 268 in epoch 1, gen_loss = 0.3804052726376012, disc_loss = 0.14492262477491424
Trained batch 269 in epoch 1, gen_loss = 0.38014712902130904, disc_loss = 0.1447874146617121
Trained batch 270 in epoch 1, gen_loss = 0.38022655056191546, disc_loss = 0.14456150569434095
Trained batch 271 in epoch 1, gen_loss = 0.38045961809728074, disc_loss = 0.14423445280750885
Trained batch 272 in epoch 1, gen_loss = 0.3806013224216608, disc_loss = 0.14405840599820727
Trained batch 273 in epoch 1, gen_loss = 0.38058868164781234, disc_loss = 0.14385614095486865
Trained batch 274 in epoch 1, gen_loss = 0.3807913049242713, disc_loss = 0.1435608684745702
Trained batch 275 in epoch 1, gen_loss = 0.3809901489403801, disc_loss = 0.14317279500697833
Trained batch 276 in epoch 1, gen_loss = 0.380913229894552, disc_loss = 0.14316979671966298
Trained batch 277 in epoch 1, gen_loss = 0.3807774131997026, disc_loss = 0.14300415214660356
Trained batch 278 in epoch 1, gen_loss = 0.3807967425354065, disc_loss = 0.14289215410054798
Trained batch 279 in epoch 1, gen_loss = 0.38084481778953755, disc_loss = 0.14249249938875436
Trained batch 280 in epoch 1, gen_loss = 0.38095717195726375, disc_loss = 0.14220218042249783
Trained batch 281 in epoch 1, gen_loss = 0.38130009570654405, disc_loss = 0.14204424794049972
Trained batch 282 in epoch 1, gen_loss = 0.3814861920296935, disc_loss = 0.1416336606345518
Trained batch 283 in epoch 1, gen_loss = 0.3814961913920624, disc_loss = 0.14154720509057522
Trained batch 284 in epoch 1, gen_loss = 0.3817532608906428, disc_loss = 0.14153009949153975
Trained batch 285 in epoch 1, gen_loss = 0.38195518873163037, disc_loss = 0.14114516674560476
Trained batch 286 in epoch 1, gen_loss = 0.3821134518974749, disc_loss = 0.1409516087457382
Trained batch 287 in epoch 1, gen_loss = 0.38262309563449687, disc_loss = 0.14075389091158286
Trained batch 288 in epoch 1, gen_loss = 0.38247405044141525, disc_loss = 0.14047212159473796
Trained batch 289 in epoch 1, gen_loss = 0.382561573334809, disc_loss = 0.1402541659322792
Trained batch 290 in epoch 1, gen_loss = 0.38274438341253814, disc_loss = 0.14016039501171546
Trained batch 291 in epoch 1, gen_loss = 0.3825853783892442, disc_loss = 0.1399514912500059
Trained batch 292 in epoch 1, gen_loss = 0.3826092469916002, disc_loss = 0.14015581182270936
Trained batch 293 in epoch 1, gen_loss = 0.3829813792693372, disc_loss = 0.14115669710726356
Trained batch 294 in epoch 1, gen_loss = 0.3829514839386536, disc_loss = 0.14090213463089224
Trained batch 295 in epoch 1, gen_loss = 0.3830857862391182, disc_loss = 0.14114881644805743
Trained batch 296 in epoch 1, gen_loss = 0.38286930498250005, disc_loss = 0.1408109140177869
Trained batch 297 in epoch 1, gen_loss = 0.3829301170154706, disc_loss = 0.14082213391818657
Trained batch 298 in epoch 1, gen_loss = 0.38272037808113674, disc_loss = 0.14101577887193215
Trained batch 299 in epoch 1, gen_loss = 0.3827548105021318, disc_loss = 0.14078873043879866
Trained batch 300 in epoch 1, gen_loss = 0.38283336603166257, disc_loss = 0.1405971754292812
Trained batch 301 in epoch 1, gen_loss = 0.38293044204940857, disc_loss = 0.1404187534288164
Trained batch 302 in epoch 1, gen_loss = 0.3831296096442163, disc_loss = 0.14007850105047423
Trained batch 303 in epoch 1, gen_loss = 0.3832649642993745, disc_loss = 0.1397593523265402
Trained batch 304 in epoch 1, gen_loss = 0.3834252415621867, disc_loss = 0.13952962523478954
Trained batch 305 in epoch 1, gen_loss = 0.3836665092632661, disc_loss = 0.13935747432820741
Trained batch 306 in epoch 1, gen_loss = 0.383980049226882, disc_loss = 0.13905707581108284
Trained batch 307 in epoch 1, gen_loss = 0.3839832510944311, disc_loss = 0.13911118524681246
Trained batch 308 in epoch 1, gen_loss = 0.38398530196796343, disc_loss = 0.13977615223612794
Trained batch 309 in epoch 1, gen_loss = 0.38414672608337097, disc_loss = 0.13956665831107284
Trained batch 310 in epoch 1, gen_loss = 0.38425383014885944, disc_loss = 0.13924064775299988
Trained batch 311 in epoch 1, gen_loss = 0.38440310759231067, disc_loss = 0.13951153497402677
Trained batch 312 in epoch 1, gen_loss = 0.3841397411430987, disc_loss = 0.1403331919231068
Trained batch 313 in epoch 1, gen_loss = 0.38423401027158566, disc_loss = 0.14059207558181067
Trained batch 314 in epoch 1, gen_loss = 0.38426544699403975, disc_loss = 0.14067766896434247
Trained batch 315 in epoch 1, gen_loss = 0.3844371931745282, disc_loss = 0.14073008150923288
Trained batch 316 in epoch 1, gen_loss = 0.3846538256301489, disc_loss = 0.14069179474296817
Trained batch 317 in epoch 1, gen_loss = 0.3845255478466832, disc_loss = 0.1406971583869191
Trained batch 318 in epoch 1, gen_loss = 0.38447696722600155, disc_loss = 0.1405360453519795
Trained batch 319 in epoch 1, gen_loss = 0.3846877712290734, disc_loss = 0.14043741771602072
Trained batch 320 in epoch 1, gen_loss = 0.38488369052098176, disc_loss = 0.1401927713304758
Trained batch 321 in epoch 1, gen_loss = 0.38506096115578775, disc_loss = 0.1402188724901828
Trained batch 322 in epoch 1, gen_loss = 0.3851061216541119, disc_loss = 0.13996475745257764
Trained batch 323 in epoch 1, gen_loss = 0.3854869621127476, disc_loss = 0.13965845351210898
Trained batch 324 in epoch 1, gen_loss = 0.3855193310059034, disc_loss = 0.13934436266811995
Trained batch 325 in epoch 1, gen_loss = 0.38544684552524716, disc_loss = 0.1390377978617154
Trained batch 326 in epoch 1, gen_loss = 0.38558864324646985, disc_loss = 0.13874775092103248
Trained batch 327 in epoch 1, gen_loss = 0.3857575683604653, disc_loss = 0.13838983895597842
Trained batch 328 in epoch 1, gen_loss = 0.385913660506347, disc_loss = 0.13802921915240018
Trained batch 329 in epoch 1, gen_loss = 0.3860902073256897, disc_loss = 0.1376570729849239
Trained batch 330 in epoch 1, gen_loss = 0.3862934285870492, disc_loss = 0.13733233930402383
Trained batch 331 in epoch 1, gen_loss = 0.38624606079545365, disc_loss = 0.136972225459113
Trained batch 332 in epoch 1, gen_loss = 0.38634194541084876, disc_loss = 0.13662508253970215
Trained batch 333 in epoch 1, gen_loss = 0.38654460633050897, disc_loss = 0.13628539583272117
Trained batch 334 in epoch 1, gen_loss = 0.3866021854219152, disc_loss = 0.13598234213944246
Trained batch 335 in epoch 1, gen_loss = 0.3868732117559938, disc_loss = 0.13564493545674763
Trained batch 336 in epoch 1, gen_loss = 0.3868575337113542, disc_loss = 0.13545612248838038
Trained batch 337 in epoch 1, gen_loss = 0.3869366205391094, disc_loss = 0.13524194285218444
Trained batch 338 in epoch 1, gen_loss = 0.38703578108355713, disc_loss = 0.13493245794742773
Trained batch 339 in epoch 1, gen_loss = 0.3870449524153681, disc_loss = 0.13523404601249187
Trained batch 340 in epoch 1, gen_loss = 0.3876356101892561, disc_loss = 0.13517346321345686
Trained batch 341 in epoch 1, gen_loss = 0.3880178299650811, disc_loss = 0.13491154755928625
Trained batch 342 in epoch 1, gen_loss = 0.3878695271887515, disc_loss = 0.13482375605623767
Trained batch 343 in epoch 1, gen_loss = 0.3879957761788784, disc_loss = 0.13471098077147767
Trained batch 344 in epoch 1, gen_loss = 0.3880021829104078, disc_loss = 0.1345404776947006
Trained batch 345 in epoch 1, gen_loss = 0.38807552876327767, disc_loss = 0.13472682452690654
Trained batch 346 in epoch 1, gen_loss = 0.388332902483363, disc_loss = 0.13496968884192814
Trained batch 347 in epoch 1, gen_loss = 0.3882390870016882, disc_loss = 0.1349795106557551
Trained batch 348 in epoch 1, gen_loss = 0.38793431478619234, disc_loss = 0.13498095211367467
Trained batch 349 in epoch 1, gen_loss = 0.38811212918588095, disc_loss = 0.13515845302758472
Trained batch 350 in epoch 1, gen_loss = 0.38794002960040697, disc_loss = 0.13536475687699015
Trained batch 351 in epoch 1, gen_loss = 0.38791625104336575, disc_loss = 0.13541997418558988
Trained batch 352 in epoch 1, gen_loss = 0.38772684686075864, disc_loss = 0.13592222687279115
Trained batch 353 in epoch 1, gen_loss = 0.3878274505673829, disc_loss = 0.13640492623882358
Trained batch 354 in epoch 1, gen_loss = 0.3877535353663942, disc_loss = 0.13635303212041167
Trained batch 355 in epoch 1, gen_loss = 0.3879285366431381, disc_loss = 0.13631109300781083
Trained batch 356 in epoch 1, gen_loss = 0.38781779841715547, disc_loss = 0.1362856928055652
Trained batch 357 in epoch 1, gen_loss = 0.3877047592950933, disc_loss = 0.13637066130687656
Trained batch 358 in epoch 1, gen_loss = 0.3877727628833404, disc_loss = 0.13642737437247152
Trained batch 359 in epoch 1, gen_loss = 0.38752852285073863, disc_loss = 0.1362900712191024
Trained batch 360 in epoch 1, gen_loss = 0.3875028337055296, disc_loss = 0.13621607187289198
Trained batch 361 in epoch 1, gen_loss = 0.3875633521386273, disc_loss = 0.13640066116626337
Trained batch 362 in epoch 1, gen_loss = 0.3874938574622157, disc_loss = 0.1364009517422023
Trained batch 363 in epoch 1, gen_loss = 0.3875232209134233, disc_loss = 0.1362237124627067
Trained batch 364 in epoch 1, gen_loss = 0.38748202760742134, disc_loss = 0.13621574782906737
Trained batch 365 in epoch 1, gen_loss = 0.3872285131466845, disc_loss = 0.1364172045624932
Trained batch 366 in epoch 1, gen_loss = 0.3875509751833752, disc_loss = 0.1362886019330218
Trained batch 367 in epoch 1, gen_loss = 0.3878429097568859, disc_loss = 0.1362604730251326
Trained batch 368 in epoch 1, gen_loss = 0.38773719627198167, disc_loss = 0.13627069051501148
Trained batch 369 in epoch 1, gen_loss = 0.38775385694729314, disc_loss = 0.1363672123743674
Trained batch 370 in epoch 1, gen_loss = 0.38758071281035955, disc_loss = 0.13672724817791637
Trained batch 371 in epoch 1, gen_loss = 0.38765550552997535, disc_loss = 0.1369431794105318
Trained batch 372 in epoch 1, gen_loss = 0.38741067111811756, disc_loss = 0.13679759006387987
Trained batch 373 in epoch 1, gen_loss = 0.38734798503910156, disc_loss = 0.1372660589504011
Trained batch 374 in epoch 1, gen_loss = 0.38752889931201934, disc_loss = 0.13718886114905277
Trained batch 375 in epoch 1, gen_loss = 0.3875938585384729, disc_loss = 0.1370966602884669
Trained batch 376 in epoch 1, gen_loss = 0.3873578410803165, disc_loss = 0.13716958379941135
Trained batch 377 in epoch 1, gen_loss = 0.3875079522766764, disc_loss = 0.13705395968019884
Trained batch 378 in epoch 1, gen_loss = 0.3877155781971748, disc_loss = 0.1369189578907117
Trained batch 379 in epoch 1, gen_loss = 0.3876128593949895, disc_loss = 0.13667119388272495
Trained batch 380 in epoch 1, gen_loss = 0.3874371568440139, disc_loss = 0.13649880475171516
Trained batch 381 in epoch 1, gen_loss = 0.3876333033461221, disc_loss = 0.1369020844838967
Trained batch 382 in epoch 1, gen_loss = 0.38773777096607664, disc_loss = 0.1369629330305728
Trained batch 383 in epoch 1, gen_loss = 0.38739840193496394, disc_loss = 0.13712743553090453
Trained batch 384 in epoch 1, gen_loss = 0.3870609417751238, disc_loss = 0.1372810397805138
Trained batch 385 in epoch 1, gen_loss = 0.3871685342544719, disc_loss = 0.13730966175998044
Trained batch 386 in epoch 1, gen_loss = 0.3872385764691873, disc_loss = 0.13732999951869865
Trained batch 387 in epoch 1, gen_loss = 0.3871614114602202, disc_loss = 0.13721414536151305
Trained batch 388 in epoch 1, gen_loss = 0.38746992010230574, disc_loss = 0.13698417616524472
Trained batch 389 in epoch 1, gen_loss = 0.3874497134334002, disc_loss = 0.13671311662317467
Trained batch 390 in epoch 1, gen_loss = 0.3875458796539575, disc_loss = 0.136481168160639
Trained batch 391 in epoch 1, gen_loss = 0.38729019352824107, disc_loss = 0.1363744856480851
Trained batch 392 in epoch 1, gen_loss = 0.3871976999001952, disc_loss = 0.13674261482342434
Trained batch 393 in epoch 1, gen_loss = 0.3875479166050853, disc_loss = 0.13680043384234236
Trained batch 394 in epoch 1, gen_loss = 0.3876601187865945, disc_loss = 0.13657385226622035
Trained batch 395 in epoch 1, gen_loss = 0.3877555054772382, disc_loss = 0.13632335638712076
Trained batch 396 in epoch 1, gen_loss = 0.38789963418200274, disc_loss = 0.136078906756936
Trained batch 397 in epoch 1, gen_loss = 0.3880740060054477, disc_loss = 0.13581303022474275
Trained batch 398 in epoch 1, gen_loss = 0.3882267566626532, disc_loss = 0.13557429803315932
Trained batch 399 in epoch 1, gen_loss = 0.3884396179392934, disc_loss = 0.1353320707497187
Trained batch 400 in epoch 1, gen_loss = 0.388279103467292, disc_loss = 0.13515768734566366
Trained batch 401 in epoch 1, gen_loss = 0.38856408552299093, disc_loss = 0.13487903897265963
Trained batch 402 in epoch 1, gen_loss = 0.38865503458024253, disc_loss = 0.13497976538385484
Trained batch 403 in epoch 1, gen_loss = 0.38873416572661684, disc_loss = 0.1351027634515805
Trained batch 404 in epoch 1, gen_loss = 0.38885370636427846, disc_loss = 0.13488486134389668
Trained batch 405 in epoch 1, gen_loss = 0.3889980948543901, disc_loss = 0.1348898105181093
Trained batch 406 in epoch 1, gen_loss = 0.3889215804947682, disc_loss = 0.1352179399474137
Trained batch 407 in epoch 1, gen_loss = 0.38906637575550407, disc_loss = 0.13526363986060388
Trained batch 408 in epoch 1, gen_loss = 0.38900049307672785, disc_loss = 0.13520623311118057
Trained batch 409 in epoch 1, gen_loss = 0.38929251174374324, disc_loss = 0.13502798919316109
Trained batch 410 in epoch 1, gen_loss = 0.38930329336012076, disc_loss = 0.13502805862448874
Trained batch 411 in epoch 1, gen_loss = 0.38917756807601567, disc_loss = 0.13548739293581147
Trained batch 412 in epoch 1, gen_loss = 0.38945899073927515, disc_loss = 0.1359108957342497
Trained batch 413 in epoch 1, gen_loss = 0.3893120445419049, disc_loss = 0.13674567225231712
Trained batch 414 in epoch 1, gen_loss = 0.38951803478131813, disc_loss = 0.13726694637079195
Trained batch 415 in epoch 1, gen_loss = 0.38931337611463207, disc_loss = 0.1374761102510652
Trained batch 416 in epoch 1, gen_loss = 0.38919141935072926, disc_loss = 0.13760970214189744
Trained batch 417 in epoch 1, gen_loss = 0.3891224473643531, disc_loss = 0.13793688234717152
Trained batch 418 in epoch 1, gen_loss = 0.38928442834243, disc_loss = 0.13831448013758674
Trained batch 419 in epoch 1, gen_loss = 0.38919118071595826, disc_loss = 0.13848609465972653
Trained batch 420 in epoch 1, gen_loss = 0.38902825559544735, disc_loss = 0.13871249315193954
Trained batch 421 in epoch 1, gen_loss = 0.3890977485979338, disc_loss = 0.13866176063600946
Trained batch 422 in epoch 1, gen_loss = 0.3891195203606964, disc_loss = 0.13863598154835738
Trained batch 423 in epoch 1, gen_loss = 0.38895128734128653, disc_loss = 0.13879262599083683
Trained batch 424 in epoch 1, gen_loss = 0.38910294739639056, disc_loss = 0.13876658940359074
Trained batch 425 in epoch 1, gen_loss = 0.3889788478403024, disc_loss = 0.13883366924819882
Trained batch 426 in epoch 1, gen_loss = 0.38893473591542077, disc_loss = 0.13910603288787937
Trained batch 427 in epoch 1, gen_loss = 0.3889155248267071, disc_loss = 0.13907654262496003
Trained batch 428 in epoch 1, gen_loss = 0.38902867239810923, disc_loss = 0.13925878539690117
Trained batch 429 in epoch 1, gen_loss = 0.3890222384139549, disc_loss = 0.13956060069288279
Trained batch 430 in epoch 1, gen_loss = 0.3889013928838783, disc_loss = 0.139527430556922
Trained batch 431 in epoch 1, gen_loss = 0.3888379212951771, disc_loss = 0.1394761717917087
Trained batch 432 in epoch 1, gen_loss = 0.38894999774030947, disc_loss = 0.1394572709439705
Trained batch 433 in epoch 1, gen_loss = 0.3890300151733209, disc_loss = 0.13927746210719377
Trained batch 434 in epoch 1, gen_loss = 0.38917467789403326, disc_loss = 0.13914488811131523
Trained batch 435 in epoch 1, gen_loss = 0.38905719718938575, disc_loss = 0.13912236236181075
Trained batch 436 in epoch 1, gen_loss = 0.3890816107290015, disc_loss = 0.13925993763276928
Trained batch 437 in epoch 1, gen_loss = 0.38922650564342876, disc_loss = 0.13934800583554524
Trained batch 438 in epoch 1, gen_loss = 0.38932263392929606, disc_loss = 0.13923661760637931
Trained batch 439 in epoch 1, gen_loss = 0.38931791379370473, disc_loss = 0.13918628657279028
Trained batch 440 in epoch 1, gen_loss = 0.3891697599977052, disc_loss = 0.13903636441623068
Trained batch 441 in epoch 1, gen_loss = 0.38900958787127315, disc_loss = 0.13888984502449092
Trained batch 442 in epoch 1, gen_loss = 0.38913267632235793, disc_loss = 0.138665496102591
Trained batch 443 in epoch 1, gen_loss = 0.3891800260423003, disc_loss = 0.13848263261260818
Trained batch 444 in epoch 1, gen_loss = 0.38927853700150267, disc_loss = 0.13832686735379895
Trained batch 445 in epoch 1, gen_loss = 0.38929992723758977, disc_loss = 0.13809363267722752
Trained batch 446 in epoch 1, gen_loss = 0.3890363517690292, disc_loss = 0.13804623472318886
Trained batch 447 in epoch 1, gen_loss = 0.3891550582900111, disc_loss = 0.1379891844137871
Trained batch 448 in epoch 1, gen_loss = 0.3892063435108996, disc_loss = 0.13800185307536797
Trained batch 449 in epoch 1, gen_loss = 0.3893953595889939, disc_loss = 0.13792312980732985
Trained batch 450 in epoch 1, gen_loss = 0.3895141525635962, disc_loss = 0.1378653197592649
Trained batch 451 in epoch 1, gen_loss = 0.38960144929258167, disc_loss = 0.13774369219606494
Trained batch 452 in epoch 1, gen_loss = 0.38966737332328266, disc_loss = 0.13759263068083963
Trained batch 453 in epoch 1, gen_loss = 0.3895941197150079, disc_loss = 0.13740175628690007
Trained batch 454 in epoch 1, gen_loss = 0.3897460557929762, disc_loss = 0.13720777917571447
Trained batch 455 in epoch 1, gen_loss = 0.38977384929986375, disc_loss = 0.13714599451091009
Trained batch 456 in epoch 1, gen_loss = 0.3901576533815793, disc_loss = 0.13725114959603912
Trained batch 457 in epoch 1, gen_loss = 0.3900936323026903, disc_loss = 0.13717318420790495
Trained batch 458 in epoch 1, gen_loss = 0.39032210494048714, disc_loss = 0.13698263172758235
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.3101087212562561, disc_loss = 0.12055008113384247
Trained batch 1 in epoch 2, gen_loss = 0.3624734878540039, disc_loss = 0.0924297645688057
Trained batch 2 in epoch 2, gen_loss = 0.35919949412345886, disc_loss = 0.08555847158034642
Trained batch 3 in epoch 2, gen_loss = 0.3439466059207916, disc_loss = 0.11501836962997913
Trained batch 4 in epoch 2, gen_loss = 0.35739210844039915, disc_loss = 0.10050199627876281
Trained batch 5 in epoch 2, gen_loss = 0.3721034775177638, disc_loss = 0.09979199493924777
Trained batch 6 in epoch 2, gen_loss = 0.3759375044277736, disc_loss = 0.11096710924591337
Trained batch 7 in epoch 2, gen_loss = 0.39150799810886383, disc_loss = 0.11069714464247227
Trained batch 8 in epoch 2, gen_loss = 0.38584814469019574, disc_loss = 0.10551219847467211
Trained batch 9 in epoch 2, gen_loss = 0.38263423144817355, disc_loss = 0.10272244215011597
Trained batch 10 in epoch 2, gen_loss = 0.37809587066823785, disc_loss = 0.09680031104521318
Trained batch 11 in epoch 2, gen_loss = 0.3789049983024597, disc_loss = 0.09339792343477409
Trained batch 12 in epoch 2, gen_loss = 0.38464441666236293, disc_loss = 0.09110030245322448
Trained batch 13 in epoch 2, gen_loss = 0.3948624006339482, disc_loss = 0.09620166410292898
Trained batch 14 in epoch 2, gen_loss = 0.3918528954188029, disc_loss = 0.09147001231710115
Trained batch 15 in epoch 2, gen_loss = 0.3871755860745907, disc_loss = 0.09541701176203787
Trained batch 16 in epoch 2, gen_loss = 0.3860324831569896, disc_loss = 0.11563490440740305
Trained batch 17 in epoch 2, gen_loss = 0.3880910575389862, disc_loss = 0.11527595110237598
Trained batch 18 in epoch 2, gen_loss = 0.38973763898799296, disc_loss = 0.11214582151488255
Trained batch 19 in epoch 2, gen_loss = 0.3871610760688782, disc_loss = 0.10753232100978494
Trained batch 20 in epoch 2, gen_loss = 0.3853928233895983, disc_loss = 0.10415261194464706
Trained batch 21 in epoch 2, gen_loss = 0.3832949941808527, disc_loss = 0.10196510592306202
Trained batch 22 in epoch 2, gen_loss = 0.38623770682708075, disc_loss = 0.09964092245892338
Trained batch 23 in epoch 2, gen_loss = 0.3887324432531993, disc_loss = 0.09959760905864339
Trained batch 24 in epoch 2, gen_loss = 0.3874583649635315, disc_loss = 0.1055897007137537
Trained batch 25 in epoch 2, gen_loss = 0.38945637757961565, disc_loss = 0.10791232358091153
Trained batch 26 in epoch 2, gen_loss = 0.3858340161818045, disc_loss = 0.10615051820598266
Trained batch 27 in epoch 2, gen_loss = 0.3832926558596747, disc_loss = 0.1077564798428544
Trained batch 28 in epoch 2, gen_loss = 0.38440036568148384, disc_loss = 0.10595373212006585
Trained batch 29 in epoch 2, gen_loss = 0.38562734027703605, disc_loss = 0.1032930393392841
Trained batch 30 in epoch 2, gen_loss = 0.38795954085165457, disc_loss = 0.10143211886527077
Trained batch 31 in epoch 2, gen_loss = 0.38972748164087534, disc_loss = 0.09931044484255835
Trained batch 32 in epoch 2, gen_loss = 0.38992606780745764, disc_loss = 0.0970120546831326
Trained batch 33 in epoch 2, gen_loss = 0.3901683600509868, disc_loss = 0.09511253955390524
Trained batch 34 in epoch 2, gen_loss = 0.39098345126424516, disc_loss = 0.09312857682151454
Trained batch 35 in epoch 2, gen_loss = 0.39509906123081845, disc_loss = 0.09126809896487328
Trained batch 36 in epoch 2, gen_loss = 0.3967978688510689, disc_loss = 0.089334357026461
Trained batch 37 in epoch 2, gen_loss = 0.39725067192002345, disc_loss = 0.08792454141535257
Trained batch 38 in epoch 2, gen_loss = 0.39630383482346165, disc_loss = 0.09128658530803826
Trained batch 39 in epoch 2, gen_loss = 0.39883161783218385, disc_loss = 0.09725801143795251
Trained batch 40 in epoch 2, gen_loss = 0.39964944414976167, disc_loss = 0.09737005284646662
Trained batch 41 in epoch 2, gen_loss = 0.3998315121446337, disc_loss = 0.09534387130822454
Trained batch 42 in epoch 2, gen_loss = 0.4002273034217746, disc_loss = 0.09415618364894113
Trained batch 43 in epoch 2, gen_loss = 0.39985705437985336, disc_loss = 0.09268399658189579
Trained batch 44 in epoch 2, gen_loss = 0.40026825467745464, disc_loss = 0.09113583924869696
Trained batch 45 in epoch 2, gen_loss = 0.4014787259309188, disc_loss = 0.08992533576067376
Trained batch 46 in epoch 2, gen_loss = 0.39965769521733546, disc_loss = 0.0883417314592194
Trained batch 47 in epoch 2, gen_loss = 0.3995481462528308, disc_loss = 0.08677645815381159
Trained batch 48 in epoch 2, gen_loss = 0.4000260957649776, disc_loss = 0.08546682625856934
Trained batch 49 in epoch 2, gen_loss = 0.3994439178705215, disc_loss = 0.0845130619034171
Trained batch 50 in epoch 2, gen_loss = 0.40129326780637103, disc_loss = 0.08357866462685314
Trained batch 51 in epoch 2, gen_loss = 0.40170513609280956, disc_loss = 0.08255635004920456
Trained batch 52 in epoch 2, gen_loss = 0.40247924653988965, disc_loss = 0.0823507059084357
Trained batch 53 in epoch 2, gen_loss = 0.4034367722493631, disc_loss = 0.08174801690296994
Trained batch 54 in epoch 2, gen_loss = 0.4034977403554049, disc_loss = 0.08053394881161777
Trained batch 55 in epoch 2, gen_loss = 0.4039329583091395, disc_loss = 0.07947955340413111
Trained batch 56 in epoch 2, gen_loss = 0.4053099971068533, disc_loss = 0.07885387664039929
Trained batch 57 in epoch 2, gen_loss = 0.40557818679973995, disc_loss = 0.07793767673188243
Trained batch 58 in epoch 2, gen_loss = 0.4062255363343126, disc_loss = 0.07683721238399967
Trained batch 59 in epoch 2, gen_loss = 0.40626275887091956, disc_loss = 0.07651190984373292
Trained batch 60 in epoch 2, gen_loss = 0.4053159409859141, disc_loss = 0.07860073010574599
Trained batch 61 in epoch 2, gen_loss = 0.4063804332287081, disc_loss = 0.08030120502676695
Trained batch 62 in epoch 2, gen_loss = 0.4057753729441809, disc_loss = 0.08025244401679152
Trained batch 63 in epoch 2, gen_loss = 0.4059271439909935, disc_loss = 0.07952895321068354
Trained batch 64 in epoch 2, gen_loss = 0.40455927436168376, disc_loss = 0.07916334360264815
Trained batch 65 in epoch 2, gen_loss = 0.4048035627964771, disc_loss = 0.07841947454620492
Trained batch 66 in epoch 2, gen_loss = 0.4056687079258819, disc_loss = 0.07841126870975565
Trained batch 67 in epoch 2, gen_loss = 0.40439676361925464, disc_loss = 0.07885762441026814
Trained batch 68 in epoch 2, gen_loss = 0.40437956607860065, disc_loss = 0.07874132698212845
Trained batch 69 in epoch 2, gen_loss = 0.40394726863929203, disc_loss = 0.07868247218430043
Trained batch 70 in epoch 2, gen_loss = 0.4037781324185116, disc_loss = 0.07840489863719739
Trained batch 71 in epoch 2, gen_loss = 0.40394967007968163, disc_loss = 0.07769262563023302
Trained batch 72 in epoch 2, gen_loss = 0.4028291836993335, disc_loss = 0.07711234561180415
Trained batch 73 in epoch 2, gen_loss = 0.40333997679723277, disc_loss = 0.07623603403870319
Trained batch 74 in epoch 2, gen_loss = 0.4040674710273743, disc_loss = 0.07583121227721373
Trained batch 75 in epoch 2, gen_loss = 0.40407059773018483, disc_loss = 0.07512185085368783
Trained batch 76 in epoch 2, gen_loss = 0.40469508472975196, disc_loss = 0.07548071763345174
Trained batch 77 in epoch 2, gen_loss = 0.4056367996411446, disc_loss = 0.07634576266774765
Trained batch 78 in epoch 2, gen_loss = 0.40508825567704215, disc_loss = 0.07556185591965914
Trained batch 79 in epoch 2, gen_loss = 0.4058392684906721, disc_loss = 0.07477473731851206
Trained batch 80 in epoch 2, gen_loss = 0.40520237993311, disc_loss = 0.07421957858964617
Trained batch 81 in epoch 2, gen_loss = 0.4057045015620022, disc_loss = 0.07424619749597297
Trained batch 82 in epoch 2, gen_loss = 0.40586017880095054, disc_loss = 0.07375874456736338
Trained batch 83 in epoch 2, gen_loss = 0.40613668270054315, disc_loss = 0.07319077393705291
Trained batch 84 in epoch 2, gen_loss = 0.4061168225372539, disc_loss = 0.07241517780896495
Trained batch 85 in epoch 2, gen_loss = 0.4056097494308339, disc_loss = 0.07169850342798718
Trained batch 86 in epoch 2, gen_loss = 0.40492361441425895, disc_loss = 0.07100860880495145
Trained batch 87 in epoch 2, gen_loss = 0.40455456518314103, disc_loss = 0.07046814810018986
Trained batch 88 in epoch 2, gen_loss = 0.40441234192151704, disc_loss = 0.07010902377536123
Trained batch 89 in epoch 2, gen_loss = 0.40498514076073966, disc_loss = 0.06951900206299291
Trained batch 90 in epoch 2, gen_loss = 0.4046071911906148, disc_loss = 0.06907932307816796
Trained batch 91 in epoch 2, gen_loss = 0.40451290879560553, disc_loss = 0.06903820066793781
Trained batch 92 in epoch 2, gen_loss = 0.4047207069653337, disc_loss = 0.06864779485609904
Trained batch 93 in epoch 2, gen_loss = 0.4040428694892437, disc_loss = 0.06816025299238081
Trained batch 94 in epoch 2, gen_loss = 0.40412499998745166, disc_loss = 0.06759009946529802
Trained batch 95 in epoch 2, gen_loss = 0.4039212604984641, disc_loss = 0.06728994657169096
Trained batch 96 in epoch 2, gen_loss = 0.4048506847976409, disc_loss = 0.06787971657768045
Trained batch 97 in epoch 2, gen_loss = 0.40414102071402025, disc_loss = 0.06804637790524534
Trained batch 98 in epoch 2, gen_loss = 0.4045938726025398, disc_loss = 0.06767334769282377
Trained batch 99 in epoch 2, gen_loss = 0.4050258007645607, disc_loss = 0.0670969966892153
Trained batch 100 in epoch 2, gen_loss = 0.4055846885289296, disc_loss = 0.06658871550260499
Trained batch 101 in epoch 2, gen_loss = 0.4057947248220444, disc_loss = 0.06618154004179672
Trained batch 102 in epoch 2, gen_loss = 0.4054036516587711, disc_loss = 0.06565252429290304
Trained batch 103 in epoch 2, gen_loss = 0.4055408038772069, disc_loss = 0.0652271954414363
Trained batch 104 in epoch 2, gen_loss = 0.40566420469965253, disc_loss = 0.06499633494587172
Trained batch 105 in epoch 2, gen_loss = 0.40522868650139504, disc_loss = 0.0645424093664536
Trained batch 106 in epoch 2, gen_loss = 0.4050237386026115, disc_loss = 0.0640025564304022
Trained batch 107 in epoch 2, gen_loss = 0.4053398232769083, disc_loss = 0.06352435916455255
Trained batch 108 in epoch 2, gen_loss = 0.4051925395060023, disc_loss = 0.06305163598901362
Trained batch 109 in epoch 2, gen_loss = 0.40529094338417054, disc_loss = 0.06266928155144508
Trained batch 110 in epoch 2, gen_loss = 0.40541079183956524, disc_loss = 0.06241371371019799
Trained batch 111 in epoch 2, gen_loss = 0.4065608164029462, disc_loss = 0.061997109616640955
Trained batch 112 in epoch 2, gen_loss = 0.40651062895766404, disc_loss = 0.061597738505662546
Trained batch 113 in epoch 2, gen_loss = 0.4065624595734111, disc_loss = 0.06133309496043805
Trained batch 114 in epoch 2, gen_loss = 0.4063971988532854, disc_loss = 0.0615490493486109
Trained batch 115 in epoch 2, gen_loss = 0.40705669208847245, disc_loss = 0.06266381295301535
Trained batch 116 in epoch 2, gen_loss = 0.40653392035736996, disc_loss = 0.06451708243156855
Trained batch 117 in epoch 2, gen_loss = 0.40672478837482, disc_loss = 0.06673005033063434
Trained batch 118 in epoch 2, gen_loss = 0.4062393432905694, disc_loss = 0.0668801289568303
Trained batch 119 in epoch 2, gen_loss = 0.40591583053270974, disc_loss = 0.06806250052371372
Trained batch 120 in epoch 2, gen_loss = 0.40564683867880136, disc_loss = 0.06829532191988603
Trained batch 121 in epoch 2, gen_loss = 0.4060946189966358, disc_loss = 0.06858366549961635
Trained batch 122 in epoch 2, gen_loss = 0.4063270111394122, disc_loss = 0.06922389402591843
Trained batch 123 in epoch 2, gen_loss = 0.4060637357254182, disc_loss = 0.06974739718791698
Trained batch 124 in epoch 2, gen_loss = 0.4061236729621887, disc_loss = 0.0701777768060565
Trained batch 125 in epoch 2, gen_loss = 0.40538110666804844, disc_loss = 0.07017039577846253
Trained batch 126 in epoch 2, gen_loss = 0.40526532704435936, disc_loss = 0.07017423141395718
Trained batch 127 in epoch 2, gen_loss = 0.4050238679628819, disc_loss = 0.07072192627674667
Trained batch 128 in epoch 2, gen_loss = 0.4054580836795097, disc_loss = 0.07178170169710882
Trained batch 129 in epoch 2, gen_loss = 0.40520798701506394, disc_loss = 0.07252850325491567
Trained batch 130 in epoch 2, gen_loss = 0.4054459711067549, disc_loss = 0.07274590352308431
Trained batch 131 in epoch 2, gen_loss = 0.404984938827428, disc_loss = 0.07322899635288525
Trained batch 132 in epoch 2, gen_loss = 0.40514374339490905, disc_loss = 0.07337841390863173
Trained batch 133 in epoch 2, gen_loss = 0.40493095988657934, disc_loss = 0.07374788275155336
Trained batch 134 in epoch 2, gen_loss = 0.40518443981806435, disc_loss = 0.07467281917041099
Trained batch 135 in epoch 2, gen_loss = 0.40443986720022035, disc_loss = 0.07585720180342083
Trained batch 136 in epoch 2, gen_loss = 0.4043304189278262, disc_loss = 0.07589760819028546
Trained batch 137 in epoch 2, gen_loss = 0.4046080021754555, disc_loss = 0.07771927403772007
Trained batch 138 in epoch 2, gen_loss = 0.40400036161752056, disc_loss = 0.0789120916022564
Trained batch 139 in epoch 2, gen_loss = 0.40368316237415586, disc_loss = 0.0793661115890635
Trained batch 140 in epoch 2, gen_loss = 0.40295111181888177, disc_loss = 0.0792635771122279
Trained batch 141 in epoch 2, gen_loss = 0.40273822403289905, disc_loss = 0.07927614575724157
Trained batch 142 in epoch 2, gen_loss = 0.4023897264387224, disc_loss = 0.07899845620109276
Trained batch 143 in epoch 2, gen_loss = 0.40267470313443077, disc_loss = 0.0785857836340761
Trained batch 144 in epoch 2, gen_loss = 0.4022519666573097, disc_loss = 0.07852734963827092
Trained batch 145 in epoch 2, gen_loss = 0.4020270137754205, disc_loss = 0.07894366866692085
Trained batch 146 in epoch 2, gen_loss = 0.40203048278685327, disc_loss = 0.079103974910567
Trained batch 147 in epoch 2, gen_loss = 0.4024864773492555, disc_loss = 0.07884518038859037
Trained batch 148 in epoch 2, gen_loss = 0.4018014401397449, disc_loss = 0.07932679587037571
Trained batch 149 in epoch 2, gen_loss = 0.4018069165945053, disc_loss = 0.08003348481530945
Trained batch 150 in epoch 2, gen_loss = 0.4016539949849741, disc_loss = 0.08005589539715588
Trained batch 151 in epoch 2, gen_loss = 0.40105201950983, disc_loss = 0.08003231350602091
Trained batch 152 in epoch 2, gen_loss = 0.4017523166790507, disc_loss = 0.07966837506692588
Trained batch 153 in epoch 2, gen_loss = 0.40146747695935237, disc_loss = 0.0793376340434052
Trained batch 154 in epoch 2, gen_loss = 0.40158202455889797, disc_loss = 0.07929851666934067
Trained batch 155 in epoch 2, gen_loss = 0.40077981429222304, disc_loss = 0.07963421438725139
Trained batch 156 in epoch 2, gen_loss = 0.40113236987666717, disc_loss = 0.07923837537005259
Trained batch 157 in epoch 2, gen_loss = 0.40106892510305475, disc_loss = 0.0798942380631932
Trained batch 158 in epoch 2, gen_loss = 0.40084957101809904, disc_loss = 0.08021667233592122
Trained batch 159 in epoch 2, gen_loss = 0.4007919803261757, disc_loss = 0.0798559075628873
Trained batch 160 in epoch 2, gen_loss = 0.4009116338276715, disc_loss = 0.07955124494706436
Trained batch 161 in epoch 2, gen_loss = 0.40086747190834565, disc_loss = 0.07913185526720351
Trained batch 162 in epoch 2, gen_loss = 0.4006052940535399, disc_loss = 0.0788498462743463
Trained batch 163 in epoch 2, gen_loss = 0.400680195812772, disc_loss = 0.07876310546927881
Trained batch 164 in epoch 2, gen_loss = 0.40058965213371045, disc_loss = 0.07938673400856329
Trained batch 165 in epoch 2, gen_loss = 0.4008476651576628, disc_loss = 0.08041007030777723
Trained batch 166 in epoch 2, gen_loss = 0.40055834693823034, disc_loss = 0.08012367447581656
Trained batch 167 in epoch 2, gen_loss = 0.39997063807788347, disc_loss = 0.08054678232431234
Trained batch 168 in epoch 2, gen_loss = 0.4006070210736179, disc_loss = 0.08065594685919715
Trained batch 169 in epoch 2, gen_loss = 0.4005973712486379, disc_loss = 0.08068710291100775
Trained batch 170 in epoch 2, gen_loss = 0.400332521451147, disc_loss = 0.08163661624669855
Trained batch 171 in epoch 2, gen_loss = 0.4004275081462638, disc_loss = 0.08169604016489587
Trained batch 172 in epoch 2, gen_loss = 0.4009496836648511, disc_loss = 0.08189405851346047
Trained batch 173 in epoch 2, gen_loss = 0.4004603771642707, disc_loss = 0.08176490186510244
Trained batch 174 in epoch 2, gen_loss = 0.39990840809685846, disc_loss = 0.08166322756558657
Trained batch 175 in epoch 2, gen_loss = 0.39962854693559086, disc_loss = 0.08176264854211529
Trained batch 176 in epoch 2, gen_loss = 0.39983054423062814, disc_loss = 0.08180927183731633
Trained batch 177 in epoch 2, gen_loss = 0.3997953169131547, disc_loss = 0.08143842650912284
Trained batch 178 in epoch 2, gen_loss = 0.39980752874353076, disc_loss = 0.08110449698821293
Trained batch 179 in epoch 2, gen_loss = 0.3996885374188423, disc_loss = 0.08073423764047523
Trained batch 180 in epoch 2, gen_loss = 0.3995440664870963, disc_loss = 0.0803547404572697
Trained batch 181 in epoch 2, gen_loss = 0.39946646660893825, disc_loss = 0.08012478980286927
Trained batch 182 in epoch 2, gen_loss = 0.39967057076308243, disc_loss = 0.08022245603404898
Trained batch 183 in epoch 2, gen_loss = 0.39976877897329954, disc_loss = 0.07989058816177852
Trained batch 184 in epoch 2, gen_loss = 0.39950054593988366, disc_loss = 0.0795093490515609
Trained batch 185 in epoch 2, gen_loss = 0.39936157083639534, disc_loss = 0.07921936334441265
Trained batch 186 in epoch 2, gen_loss = 0.39975930088981587, disc_loss = 0.07887503658645453
Trained batch 187 in epoch 2, gen_loss = 0.4002944589295286, disc_loss = 0.0786169636845985
Trained batch 188 in epoch 2, gen_loss = 0.4004343303423079, disc_loss = 0.07839212547396383
Trained batch 189 in epoch 2, gen_loss = 0.40087288351435413, disc_loss = 0.07802567024176058
Trained batch 190 in epoch 2, gen_loss = 0.4008437956814991, disc_loss = 0.07838982059888502
Trained batch 191 in epoch 2, gen_loss = 0.4005629277477662, disc_loss = 0.0790657108979455
Trained batch 192 in epoch 2, gen_loss = 0.40096778140784545, disc_loss = 0.07875780590419015
Trained batch 193 in epoch 2, gen_loss = 0.40113722110531996, disc_loss = 0.07848224745698504
Trained batch 194 in epoch 2, gen_loss = 0.40074536815667766, disc_loss = 0.0781817636715296
Trained batch 195 in epoch 2, gen_loss = 0.4006948870967846, disc_loss = 0.0781279566165592
Trained batch 196 in epoch 2, gen_loss = 0.4007877542585286, disc_loss = 0.07804934861053367
Trained batch 197 in epoch 2, gen_loss = 0.4007821393133414, disc_loss = 0.07771781169705921
Trained batch 198 in epoch 2, gen_loss = 0.40087839466842573, disc_loss = 0.07758617416099088
Trained batch 199 in epoch 2, gen_loss = 0.4008814957737923, disc_loss = 0.07739117005839943
Trained batch 200 in epoch 2, gen_loss = 0.4009475190544603, disc_loss = 0.07736438273716328
Trained batch 201 in epoch 2, gen_loss = 0.4008693939978533, disc_loss = 0.07809409711251755
Trained batch 202 in epoch 2, gen_loss = 0.40133228486981887, disc_loss = 0.07799408260017193
Trained batch 203 in epoch 2, gen_loss = 0.40140756599458993, disc_loss = 0.07774829134052876
Trained batch 204 in epoch 2, gen_loss = 0.40206036262395906, disc_loss = 0.07751028378743952
Trained batch 205 in epoch 2, gen_loss = 0.4020214741959155, disc_loss = 0.0772321357039138
Trained batch 206 in epoch 2, gen_loss = 0.40210089087486267, disc_loss = 0.07700421642242135
Trained batch 207 in epoch 2, gen_loss = 0.4025876893160435, disc_loss = 0.07672637805808336
Trained batch 208 in epoch 2, gen_loss = 0.40262791157909555, disc_loss = 0.07657024596759862
Trained batch 209 in epoch 2, gen_loss = 0.4028233017240252, disc_loss = 0.0764268728327893
Trained batch 210 in epoch 2, gen_loss = 0.402911478450513, disc_loss = 0.07616431900781195
Trained batch 211 in epoch 2, gen_loss = 0.4031255957934092, disc_loss = 0.07588617110027457
Trained batch 212 in epoch 2, gen_loss = 0.40284376650908743, disc_loss = 0.07579583372098739
Trained batch 213 in epoch 2, gen_loss = 0.4032217527382842, disc_loss = 0.0766238199250999
Trained batch 214 in epoch 2, gen_loss = 0.40300796475521355, disc_loss = 0.07716616865160854
Trained batch 215 in epoch 2, gen_loss = 0.403134079857005, disc_loss = 0.07689374001455251
Trained batch 216 in epoch 2, gen_loss = 0.40356692424567614, disc_loss = 0.07694885504650904
Trained batch 217 in epoch 2, gen_loss = 0.40358953341978404, disc_loss = 0.07672746439353315
Trained batch 218 in epoch 2, gen_loss = 0.4035208864843464, disc_loss = 0.07640714248106496
Trained batch 219 in epoch 2, gen_loss = 0.40342715883796865, disc_loss = 0.07611176016825166
Trained batch 220 in epoch 2, gen_loss = 0.40350086966790766, disc_loss = 0.07583758504681998
Trained batch 221 in epoch 2, gen_loss = 0.40338611508811917, disc_loss = 0.0755781580501043
Trained batch 222 in epoch 2, gen_loss = 0.40346004717018574, disc_loss = 0.075352857749692
Trained batch 223 in epoch 2, gen_loss = 0.4035718520837171, disc_loss = 0.07509550647643794
Trained batch 224 in epoch 2, gen_loss = 0.40360862970352174, disc_loss = 0.0748835973524385
Trained batch 225 in epoch 2, gen_loss = 0.40381779607418367, disc_loss = 0.07473410765714614
Trained batch 226 in epoch 2, gen_loss = 0.4038833251083475, disc_loss = 0.07444296608625661
Trained batch 227 in epoch 2, gen_loss = 0.40358996417438775, disc_loss = 0.07449851879899047
Trained batch 228 in epoch 2, gen_loss = 0.40388278786792503, disc_loss = 0.07504128852216567
Trained batch 229 in epoch 2, gen_loss = 0.40390414375325906, disc_loss = 0.07482742703236316
Trained batch 230 in epoch 2, gen_loss = 0.4037495518659616, disc_loss = 0.07480532076467812
Trained batch 231 in epoch 2, gen_loss = 0.40370458467253323, disc_loss = 0.07466309840774871
Trained batch 232 in epoch 2, gen_loss = 0.4034361267550309, disc_loss = 0.07456923260597328
Trained batch 233 in epoch 2, gen_loss = 0.40311749419595444, disc_loss = 0.0750804190746803
Trained batch 234 in epoch 2, gen_loss = 0.403221609490983, disc_loss = 0.07552096171978306
Trained batch 235 in epoch 2, gen_loss = 0.4030187263832254, disc_loss = 0.07577410460670747
Trained batch 236 in epoch 2, gen_loss = 0.40266560502193144, disc_loss = 0.0757383059765279
Trained batch 237 in epoch 2, gen_loss = 0.40260624284503843, disc_loss = 0.07552742695498492
Trained batch 238 in epoch 2, gen_loss = 0.4029158625642625, disc_loss = 0.0755306548442863
Trained batch 239 in epoch 2, gen_loss = 0.40293449598054093, disc_loss = 0.07603593773286169
Trained batch 240 in epoch 2, gen_loss = 0.40308560115667796, disc_loss = 0.07615291324532997
Trained batch 241 in epoch 2, gen_loss = 0.40334249860491633, disc_loss = 0.07596745517889945
Trained batch 242 in epoch 2, gen_loss = 0.403217984447754, disc_loss = 0.07597613896132129
Trained batch 243 in epoch 2, gen_loss = 0.40300952008024593, disc_loss = 0.07576478520393005
Trained batch 244 in epoch 2, gen_loss = 0.4028499248076458, disc_loss = 0.07577542754232275
Trained batch 245 in epoch 2, gen_loss = 0.40245479430125014, disc_loss = 0.0758761904444697
Trained batch 246 in epoch 2, gen_loss = 0.4023845379169171, disc_loss = 0.07571302737799371
Trained batch 247 in epoch 2, gen_loss = 0.40276118896661267, disc_loss = 0.07550906816933063
Trained batch 248 in epoch 2, gen_loss = 0.4026786276853707, disc_loss = 0.07529460954812756
Trained batch 249 in epoch 2, gen_loss = 0.4029300924539566, disc_loss = 0.07504776500537992
Trained batch 250 in epoch 2, gen_loss = 0.40315722694909906, disc_loss = 0.07478693020400179
Trained batch 251 in epoch 2, gen_loss = 0.4032618688449027, disc_loss = 0.07452157893336363
Trained batch 252 in epoch 2, gen_loss = 0.40373688029206317, disc_loss = 0.07426909813767836
Trained batch 253 in epoch 2, gen_loss = 0.40418156852403025, disc_loss = 0.07402074185207369
Trained batch 254 in epoch 2, gen_loss = 0.4043699639685014, disc_loss = 0.07378354810689594
Trained batch 255 in epoch 2, gen_loss = 0.40444197750184685, disc_loss = 0.07352886697117356
Trained batch 256 in epoch 2, gen_loss = 0.4045936504690564, disc_loss = 0.0732865086811004
Trained batch 257 in epoch 2, gen_loss = 0.4045724333949791, disc_loss = 0.0730268810695225
Trained batch 258 in epoch 2, gen_loss = 0.40467564963005687, disc_loss = 0.0727721698344847
Trained batch 259 in epoch 2, gen_loss = 0.4046402870462491, disc_loss = 0.07250969522955039
Trained batch 260 in epoch 2, gen_loss = 0.404803823922329, disc_loss = 0.07229361956282537
Trained batch 261 in epoch 2, gen_loss = 0.4048907478119581, disc_loss = 0.07204015445113467
Trained batch 262 in epoch 2, gen_loss = 0.4051945642373408, disc_loss = 0.07191335293907006
Trained batch 263 in epoch 2, gen_loss = 0.4052876249858827, disc_loss = 0.07166813529329374
Trained batch 264 in epoch 2, gen_loss = 0.4054345614505264, disc_loss = 0.0714457568642244
Trained batch 265 in epoch 2, gen_loss = 0.40535893991477506, disc_loss = 0.07122300112711027
Trained batch 266 in epoch 2, gen_loss = 0.4051468435967906, disc_loss = 0.07099298489443985
Trained batch 267 in epoch 2, gen_loss = 0.40517597100627956, disc_loss = 0.07075027319943226
Trained batch 268 in epoch 2, gen_loss = 0.4051782188583927, disc_loss = 0.07058471584429472
Trained batch 269 in epoch 2, gen_loss = 0.4047565675444073, disc_loss = 0.07090422587503714
Trained batch 270 in epoch 2, gen_loss = 0.404984216078621, disc_loss = 0.07181909954436536
Trained batch 271 in epoch 2, gen_loss = 0.40503808636875716, disc_loss = 0.07164771069930044
Trained batch 272 in epoch 2, gen_loss = 0.4050904123774378, disc_loss = 0.07154261416179084
Trained batch 273 in epoch 2, gen_loss = 0.4051395986419525, disc_loss = 0.07134819923845684
Trained batch 274 in epoch 2, gen_loss = 0.40511072278022764, disc_loss = 0.07110736430537971
Trained batch 275 in epoch 2, gen_loss = 0.4050210423875546, disc_loss = 0.07094377039196105
Trained batch 276 in epoch 2, gen_loss = 0.40474326300707103, disc_loss = 0.07095172485027341
Trained batch 277 in epoch 2, gen_loss = 0.40473606131917284, disc_loss = 0.07074818119788609
Trained batch 278 in epoch 2, gen_loss = 0.4048987775506939, disc_loss = 0.07066239707846207
Trained batch 279 in epoch 2, gen_loss = 0.404591594849314, disc_loss = 0.07051070864877797
Trained batch 280 in epoch 2, gen_loss = 0.40475868521211833, disc_loss = 0.07060819882998952
Trained batch 281 in epoch 2, gen_loss = 0.4049795481330114, disc_loss = 0.07088895345681366
Trained batch 282 in epoch 2, gen_loss = 0.4047589969719257, disc_loss = 0.0707589407260579
Trained batch 283 in epoch 2, gen_loss = 0.40485566592132544, disc_loss = 0.07057703832249669
Trained batch 284 in epoch 2, gen_loss = 0.40472658684379176, disc_loss = 0.07047066356692659
Trained batch 285 in epoch 2, gen_loss = 0.40455302002129856, disc_loss = 0.07110905858453598
Trained batch 286 in epoch 2, gen_loss = 0.4046553618401185, disc_loss = 0.07130918677941692
Trained batch 287 in epoch 2, gen_loss = 0.4046329237106774, disc_loss = 0.07116996559812429
Trained batch 288 in epoch 2, gen_loss = 0.40488803840426013, disc_loss = 0.07109429110582777
Trained batch 289 in epoch 2, gen_loss = 0.40491014307942885, disc_loss = 0.07099010923331411
Trained batch 290 in epoch 2, gen_loss = 0.4046007115201852, disc_loss = 0.07097650451995305
Trained batch 291 in epoch 2, gen_loss = 0.4050793344639752, disc_loss = 0.07113102412214885
Trained batch 292 in epoch 2, gen_loss = 0.4051072716509523, disc_loss = 0.0709677155657255
Trained batch 293 in epoch 2, gen_loss = 0.4053133677463142, disc_loss = 0.07099098125694409
Trained batch 294 in epoch 2, gen_loss = 0.4054264868720103, disc_loss = 0.07085470290286308
Trained batch 295 in epoch 2, gen_loss = 0.4055186012709463, disc_loss = 0.07070244487054092
Trained batch 296 in epoch 2, gen_loss = 0.4054428042988183, disc_loss = 0.07052031501356248
Trained batch 297 in epoch 2, gen_loss = 0.4052876646086674, disc_loss = 0.07040295148137082
Trained batch 298 in epoch 2, gen_loss = 0.40544955287888695, disc_loss = 0.0704812986175078
Trained batch 299 in epoch 2, gen_loss = 0.4054172513882319, disc_loss = 0.07052794501961519
Trained batch 300 in epoch 2, gen_loss = 0.40566022045588573, disc_loss = 0.0703534093388415
Trained batch 301 in epoch 2, gen_loss = 0.4058634586484227, disc_loss = 0.07016769524151768
Trained batch 302 in epoch 2, gen_loss = 0.40584771743308595, disc_loss = 0.06995933676421298
Trained batch 303 in epoch 2, gen_loss = 0.40570657876761335, disc_loss = 0.06980504419219583
Trained batch 304 in epoch 2, gen_loss = 0.40595495495639866, disc_loss = 0.0696319824985427
Trained batch 305 in epoch 2, gen_loss = 0.406117340902877, disc_loss = 0.0694697352591902
Trained batch 306 in epoch 2, gen_loss = 0.4062459000935384, disc_loss = 0.0694176684412802
Trained batch 307 in epoch 2, gen_loss = 0.4063592589907832, disc_loss = 0.06924212796389814
Trained batch 308 in epoch 2, gen_loss = 0.40639119588055655, disc_loss = 0.06904237818509389
Trained batch 309 in epoch 2, gen_loss = 0.40643357105793493, disc_loss = 0.06887262042221283
Trained batch 310 in epoch 2, gen_loss = 0.40643138517520816, disc_loss = 0.06873023288827569
Trained batch 311 in epoch 2, gen_loss = 0.40641129800142384, disc_loss = 0.06856962266372135
Trained batch 312 in epoch 2, gen_loss = 0.40669398528699297, disc_loss = 0.06838281031477804
Trained batch 313 in epoch 2, gen_loss = 0.4066922465327439, disc_loss = 0.06819338512393368
Trained batch 314 in epoch 2, gen_loss = 0.40679494653429304, disc_loss = 0.06806502218195606
Trained batch 315 in epoch 2, gen_loss = 0.406862862974028, disc_loss = 0.06788146645685399
Trained batch 316 in epoch 2, gen_loss = 0.4069626666958024, disc_loss = 0.06784427910014892
Trained batch 317 in epoch 2, gen_loss = 0.4069551818963117, disc_loss = 0.06778196645051288
Trained batch 318 in epoch 2, gen_loss = 0.407105175865855, disc_loss = 0.06765903153115166
Trained batch 319 in epoch 2, gen_loss = 0.4074083646759391, disc_loss = 0.06749326338613174
Trained batch 320 in epoch 2, gen_loss = 0.40731311847116347, disc_loss = 0.06732220869551984
Trained batch 321 in epoch 2, gen_loss = 0.40746025389395885, disc_loss = 0.06721493684663582
Trained batch 322 in epoch 2, gen_loss = 0.40730305943326683, disc_loss = 0.06712721153984175
Trained batch 323 in epoch 2, gen_loss = 0.4072956446512246, disc_loss = 0.06698306502895085
Trained batch 324 in epoch 2, gen_loss = 0.4078033186839177, disc_loss = 0.06682190051015753
Trained batch 325 in epoch 2, gen_loss = 0.40775793991937226, disc_loss = 0.06672277432535004
Trained batch 326 in epoch 2, gen_loss = 0.40782926644024864, disc_loss = 0.06662720535947324
Trained batch 327 in epoch 2, gen_loss = 0.4078584914890731, disc_loss = 0.06644296731726017
Trained batch 328 in epoch 2, gen_loss = 0.4076175190576304, disc_loss = 0.06636952534516125
Trained batch 329 in epoch 2, gen_loss = 0.4079947263002396, disc_loss = 0.06629291824065149
Trained batch 330 in epoch 2, gen_loss = 0.40805808051835374, disc_loss = 0.06612175787880657
Trained batch 331 in epoch 2, gen_loss = 0.40801477207835896, disc_loss = 0.06599940481197358
Trained batch 332 in epoch 2, gen_loss = 0.4079124467508929, disc_loss = 0.0660944660278121
Trained batch 333 in epoch 2, gen_loss = 0.4079044382729216, disc_loss = 0.06630457081541999
Trained batch 334 in epoch 2, gen_loss = 0.4080832307018451, disc_loss = 0.06637304376727388
Trained batch 335 in epoch 2, gen_loss = 0.4079729596241599, disc_loss = 0.06621716135885522
Trained batch 336 in epoch 2, gen_loss = 0.4077312933938793, disc_loss = 0.06612051787816585
Trained batch 337 in epoch 2, gen_loss = 0.40777477657301187, disc_loss = 0.06598646956297552
Trained batch 338 in epoch 2, gen_loss = 0.40752465992198933, disc_loss = 0.0658779243284776
Trained batch 339 in epoch 2, gen_loss = 0.40730721056461333, disc_loss = 0.0657444020938676
Trained batch 340 in epoch 2, gen_loss = 0.407295125146066, disc_loss = 0.06557251023035769
Trained batch 341 in epoch 2, gen_loss = 0.40752877939862814, disc_loss = 0.06546020017642724
Trained batch 342 in epoch 2, gen_loss = 0.40752212264447446, disc_loss = 0.0654308541566568
Trained batch 343 in epoch 2, gen_loss = 0.40751679345618846, disc_loss = 0.0652757968434111
Trained batch 344 in epoch 2, gen_loss = 0.4075995598150336, disc_loss = 0.06522252756454375
Trained batch 345 in epoch 2, gen_loss = 0.407604838382302, disc_loss = 0.06524751891215154
Trained batch 346 in epoch 2, gen_loss = 0.40779987278177005, disc_loss = 0.06511792965952619
Trained batch 347 in epoch 2, gen_loss = 0.40775500768902656, disc_loss = 0.06498185689454021
Trained batch 348 in epoch 2, gen_loss = 0.4077246394915704, disc_loss = 0.06481302908773835
Trained batch 349 in epoch 2, gen_loss = 0.40762271438326153, disc_loss = 0.06465145494522793
Trained batch 350 in epoch 2, gen_loss = 0.40786554636778655, disc_loss = 0.06450607347172126
Trained batch 351 in epoch 2, gen_loss = 0.4079717493362047, disc_loss = 0.06434901741026393
Trained batch 352 in epoch 2, gen_loss = 0.4081184967887976, disc_loss = 0.06420833156536473
Trained batch 353 in epoch 2, gen_loss = 0.40807639727484707, disc_loss = 0.06415408678447544
Trained batch 354 in epoch 2, gen_loss = 0.40840893194709027, disc_loss = 0.06424544524191551
Trained batch 355 in epoch 2, gen_loss = 0.40850783532924867, disc_loss = 0.06410020149543127
Trained batch 356 in epoch 2, gen_loss = 0.4083938356541118, disc_loss = 0.06416058959048085
Trained batch 357 in epoch 2, gen_loss = 0.4084710202403575, disc_loss = 0.06400947069603555
Trained batch 358 in epoch 2, gen_loss = 0.40855143362433133, disc_loss = 0.06385307470310614
Trained batch 359 in epoch 2, gen_loss = 0.408679494758447, disc_loss = 0.06369041610612637
Trained batch 360 in epoch 2, gen_loss = 0.4085287850484293, disc_loss = 0.06360258047992667
Trained batch 361 in epoch 2, gen_loss = 0.4084838166091982, disc_loss = 0.06345581851683516
Trained batch 362 in epoch 2, gen_loss = 0.4084324204560482, disc_loss = 0.06331879485747456
Trained batch 363 in epoch 2, gen_loss = 0.40832025320320336, disc_loss = 0.06315653477181363
Trained batch 364 in epoch 2, gen_loss = 0.4082876452027935, disc_loss = 0.06301685994465465
Trained batch 365 in epoch 2, gen_loss = 0.4079824113617829, disc_loss = 0.06306162085943942
Trained batch 366 in epoch 2, gen_loss = 0.40808132794312624, disc_loss = 0.06323149504155245
Trained batch 367 in epoch 2, gen_loss = 0.4079719010092642, disc_loss = 0.06308427187563527
Trained batch 368 in epoch 2, gen_loss = 0.4079556371461408, disc_loss = 0.06302388421030145
Trained batch 369 in epoch 2, gen_loss = 0.40794566724751447, disc_loss = 0.06286746404712668
Trained batch 370 in epoch 2, gen_loss = 0.4079602355102323, disc_loss = 0.0627399096089714
Trained batch 371 in epoch 2, gen_loss = 0.4080122009881081, disc_loss = 0.06260937011189839
Trained batch 372 in epoch 2, gen_loss = 0.4078616698849297, disc_loss = 0.06267343437044455
Trained batch 373 in epoch 2, gen_loss = 0.4081352154679477, disc_loss = 0.06269187352216658
Trained batch 374 in epoch 2, gen_loss = 0.408107740799586, disc_loss = 0.06265687995652358
Trained batch 375 in epoch 2, gen_loss = 0.40797370030207836, disc_loss = 0.06282964267054612
Trained batch 376 in epoch 2, gen_loss = 0.40796388681750717, disc_loss = 0.06290687651766232
Trained batch 377 in epoch 2, gen_loss = 0.4078692811191397, disc_loss = 0.06279986951421335
Trained batch 378 in epoch 2, gen_loss = 0.4078289442609671, disc_loss = 0.06273048019680467
Trained batch 379 in epoch 2, gen_loss = 0.40783956944942473, disc_loss = 0.06259503823116813
Trained batch 380 in epoch 2, gen_loss = 0.4078757453152514, disc_loss = 0.06250022142255322
Trained batch 381 in epoch 2, gen_loss = 0.40805674215573917, disc_loss = 0.06253561201744288
Trained batch 382 in epoch 2, gen_loss = 0.40777808746843364, disc_loss = 0.0626091469959514
Trained batch 383 in epoch 2, gen_loss = 0.407895187381655, disc_loss = 0.06249505713882778
Trained batch 384 in epoch 2, gen_loss = 0.40782324989120683, disc_loss = 0.062372878046295085
Trained batch 385 in epoch 2, gen_loss = 0.4079451030554549, disc_loss = 0.06223026719523372
Trained batch 386 in epoch 2, gen_loss = 0.4079500565387174, disc_loss = 0.06208635319881045
Trained batch 387 in epoch 2, gen_loss = 0.4080019420416085, disc_loss = 0.061942548824704645
Trained batch 388 in epoch 2, gen_loss = 0.40807439880996255, disc_loss = 0.06179399278187277
Trained batch 389 in epoch 2, gen_loss = 0.4079414086464124, disc_loss = 0.061722177049765986
Trained batch 390 in epoch 2, gen_loss = 0.4077975413073664, disc_loss = 0.06159456613261605
Trained batch 391 in epoch 2, gen_loss = 0.40784615871249413, disc_loss = 0.0614943310062458
Trained batch 392 in epoch 2, gen_loss = 0.4079534367447288, disc_loss = 0.061368690173286215
Trained batch 393 in epoch 2, gen_loss = 0.4078889421097518, disc_loss = 0.06124232457194307
Trained batch 394 in epoch 2, gen_loss = 0.40757969089701207, disc_loss = 0.06121387744110219
Trained batch 395 in epoch 2, gen_loss = 0.4076894154452314, disc_loss = 0.0611532922820047
Trained batch 396 in epoch 2, gen_loss = 0.40790705116329623, disc_loss = 0.06103772976170634
Trained batch 397 in epoch 2, gen_loss = 0.40802650954855146, disc_loss = 0.060916212055102066
Trained batch 398 in epoch 2, gen_loss = 0.40798183693025347, disc_loss = 0.060853409830639534
Trained batch 399 in epoch 2, gen_loss = 0.4079401055723429, disc_loss = 0.06073137319646776
Trained batch 400 in epoch 2, gen_loss = 0.40806254328337693, disc_loss = 0.06063349723369998
Trained batch 401 in epoch 2, gen_loss = 0.40820797321511737, disc_loss = 0.060503409459575344
Trained batch 402 in epoch 2, gen_loss = 0.4081287574087716, disc_loss = 0.060375324686152615
Trained batch 403 in epoch 2, gen_loss = 0.4081628605870917, disc_loss = 0.060236718125254066
Trained batch 404 in epoch 2, gen_loss = 0.40812381344077026, disc_loss = 0.06014007562886418
Trained batch 405 in epoch 2, gen_loss = 0.4080491292065588, disc_loss = 0.06007807539647509
Trained batch 406 in epoch 2, gen_loss = 0.4080468739133502, disc_loss = 0.05997001467826399
Trained batch 407 in epoch 2, gen_loss = 0.40810243558942105, disc_loss = 0.059835218388459406
Trained batch 408 in epoch 2, gen_loss = 0.40807727022975465, disc_loss = 0.059705847279967916
Trained batch 409 in epoch 2, gen_loss = 0.40816512231419727, disc_loss = 0.05958195170160474
Trained batch 410 in epoch 2, gen_loss = 0.40819805309430235, disc_loss = 0.05944815774078859
Trained batch 411 in epoch 2, gen_loss = 0.40837313176937473, disc_loss = 0.059327489782341765
Trained batch 412 in epoch 2, gen_loss = 0.40855027688328927, disc_loss = 0.05922502950826078
Trained batch 413 in epoch 2, gen_loss = 0.4084839859734411, disc_loss = 0.05923903543178154
Trained batch 414 in epoch 2, gen_loss = 0.40864054237503605, disc_loss = 0.05927789445113705
Trained batch 415 in epoch 2, gen_loss = 0.40884875850035596, disc_loss = 0.05915727840888744
Trained batch 416 in epoch 2, gen_loss = 0.40888685959992077, disc_loss = 0.059027008149478075
Trained batch 417 in epoch 2, gen_loss = 0.4088882361872915, disc_loss = 0.05891900487315427
Trained batch 418 in epoch 2, gen_loss = 0.4088841601317139, disc_loss = 0.058795441793353435
Trained batch 419 in epoch 2, gen_loss = 0.40878473669290544, disc_loss = 0.05868099120534247
Trained batch 420 in epoch 2, gen_loss = 0.40897824411720674, disc_loss = 0.05856044374565614
Trained batch 421 in epoch 2, gen_loss = 0.40900447343198043, disc_loss = 0.05843125631970958
Trained batch 422 in epoch 2, gen_loss = 0.4090903230874533, disc_loss = 0.05830771102840807
Trained batch 423 in epoch 2, gen_loss = 0.40916162342676576, disc_loss = 0.05818057223552627
Trained batch 424 in epoch 2, gen_loss = 0.40927915012135224, disc_loss = 0.05805736751569544
Trained batch 425 in epoch 2, gen_loss = 0.409399045185304, disc_loss = 0.05793220155758722
Trained batch 426 in epoch 2, gen_loss = 0.40938479845920267, disc_loss = 0.05781426942368546
Trained batch 427 in epoch 2, gen_loss = 0.4093714223426079, disc_loss = 0.057693019594178996
Trained batch 428 in epoch 2, gen_loss = 0.4091862435941096, disc_loss = 0.057683631654021204
Trained batch 429 in epoch 2, gen_loss = 0.4092035648434661, disc_loss = 0.05851340693919811
Trained batch 430 in epoch 2, gen_loss = 0.40900586396801497, disc_loss = 0.05892915409836235
Trained batch 431 in epoch 2, gen_loss = 0.4089960569722785, disc_loss = 0.059123121355056624
Trained batch 432 in epoch 2, gen_loss = 0.40891550140623134, disc_loss = 0.05910354547899466
Trained batch 433 in epoch 2, gen_loss = 0.40892008482585857, disc_loss = 0.05904452096507777
Trained batch 434 in epoch 2, gen_loss = 0.40882700811857464, disc_loss = 0.05897979150344243
Trained batch 435 in epoch 2, gen_loss = 0.40870908299170505, disc_loss = 0.05899687336732146
Trained batch 436 in epoch 2, gen_loss = 0.40870520022422824, disc_loss = 0.05897623670310873
Trained batch 437 in epoch 2, gen_loss = 0.4086795271667716, disc_loss = 0.05888127747999683
Trained batch 438 in epoch 2, gen_loss = 0.4084557948595842, disc_loss = 0.059000675184630993
Trained batch 439 in epoch 2, gen_loss = 0.408574206111106, disc_loss = 0.05972522564698011
Trained batch 440 in epoch 2, gen_loss = 0.4086149668071816, disc_loss = 0.05996028953728154
Trained batch 441 in epoch 2, gen_loss = 0.4085306817859546, disc_loss = 0.05999033449521094
Trained batch 442 in epoch 2, gen_loss = 0.4085006972198831, disc_loss = 0.059979970234763674
Trained batch 443 in epoch 2, gen_loss = 0.4083572171024374, disc_loss = 0.059863061537160665
Trained batch 444 in epoch 2, gen_loss = 0.40829099764984644, disc_loss = 0.05986943417595009
Trained batch 445 in epoch 2, gen_loss = 0.4083574525176677, disc_loss = 0.05980029772975453
Trained batch 446 in epoch 2, gen_loss = 0.4083872120119048, disc_loss = 0.05969980060095822
Trained batch 447 in epoch 2, gen_loss = 0.4083578528038093, disc_loss = 0.05961866588040721
Trained batch 448 in epoch 2, gen_loss = 0.4084321314879674, disc_loss = 0.05952279270732389
Trained batch 449 in epoch 2, gen_loss = 0.40853875895341235, disc_loss = 0.059436522119988996
Trained batch 450 in epoch 2, gen_loss = 0.4086009328090431, disc_loss = 0.05947499857087952
Trained batch 451 in epoch 2, gen_loss = 0.40858732170499534, disc_loss = 0.059674574682423105
Trained batch 452 in epoch 2, gen_loss = 0.4087364728219199, disc_loss = 0.06006661696651453
Trained batch 453 in epoch 2, gen_loss = 0.40888612077362213, disc_loss = 0.059964607412299135
Trained batch 454 in epoch 2, gen_loss = 0.4088040892894451, disc_loss = 0.05991566929106529
Trained batch 455 in epoch 2, gen_loss = 0.40890101683244373, disc_loss = 0.05981853577970086
Trained batch 456 in epoch 2, gen_loss = 0.4089133077559899, disc_loss = 0.059701455920054304
Trained batch 457 in epoch 2, gen_loss = 0.40885407897322457, disc_loss = 0.05960978268275615
Trained batch 458 in epoch 2, gen_loss = 0.4092263315108347, disc_loss = 0.05953478262899748
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.37713655829429626, disc_loss = 0.04441491514444351
Trained batch 1 in epoch 3, gen_loss = 0.3864686042070389, disc_loss = 0.032457081601023674
Trained batch 2 in epoch 3, gen_loss = 0.4024646580219269, disc_loss = 0.04902787630756696
Trained batch 3 in epoch 3, gen_loss = 0.40039751678705215, disc_loss = 0.03877795650623739
Trained batch 4 in epoch 3, gen_loss = 0.38715568780899046, disc_loss = 0.03891155328601599
Trained batch 5 in epoch 3, gen_loss = 0.3892102887233098, disc_loss = 0.03531530639156699
Trained batch 6 in epoch 3, gen_loss = 0.4081892839499882, disc_loss = 0.041568334746573656
Trained batch 7 in epoch 3, gen_loss = 0.3974147327244282, disc_loss = 0.04629239172209054
Trained batch 8 in epoch 3, gen_loss = 0.4061240586969588, disc_loss = 0.05196103215631512
Trained batch 9 in epoch 3, gen_loss = 0.4099054425954819, disc_loss = 0.05069559188559651
Trained batch 10 in epoch 3, gen_loss = 0.41264389048923145, disc_loss = 0.046616808638315306
Trained batch 11 in epoch 3, gen_loss = 0.41023869315783185, disc_loss = 0.043175402097404
Trained batch 12 in epoch 3, gen_loss = 0.4051969784956712, disc_loss = 0.040466188381497674
Trained batch 13 in epoch 3, gen_loss = 0.4037841239145824, disc_loss = 0.03837936238518783
Trained batch 14 in epoch 3, gen_loss = 0.4030243535836538, disc_loss = 0.03685830806692441
Trained batch 15 in epoch 3, gen_loss = 0.4009270407259464, disc_loss = 0.03497453819727525
Trained batch 16 in epoch 3, gen_loss = 0.4041092500967138, disc_loss = 0.03392861624631811
Trained batch 17 in epoch 3, gen_loss = 0.4035744567712148, disc_loss = 0.032686856006168656
Trained batch 18 in epoch 3, gen_loss = 0.40445118515115036, disc_loss = 0.03280972723702067
Trained batch 19 in epoch 3, gen_loss = 0.4075906202197075, disc_loss = 0.03493546205572784
Trained batch 20 in epoch 3, gen_loss = 0.40681631082580205, disc_loss = 0.05009610556243431
Trained batch 21 in epoch 3, gen_loss = 0.4027042470195077, disc_loss = 0.04911237155002626
Trained batch 22 in epoch 3, gen_loss = 0.40012505391369696, disc_loss = 0.053622878237586956
Trained batch 23 in epoch 3, gen_loss = 0.40033907319108647, disc_loss = 0.06253917278566708
Trained batch 24 in epoch 3, gen_loss = 0.39652676582336427, disc_loss = 0.061900421194732186
Trained batch 25 in epoch 3, gen_loss = 0.39451124576421887, disc_loss = 0.06224821232115993
Trained batch 26 in epoch 3, gen_loss = 0.3933507623495879, disc_loss = 0.061319704788426556
Trained batch 27 in epoch 3, gen_loss = 0.3950824109571321, disc_loss = 0.061633443825745156
Trained batch 28 in epoch 3, gen_loss = 0.3947242806697714, disc_loss = 0.06038568506081556
Trained batch 29 in epoch 3, gen_loss = 0.3928356389204661, disc_loss = 0.06131794803465406
Trained batch 30 in epoch 3, gen_loss = 0.39693354791210544, disc_loss = 0.06320493094502919
Trained batch 31 in epoch 3, gen_loss = 0.39659281075000763, disc_loss = 0.06220997977652587
Trained batch 32 in epoch 3, gen_loss = 0.396167028130907, disc_loss = 0.06057832220738584
Trained batch 33 in epoch 3, gen_loss = 0.39683522546992583, disc_loss = 0.059147278504336584
Trained batch 34 in epoch 3, gen_loss = 0.3957353711128235, disc_loss = 0.05771257797522204
Trained batch 35 in epoch 3, gen_loss = 0.3949746299121115, disc_loss = 0.056228833376533456
Trained batch 36 in epoch 3, gen_loss = 0.3957430768657375, disc_loss = 0.0548591915820096
Trained batch 37 in epoch 3, gen_loss = 0.39645689882730184, disc_loss = 0.05383288193690149
Trained batch 38 in epoch 3, gen_loss = 0.39736888729608977, disc_loss = 0.05371963414244163
Trained batch 39 in epoch 3, gen_loss = 0.4001330278813839, disc_loss = 0.055534154269844295
Trained batch 40 in epoch 3, gen_loss = 0.40119327786492137, disc_loss = 0.05439736734984851
Trained batch 41 in epoch 3, gen_loss = 0.40211260886419387, disc_loss = 0.053839121324320637
Trained batch 42 in epoch 3, gen_loss = 0.4025803845982219, disc_loss = 0.052777238493395405
Trained batch 43 in epoch 3, gen_loss = 0.4025119664994153, disc_loss = 0.05175060024273328
Trained batch 44 in epoch 3, gen_loss = 0.40220475792884824, disc_loss = 0.050707527208659384
Trained batch 45 in epoch 3, gen_loss = 0.4023812030968459, disc_loss = 0.04980014481217317
Trained batch 46 in epoch 3, gen_loss = 0.40271106362342834, disc_loss = 0.04884579415096248
Trained batch 47 in epoch 3, gen_loss = 0.40369938624401885, disc_loss = 0.0479930235305801
Trained batch 48 in epoch 3, gen_loss = 0.4034348738436796, disc_loss = 0.047108999291929056
Trained batch 49 in epoch 3, gen_loss = 0.4040228915214539, disc_loss = 0.046252668630331756
Trained batch 50 in epoch 3, gen_loss = 0.4029312560371324, disc_loss = 0.04547779402677335
Trained batch 51 in epoch 3, gen_loss = 0.4025784031702922, disc_loss = 0.044937726987812385
Trained batch 52 in epoch 3, gen_loss = 0.4028014698118534, disc_loss = 0.04460865872437662
Trained batch 53 in epoch 3, gen_loss = 0.4021854974605419, disc_loss = 0.04400886772890334
Trained batch 54 in epoch 3, gen_loss = 0.4016945307905024, disc_loss = 0.044306904331526974
Trained batch 55 in epoch 3, gen_loss = 0.40365975882325855, disc_loss = 0.04463913303334266
Trained batch 56 in epoch 3, gen_loss = 0.4032105144701506, disc_loss = 0.04468065394055948
Trained batch 57 in epoch 3, gen_loss = 0.4024616623746938, disc_loss = 0.04579647500389095
Trained batch 58 in epoch 3, gen_loss = 0.403154884859667, disc_loss = 0.045356577151786474
Trained batch 59 in epoch 3, gen_loss = 0.40287923961877825, disc_loss = 0.04517316804267466
Trained batch 60 in epoch 3, gen_loss = 0.4029282922627496, disc_loss = 0.04458563983990032
Trained batch 61 in epoch 3, gen_loss = 0.4029364196523543, disc_loss = 0.04441015303675686
Trained batch 62 in epoch 3, gen_loss = 0.40351591696814887, disc_loss = 0.04385416042650976
Trained batch 63 in epoch 3, gen_loss = 0.40338939242064953, disc_loss = 0.04334942843706813
Trained batch 64 in epoch 3, gen_loss = 0.40390226290776177, disc_loss = 0.042806123942136766
Trained batch 65 in epoch 3, gen_loss = 0.40337198972702026, disc_loss = 0.04231368978931145
Trained batch 66 in epoch 3, gen_loss = 0.4037278721581644, disc_loss = 0.04174695668547456
Trained batch 67 in epoch 3, gen_loss = 0.40383248118793263, disc_loss = 0.041190325648879964
Trained batch 68 in epoch 3, gen_loss = 0.4049914833428203, disc_loss = 0.040804557525890246
Trained batch 69 in epoch 3, gen_loss = 0.4045334522213255, disc_loss = 0.04031789879248079
Trained batch 70 in epoch 3, gen_loss = 0.4055909354921798, disc_loss = 0.03992978465402315
Trained batch 71 in epoch 3, gen_loss = 0.40533512292636764, disc_loss = 0.039452784083550796
Trained batch 72 in epoch 3, gen_loss = 0.4050435187065438, disc_loss = 0.03902064295396311
Trained batch 73 in epoch 3, gen_loss = 0.4066685969765122, disc_loss = 0.038914450604745465
Trained batch 74 in epoch 3, gen_loss = 0.4068724083900452, disc_loss = 0.038550045524413386
Trained batch 75 in epoch 3, gen_loss = 0.40615949191545186, disc_loss = 0.038146402904347176
Trained batch 76 in epoch 3, gen_loss = 0.40680891275405884, disc_loss = 0.03772471166312598
Trained batch 77 in epoch 3, gen_loss = 0.40688435160196745, disc_loss = 0.037466696973961704
Trained batch 78 in epoch 3, gen_loss = 0.40732263839697536, disc_loss = 0.03709458562993456
Trained batch 79 in epoch 3, gen_loss = 0.40684964396059514, disc_loss = 0.03675126374873798
Trained batch 80 in epoch 3, gen_loss = 0.4077230982574416, disc_loss = 0.036500056374841085
Trained batch 81 in epoch 3, gen_loss = 0.408079478798843, disc_loss = 0.036117735980419306
Trained batch 82 in epoch 3, gen_loss = 0.4090988348765546, disc_loss = 0.03576522843676608
Trained batch 83 in epoch 3, gen_loss = 0.4093923955446198, disc_loss = 0.03543934725236059
Trained batch 84 in epoch 3, gen_loss = 0.4092732969452353, disc_loss = 0.03510738799951094
Trained batch 85 in epoch 3, gen_loss = 0.4096725687038067, disc_loss = 0.034767879240842924
Trained batch 86 in epoch 3, gen_loss = 0.41038667676092566, disc_loss = 0.03451929919303919
Trained batch 87 in epoch 3, gen_loss = 0.4101389053870331, disc_loss = 0.034223037128950556
Trained batch 88 in epoch 3, gen_loss = 0.41053748264741363, disc_loss = 0.033937824787990595
Trained batch 89 in epoch 3, gen_loss = 0.40970074832439424, disc_loss = 0.03407340447366652
Trained batch 90 in epoch 3, gen_loss = 0.40868105698417834, disc_loss = 0.03475994420503931
Trained batch 91 in epoch 3, gen_loss = 0.4090363995536514, disc_loss = 0.03501556562917793
Trained batch 92 in epoch 3, gen_loss = 0.4091598394737449, disc_loss = 0.03471522248770681
Trained batch 93 in epoch 3, gen_loss = 0.4096048908664825, disc_loss = 0.03461357302458442
Trained batch 94 in epoch 3, gen_loss = 0.4091025832452272, disc_loss = 0.03470813350899047
Trained batch 95 in epoch 3, gen_loss = 0.4101034014796217, disc_loss = 0.03512107287194036
Trained batch 96 in epoch 3, gen_loss = 0.4104914907942113, disc_loss = 0.03492748871032802
Trained batch 97 in epoch 3, gen_loss = 0.4103286044330013, disc_loss = 0.03474095219755735
Trained batch 98 in epoch 3, gen_loss = 0.4107735599532272, disc_loss = 0.03444914383616186
Trained batch 99 in epoch 3, gen_loss = 0.41125097721815107, disc_loss = 0.034185548240784555
Trained batch 100 in epoch 3, gen_loss = 0.4111842215061188, disc_loss = 0.03393608171465152
Trained batch 101 in epoch 3, gen_loss = 0.4105278627545226, disc_loss = 0.034226701925873904
Trained batch 102 in epoch 3, gen_loss = 0.4107586857184623, disc_loss = 0.037150251437249836
Trained batch 103 in epoch 3, gen_loss = 0.41057370373835933, disc_loss = 0.038748193194176286
Trained batch 104 in epoch 3, gen_loss = 0.4101945610273452, disc_loss = 0.03844181928739306
Trained batch 105 in epoch 3, gen_loss = 0.409254271466777, disc_loss = 0.03868036644911077
Trained batch 106 in epoch 3, gen_loss = 0.4086590768577896, disc_loss = 0.03919359677575668
Trained batch 107 in epoch 3, gen_loss = 0.40906029084214457, disc_loss = 0.03977460315649363
Trained batch 108 in epoch 3, gen_loss = 0.408896678358043, disc_loss = 0.03947270593024927
Trained batch 109 in epoch 3, gen_loss = 0.40850420540029353, disc_loss = 0.039231809074143795
Trained batch 110 in epoch 3, gen_loss = 0.4086566000908345, disc_loss = 0.03898035562681118
Trained batch 111 in epoch 3, gen_loss = 0.40821460501423906, disc_loss = 0.039247610629120445
Trained batch 112 in epoch 3, gen_loss = 0.40769632463961575, disc_loss = 0.038983050377347166
Trained batch 113 in epoch 3, gen_loss = 0.40730004404720505, disc_loss = 0.03938949566228282
Trained batch 114 in epoch 3, gen_loss = 0.406604795611423, disc_loss = 0.04095806039505355
Trained batch 115 in epoch 3, gen_loss = 0.4058228615542938, disc_loss = 0.04124234842160588
Trained batch 116 in epoch 3, gen_loss = 0.4056924459261772, disc_loss = 0.041669564948488884
Trained batch 117 in epoch 3, gen_loss = 0.4059767000756021, disc_loss = 0.04232123728360097
Trained batch 118 in epoch 3, gen_loss = 0.4054830585207258, disc_loss = 0.042816314883451875
Trained batch 119 in epoch 3, gen_loss = 0.4059466391801834, disc_loss = 0.04376061546887892
Trained batch 120 in epoch 3, gen_loss = 0.40571053658635164, disc_loss = 0.04348106040957977
Trained batch 121 in epoch 3, gen_loss = 0.4059193571571444, disc_loss = 0.043300393867672836
Trained batch 122 in epoch 3, gen_loss = 0.40619675827220203, disc_loss = 0.04308429180750457
Trained batch 123 in epoch 3, gen_loss = 0.4071345336494907, disc_loss = 0.042784207716449016
Trained batch 124 in epoch 3, gen_loss = 0.407434376001358, disc_loss = 0.042537599427625535
Trained batch 125 in epoch 3, gen_loss = 0.4078001644876268, disc_loss = 0.043067101195144154
Trained batch 126 in epoch 3, gen_loss = 0.4077051148170561, disc_loss = 0.042866531068341825
Trained batch 127 in epoch 3, gen_loss = 0.4081275542266667, disc_loss = 0.04293188049450691
Trained batch 128 in epoch 3, gen_loss = 0.40780801666799443, disc_loss = 0.04270852055191243
Trained batch 129 in epoch 3, gen_loss = 0.40740366921975063, disc_loss = 0.042570135597354515
Trained batch 130 in epoch 3, gen_loss = 0.40725222389206633, disc_loss = 0.042375511679983206
Trained batch 131 in epoch 3, gen_loss = 0.4069086534507347, disc_loss = 0.04230365013019323
Trained batch 132 in epoch 3, gen_loss = 0.40709464375237775, disc_loss = 0.04269231640019531
Trained batch 133 in epoch 3, gen_loss = 0.40661522367996955, disc_loss = 0.04410166779720683
Trained batch 134 in epoch 3, gen_loss = 0.4068864780443686, disc_loss = 0.04513531037330352
Trained batch 135 in epoch 3, gen_loss = 0.40740318399141817, disc_loss = 0.04516682444955222
Trained batch 136 in epoch 3, gen_loss = 0.40793541508869535, disc_loss = 0.044936435948037645
Trained batch 137 in epoch 3, gen_loss = 0.40779799849226855, disc_loss = 0.04469128299092847
Trained batch 138 in epoch 3, gen_loss = 0.4071723417841273, disc_loss = 0.04457313726026323
Trained batch 139 in epoch 3, gen_loss = 0.40697221010923385, disc_loss = 0.044297568804384874
Trained batch 140 in epoch 3, gen_loss = 0.40696261685790747, disc_loss = 0.044073701279687016
Trained batch 141 in epoch 3, gen_loss = 0.4068760336704657, disc_loss = 0.044135454968339434
Trained batch 142 in epoch 3, gen_loss = 0.40697781293542235, disc_loss = 0.04453659170124862
Trained batch 143 in epoch 3, gen_loss = 0.4068019222468138, disc_loss = 0.04465305182222639
Trained batch 144 in epoch 3, gen_loss = 0.4069805400124912, disc_loss = 0.044985566806883134
Trained batch 145 in epoch 3, gen_loss = 0.4070613588372322, disc_loss = 0.04484377995815945
Trained batch 146 in epoch 3, gen_loss = 0.40716310098868647, disc_loss = 0.044707446940382624
Trained batch 147 in epoch 3, gen_loss = 0.4073663287468859, disc_loss = 0.04454849601716961
Trained batch 148 in epoch 3, gen_loss = 0.40760430693626404, disc_loss = 0.044365936694916765
Trained batch 149 in epoch 3, gen_loss = 0.40766786654790244, disc_loss = 0.04418748594044397
Trained batch 150 in epoch 3, gen_loss = 0.4080641859809294, disc_loss = 0.04397027072842103
Trained batch 151 in epoch 3, gen_loss = 0.4084281866487704, disc_loss = 0.045309525637237946
Trained batch 152 in epoch 3, gen_loss = 0.40762417807298545, disc_loss = 0.04820044277071515
Trained batch 153 in epoch 3, gen_loss = 0.4077071597823849, disc_loss = 0.04849631510306053
Trained batch 154 in epoch 3, gen_loss = 0.40786462906868226, disc_loss = 0.048506633328994915
Trained batch 155 in epoch 3, gen_loss = 0.4074235228009713, disc_loss = 0.048320394897391684
Trained batch 156 in epoch 3, gen_loss = 0.407553884064316, disc_loss = 0.048239196020409846
Trained batch 157 in epoch 3, gen_loss = 0.40756074971036066, disc_loss = 0.04810021827557372
Trained batch 158 in epoch 3, gen_loss = 0.4076840375204506, disc_loss = 0.048173304534452795
Trained batch 159 in epoch 3, gen_loss = 0.4075598672032356, disc_loss = 0.04801873446413083
Trained batch 160 in epoch 3, gen_loss = 0.4072859994372966, disc_loss = 0.04795710754476673
Trained batch 161 in epoch 3, gen_loss = 0.4072832667533262, disc_loss = 0.04791701095678878
Trained batch 162 in epoch 3, gen_loss = 0.4072998027128676, disc_loss = 0.04778507674552866
Trained batch 163 in epoch 3, gen_loss = 0.4071505780263645, disc_loss = 0.047519077091171154
Trained batch 164 in epoch 3, gen_loss = 0.4073150685339263, disc_loss = 0.04737553562489197
Trained batch 165 in epoch 3, gen_loss = 0.40735895303358516, disc_loss = 0.04713860716732466
Trained batch 166 in epoch 3, gen_loss = 0.4071731378218371, disc_loss = 0.04707645485874734
Trained batch 167 in epoch 3, gen_loss = 0.40709375182078, disc_loss = 0.047370079188286104
Trained batch 168 in epoch 3, gen_loss = 0.40761010692669797, disc_loss = 0.048019368437080254
Trained batch 169 in epoch 3, gen_loss = 0.40776587181231555, disc_loss = 0.047768473949776416
Trained batch 170 in epoch 3, gen_loss = 0.40789134268872224, disc_loss = 0.047711210811445325
Trained batch 171 in epoch 3, gen_loss = 0.40777677626803865, disc_loss = 0.047460122338528636
Trained batch 172 in epoch 3, gen_loss = 0.4078038119511797, disc_loss = 0.04720528158924483
Trained batch 173 in epoch 3, gen_loss = 0.40767982944674874, disc_loss = 0.04701272562017728
Trained batch 174 in epoch 3, gen_loss = 0.40713597229548865, disc_loss = 0.046860015977706226
Trained batch 175 in epoch 3, gen_loss = 0.40689169632440264, disc_loss = 0.04664186364971101
Trained batch 176 in epoch 3, gen_loss = 0.40713683983026927, disc_loss = 0.04642778638708221
Trained batch 177 in epoch 3, gen_loss = 0.40751691798815565, disc_loss = 0.046390216122643
Trained batch 178 in epoch 3, gen_loss = 0.40707652961741614, disc_loss = 0.046450941209478416
Trained batch 179 in epoch 3, gen_loss = 0.4076558805174298, disc_loss = 0.04685659999959171
Trained batch 180 in epoch 3, gen_loss = 0.40759303326106205, disc_loss = 0.04785524213491059
Trained batch 181 in epoch 3, gen_loss = 0.4079036234499334, disc_loss = 0.04798652877990198
Trained batch 182 in epoch 3, gen_loss = 0.40811428997686, disc_loss = 0.048267595831284434
Trained batch 183 in epoch 3, gen_loss = 0.40805032687342685, disc_loss = 0.0481597713407372
Trained batch 184 in epoch 3, gen_loss = 0.4079850686563028, disc_loss = 0.04795412701126692
Trained batch 185 in epoch 3, gen_loss = 0.4079398179566988, disc_loss = 0.04773893960881778
Trained batch 186 in epoch 3, gen_loss = 0.4080758762550864, disc_loss = 0.047632154580305286
Trained batch 187 in epoch 3, gen_loss = 0.4076131171685584, disc_loss = 0.04756648793440074
Trained batch 188 in epoch 3, gen_loss = 0.4076446389395093, disc_loss = 0.04741866168659673
Trained batch 189 in epoch 3, gen_loss = 0.4077478117064426, disc_loss = 0.04732174574838657
Trained batch 190 in epoch 3, gen_loss = 0.40774174448083206, disc_loss = 0.047675022587219146
Trained batch 191 in epoch 3, gen_loss = 0.4078073943965137, disc_loss = 0.04938819227875987
Trained batch 192 in epoch 3, gen_loss = 0.40763462145711477, disc_loss = 0.0499298637346823
Trained batch 193 in epoch 3, gen_loss = 0.40766255618985164, disc_loss = 0.0508380231889176
Trained batch 194 in epoch 3, gen_loss = 0.4078503918953431, disc_loss = 0.051413281601017866
Trained batch 195 in epoch 3, gen_loss = 0.40768227422115755, disc_loss = 0.051353187770677766
Trained batch 196 in epoch 3, gen_loss = 0.40748001022387276, disc_loss = 0.051713575523932874
Trained batch 197 in epoch 3, gen_loss = 0.40760969573801215, disc_loss = 0.051789282054423985
Trained batch 198 in epoch 3, gen_loss = 0.4076158699378296, disc_loss = 0.05182279647800641
Trained batch 199 in epoch 3, gen_loss = 0.40772597298026086, disc_loss = 0.05235076272394508
Trained batch 200 in epoch 3, gen_loss = 0.4078537686843777, disc_loss = 0.0522909467039046
Trained batch 201 in epoch 3, gen_loss = 0.4080755278320596, disc_loss = 0.05243880981763843
Trained batch 202 in epoch 3, gen_loss = 0.40781158458423145, disc_loss = 0.05246139001651791
Trained batch 203 in epoch 3, gen_loss = 0.4078661415214632, disc_loss = 0.05235932909372244
Trained batch 204 in epoch 3, gen_loss = 0.4082330801138064, disc_loss = 0.05220220204806182
Trained batch 205 in epoch 3, gen_loss = 0.40831463241461413, disc_loss = 0.05241574979504769
Trained batch 206 in epoch 3, gen_loss = 0.4081431415633879, disc_loss = 0.052954823098140924
Trained batch 207 in epoch 3, gen_loss = 0.4081270105850238, disc_loss = 0.053161276965581164
Trained batch 208 in epoch 3, gen_loss = 0.408162606389899, disc_loss = 0.05332746138822947
Trained batch 209 in epoch 3, gen_loss = 0.4082823524872462, disc_loss = 0.05327841906941363
Trained batch 210 in epoch 3, gen_loss = 0.408250716201502, disc_loss = 0.05305841431392454
Trained batch 211 in epoch 3, gen_loss = 0.4082361291039665, disc_loss = 0.05283824164850883
Trained batch 212 in epoch 3, gen_loss = 0.408019225222404, disc_loss = 0.052782580608440814
Trained batch 213 in epoch 3, gen_loss = 0.4080647940390578, disc_loss = 0.05258541179725152
Trained batch 214 in epoch 3, gen_loss = 0.40803923967272737, disc_loss = 0.052452175836836874
Trained batch 215 in epoch 3, gen_loss = 0.4080352559685707, disc_loss = 0.05224900950324135
Trained batch 216 in epoch 3, gen_loss = 0.40782273447458645, disc_loss = 0.05210817647102173
Trained batch 217 in epoch 3, gen_loss = 0.40803906020768194, disc_loss = 0.05208089208409805
Trained batch 218 in epoch 3, gen_loss = 0.4076390386172081, disc_loss = 0.05211319826058533
Trained batch 219 in epoch 3, gen_loss = 0.40763412659818477, disc_loss = 0.05193248111119663
Trained batch 220 in epoch 3, gen_loss = 0.40782605765631835, disc_loss = 0.05194808129111633
Trained batch 221 in epoch 3, gen_loss = 0.4080753134446101, disc_loss = 0.05194076064445481
Trained batch 222 in epoch 3, gen_loss = 0.40817313036576514, disc_loss = 0.051804871279579244
Trained batch 223 in epoch 3, gen_loss = 0.4082847668656281, disc_loss = 0.05159710191323289
Trained batch 224 in epoch 3, gen_loss = 0.4083101518948873, disc_loss = 0.05155143070552084
Trained batch 225 in epoch 3, gen_loss = 0.40755362676835694, disc_loss = 0.05202340995645629
Trained batch 226 in epoch 3, gen_loss = 0.4078734307037051, disc_loss = 0.05301202139468445
Trained batch 227 in epoch 3, gen_loss = 0.4078535408827296, disc_loss = 0.053095518349947635
Trained batch 228 in epoch 3, gen_loss = 0.40774442014735857, disc_loss = 0.05308842985976211
Trained batch 229 in epoch 3, gen_loss = 0.4075904837121134, disc_loss = 0.05295677554348241
Trained batch 230 in epoch 3, gen_loss = 0.4071739980410704, disc_loss = 0.05284491382958569
Trained batch 231 in epoch 3, gen_loss = 0.40690528203187315, disc_loss = 0.05271305508333547
Trained batch 232 in epoch 3, gen_loss = 0.4070251907657656, disc_loss = 0.052649098836173316
Trained batch 233 in epoch 3, gen_loss = 0.40708964286196947, disc_loss = 0.05248271425565084
Trained batch 234 in epoch 3, gen_loss = 0.4071293848626157, disc_loss = 0.05256097300889644
Trained batch 235 in epoch 3, gen_loss = 0.40672596581911635, disc_loss = 0.05353829968657534
Trained batch 236 in epoch 3, gen_loss = 0.4070672978831746, disc_loss = 0.054107679439244896
Trained batch 237 in epoch 3, gen_loss = 0.40707008202536765, disc_loss = 0.053926323395723307
Trained batch 238 in epoch 3, gen_loss = 0.40732940944168855, disc_loss = 0.05373603341298248
Trained batch 239 in epoch 3, gen_loss = 0.40708089880645276, disc_loss = 0.053877574752550575
Trained batch 240 in epoch 3, gen_loss = 0.4072304903471618, disc_loss = 0.054023045617546034
Trained batch 241 in epoch 3, gen_loss = 0.4072172304322897, disc_loss = 0.053823591025222925
Trained batch 242 in epoch 3, gen_loss = 0.4074966067394602, disc_loss = 0.05366083078178359
Trained batch 243 in epoch 3, gen_loss = 0.4075449872456613, disc_loss = 0.05350270400541361
Trained batch 244 in epoch 3, gen_loss = 0.40761581647152806, disc_loss = 0.0533234821290386
Trained batch 245 in epoch 3, gen_loss = 0.407792280359966, disc_loss = 0.053256194372244964
Trained batch 246 in epoch 3, gen_loss = 0.4078370929970915, disc_loss = 0.053200253289238164
Trained batch 247 in epoch 3, gen_loss = 0.40823569449205555, disc_loss = 0.053084117615775715
Trained batch 248 in epoch 3, gen_loss = 0.40830565779563416, disc_loss = 0.0529137005558215
Trained batch 249 in epoch 3, gen_loss = 0.40806022346019744, disc_loss = 0.05284437493979931
Trained batch 250 in epoch 3, gen_loss = 0.40786865591052995, disc_loss = 0.053108449491015466
Trained batch 251 in epoch 3, gen_loss = 0.4081307232143387, disc_loss = 0.05319879007422262
Trained batch 252 in epoch 3, gen_loss = 0.4080769046257607, disc_loss = 0.05317196922870022
Trained batch 253 in epoch 3, gen_loss = 0.40820011918939003, disc_loss = 0.053014910013568915
Trained batch 254 in epoch 3, gen_loss = 0.408045714041766, disc_loss = 0.05291498245342689
Trained batch 255 in epoch 3, gen_loss = 0.4080115936230868, disc_loss = 0.052730566094396636
Trained batch 256 in epoch 3, gen_loss = 0.408183183999377, disc_loss = 0.052555272393725844
Trained batch 257 in epoch 3, gen_loss = 0.4081548644128696, disc_loss = 0.05240123585234721
Trained batch 258 in epoch 3, gen_loss = 0.4080661142884995, disc_loss = 0.05237480482215989
Trained batch 259 in epoch 3, gen_loss = 0.4079769351161443, disc_loss = 0.0525958840860627
Trained batch 260 in epoch 3, gen_loss = 0.4077336558665352, disc_loss = 0.053140540480599435
Trained batch 261 in epoch 3, gen_loss = 0.4072181129728565, disc_loss = 0.05363237450276111
Trained batch 262 in epoch 3, gen_loss = 0.4072012486566609, disc_loss = 0.05383701131505601
Trained batch 263 in epoch 3, gen_loss = 0.4072543206540021, disc_loss = 0.053800063382368535
Trained batch 264 in epoch 3, gen_loss = 0.40705498322001044, disc_loss = 0.0537515278044596
Trained batch 265 in epoch 3, gen_loss = 0.4069620085165913, disc_loss = 0.05357763350983255
Trained batch 266 in epoch 3, gen_loss = 0.40693373916747416, disc_loss = 0.05348521978018826
Trained batch 267 in epoch 3, gen_loss = 0.4069585615574424, disc_loss = 0.05332541873560412
Trained batch 268 in epoch 3, gen_loss = 0.40675920137242316, disc_loss = 0.053161613589505836
Trained batch 269 in epoch 3, gen_loss = 0.40704866073749685, disc_loss = 0.053040442175956236
Trained batch 270 in epoch 3, gen_loss = 0.4071252673754393, disc_loss = 0.05294144276797606
Trained batch 271 in epoch 3, gen_loss = 0.40712393031400795, disc_loss = 0.05279262684908805
Trained batch 272 in epoch 3, gen_loss = 0.4071959043160463, disc_loss = 0.052753980143589306
Trained batch 273 in epoch 3, gen_loss = 0.40728651215560246, disc_loss = 0.052625195345888935
Trained batch 274 in epoch 3, gen_loss = 0.40730226256630636, disc_loss = 0.05254739132625136
Trained batch 275 in epoch 3, gen_loss = 0.40747314151646435, disc_loss = 0.052703729275600526
Trained batch 276 in epoch 3, gen_loss = 0.40712139290162375, disc_loss = 0.052711190459140266
Trained batch 277 in epoch 3, gen_loss = 0.40715836052843135, disc_loss = 0.05254400195888907
Trained batch 278 in epoch 3, gen_loss = 0.40703820060658197, disc_loss = 0.05237153059332281
Trained batch 279 in epoch 3, gen_loss = 0.4068023421934673, disc_loss = 0.052198435976502616
Trained batch 280 in epoch 3, gen_loss = 0.4066372579527071, disc_loss = 0.05209577273000761
Trained batch 281 in epoch 3, gen_loss = 0.40665294367370874, disc_loss = 0.05206609050848964
Trained batch 282 in epoch 3, gen_loss = 0.40645311872866463, disc_loss = 0.052042269162741545
Trained batch 283 in epoch 3, gen_loss = 0.40629680979419763, disc_loss = 0.051890204209690045
Trained batch 284 in epoch 3, gen_loss = 0.4064206453791836, disc_loss = 0.05185944964259601
Trained batch 285 in epoch 3, gen_loss = 0.406234605433224, disc_loss = 0.05186674244526018
Trained batch 286 in epoch 3, gen_loss = 0.40627906816761666, disc_loss = 0.05175738393098687
Trained batch 287 in epoch 3, gen_loss = 0.4061734303832054, disc_loss = 0.0516189726105141
Trained batch 288 in epoch 3, gen_loss = 0.4059017566661109, disc_loss = 0.05148528331478213
Trained batch 289 in epoch 3, gen_loss = 0.40611320538767454, disc_loss = 0.051336962410152474
Trained batch 290 in epoch 3, gen_loss = 0.40594181459384276, disc_loss = 0.051190260415288694
Trained batch 291 in epoch 3, gen_loss = 0.40601837920815975, disc_loss = 0.051036150933064725
Trained batch 292 in epoch 3, gen_loss = 0.40626166623607024, disc_loss = 0.05102248192183139
Trained batch 293 in epoch 3, gen_loss = 0.40660025777459957, disc_loss = 0.05103547308359574
Trained batch 294 in epoch 3, gen_loss = 0.4067993034750728, disc_loss = 0.050941546228161806
Trained batch 295 in epoch 3, gen_loss = 0.4067299572398534, disc_loss = 0.05081008853409691
Trained batch 296 in epoch 3, gen_loss = 0.40674876805507776, disc_loss = 0.050671006927599106
Trained batch 297 in epoch 3, gen_loss = 0.406982954916538, disc_loss = 0.05055543055426604
Trained batch 298 in epoch 3, gen_loss = 0.40679781512671886, disc_loss = 0.05057930830635604
Trained batch 299 in epoch 3, gen_loss = 0.40674936254819233, disc_loss = 0.05080381668017556
Trained batch 300 in epoch 3, gen_loss = 0.40705672253009884, disc_loss = 0.05081842847298398
Trained batch 301 in epoch 3, gen_loss = 0.4071632255584199, disc_loss = 0.05074674338996657
Trained batch 302 in epoch 3, gen_loss = 0.4071043806500954, disc_loss = 0.05059364583287941
Trained batch 303 in epoch 3, gen_loss = 0.4071240178064296, disc_loss = 0.050493586705813776
Trained batch 304 in epoch 3, gen_loss = 0.407063458591211, disc_loss = 0.05034273785432098
Trained batch 305 in epoch 3, gen_loss = 0.40706858253167344, disc_loss = 0.050197217287800085
Trained batch 306 in epoch 3, gen_loss = 0.40689549791696406, disc_loss = 0.05004500713296453
Trained batch 307 in epoch 3, gen_loss = 0.40692459666109704, disc_loss = 0.049894323279210305
Trained batch 308 in epoch 3, gen_loss = 0.4070255708154351, disc_loss = 0.0497460699215242
Trained batch 309 in epoch 3, gen_loss = 0.40698686828536373, disc_loss = 0.04960880494646488
Trained batch 310 in epoch 3, gen_loss = 0.40691760239877117, disc_loss = 0.04946924026282894
Trained batch 311 in epoch 3, gen_loss = 0.4070101197904501, disc_loss = 0.0493282190649412
Trained batch 312 in epoch 3, gen_loss = 0.40698408347349196, disc_loss = 0.04929421262773938
Trained batch 313 in epoch 3, gen_loss = 0.40685783051381447, disc_loss = 0.0491890837141805
Trained batch 314 in epoch 3, gen_loss = 0.4068755957815382, disc_loss = 0.04910327206469244
Trained batch 315 in epoch 3, gen_loss = 0.40684444287532495, disc_loss = 0.048974927329116416
Trained batch 316 in epoch 3, gen_loss = 0.4068494895091192, disc_loss = 0.04893406929759667
Trained batch 317 in epoch 3, gen_loss = 0.40676649823878547, disc_loss = 0.04888168319696619
Trained batch 318 in epoch 3, gen_loss = 0.4069773281069011, disc_loss = 0.04879130179290207
Trained batch 319 in epoch 3, gen_loss = 0.40728334048762915, disc_loss = 0.04867006307467818
Trained batch 320 in epoch 3, gen_loss = 0.4072271786003469, disc_loss = 0.048622259852763645
Trained batch 321 in epoch 3, gen_loss = 0.4073625177330112, disc_loss = 0.048485153149350646
Trained batch 322 in epoch 3, gen_loss = 0.40747686436301783, disc_loss = 0.04836559610227959
Trained batch 323 in epoch 3, gen_loss = 0.40757175902893517, disc_loss = 0.04830289333426382
Trained batch 324 in epoch 3, gen_loss = 0.40743161586614757, disc_loss = 0.04819799558761028
Trained batch 325 in epoch 3, gen_loss = 0.4073610503249373, disc_loss = 0.04808563817623843
Trained batch 326 in epoch 3, gen_loss = 0.40750848372048193, disc_loss = 0.04795006750684106
Trained batch 327 in epoch 3, gen_loss = 0.4076050901558341, disc_loss = 0.047820506362590894
Trained batch 328 in epoch 3, gen_loss = 0.4077705354132551, disc_loss = 0.04769652997466274
Trained batch 329 in epoch 3, gen_loss = 0.4078393920804515, disc_loss = 0.04759047252591699
Trained batch 330 in epoch 3, gen_loss = 0.4079283157144068, disc_loss = 0.047464520281484616
Trained batch 331 in epoch 3, gen_loss = 0.40826772620160895, disc_loss = 0.0473832828799229
Trained batch 332 in epoch 3, gen_loss = 0.4085072740778193, disc_loss = 0.04727460440547505
Trained batch 333 in epoch 3, gen_loss = 0.40854525566101074, disc_loss = 0.04716874844140881
Trained batch 334 in epoch 3, gen_loss = 0.408602930004917, disc_loss = 0.047062517051348715
Trained batch 335 in epoch 3, gen_loss = 0.40858045042980284, disc_loss = 0.04694088453695821
Trained batch 336 in epoch 3, gen_loss = 0.4086399983935257, disc_loss = 0.046880612117362705
Trained batch 337 in epoch 3, gen_loss = 0.408709565916005, disc_loss = 0.04675784958705593
Trained batch 338 in epoch 3, gen_loss = 0.4088777017101074, disc_loss = 0.04664394846062415
Trained batch 339 in epoch 3, gen_loss = 0.40895254033453327, disc_loss = 0.04652513234177604
Trained batch 340 in epoch 3, gen_loss = 0.4090079606628138, disc_loss = 0.04642079907190874
Trained batch 341 in epoch 3, gen_loss = 0.40884756013663887, disc_loss = 0.04632255937209712
Trained batch 342 in epoch 3, gen_loss = 0.40875127346800644, disc_loss = 0.046201400087505534
Trained batch 343 in epoch 3, gen_loss = 0.40871195243888125, disc_loss = 0.04624573506081888
Trained batch 344 in epoch 3, gen_loss = 0.4090332351732945, disc_loss = 0.04731240808977273
Trained batch 345 in epoch 3, gen_loss = 0.40898579867244456, disc_loss = 0.0473278293936551
Trained batch 346 in epoch 3, gen_loss = 0.4088609550974898, disc_loss = 0.04746104371921838
Trained batch 347 in epoch 3, gen_loss = 0.4087315500638951, disc_loss = 0.04748625343400535
Trained batch 348 in epoch 3, gen_loss = 0.4089996583311469, disc_loss = 0.047468289079806394
Trained batch 349 in epoch 3, gen_loss = 0.4090161577292851, disc_loss = 0.04749903333839029
Trained batch 350 in epoch 3, gen_loss = 0.4088838491005096, disc_loss = 0.04776646086264221
Trained batch 351 in epoch 3, gen_loss = 0.4089543138715354, disc_loss = 0.04764763222126269
Trained batch 352 in epoch 3, gen_loss = 0.4091267869425225, disc_loss = 0.04775752180662249
Trained batch 353 in epoch 3, gen_loss = 0.4089297352537597, disc_loss = 0.04776928178889751
Trained batch 354 in epoch 3, gen_loss = 0.4089470457023298, disc_loss = 0.047686546675624775
Trained batch 355 in epoch 3, gen_loss = 0.4090814089842057, disc_loss = 0.04769577897151179
Trained batch 356 in epoch 3, gen_loss = 0.40917599151114453, disc_loss = 0.047593027250893434
Trained batch 357 in epoch 3, gen_loss = 0.4090676058770558, disc_loss = 0.04749721027689585
Trained batch 358 in epoch 3, gen_loss = 0.4090791103899645, disc_loss = 0.04748011266483217
Trained batch 359 in epoch 3, gen_loss = 0.40895130559802056, disc_loss = 0.04766024266460186
Trained batch 360 in epoch 3, gen_loss = 0.4087492542088527, disc_loss = 0.047686025295845154
Trained batch 361 in epoch 3, gen_loss = 0.40871067303978936, disc_loss = 0.047566091713176537
Trained batch 362 in epoch 3, gen_loss = 0.4088623514681151, disc_loss = 0.04749100510551807
Trained batch 363 in epoch 3, gen_loss = 0.40882599427477345, disc_loss = 0.04742608584686193
Trained batch 364 in epoch 3, gen_loss = 0.4088880578949027, disc_loss = 0.04742337654038549
Trained batch 365 in epoch 3, gen_loss = 0.40893941743126333, disc_loss = 0.0473235182946324
Trained batch 366 in epoch 3, gen_loss = 0.40882153504550944, disc_loss = 0.04725535200180471
Trained batch 367 in epoch 3, gen_loss = 0.408778155060566, disc_loss = 0.04730048401562153
Trained batch 368 in epoch 3, gen_loss = 0.40882238422628986, disc_loss = 0.047207680643791064
Trained batch 369 in epoch 3, gen_loss = 0.4089408053739651, disc_loss = 0.04714820994555044
Trained batch 370 in epoch 3, gen_loss = 0.40878341268657675, disc_loss = 0.04707146444448303
Trained batch 371 in epoch 3, gen_loss = 0.4087668027608625, disc_loss = 0.047020184195986
Trained batch 372 in epoch 3, gen_loss = 0.40876083727176965, disc_loss = 0.04691901036922697
Trained batch 373 in epoch 3, gen_loss = 0.4087157328339184, disc_loss = 0.046819517761842414
Trained batch 374 in epoch 3, gen_loss = 0.40881499950091044, disc_loss = 0.046740244114771484
Trained batch 375 in epoch 3, gen_loss = 0.4086016023412664, disc_loss = 0.04665225417727228
Trained batch 376 in epoch 3, gen_loss = 0.40865446884056617, disc_loss = 0.046662387993329994
Trained batch 377 in epoch 3, gen_loss = 0.4085012272236839, disc_loss = 0.046627298238312714
Trained batch 378 in epoch 3, gen_loss = 0.4084139706906039, disc_loss = 0.04652866680300389
Trained batch 379 in epoch 3, gen_loss = 0.40852389343475043, disc_loss = 0.04652584797494407
Trained batch 380 in epoch 3, gen_loss = 0.40847094736387096, disc_loss = 0.046435884808085054
Trained batch 381 in epoch 3, gen_loss = 0.40835190443468344, disc_loss = 0.0463427498208905
Trained batch 382 in epoch 3, gen_loss = 0.40846540185552355, disc_loss = 0.04625369988651776
Trained batch 383 in epoch 3, gen_loss = 0.4084056179660062, disc_loss = 0.0462032711845192
Trained batch 384 in epoch 3, gen_loss = 0.4087131480117897, disc_loss = 0.046106419767337765
Trained batch 385 in epoch 3, gen_loss = 0.4087951666641729, disc_loss = 0.046055908992264055
Trained batch 386 in epoch 3, gen_loss = 0.40866851806640625, disc_loss = 0.045960788157207826
Trained batch 387 in epoch 3, gen_loss = 0.4084720408025476, disc_loss = 0.04594795768972505
Trained batch 388 in epoch 3, gen_loss = 0.40849472034559764, disc_loss = 0.046321110605384325
Trained batch 389 in epoch 3, gen_loss = 0.4082425695963395, disc_loss = 0.04722066974589745
Trained batch 390 in epoch 3, gen_loss = 0.4080901681767095, disc_loss = 0.04721596766718189
Trained batch 391 in epoch 3, gen_loss = 0.4082450610490478, disc_loss = 0.04733849963237417
Trained batch 392 in epoch 3, gen_loss = 0.40831104451766753, disc_loss = 0.04742399722742955
Trained batch 393 in epoch 3, gen_loss = 0.40841317607969196, disc_loss = 0.047425608724464434
Trained batch 394 in epoch 3, gen_loss = 0.40858500049084046, disc_loss = 0.04740388585030561
Trained batch 395 in epoch 3, gen_loss = 0.40851605954495346, disc_loss = 0.04739269357576797
Trained batch 396 in epoch 3, gen_loss = 0.40846584741054315, disc_loss = 0.047467219375275656
Trained batch 397 in epoch 3, gen_loss = 0.4082898040812219, disc_loss = 0.04768932016564056
Trained batch 398 in epoch 3, gen_loss = 0.4082874445090617, disc_loss = 0.0478121468483384
Trained batch 399 in epoch 3, gen_loss = 0.4082347823679447, disc_loss = 0.04772139603213873
Trained batch 400 in epoch 3, gen_loss = 0.4081376745665163, disc_loss = 0.04767966803634757
Trained batch 401 in epoch 3, gen_loss = 0.4082794236158257, disc_loss = 0.04759304659077388
Trained batch 402 in epoch 3, gen_loss = 0.4084278666795631, disc_loss = 0.04750735234069377
Trained batch 403 in epoch 3, gen_loss = 0.4084854390066449, disc_loss = 0.04741361334235269
Trained batch 404 in epoch 3, gen_loss = 0.4084992047445274, disc_loss = 0.04731428900814075
Trained batch 405 in epoch 3, gen_loss = 0.40877507010410574, disc_loss = 0.04723800225424227
Trained batch 406 in epoch 3, gen_loss = 0.4089161417554579, disc_loss = 0.047135419835261
Trained batch 407 in epoch 3, gen_loss = 0.4089610148586479, disc_loss = 0.04703463445470084
Trained batch 408 in epoch 3, gen_loss = 0.409208203440482, disc_loss = 0.04693533068871203
Trained batch 409 in epoch 3, gen_loss = 0.40924478195062497, disc_loss = 0.04683572281231513
Trained batch 410 in epoch 3, gen_loss = 0.4093654104247871, disc_loss = 0.046734198923913846
Trained batch 411 in epoch 3, gen_loss = 0.4093445260258554, disc_loss = 0.04663741955752891
Trained batch 412 in epoch 3, gen_loss = 0.4091216991080499, disc_loss = 0.04654530391433066
Trained batch 413 in epoch 3, gen_loss = 0.40925404515819275, disc_loss = 0.046480738146765975
Trained batch 414 in epoch 3, gen_loss = 0.40932537532714475, disc_loss = 0.046379169603495536
Trained batch 415 in epoch 3, gen_loss = 0.40923814547176546, disc_loss = 0.046286331119727735
Trained batch 416 in epoch 3, gen_loss = 0.40920616161051415, disc_loss = 0.046198236165854105
Trained batch 417 in epoch 3, gen_loss = 0.4091223184571882, disc_loss = 0.04612635211232586
Trained batch 418 in epoch 3, gen_loss = 0.40910650750617705, disc_loss = 0.046123300820726874
Trained batch 419 in epoch 3, gen_loss = 0.40905225908472426, disc_loss = 0.04610742698368128
Trained batch 420 in epoch 3, gen_loss = 0.409188663308241, disc_loss = 0.0462989958855954
Trained batch 421 in epoch 3, gen_loss = 0.40916508866994866, disc_loss = 0.046282840174870006
Trained batch 422 in epoch 3, gen_loss = 0.4092374723712885, disc_loss = 0.04621483640245495
Trained batch 423 in epoch 3, gen_loss = 0.409312746926861, disc_loss = 0.04612638303990265
Trained batch 424 in epoch 3, gen_loss = 0.40927520015660457, disc_loss = 0.04606782679993878
Trained batch 425 in epoch 3, gen_loss = 0.40934379391826936, disc_loss = 0.04599289365818925
Trained batch 426 in epoch 3, gen_loss = 0.4093846801572438, disc_loss = 0.045914494331633846
Trained batch 427 in epoch 3, gen_loss = 0.40917744884424123, disc_loss = 0.0458489874846772
Trained batch 428 in epoch 3, gen_loss = 0.40922307210924463, disc_loss = 0.04575758377830379
Trained batch 429 in epoch 3, gen_loss = 0.40920165506906286, disc_loss = 0.045667058946889674
Trained batch 430 in epoch 3, gen_loss = 0.4089939574216192, disc_loss = 0.04568689083842574
Trained batch 431 in epoch 3, gen_loss = 0.4092616625820045, disc_loss = 0.04605565586448561
Trained batch 432 in epoch 3, gen_loss = 0.4093815154346528, disc_loss = 0.04600540619810256
Trained batch 433 in epoch 3, gen_loss = 0.4092812332140136, disc_loss = 0.04613019355029846
Trained batch 434 in epoch 3, gen_loss = 0.4094301122358476, disc_loss = 0.04622123449366411
Trained batch 435 in epoch 3, gen_loss = 0.409588004744381, disc_loss = 0.04618752660462633
Trained batch 436 in epoch 3, gen_loss = 0.4095456808873663, disc_loss = 0.04609303813037682
Trained batch 437 in epoch 3, gen_loss = 0.40950530536098567, disc_loss = 0.046038433291192365
Trained batch 438 in epoch 3, gen_loss = 0.4096207484297437, disc_loss = 0.04600465684919141
Trained batch 439 in epoch 3, gen_loss = 0.4095691143789075, disc_loss = 0.04593200130356391
Trained batch 440 in epoch 3, gen_loss = 0.4094414210914214, disc_loss = 0.04587318586943726
Trained batch 441 in epoch 3, gen_loss = 0.4094292395389997, disc_loss = 0.0459751872713488
Trained batch 442 in epoch 3, gen_loss = 0.4093061154771335, disc_loss = 0.0463644129820126
Trained batch 443 in epoch 3, gen_loss = 0.40929561994365743, disc_loss = 0.04664885715071766
Trained batch 444 in epoch 3, gen_loss = 0.40956729831320515, disc_loss = 0.046567600652094136
Trained batch 445 in epoch 3, gen_loss = 0.4095419144817532, disc_loss = 0.046492491678059134
Trained batch 446 in epoch 3, gen_loss = 0.40941949538736533, disc_loss = 0.0464117122815101
Trained batch 447 in epoch 3, gen_loss = 0.40931265269007, disc_loss = 0.046323776622947274
Trained batch 448 in epoch 3, gen_loss = 0.409249170718586, disc_loss = 0.04623091650477513
Trained batch 449 in epoch 3, gen_loss = 0.40915825996134014, disc_loss = 0.04614759433859338
Trained batch 450 in epoch 3, gen_loss = 0.4092322535763294, disc_loss = 0.04606373414671887
Trained batch 451 in epoch 3, gen_loss = 0.40912568536216176, disc_loss = 0.0459746420883112
Trained batch 452 in epoch 3, gen_loss = 0.4091958718057763, disc_loss = 0.04589162934335076
Trained batch 453 in epoch 3, gen_loss = 0.40928687877329434, disc_loss = 0.04579992128878684
Trained batch 454 in epoch 3, gen_loss = 0.4091488457643069, disc_loss = 0.045724484389443154
Trained batch 455 in epoch 3, gen_loss = 0.4092912681792912, disc_loss = 0.04564188769967459
Trained batch 456 in epoch 3, gen_loss = 0.4092610887938568, disc_loss = 0.045605080470715854
Trained batch 457 in epoch 3, gen_loss = 0.40908652635120407, disc_loss = 0.04556832658116783
Trained batch 458 in epoch 3, gen_loss = 0.40879348485298406, disc_loss = 0.04548970596258141
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.41842296719551086, disc_loss = 0.07514353096485138
Trained batch 1 in epoch 4, gen_loss = 0.3981316536664963, disc_loss = 0.10498525947332382
Trained batch 2 in epoch 4, gen_loss = 0.39907628297805786, disc_loss = 0.09405672301848729
Trained batch 3 in epoch 4, gen_loss = 0.41328077018260956, disc_loss = 0.08023977372795343
Trained batch 4 in epoch 4, gen_loss = 0.40896316766738894, disc_loss = 0.07443646788597107
Trained batch 5 in epoch 4, gen_loss = 0.40854645768801373, disc_loss = 0.06487490391979615
Trained batch 6 in epoch 4, gen_loss = 0.4159301774842398, disc_loss = 0.05903939264161246
Trained batch 7 in epoch 4, gen_loss = 0.4213617965579033, disc_loss = 0.05258520826464519
Trained batch 8 in epoch 4, gen_loss = 0.412944667869144, disc_loss = 0.05118243432500296
Trained batch 9 in epoch 4, gen_loss = 0.4113002747297287, disc_loss = 0.04648939515464008
Trained batch 10 in epoch 4, gen_loss = 0.41307405721057544, disc_loss = 0.044727904510430315
Trained batch 11 in epoch 4, gen_loss = 0.4156104326248169, disc_loss = 0.04653793383234491
Trained batch 12 in epoch 4, gen_loss = 0.4160568095170535, disc_loss = 0.05057051946194126
Trained batch 13 in epoch 4, gen_loss = 0.4139469414949417, disc_loss = 0.04872765774572534
Trained batch 14 in epoch 4, gen_loss = 0.4109527627627055, disc_loss = 0.04675435023382306
Trained batch 15 in epoch 4, gen_loss = 0.4131481386721134, disc_loss = 0.04624739263090305
Trained batch 16 in epoch 4, gen_loss = 0.4113101082689622, disc_loss = 0.0457393831354292
Trained batch 17 in epoch 4, gen_loss = 0.408610752887196, disc_loss = 0.04503103343045546
Trained batch 18 in epoch 4, gen_loss = 0.410753480697933, disc_loss = 0.04323877700555481
Trained batch 19 in epoch 4, gen_loss = 0.411333392560482, disc_loss = 0.045998461474664507
Trained batch 20 in epoch 4, gen_loss = 0.4107930617673056, disc_loss = 0.05125500113215475
Trained batch 21 in epoch 4, gen_loss = 0.4140058065002615, disc_loss = 0.050140793033113536
Trained batch 22 in epoch 4, gen_loss = 0.41323430771413056, disc_loss = 0.04906445986631772
Trained batch 23 in epoch 4, gen_loss = 0.4132556455830733, disc_loss = 0.047217509301844984
Trained batch 24 in epoch 4, gen_loss = 0.41095401883125304, disc_loss = 0.04573030112311244
Trained batch 25 in epoch 4, gen_loss = 0.4115955657683886, disc_loss = 0.045236993133305356
Trained batch 26 in epoch 4, gen_loss = 0.41129745487813596, disc_loss = 0.04385078008528109
Trained batch 27 in epoch 4, gen_loss = 0.4090008150253977, disc_loss = 0.04260469344444573
Trained batch 28 in epoch 4, gen_loss = 0.40959669187151154, disc_loss = 0.04132593439185414
Trained batch 29 in epoch 4, gen_loss = 0.4098178247610728, disc_loss = 0.04012365749416252
Trained batch 30 in epoch 4, gen_loss = 0.4113431159527071, disc_loss = 0.038941437002992435
Trained batch 31 in epoch 4, gen_loss = 0.41032555792480707, disc_loss = 0.03786835337814409
Trained batch 32 in epoch 4, gen_loss = 0.4095779169689525, disc_loss = 0.036908944165616325
Trained batch 33 in epoch 4, gen_loss = 0.40855968436774087, disc_loss = 0.035947777495226436
Trained batch 34 in epoch 4, gen_loss = 0.40687719753810336, disc_loss = 0.03502840180216091
Trained batch 35 in epoch 4, gen_loss = 0.4068031410376231, disc_loss = 0.03417084178525127
Trained batch 36 in epoch 4, gen_loss = 0.4074306206123249, disc_loss = 0.033354858074941346
Trained batch 37 in epoch 4, gen_loss = 0.40590541613729375, disc_loss = 0.03265027102622155
Trained batch 38 in epoch 4, gen_loss = 0.403944302827884, disc_loss = 0.03186609969140054
Trained batch 39 in epoch 4, gen_loss = 0.4026722520589828, disc_loss = 0.031150949775474147
Trained batch 40 in epoch 4, gen_loss = 0.40379087663278346, disc_loss = 0.030623246103570593
Trained batch 41 in epoch 4, gen_loss = 0.4050352665640059, disc_loss = 0.03016752539579535
Trained batch 42 in epoch 4, gen_loss = 0.40700017227682955, disc_loss = 0.029613731672640805
Trained batch 43 in epoch 4, gen_loss = 0.40757322311401367, disc_loss = 0.029037789870265195
Trained batch 44 in epoch 4, gen_loss = 0.40861176517274644, disc_loss = 0.02848377958871424
Trained batch 45 in epoch 4, gen_loss = 0.40954616017963574, disc_loss = 0.0279594551032895
Trained batch 46 in epoch 4, gen_loss = 0.40945486185398505, disc_loss = 0.027563370382809576
Trained batch 47 in epoch 4, gen_loss = 0.41055928853650886, disc_loss = 0.02738686671849185
Trained batch 48 in epoch 4, gen_loss = 0.40972431521026453, disc_loss = 0.027196347005475238
Trained batch 49 in epoch 4, gen_loss = 0.4092435032129288, disc_loss = 0.026933865691535174
Trained batch 50 in epoch 4, gen_loss = 0.40861866170284794, disc_loss = 0.026504999697756243
Trained batch 51 in epoch 4, gen_loss = 0.4080364411840072, disc_loss = 0.026047978191994704
Trained batch 52 in epoch 4, gen_loss = 0.40721180079118263, disc_loss = 0.0256039129069321
Trained batch 53 in epoch 4, gen_loss = 0.4059722274541855, disc_loss = 0.02516769331069318
Trained batch 54 in epoch 4, gen_loss = 0.40475266792557457, disc_loss = 0.024759476860477164
Trained batch 55 in epoch 4, gen_loss = 0.40524052509239744, disc_loss = 0.024449467143443013
Trained batch 56 in epoch 4, gen_loss = 0.40473185139789913, disc_loss = 0.024050432241015267
Trained batch 57 in epoch 4, gen_loss = 0.40583197258669756, disc_loss = 0.023695458786497856
Trained batch 58 in epoch 4, gen_loss = 0.40546930998058645, disc_loss = 0.023323642875273096
Trained batch 59 in epoch 4, gen_loss = 0.4046606739362081, disc_loss = 0.022991419401175033
Trained batch 60 in epoch 4, gen_loss = 0.4056781828403473, disc_loss = 0.02265554448574415
Trained batch 61 in epoch 4, gen_loss = 0.4050360942079175, disc_loss = 0.022357038766776603
Trained batch 62 in epoch 4, gen_loss = 0.4049722112360455, disc_loss = 0.022044660142874196
Trained batch 63 in epoch 4, gen_loss = 0.4040616014972329, disc_loss = 0.021737394781666808
Trained batch 64 in epoch 4, gen_loss = 0.4040112990599412, disc_loss = 0.021428154631016345
Trained batch 65 in epoch 4, gen_loss = 0.4037273255261508, disc_loss = 0.021149626410933153
Trained batch 66 in epoch 4, gen_loss = 0.4036543831896426, disc_loss = 0.02086064316950905
Trained batch 67 in epoch 4, gen_loss = 0.40303439208689856, disc_loss = 0.02060423179372104
Trained batch 68 in epoch 4, gen_loss = 0.4032077163025953, disc_loss = 0.020332045215384467
Trained batch 69 in epoch 4, gen_loss = 0.40403706984860555, disc_loss = 0.020146933926402457
Trained batch 70 in epoch 4, gen_loss = 0.4030654463969486, disc_loss = 0.019920719731730263
Trained batch 71 in epoch 4, gen_loss = 0.40248070533076924, disc_loss = 0.019698793925474294
Trained batch 72 in epoch 4, gen_loss = 0.4029058907946495, disc_loss = 0.019454374887074712
Trained batch 73 in epoch 4, gen_loss = 0.402976547544067, disc_loss = 0.019219057090152557
Trained batch 74 in epoch 4, gen_loss = 0.4033046340942383, disc_loss = 0.01899866689617435
Trained batch 75 in epoch 4, gen_loss = 0.40299448096438456, disc_loss = 0.018778970097436717
Trained batch 76 in epoch 4, gen_loss = 0.4025428999554027, disc_loss = 0.018577863268747732
Trained batch 77 in epoch 4, gen_loss = 0.40180226396291685, disc_loss = 0.01836202933321683
Trained batch 78 in epoch 4, gen_loss = 0.4022404178033901, disc_loss = 0.018167170940580058
Trained batch 79 in epoch 4, gen_loss = 0.4030278388410807, disc_loss = 0.0179782531427918
Trained batch 80 in epoch 4, gen_loss = 0.40276029889966236, disc_loss = 0.017770474719136585
Trained batch 81 in epoch 4, gen_loss = 0.4025918790479986, disc_loss = 0.01758519942849511
Trained batch 82 in epoch 4, gen_loss = 0.4022024884281388, disc_loss = 0.01740048500058432
Trained batch 83 in epoch 4, gen_loss = 0.40223606392031624, disc_loss = 0.017226362420756015
Trained batch 84 in epoch 4, gen_loss = 0.4026905999464147, disc_loss = 0.017045694214346655
Trained batch 85 in epoch 4, gen_loss = 0.4027483203383379, disc_loss = 0.016862933819052264
Trained batch 86 in epoch 4, gen_loss = 0.4030513633256671, disc_loss = 0.016692361106625062
Trained batch 87 in epoch 4, gen_loss = 0.40316636250777677, disc_loss = 0.016526491635225037
Trained batch 88 in epoch 4, gen_loss = 0.4027833268883523, disc_loss = 0.016357902780154282
Trained batch 89 in epoch 4, gen_loss = 0.4025000618563758, disc_loss = 0.016194270397277756
Trained batch 90 in epoch 4, gen_loss = 0.403185683619845, disc_loss = 0.016060078026634735
Trained batch 91 in epoch 4, gen_loss = 0.4028455994051436, disc_loss = 0.01592301417511645
Trained batch 92 in epoch 4, gen_loss = 0.40304083497293536, disc_loss = 0.01576955653651948
Trained batch 93 in epoch 4, gen_loss = 0.4033852866355409, disc_loss = 0.015620736359430358
Trained batch 94 in epoch 4, gen_loss = 0.40318126270645543, disc_loss = 0.015475823471665774
Trained batch 95 in epoch 4, gen_loss = 0.4021944096311927, disc_loss = 0.015326718860402858
Trained batch 96 in epoch 4, gen_loss = 0.40243538630377385, disc_loss = 0.015209975395562876
Trained batch 97 in epoch 4, gen_loss = 0.4021111243233389, disc_loss = 0.015112089423215663
Trained batch 98 in epoch 4, gen_loss = 0.4026058012186879, disc_loss = 0.015027601876286696
Trained batch 99 in epoch 4, gen_loss = 0.4027834567427635, disc_loss = 0.0149168566823937
Trained batch 100 in epoch 4, gen_loss = 0.4031061075701572, disc_loss = 0.014791441518850255
Trained batch 101 in epoch 4, gen_loss = 0.40341928922662545, disc_loss = 0.01466802660576707
Trained batch 102 in epoch 4, gen_loss = 0.4037649240887281, disc_loss = 0.014548548777560585
Trained batch 103 in epoch 4, gen_loss = 0.4028265097966561, disc_loss = 0.01447246742184059
Trained batch 104 in epoch 4, gen_loss = 0.40308284532456173, disc_loss = 0.014381738069156805
Trained batch 105 in epoch 4, gen_loss = 0.4031590768751108, disc_loss = 0.014278905861571713
Trained batch 106 in epoch 4, gen_loss = 0.403557831160376, disc_loss = 0.014169518446340878
Trained batch 107 in epoch 4, gen_loss = 0.4034985218335081, disc_loss = 0.014062704317944331
Trained batch 108 in epoch 4, gen_loss = 0.40345664882878646, disc_loss = 0.013948223751183566
Trained batch 109 in epoch 4, gen_loss = 0.40324102775617077, disc_loss = 0.013832547318782995
Trained batch 110 in epoch 4, gen_loss = 0.4032236200732154, disc_loss = 0.013720110297907848
Trained batch 111 in epoch 4, gen_loss = 0.40388408675789833, disc_loss = 0.013622507901995309
Trained batch 112 in epoch 4, gen_loss = 0.40409939136125345, disc_loss = 0.013516375895968713
Trained batch 113 in epoch 4, gen_loss = 0.40428580997283, disc_loss = 0.013414554803411624
Trained batch 114 in epoch 4, gen_loss = 0.40403442175491994, disc_loss = 0.013318890826169239
Trained batch 115 in epoch 4, gen_loss = 0.4042105679881984, disc_loss = 0.013218302815622682
Trained batch 116 in epoch 4, gen_loss = 0.40399473880091286, disc_loss = 0.013118963887612535
Trained batch 117 in epoch 4, gen_loss = 0.4036025677697133, disc_loss = 0.013023095706604043
Trained batch 118 in epoch 4, gen_loss = 0.4039219758089851, disc_loss = 0.012927333554331245
Trained batch 119 in epoch 4, gen_loss = 0.4037542906900247, disc_loss = 0.012833195397009452
Trained batch 120 in epoch 4, gen_loss = 0.4032303474166177, disc_loss = 0.012739536269714148
Trained batch 121 in epoch 4, gen_loss = 0.40294160315247834, disc_loss = 0.012649615299048239
Trained batch 122 in epoch 4, gen_loss = 0.4031011469480468, disc_loss = 0.012563641482161554
Trained batch 123 in epoch 4, gen_loss = 0.4030710838494762, disc_loss = 0.012476089957823617
Trained batch 124 in epoch 4, gen_loss = 0.40336635756492617, disc_loss = 0.012389388057403266
Trained batch 125 in epoch 4, gen_loss = 0.40356294124845477, disc_loss = 0.01230520515754405
Trained batch 126 in epoch 4, gen_loss = 0.40354874378114236, disc_loss = 0.012222099306765856
Trained batch 127 in epoch 4, gen_loss = 0.40354203106835485, disc_loss = 0.012139892682171194
Trained batch 128 in epoch 4, gen_loss = 0.40346893922303073, disc_loss = 0.012066520214470666
Trained batch 129 in epoch 4, gen_loss = 0.4037707464053081, disc_loss = 0.011987573723308742
Trained batch 130 in epoch 4, gen_loss = 0.4039497946509878, disc_loss = 0.011904895773960832
Trained batch 131 in epoch 4, gen_loss = 0.40375625929146103, disc_loss = 0.011826665683077987
Trained batch 132 in epoch 4, gen_loss = 0.40338992848432154, disc_loss = 0.011751589113216204
Trained batch 133 in epoch 4, gen_loss = 0.40305629706204826, disc_loss = 0.01167454584519059
Trained batch 134 in epoch 4, gen_loss = 0.4033825836799763, disc_loss = 0.011598910359424298
Trained batch 135 in epoch 4, gen_loss = 0.4038310224080787, disc_loss = 0.011537255391457994
Trained batch 136 in epoch 4, gen_loss = 0.4036300974170657, disc_loss = 0.011472113565609784
Trained batch 137 in epoch 4, gen_loss = 0.4034414377765379, disc_loss = 0.011421010602582786
Trained batch 138 in epoch 4, gen_loss = 0.40279681798365474, disc_loss = 0.011358520852756961
Trained batch 139 in epoch 4, gen_loss = 0.40233618319034575, disc_loss = 0.011299292898703633
Trained batch 140 in epoch 4, gen_loss = 0.4020985449459536, disc_loss = 0.011231772888101742
Trained batch 141 in epoch 4, gen_loss = 0.40203417900582433, disc_loss = 0.011165805293811145
Trained batch 142 in epoch 4, gen_loss = 0.40184925861291954, disc_loss = 0.011103291738569944
Trained batch 143 in epoch 4, gen_loss = 0.4021233237451977, disc_loss = 0.01103598135523498
Trained batch 144 in epoch 4, gen_loss = 0.4021218410853682, disc_loss = 0.010979277940852374
Trained batch 145 in epoch 4, gen_loss = 0.40207196078071855, disc_loss = 0.010916603056152593
Trained batch 146 in epoch 4, gen_loss = 0.40264657950725685, disc_loss = 0.010858231214616371
Trained batch 147 in epoch 4, gen_loss = 0.40280576412742203, disc_loss = 0.010809527621982066
Trained batch 148 in epoch 4, gen_loss = 0.40274054432075296, disc_loss = 0.010752169887266502
Trained batch 149 in epoch 4, gen_loss = 0.4023258493343989, disc_loss = 0.01069112501728038
Trained batch 150 in epoch 4, gen_loss = 0.4026599700087743, disc_loss = 0.010633756599345843
Trained batch 151 in epoch 4, gen_loss = 0.4025941230356693, disc_loss = 0.010576990642891216
Trained batch 152 in epoch 4, gen_loss = 0.4024253565501543, disc_loss = 0.0105153994111259
Trained batch 153 in epoch 4, gen_loss = 0.4025010706542374, disc_loss = 0.010464854139302458
Trained batch 154 in epoch 4, gen_loss = 0.40242896829881974, disc_loss = 0.010412071926158763
Trained batch 155 in epoch 4, gen_loss = 0.4031215770504413, disc_loss = 0.010355666343970463
Trained batch 156 in epoch 4, gen_loss = 0.40332665944555, disc_loss = 0.010301477734035083
Trained batch 157 in epoch 4, gen_loss = 0.4030817509451999, disc_loss = 0.010253987191068126
Trained batch 158 in epoch 4, gen_loss = 0.4028775232767909, disc_loss = 0.01020097879197964
Trained batch 159 in epoch 4, gen_loss = 0.4029494432732463, disc_loss = 0.010143630550737725
Trained batch 160 in epoch 4, gen_loss = 0.40279680379429217, disc_loss = 0.010089109747913544
Trained batch 161 in epoch 4, gen_loss = 0.4028796976731147, disc_loss = 0.010037027421568371
Trained batch 162 in epoch 4, gen_loss = 0.4027378398216575, disc_loss = 0.00998171147936098
Trained batch 163 in epoch 4, gen_loss = 0.40227379995148355, disc_loss = 0.009928887176168402
Trained batch 164 in epoch 4, gen_loss = 0.40202836990356444, disc_loss = 0.009879051558108944
Trained batch 165 in epoch 4, gen_loss = 0.4019046397094267, disc_loss = 0.00983261144215084
Trained batch 166 in epoch 4, gen_loss = 0.4022492761026599, disc_loss = 0.009785102340141813
Trained batch 167 in epoch 4, gen_loss = 0.4021126242975394, disc_loss = 0.00973660823711682
Trained batch 168 in epoch 4, gen_loss = 0.40212763713661737, disc_loss = 0.009694969185115494
Trained batch 169 in epoch 4, gen_loss = 0.4020164033945869, disc_loss = 0.009652213585179517
Trained batch 170 in epoch 4, gen_loss = 0.4016459488380722, disc_loss = 0.009603519170348974
Trained batch 171 in epoch 4, gen_loss = 0.40179546679868255, disc_loss = 0.009557144968164002
Trained batch 172 in epoch 4, gen_loss = 0.40148999839159794, disc_loss = 0.009523660364436965
Trained batch 173 in epoch 4, gen_loss = 0.4014391030730872, disc_loss = 0.00948810207807384
Trained batch 174 in epoch 4, gen_loss = 0.40202255368232725, disc_loss = 0.009447538433596492
Trained batch 175 in epoch 4, gen_loss = 0.40195202319459483, disc_loss = 0.009412597632035613
Trained batch 176 in epoch 4, gen_loss = 0.40200096436139554, disc_loss = 0.009387405210379826
Trained batch 177 in epoch 4, gen_loss = 0.4019625036234266, disc_loss = 0.009344545691378749
Trained batch 178 in epoch 4, gen_loss = 0.4019695756821659, disc_loss = 0.009297626273831426
Trained batch 179 in epoch 4, gen_loss = 0.4025202582279841, disc_loss = 0.00927416198861061
Trained batch 180 in epoch 4, gen_loss = 0.40242914452078593, disc_loss = 0.009234191247812622
Trained batch 181 in epoch 4, gen_loss = 0.40248338632531216, disc_loss = 0.009192677505780011
Trained batch 182 in epoch 4, gen_loss = 0.4020677772376055, disc_loss = 0.00915067582811061
Trained batch 183 in epoch 4, gen_loss = 0.4021922460068827, disc_loss = 0.00910977246657358
Trained batch 184 in epoch 4, gen_loss = 0.40242189829413955, disc_loss = 0.009071495821321936
Trained batch 185 in epoch 4, gen_loss = 0.4023606110644597, disc_loss = 0.00903386151811148
Trained batch 186 in epoch 4, gen_loss = 0.40261589779573326, disc_loss = 0.009001932767429015
Trained batch 187 in epoch 4, gen_loss = 0.40269913603650764, disc_loss = 0.008964225562522188
Trained batch 188 in epoch 4, gen_loss = 0.4023687861583851, disc_loss = 0.00892642787509849
Trained batch 189 in epoch 4, gen_loss = 0.40221934506767676, disc_loss = 0.008886468476664864
Trained batch 190 in epoch 4, gen_loss = 0.4023469809774329, disc_loss = 0.00884750421666077
Trained batch 191 in epoch 4, gen_loss = 0.4020883327660461, disc_loss = 0.008811086447773656
Trained batch 192 in epoch 4, gen_loss = 0.40218315146129985, disc_loss = 0.008777046042923946
Trained batch 193 in epoch 4, gen_loss = 0.4020027224857783, disc_loss = 0.008736673241166743
Trained batch 194 in epoch 4, gen_loss = 0.40232519476841655, disc_loss = 0.008700101641424669
Trained batch 195 in epoch 4, gen_loss = 0.40230605584018087, disc_loss = 0.008664936824209931
Trained batch 196 in epoch 4, gen_loss = 0.40212994556741666, disc_loss = 0.008627828762826372
Trained batch 197 in epoch 4, gen_loss = 0.40206566272359906, disc_loss = 0.008595826466758312
Trained batch 198 in epoch 4, gen_loss = 0.40199591241889265, disc_loss = 0.008557893316806692
Trained batch 199 in epoch 4, gen_loss = 0.40228797495365143, disc_loss = 0.008531088150048162
Trained batch 200 in epoch 4, gen_loss = 0.40230696014503936, disc_loss = 0.008495827171597074
Trained batch 201 in epoch 4, gen_loss = 0.4023926054487134, disc_loss = 0.008467185274999829
Trained batch 202 in epoch 4, gen_loss = 0.4023117091268154, disc_loss = 0.008431649096757449
Trained batch 203 in epoch 4, gen_loss = 0.40242399888880115, disc_loss = 0.008396397655494237
Trained batch 204 in epoch 4, gen_loss = 0.40252135294239694, disc_loss = 0.008361266972213165
Trained batch 205 in epoch 4, gen_loss = 0.4021789194310753, disc_loss = 0.008325162769500979
Trained batch 206 in epoch 4, gen_loss = 0.4022429484676048, disc_loss = 0.008291464999986245
Trained batch 207 in epoch 4, gen_loss = 0.40194443011513126, disc_loss = 0.008257142158702034
Trained batch 208 in epoch 4, gen_loss = 0.40178836960541575, disc_loss = 0.008222845094178192
Trained batch 209 in epoch 4, gen_loss = 0.4017353926386152, disc_loss = 0.00818936323852367
Trained batch 210 in epoch 4, gen_loss = 0.4016375033211369, disc_loss = 0.008155455704396635
Trained batch 211 in epoch 4, gen_loss = 0.4015263854613844, disc_loss = 0.008122891879295666
Trained batch 212 in epoch 4, gen_loss = 0.40169392379236896, disc_loss = 0.008093561559309964
Trained batch 213 in epoch 4, gen_loss = 0.4016305096795626, disc_loss = 0.008061963835541837
Trained batch 214 in epoch 4, gen_loss = 0.4016990808553474, disc_loss = 0.008030349925582752
Trained batch 215 in epoch 4, gen_loss = 0.40192083407331397, disc_loss = 0.007999746195478278
Trained batch 216 in epoch 4, gen_loss = 0.40159064064377464, disc_loss = 0.007970343317894462
Trained batch 217 in epoch 4, gen_loss = 0.401526463277843, disc_loss = 0.00794178747049738
Trained batch 218 in epoch 4, gen_loss = 0.40174291476811447, disc_loss = 0.007912498024626121
Trained batch 219 in epoch 4, gen_loss = 0.40191092057661576, disc_loss = 0.007881064494722523
Trained batch 220 in epoch 4, gen_loss = 0.4020383821893062, disc_loss = 0.007850680241890133
Trained batch 221 in epoch 4, gen_loss = 0.4019228911346143, disc_loss = 0.007820264993996889
Trained batch 222 in epoch 4, gen_loss = 0.40194203139955154, disc_loss = 0.007792243927418601
Trained batch 223 in epoch 4, gen_loss = 0.4017425159524594, disc_loss = 0.007763833552027271
Trained batch 224 in epoch 4, gen_loss = 0.4016733729839325, disc_loss = 0.007734209436975005
Trained batch 225 in epoch 4, gen_loss = 0.40172440657573466, disc_loss = 0.007705562334637512
Trained batch 226 in epoch 4, gen_loss = 0.4015273333646127, disc_loss = 0.007678283946455296
Trained batch 227 in epoch 4, gen_loss = 0.40133914625958395, disc_loss = 0.0076503087569890025
Trained batch 228 in epoch 4, gen_loss = 0.4010370145978886, disc_loss = 0.007621302579755297
Trained batch 229 in epoch 4, gen_loss = 0.40124189400154614, disc_loss = 0.007597216598578202
Trained batch 230 in epoch 4, gen_loss = 0.4010262697032004, disc_loss = 0.007573513701423051
Trained batch 231 in epoch 4, gen_loss = 0.4007553721553293, disc_loss = 0.007549026892931955
Trained batch 232 in epoch 4, gen_loss = 0.4007652909714777, disc_loss = 0.007526695051044625
Trained batch 233 in epoch 4, gen_loss = 0.4007418577232931, disc_loss = 0.007504864907515052
Trained batch 234 in epoch 4, gen_loss = 0.4007948526676665, disc_loss = 0.007479872217926969
Trained batch 235 in epoch 4, gen_loss = 0.4008342170361745, disc_loss = 0.007454868511867046
Trained batch 236 in epoch 4, gen_loss = 0.4006376710370623, disc_loss = 0.007428015635559092
Trained batch 237 in epoch 4, gen_loss = 0.4007132396477611, disc_loss = 0.007402430611570608
Trained batch 238 in epoch 4, gen_loss = 0.40073828804443073, disc_loss = 0.007376500920472456
Trained batch 239 in epoch 4, gen_loss = 0.40059356316924094, disc_loss = 0.0073498834872831745
Trained batch 240 in epoch 4, gen_loss = 0.40048603769159913, disc_loss = 0.007327426335324159
Trained batch 241 in epoch 4, gen_loss = 0.4002894047370627, disc_loss = 0.007306306532724599
Trained batch 242 in epoch 4, gen_loss = 0.40015776817200116, disc_loss = 0.007280017960473604
Trained batch 243 in epoch 4, gen_loss = 0.40017964861920624, disc_loss = 0.007259018282400307
Trained batch 244 in epoch 4, gen_loss = 0.3998721794206269, disc_loss = 0.007249248436680634
Trained batch 245 in epoch 4, gen_loss = 0.399790649491597, disc_loss = 0.007229951128214068
Trained batch 246 in epoch 4, gen_loss = 0.4000438898198518, disc_loss = 0.007207871318807984
Trained batch 247 in epoch 4, gen_loss = 0.39981381967663765, disc_loss = 0.007182888538556008
Trained batch 248 in epoch 4, gen_loss = 0.39979295677928084, disc_loss = 0.007158079353136845
Trained batch 249 in epoch 4, gen_loss = 0.39973626816272734, disc_loss = 0.007133564327144995
Trained batch 250 in epoch 4, gen_loss = 0.39975469960159515, disc_loss = 0.007111609960485071
Trained batch 251 in epoch 4, gen_loss = 0.3997678594693305, disc_loss = 0.007087231428447431
Trained batch 252 in epoch 4, gen_loss = 0.39964983880284277, disc_loss = 0.0070628983549784734
Trained batch 253 in epoch 4, gen_loss = 0.3997970593022549, disc_loss = 0.007039045973444416
Trained batch 254 in epoch 4, gen_loss = 0.4001455511532578, disc_loss = 0.007023562409449369
Trained batch 255 in epoch 4, gen_loss = 0.3999447824899107, disc_loss = 0.0070001885990222945
Trained batch 256 in epoch 4, gen_loss = 0.4001573513222112, disc_loss = 0.006978593467044416
Trained batch 257 in epoch 4, gen_loss = 0.4001732753921849, disc_loss = 0.006955961840517833
Trained batch 258 in epoch 4, gen_loss = 0.40016875890691306, disc_loss = 0.006932602569408729
Trained batch 259 in epoch 4, gen_loss = 0.4001626286369104, disc_loss = 0.006911159234005026
Trained batch 260 in epoch 4, gen_loss = 0.4000129336598276, disc_loss = 0.006889377990728637
Trained batch 261 in epoch 4, gen_loss = 0.40009533119110663, disc_loss = 0.006866958041414121
Trained batch 262 in epoch 4, gen_loss = 0.39990399568253143, disc_loss = 0.006844235429435812
Trained batch 263 in epoch 4, gen_loss = 0.39986625652421603, disc_loss = 0.006822776297860511
Trained batch 264 in epoch 4, gen_loss = 0.3998883023576916, disc_loss = 0.006800875216414976
Trained batch 265 in epoch 4, gen_loss = 0.399712210423068, disc_loss = 0.006778163600606227
Trained batch 266 in epoch 4, gen_loss = 0.3997038250112355, disc_loss = 0.006757039016710894
Trained batch 267 in epoch 4, gen_loss = 0.39970367134951834, disc_loss = 0.0067385436831052595
Trained batch 268 in epoch 4, gen_loss = 0.3994696327523228, disc_loss = 0.006717861941833825
Trained batch 269 in epoch 4, gen_loss = 0.3996579451693429, disc_loss = 0.006698687287711504
Trained batch 270 in epoch 4, gen_loss = 0.3999291672697806, disc_loss = 0.006682554883856629
Trained batch 271 in epoch 4, gen_loss = 0.4000673853956601, disc_loss = 0.006664319570143775
Trained batch 272 in epoch 4, gen_loss = 0.40007024501269556, disc_loss = 0.006644743150773871
Trained batch 273 in epoch 4, gen_loss = 0.3999691854645736, disc_loss = 0.0066246023683309094
Trained batch 274 in epoch 4, gen_loss = 0.39994844154878095, disc_loss = 0.006605728972830217
Trained batch 275 in epoch 4, gen_loss = 0.39988034920416016, disc_loss = 0.006587732448099195
Trained batch 276 in epoch 4, gen_loss = 0.399587843069531, disc_loss = 0.00656998505927656
Trained batch 277 in epoch 4, gen_loss = 0.3995926187192793, disc_loss = 0.006550525849653247
Trained batch 278 in epoch 4, gen_loss = 0.39962442064370735, disc_loss = 0.00653495633074226
Trained batch 279 in epoch 4, gen_loss = 0.39971011259726114, disc_loss = 0.00652074198192817
Trained batch 280 in epoch 4, gen_loss = 0.3997222681486734, disc_loss = 0.006501618545507396
Trained batch 281 in epoch 4, gen_loss = 0.3996020175041036, disc_loss = 0.006484501208930032
Trained batch 282 in epoch 4, gen_loss = 0.39949920194309085, disc_loss = 0.006469830992185698
Trained batch 283 in epoch 4, gen_loss = 0.399519124081437, disc_loss = 0.006452883095078786
Trained batch 284 in epoch 4, gen_loss = 0.3994431677617525, disc_loss = 0.006437802209984511
Trained batch 285 in epoch 4, gen_loss = 0.3996461332886369, disc_loss = 0.006422208049586955
Trained batch 286 in epoch 4, gen_loss = 0.3996799543551867, disc_loss = 0.006404364365761457
Trained batch 287 in epoch 4, gen_loss = 0.39994656367020476, disc_loss = 0.006387010189428111
Trained batch 288 in epoch 4, gen_loss = 0.39982228120305546, disc_loss = 0.006368790872219409
Trained batch 289 in epoch 4, gen_loss = 0.4000203552944907, disc_loss = 0.0063520449849953555
Trained batch 290 in epoch 4, gen_loss = 0.40002300188303813, disc_loss = 0.0063347628340525135
Trained batch 291 in epoch 4, gen_loss = 0.3998492120267594, disc_loss = 0.006319437480782005
Trained batch 292 in epoch 4, gen_loss = 0.4000656898721493, disc_loss = 0.006306668874011423
Trained batch 293 in epoch 4, gen_loss = 0.39992847582515406, disc_loss = 0.00629386508090542
Trained batch 294 in epoch 4, gen_loss = 0.3999331221742145, disc_loss = 0.00627609762477578
Trained batch 295 in epoch 4, gen_loss = 0.3998955726824902, disc_loss = 0.006259301072261862
Trained batch 296 in epoch 4, gen_loss = 0.3997526187888701, disc_loss = 0.006241212531756485
Trained batch 297 in epoch 4, gen_loss = 0.39949612249463995, disc_loss = 0.006224533879931004
Trained batch 298 in epoch 4, gen_loss = 0.39941410246900094, disc_loss = 0.006206560898050479
Trained batch 299 in epoch 4, gen_loss = 0.39951891799767814, disc_loss = 0.006192682412802242
Trained batch 300 in epoch 4, gen_loss = 0.39962707009426385, disc_loss = 0.006180143527001254
Trained batch 301 in epoch 4, gen_loss = 0.3998803267415786, disc_loss = 0.006164541973197364
Trained batch 302 in epoch 4, gen_loss = 0.39985318467168524, disc_loss = 0.006147417771013718
Trained batch 303 in epoch 4, gen_loss = 0.39968337628402206, disc_loss = 0.006130793852016244
Trained batch 304 in epoch 4, gen_loss = 0.39946108509282596, disc_loss = 0.006114285672656031
Trained batch 305 in epoch 4, gen_loss = 0.39954087966018254, disc_loss = 0.006098303665578962
Trained batch 306 in epoch 4, gen_loss = 0.39939678783137167, disc_loss = 0.0060827745674921245
Trained batch 307 in epoch 4, gen_loss = 0.3992868194525892, disc_loss = 0.006065940362319664
Trained batch 308 in epoch 4, gen_loss = 0.3992473365419505, disc_loss = 0.006050215239491928
Trained batch 309 in epoch 4, gen_loss = 0.3994042802241541, disc_loss = 0.006034282202111377
Trained batch 310 in epoch 4, gen_loss = 0.3994037658455288, disc_loss = 0.006018910543555903
Trained batch 311 in epoch 4, gen_loss = 0.399419087343491, disc_loss = 0.006003503952226124
Trained batch 312 in epoch 4, gen_loss = 0.3995301191227886, disc_loss = 0.005989250929701847
Trained batch 313 in epoch 4, gen_loss = 0.39958702502356974, disc_loss = 0.0059739794981796416
Trained batch 314 in epoch 4, gen_loss = 0.39939372927423505, disc_loss = 0.005959646747861471
Trained batch 315 in epoch 4, gen_loss = 0.39956858886193625, disc_loss = 0.00595151848503082
Trained batch 316 in epoch 4, gen_loss = 0.3997280148301591, disc_loss = 0.005939740012252956
Trained batch 317 in epoch 4, gen_loss = 0.39959453833553027, disc_loss = 0.005927532005238013
Trained batch 318 in epoch 4, gen_loss = 0.39957627271036367, disc_loss = 0.005912436944210674
Trained batch 319 in epoch 4, gen_loss = 0.3999455239623785, disc_loss = 0.0059009783562942175
Trained batch 320 in epoch 4, gen_loss = 0.3997519962327131, disc_loss = 0.005886772229347807
Trained batch 321 in epoch 4, gen_loss = 0.39999796042901387, disc_loss = 0.00587550843725999
Trained batch 322 in epoch 4, gen_loss = 0.4001489663640781, disc_loss = 0.005863312069591908
Trained batch 323 in epoch 4, gen_loss = 0.4000814740120629, disc_loss = 0.00584974730844368
Trained batch 324 in epoch 4, gen_loss = 0.4003011279839736, disc_loss = 0.005837425144317632
Trained batch 325 in epoch 4, gen_loss = 0.40040897006637477, disc_loss = 0.0058231371318481495
Trained batch 326 in epoch 4, gen_loss = 0.40043872667744257, disc_loss = 0.005808270410513534
Trained batch 327 in epoch 4, gen_loss = 0.4002743502397363, disc_loss = 0.005793428835182212
Trained batch 328 in epoch 4, gen_loss = 0.40057248040173193, disc_loss = 0.005786200160320599
Trained batch 329 in epoch 4, gen_loss = 0.40068196907187953, disc_loss = 0.005771944147118396
Trained batch 330 in epoch 4, gen_loss = 0.4006866059094397, disc_loss = 0.00575780787830891
Trained batch 331 in epoch 4, gen_loss = 0.40058968476502294, disc_loss = 0.005743146803705527
Trained batch 332 in epoch 4, gen_loss = 0.40066169448443, disc_loss = 0.005729563515206838
Trained batch 333 in epoch 4, gen_loss = 0.400752573402342, disc_loss = 0.005717659064653625
Trained batch 334 in epoch 4, gen_loss = 0.40098463608257806, disc_loss = 0.005703754126921352
Trained batch 335 in epoch 4, gen_loss = 0.40109058354227317, disc_loss = 0.005690086716986982
Trained batch 336 in epoch 4, gen_loss = 0.4009354416977404, disc_loss = 0.005679232375979567
Trained batch 337 in epoch 4, gen_loss = 0.400935405369341, disc_loss = 0.005674258932042812
Trained batch 338 in epoch 4, gen_loss = 0.4009467530391209, disc_loss = 0.005665233943392976
Trained batch 339 in epoch 4, gen_loss = 0.40095724393339716, disc_loss = 0.005651485742761425
Trained batch 340 in epoch 4, gen_loss = 0.40095321226679337, disc_loss = 0.005638253161051417
Trained batch 341 in epoch 4, gen_loss = 0.4008586303881037, disc_loss = 0.005624997979118516
Trained batch 342 in epoch 4, gen_loss = 0.40087658888049443, disc_loss = 0.005611472987975795
Trained batch 343 in epoch 4, gen_loss = 0.400744765737029, disc_loss = 0.005600615665296277
Trained batch 344 in epoch 4, gen_loss = 0.400714636799218, disc_loss = 0.005591043187609023
Trained batch 345 in epoch 4, gen_loss = 0.4008138127237386, disc_loss = 0.005578323886655755
Trained batch 346 in epoch 4, gen_loss = 0.40073605109360444, disc_loss = 0.005565164584072001
Trained batch 347 in epoch 4, gen_loss = 0.40051827631120024, disc_loss = 0.005553090842688274
Trained batch 348 in epoch 4, gen_loss = 0.40069799684521806, disc_loss = 0.005546359945906534
Trained batch 349 in epoch 4, gen_loss = 0.4006230455636978, disc_loss = 0.0055373141683438525
Trained batch 350 in epoch 4, gen_loss = 0.4007096002753983, disc_loss = 0.0055247756104950824
Trained batch 351 in epoch 4, gen_loss = 0.40060807146470656, disc_loss = 0.005513830547153537
Trained batch 352 in epoch 4, gen_loss = 0.40045139261075524, disc_loss = 0.005502423684596857
Trained batch 353 in epoch 4, gen_loss = 0.4002989818484096, disc_loss = 0.005490635528451485
Trained batch 354 in epoch 4, gen_loss = 0.4004044682207242, disc_loss = 0.005479871191274585
Trained batch 355 in epoch 4, gen_loss = 0.400311567307858, disc_loss = 0.005469963369986534
Trained batch 356 in epoch 4, gen_loss = 0.40029966230152036, disc_loss = 0.005458338582837375
Trained batch 357 in epoch 4, gen_loss = 0.40056042431453087, disc_loss = 0.005446597997342398
Trained batch 358 in epoch 4, gen_loss = 0.4005396376081164, disc_loss = 0.00543571305140194
Trained batch 359 in epoch 4, gen_loss = 0.40046949278977184, disc_loss = 0.005426467428171438
Trained batch 360 in epoch 4, gen_loss = 0.40057298896055143, disc_loss = 0.005417748722808894
Trained batch 361 in epoch 4, gen_loss = 0.40062567262359744, disc_loss = 0.00540770002231079
Trained batch 362 in epoch 4, gen_loss = 0.40044309038761233, disc_loss = 0.005399523547769732
Trained batch 363 in epoch 4, gen_loss = 0.40043926386387796, disc_loss = 0.005388326905661385
Trained batch 364 in epoch 4, gen_loss = 0.40035343668232226, disc_loss = 0.005376416031264841
Trained batch 365 in epoch 4, gen_loss = 0.40025705954090496, disc_loss = 0.005364869121504093
Trained batch 366 in epoch 4, gen_loss = 0.4002818950028121, disc_loss = 0.005359606333463948
Trained batch 367 in epoch 4, gen_loss = 0.40029411042190116, disc_loss = 0.005352949772476795
Trained batch 368 in epoch 4, gen_loss = 0.40045126723403207, disc_loss = 0.00534316899648017
Trained batch 369 in epoch 4, gen_loss = 0.40043761399952144, disc_loss = 0.005332562514121418
Trained batch 370 in epoch 4, gen_loss = 0.40036869852369367, disc_loss = 0.005321152154149141
Trained batch 371 in epoch 4, gen_loss = 0.400333345577281, disc_loss = 0.005309942532524777
Trained batch 372 in epoch 4, gen_loss = 0.40030339224408845, disc_loss = 0.005298817424314601
Trained batch 373 in epoch 4, gen_loss = 0.40029530840761524, disc_loss = 0.005286650802973748
Trained batch 374 in epoch 4, gen_loss = 0.4002053688367208, disc_loss = 0.0052769439544839165
Trained batch 375 in epoch 4, gen_loss = 0.40007040570390984, disc_loss = 0.005267335901543389
Trained batch 376 in epoch 4, gen_loss = 0.4000660834799395, disc_loss = 0.005257421875507163
Trained batch 377 in epoch 4, gen_loss = 0.39993556845125067, disc_loss = 0.005250582018917644
Trained batch 378 in epoch 4, gen_loss = 0.39988320774956554, disc_loss = 0.005243071613711671
Trained batch 379 in epoch 4, gen_loss = 0.40006846158128034, disc_loss = 0.005234484820118125
Trained batch 380 in epoch 4, gen_loss = 0.4001555818272388, disc_loss = 0.005226418747061868
Trained batch 381 in epoch 4, gen_loss = 0.39993217985355417, disc_loss = 0.005218937736600687
Trained batch 382 in epoch 4, gen_loss = 0.40004621745712143, disc_loss = 0.0052109206876201995
Trained batch 383 in epoch 4, gen_loss = 0.3999508287912856, disc_loss = 0.0051996379070260446
Trained batch 384 in epoch 4, gen_loss = 0.39998858656202047, disc_loss = 0.005189846573675705
Trained batch 385 in epoch 4, gen_loss = 0.40002064213851574, disc_loss = 0.005179767100287631
Trained batch 386 in epoch 4, gen_loss = 0.3999798923961876, disc_loss = 0.0051698637046329
Trained batch 387 in epoch 4, gen_loss = 0.40007288131824476, disc_loss = 0.005159857914814265
Trained batch 388 in epoch 4, gen_loss = 0.399853376772226, disc_loss = 0.00515117875155502
Trained batch 389 in epoch 4, gen_loss = 0.399696597074851, disc_loss = 0.005140813468740537
Trained batch 390 in epoch 4, gen_loss = 0.3997221545642599, disc_loss = 0.005131297182682378
Trained batch 391 in epoch 4, gen_loss = 0.3996009912569912, disc_loss = 0.00512130002666987
Trained batch 392 in epoch 4, gen_loss = 0.39942993068209737, disc_loss = 0.005111996572033405
Trained batch 393 in epoch 4, gen_loss = 0.3993054381784449, disc_loss = 0.005102714733161543
Trained batch 394 in epoch 4, gen_loss = 0.3992523617382291, disc_loss = 0.005097445704431945
Trained batch 395 in epoch 4, gen_loss = 0.39916282621296967, disc_loss = 0.005088412631514736
Trained batch 396 in epoch 4, gen_loss = 0.3991911979556384, disc_loss = 0.005079153118777073
Trained batch 397 in epoch 4, gen_loss = 0.39912536066381177, disc_loss = 0.005072980042167907
Trained batch 398 in epoch 4, gen_loss = 0.3991244253060573, disc_loss = 0.0050642514702885
Trained batch 399 in epoch 4, gen_loss = 0.3991484398394823, disc_loss = 0.005054870894527994
Trained batch 400 in epoch 4, gen_loss = 0.39911176862562087, disc_loss = 0.005045530357818465
Trained batch 401 in epoch 4, gen_loss = 0.39906961615405867, disc_loss = 0.005037549063876105
Trained batch 402 in epoch 4, gen_loss = 0.39920874794127037, disc_loss = 0.005030073940455821
Trained batch 403 in epoch 4, gen_loss = 0.3991314065043289, disc_loss = 0.005026122060371563
Trained batch 404 in epoch 4, gen_loss = 0.39922984676596557, disc_loss = 0.005018524034236224
Trained batch 405 in epoch 4, gen_loss = 0.3991707052503313, disc_loss = 0.005010571613795413
Trained batch 406 in epoch 4, gen_loss = 0.39902637939195373, disc_loss = 0.005002382715662864
Trained batch 407 in epoch 4, gen_loss = 0.39910393222874285, disc_loss = 0.004994812846930204
Trained batch 408 in epoch 4, gen_loss = 0.399240302718939, disc_loss = 0.004986102730069938
Trained batch 409 in epoch 4, gen_loss = 0.39901618863024363, disc_loss = 0.00497700116262067
Trained batch 410 in epoch 4, gen_loss = 0.3990085879091509, disc_loss = 0.004971397887981087
Trained batch 411 in epoch 4, gen_loss = 0.3991174836760586, disc_loss = 0.004964544061736375
Trained batch 412 in epoch 4, gen_loss = 0.39888894038396655, disc_loss = 0.004958939036415308
Trained batch 413 in epoch 4, gen_loss = 0.3988626878618618, disc_loss = 0.004955819357188806
Trained batch 414 in epoch 4, gen_loss = 0.39877470358308537, disc_loss = 0.004949232374587242
Trained batch 415 in epoch 4, gen_loss = 0.3986806830104727, disc_loss = 0.004943749325320823
Trained batch 416 in epoch 4, gen_loss = 0.39872312681566324, disc_loss = 0.004938261910917894
Trained batch 417 in epoch 4, gen_loss = 0.39872155648669555, disc_loss = 0.004930239374098773
Trained batch 418 in epoch 4, gen_loss = 0.39879846921399553, disc_loss = 0.0049221361153770175
Trained batch 419 in epoch 4, gen_loss = 0.3988822884502865, disc_loss = 0.004915492650165799
Trained batch 420 in epoch 4, gen_loss = 0.3989071567806099, disc_loss = 0.004909113397923544
Trained batch 421 in epoch 4, gen_loss = 0.3988973205264711, disc_loss = 0.0049083308014418415
Trained batch 422 in epoch 4, gen_loss = 0.3986954047888447, disc_loss = 0.004899958937635852
Trained batch 423 in epoch 4, gen_loss = 0.39882569942834245, disc_loss = 0.00489378728511752
Trained batch 424 in epoch 4, gen_loss = 0.3987884796366972, disc_loss = 0.004893150718280059
Trained batch 425 in epoch 4, gen_loss = 0.39882790083896386, disc_loss = 0.004904319557083657
Trained batch 426 in epoch 4, gen_loss = 0.3989385591876591, disc_loss = 0.004904468100794986
Trained batch 427 in epoch 4, gen_loss = 0.3988841834051587, disc_loss = 0.004897238092364256
Trained batch 428 in epoch 4, gen_loss = 0.3988905294097109, disc_loss = 0.004898200638425083
Trained batch 429 in epoch 4, gen_loss = 0.39890636427457943, disc_loss = 0.004897231058228414
Trained batch 430 in epoch 4, gen_loss = 0.3988071442203566, disc_loss = 0.004891238585622276
Trained batch 431 in epoch 4, gen_loss = 0.39902472289072144, disc_loss = 0.0049226408394773625
Trained batch 432 in epoch 4, gen_loss = 0.399093985282246, disc_loss = 0.004941515355396749
Trained batch 433 in epoch 4, gen_loss = 0.39913663103283825, disc_loss = 0.004939672530442047
Trained batch 434 in epoch 4, gen_loss = 0.39917323781155994, disc_loss = 0.004935614182078547
Trained batch 435 in epoch 4, gen_loss = 0.3991484851191897, disc_loss = 0.00493065336181936
Trained batch 436 in epoch 4, gen_loss = 0.3992220954436732, disc_loss = 0.004926438835232137
Trained batch 437 in epoch 4, gen_loss = 0.3992545196454819, disc_loss = 0.004925083930095973
Trained batch 438 in epoch 4, gen_loss = 0.3993815118468161, disc_loss = 0.004934040112219378
Trained batch 439 in epoch 4, gen_loss = 0.39940358393571596, disc_loss = 0.00494776969876098
Trained batch 440 in epoch 4, gen_loss = 0.3996763155709048, disc_loss = 0.004957724332781994
Trained batch 441 in epoch 4, gen_loss = 0.3996469689305551, disc_loss = 0.004959959056116725
Trained batch 442 in epoch 4, gen_loss = 0.3996572941878041, disc_loss = 0.004957049318513587
Trained batch 443 in epoch 4, gen_loss = 0.3995703474224151, disc_loss = 0.004951478586991544
Trained batch 444 in epoch 4, gen_loss = 0.39971663824627907, disc_loss = 0.004968147608451545
Trained batch 445 in epoch 4, gen_loss = 0.39974677682992055, disc_loss = 0.0049671900733749925
Trained batch 446 in epoch 4, gen_loss = 0.3997665311666143, disc_loss = 0.004959946548539137
Trained batch 447 in epoch 4, gen_loss = 0.3999374042531209, disc_loss = 0.004963763052208898
Trained batch 448 in epoch 4, gen_loss = 0.40004902885592064, disc_loss = 0.0050121273304582605
Trained batch 449 in epoch 4, gen_loss = 0.39983724580870733, disc_loss = 0.005097063297871501
Trained batch 450 in epoch 4, gen_loss = 0.3999300839631362, disc_loss = 0.005329912406817789
Trained batch 451 in epoch 4, gen_loss = 0.3999560598646645, disc_loss = 0.005518777343594939
Trained batch 452 in epoch 4, gen_loss = 0.400047518888583, disc_loss = 0.005548424589361329
Trained batch 453 in epoch 4, gen_loss = 0.40026161022123263, disc_loss = 0.005611958874785444
Trained batch 454 in epoch 4, gen_loss = 0.40042434537803734, disc_loss = 0.005624841796592451
Trained batch 455 in epoch 4, gen_loss = 0.4004579133501178, disc_loss = 0.005660911658707303
Trained batch 456 in epoch 4, gen_loss = 0.400506083892263, disc_loss = 0.005671250489458882
Trained batch 457 in epoch 4, gen_loss = 0.4006065946869454, disc_loss = 0.005671755414035204
Trained batch 458 in epoch 4, gen_loss = 0.400468903754012, disc_loss = 0.005704780435138879
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.391872376203537, disc_loss = 0.026270832866430283
Trained batch 1 in epoch 5, gen_loss = 0.4204198867082596, disc_loss = 0.042294375598430634
Trained batch 2 in epoch 5, gen_loss = 0.43443843722343445, disc_loss = 0.03455457153419653
Trained batch 3 in epoch 5, gen_loss = 0.433749295771122, disc_loss = 0.02957584452815354
Trained batch 4 in epoch 5, gen_loss = 0.42433112263679507, disc_loss = 0.024791240971535445
Trained batch 5 in epoch 5, gen_loss = 0.4149080216884613, disc_loss = 0.0226420930121094
Trained batch 6 in epoch 5, gen_loss = 0.41150362151009695, disc_loss = 0.020467833748885562
Trained batch 7 in epoch 5, gen_loss = 0.4164790026843548, disc_loss = 0.01850081729935482
Trained batch 8 in epoch 5, gen_loss = 0.40960225462913513, disc_loss = 0.016779923423503835
Trained batch 9 in epoch 5, gen_loss = 0.40727064311504363, disc_loss = 0.015320549183525146
Trained batch 10 in epoch 5, gen_loss = 0.40772818706252356, disc_loss = 0.01467972945167937
Trained batch 11 in epoch 5, gen_loss = 0.40609778215487796, disc_loss = 0.014908312684080252
Trained batch 12 in epoch 5, gen_loss = 0.4054473340511322, disc_loss = 0.014108411914024215
Trained batch 13 in epoch 5, gen_loss = 0.4101504938943045, disc_loss = 0.014854817734366017
Trained batch 14 in epoch 5, gen_loss = 0.4110938588778178, disc_loss = 0.01431316852880021
Trained batch 15 in epoch 5, gen_loss = 0.40597983077168465, disc_loss = 0.014677780636702664
Trained batch 16 in epoch 5, gen_loss = 0.4092583130387699, disc_loss = 0.015085665248882245
Trained batch 17 in epoch 5, gen_loss = 0.4095856381787194, disc_loss = 0.014754814884832336
Trained batch 18 in epoch 5, gen_loss = 0.409119576215744, disc_loss = 0.014963076952354689
Trained batch 19 in epoch 5, gen_loss = 0.41186829209327697, disc_loss = 0.014577472500968724
Trained batch 20 in epoch 5, gen_loss = 0.41546655410812017, disc_loss = 0.014072834525168651
Trained batch 21 in epoch 5, gen_loss = 0.41524783860553394, disc_loss = 0.015857190877961166
Trained batch 22 in epoch 5, gen_loss = 0.41180014999016473, disc_loss = 0.02161271445979567
Trained batch 23 in epoch 5, gen_loss = 0.4143865096072356, disc_loss = 0.024065809916161623
Trained batch 24 in epoch 5, gen_loss = 0.41630560517311094, disc_loss = 0.02354337756522
Trained batch 25 in epoch 5, gen_loss = 0.4136085705115245, disc_loss = 0.022951953838436075
Trained batch 26 in epoch 5, gen_loss = 0.4137133801424945, disc_loss = 0.022840369294432027
Trained batch 27 in epoch 5, gen_loss = 0.41145667327301844, disc_loss = 0.022681514408239827
Trained batch 28 in epoch 5, gen_loss = 0.4123740699784509, disc_loss = 0.022286840626199185
Trained batch 29 in epoch 5, gen_loss = 0.4105980197588603, disc_loss = 0.0219054403482005
Trained batch 30 in epoch 5, gen_loss = 0.40950164871831096, disc_loss = 0.021612124885582635
Trained batch 31 in epoch 5, gen_loss = 0.40823765099048615, disc_loss = 0.021764793615147937
Trained batch 32 in epoch 5, gen_loss = 0.4076616113836115, disc_loss = 0.02130842483320245
Trained batch 33 in epoch 5, gen_loss = 0.40688445024630604, disc_loss = 0.021439933142734364
Trained batch 34 in epoch 5, gen_loss = 0.40676923394203185, disc_loss = 0.0215267743183566
Trained batch 35 in epoch 5, gen_loss = 0.4065853911969397, disc_loss = 0.021067526508381382
Trained batch 36 in epoch 5, gen_loss = 0.40796616995656815, disc_loss = 0.020647775715317677
Trained batch 37 in epoch 5, gen_loss = 0.40830126953752416, disc_loss = 0.020450824853277913
Trained batch 38 in epoch 5, gen_loss = 0.40702196879264635, disc_loss = 0.021077267234571852
Trained batch 39 in epoch 5, gen_loss = 0.40906642973423, disc_loss = 0.020865875022718684
Trained batch 40 in epoch 5, gen_loss = 0.4119105847870431, disc_loss = 0.02175942409170292
Trained batch 41 in epoch 5, gen_loss = 0.41262112699803855, disc_loss = 0.02166492204248373
Trained batch 42 in epoch 5, gen_loss = 0.41211724835772845, disc_loss = 0.022845129942694723
Trained batch 43 in epoch 5, gen_loss = 0.41271334276957944, disc_loss = 0.024497260556513953
Trained batch 44 in epoch 5, gen_loss = 0.41231795019573636, disc_loss = 0.025550527503300044
Trained batch 45 in epoch 5, gen_loss = 0.411777521605077, disc_loss = 0.025484909794455314
Trained batch 46 in epoch 5, gen_loss = 0.41253952206449307, disc_loss = 0.025227413775320066
Trained batch 47 in epoch 5, gen_loss = 0.4126310770710309, disc_loss = 0.024929766780890834
Trained batch 48 in epoch 5, gen_loss = 0.413243475008984, disc_loss = 0.024616141599241873
Trained batch 49 in epoch 5, gen_loss = 0.4127413058280945, disc_loss = 0.024391400371678175
Trained batch 50 in epoch 5, gen_loss = 0.4110004890198801, disc_loss = 0.024269252727903864
Trained batch 51 in epoch 5, gen_loss = 0.4105014428496361, disc_loss = 0.02391360037906382
Trained batch 52 in epoch 5, gen_loss = 0.410522332168975, disc_loss = 0.02427074766963861
Trained batch 53 in epoch 5, gen_loss = 0.4094849212302102, disc_loss = 0.0291013304118274
Trained batch 54 in epoch 5, gen_loss = 0.40985383933240715, disc_loss = 0.034374200252138755
Trained batch 55 in epoch 5, gen_loss = 0.4089299328625202, disc_loss = 0.03429931598865161
Trained batch 56 in epoch 5, gen_loss = 0.40847673593905937, disc_loss = 0.03465689376012929
Trained batch 57 in epoch 5, gen_loss = 0.40848769658598405, disc_loss = 0.034350372116274105
Trained batch 58 in epoch 5, gen_loss = 0.409204718420061, disc_loss = 0.033885450358897194
Trained batch 59 in epoch 5, gen_loss = 0.409251876672109, disc_loss = 0.03342020243483906
Trained batch 60 in epoch 5, gen_loss = 0.4085470584572339, disc_loss = 0.03297138567937569
Trained batch 61 in epoch 5, gen_loss = 0.4077453459462812, disc_loss = 0.03248600400758967
Trained batch 62 in epoch 5, gen_loss = 0.40806087141945246, disc_loss = 0.032066752908692236
Trained batch 63 in epoch 5, gen_loss = 0.40803137281909585, disc_loss = 0.03164289852065849
Trained batch 64 in epoch 5, gen_loss = 0.40822242269149195, disc_loss = 0.031205733983705825
Trained batch 65 in epoch 5, gen_loss = 0.4080765134457386, disc_loss = 0.030775452261988186
Trained batch 66 in epoch 5, gen_loss = 0.4093056725921915, disc_loss = 0.030397979754593168
Trained batch 67 in epoch 5, gen_loss = 0.4094100292114651, disc_loss = 0.03001670552047846
Trained batch 68 in epoch 5, gen_loss = 0.40915088074794714, disc_loss = 0.029632476536368114
Trained batch 69 in epoch 5, gen_loss = 0.4093264315809522, disc_loss = 0.029241834035409347
Trained batch 70 in epoch 5, gen_loss = 0.40871773891046015, disc_loss = 0.02893376803602761
Trained batch 71 in epoch 5, gen_loss = 0.4089109351237615, disc_loss = 0.028651699469062604
Trained batch 72 in epoch 5, gen_loss = 0.40951368988376774, disc_loss = 0.028322465188342007
Trained batch 73 in epoch 5, gen_loss = 0.40904504181565465, disc_loss = 0.027973132258331455
Trained batch 74 in epoch 5, gen_loss = 0.4088585090637207, disc_loss = 0.027633479746679464
Trained batch 75 in epoch 5, gen_loss = 0.40938717009205566, disc_loss = 0.02735428075845304
Trained batch 76 in epoch 5, gen_loss = 0.4092775672287136, disc_loss = 0.027071349842885097
Trained batch 77 in epoch 5, gen_loss = 0.4089517287718944, disc_loss = 0.026802964389133148
Trained batch 78 in epoch 5, gen_loss = 0.40877455887915215, disc_loss = 0.026537761050924848
Trained batch 79 in epoch 5, gen_loss = 0.4089761275798082, disc_loss = 0.026233983907150104
Trained batch 80 in epoch 5, gen_loss = 0.4089816415015562, disc_loss = 0.025931651163616298
Trained batch 81 in epoch 5, gen_loss = 0.40844413601770635, disc_loss = 0.02564286256901829
Trained batch 82 in epoch 5, gen_loss = 0.408710301640522, disc_loss = 0.025406485285991466
Trained batch 83 in epoch 5, gen_loss = 0.40816296495142435, disc_loss = 0.02519746617846457
Trained batch 84 in epoch 5, gen_loss = 0.4085519475095412, disc_loss = 0.024962320493753343
Trained batch 85 in epoch 5, gen_loss = 0.4081717989472456, disc_loss = 0.024688283812666183
Trained batch 86 in epoch 5, gen_loss = 0.4070194236848546, disc_loss = 0.024453508600742482
Trained batch 87 in epoch 5, gen_loss = 0.40667377750981937, disc_loss = 0.02420405467009087
Trained batch 88 in epoch 5, gen_loss = 0.4066356196162406, disc_loss = 0.023964309314098417
Trained batch 89 in epoch 5, gen_loss = 0.4064091606272591, disc_loss = 0.023728891433630554
Trained batch 90 in epoch 5, gen_loss = 0.40653591529353633, disc_loss = 0.02348908120996554
Trained batch 91 in epoch 5, gen_loss = 0.40681523311397305, disc_loss = 0.02324977224065072
Trained batch 92 in epoch 5, gen_loss = 0.4067015468433339, disc_loss = 0.023019237611542946
Trained batch 93 in epoch 5, gen_loss = 0.40619448302908145, disc_loss = 0.022816679636115566
Trained batch 94 in epoch 5, gen_loss = 0.4060254294621317, disc_loss = 0.02259456654520411
Trained batch 95 in epoch 5, gen_loss = 0.406397716452678, disc_loss = 0.022378425765055
Trained batch 96 in epoch 5, gen_loss = 0.4060450537303059, disc_loss = 0.02217501816075756
Trained batch 97 in epoch 5, gen_loss = 0.40580091610246777, disc_loss = 0.02197115034297375
Trained batch 98 in epoch 5, gen_loss = 0.4053296594306676, disc_loss = 0.021758537787139754
Trained batch 99 in epoch 5, gen_loss = 0.4050720515847206, disc_loss = 0.021565562710748054
Trained batch 100 in epoch 5, gen_loss = 0.4049982106921696, disc_loss = 0.02136673857423357
Trained batch 101 in epoch 5, gen_loss = 0.405360328800538, disc_loss = 0.021187070296625334
Trained batch 102 in epoch 5, gen_loss = 0.40546151098695776, disc_loss = 0.021001697134212998
Trained batch 103 in epoch 5, gen_loss = 0.4051778603058595, disc_loss = 0.020813795620947182
Trained batch 104 in epoch 5, gen_loss = 0.40506442870412557, disc_loss = 0.02062911891234329
Trained batch 105 in epoch 5, gen_loss = 0.4047857882841578, disc_loss = 0.02044691377317199
Trained batch 106 in epoch 5, gen_loss = 0.404627419242235, disc_loss = 0.020265807690877886
Trained batch 107 in epoch 5, gen_loss = 0.4046231088814912, disc_loss = 0.020093601630866976
Trained batch 108 in epoch 5, gen_loss = 0.40453300481542537, disc_loss = 0.019920981500336235
Trained batch 109 in epoch 5, gen_loss = 0.40395861999555066, disc_loss = 0.01975066528327509
Trained batch 110 in epoch 5, gen_loss = 0.40343003068958316, disc_loss = 0.019585625900412903
Trained batch 111 in epoch 5, gen_loss = 0.403409870075328, disc_loss = 0.01943048812401165
Trained batch 112 in epoch 5, gen_loss = 0.4031701401799126, disc_loss = 0.01927868092063798
Trained batch 113 in epoch 5, gen_loss = 0.40272141234916553, disc_loss = 0.019118634601462667
Trained batch 114 in epoch 5, gen_loss = 0.40267470038455466, disc_loss = 0.01896144080168122
Trained batch 115 in epoch 5, gen_loss = 0.40236246406004345, disc_loss = 0.018805614139198262
Trained batch 116 in epoch 5, gen_loss = 0.40213374678905195, disc_loss = 0.018667825430524178
Trained batch 117 in epoch 5, gen_loss = 0.401579364123991, disc_loss = 0.018518924948431836
Trained batch 118 in epoch 5, gen_loss = 0.4012821321727849, disc_loss = 0.018379966345392636
Trained batch 119 in epoch 5, gen_loss = 0.4012976087629795, disc_loss = 0.018239693408152863
Trained batch 120 in epoch 5, gen_loss = 0.40093386936778863, disc_loss = 0.0180965066124485
Trained batch 121 in epoch 5, gen_loss = 0.4005338715725258, disc_loss = 0.017959368989142573
Trained batch 122 in epoch 5, gen_loss = 0.40066692548069527, disc_loss = 0.017830694432661876
Trained batch 123 in epoch 5, gen_loss = 0.4010233975225879, disc_loss = 0.01770055956055125
Trained batch 124 in epoch 5, gen_loss = 0.40122311282157896, disc_loss = 0.017579283175524325
Trained batch 125 in epoch 5, gen_loss = 0.4014005966129757, disc_loss = 0.017460658497247282
Trained batch 126 in epoch 5, gen_loss = 0.4007313863968286, disc_loss = 0.017337658931592875
Trained batch 127 in epoch 5, gen_loss = 0.40068685566075146, disc_loss = 0.017220022911260457
Trained batch 128 in epoch 5, gen_loss = 0.40041924423949665, disc_loss = 0.01711040491359164
Trained batch 129 in epoch 5, gen_loss = 0.40023003954153796, disc_loss = 0.016988059100605406
Trained batch 130 in epoch 5, gen_loss = 0.40019678114024737, disc_loss = 0.016867207124640893
Trained batch 131 in epoch 5, gen_loss = 0.40008824702465173, disc_loss = 0.016751275960070252
Trained batch 132 in epoch 5, gen_loss = 0.40004122436494755, disc_loss = 0.016640052799384034
Trained batch 133 in epoch 5, gen_loss = 0.3994440907862649, disc_loss = 0.016547029453534774
Trained batch 134 in epoch 5, gen_loss = 0.39950666471763896, disc_loss = 0.016447485750109923
Trained batch 135 in epoch 5, gen_loss = 0.39927219972014427, disc_loss = 0.0163488543488818
Trained batch 136 in epoch 5, gen_loss = 0.3994649698699478, disc_loss = 0.01625596854052282
Trained batch 137 in epoch 5, gen_loss = 0.3996015445909638, disc_loss = 0.01615188906240898
Trained batch 138 in epoch 5, gen_loss = 0.39975531753018606, disc_loss = 0.01604958304343075
Trained batch 139 in epoch 5, gen_loss = 0.3996014967560768, disc_loss = 0.015951120892922128
Trained batch 140 in epoch 5, gen_loss = 0.3993869309729718, disc_loss = 0.015858742421251848
Trained batch 141 in epoch 5, gen_loss = 0.39923688097738885, disc_loss = 0.015761108812794064
Trained batch 142 in epoch 5, gen_loss = 0.39927599230012695, disc_loss = 0.01567343227244536
Trained batch 143 in epoch 5, gen_loss = 0.39900704763001865, disc_loss = 0.015589727503942817
Trained batch 144 in epoch 5, gen_loss = 0.3990594929662244, disc_loss = 0.015546268302995455
Trained batch 145 in epoch 5, gen_loss = 0.39936543123362817, disc_loss = 0.01578401246112899
Trained batch 146 in epoch 5, gen_loss = 0.4001602644012088, disc_loss = 0.015840046919904472
Trained batch 147 in epoch 5, gen_loss = 0.40059277556232503, disc_loss = 0.015780040737464897
Trained batch 148 in epoch 5, gen_loss = 0.40018669430841536, disc_loss = 0.016068124276001457
Trained batch 149 in epoch 5, gen_loss = 0.4009850052992503, disc_loss = 0.017166901672802246
Trained batch 150 in epoch 5, gen_loss = 0.4013374603742006, disc_loss = 0.017181122534837424
Trained batch 151 in epoch 5, gen_loss = 0.4012047121007192, disc_loss = 0.017129556577282
Trained batch 152 in epoch 5, gen_loss = 0.40116527773975547, disc_loss = 0.017376484539210674
Trained batch 153 in epoch 5, gen_loss = 0.4013508562143747, disc_loss = 0.017302472586970315
Trained batch 154 in epoch 5, gen_loss = 0.40153452600202255, disc_loss = 0.01724391395879549
Trained batch 155 in epoch 5, gen_loss = 0.4013769762256207, disc_loss = 0.017222047689033505
Trained batch 156 in epoch 5, gen_loss = 0.4010625339237748, disc_loss = 0.01726479002735785
Trained batch 157 in epoch 5, gen_loss = 0.4008481096995028, disc_loss = 0.017248247827836488
Trained batch 158 in epoch 5, gen_loss = 0.4006824995736656, disc_loss = 0.017252022758896503
Trained batch 159 in epoch 5, gen_loss = 0.40011859592050314, disc_loss = 0.01754206136793073
Trained batch 160 in epoch 5, gen_loss = 0.39997868360199546, disc_loss = 0.01792569872192888
Trained batch 161 in epoch 5, gen_loss = 0.3996388577384713, disc_loss = 0.01934274770772188
Trained batch 162 in epoch 5, gen_loss = 0.40008070772410903, disc_loss = 0.022171685456061175
Trained batch 163 in epoch 5, gen_loss = 0.40012254002617625, disc_loss = 0.023406648663051494
Trained batch 164 in epoch 5, gen_loss = 0.3999628995404099, disc_loss = 0.023839334619697183
Trained batch 165 in epoch 5, gen_loss = 0.3998469218432185, disc_loss = 0.023974150661533383
Trained batch 166 in epoch 5, gen_loss = 0.3999427423148812, disc_loss = 0.0239152951053801
Trained batch 167 in epoch 5, gen_loss = 0.3995556506727423, disc_loss = 0.023848114286790536
Trained batch 168 in epoch 5, gen_loss = 0.39947453211750505, disc_loss = 0.023775306647056547
Trained batch 169 in epoch 5, gen_loss = 0.39956335811054006, disc_loss = 0.023820086361443185
Trained batch 170 in epoch 5, gen_loss = 0.39934321436268544, disc_loss = 0.024207724825743238
Trained batch 171 in epoch 5, gen_loss = 0.39921720048715903, disc_loss = 0.024466392487696328
Trained batch 172 in epoch 5, gen_loss = 0.39906243144432246, disc_loss = 0.025161436754561464
Trained batch 173 in epoch 5, gen_loss = 0.39890009678643323, disc_loss = 0.02581061736577533
Trained batch 174 in epoch 5, gen_loss = 0.39892343640327455, disc_loss = 0.026718093466479333
Trained batch 175 in epoch 5, gen_loss = 0.3987709646197883, disc_loss = 0.030291673273247645
Trained batch 176 in epoch 5, gen_loss = 0.3985426798041931, disc_loss = 0.0315925791806352
Trained batch 177 in epoch 5, gen_loss = 0.39866042421774917, disc_loss = 0.03329998620078125
Trained batch 178 in epoch 5, gen_loss = 0.39818598221800183, disc_loss = 0.03434696773882674
Trained batch 179 in epoch 5, gen_loss = 0.39762914097971386, disc_loss = 0.035232858826445106
Trained batch 180 in epoch 5, gen_loss = 0.3974125103726571, disc_loss = 0.03676407818279862
Trained batch 181 in epoch 5, gen_loss = 0.3973018535218396, disc_loss = 0.04025412241481807
Trained batch 182 in epoch 5, gen_loss = 0.3970700990958292, disc_loss = 0.04244415206634923
Trained batch 183 in epoch 5, gen_loss = 0.39739949207590974, disc_loss = 0.04344954006671248
Trained batch 184 in epoch 5, gen_loss = 0.39780376166910736, disc_loss = 0.0438023116650387
Trained batch 185 in epoch 5, gen_loss = 0.3972158178847323, disc_loss = 0.045049235756416374
Trained batch 186 in epoch 5, gen_loss = 0.39665738337817674, disc_loss = 0.04749226543328969
Trained batch 187 in epoch 5, gen_loss = 0.39622580830721144, disc_loss = 0.04876243185463728
Trained batch 188 in epoch 5, gen_loss = 0.39651999886704503, disc_loss = 0.049440107067798084
Trained batch 189 in epoch 5, gen_loss = 0.3964793567594729, disc_loss = 0.05007873841310165
Trained batch 190 in epoch 5, gen_loss = 0.396088668657223, disc_loss = 0.050437484473826275
Trained batch 191 in epoch 5, gen_loss = 0.39604523389910656, disc_loss = 0.050473930945675725
Trained batch 192 in epoch 5, gen_loss = 0.3961336299236574, disc_loss = 0.05049061922958468
Trained batch 193 in epoch 5, gen_loss = 0.39651768754438027, disc_loss = 0.05045816026833244
Trained batch 194 in epoch 5, gen_loss = 0.3963021880541092, disc_loss = 0.0503925884485794
Trained batch 195 in epoch 5, gen_loss = 0.39626309853427266, disc_loss = 0.05019702260680639
Trained batch 196 in epoch 5, gen_loss = 0.39577316299912896, disc_loss = 0.05003581211286441
Trained batch 197 in epoch 5, gen_loss = 0.3957572245236599, disc_loss = 0.04989651175812028
Trained batch 198 in epoch 5, gen_loss = 0.3954591071186353, disc_loss = 0.04975144158032063
Trained batch 199 in epoch 5, gen_loss = 0.3956634590029717, disc_loss = 0.049668956260138654
Trained batch 200 in epoch 5, gen_loss = 0.3957620516641816, disc_loss = 0.04946501678248534
Trained batch 201 in epoch 5, gen_loss = 0.39572069683287403, disc_loss = 0.04931752124684863
Trained batch 202 in epoch 5, gen_loss = 0.3958644072704127, disc_loss = 0.04910944605084466
Trained batch 203 in epoch 5, gen_loss = 0.3959584903775477, disc_loss = 0.04889835279940527
Trained batch 204 in epoch 5, gen_loss = 0.3958009974258702, disc_loss = 0.048685411641817174
Trained batch 205 in epoch 5, gen_loss = 0.3957217591769487, disc_loss = 0.04848718731432421
Trained batch 206 in epoch 5, gen_loss = 0.3957966412035164, disc_loss = 0.048297846996605595
Trained batch 207 in epoch 5, gen_loss = 0.39587256126105785, disc_loss = 0.04812255426608877
Trained batch 208 in epoch 5, gen_loss = 0.3957934502209203, disc_loss = 0.047988297106669194
Trained batch 209 in epoch 5, gen_loss = 0.3960056563218435, disc_loss = 0.047854551806813105
Trained batch 210 in epoch 5, gen_loss = 0.39590947167568297, disc_loss = 0.047675486195830286
Trained batch 211 in epoch 5, gen_loss = 0.39613743435661747, disc_loss = 0.04747296010120992
Trained batch 212 in epoch 5, gen_loss = 0.39588196442720475, disc_loss = 0.047314348644544174
Trained batch 213 in epoch 5, gen_loss = 0.3956127592893404, disc_loss = 0.047137792192554
Trained batch 214 in epoch 5, gen_loss = 0.3952747271504513, disc_loss = 0.046988801264778036
Trained batch 215 in epoch 5, gen_loss = 0.3951678260884903, disc_loss = 0.04697065383569915
Trained batch 216 in epoch 5, gen_loss = 0.3953225559078603, disc_loss = 0.04689037807211752
Trained batch 217 in epoch 5, gen_loss = 0.39548992413446443, disc_loss = 0.04669500258404104
Trained batch 218 in epoch 5, gen_loss = 0.3952681148705417, disc_loss = 0.04656459411396751
Trained batch 219 in epoch 5, gen_loss = 0.3951033039526506, disc_loss = 0.04651958778029604
Trained batch 220 in epoch 5, gen_loss = 0.3950677054230444, disc_loss = 0.04635850997821837
Trained batch 221 in epoch 5, gen_loss = 0.3951141200624071, disc_loss = 0.04618805405544327
Trained batch 222 in epoch 5, gen_loss = 0.3952443645139446, disc_loss = 0.0460314108630446
Trained batch 223 in epoch 5, gen_loss = 0.39568387331174953, disc_loss = 0.04596962345151821
Trained batch 224 in epoch 5, gen_loss = 0.39563003420829773, disc_loss = 0.045793831651357725
Trained batch 225 in epoch 5, gen_loss = 0.3958085987683946, disc_loss = 0.04564242039892649
Trained batch 226 in epoch 5, gen_loss = 0.39557464151655525, disc_loss = 0.04551530044832542
Trained batch 227 in epoch 5, gen_loss = 0.395624700606915, disc_loss = 0.0455069734044516
Trained batch 228 in epoch 5, gen_loss = 0.3953982117915258, disc_loss = 0.04540365506202495
Trained batch 229 in epoch 5, gen_loss = 0.3957605753255927, disc_loss = 0.04524412047112887
Trained batch 230 in epoch 5, gen_loss = 0.39592292040457455, disc_loss = 0.04506471826371362
Trained batch 231 in epoch 5, gen_loss = 0.39595837480035323, disc_loss = 0.04489982040304939
Trained batch 232 in epoch 5, gen_loss = 0.3958594300204592, disc_loss = 0.0447257793487985
Trained batch 233 in epoch 5, gen_loss = 0.39606777941569304, disc_loss = 0.04457755077657147
Trained batch 234 in epoch 5, gen_loss = 0.3958117277064222, disc_loss = 0.044401991921922866
Trained batch 235 in epoch 5, gen_loss = 0.3957095133551097, disc_loss = 0.04423567378608376
Trained batch 236 in epoch 5, gen_loss = 0.39574491348950674, disc_loss = 0.04409106397379449
Trained batch 237 in epoch 5, gen_loss = 0.3956062786218499, disc_loss = 0.04393857425570825
Trained batch 238 in epoch 5, gen_loss = 0.3953875460385279, disc_loss = 0.04381516407839135
Trained batch 239 in epoch 5, gen_loss = 0.3953471913933754, disc_loss = 0.04365540309590869
Trained batch 240 in epoch 5, gen_loss = 0.3951067868852022, disc_loss = 0.04348784656900549
Trained batch 241 in epoch 5, gen_loss = 0.39488678062257687, disc_loss = 0.04333574473756858
Trained batch 242 in epoch 5, gen_loss = 0.3948476491151033, disc_loss = 0.043171554918586826
Trained batch 243 in epoch 5, gen_loss = 0.39501594287938757, disc_loss = 0.04301559966850499
Trained batch 244 in epoch 5, gen_loss = 0.3952551925668911, disc_loss = 0.043026317707120385
Trained batch 245 in epoch 5, gen_loss = 0.39515709719522213, disc_loss = 0.04318794307305584
Trained batch 246 in epoch 5, gen_loss = 0.39532052710471366, disc_loss = 0.043051060513255794
Trained batch 247 in epoch 5, gen_loss = 0.39549099173276653, disc_loss = 0.04298736220164668
Trained batch 248 in epoch 5, gen_loss = 0.39563813338796777, disc_loss = 0.04295741331863617
Trained batch 249 in epoch 5, gen_loss = 0.39585589051246645, disc_loss = 0.0428184801095631
Trained batch 250 in epoch 5, gen_loss = 0.3959172956972008, disc_loss = 0.04302520486521553
Trained batch 251 in epoch 5, gen_loss = 0.3957692910991018, disc_loss = 0.043895523350026146
Trained batch 252 in epoch 5, gen_loss = 0.3956199600526938, disc_loss = 0.04422414803986986
Trained batch 253 in epoch 5, gen_loss = 0.39581000687569146, disc_loss = 0.04412884621374038
Trained batch 254 in epoch 5, gen_loss = 0.3955760504685196, disc_loss = 0.04398889870122623
Trained batch 255 in epoch 5, gen_loss = 0.3954709217650816, disc_loss = 0.04399723790788812
Trained batch 256 in epoch 5, gen_loss = 0.3956822169661986, disc_loss = 0.04447329436960641
Trained batch 257 in epoch 5, gen_loss = 0.3958285269580146, disc_loss = 0.045825681466629097
Trained batch 258 in epoch 5, gen_loss = 0.3957243822946512, disc_loss = 0.04606179206728266
Trained batch 259 in epoch 5, gen_loss = 0.39558789821771473, disc_loss = 0.046540893597949225
Trained batch 260 in epoch 5, gen_loss = 0.3954713013437059, disc_loss = 0.04665046140807592
Trained batch 261 in epoch 5, gen_loss = 0.3955641525392314, disc_loss = 0.04659972056717157
Trained batch 262 in epoch 5, gen_loss = 0.3951074034542185, disc_loss = 0.04664773143940347
Trained batch 263 in epoch 5, gen_loss = 0.394992512058128, disc_loss = 0.046506154172565206
Trained batch 264 in epoch 5, gen_loss = 0.39480836368956657, disc_loss = 0.04638897836151234
Trained batch 265 in epoch 5, gen_loss = 0.3946083210464707, disc_loss = 0.04689075997168429
Trained batch 266 in epoch 5, gen_loss = 0.39464638987730505, disc_loss = 0.04858425095453266
Trained batch 267 in epoch 5, gen_loss = 0.3946374887183531, disc_loss = 0.048927482361549084
Trained batch 268 in epoch 5, gen_loss = 0.39443936578403177, disc_loss = 0.0489908681754421
Trained batch 269 in epoch 5, gen_loss = 0.3944894313812256, disc_loss = 0.048930214598766286
Trained batch 270 in epoch 5, gen_loss = 0.394376594861935, disc_loss = 0.048833016915946194
Trained batch 271 in epoch 5, gen_loss = 0.3943280554650461, disc_loss = 0.04891433407058631
Trained batch 272 in epoch 5, gen_loss = 0.39424892779671666, disc_loss = 0.04899766740125635
Trained batch 273 in epoch 5, gen_loss = 0.3940498077303824, disc_loss = 0.049140469155598936
Trained batch 274 in epoch 5, gen_loss = 0.39410081429914995, disc_loss = 0.04912567729786546
Trained batch 275 in epoch 5, gen_loss = 0.3938917234755944, disc_loss = 0.049020091899918676
Trained batch 276 in epoch 5, gen_loss = 0.3936689931778271, disc_loss = 0.04904782387914661
Trained batch 277 in epoch 5, gen_loss = 0.3937172690312639, disc_loss = 0.04969346247719795
Trained batch 278 in epoch 5, gen_loss = 0.39348346059040357, disc_loss = 0.05141193660516058
Trained batch 279 in epoch 5, gen_loss = 0.39357027879783085, disc_loss = 0.051543749953478775
Trained batch 280 in epoch 5, gen_loss = 0.3934193429573575, disc_loss = 0.051859897098817206
Trained batch 281 in epoch 5, gen_loss = 0.3933588996635261, disc_loss = 0.052064702685729186
Trained batch 282 in epoch 5, gen_loss = 0.39315497032745145, disc_loss = 0.05204954567466543
Trained batch 283 in epoch 5, gen_loss = 0.39323510187612454, disc_loss = 0.0522826217739223
Trained batch 284 in epoch 5, gen_loss = 0.3929227061438979, disc_loss = 0.0528335516698446
Trained batch 285 in epoch 5, gen_loss = 0.39279801278681187, disc_loss = 0.05284289695738515
Trained batch 286 in epoch 5, gen_loss = 0.39279048409611506, disc_loss = 0.05281779064065923
Trained batch 287 in epoch 5, gen_loss = 0.393122629986869, disc_loss = 0.053011055367783735
Trained batch 288 in epoch 5, gen_loss = 0.39275844843742347, disc_loss = 0.05312931509732807
Trained batch 289 in epoch 5, gen_loss = 0.3928804085172456, disc_loss = 0.053030336864798425
Trained batch 290 in epoch 5, gen_loss = 0.3928072854006004, disc_loss = 0.05347164977430702
Trained batch 291 in epoch 5, gen_loss = 0.3924396449368294, disc_loss = 0.0541234498009108
Trained batch 292 in epoch 5, gen_loss = 0.39247643174571795, disc_loss = 0.0541624750657112
Trained batch 293 in epoch 5, gen_loss = 0.3923410523910912, disc_loss = 0.05421599440199804
Trained batch 294 in epoch 5, gen_loss = 0.3920053383051339, disc_loss = 0.05461523192993886
Trained batch 295 in epoch 5, gen_loss = 0.39195167041710904, disc_loss = 0.05562384138210217
Trained batch 296 in epoch 5, gen_loss = 0.39189199847404405, disc_loss = 0.05557677236143405
Trained batch 297 in epoch 5, gen_loss = 0.3921651005144887, disc_loss = 0.05547837445324118
Trained batch 298 in epoch 5, gen_loss = 0.3921361506782647, disc_loss = 0.05534297183454255
Trained batch 299 in epoch 5, gen_loss = 0.39200646728277205, disc_loss = 0.05518170881376136
Trained batch 300 in epoch 5, gen_loss = 0.39198149379305663, disc_loss = 0.055022515364082536
Trained batch 301 in epoch 5, gen_loss = 0.39209363170412204, disc_loss = 0.05486346877296455
Trained batch 302 in epoch 5, gen_loss = 0.3921221426808008, disc_loss = 0.05470217009464574
Trained batch 303 in epoch 5, gen_loss = 0.3921539162922847, disc_loss = 0.054708390092089665
Trained batch 304 in epoch 5, gen_loss = 0.39226122215145925, disc_loss = 0.054637670272495595
Trained batch 305 in epoch 5, gen_loss = 0.39204761142434635, disc_loss = 0.054650888418941605
Trained batch 306 in epoch 5, gen_loss = 0.3921979686142179, disc_loss = 0.05492681506334831
Trained batch 307 in epoch 5, gen_loss = 0.39221376383846457, disc_loss = 0.05539859815590634
Trained batch 308 in epoch 5, gen_loss = 0.39223771988381073, disc_loss = 0.05559836596858606
Trained batch 309 in epoch 5, gen_loss = 0.3922895611293854, disc_loss = 0.05549460939082858
Trained batch 310 in epoch 5, gen_loss = 0.3924566637664746, disc_loss = 0.05545627126912661
Trained batch 311 in epoch 5, gen_loss = 0.39244585312329805, disc_loss = 0.05547997240818148
Trained batch 312 in epoch 5, gen_loss = 0.39247357102628716, disc_loss = 0.055662544771319274
Trained batch 313 in epoch 5, gen_loss = 0.3921029753745741, disc_loss = 0.05581105756703141
Trained batch 314 in epoch 5, gen_loss = 0.3923881784317985, disc_loss = 0.05589194822860586
Trained batch 315 in epoch 5, gen_loss = 0.3923265716131729, disc_loss = 0.05576387374891009
Trained batch 316 in epoch 5, gen_loss = 0.3924731233330555, disc_loss = 0.055639561835481056
Trained batch 317 in epoch 5, gen_loss = 0.39248258606442865, disc_loss = 0.055483129790525755
Trained batch 318 in epoch 5, gen_loss = 0.3925982240972848, disc_loss = 0.05532855035859046
Trained batch 319 in epoch 5, gen_loss = 0.3925730184651911, disc_loss = 0.05516867634560185
Trained batch 320 in epoch 5, gen_loss = 0.39250237093164914, disc_loss = 0.0550259975032849
Trained batch 321 in epoch 5, gen_loss = 0.3927079292002672, disc_loss = 0.054867916711373255
Trained batch 322 in epoch 5, gen_loss = 0.39278350304523857, disc_loss = 0.05474010309699675
Trained batch 323 in epoch 5, gen_loss = 0.39265393447360875, disc_loss = 0.054608200558707014
Trained batch 324 in epoch 5, gen_loss = 0.392428249670909, disc_loss = 0.054603325274522205
Trained batch 325 in epoch 5, gen_loss = 0.3925952956171855, disc_loss = 0.05463920561921714
Trained batch 326 in epoch 5, gen_loss = 0.3927197519245498, disc_loss = 0.05461455519017066
Trained batch 327 in epoch 5, gen_loss = 0.39288110640354273, disc_loss = 0.054760323811667434
Trained batch 328 in epoch 5, gen_loss = 0.3930461864159825, disc_loss = 0.05484774253259648
Trained batch 329 in epoch 5, gen_loss = 0.39322022660212086, disc_loss = 0.05473349563703364
Trained batch 330 in epoch 5, gen_loss = 0.3934860143056449, disc_loss = 0.05458901551734301
Trained batch 331 in epoch 5, gen_loss = 0.39346201915338813, disc_loss = 0.05444427665602836
Trained batch 332 in epoch 5, gen_loss = 0.3934342113880066, disc_loss = 0.054297450877965205
Trained batch 333 in epoch 5, gen_loss = 0.39351347008508125, disc_loss = 0.05414987216730781
Trained batch 334 in epoch 5, gen_loss = 0.393473700000279, disc_loss = 0.054008328273663045
Trained batch 335 in epoch 5, gen_loss = 0.39363168206598076, disc_loss = 0.05387278090330212
Trained batch 336 in epoch 5, gen_loss = 0.39367954578880743, disc_loss = 0.053721230454122484
Trained batch 337 in epoch 5, gen_loss = 0.39388733776010704, disc_loss = 0.053573658308062495
Trained batch 338 in epoch 5, gen_loss = 0.39380276660300284, disc_loss = 0.05342230488869683
Trained batch 339 in epoch 5, gen_loss = 0.39410771008800055, disc_loss = 0.053279562121058596
Trained batch 340 in epoch 5, gen_loss = 0.39447682676427176, disc_loss = 0.05314980145141652
Trained batch 341 in epoch 5, gen_loss = 0.39468165081844, disc_loss = 0.05300283505038728
Trained batch 342 in epoch 5, gen_loss = 0.39481935400309437, disc_loss = 0.052863362167029214
Trained batch 343 in epoch 5, gen_loss = 0.39506237451420273, disc_loss = 0.05271771488231363
Trained batch 344 in epoch 5, gen_loss = 0.39506477082985036, disc_loss = 0.052575327632645066
Trained batch 345 in epoch 5, gen_loss = 0.3950714243285229, disc_loss = 0.05243237569744462
Trained batch 346 in epoch 5, gen_loss = 0.39507763246637945, disc_loss = 0.05228935862654519
Trained batch 347 in epoch 5, gen_loss = 0.39500371529453104, disc_loss = 0.05216881696950382
Trained batch 348 in epoch 5, gen_loss = 0.3947472094123206, disc_loss = 0.0521965193791371
Trained batch 349 in epoch 5, gen_loss = 0.39468260288238527, disc_loss = 0.05236915794783272
Trained batch 350 in epoch 5, gen_loss = 0.39469116060142845, disc_loss = 0.05225278303856985
Trained batch 351 in epoch 5, gen_loss = 0.3945690348575061, disc_loss = 0.05221877501538653
Trained batch 352 in epoch 5, gen_loss = 0.39478460697209194, disc_loss = 0.05217762345698116
Trained batch 353 in epoch 5, gen_loss = 0.3948275873721656, disc_loss = 0.05207387499934152
Trained batch 354 in epoch 5, gen_loss = 0.3949397688180628, disc_loss = 0.05194831652957028
Trained batch 355 in epoch 5, gen_loss = 0.39496874524636216, disc_loss = 0.0518355259906927
Trained batch 356 in epoch 5, gen_loss = 0.39488760012538493, disc_loss = 0.05173218904336372
Trained batch 357 in epoch 5, gen_loss = 0.3951531844265634, disc_loss = 0.05159997245652585
Trained batch 358 in epoch 5, gen_loss = 0.39515904289434217, disc_loss = 0.05147869502499695
Trained batch 359 in epoch 5, gen_loss = 0.3951962471836143, disc_loss = 0.05138353853819556
Trained batch 360 in epoch 5, gen_loss = 0.3952886928646848, disc_loss = 0.051250952315146564
Trained batch 361 in epoch 5, gen_loss = 0.3953445196481041, disc_loss = 0.05112633629408099
Trained batch 362 in epoch 5, gen_loss = 0.39527986479856425, disc_loss = 0.05100467078725759
Trained batch 363 in epoch 5, gen_loss = 0.39522754687529343, disc_loss = 0.050900433927481475
Trained batch 364 in epoch 5, gen_loss = 0.39517194579725395, disc_loss = 0.05080005112789852
Trained batch 365 in epoch 5, gen_loss = 0.39529908704953115, disc_loss = 0.050686937004748904
Trained batch 366 in epoch 5, gen_loss = 0.39530719585249796, disc_loss = 0.05060630831318687
Trained batch 367 in epoch 5, gen_loss = 0.3954070598372947, disc_loss = 0.050532026592048605
Trained batch 368 in epoch 5, gen_loss = 0.39557842050141434, disc_loss = 0.05051200380684495
Trained batch 369 in epoch 5, gen_loss = 0.3955382107077418, disc_loss = 0.050416947685880585
Trained batch 370 in epoch 5, gen_loss = 0.3956607706302581, disc_loss = 0.05032569134461686
Trained batch 371 in epoch 5, gen_loss = 0.39597160577453594, disc_loss = 0.05020177159542894
Trained batch 372 in epoch 5, gen_loss = 0.3961421200960635, disc_loss = 0.05009652766316065
Trained batch 373 in epoch 5, gen_loss = 0.39615207918506257, disc_loss = 0.04997094661569507
Trained batch 374 in epoch 5, gen_loss = 0.3961987040042877, disc_loss = 0.04987388573323066
Trained batch 375 in epoch 5, gen_loss = 0.396269855901916, disc_loss = 0.04977161327777604
Trained batch 376 in epoch 5, gen_loss = 0.396385481645321, disc_loss = 0.04966018559637823
Trained batch 377 in epoch 5, gen_loss = 0.39668103240469776, disc_loss = 0.04967887442612592
Trained batch 378 in epoch 5, gen_loss = 0.3966783051597726, disc_loss = 0.04955709557154027
Trained batch 379 in epoch 5, gen_loss = 0.39667224695808007, disc_loss = 0.049434508224428436
Trained batch 380 in epoch 5, gen_loss = 0.3967215238124367, disc_loss = 0.049315628926104714
Trained batch 381 in epoch 5, gen_loss = 0.39678295760254584, disc_loss = 0.04921544759692161
Trained batch 382 in epoch 5, gen_loss = 0.3967299438799019, disc_loss = 0.04917664050751344
Trained batch 383 in epoch 5, gen_loss = 0.3969156820482264, disc_loss = 0.04913676178011883
Trained batch 384 in epoch 5, gen_loss = 0.39708979408462325, disc_loss = 0.04901569249855306
Trained batch 385 in epoch 5, gen_loss = 0.39683153028624046, disc_loss = 0.04919577589052864
Trained batch 386 in epoch 5, gen_loss = 0.3968753405781679, disc_loss = 0.050089054120534875
Trained batch 387 in epoch 5, gen_loss = 0.3967037573456764, disc_loss = 0.05011325701396101
Trained batch 388 in epoch 5, gen_loss = 0.39659188875502366, disc_loss = 0.05003645014694765
Trained batch 389 in epoch 5, gen_loss = 0.39653182893227307, disc_loss = 0.04992708609937929
Trained batch 390 in epoch 5, gen_loss = 0.39654972783439907, disc_loss = 0.049809765353378464
Trained batch 391 in epoch 5, gen_loss = 0.39680408253049365, disc_loss = 0.04970695709554854
Trained batch 392 in epoch 5, gen_loss = 0.39689694492871525, disc_loss = 0.0496087706766006
Trained batch 393 in epoch 5, gen_loss = 0.3967167065682145, disc_loss = 0.049509685845108384
Trained batch 394 in epoch 5, gen_loss = 0.3965989114362982, disc_loss = 0.04956714350515033
Trained batch 395 in epoch 5, gen_loss = 0.3963176965562984, disc_loss = 0.049630457177173785
Trained batch 396 in epoch 5, gen_loss = 0.3965598944602745, disc_loss = 0.049858718321533164
Trained batch 397 in epoch 5, gen_loss = 0.3963066960998516, disc_loss = 0.05049855808593478
Trained batch 398 in epoch 5, gen_loss = 0.39666996235237983, disc_loss = 0.05129994354826424
Trained batch 399 in epoch 5, gen_loss = 0.3967148843407631, disc_loss = 0.05155504934416968
Trained batch 400 in epoch 5, gen_loss = 0.3964778607771581, disc_loss = 0.05155880759372039
Trained batch 401 in epoch 5, gen_loss = 0.39634790623662486, disc_loss = 0.051564609056624786
Trained batch 402 in epoch 5, gen_loss = 0.3964136423307376, disc_loss = 0.051476461839863326
Trained batch 403 in epoch 5, gen_loss = 0.3965752076837096, disc_loss = 0.05137262707227486
Trained batch 404 in epoch 5, gen_loss = 0.39654219091674425, disc_loss = 0.05128869944076732
Trained batch 405 in epoch 5, gen_loss = 0.3965809384883918, disc_loss = 0.05119621864186825
Trained batch 406 in epoch 5, gen_loss = 0.3964659253121594, disc_loss = 0.051137184851639275
Trained batch 407 in epoch 5, gen_loss = 0.39612577190878345, disc_loss = 0.051123255648503
Trained batch 408 in epoch 5, gen_loss = 0.3959678214016054, disc_loss = 0.05112770238414766
Trained batch 409 in epoch 5, gen_loss = 0.39586628268404705, disc_loss = 0.05124847858437201
Trained batch 410 in epoch 5, gen_loss = 0.39591921492504667, disc_loss = 0.05125143087495667
Trained batch 411 in epoch 5, gen_loss = 0.39597359249024716, disc_loss = 0.05120743105334379
Trained batch 412 in epoch 5, gen_loss = 0.39580194994843326, disc_loss = 0.05125923371255357
Trained batch 413 in epoch 5, gen_loss = 0.39581957747394914, disc_loss = 0.05153764798213134
Trained batch 414 in epoch 5, gen_loss = 0.39564967729959144, disc_loss = 0.052451462481950734
Trained batch 415 in epoch 5, gen_loss = 0.3958194281619329, disc_loss = 0.05332064176750114
Trained batch 416 in epoch 5, gen_loss = 0.3957523715724762, disc_loss = 0.05332072565543668
Trained batch 417 in epoch 5, gen_loss = 0.39554603298029833, disc_loss = 0.053362334534079146
Trained batch 418 in epoch 5, gen_loss = 0.39564070738585294, disc_loss = 0.053332198868413415
Trained batch 419 in epoch 5, gen_loss = 0.39562680423259733, disc_loss = 0.0532286092188553
Trained batch 420 in epoch 5, gen_loss = 0.39560514553992027, disc_loss = 0.0531329272015987
Trained batch 421 in epoch 5, gen_loss = 0.3954894198766817, disc_loss = 0.05302953173368353
Trained batch 422 in epoch 5, gen_loss = 0.3954339687564976, disc_loss = 0.05301108383603865
Trained batch 423 in epoch 5, gen_loss = 0.3954466677639844, disc_loss = 0.05311605833041952
Trained batch 424 in epoch 5, gen_loss = 0.3954801913569955, disc_loss = 0.053246803578838486
Trained batch 425 in epoch 5, gen_loss = 0.3953872193612963, disc_loss = 0.053324940353560925
Trained batch 426 in epoch 5, gen_loss = 0.3953314516388002, disc_loss = 0.05341314025094026
Trained batch 427 in epoch 5, gen_loss = 0.39537785954286003, disc_loss = 0.053782547551406344
Trained batch 428 in epoch 5, gen_loss = 0.395051814806767, disc_loss = 0.0540410264394906
Trained batch 429 in epoch 5, gen_loss = 0.3953121380057446, disc_loss = 0.05400739386393472
Trained batch 430 in epoch 5, gen_loss = 0.3952925963772422, disc_loss = 0.05412835065691933
Trained batch 431 in epoch 5, gen_loss = 0.39531586195031804, disc_loss = 0.0542368907970538
Trained batch 432 in epoch 5, gen_loss = 0.3955503377297734, disc_loss = 0.05423992599226754
Trained batch 433 in epoch 5, gen_loss = 0.39577589434687444, disc_loss = 0.054158167297010895
Trained batch 434 in epoch 5, gen_loss = 0.39569775893770415, disc_loss = 0.05417707820366747
Trained batch 435 in epoch 5, gen_loss = 0.3958744121664161, disc_loss = 0.054070854343131074
Trained batch 436 in epoch 5, gen_loss = 0.3959922567521407, disc_loss = 0.054020559604229614
Trained batch 437 in epoch 5, gen_loss = 0.3961369979735379, disc_loss = 0.05390804013400551
Trained batch 438 in epoch 5, gen_loss = 0.3960866510596525, disc_loss = 0.05384252329369167
Trained batch 439 in epoch 5, gen_loss = 0.39606442959471183, disc_loss = 0.05373726175312186
Trained batch 440 in epoch 5, gen_loss = 0.3959291815892909, disc_loss = 0.053633878025877796
Trained batch 441 in epoch 5, gen_loss = 0.3958977222847183, disc_loss = 0.05356523375765935
Trained batch 442 in epoch 5, gen_loss = 0.39596278020275366, disc_loss = 0.05345403734512068
Trained batch 443 in epoch 5, gen_loss = 0.39615164354846283, disc_loss = 0.05334584613323845
Trained batch 444 in epoch 5, gen_loss = 0.39619621145591305, disc_loss = 0.053235291075772406
Trained batch 445 in epoch 5, gen_loss = 0.3963872401436348, disc_loss = 0.05313111674977621
Trained batch 446 in epoch 5, gen_loss = 0.39642293447882804, disc_loss = 0.05303170342324927
Trained batch 447 in epoch 5, gen_loss = 0.39640505804813336, disc_loss = 0.05305232600260622
Trained batch 448 in epoch 5, gen_loss = 0.3965390074359282, disc_loss = 0.053100279305635316
Trained batch 449 in epoch 5, gen_loss = 0.39656578607029386, disc_loss = 0.05300817966189546
Trained batch 450 in epoch 5, gen_loss = 0.3965352473660742, disc_loss = 0.05297865181427734
Trained batch 451 in epoch 5, gen_loss = 0.39662103816471267, disc_loss = 0.05292373654714361
Trained batch 452 in epoch 5, gen_loss = 0.3967627489540487, disc_loss = 0.05281445977139795
Trained batch 453 in epoch 5, gen_loss = 0.3968851110089718, disc_loss = 0.05270475888250925
Trained batch 454 in epoch 5, gen_loss = 0.3970324769779876, disc_loss = 0.0525952149938618
Trained batch 455 in epoch 5, gen_loss = 0.39702109352015613, disc_loss = 0.05249352976687461
Trained batch 456 in epoch 5, gen_loss = 0.39694643816227987, disc_loss = 0.05239440418188348
Trained batch 457 in epoch 5, gen_loss = 0.3968942352778006, disc_loss = 0.052287696534233964
Trained batch 458 in epoch 5, gen_loss = 0.3970644668166674, disc_loss = 0.05222083473045984
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.45570385456085205, disc_loss = 0.012709091417491436
Trained batch 1 in epoch 6, gen_loss = 0.46005071699619293, disc_loss = 0.00869666924700141
Trained batch 2 in epoch 6, gen_loss = 0.44129207730293274, disc_loss = 0.007692952950795491
Trained batch 3 in epoch 6, gen_loss = 0.4244763180613518, disc_loss = 0.007543260231614113
Trained batch 4 in epoch 6, gen_loss = 0.4207117736339569, disc_loss = 0.006596525479108095
Trained batch 5 in epoch 6, gen_loss = 0.4291819781064987, disc_loss = 0.0099963394459337
Trained batch 6 in epoch 6, gen_loss = 0.42091014981269836, disc_loss = 0.013326854378517185
Trained batch 7 in epoch 6, gen_loss = 0.4171459637582302, disc_loss = 0.01225934294052422
Trained batch 8 in epoch 6, gen_loss = 0.4198569920327928, disc_loss = 0.0112243527546525
Trained batch 9 in epoch 6, gen_loss = 0.42406071722507477, disc_loss = 0.012205224204808473
Trained batch 10 in epoch 6, gen_loss = 0.4232361235401847, disc_loss = 0.011817319149320776
Trained batch 11 in epoch 6, gen_loss = 0.42166973402102786, disc_loss = 0.01210172800347209
Trained batch 12 in epoch 6, gen_loss = 0.42250930116726804, disc_loss = 0.011494012549519539
Trained batch 13 in epoch 6, gen_loss = 0.42093812780720846, disc_loss = 0.011274989760879959
Trained batch 14 in epoch 6, gen_loss = 0.42287293473879495, disc_loss = 0.011290839624901612
Trained batch 15 in epoch 6, gen_loss = 0.4189963061362505, disc_loss = 0.011609509645495564
Trained batch 16 in epoch 6, gen_loss = 0.41726086946094737, disc_loss = 0.01171964138527127
Trained batch 17 in epoch 6, gen_loss = 0.4166797250509262, disc_loss = 0.01353946260900961
Trained batch 18 in epoch 6, gen_loss = 0.412725977207485, disc_loss = 0.013982453775641165
Trained batch 19 in epoch 6, gen_loss = 0.4164964631199837, disc_loss = 0.013618629332631827
Trained batch 20 in epoch 6, gen_loss = 0.419641497589293, disc_loss = 0.013257031484196583
Trained batch 21 in epoch 6, gen_loss = 0.4208577424287796, disc_loss = 0.014305153374814174
Trained batch 22 in epoch 6, gen_loss = 0.4217426167882007, disc_loss = 0.017568671205283506
Trained batch 23 in epoch 6, gen_loss = 0.41975799823800725, disc_loss = 0.018807868492634345
Trained batch 24 in epoch 6, gen_loss = 0.4192367959022522, disc_loss = 0.01869368741288781
Trained batch 25 in epoch 6, gen_loss = 0.41777727237114537, disc_loss = 0.018390048707190614
Trained batch 26 in epoch 6, gen_loss = 0.4166428965550882, disc_loss = 0.01878780538768128
Trained batch 27 in epoch 6, gen_loss = 0.4176093137689999, disc_loss = 0.018452875698650523
Trained batch 28 in epoch 6, gen_loss = 0.4208416085818718, disc_loss = 0.019592489902700842
Trained batch 29 in epoch 6, gen_loss = 0.41881868640581765, disc_loss = 0.0209636511746794
Trained batch 30 in epoch 6, gen_loss = 0.42352547568659626, disc_loss = 0.021423949334289757
Trained batch 31 in epoch 6, gen_loss = 0.4256050605326891, disc_loss = 0.022452221703133546
Trained batch 32 in epoch 6, gen_loss = 0.42340157519687305, disc_loss = 0.02273422387908354
Trained batch 33 in epoch 6, gen_loss = 0.42412230460082784, disc_loss = 0.02249204075676115
Trained batch 34 in epoch 6, gen_loss = 0.42400449088641573, disc_loss = 0.021979213346328054
Trained batch 35 in epoch 6, gen_loss = 0.4260906899968783, disc_loss = 0.021644363024582464
Trained batch 36 in epoch 6, gen_loss = 0.4245900793655499, disc_loss = 0.02251141392500014
Trained batch 37 in epoch 6, gen_loss = 0.4265562350812711, disc_loss = 0.022791286587323014
Trained batch 38 in epoch 6, gen_loss = 0.4256728314436399, disc_loss = 0.023194020327467185
Trained batch 39 in epoch 6, gen_loss = 0.42506148442626, disc_loss = 0.02357928208075464
Trained batch 40 in epoch 6, gen_loss = 0.42399839511731774, disc_loss = 0.024506932306216984
Trained batch 41 in epoch 6, gen_loss = 0.4243778543812888, disc_loss = 0.02812114247076568
Trained batch 42 in epoch 6, gen_loss = 0.42363727369973825, disc_loss = 0.030609045221015464
Trained batch 43 in epoch 6, gen_loss = 0.42513594844124536, disc_loss = 0.03168491202152588
Trained batch 44 in epoch 6, gen_loss = 0.4268639577759637, disc_loss = 0.032244887244370246
Trained batch 45 in epoch 6, gen_loss = 0.42635899587817816, disc_loss = 0.03185779161994224
Trained batch 46 in epoch 6, gen_loss = 0.4253052853523417, disc_loss = 0.03154826154337918
Trained batch 47 in epoch 6, gen_loss = 0.4230336273709933, disc_loss = 0.032959719091498606
Trained batch 48 in epoch 6, gen_loss = 0.42424964600679826, disc_loss = 0.03509545894529747
Trained batch 49 in epoch 6, gen_loss = 0.4226205176115036, disc_loss = 0.04087251445278525
Trained batch 50 in epoch 6, gen_loss = 0.42424678510310604, disc_loss = 0.04193485811279685
Trained batch 51 in epoch 6, gen_loss = 0.4231199948833539, disc_loss = 0.04300591483927117
Trained batch 52 in epoch 6, gen_loss = 0.421186608525942, disc_loss = 0.04668631016294349
Trained batch 53 in epoch 6, gen_loss = 0.42100775241851807, disc_loss = 0.047669773904123795
Trained batch 54 in epoch 6, gen_loss = 0.4210473916747353, disc_loss = 0.04717651827430183
Trained batch 55 in epoch 6, gen_loss = 0.422427627657141, disc_loss = 0.047287577081338635
Trained batch 56 in epoch 6, gen_loss = 0.42321386358194185, disc_loss = 0.046908164380543065
Trained batch 57 in epoch 6, gen_loss = 0.42240185624566573, disc_loss = 0.04673694429019916
Trained batch 58 in epoch 6, gen_loss = 0.4205849352529493, disc_loss = 0.05114202221887092
Trained batch 59 in epoch 6, gen_loss = 0.4208482176065445, disc_loss = 0.054228392196819186
Trained batch 60 in epoch 6, gen_loss = 0.4203596330079876, disc_loss = 0.05359742572134147
Trained batch 61 in epoch 6, gen_loss = 0.4203879506357254, disc_loss = 0.05289245305222369
Trained batch 62 in epoch 6, gen_loss = 0.4194722379010821, disc_loss = 0.05229772479524688
Trained batch 63 in epoch 6, gen_loss = 0.4187590731307864, disc_loss = 0.051603500454803
Trained batch 64 in epoch 6, gen_loss = 0.41835592710054836, disc_loss = 0.050865011827017255
Trained batch 65 in epoch 6, gen_loss = 0.4170380144408255, disc_loss = 0.05014777877791361
Trained batch 66 in epoch 6, gen_loss = 0.4165148485952349, disc_loss = 0.0494569999290936
Trained batch 67 in epoch 6, gen_loss = 0.4164262361386243, disc_loss = 0.04878325034480761
Trained batch 68 in epoch 6, gen_loss = 0.4164775385372881, disc_loss = 0.04811631902323469
Trained batch 69 in epoch 6, gen_loss = 0.41598766786711555, disc_loss = 0.047474727896042165
Trained batch 70 in epoch 6, gen_loss = 0.4164271980104312, disc_loss = 0.046873089112997264
Trained batch 71 in epoch 6, gen_loss = 0.4167748631702529, disc_loss = 0.04635895761829387
Trained batch 72 in epoch 6, gen_loss = 0.41650828025112413, disc_loss = 0.04583289880267255
Trained batch 73 in epoch 6, gen_loss = 0.41607568231788844, disc_loss = 0.045803213872745434
Trained batch 74 in epoch 6, gen_loss = 0.4168370230992635, disc_loss = 0.045743799634898705
Trained batch 75 in epoch 6, gen_loss = 0.41663700342178345, disc_loss = 0.04554689604801273
Trained batch 76 in epoch 6, gen_loss = 0.4155262964112418, disc_loss = 0.04778787152926353
Trained batch 77 in epoch 6, gen_loss = 0.41629383732111025, disc_loss = 0.05138438221556731
Trained batch 78 in epoch 6, gen_loss = 0.41661016020593766, disc_loss = 0.05117198511592667
Trained batch 79 in epoch 6, gen_loss = 0.4157792184501886, disc_loss = 0.050686863975715826
Trained batch 80 in epoch 6, gen_loss = 0.4147915133723506, disc_loss = 0.050655814396493415
Trained batch 81 in epoch 6, gen_loss = 0.41414967470052766, disc_loss = 0.050304190712844636
Trained batch 82 in epoch 6, gen_loss = 0.41418217320040046, disc_loss = 0.049747355823708046
Trained batch 83 in epoch 6, gen_loss = 0.4142005071043968, disc_loss = 0.0492256590847059
Trained batch 84 in epoch 6, gen_loss = 0.4134075711755192, disc_loss = 0.04875998070518322
Trained batch 85 in epoch 6, gen_loss = 0.4132100946681444, disc_loss = 0.048377041951320025
Trained batch 86 in epoch 6, gen_loss = 0.4127477753436428, disc_loss = 0.048089851258622335
Trained batch 87 in epoch 6, gen_loss = 0.4124367924576456, disc_loss = 0.04770993919439868
Trained batch 88 in epoch 6, gen_loss = 0.4117951781562205, disc_loss = 0.04765878893759395
Trained batch 89 in epoch 6, gen_loss = 0.41203042997254263, disc_loss = 0.04813250228503926
Trained batch 90 in epoch 6, gen_loss = 0.41247826159655393, disc_loss = 0.04842153846306706
Trained batch 91 in epoch 6, gen_loss = 0.4118646807644678, disc_loss = 0.04883417414005279
Trained batch 92 in epoch 6, gen_loss = 0.41232746487022726, disc_loss = 0.049937752543658176
Trained batch 93 in epoch 6, gen_loss = 0.4123095822461108, disc_loss = 0.04948416021107597
Trained batch 94 in epoch 6, gen_loss = 0.4121621991458692, disc_loss = 0.04952509075550265
Trained batch 95 in epoch 6, gen_loss = 0.41234823657820624, disc_loss = 0.049140206419300135
Trained batch 96 in epoch 6, gen_loss = 0.4126750891356124, disc_loss = 0.04868530496215621
Trained batch 97 in epoch 6, gen_loss = 0.412982846705281, disc_loss = 0.048316163749776174
Trained batch 98 in epoch 6, gen_loss = 0.41252378472174056, disc_loss = 0.04846977231544301
Trained batch 99 in epoch 6, gen_loss = 0.4128592574596405, disc_loss = 0.0493054973310791
Trained batch 100 in epoch 6, gen_loss = 0.4128268048314765, disc_loss = 0.049643669828385265
Trained batch 101 in epoch 6, gen_loss = 0.4128896915445141, disc_loss = 0.049265239805476195
Trained batch 102 in epoch 6, gen_loss = 0.4132530729747513, disc_loss = 0.04895701185004442
Trained batch 103 in epoch 6, gen_loss = 0.4129892077583533, disc_loss = 0.048525776622297526
Trained batch 104 in epoch 6, gen_loss = 0.41224199249630883, disc_loss = 0.048120371964094896
Trained batch 105 in epoch 6, gen_loss = 0.4119568722990324, disc_loss = 0.04786512435123957
Trained batch 106 in epoch 6, gen_loss = 0.41162463716257397, disc_loss = 0.04769668460249135
Trained batch 107 in epoch 6, gen_loss = 0.4116151774371112, disc_loss = 0.04741789145541757
Trained batch 108 in epoch 6, gen_loss = 0.4112763527883302, disc_loss = 0.04707184751996548
Trained batch 109 in epoch 6, gen_loss = 0.4106008700349114, disc_loss = 0.0468939913965931
Trained batch 110 in epoch 6, gen_loss = 0.41096600084691437, disc_loss = 0.04652164604405763
Trained batch 111 in epoch 6, gen_loss = 0.41075075497584684, disc_loss = 0.04621386329069667
Trained batch 112 in epoch 6, gen_loss = 0.41134785630006704, disc_loss = 0.045969103510384406
Trained batch 113 in epoch 6, gen_loss = 0.4114013400517012, disc_loss = 0.04561414839005457
Trained batch 114 in epoch 6, gen_loss = 0.41157465188399606, disc_loss = 0.04542712567414602
Trained batch 115 in epoch 6, gen_loss = 0.4115737209032322, disc_loss = 0.045197989950197394
Trained batch 116 in epoch 6, gen_loss = 0.4118694668142205, disc_loss = 0.04486768813923192
Trained batch 117 in epoch 6, gen_loss = 0.41194339702695104, disc_loss = 0.04455031839917588
Trained batch 118 in epoch 6, gen_loss = 0.4110271259516227, disc_loss = 0.04428922850834284
Trained batch 119 in epoch 6, gen_loss = 0.411544743925333, disc_loss = 0.04406629350075188
Trained batch 120 in epoch 6, gen_loss = 0.41184241835736046, disc_loss = 0.04372206894865583
Trained batch 121 in epoch 6, gen_loss = 0.41250233034618566, disc_loss = 0.04343349701480665
Trained batch 122 in epoch 6, gen_loss = 0.412629793572232, disc_loss = 0.04313087378954136
Trained batch 123 in epoch 6, gen_loss = 0.41245366104187503, disc_loss = 0.04304891936255679
Trained batch 124 in epoch 6, gen_loss = 0.4121983141899109, disc_loss = 0.0435824889279902
Trained batch 125 in epoch 6, gen_loss = 0.41105570845187656, disc_loss = 0.04507942441924815
Trained batch 126 in epoch 6, gen_loss = 0.41162389681095213, disc_loss = 0.04624582818657981
Trained batch 127 in epoch 6, gen_loss = 0.4117139314766973, disc_loss = 0.04613046223312267
Trained batch 128 in epoch 6, gen_loss = 0.4114394398160683, disc_loss = 0.045924968833407
Trained batch 129 in epoch 6, gen_loss = 0.4116252337510769, disc_loss = 0.045996803378399745
Trained batch 130 in epoch 6, gen_loss = 0.41121789676542503, disc_loss = 0.04573036719269993
Trained batch 131 in epoch 6, gen_loss = 0.41066949543627823, disc_loss = 0.045778006431646645
Trained batch 132 in epoch 6, gen_loss = 0.41080105618426677, disc_loss = 0.04646693988304053
Trained batch 133 in epoch 6, gen_loss = 0.41057644717728914, disc_loss = 0.04628855240559066
Trained batch 134 in epoch 6, gen_loss = 0.4101468214282283, disc_loss = 0.046365285143946056
Trained batch 135 in epoch 6, gen_loss = 0.40961600336081844, disc_loss = 0.047215272182845235
Trained batch 136 in epoch 6, gen_loss = 0.40923915205210665, disc_loss = 0.04754276742587668
Trained batch 137 in epoch 6, gen_loss = 0.4095188450554143, disc_loss = 0.04729537508936356
Trained batch 138 in epoch 6, gen_loss = 0.4098095670878458, disc_loss = 0.048499692844481565
Trained batch 139 in epoch 6, gen_loss = 0.40933538547583986, disc_loss = 0.04870023785624653
Trained batch 140 in epoch 6, gen_loss = 0.40907100477117175, disc_loss = 0.04874093819687024
Trained batch 141 in epoch 6, gen_loss = 0.4093011071984197, disc_loss = 0.04854482010623414
Trained batch 142 in epoch 6, gen_loss = 0.40971114939742986, disc_loss = 0.048848974612912724
Trained batch 143 in epoch 6, gen_loss = 0.4090744625363085, disc_loss = 0.049435139501131035
Trained batch 144 in epoch 6, gen_loss = 0.4093225096834117, disc_loss = 0.0504519625695358
Trained batch 145 in epoch 6, gen_loss = 0.4085936821895103, disc_loss = 0.05119672139200752
Trained batch 146 in epoch 6, gen_loss = 0.40896949374756847, disc_loss = 0.05145260972623415
Trained batch 147 in epoch 6, gen_loss = 0.40861520110755356, disc_loss = 0.05121291194400574
Trained batch 148 in epoch 6, gen_loss = 0.4083823547667305, disc_loss = 0.0509841703222252
Trained batch 149 in epoch 6, gen_loss = 0.40803821206092833, disc_loss = 0.05083863178578516
Trained batch 150 in epoch 6, gen_loss = 0.4077724437445205, disc_loss = 0.05055958273456685
Trained batch 151 in epoch 6, gen_loss = 0.40806010541947263, disc_loss = 0.050282371441809165
Trained batch 152 in epoch 6, gen_loss = 0.40802113078778085, disc_loss = 0.050062642502750644
Trained batch 153 in epoch 6, gen_loss = 0.40738746988308894, disc_loss = 0.049881999710477985
Trained batch 154 in epoch 6, gen_loss = 0.40770275362076297, disc_loss = 0.049678066820507086
Trained batch 155 in epoch 6, gen_loss = 0.40766188158438754, disc_loss = 0.04958593235530246
Trained batch 156 in epoch 6, gen_loss = 0.40792734987416845, disc_loss = 0.04946211863392193
Trained batch 157 in epoch 6, gen_loss = 0.4081279669381395, disc_loss = 0.04939565838526793
Trained batch 158 in epoch 6, gen_loss = 0.4082763196912202, disc_loss = 0.04925634112478521
Trained batch 159 in epoch 6, gen_loss = 0.4083766840398312, disc_loss = 0.0489688556510373
Trained batch 160 in epoch 6, gen_loss = 0.40809429876552605, disc_loss = 0.04883355632140909
Trained batch 161 in epoch 6, gen_loss = 0.40839471493238283, disc_loss = 0.048917590225126914
Trained batch 162 in epoch 6, gen_loss = 0.4081061881012712, disc_loss = 0.04869922725740889
Trained batch 163 in epoch 6, gen_loss = 0.4082949644908672, disc_loss = 0.048551653510402526
Trained batch 164 in epoch 6, gen_loss = 0.40883572282213154, disc_loss = 0.048308948183319336
Trained batch 165 in epoch 6, gen_loss = 0.40918962711311246, disc_loss = 0.04815098273438817
Trained batch 166 in epoch 6, gen_loss = 0.4094247439664281, disc_loss = 0.047878545872075205
Trained batch 167 in epoch 6, gen_loss = 0.40925459279900506, disc_loss = 0.04768382640516696
Trained batch 168 in epoch 6, gen_loss = 0.4091647972722025, disc_loss = 0.04741868179583558
Trained batch 169 in epoch 6, gen_loss = 0.40887017074753257, disc_loss = 0.047264276128536196
Trained batch 170 in epoch 6, gen_loss = 0.4085603684012653, disc_loss = 0.04732089824239282
Trained batch 171 in epoch 6, gen_loss = 0.40924363739268727, disc_loss = 0.04727822534745386
Trained batch 172 in epoch 6, gen_loss = 0.4092164130913729, disc_loss = 0.04706069764767294
Trained batch 173 in epoch 6, gen_loss = 0.40923135838974484, disc_loss = 0.0468112449094803
Trained batch 174 in epoch 6, gen_loss = 0.40945329785346984, disc_loss = 0.046585691271881974
Trained batch 175 in epoch 6, gen_loss = 0.40931536917659367, disc_loss = 0.0463472375506006
Trained batch 176 in epoch 6, gen_loss = 0.4090079316648386, disc_loss = 0.0461076287286998
Trained batch 177 in epoch 6, gen_loss = 0.4092467393767968, disc_loss = 0.0459218100432746
Trained batch 178 in epoch 6, gen_loss = 0.40919576427124066, disc_loss = 0.04569389715702299
Trained batch 179 in epoch 6, gen_loss = 0.4094758922855059, disc_loss = 0.04556485970064791
Trained batch 180 in epoch 6, gen_loss = 0.4096622323792284, disc_loss = 0.04532731441750052
Trained batch 181 in epoch 6, gen_loss = 0.4095160029419176, disc_loss = 0.045113121532927174
Trained batch 182 in epoch 6, gen_loss = 0.40921590758151694, disc_loss = 0.04549603904673799
Trained batch 183 in epoch 6, gen_loss = 0.409192296149938, disc_loss = 0.04610645519468286
Trained batch 184 in epoch 6, gen_loss = 0.40947915557268505, disc_loss = 0.04597556030730138
Trained batch 185 in epoch 6, gen_loss = 0.4092863706811782, disc_loss = 0.04587786798415485
Trained batch 186 in epoch 6, gen_loss = 0.4094115835141371, disc_loss = 0.045663695149920525
Trained batch 187 in epoch 6, gen_loss = 0.40971599550957377, disc_loss = 0.045590384868270856
Trained batch 188 in epoch 6, gen_loss = 0.40940708726171465, disc_loss = 0.0453881999211652
Trained batch 189 in epoch 6, gen_loss = 0.4096450874679967, disc_loss = 0.04519992009001343
Trained batch 190 in epoch 6, gen_loss = 0.4095705524477035, disc_loss = 0.04509955321814065
Trained batch 191 in epoch 6, gen_loss = 0.4097279122409721, disc_loss = 0.04518094170877399
Trained batch 192 in epoch 6, gen_loss = 0.4098345110762305, disc_loss = 0.044994870239357256
Trained batch 193 in epoch 6, gen_loss = 0.4097723429350509, disc_loss = 0.04485220420798383
Trained batch 194 in epoch 6, gen_loss = 0.41013199595304634, disc_loss = 0.044643281285579386
Trained batch 195 in epoch 6, gen_loss = 0.4103112812249028, disc_loss = 0.04444213406353885
Trained batch 196 in epoch 6, gen_loss = 0.4103388382396117, disc_loss = 0.04424310036400702
Trained batch 197 in epoch 6, gen_loss = 0.4100882284569018, disc_loss = 0.04406280837238136
Trained batch 198 in epoch 6, gen_loss = 0.410009627815467, disc_loss = 0.04386385638341682
Trained batch 199 in epoch 6, gen_loss = 0.40998487547039986, disc_loss = 0.043950566886924204
Trained batch 200 in epoch 6, gen_loss = 0.4093801334722718, disc_loss = 0.04572336999838477
Trained batch 201 in epoch 6, gen_loss = 0.40910140801184247, disc_loss = 0.04589683294646663
Trained batch 202 in epoch 6, gen_loss = 0.40915440397309555, disc_loss = 0.045872457632840855
Trained batch 203 in epoch 6, gen_loss = 0.4089694503767818, disc_loss = 0.04578627406290787
Trained batch 204 in epoch 6, gen_loss = 0.40902430168012294, disc_loss = 0.04563344148237531
Trained batch 205 in epoch 6, gen_loss = 0.40888246995152777, disc_loss = 0.04553487309191412
Trained batch 206 in epoch 6, gen_loss = 0.40911442674876414, disc_loss = 0.04558596250731588
Trained batch 207 in epoch 6, gen_loss = 0.4092647943359155, disc_loss = 0.04552529462111684
Trained batch 208 in epoch 6, gen_loss = 0.40912098148793125, disc_loss = 0.0453329289122596
Trained batch 209 in epoch 6, gen_loss = 0.40930794647761753, disc_loss = 0.045216340081588854
Trained batch 210 in epoch 6, gen_loss = 0.40913426960814053, disc_loss = 0.045030464574924156
Trained batch 211 in epoch 6, gen_loss = 0.4090497552786233, disc_loss = 0.04489393688009103
Trained batch 212 in epoch 6, gen_loss = 0.4090854756429162, disc_loss = 0.044711101118107915
Trained batch 213 in epoch 6, gen_loss = 0.4091207731828511, disc_loss = 0.04453468395214284
Trained batch 214 in epoch 6, gen_loss = 0.4095305618851684, disc_loss = 0.04438438975403822
Trained batch 215 in epoch 6, gen_loss = 0.40976487624424474, disc_loss = 0.04429851620915105
Trained batch 216 in epoch 6, gen_loss = 0.40997432069295014, disc_loss = 0.04420219776585423
Trained batch 217 in epoch 6, gen_loss = 0.4098103431933517, disc_loss = 0.044423790693436875
Trained batch 218 in epoch 6, gen_loss = 0.4100439181066539, disc_loss = 0.04453779021533181
Trained batch 219 in epoch 6, gen_loss = 0.4101782630790364, disc_loss = 0.04450499716172503
Trained batch 220 in epoch 6, gen_loss = 0.41026728994706096, disc_loss = 0.044366967997079655
Trained batch 221 in epoch 6, gen_loss = 0.41022900418118313, disc_loss = 0.044229001706667444
Trained batch 222 in epoch 6, gen_loss = 0.41020225649991915, disc_loss = 0.0440607464939122
Trained batch 223 in epoch 6, gen_loss = 0.41004431394061874, disc_loss = 0.04394316883034272
Trained batch 224 in epoch 6, gen_loss = 0.41013512942526076, disc_loss = 0.04376991367795401
Trained batch 225 in epoch 6, gen_loss = 0.40982993738313694, disc_loss = 0.043649669190605
Trained batch 226 in epoch 6, gen_loss = 0.4097657050067633, disc_loss = 0.0435875573786312
Trained batch 227 in epoch 6, gen_loss = 0.40988064413530784, disc_loss = 0.04347732675204609
Trained batch 228 in epoch 6, gen_loss = 0.4097088734135357, disc_loss = 0.0435650964129277
Trained batch 229 in epoch 6, gen_loss = 0.40982796264731364, disc_loss = 0.04420926809594359
Trained batch 230 in epoch 6, gen_loss = 0.4094394104821341, disc_loss = 0.04449387667781282
Trained batch 231 in epoch 6, gen_loss = 0.4095843119611, disc_loss = 0.04434198329971846
Trained batch 232 in epoch 6, gen_loss = 0.4093886694427212, disc_loss = 0.044238717652969224
Trained batch 233 in epoch 6, gen_loss = 0.4092730460768072, disc_loss = 0.044120576608782776
Trained batch 234 in epoch 6, gen_loss = 0.4092114936798177, disc_loss = 0.043976277879815784
Trained batch 235 in epoch 6, gen_loss = 0.4093083414738461, disc_loss = 0.043819310017308946
Trained batch 236 in epoch 6, gen_loss = 0.40914835934900534, disc_loss = 0.043684271568990456
Trained batch 237 in epoch 6, gen_loss = 0.40898943611052857, disc_loss = 0.04351368786360161
Trained batch 238 in epoch 6, gen_loss = 0.40917877634698874, disc_loss = 0.04337782189873472
Trained batch 239 in epoch 6, gen_loss = 0.40924754974742733, disc_loss = 0.0432700760041674
Trained batch 240 in epoch 6, gen_loss = 0.40908142417298315, disc_loss = 0.043130938527927855
Trained batch 241 in epoch 6, gen_loss = 0.40920291003609494, disc_loss = 0.04298030787863392
Trained batch 242 in epoch 6, gen_loss = 0.40916253473042463, disc_loss = 0.042863978172648594
Trained batch 243 in epoch 6, gen_loss = 0.4092265653317092, disc_loss = 0.042727743500660435
Trained batch 244 in epoch 6, gen_loss = 0.4092188696472012, disc_loss = 0.04256255371325022
Trained batch 245 in epoch 6, gen_loss = 0.4093283380919356, disc_loss = 0.042409386946744
Trained batch 246 in epoch 6, gen_loss = 0.4093376430663985, disc_loss = 0.042253056881376184
Trained batch 247 in epoch 6, gen_loss = 0.409480033983146, disc_loss = 0.042093352163999134
Trained batch 248 in epoch 6, gen_loss = 0.4096813948757677, disc_loss = 0.04193354601481832
Trained batch 249 in epoch 6, gen_loss = 0.40975321424007416, disc_loss = 0.04177215858735144
Trained batch 250 in epoch 6, gen_loss = 0.40964174460604846, disc_loss = 0.04161486516435783
Trained batch 251 in epoch 6, gen_loss = 0.4094601905062085, disc_loss = 0.04145557871587308
Trained batch 252 in epoch 6, gen_loss = 0.4094765787068092, disc_loss = 0.041306582065078284
Trained batch 253 in epoch 6, gen_loss = 0.4096677333820523, disc_loss = 0.04115241305906267
Trained batch 254 in epoch 6, gen_loss = 0.40982202466796425, disc_loss = 0.04100066441494753
Trained batch 255 in epoch 6, gen_loss = 0.4098197704879567, disc_loss = 0.04085304912223364
Trained batch 256 in epoch 6, gen_loss = 0.4099363734518044, disc_loss = 0.04070342511685152
Trained batch 257 in epoch 6, gen_loss = 0.4099126790845117, disc_loss = 0.040555508327201124
Trained batch 258 in epoch 6, gen_loss = 0.40965715718085244, disc_loss = 0.04040583870535479
Trained batch 259 in epoch 6, gen_loss = 0.40950608860987886, disc_loss = 0.04025859449846814
Trained batch 260 in epoch 6, gen_loss = 0.40940841233136555, disc_loss = 0.040111512438147916
Trained batch 261 in epoch 6, gen_loss = 0.4091872580861317, disc_loss = 0.03996332029355263
Trained batch 262 in epoch 6, gen_loss = 0.40908158765999536, disc_loss = 0.03982251665878956
Trained batch 263 in epoch 6, gen_loss = 0.4088670559453242, disc_loss = 0.03968295949523577
Trained batch 264 in epoch 6, gen_loss = 0.4090542192729014, disc_loss = 0.03957258256565217
Trained batch 265 in epoch 6, gen_loss = 0.40914501160159145, disc_loss = 0.03944936282783957
Trained batch 266 in epoch 6, gen_loss = 0.4090076396974285, disc_loss = 0.039309136907409614
Trained batch 267 in epoch 6, gen_loss = 0.40909015420657485, disc_loss = 0.03917419595284207
Trained batch 268 in epoch 6, gen_loss = 0.4090336420500589, disc_loss = 0.0390421151954743
Trained batch 269 in epoch 6, gen_loss = 0.40901771905245604, disc_loss = 0.038902582274318705
Trained batch 270 in epoch 6, gen_loss = 0.4090066717119674, disc_loss = 0.038794354832476875
Trained batch 271 in epoch 6, gen_loss = 0.40906830077223916, disc_loss = 0.038683129979129746
Trained batch 272 in epoch 6, gen_loss = 0.40897339244028585, disc_loss = 0.03854870062531228
Trained batch 273 in epoch 6, gen_loss = 0.40929395177938643, disc_loss = 0.03841952539693197
Trained batch 274 in epoch 6, gen_loss = 0.4091598496653817, disc_loss = 0.03829236498229544
Trained batch 275 in epoch 6, gen_loss = 0.4088562840352888, disc_loss = 0.03816429210069212
Trained batch 276 in epoch 6, gen_loss = 0.4088722575012097, disc_loss = 0.03803465525083419
Trained batch 277 in epoch 6, gen_loss = 0.40890433344480803, disc_loss = 0.03790583690961742
Trained batch 278 in epoch 6, gen_loss = 0.4090339443162351, disc_loss = 0.037774870064907366
Trained batch 279 in epoch 6, gen_loss = 0.40886333638003897, disc_loss = 0.03764727739575652
Trained batch 280 in epoch 6, gen_loss = 0.40863937022847213, disc_loss = 0.03751701095640275
Trained batch 281 in epoch 6, gen_loss = 0.40865288378921805, disc_loss = 0.037389148039089395
Trained batch 282 in epoch 6, gen_loss = 0.4085689367127503, disc_loss = 0.0372645720163222
Trained batch 283 in epoch 6, gen_loss = 0.40857432079567035, disc_loss = 0.037138954945348045
Trained batch 284 in epoch 6, gen_loss = 0.4085289826518611, disc_loss = 0.037013606067844915
Trained batch 285 in epoch 6, gen_loss = 0.40829501160374887, disc_loss = 0.036894901321022085
Trained batch 286 in epoch 6, gen_loss = 0.4083403712365685, disc_loss = 0.03677535375648337
Trained batch 287 in epoch 6, gen_loss = 0.40828787173248, disc_loss = 0.036652401022567775
Trained batch 288 in epoch 6, gen_loss = 0.40846620350560514, disc_loss = 0.03653295429433119
Trained batch 289 in epoch 6, gen_loss = 0.40848171382114806, disc_loss = 0.036411597696935825
Trained batch 290 in epoch 6, gen_loss = 0.4084918933226071, disc_loss = 0.03629211170472448
Trained batch 291 in epoch 6, gen_loss = 0.40845248980881416, disc_loss = 0.036174531184433485
Trained batch 292 in epoch 6, gen_loss = 0.40863548936290545, disc_loss = 0.03605677497393607
Trained batch 293 in epoch 6, gen_loss = 0.40869620006506135, disc_loss = 0.03593925392606809
Trained batch 294 in epoch 6, gen_loss = 0.40884971446910146, disc_loss = 0.03582305006043575
Trained batch 295 in epoch 6, gen_loss = 0.4086069086113492, disc_loss = 0.03570766794271893
Trained batch 296 in epoch 6, gen_loss = 0.4085833286797559, disc_loss = 0.035594595670668715
Trained batch 297 in epoch 6, gen_loss = 0.40840101582091926, disc_loss = 0.03547917611993874
Trained batch 298 in epoch 6, gen_loss = 0.40827667284570013, disc_loss = 0.03536587651121278
Trained batch 299 in epoch 6, gen_loss = 0.4083054115374883, disc_loss = 0.03526183515631904
Trained batch 300 in epoch 6, gen_loss = 0.4080647375694541, disc_loss = 0.03515245631318601
Trained batch 301 in epoch 6, gen_loss = 0.40805136180476637, disc_loss = 0.03504293694836242
Trained batch 302 in epoch 6, gen_loss = 0.40800764684629914, disc_loss = 0.0349318048023087
Trained batch 303 in epoch 6, gen_loss = 0.4079513440986997, disc_loss = 0.03482416241719253
Trained batch 304 in epoch 6, gen_loss = 0.4084124951089015, disc_loss = 0.0347690160725968
Trained batch 305 in epoch 6, gen_loss = 0.4083588753455605, disc_loss = 0.034668533866875045
Trained batch 306 in epoch 6, gen_loss = 0.4085476899380016, disc_loss = 0.03456185696948417
Trained batch 307 in epoch 6, gen_loss = 0.408428097603383, disc_loss = 0.034457241592841074
Trained batch 308 in epoch 6, gen_loss = 0.4084016920872105, disc_loss = 0.03435943258623367
Trained batch 309 in epoch 6, gen_loss = 0.40819513134417995, disc_loss = 0.03425288885764237
Trained batch 310 in epoch 6, gen_loss = 0.4082394196289529, disc_loss = 0.034150904637066666
Trained batch 311 in epoch 6, gen_loss = 0.40825127323086446, disc_loss = 0.03404726429046908
Trained batch 312 in epoch 6, gen_loss = 0.4082912627500467, disc_loss = 0.033943033876483696
Trained batch 313 in epoch 6, gen_loss = 0.4082991230260035, disc_loss = 0.033839585362254364
Trained batch 314 in epoch 6, gen_loss = 0.4083259707405454, disc_loss = 0.0337400011707186
Trained batch 315 in epoch 6, gen_loss = 0.40827652745986287, disc_loss = 0.03363744933504458
Trained batch 316 in epoch 6, gen_loss = 0.4084548999082403, disc_loss = 0.033536984098631574
Trained batch 317 in epoch 6, gen_loss = 0.4084566501701403, disc_loss = 0.0334353316934053
Trained batch 318 in epoch 6, gen_loss = 0.4083100065915936, disc_loss = 0.0333370142477655
Trained batch 319 in epoch 6, gen_loss = 0.40837811324745416, disc_loss = 0.03324101504622377
Trained batch 320 in epoch 6, gen_loss = 0.40818967783933857, disc_loss = 0.033143880614587264
Trained batch 321 in epoch 6, gen_loss = 0.40807430770086206, disc_loss = 0.033047845783811175
Trained batch 322 in epoch 6, gen_loss = 0.40811310906897386, disc_loss = 0.032950521572911104
Trained batch 323 in epoch 6, gen_loss = 0.4082481038791162, disc_loss = 0.03285605643004938
Trained batch 324 in epoch 6, gen_loss = 0.40822279673356276, disc_loss = 0.03276188063506897
Trained batch 325 in epoch 6, gen_loss = 0.40829643963670437, disc_loss = 0.032666898520014885
Trained batch 326 in epoch 6, gen_loss = 0.4082242232214785, disc_loss = 0.03257658908361518
Trained batch 327 in epoch 6, gen_loss = 0.4082552342698341, disc_loss = 0.03248766853677097
Trained batch 328 in epoch 6, gen_loss = 0.40849843086805027, disc_loss = 0.032397387481696543
Trained batch 329 in epoch 6, gen_loss = 0.4083721715392488, disc_loss = 0.032304798572140775
Trained batch 330 in epoch 6, gen_loss = 0.40843643657750595, disc_loss = 0.032211356259969674
Trained batch 331 in epoch 6, gen_loss = 0.40832479953406803, disc_loss = 0.032118112194570655
Trained batch 332 in epoch 6, gen_loss = 0.40860988920157376, disc_loss = 0.03202988952887734
Trained batch 333 in epoch 6, gen_loss = 0.40843578726945523, disc_loss = 0.031951577843914176
Trained batch 334 in epoch 6, gen_loss = 0.40829267475142406, disc_loss = 0.03186519980472304
Trained batch 335 in epoch 6, gen_loss = 0.4084301130580051, disc_loss = 0.03177801757590801
Trained batch 336 in epoch 6, gen_loss = 0.4084985815099156, disc_loss = 0.03169603975357084
Trained batch 337 in epoch 6, gen_loss = 0.40846337704263497, disc_loss = 0.03161205754191036
Trained batch 338 in epoch 6, gen_loss = 0.4085449088463741, disc_loss = 0.03153050479075286
Trained batch 339 in epoch 6, gen_loss = 0.4085688236881705, disc_loss = 0.0314466863822685
Trained batch 340 in epoch 6, gen_loss = 0.40895319194737767, disc_loss = 0.031362938723332984
Trained batch 341 in epoch 6, gen_loss = 0.40902505928312827, disc_loss = 0.031279427937520615
Trained batch 342 in epoch 6, gen_loss = 0.40886953820640076, disc_loss = 0.03119142438249755
Trained batch 343 in epoch 6, gen_loss = 0.4087190323964108, disc_loss = 0.03110451332894479
Trained batch 344 in epoch 6, gen_loss = 0.4086906712124313, disc_loss = 0.031040676490174255
Trained batch 345 in epoch 6, gen_loss = 0.4086871374549204, disc_loss = 0.030955241068476285
Trained batch 346 in epoch 6, gen_loss = 0.4088261830016584, disc_loss = 0.0308830610594527
Trained batch 347 in epoch 6, gen_loss = 0.40883566584737824, disc_loss = 0.030803218708726866
Trained batch 348 in epoch 6, gen_loss = 0.4088975494263165, disc_loss = 0.0307347670725859
Trained batch 349 in epoch 6, gen_loss = 0.4089112445286342, disc_loss = 0.030650870185345413
Trained batch 350 in epoch 6, gen_loss = 0.4088502171372416, disc_loss = 0.030566984707983132
Trained batch 351 in epoch 6, gen_loss = 0.40882976327768783, disc_loss = 0.030485762473042334
Trained batch 352 in epoch 6, gen_loss = 0.4087606008262202, disc_loss = 0.030408370682558115
Trained batch 353 in epoch 6, gen_loss = 0.40863281345300084, disc_loss = 0.03033058232388401
Trained batch 354 in epoch 6, gen_loss = 0.40880224948198024, disc_loss = 0.03026586900806238
Trained batch 355 in epoch 6, gen_loss = 0.40895270447382764, disc_loss = 0.03021087250188307
Trained batch 356 in epoch 6, gen_loss = 0.40890237446926553, disc_loss = 0.030147918178478166
Trained batch 357 in epoch 6, gen_loss = 0.4087073291813195, disc_loss = 0.030103788247420427
Trained batch 358 in epoch 6, gen_loss = 0.4087531913621844, disc_loss = 0.030056530419700783
Trained batch 359 in epoch 6, gen_loss = 0.4088846660322613, disc_loss = 0.02999742208242727
Trained batch 360 in epoch 6, gen_loss = 0.4087600149936623, disc_loss = 0.029967700378257276
Trained batch 361 in epoch 6, gen_loss = 0.40853448294473615, disc_loss = 0.029923535188150628
Trained batch 362 in epoch 6, gen_loss = 0.408557466977884, disc_loss = 0.02998269842385979
Trained batch 363 in epoch 6, gen_loss = 0.40828578910984836, disc_loss = 0.030222507750815048
Trained batch 364 in epoch 6, gen_loss = 0.4084565020587346, disc_loss = 0.03079924057237804
Trained batch 365 in epoch 6, gen_loss = 0.40852781690535, disc_loss = 0.0307346129366273
Trained batch 366 in epoch 6, gen_loss = 0.4084632408878784, disc_loss = 0.03068227492392124
Trained batch 367 in epoch 6, gen_loss = 0.4083428601531879, disc_loss = 0.030616596958007784
Trained batch 368 in epoch 6, gen_loss = 0.4081868643198556, disc_loss = 0.030544008172513428
Trained batch 369 in epoch 6, gen_loss = 0.4081356401379044, disc_loss = 0.030475502687732917
Trained batch 370 in epoch 6, gen_loss = 0.4080764614346856, disc_loss = 0.030413572947592588
Trained batch 371 in epoch 6, gen_loss = 0.4079937882801538, disc_loss = 0.030343435279103697
Trained batch 372 in epoch 6, gen_loss = 0.40799827126651284, disc_loss = 0.0302714510151652
Trained batch 373 in epoch 6, gen_loss = 0.40783126875359743, disc_loss = 0.03019983490012626
Trained batch 374 in epoch 6, gen_loss = 0.40771007084846494, disc_loss = 0.030126561709990105
Trained batch 375 in epoch 6, gen_loss = 0.40761757689587613, disc_loss = 0.03005058646042326
Trained batch 376 in epoch 6, gen_loss = 0.4075914354950427, disc_loss = 0.02997864592932807
Trained batch 377 in epoch 6, gen_loss = 0.4074893284727026, disc_loss = 0.02990566601849866
Trained batch 378 in epoch 6, gen_loss = 0.40742984288286094, disc_loss = 0.029833092392633587
Trained batch 379 in epoch 6, gen_loss = 0.40757846212700793, disc_loss = 0.029773970239023728
Trained batch 380 in epoch 6, gen_loss = 0.40736724940810615, disc_loss = 0.029709059634157934
Trained batch 381 in epoch 6, gen_loss = 0.4072958198985504, disc_loss = 0.029644623066296224
Trained batch 382 in epoch 6, gen_loss = 0.40731050770525523, disc_loss = 0.029577003540556306
Trained batch 383 in epoch 6, gen_loss = 0.40734992261665565, disc_loss = 0.029505212119753804
Trained batch 384 in epoch 6, gen_loss = 0.407389480417425, disc_loss = 0.02943399788648519
Trained batch 385 in epoch 6, gen_loss = 0.40734940443014234, disc_loss = 0.029361834314982335
Trained batch 386 in epoch 6, gen_loss = 0.40730876146360884, disc_loss = 0.02928917445585334
Trained batch 387 in epoch 6, gen_loss = 0.40730979792850536, disc_loss = 0.029217315927152664
Trained batch 388 in epoch 6, gen_loss = 0.4073957242358926, disc_loss = 0.029148001081350912
Trained batch 389 in epoch 6, gen_loss = 0.40736031203697887, disc_loss = 0.0290772535927737
Trained batch 390 in epoch 6, gen_loss = 0.4074363567487663, disc_loss = 0.029009604684846556
Trained batch 391 in epoch 6, gen_loss = 0.40740152197528856, disc_loss = 0.0289391554317114
Trained batch 392 in epoch 6, gen_loss = 0.4074385568840813, disc_loss = 0.02886833979762408
Trained batch 393 in epoch 6, gen_loss = 0.4072853267797964, disc_loss = 0.028798925066319515
Trained batch 394 in epoch 6, gen_loss = 0.40724636768992944, disc_loss = 0.02872935470158258
Trained batch 395 in epoch 6, gen_loss = 0.4070875003482356, disc_loss = 0.028660209820079007
Trained batch 396 in epoch 6, gen_loss = 0.40700115259708625, disc_loss = 0.028591317179206974
Trained batch 397 in epoch 6, gen_loss = 0.4069598773915564, disc_loss = 0.028522885212061654
Trained batch 398 in epoch 6, gen_loss = 0.4069135392967023, disc_loss = 0.028457508384504525
Trained batch 399 in epoch 6, gen_loss = 0.40687682792544366, disc_loss = 0.028391130037489345
Trained batch 400 in epoch 6, gen_loss = 0.4067892528085637, disc_loss = 0.02832322796583733
Trained batch 401 in epoch 6, gen_loss = 0.4068538825310285, disc_loss = 0.028258014765141802
Trained batch 402 in epoch 6, gen_loss = 0.40672686681262316, disc_loss = 0.028191189279620336
Trained batch 403 in epoch 6, gen_loss = 0.40665076259929356, disc_loss = 0.028128760528236645
Trained batch 404 in epoch 6, gen_loss = 0.40685330231984457, disc_loss = 0.02806600294691039
Trained batch 405 in epoch 6, gen_loss = 0.40676769394005463, disc_loss = 0.028002382200176878
Trained batch 406 in epoch 6, gen_loss = 0.4067753992736779, disc_loss = 0.0279405280648495
Trained batch 407 in epoch 6, gen_loss = 0.40677795135507394, disc_loss = 0.02787792987752861
Trained batch 408 in epoch 6, gen_loss = 0.40669884592804756, disc_loss = 0.027812746492633482
Trained batch 409 in epoch 6, gen_loss = 0.40674131505373046, disc_loss = 0.02774792281831274
Trained batch 410 in epoch 6, gen_loss = 0.4065516104518352, disc_loss = 0.027683962555432245
Trained batch 411 in epoch 6, gen_loss = 0.4064265559743909, disc_loss = 0.027620255911227732
Trained batch 412 in epoch 6, gen_loss = 0.4063683619799395, disc_loss = 0.027556203766308778
Trained batch 413 in epoch 6, gen_loss = 0.4062368899295871, disc_loss = 0.027492159587254632
Trained batch 414 in epoch 6, gen_loss = 0.40621368138186903, disc_loss = 0.02742830071295331
Trained batch 415 in epoch 6, gen_loss = 0.40604632885123676, disc_loss = 0.027364379883902775
Trained batch 416 in epoch 6, gen_loss = 0.40608435912097957, disc_loss = 0.027301250067506014
Trained batch 417 in epoch 6, gen_loss = 0.40612429109486664, disc_loss = 0.027239977529731414
Trained batch 418 in epoch 6, gen_loss = 0.4059630476631811, disc_loss = 0.027177832881766673
Trained batch 419 in epoch 6, gen_loss = 0.4060324231783549, disc_loss = 0.027117483493306543
Trained batch 420 in epoch 6, gen_loss = 0.40586510159057565, disc_loss = 0.02705811034979834
Trained batch 421 in epoch 6, gen_loss = 0.4058023379029821, disc_loss = 0.026997539852867212
Trained batch 422 in epoch 6, gen_loss = 0.40563911157296906, disc_loss = 0.026935994166310602
Trained batch 423 in epoch 6, gen_loss = 0.40549153785379427, disc_loss = 0.02687547761888709
Trained batch 424 in epoch 6, gen_loss = 0.4053496169342714, disc_loss = 0.026814916958648932
Trained batch 425 in epoch 6, gen_loss = 0.4052832346287132, disc_loss = 0.026755142518911652
Trained batch 426 in epoch 6, gen_loss = 0.40526303474462005, disc_loss = 0.026694847496861126
Trained batch 427 in epoch 6, gen_loss = 0.4053545768294379, disc_loss = 0.02663664511327684
Trained batch 428 in epoch 6, gen_loss = 0.40527834592165646, disc_loss = 0.026579178143281812
Trained batch 429 in epoch 6, gen_loss = 0.4052356531453687, disc_loss = 0.026519351126084667
Trained batch 430 in epoch 6, gen_loss = 0.4052554774173728, disc_loss = 0.02646177097411692
Trained batch 431 in epoch 6, gen_loss = 0.4051430934557208, disc_loss = 0.026403964781719778
Trained batch 432 in epoch 6, gen_loss = 0.4049639276489099, disc_loss = 0.026347577953646627
Trained batch 433 in epoch 6, gen_loss = 0.4049899111145652, disc_loss = 0.02628947145193987
Trained batch 434 in epoch 6, gen_loss = 0.4049956392967838, disc_loss = 0.026233194976370652
Trained batch 435 in epoch 6, gen_loss = 0.4047458386475887, disc_loss = 0.02618650919912648
Trained batch 436 in epoch 6, gen_loss = 0.4045175785876521, disc_loss = 0.026130157557222353
Trained batch 437 in epoch 6, gen_loss = 0.4043996936926559, disc_loss = 0.026074339718861955
Trained batch 438 in epoch 6, gen_loss = 0.40438153267178284, disc_loss = 0.026019276506405384
Trained batch 439 in epoch 6, gen_loss = 0.40442281263795765, disc_loss = 0.025963916757609694
Trained batch 440 in epoch 6, gen_loss = 0.4044849081239462, disc_loss = 0.025907920504014203
Trained batch 441 in epoch 6, gen_loss = 0.4044789360389451, disc_loss = 0.025851386324797516
Trained batch 442 in epoch 6, gen_loss = 0.4043241915530599, disc_loss = 0.02579506752359771
Trained batch 443 in epoch 6, gen_loss = 0.4042906702772991, disc_loss = 0.025739224707059614
Trained batch 444 in epoch 6, gen_loss = 0.4043365246794197, disc_loss = 0.02568347032412133
Trained batch 445 in epoch 6, gen_loss = 0.40420179042313664, disc_loss = 0.02562873514532007
Trained batch 446 in epoch 6, gen_loss = 0.40417223222037024, disc_loss = 0.025576841603897896
Trained batch 447 in epoch 6, gen_loss = 0.40419674811086487, disc_loss = 0.025524946047101236
Trained batch 448 in epoch 6, gen_loss = 0.40417472570138946, disc_loss = 0.025472072306252966
Trained batch 449 in epoch 6, gen_loss = 0.4040457847383287, disc_loss = 0.025418715273909685
Trained batch 450 in epoch 6, gen_loss = 0.4042057129998429, disc_loss = 0.025369478647489754
Trained batch 451 in epoch 6, gen_loss = 0.40432406243233554, disc_loss = 0.02531732664782496
Trained batch 452 in epoch 6, gen_loss = 0.4042539868923212, disc_loss = 0.025264543254508186
Trained batch 453 in epoch 6, gen_loss = 0.4043464077070421, disc_loss = 0.02521140463773309
Trained batch 454 in epoch 6, gen_loss = 0.404382954455994, disc_loss = 0.025160616281657264
Trained batch 455 in epoch 6, gen_loss = 0.4043845177481049, disc_loss = 0.025108129072019404
Trained batch 456 in epoch 6, gen_loss = 0.40438229999865694, disc_loss = 0.02505576515700709
Trained batch 457 in epoch 6, gen_loss = 0.40420902426065836, disc_loss = 0.025004002784671644
Trained batch 458 in epoch 6, gen_loss = 0.40461200540621556, disc_loss = 0.025030511245232943
Testing Epoch 6
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:30:46,790
------------------------------------------------------------
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.3578867018222809, disc_loss = 0.004663607571274042
Trained batch 1 in epoch 7, gen_loss = 0.3753548711538315, disc_loss = 0.004415384028106928
Trained batch 2 in epoch 7, gen_loss = 0.3933717409769694, disc_loss = 0.0035983544463912645
Trained batch 3 in epoch 7, gen_loss = 0.39594337344169617, disc_loss = 0.003599288815166801
Trained batch 4 in epoch 7, gen_loss = 0.40013574361801146, disc_loss = 0.003320046840235591
Trained batch 5 in epoch 7, gen_loss = 0.3889001707235972, disc_loss = 0.0030008378283431134
Trained batch 6 in epoch 7, gen_loss = 0.38670039602688383, disc_loss = 0.00274844332930765
Trained batch 7 in epoch 7, gen_loss = 0.38905005156993866, disc_loss = 0.002643926505697891
Trained batch 8 in epoch 7, gen_loss = 0.38480500711335075, disc_loss = 0.0024985344821794164
Trained batch 9 in epoch 7, gen_loss = 0.3839119702577591, disc_loss = 0.0023531247512437402
Trained batch 10 in epoch 7, gen_loss = 0.38004022565754975, disc_loss = 0.0022797184382480655
Trained batch 11 in epoch 7, gen_loss = 0.37964861591657, disc_loss = 0.0021794843390428773
Trained batch 12 in epoch 7, gen_loss = 0.37787556189757127, disc_loss = 0.0020905811285886625
Trained batch 13 in epoch 7, gen_loss = 0.3832152251686369, disc_loss = 0.0020445514154354377
Trained batch 14 in epoch 7, gen_loss = 0.38437719543774923, disc_loss = 0.001972351223230362
Trained batch 15 in epoch 7, gen_loss = 0.3837143871933222, disc_loss = 0.0019043450593017042
Trained batch 16 in epoch 7, gen_loss = 0.3818935173399308, disc_loss = 0.0018389220760368248
Trained batch 17 in epoch 7, gen_loss = 0.3818667812479867, disc_loss = 0.0017808495128216844
Trained batch 18 in epoch 7, gen_loss = 0.38391709327697754, disc_loss = 0.001786827949169827
Trained batch 19 in epoch 7, gen_loss = 0.3826690152287483, disc_loss = 0.0017712680681142956
Trained batch 20 in epoch 7, gen_loss = 0.3831337108498528, disc_loss = 0.00173079056964655
Trained batch 21 in epoch 7, gen_loss = 0.3804511495611884, disc_loss = 0.0017167482477485794
Trained batch 22 in epoch 7, gen_loss = 0.37986392560212506, disc_loss = 0.0016948012660419488
Trained batch 23 in epoch 7, gen_loss = 0.3789142183959484, disc_loss = 0.0016564794423175044
Trained batch 24 in epoch 7, gen_loss = 0.37768176913261414, disc_loss = 0.0016238927678205073
Trained batch 25 in epoch 7, gen_loss = 0.3763808516355661, disc_loss = 0.001606515691561911
Trained batch 26 in epoch 7, gen_loss = 0.3769150420471474, disc_loss = 0.0015981830807437222
Trained batch 27 in epoch 7, gen_loss = 0.37688051589897703, disc_loss = 0.0015739845028812332
Trained batch 28 in epoch 7, gen_loss = 0.37941287509326277, disc_loss = 0.001581650395909774
Trained batch 29 in epoch 7, gen_loss = 0.37874588668346404, disc_loss = 0.0015739550115540623
Trained batch 30 in epoch 7, gen_loss = 0.37699771792657916, disc_loss = 0.0015821312854607259
Trained batch 31 in epoch 7, gen_loss = 0.3773858919739723, disc_loss = 0.001584859175636666
Trained batch 32 in epoch 7, gen_loss = 0.37753312154249713, disc_loss = 0.0015854656865650957
Trained batch 33 in epoch 7, gen_loss = 0.3773832373759326, disc_loss = 0.0015653651635682978
Trained batch 34 in epoch 7, gen_loss = 0.3789146687303271, disc_loss = 0.001574898263373013
Trained batch 35 in epoch 7, gen_loss = 0.38095344520277447, disc_loss = 0.0015680639884926172
Trained batch 36 in epoch 7, gen_loss = 0.38105427493920196, disc_loss = 0.0015611701843177748
Trained batch 37 in epoch 7, gen_loss = 0.3839848417984812, disc_loss = 0.0015514201751150388
Trained batch 38 in epoch 7, gen_loss = 0.38272875470992845, disc_loss = 0.0015590536387231296
Trained batch 39 in epoch 7, gen_loss = 0.3826492764055729, disc_loss = 0.0015430855026352219
Trained batch 40 in epoch 7, gen_loss = 0.3832564157683675, disc_loss = 0.001540271183419064
Trained batch 41 in epoch 7, gen_loss = 0.3840834555171785, disc_loss = 0.0015275883640805702
Trained batch 42 in epoch 7, gen_loss = 0.3851747131624887, disc_loss = 0.0015279219017450719
Trained batch 43 in epoch 7, gen_loss = 0.38523145290938293, disc_loss = 0.001518022180376151
Trained batch 44 in epoch 7, gen_loss = 0.385934884680642, disc_loss = 0.0015092363024854826
Trained batch 45 in epoch 7, gen_loss = 0.3865506668453631, disc_loss = 0.0015007246288207723
Trained batch 46 in epoch 7, gen_loss = 0.3872612841585849, disc_loss = 0.0014886299527170968
Trained batch 47 in epoch 7, gen_loss = 0.38750936339298886, disc_loss = 0.0014864692117650218
Trained batch 48 in epoch 7, gen_loss = 0.38735554352098583, disc_loss = 0.001482155783415525
Trained batch 49 in epoch 7, gen_loss = 0.38768821954727173, disc_loss = 0.0014920230687130243
Trained batch 50 in epoch 7, gen_loss = 0.38882774056172836, disc_loss = 0.0014908476835390663
Trained batch 51 in epoch 7, gen_loss = 0.3898597445625525, disc_loss = 0.0015110743082074735
Trained batch 52 in epoch 7, gen_loss = 0.3900863421413134, disc_loss = 0.0015363610659304232
Trained batch 53 in epoch 7, gen_loss = 0.3902577531558496, disc_loss = 0.0015459666513682653
Trained batch 54 in epoch 7, gen_loss = 0.3896205409006639, disc_loss = 0.0016277671421200714
Trained batch 55 in epoch 7, gen_loss = 0.3893715984054974, disc_loss = 0.0017831184055207164
Trained batch 56 in epoch 7, gen_loss = 0.3900020540806285, disc_loss = 0.0018308404884137736
Trained batch 57 in epoch 7, gen_loss = 0.3892651030729557, disc_loss = 0.0028974071259465837
Trained batch 58 in epoch 7, gen_loss = 0.3895315199585284, disc_loss = 0.0032437787898342615
Trained batch 59 in epoch 7, gen_loss = 0.3890561853845914, disc_loss = 0.0034008758811978623
Trained batch 60 in epoch 7, gen_loss = 0.38758058039868465, disc_loss = 0.003950860661446865
Trained batch 61 in epoch 7, gen_loss = 0.3883283109434189, disc_loss = 0.004264074322324426
Trained batch 62 in epoch 7, gen_loss = 0.3892251205822778, disc_loss = 0.004475035398851134
Trained batch 63 in epoch 7, gen_loss = 0.3891693032346666, disc_loss = 0.007392337579403829
Trained batch 64 in epoch 7, gen_loss = 0.3902571806540856, disc_loss = 0.012883717771798659
Trained batch 65 in epoch 7, gen_loss = 0.3893090734879176, disc_loss = 0.012928841244887955
Trained batch 66 in epoch 7, gen_loss = 0.38888533924942587, disc_loss = 0.013168607578689316
Trained batch 67 in epoch 7, gen_loss = 0.39016789329402585, disc_loss = 0.013099224940935314
Trained batch 68 in epoch 7, gen_loss = 0.38990019413008203, disc_loss = 0.013400489954527575
Trained batch 69 in epoch 7, gen_loss = 0.3894177364451545, disc_loss = 0.013481248041249014
Trained batch 70 in epoch 7, gen_loss = 0.3895709858813756, disc_loss = 0.013486659538794413
Trained batch 71 in epoch 7, gen_loss = 0.38965248730447555, disc_loss = 0.01359264970799106
Trained batch 72 in epoch 7, gen_loss = 0.38994642194003276, disc_loss = 0.013462493519062712
Trained batch 73 in epoch 7, gen_loss = 0.3904534582350705, disc_loss = 0.013695772074169252
Trained batch 74 in epoch 7, gen_loss = 0.38918411612510684, disc_loss = 0.015942447624014068
Trained batch 75 in epoch 7, gen_loss = 0.3890883812778874, disc_loss = 0.0230280808333957
Trained batch 76 in epoch 7, gen_loss = 0.3887037669683432, disc_loss = 0.02506682900001307
Trained batch 77 in epoch 7, gen_loss = 0.38802392054826784, disc_loss = 0.026605970815021116
Trained batch 78 in epoch 7, gen_loss = 0.38736106926881814, disc_loss = 0.027174679389300085
Trained batch 79 in epoch 7, gen_loss = 0.3874552108347416, disc_loss = 0.027158062477974455
Trained batch 80 in epoch 7, gen_loss = 0.38864834220321093, disc_loss = 0.026990483311597074
Trained batch 81 in epoch 7, gen_loss = 0.3891190464903669, disc_loss = 0.026767495557489782
Trained batch 82 in epoch 7, gen_loss = 0.38914895344929523, disc_loss = 0.026551413151340176
Trained batch 83 in epoch 7, gen_loss = 0.38970114361672176, disc_loss = 0.02627612232200114
Trained batch 84 in epoch 7, gen_loss = 0.3898180628524107, disc_loss = 0.026078753784874127
Trained batch 85 in epoch 7, gen_loss = 0.39049081019190857, disc_loss = 0.02585948898448869
Trained batch 86 in epoch 7, gen_loss = 0.39104132165854005, disc_loss = 0.02563594704314574
Trained batch 87 in epoch 7, gen_loss = 0.3912235247817906, disc_loss = 0.025376127012185116
Trained batch 88 in epoch 7, gen_loss = 0.39067589299062666, disc_loss = 0.02524363688583057
Trained batch 89 in epoch 7, gen_loss = 0.3901551316181819, disc_loss = 0.025061124734606387
Trained batch 90 in epoch 7, gen_loss = 0.390079276902335, disc_loss = 0.024828582089317573
Trained batch 91 in epoch 7, gen_loss = 0.3904504150800083, disc_loss = 0.024628937946070673
Trained batch 92 in epoch 7, gen_loss = 0.3899477133827825, disc_loss = 0.02449707859458642
Trained batch 93 in epoch 7, gen_loss = 0.3897905752379843, disc_loss = 0.02448364783467309
Trained batch 94 in epoch 7, gen_loss = 0.38908910218038056, disc_loss = 0.024377332699460616
Trained batch 95 in epoch 7, gen_loss = 0.3887962708249688, disc_loss = 0.02427708648914025
Trained batch 96 in epoch 7, gen_loss = 0.38971676623698365, disc_loss = 0.02527769298122274
Trained batch 97 in epoch 7, gen_loss = 0.388648584485054, disc_loss = 0.030604550161764825
Trained batch 98 in epoch 7, gen_loss = 0.3891646425531368, disc_loss = 0.031148225711682114
Trained batch 99 in epoch 7, gen_loss = 0.3891448977589607, disc_loss = 0.031937397162546406
Trained batch 100 in epoch 7, gen_loss = 0.3882075530467647, disc_loss = 0.03421267487470632
Trained batch 101 in epoch 7, gen_loss = 0.38802347843553503, disc_loss = 0.03476543158724192
Trained batch 102 in epoch 7, gen_loss = 0.3889248666254062, disc_loss = 0.03485779573031005
Trained batch 103 in epoch 7, gen_loss = 0.38939271150873256, disc_loss = 0.035472390961121376
Trained batch 104 in epoch 7, gen_loss = 0.3893399320897602, disc_loss = 0.035973464239144784
Trained batch 105 in epoch 7, gen_loss = 0.38960771571915104, disc_loss = 0.035742983655270434
Trained batch 106 in epoch 7, gen_loss = 0.3902702069728174, disc_loss = 0.035634838508672696
Trained batch 107 in epoch 7, gen_loss = 0.389933867862931, disc_loss = 0.03556359776013306
Trained batch 108 in epoch 7, gen_loss = 0.3900107191790135, disc_loss = 0.035566815194874625
Trained batch 109 in epoch 7, gen_loss = 0.3902010454372926, disc_loss = 0.03539958346730352
Trained batch 110 in epoch 7, gen_loss = 0.39032218182409134, disc_loss = 0.03511427207440893
Trained batch 111 in epoch 7, gen_loss = 0.38987170505736557, disc_loss = 0.03488083363845362
Trained batch 112 in epoch 7, gen_loss = 0.389678004568657, disc_loss = 0.03459886085310028
Trained batch 113 in epoch 7, gen_loss = 0.38957632947386356, disc_loss = 0.03438586182534907
Trained batch 114 in epoch 7, gen_loss = 0.3891663893409397, disc_loss = 0.03417875495911373
Trained batch 115 in epoch 7, gen_loss = 0.38926723445283956, disc_loss = 0.033945508129144056
Trained batch 116 in epoch 7, gen_loss = 0.38922998869520986, disc_loss = 0.0339901681843166
Trained batch 117 in epoch 7, gen_loss = 0.3900785383026479, disc_loss = 0.03576676195962907
Trained batch 118 in epoch 7, gen_loss = 0.3895481834892465, disc_loss = 0.04039221628375367
Trained batch 119 in epoch 7, gen_loss = 0.38923098271091777, disc_loss = 0.04083536523830844
Trained batch 120 in epoch 7, gen_loss = 0.38949379792883376, disc_loss = 0.04144077479102349
Trained batch 121 in epoch 7, gen_loss = 0.3888917594659524, disc_loss = 0.04169426860381299
Trained batch 122 in epoch 7, gen_loss = 0.3886448786995275, disc_loss = 0.043430278233415255
Trained batch 123 in epoch 7, gen_loss = 0.3893797568255855, disc_loss = 0.044062029108904575
Trained batch 124 in epoch 7, gen_loss = 0.3898386125564575, disc_loss = 0.044699884314555675
Trained batch 125 in epoch 7, gen_loss = 0.39066266682412887, disc_loss = 0.04550391011769765
Trained batch 126 in epoch 7, gen_loss = 0.39058022682122356, disc_loss = 0.04583560794593737
Trained batch 127 in epoch 7, gen_loss = 0.3904542962554842, disc_loss = 0.045854955319100554
Trained batch 128 in epoch 7, gen_loss = 0.3908256003560946, disc_loss = 0.04573691342172191
Trained batch 129 in epoch 7, gen_loss = 0.39094580228512105, disc_loss = 0.045586248204703084
Trained batch 130 in epoch 7, gen_loss = 0.3904790932895573, disc_loss = 0.045407139934787795
Trained batch 131 in epoch 7, gen_loss = 0.38971494047930744, disc_loss = 0.04528363622331667
Trained batch 132 in epoch 7, gen_loss = 0.38968260171718166, disc_loss = 0.0450683479845923
Trained batch 133 in epoch 7, gen_loss = 0.39031860054428896, disc_loss = 0.04507838062109745
Trained batch 134 in epoch 7, gen_loss = 0.3905634025732676, disc_loss = 0.04507677892128144
Trained batch 135 in epoch 7, gen_loss = 0.3910673004301155, disc_loss = 0.04487057568835821
Trained batch 136 in epoch 7, gen_loss = 0.39160472807222907, disc_loss = 0.04460524111335254
Trained batch 137 in epoch 7, gen_loss = 0.39178640902906225, disc_loss = 0.04465487827859023
Trained batch 138 in epoch 7, gen_loss = 0.3919378405423473, disc_loss = 0.04523023187472626
Trained batch 139 in epoch 7, gen_loss = 0.39212475568056104, disc_loss = 0.044972705891372505
Trained batch 140 in epoch 7, gen_loss = 0.39225624026136197, disc_loss = 0.04494729896731582
Trained batch 141 in epoch 7, gen_loss = 0.392483769797943, disc_loss = 0.04472887599029132
Trained batch 142 in epoch 7, gen_loss = 0.3924146853126846, disc_loss = 0.04443960891868854
Trained batch 143 in epoch 7, gen_loss = 0.3925371898545159, disc_loss = 0.04418135719970451
Trained batch 144 in epoch 7, gen_loss = 0.3931486061934767, disc_loss = 0.043981302629530046
Trained batch 145 in epoch 7, gen_loss = 0.39354209724354416, disc_loss = 0.043771801130887605
Trained batch 146 in epoch 7, gen_loss = 0.39385566115379333, disc_loss = 0.04381412746373653
Trained batch 147 in epoch 7, gen_loss = 0.3936140519138929, disc_loss = 0.04462221720156801
Trained batch 148 in epoch 7, gen_loss = 0.3936868864017845, disc_loss = 0.045836645907069234
Trained batch 149 in epoch 7, gen_loss = 0.3943973066409429, disc_loss = 0.0456040278049962
Trained batch 150 in epoch 7, gen_loss = 0.39457852418059547, disc_loss = 0.04552549644048011
Trained batch 151 in epoch 7, gen_loss = 0.39430415277418335, disc_loss = 0.0453485633146269
Trained batch 152 in epoch 7, gen_loss = 0.3944083869067672, disc_loss = 0.04514860799817636
Trained batch 153 in epoch 7, gen_loss = 0.3947491699999029, disc_loss = 0.04490920245479611
Trained batch 154 in epoch 7, gen_loss = 0.39500400347094383, disc_loss = 0.044963420588418
Trained batch 155 in epoch 7, gen_loss = 0.3955831365325512, disc_loss = 0.04508120232024409
Trained batch 156 in epoch 7, gen_loss = 0.3951824117618002, disc_loss = 0.04560379408467502
Trained batch 157 in epoch 7, gen_loss = 0.3953571202634256, disc_loss = 0.0465974737923221
Trained batch 158 in epoch 7, gen_loss = 0.3957036632411885, disc_loss = 0.04645063354137336
Trained batch 159 in epoch 7, gen_loss = 0.3949080236256123, disc_loss = 0.0463137390648626
Trained batch 160 in epoch 7, gen_loss = 0.39450458395555155, disc_loss = 0.04651338191484593
Trained batch 161 in epoch 7, gen_loss = 0.39456566984270824, disc_loss = 0.046409797921193256
Trained batch 162 in epoch 7, gen_loss = 0.3950366067008738, disc_loss = 0.04621161224264823
Trained batch 163 in epoch 7, gen_loss = 0.39510148709140175, disc_loss = 0.046136869399072945
Trained batch 164 in epoch 7, gen_loss = 0.3947720421083046, disc_loss = 0.046427957812733386
Trained batch 165 in epoch 7, gen_loss = 0.3951755638223097, disc_loss = 0.04751061877910418
Trained batch 166 in epoch 7, gen_loss = 0.39518339155676835, disc_loss = 0.04736583741015091
Trained batch 167 in epoch 7, gen_loss = 0.39507677796341123, disc_loss = 0.04717807335137401
Trained batch 168 in epoch 7, gen_loss = 0.39508764419329945, disc_loss = 0.0470380572324547
Trained batch 169 in epoch 7, gen_loss = 0.39470600661109473, disc_loss = 0.0470655945050941
Trained batch 170 in epoch 7, gen_loss = 0.39479904791765047, disc_loss = 0.04728653100870648
Trained batch 171 in epoch 7, gen_loss = 0.3942059030713037, disc_loss = 0.047357200729176076
Trained batch 172 in epoch 7, gen_loss = 0.3945459682128333, disc_loss = 0.04789097712414253
Trained batch 173 in epoch 7, gen_loss = 0.3940428613588728, disc_loss = 0.05091055484532764
Trained batch 174 in epoch 7, gen_loss = 0.39407181876046316, disc_loss = 0.05127846093881609
Trained batch 175 in epoch 7, gen_loss = 0.39432994344017724, disc_loss = 0.054366425926259995
Trained batch 176 in epoch 7, gen_loss = 0.3941643746559229, disc_loss = 0.05456695943251305
Trained batch 177 in epoch 7, gen_loss = 0.39425319634126815, disc_loss = 0.05459016561279272
Trained batch 178 in epoch 7, gen_loss = 0.3946064682313184, disc_loss = 0.05461136761346478
Trained batch 179 in epoch 7, gen_loss = 0.3945627399616771, disc_loss = 0.0544613826790333
Trained batch 180 in epoch 7, gen_loss = 0.39427710682647665, disc_loss = 0.054217153334622244
Trained batch 181 in epoch 7, gen_loss = 0.3942351655645685, disc_loss = 0.054090435593964654
Trained batch 182 in epoch 7, gen_loss = 0.3940116649116975, disc_loss = 0.05389140323192502
Trained batch 183 in epoch 7, gen_loss = 0.39422344545955246, disc_loss = 0.05390795134798796
Trained batch 184 in epoch 7, gen_loss = 0.3939210092699206, disc_loss = 0.0544613568442622
Trained batch 185 in epoch 7, gen_loss = 0.39395093533300585, disc_loss = 0.05495176128623757
Trained batch 186 in epoch 7, gen_loss = 0.39327666705304926, disc_loss = 0.05591240422432884
Trained batch 187 in epoch 7, gen_loss = 0.39331283277653634, disc_loss = 0.05623204107278651
Trained batch 188 in epoch 7, gen_loss = 0.39348747080596036, disc_loss = 0.05619334800830406
Trained batch 189 in epoch 7, gen_loss = 0.39307126936159636, disc_loss = 0.056149843499664905
Trained batch 190 in epoch 7, gen_loss = 0.3932141493128232, disc_loss = 0.05593874006860046
Trained batch 191 in epoch 7, gen_loss = 0.39336573363592225, disc_loss = 0.05574048346200774
Trained batch 192 in epoch 7, gen_loss = 0.3929171721243488, disc_loss = 0.05569333765309526
Trained batch 193 in epoch 7, gen_loss = 0.3932186961174011, disc_loss = 0.055637388584052795
Trained batch 194 in epoch 7, gen_loss = 0.3929346275635255, disc_loss = 0.05553292460912743
Trained batch 195 in epoch 7, gen_loss = 0.3931496788044365, disc_loss = 0.05546227850914429
Trained batch 196 in epoch 7, gen_loss = 0.39268796456041677, disc_loss = 0.056530191140251734
Trained batch 197 in epoch 7, gen_loss = 0.3927980467225566, disc_loss = 0.0587589408937169
Trained batch 198 in epoch 7, gen_loss = 0.39262223348545666, disc_loss = 0.059195714687107215
Trained batch 199 in epoch 7, gen_loss = 0.3921741361916065, disc_loss = 0.05962083668244304
Trained batch 200 in epoch 7, gen_loss = 0.39251714796569215, disc_loss = 0.059602394744357676
Trained batch 201 in epoch 7, gen_loss = 0.39251685098256217, disc_loss = 0.059370536581062165
Trained batch 202 in epoch 7, gen_loss = 0.39287712186428125, disc_loss = 0.05915894596338538
Trained batch 203 in epoch 7, gen_loss = 0.39269536967371027, disc_loss = 0.05890141557200182
Trained batch 204 in epoch 7, gen_loss = 0.392789533661633, disc_loss = 0.05864387135753953
Trained batch 205 in epoch 7, gen_loss = 0.3924258980646874, disc_loss = 0.05844151289501788
Trained batch 206 in epoch 7, gen_loss = 0.3923325482485951, disc_loss = 0.058187615117654294
Trained batch 207 in epoch 7, gen_loss = 0.39211615103368574, disc_loss = 0.057956182639967525
Trained batch 208 in epoch 7, gen_loss = 0.3918298731009926, disc_loss = 0.057823222139727716
Trained batch 209 in epoch 7, gen_loss = 0.3918147691658565, disc_loss = 0.05763421086178693
Trained batch 210 in epoch 7, gen_loss = 0.39157629479164197, disc_loss = 0.057575953312458746
Trained batch 211 in epoch 7, gen_loss = 0.39171626432886664, disc_loss = 0.05737957532351775
Trained batch 212 in epoch 7, gen_loss = 0.39169098681687187, disc_loss = 0.05753261471815416
Trained batch 213 in epoch 7, gen_loss = 0.3916788645715357, disc_loss = 0.05862083618565045
Trained batch 214 in epoch 7, gen_loss = 0.39150391110154087, disc_loss = 0.058924996281356744
Trained batch 215 in epoch 7, gen_loss = 0.39152324765368746, disc_loss = 0.05891955742225508
Trained batch 216 in epoch 7, gen_loss = 0.39112496939122954, disc_loss = 0.05901826662360154
Trained batch 217 in epoch 7, gen_loss = 0.39070493652733096, disc_loss = 0.05928999891343373
Trained batch 218 in epoch 7, gen_loss = 0.39075844187170405, disc_loss = 0.06047760632306924
Trained batch 219 in epoch 7, gen_loss = 0.3907356250015172, disc_loss = 0.06025063424736304
Trained batch 220 in epoch 7, gen_loss = 0.39064352194108576, disc_loss = 0.060112113322972054
Trained batch 221 in epoch 7, gen_loss = 0.390492789917164, disc_loss = 0.06044648104029506
Trained batch 222 in epoch 7, gen_loss = 0.3907272539063954, disc_loss = 0.06043492900359031
Trained batch 223 in epoch 7, gen_loss = 0.39084936159529854, disc_loss = 0.060290872506292156
Trained batch 224 in epoch 7, gen_loss = 0.3904767599370744, disc_loss = 0.06064038043660629
Trained batch 225 in epoch 7, gen_loss = 0.39057439433789887, disc_loss = 0.06178560093549014
Trained batch 226 in epoch 7, gen_loss = 0.3902675951892584, disc_loss = 0.061911358662402986
Trained batch 227 in epoch 7, gen_loss = 0.3896930560208203, disc_loss = 0.06242532801447771
Trained batch 228 in epoch 7, gen_loss = 0.38994083706468474, disc_loss = 0.062296820377705286
Trained batch 229 in epoch 7, gen_loss = 0.3902394855799882, disc_loss = 0.062160344952565574
Trained batch 230 in epoch 7, gen_loss = 0.3902412806496476, disc_loss = 0.06191845658337052
Trained batch 231 in epoch 7, gen_loss = 0.3903644993130503, disc_loss = 0.06170096706046024
Trained batch 232 in epoch 7, gen_loss = 0.390521726766881, disc_loss = 0.06159042079394379
Trained batch 233 in epoch 7, gen_loss = 0.39054991788843757, disc_loss = 0.06137510137577764
Trained batch 234 in epoch 7, gen_loss = 0.39086842295971325, disc_loss = 0.061153274996731274
Trained batch 235 in epoch 7, gen_loss = 0.3905386343850928, disc_loss = 0.06111978153896447
Trained batch 236 in epoch 7, gen_loss = 0.3906829150920176, disc_loss = 0.06155297300068049
Trained batch 237 in epoch 7, gen_loss = 0.39064218304237397, disc_loss = 0.0613370650653833
Trained batch 238 in epoch 7, gen_loss = 0.3906521199886769, disc_loss = 0.06147027806360392
Trained batch 239 in epoch 7, gen_loss = 0.39060298167169094, disc_loss = 0.06150130556998192
Trained batch 240 in epoch 7, gen_loss = 0.39047483450644244, disc_loss = 0.061265819072501185
Trained batch 241 in epoch 7, gen_loss = 0.3904780332953477, disc_loss = 0.06108823029563978
Trained batch 242 in epoch 7, gen_loss = 0.3906725421854498, disc_loss = 0.06088952500964304
Trained batch 243 in epoch 7, gen_loss = 0.3905644194513071, disc_loss = 0.06068102884145461
Trained batch 244 in epoch 7, gen_loss = 0.39039180047658023, disc_loss = 0.06047527214574001
Trained batch 245 in epoch 7, gen_loss = 0.3904849267829724, disc_loss = 0.06068373086121183
Trained batch 246 in epoch 7, gen_loss = 0.3904871781345321, disc_loss = 0.060760044278096226
Trained batch 247 in epoch 7, gen_loss = 0.3905335838996595, disc_loss = 0.06060874822663121
Trained batch 248 in epoch 7, gen_loss = 0.3906635731817728, disc_loss = 0.060393751245674615
Trained batch 249 in epoch 7, gen_loss = 0.3908383923768997, disc_loss = 0.0601881488210056
Trained batch 250 in epoch 7, gen_loss = 0.3907680715697695, disc_loss = 0.059995861384744914
Trained batch 251 in epoch 7, gen_loss = 0.3908905095997311, disc_loss = 0.060049539648360455
Trained batch 252 in epoch 7, gen_loss = 0.3905216172749817, disc_loss = 0.06058584254721857
Trained batch 253 in epoch 7, gen_loss = 0.3904028360064574, disc_loss = 0.06095809742691927
Trained batch 254 in epoch 7, gen_loss = 0.39071755794917834, disc_loss = 0.06077316968231553
Trained batch 255 in epoch 7, gen_loss = 0.39106883271597326, disc_loss = 0.060581360352671254
Trained batch 256 in epoch 7, gen_loss = 0.39112877729801815, disc_loss = 0.060364531757398816
Trained batch 257 in epoch 7, gen_loss = 0.3910805028538371, disc_loss = 0.060157327699996606
Trained batch 258 in epoch 7, gen_loss = 0.3912567183317825, disc_loss = 0.05994148953016811
Trained batch 259 in epoch 7, gen_loss = 0.3913779624379598, disc_loss = 0.05972612759192438
Trained batch 260 in epoch 7, gen_loss = 0.3915151717333958, disc_loss = 0.05950756523230959
Trained batch 261 in epoch 7, gen_loss = 0.39165238023714255, disc_loss = 0.05928898603457225
Trained batch 262 in epoch 7, gen_loss = 0.39189449541922305, disc_loss = 0.05907899969785931
Trained batch 263 in epoch 7, gen_loss = 0.39192796103430516, disc_loss = 0.05887596797269494
Trained batch 264 in epoch 7, gen_loss = 0.39206720871745415, disc_loss = 0.05866530516540702
Trained batch 265 in epoch 7, gen_loss = 0.39210806719790725, disc_loss = 0.05845379772183793
Trained batch 266 in epoch 7, gen_loss = 0.39204198657796624, disc_loss = 0.05824294762205409
Trained batch 267 in epoch 7, gen_loss = 0.3919326495101203, disc_loss = 0.05803705481382316
Trained batch 268 in epoch 7, gen_loss = 0.3919494724849786, disc_loss = 0.05782673476444779
Trained batch 269 in epoch 7, gen_loss = 0.39211712104302865, disc_loss = 0.05762094740811908
Trained batch 270 in epoch 7, gen_loss = 0.39229293052120845, disc_loss = 0.05742311923927026
Trained batch 271 in epoch 7, gen_loss = 0.3922706186113989, disc_loss = 0.05722702293068698
Trained batch 272 in epoch 7, gen_loss = 0.3924023701157762, disc_loss = 0.05702917387853155
Trained batch 273 in epoch 7, gen_loss = 0.3926202045740002, disc_loss = 0.05683434691070239
Trained batch 274 in epoch 7, gen_loss = 0.3926154445518147, disc_loss = 0.05664625041885302
Trained batch 275 in epoch 7, gen_loss = 0.3927308416021043, disc_loss = 0.056452793621945704
Trained batch 276 in epoch 7, gen_loss = 0.39288667629772145, disc_loss = 0.056277521128811625
Trained batch 277 in epoch 7, gen_loss = 0.39290082615485294, disc_loss = 0.05609177617903082
Trained batch 278 in epoch 7, gen_loss = 0.39306573521706367, disc_loss = 0.055905552929155465
Trained batch 279 in epoch 7, gen_loss = 0.39298567473888396, disc_loss = 0.05572165498181546
Trained batch 280 in epoch 7, gen_loss = 0.39308834394101994, disc_loss = 0.05552869275261174
Trained batch 281 in epoch 7, gen_loss = 0.3930105968570033, disc_loss = 0.05534389356860448
Trained batch 282 in epoch 7, gen_loss = 0.39294813557564157, disc_loss = 0.05515336752610031
Trained batch 283 in epoch 7, gen_loss = 0.39259935117943184, disc_loss = 0.05496444343363794
Trained batch 284 in epoch 7, gen_loss = 0.39250211841181704, disc_loss = 0.054780837725398636
Trained batch 285 in epoch 7, gen_loss = 0.3924648122979211, disc_loss = 0.054594222838637074
Trained batch 286 in epoch 7, gen_loss = 0.3928217743539644, disc_loss = 0.054429768031188826
Trained batch 287 in epoch 7, gen_loss = 0.3928576599185665, disc_loss = 0.0542525518069144
Trained batch 288 in epoch 7, gen_loss = 0.392845097916349, disc_loss = 0.05407420146117103
Trained batch 289 in epoch 7, gen_loss = 0.3932314994006321, disc_loss = 0.05389930850741903
Trained batch 290 in epoch 7, gen_loss = 0.39348092624002307, disc_loss = 0.053721447524661035
Trained batch 291 in epoch 7, gen_loss = 0.3935745507478714, disc_loss = 0.05354983519825746
Trained batch 292 in epoch 7, gen_loss = 0.3933791818268877, disc_loss = 0.05337333584735933
Trained batch 293 in epoch 7, gen_loss = 0.3937393196788775, disc_loss = 0.05320262213393596
Trained batch 294 in epoch 7, gen_loss = 0.39392259282580877, disc_loss = 0.05303416235818354
Trained batch 295 in epoch 7, gen_loss = 0.39378076419234276, disc_loss = 0.052869234019552194
Trained batch 296 in epoch 7, gen_loss = 0.39368359097326644, disc_loss = 0.05270133444804993
Trained batch 297 in epoch 7, gen_loss = 0.3937235754608308, disc_loss = 0.05253184461851304
Trained batch 298 in epoch 7, gen_loss = 0.3937496323649301, disc_loss = 0.05237126582552115
Trained batch 299 in epoch 7, gen_loss = 0.39387666086355844, disc_loss = 0.05222726062968529
Trained batch 300 in epoch 7, gen_loss = 0.39397958336874495, disc_loss = 0.05207061939397084
Trained batch 301 in epoch 7, gen_loss = 0.3940252264011775, disc_loss = 0.0519045655723948
Trained batch 302 in epoch 7, gen_loss = 0.3939030616000147, disc_loss = 0.051737780057826685
Trained batch 303 in epoch 7, gen_loss = 0.3938683232194499, disc_loss = 0.05158138404792561
Trained batch 304 in epoch 7, gen_loss = 0.394239652743105, disc_loss = 0.05143642405593829
Trained batch 305 in epoch 7, gen_loss = 0.3942827790780784, disc_loss = 0.05128906094343584
Trained batch 306 in epoch 7, gen_loss = 0.3942013318841543, disc_loss = 0.051163876476790146
Trained batch 307 in epoch 7, gen_loss = 0.39458363300020044, disc_loss = 0.05103034475215789
Trained batch 308 in epoch 7, gen_loss = 0.39485110511285976, disc_loss = 0.05088298917204762
Trained batch 309 in epoch 7, gen_loss = 0.3950004643009555, disc_loss = 0.050731705206318665
Trained batch 310 in epoch 7, gen_loss = 0.3949800055126669, disc_loss = 0.05066015328699124
Trained batch 311 in epoch 7, gen_loss = 0.3950280444935346, disc_loss = 0.050540259656256054
Trained batch 312 in epoch 7, gen_loss = 0.39503269387891116, disc_loss = 0.05038960866787034
Trained batch 313 in epoch 7, gen_loss = 0.39502093860298204, disc_loss = 0.050244968938218594
Trained batch 314 in epoch 7, gen_loss = 0.3951450028116741, disc_loss = 0.050112844556237435
Trained batch 315 in epoch 7, gen_loss = 0.39501432933007613, disc_loss = 0.049967544066942225
Trained batch 316 in epoch 7, gen_loss = 0.39517786628816404, disc_loss = 0.04984166419294395
Trained batch 317 in epoch 7, gen_loss = 0.3951869282707478, disc_loss = 0.04974690851892356
Trained batch 318 in epoch 7, gen_loss = 0.39515747489600345, disc_loss = 0.04967900243172492
Trained batch 319 in epoch 7, gen_loss = 0.39521614322438836, disc_loss = 0.04987148341224383
Trained batch 320 in epoch 7, gen_loss = 0.39515169378010284, disc_loss = 0.050083276095279315
Trained batch 321 in epoch 7, gen_loss = 0.3952900175907597, disc_loss = 0.05005939354775155
Trained batch 322 in epoch 7, gen_loss = 0.39492592215538025, disc_loss = 0.0501591741666414
Trained batch 323 in epoch 7, gen_loss = 0.3950148942293944, disc_loss = 0.05007088723801577
Trained batch 324 in epoch 7, gen_loss = 0.39487890949616067, disc_loss = 0.049988879678018676
Trained batch 325 in epoch 7, gen_loss = 0.39473974256793415, disc_loss = 0.04991094784241918
Trained batch 326 in epoch 7, gen_loss = 0.3950235410750095, disc_loss = 0.05026885723771345
Trained batch 327 in epoch 7, gen_loss = 0.39500372911371834, disc_loss = 0.050529584722137706
Trained batch 328 in epoch 7, gen_loss = 0.3950459303102232, disc_loss = 0.050485562252009564
Trained batch 329 in epoch 7, gen_loss = 0.39510294858253364, disc_loss = 0.0504466700415254
Trained batch 330 in epoch 7, gen_loss = 0.3951595365280831, disc_loss = 0.0503066274486243
Trained batch 331 in epoch 7, gen_loss = 0.3953329078763364, disc_loss = 0.050188585732052246
Trained batch 332 in epoch 7, gen_loss = 0.39533262039806033, disc_loss = 0.05004566376549877
Trained batch 333 in epoch 7, gen_loss = 0.3951269154420156, disc_loss = 0.04990432877842933
Trained batch 334 in epoch 7, gen_loss = 0.3949956921499167, disc_loss = 0.04979757288689795
Trained batch 335 in epoch 7, gen_loss = 0.3949173076876572, disc_loss = 0.04969251528572862
Trained batch 336 in epoch 7, gen_loss = 0.39503794528256536, disc_loss = 0.04958904459322899
Trained batch 337 in epoch 7, gen_loss = 0.3947047995921423, disc_loss = 0.04981173175857568
Trained batch 338 in epoch 7, gen_loss = 0.3948045437139044, disc_loss = 0.05081037124175892
Trained batch 339 in epoch 7, gen_loss = 0.39482847390805975, disc_loss = 0.05069318173696315
Trained batch 340 in epoch 7, gen_loss = 0.39439894202168035, disc_loss = 0.05063918983352799
Trained batch 341 in epoch 7, gen_loss = 0.39447873342804046, disc_loss = 0.05058777014155088
Trained batch 342 in epoch 7, gen_loss = 0.3944210091241942, disc_loss = 0.050471399483608986
Trained batch 343 in epoch 7, gen_loss = 0.39449167277577313, disc_loss = 0.0503396205270736
Trained batch 344 in epoch 7, gen_loss = 0.3946518247542174, disc_loss = 0.05021891040454173
Trained batch 345 in epoch 7, gen_loss = 0.3947599962612108, disc_loss = 0.05024081778041668
Trained batch 346 in epoch 7, gen_loss = 0.39457619018444756, disc_loss = 0.05016038196362013
Trained batch 347 in epoch 7, gen_loss = 0.39454989974526156, disc_loss = 0.050035257793490606
Trained batch 348 in epoch 7, gen_loss = 0.39438499121747933, disc_loss = 0.050111436593795945
Trained batch 349 in epoch 7, gen_loss = 0.3944493170295443, disc_loss = 0.05053174761972124
Trained batch 350 in epoch 7, gen_loss = 0.3943563951046718, disc_loss = 0.050587922697349526
Trained batch 351 in epoch 7, gen_loss = 0.3943363065746697, disc_loss = 0.05049740737062662
Trained batch 352 in epoch 7, gen_loss = 0.3943928291034428, disc_loss = 0.05041879310688827
Trained batch 353 in epoch 7, gen_loss = 0.39455402688791524, disc_loss = 0.05029161449302761
Trained batch 354 in epoch 7, gen_loss = 0.39439979984726703, disc_loss = 0.050245036784736574
Trained batch 355 in epoch 7, gen_loss = 0.39452291706974585, disc_loss = 0.050306618372416595
Trained batch 356 in epoch 7, gen_loss = 0.3944418389423221, disc_loss = 0.050380861508452626
Trained batch 357 in epoch 7, gen_loss = 0.39458443274378113, disc_loss = 0.050382256624126265
Trained batch 358 in epoch 7, gen_loss = 0.39476525061309836, disc_loss = 0.05024992889244094
Trained batch 359 in epoch 7, gen_loss = 0.3948376994993952, disc_loss = 0.050136059826440434
Trained batch 360 in epoch 7, gen_loss = 0.3947973153102431, disc_loss = 0.050038145510499156
Trained batch 361 in epoch 7, gen_loss = 0.39451696818375454, disc_loss = 0.05000642387730903
Trained batch 362 in epoch 7, gen_loss = 0.3945670954616273, disc_loss = 0.049886866585388726
Trained batch 363 in epoch 7, gen_loss = 0.3944837877547348, disc_loss = 0.04984413153107488
Trained batch 364 in epoch 7, gen_loss = 0.39468733880617846, disc_loss = 0.04977895811643477
Trained batch 365 in epoch 7, gen_loss = 0.3948070809977954, disc_loss = 0.049696158380928335
Trained batch 366 in epoch 7, gen_loss = 0.3945054932413699, disc_loss = 0.04990329715973325
Trained batch 367 in epoch 7, gen_loss = 0.3947600646997276, disc_loss = 0.050153844086193916
Trained batch 368 in epoch 7, gen_loss = 0.3948041155409361, disc_loss = 0.050030083975882135
Trained batch 369 in epoch 7, gen_loss = 0.3947071378295486, disc_loss = 0.04992094587871326
Trained batch 370 in epoch 7, gen_loss = 0.39470311734232943, disc_loss = 0.04986745179577472
Trained batch 371 in epoch 7, gen_loss = 0.3947662965905282, disc_loss = 0.04974774206892753
Trained batch 372 in epoch 7, gen_loss = 0.39491635089585353, disc_loss = 0.04963888909312554
Trained batch 373 in epoch 7, gen_loss = 0.3950215475285117, disc_loss = 0.049514830360073286
Trained batch 374 in epoch 7, gen_loss = 0.3950374680360158, disc_loss = 0.049432451932225376
Trained batch 375 in epoch 7, gen_loss = 0.39517125479401427, disc_loss = 0.0493467143088755
Trained batch 376 in epoch 7, gen_loss = 0.3954145136024971, disc_loss = 0.04934281422877042
Trained batch 377 in epoch 7, gen_loss = 0.39533518428209596, disc_loss = 0.04925849729093782
Trained batch 378 in epoch 7, gen_loss = 0.3952581028510524, disc_loss = 0.04914426010106334
Trained batch 379 in epoch 7, gen_loss = 0.39534306565397664, disc_loss = 0.0491830549421904
Trained batch 380 in epoch 7, gen_loss = 0.39554281466276314, disc_loss = 0.04908193131829942
Trained batch 381 in epoch 7, gen_loss = 0.3957052830782236, disc_loss = 0.0491740834478384
Trained batch 382 in epoch 7, gen_loss = 0.3956195254549968, disc_loss = 0.04917864472524436
Trained batch 383 in epoch 7, gen_loss = 0.3957005971266578, disc_loss = 0.04909796817552584
Trained batch 384 in epoch 7, gen_loss = 0.3959045941953535, disc_loss = 0.04898205099539686
Trained batch 385 in epoch 7, gen_loss = 0.39575943659624285, disc_loss = 0.048867449826540406
Trained batch 386 in epoch 7, gen_loss = 0.3960276823635249, disc_loss = 0.04880568954611717
Trained batch 387 in epoch 7, gen_loss = 0.39629475795423863, disc_loss = 0.048691594482191895
Trained batch 388 in epoch 7, gen_loss = 0.39630893485711594, disc_loss = 0.04870690592935136
Trained batch 389 in epoch 7, gen_loss = 0.39614383692924793, disc_loss = 0.04873493633647927
Trained batch 390 in epoch 7, gen_loss = 0.3960072833406346, disc_loss = 0.04866656676620183
Trained batch 391 in epoch 7, gen_loss = 0.3962432436492978, disc_loss = 0.04870942697194476
Trained batch 392 in epoch 7, gen_loss = 0.3960944976060445, disc_loss = 0.048778343086549186
Trained batch 393 in epoch 7, gen_loss = 0.396385698527249, disc_loss = 0.048766111589697556
Trained batch 394 in epoch 7, gen_loss = 0.39686558148528955, disc_loss = 0.048672526422740676
Trained batch 395 in epoch 7, gen_loss = 0.396839457629907, disc_loss = 0.048562578990852055
Trained batch 396 in epoch 7, gen_loss = 0.3968021468041225, disc_loss = 0.04847283310404104
Trained batch 397 in epoch 7, gen_loss = 0.39675722926405804, disc_loss = 0.04836498698715153
Trained batch 398 in epoch 7, gen_loss = 0.39686563745477144, disc_loss = 0.04825526965478024
Trained batch 399 in epoch 7, gen_loss = 0.3968228293955326, disc_loss = 0.048155131082603476
Trained batch 400 in epoch 7, gen_loss = 0.39686656488742017, disc_loss = 0.04805160659766568
Trained batch 401 in epoch 7, gen_loss = 0.3967935468130444, disc_loss = 0.04793924213006551
Trained batch 402 in epoch 7, gen_loss = 0.39657319435114896, disc_loss = 0.04782845785482567
Trained batch 403 in epoch 7, gen_loss = 0.39669737485375733, disc_loss = 0.04771848573994311
Trained batch 404 in epoch 7, gen_loss = 0.39678517793431695, disc_loss = 0.04761644883158927
Trained batch 405 in epoch 7, gen_loss = 0.39696040455930925, disc_loss = 0.04750757561833139
Trained batch 406 in epoch 7, gen_loss = 0.3969341534800846, disc_loss = 0.047403446230917246
Trained batch 407 in epoch 7, gen_loss = 0.3969230756309687, disc_loss = 0.04729851930988291
Trained batch 408 in epoch 7, gen_loss = 0.39696508201526837, disc_loss = 0.04718767444037862
Trained batch 409 in epoch 7, gen_loss = 0.3970717868426951, disc_loss = 0.047080094418232896
Trained batch 410 in epoch 7, gen_loss = 0.396942792292639, disc_loss = 0.0469791734920545
Trained batch 411 in epoch 7, gen_loss = 0.39698124242928423, disc_loss = 0.04689268275258443
Trained batch 412 in epoch 7, gen_loss = 0.3970698646425335, disc_loss = 0.04678990769007787
Trained batch 413 in epoch 7, gen_loss = 0.3969687322775523, disc_loss = 0.046682476985987036
Trained batch 414 in epoch 7, gen_loss = 0.3971881029117538, disc_loss = 0.04658217388247308
Trained batch 415 in epoch 7, gen_loss = 0.39704419729801327, disc_loss = 0.046478741867059185
Trained batch 416 in epoch 7, gen_loss = 0.39696950606590836, disc_loss = 0.046397511074425565
Trained batch 417 in epoch 7, gen_loss = 0.3969551662081166, disc_loss = 0.046310608950192914
Trained batch 418 in epoch 7, gen_loss = 0.396901056419409, disc_loss = 0.04625186272316139
Trained batch 419 in epoch 7, gen_loss = 0.39694713446356, disc_loss = 0.046527040729692784
Trained batch 420 in epoch 7, gen_loss = 0.39675937100997166, disc_loss = 0.04694451042824268
Trained batch 421 in epoch 7, gen_loss = 0.39685493015565015, disc_loss = 0.04692020380008255
Trained batch 422 in epoch 7, gen_loss = 0.396847400118555, disc_loss = 0.047001159745384116
Trained batch 423 in epoch 7, gen_loss = 0.39672896554166415, disc_loss = 0.046940254897427224
Trained batch 424 in epoch 7, gen_loss = 0.3967680891822366, disc_loss = 0.046901739447733716
Trained batch 425 in epoch 7, gen_loss = 0.39679494248309605, disc_loss = 0.04680700150103649
Trained batch 426 in epoch 7, gen_loss = 0.39682258948230076, disc_loss = 0.0467203984993174
Trained batch 427 in epoch 7, gen_loss = 0.3967979963276988, disc_loss = 0.04663173319153362
Trained batch 428 in epoch 7, gen_loss = 0.3969150148766302, disc_loss = 0.04653144070793416
Trained batch 429 in epoch 7, gen_loss = 0.3968372011600539, disc_loss = 0.04643284880358531
Trained batch 430 in epoch 7, gen_loss = 0.3967190402843006, disc_loss = 0.04632952296660712
Trained batch 431 in epoch 7, gen_loss = 0.3965236690171339, disc_loss = 0.046226628971824
Trained batch 432 in epoch 7, gen_loss = 0.3965014630872713, disc_loss = 0.04612503350025697
Trained batch 433 in epoch 7, gen_loss = 0.39646152643838783, disc_loss = 0.04602307161948781
Trained batch 434 in epoch 7, gen_loss = 0.3964578771043098, disc_loss = 0.0459224114626721
Trained batch 435 in epoch 7, gen_loss = 0.3965700487478064, disc_loss = 0.045831024449573904
Trained batch 436 in epoch 7, gen_loss = 0.3964946767149037, disc_loss = 0.04575018951436505
Trained batch 437 in epoch 7, gen_loss = 0.39647919599596226, disc_loss = 0.04566814866888158
Trained batch 438 in epoch 7, gen_loss = 0.39633407862963055, disc_loss = 0.045614928872020094
Trained batch 439 in epoch 7, gen_loss = 0.39610744335434656, disc_loss = 0.04556224451926855
Trained batch 440 in epoch 7, gen_loss = 0.39602643548766503, disc_loss = 0.04573694659571761
Trained batch 441 in epoch 7, gen_loss = 0.3961939755742906, disc_loss = 0.04604524361299945
Trained batch 442 in epoch 7, gen_loss = 0.396026776283643, disc_loss = 0.046194548337456495
Trained batch 443 in epoch 7, gen_loss = 0.3960227766955221, disc_loss = 0.046286468443786935
Trained batch 444 in epoch 7, gen_loss = 0.396028791317779, disc_loss = 0.04619715146529436
Trained batch 445 in epoch 7, gen_loss = 0.3961181053265328, disc_loss = 0.04611438805915545
Trained batch 446 in epoch 7, gen_loss = 0.3961146351875075, disc_loss = 0.04605947281491799
Trained batch 447 in epoch 7, gen_loss = 0.3961925894421126, disc_loss = 0.046052037039122036
Trained batch 448 in epoch 7, gen_loss = 0.39619144837150067, disc_loss = 0.04617849901618793
Trained batch 449 in epoch 7, gen_loss = 0.3960529350572162, disc_loss = 0.04701172457736296
Trained batch 450 in epoch 7, gen_loss = 0.39613307824155974, disc_loss = 0.04711434910806441
Trained batch 451 in epoch 7, gen_loss = 0.3961044503128634, disc_loss = 0.04711971513499955
Trained batch 452 in epoch 7, gen_loss = 0.3959773528917999, disc_loss = 0.047434580929050014
Trained batch 453 in epoch 7, gen_loss = 0.39614602358855866, disc_loss = 0.04752765531025495
Trained batch 454 in epoch 7, gen_loss = 0.3960016295150086, disc_loss = 0.04770731455121947
Trained batch 455 in epoch 7, gen_loss = 0.39612851579461184, disc_loss = 0.04801185155354273
Trained batch 456 in epoch 7, gen_loss = 0.3961208526623849, disc_loss = 0.04794054883886312
Trained batch 457 in epoch 7, gen_loss = 0.39610832454596023, disc_loss = 0.047920245501720124
Trained batch 458 in epoch 7, gen_loss = 0.39626281758798754, disc_loss = 0.04793893389567664
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.28108033537864685, disc_loss = 0.06897792220115662
Trained batch 1 in epoch 8, gen_loss = 0.32740139961242676, disc_loss = 0.03994069155305624
Trained batch 2 in epoch 8, gen_loss = 0.3797015845775604, disc_loss = 0.02956457994878292
Trained batch 3 in epoch 8, gen_loss = 0.386011965572834, disc_loss = 0.026246279012411833
Trained batch 4 in epoch 8, gen_loss = 0.3806601881980896, disc_loss = 0.022291846200823785
Trained batch 5 in epoch 8, gen_loss = 0.38267235457897186, disc_loss = 0.024796432194610436
Trained batch 6 in epoch 8, gen_loss = 0.37817559923444477, disc_loss = 0.03905578888952732
Trained batch 7 in epoch 8, gen_loss = 0.38199902698397636, disc_loss = 0.07899549487046897
Trained batch 8 in epoch 8, gen_loss = 0.38805891076723736, disc_loss = 0.0777669000542826
Trained batch 9 in epoch 8, gen_loss = 0.39993736445903777, disc_loss = 0.08104307558387518
Trained batch 10 in epoch 8, gen_loss = 0.3969145986166867, disc_loss = 0.0771925871006467
Trained batch 11 in epoch 8, gen_loss = 0.3916141043106715, disc_loss = 0.07842562921966116
Trained batch 12 in epoch 8, gen_loss = 0.40195537071961623, disc_loss = 0.07618728982141384
Trained batch 13 in epoch 8, gen_loss = 0.3994386558021818, disc_loss = 0.08571159107876676
Trained batch 14 in epoch 8, gen_loss = 0.39985103805859884, disc_loss = 0.08112845358749231
Trained batch 15 in epoch 8, gen_loss = 0.4023452438414097, disc_loss = 0.08178138535004109
Trained batch 16 in epoch 8, gen_loss = 0.4079289664240444, disc_loss = 0.07774988561868668
Trained batch 17 in epoch 8, gen_loss = 0.405926634867986, disc_loss = 0.07373772908209099
Trained batch 18 in epoch 8, gen_loss = 0.40611245600800766, disc_loss = 0.07042045768742498
Trained batch 19 in epoch 8, gen_loss = 0.4065408930182457, disc_loss = 0.06701246092561633
Trained batch 20 in epoch 8, gen_loss = 0.40703500168664114, disc_loss = 0.06401937443851716
Trained batch 21 in epoch 8, gen_loss = 0.4068620042367415, disc_loss = 0.06134084753946147
Trained batch 22 in epoch 8, gen_loss = 0.4057550339595131, disc_loss = 0.0587634011576681
Trained batch 23 in epoch 8, gen_loss = 0.40630610287189484, disc_loss = 0.05639352696986558
Trained batch 24 in epoch 8, gen_loss = 0.40541852951049806, disc_loss = 0.05421111909672618
Trained batch 25 in epoch 8, gen_loss = 0.40561315646538365, disc_loss = 0.05225746645233952
Trained batch 26 in epoch 8, gen_loss = 0.40463182771647416, disc_loss = 0.05041600805189875
Trained batch 27 in epoch 8, gen_loss = 0.40269050534282413, disc_loss = 0.04866581294585818
Trained batch 28 in epoch 8, gen_loss = 0.4030875954134711, disc_loss = 0.047072464303145635
Trained batch 29 in epoch 8, gen_loss = 0.4031634509563446, disc_loss = 0.04558805758909633
Trained batch 30 in epoch 8, gen_loss = 0.4015632752449282, disc_loss = 0.044170107012764824
Trained batch 31 in epoch 8, gen_loss = 0.3994417004287243, disc_loss = 0.042897616938716965
Trained batch 32 in epoch 8, gen_loss = 0.39910002188249066, disc_loss = 0.04165228151462295
Trained batch 33 in epoch 8, gen_loss = 0.3989093400099698, disc_loss = 0.040467617872362846
Trained batch 34 in epoch 8, gen_loss = 0.39848592281341555, disc_loss = 0.03936350149701216
Trained batch 35 in epoch 8, gen_loss = 0.3989310281144248, disc_loss = 0.038349931344984926
Trained batch 36 in epoch 8, gen_loss = 0.3981902526842581, disc_loss = 0.037379405439227215
Trained batch 37 in epoch 8, gen_loss = 0.39965307320419113, disc_loss = 0.03655880449744137
Trained batch 38 in epoch 8, gen_loss = 0.3994192947179843, disc_loss = 0.03570861019826948
Trained batch 39 in epoch 8, gen_loss = 0.39855156987905505, disc_loss = 0.034861004608683285
Trained batch 40 in epoch 8, gen_loss = 0.39950888331343487, disc_loss = 0.03406551919832099
Trained batch 41 in epoch 8, gen_loss = 0.40005219053654445, disc_loss = 0.03329828639869534
Trained batch 42 in epoch 8, gen_loss = 0.3996715677338977, disc_loss = 0.03256141736312921
Trained batch 43 in epoch 8, gen_loss = 0.3997293785214424, disc_loss = 0.03187443941186013
Trained batch 44 in epoch 8, gen_loss = 0.3985841631889343, disc_loss = 0.031216584495268762
Trained batch 45 in epoch 8, gen_loss = 0.39882754113363184, disc_loss = 0.03057124663863088
Trained batch 46 in epoch 8, gen_loss = 0.39923469563747976, disc_loss = 0.02995800539514327
Trained batch 47 in epoch 8, gen_loss = 0.39894323982298374, disc_loss = 0.029360475399395607
Trained batch 48 in epoch 8, gen_loss = 0.39783034397631273, disc_loss = 0.02878985944327575
Trained batch 49 in epoch 8, gen_loss = 0.39773243010044096, disc_loss = 0.028232955578714608
Trained batch 50 in epoch 8, gen_loss = 0.39704345721824497, disc_loss = 0.027702160677233457
Trained batch 51 in epoch 8, gen_loss = 0.39596091841275877, disc_loss = 0.02719273926833501
Trained batch 52 in epoch 8, gen_loss = 0.39487388336433554, disc_loss = 0.026711688221010537
Trained batch 53 in epoch 8, gen_loss = 0.39554406316192064, disc_loss = 0.026238485444250895
Trained batch 54 in epoch 8, gen_loss = 0.3948306771841916, disc_loss = 0.02578986113975671
Trained batch 55 in epoch 8, gen_loss = 0.39530870637723375, disc_loss = 0.02538271190548715
Trained batch 56 in epoch 8, gen_loss = 0.39561175672631516, disc_loss = 0.024961504627738083
Trained batch 57 in epoch 8, gen_loss = 0.3945055830067602, disc_loss = 0.02456014059435833
Trained batch 58 in epoch 8, gen_loss = 0.3945122381388131, disc_loss = 0.024172008751844196
Trained batch 59 in epoch 8, gen_loss = 0.3953115433454514, disc_loss = 0.023809540663690617
Trained batch 60 in epoch 8, gen_loss = 0.3953499662094429, disc_loss = 0.02345630587231307
Trained batch 61 in epoch 8, gen_loss = 0.3949285649484204, disc_loss = 0.023097726989597563
Trained batch 62 in epoch 8, gen_loss = 0.3957446841966538, disc_loss = 0.022757640636954752
Trained batch 63 in epoch 8, gen_loss = 0.39634952740743756, disc_loss = 0.022446680730354274
Trained batch 64 in epoch 8, gen_loss = 0.395992525265767, disc_loss = 0.022130057201362574
Trained batch 65 in epoch 8, gen_loss = 0.3964327411218123, disc_loss = 0.021824822440094344
Trained batch 66 in epoch 8, gen_loss = 0.3961446761195339, disc_loss = 0.021533343103477983
Trained batch 67 in epoch 8, gen_loss = 0.3956165576682371, disc_loss = 0.021233429825823644
Trained batch 68 in epoch 8, gen_loss = 0.3958967863649562, disc_loss = 0.020948236099565806
Trained batch 69 in epoch 8, gen_loss = 0.3951204014675958, disc_loss = 0.020674510952085258
Trained batch 70 in epoch 8, gen_loss = 0.3954155037940388, disc_loss = 0.02042480853294403
Trained batch 71 in epoch 8, gen_loss = 0.39468787817491424, disc_loss = 0.020187432049877115
Trained batch 72 in epoch 8, gen_loss = 0.39417703470138654, disc_loss = 0.019926312613964388
Trained batch 73 in epoch 8, gen_loss = 0.3943381619614524, disc_loss = 0.01968749371715947
Trained batch 74 in epoch 8, gen_loss = 0.39445321838061015, disc_loss = 0.01945804705377668
Trained batch 75 in epoch 8, gen_loss = 0.39441029570604624, disc_loss = 0.01922139858269427
Trained batch 76 in epoch 8, gen_loss = 0.39427900314331055, disc_loss = 0.018988965898631263
Trained batch 77 in epoch 8, gen_loss = 0.39374508154697907, disc_loss = 0.01876139121118169
Trained batch 78 in epoch 8, gen_loss = 0.3939483248734776, disc_loss = 0.01854008916747768
Trained batch 79 in epoch 8, gen_loss = 0.3932356063276529, disc_loss = 0.018321169239061418
Trained batch 80 in epoch 8, gen_loss = 0.3927787439322766, disc_loss = 0.01811234167644777
Trained batch 81 in epoch 8, gen_loss = 0.39267155346347066, disc_loss = 0.017940407719678905
Trained batch 82 in epoch 8, gen_loss = 0.39208466712250767, disc_loss = 0.017763474943531476
Trained batch 83 in epoch 8, gen_loss = 0.39210923157987143, disc_loss = 0.01757293796843095
Trained batch 84 in epoch 8, gen_loss = 0.39172397781820856, disc_loss = 0.017379021299455094
Trained batch 85 in epoch 8, gen_loss = 0.3912731901157734, disc_loss = 0.017192365940075453
Trained batch 86 in epoch 8, gen_loss = 0.39120227338253766, disc_loss = 0.01700824000952958
Trained batch 87 in epoch 8, gen_loss = 0.3917269943790002, disc_loss = 0.016832499899795617
Trained batch 88 in epoch 8, gen_loss = 0.39128160878513635, disc_loss = 0.016657559853831955
Trained batch 89 in epoch 8, gen_loss = 0.3906315594911575, disc_loss = 0.016488025259847442
Trained batch 90 in epoch 8, gen_loss = 0.39105788561014027, disc_loss = 0.016315279621886766
Trained batch 91 in epoch 8, gen_loss = 0.3911024286695149, disc_loss = 0.01614757236877821
Trained batch 92 in epoch 8, gen_loss = 0.39145306810255975, disc_loss = 0.01598454412618672
Trained batch 93 in epoch 8, gen_loss = 0.39136119599037983, disc_loss = 0.01583026047979303
Trained batch 94 in epoch 8, gen_loss = 0.390391888430244, disc_loss = 0.015678166971836043
Trained batch 95 in epoch 8, gen_loss = 0.3901123084748785, disc_loss = 0.015527008851980403
Trained batch 96 in epoch 8, gen_loss = 0.3901536332577774, disc_loss = 0.015403049749552667
Trained batch 97 in epoch 8, gen_loss = 0.39007814654282164, disc_loss = 0.015253095691595987
Trained batch 98 in epoch 8, gen_loss = 0.39022995426197243, disc_loss = 0.015112578532555036
Trained batch 99 in epoch 8, gen_loss = 0.3909662392735481, disc_loss = 0.014976349495118484
Trained batch 100 in epoch 8, gen_loss = 0.3915030814633511, disc_loss = 0.01483905962829727
Trained batch 101 in epoch 8, gen_loss = 0.3921075539261687, disc_loss = 0.014706552315129004
Trained batch 102 in epoch 8, gen_loss = 0.39190556094484424, disc_loss = 0.014576094495177775
Trained batch 103 in epoch 8, gen_loss = 0.39219235055721724, disc_loss = 0.014449744847997163
Trained batch 104 in epoch 8, gen_loss = 0.39197862574032377, disc_loss = 0.014336305628308938
Trained batch 105 in epoch 8, gen_loss = 0.39180641410485756, disc_loss = 0.01421699974628798
Trained batch 106 in epoch 8, gen_loss = 0.3913740457218384, disc_loss = 0.014095297490168258
Trained batch 107 in epoch 8, gen_loss = 0.3912273104544039, disc_loss = 0.013973853168189871
Trained batch 108 in epoch 8, gen_loss = 0.3912086631726781, disc_loss = 0.01385953897341163
Trained batch 109 in epoch 8, gen_loss = 0.39143758822571145, disc_loss = 0.013754318020602858
Trained batch 110 in epoch 8, gen_loss = 0.39189732316378, disc_loss = 0.013640231368979355
Trained batch 111 in epoch 8, gen_loss = 0.39168524289769785, disc_loss = 0.01352688732835564
Trained batch 112 in epoch 8, gen_loss = 0.39146059804258093, disc_loss = 0.013417537228319695
Trained batch 113 in epoch 8, gen_loss = 0.39103984414485465, disc_loss = 0.013308202226956686
Trained batch 114 in epoch 8, gen_loss = 0.39052250203878985, disc_loss = 0.013206500293808463
Trained batch 115 in epoch 8, gen_loss = 0.3898890570833765, disc_loss = 0.013102984819601387
Trained batch 116 in epoch 8, gen_loss = 0.38928356129898983, disc_loss = 0.012997866387809347
Trained batch 117 in epoch 8, gen_loss = 0.3888949246729835, disc_loss = 0.012898929301211295
Trained batch 118 in epoch 8, gen_loss = 0.3885117225787219, disc_loss = 0.012810152402135911
Trained batch 119 in epoch 8, gen_loss = 0.38857275719443957, disc_loss = 0.012712347570050042
Trained batch 120 in epoch 8, gen_loss = 0.3880987610698731, disc_loss = 0.012616115685240636
Trained batch 121 in epoch 8, gen_loss = 0.3883391582086438, disc_loss = 0.012529220960206032
Trained batch 122 in epoch 8, gen_loss = 0.3881436012140134, disc_loss = 0.01243912823246489
Trained batch 123 in epoch 8, gen_loss = 0.3883039516306693, disc_loss = 0.012348708852979114
Trained batch 124 in epoch 8, gen_loss = 0.3883932535648346, disc_loss = 0.012264585062395781
Trained batch 125 in epoch 8, gen_loss = 0.388253685027834, disc_loss = 0.012181692314611393
Trained batch 126 in epoch 8, gen_loss = 0.3878806784866363, disc_loss = 0.012092098354464616
Trained batch 127 in epoch 8, gen_loss = 0.38802826101891696, disc_loss = 0.012007082933450874
Trained batch 128 in epoch 8, gen_loss = 0.3877398198427156, disc_loss = 0.01192123366451223
Trained batch 129 in epoch 8, gen_loss = 0.38800491874034587, disc_loss = 0.01184891429102908
Trained batch 130 in epoch 8, gen_loss = 0.38844064173807624, disc_loss = 0.011780177037771934
Trained batch 131 in epoch 8, gen_loss = 0.3884294821005879, disc_loss = 0.011697284435010233
Trained batch 132 in epoch 8, gen_loss = 0.3884086053174241, disc_loss = 0.011618142147089838
Trained batch 133 in epoch 8, gen_loss = 0.38861954189948184, disc_loss = 0.011538927081482374
Trained batch 134 in epoch 8, gen_loss = 0.3884517676300473, disc_loss = 0.01146540554818111
Trained batch 135 in epoch 8, gen_loss = 0.38896169929819946, disc_loss = 0.011392693599833258
Trained batch 136 in epoch 8, gen_loss = 0.3891541340055257, disc_loss = 0.011319639080928054
Trained batch 137 in epoch 8, gen_loss = 0.38946866470834485, disc_loss = 0.011250391590284129
Trained batch 138 in epoch 8, gen_loss = 0.38898797343960767, disc_loss = 0.011179897923729375
Trained batch 139 in epoch 8, gen_loss = 0.3889573459114347, disc_loss = 0.011107764618853773
Trained batch 140 in epoch 8, gen_loss = 0.3891374062984548, disc_loss = 0.011036682422751732
Trained batch 141 in epoch 8, gen_loss = 0.3890464022545747, disc_loss = 0.010965940233034698
Trained batch 142 in epoch 8, gen_loss = 0.3888201957399195, disc_loss = 0.010894422981500547
Trained batch 143 in epoch 8, gen_loss = 0.3891048007127311, disc_loss = 0.010830416602402693
Trained batch 144 in epoch 8, gen_loss = 0.389002270739654, disc_loss = 0.010766696119440141
Trained batch 145 in epoch 8, gen_loss = 0.38904348730224453, disc_loss = 0.010701074780440214
Trained batch 146 in epoch 8, gen_loss = 0.3894074013849505, disc_loss = 0.010641591251609201
Trained batch 147 in epoch 8, gen_loss = 0.3894937427060024, disc_loss = 0.010577220205812261
Trained batch 148 in epoch 8, gen_loss = 0.3893894571185912, disc_loss = 0.010510685748964448
Trained batch 149 in epoch 8, gen_loss = 0.3895074458916982, disc_loss = 0.010448398739099503
Trained batch 150 in epoch 8, gen_loss = 0.38898696863888116, disc_loss = 0.010392686719111852
Trained batch 151 in epoch 8, gen_loss = 0.3887446438403506, disc_loss = 0.010329761902348286
Trained batch 152 in epoch 8, gen_loss = 0.3887803807757259, disc_loss = 0.010268904789186576
Trained batch 153 in epoch 8, gen_loss = 0.3882488269697536, disc_loss = 0.010213895707675438
Trained batch 154 in epoch 8, gen_loss = 0.3880715210591593, disc_loss = 0.010160266580210338
Trained batch 155 in epoch 8, gen_loss = 0.3881788815443332, disc_loss = 0.010101764810641702
Trained batch 156 in epoch 8, gen_loss = 0.38827068410861265, disc_loss = 0.01004412107297166
Trained batch 157 in epoch 8, gen_loss = 0.38829696970649913, disc_loss = 0.00998654178177195
Trained batch 158 in epoch 8, gen_loss = 0.3884783724568925, disc_loss = 0.009932967628068261
Trained batch 159 in epoch 8, gen_loss = 0.3883524056524038, disc_loss = 0.009880560818055528
Trained batch 160 in epoch 8, gen_loss = 0.38818305656776664, disc_loss = 0.009826495572823384
Trained batch 161 in epoch 8, gen_loss = 0.38778195281823474, disc_loss = 0.0097770531985903
Trained batch 162 in epoch 8, gen_loss = 0.38791306325994385, disc_loss = 0.009729650723990738
Trained batch 163 in epoch 8, gen_loss = 0.3875610686656905, disc_loss = 0.009677093465054385
Trained batch 164 in epoch 8, gen_loss = 0.3875202254815535, disc_loss = 0.009632475922857835
Trained batch 165 in epoch 8, gen_loss = 0.38755765629101946, disc_loss = 0.009582063658317238
Trained batch 166 in epoch 8, gen_loss = 0.3875995945787715, disc_loss = 0.009531691479064457
Trained batch 167 in epoch 8, gen_loss = 0.3875934247459684, disc_loss = 0.009483697345006346
Trained batch 168 in epoch 8, gen_loss = 0.38792608017046776, disc_loss = 0.009442950771451988
Trained batch 169 in epoch 8, gen_loss = 0.38810080728110147, disc_loss = 0.009401102482190575
Trained batch 170 in epoch 8, gen_loss = 0.3882325854566362, disc_loss = 0.009358370331135082
Trained batch 171 in epoch 8, gen_loss = 0.3883731337480767, disc_loss = 0.009313478696682533
Trained batch 172 in epoch 8, gen_loss = 0.3887161574611774, disc_loss = 0.009265217320075679
Trained batch 173 in epoch 8, gen_loss = 0.3889423560822147, disc_loss = 0.00921973350742864
Trained batch 174 in epoch 8, gen_loss = 0.3888491894517626, disc_loss = 0.009171938621771654
Trained batch 175 in epoch 8, gen_loss = 0.3889700176024979, disc_loss = 0.009126864766254916
Trained batch 176 in epoch 8, gen_loss = 0.38908230702755814, disc_loss = 0.00908200930255481
Trained batch 177 in epoch 8, gen_loss = 0.38872866935274575, disc_loss = 0.009041349516378382
Trained batch 178 in epoch 8, gen_loss = 0.3886853263364824, disc_loss = 0.008997281796400377
Trained batch 179 in epoch 8, gen_loss = 0.38871035112275015, disc_loss = 0.008955032245527643
Trained batch 180 in epoch 8, gen_loss = 0.388628091601377, disc_loss = 0.008917249235239661
Trained batch 181 in epoch 8, gen_loss = 0.38852345091956003, disc_loss = 0.0088783003332907
Trained batch 182 in epoch 8, gen_loss = 0.38849667056662135, disc_loss = 0.008835351769239871
Trained batch 183 in epoch 8, gen_loss = 0.3884233731938445, disc_loss = 0.008792262488619283
Trained batch 184 in epoch 8, gen_loss = 0.3882837213374473, disc_loss = 0.00874936322971071
Trained batch 185 in epoch 8, gen_loss = 0.3884833379778811, disc_loss = 0.008710341267062412
Trained batch 186 in epoch 8, gen_loss = 0.38834759083023684, disc_loss = 0.008667768034610878
Trained batch 187 in epoch 8, gen_loss = 0.388005330366023, disc_loss = 0.008628048194062083
Trained batch 188 in epoch 8, gen_loss = 0.3881685178746622, disc_loss = 0.008594171112654583
Trained batch 189 in epoch 8, gen_loss = 0.3882530596695448, disc_loss = 0.008566465483071576
Trained batch 190 in epoch 8, gen_loss = 0.3881006282973664, disc_loss = 0.008532270740995584
Trained batch 191 in epoch 8, gen_loss = 0.3880902756936848, disc_loss = 0.008504758754497743
Trained batch 192 in epoch 8, gen_loss = 0.38842897356482986, disc_loss = 0.008478923164515567
Trained batch 193 in epoch 8, gen_loss = 0.3884569566274427, disc_loss = 0.00844171835462438
Trained batch 194 in epoch 8, gen_loss = 0.38845677834290726, disc_loss = 0.008404491466279022
Trained batch 195 in epoch 8, gen_loss = 0.3884428794286689, disc_loss = 0.008384519781114305
Trained batch 196 in epoch 8, gen_loss = 0.38825816581697026, disc_loss = 0.008349469448628877
Trained batch 197 in epoch 8, gen_loss = 0.3882114128632979, disc_loss = 0.008313563483593177
Trained batch 198 in epoch 8, gen_loss = 0.38813636919960903, disc_loss = 0.008277026488885621
Trained batch 199 in epoch 8, gen_loss = 0.3879771454632282, disc_loss = 0.008252387381508014
Trained batch 200 in epoch 8, gen_loss = 0.38807232581560885, disc_loss = 0.00823977817978191
Trained batch 201 in epoch 8, gen_loss = 0.38806927971320576, disc_loss = 0.008219638050390905
Trained batch 202 in epoch 8, gen_loss = 0.3880940434967943, disc_loss = 0.008186727753620173
Trained batch 203 in epoch 8, gen_loss = 0.38809456486327976, disc_loss = 0.008155865653523007
Trained batch 204 in epoch 8, gen_loss = 0.3879569931728084, disc_loss = 0.008120722191056192
Trained batch 205 in epoch 8, gen_loss = 0.38772019454576434, disc_loss = 0.008103559353418232
Trained batch 206 in epoch 8, gen_loss = 0.38783641224322113, disc_loss = 0.008073515888328263
Trained batch 207 in epoch 8, gen_loss = 0.3880362348774305, disc_loss = 0.008041775869060075
Trained batch 208 in epoch 8, gen_loss = 0.38811389167913407, disc_loss = 0.00800724624311908
Trained batch 209 in epoch 8, gen_loss = 0.38797265660195124, disc_loss = 0.007983484972612045
Trained batch 210 in epoch 8, gen_loss = 0.3877734400649771, disc_loss = 0.007953015459266655
Trained batch 211 in epoch 8, gen_loss = 0.38770809193264766, disc_loss = 0.007919831933148363
Trained batch 212 in epoch 8, gen_loss = 0.38767839261623616, disc_loss = 0.0078862938647893
Trained batch 213 in epoch 8, gen_loss = 0.3880356785571464, disc_loss = 0.0078654102559493
Trained batch 214 in epoch 8, gen_loss = 0.3877683315166207, disc_loss = 0.007841972567325155
Trained batch 215 in epoch 8, gen_loss = 0.38781336046479364, disc_loss = 0.007810205722678263
Trained batch 216 in epoch 8, gen_loss = 0.387727316898135, disc_loss = 0.007784107274296457
Trained batch 217 in epoch 8, gen_loss = 0.38779817890683443, disc_loss = 0.0077565818335626
Trained batch 218 in epoch 8, gen_loss = 0.3877426402209556, disc_loss = 0.007727408972217969
Trained batch 219 in epoch 8, gen_loss = 0.3877798469229178, disc_loss = 0.007697133293153125
Trained batch 220 in epoch 8, gen_loss = 0.3876259860949279, disc_loss = 0.007666510641227194
Trained batch 221 in epoch 8, gen_loss = 0.3878012491507573, disc_loss = 0.007637076256303788
Trained batch 222 in epoch 8, gen_loss = 0.38781028037113996, disc_loss = 0.007608726140134654
Trained batch 223 in epoch 8, gen_loss = 0.38791005393224104, disc_loss = 0.007604985865587618
Trained batch 224 in epoch 8, gen_loss = 0.3878589860598246, disc_loss = 0.007584595790702022
Trained batch 225 in epoch 8, gen_loss = 0.3877638639074511, disc_loss = 0.007557390128680612
Trained batch 226 in epoch 8, gen_loss = 0.3876762962551369, disc_loss = 0.0075809695798440095
Trained batch 227 in epoch 8, gen_loss = 0.3878041500585121, disc_loss = 0.007568524344446415
Trained batch 228 in epoch 8, gen_loss = 0.38812553674373046, disc_loss = 0.007547214745968889
Trained batch 229 in epoch 8, gen_loss = 0.38807155386261316, disc_loss = 0.007519243171428451
Trained batch 230 in epoch 8, gen_loss = 0.3879334164130223, disc_loss = 0.007492663932700129
Trained batch 231 in epoch 8, gen_loss = 0.3877374364127373, disc_loss = 0.007464023956282321
Trained batch 232 in epoch 8, gen_loss = 0.3878461475536035, disc_loss = 0.007459187881157698
Trained batch 233 in epoch 8, gen_loss = 0.38776663174996007, disc_loss = 0.007445659847635553
Trained batch 234 in epoch 8, gen_loss = 0.38771330219634037, disc_loss = 0.00746222731379911
Trained batch 235 in epoch 8, gen_loss = 0.3875941360148333, disc_loss = 0.007446673562576584
Trained batch 236 in epoch 8, gen_loss = 0.38752665109775236, disc_loss = 0.007425031201316649
Trained batch 237 in epoch 8, gen_loss = 0.38758118037416156, disc_loss = 0.007412137521407371
Trained batch 238 in epoch 8, gen_loss = 0.3879165880101495, disc_loss = 0.007410777164779011
Trained batch 239 in epoch 8, gen_loss = 0.38783324708541234, disc_loss = 0.007417257177682283
Trained batch 240 in epoch 8, gen_loss = 0.3878859051530292, disc_loss = 0.0074105558547875325
Trained batch 241 in epoch 8, gen_loss = 0.3880379943808248, disc_loss = 0.0074932106726317985
Trained batch 242 in epoch 8, gen_loss = 0.38806636649885295, disc_loss = 0.007525610542997963
Trained batch 243 in epoch 8, gen_loss = 0.387948997196604, disc_loss = 0.00774016154292574
Trained batch 244 in epoch 8, gen_loss = 0.38828340501201397, disc_loss = 0.008002991724417222
Trained batch 245 in epoch 8, gen_loss = 0.3885712950694852, disc_loss = 0.008023824895792678
Trained batch 246 in epoch 8, gen_loss = 0.3883931546317421, disc_loss = 0.008057064754767758
Trained batch 247 in epoch 8, gen_loss = 0.38848830627337577, disc_loss = 0.008135934800638126
Trained batch 248 in epoch 8, gen_loss = 0.38865099051391266, disc_loss = 0.00818151360224319
Trained batch 249 in epoch 8, gen_loss = 0.3885984250307083, disc_loss = 0.008189027023501693
Trained batch 250 in epoch 8, gen_loss = 0.3883981710648632, disc_loss = 0.008200648798239955
Trained batch 251 in epoch 8, gen_loss = 0.3887111283247433, disc_loss = 0.008184806777289994
Trained batch 252 in epoch 8, gen_loss = 0.38901109787315247, disc_loss = 0.008164832634453776
Trained batch 253 in epoch 8, gen_loss = 0.3893244206670701, disc_loss = 0.008153711618877596
Trained batch 254 in epoch 8, gen_loss = 0.38948267768411077, disc_loss = 0.008132410474012003
Trained batch 255 in epoch 8, gen_loss = 0.38957483822014183, disc_loss = 0.008120068364405597
Trained batch 256 in epoch 8, gen_loss = 0.3896971796041333, disc_loss = 0.00809991626695871
Trained batch 257 in epoch 8, gen_loss = 0.38960324643656263, disc_loss = 0.008075861768822308
Trained batch 258 in epoch 8, gen_loss = 0.3896803419792514, disc_loss = 0.008061931852851796
Trained batch 259 in epoch 8, gen_loss = 0.3896221103576513, disc_loss = 0.008066052215872333
Trained batch 260 in epoch 8, gen_loss = 0.3893048577153363, disc_loss = 0.008064580691881991
Trained batch 261 in epoch 8, gen_loss = 0.3895212105894817, disc_loss = 0.008094603888502075
Trained batch 262 in epoch 8, gen_loss = 0.38997758669998256, disc_loss = 0.008093787629437056
Trained batch 263 in epoch 8, gen_loss = 0.39019089282462094, disc_loss = 0.008076429557122261
Trained batch 264 in epoch 8, gen_loss = 0.390146371553529, disc_loss = 0.008056718908373338
Trained batch 265 in epoch 8, gen_loss = 0.38984094997097674, disc_loss = 0.008035030555158602
Trained batch 266 in epoch 8, gen_loss = 0.38957485523116725, disc_loss = 0.008020213330321517
Trained batch 267 in epoch 8, gen_loss = 0.38967403725012023, disc_loss = 0.008001447198721371
Trained batch 268 in epoch 8, gen_loss = 0.38946517371333667, disc_loss = 0.007991988534284374
Trained batch 269 in epoch 8, gen_loss = 0.3892280712171837, disc_loss = 0.007969991333730933
Trained batch 270 in epoch 8, gen_loss = 0.3888098682204736, disc_loss = 0.007959120137517331
Trained batch 271 in epoch 8, gen_loss = 0.3890111215193482, disc_loss = 0.00795040464564569
Trained batch 272 in epoch 8, gen_loss = 0.3890195503121331, disc_loss = 0.007944894743479461
Trained batch 273 in epoch 8, gen_loss = 0.38889986853094866, disc_loss = 0.007922611607197863
Trained batch 274 in epoch 8, gen_loss = 0.38883749387481, disc_loss = 0.007902559351853349
Trained batch 275 in epoch 8, gen_loss = 0.38868655631507654, disc_loss = 0.007928847505684023
Trained batch 276 in epoch 8, gen_loss = 0.3885422598584034, disc_loss = 0.007976499108752297
Trained batch 277 in epoch 8, gen_loss = 0.3885986758865041, disc_loss = 0.00809130484821181
Trained batch 278 in epoch 8, gen_loss = 0.3884953150398842, disc_loss = 0.0086125384792552
Trained batch 280 in epoch 8, gen_loss = 0.3890926007486323, disc_loss = 0.010755530503840314
Trained batch 281 in epoch 8, gen_loss = 0.3888943193229378, disc_loss = 0.010961418107799287
Trained batch 282 in epoch 8, gen_loss = 0.3889408577036099, disc_loss = 0.01111550194247504
Trained batch 283 in epoch 8, gen_loss = 0.3891556420376603, disc_loss = 0.011124706179441385
Trained batch 284 in epoch 8, gen_loss = 0.38897285628737066, disc_loss = 0.011112739985579984
Trained batch 285 in epoch 8, gen_loss = 0.38903641117202653, disc_loss = 0.0111120225620697
Trained batch 286 in epoch 8, gen_loss = 0.38915472454310296, disc_loss = 0.011086133612118635
Trained batch 287 in epoch 8, gen_loss = 0.3890650382058488, disc_loss = 0.01106828320674443
Trained batch 288 in epoch 8, gen_loss = 0.38910672305777, disc_loss = 0.011048784816257371
Trained batch 289 in epoch 8, gen_loss = 0.3888701286809198, disc_loss = 0.011023719168814092
Trained batch 290 in epoch 8, gen_loss = 0.38887886339446526, disc_loss = 0.011032134243303147
Trained batch 291 in epoch 8, gen_loss = 0.38894931359650337, disc_loss = 0.011148720954174865
Trained batch 292 in epoch 8, gen_loss = 0.38888224786458975, disc_loss = 0.011302636014520105
Trained batch 293 in epoch 8, gen_loss = 0.388823280731837, disc_loss = 0.011527656647218328
Trained batch 294 in epoch 8, gen_loss = 0.38909957004805745, disc_loss = 0.012422197703587807
Trained batch 295 in epoch 8, gen_loss = 0.3889470174908638, disc_loss = 0.01309241827678036
Trained batch 296 in epoch 8, gen_loss = 0.3890360166328122, disc_loss = 0.01350527058546792
Trained batch 297 in epoch 8, gen_loss = 0.3892123096141239, disc_loss = 0.013588864731308598
Trained batch 298 in epoch 8, gen_loss = 0.3891202838325182, disc_loss = 0.013607864345993884
Trained batch 299 in epoch 8, gen_loss = 0.3891284935673078, disc_loss = 0.013619094329575698
Trained batch 300 in epoch 8, gen_loss = 0.3890037228696766, disc_loss = 0.013598894318287258
Trained batch 301 in epoch 8, gen_loss = 0.3890570556091157, disc_loss = 0.013567527082273798
Trained batch 302 in epoch 8, gen_loss = 0.3890990467354803, disc_loss = 0.01353105980435712
Trained batch 303 in epoch 8, gen_loss = 0.38899849992441504, disc_loss = 0.013494560956084905
Trained batch 304 in epoch 8, gen_loss = 0.38899180478737, disc_loss = 0.013457173730445202
Trained batch 305 in epoch 8, gen_loss = 0.3889881999664057, disc_loss = 0.013423640255091919
Trained batch 306 in epoch 8, gen_loss = 0.38908682622816354, disc_loss = 0.013389128178406616
Trained batch 307 in epoch 8, gen_loss = 0.38906249036262563, disc_loss = 0.013360230451715844
Trained batch 308 in epoch 8, gen_loss = 0.38922743099021295, disc_loss = 0.01333935428290209
Trained batch 309 in epoch 8, gen_loss = 0.3890797426623683, disc_loss = 0.013328741523887843
Trained batch 310 in epoch 8, gen_loss = 0.38916778679446007, disc_loss = 0.013296411953674828
Trained batch 311 in epoch 8, gen_loss = 0.3889138071009746, disc_loss = 0.013273453595152555
Trained batch 312 in epoch 8, gen_loss = 0.3889823509290957, disc_loss = 0.01330062611766469
Trained batch 313 in epoch 8, gen_loss = 0.3887323199943372, disc_loss = 0.013286879136387235
Trained batch 314 in epoch 8, gen_loss = 0.38835768595574394, disc_loss = 0.013440411790673222
Trained batch 315 in epoch 8, gen_loss = 0.3884835288494448, disc_loss = 0.013475408275092988
Trained batch 316 in epoch 8, gen_loss = 0.388439495762816, disc_loss = 0.013580095485640155
Trained batch 317 in epoch 8, gen_loss = 0.38811575963437184, disc_loss = 0.014179720471572108
Trained batch 318 in epoch 8, gen_loss = 0.3882972761568231, disc_loss = 0.015519620884256584
Trained batch 319 in epoch 8, gen_loss = 0.38830308923497797, disc_loss = 0.01557565161929233
Trained batch 320 in epoch 8, gen_loss = 0.38787189460246363, disc_loss = 0.01588256796821952
Trained batch 321 in epoch 8, gen_loss = 0.3879506002116648, disc_loss = 0.016252985193758555
Trained batch 322 in epoch 8, gen_loss = 0.38803916726688115, disc_loss = 0.017251609099434902
Trained batch 323 in epoch 8, gen_loss = 0.3882163339926873, disc_loss = 0.01754317798703495
Trained batch 324 in epoch 8, gen_loss = 0.38807443472055286, disc_loss = 0.01762283151396192
Trained batch 325 in epoch 8, gen_loss = 0.38790690277251727, disc_loss = 0.01763486078128996
Trained batch 326 in epoch 8, gen_loss = 0.38796745117651216, disc_loss = 0.017803581071225785
Trained batch 327 in epoch 8, gen_loss = 0.387946385345081, disc_loss = 0.017878576112263723
Trained batch 328 in epoch 8, gen_loss = 0.38799526934203404, disc_loss = 0.017919814173064243
Trained batch 329 in epoch 8, gen_loss = 0.3877608908848329, disc_loss = 0.018021165882942804
Trained batch 330 in epoch 8, gen_loss = 0.38800090101190204, disc_loss = 0.018004337833558415
Trained batch 331 in epoch 8, gen_loss = 0.3880775319524558, disc_loss = 0.01811394450697958
Trained batch 332 in epoch 8, gen_loss = 0.38833561978182635, disc_loss = 0.01834645718140332
Trained batch 333 in epoch 8, gen_loss = 0.38842799420842156, disc_loss = 0.018315031690924556
Trained batch 334 in epoch 8, gen_loss = 0.38872944081007543, disc_loss = 0.01833309368994921
Trained batch 335 in epoch 8, gen_loss = 0.3886085931389105, disc_loss = 0.0183093056063323
Trained batch 336 in epoch 8, gen_loss = 0.3886425091003452, disc_loss = 0.01830482610725198
Trained batch 337 in epoch 8, gen_loss = 0.388696463855766, disc_loss = 0.01831833202772107
Trained batch 338 in epoch 8, gen_loss = 0.38869824636299, disc_loss = 0.018293295914147894
Trained batch 339 in epoch 8, gen_loss = 0.3888644814491272, disc_loss = 0.018336915478165097
Trained batch 340 in epoch 8, gen_loss = 0.3889875248555214, disc_loss = 0.018324845540132428
Trained batch 341 in epoch 8, gen_loss = 0.3890925466317182, disc_loss = 0.018314466388264332
Trained batch 342 in epoch 8, gen_loss = 0.3891430800405953, disc_loss = 0.01828895263650805
Trained batch 343 in epoch 8, gen_loss = 0.3894220282172048, disc_loss = 0.018345817109992252
Trained batch 344 in epoch 8, gen_loss = 0.3893302744713382, disc_loss = 0.018774103307151707
Trained batch 345 in epoch 8, gen_loss = 0.3894913982966043, disc_loss = 0.020517010789504544
Trained batch 346 in epoch 8, gen_loss = 0.38951422029338584, disc_loss = 0.02098085927597169
Trained batch 347 in epoch 8, gen_loss = 0.3893630700721138, disc_loss = 0.021246135287018943
Trained batch 348 in epoch 8, gen_loss = 0.38913457338994417, disc_loss = 0.02140423822961214
Trained batch 349 in epoch 8, gen_loss = 0.3890113119568144, disc_loss = 0.02142471156881324
Trained batch 350 in epoch 8, gen_loss = 0.3890288155472856, disc_loss = 0.021385057915554003
Trained batch 351 in epoch 8, gen_loss = 0.38897844192317943, disc_loss = 0.021350540790907955
Trained batch 352 in epoch 8, gen_loss = 0.3891728284845271, disc_loss = 0.021317457119345917
Trained batch 353 in epoch 8, gen_loss = 0.3894646811788365, disc_loss = 0.021274250665006076
Trained batch 354 in epoch 8, gen_loss = 0.3895786375227109, disc_loss = 0.021224675516427403
Trained batch 355 in epoch 8, gen_loss = 0.3896804036719076, disc_loss = 0.021182972071901632
Trained batch 356 in epoch 8, gen_loss = 0.3895521873519534, disc_loss = 0.02114015897730736
Trained batch 357 in epoch 8, gen_loss = 0.3895160758961512, disc_loss = 0.021088485730884794
Trained batch 358 in epoch 8, gen_loss = 0.3894103458332816, disc_loss = 0.021038831930223614
Trained batch 359 in epoch 8, gen_loss = 0.38942830877171625, disc_loss = 0.02098986357062434
Trained batch 360 in epoch 8, gen_loss = 0.3894155077491771, disc_loss = 0.020941510650785925
Trained batch 361 in epoch 8, gen_loss = 0.38940622711049916, disc_loss = 0.020904744239472552
Trained batch 362 in epoch 8, gen_loss = 0.38952529257979274, disc_loss = 0.020878384595341755
Trained batch 363 in epoch 8, gen_loss = 0.3893106190057901, disc_loss = 0.020908908603794792
Trained batch 364 in epoch 8, gen_loss = 0.38940738953956183, disc_loss = 0.021041542528937123
Trained batch 365 in epoch 8, gen_loss = 0.3893308830880077, disc_loss = 0.021331045178625264
Trained batch 366 in epoch 8, gen_loss = 0.38928423980276333, disc_loss = 0.021945958152636683
Trained batch 367 in epoch 8, gen_loss = 0.3894195339601973, disc_loss = 0.02243917507534523
Trained batch 368 in epoch 8, gen_loss = 0.38957237987337395, disc_loss = 0.022518734705096823
Trained batch 369 in epoch 8, gen_loss = 0.38935939355476484, disc_loss = 0.02343137377268962
Trained batch 370 in epoch 8, gen_loss = 0.3896806869063416, disc_loss = 0.02412524691097579
Trained batch 371 in epoch 8, gen_loss = 0.38978761458589184, disc_loss = 0.024293119290603266
Trained batch 372 in epoch 8, gen_loss = 0.3896261227514405, disc_loss = 0.02438542236082116
Trained batch 373 in epoch 8, gen_loss = 0.3894652546567713, disc_loss = 0.02455355447373368
Trained batch 374 in epoch 8, gen_loss = 0.389262308994929, disc_loss = 0.024598074875772
Trained batch 375 in epoch 8, gen_loss = 0.38924077081870523, disc_loss = 0.024593195603030953
Trained batch 376 in epoch 8, gen_loss = 0.3891220023208335, disc_loss = 0.024553611538612557
Trained batch 377 in epoch 8, gen_loss = 0.3889177416367506, disc_loss = 0.02490160655644205
Trained batch 378 in epoch 8, gen_loss = 0.38911803566057007, disc_loss = 0.02552309418023419
Trained batch 379 in epoch 8, gen_loss = 0.38905547810228247, disc_loss = 0.025485177838096493
Trained batch 380 in epoch 8, gen_loss = 0.3890941581075273, disc_loss = 0.025509964528046256
Trained batch 381 in epoch 8, gen_loss = 0.3891893063540234, disc_loss = 0.025516348798315564
Trained batch 382 in epoch 8, gen_loss = 0.38895716648500206, disc_loss = 0.025564172852288337
Trained batch 383 in epoch 8, gen_loss = 0.38884627415488165, disc_loss = 0.025520579797254566
Trained batch 384 in epoch 8, gen_loss = 0.3886186302482308, disc_loss = 0.02547885485525642
Trained batch 385 in epoch 8, gen_loss = 0.38850237730253545, disc_loss = 0.025449520334060945
Trained batch 386 in epoch 8, gen_loss = 0.38859605003697, disc_loss = 0.025567684062691623
Trained batch 387 in epoch 8, gen_loss = 0.38859857134905057, disc_loss = 0.025937063638696967
Trained batch 388 in epoch 8, gen_loss = 0.3884296110785712, disc_loss = 0.02620420105046662
Trained batch 389 in epoch 8, gen_loss = 0.38869372713260164, disc_loss = 0.026241376881416027
Trained batch 390 in epoch 8, gen_loss = 0.3888295289805478, disc_loss = 0.026199475695352876
Trained batch 391 in epoch 8, gen_loss = 0.38882901253444807, disc_loss = 0.026151236921206723
Trained batch 392 in epoch 8, gen_loss = 0.3890037286372585, disc_loss = 0.02609626967791686
Trained batch 393 in epoch 8, gen_loss = 0.3889243769161592, disc_loss = 0.026056772197223254
Trained batch 394 in epoch 8, gen_loss = 0.3888723577125163, disc_loss = 0.026050010182057756
Trained batch 395 in epoch 8, gen_loss = 0.38883812582553035, disc_loss = 0.02604603138987464
Trained batch 396 in epoch 8, gen_loss = 0.3888491703671232, disc_loss = 0.025992008775322505
Trained batch 397 in epoch 8, gen_loss = 0.3889569214840031, disc_loss = 0.026102744520234703
Trained batch 398 in epoch 8, gen_loss = 0.3888590515854962, disc_loss = 0.027005596184416822
Trained batch 399 in epoch 8, gen_loss = 0.3891399899870157, disc_loss = 0.02723987619392574
Trained batch 400 in epoch 8, gen_loss = 0.38913213909415534, disc_loss = 0.027202440811288624
Trained batch 401 in epoch 8, gen_loss = 0.38921566870971697, disc_loss = 0.027165300541775142
Trained batch 402 in epoch 8, gen_loss = 0.389054328499006, disc_loss = 0.02743882169165919
Trained batch 403 in epoch 8, gen_loss = 0.3891327381871714, disc_loss = 0.02784834616808313
Trained batch 404 in epoch 8, gen_loss = 0.3892322924402025, disc_loss = 0.027821722277152686
Trained batch 405 in epoch 8, gen_loss = 0.3892083039571499, disc_loss = 0.027917005617189877
Trained batch 406 in epoch 8, gen_loss = 0.3892958274783901, disc_loss = 0.02786978191858574
Trained batch 407 in epoch 8, gen_loss = 0.38943903878623365, disc_loss = 0.027813250313092973
Trained batch 408 in epoch 8, gen_loss = 0.3892595077930861, disc_loss = 0.027924866672869416
Trained batch 409 in epoch 8, gen_loss = 0.3891182985974521, disc_loss = 0.028781777497653555
Trained batch 410 in epoch 8, gen_loss = 0.3891373093255825, disc_loss = 0.029347551660272326
Trained batch 411 in epoch 8, gen_loss = 0.3889735286820282, disc_loss = 0.029371015451740003
Trained batch 412 in epoch 8, gen_loss = 0.38869090692183006, disc_loss = 0.029699116345431844
Trained batch 413 in epoch 8, gen_loss = 0.3887478130451147, disc_loss = 0.030267100452764886
Trained batch 414 in epoch 8, gen_loss = 0.3885619545557413, disc_loss = 0.030305923651679452
Trained batch 415 in epoch 8, gen_loss = 0.3884993206996184, disc_loss = 0.030366435893273983
Trained batch 416 in epoch 8, gen_loss = 0.3884626106678439, disc_loss = 0.03033448311297013
Trained batch 417 in epoch 8, gen_loss = 0.38833589866115714, disc_loss = 0.03031204814207183
Trained batch 418 in epoch 8, gen_loss = 0.38830986071315754, disc_loss = 0.030263970359306346
Trained batch 419 in epoch 8, gen_loss = 0.38821627518960405, disc_loss = 0.030278270891202348
Trained batch 420 in epoch 8, gen_loss = 0.3884004362263759, disc_loss = 0.030292690795737886
Trained batch 421 in epoch 8, gen_loss = 0.38821071915999406, disc_loss = 0.030444510638607904
Trained batch 422 in epoch 8, gen_loss = 0.3881725923953045, disc_loss = 0.03063072035657176
Trained batch 423 in epoch 8, gen_loss = 0.38815726754519175, disc_loss = 0.03117864488026584
Trained batch 424 in epoch 8, gen_loss = 0.3881421391402974, disc_loss = 0.031135737540967323
Trained batch 425 in epoch 8, gen_loss = 0.3880805261957813, disc_loss = 0.031116691396130082
Trained batch 426 in epoch 8, gen_loss = 0.387972031600023, disc_loss = 0.031097859837795307
Trained batch 427 in epoch 8, gen_loss = 0.38790563521819693, disc_loss = 0.03109155667545361
Trained batch 428 in epoch 8, gen_loss = 0.38804638601127484, disc_loss = 0.031094424174729483
Trained batch 429 in epoch 8, gen_loss = 0.38801707673904506, disc_loss = 0.03124625642112521
Trained batch 430 in epoch 8, gen_loss = 0.38816285582816795, disc_loss = 0.031334519861676575
Trained batch 431 in epoch 8, gen_loss = 0.38837766743920465, disc_loss = 0.03131814901199606
Trained batch 432 in epoch 8, gen_loss = 0.3881319878283054, disc_loss = 0.031740248685070326
Trained batch 433 in epoch 8, gen_loss = 0.3882457361243288, disc_loss = 0.03275799586476269
Trained batch 434 in epoch 8, gen_loss = 0.3883416754075851, disc_loss = 0.03291536257869896
Trained batch 435 in epoch 8, gen_loss = 0.3883173156768904, disc_loss = 0.03324281841243079
Trained batch 436 in epoch 8, gen_loss = 0.38836481001066125, disc_loss = 0.03327889805254729
Trained batch 437 in epoch 8, gen_loss = 0.38833722574253604, disc_loss = 0.03341376696411333
Trained batch 438 in epoch 8, gen_loss = 0.38821060354725917, disc_loss = 0.03357411907446955
Trained batch 439 in epoch 8, gen_loss = 0.3882036457684907, disc_loss = 0.033611920501359485
Trained batch 440 in epoch 8, gen_loss = 0.3882684344742574, disc_loss = 0.03362106574095296
Trained batch 441 in epoch 8, gen_loss = 0.38822130083498374, disc_loss = 0.03362643317534374
Trained batch 442 in epoch 8, gen_loss = 0.3880632441684301, disc_loss = 0.033872726505819885
Trained batch 443 in epoch 8, gen_loss = 0.3878930245299597, disc_loss = 0.03408421431710054
Trained batch 444 in epoch 8, gen_loss = 0.3879612595177768, disc_loss = 0.03406729472152303
Trained batch 445 in epoch 8, gen_loss = 0.38793297399319876, disc_loss = 0.03418818786072089
Trained batch 446 in epoch 8, gen_loss = 0.3876925069480401, disc_loss = 0.03432854031623077
Trained batch 447 in epoch 8, gen_loss = 0.38780914300254415, disc_loss = 0.03461832395156047
Trained batch 448 in epoch 8, gen_loss = 0.3877328291103941, disc_loss = 0.03542423827411868
Trained batch 449 in epoch 8, gen_loss = 0.387950972782241, disc_loss = 0.03604261803958151
Trained batch 450 in epoch 8, gen_loss = 0.3879267191411122, disc_loss = 0.036202812554963146
Trained batch 451 in epoch 8, gen_loss = 0.38786295142057725, disc_loss = 0.03620812934782125
Trained batch 452 in epoch 8, gen_loss = 0.38777124638325855, disc_loss = 0.036177871539103276
Trained batch 453 in epoch 8, gen_loss = 0.3877595919081818, disc_loss = 0.036121270198801674
Trained batch 454 in epoch 8, gen_loss = 0.38782658249467283, disc_loss = 0.03605310130700633
Trained batch 455 in epoch 8, gen_loss = 0.38778326647323474, disc_loss = 0.03598120581183027
Trained batch 456 in epoch 8, gen_loss = 0.38786818370777354, disc_loss = 0.035912787342032404
Trained batch 457 in epoch 8, gen_loss = 0.3879191874807058, disc_loss = 0.03584116168053796
Trained batch 458 in epoch 8, gen_loss = 0.3879059503151181, disc_loss = 0.035775847861356624
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.3970825672149658, disc_loss = 0.004930734168738127
Trained batch 1 in epoch 9, gen_loss = 0.3764355778694153, disc_loss = 0.003981527406722307
Trained batch 2 in epoch 9, gen_loss = 0.37124164899190265, disc_loss = 0.003538383636623621
Trained batch 3 in epoch 9, gen_loss = 0.36035510152578354, disc_loss = 0.0030942883749958128
Trained batch 4 in epoch 9, gen_loss = 0.35769088864326476, disc_loss = 0.0029121900675818323
Trained batch 5 in epoch 9, gen_loss = 0.3677075058221817, disc_loss = 0.002758529367080579
Trained batch 6 in epoch 9, gen_loss = 0.37383568712643217, disc_loss = 0.002639993193692395
Trained batch 7 in epoch 9, gen_loss = 0.38272300735116005, disc_loss = 0.0026749352109618485
Trained batch 8 in epoch 9, gen_loss = 0.38416725397109985, disc_loss = 0.0026011301411522757
Trained batch 9 in epoch 9, gen_loss = 0.3868454575538635, disc_loss = 0.002510609745513648
Trained batch 10 in epoch 9, gen_loss = 0.38110308755527844, disc_loss = 0.0030380217252637854
Trained batch 11 in epoch 9, gen_loss = 0.38218242178360623, disc_loss = 0.0036930425461226455
Trained batch 12 in epoch 9, gen_loss = 0.38410145273575413, disc_loss = 0.003541023192855601
Trained batch 13 in epoch 9, gen_loss = 0.3809673381703241, disc_loss = 0.0034723851048121496
Trained batch 14 in epoch 9, gen_loss = 0.3852020879586538, disc_loss = 0.0033584374546383818
Trained batch 15 in epoch 9, gen_loss = 0.38426768593490124, disc_loss = 0.003378391767910216
Trained batch 16 in epoch 9, gen_loss = 0.38925231029005614, disc_loss = 0.003297434400712304
Trained batch 17 in epoch 9, gen_loss = 0.3870426267385483, disc_loss = 0.0033955671501138974
Trained batch 18 in epoch 9, gen_loss = 0.38444560452511434, disc_loss = 0.0033831652560222304
Trained batch 19 in epoch 9, gen_loss = 0.38374907821416854, disc_loss = 0.0032995583896990865
Trained batch 20 in epoch 9, gen_loss = 0.38486869704155696, disc_loss = 0.003211648940729598
Trained batch 21 in epoch 9, gen_loss = 0.3817170032046058, disc_loss = 0.003137651957910169
Trained batch 22 in epoch 9, gen_loss = 0.3834860519222591, disc_loss = 0.0031494758820728116
Trained batch 23 in epoch 9, gen_loss = 0.3837582605580489, disc_loss = 0.003096404999572163
Trained batch 24 in epoch 9, gen_loss = 0.38311978816986086, disc_loss = 0.003038701340556145
Trained batch 25 in epoch 9, gen_loss = 0.38270650574794185, disc_loss = 0.00305659630192587
Trained batch 26 in epoch 9, gen_loss = 0.3829979620597981, disc_loss = 0.003066668209309379
Trained batch 27 in epoch 9, gen_loss = 0.3817127315061433, disc_loss = 0.0031252280792354475
Trained batch 28 in epoch 9, gen_loss = 0.38289849511508284, disc_loss = 0.003201664032029181
Trained batch 29 in epoch 9, gen_loss = 0.38214727242787677, disc_loss = 0.0032592649493987363
Trained batch 30 in epoch 9, gen_loss = 0.38340359926223755, disc_loss = 0.003211736138309202
Trained batch 31 in epoch 9, gen_loss = 0.38157386519014835, disc_loss = 0.0032007516419980675
Trained batch 32 in epoch 9, gen_loss = 0.38304282408772095, disc_loss = 0.003207371478448763
Trained batch 33 in epoch 9, gen_loss = 0.3832942378871581, disc_loss = 0.00327727004803498
Trained batch 34 in epoch 9, gen_loss = 0.38362324493271965, disc_loss = 0.0033346350105213267
Trained batch 35 in epoch 9, gen_loss = 0.383977682226234, disc_loss = 0.0033608050693550873
Trained batch 36 in epoch 9, gen_loss = 0.38479536369040207, disc_loss = 0.0033449786148864675
Trained batch 37 in epoch 9, gen_loss = 0.38470440161855596, disc_loss = 0.003360182298102269
Trained batch 38 in epoch 9, gen_loss = 0.3828433492244818, disc_loss = 0.003330198749422263
Trained batch 39 in epoch 9, gen_loss = 0.3843236416578293, disc_loss = 0.003325729997595772
Trained batch 40 in epoch 9, gen_loss = 0.3835045055645268, disc_loss = 0.003405243311667951
Trained batch 41 in epoch 9, gen_loss = 0.38578639711652485, disc_loss = 0.0034133862604254057
Trained batch 42 in epoch 9, gen_loss = 0.3873473558315011, disc_loss = 0.003492917968393412
Trained batch 43 in epoch 9, gen_loss = 0.3873462507670576, disc_loss = 0.0034724551369436085
Trained batch 44 in epoch 9, gen_loss = 0.38735268049769933, disc_loss = 0.0034605879853996965
Trained batch 45 in epoch 9, gen_loss = 0.3880460378916367, disc_loss = 0.00344972880354718
Trained batch 46 in epoch 9, gen_loss = 0.3894503522426524, disc_loss = 0.003417093569333566
Trained batch 47 in epoch 9, gen_loss = 0.3884528800845146, disc_loss = 0.0034310297875587517
Trained batch 48 in epoch 9, gen_loss = 0.38887105973399416, disc_loss = 0.003474462601565281
Trained batch 49 in epoch 9, gen_loss = 0.3878711438179016, disc_loss = 0.0034513698937371374
Trained batch 50 in epoch 9, gen_loss = 0.38806477013756246, disc_loss = 0.0034663933922774066
Trained batch 51 in epoch 9, gen_loss = 0.38797676677887255, disc_loss = 0.0036175134726083623
Trained batch 52 in epoch 9, gen_loss = 0.38791183255753425, disc_loss = 0.0037885175376497914
Trained batch 53 in epoch 9, gen_loss = 0.38764768176608616, disc_loss = 0.0038753499544260128
Trained batch 54 in epoch 9, gen_loss = 0.3870221809907393, disc_loss = 0.0047213354528966274
Trained batch 55 in epoch 9, gen_loss = 0.38789383162345203, disc_loss = 0.004867521942027712
Trained batch 56 in epoch 9, gen_loss = 0.3879881678966054, disc_loss = 0.00544749909047887
Trained batch 57 in epoch 9, gen_loss = 0.3868075696558788, disc_loss = 0.008564998905559808
Trained batch 58 in epoch 9, gen_loss = 0.385726683725745, disc_loss = 0.011967463793738161
Trained batch 59 in epoch 9, gen_loss = 0.38740483671426773, disc_loss = 0.02002276408408458
Trained batch 60 in epoch 9, gen_loss = 0.3874126814427923, disc_loss = 0.02241634885536232
Trained batch 61 in epoch 9, gen_loss = 0.38699408404288754, disc_loss = 0.024342838340559073
Trained batch 62 in epoch 9, gen_loss = 0.3873148352380783, disc_loss = 0.024477926892272774
Trained batch 63 in epoch 9, gen_loss = 0.3883373294956982, disc_loss = 0.024443145168334013
Trained batch 64 in epoch 9, gen_loss = 0.3878669968018165, disc_loss = 0.024758177275697773
Trained batch 65 in epoch 9, gen_loss = 0.387182587927038, disc_loss = 0.02501098616542577
Trained batch 66 in epoch 9, gen_loss = 0.3864551911603159, disc_loss = 0.025148775842068576
Trained batch 67 in epoch 9, gen_loss = 0.38597886877901416, disc_loss = 0.025016733907464454
Trained batch 68 in epoch 9, gen_loss = 0.385348054377929, disc_loss = 0.025291930475825633
Trained batch 69 in epoch 9, gen_loss = 0.3841894596815109, disc_loss = 0.02730827349836805
Trained batch 70 in epoch 9, gen_loss = 0.3861229356745599, disc_loss = 0.03409389057196677
Trained batch 71 in epoch 9, gen_loss = 0.38597287444604766, disc_loss = 0.03474598654429428
Trained batch 72 in epoch 9, gen_loss = 0.3849440343575935, disc_loss = 0.03630778792773514
Trained batch 73 in epoch 9, gen_loss = 0.3843874464163909, disc_loss = 0.036623559259759214
Trained batch 74 in epoch 9, gen_loss = 0.38439518133799233, disc_loss = 0.036790079098815716
Trained batch 75 in epoch 9, gen_loss = 0.3838299881470831, disc_loss = 0.03727695779372497
Trained batch 76 in epoch 9, gen_loss = 0.38329612899136234, disc_loss = 0.03772688426936118
Trained batch 77 in epoch 9, gen_loss = 0.38287405325816226, disc_loss = 0.03933789860158681
Trained batch 78 in epoch 9, gen_loss = 0.3823878651932825, disc_loss = 0.04348984240153451
Trained batch 79 in epoch 9, gen_loss = 0.3829386729747057, disc_loss = 0.04425603963609319
Trained batch 80 in epoch 9, gen_loss = 0.3831077420417173, disc_loss = 0.0462278737715319
Trained batch 81 in epoch 9, gen_loss = 0.382202420656274, disc_loss = 0.046844331976367025
Trained batch 82 in epoch 9, gen_loss = 0.3813555136502507, disc_loss = 0.04859216315727905
Trained batch 83 in epoch 9, gen_loss = 0.38269847808849244, disc_loss = 0.04854789058888508
Trained batch 84 in epoch 9, gen_loss = 0.38341761792407314, disc_loss = 0.04905945835908984
Trained batch 85 in epoch 9, gen_loss = 0.38374138259610463, disc_loss = 0.049254660102062274
Trained batch 86 in epoch 9, gen_loss = 0.3833061562872481, disc_loss = 0.04982444543081025
Trained batch 87 in epoch 9, gen_loss = 0.3832163560119542, disc_loss = 0.05015264038493941
Trained batch 88 in epoch 9, gen_loss = 0.38328748439135174, disc_loss = 0.051679849224374366
Trained batch 89 in epoch 9, gen_loss = 0.383218882812394, disc_loss = 0.05581120080573277
Trained batch 90 in epoch 9, gen_loss = 0.3844850921368861, disc_loss = 0.05583877437543329
Trained batch 91 in epoch 9, gen_loss = 0.38407620722832886, disc_loss = 0.05636348236989959
Trained batch 92 in epoch 9, gen_loss = 0.38295673234488375, disc_loss = 0.057557497631698366
Trained batch 93 in epoch 9, gen_loss = 0.38430389318060365, disc_loss = 0.05895687371958047
Trained batch 94 in epoch 9, gen_loss = 0.3842888970124094, disc_loss = 0.05854715494880159
Trained batch 95 in epoch 9, gen_loss = 0.38386151815454167, disc_loss = 0.058117492413051274
Trained batch 96 in epoch 9, gen_loss = 0.38288659809790937, disc_loss = 0.057665586565169936
Trained batch 97 in epoch 9, gen_loss = 0.383140432591341, disc_loss = 0.05719542045060697
Trained batch 98 in epoch 9, gen_loss = 0.38320014753727, disc_loss = 0.057023574210082494
Trained batch 99 in epoch 9, gen_loss = 0.383627325296402, disc_loss = 0.05668303513666615
Trained batch 100 in epoch 9, gen_loss = 0.38381226729638507, disc_loss = 0.05635558361750059
Trained batch 101 in epoch 9, gen_loss = 0.3834522124014649, disc_loss = 0.05615401682306958
Trained batch 102 in epoch 9, gen_loss = 0.3834295348056312, disc_loss = 0.056371336909083344
Trained batch 103 in epoch 9, gen_loss = 0.383383653484858, disc_loss = 0.059462932348161794
Trained batch 104 in epoch 9, gen_loss = 0.3831165915443784, disc_loss = 0.059573373533341856
Trained batch 105 in epoch 9, gen_loss = 0.3828255590402855, disc_loss = 0.060250479145906866
Trained batch 106 in epoch 9, gen_loss = 0.3831913357026109, disc_loss = 0.059828563556336214
Trained batch 107 in epoch 9, gen_loss = 0.38365084760718876, disc_loss = 0.059527472254423494
Trained batch 108 in epoch 9, gen_loss = 0.3843016690070476, disc_loss = 0.05903111791041671
Trained batch 109 in epoch 9, gen_loss = 0.3836603638800708, disc_loss = 0.05908545861655677
Trained batch 110 in epoch 9, gen_loss = 0.3836378855211241, disc_loss = 0.05881278975111608
Trained batch 111 in epoch 9, gen_loss = 0.3831584339163133, disc_loss = 0.05845233097664147
Trained batch 112 in epoch 9, gen_loss = 0.38328048745087817, disc_loss = 0.05804832503652876
Trained batch 113 in epoch 9, gen_loss = 0.3838829296199899, disc_loss = 0.05772535285397776
Trained batch 114 in epoch 9, gen_loss = 0.38396520873774653, disc_loss = 0.058704850253770535
Trained batch 115 in epoch 9, gen_loss = 0.38415439169982385, disc_loss = 0.06226164004404162
Trained batch 116 in epoch 9, gen_loss = 0.3843412277026054, disc_loss = 0.06178465385077537
Trained batch 117 in epoch 9, gen_loss = 0.38403294172327396, disc_loss = 0.06170392164100214
Trained batch 118 in epoch 9, gen_loss = 0.3835026444006367, disc_loss = 0.06140727236546075
Trained batch 119 in epoch 9, gen_loss = 0.38284188136458397, disc_loss = 0.06129183511366136
Trained batch 120 in epoch 9, gen_loss = 0.38255904011489933, disc_loss = 0.06114471327967572
Trained batch 121 in epoch 9, gen_loss = 0.38235078507759535, disc_loss = 0.060835849339157706
Trained batch 122 in epoch 9, gen_loss = 0.38247847702445054, disc_loss = 0.06106845268078633
Trained batch 123 in epoch 9, gen_loss = 0.382670069894483, disc_loss = 0.06169775221309054
Trained batch 124 in epoch 9, gen_loss = 0.3828380615711212, disc_loss = 0.06192346867732704
Trained batch 125 in epoch 9, gen_loss = 0.3838800345621412, disc_loss = 0.06275467535976084
Trained batch 126 in epoch 9, gen_loss = 0.3840510035593679, disc_loss = 0.06237069630856061
Trained batch 127 in epoch 9, gen_loss = 0.38383868359960616, disc_loss = 0.06290880150299927
Trained batch 128 in epoch 9, gen_loss = 0.38392469610354696, disc_loss = 0.06279881439142854
Trained batch 129 in epoch 9, gen_loss = 0.3841958327935292, disc_loss = 0.06293649446183386
Trained batch 130 in epoch 9, gen_loss = 0.38420361962937216, disc_loss = 0.06254034146545669
Trained batch 131 in epoch 9, gen_loss = 0.38395493929133273, disc_loss = 0.06219644964298685
Trained batch 132 in epoch 9, gen_loss = 0.3838550517881723, disc_loss = 0.061829553376113004
Trained batch 133 in epoch 9, gen_loss = 0.3838950571284365, disc_loss = 0.06144274269932631
Trained batch 134 in epoch 9, gen_loss = 0.3836117861447511, disc_loss = 0.06101888967850418
Trained batch 135 in epoch 9, gen_loss = 0.3835303612491664, disc_loss = 0.060602536731440684
Trained batch 136 in epoch 9, gen_loss = 0.3834699455403934, disc_loss = 0.06092391916836211
Trained batch 137 in epoch 9, gen_loss = 0.38335940716923145, disc_loss = 0.06118856827168307
Trained batch 138 in epoch 9, gen_loss = 0.3828733134612763, disc_loss = 0.06198581884842929
Trained batch 139 in epoch 9, gen_loss = 0.3831426109586443, disc_loss = 0.06214539422487308
Trained batch 140 in epoch 9, gen_loss = 0.38285227933673993, disc_loss = 0.06380861609718426
Trained batch 141 in epoch 9, gen_loss = 0.3830648379426607, disc_loss = 0.06397211727928895
Trained batch 142 in epoch 9, gen_loss = 0.38259083095130386, disc_loss = 0.06416069969398107
Trained batch 143 in epoch 9, gen_loss = 0.38257208011216587, disc_loss = 0.06434128079531042
Trained batch 144 in epoch 9, gen_loss = 0.3818189333225119, disc_loss = 0.06510817817540775
Trained batch 145 in epoch 9, gen_loss = 0.3826115462061477, disc_loss = 0.06736195820211496
Trained batch 146 in epoch 9, gen_loss = 0.3831499885945093, disc_loss = 0.06764571614987945
Trained batch 147 in epoch 9, gen_loss = 0.38338430044618815, disc_loss = 0.06897054122276353
Trained batch 148 in epoch 9, gen_loss = 0.3829919993877411, disc_loss = 0.06883483883087217
Trained batch 149 in epoch 9, gen_loss = 0.3823271240790685, disc_loss = 0.06866705385812868
Trained batch 150 in epoch 9, gen_loss = 0.3819095894990378, disc_loss = 0.06843157219145422
Trained batch 151 in epoch 9, gen_loss = 0.38199621478193685, disc_loss = 0.06814064658216298
Trained batch 152 in epoch 9, gen_loss = 0.3822096167436612, disc_loss = 0.06782232008697892
Trained batch 153 in epoch 9, gen_loss = 0.38195783364308344, disc_loss = 0.06787512343007975
Trained batch 154 in epoch 9, gen_loss = 0.38193355491084435, disc_loss = 0.06784990447152767
Trained batch 155 in epoch 9, gen_loss = 0.38253140965333354, disc_loss = 0.06768489182920745
Trained batch 156 in epoch 9, gen_loss = 0.38257362907099873, disc_loss = 0.06763475350768655
Trained batch 157 in epoch 9, gen_loss = 0.38314269916920723, disc_loss = 0.06725261465180665
Trained batch 158 in epoch 9, gen_loss = 0.3834424536183195, disc_loss = 0.06748079345561564
Trained batch 159 in epoch 9, gen_loss = 0.3834869576618075, disc_loss = 0.06768038469454041
Trained batch 160 in epoch 9, gen_loss = 0.3836132717428741, disc_loss = 0.06729111827834747
Trained batch 161 in epoch 9, gen_loss = 0.3840212433794398, disc_loss = 0.06696286846245467
Trained batch 162 in epoch 9, gen_loss = 0.3840927574897836, disc_loss = 0.06659607767938791
Trained batch 163 in epoch 9, gen_loss = 0.38459805780794565, disc_loss = 0.0662248980682684
Trained batch 164 in epoch 9, gen_loss = 0.38481824109048557, disc_loss = 0.06592716813285017
Trained batch 165 in epoch 9, gen_loss = 0.3848294035856982, disc_loss = 0.0655889827463529
Trained batch 166 in epoch 9, gen_loss = 0.38470691121266987, disc_loss = 0.06526377483014531
Trained batch 167 in epoch 9, gen_loss = 0.3851686402090958, disc_loss = 0.06497141985372375
Trained batch 168 in epoch 9, gen_loss = 0.3852862481182144, disc_loss = 0.0646874223981802
Trained batch 169 in epoch 9, gen_loss = 0.385286068741013, disc_loss = 0.06486694383681478
Trained batch 170 in epoch 9, gen_loss = 0.38554605214219345, disc_loss = 0.06464139755940533
Trained batch 171 in epoch 9, gen_loss = 0.38553441783716513, disc_loss = 0.06455007325830804
Trained batch 172 in epoch 9, gen_loss = 0.38530835888289305, disc_loss = 0.06598406108876831
Trained batch 173 in epoch 9, gen_loss = 0.3857038341376973, disc_loss = 0.06927393094620443
Trained batch 174 in epoch 9, gen_loss = 0.3859980516774314, disc_loss = 0.06940196220763027
Trained batch 175 in epoch 9, gen_loss = 0.38584320568902924, disc_loss = 0.06921255008968398
Trained batch 176 in epoch 9, gen_loss = 0.3861748545856799, disc_loss = 0.06903692270039796
Trained batch 177 in epoch 9, gen_loss = 0.38556784542089095, disc_loss = 0.06883914421673529
Trained batch 178 in epoch 9, gen_loss = 0.38567564890371353, disc_loss = 0.06852445896459983
Trained batch 179 in epoch 9, gen_loss = 0.3855293861693806, disc_loss = 0.06817926633973709
Trained batch 180 in epoch 9, gen_loss = 0.38577105821166907, disc_loss = 0.0678182019021115
Trained batch 181 in epoch 9, gen_loss = 0.38538344777547395, disc_loss = 0.0674602495900427
Trained batch 182 in epoch 9, gen_loss = 0.38544577734717905, disc_loss = 0.06711415975746479
Trained batch 183 in epoch 9, gen_loss = 0.38526980449324066, disc_loss = 0.06677139262193003
Trained batch 184 in epoch 9, gen_loss = 0.3856473652092186, disc_loss = 0.0664307885022985
Trained batch 185 in epoch 9, gen_loss = 0.3857468491600406, disc_loss = 0.06608856984248926
Trained batch 186 in epoch 9, gen_loss = 0.3860664998783785, disc_loss = 0.0657520693836405
Trained batch 187 in epoch 9, gen_loss = 0.38646274488022986, disc_loss = 0.0654234672138626
Trained batch 188 in epoch 9, gen_loss = 0.3862265507695536, disc_loss = 0.06512794154572976
Trained batch 189 in epoch 9, gen_loss = 0.3864263694537313, disc_loss = 0.0648624286913362
Trained batch 190 in epoch 9, gen_loss = 0.3865794311643271, disc_loss = 0.0646022374312642
Trained batch 191 in epoch 9, gen_loss = 0.3859911809364955, disc_loss = 0.06439387022449712
Trained batch 192 in epoch 9, gen_loss = 0.38622744111199453, disc_loss = 0.0643362174018098
Trained batch 193 in epoch 9, gen_loss = 0.38589826226234436, disc_loss = 0.06495004266586885
Trained batch 194 in epoch 9, gen_loss = 0.38611889282862344, disc_loss = 0.06667540046887901
Trained batch 195 in epoch 9, gen_loss = 0.3858137960944857, disc_loss = 0.06670158041156449
Trained batch 196 in epoch 9, gen_loss = 0.38514201350623584, disc_loss = 0.06680408184686061
Trained batch 197 in epoch 9, gen_loss = 0.3849786894791054, disc_loss = 0.06711795862359607
Trained batch 198 in epoch 9, gen_loss = 0.38495593454370547, disc_loss = 0.06734752059965651
Trained batch 199 in epoch 9, gen_loss = 0.38470628663897516, disc_loss = 0.0672908997000195
Trained batch 200 in epoch 9, gen_loss = 0.3848662254822195, disc_loss = 0.06699057270202842
Trained batch 201 in epoch 9, gen_loss = 0.3847642757809988, disc_loss = 0.06673311970731484
Trained batch 202 in epoch 9, gen_loss = 0.3846670666645313, disc_loss = 0.06693203447460028
Trained batch 203 in epoch 9, gen_loss = 0.38459642625906887, disc_loss = 0.06701390110367142
Trained batch 204 in epoch 9, gen_loss = 0.3847360222804837, disc_loss = 0.06676070083432445
Trained batch 205 in epoch 9, gen_loss = 0.38484736278797815, disc_loss = 0.06685823958267648
Trained batch 206 in epoch 9, gen_loss = 0.3851262711096501, disc_loss = 0.06656683557374393
Trained batch 207 in epoch 9, gen_loss = 0.3849550008487243, disc_loss = 0.06658596646425743
Trained batch 208 in epoch 9, gen_loss = 0.38504365143593416, disc_loss = 0.06652919660014898
Trained batch 209 in epoch 9, gen_loss = 0.38501019307545253, disc_loss = 0.06639735220399286
Trained batch 210 in epoch 9, gen_loss = 0.38479536715276996, disc_loss = 0.06628884010290577
Trained batch 211 in epoch 9, gen_loss = 0.38462673816478476, disc_loss = 0.0661362006904487
Trained batch 212 in epoch 9, gen_loss = 0.385092319457184, disc_loss = 0.06590769660960831
Trained batch 213 in epoch 9, gen_loss = 0.38441141033284015, disc_loss = 0.06716669650931155
Trained batch 214 in epoch 9, gen_loss = 0.3848291564819425, disc_loss = 0.06983971111259835
Trained batch 215 in epoch 9, gen_loss = 0.3849217979996293, disc_loss = 0.07045848799343393
Trained batch 216 in epoch 9, gen_loss = 0.385108681730411, disc_loss = 0.07032023933995087
Trained batch 217 in epoch 9, gen_loss = 0.38508292376448255, disc_loss = 0.07020502030601673
Trained batch 218 in epoch 9, gen_loss = 0.38519062462462683, disc_loss = 0.06996765731702044
Trained batch 219 in epoch 9, gen_loss = 0.38508659276095303, disc_loss = 0.06970774298745462
Trained batch 220 in epoch 9, gen_loss = 0.38487667951109183, disc_loss = 0.06942211324349046
Trained batch 221 in epoch 9, gen_loss = 0.38497692158630303, disc_loss = 0.06914952708836142
Trained batch 222 in epoch 9, gen_loss = 0.3850109546441134, disc_loss = 0.06893226065184303
Trained batch 223 in epoch 9, gen_loss = 0.3855675297922322, disc_loss = 0.06878715276460363
Trained batch 224 in epoch 9, gen_loss = 0.38531202329529657, disc_loss = 0.06885000793677237
Trained batch 225 in epoch 9, gen_loss = 0.38506732881069183, disc_loss = 0.06867645009404329
Trained batch 226 in epoch 9, gen_loss = 0.38537630701380154, disc_loss = 0.06873071004353497
Trained batch 227 in epoch 9, gen_loss = 0.3854172538247025, disc_loss = 0.06859086273573012
Trained batch 228 in epoch 9, gen_loss = 0.3854752409406104, disc_loss = 0.06878209032126455
Trained batch 229 in epoch 9, gen_loss = 0.3860571692819181, disc_loss = 0.06928849443185912
Trained batch 230 in epoch 9, gen_loss = 0.3861154783597756, disc_loss = 0.0691565960198157
Trained batch 231 in epoch 9, gen_loss = 0.38607177408090954, disc_loss = 0.06896837814590605
Trained batch 232 in epoch 9, gen_loss = 0.3857881526578649, disc_loss = 0.06894331132241649
Trained batch 233 in epoch 9, gen_loss = 0.38551620387623453, disc_loss = 0.06904972597168615
Trained batch 234 in epoch 9, gen_loss = 0.3854862493403414, disc_loss = 0.06892965706461604
Trained batch 235 in epoch 9, gen_loss = 0.3859949630953498, disc_loss = 0.0687649385407725
Trained batch 236 in epoch 9, gen_loss = 0.38586057351611336, disc_loss = 0.06935992707470864
Trained batch 237 in epoch 9, gen_loss = 0.38565917400752797, disc_loss = 0.06991417445594586
Trained batch 238 in epoch 9, gen_loss = 0.38601742965406954, disc_loss = 0.07013528163751362
Trained batch 239 in epoch 9, gen_loss = 0.3861588206142187, disc_loss = 0.07007578430736126
Trained batch 240 in epoch 9, gen_loss = 0.3855423126601579, disc_loss = 0.07039976298724035
Trained batch 241 in epoch 9, gen_loss = 0.38523719410512075, disc_loss = 0.07101273037346988
Trained batch 242 in epoch 9, gen_loss = 0.3856162157200982, disc_loss = 0.07255789961995472
Trained batch 243 in epoch 9, gen_loss = 0.38531613930082714, disc_loss = 0.07340620573587166
Trained batch 244 in epoch 9, gen_loss = 0.3850498352123767, disc_loss = 0.07385567614656625
Trained batch 245 in epoch 9, gen_loss = 0.38500716222253273, disc_loss = 0.07365965280810569
Trained batch 246 in epoch 9, gen_loss = 0.38524647201845036, disc_loss = 0.07344886424728794
Trained batch 247 in epoch 9, gen_loss = 0.3853068474920527, disc_loss = 0.07339681658871292
Trained batch 248 in epoch 9, gen_loss = 0.38530218140427847, disc_loss = 0.07322523489512174
Trained batch 249 in epoch 9, gen_loss = 0.3852946110367775, disc_loss = 0.07319987840391695
Trained batch 250 in epoch 9, gen_loss = 0.38517133179176377, disc_loss = 0.07313286089542437
Trained batch 251 in epoch 9, gen_loss = 0.3852215816695539, disc_loss = 0.07324076113697614
Trained batch 252 in epoch 9, gen_loss = 0.38495711958691065, disc_loss = 0.07355208925556818
Trained batch 253 in epoch 9, gen_loss = 0.38475918599705056, disc_loss = 0.07356515463155613
Trained batch 254 in epoch 9, gen_loss = 0.3848706880620882, disc_loss = 0.07360059599410378
Trained batch 255 in epoch 9, gen_loss = 0.38465253106551245, disc_loss = 0.07435047735089029
Trained batch 256 in epoch 9, gen_loss = 0.38476657803652353, disc_loss = 0.07523058805114623
Trained batch 257 in epoch 9, gen_loss = 0.38516050975683125, disc_loss = 0.07499336380720889
Trained batch 258 in epoch 9, gen_loss = 0.38506441428164256, disc_loss = 0.074895101942798
Trained batch 259 in epoch 9, gen_loss = 0.38460477435818086, disc_loss = 0.07482348597572687
Trained batch 260 in epoch 9, gen_loss = 0.38463686212497655, disc_loss = 0.07459515858605732
Trained batch 261 in epoch 9, gen_loss = 0.3846993580005551, disc_loss = 0.07433252882404352
Trained batch 262 in epoch 9, gen_loss = 0.3852170233830753, disc_loss = 0.07407933117524355
Trained batch 263 in epoch 9, gen_loss = 0.3850564927878705, disc_loss = 0.07401834204828253
Trained batch 264 in epoch 9, gen_loss = 0.3850080920277901, disc_loss = 0.07386082910739307
Trained batch 265 in epoch 9, gen_loss = 0.3847398334988078, disc_loss = 0.07399292659413602
Trained batch 266 in epoch 9, gen_loss = 0.384819480754463, disc_loss = 0.07430152287567209
Trained batch 267 in epoch 9, gen_loss = 0.3851254257137206, disc_loss = 0.07509378421141195
Trained batch 268 in epoch 9, gen_loss = 0.38533840009935727, disc_loss = 0.07496328794026962
Trained batch 269 in epoch 9, gen_loss = 0.38500579877032176, disc_loss = 0.07490156271701885
Trained batch 270 in epoch 9, gen_loss = 0.38489152293143675, disc_loss = 0.0747991271567878
Trained batch 271 in epoch 9, gen_loss = 0.3851756640326451, disc_loss = 0.07456013854928589
Trained batch 272 in epoch 9, gen_loss = 0.3853398398274467, disc_loss = 0.0743686382031075
Trained batch 273 in epoch 9, gen_loss = 0.38532790688485125, disc_loss = 0.07425790885293408
Trained batch 274 in epoch 9, gen_loss = 0.38557472960515454, disc_loss = 0.07404385096139529
Trained batch 275 in epoch 9, gen_loss = 0.3855505760057249, disc_loss = 0.07405179963899318
Trained batch 276 in epoch 9, gen_loss = 0.38560693998844614, disc_loss = 0.0742415205158616
Trained batch 277 in epoch 9, gen_loss = 0.3854359579708079, disc_loss = 0.0749191618574743
Trained batch 278 in epoch 9, gen_loss = 0.38581399726397675, disc_loss = 0.07561223741160125
Trained batch 279 in epoch 9, gen_loss = 0.3858527829072305, disc_loss = 0.0757192221686377
Trained batch 280 in epoch 9, gen_loss = 0.38567599107998546, disc_loss = 0.07557366537327921
Trained batch 281 in epoch 9, gen_loss = 0.3854381352768722, disc_loss = 0.07536823112444939
Trained batch 282 in epoch 9, gen_loss = 0.3852459369720924, disc_loss = 0.07515508510902945
Trained batch 283 in epoch 9, gen_loss = 0.3853295024117114, disc_loss = 0.07490858825048248
Trained batch 284 in epoch 9, gen_loss = 0.3854597066055264, disc_loss = 0.0746607360168638
Trained batch 285 in epoch 9, gen_loss = 0.38530889752653097, disc_loss = 0.07442536512129269
Trained batch 286 in epoch 9, gen_loss = 0.3853070243206589, disc_loss = 0.07419674994443455
Trained batch 287 in epoch 9, gen_loss = 0.38506891707786256, disc_loss = 0.07402545577497222
Trained batch 288 in epoch 9, gen_loss = 0.38498770803934973, disc_loss = 0.07411231514659411
Trained batch 289 in epoch 9, gen_loss = 0.3851582923325999, disc_loss = 0.07405777915605698
Trained batch 290 in epoch 9, gen_loss = 0.38545252792409196, disc_loss = 0.07486566392019954
Trained batch 291 in epoch 9, gen_loss = 0.38543734827066123, disc_loss = 0.0757675443693026
Trained batch 292 in epoch 9, gen_loss = 0.385490557897213, disc_loss = 0.076002139105452
Trained batch 293 in epoch 9, gen_loss = 0.38532068286420534, disc_loss = 0.07672002539355434
Trained batch 294 in epoch 9, gen_loss = 0.38493761687965716, disc_loss = 0.0770066334818632
Trained batch 295 in epoch 9, gen_loss = 0.3847194344711465, disc_loss = 0.07694372177640027
Trained batch 296 in epoch 9, gen_loss = 0.3846619419678293, disc_loss = 0.07685233043312324
Trained batch 297 in epoch 9, gen_loss = 0.38471946995330336, disc_loss = 0.07698956907308041
Trained batch 298 in epoch 9, gen_loss = 0.3847400717013656, disc_loss = 0.07717573807503168
Trained batch 299 in epoch 9, gen_loss = 0.38473821376760803, disc_loss = 0.07696236368268729
Trained batch 300 in epoch 9, gen_loss = 0.38499934357464116, disc_loss = 0.07688786110460163
Trained batch 301 in epoch 9, gen_loss = 0.38499852348834473, disc_loss = 0.07666180415436724
Trained batch 302 in epoch 9, gen_loss = 0.3850958382237469, disc_loss = 0.07649947171754176
Trained batch 303 in epoch 9, gen_loss = 0.38471978172463805, disc_loss = 0.07638466365537361
Trained batch 304 in epoch 9, gen_loss = 0.3847939993025827, disc_loss = 0.07620518904362546
Trained batch 305 in epoch 9, gen_loss = 0.38502660310930675, disc_loss = 0.07597065685633449
Trained batch 306 in epoch 9, gen_loss = 0.3849649617163288, disc_loss = 0.07578180386026538
Trained batch 307 in epoch 9, gen_loss = 0.3851950466149039, disc_loss = 0.07558366929955006
Trained batch 308 in epoch 9, gen_loss = 0.3852239566038342, disc_loss = 0.07559967600713366
Trained batch 309 in epoch 9, gen_loss = 0.3852748289704323, disc_loss = 0.07598116056873433
Trained batch 310 in epoch 9, gen_loss = 0.3852311573515368, disc_loss = 0.07633591604110608
Trained batch 311 in epoch 9, gen_loss = 0.38518320372662485, disc_loss = 0.0762526914387798
Trained batch 312 in epoch 9, gen_loss = 0.38521915488540176, disc_loss = 0.07637339172521815
Trained batch 313 in epoch 9, gen_loss = 0.3853139855964169, disc_loss = 0.07618758853252051
Trained batch 314 in epoch 9, gen_loss = 0.3852343248469489, disc_loss = 0.07621935667204005
Trained batch 315 in epoch 9, gen_loss = 0.38550815679415873, disc_loss = 0.07602565655708785
Trained batch 316 in epoch 9, gen_loss = 0.3860768094329804, disc_loss = 0.07609992512216797
Trained batch 317 in epoch 9, gen_loss = 0.38593031451949533, disc_loss = 0.07634927264748598
Trained batch 318 in epoch 9, gen_loss = 0.38607204236020115, disc_loss = 0.07647520946309577
Trained batch 319 in epoch 9, gen_loss = 0.38612242401577535, disc_loss = 0.07628721443179529
Trained batch 320 in epoch 9, gen_loss = 0.386094082320962, disc_loss = 0.07672030432004702
Trained batch 321 in epoch 9, gen_loss = 0.3863301293357559, disc_loss = 0.0770178084805469
Trained batch 322 in epoch 9, gen_loss = 0.3862321342200318, disc_loss = 0.0768121532524933
Trained batch 323 in epoch 9, gen_loss = 0.3862123720715811, disc_loss = 0.07663672814364142
Trained batch 324 in epoch 9, gen_loss = 0.3861163476338753, disc_loss = 0.07667065637902572
Trained batch 325 in epoch 9, gen_loss = 0.38594958254713224, disc_loss = 0.07652788495279254
Trained batch 326 in epoch 9, gen_loss = 0.38595535590196606, disc_loss = 0.07716198033433898
Trained batch 327 in epoch 9, gen_loss = 0.38583649872098025, disc_loss = 0.07765505136070182
Trained batch 328 in epoch 9, gen_loss = 0.3859195503148627, disc_loss = 0.07757508111862879
Trained batch 329 in epoch 9, gen_loss = 0.38578774743910993, disc_loss = 0.07762800179929896
Trained batch 330 in epoch 9, gen_loss = 0.3856076221361621, disc_loss = 0.07770782497815586
Trained batch 331 in epoch 9, gen_loss = 0.38579185203794975, disc_loss = 0.07755165484576788
Trained batch 332 in epoch 9, gen_loss = 0.3859163748698908, disc_loss = 0.07736165675001817
Trained batch 333 in epoch 9, gen_loss = 0.3856437671594991, disc_loss = 0.07728897944137365
Trained batch 334 in epoch 9, gen_loss = 0.3858076512368757, disc_loss = 0.07751285672855021
Trained batch 335 in epoch 9, gen_loss = 0.3853953241681059, disc_loss = 0.07771752649430363
Trained batch 336 in epoch 9, gen_loss = 0.38528276555439134, disc_loss = 0.07762674057651699
Trained batch 337 in epoch 9, gen_loss = 0.38513076062914886, disc_loss = 0.07751623573079264
Trained batch 338 in epoch 9, gen_loss = 0.38509547556571905, disc_loss = 0.07739448360549313
Trained batch 339 in epoch 9, gen_loss = 0.3852368327186388, disc_loss = 0.07721332930138006
Trained batch 340 in epoch 9, gen_loss = 0.38527126933647393, disc_loss = 0.07710209080834718
Trained batch 341 in epoch 9, gen_loss = 0.3850495732057164, disc_loss = 0.077419032244698
Trained batch 342 in epoch 9, gen_loss = 0.385079758029985, disc_loss = 0.07837096015778819
Trained batch 343 in epoch 9, gen_loss = 0.38528490460716014, disc_loss = 0.07877294457690834
Trained batch 344 in epoch 9, gen_loss = 0.3854130299626917, disc_loss = 0.07890310214589472
Trained batch 345 in epoch 9, gen_loss = 0.3854177119156529, disc_loss = 0.07881683758809904
Trained batch 346 in epoch 9, gen_loss = 0.3852745607624136, disc_loss = 0.0788391869278995
Trained batch 347 in epoch 9, gen_loss = 0.3853279609532877, disc_loss = 0.07864961860936949
Trained batch 348 in epoch 9, gen_loss = 0.3852163290652983, disc_loss = 0.07875550580998204
Trained batch 349 in epoch 9, gen_loss = 0.38517148107290267, disc_loss = 0.07874874006424631
Trained batch 350 in epoch 9, gen_loss = 0.3850242750682043, disc_loss = 0.07948385321261876
Trained batch 351 in epoch 9, gen_loss = 0.385268498762426, disc_loss = 0.07960921092043546
Trained batch 352 in epoch 9, gen_loss = 0.38523639974952084, disc_loss = 0.0795481751221773
Trained batch 353 in epoch 9, gen_loss = 0.38492275719757135, disc_loss = 0.08036779363950093
Trained batch 354 in epoch 9, gen_loss = 0.3846186371336521, disc_loss = 0.0809191344489514
Trained batch 355 in epoch 9, gen_loss = 0.3844491813038842, disc_loss = 0.08133531403675508
Trained batch 356 in epoch 9, gen_loss = 0.3842360726675066, disc_loss = 0.08168939123300611
Trained batch 357 in epoch 9, gen_loss = 0.3844017261150163, disc_loss = 0.08167871524834766
Trained batch 358 in epoch 9, gen_loss = 0.3845541622894388, disc_loss = 0.0817961648812201
Trained batch 359 in epoch 9, gen_loss = 0.3843428590645393, disc_loss = 0.08195311857594384
Trained batch 360 in epoch 9, gen_loss = 0.38458266313551537, disc_loss = 0.08181447580126514
Trained batch 361 in epoch 9, gen_loss = 0.3847931870851069, disc_loss = 0.08166613044906716
Trained batch 362 in epoch 9, gen_loss = 0.3849210318372926, disc_loss = 0.08160071137563912
Trained batch 363 in epoch 9, gen_loss = 0.38496356789063624, disc_loss = 0.0814682431109659
Trained batch 364 in epoch 9, gen_loss = 0.3851054841933185, disc_loss = 0.08130870175688235
Trained batch 365 in epoch 9, gen_loss = 0.3849256368852704, disc_loss = 0.08133591617879972
Trained batch 366 in epoch 9, gen_loss = 0.3851648524850201, disc_loss = 0.08154559468378487
Trained batch 367 in epoch 9, gen_loss = 0.3852844592588751, disc_loss = 0.08141562091591566
Trained batch 368 in epoch 9, gen_loss = 0.3853217637555063, disc_loss = 0.08142733408345117
Trained batch 369 in epoch 9, gen_loss = 0.3854726944823523, disc_loss = 0.08128421223546202
Trained batch 370 in epoch 9, gen_loss = 0.38552541203415297, disc_loss = 0.08127295199249472
Trained batch 371 in epoch 9, gen_loss = 0.38551607299395785, disc_loss = 0.08108430012549844
Trained batch 372 in epoch 9, gen_loss = 0.3854842976574604, disc_loss = 0.08104245755421971
Trained batch 373 in epoch 9, gen_loss = 0.38538011219252877, disc_loss = 0.0808909404450121
Trained batch 374 in epoch 9, gen_loss = 0.3852765022516251, disc_loss = 0.08084417785455783
Trained batch 375 in epoch 9, gen_loss = 0.385385370912387, disc_loss = 0.08071037739802628
Trained batch 376 in epoch 9, gen_loss = 0.3854230378682797, disc_loss = 0.08064846530685137
Trained batch 377 in epoch 9, gen_loss = 0.3856646963764751, disc_loss = 0.08047564693839934
Trained batch 378 in epoch 9, gen_loss = 0.38561370265043504, disc_loss = 0.08035880847684154
Trained batch 379 in epoch 9, gen_loss = 0.3856887945611226, disc_loss = 0.08037420816621497
Trained batch 380 in epoch 9, gen_loss = 0.38553756268162115, disc_loss = 0.08073850769520276
Trained batch 381 in epoch 9, gen_loss = 0.38574640995076814, disc_loss = 0.0815942284275646
Trained batch 382 in epoch 9, gen_loss = 0.3858876597554503, disc_loss = 0.08140899370820809
Trained batch 383 in epoch 9, gen_loss = 0.38593858600749326, disc_loss = 0.08122799473251992
Trained batch 384 in epoch 9, gen_loss = 0.38583455345073303, disc_loss = 0.08110379053690991
Trained batch 385 in epoch 9, gen_loss = 0.38579189958813276, disc_loss = 0.08093397210019163
Trained batch 386 in epoch 9, gen_loss = 0.3857906316370927, disc_loss = 0.08078531461505542
Trained batch 387 in epoch 9, gen_loss = 0.38580397359028307, disc_loss = 0.08063981504678804
Trained batch 388 in epoch 9, gen_loss = 0.38564917816754174, disc_loss = 0.0806786033485305
Trained batch 389 in epoch 9, gen_loss = 0.3854824173526886, disc_loss = 0.08092180346496976
Trained batch 390 in epoch 9, gen_loss = 0.3853630481854729, disc_loss = 0.08175208693241601
Trained batch 391 in epoch 9, gen_loss = 0.3855098838328707, disc_loss = 0.08186198175381108
Trained batch 392 in epoch 9, gen_loss = 0.3855938304395773, disc_loss = 0.08168138452727376
Trained batch 393 in epoch 9, gen_loss = 0.38572453994890155, disc_loss = 0.08149395430422753
Trained batch 394 in epoch 9, gen_loss = 0.38558041457133957, disc_loss = 0.08134080263302673
Trained batch 395 in epoch 9, gen_loss = 0.38547115189710046, disc_loss = 0.08116627948104659
Trained batch 396 in epoch 9, gen_loss = 0.3855311098492116, disc_loss = 0.08098264232099582
Trained batch 397 in epoch 9, gen_loss = 0.3855879664346201, disc_loss = 0.08082861819505767
Trained batch 398 in epoch 9, gen_loss = 0.38571758284455254, disc_loss = 0.0806683421270329
Trained batch 399 in epoch 9, gen_loss = 0.38559282917529347, disc_loss = 0.08080070307711139
Trained batch 400 in epoch 9, gen_loss = 0.3857114626062184, disc_loss = 0.0812904879176743
Trained batch 401 in epoch 9, gen_loss = 0.3853449918959864, disc_loss = 0.08211740412383307
Trained batch 402 in epoch 9, gen_loss = 0.3853290878587562, disc_loss = 0.08222119503009778
Trained batch 403 in epoch 9, gen_loss = 0.38526718875411714, disc_loss = 0.08248245225767467
Trained batch 404 in epoch 9, gen_loss = 0.3852610804048585, disc_loss = 0.08282941024474523
Trained batch 405 in epoch 9, gen_loss = 0.3851723132535742, disc_loss = 0.08311533704262429
Trained batch 406 in epoch 9, gen_loss = 0.385206907877758, disc_loss = 0.08330809612614297
Trained batch 407 in epoch 9, gen_loss = 0.3851677859019415, disc_loss = 0.08337429849038303
Trained batch 408 in epoch 9, gen_loss = 0.3852314707483814, disc_loss = 0.08347601709718883
Trained batch 409 in epoch 9, gen_loss = 0.3851229034182502, disc_loss = 0.08349599803956907
Trained batch 410 in epoch 9, gen_loss = 0.385048306082577, disc_loss = 0.08342790382703508
Trained batch 411 in epoch 9, gen_loss = 0.3850748252159762, disc_loss = 0.08333726611793113
Trained batch 412 in epoch 9, gen_loss = 0.38524516460826264, disc_loss = 0.08331124732816551
Trained batch 413 in epoch 9, gen_loss = 0.3853293488495016, disc_loss = 0.08318701010548334
Trained batch 414 in epoch 9, gen_loss = 0.3853691449007356, disc_loss = 0.0830847372065287
Trained batch 415 in epoch 9, gen_loss = 0.38531756118083227, disc_loss = 0.08303206519877467
Trained batch 416 in epoch 9, gen_loss = 0.38541428294542024, disc_loss = 0.08288789784191825
Trained batch 417 in epoch 9, gen_loss = 0.38544441477961516, disc_loss = 0.08283461647054724
Trained batch 418 in epoch 9, gen_loss = 0.38541297863519847, disc_loss = 0.08283522121190384
Trained batch 419 in epoch 9, gen_loss = 0.3857636177468868, disc_loss = 0.08290464422842932
Trained batch 420 in epoch 9, gen_loss = 0.3859274448592419, disc_loss = 0.08275042447502638
Trained batch 421 in epoch 9, gen_loss = 0.3859358081391072, disc_loss = 0.08265260733019614
Trained batch 422 in epoch 9, gen_loss = 0.38576628767993154, disc_loss = 0.0826490124661132
Trained batch 423 in epoch 9, gen_loss = 0.3855270735286879, disc_loss = 0.08308678505863151
Trained batch 424 in epoch 9, gen_loss = 0.38565424480858973, disc_loss = 0.08296249853994916
Trained batch 425 in epoch 9, gen_loss = 0.3857503065690748, disc_loss = 0.08288650292282303
Trained batch 426 in epoch 9, gen_loss = 0.3856788670221034, disc_loss = 0.08272075346633967
Trained batch 427 in epoch 9, gen_loss = 0.3856182193435798, disc_loss = 0.08254633120600587
Trained batch 428 in epoch 9, gen_loss = 0.3855439411662953, disc_loss = 0.08237370897718382
Trained batch 429 in epoch 9, gen_loss = 0.3856411108790442, disc_loss = 0.08220567439011363
Trained batch 430 in epoch 9, gen_loss = 0.38579465269074364, disc_loss = 0.08202544281695669
Trained batch 431 in epoch 9, gen_loss = 0.38581529614964016, disc_loss = 0.08184305844123527
Trained batch 432 in epoch 9, gen_loss = 0.3858620947351632, disc_loss = 0.08166170809052317
Trained batch 433 in epoch 9, gen_loss = 0.3857613013293337, disc_loss = 0.08149222013849576
Trained batch 434 in epoch 9, gen_loss = 0.38578475162215614, disc_loss = 0.08131971913443387
Trained batch 435 in epoch 9, gen_loss = 0.3856147945679109, disc_loss = 0.08114425595016689
Trained batch 436 in epoch 9, gen_loss = 0.38552296499229405, disc_loss = 0.08096458557225951
Trained batch 437 in epoch 9, gen_loss = 0.38557154644433766, disc_loss = 0.08079251343252554
Trained batch 438 in epoch 9, gen_loss = 0.3855860332761104, disc_loss = 0.08061757617882519
Trained batch 439 in epoch 9, gen_loss = 0.3856300892139023, disc_loss = 0.08044071951986884
Trained batch 440 in epoch 9, gen_loss = 0.38565039840820425, disc_loss = 0.08026396187841724
Trained batch 441 in epoch 9, gen_loss = 0.3856873461361385, disc_loss = 0.08008777785190799
Trained batch 442 in epoch 9, gen_loss = 0.3856347011187814, disc_loss = 0.0799156325663236
Trained batch 443 in epoch 9, gen_loss = 0.38577959723435007, disc_loss = 0.0797622011762599
Trained batch 444 in epoch 9, gen_loss = 0.3858801418141033, disc_loss = 0.07959397427758641
Trained batch 445 in epoch 9, gen_loss = 0.3859651624287725, disc_loss = 0.0794270134837922
Trained batch 446 in epoch 9, gen_loss = 0.386076998090584, disc_loss = 0.0792530130519963
Trained batch 447 in epoch 9, gen_loss = 0.3861145263737334, disc_loss = 0.07908864723659852
Trained batch 448 in epoch 9, gen_loss = 0.38618089059546157, disc_loss = 0.0789235338863226
Trained batch 449 in epoch 9, gen_loss = 0.38608861767583424, disc_loss = 0.07876008580542274
Trained batch 450 in epoch 9, gen_loss = 0.3860504759719261, disc_loss = 0.07859003387067359
Trained batch 451 in epoch 9, gen_loss = 0.3860252228260568, disc_loss = 0.07842086979282806
Trained batch 452 in epoch 9, gen_loss = 0.3859933967687699, disc_loss = 0.07825768293677182
Trained batch 453 in epoch 9, gen_loss = 0.3860078760246348, disc_loss = 0.07808948053654267
Trained batch 454 in epoch 9, gen_loss = 0.38595360900674547, disc_loss = 0.07792316461288995
Trained batch 455 in epoch 9, gen_loss = 0.38598914336609214, disc_loss = 0.07775697916829877
Trained batch 456 in epoch 9, gen_loss = 0.38597643743849946, disc_loss = 0.07759241034384792
Trained batch 457 in epoch 9, gen_loss = 0.3859912166493949, disc_loss = 0.07743076033286311
Trained batch 458 in epoch 9, gen_loss = 0.38573345402357107, disc_loss = 0.07762275178397322
Testing Epoch 9
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:38:35,277
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:38:35,343
------------------------------------------------------------
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.3612070083618164, disc_loss = 0.020579207688570023
Trained batch 1 in epoch 10, gen_loss = 0.361175000667572, disc_loss = 0.031552014872431755
Trained batch 2 in epoch 10, gen_loss = 0.36874161163965863, disc_loss = 0.022979275323450565
Trained batch 3 in epoch 10, gen_loss = 0.3848765641450882, disc_loss = 0.01975051430054009
Trained batch 4 in epoch 10, gen_loss = 0.38802509307861327, disc_loss = 0.017215227521955968
Trained batch 5 in epoch 10, gen_loss = 0.3922637204329173, disc_loss = 0.015089107910171151
Trained batch 6 in epoch 10, gen_loss = 0.39308386615344454, disc_loss = 0.01334784269732024
Trained batch 7 in epoch 10, gen_loss = 0.39468690007925034, disc_loss = 0.012437543919077143
Trained batch 8 in epoch 10, gen_loss = 0.3994801508055793, disc_loss = 0.011947303467119733
Trained batch 9 in epoch 10, gen_loss = 0.401993590593338, disc_loss = 0.011204352951608598
Trained batch 10 in epoch 10, gen_loss = 0.39919419993053784, disc_loss = 0.010458578334443948
Trained batch 11 in epoch 10, gen_loss = 0.39799873779217404, disc_loss = 0.0101331813299718
Trained batch 12 in epoch 10, gen_loss = 0.39677533278098476, disc_loss = 0.009567947001554646
Trained batch 13 in epoch 10, gen_loss = 0.3974084236792156, disc_loss = 0.009199181155833815
Trained batch 14 in epoch 10, gen_loss = 0.39714633822441103, disc_loss = 0.008908811071887613
Trained batch 15 in epoch 10, gen_loss = 0.39572942070662975, disc_loss = 0.008789284431259148
Trained batch 16 in epoch 10, gen_loss = 0.3934081161723417, disc_loss = 0.008577167344115236
Trained batch 17 in epoch 10, gen_loss = 0.39356493287616306, disc_loss = 0.008402881070247127
Trained batch 18 in epoch 10, gen_loss = 0.39091636162055166, disc_loss = 0.008488106749657737
Trained batch 19 in epoch 10, gen_loss = 0.39207455813884734, disc_loss = 0.008392538886982947
Trained batch 20 in epoch 10, gen_loss = 0.39176881029492333, disc_loss = 0.008326735225550476
Trained batch 21 in epoch 10, gen_loss = 0.39396093921227887, disc_loss = 0.00813795699187639
Trained batch 22 in epoch 10, gen_loss = 0.3942915538082952, disc_loss = 0.007848129314167993
Trained batch 23 in epoch 10, gen_loss = 0.39756499355038005, disc_loss = 0.007678400210958595
Trained batch 24 in epoch 10, gen_loss = 0.3964271342754364, disc_loss = 0.00855601224116981
Trained batch 25 in epoch 10, gen_loss = 0.39621187861149126, disc_loss = 0.008345880268069986
Trained batch 26 in epoch 10, gen_loss = 0.39785218238830566, disc_loss = 0.008574383583402744
Trained batch 27 in epoch 10, gen_loss = 0.39315123004572733, disc_loss = 0.010435174793071513
Trained batch 28 in epoch 10, gen_loss = 0.39422399524984686, disc_loss = 0.010781426536690059
Trained batch 29 in epoch 10, gen_loss = 0.39368639489014945, disc_loss = 0.01391577289905399
Trained batch 30 in epoch 10, gen_loss = 0.39188897609710693, disc_loss = 0.016571318588009285
Trained batch 31 in epoch 10, gen_loss = 0.3913141917437315, disc_loss = 0.017026903202349786
Trained batch 32 in epoch 10, gen_loss = 0.39112752495389996, disc_loss = 0.01771307497454638
Trained batch 33 in epoch 10, gen_loss = 0.3909731191747329, disc_loss = 0.01909800583962351
Trained batch 34 in epoch 10, gen_loss = 0.39336181708744594, disc_loss = 0.019612742834059255
Trained batch 35 in epoch 10, gen_loss = 0.39228203975492054, disc_loss = 0.022220257753765002
Trained batch 36 in epoch 10, gen_loss = 0.3943188069639979, disc_loss = 0.03725165338255465
Trained batch 37 in epoch 10, gen_loss = 0.3942326950399499, disc_loss = 0.03832640271560338
Trained batch 38 in epoch 10, gen_loss = 0.3931980163623125, disc_loss = 0.03829624779068698
Trained batch 39 in epoch 10, gen_loss = 0.39241388961672785, disc_loss = 0.0381102841172833
Trained batch 40 in epoch 10, gen_loss = 0.39282605633503054, disc_loss = 0.03834911870270422
Trained batch 41 in epoch 10, gen_loss = 0.39215642639568876, disc_loss = 0.04077606415930426
Trained batch 42 in epoch 10, gen_loss = 0.39394781270692514, disc_loss = 0.04244398826538304
Trained batch 43 in epoch 10, gen_loss = 0.3926419297402555, disc_loss = 0.04162551344647496
Trained batch 44 in epoch 10, gen_loss = 0.3923341373602549, disc_loss = 0.041247437816734116
Trained batch 45 in epoch 10, gen_loss = 0.3911390110202458, disc_loss = 0.04087505210697165
Trained batch 46 in epoch 10, gen_loss = 0.3898677280608644, disc_loss = 0.04252260380939759
Trained batch 47 in epoch 10, gen_loss = 0.38926210813224316, disc_loss = 0.0434874435547196
Trained batch 48 in epoch 10, gen_loss = 0.3908168156536258, disc_loss = 0.04849200981327009
Trained batch 49 in epoch 10, gen_loss = 0.390786669254303, disc_loss = 0.05019942965824157
Trained batch 50 in epoch 10, gen_loss = 0.3931210718902887, disc_loss = 0.04932550564134384
Trained batch 51 in epoch 10, gen_loss = 0.3943763633187001, disc_loss = 0.04854601817295098
Trained batch 52 in epoch 10, gen_loss = 0.39400012931733763, disc_loss = 0.04772917457575084
Trained batch 53 in epoch 10, gen_loss = 0.3956715138974013, disc_loss = 0.04713716891301037
Trained batch 54 in epoch 10, gen_loss = 0.3957636009563099, disc_loss = 0.046443373798816044
Trained batch 55 in epoch 10, gen_loss = 0.3944610229560307, disc_loss = 0.04583818173185656
Trained batch 56 in epoch 10, gen_loss = 0.3925520443079764, disc_loss = 0.0465543868812618
Trained batch 57 in epoch 10, gen_loss = 0.39318775051626664, disc_loss = 0.05072558157804326
Trained batch 58 in epoch 10, gen_loss = 0.391351249258397, disc_loss = 0.05274800022164265
Trained batch 59 in epoch 10, gen_loss = 0.39280518939097725, disc_loss = 0.05282495369901881
Trained batch 60 in epoch 10, gen_loss = 0.39237993662474585, disc_loss = 0.052253401246624157
Trained batch 61 in epoch 10, gen_loss = 0.3921092099720432, disc_loss = 0.05293518335243026
Trained batch 62 in epoch 10, gen_loss = 0.3913978896443806, disc_loss = 0.05438480094917828
Trained batch 63 in epoch 10, gen_loss = 0.3899138355627656, disc_loss = 0.06117911619730876
Trained batch 64 in epoch 10, gen_loss = 0.3902132254380446, disc_loss = 0.0614758858922869
Trained batch 65 in epoch 10, gen_loss = 0.3910622497399648, disc_loss = 0.061216038852845406
Trained batch 66 in epoch 10, gen_loss = 0.3916271039799078, disc_loss = 0.06086914903317481
Trained batch 67 in epoch 10, gen_loss = 0.3917498080169453, disc_loss = 0.060612000090152246
Trained batch 68 in epoch 10, gen_loss = 0.39078909892966784, disc_loss = 0.06016483258091561
Trained batch 69 in epoch 10, gen_loss = 0.3903541484049388, disc_loss = 0.05952659563627094
Trained batch 70 in epoch 10, gen_loss = 0.3910623772043577, disc_loss = 0.05884241963684244
Trained batch 71 in epoch 10, gen_loss = 0.39027128534184563, disc_loss = 0.058284376570049465
Trained batch 72 in epoch 10, gen_loss = 0.3901624867360886, disc_loss = 0.05773362489608563
Trained batch 73 in epoch 10, gen_loss = 0.3890516641172203, disc_loss = 0.05980719840216979
Trained batch 74 in epoch 10, gen_loss = 0.3886987996101379, disc_loss = 0.06381832771313688
Trained batch 75 in epoch 10, gen_loss = 0.38842519019779403, disc_loss = 0.0634398342532988
Trained batch 76 in epoch 10, gen_loss = 0.38877056829341045, disc_loss = 0.06346120518728994
Trained batch 77 in epoch 10, gen_loss = 0.39010792894241136, disc_loss = 0.06306209780860883
Trained batch 78 in epoch 10, gen_loss = 0.39047490720507466, disc_loss = 0.06267011036235792
Trained batch 79 in epoch 10, gen_loss = 0.3894762974232435, disc_loss = 0.06327120440837461
Trained batch 80 in epoch 10, gen_loss = 0.38954902799041186, disc_loss = 0.06316279525937582
Trained batch 81 in epoch 10, gen_loss = 0.3907867241196516, disc_loss = 0.06270842679219729
Trained batch 82 in epoch 10, gen_loss = 0.38981942778610323, disc_loss = 0.06290559540502727
Trained batch 83 in epoch 10, gen_loss = 0.3913044471825872, disc_loss = 0.06821100216724776
Trained batch 84 in epoch 10, gen_loss = 0.3906400887405171, disc_loss = 0.07028149925446248
Trained batch 85 in epoch 10, gen_loss = 0.3909206428500109, disc_loss = 0.07317579137215521
Trained batch 86 in epoch 10, gen_loss = 0.3891644995102937, disc_loss = 0.07466305619180631
Trained batch 87 in epoch 10, gen_loss = 0.389429877766154, disc_loss = 0.07767411810610528
Trained batch 88 in epoch 10, gen_loss = 0.3900142814336198, disc_loss = 0.07850949213254067
Trained batch 89 in epoch 10, gen_loss = 0.39045725994639924, disc_loss = 0.07798074511035034
Trained batch 90 in epoch 10, gen_loss = 0.39022678202325173, disc_loss = 0.0779552582758837
Trained batch 91 in epoch 10, gen_loss = 0.38986587686383206, disc_loss = 0.07797103750003177
Trained batch 92 in epoch 10, gen_loss = 0.3898099664077964, disc_loss = 0.07727333849486244
Trained batch 93 in epoch 10, gen_loss = 0.39007244433494326, disc_loss = 0.07687679890473868
Trained batch 94 in epoch 10, gen_loss = 0.39015114464257894, disc_loss = 0.07684040852136126
Trained batch 95 in epoch 10, gen_loss = 0.390381021425128, disc_loss = 0.077807076103151
Trained batch 96 in epoch 10, gen_loss = 0.39009983699346323, disc_loss = 0.07924321507218957
Trained batch 97 in epoch 10, gen_loss = 0.39031246912722684, disc_loss = 0.07908343765361957
Trained batch 98 in epoch 10, gen_loss = 0.3908941378497114, disc_loss = 0.07852962950122251
Trained batch 99 in epoch 10, gen_loss = 0.3905939853191376, disc_loss = 0.07829554563621059
Trained batch 100 in epoch 10, gen_loss = 0.3902581838688048, disc_loss = 0.07887885968735682
Trained batch 101 in epoch 10, gen_loss = 0.3913523136985068, disc_loss = 0.08084310173267024
Trained batch 102 in epoch 10, gen_loss = 0.391662944867773, disc_loss = 0.08049728853618997
Trained batch 103 in epoch 10, gen_loss = 0.39097358687565875, disc_loss = 0.08069482920557046
Trained batch 104 in epoch 10, gen_loss = 0.3908330304282052, disc_loss = 0.08055560122510153
Trained batch 105 in epoch 10, gen_loss = 0.39127953322428577, disc_loss = 0.07985468853027823
Trained batch 106 in epoch 10, gen_loss = 0.3912455765443428, disc_loss = 0.08049455867584134
Trained batch 107 in epoch 10, gen_loss = 0.39098622291176405, disc_loss = 0.08299956164814325
Trained batch 108 in epoch 10, gen_loss = 0.3905036268977944, disc_loss = 0.08336875783578587
Trained batch 109 in epoch 10, gen_loss = 0.3899361079389399, disc_loss = 0.08309221177319573
Trained batch 110 in epoch 10, gen_loss = 0.38963863226744505, disc_loss = 0.08271865913568921
Trained batch 111 in epoch 10, gen_loss = 0.3897547213626759, disc_loss = 0.0821929420781089
Trained batch 112 in epoch 10, gen_loss = 0.3891244855074756, disc_loss = 0.08163184764284014
Trained batch 113 in epoch 10, gen_loss = 0.38904950127267, disc_loss = 0.08145167651839488
Trained batch 114 in epoch 10, gen_loss = 0.3885105358517688, disc_loss = 0.08207634738646448
Trained batch 115 in epoch 10, gen_loss = 0.38910283122597067, disc_loss = 0.08435159407210825
Trained batch 116 in epoch 10, gen_loss = 0.3889521604929215, disc_loss = 0.08422261303983247
Trained batch 117 in epoch 10, gen_loss = 0.388694512389474, disc_loss = 0.0837593738056751
Trained batch 118 in epoch 10, gen_loss = 0.38865663399215505, disc_loss = 0.08349496977082885
Trained batch 119 in epoch 10, gen_loss = 0.3884012428422769, disc_loss = 0.08300098616358204
Trained batch 120 in epoch 10, gen_loss = 0.38860862067908297, disc_loss = 0.08235798035517397
Trained batch 121 in epoch 10, gen_loss = 0.38867025736902583, disc_loss = 0.08175321810184139
Trained batch 122 in epoch 10, gen_loss = 0.38940807110894987, disc_loss = 0.08167588996806947
Trained batch 123 in epoch 10, gen_loss = 0.3886875310732472, disc_loss = 0.08235108078600117
Trained batch 124 in epoch 10, gen_loss = 0.3892477114200592, disc_loss = 0.08204161767475307
Trained batch 125 in epoch 10, gen_loss = 0.38884381855291034, disc_loss = 0.08244522570610224
Trained batch 126 in epoch 10, gen_loss = 0.3886278679990393, disc_loss = 0.08304455927499813
Trained batch 127 in epoch 10, gen_loss = 0.38864260422997177, disc_loss = 0.08266469345653604
Trained batch 128 in epoch 10, gen_loss = 0.38860119451848113, disc_loss = 0.08209280057290438
Trained batch 129 in epoch 10, gen_loss = 0.38807681569686303, disc_loss = 0.08205842129133928
Trained batch 130 in epoch 10, gen_loss = 0.388077306838436, disc_loss = 0.0818347733535356
Trained batch 131 in epoch 10, gen_loss = 0.3878910661195264, disc_loss = 0.08135552448749711
Trained batch 132 in epoch 10, gen_loss = 0.38801938384995427, disc_loss = 0.08134065516454105
Trained batch 133 in epoch 10, gen_loss = 0.3881033018453797, disc_loss = 0.08135788825013911
Trained batch 134 in epoch 10, gen_loss = 0.3876424436216001, disc_loss = 0.08098372277389798
Trained batch 135 in epoch 10, gen_loss = 0.3879256263813552, disc_loss = 0.08050770897192278
Trained batch 136 in epoch 10, gen_loss = 0.3878176105718543, disc_loss = 0.079971385254681
Trained batch 137 in epoch 10, gen_loss = 0.3883645843336548, disc_loss = 0.07950182507941635
Trained batch 138 in epoch 10, gen_loss = 0.3885576962995872, disc_loss = 0.07917806616542097
Trained batch 139 in epoch 10, gen_loss = 0.3889674872159958, disc_loss = 0.0787839153033149
Trained batch 140 in epoch 10, gen_loss = 0.3890114037703115, disc_loss = 0.07851203317516187
Trained batch 141 in epoch 10, gen_loss = 0.389184403167644, disc_loss = 0.07871995680526056
Trained batch 142 in epoch 10, gen_loss = 0.3884579218350924, disc_loss = 0.08065292513212906
Trained batch 143 in epoch 10, gen_loss = 0.3882688532272975, disc_loss = 0.08063561974267941
Trained batch 144 in epoch 10, gen_loss = 0.3885367196181725, disc_loss = 0.08065752313022727
Trained batch 145 in epoch 10, gen_loss = 0.3886345290157893, disc_loss = 0.08028047335850814
Trained batch 146 in epoch 10, gen_loss = 0.38805365744902165, disc_loss = 0.08001432616460029
Trained batch 147 in epoch 10, gen_loss = 0.38802202670155345, disc_loss = 0.07964972608464745
Trained batch 148 in epoch 10, gen_loss = 0.388272282461192, disc_loss = 0.07916455642607738
Trained batch 149 in epoch 10, gen_loss = 0.3881366602579753, disc_loss = 0.07870181690125416
Trained batch 150 in epoch 10, gen_loss = 0.3885125184295983, disc_loss = 0.07848898637638926
Trained batch 151 in epoch 10, gen_loss = 0.3884766735136509, disc_loss = 0.07810749186319299
Trained batch 152 in epoch 10, gen_loss = 0.38840772552427905, disc_loss = 0.07782922457946233
Trained batch 153 in epoch 10, gen_loss = 0.3887604426640969, disc_loss = 0.077572083818823
Trained batch 154 in epoch 10, gen_loss = 0.3892200560339035, disc_loss = 0.07723833119887258
Trained batch 155 in epoch 10, gen_loss = 0.38862315145058507, disc_loss = 0.07805655255931644
Trained batch 156 in epoch 10, gen_loss = 0.38899200414396395, disc_loss = 0.08048342850955001
Trained batch 157 in epoch 10, gen_loss = 0.38955672104147415, disc_loss = 0.08075555766891405
Trained batch 158 in epoch 10, gen_loss = 0.3892305034136622, disc_loss = 0.08154865943990741
Trained batch 159 in epoch 10, gen_loss = 0.3891930963844061, disc_loss = 0.08115138324646978
Trained batch 160 in epoch 10, gen_loss = 0.3887364923583795, disc_loss = 0.08077779645244851
Trained batch 161 in epoch 10, gen_loss = 0.3884199024350555, disc_loss = 0.08035138427469603
Trained batch 162 in epoch 10, gen_loss = 0.3882700709477524, disc_loss = 0.08002465955221717
Trained batch 163 in epoch 10, gen_loss = 0.3881372638591906, disc_loss = 0.07974756666794192
Trained batch 164 in epoch 10, gen_loss = 0.3883586995529406, disc_loss = 0.07962481802696306
Trained batch 165 in epoch 10, gen_loss = 0.3880235287080328, disc_loss = 0.08012858624373709
Trained batch 166 in epoch 10, gen_loss = 0.3885573869693779, disc_loss = 0.08311223679132938
Trained batch 167 in epoch 10, gen_loss = 0.3884201468456359, disc_loss = 0.08394340779271997
Trained batch 168 in epoch 10, gen_loss = 0.38769647796478496, disc_loss = 0.08594680536598981
Trained batch 169 in epoch 10, gen_loss = 0.38762819907244517, disc_loss = 0.08674901249298059
Trained batch 170 in epoch 10, gen_loss = 0.3871949627036937, disc_loss = 0.08737536888890927
Trained batch 171 in epoch 10, gen_loss = 0.38690960130026175, disc_loss = 0.0873540188822094
Trained batch 172 in epoch 10, gen_loss = 0.38659085393641035, disc_loss = 0.08736971919586332
Trained batch 173 in epoch 10, gen_loss = 0.38640571668230256, disc_loss = 0.08717639766628159
Trained batch 174 in epoch 10, gen_loss = 0.3865976980754307, disc_loss = 0.086895810140829
Trained batch 175 in epoch 10, gen_loss = 0.3866818586195057, disc_loss = 0.08656883774065963
Trained batch 176 in epoch 10, gen_loss = 0.38639894750832166, disc_loss = 0.08636501785972824
Trained batch 177 in epoch 10, gen_loss = 0.3862290926528781, disc_loss = 0.0863168903958743
Trained batch 178 in epoch 10, gen_loss = 0.38579307704664473, disc_loss = 0.08657550633697661
Trained batch 179 in epoch 10, gen_loss = 0.385875372423066, disc_loss = 0.08658543159641946
Trained batch 180 in epoch 10, gen_loss = 0.3858991265296936, disc_loss = 0.08712516738312803
Trained batch 181 in epoch 10, gen_loss = 0.385496470954392, disc_loss = 0.08942688302428635
Trained batch 182 in epoch 10, gen_loss = 0.38571444316639925, disc_loss = 0.08982163412074044
Trained batch 183 in epoch 10, gen_loss = 0.38611468024875806, disc_loss = 0.09138824002002366
Trained batch 184 in epoch 10, gen_loss = 0.3857844605639174, disc_loss = 0.09129623529954335
Trained batch 185 in epoch 10, gen_loss = 0.38538911409916415, disc_loss = 0.0912076538936886
Trained batch 186 in epoch 10, gen_loss = 0.38548534742013657, disc_loss = 0.09129448578553523
Trained batch 187 in epoch 10, gen_loss = 0.38586428079833374, disc_loss = 0.09202433933201741
Trained batch 188 in epoch 10, gen_loss = 0.3855508094426816, disc_loss = 0.09176942458617743
Trained batch 189 in epoch 10, gen_loss = 0.38533560978738884, disc_loss = 0.09167746298480779
Trained batch 190 in epoch 10, gen_loss = 0.38510338252127485, disc_loss = 0.09151174286892394
Trained batch 191 in epoch 10, gen_loss = 0.38481819986676175, disc_loss = 0.09137408379926153
Trained batch 192 in epoch 10, gen_loss = 0.38433101186480545, disc_loss = 0.09202357461565015
Trained batch 193 in epoch 10, gen_loss = 0.3845046889228919, disc_loss = 0.09263915290993628
Trained batch 194 in epoch 10, gen_loss = 0.3846460836055951, disc_loss = 0.0922854291024403
Trained batch 195 in epoch 10, gen_loss = 0.38435737667035086, disc_loss = 0.0918844764736215
Trained batch 196 in epoch 10, gen_loss = 0.38399676547437755, disc_loss = 0.09163195305021697
Trained batch 197 in epoch 10, gen_loss = 0.38423411186897394, disc_loss = 0.09132289187394722
Trained batch 198 in epoch 10, gen_loss = 0.38430220862129827, disc_loss = 0.09091735164981204
Trained batch 199 in epoch 10, gen_loss = 0.3842089174687862, disc_loss = 0.09064068682375365
Trained batch 200 in epoch 10, gen_loss = 0.3842150090049155, disc_loss = 0.09080176021954721
Trained batch 201 in epoch 10, gen_loss = 0.3842488233700837, disc_loss = 0.09185309593662583
Trained batch 202 in epoch 10, gen_loss = 0.38393537032193154, disc_loss = 0.0915677654063742
Trained batch 203 in epoch 10, gen_loss = 0.38381486181534974, disc_loss = 0.09151225049372799
Trained batch 204 in epoch 10, gen_loss = 0.3839783768828322, disc_loss = 0.09115388461434078
Trained batch 205 in epoch 10, gen_loss = 0.3838266445305741, disc_loss = 0.09128536980992491
Trained batch 206 in epoch 10, gen_loss = 0.38354318686153577, disc_loss = 0.09279111188674427
Trained batch 207 in epoch 10, gen_loss = 0.3837893166794227, disc_loss = 0.09253647736197589
Trained batch 208 in epoch 10, gen_loss = 0.38405740474970146, disc_loss = 0.09247051509939419
Trained batch 209 in epoch 10, gen_loss = 0.3839889774719874, disc_loss = 0.09225139875918449
Trained batch 210 in epoch 10, gen_loss = 0.3836427904418295, disc_loss = 0.09278876764227535
Trained batch 211 in epoch 10, gen_loss = 0.38347099243469956, disc_loss = 0.09313684697416699
Trained batch 212 in epoch 10, gen_loss = 0.3835309587174178, disc_loss = 0.09284267340078425
Trained batch 213 in epoch 10, gen_loss = 0.3835541062822966, disc_loss = 0.09272447694854584
Trained batch 214 in epoch 10, gen_loss = 0.3836860357328903, disc_loss = 0.09241862354128687
Trained batch 215 in epoch 10, gen_loss = 0.3841376775116832, disc_loss = 0.09220065152233776
Trained batch 216 in epoch 10, gen_loss = 0.38430895728449666, disc_loss = 0.0918075727880396
Trained batch 217 in epoch 10, gen_loss = 0.38457374110681203, disc_loss = 0.0914072935659558
Trained batch 218 in epoch 10, gen_loss = 0.3846287589911456, disc_loss = 0.09107281628371
Trained batch 219 in epoch 10, gen_loss = 0.3845203021710569, disc_loss = 0.09068725968351249
Trained batch 220 in epoch 10, gen_loss = 0.38442052084935735, disc_loss = 0.09031298022392749
Trained batch 221 in epoch 10, gen_loss = 0.3842871971764006, disc_loss = 0.09021292234926175
Trained batch 222 in epoch 10, gen_loss = 0.3847065510503914, disc_loss = 0.08995356605254581
Trained batch 223 in epoch 10, gen_loss = 0.3851753425385271, disc_loss = 0.08963737195985491
Trained batch 224 in epoch 10, gen_loss = 0.3848732758892907, disc_loss = 0.08933197658819457
Trained batch 225 in epoch 10, gen_loss = 0.3854467806826651, disc_loss = 0.08925069893186961
Trained batch 226 in epoch 10, gen_loss = 0.38566920358178897, disc_loss = 0.08893165101362843
Trained batch 227 in epoch 10, gen_loss = 0.38557774952629154, disc_loss = 0.08882777867409841
Trained batch 228 in epoch 10, gen_loss = 0.38549648778407336, disc_loss = 0.08931511104428189
Trained batch 229 in epoch 10, gen_loss = 0.38583889137143673, disc_loss = 0.08899206910586066
Trained batch 230 in epoch 10, gen_loss = 0.3857473008560412, disc_loss = 0.08901297384409387
Trained batch 231 in epoch 10, gen_loss = 0.3852138776203682, disc_loss = 0.0902826673911226
Trained batch 232 in epoch 10, gen_loss = 0.38510988173055033, disc_loss = 0.09006273403839715
Trained batch 233 in epoch 10, gen_loss = 0.3853215891071874, disc_loss = 0.0900165769420803
Trained batch 234 in epoch 10, gen_loss = 0.3851710686024199, disc_loss = 0.09019184051814708
Trained batch 235 in epoch 10, gen_loss = 0.38553879788871537, disc_loss = 0.09116142662538027
Trained batch 236 in epoch 10, gen_loss = 0.3851384164663307, disc_loss = 0.0924718715987298
Trained batch 237 in epoch 10, gen_loss = 0.38501659386298237, disc_loss = 0.09253570775035769
Trained batch 238 in epoch 10, gen_loss = 0.3851074790854833, disc_loss = 0.09256040407286248
Trained batch 239 in epoch 10, gen_loss = 0.38521615068117776, disc_loss = 0.09229838071526804
Trained batch 240 in epoch 10, gen_loss = 0.3852290595220827, disc_loss = 0.09206581572785634
Trained batch 241 in epoch 10, gen_loss = 0.3849453056646773, disc_loss = 0.09180376776744234
Trained batch 242 in epoch 10, gen_loss = 0.3848189786383154, disc_loss = 0.09182265559843752
Trained batch 243 in epoch 10, gen_loss = 0.38498404756432675, disc_loss = 0.09190631776448858
Trained batch 244 in epoch 10, gen_loss = 0.38524569625757177, disc_loss = 0.09159202371457857
Trained batch 245 in epoch 10, gen_loss = 0.38505521780107077, disc_loss = 0.0914903932423293
Trained batch 246 in epoch 10, gen_loss = 0.3850456073216581, disc_loss = 0.09136048895457707
Trained batch 247 in epoch 10, gen_loss = 0.3848569143202997, disc_loss = 0.09153947896125066
Trained batch 248 in epoch 10, gen_loss = 0.38500839388035385, disc_loss = 0.09138207476731973
Trained batch 249 in epoch 10, gen_loss = 0.3849605211019516, disc_loss = 0.09135076267551631
Trained batch 250 in epoch 10, gen_loss = 0.3848203297155312, disc_loss = 0.09190179414553679
Trained batch 251 in epoch 10, gen_loss = 0.3847908141121032, disc_loss = 0.09181759285736858
Trained batch 252 in epoch 10, gen_loss = 0.3847887082533403, disc_loss = 0.09280950777332037
Trained batch 253 in epoch 10, gen_loss = 0.384272612220659, disc_loss = 0.09420677366406166
Trained batch 254 in epoch 10, gen_loss = 0.3842974233861063, disc_loss = 0.0941826657145558
Trained batch 255 in epoch 10, gen_loss = 0.3843324282206595, disc_loss = 0.0944445401937628
Trained batch 256 in epoch 10, gen_loss = 0.3842094102258348, disc_loss = 0.09490902992490867
Trained batch 257 in epoch 10, gen_loss = 0.38421248904494354, disc_loss = 0.0950356585383343
Trained batch 258 in epoch 10, gen_loss = 0.3843964403890735, disc_loss = 0.0950966125100664
Trained batch 259 in epoch 10, gen_loss = 0.3844453706191136, disc_loss = 0.09520564037285602
Trained batch 260 in epoch 10, gen_loss = 0.38466388489551473, disc_loss = 0.09519221537596621
Trained batch 261 in epoch 10, gen_loss = 0.38488287234124335, disc_loss = 0.09503746396268341
Trained batch 262 in epoch 10, gen_loss = 0.3849737759778708, disc_loss = 0.09490159027430693
Trained batch 263 in epoch 10, gen_loss = 0.3847883070508639, disc_loss = 0.09513766960166818
Trained batch 264 in epoch 10, gen_loss = 0.3847649054707221, disc_loss = 0.09603327949496232
Trained batch 265 in epoch 10, gen_loss = 0.3848160278976412, disc_loss = 0.09574941959130556
Trained batch 266 in epoch 10, gen_loss = 0.3847359248091666, disc_loss = 0.09561594647062377
Trained batch 267 in epoch 10, gen_loss = 0.38448553020829584, disc_loss = 0.0955326520349594
Trained batch 268 in epoch 10, gen_loss = 0.38456021144044444, disc_loss = 0.09606803592457176
Trained batch 269 in epoch 10, gen_loss = 0.3842625202956023, disc_loss = 0.09656097827117062
Trained batch 270 in epoch 10, gen_loss = 0.3842819053748437, disc_loss = 0.09675342481277498
Trained batch 271 in epoch 10, gen_loss = 0.3841060882105547, disc_loss = 0.09687090822861887
Trained batch 272 in epoch 10, gen_loss = 0.3837764214028369, disc_loss = 0.0969479445243534
Trained batch 273 in epoch 10, gen_loss = 0.3836337085405405, disc_loss = 0.09758189602255359
Trained batch 274 in epoch 10, gen_loss = 0.3839256307211789, disc_loss = 0.09829630731435662
Trained batch 275 in epoch 10, gen_loss = 0.3839179462064867, disc_loss = 0.09819264001587567
Trained batch 276 in epoch 10, gen_loss = 0.3835957291324216, disc_loss = 0.09837032390829001
Trained batch 277 in epoch 10, gen_loss = 0.3834671698671451, disc_loss = 0.0982884152167604
Trained batch 278 in epoch 10, gen_loss = 0.38344807169770684, disc_loss = 0.09805473214178931
Trained batch 279 in epoch 10, gen_loss = 0.38371569737792016, disc_loss = 0.09781603822734074
Trained batch 280 in epoch 10, gen_loss = 0.3838142048421704, disc_loss = 0.09764188491189156
Trained batch 281 in epoch 10, gen_loss = 0.38373581885446045, disc_loss = 0.09751273940254584
Trained batch 282 in epoch 10, gen_loss = 0.383893210138112, disc_loss = 0.09840026376982855
Trained batch 283 in epoch 10, gen_loss = 0.3837635255825352, disc_loss = 0.09967400611322505
Trained batch 284 in epoch 10, gen_loss = 0.3841262027882693, disc_loss = 0.09953488354865266
Trained batch 285 in epoch 10, gen_loss = 0.38399698392494575, disc_loss = 0.09947902889241679
Trained batch 286 in epoch 10, gen_loss = 0.38406341021899976, disc_loss = 0.09939258748370154
Trained batch 287 in epoch 10, gen_loss = 0.38382178731262684, disc_loss = 0.09936668977590873
Trained batch 288 in epoch 10, gen_loss = 0.38372810035428373, disc_loss = 0.09943406972437968
Trained batch 289 in epoch 10, gen_loss = 0.3832688140458074, disc_loss = 0.09944695768926036
Trained batch 290 in epoch 10, gen_loss = 0.3834047426063171, disc_loss = 0.0994683846445671
Trained batch 291 in epoch 10, gen_loss = 0.38305781067234196, disc_loss = 0.099557071492835
Trained batch 292 in epoch 10, gen_loss = 0.38329046506930536, disc_loss = 0.09932296340029573
Trained batch 293 in epoch 10, gen_loss = 0.3831317709619496, disc_loss = 0.09922570981905751
Trained batch 294 in epoch 10, gen_loss = 0.38325769244614294, disc_loss = 0.09905883632837084
Trained batch 295 in epoch 10, gen_loss = 0.3832044276232655, disc_loss = 0.09895531370892895
Trained batch 296 in epoch 10, gen_loss = 0.38293649602417995, disc_loss = 0.09894560270798503
Trained batch 297 in epoch 10, gen_loss = 0.38286102598145505, disc_loss = 0.09884222440230941
Trained batch 298 in epoch 10, gen_loss = 0.3824282353338988, disc_loss = 0.09900368927872076
Trained batch 299 in epoch 10, gen_loss = 0.38281659126281736, disc_loss = 0.10018577926714595
Trained batch 300 in epoch 10, gen_loss = 0.3828035412832748, disc_loss = 0.10015423079423508
Trained batch 301 in epoch 10, gen_loss = 0.38268672541672033, disc_loss = 0.10009849193237648
Trained batch 302 in epoch 10, gen_loss = 0.38262778028796607, disc_loss = 0.10001225856427878
Trained batch 303 in epoch 10, gen_loss = 0.3824845933796544, disc_loss = 0.10004527394669008
Trained batch 304 in epoch 10, gen_loss = 0.38258136549934013, disc_loss = 0.09999293101966747
Trained batch 305 in epoch 10, gen_loss = 0.38263718744898156, disc_loss = 0.09982959135645526
Trained batch 306 in epoch 10, gen_loss = 0.3824973677190973, disc_loss = 0.09985664560526294
Trained batch 307 in epoch 10, gen_loss = 0.38284418412617277, disc_loss = 0.10073929643727138
Trained batch 308 in epoch 10, gen_loss = 0.38271540933828135, disc_loss = 0.1004476037959969
Trained batch 309 in epoch 10, gen_loss = 0.3826324979143758, disc_loss = 0.10029757900929619
Trained batch 310 in epoch 10, gen_loss = 0.3823916501937572, disc_loss = 0.10016960777279432
Trained batch 311 in epoch 10, gen_loss = 0.3823593953290047, disc_loss = 0.0998733907166379
Trained batch 312 in epoch 10, gen_loss = 0.382227162107492, disc_loss = 0.09964824197650217
Trained batch 313 in epoch 10, gen_loss = 0.3822260444900792, disc_loss = 0.09998867237142578
Trained batch 314 in epoch 10, gen_loss = 0.3823695891433292, disc_loss = 0.10047294817909244
Trained batch 315 in epoch 10, gen_loss = 0.3823505146782609, disc_loss = 0.10040995868768755
Trained batch 316 in epoch 10, gen_loss = 0.3823290419315314, disc_loss = 0.10022839500674573
Trained batch 317 in epoch 10, gen_loss = 0.3822903945198599, disc_loss = 0.10026485659108854
Trained batch 318 in epoch 10, gen_loss = 0.3821631630760002, disc_loss = 0.10076214736225346
Trained batch 319 in epoch 10, gen_loss = 0.3823718836531043, disc_loss = 0.10150211978398146
Trained batch 320 in epoch 10, gen_loss = 0.3826074931666116, disc_loss = 0.10146298181668875
Trained batch 321 in epoch 10, gen_loss = 0.38262701302951907, disc_loss = 0.10118602632085058
Trained batch 322 in epoch 10, gen_loss = 0.38271212863848303, disc_loss = 0.1012035765311747
Trained batch 323 in epoch 10, gen_loss = 0.3825631500394256, disc_loss = 0.10093440894356549
Trained batch 324 in epoch 10, gen_loss = 0.3825909733772278, disc_loss = 0.1007115682035398
Trained batch 325 in epoch 10, gen_loss = 0.3824104641112813, disc_loss = 0.10042814009014425
Trained batch 326 in epoch 10, gen_loss = 0.3826238850205681, disc_loss = 0.10023394469898023
Trained batch 327 in epoch 10, gen_loss = 0.3824932731506301, disc_loss = 0.10018950538559272
Trained batch 328 in epoch 10, gen_loss = 0.3827330297974468, disc_loss = 0.10039007325379297
Trained batch 329 in epoch 10, gen_loss = 0.38269131617112595, disc_loss = 0.10023870124044179
Trained batch 330 in epoch 10, gen_loss = 0.38284643494110454, disc_loss = 0.10002451150514906
Trained batch 331 in epoch 10, gen_loss = 0.38285113350454586, disc_loss = 0.09987559972025162
Trained batch 332 in epoch 10, gen_loss = 0.38274888170732035, disc_loss = 0.09985728366314447
Trained batch 333 in epoch 10, gen_loss = 0.3830564164829825, disc_loss = 0.1004894987594972
Trained batch 334 in epoch 10, gen_loss = 0.382900675286108, disc_loss = 0.10048673292135459
Trained batch 335 in epoch 10, gen_loss = 0.3827182220383769, disc_loss = 0.10053722062799525
Trained batch 336 in epoch 10, gen_loss = 0.38255877691135914, disc_loss = 0.10041568254933136
Trained batch 337 in epoch 10, gen_loss = 0.3825902156752242, disc_loss = 0.10016644759497677
Trained batch 338 in epoch 10, gen_loss = 0.3826628582315811, disc_loss = 0.10015652205858237
Trained batch 339 in epoch 10, gen_loss = 0.38250257828656364, disc_loss = 0.1000164245330619
Trained batch 340 in epoch 10, gen_loss = 0.38258249922232196, disc_loss = 0.09987036587979066
Trained batch 341 in epoch 10, gen_loss = 0.3826629790472008, disc_loss = 0.0996563281742747
Trained batch 342 in epoch 10, gen_loss = 0.38276864905399066, disc_loss = 0.0995295734461071
Trained batch 343 in epoch 10, gen_loss = 0.3830337584191977, disc_loss = 0.09928133241158131
Trained batch 344 in epoch 10, gen_loss = 0.3830632188181946, disc_loss = 0.0992866480473321
Trained batch 345 in epoch 10, gen_loss = 0.3830468068060847, disc_loss = 0.09962684275633575
Trained batch 346 in epoch 10, gen_loss = 0.38342637210139624, disc_loss = 0.09989297220292863
Trained batch 347 in epoch 10, gen_loss = 0.38351246277833806, disc_loss = 0.09971170550166768
Trained batch 348 in epoch 10, gen_loss = 0.38369886564320344, disc_loss = 0.09946764038974436
Trained batch 349 in epoch 10, gen_loss = 0.38356022494179864, disc_loss = 0.09920324778117771
Trained batch 350 in epoch 10, gen_loss = 0.38353413275504045, disc_loss = 0.09894901826550542
Trained batch 351 in epoch 10, gen_loss = 0.3834460443732413, disc_loss = 0.09870692172063916
Trained batch 352 in epoch 10, gen_loss = 0.383483539981815, disc_loss = 0.09843525670207615
Trained batch 353 in epoch 10, gen_loss = 0.3833727659815449, disc_loss = 0.0981662518438215
Trained batch 354 in epoch 10, gen_loss = 0.38352750590149787, disc_loss = 0.0978996783147343
Trained batch 355 in epoch 10, gen_loss = 0.38352367641885626, disc_loss = 0.09764402028463592
Trained batch 356 in epoch 10, gen_loss = 0.38347059079245027, disc_loss = 0.09737983103437188
Trained batch 357 in epoch 10, gen_loss = 0.3834761327871397, disc_loss = 0.09712109034920018
Trained batch 358 in epoch 10, gen_loss = 0.3834088711187368, disc_loss = 0.09686679559666404
Trained batch 359 in epoch 10, gen_loss = 0.3833652589884069, disc_loss = 0.09663089539972133
Trained batch 360 in epoch 10, gen_loss = 0.3832099333694437, disc_loss = 0.09641042789586218
Trained batch 361 in epoch 10, gen_loss = 0.3833041421616275, disc_loss = 0.09626018877838383
Trained batch 362 in epoch 10, gen_loss = 0.38323607581049285, disc_loss = 0.09633043597544705
Trained batch 363 in epoch 10, gen_loss = 0.38335153042942616, disc_loss = 0.0967283742636657
Trained batch 364 in epoch 10, gen_loss = 0.38344332110391904, disc_loss = 0.09665764544018837
Trained batch 365 in epoch 10, gen_loss = 0.3834949972851029, disc_loss = 0.09663533727076068
Trained batch 366 in epoch 10, gen_loss = 0.383703798461675, disc_loss = 0.09641480045228161
Trained batch 367 in epoch 10, gen_loss = 0.3837230319724135, disc_loss = 0.09618889884681582
Trained batch 368 in epoch 10, gen_loss = 0.3836930856956699, disc_loss = 0.09598906457406496
Trained batch 369 in epoch 10, gen_loss = 0.3835615313536412, disc_loss = 0.09586928810081068
Trained batch 370 in epoch 10, gen_loss = 0.38368389026495325, disc_loss = 0.09667642973928217
Trained batch 371 in epoch 10, gen_loss = 0.3834685708085696, disc_loss = 0.09664568882898718
Trained batch 372 in epoch 10, gen_loss = 0.38351302635893425, disc_loss = 0.09650790886191936
Trained batch 373 in epoch 10, gen_loss = 0.3835365887791078, disc_loss = 0.0963544397357164
Trained batch 374 in epoch 10, gen_loss = 0.38349522852897644, disc_loss = 0.09612813594006002
Trained batch 375 in epoch 10, gen_loss = 0.3835638553855267, disc_loss = 0.09592196404837329
Trained batch 376 in epoch 10, gen_loss = 0.3836698853052579, disc_loss = 0.09570909755005544
Trained batch 377 in epoch 10, gen_loss = 0.3837304790183981, disc_loss = 0.09548225145720478
Trained batch 378 in epoch 10, gen_loss = 0.3837501505748578, disc_loss = 0.09525677876112035
Trained batch 379 in epoch 10, gen_loss = 0.38373540718304483, disc_loss = 0.09512858666099706
Trained batch 380 in epoch 10, gen_loss = 0.3839271422915571, disc_loss = 0.09501865276213725
Trained batch 381 in epoch 10, gen_loss = 0.38385147636473493, disc_loss = 0.09554804281114615
Trained batch 382 in epoch 10, gen_loss = 0.3840694259414474, disc_loss = 0.0958296124058637
Trained batch 383 in epoch 10, gen_loss = 0.38428673644860584, disc_loss = 0.09573574275721815
Trained batch 384 in epoch 10, gen_loss = 0.38433158289302477, disc_loss = 0.0955055240777551
Trained batch 385 in epoch 10, gen_loss = 0.38427550326357235, disc_loss = 0.09529903863008989
Trained batch 386 in epoch 10, gen_loss = 0.3844747092834739, disc_loss = 0.09510953634801665
Trained batch 387 in epoch 10, gen_loss = 0.3844626788626012, disc_loss = 0.0948932794367981
Trained batch 388 in epoch 10, gen_loss = 0.3845516369704416, disc_loss = 0.09466158291911539
Trained batch 389 in epoch 10, gen_loss = 0.384570474196703, disc_loss = 0.09443055600680124
Trained batch 390 in epoch 10, gen_loss = 0.3846169403751793, disc_loss = 0.09419855384377625
Trained batch 391 in epoch 10, gen_loss = 0.3847152975444891, disc_loss = 0.09396592628006462
Trained batch 392 in epoch 10, gen_loss = 0.3846141733892698, disc_loss = 0.09373115703378243
Trained batch 393 in epoch 10, gen_loss = 0.384698591861628, disc_loss = 0.09350272045567688
Trained batch 394 in epoch 10, gen_loss = 0.38469497320018237, disc_loss = 0.0932781725231841
Trained batch 395 in epoch 10, gen_loss = 0.3847448169583022, disc_loss = 0.09304889529353158
Trained batch 396 in epoch 10, gen_loss = 0.384595802884258, disc_loss = 0.09282585058035212
Trained batch 397 in epoch 10, gen_loss = 0.38466688893248685, disc_loss = 0.09260567905552142
Trained batch 398 in epoch 10, gen_loss = 0.3847751400076357, disc_loss = 0.09238851731257948
Trained batch 399 in epoch 10, gen_loss = 0.3847137849777937, disc_loss = 0.0921679859427968
Trained batch 400 in epoch 10, gen_loss = 0.3848229551553132, disc_loss = 0.0919518260641762
Trained batch 401 in epoch 10, gen_loss = 0.38492348567763374, disc_loss = 0.09172964812342115
Trained batch 402 in epoch 10, gen_loss = 0.3849160516676181, disc_loss = 0.09150823640345918
Trained batch 403 in epoch 10, gen_loss = 0.38484194387893866, disc_loss = 0.09128628974886482
Trained batch 404 in epoch 10, gen_loss = 0.384788308761738, disc_loss = 0.09106542584083882
Trained batch 405 in epoch 10, gen_loss = 0.38488637644962725, disc_loss = 0.09084601520349643
Trained batch 406 in epoch 10, gen_loss = 0.3849243537067488, disc_loss = 0.09062756775479068
Trained batch 407 in epoch 10, gen_loss = 0.38498789912053183, disc_loss = 0.09041047229359667
Trained batch 408 in epoch 10, gen_loss = 0.3848985300233137, disc_loss = 0.0901947445910729
Trained batch 409 in epoch 10, gen_loss = 0.38496523557639706, disc_loss = 0.08998063580820155
Trained batch 410 in epoch 10, gen_loss = 0.3849181271817562, disc_loss = 0.08976912277568258
Trained batch 411 in epoch 10, gen_loss = 0.3848955295618298, disc_loss = 0.08955514335296189
Trained batch 412 in epoch 10, gen_loss = 0.3850091105511922, disc_loss = 0.08934471723099283
Trained batch 413 in epoch 10, gen_loss = 0.38507490140804346, disc_loss = 0.08913677033281026
Trained batch 414 in epoch 10, gen_loss = 0.385137804014137, disc_loss = 0.08892709916620235
Trained batch 415 in epoch 10, gen_loss = 0.38516226024008715, disc_loss = 0.08871757996054769
Trained batch 416 in epoch 10, gen_loss = 0.38508327551882904, disc_loss = 0.08850871203093158
Trained batch 417 in epoch 10, gen_loss = 0.385243081376313, disc_loss = 0.08830505943969649
Trained batch 418 in epoch 10, gen_loss = 0.3852026934839945, disc_loss = 0.08811240200078901
Trained batch 419 in epoch 10, gen_loss = 0.3853512326876322, disc_loss = 0.08793145347902152
Trained batch 420 in epoch 10, gen_loss = 0.38541942084486863, disc_loss = 0.0877490069060708
Trained batch 421 in epoch 10, gen_loss = 0.38542782250456337, disc_loss = 0.08754941620571556
Trained batch 422 in epoch 10, gen_loss = 0.38540890559237057, disc_loss = 0.08735117015300041
Trained batch 423 in epoch 10, gen_loss = 0.3855006826233189, disc_loss = 0.08715363217540797
Trained batch 424 in epoch 10, gen_loss = 0.3855828358145321, disc_loss = 0.08695314567399157
Trained batch 425 in epoch 10, gen_loss = 0.3857445217354197, disc_loss = 0.08676389268432207
Trained batch 426 in epoch 10, gen_loss = 0.38567262797221646, disc_loss = 0.08658370401451813
Trained batch 427 in epoch 10, gen_loss = 0.3857841269574433, disc_loss = 0.08639327304358332
Trained batch 428 in epoch 10, gen_loss = 0.3857449859311253, disc_loss = 0.08619768874440777
Trained batch 429 in epoch 10, gen_loss = 0.3858918116536251, disc_loss = 0.08600418269607174
Trained batch 430 in epoch 10, gen_loss = 0.38604751090992356, disc_loss = 0.08581255017828386
Trained batch 431 in epoch 10, gen_loss = 0.38597805708370825, disc_loss = 0.08562275012001111
Trained batch 432 in epoch 10, gen_loss = 0.385918437815153, disc_loss = 0.08542954677572866
Trained batch 433 in epoch 10, gen_loss = 0.38587679875336484, disc_loss = 0.08523570952565765
Trained batch 434 in epoch 10, gen_loss = 0.38595482247999346, disc_loss = 0.08504474256669396
Trained batch 435 in epoch 10, gen_loss = 0.38597928267826725, disc_loss = 0.08485482964897528
Trained batch 436 in epoch 10, gen_loss = 0.3858606957189006, disc_loss = 0.08466699099843764
Trained batch 437 in epoch 10, gen_loss = 0.3858187408888177, disc_loss = 0.0844793927422023
Trained batch 438 in epoch 10, gen_loss = 0.38594842323681217, disc_loss = 0.08430197703862109
Trained batch 439 in epoch 10, gen_loss = 0.3859519978815859, disc_loss = 0.08411749478916383
Trained batch 440 in epoch 10, gen_loss = 0.3859368482955189, disc_loss = 0.08392958486343939
Trained batch 441 in epoch 10, gen_loss = 0.3859949981734763, disc_loss = 0.08374571500212266
Trained batch 442 in epoch 10, gen_loss = 0.3859577873221369, disc_loss = 0.08356381730417223
Trained batch 443 in epoch 10, gen_loss = 0.3858679792097023, disc_loss = 0.08338307817482289
Trained batch 444 in epoch 10, gen_loss = 0.38589023432035124, disc_loss = 0.08320121217827742
Trained batch 445 in epoch 10, gen_loss = 0.3860495635078627, disc_loss = 0.08302142969859898
Trained batch 446 in epoch 10, gen_loss = 0.38608277090710547, disc_loss = 0.08283901198244169
Trained batch 447 in epoch 10, gen_loss = 0.3860808499157429, disc_loss = 0.0826569523451326
Trained batch 448 in epoch 10, gen_loss = 0.3858914775545719, disc_loss = 0.08248472244599067
Trained batch 449 in epoch 10, gen_loss = 0.3859894039895799, disc_loss = 0.08230752486425141
Trained batch 450 in epoch 10, gen_loss = 0.38593284452040816, disc_loss = 0.08213410123526026
Trained batch 451 in epoch 10, gen_loss = 0.38600803852345034, disc_loss = 0.08195789668717282
Trained batch 452 in epoch 10, gen_loss = 0.38614398056834476, disc_loss = 0.08178060328732831
Trained batch 453 in epoch 10, gen_loss = 0.3860577835254207, disc_loss = 0.08160552565989983
Trained batch 454 in epoch 10, gen_loss = 0.38610129624932676, disc_loss = 0.08143116813280958
Trained batch 455 in epoch 10, gen_loss = 0.38603933789489564, disc_loss = 0.08125611718972786
Trained batch 456 in epoch 10, gen_loss = 0.38605467593643805, disc_loss = 0.08108123442916204
Trained batch 457 in epoch 10, gen_loss = 0.38602315579179075, disc_loss = 0.08090652528780158
Trained batch 458 in epoch 10, gen_loss = 0.3862539650567996, disc_loss = 0.08076675668914755
Testing Epoch 10
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:41:10,836
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:41:10,859
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:41:10,902
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-09-01 10:41:10,924
------------------------------------------------------------
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.4524461030960083, disc_loss = 0.0030185128562152386
Trained batch 1 in epoch 11, gen_loss = 0.42709028720855713, disc_loss = 0.0027901495341211557
Trained batch 2 in epoch 11, gen_loss = 0.4440705180168152, disc_loss = 0.0027702496542284885
Trained batch 3 in epoch 11, gen_loss = 0.43462343513965607, disc_loss = 0.0026151949423365295
Trained batch 4 in epoch 11, gen_loss = 0.4307486295700073, disc_loss = 0.0027249987702816724
Trained batch 5 in epoch 11, gen_loss = 0.42237284282843274, disc_loss = 0.0025062850521256528
Trained batch 6 in epoch 11, gen_loss = 0.41699302196502686, disc_loss = 0.0026110379091863123
Trained batch 7 in epoch 11, gen_loss = 0.4136689528822899, disc_loss = 0.0024471197684761137
Trained batch 8 in epoch 11, gen_loss = 0.413903640376197, disc_loss = 0.0022969498919943967
Trained batch 9 in epoch 11, gen_loss = 0.40696209073066714, disc_loss = 0.0021748926024883985
Trained batch 10 in epoch 11, gen_loss = 0.4047749475999312, disc_loss = 0.002140184726820073
Trained batch 11 in epoch 11, gen_loss = 0.4035143901904424, disc_loss = 0.0021095145105694733
Trained batch 12 in epoch 11, gen_loss = 0.39866690223033613, disc_loss = 0.00207621745693569
Trained batch 13 in epoch 11, gen_loss = 0.39866240535463604, disc_loss = 0.002073490060865879
Trained batch 14 in epoch 11, gen_loss = 0.3986588895320892, disc_loss = 0.0020591954390207926
Trained batch 15 in epoch 11, gen_loss = 0.3969862964004278, disc_loss = 0.0020400112989591435
Trained batch 16 in epoch 11, gen_loss = 0.3966239918680752, disc_loss = 0.0020244215916403953
Trained batch 17 in epoch 11, gen_loss = 0.39642446570926243, disc_loss = 0.0019917573404705357
Trained batch 18 in epoch 11, gen_loss = 0.39498057177192286, disc_loss = 0.0019377309302064149
Trained batch 19 in epoch 11, gen_loss = 0.3956710368394852, disc_loss = 0.0018982487847097218
Trained batch 20 in epoch 11, gen_loss = 0.39277407101222445, disc_loss = 0.0018744448177693855
Trained batch 21 in epoch 11, gen_loss = 0.39398511431433936, disc_loss = 0.0020230498524721374
Trained batch 22 in epoch 11, gen_loss = 0.39690307948900305, disc_loss = 0.0020139287883901725
Trained batch 23 in epoch 11, gen_loss = 0.3987099292377631, disc_loss = 0.002073346253988954
Trained batch 24 in epoch 11, gen_loss = 0.39957439064979555, disc_loss = 0.0021305462392047047
Trained batch 25 in epoch 11, gen_loss = 0.3990586262482863, disc_loss = 0.002141860604751855
Trained batch 26 in epoch 11, gen_loss = 0.40078440418949834, disc_loss = 0.0021327653149556783
Trained batch 27 in epoch 11, gen_loss = 0.40005101689270567, disc_loss = 0.0021021107220024404
Trained batch 28 in epoch 11, gen_loss = 0.4000949243019367, disc_loss = 0.0020812257265286713
Trained batch 29 in epoch 11, gen_loss = 0.4012309710184733, disc_loss = 0.0020779999167037507
Trained batch 30 in epoch 11, gen_loss = 0.4009623642890684, disc_loss = 0.002075443791616107
Trained batch 31 in epoch 11, gen_loss = 0.40041470993310213, disc_loss = 0.002069384259812068
Trained batch 32 in epoch 11, gen_loss = 0.39910722049799835, disc_loss = 0.0021155779391075625
Trained batch 33 in epoch 11, gen_loss = 0.39913712266613455, disc_loss = 0.0020978130906929866
Trained batch 34 in epoch 11, gen_loss = 0.39829709615026204, disc_loss = 0.002066131534853152
Trained batch 35 in epoch 11, gen_loss = 0.3975058827135298, disc_loss = 0.002033076114862019
Trained batch 36 in epoch 11, gen_loss = 0.3978738253181045, disc_loss = 0.0021537288699324266
Trained batch 37 in epoch 11, gen_loss = 0.39804905025582565, disc_loss = 0.0021810671268643715
Trained batch 38 in epoch 11, gen_loss = 0.3979971760358566, disc_loss = 0.0021642485039475826
Trained batch 39 in epoch 11, gen_loss = 0.3994296990334988, disc_loss = 0.0021845149414730257
Trained batch 40 in epoch 11, gen_loss = 0.3989320579098492, disc_loss = 0.0022125145798072036
Trained batch 41 in epoch 11, gen_loss = 0.39800705583322615, disc_loss = 0.002194778213465941
Trained batch 42 in epoch 11, gen_loss = 0.39897081186605055, disc_loss = 0.0021884645522182245
Trained batch 43 in epoch 11, gen_loss = 0.39709591188214044, disc_loss = 0.002170633904328993
Trained batch 44 in epoch 11, gen_loss = 0.3971835712591807, disc_loss = 0.002146914918234365
Trained batch 45 in epoch 11, gen_loss = 0.39770382448383, disc_loss = 0.0021270688246105515
Trained batch 46 in epoch 11, gen_loss = 0.39709445009840294, disc_loss = 0.0021169219386486457
Trained batch 47 in epoch 11, gen_loss = 0.3952670097351074, disc_loss = 0.002104754235915607
Trained batch 48 in epoch 11, gen_loss = 0.3961436042980272, disc_loss = 0.002094904617739043
Trained batch 49 in epoch 11, gen_loss = 0.3961039465665817, disc_loss = 0.0020812763937283307
Trained batch 50 in epoch 11, gen_loss = 0.39586745991426353, disc_loss = 0.0020869102331298383
Trained batch 51 in epoch 11, gen_loss = 0.3952071053477434, disc_loss = 0.0020850486930262726
Trained batch 52 in epoch 11, gen_loss = 0.3940928004822641, disc_loss = 0.0021183818176757755
Trained batch 53 in epoch 11, gen_loss = 0.39455580049090916, disc_loss = 0.0022498627626595814
Trained batch 54 in epoch 11, gen_loss = 0.3943240452896465, disc_loss = 0.002237962665755979
Trained batch 55 in epoch 11, gen_loss = 0.39452995519552914, disc_loss = 0.0022267194342150886
Trained batch 56 in epoch 11, gen_loss = 0.3942074017566547, disc_loss = 0.0022109171014132074
Trained batch 57 in epoch 11, gen_loss = 0.39406397167978613, disc_loss = 0.0022066907007809214
Trained batch 58 in epoch 11, gen_loss = 0.39324248039116294, disc_loss = 0.0021840906652653494
Trained batch 59 in epoch 11, gen_loss = 0.3932174235582352, disc_loss = 0.002172108998638578
Trained batch 60 in epoch 11, gen_loss = 0.39372075092597086, disc_loss = 0.0021532716708578415
Trained batch 61 in epoch 11, gen_loss = 0.3928688649208315, disc_loss = 0.0021362765570126113
Trained batch 62 in epoch 11, gen_loss = 0.39276802634435987, disc_loss = 0.0021517364158561187
Trained batch 63 in epoch 11, gen_loss = 0.3933515204116702, disc_loss = 0.0021442953120640595
Trained batch 64 in epoch 11, gen_loss = 0.39388950971456677, disc_loss = 0.0021303285172997186
Trained batch 65 in epoch 11, gen_loss = 0.39411159762830444, disc_loss = 0.002112610295598367
Trained batch 66 in epoch 11, gen_loss = 0.3935158234923633, disc_loss = 0.0021056805219529058
Trained batch 67 in epoch 11, gen_loss = 0.39274942305158167, disc_loss = 0.00211337094215731
Trained batch 68 in epoch 11, gen_loss = 0.3924901852573174, disc_loss = 0.002099836206374069
Trained batch 69 in epoch 11, gen_loss = 0.3920374580792018, disc_loss = 0.00209386614151299
Trained batch 70 in epoch 11, gen_loss = 0.3915825154579861, disc_loss = 0.002078111014578124
Trained batch 71 in epoch 11, gen_loss = 0.39151624631550574, disc_loss = 0.002068302477709949
Trained batch 72 in epoch 11, gen_loss = 0.39181761586502806, disc_loss = 0.002061153494127809
Trained batch 73 in epoch 11, gen_loss = 0.3926805584011851, disc_loss = 0.0020561925201626444
Trained batch 74 in epoch 11, gen_loss = 0.39201486269632974, disc_loss = 0.0020571991320078573
Trained batch 75 in epoch 11, gen_loss = 0.39200125281748016, disc_loss = 0.0021312670417644674
Trained batch 76 in epoch 11, gen_loss = 0.3924199803309007, disc_loss = 0.0022050460464889546
Trained batch 77 in epoch 11, gen_loss = 0.39352038426276964, disc_loss = 0.002251580102333369
Trained batch 78 in epoch 11, gen_loss = 0.3939776265922981, disc_loss = 0.0022506489922422207
Trained batch 79 in epoch 11, gen_loss = 0.39430306032299994, disc_loss = 0.0023107075176085345
Trained batch 80 in epoch 11, gen_loss = 0.39500442846321765, disc_loss = 0.00230904384429946
Trained batch 81 in epoch 11, gen_loss = 0.394936723680031, disc_loss = 0.0023019607178866863
Trained batch 82 in epoch 11, gen_loss = 0.39582477456115817, disc_loss = 0.0023863519014543796
Trained batch 83 in epoch 11, gen_loss = 0.3960593495340574, disc_loss = 0.0023911855865402947
Trained batch 84 in epoch 11, gen_loss = 0.3957377325086033, disc_loss = 0.0023958190919502694
Trained batch 85 in epoch 11, gen_loss = 0.3953560895698015, disc_loss = 0.002472163370247324
Trained batch 86 in epoch 11, gen_loss = 0.3952678695492361, disc_loss = 0.002548071681575357
Trained batch 87 in epoch 11, gen_loss = 0.3958396092057228, disc_loss = 0.002562667851717296
Trained batch 88 in epoch 11, gen_loss = 0.3954979820867603, disc_loss = 0.0033390337988483103
Trained batch 89 in epoch 11, gen_loss = 0.39528018467956116, disc_loss = 0.0035303810559627084
Trained batch 90 in epoch 11, gen_loss = 0.39481982294019763, disc_loss = 0.003669918949746496
Trained batch 91 in epoch 11, gen_loss = 0.39459550899008045, disc_loss = 0.0037520022445317845
Trained batch 92 in epoch 11, gen_loss = 0.39429901331983586, disc_loss = 0.003781640907168709
Trained batch 93 in epoch 11, gen_loss = 0.392945334632346, disc_loss = 0.004001626095912875
Trained batch 94 in epoch 11, gen_loss = 0.39210670872738485, disc_loss = 0.004166695519693588
Trained batch 95 in epoch 11, gen_loss = 0.3919049672161539, disc_loss = 0.004208247114244538
Trained batch 96 in epoch 11, gen_loss = 0.3918373815177642, disc_loss = 0.004332763685355174
Trained batch 97 in epoch 11, gen_loss = 0.39214288154426885, disc_loss = 0.00436293215928029
Trained batch 98 in epoch 11, gen_loss = 0.3923024553241152, disc_loss = 0.004391869826411659
Trained batch 99 in epoch 11, gen_loss = 0.39297848641872407, disc_loss = 0.00474428856279701
Trained batch 100 in epoch 11, gen_loss = 0.39249961004398837, disc_loss = 0.007093330656205959
Trained batch 101 in epoch 11, gen_loss = 0.393212451654322, disc_loss = 0.00814082014703137
Trained batch 102 in epoch 11, gen_loss = 0.3942521908908214, disc_loss = 0.00963904652111594
Trained batch 103 in epoch 11, gen_loss = 0.3947530257014128, disc_loss = 0.009666386432050226
Trained batch 104 in epoch 11, gen_loss = 0.3952725603466942, disc_loss = 0.009767278048786378
Trained batch 105 in epoch 11, gen_loss = 0.39463331901802207, disc_loss = 0.009794181761911736
Trained batch 106 in epoch 11, gen_loss = 0.39473831207952764, disc_loss = 0.009756281906651837
Trained batch 107 in epoch 11, gen_loss = 0.394964243526812, disc_loss = 0.009692508425494586
Trained batch 108 in epoch 11, gen_loss = 0.3949440020486849, disc_loss = 0.00962735364777506
Trained batch 109 in epoch 11, gen_loss = 0.39493132369084794, disc_loss = 0.009556431180416521
Trained batch 110 in epoch 11, gen_loss = 0.3943257377491341, disc_loss = 0.009495493571005494
Trained batch 111 in epoch 11, gen_loss = 0.3937489967793226, disc_loss = 0.009428340755610927
Trained batch 112 in epoch 11, gen_loss = 0.39391566034966863, disc_loss = 0.009370951131357094
Trained batch 113 in epoch 11, gen_loss = 0.3936654028662464, disc_loss = 0.009318723503639105
Trained batch 114 in epoch 11, gen_loss = 0.39405657493549845, disc_loss = 0.009285584583109163
Trained batch 115 in epoch 11, gen_loss = 0.39387418021415843, disc_loss = 0.009221257723201516
Trained batch 116 in epoch 11, gen_loss = 0.39350873588496804, disc_loss = 0.00916741840226942
Trained batch 117 in epoch 11, gen_loss = 0.39317088258468497, disc_loss = 0.009107361485494963
Trained batch 118 in epoch 11, gen_loss = 0.39311423847655286, disc_loss = 0.009048751024177158
Trained batch 119 in epoch 11, gen_loss = 0.39343543772896133, disc_loss = 0.008993841743601176
Trained batch 120 in epoch 11, gen_loss = 0.3933933739327202, disc_loss = 0.008935797541048224
Trained batch 121 in epoch 11, gen_loss = 0.3935311363368738, disc_loss = 0.008882094229014254
Trained batch 122 in epoch 11, gen_loss = 0.3940278655145226, disc_loss = 0.008832443144922032
Trained batch 123 in epoch 11, gen_loss = 0.3942667442944742, disc_loss = 0.008778979110854467
Trained batch 124 in epoch 11, gen_loss = 0.3942349169254303, disc_loss = 0.008731563358567656
Trained batch 125 in epoch 11, gen_loss = 0.39428557360929156, disc_loss = 0.008682663725238175
Trained batch 126 in epoch 11, gen_loss = 0.3939641010104202, disc_loss = 0.008643472421452345
Trained batch 127 in epoch 11, gen_loss = 0.3940457708667964, disc_loss = 0.008623448921753152
Trained batch 128 in epoch 11, gen_loss = 0.394011013498602, disc_loss = 0.008687626188729218
Trained batch 129 in epoch 11, gen_loss = 0.3940237308924015, disc_loss = 0.008645226581631084
Trained batch 130 in epoch 11, gen_loss = 0.39411627472811983, disc_loss = 0.008606939136676263
Trained batch 131 in epoch 11, gen_loss = 0.3943329954689199, disc_loss = 0.008870058094158374
Trained batch 132 in epoch 11, gen_loss = 0.3943576767928618, disc_loss = 0.008839659785844833
Trained batch 133 in epoch 11, gen_loss = 0.39446020326507625, disc_loss = 0.008901596904224925
Trained batch 134 in epoch 11, gen_loss = 0.3940829908406293, disc_loss = 0.008858389328923766
Trained batch 135 in epoch 11, gen_loss = 0.3935947385342682, disc_loss = 0.008862065682906713
Trained batch 136 in epoch 11, gen_loss = 0.3935643193060464, disc_loss = 0.00915299400595445
Trained batch 137 in epoch 11, gen_loss = 0.3935851387787556, disc_loss = 0.009680887938146412
Trained batch 138 in epoch 11, gen_loss = 0.39363665760849875, disc_loss = 0.00993951695230823
Trained batch 139 in epoch 11, gen_loss = 0.39325320358787264, disc_loss = 0.009969732262626556
Trained batch 140 in epoch 11, gen_loss = 0.3929744952536644, disc_loss = 0.00996767665863909
Trained batch 141 in epoch 11, gen_loss = 0.39276904392410333, disc_loss = 0.009947761644865058
Trained batch 142 in epoch 11, gen_loss = 0.3930464301492784, disc_loss = 0.01040783338330139
Trained batch 143 in epoch 11, gen_loss = 0.39202292832649416, disc_loss = 0.012345562185348373
Trained batch 144 in epoch 11, gen_loss = 0.39206733364483404, disc_loss = 0.014187258701161321
Trained batch 145 in epoch 11, gen_loss = 0.39231783406783455, disc_loss = 0.014281626319519104
Trained batch 146 in epoch 11, gen_loss = 0.3924929356696654, disc_loss = 0.01475393867237354
Trained batch 147 in epoch 11, gen_loss = 0.39176251225777575, disc_loss = 0.014958089986042044
Trained batch 148 in epoch 11, gen_loss = 0.3917448411651906, disc_loss = 0.014996086079283499
Trained batch 149 in epoch 11, gen_loss = 0.39186289777358374, disc_loss = 0.014950243446510286
Trained batch 150 in epoch 11, gen_loss = 0.3913965666333571, disc_loss = 0.015169698881472628
Trained batch 151 in epoch 11, gen_loss = 0.39152140395813867, disc_loss = 0.016587397096660232
Trained batch 152 in epoch 11, gen_loss = 0.3907027132565679, disc_loss = 0.018151486147152493
Trained batch 153 in epoch 11, gen_loss = 0.39092025325282825, disc_loss = 0.018861177789392072
Trained batch 154 in epoch 11, gen_loss = 0.3909515716375843, disc_loss = 0.018851516504711924
Trained batch 155 in epoch 11, gen_loss = 0.391410433424589, disc_loss = 0.018754903284552243
Trained batch 156 in epoch 11, gen_loss = 0.3909583609005448, disc_loss = 0.01872635319915001
Trained batch 157 in epoch 11, gen_loss = 0.39088149057536187, disc_loss = 0.018701870628791754
Trained batch 158 in epoch 11, gen_loss = 0.39097845507492807, disc_loss = 0.0186052765344334
Trained batch 159 in epoch 11, gen_loss = 0.3909152542240918, disc_loss = 0.018545050176180668
Trained batch 160 in epoch 11, gen_loss = 0.3909032071784416, disc_loss = 0.018450148293013852
Trained batch 161 in epoch 11, gen_loss = 0.39108155106688725, disc_loss = 0.018368187661564415
Trained batch 162 in epoch 11, gen_loss = 0.3906826237045183, disc_loss = 0.018508229121148724
Trained batch 163 in epoch 11, gen_loss = 0.3905903112779303, disc_loss = 0.018447098682106405
Trained batch 164 in epoch 11, gen_loss = 0.3899400632489811, disc_loss = 0.01879962756877031
Trained batch 165 in epoch 11, gen_loss = 0.3896158018923668, disc_loss = 0.01881944604361071
Trained batch 166 in epoch 11, gen_loss = 0.3898421972990036, disc_loss = 0.019091485644701846
Trained batch 167 in epoch 11, gen_loss = 0.3900400748742478, disc_loss = 0.019578604966573904
Trained batch 168 in epoch 11, gen_loss = 0.3896762771895651, disc_loss = 0.021522517880209938
Trained batch 169 in epoch 11, gen_loss = 0.3901623141239671, disc_loss = 0.0219204142326763
Trained batch 170 in epoch 11, gen_loss = 0.3902288059219282, disc_loss = 0.022030197636071832
Trained batch 171 in epoch 11, gen_loss = 0.3898761030719724, disc_loss = 0.022124595341115626
Trained batch 172 in epoch 11, gen_loss = 0.38992861490373665, disc_loss = 0.022254845360966904
Trained batch 173 in epoch 11, gen_loss = 0.38995174284296474, disc_loss = 0.022224168643093102
Trained batch 174 in epoch 11, gen_loss = 0.39036721544606345, disc_loss = 0.0228738280458908
Trained batch 175 in epoch 11, gen_loss = 0.38995638938451355, disc_loss = 0.02373279171495762
Trained batch 176 in epoch 11, gen_loss = 0.390449989397647, disc_loss = 0.02366192827966738
Trained batch 177 in epoch 11, gen_loss = 0.39051380728402835, disc_loss = 0.023625387911543543
Trained batch 178 in epoch 11, gen_loss = 0.39063672937827404, disc_loss = 0.0235376346657344
Trained batch 179 in epoch 11, gen_loss = 0.3902607772913244, disc_loss = 0.023522418102947994
Trained batch 180 in epoch 11, gen_loss = 0.38987387881423885, disc_loss = 0.023765500888964213
Trained batch 181 in epoch 11, gen_loss = 0.39030722888943914, disc_loss = 0.023900715805011914
Trained batch 182 in epoch 11, gen_loss = 0.39018148208250764, disc_loss = 0.024034346048618396
Trained batch 183 in epoch 11, gen_loss = 0.38964121715854044, disc_loss = 0.024764245767627195
Trained batch 184 in epoch 11, gen_loss = 0.3899691110527193, disc_loss = 0.02476716627228401
Trained batch 185 in epoch 11, gen_loss = 0.3902163514366714, disc_loss = 0.02516479411360217
Trained batch 186 in epoch 11, gen_loss = 0.39008843412692534, disc_loss = 0.02507126410454412
Trained batch 187 in epoch 11, gen_loss = 0.39001249751829087, disc_loss = 0.02501457525315655
Trained batch 188 in epoch 11, gen_loss = 0.38989192412959206, disc_loss = 0.024948964929627008
Trained batch 189 in epoch 11, gen_loss = 0.3898650841493356, disc_loss = 0.02485032076150865
Trained batch 190 in epoch 11, gen_loss = 0.3898197687889269, disc_loss = 0.024775158501161916
Trained batch 191 in epoch 11, gen_loss = 0.38968329682635766, disc_loss = 0.024696903986599256
Trained batch 192 in epoch 11, gen_loss = 0.3896515467469556, disc_loss = 0.024828085728312983
Trained batch 193 in epoch 11, gen_loss = 0.3895064772865207, disc_loss = 0.025246749933900255
Trained batch 194 in epoch 11, gen_loss = 0.3890348033263133, disc_loss = 0.026510718029637177
Trained batch 195 in epoch 11, gen_loss = 0.3887367837739234, disc_loss = 0.026693866345247407
Trained batch 196 in epoch 11, gen_loss = 0.3893652239880586, disc_loss = 0.027151286076673962
Trained batch 197 in epoch 11, gen_loss = 0.38930466462566393, disc_loss = 0.02774498672306895
Trained batch 198 in epoch 11, gen_loss = 0.3895219732918332, disc_loss = 0.02768078106092804
Trained batch 199 in epoch 11, gen_loss = 0.3892553823441267, disc_loss = 0.027797869298956356
Trained batch 200 in epoch 11, gen_loss = 0.38922164800451764, disc_loss = 0.027843710391281813
Trained batch 201 in epoch 11, gen_loss = 0.38942492207383167, disc_loss = 0.027900800131385833
Trained batch 202 in epoch 11, gen_loss = 0.38984926147707577, disc_loss = 0.028126335592155938
Trained batch 203 in epoch 11, gen_loss = 0.3896755943549614, disc_loss = 0.02866377596065457
Trained batch 204 in epoch 11, gen_loss = 0.38982433102479797, disc_loss = 0.0288711362717128
Trained batch 205 in epoch 11, gen_loss = 0.3900428620501629, disc_loss = 0.028751846994567228
Trained batch 206 in epoch 11, gen_loss = 0.39023249830312773, disc_loss = 0.02870250390201429
Trained batch 207 in epoch 11, gen_loss = 0.3903100141682304, disc_loss = 0.028663432695164096
Trained batch 208 in epoch 11, gen_loss = 0.39013355606765837, disc_loss = 0.028690623007514224
Trained batch 209 in epoch 11, gen_loss = 0.3904334713305746, disc_loss = 0.028781192664921816
Trained batch 210 in epoch 11, gen_loss = 0.3903160689142643, disc_loss = 0.028740640609940048
Trained batch 211 in epoch 11, gen_loss = 0.39036776273036905, disc_loss = 0.02939871611141705
Trained batch 212 in epoch 11, gen_loss = 0.3906853108758658, disc_loss = 0.030749247776138914
Trained batch 213 in epoch 11, gen_loss = 0.39064318477828924, disc_loss = 0.03063769864569044
Trained batch 214 in epoch 11, gen_loss = 0.3903697033954221, disc_loss = 0.03065220410123381
Trained batch 215 in epoch 11, gen_loss = 0.3904256997974934, disc_loss = 0.030596588908035
Trained batch 216 in epoch 11, gen_loss = 0.3903023763323709, disc_loss = 0.030560122499744567
Trained batch 217 in epoch 11, gen_loss = 0.39044744165938927, disc_loss = 0.03044838794248623
Trained batch 218 in epoch 11, gen_loss = 0.3902510206585061, disc_loss = 0.03041925343533884
Trained batch 219 in epoch 11, gen_loss = 0.3899109759791331, disc_loss = 0.030543990290871906
Trained batch 220 in epoch 11, gen_loss = 0.39021430262343376, disc_loss = 0.03182940285524345
Trained batch 221 in epoch 11, gen_loss = 0.3902499266975635, disc_loss = 0.03277523197424556
Trained batch 222 in epoch 11, gen_loss = 0.3906986362597333, disc_loss = 0.03322848028789437
Trained batch 223 in epoch 11, gen_loss = 0.3902935021823006, disc_loss = 0.033331522478485046
Trained batch 224 in epoch 11, gen_loss = 0.39005974683496686, disc_loss = 0.033282766467891634
Trained batch 225 in epoch 11, gen_loss = 0.389731980992102, disc_loss = 0.03330127617284507
Trained batch 226 in epoch 11, gen_loss = 0.3897249761000604, disc_loss = 0.03317594996269891
Trained batch 227 in epoch 11, gen_loss = 0.38996161566230286, disc_loss = 0.03354576509803321
Trained batch 228 in epoch 11, gen_loss = 0.38998770538115607, disc_loss = 0.03395045010574308
Trained batch 229 in epoch 11, gen_loss = 0.3900454946834108, disc_loss = 0.03399652989692581
Trained batch 230 in epoch 11, gen_loss = 0.3902274800456447, disc_loss = 0.0338787539490172
Trained batch 231 in epoch 11, gen_loss = 0.3904384671999463, disc_loss = 0.033762600938769476
Trained batch 232 in epoch 11, gen_loss = 0.39070063311398795, disc_loss = 0.033662247263162914
Trained batch 233 in epoch 11, gen_loss = 0.39043389891202634, disc_loss = 0.03359269909908932
Trained batch 234 in epoch 11, gen_loss = 0.3904896267551057, disc_loss = 0.033535474613606134
Trained batch 235 in epoch 11, gen_loss = 0.39101850664464094, disc_loss = 0.033799412655861165
Trained batch 236 in epoch 11, gen_loss = 0.3906959801409315, disc_loss = 0.03502573570745451
Trained batch 237 in epoch 11, gen_loss = 0.39092666092289596, disc_loss = 0.035512300986432696
Trained batch 238 in epoch 11, gen_loss = 0.391093912546106, disc_loss = 0.03545223027185213
Trained batch 239 in epoch 11, gen_loss = 0.3913581108674407, disc_loss = 0.035327354527059165
Trained batch 240 in epoch 11, gen_loss = 0.39144599814879943, disc_loss = 0.03520201566615586
Trained batch 241 in epoch 11, gen_loss = 0.39156383836318637, disc_loss = 0.0350827298233909
Trained batch 242 in epoch 11, gen_loss = 0.3917984673638403, disc_loss = 0.034964916014127864
Trained batch 243 in epoch 11, gen_loss = 0.3916645613727999, disc_loss = 0.03484235223159423
Trained batch 244 in epoch 11, gen_loss = 0.39176389471608764, disc_loss = 0.03471385920752904
Trained batch 245 in epoch 11, gen_loss = 0.39197024067000646, disc_loss = 0.03458481482409955
Trained batch 246 in epoch 11, gen_loss = 0.3921476921692551, disc_loss = 0.03445182491974294
Trained batch 247 in epoch 11, gen_loss = 0.3922300072567117, disc_loss = 0.03432610770546636
Trained batch 248 in epoch 11, gen_loss = 0.3921263396859648, disc_loss = 0.03419573349461154
Trained batch 249 in epoch 11, gen_loss = 0.3919597838521004, disc_loss = 0.03407308336766437
Trained batch 250 in epoch 11, gen_loss = 0.3916619624868332, disc_loss = 0.03395021248996569
Trained batch 251 in epoch 11, gen_loss = 0.3917593295493769, disc_loss = 0.03383312194787395
Trained batch 252 in epoch 11, gen_loss = 0.3917476961853005, disc_loss = 0.033710427459406674
Trained batch 253 in epoch 11, gen_loss = 0.39167798509982626, disc_loss = 0.03358676248847866
Trained batch 254 in epoch 11, gen_loss = 0.39157172599259543, disc_loss = 0.033466785911050644
Trained batch 255 in epoch 11, gen_loss = 0.39181535242823884, disc_loss = 0.03335262433256503
Trained batch 256 in epoch 11, gen_loss = 0.3919054893088248, disc_loss = 0.033231893784895626
Trained batch 257 in epoch 11, gen_loss = 0.39178975602222044, disc_loss = 0.03311519941194127
Trained batch 258 in epoch 11, gen_loss = 0.39197050921014837, disc_loss = 0.03299911067826479
Trained batch 259 in epoch 11, gen_loss = 0.3920727751002862, disc_loss = 0.03290676632940841
Trained batch 260 in epoch 11, gen_loss = 0.39221801172042714, disc_loss = 0.03280078635285198
Trained batch 261 in epoch 11, gen_loss = 0.39239207928189795, disc_loss = 0.03268506902115391
Trained batch 262 in epoch 11, gen_loss = 0.3924095233470315, disc_loss = 0.03256922648881452
Trained batch 263 in epoch 11, gen_loss = 0.3924776080318473, disc_loss = 0.03247367367051387
Trained batch 264 in epoch 11, gen_loss = 0.39218507369734207, disc_loss = 0.03248523974940532
Trained batch 265 in epoch 11, gen_loss = 0.3923696740565443, disc_loss = 0.03244600559215419
Trained batch 266 in epoch 11, gen_loss = 0.3922570941041918, disc_loss = 0.03260796354631876
Trained batch 267 in epoch 11, gen_loss = 0.39202853375628816, disc_loss = 0.03333441348122641
Trained batch 268 in epoch 11, gen_loss = 0.39208770667974835, disc_loss = 0.03333181557617736
Trained batch 269 in epoch 11, gen_loss = 0.392196972447413, disc_loss = 0.03402918013614706
Trained batch 270 in epoch 11, gen_loss = 0.39203273100826574, disc_loss = 0.03509193900122043
Trained batch 271 in epoch 11, gen_loss = 0.39207614273490277, disc_loss = 0.03509367223844439
Trained batch 272 in epoch 11, gen_loss = 0.39229743641156417, disc_loss = 0.035666948867085026
Trained batch 273 in epoch 11, gen_loss = 0.3921695229237097, disc_loss = 0.035729578302333635
Trained batch 274 in epoch 11, gen_loss = 0.3922508066892624, disc_loss = 0.03572123423938386
Trained batch 275 in epoch 11, gen_loss = 0.39230068476087804, disc_loss = 0.035703752912408876
Trained batch 276 in epoch 11, gen_loss = 0.3917919689459921, disc_loss = 0.0359360897305862
Trained batch 277 in epoch 11, gen_loss = 0.3918606450767826, disc_loss = 0.036573927387638726
Trained batch 278 in epoch 11, gen_loss = 0.39149351888019124, disc_loss = 0.036617359293768297
Trained batch 279 in epoch 11, gen_loss = 0.3914913651666471, disc_loss = 0.03659571449180865
Trained batch 280 in epoch 11, gen_loss = 0.39150485030484794, disc_loss = 0.03650502780381113
Trained batch 281 in epoch 11, gen_loss = 0.39159533598110186, disc_loss = 0.036513697693259815
Trained batch 282 in epoch 11, gen_loss = 0.3919449423837999, disc_loss = 0.03650273846720704
Trained batch 283 in epoch 11, gen_loss = 0.3921431252129481, disc_loss = 0.036506426081628685
Trained batch 284 in epoch 11, gen_loss = 0.3924519109621383, disc_loss = 0.03642564769221568
Trained batch 285 in epoch 11, gen_loss = 0.39247708142428966, disc_loss = 0.03634360385448118
Trained batch 286 in epoch 11, gen_loss = 0.39247068435680577, disc_loss = 0.03634928265231165
Trained batch 287 in epoch 11, gen_loss = 0.3926050175084836, disc_loss = 0.03704125397659178
Trained batch 288 in epoch 11, gen_loss = 0.3925400086030828, disc_loss = 0.038939540203947534
Trained batch 289 in epoch 11, gen_loss = 0.39264390052392567, disc_loss = 0.03999485994954112
Trained batch 290 in epoch 11, gen_loss = 0.39250307860448186, disc_loss = 0.040702829448285405
Trained batch 291 in epoch 11, gen_loss = 0.39242885236258374, disc_loss = 0.04139116742968725
Trained batch 292 in epoch 11, gen_loss = 0.3923270499441811, disc_loss = 0.04204237226868818
Trained batch 293 in epoch 11, gen_loss = 0.39218632658930863, disc_loss = 0.042703353879469615
Trained batch 294 in epoch 11, gen_loss = 0.3918314258425923, disc_loss = 0.04335049274338062
Trained batch 295 in epoch 11, gen_loss = 0.3914209421522714, disc_loss = 0.043928730626027354
Trained batch 296 in epoch 11, gen_loss = 0.3910411508496763, disc_loss = 0.04434712988485955
Trained batch 297 in epoch 11, gen_loss = 0.3912610871179792, disc_loss = 0.04466008474689365
Trained batch 298 in epoch 11, gen_loss = 0.39090632201237824, disc_loss = 0.04503821902776006
Trained batch 299 in epoch 11, gen_loss = 0.39077172135313354, disc_loss = 0.045277212358778345
Trained batch 300 in epoch 11, gen_loss = 0.39075683522660076, disc_loss = 0.045342254774579996
Trained batch 301 in epoch 11, gen_loss = 0.3906813698592565, disc_loss = 0.045453062660711516
Trained batch 302 in epoch 11, gen_loss = 0.39109340580579866, disc_loss = 0.04547679082224631
Trained batch 303 in epoch 11, gen_loss = 0.3909794188741791, disc_loss = 0.04545960952504844
Trained batch 304 in epoch 11, gen_loss = 0.39077982966040004, disc_loss = 0.045817438840148515
Trained batch 305 in epoch 11, gen_loss = 0.3911181437521199, disc_loss = 0.04633600999840103
Trained batch 306 in epoch 11, gen_loss = 0.39111629589566965, disc_loss = 0.046435748882582624
Trained batch 307 in epoch 11, gen_loss = 0.39105872272864567, disc_loss = 0.04656191174789066
Trained batch 308 in epoch 11, gen_loss = 0.391040580992174, disc_loss = 0.046534267525809504
Trained batch 309 in epoch 11, gen_loss = 0.3910992470960463, disc_loss = 0.04643191241306223
Trained batch 310 in epoch 11, gen_loss = 0.39089537859921286, disc_loss = 0.04642164294265055
Trained batch 311 in epoch 11, gen_loss = 0.39078592275006646, disc_loss = 0.04685489483847796
Trained batch 312 in epoch 11, gen_loss = 0.391010471949943, disc_loss = 0.04855240452119682
Trained batch 313 in epoch 11, gen_loss = 0.3910206581471832, disc_loss = 0.049006099098252286
Trained batch 314 in epoch 11, gen_loss = 0.39094207253721025, disc_loss = 0.04935101014377165
Trained batch 315 in epoch 11, gen_loss = 0.3909141071895255, disc_loss = 0.049539810910458455
Trained batch 316 in epoch 11, gen_loss = 0.3907469943964895, disc_loss = 0.049612982736603715
Trained batch 317 in epoch 11, gen_loss = 0.39041196845425, disc_loss = 0.049669426769595126
Trained batch 318 in epoch 11, gen_loss = 0.3904763474640054, disc_loss = 0.049687893428039795
Trained batch 319 in epoch 11, gen_loss = 0.39037808827124537, disc_loss = 0.049818201215020966
Trained batch 320 in epoch 11, gen_loss = 0.3900643082515473, disc_loss = 0.04992993323696702
Trained batch 321 in epoch 11, gen_loss = 0.39011421387795336, disc_loss = 0.049880741202049765
Trained batch 322 in epoch 11, gen_loss = 0.389941490425414, disc_loss = 0.04987613687575752
Trained batch 323 in epoch 11, gen_loss = 0.38999476711507197, disc_loss = 0.050141964168474655
Trained batch 324 in epoch 11, gen_loss = 0.38982561253584347, disc_loss = 0.05129686136980756
Trained batch 325 in epoch 11, gen_loss = 0.39007016170792785, disc_loss = 0.05135946630884499
Trained batch 326 in epoch 11, gen_loss = 0.390335306160676, disc_loss = 0.05141221630829885
Trained batch 327 in epoch 11, gen_loss = 0.39026938374267844, disc_loss = 0.05132660546046171
Trained batch 328 in epoch 11, gen_loss = 0.39002916121736486, disc_loss = 0.05130763344309579
Trained batch 329 in epoch 11, gen_loss = 0.3898175783681147, disc_loss = 0.05144567931331976
Trained batch 330 in epoch 11, gen_loss = 0.3899560311859828, disc_loss = 0.05131519665791065
Trained batch 331 in epoch 11, gen_loss = 0.3902474132377699, disc_loss = 0.05133219123909149
Trained batch 332 in epoch 11, gen_loss = 0.3901625036208837, disc_loss = 0.051211044181476685
Trained batch 333 in epoch 11, gen_loss = 0.38991257865093426, disc_loss = 0.051710690466846024
Trained batch 334 in epoch 11, gen_loss = 0.3901845773209387, disc_loss = 0.05226206427002187
Trained batch 335 in epoch 11, gen_loss = 0.39038653010945945, disc_loss = 0.05218607345297988
Trained batch 336 in epoch 11, gen_loss = 0.3903207939438721, disc_loss = 0.05212239239078833
Trained batch 337 in epoch 11, gen_loss = 0.3900479136045868, disc_loss = 0.05216723611094774
Trained batch 338 in epoch 11, gen_loss = 0.38994942385714315, disc_loss = 0.05206423909451461
Trained batch 339 in epoch 11, gen_loss = 0.3899971303256119, disc_loss = 0.05217038090101114
Trained batch 340 in epoch 11, gen_loss = 0.3899027784286706, disc_loss = 0.052706402412730426
Trained batch 341 in epoch 11, gen_loss = 0.390187298214575, disc_loss = 0.053839544798669606
Trained batch 342 in epoch 11, gen_loss = 0.3901846732498953, disc_loss = 0.05409636284983595
Trained batch 343 in epoch 11, gen_loss = 0.3900417129747396, disc_loss = 0.05411140219515547
Trained batch 344 in epoch 11, gen_loss = 0.39000243738941526, disc_loss = 0.05416063097865739
Trained batch 345 in epoch 11, gen_loss = 0.39007296688811627, disc_loss = 0.05404938083455623
Trained batch 346 in epoch 11, gen_loss = 0.39002056875043367, disc_loss = 0.05391600050645416
Trained batch 347 in epoch 11, gen_loss = 0.39019295423366557, disc_loss = 0.05382179034286414
Trained batch 348 in epoch 11, gen_loss = 0.3902000745165997, disc_loss = 0.05371155334739308
Trained batch 349 in epoch 11, gen_loss = 0.3901555358937808, disc_loss = 0.0536742069149789
Trained batch 350 in epoch 11, gen_loss = 0.3900608654290523, disc_loss = 0.05398038349166098
Trained batch 351 in epoch 11, gen_loss = 0.38982384165071626, disc_loss = 0.055027101411476244
Trained batch 352 in epoch 11, gen_loss = 0.3897620671278357, disc_loss = 0.055161755574569
Trained batch 353 in epoch 11, gen_loss = 0.38988444474288975, disc_loss = 0.05513074060692846
Trained batch 354 in epoch 11, gen_loss = 0.3899237728034946, disc_loss = 0.05526080485203789
Trained batch 355 in epoch 11, gen_loss = 0.3898707956829098, disc_loss = 0.0554050115369433
Trained batch 356 in epoch 11, gen_loss = 0.38982348578149867, disc_loss = 0.05588154802627141
Trained batch 357 in epoch 11, gen_loss = 0.3899115717361093, disc_loss = 0.05600359287749008
Trained batch 358 in epoch 11, gen_loss = 0.38990272432150613, disc_loss = 0.05603373371366889
Trained batch 359 in epoch 11, gen_loss = 0.3895379757301675, disc_loss = 0.05627756864899614
Trained batch 360 in epoch 11, gen_loss = 0.3897255408549243, disc_loss = 0.057193754545614185
Trained batch 361 in epoch 11, gen_loss = 0.3894774360962994, disc_loss = 0.057425565410788734
Trained batch 362 in epoch 11, gen_loss = 0.38929224297527437, disc_loss = 0.057388115684840486
Trained batch 363 in epoch 11, gen_loss = 0.3891709072331151, disc_loss = 0.05729618733064374
Trained batch 364 in epoch 11, gen_loss = 0.3888823543917643, disc_loss = 0.057409328579813346
Trained batch 365 in epoch 11, gen_loss = 0.38886652377948083, disc_loss = 0.05731609712585125
Trained batch 366 in epoch 11, gen_loss = 0.3888533379710013, disc_loss = 0.057316683228026154
Trained batch 367 in epoch 11, gen_loss = 0.3886552991993401, disc_loss = 0.05773631841198632
Trained batch 368 in epoch 11, gen_loss = 0.3884737885337535, disc_loss = 0.05797026770316862
Trained batch 369 in epoch 11, gen_loss = 0.3883177258275651, disc_loss = 0.05797534523110182
Trained batch 370 in epoch 11, gen_loss = 0.38818001389664136, disc_loss = 0.05787313160721233
Trained batch 371 in epoch 11, gen_loss = 0.388131456229315, disc_loss = 0.057769117942292704
Trained batch 372 in epoch 11, gen_loss = 0.38795049880049504, disc_loss = 0.057801326167839645
Trained batch 373 in epoch 11, gen_loss = 0.3879345580935478, disc_loss = 0.05816032030815159
Trained batch 374 in epoch 11, gen_loss = 0.38769995685418446, disc_loss = 0.05863483177156498
Trained batch 375 in epoch 11, gen_loss = 0.38777912007842924, disc_loss = 0.05856333428806813
Trained batch 376 in epoch 11, gen_loss = 0.38785550595120344, disc_loss = 0.05844770544869405
Trained batch 377 in epoch 11, gen_loss = 0.3878399395832309, disc_loss = 0.05837732883664242
Trained batch 378 in epoch 11, gen_loss = 0.3878240051008466, disc_loss = 0.058364273965823166
Trained batch 379 in epoch 11, gen_loss = 0.38799896016716956, disc_loss = 0.058829881133523915
Trained batch 380 in epoch 11, gen_loss = 0.3882072495585039, disc_loss = 0.059367112248581086
Trained batch 381 in epoch 11, gen_loss = 0.3883800406340529, disc_loss = 0.05924693301974684
Trained batch 382 in epoch 11, gen_loss = 0.3883996588365216, disc_loss = 0.05933050404748984
Trained batch 383 in epoch 11, gen_loss = 0.3883410107421999, disc_loss = 0.05919431820711907
Trained batch 384 in epoch 11, gen_loss = 0.3884974723125433, disc_loss = 0.05911775343029385
Trained batch 385 in epoch 11, gen_loss = 0.3883714017704361, disc_loss = 0.059194229923519234
Trained batch 386 in epoch 11, gen_loss = 0.38852435069336755, disc_loss = 0.059086860861756796
Trained batch 387 in epoch 11, gen_loss = 0.3884060303344555, disc_loss = 0.059030033983158176
Trained batch 388 in epoch 11, gen_loss = 0.3882262167786571, disc_loss = 0.05943582912668787
Trained batch 389 in epoch 11, gen_loss = 0.3882875056985097, disc_loss = 0.05945332836365709
Trained batch 390 in epoch 11, gen_loss = 0.3884818881292782, disc_loss = 0.0593933006715806
Trained batch 391 in epoch 11, gen_loss = 0.3883735600250716, disc_loss = 0.05935619604133535
Trained batch 392 in epoch 11, gen_loss = 0.38826004842310463, disc_loss = 0.05977330404143003
Trained batch 393 in epoch 11, gen_loss = 0.38866813605660716, disc_loss = 0.06059606467771963
Trained batch 394 in epoch 11, gen_loss = 0.38877905882612057, disc_loss = 0.06061873230287405
Trained batch 395 in epoch 11, gen_loss = 0.3885257825481169, disc_loss = 0.06052716688230643
Trained batch 396 in epoch 11, gen_loss = 0.3882939018665693, disc_loss = 0.061267116155430804
Trained batch 397 in epoch 11, gen_loss = 0.3883784142645759, disc_loss = 0.06174167528679482
Trained batch 398 in epoch 11, gen_loss = 0.3883724503573917, disc_loss = 0.06171069471054666
Trained batch 399 in epoch 11, gen_loss = 0.38827858578413726, disc_loss = 0.061609419643937145
Trained batch 400 in epoch 11, gen_loss = 0.38831072194766525, disc_loss = 0.061519974117176586
Trained batch 401 in epoch 11, gen_loss = 0.38822103150893206, disc_loss = 0.0614935057877739
Trained batch 402 in epoch 11, gen_loss = 0.38824275701720423, disc_loss = 0.06138417902997655
Trained batch 403 in epoch 11, gen_loss = 0.3883155690930267, disc_loss = 0.06136759137187273
Trained batch 404 in epoch 11, gen_loss = 0.388237640555994, disc_loss = 0.061309016099556086
Trained batch 405 in epoch 11, gen_loss = 0.3880254843185101, disc_loss = 0.0615152484852605
Trained batch 406 in epoch 11, gen_loss = 0.3879505074068135, disc_loss = 0.062238430232782124
Trained batch 407 in epoch 11, gen_loss = 0.38786437234603893, disc_loss = 0.06311354831725076
Trained batch 408 in epoch 11, gen_loss = 0.38799556182619993, disc_loss = 0.06327504741083739
Trained batch 409 in epoch 11, gen_loss = 0.3878628185972935, disc_loss = 0.0635034394510113
Trained batch 410 in epoch 11, gen_loss = 0.3877308617035548, disc_loss = 0.06389109088689171
Trained batch 411 in epoch 11, gen_loss = 0.38760753796951286, disc_loss = 0.06441868912090674
Trained batch 412 in epoch 11, gen_loss = 0.38775332986442573, disc_loss = 0.06452398173444505
Trained batch 413 in epoch 11, gen_loss = 0.3877221406010038, disc_loss = 0.0647314858708895
Trained batch 414 in epoch 11, gen_loss = 0.3880538402910692, disc_loss = 0.06499502595923616
Trained batch 415 in epoch 11, gen_loss = 0.38797828830921877, disc_loss = 0.06488573134237623
Trained batch 416 in epoch 11, gen_loss = 0.387885730293729, disc_loss = 0.06501301755370434
Trained batch 417 in epoch 11, gen_loss = 0.38807884667906467, disc_loss = 0.06495978069546271
Trained batch 418 in epoch 11, gen_loss = 0.38798035396738667, disc_loss = 0.06488630451569845
Trained batch 419 in epoch 11, gen_loss = 0.38794660408582005, disc_loss = 0.06481094618821295
Trained batch 420 in epoch 11, gen_loss = 0.3876960486032051, disc_loss = 0.06522683310294812
Trained batch 421 in epoch 11, gen_loss = 0.38782135842112003, disc_loss = 0.06529054285266538
Trained batch 422 in epoch 11, gen_loss = 0.3880660205234027, disc_loss = 0.06599843149248458
Trained batch 423 in epoch 11, gen_loss = 0.38788668561797096, disc_loss = 0.06633382135445366
Trained batch 424 in epoch 11, gen_loss = 0.38787970209822936, disc_loss = 0.0664870306972743
Trained batch 425 in epoch 11, gen_loss = 0.38784692338514776, disc_loss = 0.06637003075057081
Trained batch 426 in epoch 11, gen_loss = 0.3879008628515226, disc_loss = 0.06625918313709309
Trained batch 427 in epoch 11, gen_loss = 0.3879448733527527, disc_loss = 0.06614736437924841
Trained batch 428 in epoch 11, gen_loss = 0.38799781631895436, disc_loss = 0.06603054931014993
Trained batch 429 in epoch 11, gen_loss = 0.38788521681414095, disc_loss = 0.06592457957571199
Trained batch 430 in epoch 11, gen_loss = 0.38795810927509433, disc_loss = 0.06581525349791817
Trained batch 431 in epoch 11, gen_loss = 0.38799493480473757, disc_loss = 0.06575767851905699
Trained batch 432 in epoch 11, gen_loss = 0.3879652363667587, disc_loss = 0.06570743216985651
Trained batch 433 in epoch 11, gen_loss = 0.3878066305259955, disc_loss = 0.06579707820351506
Trained batch 434 in epoch 11, gen_loss = 0.38779511242762377, disc_loss = 0.06589489438672733
Trained batch 435 in epoch 11, gen_loss = 0.38782326948888807, disc_loss = 0.06589546779073442
Trained batch 436 in epoch 11, gen_loss = 0.38795258432149343, disc_loss = 0.0659182059402243
Trained batch 437 in epoch 11, gen_loss = 0.38784831888191235, disc_loss = 0.06596243937662484
Trained batch 438 in epoch 11, gen_loss = 0.3879859447818682, disc_loss = 0.06625838348549708
Trained batch 439 in epoch 11, gen_loss = 0.38799441771751103, disc_loss = 0.06627820545558775
Trained batch 440 in epoch 11, gen_loss = 0.3880772329444518, disc_loss = 0.06631083521160958
Trained batch 441 in epoch 11, gen_loss = 0.38812929658193934, disc_loss = 0.06628258305425835
Trained batch 442 in epoch 11, gen_loss = 0.3881251126796882, disc_loss = 0.06636021637676272
Trained batch 443 in epoch 11, gen_loss = 0.38823961684698455, disc_loss = 0.06670390146596751
Trained batch 444 in epoch 11, gen_loss = 0.3880009100343404, disc_loss = 0.0676003133640049
Trained batch 445 in epoch 11, gen_loss = 0.38783575751455374, disc_loss = 0.06779038441610719
Trained batch 446 in epoch 11, gen_loss = 0.38790798803970583, disc_loss = 0.0679900613199332
Trained batch 447 in epoch 11, gen_loss = 0.3881047900566565, disc_loss = 0.06815320755543196
Trained batch 448 in epoch 11, gen_loss = 0.3880880614763379, disc_loss = 0.06811253208680522
Trained batch 449 in epoch 11, gen_loss = 0.38787705961200925, disc_loss = 0.06810437265292017
Trained batch 450 in epoch 11, gen_loss = 0.38805108968408036, disc_loss = 0.06810385229901314
Trained batch 451 in epoch 11, gen_loss = 0.3879475441588237, disc_loss = 0.06806316065104406
Trained batch 452 in epoch 11, gen_loss = 0.38795510141660045, disc_loss = 0.06798220836124681
Trained batch 453 in epoch 11, gen_loss = 0.38795594657701543, disc_loss = 0.06805342590843537
Trained batch 454 in epoch 11, gen_loss = 0.3876923941321425, disc_loss = 0.06825973359525081
Trained batch 455 in epoch 11, gen_loss = 0.3880003395637399, disc_loss = 0.06869446611151368
Trained batch 456 in epoch 11, gen_loss = 0.3880897277489272, disc_loss = 0.06855836678199527
Trained batch 457 in epoch 11, gen_loss = 0.3880387012029319, disc_loss = 0.0684371048823003
Trained batch 458 in epoch 11, gen_loss = 0.38832335206548113, disc_loss = 0.06836635697341863
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.3704046607017517, disc_loss = 0.052212223410606384
Trained batch 1 in epoch 12, gen_loss = 0.39802223443984985, disc_loss = 0.02870040573179722
Trained batch 2 in epoch 12, gen_loss = 0.38494986295700073, disc_loss = 0.0235247357438008
Trained batch 3 in epoch 12, gen_loss = 0.3895084708929062, disc_loss = 0.029782363679260015
Trained batch 4 in epoch 12, gen_loss = 0.3841480851173401, disc_loss = 0.03171338848769665
Trained batch 5 in epoch 12, gen_loss = 0.38963744541009265, disc_loss = 0.034333151144286
Trained batch 6 in epoch 12, gen_loss = 0.38685283064842224, disc_loss = 0.04252417092876775
Trained batch 7 in epoch 12, gen_loss = 0.3943038769066334, disc_loss = 0.04149852762930095
Trained batch 8 in epoch 12, gen_loss = 0.3991997010178036, disc_loss = 0.04268529742128319
Trained batch 9 in epoch 12, gen_loss = 0.40233211815357206, disc_loss = 0.04690606277436018
Trained batch 10 in epoch 12, gen_loss = 0.39620287309993396, disc_loss = 0.045470606366341766
Trained batch 11 in epoch 12, gen_loss = 0.3974330772956212, disc_loss = 0.04337845494349798
Trained batch 12 in epoch 12, gen_loss = 0.4007462033858666, disc_loss = 0.049540387896391064
Trained batch 13 in epoch 12, gen_loss = 0.39520334345953806, disc_loss = 0.06481189919369561
Trained batch 14 in epoch 12, gen_loss = 0.39574882984161375, disc_loss = 0.08833005130290986
Trained batch 15 in epoch 12, gen_loss = 0.39243365824222565, disc_loss = 0.0861787514295429
Trained batch 16 in epoch 12, gen_loss = 0.39304528692189383, disc_loss = 0.08322314041502335
Trained batch 17 in epoch 12, gen_loss = 0.3860896991358863, disc_loss = 0.08478635301192601
Trained batch 18 in epoch 12, gen_loss = 0.38600681016319677, disc_loss = 0.08261244547994513
Trained batch 19 in epoch 12, gen_loss = 0.38124892115592957, disc_loss = 0.08147781118750572
Trained batch 20 in epoch 12, gen_loss = 0.3784864090737842, disc_loss = 0.08018386275285766
Trained batch 21 in epoch 12, gen_loss = 0.3819687203927474, disc_loss = 0.07851942002095959
Trained batch 22 in epoch 12, gen_loss = 0.3792038857936859, disc_loss = 0.08135176466211029
Trained batch 23 in epoch 12, gen_loss = 0.3801068936785062, disc_loss = 0.08804685855284333
Trained batch 24 in epoch 12, gen_loss = 0.3767461121082306, disc_loss = 0.09042579397559165
Trained batch 25 in epoch 12, gen_loss = 0.3760977123792355, disc_loss = 0.08915449292040788
Trained batch 26 in epoch 12, gen_loss = 0.37828577116683676, disc_loss = 0.08627125213819521
Trained batch 27 in epoch 12, gen_loss = 0.3785517045429775, disc_loss = 0.08466455692957554
Trained batch 28 in epoch 12, gen_loss = 0.37918744827138967, disc_loss = 0.08259440162058534
Trained batch 29 in epoch 12, gen_loss = 0.3811689535776774, disc_loss = 0.08171742347379525
Trained batch 30 in epoch 12, gen_loss = 0.3809644003068247, disc_loss = 0.08360586952297919
Trained batch 31 in epoch 12, gen_loss = 0.3864406682550907, disc_loss = 0.08988024981226772
Trained batch 32 in epoch 12, gen_loss = 0.3888509688955365, disc_loss = 0.08894117673238118
Trained batch 33 in epoch 12, gen_loss = 0.3902186015072991, disc_loss = 0.09387460613951963
Trained batch 34 in epoch 12, gen_loss = 0.3924833152975355, disc_loss = 0.09214759128434317
Trained batch 35 in epoch 12, gen_loss = 0.3921358312169711, disc_loss = 0.09260236451195346
Trained batch 36 in epoch 12, gen_loss = 0.390478370157448, disc_loss = 0.0907869700946518
Trained batch 37 in epoch 12, gen_loss = 0.3896082655379647, disc_loss = 0.08943184264200299
Trained batch 38 in epoch 12, gen_loss = 0.38972357985300893, disc_loss = 0.08796661313718711
Trained batch 39 in epoch 12, gen_loss = 0.38848228231072424, disc_loss = 0.08665047450922429
Trained batch 40 in epoch 12, gen_loss = 0.3902554948155473, disc_loss = 0.08716582883967132
Trained batch 41 in epoch 12, gen_loss = 0.38823842931361424, disc_loss = 0.08903139718763885
Trained batch 42 in epoch 12, gen_loss = 0.3884371144827022, disc_loss = 0.08961518468378588
Trained batch 43 in epoch 12, gen_loss = 0.38694922693751077, disc_loss = 0.09523340496657924
Trained batch 44 in epoch 12, gen_loss = 0.38633465303315057, disc_loss = 0.10007344662315315
Trained batch 45 in epoch 12, gen_loss = 0.38777210531027423, disc_loss = 0.10669224850995385
Trained batch 46 in epoch 12, gen_loss = 0.3891114801802534, disc_loss = 0.106281213581245
Trained batch 47 in epoch 12, gen_loss = 0.38826025649905205, disc_loss = 0.10662376581846426
Trained batch 48 in epoch 12, gen_loss = 0.38560658450029334, disc_loss = 0.10698337605869283
Trained batch 49 in epoch 12, gen_loss = 0.3850193464756012, disc_loss = 0.10735160406678915
Trained batch 50 in epoch 12, gen_loss = 0.3848358164815342, disc_loss = 0.10661311706929814
Trained batch 51 in epoch 12, gen_loss = 0.38278373732016635, disc_loss = 0.10584609206909171
Trained batch 52 in epoch 12, gen_loss = 0.3818346098908838, disc_loss = 0.10635404172792749
Trained batch 53 in epoch 12, gen_loss = 0.38204943637053174, disc_loss = 0.10704371026130738
Trained batch 54 in epoch 12, gen_loss = 0.3816258002411235, disc_loss = 0.10540980612012472
Trained batch 55 in epoch 12, gen_loss = 0.3824999470795904, disc_loss = 0.10542565793730319
Trained batch 56 in epoch 12, gen_loss = 0.3806430352361579, disc_loss = 0.10706958694285468
Trained batch 57 in epoch 12, gen_loss = 0.3803645819425583, disc_loss = 0.10876527065732355
Trained batch 58 in epoch 12, gen_loss = 0.3825526666843285, disc_loss = 0.10909294826373206
Trained batch 59 in epoch 12, gen_loss = 0.3832046166062355, disc_loss = 0.10770507774626216
Trained batch 60 in epoch 12, gen_loss = 0.3814324668196381, disc_loss = 0.1083509337889855
Trained batch 61 in epoch 12, gen_loss = 0.38245700492012885, disc_loss = 0.10897037624231269
Trained batch 62 in epoch 12, gen_loss = 0.3811038855522398, disc_loss = 0.10849160922779924
Trained batch 63 in epoch 12, gen_loss = 0.3815664043650031, disc_loss = 0.10757597940391861
Trained batch 64 in epoch 12, gen_loss = 0.3812376659650069, disc_loss = 0.10694011951295229
Trained batch 65 in epoch 12, gen_loss = 0.3811002495613965, disc_loss = 0.10989052280219215
Trained batch 66 in epoch 12, gen_loss = 0.3806465646224235, disc_loss = 0.11071695962837383
Trained batch 67 in epoch 12, gen_loss = 0.3796878658673343, disc_loss = 0.11030722932670922
Trained batch 68 in epoch 12, gen_loss = 0.37981223800907965, disc_loss = 0.1097727487862542
Trained batch 69 in epoch 12, gen_loss = 0.37977214327880315, disc_loss = 0.1105345264875463
Trained batch 70 in epoch 12, gen_loss = 0.3807865108402682, disc_loss = 0.10928735207818763
Trained batch 71 in epoch 12, gen_loss = 0.3791670902735657, disc_loss = 0.10826544367915227
Trained batch 72 in epoch 12, gen_loss = 0.37997307761074745, disc_loss = 0.1070553116143158
Trained batch 73 in epoch 12, gen_loss = 0.3783167197897628, disc_loss = 0.10694110884356338
Trained batch 74 in epoch 12, gen_loss = 0.37838441689809166, disc_loss = 0.11013315804302692
Trained batch 75 in epoch 12, gen_loss = 0.37779072632915095, disc_loss = 0.11094447036616896
Trained batch 76 in epoch 12, gen_loss = 0.378378369978496, disc_loss = 0.11070740752696216
Trained batch 77 in epoch 12, gen_loss = 0.37676667326535934, disc_loss = 0.11047391314059496
Trained batch 78 in epoch 12, gen_loss = 0.37614889386334, disc_loss = 0.10968370294740683
Trained batch 79 in epoch 12, gen_loss = 0.3767597209662199, disc_loss = 0.10850656726397574
Trained batch 80 in epoch 12, gen_loss = 0.37715510968808774, disc_loss = 0.10827209032428117
Trained batch 81 in epoch 12, gen_loss = 0.37644566740931534, disc_loss = 0.10782902319802017
Trained batch 82 in epoch 12, gen_loss = 0.3764182199914771, disc_loss = 0.10721864789185753
Trained batch 83 in epoch 12, gen_loss = 0.37657836079597473, disc_loss = 0.1086046521418861
Trained batch 84 in epoch 12, gen_loss = 0.3758797228336334, disc_loss = 0.10882434630218674
Trained batch 85 in epoch 12, gen_loss = 0.37608464963214344, disc_loss = 0.1077235925639438
Trained batch 86 in epoch 12, gen_loss = 0.37725237114676113, disc_loss = 0.10813074813748913
Trained batch 87 in epoch 12, gen_loss = 0.37594113702123816, disc_loss = 0.10758744296617806
Trained batch 88 in epoch 12, gen_loss = 0.3744414534126775, disc_loss = 0.10741439208472042
Trained batch 89 in epoch 12, gen_loss = 0.3749579540557332, disc_loss = 0.10639833569940593
Trained batch 90 in epoch 12, gen_loss = 0.3747186364380868, disc_loss = 0.10690607910382223
Trained batch 91 in epoch 12, gen_loss = 0.3739669836409714, disc_loss = 0.10967801715773733
Trained batch 92 in epoch 12, gen_loss = 0.3738613572492394, disc_loss = 0.10881763294098838
Trained batch 93 in epoch 12, gen_loss = 0.3748645508225928, disc_loss = 0.10912133481829091
Trained batch 94 in epoch 12, gen_loss = 0.37465653717517855, disc_loss = 0.10838858714621318
Trained batch 95 in epoch 12, gen_loss = 0.37553702713921666, disc_loss = 0.10790297553952162
Trained batch 96 in epoch 12, gen_loss = 0.37580392056519224, disc_loss = 0.10787105185853452
Trained batch 97 in epoch 12, gen_loss = 0.37580400233974265, disc_loss = 0.10740975566132337
Trained batch 98 in epoch 12, gen_loss = 0.3754669805668821, disc_loss = 0.108258299924659
Trained batch 99 in epoch 12, gen_loss = 0.3750409273803234, disc_loss = 0.10880989955738186
Trained batch 100 in epoch 12, gen_loss = 0.3767255944485712, disc_loss = 0.10848988063338369
Trained batch 101 in epoch 12, gen_loss = 0.37709490501997517, disc_loss = 0.10765489066640536
Trained batch 102 in epoch 12, gen_loss = 0.37677318971712614, disc_loss = 0.10714134884980119
Trained batch 103 in epoch 12, gen_loss = 0.3769730113160152, disc_loss = 0.10692075833391684
Trained batch 104 in epoch 12, gen_loss = 0.3771403881765547, disc_loss = 0.10819056395973478
Trained batch 105 in epoch 12, gen_loss = 0.37692238657541993, disc_loss = 0.10963937942430659
Trained batch 106 in epoch 12, gen_loss = 0.37702835288560277, disc_loss = 0.10967464132286678
Trained batch 107 in epoch 12, gen_loss = 0.37668090161901935, disc_loss = 0.10871164718021949
Trained batch 108 in epoch 12, gen_loss = 0.3763390463699988, disc_loss = 0.10804825874233465
Trained batch 109 in epoch 12, gen_loss = 0.37662708610296247, disc_loss = 0.10751510069451549
Trained batch 110 in epoch 12, gen_loss = 0.37634880303799567, disc_loss = 0.10699136132324064
Trained batch 111 in epoch 12, gen_loss = 0.37717115732708145, disc_loss = 0.10879620397463441
Trained batch 112 in epoch 12, gen_loss = 0.3770083018900019, disc_loss = 0.11001043819484457
Trained batch 113 in epoch 12, gen_loss = 0.3776597541413809, disc_loss = 0.10908938535047989
Trained batch 114 in epoch 12, gen_loss = 0.37801840240540713, disc_loss = 0.10869470824204061
Trained batch 115 in epoch 12, gen_loss = 0.37838923558592796, disc_loss = 0.10813116207558277
Trained batch 116 in epoch 12, gen_loss = 0.3784610831584686, disc_loss = 0.10795626396902351
Trained batch 117 in epoch 12, gen_loss = 0.37884850560103434, disc_loss = 0.10871976534283515
Trained batch 118 in epoch 12, gen_loss = 0.3782560278137191, disc_loss = 0.10815998403934621
Trained batch 119 in epoch 12, gen_loss = 0.3778275749335686, disc_loss = 0.10750523472670466
Trained batch 120 in epoch 12, gen_loss = 0.378376865559373, disc_loss = 0.10665328833774841
Trained batch 121 in epoch 12, gen_loss = 0.3786325458376134, disc_loss = 0.10601452776978983
Trained batch 122 in epoch 12, gen_loss = 0.37880782225752263, disc_loss = 0.10543656896618081
Trained batch 123 in epoch 12, gen_loss = 0.37880703434348106, disc_loss = 0.10531764738111486
Trained batch 124 in epoch 12, gen_loss = 0.37947240364551543, disc_loss = 0.10643780490010976
Trained batch 125 in epoch 12, gen_loss = 0.3794371167582179, disc_loss = 0.10727642271815548
Trained batch 126 in epoch 12, gen_loss = 0.3794260143529712, disc_loss = 0.1068706492724733
Trained batch 127 in epoch 12, gen_loss = 0.37989958247635514, disc_loss = 0.10635731217189459
Trained batch 128 in epoch 12, gen_loss = 0.3805640777645185, disc_loss = 0.10621245499238256
Trained batch 129 in epoch 12, gen_loss = 0.38008833539027437, disc_loss = 0.10633202165795061
Trained batch 130 in epoch 12, gen_loss = 0.38025387473233785, disc_loss = 0.1065873530344995
Trained batch 131 in epoch 12, gen_loss = 0.38011074619311275, disc_loss = 0.10643383509931013
Trained batch 132 in epoch 12, gen_loss = 0.3801490690251042, disc_loss = 0.1058677756822759
Trained batch 133 in epoch 12, gen_loss = 0.3803558074938717, disc_loss = 0.10575687532910882
Trained batch 134 in epoch 12, gen_loss = 0.3797152703558957, disc_loss = 0.10752759800051097
Trained batch 135 in epoch 12, gen_loss = 0.3805478049770874, disc_loss = 0.10707999421420562
Trained batch 136 in epoch 12, gen_loss = 0.37997104227542877, disc_loss = 0.10709808707699506
Trained batch 137 in epoch 12, gen_loss = 0.38067813638759695, disc_loss = 0.10689929819436393
Trained batch 138 in epoch 12, gen_loss = 0.38071350431699547, disc_loss = 0.10655693029783828
Trained batch 139 in epoch 12, gen_loss = 0.3806612130786691, disc_loss = 0.10625697103595096
Trained batch 140 in epoch 12, gen_loss = 0.38030511320482757, disc_loss = 0.10616380764263952
Trained batch 141 in epoch 12, gen_loss = 0.3808217020311826, disc_loss = 0.10642097696898059
Trained batch 142 in epoch 12, gen_loss = 0.38032321235933503, disc_loss = 0.10719872350068567
Trained batch 143 in epoch 12, gen_loss = 0.3810574680359827, disc_loss = 0.10734180356505224
Trained batch 144 in epoch 12, gen_loss = 0.3817741594437895, disc_loss = 0.10678242908084187
Trained batch 145 in epoch 12, gen_loss = 0.3821117807536909, disc_loss = 0.1060914705277816
Trained batch 146 in epoch 12, gen_loss = 0.38254034448237645, disc_loss = 0.10551598269593757
Trained batch 147 in epoch 12, gen_loss = 0.38259070195459033, disc_loss = 0.10492694513192652
Trained batch 148 in epoch 12, gen_loss = 0.3827435959305539, disc_loss = 0.10442177639436602
Trained batch 149 in epoch 12, gen_loss = 0.38219686339298886, disc_loss = 0.10395111484453082
Trained batch 150 in epoch 12, gen_loss = 0.38235161645917703, disc_loss = 0.1033949169163771
Trained batch 151 in epoch 12, gen_loss = 0.38245228825038985, disc_loss = 0.10385522943014573
Trained batch 152 in epoch 12, gen_loss = 0.38180937028788275, disc_loss = 0.10596374758927066
Trained batch 153 in epoch 12, gen_loss = 0.3818420488145444, disc_loss = 0.10626293051770175
Trained batch 154 in epoch 12, gen_loss = 0.3822918310280769, disc_loss = 0.10587206704602126
Trained batch 155 in epoch 12, gen_loss = 0.3822539784014225, disc_loss = 0.10572142307407772
Trained batch 156 in epoch 12, gen_loss = 0.3816875191820655, disc_loss = 0.10613186809880908
Trained batch 157 in epoch 12, gen_loss = 0.38227259744948977, disc_loss = 0.10659555186034192
Trained batch 158 in epoch 12, gen_loss = 0.3824251296947587, disc_loss = 0.10663776756293557
Trained batch 159 in epoch 12, gen_loss = 0.38184667928144334, disc_loss = 0.10739757652045227
Trained batch 160 in epoch 12, gen_loss = 0.382067412230539, disc_loss = 0.10796110230781462
Trained batch 161 in epoch 12, gen_loss = 0.3820036014105067, disc_loss = 0.10757251440857847
Trained batch 162 in epoch 12, gen_loss = 0.38194284656662153, disc_loss = 0.10741010987616938
Trained batch 163 in epoch 12, gen_loss = 0.3820912597201219, disc_loss = 0.1071555527529066
Trained batch 164 in epoch 12, gen_loss = 0.38231061128052796, disc_loss = 0.10664671342819929
Trained batch 165 in epoch 12, gen_loss = 0.3818069706300655, disc_loss = 0.10664707996198032
Trained batch 166 in epoch 12, gen_loss = 0.38182423080869776, disc_loss = 0.10718395796877717
Trained batch 167 in epoch 12, gen_loss = 0.38164992071688175, disc_loss = 0.10728756080581141
Trained batch 168 in epoch 12, gen_loss = 0.38216926527799233, disc_loss = 0.10708434817507952
Trained batch 169 in epoch 12, gen_loss = 0.381909380151945, disc_loss = 0.10700135445222259
Trained batch 170 in epoch 12, gen_loss = 0.38225934353836794, disc_loss = 0.10699355209583951
Trained batch 171 in epoch 12, gen_loss = 0.38193136756849844, disc_loss = 0.10702568322398462
Trained batch 172 in epoch 12, gen_loss = 0.38242516378102276, disc_loss = 0.1069235728429146
Trained batch 173 in epoch 12, gen_loss = 0.3822952105567373, disc_loss = 0.10676090444448864
Trained batch 174 in epoch 12, gen_loss = 0.382346653342247, disc_loss = 0.10619309199707849
Trained batch 175 in epoch 12, gen_loss = 0.38281045185232704, disc_loss = 0.10570499958174134
Trained batch 176 in epoch 12, gen_loss = 0.3825665083477053, disc_loss = 0.10549446154322664
Trained batch 177 in epoch 12, gen_loss = 0.38271500898546046, disc_loss = 0.10613657330068645
Trained batch 178 in epoch 12, gen_loss = 0.38262888198125294, disc_loss = 0.10673175607521773
Trained batch 179 in epoch 12, gen_loss = 0.38325681479440793, disc_loss = 0.10656329448231393
Trained batch 180 in epoch 12, gen_loss = 0.3831009360143493, disc_loss = 0.10615563249596245
Trained batch 181 in epoch 12, gen_loss = 0.3832298139785672, disc_loss = 0.10609539296314284
Trained batch 182 in epoch 12, gen_loss = 0.38351302272309373, disc_loss = 0.10625814382862198
Trained batch 183 in epoch 12, gen_loss = 0.383278499883802, disc_loss = 0.10663323348347584
Trained batch 184 in epoch 12, gen_loss = 0.3836795177814123, disc_loss = 0.1064293844575012
Trained batch 185 in epoch 12, gen_loss = 0.38406417422717615, disc_loss = 0.10587696459454794
Trained batch 186 in epoch 12, gen_loss = 0.3841936367558923, disc_loss = 0.10540629513711136
Trained batch 187 in epoch 12, gen_loss = 0.384439053766905, disc_loss = 0.10498706910987088
Trained batch 188 in epoch 12, gen_loss = 0.384502237514844, disc_loss = 0.10528358061940818
Trained batch 189 in epoch 12, gen_loss = 0.3843635476733509, disc_loss = 0.10748388502305668
Trained batch 190 in epoch 12, gen_loss = 0.3839396271874143, disc_loss = 0.10792951217330797
Trained batch 191 in epoch 12, gen_loss = 0.3841852745196472, disc_loss = 0.10824038330611074
Trained batch 192 in epoch 12, gen_loss = 0.38387478579202466, disc_loss = 0.10849431197405093
Trained batch 193 in epoch 12, gen_loss = 0.3838676365534055, disc_loss = 0.10895294928203154
Trained batch 194 in epoch 12, gen_loss = 0.38377771767286156, disc_loss = 0.10888137528672814
Trained batch 195 in epoch 12, gen_loss = 0.38349062941816386, disc_loss = 0.1087664392163825
Trained batch 196 in epoch 12, gen_loss = 0.3837089575638021, disc_loss = 0.10839002690783839
Trained batch 197 in epoch 12, gen_loss = 0.38377357123777117, disc_loss = 0.10797058041866003
Trained batch 198 in epoch 12, gen_loss = 0.38382469147593534, disc_loss = 0.10757477594371043
Trained batch 199 in epoch 12, gen_loss = 0.3836108557134867, disc_loss = 0.10807898064842447
Trained batch 200 in epoch 12, gen_loss = 0.38431968210051903, disc_loss = 0.10892496259642107
Trained batch 201 in epoch 12, gen_loss = 0.38433895702704346, disc_loss = 0.10843556937946025
Trained batch 202 in epoch 12, gen_loss = 0.3844927188944934, disc_loss = 0.10799009574283594
Trained batch 203 in epoch 12, gen_loss = 0.3847735484002852, disc_loss = 0.10763953243811414
Trained batch 204 in epoch 12, gen_loss = 0.38504627412412223, disc_loss = 0.10714460045053828
Trained batch 205 in epoch 12, gen_loss = 0.38565988064680284, disc_loss = 0.10675438946266703
Trained batch 206 in epoch 12, gen_loss = 0.3855006096587665, disc_loss = 0.10639941171126593
Trained batch 207 in epoch 12, gen_loss = 0.385630682325707, disc_loss = 0.10594279887020373
Trained batch 208 in epoch 12, gen_loss = 0.3858925070631447, disc_loss = 0.10550997020569786
Trained batch 209 in epoch 12, gen_loss = 0.38604725975365867, disc_loss = 0.10514704454024988
Trained batch 210 in epoch 12, gen_loss = 0.3865714840838129, disc_loss = 0.10471990920153063
Trained batch 211 in epoch 12, gen_loss = 0.3868220936999006, disc_loss = 0.10431976887212961
Trained batch 212 in epoch 12, gen_loss = 0.38691559063157005, disc_loss = 0.10420095238685957
Trained batch 213 in epoch 12, gen_loss = 0.3866291644277974, disc_loss = 0.1046784790689735
Trained batch 214 in epoch 12, gen_loss = 0.3869711306899093, disc_loss = 0.10544948456808925
Trained batch 215 in epoch 12, gen_loss = 0.3868372715595696, disc_loss = 0.1053641150830555
Trained batch 216 in epoch 12, gen_loss = 0.38663356843906616, disc_loss = 0.1064355277954193
Trained batch 217 in epoch 12, gen_loss = 0.38658687164750666, disc_loss = 0.1061058819930522
Trained batch 218 in epoch 12, gen_loss = 0.386757144032548, disc_loss = 0.10583512395084517
Trained batch 219 in epoch 12, gen_loss = 0.38659620901400393, disc_loss = 0.10556120600085706
Trained batch 220 in epoch 12, gen_loss = 0.38659459480602815, disc_loss = 0.10563360652106717
Trained batch 221 in epoch 12, gen_loss = 0.3866156305412988, disc_loss = 0.1058350044180983
Trained batch 222 in epoch 12, gen_loss = 0.38627461754954984, disc_loss = 0.10622544097400902
Trained batch 223 in epoch 12, gen_loss = 0.38633003065894755, disc_loss = 0.10650004910712596
Trained batch 224 in epoch 12, gen_loss = 0.3865885809395048, disc_loss = 0.10782828581208984
Trained batch 225 in epoch 12, gen_loss = 0.3867535995303002, disc_loss = 0.10750617865118635
Trained batch 226 in epoch 12, gen_loss = 0.38679062906603456, disc_loss = 0.1074196434382858
Trained batch 227 in epoch 12, gen_loss = 0.3865234940067718, disc_loss = 0.10721856346067957
Trained batch 228 in epoch 12, gen_loss = 0.3864144928200276, disc_loss = 0.10698353878413551
Trained batch 229 in epoch 12, gen_loss = 0.38687638906033145, disc_loss = 0.1073226154356709
Trained batch 230 in epoch 12, gen_loss = 0.3868796770577823, disc_loss = 0.10709326087146417
Trained batch 231 in epoch 12, gen_loss = 0.38692640378300486, disc_loss = 0.10676568197608315
Trained batch 232 in epoch 12, gen_loss = 0.38677069193048025, disc_loss = 0.10653255408421926
Trained batch 233 in epoch 12, gen_loss = 0.38658988507639647, disc_loss = 0.1063703522265244
Trained batch 234 in epoch 12, gen_loss = 0.38650403168607267, disc_loss = 0.1061459358880653
Trained batch 235 in epoch 12, gen_loss = 0.38684225606463724, disc_loss = 0.10580143432125007
Trained batch 236 in epoch 12, gen_loss = 0.38676227264514956, disc_loss = 0.10545100296262007
Trained batch 237 in epoch 12, gen_loss = 0.3866749551742017, disc_loss = 0.10563077714427241
Trained batch 238 in epoch 12, gen_loss = 0.386830083807642, disc_loss = 0.10666688758622715
Trained batch 239 in epoch 12, gen_loss = 0.3868669126803676, disc_loss = 0.10630809678890121
Trained batch 240 in epoch 12, gen_loss = 0.38675634142521503, disc_loss = 0.10638311803843285
Trained batch 241 in epoch 12, gen_loss = 0.38662139843564386, disc_loss = 0.10607564604979716
Trained batch 242 in epoch 12, gen_loss = 0.38628309308992004, disc_loss = 0.10586040714035125
Trained batch 243 in epoch 12, gen_loss = 0.3864545379383642, disc_loss = 0.10546968145425752
Trained batch 244 in epoch 12, gen_loss = 0.386452195778185, disc_loss = 0.10509374637194738
Trained batch 245 in epoch 12, gen_loss = 0.386391805984625, disc_loss = 0.10486554626822168
Trained batch 246 in epoch 12, gen_loss = 0.38672461424037996, disc_loss = 0.10556922388274359
Trained batch 247 in epoch 12, gen_loss = 0.38653007576302173, disc_loss = 0.10672822558403676
Trained batch 248 in epoch 12, gen_loss = 0.38633382146856393, disc_loss = 0.10709858921928758
Trained batch 249 in epoch 12, gen_loss = 0.38619973307847977, disc_loss = 0.10683456139080226
Trained batch 250 in epoch 12, gen_loss = 0.3863146887476226, disc_loss = 0.10655499812015203
Trained batch 251 in epoch 12, gen_loss = 0.38635553259934696, disc_loss = 0.10636922710996476
Trained batch 252 in epoch 12, gen_loss = 0.38657392290505493, disc_loss = 0.10646943064597933
Trained batch 253 in epoch 12, gen_loss = 0.3863295162404616, disc_loss = 0.10657170878202603
Trained batch 254 in epoch 12, gen_loss = 0.3867535693388359, disc_loss = 0.10640568467149256
Trained batch 255 in epoch 12, gen_loss = 0.3867584075196646, disc_loss = 0.10612681502061605
Trained batch 256 in epoch 12, gen_loss = 0.38684114738429104, disc_loss = 0.10578705496354036
Trained batch 257 in epoch 12, gen_loss = 0.3869115579151368, disc_loss = 0.10597448159088634
Trained batch 258 in epoch 12, gen_loss = 0.3868382329761292, disc_loss = 0.10676837523924511
Trained batch 259 in epoch 12, gen_loss = 0.3866690682104001, disc_loss = 0.10646863595331804
Trained batch 260 in epoch 12, gen_loss = 0.38668030060799186, disc_loss = 0.10621680410478936
Trained batch 261 in epoch 12, gen_loss = 0.3865358518393895, disc_loss = 0.10602721426714183
Trained batch 262 in epoch 12, gen_loss = 0.38632319153714995, disc_loss = 0.10585043644320093
Trained batch 263 in epoch 12, gen_loss = 0.3864770257901965, disc_loss = 0.10549472380874002
Trained batch 264 in epoch 12, gen_loss = 0.3862850772322349, disc_loss = 0.10537807624962814
Trained batch 265 in epoch 12, gen_loss = 0.3863493573284687, disc_loss = 0.10515257809836333
Trained batch 266 in epoch 12, gen_loss = 0.38607047710302617, disc_loss = 0.10497402624237571
Trained batch 267 in epoch 12, gen_loss = 0.38633567511812966, disc_loss = 0.10471833345598416
Trained batch 268 in epoch 12, gen_loss = 0.38608019951329353, disc_loss = 0.10452108245626868
Trained batch 269 in epoch 12, gen_loss = 0.3863822109721325, disc_loss = 0.1050669129230772
Trained batch 270 in epoch 12, gen_loss = 0.38644875157143355, disc_loss = 0.10558859393433616
Trained batch 271 in epoch 12, gen_loss = 0.3863960150081445, disc_loss = 0.10542711656479001
Trained batch 272 in epoch 12, gen_loss = 0.3866071064066101, disc_loss = 0.10530773189853564
Trained batch 273 in epoch 12, gen_loss = 0.3866304505589235, disc_loss = 0.10535255588257998
Trained batch 274 in epoch 12, gen_loss = 0.386892644979737, disc_loss = 0.1054253728535365
Trained batch 275 in epoch 12, gen_loss = 0.38647469700030657, disc_loss = 0.10572572017216758
Trained batch 276 in epoch 12, gen_loss = 0.38661159585744465, disc_loss = 0.10594412208188474
Trained batch 277 in epoch 12, gen_loss = 0.38673479860420706, disc_loss = 0.10561697807317104
Trained batch 278 in epoch 12, gen_loss = 0.3864909110851185, disc_loss = 0.10528305535268132
Trained batch 279 in epoch 12, gen_loss = 0.3862612318247557, disc_loss = 0.10528984670360972
Trained batch 280 in epoch 12, gen_loss = 0.3864952167264083, disc_loss = 0.10518964392454545
Trained batch 281 in epoch 12, gen_loss = 0.386514349979289, disc_loss = 0.10518577646510345
Trained batch 282 in epoch 12, gen_loss = 0.3864369191782213, disc_loss = 0.10607426699626098
Trained batch 283 in epoch 12, gen_loss = 0.3870377947222179, disc_loss = 0.10607355491186059
Trained batch 284 in epoch 12, gen_loss = 0.3874264672659991, disc_loss = 0.1058985732021954
Trained batch 285 in epoch 12, gen_loss = 0.38711939507222676, disc_loss = 0.10618489297347834
Trained batch 286 in epoch 12, gen_loss = 0.38728569126087614, disc_loss = 0.10612017016708591
Trained batch 287 in epoch 12, gen_loss = 0.3873646144962145, disc_loss = 0.10604719464996985
Trained batch 288 in epoch 12, gen_loss = 0.3873849667376713, disc_loss = 0.10594957251469105
Trained batch 289 in epoch 12, gen_loss = 0.38743304697604014, disc_loss = 0.1058605330691127
Trained batch 290 in epoch 12, gen_loss = 0.38739386574714046, disc_loss = 0.10590980782355998
Trained batch 291 in epoch 12, gen_loss = 0.3870754501693053, disc_loss = 0.10622078133587509
Trained batch 292 in epoch 12, gen_loss = 0.38727955133638287, disc_loss = 0.10625866097922568
Trained batch 293 in epoch 12, gen_loss = 0.3872208015955224, disc_loss = 0.10610931324075629
Trained batch 294 in epoch 12, gen_loss = 0.38731235775907163, disc_loss = 0.10585988540739073
Trained batch 295 in epoch 12, gen_loss = 0.3876305001510962, disc_loss = 0.10574872983537766
Trained batch 296 in epoch 12, gen_loss = 0.38766599910628513, disc_loss = 0.10577444283617818
Trained batch 297 in epoch 12, gen_loss = 0.3876652889103697, disc_loss = 0.10552687292149752
Trained batch 298 in epoch 12, gen_loss = 0.38762587503246637, disc_loss = 0.10538137886505013
Trained batch 299 in epoch 12, gen_loss = 0.3876499854028225, disc_loss = 0.10590225210258117
Trained batch 300 in epoch 12, gen_loss = 0.38744147527851536, disc_loss = 0.10675752143595256
Trained batch 301 in epoch 12, gen_loss = 0.3874322117263118, disc_loss = 0.10667989825342615
Trained batch 302 in epoch 12, gen_loss = 0.3873595874203314, disc_loss = 0.10637061511052667
Trained batch 303 in epoch 12, gen_loss = 0.3875307583397156, disc_loss = 0.1060605272941757
Trained batch 304 in epoch 12, gen_loss = 0.3875006078208079, disc_loss = 0.10595913757035723
Trained batch 305 in epoch 12, gen_loss = 0.3876912866055576, disc_loss = 0.1059984087356628
Trained batch 306 in epoch 12, gen_loss = 0.38767534130365144, disc_loss = 0.10597450480756959
Trained batch 307 in epoch 12, gen_loss = 0.38760935529679447, disc_loss = 0.10570955644029059
Trained batch 308 in epoch 12, gen_loss = 0.3872347951996288, disc_loss = 0.10587961089113143
Trained batch 309 in epoch 12, gen_loss = 0.3871015921235085, disc_loss = 0.10622257147915662
Trained batch 310 in epoch 12, gen_loss = 0.38689036121130754, disc_loss = 0.10684422127920476
Trained batch 311 in epoch 12, gen_loss = 0.38668328098570687, disc_loss = 0.10676859830094215
Trained batch 312 in epoch 12, gen_loss = 0.38684031019766874, disc_loss = 0.10672888083431048
Trained batch 313 in epoch 12, gen_loss = 0.3867074161483224, disc_loss = 0.10667999392333825
Trained batch 314 in epoch 12, gen_loss = 0.3865226641060814, disc_loss = 0.106881488739912
Trained batch 315 in epoch 12, gen_loss = 0.3865882203077214, disc_loss = 0.10680078137282847
Trained batch 316 in epoch 12, gen_loss = 0.3865586322282767, disc_loss = 0.10658811184222154
Trained batch 317 in epoch 12, gen_loss = 0.38664601682304583, disc_loss = 0.106305338405717
Trained batch 318 in epoch 12, gen_loss = 0.3865530638952614, disc_loss = 0.10622405918128204
Trained batch 319 in epoch 12, gen_loss = 0.3866306581068784, disc_loss = 0.10614706304477295
Trained batch 320 in epoch 12, gen_loss = 0.38617938422711096, disc_loss = 0.10631986067853752
Trained batch 321 in epoch 12, gen_loss = 0.38662209477483855, disc_loss = 0.1065671179567967
Trained batch 322 in epoch 12, gen_loss = 0.386749535614492, disc_loss = 0.10652676627080276
Trained batch 323 in epoch 12, gen_loss = 0.3866680497188627, disc_loss = 0.10641287321104081
Trained batch 324 in epoch 12, gen_loss = 0.38667152267235977, disc_loss = 0.10648727466137363
Trained batch 325 in epoch 12, gen_loss = 0.3867788813048345, disc_loss = 0.1072342174879041
Trained batch 326 in epoch 12, gen_loss = 0.3868637854170726, disc_loss = 0.10720205333066779
Trained batch 327 in epoch 12, gen_loss = 0.38674534412055483, disc_loss = 0.10695267245940092
Trained batch 328 in epoch 12, gen_loss = 0.3868990616595491, disc_loss = 0.10689334152266383
Trained batch 329 in epoch 12, gen_loss = 0.3871815386143598, disc_loss = 0.10714869794830906
Trained batch 330 in epoch 12, gen_loss = 0.38705124064514645, disc_loss = 0.1070200960922795
Trained batch 331 in epoch 12, gen_loss = 0.3869734146149762, disc_loss = 0.10694471926074924
Trained batch 332 in epoch 12, gen_loss = 0.38718912184417426, disc_loss = 0.10688326769444095
Trained batch 333 in epoch 12, gen_loss = 0.38719090542750445, disc_loss = 0.10681900303827566
Trained batch 334 in epoch 12, gen_loss = 0.38732949655447435, disc_loss = 0.10666019951980284
Trained batch 335 in epoch 12, gen_loss = 0.38752940492261023, disc_loss = 0.10646175475475113
Trained batch 336 in epoch 12, gen_loss = 0.38742769109389197, disc_loss = 0.10622725150346181
Trained batch 337 in epoch 12, gen_loss = 0.3870810515429141, disc_loss = 0.1064574789330253
Trained batch 338 in epoch 12, gen_loss = 0.3872902394220189, disc_loss = 0.10704479090578217
Trained batch 339 in epoch 12, gen_loss = 0.3873024915947634, disc_loss = 0.10699919769951306
Trained batch 340 in epoch 12, gen_loss = 0.38728461010365195, disc_loss = 0.10709732077070826
Trained batch 341 in epoch 12, gen_loss = 0.3871718974489915, disc_loss = 0.10705307353565698
Trained batch 342 in epoch 12, gen_loss = 0.3872007338368163, disc_loss = 0.1072175641457276
Trained batch 343 in epoch 12, gen_loss = 0.38697727795603665, disc_loss = 0.10724849291660195
Trained batch 344 in epoch 12, gen_loss = 0.38688492170278577, disc_loss = 0.10706055926536952
Trained batch 345 in epoch 12, gen_loss = 0.38694413910711434, disc_loss = 0.1071669987976185
Trained batch 346 in epoch 12, gen_loss = 0.38698694212979473, disc_loss = 0.10741360938466377
Trained batch 347 in epoch 12, gen_loss = 0.3871810907262495, disc_loss = 0.1074661967256267
Trained batch 348 in epoch 12, gen_loss = 0.38719254680895876, disc_loss = 0.10724906922107226
Trained batch 349 in epoch 12, gen_loss = 0.3872769227198192, disc_loss = 0.1070284103056682
Trained batch 350 in epoch 12, gen_loss = 0.38709266258780434, disc_loss = 0.1069304358487434
Trained batch 351 in epoch 12, gen_loss = 0.3870415481823412, disc_loss = 0.10707640326026277
Trained batch 352 in epoch 12, gen_loss = 0.38664498047180285, disc_loss = 0.10720108204492218
Trained batch 353 in epoch 12, gen_loss = 0.3864978290041961, disc_loss = 0.10699093996252507
Trained batch 354 in epoch 12, gen_loss = 0.38656870420549955, disc_loss = 0.10682119926385267
Trained batch 355 in epoch 12, gen_loss = 0.3863334464055769, disc_loss = 0.10709834163563765
Trained batch 356 in epoch 12, gen_loss = 0.3860532307491249, disc_loss = 0.10765962154377534
Trained batch 357 in epoch 12, gen_loss = 0.38613622598141933, disc_loss = 0.10805351780233229
Trained batch 358 in epoch 12, gen_loss = 0.38617194022640877, disc_loss = 0.10785507087914849
Trained batch 359 in epoch 12, gen_loss = 0.38606317821476194, disc_loss = 0.10783089031853403
Trained batch 360 in epoch 12, gen_loss = 0.3862750556660491, disc_loss = 0.1076030688156526
Trained batch 361 in epoch 12, gen_loss = 0.38616954193589437, disc_loss = 0.107401815205761
Trained batch 362 in epoch 12, gen_loss = 0.38612355706448726, disc_loss = 0.10729339590409037
Trained batch 363 in epoch 12, gen_loss = 0.3859980079335171, disc_loss = 0.10746758556950346
Trained batch 364 in epoch 12, gen_loss = 0.38610138313411035, disc_loss = 0.10810638513951881
Trained batch 365 in epoch 12, gen_loss = 0.3859493389644258, disc_loss = 0.10794508467234996
Trained batch 366 in epoch 12, gen_loss = 0.3858257379453903, disc_loss = 0.108122522096411
Trained batch 367 in epoch 12, gen_loss = 0.3857998322371555, disc_loss = 0.10808763926236323
Trained batch 368 in epoch 12, gen_loss = 0.38569690824201114, disc_loss = 0.10810017656297663
Trained batch 369 in epoch 12, gen_loss = 0.3855486853702648, disc_loss = 0.10843665992362878
Trained batch 370 in epoch 12, gen_loss = 0.3856339455454176, disc_loss = 0.10820764427592933
Trained batch 371 in epoch 12, gen_loss = 0.38587333958956505, disc_loss = 0.10821959664619538
Trained batch 372 in epoch 12, gen_loss = 0.38601472278702353, disc_loss = 0.10801397037165535
Trained batch 373 in epoch 12, gen_loss = 0.3859860246034867, disc_loss = 0.10810396586106542
Trained batch 374 in epoch 12, gen_loss = 0.38622884805997215, disc_loss = 0.10818074223274986
Trained batch 375 in epoch 12, gen_loss = 0.3863928323571986, disc_loss = 0.10806193673225278
Trained batch 376 in epoch 12, gen_loss = 0.38625550119883184, disc_loss = 0.10814329972787111
Trained batch 377 in epoch 12, gen_loss = 0.38629740224313486, disc_loss = 0.10805784105618912
Trained batch 378 in epoch 12, gen_loss = 0.3865499117443618, disc_loss = 0.10851998901299366
Trained batch 379 in epoch 12, gen_loss = 0.3864052084715743, disc_loss = 0.10900076701134247
Trained batch 380 in epoch 12, gen_loss = 0.386744620997136, disc_loss = 0.10902777434329153
Trained batch 381 in epoch 12, gen_loss = 0.3865906019641467, disc_loss = 0.10888702077035309
Trained batch 382 in epoch 12, gen_loss = 0.3865164473224869, disc_loss = 0.10872078173266184
Trained batch 383 in epoch 12, gen_loss = 0.3862672943311433, disc_loss = 0.10891298842883164
Trained batch 384 in epoch 12, gen_loss = 0.38631036552515896, disc_loss = 0.10923904921593411
Trained batch 385 in epoch 12, gen_loss = 0.38616892981096873, disc_loss = 0.10912789286529269
Trained batch 386 in epoch 12, gen_loss = 0.38595500711630787, disc_loss = 0.1092753771305065
Trained batch 387 in epoch 12, gen_loss = 0.3859886181415971, disc_loss = 0.10921880111131894
Trained batch 388 in epoch 12, gen_loss = 0.3862763895320402, disc_loss = 0.10908782159296705
Trained batch 389 in epoch 12, gen_loss = 0.38591377651080105, disc_loss = 0.1091925596472067
Trained batch 390 in epoch 12, gen_loss = 0.38590797301753405, disc_loss = 0.10916065497924109
Trained batch 391 in epoch 12, gen_loss = 0.3860291111073932, disc_loss = 0.1093286746739866
Trained batch 392 in epoch 12, gen_loss = 0.38593955781623607, disc_loss = 0.10919414987579064
Trained batch 393 in epoch 12, gen_loss = 0.3858356760994432, disc_loss = 0.10903865446780955
Trained batch 394 in epoch 12, gen_loss = 0.3860073961034606, disc_loss = 0.10880014092508185
Trained batch 395 in epoch 12, gen_loss = 0.3860911173802434, disc_loss = 0.10860821736078108
Trained batch 396 in epoch 12, gen_loss = 0.38607494401691544, disc_loss = 0.10855979194292231
Trained batch 397 in epoch 12, gen_loss = 0.38598668695095195, disc_loss = 0.1095890266664008
Trained batch 398 in epoch 12, gen_loss = 0.38588987981765194, disc_loss = 0.10946312142106562
Trained batch 399 in epoch 12, gen_loss = 0.38605922855436803, disc_loss = 0.10961186646134592
Trained batch 400 in epoch 12, gen_loss = 0.38578057393171544, disc_loss = 0.10969925858196512
Trained batch 401 in epoch 12, gen_loss = 0.38579231493212096, disc_loss = 0.10954369683008622
Trained batch 402 in epoch 12, gen_loss = 0.3857789975833656, disc_loss = 0.10940725373557166
Trained batch 403 in epoch 12, gen_loss = 0.38583813622446345, disc_loss = 0.10930080162845368
Trained batch 404 in epoch 12, gen_loss = 0.38591202438613514, disc_loss = 0.10935614028669617
Trained batch 405 in epoch 12, gen_loss = 0.38615983504379914, disc_loss = 0.10937795190374583
Trained batch 406 in epoch 12, gen_loss = 0.38611584813940436, disc_loss = 0.10928762867630297
Trained batch 407 in epoch 12, gen_loss = 0.38605960933308975, disc_loss = 0.1091966921265018
Trained batch 408 in epoch 12, gen_loss = 0.3860376739560246, disc_loss = 0.10941315222472353
Trained batch 409 in epoch 12, gen_loss = 0.3859786470488804, disc_loss = 0.11022895255307781
Trained batch 410 in epoch 12, gen_loss = 0.3858790208388419, disc_loss = 0.1101670958466574
Trained batch 411 in epoch 12, gen_loss = 0.3858517024991582, disc_loss = 0.11035864923750638
Trained batch 412 in epoch 12, gen_loss = 0.38571581215604456, disc_loss = 0.11041449389778997
Trained batch 413 in epoch 12, gen_loss = 0.38583426458248193, disc_loss = 0.11039008155739574
Trained batch 414 in epoch 12, gen_loss = 0.3857186103441629, disc_loss = 0.11043022363502757
Trained batch 415 in epoch 12, gen_loss = 0.38569320967564213, disc_loss = 0.11027805749528433
Trained batch 416 in epoch 12, gen_loss = 0.38571452830049346, disc_loss = 0.11008912383531816
Trained batch 417 in epoch 12, gen_loss = 0.3856952862020885, disc_loss = 0.10996566681329464
Trained batch 418 in epoch 12, gen_loss = 0.38563481798319943, disc_loss = 0.1101405010002983
Trained batch 419 in epoch 12, gen_loss = 0.385698859109765, disc_loss = 0.11009044706311431
Trained batch 420 in epoch 12, gen_loss = 0.38560699191908937, disc_loss = 0.11016184525705891
Trained batch 421 in epoch 12, gen_loss = 0.38564302648695725, disc_loss = 0.11022983041759668
Trained batch 422 in epoch 12, gen_loss = 0.3857323061630799, disc_loss = 0.11087639339765794
Trained batch 423 in epoch 12, gen_loss = 0.3855305464481408, disc_loss = 0.11136653888113972
Trained batch 424 in epoch 12, gen_loss = 0.38564874606973987, disc_loss = 0.111215491633424
Trained batch 425 in epoch 12, gen_loss = 0.3858816293483609, disc_loss = 0.11119723579400337
Trained batch 426 in epoch 12, gen_loss = 0.38583705143292, disc_loss = 0.11113578538831315
Trained batch 427 in epoch 12, gen_loss = 0.3857029042093553, disc_loss = 0.11131041880509877
Trained batch 428 in epoch 12, gen_loss = 0.38583770887557167, disc_loss = 0.11142811429793219
Trained batch 429 in epoch 12, gen_loss = 0.3856891825448635, disc_loss = 0.11129741446591568
Trained batch 430 in epoch 12, gen_loss = 0.38560654682792256, disc_loss = 0.11144710738069255
Trained batch 431 in epoch 12, gen_loss = 0.3856781503116643, disc_loss = 0.11124550817314433
Trained batch 432 in epoch 12, gen_loss = 0.3858877596623903, disc_loss = 0.1111819158785699
Trained batch 433 in epoch 12, gen_loss = 0.38578615753057366, disc_loss = 0.11140982487908466
Trained batch 434 in epoch 12, gen_loss = 0.38612892497545004, disc_loss = 0.11141883632082535
Trained batch 435 in epoch 12, gen_loss = 0.3859498392824733, disc_loss = 0.11154973333158932
Trained batch 436 in epoch 12, gen_loss = 0.3860109683714415, disc_loss = 0.11213722856272038
Trained batch 437 in epoch 12, gen_loss = 0.3860973290520716, disc_loss = 0.11211365148888637
Trained batch 438 in epoch 12, gen_loss = 0.3861252882078731, disc_loss = 0.11216164888296455
Trained batch 439 in epoch 12, gen_loss = 0.3860820548100905, disc_loss = 0.11232450699793514
Trained batch 440 in epoch 12, gen_loss = 0.3862029572192774, disc_loss = 0.11230712004381817
Trained batch 441 in epoch 12, gen_loss = 0.3861582847607082, disc_loss = 0.11244928075434699
Trained batch 442 in epoch 12, gen_loss = 0.38610302211199604, disc_loss = 0.11244791776938343
Trained batch 443 in epoch 12, gen_loss = 0.38617726690597365, disc_loss = 0.11227663138751276
Trained batch 444 in epoch 12, gen_loss = 0.38640270474251737, disc_loss = 0.11211015858865353
Trained batch 445 in epoch 12, gen_loss = 0.3861556430702252, disc_loss = 0.11276085743776652
Trained batch 446 in epoch 12, gen_loss = 0.3862779688515119, disc_loss = 0.11292305517570851
Trained batch 447 in epoch 12, gen_loss = 0.38626874005421996, disc_loss = 0.11283283711132494
Trained batch 448 in epoch 12, gen_loss = 0.38621313017035913, disc_loss = 0.11277874217851955
Trained batch 449 in epoch 12, gen_loss = 0.386060219473309, disc_loss = 0.11266499596027037
Trained batch 450 in epoch 12, gen_loss = 0.3860541977929963, disc_loss = 0.11257619782972528
Trained batch 451 in epoch 12, gen_loss = 0.3861558356907515, disc_loss = 0.11252473308436935
Trained batch 452 in epoch 12, gen_loss = 0.38610793804753957, disc_loss = 0.112628395100706
Trained batch 453 in epoch 12, gen_loss = 0.3859251475675516, disc_loss = 0.11269467235912081
Trained batch 454 in epoch 12, gen_loss = 0.3858256006633842, disc_loss = 0.1128945627433995
Trained batch 455 in epoch 12, gen_loss = 0.38566810866458373, disc_loss = 0.11320101277465654
Trained batch 456 in epoch 12, gen_loss = 0.3856040629959733, disc_loss = 0.11301525187101907
Trained batch 457 in epoch 12, gen_loss = 0.3856456705316185, disc_loss = 0.11302327952453435
Trained batch 458 in epoch 12, gen_loss = 0.38561333284139115, disc_loss = 0.1140044885931013
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.3305594325065613, disc_loss = 0.40365689992904663
Trained batch 1 in epoch 13, gen_loss = 0.3760234862565994, disc_loss = 0.2661905139684677
Trained batch 2 in epoch 13, gen_loss = 0.36117852727572125, disc_loss = 0.21882384022076926
Trained batch 3 in epoch 13, gen_loss = 0.37062232941389084, disc_loss = 0.19981006905436516
Trained batch 4 in epoch 13, gen_loss = 0.36661126017570494, disc_loss = 0.1832453966140747
Trained batch 5 in epoch 13, gen_loss = 0.370851402481397, disc_loss = 0.16901644443472227
Trained batch 6 in epoch 13, gen_loss = 0.36689139689717976, disc_loss = 0.162047946027347
Trained batch 7 in epoch 13, gen_loss = 0.3632342591881752, disc_loss = 0.15432592947036028
Trained batch 8 in epoch 13, gen_loss = 0.36134587393866646, disc_loss = 0.15107858926057816
Trained batch 9 in epoch 13, gen_loss = 0.36217741668224335, disc_loss = 0.15847637578845025
Trained batch 10 in epoch 13, gen_loss = 0.3747596767815677, disc_loss = 0.15592859482223337
Trained batch 11 in epoch 13, gen_loss = 0.37124383449554443, disc_loss = 0.15663393028080463
Trained batch 12 in epoch 13, gen_loss = 0.37861466866273147, disc_loss = 0.15118246812086839
Trained batch 13 in epoch 13, gen_loss = 0.38152793049812317, disc_loss = 0.14472445233591966
Trained batch 14 in epoch 13, gen_loss = 0.3818357944488525, disc_loss = 0.14055609876910846
Trained batch 15 in epoch 13, gen_loss = 0.3851013854146004, disc_loss = 0.13663907232694328
Trained batch 16 in epoch 13, gen_loss = 0.3815143231083365, disc_loss = 0.13548339443171725
Trained batch 17 in epoch 13, gen_loss = 0.3815467605988185, disc_loss = 0.13404682216544947
Trained batch 18 in epoch 13, gen_loss = 0.38691808048047516, disc_loss = 0.1397601046452397
Trained batch 19 in epoch 13, gen_loss = 0.3910947322845459, disc_loss = 0.1340893315151334
Trained batch 20 in epoch 13, gen_loss = 0.38705874057043166, disc_loss = 0.13301556504198483
Trained batch 21 in epoch 13, gen_loss = 0.38804932074113324, disc_loss = 0.13310540992427955
Trained batch 22 in epoch 13, gen_loss = 0.3868016807929329, disc_loss = 0.12902316839798636
Trained batch 23 in epoch 13, gen_loss = 0.384578147282203, disc_loss = 0.12916121383508047
Trained batch 24 in epoch 13, gen_loss = 0.3863897466659546, disc_loss = 0.12932227432727814
Trained batch 25 in epoch 13, gen_loss = 0.38848792818876415, disc_loss = 0.127321346448018
Trained batch 26 in epoch 13, gen_loss = 0.38783290540730514, disc_loss = 0.1256786631765189
Trained batch 27 in epoch 13, gen_loss = 0.38900853799922125, disc_loss = 0.12316665266241346
Trained batch 28 in epoch 13, gen_loss = 0.3875874414526183, disc_loss = 0.11987713743643515
Trained batch 29 in epoch 13, gen_loss = 0.38605498572190605, disc_loss = 0.12071413540591797
Trained batch 30 in epoch 13, gen_loss = 0.3859352700171932, disc_loss = 0.12398459107404755
Trained batch 31 in epoch 13, gen_loss = 0.3847736241295934, disc_loss = 0.12397248618071899
Trained batch 32 in epoch 13, gen_loss = 0.38781111348759045, disc_loss = 0.12235508718048081
Trained batch 33 in epoch 13, gen_loss = 0.3901172061176861, disc_loss = 0.12451622147551354
Trained batch 34 in epoch 13, gen_loss = 0.3872309718813215, disc_loss = 0.12544741880680835
Trained batch 35 in epoch 13, gen_loss = 0.38806923147704864, disc_loss = 0.12261217382426064
Trained batch 36 in epoch 13, gen_loss = 0.3891583511958251, disc_loss = 0.12223263251016268
Trained batch 37 in epoch 13, gen_loss = 0.38737131812070547, disc_loss = 0.12177531739794895
Trained batch 38 in epoch 13, gen_loss = 0.38553334657962507, disc_loss = 0.12015961975050278
Trained batch 39 in epoch 13, gen_loss = 0.3834225043654442, disc_loss = 0.12122095138765872
Trained batch 40 in epoch 13, gen_loss = 0.38274437552545126, disc_loss = 0.12098621690600384
Trained batch 41 in epoch 13, gen_loss = 0.3825611351501374, disc_loss = 0.12025130367172616
Trained batch 42 in epoch 13, gen_loss = 0.38085371810336444, disc_loss = 0.11861010367960431
Trained batch 43 in epoch 13, gen_loss = 0.38096460564569995, disc_loss = 0.11692853657190096
Trained batch 44 in epoch 13, gen_loss = 0.3811874330043793, disc_loss = 0.11620952366954751
Trained batch 45 in epoch 13, gen_loss = 0.38258279665656714, disc_loss = 0.1140220470159598
Trained batch 46 in epoch 13, gen_loss = 0.38291483483415967, disc_loss = 0.11446141534821784
Trained batch 47 in epoch 13, gen_loss = 0.3815378149350484, disc_loss = 0.12133010449664046
Trained batch 48 in epoch 13, gen_loss = 0.38358382302887584, disc_loss = 0.11966299056550678
Trained batch 49 in epoch 13, gen_loss = 0.384466108083725, disc_loss = 0.11939738396555186
Trained batch 50 in epoch 13, gen_loss = 0.3835568130016327, disc_loss = 0.11900891469535875
Trained batch 51 in epoch 13, gen_loss = 0.38378696544812274, disc_loss = 0.11808695948611085
Trained batch 52 in epoch 13, gen_loss = 0.38454545781297506, disc_loss = 0.12049161505727272
Trained batch 53 in epoch 13, gen_loss = 0.383740085694525, disc_loss = 0.12106671091169119
Trained batch 54 in epoch 13, gen_loss = 0.3825723176652735, disc_loss = 0.12014479952102358
Trained batch 55 in epoch 13, gen_loss = 0.38393138721585274, disc_loss = 0.11854685324111155
Trained batch 56 in epoch 13, gen_loss = 0.3832148261237563, disc_loss = 0.11784854714284863
Trained batch 57 in epoch 13, gen_loss = 0.38299746605856666, disc_loss = 0.11761751218602576
Trained batch 58 in epoch 13, gen_loss = 0.3835677014569105, disc_loss = 0.11975444234528784
Trained batch 59 in epoch 13, gen_loss = 0.3815961023171743, disc_loss = 0.12131375682850679
Trained batch 60 in epoch 13, gen_loss = 0.3816568465506444, disc_loss = 0.12154247685045493
Trained batch 61 in epoch 13, gen_loss = 0.3803335807977184, disc_loss = 0.12054048286330316
Trained batch 62 in epoch 13, gen_loss = 0.380619504148998, disc_loss = 0.11931202690752726
Trained batch 63 in epoch 13, gen_loss = 0.38031761860474944, disc_loss = 0.11829549225512892
Trained batch 64 in epoch 13, gen_loss = 0.37931776367701014, disc_loss = 0.11825184168723914
Trained batch 65 in epoch 13, gen_loss = 0.38243876216989575, disc_loss = 0.11929223517125304
Trained batch 66 in epoch 13, gen_loss = 0.38221494519888466, disc_loss = 0.11893105440175356
Trained batch 67 in epoch 13, gen_loss = 0.381268491201541, disc_loss = 0.12344886866562507
Trained batch 68 in epoch 13, gen_loss = 0.3812673752722533, disc_loss = 0.12268190031898195
Trained batch 69 in epoch 13, gen_loss = 0.3809318742581776, disc_loss = 0.1236573450267315
Trained batch 70 in epoch 13, gen_loss = 0.38040090194890197, disc_loss = 0.1248871632654902
Trained batch 71 in epoch 13, gen_loss = 0.3804101517630948, disc_loss = 0.12469508654127519
Trained batch 72 in epoch 13, gen_loss = 0.3816657417441068, disc_loss = 0.12336158846849449
Trained batch 73 in epoch 13, gen_loss = 0.3815363750264451, disc_loss = 0.12253759627708712
Trained batch 74 in epoch 13, gen_loss = 0.3824314117431641, disc_loss = 0.12164359298845132
Trained batch 75 in epoch 13, gen_loss = 0.38202088639924403, disc_loss = 0.12215543369223412
Trained batch 76 in epoch 13, gen_loss = 0.3816674475546007, disc_loss = 0.1221920723797052
Trained batch 77 in epoch 13, gen_loss = 0.382829663845209, disc_loss = 0.1217468564088146
Trained batch 78 in epoch 13, gen_loss = 0.3825510570520087, disc_loss = 0.12099199532236479
Trained batch 79 in epoch 13, gen_loss = 0.3830849412828684, disc_loss = 0.1202578284079209
Trained batch 80 in epoch 13, gen_loss = 0.3822283998683647, disc_loss = 0.12148162172992288
Trained batch 81 in epoch 13, gen_loss = 0.382998996028086, disc_loss = 0.12334754483819735
Trained batch 82 in epoch 13, gen_loss = 0.3829331681670913, disc_loss = 0.12328036095812378
Trained batch 83 in epoch 13, gen_loss = 0.3825621899394762, disc_loss = 0.12410806565146361
Trained batch 84 in epoch 13, gen_loss = 0.38196053785436296, disc_loss = 0.12311393568182692
Trained batch 85 in epoch 13, gen_loss = 0.38300378204778185, disc_loss = 0.12189994945169189
Trained batch 86 in epoch 13, gen_loss = 0.3826583918483778, disc_loss = 0.12181265483042975
Trained batch 87 in epoch 13, gen_loss = 0.38287693295966496, disc_loss = 0.12147408336485652
Trained batch 88 in epoch 13, gen_loss = 0.3837464063355092, disc_loss = 0.12062827830485413
Trained batch 89 in epoch 13, gen_loss = 0.38404448827107746, disc_loss = 0.12081011606173384
Trained batch 90 in epoch 13, gen_loss = 0.3832271370913956, disc_loss = 0.12435460424275843
Trained batch 91 in epoch 13, gen_loss = 0.3842487536046816, disc_loss = 0.12531345100749447
Trained batch 92 in epoch 13, gen_loss = 0.38303273659880444, disc_loss = 0.12611183209685228
Trained batch 93 in epoch 13, gen_loss = 0.3833867133931911, disc_loss = 0.12616361144613078
Trained batch 94 in epoch 13, gen_loss = 0.38350685834884646, disc_loss = 0.12553406598928726
Trained batch 95 in epoch 13, gen_loss = 0.3828878526886304, disc_loss = 0.12480819289339706
Trained batch 96 in epoch 13, gen_loss = 0.38229822375110745, disc_loss = 0.12457442085844339
Trained batch 97 in epoch 13, gen_loss = 0.3823923286126584, disc_loss = 0.12428343716096513
Trained batch 98 in epoch 13, gen_loss = 0.3814664901507021, disc_loss = 0.12488418631255627
Trained batch 99 in epoch 13, gen_loss = 0.3814323827624321, disc_loss = 0.12493519151583314
Trained batch 100 in epoch 13, gen_loss = 0.3812416337504245, disc_loss = 0.12549133593271863
Trained batch 101 in epoch 13, gen_loss = 0.38072408531226365, disc_loss = 0.12569187736759582
Trained batch 102 in epoch 13, gen_loss = 0.3800810320863446, disc_loss = 0.12579817963239637
Trained batch 103 in epoch 13, gen_loss = 0.3796669284884746, disc_loss = 0.1266608211892442
Trained batch 104 in epoch 13, gen_loss = 0.3791030787286304, disc_loss = 0.12754009999334812
Trained batch 105 in epoch 13, gen_loss = 0.3794812838423927, disc_loss = 0.12689606010702983
Trained batch 106 in epoch 13, gen_loss = 0.37999208480398233, disc_loss = 0.1262116278478197
Trained batch 107 in epoch 13, gen_loss = 0.38048819783661103, disc_loss = 0.12618344630701123
Trained batch 108 in epoch 13, gen_loss = 0.38013167446906415, disc_loss = 0.12909216421801561
Trained batch 109 in epoch 13, gen_loss = 0.3795967408201911, disc_loss = 0.12907208226282488
Trained batch 110 in epoch 13, gen_loss = 0.380327440865405, disc_loss = 0.12963145952839572
Trained batch 111 in epoch 13, gen_loss = 0.3795582340764148, disc_loss = 0.13001859542315028
Trained batch 112 in epoch 13, gen_loss = 0.37979565494883377, disc_loss = 0.12964174746478027
Trained batch 113 in epoch 13, gen_loss = 0.3798240765667798, disc_loss = 0.1305727514421992
Trained batch 114 in epoch 13, gen_loss = 0.3800414658111075, disc_loss = 0.1302104724004217
Trained batch 115 in epoch 13, gen_loss = 0.3798181499386656, disc_loss = 0.12996113629497844
Trained batch 116 in epoch 13, gen_loss = 0.3790910847676106, disc_loss = 0.13048870041648036
Trained batch 117 in epoch 13, gen_loss = 0.3794484537536815, disc_loss = 0.13113576850964356
Trained batch 118 in epoch 13, gen_loss = 0.37893250709822196, disc_loss = 0.13127836755656896
Trained batch 119 in epoch 13, gen_loss = 0.3789778540531794, disc_loss = 0.13069174247793852
Trained batch 120 in epoch 13, gen_loss = 0.37904082078579043, disc_loss = 0.13033268663816708
Trained batch 121 in epoch 13, gen_loss = 0.37967698227186675, disc_loss = 0.13045074651781163
Trained batch 122 in epoch 13, gen_loss = 0.3790735284971997, disc_loss = 0.13018921958055438
Trained batch 123 in epoch 13, gen_loss = 0.3794236031751479, disc_loss = 0.1300940947577117
Trained batch 124 in epoch 13, gen_loss = 0.37996766829490664, disc_loss = 0.13101359404623508
Trained batch 125 in epoch 13, gen_loss = 0.3791803656116364, disc_loss = 0.13050107576603454
Trained batch 126 in epoch 13, gen_loss = 0.3782902038472844, disc_loss = 0.1316498418404596
Trained batch 127 in epoch 13, gen_loss = 0.3785625316668302, disc_loss = 0.13175281476287637
Trained batch 128 in epoch 13, gen_loss = 0.37894639003184416, disc_loss = 0.1309240691565959
Trained batch 129 in epoch 13, gen_loss = 0.3785814791917801, disc_loss = 0.13049673577054188
Trained batch 130 in epoch 13, gen_loss = 0.37872597484188225, disc_loss = 0.13061663134464327
Trained batch 131 in epoch 13, gen_loss = 0.37938529952909006, disc_loss = 0.13002998321176026
Trained batch 132 in epoch 13, gen_loss = 0.379553283739807, disc_loss = 0.12931348250380584
Trained batch 133 in epoch 13, gen_loss = 0.37880639620681306, disc_loss = 0.12929760677211766
Trained batch 134 in epoch 13, gen_loss = 0.3783679677380456, disc_loss = 0.1312886247066436
Trained batch 135 in epoch 13, gen_loss = 0.37951285150997777, disc_loss = 0.13165250925949828
Trained batch 136 in epoch 13, gen_loss = 0.3802509866926792, disc_loss = 0.13204889218356922
Trained batch 137 in epoch 13, gen_loss = 0.3799460610185844, disc_loss = 0.1316660091523891
Trained batch 138 in epoch 13, gen_loss = 0.37974344804990207, disc_loss = 0.1312629224183105
Trained batch 139 in epoch 13, gen_loss = 0.3799015813640186, disc_loss = 0.1307532079118703
Trained batch 140 in epoch 13, gen_loss = 0.3803657481433652, disc_loss = 0.1301518246557907
Trained batch 141 in epoch 13, gen_loss = 0.3794483708243975, disc_loss = 0.12985287072845328
Trained batch 142 in epoch 13, gen_loss = 0.379389276037683, disc_loss = 0.1299712031793136
Trained batch 143 in epoch 13, gen_loss = 0.3791276555922296, disc_loss = 0.12962411278082678
Trained batch 144 in epoch 13, gen_loss = 0.37898532933202284, disc_loss = 0.1290612766583418
Trained batch 145 in epoch 13, gen_loss = 0.37858536431234174, disc_loss = 0.12919282945102617
Trained batch 146 in epoch 13, gen_loss = 0.3787451110729555, disc_loss = 0.12910745689506029
Trained batch 147 in epoch 13, gen_loss = 0.3785115550901439, disc_loss = 0.12880699131386103
Trained batch 148 in epoch 13, gen_loss = 0.37884666595683003, disc_loss = 0.12818309858491356
Trained batch 149 in epoch 13, gen_loss = 0.3793897267182668, disc_loss = 0.12747455750902495
Trained batch 150 in epoch 13, gen_loss = 0.379231957410345, disc_loss = 0.1268624837528791
Trained batch 151 in epoch 13, gen_loss = 0.3792751717724298, disc_loss = 0.1275780675932765
Trained batch 152 in epoch 13, gen_loss = 0.37959955720340505, disc_loss = 0.12733636090373682
Trained batch 153 in epoch 13, gen_loss = 0.37980826740915125, disc_loss = 0.12684808705340733
Trained batch 154 in epoch 13, gen_loss = 0.37946967809431015, disc_loss = 0.12740554795149833
Trained batch 155 in epoch 13, gen_loss = 0.37964847397345763, disc_loss = 0.1275307075239909
Trained batch 156 in epoch 13, gen_loss = 0.379316328437465, disc_loss = 0.12718474096173693
Trained batch 157 in epoch 13, gen_loss = 0.3791675007418741, disc_loss = 0.12727876120730292
Trained batch 158 in epoch 13, gen_loss = 0.3790403769451117, disc_loss = 0.12702363429579344
Trained batch 159 in epoch 13, gen_loss = 0.38008426427841185, disc_loss = 0.1292009774595499
Trained batch 160 in epoch 13, gen_loss = 0.3802962573418706, disc_loss = 0.1286506605629595
Trained batch 161 in epoch 13, gen_loss = 0.38036687782517187, disc_loss = 0.12884052143788632
Trained batch 162 in epoch 13, gen_loss = 0.38090369598997154, disc_loss = 0.12853661499506125
Trained batch 163 in epoch 13, gen_loss = 0.38088392811577493, disc_loss = 0.12800826032350704
Trained batch 164 in epoch 13, gen_loss = 0.38090606675003513, disc_loss = 0.12780648375099354
Trained batch 165 in epoch 13, gen_loss = 0.3809093834764986, disc_loss = 0.12740235073289957
Trained batch 166 in epoch 13, gen_loss = 0.3811109101700926, disc_loss = 0.12695739534265266
Trained batch 167 in epoch 13, gen_loss = 0.3813761408839907, disc_loss = 0.12648962606631575
Trained batch 168 in epoch 13, gen_loss = 0.38136805726226264, disc_loss = 0.12640584295494317
Trained batch 169 in epoch 13, gen_loss = 0.38134766659315894, disc_loss = 0.1271959387642496
Trained batch 170 in epoch 13, gen_loss = 0.3813401214909135, disc_loss = 0.1272242165535514
Trained batch 171 in epoch 13, gen_loss = 0.381357743123243, disc_loss = 0.1266795618156361
Trained batch 172 in epoch 13, gen_loss = 0.38122205737698284, disc_loss = 0.12687480669317908
Trained batch 173 in epoch 13, gen_loss = 0.3813152301242982, disc_loss = 0.12628021308531365
Trained batch 174 in epoch 13, gen_loss = 0.3818637660571507, disc_loss = 0.12583418178771225
Trained batch 175 in epoch 13, gen_loss = 0.3812318586490371, disc_loss = 0.12551646638365294
Trained batch 176 in epoch 13, gen_loss = 0.38104371835956463, disc_loss = 0.12525614924560496
Trained batch 177 in epoch 13, gen_loss = 0.3817440833938256, disc_loss = 0.12626412608189863
Trained batch 178 in epoch 13, gen_loss = 0.3814521804868176, disc_loss = 0.12576263700741963
Trained batch 179 in epoch 13, gen_loss = 0.38092590752575134, disc_loss = 0.12574598833711612
Trained batch 180 in epoch 13, gen_loss = 0.38119112012794665, disc_loss = 0.12644245211055594
Trained batch 181 in epoch 13, gen_loss = 0.38125272684699885, disc_loss = 0.12617341890562694
Trained batch 182 in epoch 13, gen_loss = 0.38112319053196514, disc_loss = 0.1256990779516964
Trained batch 183 in epoch 13, gen_loss = 0.3811622543827347, disc_loss = 0.12558311716977344
Trained batch 184 in epoch 13, gen_loss = 0.38077293795508305, disc_loss = 0.12699449375473165
Trained batch 185 in epoch 13, gen_loss = 0.38101678654070825, disc_loss = 0.12771452329452
Trained batch 186 in epoch 13, gen_loss = 0.3810356589243374, disc_loss = 0.12740863874594477
Trained batch 187 in epoch 13, gen_loss = 0.3808555155992508, disc_loss = 0.12730620237701434
Trained batch 188 in epoch 13, gen_loss = 0.38054403016176175, disc_loss = 0.1268916477266916
Trained batch 189 in epoch 13, gen_loss = 0.3801550929483615, disc_loss = 0.12669290958070442
Trained batch 190 in epoch 13, gen_loss = 0.3803596148628215, disc_loss = 0.1266878043930412
Trained batch 191 in epoch 13, gen_loss = 0.380347892952462, disc_loss = 0.12727135065748976
Trained batch 192 in epoch 13, gen_loss = 0.3801656573856433, disc_loss = 0.12747097442920652
Trained batch 193 in epoch 13, gen_loss = 0.37972758203437645, disc_loss = 0.127561673320369
Trained batch 194 in epoch 13, gen_loss = 0.3794625118756906, disc_loss = 0.12790614751478036
Trained batch 195 in epoch 13, gen_loss = 0.3793770377429164, disc_loss = 0.127970017977439
Trained batch 196 in epoch 13, gen_loss = 0.3792234713656043, disc_loss = 0.12781544164919914
Trained batch 197 in epoch 13, gen_loss = 0.37884772155019975, disc_loss = 0.12800409666478935
Trained batch 198 in epoch 13, gen_loss = 0.3792773937460166, disc_loss = 0.12876959915399253
Trained batch 199 in epoch 13, gen_loss = 0.37949407935142515, disc_loss = 0.1281728071765974
Trained batch 200 in epoch 13, gen_loss = 0.37929349589110606, disc_loss = 0.12794302864028
Trained batch 201 in epoch 13, gen_loss = 0.3793342178410823, disc_loss = 0.1275061458985478
Trained batch 202 in epoch 13, gen_loss = 0.37933410594028794, disc_loss = 0.12691543955502693
Trained batch 203 in epoch 13, gen_loss = 0.37910931995686364, disc_loss = 0.12678552334489046
Trained batch 204 in epoch 13, gen_loss = 0.37957297171034465, disc_loss = 0.12700997397939606
Trained batch 205 in epoch 13, gen_loss = 0.3794851326248021, disc_loss = 0.12689593958315773
Trained batch 206 in epoch 13, gen_loss = 0.3793799092516231, disc_loss = 0.12731015001500143
Trained batch 207 in epoch 13, gen_loss = 0.37939071426024806, disc_loss = 0.12809008828704604
Trained batch 208 in epoch 13, gen_loss = 0.3791889354372709, disc_loss = 0.12796348528981066
Trained batch 209 in epoch 13, gen_loss = 0.37927695895944324, disc_loss = 0.12769550847421798
Trained batch 210 in epoch 13, gen_loss = 0.37957273656723056, disc_loss = 0.12762184359433384
Trained batch 211 in epoch 13, gen_loss = 0.37960337130528576, disc_loss = 0.12723460754397203
Trained batch 212 in epoch 13, gen_loss = 0.3794494429384599, disc_loss = 0.12699103795709044
Trained batch 213 in epoch 13, gen_loss = 0.3789902038384821, disc_loss = 0.1270606037986543
Trained batch 214 in epoch 13, gen_loss = 0.3792459361774977, disc_loss = 0.12684295728022968
Trained batch 215 in epoch 13, gen_loss = 0.37915595110367845, disc_loss = 0.12669326288677338
Trained batch 216 in epoch 13, gen_loss = 0.37884657709829267, disc_loss = 0.12756614414073766
Trained batch 217 in epoch 13, gen_loss = 0.3792020524040275, disc_loss = 0.12726872270380002
Trained batch 218 in epoch 13, gen_loss = 0.37939965765770167, disc_loss = 0.12686664244951043
Trained batch 219 in epoch 13, gen_loss = 0.3792555120858279, disc_loss = 0.12689690310084684
Trained batch 220 in epoch 13, gen_loss = 0.3793686149616587, disc_loss = 0.12794548830615854
Trained batch 221 in epoch 13, gen_loss = 0.3798665204295167, disc_loss = 0.1276590220487534
Trained batch 222 in epoch 13, gen_loss = 0.3798036287985575, disc_loss = 0.1283460787785628
Trained batch 223 in epoch 13, gen_loss = 0.3800090963819197, disc_loss = 0.12835731075860426
Trained batch 224 in epoch 13, gen_loss = 0.37976247787475587, disc_loss = 0.12847457486308284
Trained batch 225 in epoch 13, gen_loss = 0.379241820589631, disc_loss = 0.12865413070565698
Trained batch 226 in epoch 13, gen_loss = 0.37940048882614674, disc_loss = 0.12876294111414496
Trained batch 227 in epoch 13, gen_loss = 0.37968986768994417, disc_loss = 0.12843075951381602
Trained batch 228 in epoch 13, gen_loss = 0.3795198665435658, disc_loss = 0.1286346592358822
Trained batch 229 in epoch 13, gen_loss = 0.3792738524468049, disc_loss = 0.12859208539695197
Trained batch 230 in epoch 13, gen_loss = 0.3792341329576649, disc_loss = 0.12909414513980028
Trained batch 231 in epoch 13, gen_loss = 0.37908420005235177, disc_loss = 0.12938718987098927
Trained batch 232 in epoch 13, gen_loss = 0.37908227415555534, disc_loss = 0.12949916305891818
Trained batch 233 in epoch 13, gen_loss = 0.3790685263199684, disc_loss = 0.12938533297891164
Trained batch 234 in epoch 13, gen_loss = 0.3791373687855741, disc_loss = 0.12917373390828676
Trained batch 235 in epoch 13, gen_loss = 0.379214626373881, disc_loss = 0.12879093616048537
Trained batch 236 in epoch 13, gen_loss = 0.3790448949306826, disc_loss = 0.1286778578550441
Trained batch 237 in epoch 13, gen_loss = 0.379241943359375, disc_loss = 0.1281857076101005
Trained batch 238 in epoch 13, gen_loss = 0.379247445441689, disc_loss = 0.12767892665420677
Trained batch 239 in epoch 13, gen_loss = 0.37915346150596935, disc_loss = 0.1272837150162862
Trained batch 240 in epoch 13, gen_loss = 0.3792797690605227, disc_loss = 0.12717222010608592
Trained batch 241 in epoch 13, gen_loss = 0.3792635307085416, disc_loss = 0.12758462087343608
Trained batch 242 in epoch 13, gen_loss = 0.3794538874194455, disc_loss = 0.12745574606705165
Trained batch 243 in epoch 13, gen_loss = 0.37953984126692913, disc_loss = 0.1271913134298272
Trained batch 244 in epoch 13, gen_loss = 0.3792677160428495, disc_loss = 0.12764922078812913
Trained batch 245 in epoch 13, gen_loss = 0.3796375157629571, disc_loss = 0.12913266456746533
Trained batch 246 in epoch 13, gen_loss = 0.38007243586937905, disc_loss = 0.12893769675337893
Trained batch 247 in epoch 13, gen_loss = 0.3796239294592411, disc_loss = 0.12923852143426157
Trained batch 248 in epoch 13, gen_loss = 0.379581225684369, disc_loss = 0.12900410343642277
Trained batch 249 in epoch 13, gen_loss = 0.3798134050369263, disc_loss = 0.1287712595704943
Trained batch 250 in epoch 13, gen_loss = 0.3798624788859926, disc_loss = 0.12867020176857175
Trained batch 251 in epoch 13, gen_loss = 0.37995893685590654, disc_loss = 0.12864437595283287
Trained batch 252 in epoch 13, gen_loss = 0.37993105221171625, disc_loss = 0.12850270714250064
Trained batch 253 in epoch 13, gen_loss = 0.37993369280822636, disc_loss = 0.12816689620491148
Trained batch 254 in epoch 13, gen_loss = 0.3798505628810209, disc_loss = 0.12813583068440065
Trained batch 255 in epoch 13, gen_loss = 0.3798749573761597, disc_loss = 0.12843919428451045
Trained batch 256 in epoch 13, gen_loss = 0.3805125911180147, disc_loss = 0.12946740290918296
Trained batch 257 in epoch 13, gen_loss = 0.38081164842890214, disc_loss = 0.12910195234477115
Trained batch 258 in epoch 13, gen_loss = 0.3808491211600285, disc_loss = 0.12922823235831263
Trained batch 259 in epoch 13, gen_loss = 0.3810857951641083, disc_loss = 0.1291344438267585
Trained batch 260 in epoch 13, gen_loss = 0.3812377097734546, disc_loss = 0.12888070774867674
Trained batch 261 in epoch 13, gen_loss = 0.3811277856353585, disc_loss = 0.12887711657516887
Trained batch 262 in epoch 13, gen_loss = 0.38115507092312717, disc_loss = 0.12891780026434096
Trained batch 263 in epoch 13, gen_loss = 0.3815014205421462, disc_loss = 0.1285794538844405
Trained batch 264 in epoch 13, gen_loss = 0.38107058315906883, disc_loss = 0.1285512434511955
Trained batch 265 in epoch 13, gen_loss = 0.38108573047290173, disc_loss = 0.12837325944915357
Trained batch 266 in epoch 13, gen_loss = 0.3812048539017024, disc_loss = 0.12820366533710326
Trained batch 267 in epoch 13, gen_loss = 0.38161399649150335, disc_loss = 0.12807304813325016
Trained batch 268 in epoch 13, gen_loss = 0.3817123194609433, disc_loss = 0.12812817158509862
Trained batch 269 in epoch 13, gen_loss = 0.3819058182062926, disc_loss = 0.12844422515654177
Trained batch 270 in epoch 13, gen_loss = 0.3817940375241846, disc_loss = 0.12880729475123912
Trained batch 271 in epoch 13, gen_loss = 0.38177627456538815, disc_loss = 0.12918281566988513
Trained batch 272 in epoch 13, gen_loss = 0.3819011734737145, disc_loss = 0.12887159041248453
Trained batch 273 in epoch 13, gen_loss = 0.3818395571769589, disc_loss = 0.12907312339491273
Trained batch 274 in epoch 13, gen_loss = 0.38195138237693094, disc_loss = 0.12903508481146259
Trained batch 275 in epoch 13, gen_loss = 0.3821562616073567, disc_loss = 0.12863285901139665
Trained batch 276 in epoch 13, gen_loss = 0.3821892934155378, disc_loss = 0.12832643668123586
Trained batch 277 in epoch 13, gen_loss = 0.38234981851612065, disc_loss = 0.1279740897392546
Trained batch 278 in epoch 13, gen_loss = 0.38191955245523895, disc_loss = 0.1279814144993688
Trained batch 279 in epoch 13, gen_loss = 0.38213087607707297, disc_loss = 0.12867305916900348
Trained batch 280 in epoch 13, gen_loss = 0.3821042881105294, disc_loss = 0.12843863267842615
Trained batch 281 in epoch 13, gen_loss = 0.381900817367202, disc_loss = 0.1286345059200725
Trained batch 282 in epoch 13, gen_loss = 0.38194685658380756, disc_loss = 0.12837577739717312
Trained batch 283 in epoch 13, gen_loss = 0.3823604294112031, disc_loss = 0.12849293286669475
Trained batch 284 in epoch 13, gen_loss = 0.3821837119888841, disc_loss = 0.1285339679585345
Trained batch 285 in epoch 13, gen_loss = 0.3817914320038749, disc_loss = 0.12839897106714235
Trained batch 286 in epoch 13, gen_loss = 0.38197055137115904, disc_loss = 0.12834749435227144
Trained batch 287 in epoch 13, gen_loss = 0.3818199027122723, disc_loss = 0.12824264069947983
Trained batch 288 in epoch 13, gen_loss = 0.3815628364424392, disc_loss = 0.12821616332455954
Trained batch 289 in epoch 13, gen_loss = 0.38139268838126084, disc_loss = 0.12796302874058743
Trained batch 290 in epoch 13, gen_loss = 0.3814883531164058, disc_loss = 0.12797198052393252
Trained batch 291 in epoch 13, gen_loss = 0.3813360033378209, disc_loss = 0.1286172398815748
Trained batch 292 in epoch 13, gen_loss = 0.38170047750245184, disc_loss = 0.1285270509157495
Trained batch 293 in epoch 13, gen_loss = 0.38178798505643596, disc_loss = 0.1282842001342373
Trained batch 294 in epoch 13, gen_loss = 0.38163147831367233, disc_loss = 0.1282781562262799
Trained batch 295 in epoch 13, gen_loss = 0.3814348311641732, disc_loss = 0.1280129786432922
Trained batch 296 in epoch 13, gen_loss = 0.3813633103964706, disc_loss = 0.12782395041080485
Trained batch 297 in epoch 13, gen_loss = 0.3815267422055238, disc_loss = 0.12776012833217695
Trained batch 298 in epoch 13, gen_loss = 0.381685318556119, disc_loss = 0.12768893573825624
Trained batch 299 in epoch 13, gen_loss = 0.3818463921546936, disc_loss = 0.12813072529466202
Trained batch 300 in epoch 13, gen_loss = 0.38179448276659184, disc_loss = 0.12801240312331588
Trained batch 301 in epoch 13, gen_loss = 0.38183476218324625, disc_loss = 0.12787229031947325
Trained batch 302 in epoch 13, gen_loss = 0.3821083590535834, disc_loss = 0.12772946752663147
Trained batch 303 in epoch 13, gen_loss = 0.38201233391699035, disc_loss = 0.12742291088981897
Trained batch 304 in epoch 13, gen_loss = 0.3821119335831189, disc_loss = 0.12711391490044407
Trained batch 305 in epoch 13, gen_loss = 0.3817659646662232, disc_loss = 0.12818330684159365
Trained batch 306 in epoch 13, gen_loss = 0.38209492404996764, disc_loss = 0.12872742831931488
Trained batch 307 in epoch 13, gen_loss = 0.3822727231429769, disc_loss = 0.1285181320771309
Trained batch 308 in epoch 13, gen_loss = 0.3822173509011377, disc_loss = 0.12830119532560116
Trained batch 309 in epoch 13, gen_loss = 0.38216375583602535, disc_loss = 0.12824572688419253
Trained batch 310 in epoch 13, gen_loss = 0.3822711082325104, disc_loss = 0.12788609987412283
Trained batch 311 in epoch 13, gen_loss = 0.38220573818454373, disc_loss = 0.12813383512324295
Trained batch 312 in epoch 13, gen_loss = 0.3821014629575772, disc_loss = 0.12825510457616313
Trained batch 313 in epoch 13, gen_loss = 0.3821516218268947, disc_loss = 0.1280042011792042
Trained batch 314 in epoch 13, gen_loss = 0.3822006811225225, disc_loss = 0.12784455385029553
Trained batch 315 in epoch 13, gen_loss = 0.3822558871175669, disc_loss = 0.1279621164305607
Trained batch 316 in epoch 13, gen_loss = 0.3825587607708639, disc_loss = 0.12795456533675736
Trained batch 317 in epoch 13, gen_loss = 0.3826378622332459, disc_loss = 0.12787172884340603
Trained batch 318 in epoch 13, gen_loss = 0.38253591324094693, disc_loss = 0.12766260867004156
Trained batch 319 in epoch 13, gen_loss = 0.38236562330275775, disc_loss = 0.12749227300082566
Trained batch 320 in epoch 13, gen_loss = 0.3820600610841472, disc_loss = 0.12729077828711485
Trained batch 321 in epoch 13, gen_loss = 0.3822054990700313, disc_loss = 0.1272747868640198
Trained batch 322 in epoch 13, gen_loss = 0.3823141618040693, disc_loss = 0.12760225711851714
Trained batch 323 in epoch 13, gen_loss = 0.38210152917438084, disc_loss = 0.12860364060601748
Trained batch 324 in epoch 13, gen_loss = 0.3822105219730964, disc_loss = 0.1288384369087334
Trained batch 325 in epoch 13, gen_loss = 0.38210532279468024, disc_loss = 0.12870337604545057
Trained batch 326 in epoch 13, gen_loss = 0.38220065039232237, disc_loss = 0.12857759311732578
Trained batch 327 in epoch 13, gen_loss = 0.3820570446550846, disc_loss = 0.12828987963616895
Trained batch 328 in epoch 13, gen_loss = 0.38194309478472793, disc_loss = 0.12808596990057083
Trained batch 329 in epoch 13, gen_loss = 0.38191215124997224, disc_loss = 0.12789973250420933
Trained batch 330 in epoch 13, gen_loss = 0.3817197169061874, disc_loss = 0.12771086493405737
Trained batch 331 in epoch 13, gen_loss = 0.38204989932387706, disc_loss = 0.1276843107925414
Trained batch 332 in epoch 13, gen_loss = 0.3820841940673622, disc_loss = 0.1274609303356403
Trained batch 333 in epoch 13, gen_loss = 0.3820696040363369, disc_loss = 0.12717309698579599
Trained batch 334 in epoch 13, gen_loss = 0.3821314823271623, disc_loss = 0.12713779252884325
Trained batch 335 in epoch 13, gen_loss = 0.3818497495459659, disc_loss = 0.12757608575685436
Trained batch 336 in epoch 13, gen_loss = 0.3819577859311146, disc_loss = 0.1273027616083202
Trained batch 337 in epoch 13, gen_loss = 0.38208265382157275, disc_loss = 0.12732261909342774
Trained batch 338 in epoch 13, gen_loss = 0.3820086374747015, disc_loss = 0.12733214092097495
Trained batch 339 in epoch 13, gen_loss = 0.38206394455012155, disc_loss = 0.12718257725047058
Trained batch 340 in epoch 13, gen_loss = 0.3819666276754172, disc_loss = 0.12699340393799535
Trained batch 341 in epoch 13, gen_loss = 0.3820033698228368, disc_loss = 0.1266812403476661
Trained batch 342 in epoch 13, gen_loss = 0.38213379659388574, disc_loss = 0.12650885128445988
Trained batch 343 in epoch 13, gen_loss = 0.38198138730123987, disc_loss = 0.12639410459831746
Trained batch 344 in epoch 13, gen_loss = 0.3819351917591648, disc_loss = 0.12620178800805107
Trained batch 345 in epoch 13, gen_loss = 0.38180578728287207, disc_loss = 0.12598975640829285
Trained batch 346 in epoch 13, gen_loss = 0.3819463749440328, disc_loss = 0.12596204907630681
Trained batch 347 in epoch 13, gen_loss = 0.38177140699378376, disc_loss = 0.1262015420796307
Trained batch 348 in epoch 13, gen_loss = 0.38184655404364143, disc_loss = 0.1264640188557136
Trained batch 349 in epoch 13, gen_loss = 0.38190417059830256, disc_loss = 0.12625137080704527
Trained batch 350 in epoch 13, gen_loss = 0.3817670677292381, disc_loss = 0.12610246390343094
Trained batch 351 in epoch 13, gen_loss = 0.38188328907232394, disc_loss = 0.1261697595751188
Trained batch 352 in epoch 13, gen_loss = 0.3817383161516433, disc_loss = 0.12627363509548664
Trained batch 353 in epoch 13, gen_loss = 0.3817924586056316, disc_loss = 0.12621313506753137
Trained batch 354 in epoch 13, gen_loss = 0.3816671719013805, disc_loss = 0.12611731144560265
Trained batch 355 in epoch 13, gen_loss = 0.3818731127997463, disc_loss = 0.1261954131402766
Trained batch 356 in epoch 13, gen_loss = 0.38197574987798844, disc_loss = 0.12609561712869785
Trained batch 357 in epoch 13, gen_loss = 0.3819797542674581, disc_loss = 0.1260154937256086
Trained batch 358 in epoch 13, gen_loss = 0.3820203963594516, disc_loss = 0.12577509615067028
Trained batch 359 in epoch 13, gen_loss = 0.38212826541728445, disc_loss = 0.12558543790364637
Trained batch 360 in epoch 13, gen_loss = 0.3821123710464573, disc_loss = 0.12566314138848736
Trained batch 361 in epoch 13, gen_loss = 0.3820222604669919, disc_loss = 0.12650809096023236
Trained batch 362 in epoch 13, gen_loss = 0.38232335850555377, disc_loss = 0.12643729015471564
Trained batch 363 in epoch 13, gen_loss = 0.38255052325817257, disc_loss = 0.12622554877204922
Trained batch 364 in epoch 13, gen_loss = 0.3825887124832362, disc_loss = 0.12604210283479667
Trained batch 365 in epoch 13, gen_loss = 0.38229471265943976, disc_loss = 0.12616397453283718
Trained batch 366 in epoch 13, gen_loss = 0.3824457302080513, disc_loss = 0.1264695258879633
Trained batch 367 in epoch 13, gen_loss = 0.3824468990382941, disc_loss = 0.12640175572216875
Trained batch 368 in epoch 13, gen_loss = 0.3822810430998402, disc_loss = 0.12635763266772476
Trained batch 369 in epoch 13, gen_loss = 0.3822505304136792, disc_loss = 0.126221565626612
Trained batch 370 in epoch 13, gen_loss = 0.3822216416465626, disc_loss = 0.12599440379510068
Trained batch 371 in epoch 13, gen_loss = 0.3821718938728815, disc_loss = 0.1257822440038385
Trained batch 372 in epoch 13, gen_loss = 0.38206926675328623, disc_loss = 0.12560051962878085
Trained batch 373 in epoch 13, gen_loss = 0.38211320810776983, disc_loss = 0.12565613669134118
Trained batch 374 in epoch 13, gen_loss = 0.3818317737579346, disc_loss = 0.12624684651320178
Trained batch 375 in epoch 13, gen_loss = 0.3820553331616077, disc_loss = 0.1261319399159897
Trained batch 376 in epoch 13, gen_loss = 0.3820518884481739, disc_loss = 0.12588080085581785
Trained batch 377 in epoch 13, gen_loss = 0.38199773028729456, disc_loss = 0.12568282623400803
Trained batch 378 in epoch 13, gen_loss = 0.38194565872089214, disc_loss = 0.1253972001297591
Trained batch 379 in epoch 13, gen_loss = 0.38192791876040005, disc_loss = 0.12526697528818131
Trained batch 380 in epoch 13, gen_loss = 0.3819466324772422, disc_loss = 0.12558211813121056
Trained batch 381 in epoch 13, gen_loss = 0.3816924915107757, disc_loss = 0.12566525622329514
Trained batch 382 in epoch 13, gen_loss = 0.38184235410341705, disc_loss = 0.12545906907608903
Trained batch 383 in epoch 13, gen_loss = 0.38204272619138163, disc_loss = 0.12538019968997105
Trained batch 384 in epoch 13, gen_loss = 0.3821714073806614, disc_loss = 0.12540806510255903
Trained batch 385 in epoch 13, gen_loss = 0.3820977878848506, disc_loss = 0.12545329874376598
Trained batch 386 in epoch 13, gen_loss = 0.3822804524608977, disc_loss = 0.12524897031105806
Trained batch 387 in epoch 13, gen_loss = 0.3822149334801841, disc_loss = 0.12536180973384223
Trained batch 388 in epoch 13, gen_loss = 0.38215286052931857, disc_loss = 0.1256738366920664
Trained batch 389 in epoch 13, gen_loss = 0.3820565064748128, disc_loss = 0.1259001154321222
Trained batch 390 in epoch 13, gen_loss = 0.38191461037187013, disc_loss = 0.1258332560855962
Trained batch 391 in epoch 13, gen_loss = 0.3818642113889967, disc_loss = 0.12563661821970565
Trained batch 392 in epoch 13, gen_loss = 0.38192618568131637, disc_loss = 0.12554841708159667
Trained batch 393 in epoch 13, gen_loss = 0.38178388297860394, disc_loss = 0.1255928377968349
Trained batch 394 in epoch 13, gen_loss = 0.38177195689346216, disc_loss = 0.12552436678493514
Trained batch 395 in epoch 13, gen_loss = 0.3818726765386986, disc_loss = 0.12541222084675813
Trained batch 396 in epoch 13, gen_loss = 0.3817033883306181, disc_loss = 0.12531698826977264
Trained batch 397 in epoch 13, gen_loss = 0.3816372386025424, disc_loss = 0.1251746733361696
Trained batch 398 in epoch 13, gen_loss = 0.38162591881620556, disc_loss = 0.12494508507206364
Trained batch 399 in epoch 13, gen_loss = 0.38161880113184454, disc_loss = 0.12475374580943026
Trained batch 400 in epoch 13, gen_loss = 0.38183559778325277, disc_loss = 0.1245961950643643
Trained batch 401 in epoch 13, gen_loss = 0.3815782701049871, disc_loss = 0.1245026335789734
Trained batch 402 in epoch 13, gen_loss = 0.3815850127423667, disc_loss = 0.12442917149010167
Trained batch 403 in epoch 13, gen_loss = 0.3813445461120936, disc_loss = 0.12455311372972988
Trained batch 404 in epoch 13, gen_loss = 0.3815666170031936, disc_loss = 0.12450934477081453
Trained batch 405 in epoch 13, gen_loss = 0.3814758915325691, disc_loss = 0.12433521843772254
Trained batch 406 in epoch 13, gen_loss = 0.38129609691423044, disc_loss = 0.12463192097700822
Trained batch 407 in epoch 13, gen_loss = 0.38141174278422896, disc_loss = 0.1253231547044718
Trained batch 408 in epoch 13, gen_loss = 0.38142792607286446, disc_loss = 0.12525272631361936
Trained batch 409 in epoch 13, gen_loss = 0.3813649868819772, disc_loss = 0.1250307821793618
Trained batch 410 in epoch 13, gen_loss = 0.3814718560145719, disc_loss = 0.12488733313257133
Trained batch 411 in epoch 13, gen_loss = 0.3813060358600709, disc_loss = 0.1250259474211472
Trained batch 412 in epoch 13, gen_loss = 0.38122213298125646, disc_loss = 0.12528765091185456
Trained batch 413 in epoch 13, gen_loss = 0.381130867894145, disc_loss = 0.12531105667951062
Trained batch 414 in epoch 13, gen_loss = 0.38114443873784626, disc_loss = 0.1251547135738095
Trained batch 415 in epoch 13, gen_loss = 0.3811155791179492, disc_loss = 0.1250195111060748
Trained batch 416 in epoch 13, gen_loss = 0.3811309330469127, disc_loss = 0.12492765367089166
Trained batch 417 in epoch 13, gen_loss = 0.38114752624023474, disc_loss = 0.12472828504023405
Trained batch 418 in epoch 13, gen_loss = 0.38091723660011567, disc_loss = 0.12461581864996607
Trained batch 419 in epoch 13, gen_loss = 0.3807164353983743, disc_loss = 0.12452105221316395
Trained batch 420 in epoch 13, gen_loss = 0.3808878568883746, disc_loss = 0.12429410109137165
Trained batch 421 in epoch 13, gen_loss = 0.38088859815450643, disc_loss = 0.12411218344551728
Trained batch 422 in epoch 13, gen_loss = 0.3808752060218342, disc_loss = 0.12399767865547932
Trained batch 423 in epoch 13, gen_loss = 0.3808620899634541, disc_loss = 0.12401713910271009
Trained batch 424 in epoch 13, gen_loss = 0.3809255205883699, disc_loss = 0.12382246073225842
Trained batch 425 in epoch 13, gen_loss = 0.3808782544214401, disc_loss = 0.12376978540106594
Trained batch 426 in epoch 13, gen_loss = 0.38081380801681053, disc_loss = 0.12377225167600032
Trained batch 427 in epoch 13, gen_loss = 0.38090112324908515, disc_loss = 0.12385049122538
Trained batch 428 in epoch 13, gen_loss = 0.3808983165623147, disc_loss = 0.12386966826359466
Trained batch 429 in epoch 13, gen_loss = 0.3810327140397804, disc_loss = 0.12366827390763128
Trained batch 430 in epoch 13, gen_loss = 0.3811741575010968, disc_loss = 0.12361792712353532
Trained batch 431 in epoch 13, gen_loss = 0.381149312067363, disc_loss = 0.12391332834118253
Trained batch 432 in epoch 13, gen_loss = 0.38132835253556935, disc_loss = 0.1238846272696885
Trained batch 433 in epoch 13, gen_loss = 0.38137997130644485, disc_loss = 0.12374658896888216
Trained batch 434 in epoch 13, gen_loss = 0.3813460978283279, disc_loss = 0.12354798841600617
Trained batch 435 in epoch 13, gen_loss = 0.3815655302974062, disc_loss = 0.12330417203131654
Trained batch 436 in epoch 13, gen_loss = 0.3815298532593987, disc_loss = 0.1232266774714351
Trained batch 437 in epoch 13, gen_loss = 0.3814512821909499, disc_loss = 0.12350505533985386
Trained batch 438 in epoch 13, gen_loss = 0.3817372594987613, disc_loss = 0.1234253309720147
Trained batch 439 in epoch 13, gen_loss = 0.3819793357090516, disc_loss = 0.12333107741062783
Trained batch 440 in epoch 13, gen_loss = 0.3818600262914385, disc_loss = 0.1236004374061802
Trained batch 441 in epoch 13, gen_loss = 0.381894884673179, disc_loss = 0.12342439023503925
Trained batch 442 in epoch 13, gen_loss = 0.38195537552069325, disc_loss = 0.12325907632830484
Trained batch 443 in epoch 13, gen_loss = 0.3818212407934773, disc_loss = 0.12329218353392338
Trained batch 444 in epoch 13, gen_loss = 0.3820568888374929, disc_loss = 0.12317470800696631
Trained batch 445 in epoch 13, gen_loss = 0.38210355460376483, disc_loss = 0.12298780184911538
Trained batch 446 in epoch 13, gen_loss = 0.38230380422583626, disc_loss = 0.1229170100102972
Trained batch 447 in epoch 13, gen_loss = 0.3822403055216585, disc_loss = 0.1233109789869299
Trained batch 448 in epoch 13, gen_loss = 0.3825233945071299, disc_loss = 0.123647487372832
Trained batch 449 in epoch 13, gen_loss = 0.3824482844273249, disc_loss = 0.12366546067616178
Trained batch 450 in epoch 13, gen_loss = 0.38216261489692654, disc_loss = 0.12416118660636098
Trained batch 451 in epoch 13, gen_loss = 0.38249077014954747, disc_loss = 0.12391856356948383
Trained batch 452 in epoch 13, gen_loss = 0.3825628851554778, disc_loss = 0.12369511124038571
Trained batch 453 in epoch 13, gen_loss = 0.38256892627556416, disc_loss = 0.12354345410130918
Trained batch 454 in epoch 13, gen_loss = 0.38248894011581336, disc_loss = 0.12338959973121247
Trained batch 455 in epoch 13, gen_loss = 0.3825474243545741, disc_loss = 0.12327047782692764
Trained batch 456 in epoch 13, gen_loss = 0.38248367010894957, disc_loss = 0.12315848377315201
Trained batch 457 in epoch 13, gen_loss = 0.3824502806866533, disc_loss = 0.12311565931825431
Trained batch 458 in epoch 13, gen_loss = 0.38296732644110204, disc_loss = 0.12297684546409901
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.40128228068351746, disc_loss = 0.07191482186317444
Trained batch 1 in epoch 14, gen_loss = 0.4416191875934601, disc_loss = 0.102020263671875
Trained batch 2 in epoch 14, gen_loss = 0.41773154338200885, disc_loss = 0.09342723836501439
Trained batch 3 in epoch 14, gen_loss = 0.41554275155067444, disc_loss = 0.09755810163915157
Trained batch 4 in epoch 14, gen_loss = 0.40792704820632936, disc_loss = 0.13477300852537155
Trained batch 5 in epoch 14, gen_loss = 0.403230478366216, disc_loss = 0.11852304389079411
Trained batch 6 in epoch 14, gen_loss = 0.41277876496315, disc_loss = 0.1158512681722641
Trained batch 7 in epoch 14, gen_loss = 0.40356146544218063, disc_loss = 0.1268590297549963
Trained batch 8 in epoch 14, gen_loss = 0.4075349536206987, disc_loss = 0.12226701113912794
Trained batch 9 in epoch 14, gen_loss = 0.4070929169654846, disc_loss = 0.11575893163681031
Trained batch 10 in epoch 14, gen_loss = 0.4092172926122492, disc_loss = 0.11015143482522531
Trained batch 11 in epoch 14, gen_loss = 0.4006471013029416, disc_loss = 0.10593382672717173
Trained batch 12 in epoch 14, gen_loss = 0.3968356435115521, disc_loss = 0.10639175915947327
Trained batch 13 in epoch 14, gen_loss = 0.40164381691387724, disc_loss = 0.11344302472259317
Trained batch 14 in epoch 14, gen_loss = 0.3971450547377268, disc_loss = 0.12082417532801629
Trained batch 15 in epoch 14, gen_loss = 0.3944647777825594, disc_loss = 0.11710061156190932
Trained batch 16 in epoch 14, gen_loss = 0.3983151456888984, disc_loss = 0.11530246432213222
Trained batch 17 in epoch 14, gen_loss = 0.3969530910253525, disc_loss = 0.11113549872404999
Trained batch 18 in epoch 14, gen_loss = 0.39705389581228556, disc_loss = 0.1087375677337772
Trained batch 19 in epoch 14, gen_loss = 0.3977619200944901, disc_loss = 0.11127473507076502
Trained batch 20 in epoch 14, gen_loss = 0.39374494552612305, disc_loss = 0.11813115026979219
Trained batch 21 in epoch 14, gen_loss = 0.3976343815976923, disc_loss = 0.11479819786142219
Trained batch 22 in epoch 14, gen_loss = 0.39953046777974005, disc_loss = 0.11076018602951714
Trained batch 23 in epoch 14, gen_loss = 0.3976835012435913, disc_loss = 0.10745367966592312
Trained batch 24 in epoch 14, gen_loss = 0.39474619388580323, disc_loss = 0.10637504696846008
Trained batch 25 in epoch 14, gen_loss = 0.39369696837205154, disc_loss = 0.10431694210721897
Trained batch 26 in epoch 14, gen_loss = 0.39519121801411666, disc_loss = 0.10309997256155368
Trained batch 27 in epoch 14, gen_loss = 0.39607245687927517, disc_loss = 0.10443841027362007
Trained batch 28 in epoch 14, gen_loss = 0.3911779070722646, disc_loss = 0.10455141088058209
Trained batch 29 in epoch 14, gen_loss = 0.39005574186642966, disc_loss = 0.10516556575894356
Trained batch 30 in epoch 14, gen_loss = 0.3910133954017393, disc_loss = 0.10371529623385399
Trained batch 31 in epoch 14, gen_loss = 0.3926926888525486, disc_loss = 0.10083250654861331
Trained batch 32 in epoch 14, gen_loss = 0.39031283963810315, disc_loss = 0.10039268750132936
Trained batch 33 in epoch 14, gen_loss = 0.39072151394451365, disc_loss = 0.09975040090434692
Trained batch 34 in epoch 14, gen_loss = 0.3903549994741167, disc_loss = 0.10165357547146933
Trained batch 35 in epoch 14, gen_loss = 0.3909336957666609, disc_loss = 0.10394938248727056
Trained batch 36 in epoch 14, gen_loss = 0.38958441405682953, disc_loss = 0.10289622359984629
Trained batch 37 in epoch 14, gen_loss = 0.38715419251667826, disc_loss = 0.10545399314478825
Trained batch 38 in epoch 14, gen_loss = 0.3876805603504181, disc_loss = 0.1062409316117947
Trained batch 39 in epoch 14, gen_loss = 0.3888921454548836, disc_loss = 0.10619399603456259
Trained batch 40 in epoch 14, gen_loss = 0.3869776551316424, disc_loss = 0.10680345518559944
Trained batch 41 in epoch 14, gen_loss = 0.3865936405601956, disc_loss = 0.10511452828844388
Trained batch 42 in epoch 14, gen_loss = 0.38563694302425827, disc_loss = 0.10858428842106531
Trained batch 43 in epoch 14, gen_loss = 0.38489771431142633, disc_loss = 0.11109796759079803
Trained batch 44 in epoch 14, gen_loss = 0.3842713024881151, disc_loss = 0.11040509425931506
Trained batch 45 in epoch 14, gen_loss = 0.38514912581962085, disc_loss = 0.10924512528530929
Trained batch 46 in epoch 14, gen_loss = 0.3849443514296349, disc_loss = 0.108276709200854
Trained batch 47 in epoch 14, gen_loss = 0.3836884306122859, disc_loss = 0.1073536262071381
Trained batch 48 in epoch 14, gen_loss = 0.3831935859456354, disc_loss = 0.10583530875797174
Trained batch 49 in epoch 14, gen_loss = 0.38264382123947144, disc_loss = 0.10638313584029674
Trained batch 50 in epoch 14, gen_loss = 0.3823295890116224, disc_loss = 0.10664431422072299
Trained batch 51 in epoch 14, gen_loss = 0.38333417016726273, disc_loss = 0.10828420484008697
Trained batch 52 in epoch 14, gen_loss = 0.382580521534074, disc_loss = 0.10811466491728458
Trained batch 53 in epoch 14, gen_loss = 0.38253973645192607, disc_loss = 0.10816724522522202
Trained batch 54 in epoch 14, gen_loss = 0.38338721936399284, disc_loss = 0.10798326642675833
Trained batch 55 in epoch 14, gen_loss = 0.38295076681034906, disc_loss = 0.10774926980957389
Trained batch 56 in epoch 14, gen_loss = 0.38301950170282734, disc_loss = 0.10745179176069143
Trained batch 57 in epoch 14, gen_loss = 0.3824739101631888, disc_loss = 0.10614108133675723
Trained batch 58 in epoch 14, gen_loss = 0.3841918216923536, disc_loss = 0.10544566033502757
Trained batch 59 in epoch 14, gen_loss = 0.3850230778257052, disc_loss = 0.10517202025900284
Trained batch 60 in epoch 14, gen_loss = 0.38598147620920276, disc_loss = 0.10453462948808905
Trained batch 61 in epoch 14, gen_loss = 0.38706190211157643, disc_loss = 0.10964971834853772
Trained batch 62 in epoch 14, gen_loss = 0.3855167669909341, disc_loss = 0.1106649169491397
Trained batch 63 in epoch 14, gen_loss = 0.38432322861626744, disc_loss = 0.11032524687470868
Trained batch 64 in epoch 14, gen_loss = 0.38508116602897646, disc_loss = 0.11086313363451224
Trained batch 65 in epoch 14, gen_loss = 0.383746524200295, disc_loss = 0.11048136453962687
Trained batch 66 in epoch 14, gen_loss = 0.3848092400315982, disc_loss = 0.10957385910980737
Trained batch 67 in epoch 14, gen_loss = 0.3861028324155247, disc_loss = 0.10886449394199778
Trained batch 68 in epoch 14, gen_loss = 0.3861459523871325, disc_loss = 0.10846127283529959
Trained batch 69 in epoch 14, gen_loss = 0.3854353334222521, disc_loss = 0.10912525095045567
Trained batch 70 in epoch 14, gen_loss = 0.38633792291224844, disc_loss = 0.10802716447014205
Trained batch 71 in epoch 14, gen_loss = 0.38646845560934806, disc_loss = 0.10878533507800764
Trained batch 72 in epoch 14, gen_loss = 0.38636382393641017, disc_loss = 0.1083175902293153
Trained batch 73 in epoch 14, gen_loss = 0.38578905245742284, disc_loss = 0.10728093639418886
Trained batch 74 in epoch 14, gen_loss = 0.38543994148572286, disc_loss = 0.10645178188880285
Trained batch 75 in epoch 14, gen_loss = 0.3846919685602188, disc_loss = 0.10598418538115527
Trained batch 76 in epoch 14, gen_loss = 0.384927008833204, disc_loss = 0.1054841521885488
Trained batch 77 in epoch 14, gen_loss = 0.3851381181142269, disc_loss = 0.10477706895042689
Trained batch 78 in epoch 14, gen_loss = 0.38485208530969256, disc_loss = 0.10577307141657118
Trained batch 79 in epoch 14, gen_loss = 0.3864519398659468, disc_loss = 0.1088732154108584
Trained batch 80 in epoch 14, gen_loss = 0.3857323244030093, disc_loss = 0.10868045577296505
Trained batch 81 in epoch 14, gen_loss = 0.3846755351235227, disc_loss = 0.11216372106133438
Trained batch 82 in epoch 14, gen_loss = 0.3849000327558403, disc_loss = 0.11188179667455604
Trained batch 83 in epoch 14, gen_loss = 0.3847552647902852, disc_loss = 0.11133152086819921
Trained batch 84 in epoch 14, gen_loss = 0.38363400136723236, disc_loss = 0.11058653435286353
Trained batch 85 in epoch 14, gen_loss = 0.38281791743844057, disc_loss = 0.11150924462911695
Trained batch 86 in epoch 14, gen_loss = 0.38236030388152464, disc_loss = 0.11203113164024792
Trained batch 87 in epoch 14, gen_loss = 0.38285012407736346, disc_loss = 0.1111452764916149
Trained batch 88 in epoch 14, gen_loss = 0.38261712367615003, disc_loss = 0.11062101793757985
Trained batch 89 in epoch 14, gen_loss = 0.38298235701190103, disc_loss = 0.11081019267439843
Trained batch 90 in epoch 14, gen_loss = 0.382136012171651, disc_loss = 0.11164780804416635
Trained batch 91 in epoch 14, gen_loss = 0.3820417290148528, disc_loss = 0.11162642883541792
Trained batch 92 in epoch 14, gen_loss = 0.38180052048416546, disc_loss = 0.11124866800282592
Trained batch 93 in epoch 14, gen_loss = 0.3812464120540213, disc_loss = 0.11070513479570125
Trained batch 94 in epoch 14, gen_loss = 0.38098215868598534, disc_loss = 0.11028942183444375
Trained batch 95 in epoch 14, gen_loss = 0.381705433751146, disc_loss = 0.11083698381359379
Trained batch 96 in epoch 14, gen_loss = 0.38158038227828506, disc_loss = 0.11025271434144876
Trained batch 97 in epoch 14, gen_loss = 0.3810509522350467, disc_loss = 0.10984883008866894
Trained batch 98 in epoch 14, gen_loss = 0.3821832673116164, disc_loss = 0.1094138982771623
Trained batch 99 in epoch 14, gen_loss = 0.38193992763757706, disc_loss = 0.10921429850161075
Trained batch 100 in epoch 14, gen_loss = 0.3808253186173958, disc_loss = 0.11183897435370058
Trained batch 101 in epoch 14, gen_loss = 0.3815021430160485, disc_loss = 0.11098369630966701
Trained batch 102 in epoch 14, gen_loss = 0.38277110225946, disc_loss = 0.11072414719219346
Trained batch 103 in epoch 14, gen_loss = 0.3825170738765827, disc_loss = 0.1101343220171447
Trained batch 104 in epoch 14, gen_loss = 0.38127137337412154, disc_loss = 0.10970082889710153
Trained batch 105 in epoch 14, gen_loss = 0.38074679504025655, disc_loss = 0.10983692555916759
Trained batch 106 in epoch 14, gen_loss = 0.3815567730186142, disc_loss = 0.10923227288316344
Trained batch 107 in epoch 14, gen_loss = 0.3815936142647708, disc_loss = 0.10904669095934541
Trained batch 108 in epoch 14, gen_loss = 0.38137347873197786, disc_loss = 0.10984964036476721
Trained batch 109 in epoch 14, gen_loss = 0.3817526849833402, disc_loss = 0.11141951067203826
Trained batch 110 in epoch 14, gen_loss = 0.38129720118668703, disc_loss = 0.11145819236969089
Trained batch 111 in epoch 14, gen_loss = 0.3813099970242807, disc_loss = 0.11103638185055129
Trained batch 112 in epoch 14, gen_loss = 0.3813075771373985, disc_loss = 0.11087063188969562
Trained batch 113 in epoch 14, gen_loss = 0.3812644675112607, disc_loss = 0.11162691128750642
Trained batch 114 in epoch 14, gen_loss = 0.38127151986827024, disc_loss = 0.11129979513909506
Trained batch 115 in epoch 14, gen_loss = 0.3811002805315215, disc_loss = 0.11077169357831108
Trained batch 116 in epoch 14, gen_loss = 0.380661840367521, disc_loss = 0.11203391280057085
Trained batch 117 in epoch 14, gen_loss = 0.3817359858145148, disc_loss = 0.11430998478021662
Trained batch 118 in epoch 14, gen_loss = 0.3813817636305545, disc_loss = 0.11412511024029315
Trained batch 119 in epoch 14, gen_loss = 0.3810237616300583, disc_loss = 0.11490351405615608
Trained batch 120 in epoch 14, gen_loss = 0.381186938729168, disc_loss = 0.11520981009710919
Trained batch 121 in epoch 14, gen_loss = 0.38165424544303145, disc_loss = 0.11454342333141898
Trained batch 122 in epoch 14, gen_loss = 0.38126592665183834, disc_loss = 0.11452854633694742
Trained batch 123 in epoch 14, gen_loss = 0.38141019041499785, disc_loss = 0.11422078452643848
Trained batch 124 in epoch 14, gen_loss = 0.38213020300865175, disc_loss = 0.1135007639825344
Trained batch 125 in epoch 14, gen_loss = 0.38214070432715946, disc_loss = 0.11305172315665654
Trained batch 126 in epoch 14, gen_loss = 0.3820768766046509, disc_loss = 0.11283472655561026
Trained batch 127 in epoch 14, gen_loss = 0.38242681766860187, disc_loss = 0.1122902239440009
Trained batch 128 in epoch 14, gen_loss = 0.3825163162031839, disc_loss = 0.11192096873771312
Trained batch 129 in epoch 14, gen_loss = 0.38220505049595466, disc_loss = 0.11204248735537896
Trained batch 130 in epoch 14, gen_loss = 0.38237949978304275, disc_loss = 0.11176399710296675
Trained batch 131 in epoch 14, gen_loss = 0.38231518977519235, disc_loss = 0.11110665340145881
Trained batch 132 in epoch 14, gen_loss = 0.3824094663885303, disc_loss = 0.11058927625697806
Trained batch 133 in epoch 14, gen_loss = 0.3823194619434983, disc_loss = 0.11053883007713663
Trained batch 134 in epoch 14, gen_loss = 0.38272475600242617, disc_loss = 0.110310699004266
Trained batch 135 in epoch 14, gen_loss = 0.3827987782218877, disc_loss = 0.11033193593132584
Trained batch 136 in epoch 14, gen_loss = 0.3823937312529905, disc_loss = 0.11208338460402333
Trained batch 137 in epoch 14, gen_loss = 0.3824519178141718, disc_loss = 0.11190512243226386
Trained batch 138 in epoch 14, gen_loss = 0.38261618459825036, disc_loss = 0.11137925663279544
Trained batch 139 in epoch 14, gen_loss = 0.3825486021382468, disc_loss = 0.1109104523302189
Trained batch 140 in epoch 14, gen_loss = 0.3820611927526217, disc_loss = 0.11093997798120299
Trained batch 141 in epoch 14, gen_loss = 0.38248869524875156, disc_loss = 0.11070426822390775
Trained batch 142 in epoch 14, gen_loss = 0.3823464293996771, disc_loss = 0.11028535722696281
Trained batch 143 in epoch 14, gen_loss = 0.38187257655792767, disc_loss = 0.11012829960479091
Trained batch 144 in epoch 14, gen_loss = 0.3819656478947607, disc_loss = 0.11242487097865549
Trained batch 145 in epoch 14, gen_loss = 0.38147936455191, disc_loss = 0.11282406090312216
Trained batch 146 in epoch 14, gen_loss = 0.3814773504831353, disc_loss = 0.11265553195713734
Trained batch 147 in epoch 14, gen_loss = 0.38202959681684906, disc_loss = 0.11277516776494481
Trained batch 148 in epoch 14, gen_loss = 0.3818881503687609, disc_loss = 0.11262300671797071
Trained batch 149 in epoch 14, gen_loss = 0.38154069443543753, disc_loss = 0.11228756764282782
Trained batch 150 in epoch 14, gen_loss = 0.381742282813748, disc_loss = 0.11178330202519104
Trained batch 151 in epoch 14, gen_loss = 0.38210709745946686, disc_loss = 0.11117098403261289
Trained batch 152 in epoch 14, gen_loss = 0.38215402859488345, disc_loss = 0.1106628858259106
Trained batch 153 in epoch 14, gen_loss = 0.38231998604613465, disc_loss = 0.11040590407157486
Trained batch 154 in epoch 14, gen_loss = 0.3829952953323241, disc_loss = 0.10993080089890188
Trained batch 155 in epoch 14, gen_loss = 0.3828385634682117, disc_loss = 0.10950024322105142
Trained batch 156 in epoch 14, gen_loss = 0.38278444291679725, disc_loss = 0.10946585846602157
Trained batch 157 in epoch 14, gen_loss = 0.3823528008747704, disc_loss = 0.10955620275315227
Trained batch 158 in epoch 14, gen_loss = 0.38321215008039894, disc_loss = 0.10933195200965465
Trained batch 159 in epoch 14, gen_loss = 0.38312465529888867, disc_loss = 0.10882202952634543
Trained batch 160 in epoch 14, gen_loss = 0.38306783944923684, disc_loss = 0.10830372855391192
Trained batch 161 in epoch 14, gen_loss = 0.3831801265478134, disc_loss = 0.10788913789768646
Trained batch 162 in epoch 14, gen_loss = 0.38330109554565756, disc_loss = 0.10764067319501763
Trained batch 163 in epoch 14, gen_loss = 0.3825657265942271, disc_loss = 0.1074756482139048
Trained batch 164 in epoch 14, gen_loss = 0.3825858905459895, disc_loss = 0.10738410350273955
Trained batch 165 in epoch 14, gen_loss = 0.38294301442353124, disc_loss = 0.10722638582474137
Trained batch 166 in epoch 14, gen_loss = 0.38314010265344633, disc_loss = 0.10726107033471505
Trained batch 167 in epoch 14, gen_loss = 0.38242302693071817, disc_loss = 0.10698192931401233
Trained batch 168 in epoch 14, gen_loss = 0.3821033415709727, disc_loss = 0.10824325479038016
Trained batch 169 in epoch 14, gen_loss = 0.3825966887614306, disc_loss = 0.10975934890482356
Trained batch 170 in epoch 14, gen_loss = 0.3831950668354481, disc_loss = 0.10918271107522891
Trained batch 171 in epoch 14, gen_loss = 0.3829725166392881, disc_loss = 0.10877581464321634
Trained batch 172 in epoch 14, gen_loss = 0.3830667825448031, disc_loss = 0.10898738440040047
Trained batch 173 in epoch 14, gen_loss = 0.38338410323378685, disc_loss = 0.1090984294330166
Trained batch 174 in epoch 14, gen_loss = 0.38369675278663634, disc_loss = 0.10865762763257537
Trained batch 175 in epoch 14, gen_loss = 0.38374977304854174, disc_loss = 0.10837855373657393
Trained batch 176 in epoch 14, gen_loss = 0.3835315035898133, disc_loss = 0.10857310711727136
Trained batch 177 in epoch 14, gen_loss = 0.38314889856938567, disc_loss = 0.10873989297830489
Trained batch 178 in epoch 14, gen_loss = 0.3833631212151916, disc_loss = 0.10901739957674755
Trained batch 179 in epoch 14, gen_loss = 0.38267588135268954, disc_loss = 0.1091173626223786
Trained batch 180 in epoch 14, gen_loss = 0.38347633882780763, disc_loss = 0.10874915680235755
Trained batch 181 in epoch 14, gen_loss = 0.38395358310950983, disc_loss = 0.10850971590748036
Trained batch 182 in epoch 14, gen_loss = 0.38338679352093263, disc_loss = 0.10890760567405673
Trained batch 183 in epoch 14, gen_loss = 0.38354746851584187, disc_loss = 0.10929867282570542
Trained batch 184 in epoch 14, gen_loss = 0.3833928348244848, disc_loss = 0.10942506304363141
Trained batch 185 in epoch 14, gen_loss = 0.38351751479410356, disc_loss = 0.10950114315135344
Trained batch 186 in epoch 14, gen_loss = 0.3832735347556558, disc_loss = 0.10959590032676803
Trained batch 187 in epoch 14, gen_loss = 0.3834314671285609, disc_loss = 0.1094248775699909
Trained batch 188 in epoch 14, gen_loss = 0.38306265517517374, disc_loss = 0.1090309620445604
Trained batch 189 in epoch 14, gen_loss = 0.3828299851793992, disc_loss = 0.10896781409943575
Trained batch 190 in epoch 14, gen_loss = 0.3832017877651135, disc_loss = 0.10914158463692634
Trained batch 191 in epoch 14, gen_loss = 0.38275240765263635, disc_loss = 0.1088864842458861
Trained batch 192 in epoch 14, gen_loss = 0.38236971485182414, disc_loss = 0.10873864497989416
Trained batch 193 in epoch 14, gen_loss = 0.38228083378875377, disc_loss = 0.1085211784367632
Trained batch 194 in epoch 14, gen_loss = 0.38260739231720947, disc_loss = 0.1089003474236681
Trained batch 195 in epoch 14, gen_loss = 0.3829220942392641, disc_loss = 0.10942618191071159
Trained batch 196 in epoch 14, gen_loss = 0.382988527795385, disc_loss = 0.10932007215936021
Trained batch 197 in epoch 14, gen_loss = 0.3833410619485258, disc_loss = 0.10892360128292983
Trained batch 198 in epoch 14, gen_loss = 0.38348032646442776, disc_loss = 0.10861273289157368
Trained batch 199 in epoch 14, gen_loss = 0.38383245170116426, disc_loss = 0.10845321893226355
Trained batch 200 in epoch 14, gen_loss = 0.38407630914479346, disc_loss = 0.10903309129493598
Trained batch 201 in epoch 14, gen_loss = 0.38395240652089074, disc_loss = 0.10896756377827266
Trained batch 202 in epoch 14, gen_loss = 0.3839208520398351, disc_loss = 0.10861565308012251
Trained batch 203 in epoch 14, gen_loss = 0.3836989623366618, disc_loss = 0.10820234159245064
Trained batch 204 in epoch 14, gen_loss = 0.3835596196535157, disc_loss = 0.10802302947040739
Trained batch 205 in epoch 14, gen_loss = 0.3837431738677534, disc_loss = 0.10820074760563021
Trained batch 206 in epoch 14, gen_loss = 0.383478680094659, disc_loss = 0.10822384823833543
Trained batch 207 in epoch 14, gen_loss = 0.38397785577063376, disc_loss = 0.10784827989006701
Trained batch 208 in epoch 14, gen_loss = 0.3842392070441725, disc_loss = 0.1076984093190309
Trained batch 209 in epoch 14, gen_loss = 0.38431392170134043, disc_loss = 0.1078217915791486
Trained batch 210 in epoch 14, gen_loss = 0.3842957827717207, disc_loss = 0.1074492747440793
Trained batch 211 in epoch 14, gen_loss = 0.3845397399843864, disc_loss = 0.10710615955099885
Trained batch 212 in epoch 14, gen_loss = 0.3846367375111916, disc_loss = 0.10701431976325215
Trained batch 213 in epoch 14, gen_loss = 0.3847153444434995, disc_loss = 0.10728562879593712
Trained batch 214 in epoch 14, gen_loss = 0.38436388567436575, disc_loss = 0.10759288182178903
Trained batch 215 in epoch 14, gen_loss = 0.38428481447475926, disc_loss = 0.10754455196998876
Trained batch 216 in epoch 14, gen_loss = 0.3840631364677359, disc_loss = 0.10853639765629708
Trained batch 217 in epoch 14, gen_loss = 0.3845134471808005, disc_loss = 0.10973754113779292
Trained batch 218 in epoch 14, gen_loss = 0.38499206290941806, disc_loss = 0.10946155193614769
Trained batch 219 in epoch 14, gen_loss = 0.3847663941708478, disc_loss = 0.10964192897504703
Trained batch 220 in epoch 14, gen_loss = 0.3846842963501339, disc_loss = 0.10924224862702427
Trained batch 221 in epoch 14, gen_loss = 0.38490366506146956, disc_loss = 0.10890503629186266
Trained batch 222 in epoch 14, gen_loss = 0.38457719440417437, disc_loss = 0.10890072943734615
Trained batch 223 in epoch 14, gen_loss = 0.3844301679304668, disc_loss = 0.10966965049322296
Trained batch 224 in epoch 14, gen_loss = 0.3844825005531311, disc_loss = 0.10975495145138767
Trained batch 225 in epoch 14, gen_loss = 0.3844783565903132, disc_loss = 0.10987125593031534
Trained batch 226 in epoch 14, gen_loss = 0.38449405271576365, disc_loss = 0.10996680170510965
Trained batch 227 in epoch 14, gen_loss = 0.38432360518919795, disc_loss = 0.10993228498601208
Trained batch 228 in epoch 14, gen_loss = 0.3843603521975888, disc_loss = 0.10981347736003748
Trained batch 229 in epoch 14, gen_loss = 0.3844207216864047, disc_loss = 0.1094830991335861
Trained batch 230 in epoch 14, gen_loss = 0.3843690843293161, disc_loss = 0.10924525198111415
Trained batch 231 in epoch 14, gen_loss = 0.3844018343450694, disc_loss = 0.1089225053056625
Trained batch 232 in epoch 14, gen_loss = 0.38444307113921694, disc_loss = 0.10877179716166124
Trained batch 233 in epoch 14, gen_loss = 0.3844031073853501, disc_loss = 0.10842547270779808
Trained batch 234 in epoch 14, gen_loss = 0.38484335465634123, disc_loss = 0.1085233325455734
Trained batch 235 in epoch 14, gen_loss = 0.3844133301054017, disc_loss = 0.10869421631145149
Trained batch 236 in epoch 14, gen_loss = 0.3845736735229251, disc_loss = 0.10835822771857434
Trained batch 237 in epoch 14, gen_loss = 0.3847105734738983, disc_loss = 0.10815767810421706
Trained batch 238 in epoch 14, gen_loss = 0.3848966337646899, disc_loss = 0.10789759685850418
Trained batch 239 in epoch 14, gen_loss = 0.38460106402635574, disc_loss = 0.10761816172162071
Trained batch 240 in epoch 14, gen_loss = 0.3846027010209333, disc_loss = 0.10760265000983764
Trained batch 241 in epoch 14, gen_loss = 0.3843063497838895, disc_loss = 0.10779179669223911
Trained batch 242 in epoch 14, gen_loss = 0.38428864655671297, disc_loss = 0.10754316822537546
Trained batch 243 in epoch 14, gen_loss = 0.38461590020871556, disc_loss = 0.10716199137453662
Trained batch 244 in epoch 14, gen_loss = 0.38459443097211876, disc_loss = 0.10688143509383104
Trained batch 245 in epoch 14, gen_loss = 0.3850827287367689, disc_loss = 0.1067317772384097
Trained batch 246 in epoch 14, gen_loss = 0.3850806529222712, disc_loss = 0.10641300263494133
Trained batch 247 in epoch 14, gen_loss = 0.3851545873668886, disc_loss = 0.10621326974022292
Trained batch 248 in epoch 14, gen_loss = 0.3854050479500169, disc_loss = 0.10614350301972833
Trained batch 249 in epoch 14, gen_loss = 0.38527720713615415, disc_loss = 0.10604111455380917
Trained batch 250 in epoch 14, gen_loss = 0.385181655565581, disc_loss = 0.10610484561894044
Trained batch 251 in epoch 14, gen_loss = 0.3850503795676761, disc_loss = 0.1064642502349757
Trained batch 252 in epoch 14, gen_loss = 0.3854654278208616, disc_loss = 0.10659353595536217
Trained batch 253 in epoch 14, gen_loss = 0.3857273333889293, disc_loss = 0.10623311334634274
Trained batch 254 in epoch 14, gen_loss = 0.38536589461214404, disc_loss = 0.1058774336916851
Trained batch 255 in epoch 14, gen_loss = 0.3853036977816373, disc_loss = 0.10569662938723923
Trained batch 256 in epoch 14, gen_loss = 0.3852418795633873, disc_loss = 0.10548846529803967
Trained batch 257 in epoch 14, gen_loss = 0.385461321288301, disc_loss = 0.1051690344150041
Trained batch 258 in epoch 14, gen_loss = 0.38552056834044146, disc_loss = 0.10512807757079486
Trained batch 259 in epoch 14, gen_loss = 0.38590343181903547, disc_loss = 0.10528151007870643
Trained batch 260 in epoch 14, gen_loss = 0.3857258591387007, disc_loss = 0.10533352226547012
Trained batch 261 in epoch 14, gen_loss = 0.3860445377480893, disc_loss = 0.10505594232453759
Trained batch 262 in epoch 14, gen_loss = 0.3860829838555122, disc_loss = 0.10506128272247064
Trained batch 263 in epoch 14, gen_loss = 0.38588593888914946, disc_loss = 0.1054063056574457
Trained batch 264 in epoch 14, gen_loss = 0.3859865741909675, disc_loss = 0.10512907612225357
Trained batch 265 in epoch 14, gen_loss = 0.3860698429713572, disc_loss = 0.10586633824890382
Trained batch 266 in epoch 14, gen_loss = 0.3861748481287938, disc_loss = 0.10593204250845235
Trained batch 267 in epoch 14, gen_loss = 0.3864070192646624, disc_loss = 0.10562664391681441
Trained batch 268 in epoch 14, gen_loss = 0.38658683993559345, disc_loss = 0.10541747586947059
Trained batch 269 in epoch 14, gen_loss = 0.38654829131232366, disc_loss = 0.10532031455594633
Trained batch 270 in epoch 14, gen_loss = 0.3861125277637116, disc_loss = 0.10603759164588587
Trained batch 271 in epoch 14, gen_loss = 0.3864245477187283, disc_loss = 0.10663273162550896
Trained batch 272 in epoch 14, gen_loss = 0.38649068025005606, disc_loss = 0.10650314558843225
Trained batch 273 in epoch 14, gen_loss = 0.38635413370428295, disc_loss = 0.10655951063848869
Trained batch 274 in epoch 14, gen_loss = 0.3862686573375355, disc_loss = 0.10641135613010688
Trained batch 275 in epoch 14, gen_loss = 0.3865544957959134, disc_loss = 0.10619870641106821
Trained batch 276 in epoch 14, gen_loss = 0.3867431154965494, disc_loss = 0.10596521805622194
Trained batch 277 in epoch 14, gen_loss = 0.38692474311633074, disc_loss = 0.10583343106596697
Trained batch 278 in epoch 14, gen_loss = 0.3869351115491655, disc_loss = 0.10595086581778035
Trained batch 279 in epoch 14, gen_loss = 0.38697208549295153, disc_loss = 0.1058855864252629
Trained batch 280 in epoch 14, gen_loss = 0.38682823058124965, disc_loss = 0.10610635935584103
Trained batch 281 in epoch 14, gen_loss = 0.38694233357483615, disc_loss = 0.10587358076112173
Trained batch 282 in epoch 14, gen_loss = 0.38735551652975725, disc_loss = 0.10633186056433318
Trained batch 283 in epoch 14, gen_loss = 0.38700928570519033, disc_loss = 0.10707767153303073
Trained batch 284 in epoch 14, gen_loss = 0.38678623688848396, disc_loss = 0.10699911313948401
Trained batch 285 in epoch 14, gen_loss = 0.3866887414580458, disc_loss = 0.1070004862381497
Trained batch 286 in epoch 14, gen_loss = 0.38659872670206874, disc_loss = 0.10704877926198966
Trained batch 287 in epoch 14, gen_loss = 0.38641343928045696, disc_loss = 0.1069204867073697
Trained batch 288 in epoch 14, gen_loss = 0.3866067961838006, disc_loss = 0.10665274964110559
Trained batch 289 in epoch 14, gen_loss = 0.38652174534468814, disc_loss = 0.10655008763524479
Trained batch 290 in epoch 14, gen_loss = 0.38652845152055276, disc_loss = 0.10642736426577024
Trained batch 291 in epoch 14, gen_loss = 0.3866725674230758, disc_loss = 0.10652372142465862
Trained batch 292 in epoch 14, gen_loss = 0.3864119123069906, disc_loss = 0.1071244606735509
Trained batch 293 in epoch 14, gen_loss = 0.38652583683023645, disc_loss = 0.1076424419214683
Trained batch 294 in epoch 14, gen_loss = 0.3863010548939139, disc_loss = 0.10741096224509558
Trained batch 295 in epoch 14, gen_loss = 0.3862485688280415, disc_loss = 0.10804455842810205
Trained batch 296 in epoch 14, gen_loss = 0.3862523943286151, disc_loss = 0.10802378239241814
Trained batch 297 in epoch 14, gen_loss = 0.3862249476197582, disc_loss = 0.10800680350324751
Trained batch 298 in epoch 14, gen_loss = 0.3862119149603573, disc_loss = 0.10796274595822279
Trained batch 299 in epoch 14, gen_loss = 0.385990229845047, disc_loss = 0.10796128396876156
Trained batch 300 in epoch 14, gen_loss = 0.3858261953952701, disc_loss = 0.1081468416377902
Trained batch 301 in epoch 14, gen_loss = 0.38574519033068855, disc_loss = 0.1081645244713996
Trained batch 302 in epoch 14, gen_loss = 0.3858696241976798, disc_loss = 0.10786363787076163
Trained batch 303 in epoch 14, gen_loss = 0.38588657083087846, disc_loss = 0.10766362693883773
Trained batch 304 in epoch 14, gen_loss = 0.3856876338114504, disc_loss = 0.1074470064648595
Trained batch 305 in epoch 14, gen_loss = 0.38579605354203117, disc_loss = 0.10725501885491551
Trained batch 306 in epoch 14, gen_loss = 0.38574657824606384, disc_loss = 0.10722031325089718
Trained batch 307 in epoch 14, gen_loss = 0.3859918535529793, disc_loss = 0.10777602905661544
Trained batch 308 in epoch 14, gen_loss = 0.38599963375279817, disc_loss = 0.10782616893824154
Trained batch 309 in epoch 14, gen_loss = 0.38582956242945887, disc_loss = 0.10769376353090329
Trained batch 310 in epoch 14, gen_loss = 0.3858017224782533, disc_loss = 0.10742718809347157
Trained batch 311 in epoch 14, gen_loss = 0.38586767982596004, disc_loss = 0.10722594887603265
Trained batch 312 in epoch 14, gen_loss = 0.3857350938807661, disc_loss = 0.10698067732214832
Trained batch 313 in epoch 14, gen_loss = 0.3856226478222829, disc_loss = 0.10687154597620581
Trained batch 314 in epoch 14, gen_loss = 0.38590734184734404, disc_loss = 0.10668800977901334
Trained batch 315 in epoch 14, gen_loss = 0.385961762334727, disc_loss = 0.10654503804678687
Trained batch 316 in epoch 14, gen_loss = 0.3859229650031129, disc_loss = 0.10654041772467387
Trained batch 317 in epoch 14, gen_loss = 0.3858374888604542, disc_loss = 0.10670168645996249
Trained batch 318 in epoch 14, gen_loss = 0.38622643478611796, disc_loss = 0.10719279318662553
Trained batch 319 in epoch 14, gen_loss = 0.3862107929773629, disc_loss = 0.10712962639227044
Trained batch 320 in epoch 14, gen_loss = 0.38616808608313585, disc_loss = 0.107813244340274
Trained batch 321 in epoch 14, gen_loss = 0.3862382863989528, disc_loss = 0.10759839917365346
Trained batch 322 in epoch 14, gen_loss = 0.38637886235588476, disc_loss = 0.10745137392171304
Trained batch 323 in epoch 14, gen_loss = 0.38640219938975795, disc_loss = 0.10732759128002749
Trained batch 324 in epoch 14, gen_loss = 0.3861190451108492, disc_loss = 0.10753574643857204
Trained batch 325 in epoch 14, gen_loss = 0.3860958820106062, disc_loss = 0.10732840522380968
Trained batch 326 in epoch 14, gen_loss = 0.38627240909348937, disc_loss = 0.1072470558955354
Trained batch 327 in epoch 14, gen_loss = 0.38605184180707464, disc_loss = 0.10743481415698714
Trained batch 328 in epoch 14, gen_loss = 0.3860340153736184, disc_loss = 0.10774191439231025
Trained batch 329 in epoch 14, gen_loss = 0.3858025622187239, disc_loss = 0.10799645243889906
Trained batch 330 in epoch 14, gen_loss = 0.3859108065190272, disc_loss = 0.10794218368209291
Trained batch 331 in epoch 14, gen_loss = 0.38596678525209427, disc_loss = 0.10795856583358562
Trained batch 332 in epoch 14, gen_loss = 0.3858916815873739, disc_loss = 0.10787092057244108
Trained batch 333 in epoch 14, gen_loss = 0.3859997500559527, disc_loss = 0.1076401187313308
Trained batch 334 in epoch 14, gen_loss = 0.3861078212510294, disc_loss = 0.10745326164665062
Trained batch 335 in epoch 14, gen_loss = 0.3861338992913564, disc_loss = 0.10727588158001058
Trained batch 336 in epoch 14, gen_loss = 0.38615308308459884, disc_loss = 0.10709148083567531
Trained batch 337 in epoch 14, gen_loss = 0.38619918027925776, disc_loss = 0.10727112228601907
Trained batch 338 in epoch 14, gen_loss = 0.38653738458248016, disc_loss = 0.10787985506563676
Trained batch 339 in epoch 14, gen_loss = 0.3864924260798623, disc_loss = 0.10766869550844764
Trained batch 340 in epoch 14, gen_loss = 0.38637786736586227, disc_loss = 0.1081461219903617
Trained batch 341 in epoch 14, gen_loss = 0.3866841558650223, disc_loss = 0.10841214456132542
Trained batch 342 in epoch 14, gen_loss = 0.3868547541580812, disc_loss = 0.10819194032254006
Trained batch 343 in epoch 14, gen_loss = 0.3866346365837164, disc_loss = 0.10829902976090738
Trained batch 344 in epoch 14, gen_loss = 0.3866289876509404, disc_loss = 0.10833062593001819
Trained batch 345 in epoch 14, gen_loss = 0.38648825780504703, disc_loss = 0.10812005630796613
Trained batch 346 in epoch 14, gen_loss = 0.3861335211081876, disc_loss = 0.10815492926986743
Trained batch 347 in epoch 14, gen_loss = 0.3860999246438344, disc_loss = 0.10807462601558487
Trained batch 348 in epoch 14, gen_loss = 0.3861741205853514, disc_loss = 0.10800777302846783
Trained batch 349 in epoch 14, gen_loss = 0.3858981613601957, disc_loss = 0.10796091647818684
Trained batch 350 in epoch 14, gen_loss = 0.3857118542547579, disc_loss = 0.10787022998689162
Trained batch 351 in epoch 14, gen_loss = 0.38570341594855895, disc_loss = 0.10778168730427172
Trained batch 352 in epoch 14, gen_loss = 0.38560076872620297, disc_loss = 0.10765749367782397
Trained batch 353 in epoch 14, gen_loss = 0.3852634284287523, disc_loss = 0.10770895331834922
Trained batch 354 in epoch 14, gen_loss = 0.38525635314659334, disc_loss = 0.10773227638499418
Trained batch 355 in epoch 14, gen_loss = 0.3851892159561093, disc_loss = 0.10763368839031776
Trained batch 356 in epoch 14, gen_loss = 0.38522596085438876, disc_loss = 0.10742870465453182
Trained batch 357 in epoch 14, gen_loss = 0.3853322192610309, disc_loss = 0.10728542248369845
Trained batch 358 in epoch 14, gen_loss = 0.38520824444327184, disc_loss = 0.10728298546616663
Trained batch 359 in epoch 14, gen_loss = 0.38527712292141386, disc_loss = 0.10720424906402412
Trained batch 360 in epoch 14, gen_loss = 0.38514642702245316, disc_loss = 0.10695743914487206
Trained batch 361 in epoch 14, gen_loss = 0.3850429040786311, disc_loss = 0.10673123446565883
Trained batch 362 in epoch 14, gen_loss = 0.384890870203985, disc_loss = 0.10661977308625278
Trained batch 363 in epoch 14, gen_loss = 0.38515888662128656, disc_loss = 0.10640240263879545
Trained batch 364 in epoch 14, gen_loss = 0.3852258977008193, disc_loss = 0.10640619825571776
Trained batch 365 in epoch 14, gen_loss = 0.38503169125872233, disc_loss = 0.10630190307070893
Trained batch 366 in epoch 14, gen_loss = 0.38468532714921705, disc_loss = 0.10647304546676718
Trained batch 367 in epoch 14, gen_loss = 0.3847055291837972, disc_loss = 0.10661194651418002
Trained batch 368 in epoch 14, gen_loss = 0.3847685804373527, disc_loss = 0.10666161640055054
Trained batch 369 in epoch 14, gen_loss = 0.38485854115035084, disc_loss = 0.10661778264502819
Trained batch 370 in epoch 14, gen_loss = 0.3849488604422207, disc_loss = 0.1065205284180948
Trained batch 371 in epoch 14, gen_loss = 0.3848417286751091, disc_loss = 0.10668574257313164
Trained batch 372 in epoch 14, gen_loss = 0.3849812006982338, disc_loss = 0.10666613993621943
Trained batch 373 in epoch 14, gen_loss = 0.3849969804286957, disc_loss = 0.10646864964830924
Trained batch 374 in epoch 14, gen_loss = 0.38481320754686993, disc_loss = 0.1064823694601655
Trained batch 375 in epoch 14, gen_loss = 0.3848163141532147, disc_loss = 0.10629470350884615
Trained batch 376 in epoch 14, gen_loss = 0.38493743388659124, disc_loss = 0.10609105799287874
Trained batch 377 in epoch 14, gen_loss = 0.3849447229236522, disc_loss = 0.10599839601360223
Trained batch 378 in epoch 14, gen_loss = 0.38511830859259755, disc_loss = 0.10591571055362517
Trained batch 379 in epoch 14, gen_loss = 0.38509824573993684, disc_loss = 0.1059773386186479
Trained batch 380 in epoch 14, gen_loss = 0.3850926152990246, disc_loss = 0.10641294020396752
Trained batch 381 in epoch 14, gen_loss = 0.38533250636455274, disc_loss = 0.10635107325350973
Trained batch 382 in epoch 14, gen_loss = 0.38540834624213277, disc_loss = 0.10618767343393427
Trained batch 383 in epoch 14, gen_loss = 0.38539582227046293, disc_loss = 0.1062670044945359
Trained batch 384 in epoch 14, gen_loss = 0.3854501257469128, disc_loss = 0.10604388372996798
Trained batch 385 in epoch 14, gen_loss = 0.385771981406706, disc_loss = 0.10592848147202881
Trained batch 386 in epoch 14, gen_loss = 0.38582548714731396, disc_loss = 0.10589600810468273
Trained batch 387 in epoch 14, gen_loss = 0.3859527740128261, disc_loss = 0.10567814037539833
Trained batch 388 in epoch 14, gen_loss = 0.3862474417471947, disc_loss = 0.10552313762709767
Trained batch 389 in epoch 14, gen_loss = 0.38629126418859533, disc_loss = 0.10591174455550618
Trained batch 390 in epoch 14, gen_loss = 0.3866560522400205, disc_loss = 0.10636154914517766
Trained batch 391 in epoch 14, gen_loss = 0.38698456687282545, disc_loss = 0.10619766194591945
Trained batch 392 in epoch 14, gen_loss = 0.3870525325982625, disc_loss = 0.10604958872976725
Trained batch 393 in epoch 14, gen_loss = 0.38695776364222395, disc_loss = 0.10585635652538711
Trained batch 394 in epoch 14, gen_loss = 0.3869423788559588, disc_loss = 0.10575647150178122
Trained batch 395 in epoch 14, gen_loss = 0.3870715501182007, disc_loss = 0.10584688028367707
Trained batch 396 in epoch 14, gen_loss = 0.38710547807234663, disc_loss = 0.10570384488588842
Trained batch 397 in epoch 14, gen_loss = 0.38718798621815054, disc_loss = 0.10555419392050736
Trained batch 398 in epoch 14, gen_loss = 0.3873277864509955, disc_loss = 0.10540170660172414
Trained batch 399 in epoch 14, gen_loss = 0.3873948335647583, disc_loss = 0.10529358270345256
Trained batch 400 in epoch 14, gen_loss = 0.3875071583246055, disc_loss = 0.10539261285828756
Trained batch 401 in epoch 14, gen_loss = 0.38769683575452263, disc_loss = 0.10534167599943073
Trained batch 402 in epoch 14, gen_loss = 0.3873971924000875, disc_loss = 0.10578241810045452
Trained batch 403 in epoch 14, gen_loss = 0.3876402960112779, disc_loss = 0.10665269084228664
Trained batch 404 in epoch 14, gen_loss = 0.38765330218974453, disc_loss = 0.10652825744753634
Trained batch 405 in epoch 14, gen_loss = 0.38735611266984143, disc_loss = 0.10684062548559801
Trained batch 406 in epoch 14, gen_loss = 0.38744564123762915, disc_loss = 0.10669674792759468
Trained batch 407 in epoch 14, gen_loss = 0.3874352192323582, disc_loss = 0.10658265601651852
Trained batch 408 in epoch 14, gen_loss = 0.38731634245233604, disc_loss = 0.1063963961480117
Trained batch 409 in epoch 14, gen_loss = 0.3871423550495287, disc_loss = 0.10630923453945576
Trained batch 410 in epoch 14, gen_loss = 0.3870404920293757, disc_loss = 0.10613302994120657
Trained batch 411 in epoch 14, gen_loss = 0.38708562346048725, disc_loss = 0.10603611831987295
Trained batch 412 in epoch 14, gen_loss = 0.386996562198057, disc_loss = 0.10588879375233705
Trained batch 413 in epoch 14, gen_loss = 0.38711724419524707, disc_loss = 0.1057294577355654
Trained batch 414 in epoch 14, gen_loss = 0.3872855750193079, disc_loss = 0.10559130590857871
Trained batch 415 in epoch 14, gen_loss = 0.3874741257526554, disc_loss = 0.10539257410206258
Trained batch 416 in epoch 14, gen_loss = 0.3873763880569586, disc_loss = 0.10526455369078927
Trained batch 417 in epoch 14, gen_loss = 0.38735703952860034, disc_loss = 0.10522657893286154
Trained batch 418 in epoch 14, gen_loss = 0.38745150610199974, disc_loss = 0.10513358629199727
Trained batch 419 in epoch 14, gen_loss = 0.3876878177126249, disc_loss = 0.10500117873196446
Trained batch 420 in epoch 14, gen_loss = 0.3875423647162467, disc_loss = 0.10488218117965444
Trained batch 421 in epoch 14, gen_loss = 0.387579328146591, disc_loss = 0.1048911242410364
Trained batch 422 in epoch 14, gen_loss = 0.38783629030764244, disc_loss = 0.10499254217146771
Trained batch 423 in epoch 14, gen_loss = 0.3878413589917264, disc_loss = 0.1048707220514463
Trained batch 424 in epoch 14, gen_loss = 0.38776403574382556, disc_loss = 0.10465665306457701
Trained batch 425 in epoch 14, gen_loss = 0.38790140899134357, disc_loss = 0.10446939618051262
Trained batch 426 in epoch 14, gen_loss = 0.38777766901938643, disc_loss = 0.1043322506214577
Trained batch 427 in epoch 14, gen_loss = 0.38760500227179484, disc_loss = 0.10425324124179641
Trained batch 428 in epoch 14, gen_loss = 0.3875210261567211, disc_loss = 0.10417095904123463
Trained batch 429 in epoch 14, gen_loss = 0.38768470779407854, disc_loss = 0.10406344224330644
Trained batch 430 in epoch 14, gen_loss = 0.3878170084510768, disc_loss = 0.10391710753706035
Trained batch 431 in epoch 14, gen_loss = 0.3878199549874774, disc_loss = 0.10395255563910016
Trained batch 432 in epoch 14, gen_loss = 0.3878387284333932, disc_loss = 0.10417862102071009
Trained batch 433 in epoch 14, gen_loss = 0.3879359159189435, disc_loss = 0.1041043627007182
Trained batch 434 in epoch 14, gen_loss = 0.38778485176207006, disc_loss = 0.10395531534249412
Trained batch 435 in epoch 14, gen_loss = 0.3877149410887596, disc_loss = 0.10392134499719041
Trained batch 436 in epoch 14, gen_loss = 0.3879673283896675, disc_loss = 0.10386254525694408
Trained batch 437 in epoch 14, gen_loss = 0.38784188957519183, disc_loss = 0.10380698024129419
Trained batch 438 in epoch 14, gen_loss = 0.3878622579140109, disc_loss = 0.1036902763573177
Trained batch 439 in epoch 14, gen_loss = 0.38799054195935073, disc_loss = 0.10352665654764595
Trained batch 440 in epoch 14, gen_loss = 0.38771559673101724, disc_loss = 0.10363379473715616
Trained batch 441 in epoch 14, gen_loss = 0.3879165857086354, disc_loss = 0.1038755904777793
Trained batch 442 in epoch 14, gen_loss = 0.3878402814908168, disc_loss = 0.10377105772621409
Trained batch 443 in epoch 14, gen_loss = 0.3877774570305068, disc_loss = 0.10409851283095106
Trained batch 444 in epoch 14, gen_loss = 0.3877303338452671, disc_loss = 0.1040047751279192
Trained batch 445 in epoch 14, gen_loss = 0.3877111696742575, disc_loss = 0.10381336205517831
Trained batch 446 in epoch 14, gen_loss = 0.38776051618108814, disc_loss = 0.10366010768609893
Trained batch 447 in epoch 14, gen_loss = 0.38765868577840074, disc_loss = 0.1035158646097573
Trained batch 448 in epoch 14, gen_loss = 0.38761554449332053, disc_loss = 0.10357576933272498
Trained batch 449 in epoch 14, gen_loss = 0.38786024490992227, disc_loss = 0.10363700375995702
Trained batch 450 in epoch 14, gen_loss = 0.3879363949838076, disc_loss = 0.10364441383018792
Trained batch 451 in epoch 14, gen_loss = 0.3878197301409941, disc_loss = 0.10393660229762637
Trained batch 452 in epoch 14, gen_loss = 0.3880406663512552, disc_loss = 0.10436508458551784
Trained batch 453 in epoch 14, gen_loss = 0.3880070693429871, disc_loss = 0.10427217217703813
Trained batch 454 in epoch 14, gen_loss = 0.38785967990592285, disc_loss = 0.10445708825078967
Trained batch 455 in epoch 14, gen_loss = 0.38798020871584876, disc_loss = 0.10434143742946744
Trained batch 456 in epoch 14, gen_loss = 0.3880660035025891, disc_loss = 0.10416828124647394
Trained batch 457 in epoch 14, gen_loss = 0.3880679851406006, disc_loss = 0.10399729563899371
Trained batch 458 in epoch 14, gen_loss = 0.3877072390128325, disc_loss = 0.10497931773066196
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.3197861611843109, disc_loss = 0.5600184798240662
Trained batch 1 in epoch 15, gen_loss = 0.33948157727718353, disc_loss = 0.3133559897542
Trained batch 2 in epoch 15, gen_loss = 0.3624839286009471, disc_loss = 0.2452038253347079
Trained batch 3 in epoch 15, gen_loss = 0.3501238226890564, disc_loss = 0.19801544956862926
Trained batch 4 in epoch 15, gen_loss = 0.3554125547409058, disc_loss = 0.1760122984647751
Trained batch 5 in epoch 15, gen_loss = 0.3643415868282318, disc_loss = 0.15502935399611792
Trained batch 6 in epoch 15, gen_loss = 0.3696074868951525, disc_loss = 0.13761602342128754
Trained batch 7 in epoch 15, gen_loss = 0.36394141986966133, disc_loss = 0.12654760852456093
Trained batch 8 in epoch 15, gen_loss = 0.3640529347790612, disc_loss = 0.1246373090479109
Trained batch 9 in epoch 15, gen_loss = 0.3652767091989517, disc_loss = 0.12398389056324959
Trained batch 10 in epoch 15, gen_loss = 0.36708364161578094, disc_loss = 0.1231466755270958
Trained batch 11 in epoch 15, gen_loss = 0.368154413998127, disc_loss = 0.1203407421708107
Trained batch 12 in epoch 15, gen_loss = 0.37142659838383013, disc_loss = 0.1169824221959481
Trained batch 13 in epoch 15, gen_loss = 0.36879719368049074, disc_loss = 0.12076051320348467
Trained batch 14 in epoch 15, gen_loss = 0.3634780506292979, disc_loss = 0.12112796703974406
Trained batch 15 in epoch 15, gen_loss = 0.3673887215554714, disc_loss = 0.12765398528426886
Trained batch 16 in epoch 15, gen_loss = 0.36344249108258414, disc_loss = 0.1392848377718645
Trained batch 17 in epoch 15, gen_loss = 0.3624838872088326, disc_loss = 0.13709975199566948
Trained batch 18 in epoch 15, gen_loss = 0.3693974488659909, disc_loss = 0.1384998818761424
Trained batch 19 in epoch 15, gen_loss = 0.3726165726780891, disc_loss = 0.13520288318395615
Trained batch 20 in epoch 15, gen_loss = 0.37677140604882015, disc_loss = 0.1309949638588088
Trained batch 21 in epoch 15, gen_loss = 0.3712445998733694, disc_loss = 0.13437708162448622
Trained batch 22 in epoch 15, gen_loss = 0.37170017672621686, disc_loss = 0.13851111447033676
Trained batch 23 in epoch 15, gen_loss = 0.3705410373707612, disc_loss = 0.1368361609056592
Trained batch 24 in epoch 15, gen_loss = 0.3742015588283539, disc_loss = 0.13394375056028365
Trained batch 25 in epoch 15, gen_loss = 0.37786035812818086, disc_loss = 0.13277719026574722
Trained batch 26 in epoch 15, gen_loss = 0.3763107226954566, disc_loss = 0.13207462871516193
Trained batch 27 in epoch 15, gen_loss = 0.378120203103338, disc_loss = 0.13192836567759514
Trained batch 28 in epoch 15, gen_loss = 0.3736779987812042, disc_loss = 0.1293267558874755
Trained batch 29 in epoch 15, gen_loss = 0.3707115123669306, disc_loss = 0.1280837873617808
Trained batch 30 in epoch 15, gen_loss = 0.3713519198279227, disc_loss = 0.1322191386453567
Trained batch 31 in epoch 15, gen_loss = 0.3696547159925103, disc_loss = 0.1354049169458449
Trained batch 32 in epoch 15, gen_loss = 0.3729327926130006, disc_loss = 0.1328267694422693
Trained batch 33 in epoch 15, gen_loss = 0.3737770923796822, disc_loss = 0.1331825869924882
Trained batch 34 in epoch 15, gen_loss = 0.37286407692091805, disc_loss = 0.1319520224417959
Trained batch 35 in epoch 15, gen_loss = 0.3720594305131171, disc_loss = 0.12904132074779934
Trained batch 36 in epoch 15, gen_loss = 0.3730757027058988, disc_loss = 0.12642048752388438
Trained batch 37 in epoch 15, gen_loss = 0.3732142393526278, disc_loss = 0.12449446595028828
Trained batch 38 in epoch 15, gen_loss = 0.3744133642086616, disc_loss = 0.12189071701887326
Trained batch 39 in epoch 15, gen_loss = 0.3750621497631073, disc_loss = 0.12138637099415064
Trained batch 40 in epoch 15, gen_loss = 0.374837809219593, disc_loss = 0.1238030575034095
Trained batch 41 in epoch 15, gen_loss = 0.3754417520193827, disc_loss = 0.12483847159005347
Trained batch 42 in epoch 15, gen_loss = 0.3763438754303511, disc_loss = 0.12234747089272321
Trained batch 43 in epoch 15, gen_loss = 0.3731695471162146, disc_loss = 0.12438420875167305
Trained batch 44 in epoch 15, gen_loss = 0.37429599662621815, disc_loss = 0.12856717366311285
Trained batch 45 in epoch 15, gen_loss = 0.373764199083266, disc_loss = 0.12668107992605024
Trained batch 46 in epoch 15, gen_loss = 0.3731662025477024, disc_loss = 0.1259661522158917
Trained batch 47 in epoch 15, gen_loss = 0.374310246668756, disc_loss = 0.12447568114536504
Trained batch 48 in epoch 15, gen_loss = 0.3724896369539962, disc_loss = 0.1240849077549516
Trained batch 49 in epoch 15, gen_loss = 0.37245447307825086, disc_loss = 0.12414143435657024
Trained batch 50 in epoch 15, gen_loss = 0.3725012496990316, disc_loss = 0.12249255830458566
Trained batch 51 in epoch 15, gen_loss = 0.3731506441075068, disc_loss = 0.1212501972913742
Trained batch 52 in epoch 15, gen_loss = 0.3738879581105034, disc_loss = 0.11957759916220072
Trained batch 53 in epoch 15, gen_loss = 0.37508762186324157, disc_loss = 0.11835088325595414
Trained batch 54 in epoch 15, gen_loss = 0.37312782379713927, disc_loss = 0.1188003547489643
Trained batch 55 in epoch 15, gen_loss = 0.37394706399313044, disc_loss = 0.11906849958800844
Trained batch 56 in epoch 15, gen_loss = 0.373482677235938, disc_loss = 0.11981754390555516
Trained batch 57 in epoch 15, gen_loss = 0.3756640741023524, disc_loss = 0.11840067270757823
Trained batch 58 in epoch 15, gen_loss = 0.3760788564459752, disc_loss = 0.11754143067588241
Trained batch 59 in epoch 15, gen_loss = 0.3754073686897755, disc_loss = 0.11754397619515658
Trained batch 60 in epoch 15, gen_loss = 0.3743427344521538, disc_loss = 0.11676423233307776
Trained batch 61 in epoch 15, gen_loss = 0.3748836264975609, disc_loss = 0.11532105072852104
Trained batch 62 in epoch 15, gen_loss = 0.37477237577476197, disc_loss = 0.11394153884242451
Trained batch 63 in epoch 15, gen_loss = 0.3757737793494016, disc_loss = 0.11248453409643844
Trained batch 64 in epoch 15, gen_loss = 0.37613281309604646, disc_loss = 0.11330210480552454
Trained batch 65 in epoch 15, gen_loss = 0.3754366665627017, disc_loss = 0.11883959631350907
Trained batch 66 in epoch 15, gen_loss = 0.37667563001611337, disc_loss = 0.11862032143260116
Trained batch 67 in epoch 15, gen_loss = 0.37633811704376163, disc_loss = 0.11875047693576883
Trained batch 68 in epoch 15, gen_loss = 0.3759265699680301, disc_loss = 0.12021931665747063
Trained batch 69 in epoch 15, gen_loss = 0.3755904229623931, disc_loss = 0.11932424264294761
Trained batch 70 in epoch 15, gen_loss = 0.375437800943012, disc_loss = 0.11862647239591034
Trained batch 71 in epoch 15, gen_loss = 0.3757275440212753, disc_loss = 0.11754346043906277
Trained batch 72 in epoch 15, gen_loss = 0.3756902179081146, disc_loss = 0.11757903847180001
Trained batch 73 in epoch 15, gen_loss = 0.3755343711456737, disc_loss = 0.11701345660195157
Trained batch 74 in epoch 15, gen_loss = 0.37590292394161223, disc_loss = 0.11591038142641386
Trained batch 75 in epoch 15, gen_loss = 0.3750225585934363, disc_loss = 0.11567191931566126
Trained batch 76 in epoch 15, gen_loss = 0.37580379553429494, disc_loss = 0.11444789330874171
Trained batch 77 in epoch 15, gen_loss = 0.37648294655940473, disc_loss = 0.11426549915892956
Trained batch 78 in epoch 15, gen_loss = 0.37553982851626, disc_loss = 0.11429551946400088
Trained batch 79 in epoch 15, gen_loss = 0.37508561182767153, disc_loss = 0.11490656104870141
Trained batch 80 in epoch 15, gen_loss = 0.37564556227054124, disc_loss = 0.11540021006891757
Trained batch 81 in epoch 15, gen_loss = 0.3770436348348129, disc_loss = 0.11449552422798262
Trained batch 82 in epoch 15, gen_loss = 0.3775099711604865, disc_loss = 0.11376362172774522
Trained batch 83 in epoch 15, gen_loss = 0.37711960165983155, disc_loss = 0.11315623258373567
Trained batch 84 in epoch 15, gen_loss = 0.3775613779530806, disc_loss = 0.11207806993933285
Trained batch 85 in epoch 15, gen_loss = 0.37765425079783727, disc_loss = 0.11149924083851105
Trained batch 86 in epoch 15, gen_loss = 0.37745666589545107, disc_loss = 0.11132830321446233
Trained batch 87 in epoch 15, gen_loss = 0.37797728705812583, disc_loss = 0.11061743248931387
Trained batch 88 in epoch 15, gen_loss = 0.3780986480833439, disc_loss = 0.10997501099377535
Trained batch 89 in epoch 15, gen_loss = 0.3779173316227065, disc_loss = 0.10928818873233265
Trained batch 90 in epoch 15, gen_loss = 0.3785621630293982, disc_loss = 0.10909785723293221
Trained batch 91 in epoch 15, gen_loss = 0.3793793493962806, disc_loss = 0.10861199697398621
Trained batch 92 in epoch 15, gen_loss = 0.37997248913011245, disc_loss = 0.1078630984630636
Trained batch 93 in epoch 15, gen_loss = 0.3812086076495495, disc_loss = 0.10741630537395781
Trained batch 94 in epoch 15, gen_loss = 0.38241646274140007, disc_loss = 0.10742295604003103
Trained batch 95 in epoch 15, gen_loss = 0.38212454644963145, disc_loss = 0.10819539132838447
Trained batch 96 in epoch 15, gen_loss = 0.3819376154965961, disc_loss = 0.10760901637913026
Trained batch 97 in epoch 15, gen_loss = 0.3823522181839359, disc_loss = 0.10695004934559063
Trained batch 98 in epoch 15, gen_loss = 0.38171171946356997, disc_loss = 0.10699379519380704
Trained batch 99 in epoch 15, gen_loss = 0.38233337804675105, disc_loss = 0.10690538704395294
Trained batch 100 in epoch 15, gen_loss = 0.38128364956614996, disc_loss = 0.10697043967424053
Trained batch 101 in epoch 15, gen_loss = 0.3822810785735355, disc_loss = 0.10661415061822124
Trained batch 102 in epoch 15, gen_loss = 0.3818217803841656, disc_loss = 0.10604620609179284
Trained batch 103 in epoch 15, gen_loss = 0.3812816743380748, disc_loss = 0.10528701955739123
Trained batch 104 in epoch 15, gen_loss = 0.3815302188907351, disc_loss = 0.10455630354228473
Trained batch 105 in epoch 15, gen_loss = 0.3812619294479208, disc_loss = 0.10417384756201843
Trained batch 106 in epoch 15, gen_loss = 0.3811044393577308, disc_loss = 0.10400869756519238
Trained batch 107 in epoch 15, gen_loss = 0.38097906705957874, disc_loss = 0.10329013942154469
Trained batch 108 in epoch 15, gen_loss = 0.3815631575267249, disc_loss = 0.10255388773704341
Trained batch 109 in epoch 15, gen_loss = 0.3810186257416552, disc_loss = 0.10210848001932556
Trained batch 110 in epoch 15, gen_loss = 0.38187593449880414, disc_loss = 0.10145645415796353
Trained batch 111 in epoch 15, gen_loss = 0.3821332413437111, disc_loss = 0.10098167716725064
Trained batch 112 in epoch 15, gen_loss = 0.38236675840036005, disc_loss = 0.10164251206525132
Trained batch 113 in epoch 15, gen_loss = 0.3833210550640759, disc_loss = 0.10366067180834841
Trained batch 114 in epoch 15, gen_loss = 0.38252391724482826, disc_loss = 0.10313769240418207
Trained batch 115 in epoch 15, gen_loss = 0.382752217223932, disc_loss = 0.10287338859754903
Trained batch 116 in epoch 15, gen_loss = 0.3832523872454961, disc_loss = 0.10251024338361035
Trained batch 117 in epoch 15, gen_loss = 0.38334430438482153, disc_loss = 0.10197121995674857
Trained batch 118 in epoch 15, gen_loss = 0.38336339680587544, disc_loss = 0.10136218489531208
Trained batch 119 in epoch 15, gen_loss = 0.3830975580960512, disc_loss = 0.10144860205861429
Trained batch 120 in epoch 15, gen_loss = 0.3827253807921055, disc_loss = 0.10262984882516801
Trained batch 121 in epoch 15, gen_loss = 0.3837214318699524, disc_loss = 0.10329330988900094
Trained batch 122 in epoch 15, gen_loss = 0.3848643546424261, disc_loss = 0.10259037879787809
Trained batch 123 in epoch 15, gen_loss = 0.3844414284873393, disc_loss = 0.10243164372420119
Trained batch 124 in epoch 15, gen_loss = 0.3839822939634323, disc_loss = 0.10204447802901268
Trained batch 125 in epoch 15, gen_loss = 0.38409309479452314, disc_loss = 0.1013683881462803
Trained batch 126 in epoch 15, gen_loss = 0.3843382041989349, disc_loss = 0.10095092406364407
Trained batch 127 in epoch 15, gen_loss = 0.3842601132346317, disc_loss = 0.10069130458578002
Trained batch 128 in epoch 15, gen_loss = 0.383666063579478, disc_loss = 0.10059718508995319
Trained batch 129 in epoch 15, gen_loss = 0.38335020759930977, disc_loss = 0.10107114875259307
Trained batch 130 in epoch 15, gen_loss = 0.3834707217134592, disc_loss = 0.10071229688709474
Trained batch 131 in epoch 15, gen_loss = 0.38231140273538505, disc_loss = 0.10195607831701636
Trained batch 132 in epoch 15, gen_loss = 0.383751141733693, disc_loss = 0.10497611384362654
Trained batch 133 in epoch 15, gen_loss = 0.38441157885896626, disc_loss = 0.10459136283164149
Trained batch 134 in epoch 15, gen_loss = 0.3843325759525652, disc_loss = 0.1043233026370958
Trained batch 135 in epoch 15, gen_loss = 0.383997454034055, disc_loss = 0.10417567734496996
Trained batch 136 in epoch 15, gen_loss = 0.3843730978504585, disc_loss = 0.1035509825187878
Trained batch 137 in epoch 15, gen_loss = 0.3847044623200444, disc_loss = 0.10367998210848242
Trained batch 138 in epoch 15, gen_loss = 0.38423879466039673, disc_loss = 0.10317009135330324
Trained batch 139 in epoch 15, gen_loss = 0.3835715009697846, disc_loss = 0.10412284566887788
Trained batch 140 in epoch 15, gen_loss = 0.38374824631721416, disc_loss = 0.10412320684879384
Trained batch 141 in epoch 15, gen_loss = 0.3840577385165322, disc_loss = 0.10369783844536459
Trained batch 142 in epoch 15, gen_loss = 0.3837518534668676, disc_loss = 0.10354882254675551
Trained batch 143 in epoch 15, gen_loss = 0.3836323263951474, disc_loss = 0.10349395472763313
Trained batch 144 in epoch 15, gen_loss = 0.3831101414458505, disc_loss = 0.10322313776303982
Trained batch 145 in epoch 15, gen_loss = 0.3833063854134246, disc_loss = 0.10310407901463443
Trained batch 146 in epoch 15, gen_loss = 0.38320958117643994, disc_loss = 0.10278640287060316
Trained batch 147 in epoch 15, gen_loss = 0.3829552449688718, disc_loss = 0.10494704901970722
Trained batch 148 in epoch 15, gen_loss = 0.3833881335570508, disc_loss = 0.1048885737389526
Trained batch 149 in epoch 15, gen_loss = 0.38356754372517265, disc_loss = 0.10452087988456091
Trained batch 150 in epoch 15, gen_loss = 0.38351834086787623, disc_loss = 0.10414075681211933
Trained batch 151 in epoch 15, gen_loss = 0.38371409897349384, disc_loss = 0.10374388846225645
Trained batch 152 in epoch 15, gen_loss = 0.38398971131034926, disc_loss = 0.10324869375505479
Trained batch 153 in epoch 15, gen_loss = 0.3834511992799771, disc_loss = 0.10301270275437213
Trained batch 154 in epoch 15, gen_loss = 0.38354767282162944, disc_loss = 0.10264197660069312
Trained batch 155 in epoch 15, gen_loss = 0.3843942436461265, disc_loss = 0.10212058336354601
Trained batch 156 in epoch 15, gen_loss = 0.3847073080243578, disc_loss = 0.1017602437359702
Trained batch 157 in epoch 15, gen_loss = 0.3845479751500902, disc_loss = 0.1014021526715612
Trained batch 158 in epoch 15, gen_loss = 0.3846535349979341, disc_loss = 0.10180910307703153
Trained batch 159 in epoch 15, gen_loss = 0.3853277788497508, disc_loss = 0.10205357718514278
Trained batch 160 in epoch 15, gen_loss = 0.385499211479418, disc_loss = 0.101495923833077
Trained batch 161 in epoch 15, gen_loss = 0.3861924026299406, disc_loss = 0.10111599898448696
Trained batch 162 in epoch 15, gen_loss = 0.38586136927268255, disc_loss = 0.10116774922499627
Trained batch 163 in epoch 15, gen_loss = 0.3859113034133504, disc_loss = 0.10077149591340524
Trained batch 164 in epoch 15, gen_loss = 0.38655641051855955, disc_loss = 0.10048402127894489
Trained batch 165 in epoch 15, gen_loss = 0.3865343920258154, disc_loss = 0.10038709761687072
Trained batch 166 in epoch 15, gen_loss = 0.3865043022140057, disc_loss = 0.10018226990621247
Trained batch 167 in epoch 15, gen_loss = 0.38639531328919385, disc_loss = 0.1001444770289319
Trained batch 168 in epoch 15, gen_loss = 0.38627209615777935, disc_loss = 0.10002124600509214
Trained batch 169 in epoch 15, gen_loss = 0.38638969335485907, disc_loss = 0.09973322429201183
Trained batch 170 in epoch 15, gen_loss = 0.38588680780073353, disc_loss = 0.09941020143920914
Trained batch 171 in epoch 15, gen_loss = 0.385871694444917, disc_loss = 0.09899759748517427
Trained batch 172 in epoch 15, gen_loss = 0.3852796328033326, disc_loss = 0.09888004090615435
Trained batch 173 in epoch 15, gen_loss = 0.3849810439793543, disc_loss = 0.09907130525586591
Trained batch 174 in epoch 15, gen_loss = 0.3857428873436792, disc_loss = 0.09896721691957541
Trained batch 175 in epoch 15, gen_loss = 0.3854421494867314, disc_loss = 0.09886585066983984
Trained batch 176 in epoch 15, gen_loss = 0.3850074387707953, disc_loss = 0.09903180692871075
Trained batch 177 in epoch 15, gen_loss = 0.38501533003670446, disc_loss = 0.10001762940684396
Trained batch 178 in epoch 15, gen_loss = 0.3845272750994347, disc_loss = 0.10109499572417256
Trained batch 179 in epoch 15, gen_loss = 0.3844805296096537, disc_loss = 0.10122887575998903
Trained batch 180 in epoch 15, gen_loss = 0.38467960092573533, disc_loss = 0.10091801694702378
Trained batch 181 in epoch 15, gen_loss = 0.38458352224839915, disc_loss = 0.1007320606507934
Trained batch 182 in epoch 15, gen_loss = 0.3843416416091346, disc_loss = 0.10031394021270054
Trained batch 183 in epoch 15, gen_loss = 0.38442287067680253, disc_loss = 0.0999139217639585
Trained batch 184 in epoch 15, gen_loss = 0.38453550991174335, disc_loss = 0.09950651370391653
Trained batch 185 in epoch 15, gen_loss = 0.38440255380125454, disc_loss = 0.0992532288855923
Trained batch 186 in epoch 15, gen_loss = 0.38551868211458074, disc_loss = 0.09947131786316155
Trained batch 187 in epoch 15, gen_loss = 0.3855652446918031, disc_loss = 0.09977268020404463
Trained batch 188 in epoch 15, gen_loss = 0.3863079543939974, disc_loss = 0.09973299319032954
Trained batch 189 in epoch 15, gen_loss = 0.38628496174749577, disc_loss = 0.09964755362782039
Trained batch 190 in epoch 15, gen_loss = 0.3861388775534655, disc_loss = 0.1001179443467506
Trained batch 191 in epoch 15, gen_loss = 0.3863885945174843, disc_loss = 0.09969248305424117
Trained batch 192 in epoch 15, gen_loss = 0.38653259566102005, disc_loss = 0.09982678812441122
Trained batch 193 in epoch 15, gen_loss = 0.3861131498340479, disc_loss = 0.09953466492714648
Trained batch 194 in epoch 15, gen_loss = 0.386126460096775, disc_loss = 0.0992720366957096
Trained batch 195 in epoch 15, gen_loss = 0.38619280750958285, disc_loss = 0.0989357773879809
Trained batch 196 in epoch 15, gen_loss = 0.3864504803104449, disc_loss = 0.09859140609688868
Trained batch 197 in epoch 15, gen_loss = 0.3867047316949777, disc_loss = 0.09836822308863354
Trained batch 198 in epoch 15, gen_loss = 0.3868477241927056, disc_loss = 0.0980126288293594
Trained batch 199 in epoch 15, gen_loss = 0.3871976178139448, disc_loss = 0.09782981628552079
Trained batch 200 in epoch 15, gen_loss = 0.3870822153429487, disc_loss = 0.09763149123879808
Trained batch 201 in epoch 15, gen_loss = 0.386843510267168, disc_loss = 0.09770016386957452
Trained batch 202 in epoch 15, gen_loss = 0.3867722201376713, disc_loss = 0.09751013589316401
Trained batch 203 in epoch 15, gen_loss = 0.38638488181373654, disc_loss = 0.09773983061313629
Trained batch 204 in epoch 15, gen_loss = 0.38700970258654616, disc_loss = 0.09837909835140879
Trained batch 205 in epoch 15, gen_loss = 0.38691361501668264, disc_loss = 0.09806975798265448
Trained batch 206 in epoch 15, gen_loss = 0.386726342321594, disc_loss = 0.09818295817732235
Trained batch 207 in epoch 15, gen_loss = 0.3867017435483061, disc_loss = 0.09822479621149026
Trained batch 208 in epoch 15, gen_loss = 0.3864972807431335, disc_loss = 0.09802527918199604
Trained batch 209 in epoch 15, gen_loss = 0.38655484879300706, disc_loss = 0.09785680121609143
Trained batch 210 in epoch 15, gen_loss = 0.38670454467359877, disc_loss = 0.0984328324549006
Trained batch 211 in epoch 15, gen_loss = 0.38635495565128775, disc_loss = 0.09889097402821172
Trained batch 212 in epoch 15, gen_loss = 0.38621229849790745, disc_loss = 0.09878243589904946
Trained batch 213 in epoch 15, gen_loss = 0.3863345095626662, disc_loss = 0.09875673327212021
Trained batch 214 in epoch 15, gen_loss = 0.3862691023322039, disc_loss = 0.09863330430762712
Trained batch 215 in epoch 15, gen_loss = 0.3862831780893935, disc_loss = 0.0984662216225708
Trained batch 216 in epoch 15, gen_loss = 0.38611005177970303, disc_loss = 0.09853985205224033
Trained batch 217 in epoch 15, gen_loss = 0.3856944689920189, disc_loss = 0.09850004100061338
Trained batch 218 in epoch 15, gen_loss = 0.3858924252937918, disc_loss = 0.09814140659897294
Trained batch 219 in epoch 15, gen_loss = 0.38581480878320606, disc_loss = 0.0984477377411994
Trained batch 220 in epoch 15, gen_loss = 0.3854023647658965, disc_loss = 0.09903622910852346
Trained batch 221 in epoch 15, gen_loss = 0.3853676143932987, disc_loss = 0.09895337718698355
Trained batch 222 in epoch 15, gen_loss = 0.3856172013042219, disc_loss = 0.09883423881279513
Trained batch 223 in epoch 15, gen_loss = 0.3858152991825981, disc_loss = 0.09856544385131981
Trained batch 224 in epoch 15, gen_loss = 0.38585841251744163, disc_loss = 0.09824419644971688
Trained batch 225 in epoch 15, gen_loss = 0.3855412406599627, disc_loss = 0.09850417539905922
Trained batch 226 in epoch 15, gen_loss = 0.3856736767528341, disc_loss = 0.09858697154743819
Trained batch 227 in epoch 15, gen_loss = 0.3854938548777187, disc_loss = 0.09875038737561881
Trained batch 228 in epoch 15, gen_loss = 0.3850309071192054, disc_loss = 0.10020783544400114
Trained batch 229 in epoch 15, gen_loss = 0.38523143277220107, disc_loss = 0.09998744153620108
Trained batch 230 in epoch 15, gen_loss = 0.3851346043926297, disc_loss = 0.09964556395362466
Trained batch 231 in epoch 15, gen_loss = 0.38521025439017803, disc_loss = 0.09963428958094325
Trained batch 232 in epoch 15, gen_loss = 0.38493726482462987, disc_loss = 0.09957251857662405
Trained batch 233 in epoch 15, gen_loss = 0.3853357418352722, disc_loss = 0.09922110846536791
Trained batch 234 in epoch 15, gen_loss = 0.3856602515946043, disc_loss = 0.09960889768727282
Trained batch 235 in epoch 15, gen_loss = 0.3852726834178981, disc_loss = 0.10063531682274099
Trained batch 236 in epoch 15, gen_loss = 0.38553881726938966, disc_loss = 0.10026815018856325
Trained batch 237 in epoch 15, gen_loss = 0.38584387308659673, disc_loss = 0.10012425839932275
Trained batch 238 in epoch 15, gen_loss = 0.3860945118645744, disc_loss = 0.09982352578334479
Trained batch 239 in epoch 15, gen_loss = 0.3860870245223244, disc_loss = 0.09976683040925612
Trained batch 240 in epoch 15, gen_loss = 0.38601719387092037, disc_loss = 0.09993744563481373
Trained batch 241 in epoch 15, gen_loss = 0.38560969013074214, disc_loss = 0.10048006757447296
Trained batch 242 in epoch 15, gen_loss = 0.38617839323885644, disc_loss = 0.10018030185359741
Trained batch 243 in epoch 15, gen_loss = 0.38637237745474595, disc_loss = 0.10078183899740459
Trained batch 244 in epoch 15, gen_loss = 0.38630578451010644, disc_loss = 0.10105940793089721
Trained batch 245 in epoch 15, gen_loss = 0.3864266012863415, disc_loss = 0.10075612831860781
Trained batch 246 in epoch 15, gen_loss = 0.3866851174758996, disc_loss = 0.10047732837317203
Trained batch 247 in epoch 15, gen_loss = 0.38661608021826516, disc_loss = 0.10023043409080035
Trained batch 248 in epoch 15, gen_loss = 0.3865261492599924, disc_loss = 0.09997993977703004
Trained batch 249 in epoch 15, gen_loss = 0.3867248120903969, disc_loss = 0.0997001835629344
Trained batch 250 in epoch 15, gen_loss = 0.3868881259187759, disc_loss = 0.099482367779926
Trained batch 251 in epoch 15, gen_loss = 0.38730186005196876, disc_loss = 0.09941187211948019
Trained batch 252 in epoch 15, gen_loss = 0.387316159521167, disc_loss = 0.10008820627076118
Trained batch 253 in epoch 15, gen_loss = 0.3878165144971975, disc_loss = 0.10006690140461594
Trained batch 254 in epoch 15, gen_loss = 0.3877251422288371, disc_loss = 0.09990287451621364
Trained batch 255 in epoch 15, gen_loss = 0.3876270970213227, disc_loss = 0.10092454071127577
Trained batch 256 in epoch 15, gen_loss = 0.3876643699778657, disc_loss = 0.10102587369368465
Trained batch 257 in epoch 15, gen_loss = 0.38781207181917604, disc_loss = 0.10089414176177378
Trained batch 258 in epoch 15, gen_loss = 0.3879072915288012, disc_loss = 0.10074757654435616
Trained batch 259 in epoch 15, gen_loss = 0.3878858494643982, disc_loss = 0.10049909156245682
Trained batch 260 in epoch 15, gen_loss = 0.3878556690339384, disc_loss = 0.10030639146622342
Trained batch 261 in epoch 15, gen_loss = 0.3878526087594396, disc_loss = 0.10002753486188541
Trained batch 262 in epoch 15, gen_loss = 0.38789930106795784, disc_loss = 0.09982333368419921
Trained batch 263 in epoch 15, gen_loss = 0.38781314123083244, disc_loss = 0.09986426909171948
Trained batch 264 in epoch 15, gen_loss = 0.3875998484076194, disc_loss = 0.10042292224770447
Trained batch 265 in epoch 15, gen_loss = 0.38806821131392527, disc_loss = 0.10034258721774458
Trained batch 266 in epoch 15, gen_loss = 0.38870500898763033, disc_loss = 0.10028724751194541
Trained batch 267 in epoch 15, gen_loss = 0.38857603434528876, disc_loss = 0.09998146910915401
Trained batch 268 in epoch 15, gen_loss = 0.38827506799015415, disc_loss = 0.09971154081638639
Trained batch 269 in epoch 15, gen_loss = 0.38839857175394343, disc_loss = 0.09955860502603982
Trained batch 270 in epoch 15, gen_loss = 0.38849397289577003, disc_loss = 0.09938300655969175
Trained batch 271 in epoch 15, gen_loss = 0.38838815420646877, disc_loss = 0.09920106524848105
Trained batch 272 in epoch 15, gen_loss = 0.3883759076451207, disc_loss = 0.09924486662250953
Trained batch 273 in epoch 15, gen_loss = 0.3885021046021559, disc_loss = 0.0994012504340197
Trained batch 274 in epoch 15, gen_loss = 0.3879645576802167, disc_loss = 0.09961626741696487
Trained batch 275 in epoch 15, gen_loss = 0.38808627442821214, disc_loss = 0.0994466349442044
Trained batch 276 in epoch 15, gen_loss = 0.38811525073077274, disc_loss = 0.09927477686924839
Trained batch 277 in epoch 15, gen_loss = 0.3880234025686765, disc_loss = 0.09940244945556782
Trained batch 278 in epoch 15, gen_loss = 0.3878623386544566, disc_loss = 0.09937843252440721
Trained batch 279 in epoch 15, gen_loss = 0.3878129698868309, disc_loss = 0.09915696347265371
Trained batch 280 in epoch 15, gen_loss = 0.38807000803141406, disc_loss = 0.09941329514720473
Trained batch 281 in epoch 15, gen_loss = 0.3882246965951953, disc_loss = 0.09933536028793306
Trained batch 282 in epoch 15, gen_loss = 0.3882838897801962, disc_loss = 0.09901591849450825
Trained batch 283 in epoch 15, gen_loss = 0.38834509615537144, disc_loss = 0.0987869909288965
Trained batch 284 in epoch 15, gen_loss = 0.38874469164170716, disc_loss = 0.09862005375652459
Trained batch 285 in epoch 15, gen_loss = 0.38866385176673635, disc_loss = 0.09846083921139369
Trained batch 286 in epoch 15, gen_loss = 0.3887922363518007, disc_loss = 0.09826903924904115
Trained batch 287 in epoch 15, gen_loss = 0.3887318708519969, disc_loss = 0.098265360727156
Trained batch 288 in epoch 15, gen_loss = 0.38902429071058453, disc_loss = 0.09887325722131246
Trained batch 289 in epoch 15, gen_loss = 0.389011852237685, disc_loss = 0.09868467738851905
Trained batch 290 in epoch 15, gen_loss = 0.38906673411118614, disc_loss = 0.09864329312099111
Trained batch 291 in epoch 15, gen_loss = 0.3890169214406242, disc_loss = 0.09900354240281023
Trained batch 292 in epoch 15, gen_loss = 0.38898614064214987, disc_loss = 0.09876398141766063
Trained batch 293 in epoch 15, gen_loss = 0.38893226108380724, disc_loss = 0.09860298175326719
Trained batch 294 in epoch 15, gen_loss = 0.38873401804495666, disc_loss = 0.0985044279183119
Trained batch 295 in epoch 15, gen_loss = 0.38880368991679437, disc_loss = 0.09836060810217483
Trained batch 296 in epoch 15, gen_loss = 0.38866411370259746, disc_loss = 0.09832635117688464
Trained batch 297 in epoch 15, gen_loss = 0.38866691096317046, disc_loss = 0.09842634908292418
Trained batch 298 in epoch 15, gen_loss = 0.3881394752989645, disc_loss = 0.09851805688532997
Trained batch 299 in epoch 15, gen_loss = 0.38809423382083574, disc_loss = 0.09842427360204359
Trained batch 300 in epoch 15, gen_loss = 0.3878763011622667, disc_loss = 0.09833868530786216
Trained batch 301 in epoch 15, gen_loss = 0.38798756665544004, disc_loss = 0.09814150972809914
Trained batch 302 in epoch 15, gen_loss = 0.38826448084300896, disc_loss = 0.09797856802729392
Trained batch 303 in epoch 15, gen_loss = 0.388219757740827, disc_loss = 0.0977240999161854
Trained batch 304 in epoch 15, gen_loss = 0.38841566878264067, disc_loss = 0.09743104133693899
Trained batch 305 in epoch 15, gen_loss = 0.3883868194386071, disc_loss = 0.09726192764450911
Trained batch 306 in epoch 15, gen_loss = 0.38827033156486596, disc_loss = 0.09714714266626764
Trained batch 307 in epoch 15, gen_loss = 0.3883069765741949, disc_loss = 0.09700531318977282
Trained batch 308 in epoch 15, gen_loss = 0.38818901029798203, disc_loss = 0.09675643313977518
Trained batch 309 in epoch 15, gen_loss = 0.3882014255850546, disc_loss = 0.09662475466367698
Trained batch 310 in epoch 15, gen_loss = 0.38808194258013723, disc_loss = 0.09680206494531639
Trained batch 311 in epoch 15, gen_loss = 0.3882802746330316, disc_loss = 0.09685301800401738
Trained batch 312 in epoch 15, gen_loss = 0.38826329187272834, disc_loss = 0.09665096617235353
Trained batch 313 in epoch 15, gen_loss = 0.38833154315591617, disc_loss = 0.09644109192808532
Trained batch 314 in epoch 15, gen_loss = 0.3884257231912916, disc_loss = 0.09651493311283134
Trained batch 315 in epoch 15, gen_loss = 0.38860261096041415, disc_loss = 0.09651120355399916
Trained batch 316 in epoch 15, gen_loss = 0.3885348949240585, disc_loss = 0.09625516686153712
Trained batch 317 in epoch 15, gen_loss = 0.38882608510225825, disc_loss = 0.09605255858890666
Trained batch 318 in epoch 15, gen_loss = 0.38896430552379463, disc_loss = 0.09602236152162373
Trained batch 319 in epoch 15, gen_loss = 0.3886675946880132, disc_loss = 0.0963572276988998
Trained batch 320 in epoch 15, gen_loss = 0.38884153196187776, disc_loss = 0.09660597751352275
Trained batch 321 in epoch 15, gen_loss = 0.3886711249903122, disc_loss = 0.09650999263669394
Trained batch 322 in epoch 15, gen_loss = 0.3886928229416856, disc_loss = 0.09633275031489853
Trained batch 323 in epoch 15, gen_loss = 0.3887005637365359, disc_loss = 0.09624388172394699
Trained batch 324 in epoch 15, gen_loss = 0.3886718048040683, disc_loss = 0.09624060662893148
Trained batch 325 in epoch 15, gen_loss = 0.388689539046741, disc_loss = 0.09611779538217498
Trained batch 326 in epoch 15, gen_loss = 0.38855176430412025, disc_loss = 0.09598313806299405
Trained batch 327 in epoch 15, gen_loss = 0.388311394785599, disc_loss = 0.09598418033295651
Trained batch 328 in epoch 15, gen_loss = 0.38855019614870423, disc_loss = 0.09605465325495754
Trained batch 329 in epoch 15, gen_loss = 0.3886252351330988, disc_loss = 0.09584732257732839
Trained batch 330 in epoch 15, gen_loss = 0.38849909675625516, disc_loss = 0.09575418107144062
Trained batch 331 in epoch 15, gen_loss = 0.3887844516121479, disc_loss = 0.09550617578024247
Trained batch 332 in epoch 15, gen_loss = 0.3889307871505663, disc_loss = 0.09570404584030132
Trained batch 333 in epoch 15, gen_loss = 0.38873516420225895, disc_loss = 0.09602612097507822
Trained batch 334 in epoch 15, gen_loss = 0.3886838487279949, disc_loss = 0.09593276129062496
Trained batch 335 in epoch 15, gen_loss = 0.38860321874242454, disc_loss = 0.09576071547122583
Trained batch 336 in epoch 15, gen_loss = 0.38857510610751655, disc_loss = 0.09569314543367848
Trained batch 337 in epoch 15, gen_loss = 0.3889799566399416, disc_loss = 0.09581952230156174
Trained batch 338 in epoch 15, gen_loss = 0.38911690134390264, disc_loss = 0.0958527736146014
Trained batch 339 in epoch 15, gen_loss = 0.3890934337149648, disc_loss = 0.09590071298401145
Trained batch 340 in epoch 15, gen_loss = 0.3889848035364207, disc_loss = 0.09582542876038383
Trained batch 341 in epoch 15, gen_loss = 0.3890483797206516, disc_loss = 0.09587191477722941
Trained batch 342 in epoch 15, gen_loss = 0.3888745866172863, disc_loss = 0.09590475166721525
Trained batch 343 in epoch 15, gen_loss = 0.3889314813409434, disc_loss = 0.09566812855624703
Trained batch 344 in epoch 15, gen_loss = 0.38915437602478525, disc_loss = 0.09543586296663768
Trained batch 345 in epoch 15, gen_loss = 0.38908750253777974, disc_loss = 0.09528993583698837
Trained batch 346 in epoch 15, gen_loss = 0.3892862104974494, disc_loss = 0.0952138919544323
Trained batch 347 in epoch 15, gen_loss = 0.3892388441011138, disc_loss = 0.09529960749606634
Trained batch 348 in epoch 15, gen_loss = 0.3893604865644586, disc_loss = 0.09582729995208006
Trained batch 349 in epoch 15, gen_loss = 0.3891358751484326, disc_loss = 0.09588392761136805
Trained batch 350 in epoch 15, gen_loss = 0.38902257730988016, disc_loss = 0.09581150845796974
Trained batch 351 in epoch 15, gen_loss = 0.3891329400834035, disc_loss = 0.09592317727352069
Trained batch 352 in epoch 15, gen_loss = 0.38898296316521025, disc_loss = 0.09570327739392225
Trained batch 353 in epoch 15, gen_loss = 0.3888967535169111, disc_loss = 0.09582849411493809
Trained batch 354 in epoch 15, gen_loss = 0.3888938396329611, disc_loss = 0.09567632170944987
Trained batch 355 in epoch 15, gen_loss = 0.3887856381244204, disc_loss = 0.09565470356682546
Trained batch 356 in epoch 15, gen_loss = 0.38862413990230454, disc_loss = 0.09592210592738554
Trained batch 357 in epoch 15, gen_loss = 0.3885361667535159, disc_loss = 0.09568688781755097
Trained batch 358 in epoch 15, gen_loss = 0.38873895168470474, disc_loss = 0.09572221484543719
Trained batch 359 in epoch 15, gen_loss = 0.3887064172575871, disc_loss = 0.09554591364641156
Trained batch 360 in epoch 15, gen_loss = 0.38848210285079776, disc_loss = 0.09564214911301545
Trained batch 361 in epoch 15, gen_loss = 0.3885559517457999, disc_loss = 0.095774136684341
Trained batch 362 in epoch 15, gen_loss = 0.3883012542629373, disc_loss = 0.09571908229125597
Trained batch 363 in epoch 15, gen_loss = 0.38826116317739856, disc_loss = 0.09569592650590854
Trained batch 364 in epoch 15, gen_loss = 0.38840954348649065, disc_loss = 0.09553570530492149
Trained batch 365 in epoch 15, gen_loss = 0.3884176878574116, disc_loss = 0.09542109651867646
Trained batch 366 in epoch 15, gen_loss = 0.3885270565423394, disc_loss = 0.09567117217511995
Trained batch 367 in epoch 15, gen_loss = 0.38847463638724195, disc_loss = 0.09592561692546081
Trained batch 368 in epoch 15, gen_loss = 0.3885527227709933, disc_loss = 0.09586815157940556
Trained batch 369 in epoch 15, gen_loss = 0.38830245012367093, disc_loss = 0.0960102317452028
Trained batch 370 in epoch 15, gen_loss = 0.3881669701993305, disc_loss = 0.09621841335453274
Trained batch 371 in epoch 15, gen_loss = 0.3882634241173985, disc_loss = 0.0961471451496485
Trained batch 372 in epoch 15, gen_loss = 0.3882954141010228, disc_loss = 0.09638527019234029
Trained batch 373 in epoch 15, gen_loss = 0.38832875564295977, disc_loss = 0.09625596692038571
Trained batch 374 in epoch 15, gen_loss = 0.3885126924912135, disc_loss = 0.09632204383114974
Trained batch 375 in epoch 15, gen_loss = 0.38837440157348807, disc_loss = 0.09667036533256636
Trained batch 376 in epoch 15, gen_loss = 0.3884864903650486, disc_loss = 0.09654040943426068
Trained batch 377 in epoch 15, gen_loss = 0.3884830746464628, disc_loss = 0.09659138119350823
Trained batch 378 in epoch 15, gen_loss = 0.388332074227937, disc_loss = 0.09652880406729622
Trained batch 379 in epoch 15, gen_loss = 0.3880916587224132, disc_loss = 0.09675297774864655
Trained batch 380 in epoch 15, gen_loss = 0.3882287274117232, disc_loss = 0.09683802006692868
Trained batch 381 in epoch 15, gen_loss = 0.3882472815079839, disc_loss = 0.096665485947349
Trained batch 382 in epoch 15, gen_loss = 0.3883787776020115, disc_loss = 0.09654255818779879
Trained batch 383 in epoch 15, gen_loss = 0.3884909809178983, disc_loss = 0.09661788524924002
Trained batch 384 in epoch 15, gen_loss = 0.38822208313972917, disc_loss = 0.09659156103122545
Trained batch 385 in epoch 15, gen_loss = 0.38833232876395934, disc_loss = 0.09642380730302068
Trained batch 386 in epoch 15, gen_loss = 0.388441293854122, disc_loss = 0.09633811868881224
Trained batch 387 in epoch 15, gen_loss = 0.3884820481474252, disc_loss = 0.09615330382720712
Trained batch 388 in epoch 15, gen_loss = 0.38854443295296176, disc_loss = 0.09602227449838484
Trained batch 389 in epoch 15, gen_loss = 0.3885394312250309, disc_loss = 0.0958618097866957
Trained batch 390 in epoch 15, gen_loss = 0.38855778641255617, disc_loss = 0.09573938525127024
Trained batch 391 in epoch 15, gen_loss = 0.38853128098559625, disc_loss = 0.09592962509249242
Trained batch 392 in epoch 15, gen_loss = 0.3889959146275775, disc_loss = 0.09606138430061838
Trained batch 393 in epoch 15, gen_loss = 0.3889343369808899, disc_loss = 0.09587016680424437
Trained batch 394 in epoch 15, gen_loss = 0.38895917221715176, disc_loss = 0.09596878408536881
Trained batch 395 in epoch 15, gen_loss = 0.3889707458214928, disc_loss = 0.09585750712119419
Trained batch 396 in epoch 15, gen_loss = 0.38889960771994264, disc_loss = 0.09575802519898721
Trained batch 397 in epoch 15, gen_loss = 0.38891309338748153, disc_loss = 0.0956523086473196
Trained batch 398 in epoch 15, gen_loss = 0.38882882220852644, disc_loss = 0.09557474650591985
Trained batch 399 in epoch 15, gen_loss = 0.38873197134584186, disc_loss = 0.09558165724854917
Trained batch 400 in epoch 15, gen_loss = 0.38859381814698624, disc_loss = 0.09560768486016855
Trained batch 401 in epoch 15, gen_loss = 0.38887974097212746, disc_loss = 0.09560112037524507
Trained batch 402 in epoch 15, gen_loss = 0.3889877005265309, disc_loss = 0.09551194444686988
Trained batch 403 in epoch 15, gen_loss = 0.38913515966274953, disc_loss = 0.09532082424323896
Trained batch 404 in epoch 15, gen_loss = 0.38921992377734477, disc_loss = 0.09535954878378061
Trained batch 405 in epoch 15, gen_loss = 0.38910919754522777, disc_loss = 0.09553678642517974
Trained batch 406 in epoch 15, gen_loss = 0.38926923044337103, disc_loss = 0.09540732228254364
Trained batch 407 in epoch 15, gen_loss = 0.3893494128669594, disc_loss = 0.09521098772072982
Trained batch 408 in epoch 15, gen_loss = 0.3890571700258768, disc_loss = 0.095212766251693
Trained batch 409 in epoch 15, gen_loss = 0.38921422954739593, disc_loss = 0.09506750423234046
Trained batch 410 in epoch 15, gen_loss = 0.38921296353612794, disc_loss = 0.09501306752735464
Trained batch 411 in epoch 15, gen_loss = 0.3891441942490999, disc_loss = 0.0952261636074343
Trained batch 412 in epoch 15, gen_loss = 0.38935443827517097, disc_loss = 0.09506047971447429
Trained batch 413 in epoch 15, gen_loss = 0.38950442220421805, disc_loss = 0.09506422072280073
Trained batch 414 in epoch 15, gen_loss = 0.38948783583669777, disc_loss = 0.09517006920538394
Trained batch 415 in epoch 15, gen_loss = 0.38958960316645413, disc_loss = 0.09510238971695519
Trained batch 416 in epoch 15, gen_loss = 0.3895901827860793, disc_loss = 0.09509859819912153
Trained batch 417 in epoch 15, gen_loss = 0.3897360205721627, disc_loss = 0.09495046894115053
Trained batch 418 in epoch 15, gen_loss = 0.3897789947528543, disc_loss = 0.0948618660905445
Trained batch 419 in epoch 15, gen_loss = 0.38968390868533226, disc_loss = 0.09505947368618634
Trained batch 420 in epoch 15, gen_loss = 0.389812023120085, disc_loss = 0.09526089373356585
Trained batch 421 in epoch 15, gen_loss = 0.38982455322951504, disc_loss = 0.09505616566078005
Trained batch 422 in epoch 15, gen_loss = 0.3896684226344381, disc_loss = 0.09490464890846899
Trained batch 423 in epoch 15, gen_loss = 0.38985057494972114, disc_loss = 0.09472615004051477
Trained batch 424 in epoch 15, gen_loss = 0.389902323309113, disc_loss = 0.09456090725739212
Trained batch 425 in epoch 15, gen_loss = 0.3898158261963459, disc_loss = 0.09442288184783339
Trained batch 426 in epoch 15, gen_loss = 0.38989405634112884, disc_loss = 0.09429588430807588
Trained batch 427 in epoch 15, gen_loss = 0.38987418198000606, disc_loss = 0.0941981901479972
Trained batch 428 in epoch 15, gen_loss = 0.38992020449577236, disc_loss = 0.09439119493636565
Trained batch 429 in epoch 15, gen_loss = 0.3899146631360054, disc_loss = 0.09446835374286355
Trained batch 430 in epoch 15, gen_loss = 0.3896698815156025, disc_loss = 0.0945537741859973
Trained batch 431 in epoch 15, gen_loss = 0.38995650634859447, disc_loss = 0.09493233548278955
Trained batch 432 in epoch 15, gen_loss = 0.38987955254853185, disc_loss = 0.09496983684659624
Trained batch 433 in epoch 15, gen_loss = 0.38982812349560075, disc_loss = 0.09495677067876755
Trained batch 434 in epoch 15, gen_loss = 0.3898820172438676, disc_loss = 0.09496692323350701
Trained batch 435 in epoch 15, gen_loss = 0.38988544788519175, disc_loss = 0.09482454313947862
Trained batch 436 in epoch 15, gen_loss = 0.3898317608939701, disc_loss = 0.09487450256031561
Trained batch 437 in epoch 15, gen_loss = 0.38993978170363325, disc_loss = 0.09475796531299002
Trained batch 438 in epoch 15, gen_loss = 0.3898992458006244, disc_loss = 0.09477344882761496
Trained batch 439 in epoch 15, gen_loss = 0.389915513552048, disc_loss = 0.09555050880775194
Trained batch 440 in epoch 15, gen_loss = 0.39017414813544476, disc_loss = 0.09552601284966244
Trained batch 441 in epoch 15, gen_loss = 0.39015936794189304, disc_loss = 0.0954099828440578
Trained batch 442 in epoch 15, gen_loss = 0.39030892070609885, disc_loss = 0.09523339882602339
Trained batch 443 in epoch 15, gen_loss = 0.3900797835945546, disc_loss = 0.09562338929128338
Trained batch 444 in epoch 15, gen_loss = 0.3902081946643551, disc_loss = 0.09588221117561117
Trained batch 445 in epoch 15, gen_loss = 0.390375898056768, disc_loss = 0.09577279040305937
Trained batch 446 in epoch 15, gen_loss = 0.39009428374319266, disc_loss = 0.09581499843664418
Trained batch 447 in epoch 15, gen_loss = 0.39015495121878174, disc_loss = 0.09564928479085211
Trained batch 448 in epoch 15, gen_loss = 0.3900996143608157, disc_loss = 0.09552215013802383
Trained batch 449 in epoch 15, gen_loss = 0.3900443520479732, disc_loss = 0.09538257801491354
Trained batch 450 in epoch 15, gen_loss = 0.38989434885212165, disc_loss = 0.09528284332200786
Trained batch 451 in epoch 15, gen_loss = 0.38994753106901076, disc_loss = 0.095100027377165
Trained batch 452 in epoch 15, gen_loss = 0.3898697426053336, disc_loss = 0.09500237853650752
Trained batch 453 in epoch 15, gen_loss = 0.38996746548603284, disc_loss = 0.09487316093616811
Trained batch 454 in epoch 15, gen_loss = 0.3899489661166956, disc_loss = 0.09485682166375957
Trained batch 455 in epoch 15, gen_loss = 0.38989593699705183, disc_loss = 0.09487696917596877
Trained batch 456 in epoch 15, gen_loss = 0.38981210523543786, disc_loss = 0.0948790174458559
Trained batch 457 in epoch 15, gen_loss = 0.38984865864421603, disc_loss = 0.0947297924893652
Trained batch 458 in epoch 15, gen_loss = 0.3898800577408348, disc_loss = 0.09527208428821793
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.3893882930278778, disc_loss = 0.07174424827098846
Trained batch 1 in epoch 16, gen_loss = 0.37209974229335785, disc_loss = 0.06904782354831696
Trained batch 2 in epoch 16, gen_loss = 0.36350808540980023, disc_loss = 0.060336634516716
Trained batch 3 in epoch 16, gen_loss = 0.3485133796930313, disc_loss = 0.0642436146736145
Trained batch 4 in epoch 16, gen_loss = 0.35547791719436644, disc_loss = 0.08224359154701233
Trained batch 5 in epoch 16, gen_loss = 0.373985896507899, disc_loss = 0.08507087081670761
Trained batch 6 in epoch 16, gen_loss = 0.37449343289647785, disc_loss = 0.08035133991922651
Trained batch 7 in epoch 16, gen_loss = 0.3670010603964329, disc_loss = 0.07465398870408535
Trained batch 8 in epoch 16, gen_loss = 0.3701776961485545, disc_loss = 0.06906355379356278
Trained batch 9 in epoch 16, gen_loss = 0.3710142940282822, disc_loss = 0.06399761475622653
Trained batch 10 in epoch 16, gen_loss = 0.3691597878932953, disc_loss = 0.060432040725242005
Trained batch 11 in epoch 16, gen_loss = 0.3693973496556282, disc_loss = 0.06215762672945857
Trained batch 12 in epoch 16, gen_loss = 0.36136561861405003, disc_loss = 0.06938022332122692
Trained batch 13 in epoch 16, gen_loss = 0.3688441110508783, disc_loss = 0.07517608960292169
Trained batch 14 in epoch 16, gen_loss = 0.3709672451019287, disc_loss = 0.07161321491003036
Trained batch 15 in epoch 16, gen_loss = 0.3690496888011694, disc_loss = 0.07106916420161724
Trained batch 16 in epoch 16, gen_loss = 0.37091631223173704, disc_loss = 0.06850603113279623
Trained batch 17 in epoch 16, gen_loss = 0.3724480089214113, disc_loss = 0.06656132058964835
Trained batch 18 in epoch 16, gen_loss = 0.37335043204458135, disc_loss = 0.06614898890256882
Trained batch 19 in epoch 16, gen_loss = 0.3744839832186699, disc_loss = 0.06557487659156322
Trained batch 20 in epoch 16, gen_loss = 0.3758701682090759, disc_loss = 0.06494520356257756
Trained batch 21 in epoch 16, gen_loss = 0.3717630329457196, disc_loss = 0.0655030340633609
Trained batch 22 in epoch 16, gen_loss = 0.3674956223239069, disc_loss = 0.06904378436181856
Trained batch 23 in epoch 16, gen_loss = 0.3720922792951266, disc_loss = 0.0779184081281225
Trained batch 24 in epoch 16, gen_loss = 0.37345424890518186, disc_loss = 0.0756796795129776
Trained batch 25 in epoch 16, gen_loss = 0.3719201385974884, disc_loss = 0.07475711806462361
Trained batch 26 in epoch 16, gen_loss = 0.37074924839867485, disc_loss = 0.07442018389701843
Trained batch 27 in epoch 16, gen_loss = 0.3719745235783713, disc_loss = 0.07201726210769266
Trained batch 28 in epoch 16, gen_loss = 0.37189858329707176, disc_loss = 0.07051446129856952
Trained batch 29 in epoch 16, gen_loss = 0.37175926367441814, disc_loss = 0.0689164120859156
Trained batch 30 in epoch 16, gen_loss = 0.3718167976025612, disc_loss = 0.06795235880981049
Trained batch 31 in epoch 16, gen_loss = 0.37403513211756945, disc_loss = 0.06744590065500233
Trained batch 32 in epoch 16, gen_loss = 0.37382223028125183, disc_loss = 0.06811793499880216
Trained batch 33 in epoch 16, gen_loss = 0.377410327686983, disc_loss = 0.07286055507960126
Trained batch 34 in epoch 16, gen_loss = 0.37702994687216623, disc_loss = 0.07170276462233492
Trained batch 35 in epoch 16, gen_loss = 0.37746191521485645, disc_loss = 0.07137748279557046
Trained batch 36 in epoch 16, gen_loss = 0.3791544920689351, disc_loss = 0.07020438378173355
Trained batch 37 in epoch 16, gen_loss = 0.3786301557954989, disc_loss = 0.069456488935669
Trained batch 38 in epoch 16, gen_loss = 0.37669668518579924, disc_loss = 0.06989149277647719
Trained batch 39 in epoch 16, gen_loss = 0.3788279786705971, disc_loss = 0.07106905902037397
Trained batch 40 in epoch 16, gen_loss = 0.3771416915626061, disc_loss = 0.07552212282515518
Trained batch 41 in epoch 16, gen_loss = 0.37713570041315897, disc_loss = 0.08558051879074247
Trained batch 42 in epoch 16, gen_loss = 0.3790707012941671, disc_loss = 0.08619571673185673
Trained batch 43 in epoch 16, gen_loss = 0.3778839571909471, disc_loss = 0.08769070396242155
Trained batch 44 in epoch 16, gen_loss = 0.37745672861735025, disc_loss = 0.08742087174000011
Trained batch 45 in epoch 16, gen_loss = 0.3785356710786405, disc_loss = 0.08602776306519366
Trained batch 46 in epoch 16, gen_loss = 0.3781486648194333, disc_loss = 0.08549349652999576
Trained batch 47 in epoch 16, gen_loss = 0.3766986106832822, disc_loss = 0.08608959903358482
Trained batch 48 in epoch 16, gen_loss = 0.3783507997892341, disc_loss = 0.08452982633203572
Trained batch 49 in epoch 16, gen_loss = 0.3783198815584183, disc_loss = 0.08471117029897869
Trained batch 50 in epoch 16, gen_loss = 0.37939652683688146, disc_loss = 0.08340558514692913
Trained batch 51 in epoch 16, gen_loss = 0.37891455739736557, disc_loss = 0.08258550967842054
Trained batch 52 in epoch 16, gen_loss = 0.3783208176774799, disc_loss = 0.08172144455272916
Trained batch 53 in epoch 16, gen_loss = 0.3785533375210232, disc_loss = 0.08160855975519452
Trained batch 54 in epoch 16, gen_loss = 0.3790925871242176, disc_loss = 0.08090778151527048
Trained batch 55 in epoch 16, gen_loss = 0.3787380536752088, disc_loss = 0.08054691010121522
Trained batch 56 in epoch 16, gen_loss = 0.37870883366517855, disc_loss = 0.07949304730190258
Trained batch 57 in epoch 16, gen_loss = 0.37748448447934513, disc_loss = 0.07859874978372507
Trained batch 58 in epoch 16, gen_loss = 0.37831315751803124, disc_loss = 0.07946765093701118
Trained batch 59 in epoch 16, gen_loss = 0.37806537250677746, disc_loss = 0.08321045512178292
Trained batch 60 in epoch 16, gen_loss = 0.3782742033239271, disc_loss = 0.08309679990634322
Trained batch 61 in epoch 16, gen_loss = 0.37773541913878533, disc_loss = 0.08270143824929913
Trained batch 62 in epoch 16, gen_loss = 0.3781093046778724, disc_loss = 0.08232579225792534
Trained batch 63 in epoch 16, gen_loss = 0.37854971177875996, disc_loss = 0.08135042839421658
Trained batch 64 in epoch 16, gen_loss = 0.3809220763353201, disc_loss = 0.08091166477220563
Trained batch 65 in epoch 16, gen_loss = 0.3810860022450938, disc_loss = 0.08011561013391298
Trained batch 66 in epoch 16, gen_loss = 0.381378351307627, disc_loss = 0.08064963103536127
Trained batch 67 in epoch 16, gen_loss = 0.3816353919751504, disc_loss = 0.08003213811967083
Trained batch 68 in epoch 16, gen_loss = 0.3823596459368001, disc_loss = 0.07963337432728082
Trained batch 69 in epoch 16, gen_loss = 0.3820171432835715, disc_loss = 0.0802096084492015
Trained batch 70 in epoch 16, gen_loss = 0.38394026437275847, disc_loss = 0.08043974351373986
Trained batch 71 in epoch 16, gen_loss = 0.3849396842221419, disc_loss = 0.07955271571538308
Trained batch 72 in epoch 16, gen_loss = 0.3836748232580211, disc_loss = 0.0789836289629034
Trained batch 73 in epoch 16, gen_loss = 0.3838983178138733, disc_loss = 0.0787077973206603
Trained batch 74 in epoch 16, gen_loss = 0.38546283801396686, disc_loss = 0.07827590725695094
Trained batch 75 in epoch 16, gen_loss = 0.385580507156096, disc_loss = 0.07786012001605214
Trained batch 76 in epoch 16, gen_loss = 0.38494871034250633, disc_loss = 0.07780720314688304
Trained batch 77 in epoch 16, gen_loss = 0.38480687065002245, disc_loss = 0.07792540746502197
Trained batch 78 in epoch 16, gen_loss = 0.38576768018022367, disc_loss = 0.07945818833040097
Trained batch 79 in epoch 16, gen_loss = 0.38609469383955003, disc_loss = 0.07879974357201718
Trained batch 80 in epoch 16, gen_loss = 0.3858468171990948, disc_loss = 0.07836620766600524
Trained batch 81 in epoch 16, gen_loss = 0.3866852252948575, disc_loss = 0.0777204190891963
Trained batch 82 in epoch 16, gen_loss = 0.38730033765356225, disc_loss = 0.07702938769663494
Trained batch 83 in epoch 16, gen_loss = 0.38770877853745506, disc_loss = 0.0767582124265443
Trained batch 84 in epoch 16, gen_loss = 0.38746654636719646, disc_loss = 0.07729330735061975
Trained batch 85 in epoch 16, gen_loss = 0.38767791071603463, disc_loss = 0.0772014404701199
Trained batch 86 in epoch 16, gen_loss = 0.3873173152578288, disc_loss = 0.07689174861465206
Trained batch 87 in epoch 16, gen_loss = 0.3877153572711078, disc_loss = 0.07734463174975562
Trained batch 88 in epoch 16, gen_loss = 0.3874562221966433, disc_loss = 0.08127892265891594
Trained batch 89 in epoch 16, gen_loss = 0.387443294790056, disc_loss = 0.08089346965878375
Trained batch 90 in epoch 16, gen_loss = 0.38701346123611535, disc_loss = 0.08118172454043895
Trained batch 91 in epoch 16, gen_loss = 0.3875224140027295, disc_loss = 0.08061920804396758
Trained batch 92 in epoch 16, gen_loss = 0.3878694054900959, disc_loss = 0.08010301528178075
Trained batch 93 in epoch 16, gen_loss = 0.3874284089245695, disc_loss = 0.08017795673135589
Trained batch 94 in epoch 16, gen_loss = 0.3874584530529223, disc_loss = 0.080707170907408
Trained batch 95 in epoch 16, gen_loss = 0.387584727567931, disc_loss = 0.08105417866318021
Trained batch 96 in epoch 16, gen_loss = 0.38710634886603995, disc_loss = 0.0841568382504905
Trained batch 97 in epoch 16, gen_loss = 0.38830117820477, disc_loss = 0.08430336785920876
Trained batch 98 in epoch 16, gen_loss = 0.38876710847170665, disc_loss = 0.0839983699514032
Trained batch 99 in epoch 16, gen_loss = 0.3881995052099228, disc_loss = 0.08456729625817389
Trained batch 100 in epoch 16, gen_loss = 0.38797122712182525, disc_loss = 0.08413793273399224
Trained batch 101 in epoch 16, gen_loss = 0.38809246584480883, disc_loss = 0.08599694826932368
Trained batch 102 in epoch 16, gen_loss = 0.38805916673928786, disc_loss = 0.08590163306324082
Trained batch 103 in epoch 16, gen_loss = 0.3878781087696552, disc_loss = 0.08624796233981705
Trained batch 104 in epoch 16, gen_loss = 0.3883345930349259, disc_loss = 0.08713271016077627
Trained batch 105 in epoch 16, gen_loss = 0.38762698561515446, disc_loss = 0.08796666992634956
Trained batch 106 in epoch 16, gen_loss = 0.38787530042300716, disc_loss = 0.08776497076239402
Trained batch 107 in epoch 16, gen_loss = 0.38840151495403713, disc_loss = 0.08741291282543291
Trained batch 108 in epoch 16, gen_loss = 0.38835070494118085, disc_loss = 0.0869924451156152
Trained batch 109 in epoch 16, gen_loss = 0.38679550750689073, disc_loss = 0.08717373146844859
Trained batch 110 in epoch 16, gen_loss = 0.3865829104775781, disc_loss = 0.08715238232115233
Trained batch 111 in epoch 16, gen_loss = 0.38666955408241066, disc_loss = 0.08665511289395258
Trained batch 112 in epoch 16, gen_loss = 0.386659831863589, disc_loss = 0.08638409463754665
Trained batch 113 in epoch 16, gen_loss = 0.3868243992328644, disc_loss = 0.08581841836291317
Trained batch 114 in epoch 16, gen_loss = 0.3867773895678313, disc_loss = 0.0855155807595862
Trained batch 115 in epoch 16, gen_loss = 0.38719934327849026, disc_loss = 0.085382684884625
Trained batch 116 in epoch 16, gen_loss = 0.38727439392326224, disc_loss = 0.08524970864303984
Trained batch 117 in epoch 16, gen_loss = 0.387499297321853, disc_loss = 0.08482798897282426
Trained batch 118 in epoch 16, gen_loss = 0.38764764130616386, disc_loss = 0.08455261629967004
Trained batch 119 in epoch 16, gen_loss = 0.387311927229166, disc_loss = 0.08464734831747288
Trained batch 120 in epoch 16, gen_loss = 0.38733329236014813, disc_loss = 0.08474968692041503
Trained batch 121 in epoch 16, gen_loss = 0.38722814521828636, disc_loss = 0.08504866476964633
Trained batch 122 in epoch 16, gen_loss = 0.38772485023591574, disc_loss = 0.08605152257619714
Trained batch 123 in epoch 16, gen_loss = 0.3879717929709342, disc_loss = 0.08618402803662203
Trained batch 124 in epoch 16, gen_loss = 0.3886667807102203, disc_loss = 0.08621080885455012
Trained batch 125 in epoch 16, gen_loss = 0.3884418154992754, disc_loss = 0.08622330182882411
Trained batch 126 in epoch 16, gen_loss = 0.3879925526502564, disc_loss = 0.08577676313584597
Trained batch 127 in epoch 16, gen_loss = 0.38827186077833176, disc_loss = 0.08535317252608365
Trained batch 128 in epoch 16, gen_loss = 0.3887122855630032, disc_loss = 0.0850969341857893
Trained batch 129 in epoch 16, gen_loss = 0.388711604475975, disc_loss = 0.08540384118588498
Trained batch 130 in epoch 16, gen_loss = 0.38875155685512164, disc_loss = 0.08568525788879008
Trained batch 131 in epoch 16, gen_loss = 0.38981304295135266, disc_loss = 0.08656089275609702
Trained batch 132 in epoch 16, gen_loss = 0.389774716662285, disc_loss = 0.08621894576257669
Trained batch 133 in epoch 16, gen_loss = 0.38947643940128496, disc_loss = 0.0860947487535261
Trained batch 134 in epoch 16, gen_loss = 0.38920768521450183, disc_loss = 0.08667866579015497
Trained batch 135 in epoch 16, gen_loss = 0.3900691001292537, disc_loss = 0.0889633231323815
Trained batch 136 in epoch 16, gen_loss = 0.39002679059975337, disc_loss = 0.08858365013202937
Trained batch 137 in epoch 16, gen_loss = 0.3894603369028672, disc_loss = 0.08993347698782125
Trained batch 138 in epoch 16, gen_loss = 0.389691967329533, disc_loss = 0.09083783033927031
Trained batch 139 in epoch 16, gen_loss = 0.38961906028645377, disc_loss = 0.09054970445577055
Trained batch 140 in epoch 16, gen_loss = 0.389162503869821, disc_loss = 0.09028618996434495
Trained batch 141 in epoch 16, gen_loss = 0.3886592616917382, disc_loss = 0.09022597110384262
Trained batch 142 in epoch 16, gen_loss = 0.3887468584767588, disc_loss = 0.08994055406183943
Trained batch 143 in epoch 16, gen_loss = 0.38877793215215206, disc_loss = 0.089781956925031
Trained batch 144 in epoch 16, gen_loss = 0.388167575721083, disc_loss = 0.09077514592108542
Trained batch 145 in epoch 16, gen_loss = 0.3889888937342657, disc_loss = 0.0914952814904335
Trained batch 146 in epoch 16, gen_loss = 0.3892536463380671, disc_loss = 0.09098209420117695
Trained batch 147 in epoch 16, gen_loss = 0.38895999318039093, disc_loss = 0.09070944934265336
Trained batch 148 in epoch 16, gen_loss = 0.38886542048230266, disc_loss = 0.09032157540708881
Trained batch 149 in epoch 16, gen_loss = 0.3883378412326177, disc_loss = 0.09004256737418473
Trained batch 150 in epoch 16, gen_loss = 0.3886233001750037, disc_loss = 0.0898857838289183
Trained batch 151 in epoch 16, gen_loss = 0.38863000979549006, disc_loss = 0.0900933041304693
Trained batch 152 in epoch 16, gen_loss = 0.3895762293946509, disc_loss = 0.08992286603228232
Trained batch 153 in epoch 16, gen_loss = 0.38960702833417177, disc_loss = 0.09000793459534935
Trained batch 154 in epoch 16, gen_loss = 0.3893203568074011, disc_loss = 0.09156179093725739
Trained batch 155 in epoch 16, gen_loss = 0.38999415265444, disc_loss = 0.09118681307583569
Trained batch 156 in epoch 16, gen_loss = 0.389958424173343, disc_loss = 0.09165977095520705
Trained batch 157 in epoch 16, gen_loss = 0.3901757331965845, disc_loss = 0.09129625105864922
Trained batch 158 in epoch 16, gen_loss = 0.38986258817918645, disc_loss = 0.09202483680345258
Trained batch 159 in epoch 16, gen_loss = 0.3900597358122468, disc_loss = 0.0920409246784402
Trained batch 160 in epoch 16, gen_loss = 0.3902200871372815, disc_loss = 0.09160876071358227
Trained batch 161 in epoch 16, gen_loss = 0.3903005321820577, disc_loss = 0.09141226578216402
Trained batch 162 in epoch 16, gen_loss = 0.39010354382860146, disc_loss = 0.09093190824750103
Trained batch 163 in epoch 16, gen_loss = 0.3907685018167263, disc_loss = 0.09051564010144098
Trained batch 164 in epoch 16, gen_loss = 0.3906707089958769, disc_loss = 0.09013057623453664
Trained batch 165 in epoch 16, gen_loss = 0.3904825448989868, disc_loss = 0.08978743686520281
Trained batch 166 in epoch 16, gen_loss = 0.3907971412478807, disc_loss = 0.08943280784279375
Trained batch 167 in epoch 16, gen_loss = 0.39082036735046477, disc_loss = 0.08940128486747631
Trained batch 168 in epoch 16, gen_loss = 0.39095221874276564, disc_loss = 0.08970799814281467
Trained batch 169 in epoch 16, gen_loss = 0.3913555327583762, disc_loss = 0.08996159374330412
Trained batch 170 in epoch 16, gen_loss = 0.3908725922916368, disc_loss = 0.08967630357388952
Trained batch 171 in epoch 16, gen_loss = 0.3911294807181802, disc_loss = 0.08931119946037354
Trained batch 172 in epoch 16, gen_loss = 0.3909280267409507, disc_loss = 0.08894679480302282
Trained batch 173 in epoch 16, gen_loss = 0.3908778197806457, disc_loss = 0.08873082111032958
Trained batch 174 in epoch 16, gen_loss = 0.39035757660865783, disc_loss = 0.08878721969734345
Trained batch 175 in epoch 16, gen_loss = 0.3906382859091867, disc_loss = 0.0888249965580392
Trained batch 176 in epoch 16, gen_loss = 0.3905817421816163, disc_loss = 0.08861131804316479
Trained batch 177 in epoch 16, gen_loss = 0.39076117735900234, disc_loss = 0.08825160778818254
Trained batch 178 in epoch 16, gen_loss = 0.3913619658134503, disc_loss = 0.08793952959386746
Trained batch 179 in epoch 16, gen_loss = 0.3915423654847675, disc_loss = 0.0878614972681842
Trained batch 180 in epoch 16, gen_loss = 0.39114765798189366, disc_loss = 0.08774762660604567
Trained batch 181 in epoch 16, gen_loss = 0.3912397331588871, disc_loss = 0.08781429656760788
Trained batch 182 in epoch 16, gen_loss = 0.39178365827258166, disc_loss = 0.08764454865156383
Trained batch 183 in epoch 16, gen_loss = 0.39214809352289076, disc_loss = 0.08738601070312459
Trained batch 184 in epoch 16, gen_loss = 0.3920216260729609, disc_loss = 0.0882530023142494
Trained batch 185 in epoch 16, gen_loss = 0.3918727254995736, disc_loss = 0.0882019430664318
Trained batch 186 in epoch 16, gen_loss = 0.39238265236431263, disc_loss = 0.08790994228615878
Trained batch 187 in epoch 16, gen_loss = 0.39223232041014, disc_loss = 0.08772049646358937
Trained batch 188 in epoch 16, gen_loss = 0.39237949725181337, disc_loss = 0.08755347268931844
Trained batch 189 in epoch 16, gen_loss = 0.3928643951290532, disc_loss = 0.08770230944072338
Trained batch 190 in epoch 16, gen_loss = 0.3927172096299876, disc_loss = 0.08761402143711584
Trained batch 191 in epoch 16, gen_loss = 0.3928006586308281, disc_loss = 0.08744784390485923
Trained batch 192 in epoch 16, gen_loss = 0.39361520165606484, disc_loss = 0.08736788833012003
Trained batch 193 in epoch 16, gen_loss = 0.39397876241157964, disc_loss = 0.0873171568478544
Trained batch 194 in epoch 16, gen_loss = 0.39398344250825734, disc_loss = 0.0871811343715168
Trained batch 195 in epoch 16, gen_loss = 0.39381033805560095, disc_loss = 0.08779154083339916
Trained batch 196 in epoch 16, gen_loss = 0.393833625891487, disc_loss = 0.08975483231520667
Trained batch 197 in epoch 16, gen_loss = 0.3933879582568853, disc_loss = 0.08969764942256263
Trained batch 198 in epoch 16, gen_loss = 0.39301066108085403, disc_loss = 0.08973957680811609
Trained batch 199 in epoch 16, gen_loss = 0.39297148302197454, disc_loss = 0.08965609815204516
Trained batch 200 in epoch 16, gen_loss = 0.3926958111091633, disc_loss = 0.08971797493494936
Trained batch 201 in epoch 16, gen_loss = 0.39274178622382705, disc_loss = 0.08940807983767943
Trained batch 202 in epoch 16, gen_loss = 0.39249614908777436, disc_loss = 0.08924973737035552
Trained batch 203 in epoch 16, gen_loss = 0.39269883755375357, disc_loss = 0.08890773738761816
Trained batch 204 in epoch 16, gen_loss = 0.3928894108388482, disc_loss = 0.08893542619785522
Trained batch 205 in epoch 16, gen_loss = 0.3931379308110302, disc_loss = 0.08906826991090569
Trained batch 206 in epoch 16, gen_loss = 0.39335435873644364, disc_loss = 0.08880505850538611
Trained batch 207 in epoch 16, gen_loss = 0.39302342757582664, disc_loss = 0.08860197094886993
Trained batch 208 in epoch 16, gen_loss = 0.3931898324968712, disc_loss = 0.08862852570088357
Trained batch 209 in epoch 16, gen_loss = 0.39270938308466047, disc_loss = 0.08960989689942273
Trained batch 210 in epoch 16, gen_loss = 0.39250957358504923, disc_loss = 0.08997194424174479
Trained batch 211 in epoch 16, gen_loss = 0.39236422150202516, disc_loss = 0.0898496083814194
Trained batch 212 in epoch 16, gen_loss = 0.3919539965094535, disc_loss = 0.08984489036951336
Trained batch 213 in epoch 16, gen_loss = 0.3923342179193675, disc_loss = 0.0896406026195874
Trained batch 214 in epoch 16, gen_loss = 0.3921843699244566, disc_loss = 0.08930272982607401
Trained batch 215 in epoch 16, gen_loss = 0.39222724915102675, disc_loss = 0.08893764568535888
Trained batch 216 in epoch 16, gen_loss = 0.392329893765911, disc_loss = 0.08866357694547367
Trained batch 217 in epoch 16, gen_loss = 0.39225114020732565, disc_loss = 0.08833156253740944
Trained batch 218 in epoch 16, gen_loss = 0.39233727161198445, disc_loss = 0.08800125910717671
Trained batch 219 in epoch 16, gen_loss = 0.3922241827303713, disc_loss = 0.08783578562169252
Trained batch 220 in epoch 16, gen_loss = 0.39203860668035656, disc_loss = 0.08795821687998882
Trained batch 221 in epoch 16, gen_loss = 0.3925185320345131, disc_loss = 0.08775060811197502
Trained batch 222 in epoch 16, gen_loss = 0.39244692221350735, disc_loss = 0.08748218735613163
Trained batch 223 in epoch 16, gen_loss = 0.39245396945625544, disc_loss = 0.0873179196350975
Trained batch 224 in epoch 16, gen_loss = 0.39254595200220743, disc_loss = 0.08726917493053608
Trained batch 225 in epoch 16, gen_loss = 0.39255566842260614, disc_loss = 0.08710629226994264
Trained batch 226 in epoch 16, gen_loss = 0.3924256315052772, disc_loss = 0.08718806220678046
Trained batch 227 in epoch 16, gen_loss = 0.3931924487676537, disc_loss = 0.08746742572545547
Trained batch 228 in epoch 16, gen_loss = 0.393251150586199, disc_loss = 0.08713282411104661
Trained batch 229 in epoch 16, gen_loss = 0.393195870777835, disc_loss = 0.0874932341662276
Trained batch 230 in epoch 16, gen_loss = 0.39342483839431364, disc_loss = 0.08758542874376431
Trained batch 231 in epoch 16, gen_loss = 0.3936981797732156, disc_loss = 0.0874567069494615
Trained batch 232 in epoch 16, gen_loss = 0.3936504637222945, disc_loss = 0.08733934254181679
Trained batch 233 in epoch 16, gen_loss = 0.3935753073957231, disc_loss = 0.08706645926054662
Trained batch 234 in epoch 16, gen_loss = 0.39358564970341137, disc_loss = 0.08685247963690694
Trained batch 235 in epoch 16, gen_loss = 0.39352451820494766, disc_loss = 0.08672637133109304
Trained batch 236 in epoch 16, gen_loss = 0.3929694429480074, disc_loss = 0.08681874678819931
Trained batch 237 in epoch 16, gen_loss = 0.3932867368229297, disc_loss = 0.08658039824011884
Trained batch 238 in epoch 16, gen_loss = 0.39311395728937254, disc_loss = 0.08658831570274099
Trained batch 239 in epoch 16, gen_loss = 0.3928199030458927, disc_loss = 0.0873023638559971
Trained batch 240 in epoch 16, gen_loss = 0.3929767079373118, disc_loss = 0.08704803504351202
Trained batch 241 in epoch 16, gen_loss = 0.39306501280670325, disc_loss = 0.08689182175300277
Trained batch 242 in epoch 16, gen_loss = 0.3929451787422714, disc_loss = 0.0867575007575131
Trained batch 243 in epoch 16, gen_loss = 0.3928109505137459, disc_loss = 0.0865296365093959
Trained batch 244 in epoch 16, gen_loss = 0.3926880609016029, disc_loss = 0.08627513371674078
Trained batch 245 in epoch 16, gen_loss = 0.3928136147134672, disc_loss = 0.0869975069867129
Trained batch 246 in epoch 16, gen_loss = 0.39232286509232, disc_loss = 0.08850311585758561
Trained batch 247 in epoch 16, gen_loss = 0.39217428322280606, disc_loss = 0.08886542283712075
Trained batch 248 in epoch 16, gen_loss = 0.3921597999741275, disc_loss = 0.0893172901628696
Trained batch 249 in epoch 16, gen_loss = 0.3921136475801468, disc_loss = 0.08951883707754314
Trained batch 250 in epoch 16, gen_loss = 0.3919523757292455, disc_loss = 0.08928302828170567
Trained batch 251 in epoch 16, gen_loss = 0.3917563433448474, disc_loss = 0.08937520106389586
Trained batch 252 in epoch 16, gen_loss = 0.39149907643615967, disc_loss = 0.08942059805734533
Trained batch 253 in epoch 16, gen_loss = 0.39141559776828044, disc_loss = 0.08911866381375749
Trained batch 254 in epoch 16, gen_loss = 0.39121718044374504, disc_loss = 0.08887861291969232
Trained batch 255 in epoch 16, gen_loss = 0.3914274323033169, disc_loss = 0.0886133745789266
Trained batch 256 in epoch 16, gen_loss = 0.39107619220180734, disc_loss = 0.08857128428338741
Trained batch 257 in epoch 16, gen_loss = 0.39130897011405735, disc_loss = 0.08844438245584972
Trained batch 258 in epoch 16, gen_loss = 0.3912391564790807, disc_loss = 0.08848929164830495
Trained batch 259 in epoch 16, gen_loss = 0.39130089179827615, disc_loss = 0.08871968521629102
Trained batch 260 in epoch 16, gen_loss = 0.3913595182000449, disc_loss = 0.088514921721071
Trained batch 261 in epoch 16, gen_loss = 0.39113052951470584, disc_loss = 0.08865915518787242
Trained batch 262 in epoch 16, gen_loss = 0.3915715179062615, disc_loss = 0.08937251132810241
Trained batch 263 in epoch 16, gen_loss = 0.39145460295857804, disc_loss = 0.08908109056276524
Trained batch 264 in epoch 16, gen_loss = 0.3912421617867812, disc_loss = 0.08906184263211095
Trained batch 265 in epoch 16, gen_loss = 0.391290080054362, disc_loss = 0.08880218284211605
Trained batch 266 in epoch 16, gen_loss = 0.39145540956700786, disc_loss = 0.0885800502981558
Trained batch 267 in epoch 16, gen_loss = 0.3915600266251991, disc_loss = 0.08833549634393638
Trained batch 268 in epoch 16, gen_loss = 0.39141770178057445, disc_loss = 0.08824220998905129
Trained batch 269 in epoch 16, gen_loss = 0.3912602500783073, disc_loss = 0.08803231217898429
Trained batch 270 in epoch 16, gen_loss = 0.3908561359252437, disc_loss = 0.08799146103236233
Trained batch 271 in epoch 16, gen_loss = 0.39106121692149076, disc_loss = 0.08775308951975175
Trained batch 272 in epoch 16, gen_loss = 0.39073248780690706, disc_loss = 0.0879895819108865
Trained batch 273 in epoch 16, gen_loss = 0.3908793342157002, disc_loss = 0.08879613647081067
Trained batch 274 in epoch 16, gen_loss = 0.39042572422461075, disc_loss = 0.08898644603619521
Trained batch 275 in epoch 16, gen_loss = 0.3907185233589532, disc_loss = 0.08890702876943987
Trained batch 276 in epoch 16, gen_loss = 0.3907936423048646, disc_loss = 0.08873985468877298
Trained batch 277 in epoch 16, gen_loss = 0.3908188627134982, disc_loss = 0.08854736656238653
Trained batch 278 in epoch 16, gen_loss = 0.3907054466158686, disc_loss = 0.08827003629170492
Trained batch 279 in epoch 16, gen_loss = 0.3904727835740362, disc_loss = 0.08838378452596121
Trained batch 280 in epoch 16, gen_loss = 0.3907310111030565, disc_loss = 0.08812532868415276
Trained batch 281 in epoch 16, gen_loss = 0.3908878119913399, disc_loss = 0.08836865356581695
Trained batch 282 in epoch 16, gen_loss = 0.3906111306520738, disc_loss = 0.08869394702284002
Trained batch 283 in epoch 16, gen_loss = 0.39080641880421574, disc_loss = 0.08847712439609508
Trained batch 284 in epoch 16, gen_loss = 0.39102992185375146, disc_loss = 0.08839242254596269
Trained batch 285 in epoch 16, gen_loss = 0.39099943064726317, disc_loss = 0.08836729069227366
Trained batch 286 in epoch 16, gen_loss = 0.39080133286502716, disc_loss = 0.08832785936448892
Trained batch 287 in epoch 16, gen_loss = 0.3904720988745491, disc_loss = 0.08823539239205679
Trained batch 288 in epoch 16, gen_loss = 0.39037242294595315, disc_loss = 0.08811364714926347
Trained batch 289 in epoch 16, gen_loss = 0.3907220824011441, disc_loss = 0.08830374918781735
Trained batch 290 in epoch 16, gen_loss = 0.39062821076498, disc_loss = 0.08812262345892713
Trained batch 291 in epoch 16, gen_loss = 0.3905175650772983, disc_loss = 0.08802243198542409
Trained batch 292 in epoch 16, gen_loss = 0.39058087272855607, disc_loss = 0.08780188409217439
Trained batch 293 in epoch 16, gen_loss = 0.39093390411260176, disc_loss = 0.08766502000828635
Trained batch 294 in epoch 16, gen_loss = 0.39120981753882716, disc_loss = 0.08774136060659411
Trained batch 295 in epoch 16, gen_loss = 0.39117060541301163, disc_loss = 0.08794384342272187
Trained batch 296 in epoch 16, gen_loss = 0.39135966608018585, disc_loss = 0.0878749370201795
Trained batch 297 in epoch 16, gen_loss = 0.39148257732791386, disc_loss = 0.08765716451507737
Trained batch 298 in epoch 16, gen_loss = 0.3914229537930377, disc_loss = 0.08769523963662344
Trained batch 299 in epoch 16, gen_loss = 0.39144432932138445, disc_loss = 0.08799049124897768
Trained batch 300 in epoch 16, gen_loss = 0.3914258971166769, disc_loss = 0.0879618881032044
Trained batch 301 in epoch 16, gen_loss = 0.3912829516936612, disc_loss = 0.08783538370171179
Trained batch 302 in epoch 16, gen_loss = 0.39147334690928065, disc_loss = 0.08758772819736364
Trained batch 303 in epoch 16, gen_loss = 0.3915158934695156, disc_loss = 0.08742823673406076
Trained batch 304 in epoch 16, gen_loss = 0.3915418557456282, disc_loss = 0.08730313400356252
Trained batch 305 in epoch 16, gen_loss = 0.39193469724234414, disc_loss = 0.08708962942838815
Trained batch 306 in epoch 16, gen_loss = 0.3920505668130682, disc_loss = 0.08689315842634449
Trained batch 307 in epoch 16, gen_loss = 0.3921485027516043, disc_loss = 0.08664612860158812
Trained batch 308 in epoch 16, gen_loss = 0.3923278526195045, disc_loss = 0.08644329697876252
Trained batch 309 in epoch 16, gen_loss = 0.39232263228585645, disc_loss = 0.08624301622922141
Trained batch 310 in epoch 16, gen_loss = 0.39242290080168624, disc_loss = 0.0861344526168498
Trained batch 311 in epoch 16, gen_loss = 0.39215931334556675, disc_loss = 0.08648561446730477
Trained batch 312 in epoch 16, gen_loss = 0.39260532033329193, disc_loss = 0.08721475364319003
Trained batch 313 in epoch 16, gen_loss = 0.39243346908289917, disc_loss = 0.08704434733120071
Trained batch 314 in epoch 16, gen_loss = 0.3923577092942737, disc_loss = 0.08720040188156186
Trained batch 315 in epoch 16, gen_loss = 0.3925500650760494, disc_loss = 0.08699446038160284
Trained batch 316 in epoch 16, gen_loss = 0.3928911149125746, disc_loss = 0.08675491455384186
Trained batch 317 in epoch 16, gen_loss = 0.39292794700313666, disc_loss = 0.08662448149121735
Trained batch 318 in epoch 16, gen_loss = 0.39308295036931773, disc_loss = 0.08647699047282899
Trained batch 319 in epoch 16, gen_loss = 0.39327898509800435, disc_loss = 0.0863134477098356
Trained batch 320 in epoch 16, gen_loss = 0.39330384580888483, disc_loss = 0.08620770320128011
Trained batch 321 in epoch 16, gen_loss = 0.3934347654536644, disc_loss = 0.08616755678758072
Trained batch 322 in epoch 16, gen_loss = 0.39337999219126746, disc_loss = 0.08602625097439338
Trained batch 323 in epoch 16, gen_loss = 0.39340928141717557, disc_loss = 0.08590152040325151
Trained batch 324 in epoch 16, gen_loss = 0.39345382360311654, disc_loss = 0.08573417438194156
Trained batch 325 in epoch 16, gen_loss = 0.3935706310111321, disc_loss = 0.08557753981822427
Trained batch 326 in epoch 16, gen_loss = 0.39340966393094545, disc_loss = 0.08551330319164314
Trained batch 327 in epoch 16, gen_loss = 0.3935982517716361, disc_loss = 0.08559163638657503
Trained batch 328 in epoch 16, gen_loss = 0.39337582211364003, disc_loss = 0.08571874417540105
Trained batch 329 in epoch 16, gen_loss = 0.393346751278097, disc_loss = 0.08564368053339422
Trained batch 330 in epoch 16, gen_loss = 0.3933611669749292, disc_loss = 0.08542982987592453
Trained batch 331 in epoch 16, gen_loss = 0.39342869620725335, disc_loss = 0.08521077362960766
Trained batch 332 in epoch 16, gen_loss = 0.393401213773378, disc_loss = 0.08515300562146592
Trained batch 333 in epoch 16, gen_loss = 0.39338206896881855, disc_loss = 0.08497283550977573
Trained batch 334 in epoch 16, gen_loss = 0.39314505742557015, disc_loss = 0.08510410270945572
Trained batch 335 in epoch 16, gen_loss = 0.3933051667575325, disc_loss = 0.08538522670139737
Trained batch 336 in epoch 16, gen_loss = 0.3935233146748132, disc_loss = 0.08532401595612883
Trained batch 337 in epoch 16, gen_loss = 0.3937525841787722, disc_loss = 0.08512689079676022
Trained batch 338 in epoch 16, gen_loss = 0.39363217661514394, disc_loss = 0.08493641832195069
Trained batch 339 in epoch 16, gen_loss = 0.39370186267530216, disc_loss = 0.08507650919833823
Trained batch 340 in epoch 16, gen_loss = 0.3934868975293951, disc_loss = 0.08544486997201164
Trained batch 341 in epoch 16, gen_loss = 0.39365530528171716, disc_loss = 0.08535369916012979
Trained batch 342 in epoch 16, gen_loss = 0.393630371583794, disc_loss = 0.08530510906754578
Trained batch 343 in epoch 16, gen_loss = 0.3936398557798807, disc_loss = 0.08556485424213502
Trained batch 344 in epoch 16, gen_loss = 0.3936696711657704, disc_loss = 0.08555358716462186
Trained batch 345 in epoch 16, gen_loss = 0.3936272882829512, disc_loss = 0.08547373373475937
Trained batch 346 in epoch 16, gen_loss = 0.3935343604266472, disc_loss = 0.08535304402674868
Trained batch 347 in epoch 16, gen_loss = 0.393870170774131, disc_loss = 0.08609408537466508
Trained batch 348 in epoch 16, gen_loss = 0.3937167753292018, disc_loss = 0.08617323226186001
Trained batch 349 in epoch 16, gen_loss = 0.39368496409484316, disc_loss = 0.08612052590852337
Trained batch 350 in epoch 16, gen_loss = 0.3936027723160225, disc_loss = 0.0860024457890275
Trained batch 351 in epoch 16, gen_loss = 0.3935662993991917, disc_loss = 0.08585364814048675
Trained batch 352 in epoch 16, gen_loss = 0.39327216688701855, disc_loss = 0.08581842737610085
Trained batch 353 in epoch 16, gen_loss = 0.3932892281120106, disc_loss = 0.08565801759987102
Trained batch 354 in epoch 16, gen_loss = 0.3931153226066643, disc_loss = 0.08552616909277481
Trained batch 355 in epoch 16, gen_loss = 0.3934589670447821, disc_loss = 0.08566570339666868
Trained batch 356 in epoch 16, gen_loss = 0.39321083823839825, disc_loss = 0.08583480269055949
Trained batch 357 in epoch 16, gen_loss = 0.3933408695725755, disc_loss = 0.08588474902698989
Trained batch 358 in epoch 16, gen_loss = 0.3931733507631881, disc_loss = 0.08579246647017788
Trained batch 359 in epoch 16, gen_loss = 0.3930161026616891, disc_loss = 0.08570953562157228
Trained batch 360 in epoch 16, gen_loss = 0.3929912545344176, disc_loss = 0.08560864163118923
Trained batch 361 in epoch 16, gen_loss = 0.39287288338769205, disc_loss = 0.08551052943494644
Trained batch 362 in epoch 16, gen_loss = 0.3930328978487283, disc_loss = 0.08545904875586717
Trained batch 363 in epoch 16, gen_loss = 0.39335615400757107, disc_loss = 0.08544808661099523
Trained batch 364 in epoch 16, gen_loss = 0.39345261307611856, disc_loss = 0.08531438052169468
Trained batch 365 in epoch 16, gen_loss = 0.3934769745244355, disc_loss = 0.0851505982849869
Trained batch 366 in epoch 16, gen_loss = 0.39337862203816304, disc_loss = 0.085037104659828
Trained batch 367 in epoch 16, gen_loss = 0.39332176088962867, disc_loss = 0.08496850377338452
Trained batch 368 in epoch 16, gen_loss = 0.39349597337123177, disc_loss = 0.08516416043108758
Trained batch 369 in epoch 16, gen_loss = 0.39341092431867447, disc_loss = 0.08535729091538972
Trained batch 370 in epoch 16, gen_loss = 0.3934849972994822, disc_loss = 0.08516984110738268
Trained batch 371 in epoch 16, gen_loss = 0.3935443968061478, disc_loss = 0.0850791843640568
Trained batch 372 in epoch 16, gen_loss = 0.39353532206277103, disc_loss = 0.08497181922402083
Trained batch 373 in epoch 16, gen_loss = 0.3934516198335484, disc_loss = 0.084784156148556
Trained batch 374 in epoch 16, gen_loss = 0.3934259362220764, disc_loss = 0.08469659892593821
Trained batch 375 in epoch 16, gen_loss = 0.39322475890846964, disc_loss = 0.08460943091616153
Trained batch 376 in epoch 16, gen_loss = 0.39319481805401707, disc_loss = 0.08458286391284603
Trained batch 377 in epoch 16, gen_loss = 0.3929743621715162, disc_loss = 0.08467117665340464
Trained batch 378 in epoch 16, gen_loss = 0.393182670535387, disc_loss = 0.0848368857643201
Trained batch 379 in epoch 16, gen_loss = 0.39310035431071333, disc_loss = 0.08540844399555537
Trained batch 380 in epoch 16, gen_loss = 0.39348260569447296, disc_loss = 0.08578380113076467
Trained batch 381 in epoch 16, gen_loss = 0.39365529155856027, disc_loss = 0.08571596556655205
Trained batch 382 in epoch 16, gen_loss = 0.3935629168316216, disc_loss = 0.08573719092545054
Trained batch 383 in epoch 16, gen_loss = 0.39333076860445243, disc_loss = 0.08578737095497975
Trained batch 384 in epoch 16, gen_loss = 0.39340923281459067, disc_loss = 0.08579814909993634
Trained batch 385 in epoch 16, gen_loss = 0.3933520337923821, disc_loss = 0.08569444515115046
Trained batch 386 in epoch 16, gen_loss = 0.3932732843459423, disc_loss = 0.0856595270766441
Trained batch 387 in epoch 16, gen_loss = 0.39327979779120575, disc_loss = 0.08587725076358765
Trained batch 388 in epoch 16, gen_loss = 0.3931504955328522, disc_loss = 0.0860434834926765
Trained batch 389 in epoch 16, gen_loss = 0.39320466480193994, disc_loss = 0.08589513381489386
Trained batch 390 in epoch 16, gen_loss = 0.3932936411836873, disc_loss = 0.08584108488881946
Trained batch 391 in epoch 16, gen_loss = 0.39312981129909047, disc_loss = 0.08574049032592614
Trained batch 392 in epoch 16, gen_loss = 0.3928394925048333, disc_loss = 0.08585219144342472
Trained batch 393 in epoch 16, gen_loss = 0.3929817031331474, disc_loss = 0.0857257061687577
Trained batch 394 in epoch 16, gen_loss = 0.3931186412708669, disc_loss = 0.08559079707211142
Trained batch 395 in epoch 16, gen_loss = 0.39321554790843616, disc_loss = 0.08550075664904645
Trained batch 396 in epoch 16, gen_loss = 0.3932347965780974, disc_loss = 0.08551911322249836
Trained batch 397 in epoch 16, gen_loss = 0.3932282880472778, disc_loss = 0.08542163545925675
Trained batch 398 in epoch 16, gen_loss = 0.39342048308604344, disc_loss = 0.08537139937183574
Trained batch 399 in epoch 16, gen_loss = 0.3933253308385611, disc_loss = 0.08527541146031581
Trained batch 400 in epoch 16, gen_loss = 0.39311201376213395, disc_loss = 0.0851517484054211
Trained batch 401 in epoch 16, gen_loss = 0.393178626376005, disc_loss = 0.08512934443160929
Trained batch 402 in epoch 16, gen_loss = 0.3933535766956528, disc_loss = 0.08512466089689073
Trained batch 403 in epoch 16, gen_loss = 0.3934688898596433, disc_loss = 0.08519151594171688
Trained batch 404 in epoch 16, gen_loss = 0.39351014870184436, disc_loss = 0.08527772288056619
Trained batch 405 in epoch 16, gen_loss = 0.39316638078301996, disc_loss = 0.08577518203075553
Trained batch 406 in epoch 16, gen_loss = 0.39365409918733546, disc_loss = 0.08599166148651108
Trained batch 407 in epoch 16, gen_loss = 0.39369432036491003, disc_loss = 0.08586023561998873
Trained batch 408 in epoch 16, gen_loss = 0.39352581699203454, disc_loss = 0.08621094917222712
Trained batch 409 in epoch 16, gen_loss = 0.3935021483316654, disc_loss = 0.08624369044470169
Trained batch 410 in epoch 16, gen_loss = 0.3936232516945424, disc_loss = 0.0863780551182147
Trained batch 411 in epoch 16, gen_loss = 0.39355747691057263, disc_loss = 0.08635475193896304
Trained batch 412 in epoch 16, gen_loss = 0.39363888165852634, disc_loss = 0.08656581161435487
Trained batch 413 in epoch 16, gen_loss = 0.3936780741537251, disc_loss = 0.08662455646289684
Trained batch 414 in epoch 16, gen_loss = 0.39361801707600974, disc_loss = 0.08662970543962466
Trained batch 415 in epoch 16, gen_loss = 0.39341346016870093, disc_loss = 0.0870310673165547
Trained batch 416 in epoch 16, gen_loss = 0.3933785881498735, disc_loss = 0.08696475662000709
Trained batch 417 in epoch 16, gen_loss = 0.3935564106160944, disc_loss = 0.08691631012783346
Trained batch 418 in epoch 16, gen_loss = 0.393549512636121, disc_loss = 0.08688388237960833
Trained batch 419 in epoch 16, gen_loss = 0.3936405844631649, disc_loss = 0.08681917263616232
Trained batch 420 in epoch 16, gen_loss = 0.39358790151580214, disc_loss = 0.0868352705960089
Trained batch 421 in epoch 16, gen_loss = 0.39354586474138414, disc_loss = 0.08674744531949231
Trained batch 422 in epoch 16, gen_loss = 0.39342695087123986, disc_loss = 0.08669525368500228
Trained batch 423 in epoch 16, gen_loss = 0.3935031797385441, disc_loss = 0.08684031803595815
Trained batch 424 in epoch 16, gen_loss = 0.3932472990540897, disc_loss = 0.08727174434043905
Trained batch 425 in epoch 16, gen_loss = 0.3935230080510529, disc_loss = 0.08736852032980694
Trained batch 426 in epoch 16, gen_loss = 0.39346014462254364, disc_loss = 0.0873523282238328
Trained batch 427 in epoch 16, gen_loss = 0.39316536061396107, disc_loss = 0.0878896641830052
Trained batch 428 in epoch 16, gen_loss = 0.3929928249412483, disc_loss = 0.08778111260093419
Trained batch 429 in epoch 16, gen_loss = 0.3930047241061233, disc_loss = 0.08762557355275508
Trained batch 430 in epoch 16, gen_loss = 0.392920953768312, disc_loss = 0.08750956575872415
Trained batch 431 in epoch 16, gen_loss = 0.3930461512257655, disc_loss = 0.08743935078705868
Trained batch 432 in epoch 16, gen_loss = 0.39293891927937163, disc_loss = 0.0874963548350606
Trained batch 433 in epoch 16, gen_loss = 0.3927149123722507, disc_loss = 0.08779104565879682
Trained batch 434 in epoch 16, gen_loss = 0.39257990375332447, disc_loss = 0.08800636071219355
Trained batch 435 in epoch 16, gen_loss = 0.39255996109969027, disc_loss = 0.08815465922522948
Trained batch 436 in epoch 16, gen_loss = 0.3926921426158748, disc_loss = 0.08802001483768258
Trained batch 437 in epoch 16, gen_loss = 0.3926086800691744, disc_loss = 0.08789629181613083
Trained batch 438 in epoch 16, gen_loss = 0.39253176887920616, disc_loss = 0.08786864144566356
Trained batch 439 in epoch 16, gen_loss = 0.3925031949850646, disc_loss = 0.08819571625420146
Trained batch 440 in epoch 16, gen_loss = 0.39233618481359245, disc_loss = 0.0883301098159432
Trained batch 441 in epoch 16, gen_loss = 0.39231247019983523, disc_loss = 0.08823970356656921
Trained batch 442 in epoch 16, gen_loss = 0.39248246163062533, disc_loss = 0.08808191365228113
Trained batch 443 in epoch 16, gen_loss = 0.3925788427392642, disc_loss = 0.08802431351022778
Trained batch 444 in epoch 16, gen_loss = 0.39254553190777813, disc_loss = 0.08810103427555956
Trained batch 445 in epoch 16, gen_loss = 0.39284985302007785, disc_loss = 0.0890183775453941
Trained batch 446 in epoch 16, gen_loss = 0.3930721055607934, disc_loss = 0.08893593090588447
Trained batch 447 in epoch 16, gen_loss = 0.39302695096869555, disc_loss = 0.08885848433939307
Trained batch 448 in epoch 16, gen_loss = 0.39286170697424616, disc_loss = 0.08880128082456296
Trained batch 449 in epoch 16, gen_loss = 0.39269061969386204, disc_loss = 0.08887307888828218
Trained batch 450 in epoch 16, gen_loss = 0.3927569541989303, disc_loss = 0.08880987496501426
Trained batch 451 in epoch 16, gen_loss = 0.39269472533358935, disc_loss = 0.0887260382358331
Trained batch 452 in epoch 16, gen_loss = 0.39258043754179744, disc_loss = 0.08862728331850689
Trained batch 453 in epoch 16, gen_loss = 0.3925268500386881, disc_loss = 0.0885000792014031
Trained batch 454 in epoch 16, gen_loss = 0.3925390280210055, disc_loss = 0.0883946382972811
Trained batch 455 in epoch 16, gen_loss = 0.3923090447982152, disc_loss = 0.08842629144323598
Trained batch 456 in epoch 16, gen_loss = 0.3924411440704271, disc_loss = 0.08834993500869795
Trained batch 457 in epoch 16, gen_loss = 0.39254603245372854, disc_loss = 0.08818046714577775
Trained batch 458 in epoch 16, gen_loss = 0.3926331123625271, disc_loss = 0.08802584919587492
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.2953644394874573, disc_loss = 0.27988430857658386
Trained batch 1 in epoch 17, gen_loss = 0.40710264444351196, disc_loss = 0.19335071370005608
Trained batch 2 in epoch 17, gen_loss = 0.4168311456839244, disc_loss = 0.17603825281063715
Trained batch 3 in epoch 17, gen_loss = 0.41226375102996826, disc_loss = 0.15090727247297764
Trained batch 4 in epoch 17, gen_loss = 0.39683362245559695, disc_loss = 0.12712213397026062
Trained batch 5 in epoch 17, gen_loss = 0.3880114456017812, disc_loss = 0.1084768249032398
Trained batch 6 in epoch 17, gen_loss = 0.39438470772334505, disc_loss = 0.09669895855976003
Trained batch 7 in epoch 17, gen_loss = 0.39791837334632874, disc_loss = 0.10688742774073035
Trained batch 8 in epoch 17, gen_loss = 0.3824688262409634, disc_loss = 0.12151432171877888
Trained batch 9 in epoch 17, gen_loss = 0.3880139499902725, disc_loss = 0.11232717307284475
Trained batch 10 in epoch 17, gen_loss = 0.3930659971453927, disc_loss = 0.11497934814542532
Trained batch 11 in epoch 17, gen_loss = 0.3972824787100156, disc_loss = 0.10982668624880414
Trained batch 12 in epoch 17, gen_loss = 0.39950514756716216, disc_loss = 0.11375455766056593
Trained batch 13 in epoch 17, gen_loss = 0.3993771757398333, disc_loss = 0.12209188066689032
Trained batch 14 in epoch 17, gen_loss = 0.3997199912865957, disc_loss = 0.11508334632962942
Trained batch 15 in epoch 17, gen_loss = 0.39307827688753605, disc_loss = 0.1100274010677822
Trained batch 16 in epoch 17, gen_loss = 0.3923615778193754, disc_loss = 0.10422762905192726
Trained batch 17 in epoch 17, gen_loss = 0.40134427282545304, disc_loss = 0.10073281560714047
Trained batch 18 in epoch 17, gen_loss = 0.398643096810893, disc_loss = 0.0979126764853534
Trained batch 19 in epoch 17, gen_loss = 0.3995581388473511, disc_loss = 0.09426034479402005
Trained batch 20 in epoch 17, gen_loss = 0.3961385800724938, disc_loss = 0.0920124211392942
Trained batch 21 in epoch 17, gen_loss = 0.39549097418785095, disc_loss = 0.08907214107669213
Trained batch 22 in epoch 17, gen_loss = 0.39589832010476483, disc_loss = 0.08652304894412341
Trained batch 23 in epoch 17, gen_loss = 0.3940313036243121, disc_loss = 0.0842163834022358
Trained batch 24 in epoch 17, gen_loss = 0.38945685625076293, disc_loss = 0.08278882216662169
Trained batch 25 in epoch 17, gen_loss = 0.3905863337791883, disc_loss = 0.08029138407884882
Trained batch 26 in epoch 17, gen_loss = 0.39174507172019396, disc_loss = 0.0785196878498903
Trained batch 27 in epoch 17, gen_loss = 0.39371141897780554, disc_loss = 0.08061938756145537
Trained batch 28 in epoch 17, gen_loss = 0.39428013665922756, disc_loss = 0.08683043535284955
Trained batch 29 in epoch 17, gen_loss = 0.39520074625809987, disc_loss = 0.08637231610094508
Trained batch 30 in epoch 17, gen_loss = 0.39444274190933476, disc_loss = 0.08513526687578808
Trained batch 31 in epoch 17, gen_loss = 0.3928528856486082, disc_loss = 0.08695672565954737
Trained batch 32 in epoch 17, gen_loss = 0.39356814099080634, disc_loss = 0.08920788423468669
Trained batch 33 in epoch 17, gen_loss = 0.3945891673074049, disc_loss = 0.08769138373763245
Trained batch 34 in epoch 17, gen_loss = 0.39314528363091605, disc_loss = 0.08684645079608475
Trained batch 35 in epoch 17, gen_loss = 0.39159512105915284, disc_loss = 0.08585655924657153
Trained batch 36 in epoch 17, gen_loss = 0.3930290212502351, disc_loss = 0.08486905409576925
Trained batch 37 in epoch 17, gen_loss = 0.3917303273552342, disc_loss = 0.08527720736731824
Trained batch 38 in epoch 17, gen_loss = 0.3924428010598207, disc_loss = 0.08362954289007646
Trained batch 39 in epoch 17, gen_loss = 0.39532550573349, disc_loss = 0.0832011093152687
Trained batch 40 in epoch 17, gen_loss = 0.39626709353633044, disc_loss = 0.08302225015784909
Trained batch 41 in epoch 17, gen_loss = 0.39663144307477133, disc_loss = 0.08159737122644271
Trained batch 42 in epoch 17, gen_loss = 0.3956991593505061, disc_loss = 0.0805097188757256
Trained batch 43 in epoch 17, gen_loss = 0.3960025994615121, disc_loss = 0.08034802391193807
Trained batch 44 in epoch 17, gen_loss = 0.3970165272553762, disc_loss = 0.07933375754704078
Trained batch 45 in epoch 17, gen_loss = 0.39584452367347217, disc_loss = 0.0793374454724076
Trained batch 46 in epoch 17, gen_loss = 0.3977854239179733, disc_loss = 0.08223802947062761
Trained batch 47 in epoch 17, gen_loss = 0.39653321355581284, disc_loss = 0.080968785933995
Trained batch 48 in epoch 17, gen_loss = 0.39590539555160364, disc_loss = 0.08391872008464166
Trained batch 49 in epoch 17, gen_loss = 0.3959865754842758, disc_loss = 0.08290395421907305
Trained batch 50 in epoch 17, gen_loss = 0.39641521023769005, disc_loss = 0.08166310806557828
Trained batch 51 in epoch 17, gen_loss = 0.395815660747198, disc_loss = 0.08033533944175221
Trained batch 52 in epoch 17, gen_loss = 0.3946189464263196, disc_loss = 0.08195178159776162
Trained batch 53 in epoch 17, gen_loss = 0.39568489348446884, disc_loss = 0.08165889914595971
Trained batch 54 in epoch 17, gen_loss = 0.3958915894681757, disc_loss = 0.08095248556611213
Trained batch 55 in epoch 17, gen_loss = 0.3950449020734855, disc_loss = 0.08287565754393914
Trained batch 56 in epoch 17, gen_loss = 0.39637745210998937, disc_loss = 0.08495230552854768
Trained batch 57 in epoch 17, gen_loss = 0.39544356691426247, disc_loss = 0.08482230247544317
Trained batch 58 in epoch 17, gen_loss = 0.3946125391176191, disc_loss = 0.08705812286964412
Trained batch 59 in epoch 17, gen_loss = 0.3949072629213333, disc_loss = 0.08949144555566212
Trained batch 60 in epoch 17, gen_loss = 0.39331720842689766, disc_loss = 0.08970277852638335
Trained batch 61 in epoch 17, gen_loss = 0.39319978414043305, disc_loss = 0.0903063181998028
Trained batch 62 in epoch 17, gen_loss = 0.39341811149839373, disc_loss = 0.08910887978143162
Trained batch 63 in epoch 17, gen_loss = 0.393407101277262, disc_loss = 0.08797019909252413
Trained batch 64 in epoch 17, gen_loss = 0.39303450401012713, disc_loss = 0.0868800965639261
Trained batch 65 in epoch 17, gen_loss = 0.39226276630705054, disc_loss = 0.08631252175705
Trained batch 66 in epoch 17, gen_loss = 0.3923413673443581, disc_loss = 0.08585098085563574
Trained batch 67 in epoch 17, gen_loss = 0.391430485774489, disc_loss = 0.08522371509495903
Trained batch 68 in epoch 17, gen_loss = 0.392323260721953, disc_loss = 0.08542594378409178
Trained batch 69 in epoch 17, gen_loss = 0.3921574703284672, disc_loss = 0.08581060203058379
Trained batch 70 in epoch 17, gen_loss = 0.3930499482322747, disc_loss = 0.0865666313280522
Trained batch 71 in epoch 17, gen_loss = 0.3932107525567214, disc_loss = 0.0860152891319659
Trained batch 72 in epoch 17, gen_loss = 0.3941649655773215, disc_loss = 0.0853143538003915
Trained batch 73 in epoch 17, gen_loss = 0.3949259906201749, disc_loss = 0.0846404369316391
Trained batch 74 in epoch 17, gen_loss = 0.3955233323574066, disc_loss = 0.08405761515100797
Trained batch 75 in epoch 17, gen_loss = 0.3962855460612397, disc_loss = 0.08309207214532714
Trained batch 76 in epoch 17, gen_loss = 0.395903912844596, disc_loss = 0.08254024928266351
Trained batch 77 in epoch 17, gen_loss = 0.3952456873196822, disc_loss = 0.08211258407204579
Trained batch 78 in epoch 17, gen_loss = 0.3974086808252938, disc_loss = 0.08158674081669579
Trained batch 79 in epoch 17, gen_loss = 0.39749952480196954, disc_loss = 0.08118953425437211
Trained batch 80 in epoch 17, gen_loss = 0.3978569743074017, disc_loss = 0.08037723288123991
Trained batch 81 in epoch 17, gen_loss = 0.397509820214132, disc_loss = 0.07983227128662714
Trained batch 82 in epoch 17, gen_loss = 0.39625268564166793, disc_loss = 0.0800744193684624
Trained batch 83 in epoch 17, gen_loss = 0.3981969274935268, disc_loss = 0.07933097277280121
Trained batch 84 in epoch 17, gen_loss = 0.3987760701600243, disc_loss = 0.0797484305632465
Trained batch 85 in epoch 17, gen_loss = 0.398922526905703, disc_loss = 0.07944495064141445
Trained batch 86 in epoch 17, gen_loss = 0.3997791563642436, disc_loss = 0.07882676558333566
Trained batch 87 in epoch 17, gen_loss = 0.4000481864945455, disc_loss = 0.0785481628157537
Trained batch 88 in epoch 17, gen_loss = 0.39977882316942964, disc_loss = 0.07833804778252425
Trained batch 89 in epoch 17, gen_loss = 0.3995735108852386, disc_loss = 0.07771046652148167
Trained batch 90 in epoch 17, gen_loss = 0.39968810238680996, disc_loss = 0.07705768566210192
Trained batch 91 in epoch 17, gen_loss = 0.40090736941150995, disc_loss = 0.07648246630054453
Trained batch 92 in epoch 17, gen_loss = 0.4012450175259703, disc_loss = 0.07604177536502961
Trained batch 93 in epoch 17, gen_loss = 0.3998776094076481, disc_loss = 0.07611445480204643
Trained batch 94 in epoch 17, gen_loss = 0.39969942726586993, disc_loss = 0.07557377070188523
Trained batch 95 in epoch 17, gen_loss = 0.3995785654212038, disc_loss = 0.07518867259689917
Trained batch 96 in epoch 17, gen_loss = 0.39931980666426037, disc_loss = 0.07498214582038909
Trained batch 97 in epoch 17, gen_loss = 0.39903001760949897, disc_loss = 0.07441332172222283
Trained batch 98 in epoch 17, gen_loss = 0.39945839029369934, disc_loss = 0.07532716200056702
Trained batch 99 in epoch 17, gen_loss = 0.3980963259935379, disc_loss = 0.0791311989352107
Trained batch 100 in epoch 17, gen_loss = 0.398243784314335, disc_loss = 0.07892803161746205
Trained batch 101 in epoch 17, gen_loss = 0.3986160273061079, disc_loss = 0.07942393911527652
Trained batch 102 in epoch 17, gen_loss = 0.3981777305163226, disc_loss = 0.07936940385589322
Trained batch 103 in epoch 17, gen_loss = 0.39777684355011356, disc_loss = 0.0791397514179922
Trained batch 104 in epoch 17, gen_loss = 0.39825615400359743, disc_loss = 0.07882619425654411
Trained batch 105 in epoch 17, gen_loss = 0.39771117719839205, disc_loss = 0.07845292725371865
Trained batch 106 in epoch 17, gen_loss = 0.39778425008337076, disc_loss = 0.07809223495771951
Trained batch 107 in epoch 17, gen_loss = 0.39758114489140334, disc_loss = 0.07761037884349073
Trained batch 108 in epoch 17, gen_loss = 0.39813817695740167, disc_loss = 0.07821674409125923
Trained batch 109 in epoch 17, gen_loss = 0.3977459100159732, disc_loss = 0.0805954683572054
Trained batch 110 in epoch 17, gen_loss = 0.398160715897878, disc_loss = 0.08078392732653532
Trained batch 111 in epoch 17, gen_loss = 0.398118795560939, disc_loss = 0.08042093053726214
Trained batch 112 in epoch 17, gen_loss = 0.3980290333254147, disc_loss = 0.08088108020282425
Trained batch 113 in epoch 17, gen_loss = 0.3977308239330325, disc_loss = 0.0803429023934561
Trained batch 114 in epoch 17, gen_loss = 0.39765293028043663, disc_loss = 0.07984811112932537
Trained batch 115 in epoch 17, gen_loss = 0.3977095677421011, disc_loss = 0.07929245129645128
Trained batch 116 in epoch 17, gen_loss = 0.39867932139298856, disc_loss = 0.07939237774087068
Trained batch 117 in epoch 17, gen_loss = 0.39801859350527746, disc_loss = 0.07994708062891485
Trained batch 118 in epoch 17, gen_loss = 0.3984388668997949, disc_loss = 0.08045848813534033
Trained batch 119 in epoch 17, gen_loss = 0.3984944706161817, disc_loss = 0.08030619249523928
Trained batch 120 in epoch 17, gen_loss = 0.3987059630145711, disc_loss = 0.07978733839113111
Trained batch 121 in epoch 17, gen_loss = 0.3987442680069658, disc_loss = 0.07936121733309548
Trained batch 122 in epoch 17, gen_loss = 0.3992613563692667, disc_loss = 0.07897909769288651
Trained batch 123 in epoch 17, gen_loss = 0.3996708820904455, disc_loss = 0.07902997079485606
Trained batch 124 in epoch 17, gen_loss = 0.39991598439216614, disc_loss = 0.07885989543050527
Trained batch 125 in epoch 17, gen_loss = 0.400276266156681, disc_loss = 0.07834711910358497
Trained batch 126 in epoch 17, gen_loss = 0.39994517062592694, disc_loss = 0.07788418579523958
Trained batch 127 in epoch 17, gen_loss = 0.3996024446096271, disc_loss = 0.07750164628669154
Trained batch 128 in epoch 17, gen_loss = 0.39959433582402015, disc_loss = 0.0770511355020048
Trained batch 129 in epoch 17, gen_loss = 0.3993716634236849, disc_loss = 0.07686235891798368
Trained batch 130 in epoch 17, gen_loss = 0.39962368111574015, disc_loss = 0.07651918820809317
Trained batch 131 in epoch 17, gen_loss = 0.39966106008399616, disc_loss = 0.07604167634395487
Trained batch 132 in epoch 17, gen_loss = 0.3999082009146984, disc_loss = 0.07562760847683687
Trained batch 133 in epoch 17, gen_loss = 0.39946567723110543, disc_loss = 0.07533118007843619
Trained batch 134 in epoch 17, gen_loss = 0.39929281693917734, disc_loss = 0.0757203999630831
Trained batch 135 in epoch 17, gen_loss = 0.39885632014449907, disc_loss = 0.0779420706196962
Trained batch 136 in epoch 17, gen_loss = 0.3992099614038955, disc_loss = 0.0777155410117694
Trained batch 137 in epoch 17, gen_loss = 0.3999056470566902, disc_loss = 0.07782526585556891
Trained batch 138 in epoch 17, gen_loss = 0.39962564591023564, disc_loss = 0.07814153719345014
Trained batch 139 in epoch 17, gen_loss = 0.3996529757976532, disc_loss = 0.07806082385193025
Trained batch 140 in epoch 17, gen_loss = 0.3997850297613347, disc_loss = 0.07794597452995203
Trained batch 141 in epoch 17, gen_loss = 0.3998650973531562, disc_loss = 0.07778195028101474
Trained batch 142 in epoch 17, gen_loss = 0.39980629815921914, disc_loss = 0.0774846076835077
Trained batch 143 in epoch 17, gen_loss = 0.399883765520321, disc_loss = 0.07716247905045748
Trained batch 144 in epoch 17, gen_loss = 0.3997282394047441, disc_loss = 0.07735669371382943
Trained batch 145 in epoch 17, gen_loss = 0.3990537103724806, disc_loss = 0.07854761412903054
Trained batch 146 in epoch 17, gen_loss = 0.3995226349960379, disc_loss = 0.07836086870658965
Trained batch 147 in epoch 17, gen_loss = 0.3998618991793813, disc_loss = 0.07807463450306976
Trained batch 148 in epoch 17, gen_loss = 0.3999662683314125, disc_loss = 0.07776799743007494
Trained batch 149 in epoch 17, gen_loss = 0.3997117890914281, disc_loss = 0.07754118795196216
Trained batch 150 in epoch 17, gen_loss = 0.3997239630348635, disc_loss = 0.07730192318558693
Trained batch 151 in epoch 17, gen_loss = 0.4003022654276145, disc_loss = 0.0772512092157022
Trained batch 152 in epoch 17, gen_loss = 0.3996136163184845, disc_loss = 0.07717005214562603
Trained batch 153 in epoch 17, gen_loss = 0.3997925179345267, disc_loss = 0.07714853210785946
Trained batch 154 in epoch 17, gen_loss = 0.3993401192849682, disc_loss = 0.07739635559339678
Trained batch 155 in epoch 17, gen_loss = 0.400027463833491, disc_loss = 0.07784185756762059
Trained batch 156 in epoch 17, gen_loss = 0.3998586324749479, disc_loss = 0.07745369133438654
Trained batch 157 in epoch 17, gen_loss = 0.39969778721091115, disc_loss = 0.07718833619610796
Trained batch 158 in epoch 17, gen_loss = 0.3994418868103867, disc_loss = 0.07691014003969214
Trained batch 159 in epoch 17, gen_loss = 0.39954549837857484, disc_loss = 0.07657685826998203
Trained batch 160 in epoch 17, gen_loss = 0.3993390883718218, disc_loss = 0.07657693393574738
Trained batch 161 in epoch 17, gen_loss = 0.39979214046472383, disc_loss = 0.07724569712616043
Trained batch 162 in epoch 17, gen_loss = 0.3991422088233971, disc_loss = 0.0771804665175318
Trained batch 163 in epoch 17, gen_loss = 0.39873002287818166, disc_loss = 0.07721330491235344
Trained batch 164 in epoch 17, gen_loss = 0.39862397638234226, disc_loss = 0.07996803208282499
Trained batch 165 in epoch 17, gen_loss = 0.3981974600668413, disc_loss = 0.0803021016833653
Trained batch 166 in epoch 17, gen_loss = 0.39810125538688934, disc_loss = 0.08023574932695862
Trained batch 167 in epoch 17, gen_loss = 0.3983068686156046, disc_loss = 0.07998723113199785
Trained batch 168 in epoch 17, gen_loss = 0.3981744953866541, disc_loss = 0.079750604795281
Trained batch 169 in epoch 17, gen_loss = 0.39780704782289616, disc_loss = 0.07956300369080375
Trained batch 170 in epoch 17, gen_loss = 0.39755954083643463, disc_loss = 0.0791934156104138
Trained batch 171 in epoch 17, gen_loss = 0.3979546519559483, disc_loss = 0.07887958623685462
Trained batch 172 in epoch 17, gen_loss = 0.3975872783302572, disc_loss = 0.07860486421497226
Trained batch 173 in epoch 17, gen_loss = 0.3975223792695451, disc_loss = 0.0782223885247334
Trained batch 174 in epoch 17, gen_loss = 0.3974751547404698, disc_loss = 0.07839465785771609
Trained batch 175 in epoch 17, gen_loss = 0.3972302893684669, disc_loss = 0.07989720421822065
Trained batch 176 in epoch 17, gen_loss = 0.3970795942228393, disc_loss = 0.07969675004208661
Trained batch 177 in epoch 17, gen_loss = 0.39670630552795494, disc_loss = 0.07956417825261361
Trained batch 178 in epoch 17, gen_loss = 0.3963997495573992, disc_loss = 0.07926805072344381
Trained batch 179 in epoch 17, gen_loss = 0.39671859873665705, disc_loss = 0.07959155693339805
Trained batch 180 in epoch 17, gen_loss = 0.3962075189990892, disc_loss = 0.08020978890750455
Trained batch 181 in epoch 17, gen_loss = 0.39682370293271413, disc_loss = 0.08006183236612233
Trained batch 182 in epoch 17, gen_loss = 0.39717004533673894, disc_loss = 0.0797367646038288
Trained batch 183 in epoch 17, gen_loss = 0.39751291696144186, disc_loss = 0.07960159720792233
Trained batch 184 in epoch 17, gen_loss = 0.3976386060585847, disc_loss = 0.08001882957949026
Trained batch 185 in epoch 17, gen_loss = 0.3974363161351091, disc_loss = 0.08063276697410851
Trained batch 186 in epoch 17, gen_loss = 0.3969408131856969, disc_loss = 0.08062117423782533
Trained batch 187 in epoch 17, gen_loss = 0.39744499373309156, disc_loss = 0.08055000998416638
Trained batch 188 in epoch 17, gen_loss = 0.39770801562480823, disc_loss = 0.08029865529191084
Trained batch 189 in epoch 17, gen_loss = 0.3978679021722392, disc_loss = 0.0800458749511132
Trained batch 190 in epoch 17, gen_loss = 0.39779963309228106, disc_loss = 0.07975976039894432
Trained batch 191 in epoch 17, gen_loss = 0.39768656079346937, disc_loss = 0.0796435441346451
Trained batch 192 in epoch 17, gen_loss = 0.3978774587725111, disc_loss = 0.07948770284787825
Trained batch 193 in epoch 17, gen_loss = 0.3980535463881247, disc_loss = 0.07931018750826568
Trained batch 194 in epoch 17, gen_loss = 0.3986650492900457, disc_loss = 0.07909992741755185
Trained batch 195 in epoch 17, gen_loss = 0.39851406855242594, disc_loss = 0.07899296469511274
Trained batch 196 in epoch 17, gen_loss = 0.39833861105333124, disc_loss = 0.07957445307715139
Trained batch 197 in epoch 17, gen_loss = 0.3980224999514493, disc_loss = 0.07990436974179113
Trained batch 198 in epoch 17, gen_loss = 0.3979000868509762, disc_loss = 0.07955486738782881
Trained batch 199 in epoch 17, gen_loss = 0.398057619035244, disc_loss = 0.07936783832963556
Trained batch 200 in epoch 17, gen_loss = 0.3981332265915562, disc_loss = 0.07921159287349354
Trained batch 201 in epoch 17, gen_loss = 0.39782429567658073, disc_loss = 0.07952267563634433
Trained batch 202 in epoch 17, gen_loss = 0.39864637728395136, disc_loss = 0.0798740542351539
Trained batch 203 in epoch 17, gen_loss = 0.3983284698105326, disc_loss = 0.07999768883775116
Trained batch 204 in epoch 17, gen_loss = 0.3985970677399054, disc_loss = 0.07975171753091784
Trained batch 205 in epoch 17, gen_loss = 0.3987360336248157, disc_loss = 0.07953152584490701
Trained batch 206 in epoch 17, gen_loss = 0.3987631558796058, disc_loss = 0.07949905590140734
Trained batch 207 in epoch 17, gen_loss = 0.3985240667198713, disc_loss = 0.07916624040808529
Trained batch 208 in epoch 17, gen_loss = 0.3983413773860658, disc_loss = 0.07955511804652271
Trained batch 209 in epoch 17, gen_loss = 0.3988422200793312, disc_loss = 0.08037880814323822
Trained batch 210 in epoch 17, gen_loss = 0.3990727853718527, disc_loss = 0.08004963377234636
Trained batch 211 in epoch 17, gen_loss = 0.3989291566441644, disc_loss = 0.0801649528406209
Trained batch 212 in epoch 17, gen_loss = 0.39898349351726226, disc_loss = 0.07991770709571844
Trained batch 213 in epoch 17, gen_loss = 0.39885177108171943, disc_loss = 0.08009183078255748
Trained batch 214 in epoch 17, gen_loss = 0.3985688210919846, disc_loss = 0.08042746067133753
Trained batch 215 in epoch 17, gen_loss = 0.39877454757138536, disc_loss = 0.08019268457967511
Trained batch 216 in epoch 17, gen_loss = 0.39890461651960274, disc_loss = 0.08015685395041507
Trained batch 217 in epoch 17, gen_loss = 0.3987791181430904, disc_loss = 0.08025986438514579
Trained batch 218 in epoch 17, gen_loss = 0.39859759181601817, disc_loss = 0.0802728526983155
Trained batch 219 in epoch 17, gen_loss = 0.39852002953941174, disc_loss = 0.0803374490996992
Trained batch 220 in epoch 17, gen_loss = 0.3983315244249629, disc_loss = 0.08052334264005066
Trained batch 221 in epoch 17, gen_loss = 0.3987795695796743, disc_loss = 0.08042563592410974
Trained batch 222 in epoch 17, gen_loss = 0.398397399571979, disc_loss = 0.08102381684203452
Trained batch 223 in epoch 17, gen_loss = 0.39808563036578043, disc_loss = 0.08262119203157324
Trained batch 224 in epoch 17, gen_loss = 0.3983947413497501, disc_loss = 0.08264199055317376
Trained batch 225 in epoch 17, gen_loss = 0.398037388920784, disc_loss = 0.08242868241829286
Trained batch 226 in epoch 17, gen_loss = 0.3980817796112682, disc_loss = 0.08223172630458282
Trained batch 227 in epoch 17, gen_loss = 0.3980408513493705, disc_loss = 0.08199149852602236
Trained batch 228 in epoch 17, gen_loss = 0.39794002206564993, disc_loss = 0.08178399419045995
Trained batch 229 in epoch 17, gen_loss = 0.39799117692138836, disc_loss = 0.08167176509438001
Trained batch 230 in epoch 17, gen_loss = 0.39809345528160855, disc_loss = 0.08149401661718175
Trained batch 231 in epoch 17, gen_loss = 0.39805768224699745, disc_loss = 0.0812830866579416
Trained batch 232 in epoch 17, gen_loss = 0.3980068613019624, disc_loss = 0.08130135947174909
Trained batch 233 in epoch 17, gen_loss = 0.39777822576017463, disc_loss = 0.08149497064913058
Trained batch 234 in epoch 17, gen_loss = 0.3973528869608615, disc_loss = 0.08229721043100383
Trained batch 235 in epoch 17, gen_loss = 0.3969977067436202, disc_loss = 0.08229976340386448
Trained batch 236 in epoch 17, gen_loss = 0.3969972948484783, disc_loss = 0.0824038281070092
Trained batch 237 in epoch 17, gen_loss = 0.3964688826759322, disc_loss = 0.08265366847039897
Trained batch 238 in epoch 17, gen_loss = 0.3963385195662287, disc_loss = 0.08241798094703687
Trained batch 239 in epoch 17, gen_loss = 0.39642247458299, disc_loss = 0.08222448686525846
Trained batch 240 in epoch 17, gen_loss = 0.396429423598333, disc_loss = 0.08207405848946438
Trained batch 241 in epoch 17, gen_loss = 0.39661419330057035, disc_loss = 0.0821938695008905
Trained batch 242 in epoch 17, gen_loss = 0.396589071784981, disc_loss = 0.08253823912514703
Trained batch 243 in epoch 17, gen_loss = 0.39691602682969607, disc_loss = 0.08239947331565448
Trained batch 244 in epoch 17, gen_loss = 0.39723827826733493, disc_loss = 0.08216347840747663
Trained batch 245 in epoch 17, gen_loss = 0.3970309849677047, disc_loss = 0.08189843116116112
Trained batch 246 in epoch 17, gen_loss = 0.3970401699726398, disc_loss = 0.0818309092833868
Trained batch 247 in epoch 17, gen_loss = 0.39713906953411715, disc_loss = 0.08160793381337557
Trained batch 248 in epoch 17, gen_loss = 0.3969722038292023, disc_loss = 0.08207999693087666
Trained batch 249 in epoch 17, gen_loss = 0.39666170585155486, disc_loss = 0.08278734555467963
Trained batch 250 in epoch 17, gen_loss = 0.39665227024203753, disc_loss = 0.08279087601890009
Trained batch 251 in epoch 17, gen_loss = 0.39665705568733667, disc_loss = 0.08273921764662696
Trained batch 252 in epoch 17, gen_loss = 0.39646870239450055, disc_loss = 0.08257475494970329
Trained batch 253 in epoch 17, gen_loss = 0.396304370498094, disc_loss = 0.08238385906296335
Trained batch 254 in epoch 17, gen_loss = 0.39642566091874065, disc_loss = 0.08237963021897218
Trained batch 255 in epoch 17, gen_loss = 0.396361043327488, disc_loss = 0.08261852392388391
Trained batch 256 in epoch 17, gen_loss = 0.3968377986538735, disc_loss = 0.08312042574633768
Trained batch 257 in epoch 17, gen_loss = 0.396857677273048, disc_loss = 0.08290841679861263
Trained batch 258 in epoch 17, gen_loss = 0.3965634512625146, disc_loss = 0.08307471107260025
Trained batch 259 in epoch 17, gen_loss = 0.3964038537098811, disc_loss = 0.08309533187331489
Trained batch 260 in epoch 17, gen_loss = 0.39666858783626924, disc_loss = 0.08294752438220827
Trained batch 261 in epoch 17, gen_loss = 0.39666391112877214, disc_loss = 0.0829651921184179
Trained batch 262 in epoch 17, gen_loss = 0.3963344483547791, disc_loss = 0.08286403490322511
Trained batch 263 in epoch 17, gen_loss = 0.3962309305189234, disc_loss = 0.08349823852591781
Trained batch 264 in epoch 17, gen_loss = 0.3963851214579816, disc_loss = 0.08330672312668472
Trained batch 265 in epoch 17, gen_loss = 0.3960289705292623, disc_loss = 0.08389767704363492
Trained batch 266 in epoch 17, gen_loss = 0.3959751385874516, disc_loss = 0.08408000135675686
Trained batch 267 in epoch 17, gen_loss = 0.39622444092337766, disc_loss = 0.08397422167611544
Trained batch 268 in epoch 17, gen_loss = 0.3961122488000579, disc_loss = 0.08378511817855795
Trained batch 269 in epoch 17, gen_loss = 0.39628910643083076, disc_loss = 0.0836432960677754
Trained batch 270 in epoch 17, gen_loss = 0.39600495834632116, disc_loss = 0.08342885965914414
Trained batch 271 in epoch 17, gen_loss = 0.39582774579963265, disc_loss = 0.08331775390337605
Trained batch 272 in epoch 17, gen_loss = 0.39609133094658344, disc_loss = 0.0831776171301802
Trained batch 273 in epoch 17, gen_loss = 0.3960843220026824, disc_loss = 0.0830033063297126
Trained batch 274 in epoch 17, gen_loss = 0.3962625818902796, disc_loss = 0.08281409280205315
Trained batch 275 in epoch 17, gen_loss = 0.39624302272779355, disc_loss = 0.08276006228803401
Trained batch 276 in epoch 17, gen_loss = 0.39639630354268457, disc_loss = 0.0827074685984624
Trained batch 277 in epoch 17, gen_loss = 0.3960679204558297, disc_loss = 0.08247400348228838
Trained batch 278 in epoch 17, gen_loss = 0.39610038297150724, disc_loss = 0.08225276583211504
Trained batch 279 in epoch 17, gen_loss = 0.39617497165288246, disc_loss = 0.08203537865608398
Trained batch 280 in epoch 17, gen_loss = 0.3963719541704103, disc_loss = 0.08181613917359784
Trained batch 281 in epoch 17, gen_loss = 0.39627351109863174, disc_loss = 0.08163639501146708
Trained batch 282 in epoch 17, gen_loss = 0.39602914052380267, disc_loss = 0.08153682116208459
Trained batch 283 in epoch 17, gen_loss = 0.39595334168890833, disc_loss = 0.0814354110109082
Trained batch 284 in epoch 17, gen_loss = 0.39592379770780867, disc_loss = 0.08127469490690713
Trained batch 285 in epoch 17, gen_loss = 0.3956884842860949, disc_loss = 0.08116388984897233
Trained batch 286 in epoch 17, gen_loss = 0.3957483253412546, disc_loss = 0.08133780133005115
Trained batch 287 in epoch 17, gen_loss = 0.39541826655881274, disc_loss = 0.08157824302907102
Trained batch 288 in epoch 17, gen_loss = 0.39584393268225515, disc_loss = 0.08156866670157567
Trained batch 289 in epoch 17, gen_loss = 0.3960541237017204, disc_loss = 0.08137679754852735
Trained batch 290 in epoch 17, gen_loss = 0.3960750957125241, disc_loss = 0.0812536719450375
Trained batch 291 in epoch 17, gen_loss = 0.39617599404021486, disc_loss = 0.08144507931915354
Trained batch 292 in epoch 17, gen_loss = 0.3959863131973931, disc_loss = 0.08161299192241739
Trained batch 293 in epoch 17, gen_loss = 0.39608888155749056, disc_loss = 0.08156927231205058
Trained batch 294 in epoch 17, gen_loss = 0.3961914432250847, disc_loss = 0.08141719168209928
Trained batch 295 in epoch 17, gen_loss = 0.39601208984449104, disc_loss = 0.08125492801726167
Trained batch 296 in epoch 17, gen_loss = 0.39567652384841484, disc_loss = 0.08111306343553745
Trained batch 297 in epoch 17, gen_loss = 0.3957900668950689, disc_loss = 0.08089980373984115
Trained batch 298 in epoch 17, gen_loss = 0.3960619317648004, disc_loss = 0.08072846102213681
Trained batch 299 in epoch 17, gen_loss = 0.3964373709758123, disc_loss = 0.08057270214892924
Trained batch 300 in epoch 17, gen_loss = 0.39648401291663465, disc_loss = 0.08052362423340645
Trained batch 301 in epoch 17, gen_loss = 0.3966995733265845, disc_loss = 0.08096175168067316
Trained batch 302 in epoch 17, gen_loss = 0.39647335345202156, disc_loss = 0.08122268408573795
Trained batch 303 in epoch 17, gen_loss = 0.39663628890718283, disc_loss = 0.08099700936030499
Trained batch 304 in epoch 17, gen_loss = 0.3966551143614972, disc_loss = 0.08088828602836269
Trained batch 305 in epoch 17, gen_loss = 0.39655714350588184, disc_loss = 0.08077367367466388
Trained batch 306 in epoch 17, gen_loss = 0.39659030429703407, disc_loss = 0.080689160611347
Trained batch 307 in epoch 17, gen_loss = 0.3966588710809683, disc_loss = 0.08059388631652412
Trained batch 308 in epoch 17, gen_loss = 0.3965609958063823, disc_loss = 0.08046728739376303
Trained batch 309 in epoch 17, gen_loss = 0.39639494169142936, disc_loss = 0.08035121560397167
Trained batch 310 in epoch 17, gen_loss = 0.39659267242315116, disc_loss = 0.08043020611802577
Trained batch 311 in epoch 17, gen_loss = 0.3965432269450946, disc_loss = 0.08039047753211492
Trained batch 312 in epoch 17, gen_loss = 0.39625161981430296, disc_loss = 0.08022993538504877
Trained batch 313 in epoch 17, gen_loss = 0.39634936668310955, disc_loss = 0.08009658747643328
Trained batch 314 in epoch 17, gen_loss = 0.3962544314445011, disc_loss = 0.07999073304531593
Trained batch 315 in epoch 17, gen_loss = 0.3961859850000732, disc_loss = 0.0803069950912525
Trained batch 316 in epoch 17, gen_loss = 0.3962439000606537, disc_loss = 0.08073524524067009
Trained batch 317 in epoch 17, gen_loss = 0.39604199738622464, disc_loss = 0.08066941347594063
Trained batch 318 in epoch 17, gen_loss = 0.3958997660109242, disc_loss = 0.0804953160243208
Trained batch 319 in epoch 17, gen_loss = 0.3959165601991117, disc_loss = 0.08031328802171629
Trained batch 320 in epoch 17, gen_loss = 0.3956702729437582, disc_loss = 0.08021328994870836
Trained batch 321 in epoch 17, gen_loss = 0.395604340741353, disc_loss = 0.08035983001489354
Trained batch 322 in epoch 17, gen_loss = 0.3955103564926714, disc_loss = 0.08053385491422363
Trained batch 323 in epoch 17, gen_loss = 0.39572358471743857, disc_loss = 0.08033674990148916
Trained batch 324 in epoch 17, gen_loss = 0.3956054432575519, disc_loss = 0.08018430415540934
Trained batch 325 in epoch 17, gen_loss = 0.39545300346942036, disc_loss = 0.079996244150551
Trained batch 326 in epoch 17, gen_loss = 0.395251861588306, disc_loss = 0.07979677032269196
Trained batch 327 in epoch 17, gen_loss = 0.3953997727210929, disc_loss = 0.07963376643601805
Trained batch 328 in epoch 17, gen_loss = 0.39517049414408606, disc_loss = 0.0794977541463761
Trained batch 329 in epoch 17, gen_loss = 0.3951422420415011, disc_loss = 0.07933277554076278
Trained batch 330 in epoch 17, gen_loss = 0.3950383104946678, disc_loss = 0.07919363258547203
Trained batch 331 in epoch 17, gen_loss = 0.3948533570012414, disc_loss = 0.07902367225376866
Trained batch 332 in epoch 17, gen_loss = 0.39488276705011593, disc_loss = 0.07897444613915575
Trained batch 333 in epoch 17, gen_loss = 0.3946603548205541, disc_loss = 0.0793625705117014
Trained batch 334 in epoch 17, gen_loss = 0.39498009014485486, disc_loss = 0.07974942004891919
Trained batch 335 in epoch 17, gen_loss = 0.39518347533331033, disc_loss = 0.07958406358790983
Trained batch 336 in epoch 17, gen_loss = 0.3950913959688532, disc_loss = 0.07941875980686097
Trained batch 337 in epoch 17, gen_loss = 0.3950875427066927, disc_loss = 0.07924857489577324
Trained batch 338 in epoch 17, gen_loss = 0.39502528380152047, disc_loss = 0.07903463005536074
Trained batch 339 in epoch 17, gen_loss = 0.395024097579367, disc_loss = 0.07884338782442843
Trained batch 340 in epoch 17, gen_loss = 0.3949774931952401, disc_loss = 0.07866438562350889
Trained batch 341 in epoch 17, gen_loss = 0.3949972247345406, disc_loss = 0.07858667972535767
Trained batch 342 in epoch 17, gen_loss = 0.39527466059078625, disc_loss = 0.07849762043521981
Trained batch 343 in epoch 17, gen_loss = 0.395300192368585, disc_loss = 0.07848437628600487
Trained batch 344 in epoch 17, gen_loss = 0.39539617515992426, disc_loss = 0.07871320182862489
Trained batch 345 in epoch 17, gen_loss = 0.39534307163574794, disc_loss = 0.07870541721840814
Trained batch 346 in epoch 17, gen_loss = 0.3953669820120424, disc_loss = 0.07852494162145025
Trained batch 347 in epoch 17, gen_loss = 0.39542605205513964, disc_loss = 0.07846204982000007
Trained batch 348 in epoch 17, gen_loss = 0.39518214322434453, disc_loss = 0.07935350094214723
Trained batch 349 in epoch 17, gen_loss = 0.39543959643159593, disc_loss = 0.07983964458640133
Trained batch 350 in epoch 17, gen_loss = 0.39541619498165925, disc_loss = 0.07975360225259918
Trained batch 351 in epoch 17, gen_loss = 0.39536486117338593, disc_loss = 0.07985660421598534
Trained batch 352 in epoch 17, gen_loss = 0.3953711473232626, disc_loss = 0.07971137060807548
Trained batch 353 in epoch 17, gen_loss = 0.39540462961978157, disc_loss = 0.07957606396958822
Trained batch 354 in epoch 17, gen_loss = 0.395590796437062, disc_loss = 0.07938929679213276
Trained batch 355 in epoch 17, gen_loss = 0.3954749093129394, disc_loss = 0.07929898836660419
Trained batch 356 in epoch 17, gen_loss = 0.3956868267025934, disc_loss = 0.07922323082028483
Trained batch 357 in epoch 17, gen_loss = 0.3955594181348492, disc_loss = 0.07904489971593272
Trained batch 358 in epoch 17, gen_loss = 0.3952251578937998, disc_loss = 0.07902761516070465
Trained batch 359 in epoch 17, gen_loss = 0.3952605521513356, disc_loss = 0.07904140662091473
Trained batch 360 in epoch 17, gen_loss = 0.3951921306983916, disc_loss = 0.0789111514015954
Trained batch 361 in epoch 17, gen_loss = 0.3951011171657077, disc_loss = 0.07886690939184875
Trained batch 362 in epoch 17, gen_loss = 0.3952360793578723, disc_loss = 0.07919744909651187
Trained batch 363 in epoch 17, gen_loss = 0.3952144123204462, disc_loss = 0.07922311279165385
Trained batch 364 in epoch 17, gen_loss = 0.3954375146186515, disc_loss = 0.07904177862028144
Trained batch 365 in epoch 17, gen_loss = 0.3953686728666389, disc_loss = 0.07888719869797917
Trained batch 366 in epoch 17, gen_loss = 0.3952307524895473, disc_loss = 0.07875441612386493
Trained batch 367 in epoch 17, gen_loss = 0.3953857974999625, disc_loss = 0.07859756557382239
Trained batch 368 in epoch 17, gen_loss = 0.3953775961386156, disc_loss = 0.07855372414305846
Trained batch 369 in epoch 17, gen_loss = 0.39530173854247946, disc_loss = 0.07841202053618995
Trained batch 370 in epoch 17, gen_loss = 0.39538890998961146, disc_loss = 0.07844104974046148
Trained batch 371 in epoch 17, gen_loss = 0.395696804488218, disc_loss = 0.07840527520735338
Trained batch 372 in epoch 17, gen_loss = 0.39587761697436785, disc_loss = 0.07826435681552334
Trained batch 373 in epoch 17, gen_loss = 0.3958894160979572, disc_loss = 0.07809846740425191
Trained batch 374 in epoch 17, gen_loss = 0.39580708312988283, disc_loss = 0.07830683286736409
Trained batch 375 in epoch 17, gen_loss = 0.39591384346180775, disc_loss = 0.07876005273143899
Trained batch 376 in epoch 17, gen_loss = 0.39562912558054736, disc_loss = 0.07861031172673566
Trained batch 377 in epoch 17, gen_loss = 0.39583932320592263, disc_loss = 0.0785412462255745
Trained batch 378 in epoch 17, gen_loss = 0.3958510467905482, disc_loss = 0.07844532726180192
Trained batch 379 in epoch 17, gen_loss = 0.39566409729029, disc_loss = 0.07839782901451384
Trained batch 380 in epoch 17, gen_loss = 0.3957367894530609, disc_loss = 0.0783986068963809
Trained batch 381 in epoch 17, gen_loss = 0.3953739133180748, disc_loss = 0.07859394858050019
Trained batch 382 in epoch 17, gen_loss = 0.395354820838485, disc_loss = 0.07860845808601177
Trained batch 383 in epoch 17, gen_loss = 0.39521230695148307, disc_loss = 0.07847314696361234
Trained batch 384 in epoch 17, gen_loss = 0.39533989429473876, disc_loss = 0.07836349310184067
Trained batch 385 in epoch 17, gen_loss = 0.39516724036147555, disc_loss = 0.07830991576440208
Trained batch 386 in epoch 17, gen_loss = 0.3951870649667981, disc_loss = 0.07845592209756451
Trained batch 387 in epoch 17, gen_loss = 0.39511524110110763, disc_loss = 0.07901194848878712
Trained batch 388 in epoch 17, gen_loss = 0.39500826934309424, disc_loss = 0.0792544594436769
Trained batch 389 in epoch 17, gen_loss = 0.39491648505895566, disc_loss = 0.07915743357048202
Trained batch 390 in epoch 17, gen_loss = 0.3949208312937061, disc_loss = 0.07900630382349348
Trained batch 391 in epoch 17, gen_loss = 0.3950333359594248, disc_loss = 0.07891427087645066
Trained batch 392 in epoch 17, gen_loss = 0.39496860810515233, disc_loss = 0.07884049633370935
Trained batch 393 in epoch 17, gen_loss = 0.39497222785417196, disc_loss = 0.07868683584705752
Trained batch 394 in epoch 17, gen_loss = 0.3948258916033974, disc_loss = 0.07869033504843334
Trained batch 395 in epoch 17, gen_loss = 0.39487019677956897, disc_loss = 0.07861618250561407
Trained batch 396 in epoch 17, gen_loss = 0.39510812657305816, disc_loss = 0.07855544163040835
Trained batch 397 in epoch 17, gen_loss = 0.3950426190642256, disc_loss = 0.07889833522904384
Trained batch 398 in epoch 17, gen_loss = 0.3950276179869372, disc_loss = 0.07874467975242917
Trained batch 399 in epoch 17, gen_loss = 0.3952030844241381, disc_loss = 0.07857326999073848
Trained batch 400 in epoch 17, gen_loss = 0.3951478894066038, disc_loss = 0.07851291689185654
Trained batch 401 in epoch 17, gen_loss = 0.39497201493130396, disc_loss = 0.07860629944204914
Trained batch 402 in epoch 17, gen_loss = 0.39515411210415086, disc_loss = 0.07878980482177388
Trained batch 403 in epoch 17, gen_loss = 0.3952904657857253, disc_loss = 0.07864960531777895
Trained batch 404 in epoch 17, gen_loss = 0.39522097581698573, disc_loss = 0.07873824972567367
Trained batch 405 in epoch 17, gen_loss = 0.39525217441796084, disc_loss = 0.07857146544904985
Trained batch 406 in epoch 17, gen_loss = 0.39525406710638755, disc_loss = 0.07843146482780027
Trained batch 407 in epoch 17, gen_loss = 0.39513520845303346, disc_loss = 0.07832121898821902
Trained batch 408 in epoch 17, gen_loss = 0.3950913646839067, disc_loss = 0.07846695329074026
Trained batch 409 in epoch 17, gen_loss = 0.39470731528793895, disc_loss = 0.07893518600612878
Trained batch 410 in epoch 17, gen_loss = 0.394837885007371, disc_loss = 0.07896192562641743
Trained batch 411 in epoch 17, gen_loss = 0.3949962318377587, disc_loss = 0.07881313302888743
Trained batch 412 in epoch 17, gen_loss = 0.3948583219732557, disc_loss = 0.07871104118393928
Trained batch 413 in epoch 17, gen_loss = 0.39472045335504746, disc_loss = 0.07877739878812275
Trained batch 414 in epoch 17, gen_loss = 0.39463873613311584, disc_loss = 0.07863039505409908
Trained batch 415 in epoch 17, gen_loss = 0.3945901759255391, disc_loss = 0.07851525278797802
Trained batch 416 in epoch 17, gen_loss = 0.39479317553609394, disc_loss = 0.07843616736128176
Trained batch 417 in epoch 17, gen_loss = 0.3947021480667534, disc_loss = 0.07841765849392095
Trained batch 418 in epoch 17, gen_loss = 0.3947669658854355, disc_loss = 0.07831089144354789
Trained batch 419 in epoch 17, gen_loss = 0.3948550922530038, disc_loss = 0.07816144601175827
Trained batch 420 in epoch 17, gen_loss = 0.39482997594989677, disc_loss = 0.07806528289525852
Trained batch 421 in epoch 17, gen_loss = 0.39483488022716123, disc_loss = 0.07801968449620768
Trained batch 422 in epoch 17, gen_loss = 0.3947426178635717, disc_loss = 0.07793307815839143
Trained batch 423 in epoch 17, gen_loss = 0.3946121304805549, disc_loss = 0.0777773100790515
Trained batch 424 in epoch 17, gen_loss = 0.39462432622909543, disc_loss = 0.07768237168078913
Trained batch 425 in epoch 17, gen_loss = 0.39437557763896636, disc_loss = 0.07766139270965132
Trained batch 426 in epoch 17, gen_loss = 0.39440483210795935, disc_loss = 0.07753707127170135
Trained batch 427 in epoch 17, gen_loss = 0.394574635566395, disc_loss = 0.07751514564842751
Trained batch 428 in epoch 17, gen_loss = 0.39437919910693225, disc_loss = 0.07787214206327578
Trained batch 429 in epoch 17, gen_loss = 0.39459935842558397, disc_loss = 0.07779595348334244
Trained batch 430 in epoch 17, gen_loss = 0.39473769296902794, disc_loss = 0.0777025127766131
Trained batch 431 in epoch 17, gen_loss = 0.39471990966962445, disc_loss = 0.07759932081723862
Trained batch 432 in epoch 17, gen_loss = 0.3945577210697236, disc_loss = 0.07775664186496589
Trained batch 433 in epoch 17, gen_loss = 0.394557049609549, disc_loss = 0.07776446176761512
Trained batch 434 in epoch 17, gen_loss = 0.39471513279553117, disc_loss = 0.07766432583803075
Trained batch 435 in epoch 17, gen_loss = 0.39478159155867515, disc_loss = 0.07784602989083789
Trained batch 436 in epoch 17, gen_loss = 0.3947372238750589, disc_loss = 0.07802905131864533
Trained batch 437 in epoch 17, gen_loss = 0.39500306322150036, disc_loss = 0.07803907784416456
Trained batch 438 in epoch 17, gen_loss = 0.394928241441353, disc_loss = 0.07794054207054724
Trained batch 439 in epoch 17, gen_loss = 0.39496752673929386, disc_loss = 0.07788435427090999
Trained batch 440 in epoch 17, gen_loss = 0.39512384100025205, disc_loss = 0.07792899414449254
Trained batch 441 in epoch 17, gen_loss = 0.3949633527934821, disc_loss = 0.07804502684799997
Trained batch 442 in epoch 17, gen_loss = 0.39501126679017906, disc_loss = 0.07822228056372356
Trained batch 443 in epoch 17, gen_loss = 0.3949788265802839, disc_loss = 0.07817969618675609
Trained batch 444 in epoch 17, gen_loss = 0.3948001627171977, disc_loss = 0.07819049182358417
Trained batch 445 in epoch 17, gen_loss = 0.39496863302628554, disc_loss = 0.07811122669759019
Trained batch 446 in epoch 17, gen_loss = 0.3949963458432447, disc_loss = 0.07805835343772333
Trained batch 447 in epoch 17, gen_loss = 0.3949617159419826, disc_loss = 0.0780188242019254
Trained batch 448 in epoch 17, gen_loss = 0.3949917051733735, disc_loss = 0.07822398349999518
Trained batch 449 in epoch 17, gen_loss = 0.3948393979999754, disc_loss = 0.07841686549906929
Trained batch 450 in epoch 17, gen_loss = 0.39486868775340245, disc_loss = 0.07828998710844509
Trained batch 451 in epoch 17, gen_loss = 0.394782059224306, disc_loss = 0.0782326732997049
Trained batch 452 in epoch 17, gen_loss = 0.3948112092665489, disc_loss = 0.07812448101484157
Trained batch 453 in epoch 17, gen_loss = 0.394968275784921, disc_loss = 0.07807723066609533
Trained batch 454 in epoch 17, gen_loss = 0.394877774309326, disc_loss = 0.07814217903907154
Trained batch 455 in epoch 17, gen_loss = 0.39494259028058304, disc_loss = 0.0781263752019425
Trained batch 456 in epoch 17, gen_loss = 0.3950513624127636, disc_loss = 0.07800609275853543
Trained batch 457 in epoch 17, gen_loss = 0.39488103771053545, disc_loss = 0.0779499536823465
Trained batch 458 in epoch 17, gen_loss = 0.39540043745944703, disc_loss = 0.07783566625314016
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.47494935989379883, disc_loss = 0.011767540127038956
Trained batch 1 in epoch 18, gen_loss = 0.4519343078136444, disc_loss = 0.016383107751607895
Trained batch 2 in epoch 18, gen_loss = 0.4410449465115865, disc_loss = 0.016176133106152218
Trained batch 3 in epoch 18, gen_loss = 0.4135735481977463, disc_loss = 0.020822418853640556
Trained batch 4 in epoch 18, gen_loss = 0.40388338565826415, disc_loss = 0.020001566037535667
Trained batch 5 in epoch 18, gen_loss = 0.40201491117477417, disc_loss = 0.021980844127635162
Trained batch 6 in epoch 18, gen_loss = 0.39582175867898123, disc_loss = 0.02550196780690125
Trained batch 7 in epoch 18, gen_loss = 0.3894914537668228, disc_loss = 0.027364013018086553
Trained batch 8 in epoch 18, gen_loss = 0.38588111599286395, disc_loss = 0.02567217830154631
Trained batch 9 in epoch 18, gen_loss = 0.3932874113321304, disc_loss = 0.026629678532481195
Trained batch 10 in epoch 18, gen_loss = 0.39344940131360834, disc_loss = 0.034675742076201874
Trained batch 11 in epoch 18, gen_loss = 0.39357788612445194, disc_loss = 0.035534667472044625
Trained batch 12 in epoch 18, gen_loss = 0.3960354167681474, disc_loss = 0.039828188717365265
Trained batch 13 in epoch 18, gen_loss = 0.3920349308422634, disc_loss = 0.05739832190530641
Trained batch 14 in epoch 18, gen_loss = 0.3964250286420186, disc_loss = 0.059384531279404955
Trained batch 15 in epoch 18, gen_loss = 0.39972920902073383, disc_loss = 0.058063053060323
Trained batch 16 in epoch 18, gen_loss = 0.40072884629754457, disc_loss = 0.058463848689023185
Trained batch 17 in epoch 18, gen_loss = 0.3998066402143902, disc_loss = 0.0583220049738884
Trained batch 18 in epoch 18, gen_loss = 0.39630671394498723, disc_loss = 0.057085900518455
Trained batch 19 in epoch 18, gen_loss = 0.3983307495713234, disc_loss = 0.06226868536323309
Trained batch 20 in epoch 18, gen_loss = 0.3917899926503499, disc_loss = 0.08116037700147856
Trained batch 21 in epoch 18, gen_loss = 0.3952324092388153, disc_loss = 0.0803583123805848
Trained batch 22 in epoch 18, gen_loss = 0.39389196038246155, disc_loss = 0.07891407949121101
Trained batch 23 in epoch 18, gen_loss = 0.3939219266176224, disc_loss = 0.07723573579763372
Trained batch 24 in epoch 18, gen_loss = 0.3934465038776398, disc_loss = 0.07904083326458931
Trained batch 25 in epoch 18, gen_loss = 0.3974102746981841, disc_loss = 0.07920824607404378
Trained batch 26 in epoch 18, gen_loss = 0.39743262750131114, disc_loss = 0.07754850704912786
Trained batch 27 in epoch 18, gen_loss = 0.39443706401756834, disc_loss = 0.07698086143604346
Trained batch 28 in epoch 18, gen_loss = 0.3967118448224561, disc_loss = 0.07588919958677785
Trained batch 29 in epoch 18, gen_loss = 0.3955773115158081, disc_loss = 0.07551976479589939
Trained batch 30 in epoch 18, gen_loss = 0.39432339899001584, disc_loss = 0.07742190973893288
Trained batch 31 in epoch 18, gen_loss = 0.39783792197704315, disc_loss = 0.07601765298750252
Trained batch 32 in epoch 18, gen_loss = 0.39714270107673877, disc_loss = 0.07555266582604611
Trained batch 33 in epoch 18, gen_loss = 0.39484113104203167, disc_loss = 0.07634283448843394
Trained batch 34 in epoch 18, gen_loss = 0.39691236189433504, disc_loss = 0.07573428271072251
Trained batch 35 in epoch 18, gen_loss = 0.3978456308444341, disc_loss = 0.07449520663875672
Trained batch 36 in epoch 18, gen_loss = 0.39886647301751216, disc_loss = 0.07278869260807296
Trained batch 37 in epoch 18, gen_loss = 0.3987512878681484, disc_loss = 0.0718793377868439
Trained batch 38 in epoch 18, gen_loss = 0.3987994568470197, disc_loss = 0.07107670691150886
Trained batch 39 in epoch 18, gen_loss = 0.4003567241132259, disc_loss = 0.06977496119216084
Trained batch 40 in epoch 18, gen_loss = 0.39915204920419833, disc_loss = 0.06860305596052146
Trained batch 41 in epoch 18, gen_loss = 0.3980437098514466, disc_loss = 0.06778523618621486
Trained batch 42 in epoch 18, gen_loss = 0.3970798940159554, disc_loss = 0.06751154293847639
Trained batch 43 in epoch 18, gen_loss = 0.39679912613196805, disc_loss = 0.06768459386446259
Trained batch 44 in epoch 18, gen_loss = 0.39719502329826356, disc_loss = 0.0701138135459688
Trained batch 45 in epoch 18, gen_loss = 0.39623518676861474, disc_loss = 0.07138027898643327
Trained batch 46 in epoch 18, gen_loss = 0.3972457710732805, disc_loss = 0.07120847147195897
Trained batch 47 in epoch 18, gen_loss = 0.3979440989593665, disc_loss = 0.07026077496508758
Trained batch 48 in epoch 18, gen_loss = 0.4003755511069784, disc_loss = 0.06975231456513308
Trained batch 49 in epoch 18, gen_loss = 0.39967738270759584, disc_loss = 0.07101999253034591
Trained batch 50 in epoch 18, gen_loss = 0.40272557852314966, disc_loss = 0.07557643307190315
Trained batch 51 in epoch 18, gen_loss = 0.4031490098971587, disc_loss = 0.07433036096895543
Trained batch 52 in epoch 18, gen_loss = 0.401664618051277, disc_loss = 0.07378025421486148
Trained batch 53 in epoch 18, gen_loss = 0.4007318682140774, disc_loss = 0.07270701948760284
Trained batch 54 in epoch 18, gen_loss = 0.39997641119089994, disc_loss = 0.07182004544883966
Trained batch 55 in epoch 18, gen_loss = 0.3988477795251778, disc_loss = 0.07116883705436651
Trained batch 56 in epoch 18, gen_loss = 0.39900887744468555, disc_loss = 0.0701943600158158
Trained batch 57 in epoch 18, gen_loss = 0.3978295912002695, disc_loss = 0.06942590430443144
Trained batch 58 in epoch 18, gen_loss = 0.39728878766803416, disc_loss = 0.0686031474053102
Trained batch 59 in epoch 18, gen_loss = 0.3974085122346878, disc_loss = 0.06823930561852952
Trained batch 60 in epoch 18, gen_loss = 0.39651413921450007, disc_loss = 0.06978579886929422
Trained batch 61 in epoch 18, gen_loss = 0.39764158091237467, disc_loss = 0.07241002898362855
Trained batch 62 in epoch 18, gen_loss = 0.3987251567462134, disc_loss = 0.07183295945149093
Trained batch 63 in epoch 18, gen_loss = 0.3984850812703371, disc_loss = 0.0720645082910778
Trained batch 64 in epoch 18, gen_loss = 0.3994645077448625, disc_loss = 0.07156373705141819
Trained batch 65 in epoch 18, gen_loss = 0.39918316991040204, disc_loss = 0.07072047992242557
Trained batch 66 in epoch 18, gen_loss = 0.3997037410736084, disc_loss = 0.06979448798654685
Trained batch 67 in epoch 18, gen_loss = 0.39890384104321985, disc_loss = 0.06903522184995167
Trained batch 68 in epoch 18, gen_loss = 0.39943939145060553, disc_loss = 0.06828359247225782
Trained batch 69 in epoch 18, gen_loss = 0.4001997130257743, disc_loss = 0.0674866296350956
Trained batch 70 in epoch 18, gen_loss = 0.40026966660795077, disc_loss = 0.06760723280235076
Trained batch 71 in epoch 18, gen_loss = 0.3987436422871219, disc_loss = 0.0689489044662979
Trained batch 72 in epoch 18, gen_loss = 0.39943972066657185, disc_loss = 0.07061699277734103
Trained batch 73 in epoch 18, gen_loss = 0.3993951915889173, disc_loss = 0.06999807442362244
Trained batch 74 in epoch 18, gen_loss = 0.3994352686405182, disc_loss = 0.0692882334192594
Trained batch 75 in epoch 18, gen_loss = 0.39912088254564687, disc_loss = 0.06857412158952732
Trained batch 76 in epoch 18, gen_loss = 0.39979003698794874, disc_loss = 0.06787972674741373
Trained batch 77 in epoch 18, gen_loss = 0.4007048622155801, disc_loss = 0.06787331306781524
Trained batch 78 in epoch 18, gen_loss = 0.4002092141139356, disc_loss = 0.06886729371698597
Trained batch 79 in epoch 18, gen_loss = 0.400010846555233, disc_loss = 0.06862998306751251
Trained batch 80 in epoch 18, gen_loss = 0.39989667063877904, disc_loss = 0.06831255775910837
Trained batch 81 in epoch 18, gen_loss = 0.3993640967258593, disc_loss = 0.06914582975753923
Trained batch 82 in epoch 18, gen_loss = 0.399837240397212, disc_loss = 0.06921738188668906
Trained batch 83 in epoch 18, gen_loss = 0.3995085156389645, disc_loss = 0.06861510939363923
Trained batch 84 in epoch 18, gen_loss = 0.39896756831337427, disc_loss = 0.06802648783606642
Trained batch 85 in epoch 18, gen_loss = 0.39903678623742833, disc_loss = 0.06773775534401107
Trained batch 86 in epoch 18, gen_loss = 0.3985972812120942, disc_loss = 0.06733477779332249
Trained batch 87 in epoch 18, gen_loss = 0.3985746038908308, disc_loss = 0.06887787881053307
Trained batch 88 in epoch 18, gen_loss = 0.4005294532588359, disc_loss = 0.07151293415534363
Trained batch 89 in epoch 18, gen_loss = 0.4003890448146396, disc_loss = 0.07136920251780086
Trained batch 90 in epoch 18, gen_loss = 0.4004242030473856, disc_loss = 0.07182217241971048
Trained batch 91 in epoch 18, gen_loss = 0.4001452456349912, disc_loss = 0.07168353348970413
Trained batch 92 in epoch 18, gen_loss = 0.4003794943132708, disc_loss = 0.07131058298131471
Trained batch 93 in epoch 18, gen_loss = 0.40043680908832147, disc_loss = 0.0708004131001678
Trained batch 94 in epoch 18, gen_loss = 0.4000715180447227, disc_loss = 0.07028545111809906
Trained batch 95 in epoch 18, gen_loss = 0.3999983010192712, disc_loss = 0.06987004065498088
Trained batch 96 in epoch 18, gen_loss = 0.3995792079217655, disc_loss = 0.06938316972599816
Trained batch 97 in epoch 18, gen_loss = 0.39928047237347586, disc_loss = 0.06936907106820418
Trained batch 98 in epoch 18, gen_loss = 0.3994591266217858, disc_loss = 0.07086565164905606
Trained batch 99 in epoch 18, gen_loss = 0.39859464347362517, disc_loss = 0.07183785922825336
Trained batch 100 in epoch 18, gen_loss = 0.39872747128552727, disc_loss = 0.07253853954596094
Trained batch 101 in epoch 18, gen_loss = 0.398432973260973, disc_loss = 0.07235774098365914
Trained batch 102 in epoch 18, gen_loss = 0.3980822195705858, disc_loss = 0.07266821090168166
Trained batch 103 in epoch 18, gen_loss = 0.39854859044918645, disc_loss = 0.07331445118269095
Trained batch 104 in epoch 18, gen_loss = 0.39931942763782685, disc_loss = 0.07289035451554117
Trained batch 105 in epoch 18, gen_loss = 0.39963309101338657, disc_loss = 0.07240333228881629
Trained batch 106 in epoch 18, gen_loss = 0.3999398829781006, disc_loss = 0.0721179059941635
Trained batch 107 in epoch 18, gen_loss = 0.4002280240809476, disc_loss = 0.07186683129381251
Trained batch 108 in epoch 18, gen_loss = 0.39981597661972046, disc_loss = 0.07154022068332094
Trained batch 109 in epoch 18, gen_loss = 0.39960155568339606, disc_loss = 0.07115692750296809
Trained batch 110 in epoch 18, gen_loss = 0.3995782708799517, disc_loss = 0.07134745561996021
Trained batch 111 in epoch 18, gen_loss = 0.39945983115051475, disc_loss = 0.07185436416018222
Trained batch 112 in epoch 18, gen_loss = 0.4003613003059826, disc_loss = 0.07146972460688743
Trained batch 113 in epoch 18, gen_loss = 0.4003677172096152, disc_loss = 0.07175664123343795
Trained batch 114 in epoch 18, gen_loss = 0.4003659375335859, disc_loss = 0.07176406956885172
Trained batch 115 in epoch 18, gen_loss = 0.39963152953262987, disc_loss = 0.07210364645539687
Trained batch 116 in epoch 18, gen_loss = 0.3995077783225948, disc_loss = 0.07214163476203242
Trained batch 117 in epoch 18, gen_loss = 0.4000019592753911, disc_loss = 0.07246332757680093
Trained batch 118 in epoch 18, gen_loss = 0.3997320527789973, disc_loss = 0.07255772642102562
Trained batch 119 in epoch 18, gen_loss = 0.400024751573801, disc_loss = 0.07209558912242452
Trained batch 120 in epoch 18, gen_loss = 0.3991329857140533, disc_loss = 0.07250445517749826
Trained batch 121 in epoch 18, gen_loss = 0.39959470317011975, disc_loss = 0.07321791182898107
Trained batch 122 in epoch 18, gen_loss = 0.3991704716430447, disc_loss = 0.07283261572805846
Trained batch 123 in epoch 18, gen_loss = 0.3983100518103569, disc_loss = 0.07282175150729957
Trained batch 124 in epoch 18, gen_loss = 0.39798466229438784, disc_loss = 0.07267114919424057
Trained batch 125 in epoch 18, gen_loss = 0.3975222422963097, disc_loss = 0.07259174377199203
Trained batch 126 in epoch 18, gen_loss = 0.3971082218519346, disc_loss = 0.07264016193198407
Trained batch 127 in epoch 18, gen_loss = 0.3974387750495225, disc_loss = 0.07238662071176805
Trained batch 128 in epoch 18, gen_loss = 0.39686253320339115, disc_loss = 0.07226551171074543
Trained batch 129 in epoch 18, gen_loss = 0.39688629164145545, disc_loss = 0.07190055176615714
Trained batch 130 in epoch 18, gen_loss = 0.3976596587031852, disc_loss = 0.07153164224258361
Trained batch 131 in epoch 18, gen_loss = 0.397986847568642, disc_loss = 0.07125252689884017
Trained batch 132 in epoch 18, gen_loss = 0.39767890653215854, disc_loss = 0.07092170887871792
Trained batch 133 in epoch 18, gen_loss = 0.39763746421728563, disc_loss = 0.0710482947639565
Trained batch 134 in epoch 18, gen_loss = 0.3973401164567029, disc_loss = 0.0720548697091915
Trained batch 135 in epoch 18, gen_loss = 0.39773542017621155, disc_loss = 0.07206818220369957
Trained batch 136 in epoch 18, gen_loss = 0.3976769097094988, disc_loss = 0.07188322318948968
Trained batch 137 in epoch 18, gen_loss = 0.39740864846153534, disc_loss = 0.07199611228661261
Trained batch 138 in epoch 18, gen_loss = 0.3962511436330329, disc_loss = 0.07176088820472895
Trained batch 139 in epoch 18, gen_loss = 0.3964024989732674, disc_loss = 0.07172577322593757
Trained batch 140 in epoch 18, gen_loss = 0.3958584276285577, disc_loss = 0.07176219724805642
Trained batch 141 in epoch 18, gen_loss = 0.39548609993407424, disc_loss = 0.07156792828734491
Trained batch 142 in epoch 18, gen_loss = 0.3959284853059929, disc_loss = 0.07171132931342492
Trained batch 143 in epoch 18, gen_loss = 0.39578325684285826, disc_loss = 0.07213080829630296
Trained batch 144 in epoch 18, gen_loss = 0.39649120497292484, disc_loss = 0.0723508567645632
Trained batch 145 in epoch 18, gen_loss = 0.3963902922321672, disc_loss = 0.0723116213634406
Trained batch 146 in epoch 18, gen_loss = 0.3964084243896056, disc_loss = 0.07199523188680614
Trained batch 147 in epoch 18, gen_loss = 0.39596290493736397, disc_loss = 0.07195739489602479
Trained batch 148 in epoch 18, gen_loss = 0.3958736251064595, disc_loss = 0.07222179944733245
Trained batch 149 in epoch 18, gen_loss = 0.3964742498596509, disc_loss = 0.0726232115055124
Trained batch 150 in epoch 18, gen_loss = 0.3961072687479044, disc_loss = 0.07227652581618321
Trained batch 151 in epoch 18, gen_loss = 0.3958918529709703, disc_loss = 0.07239032480375547
Trained batch 152 in epoch 18, gen_loss = 0.3962447435832491, disc_loss = 0.07211285017528175
Trained batch 153 in epoch 18, gen_loss = 0.3968178274763095, disc_loss = 0.07181553563175651
Trained batch 154 in epoch 18, gen_loss = 0.3968610668374646, disc_loss = 0.07140175314439881
Trained batch 155 in epoch 18, gen_loss = 0.3965914884629922, disc_loss = 0.07140284675197342
Trained batch 156 in epoch 18, gen_loss = 0.39710702837272815, disc_loss = 0.07104649497967237
Trained batch 157 in epoch 18, gen_loss = 0.39739575048413456, disc_loss = 0.07085828621034758
Trained batch 158 in epoch 18, gen_loss = 0.39722009752906345, disc_loss = 0.07049785720758468
Trained batch 159 in epoch 18, gen_loss = 0.39727030945941805, disc_loss = 0.07032132463064045
Trained batch 160 in epoch 18, gen_loss = 0.3975303834824829, disc_loss = 0.07003791019413041
Trained batch 161 in epoch 18, gen_loss = 0.3974274476921117, disc_loss = 0.06975509115943203
Trained batch 162 in epoch 18, gen_loss = 0.39723780248428414, disc_loss = 0.06949164418995014
Trained batch 163 in epoch 18, gen_loss = 0.39756495787239654, disc_loss = 0.06951447087907936
Trained batch 164 in epoch 18, gen_loss = 0.39724028914263754, disc_loss = 0.07011017937100295
Trained batch 165 in epoch 18, gen_loss = 0.39794886336628216, disc_loss = 0.07041898008480847
Trained batch 166 in epoch 18, gen_loss = 0.3981672644079802, disc_loss = 0.07011551789180961
Trained batch 167 in epoch 18, gen_loss = 0.3980408292263746, disc_loss = 0.06999961544005644
Trained batch 168 in epoch 18, gen_loss = 0.39763667447679846, disc_loss = 0.06988335502218213
Trained batch 169 in epoch 18, gen_loss = 0.3969706473105094, disc_loss = 0.06989889377180268
Trained batch 170 in epoch 18, gen_loss = 0.3970651278893153, disc_loss = 0.06969685153218738
Trained batch 171 in epoch 18, gen_loss = 0.39721920696455376, disc_loss = 0.06949367679568917
Trained batch 172 in epoch 18, gen_loss = 0.3971271171218398, disc_loss = 0.06918511800252633
Trained batch 173 in epoch 18, gen_loss = 0.3971025626035942, disc_loss = 0.06912400609888565
Trained batch 174 in epoch 18, gen_loss = 0.397336762036596, disc_loss = 0.0690704878951822
Trained batch 175 in epoch 18, gen_loss = 0.39684487430548127, disc_loss = 0.068945192435587
Trained batch 176 in epoch 18, gen_loss = 0.3968556977092883, disc_loss = 0.06865622065329956
Trained batch 177 in epoch 18, gen_loss = 0.3967873165279292, disc_loss = 0.0684940984702847
Trained batch 178 in epoch 18, gen_loss = 0.39639661590147285, disc_loss = 0.06865933493778692
Trained batch 179 in epoch 18, gen_loss = 0.3967112459242344, disc_loss = 0.06854842133406136
Trained batch 180 in epoch 18, gen_loss = 0.3970370181522317, disc_loss = 0.06821812126394464
Trained batch 181 in epoch 18, gen_loss = 0.39700757417377536, disc_loss = 0.06796216369084604
Trained batch 182 in epoch 18, gen_loss = 0.39742649489087484, disc_loss = 0.06768500631868514
Trained batch 183 in epoch 18, gen_loss = 0.39742622775552067, disc_loss = 0.0680185146427349
Trained batch 184 in epoch 18, gen_loss = 0.3968215580727603, disc_loss = 0.06774951072560774
Trained batch 185 in epoch 18, gen_loss = 0.39642768657656124, disc_loss = 0.06898178030005707
Trained batch 186 in epoch 18, gen_loss = 0.39695951334614166, disc_loss = 0.06907614768746702
Trained batch 187 in epoch 18, gen_loss = 0.39745400473475456, disc_loss = 0.0690412151012966
Trained batch 188 in epoch 18, gen_loss = 0.3972473331387081, disc_loss = 0.06893336713787108
Trained batch 189 in epoch 18, gen_loss = 0.3967316578093328, disc_loss = 0.06889037705565754
Trained batch 190 in epoch 18, gen_loss = 0.39635279376781424, disc_loss = 0.06921941279896891
Trained batch 191 in epoch 18, gen_loss = 0.396288796250398, disc_loss = 0.0693387525388971
Trained batch 192 in epoch 18, gen_loss = 0.39613133028072395, disc_loss = 0.06917866029887619
Trained batch 193 in epoch 18, gen_loss = 0.3962333811466227, disc_loss = 0.06887922101874941
Trained batch 194 in epoch 18, gen_loss = 0.39584618722781156, disc_loss = 0.0687965425543296
Trained batch 195 in epoch 18, gen_loss = 0.39620757581932203, disc_loss = 0.06852372022991886
Trained batch 196 in epoch 18, gen_loss = 0.3961556062934362, disc_loss = 0.06835227639315092
Trained batch 197 in epoch 18, gen_loss = 0.39584424000496815, disc_loss = 0.06816858638341379
Trained batch 198 in epoch 18, gen_loss = 0.3956762855526191, disc_loss = 0.06806951716317604
Trained batch 199 in epoch 18, gen_loss = 0.3955396381765604, disc_loss = 0.068483604490757
Trained batch 200 in epoch 18, gen_loss = 0.39528833433466765, disc_loss = 0.06911000083038463
Trained batch 201 in epoch 18, gen_loss = 0.3954593655053932, disc_loss = 0.0688496596447312
Trained batch 202 in epoch 18, gen_loss = 0.39599259887716454, disc_loss = 0.06863479536448794
Trained batch 203 in epoch 18, gen_loss = 0.3959585041830353, disc_loss = 0.06850106798696752
Trained batch 204 in epoch 18, gen_loss = 0.39603650649873223, disc_loss = 0.06862158629952407
Trained batch 205 in epoch 18, gen_loss = 0.39598536050146066, disc_loss = 0.0684201400636614
Trained batch 206 in epoch 18, gen_loss = 0.3958831569854764, disc_loss = 0.06831397448220979
Trained batch 207 in epoch 18, gen_loss = 0.39567461172835183, disc_loss = 0.06818718370945695
Trained batch 208 in epoch 18, gen_loss = 0.3963806836656406, disc_loss = 0.06843623523399875
Trained batch 209 in epoch 18, gen_loss = 0.3959796704706692, disc_loss = 0.06852425557694265
Trained batch 210 in epoch 18, gen_loss = 0.3958449927975216, disc_loss = 0.06824193771716684
Trained batch 211 in epoch 18, gen_loss = 0.3957844728709392, disc_loss = 0.06808896688305123
Trained batch 212 in epoch 18, gen_loss = 0.39572512676738236, disc_loss = 0.06802432996793673
Trained batch 213 in epoch 18, gen_loss = 0.39547961163465106, disc_loss = 0.067775598152706
Trained batch 214 in epoch 18, gen_loss = 0.3958548389895018, disc_loss = 0.06755534339436264
Trained batch 215 in epoch 18, gen_loss = 0.3959545858066391, disc_loss = 0.06731932286035132
Trained batch 216 in epoch 18, gen_loss = 0.39589416795337257, disc_loss = 0.06716588036530578
Trained batch 217 in epoch 18, gen_loss = 0.39559866481144496, disc_loss = 0.06716527765907279
Trained batch 218 in epoch 18, gen_loss = 0.3958277036202008, disc_loss = 0.06755361699214264
Trained batch 219 in epoch 18, gen_loss = 0.3955941971730102, disc_loss = 0.06761499135331674
Trained batch 220 in epoch 18, gen_loss = 0.39557346411689914, disc_loss = 0.06736086878285014
Trained batch 221 in epoch 18, gen_loss = 0.395504885495783, disc_loss = 0.06711386084170626
Trained batch 222 in epoch 18, gen_loss = 0.3958743006792838, disc_loss = 0.0669022582412902
Trained batch 223 in epoch 18, gen_loss = 0.3962855682974415, disc_loss = 0.06674642102942537
Trained batch 224 in epoch 18, gen_loss = 0.39643623703055914, disc_loss = 0.06660860515717003
Trained batch 225 in epoch 18, gen_loss = 0.396492373824647, disc_loss = 0.06647417490345846
Trained batch 226 in epoch 18, gen_loss = 0.3968592790911376, disc_loss = 0.06631844881757896
Trained batch 227 in epoch 18, gen_loss = 0.3971913767357667, disc_loss = 0.06647968701119616
Trained batch 228 in epoch 18, gen_loss = 0.3969386816675486, disc_loss = 0.06672729893819343
Trained batch 229 in epoch 18, gen_loss = 0.3974341512374256, disc_loss = 0.06647163949015995
Trained batch 230 in epoch 18, gen_loss = 0.3978269049228528, disc_loss = 0.06633010824731031
Trained batch 231 in epoch 18, gen_loss = 0.39801481205584677, disc_loss = 0.06624544694907321
Trained batch 232 in epoch 18, gen_loss = 0.39816620645349116, disc_loss = 0.06602040859331006
Trained batch 233 in epoch 18, gen_loss = 0.39818105273521864, disc_loss = 0.0658559130353487
Trained batch 234 in epoch 18, gen_loss = 0.39789911210536955, disc_loss = 0.06570976355529212
Trained batch 235 in epoch 18, gen_loss = 0.3978572032588013, disc_loss = 0.06573081983774269
Trained batch 236 in epoch 18, gen_loss = 0.39812693886364564, disc_loss = 0.06568774006836399
Trained batch 237 in epoch 18, gen_loss = 0.39814570890504775, disc_loss = 0.06562092668228164
Trained batch 238 in epoch 18, gen_loss = 0.39806792408103225, disc_loss = 0.0655158652912311
Trained batch 239 in epoch 18, gen_loss = 0.39768539437403283, disc_loss = 0.06572973837998385
Trained batch 240 in epoch 18, gen_loss = 0.39825390205096406, disc_loss = 0.06656805668180785
Trained batch 241 in epoch 18, gen_loss = 0.398181347992302, disc_loss = 0.06694576573319548
Trained batch 242 in epoch 18, gen_loss = 0.3980865141859761, disc_loss = 0.06700837812597246
Trained batch 243 in epoch 18, gen_loss = 0.3984260597556341, disc_loss = 0.06681296567157766
Trained batch 244 in epoch 18, gen_loss = 0.39860050623514215, disc_loss = 0.06688971679505645
Trained batch 245 in epoch 18, gen_loss = 0.3987953846411007, disc_loss = 0.06698432142611563
Trained batch 246 in epoch 18, gen_loss = 0.3986375456758839, disc_loss = 0.06693003123422504
Trained batch 247 in epoch 18, gen_loss = 0.3984423608429009, disc_loss = 0.06678161341621872
Trained batch 248 in epoch 18, gen_loss = 0.3985247123073861, disc_loss = 0.06677622971570037
Trained batch 249 in epoch 18, gen_loss = 0.39895634120702744, disc_loss = 0.06710558406636119
Trained batch 250 in epoch 18, gen_loss = 0.3986422973443787, disc_loss = 0.06720397913405501
Trained batch 251 in epoch 18, gen_loss = 0.39845696759838906, disc_loss = 0.0675411263207299
Trained batch 252 in epoch 18, gen_loss = 0.39872536316455115, disc_loss = 0.06843948633347458
Trained batch 253 in epoch 18, gen_loss = 0.39850235049884153, disc_loss = 0.06833460309183387
Trained batch 254 in epoch 18, gen_loss = 0.3981912724527658, disc_loss = 0.06894503987814281
Trained batch 255 in epoch 18, gen_loss = 0.3985404027043842, disc_loss = 0.06897982106238487
Trained batch 256 in epoch 18, gen_loss = 0.39861877506113236, disc_loss = 0.06898417693095332
Trained batch 257 in epoch 18, gen_loss = 0.398776111618955, disc_loss = 0.06891128817544312
Trained batch 258 in epoch 18, gen_loss = 0.398515000133901, disc_loss = 0.06885668929867647
Trained batch 259 in epoch 18, gen_loss = 0.398430053717815, disc_loss = 0.06880712848371612
Trained batch 260 in epoch 18, gen_loss = 0.3987052612491951, disc_loss = 0.06876195922593846
Trained batch 261 in epoch 18, gen_loss = 0.3986460199679127, disc_loss = 0.06874379420027364
Trained batch 262 in epoch 18, gen_loss = 0.39880850803489465, disc_loss = 0.0686989460855779
Trained batch 263 in epoch 18, gen_loss = 0.3986425878988071, disc_loss = 0.06862345897719603
Trained batch 264 in epoch 18, gen_loss = 0.39842857139290505, disc_loss = 0.06871271932954495
Trained batch 265 in epoch 18, gen_loss = 0.3985525829563464, disc_loss = 0.06903299522285063
Trained batch 266 in epoch 18, gen_loss = 0.3986887055055032, disc_loss = 0.0689129058362337
Trained batch 267 in epoch 18, gen_loss = 0.3985577126158707, disc_loss = 0.06872273916587122
Trained batch 268 in epoch 18, gen_loss = 0.3986774515152864, disc_loss = 0.06852824254425374
Trained batch 269 in epoch 18, gen_loss = 0.3988438751410555, disc_loss = 0.06837203474715352
Trained batch 270 in epoch 18, gen_loss = 0.3987212413681389, disc_loss = 0.06824105320587699
Trained batch 271 in epoch 18, gen_loss = 0.39880327513331876, disc_loss = 0.06820188237778733
Trained batch 272 in epoch 18, gen_loss = 0.3986784489927711, disc_loss = 0.06852189099054525
Trained batch 273 in epoch 18, gen_loss = 0.39887681249937, disc_loss = 0.06880913456956292
Trained batch 274 in epoch 18, gen_loss = 0.39904030480168085, disc_loss = 0.06869598587466912
Trained batch 275 in epoch 18, gen_loss = 0.39895619457398634, disc_loss = 0.06850218696627712
Trained batch 276 in epoch 18, gen_loss = 0.3988606038399121, disc_loss = 0.06836866596142092
Trained batch 277 in epoch 18, gen_loss = 0.3988628655993681, disc_loss = 0.06823231848023778
Trained batch 278 in epoch 18, gen_loss = 0.3987973975985708, disc_loss = 0.06813125567357173
Trained batch 279 in epoch 18, gen_loss = 0.3989438478967973, disc_loss = 0.06815139407824193
Trained batch 280 in epoch 18, gen_loss = 0.3987178737264511, disc_loss = 0.06845812681147637
Trained batch 281 in epoch 18, gen_loss = 0.39890897776006806, disc_loss = 0.06843834408684403
Trained batch 282 in epoch 18, gen_loss = 0.3991591369621324, disc_loss = 0.0682721697254758
Trained batch 283 in epoch 18, gen_loss = 0.3992048402802205, disc_loss = 0.0681360322575439
Trained batch 284 in epoch 18, gen_loss = 0.3989432999439407, disc_loss = 0.06812530461241278
Trained batch 285 in epoch 18, gen_loss = 0.39890834298375605, disc_loss = 0.06813500379375019
Trained batch 286 in epoch 18, gen_loss = 0.39872787602064086, disc_loss = 0.06797161835281483
Trained batch 287 in epoch 18, gen_loss = 0.3987827412266698, disc_loss = 0.06793054214601095
Trained batch 288 in epoch 18, gen_loss = 0.39900119592367983, disc_loss = 0.0677509549102878
Trained batch 289 in epoch 18, gen_loss = 0.39895305104296785, disc_loss = 0.06770231313361176
Trained batch 290 in epoch 18, gen_loss = 0.39879519377172606, disc_loss = 0.06772943235984988
Trained batch 291 in epoch 18, gen_loss = 0.39872613115465805, disc_loss = 0.06758017684269237
Trained batch 292 in epoch 18, gen_loss = 0.398843559032821, disc_loss = 0.06738687640392943
Trained batch 293 in epoch 18, gen_loss = 0.3989091802920614, disc_loss = 0.06718112846684395
Trained batch 294 in epoch 18, gen_loss = 0.3990778424477173, disc_loss = 0.06700122429973493
Trained batch 295 in epoch 18, gen_loss = 0.3992837953909829, disc_loss = 0.06691665826931696
Trained batch 296 in epoch 18, gen_loss = 0.399166609953951, disc_loss = 0.06691874962877044
Trained batch 297 in epoch 18, gen_loss = 0.399371698448722, disc_loss = 0.06694960869511202
Trained batch 298 in epoch 18, gen_loss = 0.39922389223623433, disc_loss = 0.0668221886198108
Trained batch 299 in epoch 18, gen_loss = 0.39893330877025923, disc_loss = 0.06737737890643378
Trained batch 300 in epoch 18, gen_loss = 0.3993383892053782, disc_loss = 0.06733223656347127
Trained batch 301 in epoch 18, gen_loss = 0.39952955049592137, disc_loss = 0.06720690670059315
Trained batch 302 in epoch 18, gen_loss = 0.3995542680174604, disc_loss = 0.06709456446552926
Trained batch 303 in epoch 18, gen_loss = 0.3994929401792194, disc_loss = 0.06727735188752904
Trained batch 304 in epoch 18, gen_loss = 0.39962559620865057, disc_loss = 0.06708811603975101
Trained batch 305 in epoch 18, gen_loss = 0.3996756536995663, disc_loss = 0.06723017332576264
Trained batch 306 in epoch 18, gen_loss = 0.39944885292542487, disc_loss = 0.06733014271367062
Trained batch 307 in epoch 18, gen_loss = 0.39942947247779215, disc_loss = 0.06720515911455278
Trained batch 308 in epoch 18, gen_loss = 0.3993790985407567, disc_loss = 0.06708875904914631
Trained batch 309 in epoch 18, gen_loss = 0.3991685464016853, disc_loss = 0.06703663371022671
Trained batch 310 in epoch 18, gen_loss = 0.39909142423481037, disc_loss = 0.06689203861154544
Trained batch 311 in epoch 18, gen_loss = 0.39923831089757955, disc_loss = 0.06672904431485595
Trained batch 312 in epoch 18, gen_loss = 0.3990589772074367, disc_loss = 0.0666813557497419
Trained batch 313 in epoch 18, gen_loss = 0.39861698510350696, disc_loss = 0.06661776671553873
Trained batch 314 in epoch 18, gen_loss = 0.3982655855871382, disc_loss = 0.067247388618333
Trained batch 315 in epoch 18, gen_loss = 0.3988635075526147, disc_loss = 0.06740320228700396
Trained batch 316 in epoch 18, gen_loss = 0.3987848271236811, disc_loss = 0.06753358016912869
Trained batch 317 in epoch 18, gen_loss = 0.39846768642558994, disc_loss = 0.06792933130695385
Trained batch 318 in epoch 18, gen_loss = 0.39854326092150516, disc_loss = 0.06832440578171452
Trained batch 319 in epoch 18, gen_loss = 0.39871032130904493, disc_loss = 0.06914396008942277
Trained batch 320 in epoch 18, gen_loss = 0.39859916232642356, disc_loss = 0.06960932750289685
Trained batch 321 in epoch 18, gen_loss = 0.39839877535282453, disc_loss = 0.0708596053191964
Trained batch 322 in epoch 18, gen_loss = 0.3983497888587946, disc_loss = 0.07123325126182184
Trained batch 323 in epoch 18, gen_loss = 0.3984036786412751, disc_loss = 0.07150093831673816
Trained batch 324 in epoch 18, gen_loss = 0.3982556232580772, disc_loss = 0.07166168008859342
Trained batch 325 in epoch 18, gen_loss = 0.39820504851319305, disc_loss = 0.07164748077012278
Trained batch 326 in epoch 18, gen_loss = 0.39808079449955475, disc_loss = 0.07159151221178359
Trained batch 327 in epoch 18, gen_loss = 0.39815179990013927, disc_loss = 0.07154553323393552
Trained batch 328 in epoch 18, gen_loss = 0.39807030264186277, disc_loss = 0.07146108900069466
Trained batch 329 in epoch 18, gen_loss = 0.3982369957096649, disc_loss = 0.07140655877689521
Trained batch 330 in epoch 18, gen_loss = 0.39813105122740533, disc_loss = 0.07138020307771029
Trained batch 331 in epoch 18, gen_loss = 0.398182270711804, disc_loss = 0.07125912473750222
Trained batch 332 in epoch 18, gen_loss = 0.39825972686479755, disc_loss = 0.0712711077362478
Trained batch 333 in epoch 18, gen_loss = 0.39794117145374147, disc_loss = 0.07133242337891978
Trained batch 334 in epoch 18, gen_loss = 0.39771633366150644, disc_loss = 0.07127033749511882
Trained batch 335 in epoch 18, gen_loss = 0.39808521920903805, disc_loss = 0.07112315134699679
Trained batch 336 in epoch 18, gen_loss = 0.398064180943308, disc_loss = 0.07110357482970114
Trained batch 337 in epoch 18, gen_loss = 0.397921320557947, disc_loss = 0.07148096092684558
Trained batch 338 in epoch 18, gen_loss = 0.39807793291444976, disc_loss = 0.07167557338499918
Trained batch 339 in epoch 18, gen_loss = 0.3979297406971455, disc_loss = 0.0715847752385718
Trained batch 340 in epoch 18, gen_loss = 0.39774064553622973, disc_loss = 0.07177231819682982
Trained batch 341 in epoch 18, gen_loss = 0.3977578955522755, disc_loss = 0.07174361242820122
Trained batch 342 in epoch 18, gen_loss = 0.39787433494110497, disc_loss = 0.07162254054979054
Trained batch 343 in epoch 18, gen_loss = 0.39759024947361893, disc_loss = 0.0716224746930218
Trained batch 344 in epoch 18, gen_loss = 0.397694165767103, disc_loss = 0.07151745308352553
Trained batch 345 in epoch 18, gen_loss = 0.3977690471303945, disc_loss = 0.07146039557767052
Trained batch 346 in epoch 18, gen_loss = 0.3978832054464549, disc_loss = 0.07129795948896954
Trained batch 347 in epoch 18, gen_loss = 0.39789276009147195, disc_loss = 0.07122382588802312
Trained batch 348 in epoch 18, gen_loss = 0.3978378691184828, disc_loss = 0.07112759537194298
Trained batch 349 in epoch 18, gen_loss = 0.39788591363600323, disc_loss = 0.07099898443424275
Trained batch 350 in epoch 18, gen_loss = 0.39785358857395303, disc_loss = 0.07100627790775649
Trained batch 351 in epoch 18, gen_loss = 0.39754706752401864, disc_loss = 0.07149135182474063
Trained batch 352 in epoch 18, gen_loss = 0.39783798276364973, disc_loss = 0.07145669146390796
Trained batch 353 in epoch 18, gen_loss = 0.3979309283323207, disc_loss = 0.07140458198159007
Trained batch 354 in epoch 18, gen_loss = 0.3977535330493685, disc_loss = 0.0713757111546649
Trained batch 355 in epoch 18, gen_loss = 0.3975929684434714, disc_loss = 0.07144390594664166
Trained batch 356 in epoch 18, gen_loss = 0.3974921431611566, disc_loss = 0.07171707268261693
Trained batch 357 in epoch 18, gen_loss = 0.39774977582293514, disc_loss = 0.07167475505903696
Trained batch 358 in epoch 18, gen_loss = 0.39795612213837406, disc_loss = 0.07151128767540776
Trained batch 359 in epoch 18, gen_loss = 0.3978677764121029, disc_loss = 0.07145949153798736
Trained batch 360 in epoch 18, gen_loss = 0.39771990560593695, disc_loss = 0.07141108633150602
Trained batch 361 in epoch 18, gen_loss = 0.39749434207519774, disc_loss = 0.07126326351400815
Trained batch 362 in epoch 18, gen_loss = 0.39757268992829914, disc_loss = 0.07128081276509962
Trained batch 363 in epoch 18, gen_loss = 0.39764577359124853, disc_loss = 0.07161485506886882
Trained batch 364 in epoch 18, gen_loss = 0.39742956769793003, disc_loss = 0.0717194847328818
Trained batch 365 in epoch 18, gen_loss = 0.3974453738885499, disc_loss = 0.07163967256042394
Trained batch 366 in epoch 18, gen_loss = 0.3976872372123786, disc_loss = 0.07158230464113749
Trained batch 367 in epoch 18, gen_loss = 0.3975978386385933, disc_loss = 0.07151909659201604
Trained batch 368 in epoch 18, gen_loss = 0.39762480120833327, disc_loss = 0.07147665699151393
Trained batch 369 in epoch 18, gen_loss = 0.39796496520976765, disc_loss = 0.07137442188639496
Trained batch 370 in epoch 18, gen_loss = 0.39798721667087944, disc_loss = 0.07125435004668496
Trained batch 371 in epoch 18, gen_loss = 0.39792113218416447, disc_loss = 0.071410852957577
Trained batch 372 in epoch 18, gen_loss = 0.39804702593717756, disc_loss = 0.07184499548373609
Trained batch 373 in epoch 18, gen_loss = 0.39796516773375595, disc_loss = 0.07187267666045118
Trained batch 374 in epoch 18, gen_loss = 0.3978575019439061, disc_loss = 0.07176228617380062
Trained batch 375 in epoch 18, gen_loss = 0.398050387132358, disc_loss = 0.07170270885430038
Trained batch 376 in epoch 18, gen_loss = 0.3981932730115061, disc_loss = 0.07155415230240446
Trained batch 377 in epoch 18, gen_loss = 0.3983164015349257, disc_loss = 0.07143923047703331
Trained batch 378 in epoch 18, gen_loss = 0.39839950813309816, disc_loss = 0.07133163321802594
Trained batch 379 in epoch 18, gen_loss = 0.39841423375826135, disc_loss = 0.07134703653374393
Trained batch 380 in epoch 18, gen_loss = 0.39867327505052874, disc_loss = 0.07132172438602044
Trained batch 381 in epoch 18, gen_loss = 0.3984955365511135, disc_loss = 0.07119966130362365
Trained batch 382 in epoch 18, gen_loss = 0.39843590635388076, disc_loss = 0.07109563367553152
Trained batch 383 in epoch 18, gen_loss = 0.3984155042950685, disc_loss = 0.07107243263696243
Trained batch 384 in epoch 18, gen_loss = 0.39836938996593674, disc_loss = 0.07102174742219897
Trained batch 385 in epoch 18, gen_loss = 0.39846172585234124, disc_loss = 0.0708650318215664
Trained batch 386 in epoch 18, gen_loss = 0.3983495220426441, disc_loss = 0.07086107905626836
Trained batch 387 in epoch 18, gen_loss = 0.39819266904414313, disc_loss = 0.07078816989177511
Trained batch 388 in epoch 18, gen_loss = 0.3982114114231193, disc_loss = 0.07071320469081785
Trained batch 389 in epoch 18, gen_loss = 0.39829895744721094, disc_loss = 0.07060063521688183
Trained batch 390 in epoch 18, gen_loss = 0.39840102085219625, disc_loss = 0.07046184723344072
Trained batch 391 in epoch 18, gen_loss = 0.3983341976620105, disc_loss = 0.07037754380856925
Trained batch 392 in epoch 18, gen_loss = 0.3983710364606848, disc_loss = 0.07025669396881004
Trained batch 393 in epoch 18, gen_loss = 0.3984402619718295, disc_loss = 0.07014951676480131
Trained batch 394 in epoch 18, gen_loss = 0.39830001422876044, disc_loss = 0.0701278755111219
Trained batch 395 in epoch 18, gen_loss = 0.398359386796, disc_loss = 0.0702144021116611
Trained batch 396 in epoch 18, gen_loss = 0.39865621335110074, disc_loss = 0.0703960941935554
Trained batch 397 in epoch 18, gen_loss = 0.39865510775965063, disc_loss = 0.07024827382606852
Trained batch 398 in epoch 18, gen_loss = 0.3988081447985537, disc_loss = 0.0701960205943102
Trained batch 399 in epoch 18, gen_loss = 0.3989200125262141, disc_loss = 0.07006781660253182
Trained batch 400 in epoch 18, gen_loss = 0.39909338769026825, disc_loss = 0.06992661369328115
Trained batch 401 in epoch 18, gen_loss = 0.3989893132403715, disc_loss = 0.06986107378595727
Trained batch 402 in epoch 18, gen_loss = 0.39862477176686373, disc_loss = 0.07001472811535851
Trained batch 403 in epoch 18, gen_loss = 0.39864972805475246, disc_loss = 0.0702231658581128
Trained batch 404 in epoch 18, gen_loss = 0.3987210553737334, disc_loss = 0.0701095552103203
Trained batch 405 in epoch 18, gen_loss = 0.39855148687298075, disc_loss = 0.07010852058505264
Trained batch 406 in epoch 18, gen_loss = 0.39839680793097915, disc_loss = 0.07037538778110057
Trained batch 407 in epoch 18, gen_loss = 0.3985224619288655, disc_loss = 0.07027414938955404
Trained batch 408 in epoch 18, gen_loss = 0.39834500433908987, disc_loss = 0.07015625751989468
Trained batch 409 in epoch 18, gen_loss = 0.3983540185704464, disc_loss = 0.07004102286087667
Trained batch 410 in epoch 18, gen_loss = 0.3982780280266945, disc_loss = 0.07018046682233721
Trained batch 411 in epoch 18, gen_loss = 0.3981053859212445, disc_loss = 0.07063267014025557
Trained batch 412 in epoch 18, gen_loss = 0.39827651936407527, disc_loss = 0.07053432258445833
Trained batch 413 in epoch 18, gen_loss = 0.3982442244167489, disc_loss = 0.07071794688494669
Trained batch 414 in epoch 18, gen_loss = 0.3980390812618187, disc_loss = 0.07068462264331349
Trained batch 415 in epoch 18, gen_loss = 0.3982285366823467, disc_loss = 0.07100223939946423
Trained batch 416 in epoch 18, gen_loss = 0.398006552879473, disc_loss = 0.07146694581080183
Trained batch 417 in epoch 18, gen_loss = 0.39772244585615596, disc_loss = 0.07147837687132247
Trained batch 418 in epoch 18, gen_loss = 0.39808617297533305, disc_loss = 0.07173427199913736
Trained batch 419 in epoch 18, gen_loss = 0.39805202310283977, disc_loss = 0.07178375004524631
Trained batch 420 in epoch 18, gen_loss = 0.39796430477761885, disc_loss = 0.07170623494201558
Trained batch 421 in epoch 18, gen_loss = 0.39791780318270364, disc_loss = 0.07169985650460373
Trained batch 422 in epoch 18, gen_loss = 0.3980068019448161, disc_loss = 0.07158661109062867
Trained batch 423 in epoch 18, gen_loss = 0.39810913017476507, disc_loss = 0.07146778399836412
Trained batch 424 in epoch 18, gen_loss = 0.3979874712930006, disc_loss = 0.0713698525398093
Trained batch 425 in epoch 18, gen_loss = 0.39794621413722286, disc_loss = 0.07125817826280081
Trained batch 426 in epoch 18, gen_loss = 0.39785757524766185, disc_loss = 0.07117256954251254
Trained batch 427 in epoch 18, gen_loss = 0.39802462966224855, disc_loss = 0.07103816043176453
Trained batch 428 in epoch 18, gen_loss = 0.3981093042171918, disc_loss = 0.07099607962211876
Trained batch 429 in epoch 18, gen_loss = 0.39806291859510334, disc_loss = 0.07110886180686743
Trained batch 430 in epoch 18, gen_loss = 0.3981790139821732, disc_loss = 0.07113282278983955
Trained batch 431 in epoch 18, gen_loss = 0.3981727236467931, disc_loss = 0.07108050033113816
Trained batch 432 in epoch 18, gen_loss = 0.398149736518122, disc_loss = 0.07095121406663991
Trained batch 433 in epoch 18, gen_loss = 0.39804698447889997, disc_loss = 0.07082884377383623
Trained batch 434 in epoch 18, gen_loss = 0.3980693678403723, disc_loss = 0.07073067912896132
Trained batch 435 in epoch 18, gen_loss = 0.39801922724197764, disc_loss = 0.070668711034376
Trained batch 436 in epoch 18, gen_loss = 0.39796646212140263, disc_loss = 0.0706528034338246
Trained batch 437 in epoch 18, gen_loss = 0.39808098043072715, disc_loss = 0.07084626842877023
Trained batch 438 in epoch 18, gen_loss = 0.3979808012350274, disc_loss = 0.07094332116501138
Trained batch 439 in epoch 18, gen_loss = 0.3979682630097324, disc_loss = 0.07085638513407586
Trained batch 440 in epoch 18, gen_loss = 0.39785976457893174, disc_loss = 0.07109285407655296
Trained batch 441 in epoch 18, gen_loss = 0.39777486845513815, disc_loss = 0.07109886178392832
Trained batch 442 in epoch 18, gen_loss = 0.3977875726015788, disc_loss = 0.0709858401394691
Trained batch 443 in epoch 18, gen_loss = 0.39796128214613813, disc_loss = 0.07089526453558859
Trained batch 444 in epoch 18, gen_loss = 0.39789749561400894, disc_loss = 0.07096601428903555
Trained batch 445 in epoch 18, gen_loss = 0.39795381609233504, disc_loss = 0.07098025448344682
Trained batch 446 in epoch 18, gen_loss = 0.3978814532359441, disc_loss = 0.07085735405226481
Trained batch 447 in epoch 18, gen_loss = 0.3977746297937951, disc_loss = 0.07082318463238023
Trained batch 448 in epoch 18, gen_loss = 0.3977750032343684, disc_loss = 0.07082355679749182
Trained batch 449 in epoch 18, gen_loss = 0.3976386274562942, disc_loss = 0.07085874774596758
Trained batch 450 in epoch 18, gen_loss = 0.39770630930453343, disc_loss = 0.0707501067145998
Trained batch 451 in epoch 18, gen_loss = 0.39785740145407944, disc_loss = 0.07065539891353553
Trained batch 452 in epoch 18, gen_loss = 0.3977073249766895, disc_loss = 0.07068619487506993
Trained batch 453 in epoch 18, gen_loss = 0.3976170558827039, disc_loss = 0.07091571915985007
Trained batch 454 in epoch 18, gen_loss = 0.39766756371482387, disc_loss = 0.07086504512967971
Trained batch 455 in epoch 18, gen_loss = 0.397773147707707, disc_loss = 0.07076735587651727
Trained batch 456 in epoch 18, gen_loss = 0.39790108992312617, disc_loss = 0.07076840532059156
Trained batch 457 in epoch 18, gen_loss = 0.3976907421342671, disc_loss = 0.07115196390077472
Trained batch 458 in epoch 18, gen_loss = 0.3981525457437781, disc_loss = 0.07160130028525663
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.32783830165863037, disc_loss = 0.1520412415266037
Trained batch 1 in epoch 19, gen_loss = 0.29168783128261566, disc_loss = 0.2241542860865593
Trained batch 2 in epoch 19, gen_loss = 0.3347056408723195, disc_loss = 0.1718384474515915
Trained batch 3 in epoch 19, gen_loss = 0.3606672137975693, disc_loss = 0.14146772678941488
Trained batch 4 in epoch 19, gen_loss = 0.37317054271697997, disc_loss = 0.13165579959750176
Trained batch 5 in epoch 19, gen_loss = 0.37464019656181335, disc_loss = 0.11994076458116372
Trained batch 6 in epoch 19, gen_loss = 0.37045606119292124, disc_loss = 0.10825648212007113
Trained batch 7 in epoch 19, gen_loss = 0.3584953583776951, disc_loss = 0.11037893174216151
Trained batch 8 in epoch 19, gen_loss = 0.34647466076744926, disc_loss = 0.12760738821493256
Trained batch 9 in epoch 19, gen_loss = 0.35098675191402434, disc_loss = 0.12058768011629581
Trained batch 10 in epoch 19, gen_loss = 0.3570067123933272, disc_loss = 0.11617611247030171
Trained batch 11 in epoch 19, gen_loss = 0.3614664127429326, disc_loss = 0.11240431076536576
Trained batch 12 in epoch 19, gen_loss = 0.36409297356238735, disc_loss = 0.10596039977211219
Trained batch 13 in epoch 19, gen_loss = 0.3708691086087908, disc_loss = 0.1012989061751536
Trained batch 14 in epoch 19, gen_loss = 0.3710544268290202, disc_loss = 0.09709290290872256
Trained batch 15 in epoch 19, gen_loss = 0.3713784720748663, disc_loss = 0.09584406088106334
Trained batch 16 in epoch 19, gen_loss = 0.37356851907337413, disc_loss = 0.09497278249439071
Trained batch 17 in epoch 19, gen_loss = 0.37024610075685715, disc_loss = 0.09368037701480919
Trained batch 18 in epoch 19, gen_loss = 0.37435258219116613, disc_loss = 0.08979939767404606
Trained batch 19 in epoch 19, gen_loss = 0.3776939168572426, disc_loss = 0.08683020193129778
Trained batch 20 in epoch 19, gen_loss = 0.37699915823482333, disc_loss = 0.08823296693818909
Trained batch 21 in epoch 19, gen_loss = 0.3784871006553823, disc_loss = 0.09817794625732032
Trained batch 22 in epoch 19, gen_loss = 0.37643300061640533, disc_loss = 0.09940630246115767
Trained batch 23 in epoch 19, gen_loss = 0.38024477288126945, disc_loss = 0.095684734871611
Trained batch 24 in epoch 19, gen_loss = 0.37718010783195494, disc_loss = 0.09402662314474583
Trained batch 25 in epoch 19, gen_loss = 0.3774758451260053, disc_loss = 0.09246016659129125
Trained batch 26 in epoch 19, gen_loss = 0.3764665049535257, disc_loss = 0.09201202120769907
Trained batch 27 in epoch 19, gen_loss = 0.38100170344114304, disc_loss = 0.09084112030853118
Trained batch 28 in epoch 19, gen_loss = 0.3826599491053614, disc_loss = 0.08882303837815235
Trained batch 29 in epoch 19, gen_loss = 0.383487668633461, disc_loss = 0.09260960513104995
Trained batch 30 in epoch 19, gen_loss = 0.3862005587547056, disc_loss = 0.09195519665316228
Trained batch 31 in epoch 19, gen_loss = 0.3852125285193324, disc_loss = 0.09107982268324122
Trained batch 32 in epoch 19, gen_loss = 0.38405650492870447, disc_loss = 0.09033677247211788
Trained batch 33 in epoch 19, gen_loss = 0.3876266987884746, disc_loss = 0.08910242911866482
Trained batch 34 in epoch 19, gen_loss = 0.3887539667742593, disc_loss = 0.08677543065111552
Trained batch 35 in epoch 19, gen_loss = 0.3878657619158427, disc_loss = 0.08654895801252376
Trained batch 36 in epoch 19, gen_loss = 0.3905764536277668, disc_loss = 0.08632283661564863
Trained batch 37 in epoch 19, gen_loss = 0.39147282979990305, disc_loss = 0.08460656635610289
Trained batch 38 in epoch 19, gen_loss = 0.39199680701280254, disc_loss = 0.0833763043061854
Trained batch 39 in epoch 19, gen_loss = 0.3919146522879601, disc_loss = 0.08164935862878338
Trained batch 40 in epoch 19, gen_loss = 0.3925257790379408, disc_loss = 0.08204744452974055
Trained batch 41 in epoch 19, gen_loss = 0.3921678059157871, disc_loss = 0.0827513513310502
Trained batch 42 in epoch 19, gen_loss = 0.3921962179416834, disc_loss = 0.08201488320780702
Trained batch 43 in epoch 19, gen_loss = 0.39125309545885434, disc_loss = 0.0804120561806485
Trained batch 44 in epoch 19, gen_loss = 0.3913553694883982, disc_loss = 0.07996587410776151
Trained batch 45 in epoch 19, gen_loss = 0.3923112996246504, disc_loss = 0.07987277490167838
Trained batch 46 in epoch 19, gen_loss = 0.3917156572037555, disc_loss = 0.08048365618835421
Trained batch 47 in epoch 19, gen_loss = 0.393193203335007, disc_loss = 0.08284296705581558
Trained batch 48 in epoch 19, gen_loss = 0.39420588405764834, disc_loss = 0.08144304449955116
Trained batch 49 in epoch 19, gen_loss = 0.3955392211675644, disc_loss = 0.0806094337720424
Trained batch 50 in epoch 19, gen_loss = 0.39587441378948734, disc_loss = 0.07923915913766798
Trained batch 51 in epoch 19, gen_loss = 0.39745234927305806, disc_loss = 0.07813944758023493
Trained batch 52 in epoch 19, gen_loss = 0.39826316428634356, disc_loss = 0.0769454798450307
Trained batch 53 in epoch 19, gen_loss = 0.39740552173720467, disc_loss = 0.0758173402864486
Trained batch 54 in epoch 19, gen_loss = 0.39706003882668234, disc_loss = 0.07472689581018957
Trained batch 55 in epoch 19, gen_loss = 0.39516870624252726, disc_loss = 0.07454690599115565
Trained batch 56 in epoch 19, gen_loss = 0.3965932601376584, disc_loss = 0.07510680805793718
Trained batch 57 in epoch 19, gen_loss = 0.3947925829681857, disc_loss = 0.07663074607061672
Trained batch 58 in epoch 19, gen_loss = 0.3947334324909469, disc_loss = 0.07645168959684039
Trained batch 59 in epoch 19, gen_loss = 0.3940420880913734, disc_loss = 0.07558491188877572
Trained batch 60 in epoch 19, gen_loss = 0.39428560069349944, disc_loss = 0.07481281351695052
Trained batch 61 in epoch 19, gen_loss = 0.3955511830506786, disc_loss = 0.07409810304130998
Trained batch 62 in epoch 19, gen_loss = 0.3960978809803251, disc_loss = 0.07321205293937098
Trained batch 63 in epoch 19, gen_loss = 0.39613495441153646, disc_loss = 0.07247897309571272
Trained batch 64 in epoch 19, gen_loss = 0.39658780785707326, disc_loss = 0.07260811067401217
Trained batch 65 in epoch 19, gen_loss = 0.39603463357145136, disc_loss = 0.07306852927572574
Trained batch 66 in epoch 19, gen_loss = 0.3965072084718676, disc_loss = 0.0721181410003398
Trained batch 67 in epoch 19, gen_loss = 0.3976283634410185, disc_loss = 0.07136557562797166
Trained batch 68 in epoch 19, gen_loss = 0.39836474000543787, disc_loss = 0.07070590568490434
Trained batch 69 in epoch 19, gen_loss = 0.39855297676154544, disc_loss = 0.07000933906196484
Trained batch 70 in epoch 19, gen_loss = 0.3984741686095654, disc_loss = 0.06924098869785666
Trained batch 71 in epoch 19, gen_loss = 0.3981533522407214, disc_loss = 0.06898829432126756
Trained batch 72 in epoch 19, gen_loss = 0.39868498379237033, disc_loss = 0.06946508370161261
Trained batch 73 in epoch 19, gen_loss = 0.40049237455870657, disc_loss = 0.06872099102474749
Trained batch 74 in epoch 19, gen_loss = 0.40162705222765605, disc_loss = 0.06913196353241802
Trained batch 75 in epoch 19, gen_loss = 0.4008824852736373, disc_loss = 0.06889846576010122
Trained batch 76 in epoch 19, gen_loss = 0.4006905962120403, disc_loss = 0.06843658912225396
Trained batch 77 in epoch 19, gen_loss = 0.4006424129773409, disc_loss = 0.06871536295884886
Trained batch 78 in epoch 19, gen_loss = 0.40035441253758686, disc_loss = 0.06808204121911261
Trained batch 79 in epoch 19, gen_loss = 0.3994378615170717, disc_loss = 0.06885030719568022
Trained batch 80 in epoch 19, gen_loss = 0.4001442591349284, disc_loss = 0.06910615325273003
Trained batch 81 in epoch 19, gen_loss = 0.40167945623397827, disc_loss = 0.0684779243963975
Trained batch 82 in epoch 19, gen_loss = 0.4017389079174363, disc_loss = 0.0678753227455519
Trained batch 83 in epoch 19, gen_loss = 0.4009022098921594, disc_loss = 0.06745895852578715
Trained batch 84 in epoch 19, gen_loss = 0.4024054937502917, disc_loss = 0.06681591809782035
Trained batch 85 in epoch 19, gen_loss = 0.4017054584137229, disc_loss = 0.06652473210530399
Trained batch 86 in epoch 19, gen_loss = 0.3999006508410662, disc_loss = 0.06633577297238269
Trained batch 87 in epoch 19, gen_loss = 0.3998343395915898, disc_loss = 0.06602410856232216
Trained batch 88 in epoch 19, gen_loss = 0.39945473798205344, disc_loss = 0.06554786499401324
Trained batch 89 in epoch 19, gen_loss = 0.3993423021501965, disc_loss = 0.06555577117639283
Trained batch 90 in epoch 19, gen_loss = 0.39702001443276036, disc_loss = 0.0676951444257501
Trained batch 91 in epoch 19, gen_loss = 0.3981024114334065, disc_loss = 0.0671828742513595
Trained batch 92 in epoch 19, gen_loss = 0.39771640460978275, disc_loss = 0.06718138808144196
Trained batch 93 in epoch 19, gen_loss = 0.3972054228503653, disc_loss = 0.0670187700232689
Trained batch 94 in epoch 19, gen_loss = 0.3971117716086538, disc_loss = 0.06700133895501495
Trained batch 95 in epoch 19, gen_loss = 0.39718696506073076, disc_loss = 0.06780323939650164
Trained batch 96 in epoch 19, gen_loss = 0.3991976733674708, disc_loss = 0.06830584352413557
Trained batch 97 in epoch 19, gen_loss = 0.3993200255291803, disc_loss = 0.06799415877678108
Trained batch 98 in epoch 19, gen_loss = 0.3993900707273772, disc_loss = 0.06824343687751228
Trained batch 99 in epoch 19, gen_loss = 0.3995779946446419, disc_loss = 0.06811345225665719
Trained batch 100 in epoch 19, gen_loss = 0.39951059074685125, disc_loss = 0.06807527866786217
Trained batch 101 in epoch 19, gen_loss = 0.39931158487703283, disc_loss = 0.06811133390931669
Trained batch 102 in epoch 19, gen_loss = 0.3994877170590521, disc_loss = 0.06898623428678194
Trained batch 103 in epoch 19, gen_loss = 0.3995776634949904, disc_loss = 0.0698054255066941
Trained batch 104 in epoch 19, gen_loss = 0.4000747876507895, disc_loss = 0.06944038969508949
Trained batch 105 in epoch 19, gen_loss = 0.4000192186180151, disc_loss = 0.06927455492967845
Trained batch 106 in epoch 19, gen_loss = 0.4004739726258216, disc_loss = 0.06903740967771857
Trained batch 107 in epoch 19, gen_loss = 0.4001716240136712, disc_loss = 0.06868177040531817
Trained batch 108 in epoch 19, gen_loss = 0.40124917987289777, disc_loss = 0.06831198201489148
Trained batch 109 in epoch 19, gen_loss = 0.40076876363971015, disc_loss = 0.06847476426258006
Trained batch 110 in epoch 19, gen_loss = 0.40012727557001887, disc_loss = 0.07066497161799858
Trained batch 111 in epoch 19, gen_loss = 0.4008595182427338, disc_loss = 0.07161582043876738
Trained batch 112 in epoch 19, gen_loss = 0.4007973209419082, disc_loss = 0.07125145063809721
Trained batch 113 in epoch 19, gen_loss = 0.40104137334907264, disc_loss = 0.07127788400261156
Trained batch 114 in epoch 19, gen_loss = 0.4004504706548608, disc_loss = 0.07096714100840947
Trained batch 115 in epoch 19, gen_loss = 0.40096898042950135, disc_loss = 0.07061492486712362
Trained batch 116 in epoch 19, gen_loss = 0.4011389243806529, disc_loss = 0.07025877354889472
Trained batch 117 in epoch 19, gen_loss = 0.40113132939500323, disc_loss = 0.07018564831291846
Trained batch 118 in epoch 19, gen_loss = 0.4008017768379019, disc_loss = 0.07100796461997538
Trained batch 119 in epoch 19, gen_loss = 0.400434264789025, disc_loss = 0.0727980754066569
Trained batch 120 in epoch 19, gen_loss = 0.3992798700312938, disc_loss = 0.07247414695837896
Trained batch 121 in epoch 19, gen_loss = 0.39993939316663585, disc_loss = 0.07354645581045723
Trained batch 122 in epoch 19, gen_loss = 0.39886255574420215, disc_loss = 0.07461450125158924
Trained batch 123 in epoch 19, gen_loss = 0.39900117367506027, disc_loss = 0.07427642648033198
Trained batch 124 in epoch 19, gen_loss = 0.39936388802528383, disc_loss = 0.07393325406685472
Trained batch 125 in epoch 19, gen_loss = 0.3991803453555183, disc_loss = 0.07375998263217745
Trained batch 126 in epoch 19, gen_loss = 0.39874476992239166, disc_loss = 0.07373421281708155
Trained batch 127 in epoch 19, gen_loss = 0.39792345906607807, disc_loss = 0.07347256585853756
Trained batch 128 in epoch 19, gen_loss = 0.39844104093174604, disc_loss = 0.07310660954839153
Trained batch 129 in epoch 19, gen_loss = 0.3978908006961529, disc_loss = 0.07299811192788183
Trained batch 130 in epoch 19, gen_loss = 0.3982252264750823, disc_loss = 0.0731772511436796
Trained batch 131 in epoch 19, gen_loss = 0.39835601051648456, disc_loss = 0.0727709543249203
Trained batch 132 in epoch 19, gen_loss = 0.39690288766882476, disc_loss = 0.07251806959467835
Trained batch 133 in epoch 19, gen_loss = 0.3971070740649949, disc_loss = 0.07215113077771419
Trained batch 134 in epoch 19, gen_loss = 0.39704722430970935, disc_loss = 0.07189082841699322
Trained batch 135 in epoch 19, gen_loss = 0.39702371902325573, disc_loss = 0.07172287120278377
Trained batch 136 in epoch 19, gen_loss = 0.3962944524131552, disc_loss = 0.07162474230761184
Trained batch 137 in epoch 19, gen_loss = 0.3962553331385488, disc_loss = 0.07119674545685774
Trained batch 138 in epoch 19, gen_loss = 0.39716761082196406, disc_loss = 0.07114693047746802
Trained batch 139 in epoch 19, gen_loss = 0.3972133491720472, disc_loss = 0.07085504153676864
Trained batch 140 in epoch 19, gen_loss = 0.39749045680600703, disc_loss = 0.07042004671674354
Trained batch 141 in epoch 19, gen_loss = 0.3973007428813988, disc_loss = 0.07079929629222713
Trained batch 142 in epoch 19, gen_loss = 0.39685673709515923, disc_loss = 0.07209627915473356
Trained batch 143 in epoch 19, gen_loss = 0.39732202721966636, disc_loss = 0.07188446133255234
Trained batch 144 in epoch 19, gen_loss = 0.39771222225550945, disc_loss = 0.07199213994538475
Trained batch 145 in epoch 19, gen_loss = 0.39754291225786076, disc_loss = 0.07190999415805181
Trained batch 146 in epoch 19, gen_loss = 0.3976911857825558, disc_loss = 0.07154110024942933
Trained batch 147 in epoch 19, gen_loss = 0.3979891556743029, disc_loss = 0.07111621486664926
Trained batch 148 in epoch 19, gen_loss = 0.39817412647624945, disc_loss = 0.07074369701100576
Trained batch 149 in epoch 19, gen_loss = 0.39792945961157483, disc_loss = 0.07054575608111918
Trained batch 150 in epoch 19, gen_loss = 0.39766735687161126, disc_loss = 0.07044336985216926
Trained batch 151 in epoch 19, gen_loss = 0.39740143520267385, disc_loss = 0.07010309658883336
Trained batch 152 in epoch 19, gen_loss = 0.39719582402628234, disc_loss = 0.06976149803076208
Trained batch 153 in epoch 19, gen_loss = 0.3978327592084934, disc_loss = 0.06941147041869919
Trained batch 154 in epoch 19, gen_loss = 0.3972522747132086, disc_loss = 0.06924113385799911
Trained batch 155 in epoch 19, gen_loss = 0.3975828121869992, disc_loss = 0.06889484886927769
Trained batch 156 in epoch 19, gen_loss = 0.3979570795396331, disc_loss = 0.06854772234667733
Trained batch 157 in epoch 19, gen_loss = 0.398051083653788, disc_loss = 0.06827147890035581
Trained batch 158 in epoch 19, gen_loss = 0.39799229941278136, disc_loss = 0.06818208712557296
Trained batch 159 in epoch 19, gen_loss = 0.3981009256094694, disc_loss = 0.06879694056988228
Trained batch 160 in epoch 19, gen_loss = 0.397433773886343, disc_loss = 0.06915879846833971
Trained batch 161 in epoch 19, gen_loss = 0.39750943470884254, disc_loss = 0.0687968941250195
Trained batch 162 in epoch 19, gen_loss = 0.3976688224113792, disc_loss = 0.06856023462237848
Trained batch 163 in epoch 19, gen_loss = 0.3976458696330466, disc_loss = 0.0682371283637178
Trained batch 164 in epoch 19, gen_loss = 0.3976268273411375, disc_loss = 0.06791059175280459
Trained batch 165 in epoch 19, gen_loss = 0.3975937702210553, disc_loss = 0.0676223099573953
Trained batch 166 in epoch 19, gen_loss = 0.39792186771324295, disc_loss = 0.06734417636828598
Trained batch 167 in epoch 19, gen_loss = 0.3975630407886846, disc_loss = 0.06744860289230321
Trained batch 168 in epoch 19, gen_loss = 0.3978071168682279, disc_loss = 0.06753990727823955
Trained batch 169 in epoch 19, gen_loss = 0.398126356216038, disc_loss = 0.06721751951502965
Trained batch 170 in epoch 19, gen_loss = 0.39875632925340304, disc_loss = 0.06702665617275569
Trained batch 171 in epoch 19, gen_loss = 0.39922814729601835, disc_loss = 0.06676429470860247
Trained batch 172 in epoch 19, gen_loss = 0.3988684924007151, disc_loss = 0.06752158292014733
Trained batch 173 in epoch 19, gen_loss = 0.39939529697100323, disc_loss = 0.06809499187277224
Trained batch 174 in epoch 19, gen_loss = 0.39904507551874435, disc_loss = 0.06796437190845608
Trained batch 175 in epoch 19, gen_loss = 0.3991679452698339, disc_loss = 0.06837733711952089
Trained batch 176 in epoch 19, gen_loss = 0.3994687437000921, disc_loss = 0.06805096807400302
Trained batch 177 in epoch 19, gen_loss = 0.399667649624053, disc_loss = 0.06784691239623458
Trained batch 178 in epoch 19, gen_loss = 0.39976266559275836, disc_loss = 0.06756249369595553
Trained batch 179 in epoch 19, gen_loss = 0.3999383136630058, disc_loss = 0.0673300749492935
Trained batch 180 in epoch 19, gen_loss = 0.39977356528050334, disc_loss = 0.06710078622579821
Trained batch 181 in epoch 19, gen_loss = 0.3998341453926904, disc_loss = 0.06682846297837466
Trained batch 182 in epoch 19, gen_loss = 0.3998881705471727, disc_loss = 0.06661311029889137
Trained batch 183 in epoch 19, gen_loss = 0.4000860164346902, disc_loss = 0.06642435541447334
Trained batch 184 in epoch 19, gen_loss = 0.40013327920759045, disc_loss = 0.06642736395619608
Trained batch 185 in epoch 19, gen_loss = 0.400133561222784, disc_loss = 0.06685846809407957
Trained batch 186 in epoch 19, gen_loss = 0.4005170752976667, disc_loss = 0.06665106247961122
Trained batch 187 in epoch 19, gen_loss = 0.40082802544248863, disc_loss = 0.06658182836860974
Trained batch 188 in epoch 19, gen_loss = 0.40054198547645853, disc_loss = 0.06722284369318494
Trained batch 189 in epoch 19, gen_loss = 0.4007371358181301, disc_loss = 0.06714521806049896
Trained batch 190 in epoch 19, gen_loss = 0.40128078963119945, disc_loss = 0.0669633435519383
Trained batch 191 in epoch 19, gen_loss = 0.40068353976433474, disc_loss = 0.06694316618328837
Trained batch 192 in epoch 19, gen_loss = 0.40038567781448364, disc_loss = 0.06680236466064894
Trained batch 193 in epoch 19, gen_loss = 0.4006507270729419, disc_loss = 0.06661431716764633
Trained batch 194 in epoch 19, gen_loss = 0.4009463047369933, disc_loss = 0.06637786391597146
Trained batch 195 in epoch 19, gen_loss = 0.40101383474408364, disc_loss = 0.06622845173708866
Trained batch 196 in epoch 19, gen_loss = 0.4013099183285902, disc_loss = 0.06605755889239877
Trained batch 197 in epoch 19, gen_loss = 0.4014071500060534, disc_loss = 0.06581684732292262
Trained batch 198 in epoch 19, gen_loss = 0.4009383446607158, disc_loss = 0.06565956510931029
Trained batch 199 in epoch 19, gen_loss = 0.4006256750226021, disc_loss = 0.0654114325880073
Trained batch 200 in epoch 19, gen_loss = 0.4003522882414101, disc_loss = 0.06516384729763391
Trained batch 201 in epoch 19, gen_loss = 0.4005718771183845, disc_loss = 0.06489233102990628
Trained batch 202 in epoch 19, gen_loss = 0.40076172704179885, disc_loss = 0.06471122082166851
Trained batch 203 in epoch 19, gen_loss = 0.4006600111138587, disc_loss = 0.06471028204724266
Trained batch 204 in epoch 19, gen_loss = 0.40090408456034776, disc_loss = 0.06446770308539271
Trained batch 205 in epoch 19, gen_loss = 0.40061365313900327, disc_loss = 0.06430075278514726
Trained batch 206 in epoch 19, gen_loss = 0.40021649478138355, disc_loss = 0.06419773042372963
Trained batch 207 in epoch 19, gen_loss = 0.40028885608682263, disc_loss = 0.06395703806461264
Trained batch 208 in epoch 19, gen_loss = 0.40023481432330665, disc_loss = 0.06378584080398012
Trained batch 209 in epoch 19, gen_loss = 0.4004773581311816, disc_loss = 0.06373333873981167
Trained batch 210 in epoch 19, gen_loss = 0.4006073233358103, disc_loss = 0.06362566981967803
Trained batch 211 in epoch 19, gen_loss = 0.3999753247173327, disc_loss = 0.06349816445463319
Trained batch 212 in epoch 19, gen_loss = 0.40017225065141776, disc_loss = 0.06329520273857484
Trained batch 213 in epoch 19, gen_loss = 0.4004148366016762, disc_loss = 0.06310458629061337
Trained batch 214 in epoch 19, gen_loss = 0.4001892838367196, disc_loss = 0.06318702480950675
Trained batch 215 in epoch 19, gen_loss = 0.40014041242776094, disc_loss = 0.06325712115115796
Trained batch 216 in epoch 19, gen_loss = 0.40025072218635666, disc_loss = 0.06310189397542089
Trained batch 217 in epoch 19, gen_loss = 0.40026056342715516, disc_loss = 0.06302336200755602
Trained batch 218 in epoch 19, gen_loss = 0.40006501380711385, disc_loss = 0.06328818103995974
Trained batch 219 in epoch 19, gen_loss = 0.4006857931613922, disc_loss = 0.06362584799485789
Trained batch 220 in epoch 19, gen_loss = 0.40046184351541336, disc_loss = 0.06343640872315247
Trained batch 221 in epoch 19, gen_loss = 0.4003027160693933, disc_loss = 0.06327007210662437
Trained batch 222 in epoch 19, gen_loss = 0.4004814743728381, disc_loss = 0.06303122907985553
Trained batch 223 in epoch 19, gen_loss = 0.4005830752264176, disc_loss = 0.0629027486117723
Trained batch 224 in epoch 19, gen_loss = 0.4002551183435652, disc_loss = 0.06286492118611932
Trained batch 225 in epoch 19, gen_loss = 0.40021057268687055, disc_loss = 0.06278225806937347
Trained batch 226 in epoch 19, gen_loss = 0.39990420659208087, disc_loss = 0.06266097553148209
Trained batch 227 in epoch 19, gen_loss = 0.4001960967454994, disc_loss = 0.06259798254662503
Trained batch 228 in epoch 19, gen_loss = 0.40037586504194933, disc_loss = 0.06250019274920421
Trained batch 229 in epoch 19, gen_loss = 0.4004319190979004, disc_loss = 0.062335667105229656
Trained batch 230 in epoch 19, gen_loss = 0.4008787044715056, disc_loss = 0.06213214215560457
Trained batch 231 in epoch 19, gen_loss = 0.40061227437751046, disc_loss = 0.06195835889806842
Trained batch 232 in epoch 19, gen_loss = 0.400726774987233, disc_loss = 0.06175662447846307
Trained batch 233 in epoch 19, gen_loss = 0.40091189436423474, disc_loss = 0.06153316630456501
Trained batch 234 in epoch 19, gen_loss = 0.40088293755308113, disc_loss = 0.061329087902336044
Trained batch 235 in epoch 19, gen_loss = 0.4008556978177216, disc_loss = 0.0611978991182079
Trained batch 236 in epoch 19, gen_loss = 0.4012171499085326, disc_loss = 0.06133124778707382
Trained batch 237 in epoch 19, gen_loss = 0.4010272321580839, disc_loss = 0.06146218001005091
Trained batch 238 in epoch 19, gen_loss = 0.4009812531610912, disc_loss = 0.061382395696580785
Trained batch 239 in epoch 19, gen_loss = 0.40114036152760185, disc_loss = 0.061191394480799015
Trained batch 240 in epoch 19, gen_loss = 0.40139235797264766, disc_loss = 0.06103928101778463
Trained batch 241 in epoch 19, gen_loss = 0.4011088014880488, disc_loss = 0.060953359333182536
Trained batch 242 in epoch 19, gen_loss = 0.4013092433228905, disc_loss = 0.06096664646548437
Trained batch 243 in epoch 19, gen_loss = 0.4012369368164266, disc_loss = 0.061054609278904
Trained batch 244 in epoch 19, gen_loss = 0.40194614359310693, disc_loss = 0.06136825941312982
Trained batch 245 in epoch 19, gen_loss = 0.4023320185459726, disc_loss = 0.06124533990557056
Trained batch 246 in epoch 19, gen_loss = 0.40259206065764797, disc_loss = 0.061110003627007185
Trained batch 247 in epoch 19, gen_loss = 0.4027668934675955, disc_loss = 0.060973308730735296
Trained batch 248 in epoch 19, gen_loss = 0.40292605290929956, disc_loss = 0.06081065676739836
Trained batch 249 in epoch 19, gen_loss = 0.4030172944068909, disc_loss = 0.060629138177260754
Trained batch 250 in epoch 19, gen_loss = 0.4031896929579427, disc_loss = 0.06049576244944061
Trained batch 251 in epoch 19, gen_loss = 0.40338894890414345, disc_loss = 0.060371519426726514
Trained batch 252 in epoch 19, gen_loss = 0.403306085012647, disc_loss = 0.06016804377471093
Trained batch 253 in epoch 19, gen_loss = 0.4035659708141342, disc_loss = 0.05996439045874446
Trained batch 254 in epoch 19, gen_loss = 0.40362281530511146, disc_loss = 0.059792554117373976
Trained batch 255 in epoch 19, gen_loss = 0.403719334397465, disc_loss = 0.0595924384524551
Trained batch 256 in epoch 19, gen_loss = 0.4038881418306076, disc_loss = 0.059541552401861673
Trained batch 257 in epoch 19, gen_loss = 0.4037659321875535, disc_loss = 0.059395275344032536
Trained batch 258 in epoch 19, gen_loss = 0.40369954198944064, disc_loss = 0.0591932601173153
Trained batch 259 in epoch 19, gen_loss = 0.40353827063853925, disc_loss = 0.05914448893521554
Trained batch 260 in epoch 19, gen_loss = 0.4040204243184963, disc_loss = 0.059190660156666436
Trained batch 261 in epoch 19, gen_loss = 0.40419901634445626, disc_loss = 0.05905357077682234
Trained batch 262 in epoch 19, gen_loss = 0.40432951636187475, disc_loss = 0.058880235293363094
Trained batch 263 in epoch 19, gen_loss = 0.40461999121488945, disc_loss = 0.05869494170606644
Trained batch 264 in epoch 19, gen_loss = 0.4045731471394593, disc_loss = 0.05869134955002733
Trained batch 265 in epoch 19, gen_loss = 0.404125606207023, disc_loss = 0.05909015225155517
Trained batch 266 in epoch 19, gen_loss = 0.4041607812995768, disc_loss = 0.059156840138681485
Trained batch 267 in epoch 19, gen_loss = 0.40442285564408376, disc_loss = 0.05897403140934601
Trained batch 268 in epoch 19, gen_loss = 0.4045876891639596, disc_loss = 0.05879186105059259
Trained batch 269 in epoch 19, gen_loss = 0.40450784376374, disc_loss = 0.05863770851003075
Trained batch 270 in epoch 19, gen_loss = 0.4046733841245025, disc_loss = 0.05890508576354692
Trained batch 271 in epoch 19, gen_loss = 0.4041645956390044, disc_loss = 0.05919013487565441
Trained batch 272 in epoch 19, gen_loss = 0.4040828085207677, disc_loss = 0.059042498048040126
Trained batch 273 in epoch 19, gen_loss = 0.4039514559681398, disc_loss = 0.05889580604946581
Trained batch 274 in epoch 19, gen_loss = 0.40385721412571995, disc_loss = 0.058731455848636954
Trained batch 275 in epoch 19, gen_loss = 0.4039864469913469, disc_loss = 0.05862340647423559
Trained batch 276 in epoch 19, gen_loss = 0.40406798627832735, disc_loss = 0.058835568415868476
Trained batch 277 in epoch 19, gen_loss = 0.4038948263410184, disc_loss = 0.05895528251392325
Trained batch 278 in epoch 19, gen_loss = 0.4038509999979354, disc_loss = 0.05879243461441876
Trained batch 279 in epoch 19, gen_loss = 0.4038564663912569, disc_loss = 0.05866280731113095
Trained batch 280 in epoch 19, gen_loss = 0.40378415478506124, disc_loss = 0.058502668102215515
Trained batch 281 in epoch 19, gen_loss = 0.4040148950426291, disc_loss = 0.05842743950552499
Trained batch 282 in epoch 19, gen_loss = 0.4037167879591561, disc_loss = 0.058442105665842445
Trained batch 283 in epoch 19, gen_loss = 0.40394126172636596, disc_loss = 0.05835733902935778
Trained batch 284 in epoch 19, gen_loss = 0.403833243930549, disc_loss = 0.058220188252693206
Trained batch 285 in epoch 19, gen_loss = 0.40364249269445457, disc_loss = 0.058235832377682095
Trained batch 286 in epoch 19, gen_loss = 0.4036738353323853, disc_loss = 0.0584509639436126
Trained batch 287 in epoch 19, gen_loss = 0.40357930430521566, disc_loss = 0.05922318796931197
Trained batch 288 in epoch 19, gen_loss = 0.40388368147467246, disc_loss = 0.05933976009533222
Trained batch 289 in epoch 19, gen_loss = 0.4040301449339965, disc_loss = 0.059249530242884464
Trained batch 290 in epoch 19, gen_loss = 0.4038245633910202, disc_loss = 0.05939145206835415
Trained batch 291 in epoch 19, gen_loss = 0.40409549876843415, disc_loss = 0.05923381517162827
Trained batch 292 in epoch 19, gen_loss = 0.40405094348936765, disc_loss = 0.059167048761958045
Trained batch 293 in epoch 19, gen_loss = 0.404003413051975, disc_loss = 0.05900940916589683
Trained batch 294 in epoch 19, gen_loss = 0.4036610487153975, disc_loss = 0.05914739990859466
Trained batch 295 in epoch 19, gen_loss = 0.4036254522365493, disc_loss = 0.059013092460903666
Trained batch 296 in epoch 19, gen_loss = 0.40365973426035356, disc_loss = 0.058935935736041174
Trained batch 297 in epoch 19, gen_loss = 0.4034139400960615, disc_loss = 0.05892539512984855
Trained batch 298 in epoch 19, gen_loss = 0.4034023270957845, disc_loss = 0.058919858958347886
Trained batch 299 in epoch 19, gen_loss = 0.4031755886475245, disc_loss = 0.0588162084777529
Trained batch 300 in epoch 19, gen_loss = 0.40310616617979006, disc_loss = 0.058671915728871114
Trained batch 301 in epoch 19, gen_loss = 0.40307150317343654, disc_loss = 0.05856609454730045
Trained batch 302 in epoch 19, gen_loss = 0.403053619680625, disc_loss = 0.05847048031461268
Trained batch 303 in epoch 19, gen_loss = 0.402870754564279, disc_loss = 0.05834088647143768
Trained batch 304 in epoch 19, gen_loss = 0.40261093485550803, disc_loss = 0.05822834378474804
Trained batch 305 in epoch 19, gen_loss = 0.4027163088321686, disc_loss = 0.05810770656444814
Trained batch 306 in epoch 19, gen_loss = 0.40252682654011135, disc_loss = 0.05807067835946182
Trained batch 307 in epoch 19, gen_loss = 0.40292509364617335, disc_loss = 0.057915350980149556
Trained batch 308 in epoch 19, gen_loss = 0.40314620791129696, disc_loss = 0.05781609283060945
Trained batch 309 in epoch 19, gen_loss = 0.40308318513055, disc_loss = 0.0578487221767465
Trained batch 310 in epoch 19, gen_loss = 0.40304121509242286, disc_loss = 0.05779141239324806
Trained batch 311 in epoch 19, gen_loss = 0.4032009514287496, disc_loss = 0.057707743147591084
Trained batch 312 in epoch 19, gen_loss = 0.4033186229082723, disc_loss = 0.05755323893316209
Trained batch 313 in epoch 19, gen_loss = 0.40335503752064555, disc_loss = 0.05739824391848105
Trained batch 314 in epoch 19, gen_loss = 0.40335047680234154, disc_loss = 0.057256737932385435
Trained batch 315 in epoch 19, gen_loss = 0.40335411983954755, disc_loss = 0.057140286671457506
Trained batch 316 in epoch 19, gen_loss = 0.4032714058548118, disc_loss = 0.05718689450806107
Trained batch 317 in epoch 19, gen_loss = 0.4034678969743117, disc_loss = 0.057744937909345304
Trained batch 318 in epoch 19, gen_loss = 0.4032136186910647, disc_loss = 0.05827984693941885
Trained batch 319 in epoch 19, gen_loss = 0.40327834729105233, disc_loss = 0.05856811957346508
Trained batch 320 in epoch 19, gen_loss = 0.40348750752080637, disc_loss = 0.05844921600276668
Trained batch 321 in epoch 19, gen_loss = 0.4034551553289342, disc_loss = 0.05833229303550878
Trained batch 322 in epoch 19, gen_loss = 0.40317433694198773, disc_loss = 0.0582435113671971
Trained batch 323 in epoch 19, gen_loss = 0.403427257122081, disc_loss = 0.058107142447333004
Trained batch 324 in epoch 19, gen_loss = 0.40351465481978194, disc_loss = 0.05823724953744274
Trained batch 325 in epoch 19, gen_loss = 0.40341298446699153, disc_loss = 0.05817988104232661
Trained batch 326 in epoch 19, gen_loss = 0.4032380756799599, disc_loss = 0.058294557087658835
Trained batch 327 in epoch 19, gen_loss = 0.4031601768986481, disc_loss = 0.058552181786891616
Trained batch 328 in epoch 19, gen_loss = 0.40304392204820927, disc_loss = 0.0584637335711088
Trained batch 329 in epoch 19, gen_loss = 0.402963727441701, disc_loss = 0.05861371377003238
Trained batch 330 in epoch 19, gen_loss = 0.40289485292492316, disc_loss = 0.05850174095273423
Trained batch 331 in epoch 19, gen_loss = 0.4028485048427639, disc_loss = 0.05844235206611948
Trained batch 332 in epoch 19, gen_loss = 0.4026668205096557, disc_loss = 0.058345820985499536
Trained batch 333 in epoch 19, gen_loss = 0.4027448202857, disc_loss = 0.058224452922990666
Trained batch 334 in epoch 19, gen_loss = 0.40263636788325524, disc_loss = 0.058120133289928315
Trained batch 335 in epoch 19, gen_loss = 0.40268204804687274, disc_loss = 0.05865293601112041
Trained batch 336 in epoch 19, gen_loss = 0.40263325895682994, disc_loss = 0.0589496390051167
Trained batch 337 in epoch 19, gen_loss = 0.40254078161787, disc_loss = 0.05892738935361291
Trained batch 338 in epoch 19, gen_loss = 0.40226464742756174, disc_loss = 0.05896909020231229
Trained batch 339 in epoch 19, gen_loss = 0.40254645943641665, disc_loss = 0.05894245346049395
Trained batch 340 in epoch 19, gen_loss = 0.4020961704404473, disc_loss = 0.05956567354811645
Trained batch 341 in epoch 19, gen_loss = 0.40239636848370236, disc_loss = 0.059753924418970594
Trained batch 342 in epoch 19, gen_loss = 0.40244412209306446, disc_loss = 0.05965866532540574
Trained batch 343 in epoch 19, gen_loss = 0.40245795930021033, disc_loss = 0.059644281881763926
Trained batch 344 in epoch 19, gen_loss = 0.4022717421901399, disc_loss = 0.059557698684596067
Trained batch 345 in epoch 19, gen_loss = 0.4022394924752974, disc_loss = 0.05941835085247681
Trained batch 346 in epoch 19, gen_loss = 0.40226756285349985, disc_loss = 0.05929741099804253
Trained batch 347 in epoch 19, gen_loss = 0.40240915560688095, disc_loss = 0.059256478305103194
Trained batch 348 in epoch 19, gen_loss = 0.4023388600708079, disc_loss = 0.05916231213788633
Trained batch 349 in epoch 19, gen_loss = 0.4021706617304257, disc_loss = 0.059154485183368834
Trained batch 350 in epoch 19, gen_loss = 0.4021912564833959, disc_loss = 0.05908686787213738
Trained batch 351 in epoch 19, gen_loss = 0.4022459856403822, disc_loss = 0.05897111364836085
Trained batch 352 in epoch 19, gen_loss = 0.40221303950456994, disc_loss = 0.05883126604705838
Trained batch 353 in epoch 19, gen_loss = 0.4021237461832957, disc_loss = 0.058733837722437614
Trained batch 354 in epoch 19, gen_loss = 0.4020465949471568, disc_loss = 0.05866223613692211
Trained batch 355 in epoch 19, gen_loss = 0.40204866896017216, disc_loss = 0.05851796464183567
Trained batch 356 in epoch 19, gen_loss = 0.4020612857171467, disc_loss = 0.05845615025792344
Trained batch 357 in epoch 19, gen_loss = 0.40210342453012254, disc_loss = 0.05859909456499004
Trained batch 358 in epoch 19, gen_loss = 0.4022786304728234, disc_loss = 0.05870987259209529
Trained batch 359 in epoch 19, gen_loss = 0.4022925676984919, disc_loss = 0.05859098537023076
Trained batch 360 in epoch 19, gen_loss = 0.4022657867531367, disc_loss = 0.058614069499188924
Trained batch 361 in epoch 19, gen_loss = 0.402450495126827, disc_loss = 0.058489102596231836
Trained batch 362 in epoch 19, gen_loss = 0.40261836900034553, disc_loss = 0.05856643411261607
Trained batch 363 in epoch 19, gen_loss = 0.40228508801741913, disc_loss = 0.05890449778570865
Trained batch 364 in epoch 19, gen_loss = 0.40249457779812486, disc_loss = 0.05913842258566659
Trained batch 365 in epoch 19, gen_loss = 0.40248005706918694, disc_loss = 0.05900356045140391
Trained batch 366 in epoch 19, gen_loss = 0.40231136953311003, disc_loss = 0.058983332971085566
Trained batch 367 in epoch 19, gen_loss = 0.4021415356951563, disc_loss = 0.058887716912937794
Trained batch 368 in epoch 19, gen_loss = 0.4022311090534619, disc_loss = 0.05878041556791521
Trained batch 369 in epoch 19, gen_loss = 0.4023146890707918, disc_loss = 0.05866495030428711
Trained batch 370 in epoch 19, gen_loss = 0.4021197350600338, disc_loss = 0.058684346628829716
Trained batch 371 in epoch 19, gen_loss = 0.4021681624474705, disc_loss = 0.058837543290499
Trained batch 372 in epoch 19, gen_loss = 0.4023974247416606, disc_loss = 0.05887325163855749
Trained batch 373 in epoch 19, gen_loss = 0.40244102035773627, disc_loss = 0.05876220375135103
Trained batch 374 in epoch 19, gen_loss = 0.4024906844695409, disc_loss = 0.058758126525829235
Trained batch 375 in epoch 19, gen_loss = 0.40254436746398187, disc_loss = 0.05862302770912449
Trained batch 376 in epoch 19, gen_loss = 0.40246579331649707, disc_loss = 0.05854342298196821
Trained batch 377 in epoch 19, gen_loss = 0.40231549791085025, disc_loss = 0.05858615625565921
Trained batch 378 in epoch 19, gen_loss = 0.4025254703684658, disc_loss = 0.05846884077670431
Trained batch 379 in epoch 19, gen_loss = 0.4026721919445615, disc_loss = 0.05839786573288668
Trained batch 380 in epoch 19, gen_loss = 0.4027720575961541, disc_loss = 0.05845475168116489
Trained batch 381 in epoch 19, gen_loss = 0.4025526335024085, disc_loss = 0.05853628467266199
Trained batch 382 in epoch 19, gen_loss = 0.40265198246461603, disc_loss = 0.05889081319443901
Trained batch 383 in epoch 19, gen_loss = 0.40268362503654015, disc_loss = 0.05886315857666583
Trained batch 384 in epoch 19, gen_loss = 0.40274339538890047, disc_loss = 0.05876941229156279
Trained batch 385 in epoch 19, gen_loss = 0.4027461504920777, disc_loss = 0.05866367908537272
Trained batch 386 in epoch 19, gen_loss = 0.40269786308132094, disc_loss = 0.05857940586716976
Trained batch 387 in epoch 19, gen_loss = 0.4025774288960953, disc_loss = 0.05847807890692361
Trained batch 388 in epoch 19, gen_loss = 0.40250710361567743, disc_loss = 0.058416766606529835
Trained batch 389 in epoch 19, gen_loss = 0.4024545741768984, disc_loss = 0.05843990150576409
Trained batch 390 in epoch 19, gen_loss = 0.4023385741902739, disc_loss = 0.05844425501139915
Trained batch 391 in epoch 19, gen_loss = 0.40236462861755673, disc_loss = 0.05848375532647823
Trained batch 392 in epoch 19, gen_loss = 0.4025902576346434, disc_loss = 0.05863339341726657
Trained batch 393 in epoch 19, gen_loss = 0.40246231502234026, disc_loss = 0.05887656250075073
Trained batch 394 in epoch 19, gen_loss = 0.4027455965552149, disc_loss = 0.05881385608588027
Trained batch 395 in epoch 19, gen_loss = 0.4027768261730671, disc_loss = 0.058807027024085246
Trained batch 396 in epoch 19, gen_loss = 0.40262280029223607, disc_loss = 0.05869468996038552
Trained batch 397 in epoch 19, gen_loss = 0.40246176588625165, disc_loss = 0.058644944606536076
Trained batch 398 in epoch 19, gen_loss = 0.40255140485171986, disc_loss = 0.05857635918831952
Trained batch 399 in epoch 19, gen_loss = 0.40250230211764576, disc_loss = 0.058505282948026434
Trained batch 400 in epoch 19, gen_loss = 0.402378835917411, disc_loss = 0.05844836972509871
Trained batch 401 in epoch 19, gen_loss = 0.4025319795777549, disc_loss = 0.05835192843887084
Trained batch 402 in epoch 19, gen_loss = 0.4024570525505998, disc_loss = 0.0585289488121331
Trained batch 403 in epoch 19, gen_loss = 0.40232789888978004, disc_loss = 0.05940146781711627
Trained batch 404 in epoch 19, gen_loss = 0.40218417471573675, disc_loss = 0.05958719688272219
Trained batch 405 in epoch 19, gen_loss = 0.4025259972572914, disc_loss = 0.06021120520927966
Trained batch 406 in epoch 19, gen_loss = 0.40236380004326305, disc_loss = 0.06032747622117107
Trained batch 407 in epoch 19, gen_loss = 0.4023758576562007, disc_loss = 0.06029967865655564
Trained batch 408 in epoch 19, gen_loss = 0.4024330326936647, disc_loss = 0.06026908979935613
Trained batch 409 in epoch 19, gen_loss = 0.4024738693019239, disc_loss = 0.060231851355922295
Trained batch 410 in epoch 19, gen_loss = 0.4025015979280147, disc_loss = 0.06018417435211023
Trained batch 411 in epoch 19, gen_loss = 0.40234128353231163, disc_loss = 0.060083779937008995
Trained batch 412 in epoch 19, gen_loss = 0.40230689372768125, disc_loss = 0.06000214675892388
Trained batch 413 in epoch 19, gen_loss = 0.4022796600697121, disc_loss = 0.059898998467971525
Trained batch 414 in epoch 19, gen_loss = 0.40235276943947895, disc_loss = 0.059811868407505464
Trained batch 415 in epoch 19, gen_loss = 0.40224028396635103, disc_loss = 0.05981416219975262
Trained batch 416 in epoch 19, gen_loss = 0.402309646745094, disc_loss = 0.05972841435739641
Trained batch 417 in epoch 19, gen_loss = 0.40226928273028734, disc_loss = 0.059671736149669904
Trained batch 418 in epoch 19, gen_loss = 0.40215169035591775, disc_loss = 0.059634089791093706
Trained batch 419 in epoch 19, gen_loss = 0.4020405116890158, disc_loss = 0.05955870062933259
Trained batch 420 in epoch 19, gen_loss = 0.4021852785575418, disc_loss = 0.05953676528861467
Trained batch 421 in epoch 19, gen_loss = 0.4019399820275216, disc_loss = 0.059468627745126734
Trained batch 422 in epoch 19, gen_loss = 0.4018623679171781, disc_loss = 0.0594042911343981
Trained batch 423 in epoch 19, gen_loss = 0.4019758285568008, disc_loss = 0.05928670844603506
Trained batch 424 in epoch 19, gen_loss = 0.4021439828942804, disc_loss = 0.05920578759273185
Trained batch 425 in epoch 19, gen_loss = 0.4021536557117538, disc_loss = 0.05914164829382699
Trained batch 426 in epoch 19, gen_loss = 0.4021896769835742, disc_loss = 0.05913657150547559
Trained batch 427 in epoch 19, gen_loss = 0.40233167041545714, disc_loss = 0.05920131300754462
Trained batch 428 in epoch 19, gen_loss = 0.4024072751090243, disc_loss = 0.05916697175799932
Trained batch 429 in epoch 19, gen_loss = 0.40239549241093703, disc_loss = 0.059168115014556884
Trained batch 430 in epoch 19, gen_loss = 0.4023096067377144, disc_loss = 0.059154191167847946
Trained batch 431 in epoch 19, gen_loss = 0.4024490661988104, disc_loss = 0.05903505095543719
Trained batch 432 in epoch 19, gen_loss = 0.4025758593310935, disc_loss = 0.05891584395592297
Trained batch 433 in epoch 19, gen_loss = 0.40251799302029717, disc_loss = 0.058932942184855654
Trained batch 434 in epoch 19, gen_loss = 0.40235110531593193, disc_loss = 0.05966079749445292
Trained batch 435 in epoch 19, gen_loss = 0.40266348472839103, disc_loss = 0.059874982911657645
Trained batch 436 in epoch 19, gen_loss = 0.40285668612481257, disc_loss = 0.05984261564300896
Trained batch 437 in epoch 19, gen_loss = 0.40259430210476055, disc_loss = 0.059788902988657355
Trained batch 438 in epoch 19, gen_loss = 0.40245219430374934, disc_loss = 0.05990325085551463
Trained batch 439 in epoch 19, gen_loss = 0.4026207336986607, disc_loss = 0.06004185556031933
Trained batch 440 in epoch 19, gen_loss = 0.40267422994653657, disc_loss = 0.05995727292538669
Trained batch 441 in epoch 19, gen_loss = 0.4025277691256946, disc_loss = 0.060154777720814984
Trained batch 442 in epoch 19, gen_loss = 0.40248248448624835, disc_loss = 0.06043998201737184
Trained batch 443 in epoch 19, gen_loss = 0.4022583306037091, disc_loss = 0.060422400877861354
Trained batch 444 in epoch 19, gen_loss = 0.402202672603425, disc_loss = 0.060333416193430675
Trained batch 445 in epoch 19, gen_loss = 0.4020043482227176, disc_loss = 0.06023701332664042
Trained batch 446 in epoch 19, gen_loss = 0.4019879224383058, disc_loss = 0.060143314882221174
Trained batch 447 in epoch 19, gen_loss = 0.4019265743970339, disc_loss = 0.060053574358919705
Trained batch 448 in epoch 19, gen_loss = 0.4020223152597657, disc_loss = 0.06023743676171039
Trained batch 449 in epoch 19, gen_loss = 0.40185240344868767, disc_loss = 0.060683150495299036
Trained batch 450 in epoch 19, gen_loss = 0.4019100492584732, disc_loss = 0.06066974329797266
Trained batch 451 in epoch 19, gen_loss = 0.4019496517041616, disc_loss = 0.060741310738299074
Trained batch 452 in epoch 19, gen_loss = 0.4019812255045173, disc_loss = 0.060695790664126344
Trained batch 453 in epoch 19, gen_loss = 0.40175837347292165, disc_loss = 0.06063361625630195
Trained batch 454 in epoch 19, gen_loss = 0.4015225932820813, disc_loss = 0.06053494552846302
Trained batch 455 in epoch 19, gen_loss = 0.40138820424806654, disc_loss = 0.06045373551764019
Trained batch 456 in epoch 19, gen_loss = 0.4014125418415216, disc_loss = 0.060387830603541706
Trained batch 457 in epoch 19, gen_loss = 0.4015382069232162, disc_loss = 0.060362528978062054
Trained batch 458 in epoch 19, gen_loss = 0.4016616585662422, disc_loss = 0.06032479113000313
Testing Epoch 19
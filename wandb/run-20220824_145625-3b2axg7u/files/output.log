/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5904686450958252, disc_loss = 0.8417850732803345
Trained batch 1 in epoch 0, gen_loss = 0.5434458404779434, disc_loss = 0.7247096300125122
Trained batch 2 in epoch 0, gen_loss = 0.5185314416885376, disc_loss = 0.6227433085441589
Trained batch 3 in epoch 0, gen_loss = 0.49594566971063614, disc_loss = 0.5442519634962082
Trained batch 4 in epoch 0, gen_loss = 0.48719149827957153, disc_loss = 0.4829296410083771
Trained batch 5 in epoch 0, gen_loss = 0.46679141124089557, disc_loss = 0.4410114338000615
Trained batch 6 in epoch 0, gen_loss = 0.45709049701690674, disc_loss = 0.4352256953716278
Trained batch 7 in epoch 0, gen_loss = 0.4663943275809288, disc_loss = 0.40269113704562187
Trained batch 8 in epoch 0, gen_loss = 0.47017647822697956, disc_loss = 0.37516938481065965
Trained batch 9 in epoch 0, gen_loss = 0.46495274603366854, disc_loss = 0.3504141613841057
Trained batch 10 in epoch 0, gen_loss = 0.46562042561444367, disc_loss = 0.33108179000290955
Trained batch 11 in epoch 0, gen_loss = 0.4591437379519145, disc_loss = 0.31104799918830395
Trained batch 12 in epoch 0, gen_loss = 0.4513751222537114, disc_loss = 0.29256380005524707
Trained batch 13 in epoch 0, gen_loss = 0.44751346324171337, disc_loss = 0.27890461470399586
Trained batch 14 in epoch 0, gen_loss = 0.450126588344574, disc_loss = 0.2689077277978261
Trained batch 15 in epoch 0, gen_loss = 0.45115922950208187, disc_loss = 0.2582316119223833
Trained batch 16 in epoch 0, gen_loss = 0.4513131467735066, disc_loss = 0.249143767006257
Trained batch 17 in epoch 0, gen_loss = 0.4519878774881363, disc_loss = 0.24036465171310636
Trained batch 18 in epoch 0, gen_loss = 0.4503697219647859, disc_loss = 0.2325759592809175
Trained batch 19 in epoch 0, gen_loss = 0.4528993606567383, disc_loss = 0.22667981423437594
Trained batch 20 in epoch 0, gen_loss = 0.4537583915960221, disc_loss = 0.225350378879479
Trained batch 21 in epoch 0, gen_loss = 0.45874674076383765, disc_loss = 0.22449064695022322
Trained batch 22 in epoch 0, gen_loss = 0.45819064197332965, disc_loss = 0.22634259157854578
Trained batch 23 in epoch 0, gen_loss = 0.462602944423755, disc_loss = 0.22881808783859015
Trained batch 24 in epoch 0, gen_loss = 0.4629754662513733, disc_loss = 0.2287389412522316
Trained batch 25 in epoch 0, gen_loss = 0.4599450585933832, disc_loss = 0.23442994086788252
Trained batch 26 in epoch 0, gen_loss = 0.46069039680339674, disc_loss = 0.2411097721369178
Trained batch 27 in epoch 0, gen_loss = 0.4633457767111914, disc_loss = 0.24005380139819213
Trained batch 28 in epoch 0, gen_loss = 0.46377062180946615, disc_loss = 0.23478966925678582
Trained batch 29 in epoch 0, gen_loss = 0.46380347907543185, disc_loss = 0.23063084507981937
Trained batch 30 in epoch 0, gen_loss = 0.4626300921363215, disc_loss = 0.2261436497492175
Trained batch 31 in epoch 0, gen_loss = 0.46048498433083296, disc_loss = 0.22247411566786468
Trained batch 32 in epoch 0, gen_loss = 0.45956052794600977, disc_loss = 0.2264054027019125
Trained batch 33 in epoch 0, gen_loss = 0.4607965876074398, disc_loss = 0.23346538469195366
Trained batch 34 in epoch 0, gen_loss = 0.45942051751273016, disc_loss = 0.23043926124061856
Trained batch 35 in epoch 0, gen_loss = 0.456658902267615, disc_loss = 0.22896491342948544
Trained batch 36 in epoch 0, gen_loss = 0.45609657587231817, disc_loss = 0.2248382175693641
Trained batch 37 in epoch 0, gen_loss = 0.4566873131613982, disc_loss = 0.22036632964093433
Trained batch 38 in epoch 0, gen_loss = 0.45669160057336855, disc_loss = 0.2161883835036021
Trained batch 39 in epoch 0, gen_loss = 0.45612456649541855, disc_loss = 0.21185466991737484
Trained batch 40 in epoch 0, gen_loss = 0.4567335662318439, disc_loss = 0.208312334538233
Trained batch 41 in epoch 0, gen_loss = 0.4591533179794039, disc_loss = 0.20590373935798803
Trained batch 42 in epoch 0, gen_loss = 0.4591257773166479, disc_loss = 0.20262645540195842
Trained batch 43 in epoch 0, gen_loss = 0.4589462246407162, disc_loss = 0.1989882985468615
Trained batch 44 in epoch 0, gen_loss = 0.4577826586034563, disc_loss = 0.19548849927054512
Trained batch 45 in epoch 0, gen_loss = 0.4574037744947102, disc_loss = 0.19296075128342793
Trained batch 46 in epoch 0, gen_loss = 0.4570833552390971, disc_loss = 0.19059312042403728
Trained batch 47 in epoch 0, gen_loss = 0.4565103631466627, disc_loss = 0.19036093556011716
Trained batch 48 in epoch 0, gen_loss = 0.4584257645266397, disc_loss = 0.18983343441267403
Trained batch 49 in epoch 0, gen_loss = 0.4574032312631607, disc_loss = 0.18842889577150346
Trained batch 50 in epoch 0, gen_loss = 0.45578157901763916, disc_loss = 0.1931459924169615
Trained batch 51 in epoch 0, gen_loss = 0.4558568980831366, disc_loss = 0.19168379730903184
Trained batch 52 in epoch 0, gen_loss = 0.45715054869651794, disc_loss = 0.19436696958991717
Trained batch 53 in epoch 0, gen_loss = 0.4558885919827002, disc_loss = 0.19343995578863002
Trained batch 54 in epoch 0, gen_loss = 0.45350829904729667, disc_loss = 0.19404969757253474
Trained batch 55 in epoch 0, gen_loss = 0.4519623778760433, disc_loss = 0.19235170419727052
Trained batch 56 in epoch 0, gen_loss = 0.45112934551740946, disc_loss = 0.19069918245077133
Trained batch 57 in epoch 0, gen_loss = 0.45111119490245294, disc_loss = 0.18920084602873902
Trained batch 58 in epoch 0, gen_loss = 0.45084025597168226, disc_loss = 0.18801312855744767
Trained batch 59 in epoch 0, gen_loss = 0.44930468847354255, disc_loss = 0.1861413908501466
Trained batch 60 in epoch 0, gen_loss = 0.4476624942216717, disc_loss = 0.18599928158228515
Trained batch 61 in epoch 0, gen_loss = 0.4482913661387659, disc_loss = 0.18384051479158864
Trained batch 62 in epoch 0, gen_loss = 0.4491973330104162, disc_loss = 0.18481236353280053
Trained batch 63 in epoch 0, gen_loss = 0.4479445917531848, disc_loss = 0.18401544133666903
Trained batch 64 in epoch 0, gen_loss = 0.4465897826048044, disc_loss = 0.19293006349068423
Trained batch 65 in epoch 0, gen_loss = 0.44659250929500116, disc_loss = 0.1949431116156506
Trained batch 66 in epoch 0, gen_loss = 0.4466644997027383, disc_loss = 0.19481129688558294
Trained batch 67 in epoch 0, gen_loss = 0.4469207691795686, disc_loss = 0.1948289482251686
Trained batch 68 in epoch 0, gen_loss = 0.44611443600792816, disc_loss = 0.19436801462501718
Trained batch 69 in epoch 0, gen_loss = 0.4446901789733342, disc_loss = 0.19368262769920486
Trained batch 70 in epoch 0, gen_loss = 0.4453265259803181, disc_loss = 0.19322101383561818
Trained batch 71 in epoch 0, gen_loss = 0.4454931856857406, disc_loss = 0.1926829269569781
Trained batch 72 in epoch 0, gen_loss = 0.44608276265941255, disc_loss = 0.19266974364649758
Trained batch 73 in epoch 0, gen_loss = 0.44555953346394206, disc_loss = 0.19217982777469866
Trained batch 74 in epoch 0, gen_loss = 0.4452315167586009, disc_loss = 0.19131148705879847
Trained batch 75 in epoch 0, gen_loss = 0.44482021739608363, disc_loss = 0.19112321940299712
Trained batch 76 in epoch 0, gen_loss = 0.4452555508582623, disc_loss = 0.19041227781540387
Trained batch 77 in epoch 0, gen_loss = 0.4455115497112274, disc_loss = 0.19020034210422102
Trained batch 78 in epoch 0, gen_loss = 0.44450380266467227, disc_loss = 0.19131620464068425
Trained batch 79 in epoch 0, gen_loss = 0.4447535663843155, disc_loss = 0.191860977653414
Trained batch 80 in epoch 0, gen_loss = 0.44454053081112144, disc_loss = 0.19289361152016085
Trained batch 81 in epoch 0, gen_loss = 0.4449238366470104, disc_loss = 0.19289197454728732
Trained batch 82 in epoch 0, gen_loss = 0.4446684028728899, disc_loss = 0.19267853044242744
Trained batch 83 in epoch 0, gen_loss = 0.44425938313915614, disc_loss = 0.19192094488867692
Trained batch 84 in epoch 0, gen_loss = 0.44433554516119117, disc_loss = 0.19257982925457112
Trained batch 85 in epoch 0, gen_loss = 0.44517654423103775, disc_loss = 0.19338231923621754
Trained batch 86 in epoch 0, gen_loss = 0.44437894601931516, disc_loss = 0.1929119091438151
Trained batch 87 in epoch 0, gen_loss = 0.4432046796110543, disc_loss = 0.1941728929735043
Trained batch 88 in epoch 0, gen_loss = 0.4436192324991976, disc_loss = 0.19331476234653022
Trained batch 89 in epoch 0, gen_loss = 0.44405130975776247, disc_loss = 0.19452837415867383
Trained batch 90 in epoch 0, gen_loss = 0.44343889283609916, disc_loss = 0.1967762883056651
Trained batch 91 in epoch 0, gen_loss = 0.4427094789950744, disc_loss = 0.19708377649278744
Trained batch 92 in epoch 0, gen_loss = 0.4431720318332795, disc_loss = 0.19672000159819922
Trained batch 93 in epoch 0, gen_loss = 0.44290391181377653, disc_loss = 0.19680527970194817
Trained batch 94 in epoch 0, gen_loss = 0.44239292772192707, disc_loss = 0.19677108926208395
Trained batch 95 in epoch 0, gen_loss = 0.4430693543205659, disc_loss = 0.19672437749492624
Trained batch 96 in epoch 0, gen_loss = 0.443028781831879, disc_loss = 0.19819970866761258
Trained batch 97 in epoch 0, gen_loss = 0.44225803443363737, disc_loss = 0.19829143560966667
Trained batch 98 in epoch 0, gen_loss = 0.44208279854119426, disc_loss = 0.19880990842075058
Trained batch 99 in epoch 0, gen_loss = 0.4418152341246605, disc_loss = 0.1992605524510145
Trained batch 100 in epoch 0, gen_loss = 0.44118325131954533, disc_loss = 0.19891187541260577
Trained batch 101 in epoch 0, gen_loss = 0.4410978649176803, disc_loss = 0.19875354078762672
Trained batch 102 in epoch 0, gen_loss = 0.4414719088563641, disc_loss = 0.19827985524841882
Trained batch 103 in epoch 0, gen_loss = 0.4406318716131724, disc_loss = 0.1980544446895902
Trained batch 104 in epoch 0, gen_loss = 0.43982944374992733, disc_loss = 0.19874298239038105
Trained batch 105 in epoch 0, gen_loss = 0.43967213917453335, disc_loss = 0.19809989272704664
Trained batch 106 in epoch 0, gen_loss = 0.43929740591583966, disc_loss = 0.19745025352061352
Trained batch 107 in epoch 0, gen_loss = 0.43899932144968595, disc_loss = 0.19776680161831556
Trained batch 108 in epoch 0, gen_loss = 0.43859940247798185, disc_loss = 0.19962444416153322
Trained batch 109 in epoch 0, gen_loss = 0.43921878906813533, disc_loss = 0.19986035532572052
Trained batch 110 in epoch 0, gen_loss = 0.4393953863564912, disc_loss = 0.20062984116711058
Trained batch 111 in epoch 0, gen_loss = 0.439965554113899, disc_loss = 0.2009932553794767
Trained batch 112 in epoch 0, gen_loss = 0.43919000636159844, disc_loss = 0.20114035001107022
Trained batch 113 in epoch 0, gen_loss = 0.43819380773786915, disc_loss = 0.20130902561440803
Trained batch 114 in epoch 0, gen_loss = 0.43800306294275365, disc_loss = 0.20160409542529478
Trained batch 115 in epoch 0, gen_loss = 0.4375759209024495, disc_loss = 0.2017323482010899
Trained batch 116 in epoch 0, gen_loss = 0.4365227395652706, disc_loss = 0.20264413920987365
Trained batch 117 in epoch 0, gen_loss = 0.4359879354804249, disc_loss = 0.20457395627084424
Trained batch 118 in epoch 0, gen_loss = 0.43621561256777336, disc_loss = 0.20522615006741354
Trained batch 119 in epoch 0, gen_loss = 0.4357042816778024, disc_loss = 0.2057181111847361
Trained batch 120 in epoch 0, gen_loss = 0.436097812800368, disc_loss = 0.20600434171020493
Trained batch 121 in epoch 0, gen_loss = 0.4355275567437782, disc_loss = 0.2065797652743879
Trained batch 122 in epoch 0, gen_loss = 0.43502609928448993, disc_loss = 0.20687842120726904
Trained batch 123 in epoch 0, gen_loss = 0.43419705139052484, disc_loss = 0.2071713137650682
Trained batch 124 in epoch 0, gen_loss = 0.4340331799983978, disc_loss = 0.20707077604532242
Trained batch 125 in epoch 0, gen_loss = 0.4339253393903611, disc_loss = 0.20699936961607326
Trained batch 126 in epoch 0, gen_loss = 0.43417221941347195, disc_loss = 0.2069793154052862
Trained batch 127 in epoch 0, gen_loss = 0.4333050961140543, disc_loss = 0.20726666477276012
Trained batch 128 in epoch 0, gen_loss = 0.4328928296418153, disc_loss = 0.20772934231416199
Trained batch 129 in epoch 0, gen_loss = 0.43272237892334275, disc_loss = 0.2079295199077863
Trained batch 130 in epoch 0, gen_loss = 0.4324252232340456, disc_loss = 0.20799450320369414
Trained batch 131 in epoch 0, gen_loss = 0.43186412864562235, disc_loss = 0.20808181533533515
Trained batch 132 in epoch 0, gen_loss = 0.43187764914412247, disc_loss = 0.208615675064406
Trained batch 133 in epoch 0, gen_loss = 0.4318772776802974, disc_loss = 0.20871474332551457
Trained batch 134 in epoch 0, gen_loss = 0.4315584988505752, disc_loss = 0.20882973742705804
Trained batch 135 in epoch 0, gen_loss = 0.4312232910271953, disc_loss = 0.2089410970425781
Trained batch 136 in epoch 0, gen_loss = 0.43058756341899396, disc_loss = 0.20906875195511937
Trained batch 137 in epoch 0, gen_loss = 0.4302285080370696, disc_loss = 0.2093007005751133
Trained batch 138 in epoch 0, gen_loss = 0.4302891076897546, disc_loss = 0.20936335414219245
Trained batch 139 in epoch 0, gen_loss = 0.4298035955854825, disc_loss = 0.20953583073403154
Trained batch 140 in epoch 0, gen_loss = 0.429505023127752, disc_loss = 0.20982780709122936
Trained batch 141 in epoch 0, gen_loss = 0.42934178697391295, disc_loss = 0.2100055254995823
Trained batch 142 in epoch 0, gen_loss = 0.42932982357231886, disc_loss = 0.21007728842380163
Trained batch 143 in epoch 0, gen_loss = 0.42899921391573215, disc_loss = 0.21021336591285136
Trained batch 144 in epoch 0, gen_loss = 0.42809596822179596, disc_loss = 0.21076826787200467
Trained batch 145 in epoch 0, gen_loss = 0.4278097538507148, disc_loss = 0.21087682262471277
Trained batch 146 in epoch 0, gen_loss = 0.42807241747168456, disc_loss = 0.21096934707594567
Trained batch 147 in epoch 0, gen_loss = 0.4285980976513914, disc_loss = 0.211093870520189
Trained batch 148 in epoch 0, gen_loss = 0.42824963975272723, disc_loss = 0.2115344410674684
Trained batch 149 in epoch 0, gen_loss = 0.42796931803226473, disc_loss = 0.21190568084518116
Trained batch 150 in epoch 0, gen_loss = 0.4277338571106361, disc_loss = 0.2119289245333103
Trained batch 151 in epoch 0, gen_loss = 0.42759090387507487, disc_loss = 0.21209116588885846
Trained batch 152 in epoch 0, gen_loss = 0.4273608611300101, disc_loss = 0.21236230476814158
Trained batch 153 in epoch 0, gen_loss = 0.42675352309431347, disc_loss = 0.21268775570508722
Trained batch 154 in epoch 0, gen_loss = 0.42649635114977436, disc_loss = 0.21285481265475673
Trained batch 155 in epoch 0, gen_loss = 0.42601175415210235, disc_loss = 0.21305399278226572
Trained batch 156 in epoch 0, gen_loss = 0.42533806478901276, disc_loss = 0.2131268160453268
Trained batch 157 in epoch 0, gen_loss = 0.42489440343048, disc_loss = 0.21318438069163997
Trained batch 158 in epoch 0, gen_loss = 0.4248371330447167, disc_loss = 0.2131823924071384
Trained batch 159 in epoch 0, gen_loss = 0.424618018604815, disc_loss = 0.2131520674098283
Trained batch 160 in epoch 0, gen_loss = 0.42383378503485497, disc_loss = 0.21326055349955647
Trained batch 161 in epoch 0, gen_loss = 0.42357971841170466, disc_loss = 0.21359766141316036
Trained batch 162 in epoch 0, gen_loss = 0.42381144794949727, disc_loss = 0.2135141372589246
Trained batch 163 in epoch 0, gen_loss = 0.42376560608788233, disc_loss = 0.21341660705099746
Trained batch 164 in epoch 0, gen_loss = 0.4230920737439936, disc_loss = 0.21347023370591076
Trained batch 165 in epoch 0, gen_loss = 0.42287498927978145, disc_loss = 0.21357189509344388
Trained batch 166 in epoch 0, gen_loss = 0.4230092473015814, disc_loss = 0.21348880003847762
Trained batch 167 in epoch 0, gen_loss = 0.4230289390044553, disc_loss = 0.21343615673305022
Trained batch 168 in epoch 0, gen_loss = 0.422977981130047, disc_loss = 0.21337015605008108
Trained batch 169 in epoch 0, gen_loss = 0.4225883061394972, disc_loss = 0.2134693703668959
Trained batch 170 in epoch 0, gen_loss = 0.4222726271166439, disc_loss = 0.21362236477652488
Trained batch 171 in epoch 0, gen_loss = 0.42211799202270284, disc_loss = 0.21370997613425866
Trained batch 172 in epoch 0, gen_loss = 0.4219247202652727, disc_loss = 0.21434193371520566
Trained batch 173 in epoch 0, gen_loss = 0.4217128541277743, disc_loss = 0.2145972322544147
Trained batch 174 in epoch 0, gen_loss = 0.420940306867872, disc_loss = 0.21476839819124766
Trained batch 175 in epoch 0, gen_loss = 0.42039736512709747, disc_loss = 0.21477278512479228
Trained batch 176 in epoch 0, gen_loss = 0.41981260352215527, disc_loss = 0.21501145949639844
Trained batch 177 in epoch 0, gen_loss = 0.4190738216209947, disc_loss = 0.2151251754650239
Trained batch 178 in epoch 0, gen_loss = 0.4190914685832722, disc_loss = 0.21531650877698175
Trained batch 179 in epoch 0, gen_loss = 0.4188840231961674, disc_loss = 0.2153999377042055
Trained batch 180 in epoch 0, gen_loss = 0.4189310452556083, disc_loss = 0.21544003647170673
Trained batch 181 in epoch 0, gen_loss = 0.4187024514098744, disc_loss = 0.21542522061493372
Trained batch 182 in epoch 0, gen_loss = 0.41816499519869277, disc_loss = 0.21544986047217105
Trained batch 183 in epoch 0, gen_loss = 0.4178752811706584, disc_loss = 0.2154833900782725
Trained batch 184 in epoch 0, gen_loss = 0.4174897912386301, disc_loss = 0.21530342597413707
Trained batch 185 in epoch 0, gen_loss = 0.41708465321089633, disc_loss = 0.21526290872885334
Trained batch 186 in epoch 0, gen_loss = 0.41656220740175504, disc_loss = 0.21525841907543294
Trained batch 187 in epoch 0, gen_loss = 0.4164636943568575, disc_loss = 0.2151396733094403
Trained batch 188 in epoch 0, gen_loss = 0.415995650190525, disc_loss = 0.21513031876434094
Trained batch 189 in epoch 0, gen_loss = 0.4161967275958312, disc_loss = 0.2154537304843727
Trained batch 190 in epoch 0, gen_loss = 0.4162109016747999, disc_loss = 0.21594905311056456
Trained batch 191 in epoch 0, gen_loss = 0.4160056033482154, disc_loss = 0.21629884377277145
Trained batch 192 in epoch 0, gen_loss = 0.4158115674176982, disc_loss = 0.21640614196272093
Trained batch 193 in epoch 0, gen_loss = 0.41548306395098106, disc_loss = 0.21649001488826938
Trained batch 194 in epoch 0, gen_loss = 0.41524650836602234, disc_loss = 0.21646547313684072
Trained batch 195 in epoch 0, gen_loss = 0.4151036400271922, disc_loss = 0.21636868773826531
Trained batch 196 in epoch 0, gen_loss = 0.4149843204747602, disc_loss = 0.21639881048559537
Trained batch 197 in epoch 0, gen_loss = 0.4142254323068291, disc_loss = 0.21636072489799876
Trained batch 198 in epoch 0, gen_loss = 0.41426863697305993, disc_loss = 0.21704020478467845
Trained batch 199 in epoch 0, gen_loss = 0.4141272781789303, disc_loss = 0.21721475090831519
Trained batch 200 in epoch 0, gen_loss = 0.41406241993405923, disc_loss = 0.21729172006323563
Trained batch 201 in epoch 0, gen_loss = 0.41395739738893983, disc_loss = 0.21732672403501993
Trained batch 202 in epoch 0, gen_loss = 0.41360465426163134, disc_loss = 0.21729185828581232
Trained batch 203 in epoch 0, gen_loss = 0.41317476653585244, disc_loss = 0.21747739543663522
Trained batch 204 in epoch 0, gen_loss = 0.4126153429833854, disc_loss = 0.21737630247342876
Trained batch 205 in epoch 0, gen_loss = 0.4123640582688804, disc_loss = 0.21731441392047893
Trained batch 206 in epoch 0, gen_loss = 0.41202975240882467, disc_loss = 0.21721286290653663
Trained batch 207 in epoch 0, gen_loss = 0.41176085804517454, disc_loss = 0.21733590562899524
Trained batch 208 in epoch 0, gen_loss = 0.41156994754617865, disc_loss = 0.21725251547029714
Trained batch 209 in epoch 0, gen_loss = 0.41131778089773086, disc_loss = 0.21717681100680714
Trained batch 210 in epoch 0, gen_loss = 0.410710889298769, disc_loss = 0.21720011931318808
Trained batch 211 in epoch 0, gen_loss = 0.41029671354676195, disc_loss = 0.21778216111069582
Trained batch 212 in epoch 0, gen_loss = 0.4100866407295908, disc_loss = 0.21789033014869466
Trained batch 213 in epoch 0, gen_loss = 0.4097742663922711, disc_loss = 0.2180315459094872
Trained batch 214 in epoch 0, gen_loss = 0.4094581771728604, disc_loss = 0.21797647320253905
Trained batch 215 in epoch 0, gen_loss = 0.4090242022993388, disc_loss = 0.21805135722927474
Trained batch 216 in epoch 0, gen_loss = 0.40911601820299703, disc_loss = 0.21835943627330015
Trained batch 217 in epoch 0, gen_loss = 0.4088701378861698, disc_loss = 0.21832964846163716
Trained batch 218 in epoch 0, gen_loss = 0.4083468594235372, disc_loss = 0.2182741397523989
Trained batch 219 in epoch 0, gen_loss = 0.40842343893918126, disc_loss = 0.21818388642912562
Trained batch 220 in epoch 0, gen_loss = 0.40817962688018833, disc_loss = 0.21814456976511898
Trained batch 221 in epoch 0, gen_loss = 0.40794987949702116, disc_loss = 0.21815312032898268
Trained batch 222 in epoch 0, gen_loss = 0.4077430283274886, disc_loss = 0.21812375394351813
Trained batch 223 in epoch 0, gen_loss = 0.40745124513549463, disc_loss = 0.21813620796560176
Trained batch 224 in epoch 0, gen_loss = 0.4073080599308014, disc_loss = 0.2181188483701812
Trained batch 225 in epoch 0, gen_loss = 0.4071773389535668, disc_loss = 0.21803730716351913
Trained batch 226 in epoch 0, gen_loss = 0.40693645881661233, disc_loss = 0.21790417060584225
Trained batch 227 in epoch 0, gen_loss = 0.4067134917305227, disc_loss = 0.21794017100412594
Trained batch 228 in epoch 0, gen_loss = 0.4064805049563079, disc_loss = 0.21806335107598243
Trained batch 229 in epoch 0, gen_loss = 0.40634794623955434, disc_loss = 0.21827441748717558
Trained batch 230 in epoch 0, gen_loss = 0.405958959034511, disc_loss = 0.21839554011176676
Trained batch 231 in epoch 0, gen_loss = 0.40583308413624763, disc_loss = 0.21833345155906062
Trained batch 232 in epoch 0, gen_loss = 0.40582907251022404, disc_loss = 0.21829445867963104
Trained batch 233 in epoch 0, gen_loss = 0.40583133200804394, disc_loss = 0.21817395610050258
Trained batch 234 in epoch 0, gen_loss = 0.40556591000962766, disc_loss = 0.21812031595630849
Trained batch 235 in epoch 0, gen_loss = 0.40514679139448423, disc_loss = 0.21819523055800946
Trained batch 236 in epoch 0, gen_loss = 0.40554417977856183, disc_loss = 0.2179888251398686
Trained batch 237 in epoch 0, gen_loss = 0.40523613350731985, disc_loss = 0.2180657140409746
Trained batch 238 in epoch 0, gen_loss = 0.4051338855691535, disc_loss = 0.21867297437026412
Trained batch 239 in epoch 0, gen_loss = 0.4048914682120085, disc_loss = 0.21869848733767866
Trained batch 240 in epoch 0, gen_loss = 0.40476790812500285, disc_loss = 0.21877118478301155
Trained batch 241 in epoch 0, gen_loss = 0.40450842333726644, disc_loss = 0.2188649364431535
Trained batch 242 in epoch 0, gen_loss = 0.4041772963088236, disc_loss = 0.21889890322592032
Trained batch 243 in epoch 0, gen_loss = 0.4040699987137904, disc_loss = 0.21891942830970051
Trained batch 244 in epoch 0, gen_loss = 0.40407156263078964, disc_loss = 0.21894018981529742
Trained batch 245 in epoch 0, gen_loss = 0.403988077146251, disc_loss = 0.21883510262137507
Trained batch 246 in epoch 0, gen_loss = 0.4036270188175232, disc_loss = 0.2186996598053075
Trained batch 247 in epoch 0, gen_loss = 0.40352541196250147, disc_loss = 0.2187421981906218
Trained batch 248 in epoch 0, gen_loss = 0.40351470335420353, disc_loss = 0.21876988314600834
Trained batch 249 in epoch 0, gen_loss = 0.4036201951503754, disc_loss = 0.21911142870783806
Trained batch 250 in epoch 0, gen_loss = 0.4034732499445577, disc_loss = 0.21896488468841727
Trained batch 251 in epoch 0, gen_loss = 0.40323295408771154, disc_loss = 0.21898853291003478
Trained batch 252 in epoch 0, gen_loss = 0.40314726796546, disc_loss = 0.21899815265958017
Trained batch 253 in epoch 0, gen_loss = 0.4027275815019457, disc_loss = 0.2189955717524675
Trained batch 254 in epoch 0, gen_loss = 0.4027367794046215, disc_loss = 0.21900148622545543
Trained batch 255 in epoch 0, gen_loss = 0.4029586842516437, disc_loss = 0.21902191927074455
Trained batch 256 in epoch 0, gen_loss = 0.40269354739541674, disc_loss = 0.2192305980199506
Trained batch 257 in epoch 0, gen_loss = 0.40244643517242845, disc_loss = 0.21912893297713856
Trained batch 258 in epoch 0, gen_loss = 0.40249553702512764, disc_loss = 0.21906921304906196
Trained batch 259 in epoch 0, gen_loss = 0.4023291430794276, disc_loss = 0.219076456158207
Trained batch 260 in epoch 0, gen_loss = 0.4020850810282989, disc_loss = 0.21894188553551605
Trained batch 261 in epoch 0, gen_loss = 0.40207428911715065, disc_loss = 0.21913156337069192
Trained batch 262 in epoch 0, gen_loss = 0.40202948235740227, disc_loss = 0.21954268457885023
Trained batch 263 in epoch 0, gen_loss = 0.40178111624537094, disc_loss = 0.21998425022783605
Trained batch 264 in epoch 0, gen_loss = 0.4017270084821953, disc_loss = 0.22007053755926637
Trained batch 265 in epoch 0, gen_loss = 0.4016448854279697, disc_loss = 0.220068125264313
Trained batch 266 in epoch 0, gen_loss = 0.40141165836920006, disc_loss = 0.22007560928104522
Trained batch 267 in epoch 0, gen_loss = 0.40120984891902156, disc_loss = 0.2200773076168192
Trained batch 268 in epoch 0, gen_loss = 0.40102049686208535, disc_loss = 0.21997209499870535
Trained batch 269 in epoch 0, gen_loss = 0.40081897764294233, disc_loss = 0.22000097756584486
Trained batch 270 in epoch 0, gen_loss = 0.4002946801071237, disc_loss = 0.22006088465012308
Trained batch 271 in epoch 0, gen_loss = 0.39999028306235285, disc_loss = 0.21998010956517913
Trained batch 272 in epoch 0, gen_loss = 0.3996146302738469, disc_loss = 0.21991619645130067
Trained batch 273 in epoch 0, gen_loss = 0.3996759826031915, disc_loss = 0.2199239451574148
Trained batch 274 in epoch 0, gen_loss = 0.3996622028134086, disc_loss = 0.21977511446584355
Trained batch 275 in epoch 0, gen_loss = 0.39965980046469235, disc_loss = 0.2195857070872317
Trained batch 276 in epoch 0, gen_loss = 0.3996192816147305, disc_loss = 0.21956186375785822
Trained batch 277 in epoch 0, gen_loss = 0.39963923823490416, disc_loss = 0.21949540285004987
Trained batch 278 in epoch 0, gen_loss = 0.39922875080484643, disc_loss = 0.2197000808666684
Trained batch 279 in epoch 0, gen_loss = 0.399310446956328, disc_loss = 0.2200832421492253
Trained batch 280 in epoch 0, gen_loss = 0.39908963590330077, disc_loss = 0.22009912581312274
Trained batch 281 in epoch 0, gen_loss = 0.39884038988157366, disc_loss = 0.22015990171555086
Trained batch 282 in epoch 0, gen_loss = 0.39865772694665214, disc_loss = 0.22015900944125946
Trained batch 283 in epoch 0, gen_loss = 0.3987506463284224, disc_loss = 0.22015345461246832
Trained batch 284 in epoch 0, gen_loss = 0.39873782532256946, disc_loss = 0.2203596075114451
Trained batch 285 in epoch 0, gen_loss = 0.3985097372865343, disc_loss = 0.2203900870066006
Trained batch 286 in epoch 0, gen_loss = 0.39833965253746884, disc_loss = 0.2203936194968556
Trained batch 287 in epoch 0, gen_loss = 0.3981155163298051, disc_loss = 0.22036606303623152
Trained batch 288 in epoch 0, gen_loss = 0.39798883459559775, disc_loss = 0.22035891980345274
Trained batch 289 in epoch 0, gen_loss = 0.39813514865677935, disc_loss = 0.2203196891166013
Trained batch 290 in epoch 0, gen_loss = 0.39805217430353984, disc_loss = 0.22021595235030675
Trained batch 291 in epoch 0, gen_loss = 0.3980421159569531, disc_loss = 0.2201665440599804
Trained batch 292 in epoch 0, gen_loss = 0.39793642012739344, disc_loss = 0.22011613355053164
Trained batch 293 in epoch 0, gen_loss = 0.3978155845282029, disc_loss = 0.2200107409992591
Trained batch 294 in epoch 0, gen_loss = 0.39795173335883577, disc_loss = 0.22017410859718162
Trained batch 295 in epoch 0, gen_loss = 0.397924451308476, disc_loss = 0.2205172093283083
Trained batch 296 in epoch 0, gen_loss = 0.39767985943993334, disc_loss = 0.2205278758298267
Trained batch 297 in epoch 0, gen_loss = 0.3975936504418418, disc_loss = 0.2205059492598044
Trained batch 298 in epoch 0, gen_loss = 0.3974897637215745, disc_loss = 0.22055560746619535
Trained batch 299 in epoch 0, gen_loss = 0.39749002387126287, disc_loss = 0.2205126558492581
Trained batch 300 in epoch 0, gen_loss = 0.3977210252387975, disc_loss = 0.220515473018651
Trained batch 301 in epoch 0, gen_loss = 0.3974794808602491, disc_loss = 0.22045916000640156
Trained batch 302 in epoch 0, gen_loss = 0.3972919516437518, disc_loss = 0.2203191118222652
Trained batch 303 in epoch 0, gen_loss = 0.3972271797492316, disc_loss = 0.22028673153468653
Trained batch 304 in epoch 0, gen_loss = 0.39710678692723883, disc_loss = 0.22032726707517122
Trained batch 305 in epoch 0, gen_loss = 0.39694449052312014, disc_loss = 0.22041591074244649
Trained batch 306 in epoch 0, gen_loss = 0.3967314414946963, disc_loss = 0.2207396301025288
Trained batch 307 in epoch 0, gen_loss = 0.39655051099789607, disc_loss = 0.22071845028791334
Trained batch 308 in epoch 0, gen_loss = 0.3961798674080364, disc_loss = 0.22066429351429337
Trained batch 309 in epoch 0, gen_loss = 0.3958864669645986, disc_loss = 0.22068319943162704
Trained batch 310 in epoch 0, gen_loss = 0.39584286764886983, disc_loss = 0.22062662931404697
Trained batch 311 in epoch 0, gen_loss = 0.39570479343334836, disc_loss = 0.22050445543554348
Trained batch 312 in epoch 0, gen_loss = 0.39573245469373636, disc_loss = 0.2204243830931834
Trained batch 313 in epoch 0, gen_loss = 0.395777086163782, disc_loss = 0.22038288777516146
Trained batch 314 in epoch 0, gen_loss = 0.3956744091851371, disc_loss = 0.2203042904299403
Trained batch 315 in epoch 0, gen_loss = 0.3954746888219556, disc_loss = 0.22019129097933257
Trained batch 316 in epoch 0, gen_loss = 0.39528297024194375, disc_loss = 0.22004371639399875
Trained batch 317 in epoch 0, gen_loss = 0.39521249941310044, disc_loss = 0.2200383888147537
Trained batch 318 in epoch 0, gen_loss = 0.3950484125031199, disc_loss = 0.2200066295210097
Trained batch 319 in epoch 0, gen_loss = 0.3949769024737179, disc_loss = 0.21991167452652008
Trained batch 320 in epoch 0, gen_loss = 0.3948824553289146, disc_loss = 0.21986899190695486
Trained batch 321 in epoch 0, gen_loss = 0.39499998129672886, disc_loss = 0.22036284876998907
Trained batch 322 in epoch 0, gen_loss = 0.3946981769597198, disc_loss = 0.2207699847341322
Trained batch 323 in epoch 0, gen_loss = 0.39445771359735066, disc_loss = 0.22070928600927195
Trained batch 324 in epoch 0, gen_loss = 0.3942431625036093, disc_loss = 0.2206081082499944
Trained batch 325 in epoch 0, gen_loss = 0.3940335781844847, disc_loss = 0.22062639903528558
Trained batch 326 in epoch 0, gen_loss = 0.39384566361386475, disc_loss = 0.22054727892718912
Trained batch 327 in epoch 0, gen_loss = 0.393948940969095, disc_loss = 0.22044090842601002
Trained batch 328 in epoch 0, gen_loss = 0.39387811045516224, disc_loss = 0.22037141471195365
Trained batch 329 in epoch 0, gen_loss = 0.393598530328635, disc_loss = 0.22025101372238362
Trained batch 330 in epoch 0, gen_loss = 0.39345901178089154, disc_loss = 0.22028733459033994
Trained batch 331 in epoch 0, gen_loss = 0.3933350103626768, disc_loss = 0.2206198320645525
Trained batch 332 in epoch 0, gen_loss = 0.3931975779053685, disc_loss = 0.22055116566541316
Trained batch 333 in epoch 0, gen_loss = 0.3930391515800339, disc_loss = 0.22049960647960623
Trained batch 334 in epoch 0, gen_loss = 0.392857357014471, disc_loss = 0.2203744010471586
Trained batch 335 in epoch 0, gen_loss = 0.3926791544294074, disc_loss = 0.22019278065168432
Trained batch 336 in epoch 0, gen_loss = 0.39254119594302306, disc_loss = 0.22007263814394834
Trained batch 337 in epoch 0, gen_loss = 0.3926136136584028, disc_loss = 0.22000502440086483
Trained batch 338 in epoch 0, gen_loss = 0.3923380344139088, disc_loss = 0.21994958222351946
Trained batch 339 in epoch 0, gen_loss = 0.39220972420538175, disc_loss = 0.2198605834342101
Trained batch 340 in epoch 0, gen_loss = 0.39221984261641407, disc_loss = 0.21969935037960406
Trained batch 341 in epoch 0, gen_loss = 0.39217758579560885, disc_loss = 0.21956482257323656
Trained batch 342 in epoch 0, gen_loss = 0.3922236700794787, disc_loss = 0.2193965696602104
Trained batch 343 in epoch 0, gen_loss = 0.3920617147760336, disc_loss = 0.21950124492219023
Trained batch 344 in epoch 0, gen_loss = 0.3919582125933274, disc_loss = 0.21983892479236575
Trained batch 345 in epoch 0, gen_loss = 0.3918646748010823, disc_loss = 0.21995474917092764
Trained batch 346 in epoch 0, gen_loss = 0.3917715715228309, disc_loss = 0.21987493196636523
Trained batch 347 in epoch 0, gen_loss = 0.3917067177679347, disc_loss = 0.2197716786130064
Trained batch 348 in epoch 0, gen_loss = 0.3917293499909704, disc_loss = 0.21961170385850534
Trained batch 349 in epoch 0, gen_loss = 0.3916056571687971, disc_loss = 0.2194723918395383
Trained batch 350 in epoch 0, gen_loss = 0.3915241312267434, disc_loss = 0.21947168843274104
Trained batch 351 in epoch 0, gen_loss = 0.39140297125347634, disc_loss = 0.2194847777612846
Trained batch 352 in epoch 0, gen_loss = 0.3913940415841662, disc_loss = 0.2193468663704294
Trained batch 353 in epoch 0, gen_loss = 0.3913215754059075, disc_loss = 0.21918524277664847
Trained batch 354 in epoch 0, gen_loss = 0.3914345870555287, disc_loss = 0.21919175270997301
Trained batch 355 in epoch 0, gen_loss = 0.3913858886180299, disc_loss = 0.2190379967724674
Trained batch 356 in epoch 0, gen_loss = 0.3912898092543712, disc_loss = 0.21887273988386496
Trained batch 357 in epoch 0, gen_loss = 0.3913507955200845, disc_loss = 0.21902495079450102
Trained batch 358 in epoch 0, gen_loss = 0.3909855626087667, disc_loss = 0.21898755952093263
Trained batch 359 in epoch 0, gen_loss = 0.3907714899215433, disc_loss = 0.21897017125868135
Trained batch 360 in epoch 0, gen_loss = 0.3906067921018997, disc_loss = 0.21889452312213892
Trained batch 361 in epoch 0, gen_loss = 0.39041833785357394, disc_loss = 0.21879755600628273
Trained batch 362 in epoch 0, gen_loss = 0.3903525164633086, disc_loss = 0.2186989805791989
Trained batch 363 in epoch 0, gen_loss = 0.39021305707129805, disc_loss = 0.21868425405041858
Trained batch 364 in epoch 0, gen_loss = 0.3903201361225076, disc_loss = 0.2186334232149059
Trained batch 365 in epoch 0, gen_loss = 0.39020277738896875, disc_loss = 0.21860779111421175
Trained batch 366 in epoch 0, gen_loss = 0.3900329054051589, disc_loss = 0.21864767626374554
Trained batch 367 in epoch 0, gen_loss = 0.38997996736155904, disc_loss = 0.21869232252483134
Trained batch 368 in epoch 0, gen_loss = 0.38989365577374696, disc_loss = 0.21859227934584707
Trained batch 369 in epoch 0, gen_loss = 0.3899044579750783, disc_loss = 0.2184746327231059
Trained batch 370 in epoch 0, gen_loss = 0.38974977720458553, disc_loss = 0.21835071067363426
Trained batch 371 in epoch 0, gen_loss = 0.38946887818715903, disc_loss = 0.21841535727263137
Trained batch 372 in epoch 0, gen_loss = 0.38936822999258786, disc_loss = 0.2184562911816321
Trained batch 373 in epoch 0, gen_loss = 0.38927465892411806, disc_loss = 0.21853938397956404
Trained batch 374 in epoch 0, gen_loss = 0.3891467935244242, disc_loss = 0.21843898791074753
Trained batch 375 in epoch 0, gen_loss = 0.38892463753198053, disc_loss = 0.21837958378439887
Trained batch 376 in epoch 0, gen_loss = 0.388873632137592, disc_loss = 0.21828832528714476
Trained batch 377 in epoch 0, gen_loss = 0.38875821437785235, disc_loss = 0.2182151647432456
Trained batch 378 in epoch 0, gen_loss = 0.3885850109022337, disc_loss = 0.21817591501335984
Trained batch 379 in epoch 0, gen_loss = 0.38841248178168347, disc_loss = 0.21815501331890885
Trained batch 380 in epoch 0, gen_loss = 0.388325961164915, disc_loss = 0.21809272352713613
Trained batch 381 in epoch 0, gen_loss = 0.38831675949833155, disc_loss = 0.21796251066926262
Trained batch 382 in epoch 0, gen_loss = 0.38829528055987844, disc_loss = 0.2177437763495794
Trained batch 383 in epoch 0, gen_loss = 0.388138175321122, disc_loss = 0.21753099783866978
Trained batch 384 in epoch 0, gen_loss = 0.38816856014264095, disc_loss = 0.21737105039420065
Trained batch 385 in epoch 0, gen_loss = 0.3879892921046272, disc_loss = 0.21753978989825348
Trained batch 386 in epoch 0, gen_loss = 0.3881353089821739, disc_loss = 0.21793875173311825
Trained batch 387 in epoch 0, gen_loss = 0.3879898935556412, disc_loss = 0.2179306617832368
Trained batch 388 in epoch 0, gen_loss = 0.38778427135975013, disc_loss = 0.21787610046737912
Trained batch 389 in epoch 0, gen_loss = 0.3876087158918381, disc_loss = 0.21774455211483515
Trained batch 390 in epoch 0, gen_loss = 0.38779946826303097, disc_loss = 0.21757673921868625
Trained batch 391 in epoch 0, gen_loss = 0.3879189927663122, disc_loss = 0.21755140098001885
Trained batch 392 in epoch 0, gen_loss = 0.38761958972795013, disc_loss = 0.21753678341934093
Trained batch 393 in epoch 0, gen_loss = 0.3876538966512922, disc_loss = 0.2173940299769041
Trained batch 394 in epoch 0, gen_loss = 0.38758459868310374, disc_loss = 0.21732154467815085
Trained batch 395 in epoch 0, gen_loss = 0.38756416075759464, disc_loss = 0.21729333286709857
Trained batch 396 in epoch 0, gen_loss = 0.3875651596024895, disc_loss = 0.2172537162074214
Trained batch 397 in epoch 0, gen_loss = 0.38754208685465197, disc_loss = 0.21733121426036608
Trained batch 398 in epoch 0, gen_loss = 0.3874911600933935, disc_loss = 0.21736750228886018
Trained batch 399 in epoch 0, gen_loss = 0.3874442210793495, disc_loss = 0.2172537092678249
Trained batch 400 in epoch 0, gen_loss = 0.38731664040142166, disc_loss = 0.21711509373791496
Trained batch 401 in epoch 0, gen_loss = 0.3873741147085209, disc_loss = 0.21706631184736294
Trained batch 402 in epoch 0, gen_loss = 0.3871810990143059, disc_loss = 0.21721602127732473
Trained batch 403 in epoch 0, gen_loss = 0.3871156856565192, disc_loss = 0.21724488835154784
Trained batch 404 in epoch 0, gen_loss = 0.3870113660523921, disc_loss = 0.21714963454891134
Trained batch 405 in epoch 0, gen_loss = 0.38700645750966567, disc_loss = 0.21693887001848572
Trained batch 406 in epoch 0, gen_loss = 0.3867051594819718, disc_loss = 0.21688540874813347
Trained batch 407 in epoch 0, gen_loss = 0.3867782865669213, disc_loss = 0.21669533131096294
Trained batch 408 in epoch 0, gen_loss = 0.38672563812551985, disc_loss = 0.2166651471137709
Trained batch 409 in epoch 0, gen_loss = 0.38690588052679853, disc_loss = 0.2166819900819441
Trained batch 410 in epoch 0, gen_loss = 0.3867641005782895, disc_loss = 0.21673272885472816
Trained batch 411 in epoch 0, gen_loss = 0.3866529947201025, disc_loss = 0.21661869134500766
Trained batch 412 in epoch 0, gen_loss = 0.386781946798791, disc_loss = 0.21642257401282217
Trained batch 413 in epoch 0, gen_loss = 0.38674407844670156, disc_loss = 0.21634654594576302
Trained batch 414 in epoch 0, gen_loss = 0.3869198723729835, disc_loss = 0.2163444052798202
Trained batch 415 in epoch 0, gen_loss = 0.38686581206722903, disc_loss = 0.21614613686688244
Trained batch 416 in epoch 0, gen_loss = 0.38680182093624876, disc_loss = 0.21589983565558632
Trained batch 417 in epoch 0, gen_loss = 0.3867889823097932, disc_loss = 0.21571007846859083
Trained batch 418 in epoch 0, gen_loss = 0.38678670726129716, disc_loss = 0.2155647813242489
Trained batch 419 in epoch 0, gen_loss = 0.3868755006364414, disc_loss = 0.2153740555934963
Trained batch 420 in epoch 0, gen_loss = 0.3867269224197451, disc_loss = 0.2154517557622418
Trained batch 421 in epoch 0, gen_loss = 0.3866538534655955, disc_loss = 0.21578937339909834
Trained batch 422 in epoch 0, gen_loss = 0.3864381528915243, disc_loss = 0.2157086455054035
Trained batch 423 in epoch 0, gen_loss = 0.38649811722197625, disc_loss = 0.21559274574425422
Trained batch 424 in epoch 0, gen_loss = 0.3863476049198824, disc_loss = 0.2154723396897316
Trained batch 425 in epoch 0, gen_loss = 0.3862554319028004, disc_loss = 0.21527695020949336
Trained batch 426 in epoch 0, gen_loss = 0.38624778445766456, disc_loss = 0.2150564515653483
Trained batch 427 in epoch 0, gen_loss = 0.3860785046888289, disc_loss = 0.21496310622962278
Trained batch 428 in epoch 0, gen_loss = 0.38606191466460416, disc_loss = 0.21479462248670472
Trained batch 429 in epoch 0, gen_loss = 0.38607091688832573, disc_loss = 0.21461535621174546
Trained batch 430 in epoch 0, gen_loss = 0.38598741463054914, disc_loss = 0.21451312640634324
Trained batch 431 in epoch 0, gen_loss = 0.3859363653593593, disc_loss = 0.21447546974997278
Trained batch 432 in epoch 0, gen_loss = 0.3859693926283724, disc_loss = 0.21473607099152603
Trained batch 433 in epoch 0, gen_loss = 0.38571397822848114, disc_loss = 0.21493959181388403
Trained batch 434 in epoch 0, gen_loss = 0.38559140583564494, disc_loss = 0.21492431377884985
Trained batch 435 in epoch 0, gen_loss = 0.3855182518242696, disc_loss = 0.2148942625269704
Trained batch 436 in epoch 0, gen_loss = 0.3851967581145005, disc_loss = 0.21491463108998415
Trained batch 437 in epoch 0, gen_loss = 0.38516268083085753, disc_loss = 0.2148166843711241
Trained batch 438 in epoch 0, gen_loss = 0.3852073494217662, disc_loss = 0.21493212744627563
Trained batch 439 in epoch 0, gen_loss = 0.38508925509046427, disc_loss = 0.21490800277414648
Trained batch 440 in epoch 0, gen_loss = 0.38511795200863663, disc_loss = 0.2147171553266562
Trained batch 441 in epoch 0, gen_loss = 0.38511227276934756, disc_loss = 0.21458672855167368
Trained batch 442 in epoch 0, gen_loss = 0.3851117778645143, disc_loss = 0.21455719903885107
Trained batch 443 in epoch 0, gen_loss = 0.3853193027143543, disc_loss = 0.21483828790217369
Trained batch 444 in epoch 0, gen_loss = 0.3853911936617969, disc_loss = 0.2146861398655377
Trained batch 445 in epoch 0, gen_loss = 0.3853898333393939, disc_loss = 0.2147220562759269
Trained batch 446 in epoch 0, gen_loss = 0.3854796539417049, disc_loss = 0.21458866097183035
Trained batch 447 in epoch 0, gen_loss = 0.3853424503800592, disc_loss = 0.2145033613279728
Trained batch 448 in epoch 0, gen_loss = 0.38518941452216465, disc_loss = 0.21448772828735593
Trained batch 449 in epoch 0, gen_loss = 0.38528908090458974, disc_loss = 0.21433144345879554
Trained batch 450 in epoch 0, gen_loss = 0.3852083675414654, disc_loss = 0.21426721113814484
Trained batch 451 in epoch 0, gen_loss = 0.38509860552385844, disc_loss = 0.21413345728893723
Trained batch 452 in epoch 0, gen_loss = 0.3851776210874911, disc_loss = 0.21400602462868026
Trained batch 453 in epoch 0, gen_loss = 0.3850085647030024, disc_loss = 0.21393451906970418
Trained batch 454 in epoch 0, gen_loss = 0.3851225891938576, disc_loss = 0.21386644471805175
Trained batch 455 in epoch 0, gen_loss = 0.384937665408902, disc_loss = 0.21373211319574661
Trained batch 456 in epoch 0, gen_loss = 0.3849593231727571, disc_loss = 0.21428553484526974
Trained batch 457 in epoch 0, gen_loss = 0.3849126773044532, disc_loss = 0.2140898979777332
Trained batch 458 in epoch 0, gen_loss = 0.38498968428126606, disc_loss = 0.213922390491095
Trained batch 459 in epoch 0, gen_loss = 0.3848880123509013, disc_loss = 0.21367573103179102
Trained batch 460 in epoch 0, gen_loss = 0.38466713572660394, disc_loss = 0.2135816358046004
Trained batch 461 in epoch 0, gen_loss = 0.3846303660954748, disc_loss = 0.21352697850821853
Trained batch 462 in epoch 0, gen_loss = 0.3846017529395435, disc_loss = 0.21367330627101544
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.3372631072998047, disc_loss = 0.5006919503211975
Trained batch 1 in epoch 1, gen_loss = 0.3788130283355713, disc_loss = 0.42342421412467957
Trained batch 2 in epoch 1, gen_loss = 0.41242047150929767, disc_loss = 0.5287720561027527
Trained batch 3 in epoch 1, gen_loss = 0.40885716676712036, disc_loss = 0.6393261104822159
Trained batch 4 in epoch 1, gen_loss = 0.40461317300796507, disc_loss = 0.6891320943832397
Trained batch 5 in epoch 1, gen_loss = 0.4075669546922048, disc_loss = 0.638436088959376
Trained batch 6 in epoch 1, gen_loss = 0.3955662761415754, disc_loss = 0.5935448663575309
Trained batch 7 in epoch 1, gen_loss = 0.3927466347813606, disc_loss = 0.5482227355241776
Trained batch 8 in epoch 1, gen_loss = 0.3893040782875485, disc_loss = 0.5129804064830145
Trained batch 9 in epoch 1, gen_loss = 0.38527053594589233, disc_loss = 0.4866494759917259
Trained batch 10 in epoch 1, gen_loss = 0.38285111026330426, disc_loss = 0.46439443257721985
Trained batch 11 in epoch 1, gen_loss = 0.38211191942294437, disc_loss = 0.44641607875625294
Trained batch 12 in epoch 1, gen_loss = 0.37571051716804504, disc_loss = 0.4306504657635322
Trained batch 13 in epoch 1, gen_loss = 0.37595242474760326, disc_loss = 0.41672031581401825
Trained batch 14 in epoch 1, gen_loss = 0.3742718438307444, disc_loss = 0.40375502705574035
Trained batch 15 in epoch 1, gen_loss = 0.376598896458745, disc_loss = 0.3904088716953993
Trained batch 16 in epoch 1, gen_loss = 0.3766215338426478, disc_loss = 0.379141669939546
Trained batch 17 in epoch 1, gen_loss = 0.37273934649096596, disc_loss = 0.3687211374441783
Trained batch 18 in epoch 1, gen_loss = 0.37222495831941305, disc_loss = 0.3589474088267276
Trained batch 19 in epoch 1, gen_loss = 0.3728525832295418, disc_loss = 0.3508878380060196
Trained batch 20 in epoch 1, gen_loss = 0.37008504498572575, disc_loss = 0.3437931722118741
Trained batch 21 in epoch 1, gen_loss = 0.3674349974502217, disc_loss = 0.33805369247089734
Trained batch 22 in epoch 1, gen_loss = 0.3654561107573302, disc_loss = 0.33175314185412036
Trained batch 23 in epoch 1, gen_loss = 0.3658171171943347, disc_loss = 0.326278543099761
Trained batch 24 in epoch 1, gen_loss = 0.3661932909488678, disc_loss = 0.32122264206409457
Trained batch 25 in epoch 1, gen_loss = 0.36420001089572906, disc_loss = 0.3168184058024333
Trained batch 26 in epoch 1, gen_loss = 0.36117945666666385, disc_loss = 0.31300700925014635
Trained batch 27 in epoch 1, gen_loss = 0.3615676292351314, disc_loss = 0.3090902662702969
Trained batch 28 in epoch 1, gen_loss = 0.35806564010422803, disc_loss = 0.3054843020850214
Trained batch 29 in epoch 1, gen_loss = 0.3584264109532038, disc_loss = 0.3019328147172928
Trained batch 30 in epoch 1, gen_loss = 0.3597078957865315, disc_loss = 0.2986088423959671
Trained batch 31 in epoch 1, gen_loss = 0.3601047145202756, disc_loss = 0.29660183703526855
Trained batch 32 in epoch 1, gen_loss = 0.3593539396921794, disc_loss = 0.29323530332608655
Trained batch 33 in epoch 1, gen_loss = 0.359581173342817, disc_loss = 0.2901983918512569
Trained batch 34 in epoch 1, gen_loss = 0.3594905129500798, disc_loss = 0.28625558146408625
Trained batch 35 in epoch 1, gen_loss = 0.35954556945297456, disc_loss = 0.2832784416774909
Trained batch 36 in epoch 1, gen_loss = 0.3601739535460601, disc_loss = 0.28068944288266673
Trained batch 37 in epoch 1, gen_loss = 0.35991703052269786, disc_loss = 0.28055303857514735
Trained batch 38 in epoch 1, gen_loss = 0.35933388272921246, disc_loss = 0.2818395407536091
Trained batch 39 in epoch 1, gen_loss = 0.35866833105683327, disc_loss = 0.2797579936683178
Trained batch 40 in epoch 1, gen_loss = 0.35981504510088663, disc_loss = 0.2772670700782683
Trained batch 41 in epoch 1, gen_loss = 0.35850948308195385, disc_loss = 0.27731464164597647
Trained batch 42 in epoch 1, gen_loss = 0.3583493565404138, disc_loss = 0.2745896962492965
Trained batch 43 in epoch 1, gen_loss = 0.35785533352331683, disc_loss = 0.27233571728522127
Trained batch 44 in epoch 1, gen_loss = 0.3581949637995826, disc_loss = 0.2703372243377897
Trained batch 45 in epoch 1, gen_loss = 0.3595672878234283, disc_loss = 0.26781284582355747
Trained batch 46 in epoch 1, gen_loss = 0.359004167800254, disc_loss = 0.26549382698028645
Trained batch 47 in epoch 1, gen_loss = 0.35764457285404205, disc_loss = 0.26390346450110275
Trained batch 48 in epoch 1, gen_loss = 0.3588456846013361, disc_loss = 0.26258052733479714
Trained batch 49 in epoch 1, gen_loss = 0.35871547400951387, disc_loss = 0.2622498646378517
Trained batch 50 in epoch 1, gen_loss = 0.35749659175966303, disc_loss = 0.260686743200994
Trained batch 51 in epoch 1, gen_loss = 0.3578900826665071, disc_loss = 0.2587189574081164
Trained batch 52 in epoch 1, gen_loss = 0.35908200043552324, disc_loss = 0.25690956498092077
Trained batch 53 in epoch 1, gen_loss = 0.35835731084699984, disc_loss = 0.2547979699792685
Trained batch 54 in epoch 1, gen_loss = 0.3584772364659743, disc_loss = 0.25312458141283556
Trained batch 55 in epoch 1, gen_loss = 0.35775072287235943, disc_loss = 0.2520845088043383
Trained batch 56 in epoch 1, gen_loss = 0.35796962965998735, disc_loss = 0.25083753231324646
Trained batch 57 in epoch 1, gen_loss = 0.3573410043428684, disc_loss = 0.2494621032784725
Trained batch 58 in epoch 1, gen_loss = 0.35685865101167713, disc_loss = 0.2487808056807114
Trained batch 59 in epoch 1, gen_loss = 0.3576693837841352, disc_loss = 0.24942117432753244
Trained batch 60 in epoch 1, gen_loss = 0.3576880053418582, disc_loss = 0.24791668770743197
Trained batch 61 in epoch 1, gen_loss = 0.3576607761844512, disc_loss = 0.24634438320513694
Trained batch 62 in epoch 1, gen_loss = 0.3588603115271008, disc_loss = 0.24472857183880276
Trained batch 63 in epoch 1, gen_loss = 0.3598951152525842, disc_loss = 0.2428504740819335
Trained batch 64 in epoch 1, gen_loss = 0.35949439406394956, disc_loss = 0.24171388286810655
Trained batch 65 in epoch 1, gen_loss = 0.3604349241112218, disc_loss = 0.2428475437742291
Trained batch 66 in epoch 1, gen_loss = 0.36032578793924247, disc_loss = 0.24191589186440654
Trained batch 67 in epoch 1, gen_loss = 0.3603131026029587, disc_loss = 0.2417457329438013
Trained batch 68 in epoch 1, gen_loss = 0.3602592746416728, disc_loss = 0.24175518707952637
Trained batch 69 in epoch 1, gen_loss = 0.35965600269181386, disc_loss = 0.24170690178871154
Trained batch 70 in epoch 1, gen_loss = 0.3596796674627653, disc_loss = 0.2403439159544421
Trained batch 71 in epoch 1, gen_loss = 0.3602437112066481, disc_loss = 0.23896116659873062
Trained batch 72 in epoch 1, gen_loss = 0.35961646576450296, disc_loss = 0.23803742679014597
Trained batch 73 in epoch 1, gen_loss = 0.3590820302834382, disc_loss = 0.23716774220402176
Trained batch 74 in epoch 1, gen_loss = 0.3591314693291982, disc_loss = 0.23624008595943452
Trained batch 75 in epoch 1, gen_loss = 0.3595836888018407, disc_loss = 0.23503255785295837
Trained batch 76 in epoch 1, gen_loss = 0.3592655654851492, disc_loss = 0.23389584464686258
Trained batch 77 in epoch 1, gen_loss = 0.36039739426894063, disc_loss = 0.23304815227404618
Trained batch 78 in epoch 1, gen_loss = 0.3592894269695765, disc_loss = 0.2335883143204677
Trained batch 79 in epoch 1, gen_loss = 0.35911923050880434, disc_loss = 0.23620051611214876
Trained batch 80 in epoch 1, gen_loss = 0.35876548290252686, disc_loss = 0.23637114502029655
Trained batch 81 in epoch 1, gen_loss = 0.3592369302016933, disc_loss = 0.23603911588831647
Trained batch 82 in epoch 1, gen_loss = 0.35868099511387835, disc_loss = 0.23591130020388637
Trained batch 83 in epoch 1, gen_loss = 0.35811820803653627, disc_loss = 0.23532400652766228
Trained batch 84 in epoch 1, gen_loss = 0.35795029892640956, disc_loss = 0.23483653156196369
Trained batch 85 in epoch 1, gen_loss = 0.35705272576143576, disc_loss = 0.23433442777672478
Trained batch 86 in epoch 1, gen_loss = 0.35779169133339805, disc_loss = 0.2334157980379017
Trained batch 87 in epoch 1, gen_loss = 0.3578737913207574, disc_loss = 0.23208161968399177
Trained batch 88 in epoch 1, gen_loss = 0.35796668824185146, disc_loss = 0.23072620497995547
Trained batch 89 in epoch 1, gen_loss = 0.3581012984116872, disc_loss = 0.22991017972429592
Trained batch 90 in epoch 1, gen_loss = 0.3579911923670507, disc_loss = 0.22892335949690787
Trained batch 91 in epoch 1, gen_loss = 0.3586421401604362, disc_loss = 0.22820336541727834
Trained batch 92 in epoch 1, gen_loss = 0.35864267297970354, disc_loss = 0.22728247676164873
Trained batch 93 in epoch 1, gen_loss = 0.35905554224836067, disc_loss = 0.22686147491665595
Trained batch 94 in epoch 1, gen_loss = 0.35903880125597903, disc_loss = 0.22644919384466974
Trained batch 95 in epoch 1, gen_loss = 0.35953098939110834, disc_loss = 0.2265515506733209
Trained batch 96 in epoch 1, gen_loss = 0.359652744740555, disc_loss = 0.22591281943407254
Trained batch 97 in epoch 1, gen_loss = 0.3596389491339119, disc_loss = 0.22493816874161057
Trained batch 98 in epoch 1, gen_loss = 0.35957199666235184, disc_loss = 0.22390118549869517
Trained batch 99 in epoch 1, gen_loss = 0.3593948355317116, disc_loss = 0.22368947841227055
Trained batch 100 in epoch 1, gen_loss = 0.3585750717337769, disc_loss = 0.22349622838272906
Trained batch 101 in epoch 1, gen_loss = 0.359107858117889, disc_loss = 0.22410018501036308
Trained batch 102 in epoch 1, gen_loss = 0.35935441816894753, disc_loss = 0.22319321298194164
Trained batch 103 in epoch 1, gen_loss = 0.35959469555662227, disc_loss = 0.22213405248923943
Trained batch 104 in epoch 1, gen_loss = 0.3595963526339758, disc_loss = 0.22127692891018733
Trained batch 105 in epoch 1, gen_loss = 0.35916926894547807, disc_loss = 0.22184475687033725
Trained batch 106 in epoch 1, gen_loss = 0.35965498474156743, disc_loss = 0.22205677343027613
Trained batch 107 in epoch 1, gen_loss = 0.35942536040588663, disc_loss = 0.22097378300019987
Trained batch 108 in epoch 1, gen_loss = 0.3590826996422689, disc_loss = 0.22070109810030789
Trained batch 109 in epoch 1, gen_loss = 0.3594042964956977, disc_loss = 0.22009444582191381
Trained batch 110 in epoch 1, gen_loss = 0.3593917303794139, disc_loss = 0.21944027783365938
Trained batch 111 in epoch 1, gen_loss = 0.3593323012547834, disc_loss = 0.2198078059591353
Trained batch 112 in epoch 1, gen_loss = 0.35919446280572265, disc_loss = 0.21928081173548655
Trained batch 113 in epoch 1, gen_loss = 0.35894267025746796, disc_loss = 0.21841416324962648
Trained batch 114 in epoch 1, gen_loss = 0.35859805656516036, disc_loss = 0.21800165979758554
Trained batch 115 in epoch 1, gen_loss = 0.35990272976201154, disc_loss = 0.21726640570780326
Trained batch 116 in epoch 1, gen_loss = 0.36044180622467625, disc_loss = 0.21640324019468749
Trained batch 117 in epoch 1, gen_loss = 0.3607304512949313, disc_loss = 0.21589210528438374
Trained batch 118 in epoch 1, gen_loss = 0.36095427865741636, disc_loss = 0.2150654140390268
Trained batch 119 in epoch 1, gen_loss = 0.36061276992162067, disc_loss = 0.21490325840810934
Trained batch 120 in epoch 1, gen_loss = 0.3609107954442994, disc_loss = 0.2163136174117238
Trained batch 121 in epoch 1, gen_loss = 0.36146665840852454, disc_loss = 0.2160288734269924
Trained batch 122 in epoch 1, gen_loss = 0.3610602459771846, disc_loss = 0.21535153505278798
Trained batch 123 in epoch 1, gen_loss = 0.3604161703298169, disc_loss = 0.214689853571115
Trained batch 124 in epoch 1, gen_loss = 0.3603184313774109, disc_loss = 0.2149112523794174
Trained batch 125 in epoch 1, gen_loss = 0.36038843104763635, disc_loss = 0.21472956476703522
Trained batch 126 in epoch 1, gen_loss = 0.3601778797277315, disc_loss = 0.2138367012495131
Trained batch 127 in epoch 1, gen_loss = 0.360741003183648, disc_loss = 0.21327684342395514
Trained batch 128 in epoch 1, gen_loss = 0.3600319882695989, disc_loss = 0.21350117928759996
Trained batch 129 in epoch 1, gen_loss = 0.36095029436624965, disc_loss = 0.21355717239471583
Trained batch 130 in epoch 1, gen_loss = 0.36063695135917373, disc_loss = 0.21294061828205604
Trained batch 131 in epoch 1, gen_loss = 0.3606804916352937, disc_loss = 0.21212233840064568
Trained batch 132 in epoch 1, gen_loss = 0.3607618884932726, disc_loss = 0.21127265238000037
Trained batch 133 in epoch 1, gen_loss = 0.36030747352251363, disc_loss = 0.21105594516022883
Trained batch 134 in epoch 1, gen_loss = 0.3609311741811258, disc_loss = 0.21007122011096388
Trained batch 135 in epoch 1, gen_loss = 0.3614121603176874, disc_loss = 0.2094871708575417
Trained batch 136 in epoch 1, gen_loss = 0.3615254805470905, disc_loss = 0.20939290131965693
Trained batch 137 in epoch 1, gen_loss = 0.36194197272045026, disc_loss = 0.21010033786296844
Trained batch 138 in epoch 1, gen_loss = 0.3617856952783873, disc_loss = 0.21020855824295565
Trained batch 139 in epoch 1, gen_loss = 0.36219678840466907, disc_loss = 0.20994303950241633
Trained batch 140 in epoch 1, gen_loss = 0.36266976700606923, disc_loss = 0.2092795732913288
Trained batch 141 in epoch 1, gen_loss = 0.3625278890552655, disc_loss = 0.20839112367428525
Trained batch 142 in epoch 1, gen_loss = 0.36294416614345737, disc_loss = 0.20757077181047492
Trained batch 143 in epoch 1, gen_loss = 0.3628470405108399, disc_loss = 0.2073359366816779
Trained batch 144 in epoch 1, gen_loss = 0.36315532018398416, disc_loss = 0.20722250368060738
Trained batch 145 in epoch 1, gen_loss = 0.3635696389087259, disc_loss = 0.2071040971332217
Trained batch 146 in epoch 1, gen_loss = 0.36329629591533114, disc_loss = 0.20688213504293337
Trained batch 147 in epoch 1, gen_loss = 0.36339665667430776, disc_loss = 0.20636267703328584
Trained batch 148 in epoch 1, gen_loss = 0.36312633272785466, disc_loss = 0.20562167660701994
Trained batch 149 in epoch 1, gen_loss = 0.36272292415301005, disc_loss = 0.20561214948693912
Trained batch 150 in epoch 1, gen_loss = 0.3630840983611858, disc_loss = 0.20569060214900023
Trained batch 151 in epoch 1, gen_loss = 0.3630090036282414, disc_loss = 0.20504045158036446
Trained batch 152 in epoch 1, gen_loss = 0.36295592161565043, disc_loss = 0.204221920006805
Trained batch 153 in epoch 1, gen_loss = 0.36276111297019115, disc_loss = 0.2035891827341024
Trained batch 154 in epoch 1, gen_loss = 0.3624405172563368, disc_loss = 0.2030994940669306
Trained batch 155 in epoch 1, gen_loss = 0.3626456272143584, disc_loss = 0.20305376122586238
Trained batch 156 in epoch 1, gen_loss = 0.3624664359031969, disc_loss = 0.20285406884304277
Trained batch 157 in epoch 1, gen_loss = 0.36260993552358844, disc_loss = 0.20295455292621745
Trained batch 158 in epoch 1, gen_loss = 0.36233722807476354, disc_loss = 0.2032586558716102
Trained batch 159 in epoch 1, gen_loss = 0.3628377798944712, disc_loss = 0.20337272784672678
Trained batch 160 in epoch 1, gen_loss = 0.3629262515846987, disc_loss = 0.20286219169079148
Trained batch 161 in epoch 1, gen_loss = 0.3624310622244705, disc_loss = 0.2023558418875859
Trained batch 162 in epoch 1, gen_loss = 0.3624068860627391, disc_loss = 0.20175303413641232
Trained batch 163 in epoch 1, gen_loss = 0.36266805413292674, disc_loss = 0.20121589884525393
Trained batch 164 in epoch 1, gen_loss = 0.3626297416109027, disc_loss = 0.20042156915773046
Trained batch 165 in epoch 1, gen_loss = 0.363089916217758, disc_loss = 0.20029318094792137
Trained batch 166 in epoch 1, gen_loss = 0.36329803798726934, disc_loss = 0.19989511687420086
Trained batch 167 in epoch 1, gen_loss = 0.36304285164390293, disc_loss = 0.1992681866866492
Trained batch 168 in epoch 1, gen_loss = 0.36273533264560814, disc_loss = 0.19925758370457317
Trained batch 169 in epoch 1, gen_loss = 0.36286782359375674, disc_loss = 0.19965192820219432
Trained batch 170 in epoch 1, gen_loss = 0.36271407590274923, disc_loss = 0.1991499333440909
Trained batch 171 in epoch 1, gen_loss = 0.36326247852209004, disc_loss = 0.19825044937085273
Trained batch 172 in epoch 1, gen_loss = 0.3632864374990408, disc_loss = 0.1975259780883789
Trained batch 173 in epoch 1, gen_loss = 0.3634301620995861, disc_loss = 0.19697997337956538
Trained batch 174 in epoch 1, gen_loss = 0.36327067034585137, disc_loss = 0.1969476129753249
Trained batch 175 in epoch 1, gen_loss = 0.36380081810057163, disc_loss = 0.19621594296768308
Trained batch 176 in epoch 1, gen_loss = 0.3640001163644306, disc_loss = 0.19600319639269242
Trained batch 177 in epoch 1, gen_loss = 0.36452401488014824, disc_loss = 0.19566846626360765
Trained batch 178 in epoch 1, gen_loss = 0.3651618591234005, disc_loss = 0.19503538077437013
Trained batch 179 in epoch 1, gen_loss = 0.364856033358309, disc_loss = 0.19494963809847832
Trained batch 180 in epoch 1, gen_loss = 0.3658330195187205, disc_loss = 0.1963064342078583
Trained batch 181 in epoch 1, gen_loss = 0.36575742589903404, disc_loss = 0.19633075922400087
Trained batch 182 in epoch 1, gen_loss = 0.365518139685438, disc_loss = 0.19662894512134824
Trained batch 183 in epoch 1, gen_loss = 0.36560041586989944, disc_loss = 0.19617413389294044
Trained batch 184 in epoch 1, gen_loss = 0.36516925483136564, disc_loss = 0.1958503307522954
Trained batch 185 in epoch 1, gen_loss = 0.3655942008700422, disc_loss = 0.1954190483897604
Trained batch 186 in epoch 1, gen_loss = 0.3654911455942348, disc_loss = 0.19488942340255422
Trained batch 187 in epoch 1, gen_loss = 0.36544155028272185, disc_loss = 0.1943583114746403
Trained batch 188 in epoch 1, gen_loss = 0.3656042561959968, disc_loss = 0.19362207066523965
Trained batch 189 in epoch 1, gen_loss = 0.36568497435042735, disc_loss = 0.19298447548950973
Trained batch 190 in epoch 1, gen_loss = 0.3662474728067508, disc_loss = 0.19224405981093176
Trained batch 191 in epoch 1, gen_loss = 0.36590183914328617, disc_loss = 0.19181391431872422
Trained batch 192 in epoch 1, gen_loss = 0.36628772619474737, disc_loss = 0.19272608975903976
Trained batch 193 in epoch 1, gen_loss = 0.366192486329177, disc_loss = 0.19219801903308667
Trained batch 194 in epoch 1, gen_loss = 0.3663475861916175, disc_loss = 0.1925957192022067
Trained batch 195 in epoch 1, gen_loss = 0.36670711514901144, disc_loss = 0.19330406795274846
Trained batch 196 in epoch 1, gen_loss = 0.36675294447066215, disc_loss = 0.19315728202916038
Trained batch 197 in epoch 1, gen_loss = 0.3666684010414162, disc_loss = 0.1927437980029017
Trained batch 198 in epoch 1, gen_loss = 0.36636456757334607, disc_loss = 0.19285608182225994
Trained batch 199 in epoch 1, gen_loss = 0.36638192042708395, disc_loss = 0.1928041543625295
Trained batch 200 in epoch 1, gen_loss = 0.36622400174093483, disc_loss = 0.19246228852897734
Trained batch 201 in epoch 1, gen_loss = 0.366723167571691, disc_loss = 0.19199296771225952
Trained batch 202 in epoch 1, gen_loss = 0.3667974783281975, disc_loss = 0.1919469665827716
Trained batch 203 in epoch 1, gen_loss = 0.36721115836910173, disc_loss = 0.19157200783272
Trained batch 204 in epoch 1, gen_loss = 0.36711964389172996, disc_loss = 0.19103387556061513
Trained batch 205 in epoch 1, gen_loss = 0.3669561952063181, disc_loss = 0.1912676336659679
Trained batch 206 in epoch 1, gen_loss = 0.36712339275701034, disc_loss = 0.19135325590985408
Trained batch 207 in epoch 1, gen_loss = 0.3670485200217137, disc_loss = 0.19078828288743702
Trained batch 208 in epoch 1, gen_loss = 0.3670182899710094, disc_loss = 0.1903595198391442
Trained batch 209 in epoch 1, gen_loss = 0.36717798837593624, disc_loss = 0.1899515696402107
Trained batch 210 in epoch 1, gen_loss = 0.36704373557420705, disc_loss = 0.18933531036379778
Trained batch 211 in epoch 1, gen_loss = 0.3672543831591336, disc_loss = 0.18863647380176018
Trained batch 212 in epoch 1, gen_loss = 0.3673325667918568, disc_loss = 0.18794208619866012
Trained batch 213 in epoch 1, gen_loss = 0.36756375710540845, disc_loss = 0.18726962047550721
Trained batch 214 in epoch 1, gen_loss = 0.367533617518669, disc_loss = 0.18661955191298973
Trained batch 215 in epoch 1, gen_loss = 0.3673932334339177, disc_loss = 0.1862087926344463
Trained batch 216 in epoch 1, gen_loss = 0.36723583442274876, disc_loss = 0.1867075998353244
Trained batch 217 in epoch 1, gen_loss = 0.36728571423696815, disc_loss = 0.18636276926674428
Trained batch 218 in epoch 1, gen_loss = 0.36742882832000245, disc_loss = 0.1861906450871191
Trained batch 219 in epoch 1, gen_loss = 0.36701726764440534, disc_loss = 0.18696835195137695
Trained batch 220 in epoch 1, gen_loss = 0.36726319331389207, disc_loss = 0.1880155094305045
Trained batch 221 in epoch 1, gen_loss = 0.3672668794253925, disc_loss = 0.1880003933266208
Trained batch 222 in epoch 1, gen_loss = 0.3669388767315133, disc_loss = 0.18817384512635624
Trained batch 223 in epoch 1, gen_loss = 0.3667312602379492, disc_loss = 0.18800034245941788
Trained batch 224 in epoch 1, gen_loss = 0.3664955165651109, disc_loss = 0.18772287135322888
Trained batch 225 in epoch 1, gen_loss = 0.3667127922572921, disc_loss = 0.1873689542269021
Trained batch 226 in epoch 1, gen_loss = 0.36675962044278954, disc_loss = 0.1870083071225803
Trained batch 227 in epoch 1, gen_loss = 0.36693884301603885, disc_loss = 0.18654263612667196
Trained batch 228 in epoch 1, gen_loss = 0.3667998687408897, disc_loss = 0.18610613339267443
Trained batch 229 in epoch 1, gen_loss = 0.3667800987544267, disc_loss = 0.1856034650588813
Trained batch 230 in epoch 1, gen_loss = 0.36674416220033323, disc_loss = 0.1851215459148347
Trained batch 231 in epoch 1, gen_loss = 0.3668241476447418, disc_loss = 0.1846741728067141
Trained batch 232 in epoch 1, gen_loss = 0.36729662536039887, disc_loss = 0.18427761796014502
Trained batch 233 in epoch 1, gen_loss = 0.36703939595793045, disc_loss = 0.18399068772092333
Trained batch 234 in epoch 1, gen_loss = 0.3675019127257327, disc_loss = 0.18363988978114534
Trained batch 235 in epoch 1, gen_loss = 0.36733160231073025, disc_loss = 0.18304689171708236
Trained batch 236 in epoch 1, gen_loss = 0.3673572699983412, disc_loss = 0.182526179239594
Trained batch 237 in epoch 1, gen_loss = 0.36750106788983866, disc_loss = 0.18194293614257784
Trained batch 238 in epoch 1, gen_loss = 0.367726517022903, disc_loss = 0.18173072092765047
Trained batch 239 in epoch 1, gen_loss = 0.3676493560274442, disc_loss = 0.18205786373776695
Trained batch 240 in epoch 1, gen_loss = 0.36800972789649644, disc_loss = 0.18168609012768477
Trained batch 241 in epoch 1, gen_loss = 0.3680633881614228, disc_loss = 0.18102469969510046
Trained batch 242 in epoch 1, gen_loss = 0.36778184464929525, disc_loss = 0.18058447932264932
Trained batch 243 in epoch 1, gen_loss = 0.36779975988825814, disc_loss = 0.1800946196174768
Trained batch 244 in epoch 1, gen_loss = 0.3681272554154299, disc_loss = 0.17948440293572387
Trained batch 245 in epoch 1, gen_loss = 0.36823276690835877, disc_loss = 0.17883292734017217
Trained batch 246 in epoch 1, gen_loss = 0.3686134646296019, disc_loss = 0.17825415834543193
Trained batch 247 in epoch 1, gen_loss = 0.369122578732429, disc_loss = 0.1778020070895793
Trained batch 248 in epoch 1, gen_loss = 0.36894236247702294, disc_loss = 0.17720776964652252
Trained batch 249 in epoch 1, gen_loss = 0.3688792219161987, disc_loss = 0.17681180111318825
Trained batch 250 in epoch 1, gen_loss = 0.36918613504603565, disc_loss = 0.17663893950323897
Trained batch 251 in epoch 1, gen_loss = 0.3691160101739187, disc_loss = 0.17606826802893055
Trained batch 252 in epoch 1, gen_loss = 0.36908171923735394, disc_loss = 0.17551330763390177
Trained batch 253 in epoch 1, gen_loss = 0.36935195432403894, disc_loss = 0.17496874498012732
Trained batch 254 in epoch 1, gen_loss = 0.3694605480222141, disc_loss = 0.17450873262303718
Trained batch 255 in epoch 1, gen_loss = 0.3695856658741832, disc_loss = 0.17467562837555306
Trained batch 256 in epoch 1, gen_loss = 0.3702272673061386, disc_loss = 0.17469938169686478
Trained batch 257 in epoch 1, gen_loss = 0.37045885564744935, disc_loss = 0.17413961028232594
Trained batch 258 in epoch 1, gen_loss = 0.37069000125391605, disc_loss = 0.17374453185895694
Trained batch 259 in epoch 1, gen_loss = 0.37090783485999473, disc_loss = 0.17324842756184247
Trained batch 260 in epoch 1, gen_loss = 0.3709554875490766, disc_loss = 0.17270867014125388
Trained batch 261 in epoch 1, gen_loss = 0.3710726247034, disc_loss = 0.17210884142723928
Trained batch 262 in epoch 1, gen_loss = 0.370965064138514, disc_loss = 0.17153445473330328
Trained batch 263 in epoch 1, gen_loss = 0.3710941464611978, disc_loss = 0.17097714204679837
Trained batch 264 in epoch 1, gen_loss = 0.3708154168893706, disc_loss = 0.17042692456886455
Trained batch 265 in epoch 1, gen_loss = 0.37091441855842905, disc_loss = 0.1698200685686355
Trained batch 266 in epoch 1, gen_loss = 0.37107151914178654, disc_loss = 0.1692589359385858
Trained batch 267 in epoch 1, gen_loss = 0.3716762273836492, disc_loss = 0.16872185446085658
Trained batch 268 in epoch 1, gen_loss = 0.37204628905842296, disc_loss = 0.16814803571326029
Trained batch 269 in epoch 1, gen_loss = 0.3724215668660623, disc_loss = 0.16757479776731796
Trained batch 270 in epoch 1, gen_loss = 0.372479083683218, disc_loss = 0.16700271659657853
Trained batch 271 in epoch 1, gen_loss = 0.3726124358089531, disc_loss = 0.16645936103304848
Trained batch 272 in epoch 1, gen_loss = 0.372659900358745, disc_loss = 0.165925686568322
Trained batch 273 in epoch 1, gen_loss = 0.3729407220643802, disc_loss = 0.16535680453857257
Trained batch 274 in epoch 1, gen_loss = 0.37302683732726355, disc_loss = 0.1648099191419103
Trained batch 275 in epoch 1, gen_loss = 0.3733836126284323, disc_loss = 0.16426457337481712
Trained batch 276 in epoch 1, gen_loss = 0.3733039434851292, disc_loss = 0.163777050716863
Trained batch 277 in epoch 1, gen_loss = 0.37306760991219995, disc_loss = 0.16373284594926366
Trained batch 278 in epoch 1, gen_loss = 0.3736399907792341, disc_loss = 0.1638351287859689
Trained batch 279 in epoch 1, gen_loss = 0.3739706642925739, disc_loss = 0.1633131082003404
Trained batch 280 in epoch 1, gen_loss = 0.37404490726274103, disc_loss = 0.16285951721591352
Trained batch 281 in epoch 1, gen_loss = 0.37411975860595703, disc_loss = 0.16239835316288873
Trained batch 282 in epoch 1, gen_loss = 0.37415531930569623, disc_loss = 0.16185883021265163
Trained batch 283 in epoch 1, gen_loss = 0.3743092102903715, disc_loss = 0.16147545076460695
Trained batch 284 in epoch 1, gen_loss = 0.37423972999840455, disc_loss = 0.16148580199663054
Trained batch 285 in epoch 1, gen_loss = 0.37415257127551765, disc_loss = 0.16120399953471823
Trained batch 286 in epoch 1, gen_loss = 0.3741377878687523, disc_loss = 0.16076157262178872
Trained batch 287 in epoch 1, gen_loss = 0.37467324506077504, disc_loss = 0.16068106037952626
Trained batch 288 in epoch 1, gen_loss = 0.3746861867013687, disc_loss = 0.16020015515644864
Trained batch 289 in epoch 1, gen_loss = 0.37460968114178755, disc_loss = 0.15976469219373218
Trained batch 290 in epoch 1, gen_loss = 0.37486624553850834, disc_loss = 0.15931743024960415
Trained batch 291 in epoch 1, gen_loss = 0.3751169852402112, disc_loss = 0.15905748152059235
Trained batch 292 in epoch 1, gen_loss = 0.3752228833302703, disc_loss = 0.1586371164247648
Trained batch 293 in epoch 1, gen_loss = 0.37563295084602977, disc_loss = 0.15818637653830506
Trained batch 294 in epoch 1, gen_loss = 0.3757485256356708, disc_loss = 0.15778058757216243
Trained batch 295 in epoch 1, gen_loss = 0.37570805908054916, disc_loss = 0.15732117799563786
Trained batch 296 in epoch 1, gen_loss = 0.3757335332909016, disc_loss = 0.15682142925596096
Trained batch 297 in epoch 1, gen_loss = 0.3757989313578446, disc_loss = 0.15633134008541502
Trained batch 298 in epoch 1, gen_loss = 0.37577499384465424, disc_loss = 0.15587189897309278
Trained batch 299 in epoch 1, gen_loss = 0.37603206555048624, disc_loss = 0.1554219855957975
Trained batch 300 in epoch 1, gen_loss = 0.3761832440810346, disc_loss = 0.15494227491356308
Trained batch 301 in epoch 1, gen_loss = 0.3762344852188565, disc_loss = 0.15453134817287129
Trained batch 302 in epoch 1, gen_loss = 0.3761586914754937, disc_loss = 0.15453503086314638
Trained batch 303 in epoch 1, gen_loss = 0.37654831789826093, disc_loss = 0.15507245788926652
Trained batch 304 in epoch 1, gen_loss = 0.37647055827203346, disc_loss = 0.1549324266459854
Trained batch 305 in epoch 1, gen_loss = 0.3766162646751778, disc_loss = 0.15456049718583623
Trained batch 306 in epoch 1, gen_loss = 0.3767399406394275, disc_loss = 0.1543158083784027
Trained batch 307 in epoch 1, gen_loss = 0.37660972590183284, disc_loss = 0.15434161895075693
Trained batch 308 in epoch 1, gen_loss = 0.37682793065182213, disc_loss = 0.15440678757744988
Trained batch 309 in epoch 1, gen_loss = 0.37677867028021045, disc_loss = 0.15401389936225549
Trained batch 310 in epoch 1, gen_loss = 0.37669278235680803, disc_loss = 0.15392804961244297
Trained batch 311 in epoch 1, gen_loss = 0.37697141779920995, disc_loss = 0.15523689709162006
Trained batch 312 in epoch 1, gen_loss = 0.37672110439870304, disc_loss = 0.15500808562845372
Trained batch 313 in epoch 1, gen_loss = 0.376515313698228, disc_loss = 0.1550916885203759
Trained batch 314 in epoch 1, gen_loss = 0.3765916027720012, disc_loss = 0.15496393752890447
Trained batch 315 in epoch 1, gen_loss = 0.3764547074708757, disc_loss = 0.15472917233688074
Trained batch 316 in epoch 1, gen_loss = 0.37640844149168357, disc_loss = 0.1545426824485607
Trained batch 317 in epoch 1, gen_loss = 0.37659238072686224, disc_loss = 0.15420860830846728
Trained batch 318 in epoch 1, gen_loss = 0.37664193064441504, disc_loss = 0.15387675914399582
Trained batch 319 in epoch 1, gen_loss = 0.37682581320405006, disc_loss = 0.15399066257232336
Trained batch 320 in epoch 1, gen_loss = 0.3765253406076045, disc_loss = 0.15482283131483465
Trained batch 321 in epoch 1, gen_loss = 0.37673278458370185, disc_loss = 0.1546373699201699
Trained batch 322 in epoch 1, gen_loss = 0.37664523277858464, disc_loss = 0.15485568207057177
Trained batch 323 in epoch 1, gen_loss = 0.37641253929447244, disc_loss = 0.15482063872889143
Trained batch 324 in epoch 1, gen_loss = 0.3764714337312258, disc_loss = 0.15501818428532435
Trained batch 325 in epoch 1, gen_loss = 0.37664792618137194, disc_loss = 0.15505907214618075
Trained batch 326 in epoch 1, gen_loss = 0.3766141455472427, disc_loss = 0.15478046510414156
Trained batch 327 in epoch 1, gen_loss = 0.3765442373185623, disc_loss = 0.15455487846090207
Trained batch 328 in epoch 1, gen_loss = 0.3765084891152599, disc_loss = 0.1544242201508858
Trained batch 329 in epoch 1, gen_loss = 0.37651300240646707, disc_loss = 0.15430299222864435
Trained batch 330 in epoch 1, gen_loss = 0.3764047626282153, disc_loss = 0.1540211397687429
Trained batch 331 in epoch 1, gen_loss = 0.37686805929764206, disc_loss = 0.15376932189395898
Trained batch 332 in epoch 1, gen_loss = 0.3770420194209159, disc_loss = 0.1533966420900759
Trained batch 333 in epoch 1, gen_loss = 0.3770235716225858, disc_loss = 0.15308869275693854
Trained batch 334 in epoch 1, gen_loss = 0.37729225140898975, disc_loss = 0.15314316605287256
Trained batch 335 in epoch 1, gen_loss = 0.3772948872120607, disc_loss = 0.15348350272480665
Trained batch 336 in epoch 1, gen_loss = 0.37713256451779376, disc_loss = 0.1532727732220858
Trained batch 337 in epoch 1, gen_loss = 0.3770720461416527, disc_loss = 0.15302531769741656
Trained batch 338 in epoch 1, gen_loss = 0.37701719823488444, disc_loss = 0.1528839532280434
Trained batch 339 in epoch 1, gen_loss = 0.3772984259268817, disc_loss = 0.15284269719713311
Trained batch 340 in epoch 1, gen_loss = 0.37731474908915436, disc_loss = 0.15263447392994095
Trained batch 341 in epoch 1, gen_loss = 0.37723279295609013, disc_loss = 0.15230653331783867
Trained batch 342 in epoch 1, gen_loss = 0.37738045137755727, disc_loss = 0.15194618788007483
Trained batch 343 in epoch 1, gen_loss = 0.3776121079748453, disc_loss = 0.15156753867225678
Trained batch 344 in epoch 1, gen_loss = 0.3777400288892829, disc_loss = 0.15130394104652214
Trained batch 345 in epoch 1, gen_loss = 0.37767752005874766, disc_loss = 0.15096149907172846
Trained batch 346 in epoch 1, gen_loss = 0.3778602461134666, disc_loss = 0.1508573122263513
Trained batch 347 in epoch 1, gen_loss = 0.3782329084030513, disc_loss = 0.15073974299158943
Trained batch 348 in epoch 1, gen_loss = 0.37819217935332594, disc_loss = 0.1503756769764688
Trained batch 349 in epoch 1, gen_loss = 0.37814352444240024, disc_loss = 0.15056992566745195
Trained batch 350 in epoch 1, gen_loss = 0.3780864368476759, disc_loss = 0.15111425138765847
Trained batch 351 in epoch 1, gen_loss = 0.3781061511148106, disc_loss = 0.15132012385187077
Trained batch 352 in epoch 1, gen_loss = 0.3783177003137788, disc_loss = 0.15132940729167155
Trained batch 353 in epoch 1, gen_loss = 0.37829714895641736, disc_loss = 0.1512492858268068
Trained batch 354 in epoch 1, gen_loss = 0.37832323421894665, disc_loss = 0.15102440737660083
Trained batch 355 in epoch 1, gen_loss = 0.3782792213592636, disc_loss = 0.15080245969074077
Trained batch 356 in epoch 1, gen_loss = 0.37816084199258926, disc_loss = 0.15061922160339872
Trained batch 357 in epoch 1, gen_loss = 0.37806241622184245, disc_loss = 0.15046607338506
Trained batch 358 in epoch 1, gen_loss = 0.3780294202662444, disc_loss = 0.15036418888468844
Trained batch 359 in epoch 1, gen_loss = 0.37817998727162677, disc_loss = 0.15013626859161175
Trained batch 360 in epoch 1, gen_loss = 0.37824564140259065, disc_loss = 0.15003286068614088
Trained batch 361 in epoch 1, gen_loss = 0.37848890461645074, disc_loss = 0.14983650883248087
Trained batch 362 in epoch 1, gen_loss = 0.3782984842610425, disc_loss = 0.1496089417307789
Trained batch 363 in epoch 1, gen_loss = 0.3784398790244218, disc_loss = 0.14947852344702478
Trained batch 364 in epoch 1, gen_loss = 0.37807215386874055, disc_loss = 0.14981668885184884
Trained batch 365 in epoch 1, gen_loss = 0.37846599006261983, disc_loss = 0.1496307215134262
Trained batch 366 in epoch 1, gen_loss = 0.37835331784931775, disc_loss = 0.14934462867930978
Trained batch 367 in epoch 1, gen_loss = 0.378359060248603, disc_loss = 0.14901850957413326
Trained batch 368 in epoch 1, gen_loss = 0.37835415478967394, disc_loss = 0.14869302314097885
Trained batch 369 in epoch 1, gen_loss = 0.378197620688258, disc_loss = 0.14874952005323122
Trained batch 370 in epoch 1, gen_loss = 0.3780405227386084, disc_loss = 0.14957872560031893
Trained batch 371 in epoch 1, gen_loss = 0.3779110583246395, disc_loss = 0.14946400843590738
Trained batch 372 in epoch 1, gen_loss = 0.3779661959042178, disc_loss = 0.14985179466422618
Trained batch 373 in epoch 1, gen_loss = 0.37765872741446777, disc_loss = 0.150162347943527
Trained batch 374 in epoch 1, gen_loss = 0.3776295761267344, disc_loss = 0.15010253652681907
Trained batch 375 in epoch 1, gen_loss = 0.3775207539029578, disc_loss = 0.1502773128920532
Trained batch 376 in epoch 1, gen_loss = 0.3774331212043762, disc_loss = 0.15051811120030656
Trained batch 377 in epoch 1, gen_loss = 0.3770966604746208, disc_loss = 0.15071585960439826
Trained batch 378 in epoch 1, gen_loss = 0.3768027227440736, disc_loss = 0.15069977515241953
Trained batch 379 in epoch 1, gen_loss = 0.37661191538760536, disc_loss = 0.15063288957615825
Trained batch 380 in epoch 1, gen_loss = 0.37661439227306936, disc_loss = 0.1505655310436927
Trained batch 381 in epoch 1, gen_loss = 0.3765683174133301, disc_loss = 0.15042077918434565
Trained batch 382 in epoch 1, gen_loss = 0.37665106671286, disc_loss = 0.15015303460983243
Trained batch 383 in epoch 1, gen_loss = 0.3765593155597647, disc_loss = 0.15019827330979751
Trained batch 384 in epoch 1, gen_loss = 0.37636933102236164, disc_loss = 0.15046931863943866
Trained batch 385 in epoch 1, gen_loss = 0.3762380644447445, disc_loss = 0.15031256336342408
Trained batch 386 in epoch 1, gen_loss = 0.37630577158250245, disc_loss = 0.150209124455137
Trained batch 387 in epoch 1, gen_loss = 0.3762821735641391, disc_loss = 0.1500052147108063
Trained batch 388 in epoch 1, gen_loss = 0.3762829623216222, disc_loss = 0.14978325859928424
Trained batch 389 in epoch 1, gen_loss = 0.37620885311028895, disc_loss = 0.14953422685607504
Trained batch 390 in epoch 1, gen_loss = 0.3763583816225876, disc_loss = 0.14929080597074973
Trained batch 391 in epoch 1, gen_loss = 0.37641972113324673, disc_loss = 0.14905694792075652
Trained batch 392 in epoch 1, gen_loss = 0.3765636937308858, disc_loss = 0.14892407379447276
Trained batch 393 in epoch 1, gen_loss = 0.37652647533089983, disc_loss = 0.14899824139647905
Trained batch 394 in epoch 1, gen_loss = 0.37679958849013606, disc_loss = 0.14900891392055568
Trained batch 395 in epoch 1, gen_loss = 0.37692063422215105, disc_loss = 0.14873921545457583
Trained batch 396 in epoch 1, gen_loss = 0.3769061909214375, disc_loss = 0.14847198253267582
Trained batch 397 in epoch 1, gen_loss = 0.37691517833189747, disc_loss = 0.14819987412850985
Trained batch 398 in epoch 1, gen_loss = 0.37708406527538346, disc_loss = 0.1479088704738962
Trained batch 399 in epoch 1, gen_loss = 0.37714569792151453, disc_loss = 0.14761916385730728
Trained batch 400 in epoch 1, gen_loss = 0.37728979596473333, disc_loss = 0.14731432900919655
Trained batch 401 in epoch 1, gen_loss = 0.37745105612337293, disc_loss = 0.14700238675629693
Trained batch 402 in epoch 1, gen_loss = 0.3774985251000738, disc_loss = 0.1467001166855616
Trained batch 403 in epoch 1, gen_loss = 0.3776467870367636, disc_loss = 0.1463741141389871
Trained batch 404 in epoch 1, gen_loss = 0.3776161603721572, disc_loss = 0.1460683432534153
Trained batch 405 in epoch 1, gen_loss = 0.3778227766599561, disc_loss = 0.1457588245514138
Trained batch 406 in epoch 1, gen_loss = 0.37778386349174253, disc_loss = 0.14545290703892122
Trained batch 407 in epoch 1, gen_loss = 0.377919488312567, disc_loss = 0.14512348905041375
Trained batch 408 in epoch 1, gen_loss = 0.3779527692893898, disc_loss = 0.1448377811493384
Trained batch 409 in epoch 1, gen_loss = 0.3780710883256866, disc_loss = 0.14454893774648264
Trained batch 410 in epoch 1, gen_loss = 0.37812283809167624, disc_loss = 0.1443332906431743
Trained batch 411 in epoch 1, gen_loss = 0.3781997716976601, disc_loss = 0.1441127849806064
Trained batch 412 in epoch 1, gen_loss = 0.3782164284161159, disc_loss = 0.14382152777553037
Trained batch 413 in epoch 1, gen_loss = 0.37823071291193294, disc_loss = 0.14356820804971285
Trained batch 414 in epoch 1, gen_loss = 0.37846083633870964, disc_loss = 0.14355037702045526
Trained batch 415 in epoch 1, gen_loss = 0.3785073400403445, disc_loss = 0.14372548039626473
Trained batch 416 in epoch 1, gen_loss = 0.37862287015080165, disc_loss = 0.14364489238950418
Trained batch 417 in epoch 1, gen_loss = 0.37878691651034013, disc_loss = 0.14370457665397648
Trained batch 418 in epoch 1, gen_loss = 0.3788661342958846, disc_loss = 0.14352725497346933
Trained batch 419 in epoch 1, gen_loss = 0.3790886710087458, disc_loss = 0.143337359895841
Trained batch 420 in epoch 1, gen_loss = 0.379195013762653, disc_loss = 0.14309089939218378
Trained batch 421 in epoch 1, gen_loss = 0.37919586522601795, disc_loss = 0.14287351814685698
Trained batch 422 in epoch 1, gen_loss = 0.37927238371918953, disc_loss = 0.14256580027335503
Trained batch 423 in epoch 1, gen_loss = 0.3790671039583548, disc_loss = 0.14238633490870442
Trained batch 424 in epoch 1, gen_loss = 0.3792752170562744, disc_loss = 0.14227376085432136
Trained batch 425 in epoch 1, gen_loss = 0.3791592795524239, disc_loss = 0.14210298044843153
Trained batch 426 in epoch 1, gen_loss = 0.3791154805893641, disc_loss = 0.1418349405563059
Trained batch 427 in epoch 1, gen_loss = 0.3793037207187893, disc_loss = 0.14174859388949018
Trained batch 428 in epoch 1, gen_loss = 0.37909693345601186, disc_loss = 0.14170562020461738
Trained batch 429 in epoch 1, gen_loss = 0.37925771807515346, disc_loss = 0.14151927077233098
Trained batch 430 in epoch 1, gen_loss = 0.37936842393155995, disc_loss = 0.1412571667587674
Trained batch 431 in epoch 1, gen_loss = 0.37945915820697945, disc_loss = 0.14096235586718345
Trained batch 432 in epoch 1, gen_loss = 0.37949523302203786, disc_loss = 0.14068924269357194
Trained batch 433 in epoch 1, gen_loss = 0.379554100094303, disc_loss = 0.1407159399691849
Trained batch 434 in epoch 1, gen_loss = 0.3798136954334961, disc_loss = 0.1408472519175246
Trained batch 435 in epoch 1, gen_loss = 0.37976554678667573, disc_loss = 0.14085029906576174
Trained batch 436 in epoch 1, gen_loss = 0.37975266275744146, disc_loss = 0.14061325016373968
Trained batch 437 in epoch 1, gen_loss = 0.379806488003905, disc_loss = 0.14036360331364486
Trained batch 438 in epoch 1, gen_loss = 0.3797577525189906, disc_loss = 0.14019648319403036
Trained batch 439 in epoch 1, gen_loss = 0.379833509163423, disc_loss = 0.13995798981367527
Trained batch 440 in epoch 1, gen_loss = 0.3797821897227748, disc_loss = 0.13971047464741262
Trained batch 441 in epoch 1, gen_loss = 0.37987748988613285, disc_loss = 0.1395835730129204
Trained batch 442 in epoch 1, gen_loss = 0.37979650497436523, disc_loss = 0.13961557323916166
Trained batch 443 in epoch 1, gen_loss = 0.3799358086140306, disc_loss = 0.13977829074730408
Trained batch 444 in epoch 1, gen_loss = 0.3798654342635294, disc_loss = 0.13982813729789484
Trained batch 445 in epoch 1, gen_loss = 0.3800619451053474, disc_loss = 0.13955677591573296
Trained batch 446 in epoch 1, gen_loss = 0.3801291973665523, disc_loss = 0.139349834082994
Trained batch 447 in epoch 1, gen_loss = 0.38032536155411173, disc_loss = 0.13907832953555044
Trained batch 448 in epoch 1, gen_loss = 0.3802614714493996, disc_loss = 0.13884985976477043
Trained batch 449 in epoch 1, gen_loss = 0.3803125317229165, disc_loss = 0.1385798187698755
Trained batch 450 in epoch 1, gen_loss = 0.3803789984360502, disc_loss = 0.13828871885888658
Trained batch 451 in epoch 1, gen_loss = 0.3804409316023894, disc_loss = 0.1380224685757462
Trained batch 452 in epoch 1, gen_loss = 0.38051641540022085, disc_loss = 0.1377412826316246
Trained batch 453 in epoch 1, gen_loss = 0.38060709112016117, disc_loss = 0.1374550025903985
Trained batch 454 in epoch 1, gen_loss = 0.3806723049708775, disc_loss = 0.13721509056043002
Trained batch 455 in epoch 1, gen_loss = 0.3808943157394727, disc_loss = 0.1370299257135852
Trained batch 456 in epoch 1, gen_loss = 0.3808742208606044, disc_loss = 0.13677045590543804
Trained batch 457 in epoch 1, gen_loss = 0.3809196037366401, disc_loss = 0.13650069872677878
Trained batch 458 in epoch 1, gen_loss = 0.38102789901700157, disc_loss = 0.13624180839670932
Trained batch 459 in epoch 1, gen_loss = 0.3811144129089687, disc_loss = 0.13596063816170814
Trained batch 460 in epoch 1, gen_loss = 0.3812253726020035, disc_loss = 0.13568404003262616
Trained batch 461 in epoch 1, gen_loss = 0.3812144940549677, disc_loss = 0.13552840950584352
Trained batch 462 in epoch 1, gen_loss = 0.3810670597249437, disc_loss = 0.1366831042329111
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4376482367515564, disc_loss = 0.0542902946472168
Trained batch 1 in epoch 2, gen_loss = 0.3925626277923584, disc_loss = 0.08079783245921135
Trained batch 2 in epoch 2, gen_loss = 0.3721814254919688, disc_loss = 0.06720001250505447
Trained batch 3 in epoch 2, gen_loss = 0.3723170906305313, disc_loss = 0.0728797372430563
Trained batch 4 in epoch 2, gen_loss = 0.37386473417282107, disc_loss = 0.07210208624601364
Trained batch 5 in epoch 2, gen_loss = 0.3884526938199997, disc_loss = 0.06387026607990265
Trained batch 6 in epoch 2, gen_loss = 0.3958244834627424, disc_loss = 0.05843057696308408
Trained batch 7 in epoch 2, gen_loss = 0.39627616479992867, disc_loss = 0.052465022541582584
Trained batch 8 in epoch 2, gen_loss = 0.3961268862088521, disc_loss = 0.04868253486024009
Trained batch 9 in epoch 2, gen_loss = 0.39876789450645445, disc_loss = 0.04523754799738526
Trained batch 10 in epoch 2, gen_loss = 0.3998094228180972, disc_loss = 0.04388195216994394
Trained batch 11 in epoch 2, gen_loss = 0.40026748677094776, disc_loss = 0.04361558775417507
Trained batch 12 in epoch 2, gen_loss = 0.410596815439371, disc_loss = 0.04155159318962923
Trained batch 13 in epoch 2, gen_loss = 0.4059956989118031, disc_loss = 0.03971330615292702
Trained batch 14 in epoch 2, gen_loss = 0.4069335341453552, disc_loss = 0.03844015492747228
Trained batch 15 in epoch 2, gen_loss = 0.41231624968349934, disc_loss = 0.037809281318914145
Trained batch 16 in epoch 2, gen_loss = 0.4093024292412926, disc_loss = 0.036243292283924186
Trained batch 17 in epoch 2, gen_loss = 0.41004199120733476, disc_loss = 0.034670984424236745
Trained batch 18 in epoch 2, gen_loss = 0.4082904599214855, disc_loss = 0.03324290088034774
Trained batch 19 in epoch 2, gen_loss = 0.4096636831760406, disc_loss = 0.03267283027525991
Trained batch 20 in epoch 2, gen_loss = 0.4078699861254011, disc_loss = 0.03141015765833713
Trained batch 21 in epoch 2, gen_loss = 0.4089496000246568, disc_loss = 0.030521231301298194
Trained batch 22 in epoch 2, gen_loss = 0.40732353925704956, disc_loss = 0.029476443406842325
Trained batch 23 in epoch 2, gen_loss = 0.40574274212121964, disc_loss = 0.028554095692622166
Trained batch 24 in epoch 2, gen_loss = 0.4050299286842346, disc_loss = 0.028285760469734668
Trained batch 25 in epoch 2, gen_loss = 0.406300255885491, disc_loss = 0.02749459954121938
Trained batch 26 in epoch 2, gen_loss = 0.4066919066287853, disc_loss = 0.02695398977785199
Trained batch 27 in epoch 2, gen_loss = 0.4090078983988081, disc_loss = 0.026719327550381422
Trained batch 28 in epoch 2, gen_loss = 0.4107909521152233, disc_loss = 0.02604549374945205
Trained batch 29 in epoch 2, gen_loss = 0.41352289319038393, disc_loss = 0.025602413155138493
Trained batch 30 in epoch 2, gen_loss = 0.4146255571996012, disc_loss = 0.025012661913229574
Trained batch 31 in epoch 2, gen_loss = 0.4145108312368393, disc_loss = 0.024605769402114674
Trained batch 32 in epoch 2, gen_loss = 0.4132038779330976, disc_loss = 0.02579112664203752
Trained batch 33 in epoch 2, gen_loss = 0.41480080958674936, disc_loss = 0.029821212211733356
Trained batch 34 in epoch 2, gen_loss = 0.41250145265034266, disc_loss = 0.03173520051475082
Trained batch 35 in epoch 2, gen_loss = 0.41263652178976273, disc_loss = 0.031743194468112454
Trained batch 36 in epoch 2, gen_loss = 0.4148630024613561, disc_loss = 0.03335272196076206
Trained batch 37 in epoch 2, gen_loss = 0.4144161343574524, disc_loss = 0.03321836553023834
Trained batch 38 in epoch 2, gen_loss = 0.41308086728438353, disc_loss = 0.03294458008633974
Trained batch 39 in epoch 2, gen_loss = 0.41290577203035356, disc_loss = 0.03270729791838676
Trained batch 40 in epoch 2, gen_loss = 0.4136993870502565, disc_loss = 0.03270263963083669
Trained batch 41 in epoch 2, gen_loss = 0.41384750462713693, disc_loss = 0.032310996359835066
Trained batch 42 in epoch 2, gen_loss = 0.41363049939621327, disc_loss = 0.03208353597844063
Trained batch 43 in epoch 2, gen_loss = 0.41512771357189526, disc_loss = 0.031656706536358055
Trained batch 44 in epoch 2, gen_loss = 0.41476062734921776, disc_loss = 0.031244112013114823
Trained batch 45 in epoch 2, gen_loss = 0.4143824279308319, disc_loss = 0.030864962012223576
Trained batch 46 in epoch 2, gen_loss = 0.4139870931493475, disc_loss = 0.030557968673553874
Trained batch 47 in epoch 2, gen_loss = 0.4139049630612135, disc_loss = 0.03084527763227622
Trained batch 48 in epoch 2, gen_loss = 0.41473120025226046, disc_loss = 0.031040527762807146
Trained batch 49 in epoch 2, gen_loss = 0.41403838217258454, disc_loss = 0.03089734349399805
Trained batch 50 in epoch 2, gen_loss = 0.4125647702637841, disc_loss = 0.030462884654601414
Trained batch 51 in epoch 2, gen_loss = 0.4131143299432901, disc_loss = 0.030047867142666992
Trained batch 52 in epoch 2, gen_loss = 0.4125701548918238, disc_loss = 0.02961539143239552
Trained batch 53 in epoch 2, gen_loss = 0.4112902134656906, disc_loss = 0.029556408041605243
Trained batch 54 in epoch 2, gen_loss = 0.41209105307405647, disc_loss = 0.029409499737349423
Trained batch 55 in epoch 2, gen_loss = 0.4113513454794884, disc_loss = 0.029192460434777395
Trained batch 56 in epoch 2, gen_loss = 0.412097725429033, disc_loss = 0.029145194903800364
Trained batch 57 in epoch 2, gen_loss = 0.41109090067189313, disc_loss = 0.028832233960515465
Trained batch 58 in epoch 2, gen_loss = 0.41076732540534716, disc_loss = 0.02883739816814156
Trained batch 59 in epoch 2, gen_loss = 0.4125524585445722, disc_loss = 0.028786033919701973
Trained batch 60 in epoch 2, gen_loss = 0.4136596576112216, disc_loss = 0.028504503951942334
Trained batch 61 in epoch 2, gen_loss = 0.41309269878172106, disc_loss = 0.028235830201376832
Trained batch 62 in epoch 2, gen_loss = 0.4127939934768374, disc_loss = 0.027883917921119265
Trained batch 63 in epoch 2, gen_loss = 0.4118952243588865, disc_loss = 0.027591313075390644
Trained batch 64 in epoch 2, gen_loss = 0.4108694434165955, disc_loss = 0.02738183749696383
Trained batch 65 in epoch 2, gen_loss = 0.4104992485407627, disc_loss = 0.02711368596294161
Trained batch 66 in epoch 2, gen_loss = 0.4098538880917563, disc_loss = 0.02692091079957005
Trained batch 67 in epoch 2, gen_loss = 0.40848096416277047, disc_loss = 0.026665620492113865
Trained batch 68 in epoch 2, gen_loss = 0.40794791302819183, disc_loss = 0.026363488799635914
Trained batch 69 in epoch 2, gen_loss = 0.4089901864528656, disc_loss = 0.026269336231052876
Trained batch 70 in epoch 2, gen_loss = 0.4089877941239048, disc_loss = 0.02614921648842348
Trained batch 71 in epoch 2, gen_loss = 0.4082607887685299, disc_loss = 0.02616699984193676
Trained batch 72 in epoch 2, gen_loss = 0.40860192824716435, disc_loss = 0.02666215585825378
Trained batch 73 in epoch 2, gen_loss = 0.4080582973924843, disc_loss = 0.029575033641948894
Trained batch 74 in epoch 2, gen_loss = 0.4093810625871023, disc_loss = 0.03170272953808308
Trained batch 75 in epoch 2, gen_loss = 0.4080703458503673, disc_loss = 0.03305456245710191
Trained batch 76 in epoch 2, gen_loss = 0.40835722042368605, disc_loss = 0.0330635839226571
Trained batch 77 in epoch 2, gen_loss = 0.4085309944855861, disc_loss = 0.03500113977740208
Trained batch 78 in epoch 2, gen_loss = 0.4078189911721628, disc_loss = 0.0369111140836266
Trained batch 79 in epoch 2, gen_loss = 0.4085151754319668, disc_loss = 0.03745764202903956
Trained batch 80 in epoch 2, gen_loss = 0.4082156107013608, disc_loss = 0.037358877835450346
Trained batch 81 in epoch 2, gen_loss = 0.4080282228022087, disc_loss = 0.037236001069952805
Trained batch 82 in epoch 2, gen_loss = 0.4075791473130146, disc_loss = 0.036942110363259374
Trained batch 83 in epoch 2, gen_loss = 0.4073722476050967, disc_loss = 0.036689933034635726
Trained batch 84 in epoch 2, gen_loss = 0.4079053068862242, disc_loss = 0.03640044494805967
Trained batch 85 in epoch 2, gen_loss = 0.40761469061984573, disc_loss = 0.03632142023335016
Trained batch 86 in epoch 2, gen_loss = 0.4070440773991333, disc_loss = 0.03604099668305496
Trained batch 87 in epoch 2, gen_loss = 0.4073236154561693, disc_loss = 0.03576529785906049
Trained batch 88 in epoch 2, gen_loss = 0.4069572034176816, disc_loss = 0.03556625492703379
Trained batch 89 in epoch 2, gen_loss = 0.4070891777674357, disc_loss = 0.03524905398695005
Trained batch 90 in epoch 2, gen_loss = 0.40757963683578996, disc_loss = 0.034951954220349975
Trained batch 91 in epoch 2, gen_loss = 0.40738847041907517, disc_loss = 0.0346313314512372
Trained batch 92 in epoch 2, gen_loss = 0.40759838076048, disc_loss = 0.03440776757735719
Trained batch 93 in epoch 2, gen_loss = 0.40760540708582454, disc_loss = 0.034133967309397585
Trained batch 94 in epoch 2, gen_loss = 0.40794942598593864, disc_loss = 0.03387817076750492
Trained batch 95 in epoch 2, gen_loss = 0.4078346900641918, disc_loss = 0.03368449250895841
Trained batch 96 in epoch 2, gen_loss = 0.40769094351640683, disc_loss = 0.03341595955269853
Trained batch 97 in epoch 2, gen_loss = 0.40742378453819117, disc_loss = 0.03320928606945945
Trained batch 98 in epoch 2, gen_loss = 0.40753963981011904, disc_loss = 0.03293065290258388
Trained batch 99 in epoch 2, gen_loss = 0.40781956404447556, disc_loss = 0.0327166688349098
Trained batch 100 in epoch 2, gen_loss = 0.4078439692459484, disc_loss = 0.032501076846060774
Trained batch 101 in epoch 2, gen_loss = 0.4093174484430575, disc_loss = 0.03229335568589615
Trained batch 102 in epoch 2, gen_loss = 0.40902781660116994, disc_loss = 0.03203567909981007
Trained batch 103 in epoch 2, gen_loss = 0.40902774752332616, disc_loss = 0.031919885789438225
Trained batch 104 in epoch 2, gen_loss = 0.40964226296969825, disc_loss = 0.031745934739176716
Trained batch 105 in epoch 2, gen_loss = 0.40969063679002365, disc_loss = 0.03150598564677222
Trained batch 106 in epoch 2, gen_loss = 0.40952015647264284, disc_loss = 0.031341684090025794
Trained batch 107 in epoch 2, gen_loss = 0.4091720641763122, disc_loss = 0.031122421884598832
Trained batch 108 in epoch 2, gen_loss = 0.4088071562828274, disc_loss = 0.030899226216924026
Trained batch 109 in epoch 2, gen_loss = 0.40827188085425986, disc_loss = 0.03082608915442093
Trained batch 110 in epoch 2, gen_loss = 0.4079559260123485, disc_loss = 0.030594914048272477
Trained batch 111 in epoch 2, gen_loss = 0.40847557437207016, disc_loss = 0.030383436832510467
Trained batch 112 in epoch 2, gen_loss = 0.4085251913133976, disc_loss = 0.030170915965650198
Trained batch 113 in epoch 2, gen_loss = 0.408820872244082, disc_loss = 0.02998972416593971
Trained batch 114 in epoch 2, gen_loss = 0.40887006417564725, disc_loss = 0.0298630567955906
Trained batch 115 in epoch 2, gen_loss = 0.4084984937618519, disc_loss = 0.0296837986358602
Trained batch 116 in epoch 2, gen_loss = 0.4086348126586686, disc_loss = 0.029519808506513506
Trained batch 117 in epoch 2, gen_loss = 0.4081075779967389, disc_loss = 0.02946664273375803
Trained batch 118 in epoch 2, gen_loss = 0.4085578437612838, disc_loss = 0.02929945125346299
Trained batch 119 in epoch 2, gen_loss = 0.40879486575722696, disc_loss = 0.029119084142924596
Trained batch 120 in epoch 2, gen_loss = 0.40877840957365746, disc_loss = 0.028944903711426603
Trained batch 121 in epoch 2, gen_loss = 0.40895082593941295, disc_loss = 0.02875570984190849
Trained batch 122 in epoch 2, gen_loss = 0.4081958452375924, disc_loss = 0.028631125364785757
Trained batch 123 in epoch 2, gen_loss = 0.40856278231067045, disc_loss = 0.028494543388425823
Trained batch 124 in epoch 2, gen_loss = 0.4086021094322205, disc_loss = 0.02839880280941725
Trained batch 125 in epoch 2, gen_loss = 0.4082944289086357, disc_loss = 0.028356758471105307
Trained batch 126 in epoch 2, gen_loss = 0.4086121231552184, disc_loss = 0.02822299528955005
Trained batch 127 in epoch 2, gen_loss = 0.40889331069774926, disc_loss = 0.02813095810415689
Trained batch 128 in epoch 2, gen_loss = 0.408739812383356, disc_loss = 0.02818874276943447
Trained batch 129 in epoch 2, gen_loss = 0.40887012091966773, disc_loss = 0.02811015842912289
Trained batch 130 in epoch 2, gen_loss = 0.40934648927841477, disc_loss = 0.02797532024729343
Trained batch 131 in epoch 2, gen_loss = 0.40919851353674225, disc_loss = 0.02796923350825003
Trained batch 132 in epoch 2, gen_loss = 0.4093061067107925, disc_loss = 0.02803738948826055
Trained batch 133 in epoch 2, gen_loss = 0.4091329923761425, disc_loss = 0.02816138401238331
Trained batch 134 in epoch 2, gen_loss = 0.4093688348929087, disc_loss = 0.028149504614648997
Trained batch 135 in epoch 2, gen_loss = 0.4089519585318425, disc_loss = 0.028012226198745126
Trained batch 136 in epoch 2, gen_loss = 0.4091774281794137, disc_loss = 0.02789694980385095
Trained batch 137 in epoch 2, gen_loss = 0.40929341748140863, disc_loss = 0.027761176592953827
Trained batch 138 in epoch 2, gen_loss = 0.4096492837658889, disc_loss = 0.02767373981262497
Trained batch 139 in epoch 2, gen_loss = 0.4090092135327203, disc_loss = 0.02755795391941709
Trained batch 140 in epoch 2, gen_loss = 0.4090993446661225, disc_loss = 0.02745519783876255
Trained batch 141 in epoch 2, gen_loss = 0.4090585154546818, disc_loss = 0.02736409870304272
Trained batch 142 in epoch 2, gen_loss = 0.4087726359183972, disc_loss = 0.027325194433227284
Trained batch 143 in epoch 2, gen_loss = 0.4093153950654798, disc_loss = 0.027272114711296227
Trained batch 144 in epoch 2, gen_loss = 0.40982761198076706, disc_loss = 0.027229808270931244
Trained batch 145 in epoch 2, gen_loss = 0.4097896879666472, disc_loss = 0.027109292520797006
Trained batch 146 in epoch 2, gen_loss = 0.4094398599498126, disc_loss = 0.02711637531641592
Trained batch 147 in epoch 2, gen_loss = 0.4096662649834478, disc_loss = 0.027459131157327746
Trained batch 148 in epoch 2, gen_loss = 0.4093879181266631, disc_loss = 0.028004537049005896
Trained batch 149 in epoch 2, gen_loss = 0.40969982782999675, disc_loss = 0.02793314082548022
Trained batch 150 in epoch 2, gen_loss = 0.4095230378851985, disc_loss = 0.027879868325660164
Trained batch 151 in epoch 2, gen_loss = 0.4094303989488828, disc_loss = 0.02790231366127141
Trained batch 152 in epoch 2, gen_loss = 0.4091909317409291, disc_loss = 0.027866094190554292
Trained batch 153 in epoch 2, gen_loss = 0.40971147936659974, disc_loss = 0.028076599926578922
Trained batch 154 in epoch 2, gen_loss = 0.4096890132273397, disc_loss = 0.02840220926389579
Trained batch 155 in epoch 2, gen_loss = 0.4092606787498181, disc_loss = 0.02861045530806176
Trained batch 156 in epoch 2, gen_loss = 0.40930070467055985, disc_loss = 0.028498382449956835
Trained batch 157 in epoch 2, gen_loss = 0.4089281845696365, disc_loss = 0.02854490601398711
Trained batch 158 in epoch 2, gen_loss = 0.40912374422985054, disc_loss = 0.02950590812021269
Trained batch 159 in epoch 2, gen_loss = 0.40878251753747463, disc_loss = 0.03152297344640829
Trained batch 160 in epoch 2, gen_loss = 0.40828121985707966, disc_loss = 0.031647752837410996
Trained batch 161 in epoch 2, gen_loss = 0.40796922772754857, disc_loss = 0.03180992015189043
Trained batch 162 in epoch 2, gen_loss = 0.4081985513491133, disc_loss = 0.031731666305725194
Trained batch 163 in epoch 2, gen_loss = 0.40816019675353676, disc_loss = 0.03162180694819587
Trained batch 164 in epoch 2, gen_loss = 0.4084670948259758, disc_loss = 0.031529040374990665
Trained batch 165 in epoch 2, gen_loss = 0.40815575995359077, disc_loss = 0.03148312836391739
Trained batch 166 in epoch 2, gen_loss = 0.4081412550218091, disc_loss = 0.03139575741471288
Trained batch 167 in epoch 2, gen_loss = 0.40786782652139664, disc_loss = 0.03202382879819544
Trained batch 168 in epoch 2, gen_loss = 0.40757541614171316, disc_loss = 0.03289439530282683
Trained batch 169 in epoch 2, gen_loss = 0.40774411646758807, disc_loss = 0.03306001888259369
Trained batch 170 in epoch 2, gen_loss = 0.4079106587764115, disc_loss = 0.03334544153546381
Trained batch 171 in epoch 2, gen_loss = 0.4082045338528101, disc_loss = 0.033282193864240896
Trained batch 172 in epoch 2, gen_loss = 0.40828784421689246, disc_loss = 0.03323805159916078
Trained batch 173 in epoch 2, gen_loss = 0.4081602730285162, disc_loss = 0.03319151271348712
Trained batch 174 in epoch 2, gen_loss = 0.40851819396018985, disc_loss = 0.033147448780281204
Trained batch 175 in epoch 2, gen_loss = 0.40811327946456993, disc_loss = 0.03330587109931829
Trained batch 176 in epoch 2, gen_loss = 0.4085641796306028, disc_loss = 0.03342064045958937
Trained batch 177 in epoch 2, gen_loss = 0.40855760353334836, disc_loss = 0.03332401108875703
Trained batch 178 in epoch 2, gen_loss = 0.4083236194522687, disc_loss = 0.033301095743585564
Trained batch 179 in epoch 2, gen_loss = 0.4086520226465331, disc_loss = 0.0333379005599353
Trained batch 180 in epoch 2, gen_loss = 0.4089209089950962, disc_loss = 0.03320622010907745
Trained batch 181 in epoch 2, gen_loss = 0.4088477238521471, disc_loss = 0.03315049903160268
Trained batch 182 in epoch 2, gen_loss = 0.4087901187073338, disc_loss = 0.0330158672066497
Trained batch 183 in epoch 2, gen_loss = 0.40873368699913437, disc_loss = 0.032874329585035375
Trained batch 184 in epoch 2, gen_loss = 0.4088945126211321, disc_loss = 0.032732765862365835
Trained batch 185 in epoch 2, gen_loss = 0.40888980047036244, disc_loss = 0.03260356430915655
Trained batch 186 in epoch 2, gen_loss = 0.4084734180394341, disc_loss = 0.0326108162410876
Trained batch 187 in epoch 2, gen_loss = 0.40809259484422966, disc_loss = 0.03267452383086957
Trained batch 188 in epoch 2, gen_loss = 0.40799028122866593, disc_loss = 0.03258332517244434
Trained batch 189 in epoch 2, gen_loss = 0.407951451602735, disc_loss = 0.03247994496977251
Trained batch 190 in epoch 2, gen_loss = 0.40760605622336504, disc_loss = 0.03234274837271315
Trained batch 191 in epoch 2, gen_loss = 0.40693352402498323, disc_loss = 0.032269586272983965
Trained batch 192 in epoch 2, gen_loss = 0.4072539160906342, disc_loss = 0.032667373985032805
Trained batch 193 in epoch 2, gen_loss = 0.4069218824511951, disc_loss = 0.033236098511759
Trained batch 194 in epoch 2, gen_loss = 0.4072888678465134, disc_loss = 0.03336666410502333
Trained batch 195 in epoch 2, gen_loss = 0.4073606861793265, disc_loss = 0.033338457951797365
Trained batch 196 in epoch 2, gen_loss = 0.4072546031571887, disc_loss = 0.0332708873568566
Trained batch 197 in epoch 2, gen_loss = 0.4069539648715896, disc_loss = 0.03317070674066516
Trained batch 198 in epoch 2, gen_loss = 0.40739630844125796, disc_loss = 0.03304899220200415
Trained batch 199 in epoch 2, gen_loss = 0.40749450504779816, disc_loss = 0.03292889795033261
Trained batch 200 in epoch 2, gen_loss = 0.407387103903946, disc_loss = 0.0327922322356434
Trained batch 201 in epoch 2, gen_loss = 0.4072884397931618, disc_loss = 0.032661101946810094
Trained batch 202 in epoch 2, gen_loss = 0.4071067706704727, disc_loss = 0.03257116032167902
Trained batch 203 in epoch 2, gen_loss = 0.40709377664561364, disc_loss = 0.0324835734734056
Trained batch 204 in epoch 2, gen_loss = 0.4065172323366491, disc_loss = 0.03238990961051569
Trained batch 205 in epoch 2, gen_loss = 0.40650108688085984, disc_loss = 0.03230888387459575
Trained batch 206 in epoch 2, gen_loss = 0.40667805997069906, disc_loss = 0.03221346240868603
Trained batch 207 in epoch 2, gen_loss = 0.4064838417734091, disc_loss = 0.03233244890669504
Trained batch 208 in epoch 2, gen_loss = 0.40663470734249463, disc_loss = 0.03225602220262637
Trained batch 209 in epoch 2, gen_loss = 0.4065975329705647, disc_loss = 0.03225005369278647
Trained batch 210 in epoch 2, gen_loss = 0.40630681494965937, disc_loss = 0.032396815337629115
Trained batch 211 in epoch 2, gen_loss = 0.4065667178552106, disc_loss = 0.03230471935404359
Trained batch 212 in epoch 2, gen_loss = 0.4065285409000558, disc_loss = 0.0321793344894975
Trained batch 213 in epoch 2, gen_loss = 0.40664052865772604, disc_loss = 0.032073455222960665
Trained batch 214 in epoch 2, gen_loss = 0.40656672840894653, disc_loss = 0.03195276083641274
Trained batch 215 in epoch 2, gen_loss = 0.406613492027477, disc_loss = 0.0318287935073453
Trained batch 216 in epoch 2, gen_loss = 0.4064164507773615, disc_loss = 0.03177257149999592
Trained batch 217 in epoch 2, gen_loss = 0.4067265575905459, disc_loss = 0.03174543541369088
Trained batch 218 in epoch 2, gen_loss = 0.4069173527907019, disc_loss = 0.0317339743211117
Trained batch 219 in epoch 2, gen_loss = 0.40677825605327433, disc_loss = 0.03163510578769174
Trained batch 220 in epoch 2, gen_loss = 0.40689165505888236, disc_loss = 0.031524296135671134
Trained batch 221 in epoch 2, gen_loss = 0.4066144022587183, disc_loss = 0.03145627402448775
Trained batch 222 in epoch 2, gen_loss = 0.40682781891972497, disc_loss = 0.031342440019591376
Trained batch 223 in epoch 2, gen_loss = 0.4069003983001624, disc_loss = 0.03125333703480594
Trained batch 224 in epoch 2, gen_loss = 0.4068708552254571, disc_loss = 0.031142839828713072
Trained batch 225 in epoch 2, gen_loss = 0.4066411636571969, disc_loss = 0.031034906289696827
Trained batch 226 in epoch 2, gen_loss = 0.4069456203393474, disc_loss = 0.030929951438278223
Trained batch 227 in epoch 2, gen_loss = 0.4067218495826972, disc_loss = 0.030812502189196254
Trained batch 228 in epoch 2, gen_loss = 0.40667091719968873, disc_loss = 0.03070897969323735
Trained batch 229 in epoch 2, gen_loss = 0.40695404177126676, disc_loss = 0.03061004411429167
Trained batch 230 in epoch 2, gen_loss = 0.4068668685950242, disc_loss = 0.030518024853426657
Trained batch 231 in epoch 2, gen_loss = 0.4070449721967352, disc_loss = 0.03041665450316565
Trained batch 232 in epoch 2, gen_loss = 0.407246747242023, disc_loss = 0.03040032436503617
Trained batch 233 in epoch 2, gen_loss = 0.4075325645952143, disc_loss = 0.03030591107841231
Trained batch 234 in epoch 2, gen_loss = 0.40787891999204107, disc_loss = 0.030218267147528365
Trained batch 235 in epoch 2, gen_loss = 0.40789657919588734, disc_loss = 0.030119832145381657
Trained batch 236 in epoch 2, gen_loss = 0.4083396909357626, disc_loss = 0.030029874524879683
Trained batch 237 in epoch 2, gen_loss = 0.40822247647437726, disc_loss = 0.02993571844945873
Trained batch 238 in epoch 2, gen_loss = 0.4079625428221715, disc_loss = 0.02983681029332295
Trained batch 239 in epoch 2, gen_loss = 0.4081505823880434, disc_loss = 0.029745222113948935
Trained batch 240 in epoch 2, gen_loss = 0.40812637981537464, disc_loss = 0.02964228483813494
Trained batch 241 in epoch 2, gen_loss = 0.40804350585484306, disc_loss = 0.02955172055647208
Trained batch 242 in epoch 2, gen_loss = 0.40793063230965854, disc_loss = 0.02950159688920948
Trained batch 243 in epoch 2, gen_loss = 0.40792086854821347, disc_loss = 0.02943335608846401
Trained batch 244 in epoch 2, gen_loss = 0.40783808134040056, disc_loss = 0.02935676048034612
Trained batch 245 in epoch 2, gen_loss = 0.40745485216621463, disc_loss = 0.029310306407344656
Trained batch 246 in epoch 2, gen_loss = 0.4073912480823424, disc_loss = 0.029224442282261755
Trained batch 247 in epoch 2, gen_loss = 0.40746788308024406, disc_loss = 0.02913924916684928
Trained batch 248 in epoch 2, gen_loss = 0.4077618985051611, disc_loss = 0.02906556043167969
Trained batch 249 in epoch 2, gen_loss = 0.4076400154829025, disc_loss = 0.029099365638569
Trained batch 250 in epoch 2, gen_loss = 0.4076450917112875, disc_loss = 0.02907194337618363
Trained batch 251 in epoch 2, gen_loss = 0.40772902338750777, disc_loss = 0.028976196530348962
Trained batch 252 in epoch 2, gen_loss = 0.40788661620833655, disc_loss = 0.028907561347094685
Trained batch 253 in epoch 2, gen_loss = 0.40790448026863607, disc_loss = 0.028818063903599977
Trained batch 254 in epoch 2, gen_loss = 0.40769989256765327, disc_loss = 0.028755497852084682
Trained batch 255 in epoch 2, gen_loss = 0.40762626845389605, disc_loss = 0.028738219101796858
Trained batch 256 in epoch 2, gen_loss = 0.4076174098693907, disc_loss = 0.02870700453273981
Trained batch 257 in epoch 2, gen_loss = 0.4075603187084198, disc_loss = 0.028612423966126156
Trained batch 258 in epoch 2, gen_loss = 0.4072871200136236, disc_loss = 0.02855639481507098
Trained batch 259 in epoch 2, gen_loss = 0.4073058198277767, disc_loss = 0.028499667167377014
Trained batch 260 in epoch 2, gen_loss = 0.4074101844281529, disc_loss = 0.028415626730284586
Trained batch 261 in epoch 2, gen_loss = 0.40715346081566267, disc_loss = 0.02832423560747891
Trained batch 262 in epoch 2, gen_loss = 0.40681656231898317, disc_loss = 0.028246116555320673
Trained batch 263 in epoch 2, gen_loss = 0.40702670620697917, disc_loss = 0.02818301074192718
Trained batch 264 in epoch 2, gen_loss = 0.4070997212293013, disc_loss = 0.028101433205576436
Trained batch 265 in epoch 2, gen_loss = 0.40707359054034814, disc_loss = 0.02801723347948794
Trained batch 266 in epoch 2, gen_loss = 0.40697834487264967, disc_loss = 0.027948497606211164
Trained batch 267 in epoch 2, gen_loss = 0.4070419629118336, disc_loss = 0.027859510388225317
Trained batch 268 in epoch 2, gen_loss = 0.40690932397948765, disc_loss = 0.02777186643373789
Trained batch 269 in epoch 2, gen_loss = 0.40689793162875704, disc_loss = 0.027690989134350308
Trained batch 270 in epoch 2, gen_loss = 0.407146556241046, disc_loss = 0.027605553686866242
Trained batch 271 in epoch 2, gen_loss = 0.40738783787716837, disc_loss = 0.027523491548730388
Trained batch 272 in epoch 2, gen_loss = 0.40762529235619765, disc_loss = 0.027474860640263166
Trained batch 273 in epoch 2, gen_loss = 0.40770168232656745, disc_loss = 0.02740093157966587
Trained batch 274 in epoch 2, gen_loss = 0.4076077958670529, disc_loss = 0.027412263417447156
Trained batch 275 in epoch 2, gen_loss = 0.4077328905679177, disc_loss = 0.02737066586184707
Trained batch 276 in epoch 2, gen_loss = 0.40790540313462487, disc_loss = 0.027314532744876423
Trained batch 277 in epoch 2, gen_loss = 0.4079784711273454, disc_loss = 0.02723512835398638
Trained batch 278 in epoch 2, gen_loss = 0.40826765877798893, disc_loss = 0.027177981705167813
Trained batch 279 in epoch 2, gen_loss = 0.4083065468285765, disc_loss = 0.027168654657102057
Trained batch 280 in epoch 2, gen_loss = 0.4084029311175024, disc_loss = 0.027159253784929307
Trained batch 281 in epoch 2, gen_loss = 0.4083003004391988, disc_loss = 0.027106852921267563
Trained batch 282 in epoch 2, gen_loss = 0.408284184578872, disc_loss = 0.02713175280868691
Trained batch 283 in epoch 2, gen_loss = 0.408098568169164, disc_loss = 0.02705452546254325
Trained batch 284 in epoch 2, gen_loss = 0.4082662338750404, disc_loss = 0.027001191901141093
Trained batch 285 in epoch 2, gen_loss = 0.4084125512338185, disc_loss = 0.02692206097616964
Trained batch 286 in epoch 2, gen_loss = 0.40845237397150713, disc_loss = 0.026852520724648176
Trained batch 287 in epoch 2, gen_loss = 0.4084004523853461, disc_loss = 0.026772886817020156
Trained batch 288 in epoch 2, gen_loss = 0.408310601868019, disc_loss = 0.026696741814599422
Trained batch 289 in epoch 2, gen_loss = 0.4086340565105964, disc_loss = 0.026659691136266137
Trained batch 290 in epoch 2, gen_loss = 0.4083498867926319, disc_loss = 0.02665086828741882
Trained batch 291 in epoch 2, gen_loss = 0.4084058768332821, disc_loss = 0.02659204956750092
Trained batch 292 in epoch 2, gen_loss = 0.4085553857043335, disc_loss = 0.026585464316512437
Trained batch 293 in epoch 2, gen_loss = 0.40854419402930203, disc_loss = 0.0265159122028141
Trained batch 294 in epoch 2, gen_loss = 0.4087127553204359, disc_loss = 0.02648183504056375
Trained batch 295 in epoch 2, gen_loss = 0.40896216226187915, disc_loss = 0.026414845983585896
Trained batch 296 in epoch 2, gen_loss = 0.4088964489373294, disc_loss = 0.026361848254333742
Trained batch 297 in epoch 2, gen_loss = 0.4090037101867215, disc_loss = 0.026296234494325197
Trained batch 298 in epoch 2, gen_loss = 0.4089675568617307, disc_loss = 0.026314241454989517
Trained batch 299 in epoch 2, gen_loss = 0.4086793898542722, disc_loss = 0.026547349491156638
Trained batch 300 in epoch 2, gen_loss = 0.4088939813482405, disc_loss = 0.02675047672610495
Trained batch 301 in epoch 2, gen_loss = 0.4085380571172727, disc_loss = 0.02692968755904955
Trained batch 302 in epoch 2, gen_loss = 0.40844032561818366, disc_loss = 0.02725146774651341
Trained batch 303 in epoch 2, gen_loss = 0.40846395267075614, disc_loss = 0.027397755262331645
Trained batch 304 in epoch 2, gen_loss = 0.4084846740863362, disc_loss = 0.0274569721968814
Trained batch 305 in epoch 2, gen_loss = 0.4082333096881318, disc_loss = 0.027505361503964057
Trained batch 306 in epoch 2, gen_loss = 0.4083864219996362, disc_loss = 0.027459694204566825
Trained batch 307 in epoch 2, gen_loss = 0.4084647513635747, disc_loss = 0.027478841549184705
Trained batch 308 in epoch 2, gen_loss = 0.4083088511980853, disc_loss = 0.028510226248718292
Trained batch 309 in epoch 2, gen_loss = 0.4085029378052681, disc_loss = 0.029560234125763658
Trained batch 310 in epoch 2, gen_loss = 0.4084218024632555, disc_loss = 0.029753335435662144
Trained batch 311 in epoch 2, gen_loss = 0.40836646761267614, disc_loss = 0.029995896081881933
Trained batch 312 in epoch 2, gen_loss = 0.40826832134121904, disc_loss = 0.030154469097181915
Trained batch 313 in epoch 2, gen_loss = 0.40797888017763756, disc_loss = 0.03031572834054708
Trained batch 314 in epoch 2, gen_loss = 0.40826109865355115, disc_loss = 0.0304251237210655
Trained batch 315 in epoch 2, gen_loss = 0.40808468510078477, disc_loss = 0.03041107455545541
Trained batch 316 in epoch 2, gen_loss = 0.4078715824366368, disc_loss = 0.030528119901835637
Trained batch 317 in epoch 2, gen_loss = 0.40809607796324127, disc_loss = 0.03115596470376184
Trained batch 318 in epoch 2, gen_loss = 0.407960129101822, disc_loss = 0.03141655198803469
Trained batch 319 in epoch 2, gen_loss = 0.40805185940116645, disc_loss = 0.032391764763451646
Trained batch 320 in epoch 2, gen_loss = 0.407820390856526, disc_loss = 0.03339603662090463
Trained batch 321 in epoch 2, gen_loss = 0.407789792981207, disc_loss = 0.03372931404484679
Trained batch 322 in epoch 2, gen_loss = 0.40756137701379996, disc_loss = 0.03421413149229098
Trained batch 323 in epoch 2, gen_loss = 0.40742698983277803, disc_loss = 0.03470792210183716
Trained batch 324 in epoch 2, gen_loss = 0.4072783662722661, disc_loss = 0.03512432261585043
Trained batch 325 in epoch 2, gen_loss = 0.4073307623892474, disc_loss = 0.035314074441779156
Trained batch 326 in epoch 2, gen_loss = 0.40712344409493495, disc_loss = 0.03535983641275891
Trained batch 327 in epoch 2, gen_loss = 0.40694498970377735, disc_loss = 0.0353684784182938
Trained batch 328 in epoch 2, gen_loss = 0.4069025415055295, disc_loss = 0.035348146597608515
Trained batch 329 in epoch 2, gen_loss = 0.4066095185099226, disc_loss = 0.03537798689706533
Trained batch 330 in epoch 2, gen_loss = 0.4066538218285022, disc_loss = 0.035380250286153346
Trained batch 331 in epoch 2, gen_loss = 0.40672648464699823, disc_loss = 0.035310139249819496
Trained batch 332 in epoch 2, gen_loss = 0.40663960916144, disc_loss = 0.035284453677153355
Trained batch 333 in epoch 2, gen_loss = 0.4066838854087327, disc_loss = 0.035267682359860594
Trained batch 334 in epoch 2, gen_loss = 0.4067042617655512, disc_loss = 0.03520036627913811
Trained batch 335 in epoch 2, gen_loss = 0.40653534836712335, disc_loss = 0.03515712612092362
Trained batch 336 in epoch 2, gen_loss = 0.40648810233843435, disc_loss = 0.03510163515634857
Trained batch 337 in epoch 2, gen_loss = 0.40657801150217565, disc_loss = 0.03503920265870202
Trained batch 338 in epoch 2, gen_loss = 0.40673774595105894, disc_loss = 0.034961133399994765
Trained batch 339 in epoch 2, gen_loss = 0.4068195914520937, disc_loss = 0.03489003927200375
Trained batch 340 in epoch 2, gen_loss = 0.4067148919329266, disc_loss = 0.03481902249698197
Trained batch 341 in epoch 2, gen_loss = 0.4067761406563876, disc_loss = 0.034741435032501294
Trained batch 342 in epoch 2, gen_loss = 0.40665303201091535, disc_loss = 0.034659040563688244
Trained batch 343 in epoch 2, gen_loss = 0.40680907710000525, disc_loss = 0.03458342934433414
Trained batch 344 in epoch 2, gen_loss = 0.40665704072385594, disc_loss = 0.03450694339403856
Trained batch 345 in epoch 2, gen_loss = 0.4066679940230585, disc_loss = 0.034424576920462566
Trained batch 346 in epoch 2, gen_loss = 0.40679373461162666, disc_loss = 0.03435524701884269
Trained batch 347 in epoch 2, gen_loss = 0.4067901640102781, disc_loss = 0.0342690211937538
Trained batch 348 in epoch 2, gen_loss = 0.40690805585814754, disc_loss = 0.034189870681101325
Trained batch 349 in epoch 2, gen_loss = 0.4067832319225584, disc_loss = 0.034166199984028936
Trained batch 350 in epoch 2, gen_loss = 0.4070082648187621, disc_loss = 0.034372196910886936
Trained batch 351 in epoch 2, gen_loss = 0.406656510789286, disc_loss = 0.035038587545965456
Trained batch 352 in epoch 2, gen_loss = 0.40670861527534785, disc_loss = 0.03498022309860621
Trained batch 353 in epoch 2, gen_loss = 0.40676195742720267, disc_loss = 0.03535706555013055
Trained batch 354 in epoch 2, gen_loss = 0.4066200186668987, disc_loss = 0.03557788734783379
Trained batch 355 in epoch 2, gen_loss = 0.4064570828602555, disc_loss = 0.035569744465841255
Trained batch 356 in epoch 2, gen_loss = 0.40632950232810333, disc_loss = 0.035513694942028835
Trained batch 357 in epoch 2, gen_loss = 0.4060671417739804, disc_loss = 0.03559310161820795
Trained batch 358 in epoch 2, gen_loss = 0.40632555237387546, disc_loss = 0.03573016075074963
Trained batch 359 in epoch 2, gen_loss = 0.4062620720101727, disc_loss = 0.03585099259055116
Trained batch 360 in epoch 2, gen_loss = 0.4064275459734687, disc_loss = 0.035778469649863295
Trained batch 361 in epoch 2, gen_loss = 0.40644460760098133, disc_loss = 0.03571814714766298
Trained batch 362 in epoch 2, gen_loss = 0.4064696312114884, disc_loss = 0.03563475760069391
Trained batch 363 in epoch 2, gen_loss = 0.4065870384757335, disc_loss = 0.03556522463862835
Trained batch 364 in epoch 2, gen_loss = 0.4066562805273761, disc_loss = 0.035507493939454834
Trained batch 365 in epoch 2, gen_loss = 0.40679405849488054, disc_loss = 0.03542618947154511
Trained batch 366 in epoch 2, gen_loss = 0.4065154970341872, disc_loss = 0.03537430271140886
Trained batch 367 in epoch 2, gen_loss = 0.406567105051616, disc_loss = 0.03529824457718465
Trained batch 368 in epoch 2, gen_loss = 0.40673133060538025, disc_loss = 0.03521789867572264
Trained batch 369 in epoch 2, gen_loss = 0.4069074398762471, disc_loss = 0.035155000927782544
Trained batch 370 in epoch 2, gen_loss = 0.4069633032433749, disc_loss = 0.035081896893278446
Trained batch 371 in epoch 2, gen_loss = 0.4068999840847908, disc_loss = 0.03501212643459439
Trained batch 372 in epoch 2, gen_loss = 0.4070354472376386, disc_loss = 0.03497039878256519
Trained batch 373 in epoch 2, gen_loss = 0.4072357643256213, disc_loss = 0.03489247791190198
Trained batch 374 in epoch 2, gen_loss = 0.4071821653842926, disc_loss = 0.03481703901539246
Trained batch 375 in epoch 2, gen_loss = 0.4072116344691591, disc_loss = 0.034741245678308955
Trained batch 376 in epoch 2, gen_loss = 0.40714052951936697, disc_loss = 0.03469094856634775
Trained batch 377 in epoch 2, gen_loss = 0.40724454630935003, disc_loss = 0.034642552782007785
Trained batch 378 in epoch 2, gen_loss = 0.40731182143996447, disc_loss = 0.034573969662209145
Trained batch 379 in epoch 2, gen_loss = 0.4074764849323975, disc_loss = 0.03449822132794284
Trained batch 380 in epoch 2, gen_loss = 0.40758957684509395, disc_loss = 0.034419542254288525
Trained batch 381 in epoch 2, gen_loss = 0.4076143194243546, disc_loss = 0.034355107850897376
Trained batch 382 in epoch 2, gen_loss = 0.40786489089537536, disc_loss = 0.03428330354382802
Trained batch 383 in epoch 2, gen_loss = 0.4081555224644641, disc_loss = 0.034216929355655644
Trained batch 384 in epoch 2, gen_loss = 0.4082516921805097, disc_loss = 0.03415884168262218
Trained batch 385 in epoch 2, gen_loss = 0.4083509435153378, disc_loss = 0.03409404147155776
Trained batch 386 in epoch 2, gen_loss = 0.4084799726342046, disc_loss = 0.034022277799851286
Trained batch 387 in epoch 2, gen_loss = 0.4082897087347876, disc_loss = 0.03394507323319726
Trained batch 388 in epoch 2, gen_loss = 0.4082865113617522, disc_loss = 0.03386848259377257
Trained batch 389 in epoch 2, gen_loss = 0.4081363410521776, disc_loss = 0.03379987614372602
Trained batch 390 in epoch 2, gen_loss = 0.4081084575037212, disc_loss = 0.03372602193209026
Trained batch 391 in epoch 2, gen_loss = 0.4080894149991931, disc_loss = 0.033649972871620665
Trained batch 392 in epoch 2, gen_loss = 0.4081075165714623, disc_loss = 0.03357521205093077
Trained batch 393 in epoch 2, gen_loss = 0.407866301497227, disc_loss = 0.03350242638965208
Trained batch 394 in epoch 2, gen_loss = 0.4078258120560948, disc_loss = 0.033430539334452225
Trained batch 395 in epoch 2, gen_loss = 0.40789335951058553, disc_loss = 0.033373344039328096
Trained batch 396 in epoch 2, gen_loss = 0.40797271453763734, disc_loss = 0.03330374261955508
Trained batch 397 in epoch 2, gen_loss = 0.4079635804472257, disc_loss = 0.033235032070456215
Trained batch 398 in epoch 2, gen_loss = 0.4079973948629279, disc_loss = 0.033161623130335396
Trained batch 399 in epoch 2, gen_loss = 0.4082522913813591, disc_loss = 0.03309048541239463
Trained batch 400 in epoch 2, gen_loss = 0.4084373152910028, disc_loss = 0.03301964399922741
Trained batch 401 in epoch 2, gen_loss = 0.40852778542101087, disc_loss = 0.03294812815625276
Trained batch 402 in epoch 2, gen_loss = 0.40850645495999244, disc_loss = 0.03288109397178252
Trained batch 403 in epoch 2, gen_loss = 0.4085446698683323, disc_loss = 0.03283988807977426
Trained batch 404 in epoch 2, gen_loss = 0.4087064763646067, disc_loss = 0.032776781202604376
Trained batch 405 in epoch 2, gen_loss = 0.40866235133462353, disc_loss = 0.03270562046512576
Trained batch 406 in epoch 2, gen_loss = 0.40872602102504607, disc_loss = 0.03264007089643554
Trained batch 407 in epoch 2, gen_loss = 0.4087883270546502, disc_loss = 0.03257220818069946
Trained batch 408 in epoch 2, gen_loss = 0.40867216167356685, disc_loss = 0.032502602016744556
Trained batch 409 in epoch 2, gen_loss = 0.4087389624700314, disc_loss = 0.032432580838638654
Trained batch 410 in epoch 2, gen_loss = 0.408708925374813, disc_loss = 0.03236126082262745
Trained batch 411 in epoch 2, gen_loss = 0.4086965385426595, disc_loss = 0.03229082800737284
Trained batch 412 in epoch 2, gen_loss = 0.408705328841475, disc_loss = 0.03222695745293223
Trained batch 413 in epoch 2, gen_loss = 0.40870443094467773, disc_loss = 0.032158030307253345
Trained batch 414 in epoch 2, gen_loss = 0.4085696495441069, disc_loss = 0.03209969198039497
Trained batch 415 in epoch 2, gen_loss = 0.40849541844083714, disc_loss = 0.032040976433423705
Trained batch 416 in epoch 2, gen_loss = 0.408611838551734, disc_loss = 0.03197810318593463
Trained batch 417 in epoch 2, gen_loss = 0.4085202590700542, disc_loss = 0.031909153993914356
Trained batch 418 in epoch 2, gen_loss = 0.4085022753775831, disc_loss = 0.031839312167575934
Trained batch 419 in epoch 2, gen_loss = 0.4084401528040568, disc_loss = 0.03176993049592489
Trained batch 420 in epoch 2, gen_loss = 0.4086080187856443, disc_loss = 0.03170324048478678
Trained batch 421 in epoch 2, gen_loss = 0.40863627032928557, disc_loss = 0.031636885526232526
Trained batch 422 in epoch 2, gen_loss = 0.40857618955573854, disc_loss = 0.03157021155268236
Trained batch 423 in epoch 2, gen_loss = 0.4085678245239663, disc_loss = 0.03150992667113589
Trained batch 424 in epoch 2, gen_loss = 0.40858271711012895, disc_loss = 0.03144381267511669
Trained batch 425 in epoch 2, gen_loss = 0.4084742968910737, disc_loss = 0.03137587048080553
Trained batch 426 in epoch 2, gen_loss = 0.40850061206125265, disc_loss = 0.03131242438799656
Trained batch 427 in epoch 2, gen_loss = 0.408414927598472, disc_loss = 0.03124641634308446
Trained batch 428 in epoch 2, gen_loss = 0.4084688661259649, disc_loss = 0.031190699625799394
Trained batch 429 in epoch 2, gen_loss = 0.4085570516974427, disc_loss = 0.031128666560208903
Trained batch 430 in epoch 2, gen_loss = 0.4084565429980683, disc_loss = 0.031062944201220976
Trained batch 431 in epoch 2, gen_loss = 0.4082984941563121, disc_loss = 0.031012982085855952
Trained batch 432 in epoch 2, gen_loss = 0.4083241018494613, disc_loss = 0.030958530343595816
Trained batch 433 in epoch 2, gen_loss = 0.4082254989218602, disc_loss = 0.03091224449824044
Trained batch 434 in epoch 2, gen_loss = 0.408206764651441, disc_loss = 0.030860441069964363
Trained batch 435 in epoch 2, gen_loss = 0.40835467158654415, disc_loss = 0.03081257580971738
Trained batch 436 in epoch 2, gen_loss = 0.4083196966817232, disc_loss = 0.03075578686242041
Trained batch 437 in epoch 2, gen_loss = 0.40826967508281203, disc_loss = 0.030697239624531983
Trained batch 438 in epoch 2, gen_loss = 0.4081706632785754, disc_loss = 0.030638849165434853
Trained batch 439 in epoch 2, gen_loss = 0.40817926546389405, disc_loss = 0.030586007438515396
Trained batch 440 in epoch 2, gen_loss = 0.40821193574237175, disc_loss = 0.030532852529026485
Trained batch 441 in epoch 2, gen_loss = 0.4081045252974756, disc_loss = 0.030486457456510126
Trained batch 442 in epoch 2, gen_loss = 0.4082868396563132, disc_loss = 0.030435888683234193
Trained batch 443 in epoch 2, gen_loss = 0.40827058893334756, disc_loss = 0.030377035522162244
Trained batch 444 in epoch 2, gen_loss = 0.40841315040427645, disc_loss = 0.030323153329238798
Trained batch 445 in epoch 2, gen_loss = 0.4083977576194857, disc_loss = 0.030263358650879407
Trained batch 446 in epoch 2, gen_loss = 0.4084208240311685, disc_loss = 0.030204171646111364
Trained batch 447 in epoch 2, gen_loss = 0.40866050915792584, disc_loss = 0.030147753808705602
Trained batch 448 in epoch 2, gen_loss = 0.40858574686177856, disc_loss = 0.030090571302331504
Trained batch 449 in epoch 2, gen_loss = 0.4086081834634145, disc_loss = 0.03003379225316975
Trained batch 450 in epoch 2, gen_loss = 0.40857926652066723, disc_loss = 0.029986072707500002
Trained batch 451 in epoch 2, gen_loss = 0.4087018067989729, disc_loss = 0.029931307351010628
Trained batch 452 in epoch 2, gen_loss = 0.40872948697334355, disc_loss = 0.029876531273430876
Trained batch 453 in epoch 2, gen_loss = 0.4087429451653611, disc_loss = 0.029820089070495662
Trained batch 454 in epoch 2, gen_loss = 0.40878315299421875, disc_loss = 0.029762982936309915
Trained batch 455 in epoch 2, gen_loss = 0.4088180915436201, disc_loss = 0.02970380683658285
Trained batch 456 in epoch 2, gen_loss = 0.40872582251968215, disc_loss = 0.029647381778570053
Trained batch 457 in epoch 2, gen_loss = 0.40879969292332513, disc_loss = 0.02959604855061521
Trained batch 458 in epoch 2, gen_loss = 0.40880802552944173, disc_loss = 0.029539234428981032
Trained batch 459 in epoch 2, gen_loss = 0.40870604644651, disc_loss = 0.029489085136953256
Trained batch 460 in epoch 2, gen_loss = 0.4087770795873861, disc_loss = 0.029435148704069748
Trained batch 461 in epoch 2, gen_loss = 0.4086125889768848, disc_loss = 0.02943198197295494
Trained batch 462 in epoch 2, gen_loss = 0.40928781206355497, disc_loss = 0.02953402913571788
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.47453320026397705, disc_loss = 0.021309103816747665
Trained batch 1 in epoch 3, gen_loss = 0.43134376406669617, disc_loss = 0.045015135779976845
Trained batch 2 in epoch 3, gen_loss = 0.4281753997008006, disc_loss = 0.053949580838282905
Trained batch 3 in epoch 3, gen_loss = 0.4206821992993355, disc_loss = 0.04737880500033498
Trained batch 4 in epoch 3, gen_loss = 0.4027179658412933, disc_loss = 0.04594135768711567
Trained batch 5 in epoch 3, gen_loss = 0.41167591512203217, disc_loss = 0.0472436153019468
Trained batch 6 in epoch 3, gen_loss = 0.4173719414642879, disc_loss = 0.06455513648688793
Trained batch 7 in epoch 3, gen_loss = 0.40397537872195244, disc_loss = 0.07948148273862898
Trained batch 8 in epoch 3, gen_loss = 0.4073442982302772, disc_loss = 0.0813652610199319
Trained batch 9 in epoch 3, gen_loss = 0.39119324237108233, disc_loss = 0.08271429259330035
Trained batch 10 in epoch 3, gen_loss = 0.3927800560539419, disc_loss = 0.08370880731804804
Trained batch 11 in epoch 3, gen_loss = 0.3880135081708431, disc_loss = 0.08214990189298987
Trained batch 12 in epoch 3, gen_loss = 0.38931834124601805, disc_loss = 0.07629336266276929
Trained batch 13 in epoch 3, gen_loss = 0.38960608520678114, disc_loss = 0.07625979577590312
Trained batch 14 in epoch 3, gen_loss = 0.3859093616406123, disc_loss = 0.07811668682843446
Trained batch 15 in epoch 3, gen_loss = 0.38949728664010763, disc_loss = 0.07374987268121913
Trained batch 16 in epoch 3, gen_loss = 0.38715920816449556, disc_loss = 0.07069883884533364
Trained batch 17 in epoch 3, gen_loss = 0.38885465347104603, disc_loss = 0.06821694457903504
Trained batch 18 in epoch 3, gen_loss = 0.39151769013781296, disc_loss = 0.06528185303077887
Trained batch 19 in epoch 3, gen_loss = 0.3959219969809055, disc_loss = 0.06286549544893205
Trained batch 20 in epoch 3, gen_loss = 0.3997637125707808, disc_loss = 0.06025555960479237
Trained batch 21 in epoch 3, gen_loss = 0.4001605991612781, disc_loss = 0.0579225909049538
Trained batch 22 in epoch 3, gen_loss = 0.39905042946338654, disc_loss = 0.05563841845192339
Trained batch 23 in epoch 3, gen_loss = 0.3988245620081822, disc_loss = 0.053463098437835775
Trained batch 24 in epoch 3, gen_loss = 0.3991715329885483, disc_loss = 0.05170698098838329
Trained batch 25 in epoch 3, gen_loss = 0.4014683451790076, disc_loss = 0.05074569654579346
Trained batch 26 in epoch 3, gen_loss = 0.4009230594944071, disc_loss = 0.049384082150128156
Trained batch 27 in epoch 3, gen_loss = 0.3982076213828155, disc_loss = 0.04798083060554096
Trained batch 28 in epoch 3, gen_loss = 0.396736417864931, disc_loss = 0.046598271145645916
Trained batch 29 in epoch 3, gen_loss = 0.3982820635040601, disc_loss = 0.0452689022757113
Trained batch 30 in epoch 3, gen_loss = 0.3984285347884701, disc_loss = 0.043916899260253675
Trained batch 31 in epoch 3, gen_loss = 0.40004004118964076, disc_loss = 0.04272161825792864
Trained batch 32 in epoch 3, gen_loss = 0.398227618950786, disc_loss = 0.04152651790134383
Trained batch 33 in epoch 3, gen_loss = 0.398914433139212, disc_loss = 0.04051159099018311
Trained batch 34 in epoch 3, gen_loss = 0.4005177340337208, disc_loss = 0.039493953210434744
Trained batch 35 in epoch 3, gen_loss = 0.4040369701882203, disc_loss = 0.03854309944694655
Trained batch 36 in epoch 3, gen_loss = 0.40311157179845347, disc_loss = 0.037617686405979296
Trained batch 37 in epoch 3, gen_loss = 0.40364831803660645, disc_loss = 0.03672788282366175
Trained batch 38 in epoch 3, gen_loss = 0.4039414689326898, disc_loss = 0.035959188802502096
Trained batch 39 in epoch 3, gen_loss = 0.40233105756342413, disc_loss = 0.035409393487498164
Trained batch 40 in epoch 3, gen_loss = 0.4004964970233964, disc_loss = 0.034976720991658
Trained batch 41 in epoch 3, gen_loss = 0.40118526809272315, disc_loss = 0.03428901224175379
Trained batch 42 in epoch 3, gen_loss = 0.40118788945120437, disc_loss = 0.033681491693091946
Trained batch 43 in epoch 3, gen_loss = 0.40229011564092204, disc_loss = 0.03370341125198386
Trained batch 44 in epoch 3, gen_loss = 0.4028463592131933, disc_loss = 0.033377301775746875
Trained batch 45 in epoch 3, gen_loss = 0.4044537333690602, disc_loss = 0.03280435935796603
Trained batch 46 in epoch 3, gen_loss = 0.4044723570980924, disc_loss = 0.032437336353704015
Trained batch 47 in epoch 3, gen_loss = 0.40587366838008165, disc_loss = 0.031839989644746915
Trained batch 48 in epoch 3, gen_loss = 0.40586823377074027, disc_loss = 0.031473471626297246
Trained batch 49 in epoch 3, gen_loss = 0.4052586826682091, disc_loss = 0.03104631984140724
Trained batch 50 in epoch 3, gen_loss = 0.4053090246869068, disc_loss = 0.030529211562893847
Trained batch 51 in epoch 3, gen_loss = 0.406916800313271, disc_loss = 0.030087314881921675
Trained batch 52 in epoch 3, gen_loss = 0.40699278155587754, disc_loss = 0.029659387440297683
Trained batch 53 in epoch 3, gen_loss = 0.4064660378628307, disc_loss = 0.029279113259959827
Trained batch 54 in epoch 3, gen_loss = 0.4054086075587706, disc_loss = 0.02882801865396852
Trained batch 55 in epoch 3, gen_loss = 0.40617068404597895, disc_loss = 0.028406738390913233
Trained batch 56 in epoch 3, gen_loss = 0.4056519664693297, disc_loss = 0.028115276136974756
Trained batch 57 in epoch 3, gen_loss = 0.4043456210658468, disc_loss = 0.028186281263860392
Trained batch 58 in epoch 3, gen_loss = 0.40432271942243736, disc_loss = 0.027853120801086397
Trained batch 59 in epoch 3, gen_loss = 0.4027612614134947, disc_loss = 0.027836920806051543
Trained batch 60 in epoch 3, gen_loss = 0.40305075220397263, disc_loss = 0.028267600058318406
Trained batch 61 in epoch 3, gen_loss = 0.40302719824737115, disc_loss = 0.028022781709179042
Trained batch 62 in epoch 3, gen_loss = 0.4027251319752799, disc_loss = 0.027919579123605102
Trained batch 63 in epoch 3, gen_loss = 0.4036570901516825, disc_loss = 0.02769508652636432
Trained batch 64 in epoch 3, gen_loss = 0.4036350124157392, disc_loss = 0.027350792879811847
Trained batch 65 in epoch 3, gen_loss = 0.40481555619926163, disc_loss = 0.02705783422711785
Trained batch 66 in epoch 3, gen_loss = 0.4045656752675327, disc_loss = 0.026766146793822523
Trained batch 67 in epoch 3, gen_loss = 0.40423276604098435, disc_loss = 0.026424475647646058
Trained batch 68 in epoch 3, gen_loss = 0.4040687863809475, disc_loss = 0.026093257449405348
Trained batch 69 in epoch 3, gen_loss = 0.40359376732792174, disc_loss = 0.025810883546780263
Trained batch 70 in epoch 3, gen_loss = 0.4030528935328336, disc_loss = 0.025524352027864104
Trained batch 71 in epoch 3, gen_loss = 0.4026132070769866, disc_loss = 0.025297038185979344
Trained batch 72 in epoch 3, gen_loss = 0.4028473139217455, disc_loss = 0.025023451208915203
Trained batch 73 in epoch 3, gen_loss = 0.4033711872793533, disc_loss = 0.02475482477756167
Trained batch 74 in epoch 3, gen_loss = 0.40365847885608674, disc_loss = 0.02455053409561515
Trained batch 75 in epoch 3, gen_loss = 0.40346472886832135, disc_loss = 0.02429278455307021
Trained batch 76 in epoch 3, gen_loss = 0.40356200759287003, disc_loss = 0.0240610368948962
Trained batch 77 in epoch 3, gen_loss = 0.4049340973679836, disc_loss = 0.0238470621048831
Trained batch 78 in epoch 3, gen_loss = 0.4055620411151572, disc_loss = 0.023802180633043186
Trained batch 79 in epoch 3, gen_loss = 0.4050589526072145, disc_loss = 0.023683523316867648
Trained batch 80 in epoch 3, gen_loss = 0.4047084739546717, disc_loss = 0.023441741047542035
Trained batch 81 in epoch 3, gen_loss = 0.4042843247695667, disc_loss = 0.023440834941206183
Trained batch 82 in epoch 3, gen_loss = 0.4050266292080822, disc_loss = 0.023441021891692317
Trained batch 83 in epoch 3, gen_loss = 0.4046477304682845, disc_loss = 0.023256115449060286
Trained batch 84 in epoch 3, gen_loss = 0.40449935250422536, disc_loss = 0.02304377782651607
Trained batch 85 in epoch 3, gen_loss = 0.404397297563941, disc_loss = 0.022832661363577773
Trained batch 86 in epoch 3, gen_loss = 0.40434980135539483, disc_loss = 0.02269906160453784
Trained batch 87 in epoch 3, gen_loss = 0.4041519146412611, disc_loss = 0.02249024911593138
Trained batch 88 in epoch 3, gen_loss = 0.40474810777755266, disc_loss = 0.022330124700295457
Trained batch 89 in epoch 3, gen_loss = 0.4045043536358409, disc_loss = 0.022138290676391788
Trained batch 90 in epoch 3, gen_loss = 0.404819144816189, disc_loss = 0.02237232712066763
Trained batch 91 in epoch 3, gen_loss = 0.40554609068709874, disc_loss = 0.022506187416856057
Trained batch 92 in epoch 3, gen_loss = 0.40623069498487696, disc_loss = 0.022329445778121872
Trained batch 93 in epoch 3, gen_loss = 0.4059622032528228, disc_loss = 0.022146952452455113
Trained batch 94 in epoch 3, gen_loss = 0.40560589511143536, disc_loss = 0.02229968346165199
Trained batch 95 in epoch 3, gen_loss = 0.4055747549670438, disc_loss = 0.022363008111521292
Trained batch 96 in epoch 3, gen_loss = 0.4053327713123302, disc_loss = 0.022269720773299022
Trained batch 97 in epoch 3, gen_loss = 0.4054965174623898, disc_loss = 0.022159568504525388
Trained batch 98 in epoch 3, gen_loss = 0.40486797043169387, disc_loss = 0.02200120838471886
Trained batch 99 in epoch 3, gen_loss = 0.4050516785681248, disc_loss = 0.021847388637252153
Trained batch 100 in epoch 3, gen_loss = 0.4051060031841297, disc_loss = 0.0217157731450504
Trained batch 101 in epoch 3, gen_loss = 0.40485429632313114, disc_loss = 0.0215771698219446
Trained batch 102 in epoch 3, gen_loss = 0.4044995057640724, disc_loss = 0.02140932813630376
Trained batch 103 in epoch 3, gen_loss = 0.4043334761204628, disc_loss = 0.021258151069140203
Trained batch 104 in epoch 3, gen_loss = 0.40447453870659783, disc_loss = 0.02110266000742004
Trained batch 105 in epoch 3, gen_loss = 0.40468489603613905, disc_loss = 0.02095695775669982
Trained batch 106 in epoch 3, gen_loss = 0.40506130972198234, disc_loss = 0.020797743683976827
Trained batch 107 in epoch 3, gen_loss = 0.4048930198230125, disc_loss = 0.020720991224085016
Trained batch 108 in epoch 3, gen_loss = 0.40462312362062824, disc_loss = 0.02058881372127921
Trained batch 109 in epoch 3, gen_loss = 0.40476743158969014, disc_loss = 0.02044606189328161
Trained batch 110 in epoch 3, gen_loss = 0.4050155543797725, disc_loss = 0.020361365733651427
Trained batch 111 in epoch 3, gen_loss = 0.40534529502370525, disc_loss = 0.020233421328677132
Trained batch 112 in epoch 3, gen_loss = 0.4052612495369616, disc_loss = 0.020093102378984994
Trained batch 113 in epoch 3, gen_loss = 0.4054651086529096, disc_loss = 0.019998774202050346
Trained batch 114 in epoch 3, gen_loss = 0.40602115872113603, disc_loss = 0.019923079321565836
Trained batch 115 in epoch 3, gen_loss = 0.4057356459570342, disc_loss = 0.019804060691967607
Trained batch 116 in epoch 3, gen_loss = 0.4061315078765918, disc_loss = 0.019678930330098186
Trained batch 117 in epoch 3, gen_loss = 0.40580847846754525, disc_loss = 0.019570140089145153
Trained batch 118 in epoch 3, gen_loss = 0.4056533668972865, disc_loss = 0.019433541000358948
Trained batch 119 in epoch 3, gen_loss = 0.40552758711079756, disc_loss = 0.01933169871335849
Trained batch 120 in epoch 3, gen_loss = 0.40528134164238766, disc_loss = 0.019255233409021758
Trained batch 121 in epoch 3, gen_loss = 0.405746761770522, disc_loss = 0.019136515995640247
Trained batch 122 in epoch 3, gen_loss = 0.40626211415946, disc_loss = 0.019015947739192383
Trained batch 123 in epoch 3, gen_loss = 0.40632287448933047, disc_loss = 0.01889531121348902
Trained batch 124 in epoch 3, gen_loss = 0.406246849656105, disc_loss = 0.01876717572659254
Trained batch 125 in epoch 3, gen_loss = 0.4060997659015277, disc_loss = 0.018648004432814936
Trained batch 126 in epoch 3, gen_loss = 0.40588948071941616, disc_loss = 0.018523181365128226
Trained batch 127 in epoch 3, gen_loss = 0.4060613712063059, disc_loss = 0.01841167646671238
Trained batch 128 in epoch 3, gen_loss = 0.4060397498136343, disc_loss = 0.018292192950873642
Trained batch 129 in epoch 3, gen_loss = 0.4061517271857995, disc_loss = 0.01817213582734649
Trained batch 130 in epoch 3, gen_loss = 0.40693121795890896, disc_loss = 0.018089130307540637
Trained batch 131 in epoch 3, gen_loss = 0.40700837755293556, disc_loss = 0.017999178645285694
Trained batch 132 in epoch 3, gen_loss = 0.4073062616407423, disc_loss = 0.017886999570869637
Trained batch 133 in epoch 3, gen_loss = 0.4075312564399705, disc_loss = 0.01777187192034143
Trained batch 134 in epoch 3, gen_loss = 0.40746093580016385, disc_loss = 0.017678400677525335
Trained batch 135 in epoch 3, gen_loss = 0.40778335852219777, disc_loss = 0.017579599619185662
Trained batch 136 in epoch 3, gen_loss = 0.40826821838417193, disc_loss = 0.017488879307995746
Trained batch 137 in epoch 3, gen_loss = 0.4080172499668771, disc_loss = 0.017405872540278495
Trained batch 138 in epoch 3, gen_loss = 0.4079296373420482, disc_loss = 0.01732330004476922
Trained batch 139 in epoch 3, gen_loss = 0.40778817183205057, disc_loss = 0.01722010994562879
Trained batch 140 in epoch 3, gen_loss = 0.4082215313158982, disc_loss = 0.017123728143447575
Trained batch 141 in epoch 3, gen_loss = 0.40833736798712905, disc_loss = 0.017027441643401454
Trained batch 142 in epoch 3, gen_loss = 0.40866858798723954, disc_loss = 0.016951342883448187
Trained batch 143 in epoch 3, gen_loss = 0.4084039656445384, disc_loss = 0.016962502276227396
Trained batch 144 in epoch 3, gen_loss = 0.40842306747518736, disc_loss = 0.01691926505320288
Trained batch 145 in epoch 3, gen_loss = 0.40835222999935283, disc_loss = 0.016838983430093383
Trained batch 146 in epoch 3, gen_loss = 0.4082299153618261, disc_loss = 0.016807444566277925
Trained batch 147 in epoch 3, gen_loss = 0.408291530669541, disc_loss = 0.016736535360168264
Trained batch 148 in epoch 3, gen_loss = 0.4084676009096555, disc_loss = 0.0166563576027976
Trained batch 149 in epoch 3, gen_loss = 0.4084590968489647, disc_loss = 0.016572619181436796
Trained batch 150 in epoch 3, gen_loss = 0.40842812908011555, disc_loss = 0.016481827744066913
Trained batch 151 in epoch 3, gen_loss = 0.4081271325090998, disc_loss = 0.016452333488575135
Trained batch 152 in epoch 3, gen_loss = 0.40856948621522365, disc_loss = 0.01645271560737218
Trained batch 153 in epoch 3, gen_loss = 0.4082869495470802, disc_loss = 0.01637844933656516
Trained batch 154 in epoch 3, gen_loss = 0.4081495828205539, disc_loss = 0.016326108905336548
Trained batch 155 in epoch 3, gen_loss = 0.4084191841001694, disc_loss = 0.016264984387164123
Trained batch 156 in epoch 3, gen_loss = 0.4083167429372763, disc_loss = 0.016187901226032503
Trained batch 157 in epoch 3, gen_loss = 0.4082836883166168, disc_loss = 0.016117255837078903
Trained batch 158 in epoch 3, gen_loss = 0.4081496347983678, disc_loss = 0.016048871967707226
Trained batch 159 in epoch 3, gen_loss = 0.40817550355568527, disc_loss = 0.015986912543303332
Trained batch 160 in epoch 3, gen_loss = 0.40824084705817776, disc_loss = 0.015920004223166785
Trained batch 161 in epoch 3, gen_loss = 0.40812905969811075, disc_loss = 0.0158385408087921
Trained batch 162 in epoch 3, gen_loss = 0.40802830887352765, disc_loss = 0.015756713943498816
Trained batch 163 in epoch 3, gen_loss = 0.40797973142527955, disc_loss = 0.0156814329320474
Trained batch 164 in epoch 3, gen_loss = 0.408254144318176, disc_loss = 0.015616841876710003
Trained batch 165 in epoch 3, gen_loss = 0.40842389458992395, disc_loss = 0.015541578917932439
Trained batch 166 in epoch 3, gen_loss = 0.408275715337542, disc_loss = 0.015476011807757045
Trained batch 167 in epoch 3, gen_loss = 0.40840626623304116, disc_loss = 0.015415724081408587
Trained batch 168 in epoch 3, gen_loss = 0.4083396013848175, disc_loss = 0.015346749881337557
Trained batch 169 in epoch 3, gen_loss = 0.4089127488872584, disc_loss = 0.015279902914977248
Trained batch 170 in epoch 3, gen_loss = 0.40881486707612086, disc_loss = 0.015221605700990784
Trained batch 171 in epoch 3, gen_loss = 0.4084476217800795, disc_loss = 0.015152048036661866
Trained batch 172 in epoch 3, gen_loss = 0.40850524604320526, disc_loss = 0.01508293967193391
Trained batch 173 in epoch 3, gen_loss = 0.4081067469442028, disc_loss = 0.015024788911861164
Trained batch 174 in epoch 3, gen_loss = 0.4082169760125024, disc_loss = 0.014957313757123692
Trained batch 175 in epoch 3, gen_loss = 0.40825168204239826, disc_loss = 0.014900040655365128
Trained batch 176 in epoch 3, gen_loss = 0.4087103952964147, disc_loss = 0.014842565951469001
Trained batch 177 in epoch 3, gen_loss = 0.40894188597965775, disc_loss = 0.0147860454241065
Trained batch 178 in epoch 3, gen_loss = 0.4088493972683752, disc_loss = 0.014732583656168268
Trained batch 179 in epoch 3, gen_loss = 0.40881298871503935, disc_loss = 0.014681489384060518
Trained batch 180 in epoch 3, gen_loss = 0.4089303715617617, disc_loss = 0.014615232725653448
Trained batch 181 in epoch 3, gen_loss = 0.4086982713459612, disc_loss = 0.014553181543066115
Trained batch 182 in epoch 3, gen_loss = 0.40875522189778707, disc_loss = 0.01452063391738332
Trained batch 183 in epoch 3, gen_loss = 0.4083957909403936, disc_loss = 0.014464435160018342
Trained batch 184 in epoch 3, gen_loss = 0.40818438231945037, disc_loss = 0.014410564029035537
Trained batch 185 in epoch 3, gen_loss = 0.408142919742292, disc_loss = 0.01434658662421048
Trained batch 186 in epoch 3, gen_loss = 0.40865897327502143, disc_loss = 0.014291723877599931
Trained batch 187 in epoch 3, gen_loss = 0.4086529627600883, disc_loss = 0.014242885216941779
Trained batch 188 in epoch 3, gen_loss = 0.40852482254227634, disc_loss = 0.014183733702228262
Trained batch 189 in epoch 3, gen_loss = 0.4084719346542107, disc_loss = 0.014122528690648707
Trained batch 190 in epoch 3, gen_loss = 0.40823998977064463, disc_loss = 0.014066365176899583
Trained batch 191 in epoch 3, gen_loss = 0.40830912603996694, disc_loss = 0.014019910750600198
Trained batch 192 in epoch 3, gen_loss = 0.40876635191045274, disc_loss = 0.013971787821887533
Trained batch 193 in epoch 3, gen_loss = 0.40844043789757895, disc_loss = 0.013931077609760398
Trained batch 194 in epoch 3, gen_loss = 0.4081091207571519, disc_loss = 0.013883894653274463
Trained batch 195 in epoch 3, gen_loss = 0.4083640276625448, disc_loss = 0.013862657755119155
Trained batch 196 in epoch 3, gen_loss = 0.4082794097928226, disc_loss = 0.013807784412576235
Trained batch 197 in epoch 3, gen_loss = 0.40829716705613667, disc_loss = 0.013759622850097866
Trained batch 198 in epoch 3, gen_loss = 0.40839165860983595, disc_loss = 0.01371125292018917
Trained batch 199 in epoch 3, gen_loss = 0.4085133270174265, disc_loss = 0.013656291167717428
Trained batch 200 in epoch 3, gen_loss = 0.408372513616263, disc_loss = 0.013603956341298658
Trained batch 201 in epoch 3, gen_loss = 0.4081804279496174, disc_loss = 0.013559452981900165
Trained batch 202 in epoch 3, gen_loss = 0.40766413891550357, disc_loss = 0.013513799534257263
Trained batch 203 in epoch 3, gen_loss = 0.4077874776341167, disc_loss = 0.01348468650123287
Trained batch 204 in epoch 3, gen_loss = 0.4077151845868041, disc_loss = 0.013459284156106595
Trained batch 205 in epoch 3, gen_loss = 0.4078501213378119, disc_loss = 0.01343632739679255
Trained batch 206 in epoch 3, gen_loss = 0.40807522718169265, disc_loss = 0.013414662171623125
Trained batch 207 in epoch 3, gen_loss = 0.40811218027598584, disc_loss = 0.013387659506406635
Trained batch 208 in epoch 3, gen_loss = 0.4077893037117269, disc_loss = 0.013337709138873947
Trained batch 209 in epoch 3, gen_loss = 0.40764060793888, disc_loss = 0.01330484499977458
Trained batch 210 in epoch 3, gen_loss = 0.408073419713861, disc_loss = 0.013265096255847346
Trained batch 211 in epoch 3, gen_loss = 0.40813790549928286, disc_loss = 0.013243506117811743
Trained batch 212 in epoch 3, gen_loss = 0.40827978307932195, disc_loss = 0.013197515127052304
Trained batch 213 in epoch 3, gen_loss = 0.4083430952975683, disc_loss = 0.013156417694169089
Trained batch 214 in epoch 3, gen_loss = 0.4081340836231099, disc_loss = 0.01313538623020746
Trained batch 215 in epoch 3, gen_loss = 0.4085778590567686, disc_loss = 0.013112764109219252
Trained batch 216 in epoch 3, gen_loss = 0.4088765794093708, disc_loss = 0.013078608509359135
Trained batch 217 in epoch 3, gen_loss = 0.40898044468886263, disc_loss = 0.01303968905180761
Trained batch 218 in epoch 3, gen_loss = 0.4090187729901919, disc_loss = 0.01300062106701133
Trained batch 219 in epoch 3, gen_loss = 0.4089319857006723, disc_loss = 0.012955072939141908
Trained batch 220 in epoch 3, gen_loss = 0.40899767736773684, disc_loss = 0.012923788477359045
Trained batch 221 in epoch 3, gen_loss = 0.408999748393759, disc_loss = 0.012914118361197881
Trained batch 222 in epoch 3, gen_loss = 0.40903807655310953, disc_loss = 0.012876872167475689
Trained batch 223 in epoch 3, gen_loss = 0.40882693051493596, disc_loss = 0.01283088051111138
Trained batch 224 in epoch 3, gen_loss = 0.40893784754806095, disc_loss = 0.012793084179154701
Trained batch 225 in epoch 3, gen_loss = 0.4092366425732596, disc_loss = 0.012764270119657493
Trained batch 226 in epoch 3, gen_loss = 0.4093032444494936, disc_loss = 0.012726708320441291
Trained batch 227 in epoch 3, gen_loss = 0.40915796101877566, disc_loss = 0.012695388440573751
Trained batch 228 in epoch 3, gen_loss = 0.4088328157319773, disc_loss = 0.01265096723703936
Trained batch 229 in epoch 3, gen_loss = 0.4085374860012013, disc_loss = 0.01261477517672693
Trained batch 230 in epoch 3, gen_loss = 0.40876827759918194, disc_loss = 0.012587694456252508
Trained batch 231 in epoch 3, gen_loss = 0.4085981887604656, disc_loss = 0.012551018088084549
Trained batch 232 in epoch 3, gen_loss = 0.4086371639127895, disc_loss = 0.0125213632521983
Trained batch 233 in epoch 3, gen_loss = 0.4083003762822885, disc_loss = 0.012495187659445418
Trained batch 234 in epoch 3, gen_loss = 0.40847408891992365, disc_loss = 0.012495173275114057
Trained batch 235 in epoch 3, gen_loss = 0.4087650851046635, disc_loss = 0.012458719317090966
Trained batch 236 in epoch 3, gen_loss = 0.4085673020233082, disc_loss = 0.01243111001571271
Trained batch 237 in epoch 3, gen_loss = 0.40801764968313087, disc_loss = 0.012431702122655736
Trained batch 238 in epoch 3, gen_loss = 0.4081601093379025, disc_loss = 0.012467694994857122
Trained batch 239 in epoch 3, gen_loss = 0.4080535183971127, disc_loss = 0.012464183347765357
Trained batch 240 in epoch 3, gen_loss = 0.4082109256033086, disc_loss = 0.012440592427332248
Trained batch 241 in epoch 3, gen_loss = 0.40835407456336925, disc_loss = 0.012425161869272837
Trained batch 242 in epoch 3, gen_loss = 0.4082573032305564, disc_loss = 0.0123883948235968
Trained batch 243 in epoch 3, gen_loss = 0.40805910045250515, disc_loss = 0.012384760147723996
Trained batch 244 in epoch 3, gen_loss = 0.40793357327276347, disc_loss = 0.012346969064971318
Trained batch 245 in epoch 3, gen_loss = 0.40772387076441835, disc_loss = 0.012322021865028494
Trained batch 246 in epoch 3, gen_loss = 0.4074493999543943, disc_loss = 0.012285148897415653
Trained batch 247 in epoch 3, gen_loss = 0.40717495611358073, disc_loss = 0.012252047884225424
Trained batch 248 in epoch 3, gen_loss = 0.40693602438672, disc_loss = 0.012254092035381251
Trained batch 249 in epoch 3, gen_loss = 0.4070855787396431, disc_loss = 0.012238491562195123
Trained batch 250 in epoch 3, gen_loss = 0.4069276724559852, disc_loss = 0.01220663678201576
Trained batch 251 in epoch 3, gen_loss = 0.4073509410141952, disc_loss = 0.01219460324639277
Trained batch 252 in epoch 3, gen_loss = 0.40740925315104926, disc_loss = 0.012165573181716998
Trained batch 253 in epoch 3, gen_loss = 0.4072434302038095, disc_loss = 0.012132680640321254
Trained batch 254 in epoch 3, gen_loss = 0.4072674111408346, disc_loss = 0.01210388027259386
Trained batch 255 in epoch 3, gen_loss = 0.4074653692659922, disc_loss = 0.01206669043222064
Trained batch 256 in epoch 3, gen_loss = 0.4076749901015471, disc_loss = 0.012041675741331297
Trained batch 257 in epoch 3, gen_loss = 0.4075402737010357, disc_loss = 0.012017323094954383
Trained batch 258 in epoch 3, gen_loss = 0.4075875327739016, disc_loss = 0.011983002333732819
Trained batch 259 in epoch 3, gen_loss = 0.40735180142980354, disc_loss = 0.011946225185126353
Trained batch 260 in epoch 3, gen_loss = 0.4072627482857284, disc_loss = 0.01191861649093814
Trained batch 261 in epoch 3, gen_loss = 0.40727375328313303, disc_loss = 0.011883324220996947
Trained batch 262 in epoch 3, gen_loss = 0.4072493621265027, disc_loss = 0.01187347373818915
Trained batch 263 in epoch 3, gen_loss = 0.4073873112034617, disc_loss = 0.01184540572064703
Trained batch 264 in epoch 3, gen_loss = 0.4072637433713337, disc_loss = 0.011817171548510778
Trained batch 265 in epoch 3, gen_loss = 0.40719891843715106, disc_loss = 0.01178608849711184
Trained batch 266 in epoch 3, gen_loss = 0.40719835382052577, disc_loss = 0.011760882537093446
Trained batch 267 in epoch 3, gen_loss = 0.40704902333777343, disc_loss = 0.011739541542778877
Trained batch 268 in epoch 3, gen_loss = 0.4067768278950652, disc_loss = 0.011771982192099925
Trained batch 269 in epoch 3, gen_loss = 0.4065551780440189, disc_loss = 0.01174068011050285
Trained batch 270 in epoch 3, gen_loss = 0.40656207545876943, disc_loss = 0.01171578817341023
Trained batch 271 in epoch 3, gen_loss = 0.4065276806735817, disc_loss = 0.011685945510501316
Trained batch 272 in epoch 3, gen_loss = 0.40647689332237175, disc_loss = 0.011669451782766443
Trained batch 273 in epoch 3, gen_loss = 0.40635015837249966, disc_loss = 0.011637827801266617
Trained batch 274 in epoch 3, gen_loss = 0.40643193846399134, disc_loss = 0.011604366637766362
Trained batch 275 in epoch 3, gen_loss = 0.4068299609141937, disc_loss = 0.011584831325782707
Trained batch 276 in epoch 3, gen_loss = 0.4068445167924523, disc_loss = 0.011554772177179906
Trained batch 277 in epoch 3, gen_loss = 0.4067012513820216, disc_loss = 0.011535731099023344
Trained batch 278 in epoch 3, gen_loss = 0.4068629501861483, disc_loss = 0.011512734481604189
Trained batch 279 in epoch 3, gen_loss = 0.40681881260659014, disc_loss = 0.011486120555283768
Trained batch 280 in epoch 3, gen_loss = 0.4067909084923327, disc_loss = 0.011454729311950372
Trained batch 281 in epoch 3, gen_loss = 0.4067761095386025, disc_loss = 0.011428608897584656
Trained batch 282 in epoch 3, gen_loss = 0.4067214367773002, disc_loss = 0.011396331768548741
Trained batch 283 in epoch 3, gen_loss = 0.4066123096141177, disc_loss = 0.01136454519107413
Trained batch 284 in epoch 3, gen_loss = 0.4062722522438618, disc_loss = 0.011356546710196294
Trained batch 285 in epoch 3, gen_loss = 0.4062152116761341, disc_loss = 0.01133812938237211
Trained batch 286 in epoch 3, gen_loss = 0.4062858005330122, disc_loss = 0.011319493547159828
Trained batch 287 in epoch 3, gen_loss = 0.4062359647100998, disc_loss = 0.011313568661636155
Trained batch 288 in epoch 3, gen_loss = 0.4065151348142888, disc_loss = 0.011308925973966872
Trained batch 289 in epoch 3, gen_loss = 0.40660331089948787, disc_loss = 0.011284529350312619
Trained batch 290 in epoch 3, gen_loss = 0.406847488071091, disc_loss = 0.011262771894329601
Trained batch 291 in epoch 3, gen_loss = 0.4067769502225804, disc_loss = 0.011233535628727549
Trained batch 292 in epoch 3, gen_loss = 0.4068388333194492, disc_loss = 0.011211803508763529
Trained batch 293 in epoch 3, gen_loss = 0.4070838438917179, disc_loss = 0.011181937522717377
Trained batch 294 in epoch 3, gen_loss = 0.407211274262202, disc_loss = 0.011152510042696939
Trained batch 295 in epoch 3, gen_loss = 0.40730566173993255, disc_loss = 0.011145475421988129
Trained batch 296 in epoch 3, gen_loss = 0.40723501677665647, disc_loss = 0.011118319469601267
Trained batch 297 in epoch 3, gen_loss = 0.4072269949837019, disc_loss = 0.011093536191057388
Trained batch 298 in epoch 3, gen_loss = 0.4070856233803325, disc_loss = 0.011073221087324928
Trained batch 299 in epoch 3, gen_loss = 0.40709120060006776, disc_loss = 0.011046850936642538
Trained batch 300 in epoch 3, gen_loss = 0.406883937823416, disc_loss = 0.011020991468548378
Trained batch 301 in epoch 3, gen_loss = 0.4067516927391488, disc_loss = 0.010993684968904944
Trained batch 302 in epoch 3, gen_loss = 0.40689572332912544, disc_loss = 0.010971007963931403
Trained batch 303 in epoch 3, gen_loss = 0.40660800730907604, disc_loss = 0.01094347635118634
Trained batch 304 in epoch 3, gen_loss = 0.40660287361653125, disc_loss = 0.010925266609267622
Trained batch 305 in epoch 3, gen_loss = 0.4067145051812035, disc_loss = 0.010913978734059759
Trained batch 306 in epoch 3, gen_loss = 0.406651782242017, disc_loss = 0.010892857801994303
Trained batch 307 in epoch 3, gen_loss = 0.4067769861937343, disc_loss = 0.01091039394990045
Trained batch 308 in epoch 3, gen_loss = 0.4067358153248296, disc_loss = 0.010898605270859783
Trained batch 309 in epoch 3, gen_loss = 0.40668462644661624, disc_loss = 0.010873787880184189
Trained batch 310 in epoch 3, gen_loss = 0.40670571627149243, disc_loss = 0.010873570870548199
Trained batch 311 in epoch 3, gen_loss = 0.4065874302520966, disc_loss = 0.01098248510597608
Trained batch 312 in epoch 3, gen_loss = 0.40652271738638895, disc_loss = 0.011005831519350076
Trained batch 313 in epoch 3, gen_loss = 0.40669146108969, disc_loss = 0.0109893293105137
Trained batch 314 in epoch 3, gen_loss = 0.40659825768735675, disc_loss = 0.010971081706266555
Trained batch 315 in epoch 3, gen_loss = 0.40640229510166975, disc_loss = 0.010949406929054781
Trained batch 316 in epoch 3, gen_loss = 0.40637260539110526, disc_loss = 0.01098252856099173
Trained batch 317 in epoch 3, gen_loss = 0.4065307465458066, disc_loss = 0.011064475106438564
Trained batch 318 in epoch 3, gen_loss = 0.40654326209267105, disc_loss = 0.011041234088273351
Trained batch 319 in epoch 3, gen_loss = 0.4068358160089701, disc_loss = 0.011027461884077638
Trained batch 320 in epoch 3, gen_loss = 0.4068843903849801, disc_loss = 0.011009495371714745
Trained batch 321 in epoch 3, gen_loss = 0.40694495290517807, disc_loss = 0.010991639488012246
Trained batch 322 in epoch 3, gen_loss = 0.4068683782136846, disc_loss = 0.011029932407183637
Trained batch 323 in epoch 3, gen_loss = 0.4071648125939163, disc_loss = 0.011031534705299563
Trained batch 324 in epoch 3, gen_loss = 0.4071540326797045, disc_loss = 0.011011530021921947
Trained batch 325 in epoch 3, gen_loss = 0.4072141102943684, disc_loss = 0.010992092676060789
Trained batch 326 in epoch 3, gen_loss = 0.40713927445973097, disc_loss = 0.010968046205898674
Trained batch 327 in epoch 3, gen_loss = 0.40727390571520095, disc_loss = 0.010949268160535522
Trained batch 328 in epoch 3, gen_loss = 0.4071504190609448, disc_loss = 0.010930273275663878
Trained batch 329 in epoch 3, gen_loss = 0.4071305211294781, disc_loss = 0.010913794689501325
Trained batch 330 in epoch 3, gen_loss = 0.4072078834217481, disc_loss = 0.010888900841358386
Trained batch 331 in epoch 3, gen_loss = 0.4070281891309353, disc_loss = 0.010865764936477125
Trained batch 332 in epoch 3, gen_loss = 0.4070827825380875, disc_loss = 0.010853222999218348
Trained batch 333 in epoch 3, gen_loss = 0.40695131909169124, disc_loss = 0.010831283455614201
Trained batch 334 in epoch 3, gen_loss = 0.40702263361482477, disc_loss = 0.010820238197694964
Trained batch 335 in epoch 3, gen_loss = 0.40697258298418354, disc_loss = 0.01080081176838749
Trained batch 336 in epoch 3, gen_loss = 0.4070410030266651, disc_loss = 0.010798812101841061
Trained batch 337 in epoch 3, gen_loss = 0.40726078830703477, disc_loss = 0.010787007471921264
Trained batch 338 in epoch 3, gen_loss = 0.4074731797507379, disc_loss = 0.010804644004224763
Trained batch 339 in epoch 3, gen_loss = 0.40737311020493505, disc_loss = 0.010827134561944096
Trained batch 340 in epoch 3, gen_loss = 0.40746347204156635, disc_loss = 0.01080767195835666
Trained batch 341 in epoch 3, gen_loss = 0.40744172633565656, disc_loss = 0.01078905438328957
Trained batch 342 in epoch 3, gen_loss = 0.40756427368513004, disc_loss = 0.01077358454259509
Trained batch 343 in epoch 3, gen_loss = 0.4075402963559988, disc_loss = 0.010767330691694867
Trained batch 344 in epoch 3, gen_loss = 0.40746331944845726, disc_loss = 0.010753775317815767
Trained batch 345 in epoch 3, gen_loss = 0.4074037951454951, disc_loss = 0.01074270091579441
Trained batch 346 in epoch 3, gen_loss = 0.407459082151696, disc_loss = 0.010747275440027718
Trained batch 347 in epoch 3, gen_loss = 0.4073333606209563, disc_loss = 0.010754359178191543
Trained batch 348 in epoch 3, gen_loss = 0.4074620473436093, disc_loss = 0.010739871243383192
Trained batch 349 in epoch 3, gen_loss = 0.40741963101284845, disc_loss = 0.01076418532723827
Trained batch 350 in epoch 3, gen_loss = 0.4074325317416096, disc_loss = 0.010755988083344664
Trained batch 351 in epoch 3, gen_loss = 0.40756165934726596, disc_loss = 0.01074660758075135
Trained batch 352 in epoch 3, gen_loss = 0.40758667117982006, disc_loss = 0.01073278832742707
Trained batch 353 in epoch 3, gen_loss = 0.4074709367028064, disc_loss = 0.01071151179237828
Trained batch 354 in epoch 3, gen_loss = 0.40742391864178884, disc_loss = 0.010711725080438272
Trained batch 355 in epoch 3, gen_loss = 0.4074151557399316, disc_loss = 0.0106938687588737
Trained batch 356 in epoch 3, gen_loss = 0.4074653466793002, disc_loss = 0.010769806375090523
Trained batch 357 in epoch 3, gen_loss = 0.4072805077420267, disc_loss = 0.011841415079679944
Trained batch 358 in epoch 3, gen_loss = 0.4073106152184494, disc_loss = 0.01214376761328979
Trained batch 359 in epoch 3, gen_loss = 0.40728336411217847, disc_loss = 0.012282467996313547
Trained batch 360 in epoch 3, gen_loss = 0.40722668629108705, disc_loss = 0.012284105897099398
Trained batch 361 in epoch 3, gen_loss = 0.4071747065002088, disc_loss = 0.012266087454476122
Trained batch 362 in epoch 3, gen_loss = 0.4074280032523736, disc_loss = 0.012308315628595629
Trained batch 363 in epoch 3, gen_loss = 0.40712868549175313, disc_loss = 0.012379406076973652
Trained batch 364 in epoch 3, gen_loss = 0.4070285346001795, disc_loss = 0.012577150002351567
Trained batch 365 in epoch 3, gen_loss = 0.40712986548578806, disc_loss = 0.014051817515941306
Trained batch 366 in epoch 3, gen_loss = 0.4068176691554872, disc_loss = 0.014304302993791346
Trained batch 367 in epoch 3, gen_loss = 0.4067597890920613, disc_loss = 0.01471195043553092
Trained batch 368 in epoch 3, gen_loss = 0.4064303632108823, disc_loss = 0.01520539644088465
Trained batch 369 in epoch 3, gen_loss = 0.40652016469755686, disc_loss = 0.01614479218748071
Trained batch 370 in epoch 3, gen_loss = 0.4064507900142284, disc_loss = 0.01716323760764879
Trained batch 371 in epoch 3, gen_loss = 0.40604379048110334, disc_loss = 0.01792350809542983
Trained batch 372 in epoch 3, gen_loss = 0.4058711497217976, disc_loss = 0.01952357088395422
Trained batch 373 in epoch 3, gen_loss = 0.4055414159587998, disc_loss = 0.02028828928618129
Trained batch 374 in epoch 3, gen_loss = 0.40532394746939343, disc_loss = 0.020889497017487883
Trained batch 375 in epoch 3, gen_loss = 0.40516069210431677, disc_loss = 0.021426592235815056
Trained batch 376 in epoch 3, gen_loss = 0.4050073647767859, disc_loss = 0.02188290728303043
Trained batch 377 in epoch 3, gen_loss = 0.4047123495311964, disc_loss = 0.02226931607244763
Trained batch 378 in epoch 3, gen_loss = 0.40463403838448286, disc_loss = 0.022508327080683885
Trained batch 379 in epoch 3, gen_loss = 0.4045216941911923, disc_loss = 0.022706222216182046
Trained batch 380 in epoch 3, gen_loss = 0.40451232455377506, disc_loss = 0.02278300970756104
Trained batch 381 in epoch 3, gen_loss = 0.4042488744199588, disc_loss = 0.022898644029104312
Trained batch 382 in epoch 3, gen_loss = 0.40420672169086513, disc_loss = 0.023232833344328848
Trained batch 383 in epoch 3, gen_loss = 0.4040521750769888, disc_loss = 0.023793707267638336
Trained batch 384 in epoch 3, gen_loss = 0.4038501459669757, disc_loss = 0.02410832188309884
Trained batch 385 in epoch 3, gen_loss = 0.40378945845859654, disc_loss = 0.024681827039554367
Trained batch 386 in epoch 3, gen_loss = 0.4036959097443933, disc_loss = 0.024934085125093968
Trained batch 387 in epoch 3, gen_loss = 0.40344415178772103, disc_loss = 0.025077475461095917
Trained batch 388 in epoch 3, gen_loss = 0.40318975637841653, disc_loss = 0.02521329755765556
Trained batch 389 in epoch 3, gen_loss = 0.40301401916986856, disc_loss = 0.025307372093606645
Trained batch 390 in epoch 3, gen_loss = 0.4031329981582549, disc_loss = 0.025561772244613225
Trained batch 391 in epoch 3, gen_loss = 0.4030376473175628, disc_loss = 0.026150372160280277
Trained batch 392 in epoch 3, gen_loss = 0.403032653773104, disc_loss = 0.026770304381946913
Trained batch 393 in epoch 3, gen_loss = 0.4030234478224958, disc_loss = 0.027024408183675165
Trained batch 394 in epoch 3, gen_loss = 0.40309447340572935, disc_loss = 0.027055988154857408
Trained batch 395 in epoch 3, gen_loss = 0.40290405883482006, disc_loss = 0.027132893692010617
Trained batch 396 in epoch 3, gen_loss = 0.40288135277984727, disc_loss = 0.027169614303645957
Trained batch 397 in epoch 3, gen_loss = 0.4026661096281143, disc_loss = 0.027260742749873754
Trained batch 398 in epoch 3, gen_loss = 0.40256899860419126, disc_loss = 0.02780889292635061
Trained batch 399 in epoch 3, gen_loss = 0.40204819068312647, disc_loss = 0.0289663828961784
Trained batch 400 in epoch 3, gen_loss = 0.40211587646358327, disc_loss = 0.02942400591557107
Trained batch 401 in epoch 3, gen_loss = 0.4020416209502007, disc_loss = 0.029965774267935077
Trained batch 402 in epoch 3, gen_loss = 0.4018888338180097, disc_loss = 0.030418518020727536
Trained batch 403 in epoch 3, gen_loss = 0.4018930167254835, disc_loss = 0.030912255965712673
Trained batch 404 in epoch 3, gen_loss = 0.40176099766919643, disc_loss = 0.03141208173833603
Trained batch 405 in epoch 3, gen_loss = 0.4014960788006853, disc_loss = 0.03190359047997119
Trained batch 406 in epoch 3, gen_loss = 0.40130584289752297, disc_loss = 0.0323294128825618
Trained batch 407 in epoch 3, gen_loss = 0.40118061466252103, disc_loss = 0.03281140035787579
Trained batch 408 in epoch 3, gen_loss = 0.4008290752367752, disc_loss = 0.03323534627053386
Trained batch 409 in epoch 3, gen_loss = 0.40065706176001853, disc_loss = 0.03355269018253993
Trained batch 410 in epoch 3, gen_loss = 0.40041643671165705, disc_loss = 0.03383403204873186
Trained batch 411 in epoch 3, gen_loss = 0.40033927972166283, disc_loss = 0.034074557027937755
Trained batch 412 in epoch 3, gen_loss = 0.4002265311037946, disc_loss = 0.034592318301794926
Trained batch 413 in epoch 3, gen_loss = 0.40012953326034084, disc_loss = 0.03467463292147748
Trained batch 414 in epoch 3, gen_loss = 0.40026986189635405, disc_loss = 0.03514085355080126
Trained batch 415 in epoch 3, gen_loss = 0.4001623379209867, disc_loss = 0.0357280713198214
Trained batch 416 in epoch 3, gen_loss = 0.40013771363013656, disc_loss = 0.035972743588265216
Trained batch 417 in epoch 3, gen_loss = 0.40006773052603434, disc_loss = 0.036204231631692556
Trained batch 418 in epoch 3, gen_loss = 0.3999436367525406, disc_loss = 0.03635076348567581
Trained batch 419 in epoch 3, gen_loss = 0.3997876852750778, disc_loss = 0.03647653551472883
Trained batch 420 in epoch 3, gen_loss = 0.39942035447107077, disc_loss = 0.03666930357735347
Trained batch 421 in epoch 3, gen_loss = 0.3992943916981819, disc_loss = 0.0366665542316601
Trained batch 422 in epoch 3, gen_loss = 0.3992383481481115, disc_loss = 0.036687341032673036
Trained batch 423 in epoch 3, gen_loss = 0.39920766426707216, disc_loss = 0.03668427995882735
Trained batch 424 in epoch 3, gen_loss = 0.3992112013872932, disc_loss = 0.03666620035874931
Trained batch 425 in epoch 3, gen_loss = 0.3991940997436013, disc_loss = 0.03667034218011275
Trained batch 426 in epoch 3, gen_loss = 0.3989641878588138, disc_loss = 0.03709034449464491
Trained batch 427 in epoch 3, gen_loss = 0.3990301230800486, disc_loss = 0.038141476064942184
Trained batch 428 in epoch 3, gen_loss = 0.39894738070892566, disc_loss = 0.03856492718618736
Trained batch 429 in epoch 3, gen_loss = 0.3987698531428049, disc_loss = 0.03906493203032242
Trained batch 430 in epoch 3, gen_loss = 0.3987633295512808, disc_loss = 0.039559339793839784
Trained batch 431 in epoch 3, gen_loss = 0.3986430203335153, disc_loss = 0.0399422756168793
Trained batch 432 in epoch 3, gen_loss = 0.39856809012884353, disc_loss = 0.040186271059066574
Trained batch 433 in epoch 3, gen_loss = 0.39834630715956887, disc_loss = 0.0405298571240732
Trained batch 434 in epoch 3, gen_loss = 0.39835819971972497, disc_loss = 0.040690907515349914
Trained batch 435 in epoch 3, gen_loss = 0.3983093239708778, disc_loss = 0.040745738249190935
Trained batch 436 in epoch 3, gen_loss = 0.39818986513794696, disc_loss = 0.0407545690044326
Trained batch 437 in epoch 3, gen_loss = 0.3979408472232078, disc_loss = 0.040759640661297905
Trained batch 438 in epoch 3, gen_loss = 0.3980202959990447, disc_loss = 0.04077543832991773
Trained batch 439 in epoch 3, gen_loss = 0.39798404770818624, disc_loss = 0.04079988118398681
Trained batch 440 in epoch 3, gen_loss = 0.3979598095222395, disc_loss = 0.04081704938528709
Trained batch 441 in epoch 3, gen_loss = 0.39777967731607444, disc_loss = 0.04083637463832822
Trained batch 442 in epoch 3, gen_loss = 0.39797459747936603, disc_loss = 0.04086797192123031
Trained batch 443 in epoch 3, gen_loss = 0.3979308518606263, disc_loss = 0.04088333640551731
Trained batch 444 in epoch 3, gen_loss = 0.397741537482551, disc_loss = 0.04139803589865816
Trained batch 445 in epoch 3, gen_loss = 0.39781006983577405, disc_loss = 0.04216740239096279
Trained batch 446 in epoch 3, gen_loss = 0.397822200585265, disc_loss = 0.0422069284303418
Trained batch 447 in epoch 3, gen_loss = 0.3977886133028993, disc_loss = 0.04251533456980334
Trained batch 448 in epoch 3, gen_loss = 0.39776289031606477, disc_loss = 0.04262347314931983
Trained batch 449 in epoch 3, gen_loss = 0.3974319876233737, disc_loss = 0.04272205393813137
Trained batch 450 in epoch 3, gen_loss = 0.39735832496519363, disc_loss = 0.04283475657427341
Trained batch 451 in epoch 3, gen_loss = 0.3973089276887147, disc_loss = 0.042816289688720144
Trained batch 452 in epoch 3, gen_loss = 0.39730841990469834, disc_loss = 0.04276063773117005
Trained batch 453 in epoch 3, gen_loss = 0.3972209018166895, disc_loss = 0.04271713145013636
Trained batch 454 in epoch 3, gen_loss = 0.3970814525098591, disc_loss = 0.04265073031483853
Trained batch 455 in epoch 3, gen_loss = 0.3970764484256506, disc_loss = 0.042589118022557444
Trained batch 456 in epoch 3, gen_loss = 0.39713081759879576, disc_loss = 0.04255426540630472
Trained batch 457 in epoch 3, gen_loss = 0.3971042963289798, disc_loss = 0.042503918859168204
Trained batch 458 in epoch 3, gen_loss = 0.39705372061215194, disc_loss = 0.04242267045050389
Trained batch 459 in epoch 3, gen_loss = 0.39713781369121176, disc_loss = 0.04234324731489481
Trained batch 460 in epoch 3, gen_loss = 0.39712633968304656, disc_loss = 0.04228981116982561
Trained batch 461 in epoch 3, gen_loss = 0.39705665386987454, disc_loss = 0.0422204872306025
Trained batch 462 in epoch 3, gen_loss = 0.39730601250867864, disc_loss = 0.04256135489958586
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.3591197729110718, disc_loss = 0.04342128336429596
Trained batch 1 in epoch 4, gen_loss = 0.38455595076084137, disc_loss = 0.033181389793753624
Trained batch 2 in epoch 4, gen_loss = 0.39319952328999835, disc_loss = 0.031207671388983727
Trained batch 3 in epoch 4, gen_loss = 0.38465844094753265, disc_loss = 0.03268069075420499
Trained batch 4 in epoch 4, gen_loss = 0.37916783690452577, disc_loss = 0.04416100420057774
Trained batch 5 in epoch 4, gen_loss = 0.40264371534188587, disc_loss = 0.07520777514825265
Trained batch 6 in epoch 4, gen_loss = 0.40067577362060547, disc_loss = 0.07344239870352405
Trained batch 7 in epoch 4, gen_loss = 0.3951793499290943, disc_loss = 0.07104284432716668
Trained batch 8 in epoch 4, gen_loss = 0.3978135916921828, disc_loss = 0.06554166951941119
Trained batch 9 in epoch 4, gen_loss = 0.3974053055047989, disc_loss = 0.06089319828897714
Trained batch 10 in epoch 4, gen_loss = 0.39890818433328107, disc_loss = 0.06097499094903469
Trained batch 11 in epoch 4, gen_loss = 0.3962041959166527, disc_loss = 0.06214448266352216
Trained batch 12 in epoch 4, gen_loss = 0.3929717311492333, disc_loss = 0.08729088721940151
Trained batch 13 in epoch 4, gen_loss = 0.3883024368967329, disc_loss = 0.08367669515843902
Trained batch 14 in epoch 4, gen_loss = 0.39402005275090535, disc_loss = 0.08320190844436487
Trained batch 15 in epoch 4, gen_loss = 0.3872136976569891, disc_loss = 0.08238444838207215
Trained batch 16 in epoch 4, gen_loss = 0.3865085366894217, disc_loss = 0.07965954404105158
Trained batch 17 in epoch 4, gen_loss = 0.38958565725220573, disc_loss = 0.07579036512308651
Trained batch 18 in epoch 4, gen_loss = 0.38996616947023494, disc_loss = 0.0722974336362983
Trained batch 19 in epoch 4, gen_loss = 0.39131953865289687, disc_loss = 0.06905001495033503
Trained batch 20 in epoch 4, gen_loss = 0.3887476892698379, disc_loss = 0.06606765765519369
Trained batch 21 in epoch 4, gen_loss = 0.3867630430243232, disc_loss = 0.06487951512363824
Trained batch 22 in epoch 4, gen_loss = 0.3902347178562828, disc_loss = 0.0630690777755302
Trained batch 23 in epoch 4, gen_loss = 0.391659177839756, disc_loss = 0.06315281661227345
Trained batch 24 in epoch 4, gen_loss = 0.39309927105903625, disc_loss = 0.06331937715411186
Trained batch 25 in epoch 4, gen_loss = 0.39438847395089954, disc_loss = 0.06256152374240068
Trained batch 26 in epoch 4, gen_loss = 0.39723883514051084, disc_loss = 0.06160111132043379
Trained batch 27 in epoch 4, gen_loss = 0.3997840540749686, disc_loss = 0.060591786700700014
Trained batch 28 in epoch 4, gen_loss = 0.39983969413000964, disc_loss = 0.05868496066601626
Trained batch 29 in epoch 4, gen_loss = 0.4001828213532766, disc_loss = 0.05730966703655819
Trained batch 30 in epoch 4, gen_loss = 0.40091688786783525, disc_loss = 0.05562008864757034
Trained batch 31 in epoch 4, gen_loss = 0.39796308893710375, disc_loss = 0.054068712634034455
Trained batch 32 in epoch 4, gen_loss = 0.39667028098395374, disc_loss = 0.052698876934521126
Trained batch 33 in epoch 4, gen_loss = 0.3986034323187435, disc_loss = 0.05135451305164572
Trained batch 34 in epoch 4, gen_loss = 0.39795898880277364, disc_loss = 0.050063212814607794
Trained batch 35 in epoch 4, gen_loss = 0.3984750252630975, disc_loss = 0.0487726723206126
Trained batch 36 in epoch 4, gen_loss = 0.3987108742868578, disc_loss = 0.04775562441932994
Trained batch 37 in epoch 4, gen_loss = 0.4009787024636018, disc_loss = 0.04669475898538765
Trained batch 38 in epoch 4, gen_loss = 0.4005544025164384, disc_loss = 0.045572951603203245
Trained batch 39 in epoch 4, gen_loss = 0.4012057207524776, disc_loss = 0.044599032308906314
Trained batch 40 in epoch 4, gen_loss = 0.4009104930773014, disc_loss = 0.04370354470319864
Trained batch 41 in epoch 4, gen_loss = 0.400883123988197, disc_loss = 0.04276792545403753
Trained batch 42 in epoch 4, gen_loss = 0.4013080250385196, disc_loss = 0.04189888905560554
Trained batch 43 in epoch 4, gen_loss = 0.40272325480526144, disc_loss = 0.04111646139062941
Trained batch 44 in epoch 4, gen_loss = 0.4019839968946245, disc_loss = 0.04032436361950305
Trained batch 45 in epoch 4, gen_loss = 0.4015913391890733, disc_loss = 0.039613144158426185
Trained batch 46 in epoch 4, gen_loss = 0.4015424112056164, disc_loss = 0.03891760475457983
Trained batch 47 in epoch 4, gen_loss = 0.4030915970603625, disc_loss = 0.03829246045400699
Trained batch 48 in epoch 4, gen_loss = 0.40367999612068645, disc_loss = 0.037593768624474805
Trained batch 49 in epoch 4, gen_loss = 0.4046396905183792, disc_loss = 0.0369148579146713
Trained batch 50 in epoch 4, gen_loss = 0.4051746235174291, disc_loss = 0.0362661759022112
Trained batch 52 in epoch 4, gen_loss = 0.4040265015836032, disc_loss = 0.03502678196824525
Trained batch 53 in epoch 4, gen_loss = 0.40400409864054787, disc_loss = 0.03451302001270017
Trained batch 54 in epoch 4, gen_loss = 0.40452209277586504, disc_loss = 0.034000575402751566
Trained batch 55 in epoch 4, gen_loss = 0.40519597115261213, disc_loss = 0.03349450211057307
Trained batch 56 in epoch 4, gen_loss = 0.4064119526168756, disc_loss = 0.03329488847878549
Trained batch 57 in epoch 4, gen_loss = 0.4060323002009556, disc_loss = 0.03331610846638294
Trained batch 58 in epoch 4, gen_loss = 0.4060717821121216, disc_loss = 0.03296790139797002
Trained batch 59 in epoch 4, gen_loss = 0.4062410150965055, disc_loss = 0.03258127766118075
Trained batch 60 in epoch 4, gen_loss = 0.4074972242605491, disc_loss = 0.032122598857939486
Trained batch 61 in epoch 4, gen_loss = 0.40679479510553423, disc_loss = 0.031771244935601226
Trained batch 62 in epoch 4, gen_loss = 0.40698168533188955, disc_loss = 0.031330265470647385
Trained batch 63 in epoch 4, gen_loss = 0.40612305607646704, disc_loss = 0.030946437847887864
Trained batch 64 in epoch 4, gen_loss = 0.4063773765013768, disc_loss = 0.030519861502286333
Trained batch 65 in epoch 4, gen_loss = 0.40614154483332776, disc_loss = 0.03020812989085574
Trained batch 66 in epoch 4, gen_loss = 0.4051996487290112, disc_loss = 0.029828975369820175
Trained batch 67 in epoch 4, gen_loss = 0.40552456238690543, disc_loss = 0.029476896739866146
Trained batch 68 in epoch 4, gen_loss = 0.4049675741057465, disc_loss = 0.02916855501699383
Trained batch 69 in epoch 4, gen_loss = 0.4058592732463564, disc_loss = 0.028842424085762885
Trained batch 70 in epoch 4, gen_loss = 0.4063689801054941, disc_loss = 0.028510972047486986
Trained batch 71 in epoch 4, gen_loss = 0.40631486599644023, disc_loss = 0.028221060214693554
Trained batch 72 in epoch 4, gen_loss = 0.4069311455504535, disc_loss = 0.027891435536032873
Trained batch 73 in epoch 4, gen_loss = 0.40676969531420115, disc_loss = 0.02759059112380586
Trained batch 74 in epoch 4, gen_loss = 0.40643077770868935, disc_loss = 0.0272540644214799
Trained batch 75 in epoch 4, gen_loss = 0.4066206757959567, disc_loss = 0.027004424583681515
Trained batch 76 in epoch 4, gen_loss = 0.4065559088409721, disc_loss = 0.026692058355849865
Trained batch 77 in epoch 4, gen_loss = 0.4069760533479544, disc_loss = 0.02638866744326571
Trained batch 78 in epoch 4, gen_loss = 0.40705772479878194, disc_loss = 0.02608706198538406
Trained batch 79 in epoch 4, gen_loss = 0.4069644521921873, disc_loss = 0.02579733415041119
Trained batch 80 in epoch 4, gen_loss = 0.4066030066690327, disc_loss = 0.025536144928385813
Trained batch 81 in epoch 4, gen_loss = 0.40638069045252917, disc_loss = 0.02525713663582304
Trained batch 82 in epoch 4, gen_loss = 0.40720911485603056, disc_loss = 0.02505763127266553
Trained batch 83 in epoch 4, gen_loss = 0.40674709989911034, disc_loss = 0.024876448733266443
Trained batch 84 in epoch 4, gen_loss = 0.4069371297078974, disc_loss = 0.024665213417371407
Trained batch 85 in epoch 4, gen_loss = 0.40640708700168965, disc_loss = 0.02442313082310436
Trained batch 86 in epoch 4, gen_loss = 0.4065158360305874, disc_loss = 0.02417711417683154
Trained batch 87 in epoch 4, gen_loss = 0.4068695730106397, disc_loss = 0.023956889982483433
Trained batch 88 in epoch 4, gen_loss = 0.40653431516015126, disc_loss = 0.02379686683364045
Trained batch 89 in epoch 4, gen_loss = 0.40590265658166674, disc_loss = 0.023667709888993867
Trained batch 90 in epoch 4, gen_loss = 0.4071697121138101, disc_loss = 0.02344700207698394
Trained batch 91 in epoch 4, gen_loss = 0.40706999891478085, disc_loss = 0.023228840970778434
Trained batch 92 in epoch 4, gen_loss = 0.4069788933441203, disc_loss = 0.023022946168077728
Trained batch 93 in epoch 4, gen_loss = 0.4073002886898974, disc_loss = 0.022816521276600978
Trained batch 94 in epoch 4, gen_loss = 0.4072796881198883, disc_loss = 0.02261205087415874
Trained batch 95 in epoch 4, gen_loss = 0.40686537387470406, disc_loss = 0.022401908106985502
Trained batch 96 in epoch 4, gen_loss = 0.4063114222792006, disc_loss = 0.02219806375106816
Trained batch 97 in epoch 4, gen_loss = 0.4061428630838589, disc_loss = 0.02200671842758905
Trained batch 98 in epoch 4, gen_loss = 0.40651000238428214, disc_loss = 0.021880077231073318
Trained batch 99 in epoch 4, gen_loss = 0.40659270614385606, disc_loss = 0.02169398394646123
Trained batch 100 in epoch 4, gen_loss = 0.4066667022681472, disc_loss = 0.021535281214106937
Trained batch 101 in epoch 4, gen_loss = 0.40648400929628636, disc_loss = 0.021350623864004863
Trained batch 102 in epoch 4, gen_loss = 0.40635208510658116, disc_loss = 0.021186651026793908
Trained batch 103 in epoch 4, gen_loss = 0.406623723415228, disc_loss = 0.02100251949965381
Trained batch 104 in epoch 4, gen_loss = 0.40585846645491463, disc_loss = 0.020830086960146824
Trained batch 105 in epoch 4, gen_loss = 0.4065563903664643, disc_loss = 0.02066653215915035
Trained batch 106 in epoch 4, gen_loss = 0.40697962769838136, disc_loss = 0.020499793501466374
Trained batch 107 in epoch 4, gen_loss = 0.4071439885430866, disc_loss = 0.020353606688634802
Trained batch 108 in epoch 4, gen_loss = 0.4069721042563062, disc_loss = 0.02019208363137729
Trained batch 109 in epoch 4, gen_loss = 0.40699831084771587, disc_loss = 0.020045061254958536
Trained batch 110 in epoch 4, gen_loss = 0.4069450975538374, disc_loss = 0.019896884167751483
Trained batch 111 in epoch 4, gen_loss = 0.4068741596170834, disc_loss = 0.019783000407707214
Trained batch 112 in epoch 4, gen_loss = 0.40697941025801465, disc_loss = 0.019648911031704824
Trained batch 113 in epoch 4, gen_loss = 0.4070379757567456, disc_loss = 0.019502288165600283
Trained batch 114 in epoch 4, gen_loss = 0.4071026317451311, disc_loss = 0.019354086909848064
Trained batch 115 in epoch 4, gen_loss = 0.4068186396154864, disc_loss = 0.019221866914825834
Trained batch 116 in epoch 4, gen_loss = 0.4061840530644115, disc_loss = 0.01908908240122991
Trained batch 117 in epoch 4, gen_loss = 0.4062179296703662, disc_loss = 0.018958779170288372
Trained batch 118 in epoch 4, gen_loss = 0.40629068693193066, disc_loss = 0.018819871965107045
Trained batch 119 in epoch 4, gen_loss = 0.40667392363150917, disc_loss = 0.018683725378165643
Trained batch 120 in epoch 4, gen_loss = 0.40686372193423187, disc_loss = 0.018545035090035765
Trained batch 121 in epoch 4, gen_loss = 0.4069120449120881, disc_loss = 0.018410384412625897
Trained batch 122 in epoch 4, gen_loss = 0.4064013410389908, disc_loss = 0.01827769236056119
Trained batch 123 in epoch 4, gen_loss = 0.4062470216904917, disc_loss = 0.018147354684544786
Trained batch 124 in epoch 4, gen_loss = 0.40656880068778994, disc_loss = 0.01802781757339835
Trained batch 125 in epoch 4, gen_loss = 0.40637501955978456, disc_loss = 0.017908101916194907
Trained batch 126 in epoch 4, gen_loss = 0.40710724784633306, disc_loss = 0.017793807960078706
Trained batch 127 in epoch 4, gen_loss = 0.40654582367278636, disc_loss = 0.017672462405244005
Trained batch 128 in epoch 4, gen_loss = 0.4067268812841223, disc_loss = 0.017585299586039757
Trained batch 129 in epoch 4, gen_loss = 0.40738508105278015, disc_loss = 0.01748778350973645
Trained batch 130 in epoch 4, gen_loss = 0.40686154843286704, disc_loss = 0.017377964803906343
Trained batch 131 in epoch 4, gen_loss = 0.4064404307441278, disc_loss = 0.017259469554780728
Trained batch 132 in epoch 4, gen_loss = 0.40618508381951124, disc_loss = 0.017145749338188285
Trained batch 133 in epoch 4, gen_loss = 0.4054287752108787, disc_loss = 0.017082679282644512
Trained batch 134 in epoch 4, gen_loss = 0.40517608214307715, disc_loss = 0.01701003143960541
Trained batch 135 in epoch 4, gen_loss = 0.40528839278747053, disc_loss = 0.01690924909866333
Trained batch 136 in epoch 4, gen_loss = 0.4048512762915479, disc_loss = 0.01681050638426911
Trained batch 137 in epoch 4, gen_loss = 0.40454564038394153, disc_loss = 0.016715977984595287
Trained batch 138 in epoch 4, gen_loss = 0.40445168605811305, disc_loss = 0.01661821687845312
Trained batch 139 in epoch 4, gen_loss = 0.40448099332196374, disc_loss = 0.016555174961519828
Trained batch 140 in epoch 4, gen_loss = 0.40468351363290284, disc_loss = 0.01645990128460479
Trained batch 141 in epoch 4, gen_loss = 0.40492900870215726, disc_loss = 0.016378322969564617
Trained batch 142 in epoch 4, gen_loss = 0.4051988199874238, disc_loss = 0.016299624392482732
Trained batch 143 in epoch 4, gen_loss = 0.4052436248295837, disc_loss = 0.01620680050998797
Trained batch 144 in epoch 4, gen_loss = 0.4051508595203531, disc_loss = 0.016119195330599002
Trained batch 145 in epoch 4, gen_loss = 0.4053051171645726, disc_loss = 0.016033362355625434
Trained batch 146 in epoch 4, gen_loss = 0.4054956945026813, disc_loss = 0.01595536547278998
Trained batch 147 in epoch 4, gen_loss = 0.4052439962287207, disc_loss = 0.01587828481648545
Trained batch 148 in epoch 4, gen_loss = 0.4048472236866919, disc_loss = 0.015789459575898945
Trained batch 149 in epoch 4, gen_loss = 0.4050303377707799, disc_loss = 0.01576560010900721
Trained batch 150 in epoch 4, gen_loss = 0.40535283522890103, disc_loss = 0.015679514205965233
Trained batch 151 in epoch 4, gen_loss = 0.4056840113511211, disc_loss = 0.01560959737444615
Trained batch 152 in epoch 4, gen_loss = 0.40528908371925354, disc_loss = 0.015533416754919184
Trained batch 153 in epoch 4, gen_loss = 0.40458701299382493, disc_loss = 0.01545694505103392
Trained batch 154 in epoch 4, gen_loss = 0.40463415345837994, disc_loss = 0.015379185404538387
Trained batch 155 in epoch 4, gen_loss = 0.4044580415655405, disc_loss = 0.015320265048499912
Trained batch 156 in epoch 4, gen_loss = 0.404249544546103, disc_loss = 0.015253358663676699
Trained batch 157 in epoch 4, gen_loss = 0.40395764025706277, disc_loss = 0.015175153251554628
Trained batch 158 in epoch 4, gen_loss = 0.40375676976059965, disc_loss = 0.015119943701158389
Trained batch 159 in epoch 4, gen_loss = 0.40398006327450275, disc_loss = 0.015049122414347948
Trained batch 160 in epoch 4, gen_loss = 0.4034470838049184, disc_loss = 0.015000515140922774
Trained batch 161 in epoch 4, gen_loss = 0.40365921678366484, disc_loss = 0.014958936856904378
Trained batch 162 in epoch 4, gen_loss = 0.4040229101122523, disc_loss = 0.014961519236447849
Trained batch 163 in epoch 4, gen_loss = 0.40380547232017283, disc_loss = 0.014951090684029979
Trained batch 164 in epoch 4, gen_loss = 0.40379863236889696, disc_loss = 0.014914874877131572
Trained batch 165 in epoch 4, gen_loss = 0.40404559851410876, disc_loss = 0.014897784979099476
Trained batch 166 in epoch 4, gen_loss = 0.40398383658089326, disc_loss = 0.01484064864689027
Trained batch 167 in epoch 4, gen_loss = 0.4047370700254327, disc_loss = 0.014792313569896146
Trained batch 168 in epoch 4, gen_loss = 0.4046542678006302, disc_loss = 0.014726827235908948
Trained batch 169 in epoch 4, gen_loss = 0.4045536146444433, disc_loss = 0.014679225140442962
Trained batch 170 in epoch 4, gen_loss = 0.4044450402956957, disc_loss = 0.014615870430134237
Trained batch 171 in epoch 4, gen_loss = 0.4043467918107676, disc_loss = 0.014548105743394211
Trained batch 172 in epoch 4, gen_loss = 0.40421072303215205, disc_loss = 0.014488633133261061
Trained batch 173 in epoch 4, gen_loss = 0.4042800807062237, disc_loss = 0.014452463875647805
Trained batch 174 in epoch 4, gen_loss = 0.4047373829569135, disc_loss = 0.014393425004423728
Trained batch 175 in epoch 4, gen_loss = 0.4050005486404354, disc_loss = 0.014335776505256283
Trained batch 176 in epoch 4, gen_loss = 0.40472613199282503, disc_loss = 0.014321858921656543
Trained batch 177 in epoch 4, gen_loss = 0.40437088521678793, disc_loss = 0.0143255225828786
Trained batch 178 in epoch 4, gen_loss = 0.40422964861939076, disc_loss = 0.014259975479639983
Trained batch 179 in epoch 4, gen_loss = 0.40390008240938186, disc_loss = 0.014296411043162354
Trained batch 180 in epoch 4, gen_loss = 0.4041283163576495, disc_loss = 0.014350732163917171
Trained batch 181 in epoch 4, gen_loss = 0.40388843646416295, disc_loss = 0.014292083678710796
Trained batch 182 in epoch 4, gen_loss = 0.4039463304756769, disc_loss = 0.014256649310293459
Trained batch 183 in epoch 4, gen_loss = 0.4039261820523635, disc_loss = 0.01422641007292955
Trained batch 184 in epoch 4, gen_loss = 0.40405992108422356, disc_loss = 0.014166397288617854
Trained batch 185 in epoch 4, gen_loss = 0.4044593532559692, disc_loss = 0.014137325897907978
Trained batch 186 in epoch 4, gen_loss = 0.4043279569098019, disc_loss = 0.014165841968715152
Trained batch 187 in epoch 4, gen_loss = 0.40386226059908564, disc_loss = 0.014114926251498586
Trained batch 188 in epoch 4, gen_loss = 0.40362735825871665, disc_loss = 0.014139295589528662
Trained batch 189 in epoch 4, gen_loss = 0.40316448917514397, disc_loss = 0.014108161235497775
Trained batch 190 in epoch 4, gen_loss = 0.40326701518128677, disc_loss = 0.014074785946331997
Trained batch 191 in epoch 4, gen_loss = 0.40321802208200097, disc_loss = 0.014037206848418768
Trained batch 192 in epoch 4, gen_loss = 0.40349805092564517, disc_loss = 0.014026550114651842
Trained batch 193 in epoch 4, gen_loss = 0.4031973640943311, disc_loss = 0.013985781428120915
Trained batch 194 in epoch 4, gen_loss = 0.4028534424610627, disc_loss = 0.013939761484447772
Trained batch 195 in epoch 4, gen_loss = 0.40318545455835303, disc_loss = 0.013907365410051746
Trained batch 196 in epoch 4, gen_loss = 0.40349157389045365, disc_loss = 0.013860696259540917
Trained batch 197 in epoch 4, gen_loss = 0.40327671681991734, disc_loss = 0.013822652410711114
Trained batch 198 in epoch 4, gen_loss = 0.4031512943943541, disc_loss = 0.013850351750509037
Trained batch 199 in epoch 4, gen_loss = 0.40321996450424197, disc_loss = 0.014245748074608855
Trained batch 200 in epoch 4, gen_loss = 0.40269763122743635, disc_loss = 0.015782611585333388
Trained batch 201 in epoch 4, gen_loss = 0.4025358250825712, disc_loss = 0.016580906836661777
Trained batch 202 in epoch 4, gen_loss = 0.40222032214033193, disc_loss = 0.017430478571042456
Trained batch 203 in epoch 4, gen_loss = 0.40189659201047, disc_loss = 0.018076546711039126
Trained batch 204 in epoch 4, gen_loss = 0.4017125176220405, disc_loss = 0.01869339906758197
Trained batch 205 in epoch 4, gen_loss = 0.4016624350570938, disc_loss = 0.019081362389204392
Trained batch 206 in epoch 4, gen_loss = 0.40111319886313546, disc_loss = 0.019403398758506826
Trained batch 207 in epoch 4, gen_loss = 0.40076692402362823, disc_loss = 0.01991429280371029
Trained batch 208 in epoch 4, gen_loss = 0.40097945785978767, disc_loss = 0.020108336397295184
Trained batch 209 in epoch 4, gen_loss = 0.4007782623881385, disc_loss = 0.02046965882348429
Trained batch 210 in epoch 4, gen_loss = 0.4011062637889555, disc_loss = 0.020929727546089457
Trained batch 211 in epoch 4, gen_loss = 0.4010507302745333, disc_loss = 0.021402267459670152
Trained batch 212 in epoch 4, gen_loss = 0.4011664148507544, disc_loss = 0.022641559548461768
Trained batch 213 in epoch 4, gen_loss = 0.4007258956955972, disc_loss = 0.023029764471727936
Trained batch 214 in epoch 4, gen_loss = 0.4009386097275934, disc_loss = 0.023413407041821196
Trained batch 215 in epoch 4, gen_loss = 0.4009119196346513, disc_loss = 0.023561323494370165
Trained batch 216 in epoch 4, gen_loss = 0.40071019736303165, disc_loss = 0.023701385334713495
Trained batch 217 in epoch 4, gen_loss = 0.4007388017046342, disc_loss = 0.02407661960577729
Trained batch 218 in epoch 4, gen_loss = 0.40028088931079325, disc_loss = 0.02539713978586659
Trained batch 219 in epoch 4, gen_loss = 0.4006850605661219, disc_loss = 0.025947144002632493
Trained batch 220 in epoch 4, gen_loss = 0.40060013519153337, disc_loss = 0.025982452987912383
Trained batch 221 in epoch 4, gen_loss = 0.40046740934118497, disc_loss = 0.02598127971250178
Trained batch 222 in epoch 4, gen_loss = 0.40038863973767236, disc_loss = 0.025933882486254747
Trained batch 223 in epoch 4, gen_loss = 0.40050146941627773, disc_loss = 0.025863769956361336
Trained batch 224 in epoch 4, gen_loss = 0.400510227282842, disc_loss = 0.025810673118361997
Trained batch 225 in epoch 4, gen_loss = 0.4006435672002556, disc_loss = 0.02574560162147705
Trained batch 226 in epoch 4, gen_loss = 0.40057621535225585, disc_loss = 0.025671063932089653
Trained batch 227 in epoch 4, gen_loss = 0.4004350862743562, disc_loss = 0.025590555519253638
Trained batch 228 in epoch 4, gen_loss = 0.40065412412043744, disc_loss = 0.025495504008252255
Trained batch 229 in epoch 4, gen_loss = 0.4004516005516052, disc_loss = 0.025457230274585765
Trained batch 230 in epoch 4, gen_loss = 0.4005680771875175, disc_loss = 0.025412240625536514
Trained batch 231 in epoch 4, gen_loss = 0.400745737013118, disc_loss = 0.025339072320815014
Trained batch 232 in epoch 4, gen_loss = 0.4007430021599127, disc_loss = 0.02527505947554748
Trained batch 233 in epoch 4, gen_loss = 0.40060716714614475, disc_loss = 0.025231473688653104
Trained batch 234 in epoch 4, gen_loss = 0.40056434501992894, disc_loss = 0.025155639994711158
Trained batch 235 in epoch 4, gen_loss = 0.4007377406045542, disc_loss = 0.025091610215032093
Trained batch 236 in epoch 4, gen_loss = 0.4010699847831002, disc_loss = 0.025036290603815597
Trained batch 237 in epoch 4, gen_loss = 0.4012841371928944, disc_loss = 0.02497333082118064
Trained batch 238 in epoch 4, gen_loss = 0.4010787306969136, disc_loss = 0.024986961557896162
Trained batch 239 in epoch 4, gen_loss = 0.40121787836154305, disc_loss = 0.024912017920966416
Trained batch 240 in epoch 4, gen_loss = 0.4008753621231966, disc_loss = 0.024843128768561012
Trained batch 241 in epoch 4, gen_loss = 0.400680512066715, disc_loss = 0.02476553803007696
Trained batch 242 in epoch 4, gen_loss = 0.40047870852329115, disc_loss = 0.02468731246051214
Trained batch 243 in epoch 4, gen_loss = 0.4005241249916983, disc_loss = 0.0246217948337826
Trained batch 244 in epoch 4, gen_loss = 0.40093008133829855, disc_loss = 0.024555412183363674
Trained batch 245 in epoch 4, gen_loss = 0.4010003261207565, disc_loss = 0.024472026345111822
Trained batch 246 in epoch 4, gen_loss = 0.40081603143379274, disc_loss = 0.02442866275115278
Trained batch 247 in epoch 4, gen_loss = 0.40060963806125427, disc_loss = 0.024394030962045486
Trained batch 248 in epoch 4, gen_loss = 0.4006170716630407, disc_loss = 0.024320985603400593
Trained batch 249 in epoch 4, gen_loss = 0.4008084706068039, disc_loss = 0.024251605150755494
Trained batch 250 in epoch 4, gen_loss = 0.40096401717083385, disc_loss = 0.024174907136675104
Trained batch 251 in epoch 4, gen_loss = 0.400773886886854, disc_loss = 0.024106004855148345
Trained batch 252 in epoch 4, gen_loss = 0.40088542459510534, disc_loss = 0.024085882921857767
Trained batch 253 in epoch 4, gen_loss = 0.40065093526220696, disc_loss = 0.024028473808228472
Trained batch 254 in epoch 4, gen_loss = 0.4007149508186415, disc_loss = 0.023952965633304533
Trained batch 255 in epoch 4, gen_loss = 0.4008640017127618, disc_loss = 0.02387383165614665
Trained batch 256 in epoch 4, gen_loss = 0.40080367173666154, disc_loss = 0.023848065904863467
Trained batch 257 in epoch 4, gen_loss = 0.40106803617736164, disc_loss = 0.023819010843280992
Trained batch 258 in epoch 4, gen_loss = 0.40088866507224596, disc_loss = 0.0237672890021383
Trained batch 259 in epoch 4, gen_loss = 0.400631064749681, disc_loss = 0.023709756885923874
Trained batch 260 in epoch 4, gen_loss = 0.4007521915709835, disc_loss = 0.023635634308113534
Trained batch 261 in epoch 4, gen_loss = 0.40080760669617255, disc_loss = 0.023556114637865222
Trained batch 262 in epoch 4, gen_loss = 0.40109407799778785, disc_loss = 0.023543333834366513
Trained batch 263 in epoch 4, gen_loss = 0.4008311461092848, disc_loss = 0.0235372815491935
Trained batch 264 in epoch 4, gen_loss = 0.40050010647413864, disc_loss = 0.023474886396214506
Trained batch 265 in epoch 4, gen_loss = 0.4009225194839607, disc_loss = 0.02340323537635386
Trained batch 266 in epoch 4, gen_loss = 0.40089548448944806, disc_loss = 0.023334779408202274
Trained batch 267 in epoch 4, gen_loss = 0.4005943160893312, disc_loss = 0.02344158920589765
Trained batch 268 in epoch 4, gen_loss = 0.4008388669960561, disc_loss = 0.024993920696598088
Trained batch 269 in epoch 4, gen_loss = 0.4007523955018432, disc_loss = 0.02528366598740427
Trained batch 270 in epoch 4, gen_loss = 0.4007254413353121, disc_loss = 0.02601368096184563
Trained batch 271 in epoch 4, gen_loss = 0.40042592344038624, disc_loss = 0.026102238079200854
Trained batch 272 in epoch 4, gen_loss = 0.4003567923774649, disc_loss = 0.026372295614560528
Trained batch 273 in epoch 4, gen_loss = 0.40027043745465524, disc_loss = 0.027017776838615944
Trained batch 274 in epoch 4, gen_loss = 0.40013681704347787, disc_loss = 0.028734384522434663
Trained batch 275 in epoch 4, gen_loss = 0.4003161776109018, disc_loss = 0.02895007991574475
Trained batch 276 in epoch 4, gen_loss = 0.40030677062509723, disc_loss = 0.029624707127302644
Trained batch 277 in epoch 4, gen_loss = 0.4000690389665768, disc_loss = 0.030037278448074065
Trained batch 278 in epoch 4, gen_loss = 0.3997075332322001, disc_loss = 0.030370801865410288
Trained batch 279 in epoch 4, gen_loss = 0.39971870290381567, disc_loss = 0.030481150764223586
Trained batch 280 in epoch 4, gen_loss = 0.3995529919120341, disc_loss = 0.030571923632211187
Trained batch 281 in epoch 4, gen_loss = 0.3995975893228612, disc_loss = 0.030778000267892944
Trained batch 282 in epoch 4, gen_loss = 0.3997240500399586, disc_loss = 0.031023066732357833
Trained batch 283 in epoch 4, gen_loss = 0.39952116197263693, disc_loss = 0.031595364676601526
Trained batch 284 in epoch 4, gen_loss = 0.3994394712280809, disc_loss = 0.03304330742337921
Trained batch 285 in epoch 4, gen_loss = 0.3990029187260808, disc_loss = 0.033117010217026475
Trained batch 286 in epoch 4, gen_loss = 0.3987605002698998, disc_loss = 0.033313057840905616
Trained batch 287 in epoch 4, gen_loss = 0.39846892696287894, disc_loss = 0.03329305269734403
Trained batch 288 in epoch 4, gen_loss = 0.3984351055019867, disc_loss = 0.03326431807947496
Trained batch 289 in epoch 4, gen_loss = 0.39856312120782916, disc_loss = 0.0332041187834091
Trained batch 290 in epoch 4, gen_loss = 0.39837228135554653, disc_loss = 0.033138960540291446
Trained batch 291 in epoch 4, gen_loss = 0.39840201002685993, disc_loss = 0.03306030146961024
Trained batch 292 in epoch 4, gen_loss = 0.3985660360941708, disc_loss = 0.03301306604606389
Trained batch 293 in epoch 4, gen_loss = 0.39815530322846915, disc_loss = 0.03302261293319301
Trained batch 294 in epoch 4, gen_loss = 0.39824411838741625, disc_loss = 0.033916957491330044
Trained batch 295 in epoch 4, gen_loss = 0.3978565152029733, disc_loss = 0.03461251457377551
Trained batch 296 in epoch 4, gen_loss = 0.3978207737508446, disc_loss = 0.03521889612911212
Trained batch 297 in epoch 4, gen_loss = 0.39780628121139217, disc_loss = 0.03518073956893082
Trained batch 298 in epoch 4, gen_loss = 0.3977667698294024, disc_loss = 0.03517654490615101
Trained batch 299 in epoch 4, gen_loss = 0.3976948540409406, disc_loss = 0.035139717923399684
Trained batch 300 in epoch 4, gen_loss = 0.3975645162140412, disc_loss = 0.03511210541941683
Trained batch 301 in epoch 4, gen_loss = 0.39749089672865456, disc_loss = 0.03503570962035782
Trained batch 302 in epoch 4, gen_loss = 0.3974107084888043, disc_loss = 0.034991075507236076
Trained batch 303 in epoch 4, gen_loss = 0.3971110458828901, disc_loss = 0.03497985445114624
Trained batch 304 in epoch 4, gen_loss = 0.3973724332989239, disc_loss = 0.03488694300042985
Trained batch 305 in epoch 4, gen_loss = 0.3974801147100972, disc_loss = 0.034812201783471906
Trained batch 306 in epoch 4, gen_loss = 0.39752391961187805, disc_loss = 0.03471233398564075
Trained batch 307 in epoch 4, gen_loss = 0.3974726770992403, disc_loss = 0.03461238868533053
Trained batch 308 in epoch 4, gen_loss = 0.39725875893071244, disc_loss = 0.03452597725737092
Trained batch 309 in epoch 4, gen_loss = 0.3972776508139026, disc_loss = 0.034485577331900955
Trained batch 310 in epoch 4, gen_loss = 0.3974276892241941, disc_loss = 0.03439902187170838
Trained batch 311 in epoch 4, gen_loss = 0.3977520330212055, disc_loss = 0.034338963074379794
Trained batch 312 in epoch 4, gen_loss = 0.3977961152696762, disc_loss = 0.03424359945328936
Trained batch 313 in epoch 4, gen_loss = 0.39788662124970914, disc_loss = 0.0341550551727859
Trained batch 314 in epoch 4, gen_loss = 0.3977471046977573, disc_loss = 0.034059030390788045
Trained batch 315 in epoch 4, gen_loss = 0.3977482254746594, disc_loss = 0.03396521533560892
Trained batch 316 in epoch 4, gen_loss = 0.39763454007049465, disc_loss = 0.03387218383941447
Trained batch 317 in epoch 4, gen_loss = 0.3978944643863342, disc_loss = 0.03377923976634366
Trained batch 318 in epoch 4, gen_loss = 0.3976756659421054, disc_loss = 0.033685159178663826
Trained batch 319 in epoch 4, gen_loss = 0.3976106603629887, disc_loss = 0.03358711508444685
Trained batch 320 in epoch 4, gen_loss = 0.3976321880505464, disc_loss = 0.03351066436878234
Trained batch 321 in epoch 4, gen_loss = 0.3976507117474301, disc_loss = 0.03344109766178053
Trained batch 322 in epoch 4, gen_loss = 0.39772081033733236, disc_loss = 0.03392572526354343
Trained batch 323 in epoch 4, gen_loss = 0.39767368892092764, disc_loss = 0.03481409510843352
Trained batch 324 in epoch 4, gen_loss = 0.39763899839841405, disc_loss = 0.03495703177490773
Trained batch 325 in epoch 4, gen_loss = 0.39770301938788294, disc_loss = 0.03501510719070211
Trained batch 326 in epoch 4, gen_loss = 0.3979303452217615, disc_loss = 0.03496954840820123
Trained batch 327 in epoch 4, gen_loss = 0.3978828923186151, disc_loss = 0.034973163817506626
Trained batch 328 in epoch 4, gen_loss = 0.39787579687895386, disc_loss = 0.034904394843360824
Trained batch 329 in epoch 4, gen_loss = 0.3978442087317958, disc_loss = 0.03494481838442329
Trained batch 330 in epoch 4, gen_loss = 0.3976961819967114, disc_loss = 0.03507446897324467
Trained batch 331 in epoch 4, gen_loss = 0.3976293012320277, disc_loss = 0.03538783806963846
Trained batch 332 in epoch 4, gen_loss = 0.39761537009173326, disc_loss = 0.035492146327216235
Trained batch 333 in epoch 4, gen_loss = 0.39784382292610443, disc_loss = 0.03550809366498867
Trained batch 334 in epoch 4, gen_loss = 0.3978269283451251, disc_loss = 0.03555531220531453
Trained batch 335 in epoch 4, gen_loss = 0.3976419674498694, disc_loss = 0.035504830824807175
Trained batch 336 in epoch 4, gen_loss = 0.3977162814104946, disc_loss = 0.03544523626205288
Trained batch 337 in epoch 4, gen_loss = 0.3977686206440954, disc_loss = 0.03537760221519226
Trained batch 338 in epoch 4, gen_loss = 0.39758112349693053, disc_loss = 0.035327473183843834
Trained batch 339 in epoch 4, gen_loss = 0.3975468223585802, disc_loss = 0.03529095423565356
Trained batch 340 in epoch 4, gen_loss = 0.39746264768136214, disc_loss = 0.0352844958998607
Trained batch 341 in epoch 4, gen_loss = 0.39743568465026496, disc_loss = 0.03538096994154798
Trained batch 342 in epoch 4, gen_loss = 0.3976603802890889, disc_loss = 0.03615474733069224
Trained batch 343 in epoch 4, gen_loss = 0.39748421666580575, disc_loss = 0.037374283052739946
Trained batch 344 in epoch 4, gen_loss = 0.39754479579303575, disc_loss = 0.03821962144920953
Trained batch 345 in epoch 4, gen_loss = 0.3974113752903966, disc_loss = 0.03822215506100403
Trained batch 346 in epoch 4, gen_loss = 0.397255995345734, disc_loss = 0.038253524102826175
Trained batch 347 in epoch 4, gen_loss = 0.3974521022247172, disc_loss = 0.03831068634680451
Trained batch 348 in epoch 4, gen_loss = 0.3974200616080986, disc_loss = 0.03822853579352687
Trained batch 349 in epoch 4, gen_loss = 0.3974575071675437, disc_loss = 0.03821972820209339
Trained batch 350 in epoch 4, gen_loss = 0.3974574550434395, disc_loss = 0.0381349364485979
Trained batch 351 in epoch 4, gen_loss = 0.39751591423357074, disc_loss = 0.03805574343840073
Trained batch 352 in epoch 4, gen_loss = 0.39753636101487677, disc_loss = 0.037967600393710554
Trained batch 353 in epoch 4, gen_loss = 0.3974480317474085, disc_loss = 0.037903666155252314
Trained batch 354 in epoch 4, gen_loss = 0.39738031239576743, disc_loss = 0.03804292145322903
Trained batch 355 in epoch 4, gen_loss = 0.39714033181747693, disc_loss = 0.03930842252337018
Trained batch 356 in epoch 4, gen_loss = 0.396993468288614, disc_loss = 0.03941098602289068
Trained batch 357 in epoch 4, gen_loss = 0.39709225546714316, disc_loss = 0.03976636183904692
Trained batch 358 in epoch 4, gen_loss = 0.3969423917010634, disc_loss = 0.03994161060338056
Trained batch 359 in epoch 4, gen_loss = 0.3971042854090532, disc_loss = 0.0400574074395182
Trained batch 360 in epoch 4, gen_loss = 0.39714125781178145, disc_loss = 0.04013940212710237
Trained batch 361 in epoch 4, gen_loss = 0.39711758066277475, disc_loss = 0.04007374997558175
Trained batch 362 in epoch 4, gen_loss = 0.39704314834815413, disc_loss = 0.04003028162740961
Trained batch 363 in epoch 4, gen_loss = 0.39704277849459385, disc_loss = 0.04003696307983853
Trained batch 364 in epoch 4, gen_loss = 0.39726621100347337, disc_loss = 0.039940760188659476
Trained batch 365 in epoch 4, gen_loss = 0.3969349039545476, disc_loss = 0.03999680840083311
Trained batch 366 in epoch 4, gen_loss = 0.39698287625403755, disc_loss = 0.03990467626960537
Trained batch 367 in epoch 4, gen_loss = 0.39681476654241915, disc_loss = 0.03992458506146922
Trained batch 368 in epoch 4, gen_loss = 0.3967695434888204, disc_loss = 0.03987249663714219
Trained batch 369 in epoch 4, gen_loss = 0.39697602657047476, disc_loss = 0.03987218663442527
Trained batch 370 in epoch 4, gen_loss = 0.39694267888917434, disc_loss = 0.03978726740096849
Trained batch 371 in epoch 4, gen_loss = 0.39723783963790504, disc_loss = 0.03969569224332239
Trained batch 372 in epoch 4, gen_loss = 0.39712084114711343, disc_loss = 0.03961117728394843
Trained batch 373 in epoch 4, gen_loss = 0.39718154646496084, disc_loss = 0.03958027707232302
Trained batch 374 in epoch 4, gen_loss = 0.39696985061963397, disc_loss = 0.039701451688694454
Trained batch 375 in epoch 4, gen_loss = 0.39716560504537946, disc_loss = 0.039653145549311104
Trained batch 376 in epoch 4, gen_loss = 0.3972500817212881, disc_loss = 0.03989792575618741
Trained batch 377 in epoch 4, gen_loss = 0.39707893487953005, disc_loss = 0.04048840916394034
Trained batch 378 in epoch 4, gen_loss = 0.39726418374710787, disc_loss = 0.0404988311051138
Trained batch 379 in epoch 4, gen_loss = 0.39742663808559114, disc_loss = 0.04051535170690745
Trained batch 380 in epoch 4, gen_loss = 0.3972924313363754, disc_loss = 0.04043467431799741
Trained batch 381 in epoch 4, gen_loss = 0.39711023874931933, disc_loss = 0.040411185765460975
Trained batch 382 in epoch 4, gen_loss = 0.39682080306832535, disc_loss = 0.040391970396360416
Trained batch 383 in epoch 4, gen_loss = 0.39670141188738245, disc_loss = 0.04032385221186511
Trained batch 384 in epoch 4, gen_loss = 0.3967210250241416, disc_loss = 0.04023458071554975
Trained batch 385 in epoch 4, gen_loss = 0.39661419785393337, disc_loss = 0.04018046996173801
Trained batch 386 in epoch 4, gen_loss = 0.3967215241695867, disc_loss = 0.04010454380195299
Trained batch 387 in epoch 4, gen_loss = 0.39676121345807597, disc_loss = 0.04001867334381197
Trained batch 388 in epoch 4, gen_loss = 0.39662812646373075, disc_loss = 0.03998976726663134
Trained batch 389 in epoch 4, gen_loss = 0.3968207523608819, disc_loss = 0.04006613633470037
Trained batch 390 in epoch 4, gen_loss = 0.39690188305152346, disc_loss = 0.03997710530671155
Trained batch 391 in epoch 4, gen_loss = 0.396687276205238, disc_loss = 0.04015040926591312
Trained batch 392 in epoch 4, gen_loss = 0.3968481409337381, disc_loss = 0.040858842457085376
Trained batch 393 in epoch 4, gen_loss = 0.39679869086609276, disc_loss = 0.040798455766026344
Trained batch 394 in epoch 4, gen_loss = 0.39657962510857403, disc_loss = 0.041593675811397786
Trained batch 395 in epoch 4, gen_loss = 0.3964254628829282, disc_loss = 0.042425280329571435
Trained batch 396 in epoch 4, gen_loss = 0.39653022373353203, disc_loss = 0.04240694640747386
Trained batch 397 in epoch 4, gen_loss = 0.39649191274115786, disc_loss = 0.042457198776508304
Trained batch 398 in epoch 4, gen_loss = 0.39636226009605524, disc_loss = 0.042465492715081085
Trained batch 399 in epoch 4, gen_loss = 0.3963112611323595, disc_loss = 0.04240576746495208
Trained batch 400 in epoch 4, gen_loss = 0.39626513804283525, disc_loss = 0.04235048411951686
Trained batch 401 in epoch 4, gen_loss = 0.3962266242029655, disc_loss = 0.04229830102664905
Trained batch 402 in epoch 4, gen_loss = 0.39618585918736515, disc_loss = 0.04223502114058123
Trained batch 403 in epoch 4, gen_loss = 0.3961286993310003, disc_loss = 0.0421883096087996
Trained batch 404 in epoch 4, gen_loss = 0.39621158764686115, disc_loss = 0.04209873491501505
Trained batch 405 in epoch 4, gen_loss = 0.3961197871879991, disc_loss = 0.04204977546065009
Trained batch 406 in epoch 4, gen_loss = 0.3961094061338345, disc_loss = 0.0419739898604842
Trained batch 407 in epoch 4, gen_loss = 0.39608775561346726, disc_loss = 0.04188161769136558
Trained batch 408 in epoch 4, gen_loss = 0.3960390697190114, disc_loss = 0.04179023210190391
Trained batch 409 in epoch 4, gen_loss = 0.3959559870202367, disc_loss = 0.041718297850102094
Trained batch 410 in epoch 4, gen_loss = 0.3959825118672819, disc_loss = 0.04162677158652567
Trained batch 411 in epoch 4, gen_loss = 0.3961198285077382, disc_loss = 0.041624848293174435
Trained batch 412 in epoch 4, gen_loss = 0.39602103187154625, disc_loss = 0.04154157557002704
Trained batch 413 in epoch 4, gen_loss = 0.3959665888749459, disc_loss = 0.04178025063823522
Trained batch 414 in epoch 4, gen_loss = 0.3961176052150956, disc_loss = 0.04194893448821168
Trained batch 415 in epoch 4, gen_loss = 0.3962544740106051, disc_loss = 0.041874248976315497
Trained batch 416 in epoch 4, gen_loss = 0.3963277640102579, disc_loss = 0.04178713271545126
Trained batch 417 in epoch 4, gen_loss = 0.3962685057991429, disc_loss = 0.041742514325116435
Trained batch 418 in epoch 4, gen_loss = 0.39634665092875676, disc_loss = 0.04165246014662202
Trained batch 419 in epoch 4, gen_loss = 0.396507969001929, disc_loss = 0.04157280266656363
Trained batch 420 in epoch 4, gen_loss = 0.39650324489611627, disc_loss = 0.041503726150519754
Trained batch 421 in epoch 4, gen_loss = 0.3965202680837487, disc_loss = 0.041413312338422804
Trained batch 422 in epoch 4, gen_loss = 0.396550942326832, disc_loss = 0.041323649455643485
Trained batch 423 in epoch 4, gen_loss = 0.39669605941986136, disc_loss = 0.041239326805225573
Trained batch 424 in epoch 4, gen_loss = 0.3967963610677158, disc_loss = 0.04120703352149576
Trained batch 425 in epoch 4, gen_loss = 0.3968753655891463, disc_loss = 0.041136101004940855
Trained batch 426 in epoch 4, gen_loss = 0.39700606905046054, disc_loss = 0.041056571235777745
Trained batch 427 in epoch 4, gen_loss = 0.3970160063042819, disc_loss = 0.04098507099122323
Trained batch 428 in epoch 4, gen_loss = 0.39706705937852393, disc_loss = 0.04090954545024557
Trained batch 429 in epoch 4, gen_loss = 0.3972351939179177, disc_loss = 0.04082775581167838
Trained batch 430 in epoch 4, gen_loss = 0.39729137542352877, disc_loss = 0.040742491065900506
Trained batch 431 in epoch 4, gen_loss = 0.3972470038053062, disc_loss = 0.04065788629614636
Trained batch 432 in epoch 4, gen_loss = 0.39713718441011725, disc_loss = 0.040570477735924405
Trained batch 433 in epoch 4, gen_loss = 0.397197650050238, disc_loss = 0.04048234752399744
Trained batch 434 in epoch 4, gen_loss = 0.3970222412854776, disc_loss = 0.04040236893436475
Trained batch 435 in epoch 4, gen_loss = 0.39691176361173663, disc_loss = 0.040317137398032915
Trained batch 436 in epoch 4, gen_loss = 0.3970177765569098, disc_loss = 0.040237500690599344
Trained batch 437 in epoch 4, gen_loss = 0.39689190223064597, disc_loss = 0.04015264087425732
Trained batch 438 in epoch 4, gen_loss = 0.3968656122141384, disc_loss = 0.04007197453736928
Trained batch 439 in epoch 4, gen_loss = 0.39681232727386734, disc_loss = 0.03998627996691291
Trained batch 440 in epoch 4, gen_loss = 0.39686736275279333, disc_loss = 0.03990257981094973
Trained batch 441 in epoch 4, gen_loss = 0.3968539215051211, disc_loss = 0.0398177010909553
Trained batch 442 in epoch 4, gen_loss = 0.39676903575053335, disc_loss = 0.03973238469752153
Trained batch 443 in epoch 4, gen_loss = 0.39673466725392387, disc_loss = 0.03964884373068868
Trained batch 444 in epoch 4, gen_loss = 0.39681403931607023, disc_loss = 0.03956604685524499
Trained batch 445 in epoch 4, gen_loss = 0.39663453814427413, disc_loss = 0.03948290257651
Trained batch 446 in epoch 4, gen_loss = 0.39652676770351075, disc_loss = 0.03939967343486821
Trained batch 447 in epoch 4, gen_loss = 0.39655247337317895, disc_loss = 0.03931638732709481
Trained batch 448 in epoch 4, gen_loss = 0.39652116341155463, disc_loss = 0.039233089411965176
Trained batch 449 in epoch 4, gen_loss = 0.39650212115711636, disc_loss = 0.03915017590832172
Trained batch 450 in epoch 4, gen_loss = 0.3965111056346851, disc_loss = 0.0390700693900476
Trained batch 451 in epoch 4, gen_loss = 0.39647102329583295, disc_loss = 0.03899050600269389
Trained batch 452 in epoch 4, gen_loss = 0.39647819085363256, disc_loss = 0.03890908025405586
Trained batch 453 in epoch 4, gen_loss = 0.39642842205873147, disc_loss = 0.03882916281045935
Trained batch 454 in epoch 4, gen_loss = 0.39645258220997487, disc_loss = 0.03874793738884094
Trained batch 455 in epoch 4, gen_loss = 0.39655656877316925, disc_loss = 0.038666993348191396
Trained batch 456 in epoch 4, gen_loss = 0.3964989672474058, disc_loss = 0.03858864289036946
Trained batch 457 in epoch 4, gen_loss = 0.3964400347403564, disc_loss = 0.03851118675859108
Trained batch 458 in epoch 4, gen_loss = 0.3964484413854437, disc_loss = 0.03843293933797433
Trained batch 459 in epoch 4, gen_loss = 0.39658436457748, disc_loss = 0.03835785215766088
Trained batch 460 in epoch 4, gen_loss = 0.39655088751279866, disc_loss = 0.03827858137329455
Trained batch 461 in epoch 4, gen_loss = 0.39657388627529144, disc_loss = 0.03820044877288815
Trained batch 462 in epoch 4, gen_loss = 0.39722208514584323, disc_loss = 0.03827873611954477
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.44784682989120483, disc_loss = 0.03376515582203865
Trained batch 1 in epoch 5, gen_loss = 0.4161933958530426, disc_loss = 0.023108532186597586
Trained batch 2 in epoch 5, gen_loss = 0.43115949630737305, disc_loss = 0.018174581540127594
Trained batch 3 in epoch 5, gen_loss = 0.4197363778948784, disc_loss = 0.020608857041224837
Trained batch 4 in epoch 5, gen_loss = 0.42288972735404967, disc_loss = 0.022856261394917966
Trained batch 5 in epoch 5, gen_loss = 0.4315914163986842, disc_loss = 0.023158022668212652
Trained batch 6 in epoch 5, gen_loss = 0.42029397402490887, disc_loss = 0.021086445078253746
Trained batch 7 in epoch 5, gen_loss = 0.4216829352080822, disc_loss = 0.021189669612795115
Trained batch 8 in epoch 5, gen_loss = 0.4138818681240082, disc_loss = 0.020555847841832373
Trained batch 9 in epoch 5, gen_loss = 0.4133641719818115, disc_loss = 0.018992312718182802
Trained batch 10 in epoch 5, gen_loss = 0.41291970014572144, disc_loss = 0.018730077977207573
Trained batch 11 in epoch 5, gen_loss = 0.4078285942475001, disc_loss = 0.022125803943102557
Trained batch 12 in epoch 5, gen_loss = 0.4043594300746918, disc_loss = 0.02163410408852192
Trained batch 13 in epoch 5, gen_loss = 0.40471741344247547, disc_loss = 0.02041337190062872
Trained batch 14 in epoch 5, gen_loss = 0.4036284605662028, disc_loss = 0.019376360128323236
Trained batch 15 in epoch 5, gen_loss = 0.4054655861109495, disc_loss = 0.01843507567537017
Trained batch 16 in epoch 5, gen_loss = 0.40357500490020304, disc_loss = 0.017569128601976177
Trained batch 17 in epoch 5, gen_loss = 0.4037686205572552, disc_loss = 0.016789492064466078
Trained batch 18 in epoch 5, gen_loss = 0.4034847805374547, disc_loss = 0.016654394665046743
Trained batch 19 in epoch 5, gen_loss = 0.4006681561470032, disc_loss = 0.016070003528147934
Trained batch 20 in epoch 5, gen_loss = 0.40276187658309937, disc_loss = 0.015592878906144983
Trained batch 21 in epoch 5, gen_loss = 0.4009842479770834, disc_loss = 0.015008102869614959
Trained batch 22 in epoch 5, gen_loss = 0.39624234904413635, disc_loss = 0.01460325501292296
Trained batch 23 in epoch 5, gen_loss = 0.39840035885572433, disc_loss = 0.014122602093266323
Trained batch 24 in epoch 5, gen_loss = 0.40052905440330505, disc_loss = 0.013650742545723914
Trained batch 25 in epoch 5, gen_loss = 0.3997913679251304, disc_loss = 0.013246373434622701
Trained batch 26 in epoch 5, gen_loss = 0.39813292357656693, disc_loss = 0.01291110337263456
Trained batch 27 in epoch 5, gen_loss = 0.39618998020887375, disc_loss = 0.012651341850869358
Trained batch 28 in epoch 5, gen_loss = 0.3972253933035094, disc_loss = 0.012461153549495441
Trained batch 29 in epoch 5, gen_loss = 0.39634755353132883, disc_loss = 0.012240754859521984
Trained batch 30 in epoch 5, gen_loss = 0.3966918107002012, disc_loss = 0.012015778736601914
Trained batch 31 in epoch 5, gen_loss = 0.3972177868708968, disc_loss = 0.011755638748581987
Trained batch 32 in epoch 5, gen_loss = 0.3971296052138011, disc_loss = 0.011605997167697007
Trained batch 33 in epoch 5, gen_loss = 0.39869081360452313, disc_loss = 0.01139242436928565
Trained batch 34 in epoch 5, gen_loss = 0.3973158930029188, disc_loss = 0.011495070844622595
Trained batch 35 in epoch 5, gen_loss = 0.39855065362321007, disc_loss = 0.011495569843747135
Trained batch 36 in epoch 5, gen_loss = 0.40006609462402964, disc_loss = 0.011386125329630199
Trained batch 37 in epoch 5, gen_loss = 0.4009676246266616, disc_loss = 0.011167484329474208
Trained batch 38 in epoch 5, gen_loss = 0.4016703382516519, disc_loss = 0.01095994253260776
Trained batch 39 in epoch 5, gen_loss = 0.4006494224071503, disc_loss = 0.010765275947051123
Trained batch 40 in epoch 5, gen_loss = 0.4010202448542525, disc_loss = 0.010740022975724281
Trained batch 41 in epoch 5, gen_loss = 0.4016373824505579, disc_loss = 0.010674567166937604
Trained batch 42 in epoch 5, gen_loss = 0.40244069348934086, disc_loss = 0.010665461231499564
Trained batch 43 in epoch 5, gen_loss = 0.4010978896509517, disc_loss = 0.010492489747279747
Trained batch 44 in epoch 5, gen_loss = 0.4021357278029124, disc_loss = 0.010393795205487145
Trained batch 45 in epoch 5, gen_loss = 0.4026440213555875, disc_loss = 0.010251951069854524
Trained batch 46 in epoch 5, gen_loss = 0.40302182892535593, disc_loss = 0.010103857585605471
Trained batch 47 in epoch 5, gen_loss = 0.4017856990297635, disc_loss = 0.009959111926339878
Trained batch 48 in epoch 5, gen_loss = 0.40034375689467605, disc_loss = 0.009808702114019163
Trained batch 49 in epoch 5, gen_loss = 0.3991850048303604, disc_loss = 0.009663632693700493
Trained batch 50 in epoch 5, gen_loss = 0.3993271817179287, disc_loss = 0.009539424437189511
Trained batch 51 in epoch 5, gen_loss = 0.39962982730223584, disc_loss = 0.00942911505430507
Trained batch 52 in epoch 5, gen_loss = 0.40044907860036166, disc_loss = 0.009299270817482809
Trained batch 53 in epoch 5, gen_loss = 0.4006824912848296, disc_loss = 0.009162955363367305
Trained batch 54 in epoch 5, gen_loss = 0.4003800533034585, disc_loss = 0.00902974229432981
Trained batch 55 in epoch 5, gen_loss = 0.40070440034781185, disc_loss = 0.008902420204581827
Trained batch 56 in epoch 5, gen_loss = 0.40126877866293253, disc_loss = 0.008784831221738275
Trained batch 57 in epoch 5, gen_loss = 0.40244326509278394, disc_loss = 0.008686581552269515
Trained batch 58 in epoch 5, gen_loss = 0.4031899611828691, disc_loss = 0.008581497858404735
Trained batch 59 in epoch 5, gen_loss = 0.40343525211016334, disc_loss = 0.008469535876065493
Trained batch 60 in epoch 5, gen_loss = 0.4038709988359545, disc_loss = 0.008381618484549347
Trained batch 61 in epoch 5, gen_loss = 0.4031126388619023, disc_loss = 0.008276114174570408
Trained batch 62 in epoch 5, gen_loss = 0.40190847951268394, disc_loss = 0.008170395703350623
Trained batch 63 in epoch 5, gen_loss = 0.40202184673398733, disc_loss = 0.008074898438280798
Trained batch 64 in epoch 5, gen_loss = 0.40167103501466606, disc_loss = 0.00798170947505591
Trained batch 65 in epoch 5, gen_loss = 0.40168260353984253, disc_loss = 0.007890725647677866
Trained batch 66 in epoch 5, gen_loss = 0.40102621201258987, disc_loss = 0.007801516097970307
Trained batch 67 in epoch 5, gen_loss = 0.400164143565823, disc_loss = 0.007764997020678814
Trained batch 68 in epoch 5, gen_loss = 0.4000727512698243, disc_loss = 0.007684726880498878
Trained batch 69 in epoch 5, gen_loss = 0.3982772814376014, disc_loss = 0.007630024130256581
Trained batch 70 in epoch 5, gen_loss = 0.39879747385710057, disc_loss = 0.007566785329992188
Trained batch 71 in epoch 5, gen_loss = 0.3973393651346366, disc_loss = 0.007493890063617275
Trained batch 72 in epoch 5, gen_loss = 0.3977307330255639, disc_loss = 0.007437625904695118
Trained batch 73 in epoch 5, gen_loss = 0.3975090456975473, disc_loss = 0.007360550019625775
Trained batch 74 in epoch 5, gen_loss = 0.3964975388844808, disc_loss = 0.007315461758213739
Trained batch 75 in epoch 5, gen_loss = 0.3958160767429753, disc_loss = 0.0072422920524044644
Trained batch 76 in epoch 5, gen_loss = 0.39577957058881785, disc_loss = 0.007181475634456842
Trained batch 77 in epoch 5, gen_loss = 0.39597074190775555, disc_loss = 0.0071226728375619035
Trained batch 78 in epoch 5, gen_loss = 0.3949344580686545, disc_loss = 0.007054161609009003
Trained batch 79 in epoch 5, gen_loss = 0.3954677008092403, disc_loss = 0.006991385227593128
Trained batch 80 in epoch 5, gen_loss = 0.39581970153031526, disc_loss = 0.006931005788817542
Trained batch 81 in epoch 5, gen_loss = 0.3960228591430478, disc_loss = 0.006868733225174521
Trained batch 82 in epoch 5, gen_loss = 0.39546177293880874, disc_loss = 0.006809719704955547
Trained batch 83 in epoch 5, gen_loss = 0.39509153224173044, disc_loss = 0.006765237281797454
Trained batch 84 in epoch 5, gen_loss = 0.39628470154369577, disc_loss = 0.006721826838603353
Trained batch 85 in epoch 5, gen_loss = 0.39669962365959965, disc_loss = 0.006680277104457017
Trained batch 86 in epoch 5, gen_loss = 0.39705354386362535, disc_loss = 0.006633521746790529
Trained batch 87 in epoch 5, gen_loss = 0.39748002351685, disc_loss = 0.006813497466447932
Trained batch 88 in epoch 5, gen_loss = 0.3978319593359915, disc_loss = 0.006887340105892149
Trained batch 89 in epoch 5, gen_loss = 0.3974575122197469, disc_loss = 0.006870057841297239
Trained batch 90 in epoch 5, gen_loss = 0.39696589963776724, disc_loss = 0.006826600155813599
Trained batch 91 in epoch 5, gen_loss = 0.3970019192151401, disc_loss = 0.00680153758604201
Trained batch 92 in epoch 5, gen_loss = 0.3965424219126342, disc_loss = 0.006769585840013479
Trained batch 93 in epoch 5, gen_loss = 0.3972402852266393, disc_loss = 0.006729702250982457
Trained batch 94 in epoch 5, gen_loss = 0.39711346092977023, disc_loss = 0.006687390516316028
Trained batch 95 in epoch 5, gen_loss = 0.39665571817507345, disc_loss = 0.006674479175368712
Trained batch 96 in epoch 5, gen_loss = 0.39644754823950146, disc_loss = 0.006636091201931008
Trained batch 97 in epoch 5, gen_loss = 0.396559547708959, disc_loss = 0.006602292434949124
Trained batch 98 in epoch 5, gen_loss = 0.3965381043727952, disc_loss = 0.006689946958560007
Trained batch 99 in epoch 5, gen_loss = 0.39611209720373153, disc_loss = 0.006758543729083613
Trained batch 100 in epoch 5, gen_loss = 0.3970654403219129, disc_loss = 0.006719106371459173
Trained batch 101 in epoch 5, gen_loss = 0.3966152185902876, disc_loss = 0.006715709782963363
Trained batch 102 in epoch 5, gen_loss = 0.39701732906323034, disc_loss = 0.006753114170792684
Trained batch 103 in epoch 5, gen_loss = 0.39756553161602753, disc_loss = 0.006752220610416351
Trained batch 104 in epoch 5, gen_loss = 0.39784822918119883, disc_loss = 0.0067171021996598156
Trained batch 105 in epoch 5, gen_loss = 0.398113765806522, disc_loss = 0.006714389919751447
Trained batch 106 in epoch 5, gen_loss = 0.3988586098791283, disc_loss = 0.006670673078613651
Trained batch 107 in epoch 5, gen_loss = 0.3986804976507469, disc_loss = 0.006630622409930866
Trained batch 108 in epoch 5, gen_loss = 0.398966170779062, disc_loss = 0.006589775455372255
Trained batch 109 in epoch 5, gen_loss = 0.3987072987989946, disc_loss = 0.006601649017962204
Trained batch 110 in epoch 5, gen_loss = 0.3984840012885429, disc_loss = 0.006590682546490686
Trained batch 111 in epoch 5, gen_loss = 0.3991200828126499, disc_loss = 0.006551795124583545
Trained batch 112 in epoch 5, gen_loss = 0.3992756697456394, disc_loss = 0.0065146698420702484
Trained batch 113 in epoch 5, gen_loss = 0.3991433214723018, disc_loss = 0.006498575889660667
Trained batch 114 in epoch 5, gen_loss = 0.3990653527819592, disc_loss = 0.0064714652131838
Trained batch 115 in epoch 5, gen_loss = 0.3990083169834367, disc_loss = 0.006447810453868568
Trained batch 116 in epoch 5, gen_loss = 0.3991618553797404, disc_loss = 0.006460273374691924
Trained batch 117 in epoch 5, gen_loss = 0.3987990607649593, disc_loss = 0.0064357776062610415
Trained batch 118 in epoch 5, gen_loss = 0.39950100764507007, disc_loss = 0.006437539867469806
Trained batch 119 in epoch 5, gen_loss = 0.3988794373969237, disc_loss = 0.006561236705359382
Trained batch 120 in epoch 5, gen_loss = 0.3992944638098567, disc_loss = 0.006576651623588024
Trained batch 121 in epoch 5, gen_loss = 0.3999674613358545, disc_loss = 0.007009820547909094
Trained batch 122 in epoch 5, gen_loss = 0.3996701669402239, disc_loss = 0.008714264418695092
Trained batch 123 in epoch 5, gen_loss = 0.3999130939764361, disc_loss = 0.010282908529681604
Trained batch 124 in epoch 5, gen_loss = 0.39928621888160704, disc_loss = 0.011862414651550352
Trained batch 125 in epoch 5, gen_loss = 0.39985077769037275, disc_loss = 0.013001533780461325
Trained batch 126 in epoch 5, gen_loss = 0.3992447745142959, disc_loss = 0.013414665932884425
Trained batch 127 in epoch 5, gen_loss = 0.39935851376503706, disc_loss = 0.01433771370739123
Trained batch 128 in epoch 5, gen_loss = 0.39977125858151635, disc_loss = 0.01824743421333156
Trained batch 129 in epoch 5, gen_loss = 0.3996998440760833, disc_loss = 0.019930265264478154
Trained batch 130 in epoch 5, gen_loss = 0.39910867537250955, disc_loss = 0.02086623831392614
Trained batch 131 in epoch 5, gen_loss = 0.39847761234550766, disc_loss = 0.02163870112748224
Trained batch 132 in epoch 5, gen_loss = 0.3976721649331258, disc_loss = 0.022079470344202917
Trained batch 133 in epoch 5, gen_loss = 0.39738183257295123, disc_loss = 0.022489703462785806
Trained batch 134 in epoch 5, gen_loss = 0.3968599447497615, disc_loss = 0.02358997877497502
Trained batch 135 in epoch 5, gen_loss = 0.3960878721931401, disc_loss = 0.027334202677593566
Trained batch 136 in epoch 5, gen_loss = 0.3963824475768709, disc_loss = 0.02846878499938107
Trained batch 137 in epoch 5, gen_loss = 0.3964030684336372, disc_loss = 0.029493448683026963
Trained batch 138 in epoch 5, gen_loss = 0.39696567328713783, disc_loss = 0.030468202263900755
Trained batch 139 in epoch 5, gen_loss = 0.39639928277049746, disc_loss = 0.031329439521401325
Trained batch 140 in epoch 5, gen_loss = 0.3956030038654382, disc_loss = 0.03212846418700663
Trained batch 141 in epoch 5, gen_loss = 0.39548716263871797, disc_loss = 0.03237909083271032
Trained batch 142 in epoch 5, gen_loss = 0.3959066530207654, disc_loss = 0.03258090791328309
Trained batch 143 in epoch 5, gen_loss = 0.39586367913418347, disc_loss = 0.03308756925738029
Trained batch 144 in epoch 5, gen_loss = 0.3951837089555017, disc_loss = 0.033789314041395895
Trained batch 145 in epoch 5, gen_loss = 0.39552242604837023, disc_loss = 0.03475562112536664
Trained batch 146 in epoch 5, gen_loss = 0.39550718279922903, disc_loss = 0.034611986729088336
Trained batch 147 in epoch 5, gen_loss = 0.39529414797151413, disc_loss = 0.03445887684623862
Trained batch 148 in epoch 5, gen_loss = 0.39533676197064804, disc_loss = 0.03456348483997628
Trained batch 149 in epoch 5, gen_loss = 0.3955903587738673, disc_loss = 0.03467793914877499
Trained batch 150 in epoch 5, gen_loss = 0.39564980142163914, disc_loss = 0.03509740815852577
Trained batch 151 in epoch 5, gen_loss = 0.3954697363078594, disc_loss = 0.03606819771429352
Trained batch 152 in epoch 5, gen_loss = 0.39481410053041244, disc_loss = 0.03784782491286522
Trained batch 153 in epoch 5, gen_loss = 0.39543849965194605, disc_loss = 0.039021377712518415
Trained batch 154 in epoch 5, gen_loss = 0.39508004130855684, disc_loss = 0.03927329921148597
Trained batch 155 in epoch 5, gen_loss = 0.39462053775787354, disc_loss = 0.03941604240203443
Trained batch 156 in epoch 5, gen_loss = 0.39470464712495257, disc_loss = 0.03977771922664207
Trained batch 157 in epoch 5, gen_loss = 0.39434685360027266, disc_loss = 0.040636176580144685
Trained batch 158 in epoch 5, gen_loss = 0.3941436250629665, disc_loss = 0.041782161286071456
Trained batch 159 in epoch 5, gen_loss = 0.394084070622921, disc_loss = 0.04192079876738717
Trained batch 160 in epoch 5, gen_loss = 0.3942012842397512, disc_loss = 0.04172376790358714
Trained batch 161 in epoch 5, gen_loss = 0.3939789283422776, disc_loss = 0.041683556231020456
Trained batch 162 in epoch 5, gen_loss = 0.3938856128534656, disc_loss = 0.04154377624441075
Trained batch 163 in epoch 5, gen_loss = 0.3936694153561825, disc_loss = 0.04147844989400743
Trained batch 164 in epoch 5, gen_loss = 0.3939691202207045, disc_loss = 0.04139808735344559
Trained batch 165 in epoch 5, gen_loss = 0.39364181351230804, disc_loss = 0.04119457428537152
Trained batch 166 in epoch 5, gen_loss = 0.39372579209104985, disc_loss = 0.04099041004149344
Trained batch 167 in epoch 5, gen_loss = 0.3937189995887734, disc_loss = 0.04078231962367205
Trained batch 168 in epoch 5, gen_loss = 0.393606528904311, disc_loss = 0.04061343826521629
Trained batch 169 in epoch 5, gen_loss = 0.3932033756200005, disc_loss = 0.04055247903212576
Trained batch 170 in epoch 5, gen_loss = 0.3937925201410439, disc_loss = 0.04051972804005579
Trained batch 171 in epoch 5, gen_loss = 0.3934106223805006, disc_loss = 0.040344785068449456
Trained batch 172 in epoch 5, gen_loss = 0.3933350755644672, disc_loss = 0.040142168708797006
Trained batch 173 in epoch 5, gen_loss = 0.39289700231332886, disc_loss = 0.04013699097572237
Trained batch 174 in epoch 5, gen_loss = 0.3936102022443499, disc_loss = 0.040780451482028836
Trained batch 175 in epoch 5, gen_loss = 0.39363936944441363, disc_loss = 0.04060187604905381
Trained batch 176 in epoch 5, gen_loss = 0.393341125068018, disc_loss = 0.041614538356582874
Trained batch 177 in epoch 5, gen_loss = 0.3932671279049991, disc_loss = 0.04296496158185823
Trained batch 178 in epoch 5, gen_loss = 0.39295453082915793, disc_loss = 0.04298104940297072
Trained batch 179 in epoch 5, gen_loss = 0.39285586956474516, disc_loss = 0.043592972673812055
Trained batch 180 in epoch 5, gen_loss = 0.39319404795024937, disc_loss = 0.044346807116143486
Trained batch 181 in epoch 5, gen_loss = 0.39295559597539376, disc_loss = 0.04428551703560995
Trained batch 182 in epoch 5, gen_loss = 0.39300534454851205, disc_loss = 0.04421530258167494
Trained batch 183 in epoch 5, gen_loss = 0.39268158100869344, disc_loss = 0.04412924162549999
Trained batch 184 in epoch 5, gen_loss = 0.39259179025082974, disc_loss = 0.04395604569880242
Trained batch 185 in epoch 5, gen_loss = 0.39224716572351354, disc_loss = 0.04377804383928437
Trained batch 186 in epoch 5, gen_loss = 0.39247072125501176, disc_loss = 0.04356985055918701
Trained batch 187 in epoch 5, gen_loss = 0.3920020291462858, disc_loss = 0.043390058806448424
Trained batch 188 in epoch 5, gen_loss = 0.3919396838813862, disc_loss = 0.04330052966904881
Trained batch 189 in epoch 5, gen_loss = 0.3919644727518684, disc_loss = 0.043228064637361584
Trained batch 190 in epoch 5, gen_loss = 0.3922160057185208, disc_loss = 0.04344182844086018
Trained batch 191 in epoch 5, gen_loss = 0.3920409418642521, disc_loss = 0.04352536483505295
Trained batch 192 in epoch 5, gen_loss = 0.3921151981143754, disc_loss = 0.04333481328004556
Trained batch 193 in epoch 5, gen_loss = 0.3920603678705766, disc_loss = 0.043374985843517615
Trained batch 194 in epoch 5, gen_loss = 0.39174756774535546, disc_loss = 0.04329194477460801
Trained batch 195 in epoch 5, gen_loss = 0.3916496488512779, disc_loss = 0.0431165183467876
Trained batch 196 in epoch 5, gen_loss = 0.39201752954933244, disc_loss = 0.04299857239841677
Trained batch 197 in epoch 5, gen_loss = 0.3918158803323303, disc_loss = 0.04279927858398437
Trained batch 198 in epoch 5, gen_loss = 0.3919291611592374, disc_loss = 0.04267657810094387
Trained batch 199 in epoch 5, gen_loss = 0.39203293427824976, disc_loss = 0.04249225297768135
Trained batch 200 in epoch 5, gen_loss = 0.3918637581429078, disc_loss = 0.04231154635856716
Trained batch 201 in epoch 5, gen_loss = 0.39207895778783475, disc_loss = 0.04217286939827246
Trained batch 202 in epoch 5, gen_loss = 0.3921646850156079, disc_loss = 0.04199046023669446
Trained batch 203 in epoch 5, gen_loss = 0.3922152517765176, disc_loss = 0.04186154876016172
Trained batch 204 in epoch 5, gen_loss = 0.3919450743896205, disc_loss = 0.04184115448705398
Trained batch 205 in epoch 5, gen_loss = 0.39208609791635307, disc_loss = 0.041665143112412394
Trained batch 206 in epoch 5, gen_loss = 0.39212838132024386, disc_loss = 0.041507762510909874
Trained batch 207 in epoch 5, gen_loss = 0.39228646586147636, disc_loss = 0.041324157313143726
Trained batch 208 in epoch 5, gen_loss = 0.39230588848511, disc_loss = 0.041148719293707045
Trained batch 209 in epoch 5, gen_loss = 0.3924361377954483, disc_loss = 0.040967896825168285
Trained batch 210 in epoch 5, gen_loss = 0.39239955824133343, disc_loss = 0.04080240436006443
Trained batch 211 in epoch 5, gen_loss = 0.3921584978980838, disc_loss = 0.040636081600513414
Trained batch 212 in epoch 5, gen_loss = 0.3921809757539364, disc_loss = 0.04046453909889441
Trained batch 213 in epoch 5, gen_loss = 0.3924525843881001, disc_loss = 0.040311784564547905
Trained batch 214 in epoch 5, gen_loss = 0.392494922876358, disc_loss = 0.0401474439154574
Trained batch 215 in epoch 5, gen_loss = 0.3927983211146461, disc_loss = 0.04001446214291112
Trained batch 216 in epoch 5, gen_loss = 0.3928206755268958, disc_loss = 0.03987994125115037
Trained batch 217 in epoch 5, gen_loss = 0.3927416995577856, disc_loss = 0.03971506687524139
Trained batch 218 in epoch 5, gen_loss = 0.392716564816427, disc_loss = 0.03959055505023172
Trained batch 219 in epoch 5, gen_loss = 0.39267102656039327, disc_loss = 0.03943382429900918
Trained batch 220 in epoch 5, gen_loss = 0.3928316432426418, disc_loss = 0.03927846025618644
Trained batch 221 in epoch 5, gen_loss = 0.39271098375320435, disc_loss = 0.03913523638799266
Trained batch 222 in epoch 5, gen_loss = 0.39278241069862124, disc_loss = 0.03899016642093141
Trained batch 223 in epoch 5, gen_loss = 0.3931561639266355, disc_loss = 0.038844840774150464
Trained batch 224 in epoch 5, gen_loss = 0.39318810145060223, disc_loss = 0.03872963681247913
Trained batch 225 in epoch 5, gen_loss = 0.3933630001492205, disc_loss = 0.03857212970332053
Trained batch 226 in epoch 5, gen_loss = 0.3935342465203239, disc_loss = 0.03845135982934025
Trained batch 227 in epoch 5, gen_loss = 0.3936501393715541, disc_loss = 0.03830148961053949
Trained batch 228 in epoch 5, gen_loss = 0.3938838507671023, disc_loss = 0.038160668263581936
Trained batch 229 in epoch 5, gen_loss = 0.39411029634268385, disc_loss = 0.038012906933790475
Trained batch 230 in epoch 5, gen_loss = 0.39411898428227476, disc_loss = 0.03786342624258411
Trained batch 231 in epoch 5, gen_loss = 0.3940827471428904, disc_loss = 0.0377142450542406
Trained batch 232 in epoch 5, gen_loss = 0.39421399442934685, disc_loss = 0.037571764654527884
Trained batch 233 in epoch 5, gen_loss = 0.39396632965813333, disc_loss = 0.03742558421501412
Trained batch 234 in epoch 5, gen_loss = 0.3940687132642624, disc_loss = 0.03728747882414609
Trained batch 235 in epoch 5, gen_loss = 0.39416416267217214, disc_loss = 0.03714704443651283
Trained batch 236 in epoch 5, gen_loss = 0.39418336082611405, disc_loss = 0.037033205077283964
Trained batch 237 in epoch 5, gen_loss = 0.39411744738326354, disc_loss = 0.03689390646456154
Trained batch 238 in epoch 5, gen_loss = 0.3940608369256662, disc_loss = 0.036761688173234185
Trained batch 239 in epoch 5, gen_loss = 0.39398377339045204, disc_loss = 0.0366457772164722
Trained batch 240 in epoch 5, gen_loss = 0.3939483944805826, disc_loss = 0.036563929869345084
Trained batch 241 in epoch 5, gen_loss = 0.393896383194884, disc_loss = 0.03643566983018825
Trained batch 242 in epoch 5, gen_loss = 0.3939739035235511, disc_loss = 0.03632395415913712
Trained batch 243 in epoch 5, gen_loss = 0.39408113343305273, disc_loss = 0.03619910013760806
Trained batch 244 in epoch 5, gen_loss = 0.3943446823528835, disc_loss = 0.03607291539855378
Trained batch 245 in epoch 5, gen_loss = 0.3945695923838189, disc_loss = 0.03596428711472715
Trained batch 246 in epoch 5, gen_loss = 0.39439996859805304, disc_loss = 0.03583158626879079
Trained batch 247 in epoch 5, gen_loss = 0.3947936882895808, disc_loss = 0.035704616466142806
Trained batch 248 in epoch 5, gen_loss = 0.3947370073881494, disc_loss = 0.03559427199105407
Trained batch 249 in epoch 5, gen_loss = 0.3944758791923523, disc_loss = 0.03546860418980941
Trained batch 250 in epoch 5, gen_loss = 0.3942090752590225, disc_loss = 0.03535210475301467
Trained batch 251 in epoch 5, gen_loss = 0.3942714269672121, disc_loss = 0.03522577893408385
Trained batch 252 in epoch 5, gen_loss = 0.3944105425842195, disc_loss = 0.03510710659755298
Trained batch 253 in epoch 5, gen_loss = 0.3944278738395436, disc_loss = 0.03501326502914959
Trained batch 254 in epoch 5, gen_loss = 0.394321485711079, disc_loss = 0.034902670747125705
Trained batch 255 in epoch 5, gen_loss = 0.39430861664004624, disc_loss = 0.034786062740295165
Trained batch 256 in epoch 5, gen_loss = 0.39411771088722614, disc_loss = 0.034745655167061504
Trained batch 257 in epoch 5, gen_loss = 0.39423907057259433, disc_loss = 0.03485638621875063
Trained batch 258 in epoch 5, gen_loss = 0.39404865224849306, disc_loss = 0.03543987021193584
Trained batch 259 in epoch 5, gen_loss = 0.3942497044801712, disc_loss = 0.03710509942298253
Trained batch 260 in epoch 5, gen_loss = 0.39472067082065276, disc_loss = 0.03740752390915906
Trained batch 261 in epoch 5, gen_loss = 0.3946280571568103, disc_loss = 0.037669231158499926
Trained batch 262 in epoch 5, gen_loss = 0.3943996426043855, disc_loss = 0.037950334152890224
Trained batch 263 in epoch 5, gen_loss = 0.39423150207960245, disc_loss = 0.03827881064772197
Trained batch 264 in epoch 5, gen_loss = 0.3940555275611158, disc_loss = 0.03824099639281279
Trained batch 265 in epoch 5, gen_loss = 0.39402925934558525, disc_loss = 0.03815722708105411
Trained batch 266 in epoch 5, gen_loss = 0.39409823241305264, disc_loss = 0.03806829467121065
Trained batch 267 in epoch 5, gen_loss = 0.39414627838935423, disc_loss = 0.03800594025428768
Trained batch 268 in epoch 5, gen_loss = 0.393912491745222, disc_loss = 0.038298563054956665
Trained batch 269 in epoch 5, gen_loss = 0.3941237142792455, disc_loss = 0.039811767416540536
Trained batch 270 in epoch 5, gen_loss = 0.3941114310628814, disc_loss = 0.039806839174460415
Trained batch 271 in epoch 5, gen_loss = 0.39381202573285384, disc_loss = 0.03994246988569263
Trained batch 272 in epoch 5, gen_loss = 0.3933920633225214, disc_loss = 0.04021933167147699
Trained batch 273 in epoch 5, gen_loss = 0.3935761908545111, disc_loss = 0.04015082785694853
Trained batch 274 in epoch 5, gen_loss = 0.393569172187285, disc_loss = 0.04037196082105352
Trained batch 275 in epoch 5, gen_loss = 0.39368549129669217, disc_loss = 0.04036174404082239
Trained batch 276 in epoch 5, gen_loss = 0.3934773266960998, disc_loss = 0.04067017000785521
Trained batch 277 in epoch 5, gen_loss = 0.39384671820582245, disc_loss = 0.04153736436818291
Trained batch 278 in epoch 5, gen_loss = 0.39381185643989125, disc_loss = 0.04150308083741188
Trained batch 279 in epoch 5, gen_loss = 0.39386393960033145, disc_loss = 0.04147909214412461
Trained batch 280 in epoch 5, gen_loss = 0.3938407718711052, disc_loss = 0.041551471087547996
Trained batch 281 in epoch 5, gen_loss = 0.39394723248819935, disc_loss = 0.04213852389073264
Trained batch 282 in epoch 5, gen_loss = 0.3936911707632112, disc_loss = 0.04336087622839378
Trained batch 283 in epoch 5, gen_loss = 0.39362651844259716, disc_loss = 0.04339291967253175
Trained batch 284 in epoch 5, gen_loss = 0.39353534276025337, disc_loss = 0.04497481745283789
Trained batch 285 in epoch 5, gen_loss = 0.39337284894256325, disc_loss = 0.044950894854712084
Trained batch 286 in epoch 5, gen_loss = 0.39322001365003684, disc_loss = 0.045124298863304386
Trained batch 287 in epoch 5, gen_loss = 0.393153778070377, disc_loss = 0.04508848234763718
Trained batch 288 in epoch 5, gen_loss = 0.3933825249490441, disc_loss = 0.04506405537011856
Trained batch 289 in epoch 5, gen_loss = 0.39318490131147976, disc_loss = 0.04498071275482853
Trained batch 290 in epoch 5, gen_loss = 0.39299312039339257, disc_loss = 0.045023597373236676
Trained batch 291 in epoch 5, gen_loss = 0.3930716538061834, disc_loss = 0.04492399413481495
Trained batch 292 in epoch 5, gen_loss = 0.3930228504101164, disc_loss = 0.044802948717685864
Trained batch 293 in epoch 5, gen_loss = 0.392925879379519, disc_loss = 0.04466808015174948
Trained batch 294 in epoch 5, gen_loss = 0.39298233773748753, disc_loss = 0.04453504845713092
Trained batch 295 in epoch 5, gen_loss = 0.3928605849678452, disc_loss = 0.044412137317153426
Trained batch 296 in epoch 5, gen_loss = 0.39280447735128177, disc_loss = 0.044291833509308494
Trained batch 297 in epoch 5, gen_loss = 0.3926653627981275, disc_loss = 0.04420050169183441
Trained batch 298 in epoch 5, gen_loss = 0.3928037765233413, disc_loss = 0.0441256994907168
Trained batch 299 in epoch 5, gen_loss = 0.39281632194916405, disc_loss = 0.04398952103724393
Trained batch 300 in epoch 5, gen_loss = 0.3928282269805769, disc_loss = 0.04386986829410075
Trained batch 301 in epoch 5, gen_loss = 0.39264465858604736, disc_loss = 0.04373423601169176
Trained batch 302 in epoch 5, gen_loss = 0.3925163120326429, disc_loss = 0.043649033777394236
Trained batch 303 in epoch 5, gen_loss = 0.39261962257717786, disc_loss = 0.04352449461715112
Trained batch 304 in epoch 5, gen_loss = 0.39267771556729175, disc_loss = 0.04343526529674953
Trained batch 305 in epoch 5, gen_loss = 0.39273487742430246, disc_loss = 0.04333313384886186
Trained batch 306 in epoch 5, gen_loss = 0.39265873028323395, disc_loss = 0.0432327429112502
Trained batch 307 in epoch 5, gen_loss = 0.39269193881130837, disc_loss = 0.04311599989925124
Trained batch 308 in epoch 5, gen_loss = 0.39286845372718515, disc_loss = 0.04299066069763467
Trained batch 309 in epoch 5, gen_loss = 0.3928569291868517, disc_loss = 0.04286057990863018
Trained batch 310 in epoch 5, gen_loss = 0.3928757892544247, disc_loss = 0.04273396831154045
Trained batch 311 in epoch 5, gen_loss = 0.39293871094018984, disc_loss = 0.0426651161139419
Trained batch 312 in epoch 5, gen_loss = 0.3931141318604588, disc_loss = 0.042556585751090066
Trained batch 313 in epoch 5, gen_loss = 0.3926869860500287, disc_loss = 0.042667863417081654
Trained batch 314 in epoch 5, gen_loss = 0.3930490809773642, disc_loss = 0.04293341157802691
Trained batch 315 in epoch 5, gen_loss = 0.39282384533670883, disc_loss = 0.04290438623902906
Trained batch 316 in epoch 5, gen_loss = 0.3926177713021119, disc_loss = 0.042881293687602205
Trained batch 317 in epoch 5, gen_loss = 0.39262085403286434, disc_loss = 0.04277587677432669
Trained batch 318 in epoch 5, gen_loss = 0.39258998660458294, disc_loss = 0.04275071835926322
Trained batch 319 in epoch 5, gen_loss = 0.39248825442045926, disc_loss = 0.04277137576245878
Trained batch 320 in epoch 5, gen_loss = 0.3926554351952217, disc_loss = 0.04268796661414635
Trained batch 321 in epoch 5, gen_loss = 0.3927196659471678, disc_loss = 0.04257413086022962
Trained batch 322 in epoch 5, gen_loss = 0.3926598723089732, disc_loss = 0.04247828701838286
Trained batch 323 in epoch 5, gen_loss = 0.3925934065087342, disc_loss = 0.042373761928131526
Trained batch 324 in epoch 5, gen_loss = 0.3926438518670889, disc_loss = 0.042345095222027826
Trained batch 325 in epoch 5, gen_loss = 0.3924953090084111, disc_loss = 0.04255336652434163
Trained batch 326 in epoch 5, gen_loss = 0.3927927184906939, disc_loss = 0.042928066653974174
Trained batch 327 in epoch 5, gen_loss = 0.39284479745277545, disc_loss = 0.04281538782503581
Trained batch 328 in epoch 5, gen_loss = 0.39280024977078193, disc_loss = 0.04362867698660772
Trained batch 329 in epoch 5, gen_loss = 0.39273247944586204, disc_loss = 0.043634666036461676
Trained batch 330 in epoch 5, gen_loss = 0.3926813047818187, disc_loss = 0.0437510266440732
Trained batch 331 in epoch 5, gen_loss = 0.3926968474883631, disc_loss = 0.04375774563389763
Trained batch 332 in epoch 5, gen_loss = 0.392627700402572, disc_loss = 0.04371401699163389
Trained batch 333 in epoch 5, gen_loss = 0.39255406069541404, disc_loss = 0.04365816110888675
Trained batch 334 in epoch 5, gen_loss = 0.39285171601309704, disc_loss = 0.04357925979524795
Trained batch 335 in epoch 5, gen_loss = 0.3929426129020396, disc_loss = 0.043484180380931194
Trained batch 336 in epoch 5, gen_loss = 0.39292997192558266, disc_loss = 0.04336795198644072
Trained batch 337 in epoch 5, gen_loss = 0.3932581558030033, disc_loss = 0.043263047762399746
Trained batch 338 in epoch 5, gen_loss = 0.3932134499416239, disc_loss = 0.04316242657853208
Trained batch 339 in epoch 5, gen_loss = 0.39332090703880085, disc_loss = 0.04305560654816765
Trained batch 340 in epoch 5, gen_loss = 0.3934533066413969, disc_loss = 0.04299151598335219
Trained batch 341 in epoch 5, gen_loss = 0.39359515835667214, disc_loss = 0.042904302594592325
Trained batch 342 in epoch 5, gen_loss = 0.3936821649790505, disc_loss = 0.04280717531863991
Trained batch 343 in epoch 5, gen_loss = 0.3937468566866808, disc_loss = 0.04269893901919415
Trained batch 344 in epoch 5, gen_loss = 0.39380962831386623, disc_loss = 0.04259867584973952
Trained batch 345 in epoch 5, gen_loss = 0.3937256057138388, disc_loss = 0.04249536952729245
Trained batch 346 in epoch 5, gen_loss = 0.3938909240002591, disc_loss = 0.04239795915077921
Trained batch 347 in epoch 5, gen_loss = 0.3938338877312068, disc_loss = 0.04230497460966213
Trained batch 348 in epoch 5, gen_loss = 0.39382403354590123, disc_loss = 0.042210230810292876
Trained batch 349 in epoch 5, gen_loss = 0.39390119177954536, disc_loss = 0.04210834784932169
Trained batch 350 in epoch 5, gen_loss = 0.3938983081922232, disc_loss = 0.0420082386399346
Trained batch 351 in epoch 5, gen_loss = 0.39416988261721353, disc_loss = 0.041901411563726884
Trained batch 352 in epoch 5, gen_loss = 0.3941451902936606, disc_loss = 0.041791491753622234
Trained batch 353 in epoch 5, gen_loss = 0.39407436617013425, disc_loss = 0.041685544001398935
Trained batch 354 in epoch 5, gen_loss = 0.3940051642102255, disc_loss = 0.04158826214162974
Trained batch 355 in epoch 5, gen_loss = 0.39414640825785946, disc_loss = 0.04148447818451122
Trained batch 356 in epoch 5, gen_loss = 0.3941460156641087, disc_loss = 0.041379385860962924
Trained batch 357 in epoch 5, gen_loss = 0.3942625008148854, disc_loss = 0.04128237050800589
Trained batch 358 in epoch 5, gen_loss = 0.39436991624845436, disc_loss = 0.04117724860072769
Trained batch 359 in epoch 5, gen_loss = 0.39431737951106494, disc_loss = 0.041077042385586536
Trained batch 360 in epoch 5, gen_loss = 0.39454422432960234, disc_loss = 0.04097236480358782
Trained batch 361 in epoch 5, gen_loss = 0.39450234108866905, disc_loss = 0.04088211823184074
Trained batch 362 in epoch 5, gen_loss = 0.39448492881680325, disc_loss = 0.04078567184067842
Trained batch 363 in epoch 5, gen_loss = 0.39454017620492765, disc_loss = 0.0406838360976218
Trained batch 364 in epoch 5, gen_loss = 0.3946479125382149, disc_loss = 0.0405849420832317
Trained batch 365 in epoch 5, gen_loss = 0.3948437534069103, disc_loss = 0.04048275034092214
Trained batch 366 in epoch 5, gen_loss = 0.3949451474142984, disc_loss = 0.04038225205225632
Trained batch 367 in epoch 5, gen_loss = 0.39483861641391466, disc_loss = 0.04028027059425569
Trained batch 368 in epoch 5, gen_loss = 0.39477178446322597, disc_loss = 0.040179089649686424
Trained batch 369 in epoch 5, gen_loss = 0.39472263334570706, disc_loss = 0.040092923730372675
Trained batch 370 in epoch 5, gen_loss = 0.3949214758256054, disc_loss = 0.03999407747239527
Trained batch 371 in epoch 5, gen_loss = 0.39497479516011413, disc_loss = 0.03989335205825296
Trained batch 372 in epoch 5, gen_loss = 0.39515562519311265, disc_loss = 0.039799507919276986
Trained batch 373 in epoch 5, gen_loss = 0.39534160215905645, disc_loss = 0.039703677897403804
Trained batch 374 in epoch 5, gen_loss = 0.3954305285612742, disc_loss = 0.03960750522185117
Trained batch 375 in epoch 5, gen_loss = 0.39548019375255766, disc_loss = 0.03951492820379691
Trained batch 376 in epoch 5, gen_loss = 0.3956939264222861, disc_loss = 0.03941846861465728
Trained batch 377 in epoch 5, gen_loss = 0.3956915757485798, disc_loss = 0.03932466658747573
Trained batch 378 in epoch 5, gen_loss = 0.3957845601683242, disc_loss = 0.03922914546615835
Trained batch 379 in epoch 5, gen_loss = 0.3957060173938149, disc_loss = 0.0391352016757561
Trained batch 380 in epoch 5, gen_loss = 0.39590112775016645, disc_loss = 0.03904555410756595
Trained batch 381 in epoch 5, gen_loss = 0.3960020710660525, disc_loss = 0.03895773268542472
Trained batch 382 in epoch 5, gen_loss = 0.39608667639154677, disc_loss = 0.03886963381807687
Trained batch 383 in epoch 5, gen_loss = 0.39603905015004176, disc_loss = 0.038858777915872146
Trained batch 384 in epoch 5, gen_loss = 0.3960479292002591, disc_loss = 0.038789158797968036
Trained batch 385 in epoch 5, gen_loss = 0.39614246029001443, disc_loss = 0.03871602524726994
Trained batch 386 in epoch 5, gen_loss = 0.396249097755097, disc_loss = 0.0386257831723783
Trained batch 387 in epoch 5, gen_loss = 0.39649192620184004, disc_loss = 0.03855179583014123
Trained batch 388 in epoch 5, gen_loss = 0.39666434387008453, disc_loss = 0.03847098907373204
Trained batch 389 in epoch 5, gen_loss = 0.3966045687596003, disc_loss = 0.038392020656595915
Trained batch 390 in epoch 5, gen_loss = 0.39654054063970173, disc_loss = 0.03830408895372763
Trained batch 391 in epoch 5, gen_loss = 0.39664909768165374, disc_loss = 0.03821588854800805
Trained batch 392 in epoch 5, gen_loss = 0.3967669384018459, disc_loss = 0.038125511331415
Trained batch 393 in epoch 5, gen_loss = 0.3969986631634272, disc_loss = 0.0380430188503348
Trained batch 394 in epoch 5, gen_loss = 0.39730782757831523, disc_loss = 0.037963998823756756
Trained batch 395 in epoch 5, gen_loss = 0.39731453223661944, disc_loss = 0.03787619567910125
Trained batch 396 in epoch 5, gen_loss = 0.3973704557725104, disc_loss = 0.03779325971259062
Trained batch 397 in epoch 5, gen_loss = 0.39755548282184794, disc_loss = 0.03770611643464768
Trained batch 398 in epoch 5, gen_loss = 0.3977070221476686, disc_loss = 0.03762256985391376
Trained batch 399 in epoch 5, gen_loss = 0.39770972184836867, disc_loss = 0.03759121092181886
Trained batch 400 in epoch 5, gen_loss = 0.39785611250454056, disc_loss = 0.03752984678020882
Trained batch 401 in epoch 5, gen_loss = 0.3978727634125088, disc_loss = 0.03746314926579159
Trained batch 402 in epoch 5, gen_loss = 0.3979980080358444, disc_loss = 0.03740450394745436
Trained batch 403 in epoch 5, gen_loss = 0.3978724062885388, disc_loss = 0.037332723683984215
Trained batch 404 in epoch 5, gen_loss = 0.39815513594650925, disc_loss = 0.0372637300800969
Trained batch 405 in epoch 5, gen_loss = 0.3980408265379262, disc_loss = 0.03719503211753278
Trained batch 406 in epoch 5, gen_loss = 0.39820287166122137, disc_loss = 0.03711167137688873
Trained batch 407 in epoch 5, gen_loss = 0.39813077274490805, disc_loss = 0.03703356264176203
Trained batch 408 in epoch 5, gen_loss = 0.39808457638057343, disc_loss = 0.03697580827512804
Trained batch 409 in epoch 5, gen_loss = 0.39794149355190556, disc_loss = 0.036904744428820996
Trained batch 410 in epoch 5, gen_loss = 0.3980140552613567, disc_loss = 0.0368827855519819
Trained batch 411 in epoch 5, gen_loss = 0.3981262879464233, disc_loss = 0.03683601496306031
Trained batch 412 in epoch 5, gen_loss = 0.39802778820725965, disc_loss = 0.03677845200536137
Trained batch 413 in epoch 5, gen_loss = 0.39803312510108024, disc_loss = 0.03672237309558623
Trained batch 414 in epoch 5, gen_loss = 0.3980144859796547, disc_loss = 0.0367686772963077
Trained batch 415 in epoch 5, gen_loss = 0.3981880906682748, disc_loss = 0.036761675052100776
Trained batch 416 in epoch 5, gen_loss = 0.3980785799826935, disc_loss = 0.03675745828250285
Trained batch 417 in epoch 5, gen_loss = 0.3982144381013213, disc_loss = 0.0366996834541974
Trained batch 418 in epoch 5, gen_loss = 0.3982156415543294, disc_loss = 0.036809073800836783
Trained batch 419 in epoch 5, gen_loss = 0.39798333098491034, disc_loss = 0.03752260607240411
Trained batch 420 in epoch 5, gen_loss = 0.3981227888913732, disc_loss = 0.038932625035923464
Trained batch 421 in epoch 5, gen_loss = 0.3978740335640749, disc_loss = 0.03909889045386615
Trained batch 422 in epoch 5, gen_loss = 0.39762443106788836, disc_loss = 0.039892521856108296
Trained batch 423 in epoch 5, gen_loss = 0.39773564237468645, disc_loss = 0.04085507916856584
Trained batch 424 in epoch 5, gen_loss = 0.3975340645453509, disc_loss = 0.04119538126595537
Trained batch 425 in epoch 5, gen_loss = 0.39732363372341567, disc_loss = 0.04174645995352846
Trained batch 426 in epoch 5, gen_loss = 0.3972784901949505, disc_loss = 0.041953609632251816
Trained batch 427 in epoch 5, gen_loss = 0.3970560377167764, disc_loss = 0.042015652668120546
Trained batch 428 in epoch 5, gen_loss = 0.39688746363688737, disc_loss = 0.04220757463220767
Trained batch 429 in epoch 5, gen_loss = 0.39678761855114336, disc_loss = 0.04233564845324212
Trained batch 430 in epoch 5, gen_loss = 0.3965199145806085, disc_loss = 0.04230092459800167
Trained batch 431 in epoch 5, gen_loss = 0.39634175101915997, disc_loss = 0.042390219392675337
Trained batch 432 in epoch 5, gen_loss = 0.39632332930663994, disc_loss = 0.04245626149504439
Trained batch 433 in epoch 5, gen_loss = 0.39622739692162806, disc_loss = 0.04242147608689131
Trained batch 434 in epoch 5, gen_loss = 0.3960122623662839, disc_loss = 0.042474250585086984
Trained batch 435 in epoch 5, gen_loss = 0.3961664985079284, disc_loss = 0.04251919482132941
Trained batch 436 in epoch 5, gen_loss = 0.3961553725006924, disc_loss = 0.042494331479863236
Trained batch 437 in epoch 5, gen_loss = 0.3960794560168976, disc_loss = 0.04244252769292447
Trained batch 438 in epoch 5, gen_loss = 0.396101098668874, disc_loss = 0.04236033616522815
Trained batch 439 in epoch 5, gen_loss = 0.3962318072264845, disc_loss = 0.04234616078240585
Trained batch 440 in epoch 5, gen_loss = 0.39623179964197464, disc_loss = 0.04226692887461299
Trained batch 441 in epoch 5, gen_loss = 0.39620625831153056, disc_loss = 0.04218427340760279
Trained batch 442 in epoch 5, gen_loss = 0.3961979603525209, disc_loss = 0.04211171059979601
Trained batch 443 in epoch 5, gen_loss = 0.39621387099897537, disc_loss = 0.042025691806286285
Trained batch 444 in epoch 5, gen_loss = 0.3962694751412681, disc_loss = 0.04194024317568231
Trained batch 445 in epoch 5, gen_loss = 0.3963505774068191, disc_loss = 0.041877671067379496
Trained batch 446 in epoch 5, gen_loss = 0.3963542133903077, disc_loss = 0.041858485616249774
Trained batch 447 in epoch 5, gen_loss = 0.396148986316153, disc_loss = 0.04199996469391668
Trained batch 448 in epoch 5, gen_loss = 0.3964496180581091, disc_loss = 0.042029288696708
Trained batch 449 in epoch 5, gen_loss = 0.3963741488589181, disc_loss = 0.04213588950715752
Trained batch 450 in epoch 5, gen_loss = 0.396201187781907, disc_loss = 0.04217550546904518
Trained batch 451 in epoch 5, gen_loss = 0.39607623483227417, disc_loss = 0.04225295569631271
Trained batch 452 in epoch 5, gen_loss = 0.39608934100626847, disc_loss = 0.04295253942984775
Trained batch 453 in epoch 5, gen_loss = 0.39613142484872876, disc_loss = 0.04307619590770724
Trained batch 454 in epoch 5, gen_loss = 0.3959767394668453, disc_loss = 0.04311306116524265
Trained batch 455 in epoch 5, gen_loss = 0.3958648512499374, disc_loss = 0.0431525494447366
Trained batch 456 in epoch 5, gen_loss = 0.395695670363157, disc_loss = 0.043268238780948716
Trained batch 457 in epoch 5, gen_loss = 0.3955929340493731, disc_loss = 0.0435670749200447
Trained batch 458 in epoch 5, gen_loss = 0.39580098242541545, disc_loss = 0.04409700913901577
Trained batch 459 in epoch 5, gen_loss = 0.39578380694855814, disc_loss = 0.0441081020755835
Trained batch 460 in epoch 5, gen_loss = 0.39572730912562304, disc_loss = 0.0441213549898105
Trained batch 461 in epoch 5, gen_loss = 0.3955877327815795, disc_loss = 0.04412158673958756
Trained batch 462 in epoch 5, gen_loss = 0.39580799513707665, disc_loss = 0.044654163588029504
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.5308895111083984, disc_loss = 0.6632080078125
Trained batch 1 in epoch 6, gen_loss = 0.44894182682037354, disc_loss = 0.5838238298892975
Trained batch 2 in epoch 6, gen_loss = 0.4040546913941701, disc_loss = 0.482860008875529
Trained batch 3 in epoch 6, gen_loss = 0.3846524879336357, disc_loss = 0.42009105533361435
Trained batch 4 in epoch 6, gen_loss = 0.3590390503406525, disc_loss = 0.38710464239120485
Trained batch 5 in epoch 6, gen_loss = 0.3533018231391907, disc_loss = 0.36206849416097003
Trained batch 6 in epoch 6, gen_loss = 0.35551199316978455, disc_loss = 0.341207959822246
Trained batch 7 in epoch 6, gen_loss = 0.35477399080991745, disc_loss = 0.3246711790561676
Trained batch 8 in epoch 6, gen_loss = 0.35875850915908813, disc_loss = 0.3082427912288242
Trained batch 9 in epoch 6, gen_loss = 0.35601894557476044, disc_loss = 0.2934445604681969
Trained batch 10 in epoch 6, gen_loss = 0.3567052266814492, disc_loss = 0.2811121629043059
Trained batch 11 in epoch 6, gen_loss = 0.3509139120578766, disc_loss = 0.27243660638729733
Trained batch 12 in epoch 6, gen_loss = 0.34925238673503584, disc_loss = 0.262325739631286
Trained batch 13 in epoch 6, gen_loss = 0.35557554236480166, disc_loss = 0.25312942053590504
Trained batch 14 in epoch 6, gen_loss = 0.3511319696903229, disc_loss = 0.24312746226787568
Trained batch 15 in epoch 6, gen_loss = 0.35167788341641426, disc_loss = 0.2337147267535329
Trained batch 16 in epoch 6, gen_loss = 0.3499658791457905, disc_loss = 0.22579653648769155
Trained batch 17 in epoch 6, gen_loss = 0.3528388655847973, disc_loss = 0.21950914876328576
Trained batch 18 in epoch 6, gen_loss = 0.3524537039430518, disc_loss = 0.2107258835121205
Trained batch 19 in epoch 6, gen_loss = 0.35214641094207766, disc_loss = 0.20113046253100036
Trained batch 20 in epoch 6, gen_loss = 0.35075185128620695, disc_loss = 0.19216048464711225
Trained batch 21 in epoch 6, gen_loss = 0.352774132381786, disc_loss = 0.1838864297606051
Trained batch 22 in epoch 6, gen_loss = 0.3541112231171649, disc_loss = 0.17693263968533796
Trained batch 23 in epoch 6, gen_loss = 0.35546867301066715, disc_loss = 0.17213836292891452
Trained batch 24 in epoch 6, gen_loss = 0.3579276490211487, disc_loss = 0.16813815902918577
Trained batch 25 in epoch 6, gen_loss = 0.3572298414432086, disc_loss = 0.164122716559527
Trained batch 26 in epoch 6, gen_loss = 0.36121469404962325, disc_loss = 0.15933572304331595
Trained batch 27 in epoch 6, gen_loss = 0.36143016070127487, disc_loss = 0.153848244409476
Trained batch 28 in epoch 6, gen_loss = 0.360835718697515, disc_loss = 0.1495301965624094
Trained batch 29 in epoch 6, gen_loss = 0.36119682689507804, disc_loss = 0.14693303139259417
Trained batch 30 in epoch 6, gen_loss = 0.36154467732675616, disc_loss = 0.145201996028904
Trained batch 31 in epoch 6, gen_loss = 0.36397949513047934, disc_loss = 0.14097800548188388
Trained batch 32 in epoch 6, gen_loss = 0.3668363870996417, disc_loss = 0.14079618205626807
Trained batch 33 in epoch 6, gen_loss = 0.3655603703330545, disc_loss = 0.1390428148648318
Trained batch 34 in epoch 6, gen_loss = 0.364000917332513, disc_loss = 0.1367196438567979
Trained batch 35 in epoch 6, gen_loss = 0.3671560660004616, disc_loss = 0.13455224047518438
Trained batch 36 in epoch 6, gen_loss = 0.3690397095035862, disc_loss = 0.13171471368420767
Trained batch 37 in epoch 6, gen_loss = 0.37046597270589127, disc_loss = 0.1285849824106615
Trained batch 38 in epoch 6, gen_loss = 0.3719101945559184, disc_loss = 0.12688905963053307
Trained batch 39 in epoch 6, gen_loss = 0.3717471159994602, disc_loss = 0.12417124987114221
Trained batch 40 in epoch 6, gen_loss = 0.37165768190128046, disc_loss = 0.12156016027509439
Trained batch 41 in epoch 6, gen_loss = 0.37048911054929096, disc_loss = 0.1209935502681349
Trained batch 42 in epoch 6, gen_loss = 0.37265599536341293, disc_loss = 0.12900491156290436
Trained batch 43 in epoch 6, gen_loss = 0.3734169094399972, disc_loss = 0.12928311791355637
Trained batch 44 in epoch 6, gen_loss = 0.3718939979871114, disc_loss = 0.14369143771214618
Trained batch 45 in epoch 6, gen_loss = 0.3710640072822571, disc_loss = 0.14538266503697503
Trained batch 46 in epoch 6, gen_loss = 0.372064692542908, disc_loss = 0.147703319411487
Trained batch 47 in epoch 6, gen_loss = 0.37097568809986115, disc_loss = 0.14777249650796875
Trained batch 48 in epoch 6, gen_loss = 0.3705115591993137, disc_loss = 0.14713614413096587
Trained batch 49 in epoch 6, gen_loss = 0.3710975170135498, disc_loss = 0.14565941462293266
Trained batch 50 in epoch 6, gen_loss = 0.3699871704858892, disc_loss = 0.14384336968628214
Trained batch 51 in epoch 6, gen_loss = 0.3695528782331027, disc_loss = 0.14175695777297592
Trained batch 52 in epoch 6, gen_loss = 0.37057156720251405, disc_loss = 0.1404011535792137
Trained batch 53 in epoch 6, gen_loss = 0.3711440607353493, disc_loss = 0.13901920335505297
Trained batch 54 in epoch 6, gen_loss = 0.37113348679109054, disc_loss = 0.13709704071622003
Trained batch 55 in epoch 6, gen_loss = 0.37067914328404833, disc_loss = 0.13504399008317186
Trained batch 56 in epoch 6, gen_loss = 0.37088387211163837, disc_loss = 0.13309257256945498
Trained batch 57 in epoch 6, gen_loss = 0.3714737938395862, disc_loss = 0.13102539216071882
Trained batch 58 in epoch 6, gen_loss = 0.3706114590167999, disc_loss = 0.1294865922497238
Trained batch 59 in epoch 6, gen_loss = 0.36931210408608117, disc_loss = 0.13284170042412977
Trained batch 60 in epoch 6, gen_loss = 0.3705779543665589, disc_loss = 0.1356913560818209
Trained batch 61 in epoch 6, gen_loss = 0.370113318966281, disc_loss = 0.1365874773642469
Trained batch 62 in epoch 6, gen_loss = 0.369977310063347, disc_loss = 0.1369904408467904
Trained batch 63 in epoch 6, gen_loss = 0.3694114228710532, disc_loss = 0.13674154422187712
Trained batch 64 in epoch 6, gen_loss = 0.36969694999548103, disc_loss = 0.13587146514596848
Trained batch 65 in epoch 6, gen_loss = 0.37003593733816437, disc_loss = 0.1348944065781931
Trained batch 66 in epoch 6, gen_loss = 0.3696778518940086, disc_loss = 0.1332398960644852
Trained batch 67 in epoch 6, gen_loss = 0.3696763980038026, disc_loss = 0.1315467727562303
Trained batch 68 in epoch 6, gen_loss = 0.3695281147956848, disc_loss = 0.12985643856497348
Trained batch 69 in epoch 6, gen_loss = 0.3694438167980739, disc_loss = 0.12817749467545322
Trained batch 70 in epoch 6, gen_loss = 0.3694970662325201, disc_loss = 0.12657030974842712
Trained batch 71 in epoch 6, gen_loss = 0.36960086185071206, disc_loss = 0.12489662950651513
Trained batch 72 in epoch 6, gen_loss = 0.3692918170804847, disc_loss = 0.12327947265353717
Trained batch 73 in epoch 6, gen_loss = 0.3711017229267069, disc_loss = 0.12196973446328696
Trained batch 74 in epoch 6, gen_loss = 0.3723214081923167, disc_loss = 0.12067508528009058
Trained batch 75 in epoch 6, gen_loss = 0.3732318156643918, disc_loss = 0.11941349304795854
Trained batch 76 in epoch 6, gen_loss = 0.3722740527871367, disc_loss = 0.11795944119985034
Trained batch 77 in epoch 6, gen_loss = 0.3710371466019215, disc_loss = 0.11728020021333717
Trained batch 78 in epoch 6, gen_loss = 0.37164009258716924, disc_loss = 0.11711400294016246
Trained batch 79 in epoch 6, gen_loss = 0.37221461348235607, disc_loss = 0.1163912862946745
Trained batch 80 in epoch 6, gen_loss = 0.3729972015192479, disc_loss = 0.11515085920576512
Trained batch 81 in epoch 6, gen_loss = 0.3736090071317626, disc_loss = 0.11391950159606229
Trained batch 82 in epoch 6, gen_loss = 0.3742599616567773, disc_loss = 0.11267455904576254
Trained batch 83 in epoch 6, gen_loss = 0.37626588415531886, disc_loss = 0.11222934088159707
Trained batch 84 in epoch 6, gen_loss = 0.3764650751562679, disc_loss = 0.11370262717828154
Trained batch 85 in epoch 6, gen_loss = 0.3775693386100059, disc_loss = 0.11953264651928357
Trained batch 86 in epoch 6, gen_loss = 0.377694728045628, disc_loss = 0.11921506490151601
Trained batch 87 in epoch 6, gen_loss = 0.3774591308425773, disc_loss = 0.11912188250888986
Trained batch 88 in epoch 6, gen_loss = 0.37629595398902893, disc_loss = 0.11894966548392444
Trained batch 89 in epoch 6, gen_loss = 0.3757330417633057, disc_loss = 0.11942855884941915
Trained batch 90 in epoch 6, gen_loss = 0.37513686110685157, disc_loss = 0.11835335614159703
Trained batch 91 in epoch 6, gen_loss = 0.3747193259389504, disc_loss = 0.11725855802449034
Trained batch 92 in epoch 6, gen_loss = 0.3744346896807353, disc_loss = 0.11618623647698632
Trained batch 93 in epoch 6, gen_loss = 0.37477630376815796, disc_loss = 0.1151512202737417
Trained batch 94 in epoch 6, gen_loss = 0.3740260798680155, disc_loss = 0.11417618752212116
Trained batch 95 in epoch 6, gen_loss = 0.3741307044401765, disc_loss = 0.1135591242685526
Trained batch 96 in epoch 6, gen_loss = 0.37464847761331144, disc_loss = 0.11355580471590468
Trained batch 97 in epoch 6, gen_loss = 0.37402478347019275, disc_loss = 0.1130117693944473
Trained batch 98 in epoch 6, gen_loss = 0.3744243946340349, disc_loss = 0.11206336488307576
Trained batch 99 in epoch 6, gen_loss = 0.3743165209889412, disc_loss = 0.11182813252788038
Trained batch 100 in epoch 6, gen_loss = 0.3734440024536435, disc_loss = 0.11213802195403098
Trained batch 101 in epoch 6, gen_loss = 0.3740130446705164, disc_loss = 0.11118997543520641
Trained batch 102 in epoch 6, gen_loss = 0.3746394234374889, disc_loss = 0.11054854237393123
Trained batch 103 in epoch 6, gen_loss = 0.3738790492598827, disc_loss = 0.10964449668356863
Trained batch 104 in epoch 6, gen_loss = 0.37423737049102784, disc_loss = 0.1088368965534582
Trained batch 105 in epoch 6, gen_loss = 0.374241349269759, disc_loss = 0.10799716054110454
Trained batch 106 in epoch 6, gen_loss = 0.3747862115084568, disc_loss = 0.1071894552132167
Trained batch 107 in epoch 6, gen_loss = 0.375215925000332, disc_loss = 0.10633241022609312
Trained batch 108 in epoch 6, gen_loss = 0.3754464248451618, disc_loss = 0.10539738539555067
Trained batch 109 in epoch 6, gen_loss = 0.3748523985797709, disc_loss = 0.10456467452459037
Trained batch 110 in epoch 6, gen_loss = 0.37458720991203376, disc_loss = 0.10366487938088474
Trained batch 111 in epoch 6, gen_loss = 0.37573868142707006, disc_loss = 0.10281068740628793
Trained batch 112 in epoch 6, gen_loss = 0.37566838195893615, disc_loss = 0.10193673241883516
Trained batch 113 in epoch 6, gen_loss = 0.3762493507381071, disc_loss = 0.10110218032148846
Trained batch 114 in epoch 6, gen_loss = 0.3765805508779443, disc_loss = 0.10025456156784102
Trained batch 115 in epoch 6, gen_loss = 0.37643782254950753, disc_loss = 0.09942615082977212
Trained batch 116 in epoch 6, gen_loss = 0.37631736351893497, disc_loss = 0.09860229026725213
Trained batch 117 in epoch 6, gen_loss = 0.37633291290978255, disc_loss = 0.09779625926048384
Trained batch 118 in epoch 6, gen_loss = 0.37664181920660644, disc_loss = 0.09699983691538394
Trained batch 119 in epoch 6, gen_loss = 0.37667808681726456, disc_loss = 0.09622146523712824
Trained batch 120 in epoch 6, gen_loss = 0.3773543351937917, disc_loss = 0.09545553154658434
Trained batch 121 in epoch 6, gen_loss = 0.37789819230798816, disc_loss = 0.0947038819822559
Trained batch 122 in epoch 6, gen_loss = 0.3777620668818311, disc_loss = 0.09403223646956126
Trained batch 123 in epoch 6, gen_loss = 0.37826036613795067, disc_loss = 0.09330184390625706
Trained batch 124 in epoch 6, gen_loss = 0.37953539824485777, disc_loss = 0.09262904862500727
Trained batch 125 in epoch 6, gen_loss = 0.3796934114089088, disc_loss = 0.09193865952104152
Trained batch 126 in epoch 6, gen_loss = 0.37951762727865085, disc_loss = 0.09128750082816724
Trained batch 127 in epoch 6, gen_loss = 0.37952304328791797, disc_loss = 0.09063546212746587
Trained batch 128 in epoch 6, gen_loss = 0.37918437474457795, disc_loss = 0.08995998822614666
Trained batch 129 in epoch 6, gen_loss = 0.3796036658378748, disc_loss = 0.08932109334721015
Trained batch 130 in epoch 6, gen_loss = 0.37965303955187324, disc_loss = 0.08868223289383277
Trained batch 131 in epoch 6, gen_loss = 0.3804088661616499, disc_loss = 0.08808132027501636
Trained batch 132 in epoch 6, gen_loss = 0.38015580132491605, disc_loss = 0.08747287245145194
Trained batch 133 in epoch 6, gen_loss = 0.37999670474386926, disc_loss = 0.0868927894382557
Trained batch 134 in epoch 6, gen_loss = 0.3799595305213222, disc_loss = 0.08632534467787654
Trained batch 135 in epoch 6, gen_loss = 0.38021497406503735, disc_loss = 0.0858072386643685
Trained batch 136 in epoch 6, gen_loss = 0.3808021454045372, disc_loss = 0.08525192261721096
Trained batch 137 in epoch 6, gen_loss = 0.38150027610253595, disc_loss = 0.0846970828074584
Trained batch 138 in epoch 6, gen_loss = 0.3815643154888702, disc_loss = 0.08417186904162598
Trained batch 139 in epoch 6, gen_loss = 0.3821150588137763, disc_loss = 0.08361088846411024
Trained batch 140 in epoch 6, gen_loss = 0.3819845278635093, disc_loss = 0.0830436170461145
Trained batch 141 in epoch 6, gen_loss = 0.3820425972972118, disc_loss = 0.08247936374186472
Trained batch 142 in epoch 6, gen_loss = 0.3824249114189948, disc_loss = 0.08201500860863475
Trained batch 143 in epoch 6, gen_loss = 0.38263931435843307, disc_loss = 0.08156455162194713
Trained batch 144 in epoch 6, gen_loss = 0.3829196296889206, disc_loss = 0.08102161077108105
Trained batch 145 in epoch 6, gen_loss = 0.38326725669919626, disc_loss = 0.08048470110205092
Trained batch 146 in epoch 6, gen_loss = 0.38337783485042803, disc_loss = 0.07995943342918391
Trained batch 147 in epoch 6, gen_loss = 0.38324881949134776, disc_loss = 0.07946995672033597
Trained batch 148 in epoch 6, gen_loss = 0.38346620694102856, disc_loss = 0.07895611629090053
Trained batch 149 in epoch 6, gen_loss = 0.38386571844418843, disc_loss = 0.07849304479236405
Trained batch 150 in epoch 6, gen_loss = 0.38398895516300835, disc_loss = 0.07804077859375848
Trained batch 151 in epoch 6, gen_loss = 0.3843484285630678, disc_loss = 0.07757284108696408
Trained batch 152 in epoch 6, gen_loss = 0.3841116177100761, disc_loss = 0.07711838575360043
Trained batch 153 in epoch 6, gen_loss = 0.38453849337317725, disc_loss = 0.07666897354042762
Trained batch 154 in epoch 6, gen_loss = 0.38515315325029437, disc_loss = 0.07621585532361942
Trained batch 155 in epoch 6, gen_loss = 0.3853213831018179, disc_loss = 0.07577001759245132
Trained batch 156 in epoch 6, gen_loss = 0.38521238402196556, disc_loss = 0.0753397146079713
Trained batch 157 in epoch 6, gen_loss = 0.38539321777186814, disc_loss = 0.07489094063285974
Trained batch 158 in epoch 6, gen_loss = 0.3858897987776582, disc_loss = 0.07446560917023874
Trained batch 159 in epoch 6, gen_loss = 0.38627552799880505, disc_loss = 0.0740387213329086
Trained batch 160 in epoch 6, gen_loss = 0.3866712349171964, disc_loss = 0.07371522088517776
Trained batch 161 in epoch 6, gen_loss = 0.38677132479202603, disc_loss = 0.07362261617176787
Trained batch 162 in epoch 6, gen_loss = 0.3876093664417969, disc_loss = 0.0735687637741626
Trained batch 163 in epoch 6, gen_loss = 0.3877636888405172, disc_loss = 0.07315153028055026
Trained batch 164 in epoch 6, gen_loss = 0.38744482199350994, disc_loss = 0.07315743487949172
Trained batch 165 in epoch 6, gen_loss = 0.38777520767895574, disc_loss = 0.07295789541844952
Trained batch 166 in epoch 6, gen_loss = 0.3879712075887326, disc_loss = 0.07257316484880037
Trained batch 167 in epoch 6, gen_loss = 0.38794914242767153, disc_loss = 0.07216209882920209
Trained batch 168 in epoch 6, gen_loss = 0.3881226589341135, disc_loss = 0.07177886180717431
Trained batch 169 in epoch 6, gen_loss = 0.3881943176774418, disc_loss = 0.07138954888454035
Trained batch 170 in epoch 6, gen_loss = 0.38801774260593436, disc_loss = 0.07100056534311706
Trained batch 171 in epoch 6, gen_loss = 0.3878825485359791, disc_loss = 0.07066185154470203
Trained batch 172 in epoch 6, gen_loss = 0.3880078298163552, disc_loss = 0.0702934914142044
Trained batch 173 in epoch 6, gen_loss = 0.3877715840079318, disc_loss = 0.06992941903587345
Trained batch 174 in epoch 6, gen_loss = 0.3879806978361947, disc_loss = 0.06960083903877863
Trained batch 175 in epoch 6, gen_loss = 0.3877505204555663, disc_loss = 0.06940577092278875
Trained batch 176 in epoch 6, gen_loss = 0.38795156869511144, disc_loss = 0.06953089016931668
Trained batch 177 in epoch 6, gen_loss = 0.3882293182142665, disc_loss = 0.06963979174367288
Trained batch 178 in epoch 6, gen_loss = 0.3883977648932175, disc_loss = 0.06944437714049062
Trained batch 179 in epoch 6, gen_loss = 0.3886014042629136, disc_loss = 0.06910868862307527
Trained batch 180 in epoch 6, gen_loss = 0.388503425193755, disc_loss = 0.06877490876947442
Trained batch 181 in epoch 6, gen_loss = 0.3885876641168699, disc_loss = 0.06842551881237631
Trained batch 182 in epoch 6, gen_loss = 0.3888782884905247, disc_loss = 0.06825192312740522
Trained batch 183 in epoch 6, gen_loss = 0.3886259760221709, disc_loss = 0.06800238186184762
Trained batch 184 in epoch 6, gen_loss = 0.38871734802787367, disc_loss = 0.06769516858574305
Trained batch 185 in epoch 6, gen_loss = 0.38802314157127055, disc_loss = 0.06783130516483378
Trained batch 186 in epoch 6, gen_loss = 0.38823832165111194, disc_loss = 0.06756801437960071
Trained batch 187 in epoch 6, gen_loss = 0.38880341246407085, disc_loss = 0.06790573788841472
Trained batch 188 in epoch 6, gen_loss = 0.38808854310600843, disc_loss = 0.06881205395489892
Trained batch 189 in epoch 6, gen_loss = 0.3884946812140314, disc_loss = 0.06851346774492413
Trained batch 190 in epoch 6, gen_loss = 0.3885217613262656, disc_loss = 0.06847523801706497
Trained batch 191 in epoch 6, gen_loss = 0.38835173193365335, disc_loss = 0.06891664382783347
Trained batch 192 in epoch 6, gen_loss = 0.3886166177883049, disc_loss = 0.0696067266646348
Trained batch 193 in epoch 6, gen_loss = 0.3882297345043458, disc_loss = 0.07096543433216698
Trained batch 194 in epoch 6, gen_loss = 0.38793389537395573, disc_loss = 0.07133776470421789
Trained batch 195 in epoch 6, gen_loss = 0.38776742986270357, disc_loss = 0.07171891205255132
Trained batch 196 in epoch 6, gen_loss = 0.3873615670325187, disc_loss = 0.07202265295672802
Trained batch 197 in epoch 6, gen_loss = 0.3868633008966542, disc_loss = 0.07252118444291292
Trained batch 198 in epoch 6, gen_loss = 0.38656947061644126, disc_loss = 0.07326500658203272
Trained batch 199 in epoch 6, gen_loss = 0.38683039978146555, disc_loss = 0.07367489026277325
Trained batch 200 in epoch 6, gen_loss = 0.38661865437801796, disc_loss = 0.0737038470598503
Trained batch 201 in epoch 6, gen_loss = 0.38659528960095774, disc_loss = 0.07385070062597457
Trained batch 202 in epoch 6, gen_loss = 0.38683264919102484, disc_loss = 0.07507441139073465
Trained batch 203 in epoch 6, gen_loss = 0.38667890224971024, disc_loss = 0.07501294381126725
Trained batch 204 in epoch 6, gen_loss = 0.3867108980330025, disc_loss = 0.0750843185602074
Trained batch 205 in epoch 6, gen_loss = 0.38695831481114173, disc_loss = 0.07498880618057457
Trained batch 206 in epoch 6, gen_loss = 0.3870738340172791, disc_loss = 0.07472571932512745
Trained batch 207 in epoch 6, gen_loss = 0.387060092905393, disc_loss = 0.07441553207396422
Trained batch 208 in epoch 6, gen_loss = 0.3869737071568886, disc_loss = 0.07415450495248883
Trained batch 209 in epoch 6, gen_loss = 0.3867542080935978, disc_loss = 0.07384396972289929
Trained batch 210 in epoch 6, gen_loss = 0.38693108165998596, disc_loss = 0.0736625829073755
Trained batch 211 in epoch 6, gen_loss = 0.3873497277217091, disc_loss = 0.07375789349261706
Trained batch 212 in epoch 6, gen_loss = 0.3870902184589368, disc_loss = 0.07400312445983466
Trained batch 213 in epoch 6, gen_loss = 0.38720777157311126, disc_loss = 0.07389154027446791
Trained batch 214 in epoch 6, gen_loss = 0.3876478752424551, disc_loss = 0.07513384763476287
Trained batch 215 in epoch 6, gen_loss = 0.3874049980055403, disc_loss = 0.07486091314327765
Trained batch 216 in epoch 6, gen_loss = 0.38732370541941735, disc_loss = 0.07512666856599672
Trained batch 217 in epoch 6, gen_loss = 0.38759951061065046, disc_loss = 0.0749346067725228
Trained batch 218 in epoch 6, gen_loss = 0.38766235807170607, disc_loss = 0.07484709100529857
Trained batch 219 in epoch 6, gen_loss = 0.38769511485641656, disc_loss = 0.07455405340508812
Trained batch 220 in epoch 6, gen_loss = 0.3874639264598691, disc_loss = 0.07457260148519676
Trained batch 221 in epoch 6, gen_loss = 0.3875027364707208, disc_loss = 0.07426073387588232
Trained batch 222 in epoch 6, gen_loss = 0.38760441862414236, disc_loss = 0.07395379385084014
Trained batch 223 in epoch 6, gen_loss = 0.3877948396173971, disc_loss = 0.07400219408009434
Trained batch 224 in epoch 6, gen_loss = 0.387443874279658, disc_loss = 0.07483338037609226
Trained batch 225 in epoch 6, gen_loss = 0.3874403041812171, disc_loss = 0.07542893784512164
Trained batch 226 in epoch 6, gen_loss = 0.3872703841604325, disc_loss = 0.07518039700690049
Trained batch 227 in epoch 6, gen_loss = 0.38690065357245895, disc_loss = 0.07502203957042902
Trained batch 228 in epoch 6, gen_loss = 0.3866563074973993, disc_loss = 0.07487633324423439
Trained batch 229 in epoch 6, gen_loss = 0.3866478835758956, disc_loss = 0.07471920609291967
Trained batch 230 in epoch 6, gen_loss = 0.3864029340155713, disc_loss = 0.07456961615531185
Trained batch 231 in epoch 6, gen_loss = 0.38636776483778296, disc_loss = 0.07436767439177291
Trained batch 232 in epoch 6, gen_loss = 0.3862665223972992, disc_loss = 0.07423460747658919
Trained batch 233 in epoch 6, gen_loss = 0.38670597995957756, disc_loss = 0.07396246813950089
Trained batch 234 in epoch 6, gen_loss = 0.3868662565312487, disc_loss = 0.07389864074561665
Trained batch 235 in epoch 6, gen_loss = 0.3868345724324049, disc_loss = 0.07362339786407775
Trained batch 236 in epoch 6, gen_loss = 0.3865833290015595, disc_loss = 0.07376234125216267
Trained batch 237 in epoch 6, gen_loss = 0.386646189233836, disc_loss = 0.07347264866043321
Trained batch 238 in epoch 6, gen_loss = 0.38658298570740673, disc_loss = 0.07392793998734004
Trained batch 239 in epoch 6, gen_loss = 0.38645510946710904, disc_loss = 0.07429241921927314
Trained batch 240 in epoch 6, gen_loss = 0.38659246952207255, disc_loss = 0.07409996060650656
Trained batch 241 in epoch 6, gen_loss = 0.38691738469541564, disc_loss = 0.07396081292112781
Trained batch 242 in epoch 6, gen_loss = 0.38681292938597406, disc_loss = 0.07376757442449132
Trained batch 243 in epoch 6, gen_loss = 0.3868748028991652, disc_loss = 0.0735817118595568
Trained batch 244 in epoch 6, gen_loss = 0.38659520015424614, disc_loss = 0.07332808395980724
Trained batch 245 in epoch 6, gen_loss = 0.3865284592640109, disc_loss = 0.07309806502208387
Trained batch 246 in epoch 6, gen_loss = 0.3866971374040673, disc_loss = 0.07303426687055181
Trained batch 247 in epoch 6, gen_loss = 0.3861093536740349, disc_loss = 0.07309045186810827
Trained batch 248 in epoch 6, gen_loss = 0.38622884901173143, disc_loss = 0.0728532365274552
Trained batch 249 in epoch 6, gen_loss = 0.38627839720249174, disc_loss = 0.07316587177384645
Trained batch 250 in epoch 6, gen_loss = 0.3861143078462061, disc_loss = 0.07310693619487087
Trained batch 251 in epoch 6, gen_loss = 0.38612350088263314, disc_loss = 0.07286080736981054
Trained batch 252 in epoch 6, gen_loss = 0.3861690521711417, disc_loss = 0.0728782925565208
Trained batch 253 in epoch 6, gen_loss = 0.38589770540477725, disc_loss = 0.0728904734976135
Trained batch 254 in epoch 6, gen_loss = 0.3858835567446316, disc_loss = 0.07266318437679872
Trained batch 255 in epoch 6, gen_loss = 0.38619491178542376, disc_loss = 0.0724733979195662
Trained batch 256 in epoch 6, gen_loss = 0.3862702974085678, disc_loss = 0.07231495413903857
Trained batch 257 in epoch 6, gen_loss = 0.3861262943855552, disc_loss = 0.07228752584178579
Trained batch 258 in epoch 6, gen_loss = 0.3864755086226813, disc_loss = 0.07236691021079981
Trained batch 259 in epoch 6, gen_loss = 0.38633891286758276, disc_loss = 0.07216832827364739
Trained batch 260 in epoch 6, gen_loss = 0.38653661556170815, disc_loss = 0.07204705300219928
Trained batch 261 in epoch 6, gen_loss = 0.3866170603810376, disc_loss = 0.07184852139743486
Trained batch 262 in epoch 6, gen_loss = 0.38707294096964845, disc_loss = 0.07164687413754146
Trained batch 263 in epoch 6, gen_loss = 0.3870950853734305, disc_loss = 0.07139435345324631
Trained batch 264 in epoch 6, gen_loss = 0.3870290217534551, disc_loss = 0.07113972862848555
Trained batch 265 in epoch 6, gen_loss = 0.3871601509644573, disc_loss = 0.07089107125013702
Trained batch 266 in epoch 6, gen_loss = 0.3872435598560933, disc_loss = 0.07064947367066776
Trained batch 267 in epoch 6, gen_loss = 0.387265832677706, disc_loss = 0.07041566965687993
Trained batch 268 in epoch 6, gen_loss = 0.3872439330616848, disc_loss = 0.07017498957010533
Trained batch 269 in epoch 6, gen_loss = 0.38709451302334114, disc_loss = 0.06997011603908268
Trained batch 270 in epoch 6, gen_loss = 0.3871141515974629, disc_loss = 0.06978546818323103
Trained batch 271 in epoch 6, gen_loss = 0.3871163279913804, disc_loss = 0.06954405030410271
Trained batch 272 in epoch 6, gen_loss = 0.3869081038040119, disc_loss = 0.06930195433155875
Trained batch 273 in epoch 6, gen_loss = 0.38699710825934025, disc_loss = 0.06907850845944626
Trained batch 274 in epoch 6, gen_loss = 0.38698585596951574, disc_loss = 0.06886368212120776
Trained batch 275 in epoch 6, gen_loss = 0.38697107740934344, disc_loss = 0.06864242681953381
Trained batch 276 in epoch 6, gen_loss = 0.3868760736625547, disc_loss = 0.06848632227982451
Trained batch 277 in epoch 6, gen_loss = 0.38702648631531555, disc_loss = 0.06839953042422722
Trained batch 278 in epoch 6, gen_loss = 0.38714399869723987, disc_loss = 0.0692285910410653
Trained batch 279 in epoch 6, gen_loss = 0.3875508690518992, disc_loss = 0.07149675894013074
Trained batch 280 in epoch 6, gen_loss = 0.38767293000136405, disc_loss = 0.07249290791499259
Trained batch 281 in epoch 6, gen_loss = 0.38759801594923576, disc_loss = 0.07283111546495731
Trained batch 282 in epoch 6, gen_loss = 0.3873826108425329, disc_loss = 0.07318063144565497
Trained batch 283 in epoch 6, gen_loss = 0.38711184630511514, disc_loss = 0.0733183494442746
Trained batch 284 in epoch 6, gen_loss = 0.3869038319378568, disc_loss = 0.07353127432513264
Trained batch 285 in epoch 6, gen_loss = 0.386484456437451, disc_loss = 0.07352637946100944
Trained batch 286 in epoch 6, gen_loss = 0.3865611674685927, disc_loss = 0.0734394013416022
Trained batch 287 in epoch 6, gen_loss = 0.3862902723873655, disc_loss = 0.07352313289124544
Trained batch 288 in epoch 6, gen_loss = 0.3861718824371747, disc_loss = 0.07333125873745958
Trained batch 289 in epoch 6, gen_loss = 0.3860840238373855, disc_loss = 0.07317250575629416
Trained batch 290 in epoch 6, gen_loss = 0.3859049267170765, disc_loss = 0.07302155337117203
Trained batch 291 in epoch 6, gen_loss = 0.3863016543527172, disc_loss = 0.07303243213770146
Trained batch 292 in epoch 6, gen_loss = 0.3861881777288157, disc_loss = 0.07313893253934084
Trained batch 293 in epoch 6, gen_loss = 0.3863802956683295, disc_loss = 0.07312071137526231
Trained batch 294 in epoch 6, gen_loss = 0.3862495452670728, disc_loss = 0.07306138937898232
Trained batch 295 in epoch 6, gen_loss = 0.3863832314272185, disc_loss = 0.07291337748677973
Trained batch 296 in epoch 6, gen_loss = 0.3865471282591322, disc_loss = 0.07280684852430139
Trained batch 297 in epoch 6, gen_loss = 0.386269167265636, disc_loss = 0.07272185059342433
Trained batch 298 in epoch 6, gen_loss = 0.3863093583878865, disc_loss = 0.07251981770803523
Trained batch 299 in epoch 6, gen_loss = 0.38631464312473934, disc_loss = 0.07233857223531232
Trained batch 300 in epoch 6, gen_loss = 0.38637269919496836, disc_loss = 0.07213966388555484
Trained batch 301 in epoch 6, gen_loss = 0.38637763409819825, disc_loss = 0.07201640847962448
Trained batch 302 in epoch 6, gen_loss = 0.38651050238719475, disc_loss = 0.07182211300785417
Trained batch 303 in epoch 6, gen_loss = 0.38657734307803604, disc_loss = 0.0716270888630166
Trained batch 304 in epoch 6, gen_loss = 0.3867840006703236, disc_loss = 0.07144141692561326
Trained batch 305 in epoch 6, gen_loss = 0.3867111539139467, disc_loss = 0.07124545610908516
Trained batch 306 in epoch 6, gen_loss = 0.38701628124286763, disc_loss = 0.07105708891656311
Trained batch 307 in epoch 6, gen_loss = 0.38752458002660184, disc_loss = 0.07087913756757709
Trained batch 308 in epoch 6, gen_loss = 0.38758616424301295, disc_loss = 0.07072227395856964
Trained batch 309 in epoch 6, gen_loss = 0.3874586607179334, disc_loss = 0.07164181829655483
Trained batch 310 in epoch 6, gen_loss = 0.38783957988886203, disc_loss = 0.0726260540301693
Trained batch 311 in epoch 6, gen_loss = 0.387558627109497, disc_loss = 0.07311050190951508
Trained batch 312 in epoch 6, gen_loss = 0.3876568835954697, disc_loss = 0.07311756188308778
Trained batch 313 in epoch 6, gen_loss = 0.38777920518331466, disc_loss = 0.07297651001747556
Trained batch 314 in epoch 6, gen_loss = 0.3877452970497192, disc_loss = 0.07280352511886684
Trained batch 315 in epoch 6, gen_loss = 0.3879447446405133, disc_loss = 0.07278044626803455
Trained batch 316 in epoch 6, gen_loss = 0.38806582869791456, disc_loss = 0.07273986973294441
Trained batch 317 in epoch 6, gen_loss = 0.3879996243887727, disc_loss = 0.07257286694747214
Trained batch 318 in epoch 6, gen_loss = 0.38795733414473577, disc_loss = 0.07262064209485246
Trained batch 319 in epoch 6, gen_loss = 0.38799001555889845, disc_loss = 0.07342353673957405
Trained batch 320 in epoch 6, gen_loss = 0.3876572454644141, disc_loss = 0.07379987660717115
Trained batch 321 in epoch 6, gen_loss = 0.3876757462572607, disc_loss = 0.07361864241097493
Trained batch 322 in epoch 6, gen_loss = 0.387650155153806, disc_loss = 0.07386849126663209
Trained batch 323 in epoch 6, gen_loss = 0.3874739648567306, disc_loss = 0.07404290620642887
Trained batch 324 in epoch 6, gen_loss = 0.38743400711279646, disc_loss = 0.07394852095283568
Trained batch 325 in epoch 6, gen_loss = 0.3875414106560631, disc_loss = 0.0738401309239958
Trained batch 326 in epoch 6, gen_loss = 0.3875048834978623, disc_loss = 0.07363990158916363
Trained batch 327 in epoch 6, gen_loss = 0.3873613071514339, disc_loss = 0.07347354026605012
Trained batch 328 in epoch 6, gen_loss = 0.3873567616504739, disc_loss = 0.07336683106597366
Trained batch 329 in epoch 6, gen_loss = 0.38745089877735484, disc_loss = 0.07321553693759734
Trained batch 330 in epoch 6, gen_loss = 0.3877154483355784, disc_loss = 0.07310599991925106
Trained batch 331 in epoch 6, gen_loss = 0.3878930861870927, disc_loss = 0.07290485394622076
Trained batch 332 in epoch 6, gen_loss = 0.38798063680216355, disc_loss = 0.07298437661390651
Trained batch 333 in epoch 6, gen_loss = 0.38789930912905823, disc_loss = 0.0739181583885293
Trained batch 334 in epoch 6, gen_loss = 0.38766676338750927, disc_loss = 0.0738688008213388
Trained batch 335 in epoch 6, gen_loss = 0.38766033202409744, disc_loss = 0.0739314971107801
Trained batch 336 in epoch 6, gen_loss = 0.38780157369746654, disc_loss = 0.0739630574922876
Trained batch 337 in epoch 6, gen_loss = 0.3876974746673065, disc_loss = 0.07390052276269461
Trained batch 338 in epoch 6, gen_loss = 0.38748214440008183, disc_loss = 0.0739394350074902
Trained batch 339 in epoch 6, gen_loss = 0.38756212872617385, disc_loss = 0.0737477331634556
Trained batch 340 in epoch 6, gen_loss = 0.38777633452695137, disc_loss = 0.07364097044699418
Trained batch 341 in epoch 6, gen_loss = 0.38786727643152424, disc_loss = 0.07347767067493119
Trained batch 342 in epoch 6, gen_loss = 0.3877087268467895, disc_loss = 0.07336969948889628
Trained batch 343 in epoch 6, gen_loss = 0.3877711194718993, disc_loss = 0.07317405491783067
Trained batch 344 in epoch 6, gen_loss = 0.38784820221472477, disc_loss = 0.07303631585293814
Trained batch 345 in epoch 6, gen_loss = 0.3876654349827353, disc_loss = 0.07287763359463865
Trained batch 346 in epoch 6, gen_loss = 0.38763423087961046, disc_loss = 0.07279185002726055
Trained batch 347 in epoch 6, gen_loss = 0.38779517725623885, disc_loss = 0.07260022745614914
Trained batch 348 in epoch 6, gen_loss = 0.3880101890652774, disc_loss = 0.07242558521010452
Trained batch 349 in epoch 6, gen_loss = 0.3881161301476615, disc_loss = 0.07224034272999104
Trained batch 350 in epoch 6, gen_loss = 0.38802099771309445, disc_loss = 0.07208950632182812
Trained batch 351 in epoch 6, gen_loss = 0.3880349881100384, disc_loss = 0.07189670273444128
Trained batch 352 in epoch 6, gen_loss = 0.3882266093921391, disc_loss = 0.07170296522786065
Trained batch 353 in epoch 6, gen_loss = 0.3880907077405412, disc_loss = 0.07151427206130814
Trained batch 354 in epoch 6, gen_loss = 0.3881953739784133, disc_loss = 0.07132254869113086
Trained batch 355 in epoch 6, gen_loss = 0.3882615130101697, disc_loss = 0.07113238473898952
Trained batch 356 in epoch 6, gen_loss = 0.38812454842051874, disc_loss = 0.07095001259276054
Trained batch 357 in epoch 6, gen_loss = 0.3881594140769383, disc_loss = 0.07076264822116778
Trained batch 358 in epoch 6, gen_loss = 0.3882910403368533, disc_loss = 0.07057823741440156
Trained batch 359 in epoch 6, gen_loss = 0.3882409549421734, disc_loss = 0.07041036255864633
Trained batch 360 in epoch 6, gen_loss = 0.3881695435648149, disc_loss = 0.07022990402443093
Trained batch 361 in epoch 6, gen_loss = 0.3882328905782647, disc_loss = 0.07005012513122917
Trained batch 362 in epoch 6, gen_loss = 0.388250072140339, disc_loss = 0.06986647499558457
Trained batch 363 in epoch 6, gen_loss = 0.38833160272666384, disc_loss = 0.06968149117252963
Trained batch 364 in epoch 6, gen_loss = 0.3883896907714948, disc_loss = 0.0695001045637445
Trained batch 365 in epoch 6, gen_loss = 0.38849595441518586, disc_loss = 0.06932037428868781
Trained batch 366 in epoch 6, gen_loss = 0.3886071864200873, disc_loss = 0.06913904426111878
Trained batch 367 in epoch 6, gen_loss = 0.3885278431293757, disc_loss = 0.06896782881433508
Trained batch 368 in epoch 6, gen_loss = 0.388462431224058, disc_loss = 0.06880399766617876
Trained batch 369 in epoch 6, gen_loss = 0.3884384344558458, disc_loss = 0.06863564449815533
Trained batch 370 in epoch 6, gen_loss = 0.3883562882473527, disc_loss = 0.0684680190085461
Trained batch 371 in epoch 6, gen_loss = 0.38842419062250405, disc_loss = 0.06829303224766327
Trained batch 372 in epoch 6, gen_loss = 0.3883505640975911, disc_loss = 0.06813164765824221
Trained batch 373 in epoch 6, gen_loss = 0.38848123711379456, disc_loss = 0.06796763702121408
Trained batch 374 in epoch 6, gen_loss = 0.38853814101219175, disc_loss = 0.06779851328705748
Trained batch 375 in epoch 6, gen_loss = 0.38864384456834894, disc_loss = 0.06762666883197256
Trained batch 376 in epoch 6, gen_loss = 0.388719217451561, disc_loss = 0.06745899423020607
Trained batch 377 in epoch 6, gen_loss = 0.38877058320890656, disc_loss = 0.06728883739129675
Trained batch 378 in epoch 6, gen_loss = 0.3888294193549647, disc_loss = 0.0671288454026662
Trained batch 379 in epoch 6, gen_loss = 0.38884696231076593, disc_loss = 0.06696169821386176
Trained batch 380 in epoch 6, gen_loss = 0.38877852570040644, disc_loss = 0.06683639199301855
Trained batch 381 in epoch 6, gen_loss = 0.3886903534540955, disc_loss = 0.06670035490051829
Trained batch 382 in epoch 6, gen_loss = 0.3886865392988718, disc_loss = 0.06653313819311715
Trained batch 383 in epoch 6, gen_loss = 0.38876272287840646, disc_loss = 0.06637422553164167
Trained batch 384 in epoch 6, gen_loss = 0.3886588909409263, disc_loss = 0.06626777862706645
Trained batch 385 in epoch 6, gen_loss = 0.3886301711278876, disc_loss = 0.06635040205896113
Trained batch 386 in epoch 6, gen_loss = 0.389020245435626, disc_loss = 0.06678426307048504
Trained batch 387 in epoch 6, gen_loss = 0.3889473489264852, disc_loss = 0.06696874389998596
Trained batch 388 in epoch 6, gen_loss = 0.3891379491528999, disc_loss = 0.06686487076097769
Trained batch 389 in epoch 6, gen_loss = 0.3890997159175384, disc_loss = 0.06703793450843734
Trained batch 390 in epoch 6, gen_loss = 0.3891222807757385, disc_loss = 0.06693145753208386
Trained batch 391 in epoch 6, gen_loss = 0.3889025478642814, disc_loss = 0.0675438399829341
Trained batch 392 in epoch 6, gen_loss = 0.38899313281207293, disc_loss = 0.06745482122812316
Trained batch 393 in epoch 6, gen_loss = 0.3890219445004681, disc_loss = 0.06742699524130068
Trained batch 394 in epoch 6, gen_loss = 0.38895812102510957, disc_loss = 0.06748586403076313
Trained batch 395 in epoch 6, gen_loss = 0.38889581416592456, disc_loss = 0.06743855006237881
Trained batch 396 in epoch 6, gen_loss = 0.38902399101545587, disc_loss = 0.06740890874442942
Trained batch 397 in epoch 6, gen_loss = 0.38881097067540615, disc_loss = 0.06737307376221253
Trained batch 398 in epoch 6, gen_loss = 0.3888941686553764, disc_loss = 0.06739176674816001
Trained batch 399 in epoch 6, gen_loss = 0.3888221442699432, disc_loss = 0.0675029174372321
Trained batch 400 in epoch 6, gen_loss = 0.38881887179657704, disc_loss = 0.06750500604842424
Trained batch 401 in epoch 6, gen_loss = 0.3887195936334667, disc_loss = 0.06738087943516467
Trained batch 402 in epoch 6, gen_loss = 0.3887035662571786, disc_loss = 0.06725934763420512
Trained batch 403 in epoch 6, gen_loss = 0.38861373885728345, disc_loss = 0.06710687480892266
Trained batch 404 in epoch 6, gen_loss = 0.38878645219920593, disc_loss = 0.06695999390974548
Trained batch 405 in epoch 6, gen_loss = 0.38883506862694406, disc_loss = 0.06681619929849386
Trained batch 406 in epoch 6, gen_loss = 0.38884806859991183, disc_loss = 0.06668317545930734
Trained batch 407 in epoch 6, gen_loss = 0.38889562375113074, disc_loss = 0.06653704236925799
Trained batch 408 in epoch 6, gen_loss = 0.38884766316064123, disc_loss = 0.066460886493685
Trained batch 409 in epoch 6, gen_loss = 0.3888680008853354, disc_loss = 0.06634288860155588
Trained batch 410 in epoch 6, gen_loss = 0.3888643062027701, disc_loss = 0.0665653644649679
Trained batch 411 in epoch 6, gen_loss = 0.3886532336473465, disc_loss = 0.06698429668763002
Trained batch 412 in epoch 6, gen_loss = 0.3889606913989162, disc_loss = 0.0669057596915742
Trained batch 413 in epoch 6, gen_loss = 0.3889061054169844, disc_loss = 0.06697695630496808
Trained batch 414 in epoch 6, gen_loss = 0.38896779001477255, disc_loss = 0.06708737184652633
Trained batch 415 in epoch 6, gen_loss = 0.3891721698097311, disc_loss = 0.0672207026615909
Trained batch 416 in epoch 6, gen_loss = 0.3890370048350282, disc_loss = 0.06710394219678494
Trained batch 417 in epoch 6, gen_loss = 0.388862282037735, disc_loss = 0.0671767393838944
Trained batch 418 in epoch 6, gen_loss = 0.38895647700760416, disc_loss = 0.06746565175091576
Trained batch 419 in epoch 6, gen_loss = 0.38887701566730226, disc_loss = 0.06738254542052302
Trained batch 420 in epoch 6, gen_loss = 0.3887063625164666, disc_loss = 0.0674093168404732
Trained batch 421 in epoch 6, gen_loss = 0.38882907328164973, disc_loss = 0.06732198225844087
Trained batch 422 in epoch 6, gen_loss = 0.38894045085208073, disc_loss = 0.06717774333777984
Trained batch 423 in epoch 6, gen_loss = 0.38887781853664594, disc_loss = 0.06704002416435682
Trained batch 424 in epoch 6, gen_loss = 0.3888774038763607, disc_loss = 0.06700201710960006
Trained batch 425 in epoch 6, gen_loss = 0.38897038135730044, disc_loss = 0.06701884712278405
Trained batch 426 in epoch 6, gen_loss = 0.38875917277235617, disc_loss = 0.06751705049777042
Trained batch 427 in epoch 6, gen_loss = 0.388846604484264, disc_loss = 0.06812713730146795
Trained batch 428 in epoch 6, gen_loss = 0.3886628486476578, disc_loss = 0.06807366494330337
Trained batch 429 in epoch 6, gen_loss = 0.3885320743156034, disc_loss = 0.06818743864193472
Trained batch 430 in epoch 6, gen_loss = 0.3885807316845365, disc_loss = 0.06823546447782516
Trained batch 431 in epoch 6, gen_loss = 0.3884524685779103, disc_loss = 0.06813188184524835
Trained batch 432 in epoch 6, gen_loss = 0.38841298828224113, disc_loss = 0.06804257538976195
Trained batch 433 in epoch 6, gen_loss = 0.3884129592213213, disc_loss = 0.06794122675774954
Trained batch 434 in epoch 6, gen_loss = 0.38851820703210505, disc_loss = 0.06788425292851853
Trained batch 435 in epoch 6, gen_loss = 0.38858626516313727, disc_loss = 0.06819842801666434
Trained batch 436 in epoch 6, gen_loss = 0.3883768374641645, disc_loss = 0.0688689503647191
Trained batch 437 in epoch 6, gen_loss = 0.38836092797860705, disc_loss = 0.06937959046606995
Trained batch 438 in epoch 6, gen_loss = 0.3883350987776537, disc_loss = 0.0693088943421934
Trained batch 439 in epoch 6, gen_loss = 0.3883392082019286, disc_loss = 0.06942092309525999
Trained batch 440 in epoch 6, gen_loss = 0.38842258533112317, disc_loss = 0.06934421675653532
Trained batch 441 in epoch 6, gen_loss = 0.3885256249575593, disc_loss = 0.06927183795271534
Trained batch 442 in epoch 6, gen_loss = 0.38835744132575817, disc_loss = 0.06933429306341465
Trained batch 443 in epoch 6, gen_loss = 0.3883612689536971, disc_loss = 0.06979957908163317
Trained batch 444 in epoch 6, gen_loss = 0.3882437087176891, disc_loss = 0.06999130751885306
Trained batch 445 in epoch 6, gen_loss = 0.38845549911394245, disc_loss = 0.07039081880503288
Trained batch 446 in epoch 6, gen_loss = 0.3883512802172027, disc_loss = 0.07038727933301338
Trained batch 447 in epoch 6, gen_loss = 0.38826374283858706, disc_loss = 0.07049173313498613
Trained batch 448 in epoch 6, gen_loss = 0.3881455281529501, disc_loss = 0.07056404697244162
Trained batch 449 in epoch 6, gen_loss = 0.38833777811792164, disc_loss = 0.0705137916876831
Trained batch 450 in epoch 6, gen_loss = 0.38835917059703834, disc_loss = 0.07053020611114205
Trained batch 451 in epoch 6, gen_loss = 0.3882310493989328, disc_loss = 0.07041126275919296
Trained batch 452 in epoch 6, gen_loss = 0.38810278853570124, disc_loss = 0.0707827350941937
Trained batch 453 in epoch 6, gen_loss = 0.3880379830162956, disc_loss = 0.07107795778782998
Trained batch 454 in epoch 6, gen_loss = 0.388038732782825, disc_loss = 0.07101052762623263
Trained batch 455 in epoch 6, gen_loss = 0.38800191800845296, disc_loss = 0.07087461218766852
Trained batch 456 in epoch 6, gen_loss = 0.38811680837585316, disc_loss = 0.07073763000403879
Trained batch 457 in epoch 6, gen_loss = 0.3883263653542798, disc_loss = 0.07061779156365883
Trained batch 458 in epoch 6, gen_loss = 0.38828086749141255, disc_loss = 0.07047430275277942
Trained batch 459 in epoch 6, gen_loss = 0.38824513761893564, disc_loss = 0.07035102804505226
Trained batch 460 in epoch 6, gen_loss = 0.38820886838203394, disc_loss = 0.07022096615015992
Trained batch 461 in epoch 6, gen_loss = 0.38817460976895835, disc_loss = 0.07011256791858882
Trained batch 462 in epoch 6, gen_loss = 0.38806868243165976, disc_loss = 0.06998667309159257
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4354485273361206, disc_loss = 0.009174998849630356
Trained batch 1 in epoch 7, gen_loss = 0.45075979828834534, disc_loss = 0.02167428284883499
Trained batch 2 in epoch 7, gen_loss = 0.4318181872367859, disc_loss = 0.018686709304650623
Trained batch 3 in epoch 7, gen_loss = 0.4264054596424103, disc_loss = 0.01534630823880434
Trained batch 4 in epoch 7, gen_loss = 0.41550469398498535, disc_loss = 0.013735871948301791
Trained batch 5 in epoch 7, gen_loss = 0.41081101695696515, disc_loss = 0.01229182716148595
Trained batch 6 in epoch 7, gen_loss = 0.41270786949566435, disc_loss = 0.019009616425526992
Trained batch 7 in epoch 7, gen_loss = 0.405262716114521, disc_loss = 0.04649462056113407
Trained batch 8 in epoch 7, gen_loss = 0.40800219111972386, disc_loss = 0.0609841667012208
Trained batch 9 in epoch 7, gen_loss = 0.40816122889518736, disc_loss = 0.05875118016265333
Trained batch 10 in epoch 7, gen_loss = 0.41244581612673675, disc_loss = 0.05547788887369362
Trained batch 11 in epoch 7, gen_loss = 0.4047781378030777, disc_loss = 0.0555711470466728
Trained batch 12 in epoch 7, gen_loss = 0.40849639360721296, disc_loss = 0.060921534430235624
Trained batch 13 in epoch 7, gen_loss = 0.40465036034584045, disc_loss = 0.060275060889710276
Trained batch 14 in epoch 7, gen_loss = 0.40482766230901085, disc_loss = 0.05757187378282348
Trained batch 15 in epoch 7, gen_loss = 0.404181445017457, disc_loss = 0.05633987669716589
Trained batch 16 in epoch 7, gen_loss = 0.4041662864825305, disc_loss = 0.05328020806807805
Trained batch 17 in epoch 7, gen_loss = 0.4019833637608422, disc_loss = 0.052025228143773146
Trained batch 18 in epoch 7, gen_loss = 0.40058471811445134, disc_loss = 0.049709855505314315
Trained batch 19 in epoch 7, gen_loss = 0.404653999209404, disc_loss = 0.0477014152565971
Trained batch 20 in epoch 7, gen_loss = 0.40496135751406354, disc_loss = 0.04568646857071491
Trained batch 21 in epoch 7, gen_loss = 0.40300293266773224, disc_loss = 0.04384949818168851
Trained batch 22 in epoch 7, gen_loss = 0.40433979423149774, disc_loss = 0.04223622399908693
Trained batch 23 in epoch 7, gen_loss = 0.400520745664835, disc_loss = 0.04099615436280146
Trained batch 24 in epoch 7, gen_loss = 0.4011192297935486, disc_loss = 0.03958166342228651
Trained batch 25 in epoch 7, gen_loss = 0.40155832584087664, disc_loss = 0.038828615636493154
Trained batch 26 in epoch 7, gen_loss = 0.40078715041831686, disc_loss = 0.03751176830243181
Trained batch 27 in epoch 7, gen_loss = 0.4001046344637871, disc_loss = 0.03635735881315278
Trained batch 28 in epoch 7, gen_loss = 0.39960085523539574, disc_loss = 0.035211564057731425
Trained batch 29 in epoch 7, gen_loss = 0.3980845481157303, disc_loss = 0.03429166551989814
Trained batch 30 in epoch 7, gen_loss = 0.39977305646865596, disc_loss = 0.03330718969265299
Trained batch 31 in epoch 7, gen_loss = 0.4001180473715067, disc_loss = 0.03240646699850913
Trained batch 32 in epoch 7, gen_loss = 0.4010728362834815, disc_loss = 0.03157997659097115
Trained batch 33 in epoch 7, gen_loss = 0.3990118021474165, disc_loss = 0.030905348358347136
Trained batch 34 in epoch 7, gen_loss = 0.3977913294519697, disc_loss = 0.030765339519296372
Trained batch 35 in epoch 7, gen_loss = 0.39862413207689923, disc_loss = 0.030166215082216594
Trained batch 36 in epoch 7, gen_loss = 0.39823480071248235, disc_loss = 0.029492289041848602
Trained batch 37 in epoch 7, gen_loss = 0.3991094702168515, disc_loss = 0.02882818989210615
Trained batch 38 in epoch 7, gen_loss = 0.39942711438888157, disc_loss = 0.028411022447145138
Trained batch 39 in epoch 7, gen_loss = 0.4004643507301807, disc_loss = 0.028010859328787774
Trained batch 40 in epoch 7, gen_loss = 0.401252237035007, disc_loss = 0.02740886529748578
Trained batch 41 in epoch 7, gen_loss = 0.40261626172633397, disc_loss = 0.026876392092422714
Trained batch 42 in epoch 7, gen_loss = 0.40359331424846207, disc_loss = 0.0265044957063659
Trained batch 43 in epoch 7, gen_loss = 0.40384032374078577, disc_loss = 0.02667452173244039
Trained batch 44 in epoch 7, gen_loss = 0.40376996199289955, disc_loss = 0.028500742201382916
Trained batch 45 in epoch 7, gen_loss = 0.40247037358905957, disc_loss = 0.032528643197703946
Trained batch 46 in epoch 7, gen_loss = 0.4038117451870695, disc_loss = 0.03554788055988227
Trained batch 47 in epoch 7, gen_loss = 0.40133725355068844, disc_loss = 0.03809685863961931
Trained batch 48 in epoch 7, gen_loss = 0.4022116588086498, disc_loss = 0.03993921208537507
Trained batch 49 in epoch 7, gen_loss = 0.4005787545442581, disc_loss = 0.040444001839496195
Trained batch 50 in epoch 7, gen_loss = 0.40052208129097433, disc_loss = 0.04011133530944148
Trained batch 51 in epoch 7, gen_loss = 0.3998317884711119, disc_loss = 0.039915594402163364
Trained batch 52 in epoch 7, gen_loss = 0.4003842596737844, disc_loss = 0.03943445034905003
Trained batch 53 in epoch 7, gen_loss = 0.401769635853944, disc_loss = 0.040005776690560636
Trained batch 54 in epoch 7, gen_loss = 0.40170397704297844, disc_loss = 0.04084758548997343
Trained batch 55 in epoch 7, gen_loss = 0.40165690811617033, disc_loss = 0.04021212636975439
Trained batch 56 in epoch 7, gen_loss = 0.4015382606732218, disc_loss = 0.03994145001317456
Trained batch 57 in epoch 7, gen_loss = 0.4016216196890535, disc_loss = 0.03932424155786505
Trained batch 58 in epoch 7, gen_loss = 0.4011553955280175, disc_loss = 0.03887295668897361
Trained batch 59 in epoch 7, gen_loss = 0.4023865297436714, disc_loss = 0.03836446076553936
Trained batch 60 in epoch 7, gen_loss = 0.40334880107738935, disc_loss = 0.03801708868094033
Trained batch 61 in epoch 7, gen_loss = 0.402701971511687, disc_loss = 0.03757242692799698
Trained batch 62 in epoch 7, gen_loss = 0.4022350245051914, disc_loss = 0.03704178788226157
Trained batch 63 in epoch 7, gen_loss = 0.40216182405129075, disc_loss = 0.038342305979313096
Trained batch 64 in epoch 7, gen_loss = 0.40107825077497045, disc_loss = 0.04368392830499663
Trained batch 65 in epoch 7, gen_loss = 0.4015940310377063, disc_loss = 0.04365116080875988
Trained batch 66 in epoch 7, gen_loss = 0.40270136541395046, disc_loss = 0.043855114878196995
Trained batch 67 in epoch 7, gen_loss = 0.40200947444228563, disc_loss = 0.04331141266875955
Trained batch 68 in epoch 7, gen_loss = 0.4018192256706348, disc_loss = 0.042823617417446294
Trained batch 69 in epoch 7, gen_loss = 0.4016741067171097, disc_loss = 0.04228061811798917
Trained batch 70 in epoch 7, gen_loss = 0.401242927346431, disc_loss = 0.041871567627310126
Trained batch 71 in epoch 7, gen_loss = 0.4005487900641229, disc_loss = 0.04139201056225122
Trained batch 72 in epoch 7, gen_loss = 0.4008384322466916, disc_loss = 0.04096497186102381
Trained batch 73 in epoch 7, gen_loss = 0.40055987399977605, disc_loss = 0.04052403859001257
Trained batch 74 in epoch 7, gen_loss = 0.39978886206944786, disc_loss = 0.04022603263768057
Trained batch 75 in epoch 7, gen_loss = 0.39966528980355515, disc_loss = 0.039746664161181174
Trained batch 76 in epoch 7, gen_loss = 0.3990487363431361, disc_loss = 0.039359247206117616
Trained batch 77 in epoch 7, gen_loss = 0.399587645362585, disc_loss = 0.03894426603503048
Trained batch 78 in epoch 7, gen_loss = 0.3995770099042337, disc_loss = 0.03849178343669429
Trained batch 79 in epoch 7, gen_loss = 0.39888892136514187, disc_loss = 0.03823087244236376
Trained batch 80 in epoch 7, gen_loss = 0.39894046459668947, disc_loss = 0.03875052580253485
Trained batch 81 in epoch 7, gen_loss = 0.39711640847892293, disc_loss = 0.042517772361795166
Trained batch 82 in epoch 7, gen_loss = 0.396725586379867, disc_loss = 0.04359284367311342
Trained batch 83 in epoch 7, gen_loss = 0.3979345049176897, disc_loss = 0.044524269098127706
Trained batch 84 in epoch 7, gen_loss = 0.39815693392473106, disc_loss = 0.04515892741379931
Trained batch 85 in epoch 7, gen_loss = 0.39813887483851856, disc_loss = 0.04571643004702881
Trained batch 86 in epoch 7, gen_loss = 0.3978712089445399, disc_loss = 0.04626166932659502
Trained batch 87 in epoch 7, gen_loss = 0.3973424681885676, disc_loss = 0.04625164557364769
Trained batch 88 in epoch 7, gen_loss = 0.3971111288901125, disc_loss = 0.04607193783877857
Trained batch 89 in epoch 7, gen_loss = 0.39688294463687473, disc_loss = 0.04592625934164971
Trained batch 90 in epoch 7, gen_loss = 0.3981508776381776, disc_loss = 0.04609597364573607
Trained batch 91 in epoch 7, gen_loss = 0.39763489624728326, disc_loss = 0.045830687697794616
Trained batch 92 in epoch 7, gen_loss = 0.3976710608569525, disc_loss = 0.04540950503270392
Trained batch 93 in epoch 7, gen_loss = 0.3974186527602216, disc_loss = 0.04497377634633015
Trained batch 94 in epoch 7, gen_loss = 0.3974167155592065, disc_loss = 0.044616100199422554
Trained batch 95 in epoch 7, gen_loss = 0.3985119943196575, disc_loss = 0.04424512717863157
Trained batch 96 in epoch 7, gen_loss = 0.3987737162825988, disc_loss = 0.04398897103725251
Trained batch 97 in epoch 7, gen_loss = 0.39842805722538305, disc_loss = 0.043692253812748404
Trained batch 98 in epoch 7, gen_loss = 0.3980475528673692, disc_loss = 0.043439292318347575
Trained batch 99 in epoch 7, gen_loss = 0.3985662120580673, disc_loss = 0.04310261696344241
Trained batch 100 in epoch 7, gen_loss = 0.39893440474378, disc_loss = 0.04292912642692796
Trained batch 101 in epoch 7, gen_loss = 0.3985234592475143, disc_loss = 0.042583579697427064
Trained batch 102 in epoch 7, gen_loss = 0.39811825289309605, disc_loss = 0.04243870714941578
Trained batch 103 in epoch 7, gen_loss = 0.39812053740024567, disc_loss = 0.042096382774896204
Trained batch 104 in epoch 7, gen_loss = 0.3985638732001895, disc_loss = 0.04175136890927596
Trained batch 105 in epoch 7, gen_loss = 0.398738997443667, disc_loss = 0.04165145939101799
Trained batch 106 in epoch 7, gen_loss = 0.3998753915880328, disc_loss = 0.04145173604652355
Trained batch 107 in epoch 7, gen_loss = 0.3998252015422892, disc_loss = 0.04120459850592953
Trained batch 108 in epoch 7, gen_loss = 0.39931194388538327, disc_loss = 0.04086132513342101
Trained batch 109 in epoch 7, gen_loss = 0.3995053789832375, disc_loss = 0.040530722829597916
Trained batch 110 in epoch 7, gen_loss = 0.400302322598191, disc_loss = 0.04032483521160913
Trained batch 111 in epoch 7, gen_loss = 0.40014253556728363, disc_loss = 0.04000526061697331
Trained batch 112 in epoch 7, gen_loss = 0.4002772812294749, disc_loss = 0.03969233695714347
Trained batch 113 in epoch 7, gen_loss = 0.40092768428618447, disc_loss = 0.03938704965995592
Trained batch 114 in epoch 7, gen_loss = 0.401226291190023, disc_loss = 0.03907692030720089
Trained batch 115 in epoch 7, gen_loss = 0.4010630761241091, disc_loss = 0.03876065685622523
Trained batch 116 in epoch 7, gen_loss = 0.4008979601228339, disc_loss = 0.03854911431717949
Trained batch 117 in epoch 7, gen_loss = 0.40117630564560325, disc_loss = 0.038268541218712926
Trained batch 118 in epoch 7, gen_loss = 0.4009828640132391, disc_loss = 0.03808483831631411
Trained batch 119 in epoch 7, gen_loss = 0.40125422229369484, disc_loss = 0.037800139386672524
Trained batch 120 in epoch 7, gen_loss = 0.4015256624576474, disc_loss = 0.03755937511686328
Trained batch 121 in epoch 7, gen_loss = 0.4012311745862492, disc_loss = 0.03729223727141736
Trained batch 122 in epoch 7, gen_loss = 0.4009885754042525, disc_loss = 0.03701409627683461
Trained batch 123 in epoch 7, gen_loss = 0.4005599829458421, disc_loss = 0.036789914313328245
Trained batch 124 in epoch 7, gen_loss = 0.40048937463760376, disc_loss = 0.03657895894907415
Trained batch 125 in epoch 7, gen_loss = 0.4004992956206912, disc_loss = 0.0363356221877482
Trained batch 126 in epoch 7, gen_loss = 0.40074532402781987, disc_loss = 0.03610802915746596
Trained batch 127 in epoch 7, gen_loss = 0.40094024455174804, disc_loss = 0.035870153065843624
Trained batch 128 in epoch 7, gen_loss = 0.4008936371452125, disc_loss = 0.03565605656359373
Trained batch 129 in epoch 7, gen_loss = 0.401271845973455, disc_loss = 0.03546134073179788
Trained batch 130 in epoch 7, gen_loss = 0.40128266629371934, disc_loss = 0.03522945037076093
Trained batch 131 in epoch 7, gen_loss = 0.40103990178216586, disc_loss = 0.03499259682421601
Trained batch 132 in epoch 7, gen_loss = 0.4015025211904282, disc_loss = 0.034762767772015216
Trained batch 133 in epoch 7, gen_loss = 0.40160772849374743, disc_loss = 0.034523795739358376
Trained batch 134 in epoch 7, gen_loss = 0.4017202624568233, disc_loss = 0.03429923322983086
Trained batch 135 in epoch 7, gen_loss = 0.4014872187638984, disc_loss = 0.034096951985060624
Trained batch 136 in epoch 7, gen_loss = 0.40131634734842897, disc_loss = 0.033874220022741354
Trained batch 137 in epoch 7, gen_loss = 0.40143407233383344, disc_loss = 0.033651562429546124
Trained batch 138 in epoch 7, gen_loss = 0.4012671029396194, disc_loss = 0.033449412787520734
Trained batch 139 in epoch 7, gen_loss = 0.40129167820726125, disc_loss = 0.033233685423952664
Trained batch 140 in epoch 7, gen_loss = 0.40139279297903074, disc_loss = 0.0330155483721128
Trained batch 141 in epoch 7, gen_loss = 0.40170673270460583, disc_loss = 0.03282243205057326
Trained batch 142 in epoch 7, gen_loss = 0.4016410672998095, disc_loss = 0.03261138789251551
Trained batch 143 in epoch 7, gen_loss = 0.40155127748019165, disc_loss = 0.032402502054335654
Trained batch 144 in epoch 7, gen_loss = 0.40121754448989344, disc_loss = 0.032198294700155485
Trained batch 145 in epoch 7, gen_loss = 0.40136935245500854, disc_loss = 0.032001651215928364
Trained batch 146 in epoch 7, gen_loss = 0.4016670383969132, disc_loss = 0.03181848599778197
Trained batch 147 in epoch 7, gen_loss = 0.40168785464924733, disc_loss = 0.03162603429675958
Trained batch 148 in epoch 7, gen_loss = 0.40133078226307095, disc_loss = 0.031428383324207776
Trained batch 149 in epoch 7, gen_loss = 0.40163279513518013, disc_loss = 0.031246543910043934
Trained batch 150 in epoch 7, gen_loss = 0.40145396890229734, disc_loss = 0.031054735126664602
Trained batch 151 in epoch 7, gen_loss = 0.4014529001555945, disc_loss = 0.03086244442429712
Trained batch 152 in epoch 7, gen_loss = 0.40100786109375797, disc_loss = 0.0306895367224439
Trained batch 153 in epoch 7, gen_loss = 0.400693513356246, disc_loss = 0.03052796122342856
Trained batch 154 in epoch 7, gen_loss = 0.4011071330116641, disc_loss = 0.030352630267190116
Trained batch 155 in epoch 7, gen_loss = 0.40125203877687454, disc_loss = 0.030206247184347983
Trained batch 156 in epoch 7, gen_loss = 0.4013822065417174, disc_loss = 0.030036807574100412
Trained batch 157 in epoch 7, gen_loss = 0.4013927871290642, disc_loss = 0.029868239139743104
Trained batch 158 in epoch 7, gen_loss = 0.4011952016713484, disc_loss = 0.029701961626872747
Trained batch 159 in epoch 7, gen_loss = 0.4015806555747986, disc_loss = 0.029536640513833846
Trained batch 160 in epoch 7, gen_loss = 0.4012752726951741, disc_loss = 0.029396978300209417
Trained batch 161 in epoch 7, gen_loss = 0.40120315128638423, disc_loss = 0.029229916940460465
Trained batch 162 in epoch 7, gen_loss = 0.4014111340411602, disc_loss = 0.029125802182489606
Trained batch 163 in epoch 7, gen_loss = 0.40128517405288977, disc_loss = 0.02901578652345939
Trained batch 164 in epoch 7, gen_loss = 0.4014119717207822, disc_loss = 0.02886735048836492
Trained batch 165 in epoch 7, gen_loss = 0.40147728015141315, disc_loss = 0.02871115224545328
Trained batch 166 in epoch 7, gen_loss = 0.40128737580990365, disc_loss = 0.028674346985278685
Trained batch 167 in epoch 7, gen_loss = 0.40144054485218866, disc_loss = 0.02853676545852241
Trained batch 168 in epoch 7, gen_loss = 0.4013048375146629, disc_loss = 0.028385793759223052
Trained batch 169 in epoch 7, gen_loss = 0.4012884771122652, disc_loss = 0.028345428639338078
Trained batch 170 in epoch 7, gen_loss = 0.4012710570591932, disc_loss = 0.028262509024233627
Trained batch 171 in epoch 7, gen_loss = 0.4016472272748171, disc_loss = 0.028197760175951474
Trained batch 172 in epoch 7, gen_loss = 0.40163266848277496, disc_loss = 0.028103814478506028
Trained batch 173 in epoch 7, gen_loss = 0.4015152733558896, disc_loss = 0.027961561028797436
Trained batch 174 in epoch 7, gen_loss = 0.401536146572658, disc_loss = 0.02782005362146135
Trained batch 175 in epoch 7, gen_loss = 0.4015620415183631, disc_loss = 0.027706894477887545
Trained batch 176 in epoch 7, gen_loss = 0.4015803229337358, disc_loss = 0.027580941495180426
Trained batch 177 in epoch 7, gen_loss = 0.40138678102011094, disc_loss = 0.027487967570777982
Trained batch 178 in epoch 7, gen_loss = 0.4015262949400108, disc_loss = 0.027402042691575042
Trained batch 179 in epoch 7, gen_loss = 0.4020152989361021, disc_loss = 0.027266775709964955
Trained batch 180 in epoch 7, gen_loss = 0.40183484653083, disc_loss = 0.027142093343871198
Trained batch 181 in epoch 7, gen_loss = 0.40193334713086976, disc_loss = 0.027025969777701442
Trained batch 182 in epoch 7, gen_loss = 0.4020643998039225, disc_loss = 0.026921087496181127
Trained batch 183 in epoch 7, gen_loss = 0.4020249846836795, disc_loss = 0.02678811189189614
Trained batch 184 in epoch 7, gen_loss = 0.40192808041701444, disc_loss = 0.02665686026353993
Trained batch 185 in epoch 7, gen_loss = 0.4018968390200728, disc_loss = 0.026535714072080187
Trained batch 186 in epoch 7, gen_loss = 0.4019807900655716, disc_loss = 0.026414648621631936
Trained batch 187 in epoch 7, gen_loss = 0.40226834410048545, disc_loss = 0.0263053333365725
Trained batch 188 in epoch 7, gen_loss = 0.4025082078875688, disc_loss = 0.026214974402036104
Trained batch 189 in epoch 7, gen_loss = 0.4026672333478928, disc_loss = 0.026182349925051984
Trained batch 190 in epoch 7, gen_loss = 0.4020437031828296, disc_loss = 0.027199983008630104
Trained batch 191 in epoch 7, gen_loss = 0.4024889647650222, disc_loss = 0.030467925629030407
Trained batch 192 in epoch 7, gen_loss = 0.40262971517335566, disc_loss = 0.03240094580651391
Trained batch 193 in epoch 7, gen_loss = 0.40207437049482286, disc_loss = 0.033347382101580766
Trained batch 194 in epoch 7, gen_loss = 0.40176355563677274, disc_loss = 0.03418240550702486
Trained batch 195 in epoch 7, gen_loss = 0.4011999253107577, disc_loss = 0.03487885914141863
Trained batch 196 in epoch 7, gen_loss = 0.40083074781495304, disc_loss = 0.035493072251751454
Trained batch 197 in epoch 7, gen_loss = 0.40067861823722567, disc_loss = 0.03593803509173802
Trained batch 198 in epoch 7, gen_loss = 0.4003739250664735, disc_loss = 0.03622776864917865
Trained batch 199 in epoch 7, gen_loss = 0.4003487679362297, disc_loss = 0.03639638367749285
Trained batch 200 in epoch 7, gen_loss = 0.39976350777777864, disc_loss = 0.036815939069753376
Trained batch 201 in epoch 7, gen_loss = 0.3988425828295179, disc_loss = 0.03775239997430437
Trained batch 202 in epoch 7, gen_loss = 0.3991489148345487, disc_loss = 0.03821795925284676
Trained batch 203 in epoch 7, gen_loss = 0.39877770921471073, disc_loss = 0.03844755222991237
Trained batch 204 in epoch 7, gen_loss = 0.39843793489584106, disc_loss = 0.03993209418443191
Trained batch 205 in epoch 7, gen_loss = 0.3986757271064138, disc_loss = 0.04091184448566089
Trained batch 206 in epoch 7, gen_loss = 0.39854561670678823, disc_loss = 0.04101672393982951
Trained batch 207 in epoch 7, gen_loss = 0.3981125144861065, disc_loss = 0.041325227641209494
Trained batch 208 in epoch 7, gen_loss = 0.3978277884744571, disc_loss = 0.04292961548396685
Trained batch 209 in epoch 7, gen_loss = 0.39779710180702665, disc_loss = 0.0436349080404311
Trained batch 210 in epoch 7, gen_loss = 0.3977354034004618, disc_loss = 0.04380539115860405
Trained batch 211 in epoch 7, gen_loss = 0.3976721432552023, disc_loss = 0.04432759714864177
Trained batch 212 in epoch 7, gen_loss = 0.39775073073559525, disc_loss = 0.04436306523961483
Trained batch 213 in epoch 7, gen_loss = 0.39790422274409054, disc_loss = 0.04457820204867781
Trained batch 214 in epoch 7, gen_loss = 0.3976893532414769, disc_loss = 0.04498830595064562
Trained batch 215 in epoch 7, gen_loss = 0.39795851590180836, disc_loss = 0.04561028510269588
Trained batch 216 in epoch 7, gen_loss = 0.39746591840196865, disc_loss = 0.045719861724062005
Trained batch 217 in epoch 7, gen_loss = 0.3970522792377603, disc_loss = 0.046490003292367646
Trained batch 218 in epoch 7, gen_loss = 0.39713639408758244, disc_loss = 0.04646898127112061
Trained batch 219 in epoch 7, gen_loss = 0.3971811071715572, disc_loss = 0.046326088517459785
Trained batch 220 in epoch 7, gen_loss = 0.39695670330955973, disc_loss = 0.04632914897499024
Trained batch 221 in epoch 7, gen_loss = 0.3968325204274676, disc_loss = 0.04647142029113581
Trained batch 222 in epoch 7, gen_loss = 0.3969900237204248, disc_loss = 0.04738015703378755
Trained batch 223 in epoch 7, gen_loss = 0.3968125103440668, disc_loss = 0.04786162183310288
Trained batch 224 in epoch 7, gen_loss = 0.3969469264480803, disc_loss = 0.047706518745981155
Trained batch 225 in epoch 7, gen_loss = 0.3969197589079891, disc_loss = 0.048593098983329315
Trained batch 226 in epoch 7, gen_loss = 0.3967141143419669, disc_loss = 0.04946106912861558
Trained batch 227 in epoch 7, gen_loss = 0.3965135553296198, disc_loss = 0.04974385090488859
Trained batch 228 in epoch 7, gen_loss = 0.39649247570069074, disc_loss = 0.04985278712404591
Trained batch 229 in epoch 7, gen_loss = 0.3960494941343432, disc_loss = 0.050715895881370196
Trained batch 230 in epoch 7, gen_loss = 0.3960400314687134, disc_loss = 0.05159334732911013
Trained batch 231 in epoch 7, gen_loss = 0.3956810837804243, disc_loss = 0.05157562898590374
Trained batch 232 in epoch 7, gen_loss = 0.3954334890254066, disc_loss = 0.05186235048666261
Trained batch 233 in epoch 7, gen_loss = 0.39557138002581066, disc_loss = 0.051787712405789964
Trained batch 234 in epoch 7, gen_loss = 0.3952668919842294, disc_loss = 0.05185745503664255
Trained batch 235 in epoch 7, gen_loss = 0.3950717476338653, disc_loss = 0.051844734944683356
Trained batch 236 in epoch 7, gen_loss = 0.39488020130602114, disc_loss = 0.05192725428916467
Trained batch 237 in epoch 7, gen_loss = 0.39491241224924056, disc_loss = 0.05248762622716281
Trained batch 238 in epoch 7, gen_loss = 0.3945981531587106, disc_loss = 0.052890303612406125
Trained batch 239 in epoch 7, gen_loss = 0.39491030952582756, disc_loss = 0.05279258650407428
Trained batch 240 in epoch 7, gen_loss = 0.39485397891632257, disc_loss = 0.05268919218430118
Trained batch 241 in epoch 7, gen_loss = 0.394851749162536, disc_loss = 0.052517248472980074
Trained batch 242 in epoch 7, gen_loss = 0.39459727410181067, disc_loss = 0.05270769724712435
Trained batch 243 in epoch 7, gen_loss = 0.3948359045459599, disc_loss = 0.053003770880855346
Trained batch 244 in epoch 7, gen_loss = 0.3948847664254052, disc_loss = 0.05288023225041297
Trained batch 245 in epoch 7, gen_loss = 0.39473268480562584, disc_loss = 0.053775041509415894
Trained batch 246 in epoch 7, gen_loss = 0.39480348607065224, disc_loss = 0.05487048077097291
Trained batch 247 in epoch 7, gen_loss = 0.39493770170355996, disc_loss = 0.0551529595221866
Trained batch 248 in epoch 7, gen_loss = 0.3948193418093953, disc_loss = 0.055246781484395956
Trained batch 249 in epoch 7, gen_loss = 0.3945449054837227, disc_loss = 0.055150721923913806
Trained batch 250 in epoch 7, gen_loss = 0.39412801027060507, disc_loss = 0.05526193324986667
Trained batch 251 in epoch 7, gen_loss = 0.39414324510901694, disc_loss = 0.05549312961086379
Trained batch 252 in epoch 7, gen_loss = 0.3937400723752297, disc_loss = 0.05609515249101526
Trained batch 253 in epoch 7, gen_loss = 0.3939853328771479, disc_loss = 0.05634251033188775
Trained batch 254 in epoch 7, gen_loss = 0.3941553701957067, disc_loss = 0.056213037232758806
Trained batch 255 in epoch 7, gen_loss = 0.3942512809881009, disc_loss = 0.056080506286434684
Trained batch 256 in epoch 7, gen_loss = 0.3939579404629622, disc_loss = 0.055998222911023764
Trained batch 257 in epoch 7, gen_loss = 0.3939110616496367, disc_loss = 0.05649370274302557
Trained batch 258 in epoch 7, gen_loss = 0.393963663676991, disc_loss = 0.05793586783389773
Trained batch 259 in epoch 7, gen_loss = 0.39406601379697137, disc_loss = 0.0583097005849525
Trained batch 260 in epoch 7, gen_loss = 0.3937364904017284, disc_loss = 0.05848323341264564
Trained batch 261 in epoch 7, gen_loss = 0.3936306700565433, disc_loss = 0.05852757333306852
Trained batch 262 in epoch 7, gen_loss = 0.39355530218706386, disc_loss = 0.058488627096740776
Trained batch 263 in epoch 7, gen_loss = 0.39310917038131843, disc_loss = 0.058375272012199275
Trained batch 264 in epoch 7, gen_loss = 0.39304247245473684, disc_loss = 0.058213179001039915
Trained batch 265 in epoch 7, gen_loss = 0.3931517779715079, disc_loss = 0.05825485072503062
Trained batch 266 in epoch 7, gen_loss = 0.3932159687584259, disc_loss = 0.05817042510696662
Trained batch 267 in epoch 7, gen_loss = 0.39302046769368115, disc_loss = 0.05819225816339352
Trained batch 268 in epoch 7, gen_loss = 0.3931768401958685, disc_loss = 0.05811988385558668
Trained batch 269 in epoch 7, gen_loss = 0.39327362428108853, disc_loss = 0.05806216315185237
Trained batch 270 in epoch 7, gen_loss = 0.393514655447974, disc_loss = 0.05790382238556854
Trained batch 271 in epoch 7, gen_loss = 0.3935871347237159, disc_loss = 0.05776667220797047
Trained batch 272 in epoch 7, gen_loss = 0.39376508954898776, disc_loss = 0.05757497206301302
Trained batch 273 in epoch 7, gen_loss = 0.3936379627480994, disc_loss = 0.05747167910508689
Trained batch 274 in epoch 7, gen_loss = 0.39350974695249036, disc_loss = 0.05741720661817288
Trained batch 275 in epoch 7, gen_loss = 0.39387661871918733, disc_loss = 0.05817536951972347
Trained batch 276 in epoch 7, gen_loss = 0.39351596669815075, disc_loss = 0.05926018863511255
Trained batch 277 in epoch 7, gen_loss = 0.39358399856647996, disc_loss = 0.059253491236402805
Trained batch 278 in epoch 7, gen_loss = 0.3934835866894773, disc_loss = 0.05917236365429643
Trained batch 279 in epoch 7, gen_loss = 0.39345758988388946, disc_loss = 0.05912593498318789
Trained batch 280 in epoch 7, gen_loss = 0.39363209309314917, disc_loss = 0.0591597145458922
Trained batch 281 in epoch 7, gen_loss = 0.3934982134201003, disc_loss = 0.059352814718166114
Trained batch 282 in epoch 7, gen_loss = 0.3937301295068997, disc_loss = 0.05981151742799793
Trained batch 283 in epoch 7, gen_loss = 0.3937301463119581, disc_loss = 0.05965540965020486
Trained batch 284 in epoch 7, gen_loss = 0.39360836979589964, disc_loss = 0.06016890409508753
Trained batch 285 in epoch 7, gen_loss = 0.3936578915356756, disc_loss = 0.06018940268460518
Trained batch 286 in epoch 7, gen_loss = 0.3935973669697599, disc_loss = 0.06009212663544842
Trained batch 287 in epoch 7, gen_loss = 0.39339818293228745, disc_loss = 0.06025530059277015
Trained batch 288 in epoch 7, gen_loss = 0.3936375425451767, disc_loss = 0.06104569908216995
Trained batch 289 in epoch 7, gen_loss = 0.39357704700067125, disc_loss = 0.06094490051036701
Trained batch 290 in epoch 7, gen_loss = 0.3934341542601995, disc_loss = 0.06085129867226231
Trained batch 291 in epoch 7, gen_loss = 0.3932490044158615, disc_loss = 0.060839888744601625
Trained batch 292 in epoch 7, gen_loss = 0.3929808826881871, disc_loss = 0.0608186213384659
Trained batch 293 in epoch 7, gen_loss = 0.3929341421747694, disc_loss = 0.060698012798806
Trained batch 294 in epoch 7, gen_loss = 0.3930224018076719, disc_loss = 0.06058070807031087
Trained batch 295 in epoch 7, gen_loss = 0.3927370339531351, disc_loss = 0.060570676769743474
Trained batch 296 in epoch 7, gen_loss = 0.39239693084349136, disc_loss = 0.06140372486626698
Trained batch 297 in epoch 7, gen_loss = 0.39281471938694884, disc_loss = 0.06202325378286796
Trained batch 298 in epoch 7, gen_loss = 0.3928720521986684, disc_loss = 0.06185570328977632
Trained batch 299 in epoch 7, gen_loss = 0.3928091039756934, disc_loss = 0.06181465773183542
Trained batch 300 in epoch 7, gen_loss = 0.39275195288697745, disc_loss = 0.06172546386321159
Trained batch 301 in epoch 7, gen_loss = 0.3929272409010407, disc_loss = 0.061931122423979204
Trained batch 302 in epoch 7, gen_loss = 0.39286957641836046, disc_loss = 0.06280245394299956
Trained batch 303 in epoch 7, gen_loss = 0.3931590148590897, disc_loss = 0.06270663377386211
Trained batch 304 in epoch 7, gen_loss = 0.39309012562525075, disc_loss = 0.06296207710268495
Trained batch 305 in epoch 7, gen_loss = 0.39304615182229896, disc_loss = 0.06288404705183995
Trained batch 306 in epoch 7, gen_loss = 0.3929278512245669, disc_loss = 0.06283140303498795
Trained batch 307 in epoch 7, gen_loss = 0.3929992359276716, disc_loss = 0.0627259241395128
Trained batch 308 in epoch 7, gen_loss = 0.3930836611677528, disc_loss = 0.06254359981019508
Trained batch 309 in epoch 7, gen_loss = 0.3931188514636409, disc_loss = 0.06238965489563622
Trained batch 310 in epoch 7, gen_loss = 0.3931655860311349, disc_loss = 0.06234491111110249
Trained batch 311 in epoch 7, gen_loss = 0.3931158140588265, disc_loss = 0.06227801682969304
Trained batch 312 in epoch 7, gen_loss = 0.3931252198002209, disc_loss = 0.06224962183573363
Trained batch 313 in epoch 7, gen_loss = 0.3932429985350864, disc_loss = 0.06250330207945043
Trained batch 314 in epoch 7, gen_loss = 0.3931384864780638, disc_loss = 0.0635233489304988
Trained batch 315 in epoch 7, gen_loss = 0.3932797988475878, disc_loss = 0.06363417123425222
Trained batch 316 in epoch 7, gen_loss = 0.39344948910952365, disc_loss = 0.06466005625143025
Trained batch 317 in epoch 7, gen_loss = 0.39340041160770933, disc_loss = 0.06464863191439284
Trained batch 318 in epoch 7, gen_loss = 0.3930273896381025, disc_loss = 0.06498435310264729
Trained batch 319 in epoch 7, gen_loss = 0.3931410986464471, disc_loss = 0.06562236801364633
Trained batch 320 in epoch 7, gen_loss = 0.39308144783490917, disc_loss = 0.06583489280453712
Trained batch 321 in epoch 7, gen_loss = 0.3931702037127862, disc_loss = 0.06605244453480143
Trained batch 322 in epoch 7, gen_loss = 0.3930268360088484, disc_loss = 0.06603218106539983
Trained batch 323 in epoch 7, gen_loss = 0.39286687643623647, disc_loss = 0.06588248291195163
Trained batch 324 in epoch 7, gen_loss = 0.39264298379421236, disc_loss = 0.06588898520164478
Trained batch 325 in epoch 7, gen_loss = 0.39258594980086287, disc_loss = 0.0658446273497203
Trained batch 326 in epoch 7, gen_loss = 0.3922853010965779, disc_loss = 0.06601930871165844
Trained batch 327 in epoch 7, gen_loss = 0.39212280325591564, disc_loss = 0.06648907791248171
Trained batch 328 in epoch 7, gen_loss = 0.3916590735995661, disc_loss = 0.06716528597272264
Trained batch 329 in epoch 7, gen_loss = 0.39158842658454723, disc_loss = 0.06712521480671553
Trained batch 330 in epoch 7, gen_loss = 0.39166713233620737, disc_loss = 0.0671824070880347
Trained batch 331 in epoch 7, gen_loss = 0.3916507795542838, disc_loss = 0.0672208105662069
Trained batch 332 in epoch 7, gen_loss = 0.3916743181578748, disc_loss = 0.06716623382227546
Trained batch 333 in epoch 7, gen_loss = 0.3912952451738055, disc_loss = 0.06761112486947785
Trained batch 334 in epoch 7, gen_loss = 0.39155453189985073, disc_loss = 0.0682824311760574
Trained batch 335 in epoch 7, gen_loss = 0.3912991548311852, disc_loss = 0.06849345448530844
Trained batch 336 in epoch 7, gen_loss = 0.3911985188545742, disc_loss = 0.06900817999382744
Trained batch 337 in epoch 7, gen_loss = 0.3911419242355951, disc_loss = 0.06884988978299858
Trained batch 338 in epoch 7, gen_loss = 0.3911139546154523, disc_loss = 0.06882022625724112
Trained batch 339 in epoch 7, gen_loss = 0.39087274946710643, disc_loss = 0.0688430881137987
Trained batch 340 in epoch 7, gen_loss = 0.3907503340163888, disc_loss = 0.06873958220376286
Trained batch 341 in epoch 7, gen_loss = 0.39062836256466416, disc_loss = 0.0685542200522481
Trained batch 342 in epoch 7, gen_loss = 0.39055096794669203, disc_loss = 0.06839682649564455
Trained batch 343 in epoch 7, gen_loss = 0.3904959294771732, disc_loss = 0.06823599156429504
Trained batch 344 in epoch 7, gen_loss = 0.39054210216238877, disc_loss = 0.06851563190035792
Trained batch 345 in epoch 7, gen_loss = 0.39059494009424495, disc_loss = 0.07009621123706578
Trained batch 346 in epoch 7, gen_loss = 0.3903365445669515, disc_loss = 0.07064772566736163
Trained batch 347 in epoch 7, gen_loss = 0.3903298069262642, disc_loss = 0.07078477870719775
Trained batch 348 in epoch 7, gen_loss = 0.3898926153138579, disc_loss = 0.07218625135873218
Trained batch 349 in epoch 7, gen_loss = 0.38990691725696836, disc_loss = 0.07238430612687288
Trained batch 350 in epoch 7, gen_loss = 0.389931553237119, disc_loss = 0.07258290317582174
Trained batch 351 in epoch 7, gen_loss = 0.38976762117818, disc_loss = 0.07256343765865578
Trained batch 352 in epoch 7, gen_loss = 0.38942755665893936, disc_loss = 0.07264596911736898
Trained batch 353 in epoch 7, gen_loss = 0.38930478679426644, disc_loss = 0.0726740515990167
Trained batch 354 in epoch 7, gen_loss = 0.38944587065300473, disc_loss = 0.07266296586776021
Trained batch 355 in epoch 7, gen_loss = 0.38928060078721366, disc_loss = 0.07261552901126267
Trained batch 356 in epoch 7, gen_loss = 0.3891265049618499, disc_loss = 0.07257289884850665
Trained batch 357 in epoch 7, gen_loss = 0.3890154944868061, disc_loss = 0.07264163393843347
Trained batch 358 in epoch 7, gen_loss = 0.3887402606624747, disc_loss = 0.07254299254598963
Trained batch 359 in epoch 7, gen_loss = 0.3886256446854936, disc_loss = 0.07240165714530222
Trained batch 360 in epoch 7, gen_loss = 0.3888515330995549, disc_loss = 0.07228001246681576
Trained batch 361 in epoch 7, gen_loss = 0.3889414431393476, disc_loss = 0.07210067448621739
Trained batch 362 in epoch 7, gen_loss = 0.3889466134559353, disc_loss = 0.07195052447037376
Trained batch 363 in epoch 7, gen_loss = 0.3890050385597643, disc_loss = 0.07182534166917481
Trained batch 364 in epoch 7, gen_loss = 0.38906020918121076, disc_loss = 0.07172677728175249
Trained batch 365 in epoch 7, gen_loss = 0.38904411467860955, disc_loss = 0.07162449097666695
Trained batch 366 in epoch 7, gen_loss = 0.38907605194428313, disc_loss = 0.07154430514956477
Trained batch 367 in epoch 7, gen_loss = 0.38938933444897766, disc_loss = 0.07154265255635635
Trained batch 368 in epoch 7, gen_loss = 0.3895273122603331, disc_loss = 0.07137154720611315
Trained batch 369 in epoch 7, gen_loss = 0.3894537929344822, disc_loss = 0.07129042801491262
Trained batch 370 in epoch 7, gen_loss = 0.3895682979706484, disc_loss = 0.07111124395589893
Trained batch 371 in epoch 7, gen_loss = 0.38944776384260066, disc_loss = 0.07109031508274886
Trained batch 372 in epoch 7, gen_loss = 0.389242168685706, disc_loss = 0.07092801736381864
Trained batch 373 in epoch 7, gen_loss = 0.3892481160912922, disc_loss = 0.07091914953254312
Trained batch 374 in epoch 7, gen_loss = 0.38948888997236886, disc_loss = 0.07126114145138611
Trained batch 375 in epoch 7, gen_loss = 0.3892861957800515, disc_loss = 0.07109106175243567
Trained batch 376 in epoch 7, gen_loss = 0.38911100095557916, disc_loss = 0.07124211172485571
Trained batch 377 in epoch 7, gen_loss = 0.38932565457764123, disc_loss = 0.07144273034753967
Trained batch 378 in epoch 7, gen_loss = 0.38942976523986905, disc_loss = 0.07127260119625979
Trained batch 379 in epoch 7, gen_loss = 0.3892901693911929, disc_loss = 0.07176258708809895
Trained batch 380 in epoch 7, gen_loss = 0.3894499751135433, disc_loss = 0.0722574000647096
Trained batch 381 in epoch 7, gen_loss = 0.38939605485550394, disc_loss = 0.07217818387163588
Trained batch 382 in epoch 7, gen_loss = 0.38918724706683394, disc_loss = 0.07212794036878024
Trained batch 383 in epoch 7, gen_loss = 0.389148202065068, disc_loss = 0.07216348068050138
Trained batch 384 in epoch 7, gen_loss = 0.38933731615543365, disc_loss = 0.07225206596625654
Trained batch 385 in epoch 7, gen_loss = 0.38909192248175184, disc_loss = 0.07240018242496003
Trained batch 386 in epoch 7, gen_loss = 0.3894350688509855, disc_loss = 0.0722405571867748
Trained batch 387 in epoch 7, gen_loss = 0.3897462852452834, disc_loss = 0.07284592977483738
Trained batch 388 in epoch 7, gen_loss = 0.3896930009739564, disc_loss = 0.07268546705743523
Trained batch 389 in epoch 7, gen_loss = 0.38952043587580704, disc_loss = 0.07264458313793279
Trained batch 390 in epoch 7, gen_loss = 0.3895652323503933, disc_loss = 0.07277719015487806
Trained batch 391 in epoch 7, gen_loss = 0.38965827473724374, disc_loss = 0.07347489291135631
Trained batch 392 in epoch 7, gen_loss = 0.38971653485874486, disc_loss = 0.07332346771527366
Trained batch 393 in epoch 7, gen_loss = 0.38953139126149533, disc_loss = 0.07326947641647587
Trained batch 394 in epoch 7, gen_loss = 0.38946602265291574, disc_loss = 0.07314784568999717
Trained batch 395 in epoch 7, gen_loss = 0.38932942956535505, disc_loss = 0.07306959694269057
Trained batch 396 in epoch 7, gen_loss = 0.3894016481842142, disc_loss = 0.07299599128157154
Trained batch 397 in epoch 7, gen_loss = 0.3894177084067958, disc_loss = 0.07324145488814221
Trained batch 398 in epoch 7, gen_loss = 0.3891184393848692, disc_loss = 0.07372644231543832
Trained batch 399 in epoch 7, gen_loss = 0.3892535408213735, disc_loss = 0.07362266946322052
Trained batch 400 in epoch 7, gen_loss = 0.3893748003422768, disc_loss = 0.07374925468961227
Trained batch 401 in epoch 7, gen_loss = 0.3893521008132702, disc_loss = 0.07366487378021702
Trained batch 402 in epoch 7, gen_loss = 0.38931983809169407, disc_loss = 0.0735695885639365
Trained batch 403 in epoch 7, gen_loss = 0.3893969039441926, disc_loss = 0.07344603215518297
Trained batch 404 in epoch 7, gen_loss = 0.3894731822941038, disc_loss = 0.07334059903392408
Trained batch 405 in epoch 7, gen_loss = 0.38939479554962053, disc_loss = 0.0733062343948906
Trained batch 406 in epoch 7, gen_loss = 0.3893595751951602, disc_loss = 0.07324934954650893
Trained batch 407 in epoch 7, gen_loss = 0.3891189087766643, disc_loss = 0.07310368355298552
Trained batch 408 in epoch 7, gen_loss = 0.38922444579799487, disc_loss = 0.07302009593894646
Trained batch 409 in epoch 7, gen_loss = 0.38935626618018965, disc_loss = 0.0728556200370715
Trained batch 410 in epoch 7, gen_loss = 0.3895273789074589, disc_loss = 0.07276982130282253
Trained batch 411 in epoch 7, gen_loss = 0.38968175385617515, disc_loss = 0.07265371050842748
Trained batch 412 in epoch 7, gen_loss = 0.3896194078370965, disc_loss = 0.0725062334124725
Trained batch 413 in epoch 7, gen_loss = 0.3896767023752853, disc_loss = 0.07259714431866131
Trained batch 414 in epoch 7, gen_loss = 0.3899516756635114, disc_loss = 0.0732572970740744
Trained batch 415 in epoch 7, gen_loss = 0.3898458181020732, disc_loss = 0.0731547749094786
Trained batch 416 in epoch 7, gen_loss = 0.38983180536497697, disc_loss = 0.07332366095979785
Trained batch 417 in epoch 7, gen_loss = 0.3897772479499356, disc_loss = 0.07318050063267555
Trained batch 418 in epoch 7, gen_loss = 0.38968849619561563, disc_loss = 0.07319270618574422
Trained batch 419 in epoch 7, gen_loss = 0.38953749278471583, disc_loss = 0.07339441198051819
Trained batch 420 in epoch 7, gen_loss = 0.3895350309208283, disc_loss = 0.0732918631497244
Trained batch 421 in epoch 7, gen_loss = 0.38952910825963266, disc_loss = 0.07326608313709912
Trained batch 422 in epoch 7, gen_loss = 0.38963996684156693, disc_loss = 0.07317432284825229
Trained batch 423 in epoch 7, gen_loss = 0.3895689760387506, disc_loss = 0.07319521462135149
Trained batch 424 in epoch 7, gen_loss = 0.389804087842212, disc_loss = 0.07362347842221532
Trained batch 425 in epoch 7, gen_loss = 0.38994740589823523, disc_loss = 0.0735395068721955
Trained batch 426 in epoch 7, gen_loss = 0.3899478230110655, disc_loss = 0.07338437765255457
Trained batch 427 in epoch 7, gen_loss = 0.3897712098730502, disc_loss = 0.0733627930692088
Trained batch 428 in epoch 7, gen_loss = 0.38988713586663865, disc_loss = 0.07380273551837539
Trained batch 429 in epoch 7, gen_loss = 0.3900909556552421, disc_loss = 0.07399207442906837
Trained batch 430 in epoch 7, gen_loss = 0.39019007524453847, disc_loss = 0.07384458273566023
Trained batch 431 in epoch 7, gen_loss = 0.3900581259901325, disc_loss = 0.07378536795079492
Trained batch 432 in epoch 7, gen_loss = 0.3902424005038744, disc_loss = 0.07365408502212634
Trained batch 433 in epoch 7, gen_loss = 0.39030675607205534, disc_loss = 0.07356779614097572
Trained batch 434 in epoch 7, gen_loss = 0.3901727580133526, disc_loss = 0.07360177823133639
Trained batch 435 in epoch 7, gen_loss = 0.39016270264983177, disc_loss = 0.07380739259699129
Trained batch 436 in epoch 7, gen_loss = 0.389958691371933, disc_loss = 0.07375669026149552
Trained batch 437 in epoch 7, gen_loss = 0.3900543427154354, disc_loss = 0.07367619089904501
Trained batch 438 in epoch 7, gen_loss = 0.3900878460980222, disc_loss = 0.07364084714454024
Trained batch 439 in epoch 7, gen_loss = 0.390102244541049, disc_loss = 0.07351357902013908
Trained batch 440 in epoch 7, gen_loss = 0.39007458661824396, disc_loss = 0.07336263934360467
Trained batch 441 in epoch 7, gen_loss = 0.39006496268025354, disc_loss = 0.07320674327470791
Trained batch 442 in epoch 7, gen_loss = 0.3901115835856638, disc_loss = 0.0730549728570918
Trained batch 443 in epoch 7, gen_loss = 0.38996105355856653, disc_loss = 0.0729220782399811
Trained batch 444 in epoch 7, gen_loss = 0.38987028481585256, disc_loss = 0.0727716426174104
Trained batch 445 in epoch 7, gen_loss = 0.3899372605264454, disc_loss = 0.0726349772475639
Trained batch 446 in epoch 7, gen_loss = 0.389913012350699, disc_loss = 0.07264863168461336
Trained batch 447 in epoch 7, gen_loss = 0.3900159205908754, disc_loss = 0.0732353404546302
Trained batch 448 in epoch 7, gen_loss = 0.38996545114203923, disc_loss = 0.07315249042974407
Trained batch 449 in epoch 7, gen_loss = 0.38989704022804894, disc_loss = 0.07312792183288062
Trained batch 450 in epoch 7, gen_loss = 0.3900277418003907, disc_loss = 0.07298419342150173
Trained batch 451 in epoch 7, gen_loss = 0.3902107206527638, disc_loss = 0.07284633176214787
Trained batch 452 in epoch 7, gen_loss = 0.39042334350660673, disc_loss = 0.07269795792702602
Trained batch 453 in epoch 7, gen_loss = 0.3903891778005377, disc_loss = 0.07255889828053266
Trained batch 454 in epoch 7, gen_loss = 0.3903642301048551, disc_loss = 0.07242304754243897
Trained batch 455 in epoch 7, gen_loss = 0.3902267395731127, disc_loss = 0.07231656817608031
Trained batch 456 in epoch 7, gen_loss = 0.39019785149744357, disc_loss = 0.07233338831863784
Trained batch 457 in epoch 7, gen_loss = 0.3901830259303859, disc_loss = 0.07219719639384517
Trained batch 458 in epoch 7, gen_loss = 0.39028083385335594, disc_loss = 0.07246010605938741
Trained batch 459 in epoch 7, gen_loss = 0.3901499604725319, disc_loss = 0.07309412858929769
Trained batch 460 in epoch 7, gen_loss = 0.39009531779687473, disc_loss = 0.07320474230289387
Trained batch 461 in epoch 7, gen_loss = 0.3901475506362977, disc_loss = 0.07343609701893473
Trained batch 462 in epoch 7, gen_loss = 0.3899068866190591, disc_loss = 0.07451212058446248
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.28330710530281067, disc_loss = 0.4822314977645874
Trained batch 1 in epoch 8, gen_loss = 0.34058578312397003, disc_loss = 0.3427797853946686
Trained batch 2 in epoch 8, gen_loss = 0.3461412886778514, disc_loss = 0.309034397204717
Trained batch 3 in epoch 8, gen_loss = 0.3461611792445183, disc_loss = 0.2839014455676079
Trained batch 4 in epoch 8, gen_loss = 0.34496704339981077, disc_loss = 0.2625493735074997
Trained batch 5 in epoch 8, gen_loss = 0.3489309400320053, disc_loss = 0.24893195182085037
Trained batch 6 in epoch 8, gen_loss = 0.34548834392002653, disc_loss = 0.2345645555428096
Trained batch 7 in epoch 8, gen_loss = 0.3372298441827297, disc_loss = 0.22029109857976437
Trained batch 8 in epoch 8, gen_loss = 0.3408556282520294, disc_loss = 0.20575040578842163
Trained batch 9 in epoch 8, gen_loss = 0.34116016030311586, disc_loss = 0.20441386550664903
Trained batch 10 in epoch 8, gen_loss = 0.3470885076306083, disc_loss = 0.21984645859761673
Trained batch 11 in epoch 8, gen_loss = 0.3559521958231926, disc_loss = 0.22612996771931648
Trained batch 12 in epoch 8, gen_loss = 0.35555679064530593, disc_loss = 0.21559796998134026
Trained batch 13 in epoch 8, gen_loss = 0.3527475893497467, disc_loss = 0.21108473730938776
Trained batch 14 in epoch 8, gen_loss = 0.35080117781956993, disc_loss = 0.2016804923613866
Trained batch 15 in epoch 8, gen_loss = 0.35117956064641476, disc_loss = 0.19305972941219807
Trained batch 16 in epoch 8, gen_loss = 0.35081861474934745, disc_loss = 0.18677238944698782
Trained batch 17 in epoch 8, gen_loss = 0.35143666962782544, disc_loss = 0.18004276851812998
Trained batch 18 in epoch 8, gen_loss = 0.35597804031874003, disc_loss = 0.17423971703178004
Trained batch 19 in epoch 8, gen_loss = 0.35980868339538574, disc_loss = 0.18290444910526277
Trained batch 20 in epoch 8, gen_loss = 0.36109062745457604, disc_loss = 0.1753771746797221
Trained batch 21 in epoch 8, gen_loss = 0.3615334548733451, disc_loss = 0.16977005909112367
Trained batch 22 in epoch 8, gen_loss = 0.36403320276218915, disc_loss = 0.1635122373700142
Trained batch 23 in epoch 8, gen_loss = 0.3650088831782341, disc_loss = 0.15873763834436735
Trained batch 24 in epoch 8, gen_loss = 0.3651652371883392, disc_loss = 0.15377619206905366
Trained batch 25 in epoch 8, gen_loss = 0.36683538326850307, disc_loss = 0.14960386833319297
Trained batch 26 in epoch 8, gen_loss = 0.3684018784099155, disc_loss = 0.14642413705587387
Trained batch 27 in epoch 8, gen_loss = 0.36859951806919916, disc_loss = 0.14460343734494277
Trained batch 28 in epoch 8, gen_loss = 0.36793633987163676, disc_loss = 0.14227441004638014
Trained batch 29 in epoch 8, gen_loss = 0.37097078959147134, disc_loss = 0.14077829495072364
Trained batch 30 in epoch 8, gen_loss = 0.3704518771940662, disc_loss = 0.13709265366196632
Trained batch 31 in epoch 8, gen_loss = 0.36799744609743357, disc_loss = 0.13782846077810973
Trained batch 32 in epoch 8, gen_loss = 0.36866085998939746, disc_loss = 0.13770530022906535
Trained batch 33 in epoch 8, gen_loss = 0.36992408159901113, disc_loss = 0.13404972470529816
Trained batch 34 in epoch 8, gen_loss = 0.3708130087171282, disc_loss = 0.130577873225723
Trained batch 35 in epoch 8, gen_loss = 0.37072932223478955, disc_loss = 0.12950084348105723
Trained batch 36 in epoch 8, gen_loss = 0.37076851322844223, disc_loss = 0.12790149661737518
Trained batch 37 in epoch 8, gen_loss = 0.3713018000125885, disc_loss = 0.12501828784221097
Trained batch 38 in epoch 8, gen_loss = 0.3728833748744084, disc_loss = 0.1244465022897109
Trained batch 39 in epoch 8, gen_loss = 0.37254267558455467, disc_loss = 0.12999470997601748
Trained batch 40 in epoch 8, gen_loss = 0.37374542253773385, disc_loss = 0.12791007066645274
Trained batch 41 in epoch 8, gen_loss = 0.3760415627842858, disc_loss = 0.12638834526851064
Trained batch 42 in epoch 8, gen_loss = 0.37708685079286264, disc_loss = 0.12450778865536978
Trained batch 43 in epoch 8, gen_loss = 0.37651238455013797, disc_loss = 0.12236619647592306
Trained batch 44 in epoch 8, gen_loss = 0.37621166970994735, disc_loss = 0.12008453450269169
Trained batch 45 in epoch 8, gen_loss = 0.3787115112594936, disc_loss = 0.11836904619375001
Trained batch 46 in epoch 8, gen_loss = 0.3777714542886044, disc_loss = 0.11715870437786934
Trained batch 47 in epoch 8, gen_loss = 0.3793984080354373, disc_loss = 0.11634072669160862
Trained batch 48 in epoch 8, gen_loss = 0.3789886728841431, disc_loss = 0.11421668052445261
Trained batch 49 in epoch 8, gen_loss = 0.37860352456569674, disc_loss = 0.11280214751139284
Trained batch 50 in epoch 8, gen_loss = 0.3796207916502859, disc_loss = 0.11068117271597479
Trained batch 51 in epoch 8, gen_loss = 0.3799282478598448, disc_loss = 0.10867050694874845
Trained batch 52 in epoch 8, gen_loss = 0.3794051133236795, disc_loss = 0.10696624616547576
Trained batch 53 in epoch 8, gen_loss = 0.3793200856005704, disc_loss = 0.10708698592390176
Trained batch 54 in epoch 8, gen_loss = 0.37857844775373284, disc_loss = 0.11194413158703934
Trained batch 55 in epoch 8, gen_loss = 0.377904763179166, disc_loss = 0.11130585338521216
Trained batch 56 in epoch 8, gen_loss = 0.3799808694605242, disc_loss = 0.11042877538293078
Trained batch 57 in epoch 8, gen_loss = 0.38021181164116696, disc_loss = 0.1090670582870471
Trained batch 58 in epoch 8, gen_loss = 0.3814290170952425, disc_loss = 0.10752087329530109
Trained batch 59 in epoch 8, gen_loss = 0.3821717689434687, disc_loss = 0.10668765297159552
Trained batch 60 in epoch 8, gen_loss = 0.3833919411799947, disc_loss = 0.1102554508958195
Trained batch 61 in epoch 8, gen_loss = 0.3834831416606903, disc_loss = 0.10874796974202318
Trained batch 62 in epoch 8, gen_loss = 0.3845272920434437, disc_loss = 0.10844719885951942
Trained batch 63 in epoch 8, gen_loss = 0.3841038844548166, disc_loss = 0.10721835744334385
Trained batch 64 in epoch 8, gen_loss = 0.3841097098130446, disc_loss = 0.10585791643422383
Trained batch 65 in epoch 8, gen_loss = 0.38426387942198553, disc_loss = 0.10464425644639766
Trained batch 66 in epoch 8, gen_loss = 0.3851473429309788, disc_loss = 0.10356857394104574
Trained batch 67 in epoch 8, gen_loss = 0.38485979332643394, disc_loss = 0.1021027084754999
Trained batch 68 in epoch 8, gen_loss = 0.38604135530582373, disc_loss = 0.10119219801213214
Trained batch 69 in epoch 8, gen_loss = 0.38568940375532423, disc_loss = 0.1008583248393344
Trained batch 70 in epoch 8, gen_loss = 0.38640321602284067, disc_loss = 0.09967997417667172
Trained batch 71 in epoch 8, gen_loss = 0.38697834437092143, disc_loss = 0.09851001164901795
Trained batch 72 in epoch 8, gen_loss = 0.388460200535108, disc_loss = 0.0986074518782329
Trained batch 73 in epoch 8, gen_loss = 0.3879584074020386, disc_loss = 0.10284250444178847
Trained batch 74 in epoch 8, gen_loss = 0.387550884882609, disc_loss = 0.10310346676036715
Trained batch 75 in epoch 8, gen_loss = 0.3889711436472441, disc_loss = 0.10483533019616612
Trained batch 76 in epoch 8, gen_loss = 0.3893956209157968, disc_loss = 0.10407339242686119
Trained batch 77 in epoch 8, gen_loss = 0.38943698429144347, disc_loss = 0.10348560181685174
Trained batch 78 in epoch 8, gen_loss = 0.38918191081360926, disc_loss = 0.10241876139977499
Trained batch 79 in epoch 8, gen_loss = 0.3890104331076145, disc_loss = 0.10257447094772942
Trained batch 80 in epoch 8, gen_loss = 0.3871713142704081, disc_loss = 0.10289805734898021
Trained batch 81 in epoch 8, gen_loss = 0.38709708848377555, disc_loss = 0.1019165785812841
Trained batch 82 in epoch 8, gen_loss = 0.38770874526845406, disc_loss = 0.10189823582431817
Trained batch 83 in epoch 8, gen_loss = 0.3870666954843771, disc_loss = 0.1045028774034498
Trained batch 84 in epoch 8, gen_loss = 0.38749979401336, disc_loss = 0.1040109963156283
Trained batch 85 in epoch 8, gen_loss = 0.38734328348276226, disc_loss = 0.10338400746695697
Trained batch 86 in epoch 8, gen_loss = 0.38712640517744523, disc_loss = 0.10311426685309444
Trained batch 87 in epoch 8, gen_loss = 0.3874024584550749, disc_loss = 0.1023743117958392
Trained batch 88 in epoch 8, gen_loss = 0.38847999710045505, disc_loss = 0.10197011817225747
Trained batch 89 in epoch 8, gen_loss = 0.3874687815705935, disc_loss = 0.10307229451524715
Trained batch 90 in epoch 8, gen_loss = 0.38740708850897276, disc_loss = 0.104266673577233
Trained batch 91 in epoch 8, gen_loss = 0.38686657518796297, disc_loss = 0.10345662059768548
Trained batch 92 in epoch 8, gen_loss = 0.3868482223441524, disc_loss = 0.10348830266445073
Trained batch 93 in epoch 8, gen_loss = 0.3866021618881124, disc_loss = 0.10267253000626063
Trained batch 94 in epoch 8, gen_loss = 0.3870483967818712, disc_loss = 0.10208817734628131
Trained batch 95 in epoch 8, gen_loss = 0.387794095557183, disc_loss = 0.10134585497144144
Trained batch 96 in epoch 8, gen_loss = 0.3878443224221161, disc_loss = 0.10113040742358749
Trained batch 97 in epoch 8, gen_loss = 0.3879469202793374, disc_loss = 0.10103046651264387
Trained batch 98 in epoch 8, gen_loss = 0.38722776177555623, disc_loss = 0.10015716263083647
Trained batch 99 in epoch 8, gen_loss = 0.3876853467524052, disc_loss = 0.09926544744055718
Trained batch 100 in epoch 8, gen_loss = 0.38745246886616885, disc_loss = 0.09853740930465041
Trained batch 101 in epoch 8, gen_loss = 0.38739265516108157, disc_loss = 0.09827733669411756
Trained batch 102 in epoch 8, gen_loss = 0.3878014407400946, disc_loss = 0.09741072264020738
Trained batch 103 in epoch 8, gen_loss = 0.3871722443459126, disc_loss = 0.09783179565028359
Trained batch 104 in epoch 8, gen_loss = 0.387164080001059, disc_loss = 0.09948659646990043
Trained batch 105 in epoch 8, gen_loss = 0.38758738324889597, disc_loss = 0.09859805920530322
Trained batch 106 in epoch 8, gen_loss = 0.3872017349316695, disc_loss = 0.09792029950767756
Trained batch 107 in epoch 8, gen_loss = 0.3871646651791202, disc_loss = 0.09722823260731443
Trained batch 108 in epoch 8, gen_loss = 0.38752335843143115, disc_loss = 0.09644020064263989
Trained batch 109 in epoch 8, gen_loss = 0.38822643228552556, disc_loss = 0.09613121743737296
Trained batch 110 in epoch 8, gen_loss = 0.38789353029684975, disc_loss = 0.09609498951986835
Trained batch 111 in epoch 8, gen_loss = 0.3876579107184495, disc_loss = 0.09533285011171497
Trained batch 112 in epoch 8, gen_loss = 0.3880401608427014, disc_loss = 0.09491672878672855
Trained batch 113 in epoch 8, gen_loss = 0.38778156525733176, disc_loss = 0.09463633587910679
Trained batch 114 in epoch 8, gen_loss = 0.38820569165374924, disc_loss = 0.09445432253667842
Trained batch 115 in epoch 8, gen_loss = 0.3875143950612381, disc_loss = 0.09393036568633698
Trained batch 116 in epoch 8, gen_loss = 0.3877535822809252, disc_loss = 0.09364932668037139
Trained batch 117 in epoch 8, gen_loss = 0.38794983430939206, disc_loss = 0.09330233701867825
Trained batch 118 in epoch 8, gen_loss = 0.3884435705527538, disc_loss = 0.09296142144770432
Trained batch 119 in epoch 8, gen_loss = 0.3885358838985364, disc_loss = 0.09232976941857488
Trained batch 120 in epoch 8, gen_loss = 0.38768993638271143, disc_loss = 0.09279784297739918
Trained batch 121 in epoch 8, gen_loss = 0.38884151238398473, disc_loss = 0.0929630924794884
Trained batch 122 in epoch 8, gen_loss = 0.3889318516826242, disc_loss = 0.0922764385103937
Trained batch 123 in epoch 8, gen_loss = 0.38913595592302663, disc_loss = 0.09221456823269686
Trained batch 124 in epoch 8, gen_loss = 0.38954017937183383, disc_loss = 0.09220174233615398
Trained batch 125 in epoch 8, gen_loss = 0.389134072949962, disc_loss = 0.0915513970327401
Trained batch 126 in epoch 8, gen_loss = 0.388319199596803, disc_loss = 0.09168654590053117
Trained batch 127 in epoch 8, gen_loss = 0.3883865891257301, disc_loss = 0.0919279956506216
Trained batch 128 in epoch 8, gen_loss = 0.3885157483723737, disc_loss = 0.09132304711830477
Trained batch 129 in epoch 8, gen_loss = 0.38831534144970087, disc_loss = 0.09292672155424953
Trained batch 130 in epoch 8, gen_loss = 0.3885307663497124, disc_loss = 0.09263100826984826
Trained batch 131 in epoch 8, gen_loss = 0.38895491973468754, disc_loss = 0.09281011574167872
Trained batch 132 in epoch 8, gen_loss = 0.38833026879264, disc_loss = 0.09282267255414474
Trained batch 133 in epoch 8, gen_loss = 0.3881342676815702, disc_loss = 0.09261333936158178
Trained batch 134 in epoch 8, gen_loss = 0.38793178145532253, disc_loss = 0.09229284068914476
Trained batch 135 in epoch 8, gen_loss = 0.38835603754748316, disc_loss = 0.09195130843641784
Trained batch 136 in epoch 8, gen_loss = 0.38852648284748525, disc_loss = 0.09131213374449497
Trained batch 137 in epoch 8, gen_loss = 0.3885870285440182, disc_loss = 0.09096038869609112
Trained batch 138 in epoch 8, gen_loss = 0.3884198490878661, disc_loss = 0.09035292181702291
Trained batch 139 in epoch 8, gen_loss = 0.3885124731276717, disc_loss = 0.08982361355197749
Trained batch 140 in epoch 8, gen_loss = 0.3885294088023774, disc_loss = 0.08922838661423389
Trained batch 141 in epoch 8, gen_loss = 0.3885537294644705, disc_loss = 0.0887753527191743
Trained batch 142 in epoch 8, gen_loss = 0.38886856042838597, disc_loss = 0.08845616038237418
Trained batch 143 in epoch 8, gen_loss = 0.3893215742169155, disc_loss = 0.08941053593945172
Trained batch 144 in epoch 8, gen_loss = 0.3889046957780575, disc_loss = 0.08957805726034888
Trained batch 145 in epoch 8, gen_loss = 0.3889025391577041, disc_loss = 0.08918882513495341
Trained batch 146 in epoch 8, gen_loss = 0.3885305196452303, disc_loss = 0.08914065832386212
Trained batch 147 in epoch 8, gen_loss = 0.3879808589211992, disc_loss = 0.09101696740332488
Trained batch 148 in epoch 8, gen_loss = 0.38799993193789617, disc_loss = 0.09123716843408226
Trained batch 149 in epoch 8, gen_loss = 0.38755566110213596, disc_loss = 0.09163687591751417
Trained batch 150 in epoch 8, gen_loss = 0.3868947709040926, disc_loss = 0.09197751205685913
Trained batch 151 in epoch 8, gen_loss = 0.387032985393154, disc_loss = 0.09186835484089036
Trained batch 152 in epoch 8, gen_loss = 0.38677792699118846, disc_loss = 0.09236339226462482
Trained batch 153 in epoch 8, gen_loss = 0.386879064142704, disc_loss = 0.09212924931924064
Trained batch 154 in epoch 8, gen_loss = 0.386759774242678, disc_loss = 0.09157722080426832
Trained batch 155 in epoch 8, gen_loss = 0.38758980511472774, disc_loss = 0.0913476575500308
Trained batch 156 in epoch 8, gen_loss = 0.38691921437242227, disc_loss = 0.09243386739473435
Trained batch 157 in epoch 8, gen_loss = 0.38688004724209824, disc_loss = 0.09223736072831516
Trained batch 158 in epoch 8, gen_loss = 0.3867545484934213, disc_loss = 0.09173030568485928
Trained batch 159 in epoch 8, gen_loss = 0.3868833460845053, disc_loss = 0.09120717682526447
Trained batch 160 in epoch 8, gen_loss = 0.3863637535283284, disc_loss = 0.09069540984465839
Trained batch 161 in epoch 8, gen_loss = 0.386641461448169, disc_loss = 0.09036899982365193
Trained batch 162 in epoch 8, gen_loss = 0.3864026450854869, disc_loss = 0.09017138248252357
Trained batch 163 in epoch 8, gen_loss = 0.3861366287782425, disc_loss = 0.09004254499450326
Trained batch 164 in epoch 8, gen_loss = 0.38668815755482877, disc_loss = 0.0899737328403827
Trained batch 165 in epoch 8, gen_loss = 0.38634458139359235, disc_loss = 0.08987430394458842
Trained batch 166 in epoch 8, gen_loss = 0.3869217178243363, disc_loss = 0.09009016034176606
Trained batch 167 in epoch 8, gen_loss = 0.3872590363912639, disc_loss = 0.08966147682319085
Trained batch 168 in epoch 8, gen_loss = 0.3873846316655007, disc_loss = 0.08926547232728738
Trained batch 169 in epoch 8, gen_loss = 0.3872142198331216, disc_loss = 0.08897023816757342
Trained batch 170 in epoch 8, gen_loss = 0.38757355894610196, disc_loss = 0.08875760760659362
Trained batch 171 in epoch 8, gen_loss = 0.38740404634628184, disc_loss = 0.08912417078174131
Trained batch 172 in epoch 8, gen_loss = 0.3879024475123841, disc_loss = 0.08953866244137632
Trained batch 173 in epoch 8, gen_loss = 0.38805081267123936, disc_loss = 0.08909044017073238
Trained batch 174 in epoch 8, gen_loss = 0.38798047091279714, disc_loss = 0.08888132928205388
Trained batch 175 in epoch 8, gen_loss = 0.3882879519157789, disc_loss = 0.08857459101339125
Trained batch 176 in epoch 8, gen_loss = 0.38905809819698334, disc_loss = 0.08980048612538873
Trained batch 177 in epoch 8, gen_loss = 0.3888259907619337, disc_loss = 0.08939853133215162
Trained batch 178 in epoch 8, gen_loss = 0.38825067120224405, disc_loss = 0.08917782333414148
Trained batch 179 in epoch 8, gen_loss = 0.3884389946030246, disc_loss = 0.08887852523993287
Trained batch 180 in epoch 8, gen_loss = 0.3885271347524053, disc_loss = 0.08885452586087239
Trained batch 181 in epoch 8, gen_loss = 0.38890621139780507, disc_loss = 0.08878553104535727
Trained batch 182 in epoch 8, gen_loss = 0.389142305554588, disc_loss = 0.08834095205093831
Trained batch 183 in epoch 8, gen_loss = 0.38872530335641425, disc_loss = 0.08795873188595894
Trained batch 184 in epoch 8, gen_loss = 0.3889066421502345, disc_loss = 0.08757072098653865
Trained batch 185 in epoch 8, gen_loss = 0.38875255845887685, disc_loss = 0.08724051817590671
Trained batch 186 in epoch 8, gen_loss = 0.3890217608787159, disc_loss = 0.08699817773711713
Trained batch 187 in epoch 8, gen_loss = 0.38913580260061204, disc_loss = 0.08788188500825236
Trained batch 188 in epoch 8, gen_loss = 0.3885426605662341, disc_loss = 0.08931100653809687
Trained batch 189 in epoch 8, gen_loss = 0.3881726264169342, disc_loss = 0.08914020788414698
Trained batch 190 in epoch 8, gen_loss = 0.38875319126076724, disc_loss = 0.08883747598400135
Trained batch 191 in epoch 8, gen_loss = 0.38869707526949543, disc_loss = 0.08855447942914907
Trained batch 192 in epoch 8, gen_loss = 0.38929025211173635, disc_loss = 0.08824255428918748
Trained batch 193 in epoch 8, gen_loss = 0.3896698566902544, disc_loss = 0.08790915568368797
Trained batch 194 in epoch 8, gen_loss = 0.38961119384337695, disc_loss = 0.08789878802326245
Trained batch 195 in epoch 8, gen_loss = 0.38982662368489773, disc_loss = 0.08927774940123212
Trained batch 196 in epoch 8, gen_loss = 0.3896927236754277, disc_loss = 0.08921317731120108
Trained batch 197 in epoch 8, gen_loss = 0.38965709575197915, disc_loss = 0.08884728587505342
Trained batch 198 in epoch 8, gen_loss = 0.38989599767941324, disc_loss = 0.0885232356727947
Trained batch 199 in epoch 8, gen_loss = 0.3899382067471743, disc_loss = 0.08828938848804682
Trained batch 200 in epoch 8, gen_loss = 0.38991118997187163, disc_loss = 0.0880424497018925
Trained batch 201 in epoch 8, gen_loss = 0.38967962599921935, disc_loss = 0.08765006340154917
Trained batch 202 in epoch 8, gen_loss = 0.3898260824639222, disc_loss = 0.08738129406139769
Trained batch 203 in epoch 8, gen_loss = 0.390296996443295, disc_loss = 0.08780061658106598
Trained batch 204 in epoch 8, gen_loss = 0.3901079603084704, disc_loss = 0.08770015497760075
Trained batch 205 in epoch 8, gen_loss = 0.3902310065708114, disc_loss = 0.08730899158738625
Trained batch 206 in epoch 8, gen_loss = 0.3902281902118582, disc_loss = 0.0869386885540137
Trained batch 207 in epoch 8, gen_loss = 0.39025075253672326, disc_loss = 0.08655804992304184
Trained batch 208 in epoch 8, gen_loss = 0.3901237282884178, disc_loss = 0.08618717493810223
Trained batch 209 in epoch 8, gen_loss = 0.39008220867032095, disc_loss = 0.08582923700811253
Trained batch 210 in epoch 8, gen_loss = 0.3896990269422531, disc_loss = 0.0854414710620533
Trained batch 211 in epoch 8, gen_loss = 0.38970630173132104, disc_loss = 0.0851143600731069
Trained batch 212 in epoch 8, gen_loss = 0.38997470150251345, disc_loss = 0.08477605722556023
Trained batch 213 in epoch 8, gen_loss = 0.3898049305393317, disc_loss = 0.08442527973354211
Trained batch 214 in epoch 8, gen_loss = 0.389794534929963, disc_loss = 0.08411728140443217
Trained batch 215 in epoch 8, gen_loss = 0.3899263824439711, disc_loss = 0.08379807074217954
Trained batch 216 in epoch 8, gen_loss = 0.38999765843565015, disc_loss = 0.08344514158120903
Trained batch 217 in epoch 8, gen_loss = 0.38985802527141133, disc_loss = 0.08314089563359088
Trained batch 218 in epoch 8, gen_loss = 0.3895198891288069, disc_loss = 0.08284822091051977
Trained batch 219 in epoch 8, gen_loss = 0.3894188896498897, disc_loss = 0.08251348190348257
Trained batch 220 in epoch 8, gen_loss = 0.38950268088153045, disc_loss = 0.08222049175513006
Trained batch 221 in epoch 8, gen_loss = 0.38972499731693183, disc_loss = 0.08189206066549765
Trained batch 222 in epoch 8, gen_loss = 0.3894909750586668, disc_loss = 0.08157706432328497
Trained batch 223 in epoch 8, gen_loss = 0.38979380650978, disc_loss = 0.08124975880075778
Trained batch 224 in epoch 8, gen_loss = 0.3895919528934691, disc_loss = 0.08117358257373174
Trained batch 225 in epoch 8, gen_loss = 0.3896398998599137, disc_loss = 0.0810628082372446
Trained batch 226 in epoch 8, gen_loss = 0.3897863959294584, disc_loss = 0.08075041299694041
Trained batch 227 in epoch 8, gen_loss = 0.3898934453333679, disc_loss = 0.0804236725895878
Trained batch 228 in epoch 8, gen_loss = 0.3900340042650439, disc_loss = 0.08009855725342921
Trained batch 229 in epoch 8, gen_loss = 0.3900319426603939, disc_loss = 0.0799515249086139
Trained batch 230 in epoch 8, gen_loss = 0.3897551947728896, disc_loss = 0.07979526423579042
Trained batch 231 in epoch 8, gen_loss = 0.3898714351114528, disc_loss = 0.07948202812835446
Trained batch 232 in epoch 8, gen_loss = 0.3900511490556815, disc_loss = 0.08001850800820558
Trained batch 233 in epoch 8, gen_loss = 0.38982671938645536, disc_loss = 0.08204970623040174
Trained batch 234 in epoch 8, gen_loss = 0.3896803104497017, disc_loss = 0.08262990807836994
Trained batch 235 in epoch 8, gen_loss = 0.38982455501869573, disc_loss = 0.08283761389537762
Trained batch 236 in epoch 8, gen_loss = 0.3900103384809655, disc_loss = 0.0830381022813388
Trained batch 237 in epoch 8, gen_loss = 0.39004108591490433, disc_loss = 0.08317592432878974
Trained batch 238 in epoch 8, gen_loss = 0.3899371925133542, disc_loss = 0.0831679633183397
Trained batch 239 in epoch 8, gen_loss = 0.39000186293075484, disc_loss = 0.08303130905066307
Trained batch 240 in epoch 8, gen_loss = 0.3899581714908117, disc_loss = 0.08285218019316676
Trained batch 241 in epoch 8, gen_loss = 0.38981140343364606, disc_loss = 0.08291967554510501
Trained batch 242 in epoch 8, gen_loss = 0.3893106003970276, disc_loss = 0.08408285925402441
Trained batch 243 in epoch 8, gen_loss = 0.38959991547172185, disc_loss = 0.08404508397578582
Trained batch 244 in epoch 8, gen_loss = 0.3895865209856812, disc_loss = 0.08393625227392328
Trained batch 245 in epoch 8, gen_loss = 0.38942829180296845, disc_loss = 0.08425264611340515
Trained batch 246 in epoch 8, gen_loss = 0.38961895534142793, disc_loss = 0.08472040271092403
Trained batch 247 in epoch 8, gen_loss = 0.3897397471892257, disc_loss = 0.08441880868462424
Trained batch 248 in epoch 8, gen_loss = 0.3896721594903364, disc_loss = 0.08440906695467999
Trained batch 249 in epoch 8, gen_loss = 0.38979217380285264, disc_loss = 0.08410033928230405
Trained batch 250 in epoch 8, gen_loss = 0.3900247460223764, disc_loss = 0.08397462559247991
Trained batch 251 in epoch 8, gen_loss = 0.38987053499098806, disc_loss = 0.08394770352687272
Trained batch 252 in epoch 8, gen_loss = 0.3902482481695447, disc_loss = 0.08414182707799871
Trained batch 253 in epoch 8, gen_loss = 0.3898107094440873, disc_loss = 0.08413528227503961
Trained batch 254 in epoch 8, gen_loss = 0.3901248403039633, disc_loss = 0.08385591125298364
Trained batch 255 in epoch 8, gen_loss = 0.39035235304618254, disc_loss = 0.08372363455055165
Trained batch 256 in epoch 8, gen_loss = 0.3901771131308626, disc_loss = 0.08357039000838995
Trained batch 257 in epoch 8, gen_loss = 0.3901261308974074, disc_loss = 0.08329197585712685
Trained batch 258 in epoch 8, gen_loss = 0.3902544543204621, disc_loss = 0.08304117827471273
Trained batch 259 in epoch 8, gen_loss = 0.39023246438457415, disc_loss = 0.08275365790065664
Trained batch 260 in epoch 8, gen_loss = 0.38990661450501146, disc_loss = 0.08276726711555688
Trained batch 261 in epoch 8, gen_loss = 0.39020982435868895, disc_loss = 0.08279513744708464
Trained batch 262 in epoch 8, gen_loss = 0.3899932405681211, disc_loss = 0.08252450205144887
Trained batch 263 in epoch 8, gen_loss = 0.38993250561708753, disc_loss = 0.08373273631459045
Trained batch 264 in epoch 8, gen_loss = 0.3900786692803761, disc_loss = 0.08425319851639698
Trained batch 265 in epoch 8, gen_loss = 0.3902913379601966, disc_loss = 0.08399251851960457
Trained batch 266 in epoch 8, gen_loss = 0.3901603197895186, disc_loss = 0.08372206639930997
Trained batch 267 in epoch 8, gen_loss = 0.39013158101866496, disc_loss = 0.08360931152172053
Trained batch 268 in epoch 8, gen_loss = 0.38993058810668363, disc_loss = 0.08340389517631008
Trained batch 269 in epoch 8, gen_loss = 0.3900376087537518, disc_loss = 0.08342467530596036
Trained batch 270 in epoch 8, gen_loss = 0.38955292045190326, disc_loss = 0.08409979021884638
Trained batch 271 in epoch 8, gen_loss = 0.3894740594550967, disc_loss = 0.08410405716174008
Trained batch 272 in epoch 8, gen_loss = 0.38947327522349445, disc_loss = 0.08414683944712846
Trained batch 273 in epoch 8, gen_loss = 0.3893039902522616, disc_loss = 0.08406538773926288
Trained batch 274 in epoch 8, gen_loss = 0.38919323124668814, disc_loss = 0.08384287689897148
Trained batch 275 in epoch 8, gen_loss = 0.38936916420209233, disc_loss = 0.08380175934618582
Trained batch 276 in epoch 8, gen_loss = 0.38917850312988683, disc_loss = 0.08403258258981179
Trained batch 277 in epoch 8, gen_loss = 0.38928451453395885, disc_loss = 0.08452851273682263
Trained batch 278 in epoch 8, gen_loss = 0.3892835874818132, disc_loss = 0.08436964356797784
Trained batch 279 in epoch 8, gen_loss = 0.3893627815480743, disc_loss = 0.0844870871531644
Trained batch 280 in epoch 8, gen_loss = 0.3896117498335889, disc_loss = 0.08504676180510547
Trained batch 281 in epoch 8, gen_loss = 0.3896597484853251, disc_loss = 0.08476356300525367
Trained batch 282 in epoch 8, gen_loss = 0.38934282621520144, disc_loss = 0.08489716255563466
Trained batch 283 in epoch 8, gen_loss = 0.38944719180884496, disc_loss = 0.08492278648560053
Trained batch 284 in epoch 8, gen_loss = 0.38922207078389953, disc_loss = 0.0847692339550377
Trained batch 285 in epoch 8, gen_loss = 0.388998810592648, disc_loss = 0.08499743648596317
Trained batch 286 in epoch 8, gen_loss = 0.3893042674567226, disc_loss = 0.08484392806413853
Trained batch 287 in epoch 8, gen_loss = 0.38932936219498515, disc_loss = 0.08463788363506966
Trained batch 288 in epoch 8, gen_loss = 0.3892961937972831, disc_loss = 0.08460147366746229
Trained batch 289 in epoch 8, gen_loss = 0.38933752996140514, disc_loss = 0.08479577541704579
Trained batch 290 in epoch 8, gen_loss = 0.3894263400961853, disc_loss = 0.08454372707107888
Trained batch 291 in epoch 8, gen_loss = 0.3892188610585585, disc_loss = 0.0845241874395806
Trained batch 292 in epoch 8, gen_loss = 0.3893238519137223, disc_loss = 0.08428229831648615
Trained batch 293 in epoch 8, gen_loss = 0.3892927064883466, disc_loss = 0.08442146597322406
Trained batch 294 in epoch 8, gen_loss = 0.38907944878279155, disc_loss = 0.08443618414418425
Trained batch 295 in epoch 8, gen_loss = 0.38907537332459075, disc_loss = 0.08418617348620869
Trained batch 296 in epoch 8, gen_loss = 0.3890114547528, disc_loss = 0.08396291281394536
Trained batch 297 in epoch 8, gen_loss = 0.38909959718084974, disc_loss = 0.08378141894842804
Trained batch 298 in epoch 8, gen_loss = 0.38936468455504414, disc_loss = 0.08356350071161338
Trained batch 299 in epoch 8, gen_loss = 0.38945228601495424, disc_loss = 0.08331619289548446
Trained batch 300 in epoch 8, gen_loss = 0.3894367022470778, disc_loss = 0.08311543589693021
Trained batch 301 in epoch 8, gen_loss = 0.3892912152685866, disc_loss = 0.0831674108519188
Trained batch 302 in epoch 8, gen_loss = 0.38942614222320393, disc_loss = 0.08420240397875507
Trained batch 303 in epoch 8, gen_loss = 0.3894922301467312, disc_loss = 0.08418591468331502
Trained batch 304 in epoch 8, gen_loss = 0.38919695044150115, disc_loss = 0.0843929639681563
Trained batch 305 in epoch 8, gen_loss = 0.38926372151164446, disc_loss = 0.08419409745031955
Trained batch 306 in epoch 8, gen_loss = 0.38936353433598136, disc_loss = 0.08403826230857825
Trained batch 307 in epoch 8, gen_loss = 0.38931222893781475, disc_loss = 0.08382310422723992
Trained batch 308 in epoch 8, gen_loss = 0.3893630928495555, disc_loss = 0.08385116729469409
Trained batch 309 in epoch 8, gen_loss = 0.38947565569992987, disc_loss = 0.08363612126709233
Trained batch 310 in epoch 8, gen_loss = 0.3896417282881077, disc_loss = 0.08387570884048795
Trained batch 311 in epoch 8, gen_loss = 0.38957928565259164, disc_loss = 0.08452147112424988
Trained batch 312 in epoch 8, gen_loss = 0.3896711459651161, disc_loss = 0.08431218036810478
Trained batch 313 in epoch 8, gen_loss = 0.3896590682446577, disc_loss = 0.08430710779710608
Trained batch 314 in epoch 8, gen_loss = 0.38964205587667133, disc_loss = 0.08451940671112093
Trained batch 315 in epoch 8, gen_loss = 0.39002921616163433, disc_loss = 0.0845166721419561
Trained batch 316 in epoch 8, gen_loss = 0.38999019760626724, disc_loss = 0.0842809357374836
Trained batch 317 in epoch 8, gen_loss = 0.3896032501035516, disc_loss = 0.08448932257937794
Trained batch 318 in epoch 8, gen_loss = 0.38986318046956975, disc_loss = 0.08548563923307206
Trained batch 319 in epoch 8, gen_loss = 0.3898193386849016, disc_loss = 0.08563366815360496
Trained batch 320 in epoch 8, gen_loss = 0.38932973090733325, disc_loss = 0.08702386840394585
Trained batch 321 in epoch 8, gen_loss = 0.3892254957130977, disc_loss = 0.08706725767223593
Trained batch 322 in epoch 8, gen_loss = 0.38913664692326594, disc_loss = 0.08783180669278783
Trained batch 323 in epoch 8, gen_loss = 0.3889324347730036, disc_loss = 0.0880600134798981
Trained batch 324 in epoch 8, gen_loss = 0.38895347943672764, disc_loss = 0.08824814291097798
Trained batch 325 in epoch 8, gen_loss = 0.38865232440225916, disc_loss = 0.08846382745484496
Trained batch 326 in epoch 8, gen_loss = 0.3886021711046178, disc_loss = 0.08846868459699214
Trained batch 327 in epoch 8, gen_loss = 0.3885979381639783, disc_loss = 0.08844141617968179
Trained batch 328 in epoch 8, gen_loss = 0.38861562406763117, disc_loss = 0.08843231259061074
Trained batch 329 in epoch 8, gen_loss = 0.38864611504655894, disc_loss = 0.08824904662782722
Trained batch 330 in epoch 8, gen_loss = 0.38864802873026566, disc_loss = 0.08824305322015619
Trained batch 331 in epoch 8, gen_loss = 0.38851716818220644, disc_loss = 0.08829499316732792
Trained batch 332 in epoch 8, gen_loss = 0.3885573016272651, disc_loss = 0.08820353587250318
Trained batch 333 in epoch 8, gen_loss = 0.3884306235049299, disc_loss = 0.08807868095711543
Trained batch 334 in epoch 8, gen_loss = 0.3886413217480503, disc_loss = 0.0881179717508381
Trained batch 335 in epoch 8, gen_loss = 0.3884591692615123, disc_loss = 0.08788411267561883
Trained batch 336 in epoch 8, gen_loss = 0.38815648902417643, disc_loss = 0.0876609323510364
Trained batch 337 in epoch 8, gen_loss = 0.3879758851415307, disc_loss = 0.08775920347729423
Trained batch 338 in epoch 8, gen_loss = 0.3881750775825309, disc_loss = 0.08754600858821322
Trained batch 339 in epoch 8, gen_loss = 0.3882917047423475, disc_loss = 0.08755732311949353
Trained batch 340 in epoch 8, gen_loss = 0.3885112070967375, disc_loss = 0.0873496310028884
Trained batch 341 in epoch 8, gen_loss = 0.38828636226598284, disc_loss = 0.0878015815876751
Trained batch 342 in epoch 8, gen_loss = 0.3885476477118345, disc_loss = 0.08887252472368212
Trained batch 343 in epoch 8, gen_loss = 0.38849916716301164, disc_loss = 0.08945381667513704
Trained batch 344 in epoch 8, gen_loss = 0.38840420764425526, disc_loss = 0.08949067791437973
Trained batch 345 in epoch 8, gen_loss = 0.38834008419444793, disc_loss = 0.08960384341640495
Trained batch 346 in epoch 8, gen_loss = 0.388215450800805, disc_loss = 0.08952970633293993
Trained batch 347 in epoch 8, gen_loss = 0.38831292281205626, disc_loss = 0.08959072492294141
Trained batch 348 in epoch 8, gen_loss = 0.3880134521207017, disc_loss = 0.08975874496100839
Trained batch 349 in epoch 8, gen_loss = 0.38804374711854117, disc_loss = 0.0897189886668431
Trained batch 350 in epoch 8, gen_loss = 0.38800295941170804, disc_loss = 0.08987837902633765
Trained batch 351 in epoch 8, gen_loss = 0.38764277464625513, disc_loss = 0.0903268285024255
Trained batch 352 in epoch 8, gen_loss = 0.3876705425488037, disc_loss = 0.09015559722872572
Trained batch 353 in epoch 8, gen_loss = 0.3877207350596196, disc_loss = 0.09005329366589207
Trained batch 354 in epoch 8, gen_loss = 0.3879088135672287, disc_loss = 0.09002879583211222
Trained batch 355 in epoch 8, gen_loss = 0.38781246367130384, disc_loss = 0.08987712405041237
Trained batch 356 in epoch 8, gen_loss = 0.3878127494279076, disc_loss = 0.08989684364213203
Trained batch 357 in epoch 8, gen_loss = 0.3879000673580436, disc_loss = 0.0898454798991641
Trained batch 358 in epoch 8, gen_loss = 0.38766095639935444, disc_loss = 0.09053441121639855
Trained batch 359 in epoch 8, gen_loss = 0.3878668000300725, disc_loss = 0.090495641313545
Trained batch 360 in epoch 8, gen_loss = 0.38784073247803874, disc_loss = 0.09035169135216738
Trained batch 361 in epoch 8, gen_loss = 0.3878230657531412, disc_loss = 0.09012854075990617
Trained batch 362 in epoch 8, gen_loss = 0.38769030078383515, disc_loss = 0.08999079906512514
Trained batch 363 in epoch 8, gen_loss = 0.38774201380355017, disc_loss = 0.0897818418708374
Trained batch 364 in epoch 8, gen_loss = 0.3879401441306284, disc_loss = 0.08963179557061154
Trained batch 365 in epoch 8, gen_loss = 0.38778648334122745, disc_loss = 0.08943204187197723
Trained batch 366 in epoch 8, gen_loss = 0.387710185401771, disc_loss = 0.08977018759969105
Trained batch 367 in epoch 8, gen_loss = 0.38779309068037116, disc_loss = 0.09067098314889059
Trained batch 368 in epoch 8, gen_loss = 0.38781166020124586, disc_loss = 0.09118681900117415
Trained batch 369 in epoch 8, gen_loss = 0.3878366609682908, disc_loss = 0.0911997208157806
Trained batch 370 in epoch 8, gen_loss = 0.3877434204370185, disc_loss = 0.09144998627345798
Trained batch 371 in epoch 8, gen_loss = 0.38735311438319503, disc_loss = 0.09150764340489742
Trained batch 372 in epoch 8, gen_loss = 0.3872168792796199, disc_loss = 0.09139270465646249
Trained batch 373 in epoch 8, gen_loss = 0.3872924366577424, disc_loss = 0.09120224484860061
Trained batch 374 in epoch 8, gen_loss = 0.3872310144901276, disc_loss = 0.09103710968171556
Trained batch 375 in epoch 8, gen_loss = 0.3870389580409578, disc_loss = 0.0908398637832935
Trained batch 376 in epoch 8, gen_loss = 0.3870704938467365, disc_loss = 0.09071154079081327
Trained batch 377 in epoch 8, gen_loss = 0.3869374265904149, disc_loss = 0.09057469676721781
Trained batch 378 in epoch 8, gen_loss = 0.3871575580580568, disc_loss = 0.09042271068270533
Trained batch 379 in epoch 8, gen_loss = 0.3871972883218213, disc_loss = 0.09023149419257319
Trained batch 380 in epoch 8, gen_loss = 0.3872104136180377, disc_loss = 0.09002823962309346
Trained batch 381 in epoch 8, gen_loss = 0.387085082331253, disc_loss = 0.08986938627636674
Trained batch 382 in epoch 8, gen_loss = 0.3872520806117095, disc_loss = 0.08973984746019266
Trained batch 383 in epoch 8, gen_loss = 0.387298186076805, disc_loss = 0.08958670569093859
Trained batch 384 in epoch 8, gen_loss = 0.3873801199646739, disc_loss = 0.0894819823311424
Trained batch 385 in epoch 8, gen_loss = 0.38730325183102504, disc_loss = 0.08930167992396637
Trained batch 386 in epoch 8, gen_loss = 0.3871354718695007, disc_loss = 0.0894070379760896
Trained batch 387 in epoch 8, gen_loss = 0.38726801002762984, disc_loss = 0.09003970146385626
Trained batch 388 in epoch 8, gen_loss = 0.38737865217547185, disc_loss = 0.08985496937132088
Trained batch 389 in epoch 8, gen_loss = 0.38731152629240967, disc_loss = 0.08966522704786024
Trained batch 390 in epoch 8, gen_loss = 0.3871542715355563, disc_loss = 0.0896503149288828
Trained batch 391 in epoch 8, gen_loss = 0.38741087495368354, disc_loss = 0.089716449996447
Trained batch 392 in epoch 8, gen_loss = 0.38735065023407683, disc_loss = 0.08949914465968807
Trained batch 393 in epoch 8, gen_loss = 0.387285966407224, disc_loss = 0.08933758166344449
Trained batch 394 in epoch 8, gen_loss = 0.3870397536060478, disc_loss = 0.08934895988388718
Trained batch 395 in epoch 8, gen_loss = 0.38710656634183843, disc_loss = 0.08938043075260904
Trained batch 396 in epoch 8, gen_loss = 0.38715519833024264, disc_loss = 0.08923587717129955
Trained batch 397 in epoch 8, gen_loss = 0.38710948240816895, disc_loss = 0.08903837385446994
Trained batch 398 in epoch 8, gen_loss = 0.3869325437193228, disc_loss = 0.0889690936832481
Trained batch 399 in epoch 8, gen_loss = 0.3867803827673197, disc_loss = 0.08915446543949657
Trained batch 400 in epoch 8, gen_loss = 0.38706062358811016, disc_loss = 0.08970843640009772
Trained batch 401 in epoch 8, gen_loss = 0.3872458743515299, disc_loss = 0.0899944209959358
Trained batch 402 in epoch 8, gen_loss = 0.3870690144764874, disc_loss = 0.0898969018029941
Trained batch 403 in epoch 8, gen_loss = 0.3869163629294622, disc_loss = 0.08991804858093325
Trained batch 404 in epoch 8, gen_loss = 0.3868234431302106, disc_loss = 0.08979201221976567
Trained batch 405 in epoch 8, gen_loss = 0.3867400118282863, disc_loss = 0.08962439126197451
Trained batch 406 in epoch 8, gen_loss = 0.38680114829569545, disc_loss = 0.08945257538307175
Trained batch 407 in epoch 8, gen_loss = 0.3867802598751059, disc_loss = 0.08929580805581246
Trained batch 408 in epoch 8, gen_loss = 0.38671571285917006, disc_loss = 0.0891392986827546
Trained batch 409 in epoch 8, gen_loss = 0.3867492244737904, disc_loss = 0.08899187565008859
Trained batch 410 in epoch 8, gen_loss = 0.38684987913082985, disc_loss = 0.08888740252381658
Trained batch 411 in epoch 8, gen_loss = 0.3867659048692694, disc_loss = 0.08896681420771785
Trained batch 412 in epoch 8, gen_loss = 0.38682164168819677, disc_loss = 0.0899565058273261
Trained batch 413 in epoch 8, gen_loss = 0.38674528601664854, disc_loss = 0.08982097903145073
Trained batch 414 in epoch 8, gen_loss = 0.3867305295295026, disc_loss = 0.08971006860732135
Trained batch 415 in epoch 8, gen_loss = 0.3867809912189841, disc_loss = 0.08956776768340766
Trained batch 416 in epoch 8, gen_loss = 0.3868008746231774, disc_loss = 0.08945448763949944
Trained batch 417 in epoch 8, gen_loss = 0.3865972074310175, disc_loss = 0.08972157373396082
Trained batch 418 in epoch 8, gen_loss = 0.3864661604521667, disc_loss = 0.09033368950540774
Trained batch 419 in epoch 8, gen_loss = 0.38636890805902935, disc_loss = 0.09014407580252737
Trained batch 420 in epoch 8, gen_loss = 0.3861850791758993, disc_loss = 0.09029244774324276
Trained batch 421 in epoch 8, gen_loss = 0.38617837859838494, disc_loss = 0.09021193678358402
Trained batch 422 in epoch 8, gen_loss = 0.38608278499709237, disc_loss = 0.09020577388183691
Trained batch 423 in epoch 8, gen_loss = 0.3859927350620054, disc_loss = 0.09040533870190628
Trained batch 424 in epoch 8, gen_loss = 0.38598456088234395, disc_loss = 0.09027483003433136
Trained batch 425 in epoch 8, gen_loss = 0.3861132859484131, disc_loss = 0.09010536947173936
Trained batch 426 in epoch 8, gen_loss = 0.38616467548198385, disc_loss = 0.08998869212379186
Trained batch 427 in epoch 8, gen_loss = 0.3862507765956014, disc_loss = 0.08987918725372161
Trained batch 428 in epoch 8, gen_loss = 0.3863165161131701, disc_loss = 0.08973367098341142
Trained batch 429 in epoch 8, gen_loss = 0.3862301816080892, disc_loss = 0.08959336878926774
Trained batch 430 in epoch 8, gen_loss = 0.3863469481883082, disc_loss = 0.08967993958483682
Trained batch 431 in epoch 8, gen_loss = 0.38663351018395686, disc_loss = 0.08973211407363932
Trained batch 432 in epoch 8, gen_loss = 0.3865397319920344, disc_loss = 0.0895755609559803
Trained batch 433 in epoch 8, gen_loss = 0.38660906069839057, disc_loss = 0.08941185064849869
Trained batch 434 in epoch 8, gen_loss = 0.3867179163571062, disc_loss = 0.0893198737200221
Trained batch 435 in epoch 8, gen_loss = 0.3865293253452406, disc_loss = 0.08930270542036059
Trained batch 436 in epoch 8, gen_loss = 0.38655606164539436, disc_loss = 0.0892870367943678
Trained batch 437 in epoch 8, gen_loss = 0.386574186758908, disc_loss = 0.08935317362139861
Trained batch 438 in epoch 8, gen_loss = 0.3864375021571722, disc_loss = 0.08924887220614965
Trained batch 439 in epoch 8, gen_loss = 0.3866470529274507, disc_loss = 0.0890676978097128
Trained batch 440 in epoch 8, gen_loss = 0.38653448447078265, disc_loss = 0.0892172085592215
Trained batch 441 in epoch 8, gen_loss = 0.3867208679202455, disc_loss = 0.08998926686506499
Trained batch 442 in epoch 8, gen_loss = 0.3867144146702898, disc_loss = 0.08980939023587726
Trained batch 443 in epoch 8, gen_loss = 0.3866732473577465, disc_loss = 0.08970129218158052
Trained batch 444 in epoch 8, gen_loss = 0.38664045086067717, disc_loss = 0.08956968573895231
Trained batch 445 in epoch 8, gen_loss = 0.38661215745012856, disc_loss = 0.08943417496382021
Trained batch 446 in epoch 8, gen_loss = 0.3867901547643162, disc_loss = 0.08925814524197105
Trained batch 447 in epoch 8, gen_loss = 0.38684413029945325, disc_loss = 0.08948140978152098
Trained batch 448 in epoch 8, gen_loss = 0.3867762830846825, disc_loss = 0.09005920938371716
Trained batch 449 in epoch 8, gen_loss = 0.3869648145304786, disc_loss = 0.08989676090267797
Trained batch 450 in epoch 8, gen_loss = 0.3869407236443919, disc_loss = 0.08987773758794972
Trained batch 451 in epoch 8, gen_loss = 0.3869623044687035, disc_loss = 0.08973394579200519
Trained batch 452 in epoch 8, gen_loss = 0.3868615829918295, disc_loss = 0.08988270776296985
Trained batch 453 in epoch 8, gen_loss = 0.3868448577394569, disc_loss = 0.08984811499915886
Trained batch 454 in epoch 8, gen_loss = 0.38671856633909457, disc_loss = 0.08969258340280298
Trained batch 455 in epoch 8, gen_loss = 0.3865734574695428, disc_loss = 0.08970483933399807
Trained batch 456 in epoch 8, gen_loss = 0.386573255453381, disc_loss = 0.08980917922553303
Trained batch 457 in epoch 8, gen_loss = 0.38647479580219135, disc_loss = 0.09032790283225152
Trained batch 458 in epoch 8, gen_loss = 0.3866523334793016, disc_loss = 0.09069325817213242
Trained batch 459 in epoch 8, gen_loss = 0.3866094097495079, disc_loss = 0.0905852073084806
Trained batch 460 in epoch 8, gen_loss = 0.38655305270776313, disc_loss = 0.0907405594984017
Trained batch 461 in epoch 8, gen_loss = 0.38652471927079285, disc_loss = 0.09103941848174996
Trained batch 462 in epoch 8, gen_loss = 0.38627835870046595, disc_loss = 0.09125092373074678
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.48737770318984985, disc_loss = 0.30023762583732605
Trained batch 1 in epoch 9, gen_loss = 0.44416067004203796, disc_loss = 0.16329868137836456
Trained batch 2 in epoch 9, gen_loss = 0.3993600209554036, disc_loss = 0.11862960581978162
Trained batch 3 in epoch 9, gen_loss = 0.40731172263622284, disc_loss = 0.09671257110312581
Trained batch 4 in epoch 9, gen_loss = 0.3934240102767944, disc_loss = 0.085349515452981
Trained batch 5 in epoch 9, gen_loss = 0.38538875182469684, disc_loss = 0.08367226676394542
Trained batch 6 in epoch 9, gen_loss = 0.37872922846249174, disc_loss = 0.10639104380139283
Trained batch 7 in epoch 9, gen_loss = 0.3839057721197605, disc_loss = 0.13327326369471848
Trained batch 8 in epoch 9, gen_loss = 0.3783753712972005, disc_loss = 0.12661134472323787
Trained batch 9 in epoch 9, gen_loss = 0.3757812947034836, disc_loss = 0.12237625811249017
Trained batch 10 in epoch 9, gen_loss = 0.38046861507675866, disc_loss = 0.12081387791443955
Trained batch 11 in epoch 9, gen_loss = 0.3713732312122981, disc_loss = 0.11578899016603827
Trained batch 12 in epoch 9, gen_loss = 0.3676977042968457, disc_loss = 0.11245453773209682
Trained batch 13 in epoch 9, gen_loss = 0.36298653909138273, disc_loss = 0.11388168656932456
Trained batch 14 in epoch 9, gen_loss = 0.3700921098391215, disc_loss = 0.11889591676493486
Trained batch 15 in epoch 9, gen_loss = 0.36924691684544086, disc_loss = 0.11391084652859718
Trained batch 16 in epoch 9, gen_loss = 0.36999870398465323, disc_loss = 0.10839230249471524
Trained batch 17 in epoch 9, gen_loss = 0.37211337520016563, disc_loss = 0.10333934022734563
Trained batch 18 in epoch 9, gen_loss = 0.3706793957634976, disc_loss = 0.10724688997786296
Trained batch 19 in epoch 9, gen_loss = 0.36563187688589094, disc_loss = 0.11876755366101861
Trained batch 20 in epoch 9, gen_loss = 0.3669777512550354, disc_loss = 0.11456465392950035
Trained batch 21 in epoch 9, gen_loss = 0.37062550810250366, disc_loss = 0.11033466695384546
Trained batch 22 in epoch 9, gen_loss = 0.3704693719096806, disc_loss = 0.10638957478753898
Trained batch 23 in epoch 9, gen_loss = 0.3721335828304291, disc_loss = 0.10278460895642638
Trained batch 24 in epoch 9, gen_loss = 0.37159667134284974, disc_loss = 0.09988711580634117
Trained batch 25 in epoch 9, gen_loss = 0.37193056367910826, disc_loss = 0.09645854602926053
Trained batch 26 in epoch 9, gen_loss = 0.3735887783545035, disc_loss = 0.09364184544042305
Trained batch 27 in epoch 9, gen_loss = 0.3758506860051836, disc_loss = 0.09167816090796675
Trained batch 28 in epoch 9, gen_loss = 0.37720596584780464, disc_loss = 0.08896154322629345
Trained batch 29 in epoch 9, gen_loss = 0.3777400682369868, disc_loss = 0.08779029600943128
Trained batch 30 in epoch 9, gen_loss = 0.37541553954924306, disc_loss = 0.092969830508434
Trained batch 31 in epoch 9, gen_loss = 0.37819227296859026, disc_loss = 0.09347779399831779
Trained batch 32 in epoch 9, gen_loss = 0.37978855136669043, disc_loss = 0.09140823129564524
Trained batch 33 in epoch 9, gen_loss = 0.3795637987992343, disc_loss = 0.0891314209164942
Trained batch 34 in epoch 9, gen_loss = 0.37682950837271556, disc_loss = 0.08873534255794116
Trained batch 35 in epoch 9, gen_loss = 0.37699508170286816, disc_loss = 0.08872329536825418
Trained batch 36 in epoch 9, gen_loss = 0.3780241511963509, disc_loss = 0.0870536879913227
Trained batch 37 in epoch 9, gen_loss = 0.38041714539653376, disc_loss = 0.08570123895218498
Trained batch 38 in epoch 9, gen_loss = 0.38087298396306163, disc_loss = 0.08388181639691958
Trained batch 39 in epoch 9, gen_loss = 0.3809795543551445, disc_loss = 0.08200633232481777
Trained batch 40 in epoch 9, gen_loss = 0.381064417885571, disc_loss = 0.08020484835908907
Trained batch 41 in epoch 9, gen_loss = 0.3800551579112098, disc_loss = 0.08233434128175889
Trained batch 42 in epoch 9, gen_loss = 0.38330203017523123, disc_loss = 0.09156116381894018
Trained batch 43 in epoch 9, gen_loss = 0.38477352126078174, disc_loss = 0.09351302638903937
Trained batch 44 in epoch 9, gen_loss = 0.3838609622584449, disc_loss = 0.09354980196803808
Trained batch 45 in epoch 9, gen_loss = 0.383090821945149, disc_loss = 0.0929414568995328
Trained batch 46 in epoch 9, gen_loss = 0.3832319030102263, disc_loss = 0.09224264607071242
Trained batch 47 in epoch 9, gen_loss = 0.38313050754368305, disc_loss = 0.09131778844554599
Trained batch 48 in epoch 9, gen_loss = 0.38292394608867414, disc_loss = 0.08991985515292202
Trained batch 49 in epoch 9, gen_loss = 0.38250201761722563, disc_loss = 0.08838323475793004
Trained batch 50 in epoch 9, gen_loss = 0.3817954916580051, disc_loss = 0.08750135635993644
Trained batch 51 in epoch 9, gen_loss = 0.3813527811032075, disc_loss = 0.08642780202297637
Trained batch 52 in epoch 9, gen_loss = 0.37988931840320805, disc_loss = 0.0852323669483358
Trained batch 53 in epoch 9, gen_loss = 0.3801730860162664, disc_loss = 0.08382343895802344
Trained batch 54 in epoch 9, gen_loss = 0.38111473972147164, disc_loss = 0.0826065398583358
Trained batch 55 in epoch 9, gen_loss = 0.38025780980076107, disc_loss = 0.08252722588700376
Trained batch 56 in epoch 9, gen_loss = 0.3802047581003423, disc_loss = 0.082779831579772
Trained batch 57 in epoch 9, gen_loss = 0.3793925488817281, disc_loss = 0.08293806535095491
Trained batch 58 in epoch 9, gen_loss = 0.38091436230530173, disc_loss = 0.08184442522351519
Trained batch 59 in epoch 9, gen_loss = 0.3813199559847514, disc_loss = 0.08184958067722618
Trained batch 60 in epoch 9, gen_loss = 0.38178701967489526, disc_loss = 0.08199418548372436
Trained batch 61 in epoch 9, gen_loss = 0.3812723207858301, disc_loss = 0.08077207216692547
Trained batch 62 in epoch 9, gen_loss = 0.3817126325198582, disc_loss = 0.07956204294330543
Trained batch 63 in epoch 9, gen_loss = 0.3816165872849524, disc_loss = 0.07851046600262634
Trained batch 64 in epoch 9, gen_loss = 0.38294835732533383, disc_loss = 0.07740972906780931
Trained batch 65 in epoch 9, gen_loss = 0.38381588549324963, disc_loss = 0.07670295074102328
Trained batch 66 in epoch 9, gen_loss = 0.3835237444336735, disc_loss = 0.07594292815913682
Trained batch 67 in epoch 9, gen_loss = 0.3836433528100743, disc_loss = 0.07584265898228348
Trained batch 68 in epoch 9, gen_loss = 0.38432568354883057, disc_loss = 0.07541466973371048
Trained batch 69 in epoch 9, gen_loss = 0.384844366141728, disc_loss = 0.07468872780113348
Trained batch 70 in epoch 9, gen_loss = 0.38601883994021885, disc_loss = 0.07449923085153733
Trained batch 71 in epoch 9, gen_loss = 0.38492756626672214, disc_loss = 0.07420771555431808
Trained batch 72 in epoch 9, gen_loss = 0.3858070875683876, disc_loss = 0.07328441063554524
Trained batch 73 in epoch 9, gen_loss = 0.38661741928474325, disc_loss = 0.07252201748181235
Trained batch 74 in epoch 9, gen_loss = 0.387171680132548, disc_loss = 0.07174300018077095
Trained batch 75 in epoch 9, gen_loss = 0.3869672660764895, disc_loss = 0.07175686154637094
Trained batch 76 in epoch 9, gen_loss = 0.3872276246547699, disc_loss = 0.07181040887636217
Trained batch 77 in epoch 9, gen_loss = 0.38711512165191847, disc_loss = 0.07171212932548653
Trained batch 78 in epoch 9, gen_loss = 0.3877291943453535, disc_loss = 0.0710696835554193
Trained batch 79 in epoch 9, gen_loss = 0.3883250534534454, disc_loss = 0.07085974100627937
Trained batch 80 in epoch 9, gen_loss = 0.38983805827152584, disc_loss = 0.07024184720774676
Trained batch 81 in epoch 9, gen_loss = 0.3888072080728484, disc_loss = 0.07294720852543123
Trained batch 82 in epoch 9, gen_loss = 0.3903606785349099, disc_loss = 0.07350904005860169
Trained batch 83 in epoch 9, gen_loss = 0.3903864551158178, disc_loss = 0.07413134516017246
Trained batch 84 in epoch 9, gen_loss = 0.3902229242465075, disc_loss = 0.07790821374887053
Trained batch 85 in epoch 9, gen_loss = 0.3895499619633652, disc_loss = 0.08022767136978029
Trained batch 86 in epoch 9, gen_loss = 0.3885371633644762, disc_loss = 0.08165703598816676
Trained batch 87 in epoch 9, gen_loss = 0.38747041537003085, disc_loss = 0.08309283721874552
Trained batch 88 in epoch 9, gen_loss = 0.38692094167966523, disc_loss = 0.08437068664646719
Trained batch 89 in epoch 9, gen_loss = 0.3856917593214247, disc_loss = 0.08541183790916371
Trained batch 90 in epoch 9, gen_loss = 0.38458093444069663, disc_loss = 0.08661702591004772
Trained batch 91 in epoch 9, gen_loss = 0.3841045631662659, disc_loss = 0.0872950938216451
Trained batch 92 in epoch 9, gen_loss = 0.3839179818989128, disc_loss = 0.08852153668500563
Trained batch 93 in epoch 9, gen_loss = 0.38298090816812314, disc_loss = 0.08953337978195161
Trained batch 94 in epoch 9, gen_loss = 0.3821681938673321, disc_loss = 0.09031728886950173
Trained batch 95 in epoch 9, gen_loss = 0.38211323227733374, disc_loss = 0.09082803196603588
Trained batch 96 in epoch 9, gen_loss = 0.3816717644942175, disc_loss = 0.091540806729961
Trained batch 97 in epoch 9, gen_loss = 0.3817923178478163, disc_loss = 0.09204193771512685
Trained batch 98 in epoch 9, gen_loss = 0.3807015491254402, disc_loss = 0.09266355066005179
Trained batch 99 in epoch 9, gen_loss = 0.38095774173736574, disc_loss = 0.09220321011263877
Trained batch 100 in epoch 9, gen_loss = 0.3795012254821192, disc_loss = 0.0930244492984718
Trained batch 101 in epoch 9, gen_loss = 0.37972567493424697, disc_loss = 0.09575357431016278
Trained batch 102 in epoch 9, gen_loss = 0.3802975339507594, disc_loss = 0.09523359748073718
Trained batch 103 in epoch 9, gen_loss = 0.38077996112406254, disc_loss = 0.09537200970449843
Trained batch 104 in epoch 9, gen_loss = 0.3805513789256414, disc_loss = 0.09505801751233992
Trained batch 105 in epoch 9, gen_loss = 0.3806727690235624, disc_loss = 0.09480593350434781
Trained batch 106 in epoch 9, gen_loss = 0.38065391375082674, disc_loss = 0.09420142264027044
Trained batch 107 in epoch 9, gen_loss = 0.37976558851423087, disc_loss = 0.09552043487093653
Trained batch 108 in epoch 9, gen_loss = 0.37994305625421193, disc_loss = 0.095941184622603
Trained batch 109 in epoch 9, gen_loss = 0.3800607360222123, disc_loss = 0.09540352371351962
Trained batch 110 in epoch 9, gen_loss = 0.38007617063887483, disc_loss = 0.09478593477140274
Trained batch 111 in epoch 9, gen_loss = 0.37963257131299805, disc_loss = 0.09499748450720549
Trained batch 112 in epoch 9, gen_loss = 0.37982306847002656, disc_loss = 0.0969127899291307
Trained batch 113 in epoch 9, gen_loss = 0.3792378642318541, disc_loss = 0.09654386557654984
Trained batch 114 in epoch 9, gen_loss = 0.37914247707180354, disc_loss = 0.09611831411476368
Trained batch 115 in epoch 9, gen_loss = 0.3787975484697983, disc_loss = 0.0961518380831092
Trained batch 116 in epoch 9, gen_loss = 0.3797230163955281, disc_loss = 0.0975480464955744
Trained batch 117 in epoch 9, gen_loss = 0.379719405229819, disc_loss = 0.09685455484047406
Trained batch 118 in epoch 9, gen_loss = 0.37931068992915273, disc_loss = 0.09660266315126244
Trained batch 119 in epoch 9, gen_loss = 0.37935948284963766, disc_loss = 0.09606116578991836
Trained batch 120 in epoch 9, gen_loss = 0.37920680703703036, disc_loss = 0.09546452459363529
Trained batch 121 in epoch 9, gen_loss = 0.3790417322125591, disc_loss = 0.09592076837176793
Trained batch 122 in epoch 9, gen_loss = 0.3795510083436966, disc_loss = 0.09632119845704941
Trained batch 123 in epoch 9, gen_loss = 0.3797694034874439, disc_loss = 0.09567125696283314
Trained batch 124 in epoch 9, gen_loss = 0.3801295040845871, disc_loss = 0.09516754664853215
Trained batch 125 in epoch 9, gen_loss = 0.3807853577392442, disc_loss = 0.09497504387538702
Trained batch 126 in epoch 9, gen_loss = 0.3805406632151191, disc_loss = 0.09448905091542076
Trained batch 127 in epoch 9, gen_loss = 0.38115930010098964, disc_loss = 0.09407525264032301
Trained batch 128 in epoch 9, gen_loss = 0.38131409386793774, disc_loss = 0.09364201606778327
Trained batch 129 in epoch 9, gen_loss = 0.38197346341151456, disc_loss = 0.09322843504711413
Trained batch 130 in epoch 9, gen_loss = 0.3817942266473333, disc_loss = 0.09273321240187715
Trained batch 131 in epoch 9, gen_loss = 0.38212424798896816, disc_loss = 0.0922132772428802
Trained batch 132 in epoch 9, gen_loss = 0.3820192104667649, disc_loss = 0.09162481566470929
Trained batch 133 in epoch 9, gen_loss = 0.3821417201143592, disc_loss = 0.09127572287610773
Trained batch 134 in epoch 9, gen_loss = 0.3823883093065686, disc_loss = 0.09171039437599204
Trained batch 135 in epoch 9, gen_loss = 0.3829869962133029, disc_loss = 0.0920425237957662
Trained batch 136 in epoch 9, gen_loss = 0.3828129591080394, disc_loss = 0.0916614741338485
Trained batch 137 in epoch 9, gen_loss = 0.3835577961543332, disc_loss = 0.0916424994053238
Trained batch 138 in epoch 9, gen_loss = 0.3836254345641719, disc_loss = 0.09159826964689352
Trained batch 139 in epoch 9, gen_loss = 0.3840311128113951, disc_loss = 0.09109107465150633
Trained batch 140 in epoch 9, gen_loss = 0.38449219492733056, disc_loss = 0.0906512913267716
Trained batch 141 in epoch 9, gen_loss = 0.3845546508968716, disc_loss = 0.09013633076167128
Trained batch 142 in epoch 9, gen_loss = 0.38461746046176326, disc_loss = 0.08996137958736374
Trained batch 143 in epoch 9, gen_loss = 0.384631575913065, disc_loss = 0.08941168071922018
Trained batch 144 in epoch 9, gen_loss = 0.3847206901887367, disc_loss = 0.08885057299108855
Trained batch 145 in epoch 9, gen_loss = 0.3852220821666391, disc_loss = 0.08829767299395004
Trained batch 146 in epoch 9, gen_loss = 0.384968129854624, disc_loss = 0.08792305878699333
Trained batch 147 in epoch 9, gen_loss = 0.3845241765516835, disc_loss = 0.0873749221964563
Trained batch 148 in epoch 9, gen_loss = 0.38441594465066925, disc_loss = 0.0870868556213959
Trained batch 149 in epoch 9, gen_loss = 0.3849440482258797, disc_loss = 0.08686007194841902
Trained batch 150 in epoch 9, gen_loss = 0.3847280897644182, disc_loss = 0.08633531549859126
Trained batch 151 in epoch 9, gen_loss = 0.3848637145404753, disc_loss = 0.08635532599873841
Trained batch 152 in epoch 9, gen_loss = 0.3853752444577373, disc_loss = 0.08821453026258479
Trained batch 153 in epoch 9, gen_loss = 0.3855131735855883, disc_loss = 0.0877247860461667
Trained batch 154 in epoch 9, gen_loss = 0.38528794867377125, disc_loss = 0.08741796077980149
Trained batch 155 in epoch 9, gen_loss = 0.3847325238852929, disc_loss = 0.08721094546266474
Trained batch 156 in epoch 9, gen_loss = 0.3845347092979273, disc_loss = 0.08812675360519036
Trained batch 157 in epoch 9, gen_loss = 0.3847926767377914, disc_loss = 0.08896521994066012
Trained batch 158 in epoch 9, gen_loss = 0.38495380689138137, disc_loss = 0.08851759241155858
Trained batch 159 in epoch 9, gen_loss = 0.3845688502304256, disc_loss = 0.08832512411754578
Trained batch 160 in epoch 9, gen_loss = 0.38460969989714416, disc_loss = 0.08782927498730443
Trained batch 161 in epoch 9, gen_loss = 0.3850042053762777, disc_loss = 0.08736065955671632
Trained batch 162 in epoch 9, gen_loss = 0.3849178734549715, disc_loss = 0.0870260078962778
Trained batch 163 in epoch 9, gen_loss = 0.3849124093426437, disc_loss = 0.08764129587471849
Trained batch 164 in epoch 9, gen_loss = 0.3845731568155867, disc_loss = 0.08852404889961084
Trained batch 165 in epoch 9, gen_loss = 0.38467162515384606, disc_loss = 0.09075525233589382
Trained batch 166 in epoch 9, gen_loss = 0.3847147507403425, disc_loss = 0.09203469031629805
Trained batch 167 in epoch 9, gen_loss = 0.38430571511742617, disc_loss = 0.092424645853628
Trained batch 168 in epoch 9, gen_loss = 0.384174057982377, disc_loss = 0.09292833587518458
Trained batch 169 in epoch 9, gen_loss = 0.38382830313023397, disc_loss = 0.09312810890157433
Trained batch 170 in epoch 9, gen_loss = 0.3835781574772115, disc_loss = 0.09356039502162333
Trained batch 171 in epoch 9, gen_loss = 0.38365444445679353, disc_loss = 0.09368034990417749
Trained batch 172 in epoch 9, gen_loss = 0.38306491387028224, disc_loss = 0.09387506519826506
Trained batch 173 in epoch 9, gen_loss = 0.382873712343046, disc_loss = 0.09408415024350772
Trained batch 174 in epoch 9, gen_loss = 0.38219581357070376, disc_loss = 0.09491625233420303
Trained batch 175 in epoch 9, gen_loss = 0.38226638742807234, disc_loss = 0.09636016538239676
Trained batch 176 in epoch 9, gen_loss = 0.38211636885074574, disc_loss = 0.096371442931941
Trained batch 177 in epoch 9, gen_loss = 0.38238769861754407, disc_loss = 0.09719951560699873
Trained batch 178 in epoch 9, gen_loss = 0.38248520015671267, disc_loss = 0.0971297636815456
Trained batch 179 in epoch 9, gen_loss = 0.38257084662715596, disc_loss = 0.09689661542781525
Trained batch 180 in epoch 9, gen_loss = 0.38226862367016173, disc_loss = 0.09670973269690795
Trained batch 181 in epoch 9, gen_loss = 0.38210438462076607, disc_loss = 0.09627807552793197
Trained batch 182 in epoch 9, gen_loss = 0.382030282759927, disc_loss = 0.09603005200828034
Trained batch 183 in epoch 9, gen_loss = 0.3822284587861403, disc_loss = 0.09603676047054646
Trained batch 184 in epoch 9, gen_loss = 0.3820711869645763, disc_loss = 0.09593071874130417
Trained batch 185 in epoch 9, gen_loss = 0.3825519870846502, disc_loss = 0.09634416134807691
Trained batch 186 in epoch 9, gen_loss = 0.3822018265883553, disc_loss = 0.0963830387389118
Trained batch 187 in epoch 9, gen_loss = 0.38260437350006815, disc_loss = 0.09600755864595796
Trained batch 188 in epoch 9, gen_loss = 0.3825854207315142, disc_loss = 0.09610684400315954
Trained batch 189 in epoch 9, gen_loss = 0.3825462952256203, disc_loss = 0.0982365868887619
Trained batch 190 in epoch 9, gen_loss = 0.38309250990445703, disc_loss = 0.09797702026577833
Trained batch 191 in epoch 9, gen_loss = 0.38342596706934273, disc_loss = 0.09776609964319505
Trained batch 192 in epoch 9, gen_loss = 0.38317593754573187, disc_loss = 0.09739656882466739
Trained batch 193 in epoch 9, gen_loss = 0.38333086830746266, disc_loss = 0.09718207355358244
Trained batch 194 in epoch 9, gen_loss = 0.3828507667168593, disc_loss = 0.09722897017804476
Trained batch 195 in epoch 9, gen_loss = 0.38290041342985875, disc_loss = 0.09731663589612866
Trained batch 196 in epoch 9, gen_loss = 0.3825285064841285, disc_loss = 0.0981813343289086
Trained batch 197 in epoch 9, gen_loss = 0.38257552961809466, disc_loss = 0.09864863445700119
Trained batch 198 in epoch 9, gen_loss = 0.38269907048898727, disc_loss = 0.09824687934213847
Trained batch 199 in epoch 9, gen_loss = 0.38236076675355435, disc_loss = 0.0983779917936772
Trained batch 200 in epoch 9, gen_loss = 0.38252081125233306, disc_loss = 0.0984936512506275
Trained batch 201 in epoch 9, gen_loss = 0.38256985812198996, disc_loss = 0.09824276508044193
Trained batch 202 in epoch 9, gen_loss = 0.38250885536811624, disc_loss = 0.0978797086482418
Trained batch 203 in epoch 9, gen_loss = 0.3824751218598263, disc_loss = 0.09745209236337128
Trained batch 204 in epoch 9, gen_loss = 0.3824707626569562, disc_loss = 0.09729253841882071
Trained batch 205 in epoch 9, gen_loss = 0.38230283797076603, disc_loss = 0.09739370292812152
Trained batch 206 in epoch 9, gen_loss = 0.3827066586357384, disc_loss = 0.09733110730612768
Trained batch 207 in epoch 9, gen_loss = 0.3827102074686151, disc_loss = 0.09716594233088052
Trained batch 208 in epoch 9, gen_loss = 0.3829293093470295, disc_loss = 0.09680235267808421
Trained batch 209 in epoch 9, gen_loss = 0.38288626493442623, disc_loss = 0.09641987276485278
Trained batch 210 in epoch 9, gen_loss = 0.3832804897526429, disc_loss = 0.09607305389639184
Trained batch 211 in epoch 9, gen_loss = 0.3832831771446849, disc_loss = 0.09585893788058662
Trained batch 212 in epoch 9, gen_loss = 0.3831091750535607, disc_loss = 0.09704276584875836
Trained batch 213 in epoch 9, gen_loss = 0.3836610596452918, disc_loss = 0.09823057836652777
Trained batch 214 in epoch 9, gen_loss = 0.38381713316884153, disc_loss = 0.09781959174677383
Trained batch 215 in epoch 9, gen_loss = 0.3836351193625618, disc_loss = 0.09769176029496723
Trained batch 216 in epoch 9, gen_loss = 0.3837400810097769, disc_loss = 0.09730202468618544
Trained batch 217 in epoch 9, gen_loss = 0.3841776056984149, disc_loss = 0.09695011696889314
Trained batch 218 in epoch 9, gen_loss = 0.3841501488669278, disc_loss = 0.09665123667550958
Trained batch 219 in epoch 9, gen_loss = 0.383982730250467, disc_loss = 0.09642468045719645
Trained batch 220 in epoch 9, gen_loss = 0.3837555296955065, disc_loss = 0.09627112790065653
Trained batch 221 in epoch 9, gen_loss = 0.3839388634036253, disc_loss = 0.09609946155467548
Trained batch 222 in epoch 9, gen_loss = 0.3839623972840373, disc_loss = 0.09610772296585844
Trained batch 223 in epoch 9, gen_loss = 0.3841853183694184, disc_loss = 0.09691234854316073
Trained batch 224 in epoch 9, gen_loss = 0.3840663809908761, disc_loss = 0.0966382822394371
Trained batch 225 in epoch 9, gen_loss = 0.38408365786339327, disc_loss = 0.0963731198942503
Trained batch 226 in epoch 9, gen_loss = 0.38409085296061596, disc_loss = 0.09603659994900227
Trained batch 227 in epoch 9, gen_loss = 0.3841181219016251, disc_loss = 0.09571775468066335
Trained batch 228 in epoch 9, gen_loss = 0.38413272381609703, disc_loss = 0.09537324612740607
Trained batch 229 in epoch 9, gen_loss = 0.38424278309811716, disc_loss = 0.09507335312664508
Trained batch 230 in epoch 9, gen_loss = 0.3844817362693481, disc_loss = 0.0948278240827255
Trained batch 231 in epoch 9, gen_loss = 0.3846122732321764, disc_loss = 0.0949063447528872
Trained batch 232 in epoch 9, gen_loss = 0.38484442317178835, disc_loss = 0.09458189374515427
Trained batch 233 in epoch 9, gen_loss = 0.3849923469954067, disc_loss = 0.09432254672750957
Trained batch 234 in epoch 9, gen_loss = 0.38524598282702427, disc_loss = 0.09402027733306935
Trained batch 235 in epoch 9, gen_loss = 0.38567969651292944, disc_loss = 0.09420888859115667
Trained batch 236 in epoch 9, gen_loss = 0.3853034361379559, disc_loss = 0.0944668235736683
Trained batch 237 in epoch 9, gen_loss = 0.3857133419198148, disc_loss = 0.09419728720858067
Trained batch 238 in epoch 9, gen_loss = 0.3860775287804743, disc_loss = 0.09382863426931733
Trained batch 239 in epoch 9, gen_loss = 0.3863898162419597, disc_loss = 0.09348202887534475
Trained batch 240 in epoch 9, gen_loss = 0.3865024214339949, disc_loss = 0.09316535779812153
Trained batch 241 in epoch 9, gen_loss = 0.38628414008489326, disc_loss = 0.09295792951949003
Trained batch 242 in epoch 9, gen_loss = 0.3861570400588306, disc_loss = 0.09266065995864294
Trained batch 243 in epoch 9, gen_loss = 0.38625376983011356, disc_loss = 0.09241344686215897
Trained batch 244 in epoch 9, gen_loss = 0.3862200979675565, disc_loss = 0.09212466788155084
Trained batch 245 in epoch 9, gen_loss = 0.38646705648521096, disc_loss = 0.0919133548140223
Trained batch 246 in epoch 9, gen_loss = 0.38677256026490014, disc_loss = 0.09241232195650396
Trained batch 247 in epoch 9, gen_loss = 0.38644241006864655, disc_loss = 0.09299932526529676
Trained batch 248 in epoch 9, gen_loss = 0.38669442526068554, disc_loss = 0.09325412649990444
Trained batch 249 in epoch 9, gen_loss = 0.3868728395104408, disc_loss = 0.0929309316687286
Trained batch 250 in epoch 9, gen_loss = 0.38680346559480844, disc_loss = 0.09258283655051572
Trained batch 251 in epoch 9, gen_loss = 0.3868503093364693, disc_loss = 0.09227763048727952
Trained batch 252 in epoch 9, gen_loss = 0.3866111976002516, disc_loss = 0.09196772618152996
Trained batch 253 in epoch 9, gen_loss = 0.3862242272167694, disc_loss = 0.09195791387666516
Trained batch 254 in epoch 9, gen_loss = 0.38629575634703917, disc_loss = 0.09272061402672062
Trained batch 255 in epoch 9, gen_loss = 0.38619737775297835, disc_loss = 0.09243430830611032
Trained batch 256 in epoch 9, gen_loss = 0.3859524548865478, disc_loss = 0.0931055570630074
Trained batch 257 in epoch 9, gen_loss = 0.38630754003922146, disc_loss = 0.09345381827158637
Trained batch 258 in epoch 9, gen_loss = 0.3860527392635014, disc_loss = 0.09331820268385313
Trained batch 259 in epoch 9, gen_loss = 0.3858505812401955, disc_loss = 0.09317328670921807
Trained batch 260 in epoch 9, gen_loss = 0.38537013239559087, disc_loss = 0.09310508818076603
Trained batch 261 in epoch 9, gen_loss = 0.3854618853398862, disc_loss = 0.0927815244049687
Trained batch 262 in epoch 9, gen_loss = 0.38552696311655155, disc_loss = 0.0924669243359917
Trained batch 263 in epoch 9, gen_loss = 0.3853097104777892, disc_loss = 0.0922621177671703
Trained batch 264 in epoch 9, gen_loss = 0.3851809209810113, disc_loss = 0.09291579808758677
Trained batch 265 in epoch 9, gen_loss = 0.3849843723097242, disc_loss = 0.09439133248761072
Trained batch 266 in epoch 9, gen_loss = 0.38461729499061453, disc_loss = 0.09435893797179622
Trained batch 267 in epoch 9, gen_loss = 0.3848766295878745, disc_loss = 0.0942304791542076
Trained batch 268 in epoch 9, gen_loss = 0.38492914785018195, disc_loss = 0.09424159539773451
Trained batch 269 in epoch 9, gen_loss = 0.3846329869495498, disc_loss = 0.09436914931499847
Trained batch 270 in epoch 9, gen_loss = 0.3847618095879185, disc_loss = 0.09417771599925642
Trained batch 271 in epoch 9, gen_loss = 0.3850138620747363, disc_loss = 0.09428267895504285
Trained batch 272 in epoch 9, gen_loss = 0.38475519042093675, disc_loss = 0.0947874994852986
Trained batch 273 in epoch 9, gen_loss = 0.38486987923401117, disc_loss = 0.09455841510169154
Trained batch 274 in epoch 9, gen_loss = 0.38505078873851084, disc_loss = 0.09447049687870523
Trained batch 275 in epoch 9, gen_loss = 0.38489031537935353, disc_loss = 0.0944317087929264
Trained batch 276 in epoch 9, gen_loss = 0.3849773891673622, disc_loss = 0.09420362273264771
Trained batch 277 in epoch 9, gen_loss = 0.38502656582662526, disc_loss = 0.09395191231206489
Trained batch 278 in epoch 9, gen_loss = 0.38496064183746187, disc_loss = 0.09416155161596435
Trained batch 279 in epoch 9, gen_loss = 0.3851292723523719, disc_loss = 0.09483280865409012
Trained batch 280 in epoch 9, gen_loss = 0.3852723926517887, disc_loss = 0.09460197615493553
Trained batch 281 in epoch 9, gen_loss = 0.38546356912834423, disc_loss = 0.09441732704731906
Trained batch 282 in epoch 9, gen_loss = 0.38582472239913873, disc_loss = 0.09417720854795758
Trained batch 283 in epoch 9, gen_loss = 0.38574045775851734, disc_loss = 0.0939439831754114
Trained batch 284 in epoch 9, gen_loss = 0.3855410591029284, disc_loss = 0.09389961481159716
Trained batch 285 in epoch 9, gen_loss = 0.3854521794856845, disc_loss = 0.09413768824228978
Trained batch 286 in epoch 9, gen_loss = 0.3853638273394482, disc_loss = 0.09401338254442303
Trained batch 287 in epoch 9, gen_loss = 0.38529753866088057, disc_loss = 0.0937469710123777
Trained batch 288 in epoch 9, gen_loss = 0.38522437292193046, disc_loss = 0.09353630081992145
Trained batch 289 in epoch 9, gen_loss = 0.38523187108080964, disc_loss = 0.09327748043719551
Trained batch 290 in epoch 9, gen_loss = 0.3855421063314189, disc_loss = 0.09335341443758957
Trained batch 291 in epoch 9, gen_loss = 0.38530002529286356, disc_loss = 0.0946803233643662
Trained batch 292 in epoch 9, gen_loss = 0.38529522381341497, disc_loss = 0.094584358541403
Trained batch 293 in epoch 9, gen_loss = 0.38556638152218187, disc_loss = 0.0944997952192971
Trained batch 294 in epoch 9, gen_loss = 0.38566325513993277, disc_loss = 0.09435547523011091
Trained batch 295 in epoch 9, gen_loss = 0.38548217789345496, disc_loss = 0.09425042286150258
Trained batch 296 in epoch 9, gen_loss = 0.3853685131879768, disc_loss = 0.09439495435103724
Trained batch 297 in epoch 9, gen_loss = 0.3853309643048568, disc_loss = 0.09475513901123965
Trained batch 298 in epoch 9, gen_loss = 0.3852681629733497, disc_loss = 0.0949178092698738
Trained batch 299 in epoch 9, gen_loss = 0.3852240926524003, disc_loss = 0.0946529443282634
Trained batch 300 in epoch 9, gen_loss = 0.38525059457831207, disc_loss = 0.0945407003999697
Trained batch 301 in epoch 9, gen_loss = 0.38490219813901067, disc_loss = 0.0946531813708905
Trained batch 302 in epoch 9, gen_loss = 0.38497622694709516, disc_loss = 0.09529921037172621
Trained batch 303 in epoch 9, gen_loss = 0.3847133476581228, disc_loss = 0.09528757265070453
Trained batch 304 in epoch 9, gen_loss = 0.3845674553366958, disc_loss = 0.09509958269105094
Trained batch 305 in epoch 9, gen_loss = 0.38468601700722005, disc_loss = 0.0955362635591597
Trained batch 306 in epoch 9, gen_loss = 0.3845136678665391, disc_loss = 0.09617593856255376
Trained batch 307 in epoch 9, gen_loss = 0.3844390426847068, disc_loss = 0.09601242055015807
Trained batch 308 in epoch 9, gen_loss = 0.3844029958869261, disc_loss = 0.09574008259235077
Trained batch 309 in epoch 9, gen_loss = 0.38443516939878464, disc_loss = 0.09552620258182287
Trained batch 310 in epoch 9, gen_loss = 0.3842045584771411, disc_loss = 0.09546181490686736
Trained batch 311 in epoch 9, gen_loss = 0.38427620720213806, disc_loss = 0.09557455327385703
Trained batch 312 in epoch 9, gen_loss = 0.38446661358633744, disc_loss = 0.09546462031670462
Trained batch 313 in epoch 9, gen_loss = 0.38418991953893833, disc_loss = 0.09530837797696233
Trained batch 314 in epoch 9, gen_loss = 0.384248746340237, disc_loss = 0.09507667933782887
Trained batch 315 in epoch 9, gen_loss = 0.38419393926293033, disc_loss = 0.09507101508376153
Trained batch 316 in epoch 9, gen_loss = 0.3839098808799256, disc_loss = 0.09590657086519977
Trained batch 317 in epoch 9, gen_loss = 0.38423298247767695, disc_loss = 0.09590494895717071
Trained batch 318 in epoch 9, gen_loss = 0.38444063744761725, disc_loss = 0.09563696518143329
Trained batch 319 in epoch 9, gen_loss = 0.38437609965913, disc_loss = 0.095411297067767
Trained batch 320 in epoch 9, gen_loss = 0.38416169175292103, disc_loss = 0.09530259412930947
Trained batch 321 in epoch 9, gen_loss = 0.38453494720392345, disc_loss = 0.09578928100928571
Trained batch 322 in epoch 9, gen_loss = 0.38434097221576763, disc_loss = 0.09577128221352957
Trained batch 323 in epoch 9, gen_loss = 0.3843034004079707, disc_loss = 0.09568892897072213
Trained batch 324 in epoch 9, gen_loss = 0.38422710753404177, disc_loss = 0.0957774624400414
Trained batch 325 in epoch 9, gen_loss = 0.3843923347767877, disc_loss = 0.09565266777698431
Trained batch 326 in epoch 9, gen_loss = 0.38440393458265776, disc_loss = 0.09542597114857548
Trained batch 327 in epoch 9, gen_loss = 0.38404672788228933, disc_loss = 0.09521959599380087
Trained batch 328 in epoch 9, gen_loss = 0.3838331187115614, disc_loss = 0.0951645298886444
Trained batch 329 in epoch 9, gen_loss = 0.38402717822428906, disc_loss = 0.09556738217220162
Trained batch 330 in epoch 9, gen_loss = 0.38427710717718405, disc_loss = 0.09536935051402297
Trained batch 331 in epoch 9, gen_loss = 0.38425746842859737, disc_loss = 0.09520824255803263
Trained batch 332 in epoch 9, gen_loss = 0.3841778588098091, disc_loss = 0.09500747702053718
Trained batch 333 in epoch 9, gen_loss = 0.38435043372258454, disc_loss = 0.09490252314079664
Trained batch 334 in epoch 9, gen_loss = 0.38435544998788124, disc_loss = 0.0948019185061775
Trained batch 335 in epoch 9, gen_loss = 0.38431616087577175, disc_loss = 0.09486503552068912
Trained batch 336 in epoch 9, gen_loss = 0.3843042107205009, disc_loss = 0.09471991580830837
Trained batch 337 in epoch 9, gen_loss = 0.3843594297061305, disc_loss = 0.09456070475059854
Trained batch 338 in epoch 9, gen_loss = 0.384492347769681, disc_loss = 0.09434232548164935
Trained batch 339 in epoch 9, gen_loss = 0.3846455136204467, disc_loss = 0.09429382670342046
Trained batch 340 in epoch 9, gen_loss = 0.384585378762564, disc_loss = 0.09483913807990439
Trained batch 341 in epoch 9, gen_loss = 0.3848458533311448, disc_loss = 0.09471510737938316
Trained batch 342 in epoch 9, gen_loss = 0.3851170499453392, disc_loss = 0.09453407213982444
Trained batch 343 in epoch 9, gen_loss = 0.38521250956800096, disc_loss = 0.09428455998449652
Trained batch 344 in epoch 9, gen_loss = 0.3851845965437267, disc_loss = 0.09407584289817707
Trained batch 345 in epoch 9, gen_loss = 0.3852235524554473, disc_loss = 0.0938297926981239
Trained batch 346 in epoch 9, gen_loss = 0.385111466050148, disc_loss = 0.09360683515603502
Trained batch 347 in epoch 9, gen_loss = 0.3851804118817565, disc_loss = 0.09344901895450278
Trained batch 348 in epoch 9, gen_loss = 0.3850855142048915, disc_loss = 0.09333958686529566
Trained batch 349 in epoch 9, gen_loss = 0.38511170331920896, disc_loss = 0.09358278839183705
Trained batch 350 in epoch 9, gen_loss = 0.3848301949579152, disc_loss = 0.0935147625693993
Trained batch 351 in epoch 9, gen_loss = 0.38483682566915045, disc_loss = 0.09350456401642243
Trained batch 352 in epoch 9, gen_loss = 0.3850076339991167, disc_loss = 0.09406656502263236
Trained batch 353 in epoch 9, gen_loss = 0.3851522794466908, disc_loss = 0.0938232540242416
Trained batch 354 in epoch 9, gen_loss = 0.38531887518687985, disc_loss = 0.09386593986984709
Trained batch 355 in epoch 9, gen_loss = 0.38542120313543954, disc_loss = 0.0936290495898156
Trained batch 356 in epoch 9, gen_loss = 0.3854826962163134, disc_loss = 0.09383165595546908
Trained batch 357 in epoch 9, gen_loss = 0.3852390493344328, disc_loss = 0.09459315374878614
Trained batch 358 in epoch 9, gen_loss = 0.3853879992261238, disc_loss = 0.0944613322828349
Trained batch 359 in epoch 9, gen_loss = 0.38543905777235826, disc_loss = 0.09433838681887008
Trained batch 360 in epoch 9, gen_loss = 0.38539051782556516, disc_loss = 0.09414184832599767
Trained batch 361 in epoch 9, gen_loss = 0.3853048549254955, disc_loss = 0.09392203505341355
Trained batch 362 in epoch 9, gen_loss = 0.38536832561670253, disc_loss = 0.09375677705734722
Trained batch 363 in epoch 9, gen_loss = 0.38537186330982615, disc_loss = 0.09356853105434841
Trained batch 364 in epoch 9, gen_loss = 0.38534584547558876, disc_loss = 0.09356344562176973
Trained batch 365 in epoch 9, gen_loss = 0.38520228948260915, disc_loss = 0.09414720713909043
Trained batch 366 in epoch 9, gen_loss = 0.38509407984625743, disc_loss = 0.09396673998305681
Trained batch 367 in epoch 9, gen_loss = 0.38503478625384363, disc_loss = 0.09380569465397655
Trained batch 368 in epoch 9, gen_loss = 0.3852941669665055, disc_loss = 0.09362662997005916
Trained batch 369 in epoch 9, gen_loss = 0.3855285214008512, disc_loss = 0.09350013712270035
Trained batch 370 in epoch 9, gen_loss = 0.38574833830572525, disc_loss = 0.09344876512905176
Trained batch 371 in epoch 9, gen_loss = 0.38569879768195975, disc_loss = 0.09340700430555209
Trained batch 372 in epoch 9, gen_loss = 0.3858247768063967, disc_loss = 0.09369303333515616
Trained batch 373 in epoch 9, gen_loss = 0.38572319628879986, disc_loss = 0.09398530901255295
Trained batch 374 in epoch 9, gen_loss = 0.3859125819603602, disc_loss = 0.09394157083332538
Trained batch 375 in epoch 9, gen_loss = 0.3858661579879675, disc_loss = 0.09373128240026454
Trained batch 376 in epoch 9, gen_loss = 0.3860140049568222, disc_loss = 0.09355398989591342
Trained batch 377 in epoch 9, gen_loss = 0.3858806645034482, disc_loss = 0.09371163953026687
Trained batch 378 in epoch 9, gen_loss = 0.3859251444682597, disc_loss = 0.09425464115968087
Trained batch 379 in epoch 9, gen_loss = 0.3860402368793362, disc_loss = 0.09411325096642893
Trained batch 380 in epoch 9, gen_loss = 0.38592148089189854, disc_loss = 0.09449388359348214
Trained batch 381 in epoch 9, gen_loss = 0.38587874466680105, disc_loss = 0.0943997979081231
Trained batch 382 in epoch 9, gen_loss = 0.38572219344872405, disc_loss = 0.09417570058460646
Trained batch 383 in epoch 9, gen_loss = 0.3855151078896597, disc_loss = 0.09426984459666225
Trained batch 384 in epoch 9, gen_loss = 0.385454617498757, disc_loss = 0.09442123411731286
Trained batch 385 in epoch 9, gen_loss = 0.3854007318307081, disc_loss = 0.09433646124686293
Trained batch 386 in epoch 9, gen_loss = 0.38550998324417635, disc_loss = 0.09417299277483647
Trained batch 387 in epoch 9, gen_loss = 0.38556431045698136, disc_loss = 0.09420174577263828
Trained batch 388 in epoch 9, gen_loss = 0.38538082005278923, disc_loss = 0.09445806366695536
Trained batch 389 in epoch 9, gen_loss = 0.3854382112622261, disc_loss = 0.09428439842393765
Trained batch 390 in epoch 9, gen_loss = 0.38557260493030937, disc_loss = 0.09480966721921016
Trained batch 391 in epoch 9, gen_loss = 0.3852452728897333, disc_loss = 0.09508746945090135
Trained batch 392 in epoch 9, gen_loss = 0.38509278151066856, disc_loss = 0.09505674128276094
Trained batch 393 in epoch 9, gen_loss = 0.3851348631802549, disc_loss = 0.09529505264448938
Trained batch 394 in epoch 9, gen_loss = 0.38491229788412024, disc_loss = 0.09519837047857574
Trained batch 395 in epoch 9, gen_loss = 0.3847277946017607, disc_loss = 0.09516397664191747
Trained batch 396 in epoch 9, gen_loss = 0.3849309193772693, disc_loss = 0.09509062939687099
Trained batch 397 in epoch 9, gen_loss = 0.38487522315290107, disc_loss = 0.09496933922882955
Trained batch 398 in epoch 9, gen_loss = 0.3848327211195365, disc_loss = 0.09491713110702976
Trained batch 399 in epoch 9, gen_loss = 0.38511643569916487, disc_loss = 0.09472129843663424
Trained batch 400 in epoch 9, gen_loss = 0.385303595974261, disc_loss = 0.09481366962993383
Trained batch 401 in epoch 9, gen_loss = 0.38523453714983974, disc_loss = 0.0947165878359877
Trained batch 402 in epoch 9, gen_loss = 0.3852618288239533, disc_loss = 0.09449767723573238
Trained batch 403 in epoch 9, gen_loss = 0.3852435098499945, disc_loss = 0.09427934609316659
Trained batch 404 in epoch 9, gen_loss = 0.3853313547961506, disc_loss = 0.09407660693022205
Trained batch 405 in epoch 9, gen_loss = 0.3852746623563649, disc_loss = 0.09394376262967369
Trained batch 406 in epoch 9, gen_loss = 0.385524431559319, disc_loss = 0.09401105612022138
Trained batch 407 in epoch 9, gen_loss = 0.3855260018551466, disc_loss = 0.09381984105315425
Trained batch 408 in epoch 9, gen_loss = 0.38544527020460234, disc_loss = 0.09376754665014067
Trained batch 409 in epoch 9, gen_loss = 0.38563666281903664, disc_loss = 0.093835573647989
Trained batch 410 in epoch 9, gen_loss = 0.38545160097072306, disc_loss = 0.09382406513857
Trained batch 411 in epoch 9, gen_loss = 0.38547981758285493, disc_loss = 0.09361563614361638
Trained batch 412 in epoch 9, gen_loss = 0.3856706962386286, disc_loss = 0.09346047037937306
Trained batch 413 in epoch 9, gen_loss = 0.3857743485610266, disc_loss = 0.09331573071273197
Trained batch 414 in epoch 9, gen_loss = 0.3856107643928873, disc_loss = 0.09343176951340164
Trained batch 415 in epoch 9, gen_loss = 0.38574272648503, disc_loss = 0.09387287827513109
Trained batch 416 in epoch 9, gen_loss = 0.38555724954576515, disc_loss = 0.09411163524918847
Trained batch 417 in epoch 9, gen_loss = 0.3857584461997571, disc_loss = 0.09397165457223448
Trained batch 418 in epoch 9, gen_loss = 0.385742282988348, disc_loss = 0.09380034193272095
Trained batch 419 in epoch 9, gen_loss = 0.3858478789173421, disc_loss = 0.09362510158902122
Trained batch 420 in epoch 9, gen_loss = 0.385784999527161, disc_loss = 0.09352478742457909
Trained batch 421 in epoch 9, gen_loss = 0.38571543896226523, disc_loss = 0.09333874301110964
Trained batch 422 in epoch 9, gen_loss = 0.3858198405509863, disc_loss = 0.09324193531845479
Trained batch 423 in epoch 9, gen_loss = 0.38591916124635145, disc_loss = 0.0932051469923331
Trained batch 424 in epoch 9, gen_loss = 0.38591288836563337, disc_loss = 0.09302244848626501
Trained batch 425 in epoch 9, gen_loss = 0.3858059670933535, disc_loss = 0.09292565737829102
Trained batch 426 in epoch 9, gen_loss = 0.38584508727668876, disc_loss = 0.092762737083456
Trained batch 427 in epoch 9, gen_loss = 0.38584016009329636, disc_loss = 0.09259311250785243
Trained batch 428 in epoch 9, gen_loss = 0.38577533063493963, disc_loss = 0.09269195994783393
Trained batch 429 in epoch 9, gen_loss = 0.38589544202699216, disc_loss = 0.09279338923651119
Trained batch 430 in epoch 9, gen_loss = 0.38624308948035585, disc_loss = 0.09261938990061355
Trained batch 431 in epoch 9, gen_loss = 0.38615700378324147, disc_loss = 0.09272791095146979
Trained batch 432 in epoch 9, gen_loss = 0.3861910317772806, disc_loss = 0.0925400802934452
Trained batch 433 in epoch 9, gen_loss = 0.38631243107642993, disc_loss = 0.09284047164615192
Trained batch 434 in epoch 9, gen_loss = 0.3861083476365298, disc_loss = 0.09318866298330583
Trained batch 435 in epoch 9, gen_loss = 0.386269772989214, disc_loss = 0.09301621658906956
Trained batch 436 in epoch 9, gen_loss = 0.38623606923379394, disc_loss = 0.0931271634190354
Trained batch 437 in epoch 9, gen_loss = 0.38614476615027205, disc_loss = 0.09348249446268972
Trained batch 438 in epoch 9, gen_loss = 0.3861947940463086, disc_loss = 0.09357653212667802
Trained batch 439 in epoch 9, gen_loss = 0.386208980361169, disc_loss = 0.09365235201972114
Trained batch 440 in epoch 9, gen_loss = 0.38599734515154444, disc_loss = 0.09411416492317201
Trained batch 441 in epoch 9, gen_loss = 0.3860585225990455, disc_loss = 0.0951577059616971
Trained batch 442 in epoch 9, gen_loss = 0.3860720263848725, disc_loss = 0.0951111305980159
Trained batch 443 in epoch 9, gen_loss = 0.3860126562282309, disc_loss = 0.09516810713679874
Trained batch 444 in epoch 9, gen_loss = 0.38586713366963893, disc_loss = 0.09511677787503164
Trained batch 445 in epoch 9, gen_loss = 0.3857637267275776, disc_loss = 0.0950394922788067
Trained batch 446 in epoch 9, gen_loss = 0.38577496242069825, disc_loss = 0.09500250628455573
Trained batch 447 in epoch 9, gen_loss = 0.38574764801056255, disc_loss = 0.09507594235765282
Trained batch 448 in epoch 9, gen_loss = 0.3855355334507596, disc_loss = 0.09547238617529781
Trained batch 449 in epoch 9, gen_loss = 0.3856690417064561, disc_loss = 0.09567924789049559
Trained batch 450 in epoch 9, gen_loss = 0.38570657911031053, disc_loss = 0.0955791682678124
Trained batch 451 in epoch 9, gen_loss = 0.3854995102547439, disc_loss = 0.09577635729858504
Trained batch 452 in epoch 9, gen_loss = 0.3854709381101937, disc_loss = 0.09566092787816233
Trained batch 453 in epoch 9, gen_loss = 0.3856054511955131, disc_loss = 0.09562807456930762
Trained batch 454 in epoch 9, gen_loss = 0.38563169303176165, disc_loss = 0.09557013995331395
Trained batch 455 in epoch 9, gen_loss = 0.38551714052364494, disc_loss = 0.09555666817540075
Trained batch 456 in epoch 9, gen_loss = 0.38540922816133605, disc_loss = 0.09544179413092671
Trained batch 457 in epoch 9, gen_loss = 0.3853701835571418, disc_loss = 0.09539610548270257
Trained batch 458 in epoch 9, gen_loss = 0.38537072664642125, disc_loss = 0.09539446144411441
Trained batch 459 in epoch 9, gen_loss = 0.3855013488103514, disc_loss = 0.0953306079943381
Trained batch 460 in epoch 9, gen_loss = 0.3853563325976601, disc_loss = 0.09526938263633958
Trained batch 461 in epoch 9, gen_loss = 0.38538772780528835, disc_loss = 0.09528838226055622
Trained batch 462 in epoch 9, gen_loss = 0.38537592207510063, disc_loss = 0.09513175041971982
Testing Epoch 9
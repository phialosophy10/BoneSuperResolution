/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 3.097907066345215, disc_loss = 0.5063937902450562
Trained batch 1 in epoch 0, gen_loss = 3.070704460144043, disc_loss = 0.9704383015632629
Trained batch 2 in epoch 0, gen_loss = 2.9849886894226074, disc_loss = 0.8228177825609843
Trained batch 3 in epoch 0, gen_loss = 2.958545506000519, disc_loss = 0.7204155996441841
Trained batch 4 in epoch 0, gen_loss = 2.9231377601623536, disc_loss = 0.649347323179245
Trained batch 5 in epoch 0, gen_loss = 2.9054903984069824, disc_loss = 0.593054011464119
Trained batch 6 in epoch 0, gen_loss = 2.8815585545131137, disc_loss = 0.5450697243213654
Trained batch 7 in epoch 0, gen_loss = 2.8810067176818848, disc_loss = 0.5062651708722115
Trained batch 8 in epoch 0, gen_loss = 2.861000325944689, disc_loss = 0.4720326413710912
Trained batch 9 in epoch 0, gen_loss = 2.8460516929626465, disc_loss = 0.443974195420742
Trained batch 10 in epoch 0, gen_loss = 2.8596591732718726, disc_loss = 0.4182500500570644
Trained batch 11 in epoch 0, gen_loss = 2.8631394505500793, disc_loss = 0.39478132749597233
Trained batch 12 in epoch 0, gen_loss = 2.8631088733673096, disc_loss = 0.3743388435015312
Trained batch 13 in epoch 0, gen_loss = 2.8442234311785017, disc_loss = 0.35680017194577623
Trained batch 14 in epoch 0, gen_loss = 2.8193556467692056, disc_loss = 0.34248150090376533
Trained batch 15 in epoch 0, gen_loss = 2.8199777603149414, disc_loss = 0.32787949685007334
Trained batch 16 in epoch 0, gen_loss = 2.831498805214377, disc_loss = 0.3142298565191381
Trained batch 17 in epoch 0, gen_loss = 2.8399810791015625, disc_loss = 0.30165689893894726
Trained batch 18 in epoch 0, gen_loss = 2.857094927837974, disc_loss = 0.2896454793057944
Trained batch 19 in epoch 0, gen_loss = 2.872480833530426, disc_loss = 0.2784696098417044
Trained batch 20 in epoch 0, gen_loss = 2.9089499428158714, disc_loss = 0.2688490233960606
Trained batch 21 in epoch 0, gen_loss = 2.928403854370117, disc_loss = 0.2612795216793364
Trained batch 22 in epoch 0, gen_loss = 2.944960874059926, disc_loss = 0.2549461408153824
Trained batch 23 in epoch 0, gen_loss = 2.9449257055918374, disc_loss = 0.24921822051207224
Trained batch 24 in epoch 0, gen_loss = 2.962350435256958, disc_loss = 0.24236533641815186
Trained batch 25 in epoch 0, gen_loss = 2.9626842003602247, disc_loss = 0.23625962120982316
Trained batch 26 in epoch 0, gen_loss = 2.963693927835535, disc_loss = 0.2300910414369018
Trained batch 27 in epoch 0, gen_loss = 2.965774749006544, disc_loss = 0.22360271109001978
Trained batch 28 in epoch 0, gen_loss = 2.975606737465694, disc_loss = 0.2174935487323794
Trained batch 29 in epoch 0, gen_loss = 2.9747804562250773, disc_loss = 0.21223956644535064
Trained batch 30 in epoch 0, gen_loss = 2.9736126084481516, disc_loss = 0.20698421328298508
Trained batch 31 in epoch 0, gen_loss = 2.9741918444633484, disc_loss = 0.20204694068524987
Trained batch 32 in epoch 0, gen_loss = 2.978642290288752, disc_loss = 0.19738262022535005
Trained batch 33 in epoch 0, gen_loss = 2.9772710730047787, disc_loss = 0.19327516875722828
Trained batch 34 in epoch 0, gen_loss = 2.980691739491054, disc_loss = 0.19017164813620704
Trained batch 35 in epoch 0, gen_loss = 2.973028520743052, disc_loss = 0.18722647511296803
Trained batch 36 in epoch 0, gen_loss = 2.9783541511844946, disc_loss = 0.18500526813236443
Trained batch 37 in epoch 0, gen_loss = 2.9836847531168083, disc_loss = 0.18212521291877093
Trained batch 38 in epoch 0, gen_loss = 2.9864659064855332, disc_loss = 0.17890002979682043
Trained batch 39 in epoch 0, gen_loss = 2.986046481132507, disc_loss = 0.1756505093537271
Trained batch 40 in epoch 0, gen_loss = 2.9997876911628536, disc_loss = 0.17232269330359087
Trained batch 41 in epoch 0, gen_loss = 2.9976936294918968, disc_loss = 0.16917665426929793
Trained batch 42 in epoch 0, gen_loss = 3.0010761327521744, disc_loss = 0.16607013110851132
Trained batch 43 in epoch 0, gen_loss = 3.0029263117096643, disc_loss = 0.1630635762756521
Trained batch 44 in epoch 0, gen_loss = 3.0005186716715495, disc_loss = 0.16044248367349306
Trained batch 45 in epoch 0, gen_loss = 2.9977698999902476, disc_loss = 0.1577292235325212
Trained batch 46 in epoch 0, gen_loss = 2.9963946697559765, disc_loss = 0.1551601561777135
Trained batch 47 in epoch 0, gen_loss = 2.9982000291347504, disc_loss = 0.15305044827982783
Trained batch 48 in epoch 0, gen_loss = 2.99790772613214, disc_loss = 0.1514066760333217
Trained batch 49 in epoch 0, gen_loss = 2.9975608253479002, disc_loss = 0.15136660680174827
Trained batch 50 in epoch 0, gen_loss = 2.99917926975325, disc_loss = 0.15270243541282766
Trained batch 51 in epoch 0, gen_loss = 3.0051468427364645, disc_loss = 0.15250964305148676
Trained batch 52 in epoch 0, gen_loss = 3.0017753367154105, disc_loss = 0.15072933844519112
Trained batch 53 in epoch 0, gen_loss = 3.0004953896557844, disc_loss = 0.14860120160436188
Trained batch 54 in epoch 0, gen_loss = 2.9990133719010785, disc_loss = 0.1467265273359689
Trained batch 55 in epoch 0, gen_loss = 3.003199598618916, disc_loss = 0.1446276048996619
Trained batch 56 in epoch 0, gen_loss = 3.00297903178031, disc_loss = 0.14257613190433435
Trained batch 57 in epoch 0, gen_loss = 3.0048910256089836, disc_loss = 0.14059530233900094
Trained batch 58 in epoch 0, gen_loss = 3.0000249814178983, disc_loss = 0.13876647656878172
Trained batch 59 in epoch 0, gen_loss = 2.9974504629770915, disc_loss = 0.13704900552208224
Trained batch 60 in epoch 0, gen_loss = 2.993750415864538, disc_loss = 0.13525027448891616
Trained batch 61 in epoch 0, gen_loss = 3.000654458999634, disc_loss = 0.13342473827182286
Trained batch 62 in epoch 0, gen_loss = 2.9997323808215914, disc_loss = 0.1317624193394468
Trained batch 63 in epoch 0, gen_loss = 2.9989636912941933, disc_loss = 0.1300938648346346
Trained batch 64 in epoch 0, gen_loss = 3.0006776516254132, disc_loss = 0.12847938964573236
Trained batch 65 in epoch 0, gen_loss = 2.998053196704749, disc_loss = 0.12689826719349984
Trained batch 66 in epoch 0, gen_loss = 2.9960604923874583, disc_loss = 0.12530850838703006
Trained batch 67 in epoch 0, gen_loss = 2.998951624421512, disc_loss = 0.12378726442180135
Trained batch 68 in epoch 0, gen_loss = 2.995270259138467, disc_loss = 0.12226898868338786
Trained batch 69 in epoch 0, gen_loss = 2.997367654527937, disc_loss = 0.12079737149178982
Trained batch 70 in epoch 0, gen_loss = 3.0001920444864623, disc_loss = 0.11942519399691635
Trained batch 71 in epoch 0, gen_loss = 3.0001417530907526, disc_loss = 0.1180821855345534
Trained batch 72 in epoch 0, gen_loss = 2.996449457455988, disc_loss = 0.11678627299221411
Trained batch 73 in epoch 0, gen_loss = 2.9950383837158614, disc_loss = 0.11547008511685841
Trained batch 74 in epoch 0, gen_loss = 2.996594092051188, disc_loss = 0.11413746885955334
Trained batch 75 in epoch 0, gen_loss = 2.9950739521729317, disc_loss = 0.11286419549172647
Trained batch 76 in epoch 0, gen_loss = 2.9913655999418975, disc_loss = 0.11163823308979536
Trained batch 77 in epoch 0, gen_loss = 2.990244358013838, disc_loss = 0.11044074554378405
Trained batch 78 in epoch 0, gen_loss = 2.991620667373078, disc_loss = 0.10926159643391266
Trained batch 79 in epoch 0, gen_loss = 2.990406346321106, disc_loss = 0.1081182603025809
Trained batch 80 in epoch 0, gen_loss = 2.9880326117998286, disc_loss = 0.1069725071321483
Trained batch 81 in epoch 0, gen_loss = 2.985852930603958, disc_loss = 0.10590620085642469
Trained batch 82 in epoch 0, gen_loss = 2.987344756183854, disc_loss = 0.1049070146540741
Trained batch 83 in epoch 0, gen_loss = 2.990112230891273, disc_loss = 0.10393234990936305
Trained batch 84 in epoch 0, gen_loss = 2.9866275843452006, disc_loss = 0.10297775819678517
Trained batch 85 in epoch 0, gen_loss = 2.989001068958016, disc_loss = 0.10219617403480549
Trained batch 86 in epoch 0, gen_loss = 2.98890846077053, disc_loss = 0.10166212542774691
Trained batch 87 in epoch 0, gen_loss = 2.9880625036629764, disc_loss = 0.10113071780440143
Trained batch 88 in epoch 0, gen_loss = 2.9861621669169223, disc_loss = 0.1005120441798916
Trained batch 89 in epoch 0, gen_loss = 2.981559427579244, disc_loss = 0.09973215606684487
Trained batch 90 in epoch 0, gen_loss = 2.9860071061731697, disc_loss = 0.09895927769101255
Trained batch 91 in epoch 0, gen_loss = 2.9868927546169446, disc_loss = 0.09813240473158658
Trained batch 92 in epoch 0, gen_loss = 2.984250553192631, disc_loss = 0.09726083858479415
Trained batch 93 in epoch 0, gen_loss = 2.987477462342445, disc_loss = 0.09642271191238407
Trained batch 94 in epoch 0, gen_loss = 2.9877061994452228, disc_loss = 0.09557779561728239
Trained batch 95 in epoch 0, gen_loss = 2.9884644572933516, disc_loss = 0.0947170147264842
Trained batch 96 in epoch 0, gen_loss = 2.9927088624423313, disc_loss = 0.09391583217135102
Trained batch 97 in epoch 0, gen_loss = 2.989504132952009, disc_loss = 0.09311984653337574
Trained batch 98 in epoch 0, gen_loss = 2.988497676271381, disc_loss = 0.09231297934258526
Trained batch 99 in epoch 0, gen_loss = 2.9901791167259217, disc_loss = 0.0915455322433263
Trained batch 100 in epoch 0, gen_loss = 2.988936207082012, disc_loss = 0.09076580766699102
Trained batch 101 in epoch 0, gen_loss = 2.9874090073155424, disc_loss = 0.09001376512734328
Trained batch 102 in epoch 0, gen_loss = 2.9863147967070054, disc_loss = 0.08929762732490752
Trained batch 103 in epoch 0, gen_loss = 2.983698601906116, disc_loss = 0.08860229994528569
Trained batch 104 in epoch 0, gen_loss = 2.9831209818522137, disc_loss = 0.08789086574245067
Trained batch 105 in epoch 0, gen_loss = 2.982125939063306, disc_loss = 0.08715737825435288
Trained batch 106 in epoch 0, gen_loss = 2.9812785219923357, disc_loss = 0.08644510807347631
Trained batch 107 in epoch 0, gen_loss = 2.983134728890878, disc_loss = 0.08573870552289817
Trained batch 108 in epoch 0, gen_loss = 2.9842509501570955, disc_loss = 0.08504421905605891
Trained batch 109 in epoch 0, gen_loss = 2.9881564552133733, disc_loss = 0.0843902882611887
Trained batch 110 in epoch 0, gen_loss = 2.9856807541202857, disc_loss = 0.08379239378379541
Trained batch 111 in epoch 0, gen_loss = 2.984513040099825, disc_loss = 0.08314224205345713
Trained batch 112 in epoch 0, gen_loss = 2.9869159175231395, disc_loss = 0.08254272442113246
Trained batch 113 in epoch 0, gen_loss = 2.9921911013753792, disc_loss = 0.08197737247438024
Trained batch 114 in epoch 0, gen_loss = 2.9924044816390327, disc_loss = 0.08143589866712042
Trained batch 115 in epoch 0, gen_loss = 2.9916014712432335, disc_loss = 0.08089482040016045
Trained batch 116 in epoch 0, gen_loss = 2.9921837668133597, disc_loss = 0.08036318130823028
Trained batch 117 in epoch 0, gen_loss = 2.9918524713839516, disc_loss = 0.07979289743007492
Trained batch 118 in epoch 0, gen_loss = 2.9917146558521175, disc_loss = 0.079226681790432
Trained batch 119 in epoch 0, gen_loss = 2.9935829897721606, disc_loss = 0.07870117744120458
Trained batch 120 in epoch 0, gen_loss = 2.993545173613493, disc_loss = 0.07818041960439406
Trained batch 121 in epoch 0, gen_loss = 2.9963284730911255, disc_loss = 0.07765937249222007
Trained batch 122 in epoch 0, gen_loss = 2.995468389697191, disc_loss = 0.07716301078264548
Trained batch 123 in epoch 0, gen_loss = 2.9945815820847788, disc_loss = 0.07664167968886754
Trained batch 124 in epoch 0, gen_loss = 2.993675806045532, disc_loss = 0.07619440848380327
Trained batch 125 in epoch 0, gen_loss = 2.9903751536021157, disc_loss = 0.07587478949230105
Trained batch 126 in epoch 0, gen_loss = 2.9925483774951123, disc_loss = 0.07559543666906479
Trained batch 127 in epoch 0, gen_loss = 2.995941726490855, disc_loss = 0.07509622255747672
Trained batch 128 in epoch 0, gen_loss = 2.9957513938578524, disc_loss = 0.07459909584402113
Trained batch 129 in epoch 0, gen_loss = 2.9937098558132464, disc_loss = 0.0741175461990329
Trained batch 130 in epoch 0, gen_loss = 2.9947822676360154, disc_loss = 0.07363484573074197
Trained batch 131 in epoch 0, gen_loss = 2.9951616832704255, disc_loss = 0.07313214651323065
Trained batch 132 in epoch 0, gen_loss = 2.994501565632067, disc_loss = 0.07264132763056043
Trained batch 133 in epoch 0, gen_loss = 2.994278559044226, disc_loss = 0.07216506087527012
Trained batch 134 in epoch 0, gen_loss = 2.9958151887964317, disc_loss = 0.07169166766452016
Trained batch 135 in epoch 0, gen_loss = 2.994257523733027, disc_loss = 0.07125185903586338
Trained batch 136 in epoch 0, gen_loss = 2.9932477561226727, disc_loss = 0.07080606306923458
Trained batch 137 in epoch 0, gen_loss = 2.9947648635808974, disc_loss = 0.07037211336073992
Trained batch 138 in epoch 0, gen_loss = 2.9970018743611067, disc_loss = 0.06994830478290967
Trained batch 139 in epoch 0, gen_loss = 2.997207638195583, disc_loss = 0.06952436465570437
Trained batch 140 in epoch 0, gen_loss = 2.9954628504759877, disc_loss = 0.06911489554079818
Trained batch 141 in epoch 0, gen_loss = 2.9920368563960977, disc_loss = 0.06869617622332569
Trained batch 142 in epoch 0, gen_loss = 2.9905896653662194, disc_loss = 0.06829188802194866
Trained batch 143 in epoch 0, gen_loss = 2.987681600782606, disc_loss = 0.0679084017206656
Trained batch 144 in epoch 0, gen_loss = 2.9843418746158994, disc_loss = 0.06771976867176849
Trained batch 145 in epoch 0, gen_loss = 2.9869116985634583, disc_loss = 0.06754791197264949
Trained batch 146 in epoch 0, gen_loss = 2.9880263464791432, disc_loss = 0.06719193730794755
Trained batch 147 in epoch 0, gen_loss = 2.9872077155757593, disc_loss = 0.06695969452187922
Trained batch 148 in epoch 0, gen_loss = 2.986713209408242, disc_loss = 0.06662830949492203
Trained batch 149 in epoch 0, gen_loss = 2.9858393383026125, disc_loss = 0.06627110517583787
Trained batch 150 in epoch 0, gen_loss = 2.9840316804039557, disc_loss = 0.06588311481986515
Trained batch 151 in epoch 0, gen_loss = 2.983688820349543, disc_loss = 0.06551078562686023
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 3.1636643409729004, disc_loss = 0.006977210287004709
Trained batch 1 in epoch 1, gen_loss = 2.8129138946533203, disc_loss = 0.023709920467808843
Trained batch 2 in epoch 1, gen_loss = 2.813593626022339, disc_loss = 0.0484273962986966
Trained batch 3 in epoch 1, gen_loss = 2.920847713947296, disc_loss = 0.04573261609766632
Trained batch 4 in epoch 1, gen_loss = 3.0719651699066164, disc_loss = 0.04520297097042203
Trained batch 5 in epoch 1, gen_loss = 3.0909658670425415, disc_loss = 0.04346656403504312
Trained batch 6 in epoch 1, gen_loss = 3.0073695523398265, disc_loss = 0.04291501834190318
Trained batch 7 in epoch 1, gen_loss = 2.9830303490161896, disc_loss = 0.04068514198297635
Trained batch 8 in epoch 1, gen_loss = 2.9647141297658286, disc_loss = 0.03708753657216827
Trained batch 9 in epoch 1, gen_loss = 2.942494010925293, disc_loss = 0.03417929545976221
Trained batch 10 in epoch 1, gen_loss = 2.9732431281696665, disc_loss = 0.031844153534621
Trained batch 11 in epoch 1, gen_loss = 2.9737279216448465, disc_loss = 0.0296063234951968
Trained batch 12 in epoch 1, gen_loss = 2.9566961435171275, disc_loss = 0.02799575149010007
Trained batch 13 in epoch 1, gen_loss = 2.933013047490801, disc_loss = 0.026660296567050473
Trained batch 14 in epoch 1, gen_loss = 2.956908130645752, disc_loss = 0.02550070798024535
Trained batch 15 in epoch 1, gen_loss = 2.9586736261844635, disc_loss = 0.02424252705532126
Trained batch 16 in epoch 1, gen_loss = 2.9682057605070225, disc_loss = 0.023168825626592424
Trained batch 17 in epoch 1, gen_loss = 2.9807304673724704, disc_loss = 0.02214712367600037
Trained batch 18 in epoch 1, gen_loss = 2.9750331326534876, disc_loss = 0.02122547386802341
Trained batch 19 in epoch 1, gen_loss = 2.976699423789978, disc_loss = 0.02042904405388981
Trained batch 20 in epoch 1, gen_loss = 2.9640460582006547, disc_loss = 0.019735097596865325
Trained batch 21 in epoch 1, gen_loss = 2.968596089969982, disc_loss = 0.019104292446916752
Trained batch 22 in epoch 1, gen_loss = 2.9687158543130625, disc_loss = 0.01848869005461102
Trained batch 23 in epoch 1, gen_loss = 2.9682268699010215, disc_loss = 0.018009442234567057
Trained batch 24 in epoch 1, gen_loss = 2.963136043548584, disc_loss = 0.017548904959112405
Trained batch 25 in epoch 1, gen_loss = 2.954559188622695, disc_loss = 0.017094224064539257
Trained batch 26 in epoch 1, gen_loss = 2.9507046893790916, disc_loss = 0.016696410391617705
Trained batch 27 in epoch 1, gen_loss = 2.950929658753531, disc_loss = 0.016228173801209778
Trained batch 28 in epoch 1, gen_loss = 2.946744787281957, disc_loss = 0.015870573713668977
Trained batch 29 in epoch 1, gen_loss = 2.9315661748250323, disc_loss = 0.01586767137826731
Trained batch 30 in epoch 1, gen_loss = 2.934574073360812, disc_loss = 0.015842078171009497
Trained batch 31 in epoch 1, gen_loss = 2.942056432366371, disc_loss = 0.015559652158117387
Trained batch 32 in epoch 1, gen_loss = 2.9451004880847353, disc_loss = 0.01533003902824765
Trained batch 33 in epoch 1, gen_loss = 2.9563766156925873, disc_loss = 0.015096405993544441
Trained batch 34 in epoch 1, gen_loss = 2.9529612609318323, disc_loss = 0.014837089773001416
Trained batch 35 in epoch 1, gen_loss = 2.9462055563926697, disc_loss = 0.014569670330577841
Trained batch 36 in epoch 1, gen_loss = 2.9489283239519275, disc_loss = 0.01427966106456478
Trained batch 37 in epoch 1, gen_loss = 2.9491390554528487, disc_loss = 0.014050899851626079
Trained batch 38 in epoch 1, gen_loss = 2.9490448267031937, disc_loss = 0.013823629780791892
Trained batch 39 in epoch 1, gen_loss = 2.952126753330231, disc_loss = 0.013575067790225149
Trained batch 40 in epoch 1, gen_loss = 2.9558333303870223, disc_loss = 0.013403678278824905
Trained batch 41 in epoch 1, gen_loss = 2.954341246968224, disc_loss = 0.013202145529378737
Trained batch 42 in epoch 1, gen_loss = 2.9525260758954426, disc_loss = 0.01296824784299662
Trained batch 43 in epoch 1, gen_loss = 2.9486179026690396, disc_loss = 0.012775508962063626
Trained batch 44 in epoch 1, gen_loss = 2.945683723025852, disc_loss = 0.012662457291864687
Trained batch 45 in epoch 1, gen_loss = 2.9400748480921206, disc_loss = 0.012604695694197131
Trained batch 46 in epoch 1, gen_loss = 2.9408363687231187, disc_loss = 0.012465000697510673
Trained batch 47 in epoch 1, gen_loss = 2.93496706088384, disc_loss = 0.012309990968788043
Trained batch 48 in epoch 1, gen_loss = 2.9358339455662943, disc_loss = 0.012178454605140249
Trained batch 49 in epoch 1, gen_loss = 2.933013162612915, disc_loss = 0.012067819386720658
Trained batch 50 in epoch 1, gen_loss = 2.936561238531973, disc_loss = 0.011991018210263812
Trained batch 51 in epoch 1, gen_loss = 2.9332816279851475, disc_loss = 0.011952279135584831
Trained batch 52 in epoch 1, gen_loss = 2.9318814682510665, disc_loss = 0.011848763633027391
Trained batch 53 in epoch 1, gen_loss = 2.93933309007574, disc_loss = 0.011725751890076531
Trained batch 54 in epoch 1, gen_loss = 2.937582492828369, disc_loss = 0.011636699905449693
Trained batch 55 in epoch 1, gen_loss = 2.9444939281259264, disc_loss = 0.01153888929236148
Trained batch 56 in epoch 1, gen_loss = 2.944681874492712, disc_loss = 0.011401570459272255
Trained batch 57 in epoch 1, gen_loss = 2.948119011418573, disc_loss = 0.01126139121258567
Trained batch 58 in epoch 1, gen_loss = 2.9459335238246593, disc_loss = 0.011161322421315362
Trained batch 59 in epoch 1, gen_loss = 2.9434049924214682, disc_loss = 0.01108618473323683
Trained batch 60 in epoch 1, gen_loss = 2.9419551130200996, disc_loss = 0.010992961347897033
Trained batch 61 in epoch 1, gen_loss = 2.939330827805304, disc_loss = 0.01091360364620003
Trained batch 62 in epoch 1, gen_loss = 2.939379033588228, disc_loss = 0.01081176499821364
Trained batch 63 in epoch 1, gen_loss = 2.9360568821430206, disc_loss = 0.010714834621467162
Trained batch 64 in epoch 1, gen_loss = 2.9336670068594124, disc_loss = 0.010631244794393962
Trained batch 65 in epoch 1, gen_loss = 2.929496570066972, disc_loss = 0.0105631214241977
Trained batch 66 in epoch 1, gen_loss = 2.92595752317514, disc_loss = 0.010527041372356575
Trained batch 67 in epoch 1, gen_loss = 2.927234109710245, disc_loss = 0.010456029853016576
Trained batch 68 in epoch 1, gen_loss = 2.9296093643575474, disc_loss = 0.010367976940250483
Trained batch 69 in epoch 1, gen_loss = 2.9268957240240914, disc_loss = 0.010287487819524748
Trained batch 70 in epoch 1, gen_loss = 2.9250630224254768, disc_loss = 0.010214880102274703
Trained batch 71 in epoch 1, gen_loss = 2.920841889248954, disc_loss = 0.010135130808016079
Trained batch 72 in epoch 1, gen_loss = 2.9228953074102533, disc_loss = 0.010040347352751519
Trained batch 73 in epoch 1, gen_loss = 2.9220753231564083, disc_loss = 0.009964186298610593
Trained batch 74 in epoch 1, gen_loss = 2.920001049041748, disc_loss = 0.009900389397516847
Trained batch 75 in epoch 1, gen_loss = 2.9183985057630037, disc_loss = 0.009859157667960972
Trained batch 76 in epoch 1, gen_loss = 2.921403476170131, disc_loss = 0.00978887539852846
Trained batch 77 in epoch 1, gen_loss = 2.9175201868399596, disc_loss = 0.009714578699248914
Trained batch 78 in epoch 1, gen_loss = 2.9168519249445275, disc_loss = 0.009653465129741573
Trained batch 79 in epoch 1, gen_loss = 2.9214355647563934, disc_loss = 0.009580841945717112
Trained batch 80 in epoch 1, gen_loss = 2.9256473500051614, disc_loss = 0.009505460363594287
Trained batch 81 in epoch 1, gen_loss = 2.9226984076383635, disc_loss = 0.009442082472804298
Trained batch 82 in epoch 1, gen_loss = 2.9257489773164314, disc_loss = 0.009381734679105231
Trained batch 83 in epoch 1, gen_loss = 2.923881491025289, disc_loss = 0.009327241566054346
Trained batch 84 in epoch 1, gen_loss = 2.924557040719425, disc_loss = 0.009268969738417688
Trained batch 85 in epoch 1, gen_loss = 2.922635100608648, disc_loss = 0.009231354323822225
Trained batch 86 in epoch 1, gen_loss = 2.92113706983369, disc_loss = 0.009174429460953194
Trained batch 87 in epoch 1, gen_loss = 2.9211718223311682, disc_loss = 0.00912102534361607
Trained batch 88 in epoch 1, gen_loss = 2.920620888806461, disc_loss = 0.009065530961379409
Trained batch 89 in epoch 1, gen_loss = 2.9197105328241983, disc_loss = 0.009000520503872799
Trained batch 90 in epoch 1, gen_loss = 2.9234630380358015, disc_loss = 0.008950283768801736
Trained batch 91 in epoch 1, gen_loss = 2.9235168228978696, disc_loss = 0.008892798727965388
Trained batch 92 in epoch 1, gen_loss = 2.9224296513424126, disc_loss = 0.00883219385349382
Trained batch 93 in epoch 1, gen_loss = 2.91969411170229, disc_loss = 0.008787801496664737
Trained batch 94 in epoch 1, gen_loss = 2.9211113151751067, disc_loss = 0.008745868055542049
Trained batch 95 in epoch 1, gen_loss = 2.919752043982347, disc_loss = 0.008697993265135059
Trained batch 96 in epoch 1, gen_loss = 2.922995599274783, disc_loss = 0.008656962810698705
Trained batch 97 in epoch 1, gen_loss = 2.9261315988034617, disc_loss = 0.00861032148205428
Trained batch 98 in epoch 1, gen_loss = 2.9256407419840493, disc_loss = 0.00855345347886811
Trained batch 99 in epoch 1, gen_loss = 2.9234371280670164, disc_loss = 0.008607401915360241
Trained batch 100 in epoch 1, gen_loss = 2.923350150042241, disc_loss = 0.00871831288625772
Trained batch 101 in epoch 1, gen_loss = 2.922901794022205, disc_loss = 0.008723450379500933
Trained batch 102 in epoch 1, gen_loss = 2.924887509021944, disc_loss = 0.00871962284696406
Trained batch 103 in epoch 1, gen_loss = 2.922437058045314, disc_loss = 0.008755772511134498
Trained batch 104 in epoch 1, gen_loss = 2.9221347422826858, disc_loss = 0.008792109727593405
Trained batch 105 in epoch 1, gen_loss = 2.9263832186752894, disc_loss = 0.008775952964019522
Trained batch 106 in epoch 1, gen_loss = 2.9264762713530352, disc_loss = 0.008756248495828744
Trained batch 107 in epoch 1, gen_loss = 2.927495132993769, disc_loss = 0.00875130378322124
Trained batch 108 in epoch 1, gen_loss = 2.9286211805606106, disc_loss = 0.00874702303260223
Trained batch 109 in epoch 1, gen_loss = 2.928237700462341, disc_loss = 0.008709497375159778
Trained batch 110 in epoch 1, gen_loss = 2.926350922197909, disc_loss = 0.008659024804679526
Trained batch 111 in epoch 1, gen_loss = 2.9264307554279054, disc_loss = 0.008614069694885984
Trained batch 112 in epoch 1, gen_loss = 2.928874119193153, disc_loss = 0.008568137509138447
Trained batch 113 in epoch 1, gen_loss = 2.928107029513309, disc_loss = 0.008528796416756353
Trained batch 114 in epoch 1, gen_loss = 2.9287396970002546, disc_loss = 0.008500358595958223
Trained batch 115 in epoch 1, gen_loss = 2.9293700168872703, disc_loss = 0.008472052446951896
Trained batch 116 in epoch 1, gen_loss = 2.930852942996555, disc_loss = 0.008437988312485127
Trained batch 117 in epoch 1, gen_loss = 2.927224563340009, disc_loss = 0.008587204207966135
Trained batch 118 in epoch 1, gen_loss = 2.9211628036338744, disc_loss = 0.009989853576608315
Trained batch 119 in epoch 1, gen_loss = 2.9249488592147825, disc_loss = 0.010688941526071478
Trained batch 120 in epoch 1, gen_loss = 2.9277833985888266, disc_loss = 0.010826837690931953
Trained batch 121 in epoch 1, gen_loss = 2.927838833605657, disc_loss = 0.010902777485946407
Trained batch 122 in epoch 1, gen_loss = 2.923631450994228, disc_loss = 0.011035865161386205
Trained batch 123 in epoch 1, gen_loss = 2.9238592386245728, disc_loss = 0.011084764839089926
Trained batch 124 in epoch 1, gen_loss = 2.9243809967041017, disc_loss = 0.011125749323517084
Trained batch 125 in epoch 1, gen_loss = 2.9260913568829734, disc_loss = 0.011107493166087402
Trained batch 126 in epoch 1, gen_loss = 2.9252822493004986, disc_loss = 0.011064690552417218
Trained batch 127 in epoch 1, gen_loss = 2.9221181254833937, disc_loss = 0.011384712161088828
Trained batch 128 in epoch 1, gen_loss = 2.9182627348936805, disc_loss = 0.011829057036964007
Trained batch 129 in epoch 1, gen_loss = 2.915611067185035, disc_loss = 0.01193034122339808
Trained batch 130 in epoch 1, gen_loss = 2.918856163971297, disc_loss = 0.012251539859664803
Trained batch 131 in epoch 1, gen_loss = 2.9219307845289055, disc_loss = 0.012407188536599278
Trained batch 132 in epoch 1, gen_loss = 2.9217095303356198, disc_loss = 0.012438987913940634
Trained batch 133 in epoch 1, gen_loss = 2.91891809719712, disc_loss = 0.012464808390489709
Trained batch 134 in epoch 1, gen_loss = 2.92078130863331, disc_loss = 0.012428874284442929
Trained batch 135 in epoch 1, gen_loss = 2.924226511927212, disc_loss = 0.012375481211005108
Trained batch 136 in epoch 1, gen_loss = 2.9262012060541305, disc_loss = 0.012326225682576426
Trained batch 137 in epoch 1, gen_loss = 2.9251642088959184, disc_loss = 0.012271448656025788
Trained batch 138 in epoch 1, gen_loss = 2.926024795436173, disc_loss = 0.012213288494821289
Trained batch 139 in epoch 1, gen_loss = 2.9256339294569833, disc_loss = 0.012148596795408853
Trained batch 140 in epoch 1, gen_loss = 2.927811367291931, disc_loss = 0.01208662059065615
Trained batch 141 in epoch 1, gen_loss = 2.930127226131063, disc_loss = 0.012022739607499729
Trained batch 142 in epoch 1, gen_loss = 2.9301332577125176, disc_loss = 0.011964761575527645
Trained batch 143 in epoch 1, gen_loss = 2.929488749967681, disc_loss = 0.011908084686082374
Trained batch 144 in epoch 1, gen_loss = 2.929015851842946, disc_loss = 0.011849414826980953
Trained batch 145 in epoch 1, gen_loss = 2.9278435625442087, disc_loss = 0.01181735394343938
Trained batch 146 in epoch 1, gen_loss = 2.9264794774606924, disc_loss = 0.011781845910183223
Trained batch 147 in epoch 1, gen_loss = 2.927721969179205, disc_loss = 0.011746424684502385
Trained batch 148 in epoch 1, gen_loss = 2.9265899034154494, disc_loss = 0.011703023571371032
Trained batch 149 in epoch 1, gen_loss = 2.927192587852478, disc_loss = 0.0116442237701267
Trained batch 150 in epoch 1, gen_loss = 2.928231823523313, disc_loss = 0.011591999942671186
Trained batch 151 in epoch 1, gen_loss = 2.9275725954457332, disc_loss = 0.011540716224484831
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 3.300781726837158, disc_loss = 0.0030250726267695427
Trained batch 1 in epoch 2, gen_loss = 3.1979658603668213, disc_loss = 0.0028593449387699366
Trained batch 2 in epoch 2, gen_loss = 3.082069714864095, disc_loss = 0.0032055243694533906
Trained batch 3 in epoch 2, gen_loss = 3.029507637023926, disc_loss = 0.003911880252417177
Trained batch 4 in epoch 2, gen_loss = 3.0640753746032714, disc_loss = 0.003912130044773221
Trained batch 5 in epoch 2, gen_loss = 3.090887943903605, disc_loss = 0.0038265955712025366
Trained batch 6 in epoch 2, gen_loss = 3.1599157197134837, disc_loss = 0.00378553506119975
Trained batch 7 in epoch 2, gen_loss = 3.113173246383667, disc_loss = 0.003852020454360172
Trained batch 8 in epoch 2, gen_loss = 3.0959374639723034, disc_loss = 0.0038137093652039766
Trained batch 9 in epoch 2, gen_loss = 3.0756327629089357, disc_loss = 0.003673027199693024
Trained batch 10 in epoch 2, gen_loss = 3.0528132048520176, disc_loss = 0.003612125694582408
Trained batch 11 in epoch 2, gen_loss = 3.0439926187197366, disc_loss = 0.003537096180176983
Trained batch 12 in epoch 2, gen_loss = 3.0278378633352427, disc_loss = 0.0034853850957006216
Trained batch 13 in epoch 2, gen_loss = 3.0232363768986295, disc_loss = 0.003480414377658495
Trained batch 14 in epoch 2, gen_loss = 3.0200206597646075, disc_loss = 0.003429137992983063
Trained batch 15 in epoch 2, gen_loss = 3.043573632836342, disc_loss = 0.003346968223922886
Trained batch 16 in epoch 2, gen_loss = 3.030015608843635, disc_loss = 0.003286346615127781
Trained batch 17 in epoch 2, gen_loss = 3.030479113260905, disc_loss = 0.003256729196032716
Trained batch 18 in epoch 2, gen_loss = 3.0311102365192615, disc_loss = 0.00322064089490787
Trained batch 19 in epoch 2, gen_loss = 3.0271360874176025, disc_loss = 0.0031618224573321642
Trained batch 20 in epoch 2, gen_loss = 3.035335200173514, disc_loss = 0.0031705223844342286
Trained batch 21 in epoch 2, gen_loss = 3.023772033778104, disc_loss = 0.003193797067400407
Trained batch 22 in epoch 2, gen_loss = 3.0161310900812563, disc_loss = 0.0032287179188721852
Trained batch 23 in epoch 2, gen_loss = 3.029298891623815, disc_loss = 0.0032521243556402624
Trained batch 24 in epoch 2, gen_loss = 3.021713972091675, disc_loss = 0.003270734213292599
Trained batch 25 in epoch 2, gen_loss = 3.027608798100398, disc_loss = 0.003290574773787879
Trained batch 26 in epoch 2, gen_loss = 3.022275174105609, disc_loss = 0.0032539184256974193
Trained batch 27 in epoch 2, gen_loss = 3.0103424787521362, disc_loss = 0.0033136422030760775
Trained batch 28 in epoch 2, gen_loss = 3.0181893233595223, disc_loss = 0.0033263312492134243
Trained batch 29 in epoch 2, gen_loss = 3.0201607942581177, disc_loss = 0.003371038365488251
Trained batch 30 in epoch 2, gen_loss = 3.021702189599314, disc_loss = 0.0034914768691505153
Trained batch 31 in epoch 2, gen_loss = 3.017245687544346, disc_loss = 0.0036445658188313246
Trained batch 32 in epoch 2, gen_loss = 3.0126456853115195, disc_loss = 0.0037439829020789175
Trained batch 33 in epoch 2, gen_loss = 3.007064665065092, disc_loss = 0.0037507205544149175
Trained batch 34 in epoch 2, gen_loss = 3.0027847153799874, disc_loss = 0.0036995109569813523
Trained batch 35 in epoch 2, gen_loss = 3.0018268558714123, disc_loss = 0.003653585386928171
Trained batch 36 in epoch 2, gen_loss = 3.007718756392195, disc_loss = 0.0036114267564403848
Trained batch 37 in epoch 2, gen_loss = 3.0120690433602584, disc_loss = 0.0035667611825230872
Trained batch 38 in epoch 2, gen_loss = 3.0035464457976513, disc_loss = 0.003527666221205623
Trained batch 39 in epoch 2, gen_loss = 2.9918361067771913, disc_loss = 0.0035873621643986555
Trained batch 40 in epoch 2, gen_loss = 2.9917340162323742, disc_loss = 0.0035854134674570184
Trained batch 41 in epoch 2, gen_loss = 2.9888952459607805, disc_loss = 0.003568289751586105
Trained batch 42 in epoch 2, gen_loss = 2.9962650676106297, disc_loss = 0.003567396809325315
Trained batch 43 in epoch 2, gen_loss = 2.9982715411619707, disc_loss = 0.0035645527003163643
Trained batch 44 in epoch 2, gen_loss = 3.0034160243140327, disc_loss = 0.0035514277819958
Trained batch 45 in epoch 2, gen_loss = 3.0087050562319546, disc_loss = 0.0035211844521615167
Trained batch 46 in epoch 2, gen_loss = 3.010656326375109, disc_loss = 0.003485842786253767
Trained batch 47 in epoch 2, gen_loss = 3.001293256878853, disc_loss = 0.003461671711799378
Trained batch 48 in epoch 2, gen_loss = 2.996839022149845, disc_loss = 0.0034410779326393896
Trained batch 49 in epoch 2, gen_loss = 2.99783522605896, disc_loss = 0.003443529009819031
Trained batch 50 in epoch 2, gen_loss = 2.9900849566740146, disc_loss = 0.0034855098792297
Trained batch 51 in epoch 2, gen_loss = 2.989100864300361, disc_loss = 0.003503858998346214
Trained batch 52 in epoch 2, gen_loss = 2.9905327176148035, disc_loss = 0.003505836069619037
Trained batch 53 in epoch 2, gen_loss = 2.9838478918428772, disc_loss = 0.0035176077055641347
Trained batch 54 in epoch 2, gen_loss = 2.976862330870195, disc_loss = 0.00353487445126203
Trained batch 55 in epoch 2, gen_loss = 2.9766287888799394, disc_loss = 0.003529040504612827
Trained batch 56 in epoch 2, gen_loss = 2.976051184169033, disc_loss = 0.0035310178349742243
Trained batch 57 in epoch 2, gen_loss = 2.979903591090235, disc_loss = 0.0035205926216239558
Trained batch 58 in epoch 2, gen_loss = 2.9828981262142373, disc_loss = 0.0035090028837133766
Trained batch 59 in epoch 2, gen_loss = 2.9793557365735372, disc_loss = 0.0035073072649538517
Trained batch 60 in epoch 2, gen_loss = 2.978410060288476, disc_loss = 0.003486756433839681
Trained batch 61 in epoch 2, gen_loss = 2.973416374575707, disc_loss = 0.0034684705765797726
Trained batch 62 in epoch 2, gen_loss = 2.9753440258994934, disc_loss = 0.0034445468816787952
Trained batch 63 in epoch 2, gen_loss = 2.9715763740241528, disc_loss = 0.0034194940963061526
Trained batch 64 in epoch 2, gen_loss = 2.9760139868809627, disc_loss = 0.003413818361094365
Trained batch 65 in epoch 2, gen_loss = 2.9697977485078755, disc_loss = 0.0034140132078336496
Trained batch 66 in epoch 2, gen_loss = 2.9682443141937256, disc_loss = 0.003418389401996314
Trained batch 67 in epoch 2, gen_loss = 2.968506529050715, disc_loss = 0.0034106362761710494
Trained batch 68 in epoch 2, gen_loss = 2.96661685169607, disc_loss = 0.0033995193442788677
Trained batch 69 in epoch 2, gen_loss = 2.971092006138393, disc_loss = 0.0033976691874808497
Trained batch 70 in epoch 2, gen_loss = 2.9650100318478865, disc_loss = 0.0034084384441113386
Trained batch 71 in epoch 2, gen_loss = 2.9638012746969857, disc_loss = 0.0034106181669307668
Trained batch 72 in epoch 2, gen_loss = 2.9690844490103525, disc_loss = 0.003415204657956141
Trained batch 73 in epoch 2, gen_loss = 2.9665768758670703, disc_loss = 0.003403617084856976
Trained batch 74 in epoch 2, gen_loss = 2.963390474319458, disc_loss = 0.0033844653672228256
Trained batch 75 in epoch 2, gen_loss = 2.9616779528166117, disc_loss = 0.003368872704940211
Trained batch 76 in epoch 2, gen_loss = 2.963169292970137, disc_loss = 0.0033500247934300986
Trained batch 77 in epoch 2, gen_loss = 2.9615385960309935, disc_loss = 0.003335646698430467
Trained batch 78 in epoch 2, gen_loss = 2.9644110021711905, disc_loss = 0.0033209535714734018
Trained batch 79 in epoch 2, gen_loss = 2.962393882870674, disc_loss = 0.0033020463495631704
Trained batch 80 in epoch 2, gen_loss = 2.9593778804496482, disc_loss = 0.0032826173694137438
Trained batch 81 in epoch 2, gen_loss = 2.959241256481264, disc_loss = 0.003271209672320543
Trained batch 82 in epoch 2, gen_loss = 2.9544643465294897, disc_loss = 0.003342924117817577
Trained batch 83 in epoch 2, gen_loss = 2.95285173257192, disc_loss = 0.0034576754274201534
Trained batch 84 in epoch 2, gen_loss = 2.949282932281494, disc_loss = 0.0034722057828570113
Trained batch 85 in epoch 2, gen_loss = 2.951116816942082, disc_loss = 0.0035079000626019267
Trained batch 86 in epoch 2, gen_loss = 2.95580399447474, disc_loss = 0.0035151452115126723
Trained batch 87 in epoch 2, gen_loss = 2.9517944238402625, disc_loss = 0.0035152967638251457
Trained batch 88 in epoch 2, gen_loss = 2.95414954892705, disc_loss = 0.003512555594671141
Trained batch 89 in epoch 2, gen_loss = 2.950207757949829, disc_loss = 0.003509785066772666
Trained batch 90 in epoch 2, gen_loss = 2.951225603019798, disc_loss = 0.0035001687157981015
Trained batch 91 in epoch 2, gen_loss = 2.9564897443937217, disc_loss = 0.0034855486642893243
Trained batch 92 in epoch 2, gen_loss = 2.9540977836937032, disc_loss = 0.0034694686752333435
Trained batch 93 in epoch 2, gen_loss = 2.952337625178885, disc_loss = 0.003451555449654289
Trained batch 94 in epoch 2, gen_loss = 2.952435026670757, disc_loss = 0.00343503054770592
Trained batch 95 in epoch 2, gen_loss = 2.953146112461885, disc_loss = 0.0034194934390446483
Trained batch 96 in epoch 2, gen_loss = 2.9505036884976414, disc_loss = 0.0034107024488567385
Trained batch 97 in epoch 2, gen_loss = 2.9495665491843712, disc_loss = 0.0033981948401969
Trained batch 98 in epoch 2, gen_loss = 2.9483569463094077, disc_loss = 0.003386151868699476
Trained batch 99 in epoch 2, gen_loss = 2.9480462503433227, disc_loss = 0.003378522461280227
Trained batch 100 in epoch 2, gen_loss = 2.946133821317465, disc_loss = 0.0033702725835033868
Trained batch 101 in epoch 2, gen_loss = 2.9485890491336, disc_loss = 0.003359023593457452
Trained batch 102 in epoch 2, gen_loss = 2.949174769873758, disc_loss = 0.003358108070633799
Trained batch 103 in epoch 2, gen_loss = 2.9480260839829078, disc_loss = 0.0033506923534262637
Trained batch 104 in epoch 2, gen_loss = 2.946621120543707, disc_loss = 0.003342957998670283
Trained batch 105 in epoch 2, gen_loss = 2.944104304853475, disc_loss = 0.003337458360342766
Trained batch 106 in epoch 2, gen_loss = 2.9456235359762317, disc_loss = 0.003331094649489795
Trained batch 107 in epoch 2, gen_loss = 2.9441105237713567, disc_loss = 0.003323570531965406
Trained batch 108 in epoch 2, gen_loss = 2.9461048589933903, disc_loss = 0.0033141758822656554
Trained batch 109 in epoch 2, gen_loss = 2.9478367913853036, disc_loss = 0.0033015029028650713
Trained batch 110 in epoch 2, gen_loss = 2.9470849423795134, disc_loss = 0.0032903570671322514
Trained batch 111 in epoch 2, gen_loss = 2.943162739276886, disc_loss = 0.0032888635936875027
Trained batch 112 in epoch 2, gen_loss = 2.9452293531029627, disc_loss = 0.003281463610329789
Trained batch 113 in epoch 2, gen_loss = 2.945214158610294, disc_loss = 0.0032793216319476955
Trained batch 114 in epoch 2, gen_loss = 2.945499955052915, disc_loss = 0.0032895977942920896
Trained batch 115 in epoch 2, gen_loss = 2.9451751996730935, disc_loss = 0.0032854076557198605
Trained batch 116 in epoch 2, gen_loss = 2.9449906715979943, disc_loss = 0.0032793771382023254
Trained batch 117 in epoch 2, gen_loss = 2.9466238668409446, disc_loss = 0.003273775614600755
Trained batch 118 in epoch 2, gen_loss = 2.945864535179459, disc_loss = 0.00326291228421502
Trained batch 119 in epoch 2, gen_loss = 2.9449824591477713, disc_loss = 0.0032496018829988316
Trained batch 120 in epoch 2, gen_loss = 2.947193009794251, disc_loss = 0.003241327549869672
Trained batch 121 in epoch 2, gen_loss = 2.9466117190533, disc_loss = 0.0032306754566561124
Trained batch 122 in epoch 2, gen_loss = 2.9480290277217462, disc_loss = 0.003220194575899258
Trained batch 123 in epoch 2, gen_loss = 2.9517732012656426, disc_loss = 0.0032070463536412364
Trained batch 124 in epoch 2, gen_loss = 2.9520303268432615, disc_loss = 0.003192241466604173
Trained batch 125 in epoch 2, gen_loss = 2.9508978961006043, disc_loss = 0.003178147243387583
Trained batch 126 in epoch 2, gen_loss = 2.950288183107151, disc_loss = 0.0031720984527313215
Trained batch 127 in epoch 2, gen_loss = 2.947550445795059, disc_loss = 0.00316501437464467
Trained batch 128 in epoch 2, gen_loss = 2.9461431207582933, disc_loss = 0.0031559750114661432
Trained batch 129 in epoch 2, gen_loss = 2.9478715694867645, disc_loss = 0.003147789475042373
Trained batch 130 in epoch 2, gen_loss = 2.9481851690598115, disc_loss = 0.0031403792383973947
Trained batch 131 in epoch 2, gen_loss = 2.9503515814289902, disc_loss = 0.0031348391776467024
Trained batch 132 in epoch 2, gen_loss = 2.950726837143862, disc_loss = 0.003134502680040896
Trained batch 133 in epoch 2, gen_loss = 2.9496556662801487, disc_loss = 0.003129476859449729
Trained batch 134 in epoch 2, gen_loss = 2.947753155672992, disc_loss = 0.0031259499964545723
Trained batch 135 in epoch 2, gen_loss = 2.9478467422373154, disc_loss = 0.003122857800061705
Trained batch 136 in epoch 2, gen_loss = 2.9496915810299615, disc_loss = 0.003113864605777292
Trained batch 137 in epoch 2, gen_loss = 2.9483857327613276, disc_loss = 0.0031168237117632034
Trained batch 138 in epoch 2, gen_loss = 2.950472114755095, disc_loss = 0.0031179422303270416
Trained batch 139 in epoch 2, gen_loss = 2.9501024075916837, disc_loss = 0.003115265629354066
Trained batch 140 in epoch 2, gen_loss = 2.9502617721016526, disc_loss = 0.0031216294225635574
Trained batch 141 in epoch 2, gen_loss = 2.9493800720698395, disc_loss = 0.003129887538076654
Trained batch 142 in epoch 2, gen_loss = 2.950184692036022, disc_loss = 0.0031354681717336076
Trained batch 143 in epoch 2, gen_loss = 2.9488130509853363, disc_loss = 0.003129742828605231
Trained batch 144 in epoch 2, gen_loss = 2.94959591503801, disc_loss = 0.0031184143467067643
Trained batch 145 in epoch 2, gen_loss = 2.951155451879109, disc_loss = 0.003107624142813458
Trained batch 146 in epoch 2, gen_loss = 2.9505841050829207, disc_loss = 0.003097967791123962
Trained batch 147 in epoch 2, gen_loss = 2.9494850200575753, disc_loss = 0.003090777071004079
Trained batch 148 in epoch 2, gen_loss = 2.94899723033777, disc_loss = 0.003084608358362277
Trained batch 149 in epoch 2, gen_loss = 2.949226794242859, disc_loss = 0.003075588318364074
Trained batch 150 in epoch 2, gen_loss = 2.9461695611082166, disc_loss = 0.0030743744901214906
Trained batch 151 in epoch 2, gen_loss = 2.947271762709869, disc_loss = 0.0030753324260187676
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 3.1888821125030518, disc_loss = 0.0021773173939436674
Trained batch 1 in epoch 3, gen_loss = 2.9870043992996216, disc_loss = 0.002157210954464972
Trained batch 2 in epoch 3, gen_loss = 3.0683680375417075, disc_loss = 0.0019828691923369965
Trained batch 3 in epoch 3, gen_loss = 3.106627643108368, disc_loss = 0.0018881754367612302
Trained batch 4 in epoch 3, gen_loss = 3.03039755821228, disc_loss = 0.0018401638604700564
Trained batch 5 in epoch 3, gen_loss = 2.997738242149353, disc_loss = 0.0018207243410870433
Trained batch 6 in epoch 3, gen_loss = 3.0220532757895335, disc_loss = 0.0018796332380069153
Trained batch 7 in epoch 3, gen_loss = 2.977104753255844, disc_loss = 0.0019131742883473635
Trained batch 8 in epoch 3, gen_loss = 3.053902546564738, disc_loss = 0.0019522511089841525
Trained batch 9 in epoch 3, gen_loss = 3.020393466949463, disc_loss = 0.0019852557219564916
Trained batch 10 in epoch 3, gen_loss = 2.991479895331643, disc_loss = 0.001981855645267801
Trained batch 11 in epoch 3, gen_loss = 2.9915891687075296, disc_loss = 0.001960525599618753
Trained batch 12 in epoch 3, gen_loss = 2.9717387786278358, disc_loss = 0.0019799672926847753
Trained batch 13 in epoch 3, gen_loss = 2.9482572419302806, disc_loss = 0.0019840143421398742
Trained batch 14 in epoch 3, gen_loss = 2.9409101168314615, disc_loss = 0.002030910023798545
Trained batch 15 in epoch 3, gen_loss = 2.9396507143974304, disc_loss = 0.0021667488326784223
Trained batch 16 in epoch 3, gen_loss = 2.939152437097886, disc_loss = 0.0022634883849498104
Trained batch 17 in epoch 3, gen_loss = 2.9390827152464123, disc_loss = 0.002275180498448511
Trained batch 18 in epoch 3, gen_loss = 2.9480222902799906, disc_loss = 0.0022538057528436184
Trained batch 19 in epoch 3, gen_loss = 2.9393401026725767, disc_loss = 0.0022055822308175268
Trained batch 20 in epoch 3, gen_loss = 2.9402351606459844, disc_loss = 0.002163012561920498
Trained batch 21 in epoch 3, gen_loss = 2.9368881203911523, disc_loss = 0.002134726610331034
Trained batch 22 in epoch 3, gen_loss = 2.9301010629405146, disc_loss = 0.0021056578616085258
Trained batch 23 in epoch 3, gen_loss = 2.936956842740377, disc_loss = 0.0020882317912764847
Trained batch 24 in epoch 3, gen_loss = 2.928601875305176, disc_loss = 0.002082334659062326
Trained batch 25 in epoch 3, gen_loss = 2.9227465849656324, disc_loss = 0.0020906665729573714
Trained batch 26 in epoch 3, gen_loss = 2.9170970916748047, disc_loss = 0.0021224687160510155
Trained batch 27 in epoch 3, gen_loss = 2.9074725253241405, disc_loss = 0.0021384012527830365
Trained batch 28 in epoch 3, gen_loss = 2.910814096187723, disc_loss = 0.0021328366690732794
Trained batch 29 in epoch 3, gen_loss = 2.9015374422073363, disc_loss = 0.002128465555142611
Trained batch 30 in epoch 3, gen_loss = 2.896912090239986, disc_loss = 0.002117993569211854
Trained batch 31 in epoch 3, gen_loss = 2.906083084642887, disc_loss = 0.0020948187848262023
Trained batch 32 in epoch 3, gen_loss = 2.912507512352683, disc_loss = 0.0020644987093736277
Trained batch 33 in epoch 3, gen_loss = 2.908579069025376, disc_loss = 0.002046694955103757
Trained batch 34 in epoch 3, gen_loss = 2.9150289194924492, disc_loss = 0.0020319338821406874
Trained batch 35 in epoch 3, gen_loss = 2.910441471470727, disc_loss = 0.002021682193218213
Trained batch 36 in epoch 3, gen_loss = 2.9124091444788753, disc_loss = 0.002003695705679019
Trained batch 37 in epoch 3, gen_loss = 2.9139034810819124, disc_loss = 0.001990279430940159
Trained batch 38 in epoch 3, gen_loss = 2.92065062889686, disc_loss = 0.0019726607715710998
Trained batch 39 in epoch 3, gen_loss = 2.9230619430541993, disc_loss = 0.0019688227883307265
Trained batch 40 in epoch 3, gen_loss = 2.936214179527469, disc_loss = 0.0019666034381882083
Trained batch 41 in epoch 3, gen_loss = 2.937785750343686, disc_loss = 0.0019816391231004325
Trained batch 42 in epoch 3, gen_loss = 2.934288368668667, disc_loss = 0.0020185393730698283
Trained batch 43 in epoch 3, gen_loss = 2.9345378442244097, disc_loss = 0.002077004605036398
Trained batch 44 in epoch 3, gen_loss = 2.9295407983991835, disc_loss = 0.002122731359365086
Trained batch 45 in epoch 3, gen_loss = 2.9320354928141055, disc_loss = 0.0021409736718456056
Trained batch 46 in epoch 3, gen_loss = 2.9355588010016906, disc_loss = 0.002142675000520304
Trained batch 47 in epoch 3, gen_loss = 2.9370141377051673, disc_loss = 0.0021306830337077067
Trained batch 48 in epoch 3, gen_loss = 2.932096169919384, disc_loss = 0.002121831853493896
Trained batch 49 in epoch 3, gen_loss = 2.9400675678253174, disc_loss = 0.0021144496113993227
Trained batch 50 in epoch 3, gen_loss = 2.9442706762575637, disc_loss = 0.0021131822551764988
Trained batch 51 in epoch 3, gen_loss = 2.941366094809312, disc_loss = 0.002106021514359432
Trained batch 52 in epoch 3, gen_loss = 2.9418157541526937, disc_loss = 0.002099919800629031
Trained batch 53 in epoch 3, gen_loss = 2.9378110346970736, disc_loss = 0.00208996691637569
Trained batch 54 in epoch 3, gen_loss = 2.9383668769489635, disc_loss = 0.0020780822410332886
Trained batch 55 in epoch 3, gen_loss = 2.9348248073032925, disc_loss = 0.0020652373724650325
Trained batch 56 in epoch 3, gen_loss = 2.9263247983497487, disc_loss = 0.002067122063109357
Trained batch 57 in epoch 3, gen_loss = 2.931974308244113, disc_loss = 0.002061912266071886
Trained batch 58 in epoch 3, gen_loss = 2.9300163277124955, disc_loss = 0.002056065327251109
Trained batch 59 in epoch 3, gen_loss = 2.9265820145606996, disc_loss = 0.0020780685629385215
Trained batch 60 in epoch 3, gen_loss = 2.9294368751713487, disc_loss = 0.002102329056007696
Trained batch 61 in epoch 3, gen_loss = 2.93476648869053, disc_loss = 0.0021317278808583658
Trained batch 62 in epoch 3, gen_loss = 2.9392375567602733, disc_loss = 0.002172990994054883
Trained batch 63 in epoch 3, gen_loss = 2.9434441551566124, disc_loss = 0.00218491070336313
Trained batch 64 in epoch 3, gen_loss = 2.946072585766132, disc_loss = 0.0021752956591976377
Trained batch 65 in epoch 3, gen_loss = 2.9448263970288364, disc_loss = 0.0021725912899428017
Trained batch 66 in epoch 3, gen_loss = 2.943088058215469, disc_loss = 0.00217129023043689
Trained batch 67 in epoch 3, gen_loss = 2.943069948869593, disc_loss = 0.00216536208309288
Trained batch 68 in epoch 3, gen_loss = 2.9439801409624624, disc_loss = 0.002152981568951214
Trained batch 69 in epoch 3, gen_loss = 2.944245229448591, disc_loss = 0.0021401774221366005
Trained batch 70 in epoch 3, gen_loss = 2.9457093494039186, disc_loss = 0.002130753791917273
Trained batch 71 in epoch 3, gen_loss = 2.9449020624160767, disc_loss = 0.0021209168076489326
Trained batch 72 in epoch 3, gen_loss = 2.9472790286965567, disc_loss = 0.0021121417784629617
Trained batch 73 in epoch 3, gen_loss = 2.9488511794322245, disc_loss = 0.002105752075393055
Trained batch 74 in epoch 3, gen_loss = 2.949302577972412, disc_loss = 0.002095435239995519
Trained batch 75 in epoch 3, gen_loss = 2.951377799636439, disc_loss = 0.00208681793638358
Trained batch 76 in epoch 3, gen_loss = 2.94853670566113, disc_loss = 0.002092654136457033
Trained batch 77 in epoch 3, gen_loss = 2.946757897352561, disc_loss = 0.0021081900206179572
Trained batch 78 in epoch 3, gen_loss = 2.944227275969107, disc_loss = 0.0021217141530323253
Trained batch 79 in epoch 3, gen_loss = 2.9459066152572633, disc_loss = 0.002122396446065977
Trained batch 80 in epoch 3, gen_loss = 2.9481047377174283, disc_loss = 0.00211798876558465
Trained batch 81 in epoch 3, gen_loss = 2.9444762032206464, disc_loss = 0.0021175171685882095
Trained batch 82 in epoch 3, gen_loss = 2.9468892338764237, disc_loss = 0.002115070138193936
Trained batch 83 in epoch 3, gen_loss = 2.9462874872343883, disc_loss = 0.002110826290888889
Trained batch 84 in epoch 3, gen_loss = 2.9473211709190816, disc_loss = 0.0021022235755534732
Trained batch 85 in epoch 3, gen_loss = 2.950135594190553, disc_loss = 0.00209476322417559
Trained batch 86 in epoch 3, gen_loss = 2.9477553120974838, disc_loss = 0.0020920412264357523
Trained batch 87 in epoch 3, gen_loss = 2.943371496417306, disc_loss = 0.0021025923871837385
Trained batch 88 in epoch 3, gen_loss = 2.945312274975723, disc_loss = 0.0021042826708427137
Trained batch 89 in epoch 3, gen_loss = 2.9477403534783257, disc_loss = 0.002095278834975842
Trained batch 90 in epoch 3, gen_loss = 2.946422042427482, disc_loss = 0.0020912849717865606
Trained batch 91 in epoch 3, gen_loss = 2.94948303958644, disc_loss = 0.0020846521466687
Trained batch 92 in epoch 3, gen_loss = 2.946690618350942, disc_loss = 0.0020882465866624666
Trained batch 93 in epoch 3, gen_loss = 2.948535997816857, disc_loss = 0.002114580260550088
Trained batch 94 in epoch 3, gen_loss = 2.946379458276849, disc_loss = 0.002143781759629124
Trained batch 95 in epoch 3, gen_loss = 2.9450315882762275, disc_loss = 0.00217197747163785
Trained batch 96 in epoch 3, gen_loss = 2.9469228110362575, disc_loss = 0.00217974708492378
Trained batch 97 in epoch 3, gen_loss = 2.943708164351327, disc_loss = 0.002193391510779608
Trained batch 98 in epoch 3, gen_loss = 2.944254822201199, disc_loss = 0.0022185486247480817
Trained batch 99 in epoch 3, gen_loss = 2.9412851786613463, disc_loss = 0.002244481707457453
Trained batch 100 in epoch 3, gen_loss = 2.940043244031396, disc_loss = 0.002256607385536674
Trained batch 101 in epoch 3, gen_loss = 2.9396473823809157, disc_loss = 0.0022594602915513165
Trained batch 102 in epoch 3, gen_loss = 2.939095802677488, disc_loss = 0.002258082693533122
Trained batch 103 in epoch 3, gen_loss = 2.9403492968816023, disc_loss = 0.0022663959624389042
Trained batch 104 in epoch 3, gen_loss = 2.942422796431042, disc_loss = 0.0022615387791856414
Trained batch 105 in epoch 3, gen_loss = 2.9435583712919704, disc_loss = 0.0022595627826445227
Trained batch 106 in epoch 3, gen_loss = 2.9448607168465015, disc_loss = 0.0022546512936459525
Trained batch 107 in epoch 3, gen_loss = 2.94401745001475, disc_loss = 0.002245635686752697
Trained batch 108 in epoch 3, gen_loss = 2.9436947949435734, disc_loss = 0.002239504224543861
Trained batch 109 in epoch 3, gen_loss = 2.939331882650202, disc_loss = 0.0022479333216324448
Trained batch 110 in epoch 3, gen_loss = 2.9416337142119535, disc_loss = 0.0022779470078882064
Trained batch 111 in epoch 3, gen_loss = 2.9419963444982256, disc_loss = 0.0023199240656270248
Trained batch 112 in epoch 3, gen_loss = 2.9423581140231243, disc_loss = 0.00235448684749416
Trained batch 113 in epoch 3, gen_loss = 2.942342394276669, disc_loss = 0.0023601700331231483
Trained batch 114 in epoch 3, gen_loss = 2.9417656069216522, disc_loss = 0.0023562860867494474
Trained batch 115 in epoch 3, gen_loss = 2.943989151510699, disc_loss = 0.0023555439577743024
Trained batch 116 in epoch 3, gen_loss = 2.945099449565268, disc_loss = 0.0023666211736237262
Trained batch 117 in epoch 3, gen_loss = 2.9454032445358016, disc_loss = 0.0023812724867346303
Trained batch 118 in epoch 3, gen_loss = 2.9438146302680006, disc_loss = 0.0023893124097175583
Trained batch 119 in epoch 3, gen_loss = 2.942568188905716, disc_loss = 0.002391367627812239
Trained batch 120 in epoch 3, gen_loss = 2.942134325169335, disc_loss = 0.0023976575846837694
Trained batch 121 in epoch 3, gen_loss = 2.943469121807911, disc_loss = 0.002404339372020093
Trained batch 122 in epoch 3, gen_loss = 2.9446618266221956, disc_loss = 0.0024040696538636477
Trained batch 123 in epoch 3, gen_loss = 2.946628955102736, disc_loss = 0.002398516343448371
Trained batch 124 in epoch 3, gen_loss = 2.944207326889038, disc_loss = 0.00239517789054662
Trained batch 125 in epoch 3, gen_loss = 2.9410662934893654, disc_loss = 0.0024079845983549833
Trained batch 126 in epoch 3, gen_loss = 2.94012995029059, disc_loss = 0.002420782061169056
Trained batch 127 in epoch 3, gen_loss = 2.9430924635380507, disc_loss = 0.0024198136843551765
Trained batch 128 in epoch 3, gen_loss = 2.9413337319396264, disc_loss = 0.002417719171223657
Trained batch 129 in epoch 3, gen_loss = 2.938832328869746, disc_loss = 0.002410237423968143
Trained batch 130 in epoch 3, gen_loss = 2.940261063684944, disc_loss = 0.002408609769079578
Trained batch 131 in epoch 3, gen_loss = 2.941804237437971, disc_loss = 0.00240782088561294
Trained batch 132 in epoch 3, gen_loss = 2.9408439066177023, disc_loss = 0.002403314529105853
Trained batch 133 in epoch 3, gen_loss = 2.9415594873143665, disc_loss = 0.0023981211446364647
Trained batch 134 in epoch 3, gen_loss = 2.942400824582135, disc_loss = 0.0023986833308030056
Trained batch 135 in epoch 3, gen_loss = 2.942494022495606, disc_loss = 0.0023937507169595096
Trained batch 136 in epoch 3, gen_loss = 2.940030165832408, disc_loss = 0.0023873737438779023
Trained batch 137 in epoch 3, gen_loss = 2.9429009738175766, disc_loss = 0.0023830005936189623
Trained batch 138 in epoch 3, gen_loss = 2.945631927723507, disc_loss = 0.0023783088122367214
Trained batch 139 in epoch 3, gen_loss = 2.945030461038862, disc_loss = 0.002373046531075878
Trained batch 140 in epoch 3, gen_loss = 2.9436680154597505, disc_loss = 0.0023751865316129534
Trained batch 141 in epoch 3, gen_loss = 2.9440082042989597, disc_loss = 0.002380521489228581
Trained batch 142 in epoch 3, gen_loss = 2.9414645124982286, disc_loss = 0.0023849422740587194
Trained batch 143 in epoch 3, gen_loss = 2.9401010639137692, disc_loss = 0.002393086649438677
Trained batch 144 in epoch 3, gen_loss = 2.941186470820986, disc_loss = 0.002393544052631177
Trained batch 145 in epoch 3, gen_loss = 2.9397427153913944, disc_loss = 0.002388447799005431
Trained batch 146 in epoch 3, gen_loss = 2.939384859435412, disc_loss = 0.002379309457289625
Trained batch 147 in epoch 3, gen_loss = 2.9377203954232707, disc_loss = 0.0023718752152588523
Trained batch 148 in epoch 3, gen_loss = 2.9371676284994854, disc_loss = 0.0023637062404304743
Trained batch 149 in epoch 3, gen_loss = 2.939824487368266, disc_loss = 0.002355535516204933
Trained batch 150 in epoch 3, gen_loss = 2.93974133516779, disc_loss = 0.0023475474468278175
Trained batch 151 in epoch 3, gen_loss = 2.9393349776142523, disc_loss = 0.002340331099970315
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.894401788711548, disc_loss = 0.0013031063135713339
Trained batch 1 in epoch 4, gen_loss = 3.01654851436615, disc_loss = 0.0011292644776403904
Trained batch 2 in epoch 4, gen_loss = 2.9634969234466553, disc_loss = 0.0010861142848928769
Trained batch 3 in epoch 4, gen_loss = 3.020264208316803, disc_loss = 0.0011146191391162574
Trained batch 4 in epoch 4, gen_loss = 2.9950751304626464, disc_loss = 0.0012257890542969108
Trained batch 5 in epoch 4, gen_loss = 2.9988467693328857, disc_loss = 0.0012639588482367496
Trained batch 6 in epoch 4, gen_loss = 2.9221350124904086, disc_loss = 0.0014861412180055464
Trained batch 7 in epoch 4, gen_loss = 2.9389967024326324, disc_loss = 0.0019123626261716709
Trained batch 8 in epoch 4, gen_loss = 2.9430962403615317, disc_loss = 0.0019786245215477217
Trained batch 9 in epoch 4, gen_loss = 2.9328575849533083, disc_loss = 0.0020595556241460146
Trained batch 10 in epoch 4, gen_loss = 2.921071312644265, disc_loss = 0.0021071324696425686
Trained batch 11 in epoch 4, gen_loss = 2.9319875637690225, disc_loss = 0.0021024471789132804
Trained batch 12 in epoch 4, gen_loss = 2.919950631948618, disc_loss = 0.0020965680999394795
Trained batch 13 in epoch 4, gen_loss = 2.9291052647999356, disc_loss = 0.0020399491934637937
Trained batch 14 in epoch 4, gen_loss = 2.9266212463378904, disc_loss = 0.0020051841624081136
Trained batch 15 in epoch 4, gen_loss = 2.914022371172905, disc_loss = 0.0019840691093122587
Trained batch 16 in epoch 4, gen_loss = 2.906850155662088, disc_loss = 0.0019623686915592234
Trained batch 17 in epoch 4, gen_loss = 2.909256524509854, disc_loss = 0.0020155481114569637
Trained batch 18 in epoch 4, gen_loss = 2.9050103990655196, disc_loss = 0.0021642050705850124
Trained batch 19 in epoch 4, gen_loss = 2.8915431261062623, disc_loss = 0.0023010387783870103
Trained batch 20 in epoch 4, gen_loss = 2.892388343811035, disc_loss = 0.0023774675625775543
Trained batch 21 in epoch 4, gen_loss = 2.912244753404097, disc_loss = 0.002389916493980722
Trained batch 22 in epoch 4, gen_loss = 2.917037984599238, disc_loss = 0.002361805719809364
Trained batch 23 in epoch 4, gen_loss = 2.909619927406311, disc_loss = 0.002383686151006259
Trained batch 24 in epoch 4, gen_loss = 2.9073119258880613, disc_loss = 0.0023909133160486817
Trained batch 25 in epoch 4, gen_loss = 2.900981151140653, disc_loss = 0.0023687088351625088
Trained batch 26 in epoch 4, gen_loss = 2.90937759258129, disc_loss = 0.0023333832397367115
Trained batch 27 in epoch 4, gen_loss = 2.9073250464030673, disc_loss = 0.0022928993067970233
Trained batch 28 in epoch 4, gen_loss = 2.906681644505468, disc_loss = 0.002281596426498787
Trained batch 29 in epoch 4, gen_loss = 2.900987410545349, disc_loss = 0.002293202995012204
Trained batch 30 in epoch 4, gen_loss = 2.914308694101149, disc_loss = 0.0023282117570840545
Trained batch 31 in epoch 4, gen_loss = 2.91143961250782, disc_loss = 0.00234464458480943
Trained batch 32 in epoch 4, gen_loss = 2.913123253620032, disc_loss = 0.0023387804429865246
Trained batch 33 in epoch 4, gen_loss = 2.9142199614468742, disc_loss = 0.002304080394370591
Trained batch 34 in epoch 4, gen_loss = 2.9215726239340647, disc_loss = 0.0022727045197305936
Trained batch 35 in epoch 4, gen_loss = 2.9142304062843323, disc_loss = 0.002266651844062532
Trained batch 36 in epoch 4, gen_loss = 2.91650542697391, disc_loss = 0.0022962288584912546
Trained batch 37 in epoch 4, gen_loss = 2.9226833519182707, disc_loss = 0.002343636303282294
Trained batch 38 in epoch 4, gen_loss = 2.929279321279281, disc_loss = 0.0023907776951837614
Trained batch 39 in epoch 4, gen_loss = 2.9348717629909515, disc_loss = 0.0023927953938255087
Trained batch 40 in epoch 4, gen_loss = 2.934595090586965, disc_loss = 0.0023643873921572797
Trained batch 41 in epoch 4, gen_loss = 2.9423215900148665, disc_loss = 0.002344655868087319
Trained batch 42 in epoch 4, gen_loss = 2.9422688373299533, disc_loss = 0.0023305746212298442
Trained batch 43 in epoch 4, gen_loss = 2.93621843511408, disc_loss = 0.0023136747821064837
Trained batch 44 in epoch 4, gen_loss = 2.937977653079563, disc_loss = 0.002288929153130286
Trained batch 45 in epoch 4, gen_loss = 2.9362039255059282, disc_loss = 0.0022723978516929174
Trained batch 46 in epoch 4, gen_loss = 2.943435440672205, disc_loss = 0.0022596383189901394
Trained batch 47 in epoch 4, gen_loss = 2.9467840492725372, disc_loss = 0.0022452920772290477
Trained batch 48 in epoch 4, gen_loss = 2.945191422287299, disc_loss = 0.0022310455049369105
Trained batch 49 in epoch 4, gen_loss = 2.952346725463867, disc_loss = 0.002227460362482816
Trained batch 50 in epoch 4, gen_loss = 2.9495522742177926, disc_loss = 0.0022557620895003864
Trained batch 51 in epoch 4, gen_loss = 2.945460136120136, disc_loss = 0.0023218296186174625
Trained batch 52 in epoch 4, gen_loss = 2.9375295594053448, disc_loss = 0.0023910955829053834
Trained batch 53 in epoch 4, gen_loss = 2.934527538440846, disc_loss = 0.002428141769659878
Trained batch 54 in epoch 4, gen_loss = 2.931584748354825, disc_loss = 0.0024324864000928675
Trained batch 55 in epoch 4, gen_loss = 2.932875156402588, disc_loss = 0.0024131936973260182
Trained batch 56 in epoch 4, gen_loss = 2.9399061621281137, disc_loss = 0.00241075591960301
Trained batch 57 in epoch 4, gen_loss = 2.9331265441302596, disc_loss = 0.0024208973687752313
Trained batch 58 in epoch 4, gen_loss = 2.935066582792896, disc_loss = 0.0024208018489150426
Trained batch 59 in epoch 4, gen_loss = 2.934630239009857, disc_loss = 0.0024158796508951734
Trained batch 60 in epoch 4, gen_loss = 2.9379198394837927, disc_loss = 0.002404460643387598
Trained batch 61 in epoch 4, gen_loss = 2.934157640703263, disc_loss = 0.002385808622479559
Trained batch 62 in epoch 4, gen_loss = 2.9342502223120794, disc_loss = 0.0023661659797653556
Trained batch 63 in epoch 4, gen_loss = 2.936155531555414, disc_loss = 0.0023444953112630174
Trained batch 64 in epoch 4, gen_loss = 2.935706875874446, disc_loss = 0.002323666908061848
Trained batch 65 in epoch 4, gen_loss = 2.9367611624977807, disc_loss = 0.0023064644897892845
Trained batch 66 in epoch 4, gen_loss = 2.937372606192062, disc_loss = 0.002291935372666748
Trained batch 67 in epoch 4, gen_loss = 2.9406023656620697, disc_loss = 0.002276559060727082
Trained batch 68 in epoch 4, gen_loss = 2.938193252121193, disc_loss = 0.0022655036772830763
Trained batch 69 in epoch 4, gen_loss = 2.9388219935553415, disc_loss = 0.0022561820323712058
Trained batch 70 in epoch 4, gen_loss = 2.9397816154318797, disc_loss = 0.0022422924742732248
Trained batch 71 in epoch 4, gen_loss = 2.941455844375822, disc_loss = 0.0022246997905313037
Trained batch 72 in epoch 4, gen_loss = 2.93868107665075, disc_loss = 0.0022124859993983927
Trained batch 73 in epoch 4, gen_loss = 2.9393713957554586, disc_loss = 0.0021980263086702877
Trained batch 74 in epoch 4, gen_loss = 2.9363417212168375, disc_loss = 0.0021951289544813336
Trained batch 75 in epoch 4, gen_loss = 2.935464655098162, disc_loss = 0.0022022348811764174
Trained batch 76 in epoch 4, gen_loss = 2.936171887756942, disc_loss = 0.0022000266131703052
Trained batch 77 in epoch 4, gen_loss = 2.935386205330873, disc_loss = 0.0022005015388668445
Trained batch 78 in epoch 4, gen_loss = 2.9377981288523616, disc_loss = 0.0022040821701771567
Trained batch 79 in epoch 4, gen_loss = 2.9382688254117966, disc_loss = 0.0021958514967991504
Trained batch 80 in epoch 4, gen_loss = 2.938681870330999, disc_loss = 0.002184676412452748
Trained batch 81 in epoch 4, gen_loss = 2.938144047085832, disc_loss = 0.0021744780448299445
Trained batch 82 in epoch 4, gen_loss = 2.9368465751050468, disc_loss = 0.002167685491072171
Trained batch 83 in epoch 4, gen_loss = 2.9343355070976984, disc_loss = 0.002172717013135774
Trained batch 84 in epoch 4, gen_loss = 2.9363163050483254, disc_loss = 0.002190665213856846
Trained batch 85 in epoch 4, gen_loss = 2.9366470048593922, disc_loss = 0.0022036472076907496
Trained batch 86 in epoch 4, gen_loss = 2.9395010032873046, disc_loss = 0.002199871506376042
Trained batch 87 in epoch 4, gen_loss = 2.9366867542266846, disc_loss = 0.0021960036372712984
Trained batch 88 in epoch 4, gen_loss = 2.9380863195054987, disc_loss = 0.0022003935209182457
Trained batch 89 in epoch 4, gen_loss = 2.938792739974128, disc_loss = 0.002208547352994275
Trained batch 90 in epoch 4, gen_loss = 2.9376499312264577, disc_loss = 0.002210873431797334
Trained batch 91 in epoch 4, gen_loss = 2.937175284261289, disc_loss = 0.002208523413687742
Trained batch 92 in epoch 4, gen_loss = 2.9357536736355034, disc_loss = 0.0022051098164401306
Trained batch 93 in epoch 4, gen_loss = 2.9364395978602955, disc_loss = 0.0021956223255132344
Trained batch 94 in epoch 4, gen_loss = 2.94002177840785, disc_loss = 0.0021866773101991335
Trained batch 95 in epoch 4, gen_loss = 2.9424283603827157, disc_loss = 0.0021796616644375413
Trained batch 96 in epoch 4, gen_loss = 2.940445447705456, disc_loss = 0.0021724644586319083
Trained batch 97 in epoch 4, gen_loss = 2.9407244555804195, disc_loss = 0.002166413221560533
Trained batch 98 in epoch 4, gen_loss = 2.9396778068157157, disc_loss = 0.00215604746034557
Trained batch 99 in epoch 4, gen_loss = 2.9459550070762632, disc_loss = 0.0021520334895467385
Trained batch 100 in epoch 4, gen_loss = 2.9465249151286512, disc_loss = 0.0021565482406508143
Trained batch 101 in epoch 4, gen_loss = 2.9483215551750335, disc_loss = 0.0021582662770478966
Trained batch 102 in epoch 4, gen_loss = 2.950159991829141, disc_loss = 0.002154484033489654
Trained batch 103 in epoch 4, gen_loss = 2.9534287590246935, disc_loss = 0.002153659415713404
Trained batch 104 in epoch 4, gen_loss = 2.9518620877038866, disc_loss = 0.0021523657160633734
Trained batch 105 in epoch 4, gen_loss = 2.948332037565843, disc_loss = 0.002174064002487422
Trained batch 106 in epoch 4, gen_loss = 2.9458784054372913, disc_loss = 0.002404843965680208
Trained batch 107 in epoch 4, gen_loss = 2.951100958718194, disc_loss = 0.0029677064454450308
Trained batch 108 in epoch 4, gen_loss = 2.9502971697291103, disc_loss = 0.003214616511645086
Trained batch 109 in epoch 4, gen_loss = 2.952623722769997, disc_loss = 0.0033767452246551825
Trained batch 110 in epoch 4, gen_loss = 2.9535633422232963, disc_loss = 0.0035359861433027764
Trained batch 111 in epoch 4, gen_loss = 2.9535358675888608, disc_loss = 0.0037010583613924348
Trained batch 112 in epoch 4, gen_loss = 2.95114917670731, disc_loss = 0.003966686088670111
Trained batch 113 in epoch 4, gen_loss = 2.950998672267847, disc_loss = 0.0042117746631623034
Trained batch 114 in epoch 4, gen_loss = 2.9551720411881157, disc_loss = 0.004406562912703046
Trained batch 115 in epoch 4, gen_loss = 2.9544177343105447, disc_loss = 0.00447005406373325
Trained batch 116 in epoch 4, gen_loss = 2.952921419062166, disc_loss = 0.004474992628515754
Trained batch 117 in epoch 4, gen_loss = 2.95104533534939, disc_loss = 0.004475907978534667
Trained batch 118 in epoch 4, gen_loss = 2.9531904729474494, disc_loss = 0.004464170806982531
Trained batch 119 in epoch 4, gen_loss = 2.952027310927709, disc_loss = 0.004442706517390131
Trained batch 120 in epoch 4, gen_loss = 2.9514839018671966, disc_loss = 0.004418708048741649
Trained batch 121 in epoch 4, gen_loss = 2.9509497861393164, disc_loss = 0.004397496759994566
Trained batch 122 in epoch 4, gen_loss = 2.9508751194651532, disc_loss = 0.004375994345078593
Trained batch 123 in epoch 4, gen_loss = 2.9502740521584787, disc_loss = 0.004372913164608631
Trained batch 124 in epoch 4, gen_loss = 2.952283374786377, disc_loss = 0.004376808445435017
Trained batch 125 in epoch 4, gen_loss = 2.9504387019172547, disc_loss = 0.004366825722316872
Trained batch 126 in epoch 4, gen_loss = 2.9492737120530736, disc_loss = 0.004345460129832101
Trained batch 127 in epoch 4, gen_loss = 2.9503993317484856, disc_loss = 0.004330698008288891
Trained batch 128 in epoch 4, gen_loss = 2.9483413844145545, disc_loss = 0.0043079439436027765
Trained batch 129 in epoch 4, gen_loss = 2.9488683920640213, disc_loss = 0.004285880963121039
Trained batch 130 in epoch 4, gen_loss = 2.9480184016336923, disc_loss = 0.004265571089962654
Trained batch 131 in epoch 4, gen_loss = 2.946996002486258, disc_loss = 0.004242651677376478
Trained batch 132 in epoch 4, gen_loss = 2.9468834866258433, disc_loss = 0.004225656146418191
Trained batch 133 in epoch 4, gen_loss = 2.9474767820159, disc_loss = 0.004207461369102264
Trained batch 134 in epoch 4, gen_loss = 2.950078499758685, disc_loss = 0.004187186292148436
Trained batch 135 in epoch 4, gen_loss = 2.9496304515530083, disc_loss = 0.004164788952039089
Trained batch 136 in epoch 4, gen_loss = 2.951177516992945, disc_loss = 0.004144231599745388
Trained batch 137 in epoch 4, gen_loss = 2.948779278907223, disc_loss = 0.0041460509465136765
Trained batch 138 in epoch 4, gen_loss = 2.949362816570474, disc_loss = 0.004156700758809532
Trained batch 139 in epoch 4, gen_loss = 2.9474722300257, disc_loss = 0.00415112297840616
Trained batch 140 in epoch 4, gen_loss = 2.9473022924247365, disc_loss = 0.004151076977950329
Trained batch 141 in epoch 4, gen_loss = 2.9466621993293223, disc_loss = 0.004140178923426248
Trained batch 142 in epoch 4, gen_loss = 2.946972483521575, disc_loss = 0.004126049615231089
Trained batch 143 in epoch 4, gen_loss = 2.9464371734195285, disc_loss = 0.004107392471067012
Trained batch 144 in epoch 4, gen_loss = 2.9481468545979466, disc_loss = 0.004089290455609945
Trained batch 145 in epoch 4, gen_loss = 2.9497003408327496, disc_loss = 0.004066378371758157
Trained batch 146 in epoch 4, gen_loss = 2.949433237516961, disc_loss = 0.004046935133547301
Trained batch 147 in epoch 4, gen_loss = 2.9493134811117843, disc_loss = 0.004026729269016131
Trained batch 148 in epoch 4, gen_loss = 2.949150271063683, disc_loss = 0.004010997692298069
Trained batch 149 in epoch 4, gen_loss = 2.948894297281901, disc_loss = 0.004004447516053915
Trained batch 150 in epoch 4, gen_loss = 2.9495339425194342, disc_loss = 0.0039938011866630305
Trained batch 151 in epoch 4, gen_loss = 2.948155122367959, disc_loss = 0.003975862797233276
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 3.4754202365875244, disc_loss = 0.0014546143356710672
Trained batch 1 in epoch 5, gen_loss = 3.2323111295700073, disc_loss = 0.0012387206079438329
Trained batch 2 in epoch 5, gen_loss = 3.1948904196421304, disc_loss = 0.00128182132417957
Trained batch 3 in epoch 5, gen_loss = 3.0234550833702087, disc_loss = 0.0028699146350845695
Trained batch 4 in epoch 5, gen_loss = 2.8498420238494875, disc_loss = 0.018526999186724423
Trained batch 5 in epoch 5, gen_loss = 3.01840078830719, disc_loss = 0.07750125066377223
Trained batch 6 in epoch 5, gen_loss = 2.944057055882045, disc_loss = 0.0785025876414563
Trained batch 7 in epoch 5, gen_loss = 2.883614480495453, disc_loss = 0.07976024103118107
Trained batch 8 in epoch 5, gen_loss = 2.91085237926907, disc_loss = 0.07673996495496896
Trained batch 9 in epoch 5, gen_loss = 2.8931861400604246, disc_loss = 0.07396920858882368
Trained batch 10 in epoch 5, gen_loss = 2.8982677459716797, disc_loss = 0.07016743292016062
Trained batch 11 in epoch 5, gen_loss = 2.894318083922068, disc_loss = 0.06553389609325677
Trained batch 12 in epoch 5, gen_loss = 2.9265877100137563, disc_loss = 0.06203814119530412
Trained batch 13 in epoch 5, gen_loss = 2.944516267095293, disc_loss = 0.060182500996493866
Trained batch 14 in epoch 5, gen_loss = 2.9464988867441813, disc_loss = 0.059766450865815085
Trained batch 15 in epoch 5, gen_loss = 2.9205538481473923, disc_loss = 0.05830399677506648
Trained batch 16 in epoch 5, gen_loss = 2.940149854211246, disc_loss = 0.055321488173349816
Trained batch 17 in epoch 5, gen_loss = 2.933126356866625, disc_loss = 0.05266632670019236
Trained batch 18 in epoch 5, gen_loss = 2.9415883139560095, disc_loss = 0.05017380693339204
Trained batch 19 in epoch 5, gen_loss = 2.945731794834137, disc_loss = 0.047915032040327786
Trained batch 20 in epoch 5, gen_loss = 2.936217251278105, disc_loss = 0.045818804109114264
Trained batch 21 in epoch 5, gen_loss = 2.9375677542252974, disc_loss = 0.04385293570389463
Trained batch 22 in epoch 5, gen_loss = 2.9369586136030112, disc_loss = 0.042032326055366706
Trained batch 23 in epoch 5, gen_loss = 2.9278989930947623, disc_loss = 0.040405202123414106
Trained batch 24 in epoch 5, gen_loss = 2.932369422912598, disc_loss = 0.03893845867365599
Trained batch 25 in epoch 5, gen_loss = 2.930473025028522, disc_loss = 0.03751584006777893
Trained batch 26 in epoch 5, gen_loss = 2.931190596686469, disc_loss = 0.0361887021895705
Trained batch 27 in epoch 5, gen_loss = 2.9196113433156694, disc_loss = 0.03497893710404502
Trained batch 28 in epoch 5, gen_loss = 2.9235522747039795, disc_loss = 0.03385012380473701
Trained batch 29 in epoch 5, gen_loss = 2.9288682063420612, disc_loss = 0.03283737134576465
Trained batch 30 in epoch 5, gen_loss = 2.9355132118348153, disc_loss = 0.031908959093984335
Trained batch 31 in epoch 5, gen_loss = 2.9361476227641106, disc_loss = 0.03098277247408987
Trained batch 32 in epoch 5, gen_loss = 2.933423302390359, disc_loss = 0.030104587859982115
Trained batch 33 in epoch 5, gen_loss = 2.931592492496266, disc_loss = 0.029274345289997977
Trained batch 34 in epoch 5, gen_loss = 2.9285737446376254, disc_loss = 0.028480186675941304
Trained batch 35 in epoch 5, gen_loss = 2.9223561419381037, disc_loss = 0.027774180334138993
Trained batch 36 in epoch 5, gen_loss = 2.919007243336858, disc_loss = 0.027087260827396972
Trained batch 37 in epoch 5, gen_loss = 2.9185654803326258, disc_loss = 0.026504268437795537
Trained batch 38 in epoch 5, gen_loss = 2.91591747601827, disc_loss = 0.025987787825915102
Trained batch 39 in epoch 5, gen_loss = 2.926560527086258, disc_loss = 0.025445903683430516
Trained batch 40 in epoch 5, gen_loss = 2.927239388954349, disc_loss = 0.02489189711319873
Trained batch 41 in epoch 5, gen_loss = 2.927772255170913, disc_loss = 0.024345603996023004
Trained batch 42 in epoch 5, gen_loss = 2.924927373265111, disc_loss = 0.02382140684883695
Trained batch 43 in epoch 5, gen_loss = 2.92484773830934, disc_loss = 0.02331221375127577
Trained batch 44 in epoch 5, gen_loss = 2.9224208884769016, disc_loss = 0.02282313651457015
Trained batch 45 in epoch 5, gen_loss = 2.925253178762353, disc_loss = 0.0223528136772549
Trained batch 46 in epoch 5, gen_loss = 2.9282745909183583, disc_loss = 0.02190441701640474
Trained batch 47 in epoch 5, gen_loss = 2.934507449467977, disc_loss = 0.021493703025043942
Trained batch 48 in epoch 5, gen_loss = 2.9446622108926577, disc_loss = 0.021115885092401688
Trained batch 49 in epoch 5, gen_loss = 2.942273259162903, disc_loss = 0.020740734105929734
Trained batch 50 in epoch 5, gen_loss = 2.9394755784203026, disc_loss = 0.02036965557593195
Trained batch 51 in epoch 5, gen_loss = 2.937574015213893, disc_loss = 0.020015811193913508
Trained batch 52 in epoch 5, gen_loss = 2.9336479879775137, disc_loss = 0.019678843168120057
Trained batch 53 in epoch 5, gen_loss = 2.9264145206522056, disc_loss = 0.019509970878802792
Trained batch 54 in epoch 5, gen_loss = 2.9135334578427403, disc_loss = 0.01967856841246513
Trained batch 55 in epoch 5, gen_loss = 2.9174030082566396, disc_loss = 0.019994819649062783
Trained batch 56 in epoch 5, gen_loss = 2.9218384717640125, disc_loss = 0.020220332480803654
Trained batch 57 in epoch 5, gen_loss = 2.9191208337915353, disc_loss = 0.020345762062914156
Trained batch 58 in epoch 5, gen_loss = 2.9150497307211665, disc_loss = 0.02022500141618489
Trained batch 59 in epoch 5, gen_loss = 2.9170618534088133, disc_loss = 0.019963767072961977
Trained batch 60 in epoch 5, gen_loss = 2.917548128815948, disc_loss = 0.01972310314886272
Trained batch 61 in epoch 5, gen_loss = 2.9183739231478785, disc_loss = 0.01944810731501709
Trained batch 62 in epoch 5, gen_loss = 2.9197801332625133, disc_loss = 0.019179268810336315
Trained batch 63 in epoch 5, gen_loss = 2.91746574267745, disc_loss = 0.018962339072459145
Trained batch 64 in epoch 5, gen_loss = 2.9181622175069957, disc_loss = 0.01874748128466308
Trained batch 65 in epoch 5, gen_loss = 2.917575666398713, disc_loss = 0.01849450055989578
Trained batch 66 in epoch 5, gen_loss = 2.915405746716172, disc_loss = 0.018253449694628814
Trained batch 67 in epoch 5, gen_loss = 2.9145820947254406, disc_loss = 0.01801713414640878
Trained batch 68 in epoch 5, gen_loss = 2.9126058661419414, disc_loss = 0.017775875779435686
Trained batch 69 in epoch 5, gen_loss = 2.9137535640171595, disc_loss = 0.017540596671668546
Trained batch 70 in epoch 5, gen_loss = 2.9194241577470805, disc_loss = 0.017310313673847368
Trained batch 71 in epoch 5, gen_loss = 2.9215624001291065, disc_loss = 0.017091731909507264
Trained batch 72 in epoch 5, gen_loss = 2.922323951982472, disc_loss = 0.016885246762572085
Trained batch 73 in epoch 5, gen_loss = 2.9196372998727336, disc_loss = 0.01670046357400212
Trained batch 74 in epoch 5, gen_loss = 2.916837902069092, disc_loss = 0.016522157900035382
Trained batch 75 in epoch 5, gen_loss = 2.9139200637215064, disc_loss = 0.01632983276259007
Trained batch 76 in epoch 5, gen_loss = 2.9159643247530056, disc_loss = 0.016140630684926043
Trained batch 77 in epoch 5, gen_loss = 2.9171779644794955, disc_loss = 0.01595361971965012
Trained batch 78 in epoch 5, gen_loss = 2.9224608608438998, disc_loss = 0.015766760187011352
Trained batch 79 in epoch 5, gen_loss = 2.922994703054428, disc_loss = 0.015584776029572821
Trained batch 80 in epoch 5, gen_loss = 2.922564571286425, disc_loss = 0.015406313204252517
Trained batch 81 in epoch 5, gen_loss = 2.925906431384203, disc_loss = 0.015232387074076275
Trained batch 82 in epoch 5, gen_loss = 2.9241131213774163, disc_loss = 0.015067052226569727
Trained batch 83 in epoch 5, gen_loss = 2.922034734771365, disc_loss = 0.014901437299115406
Trained batch 84 in epoch 5, gen_loss = 2.924599619472728, disc_loss = 0.014736842244918294
Trained batch 85 in epoch 5, gen_loss = 2.9226397303647773, disc_loss = 0.014575022004739664
Trained batch 86 in epoch 5, gen_loss = 2.9217357745115784, disc_loss = 0.014416043528880196
Trained batch 87 in epoch 5, gen_loss = 2.9224218184297737, disc_loss = 0.014260370728152338
Trained batch 88 in epoch 5, gen_loss = 2.9179737460747193, disc_loss = 0.01415774915720535
Trained batch 89 in epoch 5, gen_loss = 2.9174965328640408, disc_loss = 0.014053697572995185
Trained batch 90 in epoch 5, gen_loss = 2.920944936982878, disc_loss = 0.013925152763616867
Trained batch 91 in epoch 5, gen_loss = 2.9208673238754272, disc_loss = 0.013791275254334323
Trained batch 92 in epoch 5, gen_loss = 2.9190487707814863, disc_loss = 0.013663465839995932
Trained batch 93 in epoch 5, gen_loss = 2.9166365963347416, disc_loss = 0.013537919933367719
Trained batch 94 in epoch 5, gen_loss = 2.9163466127295243, disc_loss = 0.013407268069414911
Trained batch 95 in epoch 5, gen_loss = 2.9157728205124536, disc_loss = 0.01328237432911313
Trained batch 96 in epoch 5, gen_loss = 2.914603508624834, disc_loss = 0.01316566958113756
Trained batch 97 in epoch 5, gen_loss = 2.9166034362754045, disc_loss = 0.013056763809540175
Trained batch 98 in epoch 5, gen_loss = 2.917514442193388, disc_loss = 0.01295312220816303
Trained batch 99 in epoch 5, gen_loss = 2.9142541694641113, disc_loss = 0.012853609899175354
Trained batch 100 in epoch 5, gen_loss = 2.913541803265562, disc_loss = 0.012750152033398684
Trained batch 101 in epoch 5, gen_loss = 2.9155068374147604, disc_loss = 0.012640050412087208
Trained batch 102 in epoch 5, gen_loss = 2.913200431657069, disc_loss = 0.012540419631777783
Trained batch 103 in epoch 5, gen_loss = 2.9142791628837585, disc_loss = 0.012447944099571591
Trained batch 104 in epoch 5, gen_loss = 2.9129476933252243, disc_loss = 0.012347899504294175
Trained batch 105 in epoch 5, gen_loss = 2.9115202224479533, disc_loss = 0.012246244769864101
Trained batch 106 in epoch 5, gen_loss = 2.9145243814058395, disc_loss = 0.012172974196206082
Trained batch 107 in epoch 5, gen_loss = 2.9129800112159163, disc_loss = 0.012099484329357639
Trained batch 108 in epoch 5, gen_loss = 2.913848163884714, disc_loss = 0.012004498747463654
Trained batch 109 in epoch 5, gen_loss = 2.9133982636711813, disc_loss = 0.011903603984021835
Trained batch 110 in epoch 5, gen_loss = 2.9144844428913013, disc_loss = 0.0118043690281165
Trained batch 111 in epoch 5, gen_loss = 2.9128650554588864, disc_loss = 0.011706770369658313
Trained batch 112 in epoch 5, gen_loss = 2.9143413611217936, disc_loss = 0.011612683018479925
Trained batch 113 in epoch 5, gen_loss = 2.9147650944559196, disc_loss = 0.011519652858719621
Trained batch 114 in epoch 5, gen_loss = 2.9148724555969237, disc_loss = 0.011426534739565914
Trained batch 115 in epoch 5, gen_loss = 2.9161486235158196, disc_loss = 0.011334378800178268
Trained batch 116 in epoch 5, gen_loss = 2.9154164261288114, disc_loss = 0.011245012412675552
Trained batch 117 in epoch 5, gen_loss = 2.9161262734461637, disc_loss = 0.011159857289107927
Trained batch 118 in epoch 5, gen_loss = 2.915069253504777, disc_loss = 0.011074531257950835
Trained batch 119 in epoch 5, gen_loss = 2.9144689540068307, disc_loss = 0.010988414096451985
Trained batch 120 in epoch 5, gen_loss = 2.914396276158735, disc_loss = 0.01090419783126101
Trained batch 121 in epoch 5, gen_loss = 2.9156354450788653, disc_loss = 0.010821706647354896
Trained batch 122 in epoch 5, gen_loss = 2.911015576463405, disc_loss = 0.010793329884271645
Trained batch 123 in epoch 5, gen_loss = 2.907419564262513, disc_loss = 0.01078702942158411
Trained batch 124 in epoch 5, gen_loss = 2.905455696105957, disc_loss = 0.010721736467909068
Trained batch 125 in epoch 5, gen_loss = 2.9029279549916587, disc_loss = 0.010672541342154588
Trained batch 126 in epoch 5, gen_loss = 2.902683430769312, disc_loss = 0.010608069149054968
Trained batch 127 in epoch 5, gen_loss = 2.9011245891451836, disc_loss = 0.01054436587719465
Trained batch 128 in epoch 5, gen_loss = 2.900346637696259, disc_loss = 0.010479611874821545
Trained batch 129 in epoch 5, gen_loss = 2.903795288159297, disc_loss = 0.01041079050852344
Trained batch 130 in epoch 5, gen_loss = 2.9029143893991716, disc_loss = 0.01034435634776765
Trained batch 131 in epoch 5, gen_loss = 2.902536316351457, disc_loss = 0.01027753854930669
Trained batch 132 in epoch 5, gen_loss = 2.9023929574435816, disc_loss = 0.010210174889937463
Trained batch 133 in epoch 5, gen_loss = 2.89991090546793, disc_loss = 0.010143169558541016
Trained batch 134 in epoch 5, gen_loss = 2.9004747920566136, disc_loss = 0.010076899788152703
Trained batch 135 in epoch 5, gen_loss = 2.9012179024079265, disc_loss = 0.010013343723959919
Trained batch 136 in epoch 5, gen_loss = 2.9002123853586017, disc_loss = 0.009948601550677533
Trained batch 137 in epoch 5, gen_loss = 2.8988585921301357, disc_loss = 0.009885663632725271
Trained batch 138 in epoch 5, gen_loss = 2.898239684619492, disc_loss = 0.009825119603401813
Trained batch 139 in epoch 5, gen_loss = 2.896044720922198, disc_loss = 0.009764540480266858
Trained batch 140 in epoch 5, gen_loss = 2.895370346434573, disc_loss = 0.009703985341504243
Trained batch 141 in epoch 5, gen_loss = 2.8954027303507632, disc_loss = 0.00964403187267443
Trained batch 142 in epoch 5, gen_loss = 2.897532519760665, disc_loss = 0.009588517017835113
Trained batch 143 in epoch 5, gen_loss = 2.899462057484521, disc_loss = 0.009531449411345724
Trained batch 144 in epoch 5, gen_loss = 2.9024419406364705, disc_loss = 0.009475107935401772
Trained batch 145 in epoch 5, gen_loss = 2.905457612586348, disc_loss = 0.009420352309785962
Trained batch 146 in epoch 5, gen_loss = 2.904302269423089, disc_loss = 0.009368502008681166
Trained batch 147 in epoch 5, gen_loss = 2.9046407100316642, disc_loss = 0.009324672521403487
Trained batch 148 in epoch 5, gen_loss = 2.9056429350936175, disc_loss = 0.009271196548705108
Trained batch 149 in epoch 5, gen_loss = 2.904172356923421, disc_loss = 0.009226366787139947
Trained batch 150 in epoch 5, gen_loss = 2.906876890864593, disc_loss = 0.009194463013057652
Trained batch 151 in epoch 5, gen_loss = 2.9074966766332326, disc_loss = 0.009144877127638259
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 2.7714858055114746, disc_loss = 0.0020355088636279106
Trained batch 1 in epoch 6, gen_loss = 2.844752311706543, disc_loss = 0.0016585439443588257
Trained batch 2 in epoch 6, gen_loss = 2.923931280771891, disc_loss = 0.001494407265757521
Trained batch 3 in epoch 6, gen_loss = 2.9120993614196777, disc_loss = 0.0014602065784856677
Trained batch 4 in epoch 6, gen_loss = 2.9137343406677245, disc_loss = 0.001440925896167755
Trained batch 5 in epoch 6, gen_loss = 2.934428612391154, disc_loss = 0.0014381530539443095
Trained batch 6 in epoch 6, gen_loss = 2.9370340619768416, disc_loss = 0.0013760863470711879
Trained batch 7 in epoch 6, gen_loss = 2.941850423812866, disc_loss = 0.0014154409582260996
Trained batch 8 in epoch 6, gen_loss = 2.920154677497016, disc_loss = 0.0014189863577485085
Trained batch 9 in epoch 6, gen_loss = 2.9465991497039794, disc_loss = 0.0014120719861239195
Trained batch 10 in epoch 6, gen_loss = 2.94487511027943, disc_loss = 0.0014295415762303905
Trained batch 11 in epoch 6, gen_loss = 2.954721768697103, disc_loss = 0.0014007790499211599
Trained batch 12 in epoch 6, gen_loss = 2.980782618889442, disc_loss = 0.0013607091700228362
Trained batch 13 in epoch 6, gen_loss = 2.9768602677753995, disc_loss = 0.0013291202028215463
Trained batch 14 in epoch 6, gen_loss = 2.940614652633667, disc_loss = 0.009996354040534545
Trained batch 15 in epoch 6, gen_loss = 2.8681213334202766, disc_loss = 0.0504027935276099
Trained batch 16 in epoch 6, gen_loss = 2.8524897308910595, disc_loss = 0.07100392041577246
Trained batch 17 in epoch 6, gen_loss = 2.8937847018241882, disc_loss = 0.1366534559735252
Trained batch 18 in epoch 6, gen_loss = 2.907899574229592, disc_loss = 0.17666206819213634
Trained batch 19 in epoch 6, gen_loss = 2.8798142611980437, disc_loss = 0.18232512433605735
Trained batch 20 in epoch 6, gen_loss = 2.8557104553495134, disc_loss = 0.18929706262480023
Trained batch 21 in epoch 6, gen_loss = 2.829241682182659, disc_loss = 0.19271403785255228
Trained batch 22 in epoch 6, gen_loss = 2.8136502504348755, disc_loss = 0.19525828015352803
Trained batch 23 in epoch 6, gen_loss = 2.779634639620781, disc_loss = 0.19748073658411158
Trained batch 24 in epoch 6, gen_loss = 2.7549151849746703, disc_loss = 0.198930890832562
Trained batch 25 in epoch 6, gen_loss = 2.7405509536082926, disc_loss = 0.20011787715842588
Trained batch 26 in epoch 6, gen_loss = 2.721508604508859, disc_loss = 0.20088875539712953
Trained batch 27 in epoch 6, gen_loss = 2.707327038049698, disc_loss = 0.20158616051984218
Trained batch 28 in epoch 6, gen_loss = 2.689952698247186, disc_loss = 0.20199056969481874
Trained batch 29 in epoch 6, gen_loss = 2.676358473300934, disc_loss = 0.2020000489836093
Trained batch 30 in epoch 6, gen_loss = 2.659807778173877, disc_loss = 0.20192019519163296
Trained batch 31 in epoch 6, gen_loss = 2.648150149732828, disc_loss = 0.2016817570929561
Trained batch 32 in epoch 6, gen_loss = 2.6391887267430625, disc_loss = 0.20133999101006228
Trained batch 33 in epoch 6, gen_loss = 2.6240045077660503, disc_loss = 0.20058970874593154
Trained batch 34 in epoch 6, gen_loss = 2.60781101839883, disc_loss = 0.1989055167168512
Trained batch 35 in epoch 6, gen_loss = 2.5915964941183725, disc_loss = 0.19737954291081727
Trained batch 36 in epoch 6, gen_loss = 2.5819597663106144, disc_loss = 0.19549056986579672
Trained batch 37 in epoch 6, gen_loss = 2.574703081658012, disc_loss = 0.19445588575265566
Trained batch 38 in epoch 6, gen_loss = 2.5681772262622147, disc_loss = 0.19436278727460796
Trained batch 39 in epoch 6, gen_loss = 2.5581027656793593, disc_loss = 0.1947537014100817
Trained batch 40 in epoch 6, gen_loss = 2.5539420668671773, disc_loss = 0.20275630400567202
Trained batch 41 in epoch 6, gen_loss = 2.5531683507419767, disc_loss = 0.20961860902856902
Trained batch 42 in epoch 6, gen_loss = 2.550143150396125, disc_loss = 0.20956166554919206
Trained batch 43 in epoch 6, gen_loss = 2.549105413935401, disc_loss = 0.2100926822075218
Trained batch 44 in epoch 6, gen_loss = 2.536122441291809, disc_loss = 0.20938816118804324
Trained batch 45 in epoch 6, gen_loss = 2.540718050106712, disc_loss = 0.20819822033366148
Trained batch 46 in epoch 6, gen_loss = 2.533759449390655, disc_loss = 0.2068094707730702
Trained batch 47 in epoch 6, gen_loss = 2.5233793233831725, disc_loss = 0.20479614457023368
Trained batch 48 in epoch 6, gen_loss = 2.519729971885681, disc_loss = 0.20263779861496153
Trained batch 49 in epoch 6, gen_loss = 2.51555846452713, disc_loss = 0.20131462930352428
Trained batch 50 in epoch 6, gen_loss = 2.521151643173367, disc_loss = 0.20077713913690554
Trained batch 51 in epoch 6, gen_loss = 2.5201706771667185, disc_loss = 0.20027538158487565
Trained batch 52 in epoch 6, gen_loss = 2.5202789284148306, disc_loss = 0.19846745747919106
Trained batch 53 in epoch 6, gen_loss = 2.519149053979803, disc_loss = 0.19613016740509515
Trained batch 54 in epoch 6, gen_loss = 2.5202192848378964, disc_loss = 0.19372258103897116
Trained batch 55 in epoch 6, gen_loss = 2.5132544402565276, disc_loss = 0.19130803344160086
Trained batch 56 in epoch 6, gen_loss = 2.5215458681708887, disc_loss = 0.18935899533384495
Trained batch 57 in epoch 6, gen_loss = 2.523512332603849, disc_loss = 0.18810034587132296
Trained batch 58 in epoch 6, gen_loss = 2.533548971353951, disc_loss = 0.1885608092978423
Trained batch 59 in epoch 6, gen_loss = 2.533207978804906, disc_loss = 0.188139303700882
Trained batch 60 in epoch 6, gen_loss = 2.532980909113024, disc_loss = 0.18627208171003942
Trained batch 61 in epoch 6, gen_loss = 2.5358401402350395, disc_loss = 0.18459355199217586
Trained batch 62 in epoch 6, gen_loss = 2.5412727745752486, disc_loss = 0.18242992879545672
Trained batch 63 in epoch 6, gen_loss = 2.542318856343627, disc_loss = 0.1800552719987536
Trained batch 64 in epoch 6, gen_loss = 2.5441914833509003, disc_loss = 0.1776444662263832
Trained batch 65 in epoch 6, gen_loss = 2.553086224830512, disc_loss = 0.17585311081193417
Trained batch 66 in epoch 6, gen_loss = 2.560229029228438, disc_loss = 0.17555312764111544
Trained batch 67 in epoch 6, gen_loss = 2.5614693988772, disc_loss = 0.17435066551671993
Trained batch 68 in epoch 6, gen_loss = 2.5595671007598657, disc_loss = 0.17228846507487763
Trained batch 69 in epoch 6, gen_loss = 2.560215311391013, disc_loss = 0.1704140896950516
Trained batch 70 in epoch 6, gen_loss = 2.5614809872398916, disc_loss = 0.16842818164847081
Trained batch 71 in epoch 6, gen_loss = 2.5659099171559014, disc_loss = 0.16630736059758217
Trained batch 72 in epoch 6, gen_loss = 2.56814666806835, disc_loss = 0.1642514031343736
Trained batch 73 in epoch 6, gen_loss = 2.5700415678926416, disc_loss = 0.16220438713601135
Trained batch 74 in epoch 6, gen_loss = 2.5757306241989135, disc_loss = 0.1602276903181337
Trained batch 75 in epoch 6, gen_loss = 2.58444019210966, disc_loss = 0.15828448611596527
Trained batch 76 in epoch 6, gen_loss = 2.586429321920717, disc_loss = 0.15636985751803262
Trained batch 77 in epoch 6, gen_loss = 2.5902676536486697, disc_loss = 0.15445503056756793
Trained batch 78 in epoch 6, gen_loss = 2.593380223346662, disc_loss = 0.15257919343155985
Trained batch 79 in epoch 6, gen_loss = 2.5972438171505927, disc_loss = 0.15076615847428912
Trained batch 80 in epoch 6, gen_loss = 2.5985027610519786, disc_loss = 0.1490314955813063
Trained batch 81 in epoch 6, gen_loss = 2.603661117030353, disc_loss = 0.14737678232685117
Trained batch 82 in epoch 6, gen_loss = 2.615785091756338, disc_loss = 0.14579211045070609
Trained batch 83 in epoch 6, gen_loss = 2.6220909456411996, disc_loss = 0.14427975440810856
Trained batch 84 in epoch 6, gen_loss = 2.622479723481571, disc_loss = 0.14285192737040822
Trained batch 85 in epoch 6, gen_loss = 2.6301110220509907, disc_loss = 0.14128047086333662
Trained batch 86 in epoch 6, gen_loss = 2.635675111036191, disc_loss = 0.13972512531246797
Trained batch 87 in epoch 6, gen_loss = 2.6422835412350567, disc_loss = 0.1381973180349715
Trained batch 88 in epoch 6, gen_loss = 2.6485396596822848, disc_loss = 0.13670173175750677
Trained batch 89 in epoch 6, gen_loss = 2.6521750966707867, disc_loss = 0.1352282131537019
Trained batch 90 in epoch 6, gen_loss = 2.655020833015442, disc_loss = 0.13380546788339615
Trained batch 91 in epoch 6, gen_loss = 2.6559143882730734, disc_loss = 0.13241536057688316
Trained batch 92 in epoch 6, gen_loss = 2.6627075505513016, disc_loss = 0.1310561298403979
Trained batch 93 in epoch 6, gen_loss = 2.6673250236409776, disc_loss = 0.12972112733467006
Trained batch 94 in epoch 6, gen_loss = 2.6711522114904303, disc_loss = 0.12841009764601233
Trained batch 95 in epoch 6, gen_loss = 2.6749297864735126, disc_loss = 0.12712918716048685
Trained batch 96 in epoch 6, gen_loss = 2.6791151368740906, disc_loss = 0.12588587712758154
Trained batch 97 in epoch 6, gen_loss = 2.683106031953072, disc_loss = 0.1247335075316428
Trained batch 98 in epoch 6, gen_loss = 2.6848737218163232, disc_loss = 0.12370752721302908
Trained batch 99 in epoch 6, gen_loss = 2.690660475492477, disc_loss = 0.12280056459188927
Trained batch 100 in epoch 6, gen_loss = 2.693472405471424, disc_loss = 0.12172006773543406
Trained batch 101 in epoch 6, gen_loss = 2.6962330166031334, disc_loss = 0.12059195901497778
Trained batch 102 in epoch 6, gen_loss = 2.7009397166446574, disc_loss = 0.11948763375516384
Trained batch 103 in epoch 6, gen_loss = 2.7046213918007336, disc_loss = 0.11836445719158152
Trained batch 104 in epoch 6, gen_loss = 2.709771404947553, disc_loss = 0.11729735662728281
Trained batch 105 in epoch 6, gen_loss = 2.7105117372746736, disc_loss = 0.11626902131093578
Trained batch 106 in epoch 6, gen_loss = 2.7115871271240377, disc_loss = 0.11523635653076067
Trained batch 107 in epoch 6, gen_loss = 2.712569937661842, disc_loss = 0.11423018069224243
Trained batch 108 in epoch 6, gen_loss = 2.7175672371453103, disc_loss = 0.11328255784016428
Trained batch 109 in epoch 6, gen_loss = 2.716767366365953, disc_loss = 0.11233438137251968
Trained batch 110 in epoch 6, gen_loss = 2.72374596144702, disc_loss = 0.11137502772056053
Trained batch 111 in epoch 6, gen_loss = 2.727215252816677, disc_loss = 0.11042903452523335
Trained batch 112 in epoch 6, gen_loss = 2.7271504454908118, disc_loss = 0.10949672304301943
Trained batch 113 in epoch 6, gen_loss = 2.729037915405474, disc_loss = 0.10857395759810236
Trained batch 114 in epoch 6, gen_loss = 2.732678816629493, disc_loss = 0.10767289833621244
Trained batch 115 in epoch 6, gen_loss = 2.737795506058068, disc_loss = 0.10676760851367426
Trained batch 116 in epoch 6, gen_loss = 2.7390698316769724, disc_loss = 0.10588815489746073
Trained batch 117 in epoch 6, gen_loss = 2.7399507851923928, disc_loss = 0.10502400496921313
Trained batch 118 in epoch 6, gen_loss = 2.7413181847884873, disc_loss = 0.10417327807850338
Trained batch 119 in epoch 6, gen_loss = 2.74262031018734, disc_loss = 0.10332972096948652
Trained batch 120 in epoch 6, gen_loss = 2.7442540817024295, disc_loss = 0.1025108882261648
Trained batch 121 in epoch 6, gen_loss = 2.745442313248994, disc_loss = 0.10169154606601147
Trained batch 122 in epoch 6, gen_loss = 2.7490015097749914, disc_loss = 0.10088897700377975
Trained batch 123 in epoch 6, gen_loss = 2.7548991201385373, disc_loss = 0.10009672296573333
Trained batch 124 in epoch 6, gen_loss = 2.755549620628357, disc_loss = 0.09932101398566738
Trained batch 125 in epoch 6, gen_loss = 2.755394779500507, disc_loss = 0.0985573200321394
Trained batch 126 in epoch 6, gen_loss = 2.7581890089305365, disc_loss = 0.09780162032629458
Trained batch 127 in epoch 6, gen_loss = 2.7600290877744555, disc_loss = 0.09705160388375589
Trained batch 128 in epoch 6, gen_loss = 2.7651194130727488, disc_loss = 0.09631892511406336
Trained batch 129 in epoch 6, gen_loss = 2.7665976863641006, disc_loss = 0.09559836518780615
Trained batch 130 in epoch 6, gen_loss = 2.7673842388254997, disc_loss = 0.09488324657702847
Trained batch 131 in epoch 6, gen_loss = 2.769374550291986, disc_loss = 0.09417740349828929
Trained batch 132 in epoch 6, gen_loss = 2.770815283732307, disc_loss = 0.09348009711112197
Trained batch 133 in epoch 6, gen_loss = 2.7734674775778356, disc_loss = 0.09280571138439353
Trained batch 134 in epoch 6, gen_loss = 2.775262028199655, disc_loss = 0.09217582183105319
Trained batch 135 in epoch 6, gen_loss = 2.777800737934954, disc_loss = 0.09152612257586203
Trained batch 136 in epoch 6, gen_loss = 2.7775940677545368, disc_loss = 0.09087476255686573
Trained batch 137 in epoch 6, gen_loss = 2.7772324318471164, disc_loss = 0.09025654230187512
Trained batch 138 in epoch 6, gen_loss = 2.7787378254554254, disc_loss = 0.0896366010424212
Trained batch 139 in epoch 6, gen_loss = 2.7811437598296576, disc_loss = 0.08900715937613443
Trained batch 140 in epoch 6, gen_loss = 2.7818778854735355, disc_loss = 0.08840006250757658
Trained batch 141 in epoch 6, gen_loss = 2.7810777686011625, disc_loss = 0.08779832018042495
Trained batch 142 in epoch 6, gen_loss = 2.7825430231494503, disc_loss = 0.08719894367512772
Trained batch 143 in epoch 6, gen_loss = 2.7862233660287328, disc_loss = 0.08660564162103886
Trained batch 144 in epoch 6, gen_loss = 2.7891586443473555, disc_loss = 0.08602618858547367
Trained batch 145 in epoch 6, gen_loss = 2.7900082126055676, disc_loss = 0.08545763162961421
Trained batch 146 in epoch 6, gen_loss = 2.7931190388543263, disc_loss = 0.0848940565558879
Trained batch 147 in epoch 6, gen_loss = 2.7932916017802984, disc_loss = 0.08434013443931346
Trained batch 148 in epoch 6, gen_loss = 2.796239696893116, disc_loss = 0.08378881065920307
Trained batch 149 in epoch 6, gen_loss = 2.7972499537467956, disc_loss = 0.08324072411943538
Trained batch 150 in epoch 6, gen_loss = 2.795928152191718, disc_loss = 0.08274117784477486
Trained batch 151 in epoch 6, gen_loss = 2.794195423785009, disc_loss = 0.08227838477231623
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 3.2544476985931396, disc_loss = 0.005566476844251156
Trained batch 1 in epoch 7, gen_loss = 3.222556471824646, disc_loss = 0.004940677201375365
Trained batch 2 in epoch 7, gen_loss = 3.1701560815175376, disc_loss = 0.005384809958438079
Trained batch 3 in epoch 7, gen_loss = 3.1876734495162964, disc_loss = 0.00532989134080708
Trained batch 4 in epoch 7, gen_loss = 3.089122104644775, disc_loss = 0.005100661981850862
Trained batch 5 in epoch 7, gen_loss = 3.1087636947631836, disc_loss = 0.004946417485674222
Trained batch 6 in epoch 7, gen_loss = 3.0904151371547153, disc_loss = 0.004741036333143711
Trained batch 7 in epoch 7, gen_loss = 3.0652284026145935, disc_loss = 0.004842909693252295
Trained batch 8 in epoch 7, gen_loss = 3.0418191485934787, disc_loss = 0.005001202950047122
Trained batch 9 in epoch 7, gen_loss = 3.0045098781585695, disc_loss = 0.004731752490624785
Trained batch 10 in epoch 7, gen_loss = 3.008756074038419, disc_loss = 0.0044546465135433455
Trained batch 11 in epoch 7, gen_loss = 2.9996793270111084, disc_loss = 0.004362511176926394
Trained batch 12 in epoch 7, gen_loss = 3.0053509932297926, disc_loss = 0.004313012746234353
Trained batch 13 in epoch 7, gen_loss = 3.0194314207349504, disc_loss = 0.004165367971706603
Trained batch 14 in epoch 7, gen_loss = 3.018603277206421, disc_loss = 0.00403755361524721
Trained batch 15 in epoch 7, gen_loss = 3.0009812265634537, disc_loss = 0.00461636581167113
Trained batch 16 in epoch 7, gen_loss = 2.967300905900843, disc_loss = 0.00710820870967034
Trained batch 17 in epoch 7, gen_loss = 3.0102465947469077, disc_loss = 0.02124355964931763
Trained batch 18 in epoch 7, gen_loss = 2.9788991526553503, disc_loss = 0.025784461354640752
Trained batch 19 in epoch 7, gen_loss = 2.9693331837654116, disc_loss = 0.02752840392058715
Trained batch 20 in epoch 7, gen_loss = 2.9461958976019, disc_loss = 0.03191046189472434
Trained batch 21 in epoch 7, gen_loss = 2.9535127119584517, disc_loss = 0.0347733455604281
Trained batch 22 in epoch 7, gen_loss = 2.9329230267068613, disc_loss = 0.03671776166226229
Trained batch 23 in epoch 7, gen_loss = 2.9346356789271035, disc_loss = 0.03781147164409049
Trained batch 24 in epoch 7, gen_loss = 2.9037174129486085, disc_loss = 0.04247973251156509
Trained batch 25 in epoch 7, gen_loss = 2.9270384219976573, disc_loss = 0.054126308971227936
Trained batch 26 in epoch 7, gen_loss = 2.9167285760243735, disc_loss = 0.05538209764873264
Trained batch 27 in epoch 7, gen_loss = 2.9108568174498424, disc_loss = 0.05610078402761636
Trained batch 28 in epoch 7, gen_loss = 2.90945002128338, disc_loss = 0.055366420435943996
Trained batch 29 in epoch 7, gen_loss = 2.9145992437998456, disc_loss = 0.05479011041267465
Trained batch 30 in epoch 7, gen_loss = 2.9140395579799527, disc_loss = 0.05344089615579334
Trained batch 31 in epoch 7, gen_loss = 2.9229575842618942, disc_loss = 0.0523837126311264
Trained batch 32 in epoch 7, gen_loss = 2.9289132754007974, disc_loss = 0.05105557653234538
Trained batch 33 in epoch 7, gen_loss = 2.934006137006423, disc_loss = 0.04995776479379
Trained batch 34 in epoch 7, gen_loss = 2.9329734938485283, disc_loss = 0.04881292540979173
Trained batch 35 in epoch 7, gen_loss = 2.9280781348546348, disc_loss = 0.04789155340727626
Trained batch 36 in epoch 7, gen_loss = 2.926578779478331, disc_loss = 0.04681618709897471
Trained batch 37 in epoch 7, gen_loss = 2.929795409503736, disc_loss = 0.045811227222561444
Trained batch 38 in epoch 7, gen_loss = 2.916338290923681, disc_loss = 0.04553395189129962
Trained batch 39 in epoch 7, gen_loss = 2.901440644264221, disc_loss = 0.046172698069131005
Trained batch 40 in epoch 7, gen_loss = 2.915619623370287, disc_loss = 0.04675462391659072
Trained batch 41 in epoch 7, gen_loss = 2.9110188427425565, disc_loss = 0.04622665060395818
Trained batch 42 in epoch 7, gen_loss = 2.919489544491435, disc_loss = 0.04555278067303778
Trained batch 43 in epoch 7, gen_loss = 2.9096860072829505, disc_loss = 0.045016859483439475
Trained batch 44 in epoch 7, gen_loss = 2.9056484593285457, disc_loss = 0.044189901624081866
Trained batch 45 in epoch 7, gen_loss = 2.90796641163204, disc_loss = 0.04344545441942856
Trained batch 46 in epoch 7, gen_loss = 2.9151935628119934, disc_loss = 0.04269253073676311
Trained batch 47 in epoch 7, gen_loss = 2.9175477772951126, disc_loss = 0.04195624483691063
Trained batch 48 in epoch 7, gen_loss = 2.9301849384697114, disc_loss = 0.041298169362339744
Trained batch 49 in epoch 7, gen_loss = 2.927403030395508, disc_loss = 0.04070880000013858
Trained batch 50 in epoch 7, gen_loss = 2.924783360724356, disc_loss = 0.04012268137497207
Trained batch 51 in epoch 7, gen_loss = 2.9285276394623976, disc_loss = 0.0394687219388568
Trained batch 52 in epoch 7, gen_loss = 2.927308091577494, disc_loss = 0.03879568981938064
Trained batch 53 in epoch 7, gen_loss = 2.9351388613382974, disc_loss = 0.03817985882482457
Trained batch 54 in epoch 7, gen_loss = 2.9356343789534134, disc_loss = 0.03757873568260534
Trained batch 55 in epoch 7, gen_loss = 2.937569354261671, disc_loss = 0.03696392350580676
Trained batch 56 in epoch 7, gen_loss = 2.9483202172998797, disc_loss = 0.03636831476908635
Trained batch 57 in epoch 7, gen_loss = 2.9463628366075714, disc_loss = 0.03579067720646231
Trained batch 58 in epoch 7, gen_loss = 2.9429970717026017, disc_loss = 0.03528212760654041
Trained batch 59 in epoch 7, gen_loss = 2.9424537658691405, disc_loss = 0.034754874211891246
Trained batch 60 in epoch 7, gen_loss = 2.947240575415189, disc_loss = 0.03423908054370616
Trained batch 61 in epoch 7, gen_loss = 2.947210823335955, disc_loss = 0.03373640681797218
Trained batch 62 in epoch 7, gen_loss = 2.943068265914917, disc_loss = 0.033253004190526785
Trained batch 63 in epoch 7, gen_loss = 2.9423966258764267, disc_loss = 0.03278121958646807
Trained batch 64 in epoch 7, gen_loss = 2.9392904721773587, disc_loss = 0.032332076393784236
Trained batch 65 in epoch 7, gen_loss = 2.9405871665838994, disc_loss = 0.03188082326739801
Trained batch 66 in epoch 7, gen_loss = 2.9378209042904984, disc_loss = 0.031494085537964726
Trained batch 67 in epoch 7, gen_loss = 2.9359038998098934, disc_loss = 0.031195254790980148
Trained batch 68 in epoch 7, gen_loss = 2.9391260803609653, disc_loss = 0.030809038959821497
Trained batch 69 in epoch 7, gen_loss = 2.9391091891697476, disc_loss = 0.03040994261391461
Trained batch 70 in epoch 7, gen_loss = 2.946256402512671, disc_loss = 0.03002671230400742
Trained batch 71 in epoch 7, gen_loss = 2.9504833420117698, disc_loss = 0.029718095701860472
Trained batch 72 in epoch 7, gen_loss = 2.953434650212118, disc_loss = 0.02935172597022906
Trained batch 73 in epoch 7, gen_loss = 2.955532518593041, disc_loss = 0.028985543768047482
Trained batch 74 in epoch 7, gen_loss = 2.954720935821533, disc_loss = 0.028669013138860465
Trained batch 75 in epoch 7, gen_loss = 2.957445508555362, disc_loss = 0.028361659735980396
Trained batch 76 in epoch 7, gen_loss = 2.954582375365418, disc_loss = 0.028021295687982013
Trained batch 77 in epoch 7, gen_loss = 2.953184818610167, disc_loss = 0.027729572095454503
Trained batch 78 in epoch 7, gen_loss = 2.957779313944563, disc_loss = 0.027422058068899604
Trained batch 79 in epoch 7, gen_loss = 2.9581498384475706, disc_loss = 0.02714979760639835
Trained batch 80 in epoch 7, gen_loss = 2.95889992772797, disc_loss = 0.026869558835586095
Trained batch 81 in epoch 7, gen_loss = 2.958209596029142, disc_loss = 0.026580894169988246
Trained batch 82 in epoch 7, gen_loss = 2.9575377142572976, disc_loss = 0.026294816882876926
Trained batch 83 in epoch 7, gen_loss = 2.958995750972203, disc_loss = 0.026039460061361923
Trained batch 84 in epoch 7, gen_loss = 2.961183015037985, disc_loss = 0.0257739806712112
Trained batch 85 in epoch 7, gen_loss = 2.963721668997476, disc_loss = 0.02550223231488882
Trained batch 86 in epoch 7, gen_loss = 2.9600675791159445, disc_loss = 0.025268828426755364
Trained batch 87 in epoch 7, gen_loss = 2.9617816453630272, disc_loss = 0.02509283354315399
Trained batch 88 in epoch 7, gen_loss = 2.961407152454505, disc_loss = 0.0248385518004469
Trained batch 89 in epoch 7, gen_loss = 2.962693225012885, disc_loss = 0.024591578408661816
Trained batch 90 in epoch 7, gen_loss = 2.9613171566973677, disc_loss = 0.024341629209140174
Trained batch 91 in epoch 7, gen_loss = 2.964396598546401, disc_loss = 0.024129135822674827
Trained batch 92 in epoch 7, gen_loss = 2.9675104566799697, disc_loss = 0.0239082835965179
Trained batch 93 in epoch 7, gen_loss = 2.963997665871965, disc_loss = 0.023688133119882895
Trained batch 94 in epoch 7, gen_loss = 2.9642251642126785, disc_loss = 0.02346685773840076
Trained batch 95 in epoch 7, gen_loss = 2.964962787926197, disc_loss = 0.023245344947402675
Trained batch 96 in epoch 7, gen_loss = 2.9646788184175787, disc_loss = 0.0230209089301949
Trained batch 97 in epoch 7, gen_loss = 2.96471268060256, disc_loss = 0.0228003233823241
Trained batch 98 in epoch 7, gen_loss = 2.96273104590599, disc_loss = 0.022592612650395943
Trained batch 99 in epoch 7, gen_loss = 2.961889717578888, disc_loss = 0.022390097831375896
Trained batch 100 in epoch 7, gen_loss = 2.967513820912578, disc_loss = 0.022193417195138513
Trained batch 101 in epoch 7, gen_loss = 2.9673905606363333, disc_loss = 0.022008589452917816
Trained batch 102 in epoch 7, gen_loss = 2.966182796700487, disc_loss = 0.021814965127596578
Trained batch 103 in epoch 7, gen_loss = 2.9666992792716393, disc_loss = 0.021619055341803826
Trained batch 104 in epoch 7, gen_loss = 2.9676656495957148, disc_loss = 0.021431317397703726
Trained batch 105 in epoch 7, gen_loss = 2.9689585712720765, disc_loss = 0.02124992392315828
Trained batch 106 in epoch 7, gen_loss = 2.9692054195938824, disc_loss = 0.021075071064128637
Trained batch 107 in epoch 7, gen_loss = 2.9669697748290167, disc_loss = 0.020903317320281296
Trained batch 108 in epoch 7, gen_loss = 2.9663484862091343, disc_loss = 0.02073221233963898
Trained batch 109 in epoch 7, gen_loss = 2.96550536589189, disc_loss = 0.020572380514138126
Trained batch 110 in epoch 7, gen_loss = 2.9641926739666915, disc_loss = 0.020402233556819124
Trained batch 111 in epoch 7, gen_loss = 2.9647243725402013, disc_loss = 0.020232870236213785
Trained batch 112 in epoch 7, gen_loss = 2.9623230010007333, disc_loss = 0.020092445505016474
Trained batch 113 in epoch 7, gen_loss = 2.9620226077866136, disc_loss = 0.01993521365332989
Trained batch 114 in epoch 7, gen_loss = 2.963989065004432, disc_loss = 0.019789211005579843
Trained batch 115 in epoch 7, gen_loss = 2.9644175582918626, disc_loss = 0.019637548128857502
Trained batch 116 in epoch 7, gen_loss = 2.9614058498643403, disc_loss = 0.019558959358976755
Trained batch 117 in epoch 7, gen_loss = 2.9608939481993852, disc_loss = 0.019623958329093975
Trained batch 118 in epoch 7, gen_loss = 2.9619991619045996, disc_loss = 0.019625434148156654
Trained batch 119 in epoch 7, gen_loss = 2.9625707626342774, disc_loss = 0.019572479430159242
Trained batch 120 in epoch 7, gen_loss = 2.9606234061816505, disc_loss = 0.019520438342616887
Trained batch 121 in epoch 7, gen_loss = 2.9586931173918676, disc_loss = 0.019450980800654372
Trained batch 122 in epoch 7, gen_loss = 2.9581907532079432, disc_loss = 0.01932045686289638
Trained batch 123 in epoch 7, gen_loss = 2.957921802997589, disc_loss = 0.019184129674085264
Trained batch 124 in epoch 7, gen_loss = 2.9570011444091797, disc_loss = 0.019047099106945097
Trained batch 125 in epoch 7, gen_loss = 2.9588436947928534, disc_loss = 0.01890853231510384
Trained batch 126 in epoch 7, gen_loss = 2.9586142573769636, disc_loss = 0.018770085945615442
Trained batch 127 in epoch 7, gen_loss = 2.9593035243451595, disc_loss = 0.01863588384094328
Trained batch 128 in epoch 7, gen_loss = 2.958288268525471, disc_loss = 0.018500382263870376
Trained batch 129 in epoch 7, gen_loss = 2.958893350454477, disc_loss = 0.018373165860807953
Trained batch 130 in epoch 7, gen_loss = 2.9596248219031414, disc_loss = 0.018245606285960676
Trained batch 131 in epoch 7, gen_loss = 2.9606944792198413, disc_loss = 0.018117781071465066
Trained batch 132 in epoch 7, gen_loss = 2.9584018574621442, disc_loss = 0.017990869917220584
Trained batch 133 in epoch 7, gen_loss = 2.9591567498534475, disc_loss = 0.017864125890226394
Trained batch 134 in epoch 7, gen_loss = 2.9621609634823267, disc_loss = 0.017746183014026393
Trained batch 135 in epoch 7, gen_loss = 2.959536890773212, disc_loss = 0.017760730581358075
Trained batch 136 in epoch 7, gen_loss = 2.9528585350426444, disc_loss = 0.0189755109349524
Trained batch 137 in epoch 7, gen_loss = 2.956306219100952, disc_loss = 0.022829782123259014
Trained batch 138 in epoch 7, gen_loss = 2.9542553253311046, disc_loss = 0.023265190328732668
Trained batch 139 in epoch 7, gen_loss = 2.9500291551862445, disc_loss = 0.023673077952116726
Trained batch 140 in epoch 7, gen_loss = 2.9457721033840314, disc_loss = 0.024027751018920688
Trained batch 141 in epoch 7, gen_loss = 2.941322363598246, disc_loss = 0.02419269495499386
Trained batch 142 in epoch 7, gen_loss = 2.939933350036194, disc_loss = 0.024193927762912702
Trained batch 143 in epoch 7, gen_loss = 2.937864041990704, disc_loss = 0.024095751306352515
Trained batch 144 in epoch 7, gen_loss = 2.936881395866131, disc_loss = 0.02396043595890033
Trained batch 145 in epoch 7, gen_loss = 2.935957237465741, disc_loss = 0.023874264207273108
Trained batch 146 in epoch 7, gen_loss = 2.9356025254645317, disc_loss = 0.02377088281459042
Trained batch 147 in epoch 7, gen_loss = 2.9368639475590474, disc_loss = 0.023660696278376556
Trained batch 148 in epoch 7, gen_loss = 2.9376335336057933, disc_loss = 0.023588308711354963
Trained batch 149 in epoch 7, gen_loss = 2.938742980957031, disc_loss = 0.023473190926015377
Trained batch 150 in epoch 7, gen_loss = 2.9371082072226415, disc_loss = 0.023376225944090362
Trained batch 151 in epoch 7, gen_loss = 2.936762163513585, disc_loss = 0.023281613076840967
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 3.250518798828125, disc_loss = 0.010298818349838257
Trained batch 1 in epoch 8, gen_loss = 3.0859322547912598, disc_loss = 0.007336153648793697
Trained batch 2 in epoch 8, gen_loss = 2.9739370346069336, disc_loss = 0.006280554768939813
Trained batch 3 in epoch 8, gen_loss = 2.978864073753357, disc_loss = 0.006162099074572325
Trained batch 4 in epoch 8, gen_loss = 2.929148864746094, disc_loss = 0.005341184139251709
Trained batch 5 in epoch 8, gen_loss = 2.9736598332722983, disc_loss = 0.004943514475598931
Trained batch 6 in epoch 8, gen_loss = 2.9337069307054793, disc_loss = 0.004826300644448825
Trained batch 7 in epoch 8, gen_loss = 2.8879355788230896, disc_loss = 0.0046479369048029184
Trained batch 8 in epoch 8, gen_loss = 2.8928186098734536, disc_loss = 0.00454554264433682
Trained batch 9 in epoch 8, gen_loss = 2.884589171409607, disc_loss = 0.0043610002845525745
Trained batch 10 in epoch 8, gen_loss = 2.9047097726301714, disc_loss = 0.004228485451841896
Trained batch 11 in epoch 8, gen_loss = 2.9087477723757424, disc_loss = 0.004049819312058389
Trained batch 12 in epoch 8, gen_loss = 2.915298113456139, disc_loss = 0.0040596853941679
Trained batch 13 in epoch 8, gen_loss = 2.9006886141640797, disc_loss = 0.004259238485246897
Trained batch 14 in epoch 8, gen_loss = 2.905212736129761, disc_loss = 0.0043584448595841725
Trained batch 15 in epoch 8, gen_loss = 2.9016795605421066, disc_loss = 0.004230970022035763
Trained batch 16 in epoch 8, gen_loss = 2.906362968332627, disc_loss = 0.004202755537870175
Trained batch 17 in epoch 8, gen_loss = 2.903179128964742, disc_loss = 0.004124526839910282
Trained batch 18 in epoch 8, gen_loss = 2.898086196497867, disc_loss = 0.004049119208694289
Trained batch 19 in epoch 8, gen_loss = 2.9104198455810546, disc_loss = 0.003977776982355863
Trained batch 20 in epoch 8, gen_loss = 2.9211306344895136, disc_loss = 0.0038757077861754667
Trained batch 21 in epoch 8, gen_loss = 2.9259300990538164, disc_loss = 0.003812491110610691
Trained batch 22 in epoch 8, gen_loss = 2.9266312433325727, disc_loss = 0.0037168894600852027
Trained batch 23 in epoch 8, gen_loss = 2.930004437764486, disc_loss = 0.0036295231111580506
Trained batch 24 in epoch 8, gen_loss = 2.9365595626831054, disc_loss = 0.0035429210541769863
Trained batch 25 in epoch 8, gen_loss = 2.9409019396855283, disc_loss = 0.0034963788527350584
Trained batch 26 in epoch 8, gen_loss = 2.927234861585829, disc_loss = 0.0035053487410078997
Trained batch 27 in epoch 8, gen_loss = 2.9229758637292043, disc_loss = 0.003454625652271456
Trained batch 28 in epoch 8, gen_loss = 2.9201591508141878, disc_loss = 0.003401763620786369
Trained batch 29 in epoch 8, gen_loss = 2.9225728114446006, disc_loss = 0.003370796846381078
Trained batch 30 in epoch 8, gen_loss = 2.9272048704085813, disc_loss = 0.0033384435847702044
Trained batch 31 in epoch 8, gen_loss = 2.923516809940338, disc_loss = 0.0033020330338331405
Trained batch 32 in epoch 8, gen_loss = 2.925887512438225, disc_loss = 0.003300644136316171
Trained batch 33 in epoch 8, gen_loss = 2.921985584146836, disc_loss = 0.0032675731002681833
Trained batch 34 in epoch 8, gen_loss = 2.9103785651070733, disc_loss = 0.003310472588054836
Trained batch 35 in epoch 8, gen_loss = 2.9111402697033353, disc_loss = 0.003318465421519553
Trained batch 36 in epoch 8, gen_loss = 2.9230953551627494, disc_loss = 0.0032745772135771207
Trained batch 37 in epoch 8, gen_loss = 2.9215362260216162, disc_loss = 0.0032230782641195937
Trained batch 38 in epoch 8, gen_loss = 2.9231194593967538, disc_loss = 0.003170820959031773
Trained batch 39 in epoch 8, gen_loss = 2.908036357164383, disc_loss = 0.006133812482585199
Trained batch 40 in epoch 8, gen_loss = 2.8838323122117577, disc_loss = 0.01144381358413162
Trained batch 41 in epoch 8, gen_loss = 2.879123270511627, disc_loss = 0.012678345756804836
Trained batch 42 in epoch 8, gen_loss = 2.87679409703543, disc_loss = 0.015498641274631197
Trained batch 43 in epoch 8, gen_loss = 2.8678914227268915, disc_loss = 0.018393519929800692
Trained batch 44 in epoch 8, gen_loss = 2.8587910307778253, disc_loss = 0.020557856065635052
Trained batch 45 in epoch 8, gen_loss = 2.861610534398452, disc_loss = 0.02215549074690384
Trained batch 46 in epoch 8, gen_loss = 2.8600346560173846, disc_loss = 0.022929525361990832
Trained batch 47 in epoch 8, gen_loss = 2.8627502198020616, disc_loss = 0.02282959494671862
Trained batch 48 in epoch 8, gen_loss = 2.862971074727117, disc_loss = 0.022589896142729844
Trained batch 49 in epoch 8, gen_loss = 2.877190010547638, disc_loss = 0.022643710079137236
Trained batch 50 in epoch 8, gen_loss = 2.8679368098576865, disc_loss = 0.025134819689864182
Trained batch 51 in epoch 8, gen_loss = 2.8831687271595, disc_loss = 0.029913640081828747
Trained batch 52 in epoch 8, gen_loss = 2.8743599158413007, disc_loss = 0.03018996007257264
Trained batch 53 in epoch 8, gen_loss = 2.8742675185203552, disc_loss = 0.031184995618079685
Trained batch 54 in epoch 8, gen_loss = 2.8743053718046707, disc_loss = 0.031290720269845966
Trained batch 55 in epoch 8, gen_loss = 2.8759858970131194, disc_loss = 0.03159319736005273
Trained batch 56 in epoch 8, gen_loss = 2.880290995564377, disc_loss = 0.031255697457757046
Trained batch 57 in epoch 8, gen_loss = 2.879110305473722, disc_loss = 0.030992461161704028
Trained batch 58 in epoch 8, gen_loss = 2.8846685866178094, disc_loss = 0.030599234532959506
Trained batch 59 in epoch 8, gen_loss = 2.8886652410030367, disc_loss = 0.030253506329609083
Trained batch 60 in epoch 8, gen_loss = 2.8911331383908383, disc_loss = 0.029895378507627936
Trained batch 61 in epoch 8, gen_loss = 2.8887073474545635, disc_loss = 0.029526780511537988
Trained batch 62 in epoch 8, gen_loss = 2.887708926957751, disc_loss = 0.029190877336077392
Trained batch 63 in epoch 8, gen_loss = 2.8898889999836683, disc_loss = 0.02885335652717913
Trained batch 64 in epoch 8, gen_loss = 2.8903495183357824, disc_loss = 0.028666605608752713
Trained batch 65 in epoch 8, gen_loss = 2.8900792111049998, disc_loss = 0.028358194308538892
Trained batch 66 in epoch 8, gen_loss = 2.888940172408944, disc_loss = 0.028014119563332357
Trained batch 67 in epoch 8, gen_loss = 2.889023309244829, disc_loss = 0.027651621705016997
Trained batch 68 in epoch 8, gen_loss = 2.8895806212356123, disc_loss = 0.02731026964687297
Trained batch 69 in epoch 8, gen_loss = 2.889848026207515, disc_loss = 0.027007473983602332
Trained batch 70 in epoch 8, gen_loss = 2.889970304260791, disc_loss = 0.026688807819392795
Trained batch 71 in epoch 8, gen_loss = 2.8925133066044912, disc_loss = 0.0263803005913764
Trained batch 72 in epoch 8, gen_loss = 2.890933195205584, disc_loss = 0.02607470093620303
Trained batch 73 in epoch 8, gen_loss = 2.8942044828389144, disc_loss = 0.02579104120534769
Trained batch 74 in epoch 8, gen_loss = 2.895705469449361, disc_loss = 0.02550620651959131
Trained batch 75 in epoch 8, gen_loss = 2.893317399840606, disc_loss = 0.025217004100436737
Trained batch 76 in epoch 8, gen_loss = 2.891296050765298, disc_loss = 0.024971532954398978
Trained batch 77 in epoch 8, gen_loss = 2.8953302655464563, disc_loss = 0.024715705671741698
Trained batch 78 in epoch 8, gen_loss = 2.89434733119192, disc_loss = 0.024449966598856204
Trained batch 79 in epoch 8, gen_loss = 2.895469655096531, disc_loss = 0.024182228454446886
Trained batch 80 in epoch 8, gen_loss = 2.895305431919333, disc_loss = 0.02393333394408088
Trained batch 81 in epoch 8, gen_loss = 2.8898080689151113, disc_loss = 0.02499487515817192
Trained batch 82 in epoch 8, gen_loss = 2.8794666528701782, disc_loss = 0.028118827179668987
Trained batch 83 in epoch 8, gen_loss = 2.881863902012507, disc_loss = 0.028859959395569085
Trained batch 84 in epoch 8, gen_loss = 2.8815357278375067, disc_loss = 0.030003897858071414
Trained batch 85 in epoch 8, gen_loss = 2.8790610349455545, disc_loss = 0.030388060449568426
Trained batch 86 in epoch 8, gen_loss = 2.87712762958702, disc_loss = 0.03030170552866084
Trained batch 87 in epoch 8, gen_loss = 2.87448227270083, disc_loss = 0.030235281310689806
Trained batch 88 in epoch 8, gen_loss = 2.877088403433896, disc_loss = 0.029991126086908192
Trained batch 89 in epoch 8, gen_loss = 2.8790527595414055, disc_loss = 0.029726031087597624
Trained batch 90 in epoch 8, gen_loss = 2.8776475191116333, disc_loss = 0.029446926977290965
Trained batch 91 in epoch 8, gen_loss = 2.8799797801867775, disc_loss = 0.029165535379434004
Trained batch 92 in epoch 8, gen_loss = 2.879763863419974, disc_loss = 0.028882188280613754
Trained batch 93 in epoch 8, gen_loss = 2.8818328545448626, disc_loss = 0.028607082559400178
Trained batch 94 in epoch 8, gen_loss = 2.882887434959412, disc_loss = 0.02833823446601041
Trained batch 95 in epoch 8, gen_loss = 2.8839429977039495, disc_loss = 0.02806590494462095
Trained batch 96 in epoch 8, gen_loss = 2.8822644629429295, disc_loss = 0.027851615935208796
Trained batch 97 in epoch 8, gen_loss = 2.884624102894141, disc_loss = 0.02761288676577221
Trained batch 98 in epoch 8, gen_loss = 2.888746804661221, disc_loss = 0.02736933131801021
Trained batch 99 in epoch 8, gen_loss = 2.8861842381954195, disc_loss = 0.027184896398102863
Trained batch 100 in epoch 8, gen_loss = 2.8852651603151074, disc_loss = 0.026982977196786294
Trained batch 101 in epoch 8, gen_loss = 2.8851414883837982, disc_loss = 0.02675779132222684
Trained batch 102 in epoch 8, gen_loss = 2.887811610999617, disc_loss = 0.026538154746640872
Trained batch 103 in epoch 8, gen_loss = 2.8877920313523364, disc_loss = 0.026416626789096672
Trained batch 104 in epoch 8, gen_loss = 2.891379396120707, disc_loss = 0.02622393619246958
Trained batch 105 in epoch 8, gen_loss = 2.8914313260114417, disc_loss = 0.026064676736736285
Trained batch 106 in epoch 8, gen_loss = 2.8917827193982135, disc_loss = 0.025859150368607142
Trained batch 107 in epoch 8, gen_loss = 2.8943631836661585, disc_loss = 0.025659975426538882
Trained batch 108 in epoch 8, gen_loss = 2.8933590344332774, disc_loss = 0.025465399666620984
Trained batch 109 in epoch 8, gen_loss = 2.890888353911313, disc_loss = 0.025271750274325974
Trained batch 110 in epoch 8, gen_loss = 2.8992806995237195, disc_loss = 0.025075231128170884
Trained batch 111 in epoch 8, gen_loss = 2.9030543491244316, disc_loss = 0.024904838188376743
Trained batch 112 in epoch 8, gen_loss = 2.9036514094445556, disc_loss = 0.024706609154622836
Trained batch 113 in epoch 8, gen_loss = 2.9030985424393103, disc_loss = 0.02451299191677224
Trained batch 114 in epoch 8, gen_loss = 2.906308048704396, disc_loss = 0.02431793927680701
Trained batch 115 in epoch 8, gen_loss = 2.9075618992591727, disc_loss = 0.024139529532664617
Trained batch 116 in epoch 8, gen_loss = 2.9078957576018114, disc_loss = 0.02397634665796167
Trained batch 117 in epoch 8, gen_loss = 2.908519695370884, disc_loss = 0.023796258972744632
Trained batch 118 in epoch 8, gen_loss = 2.9061458421354533, disc_loss = 0.023623423565750427
Trained batch 119 in epoch 8, gen_loss = 2.9048401743173597, disc_loss = 0.023454038760974072
Trained batch 120 in epoch 8, gen_loss = 2.908104006909142, disc_loss = 0.02328912423604191
Trained batch 121 in epoch 8, gen_loss = 2.909615656391519, disc_loss = 0.023125444919626672
Trained batch 122 in epoch 8, gen_loss = 2.911724682745895, disc_loss = 0.022969944787787168
Trained batch 123 in epoch 8, gen_loss = 2.9108643291458005, disc_loss = 0.02280496667803926
Trained batch 124 in epoch 8, gen_loss = 2.9125003576278687, disc_loss = 0.022648560077883302
Trained batch 125 in epoch 8, gen_loss = 2.913012855582767, disc_loss = 0.02249081135405937
Trained batch 126 in epoch 8, gen_loss = 2.912192792404355, disc_loss = 0.022340239297899262
Trained batch 127 in epoch 8, gen_loss = 2.915891815908253, disc_loss = 0.022181485363944375
Trained batch 128 in epoch 8, gen_loss = 2.9199740008790362, disc_loss = 0.022021570909847757
Trained batch 129 in epoch 8, gen_loss = 2.923228763617002, disc_loss = 0.02186623790408843
Trained batch 130 in epoch 8, gen_loss = 2.9225984829982727, disc_loss = 0.02172074222204965
Trained batch 131 in epoch 8, gen_loss = 2.9252367769226884, disc_loss = 0.02156612201184599
Trained batch 132 in epoch 8, gen_loss = 2.9242031690769625, disc_loss = 0.02142286731833522
Trained batch 133 in epoch 8, gen_loss = 2.924862300282094, disc_loss = 0.021300744861294862
Trained batch 134 in epoch 8, gen_loss = 2.926056338239599, disc_loss = 0.021157619855539114
Trained batch 135 in epoch 8, gen_loss = 2.924971835578189, disc_loss = 0.021022196321556455
Trained batch 136 in epoch 8, gen_loss = 2.9260865623933556, disc_loss = 0.020880000856127182
Trained batch 137 in epoch 8, gen_loss = 2.9259164134661355, disc_loss = 0.02073984480618189
Trained batch 138 in epoch 8, gen_loss = 2.928681326427048, disc_loss = 0.020632724956066596
Trained batch 139 in epoch 8, gen_loss = 2.932106885739735, disc_loss = 0.020516328265823957
Trained batch 140 in epoch 8, gen_loss = 2.932782747221331, disc_loss = 0.02038687583990395
Trained batch 141 in epoch 8, gen_loss = 2.9343166661934115, disc_loss = 0.02026904348618495
Trained batch 142 in epoch 8, gen_loss = 2.937619915375343, disc_loss = 0.020148619822180875
Trained batch 143 in epoch 8, gen_loss = 2.9378643888566227, disc_loss = 0.02001852909759489
Trained batch 144 in epoch 8, gen_loss = 2.937869174727078, disc_loss = 0.01989022909808133
Trained batch 145 in epoch 8, gen_loss = 2.9390814933058333, disc_loss = 0.019767566752294716
Trained batch 146 in epoch 8, gen_loss = 2.939350506886333, disc_loss = 0.019646836657767647
Trained batch 147 in epoch 8, gen_loss = 2.9380324845378465, disc_loss = 0.01952586692326853
Trained batch 148 in epoch 8, gen_loss = 2.9391924510866203, disc_loss = 0.01940113604115635
Trained batch 149 in epoch 8, gen_loss = 2.939655891259511, disc_loss = 0.01927915286971256
Trained batch 150 in epoch 8, gen_loss = 2.941680989518071, disc_loss = 0.01917684034502985
Trained batch 151 in epoch 8, gen_loss = 2.9406794364515103, disc_loss = 0.01906860270154491
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 3.0841150283813477, disc_loss = 0.0015964740887284279
Trained batch 1 in epoch 9, gen_loss = 3.0131068229675293, disc_loss = 0.0017848432762548327
Trained batch 2 in epoch 9, gen_loss = 3.0311789512634277, disc_loss = 0.0021107092034071684
Trained batch 3 in epoch 9, gen_loss = 2.963420271873474, disc_loss = 0.0023371806601062417
Trained batch 4 in epoch 9, gen_loss = 2.9285497665405273, disc_loss = 0.0023940316867083313
Trained batch 5 in epoch 9, gen_loss = 2.9276475509007773, disc_loss = 0.002472822981265684
Trained batch 6 in epoch 9, gen_loss = 2.9531151907784596, disc_loss = 0.0023186362980465803
Trained batch 7 in epoch 9, gen_loss = 2.973689377307892, disc_loss = 0.00229777475760784
Trained batch 8 in epoch 9, gen_loss = 2.991743723551432, disc_loss = 0.002164571300252444
Trained batch 9 in epoch 9, gen_loss = 3.0006394386291504, disc_loss = 0.0020887093152850865
Trained batch 10 in epoch 9, gen_loss = 3.015647433020852, disc_loss = 0.0020340863107280297
Trained batch 11 in epoch 9, gen_loss = 3.02386881907781, disc_loss = 0.0019699495654397956
Trained batch 12 in epoch 9, gen_loss = 3.0242943580334005, disc_loss = 0.0019077456090599298
Trained batch 13 in epoch 9, gen_loss = 3.038099476269313, disc_loss = 0.0018366093364810304
Trained batch 14 in epoch 9, gen_loss = 3.0189736048380533, disc_loss = 0.0018116762240727744
Trained batch 15 in epoch 9, gen_loss = 3.0352648496627808, disc_loss = 0.0017894985867314972
Trained batch 16 in epoch 9, gen_loss = 3.035851141985725, disc_loss = 0.0017356208306463325
Trained batch 17 in epoch 9, gen_loss = 3.030685782432556, disc_loss = 0.0017080144866162704
Trained batch 18 in epoch 9, gen_loss = 3.0226230746821354, disc_loss = 0.0017204362911319262
Trained batch 19 in epoch 9, gen_loss = 3.0318808555603027, disc_loss = 0.0017171747458633035
Trained batch 20 in epoch 9, gen_loss = 3.040641943613688, disc_loss = 0.0016768994059280626
Trained batch 21 in epoch 9, gen_loss = 3.034136165272106, disc_loss = 0.0016417166678531264
Trained batch 22 in epoch 9, gen_loss = 3.0245255180027173, disc_loss = 0.0017795560997910798
Trained batch 23 in epoch 9, gen_loss = 3.0327816009521484, disc_loss = 0.0018621275060771343
Trained batch 24 in epoch 9, gen_loss = 3.045052967071533, disc_loss = 0.0018804881698451937
Trained batch 25 in epoch 9, gen_loss = 3.0507513743180494, disc_loss = 0.0018651464286869248
Trained batch 26 in epoch 9, gen_loss = 3.040825013761167, disc_loss = 0.0018390489858575165
Trained batch 27 in epoch 9, gen_loss = 3.0534535476139615, disc_loss = 0.0018421856366330758
Trained batch 28 in epoch 9, gen_loss = 3.0441129454250992, disc_loss = 0.001858875410358325
Trained batch 29 in epoch 9, gen_loss = 3.029259173075358, disc_loss = 0.0018414016948857656
Trained batch 30 in epoch 9, gen_loss = 3.0237367768441477, disc_loss = 0.001956263314857478
Trained batch 31 in epoch 9, gen_loss = 3.026743523776531, disc_loss = 0.0019894257329724496
Trained batch 32 in epoch 9, gen_loss = 3.0240023136138916, disc_loss = 0.001965488185471093
Trained batch 33 in epoch 9, gen_loss = 3.0243364292032577, disc_loss = 0.0019650643893435378
Trained batch 34 in epoch 9, gen_loss = 3.012310416357858, disc_loss = 0.002610691848011421
Trained batch 35 in epoch 9, gen_loss = 2.987239122390747, disc_loss = 0.005655969077553082
Trained batch 36 in epoch 9, gen_loss = 3.006821748372671, disc_loss = 0.009021077907606456
Trained batch 37 in epoch 9, gen_loss = 3.01671922834296, disc_loss = 0.008909421334177941
Trained batch 38 in epoch 9, gen_loss = 3.0089227297367196, disc_loss = 0.009065439373863718
Trained batch 39 in epoch 9, gen_loss = 3.0048785507678986, disc_loss = 0.009078537368623074
Trained batch 40 in epoch 9, gen_loss = 2.999789691552883, disc_loss = 0.00892969972607339
Trained batch 41 in epoch 9, gen_loss = 2.9992515586671376, disc_loss = 0.008807419986364298
Trained batch 42 in epoch 9, gen_loss = 3.0004629700682885, disc_loss = 0.008672977216964112
Trained batch 43 in epoch 9, gen_loss = 2.99443119764328, disc_loss = 0.008584534509943544
Trained batch 44 in epoch 9, gen_loss = 2.9974046389261884, disc_loss = 0.008487637841608376
Trained batch 45 in epoch 9, gen_loss = 2.9951159332109536, disc_loss = 0.008357356903497535
Trained batch 46 in epoch 9, gen_loss = 2.9907931216219636, disc_loss = 0.008249328252512645
Trained batch 47 in epoch 9, gen_loss = 2.9951855490605035, disc_loss = 0.008121979625381451
Trained batch 48 in epoch 9, gen_loss = 2.994341027979948, disc_loss = 0.007998559095336087
Trained batch 49 in epoch 9, gen_loss = 2.9928713130950926, disc_loss = 0.007899221269180998
Trained batch 50 in epoch 9, gen_loss = 2.9893608420502904, disc_loss = 0.007836121694851374
Trained batch 51 in epoch 9, gen_loss = 2.9956251061879673, disc_loss = 0.007750957124069548
Trained batch 52 in epoch 9, gen_loss = 3.0009203586938247, disc_loss = 0.007752721702003465
Trained batch 53 in epoch 9, gen_loss = 2.998084898348208, disc_loss = 0.007920905148946784
Trained batch 54 in epoch 9, gen_loss = 2.9921058307994497, disc_loss = 0.008055873176040635
Trained batch 55 in epoch 9, gen_loss = 2.9973810698304857, disc_loss = 0.008100330940838571
Trained batch 56 in epoch 9, gen_loss = 3.0017339597668564, disc_loss = 0.008125030005701998
Trained batch 57 in epoch 9, gen_loss = 3.0039636307749253, disc_loss = 0.008056325126431304
Trained batch 58 in epoch 9, gen_loss = 2.994213609372155, disc_loss = 0.01192193768298948
Trained batch 59 in epoch 9, gen_loss = 2.9780544718106587, disc_loss = 0.015139110133168288
Trained batch 60 in epoch 9, gen_loss = 2.9730526462930147, disc_loss = 0.01540677688660894
Trained batch 61 in epoch 9, gen_loss = 2.9666290321657733, disc_loss = 0.01661526651643667
Trained batch 62 in epoch 9, gen_loss = 2.9601154440925237, disc_loss = 0.01778045106985946
Trained batch 63 in epoch 9, gen_loss = 2.953717790544033, disc_loss = 0.01865347532566375
Trained batch 64 in epoch 9, gen_loss = 2.9514838988964374, disc_loss = 0.019182060769078538
Trained batch 65 in epoch 9, gen_loss = 2.954078952471415, disc_loss = 0.01930320042337178
Trained batch 66 in epoch 9, gen_loss = 2.9549524214730334, disc_loss = 0.01908019786516427
Trained batch 67 in epoch 9, gen_loss = 2.952794134616852, disc_loss = 0.018915392317199697
Trained batch 68 in epoch 9, gen_loss = 2.952766725982445, disc_loss = 0.018744349536195776
Trained batch 69 in epoch 9, gen_loss = 2.9541678598948886, disc_loss = 0.018535454573741714
Trained batch 70 in epoch 9, gen_loss = 2.953268652230921, disc_loss = 0.018332024395931512
Trained batch 71 in epoch 9, gen_loss = 2.9560971425639258, disc_loss = 0.01812347762218754
Trained batch 72 in epoch 9, gen_loss = 2.9549493071151107, disc_loss = 0.01792339147116402
Trained batch 73 in epoch 9, gen_loss = 2.9537321490210457, disc_loss = 0.01775674625988924
Trained batch 74 in epoch 9, gen_loss = 2.95610076268514, disc_loss = 0.017594090832863004
Trained batch 75 in epoch 9, gen_loss = 2.949742505424901, disc_loss = 0.017816742228828127
Trained batch 76 in epoch 9, gen_loss = 2.9510403112931685, disc_loss = 0.018036751084894474
Trained batch 77 in epoch 9, gen_loss = 2.9506109800094213, disc_loss = 0.01825407346432957
Trained batch 78 in epoch 9, gen_loss = 2.948201692557033, disc_loss = 0.018142137389859963
Trained batch 79 in epoch 9, gen_loss = 2.944052541255951, disc_loss = 0.018354313025338343
Trained batch 80 in epoch 9, gen_loss = 2.960048116283652, disc_loss = 0.019946871298784963
Trained batch 81 in epoch 9, gen_loss = 2.962675821490404, disc_loss = 0.019942762644637783
Trained batch 82 in epoch 9, gen_loss = 2.962461342294532, disc_loss = 0.019827632746148675
Trained batch 83 in epoch 9, gen_loss = 2.9621979111716863, disc_loss = 0.01983372667191794
Trained batch 84 in epoch 9, gen_loss = 2.964651102178237, disc_loss = 0.019673306814750983
Trained batch 85 in epoch 9, gen_loss = 2.969069333963616, disc_loss = 0.01948805032284432
Trained batch 86 in epoch 9, gen_loss = 2.975127316069329, disc_loss = 0.019293679643673928
Trained batch 87 in epoch 9, gen_loss = 2.976107830351049, disc_loss = 0.019130622917145956
Trained batch 88 in epoch 9, gen_loss = 2.9722889005468134, disc_loss = 0.019384527130947144
Trained batch 89 in epoch 9, gen_loss = 2.9709160725275674, disc_loss = 0.019480730295051926
Trained batch 90 in epoch 9, gen_loss = 2.9650873797280446, disc_loss = 0.01938763585461017
Trained batch 91 in epoch 9, gen_loss = 2.9673366106074788, disc_loss = 0.019233214691073797
Trained batch 92 in epoch 9, gen_loss = 2.9671537619765087, disc_loss = 0.019077460108179678
Trained batch 93 in epoch 9, gen_loss = 2.9670130597784166, disc_loss = 0.018918470892574677
Trained batch 94 in epoch 9, gen_loss = 2.962499711388036, disc_loss = 0.01898433199140096
Trained batch 95 in epoch 9, gen_loss = 2.9559743901093802, disc_loss = 0.01924634206504076
Trained batch 96 in epoch 9, gen_loss = 2.958138645309763, disc_loss = 0.01909367390848293
Trained batch 97 in epoch 9, gen_loss = 2.9625252436618417, disc_loss = 0.018997145865982095
Trained batch 98 in epoch 9, gen_loss = 2.9652748131992843, disc_loss = 0.018873277441904212
Trained batch 99 in epoch 9, gen_loss = 2.9625349831581116, disc_loss = 0.018717570085427723
Trained batch 100 in epoch 9, gen_loss = 2.962990687625243, disc_loss = 0.018562258073096485
Trained batch 101 in epoch 9, gen_loss = 2.960795096322602, disc_loss = 0.0183984141907536
Trained batch 102 in epoch 9, gen_loss = 2.959570465736019, disc_loss = 0.018239521960054243
Trained batch 103 in epoch 9, gen_loss = 2.961649009814629, disc_loss = 0.018098635796587378
Trained batch 104 in epoch 9, gen_loss = 2.9616527148655485, disc_loss = 0.017945923607996
Trained batch 105 in epoch 9, gen_loss = 2.960087499528561, disc_loss = 0.017848681847955856
Trained batch 106 in epoch 9, gen_loss = 2.9581357987127572, disc_loss = 0.017737199961986812
Trained batch 107 in epoch 9, gen_loss = 2.956175172770465, disc_loss = 0.017602222760884884
Trained batch 108 in epoch 9, gen_loss = 2.9547317246778295, disc_loss = 0.017462747810737426
Trained batch 109 in epoch 9, gen_loss = 2.9516451597213744, disc_loss = 0.017339711571218108
Trained batch 110 in epoch 9, gen_loss = 2.950374934050414, disc_loss = 0.01721088966063165
Trained batch 111 in epoch 9, gen_loss = 2.951335906982422, disc_loss = 0.017080940549931256
Trained batch 112 in epoch 9, gen_loss = 2.950405973248777, disc_loss = 0.016942906829598564
Trained batch 113 in epoch 9, gen_loss = 2.9511275479668067, disc_loss = 0.016814350476794828
Trained batch 114 in epoch 9, gen_loss = 2.951446122708528, disc_loss = 0.01668007099221501
Trained batch 115 in epoch 9, gen_loss = 2.9524768303180564, disc_loss = 0.01654553231391815
Trained batch 116 in epoch 9, gen_loss = 2.952909400320461, disc_loss = 0.0164197324282633
Trained batch 117 in epoch 9, gen_loss = 2.9554377127501925, disc_loss = 0.01630688990886576
Trained batch 118 in epoch 9, gen_loss = 2.957517483655144, disc_loss = 0.01617852022270711
Trained batch 119 in epoch 9, gen_loss = 2.9566901564598083, disc_loss = 0.01605288497764074
Trained batch 120 in epoch 9, gen_loss = 2.957174383904323, disc_loss = 0.015928345163302757
Trained batch 121 in epoch 9, gen_loss = 2.954472332704263, disc_loss = 0.015816858204818315
Trained batch 122 in epoch 9, gen_loss = 2.9561824624131368, disc_loss = 0.015699404341498073
Trained batch 123 in epoch 9, gen_loss = 2.957063509571937, disc_loss = 0.015584044008714808
Trained batch 124 in epoch 9, gen_loss = 2.956180896759033, disc_loss = 0.015470072213094682
Trained batch 125 in epoch 9, gen_loss = 2.953765360135881, disc_loss = 0.01537440208457632
Trained batch 126 in epoch 9, gen_loss = 2.954703640750074, disc_loss = 0.015280240684230702
Trained batch 127 in epoch 9, gen_loss = 2.953791493549943, disc_loss = 0.015190559226084588
Trained batch 128 in epoch 9, gen_loss = 2.956075067667998, disc_loss = 0.015088631072561726
Trained batch 129 in epoch 9, gen_loss = 2.9578519289310163, disc_loss = 0.014981614673384824
Trained batch 130 in epoch 9, gen_loss = 2.9568045867308403, disc_loss = 0.014878004203276809
Trained batch 131 in epoch 9, gen_loss = 2.9578201138611995, disc_loss = 0.014771763064676303
Trained batch 132 in epoch 9, gen_loss = 2.9604590584460952, disc_loss = 0.014676701958917949
Trained batch 133 in epoch 9, gen_loss = 2.9607511545295147, disc_loss = 0.014576144967794613
Trained batch 134 in epoch 9, gen_loss = 2.9587966918945314, disc_loss = 0.014479895188317944
Trained batch 135 in epoch 9, gen_loss = 2.958173194352318, disc_loss = 0.014382890278819319
Trained batch 136 in epoch 9, gen_loss = 2.959792158029375, disc_loss = 0.014287125001012273
Trained batch 137 in epoch 9, gen_loss = 2.959083218505417, disc_loss = 0.014194635137412832
Trained batch 138 in epoch 9, gen_loss = 2.956625948706977, disc_loss = 0.014098438623163635
Trained batch 139 in epoch 9, gen_loss = 2.958859782559531, disc_loss = 0.014003250508020365
Trained batch 140 in epoch 9, gen_loss = 2.9585483243279422, disc_loss = 0.01391170737259288
Trained batch 141 in epoch 9, gen_loss = 2.957813467777951, disc_loss = 0.013821134795057652
Trained batch 142 in epoch 9, gen_loss = 2.9589189999587053, disc_loss = 0.0137483542544891
Trained batch 143 in epoch 9, gen_loss = 2.957540371351772, disc_loss = 0.013681395660468196
Trained batch 144 in epoch 9, gen_loss = 2.956112338756693, disc_loss = 0.013612348488772866
Trained batch 145 in epoch 9, gen_loss = 2.956939006504947, disc_loss = 0.013528452721689127
Trained batch 146 in epoch 9, gen_loss = 2.955532104790616, disc_loss = 0.01345131674038601
Trained batch 147 in epoch 9, gen_loss = 2.9547210335731506, disc_loss = 0.013372097965534398
Trained batch 148 in epoch 9, gen_loss = 2.9548754388053946, disc_loss = 0.01329269491475163
Trained batch 149 in epoch 9, gen_loss = 2.9535496536890666, disc_loss = 0.01321354616782628
Trained batch 150 in epoch 9, gen_loss = 2.953262728571102, disc_loss = 0.013132998866679776
Trained batch 151 in epoch 9, gen_loss = 2.9547136582826314, disc_loss = 0.013054957066886249
Testing Epoch 9
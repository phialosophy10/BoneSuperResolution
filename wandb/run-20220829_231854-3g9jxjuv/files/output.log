wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.4990171790122986, disc_loss = 0.6364532113075256
Trained batch 1 in epoch 0, gen_loss = 0.4587043225765228, disc_loss = 0.5385478734970093
Trained batch 2 in epoch 0, gen_loss = 0.465051790078481, disc_loss = 0.6710541248321533
Trained batch 3 in epoch 0, gen_loss = 0.4762239158153534, disc_loss = 0.6067667603492737
Trained batch 4 in epoch 0, gen_loss = 0.4774926662445068, disc_loss = 0.5465450525283814
Trained batch 5 in epoch 0, gen_loss = 0.4771696875492732, disc_loss = 0.4963429967562358
Trained batch 6 in epoch 0, gen_loss = 0.47749234097344534, disc_loss = 0.4514898955821991
Trained batch 7 in epoch 0, gen_loss = 0.47791217640042305, disc_loss = 0.41039300709962845
Trained batch 8 in epoch 0, gen_loss = 0.4785930812358856, disc_loss = 0.37578780286841923
Trained batch 9 in epoch 0, gen_loss = 0.4775346785783768, disc_loss = 0.34650112092494967
Trained batch 10 in epoch 0, gen_loss = 0.47438781640746375, disc_loss = 0.3234359865838831
Trained batch 11 in epoch 0, gen_loss = 0.4779881810148557, disc_loss = 0.30436405042807263
Trained batch 12 in epoch 0, gen_loss = 0.47408581926272464, disc_loss = 0.28639317934329694
Trained batch 13 in epoch 0, gen_loss = 0.4767683084521975, disc_loss = 0.2757800498179027
Trained batch 14 in epoch 0, gen_loss = 0.47605509956677755, disc_loss = 0.2657558351755142
Trained batch 15 in epoch 0, gen_loss = 0.4791815038770437, disc_loss = 0.258193732239306
Trained batch 16 in epoch 0, gen_loss = 0.47980417924768787, disc_loss = 0.2502678672180456
Trained batch 17 in epoch 0, gen_loss = 0.4738206664721171, disc_loss = 0.24331693309876654
Trained batch 18 in epoch 0, gen_loss = 0.4662400217432725, disc_loss = 0.2402110707603003
Trained batch 19 in epoch 0, gen_loss = 0.4653842613101006, disc_loss = 0.23314454555511474
Trained batch 20 in epoch 0, gen_loss = 0.4687374872820718, disc_loss = 0.22590204115424836
Trained batch 21 in epoch 0, gen_loss = 0.469950024377216, disc_loss = 0.21911368417468938
Trained batch 22 in epoch 0, gen_loss = 0.46901823645052704, disc_loss = 0.21245786385691684
Trained batch 23 in epoch 0, gen_loss = 0.4680160681406657, disc_loss = 0.2064925590530038
Trained batch 24 in epoch 0, gen_loss = 0.46612800359725953, disc_loss = 0.20217869192361831
Trained batch 25 in epoch 0, gen_loss = 0.4634420493474373, disc_loss = 0.20206497237086296
Trained batch 26 in epoch 0, gen_loss = 0.4565754102336036, disc_loss = 0.20691189142288985
Trained batch 27 in epoch 0, gen_loss = 0.4573225410921233, disc_loss = 0.20374105178884097
Trained batch 28 in epoch 0, gen_loss = 0.4600456963325369, disc_loss = 0.20077958420432848
Trained batch 29 in epoch 0, gen_loss = 0.4598491797844569, disc_loss = 0.19675305734078088
Trained batch 30 in epoch 0, gen_loss = 0.45850585641399505, disc_loss = 0.1923132709437801
Trained batch 31 in epoch 0, gen_loss = 0.45766313560307026, disc_loss = 0.18801566225010902
Trained batch 32 in epoch 0, gen_loss = 0.45691569736509613, disc_loss = 0.18364384939724748
Trained batch 33 in epoch 0, gen_loss = 0.4563814191257252, disc_loss = 0.17945277658017242
Trained batch 34 in epoch 0, gen_loss = 0.4548350879124233, disc_loss = 0.17648178434797696
Trained batch 35 in epoch 0, gen_loss = 0.4565872765249676, disc_loss = 0.1730086345018612
Trained batch 36 in epoch 0, gen_loss = 0.4560341883350063, disc_loss = 0.17081005418220083
Trained batch 37 in epoch 0, gen_loss = 0.45459905345188945, disc_loss = 0.16926649653990017
Trained batch 38 in epoch 0, gen_loss = 0.45425295447691894, disc_loss = 0.1659269702549164
Trained batch 39 in epoch 0, gen_loss = 0.4570989601314068, disc_loss = 0.16305826231837273
Trained batch 40 in epoch 0, gen_loss = 0.458845185797389, disc_loss = 0.16020619469444927
Trained batch 41 in epoch 0, gen_loss = 0.4586508089587802, disc_loss = 0.1571453512601909
Trained batch 42 in epoch 0, gen_loss = 0.45823012673577596, disc_loss = 0.15432631735538327
Trained batch 43 in epoch 0, gen_loss = 0.4573642069643194, disc_loss = 0.15196144775572148
Trained batch 44 in epoch 0, gen_loss = 0.45834491120444404, disc_loss = 0.1493324325316482
Trained batch 45 in epoch 0, gen_loss = 0.4617997278337893, disc_loss = 0.14687886850341506
Trained batch 46 in epoch 0, gen_loss = 0.46433831656232794, disc_loss = 0.14479853751811575
Trained batch 47 in epoch 0, gen_loss = 0.46492428580919903, disc_loss = 0.14252051369597515
Trained batch 48 in epoch 0, gen_loss = 0.46622359022802234, disc_loss = 0.14076455819363498
Trained batch 49 in epoch 0, gen_loss = 0.4678785979747772, disc_loss = 0.1386937029659748
Trained batch 50 in epoch 0, gen_loss = 0.46800272195946935, disc_loss = 0.13683608203542
Trained batch 51 in epoch 0, gen_loss = 0.4692686286110144, disc_loss = 0.13534990440194422
Trained batch 52 in epoch 0, gen_loss = 0.47242680529378495, disc_loss = 0.13356217552187308
Trained batch 53 in epoch 0, gen_loss = 0.47366997323654314, disc_loss = 0.13158226678906768
Trained batch 54 in epoch 0, gen_loss = 0.47350954575972126, disc_loss = 0.12986829236827113
Trained batch 55 in epoch 0, gen_loss = 0.47266143560409546, disc_loss = 0.12872721876816026
Trained batch 56 in epoch 0, gen_loss = 0.47293558925913093, disc_loss = 0.12900523511333423
Trained batch 57 in epoch 0, gen_loss = 0.4747621802420452, disc_loss = 0.12859057387786693
Trained batch 58 in epoch 0, gen_loss = 0.4734568974729312, disc_loss = 0.12712181419512983
Trained batch 59 in epoch 0, gen_loss = 0.4726961478590965, disc_loss = 0.1265763322201868
Trained batch 60 in epoch 0, gen_loss = 0.47416474535817005, disc_loss = 0.12537813727117952
Trained batch 61 in epoch 0, gen_loss = 0.4757586270570755, disc_loss = 0.1240326123191945
Trained batch 62 in epoch 0, gen_loss = 0.47641232136696104, disc_loss = 0.12267749049952106
Trained batch 63 in epoch 0, gen_loss = 0.47578724659979343, disc_loss = 0.12116493663052097
Trained batch 64 in epoch 0, gen_loss = 0.47553827991852393, disc_loss = 0.11973237756353158
Trained batch 65 in epoch 0, gen_loss = 0.4747493393493421, disc_loss = 0.11903615335397648
Trained batch 66 in epoch 0, gen_loss = 0.4736041706889423, disc_loss = 0.11823513208707767
Trained batch 67 in epoch 0, gen_loss = 0.4728413544156972, disc_loss = 0.11737646633649573
Trained batch 68 in epoch 0, gen_loss = 0.4729284752106321, disc_loss = 0.11655625862919766
Trained batch 69 in epoch 0, gen_loss = 0.4742542347737721, disc_loss = 0.11573368044836181
Trained batch 70 in epoch 0, gen_loss = 0.47460429265465537, disc_loss = 0.1147262309743485
Trained batch 71 in epoch 0, gen_loss = 0.4736775888337029, disc_loss = 0.11385364747709698
Trained batch 72 in epoch 0, gen_loss = 0.47364003854255154, disc_loss = 0.11280209887517642
Trained batch 73 in epoch 0, gen_loss = 0.4728803127198606, disc_loss = 0.11288655649971317
Trained batch 74 in epoch 0, gen_loss = 0.47252570708592734, disc_loss = 0.11723211884498597
Trained batch 75 in epoch 0, gen_loss = 0.47227315604686737, disc_loss = 0.11785729151023061
Trained batch 76 in epoch 0, gen_loss = 0.4725206471108771, disc_loss = 0.11746806951312276
Trained batch 77 in epoch 0, gen_loss = 0.4724825700888267, disc_loss = 0.11644366947122109
Trained batch 78 in epoch 0, gen_loss = 0.4734034421323221, disc_loss = 0.11551323674524887
Trained batch 79 in epoch 0, gen_loss = 0.4731406483799219, disc_loss = 0.11457472452893853
Trained batch 80 in epoch 0, gen_loss = 0.472783300243778, disc_loss = 0.11349590881555169
Trained batch 81 in epoch 0, gen_loss = 0.47279176043301097, disc_loss = 0.11240274529540684
Trained batch 82 in epoch 0, gen_loss = 0.47246698227273415, disc_loss = 0.11128352497176952
Trained batch 83 in epoch 0, gen_loss = 0.4722508419127691, disc_loss = 0.11017797297487657
Trained batch 84 in epoch 0, gen_loss = 0.47248932754292206, disc_loss = 0.10907851518953547
Trained batch 85 in epoch 0, gen_loss = 0.4717131638249686, disc_loss = 0.10801680996840776
Trained batch 86 in epoch 0, gen_loss = 0.4714972280907905, disc_loss = 0.10691506216495202
Trained batch 87 in epoch 0, gen_loss = 0.47123952582478523, disc_loss = 0.1058638534529812
Trained batch 88 in epoch 0, gen_loss = 0.4710505045531841, disc_loss = 0.10485706475218025
Trained batch 89 in epoch 0, gen_loss = 0.47033197946018646, disc_loss = 0.10391115621767111
Trained batch 90 in epoch 0, gen_loss = 0.47018583855786167, disc_loss = 0.10303225883047332
Trained batch 91 in epoch 0, gen_loss = 0.4696059155723323, disc_loss = 0.10206094135165862
Trained batch 92 in epoch 0, gen_loss = 0.4698112703138782, disc_loss = 0.10113212626467469
Trained batch 93 in epoch 0, gen_loss = 0.46953550773732206, disc_loss = 0.10020244926055695
Trained batch 94 in epoch 0, gen_loss = 0.4686690622254422, disc_loss = 0.09944378941466933
Trained batch 95 in epoch 0, gen_loss = 0.4686855726564924, disc_loss = 0.09895363283188392
Trained batch 96 in epoch 0, gen_loss = 0.46877211639561606, disc_loss = 0.09809914041195333
Trained batch 97 in epoch 0, gen_loss = 0.4695510821683066, disc_loss = 0.09730407012132358
Trained batch 98 in epoch 0, gen_loss = 0.4700400678798406, disc_loss = 0.09654113776379764
Trained batch 99 in epoch 0, gen_loss = 0.46973095804452897, disc_loss = 0.09572888002730906
Trained batch 100 in epoch 0, gen_loss = 0.46926519982885606, disc_loss = 0.09492168642838697
Trained batch 101 in epoch 0, gen_loss = 0.46932609788343016, disc_loss = 0.09413195019770487
Trained batch 102 in epoch 0, gen_loss = 0.4696809947490692, disc_loss = 0.09336537523285567
Trained batch 103 in epoch 0, gen_loss = 0.4697360095496361, disc_loss = 0.09260830835690005
Trained batch 104 in epoch 0, gen_loss = 0.4699026102111453, disc_loss = 0.09188231510952824
Trained batch 105 in epoch 0, gen_loss = 0.46935773401890163, disc_loss = 0.091223393786558
Trained batch 106 in epoch 0, gen_loss = 0.4686286179261787, disc_loss = 0.09084367427417886
Trained batch 107 in epoch 0, gen_loss = 0.46938994830405273, disc_loss = 0.09021541261528102
Trained batch 108 in epoch 0, gen_loss = 0.4693830579245856, disc_loss = 0.0902061719327755
Trained batch 109 in epoch 0, gen_loss = 0.46851938475262034, disc_loss = 0.09337686678733338
Trained batch 110 in epoch 0, gen_loss = 0.46940912964107756, disc_loss = 0.09396676798896478
Trained batch 111 in epoch 0, gen_loss = 0.4696207514830998, disc_loss = 0.09363789004107405
Trained batch 112 in epoch 0, gen_loss = 0.4699741085018732, disc_loss = 0.093705197738533
Trained batch 113 in epoch 0, gen_loss = 0.47004136913701106, disc_loss = 0.0931783888341957
Trained batch 114 in epoch 0, gen_loss = 0.4703273083852685, disc_loss = 0.0927074986550471
Trained batch 115 in epoch 0, gen_loss = 0.4708466236961299, disc_loss = 0.09228296400497443
Trained batch 116 in epoch 0, gen_loss = 0.4708650374514425, disc_loss = 0.09312701686166036
Trained batch 117 in epoch 0, gen_loss = 0.4705668399899693, disc_loss = 0.09678222216129051
Trained batch 118 in epoch 0, gen_loss = 0.4705882733609496, disc_loss = 0.09699603003457564
Trained batch 119 in epoch 0, gen_loss = 0.47078630576531094, disc_loss = 0.09875300690376511
Trained batch 120 in epoch 0, gen_loss = 0.4702465935679507, disc_loss = 0.09948317105458541
Trained batch 121 in epoch 0, gen_loss = 0.4697468153765944, disc_loss = 0.0998366126011996
Trained batch 122 in epoch 0, gen_loss = 0.4697399623994905, disc_loss = 0.10040719567124194
Trained batch 123 in epoch 0, gen_loss = 0.4701214408682239, disc_loss = 0.10104717208342927
Trained batch 124 in epoch 0, gen_loss = 0.47013193082809446, disc_loss = 0.10197961237281561
Trained batch 125 in epoch 0, gen_loss = 0.4706102212270101, disc_loss = 0.10263390770359408
Trained batch 126 in epoch 0, gen_loss = 0.470349058391541, disc_loss = 0.10364140302500152
Trained batch 127 in epoch 0, gen_loss = 0.47028929903171957, disc_loss = 0.10441918999276822
Trained batch 128 in epoch 0, gen_loss = 0.47047469551249066, disc_loss = 0.10513745342893888
Trained batch 129 in epoch 0, gen_loss = 0.47057094665674065, disc_loss = 0.10545066471139972
Trained batch 130 in epoch 0, gen_loss = 0.47035592339421045, disc_loss = 0.10554347217850785
Trained batch 131 in epoch 0, gen_loss = 0.4699067346977465, disc_loss = 0.1056763099323055
Trained batch 132 in epoch 0, gen_loss = 0.46980842298134823, disc_loss = 0.10707144794243395
Trained batch 133 in epoch 0, gen_loss = 0.4700139583046757, disc_loss = 0.10752234871346336
Trained batch 134 in epoch 0, gen_loss = 0.47000853949122956, disc_loss = 0.10743224479396034
Trained batch 135 in epoch 0, gen_loss = 0.469815910081653, disc_loss = 0.10706835176439627
Trained batch 136 in epoch 0, gen_loss = 0.46986347110602106, disc_loss = 0.10701298335036874
Trained batch 137 in epoch 0, gen_loss = 0.4703444378531497, disc_loss = 0.10687504759382295
Trained batch 138 in epoch 0, gen_loss = 0.47060924189553843, disc_loss = 0.10730055121289526
Trained batch 139 in epoch 0, gen_loss = 0.4709500885435513, disc_loss = 0.107601848637153
Trained batch 140 in epoch 0, gen_loss = 0.4704064257601474, disc_loss = 0.1075277360922373
Trained batch 141 in epoch 0, gen_loss = 0.4700707346200943, disc_loss = 0.10717657008405093
Trained batch 142 in epoch 0, gen_loss = 0.47002937306057324, disc_loss = 0.10676470731704177
Trained batch 143 in epoch 0, gen_loss = 0.4705319969604413, disc_loss = 0.10627830374546142
Trained batch 144 in epoch 0, gen_loss = 0.47083585447278514, disc_loss = 0.10581379023476921
Trained batch 145 in epoch 0, gen_loss = 0.47080746721731476, disc_loss = 0.10547868973154524
Trained batch 146 in epoch 0, gen_loss = 0.47087712373052326, disc_loss = 0.10521507171318442
Trained batch 147 in epoch 0, gen_loss = 0.4709380595265208, disc_loss = 0.10597329998917475
Trained batch 148 in epoch 0, gen_loss = 0.4718423209734411, disc_loss = 0.10971479597282689
Trained batch 149 in epoch 0, gen_loss = 0.47230771541595457, disc_loss = 0.10963336288308104
Trained batch 150 in epoch 0, gen_loss = 0.47279652064999206, disc_loss = 0.11031614361787277
Trained batch 151 in epoch 0, gen_loss = 0.4729113445470208, disc_loss = 0.10994218129934252
Trained batch 152 in epoch 0, gen_loss = 0.47319406465767255, disc_loss = 0.10976713999886722
Trained batch 153 in epoch 0, gen_loss = 0.47294261006565835, disc_loss = 0.10938481816586543
Trained batch 154 in epoch 0, gen_loss = 0.47241096631173163, disc_loss = 0.10909351499210443
Trained batch 155 in epoch 0, gen_loss = 0.47165120373933744, disc_loss = 0.10918478581170814
Trained batch 156 in epoch 0, gen_loss = 0.47089658497245446, disc_loss = 0.10966225803064503
Trained batch 157 in epoch 0, gen_loss = 0.47080292750762986, disc_loss = 0.10973156587208939
Trained batch 158 in epoch 0, gen_loss = 0.47079847350060566, disc_loss = 0.10924983848729786
Trained batch 159 in epoch 0, gen_loss = 0.47040415126830337, disc_loss = 0.10883049624389969
Trained batch 160 in epoch 0, gen_loss = 0.47064671512716305, disc_loss = 0.10843197195588247
Trained batch 161 in epoch 0, gen_loss = 0.4707273934726362, disc_loss = 0.10864336576519741
Trained batch 162 in epoch 0, gen_loss = 0.4702486170947186, disc_loss = 0.10984908391155897
Trained batch 163 in epoch 0, gen_loss = 0.4698390208366441, disc_loss = 0.11025265812669403
Trained batch 164 in epoch 0, gen_loss = 0.4695804061311664, disc_loss = 0.11028186330628215
Trained batch 165 in epoch 0, gen_loss = 0.46888128012777813, disc_loss = 0.11086859629792442
Trained batch 166 in epoch 0, gen_loss = 0.46880186621300474, disc_loss = 0.11139005435418761
Trained batch 167 in epoch 0, gen_loss = 0.4683807745930694, disc_loss = 0.11212095684216668
Trained batch 168 in epoch 0, gen_loss = 0.46800641759612854, disc_loss = 0.11298362650087423
Trained batch 169 in epoch 0, gen_loss = 0.4675112973241245, disc_loss = 0.1138681064140709
Trained batch 170 in epoch 0, gen_loss = 0.46705200152787546, disc_loss = 0.11376828630046364
Trained batch 171 in epoch 0, gen_loss = 0.4666609828208768, disc_loss = 0.11385484060900676
Trained batch 172 in epoch 0, gen_loss = 0.46638034327181777, disc_loss = 0.11358542322057348
Trained batch 173 in epoch 0, gen_loss = 0.46575429675907926, disc_loss = 0.11347373874172911
Trained batch 174 in epoch 0, gen_loss = 0.4658138952936445, disc_loss = 0.11320064058793443
Trained batch 175 in epoch 0, gen_loss = 0.4656993999061259, disc_loss = 0.11283004376508127
Trained batch 176 in epoch 0, gen_loss = 0.4653855058769722, disc_loss = 0.11273052025123337
Trained batch 177 in epoch 0, gen_loss = 0.46549152741941174, disc_loss = 0.1141454736451001
Trained batch 178 in epoch 0, gen_loss = 0.46579050268540834, disc_loss = 0.11398568253589575
Trained batch 179 in epoch 0, gen_loss = 0.4653751858406597, disc_loss = 0.1140354892394195
Trained batch 180 in epoch 0, gen_loss = 0.46454706491686365, disc_loss = 0.11463038878031692
Trained batch 181 in epoch 0, gen_loss = 0.4646820028077115, disc_loss = 0.1145496982415872
Trained batch 182 in epoch 0, gen_loss = 0.4645518737086833, disc_loss = 0.11458110059687837
Trained batch 183 in epoch 0, gen_loss = 0.4648862311049648, disc_loss = 0.11468352781831408
Trained batch 184 in epoch 0, gen_loss = 0.46478864872777786, disc_loss = 0.11613382309977267
Trained batch 185 in epoch 0, gen_loss = 0.46441765882635627, disc_loss = 0.11717329918837516
Trained batch 186 in epoch 0, gen_loss = 0.4645662170680449, disc_loss = 0.11740948171678552
Trained batch 187 in epoch 0, gen_loss = 0.46448379865986233, disc_loss = 0.11772350102484702
Trained batch 188 in epoch 0, gen_loss = 0.46415432136525553, disc_loss = 0.11786024934222931
Trained batch 189 in epoch 0, gen_loss = 0.464506228973991, disc_loss = 0.11758107750333453
Trained batch 190 in epoch 0, gen_loss = 0.46423441733365284, disc_loss = 0.11739009185279695
Trained batch 191 in epoch 0, gen_loss = 0.46397678802410763, disc_loss = 0.11721532632266947
Trained batch 192 in epoch 0, gen_loss = 0.46353690488350824, disc_loss = 0.11698095847423058
Trained batch 193 in epoch 0, gen_loss = 0.4632993185335828, disc_loss = 0.11667639911462813
Trained batch 194 in epoch 0, gen_loss = 0.4629818940773988, disc_loss = 0.11658769234155233
Trained batch 195 in epoch 0, gen_loss = 0.4628788079230153, disc_loss = 0.11716260114323576
Trained batch 196 in epoch 0, gen_loss = 0.46326663787594907, disc_loss = 0.11714575677486089
Trained batch 197 in epoch 0, gen_loss = 0.463288392231922, disc_loss = 0.11688650165675114
Trained batch 198 in epoch 0, gen_loss = 0.46309003338741894, disc_loss = 0.11666494828354024
Trained batch 199 in epoch 0, gen_loss = 0.4631920625269413, disc_loss = 0.11628125592600554
Trained batch 200 in epoch 0, gen_loss = 0.46272767049756214, disc_loss = 0.11637137221886003
Trained batch 201 in epoch 0, gen_loss = 0.46225859224796295, disc_loss = 0.11757785546141539
Trained batch 202 in epoch 0, gen_loss = 0.46277856782739385, disc_loss = 0.11728047538695517
Trained batch 203 in epoch 0, gen_loss = 0.4626205226077753, disc_loss = 0.1170042677024635
Trained batch 204 in epoch 0, gen_loss = 0.4626629625878683, disc_loss = 0.11695548449983684
Trained batch 205 in epoch 0, gen_loss = 0.46241439184517535, disc_loss = 0.11680780797383016
Trained batch 206 in epoch 0, gen_loss = 0.4624762064304905, disc_loss = 0.11649590226313199
Trained batch 207 in epoch 0, gen_loss = 0.46231847858199704, disc_loss = 0.1165349820154146
Trained batch 208 in epoch 0, gen_loss = 0.46204532504652107, disc_loss = 0.11738476812679088
Trained batch 209 in epoch 0, gen_loss = 0.46229779209409444, disc_loss = 0.11756915790250613
Trained batch 210 in epoch 0, gen_loss = 0.4622307326556382, disc_loss = 0.11752997363048001
Trained batch 211 in epoch 0, gen_loss = 0.46205355030185774, disc_loss = 0.11759312299326202
Trained batch 212 in epoch 0, gen_loss = 0.4620747409516097, disc_loss = 0.11779051735350084
Trained batch 213 in epoch 0, gen_loss = 0.4622177604202912, disc_loss = 0.11789280513440754
Trained batch 214 in epoch 0, gen_loss = 0.4620893292648848, disc_loss = 0.11783507147067508
Trained batch 215 in epoch 0, gen_loss = 0.46175064863982024, disc_loss = 0.117778220934
Trained batch 216 in epoch 0, gen_loss = 0.4614158930591724, disc_loss = 0.1175879062827213
Trained batch 217 in epoch 0, gen_loss = 0.46126951495988655, disc_loss = 0.11738962300309758
Trained batch 218 in epoch 0, gen_loss = 0.4610957832641253, disc_loss = 0.11754920945575112
Trained batch 219 in epoch 0, gen_loss = 0.4613091915845871, disc_loss = 0.11783219152130187
Trained batch 220 in epoch 0, gen_loss = 0.4607422719983494, disc_loss = 0.11859537744936766
Trained batch 221 in epoch 0, gen_loss = 0.4607339238261317, disc_loss = 0.11930161415439872
Trained batch 222 in epoch 0, gen_loss = 0.4604132540290131, disc_loss = 0.11930934065376562
Trained batch 223 in epoch 0, gen_loss = 0.4601697875186801, disc_loss = 0.11911008569794442
Trained batch 224 in epoch 0, gen_loss = 0.4602805272738139, disc_loss = 0.11904171330647337
Trained batch 225 in epoch 0, gen_loss = 0.4605775588909082, disc_loss = 0.11884698901012276
Trained batch 226 in epoch 0, gen_loss = 0.46037461684138764, disc_loss = 0.11863711574381537
Trained batch 227 in epoch 0, gen_loss = 0.4604392604608285, disc_loss = 0.11855144161126462
Trained batch 228 in epoch 0, gen_loss = 0.45996055150136156, disc_loss = 0.11864889796628052
Trained batch 229 in epoch 0, gen_loss = 0.4601409515608912, disc_loss = 0.11834337915010426
Trained batch 230 in epoch 0, gen_loss = 0.4600278310703509, disc_loss = 0.11830127229148046
Trained batch 231 in epoch 0, gen_loss = 0.45979486226007854, disc_loss = 0.11926009778559593
Trained batch 232 in epoch 0, gen_loss = 0.4598440211985756, disc_loss = 0.1211020725503436
Trained batch 233 in epoch 0, gen_loss = 0.46027613539471585, disc_loss = 0.12088724445058112
Trained batch 234 in epoch 0, gen_loss = 0.4602098864443759, disc_loss = 0.12115013424624153
Trained batch 235 in epoch 0, gen_loss = 0.4600689061364885, disc_loss = 0.12112960670443283
Trained batch 236 in epoch 0, gen_loss = 0.459883562623197, disc_loss = 0.12102053087707687
Trained batch 237 in epoch 0, gen_loss = 0.4597573069965138, disc_loss = 0.12111143376130391
Trained batch 238 in epoch 0, gen_loss = 0.45972323691994577, disc_loss = 0.12093821887675064
Trained batch 239 in epoch 0, gen_loss = 0.4599189209441344, disc_loss = 0.1207653163272577
Trained batch 240 in epoch 0, gen_loss = 0.4596795747636265, disc_loss = 0.12084429661252563
Trained batch 241 in epoch 0, gen_loss = 0.4593448649999524, disc_loss = 0.12144854759859029
Trained batch 242 in epoch 0, gen_loss = 0.45932370228041347, disc_loss = 0.12174156163684993
Trained batch 243 in epoch 0, gen_loss = 0.45937796132486375, disc_loss = 0.12153132848792755
Trained batch 244 in epoch 0, gen_loss = 0.4595708384805796, disc_loss = 0.12130796431506775
Trained batch 245 in epoch 0, gen_loss = 0.4596313625816407, disc_loss = 0.12127095148557933
Trained batch 246 in epoch 0, gen_loss = 0.4592338773885719, disc_loss = 0.12133657512620755
Trained batch 247 in epoch 0, gen_loss = 0.45895044757954534, disc_loss = 0.12202339273531951
Trained batch 248 in epoch 0, gen_loss = 0.4587801258008643, disc_loss = 0.1231222306172472
Trained batch 249 in epoch 0, gen_loss = 0.45880433928966524, disc_loss = 0.12303139462694526
Trained batch 250 in epoch 0, gen_loss = 0.4585193332685417, disc_loss = 0.12305227310519176
Trained batch 251 in epoch 0, gen_loss = 0.4582279057256759, disc_loss = 0.1231774052952431
Trained batch 252 in epoch 0, gen_loss = 0.4578991204853586, disc_loss = 0.12326525690276986
Trained batch 253 in epoch 0, gen_loss = 0.45796770009938187, disc_loss = 0.12357474426100926
Trained batch 254 in epoch 0, gen_loss = 0.4574146998863594, disc_loss = 0.12430737389288113
Trained batch 255 in epoch 0, gen_loss = 0.45739518420305103, disc_loss = 0.12453025058130152
Trained batch 256 in epoch 0, gen_loss = 0.4570988118648529, disc_loss = 0.12463113523164496
Trained batch 257 in epoch 0, gen_loss = 0.45665514630864756, disc_loss = 0.12488294158549618
Trained batch 258 in epoch 0, gen_loss = 0.4566064514938929, disc_loss = 0.12486596983357631
Trained batch 259 in epoch 0, gen_loss = 0.45633451365507566, disc_loss = 0.12516841249038968
Trained batch 260 in epoch 0, gen_loss = 0.45578616800436117, disc_loss = 0.1258126379907759
Trained batch 261 in epoch 0, gen_loss = 0.4560907861886134, disc_loss = 0.125935124670589
Trained batch 262 in epoch 0, gen_loss = 0.4560071244665878, disc_loss = 0.1260898756571539
Trained batch 263 in epoch 0, gen_loss = 0.4557904316620393, disc_loss = 0.12630438327323645
Trained batch 264 in epoch 0, gen_loss = 0.45547880271695695, disc_loss = 0.12641008425644545
Trained batch 265 in epoch 0, gen_loss = 0.4551276948891188, disc_loss = 0.1270495318961715
Trained batch 266 in epoch 0, gen_loss = 0.45483999607268344, disc_loss = 0.12860498621655203
Trained batch 267 in epoch 0, gen_loss = 0.45469611660758064, disc_loss = 0.12883451438870336
Trained batch 268 in epoch 0, gen_loss = 0.45426801578262926, disc_loss = 0.1292548200918784
Trained batch 269 in epoch 0, gen_loss = 0.4537593642870585, disc_loss = 0.12958196227404253
Trained batch 270 in epoch 0, gen_loss = 0.45325149909156714, disc_loss = 0.12988481675772978
Trained batch 271 in epoch 0, gen_loss = 0.4531355229589869, disc_loss = 0.1300787123378969
Trained batch 272 in epoch 0, gen_loss = 0.4529958563846546, disc_loss = 0.13027164336948932
Trained batch 273 in epoch 0, gen_loss = 0.4526742913209609, disc_loss = 0.13026303452283253
Trained batch 274 in epoch 0, gen_loss = 0.4524419034611095, disc_loss = 0.13031219593164595
Trained batch 275 in epoch 0, gen_loss = 0.4522258534595586, disc_loss = 0.1304032198673087
Trained batch 276 in epoch 0, gen_loss = 0.45200399876931946, disc_loss = 0.13040279160969848
Trained batch 277 in epoch 0, gen_loss = 0.4518583022433219, disc_loss = 0.13044169826245458
Trained batch 278 in epoch 0, gen_loss = 0.45151312526408915, disc_loss = 0.13054074910152236
Trained batch 279 in epoch 0, gen_loss = 0.45120437794498036, disc_loss = 0.1307255326337846
Trained batch 280 in epoch 0, gen_loss = 0.451055295208595, disc_loss = 0.1311081992793709
Trained batch 281 in epoch 0, gen_loss = 0.4509736325935269, disc_loss = 0.13129786071400587
Trained batch 282 in epoch 0, gen_loss = 0.4508559702773819, disc_loss = 0.13147259519070176
Trained batch 283 in epoch 0, gen_loss = 0.4507616858037425, disc_loss = 0.1313508848141564
Trained batch 284 in epoch 0, gen_loss = 0.45034141226818686, disc_loss = 0.1315299746204625
Trained batch 285 in epoch 0, gen_loss = 0.4503010169609443, disc_loss = 0.13148337550187758
Trained batch 286 in epoch 0, gen_loss = 0.4502059056160757, disc_loss = 0.13146994057523562
Trained batch 287 in epoch 0, gen_loss = 0.4503616535415252, disc_loss = 0.13146238432252882
Trained batch 288 in epoch 0, gen_loss = 0.4501208198936753, disc_loss = 0.13163242950249193
Trained batch 289 in epoch 0, gen_loss = 0.4499561472185727, disc_loss = 0.13189165088315977
Trained batch 290 in epoch 0, gen_loss = 0.44978470040350843, disc_loss = 0.13234422440061352
Trained batch 291 in epoch 0, gen_loss = 0.44980105492350175, disc_loss = 0.133500035389722
Trained batch 292 in epoch 0, gen_loss = 0.44999525164581405, disc_loss = 0.13356329312185683
Trained batch 293 in epoch 0, gen_loss = 0.4498254824049619, disc_loss = 0.1339727607682398
Trained batch 294 in epoch 0, gen_loss = 0.4497084516589924, disc_loss = 0.13432947578761031
Trained batch 295 in epoch 0, gen_loss = 0.4494914420553156, disc_loss = 0.13444226441237875
Trained batch 296 in epoch 0, gen_loss = 0.44923105564984406, disc_loss = 0.13453660905047599
Trained batch 297 in epoch 0, gen_loss = 0.4490889914883863, disc_loss = 0.1347865347762986
Trained batch 298 in epoch 0, gen_loss = 0.4487700546066897, disc_loss = 0.134920106481225
Trained batch 299 in epoch 0, gen_loss = 0.4484355081121127, disc_loss = 0.1351523345677803
Trained batch 300 in epoch 0, gen_loss = 0.44819440813951716, disc_loss = 0.13529526558317911
Trained batch 301 in epoch 0, gen_loss = 0.4481084035919202, disc_loss = 0.1353527830993843
Trained batch 302 in epoch 0, gen_loss = 0.4478857355936132, disc_loss = 0.13579310407622322
Trained batch 303 in epoch 0, gen_loss = 0.44739611437054055, disc_loss = 0.13579034638333773
Trained batch 304 in epoch 0, gen_loss = 0.44706664603264606, disc_loss = 0.1360992408159082
Trained batch 305 in epoch 0, gen_loss = 0.4469527495063208, disc_loss = 0.1364858996798741
Trained batch 306 in epoch 0, gen_loss = 0.4466914783083267, disc_loss = 0.13689052805923388
Trained batch 307 in epoch 0, gen_loss = 0.446587369136222, disc_loss = 0.13721104783562388
Trained batch 308 in epoch 0, gen_loss = 0.44651614616603913, disc_loss = 0.1372916852259665
Trained batch 309 in epoch 0, gen_loss = 0.44638784335505577, disc_loss = 0.13742402065845746
Trained batch 310 in epoch 0, gen_loss = 0.44675265650273904, disc_loss = 0.1373550617540333
Trained batch 311 in epoch 0, gen_loss = 0.4462983276790533, disc_loss = 0.13747651203690717
Trained batch 312 in epoch 0, gen_loss = 0.44599333281715076, disc_loss = 0.13775344828244881
Trained batch 313 in epoch 0, gen_loss = 0.44589890017630945, disc_loss = 0.1377086991497618
Trained batch 314 in epoch 0, gen_loss = 0.4458579078553215, disc_loss = 0.1378532626296556
Trained batch 315 in epoch 0, gen_loss = 0.4455625468605681, disc_loss = 0.13806153960891446
Trained batch 316 in epoch 0, gen_loss = 0.4455781229286916, disc_loss = 0.13811445061987038
Trained batch 317 in epoch 0, gen_loss = 0.44546952168896514, disc_loss = 0.13806204619354703
Trained batch 318 in epoch 0, gen_loss = 0.44515728436667346, disc_loss = 0.13845955830090753
Trained batch 319 in epoch 0, gen_loss = 0.44492393219843507, disc_loss = 0.13909446838952136
Trained batch 320 in epoch 0, gen_loss = 0.44478731716161946, disc_loss = 0.1397536481437607
Trained batch 321 in epoch 0, gen_loss = 0.4443166740007282, disc_loss = 0.14018524960782494
Trained batch 322 in epoch 0, gen_loss = 0.44414062885677114, disc_loss = 0.14028538071230376
Trained batch 323 in epoch 0, gen_loss = 0.44387745084585967, disc_loss = 0.14049189670850742
Trained batch 324 in epoch 0, gen_loss = 0.443817075582651, disc_loss = 0.1405379274688088
Trained batch 325 in epoch 0, gen_loss = 0.4433805744157978, disc_loss = 0.14061680860943132
Trained batch 326 in epoch 0, gen_loss = 0.44300066941739585, disc_loss = 0.14076765651447237
Trained batch 327 in epoch 0, gen_loss = 0.4427692062425904, disc_loss = 0.14089654767374712
Trained batch 328 in epoch 0, gen_loss = 0.442442403013583, disc_loss = 0.14097993754948798
Trained batch 329 in epoch 0, gen_loss = 0.4423049574548548, disc_loss = 0.1409500855811392
Trained batch 330 in epoch 0, gen_loss = 0.4420255289337066, disc_loss = 0.14091045762555746
Trained batch 331 in epoch 0, gen_loss = 0.4417080677237855, disc_loss = 0.14089858123235943
Trained batch 332 in epoch 0, gen_loss = 0.44134570832725045, disc_loss = 0.14102121189449196
Trained batch 333 in epoch 0, gen_loss = 0.4413198975031961, disc_loss = 0.14116874051386277
Trained batch 334 in epoch 0, gen_loss = 0.4409268557135739, disc_loss = 0.14165949340798517
Trained batch 335 in epoch 0, gen_loss = 0.44086455722295104, disc_loss = 0.14237347945648557
Trained batch 336 in epoch 0, gen_loss = 0.44057377323906216, disc_loss = 0.14284764623507107
Trained batch 337 in epoch 0, gen_loss = 0.4404286861243333, disc_loss = 0.14329848098761497
Trained batch 338 in epoch 0, gen_loss = 0.4403681493965925, disc_loss = 0.143559604748578
Trained batch 339 in epoch 0, gen_loss = 0.4400335448629716, disc_loss = 0.14373601293465232
Trained batch 340 in epoch 0, gen_loss = 0.43967551613483263, disc_loss = 0.14390298501039442
Trained batch 341 in epoch 0, gen_loss = 0.4394326991679376, disc_loss = 0.14401259978862796
Trained batch 342 in epoch 0, gen_loss = 0.43917978887307746, disc_loss = 0.14404894419981074
Trained batch 343 in epoch 0, gen_loss = 0.43909686206038606, disc_loss = 0.14407334571736757
Trained batch 344 in epoch 0, gen_loss = 0.4391328693300054, disc_loss = 0.14417470395295084
Trained batch 345 in epoch 0, gen_loss = 0.4390239187575489, disc_loss = 0.14439000796279036
Trained batch 346 in epoch 0, gen_loss = 0.43896743603673377, disc_loss = 0.14448542248522084
Trained batch 347 in epoch 0, gen_loss = 0.4387333305745289, disc_loss = 0.14465568103056786
Trained batch 348 in epoch 0, gen_loss = 0.4385578382151858, disc_loss = 0.14463112757068908
Trained batch 349 in epoch 0, gen_loss = 0.438361593740327, disc_loss = 0.14482127487393362
Trained batch 350 in epoch 0, gen_loss = 0.4384869150286726, disc_loss = 0.14483078541313735
Trained batch 351 in epoch 0, gen_loss = 0.43855247350240295, disc_loss = 0.14467796227968807
Trained batch 352 in epoch 0, gen_loss = 0.4382608331972074, disc_loss = 0.14487239188401202
Trained batch 353 in epoch 0, gen_loss = 0.43793351720955415, disc_loss = 0.14494878863705332
Trained batch 354 in epoch 0, gen_loss = 0.4378571304636942, disc_loss = 0.14489930521591868
Trained batch 355 in epoch 0, gen_loss = 0.437769316136837, disc_loss = 0.14489983044972832
Trained batch 356 in epoch 0, gen_loss = 0.43775285183548596, disc_loss = 0.14504530409961439
Trained batch 357 in epoch 0, gen_loss = 0.4378393125101175, disc_loss = 0.14506867554756767
Trained batch 358 in epoch 0, gen_loss = 0.4374677845196472, disc_loss = 0.14522391443288674
Trained batch 359 in epoch 0, gen_loss = 0.4373232161005338, disc_loss = 0.14509378582394372
Trained batch 360 in epoch 0, gen_loss = 0.43725449168781166, disc_loss = 0.14487999376074676
Trained batch 361 in epoch 0, gen_loss = 0.4371554504935913, disc_loss = 0.14470549153925552
Trained batch 362 in epoch 0, gen_loss = 0.4369663227523982, disc_loss = 0.14478077121417632
Trained batch 363 in epoch 0, gen_loss = 0.4368894744541619, disc_loss = 0.1457039357679845
Trained batch 364 in epoch 0, gen_loss = 0.4369183702828133, disc_loss = 0.1460412005013595
Trained batch 365 in epoch 0, gen_loss = 0.4366467696884291, disc_loss = 0.14617026601078326
Trained batch 366 in epoch 0, gen_loss = 0.43655663720593463, disc_loss = 0.14633700673592756
Trained batch 367 in epoch 0, gen_loss = 0.4363566366550715, disc_loss = 0.14650849920808864
Trained batch 368 in epoch 0, gen_loss = 0.4361335600456248, disc_loss = 0.14660228186900295
Trained batch 369 in epoch 0, gen_loss = 0.43596498893724905, disc_loss = 0.14669552638472336
Trained batch 370 in epoch 0, gen_loss = 0.4359778353788782, disc_loss = 0.14691892193725728
Trained batch 371 in epoch 0, gen_loss = 0.43565430492162704, disc_loss = 0.14693237652611588
Trained batch 372 in epoch 0, gen_loss = 0.4354971059206024, disc_loss = 0.14699795750037195
Trained batch 373 in epoch 0, gen_loss = 0.4355525862883757, disc_loss = 0.14724528705601625
Trained batch 374 in epoch 0, gen_loss = 0.43530873767534894, disc_loss = 0.14753289425124724
Trained batch 375 in epoch 0, gen_loss = 0.4350139651685319, disc_loss = 0.1479150879944853
Trained batch 376 in epoch 0, gen_loss = 0.434843411338108, disc_loss = 0.1479867992784324
Trained batch 377 in epoch 0, gen_loss = 0.434437879257732, disc_loss = 0.14793063743315912
Trained batch 378 in epoch 0, gen_loss = 0.4340960110554909, disc_loss = 0.14838001151424207
Trained batch 379 in epoch 0, gen_loss = 0.43394045163142053, disc_loss = 0.14844152931074955
Trained batch 380 in epoch 0, gen_loss = 0.4337180075370108, disc_loss = 0.14856453403938083
Trained batch 381 in epoch 0, gen_loss = 0.4334744840704334, disc_loss = 0.14850656473424032
Trained batch 382 in epoch 0, gen_loss = 0.4332119063048699, disc_loss = 0.1488560024556502
Trained batch 383 in epoch 0, gen_loss = 0.43305311305448413, disc_loss = 0.14897601744693625
Trained batch 384 in epoch 0, gen_loss = 0.4329921271893885, disc_loss = 0.14890115731093403
Trained batch 385 in epoch 0, gen_loss = 0.43273581247873255, disc_loss = 0.14895131398195044
Trained batch 386 in epoch 0, gen_loss = 0.4324554289650239, disc_loss = 0.14896029043095596
Trained batch 387 in epoch 0, gen_loss = 0.4322631419012227, disc_loss = 0.1492747653098105
Trained batch 388 in epoch 0, gen_loss = 0.4323282427223912, disc_loss = 0.1495884742113764
Trained batch 389 in epoch 0, gen_loss = 0.43221639203719603, disc_loss = 0.1494624599026373
Trained batch 390 in epoch 0, gen_loss = 0.4319600830297641, disc_loss = 0.14944489947889392
Trained batch 391 in epoch 0, gen_loss = 0.43207008939008323, disc_loss = 0.14929224554287765
Trained batch 392 in epoch 0, gen_loss = 0.432018815106108, disc_loss = 0.1492561627032458
Trained batch 393 in epoch 0, gen_loss = 0.4317500054987554, disc_loss = 0.14927817207671285
Trained batch 394 in epoch 0, gen_loss = 0.43156160395356674, disc_loss = 0.14939162180157778
Trained batch 395 in epoch 0, gen_loss = 0.4314675784923814, disc_loss = 0.1496077217890721
Trained batch 396 in epoch 0, gen_loss = 0.4313619557946395, disc_loss = 0.14963959472521352
Trained batch 397 in epoch 0, gen_loss = 0.4312360408767384, disc_loss = 0.14960450480397247
Trained batch 398 in epoch 0, gen_loss = 0.43090997341282683, disc_loss = 0.14964460919291378
Trained batch 399 in epoch 0, gen_loss = 0.43098034888505937, disc_loss = 0.1494539810693823
Trained batch 400 in epoch 0, gen_loss = 0.43071995508343797, disc_loss = 0.1494808279865066
Trained batch 401 in epoch 0, gen_loss = 0.43068894462205876, disc_loss = 0.14954654245743926
Trained batch 402 in epoch 0, gen_loss = 0.4306176001617394, disc_loss = 0.14942765287435603
Trained batch 403 in epoch 0, gen_loss = 0.43062975582214863, disc_loss = 0.14930005382405281
Trained batch 404 in epoch 0, gen_loss = 0.4304614598368421, disc_loss = 0.1491605533838824
Trained batch 405 in epoch 0, gen_loss = 0.4304577756691449, disc_loss = 0.14899201997386044
Trained batch 406 in epoch 0, gen_loss = 0.4305174663406625, disc_loss = 0.149035358730548
Trained batch 407 in epoch 0, gen_loss = 0.4302993248782906, disc_loss = 0.1489285270605857
Trained batch 408 in epoch 0, gen_loss = 0.43024222680292384, disc_loss = 0.14866869229695834
Trained batch 409 in epoch 0, gen_loss = 0.4300961895686824, disc_loss = 0.14853746529168835
Trained batch 410 in epoch 0, gen_loss = 0.4300067695242935, disc_loss = 0.1488414316295381
Trained batch 411 in epoch 0, gen_loss = 0.4299830850032927, disc_loss = 0.1485873610120339
Trained batch 412 in epoch 0, gen_loss = 0.4300308389178777, disc_loss = 0.14834516661210082
Trained batch 413 in epoch 0, gen_loss = 0.4299317069243694, disc_loss = 0.14809082064930584
Trained batch 414 in epoch 0, gen_loss = 0.4300254968275507, disc_loss = 0.14779922799487788
Trained batch 415 in epoch 0, gen_loss = 0.430039196418455, disc_loss = 0.14758148748884337
Trained batch 416 in epoch 0, gen_loss = 0.4299428856058372, disc_loss = 0.1474237300218831
Trained batch 417 in epoch 0, gen_loss = 0.42981319243542887, disc_loss = 0.147243283285746
Trained batch 418 in epoch 0, gen_loss = 0.4298558343281894, disc_loss = 0.14770252364943234
Trained batch 419 in epoch 0, gen_loss = 0.42982351843799865, disc_loss = 0.14792430108812238
Trained batch 420 in epoch 0, gen_loss = 0.4296040600807253, disc_loss = 0.1481173932795676
Trained batch 421 in epoch 0, gen_loss = 0.42954736065243093, disc_loss = 0.14825884721316926
Trained batch 422 in epoch 0, gen_loss = 0.42954405402460843, disc_loss = 0.14835466306004894
Trained batch 423 in epoch 0, gen_loss = 0.4293796602847441, disc_loss = 0.14837387990303127
Trained batch 424 in epoch 0, gen_loss = 0.4294009268985075, disc_loss = 0.14847181080676178
Trained batch 425 in epoch 0, gen_loss = 0.4294033566830863, disc_loss = 0.1489427903199245
Trained batch 426 in epoch 0, gen_loss = 0.4293968711022192, disc_loss = 0.1489631482214608
Trained batch 427 in epoch 0, gen_loss = 0.4295105531672451, disc_loss = 0.14877159753161542
Trained batch 428 in epoch 0, gen_loss = 0.42919564920983394, disc_loss = 0.14902438725928813
Trained batch 429 in epoch 0, gen_loss = 0.42910068042056504, disc_loss = 0.1488681548448323
Trained batch 430 in epoch 0, gen_loss = 0.4291112003221313, disc_loss = 0.1488564290222982
Trained batch 431 in epoch 0, gen_loss = 0.42905590766006046, disc_loss = 0.14911605368359704
Trained batch 432 in epoch 0, gen_loss = 0.4289872183810756, disc_loss = 0.14897084536190053
Trained batch 433 in epoch 0, gen_loss = 0.42886329713504984, disc_loss = 0.14948063426809857
Trained batch 434 in epoch 0, gen_loss = 0.4286574389742709, disc_loss = 0.14989408464224516
Trained batch 435 in epoch 0, gen_loss = 0.42846146287447817, disc_loss = 0.14999112374696094
Trained batch 436 in epoch 0, gen_loss = 0.4283646619292637, disc_loss = 0.1500167176020875
Trained batch 437 in epoch 0, gen_loss = 0.42806292478352376, disc_loss = 0.1500492701923568
Trained batch 438 in epoch 0, gen_loss = 0.42790194768840467, disc_loss = 0.15020219615717886
Trained batch 439 in epoch 0, gen_loss = 0.4278570540249348, disc_loss = 0.15018328947057438
Trained batch 440 in epoch 0, gen_loss = 0.4278441685127293, disc_loss = 0.15028667832405862
Trained batch 441 in epoch 0, gen_loss = 0.4276755730625731, disc_loss = 0.15022299033105035
Trained batch 442 in epoch 0, gen_loss = 0.4275491778522259, disc_loss = 0.15014102789899228
Trained batch 443 in epoch 0, gen_loss = 0.42748725300168133, disc_loss = 0.15011512445126501
Trained batch 444 in epoch 0, gen_loss = 0.42768741544712796, disc_loss = 0.15020209909782986
Trained batch 445 in epoch 0, gen_loss = 0.427449984734903, disc_loss = 0.1501946972219499
Trained batch 446 in epoch 0, gen_loss = 0.4273598869508278, disc_loss = 0.1501246397123074
Trained batch 447 in epoch 0, gen_loss = 0.42738227925396394, disc_loss = 0.1503185460273276
Trained batch 448 in epoch 0, gen_loss = 0.42750630134463574, disc_loss = 0.15015307754767698
Trained batch 449 in epoch 0, gen_loss = 0.42753149489561715, disc_loss = 0.15001461445250444
Trained batch 450 in epoch 0, gen_loss = 0.4275223594282789, disc_loss = 0.15007823496487016
Trained batch 451 in epoch 0, gen_loss = 0.4272988209814097, disc_loss = 0.15056885596554298
Trained batch 452 in epoch 0, gen_loss = 0.4272455388215467, disc_loss = 0.150647504923343
Trained batch 453 in epoch 0, gen_loss = 0.4273059742960111, disc_loss = 0.1505291576062366
Trained batch 454 in epoch 0, gen_loss = 0.42712284320003385, disc_loss = 0.15041923407301472
Trained batch 455 in epoch 0, gen_loss = 0.42706992509856556, disc_loss = 0.1503096701834645
Trained batch 456 in epoch 0, gen_loss = 0.427141638435994, disc_loss = 0.15013929934768694
Trained batch 457 in epoch 0, gen_loss = 0.4272347743984914, disc_loss = 0.1501252056530567
Trained batch 458 in epoch 0, gen_loss = 0.42705404219544274, disc_loss = 0.15030822301311886
Trained batch 459 in epoch 0, gen_loss = 0.42696891420561334, disc_loss = 0.1510306019558693
Trained batch 460 in epoch 0, gen_loss = 0.42714467101655657, disc_loss = 0.15083741531414413
Testing Epoch 0

  0%|          | 0/25 [00:00<?, ?it/s]
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.47007277607917786, disc_loss = 0.22322168946266174
Trained batch 1 in epoch 1, gen_loss = 0.451503187417984, disc_loss = 0.16394030302762985
Trained batch 2 in epoch 1, gen_loss = 0.4104723532994588, disc_loss = 0.16317898035049438
Trained batch 3 in epoch 1, gen_loss = 0.3915821760892868, disc_loss = 0.17169443890452385
Trained batch 4 in epoch 1, gen_loss = 0.38164162039756777, disc_loss = 0.15253463685512542
Trained batch 5 in epoch 1, gen_loss = 0.38094863295555115, disc_loss = 0.1476693575580915
Trained batch 6 in epoch 1, gen_loss = 0.38930459107671467, disc_loss = 0.14276930264064244
Trained batch 7 in epoch 1, gen_loss = 0.38317978382110596, disc_loss = 0.1377282403409481
Trained batch 8 in epoch 1, gen_loss = 0.38328825102912056, disc_loss = 0.13727793428632948
Trained batch 9 in epoch 1, gen_loss = 0.3885838985443115, disc_loss = 0.13944132328033448
Trained batch 10 in epoch 1, gen_loss = 0.39698501879518683, disc_loss = 0.13157722828063098
Trained batch 11 in epoch 1, gen_loss = 0.3982829600572586, disc_loss = 0.1323818831394116
Trained batch 12 in epoch 1, gen_loss = 0.39530341212566084, disc_loss = 0.1293965893296095
Trained batch 13 in epoch 1, gen_loss = 0.39577616751194, disc_loss = 0.12866438180208206
Trained batch 14 in epoch 1, gen_loss = 0.3963995357354482, disc_loss = 0.1300739010175069
Trained batch 15 in epoch 1, gen_loss = 0.394938500598073, disc_loss = 0.13383478485047817
Trained batch 16 in epoch 1, gen_loss = 0.39656557581003976, disc_loss = 0.1318042260759017
Trained batch 17 in epoch 1, gen_loss = 0.39863521688514286, disc_loss = 0.13309027751286825
Trained batch 18 in epoch 1, gen_loss = 0.3978619214735533, disc_loss = 0.1321870657174211
Trained batch 19 in epoch 1, gen_loss = 0.3958017110824585, disc_loss = 0.1284664636477828
Trained batch 20 in epoch 1, gen_loss = 0.39407534968285335, disc_loss = 0.13002857831971987
Trained batch 21 in epoch 1, gen_loss = 0.3971605178984729, disc_loss = 0.1346236817877401
Trained batch 22 in epoch 1, gen_loss = 0.3954912333384804, disc_loss = 0.13889280658053316
Trained batch 23 in epoch 1, gen_loss = 0.39755382885535556, disc_loss = 0.1451695205954214
Trained batch 24 in epoch 1, gen_loss = 0.3941479587554932, disc_loss = 0.14599215134978294
Trained batch 25 in epoch 1, gen_loss = 0.39663136349274564, disc_loss = 0.14939418993890285
Trained batch 26 in epoch 1, gen_loss = 0.3936824014893285, disc_loss = 0.15499455937080914
Trained batch 27 in epoch 1, gen_loss = 0.3924817740917206, disc_loss = 0.15301887039095163
Trained batch 28 in epoch 1, gen_loss = 0.39610459886748217, disc_loss = 0.15223709455338016
Trained batch 29 in epoch 1, gen_loss = 0.3958915253480276, disc_loss = 0.15272839205960434
Trained batch 30 in epoch 1, gen_loss = 0.3977492182485519, disc_loss = 0.15186751790104375
Trained batch 31 in epoch 1, gen_loss = 0.39584347791969776, disc_loss = 0.15278097323607653
Trained batch 32 in epoch 1, gen_loss = 0.39587170246875647, disc_loss = 0.15188416443539388
Trained batch 33 in epoch 1, gen_loss = 0.396748563822578, disc_loss = 0.15166449601597645
Trained batch 34 in epoch 1, gen_loss = 0.39652575169290816, disc_loss = 0.1513139223413808
Trained batch 35 in epoch 1, gen_loss = 0.39646202905310524, disc_loss = 0.1509849430165357
Trained batch 36 in epoch 1, gen_loss = 0.3958399030002388, disc_loss = 0.15012103007049174
Trained batch 37 in epoch 1, gen_loss = 0.3966228114931207, disc_loss = 0.14933241913585285
Trained batch 38 in epoch 1, gen_loss = 0.3979633213617863, disc_loss = 0.15216351481966484
Trained batch 39 in epoch 1, gen_loss = 0.39667230248451235, disc_loss = 0.1517608285881579
Trained batch 40 in epoch 1, gen_loss = 0.39797897091725976, disc_loss = 0.15108839758649106
Trained batch 41 in epoch 1, gen_loss = 0.39873964091142017, disc_loss = 0.15026712302295936
Trained batch 42 in epoch 1, gen_loss = 0.398542033378468, disc_loss = 0.14850397278056587
Trained batch 43 in epoch 1, gen_loss = 0.39867202869870444, disc_loss = 0.14593320661647755
Trained batch 44 in epoch 1, gen_loss = 0.39790241254700554, disc_loss = 0.1450081100066503
Trained batch 45 in epoch 1, gen_loss = 0.3990342921536902, disc_loss = 0.14449836572875147
Trained batch 46 in epoch 1, gen_loss = 0.4005904362556782, disc_loss = 0.14196205749473673
Trained batch 47 in epoch 1, gen_loss = 0.40270403648416203, disc_loss = 0.13922589311065772
Trained batch 48 in epoch 1, gen_loss = 0.40453460812568665, disc_loss = 0.1374141082775836
Trained batch 49 in epoch 1, gen_loss = 0.4039770299196243, disc_loss = 0.1351856842637062
Trained batch 50 in epoch 1, gen_loss = 0.4054937730817234, disc_loss = 0.1329087376156274
Trained batch 51 in epoch 1, gen_loss = 0.405812819989828, disc_loss = 0.13060261719287014
Trained batch 52 in epoch 1, gen_loss = 0.40542224049568176, disc_loss = 0.12866982039204747
Trained batch 53 in epoch 1, gen_loss = 0.4073642288093214, disc_loss = 0.12743890914997016
Trained batch 54 in epoch 1, gen_loss = 0.40827111493457446, disc_loss = 0.12580167754468594
Trained batch 55 in epoch 1, gen_loss = 0.407514250172036, disc_loss = 0.12513610409639245
Trained batch 56 in epoch 1, gen_loss = 0.40754416114405584, disc_loss = 0.12414104617282487
Trained batch 57 in epoch 1, gen_loss = 0.4060957770923088, disc_loss = 0.12328951133029728
Trained batch 58 in epoch 1, gen_loss = 0.4060926396968001, disc_loss = 0.1240773710690565
Trained batch 59 in epoch 1, gen_loss = 0.40818314055601757, disc_loss = 0.13082051818879942
Trained batch 60 in epoch 1, gen_loss = 0.40764722032625167, disc_loss = 0.1340989186657501
Trained batch 61 in epoch 1, gen_loss = 0.40752587203056584, disc_loss = 0.13670806726440787
Trained batch 62 in epoch 1, gen_loss = 0.40650361587130834, disc_loss = 0.13854116575408076
Trained batch 63 in epoch 1, gen_loss = 0.40655338671058416, disc_loss = 0.140744236719911
Trained batch 64 in epoch 1, gen_loss = 0.40529611569184526, disc_loss = 0.14284700334358674
Trained batch 65 in epoch 1, gen_loss = 0.4036209912914218, disc_loss = 0.1449768777626256
Trained batch 66 in epoch 1, gen_loss = 0.4032585327305011, disc_loss = 0.14619415883086065
Trained batch 67 in epoch 1, gen_loss = 0.40233024165910836, disc_loss = 0.14719923559631057
Trained batch 68 in epoch 1, gen_loss = 0.40197727170543396, disc_loss = 0.1458795027051499
Trained batch 69 in epoch 1, gen_loss = 0.40057908935206277, disc_loss = 0.14541011012292335
Trained batch 70 in epoch 1, gen_loss = 0.39945521405045414, disc_loss = 0.14568161110485522
Trained batch 71 in epoch 1, gen_loss = 0.39940202029214966, disc_loss = 0.1456273840352272
Trained batch 72 in epoch 1, gen_loss = 0.40015587047354817, disc_loss = 0.14480556166182235
Trained batch 73 in epoch 1, gen_loss = 0.39905349346431523, disc_loss = 0.14579348352964264
Trained batch 74 in epoch 1, gen_loss = 0.3981712706883748, disc_loss = 0.15156635012477637
Trained batch 75 in epoch 1, gen_loss = 0.39754054107164083, disc_loss = 0.15109107178929998
Trained batch 76 in epoch 1, gen_loss = 0.3976687177435144, disc_loss = 0.15103262707639437
Trained batch 77 in epoch 1, gen_loss = 0.3985267801162524, disc_loss = 0.15096685028849885
Trained batch 78 in epoch 1, gen_loss = 0.3981148872194411, disc_loss = 0.15223056574269564
Trained batch 79 in epoch 1, gen_loss = 0.39880978874862194, disc_loss = 0.15172964042285458
Trained batch 80 in epoch 1, gen_loss = 0.40017072322927877, disc_loss = 0.15096606227948708
Trained batch 81 in epoch 1, gen_loss = 0.39993483954813425, disc_loss = 0.14946623177199467
Trained batch 82 in epoch 1, gen_loss = 0.39938621240926075, disc_loss = 0.15158022018934947
Trained batch 83 in epoch 1, gen_loss = 0.4000560204897608, disc_loss = 0.15281259227499722
Trained batch 84 in epoch 1, gen_loss = 0.39986493026509007, disc_loss = 0.15376403133439667
Trained batch 85 in epoch 1, gen_loss = 0.3998904810395352, disc_loss = 0.15453578058500275
Trained batch 86 in epoch 1, gen_loss = 0.4001200384107129, disc_loss = 0.15469789516780225
Trained batch 87 in epoch 1, gen_loss = 0.39987891573797574, disc_loss = 0.15395462753208863
Trained batch 88 in epoch 1, gen_loss = 0.3993928288475851, disc_loss = 0.15380274315019338
Trained batch 89 in epoch 1, gen_loss = 0.3994989186525345, disc_loss = 0.1546036449054049
Trained batch 90 in epoch 1, gen_loss = 0.39968948508356955, disc_loss = 0.15422587853006936
Trained batch 91 in epoch 1, gen_loss = 0.39896529070709064, disc_loss = 0.15505716126695598
Trained batch 92 in epoch 1, gen_loss = 0.39897197100424, disc_loss = 0.15589179261837915
Trained batch 93 in epoch 1, gen_loss = 0.3990994577712201, disc_loss = 0.15638257375858883
Trained batch 94 in epoch 1, gen_loss = 0.3985339117677588, disc_loss = 0.1557426909376916
Trained batch 95 in epoch 1, gen_loss = 0.3983914790054162, disc_loss = 0.15491732833712982
Trained batch 96 in epoch 1, gen_loss = 0.39924435363602395, disc_loss = 0.15557929092883757
Trained batch 97 in epoch 1, gen_loss = 0.3988349008925107, disc_loss = 0.15545810959586986
Trained batch 98 in epoch 1, gen_loss = 0.39852811501483726, disc_loss = 0.15604340927581292
Trained batch 99 in epoch 1, gen_loss = 0.39812457501888276, disc_loss = 0.15519234131090343
Trained batch 100 in epoch 1, gen_loss = 0.3985214377983962, disc_loss = 0.1544711751642056
Trained batch 101 in epoch 1, gen_loss = 0.39875803858626124, disc_loss = 0.15419266938104056
Trained batch 102 in epoch 1, gen_loss = 0.39900059954633993, disc_loss = 0.15360527343650177
Trained batch 103 in epoch 1, gen_loss = 0.39915361455999887, disc_loss = 0.15254804322746798
Trained batch 104 in epoch 1, gen_loss = 0.3986298450401851, disc_loss = 0.15301410799757356
Trained batch 105 in epoch 1, gen_loss = 0.39952606356368875, disc_loss = 0.15532785164684337
Trained batch 106 in epoch 1, gen_loss = 0.3993475381459031, disc_loss = 0.15608587473735352
Trained batch 107 in epoch 1, gen_loss = 0.3993574298090405, disc_loss = 0.15681632486585942
Trained batch 108 in epoch 1, gen_loss = 0.39974087203314546, disc_loss = 0.15655779362647632
Trained batch 109 in epoch 1, gen_loss = 0.39959906854412774, disc_loss = 0.15686573036523027
Trained batch 110 in epoch 1, gen_loss = 0.3988126935185613, disc_loss = 0.1564561237606245
Trained batch 111 in epoch 1, gen_loss = 0.3974666850907462, disc_loss = 0.15662876851690402
Trained batch 112 in epoch 1, gen_loss = 0.39736765306607813, disc_loss = 0.15682789883617543
Trained batch 113 in epoch 1, gen_loss = 0.39694853989701523, disc_loss = 0.15727704935788847
Trained batch 114 in epoch 1, gen_loss = 0.39672391829283343, disc_loss = 0.15831021345018045
Trained batch 115 in epoch 1, gen_loss = 0.39759357813103446, disc_loss = 0.1578753485488866
Trained batch 116 in epoch 1, gen_loss = 0.39829096682051307, disc_loss = 0.15758984340912002
Trained batch 117 in epoch 1, gen_loss = 0.3983859970407971, disc_loss = 0.15804651457721652
Trained batch 118 in epoch 1, gen_loss = 0.3985841284279062, disc_loss = 0.15866192751916267
Trained batch 119 in epoch 1, gen_loss = 0.3990851896504561, disc_loss = 0.1583121619730567
Trained batch 120 in epoch 1, gen_loss = 0.3989698936131375, disc_loss = 0.15782687168814674
Trained batch 121 in epoch 1, gen_loss = 0.39868057116133265, disc_loss = 0.15738237749205017
Trained batch 122 in epoch 1, gen_loss = 0.39854684254018274, disc_loss = 0.1570021973135389
Trained batch 123 in epoch 1, gen_loss = 0.3981427276326764, disc_loss = 0.15690692444331944
Trained batch 124 in epoch 1, gen_loss = 0.39798736810684204, disc_loss = 0.15742638721317054
Trained batch 125 in epoch 1, gen_loss = 0.39781071955249425, disc_loss = 0.15837129704388125
Trained batch 126 in epoch 1, gen_loss = 0.3969654675543778, disc_loss = 0.15905070565200932
Trained batch 127 in epoch 1, gen_loss = 0.39606987475417554, disc_loss = 0.15904727650195127
Trained batch 128 in epoch 1, gen_loss = 0.3959575219209804, disc_loss = 0.15901619198103978
Trained batch 129 in epoch 1, gen_loss = 0.3958334663739571, disc_loss = 0.1589191757930586
Trained batch 130 in epoch 1, gen_loss = 0.39568194109974925, disc_loss = 0.15913083776120693
Trained batch 131 in epoch 1, gen_loss = 0.3961450584007032, disc_loss = 0.15893859576405675
Trained batch 132 in epoch 1, gen_loss = 0.3955666510234202, disc_loss = 0.15889300038351825
Trained batch 133 in epoch 1, gen_loss = 0.39584481515991154, disc_loss = 0.15949373583156448
Trained batch 134 in epoch 1, gen_loss = 0.39589937616277626, disc_loss = 0.15991744997186794
Trained batch 135 in epoch 1, gen_loss = 0.39612144954940853, disc_loss = 0.15956575655624927
Trained batch 136 in epoch 1, gen_loss = 0.3954623502536412, disc_loss = 0.16000677864781043
Trained batch 137 in epoch 1, gen_loss = 0.39563765214837116, disc_loss = 0.16071605738387376
Trained batch 138 in epoch 1, gen_loss = 0.39535224952286097, disc_loss = 0.16048586070403564
Trained batch 139 in epoch 1, gen_loss = 0.3951800301671028, disc_loss = 0.16098234847054949
Trained batch 140 in epoch 1, gen_loss = 0.39547113281615237, disc_loss = 0.1605123551166121
Trained batch 141 in epoch 1, gen_loss = 0.395885276542583, disc_loss = 0.160546109309866
Trained batch 142 in epoch 1, gen_loss = 0.39573520901319864, disc_loss = 0.16028999398508065
Trained batch 143 in epoch 1, gen_loss = 0.3952329353325897, disc_loss = 0.1601094846911211
Trained batch 144 in epoch 1, gen_loss = 0.3952361441891769, disc_loss = 0.1598341055664009
Trained batch 145 in epoch 1, gen_loss = 0.39516516621798686, disc_loss = 0.1594031079264026
Trained batch 146 in epoch 1, gen_loss = 0.3948350761617933, disc_loss = 0.1590225804711179
Trained batch 147 in epoch 1, gen_loss = 0.3944707041656649, disc_loss = 0.15960029791411315
Trained batch 148 in epoch 1, gen_loss = 0.3946577106546236, disc_loss = 0.1593328832067399
Trained batch 149 in epoch 1, gen_loss = 0.39427645146846774, disc_loss = 0.15902773446713886
Trained batch 150 in epoch 1, gen_loss = 0.39344840590527513, disc_loss = 0.16038449480512876
Trained batch 151 in epoch 1, gen_loss = 0.39299014112667036, disc_loss = 0.16173843614830585
Trained batch 152 in epoch 1, gen_loss = 0.3928517886236602, disc_loss = 0.162538541170458
Trained batch 153 in epoch 1, gen_loss = 0.39348303226681497, disc_loss = 0.16221738797189159
Trained batch 154 in epoch 1, gen_loss = 0.39404285723163235, disc_loss = 0.16225983084089332
Trained batch 155 in epoch 1, gen_loss = 0.39381272040116483, disc_loss = 0.16160788264674827
Trained batch 156 in epoch 1, gen_loss = 0.39393855830666363, disc_loss = 0.1614752176638906
Trained batch 157 in epoch 1, gen_loss = 0.39382228745689873, disc_loss = 0.16111629259996588
Trained batch 158 in epoch 1, gen_loss = 0.39350636481489026, disc_loss = 0.16102643556447713
Trained batch 159 in epoch 1, gen_loss = 0.3940349126234651, disc_loss = 0.16077240520971828
Trained batch 160 in epoch 1, gen_loss = 0.394349757003488, disc_loss = 0.16015911793556087
Trained batch 161 in epoch 1, gen_loss = 0.393947500873495, disc_loss = 0.16088596397412963
Trained batch 162 in epoch 1, gen_loss = 0.39433784810311956, disc_loss = 0.1602260867316573
Trained batch 163 in epoch 1, gen_loss = 0.39482806568465584, disc_loss = 0.1614377142622976
Trained batch 164 in epoch 1, gen_loss = 0.3944934256149061, disc_loss = 0.16066284183638566
Trained batch 165 in epoch 1, gen_loss = 0.39425233814371635, disc_loss = 0.16148633648450655
Trained batch 166 in epoch 1, gen_loss = 0.39429437989246346, disc_loss = 0.16132935118153244
Trained batch 167 in epoch 1, gen_loss = 0.3942041838807719, disc_loss = 0.16111272045167252
Trained batch 168 in epoch 1, gen_loss = 0.39420081683869895, disc_loss = 0.16145409735680155
Trained batch 169 in epoch 1, gen_loss = 0.39412106258027696, disc_loss = 0.16104014471501987
Trained batch 170 in epoch 1, gen_loss = 0.39462756762030526, disc_loss = 0.16060585284071882
Trained batch 171 in epoch 1, gen_loss = 0.39447146376898123, disc_loss = 0.16005202689814532
Trained batch 172 in epoch 1, gen_loss = 0.39484339607933355, disc_loss = 0.1600985930521967
Trained batch 173 in epoch 1, gen_loss = 0.3948422869046529, disc_loss = 0.1599235401446021
Trained batch 174 in epoch 1, gen_loss = 0.39511475358690534, disc_loss = 0.15951151987803833
Trained batch 175 in epoch 1, gen_loss = 0.39473188075829635, disc_loss = 0.15938026123066348
Trained batch 176 in epoch 1, gen_loss = 0.395113914531503, disc_loss = 0.15880519418456293
Trained batch 177 in epoch 1, gen_loss = 0.39569706042830866, disc_loss = 0.1586688150588967
Trained batch 178 in epoch 1, gen_loss = 0.39611533750368894, disc_loss = 0.1586534760257635
Trained batch 179 in epoch 1, gen_loss = 0.39608093384239407, disc_loss = 0.16000973463782833
Trained batch 180 in epoch 1, gen_loss = 0.39618532499555725, disc_loss = 0.16020012212124812
Trained batch 181 in epoch 1, gen_loss = 0.39624247118666933, disc_loss = 0.1597102892912597
Trained batch 182 in epoch 1, gen_loss = 0.39609120094059597, disc_loss = 0.15984749380254842
Trained batch 183 in epoch 1, gen_loss = 0.39606799088094546, disc_loss = 0.1603141868557862
Trained batch 184 in epoch 1, gen_loss = 0.3958775815126058, disc_loss = 0.15973946802016045
Trained batch 185 in epoch 1, gen_loss = 0.39549337776117427, disc_loss = 0.15939730537494504
Trained batch 186 in epoch 1, gen_loss = 0.39592318882279215, disc_loss = 0.15910164146798658
Trained batch 187 in epoch 1, gen_loss = 0.3960508550418184, disc_loss = 0.1603805572141279
Trained batch 188 in epoch 1, gen_loss = 0.39610832566937443, disc_loss = 0.16133525308773475
Trained batch 189 in epoch 1, gen_loss = 0.396244762916314, disc_loss = 0.16109458736977295
Trained batch 190 in epoch 1, gen_loss = 0.39628822266743446, disc_loss = 0.16088804918102412
Trained batch 191 in epoch 1, gen_loss = 0.39565085247159004, disc_loss = 0.1611476512189256
Trained batch 192 in epoch 1, gen_loss = 0.39561331550074363, disc_loss = 0.16068646913500492
Trained batch 193 in epoch 1, gen_loss = 0.3954693764140925, disc_loss = 0.16047238558050744
Trained batch 194 in epoch 1, gen_loss = 0.39566745758056643, disc_loss = 0.1600156103523496
Trained batch 195 in epoch 1, gen_loss = 0.3955927708623361, disc_loss = 0.159972666054774
Trained batch 196 in epoch 1, gen_loss = 0.395434606650154, disc_loss = 0.15992593125624555
Trained batch 197 in epoch 1, gen_loss = 0.3954030392747937, disc_loss = 0.16065472540812512
Trained batch 198 in epoch 1, gen_loss = 0.3958024379596039, disc_loss = 0.1605603574686239
Trained batch 199 in epoch 1, gen_loss = 0.39536613985896113, disc_loss = 0.1603299181489274
Trained batch 200 in epoch 1, gen_loss = 0.3954387574053522, disc_loss = 0.1598462409742955
Trained batch 201 in epoch 1, gen_loss = 0.39542534416264824, disc_loss = 0.15957337757572532
Trained batch 202 in epoch 1, gen_loss = 0.3955956449355985, disc_loss = 0.1598551881825322
Trained batch 203 in epoch 1, gen_loss = 0.3957671099433712, disc_loss = 0.1598892452186156
Trained batch 204 in epoch 1, gen_loss = 0.39548496952871, disc_loss = 0.15977061295927297
Trained batch 205 in epoch 1, gen_loss = 0.39540975490241376, disc_loss = 0.1596798234149018
Trained batch 206 in epoch 1, gen_loss = 0.39522302107534546, disc_loss = 0.15928763129123022
Trained batch 207 in epoch 1, gen_loss = 0.39460782749721635, disc_loss = 0.15908046137953463
Trained batch 208 in epoch 1, gen_loss = 0.3947137277662469, disc_loss = 0.1589572006105735
Trained batch 209 in epoch 1, gen_loss = 0.39461940683069685, disc_loss = 0.15951737250157055
Trained batch 210 in epoch 1, gen_loss = 0.3943087917651045, disc_loss = 0.15961629180105236
Trained batch 211 in epoch 1, gen_loss = 0.39431420601201506, disc_loss = 0.16001085107179605
Trained batch 212 in epoch 1, gen_loss = 0.3944296958580823, disc_loss = 0.15983110749787988
Trained batch 213 in epoch 1, gen_loss = 0.3943445665814052, disc_loss = 0.1601753179114486
Trained batch 214 in epoch 1, gen_loss = 0.3944525871165963, disc_loss = 0.16000997714784948
Trained batch 215 in epoch 1, gen_loss = 0.39434785506239645, disc_loss = 0.16000056514706187
Trained batch 216 in epoch 1, gen_loss = 0.3944079533974696, disc_loss = 0.16061947559551573
Trained batch 217 in epoch 1, gen_loss = 0.3941080983078808, disc_loss = 0.16039626388767853
Trained batch 218 in epoch 1, gen_loss = 0.3940574181134298, disc_loss = 0.16027031055987562
Trained batch 219 in epoch 1, gen_loss = 0.39385674433274703, disc_loss = 0.1603542516135018
Trained batch 220 in epoch 1, gen_loss = 0.39391777418317836, disc_loss = 0.1603435093149273
Trained batch 221 in epoch 1, gen_loss = 0.3939690027419511, disc_loss = 0.16039704886760126
Trained batch 222 in epoch 1, gen_loss = 0.39371509148400996, disc_loss = 0.16047905218023223
Trained batch 223 in epoch 1, gen_loss = 0.393674059238817, disc_loss = 0.1604573680046347
Trained batch 224 in epoch 1, gen_loss = 0.39337820490201314, disc_loss = 0.16024328453259334
Trained batch 225 in epoch 1, gen_loss = 0.39357497721119267, disc_loss = 0.1602833715053193
Trained batch 226 in epoch 1, gen_loss = 0.3935631756477944, disc_loss = 0.1600425281738329
Trained batch 227 in epoch 1, gen_loss = 0.3933532355647338, disc_loss = 0.1596678843713578
Trained batch 228 in epoch 1, gen_loss = 0.3932790194015836, disc_loss = 0.15961810744339072
Trained batch 229 in epoch 1, gen_loss = 0.3935209979181704, disc_loss = 0.15958372956627737
Trained batch 230 in epoch 1, gen_loss = 0.3935498288183501, disc_loss = 0.15962839687396307
Trained batch 231 in epoch 1, gen_loss = 0.3932745946121627, disc_loss = 0.15968013881978677
Trained batch 232 in epoch 1, gen_loss = 0.39313223983596834, disc_loss = 0.1592725354802391
Trained batch 233 in epoch 1, gen_loss = 0.3929635947331404, disc_loss = 0.15931663356132358
Trained batch 234 in epoch 1, gen_loss = 0.39302287253927676, disc_loss = 0.15978329580752773
Trained batch 235 in epoch 1, gen_loss = 0.3928292790206812, disc_loss = 0.15964286887655194
Trained batch 236 in epoch 1, gen_loss = 0.39315566760075243, disc_loss = 0.16032564274982436
Trained batch 237 in epoch 1, gen_loss = 0.3930843843131506, disc_loss = 0.16017487015528212
Trained batch 238 in epoch 1, gen_loss = 0.3932951904490403, disc_loss = 0.16011492312188302
Trained batch 239 in epoch 1, gen_loss = 0.3931052864839633, disc_loss = 0.15980063806831216
Trained batch 240 in epoch 1, gen_loss = 0.39317215601932953, disc_loss = 0.15979810633708208
Trained batch 241 in epoch 1, gen_loss = 0.39296303381604597, disc_loss = 0.1596888141775858
Trained batch 242 in epoch 1, gen_loss = 0.39339885814690295, disc_loss = 0.15947346275465357
Trained batch 243 in epoch 1, gen_loss = 0.39332862161710613, disc_loss = 0.1596973796993433
Trained batch 244 in epoch 1, gen_loss = 0.39318173065477485, disc_loss = 0.1597141132937098
Trained batch 245 in epoch 1, gen_loss = 0.39325911945443814, disc_loss = 0.1598348887372247
Trained batch 246 in epoch 1, gen_loss = 0.39324233382337004, disc_loss = 0.15969534582922212
Trained batch 247 in epoch 1, gen_loss = 0.39322241780257994, disc_loss = 0.159837618256138
Trained batch 248 in epoch 1, gen_loss = 0.3930403024077894, disc_loss = 0.1598274578792922
Trained batch 249 in epoch 1, gen_loss = 0.39313384330272677, disc_loss = 0.16011343261227012
Trained batch 250 in epoch 1, gen_loss = 0.39301901735157607, disc_loss = 0.16000992317583812
Trained batch 251 in epoch 1, gen_loss = 0.3925276098270265, disc_loss = 0.1599928747589094
Trained batch 252 in epoch 1, gen_loss = 0.3925809300699724, disc_loss = 0.15985922724111631
Trained batch 253 in epoch 1, gen_loss = 0.3926105367855763, disc_loss = 0.1594717390211959
Trained batch 254 in epoch 1, gen_loss = 0.39280387046290377, disc_loss = 0.1595533211112899
Trained batch 255 in epoch 1, gen_loss = 0.39273845439311117, disc_loss = 0.1598648929175397
Trained batch 256 in epoch 1, gen_loss = 0.39265780272650813, disc_loss = 0.16036110602913548
Trained batch 257 in epoch 1, gen_loss = 0.39239495576814165, disc_loss = 0.1603243459239891
Trained batch 258 in epoch 1, gen_loss = 0.3923491677952549, disc_loss = 0.16012459276711505
Trained batch 259 in epoch 1, gen_loss = 0.39222985964555007, disc_loss = 0.15984113233235592
Trained batch 260 in epoch 1, gen_loss = 0.3921668080762885, disc_loss = 0.15968886171592492
Trained batch 261 in epoch 1, gen_loss = 0.3925511810843271, disc_loss = 0.15981651262117139
Trained batch 262 in epoch 1, gen_loss = 0.3922048897797617, disc_loss = 0.15960989744816784
Trained batch 263 in epoch 1, gen_loss = 0.3926036468509472, disc_loss = 0.15958349417655193
Trained batch 264 in epoch 1, gen_loss = 0.3928043396967762, disc_loss = 0.159215886409412
Trained batch 265 in epoch 1, gen_loss = 0.39286997959129794, disc_loss = 0.15873558799337065
Trained batch 266 in epoch 1, gen_loss = 0.3931941883394334, disc_loss = 0.15820905925838577
Trained batch 267 in epoch 1, gen_loss = 0.3931067740516876, disc_loss = 0.15772952646392382
Trained batch 268 in epoch 1, gen_loss = 0.3929137773673331, disc_loss = 0.1576460797762062
Trained batch 269 in epoch 1, gen_loss = 0.3929337807275631, disc_loss = 0.15762961645852083
Trained batch 270 in epoch 1, gen_loss = 0.3929690598781698, disc_loss = 0.15732529023627842
Trained batch 271 in epoch 1, gen_loss = 0.39293955595177765, disc_loss = 0.1569699192084098
Trained batch 272 in epoch 1, gen_loss = 0.39309076697398454, disc_loss = 0.15689108759205747
Trained batch 273 in epoch 1, gen_loss = 0.3929831965343796, disc_loss = 0.1564381974205429
Trained batch 274 in epoch 1, gen_loss = 0.3929247644814578, disc_loss = 0.15613844394345175
Trained batch 275 in epoch 1, gen_loss = 0.39356188335712405, disc_loss = 0.15564911256112374
Trained batch 276 in epoch 1, gen_loss = 0.39366981935845385, disc_loss = 0.155397110141222
Trained batch 277 in epoch 1, gen_loss = 0.39386801389481524, disc_loss = 0.1558362138323593
Trained batch 278 in epoch 1, gen_loss = 0.393810037430042, disc_loss = 0.15622206240238148
Trained batch 279 in epoch 1, gen_loss = 0.3939052737184933, disc_loss = 0.155855314855996
Trained batch 280 in epoch 1, gen_loss = 0.39371331433808676, disc_loss = 0.15553140305844385
Trained batch 281 in epoch 1, gen_loss = 0.39361779729947977, disc_loss = 0.1553175624770423
Trained batch 282 in epoch 1, gen_loss = 0.3936140568854531, disc_loss = 0.15490420171563174
Trained batch 283 in epoch 1, gen_loss = 0.39326363014923016, disc_loss = 0.15462218858236054
Trained batch 284 in epoch 1, gen_loss = 0.3934472492912359, disc_loss = 0.15436723188807566
Trained batch 285 in epoch 1, gen_loss = 0.39335564456202765, disc_loss = 0.1545820594504736
Trained batch 286 in epoch 1, gen_loss = 0.39380823454790415, disc_loss = 0.15518558511789562
Trained batch 287 in epoch 1, gen_loss = 0.3936236682865355, disc_loss = 0.15485003945973908
Trained batch 288 in epoch 1, gen_loss = 0.3937449660474454, disc_loss = 0.15448704754746806
Trained batch 289 in epoch 1, gen_loss = 0.3934473528944213, disc_loss = 0.15414266894282452
Trained batch 290 in epoch 1, gen_loss = 0.3933968961853342, disc_loss = 0.15406124523914455
Trained batch 291 in epoch 1, gen_loss = 0.39340488939252616, disc_loss = 0.1536176171861844
Trained batch 292 in epoch 1, gen_loss = 0.39364038077230745, disc_loss = 0.15319262143961906
Trained batch 293 in epoch 1, gen_loss = 0.3937092157853704, disc_loss = 0.15294553229559948
Trained batch 294 in epoch 1, gen_loss = 0.3936988245632689, disc_loss = 0.1532188070685429
Trained batch 295 in epoch 1, gen_loss = 0.3935832535294262, disc_loss = 0.1533469285570538
Trained batch 296 in epoch 1, gen_loss = 0.3936664278459067, disc_loss = 0.15307318400717043
Trained batch 297 in epoch 1, gen_loss = 0.3937852753688825, disc_loss = 0.15306134406014676
Trained batch 298 in epoch 1, gen_loss = 0.39347383698890837, disc_loss = 0.15356527357658115
Trained batch 299 in epoch 1, gen_loss = 0.3936528739333153, disc_loss = 0.1536033152944098
Trained batch 300 in epoch 1, gen_loss = 0.39379743830706193, disc_loss = 0.1532081940746634
Trained batch 301 in epoch 1, gen_loss = 0.3936472080203871, disc_loss = 0.15308730458742045
Trained batch 302 in epoch 1, gen_loss = 0.3936988081869119, disc_loss = 0.15280624650258928
Trained batch 303 in epoch 1, gen_loss = 0.3937093394955522, disc_loss = 0.15262659246065213
Trained batch 304 in epoch 1, gen_loss = 0.39378030857101814, disc_loss = 0.15222159169431104
Trained batch 305 in epoch 1, gen_loss = 0.39363524074258366, disc_loss = 0.15214899561848808
Trained batch 306 in epoch 1, gen_loss = 0.39391056887489967, disc_loss = 0.1519853518305025
Trained batch 307 in epoch 1, gen_loss = 0.3941620970507721, disc_loss = 0.15175784577301085
Trained batch 308 in epoch 1, gen_loss = 0.3941777202882427, disc_loss = 0.15164679908238857
Trained batch 309 in epoch 1, gen_loss = 0.3942332313906762, disc_loss = 0.15130477150781982
Trained batch 310 in epoch 1, gen_loss = 0.3942763971170812, disc_loss = 0.1514923467339762
Trained batch 311 in epoch 1, gen_loss = 0.3945685420662929, disc_loss = 0.15133266697506395
Trained batch 312 in epoch 1, gen_loss = 0.39458068367391347, disc_loss = 0.15104507711736825
Trained batch 313 in epoch 1, gen_loss = 0.39465659163939726, disc_loss = 0.1509988038610833
Trained batch 314 in epoch 1, gen_loss = 0.39435111293717034, disc_loss = 0.15088086981799395
Trained batch 315 in epoch 1, gen_loss = 0.39427701704487017, disc_loss = 0.1506766992344085
Trained batch 316 in epoch 1, gen_loss = 0.3941631248508718, disc_loss = 0.15041995661668126
Trained batch 317 in epoch 1, gen_loss = 0.3941823348121823, disc_loss = 0.15012008507894176
Trained batch 318 in epoch 1, gen_loss = 0.3940110726042601, disc_loss = 0.15019787005718133
Trained batch 319 in epoch 1, gen_loss = 0.3940857335925102, disc_loss = 0.15015898107958492
Trained batch 320 in epoch 1, gen_loss = 0.3940417026619302, disc_loss = 0.14980950120349076
Trained batch 321 in epoch 1, gen_loss = 0.39374090610824014, disc_loss = 0.15008338022201975
Trained batch 322 in epoch 1, gen_loss = 0.3940050517073357, disc_loss = 0.15013665666417347
Trained batch 323 in epoch 1, gen_loss = 0.39390595422850716, disc_loss = 0.1498441700162481
Trained batch 324 in epoch 1, gen_loss = 0.39379586614095247, disc_loss = 0.1495478239053717
Trained batch 325 in epoch 1, gen_loss = 0.3935565454828227, disc_loss = 0.14951684884441319
Trained batch 326 in epoch 1, gen_loss = 0.3935625945027086, disc_loss = 0.14922597030012524
Trained batch 327 in epoch 1, gen_loss = 0.39337529750858863, disc_loss = 0.1491483650823328
Trained batch 328 in epoch 1, gen_loss = 0.393404212132051, disc_loss = 0.14890812940635126
Trained batch 329 in epoch 1, gen_loss = 0.393435126543045, disc_loss = 0.14855796324202056
Trained batch 330 in epoch 1, gen_loss = 0.3934116461665969, disc_loss = 0.14817633491932355
Trained batch 331 in epoch 1, gen_loss = 0.39331912644297246, disc_loss = 0.14781205923049653
Trained batch 332 in epoch 1, gen_loss = 0.3934440440064794, disc_loss = 0.14749305305146687
Trained batch 333 in epoch 1, gen_loss = 0.39381407593895573, disc_loss = 0.14759420573677934
Trained batch 334 in epoch 1, gen_loss = 0.39407879799159606, disc_loss = 0.14721820963574433
Trained batch 335 in epoch 1, gen_loss = 0.39382179640233517, disc_loss = 0.14726510860990466
Trained batch 336 in epoch 1, gen_loss = 0.39389098495333413, disc_loss = 0.1477654586443871
Trained batch 337 in epoch 1, gen_loss = 0.3937460833928994, disc_loss = 0.1475941390873721
Trained batch 338 in epoch 1, gen_loss = 0.3936867933709361, disc_loss = 0.14740355921343276
Trained batch 339 in epoch 1, gen_loss = 0.3936710050000864, disc_loss = 0.14747769554036066
Trained batch 340 in epoch 1, gen_loss = 0.3936535231004363, disc_loss = 0.1473618139242453
Trained batch 341 in epoch 1, gen_loss = 0.3936723358275598, disc_loss = 0.14710742947291475
Trained batch 342 in epoch 1, gen_loss = 0.3934723137071459, disc_loss = 0.14677761549146373
Trained batch 343 in epoch 1, gen_loss = 0.39324501208787743, disc_loss = 0.14651596732166877
Trained batch 344 in epoch 1, gen_loss = 0.3932417848835821, disc_loss = 0.14634398148273645
Trained batch 345 in epoch 1, gen_loss = 0.39323583934348444, disc_loss = 0.1461144375205686
Trained batch 346 in epoch 1, gen_loss = 0.39318287346823416, disc_loss = 0.14572859046610356
Trained batch 347 in epoch 1, gen_loss = 0.39308817590447676, disc_loss = 0.14536793370484963
Trained batch 348 in epoch 1, gen_loss = 0.3930393734087575, disc_loss = 0.14503454976851243
Trained batch 349 in epoch 1, gen_loss = 0.3929038567202432, disc_loss = 0.14470245944069965
Trained batch 350 in epoch 1, gen_loss = 0.3932233442608108, disc_loss = 0.14432679857007968
Trained batch 351 in epoch 1, gen_loss = 0.3932783368297599, disc_loss = 0.14398074357516386
Trained batch 352 in epoch 1, gen_loss = 0.39317807766263274, disc_loss = 0.14364974714667872
Trained batch 353 in epoch 1, gen_loss = 0.3934586107057367, disc_loss = 0.14326687111640296
Trained batch 354 in epoch 1, gen_loss = 0.3933777495169304, disc_loss = 0.1428953309792658
Trained batch 355 in epoch 1, gen_loss = 0.3935850533039382, disc_loss = 0.142560490629416
Trained batch 356 in epoch 1, gen_loss = 0.3936706080156214, disc_loss = 0.14225938498024263
Trained batch 357 in epoch 1, gen_loss = 0.39365242105289544, disc_loss = 0.14192734364493018
Trained batch 358 in epoch 1, gen_loss = 0.3936527909342625, disc_loss = 0.1416602463988084
Trained batch 359 in epoch 1, gen_loss = 0.39381821933719846, disc_loss = 0.14171975819238772
Trained batch 360 in epoch 1, gen_loss = 0.3934942460786603, disc_loss = 0.14157782888447562
Trained batch 361 in epoch 1, gen_loss = 0.3936421816849577, disc_loss = 0.14124497739104194
Trained batch 362 in epoch 1, gen_loss = 0.3938080548583312, disc_loss = 0.1409835281240505
Trained batch 363 in epoch 1, gen_loss = 0.3940501455422286, disc_loss = 0.14071264898578462
Trained batch 364 in epoch 1, gen_loss = 0.3941190666531863, disc_loss = 0.14054902988702875
Trained batch 365 in epoch 1, gen_loss = 0.39425540971951406, disc_loss = 0.1403549669458037
Trained batch 366 in epoch 1, gen_loss = 0.3941373952565466, disc_loss = 0.1400796426307887
Trained batch 367 in epoch 1, gen_loss = 0.3942631638568381, disc_loss = 0.1397604529275154
Trained batch 368 in epoch 1, gen_loss = 0.39411723759116196, disc_loss = 0.1395244992194258
Trained batch 369 in epoch 1, gen_loss = 0.3943276329620464, disc_loss = 0.13923587969982543
Trained batch 370 in epoch 1, gen_loss = 0.3944892725051253, disc_loss = 0.1390297162017692
Trained batch 371 in epoch 1, gen_loss = 0.39441999624813756, disc_loss = 0.13903361192143332
Trained batch 372 in epoch 1, gen_loss = 0.3944581655970208, disc_loss = 0.13897199001682586
Trained batch 373 in epoch 1, gen_loss = 0.3945532598916222, disc_loss = 0.13865511937385655
Trained batch 374 in epoch 1, gen_loss = 0.39442548179626463, disc_loss = 0.13833589886377254
Trained batch 375 in epoch 1, gen_loss = 0.3944371657327135, disc_loss = 0.13835768761024117
Trained batch 376 in epoch 1, gen_loss = 0.39464742111274353, disc_loss = 0.13821968243306684
Trained batch 377 in epoch 1, gen_loss = 0.39464653728815613, disc_loss = 0.13794377675555922
Trained batch 378 in epoch 1, gen_loss = 0.39447689245118317, disc_loss = 0.13781925812511064
Trained batch 379 in epoch 1, gen_loss = 0.3946670983182757, disc_loss = 0.13759478645056095
Trained batch 380 in epoch 1, gen_loss = 0.3946481930615082, disc_loss = 0.1373406653109146
Trained batch 381 in epoch 1, gen_loss = 0.39467580866127117, disc_loss = 0.13706400921002654
Trained batch 382 in epoch 1, gen_loss = 0.39453479390854, disc_loss = 0.13678803278118684
Trained batch 383 in epoch 1, gen_loss = 0.39453159730571014, disc_loss = 0.13652257308664653
Trained batch 384 in epoch 1, gen_loss = 0.39453767220695296, disc_loss = 0.1362011712213809
Trained batch 385 in epoch 1, gen_loss = 0.3943809756497645, disc_loss = 0.13630335439488755
Trained batch 386 in epoch 1, gen_loss = 0.3946315341987659, disc_loss = 0.13604584652256674
Trained batch 387 in epoch 1, gen_loss = 0.3946723153757066, disc_loss = 0.13576764947753975
Trained batch 388 in epoch 1, gen_loss = 0.3945167957970293, disc_loss = 0.135479383833783
Trained batch 389 in epoch 1, gen_loss = 0.3943806074368648, disc_loss = 0.1354516288337226
Trained batch 390 in epoch 1, gen_loss = 0.39437666977457986, disc_loss = 0.13562450688713423
Trained batch 391 in epoch 1, gen_loss = 0.3943856666434784, disc_loss = 0.13535987826453863
Trained batch 392 in epoch 1, gen_loss = 0.3942145166809626, disc_loss = 0.13543180906410512
Trained batch 393 in epoch 1, gen_loss = 0.39418860059704275, disc_loss = 0.13527215462471098
Trained batch 394 in epoch 1, gen_loss = 0.39423372881321966, disc_loss = 0.13500052161656226
Trained batch 395 in epoch 1, gen_loss = 0.3940436113813911, disc_loss = 0.13478388429638186
Trained batch 396 in epoch 1, gen_loss = 0.39413219990598164, disc_loss = 0.13454737792246663
Trained batch 397 in epoch 1, gen_loss = 0.3940551956394809, disc_loss = 0.13435940699296156
Trained batch 398 in epoch 1, gen_loss = 0.394038702909809, disc_loss = 0.13412347426848079
Trained batch 399 in epoch 1, gen_loss = 0.394142846763134, disc_loss = 0.13384329768596218
Trained batch 400 in epoch 1, gen_loss = 0.394119343629799, disc_loss = 0.1336659073081806
Trained batch 401 in epoch 1, gen_loss = 0.3938735038486879, disc_loss = 0.13346187241922192
Trained batch 402 in epoch 1, gen_loss = 0.3939811965963681, disc_loss = 0.1332320483013174
Trained batch 403 in epoch 1, gen_loss = 0.39419285156349143, disc_loss = 0.13299071132943108
Trained batch 404 in epoch 1, gen_loss = 0.39431588730694334, disc_loss = 0.13270320673185734
Trained batch 405 in epoch 1, gen_loss = 0.3941585583052612, disc_loss = 0.13251184477365296
Trained batch 406 in epoch 1, gen_loss = 0.39405871733693587, disc_loss = 0.13233720379165334
Trained batch 407 in epoch 1, gen_loss = 0.3940785588587032, disc_loss = 0.13216461093101067
Trained batch 408 in epoch 1, gen_loss = 0.39423567785319025, disc_loss = 0.13199998290576315
Trained batch 409 in epoch 1, gen_loss = 0.3942566722631454, disc_loss = 0.13189326437281035
Trained batch 410 in epoch 1, gen_loss = 0.39442446073766463, disc_loss = 0.13177027424385004
Trained batch 411 in epoch 1, gen_loss = 0.3946116292505588, disc_loss = 0.13149375106587788
Trained batch 412 in epoch 1, gen_loss = 0.3944670937540456, disc_loss = 0.131288894988849
Trained batch 413 in epoch 1, gen_loss = 0.3945560771342061, disc_loss = 0.13100540860227627
Trained batch 414 in epoch 1, gen_loss = 0.3946455166282424, disc_loss = 0.1308712627424533
Trained batch 415 in epoch 1, gen_loss = 0.3946719557190171, disc_loss = 0.13061200998401126
Trained batch 416 in epoch 1, gen_loss = 0.39478910426727587, disc_loss = 0.130489062089071
Trained batch 417 in epoch 1, gen_loss = 0.3949333088534871, disc_loss = 0.1303477971123879
Trained batch 418 in epoch 1, gen_loss = 0.3950154474071785, disc_loss = 0.13009837363582097
Trained batch 419 in epoch 1, gen_loss = 0.3953560379289445, disc_loss = 0.12993915650017915
Trained batch 420 in epoch 1, gen_loss = 0.39544739264490486, disc_loss = 0.1296864121736441
Trained batch 421 in epoch 1, gen_loss = 0.3955505301743322, disc_loss = 0.12940144178488455
Trained batch 422 in epoch 1, gen_loss = 0.3956951010734477, disc_loss = 0.12911950324576163
Trained batch 423 in epoch 1, gen_loss = 0.39575490067308805, disc_loss = 0.1288770965963848
Trained batch 424 in epoch 1, gen_loss = 0.39592759454951565, disc_loss = 0.12864873658865691
Trained batch 425 in epoch 1, gen_loss = 0.3959304746327826, disc_loss = 0.1283763129014889
Trained batch 426 in epoch 1, gen_loss = 0.39599450927149216, disc_loss = 0.12810792881053212
Trained batch 427 in epoch 1, gen_loss = 0.39607007439448455, disc_loss = 0.12785902571707755
Trained batch 428 in epoch 1, gen_loss = 0.3963373771636358, disc_loss = 0.12759924225187871
Trained batch 429 in epoch 1, gen_loss = 0.3965747969095097, disc_loss = 0.1273284294057724
Trained batch 430 in epoch 1, gen_loss = 0.3967215012231725, disc_loss = 0.1270498456930409
Trained batch 431 in epoch 1, gen_loss = 0.39692702799759527, disc_loss = 0.12677825001689294
Trained batch 432 in epoch 1, gen_loss = 0.39696581018163757, disc_loss = 0.1265102969547067
Trained batch 433 in epoch 1, gen_loss = 0.39710739488425895, disc_loss = 0.1262337737384119
Trained batch 434 in epoch 1, gen_loss = 0.39715726142642144, disc_loss = 0.12597632223483304
Trained batch 435 in epoch 1, gen_loss = 0.397319309550141, disc_loss = 0.12573944802349007
Trained batch 436 in epoch 1, gen_loss = 0.3973354807707483, disc_loss = 0.12547441535188178
Trained batch 437 in epoch 1, gen_loss = 0.39747090522012757, disc_loss = 0.12523640254958954
Trained batch 438 in epoch 1, gen_loss = 0.39756329795494166, disc_loss = 0.12496916091935137
Trained batch 439 in epoch 1, gen_loss = 0.39765727465802975, disc_loss = 0.12473563761979511
Trained batch 440 in epoch 1, gen_loss = 0.3976807983554139, disc_loss = 0.12450969114988333
Trained batch 441 in epoch 1, gen_loss = 0.39783355964524714, disc_loss = 0.12427373464025422
Trained batch 442 in epoch 1, gen_loss = 0.397935545000481, disc_loss = 0.12402047415875722
Trained batch 443 in epoch 1, gen_loss = 0.39804906270525475, disc_loss = 0.12377309750215998
Trained batch 444 in epoch 1, gen_loss = 0.3980370265714238, disc_loss = 0.1235177877735807
Trained batch 445 in epoch 1, gen_loss = 0.39817619804844195, disc_loss = 0.12326683871961729
Trained batch 446 in epoch 1, gen_loss = 0.3980876812732193, disc_loss = 0.12304806994624286
Trained batch 447 in epoch 1, gen_loss = 0.3981407935331975, disc_loss = 0.12283923730033816
Trained batch 448 in epoch 1, gen_loss = 0.39811528817582503, disc_loss = 0.12264664323776463
Trained batch 449 in epoch 1, gen_loss = 0.39842381212446426, disc_loss = 0.12241313701599009
Trained batch 450 in epoch 1, gen_loss = 0.398581729297363, disc_loss = 0.12217877915401648
Trained batch 451 in epoch 1, gen_loss = 0.398740011506376, disc_loss = 0.12193022997312215
Trained batch 452 in epoch 1, gen_loss = 0.399038684289187, disc_loss = 0.12168673121742493
Trained batch 453 in epoch 1, gen_loss = 0.39919016881136116, disc_loss = 0.12144469349472763
Trained batch 454 in epoch 1, gen_loss = 0.3991571993618221, disc_loss = 0.12121432938070578
Trained batch 455 in epoch 1, gen_loss = 0.399259040099487, disc_loss = 0.12096185342453648
Trained batch 456 in epoch 1, gen_loss = 0.39932512976147677, disc_loss = 0.12071302726546902
Trained batch 457 in epoch 1, gen_loss = 0.3994075977385825, disc_loss = 0.1204919183492563
Trained batch 458 in epoch 1, gen_loss = 0.399554616095973, disc_loss = 0.12043202016908423
Trained batch 459 in epoch 1, gen_loss = 0.399365092749181, disc_loss = 0.12071416808251778
Trained batch 460 in epoch 1, gen_loss = 0.3993932608668561, disc_loss = 0.12054917921964685
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4672129452228546, disc_loss = 0.042424846440553665
Trained batch 1 in epoch 2, gen_loss = 0.4554404765367508, disc_loss = 0.03604608029127121
Trained batch 2 in epoch 2, gen_loss = 0.4637739559014638, disc_loss = 0.034608119477828346
Trained batch 3 in epoch 2, gen_loss = 0.44017884135246277, disc_loss = 0.03703330550342798
Trained batch 4 in epoch 2, gen_loss = 0.43473186492919924, disc_loss = 0.03382057435810566
Trained batch 5 in epoch 2, gen_loss = 0.43517496685187024, disc_loss = 0.0336703530823191
Trained batch 6 in epoch 2, gen_loss = 0.4289284220763615, disc_loss = 0.03181547538510391
Trained batch 7 in epoch 2, gen_loss = 0.43075018748641014, disc_loss = 0.02880497509613633
Trained batch 8 in epoch 2, gen_loss = 0.43310654163360596, disc_loss = 0.026342247871475086
Trained batch 9 in epoch 2, gen_loss = 0.43692336678504945, disc_loss = 0.024852806190028786
Trained batch 10 in epoch 2, gen_loss = 0.4355647997422652, disc_loss = 0.025935065890239042
Trained batch 11 in epoch 2, gen_loss = 0.4370519866545995, disc_loss = 0.0315409885176147
Trained batch 12 in epoch 2, gen_loss = 0.4356833054469182, disc_loss = 0.03414223962821639
Trained batch 13 in epoch 2, gen_loss = 0.437577486038208, disc_loss = 0.034249162999913096
Trained batch 14 in epoch 2, gen_loss = 0.4306150774161021, disc_loss = 0.04833987842624386
Trained batch 15 in epoch 2, gen_loss = 0.43368186615407467, disc_loss = 0.050450747745344415
Trained batch 16 in epoch 2, gen_loss = 0.4317312117885141, disc_loss = 0.05296484854839304
Trained batch 17 in epoch 2, gen_loss = 0.42424384421772426, disc_loss = 0.061014285440453224
Trained batch 18 in epoch 2, gen_loss = 0.4221569001674652, disc_loss = 0.05897607294058329
Trained batch 19 in epoch 2, gen_loss = 0.4238219797611237, disc_loss = 0.05734531090129167
Trained batch 20 in epoch 2, gen_loss = 0.42203944779577707, disc_loss = 0.056863031505296625
Trained batch 21 in epoch 2, gen_loss = 0.42330269380049274, disc_loss = 0.05585319119166921
Trained batch 22 in epoch 2, gen_loss = 0.4252595020377118, disc_loss = 0.05380257844681973
Trained batch 23 in epoch 2, gen_loss = 0.42343039189775783, disc_loss = 0.051890594438494496
Trained batch 24 in epoch 2, gen_loss = 0.4256745183467865, disc_loss = 0.05110816286876798
Trained batch 25 in epoch 2, gen_loss = 0.42723155938662016, disc_loss = 0.04957286399216033
Trained batch 26 in epoch 2, gen_loss = 0.4283194232870031, disc_loss = 0.04809220216271502
Trained batch 27 in epoch 2, gen_loss = 0.42751422843762804, disc_loss = 0.047725657250599136
Trained batch 28 in epoch 2, gen_loss = 0.42936527626267795, disc_loss = 0.04811269017578713
Trained batch 29 in epoch 2, gen_loss = 0.4292192151149114, disc_loss = 0.04797145412303507
Trained batch 30 in epoch 2, gen_loss = 0.43125711910186276, disc_loss = 0.047170232605910106
Trained batch 31 in epoch 2, gen_loss = 0.43092519603669643, disc_loss = 0.04642968274129089
Trained batch 32 in epoch 2, gen_loss = 0.4322714733354973, disc_loss = 0.045977196670278456
Trained batch 33 in epoch 2, gen_loss = 0.429686221129754, disc_loss = 0.04520379509502912
Trained batch 34 in epoch 2, gen_loss = 0.43043203524180823, disc_loss = 0.04694431444097843
Trained batch 35 in epoch 2, gen_loss = 0.4296220979756779, disc_loss = 0.05060416645008243
Trained batch 36 in epoch 2, gen_loss = 0.42920012570716237, disc_loss = 0.05010087887529988
Trained batch 37 in epoch 2, gen_loss = 0.427428275346756, disc_loss = 0.05005939519277921
Trained batch 38 in epoch 2, gen_loss = 0.42613956790703994, disc_loss = 0.052315577279585294
Trained batch 39 in epoch 2, gen_loss = 0.42657468393445014, disc_loss = 0.05155723033240065
Trained batch 40 in epoch 2, gen_loss = 0.4272395125249537, disc_loss = 0.05155760861887801
Trained batch 41 in epoch 2, gen_loss = 0.42678775106157574, disc_loss = 0.05104177528327065
Trained batch 42 in epoch 2, gen_loss = 0.4264872933543006, disc_loss = 0.05048122411853699
Trained batch 43 in epoch 2, gen_loss = 0.42573939941146155, disc_loss = 0.04960415871094235
Trained batch 44 in epoch 2, gen_loss = 0.4255197551515367, disc_loss = 0.048916508660962185
Trained batch 45 in epoch 2, gen_loss = 0.4245526149221089, disc_loss = 0.04938265801731335
Trained batch 46 in epoch 2, gen_loss = 0.4252384514250654, disc_loss = 0.04865046906621849
Trained batch 47 in epoch 2, gen_loss = 0.42531054094433784, disc_loss = 0.04869816893672881
Trained batch 48 in epoch 2, gen_loss = 0.426244035059092, disc_loss = 0.04807473300024867
Trained batch 49 in epoch 2, gen_loss = 0.42702989220619203, disc_loss = 0.047742675160989165
Trained batch 50 in epoch 2, gen_loss = 0.42771708614685955, disc_loss = 0.04704510237035506
Trained batch 51 in epoch 2, gen_loss = 0.4268176486858955, disc_loss = 0.046513523682593726
Trained batch 52 in epoch 2, gen_loss = 0.42717438036540767, disc_loss = 0.04744921743272329
Trained batch 53 in epoch 2, gen_loss = 0.42643786249337373, disc_loss = 0.04895704356022179
Trained batch 54 in epoch 2, gen_loss = 0.4266818387941881, disc_loss = 0.04915340955115177
Trained batch 55 in epoch 2, gen_loss = 0.4269334636628628, disc_loss = 0.04853066902640941
Trained batch 56 in epoch 2, gen_loss = 0.42657211579774557, disc_loss = 0.04786265923298503
Trained batch 57 in epoch 2, gen_loss = 0.42637961075223724, disc_loss = 0.047298978251437175
Trained batch 58 in epoch 2, gen_loss = 0.42573566861071827, disc_loss = 0.0470359124069623
Trained batch 59 in epoch 2, gen_loss = 0.42523076087236406, disc_loss = 0.047191098464342454
Trained batch 60 in epoch 2, gen_loss = 0.4251228888503841, disc_loss = 0.04764818681831487
Trained batch 61 in epoch 2, gen_loss = 0.42564286051257966, disc_loss = 0.0486272259900767
Trained batch 62 in epoch 2, gen_loss = 0.42698680029975045, disc_loss = 0.06085527547088171
Trained batch 63 in epoch 2, gen_loss = 0.4256611322052777, disc_loss = 0.06279424636886688
Trained batch 64 in epoch 2, gen_loss = 0.42497079693354095, disc_loss = 0.0674000062693197
Trained batch 65 in epoch 2, gen_loss = 0.4245950150670427, disc_loss = 0.0672055406171377
Trained batch 66 in epoch 2, gen_loss = 0.42421101233852443, disc_loss = 0.06787786433306425
Trained batch 67 in epoch 2, gen_loss = 0.4228976474088781, disc_loss = 0.06825471637250088
Trained batch 68 in epoch 2, gen_loss = 0.42222400247186853, disc_loss = 0.0692872008835168
Trained batch 69 in epoch 2, gen_loss = 0.4220051220485142, disc_loss = 0.06934877091885677
Trained batch 70 in epoch 2, gen_loss = 0.4217452902189443, disc_loss = 0.06979705603845732
Trained batch 71 in epoch 2, gen_loss = 0.42048678091830677, disc_loss = 0.07065056037390605
Trained batch 72 in epoch 2, gen_loss = 0.4208295773969938, disc_loss = 0.0724801151783601
Trained batch 73 in epoch 2, gen_loss = 0.42035138647298553, disc_loss = 0.07302363710855511
Trained batch 74 in epoch 2, gen_loss = 0.41978379368782043, disc_loss = 0.0733069286805888
Trained batch 75 in epoch 2, gen_loss = 0.4196348637342453, disc_loss = 0.07329388620258358
Trained batch 76 in epoch 2, gen_loss = 0.419773919241769, disc_loss = 0.0731326228963187
Trained batch 77 in epoch 2, gen_loss = 0.4182253220142462, disc_loss = 0.07331398803478059
Trained batch 78 in epoch 2, gen_loss = 0.4177836519253405, disc_loss = 0.0741290112992725
Trained batch 79 in epoch 2, gen_loss = 0.4170967057347298, disc_loss = 0.08049552837037481
Trained batch 80 in epoch 2, gen_loss = 0.4168195864300669, disc_loss = 0.08036959397227124
Trained batch 81 in epoch 2, gen_loss = 0.41697487453135046, disc_loss = 0.08488775067962706
Trained batch 82 in epoch 2, gen_loss = 0.41682740507355653, disc_loss = 0.08667525959324586
Trained batch 83 in epoch 2, gen_loss = 0.4155929308562052, disc_loss = 0.08855678784727518
Trained batch 84 in epoch 2, gen_loss = 0.4146925814011518, disc_loss = 0.08954363873447566
Trained batch 85 in epoch 2, gen_loss = 0.4147632707690084, disc_loss = 0.0903963506016014
Trained batch 86 in epoch 2, gen_loss = 0.41415463850415984, disc_loss = 0.0910956541493792
Trained batch 87 in epoch 2, gen_loss = 0.41387794505466113, disc_loss = 0.09175222033147955
Trained batch 88 in epoch 2, gen_loss = 0.4144438254029563, disc_loss = 0.09185317062950704
Trained batch 89 in epoch 2, gen_loss = 0.4138413541846805, disc_loss = 0.09219993042966558
Trained batch 90 in epoch 2, gen_loss = 0.4134332897898915, disc_loss = 0.09172957976461275
Trained batch 91 in epoch 2, gen_loss = 0.4138050872994506, disc_loss = 0.09235412939755328
Trained batch 92 in epoch 2, gen_loss = 0.41332542063087546, disc_loss = 0.09435905360426473
Trained batch 93 in epoch 2, gen_loss = 0.4130104773856224, disc_loss = 0.09484822402628972
Trained batch 94 in epoch 2, gen_loss = 0.41378468965229237, disc_loss = 0.09430185976487242
Trained batch 95 in epoch 2, gen_loss = 0.41348464973270893, disc_loss = 0.09360195784150467
Trained batch 96 in epoch 2, gen_loss = 0.4130845478515035, disc_loss = 0.09325546689197114
Trained batch 97 in epoch 2, gen_loss = 0.41383642171110424, disc_loss = 0.09270821133989612
Trained batch 98 in epoch 2, gen_loss = 0.413274481742069, disc_loss = 0.09250357418292851
Trained batch 99 in epoch 2, gen_loss = 0.4138764908909798, disc_loss = 0.09282299446407706
Trained batch 100 in epoch 2, gen_loss = 0.41381055293696944, disc_loss = 0.09248945783215141
Trained batch 101 in epoch 2, gen_loss = 0.414075474820885, disc_loss = 0.09231725110964593
Trained batch 102 in epoch 2, gen_loss = 0.41293100795699555, disc_loss = 0.09347549611160043
Trained batch 103 in epoch 2, gen_loss = 0.41359896699969584, disc_loss = 0.09681045244752358
Trained batch 104 in epoch 2, gen_loss = 0.41304074412300473, disc_loss = 0.09779238227666134
Trained batch 105 in epoch 2, gen_loss = 0.4124062741702458, disc_loss = 0.1000583746321148
Trained batch 106 in epoch 2, gen_loss = 0.4124643290154288, disc_loss = 0.10072275253326118
Trained batch 107 in epoch 2, gen_loss = 0.4118756221400367, disc_loss = 0.10053410679878046
Trained batch 108 in epoch 2, gen_loss = 0.4119351115248619, disc_loss = 0.1008631417040773
Trained batch 109 in epoch 2, gen_loss = 0.4125017220323736, disc_loss = 0.10127827981063588
Trained batch 110 in epoch 2, gen_loss = 0.41230136317175786, disc_loss = 0.1012356208326916
Trained batch 111 in epoch 2, gen_loss = 0.4121897023703371, disc_loss = 0.100935085830445
Trained batch 112 in epoch 2, gen_loss = 0.41258181170024705, disc_loss = 0.10067013765281413
Trained batch 113 in epoch 2, gen_loss = 0.41254817655212, disc_loss = 0.10115090027663923
Trained batch 114 in epoch 2, gen_loss = 0.4127850180086882, disc_loss = 0.10279937012768958
Trained batch 115 in epoch 2, gen_loss = 0.4121579160464221, disc_loss = 0.10258642765934226
Trained batch 116 in epoch 2, gen_loss = 0.41193552608163947, disc_loss = 0.10237722820403357
Trained batch 117 in epoch 2, gen_loss = 0.41196308726981534, disc_loss = 0.10193221112002887
Trained batch 118 in epoch 2, gen_loss = 0.41163611787707866, disc_loss = 0.1015159316994876
Trained batch 119 in epoch 2, gen_loss = 0.41252309158444406, disc_loss = 0.10088218540962164
Trained batch 120 in epoch 2, gen_loss = 0.4132125183077883, disc_loss = 0.10016071534338446
Trained batch 121 in epoch 2, gen_loss = 0.41388521160258623, disc_loss = 0.09945229035191482
Trained batch 122 in epoch 2, gen_loss = 0.4144949404204764, disc_loss = 0.098914929222679
Trained batch 123 in epoch 2, gen_loss = 0.4140242256464497, disc_loss = 0.0982195763105166
Trained batch 124 in epoch 2, gen_loss = 0.4139892272949219, disc_loss = 0.09764427619054913
Trained batch 125 in epoch 2, gen_loss = 0.41494594443412053, disc_loss = 0.09705330199739408
Trained batch 126 in epoch 2, gen_loss = 0.4153943801020074, disc_loss = 0.09639658632607559
Trained batch 127 in epoch 2, gen_loss = 0.41543434699997306, disc_loss = 0.0957398087666661
Trained batch 128 in epoch 2, gen_loss = 0.4151402062685915, disc_loss = 0.09515474666299861
Trained batch 129 in epoch 2, gen_loss = 0.4155465992597433, disc_loss = 0.09463180508822776
Trained batch 130 in epoch 2, gen_loss = 0.41568770777178177, disc_loss = 0.0943400046702844
Trained batch 131 in epoch 2, gen_loss = 0.4152479356888569, disc_loss = 0.09383431921190949
Trained batch 132 in epoch 2, gen_loss = 0.4155099656348838, disc_loss = 0.09322106556378697
Trained batch 133 in epoch 2, gen_loss = 0.41596522749359927, disc_loss = 0.09258111711216173
Trained batch 134 in epoch 2, gen_loss = 0.415948635118979, disc_loss = 0.09208714117951415
Trained batch 135 in epoch 2, gen_loss = 0.41573823374860425, disc_loss = 0.09154954962500864
Trained batch 136 in epoch 2, gen_loss = 0.4154784424896658, disc_loss = 0.09146510041828682
Trained batch 137 in epoch 2, gen_loss = 0.41595595923886786, disc_loss = 0.09088925057279783
Trained batch 138 in epoch 2, gen_loss = 0.4157031328558064, disc_loss = 0.0903742022296454
Trained batch 139 in epoch 2, gen_loss = 0.41489940328257424, disc_loss = 0.09030656388495117
Trained batch 140 in epoch 2, gen_loss = 0.4150648772293794, disc_loss = 0.09075898481268727
Trained batch 141 in epoch 2, gen_loss = 0.4156493309517981, disc_loss = 0.09059689760299951
Trained batch 142 in epoch 2, gen_loss = 0.4155573061296156, disc_loss = 0.09041584756915698
Trained batch 143 in epoch 2, gen_loss = 0.41533201684554416, disc_loss = 0.09057831919118245
Trained batch 144 in epoch 2, gen_loss = 0.4151746451854706, disc_loss = 0.0902021343819797
Trained batch 145 in epoch 2, gen_loss = 0.4152692242027962, disc_loss = 0.09002525823458724
Trained batch 146 in epoch 2, gen_loss = 0.41500495303244817, disc_loss = 0.09203412565941206
Trained batch 147 in epoch 2, gen_loss = 0.41496413160820267, disc_loss = 0.09212911692510888
Trained batch 148 in epoch 2, gen_loss = 0.4145731075898113, disc_loss = 0.0917046108570625
Trained batch 149 in epoch 2, gen_loss = 0.4140733999013901, disc_loss = 0.09162462616649766
Trained batch 150 in epoch 2, gen_loss = 0.41369173937285975, disc_loss = 0.09224251568601127
Trained batch 151 in epoch 2, gen_loss = 0.41424983151649175, disc_loss = 0.09204694804870278
Trained batch 152 in epoch 2, gen_loss = 0.41376319040659987, disc_loss = 0.09248550937151889
Trained batch 153 in epoch 2, gen_loss = 0.4135793308158974, disc_loss = 0.09298480359849508
Trained batch 154 in epoch 2, gen_loss = 0.41342777532915914, disc_loss = 0.0925294247816407
Trained batch 155 in epoch 2, gen_loss = 0.4140297294809268, disc_loss = 0.09398500320131485
Trained batch 156 in epoch 2, gen_loss = 0.41358389501359055, disc_loss = 0.09590884364227865
Trained batch 157 in epoch 2, gen_loss = 0.41289885417570044, disc_loss = 0.09608592616123017
Trained batch 158 in epoch 2, gen_loss = 0.4134797905601046, disc_loss = 0.09714105158001653
Trained batch 159 in epoch 2, gen_loss = 0.4130807423964143, disc_loss = 0.09724553608975839
Trained batch 160 in epoch 2, gen_loss = 0.41240300765689114, disc_loss = 0.09717617299326736
Trained batch 161 in epoch 2, gen_loss = 0.41248261744593395, disc_loss = 0.09694741190020224
Trained batch 162 in epoch 2, gen_loss = 0.41201496965314716, disc_loss = 0.09795024243406265
Trained batch 163 in epoch 2, gen_loss = 0.4115309938788414, disc_loss = 0.09838547804903966
Trained batch 164 in epoch 2, gen_loss = 0.41153152910145846, disc_loss = 0.09818017710508271
Trained batch 165 in epoch 2, gen_loss = 0.41167430059019344, disc_loss = 0.09776552833605513
Trained batch 166 in epoch 2, gen_loss = 0.4115511898152129, disc_loss = 0.09738598451364094
Trained batch 167 in epoch 2, gen_loss = 0.4117964282631874, disc_loss = 0.0972182975965552
Trained batch 168 in epoch 2, gen_loss = 0.4118903522660746, disc_loss = 0.0970857987185863
Trained batch 169 in epoch 2, gen_loss = 0.4121687678729787, disc_loss = 0.09656413639895618
Trained batch 170 in epoch 2, gen_loss = 0.41209895324985885, disc_loss = 0.09617799991872489
Trained batch 171 in epoch 2, gen_loss = 0.4114207710291064, disc_loss = 0.0960831948052442
Trained batch 172 in epoch 2, gen_loss = 0.41146714770035936, disc_loss = 0.09595492965342596
Trained batch 173 in epoch 2, gen_loss = 0.4114054922742405, disc_loss = 0.0958577392852983
Trained batch 174 in epoch 2, gen_loss = 0.41132246579442705, disc_loss = 0.09571690798604063
Trained batch 175 in epoch 2, gen_loss = 0.41090441393581306, disc_loss = 0.09547985663415272
Trained batch 176 in epoch 2, gen_loss = 0.4105661327892778, disc_loss = 0.0950355178487124
Trained batch 177 in epoch 2, gen_loss = 0.41073313188017085, disc_loss = 0.09469765066587774
Trained batch 178 in epoch 2, gen_loss = 0.4114123423006282, disc_loss = 0.09425171698552853
Trained batch 179 in epoch 2, gen_loss = 0.41160649326112536, disc_loss = 0.0937675206689164
Trained batch 180 in epoch 2, gen_loss = 0.41182133028520407, disc_loss = 0.09340634125732503
Trained batch 181 in epoch 2, gen_loss = 0.41109175652593044, disc_loss = 0.09320734550531667
Trained batch 182 in epoch 2, gen_loss = 0.4114862271671087, disc_loss = 0.09378149391716865
Trained batch 183 in epoch 2, gen_loss = 0.41090885242042335, disc_loss = 0.09365780217036523
Trained batch 184 in epoch 2, gen_loss = 0.41074696585938736, disc_loss = 0.09333588038697033
Trained batch 185 in epoch 2, gen_loss = 0.41090311077974173, disc_loss = 0.09325577824136182
Trained batch 186 in epoch 2, gen_loss = 0.41084667243422035, disc_loss = 0.09302311192172016
Trained batch 187 in epoch 2, gen_loss = 0.4109697495686247, disc_loss = 0.09266815365024625
Trained batch 188 in epoch 2, gen_loss = 0.4110421790647759, disc_loss = 0.09243813159791801
Trained batch 189 in epoch 2, gen_loss = 0.41062348296767787, disc_loss = 0.09201881488736131
Trained batch 190 in epoch 2, gen_loss = 0.41004444136045365, disc_loss = 0.09171047759198471
Trained batch 191 in epoch 2, gen_loss = 0.409782689375182, disc_loss = 0.09135963923229913
Trained batch 192 in epoch 2, gen_loss = 0.4100347059378352, disc_loss = 0.0909207249784099
Trained batch 193 in epoch 2, gen_loss = 0.40989823731564984, disc_loss = 0.09065501695287596
Trained batch 194 in epoch 2, gen_loss = 0.41018123641992227, disc_loss = 0.0902488957469662
Trained batch 195 in epoch 2, gen_loss = 0.40989096158621263, disc_loss = 0.09020299599886093
Trained batch 196 in epoch 2, gen_loss = 0.41029085362623186, disc_loss = 0.0908204375194187
Trained batch 197 in epoch 2, gen_loss = 0.41044185167611247, disc_loss = 0.09071079226248342
Trained batch 198 in epoch 2, gen_loss = 0.41032441117655694, disc_loss = 0.09030720109971774
Trained batch 199 in epoch 2, gen_loss = 0.41030548691749574, disc_loss = 0.08994140792172402
Trained batch 200 in epoch 2, gen_loss = 0.4102981886756954, disc_loss = 0.08975554757580087
Trained batch 201 in epoch 2, gen_loss = 0.41047127544879913, disc_loss = 0.08969950255024994
Trained batch 202 in epoch 2, gen_loss = 0.41077351467362766, disc_loss = 0.08946755142616374
Trained batch 203 in epoch 2, gen_loss = 0.4101538294378449, disc_loss = 0.0895350972765728
Trained batch 204 in epoch 2, gen_loss = 0.4103632887689079, disc_loss = 0.09005895234735274
Trained batch 205 in epoch 2, gen_loss = 0.4101380173442433, disc_loss = 0.08985162753774559
Trained batch 206 in epoch 2, gen_loss = 0.40993969653539614, disc_loss = 0.08998019183009574
Trained batch 207 in epoch 2, gen_loss = 0.4096796979697851, disc_loss = 0.08971761060932365
Trained batch 208 in epoch 2, gen_loss = 0.40974442183115833, disc_loss = 0.08941780780687143
Trained batch 209 in epoch 2, gen_loss = 0.41005789353733973, disc_loss = 0.08937257423198648
Trained batch 210 in epoch 2, gen_loss = 0.41021557102836137, disc_loss = 0.08914480548599178
Trained batch 211 in epoch 2, gen_loss = 0.40979094409717703, disc_loss = 0.08921979767938126
Trained batch 212 in epoch 2, gen_loss = 0.4099061868280312, disc_loss = 0.0894531550218172
Trained batch 213 in epoch 2, gen_loss = 0.4094693128750703, disc_loss = 0.08941040434831074
Trained batch 214 in epoch 2, gen_loss = 0.4095333389071531, disc_loss = 0.08921616151495729
Trained batch 215 in epoch 2, gen_loss = 0.4098573905174379, disc_loss = 0.08998447868334888
Trained batch 216 in epoch 2, gen_loss = 0.4098480191373605, disc_loss = 0.08972975089373539
Trained batch 217 in epoch 2, gen_loss = 0.4101544887921132, disc_loss = 0.0902445870622514
Trained batch 218 in epoch 2, gen_loss = 0.41065722064340493, disc_loss = 0.09020932259880109
Trained batch 219 in epoch 2, gen_loss = 0.41046127541498706, disc_loss = 0.09027504422701896
Trained batch 220 in epoch 2, gen_loss = 0.4105632670594556, disc_loss = 0.09031531743587277
Trained batch 221 in epoch 2, gen_loss = 0.41090423258038256, disc_loss = 0.09032522057610992
Trained batch 222 in epoch 2, gen_loss = 0.4110955199051331, disc_loss = 0.08998508124106935
Trained batch 223 in epoch 2, gen_loss = 0.41080774632947786, disc_loss = 0.08979767292372084
Trained batch 224 in epoch 2, gen_loss = 0.4107192207707299, disc_loss = 0.0895714021474123
Trained batch 225 in epoch 2, gen_loss = 0.41113880949210274, disc_loss = 0.08931173510289034
Trained batch 226 in epoch 2, gen_loss = 0.4114641045683806, disc_loss = 0.0889847358434342
Trained batch 227 in epoch 2, gen_loss = 0.4113842846270193, disc_loss = 0.08863635801121984
Trained batch 228 in epoch 2, gen_loss = 0.41142496831031866, disc_loss = 0.08829519044054777
Trained batch 229 in epoch 2, gen_loss = 0.411315444111824, disc_loss = 0.08802908327349503
Trained batch 230 in epoch 2, gen_loss = 0.41100424644234895, disc_loss = 0.08777878154875525
Trained batch 231 in epoch 2, gen_loss = 0.41144531515651733, disc_loss = 0.08743608936041208
Trained batch 232 in epoch 2, gen_loss = 0.41164096166647557, disc_loss = 0.08711561336393904
Trained batch 233 in epoch 2, gen_loss = 0.41184764629245824, disc_loss = 0.08696676400275184
Trained batch 234 in epoch 2, gen_loss = 0.4121549210649856, disc_loss = 0.0867387948161427
Trained batch 235 in epoch 2, gen_loss = 0.4117471959631322, disc_loss = 0.0867295745657599
Trained batch 236 in epoch 2, gen_loss = 0.41177694996198017, disc_loss = 0.08656645331626074
Trained batch 237 in epoch 2, gen_loss = 0.41189391309974577, disc_loss = 0.08679519776458375
Trained batch 238 in epoch 2, gen_loss = 0.4116298627404488, disc_loss = 0.08780788871455766
Trained batch 239 in epoch 2, gen_loss = 0.41154145635664463, disc_loss = 0.08773173899001753
Trained batch 240 in epoch 2, gen_loss = 0.4110779754848401, disc_loss = 0.08778095997761765
Trained batch 241 in epoch 2, gen_loss = 0.41107335181768273, disc_loss = 0.08749301501834565
Trained batch 242 in epoch 2, gen_loss = 0.41101570507135904, disc_loss = 0.08732367534987598
Trained batch 243 in epoch 2, gen_loss = 0.41072572205887464, disc_loss = 0.08709348055350853
Trained batch 244 in epoch 2, gen_loss = 0.4106680475935644, disc_loss = 0.08696598817727395
Trained batch 245 in epoch 2, gen_loss = 0.4106615968351442, disc_loss = 0.0867577106994766
Trained batch 246 in epoch 2, gen_loss = 0.4107008641548002, disc_loss = 0.0865115797795687
Trained batch 247 in epoch 2, gen_loss = 0.4106355596694254, disc_loss = 0.08629292632347994
Trained batch 248 in epoch 2, gen_loss = 0.4106924885726837, disc_loss = 0.08614426391595698
Trained batch 249 in epoch 2, gen_loss = 0.4107693943977356, disc_loss = 0.08584724458679557
Trained batch 250 in epoch 2, gen_loss = 0.4107166569071462, disc_loss = 0.08567801178377345
Trained batch 251 in epoch 2, gen_loss = 0.4109986594745091, disc_loss = 0.08588780948729624
Trained batch 252 in epoch 2, gen_loss = 0.4109569474642456, disc_loss = 0.08606222078660614
Trained batch 253 in epoch 2, gen_loss = 0.4109791959599247, disc_loss = 0.08592144286582672
Trained batch 254 in epoch 2, gen_loss = 0.4110203035906249, disc_loss = 0.08563317633142659
Trained batch 255 in epoch 2, gen_loss = 0.4112470872933045, disc_loss = 0.08539149202988483
Trained batch 256 in epoch 2, gen_loss = 0.4110686719881421, disc_loss = 0.08511198472217131
Trained batch 257 in epoch 2, gen_loss = 0.41135257840618605, disc_loss = 0.08484950525209654
Trained batch 258 in epoch 2, gen_loss = 0.41149450625692097, disc_loss = 0.08454806374522594
Trained batch 259 in epoch 2, gen_loss = 0.4114398934520208, disc_loss = 0.0843020583395488
Trained batch 260 in epoch 2, gen_loss = 0.4113906396988251, disc_loss = 0.08409519372614978
Trained batch 261 in epoch 2, gen_loss = 0.4110758053209945, disc_loss = 0.08451363505824035
Trained batch 262 in epoch 2, gen_loss = 0.4114538921829412, disc_loss = 0.0861747436430801
Trained batch 263 in epoch 2, gen_loss = 0.411121972582557, disc_loss = 0.08688335621969379
Trained batch 264 in epoch 2, gen_loss = 0.4106572216411806, disc_loss = 0.08753018248826265
Trained batch 265 in epoch 2, gen_loss = 0.4105094640998912, disc_loss = 0.08792834671886456
Trained batch 266 in epoch 2, gen_loss = 0.4104928866531072, disc_loss = 0.08814631926056263
Trained batch 267 in epoch 2, gen_loss = 0.41024433031900603, disc_loss = 0.0881954133406337
Trained batch 268 in epoch 2, gen_loss = 0.4102285699330298, disc_loss = 0.08834402788375058
Trained batch 269 in epoch 2, gen_loss = 0.4101224897084413, disc_loss = 0.08830441183031157
Trained batch 270 in epoch 2, gen_loss = 0.4098979996799103, disc_loss = 0.08820535967339559
Trained batch 271 in epoch 2, gen_loss = 0.40974927452557225, disc_loss = 0.08839487091651843
Trained batch 272 in epoch 2, gen_loss = 0.40980786641875466, disc_loss = 0.08940501815738368
Trained batch 273 in epoch 2, gen_loss = 0.40955251422676725, disc_loss = 0.090103981530389
Trained batch 274 in epoch 2, gen_loss = 0.4095043282075362, disc_loss = 0.08998514870689674
Trained batch 275 in epoch 2, gen_loss = 0.4094396596369536, disc_loss = 0.09006338012134792
Trained batch 276 in epoch 2, gen_loss = 0.4091775761614638, disc_loss = 0.08997893396980172
Trained batch 277 in epoch 2, gen_loss = 0.40910025423379254, disc_loss = 0.08985142813486269
Trained batch 278 in epoch 2, gen_loss = 0.40911687050669, disc_loss = 0.0896543224098488
Trained batch 279 in epoch 2, gen_loss = 0.4089826951069491, disc_loss = 0.08970713232577379
Trained batch 280 in epoch 2, gen_loss = 0.40897062569326353, disc_loss = 0.09014535968745413
Trained batch 281 in epoch 2, gen_loss = 0.40887925187323954, disc_loss = 0.08986593338376875
Trained batch 282 in epoch 2, gen_loss = 0.40893949836808463, disc_loss = 0.09053993519303445
Trained batch 283 in epoch 2, gen_loss = 0.4086741858594854, disc_loss = 0.09139039692088542
Trained batch 284 in epoch 2, gen_loss = 0.40855274409578557, disc_loss = 0.09132702308135074
Trained batch 285 in epoch 2, gen_loss = 0.40858079961963467, disc_loss = 0.09147586219559808
Trained batch 286 in epoch 2, gen_loss = 0.4082571468494495, disc_loss = 0.09179143991178544
Trained batch 287 in epoch 2, gen_loss = 0.4077314735493726, disc_loss = 0.09193952774189205
Trained batch 288 in epoch 2, gen_loss = 0.40767927823594696, disc_loss = 0.09189916824258117
Trained batch 289 in epoch 2, gen_loss = 0.4075887587563745, disc_loss = 0.09175171207893511
Trained batch 290 in epoch 2, gen_loss = 0.4076652795178784, disc_loss = 0.09160526645373028
Trained batch 291 in epoch 2, gen_loss = 0.40745390043275, disc_loss = 0.09145310538348882
Trained batch 292 in epoch 2, gen_loss = 0.4076911366636843, disc_loss = 0.09118614171285169
Trained batch 293 in epoch 2, gen_loss = 0.40772041242544343, disc_loss = 0.09106980529962247
Trained batch 294 in epoch 2, gen_loss = 0.40765509524587856, disc_loss = 0.09115981918964851
Trained batch 295 in epoch 2, gen_loss = 0.4080622598931596, disc_loss = 0.09104505584990555
Trained batch 296 in epoch 2, gen_loss = 0.4081002687565004, disc_loss = 0.0907614690311228
Trained batch 297 in epoch 2, gen_loss = 0.40819339844204433, disc_loss = 0.09048475889526558
Trained batch 298 in epoch 2, gen_loss = 0.4083028878256629, disc_loss = 0.09040924945977022
Trained batch 299 in epoch 2, gen_loss = 0.4082254348198573, disc_loss = 0.0908607285656035
Trained batch 300 in epoch 2, gen_loss = 0.4081838412142275, disc_loss = 0.09141063744022798
Trained batch 301 in epoch 2, gen_loss = 0.4082325351554037, disc_loss = 0.09137063435840094
Trained batch 302 in epoch 2, gen_loss = 0.4080108920536419, disc_loss = 0.09141445119954375
Trained batch 303 in epoch 2, gen_loss = 0.40818688518514756, disc_loss = 0.0918463418983217
Trained batch 304 in epoch 2, gen_loss = 0.407932305238286, disc_loss = 0.09212072647375162
Trained batch 305 in epoch 2, gen_loss = 0.4077395314679426, disc_loss = 0.09204074846933676
Trained batch 306 in epoch 2, gen_loss = 0.40798232114664507, disc_loss = 0.09223614991657703
Trained batch 307 in epoch 2, gen_loss = 0.40793929055526656, disc_loss = 0.09228786278830527
Trained batch 308 in epoch 2, gen_loss = 0.4076346693301278, disc_loss = 0.09212145261755846
Trained batch 309 in epoch 2, gen_loss = 0.4073792731569659, disc_loss = 0.09196375933505835
Trained batch 310 in epoch 2, gen_loss = 0.4071292579174042, disc_loss = 0.09191299077135381
Trained batch 311 in epoch 2, gen_loss = 0.40722925884601396, disc_loss = 0.09167242964777426
Trained batch 312 in epoch 2, gen_loss = 0.4072723872364519, disc_loss = 0.09159519128239574
Trained batch 313 in epoch 2, gen_loss = 0.40700035252768524, disc_loss = 0.09167473744245092
Trained batch 314 in epoch 2, gen_loss = 0.40710102981991236, disc_loss = 0.09148186003523213
Trained batch 315 in epoch 2, gen_loss = 0.4071970158551313, disc_loss = 0.09146880847107194
Trained batch 316 in epoch 2, gen_loss = 0.4073199081684137, disc_loss = 0.09155306834081182
Trained batch 317 in epoch 2, gen_loss = 0.4076258584200961, disc_loss = 0.09158692760217302
Trained batch 318 in epoch 2, gen_loss = 0.40752370015580824, disc_loss = 0.09160990759053013
Trained batch 319 in epoch 2, gen_loss = 0.4074692342430353, disc_loss = 0.09149927155231126
Trained batch 320 in epoch 2, gen_loss = 0.4074239741047595, disc_loss = 0.0913049369945983
Trained batch 321 in epoch 2, gen_loss = 0.40727010054617935, disc_loss = 0.09144567695347974
Trained batch 322 in epoch 2, gen_loss = 0.40767634099482014, disc_loss = 0.09141455034238082
Trained batch 323 in epoch 2, gen_loss = 0.40754827948999994, disc_loss = 0.0911983878719678
Trained batch 324 in epoch 2, gen_loss = 0.4073321240681868, disc_loss = 0.09104753178472702
Trained batch 325 in epoch 2, gen_loss = 0.4076880279677046, disc_loss = 0.09090984268171107
Trained batch 326 in epoch 2, gen_loss = 0.40790556485135254, disc_loss = 0.09067952377146354
Trained batch 327 in epoch 2, gen_loss = 0.40786344112782946, disc_loss = 0.09049167266547135
Trained batch 328 in epoch 2, gen_loss = 0.407789551468968, disc_loss = 0.09024220624072392
Trained batch 329 in epoch 2, gen_loss = 0.40779840901042474, disc_loss = 0.09004304825017849
Trained batch 330 in epoch 2, gen_loss = 0.4080656724573982, disc_loss = 0.08981181872203901
Trained batch 331 in epoch 2, gen_loss = 0.4081877140575145, disc_loss = 0.08958453027509063
Trained batch 332 in epoch 2, gen_loss = 0.40822890203994316, disc_loss = 0.08933625434869313
Trained batch 333 in epoch 2, gen_loss = 0.40807935889966473, disc_loss = 0.08916061041140538
Trained batch 334 in epoch 2, gen_loss = 0.4084570476368292, disc_loss = 0.08902319515985785
Trained batch 335 in epoch 2, gen_loss = 0.4086673157733111, disc_loss = 0.08881058384542398
Trained batch 336 in epoch 2, gen_loss = 0.4085777096826174, disc_loss = 0.08860783535677619
Trained batch 337 in epoch 2, gen_loss = 0.40846713222342834, disc_loss = 0.08841589588352297
Trained batch 338 in epoch 2, gen_loss = 0.40841594338417053, disc_loss = 0.08824320636678674
Trained batch 339 in epoch 2, gen_loss = 0.40839231557705824, disc_loss = 0.08800511221017908
Trained batch 340 in epoch 2, gen_loss = 0.40849581360816956, disc_loss = 0.08777121550067604
Trained batch 341 in epoch 2, gen_loss = 0.40866060999401826, disc_loss = 0.08756604226992319
Trained batch 342 in epoch 2, gen_loss = 0.40860571293024556, disc_loss = 0.0873331294460195
Trained batch 343 in epoch 2, gen_loss = 0.40897084781250287, disc_loss = 0.08710338126429422
Trained batch 344 in epoch 2, gen_loss = 0.40888561105382615, disc_loss = 0.08691159766842274
Trained batch 345 in epoch 2, gen_loss = 0.4088706862547494, disc_loss = 0.08670978513923124
Trained batch 346 in epoch 2, gen_loss = 0.4089212035411373, disc_loss = 0.08648324752849143
Trained batch 347 in epoch 2, gen_loss = 0.4089204888234193, disc_loss = 0.0862618599812254
Trained batch 348 in epoch 2, gen_loss = 0.4088519475179962, disc_loss = 0.08607531369751836
Trained batch 349 in epoch 2, gen_loss = 0.40880505161625996, disc_loss = 0.08584835941238063
Trained batch 350 in epoch 2, gen_loss = 0.40874206875464175, disc_loss = 0.0856468381514067
Trained batch 351 in epoch 2, gen_loss = 0.40877695864235813, disc_loss = 0.0854553009161133
Trained batch 352 in epoch 2, gen_loss = 0.4087666069650785, disc_loss = 0.08524758664748655
Trained batch 353 in epoch 2, gen_loss = 0.4087551748011745, disc_loss = 0.08502585753419642
Trained batch 354 in epoch 2, gen_loss = 0.4086199184538613, disc_loss = 0.08487270683260031
Trained batch 355 in epoch 2, gen_loss = 0.4086862863616997, disc_loss = 0.0846549896157106
Trained batch 356 in epoch 2, gen_loss = 0.40871551157045766, disc_loss = 0.08445920125536975
Trained batch 357 in epoch 2, gen_loss = 0.40889229521405096, disc_loss = 0.08423805930755783
Trained batch 358 in epoch 2, gen_loss = 0.4088283906740066, disc_loss = 0.08410251359416374
Trained batch 359 in epoch 2, gen_loss = 0.40858730657233133, disc_loss = 0.08417848306061286
Trained batch 360 in epoch 2, gen_loss = 0.4086585386638166, disc_loss = 0.08454370179659897
Trained batch 361 in epoch 2, gen_loss = 0.40836817808243453, disc_loss = 0.08465045767589292
Trained batch 362 in epoch 2, gen_loss = 0.40823191519282737, disc_loss = 0.08453754504844957
Trained batch 363 in epoch 2, gen_loss = 0.4081870731744137, disc_loss = 0.08479613314285506
Trained batch 364 in epoch 2, gen_loss = 0.408185808299339, disc_loss = 0.0854389312626054
Trained batch 365 in epoch 2, gen_loss = 0.4082225232176442, disc_loss = 0.08537422247673766
Trained batch 366 in epoch 2, gen_loss = 0.4081418556478433, disc_loss = 0.08530055357863979
Trained batch 367 in epoch 2, gen_loss = 0.40815058933651965, disc_loss = 0.08525681035952522
Trained batch 368 in epoch 2, gen_loss = 0.408043041865677, disc_loss = 0.08529265000684273
Trained batch 369 in epoch 2, gen_loss = 0.4081726237728789, disc_loss = 0.08554105329629336
Trained batch 370 in epoch 2, gen_loss = 0.4079758034883484, disc_loss = 0.0858814882408235
Trained batch 371 in epoch 2, gen_loss = 0.4079384311873426, disc_loss = 0.08568376163145908
Trained batch 372 in epoch 2, gen_loss = 0.40797854828131425, disc_loss = 0.08577778544551605
Trained batch 373 in epoch 2, gen_loss = 0.4080191704838034, disc_loss = 0.0857552904996742
Trained batch 374 in epoch 2, gen_loss = 0.4083079044818878, disc_loss = 0.08560633181159695
Trained batch 375 in epoch 2, gen_loss = 0.40854319827036656, disc_loss = 0.08540991496448307
Trained batch 376 in epoch 2, gen_loss = 0.4084577951728507, disc_loss = 0.08529021998926681
Trained batch 377 in epoch 2, gen_loss = 0.4085422434977123, disc_loss = 0.08522045577718586
Trained batch 378 in epoch 2, gen_loss = 0.40867769238502183, disc_loss = 0.08513930359226221
Trained batch 379 in epoch 2, gen_loss = 0.4086158241096296, disc_loss = 0.08497844847090738
Trained batch 380 in epoch 2, gen_loss = 0.40857245853253865, disc_loss = 0.08492008689424302
Trained batch 381 in epoch 2, gen_loss = 0.40850525002204935, disc_loss = 0.08471941059645441
Trained batch 382 in epoch 2, gen_loss = 0.40882863357235183, disc_loss = 0.08455722660978882
Trained batch 383 in epoch 2, gen_loss = 0.40902894944883883, disc_loss = 0.08437854491664136
Trained batch 384 in epoch 2, gen_loss = 0.4088926760407237, disc_loss = 0.08428741419300824
Trained batch 385 in epoch 2, gen_loss = 0.4090442838137632, disc_loss = 0.08411493520204151
Trained batch 386 in epoch 2, gen_loss = 0.4089117621574599, disc_loss = 0.08404511848743765
Trained batch 387 in epoch 2, gen_loss = 0.4093386879594056, disc_loss = 0.08460697712323907
Trained batch 388 in epoch 2, gen_loss = 0.4092312430661258, disc_loss = 0.08452823095545556
Trained batch 389 in epoch 2, gen_loss = 0.40906057434204296, disc_loss = 0.08450280836878869
Trained batch 390 in epoch 2, gen_loss = 0.4090491333580993, disc_loss = 0.08451763839791994
Trained batch 391 in epoch 2, gen_loss = 0.408936578400281, disc_loss = 0.08441250374165307
Trained batch 392 in epoch 2, gen_loss = 0.4089330379441191, disc_loss = 0.08424352822853749
Trained batch 393 in epoch 2, gen_loss = 0.4089642270718734, disc_loss = 0.08413638257383733
Trained batch 394 in epoch 2, gen_loss = 0.4088712808452075, disc_loss = 0.0841268955494124
Trained batch 395 in epoch 2, gen_loss = 0.4089333764982946, disc_loss = 0.08441906098412782
Trained batch 396 in epoch 2, gen_loss = 0.40870662315065975, disc_loss = 0.08439752145761845
Trained batch 397 in epoch 2, gen_loss = 0.4084640959998471, disc_loss = 0.08449253898193526
Trained batch 398 in epoch 2, gen_loss = 0.4086351266182156, disc_loss = 0.0851510402555099
Trained batch 399 in epoch 2, gen_loss = 0.408548696488142, disc_loss = 0.08510170841240323
Trained batch 400 in epoch 2, gen_loss = 0.4084711467238733, disc_loss = 0.08504234378497834
Trained batch 401 in epoch 2, gen_loss = 0.4083736535921619, disc_loss = 0.08491277376500268
Trained batch 402 in epoch 2, gen_loss = 0.4083357292132697, disc_loss = 0.0847871704893672
Trained batch 403 in epoch 2, gen_loss = 0.4082263470581262, disc_loss = 0.08480768486290322
Trained batch 404 in epoch 2, gen_loss = 0.40800054205788505, disc_loss = 0.08542983559201713
Trained batch 405 in epoch 2, gen_loss = 0.40783755062836147, disc_loss = 0.08562340141099699
Trained batch 406 in epoch 2, gen_loss = 0.40779870719230144, disc_loss = 0.08553947234315756
Trained batch 407 in epoch 2, gen_loss = 0.40767884407849875, disc_loss = 0.08546564444630206
Trained batch 408 in epoch 2, gen_loss = 0.4077800362209236, disc_loss = 0.08531299630216434
Trained batch 409 in epoch 2, gen_loss = 0.407748370853866, disc_loss = 0.0851490516544933
Trained batch 410 in epoch 2, gen_loss = 0.40764019212293506, disc_loss = 0.08513843129137463
Trained batch 411 in epoch 2, gen_loss = 0.407774996627303, disc_loss = 0.08514331487907115
Trained batch 412 in epoch 2, gen_loss = 0.4078432555348763, disc_loss = 0.08497520952122443
Trained batch 413 in epoch 2, gen_loss = 0.4078066559229496, disc_loss = 0.08480692859671578
Trained batch 414 in epoch 2, gen_loss = 0.4076638208096286, disc_loss = 0.08465960060459483
Trained batch 415 in epoch 2, gen_loss = 0.40790617200904167, disc_loss = 0.08449777052401959
Trained batch 416 in epoch 2, gen_loss = 0.408115261821724, disc_loss = 0.08444468367608081
Trained batch 417 in epoch 2, gen_loss = 0.40809505742987945, disc_loss = 0.08436222465009247
Trained batch 418 in epoch 2, gen_loss = 0.408000493817796, disc_loss = 0.08428357091347792
Trained batch 419 in epoch 2, gen_loss = 0.4080908253079369, disc_loss = 0.08414158507228076
Trained batch 420 in epoch 2, gen_loss = 0.40840135320065424, disc_loss = 0.08398921002087464
Trained batch 421 in epoch 2, gen_loss = 0.408430671451781, disc_loss = 0.08380902195856929
Trained batch 422 in epoch 2, gen_loss = 0.4084650681796649, disc_loss = 0.08363370375980757
Trained batch 423 in epoch 2, gen_loss = 0.40849031789122886, disc_loss = 0.08345691514100423
Trained batch 424 in epoch 2, gen_loss = 0.40856407950906193, disc_loss = 0.08329746321391533
Trained batch 425 in epoch 2, gen_loss = 0.4087293440467315, disc_loss = 0.0831637794879908
Trained batch 426 in epoch 2, gen_loss = 0.4088408533806544, disc_loss = 0.08298739379673184
Trained batch 427 in epoch 2, gen_loss = 0.40898631130144975, disc_loss = 0.08284179315897941
Trained batch 428 in epoch 2, gen_loss = 0.40896313840692694, disc_loss = 0.08267284310281728
Trained batch 429 in epoch 2, gen_loss = 0.4091742476751638, disc_loss = 0.08250526678965016
Trained batch 430 in epoch 2, gen_loss = 0.4092388734601766, disc_loss = 0.08232818496912683
Trained batch 431 in epoch 2, gen_loss = 0.4092380661793329, disc_loss = 0.08214802461508144
Trained batch 432 in epoch 2, gen_loss = 0.4092363310465912, disc_loss = 0.0819671259349853
Trained batch 433 in epoch 2, gen_loss = 0.4091683062402883, disc_loss = 0.08186582889845638
Trained batch 434 in epoch 2, gen_loss = 0.409214798061327, disc_loss = 0.0817377172346259
Trained batch 435 in epoch 2, gen_loss = 0.4090470924563364, disc_loss = 0.08169376453888867
Trained batch 436 in epoch 2, gen_loss = 0.4091033357231786, disc_loss = 0.08172030078814081
Trained batch 437 in epoch 2, gen_loss = 0.4092267886416553, disc_loss = 0.08155302254942386
Trained batch 438 in epoch 2, gen_loss = 0.40932256010507395, disc_loss = 0.08138828727380629
Trained batch 439 in epoch 2, gen_loss = 0.40929012169892137, disc_loss = 0.08121652448952028
Trained batch 440 in epoch 2, gen_loss = 0.40913552532390673, disc_loss = 0.08107071114670224
Trained batch 441 in epoch 2, gen_loss = 0.4092891960661875, disc_loss = 0.08090795994087278
Trained batch 442 in epoch 2, gen_loss = 0.40937176541873077, disc_loss = 0.08076043347628371
Trained batch 443 in epoch 2, gen_loss = 0.4096770133521106, disc_loss = 0.08061923821318291
Trained batch 444 in epoch 2, gen_loss = 0.4097539553481541, disc_loss = 0.08048205757513642
Trained batch 445 in epoch 2, gen_loss = 0.4097994247894116, disc_loss = 0.08032637526022245
Trained batch 446 in epoch 2, gen_loss = 0.4096786627833475, disc_loss = 0.08018928635511256
Trained batch 447 in epoch 2, gen_loss = 0.4098050106050713, disc_loss = 0.08016439642960904
Trained batch 448 in epoch 2, gen_loss = 0.4098522722190101, disc_loss = 0.08006578706358383
Trained batch 449 in epoch 2, gen_loss = 0.4099136578374439, disc_loss = 0.07994160962704983
Trained batch 450 in epoch 2, gen_loss = 0.4098243207862795, disc_loss = 0.07978739357448107
Trained batch 451 in epoch 2, gen_loss = 0.4097069961439192, disc_loss = 0.07964157097070453
Trained batch 452 in epoch 2, gen_loss = 0.40955134838095825, disc_loss = 0.07947777789065544
Trained batch 453 in epoch 2, gen_loss = 0.40962720540914244, disc_loss = 0.07932459195103447
Trained batch 454 in epoch 2, gen_loss = 0.4096688945214827, disc_loss = 0.07916393542744138
Trained batch 455 in epoch 2, gen_loss = 0.40979745676904394, disc_loss = 0.07900364330577615
Trained batch 456 in epoch 2, gen_loss = 0.40972283449945096, disc_loss = 0.07889457709304744
Trained batch 457 in epoch 2, gen_loss = 0.4098599282414632, disc_loss = 0.07899208894349212
Trained batch 458 in epoch 2, gen_loss = 0.40995955597081735, disc_loss = 0.07885600031152659
Trained batch 459 in epoch 2, gen_loss = 0.40971897542476654, disc_loss = 0.07876122835618646
Trained batch 460 in epoch 2, gen_loss = 0.40965387199292214, disc_loss = 0.07866767483991682
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4363987147808075, disc_loss = 0.008392732590436935
Trained batch 1 in epoch 3, gen_loss = 0.44622138142585754, disc_loss = 0.0088272076100111
Trained batch 2 in epoch 3, gen_loss = 0.44436530272165936, disc_loss = 0.014896457393964132
Trained batch 3 in epoch 3, gen_loss = 0.44775205850601196, disc_loss = 0.015126782469451427
Trained batch 4 in epoch 3, gen_loss = 0.44319801330566405, disc_loss = 0.015225089713931083
Trained batch 5 in epoch 3, gen_loss = 0.44627636671066284, disc_loss = 0.014216283336281776
Trained batch 6 in epoch 3, gen_loss = 0.4418265606675829, disc_loss = 0.013699028507939406
Trained batch 7 in epoch 3, gen_loss = 0.4487726576626301, disc_loss = 0.0163848017109558
Trained batch 8 in epoch 3, gen_loss = 0.4487897985511356, disc_loss = 0.015548448078334332
Trained batch 9 in epoch 3, gen_loss = 0.4459425538778305, disc_loss = 0.015213471744209528
Trained batch 10 in epoch 3, gen_loss = 0.44255834546956146, disc_loss = 0.01484606558965011
Trained batch 11 in epoch 3, gen_loss = 0.44340689728657406, disc_loss = 0.014200355391949415
Trained batch 12 in epoch 3, gen_loss = 0.4410722805903508, disc_loss = 0.013595198531850027
Trained batch 13 in epoch 3, gen_loss = 0.4439861455133983, disc_loss = 0.013380487349682621
Trained batch 14 in epoch 3, gen_loss = 0.4414744436740875, disc_loss = 0.012938705148796241
Trained batch 15 in epoch 3, gen_loss = 0.43545806035399437, disc_loss = 0.01513787783915177
Trained batch 16 in epoch 3, gen_loss = 0.43612271547317505, disc_loss = 0.01552873186986236
Trained batch 17 in epoch 3, gen_loss = 0.43746653695901233, disc_loss = 0.01657199730268783
Trained batch 18 in epoch 3, gen_loss = 0.43346324092463445, disc_loss = 0.016150215934765965
Trained batch 19 in epoch 3, gen_loss = 0.43049549460411074, disc_loss = 0.016350707877427338
Trained batch 20 in epoch 3, gen_loss = 0.429673616375242, disc_loss = 0.015908545304444573
Trained batch 21 in epoch 3, gen_loss = 0.4262976036830382, disc_loss = 0.015429616884582421
Trained batch 22 in epoch 3, gen_loss = 0.4257319634375365, disc_loss = 0.015967332535301863
Trained batch 23 in epoch 3, gen_loss = 0.42411046226819354, disc_loss = 0.017383153453314055
Trained batch 24 in epoch 3, gen_loss = 0.42487144470214844, disc_loss = 0.019891497697681188
Trained batch 25 in epoch 3, gen_loss = 0.42228627090270704, disc_loss = 0.019564700259182315
Trained batch 26 in epoch 3, gen_loss = 0.4175672299332089, disc_loss = 0.02124037898869978
Trained batch 27 in epoch 3, gen_loss = 0.4189091974071094, disc_loss = 0.025410153520559624
Trained batch 28 in epoch 3, gen_loss = 0.4184982252532038, disc_loss = 0.025019393607588678
Trained batch 29 in epoch 3, gen_loss = 0.41592439313729607, disc_loss = 0.025304091426854334
Trained batch 30 in epoch 3, gen_loss = 0.41460625202425067, disc_loss = 0.026070411962967728
Trained batch 31 in epoch 3, gen_loss = 0.41455867793411016, disc_loss = 0.027826207762700506
Trained batch 32 in epoch 3, gen_loss = 0.4157522681987647, disc_loss = 0.02933448537563284
Trained batch 33 in epoch 3, gen_loss = 0.4159596614977893, disc_loss = 0.028842964223312104
Trained batch 34 in epoch 3, gen_loss = 0.4157835015228816, disc_loss = 0.028319548722356556
Trained batch 35 in epoch 3, gen_loss = 0.4161626588967111, disc_loss = 0.028207575139175687
Trained batch 36 in epoch 3, gen_loss = 0.4147009785110886, disc_loss = 0.02761704254442373
Trained batch 37 in epoch 3, gen_loss = 0.41338417247722026, disc_loss = 0.027311204405697554
Trained batch 38 in epoch 3, gen_loss = 0.41253360341756773, disc_loss = 0.026761418124899652
Trained batch 39 in epoch 3, gen_loss = 0.412819416821003, disc_loss = 0.026208742521703243
Trained batch 40 in epoch 3, gen_loss = 0.41319489188310576, disc_loss = 0.025746785229208265
Trained batch 41 in epoch 3, gen_loss = 0.41240541282154264, disc_loss = 0.025348441442474723
Trained batch 42 in epoch 3, gen_loss = 0.4118434467981028, disc_loss = 0.024968872334115034
Trained batch 43 in epoch 3, gen_loss = 0.4125382507389242, disc_loss = 0.02453366728414866
Trained batch 44 in epoch 3, gen_loss = 0.41347953081130984, disc_loss = 0.024148934914006128
Trained batch 45 in epoch 3, gen_loss = 0.4136878297380779, disc_loss = 0.023842047697500042
Trained batch 46 in epoch 3, gen_loss = 0.4132651521804485, disc_loss = 0.023420192727303887
Trained batch 47 in epoch 3, gen_loss = 0.4129550587385893, disc_loss = 0.023158154110812273
Trained batch 48 in epoch 3, gen_loss = 0.41228274970638507, disc_loss = 0.022803935516929746
Trained batch 49 in epoch 3, gen_loss = 0.41204698503017423, disc_loss = 0.02252789125777781
Trained batch 50 in epoch 3, gen_loss = 0.4117002376154357, disc_loss = 0.022410840608690884
Trained batch 51 in epoch 3, gen_loss = 0.4100137989108379, disc_loss = 0.023708197010609392
Trained batch 52 in epoch 3, gen_loss = 0.41100845415637177, disc_loss = 0.026215544787569427
Trained batch 53 in epoch 3, gen_loss = 0.4101877173891774, disc_loss = 0.02607294369523448
Trained batch 54 in epoch 3, gen_loss = 0.4100162386894226, disc_loss = 0.02671999048272317
Trained batch 55 in epoch 3, gen_loss = 0.4106797693031175, disc_loss = 0.026427180431450585
Trained batch 56 in epoch 3, gen_loss = 0.4106299532087226, disc_loss = 0.02659940097905826
Trained batch 57 in epoch 3, gen_loss = 0.4120613742491295, disc_loss = 0.026463924770660955
Trained batch 58 in epoch 3, gen_loss = 0.41151747562117497, disc_loss = 0.029023694750552966
Trained batch 59 in epoch 3, gen_loss = 0.4120537539323171, disc_loss = 0.03420903778169304
Trained batch 60 in epoch 3, gen_loss = 0.4105922613964706, disc_loss = 0.035559549889542526
Trained batch 61 in epoch 3, gen_loss = 0.41023099182113526, disc_loss = 0.035203602307686405
Trained batch 62 in epoch 3, gen_loss = 0.41123538215955097, disc_loss = 0.035238372213724584
Trained batch 63 in epoch 3, gen_loss = 0.41095572244375944, disc_loss = 0.03549741350434488
Trained batch 64 in epoch 3, gen_loss = 0.4101586236403539, disc_loss = 0.037604537856980015
Trained batch 65 in epoch 3, gen_loss = 0.41054022989489813, disc_loss = 0.038462352819007006
Trained batch 66 in epoch 3, gen_loss = 0.41035175190043094, disc_loss = 0.03831219519558015
Trained batch 67 in epoch 3, gen_loss = 0.409799803267507, disc_loss = 0.03858884228804313
Trained batch 68 in epoch 3, gen_loss = 0.40901405612627667, disc_loss = 0.03860158253920035
Trained batch 69 in epoch 3, gen_loss = 0.4107191217797143, disc_loss = 0.03895874264916139
Trained batch 70 in epoch 3, gen_loss = 0.41152872208138586, disc_loss = 0.040036979347834706
Trained batch 71 in epoch 3, gen_loss = 0.41110647718111676, disc_loss = 0.039590736378967345
Trained batch 72 in epoch 3, gen_loss = 0.41013975380218193, disc_loss = 0.04071182557955792
Trained batch 73 in epoch 3, gen_loss = 0.4107475449910035, disc_loss = 0.04039615819960631
Trained batch 74 in epoch 3, gen_loss = 0.41115771611531576, disc_loss = 0.04034243016814192
Trained batch 75 in epoch 3, gen_loss = 0.41058113974960225, disc_loss = 0.039903820161462614
Trained batch 76 in epoch 3, gen_loss = 0.4104225012389096, disc_loss = 0.040016246995852364
Trained batch 77 in epoch 3, gen_loss = 0.4107135866697018, disc_loss = 0.03993758144907844
Trained batch 78 in epoch 3, gen_loss = 0.4103714899171757, disc_loss = 0.03982564150296812
Trained batch 79 in epoch 3, gen_loss = 0.4114678479731083, disc_loss = 0.04160586729412898
Trained batch 80 in epoch 3, gen_loss = 0.41110961856665434, disc_loss = 0.04123759091498307
Trained batch 81 in epoch 3, gen_loss = 0.4098584426612389, disc_loss = 0.04222334545423708
Trained batch 82 in epoch 3, gen_loss = 0.41057305020022106, disc_loss = 0.041969424124852
Trained batch 83 in epoch 3, gen_loss = 0.4101579991124925, disc_loss = 0.043118325051008946
Trained batch 84 in epoch 3, gen_loss = 0.410002201795578, disc_loss = 0.0430661910049179
Trained batch 85 in epoch 3, gen_loss = 0.40871535484180893, disc_loss = 0.04445398186311819
Trained batch 86 in epoch 3, gen_loss = 0.40877584342298834, disc_loss = 0.04493653100925958
Trained batch 87 in epoch 3, gen_loss = 0.40937630425799976, disc_loss = 0.0453274108109657
Trained batch 88 in epoch 3, gen_loss = 0.40837123253372276, disc_loss = 0.04505533619333854
Trained batch 89 in epoch 3, gen_loss = 0.4076467666361067, disc_loss = 0.04537330521270633
Trained batch 90 in epoch 3, gen_loss = 0.4076249999004406, disc_loss = 0.04509192155571757
Trained batch 91 in epoch 3, gen_loss = 0.40824428168327914, disc_loss = 0.04514989616227862
Trained batch 92 in epoch 3, gen_loss = 0.4082350355963553, disc_loss = 0.04637050759848407
Trained batch 93 in epoch 3, gen_loss = 0.4087573708371913, disc_loss = 0.048993637616884834
Trained batch 94 in epoch 3, gen_loss = 0.40818380023303785, disc_loss = 0.04986810608717956
Trained batch 95 in epoch 3, gen_loss = 0.4074487363298734, disc_loss = 0.051260135165648535
Trained batch 96 in epoch 3, gen_loss = 0.4070947913779426, disc_loss = 0.05422709040228546
Trained batch 97 in epoch 3, gen_loss = 0.40735980199307814, disc_loss = 0.05437204381451011
Trained batch 98 in epoch 3, gen_loss = 0.40631485045558274, disc_loss = 0.05502483996590882
Trained batch 99 in epoch 3, gen_loss = 0.40674376010894775, disc_loss = 0.054752717493101954
Trained batch 100 in epoch 3, gen_loss = 0.4076365093783577, disc_loss = 0.05446460493609752
Trained batch 101 in epoch 3, gen_loss = 0.40819455391051723, disc_loss = 0.054007904722775314
Trained batch 102 in epoch 3, gen_loss = 0.408020610080182, disc_loss = 0.05355931835212899
Trained batch 103 in epoch 3, gen_loss = 0.40813953744677395, disc_loss = 0.05313327920605214
Trained batch 104 in epoch 3, gen_loss = 0.4084552756377629, disc_loss = 0.05269874319700258
Trained batch 105 in epoch 3, gen_loss = 0.40869899178450964, disc_loss = 0.05225288510797018
Trained batch 106 in epoch 3, gen_loss = 0.40860485584936407, disc_loss = 0.05181738321242906
Trained batch 107 in epoch 3, gen_loss = 0.40794329069278856, disc_loss = 0.05146448957061188
Trained batch 108 in epoch 3, gen_loss = 0.40757945918161936, disc_loss = 0.05103239664431969
Trained batch 109 in epoch 3, gen_loss = 0.40730771774595437, disc_loss = 0.050594782346690244
Trained batch 110 in epoch 3, gen_loss = 0.4070183648182465, disc_loss = 0.05017033898531719
Trained batch 111 in epoch 3, gen_loss = 0.4068879791136299, disc_loss = 0.04976785639883019
Trained batch 112 in epoch 3, gen_loss = 0.40672802608625025, disc_loss = 0.049367732924730644
Trained batch 113 in epoch 3, gen_loss = 0.40627630839222356, disc_loss = 0.04896802056515426
Trained batch 114 in epoch 3, gen_loss = 0.4058887523153554, disc_loss = 0.04859001015758385
Trained batch 115 in epoch 3, gen_loss = 0.4059883952140808, disc_loss = 0.04821872101406213
Trained batch 116 in epoch 3, gen_loss = 0.4051382974681691, disc_loss = 0.047857188583853155
Trained batch 117 in epoch 3, gen_loss = 0.4045398237846665, disc_loss = 0.04751360795650063
Trained batch 118 in epoch 3, gen_loss = 0.4038963736105366, disc_loss = 0.04726599794303795
Trained batch 119 in epoch 3, gen_loss = 0.4044290107985338, disc_loss = 0.04708849972812459
Trained batch 120 in epoch 3, gen_loss = 0.40439751300929994, disc_loss = 0.04677204224704341
Trained batch 121 in epoch 3, gen_loss = 0.40436106724817245, disc_loss = 0.046471900753218866
Trained batch 122 in epoch 3, gen_loss = 0.40463103220714786, disc_loss = 0.046201550867408514
Trained batch 123 in epoch 3, gen_loss = 0.40373621328223136, disc_loss = 0.0461524001270112
Trained batch 124 in epoch 3, gen_loss = 0.4043927128314972, disc_loss = 0.045856794346123934
Trained batch 125 in epoch 3, gen_loss = 0.4042106370131175, disc_loss = 0.04596109929612823
Trained batch 126 in epoch 3, gen_loss = 0.4047792422489857, disc_loss = 0.0458370525221245
Trained batch 127 in epoch 3, gen_loss = 0.4051915230229497, disc_loss = 0.04554912129606237
Trained batch 128 in epoch 3, gen_loss = 0.4053231778070908, disc_loss = 0.04525653412565589
Trained batch 129 in epoch 3, gen_loss = 0.4054173231124878, disc_loss = 0.044983105493996006
Trained batch 130 in epoch 3, gen_loss = 0.40535980212779443, disc_loss = 0.04467724871871467
Trained batch 131 in epoch 3, gen_loss = 0.40597550412922195, disc_loss = 0.0444263236025687
Trained batch 132 in epoch 3, gen_loss = 0.40642782239089337, disc_loss = 0.04417772204230042
Trained batch 133 in epoch 3, gen_loss = 0.40670892307117806, disc_loss = 0.04388767688660257
Trained batch 134 in epoch 3, gen_loss = 0.40748308300971986, disc_loss = 0.04361748693993798
Trained batch 135 in epoch 3, gen_loss = 0.4073512245188741, disc_loss = 0.043365602532182544
Trained batch 136 in epoch 3, gen_loss = 0.4073045971619822, disc_loss = 0.043104801408565825
Trained batch 137 in epoch 3, gen_loss = 0.4073155619527983, disc_loss = 0.04282141760315584
Trained batch 138 in epoch 3, gen_loss = 0.40703083199562784, disc_loss = 0.042547333188247764
Trained batch 139 in epoch 3, gen_loss = 0.4066647853170122, disc_loss = 0.04226738211166646
Trained batch 140 in epoch 3, gen_loss = 0.4066098364109689, disc_loss = 0.04200031103051089
Trained batch 141 in epoch 3, gen_loss = 0.4067825496616498, disc_loss = 0.04173055623861318
Trained batch 142 in epoch 3, gen_loss = 0.40699761043061744, disc_loss = 0.04146457761135343
Trained batch 143 in epoch 3, gen_loss = 0.4070445971770419, disc_loss = 0.04122129816419652
Trained batch 144 in epoch 3, gen_loss = 0.4068665052282399, disc_loss = 0.04109565675065949
Trained batch 145 in epoch 3, gen_loss = 0.4064112766964795, disc_loss = 0.0408668509040232
Trained batch 146 in epoch 3, gen_loss = 0.4063455746287391, disc_loss = 0.04065191885456443
Trained batch 147 in epoch 3, gen_loss = 0.40615887658016103, disc_loss = 0.04041493071142484
Trained batch 148 in epoch 3, gen_loss = 0.40629866679242793, disc_loss = 0.04016802331976493
Trained batch 149 in epoch 3, gen_loss = 0.4062089083592097, disc_loss = 0.039972177702002225
Trained batch 150 in epoch 3, gen_loss = 0.4062706133387736, disc_loss = 0.03972420418813874
Trained batch 151 in epoch 3, gen_loss = 0.4061964909104924, disc_loss = 0.039497892496384385
Trained batch 152 in epoch 3, gen_loss = 0.406029576180028, disc_loss = 0.0392582402184143
Trained batch 153 in epoch 3, gen_loss = 0.4061053395271301, disc_loss = 0.03904000626326623
Trained batch 154 in epoch 3, gen_loss = 0.40612328187111885, disc_loss = 0.03880773254279648
Trained batch 155 in epoch 3, gen_loss = 0.4058974878146098, disc_loss = 0.03857954158089482
Trained batch 156 in epoch 3, gen_loss = 0.405936767341225, disc_loss = 0.038356861685384894
Trained batch 157 in epoch 3, gen_loss = 0.4059707437512241, disc_loss = 0.03813099941456855
Trained batch 158 in epoch 3, gen_loss = 0.4062112455473006, disc_loss = 0.037913739255119885
Trained batch 159 in epoch 3, gen_loss = 0.40655016582459214, disc_loss = 0.0376942345770658
Trained batch 160 in epoch 3, gen_loss = 0.4064627350857539, disc_loss = 0.037473703461253775
Trained batch 161 in epoch 3, gen_loss = 0.40641710309334744, disc_loss = 0.037266273438114166
Trained batch 162 in epoch 3, gen_loss = 0.40654154770944745, disc_loss = 0.0370577442476903
Trained batch 163 in epoch 3, gen_loss = 0.406357941649309, disc_loss = 0.036851204539899055
Trained batch 164 in epoch 3, gen_loss = 0.4064674487619689, disc_loss = 0.03665696621844263
Trained batch 165 in epoch 3, gen_loss = 0.4060947774763567, disc_loss = 0.03645859077202538
Trained batch 166 in epoch 3, gen_loss = 0.40592774302659634, disc_loss = 0.036255680699414476
Trained batch 167 in epoch 3, gen_loss = 0.40603271268662955, disc_loss = 0.036125420747945704
Trained batch 168 in epoch 3, gen_loss = 0.4061118909240474, disc_loss = 0.035939397364744594
Trained batch 169 in epoch 3, gen_loss = 0.40621383260278143, disc_loss = 0.03576148695531575
Trained batch 170 in epoch 3, gen_loss = 0.4060150278590576, disc_loss = 0.035624777470655435
Trained batch 171 in epoch 3, gen_loss = 0.4061080300530722, disc_loss = 0.03543988638016027
Trained batch 172 in epoch 3, gen_loss = 0.40587709594324145, disc_loss = 0.035256463751692134
Trained batch 173 in epoch 3, gen_loss = 0.40615136339061564, disc_loss = 0.035123941154037226
Trained batch 174 in epoch 3, gen_loss = 0.4063081797531673, disc_loss = 0.03493883454906089
Trained batch 175 in epoch 3, gen_loss = 0.40582028217613697, disc_loss = 0.03476266483300027
Trained batch 176 in epoch 3, gen_loss = 0.40570218330722746, disc_loss = 0.0345862085462711
Trained batch 177 in epoch 3, gen_loss = 0.4052246286627952, disc_loss = 0.03443173993002163
Trained batch 178 in epoch 3, gen_loss = 0.40487670931736186, disc_loss = 0.03426078574825599
Trained batch 179 in epoch 3, gen_loss = 0.4048776924610138, disc_loss = 0.034105116775673294
Trained batch 180 in epoch 3, gen_loss = 0.4048832809727495, disc_loss = 0.034186363554667705
Trained batch 181 in epoch 3, gen_loss = 0.4055580116890289, disc_loss = 0.034741123304139455
Trained batch 182 in epoch 3, gen_loss = 0.4058336239369189, disc_loss = 0.03460595467194019
Trained batch 183 in epoch 3, gen_loss = 0.40597069312048994, disc_loss = 0.034525414812378585
Trained batch 184 in epoch 3, gen_loss = 0.4058616150069881, disc_loss = 0.03439706982289617
Trained batch 185 in epoch 3, gen_loss = 0.40615020756439496, disc_loss = 0.03425177548741622
Trained batch 186 in epoch 3, gen_loss = 0.4063279767406178, disc_loss = 0.034091946190810775
Trained batch 187 in epoch 3, gen_loss = 0.40650302013184164, disc_loss = 0.0339329220389234
Trained batch 188 in epoch 3, gen_loss = 0.4071199032995436, disc_loss = 0.033801032385478415
Trained batch 189 in epoch 3, gen_loss = 0.4070429016100733, disc_loss = 0.03366938682125979
Trained batch 190 in epoch 3, gen_loss = 0.4073207434559368, disc_loss = 0.0335232573927073
Trained batch 191 in epoch 3, gen_loss = 0.4074851272938152, disc_loss = 0.03336828284955118
Trained batch 192 in epoch 3, gen_loss = 0.40723530832349947, disc_loss = 0.03322753052039004
Trained batch 193 in epoch 3, gen_loss = 0.4074044276758568, disc_loss = 0.03309338426063817
Trained batch 194 in epoch 3, gen_loss = 0.4073726493578691, disc_loss = 0.03305894726266464
Trained batch 195 in epoch 3, gen_loss = 0.40769652748594476, disc_loss = 0.0329341980752212
Trained batch 196 in epoch 3, gen_loss = 0.40791821812615175, disc_loss = 0.03280506247824748
Trained batch 197 in epoch 3, gen_loss = 0.40802112718423206, disc_loss = 0.032673188144190596
Trained batch 198 in epoch 3, gen_loss = 0.40774717717314485, disc_loss = 0.03253493844367676
Trained batch 199 in epoch 3, gen_loss = 0.4078757031261921, disc_loss = 0.03242427863879129
Trained batch 200 in epoch 3, gen_loss = 0.4075379761593852, disc_loss = 0.03228662164177542
Trained batch 201 in epoch 3, gen_loss = 0.4074275480343564, disc_loss = 0.03215359581293225
Trained batch 202 in epoch 3, gen_loss = 0.4071541199543206, disc_loss = 0.0320149212869187
Trained batch 203 in epoch 3, gen_loss = 0.4071088117711684, disc_loss = 0.031963037945531014
Trained batch 204 in epoch 3, gen_loss = 0.40721510648727416, disc_loss = 0.03195169971256358
Trained batch 205 in epoch 3, gen_loss = 0.40721086767113324, disc_loss = 0.031824868393935335
Trained batch 206 in epoch 3, gen_loss = 0.40690212117301094, disc_loss = 0.031699548315724746
Trained batch 207 in epoch 3, gen_loss = 0.4072662043170287, disc_loss = 0.031619640096323565
Trained batch 208 in epoch 3, gen_loss = 0.4073153928136141, disc_loss = 0.03151665923617887
Trained batch 209 in epoch 3, gen_loss = 0.4071296141261146, disc_loss = 0.03140336334084471
Trained batch 210 in epoch 3, gen_loss = 0.4072686377294821, disc_loss = 0.031277164472576
Trained batch 211 in epoch 3, gen_loss = 0.4073908761987146, disc_loss = 0.03116161674963978
Trained batch 212 in epoch 3, gen_loss = 0.4076710730931009, disc_loss = 0.031033373667373205
Trained batch 213 in epoch 3, gen_loss = 0.40764772641324554, disc_loss = 0.030913058962133304
Trained batch 214 in epoch 3, gen_loss = 0.4080209174821543, disc_loss = 0.03079319812010887
Trained batch 215 in epoch 3, gen_loss = 0.40802172640407525, disc_loss = 0.030670655378209496
Trained batch 216 in epoch 3, gen_loss = 0.4081428013913642, disc_loss = 0.0306111044692485
Trained batch 217 in epoch 3, gen_loss = 0.4082262134606685, disc_loss = 0.03050330442743837
Trained batch 218 in epoch 3, gen_loss = 0.40866677333775175, disc_loss = 0.03039495710317539
Trained batch 219 in epoch 3, gen_loss = 0.408818561786955, disc_loss = 0.030302128166129642
Trained batch 220 in epoch 3, gen_loss = 0.40915748638804683, disc_loss = 0.030180986342757805
Trained batch 221 in epoch 3, gen_loss = 0.4093698081937996, disc_loss = 0.03010366468581262
Trained batch 222 in epoch 3, gen_loss = 0.4097485729397145, disc_loss = 0.03003349536486939
Trained batch 223 in epoch 3, gen_loss = 0.4097776661760041, disc_loss = 0.03023680080410226
Trained batch 224 in epoch 3, gen_loss = 0.40976345631811356, disc_loss = 0.030354563747015263
Trained batch 225 in epoch 3, gen_loss = 0.40963955447737094, disc_loss = 0.030335285218712767
Trained batch 226 in epoch 3, gen_loss = 0.41008319649927416, disc_loss = 0.030373474660981857
Trained batch 227 in epoch 3, gen_loss = 0.41042302287461463, disc_loss = 0.030287975927390028
Trained batch 228 in epoch 3, gen_loss = 0.4107423999944629, disc_loss = 0.030173382237878948
Trained batch 229 in epoch 3, gen_loss = 0.410660852038342, disc_loss = 0.030077348058314426
Trained batch 230 in epoch 3, gen_loss = 0.41063935880537156, disc_loss = 0.02997756517165667
Trained batch 231 in epoch 3, gen_loss = 0.41061870484002705, disc_loss = 0.02987268794697292
Trained batch 232 in epoch 3, gen_loss = 0.4108401102057854, disc_loss = 0.02976398294303934
Trained batch 233 in epoch 3, gen_loss = 0.41093471977445817, disc_loss = 0.029657781311175507
Trained batch 234 in epoch 3, gen_loss = 0.4111828476824659, disc_loss = 0.029560111227266966
Trained batch 235 in epoch 3, gen_loss = 0.41145378944732375, disc_loss = 0.02946281171466966
Trained batch 236 in epoch 3, gen_loss = 0.4116272962797543, disc_loss = 0.029402551162626422
Trained batch 237 in epoch 3, gen_loss = 0.41196042762584045, disc_loss = 0.029365970514432974
Trained batch 238 in epoch 3, gen_loss = 0.4120685490604225, disc_loss = 0.029310323730516383
Trained batch 239 in epoch 3, gen_loss = 0.4120450758685668, disc_loss = 0.02920841749291867
Trained batch 240 in epoch 3, gen_loss = 0.41227913978683506, disc_loss = 0.02922285016610662
Trained batch 241 in epoch 3, gen_loss = 0.41196703405912255, disc_loss = 0.029208511006364152
Trained batch 242 in epoch 3, gen_loss = 0.4120815512820036, disc_loss = 0.029118641308382338
Trained batch 243 in epoch 3, gen_loss = 0.4125039168312901, disc_loss = 0.02911486061572357
Trained batch 244 in epoch 3, gen_loss = 0.412625686611448, disc_loss = 0.029076225099590968
Trained batch 245 in epoch 3, gen_loss = 0.412805184964242, disc_loss = 0.02901606426983163
Trained batch 246 in epoch 3, gen_loss = 0.4126187982829476, disc_loss = 0.02892858995056828
Trained batch 247 in epoch 3, gen_loss = 0.41275025303325347, disc_loss = 0.028861315605501012
Trained batch 248 in epoch 3, gen_loss = 0.41306032665283327, disc_loss = 0.028772042155355573
Trained batch 249 in epoch 3, gen_loss = 0.41267412090301514, disc_loss = 0.028823268380016087
Trained batch 250 in epoch 3, gen_loss = 0.4122777912483747, disc_loss = 0.028876631617160194
Trained batch 251 in epoch 3, gen_loss = 0.4122106580743714, disc_loss = 0.028785675667995024
Trained batch 252 in epoch 3, gen_loss = 0.412183325399052, disc_loss = 0.028709613309488465
Trained batch 253 in epoch 3, gen_loss = 0.4123769394290729, disc_loss = 0.02863135630279545
Trained batch 254 in epoch 3, gen_loss = 0.41250257924491285, disc_loss = 0.028563249896408297
Trained batch 255 in epoch 3, gen_loss = 0.4125954492483288, disc_loss = 0.028470103072322672
Trained batch 256 in epoch 3, gen_loss = 0.4126226406848848, disc_loss = 0.028377891661316622
Trained batch 257 in epoch 3, gen_loss = 0.4124947437482287, disc_loss = 0.028290106765131735
Trained batch 258 in epoch 3, gen_loss = 0.41244066601554397, disc_loss = 0.028205739472665498
Trained batch 259 in epoch 3, gen_loss = 0.4122189439260043, disc_loss = 0.028115406236611306
Trained batch 260 in epoch 3, gen_loss = 0.41229551322615465, disc_loss = 0.028074996850999265
Trained batch 261 in epoch 3, gen_loss = 0.41243090736501997, disc_loss = 0.027984861915447672
Trained batch 262 in epoch 3, gen_loss = 0.41251066995664243, disc_loss = 0.027904459415180716
Trained batch 263 in epoch 3, gen_loss = 0.4125520612931613, disc_loss = 0.027837957546580583
Trained batch 264 in epoch 3, gen_loss = 0.41266148517716605, disc_loss = 0.02776015906085102
Trained batch 265 in epoch 3, gen_loss = 0.4125248567950457, disc_loss = 0.02772188122048134
Trained batch 266 in epoch 3, gen_loss = 0.41253185205245285, disc_loss = 0.027646596768473305
Trained batch 267 in epoch 3, gen_loss = 0.412247429143137, disc_loss = 0.02760756694635293
Trained batch 268 in epoch 3, gen_loss = 0.41239359033152073, disc_loss = 0.027625715482952316
Trained batch 269 in epoch 3, gen_loss = 0.41260301492832324, disc_loss = 0.027542758432941305
Trained batch 270 in epoch 3, gen_loss = 0.41271683562725675, disc_loss = 0.02749524283741783
Trained batch 271 in epoch 3, gen_loss = 0.41274819829884696, disc_loss = 0.027425699637901476
Trained batch 272 in epoch 3, gen_loss = 0.41277655424215853, disc_loss = 0.027356043949231995
Trained batch 273 in epoch 3, gen_loss = 0.4127151279771415, disc_loss = 0.027268050156914404
Trained batch 274 in epoch 3, gen_loss = 0.41271994764154607, disc_loss = 0.027179040941833096
Trained batch 275 in epoch 3, gen_loss = 0.4125608783485233, disc_loss = 0.02713088433349343
Trained batch 276 in epoch 3, gen_loss = 0.41257360018117334, disc_loss = 0.027179298914854655
Trained batch 277 in epoch 3, gen_loss = 0.4126785381449212, disc_loss = 0.02709881012518924
Trained batch 278 in epoch 3, gen_loss = 0.41272955726979027, disc_loss = 0.027061330367340354
Trained batch 279 in epoch 3, gen_loss = 0.4127822127725397, disc_loss = 0.027109712274977937
Trained batch 280 in epoch 3, gen_loss = 0.4125696697481162, disc_loss = 0.027310705580500045
Trained batch 281 in epoch 3, gen_loss = 0.41283337592233155, disc_loss = 0.027268693405071417
Trained batch 282 in epoch 3, gen_loss = 0.41302009121689276, disc_loss = 0.027433589152669264
Trained batch 283 in epoch 3, gen_loss = 0.4129452652914423, disc_loss = 0.027454669770135373
Trained batch 284 in epoch 3, gen_loss = 0.4130889708535713, disc_loss = 0.02746784464096683
Trained batch 285 in epoch 3, gen_loss = 0.4132257151853788, disc_loss = 0.027392982040414703
Trained batch 286 in epoch 3, gen_loss = 0.4133345871021523, disc_loss = 0.027377423772731155
Trained batch 287 in epoch 3, gen_loss = 0.41317949671712184, disc_loss = 0.027326273509566415
Trained batch 288 in epoch 3, gen_loss = 0.4131000024430892, disc_loss = 0.0273201078423025
Trained batch 289 in epoch 3, gen_loss = 0.413116445931895, disc_loss = 0.02734526459143722
Trained batch 290 in epoch 3, gen_loss = 0.4133024981751065, disc_loss = 0.027280848950973338
Trained batch 291 in epoch 3, gen_loss = 0.41349937623902544, disc_loss = 0.027212851501408047
Trained batch 292 in epoch 3, gen_loss = 0.4137554009009547, disc_loss = 0.027143504329934818
Trained batch 293 in epoch 3, gen_loss = 0.41376182913374737, disc_loss = 0.027081976884652918
Trained batch 294 in epoch 3, gen_loss = 0.4137789863651082, disc_loss = 0.027031656050802034
Trained batch 295 in epoch 3, gen_loss = 0.41390089791368795, disc_loss = 0.026957123610348365
Trained batch 296 in epoch 3, gen_loss = 0.4139081829726094, disc_loss = 0.026885791870636822
Trained batch 297 in epoch 3, gen_loss = 0.41392677852371396, disc_loss = 0.02684577341400862
Trained batch 298 in epoch 3, gen_loss = 0.4139230682897727, disc_loss = 0.026835653775941617
Trained batch 299 in epoch 3, gen_loss = 0.41389424572388334, disc_loss = 0.026763771374244242
Trained batch 300 in epoch 3, gen_loss = 0.413668817756976, disc_loss = 0.02669163544792249
Trained batch 301 in epoch 3, gen_loss = 0.4138156772646683, disc_loss = 0.02662757500336931
Trained batch 302 in epoch 3, gen_loss = 0.4138550576400442, disc_loss = 0.026581964116672626
Trained batch 303 in epoch 3, gen_loss = 0.41367088130822305, disc_loss = 0.026551736845775803
Trained batch 304 in epoch 3, gen_loss = 0.4139955939816647, disc_loss = 0.026669791129371914
Trained batch 305 in epoch 3, gen_loss = 0.41403264489049224, disc_loss = 0.026653317444702136
Trained batch 306 in epoch 3, gen_loss = 0.4142671868156533, disc_loss = 0.02658477121075245
Trained batch 307 in epoch 3, gen_loss = 0.41469224668168403, disc_loss = 0.026545901704948492
Trained batch 308 in epoch 3, gen_loss = 0.41463717712167786, disc_loss = 0.02653447929302586
Trained batch 309 in epoch 3, gen_loss = 0.4147232093157307, disc_loss = 0.026484078896652545
Trained batch 310 in epoch 3, gen_loss = 0.41479530968850065, disc_loss = 0.026409458982910947
Trained batch 311 in epoch 3, gen_loss = 0.41477916609400356, disc_loss = 0.026349973900673482
Trained batch 312 in epoch 3, gen_loss = 0.4146277442717324, disc_loss = 0.026281862043606018
Trained batch 313 in epoch 3, gen_loss = 0.4144167722600281, disc_loss = 0.026212770242694836
Trained batch 314 in epoch 3, gen_loss = 0.4144282518871247, disc_loss = 0.026147012788033674
Trained batch 315 in epoch 3, gen_loss = 0.41436174577927287, disc_loss = 0.026077091770505982
Trained batch 316 in epoch 3, gen_loss = 0.414485667782251, disc_loss = 0.026005426193337757
Trained batch 317 in epoch 3, gen_loss = 0.4145720055643118, disc_loss = 0.02593471375938341
Trained batch 318 in epoch 3, gen_loss = 0.4145578212312023, disc_loss = 0.025861509833309718
Trained batch 319 in epoch 3, gen_loss = 0.41450157957151534, disc_loss = 0.02579074349923758
Trained batch 320 in epoch 3, gen_loss = 0.4142780448788794, disc_loss = 0.025721876423608663
Trained batch 321 in epoch 3, gen_loss = 0.41446382362650047, disc_loss = 0.025652428121473756
Trained batch 322 in epoch 3, gen_loss = 0.4144374687605229, disc_loss = 0.02559604430167529
Trained batch 323 in epoch 3, gen_loss = 0.4143250902861725, disc_loss = 0.025526172914082344
Trained batch 324 in epoch 3, gen_loss = 0.4144414460659027, disc_loss = 0.02546619408835585
Trained batch 325 in epoch 3, gen_loss = 0.41427452039499224, disc_loss = 0.025399847323234918
Trained batch 326 in epoch 3, gen_loss = 0.4143424191788431, disc_loss = 0.025332726268325605
Trained batch 327 in epoch 3, gen_loss = 0.4143957157687443, disc_loss = 0.025275131807486504
Trained batch 328 in epoch 3, gen_loss = 0.4144223408496126, disc_loss = 0.02521073263305548
Trained batch 329 in epoch 3, gen_loss = 0.41442035481785283, disc_loss = 0.02514170754743232
Trained batch 330 in epoch 3, gen_loss = 0.41420759112093025, disc_loss = 0.02507395669395875
Trained batch 331 in epoch 3, gen_loss = 0.41429886266768695, disc_loss = 0.025011918510321574
Trained batch 332 in epoch 3, gen_loss = 0.4141378681043963, disc_loss = 0.02494590416377237
Trained batch 333 in epoch 3, gen_loss = 0.41382201158714865, disc_loss = 0.024878557087591444
Trained batch 334 in epoch 3, gen_loss = 0.41370141043591857, disc_loss = 0.024819978120139065
Trained batch 335 in epoch 3, gen_loss = 0.4137159852931897, disc_loss = 0.024754068429631713
Trained batch 336 in epoch 3, gen_loss = 0.41372038808703776, disc_loss = 0.024688258947450834
Trained batch 337 in epoch 3, gen_loss = 0.41374821202642115, disc_loss = 0.02462379442053963
Trained batch 338 in epoch 3, gen_loss = 0.41373394187924434, disc_loss = 0.02455969457926674
Trained batch 339 in epoch 3, gen_loss = 0.41379358356489854, disc_loss = 0.024501658256357427
Trained batch 340 in epoch 3, gen_loss = 0.4136738375135181, disc_loss = 0.024442859286923083
Trained batch 341 in epoch 3, gen_loss = 0.41367124291191326, disc_loss = 0.02438717639708227
Trained batch 342 in epoch 3, gen_loss = 0.41357542074804055, disc_loss = 0.024327956064693824
Trained batch 343 in epoch 3, gen_loss = 0.41361466968475386, disc_loss = 0.024268215254144094
Trained batch 344 in epoch 3, gen_loss = 0.41348576683929, disc_loss = 0.024207993177022193
Trained batch 345 in epoch 3, gen_loss = 0.41349482837784496, disc_loss = 0.024146325600931065
Trained batch 346 in epoch 3, gen_loss = 0.4136169229014119, disc_loss = 0.024089586717057812
Trained batch 347 in epoch 3, gen_loss = 0.41367994291686466, disc_loss = 0.02403283130977003
Trained batch 348 in epoch 3, gen_loss = 0.4135607814037356, disc_loss = 0.023982172074025886
Trained batch 349 in epoch 3, gen_loss = 0.4135379824468068, disc_loss = 0.023923291701025196
Trained batch 350 in epoch 3, gen_loss = 0.4135224167947416, disc_loss = 0.023863556621028403
Trained batch 351 in epoch 3, gen_loss = 0.41348813313313504, disc_loss = 0.023802962780543814
Trained batch 352 in epoch 3, gen_loss = 0.413292138924342, disc_loss = 0.023869771828938267
Trained batch 353 in epoch 3, gen_loss = 0.4132249863807764, disc_loss = 0.023854198336132965
Trained batch 354 in epoch 3, gen_loss = 0.4134745458482017, disc_loss = 0.023815545113757254
Trained batch 355 in epoch 3, gen_loss = 0.4134160416682115, disc_loss = 0.023809049879540845
Trained batch 356 in epoch 3, gen_loss = 0.4138768225991759, disc_loss = 0.023906087752624677
Trained batch 357 in epoch 3, gen_loss = 0.4139900276614301, disc_loss = 0.023860553304883313
Trained batch 358 in epoch 3, gen_loss = 0.414054969476126, disc_loss = 0.02390995818257726
Trained batch 359 in epoch 3, gen_loss = 0.41423900715178913, disc_loss = 0.023927378540004915
Trained batch 360 in epoch 3, gen_loss = 0.4144285282434849, disc_loss = 0.023883555831975843
Trained batch 361 in epoch 3, gen_loss = 0.4145377155660924, disc_loss = 0.02388333301741671
Trained batch 362 in epoch 3, gen_loss = 0.41461157577096924, disc_loss = 0.023841293994978727
Trained batch 363 in epoch 3, gen_loss = 0.41480973321985415, disc_loss = 0.023786679476340927
Trained batch 364 in epoch 3, gen_loss = 0.41495914932799666, disc_loss = 0.02373304780228191
Trained batch 365 in epoch 3, gen_loss = 0.41508426871456083, disc_loss = 0.023685295936967058
Trained batch 366 in epoch 3, gen_loss = 0.4150910764039375, disc_loss = 0.023649199500969262
Trained batch 367 in epoch 3, gen_loss = 0.4152623928435471, disc_loss = 0.023650518550826033
Trained batch 368 in epoch 3, gen_loss = 0.4153439323430462, disc_loss = 0.023685923500521597
Trained batch 369 in epoch 3, gen_loss = 0.41545182369850775, disc_loss = 0.02379094586090965
Trained batch 370 in epoch 3, gen_loss = 0.41552227952409626, disc_loss = 0.023846356457380473
Trained batch 371 in epoch 3, gen_loss = 0.4156064444812395, disc_loss = 0.023814804026461456
Trained batch 372 in epoch 3, gen_loss = 0.41557034482585203, disc_loss = 0.023767189271922846
Trained batch 373 in epoch 3, gen_loss = 0.4156453822226448, disc_loss = 0.02372149054401798
Trained batch 374 in epoch 3, gen_loss = 0.415719658613205, disc_loss = 0.023670573729400835
Trained batch 375 in epoch 3, gen_loss = 0.41566595807671547, disc_loss = 0.023624797150408453
Trained batch 376 in epoch 3, gen_loss = 0.4158481962642872, disc_loss = 0.023577857171543516
Trained batch 377 in epoch 3, gen_loss = 0.41570950855338384, disc_loss = 0.023523839845361494
Trained batch 378 in epoch 3, gen_loss = 0.41550392714528106, disc_loss = 0.02348007020383267
Trained batch 379 in epoch 3, gen_loss = 0.41547073125839235, disc_loss = 0.023430551438420814
Trained batch 380 in epoch 3, gen_loss = 0.4155577082490045, disc_loss = 0.023379235316967478
Trained batch 381 in epoch 3, gen_loss = 0.41567634553185306, disc_loss = 0.02332518041055864
Trained batch 382 in epoch 3, gen_loss = 0.41573345637819475, disc_loss = 0.02327042590406074
Trained batch 383 in epoch 3, gen_loss = 0.41568910928132635, disc_loss = 0.023219319899605278
Trained batch 384 in epoch 3, gen_loss = 0.41567822160658896, disc_loss = 0.023166461014370254
Trained batch 385 in epoch 3, gen_loss = 0.4157202778084908, disc_loss = 0.023111089685849767
Trained batch 386 in epoch 3, gen_loss = 0.41590832924658017, disc_loss = 0.023058816837507858
Trained batch 387 in epoch 3, gen_loss = 0.4159194590504636, disc_loss = 0.02300392747640648
Trained batch 388 in epoch 3, gen_loss = 0.4158221294763462, disc_loss = 0.02295392503899673
Trained batch 389 in epoch 3, gen_loss = 0.4157545869167034, disc_loss = 0.022901451013958418
Trained batch 390 in epoch 3, gen_loss = 0.41553232950322766, disc_loss = 0.022858285059904695
Trained batch 391 in epoch 3, gen_loss = 0.4153416325547257, disc_loss = 0.02280618342136185
Trained batch 392 in epoch 3, gen_loss = 0.4153035082131548, disc_loss = 0.022758714127787995
Trained batch 393 in epoch 3, gen_loss = 0.41530425839012647, disc_loss = 0.022712280863286163
Trained batch 394 in epoch 3, gen_loss = 0.415214113419569, disc_loss = 0.02266017996965424
Trained batch 395 in epoch 3, gen_loss = 0.41528803448785434, disc_loss = 0.0226098236544387
Trained batch 396 in epoch 3, gen_loss = 0.4153723001329965, disc_loss = 0.02256908822131416
Trained batch 397 in epoch 3, gen_loss = 0.4151754073012414, disc_loss = 0.022521855267485482
Trained batch 398 in epoch 3, gen_loss = 0.4150950999785784, disc_loss = 0.02247700946671622
Trained batch 399 in epoch 3, gen_loss = 0.41512743704020977, disc_loss = 0.022424845636705867
Trained batch 400 in epoch 3, gen_loss = 0.41503891713006835, disc_loss = 0.022381188667860076
Trained batch 401 in epoch 3, gen_loss = 0.4150984080424949, disc_loss = 0.02233948133160726
Trained batch 402 in epoch 3, gen_loss = 0.41496681494097554, disc_loss = 0.022287963865851756
Trained batch 403 in epoch 3, gen_loss = 0.4150730530076688, disc_loss = 0.02224259527047432
Trained batch 404 in epoch 3, gen_loss = 0.41490823648594044, disc_loss = 0.022194016111991656
Trained batch 405 in epoch 3, gen_loss = 0.41482366731601394, disc_loss = 0.02214342152230726
Trained batch 406 in epoch 3, gen_loss = 0.4148516359141769, disc_loss = 0.022094789051784875
Trained batch 407 in epoch 3, gen_loss = 0.41488273463705005, disc_loss = 0.02204679463979761
Trained batch 408 in epoch 3, gen_loss = 0.4148644664322543, disc_loss = 0.022001343285995092
Trained batch 409 in epoch 3, gen_loss = 0.41486215177105695, disc_loss = 0.02195488494201904
Trained batch 410 in epoch 3, gen_loss = 0.4147609672407164, disc_loss = 0.02190826457065197
Trained batch 411 in epoch 3, gen_loss = 0.4148453286695249, disc_loss = 0.021863326636308043
Trained batch 412 in epoch 3, gen_loss = 0.41484755775541715, disc_loss = 0.021815385211982986
Trained batch 413 in epoch 3, gen_loss = 0.41485949587706783, disc_loss = 0.021770906395893005
Trained batch 414 in epoch 3, gen_loss = 0.4148625737931355, disc_loss = 0.0217277494071231
Trained batch 415 in epoch 3, gen_loss = 0.4148546885699034, disc_loss = 0.02168210812921573
Trained batch 416 in epoch 3, gen_loss = 0.4149144474122164, disc_loss = 0.02163417695164993
Trained batch 417 in epoch 3, gen_loss = 0.41479399108715603, disc_loss = 0.021587668317336696
Trained batch 418 in epoch 3, gen_loss = 0.4147745375132504, disc_loss = 0.021539919418982967
Trained batch 419 in epoch 3, gen_loss = 0.4148319410426276, disc_loss = 0.02149266551936134
Trained batch 420 in epoch 3, gen_loss = 0.414887015723276, disc_loss = 0.021446379417588937
Trained batch 421 in epoch 3, gen_loss = 0.4149434999408315, disc_loss = 0.021399999760428966
Trained batch 422 in epoch 3, gen_loss = 0.4149257401907134, disc_loss = 0.021356027966627222
Trained batch 423 in epoch 3, gen_loss = 0.4150669455247105, disc_loss = 0.02131247970595174
Trained batch 424 in epoch 3, gen_loss = 0.4149859495723949, disc_loss = 0.021269562050207136
Trained batch 425 in epoch 3, gen_loss = 0.41500889891190146, disc_loss = 0.021226199217274033
Trained batch 426 in epoch 3, gen_loss = 0.41494269030434744, disc_loss = 0.021184992013265763
Trained batch 427 in epoch 3, gen_loss = 0.41505886851070084, disc_loss = 0.021143028593380613
Trained batch 428 in epoch 3, gen_loss = 0.4149035479361083, disc_loss = 0.021100895426948152
Trained batch 429 in epoch 3, gen_loss = 0.4147729863954145, disc_loss = 0.02105633843863426
Trained batch 430 in epoch 3, gen_loss = 0.4145377841183868, disc_loss = 0.02101323415315656
Trained batch 431 in epoch 3, gen_loss = 0.414592320099473, disc_loss = 0.020980381528648583
Trained batch 432 in epoch 3, gen_loss = 0.4146023583329577, disc_loss = 0.020942083127607373
Trained batch 433 in epoch 3, gen_loss = 0.414563802873484, disc_loss = 0.020901801113966285
Trained batch 434 in epoch 3, gen_loss = 0.41454711672903477, disc_loss = 0.020861146731794566
Trained batch 435 in epoch 3, gen_loss = 0.414633916878919, disc_loss = 0.020827251554834187
Trained batch 436 in epoch 3, gen_loss = 0.4145531810530263, disc_loss = 0.02078966753561587
Trained batch 437 in epoch 3, gen_loss = 0.4143842632231647, disc_loss = 0.02077965513424582
Trained batch 438 in epoch 3, gen_loss = 0.41417477498836563, disc_loss = 0.0208216367696745
Trained batch 439 in epoch 3, gen_loss = 0.41426080411130733, disc_loss = 0.02088296704036607
Trained batch 440 in epoch 3, gen_loss = 0.4142977393943977, disc_loss = 0.020894050097637843
Trained batch 441 in epoch 3, gen_loss = 0.41452743497369515, disc_loss = 0.020907476163001485
Trained batch 442 in epoch 3, gen_loss = 0.414373222578729, disc_loss = 0.020933399618126066
Trained batch 443 in epoch 3, gen_loss = 0.4144257043261786, disc_loss = 0.020907739978619257
Trained batch 444 in epoch 3, gen_loss = 0.41445671125744166, disc_loss = 0.02092188158899211
Trained batch 445 in epoch 3, gen_loss = 0.4144516628018409, disc_loss = 0.02088973996429934
Trained batch 446 in epoch 3, gen_loss = 0.41448149265058887, disc_loss = 0.02089168831718548
Trained batch 447 in epoch 3, gen_loss = 0.4143275883314865, disc_loss = 0.020854898679577412
Trained batch 448 in epoch 3, gen_loss = 0.4144040885109678, disc_loss = 0.020817213123436096
Trained batch 449 in epoch 3, gen_loss = 0.41444129831261106, disc_loss = 0.02077873435544057
Trained batch 450 in epoch 3, gen_loss = 0.41454909639453674, disc_loss = 0.02074973760100449
Trained batch 451 in epoch 3, gen_loss = 0.41443376533225573, disc_loss = 0.020712417745097352
Trained batch 452 in epoch 3, gen_loss = 0.41445491415249064, disc_loss = 0.020680740216611235
Trained batch 453 in epoch 3, gen_loss = 0.41447756009479975, disc_loss = 0.020645608548033934
Trained batch 454 in epoch 3, gen_loss = 0.4142379919251243, disc_loss = 0.020621404179709625
Trained batch 455 in epoch 3, gen_loss = 0.41423318489340316, disc_loss = 0.020586072672526108
Trained batch 456 in epoch 3, gen_loss = 0.4143393644879631, disc_loss = 0.020551583971176093
Trained batch 457 in epoch 3, gen_loss = 0.4143666191652873, disc_loss = 0.020513674746548114
Trained batch 458 in epoch 3, gen_loss = 0.41445117072082555, disc_loss = 0.020483018852737865
Trained batch 459 in epoch 3, gen_loss = 0.4144669738800629, disc_loss = 0.020461668274567826
Trained batch 460 in epoch 3, gen_loss = 0.41468025094257777, disc_loss = 0.020432781600827704
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.35359448194503784, disc_loss = 0.00503151398152113
Trained batch 1 in epoch 4, gen_loss = 0.3741839975118637, disc_loss = 0.007649517152458429
Trained batch 2 in epoch 4, gen_loss = 0.37682504455248517, disc_loss = 0.005955010885372758
Trained batch 3 in epoch 4, gen_loss = 0.3754030764102936, disc_loss = 0.00966531754238531
Trained batch 4 in epoch 4, gen_loss = 0.387250280380249, disc_loss = 0.013508334523066878
Trained batch 5 in epoch 4, gen_loss = 0.38671544194221497, disc_loss = 0.013223596033640206
Trained batch 6 in epoch 4, gen_loss = 0.382625366960253, disc_loss = 0.012219135616240757
Trained batch 7 in epoch 4, gen_loss = 0.38653189688920975, disc_loss = 0.013428669277345762
Trained batch 8 in epoch 4, gen_loss = 0.3917682303322686, disc_loss = 0.012889681668538187
Trained batch 9 in epoch 4, gen_loss = 0.39051204919815063, disc_loss = 0.013949512760154903
Trained batch 10 in epoch 4, gen_loss = 0.38382169062441046, disc_loss = 0.020344991639087148
Trained batch 11 in epoch 4, gen_loss = 0.3944784725705783, disc_loss = 0.0347129293368198
Trained batch 12 in epoch 4, gen_loss = 0.39314934611320496, disc_loss = 0.03717229348750642
Trained batch 13 in epoch 4, gen_loss = 0.39047438970633913, disc_loss = 0.037492496676609983
Trained batch 14 in epoch 4, gen_loss = 0.38913915356000267, disc_loss = 0.04000088825511436
Trained batch 15 in epoch 4, gen_loss = 0.3833642117679119, disc_loss = 0.05523171326785814
Trained batch 16 in epoch 4, gen_loss = 0.3854874004335964, disc_loss = 0.0650900081210934
Trained batch 17 in epoch 4, gen_loss = 0.38317634496423936, disc_loss = 0.06567350820276058
Trained batch 18 in epoch 4, gen_loss = 0.38074704220420436, disc_loss = 0.06622572129249181
Trained batch 19 in epoch 4, gen_loss = 0.37893903255462646, disc_loss = 0.06439185788622126
Trained batch 20 in epoch 4, gen_loss = 0.3801941389129275, disc_loss = 0.06651926620508589
Trained batch 21 in epoch 4, gen_loss = 0.37987297908826306, disc_loss = 0.0690878285412592
Trained batch 22 in epoch 4, gen_loss = 0.3840068811955659, disc_loss = 0.07850614784325918
Trained batch 23 in epoch 4, gen_loss = 0.3800697935124238, disc_loss = 0.07643642364807117
Trained batch 24 in epoch 4, gen_loss = 0.38025532603263856, disc_loss = 0.07571480627171695
Trained batch 25 in epoch 4, gen_loss = 0.3821865916252136, disc_loss = 0.07308306669493994
Trained batch 26 in epoch 4, gen_loss = 0.38432946690806635, disc_loss = 0.07078439696622943
Trained batch 27 in epoch 4, gen_loss = 0.38434583267995287, disc_loss = 0.06958638460076015
Trained batch 28 in epoch 4, gen_loss = 0.3831662206814207, disc_loss = 0.06820890810822361
Trained batch 29 in epoch 4, gen_loss = 0.38432065546512606, disc_loss = 0.06711063970966885
Trained batch 30 in epoch 4, gen_loss = 0.3843978585735444, disc_loss = 0.06574459412255354
Trained batch 31 in epoch 4, gen_loss = 0.38527868315577507, disc_loss = 0.06396090238558827
Trained batch 32 in epoch 4, gen_loss = 0.38670072049805615, disc_loss = 0.06302041864502385
Trained batch 33 in epoch 4, gen_loss = 0.38610367126324596, disc_loss = 0.06378812703769654
Trained batch 34 in epoch 4, gen_loss = 0.3864884299891336, disc_loss = 0.06853614459479494
Trained batch 35 in epoch 4, gen_loss = 0.3877904795938068, disc_loss = 0.07045957455799605
Trained batch 36 in epoch 4, gen_loss = 0.38818484947488113, disc_loss = 0.06937691684485085
Trained batch 37 in epoch 4, gen_loss = 0.3910994937545375, disc_loss = 0.0677728463197127
Trained batch 38 in epoch 4, gen_loss = 0.3929086319911174, disc_loss = 0.06670261197723448
Trained batch 39 in epoch 4, gen_loss = 0.39435256347060205, disc_loss = 0.06765344743034803
Trained batch 40 in epoch 4, gen_loss = 0.39544395048443864, disc_loss = 0.0698435884820888
Trained batch 41 in epoch 4, gen_loss = 0.3947750088714418, disc_loss = 0.06921247928957677
Trained batch 42 in epoch 4, gen_loss = 0.3946624190308327, disc_loss = 0.06790451471000737
Trained batch 43 in epoch 4, gen_loss = 0.3952039669860493, disc_loss = 0.06657888056096536
Trained batch 44 in epoch 4, gen_loss = 0.39573161866929796, disc_loss = 0.06524510834262603
Trained batch 45 in epoch 4, gen_loss = 0.3950856496458468, disc_loss = 0.06394046749008576
Trained batch 46 in epoch 4, gen_loss = 0.3947592517162891, disc_loss = 0.06283093718910947
Trained batch 47 in epoch 4, gen_loss = 0.39428087572256726, disc_loss = 0.06265725319099147
Trained batch 48 in epoch 4, gen_loss = 0.39513994418844883, disc_loss = 0.061637500505324225
Trained batch 49 in epoch 4, gen_loss = 0.39571332454681396, disc_loss = 0.06147303686942905
Trained batch 50 in epoch 4, gen_loss = 0.3958071218986137, disc_loss = 0.06094941030731242
Trained batch 51 in epoch 4, gen_loss = 0.39554101687211257, disc_loss = 0.059906080056232616
Trained batch 52 in epoch 4, gen_loss = 0.39645439836214175, disc_loss = 0.058877338826621196
Trained batch 53 in epoch 4, gen_loss = 0.3967944957591869, disc_loss = 0.058117816272122716
Trained batch 54 in epoch 4, gen_loss = 0.39705062346024944, disc_loss = 0.05722673225047236
Trained batch 55 in epoch 4, gen_loss = 0.3979064077138901, disc_loss = 0.05642021688150375
Trained batch 56 in epoch 4, gen_loss = 0.3977089456298895, disc_loss = 0.055527458028671775
Trained batch 57 in epoch 4, gen_loss = 0.3972593864490246, disc_loss = 0.055010394895738314
Trained batch 58 in epoch 4, gen_loss = 0.3971416091514846, disc_loss = 0.05442803390560893
Trained batch 59 in epoch 4, gen_loss = 0.3983481486638387, disc_loss = 0.05371469532061989
Trained batch 60 in epoch 4, gen_loss = 0.39962079485908886, disc_loss = 0.05298043457317914
Trained batch 61 in epoch 4, gen_loss = 0.3996465874295081, disc_loss = 0.05226355042654059
Trained batch 62 in epoch 4, gen_loss = 0.4001988409057496, disc_loss = 0.05166232739279549
Trained batch 63 in epoch 4, gen_loss = 0.4000600492581725, disc_loss = 0.05264773021553992
Trained batch 64 in epoch 4, gen_loss = 0.4004600378183218, disc_loss = 0.052632291267554344
Trained batch 65 in epoch 4, gen_loss = 0.40094251298543176, disc_loss = 0.05297631205581693
Trained batch 66 in epoch 4, gen_loss = 0.40072585353210793, disc_loss = 0.05239342459922295
Trained batch 67 in epoch 4, gen_loss = 0.4017634409315446, disc_loss = 0.0520342549904907
Trained batch 68 in epoch 4, gen_loss = 0.4010661987290866, disc_loss = 0.051381040705313935
Trained batch 69 in epoch 4, gen_loss = 0.40088956952095034, disc_loss = 0.05078825744733747
Trained batch 70 in epoch 4, gen_loss = 0.4012065504638242, disc_loss = 0.0501430593463789
Trained batch 71 in epoch 4, gen_loss = 0.4024097298582395, disc_loss = 0.049511956202978685
Trained batch 72 in epoch 4, gen_loss = 0.4019391520382607, disc_loss = 0.04907772342725466
Trained batch 73 in epoch 4, gen_loss = 0.40329195518751404, disc_loss = 0.04855738962509644
Trained batch 74 in epoch 4, gen_loss = 0.40394447922706606, disc_loss = 0.048876364923392736
Trained batch 75 in epoch 4, gen_loss = 0.4035166945112379, disc_loss = 0.04905223787308818
Trained batch 76 in epoch 4, gen_loss = 0.4035081232522989, disc_loss = 0.048726484297423975
Trained batch 77 in epoch 4, gen_loss = 0.40341303822321767, disc_loss = 0.04820088370858381
Trained batch 78 in epoch 4, gen_loss = 0.40387008989913553, disc_loss = 0.047911267323843855
Trained batch 79 in epoch 4, gen_loss = 0.40507375821471214, disc_loss = 0.047365528499358336
Trained batch 80 in epoch 4, gen_loss = 0.40417350736665136, disc_loss = 0.04717104690275902
Trained batch 81 in epoch 4, gen_loss = 0.4036848537805604, disc_loss = 0.04668168625623987
Trained batch 82 in epoch 4, gen_loss = 0.4038510695997491, disc_loss = 0.04634263060975775
Trained batch 83 in epoch 4, gen_loss = 0.40329766486372265, disc_loss = 0.045891448841541116
Trained batch 84 in epoch 4, gen_loss = 0.4024476426489213, disc_loss = 0.045775329001138315
Trained batch 85 in epoch 4, gen_loss = 0.40275148839451547, disc_loss = 0.045545966805738594
Trained batch 86 in epoch 4, gen_loss = 0.4025682183517807, disc_loss = 0.045086827559996094
Trained batch 87 in epoch 4, gen_loss = 0.4026025730100545, disc_loss = 0.04462949740859172
Trained batch 88 in epoch 4, gen_loss = 0.40313292085454705, disc_loss = 0.044204750200314974
Trained batch 89 in epoch 4, gen_loss = 0.40223907861444685, disc_loss = 0.04394504960574624
Trained batch 90 in epoch 4, gen_loss = 0.4021715420288044, disc_loss = 0.043574804867423336
Trained batch 91 in epoch 4, gen_loss = 0.4025298272785933, disc_loss = 0.043148673784858343
Trained batch 92 in epoch 4, gen_loss = 0.40276547337091095, disc_loss = 0.04273074622245966
Trained batch 93 in epoch 4, gen_loss = 0.4018337885116009, disc_loss = 0.04231210182262386
Trained batch 94 in epoch 4, gen_loss = 0.4013418762307418, disc_loss = 0.041925788665876575
Trained batch 95 in epoch 4, gen_loss = 0.40109974797815084, disc_loss = 0.04155835110577755
Trained batch 96 in epoch 4, gen_loss = 0.4005464806999128, disc_loss = 0.04120858824936692
Trained batch 97 in epoch 4, gen_loss = 0.4014491721683619, disc_loss = 0.04086040954428668
Trained batch 98 in epoch 4, gen_loss = 0.4004229156657903, disc_loss = 0.04072536014471993
Trained batch 99 in epoch 4, gen_loss = 0.4010277622938156, disc_loss = 0.04208559377118945
Trained batch 100 in epoch 4, gen_loss = 0.4015869430386194, disc_loss = 0.04434087206747862
Trained batch 101 in epoch 4, gen_loss = 0.40215206263112085, disc_loss = 0.044375484754495764
Trained batch 102 in epoch 4, gen_loss = 0.40280479829288224, disc_loss = 0.04447142532077229
Trained batch 103 in epoch 4, gen_loss = 0.40269946278287816, disc_loss = 0.044136384663243704
Trained batch 104 in epoch 4, gen_loss = 0.40275899597576686, disc_loss = 0.04379230375800814
Trained batch 105 in epoch 4, gen_loss = 0.402293934012359, disc_loss = 0.043467065706005635
Trained batch 106 in epoch 4, gen_loss = 0.40181162089945, disc_loss = 0.043233898964440715
Trained batch 107 in epoch 4, gen_loss = 0.4017561549941699, disc_loss = 0.042942215188371914
Trained batch 108 in epoch 4, gen_loss = 0.40141415978790423, disc_loss = 0.04313316587529598
Trained batch 109 in epoch 4, gen_loss = 0.4005431871522557, disc_loss = 0.043359620750627735
Trained batch 110 in epoch 4, gen_loss = 0.40116968831500494, disc_loss = 0.04344569873232562
Trained batch 111 in epoch 4, gen_loss = 0.40084790917379515, disc_loss = 0.04450500744860619
Trained batch 112 in epoch 4, gen_loss = 0.4017376314222285, disc_loss = 0.046997425187609895
Trained batch 113 in epoch 4, gen_loss = 0.40171753549784944, disc_loss = 0.046685336272052506
Trained batch 114 in epoch 4, gen_loss = 0.40172638893127444, disc_loss = 0.046529520205829455
Trained batch 115 in epoch 4, gen_loss = 0.40083046591487426, disc_loss = 0.04642448034779779
Trained batch 116 in epoch 4, gen_loss = 0.4012739790810479, disc_loss = 0.04606849962495204
Trained batch 117 in epoch 4, gen_loss = 0.4009465302451182, disc_loss = 0.046329654701906496
Trained batch 118 in epoch 4, gen_loss = 0.4016161608595808, disc_loss = 0.046692949332328156
Trained batch 119 in epoch 4, gen_loss = 0.40194848825534185, disc_loss = 0.04652213781373575
Trained batch 120 in epoch 4, gen_loss = 0.4015620264632643, disc_loss = 0.047673659179790696
Trained batch 121 in epoch 4, gen_loss = 0.401764344729361, disc_loss = 0.051020502108988945
Trained batch 122 in epoch 4, gen_loss = 0.4017310869403002, disc_loss = 0.05215105600276492
Trained batch 123 in epoch 4, gen_loss = 0.4017391663885886, disc_loss = 0.05223396160234246
Trained batch 124 in epoch 4, gen_loss = 0.40184819293022156, disc_loss = 0.052406685929745435
Trained batch 125 in epoch 4, gen_loss = 0.40160794910930453, disc_loss = 0.052380914707475947
Trained batch 126 in epoch 4, gen_loss = 0.4009483135122014, disc_loss = 0.05282466991723874
Trained batch 127 in epoch 4, gen_loss = 0.40086760255508125, disc_loss = 0.053482356928725494
Trained batch 128 in epoch 4, gen_loss = 0.40082592881003093, disc_loss = 0.0533464650710135
Trained batch 129 in epoch 4, gen_loss = 0.40081922916265633, disc_loss = 0.053204451655395904
Trained batch 130 in epoch 4, gen_loss = 0.4004802860831486, disc_loss = 0.05321237033602732
Trained batch 131 in epoch 4, gen_loss = 0.4013791736779791, disc_loss = 0.05286648486754998
Trained batch 132 in epoch 4, gen_loss = 0.4017011236427422, disc_loss = 0.052531644173274585
Trained batch 133 in epoch 4, gen_loss = 0.40158114104128595, disc_loss = 0.052215156009865565
Trained batch 134 in epoch 4, gen_loss = 0.40169377856784394, disc_loss = 0.05202324330047877
Trained batch 135 in epoch 4, gen_loss = 0.4015326846171828, disc_loss = 0.05168449633878053
Trained batch 136 in epoch 4, gen_loss = 0.4021518648105816, disc_loss = 0.05135654074472994
Trained batch 137 in epoch 4, gen_loss = 0.40244310187256854, disc_loss = 0.05111117713301834
Trained batch 138 in epoch 4, gen_loss = 0.40249266834567776, disc_loss = 0.050894373635888744
Trained batch 139 in epoch 4, gen_loss = 0.4023232040660722, disc_loss = 0.050569647959699586
Trained batch 140 in epoch 4, gen_loss = 0.40229795439868954, disc_loss = 0.050244691117884634
Trained batch 141 in epoch 4, gen_loss = 0.40198301660342955, disc_loss = 0.050504590860161354
Trained batch 142 in epoch 4, gen_loss = 0.4019190010490951, disc_loss = 0.052119642512390874
Trained batch 143 in epoch 4, gen_loss = 0.40226314837733906, disc_loss = 0.05244235659807196
Trained batch 144 in epoch 4, gen_loss = 0.40281590387738986, disc_loss = 0.052141786613983325
Trained batch 145 in epoch 4, gen_loss = 0.4032821234774916, disc_loss = 0.05181459970580899
Trained batch 146 in epoch 4, gen_loss = 0.4028980833332555, disc_loss = 0.051575608630696324
Trained batch 147 in epoch 4, gen_loss = 0.4028750941962809, disc_loss = 0.051311009950507934
Trained batch 148 in epoch 4, gen_loss = 0.40360966444815566, disc_loss = 0.051071128673576466
Trained batch 149 in epoch 4, gen_loss = 0.4038259935379028, disc_loss = 0.05087765601463616
Trained batch 150 in epoch 4, gen_loss = 0.40427261946217113, disc_loss = 0.050608094340646705
Trained batch 151 in epoch 4, gen_loss = 0.40463337204173994, disc_loss = 0.0503348349256588
Trained batch 152 in epoch 4, gen_loss = 0.40447700413223964, disc_loss = 0.05029511867164105
Trained batch 153 in epoch 4, gen_loss = 0.4045868372762358, disc_loss = 0.05031136986073832
Trained batch 154 in epoch 4, gen_loss = 0.4039540277373406, disc_loss = 0.05051745086487743
Trained batch 155 in epoch 4, gen_loss = 0.4051073608108056, disc_loss = 0.05098771668361643
Trained batch 156 in epoch 4, gen_loss = 0.4050763255091989, disc_loss = 0.05078710844906367
Trained batch 157 in epoch 4, gen_loss = 0.40517651261408116, disc_loss = 0.05069041777036707
Trained batch 158 in epoch 4, gen_loss = 0.40529788421384944, disc_loss = 0.05044979120329397
Trained batch 159 in epoch 4, gen_loss = 0.4056212654337287, disc_loss = 0.05031683551787865
Trained batch 160 in epoch 4, gen_loss = 0.4056680693019251, disc_loss = 0.050071045996401435
Trained batch 161 in epoch 4, gen_loss = 0.4057272021417265, disc_loss = 0.049812263173890516
Trained batch 162 in epoch 4, gen_loss = 0.4057776465372074, disc_loss = 0.04954811065326348
Trained batch 163 in epoch 4, gen_loss = 0.4056178563978614, disc_loss = 0.04930188524729868
Trained batch 164 in epoch 4, gen_loss = 0.4055523758584803, disc_loss = 0.04905670921064236
Trained batch 165 in epoch 4, gen_loss = 0.40546135586428356, disc_loss = 0.048825091685179664
Trained batch 166 in epoch 4, gen_loss = 0.40511085012715736, disc_loss = 0.04860816915759337
Trained batch 167 in epoch 4, gen_loss = 0.40540769110832897, disc_loss = 0.048581375405081506
Trained batch 168 in epoch 4, gen_loss = 0.4055949731691349, disc_loss = 0.04836327348664932
Trained batch 169 in epoch 4, gen_loss = 0.40561391360619486, disc_loss = 0.04812862598337233
Trained batch 170 in epoch 4, gen_loss = 0.405758076418213, disc_loss = 0.04787431047052929
Trained batch 171 in epoch 4, gen_loss = 0.40580702936926555, disc_loss = 0.04761497555219373
Trained batch 172 in epoch 4, gen_loss = 0.40604544891787403, disc_loss = 0.0473864142435759
Trained batch 173 in epoch 4, gen_loss = 0.40612839796077244, disc_loss = 0.04713437204040458
Trained batch 174 in epoch 4, gen_loss = 0.40590729475021364, disc_loss = 0.04689228398326252
Trained batch 175 in epoch 4, gen_loss = 0.40578532845459203, disc_loss = 0.04664639163159088
Trained batch 176 in epoch 4, gen_loss = 0.4058551971858504, disc_loss = 0.046410430196441164
Trained batch 177 in epoch 4, gen_loss = 0.4059513211250305, disc_loss = 0.04617593274451792
Trained batch 178 in epoch 4, gen_loss = 0.4058423027312955, disc_loss = 0.04595800671029274
Trained batch 179 in epoch 4, gen_loss = 0.4059242632653978, disc_loss = 0.04572955303980659
Trained batch 180 in epoch 4, gen_loss = 0.4060373309567488, disc_loss = 0.04549791575126473
Trained batch 181 in epoch 4, gen_loss = 0.4059868494232932, disc_loss = 0.0452701198397675
Trained batch 182 in epoch 4, gen_loss = 0.4060948785862636, disc_loss = 0.045048966321870276
Trained batch 183 in epoch 4, gen_loss = 0.40620970774603926, disc_loss = 0.04483512777116393
Trained batch 184 in epoch 4, gen_loss = 0.4063384840617309, disc_loss = 0.04460971166908338
Trained batch 185 in epoch 4, gen_loss = 0.4065984769534039, disc_loss = 0.044393687286183876
Trained batch 186 in epoch 4, gen_loss = 0.4071895084916589, disc_loss = 0.044264749875341985
Trained batch 187 in epoch 4, gen_loss = 0.4074923640235941, disc_loss = 0.04406044486058044
Trained batch 188 in epoch 4, gen_loss = 0.4075215660705768, disc_loss = 0.04386976200141131
Trained batch 189 in epoch 4, gen_loss = 0.40782217226530376, disc_loss = 0.04366485541931501
Trained batch 190 in epoch 4, gen_loss = 0.4080576842055895, disc_loss = 0.04350822049080935
Trained batch 191 in epoch 4, gen_loss = 0.4078864677188297, disc_loss = 0.043308198037266266
Trained batch 192 in epoch 4, gen_loss = 0.4079369654000732, disc_loss = 0.0432080573238278
Trained batch 193 in epoch 4, gen_loss = 0.4078394403469931, disc_loss = 0.04321025344831197
Trained batch 194 in epoch 4, gen_loss = 0.40787054468423894, disc_loss = 0.043488655814853235
Trained batch 195 in epoch 4, gen_loss = 0.4079953999239571, disc_loss = 0.04351070719267413
Trained batch 196 in epoch 4, gen_loss = 0.4083122494559603, disc_loss = 0.04331296215278243
Trained batch 197 in epoch 4, gen_loss = 0.40848958477227376, disc_loss = 0.043128707603730186
Trained batch 198 in epoch 4, gen_loss = 0.4079665414352513, disc_loss = 0.043167906862463634
Trained batch 199 in epoch 4, gen_loss = 0.40844592556357384, disc_loss = 0.044029302147682754
Trained batch 200 in epoch 4, gen_loss = 0.40838828297396795, disc_loss = 0.04389714389177623
Trained batch 201 in epoch 4, gen_loss = 0.4080615112982174, disc_loss = 0.04378710971859348
Trained batch 202 in epoch 4, gen_loss = 0.40782704978740864, disc_loss = 0.04359815795699437
Trained batch 203 in epoch 4, gen_loss = 0.40758915946764107, disc_loss = 0.0434883044251953
Trained batch 204 in epoch 4, gen_loss = 0.4077259573994613, disc_loss = 0.04335257260401438
Trained batch 205 in epoch 4, gen_loss = 0.4080067862874096, disc_loss = 0.04335831961305179
Trained batch 206 in epoch 4, gen_loss = 0.40767182733701623, disc_loss = 0.044009274422924446
Trained batch 207 in epoch 4, gen_loss = 0.40786420525266576, disc_loss = 0.04549348435158698
Trained batch 208 in epoch 4, gen_loss = 0.40779572910669315, disc_loss = 0.04598798216253733
Trained batch 209 in epoch 4, gen_loss = 0.40765400259267714, disc_loss = 0.0465685818366529
Trained batch 210 in epoch 4, gen_loss = 0.4073866978640805, disc_loss = 0.04763420747363525
Trained batch 211 in epoch 4, gen_loss = 0.40707509163415656, disc_loss = 0.04988715834783847
Trained batch 212 in epoch 4, gen_loss = 0.40722461765360946, disc_loss = 0.05072651833444484
Trained batch 213 in epoch 4, gen_loss = 0.4072082577464737, disc_loss = 0.050875565317833674
Trained batch 214 in epoch 4, gen_loss = 0.4072192485942397, disc_loss = 0.050852547293572234
Trained batch 215 in epoch 4, gen_loss = 0.4070581727557712, disc_loss = 0.05074340646819177
Trained batch 216 in epoch 4, gen_loss = 0.4071252411961006, disc_loss = 0.05058955832294399
Trained batch 217 in epoch 4, gen_loss = 0.4067773857247939, disc_loss = 0.05049206347443984
Trained batch 218 in epoch 4, gen_loss = 0.406899580400284, disc_loss = 0.05035046740014055
Trained batch 219 in epoch 4, gen_loss = 0.40638408457691017, disc_loss = 0.05047369640193541
Trained batch 220 in epoch 4, gen_loss = 0.4066651241002579, disc_loss = 0.05097941535301675
Trained batch 221 in epoch 4, gen_loss = 0.4065579318248474, disc_loss = 0.05100638042036276
Trained batch 222 in epoch 4, gen_loss = 0.406198211715895, disc_loss = 0.051233235214139444
Trained batch 223 in epoch 4, gen_loss = 0.40608516628188746, disc_loss = 0.051368724041302424
Trained batch 224 in epoch 4, gen_loss = 0.4061584022310045, disc_loss = 0.05118188763037324
Trained batch 225 in epoch 4, gen_loss = 0.4061661468142957, disc_loss = 0.0510163958188542
Trained batch 226 in epoch 4, gen_loss = 0.4060318723386605, disc_loss = 0.05083512336975743
Trained batch 227 in epoch 4, gen_loss = 0.40612724279625373, disc_loss = 0.05081285092889805
Trained batch 228 in epoch 4, gen_loss = 0.40614282668417717, disc_loss = 0.050788321343197704
Trained batch 229 in epoch 4, gen_loss = 0.40613600313663484, disc_loss = 0.050632626423612236
Trained batch 230 in epoch 4, gen_loss = 0.40620952212449274, disc_loss = 0.0509317317852565
Trained batch 231 in epoch 4, gen_loss = 0.40641330850535423, disc_loss = 0.050779573994704744
Trained batch 232 in epoch 4, gen_loss = 0.4065099288209825, disc_loss = 0.05082318476749016
Trained batch 233 in epoch 4, gen_loss = 0.40614199485534275, disc_loss = 0.05095368810595037
Trained batch 234 in epoch 4, gen_loss = 0.4062016116811874, disc_loss = 0.05081673883337607
Trained batch 235 in epoch 4, gen_loss = 0.4062794113563279, disc_loss = 0.05066327664456567
Trained batch 236 in epoch 4, gen_loss = 0.40644571713254424, disc_loss = 0.05060516623780131
Trained batch 237 in epoch 4, gen_loss = 0.40675567541302754, disc_loss = 0.05045792412114557
Trained batch 238 in epoch 4, gen_loss = 0.4069525982296118, disc_loss = 0.050267472039035296
Trained batch 239 in epoch 4, gen_loss = 0.4069364829609791, disc_loss = 0.050258432904956865
Trained batch 240 in epoch 4, gen_loss = 0.40678731015114367, disc_loss = 0.05055531156268667
Trained batch 241 in epoch 4, gen_loss = 0.4068319616485233, disc_loss = 0.05045650774913201
Trained batch 242 in epoch 4, gen_loss = 0.4066405303684282, disc_loss = 0.05038989809199922
Trained batch 243 in epoch 4, gen_loss = 0.4065052148748617, disc_loss = 0.05032752749136054
Trained batch 244 in epoch 4, gen_loss = 0.40680733055484536, disc_loss = 0.05017134301858593
Trained batch 245 in epoch 4, gen_loss = 0.4068283633730276, disc_loss = 0.04999287700568273
Trained batch 246 in epoch 4, gen_loss = 0.4067214563307974, disc_loss = 0.049816019735053965
Trained batch 247 in epoch 4, gen_loss = 0.40655947632847295, disc_loss = 0.04968369046166059
Trained batch 248 in epoch 4, gen_loss = 0.4066488337085908, disc_loss = 0.0495118177439793
Trained batch 249 in epoch 4, gen_loss = 0.4069006117582321, disc_loss = 0.049331072315573696
Trained batch 250 in epoch 4, gen_loss = 0.40720690400951887, disc_loss = 0.04915189150297843
Trained batch 251 in epoch 4, gen_loss = 0.4071826467674876, disc_loss = 0.0489881929169069
Trained batch 252 in epoch 4, gen_loss = 0.4071166503570768, disc_loss = 0.04881044858035893
Trained batch 253 in epoch 4, gen_loss = 0.4073850389306001, disc_loss = 0.04863679929871083
Trained batch 254 in epoch 4, gen_loss = 0.40728356078559275, disc_loss = 0.048462337169650135
Trained batch 255 in epoch 4, gen_loss = 0.40729386848397553, disc_loss = 0.048292162695361185
Trained batch 256 in epoch 4, gen_loss = 0.40724860601388063, disc_loss = 0.04813089321371066
Trained batch 257 in epoch 4, gen_loss = 0.4071940799323163, disc_loss = 0.04800615950249309
Trained batch 258 in epoch 4, gen_loss = 0.4070448905344635, disc_loss = 0.04794048189642231
Trained batch 259 in epoch 4, gen_loss = 0.4067127671379309, disc_loss = 0.04783424958228492
Trained batch 260 in epoch 4, gen_loss = 0.4069773771753713, disc_loss = 0.04766978606603098
Trained batch 261 in epoch 4, gen_loss = 0.407154977776622, disc_loss = 0.04751713527899719
Trained batch 262 in epoch 4, gen_loss = 0.4071803201740686, disc_loss = 0.047375411823916004
Trained batch 263 in epoch 4, gen_loss = 0.40702062574299896, disc_loss = 0.04721725708981411
Trained batch 264 in epoch 4, gen_loss = 0.407035172885319, disc_loss = 0.04705650598197332
Trained batch 265 in epoch 4, gen_loss = 0.4074149535114604, disc_loss = 0.046905229223499954
Trained batch 266 in epoch 4, gen_loss = 0.40744384710261883, disc_loss = 0.04674183720136794
Trained batch 267 in epoch 4, gen_loss = 0.4074358888971272, disc_loss = 0.04657818721920085
Trained batch 268 in epoch 4, gen_loss = 0.40724747907716546, disc_loss = 0.04647027708929323
Trained batch 269 in epoch 4, gen_loss = 0.4070753608588819, disc_loss = 0.04633641845408689
Trained batch 270 in epoch 4, gen_loss = 0.4070992765611388, disc_loss = 0.04619284838994766
Trained batch 271 in epoch 4, gen_loss = 0.40716864464475827, disc_loss = 0.04603737454881946
Trained batch 272 in epoch 4, gen_loss = 0.4071665660583929, disc_loss = 0.04588629088565816
Trained batch 273 in epoch 4, gen_loss = 0.40711794075739643, disc_loss = 0.045747108347917884
Trained batch 274 in epoch 4, gen_loss = 0.40701390591534703, disc_loss = 0.04560361180623824
Trained batch 275 in epoch 4, gen_loss = 0.4072980433702469, disc_loss = 0.04547389386984371
Trained batch 276 in epoch 4, gen_loss = 0.40740264193676007, disc_loss = 0.04532058464719608
Trained batch 277 in epoch 4, gen_loss = 0.4074057068327348, disc_loss = 0.045176207079558814
Trained batch 278 in epoch 4, gen_loss = 0.40742885724618016, disc_loss = 0.04503306519493835
Trained batch 279 in epoch 4, gen_loss = 0.40760855983410565, disc_loss = 0.0448856609881789
Trained batch 280 in epoch 4, gen_loss = 0.40757101806033125, disc_loss = 0.04475466272084447
Trained batch 281 in epoch 4, gen_loss = 0.4076508081762503, disc_loss = 0.04460732379006816
Trained batch 282 in epoch 4, gen_loss = 0.40789537295014616, disc_loss = 0.04446669772033688
Trained batch 283 in epoch 4, gen_loss = 0.4081984273564648, disc_loss = 0.04432349464803619
Trained batch 284 in epoch 4, gen_loss = 0.4083102073585778, disc_loss = 0.04417926944432813
Trained batch 285 in epoch 4, gen_loss = 0.40839045812616814, disc_loss = 0.044038789218187435
Trained batch 286 in epoch 4, gen_loss = 0.40838770168583566, disc_loss = 0.043900028917652906
Trained batch 287 in epoch 4, gen_loss = 0.4085285740180148, disc_loss = 0.04376104052789742
Trained batch 288 in epoch 4, gen_loss = 0.40867734110066634, disc_loss = 0.04362868681424346
Trained batch 289 in epoch 4, gen_loss = 0.40862646277608544, disc_loss = 0.043491744453183795
Trained batch 290 in epoch 4, gen_loss = 0.40845641043177994, disc_loss = 0.04337278134957647
Trained batch 291 in epoch 4, gen_loss = 0.4082159176468849, disc_loss = 0.04326277299965923
Trained batch 292 in epoch 4, gen_loss = 0.4081897724407118, disc_loss = 0.04312987764105328
Trained batch 293 in epoch 4, gen_loss = 0.40845365426978286, disc_loss = 0.04299327367235634
Trained batch 294 in epoch 4, gen_loss = 0.40873025393081924, disc_loss = 0.04289761678536691
Trained batch 295 in epoch 4, gen_loss = 0.40903316609360074, disc_loss = 0.042815349314116395
Trained batch 296 in epoch 4, gen_loss = 0.40909067117405257, disc_loss = 0.04273658869584226
Trained batch 297 in epoch 4, gen_loss = 0.4091279204659814, disc_loss = 0.04260156056203023
Trained batch 298 in epoch 4, gen_loss = 0.40916166407208776, disc_loss = 0.04248980362432383
Trained batch 299 in epoch 4, gen_loss = 0.4090934647123019, disc_loss = 0.042366630986798555
Trained batch 300 in epoch 4, gen_loss = 0.4088488818205076, disc_loss = 0.04223770747020024
Trained batch 301 in epoch 4, gen_loss = 0.4087458054553594, disc_loss = 0.04210551552989501
Trained batch 302 in epoch 4, gen_loss = 0.40856505237003365, disc_loss = 0.0420276626887679
Trained batch 303 in epoch 4, gen_loss = 0.40839335234149504, disc_loss = 0.04199420258718371
Trained batch 304 in epoch 4, gen_loss = 0.4082643373090713, disc_loss = 0.041881352512654464
Trained batch 305 in epoch 4, gen_loss = 0.4081605722506841, disc_loss = 0.04176386243898081
Trained batch 306 in epoch 4, gen_loss = 0.4079806260060798, disc_loss = 0.041639492429143686
Trained batch 307 in epoch 4, gen_loss = 0.4080728730791575, disc_loss = 0.04152088322111273
Trained batch 308 in epoch 4, gen_loss = 0.4080221846844386, disc_loss = 0.041394198513032214
Trained batch 309 in epoch 4, gen_loss = 0.40815291125928205, disc_loss = 0.04127138127167258
Trained batch 310 in epoch 4, gen_loss = 0.4080897298464821, disc_loss = 0.0411532456032824
Trained batch 311 in epoch 4, gen_loss = 0.40797973319123954, disc_loss = 0.041045204744501136
Trained batch 312 in epoch 4, gen_loss = 0.40797723824985493, disc_loss = 0.04092922620400905
Trained batch 313 in epoch 4, gen_loss = 0.4079814689933874, disc_loss = 0.0408092779010997
Trained batch 314 in epoch 4, gen_loss = 0.40821992887390984, disc_loss = 0.0406902862845787
Trained batch 315 in epoch 4, gen_loss = 0.4082568645288673, disc_loss = 0.040583288902711546
Trained batch 316 in epoch 4, gen_loss = 0.4083296100987997, disc_loss = 0.04047299764186661
Trained batch 317 in epoch 4, gen_loss = 0.4082315391714468, disc_loss = 0.04040232086524883
Trained batch 318 in epoch 4, gen_loss = 0.40830119285837607, disc_loss = 0.04029669488421101
Trained batch 319 in epoch 4, gen_loss = 0.4082687637768686, disc_loss = 0.04018486071581719
Trained batch 320 in epoch 4, gen_loss = 0.40832969629875965, disc_loss = 0.040071847567166495
Trained batch 321 in epoch 4, gen_loss = 0.40841224891428624, disc_loss = 0.03995958193905235
Trained batch 322 in epoch 4, gen_loss = 0.40839665500741257, disc_loss = 0.03984356217732186
Trained batch 323 in epoch 4, gen_loss = 0.40853691119470714, disc_loss = 0.039768212779574555
Trained batch 324 in epoch 4, gen_loss = 0.40872085828047533, disc_loss = 0.039698967142746996
Trained batch 325 in epoch 4, gen_loss = 0.4086125029559516, disc_loss = 0.039595776308967844
Trained batch 326 in epoch 4, gen_loss = 0.4086667626458206, disc_loss = 0.0394899978014763
Trained batch 327 in epoch 4, gen_loss = 0.40856866456749963, disc_loss = 0.039388610950171404
Trained batch 328 in epoch 4, gen_loss = 0.4084747868468334, disc_loss = 0.0392863632980904
Trained batch 329 in epoch 4, gen_loss = 0.4084085872679046, disc_loss = 0.03919561634009534
Trained batch 330 in epoch 4, gen_loss = 0.40847013895245116, disc_loss = 0.039090380798518835
Trained batch 331 in epoch 4, gen_loss = 0.4083518925380994, disc_loss = 0.03898573982114174
Trained batch 332 in epoch 4, gen_loss = 0.4081223393166745, disc_loss = 0.038885575439501274
Trained batch 333 in epoch 4, gen_loss = 0.4079450002152049, disc_loss = 0.03881642849513603
Trained batch 334 in epoch 4, gen_loss = 0.4079067734640036, disc_loss = 0.038728557796731816
Trained batch 335 in epoch 4, gen_loss = 0.4080285020172596, disc_loss = 0.038667382032144815
Trained batch 336 in epoch 4, gen_loss = 0.40799585188177995, disc_loss = 0.03857081199965774
Trained batch 337 in epoch 4, gen_loss = 0.40812408703671404, disc_loss = 0.03859350107301622
Trained batch 338 in epoch 4, gen_loss = 0.4081769305168703, disc_loss = 0.038543877634151145
Trained batch 339 in epoch 4, gen_loss = 0.4081478881485322, disc_loss = 0.038453018726945364
Trained batch 340 in epoch 4, gen_loss = 0.40810151446250176, disc_loss = 0.03835622322010942
Trained batch 341 in epoch 4, gen_loss = 0.40796244484290745, disc_loss = 0.03825609228976768
Trained batch 342 in epoch 4, gen_loss = 0.4079024802143998, disc_loss = 0.03816454558777175
Trained batch 343 in epoch 4, gen_loss = 0.4079426851036937, disc_loss = 0.038100034257039686
Trained batch 344 in epoch 4, gen_loss = 0.40795120942419855, disc_loss = 0.03800274336278654
Trained batch 345 in epoch 4, gen_loss = 0.407907776060821, disc_loss = 0.03794131165967899
Trained batch 346 in epoch 4, gen_loss = 0.40797719599877724, disc_loss = 0.0378483626199752
Trained batch 347 in epoch 4, gen_loss = 0.40803542484839755, disc_loss = 0.037796756013125266
Trained batch 348 in epoch 4, gen_loss = 0.40788656029113723, disc_loss = 0.03770014257663941
Trained batch 349 in epoch 4, gen_loss = 0.4075797677891595, disc_loss = 0.037629745279305744
Trained batch 350 in epoch 4, gen_loss = 0.40765934291048944, disc_loss = 0.03753739554021093
Trained batch 351 in epoch 4, gen_loss = 0.40774589201266115, disc_loss = 0.03744772749698975
Trained batch 352 in epoch 4, gen_loss = 0.40773872292413255, disc_loss = 0.03738351442479125
Trained batch 353 in epoch 4, gen_loss = 0.4077155096719494, disc_loss = 0.037298863373517906
Trained batch 354 in epoch 4, gen_loss = 0.4077343982709965, disc_loss = 0.03722788616883713
Trained batch 355 in epoch 4, gen_loss = 0.4076987545142013, disc_loss = 0.03713669888858338
Trained batch 356 in epoch 4, gen_loss = 0.40771117121899497, disc_loss = 0.03704235414943086
Trained batch 357 in epoch 4, gen_loss = 0.40760730032148307, disc_loss = 0.03695335100709289
Trained batch 358 in epoch 4, gen_loss = 0.40770513093239086, disc_loss = 0.03686557313710098
Trained batch 359 in epoch 4, gen_loss = 0.40781912265552417, disc_loss = 0.03678228062021339
Trained batch 360 in epoch 4, gen_loss = 0.4078381272068975, disc_loss = 0.036689339304301585
Trained batch 361 in epoch 4, gen_loss = 0.40791064270293514, disc_loss = 0.03662562523441111
Trained batch 362 in epoch 4, gen_loss = 0.40780586669267704, disc_loss = 0.03653706484294648
Trained batch 363 in epoch 4, gen_loss = 0.40810361692866126, disc_loss = 0.036459898515374164
Trained batch 364 in epoch 4, gen_loss = 0.4081091227596753, disc_loss = 0.03636971521765402
Trained batch 365 in epoch 4, gen_loss = 0.4081138580874667, disc_loss = 0.036300105467703334
Trained batch 366 in epoch 4, gen_loss = 0.4081129102031282, disc_loss = 0.036211309370861394
Trained batch 367 in epoch 4, gen_loss = 0.40820576849838963, disc_loss = 0.03612511454696726
Trained batch 368 in epoch 4, gen_loss = 0.4083005792403286, disc_loss = 0.0360906856603981
Trained batch 369 in epoch 4, gen_loss = 0.4084862007482632, disc_loss = 0.03601580075919628
Trained batch 370 in epoch 4, gen_loss = 0.40863081258583583, disc_loss = 0.03593853820928666
Trained batch 371 in epoch 4, gen_loss = 0.40859005776464297, disc_loss = 0.03586731837581723
Trained batch 372 in epoch 4, gen_loss = 0.4083788434877472, disc_loss = 0.03579511307429612
Trained batch 373 in epoch 4, gen_loss = 0.40842117767601727, disc_loss = 0.035707286296332665
Trained batch 374 in epoch 4, gen_loss = 0.40840686337153115, disc_loss = 0.03563446383054058
Trained batch 375 in epoch 4, gen_loss = 0.40851036681139724, disc_loss = 0.035576005801905265
Trained batch 376 in epoch 4, gen_loss = 0.4084044166838143, disc_loss = 0.03550313013316742
Trained batch 377 in epoch 4, gen_loss = 0.40844012670731417, disc_loss = 0.03543629410932895
Trained batch 378 in epoch 4, gen_loss = 0.40865370096506104, disc_loss = 0.03535789709985453
Trained batch 379 in epoch 4, gen_loss = 0.4086588525458386, disc_loss = 0.035297814140243355
Trained batch 380 in epoch 4, gen_loss = 0.4086058851615025, disc_loss = 0.03521656507890173
Trained batch 381 in epoch 4, gen_loss = 0.40845533908973813, disc_loss = 0.035140054742927564
Trained batch 382 in epoch 4, gen_loss = 0.4086626228869117, disc_loss = 0.03507214119687054
Trained batch 383 in epoch 4, gen_loss = 0.4088503955087314, disc_loss = 0.034996086286507
Trained batch 384 in epoch 4, gen_loss = 0.4089547726241025, disc_loss = 0.03493334518310118
Trained batch 385 in epoch 4, gen_loss = 0.40895822628792083, disc_loss = 0.03488013495864839
Trained batch 386 in epoch 4, gen_loss = 0.40899511324650867, disc_loss = 0.03480569936590178
Trained batch 387 in epoch 4, gen_loss = 0.40905544614976214, disc_loss = 0.034725427676769956
Trained batch 388 in epoch 4, gen_loss = 0.4091010829170443, disc_loss = 0.03464719285508546
Trained batch 389 in epoch 4, gen_loss = 0.40896003391498176, disc_loss = 0.034565709712198724
Trained batch 390 in epoch 4, gen_loss = 0.4088440875110724, disc_loss = 0.034485590429214376
Trained batch 391 in epoch 4, gen_loss = 0.4086656345396626, disc_loss = 0.03440486332128414
Trained batch 392 in epoch 4, gen_loss = 0.4086454845870118, disc_loss = 0.03432998388505638
Trained batch 393 in epoch 4, gen_loss = 0.4085152546312603, disc_loss = 0.03425912912592273
Trained batch 394 in epoch 4, gen_loss = 0.40845118994954266, disc_loss = 0.03418082659474657
Trained batch 395 in epoch 4, gen_loss = 0.4083853732756894, disc_loss = 0.03410491862480124
Trained batch 396 in epoch 4, gen_loss = 0.40846127249131575, disc_loss = 0.03402623376206164
Trained batch 397 in epoch 4, gen_loss = 0.4085698132239394, disc_loss = 0.033947591342841595
Trained batch 398 in epoch 4, gen_loss = 0.40861085117012635, disc_loss = 0.033876203288228476
Trained batch 399 in epoch 4, gen_loss = 0.4086758752167225, disc_loss = 0.03379803426156286
Trained batch 400 in epoch 4, gen_loss = 0.4087056938252247, disc_loss = 0.033722796277061776
Trained batch 401 in epoch 4, gen_loss = 0.40877411095657157, disc_loss = 0.03365030515283365
Trained batch 402 in epoch 4, gen_loss = 0.40875319112323355, disc_loss = 0.03357991883496548
Trained batch 403 in epoch 4, gen_loss = 0.4086533074479292, disc_loss = 0.0335036934437553
Trained batch 404 in epoch 4, gen_loss = 0.4086321160381223, disc_loss = 0.033430144040741856
Trained batch 405 in epoch 4, gen_loss = 0.40854265559189423, disc_loss = 0.03335293059368054
Trained batch 406 in epoch 4, gen_loss = 0.4086805542505344, disc_loss = 0.03328402662771029
Trained batch 407 in epoch 4, gen_loss = 0.40861043801494673, disc_loss = 0.03321074677446364
Trained batch 408 in epoch 4, gen_loss = 0.4086590961605529, disc_loss = 0.03314006353118218
Trained batch 409 in epoch 4, gen_loss = 0.4086760560186898, disc_loss = 0.03307229031002285
Trained batch 410 in epoch 4, gen_loss = 0.4086384112672504, disc_loss = 0.03300808802861131
Trained batch 411 in epoch 4, gen_loss = 0.4087238444141971, disc_loss = 0.03294336475212652
Trained batch 412 in epoch 4, gen_loss = 0.40865441449617934, disc_loss = 0.03287419290890687
Trained batch 413 in epoch 4, gen_loss = 0.40853053604923006, disc_loss = 0.03280183553677682
Trained batch 414 in epoch 4, gen_loss = 0.4086532479309174, disc_loss = 0.03273600220837328
Trained batch 415 in epoch 4, gen_loss = 0.40866707243884987, disc_loss = 0.03266581410067514
Trained batch 416 in epoch 4, gen_loss = 0.40872543156861685, disc_loss = 0.03259536390119105
Trained batch 417 in epoch 4, gen_loss = 0.4088651378901952, disc_loss = 0.03252511901076901
Trained batch 418 in epoch 4, gen_loss = 0.4086507845465494, disc_loss = 0.03247341822148223
Trained batch 419 in epoch 4, gen_loss = 0.4087349839863323, disc_loss = 0.032418691162906944
Trained batch 420 in epoch 4, gen_loss = 0.4086973543263388, disc_loss = 0.03235001121415378
Trained batch 421 in epoch 4, gen_loss = 0.4086494782665894, disc_loss = 0.03228110700439644
Trained batch 422 in epoch 4, gen_loss = 0.40857515351992124, disc_loss = 0.03222172195862442
Trained batch 423 in epoch 4, gen_loss = 0.4086420486136427, disc_loss = 0.032156368893272474
Trained batch 424 in epoch 4, gen_loss = 0.40864802956581114, disc_loss = 0.03210025618619779
Trained batch 425 in epoch 4, gen_loss = 0.40872935083270634, disc_loss = 0.03204940579079546
Trained batch 426 in epoch 4, gen_loss = 0.4087151111707754, disc_loss = 0.03199096358069317
Trained batch 427 in epoch 4, gen_loss = 0.40867592164567695, disc_loss = 0.03192628012473965
Trained batch 428 in epoch 4, gen_loss = 0.40882097486849434, disc_loss = 0.031906133871482105
Trained batch 429 in epoch 4, gen_loss = 0.4088261656289877, disc_loss = 0.031902950874334854
Trained batch 430 in epoch 4, gen_loss = 0.40885983480101673, disc_loss = 0.03184557000602965
Trained batch 431 in epoch 4, gen_loss = 0.4090710273357453, disc_loss = 0.03183517679873923
Trained batch 432 in epoch 4, gen_loss = 0.409233019753912, disc_loss = 0.031799986810094355
Trained batch 433 in epoch 4, gen_loss = 0.409307812353433, disc_loss = 0.031747782308917304
Trained batch 434 in epoch 4, gen_loss = 0.40911450242174086, disc_loss = 0.0316904672946053
Trained batch 435 in epoch 4, gen_loss = 0.40914562371892665, disc_loss = 0.03164751822376675
Trained batch 436 in epoch 4, gen_loss = 0.4093712011791203, disc_loss = 0.03162479674916723
Trained batch 437 in epoch 4, gen_loss = 0.4093853848982075, disc_loss = 0.03157012774417662
Trained batch 438 in epoch 4, gen_loss = 0.4095579450928812, disc_loss = 0.03151795548091988
Trained batch 439 in epoch 4, gen_loss = 0.40953787741335956, disc_loss = 0.03146480298601091
Trained batch 440 in epoch 4, gen_loss = 0.409564311947682, disc_loss = 0.03140056217110414
Trained batch 441 in epoch 4, gen_loss = 0.40957814616854915, disc_loss = 0.031334854918953485
Trained batch 442 in epoch 4, gen_loss = 0.4095813763195451, disc_loss = 0.031273053132279294
Trained batch 443 in epoch 4, gen_loss = 0.409660726248681, disc_loss = 0.031221473488331614
Trained batch 444 in epoch 4, gen_loss = 0.4095717381895258, disc_loss = 0.031163989742589968
Trained batch 445 in epoch 4, gen_loss = 0.409405154096706, disc_loss = 0.031105546543328717
Trained batch 446 in epoch 4, gen_loss = 0.4094878755159826, disc_loss = 0.031051181554190097
Trained batch 447 in epoch 4, gen_loss = 0.40950708576877204, disc_loss = 0.030995475813792188
Trained batch 448 in epoch 4, gen_loss = 0.4093116147480988, disc_loss = 0.03094419714152597
Trained batch 449 in epoch 4, gen_loss = 0.40931999497943455, disc_loss = 0.030923686974888873
Trained batch 450 in epoch 4, gen_loss = 0.4093955716907053, disc_loss = 0.030864073130345497
Trained batch 451 in epoch 4, gen_loss = 0.4094335868031578, disc_loss = 0.030824335685012187
Trained batch 452 in epoch 4, gen_loss = 0.40939869818834806, disc_loss = 0.030764187873746154
Trained batch 453 in epoch 4, gen_loss = 0.4093715711968586, disc_loss = 0.03070467563155251
Trained batch 454 in epoch 4, gen_loss = 0.40915729377295945, disc_loss = 0.03064669992744022
Trained batch 455 in epoch 4, gen_loss = 0.4090796513646318, disc_loss = 0.030588988874928634
Trained batch 456 in epoch 4, gen_loss = 0.4090670158748293, disc_loss = 0.030532357673704852
Trained batch 457 in epoch 4, gen_loss = 0.40910850953326994, disc_loss = 0.030471942955872054
Trained batch 458 in epoch 4, gen_loss = 0.40909855473534995, disc_loss = 0.0304111862897037
Trained batch 459 in epoch 4, gen_loss = 0.4092145673606707, disc_loss = 0.03035034225018614
Trained batch 460 in epoch 4, gen_loss = 0.4092679114248644, disc_loss = 0.030292503920599914
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.37817296385765076, disc_loss = 0.0027426506858319044
Trained batch 1 in epoch 5, gen_loss = 0.3712011128664017, disc_loss = 0.0027050735661759973
Trained batch 2 in epoch 5, gen_loss = 0.3795001705487569, disc_loss = 0.0030709756538271904
Trained batch 3 in epoch 5, gen_loss = 0.3872692137956619, disc_loss = 0.0028332569636404514
Trained batch 4 in epoch 5, gen_loss = 0.38638174533843994, disc_loss = 0.002682969346642494
Trained batch 5 in epoch 5, gen_loss = 0.3852369238932927, disc_loss = 0.0026118989335373044
Trained batch 6 in epoch 5, gen_loss = 0.39050920946257456, disc_loss = 0.0027033843632255283
Trained batch 7 in epoch 5, gen_loss = 0.3911423124372959, disc_loss = 0.0027792266046162695
Trained batch 8 in epoch 5, gen_loss = 0.3896110521422492, disc_loss = 0.0027965014645208917
Trained batch 9 in epoch 5, gen_loss = 0.3901185870170593, disc_loss = 0.0028796047670766713
Trained batch 10 in epoch 5, gen_loss = 0.3922670239751989, disc_loss = 0.0028437505772506647
Trained batch 11 in epoch 5, gen_loss = 0.3916669686635335, disc_loss = 0.00286665764482071
Trained batch 12 in epoch 5, gen_loss = 0.3914855924936441, disc_loss = 0.0028933934652461456
Trained batch 13 in epoch 5, gen_loss = 0.3890574723482132, disc_loss = 0.004159735149836966
Trained batch 14 in epoch 5, gen_loss = 0.3897644301255544, disc_loss = 0.006168296343336503
Trained batch 15 in epoch 5, gen_loss = 0.39774601347744465, disc_loss = 0.006395142670953646
Trained batch 16 in epoch 5, gen_loss = 0.4013531961861779, disc_loss = 0.00646236541626208
Trained batch 17 in epoch 5, gen_loss = 0.39964460333188373, disc_loss = 0.006460883965094884
Trained batch 18 in epoch 5, gen_loss = 0.40135618887449565, disc_loss = 0.006465382285808262
Trained batch 19 in epoch 5, gen_loss = 0.4015289157629013, disc_loss = 0.006322328234091401
Trained batch 20 in epoch 5, gen_loss = 0.39947517145247685, disc_loss = 0.006260096871604522
Trained batch 21 in epoch 5, gen_loss = 0.39915110848166724, disc_loss = 0.0067772978112440214
Trained batch 22 in epoch 5, gen_loss = 0.40202541454978613, disc_loss = 0.011000973800116259
Trained batch 23 in epoch 5, gen_loss = 0.39793527498841286, disc_loss = 0.02806809399044141
Trained batch 24 in epoch 5, gen_loss = 0.3967457902431488, disc_loss = 0.03254722574725747
Trained batch 25 in epoch 5, gen_loss = 0.395344329568056, disc_loss = 0.03667166809408137
Trained batch 26 in epoch 5, gen_loss = 0.3933024958327965, disc_loss = 0.04345622584568681
Trained batch 27 in epoch 5, gen_loss = 0.39037033915519714, disc_loss = 0.04953817100197609
Trained batch 28 in epoch 5, gen_loss = 0.39277952806702976, disc_loss = 0.055551244604304946
Trained batch 29 in epoch 5, gen_loss = 0.3937640776236852, disc_loss = 0.05713931180847188
Trained batch 30 in epoch 5, gen_loss = 0.39426552864813036, disc_loss = 0.06977095198066484
Trained batch 31 in epoch 5, gen_loss = 0.3934582443907857, disc_loss = 0.07403322409663815
Trained batch 32 in epoch 5, gen_loss = 0.3960112486824845, disc_loss = 0.08219588442112911
Trained batch 33 in epoch 5, gen_loss = 0.39632262990755196, disc_loss = 0.08901152898119215
Trained batch 34 in epoch 5, gen_loss = 0.39198328128882814, disc_loss = 0.092374114120113
Trained batch 35 in epoch 5, gen_loss = 0.3895844514999125, disc_loss = 0.0997019704664126
Trained batch 36 in epoch 5, gen_loss = 0.39191850737945455, disc_loss = 0.10211016646762555
Trained batch 37 in epoch 5, gen_loss = 0.39219544161307185, disc_loss = 0.1041615225595275
Trained batch 38 in epoch 5, gen_loss = 0.3928650881235416, disc_loss = 0.10868303254485512
Trained batch 39 in epoch 5, gen_loss = 0.39319268949329855, disc_loss = 0.10934762289980426
Trained batch 40 in epoch 5, gen_loss = 0.3929942028551567, disc_loss = 0.1092889812865817
Trained batch 41 in epoch 5, gen_loss = 0.39314468524285723, disc_loss = 0.10994239387634609
Trained batch 42 in epoch 5, gen_loss = 0.3930909553932589, disc_loss = 0.1111280944653202
Trained batch 43 in epoch 5, gen_loss = 0.392082984813235, disc_loss = 0.11633281669029119
Trained batch 44 in epoch 5, gen_loss = 0.3911789798074298, disc_loss = 0.11785290196744933
Trained batch 45 in epoch 5, gen_loss = 0.38934089016655216, disc_loss = 0.11917042591528076
Trained batch 46 in epoch 5, gen_loss = 0.38847460233150644, disc_loss = 0.11898792635134244
Trained batch 47 in epoch 5, gen_loss = 0.38905066531151533, disc_loss = 0.11745202499635828
Trained batch 48 in epoch 5, gen_loss = 0.3881422071432581, disc_loss = 0.11769351808886443
Trained batch 49 in epoch 5, gen_loss = 0.3891332492232323, disc_loss = 0.12255869884975254
Trained batch 50 in epoch 5, gen_loss = 0.3878200764165205, disc_loss = 0.12320789684742398
Trained batch 51 in epoch 5, gen_loss = 0.38636436227422494, disc_loss = 0.1238894699445854
Trained batch 52 in epoch 5, gen_loss = 0.38589596270390275, disc_loss = 0.12291017699248667
Trained batch 53 in epoch 5, gen_loss = 0.3856983143422339, disc_loss = 0.12164486335004093
Trained batch 54 in epoch 5, gen_loss = 0.3861637660048225, disc_loss = 0.12151252530007199
Trained batch 55 in epoch 5, gen_loss = 0.38603847926216467, disc_loss = 0.12400324014847033
Trained batch 56 in epoch 5, gen_loss = 0.38676686846373376, disc_loss = 0.1246841801902312
Trained batch 57 in epoch 5, gen_loss = 0.385720557950694, disc_loss = 0.12409125946879644
Trained batch 58 in epoch 5, gen_loss = 0.3867873092324047, disc_loss = 0.12318794502703062
Trained batch 59 in epoch 5, gen_loss = 0.38817480728030207, disc_loss = 0.12160393450564394
Trained batch 60 in epoch 5, gen_loss = 0.3868117906519624, disc_loss = 0.11989228657187252
Trained batch 61 in epoch 5, gen_loss = 0.3874580088642336, disc_loss = 0.11864181761930306
Trained batch 62 in epoch 5, gen_loss = 0.38756275011433494, disc_loss = 0.11688907437824778
Trained batch 63 in epoch 5, gen_loss = 0.38707676879130304, disc_loss = 0.11626077739492757
Trained batch 64 in epoch 5, gen_loss = 0.38579941002222207, disc_loss = 0.11579465171895348
Trained batch 65 in epoch 5, gen_loss = 0.38640499769738224, disc_loss = 0.11660520364812603
Trained batch 66 in epoch 5, gen_loss = 0.38716414148238165, disc_loss = 0.11719349153868075
Trained batch 67 in epoch 5, gen_loss = 0.3878711709643112, disc_loss = 0.11592797937063391
Trained batch 68 in epoch 5, gen_loss = 0.3878697310236917, disc_loss = 0.11442390167275848
Trained batch 69 in epoch 5, gen_loss = 0.3888086619121688, disc_loss = 0.11307059576335762
Trained batch 70 in epoch 5, gen_loss = 0.3888476807886446, disc_loss = 0.11175031815065255
Trained batch 71 in epoch 5, gen_loss = 0.38852583886020714, disc_loss = 0.11036456602030537
Trained batch 72 in epoch 5, gen_loss = 0.3884115359962803, disc_loss = 0.10890545414709678
Trained batch 73 in epoch 5, gen_loss = 0.38815793294358897, disc_loss = 0.10748977193961272
Trained batch 74 in epoch 5, gen_loss = 0.3882031510273615, disc_loss = 0.10611366702243685
Trained batch 75 in epoch 5, gen_loss = 0.38842080749179186, disc_loss = 0.10483501701444191
Trained batch 76 in epoch 5, gen_loss = 0.389485275397053, disc_loss = 0.10358498859303919
Trained batch 77 in epoch 5, gen_loss = 0.3894940807651251, disc_loss = 0.10235809271510404
Trained batch 78 in epoch 5, gen_loss = 0.3891348742608783, disc_loss = 0.10120122592684024
Trained batch 79 in epoch 5, gen_loss = 0.3895381519570947, disc_loss = 0.10001355185522698
Trained batch 80 in epoch 5, gen_loss = 0.3901314556966593, disc_loss = 0.09884700114137412
Trained batch 81 in epoch 5, gen_loss = 0.3896239005574366, disc_loss = 0.0976871517941174
Trained batch 82 in epoch 5, gen_loss = 0.38989254239811955, disc_loss = 0.0965668664212866
Trained batch 83 in epoch 5, gen_loss = 0.3894572550696986, disc_loss = 0.09547984472564644
Trained batch 84 in epoch 5, gen_loss = 0.3900930111899095, disc_loss = 0.0944367991431671
Trained batch 85 in epoch 5, gen_loss = 0.39041752333557883, disc_loss = 0.09336162862086365
Trained batch 86 in epoch 5, gen_loss = 0.39031986618179015, disc_loss = 0.09231791049830787
Trained batch 87 in epoch 5, gen_loss = 0.3909044382585721, disc_loss = 0.0913182650666303
Trained batch 88 in epoch 5, gen_loss = 0.39080528847956925, disc_loss = 0.09032800945118488
Trained batch 89 in epoch 5, gen_loss = 0.39068439255158105, disc_loss = 0.08935265340583606
Trained batch 90 in epoch 5, gen_loss = 0.3904826305397264, disc_loss = 0.08843093670669247
Trained batch 91 in epoch 5, gen_loss = 0.3905688950225063, disc_loss = 0.08749766844456368
Trained batch 92 in epoch 5, gen_loss = 0.39063995291468917, disc_loss = 0.08661381826455634
Trained batch 93 in epoch 5, gen_loss = 0.3905449742649464, disc_loss = 0.08573511432846413
Trained batch 94 in epoch 5, gen_loss = 0.3907375478430798, disc_loss = 0.08492684815029956
Trained batch 95 in epoch 5, gen_loss = 0.3908962115334968, disc_loss = 0.08407912554927559
Trained batch 96 in epoch 5, gen_loss = 0.39100813973195775, disc_loss = 0.08324220727831509
Trained batch 97 in epoch 5, gen_loss = 0.3911344738943236, disc_loss = 0.08242438946689042
Trained batch 98 in epoch 5, gen_loss = 0.3915535562267207, disc_loss = 0.081646787052071
Trained batch 99 in epoch 5, gen_loss = 0.3913363356888294, disc_loss = 0.08090133125660941
Trained batch 100 in epoch 5, gen_loss = 0.3914584061591932, disc_loss = 0.08012418965071366
Trained batch 101 in epoch 5, gen_loss = 0.3925802986703667, disc_loss = 0.07940711200410756
Trained batch 102 in epoch 5, gen_loss = 0.39242098791506685, disc_loss = 0.0787058872808205
Trained batch 103 in epoch 5, gen_loss = 0.39244452190513796, disc_loss = 0.07797221228471383
Trained batch 104 in epoch 5, gen_loss = 0.3926446427901586, disc_loss = 0.0772556630916716
Trained batch 105 in epoch 5, gen_loss = 0.39255901538538485, disc_loss = 0.07657575906684869
Trained batch 106 in epoch 5, gen_loss = 0.3935161888877922, disc_loss = 0.07589375959909478
Trained batch 107 in epoch 5, gen_loss = 0.3941392499815535, disc_loss = 0.07527323301959161
Trained batch 108 in epoch 5, gen_loss = 0.39458965694685594, disc_loss = 0.07460892847269227
Trained batch 109 in epoch 5, gen_loss = 0.39468049799854105, disc_loss = 0.0739854205018756
Trained batch 110 in epoch 5, gen_loss = 0.3951574769374487, disc_loss = 0.07334149247538801
Trained batch 111 in epoch 5, gen_loss = 0.3952607170545629, disc_loss = 0.07270594946541158
Trained batch 112 in epoch 5, gen_loss = 0.3957421970842159, disc_loss = 0.07208616975530059
Trained batch 113 in epoch 5, gen_loss = 0.3960604747397858, disc_loss = 0.0714778414163575
Trained batch 114 in epoch 5, gen_loss = 0.39676920110764713, disc_loss = 0.07087160078201281
Trained batch 115 in epoch 5, gen_loss = 0.3970935872659601, disc_loss = 0.07028063240758112
Trained batch 116 in epoch 5, gen_loss = 0.3969393340695618, disc_loss = 0.06969641021285684
Trained batch 117 in epoch 5, gen_loss = 0.39651426912869436, disc_loss = 0.06911982069881159
Trained batch 118 in epoch 5, gen_loss = 0.3963164598250589, disc_loss = 0.06855719085555806
Trained batch 119 in epoch 5, gen_loss = 0.3961316715925932, disc_loss = 0.06799704875253762
Trained batch 120 in epoch 5, gen_loss = 0.3963430108856564, disc_loss = 0.067460256671025
Trained batch 121 in epoch 5, gen_loss = 0.39662806188962496, disc_loss = 0.06697017618180176
Trained batch 122 in epoch 5, gen_loss = 0.39767154312230707, disc_loss = 0.06652174634495522
Trained batch 123 in epoch 5, gen_loss = 0.39784070188480036, disc_loss = 0.06602318960076739
Trained batch 124 in epoch 5, gen_loss = 0.3976472443342209, disc_loss = 0.06553958112746477
Trained batch 125 in epoch 5, gen_loss = 0.39747105077618644, disc_loss = 0.06504791165103338
Trained batch 126 in epoch 5, gen_loss = 0.39784942708146853, disc_loss = 0.06455079488104254
Trained batch 127 in epoch 5, gen_loss = 0.39814928581472486, disc_loss = 0.06406242617777025
Trained batch 128 in epoch 5, gen_loss = 0.3984293107145516, disc_loss = 0.06358565156557416
Trained batch 129 in epoch 5, gen_loss = 0.39845539434598043, disc_loss = 0.06311159010689993
Trained batch 130 in epoch 5, gen_loss = 0.3983342562240499, disc_loss = 0.06264871983781799
Trained batch 131 in epoch 5, gen_loss = 0.39849626397093135, disc_loss = 0.06219394956221522
Trained batch 132 in epoch 5, gen_loss = 0.3985044045331783, disc_loss = 0.061746248089589346
Trained batch 133 in epoch 5, gen_loss = 0.3990109797511528, disc_loss = 0.06134908900373796
Trained batch 134 in epoch 5, gen_loss = 0.39895846832681586, disc_loss = 0.06091787236639195
Trained batch 135 in epoch 5, gen_loss = 0.3990295799996923, disc_loss = 0.0605171131901443
Trained batch 136 in epoch 5, gen_loss = 0.39901866780145323, disc_loss = 0.06021152306212126
Trained batch 137 in epoch 5, gen_loss = 0.398947367525619, disc_loss = 0.060287241324566414
Trained batch 138 in epoch 5, gen_loss = 0.3996520667410583, disc_loss = 0.06042383445038212
Trained batch 139 in epoch 5, gen_loss = 0.3992709141756807, disc_loss = 0.060525857284665106
Trained batch 140 in epoch 5, gen_loss = 0.39957636309430955, disc_loss = 0.06041807150270077
Trained batch 141 in epoch 5, gen_loss = 0.39954872775665473, disc_loss = 0.06007225230388658
Trained batch 142 in epoch 5, gen_loss = 0.39986101428528764, disc_loss = 0.05989869526372506
Trained batch 143 in epoch 5, gen_loss = 0.400711116174029, disc_loss = 0.059845962496991784
Trained batch 144 in epoch 5, gen_loss = 0.40099764003835875, disc_loss = 0.05956810202834935
Trained batch 145 in epoch 5, gen_loss = 0.4009871110320091, disc_loss = 0.05922083312977258
Trained batch 146 in epoch 5, gen_loss = 0.4013842558171473, disc_loss = 0.05888893170168205
Trained batch 147 in epoch 5, gen_loss = 0.4019202548708465, disc_loss = 0.058525636905451886
Trained batch 148 in epoch 5, gen_loss = 0.4017606032574737, disc_loss = 0.058188917765381355
Trained batch 149 in epoch 5, gen_loss = 0.4018223594625791, disc_loss = 0.057841085450102886
Trained batch 150 in epoch 5, gen_loss = 0.4015506684582755, disc_loss = 0.05748639522823474
Trained batch 151 in epoch 5, gen_loss = 0.4019214221717496, disc_loss = 0.057127190242202856
Trained batch 152 in epoch 5, gen_loss = 0.4016799321945976, disc_loss = 0.05677782766539238
Trained batch 153 in epoch 5, gen_loss = 0.40161058413130896, disc_loss = 0.05642155866598251
Trained batch 154 in epoch 5, gen_loss = 0.4015271818445575, disc_loss = 0.0560804754916218
Trained batch 155 in epoch 5, gen_loss = 0.40179866160719824, disc_loss = 0.05573816497165423
Trained batch 156 in epoch 5, gen_loss = 0.40219042891529716, disc_loss = 0.055395261307430874
Trained batch 157 in epoch 5, gen_loss = 0.40248800880169566, disc_loss = 0.055063154853444214
Trained batch 158 in epoch 5, gen_loss = 0.4028754617620564, disc_loss = 0.054754279385490705
Trained batch 159 in epoch 5, gen_loss = 0.40279421405866744, disc_loss = 0.05442993275792105
Trained batch 160 in epoch 5, gen_loss = 0.4027944902270477, disc_loss = 0.05410428063782013
Trained batch 161 in epoch 5, gen_loss = 0.4027522792234833, disc_loss = 0.05377957683392904
Trained batch 162 in epoch 5, gen_loss = 0.4027080719639187, disc_loss = 0.053461203962261644
Trained batch 163 in epoch 5, gen_loss = 0.4026023146764534, disc_loss = 0.05314720514664858
Trained batch 164 in epoch 5, gen_loss = 0.40263673943100553, disc_loss = 0.05283348470375958
Trained batch 165 in epoch 5, gen_loss = 0.4028782130903508, disc_loss = 0.052527153517360835
Trained batch 166 in epoch 5, gen_loss = 0.40310580189713463, disc_loss = 0.05223658559411697
Trained batch 167 in epoch 5, gen_loss = 0.40263677432778333, disc_loss = 0.05195885642855761
Trained batch 168 in epoch 5, gen_loss = 0.4024322381210045, disc_loss = 0.05167078937902584
Trained batch 169 in epoch 5, gen_loss = 0.40295407412683265, disc_loss = 0.051405447063392354
Trained batch 170 in epoch 5, gen_loss = 0.40301249311332815, disc_loss = 0.05113229952542907
Trained batch 171 in epoch 5, gen_loss = 0.40331303284958353, disc_loss = 0.05085057836922081
Trained batch 172 in epoch 5, gen_loss = 0.4033516763434934, disc_loss = 0.05056838306256521
Trained batch 173 in epoch 5, gen_loss = 0.40324578399973354, disc_loss = 0.050289168036623116
Trained batch 174 in epoch 5, gen_loss = 0.40335060247353144, disc_loss = 0.05002679797488132
Trained batch 175 in epoch 5, gen_loss = 0.40318848489021714, disc_loss = 0.049762482530654364
Trained batch 176 in epoch 5, gen_loss = 0.40324740246527613, disc_loss = 0.04949786981480922
Trained batch 177 in epoch 5, gen_loss = 0.40350766555311973, disc_loss = 0.049231024076403486
Trained batch 178 in epoch 5, gen_loss = 0.40329229756773516, disc_loss = 0.04897929216258998
Trained batch 179 in epoch 5, gen_loss = 0.40296312827203007, disc_loss = 0.04871945756992015
Trained batch 180 in epoch 5, gen_loss = 0.4029131899716446, disc_loss = 0.04846662133404707
Trained batch 181 in epoch 5, gen_loss = 0.4031156197517783, disc_loss = 0.04825738251687713
Trained batch 182 in epoch 5, gen_loss = 0.40285916610167977, disc_loss = 0.04804898787460346
Trained batch 183 in epoch 5, gen_loss = 0.40277088571177877, disc_loss = 0.04782552478781841
Trained batch 184 in epoch 5, gen_loss = 0.4029326914935499, disc_loss = 0.047603351191768575
Trained batch 185 in epoch 5, gen_loss = 0.40293236197002474, disc_loss = 0.047361237389381014
Trained batch 186 in epoch 5, gen_loss = 0.4029963606978483, disc_loss = 0.04711984353884557
Trained batch 187 in epoch 5, gen_loss = 0.40302668805135056, disc_loss = 0.046883485670711725
Trained batch 188 in epoch 5, gen_loss = 0.4031770983858714, disc_loss = 0.046644436549666345
Trained batch 189 in epoch 5, gen_loss = 0.4032269881744134, disc_loss = 0.046407457807493446
Trained batch 190 in epoch 5, gen_loss = 0.4036353463745866, disc_loss = 0.04618356917760486
Trained batch 191 in epoch 5, gen_loss = 0.4036835234146565, disc_loss = 0.045955445491320766
Trained batch 192 in epoch 5, gen_loss = 0.4036565087156592, disc_loss = 0.04572528594057679
Trained batch 193 in epoch 5, gen_loss = 0.40339152399719375, disc_loss = 0.045505037983716225
Trained batch 194 in epoch 5, gen_loss = 0.40314674033568454, disc_loss = 0.04528129203722645
Trained batch 195 in epoch 5, gen_loss = 0.4030180375034712, disc_loss = 0.045063217107577214
Trained batch 196 in epoch 5, gen_loss = 0.4028669876344313, disc_loss = 0.044847427565973194
Trained batch 197 in epoch 5, gen_loss = 0.4027379515646684, disc_loss = 0.04462859462923135
Trained batch 198 in epoch 5, gen_loss = 0.40268596624908737, disc_loss = 0.04442830042487675
Trained batch 199 in epoch 5, gen_loss = 0.40245215110480786, disc_loss = 0.044238528370624405
Trained batch 200 in epoch 5, gen_loss = 0.40237622096467374, disc_loss = 0.044028911641127065
Trained batch 201 in epoch 5, gen_loss = 0.4022886516286595, disc_loss = 0.04399675310999708
Trained batch 202 in epoch 5, gen_loss = 0.40247319154257843, disc_loss = 0.044267161610522514
Trained batch 203 in epoch 5, gen_loss = 0.40270909572056696, disc_loss = 0.04406717842143467
Trained batch 204 in epoch 5, gen_loss = 0.4025616286004462, disc_loss = 0.04390619635899983
Trained batch 205 in epoch 5, gen_loss = 0.40257984956780685, disc_loss = 0.04371941087143586
Trained batch 206 in epoch 5, gen_loss = 0.4024021005716877, disc_loss = 0.043521320071647274
Trained batch 207 in epoch 5, gen_loss = 0.40279792657551855, disc_loss = 0.0433401572450888
Trained batch 208 in epoch 5, gen_loss = 0.4031203578105954, disc_loss = 0.04314929941606721
Trained batch 209 in epoch 5, gen_loss = 0.40298343549172083, disc_loss = 0.04295858908666386
Trained batch 210 in epoch 5, gen_loss = 0.4028710826737056, disc_loss = 0.04276225662247335
Trained batch 211 in epoch 5, gen_loss = 0.4029006825162555, disc_loss = 0.042578803709233705
Trained batch 212 in epoch 5, gen_loss = 0.4029658114266508, disc_loss = 0.04239514810492245
Trained batch 213 in epoch 5, gen_loss = 0.4029550639407657, disc_loss = 0.04220431822702445
Trained batch 214 in epoch 5, gen_loss = 0.40264682596506074, disc_loss = 0.042017567673763044
Trained batch 215 in epoch 5, gen_loss = 0.4029585540432621, disc_loss = 0.04184059616926351
Trained batch 216 in epoch 5, gen_loss = 0.4032621609587823, disc_loss = 0.041660288448042065
Trained batch 217 in epoch 5, gen_loss = 0.4031083159353755, disc_loss = 0.041483863793557015
Trained batch 218 in epoch 5, gen_loss = 0.40298725201931174, disc_loss = 0.04130331945890501
Trained batch 219 in epoch 5, gen_loss = 0.40305762379006904, disc_loss = 0.04113150437955152
Trained batch 220 in epoch 5, gen_loss = 0.4030075312604732, disc_loss = 0.04095729046956345
Trained batch 221 in epoch 5, gen_loss = 0.40335171803966297, disc_loss = 0.04078132171511046
Trained batch 222 in epoch 5, gen_loss = 0.4034595319107509, disc_loss = 0.04060488980317764
Trained batch 223 in epoch 5, gen_loss = 0.4031724547302084, disc_loss = 0.040429516286946764
Trained batch 224 in epoch 5, gen_loss = 0.40297398388385774, disc_loss = 0.04025507294003748
Trained batch 225 in epoch 5, gen_loss = 0.40272585909187264, disc_loss = 0.040081951869713486
Trained batch 226 in epoch 5, gen_loss = 0.40279248783504384, disc_loss = 0.03991462646046087
Trained batch 227 in epoch 5, gen_loss = 0.4028649720314302, disc_loss = 0.039747555001859405
Trained batch 228 in epoch 5, gen_loss = 0.4028422846153834, disc_loss = 0.03958500027514213
Trained batch 229 in epoch 5, gen_loss = 0.4028837503946346, disc_loss = 0.03941961272984095
Trained batch 230 in epoch 5, gen_loss = 0.40285039057721306, disc_loss = 0.03925898510083814
Trained batch 231 in epoch 5, gen_loss = 0.4026427048675973, disc_loss = 0.039096169384971166
Trained batch 232 in epoch 5, gen_loss = 0.40289372659803974, disc_loss = 0.03893873699922754
Trained batch 233 in epoch 5, gen_loss = 0.40276839482223886, disc_loss = 0.038782872210364215
Trained batch 234 in epoch 5, gen_loss = 0.4027639591313423, disc_loss = 0.03863376869691258
Trained batch 235 in epoch 5, gen_loss = 0.4026696334072089, disc_loss = 0.03847556030703314
Trained batch 236 in epoch 5, gen_loss = 0.4025741192484707, disc_loss = 0.03832176887333975
Trained batch 237 in epoch 5, gen_loss = 0.40246055863735053, disc_loss = 0.03816807754689969
Trained batch 238 in epoch 5, gen_loss = 0.4025238822818301, disc_loss = 0.038015203559225635
Trained batch 239 in epoch 5, gen_loss = 0.40233302519967157, disc_loss = 0.03786420527321752
Trained batch 240 in epoch 5, gen_loss = 0.4021847730973944, disc_loss = 0.03771272862254723
Trained batch 241 in epoch 5, gen_loss = 0.4021164511969267, disc_loss = 0.03756189839346796
Trained batch 242 in epoch 5, gen_loss = 0.4023274198603728, disc_loss = 0.037413240864550994
Trained batch 243 in epoch 5, gen_loss = 0.4024125832881107, disc_loss = 0.03726828122534408
Trained batch 244 in epoch 5, gen_loss = 0.4024634995630809, disc_loss = 0.03712236199109834
Trained batch 245 in epoch 5, gen_loss = 0.4023850876989403, disc_loss = 0.0369758825716979
Trained batch 246 in epoch 5, gen_loss = 0.4024459602017152, disc_loss = 0.0368396245020438
Trained batch 247 in epoch 5, gen_loss = 0.40207348505575813, disc_loss = 0.0367122511839449
Trained batch 248 in epoch 5, gen_loss = 0.4017770575830735, disc_loss = 0.03657712230279324
Trained batch 249 in epoch 5, gen_loss = 0.4018912084698677, disc_loss = 0.03644080374948681
Trained batch 250 in epoch 5, gen_loss = 0.4018790261797696, disc_loss = 0.036306775138858126
Trained batch 251 in epoch 5, gen_loss = 0.4016993457954081, disc_loss = 0.036169012802438665
Trained batch 252 in epoch 5, gen_loss = 0.40180966075465613, disc_loss = 0.036032348683494114
Trained batch 253 in epoch 5, gen_loss = 0.4016066183607409, disc_loss = 0.03589627849887763
Trained batch 254 in epoch 5, gen_loss = 0.40191809014946805, disc_loss = 0.03577146192227362
Trained batch 255 in epoch 5, gen_loss = 0.4017516261083074, disc_loss = 0.03564235018347972
Trained batch 256 in epoch 5, gen_loss = 0.40218575530710854, disc_loss = 0.03551908160273551
Trained batch 257 in epoch 5, gen_loss = 0.4020987860569658, disc_loss = 0.03538685025423476
Trained batch 258 in epoch 5, gen_loss = 0.4021931193395011, disc_loss = 0.03525920957686473
Trained batch 259 in epoch 5, gen_loss = 0.40204896256327627, disc_loss = 0.03512922241397274
Trained batch 260 in epoch 5, gen_loss = 0.40180009780487336, disc_loss = 0.035003321144062585
Trained batch 261 in epoch 5, gen_loss = 0.4019700769363469, disc_loss = 0.03489125547761752
Trained batch 262 in epoch 5, gen_loss = 0.40194965853663905, disc_loss = 0.03476733528121867
Trained batch 263 in epoch 5, gen_loss = 0.4018921365001888, disc_loss = 0.03464256530886897
Trained batch 264 in epoch 5, gen_loss = 0.40201525165224977, disc_loss = 0.03451835004885171
Trained batch 265 in epoch 5, gen_loss = 0.4021928231406929, disc_loss = 0.03439477765302461
Trained batch 266 in epoch 5, gen_loss = 0.40208618287066844, disc_loss = 0.03427245047498034
Trained batch 267 in epoch 5, gen_loss = 0.4021571026697977, disc_loss = 0.03415305174560523
Trained batch 268 in epoch 5, gen_loss = 0.4021500656485114, disc_loss = 0.03403506031671892
Trained batch 269 in epoch 5, gen_loss = 0.4019894078373909, disc_loss = 0.03391499865834636
Trained batch 270 in epoch 5, gen_loss = 0.4022152139581877, disc_loss = 0.033795916142863154
Trained batch 271 in epoch 5, gen_loss = 0.4023674892480759, disc_loss = 0.033693215392892904
Trained batch 272 in epoch 5, gen_loss = 0.40219872103724286, disc_loss = 0.03357635260237238
Trained batch 273 in epoch 5, gen_loss = 0.40217796452071547, disc_loss = 0.033458267288013994
Trained batch 274 in epoch 5, gen_loss = 0.40232098097150976, disc_loss = 0.033343030377291145
Trained batch 275 in epoch 5, gen_loss = 0.40242863970174303, disc_loss = 0.03322905887793952
Trained batch 276 in epoch 5, gen_loss = 0.4024042937406994, disc_loss = 0.03312656433289595
Trained batch 277 in epoch 5, gen_loss = 0.402423370709951, disc_loss = 0.033054335089316655
Trained batch 278 in epoch 5, gen_loss = 0.40242033903103147, disc_loss = 0.032951000683580436
Trained batch 279 in epoch 5, gen_loss = 0.40249519140592643, disc_loss = 0.03288368720386643
Trained batch 280 in epoch 5, gen_loss = 0.4025745101776836, disc_loss = 0.03280087916994156
Trained batch 281 in epoch 5, gen_loss = 0.4027753121992375, disc_loss = 0.032705610090823754
Trained batch 282 in epoch 5, gen_loss = 0.4026108567895822, disc_loss = 0.03269400370065386
Trained batch 283 in epoch 5, gen_loss = 0.40250723237093067, disc_loss = 0.03283131391615082
Trained batch 284 in epoch 5, gen_loss = 0.4024983685790447, disc_loss = 0.033067941941369916
Trained batch 285 in epoch 5, gen_loss = 0.4025528716978493, disc_loss = 0.03341320632603605
Trained batch 286 in epoch 5, gen_loss = 0.40264152447313384, disc_loss = 0.03331683468493837
Trained batch 287 in epoch 5, gen_loss = 0.40256778994161224, disc_loss = 0.03389700979581297
Trained batch 288 in epoch 5, gen_loss = 0.4029125149996635, disc_loss = 0.033921610745665805
Trained batch 289 in epoch 5, gen_loss = 0.4028912305318076, disc_loss = 0.03396093968807816
Trained batch 290 in epoch 5, gen_loss = 0.4028110283449343, disc_loss = 0.033911412768626005
Trained batch 291 in epoch 5, gen_loss = 0.4024680996288175, disc_loss = 0.034138949525348
Trained batch 292 in epoch 5, gen_loss = 0.40258784185294, disc_loss = 0.03512303613932047
Trained batch 293 in epoch 5, gen_loss = 0.4025209445227571, disc_loss = 0.03541811159138764
Trained batch 294 in epoch 5, gen_loss = 0.40257355404102196, disc_loss = 0.03565257129898705
Trained batch 295 in epoch 5, gen_loss = 0.4023880984231427, disc_loss = 0.03570305507093655
Trained batch 296 in epoch 5, gen_loss = 0.4020573527423621, disc_loss = 0.03579743860112284
Trained batch 297 in epoch 5, gen_loss = 0.4020820051531664, disc_loss = 0.035824858678439195
Trained batch 298 in epoch 5, gen_loss = 0.4020111268280342, disc_loss = 0.03604230229987336
Trained batch 299 in epoch 5, gen_loss = 0.4021755455434322, disc_loss = 0.03773062661406584
Trained batch 300 in epoch 5, gen_loss = 0.4020216396183667, disc_loss = 0.03815486457970835
Trained batch 301 in epoch 5, gen_loss = 0.40179974496956694, disc_loss = 0.03859677012903394
Trained batch 302 in epoch 5, gen_loss = 0.4017146672844493, disc_loss = 0.038701231724724
Trained batch 303 in epoch 5, gen_loss = 0.4018748483473533, disc_loss = 0.03870946454538314
Trained batch 304 in epoch 5, gen_loss = 0.40165455883643664, disc_loss = 0.038708138796806214
Trained batch 305 in epoch 5, gen_loss = 0.4016007449404866, disc_loss = 0.03869055086264411
Trained batch 306 in epoch 5, gen_loss = 0.40147341787815094, disc_loss = 0.03863375102577834
Trained batch 307 in epoch 5, gen_loss = 0.4013454035021268, disc_loss = 0.03889154529239825
Trained batch 308 in epoch 5, gen_loss = 0.40150834263142643, disc_loss = 0.04014108339769157
Trained batch 309 in epoch 5, gen_loss = 0.401254973440401, disc_loss = 0.040065030652594064
Trained batch 310 in epoch 5, gen_loss = 0.4010922216429971, disc_loss = 0.04013974638318889
Trained batch 311 in epoch 5, gen_loss = 0.401142860404574, disc_loss = 0.04008216689190027
Trained batch 312 in epoch 5, gen_loss = 0.4011423382610559, disc_loss = 0.03997734283913855
Trained batch 313 in epoch 5, gen_loss = 0.4012003029892399, disc_loss = 0.039874997639147695
Trained batch 314 in epoch 5, gen_loss = 0.4012287192401432, disc_loss = 0.039824512426090974
Trained batch 315 in epoch 5, gen_loss = 0.40115216218783883, disc_loss = 0.039736023676342956
Trained batch 316 in epoch 5, gen_loss = 0.40112255288035337, disc_loss = 0.0396445272398572
Trained batch 317 in epoch 5, gen_loss = 0.401222510860776, disc_loss = 0.03957490713164245
Trained batch 318 in epoch 5, gen_loss = 0.40104095591086203, disc_loss = 0.03952207611282546
Trained batch 319 in epoch 5, gen_loss = 0.40106632369570433, disc_loss = 0.03943120975127386
Trained batch 320 in epoch 5, gen_loss = 0.40099636365505764, disc_loss = 0.0393274234621597
Trained batch 321 in epoch 5, gen_loss = 0.4011809697710209, disc_loss = 0.03926074965271277
Trained batch 322 in epoch 5, gen_loss = 0.4008305891656285, disc_loss = 0.039624077593403126
Trained batch 323 in epoch 5, gen_loss = 0.4009867012040851, disc_loss = 0.0409412132687493
Trained batch 324 in epoch 5, gen_loss = 0.40098366861159984, disc_loss = 0.040927630158212894
Trained batch 325 in epoch 5, gen_loss = 0.4007794252293973, disc_loss = 0.041020692628594056
Trained batch 326 in epoch 5, gen_loss = 0.40050101868056376, disc_loss = 0.04102234747396093
Trained batch 327 in epoch 5, gen_loss = 0.40055879418988055, disc_loss = 0.040923134054315684
Trained batch 328 in epoch 5, gen_loss = 0.4005393755019255, disc_loss = 0.04094227525089955
Trained batch 329 in epoch 5, gen_loss = 0.40041029060428796, disc_loss = 0.04087056497810408
Trained batch 330 in epoch 5, gen_loss = 0.4003850182467717, disc_loss = 0.040822258432609594
Trained batch 331 in epoch 5, gen_loss = 0.40016438340745775, disc_loss = 0.04075887743685204
Trained batch 332 in epoch 5, gen_loss = 0.4004051428030919, disc_loss = 0.04066683788533538
Trained batch 333 in epoch 5, gen_loss = 0.4003466820556247, disc_loss = 0.040625218549829735
Trained batch 334 in epoch 5, gen_loss = 0.40021783829624974, disc_loss = 0.040712866523136285
Trained batch 335 in epoch 5, gen_loss = 0.4002985176852062, disc_loss = 0.040637142703677194
Trained batch 336 in epoch 5, gen_loss = 0.40009161922804326, disc_loss = 0.04069915070310401
Trained batch 337 in epoch 5, gen_loss = 0.3997195527486547, disc_loss = 0.040941782220963875
Trained batch 338 in epoch 5, gen_loss = 0.4001337065193857, disc_loss = 0.04138837949473103
Trained batch 339 in epoch 5, gen_loss = 0.3998898653861354, disc_loss = 0.041338898096000776
Trained batch 340 in epoch 5, gen_loss = 0.39987566127630275, disc_loss = 0.04191577926932225
Trained batch 341 in epoch 5, gen_loss = 0.3998364770011595, disc_loss = 0.04306962348388682
Trained batch 342 in epoch 5, gen_loss = 0.3998066650448318, disc_loss = 0.04298309198989324
Trained batch 343 in epoch 5, gen_loss = 0.39972162588911003, disc_loss = 0.04293472771661432
Trained batch 344 in epoch 5, gen_loss = 0.3996766618628433, disc_loss = 0.042923306093038315
Trained batch 345 in epoch 5, gen_loss = 0.39961648973598646, disc_loss = 0.04285936972437254
Trained batch 346 in epoch 5, gen_loss = 0.3997157439804215, disc_loss = 0.042783060395266186
Trained batch 347 in epoch 5, gen_loss = 0.3996501734972685, disc_loss = 0.04270783973149902
Trained batch 348 in epoch 5, gen_loss = 0.39966474353925546, disc_loss = 0.0426736329959033
Trained batch 349 in epoch 5, gen_loss = 0.39955248939139504, disc_loss = 0.042851249301207386
Trained batch 350 in epoch 5, gen_loss = 0.3996695828998191, disc_loss = 0.04280952732722166
Trained batch 351 in epoch 5, gen_loss = 0.3997675707479092, disc_loss = 0.04280318179272316
Trained batch 352 in epoch 5, gen_loss = 0.3996822496733652, disc_loss = 0.04275386159145999
Trained batch 353 in epoch 5, gen_loss = 0.3996489919764174, disc_loss = 0.042648971856553315
Trained batch 354 in epoch 5, gen_loss = 0.39972097449739213, disc_loss = 0.0426464802647849
Trained batch 355 in epoch 5, gen_loss = 0.3999482063011507, disc_loss = 0.04286957472226624
Trained batch 356 in epoch 5, gen_loss = 0.3999528555559511, disc_loss = 0.04331816284929035
Trained batch 357 in epoch 5, gen_loss = 0.4000016001765954, disc_loss = 0.043350823876232056
Trained batch 358 in epoch 5, gen_loss = 0.40002594888210297, disc_loss = 0.043404293868854166
Trained batch 359 in epoch 5, gen_loss = 0.3999754353115956, disc_loss = 0.043623853647861525
Trained batch 360 in epoch 5, gen_loss = 0.39995389470928594, disc_loss = 0.04377038959237048
Trained batch 361 in epoch 5, gen_loss = 0.39995639886480666, disc_loss = 0.04368425857305311
Trained batch 362 in epoch 5, gen_loss = 0.40001382886049835, disc_loss = 0.04361446326458698
Trained batch 363 in epoch 5, gen_loss = 0.39997836664974035, disc_loss = 0.043503137141310065
Trained batch 364 in epoch 5, gen_loss = 0.3998954231200153, disc_loss = 0.043392212620987365
Trained batch 365 in epoch 5, gen_loss = 0.3996675325954547, disc_loss = 0.04335644611512448
Trained batch 366 in epoch 5, gen_loss = 0.3996788089947739, disc_loss = 0.04325236817434867
Trained batch 367 in epoch 5, gen_loss = 0.39952589648411324, disc_loss = 0.043184631866967284
Trained batch 368 in epoch 5, gen_loss = 0.39962725809757627, disc_loss = 0.04316545860194487
Trained batch 369 in epoch 5, gen_loss = 0.3996075139255137, disc_loss = 0.0431529492023401
Trained batch 370 in epoch 5, gen_loss = 0.39974776163416087, disc_loss = 0.04313030448206261
Trained batch 371 in epoch 5, gen_loss = 0.3997042310894817, disc_loss = 0.043035472361108044
Trained batch 372 in epoch 5, gen_loss = 0.3997034955040699, disc_loss = 0.04297079695057843
Trained batch 373 in epoch 5, gen_loss = 0.3998382756496496, disc_loss = 0.04288993798349461
Trained batch 374 in epoch 5, gen_loss = 0.3998362500270208, disc_loss = 0.042795857863811154
Trained batch 375 in epoch 5, gen_loss = 0.3997806880940148, disc_loss = 0.042692079729254435
Trained batch 376 in epoch 5, gen_loss = 0.3998292272302769, disc_loss = 0.04259339398895921
Trained batch 377 in epoch 5, gen_loss = 0.3997095475988413, disc_loss = 0.042513411748654174
Trained batch 378 in epoch 5, gen_loss = 0.39985024319632384, disc_loss = 0.042412424597970275
Trained batch 379 in epoch 5, gen_loss = 0.3998606453208547, disc_loss = 0.04231448375748618
Trained batch 380 in epoch 5, gen_loss = 0.4001122323155716, disc_loss = 0.04221525469830313
Trained batch 381 in epoch 5, gen_loss = 0.4003567570401112, disc_loss = 0.04215109968315371
Trained batch 382 in epoch 5, gen_loss = 0.40023819269617295, disc_loss = 0.04209231604504649
Trained batch 383 in epoch 5, gen_loss = 0.40008100172660005, disc_loss = 0.04199636972801576
Trained batch 384 in epoch 5, gen_loss = 0.4001521668263844, disc_loss = 0.04192231471450733
Trained batch 385 in epoch 5, gen_loss = 0.39998947605104646, disc_loss = 0.04185700727116384
Trained batch 386 in epoch 5, gen_loss = 0.4002263239880865, disc_loss = 0.04176572905354038
Trained batch 387 in epoch 5, gen_loss = 0.400178722384357, disc_loss = 0.04172863606417542
Trained batch 388 in epoch 5, gen_loss = 0.4001276524866761, disc_loss = 0.04180479236096766
Trained batch 389 in epoch 5, gen_loss = 0.40017255456783835, disc_loss = 0.04172742691470119
Trained batch 390 in epoch 5, gen_loss = 0.4003027499560505, disc_loss = 0.04166665222034897
Trained batch 391 in epoch 5, gen_loss = 0.4002711444865076, disc_loss = 0.04157699323027651
Trained batch 392 in epoch 5, gen_loss = 0.4002060330171925, disc_loss = 0.041485339139218494
Trained batch 393 in epoch 5, gen_loss = 0.40006300992318217, disc_loss = 0.04139920181227224
Trained batch 394 in epoch 5, gen_loss = 0.40014599022231523, disc_loss = 0.04132043311779116
Trained batch 395 in epoch 5, gen_loss = 0.400097711030582, disc_loss = 0.04122565383229151
Trained batch 396 in epoch 5, gen_loss = 0.40007339845826706, disc_loss = 0.0411379615736947
Trained batch 397 in epoch 5, gen_loss = 0.40004234528871035, disc_loss = 0.04104213524362933
Trained batch 398 in epoch 5, gen_loss = 0.40000448881982265, disc_loss = 0.040946799191823674
Trained batch 399 in epoch 5, gen_loss = 0.3997486996278167, disc_loss = 0.040868062529771126
Trained batch 400 in epoch 5, gen_loss = 0.3996587037074001, disc_loss = 0.04077561737701269
Trained batch 401 in epoch 5, gen_loss = 0.39954626015317973, disc_loss = 0.04068490335589219
Trained batch 402 in epoch 5, gen_loss = 0.3995399542023467, disc_loss = 0.040609029230601605
Trained batch 403 in epoch 5, gen_loss = 0.3994100116340831, disc_loss = 0.040522194102390365
Trained batch 404 in epoch 5, gen_loss = 0.3993628190991319, disc_loss = 0.04042902318099629
Trained batch 405 in epoch 5, gen_loss = 0.39941763184193907, disc_loss = 0.040337159672552456
Trained batch 406 in epoch 5, gen_loss = 0.39936269665965285, disc_loss = 0.04024516479358196
Trained batch 407 in epoch 5, gen_loss = 0.3995692368012433, disc_loss = 0.04016963092926387
Trained batch 408 in epoch 5, gen_loss = 0.39955617399990995, disc_loss = 0.04007759563707972
Trained batch 409 in epoch 5, gen_loss = 0.399593629742541, disc_loss = 0.03998536822391765
Trained batch 410 in epoch 5, gen_loss = 0.3994867464849259, disc_loss = 0.03989766138223954
Trained batch 411 in epoch 5, gen_loss = 0.3997163518322903, disc_loss = 0.039808365480479266
Trained batch 412 in epoch 5, gen_loss = 0.39962106037515127, disc_loss = 0.03971743179946353
Trained batch 413 in epoch 5, gen_loss = 0.399488507081633, disc_loss = 0.039627899103944195
Trained batch 414 in epoch 5, gen_loss = 0.39940079762993086, disc_loss = 0.03953700500192592
Trained batch 415 in epoch 5, gen_loss = 0.39946206368935794, disc_loss = 0.03945504601198571
Trained batch 416 in epoch 5, gen_loss = 0.39946262624195156, disc_loss = 0.03936650641753876
Trained batch 417 in epoch 5, gen_loss = 0.39945940477283376, disc_loss = 0.0392778177431486
Trained batch 418 in epoch 5, gen_loss = 0.3994295017033602, disc_loss = 0.03919255194978828
Trained batch 419 in epoch 5, gen_loss = 0.39938978513791445, disc_loss = 0.03911078623551432
Trained batch 420 in epoch 5, gen_loss = 0.39941717620558526, disc_loss = 0.039025770354852295
Trained batch 421 in epoch 5, gen_loss = 0.39927847679898637, disc_loss = 0.03893754154667744
Trained batch 422 in epoch 5, gen_loss = 0.39919019735310374, disc_loss = 0.03885042356975579
Trained batch 423 in epoch 5, gen_loss = 0.39927117642507237, disc_loss = 0.03876625377666161
Trained batch 424 in epoch 5, gen_loss = 0.39919641526306376, disc_loss = 0.03869203547207529
Trained batch 425 in epoch 5, gen_loss = 0.3991167512787899, disc_loss = 0.03862215947450528
Trained batch 426 in epoch 5, gen_loss = 0.399154825253844, disc_loss = 0.03853986138969756
Trained batch 427 in epoch 5, gen_loss = 0.3990901415802051, disc_loss = 0.03845527993540158
Trained batch 428 in epoch 5, gen_loss = 0.3990703215062757, disc_loss = 0.03837641060112439
Trained batch 429 in epoch 5, gen_loss = 0.3990788918248443, disc_loss = 0.03829580518649891
Trained batch 430 in epoch 5, gen_loss = 0.3989525076062386, disc_loss = 0.038213758817182426
Trained batch 431 in epoch 5, gen_loss = 0.39898562993578335, disc_loss = 0.03813155628692281
Trained batch 432 in epoch 5, gen_loss = 0.39908528338266025, disc_loss = 0.03805244816429526
Trained batch 433 in epoch 5, gen_loss = 0.399045249593148, disc_loss = 0.03797047170365126
Trained batch 434 in epoch 5, gen_loss = 0.3989839026640201, disc_loss = 0.03789012780782349
Trained batch 435 in epoch 5, gen_loss = 0.3989611724989677, disc_loss = 0.03780872154037827
Trained batch 436 in epoch 5, gen_loss = 0.39873242633975614, disc_loss = 0.0377316092062652
Trained batch 437 in epoch 5, gen_loss = 0.39888609765463223, disc_loss = 0.03765711793277336
Trained batch 438 in epoch 5, gen_loss = 0.3988332802383123, disc_loss = 0.03757630540339111
Trained batch 439 in epoch 5, gen_loss = 0.3987632323733785, disc_loss = 0.03749577515700366
Trained batch 440 in epoch 5, gen_loss = 0.3987177390427816, disc_loss = 0.037416161388811355
Trained batch 441 in epoch 5, gen_loss = 0.39880705112380677, disc_loss = 0.03733704304528039
Trained batch 442 in epoch 5, gen_loss = 0.3987285008077966, disc_loss = 0.03725747113945446
Trained batch 443 in epoch 5, gen_loss = 0.39857288205006103, disc_loss = 0.03718676162765126
Trained batch 444 in epoch 5, gen_loss = 0.3986981984269753, disc_loss = 0.03711044665692855
Trained batch 445 in epoch 5, gen_loss = 0.3987601625611964, disc_loss = 0.03704590547277546
Trained batch 446 in epoch 5, gen_loss = 0.3986481022448081, disc_loss = 0.03697007945118893
Trained batch 447 in epoch 5, gen_loss = 0.39874288542861386, disc_loss = 0.03689849724755082
Trained batch 448 in epoch 5, gen_loss = 0.3988439464290317, disc_loss = 0.03682503289826223
Trained batch 449 in epoch 5, gen_loss = 0.3987839029563798, disc_loss = 0.03674905988258413
Trained batch 450 in epoch 5, gen_loss = 0.3987319805471437, disc_loss = 0.03667831881577872
Trained batch 451 in epoch 5, gen_loss = 0.39883018888335314, disc_loss = 0.03661620308437995
Trained batch 452 in epoch 5, gen_loss = 0.3987738232541558, disc_loss = 0.03659850589814853
Trained batch 453 in epoch 5, gen_loss = 0.3987396638758382, disc_loss = 0.03653066712385454
Trained batch 454 in epoch 5, gen_loss = 0.3989350874672879, disc_loss = 0.03646642256625365
Trained batch 455 in epoch 5, gen_loss = 0.3988730890774413, disc_loss = 0.03639853320451118
Trained batch 456 in epoch 5, gen_loss = 0.3988888945503882, disc_loss = 0.03632499660284786
Trained batch 457 in epoch 5, gen_loss = 0.3989056265184973, disc_loss = 0.03625584387918934
Trained batch 458 in epoch 5, gen_loss = 0.39903669033305056, disc_loss = 0.03618317732484991
Trained batch 459 in epoch 5, gen_loss = 0.39906954574196235, disc_loss = 0.03610940064966638
Trained batch 460 in epoch 5, gen_loss = 0.3990564075765279, disc_loss = 0.03603874810455153
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.3888321816921234, disc_loss = 0.0032594287768006325
Trained batch 1 in epoch 6, gen_loss = 0.4106754809617996, disc_loss = 0.003736640326678753
Trained batch 2 in epoch 6, gen_loss = 0.40677108367284137, disc_loss = 0.0037878023770948253
Trained batch 3 in epoch 6, gen_loss = 0.415398932993412, disc_loss = 0.0036653311690315604
Trained batch 4 in epoch 6, gen_loss = 0.4113597571849823, disc_loss = 0.0033675195649266244
Trained batch 5 in epoch 6, gen_loss = 0.41588984926541644, disc_loss = 0.003337750482993821
Trained batch 6 in epoch 6, gen_loss = 0.41989360962595257, disc_loss = 0.0031787199966077295
Trained batch 7 in epoch 6, gen_loss = 0.42263535037636757, disc_loss = 0.003965087729739025
Trained batch 8 in epoch 6, gen_loss = 0.4141428569952647, disc_loss = 0.004193903386799825
Trained batch 9 in epoch 6, gen_loss = 0.40797737836837766, disc_loss = 0.00447132729459554
Trained batch 10 in epoch 6, gen_loss = 0.409103044054725, disc_loss = 0.00457178845747628
Trained batch 11 in epoch 6, gen_loss = 0.41420549899339676, disc_loss = 0.0045064381750610965
Trained batch 12 in epoch 6, gen_loss = 0.412406882414451, disc_loss = 0.00449102961171705
Trained batch 13 in epoch 6, gen_loss = 0.4156459016459329, disc_loss = 0.004817028280480632
Trained batch 14 in epoch 6, gen_loss = 0.41801090240478517, disc_loss = 0.004707206226885319
Trained batch 15 in epoch 6, gen_loss = 0.4162420481443405, disc_loss = 0.004552894999505952
Trained batch 16 in epoch 6, gen_loss = 0.4161936763454886, disc_loss = 0.005212735302527161
Trained batch 17 in epoch 6, gen_loss = 0.4153055664565828, disc_loss = 0.005329255169878404
Trained batch 18 in epoch 6, gen_loss = 0.41580354853680257, disc_loss = 0.0054972413927316666
Trained batch 19 in epoch 6, gen_loss = 0.4172998771071434, disc_loss = 0.0061847658827900885
Trained batch 20 in epoch 6, gen_loss = 0.4159753734157199, disc_loss = 0.006223301358875774
Trained batch 21 in epoch 6, gen_loss = 0.4147694598544728, disc_loss = 0.006114397377876396
Trained batch 22 in epoch 6, gen_loss = 0.4128203728924627, disc_loss = 0.005994659079157788
Trained batch 23 in epoch 6, gen_loss = 0.41209112976988155, disc_loss = 0.005898892122786492
Trained batch 24 in epoch 6, gen_loss = 0.4112489867210388, disc_loss = 0.005834554135799408
Trained batch 25 in epoch 6, gen_loss = 0.41161415210137, disc_loss = 0.0059291254012630535
Trained batch 26 in epoch 6, gen_loss = 0.411405137291661, disc_loss = 0.005802958315514304
Trained batch 27 in epoch 6, gen_loss = 0.41018590331077576, disc_loss = 0.005720478407706001
Trained batch 28 in epoch 6, gen_loss = 0.4111067786298949, disc_loss = 0.005630552415446988
Trained batch 29 in epoch 6, gen_loss = 0.41221284568309785, disc_loss = 0.005577043847491344
Trained batch 30 in epoch 6, gen_loss = 0.4122652526824705, disc_loss = 0.0054738389012674174
Trained batch 31 in epoch 6, gen_loss = 0.41262557730078697, disc_loss = 0.005564375918766018
Trained batch 32 in epoch 6, gen_loss = 0.41329414374900586, disc_loss = 0.005580810540722627
Trained batch 33 in epoch 6, gen_loss = 0.4131509863278445, disc_loss = 0.005652906886740204
Trained batch 34 in epoch 6, gen_loss = 0.4127894239766257, disc_loss = 0.0058701879411403625
Trained batch 35 in epoch 6, gen_loss = 0.41248145120011437, disc_loss = 0.006116295796042929
Trained batch 36 in epoch 6, gen_loss = 0.4127982492382462, disc_loss = 0.006330759635799237
Trained batch 37 in epoch 6, gen_loss = 0.4134711819259744, disc_loss = 0.006458289596546245
Trained batch 38 in epoch 6, gen_loss = 0.41562947630882263, disc_loss = 0.006453248690097378
Trained batch 39 in epoch 6, gen_loss = 0.4159480258822441, disc_loss = 0.007034491788363084
Trained batch 40 in epoch 6, gen_loss = 0.4157276567889423, disc_loss = 0.007724037569970256
Trained batch 41 in epoch 6, gen_loss = 0.41486282504740213, disc_loss = 0.00781579674332447
Trained batch 42 in epoch 6, gen_loss = 0.4145204986250678, disc_loss = 0.008366326211280254
Trained batch 43 in epoch 6, gen_loss = 0.41599243540655484, disc_loss = 0.0083724595553411
Trained batch 44 in epoch 6, gen_loss = 0.41562422381507025, disc_loss = 0.008268482377752661
Trained batch 45 in epoch 6, gen_loss = 0.4146270356748415, disc_loss = 0.008150112855693569
Trained batch 46 in epoch 6, gen_loss = 0.41340075021094463, disc_loss = 0.00805100311148674
Trained batch 47 in epoch 6, gen_loss = 0.41189740039408207, disc_loss = 0.008016453124582767
Trained batch 48 in epoch 6, gen_loss = 0.4110073647936996, disc_loss = 0.007982152229060933
Trained batch 49 in epoch 6, gen_loss = 0.41088571786880496, disc_loss = 0.007890258920378984
Trained batch 50 in epoch 6, gen_loss = 0.4092499794913273, disc_loss = 0.007799552269645182
Trained batch 51 in epoch 6, gen_loss = 0.4095915768008966, disc_loss = 0.007714018870431643
Trained batch 52 in epoch 6, gen_loss = 0.4085796908387598, disc_loss = 0.007857678756820705
Trained batch 53 in epoch 6, gen_loss = 0.40926116594561823, disc_loss = 0.007798826735880639
Trained batch 54 in epoch 6, gen_loss = 0.4102699539878152, disc_loss = 0.007809365997937592
Trained batch 55 in epoch 6, gen_loss = 0.4103566903088774, disc_loss = 0.007774048376761909
Trained batch 56 in epoch 6, gen_loss = 0.409882128238678, disc_loss = 0.007786937801396115
Trained batch 57 in epoch 6, gen_loss = 0.4093276663073178, disc_loss = 0.007758040334387073
Trained batch 58 in epoch 6, gen_loss = 0.4084437166230153, disc_loss = 0.007661953580297403
Trained batch 59 in epoch 6, gen_loss = 0.4075620626409849, disc_loss = 0.0076046416264337795
Trained batch 60 in epoch 6, gen_loss = 0.4073678650816933, disc_loss = 0.007521748309955001
Trained batch 61 in epoch 6, gen_loss = 0.4067704095955818, disc_loss = 0.007436696083224829
Trained batch 62 in epoch 6, gen_loss = 0.4064754455808609, disc_loss = 0.007386411639994809
Trained batch 63 in epoch 6, gen_loss = 0.4065098762512207, disc_loss = 0.007332063167268643
Trained batch 64 in epoch 6, gen_loss = 0.4073255575620211, disc_loss = 0.007323590017711887
Trained batch 65 in epoch 6, gen_loss = 0.40716050429777667, disc_loss = 0.007247261784152325
Trained batch 66 in epoch 6, gen_loss = 0.4067472223915271, disc_loss = 0.007179275283645561
Trained batch 67 in epoch 6, gen_loss = 0.4063657723805484, disc_loss = 0.00715376268592937
Trained batch 68 in epoch 6, gen_loss = 0.4060986499855484, disc_loss = 0.007154672605700899
Trained batch 69 in epoch 6, gen_loss = 0.4064029174191611, disc_loss = 0.007094376018669989
Trained batch 70 in epoch 6, gen_loss = 0.4061248520730247, disc_loss = 0.007036397259839824
Trained batch 71 in epoch 6, gen_loss = 0.40636995972858536, disc_loss = 0.0069766591768711805
Trained batch 72 in epoch 6, gen_loss = 0.4056135309885626, disc_loss = 0.0069227354116227525
Trained batch 73 in epoch 6, gen_loss = 0.4053785398199752, disc_loss = 0.00686353533780454
Trained batch 74 in epoch 6, gen_loss = 0.4055381218592326, disc_loss = 0.006846679778148731
Trained batch 75 in epoch 6, gen_loss = 0.40641286929971293, disc_loss = 0.006797216514027433
Trained batch 76 in epoch 6, gen_loss = 0.40647916747378066, disc_loss = 0.006747309602313228
Trained batch 77 in epoch 6, gen_loss = 0.40683786418193424, disc_loss = 0.006731460026154916
Trained batch 78 in epoch 6, gen_loss = 0.4067039006873022, disc_loss = 0.006685205758843995
Trained batch 79 in epoch 6, gen_loss = 0.4064476564526558, disc_loss = 0.00665927508380264
Trained batch 80 in epoch 6, gen_loss = 0.4066342328801567, disc_loss = 0.0066917382387651336
Trained batch 81 in epoch 6, gen_loss = 0.40703702300060085, disc_loss = 0.006801916343137258
Trained batch 82 in epoch 6, gen_loss = 0.40756668671067936, disc_loss = 0.006770196741065347
Trained batch 83 in epoch 6, gen_loss = 0.40767113332237515, disc_loss = 0.0067725827850933585
Trained batch 84 in epoch 6, gen_loss = 0.4075987896498512, disc_loss = 0.006730163267211002
Trained batch 85 in epoch 6, gen_loss = 0.40799346323623215, disc_loss = 0.006701974972519417
Trained batch 86 in epoch 6, gen_loss = 0.40826914879097337, disc_loss = 0.006728937212463425
Trained batch 87 in epoch 6, gen_loss = 0.408022172071717, disc_loss = 0.006704110890330578
Trained batch 88 in epoch 6, gen_loss = 0.4081610357493497, disc_loss = 0.006752893762935078
Trained batch 89 in epoch 6, gen_loss = 0.40836397409439085, disc_loss = 0.00682617713076373
Trained batch 90 in epoch 6, gen_loss = 0.4082452255290943, disc_loss = 0.0068178181843525105
Trained batch 91 in epoch 6, gen_loss = 0.4076097970423491, disc_loss = 0.006768871058264504
Trained batch 92 in epoch 6, gen_loss = 0.4078008446001237, disc_loss = 0.006781566697823745
Trained batch 93 in epoch 6, gen_loss = 0.4080344517814352, disc_loss = 0.00676281474273097
Trained batch 94 in epoch 6, gen_loss = 0.4083446386613344, disc_loss = 0.006717359505005573
Trained batch 95 in epoch 6, gen_loss = 0.4079440015678604, disc_loss = 0.006672279123449698
Trained batch 96 in epoch 6, gen_loss = 0.4080516502414782, disc_loss = 0.006722837043254031
Trained batch 97 in epoch 6, gen_loss = 0.4082468967048489, disc_loss = 0.006815330039861859
Trained batch 98 in epoch 6, gen_loss = 0.407816226434226, disc_loss = 0.006811999762901152
Trained batch 99 in epoch 6, gen_loss = 0.40737099319696424, disc_loss = 0.00676613007672131
Trained batch 100 in epoch 6, gen_loss = 0.4069334864616394, disc_loss = 0.0067268073106977605
Trained batch 101 in epoch 6, gen_loss = 0.4065219216486987, disc_loss = 0.006689444882795215
Trained batch 102 in epoch 6, gen_loss = 0.40617967375273845, disc_loss = 0.006648626106167303
Trained batch 103 in epoch 6, gen_loss = 0.4073319684427518, disc_loss = 0.006711828952225355
Trained batch 104 in epoch 6, gen_loss = 0.4073040783405304, disc_loss = 0.006699296202333201
Trained batch 105 in epoch 6, gen_loss = 0.4077253316370946, disc_loss = 0.006663525859245433
Trained batch 106 in epoch 6, gen_loss = 0.40762179560750444, disc_loss = 0.00662633561894785
Trained batch 107 in epoch 6, gen_loss = 0.4077228506406148, disc_loss = 0.0066073402801218135
Trained batch 108 in epoch 6, gen_loss = 0.4071626181996197, disc_loss = 0.006583830749684381
Trained batch 109 in epoch 6, gen_loss = 0.40729361935095354, disc_loss = 0.006562075228430331
Trained batch 110 in epoch 6, gen_loss = 0.4080921535019402, disc_loss = 0.006629191756433061
Trained batch 111 in epoch 6, gen_loss = 0.40787956065365244, disc_loss = 0.007607618760500502
Trained batch 112 in epoch 6, gen_loss = 0.40732425978753417, disc_loss = 0.011063998134444114
Trained batch 113 in epoch 6, gen_loss = 0.4070061285767639, disc_loss = 0.012367423442028985
Trained batch 114 in epoch 6, gen_loss = 0.40702186434165294, disc_loss = 0.013883794145658612
Trained batch 115 in epoch 6, gen_loss = 0.4069384927379674, disc_loss = 0.01750534491669708
Trained batch 116 in epoch 6, gen_loss = 0.4073528762047107, disc_loss = 0.02091192232612043
Trained batch 117 in epoch 6, gen_loss = 0.4075249367851322, disc_loss = 0.02335489984656984
Trained batch 118 in epoch 6, gen_loss = 0.4070806453207962, disc_loss = 0.025084950106155846
Trained batch 119 in epoch 6, gen_loss = 0.4067030929028988, disc_loss = 0.026949561152529593
Trained batch 120 in epoch 6, gen_loss = 0.40638288830922653, disc_loss = 0.0282036053874984
Trained batch 121 in epoch 6, gen_loss = 0.40621527809588637, disc_loss = 0.028786288129669598
Trained batch 122 in epoch 6, gen_loss = 0.4059336052192905, disc_loss = 0.02899213718076244
Trained batch 123 in epoch 6, gen_loss = 0.4054680060475103, disc_loss = 0.02912530872122114
Trained batch 124 in epoch 6, gen_loss = 0.4051459791660309, disc_loss = 0.029018393261358143
Trained batch 125 in epoch 6, gen_loss = 0.40509153476783205, disc_loss = 0.028943994346754775
Trained batch 126 in epoch 6, gen_loss = 0.40501969043664104, disc_loss = 0.028842251731346795
Trained batch 127 in epoch 6, gen_loss = 0.40473012207075953, disc_loss = 0.02868789658350579
Trained batch 128 in epoch 6, gen_loss = 0.40462319056193036, disc_loss = 0.028614932062941814
Trained batch 129 in epoch 6, gen_loss = 0.4042783689040404, disc_loss = 0.028557968338449986
Trained batch 130 in epoch 6, gen_loss = 0.4051592766328622, disc_loss = 0.028637037731579128
Trained batch 131 in epoch 6, gen_loss = 0.4057982674602306, disc_loss = 0.028488679392136295
Trained batch 132 in epoch 6, gen_loss = 0.405976561899472, disc_loss = 0.028335146184072346
Trained batch 133 in epoch 6, gen_loss = 0.4055953103659758, disc_loss = 0.028165381097707397
Trained batch 134 in epoch 6, gen_loss = 0.40558285470362065, disc_loss = 0.02799454892433628
Trained batch 135 in epoch 6, gen_loss = 0.4050741278949906, disc_loss = 0.02791117789970218
Trained batch 136 in epoch 6, gen_loss = 0.4052959848059355, disc_loss = 0.02792515272077472
Trained batch 137 in epoch 6, gen_loss = 0.40536015383575275, disc_loss = 0.027761062926045903
Trained batch 138 in epoch 6, gen_loss = 0.40518410707549224, disc_loss = 0.027591984533108502
Trained batch 139 in epoch 6, gen_loss = 0.40458351586546215, disc_loss = 0.028102486635491784
Trained batch 140 in epoch 6, gen_loss = 0.40518233116636887, disc_loss = 0.029560786138572697
Trained batch 141 in epoch 6, gen_loss = 0.4051695000117933, disc_loss = 0.029409856799478367
Trained batch 142 in epoch 6, gen_loss = 0.40532213512000503, disc_loss = 0.029368469701637024
Trained batch 143 in epoch 6, gen_loss = 0.4050212496270736, disc_loss = 0.02927613518517723
Trained batch 144 in epoch 6, gen_loss = 0.40473559930406766, disc_loss = 0.029130854484914193
Trained batch 145 in epoch 6, gen_loss = 0.40474311456288375, disc_loss = 0.0290408120825504
Trained batch 146 in epoch 6, gen_loss = 0.4043000089067991, disc_loss = 0.02890438828649012
Trained batch 147 in epoch 6, gen_loss = 0.4039114182059829, disc_loss = 0.029078352883319697
Trained batch 148 in epoch 6, gen_loss = 0.40364077607257254, disc_loss = 0.029948163641641705
Trained batch 149 in epoch 6, gen_loss = 0.4028141975402832, disc_loss = 0.03185539532608042
Trained batch 150 in epoch 6, gen_loss = 0.40264850499614185, disc_loss = 0.03359869170767434
Trained batch 151 in epoch 6, gen_loss = 0.40217387244889613, disc_loss = 0.03442130815145854
Trained batch 152 in epoch 6, gen_loss = 0.4022841543154, disc_loss = 0.03448385549435282
Trained batch 153 in epoch 6, gen_loss = 0.40217947611561067, disc_loss = 0.03438583999878255
Trained batch 154 in epoch 6, gen_loss = 0.40191232562065127, disc_loss = 0.03422556949268666
Trained batch 155 in epoch 6, gen_loss = 0.4018522350069804, disc_loss = 0.03407239243059825
Trained batch 156 in epoch 6, gen_loss = 0.4015404348540458, disc_loss = 0.034047527619857035
Trained batch 157 in epoch 6, gen_loss = 0.40177458883086337, disc_loss = 0.03414487601935722
Trained batch 158 in epoch 6, gen_loss = 0.4018103703387878, disc_loss = 0.03426357130402898
Trained batch 159 in epoch 6, gen_loss = 0.40119692478328944, disc_loss = 0.034897848604305184
Trained batch 160 in epoch 6, gen_loss = 0.4015150181254985, disc_loss = 0.038266652502316215
Trained batch 161 in epoch 6, gen_loss = 0.400897631858602, disc_loss = 0.039198962455603906
Trained batch 162 in epoch 6, gen_loss = 0.4010428245082223, disc_loss = 0.03960080203840201
Trained batch 163 in epoch 6, gen_loss = 0.4008440253574674, disc_loss = 0.03956909919663037
Trained batch 164 in epoch 6, gen_loss = 0.40058642968986974, disc_loss = 0.039481495288341786
Trained batch 165 in epoch 6, gen_loss = 0.4009203311190548, disc_loss = 0.03943414280488414
Trained batch 166 in epoch 6, gen_loss = 0.4008000259270925, disc_loss = 0.03940800143667904
Trained batch 167 in epoch 6, gen_loss = 0.4011561336616675, disc_loss = 0.03926945024397269
Trained batch 168 in epoch 6, gen_loss = 0.40124898002697873, disc_loss = 0.039107920867859344
Trained batch 169 in epoch 6, gen_loss = 0.40133381819023806, disc_loss = 0.039122334419859246
Trained batch 170 in epoch 6, gen_loss = 0.40154102723500884, disc_loss = 0.039635507282338035
Trained batch 171 in epoch 6, gen_loss = 0.40110396004693455, disc_loss = 0.03969231654137243
Trained batch 172 in epoch 6, gen_loss = 0.4004791101623822, disc_loss = 0.03958920126840085
Trained batch 173 in epoch 6, gen_loss = 0.4002602795759837, disc_loss = 0.03951500964367056
Trained batch 174 in epoch 6, gen_loss = 0.399838821547372, disc_loss = 0.03934105056870196
Trained batch 175 in epoch 6, gen_loss = 0.3996131496334618, disc_loss = 0.04013340464205777
Trained batch 176 in epoch 6, gen_loss = 0.3998030078949901, disc_loss = 0.04282565929632276
Trained batch 177 in epoch 6, gen_loss = 0.39998908140016404, disc_loss = 0.04375268980531085
Trained batch 178 in epoch 6, gen_loss = 0.3993842415303491, disc_loss = 0.044586483837890975
Trained batch 179 in epoch 6, gen_loss = 0.3986549029747645, disc_loss = 0.045460450578118775
Trained batch 180 in epoch 6, gen_loss = 0.3985160093610458, disc_loss = 0.045788225394966936
Trained batch 181 in epoch 6, gen_loss = 0.3983672634585873, disc_loss = 0.045905172058565355
Trained batch 182 in epoch 6, gen_loss = 0.39819410117597526, disc_loss = 0.04600969817148409
Trained batch 183 in epoch 6, gen_loss = 0.39803299647958384, disc_loss = 0.04590408478828106
Trained batch 184 in epoch 6, gen_loss = 0.3984285900721679, disc_loss = 0.045874817902222274
Trained batch 185 in epoch 6, gen_loss = 0.3985005860687584, disc_loss = 0.04567020289444675
Trained batch 186 in epoch 6, gen_loss = 0.3984218306719938, disc_loss = 0.04548480841928824
Trained batch 187 in epoch 6, gen_loss = 0.39854911064847987, disc_loss = 0.045276206101915066
Trained batch 188 in epoch 6, gen_loss = 0.398633936567912, disc_loss = 0.045134901188599766
Trained batch 189 in epoch 6, gen_loss = 0.39854963751215683, disc_loss = 0.04497223569594912
Trained batch 190 in epoch 6, gen_loss = 0.3985633889105932, disc_loss = 0.04476640065424924
Trained batch 191 in epoch 6, gen_loss = 0.39829275058582425, disc_loss = 0.045286056974873645
Trained batch 192 in epoch 6, gen_loss = 0.39829875690949396, disc_loss = 0.045647562130407424
Trained batch 193 in epoch 6, gen_loss = 0.39833414892560426, disc_loss = 0.04563374318225674
Trained batch 194 in epoch 6, gen_loss = 0.3980229383859879, disc_loss = 0.04544730555767623
Trained batch 195 in epoch 6, gen_loss = 0.3974088442568876, disc_loss = 0.045373121795615146
Trained batch 196 in epoch 6, gen_loss = 0.3976504596961936, disc_loss = 0.04524917744199372
Trained batch 197 in epoch 6, gen_loss = 0.39741227738182955, disc_loss = 0.04512629068734105
Trained batch 198 in epoch 6, gen_loss = 0.3974311604871223, disc_loss = 0.044998157017129524
Trained batch 199 in epoch 6, gen_loss = 0.3968848280608654, disc_loss = 0.04534591694944538
Trained batch 200 in epoch 6, gen_loss = 0.3970559326866966, disc_loss = 0.046956407986998336
Trained batch 201 in epoch 6, gen_loss = 0.39710269750344873, disc_loss = 0.04703458698839871
Trained batch 202 in epoch 6, gen_loss = 0.3969285414723927, disc_loss = 0.04684193461348894
Trained batch 203 in epoch 6, gen_loss = 0.3967831773208637, disc_loss = 0.04663303858879041
Trained batch 204 in epoch 6, gen_loss = 0.39699983233358804, disc_loss = 0.046431832225629834
Trained batch 205 in epoch 6, gen_loss = 0.39681299103116524, disc_loss = 0.046239825893528035
Trained batch 206 in epoch 6, gen_loss = 0.39681340487682876, disc_loss = 0.046035247656926154
Trained batch 207 in epoch 6, gen_loss = 0.3971208826853679, disc_loss = 0.04584368353243917
Trained batch 208 in epoch 6, gen_loss = 0.3970402514820464, disc_loss = 0.045790988069615866
Trained batch 209 in epoch 6, gen_loss = 0.3970168098097756, disc_loss = 0.045692708494053
Trained batch 210 in epoch 6, gen_loss = 0.3966097987093632, disc_loss = 0.04562344658960946
Trained batch 211 in epoch 6, gen_loss = 0.3969287071025597, disc_loss = 0.046154397618869004
Trained batch 212 in epoch 6, gen_loss = 0.39664730681499966, disc_loss = 0.047267529667473177
Trained batch 213 in epoch 6, gen_loss = 0.3968259303647781, disc_loss = 0.04862870964456663
Trained batch 214 in epoch 6, gen_loss = 0.39675745922465655, disc_loss = 0.04856090489341769
Trained batch 215 in epoch 6, gen_loss = 0.3964346240240115, disc_loss = 0.04867749180886204
Trained batch 216 in epoch 6, gen_loss = 0.396354476839716, disc_loss = 0.04854804764969558
Trained batch 217 in epoch 6, gen_loss = 0.3961879377244809, disc_loss = 0.04834231938803654
Trained batch 218 in epoch 6, gen_loss = 0.39626754609417153, disc_loss = 0.04816668115228789
Trained batch 219 in epoch 6, gen_loss = 0.3962360204620795, disc_loss = 0.048018509783485736
Trained batch 220 in epoch 6, gen_loss = 0.3962492613770843, disc_loss = 0.04784962085994356
Trained batch 221 in epoch 6, gen_loss = 0.395862888376992, disc_loss = 0.04785681939956539
Trained batch 222 in epoch 6, gen_loss = 0.39628132389265325, disc_loss = 0.048073304887034096
Trained batch 223 in epoch 6, gen_loss = 0.3960114974262459, disc_loss = 0.0489647543571274
Trained batch 224 in epoch 6, gen_loss = 0.3958725848462847, disc_loss = 0.05067252749680645
Trained batch 225 in epoch 6, gen_loss = 0.3957786550827786, disc_loss = 0.050856181687213876
Trained batch 226 in epoch 6, gen_loss = 0.3956155461886906, disc_loss = 0.05084047398718673
Trained batch 227 in epoch 6, gen_loss = 0.395638460783582, disc_loss = 0.05078980922515161
Trained batch 228 in epoch 6, gen_loss = 0.39589165404894466, disc_loss = 0.05065658398472814
Trained batch 229 in epoch 6, gen_loss = 0.39585687116436336, disc_loss = 0.05052156859259729
Trained batch 230 in epoch 6, gen_loss = 0.3959067763188185, disc_loss = 0.05055636394410132
Trained batch 231 in epoch 6, gen_loss = 0.39604000348983137, disc_loss = 0.05074588120573778
Trained batch 232 in epoch 6, gen_loss = 0.3957407622889899, disc_loss = 0.050920585429199965
Trained batch 233 in epoch 6, gen_loss = 0.39580732367487037, disc_loss = 0.050770062900498576
Trained batch 234 in epoch 6, gen_loss = 0.3958902620254679, disc_loss = 0.0507006502323883
Trained batch 235 in epoch 6, gen_loss = 0.39576065881272493, disc_loss = 0.050601037593076985
Trained batch 236 in epoch 6, gen_loss = 0.3954884560802315, disc_loss = 0.05055737419482242
Trained batch 237 in epoch 6, gen_loss = 0.39577091115863383, disc_loss = 0.0503815508187365
Trained batch 238 in epoch 6, gen_loss = 0.39575273646470394, disc_loss = 0.05031702287444478
Trained batch 239 in epoch 6, gen_loss = 0.3958435175319513, disc_loss = 0.05027216673188377
Trained batch 240 in epoch 6, gen_loss = 0.39574895298332596, disc_loss = 0.050115660477344615
Trained batch 241 in epoch 6, gen_loss = 0.39580086637134393, disc_loss = 0.050138354712273646
Trained batch 242 in epoch 6, gen_loss = 0.3957782500565297, disc_loss = 0.05081938959393696
Trained batch 243 in epoch 6, gen_loss = 0.39603106359966467, disc_loss = 0.051209476741114784
Trained batch 244 in epoch 6, gen_loss = 0.3960541557292549, disc_loss = 0.051024653938389855
Trained batch 245 in epoch 6, gen_loss = 0.3961902993723629, disc_loss = 0.05084721511135226
Trained batch 246 in epoch 6, gen_loss = 0.3964833365036891, disc_loss = 0.05069665773206123
Trained batch 247 in epoch 6, gen_loss = 0.3965892357931983, disc_loss = 0.05051143282570035
Trained batch 248 in epoch 6, gen_loss = 0.3967028948437258, disc_loss = 0.05032059057133205
Trained batch 249 in epoch 6, gen_loss = 0.3968107225894928, disc_loss = 0.050137287156656385
Trained batch 250 in epoch 6, gen_loss = 0.39676403334416244, disc_loss = 0.049946797231538775
Trained batch 251 in epoch 6, gen_loss = 0.3967543810842529, disc_loss = 0.04976282814343918
Trained batch 252 in epoch 6, gen_loss = 0.3969388958729303, disc_loss = 0.04959224007026156
Trained batch 253 in epoch 6, gen_loss = 0.39716379039400207, disc_loss = 0.04940616891363738
Trained batch 254 in epoch 6, gen_loss = 0.3974467783581977, disc_loss = 0.049226949300945684
Trained batch 255 in epoch 6, gen_loss = 0.3976405345601961, disc_loss = 0.04907880894734262
Trained batch 256 in epoch 6, gen_loss = 0.3977981893932773, disc_loss = 0.048896906965372335
Trained batch 257 in epoch 6, gen_loss = 0.3978658468686333, disc_loss = 0.04871946800131957
Trained batch 258 in epoch 6, gen_loss = 0.3978786084182474, disc_loss = 0.04854352404201641
Trained batch 259 in epoch 6, gen_loss = 0.39785730632451866, disc_loss = 0.048371729714115366
Trained batch 260 in epoch 6, gen_loss = 0.3980619554547058, disc_loss = 0.04819653206058846
Trained batch 261 in epoch 6, gen_loss = 0.3979761471957651, disc_loss = 0.048030575458315836
Trained batch 262 in epoch 6, gen_loss = 0.3980009493492402, disc_loss = 0.04786290990599491
Trained batch 263 in epoch 6, gen_loss = 0.39782587043715245, disc_loss = 0.04769175610272214
Trained batch 264 in epoch 6, gen_loss = 0.3976841141592781, disc_loss = 0.04755245011194416
Trained batch 265 in epoch 6, gen_loss = 0.39769025527893154, disc_loss = 0.04739777268876875
Trained batch 266 in epoch 6, gen_loss = 0.3974854125735465, disc_loss = 0.04729008527946997
Trained batch 267 in epoch 6, gen_loss = 0.39745199735929715, disc_loss = 0.04734637461595738
Trained batch 268 in epoch 6, gen_loss = 0.3975554843152766, disc_loss = 0.047839433797825556
Trained batch 269 in epoch 6, gen_loss = 0.3971085438021907, disc_loss = 0.04798983521587043
Trained batch 270 in epoch 6, gen_loss = 0.3969363167717008, disc_loss = 0.04788016023224295
Trained batch 271 in epoch 6, gen_loss = 0.3969027505201452, disc_loss = 0.047736178167671076
Trained batch 272 in epoch 6, gen_loss = 0.3968713325021904, disc_loss = 0.04768175429974993
Trained batch 273 in epoch 6, gen_loss = 0.39668596661003835, disc_loss = 0.047771338592657316
Trained batch 274 in epoch 6, gen_loss = 0.39724631157788365, disc_loss = 0.04782157891345295
Trained batch 275 in epoch 6, gen_loss = 0.39748177504625876, disc_loss = 0.04767291749274169
Trained batch 276 in epoch 6, gen_loss = 0.3976828487125975, disc_loss = 0.04752616554377634
Trained batch 277 in epoch 6, gen_loss = 0.39784914791155207, disc_loss = 0.04740843952050526
Trained batch 278 in epoch 6, gen_loss = 0.39752477866774394, disc_loss = 0.04739473571193047
Trained batch 279 in epoch 6, gen_loss = 0.39742612061756, disc_loss = 0.04739350288707231
Trained batch 280 in epoch 6, gen_loss = 0.39727902157875145, disc_loss = 0.047241382370454346
Trained batch 281 in epoch 6, gen_loss = 0.397393525703579, disc_loss = 0.047092870317056036
Trained batch 282 in epoch 6, gen_loss = 0.39758475309125946, disc_loss = 0.046951966337175126
Trained batch 283 in epoch 6, gen_loss = 0.3978485743134794, disc_loss = 0.04680160505362642
Trained batch 284 in epoch 6, gen_loss = 0.3980179880794726, disc_loss = 0.04671495197536914
Trained batch 285 in epoch 6, gen_loss = 0.3981302031478682, disc_loss = 0.04665555806433248
Trained batch 286 in epoch 6, gen_loss = 0.39815178492758746, disc_loss = 0.04650343569703011
Trained batch 287 in epoch 6, gen_loss = 0.398255514808827, disc_loss = 0.046446947859496705
Trained batch 288 in epoch 6, gen_loss = 0.39797841821987323, disc_loss = 0.04661192403377959
Trained batch 289 in epoch 6, gen_loss = 0.39819010598906157, disc_loss = 0.04675747034107817
Trained batch 290 in epoch 6, gen_loss = 0.3984066660666384, disc_loss = 0.04663299031466041
Trained batch 291 in epoch 6, gen_loss = 0.3983724945007938, disc_loss = 0.046507181571031064
Trained batch 292 in epoch 6, gen_loss = 0.39834028594322984, disc_loss = 0.046437585678701716
Trained batch 293 in epoch 6, gen_loss = 0.39827896279542624, disc_loss = 0.046292549331013594
Trained batch 294 in epoch 6, gen_loss = 0.39818065802929764, disc_loss = 0.046167638480379164
Trained batch 295 in epoch 6, gen_loss = 0.39820714184158557, disc_loss = 0.04605072219714497
Trained batch 296 in epoch 6, gen_loss = 0.3985607956194316, disc_loss = 0.04590805165190563
Trained batch 297 in epoch 6, gen_loss = 0.39848120990615565, disc_loss = 0.04576482606548566
Trained batch 298 in epoch 6, gen_loss = 0.39855870933437026, disc_loss = 0.04569341372122309
Trained batch 299 in epoch 6, gen_loss = 0.3986266068617503, disc_loss = 0.04567055131231124
Trained batch 300 in epoch 6, gen_loss = 0.3987637167159109, disc_loss = 0.04556472577151542
Trained batch 301 in epoch 6, gen_loss = 0.39900927087723814, disc_loss = 0.0454530695149527
Trained batch 302 in epoch 6, gen_loss = 0.3990377474932781, disc_loss = 0.045423152662119014
Trained batch 303 in epoch 6, gen_loss = 0.3989620879292488, disc_loss = 0.0454696662606071
Trained batch 304 in epoch 6, gen_loss = 0.3989186739335295, disc_loss = 0.045344769575281954
Trained batch 305 in epoch 6, gen_loss = 0.3989499981691635, disc_loss = 0.04531600839972764
Trained batch 306 in epoch 6, gen_loss = 0.3989738964685011, disc_loss = 0.04521852390042806
Trained batch 307 in epoch 6, gen_loss = 0.3989106039335201, disc_loss = 0.04508282985483816
Trained batch 308 in epoch 6, gen_loss = 0.39883165693205924, disc_loss = 0.04496998214358795
Trained batch 309 in epoch 6, gen_loss = 0.39910089354361256, disc_loss = 0.04484752251225854
Trained batch 310 in epoch 6, gen_loss = 0.3992677050196473, disc_loss = 0.04471492219919944
Trained batch 311 in epoch 6, gen_loss = 0.39904489759833384, disc_loss = 0.044592768559829354
Trained batch 312 in epoch 6, gen_loss = 0.3990355834793359, disc_loss = 0.04448230811558402
Trained batch 313 in epoch 6, gen_loss = 0.39893806578627056, disc_loss = 0.04438407674941952
Trained batch 314 in epoch 6, gen_loss = 0.39889236253405375, disc_loss = 0.04429492425646574
Trained batch 315 in epoch 6, gen_loss = 0.39879480060897293, disc_loss = 0.04419090714352795
Trained batch 316 in epoch 6, gen_loss = 0.39865807892772304, disc_loss = 0.04407848915737416
Trained batch 317 in epoch 6, gen_loss = 0.39859226261669733, disc_loss = 0.043966137197852695
Trained batch 318 in epoch 6, gen_loss = 0.39856374357187635, disc_loss = 0.04386749075357817
Trained batch 319 in epoch 6, gen_loss = 0.39865191113203763, disc_loss = 0.04377236750442535
Trained batch 320 in epoch 6, gen_loss = 0.3989657973203332, disc_loss = 0.043665168418134115
Trained batch 321 in epoch 6, gen_loss = 0.39901590791548264, disc_loss = 0.04354556511960322
Trained batch 322 in epoch 6, gen_loss = 0.3989076911480434, disc_loss = 0.04343741524664702
Trained batch 323 in epoch 6, gen_loss = 0.39904148619116087, disc_loss = 0.0433182750446262
Trained batch 324 in epoch 6, gen_loss = 0.3991802652982565, disc_loss = 0.04321590903716592
Trained batch 325 in epoch 6, gen_loss = 0.3990626652365082, disc_loss = 0.043106361872236605
Trained batch 326 in epoch 6, gen_loss = 0.39921531956130213, disc_loss = 0.04299577266342414
Trained batch 327 in epoch 6, gen_loss = 0.39929405899672976, disc_loss = 0.04291173235922143
Trained batch 328 in epoch 6, gen_loss = 0.39912464897683325, disc_loss = 0.04287140485250298
Trained batch 329 in epoch 6, gen_loss = 0.399196468519442, disc_loss = 0.042776232348247005
Trained batch 330 in epoch 6, gen_loss = 0.39935309072995834, disc_loss = 0.04266220295317809
Trained batch 331 in epoch 6, gen_loss = 0.39950044282588615, disc_loss = 0.04255351093345243
Trained batch 332 in epoch 6, gen_loss = 0.3994818758499157, disc_loss = 0.04245070937612617
Trained batch 333 in epoch 6, gen_loss = 0.3997053993854694, disc_loss = 0.04233444391325964
Trained batch 334 in epoch 6, gen_loss = 0.39969790275417155, disc_loss = 0.04222938305934641
Trained batch 335 in epoch 6, gen_loss = 0.39974349666209447, disc_loss = 0.042127524373687004
Trained batch 336 in epoch 6, gen_loss = 0.3998365201476066, disc_loss = 0.04204639546899263
Trained batch 337 in epoch 6, gen_loss = 0.3998314804403034, disc_loss = 0.04197510688830189
Trained batch 338 in epoch 6, gen_loss = 0.39989148093535837, disc_loss = 0.04185996794589633
Trained batch 339 in epoch 6, gen_loss = 0.39989403047982386, disc_loss = 0.04175447318292059
Trained batch 340 in epoch 6, gen_loss = 0.39975500788506874, disc_loss = 0.04165283410435766
Trained batch 341 in epoch 6, gen_loss = 0.39962464945706705, disc_loss = 0.04159296047601479
Trained batch 342 in epoch 6, gen_loss = 0.3997063813160877, disc_loss = 0.041935818238623725
Trained batch 343 in epoch 6, gen_loss = 0.3996307454829992, disc_loss = 0.04227123492489417
Trained batch 344 in epoch 6, gen_loss = 0.39958278649095175, disc_loss = 0.0422992661230914
Trained batch 345 in epoch 6, gen_loss = 0.3995947208190929, disc_loss = 0.04222939080138815
Trained batch 346 in epoch 6, gen_loss = 0.3995903216796237, disc_loss = 0.04213206792218069
Trained batch 347 in epoch 6, gen_loss = 0.3993203667388565, disc_loss = 0.04212468593975465
Trained batch 348 in epoch 6, gen_loss = 0.39921292585766416, disc_loss = 0.0420509587058045
Trained batch 349 in epoch 6, gen_loss = 0.39937832602432793, disc_loss = 0.042208649347137125
Trained batch 350 in epoch 6, gen_loss = 0.3991727963981465, disc_loss = 0.04239061753002879
Trained batch 351 in epoch 6, gen_loss = 0.3994082110002637, disc_loss = 0.04336802142973862
Trained batch 352 in epoch 6, gen_loss = 0.399244900465687, disc_loss = 0.04355268256485505
Trained batch 353 in epoch 6, gen_loss = 0.3994562535804544, disc_loss = 0.04354285648866099
Trained batch 354 in epoch 6, gen_loss = 0.3995361135879033, disc_loss = 0.04355041633530612
Trained batch 355 in epoch 6, gen_loss = 0.3993656240989653, disc_loss = 0.04347164626887298
Trained batch 356 in epoch 6, gen_loss = 0.39933470091899903, disc_loss = 0.04363153079075932
Trained batch 357 in epoch 6, gen_loss = 0.3994559398410041, disc_loss = 0.043577900092642986
Trained batch 358 in epoch 6, gen_loss = 0.3993249969728146, disc_loss = 0.0437359869114349
Trained batch 359 in epoch 6, gen_loss = 0.3990360444618596, disc_loss = 0.04403527295087568
Trained batch 360 in epoch 6, gen_loss = 0.39900351198096023, disc_loss = 0.04394779071970288
Trained batch 361 in epoch 6, gen_loss = 0.3987862444714288, disc_loss = 0.04428344887156472
Trained batch 362 in epoch 6, gen_loss = 0.39883704430144024, disc_loss = 0.04469994232238119
Trained batch 363 in epoch 6, gen_loss = 0.3988756386788337, disc_loss = 0.04465278280402565
Trained batch 364 in epoch 6, gen_loss = 0.39874563323308343, disc_loss = 0.04460329988920321
Trained batch 365 in epoch 6, gen_loss = 0.39883369858799084, disc_loss = 0.0445031276509634
Trained batch 366 in epoch 6, gen_loss = 0.39879508353059234, disc_loss = 0.04445550267328318
Trained batch 367 in epoch 6, gen_loss = 0.3988728110233079, disc_loss = 0.04435304785653463
Trained batch 368 in epoch 6, gen_loss = 0.3988387121902249, disc_loss = 0.04425961419758273
Trained batch 369 in epoch 6, gen_loss = 0.3989040102507617, disc_loss = 0.044154155586619635
Trained batch 370 in epoch 6, gen_loss = 0.39875114727213057, disc_loss = 0.04408496456105272
Trained batch 371 in epoch 6, gen_loss = 0.3987882251861275, disc_loss = 0.04399736065878182
Trained batch 372 in epoch 6, gen_loss = 0.3988004379553705, disc_loss = 0.04398432943780205
Trained batch 373 in epoch 6, gen_loss = 0.39906752739041884, disc_loss = 0.044626809880735085
Trained batch 374 in epoch 6, gen_loss = 0.3987780292828878, disc_loss = 0.044819463834166524
Trained batch 375 in epoch 6, gen_loss = 0.39864203896611294, disc_loss = 0.044784178021066684
Trained batch 376 in epoch 6, gen_loss = 0.3986848041770945, disc_loss = 0.04469816162144711
Trained batch 377 in epoch 6, gen_loss = 0.3987103036787144, disc_loss = 0.04460142984759634
Trained batch 378 in epoch 6, gen_loss = 0.3988279559524204, disc_loss = 0.04450582425137072
Trained batch 379 in epoch 6, gen_loss = 0.39888733154849004, disc_loss = 0.04440938568870096
Trained batch 380 in epoch 6, gen_loss = 0.3990588184260321, disc_loss = 0.04430209484630878
Trained batch 381 in epoch 6, gen_loss = 0.3990272771157519, disc_loss = 0.04420088376747493
Trained batch 382 in epoch 6, gen_loss = 0.39906587807690197, disc_loss = 0.04410799510665141
Trained batch 383 in epoch 6, gen_loss = 0.39907317360242206, disc_loss = 0.044000880564757004
Trained batch 384 in epoch 6, gen_loss = 0.39918865104774376, disc_loss = 0.04389806582967376
Trained batch 385 in epoch 6, gen_loss = 0.39914638761411675, disc_loss = 0.04381574804344519
Trained batch 386 in epoch 6, gen_loss = 0.3990788522924872, disc_loss = 0.04375772853081117
Trained batch 387 in epoch 6, gen_loss = 0.39914244682211236, disc_loss = 0.043893359535488966
Trained batch 388 in epoch 6, gen_loss = 0.39917409764770373, disc_loss = 0.043915202837571464
Trained batch 389 in epoch 6, gen_loss = 0.39911463719147905, disc_loss = 0.04382268156832418
Trained batch 390 in epoch 6, gen_loss = 0.39908267439478806, disc_loss = 0.043732122757503065
Trained batch 391 in epoch 6, gen_loss = 0.39899811893701553, disc_loss = 0.043633199606936575
Trained batch 392 in epoch 6, gen_loss = 0.3987380166090172, disc_loss = 0.0435443159166733
Trained batch 393 in epoch 6, gen_loss = 0.39874679939395885, disc_loss = 0.04345046966525769
Trained batch 394 in epoch 6, gen_loss = 0.39874986500679693, disc_loss = 0.04335982826526595
Trained batch 395 in epoch 6, gen_loss = 0.3987146819179708, disc_loss = 0.043283920590483554
Trained batch 396 in epoch 6, gen_loss = 0.3988001145403691, disc_loss = 0.04319066145769332
Trained batch 397 in epoch 6, gen_loss = 0.3987580897221014, disc_loss = 0.043106093266791656
Trained batch 398 in epoch 6, gen_loss = 0.3989510312863161, disc_loss = 0.04302281547771921
Trained batch 399 in epoch 6, gen_loss = 0.3989765003323555, disc_loss = 0.04292612597113475
Trained batch 400 in epoch 6, gen_loss = 0.3989610345732244, disc_loss = 0.04292935736598145
Trained batch 401 in epoch 6, gen_loss = 0.39906802691927, disc_loss = 0.04301529034592248
Trained batch 402 in epoch 6, gen_loss = 0.39920893725627116, disc_loss = 0.04293424702912717
Trained batch 403 in epoch 6, gen_loss = 0.39909118347533856, disc_loss = 0.042895836771770134
Trained batch 404 in epoch 6, gen_loss = 0.3992199746178992, disc_loss = 0.042811669420772865
Trained batch 405 in epoch 6, gen_loss = 0.3992537453844042, disc_loss = 0.042742560422644384
Trained batch 406 in epoch 6, gen_loss = 0.3990442744051209, disc_loss = 0.042715249580836855
Trained batch 407 in epoch 6, gen_loss = 0.3989359824826904, disc_loss = 0.04277184330082188
Trained batch 408 in epoch 6, gen_loss = 0.39903728733144356, disc_loss = 0.04274189109005453
Trained batch 409 in epoch 6, gen_loss = 0.399298736162302, disc_loss = 0.04306573185660854
Trained batch 410 in epoch 6, gen_loss = 0.399201591447032, disc_loss = 0.043268903774954834
Trained batch 411 in epoch 6, gen_loss = 0.3992929192422663, disc_loss = 0.04319238409770707
Trained batch 412 in epoch 6, gen_loss = 0.3990962400707725, disc_loss = 0.0436095350036357
Trained batch 413 in epoch 6, gen_loss = 0.39894707328167517, disc_loss = 0.043764296417453004
Trained batch 414 in epoch 6, gen_loss = 0.39882311555276434, disc_loss = 0.04428313315498183
Trained batch 415 in epoch 6, gen_loss = 0.3985657376022293, disc_loss = 0.04468041535046023
Trained batch 416 in epoch 6, gen_loss = 0.3984647670524012, disc_loss = 0.04466560523403134
Trained batch 417 in epoch 6, gen_loss = 0.3985088640137723, disc_loss = 0.04495939898692321
Trained batch 418 in epoch 6, gen_loss = 0.39827511959258016, disc_loss = 0.04514476062334309
Trained batch 419 in epoch 6, gen_loss = 0.3982405681695257, disc_loss = 0.04535040130971798
Trained batch 420 in epoch 6, gen_loss = 0.39800228068777616, disc_loss = 0.045687721447129855
Trained batch 421 in epoch 6, gen_loss = 0.3979703739497334, disc_loss = 0.04607739877970933
Trained batch 422 in epoch 6, gen_loss = 0.39781094520368193, disc_loss = 0.046259458317700994
Trained batch 423 in epoch 6, gen_loss = 0.397633876581237, disc_loss = 0.04635481078854217
Trained batch 424 in epoch 6, gen_loss = 0.3976078597237082, disc_loss = 0.04651785860385965
Trained batch 425 in epoch 6, gen_loss = 0.39735189982703034, disc_loss = 0.046592438980464786
Trained batch 426 in epoch 6, gen_loss = 0.3972108544175463, disc_loss = 0.04656340857309047
Trained batch 427 in epoch 6, gen_loss = 0.3972930206316654, disc_loss = 0.04653950023604122
Trained batch 428 in epoch 6, gen_loss = 0.3974097248140749, disc_loss = 0.04646665488081031
Trained batch 429 in epoch 6, gen_loss = 0.39738340183745985, disc_loss = 0.04638615443782751
Trained batch 430 in epoch 6, gen_loss = 0.3973703871193729, disc_loss = 0.04643282563082027
Trained batch 431 in epoch 6, gen_loss = 0.3974833779588894, disc_loss = 0.046703593969276105
Trained batch 432 in epoch 6, gen_loss = 0.39750707603767343, disc_loss = 0.0470070060746912
Trained batch 433 in epoch 6, gen_loss = 0.39770304387615574, disc_loss = 0.04700652285895315
Trained batch 434 in epoch 6, gen_loss = 0.39779937856498804, disc_loss = 0.04708369200428327
Trained batch 435 in epoch 6, gen_loss = 0.39759394239395035, disc_loss = 0.04712064536032053
Trained batch 436 in epoch 6, gen_loss = 0.39755529478976603, disc_loss = 0.047044297803866784
Trained batch 437 in epoch 6, gen_loss = 0.3975606118435185, disc_loss = 0.04700348406740928
Trained batch 438 in epoch 6, gen_loss = 0.3975409447875273, disc_loss = 0.04693865317401555
Trained batch 439 in epoch 6, gen_loss = 0.39760849089785055, disc_loss = 0.04699401528235864
Trained batch 440 in epoch 6, gen_loss = 0.3973868298692768, disc_loss = 0.047479244971187474
Trained batch 441 in epoch 6, gen_loss = 0.39746868273251734, disc_loss = 0.04783593190252376
Trained batch 442 in epoch 6, gen_loss = 0.39751962008917574, disc_loss = 0.047742832186116795
Trained batch 443 in epoch 6, gen_loss = 0.3973236594785441, disc_loss = 0.04781684703466289
Trained batch 444 in epoch 6, gen_loss = 0.3974134437823563, disc_loss = 0.04776893623822023
Trained batch 445 in epoch 6, gen_loss = 0.39727589147240594, disc_loss = 0.04784886964028826
Trained batch 446 in epoch 6, gen_loss = 0.39729899648051936, disc_loss = 0.047883384253713045
Trained batch 447 in epoch 6, gen_loss = 0.39751615348671165, disc_loss = 0.047800089817818456
Trained batch 448 in epoch 6, gen_loss = 0.3974829776780908, disc_loss = 0.047703356067245545
Trained batch 449 in epoch 6, gen_loss = 0.3975213262769911, disc_loss = 0.0476085679885
Trained batch 450 in epoch 6, gen_loss = 0.3975388903972051, disc_loss = 0.047546186939732664
Trained batch 451 in epoch 6, gen_loss = 0.3975057673797143, disc_loss = 0.04748234146921607
Trained batch 452 in epoch 6, gen_loss = 0.3973269170483217, disc_loss = 0.047513868946532735
Trained batch 453 in epoch 6, gen_loss = 0.3974052869800954, disc_loss = 0.04772933889159908
Trained batch 454 in epoch 6, gen_loss = 0.39732548876123114, disc_loss = 0.04770131046361812
Trained batch 455 in epoch 6, gen_loss = 0.3974095001293902, disc_loss = 0.04764490189304445
Trained batch 456 in epoch 6, gen_loss = 0.39749958178668365, disc_loss = 0.04756429883054329
Trained batch 457 in epoch 6, gen_loss = 0.3975314255234456, disc_loss = 0.047486519753143976
Trained batch 458 in epoch 6, gen_loss = 0.3975653351002529, disc_loss = 0.04741208545543042
Trained batch 459 in epoch 6, gen_loss = 0.39750213214884633, disc_loss = 0.047323587273611974
Trained batch 460 in epoch 6, gen_loss = 0.39747480605274377, disc_loss = 0.047231637450529024
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.42959368228912354, disc_loss = 0.010345490649342537
Trained batch 1 in epoch 7, gen_loss = 0.38565489649772644, disc_loss = 0.020679814741015434
Trained batch 2 in epoch 7, gen_loss = 0.4005790452162425, disc_loss = 0.036288620283206306
Trained batch 3 in epoch 7, gen_loss = 0.4205964282155037, disc_loss = 0.0807506563141942
Trained batch 4 in epoch 7, gen_loss = 0.4084900379180908, disc_loss = 0.07770758345723153
Trained batch 5 in epoch 7, gen_loss = 0.4062387744585673, disc_loss = 0.06613802180315058
Trained batch 6 in epoch 7, gen_loss = 0.40560469031333923, disc_loss = 0.057770673119063885
Trained batch 7 in epoch 7, gen_loss = 0.40237878262996674, disc_loss = 0.05158161366125569
Trained batch 8 in epoch 7, gen_loss = 0.4028845594988929, disc_loss = 0.04639509356477194
Trained batch 9 in epoch 7, gen_loss = 0.402621129155159, disc_loss = 0.04232467729598284
Trained batch 10 in epoch 7, gen_loss = 0.39573121612722223, disc_loss = 0.03876730947839943
Trained batch 11 in epoch 7, gen_loss = 0.39877089858055115, disc_loss = 0.035926588578149676
Trained batch 12 in epoch 7, gen_loss = 0.3986712327370277, disc_loss = 0.03881173645361112
Trained batch 13 in epoch 7, gen_loss = 0.40611082315444946, disc_loss = 0.05615890032744834
Trained batch 14 in epoch 7, gen_loss = 0.4010293702284495, disc_loss = 0.05433254123975833
Trained batch 15 in epoch 7, gen_loss = 0.39750271663069725, disc_loss = 0.06141798460157588
Trained batch 16 in epoch 7, gen_loss = 0.39768152727800254, disc_loss = 0.07019325285492574
Trained batch 17 in epoch 7, gen_loss = 0.3970826632446713, disc_loss = 0.06717808270413014
Trained batch 18 in epoch 7, gen_loss = 0.39823419639938756, disc_loss = 0.06532458524758879
Trained batch 19 in epoch 7, gen_loss = 0.3959480255842209, disc_loss = 0.06244046650826931
Trained batch 20 in epoch 7, gen_loss = 0.3932252512091682, disc_loss = 0.05974645994692331
Trained batch 21 in epoch 7, gen_loss = 0.3933821266347712, disc_loss = 0.05745700765824453
Trained batch 22 in epoch 7, gen_loss = 0.39353199367937836, disc_loss = 0.055219024682984404
Trained batch 23 in epoch 7, gen_loss = 0.39360577861468, disc_loss = 0.0532973381341435
Trained batch 24 in epoch 7, gen_loss = 0.3950525915622711, disc_loss = 0.05142357518896461
Trained batch 25 in epoch 7, gen_loss = 0.39486814118348634, disc_loss = 0.05119092223377755
Trained batch 26 in epoch 7, gen_loss = 0.39570040062621786, disc_loss = 0.05097670665148784
Trained batch 27 in epoch 7, gen_loss = 0.398234951708998, disc_loss = 0.049831605034082065
Trained batch 28 in epoch 7, gen_loss = 0.3990208701840762, disc_loss = 0.05012409869131857
Trained batch 29 in epoch 7, gen_loss = 0.400659586985906, disc_loss = 0.0495434633611391
Trained batch 30 in epoch 7, gen_loss = 0.39921378704809374, disc_loss = 0.048634337066041845
Trained batch 31 in epoch 7, gen_loss = 0.4011400369927287, disc_loss = 0.05028501267952379
Trained batch 32 in epoch 7, gen_loss = 0.4016159818027959, disc_loss = 0.05052876380751982
Trained batch 33 in epoch 7, gen_loss = 0.3997319007621092, disc_loss = 0.05130693337003536
Trained batch 34 in epoch 7, gen_loss = 0.40128318411963326, disc_loss = 0.051278262784970656
Trained batch 35 in epoch 7, gen_loss = 0.4029730525281694, disc_loss = 0.05020886435846074
Trained batch 36 in epoch 7, gen_loss = 0.40258497563568324, disc_loss = 0.049008165612011344
Trained batch 37 in epoch 7, gen_loss = 0.4039763635710666, disc_loss = 0.04784910622248916
Trained batch 38 in epoch 7, gen_loss = 0.4026111410214351, disc_loss = 0.04700348219380547
Trained batch 39 in epoch 7, gen_loss = 0.40223219320178033, disc_loss = 0.04592862776480615
Trained batch 40 in epoch 7, gen_loss = 0.40252926509554793, disc_loss = 0.045109926609367856
Trained batch 41 in epoch 7, gen_loss = 0.4013486944493793, disc_loss = 0.04414912416333599
Trained batch 42 in epoch 7, gen_loss = 0.4009849533092144, disc_loss = 0.044519562328364265
Trained batch 43 in epoch 7, gen_loss = 0.4020879952745004, disc_loss = 0.04641470276030966
Trained batch 44 in epoch 7, gen_loss = 0.40114524298244053, disc_loss = 0.04661076885337631
Trained batch 45 in epoch 7, gen_loss = 0.39994355064371356, disc_loss = 0.045879243640229106
Trained batch 46 in epoch 7, gen_loss = 0.40076955011550414, disc_loss = 0.04500957948968132
Trained batch 47 in epoch 7, gen_loss = 0.4013808313757181, disc_loss = 0.04412952621350996
Trained batch 48 in epoch 7, gen_loss = 0.4028115655694689, disc_loss = 0.04330379304913234
Trained batch 49 in epoch 7, gen_loss = 0.40320212006568906, disc_loss = 0.042511766580864786
Trained batch 50 in epoch 7, gen_loss = 0.40361832228361394, disc_loss = 0.041779668061245306
Trained batch 51 in epoch 7, gen_loss = 0.4018384739756584, disc_loss = 0.04204945213412149
Trained batch 52 in epoch 7, gen_loss = 0.40307820461831, disc_loss = 0.041640399067820806
Trained batch 53 in epoch 7, gen_loss = 0.40322951862105616, disc_loss = 0.041242195715851804
Trained batch 54 in epoch 7, gen_loss = 0.4036195088516582, disc_loss = 0.04074126855385574
Trained batch 55 in epoch 7, gen_loss = 0.40381472717438427, disc_loss = 0.04025099939566904
Trained batch 56 in epoch 7, gen_loss = 0.4038132983341552, disc_loss = 0.03962598368525505
Trained batch 57 in epoch 7, gen_loss = 0.4037827006701765, disc_loss = 0.039151714215504715
Trained batch 58 in epoch 7, gen_loss = 0.4044871714155553, disc_loss = 0.038605679939422065
Trained batch 59 in epoch 7, gen_loss = 0.4065089305241903, disc_loss = 0.038142653593483074
Trained batch 60 in epoch 7, gen_loss = 0.4071567605753414, disc_loss = 0.03764993704275274
Trained batch 61 in epoch 7, gen_loss = 0.40646872981902094, disc_loss = 0.037199864021292134
Trained batch 62 in epoch 7, gen_loss = 0.4047731941654569, disc_loss = 0.03685199005884074
Trained batch 63 in epoch 7, gen_loss = 0.4064250676892698, disc_loss = 0.03697757711779559
Trained batch 64 in epoch 7, gen_loss = 0.4066963915641491, disc_loss = 0.036633178828140864
Trained batch 65 in epoch 7, gen_loss = 0.4078305160457438, disc_loss = 0.03733301253735342
Trained batch 66 in epoch 7, gen_loss = 0.4082423034888595, disc_loss = 0.037165028592154606
Trained batch 67 in epoch 7, gen_loss = 0.40951427072286606, disc_loss = 0.03668330231106237
Trained batch 68 in epoch 7, gen_loss = 0.4089928947497105, disc_loss = 0.03624317878722281
Trained batch 69 in epoch 7, gen_loss = 0.40800863930157255, disc_loss = 0.036461069834019456
Trained batch 70 in epoch 7, gen_loss = 0.4090316161303453, disc_loss = 0.03613137180956317
Trained batch 71 in epoch 7, gen_loss = 0.40912170542611015, disc_loss = 0.03730815338591734
Trained batch 72 in epoch 7, gen_loss = 0.40894459534997807, disc_loss = 0.03726035693328675
Trained batch 73 in epoch 7, gen_loss = 0.40773252135998495, disc_loss = 0.037231679603054714
Trained batch 74 in epoch 7, gen_loss = 0.4087291169166565, disc_loss = 0.036865662100414434
Trained batch 75 in epoch 7, gen_loss = 0.4093800155740035, disc_loss = 0.03654253910491733
Trained batch 76 in epoch 7, gen_loss = 0.409318978136236, disc_loss = 0.03612482293158189
Trained batch 77 in epoch 7, gen_loss = 0.40844974112816346, disc_loss = 0.035794119631202936
Trained batch 78 in epoch 7, gen_loss = 0.40858835396887383, disc_loss = 0.035590722325812035
Trained batch 79 in epoch 7, gen_loss = 0.4084262538701296, disc_loss = 0.03535660460474901
Trained batch 80 in epoch 7, gen_loss = 0.40813435264575626, disc_loss = 0.03567611901549461
Trained batch 81 in epoch 7, gen_loss = 0.40722407618673834, disc_loss = 0.03644600416897092
Trained batch 82 in epoch 7, gen_loss = 0.40781882369374656, disc_loss = 0.03649551072999476
Trained batch 83 in epoch 7, gen_loss = 0.40846615142765497, disc_loss = 0.03631659204118131
Trained batch 84 in epoch 7, gen_loss = 0.4079305505051332, disc_loss = 0.03598954885211938
Trained batch 85 in epoch 7, gen_loss = 0.4086058309604955, disc_loss = 0.0356535738994649
Trained batch 86 in epoch 7, gen_loss = 0.40854926972553646, disc_loss = 0.035303065483725964
Trained batch 87 in epoch 7, gen_loss = 0.4090335030447353, disc_loss = 0.03495141979709098
Trained batch 88 in epoch 7, gen_loss = 0.40889675463183545, disc_loss = 0.03459386108966356
Trained batch 89 in epoch 7, gen_loss = 0.4090911931461758, disc_loss = 0.03427188284177747
Trained batch 90 in epoch 7, gen_loss = 0.4090822705855736, disc_loss = 0.03395508239455112
Trained batch 91 in epoch 7, gen_loss = 0.4089880345956139, disc_loss = 0.033632367530473224
Trained batch 92 in epoch 7, gen_loss = 0.40932415794300775, disc_loss = 0.033296618445385846
Trained batch 93 in epoch 7, gen_loss = 0.4096479244688724, disc_loss = 0.032988073750141456
Trained batch 94 in epoch 7, gen_loss = 0.40923874817396466, disc_loss = 0.0326821081242279
Trained batch 95 in epoch 7, gen_loss = 0.40956819988787174, disc_loss = 0.03240609537654867
Trained batch 96 in epoch 7, gen_loss = 0.4088509168821512, disc_loss = 0.032154135069973076
Trained batch 97 in epoch 7, gen_loss = 0.40877973820481983, disc_loss = 0.03186610893213323
Trained batch 98 in epoch 7, gen_loss = 0.40829000238216284, disc_loss = 0.03162673190047945
Trained batch 99 in epoch 7, gen_loss = 0.40809211373329163, disc_loss = 0.03136976606212556
Trained batch 100 in epoch 7, gen_loss = 0.4076659602693992, disc_loss = 0.031475853423892274
Trained batch 101 in epoch 7, gen_loss = 0.40710940168184395, disc_loss = 0.03188492904654613
Trained batch 102 in epoch 7, gen_loss = 0.40782357911461764, disc_loss = 0.03251776025965086
Trained batch 103 in epoch 7, gen_loss = 0.4072089186654641, disc_loss = 0.03225551180254955
Trained batch 104 in epoch 7, gen_loss = 0.40645964741706847, disc_loss = 0.032566521281287786
Trained batch 105 in epoch 7, gen_loss = 0.4071952590964875, disc_loss = 0.03237812340540706
Trained batch 106 in epoch 7, gen_loss = 0.4071068577120237, disc_loss = 0.032435758021947377
Trained batch 107 in epoch 7, gen_loss = 0.40674234126453046, disc_loss = 0.032224217524614046
Trained batch 108 in epoch 7, gen_loss = 0.40645114872433724, disc_loss = 0.032164247885961596
Trained batch 109 in epoch 7, gen_loss = 0.40656727985902263, disc_loss = 0.031995657255703754
Trained batch 110 in epoch 7, gen_loss = 0.4069852270521559, disc_loss = 0.03177076740911952
Trained batch 111 in epoch 7, gen_loss = 0.4069451436932598, disc_loss = 0.03156120343399899
Trained batch 112 in epoch 7, gen_loss = 0.4068131839807055, disc_loss = 0.0313156677113302
Trained batch 113 in epoch 7, gen_loss = 0.4072877864042918, disc_loss = 0.03108090583823229
Trained batch 114 in epoch 7, gen_loss = 0.4078655849332395, disc_loss = 0.030863619915655126
Trained batch 115 in epoch 7, gen_loss = 0.4077785115303664, disc_loss = 0.030635481318940633
Trained batch 116 in epoch 7, gen_loss = 0.40855221768729705, disc_loss = 0.03069621321753177
Trained batch 117 in epoch 7, gen_loss = 0.4083737084421061, disc_loss = 0.03052980143782067
Trained batch 118 in epoch 7, gen_loss = 0.4080500131895562, disc_loss = 0.030534519528297065
Trained batch 119 in epoch 7, gen_loss = 0.4079297932485739, disc_loss = 0.030365987894280504
Trained batch 120 in epoch 7, gen_loss = 0.40755082088068495, disc_loss = 0.03016807578411723
Trained batch 121 in epoch 7, gen_loss = 0.40714733424733895, disc_loss = 0.029954731762103858
Trained batch 122 in epoch 7, gen_loss = 0.40718631288869594, disc_loss = 0.029783304659574013
Trained batch 123 in epoch 7, gen_loss = 0.40724872869829976, disc_loss = 0.0296238878997223
Trained batch 124 in epoch 7, gen_loss = 0.40711707234382627, disc_loss = 0.029425292640924455
Trained batch 125 in epoch 7, gen_loss = 0.407502123997325, disc_loss = 0.02923256647773087
Trained batch 126 in epoch 7, gen_loss = 0.40723313191744287, disc_loss = 0.029041933112110445
Trained batch 127 in epoch 7, gen_loss = 0.40743263089098036, disc_loss = 0.028839339214755455
Trained batch 128 in epoch 7, gen_loss = 0.4070261571296426, disc_loss = 0.02864339354975048
Trained batch 129 in epoch 7, gen_loss = 0.4069427529206643, disc_loss = 0.028510302828195003
Trained batch 130 in epoch 7, gen_loss = 0.40724377368242687, disc_loss = 0.028364909215624096
Trained batch 131 in epoch 7, gen_loss = 0.407298319041729, disc_loss = 0.02816978460848049
Trained batch 132 in epoch 7, gen_loss = 0.4066878100086872, disc_loss = 0.028008965479518127
Trained batch 133 in epoch 7, gen_loss = 0.40652553270112224, disc_loss = 0.02786470453234028
Trained batch 134 in epoch 7, gen_loss = 0.40624787432176096, disc_loss = 0.027751443464377964
Trained batch 135 in epoch 7, gen_loss = 0.4057671824360595, disc_loss = 0.02759932663449196
Trained batch 136 in epoch 7, gen_loss = 0.40544044558149184, disc_loss = 0.027982768213485172
Trained batch 137 in epoch 7, gen_loss = 0.4058480450640554, disc_loss = 0.030011737123604162
Trained batch 138 in epoch 7, gen_loss = 0.40548363220777445, disc_loss = 0.029877028379441915
Trained batch 139 in epoch 7, gen_loss = 0.405259727367333, disc_loss = 0.030112639639992268
Trained batch 140 in epoch 7, gen_loss = 0.40513023142273547, disc_loss = 0.029936179659058544
Trained batch 141 in epoch 7, gen_loss = 0.4051369623818868, disc_loss = 0.02983034166841912
Trained batch 142 in epoch 7, gen_loss = 0.4050358615138314, disc_loss = 0.029709938016453094
Trained batch 143 in epoch 7, gen_loss = 0.40503107921944725, disc_loss = 0.029845428693483375
Trained batch 144 in epoch 7, gen_loss = 0.40461880215283097, disc_loss = 0.029760635632957364
Trained batch 145 in epoch 7, gen_loss = 0.40433188905454664, disc_loss = 0.03043027468542377
Trained batch 146 in epoch 7, gen_loss = 0.4036776192334233, disc_loss = 0.03368767408090232
Trained batch 147 in epoch 7, gen_loss = 0.4029357346731263, disc_loss = 0.0340651032731969
Trained batch 148 in epoch 7, gen_loss = 0.4032731026211041, disc_loss = 0.03446510275544586
Trained batch 149 in epoch 7, gen_loss = 0.40316844642162325, disc_loss = 0.03462476833568265
Trained batch 150 in epoch 7, gen_loss = 0.4027961010964501, disc_loss = 0.03482248475127514
Trained batch 151 in epoch 7, gen_loss = 0.4028352848009059, disc_loss = 0.03542651632022554
Trained batch 152 in epoch 7, gen_loss = 0.40295004260306266, disc_loss = 0.03546191989505067
Trained batch 153 in epoch 7, gen_loss = 0.40274120518913514, disc_loss = 0.03539993729012982
Trained batch 154 in epoch 7, gen_loss = 0.40313148133216364, disc_loss = 0.0354467467810478
Trained batch 155 in epoch 7, gen_loss = 0.40285508659405583, disc_loss = 0.03545830562525692
Trained batch 156 in epoch 7, gen_loss = 0.40265689021462847, disc_loss = 0.0356155541520803
Trained batch 157 in epoch 7, gen_loss = 0.4022187705658659, disc_loss = 0.035592634880714874
Trained batch 158 in epoch 7, gen_loss = 0.4024514539061852, disc_loss = 0.035426692968328136
Trained batch 159 in epoch 7, gen_loss = 0.40280855651944875, disc_loss = 0.035330914206861054
Trained batch 160 in epoch 7, gen_loss = 0.40283482230227924, disc_loss = 0.03513492066384241
Trained batch 161 in epoch 7, gen_loss = 0.40258234095426254, disc_loss = 0.03494482249866619
Trained batch 162 in epoch 7, gen_loss = 0.4033407918148977, disc_loss = 0.03480714869662616
Trained batch 163 in epoch 7, gen_loss = 0.403926019261523, disc_loss = 0.03465350717732047
Trained batch 164 in epoch 7, gen_loss = 0.40409295017069036, disc_loss = 0.034503008790709305
Trained batch 165 in epoch 7, gen_loss = 0.4043784712452486, disc_loss = 0.0343181137233995
Trained batch 166 in epoch 7, gen_loss = 0.40418261111139536, disc_loss = 0.03415430429904627
Trained batch 167 in epoch 7, gen_loss = 0.4038121145041216, disc_loss = 0.03419371870751049
Trained batch 168 in epoch 7, gen_loss = 0.4035378518189199, disc_loss = 0.034061637625770545
Trained batch 169 in epoch 7, gen_loss = 0.40362533926963806, disc_loss = 0.03416081350433695
Trained batch 170 in epoch 7, gen_loss = 0.4040064097147936, disc_loss = 0.03403929443022356
Trained batch 171 in epoch 7, gen_loss = 0.4041251108743424, disc_loss = 0.03390641740203813
Trained batch 172 in epoch 7, gen_loss = 0.4036378064596584, disc_loss = 0.033750305287378456
Trained batch 173 in epoch 7, gen_loss = 0.4034733284136345, disc_loss = 0.033578794086940755
Trained batch 174 in epoch 7, gen_loss = 0.40363554068974083, disc_loss = 0.03344085671672863
Trained batch 175 in epoch 7, gen_loss = 0.40342174267227, disc_loss = 0.033329390916729935
Trained batch 176 in epoch 7, gen_loss = 0.40325222092833224, disc_loss = 0.033189063103827465
Trained batch 177 in epoch 7, gen_loss = 0.40298308180959036, disc_loss = 0.03306210010307265
Trained batch 178 in epoch 7, gen_loss = 0.40349337558506587, disc_loss = 0.03291548456211039
Trained batch 179 in epoch 7, gen_loss = 0.4034479588270187, disc_loss = 0.032753445237823246
Trained batch 180 in epoch 7, gen_loss = 0.4030880700817424, disc_loss = 0.032604270886104986
Trained batch 181 in epoch 7, gen_loss = 0.40304481524687547, disc_loss = 0.03264446219731286
Trained batch 182 in epoch 7, gen_loss = 0.4027392756743509, disc_loss = 0.03341342458791542
Trained batch 183 in epoch 7, gen_loss = 0.40329295915106067, disc_loss = 0.03450518408056308
Trained batch 184 in epoch 7, gen_loss = 0.4039268165021329, disc_loss = 0.03437474413170807
Trained batch 185 in epoch 7, gen_loss = 0.4033015133232199, disc_loss = 0.03446588257542982
Trained batch 186 in epoch 7, gen_loss = 0.4033735614409421, disc_loss = 0.03431216526134089
Trained batch 187 in epoch 7, gen_loss = 0.4032001577793284, disc_loss = 0.03421990742208436
Trained batch 188 in epoch 7, gen_loss = 0.4032988166682935, disc_loss = 0.0341005758986015
Trained batch 189 in epoch 7, gen_loss = 0.403168681891341, disc_loss = 0.03443845761817341
Trained batch 190 in epoch 7, gen_loss = 0.4038630825374763, disc_loss = 0.03462004275743835
Trained batch 191 in epoch 7, gen_loss = 0.4035385556829472, disc_loss = 0.03473408194622607
Trained batch 192 in epoch 7, gen_loss = 0.40351345980723285, disc_loss = 0.03471628822014701
Trained batch 193 in epoch 7, gen_loss = 0.40354870290485856, disc_loss = 0.034827972909906094
Trained batch 194 in epoch 7, gen_loss = 0.4038318387973003, disc_loss = 0.03579308553360021
Trained batch 195 in epoch 7, gen_loss = 0.40400789708507306, disc_loss = 0.03596824713939877
Trained batch 196 in epoch 7, gen_loss = 0.4033122191271806, disc_loss = 0.03617509952179029
Trained batch 197 in epoch 7, gen_loss = 0.40351250993482995, disc_loss = 0.03777525546099765
Trained batch 198 in epoch 7, gen_loss = 0.40315166984371203, disc_loss = 0.03774079300776761
Trained batch 199 in epoch 7, gen_loss = 0.4027282597124577, disc_loss = 0.0384811881405767
Trained batch 200 in epoch 7, gen_loss = 0.4023466347461909, disc_loss = 0.038469199798954884
Trained batch 201 in epoch 7, gen_loss = 0.4025065968237301, disc_loss = 0.038461187950077254
Trained batch 202 in epoch 7, gen_loss = 0.4030953805728499, disc_loss = 0.03842291435378195
Trained batch 203 in epoch 7, gen_loss = 0.40306736368174645, disc_loss = 0.038295518646847604
Trained batch 204 in epoch 7, gen_loss = 0.4028820731290957, disc_loss = 0.03832684724773394
Trained batch 205 in epoch 7, gen_loss = 0.4029570592259898, disc_loss = 0.03838263797795274
Trained batch 206 in epoch 7, gen_loss = 0.4032850936415115, disc_loss = 0.03883152601201141
Trained batch 207 in epoch 7, gen_loss = 0.40279742373296845, disc_loss = 0.039527879153655916
Trained batch 208 in epoch 7, gen_loss = 0.40274178197509364, disc_loss = 0.03990815328901999
Trained batch 209 in epoch 7, gen_loss = 0.40236363921846663, disc_loss = 0.0398616608442916
Trained batch 210 in epoch 7, gen_loss = 0.402129592912457, disc_loss = 0.04223389245936056
Trained batch 211 in epoch 7, gen_loss = 0.4021620167032728, disc_loss = 0.04392600024694507
Trained batch 212 in epoch 7, gen_loss = 0.40199329357751656, disc_loss = 0.0439958720557619
Trained batch 213 in epoch 7, gen_loss = 0.4017229492419234, disc_loss = 0.04399766353781501
Trained batch 214 in epoch 7, gen_loss = 0.4011902742607649, disc_loss = 0.04394382053314773
Trained batch 215 in epoch 7, gen_loss = 0.4011402639249961, disc_loss = 0.04384238281852083
Trained batch 216 in epoch 7, gen_loss = 0.40097938910607367, disc_loss = 0.04376080338971921
Trained batch 217 in epoch 7, gen_loss = 0.4007410695520016, disc_loss = 0.0444087328916894
Trained batch 218 in epoch 7, gen_loss = 0.40106100333880074, disc_loss = 0.0471177561300037
Trained batch 219 in epoch 7, gen_loss = 0.4008892162279649, disc_loss = 0.0477438472412442
Trained batch 220 in epoch 7, gen_loss = 0.400592755812865, disc_loss = 0.0482078510372398
Trained batch 221 in epoch 7, gen_loss = 0.400334983258634, disc_loss = 0.04832223271174977
Trained batch 222 in epoch 7, gen_loss = 0.4002272441248188, disc_loss = 0.048271852577806786
Trained batch 223 in epoch 7, gen_loss = 0.40028327823217424, disc_loss = 0.04814533623513333
Trained batch 224 in epoch 7, gen_loss = 0.40019522507985433, disc_loss = 0.04797525477802588
Trained batch 225 in epoch 7, gen_loss = 0.39981890621438493, disc_loss = 0.047948126037258954
Trained batch 226 in epoch 7, gen_loss = 0.39945948228962097, disc_loss = 0.04791937628042954
Trained batch 227 in epoch 7, gen_loss = 0.3993748295725438, disc_loss = 0.047788827491131725
Trained batch 228 in epoch 7, gen_loss = 0.3995267584854859, disc_loss = 0.04763165006401855
Trained batch 229 in epoch 7, gen_loss = 0.3996834560580876, disc_loss = 0.04746410407672596
Trained batch 230 in epoch 7, gen_loss = 0.3999763573660995, disc_loss = 0.04730425020619356
Trained batch 231 in epoch 7, gen_loss = 0.3999015911129014, disc_loss = 0.04719574765025253
Trained batch 232 in epoch 7, gen_loss = 0.3997571213818415, disc_loss = 0.0470248753107013
Trained batch 233 in epoch 7, gen_loss = 0.3999155496175473, disc_loss = 0.04689574003534026
Trained batch 234 in epoch 7, gen_loss = 0.40008463986376497, disc_loss = 0.04673602686342882
Trained batch 235 in epoch 7, gen_loss = 0.40014930119958975, disc_loss = 0.04664342345223936
Trained batch 236 in epoch 7, gen_loss = 0.4005185453700617, disc_loss = 0.046541132621333504
Trained batch 237 in epoch 7, gen_loss = 0.40050887247594463, disc_loss = 0.04640792208398935
Trained batch 238 in epoch 7, gen_loss = 0.4004620677756465, disc_loss = 0.04624459341998411
Trained batch 239 in epoch 7, gen_loss = 0.4001106234888236, disc_loss = 0.04608060926451193
Trained batch 240 in epoch 7, gen_loss = 0.39985019710548686, disc_loss = 0.045906641502203846
Trained batch 241 in epoch 7, gen_loss = 0.3998049615828459, disc_loss = 0.045759983157762134
Trained batch 242 in epoch 7, gen_loss = 0.39995786596718147, disc_loss = 0.04562166862576863
Trained batch 243 in epoch 7, gen_loss = 0.39993014675183375, disc_loss = 0.04545926587125592
Trained batch 244 in epoch 7, gen_loss = 0.4001198601966002, disc_loss = 0.045288828779392096
Trained batch 245 in epoch 7, gen_loss = 0.400157110720146, disc_loss = 0.04513408806803447
Trained batch 246 in epoch 7, gen_loss = 0.40021219765126465, disc_loss = 0.0449746367521584
Trained batch 247 in epoch 7, gen_loss = 0.4000423265801322, disc_loss = 0.04480973565988543
Trained batch 248 in epoch 7, gen_loss = 0.40009067874835674, disc_loss = 0.044645982725268984
Trained batch 249 in epoch 7, gen_loss = 0.3999726858139038, disc_loss = 0.04452882141061127
Trained batch 250 in epoch 7, gen_loss = 0.39963881629871656, disc_loss = 0.044375237895628486
Trained batch 251 in epoch 7, gen_loss = 0.39926262980415705, disc_loss = 0.04462107200182915
Trained batch 252 in epoch 7, gen_loss = 0.3992527716244634, disc_loss = 0.045655253967233446
Trained batch 253 in epoch 7, gen_loss = 0.39918344978272446, disc_loss = 0.04569890636283406
Trained batch 254 in epoch 7, gen_loss = 0.39889032829041576, disc_loss = 0.045745343643733685
Trained batch 255 in epoch 7, gen_loss = 0.39887777622789145, disc_loss = 0.04560417746870371
Trained batch 256 in epoch 7, gen_loss = 0.39895926375333435, disc_loss = 0.045481492288715064
Trained batch 257 in epoch 7, gen_loss = 0.39903404673402626, disc_loss = 0.045330605081593
Trained batch 258 in epoch 7, gen_loss = 0.3987878214668583, disc_loss = 0.04519684862482099
Trained batch 259 in epoch 7, gen_loss = 0.3988025815441058, disc_loss = 0.045203014199908534
Trained batch 260 in epoch 7, gen_loss = 0.398961614032358, disc_loss = 0.045242646040030934
Trained batch 261 in epoch 7, gen_loss = 0.3989411223935717, disc_loss = 0.045240532004324194
Trained batch 262 in epoch 7, gen_loss = 0.39899010723987915, disc_loss = 0.04510121413120582
Trained batch 263 in epoch 7, gen_loss = 0.3991589550719117, disc_loss = 0.04505451243885821
Trained batch 264 in epoch 7, gen_loss = 0.39906363386028215, disc_loss = 0.04501855948518189
Trained batch 265 in epoch 7, gen_loss = 0.3991317852099139, disc_loss = 0.044865465920796634
Trained batch 266 in epoch 7, gen_loss = 0.3992151364628295, disc_loss = 0.04473501640766134
Trained batch 267 in epoch 7, gen_loss = 0.39909877472404226, disc_loss = 0.044652209764888595
Trained batch 268 in epoch 7, gen_loss = 0.39923885885667626, disc_loss = 0.04502707699895404
Trained batch 269 in epoch 7, gen_loss = 0.3990337739388148, disc_loss = 0.04602268417710783
Trained batch 270 in epoch 7, gen_loss = 0.3991080024365569, disc_loss = 0.04604251147505597
Trained batch 271 in epoch 7, gen_loss = 0.3990627462592195, disc_loss = 0.04665811818182085
Trained batch 272 in epoch 7, gen_loss = 0.3992527501705365, disc_loss = 0.04670163893035098
Trained batch 273 in epoch 7, gen_loss = 0.3991178910445123, disc_loss = 0.04662272551803965
Trained batch 274 in epoch 7, gen_loss = 0.3992743895270608, disc_loss = 0.046547684210606594
Trained batch 275 in epoch 7, gen_loss = 0.39939325216455734, disc_loss = 0.046439931230228125
Trained batch 276 in epoch 7, gen_loss = 0.3996828016606479, disc_loss = 0.04631402621395375
Trained batch 277 in epoch 7, gen_loss = 0.3997406891996054, disc_loss = 0.04619426596675256
Trained batch 278 in epoch 7, gen_loss = 0.3995988908420754, disc_loss = 0.04606579295042435
Trained batch 279 in epoch 7, gen_loss = 0.3995771216494696, disc_loss = 0.04593617704730215
Trained batch 280 in epoch 7, gen_loss = 0.3996142678201411, disc_loss = 0.045837683869969906
Trained batch 281 in epoch 7, gen_loss = 0.39988022408586865, disc_loss = 0.04578806036680356
Trained batch 282 in epoch 7, gen_loss = 0.399607029272895, disc_loss = 0.04643175779437061
Trained batch 283 in epoch 7, gen_loss = 0.39992715208463264, disc_loss = 0.04715192417161618
Trained batch 284 in epoch 7, gen_loss = 0.40023076356503, disc_loss = 0.04708044790548452
Trained batch 285 in epoch 7, gen_loss = 0.4000349171928593, disc_loss = 0.04700205785261428
Trained batch 286 in epoch 7, gen_loss = 0.39985770807448995, disc_loss = 0.046913600083803984
Trained batch 287 in epoch 7, gen_loss = 0.3999627267734872, disc_loss = 0.04679976443973525
Trained batch 288 in epoch 7, gen_loss = 0.39975414195687714, disc_loss = 0.04666566736448337
Trained batch 289 in epoch 7, gen_loss = 0.39980377174656967, disc_loss = 0.04651668958590719
Trained batch 290 in epoch 7, gen_loss = 0.39983283674594056, disc_loss = 0.046367616346265954
Trained batch 291 in epoch 7, gen_loss = 0.39973240192622356, disc_loss = 0.04621988193495582
Trained batch 292 in epoch 7, gen_loss = 0.39981167247270966, disc_loss = 0.04609315671859494
Trained batch 293 in epoch 7, gen_loss = 0.39983892592848563, disc_loss = 0.04606865001620636
Trained batch 294 in epoch 7, gen_loss = 0.39988460106364754, disc_loss = 0.04600909715202653
Trained batch 295 in epoch 7, gen_loss = 0.3995961802634033, disc_loss = 0.04598372783732122
Trained batch 296 in epoch 7, gen_loss = 0.39990302789893617, disc_loss = 0.04585923318929895
Trained batch 297 in epoch 7, gen_loss = 0.3999311655959827, disc_loss = 0.04586030024528853
Trained batch 298 in epoch 7, gen_loss = 0.4000876368487559, disc_loss = 0.04575830828678797
Trained batch 299 in epoch 7, gen_loss = 0.40012518028418226, disc_loss = 0.04562734406751891
Trained batch 300 in epoch 7, gen_loss = 0.40035771590926716, disc_loss = 0.045500068838686444
Trained batch 301 in epoch 7, gen_loss = 0.40024293613749623, disc_loss = 0.04539106247194161
Trained batch 302 in epoch 7, gen_loss = 0.4002885653240846, disc_loss = 0.04525488108802255
Trained batch 303 in epoch 7, gen_loss = 0.4001878969567387, disc_loss = 0.045165527958153304
Trained batch 304 in epoch 7, gen_loss = 0.4003262001960004, disc_loss = 0.045072946743276276
Trained batch 305 in epoch 7, gen_loss = 0.4003164626998839, disc_loss = 0.044999727805820754
Trained batch 306 in epoch 7, gen_loss = 0.4006490438497028, disc_loss = 0.04491317302219157
Trained batch 307 in epoch 7, gen_loss = 0.40046754227830217, disc_loss = 0.04478978232613632
Trained batch 308 in epoch 7, gen_loss = 0.4005028012308102, disc_loss = 0.04474422884773475
Trained batch 309 in epoch 7, gen_loss = 0.40051128768151806, disc_loss = 0.04461300280846415
Trained batch 310 in epoch 7, gen_loss = 0.4006431570390413, disc_loss = 0.0444918023691875
Trained batch 311 in epoch 7, gen_loss = 0.40079937369013446, disc_loss = 0.04436858947155997
Trained batch 312 in epoch 7, gen_loss = 0.4008755419200983, disc_loss = 0.04424806964693787
Trained batch 313 in epoch 7, gen_loss = 0.4010186151714082, disc_loss = 0.04412150728682376
Trained batch 314 in epoch 7, gen_loss = 0.40108658586229595, disc_loss = 0.04399801657224695
Trained batch 315 in epoch 7, gen_loss = 0.40113562967958327, disc_loss = 0.04387004353707256
Trained batch 316 in epoch 7, gen_loss = 0.40128799577240687, disc_loss = 0.04375653770643548
Trained batch 317 in epoch 7, gen_loss = 0.4013431934440661, disc_loss = 0.04362953698142496
Trained batch 318 in epoch 7, gen_loss = 0.40132822661564266, disc_loss = 0.043502499452327904
Trained batch 319 in epoch 7, gen_loss = 0.4011820871382952, disc_loss = 0.04339239619512227
Trained batch 320 in epoch 7, gen_loss = 0.4012814190157477, disc_loss = 0.04327059649670862
Trained batch 321 in epoch 7, gen_loss = 0.401414460739734, disc_loss = 0.04314449560171953
Trained batch 322 in epoch 7, gen_loss = 0.40150371092391823, disc_loss = 0.04306508203890555
Trained batch 323 in epoch 7, gen_loss = 0.40154304842890043, disc_loss = 0.04300077241647092
Trained batch 324 in epoch 7, gen_loss = 0.40160421087191656, disc_loss = 0.04290743823736333
Trained batch 325 in epoch 7, gen_loss = 0.40155880482284567, disc_loss = 0.042803436625560326
Trained batch 326 in epoch 7, gen_loss = 0.40164657315347535, disc_loss = 0.04268451548318182
Trained batch 327 in epoch 7, gen_loss = 0.4017400633452869, disc_loss = 0.04256848622718258
Trained batch 328 in epoch 7, gen_loss = 0.4016944262394427, disc_loss = 0.04247202744953742
Trained batch 329 in epoch 7, gen_loss = 0.40181992929993254, disc_loss = 0.04235964148855684
Trained batch 330 in epoch 7, gen_loss = 0.40176173315307523, disc_loss = 0.04225832262791108
Trained batch 331 in epoch 7, gen_loss = 0.40193252857909145, disc_loss = 0.04218601039961452
Trained batch 332 in epoch 7, gen_loss = 0.4020590212073054, disc_loss = 0.04207853921241611
Trained batch 333 in epoch 7, gen_loss = 0.4021601200460674, disc_loss = 0.041963046316955306
Trained batch 334 in epoch 7, gen_loss = 0.40236538399511307, disc_loss = 0.0419096223405326
Trained batch 335 in epoch 7, gen_loss = 0.4022323748185521, disc_loss = 0.041804115531184446
Trained batch 336 in epoch 7, gen_loss = 0.40211287211593605, disc_loss = 0.04170409045513797
Trained batch 337 in epoch 7, gen_loss = 0.4021380336503305, disc_loss = 0.04161939212223019
Trained batch 338 in epoch 7, gen_loss = 0.4021179265504741, disc_loss = 0.041557277461436955
Trained batch 339 in epoch 7, gen_loss = 0.4021707113174831, disc_loss = 0.041476787976674076
Trained batch 340 in epoch 7, gen_loss = 0.402299778552349, disc_loss = 0.04139047137275884
Trained batch 341 in epoch 7, gen_loss = 0.4023545143897073, disc_loss = 0.041296659739366706
Trained batch 342 in epoch 7, gen_loss = 0.40249159098019055, disc_loss = 0.041272575447726834
Trained batch 343 in epoch 7, gen_loss = 0.40259039453988854, disc_loss = 0.04120749091596863
Trained batch 344 in epoch 7, gen_loss = 0.40274907462838766, disc_loss = 0.041102135820530246
Trained batch 345 in epoch 7, gen_loss = 0.40274682468761597, disc_loss = 0.0410201363447203
Trained batch 346 in epoch 7, gen_loss = 0.40281720094447176, disc_loss = 0.04091259597140426
Trained batch 347 in epoch 7, gen_loss = 0.4028316932334297, disc_loss = 0.04081515838785482
Trained batch 348 in epoch 7, gen_loss = 0.4027358219241003, disc_loss = 0.04073804425793489
Trained batch 349 in epoch 7, gen_loss = 0.40292413898876733, disc_loss = 0.04064550057253135
Trained batch 350 in epoch 7, gen_loss = 0.4029957439824727, disc_loss = 0.040550129865548255
Trained batch 351 in epoch 7, gen_loss = 0.40289162268692796, disc_loss = 0.04048148159596498
Trained batch 352 in epoch 7, gen_loss = 0.4028337694936704, disc_loss = 0.04039176428761787
Trained batch 353 in epoch 7, gen_loss = 0.4028681798674966, disc_loss = 0.04031723358413194
Trained batch 354 in epoch 7, gen_loss = 0.4028932655361337, disc_loss = 0.0402173049006821
Trained batch 355 in epoch 7, gen_loss = 0.40298409492112275, disc_loss = 0.040120167137788126
Trained batch 356 in epoch 7, gen_loss = 0.40297293779896753, disc_loss = 0.04004108234626927
Trained batch 357 in epoch 7, gen_loss = 0.4031220041007303, disc_loss = 0.03995772358355263
Trained batch 358 in epoch 7, gen_loss = 0.4031384231154301, disc_loss = 0.03986429687768408
Trained batch 359 in epoch 7, gen_loss = 0.4032244097855356, disc_loss = 0.03978465817053802
Trained batch 360 in epoch 7, gen_loss = 0.403297461053341, disc_loss = 0.03969073688309547
Trained batch 361 in epoch 7, gen_loss = 0.4034493519456347, disc_loss = 0.03964093114051309
Trained batch 362 in epoch 7, gen_loss = 0.40332007350672044, disc_loss = 0.03954015475872278
Trained batch 363 in epoch 7, gen_loss = 0.40335402269284804, disc_loss = 0.03952477445280957
Trained batch 364 in epoch 7, gen_loss = 0.4034242837396387, disc_loss = 0.03942797656477212
Trained batch 365 in epoch 7, gen_loss = 0.4035330727452137, disc_loss = 0.03939109903192809
Trained batch 366 in epoch 7, gen_loss = 0.4034971942368905, disc_loss = 0.03929265864175676
Trained batch 367 in epoch 7, gen_loss = 0.40330010676837486, disc_loss = 0.03922031852277502
Trained batch 368 in epoch 7, gen_loss = 0.4032084769026697, disc_loss = 0.039132168476765115
Trained batch 369 in epoch 7, gen_loss = 0.40313229117844557, disc_loss = 0.039052326771481016
Trained batch 370 in epoch 7, gen_loss = 0.40328631198631143, disc_loss = 0.038969943405949885
Trained batch 371 in epoch 7, gen_loss = 0.4035019643043959, disc_loss = 0.03888035266001719
Trained batch 372 in epoch 7, gen_loss = 0.40328947316865177, disc_loss = 0.03878410380138908
Trained batch 373 in epoch 7, gen_loss = 0.40319724492529496, disc_loss = 0.038711263642541786
Trained batch 374 in epoch 7, gen_loss = 0.4033469038804372, disc_loss = 0.03861807253335913
Trained batch 375 in epoch 7, gen_loss = 0.4034353792667389, disc_loss = 0.0385259360612489
Trained batch 376 in epoch 7, gen_loss = 0.4034335788744514, disc_loss = 0.03844349632479389
Trained batch 377 in epoch 7, gen_loss = 0.4033218853215061, disc_loss = 0.038350019188814616
Trained batch 378 in epoch 7, gen_loss = 0.4034062101060923, disc_loss = 0.03830467595406722
Trained batch 379 in epoch 7, gen_loss = 0.4032771238370946, disc_loss = 0.038241704441852084
Trained batch 380 in epoch 7, gen_loss = 0.4032244460163467, disc_loss = 0.03815668167820166
Trained batch 381 in epoch 7, gen_loss = 0.4033812474829988, disc_loss = 0.038064919156144274
Trained batch 382 in epoch 7, gen_loss = 0.40353458388355945, disc_loss = 0.03798375758476186
Trained batch 383 in epoch 7, gen_loss = 0.40357186024387676, disc_loss = 0.03789278632029891
Trained batch 384 in epoch 7, gen_loss = 0.40343425908646025, disc_loss = 0.037867918663791245
Trained batch 385 in epoch 7, gen_loss = 0.40386401680467043, disc_loss = 0.03795741459383711
Trained batch 386 in epoch 7, gen_loss = 0.4039232850228785, disc_loss = 0.03789353504950224
Trained batch 387 in epoch 7, gen_loss = 0.4038075605772205, disc_loss = 0.037861148351515383
Trained batch 388 in epoch 7, gen_loss = 0.403703681454254, disc_loss = 0.03783508135929972
Trained batch 389 in epoch 7, gen_loss = 0.4038259567358555, disc_loss = 0.037751449492927164
Trained batch 390 in epoch 7, gen_loss = 0.4040416325906963, disc_loss = 0.0377219294631363
Trained batch 391 in epoch 7, gen_loss = 0.40425124581979244, disc_loss = 0.03764302948399504
Trained batch 392 in epoch 7, gen_loss = 0.40426536674111246, disc_loss = 0.037558265755535995
Trained batch 393 in epoch 7, gen_loss = 0.404064369534478, disc_loss = 0.03747618196740141
Trained batch 394 in epoch 7, gen_loss = 0.40391627934914603, disc_loss = 0.03739793061667794
Trained batch 395 in epoch 7, gen_loss = 0.4038576430293045, disc_loss = 0.03732620122856602
Trained batch 396 in epoch 7, gen_loss = 0.4038943908076442, disc_loss = 0.03724809007024772
Trained batch 397 in epoch 7, gen_loss = 0.40385422844383584, disc_loss = 0.03716638186904391
Trained batch 398 in epoch 7, gen_loss = 0.40383255093318776, disc_loss = 0.03709051937896544
Trained batch 399 in epoch 7, gen_loss = 0.40379026740789414, disc_loss = 0.0370064964145422
Trained batch 400 in epoch 7, gen_loss = 0.4037148372044884, disc_loss = 0.03692400801643506
Trained batch 401 in epoch 7, gen_loss = 0.4038156660190269, disc_loss = 0.036845808137504765
Trained batch 402 in epoch 7, gen_loss = 0.4038316092035611, disc_loss = 0.03677586045707795
Trained batch 403 in epoch 7, gen_loss = 0.4038110617363807, disc_loss = 0.03670894110455445
Trained batch 404 in epoch 7, gen_loss = 0.40377055252039873, disc_loss = 0.036669834052430995
Trained batch 405 in epoch 7, gen_loss = 0.4037464818930978, disc_loss = 0.036599872131451154
Trained batch 406 in epoch 7, gen_loss = 0.4037109607560629, disc_loss = 0.036524485149111885
Trained batch 407 in epoch 7, gen_loss = 0.4039114366705511, disc_loss = 0.0365157326176653
Trained batch 408 in epoch 7, gen_loss = 0.4038975664339322, disc_loss = 0.036522245341980224
Trained batch 409 in epoch 7, gen_loss = 0.4040024582205749, disc_loss = 0.03646402809450903
Trained batch 410 in epoch 7, gen_loss = 0.40402575747230046, disc_loss = 0.036475584887584483
Trained batch 411 in epoch 7, gen_loss = 0.4040128765899001, disc_loss = 0.036561618348836755
Trained batch 412 in epoch 7, gen_loss = 0.40424699565400224, disc_loss = 0.03648159895588353
Trained batch 413 in epoch 7, gen_loss = 0.4042109307891505, disc_loss = 0.036435827972808324
Trained batch 414 in epoch 7, gen_loss = 0.4041483759161938, disc_loss = 0.03635639537754188
Trained batch 415 in epoch 7, gen_loss = 0.4040896098774213, disc_loss = 0.03628385845289673
Trained batch 416 in epoch 7, gen_loss = 0.40400370891145665, disc_loss = 0.03625644821276089
Trained batch 417 in epoch 7, gen_loss = 0.40412067026612863, disc_loss = 0.036245763115807655
Trained batch 418 in epoch 7, gen_loss = 0.4041538269110113, disc_loss = 0.036201097667972984
Trained batch 419 in epoch 7, gen_loss = 0.4042817142038118, disc_loss = 0.036129045702650076
Trained batch 420 in epoch 7, gen_loss = 0.40427772442405413, disc_loss = 0.03608643397525165
Trained batch 421 in epoch 7, gen_loss = 0.4044522035037172, disc_loss = 0.03606441569232086
Trained batch 422 in epoch 7, gen_loss = 0.40437127167169645, disc_loss = 0.03602041370933325
Trained batch 423 in epoch 7, gen_loss = 0.40449802542351326, disc_loss = 0.03600874531658296
Trained batch 424 in epoch 7, gen_loss = 0.4045944344997406, disc_loss = 0.03597145438961247
Trained batch 425 in epoch 7, gen_loss = 0.40459571848732767, disc_loss = 0.03595862898236674
Trained batch 426 in epoch 7, gen_loss = 0.404720311910263, disc_loss = 0.035986410313235725
Trained batch 427 in epoch 7, gen_loss = 0.4047091442430131, disc_loss = 0.035928613452945846
Trained batch 428 in epoch 7, gen_loss = 0.40450890990959737, disc_loss = 0.03601477893355947
Trained batch 429 in epoch 7, gen_loss = 0.4045096170763637, disc_loss = 0.03602391266437291
Trained batch 430 in epoch 7, gen_loss = 0.4045664872066604, disc_loss = 0.035964148898075254
Trained batch 431 in epoch 7, gen_loss = 0.4044183632703843, disc_loss = 0.03592100923695533
Trained batch 432 in epoch 7, gen_loss = 0.4045023771549207, disc_loss = 0.035870853571681516
Trained batch 433 in epoch 7, gen_loss = 0.4046005792744149, disc_loss = 0.03582596224046008
Trained batch 434 in epoch 7, gen_loss = 0.4046474286879616, disc_loss = 0.035888052480188254
Trained batch 435 in epoch 7, gen_loss = 0.4045043599304803, disc_loss = 0.03610604702080643
Trained batch 436 in epoch 7, gen_loss = 0.404565721954852, disc_loss = 0.03652129966437442
Trained batch 437 in epoch 7, gen_loss = 0.4045448905392869, disc_loss = 0.0365050170861916
Trained batch 438 in epoch 7, gen_loss = 0.40443134165298966, disc_loss = 0.036457876847730206
Trained batch 439 in epoch 7, gen_loss = 0.4045609383420511, disc_loss = 0.036460220006252216
Trained batch 440 in epoch 7, gen_loss = 0.4044884973102146, disc_loss = 0.03662143301856525
Trained batch 441 in epoch 7, gen_loss = 0.4045283128907778, disc_loss = 0.03766035874020224
Trained batch 442 in epoch 7, gen_loss = 0.4044579195518795, disc_loss = 0.037759826433451736
Trained batch 443 in epoch 7, gen_loss = 0.40435041500641417, disc_loss = 0.0378017308377149
Trained batch 444 in epoch 7, gen_loss = 0.4041373986206698, disc_loss = 0.03783746129529697
Trained batch 445 in epoch 7, gen_loss = 0.4040200959540269, disc_loss = 0.03795535149649955
Trained batch 446 in epoch 7, gen_loss = 0.40396645711839063, disc_loss = 0.038166518067895235
Trained batch 447 in epoch 7, gen_loss = 0.40383509513256804, disc_loss = 0.0382346887625837
Trained batch 448 in epoch 7, gen_loss = 0.40388009609252146, disc_loss = 0.03835694201991692
Trained batch 449 in epoch 7, gen_loss = 0.4038503862751855, disc_loss = 0.038488363247985644
Trained batch 450 in epoch 7, gen_loss = 0.40371769157851617, disc_loss = 0.03863560359309657
Trained batch 451 in epoch 7, gen_loss = 0.4037516013579031, disc_loss = 0.03936795876011154
Trained batch 452 in epoch 7, gen_loss = 0.40374062313938774, disc_loss = 0.03942917156286094
Trained batch 453 in epoch 7, gen_loss = 0.40368223859875213, disc_loss = 0.03973605310326926
Trained batch 454 in epoch 7, gen_loss = 0.4037011971840492, disc_loss = 0.03995226697464074
Trained batch 455 in epoch 7, gen_loss = 0.4037748565407176, disc_loss = 0.039940849417338574
Trained batch 456 in epoch 7, gen_loss = 0.40365590204034385, disc_loss = 0.039943773443127946
Trained batch 457 in epoch 7, gen_loss = 0.4035707570970319, disc_loss = 0.03997416571941731
Trained batch 458 in epoch 7, gen_loss = 0.40362394401450563, disc_loss = 0.04004481660956943
Trained batch 459 in epoch 7, gen_loss = 0.4036493182182312, disc_loss = 0.03999966253911186
Trained batch 460 in epoch 7, gen_loss = 0.4034187554537345, disc_loss = 0.040579769918957724
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.4072858691215515, disc_loss = 0.23577839136123657
Trained batch 1 in epoch 8, gen_loss = 0.41079866886138916, disc_loss = 0.12707082834094763
Trained batch 2 in epoch 8, gen_loss = 0.39947256445884705, disc_loss = 0.11446609285970528
Trained batch 3 in epoch 8, gen_loss = 0.3986134007573128, disc_loss = 0.09403796447440982
Trained batch 4 in epoch 8, gen_loss = 0.40476242899894715, disc_loss = 0.11254784427583217
Trained batch 5 in epoch 8, gen_loss = 0.39835596084594727, disc_loss = 0.10147782942901055
Trained batch 6 in epoch 8, gen_loss = 0.40012337480272564, disc_loss = 0.0940592312919242
Trained batch 7 in epoch 8, gen_loss = 0.3958309143781662, disc_loss = 0.08406889042817056
Trained batch 8 in epoch 8, gen_loss = 0.39856000741322833, disc_loss = 0.07638383263515101
Trained batch 9 in epoch 8, gen_loss = 0.39798627197742464, disc_loss = 0.07074567172676324
Trained batch 10 in epoch 8, gen_loss = 0.3993378904732791, disc_loss = 0.06486007198691368
Trained batch 11 in epoch 8, gen_loss = 0.3953359971443812, disc_loss = 0.06776544296493132
Trained batch 12 in epoch 8, gen_loss = 0.4078335120127751, disc_loss = 0.09104886737007362
Trained batch 13 in epoch 8, gen_loss = 0.404151514172554, disc_loss = 0.10156814620963164
Trained batch 14 in epoch 8, gen_loss = 0.39998878439267477, disc_loss = 0.10079942718148231
Trained batch 15 in epoch 8, gen_loss = 0.3979246225208044, disc_loss = 0.09989268821664155
Trained batch 16 in epoch 8, gen_loss = 0.399843890877331, disc_loss = 0.09883787285755663
Trained batch 17 in epoch 8, gen_loss = 0.40396251612239414, disc_loss = 0.09593624311188857
Trained batch 18 in epoch 8, gen_loss = 0.4036236577912381, disc_loss = 0.09159640188475973
Trained batch 19 in epoch 8, gen_loss = 0.4044195175170898, disc_loss = 0.08729519918560982
Trained batch 20 in epoch 8, gen_loss = 0.40566874543825787, disc_loss = 0.0834621305000924
Trained batch 21 in epoch 8, gen_loss = 0.405041674321348, disc_loss = 0.08068734504790469
Trained batch 22 in epoch 8, gen_loss = 0.40450858681098273, disc_loss = 0.07806566596517096
Trained batch 23 in epoch 8, gen_loss = 0.40282778814435005, disc_loss = 0.07521266641560942
Trained batch 24 in epoch 8, gen_loss = 0.40312076210975645, disc_loss = 0.07259056340903043
Trained batch 25 in epoch 8, gen_loss = 0.4058891466030708, disc_loss = 0.07007031758817342
Trained batch 26 in epoch 8, gen_loss = 0.4033126488879875, disc_loss = 0.06876010089008897
Trained batch 27 in epoch 8, gen_loss = 0.4041789078286716, disc_loss = 0.06747860674347196
Trained batch 28 in epoch 8, gen_loss = 0.4046410394125971, disc_loss = 0.06542589643905902
Trained batch 29 in epoch 8, gen_loss = 0.40595787862936655, disc_loss = 0.06384406207750241
Trained batch 30 in epoch 8, gen_loss = 0.40768146611029105, disc_loss = 0.06208968348801136
Trained batch 31 in epoch 8, gen_loss = 0.40873638074845076, disc_loss = 0.060433012928115204
Trained batch 32 in epoch 8, gen_loss = 0.40675565058534796, disc_loss = 0.062267128293487156
Trained batch 33 in epoch 8, gen_loss = 0.40963326043942394, disc_loss = 0.0752750232213122
Trained batch 34 in epoch 8, gen_loss = 0.4089861341885158, disc_loss = 0.07442999144217798
Trained batch 35 in epoch 8, gen_loss = 0.4067787287963761, disc_loss = 0.074008862927763
Trained batch 36 in epoch 8, gen_loss = 0.4060518733552984, disc_loss = 0.07300892706356339
Trained batch 37 in epoch 8, gen_loss = 0.40557267869773667, disc_loss = 0.07207474683558471
Trained batch 38 in epoch 8, gen_loss = 0.40406558299675965, disc_loss = 0.07224922935263468
Trained batch 39 in epoch 8, gen_loss = 0.40269078239798545, disc_loss = 0.07264474632684141
Trained batch 40 in epoch 8, gen_loss = 0.4019063602133495, disc_loss = 0.07213113568268897
Trained batch 41 in epoch 8, gen_loss = 0.40172710234210607, disc_loss = 0.07117013280679073
Trained batch 42 in epoch 8, gen_loss = 0.4013286149779031, disc_loss = 0.07036213578959537
Trained batch 43 in epoch 8, gen_loss = 0.40099523013288324, disc_loss = 0.06923423730768263
Trained batch 44 in epoch 8, gen_loss = 0.40112224221229553, disc_loss = 0.06802693288773298
Trained batch 45 in epoch 8, gen_loss = 0.40218553659708606, disc_loss = 0.0669272251062743
Trained batch 46 in epoch 8, gen_loss = 0.40214215884817406, disc_loss = 0.06653560212555718
Trained batch 47 in epoch 8, gen_loss = 0.4049008395522833, disc_loss = 0.06996921005581196
Trained batch 48 in epoch 8, gen_loss = 0.4042478495714616, disc_loss = 0.07588742815946438
Trained batch 49 in epoch 8, gen_loss = 0.40524324893951413, disc_loss = 0.079580063726753
Trained batch 50 in epoch 8, gen_loss = 0.4054710742305307, disc_loss = 0.0784046872537218
Trained batch 51 in epoch 8, gen_loss = 0.4042278528213501, disc_loss = 0.07740821028486468
Trained batch 52 in epoch 8, gen_loss = 0.40330697118111375, disc_loss = 0.07633296377464847
Trained batch 53 in epoch 8, gen_loss = 0.40333100656668347, disc_loss = 0.07511461322644243
Trained batch 54 in epoch 8, gen_loss = 0.4043295042081313, disc_loss = 0.07393081956966356
Trained batch 55 in epoch 8, gen_loss = 0.4034814068249294, disc_loss = 0.07269469259439834
Trained batch 56 in epoch 8, gen_loss = 0.4033000396009077, disc_loss = 0.07152365089247101
Trained batch 57 in epoch 8, gen_loss = 0.40333541508378656, disc_loss = 0.07033588569450738
Trained batch 58 in epoch 8, gen_loss = 0.40388022388442085, disc_loss = 0.06924379232607908
Trained batch 59 in epoch 8, gen_loss = 0.40266296118497846, disc_loss = 0.06821976444528749
Trained batch 60 in epoch 8, gen_loss = 0.4024550235662304, disc_loss = 0.06717568251960834
Trained batch 61 in epoch 8, gen_loss = 0.4019569744986872, disc_loss = 0.06630524717301371
Trained batch 62 in epoch 8, gen_loss = 0.40181137361223734, disc_loss = 0.0658581171790877
Trained batch 63 in epoch 8, gen_loss = 0.4024666855111718, disc_loss = 0.06559649011614965
Trained batch 64 in epoch 8, gen_loss = 0.40197846660247216, disc_loss = 0.06651638007651155
Trained batch 65 in epoch 8, gen_loss = 0.402020046656782, disc_loss = 0.06773910734266268
Trained batch 66 in epoch 8, gen_loss = 0.4011345278860918, disc_loss = 0.0686002266454274
Trained batch 67 in epoch 8, gen_loss = 0.39980445363942313, disc_loss = 0.07183028051547487
Trained batch 68 in epoch 8, gen_loss = 0.4001597921917404, disc_loss = 0.07266560948008428
Trained batch 69 in epoch 8, gen_loss = 0.4000407414776938, disc_loss = 0.07244676815212837
Trained batch 70 in epoch 8, gen_loss = 0.39951042684031207, disc_loss = 0.07271371147608463
Trained batch 71 in epoch 8, gen_loss = 0.39983803240789306, disc_loss = 0.07499997913449381
Trained batch 72 in epoch 8, gen_loss = 0.399212556750807, disc_loss = 0.07535997947218688
Trained batch 73 in epoch 8, gen_loss = 0.39974047404688756, disc_loss = 0.07456813780968455
Trained batch 74 in epoch 8, gen_loss = 0.39982806126276654, disc_loss = 0.07368120367949207
Trained batch 75 in epoch 8, gen_loss = 0.39977850019931793, disc_loss = 0.07310294159565513
Trained batch 76 in epoch 8, gen_loss = 0.3991808422974178, disc_loss = 0.07229973178042413
Trained batch 77 in epoch 8, gen_loss = 0.3988683063250322, disc_loss = 0.0714392412143449
Trained batch 78 in epoch 8, gen_loss = 0.3982545684410047, disc_loss = 0.07151408591366644
Trained batch 79 in epoch 8, gen_loss = 0.3984138391911983, disc_loss = 0.07227273680036887
Trained batch 80 in epoch 8, gen_loss = 0.39845916040149737, disc_loss = 0.07162670891180083
Trained batch 81 in epoch 8, gen_loss = 0.3980618500854911, disc_loss = 0.07124198226985044
Trained batch 82 in epoch 8, gen_loss = 0.3991259182073984, disc_loss = 0.07055625760456524
Trained batch 83 in epoch 8, gen_loss = 0.3990310093476659, disc_loss = 0.06984055678670605
Trained batch 84 in epoch 8, gen_loss = 0.4003227069097407, disc_loss = 0.06946231685578823
Trained batch 85 in epoch 8, gen_loss = 0.401119144849999, disc_loss = 0.06893501123196857
Trained batch 86 in epoch 8, gen_loss = 0.4012198054242408, disc_loss = 0.06875284422916927
Trained batch 87 in epoch 8, gen_loss = 0.40057904747399414, disc_loss = 0.06848350747234443
Trained batch 88 in epoch 8, gen_loss = 0.40091064773248825, disc_loss = 0.06777618274490317
Trained batch 89 in epoch 8, gen_loss = 0.40005836288134256, disc_loss = 0.06851957342587411
Trained batch 90 in epoch 8, gen_loss = 0.4016721418925694, disc_loss = 0.07149357980649386
Trained batch 91 in epoch 8, gen_loss = 0.40092859320018603, disc_loss = 0.0708866829973767
Trained batch 92 in epoch 8, gen_loss = 0.40003332623871424, disc_loss = 0.0712631166492018
Trained batch 93 in epoch 8, gen_loss = 0.4006782091678457, disc_loss = 0.07075125693858779
Trained batch 94 in epoch 8, gen_loss = 0.40075675594179255, disc_loss = 0.07038855067895432
Trained batch 95 in epoch 8, gen_loss = 0.40072615041087073, disc_loss = 0.07042954483282908
Trained batch 96 in epoch 8, gen_loss = 0.4007332020813657, disc_loss = 0.07002563011765327
Trained batch 97 in epoch 8, gen_loss = 0.4010637363000792, disc_loss = 0.06951765381084869
Trained batch 98 in epoch 8, gen_loss = 0.40046650020763125, disc_loss = 0.07140697252400445
Trained batch 99 in epoch 8, gen_loss = 0.4008470541238785, disc_loss = 0.07585567593108862
Trained batch 100 in epoch 8, gen_loss = 0.4009002169760147, disc_loss = 0.07697182185118004
Trained batch 101 in epoch 8, gen_loss = 0.4007234471101387, disc_loss = 0.07906466020800758
Trained batch 102 in epoch 8, gen_loss = 0.40048534632886496, disc_loss = 0.0790585013224011
Trained batch 103 in epoch 8, gen_loss = 0.3998388246848033, disc_loss = 0.0785838145037325
Trained batch 104 in epoch 8, gen_loss = 0.39964048181261336, disc_loss = 0.07848202835857158
Trained batch 105 in epoch 8, gen_loss = 0.3992696907722725, disc_loss = 0.07912687431441022
Trained batch 106 in epoch 8, gen_loss = 0.3995354334327662, disc_loss = 0.07934136376672676
Trained batch 107 in epoch 8, gen_loss = 0.3987519247112451, disc_loss = 0.07980632086508666
Trained batch 108 in epoch 8, gen_loss = 0.3982719530206208, disc_loss = 0.08446003559447073
Trained batch 109 in epoch 8, gen_loss = 0.39742392789233816, disc_loss = 0.08619742523455484
Trained batch 110 in epoch 8, gen_loss = 0.39713558527800413, disc_loss = 0.08719127545938701
Trained batch 111 in epoch 8, gen_loss = 0.3977817895689181, disc_loss = 0.08835535358022233
Trained batch 112 in epoch 8, gen_loss = 0.39762241017501965, disc_loss = 0.08896382213611387
Trained batch 113 in epoch 8, gen_loss = 0.396946677251866, disc_loss = 0.08918832531280554
Trained batch 114 in epoch 8, gen_loss = 0.3964939653873444, disc_loss = 0.08927635577628794
Trained batch 115 in epoch 8, gen_loss = 0.39683449628024264, disc_loss = 0.08929937976364304
Trained batch 116 in epoch 8, gen_loss = 0.396368501532791, disc_loss = 0.08923229729183592
Trained batch 117 in epoch 8, gen_loss = 0.39599462585934136, disc_loss = 0.0894420248716754
Trained batch 118 in epoch 8, gen_loss = 0.39599570657024863, disc_loss = 0.09005765599284728
Trained batch 119 in epoch 8, gen_loss = 0.39596233864625296, disc_loss = 0.09050146609467144
Trained batch 120 in epoch 8, gen_loss = 0.39641084626686474, disc_loss = 0.09032650034459046
Trained batch 121 in epoch 8, gen_loss = 0.3960971292413649, disc_loss = 0.08977133177266625
Trained batch 122 in epoch 8, gen_loss = 0.39598295431796127, disc_loss = 0.08917341006889455
Trained batch 123 in epoch 8, gen_loss = 0.3966572474568121, disc_loss = 0.08858454918053242
Trained batch 124 in epoch 8, gen_loss = 0.39689995551109314, disc_loss = 0.08798014229908585
Trained batch 125 in epoch 8, gen_loss = 0.39714272911586457, disc_loss = 0.0876802978334978
Trained batch 126 in epoch 8, gen_loss = 0.3972838624255864, disc_loss = 0.08723886079690236
Trained batch 127 in epoch 8, gen_loss = 0.39777934714220464, disc_loss = 0.08668835685602971
Trained batch 128 in epoch 8, gen_loss = 0.39782762712286424, disc_loss = 0.08626386139527426
Trained batch 129 in epoch 8, gen_loss = 0.39825206307264477, disc_loss = 0.08645884260320319
Trained batch 130 in epoch 8, gen_loss = 0.39822157034437167, disc_loss = 0.08634313278767558
Trained batch 131 in epoch 8, gen_loss = 0.3984314968640154, disc_loss = 0.08614030658535546
Trained batch 132 in epoch 8, gen_loss = 0.39843061252644185, disc_loss = 0.08559261026084983
Trained batch 133 in epoch 8, gen_loss = 0.3983550505406821, disc_loss = 0.08506793404039718
Trained batch 134 in epoch 8, gen_loss = 0.3980626788404253, disc_loss = 0.0845689723647579
Trained batch 135 in epoch 8, gen_loss = 0.3978780063197893, disc_loss = 0.08406541833777309
Trained batch 136 in epoch 8, gen_loss = 0.39815278644979435, disc_loss = 0.08376296590945691
Trained batch 137 in epoch 8, gen_loss = 0.3974575028903242, disc_loss = 0.08373428965189858
Trained batch 138 in epoch 8, gen_loss = 0.397313985249979, disc_loss = 0.0832260668632849
Trained batch 139 in epoch 8, gen_loss = 0.3977935186454228, disc_loss = 0.08273227033537946
Trained batch 140 in epoch 8, gen_loss = 0.39758024169198164, disc_loss = 0.08229375611792536
Trained batch 141 in epoch 8, gen_loss = 0.397614126474085, disc_loss = 0.08183156290668732
Trained batch 142 in epoch 8, gen_loss = 0.39760891374174534, disc_loss = 0.08149246434791835
Trained batch 143 in epoch 8, gen_loss = 0.39713005618088776, disc_loss = 0.08127971995660725
Trained batch 144 in epoch 8, gen_loss = 0.39745744775081504, disc_loss = 0.08090387331964127
Trained batch 145 in epoch 8, gen_loss = 0.3972267543208109, disc_loss = 0.08039202177195415
Trained batch 146 in epoch 8, gen_loss = 0.3975171570469733, disc_loss = 0.0799886413317706
Trained batch 147 in epoch 8, gen_loss = 0.39778462555762883, disc_loss = 0.07953975747679234
Trained batch 148 in epoch 8, gen_loss = 0.3980572437680008, disc_loss = 0.0791965282534643
Trained batch 149 in epoch 8, gen_loss = 0.3973903552691142, disc_loss = 0.07879232396992544
Trained batch 150 in epoch 8, gen_loss = 0.39732246801553184, disc_loss = 0.07888232788613794
Trained batch 151 in epoch 8, gen_loss = 0.3983323707392341, disc_loss = 0.08009294200210686
Trained batch 152 in epoch 8, gen_loss = 0.39838405937151194, disc_loss = 0.07967661075549674
Trained batch 153 in epoch 8, gen_loss = 0.3975596313739752, disc_loss = 0.07957416485281443
Trained batch 154 in epoch 8, gen_loss = 0.39739679348084234, disc_loss = 0.0791056678600369
Trained batch 155 in epoch 8, gen_loss = 0.3972661670966026, disc_loss = 0.0787166570707296
Trained batch 156 in epoch 8, gen_loss = 0.3975006421660162, disc_loss = 0.07833535641218257
Trained batch 157 in epoch 8, gen_loss = 0.39767659144311013, disc_loss = 0.07789569167137335
Trained batch 158 in epoch 8, gen_loss = 0.3975677059131598, disc_loss = 0.07745603373590505
Trained batch 159 in epoch 8, gen_loss = 0.3976416364312172, disc_loss = 0.07701211837120354
Trained batch 160 in epoch 8, gen_loss = 0.39731013552742717, disc_loss = 0.07665384482152714
Trained batch 161 in epoch 8, gen_loss = 0.39737789921554517, disc_loss = 0.07626808306524231
Trained batch 162 in epoch 8, gen_loss = 0.39711809688550564, disc_loss = 0.07586209657687716
Trained batch 163 in epoch 8, gen_loss = 0.3966907130145445, disc_loss = 0.0757359656414426
Trained batch 164 in epoch 8, gen_loss = 0.3966944568084948, disc_loss = 0.07697021955567779
Trained batch 165 in epoch 8, gen_loss = 0.3969116587954831, disc_loss = 0.07979707683560001
Trained batch 166 in epoch 8, gen_loss = 0.3964822661733913, disc_loss = 0.07997065536053238
Trained batch 167 in epoch 8, gen_loss = 0.39639737598952796, disc_loss = 0.08022154214614559
Trained batch 168 in epoch 8, gen_loss = 0.3966284269059198, disc_loss = 0.08054171497079395
Trained batch 169 in epoch 8, gen_loss = 0.39683666211717267, disc_loss = 0.08063762015937005
Trained batch 170 in epoch 8, gen_loss = 0.3968184074463203, disc_loss = 0.08105568652046703
Trained batch 171 in epoch 8, gen_loss = 0.39690427326185757, disc_loss = 0.08132470376399714
Trained batch 172 in epoch 8, gen_loss = 0.39631599859695216, disc_loss = 0.08181934363364829
Trained batch 173 in epoch 8, gen_loss = 0.39666567023458155, disc_loss = 0.08223065788504379
Trained batch 174 in epoch 8, gen_loss = 0.39642294219561985, disc_loss = 0.08347752455089773
Trained batch 175 in epoch 8, gen_loss = 0.396464820781892, disc_loss = 0.08416985401841388
Trained batch 176 in epoch 8, gen_loss = 0.3964805756248323, disc_loss = 0.08443572581614141
Trained batch 177 in epoch 8, gen_loss = 0.395937396904056, disc_loss = 0.08464150569202859
Trained batch 178 in epoch 8, gen_loss = 0.39608891283333636, disc_loss = 0.08500991498416695
Trained batch 179 in epoch 8, gen_loss = 0.39641507234838275, disc_loss = 0.0850966910003788
Trained batch 180 in epoch 8, gen_loss = 0.39671363652740393, disc_loss = 0.08565852238451907
Trained batch 181 in epoch 8, gen_loss = 0.39637571344008815, disc_loss = 0.08657556701615289
Trained batch 182 in epoch 8, gen_loss = 0.39666761840627496, disc_loss = 0.08660493097955087
Trained batch 183 in epoch 8, gen_loss = 0.3963485855771148, disc_loss = 0.08624603893891301
Trained batch 184 in epoch 8, gen_loss = 0.39646327431137496, disc_loss = 0.08587330576737184
Trained batch 185 in epoch 8, gen_loss = 0.396349817354192, disc_loss = 0.08545934833506103
Trained batch 186 in epoch 8, gen_loss = 0.39632972628675045, disc_loss = 0.08507966820927546
Trained batch 187 in epoch 8, gen_loss = 0.39586444278346733, disc_loss = 0.08469384204239604
Trained batch 188 in epoch 8, gen_loss = 0.3958406727465372, disc_loss = 0.08428042153359722
Trained batch 189 in epoch 8, gen_loss = 0.39604027239899886, disc_loss = 0.08399075581447074
Trained batch 190 in epoch 8, gen_loss = 0.39550956880859056, disc_loss = 0.08393670784319258
Trained batch 191 in epoch 8, gen_loss = 0.39536741220702726, disc_loss = 0.08435055157557751
Trained batch 192 in epoch 8, gen_loss = 0.3953854132810405, disc_loss = 0.08454331699662258
Trained batch 193 in epoch 8, gen_loss = 0.3954206513068111, disc_loss = 0.08417382336116021
Trained batch 194 in epoch 8, gen_loss = 0.3951978263182518, disc_loss = 0.08389279077259394
Trained batch 195 in epoch 8, gen_loss = 0.39504390027450054, disc_loss = 0.08357000725381837
Trained batch 196 in epoch 8, gen_loss = 0.39483612972467685, disc_loss = 0.08320030854627262
Trained batch 197 in epoch 8, gen_loss = 0.39502988680444584, disc_loss = 0.08289033590317374
Trained batch 198 in epoch 8, gen_loss = 0.39563000651460195, disc_loss = 0.08315639439315053
Trained batch 199 in epoch 8, gen_loss = 0.3956356012821198, disc_loss = 0.08411836991086602
Trained batch 200 in epoch 8, gen_loss = 0.3958191489105794, disc_loss = 0.08387046852218571
Trained batch 201 in epoch 8, gen_loss = 0.3962192935223627, disc_loss = 0.08366769423136616
Trained batch 202 in epoch 8, gen_loss = 0.3958691227905856, disc_loss = 0.08331720592004471
Trained batch 203 in epoch 8, gen_loss = 0.39549823908829224, disc_loss = 0.08295439391889993
Trained batch 204 in epoch 8, gen_loss = 0.39564217358100706, disc_loss = 0.08270907093112062
Trained batch 205 in epoch 8, gen_loss = 0.3958100184653569, disc_loss = 0.08237161985553294
Trained batch 206 in epoch 8, gen_loss = 0.39600360566291254, disc_loss = 0.08212204957785814
Trained batch 207 in epoch 8, gen_loss = 0.3960082963682138, disc_loss = 0.08190934506889719
Trained batch 208 in epoch 8, gen_loss = 0.39597921009269055, disc_loss = 0.08178402023594916
Trained batch 209 in epoch 8, gen_loss = 0.39603457621165683, disc_loss = 0.08167639710009097
Trained batch 210 in epoch 8, gen_loss = 0.3958658722904621, disc_loss = 0.08207648330460793
Trained batch 211 in epoch 8, gen_loss = 0.396227756901732, disc_loss = 0.08201073589822594
Trained batch 212 in epoch 8, gen_loss = 0.3965877153224229, disc_loss = 0.0818297161847493
Trained batch 213 in epoch 8, gen_loss = 0.39613845456983443, disc_loss = 0.08186646263663457
Trained batch 214 in epoch 8, gen_loss = 0.39629759039989737, disc_loss = 0.08161463776473389
Trained batch 215 in epoch 8, gen_loss = 0.39662637616749163, disc_loss = 0.0814202844803394
Trained batch 216 in epoch 8, gen_loss = 0.39660947745846165, disc_loss = 0.08116709819484141
Trained batch 217 in epoch 8, gen_loss = 0.39642841307395094, disc_loss = 0.08085157135672388
Trained batch 218 in epoch 8, gen_loss = 0.39632801024336795, disc_loss = 0.0805469642491101
Trained batch 219 in epoch 8, gen_loss = 0.396157675168731, disc_loss = 0.08040617738257755
Trained batch 220 in epoch 8, gen_loss = 0.39598390878055967, disc_loss = 0.0801785901374272
Trained batch 221 in epoch 8, gen_loss = 0.39592852262226313, disc_loss = 0.07992579797198912
Trained batch 222 in epoch 8, gen_loss = 0.39621264691310076, disc_loss = 0.07973188518508935
Trained batch 223 in epoch 8, gen_loss = 0.396005876761462, disc_loss = 0.07949961057498253
Trained batch 224 in epoch 8, gen_loss = 0.3959447202417586, disc_loss = 0.07921957035031583
Trained batch 225 in epoch 8, gen_loss = 0.396146190904938, disc_loss = 0.07906739597530228
Trained batch 226 in epoch 8, gen_loss = 0.3963954331853841, disc_loss = 0.07897216084080909
Trained batch 227 in epoch 8, gen_loss = 0.39598839560098814, disc_loss = 0.0795578279761238
Trained batch 228 in epoch 8, gen_loss = 0.3960131234997745, disc_loss = 0.0796144880826166
Trained batch 229 in epoch 8, gen_loss = 0.39606023068013396, disc_loss = 0.07930246927653965
Trained batch 230 in epoch 8, gen_loss = 0.3959545489255484, disc_loss = 0.0791345015248824
Trained batch 231 in epoch 8, gen_loss = 0.39638530231755353, disc_loss = 0.07894217747199381
Trained batch 232 in epoch 8, gen_loss = 0.3966353487047515, disc_loss = 0.07867031804657673
Trained batch 233 in epoch 8, gen_loss = 0.3965176769301423, disc_loss = 0.07842618334863304
Trained batch 234 in epoch 8, gen_loss = 0.3966276766137874, disc_loss = 0.07828075536625817
Trained batch 235 in epoch 8, gen_loss = 0.3964191024838868, disc_loss = 0.07840126878739792
Trained batch 236 in epoch 8, gen_loss = 0.3966382881508598, disc_loss = 0.07819461573764117
Trained batch 237 in epoch 8, gen_loss = 0.396699129533367, disc_loss = 0.07805327416452415
Trained batch 238 in epoch 8, gen_loss = 0.39654458903368545, disc_loss = 0.07803250396834632
Trained batch 239 in epoch 8, gen_loss = 0.39655581340193746, disc_loss = 0.07783513771137222
Trained batch 240 in epoch 8, gen_loss = 0.3965304777088007, disc_loss = 0.07765387033046652
Trained batch 241 in epoch 8, gen_loss = 0.39664135811742673, disc_loss = 0.07745226543812343
Trained batch 242 in epoch 8, gen_loss = 0.39689109759566227, disc_loss = 0.07729101567739935
Trained batch 243 in epoch 8, gen_loss = 0.39686617181926476, disc_loss = 0.07715982548724555
Trained batch 244 in epoch 8, gen_loss = 0.39680088101601113, disc_loss = 0.07693240205016064
Trained batch 245 in epoch 8, gen_loss = 0.39717807517788273, disc_loss = 0.07668622919714184
Trained batch 246 in epoch 8, gen_loss = 0.3971629413033304, disc_loss = 0.07644796932892882
Trained batch 247 in epoch 8, gen_loss = 0.3974150075547157, disc_loss = 0.07622187706686917
Trained batch 248 in epoch 8, gen_loss = 0.3973898726055421, disc_loss = 0.07595650022138793
Trained batch 249 in epoch 8, gen_loss = 0.3973444234132767, disc_loss = 0.07570171438530088
Trained batch 250 in epoch 8, gen_loss = 0.3973643792815417, disc_loss = 0.07547934972625449
Trained batch 251 in epoch 8, gen_loss = 0.39746387409312384, disc_loss = 0.07524368379427682
Trained batch 252 in epoch 8, gen_loss = 0.3974883554010052, disc_loss = 0.0749647953978228
Trained batch 253 in epoch 8, gen_loss = 0.3972675227743434, disc_loss = 0.07468953243948108
Trained batch 254 in epoch 8, gen_loss = 0.39722016465430166, disc_loss = 0.07450537764850784
Trained batch 255 in epoch 8, gen_loss = 0.39739077375270426, disc_loss = 0.07430044653301593
Trained batch 256 in epoch 8, gen_loss = 0.3972673156382045, disc_loss = 0.07405956342801857
Trained batch 257 in epoch 8, gen_loss = 0.3974459782358288, disc_loss = 0.07386767557035237
Trained batch 258 in epoch 8, gen_loss = 0.3976996252205381, disc_loss = 0.07361575681356619
Trained batch 259 in epoch 8, gen_loss = 0.39759932160377504, disc_loss = 0.07338369462209252
Trained batch 260 in epoch 8, gen_loss = 0.39766563926163306, disc_loss = 0.07312187293394544
Trained batch 261 in epoch 8, gen_loss = 0.3977049716556345, disc_loss = 0.07286701288486597
Trained batch 262 in epoch 8, gen_loss = 0.39773644308626876, disc_loss = 0.07262378446616147
Trained batch 263 in epoch 8, gen_loss = 0.3979907315788847, disc_loss = 0.07238059953405437
Trained batch 264 in epoch 8, gen_loss = 0.39782975124862957, disc_loss = 0.0721497066775864
Trained batch 265 in epoch 8, gen_loss = 0.39777504703156036, disc_loss = 0.07189892167295504
Trained batch 266 in epoch 8, gen_loss = 0.3980835172790713, disc_loss = 0.07165935900662276
Trained batch 267 in epoch 8, gen_loss = 0.39782048606160864, disc_loss = 0.07143710825745184
Trained batch 268 in epoch 8, gen_loss = 0.39803528785705566, disc_loss = 0.0712065082078031
Trained batch 269 in epoch 8, gen_loss = 0.3981548187909303, disc_loss = 0.0709703607622672
Trained batch 270 in epoch 8, gen_loss = 0.39800128978556815, disc_loss = 0.07089577284658748
Trained batch 271 in epoch 8, gen_loss = 0.39818136898033757, disc_loss = 0.07126401632558554
Trained batch 272 in epoch 8, gen_loss = 0.39834398118567554, disc_loss = 0.07146559240153202
Trained batch 273 in epoch 8, gen_loss = 0.3982129599491175, disc_loss = 0.07137525728121943
Trained batch 274 in epoch 8, gen_loss = 0.39821699001572347, disc_loss = 0.07126915383745323
Trained batch 275 in epoch 8, gen_loss = 0.3980503997940948, disc_loss = 0.071409088269254
Trained batch 276 in epoch 8, gen_loss = 0.39814068188736157, disc_loss = 0.07154105108110267
Trained batch 277 in epoch 8, gen_loss = 0.3983485541112131, disc_loss = 0.07137510903420852
Trained batch 278 in epoch 8, gen_loss = 0.3985177394950689, disc_loss = 0.07127971120018473
Trained batch 279 in epoch 8, gen_loss = 0.39862589857407976, disc_loss = 0.0712428541920547
Trained batch 280 in epoch 8, gen_loss = 0.3987282269577963, disc_loss = 0.07136300848498675
Trained batch 281 in epoch 8, gen_loss = 0.39837367473341895, disc_loss = 0.07155791269152934
Trained batch 282 in epoch 8, gen_loss = 0.39819094707182356, disc_loss = 0.07138670554430662
Trained batch 283 in epoch 8, gen_loss = 0.3985056146769456, disc_loss = 0.07126759274692183
Trained batch 284 in epoch 8, gen_loss = 0.3987262679819475, disc_loss = 0.07119617502678904
Trained batch 285 in epoch 8, gen_loss = 0.3988751120917447, disc_loss = 0.07098768047102681
Trained batch 286 in epoch 8, gen_loss = 0.3988745665301014, disc_loss = 0.07077951239298652
Trained batch 287 in epoch 8, gen_loss = 0.3990130154415965, disc_loss = 0.07065978996171099
Trained batch 288 in epoch 8, gen_loss = 0.3987789608821737, disc_loss = 0.07056927043544999
Trained batch 289 in epoch 8, gen_loss = 0.398555209307835, disc_loss = 0.07064633484415966
Trained batch 290 in epoch 8, gen_loss = 0.3989125543443608, disc_loss = 0.07148566905447502
Trained batch 291 in epoch 8, gen_loss = 0.3989708227654026, disc_loss = 0.07195968509409321
Trained batch 292 in epoch 8, gen_loss = 0.3989448860643667, disc_loss = 0.0719747315176823
Trained batch 293 in epoch 8, gen_loss = 0.39911444262176954, disc_loss = 0.07195342372038535
Trained batch 294 in epoch 8, gen_loss = 0.39923190484612675, disc_loss = 0.07188092675375736
Trained batch 295 in epoch 8, gen_loss = 0.3990471443614444, disc_loss = 0.07200579328235944
Trained batch 296 in epoch 8, gen_loss = 0.3991199189966375, disc_loss = 0.07310999827678959
Trained batch 297 in epoch 8, gen_loss = 0.3991677983095182, disc_loss = 0.07328329285944268
Trained batch 298 in epoch 8, gen_loss = 0.39905985821050943, disc_loss = 0.073414067367098
Trained batch 299 in epoch 8, gen_loss = 0.39886992822090783, disc_loss = 0.07341280488297343
Trained batch 300 in epoch 8, gen_loss = 0.3988780572366873, disc_loss = 0.07338614262442454
Trained batch 301 in epoch 8, gen_loss = 0.3987108827229367, disc_loss = 0.07333821041620528
Trained batch 302 in epoch 8, gen_loss = 0.3986306346879147, disc_loss = 0.07341000239177309
Trained batch 303 in epoch 8, gen_loss = 0.3983348905059852, disc_loss = 0.07366418973910377
Trained batch 304 in epoch 8, gen_loss = 0.3985374093055725, disc_loss = 0.0742485239674322
Trained batch 305 in epoch 8, gen_loss = 0.39834825178376987, disc_loss = 0.0746051151293263
Trained batch 306 in epoch 8, gen_loss = 0.3982943935192369, disc_loss = 0.07439526965301665
Trained batch 307 in epoch 8, gen_loss = 0.39843082118344, disc_loss = 0.07458022581534339
Trained batch 308 in epoch 8, gen_loss = 0.39811917570416594, disc_loss = 0.07495995108219027
Trained batch 309 in epoch 8, gen_loss = 0.39819993992005626, disc_loss = 0.07484812140464783
Trained batch 310 in epoch 8, gen_loss = 0.39808466330985165, disc_loss = 0.07478099236103117
Trained batch 311 in epoch 8, gen_loss = 0.3981095928794298, disc_loss = 0.07474807550748572
Trained batch 312 in epoch 8, gen_loss = 0.3982016137613656, disc_loss = 0.07467542143580251
Trained batch 313 in epoch 8, gen_loss = 0.3979646819791976, disc_loss = 0.0745021017256436
Trained batch 314 in epoch 8, gen_loss = 0.39811538259188334, disc_loss = 0.07430414498916695
Trained batch 315 in epoch 8, gen_loss = 0.39806145533353465, disc_loss = 0.0742023947318615
Trained batch 316 in epoch 8, gen_loss = 0.39811776695943407, disc_loss = 0.07426834255104374
Trained batch 317 in epoch 8, gen_loss = 0.39827609249630813, disc_loss = 0.07426893350861545
Trained batch 318 in epoch 8, gen_loss = 0.39793966070611647, disc_loss = 0.07473827123665323
Trained batch 319 in epoch 8, gen_loss = 0.3981931835412979, disc_loss = 0.07494962723576463
Trained batch 320 in epoch 8, gen_loss = 0.39812661879159206, disc_loss = 0.07486237456145874
Trained batch 321 in epoch 8, gen_loss = 0.39811200495832455, disc_loss = 0.07485207654420079
Trained batch 322 in epoch 8, gen_loss = 0.3982397670347255, disc_loss = 0.07468811549453913
Trained batch 323 in epoch 8, gen_loss = 0.39828923868912236, disc_loss = 0.07450644998454753
Trained batch 324 in epoch 8, gen_loss = 0.3984087468110598, disc_loss = 0.0742969721613022
Trained batch 325 in epoch 8, gen_loss = 0.3983910235524909, disc_loss = 0.07413260194764364
Trained batch 326 in epoch 8, gen_loss = 0.3984236421935055, disc_loss = 0.07395620274981228
Trained batch 327 in epoch 8, gen_loss = 0.39862890450692756, disc_loss = 0.0737982190145952
Trained batch 328 in epoch 8, gen_loss = 0.39857639992853067, disc_loss = 0.073760243138372
Trained batch 329 in epoch 8, gen_loss = 0.3983785557927507, disc_loss = 0.07390766790644689
Trained batch 330 in epoch 8, gen_loss = 0.3982722940221654, disc_loss = 0.07430092806947555
Trained batch 331 in epoch 8, gen_loss = 0.39852242252553804, disc_loss = 0.0749265120802335
Trained batch 332 in epoch 8, gen_loss = 0.3984021979409295, disc_loss = 0.07544037217537204
Trained batch 333 in epoch 8, gen_loss = 0.3985968448087841, disc_loss = 0.07533140584246484
Trained batch 334 in epoch 8, gen_loss = 0.39867587151812084, disc_loss = 0.07525589957610884
Trained batch 335 in epoch 8, gen_loss = 0.3987451307475567, disc_loss = 0.0751231486487779
Trained batch 336 in epoch 8, gen_loss = 0.39834838256637845, disc_loss = 0.075443401877445
Trained batch 337 in epoch 8, gen_loss = 0.39841748976848534, disc_loss = 0.07529069574759203
Trained batch 338 in epoch 8, gen_loss = 0.3983628109844737, disc_loss = 0.07539114497799788
Trained batch 339 in epoch 8, gen_loss = 0.3981644223718082, disc_loss = 0.07541363365290796
Trained batch 340 in epoch 8, gen_loss = 0.3980760957138979, disc_loss = 0.07526901638534061
Trained batch 341 in epoch 8, gen_loss = 0.3979830407259757, disc_loss = 0.0753046364485346
Trained batch 342 in epoch 8, gen_loss = 0.3983568896705138, disc_loss = 0.0754224900101955
Trained batch 343 in epoch 8, gen_loss = 0.3983940747241641, disc_loss = 0.07531729955659357
Trained batch 344 in epoch 8, gen_loss = 0.39837238158004873, disc_loss = 0.07519124655619912
Trained batch 345 in epoch 8, gen_loss = 0.39836051896472885, disc_loss = 0.07519214223488907
Trained batch 346 in epoch 8, gen_loss = 0.3983933228237141, disc_loss = 0.07528667989313087
Trained batch 347 in epoch 8, gen_loss = 0.3984860486682804, disc_loss = 0.07517997763151753
Trained batch 348 in epoch 8, gen_loss = 0.3983516756306405, disc_loss = 0.07543087139042537
Trained batch 349 in epoch 8, gen_loss = 0.3984993230445044, disc_loss = 0.07627328307500908
Trained batch 350 in epoch 8, gen_loss = 0.3983019273675065, disc_loss = 0.07616464007231924
Trained batch 351 in epoch 8, gen_loss = 0.39801414717327466, disc_loss = 0.07608384436885403
Trained batch 352 in epoch 8, gen_loss = 0.3981060710743534, disc_loss = 0.07601038295849524
Trained batch 353 in epoch 8, gen_loss = 0.3980961385588188, disc_loss = 0.07599445646049949
Trained batch 354 in epoch 8, gen_loss = 0.39788672059354646, disc_loss = 0.07594745233654976
Trained batch 355 in epoch 8, gen_loss = 0.39788381512580295, disc_loss = 0.07579353614971879
Trained batch 356 in epoch 8, gen_loss = 0.39780856614687193, disc_loss = 0.07564948917123951
Trained batch 357 in epoch 8, gen_loss = 0.39762348852344065, disc_loss = 0.07568757754734941
Trained batch 358 in epoch 8, gen_loss = 0.3976037051518315, disc_loss = 0.07576682446083484
Trained batch 359 in epoch 8, gen_loss = 0.3975649303860135, disc_loss = 0.07559176939539611
Trained batch 360 in epoch 8, gen_loss = 0.3972927236986292, disc_loss = 0.0759803641566857
Trained batch 361 in epoch 8, gen_loss = 0.3973758983019307, disc_loss = 0.07689256558081557
Trained batch 362 in epoch 8, gen_loss = 0.39741969592971904, disc_loss = 0.07675522335961502
Trained batch 363 in epoch 8, gen_loss = 0.3974345202793132, disc_loss = 0.07672571208696444
Trained batch 364 in epoch 8, gen_loss = 0.39729548349772414, disc_loss = 0.07654896986300815
Trained batch 365 in epoch 8, gen_loss = 0.39743996773912604, disc_loss = 0.07638430771484075
Trained batch 366 in epoch 8, gen_loss = 0.39744734617929695, disc_loss = 0.07620874379205769
Trained batch 367 in epoch 8, gen_loss = 0.39753437827786675, disc_loss = 0.0760905421136514
Trained batch 368 in epoch 8, gen_loss = 0.39712759589922786, disc_loss = 0.07596267943540563
Trained batch 369 in epoch 8, gen_loss = 0.3971198957916853, disc_loss = 0.0759209284609234
Trained batch 370 in epoch 8, gen_loss = 0.39744482540859366, disc_loss = 0.07592307875620709
Trained batch 371 in epoch 8, gen_loss = 0.3974236505887201, disc_loss = 0.07585586997009414
Trained batch 372 in epoch 8, gen_loss = 0.3973969612220657, disc_loss = 0.0757585536119286
Trained batch 373 in epoch 8, gen_loss = 0.39760158465985945, disc_loss = 0.07559794657191331
Trained batch 374 in epoch 8, gen_loss = 0.3976341520547867, disc_loss = 0.07543878923356533
Trained batch 375 in epoch 8, gen_loss = 0.3977124263393752, disc_loss = 0.07533066401238296
Trained batch 376 in epoch 8, gen_loss = 0.39786263490071033, disc_loss = 0.07538670956080568
Trained batch 377 in epoch 8, gen_loss = 0.39763250777488035, disc_loss = 0.07556636992684275
Trained batch 378 in epoch 8, gen_loss = 0.39775211621557505, disc_loss = 0.07539713419826412
Trained batch 379 in epoch 8, gen_loss = 0.39779854060003633, disc_loss = 0.07539263216435517
Trained batch 380 in epoch 8, gen_loss = 0.3976516970421073, disc_loss = 0.07537468334811488
Trained batch 381 in epoch 8, gen_loss = 0.3976738263721241, disc_loss = 0.07524169109400888
Trained batch 382 in epoch 8, gen_loss = 0.39785040370322394, disc_loss = 0.0750749013204293
Trained batch 383 in epoch 8, gen_loss = 0.3979183377620454, disc_loss = 0.07490953983506188
Trained batch 384 in epoch 8, gen_loss = 0.39790497820872767, disc_loss = 0.07488752272608992
Trained batch 385 in epoch 8, gen_loss = 0.39816495857244943, disc_loss = 0.0750025338420905
Trained batch 386 in epoch 8, gen_loss = 0.3982279251789246, disc_loss = 0.07510747741282141
Trained batch 387 in epoch 8, gen_loss = 0.3983369721963848, disc_loss = 0.0749568450456658
Trained batch 388 in epoch 8, gen_loss = 0.3986900801600405, disc_loss = 0.07494653464034008
Trained batch 389 in epoch 8, gen_loss = 0.39865850168160905, disc_loss = 0.07484019135530942
Trained batch 390 in epoch 8, gen_loss = 0.3987074899475288, disc_loss = 0.07473502455331633
Trained batch 391 in epoch 8, gen_loss = 0.39864669287843363, disc_loss = 0.0750664584766313
Trained batch 392 in epoch 8, gen_loss = 0.39880301361623915, disc_loss = 0.07601553805020778
Trained batch 393 in epoch 8, gen_loss = 0.3986974886906934, disc_loss = 0.07597823519978275
Trained batch 394 in epoch 8, gen_loss = 0.39843677610536166, disc_loss = 0.07636340112908732
Trained batch 395 in epoch 8, gen_loss = 0.39858003408469334, disc_loss = 0.07635244890351338
Trained batch 396 in epoch 8, gen_loss = 0.3985312739832876, disc_loss = 0.07625946837479732
Trained batch 397 in epoch 8, gen_loss = 0.3984287625656056, disc_loss = 0.07619075109742245
Trained batch 398 in epoch 8, gen_loss = 0.39834585259283395, disc_loss = 0.07607053030272923
Trained batch 399 in epoch 8, gen_loss = 0.3983379456028342, disc_loss = 0.07599034139420838
Trained batch 400 in epoch 8, gen_loss = 0.3982381297094269, disc_loss = 0.07584976145249799
Trained batch 401 in epoch 8, gen_loss = 0.39828633264967456, disc_loss = 0.07570284914540414
Trained batch 402 in epoch 8, gen_loss = 0.3982490211281528, disc_loss = 0.07554736109704667
Trained batch 403 in epoch 8, gen_loss = 0.3981489622135564, disc_loss = 0.07538025451611986
Trained batch 404 in epoch 8, gen_loss = 0.39810806281036804, disc_loss = 0.07521887744236508
Trained batch 405 in epoch 8, gen_loss = 0.39818208444441483, disc_loss = 0.07516160726391256
Trained batch 406 in epoch 8, gen_loss = 0.3982672212091652, disc_loss = 0.07520376315857547
Trained batch 407 in epoch 8, gen_loss = 0.39814009623346375, disc_loss = 0.07517522995077147
Trained batch 408 in epoch 8, gen_loss = 0.3980480531972894, disc_loss = 0.0751079814371933
Trained batch 409 in epoch 8, gen_loss = 0.39812403310362887, disc_loss = 0.07504853046294756
Trained batch 410 in epoch 8, gen_loss = 0.39818345960184315, disc_loss = 0.075201810636714
Trained batch 411 in epoch 8, gen_loss = 0.39803318921657443, disc_loss = 0.0755529075621365
Trained batch 412 in epoch 8, gen_loss = 0.3982083701120451, disc_loss = 0.07558620486354352
Trained batch 413 in epoch 8, gen_loss = 0.3982074756337249, disc_loss = 0.07572596827701886
Trained batch 414 in epoch 8, gen_loss = 0.3978897600647915, disc_loss = 0.07591267516948731
Trained batch 415 in epoch 8, gen_loss = 0.397804404859646, disc_loss = 0.07584180863565192
Trained batch 416 in epoch 8, gen_loss = 0.3978727248003729, disc_loss = 0.07579199896290076
Trained batch 417 in epoch 8, gen_loss = 0.3977268055509152, disc_loss = 0.07571659034617138
Trained batch 418 in epoch 8, gen_loss = 0.3975343634874553, disc_loss = 0.07562780943710294
Trained batch 419 in epoch 8, gen_loss = 0.39776852957549547, disc_loss = 0.07556352017314306
Trained batch 420 in epoch 8, gen_loss = 0.3977421714333627, disc_loss = 0.07544234962005726
Trained batch 421 in epoch 8, gen_loss = 0.39782465927267524, disc_loss = 0.07530579379411034
Trained batch 422 in epoch 8, gen_loss = 0.3979301215556778, disc_loss = 0.07525382973650034
Trained batch 423 in epoch 8, gen_loss = 0.3977501456678476, disc_loss = 0.07510034501649228
Trained batch 424 in epoch 8, gen_loss = 0.3977098503884147, disc_loss = 0.07525074959458673
Trained batch 425 in epoch 8, gen_loss = 0.39796081615585677, disc_loss = 0.07549303382451475
Trained batch 426 in epoch 8, gen_loss = 0.3980767837522739, disc_loss = 0.07540188234875227
Trained batch 427 in epoch 8, gen_loss = 0.39800349278288466, disc_loss = 0.07532832189898277
Trained batch 428 in epoch 8, gen_loss = 0.39809497610811306, disc_loss = 0.07529024383604596
Trained batch 429 in epoch 8, gen_loss = 0.3980285343389178, disc_loss = 0.07514598655709347
Trained batch 430 in epoch 8, gen_loss = 0.39801404471325486, disc_loss = 0.07516101635603575
Trained batch 431 in epoch 8, gen_loss = 0.39808516925269805, disc_loss = 0.07531086200442924
Trained batch 432 in epoch 8, gen_loss = 0.39808698060468495, disc_loss = 0.07531156179475798
Trained batch 433 in epoch 8, gen_loss = 0.398060120916861, disc_loss = 0.07515377377069765
Trained batch 434 in epoch 8, gen_loss = 0.3982985440684461, disc_loss = 0.07505743677417437
Trained batch 435 in epoch 8, gen_loss = 0.3983342573388454, disc_loss = 0.07491892115255698
Trained batch 436 in epoch 8, gen_loss = 0.39828182606866214, disc_loss = 0.07485206165613108
Trained batch 437 in epoch 8, gen_loss = 0.3982651521149836, disc_loss = 0.07482489747458805
Trained batch 438 in epoch 8, gen_loss = 0.39831483476118507, disc_loss = 0.0746816138276546
Trained batch 439 in epoch 8, gen_loss = 0.3982032230293209, disc_loss = 0.07463704040697353
Trained batch 440 in epoch 8, gen_loss = 0.3983745797623853, disc_loss = 0.07453892503753136
Trained batch 441 in epoch 8, gen_loss = 0.3982794835354408, disc_loss = 0.07443108102011735
Trained batch 442 in epoch 8, gen_loss = 0.3981829193792817, disc_loss = 0.07432543482993043
Trained batch 443 in epoch 8, gen_loss = 0.39815088458829095, disc_loss = 0.07419410417577973
Trained batch 444 in epoch 8, gen_loss = 0.39803863017076857, disc_loss = 0.0740433577636487
Trained batch 445 in epoch 8, gen_loss = 0.3978673282826963, disc_loss = 0.07392766147292315
Trained batch 446 in epoch 8, gen_loss = 0.3979698329897268, disc_loss = 0.07378832294170222
Trained batch 447 in epoch 8, gen_loss = 0.3979002165142447, disc_loss = 0.07366910551042695
Trained batch 448 in epoch 8, gen_loss = 0.39774804759795523, disc_loss = 0.07357411794696327
Trained batch 449 in epoch 8, gen_loss = 0.3978812826010916, disc_loss = 0.07346347092754311
Trained batch 450 in epoch 8, gen_loss = 0.39786154187042805, disc_loss = 0.07338046082636206
Trained batch 451 in epoch 8, gen_loss = 0.39790108598834645, disc_loss = 0.07325468972259391
Trained batch 452 in epoch 8, gen_loss = 0.39805007924965147, disc_loss = 0.07311802293291154
Trained batch 453 in epoch 8, gen_loss = 0.3980978098800529, disc_loss = 0.07298413254853978
Trained batch 454 in epoch 8, gen_loss = 0.39809287252661946, disc_loss = 0.0728334415867761
Trained batch 455 in epoch 8, gen_loss = 0.39785517748902766, disc_loss = 0.07274944260471354
Trained batch 456 in epoch 8, gen_loss = 0.39778764604609174, disc_loss = 0.07263562255651085
Trained batch 457 in epoch 8, gen_loss = 0.39779467988092304, disc_loss = 0.072488953613607
Trained batch 458 in epoch 8, gen_loss = 0.3979077578435017, disc_loss = 0.0724162974238623
Trained batch 459 in epoch 8, gen_loss = 0.39789224542353463, disc_loss = 0.07238200102608813
Trained batch 460 in epoch 8, gen_loss = 0.3978993513514318, disc_loss = 0.07225257177471532
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.4944361746311188, disc_loss = 0.008483142592012882
Trained batch 1 in epoch 9, gen_loss = 0.43963266909122467, disc_loss = 0.00952081149443984
Trained batch 2 in epoch 9, gen_loss = 0.44345422585805255, disc_loss = 0.012980992905795574
Trained batch 3 in epoch 9, gen_loss = 0.4421069771051407, disc_loss = 0.013187110656872392
Trained batch 4 in epoch 9, gen_loss = 0.4425431489944458, disc_loss = 0.014297268725931645
Trained batch 5 in epoch 9, gen_loss = 0.43306230505307514, disc_loss = 0.012734836665913463
Trained batch 6 in epoch 9, gen_loss = 0.43425038882664274, disc_loss = 0.011793572256075484
Trained batch 7 in epoch 9, gen_loss = 0.4334857910871506, disc_loss = 0.011058077041525394
Trained batch 8 in epoch 9, gen_loss = 0.4326680103937785, disc_loss = 0.011848547651122013
Trained batch 9 in epoch 9, gen_loss = 0.4302267223596573, disc_loss = 0.017949758702889083
Trained batch 10 in epoch 9, gen_loss = 0.42674504626880994, disc_loss = 0.0243197410706092
Trained batch 11 in epoch 9, gen_loss = 0.42646511395772296, disc_loss = 0.022799833095632493
Trained batch 12 in epoch 9, gen_loss = 0.4225822595449594, disc_loss = 0.022418388702835027
Trained batch 13 in epoch 9, gen_loss = 0.4267990461417607, disc_loss = 0.022202210800190057
Trained batch 14 in epoch 9, gen_loss = 0.4236190716425578, disc_loss = 0.026847227942198515
Trained batch 15 in epoch 9, gen_loss = 0.42874961346387863, disc_loss = 0.04294110511546023
Trained batch 16 in epoch 9, gen_loss = 0.4245440539191751, disc_loss = 0.047894384520237934
Trained batch 17 in epoch 9, gen_loss = 0.4248085767030716, disc_loss = 0.05532543653518789
Trained batch 18 in epoch 9, gen_loss = 0.41575497859402705, disc_loss = 0.06288440410341871
Trained batch 19 in epoch 9, gen_loss = 0.41136455684900286, disc_loss = 0.06385349894408136
Trained batch 20 in epoch 9, gen_loss = 0.4166786486194247, disc_loss = 0.06267364733364611
Trained batch 21 in epoch 9, gen_loss = 0.4167023274031552, disc_loss = 0.06508785132742063
Trained batch 22 in epoch 9, gen_loss = 0.4140565486057945, disc_loss = 0.07510940327673503
Trained batch 23 in epoch 9, gen_loss = 0.41714712356527645, disc_loss = 0.08203333913115785
Trained batch 24 in epoch 9, gen_loss = 0.4135292303562164, disc_loss = 0.08203967111185193
Trained batch 25 in epoch 9, gen_loss = 0.40956216018933517, disc_loss = 0.08174037748876099
Trained batch 26 in epoch 9, gen_loss = 0.40736959488303576, disc_loss = 0.08131570881232619
Trained batch 27 in epoch 9, gen_loss = 0.40818016124623163, disc_loss = 0.08092309017333069
Trained batch 28 in epoch 9, gen_loss = 0.40763428190658835, disc_loss = 0.08137087230088896
Trained batch 29 in epoch 9, gen_loss = 0.40750137269496917, disc_loss = 0.07933935040297607
Trained batch 30 in epoch 9, gen_loss = 0.4059778653806256, disc_loss = 0.08674217726013833
Trained batch 31 in epoch 9, gen_loss = 0.40707201045006514, disc_loss = 0.09430922953470144
Trained batch 32 in epoch 9, gen_loss = 0.4096373834393241, disc_loss = 0.0940552066136716
Trained batch 33 in epoch 9, gen_loss = 0.4082003893221126, disc_loss = 0.099799974123016
Trained batch 34 in epoch 9, gen_loss = 0.4066456879888262, disc_loss = 0.1011159438240741
Trained batch 35 in epoch 9, gen_loss = 0.4086611005995009, disc_loss = 0.10132724430877715
Trained batch 36 in epoch 9, gen_loss = 0.41045958770288005, disc_loss = 0.10406386903864709
Trained batch 37 in epoch 9, gen_loss = 0.40878414872445556, disc_loss = 0.1090990560938065
Trained batch 38 in epoch 9, gen_loss = 0.4079115795783507, disc_loss = 0.10881045528759177
Trained batch 39 in epoch 9, gen_loss = 0.40786740109324454, disc_loss = 0.10727318247081712
Trained batch 40 in epoch 9, gen_loss = 0.4077436705914939, disc_loss = 0.10628972657978898
Trained batch 41 in epoch 9, gen_loss = 0.405309660803704, disc_loss = 0.10725919796996528
Trained batch 42 in epoch 9, gen_loss = 0.40579535794812577, disc_loss = 0.11070979508939524
Trained batch 43 in epoch 9, gen_loss = 0.4050783928145062, disc_loss = 0.10923565044702793
Trained batch 44 in epoch 9, gen_loss = 0.40347249772813587, disc_loss = 0.10758258974593547
Trained batch 45 in epoch 9, gen_loss = 0.40164490238479944, disc_loss = 0.10602503027969404
Trained batch 46 in epoch 9, gen_loss = 0.39969783640922385, disc_loss = 0.10438596256116921
Trained batch 47 in epoch 9, gen_loss = 0.4010978527367115, disc_loss = 0.10287704672858429
Trained batch 48 in epoch 9, gen_loss = 0.40141307821079175, disc_loss = 0.10137773302326701
Trained batch 49 in epoch 9, gen_loss = 0.40284440755844114, disc_loss = 0.10087856498546899
Trained batch 50 in epoch 9, gen_loss = 0.4029923782629125, disc_loss = 0.10143504069898934
Trained batch 51 in epoch 9, gen_loss = 0.40370295483332413, disc_loss = 0.10116482695313887
Trained batch 52 in epoch 9, gen_loss = 0.4041935885852238, disc_loss = 0.09938078706662329
Trained batch 53 in epoch 9, gen_loss = 0.40441074691436907, disc_loss = 0.0979035125821139
Trained batch 54 in epoch 9, gen_loss = 0.4050421638922258, disc_loss = 0.09629449007016691
Trained batch 55 in epoch 9, gen_loss = 0.4053442270628044, disc_loss = 0.0950763160279686
Trained batch 56 in epoch 9, gen_loss = 0.40475276949112876, disc_loss = 0.09451207504689432
Trained batch 57 in epoch 9, gen_loss = 0.4051355981621249, disc_loss = 0.09526212756714687
Trained batch 58 in epoch 9, gen_loss = 0.40381740816568923, disc_loss = 0.09708887022146481
Trained batch 59 in epoch 9, gen_loss = 0.4047080745299657, disc_loss = 0.09671488689103475
Trained batch 60 in epoch 9, gen_loss = 0.40608399471298595, disc_loss = 0.09657415722451004
Trained batch 61 in epoch 9, gen_loss = 0.40469902994171264, disc_loss = 0.09717335743499139
Trained batch 62 in epoch 9, gen_loss = 0.40305746926201713, disc_loss = 0.0964862615505736
Trained batch 63 in epoch 9, gen_loss = 0.403675127774477, disc_loss = 0.09598676079622237
Trained batch 64 in epoch 9, gen_loss = 0.4031322405888484, disc_loss = 0.09492347050601473
Trained batch 65 in epoch 9, gen_loss = 0.4027609978661393, disc_loss = 0.09391480601731349
Trained batch 66 in epoch 9, gen_loss = 0.40256879045002497, disc_loss = 0.09324385222297774
Trained batch 67 in epoch 9, gen_loss = 0.4020960015409133, disc_loss = 0.09214307405465447
Trained batch 68 in epoch 9, gen_loss = 0.40143492861070496, disc_loss = 0.09238947522354082
Trained batch 69 in epoch 9, gen_loss = 0.40245549167905537, disc_loss = 0.09415897178197545
Trained batch 70 in epoch 9, gen_loss = 0.40189515536939596, disc_loss = 0.0935971232091772
Trained batch 71 in epoch 9, gen_loss = 0.40081384612454307, disc_loss = 0.09398449904983863
Trained batch 72 in epoch 9, gen_loss = 0.401274565964529, disc_loss = 0.09630942782897452
Trained batch 73 in epoch 9, gen_loss = 0.4013926112974012, disc_loss = 0.09642563336780546
Trained batch 74 in epoch 9, gen_loss = 0.40206343730290733, disc_loss = 0.09541111694648861
Trained batch 75 in epoch 9, gen_loss = 0.4026860524165003, disc_loss = 0.0951586330101188
Trained batch 76 in epoch 9, gen_loss = 0.40180147274748074, disc_loss = 0.0942071326645454
Trained batch 77 in epoch 9, gen_loss = 0.40184292388268006, disc_loss = 0.09388498347610809
Trained batch 78 in epoch 9, gen_loss = 0.4021086183529866, disc_loss = 0.09318234485609433
Trained batch 79 in epoch 9, gen_loss = 0.40365776754915716, disc_loss = 0.09405823412234895
Trained batch 80 in epoch 9, gen_loss = 0.40334481258451205, disc_loss = 0.09324955610834339
Trained batch 81 in epoch 9, gen_loss = 0.40171674584470146, disc_loss = 0.09391103722950125
Trained batch 82 in epoch 9, gen_loss = 0.401384281106742, disc_loss = 0.09604574400505209
Trained batch 83 in epoch 9, gen_loss = 0.40089110143127893, disc_loss = 0.09587097027716004
Trained batch 84 in epoch 9, gen_loss = 0.4007997814346762, disc_loss = 0.09499882465666708
Trained batch 85 in epoch 9, gen_loss = 0.40028724247633024, disc_loss = 0.09398746039436827
Trained batch 86 in epoch 9, gen_loss = 0.4001255638297947, disc_loss = 0.09306576457838046
Trained batch 87 in epoch 9, gen_loss = 0.3997574191201817, disc_loss = 0.09228369855554774
Trained batch 88 in epoch 9, gen_loss = 0.40019231030110564, disc_loss = 0.09164534851887755
Trained batch 89 in epoch 9, gen_loss = 0.4000151448779636, disc_loss = 0.09100223087912632
Trained batch 90 in epoch 9, gen_loss = 0.39972212255656064, disc_loss = 0.09058831144472236
Trained batch 91 in epoch 9, gen_loss = 0.39929284155368805, disc_loss = 0.09113716693979729
Trained batch 92 in epoch 9, gen_loss = 0.3985632571481889, disc_loss = 0.09251784256369036
Trained batch 93 in epoch 9, gen_loss = 0.39785129687887555, disc_loss = 0.093926541858967
Trained batch 94 in epoch 9, gen_loss = 0.3967078036383579, disc_loss = 0.09367530498359548
Trained batch 95 in epoch 9, gen_loss = 0.3976724383731683, disc_loss = 0.09297818340807378
Trained batch 96 in epoch 9, gen_loss = 0.39801306945761455, disc_loss = 0.09220578651587219
Trained batch 97 in epoch 9, gen_loss = 0.39743626482632693, disc_loss = 0.09149562363626854
Trained batch 98 in epoch 9, gen_loss = 0.39749313845778955, disc_loss = 0.09062147394499996
Trained batch 99 in epoch 9, gen_loss = 0.39723315834999084, disc_loss = 0.08979504555463791
Trained batch 100 in epoch 9, gen_loss = 0.3981188931087456, disc_loss = 0.08922106274726367
Trained batch 101 in epoch 9, gen_loss = 0.39829910824111864, disc_loss = 0.08999095941145047
Trained batch 102 in epoch 9, gen_loss = 0.39852955271896806, disc_loss = 0.09055426235771874
Trained batch 103 in epoch 9, gen_loss = 0.3974880180679835, disc_loss = 0.0908997986967174
Trained batch 104 in epoch 9, gen_loss = 0.39828848157610214, disc_loss = 0.0901383861899376
Trained batch 105 in epoch 9, gen_loss = 0.40012076665770335, disc_loss = 0.08950306893379059
Trained batch 106 in epoch 9, gen_loss = 0.3998939052363422, disc_loss = 0.08909227075838597
Trained batch 107 in epoch 9, gen_loss = 0.3996898976189119, disc_loss = 0.08873073328976278
Trained batch 108 in epoch 9, gen_loss = 0.39924006533185274, disc_loss = 0.08983228895642342
Trained batch 109 in epoch 9, gen_loss = 0.4001725156198848, disc_loss = 0.09021151472221721
Trained batch 110 in epoch 9, gen_loss = 0.40025610671387063, disc_loss = 0.08959949999913439
Trained batch 111 in epoch 9, gen_loss = 0.40083805764360086, disc_loss = 0.08887590667498964
Trained batch 112 in epoch 9, gen_loss = 0.40112794210425523, disc_loss = 0.08845138193759243
Trained batch 113 in epoch 9, gen_loss = 0.40024417978629734, disc_loss = 0.08815504623609677
Trained batch 114 in epoch 9, gen_loss = 0.3997007820917212, disc_loss = 0.08772635485814965
Trained batch 115 in epoch 9, gen_loss = 0.3990428987248191, disc_loss = 0.08741528264664371
Trained batch 116 in epoch 9, gen_loss = 0.3994358054593078, disc_loss = 0.08691513616368811
Trained batch 117 in epoch 9, gen_loss = 0.40011112038361824, disc_loss = 0.08651619014661696
Trained batch 118 in epoch 9, gen_loss = 0.39909556483020303, disc_loss = 0.08661932944312316
Trained batch 119 in epoch 9, gen_loss = 0.3986838199198246, disc_loss = 0.08616845888706545
Trained batch 120 in epoch 9, gen_loss = 0.39867120611766155, disc_loss = 0.08560575560227898
Trained batch 121 in epoch 9, gen_loss = 0.39873074898954297, disc_loss = 0.08575555605844395
Trained batch 122 in epoch 9, gen_loss = 0.3989875413537995, disc_loss = 0.08638774000895702
Trained batch 123 in epoch 9, gen_loss = 0.39841403307453277, disc_loss = 0.08612346099389176
Trained batch 124 in epoch 9, gen_loss = 0.3983576099872589, disc_loss = 0.08562707109749317
Trained batch 125 in epoch 9, gen_loss = 0.3987695456497253, disc_loss = 0.08534830047320278
Trained batch 126 in epoch 9, gen_loss = 0.3990643885661298, disc_loss = 0.08493188676226326
Trained batch 127 in epoch 9, gen_loss = 0.3986730985343456, disc_loss = 0.0847887799172895
Trained batch 128 in epoch 9, gen_loss = 0.3990065469298252, disc_loss = 0.08523183086410512
Trained batch 129 in epoch 9, gen_loss = 0.39868859281906716, disc_loss = 0.08485413249582052
Trained batch 130 in epoch 9, gen_loss = 0.39801694304888485, disc_loss = 0.08431007092434714
Trained batch 131 in epoch 9, gen_loss = 0.3973132148385048, disc_loss = 0.08388667242516848
Trained batch 132 in epoch 9, gen_loss = 0.39685910962578047, disc_loss = 0.08356428801089077
Trained batch 133 in epoch 9, gen_loss = 0.39688018787263046, disc_loss = 0.08390858006983329
Trained batch 134 in epoch 9, gen_loss = 0.3963421795103285, disc_loss = 0.08548687292883793
Trained batch 135 in epoch 9, gen_loss = 0.39702823517077107, disc_loss = 0.08566329265972052
Trained batch 136 in epoch 9, gen_loss = 0.39674238131864226, disc_loss = 0.08564955653473191
Trained batch 137 in epoch 9, gen_loss = 0.3967691128668578, disc_loss = 0.08551463435498485
Trained batch 138 in epoch 9, gen_loss = 0.3963125746884792, disc_loss = 0.08504183666123975
Trained batch 139 in epoch 9, gen_loss = 0.3961838166628565, disc_loss = 0.08478468941923763
Trained batch 140 in epoch 9, gen_loss = 0.3965857971644571, disc_loss = 0.08445064401822099
Trained batch 141 in epoch 9, gen_loss = 0.3964771647268618, disc_loss = 0.08397036944975106
Trained batch 142 in epoch 9, gen_loss = 0.39722509296623976, disc_loss = 0.08385399902903742
Trained batch 143 in epoch 9, gen_loss = 0.3971426122718387, disc_loss = 0.08357144780327669
Trained batch 144 in epoch 9, gen_loss = 0.3966843956503375, disc_loss = 0.08348754101657661
Trained batch 145 in epoch 9, gen_loss = 0.3970018406845119, disc_loss = 0.0834617484297144
Trained batch 146 in epoch 9, gen_loss = 0.3970244060568258, disc_loss = 0.0830378667039632
Trained batch 147 in epoch 9, gen_loss = 0.39683209983883677, disc_loss = 0.08260580861462734
Trained batch 148 in epoch 9, gen_loss = 0.3970969703373493, disc_loss = 0.08228609165264256
Trained batch 149 in epoch 9, gen_loss = 0.39734044750531516, disc_loss = 0.08238323846831917
Trained batch 150 in epoch 9, gen_loss = 0.39683557800109814, disc_loss = 0.08200275300329687
Trained batch 151 in epoch 9, gen_loss = 0.39633967550961596, disc_loss = 0.08210062357523527
Trained batch 152 in epoch 9, gen_loss = 0.3964870055906134, disc_loss = 0.08256507352651919
Trained batch 153 in epoch 9, gen_loss = 0.3967901650187257, disc_loss = 0.08211544469337571
Trained batch 154 in epoch 9, gen_loss = 0.39601604457824463, disc_loss = 0.08280255836584875
Trained batch 155 in epoch 9, gen_loss = 0.39600813427032566, disc_loss = 0.08252340735485539
Trained batch 156 in epoch 9, gen_loss = 0.3966864009571683, disc_loss = 0.08209541912789747
Trained batch 157 in epoch 9, gen_loss = 0.3967866458093064, disc_loss = 0.0817249743798394
Trained batch 158 in epoch 9, gen_loss = 0.3966407296042772, disc_loss = 0.0813289673811516
Trained batch 159 in epoch 9, gen_loss = 0.39722625315189364, disc_loss = 0.08132518084603362
Trained batch 160 in epoch 9, gen_loss = 0.39674219303990005, disc_loss = 0.08125396495719689
Trained batch 161 in epoch 9, gen_loss = 0.3968662658223399, disc_loss = 0.08090524876168297
Trained batch 162 in epoch 9, gen_loss = 0.3970513672916436, disc_loss = 0.08080401801235654
Trained batch 163 in epoch 9, gen_loss = 0.39700195338667893, disc_loss = 0.08080207383282846
Trained batch 164 in epoch 9, gen_loss = 0.3980165958404541, disc_loss = 0.0808188296572277
Trained batch 165 in epoch 9, gen_loss = 0.39780002922178753, disc_loss = 0.08058737130297056
Trained batch 166 in epoch 9, gen_loss = 0.3976822852374551, disc_loss = 0.08113507954905669
Trained batch 167 in epoch 9, gen_loss = 0.39810625641118913, disc_loss = 0.08075529938408484
Trained batch 168 in epoch 9, gen_loss = 0.39824474845412217, disc_loss = 0.08063417074088691
Trained batch 169 in epoch 9, gen_loss = 0.398277241342208, disc_loss = 0.08032157516983503
Trained batch 170 in epoch 9, gen_loss = 0.39819773561076116, disc_loss = 0.08000002622234019
Trained batch 171 in epoch 9, gen_loss = 0.39812854348227034, disc_loss = 0.07965354575385708
Trained batch 172 in epoch 9, gen_loss = 0.3978824806695729, disc_loss = 0.07926024112721226
Trained batch 173 in epoch 9, gen_loss = 0.3975256635197278, disc_loss = 0.07887043158427395
Trained batch 174 in epoch 9, gen_loss = 0.39780054450035096, disc_loss = 0.07847305488373552
Trained batch 175 in epoch 9, gen_loss = 0.3979720866138285, disc_loss = 0.07806836608638563
Trained batch 176 in epoch 9, gen_loss = 0.3982549521882655, disc_loss = 0.07810128575169854
Trained batch 177 in epoch 9, gen_loss = 0.3978744792134574, disc_loss = 0.07912853743431023
Trained batch 178 in epoch 9, gen_loss = 0.3981301847782881, disc_loss = 0.07897347043523326
Trained batch 179 in epoch 9, gen_loss = 0.39799651536676617, disc_loss = 0.0787820698098383
Trained batch 180 in epoch 9, gen_loss = 0.3981553136643784, disc_loss = 0.078737859158823
Trained batch 181 in epoch 9, gen_loss = 0.39825310893766175, disc_loss = 0.0783446124360825
Trained batch 182 in epoch 9, gen_loss = 0.3986019405836616, disc_loss = 0.07807500585353847
Trained batch 183 in epoch 9, gen_loss = 0.3988666349779005, disc_loss = 0.07777104717325015
Trained batch 184 in epoch 9, gen_loss = 0.3992374782626693, disc_loss = 0.07749755187463518
Trained batch 185 in epoch 9, gen_loss = 0.39921403716328324, disc_loss = 0.0771367416982489
Trained batch 186 in epoch 9, gen_loss = 0.3992515505953906, disc_loss = 0.07683434087115733
Trained batch 187 in epoch 9, gen_loss = 0.39967796317440396, disc_loss = 0.07665110562501991
Trained batch 188 in epoch 9, gen_loss = 0.3997019097287819, disc_loss = 0.07638785005276086
Trained batch 189 in epoch 9, gen_loss = 0.3998599808467062, disc_loss = 0.07626594039121348
Trained batch 190 in epoch 9, gen_loss = 0.39909752906929136, disc_loss = 0.07618950663075943
Trained batch 191 in epoch 9, gen_loss = 0.3990341314735512, disc_loss = 0.07584409110374206
Trained batch 192 in epoch 9, gen_loss = 0.39939360961395226, disc_loss = 0.07548943120223793
Trained batch 193 in epoch 9, gen_loss = 0.39957350922614027, disc_loss = 0.0751899150320204
Trained batch 194 in epoch 9, gen_loss = 0.39949290263347137, disc_loss = 0.07493065467390876
Trained batch 195 in epoch 9, gen_loss = 0.39962093121543224, disc_loss = 0.07460635234554279
Trained batch 196 in epoch 9, gen_loss = 0.39938675858042566, disc_loss = 0.0750837849788746
Trained batch 197 in epoch 9, gen_loss = 0.39926612617993595, disc_loss = 0.07477889648130671
Trained batch 198 in epoch 9, gen_loss = 0.39852356566256614, disc_loss = 0.07528176680722054
Trained batch 199 in epoch 9, gen_loss = 0.3983155287802219, disc_loss = 0.07615179339190944
Trained batch 200 in epoch 9, gen_loss = 0.39830185791746303, disc_loss = 0.07699561780503955
Trained batch 201 in epoch 9, gen_loss = 0.39846783787897316, disc_loss = 0.07708292382326679
Trained batch 202 in epoch 9, gen_loss = 0.3985309992811363, disc_loss = 0.07699570637609204
Trained batch 203 in epoch 9, gen_loss = 0.3982396911756665, disc_loss = 0.07669795518877971
Trained batch 204 in epoch 9, gen_loss = 0.39783102303016477, disc_loss = 0.07666890761792296
Trained batch 205 in epoch 9, gen_loss = 0.39736666378465674, disc_loss = 0.07680892921504971
Trained batch 206 in epoch 9, gen_loss = 0.39737114828565845, disc_loss = 0.0770080583282535
Trained batch 207 in epoch 9, gen_loss = 0.39746784562101733, disc_loss = 0.07676332224330579
Trained batch 208 in epoch 9, gen_loss = 0.39723778227299594, disc_loss = 0.0765822067317602
Trained batch 209 in epoch 9, gen_loss = 0.39707144442058745, disc_loss = 0.07636290791089691
Trained batch 210 in epoch 9, gen_loss = 0.39660812864936357, disc_loss = 0.07607354758024851
Trained batch 211 in epoch 9, gen_loss = 0.39628698845516963, disc_loss = 0.07594085336478322
Trained batch 212 in epoch 9, gen_loss = 0.3968803668525857, disc_loss = 0.07596758972774718
Trained batch 213 in epoch 9, gen_loss = 0.39638320140749495, disc_loss = 0.0760913613735411
Trained batch 214 in epoch 9, gen_loss = 0.39642026161038596, disc_loss = 0.07599395138623063
Trained batch 215 in epoch 9, gen_loss = 0.39635781005576803, disc_loss = 0.07568279718247208
Trained batch 216 in epoch 9, gen_loss = 0.3955875118069934, disc_loss = 0.07559228167238255
Trained batch 217 in epoch 9, gen_loss = 0.3960444018791575, disc_loss = 0.07543238839177295
Trained batch 218 in epoch 9, gen_loss = 0.39607872871775607, disc_loss = 0.07515037228825362
Trained batch 219 in epoch 9, gen_loss = 0.39581127363172447, disc_loss = 0.07506011574402113
Trained batch 220 in epoch 9, gen_loss = 0.39599411796390743, disc_loss = 0.07491148292504217
Trained batch 221 in epoch 9, gen_loss = 0.39631342008575665, disc_loss = 0.07482690628206877
Trained batch 222 in epoch 9, gen_loss = 0.3963041324920184, disc_loss = 0.07477338734655035
Trained batch 223 in epoch 9, gen_loss = 0.3965038484893739, disc_loss = 0.07456792460912506
Trained batch 224 in epoch 9, gen_loss = 0.3965054629246394, disc_loss = 0.07426904706284404
Trained batch 225 in epoch 9, gen_loss = 0.3963811465464862, disc_loss = 0.07409968503866246
Trained batch 226 in epoch 9, gen_loss = 0.3963123771981521, disc_loss = 0.07387102802083027
Trained batch 227 in epoch 9, gen_loss = 0.3964844797656201, disc_loss = 0.0739686788741924
Trained batch 228 in epoch 9, gen_loss = 0.39682601873791373, disc_loss = 0.0744943500000284
Trained batch 229 in epoch 9, gen_loss = 0.3968034939273544, disc_loss = 0.07434688624925911
Trained batch 230 in epoch 9, gen_loss = 0.3971060864724122, disc_loss = 0.0740709741946584
Trained batch 231 in epoch 9, gen_loss = 0.39762758996723024, disc_loss = 0.07379522533276407
Trained batch 232 in epoch 9, gen_loss = 0.39765447614786453, disc_loss = 0.07360622189867075
Trained batch 233 in epoch 9, gen_loss = 0.39721121524388975, disc_loss = 0.07401914906321874
Trained batch 234 in epoch 9, gen_loss = 0.3975009378600628, disc_loss = 0.07448276819344214
Trained batch 235 in epoch 9, gen_loss = 0.39731365562242976, disc_loss = 0.07441461530427243
Trained batch 236 in epoch 9, gen_loss = 0.39721081660518165, disc_loss = 0.07418028632068872
Trained batch 237 in epoch 9, gen_loss = 0.39715196711926903, disc_loss = 0.07401779372863346
Trained batch 238 in epoch 9, gen_loss = 0.39731133551527764, disc_loss = 0.07388964592124565
Trained batch 239 in epoch 9, gen_loss = 0.397374595887959, disc_loss = 0.07371893053835568
Trained batch 240 in epoch 9, gen_loss = 0.39743311863964526, disc_loss = 0.07369329249177174
Trained batch 241 in epoch 9, gen_loss = 0.397254009076879, disc_loss = 0.07349858322750377
Trained batch 242 in epoch 9, gen_loss = 0.3970892780724867, disc_loss = 0.07345513067947923
Trained batch 243 in epoch 9, gen_loss = 0.39731988707771065, disc_loss = 0.07378598461958168
Trained batch 244 in epoch 9, gen_loss = 0.3970027497228311, disc_loss = 0.07513714944183522
Trained batch 245 in epoch 9, gen_loss = 0.39684928959704996, disc_loss = 0.07514762309591884
Trained batch 246 in epoch 9, gen_loss = 0.3969081082204093, disc_loss = 0.07503787629298775
Trained batch 247 in epoch 9, gen_loss = 0.396700153007142, disc_loss = 0.07481978152270219
Trained batch 248 in epoch 9, gen_loss = 0.3967822672253153, disc_loss = 0.07461228686755142
Trained batch 249 in epoch 9, gen_loss = 0.39702548235654833, disc_loss = 0.0744630108308047
Trained batch 250 in epoch 9, gen_loss = 0.39681905478357793, disc_loss = 0.07441507097133306
Trained batch 251 in epoch 9, gen_loss = 0.3969703254600366, disc_loss = 0.07417474666588186
Trained batch 252 in epoch 9, gen_loss = 0.3969692298663935, disc_loss = 0.07391824890406648
Trained batch 253 in epoch 9, gen_loss = 0.39705172867521527, disc_loss = 0.07372709811577119
Trained batch 254 in epoch 9, gen_loss = 0.3968497534008587, disc_loss = 0.07365405368709974
Trained batch 255 in epoch 9, gen_loss = 0.3969362095813267, disc_loss = 0.07395172208453005
Trained batch 256 in epoch 9, gen_loss = 0.3975823470010832, disc_loss = 0.07453600959924814
Trained batch 257 in epoch 9, gen_loss = 0.39760501954213595, disc_loss = 0.07438972416738149
Trained batch 258 in epoch 9, gen_loss = 0.3973924826586108, disc_loss = 0.07414659762639969
Trained batch 259 in epoch 9, gen_loss = 0.3973671282140108, disc_loss = 0.07416512177934727
Trained batch 260 in epoch 9, gen_loss = 0.39765689342186367, disc_loss = 0.07460733383030442
Trained batch 261 in epoch 9, gen_loss = 0.39759676835236657, disc_loss = 0.07455431058370146
Trained batch 262 in epoch 9, gen_loss = 0.39747688950467924, disc_loss = 0.07432449755821902
Trained batch 263 in epoch 9, gen_loss = 0.3973115717032642, disc_loss = 0.07419541333696213
Trained batch 264 in epoch 9, gen_loss = 0.3972754037042834, disc_loss = 0.07418340269722185
Trained batch 265 in epoch 9, gen_loss = 0.39709906700186265, disc_loss = 0.07448359628740166
Trained batch 266 in epoch 9, gen_loss = 0.3974745540918036, disc_loss = 0.07452537342103735
Trained batch 267 in epoch 9, gen_loss = 0.3974711600857884, disc_loss = 0.07432555126672638
Trained batch 268 in epoch 9, gen_loss = 0.3973352108635424, disc_loss = 0.07408664706699744
Trained batch 269 in epoch 9, gen_loss = 0.39739589001293535, disc_loss = 0.0738429470832839
Trained batch 270 in epoch 9, gen_loss = 0.39726101609833564, disc_loss = 0.07384117536858494
Trained batch 271 in epoch 9, gen_loss = 0.3972362806363141, disc_loss = 0.07384988781482474
Trained batch 272 in epoch 9, gen_loss = 0.397050699307805, disc_loss = 0.07362092418200422
Trained batch 273 in epoch 9, gen_loss = 0.39687375175039263, disc_loss = 0.07338838641749301
Trained batch 274 in epoch 9, gen_loss = 0.39715346428481013, disc_loss = 0.07314834366637198
Trained batch 275 in epoch 9, gen_loss = 0.39686934266617335, disc_loss = 0.07290429034628028
Trained batch 276 in epoch 9, gen_loss = 0.3969374419011794, disc_loss = 0.07278554976517704
Trained batch 277 in epoch 9, gen_loss = 0.39713907665271553, disc_loss = 0.07264109904435631
Trained batch 278 in epoch 9, gen_loss = 0.3970484642251845, disc_loss = 0.07244414386029045
Trained batch 279 in epoch 9, gen_loss = 0.39713076039084366, disc_loss = 0.07221753337653354
Trained batch 280 in epoch 9, gen_loss = 0.39724575545227825, disc_loss = 0.07198239805084053
Trained batch 281 in epoch 9, gen_loss = 0.39707585297366405, disc_loss = 0.07175053561482816
Trained batch 282 in epoch 9, gen_loss = 0.39707015718040534, disc_loss = 0.07153404357451484
Trained batch 283 in epoch 9, gen_loss = 0.39695264792568247, disc_loss = 0.07132958448131267
Trained batch 284 in epoch 9, gen_loss = 0.3969052272407632, disc_loss = 0.0711028520524371
Trained batch 285 in epoch 9, gen_loss = 0.3966450731341655, disc_loss = 0.0709572636499558
Trained batch 286 in epoch 9, gen_loss = 0.3967741171761257, disc_loss = 0.0707670472195625
Trained batch 287 in epoch 9, gen_loss = 0.3968726768572297, disc_loss = 0.0705483720408261
Trained batch 288 in epoch 9, gen_loss = 0.39727746775199796, disc_loss = 0.07042239852101384
Trained batch 289 in epoch 9, gen_loss = 0.3971523473488873, disc_loss = 0.0702868001037759
Trained batch 290 in epoch 9, gen_loss = 0.39719671538400486, disc_loss = 0.07010048530080526
Trained batch 291 in epoch 9, gen_loss = 0.3975756825139261, disc_loss = 0.06993514228746142
Trained batch 292 in epoch 9, gen_loss = 0.39770700240908224, disc_loss = 0.06974650456160053
Trained batch 293 in epoch 9, gen_loss = 0.3977771142408961, disc_loss = 0.06957063482611814
Trained batch 294 in epoch 9, gen_loss = 0.3975824357594474, disc_loss = 0.06937150143371043
Trained batch 295 in epoch 9, gen_loss = 0.397581935986071, disc_loss = 0.06925456093882236
Trained batch 296 in epoch 9, gen_loss = 0.3976728901618258, disc_loss = 0.06905473515811543
Trained batch 297 in epoch 9, gen_loss = 0.3977157881095905, disc_loss = 0.06887580683586131
Trained batch 298 in epoch 9, gen_loss = 0.39806873099660395, disc_loss = 0.0686706619159658
Trained batch 299 in epoch 9, gen_loss = 0.3980059169232845, disc_loss = 0.06849952596084526
Trained batch 300 in epoch 9, gen_loss = 0.39792546882383845, disc_loss = 0.06829288719296207
Trained batch 301 in epoch 9, gen_loss = 0.3978048483563575, disc_loss = 0.06813284636795866
Trained batch 302 in epoch 9, gen_loss = 0.39766582418786417, disc_loss = 0.06802043172902744
Trained batch 303 in epoch 9, gen_loss = 0.3976234340255982, disc_loss = 0.0678443651643312
Trained batch 304 in epoch 9, gen_loss = 0.3976946488267086, disc_loss = 0.06764661090937062
Trained batch 305 in epoch 9, gen_loss = 0.39764343070633273, disc_loss = 0.06750231437853788
Trained batch 306 in epoch 9, gen_loss = 0.39786696992207815, disc_loss = 0.06804028956268092
Trained batch 307 in epoch 9, gen_loss = 0.39759961636616037, disc_loss = 0.06899381097097725
Trained batch 308 in epoch 9, gen_loss = 0.39761940999902956, disc_loss = 0.06886453625917868
Trained batch 309 in epoch 9, gen_loss = 0.3975629966585867, disc_loss = 0.06899641183385205
Trained batch 310 in epoch 9, gen_loss = 0.3977783625628021, disc_loss = 0.06881925765682503
Trained batch 311 in epoch 9, gen_loss = 0.3975190095698986, disc_loss = 0.06876944935767171
Trained batch 312 in epoch 9, gen_loss = 0.397498626630908, disc_loss = 0.06863488751008345
Trained batch 313 in epoch 9, gen_loss = 0.39755259905081647, disc_loss = 0.06863473352359216
Trained batch 314 in epoch 9, gen_loss = 0.3975024271105963, disc_loss = 0.068706025291116
Trained batch 315 in epoch 9, gen_loss = 0.3974581961107405, disc_loss = 0.06859639283605627
Trained batch 316 in epoch 9, gen_loss = 0.39742734826137593, disc_loss = 0.06848742154923382
Trained batch 317 in epoch 9, gen_loss = 0.3971555043222769, disc_loss = 0.0684753407814991
Trained batch 318 in epoch 9, gen_loss = 0.39764264398794563, disc_loss = 0.06831111249347513
Trained batch 319 in epoch 9, gen_loss = 0.39788567307405176, disc_loss = 0.06813607576623326
Trained batch 320 in epoch 9, gen_loss = 0.3979486913603043, disc_loss = 0.06796724459365289
Trained batch 321 in epoch 9, gen_loss = 0.3979144406892498, disc_loss = 0.06814652251987863
Trained batch 322 in epoch 9, gen_loss = 0.3976131664248812, disc_loss = 0.06919342958607679
Trained batch 323 in epoch 9, gen_loss = 0.39756343849463227, disc_loss = 0.06925474365822465
Trained batch 324 in epoch 9, gen_loss = 0.39773081994973697, disc_loss = 0.06945940357991136
Trained batch 325 in epoch 9, gen_loss = 0.3976940329363741, disc_loss = 0.06974349642726678
Trained batch 326 in epoch 9, gen_loss = 0.39755184994013665, disc_loss = 0.06973476405896314
Trained batch 327 in epoch 9, gen_loss = 0.3977779490282623, disc_loss = 0.06975627001005838
Trained batch 328 in epoch 9, gen_loss = 0.397540729051303, disc_loss = 0.07020137783870282
Trained batch 329 in epoch 9, gen_loss = 0.3977930151603439, disc_loss = 0.07054206215155621
Trained batch 330 in epoch 9, gen_loss = 0.39768284572755463, disc_loss = 0.07058922236143778
Trained batch 331 in epoch 9, gen_loss = 0.3975522328302803, disc_loss = 0.07069671058505549
Trained batch 332 in epoch 9, gen_loss = 0.39771808093195565, disc_loss = 0.07077569502067414
Trained batch 333 in epoch 9, gen_loss = 0.3979214366949247, disc_loss = 0.07067242491025545
Trained batch 334 in epoch 9, gen_loss = 0.3979325724626655, disc_loss = 0.07050204181821267
Trained batch 335 in epoch 9, gen_loss = 0.3977086687283147, disc_loss = 0.07058506619068794
Trained batch 336 in epoch 9, gen_loss = 0.3978916060411612, disc_loss = 0.07101594942320658
Trained batch 337 in epoch 9, gen_loss = 0.3977523695170527, disc_loss = 0.07134213563490152
Trained batch 338 in epoch 9, gen_loss = 0.39760246595977683, disc_loss = 0.07130523941790064
Trained batch 339 in epoch 9, gen_loss = 0.3977651330916321, disc_loss = 0.0712722595931743
Trained batch 340 in epoch 9, gen_loss = 0.39781894987104927, disc_loss = 0.07128422735040445
Trained batch 341 in epoch 9, gen_loss = 0.3977584954329401, disc_loss = 0.07131836865483974
Trained batch 342 in epoch 9, gen_loss = 0.39787985549550015, disc_loss = 0.07173868776339788
Trained batch 343 in epoch 9, gen_loss = 0.39774969527714477, disc_loss = 0.07222760119340058
Trained batch 344 in epoch 9, gen_loss = 0.3975715230772461, disc_loss = 0.07269506093141609
Trained batch 345 in epoch 9, gen_loss = 0.39752118689993216, disc_loss = 0.07259683609627876
Trained batch 346 in epoch 9, gen_loss = 0.3974799609579339, disc_loss = 0.0726183399018598
Trained batch 347 in epoch 9, gen_loss = 0.39731012785743025, disc_loss = 0.07251040191502021
Trained batch 348 in epoch 9, gen_loss = 0.39746274907985185, disc_loss = 0.07243968088868312
Trained batch 349 in epoch 9, gen_loss = 0.39758452479328427, disc_loss = 0.07242742691056005
Trained batch 350 in epoch 9, gen_loss = 0.3975634065024194, disc_loss = 0.07225631799766438
Trained batch 351 in epoch 9, gen_loss = 0.39750085258856416, disc_loss = 0.07209871081100903
Trained batch 352 in epoch 9, gen_loss = 0.39768663897223916, disc_loss = 0.07193289090491431
Trained batch 353 in epoch 9, gen_loss = 0.39785587665556515, disc_loss = 0.07177523392157913
Trained batch 354 in epoch 9, gen_loss = 0.39756069120386955, disc_loss = 0.07189745648147565
Trained batch 355 in epoch 9, gen_loss = 0.397624092364914, disc_loss = 0.07221031864042907
Trained batch 356 in epoch 9, gen_loss = 0.39765682645371647, disc_loss = 0.07210244788430861
Trained batch 357 in epoch 9, gen_loss = 0.39753745025929127, disc_loss = 0.0723177857148102
Trained batch 358 in epoch 9, gen_loss = 0.3977531426713327, disc_loss = 0.07215224169220641
Trained batch 359 in epoch 9, gen_loss = 0.397886034556561, disc_loss = 0.07200332747177324
Trained batch 360 in epoch 9, gen_loss = 0.397752968186817, disc_loss = 0.07182811416422437
Trained batch 361 in epoch 9, gen_loss = 0.3978241652826578, disc_loss = 0.07168134704916558
Trained batch 362 in epoch 9, gen_loss = 0.3976346828638686, disc_loss = 0.07156539767000505
Trained batch 363 in epoch 9, gen_loss = 0.39759695165596165, disc_loss = 0.07145389048817598
Trained batch 364 in epoch 9, gen_loss = 0.3976151195699221, disc_loss = 0.07139220067414723
Trained batch 365 in epoch 9, gen_loss = 0.3978904172615275, disc_loss = 0.07145655742602149
Trained batch 366 in epoch 9, gen_loss = 0.3977438483072562, disc_loss = 0.07152975956739335
Trained batch 367 in epoch 9, gen_loss = 0.39783666173563054, disc_loss = 0.07137306021531517
Trained batch 368 in epoch 9, gen_loss = 0.39789700164865993, disc_loss = 0.0714003675021635
Trained batch 369 in epoch 9, gen_loss = 0.39779509519403045, disc_loss = 0.07164455458043596
Trained batch 370 in epoch 9, gen_loss = 0.39807483469540217, disc_loss = 0.07153807063474046
Trained batch 371 in epoch 9, gen_loss = 0.3982952176643315, disc_loss = 0.07179299855269292
Trained batch 372 in epoch 9, gen_loss = 0.39832551433797175, disc_loss = 0.0719017919075573
Trained batch 373 in epoch 9, gen_loss = 0.39848233157778806, disc_loss = 0.07173012253170942
Trained batch 374 in epoch 9, gen_loss = 0.3984794660011927, disc_loss = 0.07156466435765227
Trained batch 375 in epoch 9, gen_loss = 0.39854526262175527, disc_loss = 0.07139413760717403
Trained batch 376 in epoch 9, gen_loss = 0.39870987310807965, disc_loss = 0.07127569992816575
Trained batch 377 in epoch 9, gen_loss = 0.39864400111966664, disc_loss = 0.07134873017412487
Trained batch 378 in epoch 9, gen_loss = 0.3985695995016903, disc_loss = 0.07121953757425727
Trained batch 379 in epoch 9, gen_loss = 0.39857760467811637, disc_loss = 0.07121502159065322
Trained batch 380 in epoch 9, gen_loss = 0.39840081400602195, disc_loss = 0.0711739738312919
Trained batch 381 in epoch 9, gen_loss = 0.39832059777687984, disc_loss = 0.07114793415820099
Trained batch 382 in epoch 9, gen_loss = 0.39839224120499883, disc_loss = 0.07131214335794238
Trained batch 383 in epoch 9, gen_loss = 0.39832281092337024, disc_loss = 0.07119164948138253
Trained batch 384 in epoch 9, gen_loss = 0.39822774788776, disc_loss = 0.07109734890619655
Trained batch 385 in epoch 9, gen_loss = 0.3983531130641853, disc_loss = 0.07100179465728874
Trained batch 386 in epoch 9, gen_loss = 0.3984878039714286, disc_loss = 0.07090614646076386
Trained batch 387 in epoch 9, gen_loss = 0.3983609357983181, disc_loss = 0.07084754667696111
Trained batch 388 in epoch 9, gen_loss = 0.3983045947046084, disc_loss = 0.07081037089898991
Trained batch 389 in epoch 9, gen_loss = 0.3985138312746317, disc_loss = 0.0717572875941793
Trained batch 390 in epoch 9, gen_loss = 0.3985073044705574, disc_loss = 0.0716837213405639
Trained batch 391 in epoch 9, gen_loss = 0.3983385855978241, disc_loss = 0.0716485378132867
Trained batch 392 in epoch 9, gen_loss = 0.3982391583783026, disc_loss = 0.07155141546734568
Trained batch 393 in epoch 9, gen_loss = 0.3983354256464745, disc_loss = 0.07140343699623183
Trained batch 394 in epoch 9, gen_loss = 0.3984339536368092, disc_loss = 0.07125598696308046
Trained batch 395 in epoch 9, gen_loss = 0.3986127210611647, disc_loss = 0.0711338618873722
Trained batch 396 in epoch 9, gen_loss = 0.3985293610044931, disc_loss = 0.07100085188782486
Trained batch 397 in epoch 9, gen_loss = 0.3986335324507263, disc_loss = 0.07093127988203986
Trained batch 398 in epoch 9, gen_loss = 0.3986241798427768, disc_loss = 0.07077203318243262
Trained batch 399 in epoch 9, gen_loss = 0.3987372078374028, disc_loss = 0.07069697418948635
Trained batch 400 in epoch 9, gen_loss = 0.3987273696131837, disc_loss = 0.07053465842085883
Trained batch 401 in epoch 9, gen_loss = 0.3985999630235914, disc_loss = 0.07063164780685557
Trained batch 402 in epoch 9, gen_loss = 0.3986946463067242, disc_loss = 0.07076435275468282
Trained batch 403 in epoch 9, gen_loss = 0.39870030525149686, disc_loss = 0.07060230476435937
Trained batch 404 in epoch 9, gen_loss = 0.3986280433557652, disc_loss = 0.07048413839168202
Trained batch 405 in epoch 9, gen_loss = 0.3987159061387842, disc_loss = 0.07032933995802083
Trained batch 406 in epoch 9, gen_loss = 0.398728020324461, disc_loss = 0.07019130696247375
Trained batch 407 in epoch 9, gen_loss = 0.3990135741803576, disc_loss = 0.07013684171640004
Trained batch 408 in epoch 9, gen_loss = 0.39887353912688117, disc_loss = 0.07052228969697155
Trained batch 409 in epoch 9, gen_loss = 0.3989622173876297, disc_loss = 0.07100598012642344
Trained batch 410 in epoch 9, gen_loss = 0.39897487847329344, disc_loss = 0.07085115776494726
Trained batch 411 in epoch 9, gen_loss = 0.3988631823760213, disc_loss = 0.0708004962144311
Trained batch 412 in epoch 9, gen_loss = 0.39895156505754437, disc_loss = 0.0707337071038963
Trained batch 413 in epoch 9, gen_loss = 0.3989868175940237, disc_loss = 0.07060351566825476
Trained batch 414 in epoch 9, gen_loss = 0.3990482033376234, disc_loss = 0.07049875547884997
Trained batch 415 in epoch 9, gen_loss = 0.39900246602841294, disc_loss = 0.07039204633306675
Trained batch 416 in epoch 9, gen_loss = 0.39890381733147645, disc_loss = 0.07027076538853186
Trained batch 417 in epoch 9, gen_loss = 0.3988824338077358, disc_loss = 0.07013894822203408
Trained batch 418 in epoch 9, gen_loss = 0.3988283444062622, disc_loss = 0.06999855952310712
Trained batch 419 in epoch 9, gen_loss = 0.3987801077465216, disc_loss = 0.06986210403986098
Trained batch 420 in epoch 9, gen_loss = 0.39882923471531223, disc_loss = 0.06979414536739366
Trained batch 421 in epoch 9, gen_loss = 0.39864601890481477, disc_loss = 0.06969126215164873
Trained batch 422 in epoch 9, gen_loss = 0.3985341450212695, disc_loss = 0.06982792523000433
Trained batch 423 in epoch 9, gen_loss = 0.39874899383845197, disc_loss = 0.07000910269452329
Trained batch 424 in epoch 9, gen_loss = 0.39874417883508345, disc_loss = 0.0699137542100952
Trained batch 425 in epoch 9, gen_loss = 0.39858636977107315, disc_loss = 0.06990845946643169
Trained batch 426 in epoch 9, gen_loss = 0.3987005377053098, disc_loss = 0.06978809498185053
Trained batch 427 in epoch 9, gen_loss = 0.3987182589404494, disc_loss = 0.06965737250333251
Trained batch 428 in epoch 9, gen_loss = 0.3986898390771626, disc_loss = 0.06954230467239633
Trained batch 429 in epoch 9, gen_loss = 0.3986170717796614, disc_loss = 0.0693942183033065
Trained batch 430 in epoch 9, gen_loss = 0.39872211650048495, disc_loss = 0.06928626156742673
Trained batch 431 in epoch 9, gen_loss = 0.39879811172270113, disc_loss = 0.06920314262108015
Trained batch 432 in epoch 9, gen_loss = 0.39873781301270456, disc_loss = 0.06905750471745847
Trained batch 433 in epoch 9, gen_loss = 0.398698267608469, disc_loss = 0.06892495597219138
Trained batch 434 in epoch 9, gen_loss = 0.39867689845890836, disc_loss = 0.06886753218955007
Trained batch 435 in epoch 9, gen_loss = 0.3987329680506789, disc_loss = 0.06875322119187598
Trained batch 436 in epoch 9, gen_loss = 0.3986728714791806, disc_loss = 0.06869645841266252
Trained batch 437 in epoch 9, gen_loss = 0.39888966365900214, disc_loss = 0.06856187958627531
Trained batch 438 in epoch 9, gen_loss = 0.3989488698015995, disc_loss = 0.06853833246407585
Trained batch 439 in epoch 9, gen_loss = 0.3988008713519031, disc_loss = 0.06892066111957484
Trained batch 440 in epoch 9, gen_loss = 0.39889740649940203, disc_loss = 0.06919696905107454
Trained batch 441 in epoch 9, gen_loss = 0.39888172043799275, disc_loss = 0.06909605158636203
Trained batch 442 in epoch 9, gen_loss = 0.39873068034648895, disc_loss = 0.06901830955330727
Trained batch 443 in epoch 9, gen_loss = 0.3987103705671993, disc_loss = 0.06893205430845285
Trained batch 444 in epoch 9, gen_loss = 0.39862827353932884, disc_loss = 0.0689057220861818
Trained batch 445 in epoch 9, gen_loss = 0.39860810777130684, disc_loss = 0.06892562277965883
Trained batch 446 in epoch 9, gen_loss = 0.39850718299681176, disc_loss = 0.06909427154700895
Trained batch 447 in epoch 9, gen_loss = 0.39857080921397675, disc_loss = 0.06923963666278203
Trained batch 448 in epoch 9, gen_loss = 0.39862848054991, disc_loss = 0.06913868008069445
Trained batch 449 in epoch 9, gen_loss = 0.39842520637644663, disc_loss = 0.0691826228176554
Trained batch 450 in epoch 9, gen_loss = 0.39846246208822117, disc_loss = 0.06938913777189747
Trained batch 451 in epoch 9, gen_loss = 0.39827080647897933, disc_loss = 0.0694568082566612
Trained batch 452 in epoch 9, gen_loss = 0.398317048914122, disc_loss = 0.06962422120732319
Trained batch 453 in epoch 9, gen_loss = 0.3982507594684672, disc_loss = 0.06994365522071785
Trained batch 454 in epoch 9, gen_loss = 0.3982356043634834, disc_loss = 0.0698486813558982
Trained batch 455 in epoch 9, gen_loss = 0.3982507520796437, disc_loss = 0.06993770654100859
Trained batch 456 in epoch 9, gen_loss = 0.3981280550197647, disc_loss = 0.06995521568136873
Trained batch 457 in epoch 9, gen_loss = 0.3979015559543689, disc_loss = 0.06986674169428224
Trained batch 458 in epoch 9, gen_loss = 0.3979982336037559, disc_loss = 0.06984228445196723
Trained batch 459 in epoch 9, gen_loss = 0.39803953212888343, disc_loss = 0.06979071421791679
Trained batch 460 in epoch 9, gen_loss = 0.3979016109622223, disc_loss = 0.07060716870097432
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.4762606620788574, disc_loss = 0.11333416402339935
Trained batch 1 in epoch 10, gen_loss = 0.4243892878293991, disc_loss = 0.07991471514105797
Trained batch 2 in epoch 10, gen_loss = 0.403906246026357, disc_loss = 0.08470795055230458
Trained batch 3 in epoch 10, gen_loss = 0.39456675201654434, disc_loss = 0.07484050281345844
Trained batch 4 in epoch 10, gen_loss = 0.3976974546909332, disc_loss = 0.06953997611999511
Trained batch 5 in epoch 10, gen_loss = 0.38019655148188275, disc_loss = 0.10180726647377014
Trained batch 6 in epoch 10, gen_loss = 0.3972397106034415, disc_loss = 0.12617830293519156
Trained batch 7 in epoch 10, gen_loss = 0.3886987529695034, disc_loss = 0.11972689721733332
Trained batch 8 in epoch 10, gen_loss = 0.3857404291629791, disc_loss = 0.11184787667459911
Trained batch 9 in epoch 10, gen_loss = 0.38516123592853546, disc_loss = 0.10439812801778317
Trained batch 10 in epoch 10, gen_loss = 0.3815692581913688, disc_loss = 0.09703662822192366
Trained batch 11 in epoch 10, gen_loss = 0.38193559646606445, disc_loss = 0.09482735240211089
Trained batch 12 in epoch 10, gen_loss = 0.38150007449663603, disc_loss = 0.09455335111572193
Trained batch 13 in epoch 10, gen_loss = 0.3865349292755127, disc_loss = 0.09727832222623485
Trained batch 14 in epoch 10, gen_loss = 0.38656912644704183, disc_loss = 0.10265067194898923
Trained batch 15 in epoch 10, gen_loss = 0.3879967462271452, disc_loss = 0.1017461831215769
Trained batch 16 in epoch 10, gen_loss = 0.38773175548104677, disc_loss = 0.09744908857871504
Trained batch 17 in epoch 10, gen_loss = 0.38534225192334914, disc_loss = 0.09974499108890693
Trained batch 18 in epoch 10, gen_loss = 0.3877684866127215, disc_loss = 0.098275339328929
Trained batch 19 in epoch 10, gen_loss = 0.3913412407040596, disc_loss = 0.09477913174778223
Trained batch 20 in epoch 10, gen_loss = 0.3878431036358788, disc_loss = 0.09342604680430322
Trained batch 21 in epoch 10, gen_loss = 0.3903175633062016, disc_loss = 0.0898463693447411
Trained batch 22 in epoch 10, gen_loss = 0.39165865597517596, disc_loss = 0.08852471034649921
Trained batch 23 in epoch 10, gen_loss = 0.3926854021847248, disc_loss = 0.08575969511487831
Trained batch 24 in epoch 10, gen_loss = 0.3893632829189301, disc_loss = 0.08612922888249158
Trained batch 25 in epoch 10, gen_loss = 0.39256340609147, disc_loss = 0.09430074673862411
Trained batch 26 in epoch 10, gen_loss = 0.3908783616843047, disc_loss = 0.09266212261799309
Trained batch 27 in epoch 10, gen_loss = 0.3876516233597483, disc_loss = 0.09081856091506779
Trained batch 28 in epoch 10, gen_loss = 0.39019641896774027, disc_loss = 0.08849340796085267
Trained batch 29 in epoch 10, gen_loss = 0.39008316298325857, disc_loss = 0.08619424815600117
Trained batch 30 in epoch 10, gen_loss = 0.38851472350858873, disc_loss = 0.08451404329389334
Trained batch 31 in epoch 10, gen_loss = 0.38923116121441126, disc_loss = 0.08255727574578486
Trained batch 32 in epoch 10, gen_loss = 0.3891591601299517, disc_loss = 0.08121871290672006
Trained batch 33 in epoch 10, gen_loss = 0.3878486060044345, disc_loss = 0.08055090244092486
Trained batch 34 in epoch 10, gen_loss = 0.38727201223373414, disc_loss = 0.07995220334934337
Trained batch 35 in epoch 10, gen_loss = 0.3863947813709577, disc_loss = 0.0806134038656536
Trained batch 36 in epoch 10, gen_loss = 0.38769552272719304, disc_loss = 0.08122888506969085
Trained batch 37 in epoch 10, gen_loss = 0.38562247627659846, disc_loss = 0.08277427775197123
Trained batch 38 in epoch 10, gen_loss = 0.38779239929639375, disc_loss = 0.0820463685414348
Trained batch 39 in epoch 10, gen_loss = 0.38865726366639136, disc_loss = 0.08017365126870572
Trained batch 40 in epoch 10, gen_loss = 0.388792740862544, disc_loss = 0.07853046155012236
Trained batch 41 in epoch 10, gen_loss = 0.389386895157042, disc_loss = 0.07712417109204191
Trained batch 42 in epoch 10, gen_loss = 0.39103351983913154, disc_loss = 0.07598200015896975
Trained batch 43 in epoch 10, gen_loss = 0.3919274407354268, disc_loss = 0.07544958007267931
Trained batch 44 in epoch 10, gen_loss = 0.39069343739085727, disc_loss = 0.07435532129473156
Trained batch 45 in epoch 10, gen_loss = 0.39150211409382196, disc_loss = 0.07419435323580452
Trained batch 46 in epoch 10, gen_loss = 0.38946804784713906, disc_loss = 0.07443263619504076
Trained batch 47 in epoch 10, gen_loss = 0.3911795448511839, disc_loss = 0.07321838394273072
Trained batch 48 in epoch 10, gen_loss = 0.39197857465062824, disc_loss = 0.0725697642762442
Trained batch 49 in epoch 10, gen_loss = 0.3925523346662521, disc_loss = 0.07131672218441963
Trained batch 50 in epoch 10, gen_loss = 0.39298540295339096, disc_loss = 0.07083258580635576
Trained batch 51 in epoch 10, gen_loss = 0.39392434232510054, disc_loss = 0.06993413902819157
Trained batch 52 in epoch 10, gen_loss = 0.3948951751556037, disc_loss = 0.06873697184799414
Trained batch 53 in epoch 10, gen_loss = 0.393896398169023, disc_loss = 0.06770089387686716
Trained batch 54 in epoch 10, gen_loss = 0.39292982599952003, disc_loss = 0.06714620977978815
Trained batch 55 in epoch 10, gen_loss = 0.3936381164406027, disc_loss = 0.06713215309926975
Trained batch 56 in epoch 10, gen_loss = 0.39269623264931797, disc_loss = 0.06714072021279942
Trained batch 57 in epoch 10, gen_loss = 0.39359035265856773, disc_loss = 0.06651538589583902
Trained batch 58 in epoch 10, gen_loss = 0.3935097541849492, disc_loss = 0.0657812486229054
Trained batch 59 in epoch 10, gen_loss = 0.3928620124856631, disc_loss = 0.06518005581262211
Trained batch 60 in epoch 10, gen_loss = 0.3938562303292947, disc_loss = 0.0644361727458776
Trained batch 61 in epoch 10, gen_loss = 0.3943153052560745, disc_loss = 0.0634912942205706
Trained batch 62 in epoch 10, gen_loss = 0.3945123387707604, disc_loss = 0.06320803565165353
Trained batch 63 in epoch 10, gen_loss = 0.3963721035979688, disc_loss = 0.06422307121101767
Trained batch 64 in epoch 10, gen_loss = 0.3951463846059946, disc_loss = 0.0642319367482112
Trained batch 65 in epoch 10, gen_loss = 0.3948038997072162, disc_loss = 0.06384736220493462
Trained batch 66 in epoch 10, gen_loss = 0.3948802231852688, disc_loss = 0.06330561871404078
Trained batch 67 in epoch 10, gen_loss = 0.39493822481702356, disc_loss = 0.06275415782104521
Trained batch 68 in epoch 10, gen_loss = 0.3959456980228424, disc_loss = 0.06207747131154157
Trained batch 69 in epoch 10, gen_loss = 0.39716006900582995, disc_loss = 0.06167202118252005
Trained batch 70 in epoch 10, gen_loss = 0.39759177473229423, disc_loss = 0.06093575926104062
Trained batch 71 in epoch 10, gen_loss = 0.39699144413073856, disc_loss = 0.06029861746355891
Trained batch 72 in epoch 10, gen_loss = 0.3970128207990568, disc_loss = 0.05963197327537896
Trained batch 73 in epoch 10, gen_loss = 0.39782104459968776, disc_loss = 0.059246998582337354
Trained batch 74 in epoch 10, gen_loss = 0.3966838522752126, disc_loss = 0.05897216349840164
Trained batch 75 in epoch 10, gen_loss = 0.3960949515825824, disc_loss = 0.06273002638236473
Trained batch 76 in epoch 10, gen_loss = 0.39655383802079536, disc_loss = 0.06453041316239864
Trained batch 77 in epoch 10, gen_loss = 0.39572329895618635, disc_loss = 0.06445767720922446
Trained batch 78 in epoch 10, gen_loss = 0.3962360394151905, disc_loss = 0.0643023960763895
Trained batch 79 in epoch 10, gen_loss = 0.3971123583614826, disc_loss = 0.06509440382942558
Trained batch 80 in epoch 10, gen_loss = 0.39646401486279054, disc_loss = 0.06499118951183779
Trained batch 81 in epoch 10, gen_loss = 0.39666363633260493, disc_loss = 0.06430759698879428
Trained batch 82 in epoch 10, gen_loss = 0.39541597933654327, disc_loss = 0.06371862708355289
Trained batch 83 in epoch 10, gen_loss = 0.39438815876131966, disc_loss = 0.06422122060099528
Trained batch 84 in epoch 10, gen_loss = 0.39531812282169565, disc_loss = 0.06434895972556928
Trained batch 85 in epoch 10, gen_loss = 0.39467818965745527, disc_loss = 0.06392341282565234
Trained batch 86 in epoch 10, gen_loss = 0.3948575186318365, disc_loss = 0.06349814060176241
Trained batch 87 in epoch 10, gen_loss = 0.3960632393983277, disc_loss = 0.06352437594482167
Trained batch 88 in epoch 10, gen_loss = 0.3967801791228605, disc_loss = 0.06331471862334213
Trained batch 89 in epoch 10, gen_loss = 0.3974467426538467, disc_loss = 0.06281150109652016
Trained batch 90 in epoch 10, gen_loss = 0.398512350661414, disc_loss = 0.06317842868412589
Trained batch 91 in epoch 10, gen_loss = 0.39848914580500644, disc_loss = 0.06521734508240352
Trained batch 92 in epoch 10, gen_loss = 0.39845385923180526, disc_loss = 0.06494258105834966
Trained batch 93 in epoch 10, gen_loss = 0.39814508817297345, disc_loss = 0.06444171160221734
Trained batch 94 in epoch 10, gen_loss = 0.3982780004802503, disc_loss = 0.06398880107230262
Trained batch 95 in epoch 10, gen_loss = 0.3990533941735824, disc_loss = 0.06350514168540637
Trained batch 96 in epoch 10, gen_loss = 0.39884171842299787, disc_loss = 0.06298162984018474
Trained batch 97 in epoch 10, gen_loss = 0.3988310417958668, disc_loss = 0.06409976726435886
Trained batch 98 in epoch 10, gen_loss = 0.3995545611839102, disc_loss = 0.0676662806383889
Trained batch 99 in epoch 10, gen_loss = 0.39934357672929766, disc_loss = 0.0672476752102375
Trained batch 100 in epoch 10, gen_loss = 0.3987736427547908, disc_loss = 0.06820058689849211
Trained batch 101 in epoch 10, gen_loss = 0.39894026371778224, disc_loss = 0.06784049136673703
Trained batch 102 in epoch 10, gen_loss = 0.3986275442016935, disc_loss = 0.06737573191668224
Trained batch 103 in epoch 10, gen_loss = 0.3994982090707009, disc_loss = 0.06693814128923875
Trained batch 104 in epoch 10, gen_loss = 0.39970028769402277, disc_loss = 0.06657073047189485
Trained batch 105 in epoch 10, gen_loss = 0.3996980434881066, disc_loss = 0.06604247731771672
Trained batch 106 in epoch 10, gen_loss = 0.40020086804283, disc_loss = 0.06556788484661658
Trained batch 107 in epoch 10, gen_loss = 0.3999881151097792, disc_loss = 0.06515610575917419
Trained batch 108 in epoch 10, gen_loss = 0.40003684354484625, disc_loss = 0.06462135782824197
Trained batch 109 in epoch 10, gen_loss = 0.3999800887974826, disc_loss = 0.06459306676618078
Trained batch 110 in epoch 10, gen_loss = 0.39908285694079354, disc_loss = 0.06540305236237007
Trained batch 111 in epoch 10, gen_loss = 0.3997031104351793, disc_loss = 0.06586742409438427
Trained batch 112 in epoch 10, gen_loss = 0.39985169509870816, disc_loss = 0.06542195744021276
Trained batch 113 in epoch 10, gen_loss = 0.3990788888512996, disc_loss = 0.065649184627099
Trained batch 114 in epoch 10, gen_loss = 0.39954751315324205, disc_loss = 0.06521312097978332
Trained batch 115 in epoch 10, gen_loss = 0.3991644747298339, disc_loss = 0.066163549994536
Trained batch 116 in epoch 10, gen_loss = 0.39849499530262417, disc_loss = 0.06797108928967491
Trained batch 117 in epoch 10, gen_loss = 0.3987367888123302, disc_loss = 0.067630122549895
Trained batch 118 in epoch 10, gen_loss = 0.399190622968834, disc_loss = 0.0673241113398631
Trained batch 119 in epoch 10, gen_loss = 0.3987758303682009, disc_loss = 0.06717630465670178
Trained batch 120 in epoch 10, gen_loss = 0.3983305446372544, disc_loss = 0.06707148582574503
Trained batch 121 in epoch 10, gen_loss = 0.39804486979226594, disc_loss = 0.06753554203562805
Trained batch 122 in epoch 10, gen_loss = 0.39684271788209435, disc_loss = 0.06864389349380887
Trained batch 123 in epoch 10, gen_loss = 0.3971399388486339, disc_loss = 0.06848126901463876
Trained batch 124 in epoch 10, gen_loss = 0.3967965638637543, disc_loss = 0.06833010932058096
Trained batch 125 in epoch 10, gen_loss = 0.3969686487837443, disc_loss = 0.0679696653526099
Trained batch 126 in epoch 10, gen_loss = 0.396924981686074, disc_loss = 0.06796187691126518
Trained batch 127 in epoch 10, gen_loss = 0.3968356307595968, disc_loss = 0.06847260497306706
Trained batch 128 in epoch 10, gen_loss = 0.3969963844432387, disc_loss = 0.06969714974045985
Trained batch 129 in epoch 10, gen_loss = 0.3977429848450881, disc_loss = 0.07067246369014565
Trained batch 130 in epoch 10, gen_loss = 0.39745015019678887, disc_loss = 0.07034429901400367
Trained batch 131 in epoch 10, gen_loss = 0.39665100384842267, disc_loss = 0.0706091816043199
Trained batch 132 in epoch 10, gen_loss = 0.3970813159655808, disc_loss = 0.0702321333810687
Trained batch 133 in epoch 10, gen_loss = 0.39794960973867727, disc_loss = 0.070317900607557
Trained batch 134 in epoch 10, gen_loss = 0.39724319753823456, disc_loss = 0.07005457195832773
Trained batch 135 in epoch 10, gen_loss = 0.3967226500458577, disc_loss = 0.07049527612980455
Trained batch 136 in epoch 10, gen_loss = 0.3968581439804857, disc_loss = 0.07088073094912471
Trained batch 137 in epoch 10, gen_loss = 0.39681057977503625, disc_loss = 0.0707114670034228
Trained batch 138 in epoch 10, gen_loss = 0.39670946615205394, disc_loss = 0.07031723257261428
Trained batch 139 in epoch 10, gen_loss = 0.39653042874165945, disc_loss = 0.06992764150324676
Trained batch 140 in epoch 10, gen_loss = 0.3963166356932187, disc_loss = 0.06959620694768556
Trained batch 141 in epoch 10, gen_loss = 0.39577632596794987, disc_loss = 0.06980608614214079
Trained batch 142 in epoch 10, gen_loss = 0.3961298990916539, disc_loss = 0.07052063921766057
Trained batch 143 in epoch 10, gen_loss = 0.39576826844778323, disc_loss = 0.07065936877107662
Trained batch 144 in epoch 10, gen_loss = 0.39585475078944504, disc_loss = 0.0704683886584023
Trained batch 145 in epoch 10, gen_loss = 0.39649505423356407, disc_loss = 0.07009445006436069
Trained batch 146 in epoch 10, gen_loss = 0.39647069897781423, disc_loss = 0.06972905418829245
Trained batch 147 in epoch 10, gen_loss = 0.39650706121244944, disc_loss = 0.06939359498210251
Trained batch 148 in epoch 10, gen_loss = 0.3964225059787699, disc_loss = 0.06978735333346081
Trained batch 149 in epoch 10, gen_loss = 0.39678609629472095, disc_loss = 0.07014918203776081
Trained batch 150 in epoch 10, gen_loss = 0.3965648724543338, disc_loss = 0.07032734324033095
Trained batch 151 in epoch 10, gen_loss = 0.396320415562705, disc_loss = 0.07031946022088002
Trained batch 152 in epoch 10, gen_loss = 0.3964643137517318, disc_loss = 0.07040549532869478
Trained batch 153 in epoch 10, gen_loss = 0.3964142029161577, disc_loss = 0.07047536573070404
Trained batch 154 in epoch 10, gen_loss = 0.39601161056949247, disc_loss = 0.07033168592400128
Trained batch 155 in epoch 10, gen_loss = 0.3958169028927118, disc_loss = 0.07003723103433657
Trained batch 156 in epoch 10, gen_loss = 0.3960889786671681, disc_loss = 0.07013069994296807
Trained batch 157 in epoch 10, gen_loss = 0.3956592790310896, disc_loss = 0.07108024865553915
Trained batch 158 in epoch 10, gen_loss = 0.3960145173957513, disc_loss = 0.07118549112980284
Trained batch 159 in epoch 10, gen_loss = 0.3960830334573984, disc_loss = 0.07095916778198444
Trained batch 160 in epoch 10, gen_loss = 0.39585144975170583, disc_loss = 0.07156029227334335
Trained batch 161 in epoch 10, gen_loss = 0.3962356010336935, disc_loss = 0.07138631846410809
Trained batch 162 in epoch 10, gen_loss = 0.39623197931453497, disc_loss = 0.0710167698847827
Trained batch 163 in epoch 10, gen_loss = 0.39581128827682355, disc_loss = 0.07063176207494264
Trained batch 164 in epoch 10, gen_loss = 0.3957109193007151, disc_loss = 0.0702322422470333
Trained batch 165 in epoch 10, gen_loss = 0.395800120679729, disc_loss = 0.06991549676946218
Trained batch 166 in epoch 10, gen_loss = 0.395964353562829, disc_loss = 0.0695308316136504
Trained batch 167 in epoch 10, gen_loss = 0.3964139104244255, disc_loss = 0.06919497798385453
Trained batch 168 in epoch 10, gen_loss = 0.3965710454438565, disc_loss = 0.06885600977538693
Trained batch 169 in epoch 10, gen_loss = 0.396285362979945, disc_loss = 0.06892100622165291
Trained batch 170 in epoch 10, gen_loss = 0.3963346991971222, disc_loss = 0.06995111936158692
Trained batch 171 in epoch 10, gen_loss = 0.39624455588501556, disc_loss = 0.07004669704203775
Trained batch 172 in epoch 10, gen_loss = 0.39613422027902107, disc_loss = 0.06997010160528253
Trained batch 173 in epoch 10, gen_loss = 0.3962958874716156, disc_loss = 0.06970304663121786
Trained batch 174 in epoch 10, gen_loss = 0.39593868272645133, disc_loss = 0.06943576394713351
Trained batch 175 in epoch 10, gen_loss = 0.39654043028977787, disc_loss = 0.06914893353876489
Trained batch 176 in epoch 10, gen_loss = 0.3963566552110985, disc_loss = 0.06893197613594643
Trained batch 177 in epoch 10, gen_loss = 0.3967558659529418, disc_loss = 0.0685788837648677
Trained batch 178 in epoch 10, gen_loss = 0.39645848061119376, disc_loss = 0.06879735235437001
Trained batch 179 in epoch 10, gen_loss = 0.39601312544610767, disc_loss = 0.06995833194297221
Trained batch 180 in epoch 10, gen_loss = 0.39596282233849417, disc_loss = 0.0698051436480073
Trained batch 181 in epoch 10, gen_loss = 0.3963436505624226, disc_loss = 0.07222765588948687
Trained batch 182 in epoch 10, gen_loss = 0.3962390310451633, disc_loss = 0.07263126565255429
Trained batch 183 in epoch 10, gen_loss = 0.39638367797369545, disc_loss = 0.07267964962343483
Trained batch 184 in epoch 10, gen_loss = 0.39630748436257646, disc_loss = 0.07302157805376762
Trained batch 185 in epoch 10, gen_loss = 0.3958104533213441, disc_loss = 0.07391182220070272
Trained batch 186 in epoch 10, gen_loss = 0.39552932866116897, disc_loss = 0.07446412581771134
Trained batch 187 in epoch 10, gen_loss = 0.3950364680049267, disc_loss = 0.07451141779211924
Trained batch 188 in epoch 10, gen_loss = 0.39500708002892754, disc_loss = 0.07430049874598071
Trained batch 189 in epoch 10, gen_loss = 0.3948673621604317, disc_loss = 0.07424226174817274
Trained batch 190 in epoch 10, gen_loss = 0.3952628926456911, disc_loss = 0.07401381700216787
Trained batch 191 in epoch 10, gen_loss = 0.3952324671360354, disc_loss = 0.07373186592788745
Trained batch 192 in epoch 10, gen_loss = 0.39527077208528866, disc_loss = 0.07367072704156445
Trained batch 193 in epoch 10, gen_loss = 0.3953869645435786, disc_loss = 0.07430323772132397
Trained batch 194 in epoch 10, gen_loss = 0.395209934314092, disc_loss = 0.07480258955023228
Trained batch 195 in epoch 10, gen_loss = 0.39493527780382, disc_loss = 0.07447923085063088
Trained batch 196 in epoch 10, gen_loss = 0.39538926385380896, disc_loss = 0.07452962800936046
Trained batch 197 in epoch 10, gen_loss = 0.39516470513560553, disc_loss = 0.07454087494900732
Trained batch 198 in epoch 10, gen_loss = 0.39537097281547046, disc_loss = 0.07436995322455713
Trained batch 199 in epoch 10, gen_loss = 0.3948771674931049, disc_loss = 0.0746376078017056
Trained batch 200 in epoch 10, gen_loss = 0.3949485522004502, disc_loss = 0.07482969633011675
Trained batch 201 in epoch 10, gen_loss = 0.39454788397444357, disc_loss = 0.07482057487094167
Trained batch 202 in epoch 10, gen_loss = 0.3944720683133074, disc_loss = 0.07468034257295683
Trained batch 203 in epoch 10, gen_loss = 0.39433025539505717, disc_loss = 0.07454826027227968
Trained batch 204 in epoch 10, gen_loss = 0.394295493422485, disc_loss = 0.07450134752363693
Trained batch 205 in epoch 10, gen_loss = 0.3948151528545954, disc_loss = 0.07446948805986678
Trained batch 206 in epoch 10, gen_loss = 0.3946726913901343, disc_loss = 0.07440371143717121
Trained batch 207 in epoch 10, gen_loss = 0.39452598630808866, disc_loss = 0.07417152258746612
Trained batch 208 in epoch 10, gen_loss = 0.3948718521868783, disc_loss = 0.07385817126473457
Trained batch 209 in epoch 10, gen_loss = 0.39494589113053824, disc_loss = 0.07369649781889859
Trained batch 210 in epoch 10, gen_loss = 0.394704266605784, disc_loss = 0.07337436744704913
Trained batch 211 in epoch 10, gen_loss = 0.3943181400591472, disc_loss = 0.07338896022125516
Trained batch 212 in epoch 10, gen_loss = 0.3944960405848955, disc_loss = 0.07320813272375735
Trained batch 213 in epoch 10, gen_loss = 0.39433245750788215, disc_loss = 0.07310544144988895
Trained batch 214 in epoch 10, gen_loss = 0.39440751061883084, disc_loss = 0.07303065954772539
Trained batch 215 in epoch 10, gen_loss = 0.39392939016774847, disc_loss = 0.07278714026324451
Trained batch 216 in epoch 10, gen_loss = 0.39403504023354174, disc_loss = 0.07256278952729592
Trained batch 217 in epoch 10, gen_loss = 0.393810925680563, disc_loss = 0.07225426925141193
Trained batch 218 in epoch 10, gen_loss = 0.39361076785004845, disc_loss = 0.07196552909859648
Trained batch 219 in epoch 10, gen_loss = 0.3934769905426285, disc_loss = 0.07185149453157051
Trained batch 220 in epoch 10, gen_loss = 0.39339757666868325, disc_loss = 0.07226270386249636
Trained batch 221 in epoch 10, gen_loss = 0.39306678374608356, disc_loss = 0.07307253055996052
Trained batch 222 in epoch 10, gen_loss = 0.3938973407039728, disc_loss = 0.07353579686879444
Trained batch 223 in epoch 10, gen_loss = 0.39396480776901754, disc_loss = 0.07328018662103984
Trained batch 224 in epoch 10, gen_loss = 0.39410704414049785, disc_loss = 0.07299564447253942
Trained batch 225 in epoch 10, gen_loss = 0.39400497804173323, disc_loss = 0.07286189985667578
Trained batch 226 in epoch 10, gen_loss = 0.3942573965908672, disc_loss = 0.0726505464172639
Trained batch 227 in epoch 10, gen_loss = 0.3940857167829547, disc_loss = 0.07258181324996577
Trained batch 228 in epoch 10, gen_loss = 0.3942049199056417, disc_loss = 0.07256508780049575
Trained batch 229 in epoch 10, gen_loss = 0.3940714505703553, disc_loss = 0.07262391595817778
Trained batch 230 in epoch 10, gen_loss = 0.3939415184192327, disc_loss = 0.07281924476564834
Trained batch 231 in epoch 10, gen_loss = 0.3941077072301815, disc_loss = 0.07282030292192539
Trained batch 232 in epoch 10, gen_loss = 0.39424947556507944, disc_loss = 0.07253895448360896
Trained batch 233 in epoch 10, gen_loss = 0.39405299379275394, disc_loss = 0.07244716773533987
Trained batch 234 in epoch 10, gen_loss = 0.3944119486402958, disc_loss = 0.0728286804453014
Trained batch 235 in epoch 10, gen_loss = 0.3940753503623655, disc_loss = 0.07280416989706899
Trained batch 236 in epoch 10, gen_loss = 0.39413220683733624, disc_loss = 0.07254662470624856
Trained batch 237 in epoch 10, gen_loss = 0.3943254838721091, disc_loss = 0.0722680538110122
Trained batch 238 in epoch 10, gen_loss = 0.394464729345992, disc_loss = 0.0721370352891948
Trained batch 239 in epoch 10, gen_loss = 0.3942707233130932, disc_loss = 0.07195083739546439
Trained batch 240 in epoch 10, gen_loss = 0.3941711831636943, disc_loss = 0.07180175029081427
Trained batch 241 in epoch 10, gen_loss = 0.3940846488988104, disc_loss = 0.07167519261090716
Trained batch 242 in epoch 10, gen_loss = 0.39375733249962575, disc_loss = 0.07166569537402671
Trained batch 243 in epoch 10, gen_loss = 0.39413179615970517, disc_loss = 0.07179407721965528
Trained batch 244 in epoch 10, gen_loss = 0.39391415386783835, disc_loss = 0.07208710095408011
Trained batch 245 in epoch 10, gen_loss = 0.39407335027931184, disc_loss = 0.0726998927056547
Trained batch 246 in epoch 10, gen_loss = 0.3939278972776313, disc_loss = 0.07262441185623528
Trained batch 247 in epoch 10, gen_loss = 0.3938896464965036, disc_loss = 0.0725660519524207
Trained batch 248 in epoch 10, gen_loss = 0.39392109053680696, disc_loss = 0.07240341706986887
Trained batch 249 in epoch 10, gen_loss = 0.39390924310684206, disc_loss = 0.07225669185817242
Trained batch 250 in epoch 10, gen_loss = 0.3938694684154009, disc_loss = 0.07206408833839979
Trained batch 251 in epoch 10, gen_loss = 0.3943444206601098, disc_loss = 0.07209441633451552
Trained batch 252 in epoch 10, gen_loss = 0.3941629340526144, disc_loss = 0.0727366503519503
Trained batch 253 in epoch 10, gen_loss = 0.3942654724196186, disc_loss = 0.07265292509920954
Trained batch 254 in epoch 10, gen_loss = 0.39469708391264374, disc_loss = 0.07253415491066727
Trained batch 255 in epoch 10, gen_loss = 0.39474720950238407, disc_loss = 0.07231447185768047
Trained batch 256 in epoch 10, gen_loss = 0.3943805453378403, disc_loss = 0.07249311410644407
Trained batch 257 in epoch 10, gen_loss = 0.3948742329150207, disc_loss = 0.07264318984983735
Trained batch 258 in epoch 10, gen_loss = 0.3949446326056963, disc_loss = 0.07245576199733843
Trained batch 259 in epoch 10, gen_loss = 0.3948728390611135, disc_loss = 0.07238977130932303
Trained batch 260 in epoch 10, gen_loss = 0.3947328240021892, disc_loss = 0.07229859910734084
Trained batch 261 in epoch 10, gen_loss = 0.39462960517133466, disc_loss = 0.07258851263842737
Trained batch 262 in epoch 10, gen_loss = 0.3945777946551943, disc_loss = 0.07246957285180972
Trained batch 263 in epoch 10, gen_loss = 0.39450812689734227, disc_loss = 0.07226753569998298
Trained batch 264 in epoch 10, gen_loss = 0.3945808094627452, disc_loss = 0.07212085143996859
Trained batch 265 in epoch 10, gen_loss = 0.39469067741157415, disc_loss = 0.07192816130144704
Trained batch 266 in epoch 10, gen_loss = 0.39463110731335616, disc_loss = 0.07226940256993422
Trained batch 267 in epoch 10, gen_loss = 0.39495653837029615, disc_loss = 0.0732176120796088
Trained batch 268 in epoch 10, gen_loss = 0.39473083415882293, disc_loss = 0.0734480715124802
Trained batch 269 in epoch 10, gen_loss = 0.39449917442268795, disc_loss = 0.0732408620417118
Trained batch 270 in epoch 10, gen_loss = 0.3942587891407998, disc_loss = 0.0732516741785616
Trained batch 271 in epoch 10, gen_loss = 0.39420127057853865, disc_loss = 0.0731014490730184
Trained batch 272 in epoch 10, gen_loss = 0.3941881817120772, disc_loss = 0.07297435405599328
Trained batch 273 in epoch 10, gen_loss = 0.3940671981468688, disc_loss = 0.07313361203801023
Trained batch 274 in epoch 10, gen_loss = 0.3937692139365456, disc_loss = 0.07368084642020138
Trained batch 275 in epoch 10, gen_loss = 0.39402026456335315, disc_loss = 0.0756052097008712
Trained batch 276 in epoch 10, gen_loss = 0.39385688046686057, disc_loss = 0.0756200202051483
Trained batch 277 in epoch 10, gen_loss = 0.3936457340237048, disc_loss = 0.07645196588240939
Trained batch 278 in epoch 10, gen_loss = 0.39405267490708273, disc_loss = 0.07669513389521602
Trained batch 279 in epoch 10, gen_loss = 0.39394210992114886, disc_loss = 0.07686426394752094
Trained batch 280 in epoch 10, gen_loss = 0.3938156667553233, disc_loss = 0.07681305229239617
Trained batch 281 in epoch 10, gen_loss = 0.39346186711010356, disc_loss = 0.07675286650604812
Trained batch 282 in epoch 10, gen_loss = 0.39333357943662905, disc_loss = 0.07675328557198545
Trained batch 283 in epoch 10, gen_loss = 0.393130362873346, disc_loss = 0.07665768289335177
Trained batch 284 in epoch 10, gen_loss = 0.3931423568934725, disc_loss = 0.07649723207741453
Trained batch 285 in epoch 10, gen_loss = 0.39304752762501055, disc_loss = 0.07672075322874776
Trained batch 286 in epoch 10, gen_loss = 0.3933666933081291, disc_loss = 0.07695131865735669
Trained batch 287 in epoch 10, gen_loss = 0.3933146493509412, disc_loss = 0.07679886020357823
Trained batch 288 in epoch 10, gen_loss = 0.3933565007155329, disc_loss = 0.07658441400213431
Trained batch 289 in epoch 10, gen_loss = 0.39364309012889864, disc_loss = 0.07638383571315428
Trained batch 290 in epoch 10, gen_loss = 0.39352920927952245, disc_loss = 0.07652401969579282
Trained batch 291 in epoch 10, gen_loss = 0.39397185163138665, disc_loss = 0.07671416351214459
Trained batch 292 in epoch 10, gen_loss = 0.3940222202307535, disc_loss = 0.07648702850088528
Trained batch 293 in epoch 10, gen_loss = 0.3938799934322331, disc_loss = 0.07653446031138808
Trained batch 294 in epoch 10, gen_loss = 0.3938037070177369, disc_loss = 0.0765352252618236
Trained batch 295 in epoch 10, gen_loss = 0.3934803451033863, disc_loss = 0.0763572439538768
Trained batch 296 in epoch 10, gen_loss = 0.39348266231090534, disc_loss = 0.07612533678115668
Trained batch 297 in epoch 10, gen_loss = 0.39375414504300826, disc_loss = 0.07592008241152254
Trained batch 298 in epoch 10, gen_loss = 0.3936790035520509, disc_loss = 0.07583955805717553
Trained batch 299 in epoch 10, gen_loss = 0.3934952409068743, disc_loss = 0.07574656604013096
Trained batch 300 in epoch 10, gen_loss = 0.39325280046938266, disc_loss = 0.07574257849440276
Trained batch 301 in epoch 10, gen_loss = 0.3930628082610124, disc_loss = 0.07633248268355251
Trained batch 302 in epoch 10, gen_loss = 0.3931639011543576, disc_loss = 0.07641240109293031
Trained batch 303 in epoch 10, gen_loss = 0.3931052014231682, disc_loss = 0.07620456030034754
Trained batch 304 in epoch 10, gen_loss = 0.3930520851103986, disc_loss = 0.07641934737349387
Trained batch 305 in epoch 10, gen_loss = 0.39312663576961343, disc_loss = 0.07645495279290367
Trained batch 306 in epoch 10, gen_loss = 0.3931952916838059, disc_loss = 0.07624456980675216
Trained batch 307 in epoch 10, gen_loss = 0.39317576490439377, disc_loss = 0.07617794204799627
Trained batch 308 in epoch 10, gen_loss = 0.39331198471649564, disc_loss = 0.07601158260774699
Trained batch 309 in epoch 10, gen_loss = 0.3933061492058539, disc_loss = 0.07581584757764734
Trained batch 310 in epoch 10, gen_loss = 0.39317976134766336, disc_loss = 0.0757069550230021
Trained batch 311 in epoch 10, gen_loss = 0.3930746528009574, disc_loss = 0.0757250777603939
Trained batch 312 in epoch 10, gen_loss = 0.39305612721001376, disc_loss = 0.07560612500672
Trained batch 313 in epoch 10, gen_loss = 0.392977254690638, disc_loss = 0.07545225219178209
Trained batch 314 in epoch 10, gen_loss = 0.39324333961047825, disc_loss = 0.07532915752233257
Trained batch 315 in epoch 10, gen_loss = 0.39310127062888084, disc_loss = 0.07566654705884572
Trained batch 316 in epoch 10, gen_loss = 0.39341668864529966, disc_loss = 0.07564124117285154
Trained batch 317 in epoch 10, gen_loss = 0.3937582268654925, disc_loss = 0.07544190368802527
Trained batch 318 in epoch 10, gen_loss = 0.39373921012056284, disc_loss = 0.0752277018700881
Trained batch 319 in epoch 10, gen_loss = 0.39365429235622285, disc_loss = 0.07503211715666111
Trained batch 320 in epoch 10, gen_loss = 0.3936018962355046, disc_loss = 0.07481834006196939
Trained batch 321 in epoch 10, gen_loss = 0.39364697761046963, disc_loss = 0.0746272763784003
Trained batch 322 in epoch 10, gen_loss = 0.3937534905808629, disc_loss = 0.07440956030905985
Trained batch 323 in epoch 10, gen_loss = 0.39379622474496745, disc_loss = 0.07423038029307384
Trained batch 324 in epoch 10, gen_loss = 0.39403020611176126, disc_loss = 0.07415618958954627
Trained batch 325 in epoch 10, gen_loss = 0.39384914870642446, disc_loss = 0.07408653800175782
Trained batch 326 in epoch 10, gen_loss = 0.39362121056708355, disc_loss = 0.07425371766523302
Trained batch 327 in epoch 10, gen_loss = 0.3938974302898093, disc_loss = 0.07446197390261038
Trained batch 328 in epoch 10, gen_loss = 0.3937641490918887, disc_loss = 0.07459054660267199
Trained batch 329 in epoch 10, gen_loss = 0.39389615365953157, disc_loss = 0.07447320798016858
Trained batch 330 in epoch 10, gen_loss = 0.3940910445779472, disc_loss = 0.07426787448872522
Trained batch 331 in epoch 10, gen_loss = 0.39401883129254883, disc_loss = 0.07422907100373273
Trained batch 332 in epoch 10, gen_loss = 0.3939928448236024, disc_loss = 0.0740552082764091
Trained batch 333 in epoch 10, gen_loss = 0.3941786710373656, disc_loss = 0.07390276782359638
Trained batch 334 in epoch 10, gen_loss = 0.39422414498542674, disc_loss = 0.07375427683843161
Trained batch 335 in epoch 10, gen_loss = 0.39415975757652805, disc_loss = 0.0739655172191782
Trained batch 336 in epoch 10, gen_loss = 0.39412962886275454, disc_loss = 0.07467693200152511
Trained batch 337 in epoch 10, gen_loss = 0.39417949803834834, disc_loss = 0.07488757190322118
Trained batch 338 in epoch 10, gen_loss = 0.39402408875898626, disc_loss = 0.0747240274446772
Trained batch 339 in epoch 10, gen_loss = 0.3937472892158172, disc_loss = 0.07490197550779318
Trained batch 340 in epoch 10, gen_loss = 0.39385361790307455, disc_loss = 0.07515392344597935
Trained batch 341 in epoch 10, gen_loss = 0.3939145295417797, disc_loss = 0.07497107632164109
Trained batch 342 in epoch 10, gen_loss = 0.3939905144904167, disc_loss = 0.07483773602243328
Trained batch 343 in epoch 10, gen_loss = 0.3937394882357398, disc_loss = 0.0748892736832373
Trained batch 344 in epoch 10, gen_loss = 0.393703531095947, disc_loss = 0.07501535508241775
Trained batch 345 in epoch 10, gen_loss = 0.3937477011212035, disc_loss = 0.07484923039073113
Trained batch 346 in epoch 10, gen_loss = 0.3936979196944223, disc_loss = 0.074955618419612
Trained batch 347 in epoch 10, gen_loss = 0.3935642306660784, disc_loss = 0.07482910437520122
Trained batch 348 in epoch 10, gen_loss = 0.393653391340059, disc_loss = 0.07472401281770713
Trained batch 349 in epoch 10, gen_loss = 0.39361565394060954, disc_loss = 0.07479954503210527
Trained batch 350 in epoch 10, gen_loss = 0.39389213758316477, disc_loss = 0.07510786604115002
Trained batch 351 in epoch 10, gen_loss = 0.3939979319376024, disc_loss = 0.07504564149844968
Trained batch 352 in epoch 10, gen_loss = 0.3939526442427811, disc_loss = 0.0749567535075309
Trained batch 353 in epoch 10, gen_loss = 0.3942205011844635, disc_loss = 0.0748839144184554
Trained batch 354 in epoch 10, gen_loss = 0.3943748665527559, disc_loss = 0.07468986091741793
Trained batch 355 in epoch 10, gen_loss = 0.3943446668681134, disc_loss = 0.0745085216195354
Trained batch 356 in epoch 10, gen_loss = 0.39445798353654665, disc_loss = 0.0744757115272205
Trained batch 357 in epoch 10, gen_loss = 0.3943035311206093, disc_loss = 0.07453491692509315
Trained batch 358 in epoch 10, gen_loss = 0.3943300727848223, disc_loss = 0.07468134778860469
Trained batch 359 in epoch 10, gen_loss = 0.3941176996462875, disc_loss = 0.07498943999978817
Trained batch 360 in epoch 10, gen_loss = 0.39428077873430756, disc_loss = 0.07564387868553235
Trained batch 361 in epoch 10, gen_loss = 0.39414168721404524, disc_loss = 0.07548540624537768
Trained batch 362 in epoch 10, gen_loss = 0.39438268460189674, disc_loss = 0.07536496396225265
Trained batch 363 in epoch 10, gen_loss = 0.3942321895898043, disc_loss = 0.07522821712696535
Trained batch 364 in epoch 10, gen_loss = 0.3942190798994613, disc_loss = 0.07513940993390263
Trained batch 365 in epoch 10, gen_loss = 0.39399937308225474, disc_loss = 0.07498627967491257
Trained batch 366 in epoch 10, gen_loss = 0.3939685490215832, disc_loss = 0.07489992790076405
Trained batch 367 in epoch 10, gen_loss = 0.3940945746296126, disc_loss = 0.07487995276966578
Trained batch 368 in epoch 10, gen_loss = 0.3938671551584228, disc_loss = 0.075304177660384
Trained batch 369 in epoch 10, gen_loss = 0.39384745528569093, disc_loss = 0.07582577880018869
Trained batch 370 in epoch 10, gen_loss = 0.39387429724485085, disc_loss = 0.0757579541215397
Trained batch 371 in epoch 10, gen_loss = 0.39389881675922744, disc_loss = 0.07566755561668786
Trained batch 372 in epoch 10, gen_loss = 0.3937861036519263, disc_loss = 0.07554492841027777
Trained batch 373 in epoch 10, gen_loss = 0.39367370658061085, disc_loss = 0.07544457135761884
Trained batch 374 in epoch 10, gen_loss = 0.39357790764172873, disc_loss = 0.07539136092116436
Trained batch 375 in epoch 10, gen_loss = 0.39346580825587535, disc_loss = 0.07557869187625561
Trained batch 376 in epoch 10, gen_loss = 0.39343347046672505, disc_loss = 0.07612778764435484
Trained batch 377 in epoch 10, gen_loss = 0.3933269532900008, disc_loss = 0.07609623619577005
Trained batch 378 in epoch 10, gen_loss = 0.3934950989752143, disc_loss = 0.07599480529033178
Trained batch 379 in epoch 10, gen_loss = 0.39317605244485954, disc_loss = 0.07589588655698064
Trained batch 380 in epoch 10, gen_loss = 0.392951858716374, disc_loss = 0.07586231765403288
Trained batch 381 in epoch 10, gen_loss = 0.3932623860879718, disc_loss = 0.07609218811733326
Trained batch 382 in epoch 10, gen_loss = 0.3933104152156541, disc_loss = 0.07602968708157305
Trained batch 383 in epoch 10, gen_loss = 0.3932741341025879, disc_loss = 0.07588890115584945
Trained batch 384 in epoch 10, gen_loss = 0.393634187633341, disc_loss = 0.07575059806226522
Trained batch 385 in epoch 10, gen_loss = 0.3935951590538025, disc_loss = 0.07563167905261248
Trained batch 386 in epoch 10, gen_loss = 0.39351497840819744, disc_loss = 0.07552436285096314
Trained batch 387 in epoch 10, gen_loss = 0.39350902803779875, disc_loss = 0.07537915578025595
Trained batch 388 in epoch 10, gen_loss = 0.3937727761452486, disc_loss = 0.07545385616268857
Trained batch 389 in epoch 10, gen_loss = 0.39379122601105615, disc_loss = 0.07557464130461598
Trained batch 390 in epoch 10, gen_loss = 0.3937438761486727, disc_loss = 0.07572947883897502
Trained batch 391 in epoch 10, gen_loss = 0.3936418623340373, disc_loss = 0.0756145688320263
Trained batch 392 in epoch 10, gen_loss = 0.3933720797224506, disc_loss = 0.07564186101717728
Trained batch 393 in epoch 10, gen_loss = 0.39332693399209057, disc_loss = 0.07571732942818613
Trained batch 394 in epoch 10, gen_loss = 0.3930800545819198, disc_loss = 0.07556838782480624
Trained batch 395 in epoch 10, gen_loss = 0.39321031684827323, disc_loss = 0.07541898500898646
Trained batch 396 in epoch 10, gen_loss = 0.39341403029727695, disc_loss = 0.07531177257457443
Trained batch 397 in epoch 10, gen_loss = 0.3931597749791553, disc_loss = 0.07552008360072072
Trained batch 398 in epoch 10, gen_loss = 0.39333852191915486, disc_loss = 0.07580190664740807
Trained batch 399 in epoch 10, gen_loss = 0.39355426400899884, disc_loss = 0.0757200147327967
Trained batch 400 in epoch 10, gen_loss = 0.39330988825110724, disc_loss = 0.0762523764354221
Trained batch 401 in epoch 10, gen_loss = 0.39330631272116706, disc_loss = 0.07657089204161395
Trained batch 402 in epoch 10, gen_loss = 0.393407645799386, disc_loss = 0.07641576084241308
Trained batch 403 in epoch 10, gen_loss = 0.39335429860223636, disc_loss = 0.07635690030033267
Trained batch 404 in epoch 10, gen_loss = 0.3933672339827926, disc_loss = 0.07622275149886623
Trained batch 405 in epoch 10, gen_loss = 0.3931323099018905, disc_loss = 0.07616944492478016
Trained batch 406 in epoch 10, gen_loss = 0.39329198171231317, disc_loss = 0.07613788803934099
Trained batch 407 in epoch 10, gen_loss = 0.393173972473425, disc_loss = 0.0760784623208547
Trained batch 408 in epoch 10, gen_loss = 0.39313835619714266, disc_loss = 0.07600582066540831
Trained batch 409 in epoch 10, gen_loss = 0.39302134637425584, disc_loss = 0.07592353575249634
Trained batch 410 in epoch 10, gen_loss = 0.39299741184334397, disc_loss = 0.07585209650452047
Trained batch 411 in epoch 10, gen_loss = 0.3930062844770626, disc_loss = 0.0758162430799521
Trained batch 412 in epoch 10, gen_loss = 0.3931036338246186, disc_loss = 0.07572829417352166
Trained batch 413 in epoch 10, gen_loss = 0.3931712298001644, disc_loss = 0.07558654501341319
Trained batch 414 in epoch 10, gen_loss = 0.39311732161475954, disc_loss = 0.07562336155763233
Trained batch 415 in epoch 10, gen_loss = 0.39323192455161077, disc_loss = 0.07591073457465078
Trained batch 416 in epoch 10, gen_loss = 0.39318140119099787, disc_loss = 0.07586091182170084
Trained batch 417 in epoch 10, gen_loss = 0.39345315726179825, disc_loss = 0.07576817420921757
Trained batch 418 in epoch 10, gen_loss = 0.39345226701802455, disc_loss = 0.07563736832307247
Trained batch 419 in epoch 10, gen_loss = 0.39338141630093254, disc_loss = 0.07553251313178667
Trained batch 420 in epoch 10, gen_loss = 0.39340549919780815, disc_loss = 0.07562459037460015
Trained batch 421 in epoch 10, gen_loss = 0.393460511031309, disc_loss = 0.0757526581449284
Trained batch 422 in epoch 10, gen_loss = 0.3933946093628029, disc_loss = 0.07570500473929988
Trained batch 423 in epoch 10, gen_loss = 0.3934984469329411, disc_loss = 0.07557850153369934
Trained batch 424 in epoch 10, gen_loss = 0.3935322892665863, disc_loss = 0.07546159817672828
Trained batch 425 in epoch 10, gen_loss = 0.3934334748787499, disc_loss = 0.07530620234401923
Trained batch 426 in epoch 10, gen_loss = 0.39336465560859485, disc_loss = 0.07516898168796189
Trained batch 427 in epoch 10, gen_loss = 0.39337534074471375, disc_loss = 0.07508111210043812
Trained batch 428 in epoch 10, gen_loss = 0.39307902784614296, disc_loss = 0.07531384767048356
Trained batch 429 in epoch 10, gen_loss = 0.39334349008493646, disc_loss = 0.07597677237462512
Trained batch 430 in epoch 10, gen_loss = 0.39333821241927536, disc_loss = 0.07592656976152255
Trained batch 431 in epoch 10, gen_loss = 0.39312753129612515, disc_loss = 0.07599292846646642
Trained batch 432 in epoch 10, gen_loss = 0.3930152313951532, disc_loss = 0.07585568415693612
Trained batch 433 in epoch 10, gen_loss = 0.39312654685589576, disc_loss = 0.07571623306978957
Trained batch 434 in epoch 10, gen_loss = 0.393378457187236, disc_loss = 0.07556259975950608
Trained batch 435 in epoch 10, gen_loss = 0.39344307869125944, disc_loss = 0.07541744773908424
Trained batch 436 in epoch 10, gen_loss = 0.3934903495371751, disc_loss = 0.0753040680261137
Trained batch 437 in epoch 10, gen_loss = 0.3934740284670433, disc_loss = 0.07523154883887874
Trained batch 438 in epoch 10, gen_loss = 0.39336868726854174, disc_loss = 0.07512157106377473
Trained batch 439 in epoch 10, gen_loss = 0.39324190934950654, disc_loss = 0.0750660174420442
Trained batch 440 in epoch 10, gen_loss = 0.3932499169222081, disc_loss = 0.07508036189938551
Trained batch 441 in epoch 10, gen_loss = 0.3931763245644073, disc_loss = 0.07507673340609373
Trained batch 442 in epoch 10, gen_loss = 0.39321774621042116, disc_loss = 0.07518762819107377
Trained batch 443 in epoch 10, gen_loss = 0.3933477997779846, disc_loss = 0.0750436579728885
Trained batch 444 in epoch 10, gen_loss = 0.3931736545616321, disc_loss = 0.07515568754353215
Trained batch 445 in epoch 10, gen_loss = 0.3933723460665733, disc_loss = 0.0754988605569998
Trained batch 446 in epoch 10, gen_loss = 0.3934646464834277, disc_loss = 0.07536218109096857
Trained batch 447 in epoch 10, gen_loss = 0.39330650699724046, disc_loss = 0.0754399050201755
Trained batch 448 in epoch 10, gen_loss = 0.39325009767621555, disc_loss = 0.07534289054307083
Trained batch 449 in epoch 10, gen_loss = 0.3933350118001302, disc_loss = 0.07545887238035599
Trained batch 450 in epoch 10, gen_loss = 0.39321960115644194, disc_loss = 0.0756542289427207
Trained batch 451 in epoch 10, gen_loss = 0.3932446517643675, disc_loss = 0.07552420850678356
Trained batch 452 in epoch 10, gen_loss = 0.3933630792247275, disc_loss = 0.07539717849368686
Trained batch 453 in epoch 10, gen_loss = 0.39336188380413645, disc_loss = 0.07531442161288424
Trained batch 454 in epoch 10, gen_loss = 0.3934220754183256, disc_loss = 0.07517879150070987
Trained batch 455 in epoch 10, gen_loss = 0.39359237730764507, disc_loss = 0.07526526074006892
Trained batch 456 in epoch 10, gen_loss = 0.393352122484203, disc_loss = 0.07548666857916625
Trained batch 457 in epoch 10, gen_loss = 0.39346890210064217, disc_loss = 0.07540641691714656
Trained batch 458 in epoch 10, gen_loss = 0.39361025071611594, disc_loss = 0.07536712020213568
Trained batch 459 in epoch 10, gen_loss = 0.3936905821380408, disc_loss = 0.07524226225264695
Trained batch 460 in epoch 10, gen_loss = 0.393716376800082, disc_loss = 0.07567572769852367
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.4532662630081177, disc_loss = 0.1895596832036972
Trained batch 1 in epoch 11, gen_loss = 0.4713052213191986, disc_loss = 0.13193044811487198
Trained batch 2 in epoch 11, gen_loss = 0.4558364748954773, disc_loss = 0.09711758668224017
Trained batch 3 in epoch 11, gen_loss = 0.42324327677488327, disc_loss = 0.08712505269795656
Trained batch 4 in epoch 11, gen_loss = 0.4206398904323578, disc_loss = 0.07762743458151818
Trained batch 5 in epoch 11, gen_loss = 0.42218180000782013, disc_loss = 0.06931635395934184
Trained batch 6 in epoch 11, gen_loss = 0.4136874462877001, disc_loss = 0.06342523784509727
Trained batch 7 in epoch 11, gen_loss = 0.4007688909769058, disc_loss = 0.0629064457025379
Trained batch 8 in epoch 11, gen_loss = 0.3986515137884352, disc_loss = 0.05776319425139162
Trained batch 9 in epoch 11, gen_loss = 0.39676578938961027, disc_loss = 0.05668575074523687
Trained batch 10 in epoch 11, gen_loss = 0.40052177147431806, disc_loss = 0.06295321255244991
Trained batch 11 in epoch 11, gen_loss = 0.3969990983605385, disc_loss = 0.09680858300998807
Trained batch 12 in epoch 11, gen_loss = 0.3936759898295769, disc_loss = 0.11180175998463081
Trained batch 13 in epoch 11, gen_loss = 0.3980736349310194, disc_loss = 0.10762031256620373
Trained batch 14 in epoch 11, gen_loss = 0.3933401902516683, disc_loss = 0.1057016013811032
Trained batch 15 in epoch 11, gen_loss = 0.3938362505286932, disc_loss = 0.10412763978820294
Trained batch 16 in epoch 11, gen_loss = 0.3919016701333663, disc_loss = 0.10121384208254955
Trained batch 17 in epoch 11, gen_loss = 0.3886677556567722, disc_loss = 0.09808795143746668
Trained batch 18 in epoch 11, gen_loss = 0.38637175685481023, disc_loss = 0.09693114057575401
Trained batch 19 in epoch 11, gen_loss = 0.3847830340266228, disc_loss = 0.09446606850251556
Trained batch 20 in epoch 11, gen_loss = 0.38810044668969657, disc_loss = 0.09117104077623003
Trained batch 21 in epoch 11, gen_loss = 0.3868766955353997, disc_loss = 0.09303203462199731
Trained batch 22 in epoch 11, gen_loss = 0.3896693963071574, disc_loss = 0.09261734103379042
Trained batch 23 in epoch 11, gen_loss = 0.3901643914481004, disc_loss = 0.09006255492568016
Trained batch 24 in epoch 11, gen_loss = 0.39131679058074953, disc_loss = 0.08981690883636474
Trained batch 25 in epoch 11, gen_loss = 0.3919822241251285, disc_loss = 0.0888005609695728
Trained batch 26 in epoch 11, gen_loss = 0.3929785158899095, disc_loss = 0.08773647800639824
Trained batch 27 in epoch 11, gen_loss = 0.3927247588123594, disc_loss = 0.08883499620216233
Trained batch 28 in epoch 11, gen_loss = 0.3929818108164031, disc_loss = 0.09243932417754469
Trained batch 29 in epoch 11, gen_loss = 0.39075688223044075, disc_loss = 0.09065098551412423
Trained batch 30 in epoch 11, gen_loss = 0.3902517076461546, disc_loss = 0.0885882413074855
Trained batch 31 in epoch 11, gen_loss = 0.3937070947140455, disc_loss = 0.08610975241754204
Trained batch 32 in epoch 11, gen_loss = 0.3939389261332425, disc_loss = 0.08469377627426927
Trained batch 33 in epoch 11, gen_loss = 0.3950541773263146, disc_loss = 0.08394727812093847
Trained batch 34 in epoch 11, gen_loss = 0.39267888580049787, disc_loss = 0.08549417470182691
Trained batch 35 in epoch 11, gen_loss = 0.3947026448117362, disc_loss = 0.08514531867371665
Trained batch 36 in epoch 11, gen_loss = 0.394369942110938, disc_loss = 0.0845298651303794
Trained batch 37 in epoch 11, gen_loss = 0.3952281553494303, disc_loss = 0.0829305368426599
Trained batch 38 in epoch 11, gen_loss = 0.3953116161701007, disc_loss = 0.0826860887882037
Trained batch 39 in epoch 11, gen_loss = 0.39258929565548895, disc_loss = 0.08152833878993988
Trained batch 40 in epoch 11, gen_loss = 0.39366080412050575, disc_loss = 0.0796952561770634
Trained batch 41 in epoch 11, gen_loss = 0.3926233911798114, disc_loss = 0.07836568144904006
Trained batch 42 in epoch 11, gen_loss = 0.39394865410272467, disc_loss = 0.07871949692191772
Trained batch 43 in epoch 11, gen_loss = 0.39365256848660385, disc_loss = 0.07840367036194286
Trained batch 44 in epoch 11, gen_loss = 0.3932020266850789, disc_loss = 0.07906428445130587
Trained batch 45 in epoch 11, gen_loss = 0.39263612226299616, disc_loss = 0.08167884014951794
Trained batch 46 in epoch 11, gen_loss = 0.39398260192668183, disc_loss = 0.08087191368116343
Trained batch 47 in epoch 11, gen_loss = 0.39274959079921246, disc_loss = 0.080123509610227
Trained batch 48 in epoch 11, gen_loss = 0.39295784794554417, disc_loss = 0.07918909376449122
Trained batch 49 in epoch 11, gen_loss = 0.3946740418672562, disc_loss = 0.08052364321425558
Trained batch 50 in epoch 11, gen_loss = 0.3935786953159407, disc_loss = 0.0831674279133771
Trained batch 51 in epoch 11, gen_loss = 0.3935317030319801, disc_loss = 0.0826189076133932
Trained batch 52 in epoch 11, gen_loss = 0.3934841757675387, disc_loss = 0.08191845209320199
Trained batch 53 in epoch 11, gen_loss = 0.3934492203924391, disc_loss = 0.08074218767729623
Trained batch 54 in epoch 11, gen_loss = 0.39308125051585113, disc_loss = 0.07994218165562912
Trained batch 55 in epoch 11, gen_loss = 0.39341287155236515, disc_loss = 0.07872047436623168
Trained batch 56 in epoch 11, gen_loss = 0.39482578687500536, disc_loss = 0.07754376143413155
Trained batch 57 in epoch 11, gen_loss = 0.39519751739913017, disc_loss = 0.07675541094343724
Trained batch 58 in epoch 11, gen_loss = 0.3949464574708777, disc_loss = 0.07560723533822318
Trained batch 59 in epoch 11, gen_loss = 0.39422646115223564, disc_loss = 0.0753623898451527
Trained batch 60 in epoch 11, gen_loss = 0.39473263601787756, disc_loss = 0.07596143219070356
Trained batch 61 in epoch 11, gen_loss = 0.39255640920131435, disc_loss = 0.07795641949820903
Trained batch 62 in epoch 11, gen_loss = 0.3927042990449875, disc_loss = 0.07823605309166605
Trained batch 63 in epoch 11, gen_loss = 0.3923565922304988, disc_loss = 0.07745857769623399
Trained batch 64 in epoch 11, gen_loss = 0.39236613191091096, disc_loss = 0.07815052018715785
Trained batch 65 in epoch 11, gen_loss = 0.3911266995198799, disc_loss = 0.07999286145874948
Trained batch 66 in epoch 11, gen_loss = 0.3919369476055031, disc_loss = 0.07908437756904915
Trained batch 67 in epoch 11, gen_loss = 0.39308369597967935, disc_loss = 0.07965647648362552
Trained batch 68 in epoch 11, gen_loss = 0.3921109282452127, disc_loss = 0.07955649365549503
Trained batch 69 in epoch 11, gen_loss = 0.3909896803753717, disc_loss = 0.07874180520219462
Trained batch 70 in epoch 11, gen_loss = 0.3914547470253958, disc_loss = 0.07803736970773045
Trained batch 71 in epoch 11, gen_loss = 0.39197542725337875, disc_loss = 0.07734060709157752
Trained batch 72 in epoch 11, gen_loss = 0.39188655639347963, disc_loss = 0.0766027575639421
Trained batch 73 in epoch 11, gen_loss = 0.39166161377687714, disc_loss = 0.07610432645054283
Trained batch 74 in epoch 11, gen_loss = 0.39341458598772683, disc_loss = 0.07611531399190426
Trained batch 75 in epoch 11, gen_loss = 0.39323037000078903, disc_loss = 0.07573360726727467
Trained batch 76 in epoch 11, gen_loss = 0.3942190122294736, disc_loss = 0.0757632576074306
Trained batch 77 in epoch 11, gen_loss = 0.3954677077440115, disc_loss = 0.07810174303654677
Trained batch 78 in epoch 11, gen_loss = 0.3956574774995635, disc_loss = 0.07724634000347762
Trained batch 79 in epoch 11, gen_loss = 0.3946371503174305, disc_loss = 0.07945500126807019
Trained batch 80 in epoch 11, gen_loss = 0.3951487143834432, disc_loss = 0.07940745922840303
Trained batch 81 in epoch 11, gen_loss = 0.3960451672716839, disc_loss = 0.07856846458801045
Trained batch 82 in epoch 11, gen_loss = 0.39693147733987094, disc_loss = 0.07779817343745606
Trained batch 83 in epoch 11, gen_loss = 0.397936853269736, disc_loss = 0.07771616054344035
Trained batch 84 in epoch 11, gen_loss = 0.3981053895810071, disc_loss = 0.07722440521944972
Trained batch 85 in epoch 11, gen_loss = 0.39822381111078486, disc_loss = 0.07792074426055648
Trained batch 86 in epoch 11, gen_loss = 0.3974324529883505, disc_loss = 0.08013306200589942
Trained batch 87 in epoch 11, gen_loss = 0.3983840427615426, disc_loss = 0.07956528159874407
Trained batch 88 in epoch 11, gen_loss = 0.3989967101075676, disc_loss = 0.0790525721281432
Trained batch 89 in epoch 11, gen_loss = 0.39777870741155413, disc_loss = 0.07833232867221038
Trained batch 90 in epoch 11, gen_loss = 0.397231298488575, disc_loss = 0.0783591121844538
Trained batch 91 in epoch 11, gen_loss = 0.3967119656179262, disc_loss = 0.0776885507385368
Trained batch 92 in epoch 11, gen_loss = 0.39725914885920866, disc_loss = 0.07912246618540056
Trained batch 93 in epoch 11, gen_loss = 0.39695735814723565, disc_loss = 0.07935013011732
Trained batch 94 in epoch 11, gen_loss = 0.39680116835393403, disc_loss = 0.07922401655661432
Trained batch 95 in epoch 11, gen_loss = 0.3968313193569581, disc_loss = 0.08185272982033591
Trained batch 96 in epoch 11, gen_loss = 0.39593271588541795, disc_loss = 0.08216358575317048
Trained batch 97 in epoch 11, gen_loss = 0.3958096659305144, disc_loss = 0.08150141439115514
Trained batch 98 in epoch 11, gen_loss = 0.39666362483092027, disc_loss = 0.08078914701073157
Trained batch 99 in epoch 11, gen_loss = 0.3960702443122864, disc_loss = 0.08027603638358415
Trained batch 100 in epoch 11, gen_loss = 0.3958958307705303, disc_loss = 0.07962262119618382
Trained batch 101 in epoch 11, gen_loss = 0.3953034033377965, disc_loss = 0.07941497246935672
Trained batch 102 in epoch 11, gen_loss = 0.3951643876080374, disc_loss = 0.07951875094288183
Trained batch 103 in epoch 11, gen_loss = 0.39431191264436793, disc_loss = 0.08008516169726275
Trained batch 104 in epoch 11, gen_loss = 0.39476422326905386, disc_loss = 0.07998793783287207
Trained batch 105 in epoch 11, gen_loss = 0.39509888302605106, disc_loss = 0.07940220224829216
Trained batch 106 in epoch 11, gen_loss = 0.3947405979455074, disc_loss = 0.07890535495896762
Trained batch 107 in epoch 11, gen_loss = 0.39493387054514, disc_loss = 0.07834854975549711
Trained batch 108 in epoch 11, gen_loss = 0.3945792585337928, disc_loss = 0.07778286727128225
Trained batch 109 in epoch 11, gen_loss = 0.39387495788660914, disc_loss = 0.0781250713731755
Trained batch 110 in epoch 11, gen_loss = 0.39297542915687905, disc_loss = 0.08033497871512228
Trained batch 111 in epoch 11, gen_loss = 0.3939137224640165, disc_loss = 0.08111253073106386
Trained batch 112 in epoch 11, gen_loss = 0.3939907563998636, disc_loss = 0.08149701434360669
Trained batch 113 in epoch 11, gen_loss = 0.39402217927731964, disc_loss = 0.08185632041606464
Trained batch 114 in epoch 11, gen_loss = 0.3942962755327639, disc_loss = 0.0824900069800408
Trained batch 115 in epoch 11, gen_loss = 0.39412994528638906, disc_loss = 0.08207278446583398
Trained batch 116 in epoch 11, gen_loss = 0.3941698769728343, disc_loss = 0.08181059753729238
Trained batch 117 in epoch 11, gen_loss = 0.3940773341110197, disc_loss = 0.0817301217624444
Trained batch 118 in epoch 11, gen_loss = 0.39456710770350545, disc_loss = 0.08206434659033764
Trained batch 119 in epoch 11, gen_loss = 0.3950269177556038, disc_loss = 0.08164366798785826
Trained batch 120 in epoch 11, gen_loss = 0.3943471598231103, disc_loss = 0.08152669451145594
Trained batch 121 in epoch 11, gen_loss = 0.39378007391437153, disc_loss = 0.08115011592563547
Trained batch 122 in epoch 11, gen_loss = 0.39349861212862214, disc_loss = 0.0806144244999178
Trained batch 123 in epoch 11, gen_loss = 0.39365292124209866, disc_loss = 0.08005469487679581
Trained batch 124 in epoch 11, gen_loss = 0.39411275219917297, disc_loss = 0.0797336971461773
Trained batch 125 in epoch 11, gen_loss = 0.39391221862936776, disc_loss = 0.07965033687651157
Trained batch 126 in epoch 11, gen_loss = 0.39427030086517334, disc_loss = 0.07944129240207785
Trained batch 127 in epoch 11, gen_loss = 0.39421108388341963, disc_loss = 0.07931172937969677
Trained batch 128 in epoch 11, gen_loss = 0.3941713858020398, disc_loss = 0.07896673956582713
Trained batch 129 in epoch 11, gen_loss = 0.3941916919671572, disc_loss = 0.07845374148768874
Trained batch 130 in epoch 11, gen_loss = 0.3939942694802321, disc_loss = 0.07797830981977341
Trained batch 131 in epoch 11, gen_loss = 0.39313627914948895, disc_loss = 0.07925366862169043
Trained batch 132 in epoch 11, gen_loss = 0.3934946118440843, disc_loss = 0.0830480169883012
Trained batch 133 in epoch 11, gen_loss = 0.3936931851194866, disc_loss = 0.0830498051746234
Trained batch 134 in epoch 11, gen_loss = 0.39328911745989764, disc_loss = 0.08377325256803521
Trained batch 135 in epoch 11, gen_loss = 0.393478649065775, disc_loss = 0.08349276715478696
Trained batch 136 in epoch 11, gen_loss = 0.39298641333614825, disc_loss = 0.0834325627376237
Trained batch 137 in epoch 11, gen_loss = 0.39322962471540424, disc_loss = 0.08301422313746551
Trained batch 138 in epoch 11, gen_loss = 0.3937879487764921, disc_loss = 0.0825300197713345
Trained batch 139 in epoch 11, gen_loss = 0.39336595705577304, disc_loss = 0.08202294944785535
Trained batch 140 in epoch 11, gen_loss = 0.39332883049410283, disc_loss = 0.08147579187804714
Trained batch 141 in epoch 11, gen_loss = 0.39364111696330595, disc_loss = 0.08109441771447448
Trained batch 142 in epoch 11, gen_loss = 0.39266418764641237, disc_loss = 0.0815269059690458
Trained batch 143 in epoch 11, gen_loss = 0.3927523533089293, disc_loss = 0.08200938290166152
Trained batch 144 in epoch 11, gen_loss = 0.3926495611667633, disc_loss = 0.08154751982796808
Trained batch 145 in epoch 11, gen_loss = 0.3927420939076437, disc_loss = 0.08112840034858618
Trained batch 146 in epoch 11, gen_loss = 0.39201108817340563, disc_loss = 0.08079303144065499
Trained batch 147 in epoch 11, gen_loss = 0.3920524047838675, disc_loss = 0.08044501580927219
Trained batch 148 in epoch 11, gen_loss = 0.3915198175299088, disc_loss = 0.08007475715630606
Trained batch 149 in epoch 11, gen_loss = 0.39126560966173807, disc_loss = 0.0797591309932371
Trained batch 150 in epoch 11, gen_loss = 0.39089620902838296, disc_loss = 0.07930107411638593
Trained batch 151 in epoch 11, gen_loss = 0.39063340837233945, disc_loss = 0.07951263511724967
Trained batch 152 in epoch 11, gen_loss = 0.39136724164283354, disc_loss = 0.08117660487472426
Trained batch 153 in epoch 11, gen_loss = 0.39172743841425167, disc_loss = 0.08236806885061132
Trained batch 154 in epoch 11, gen_loss = 0.3924595715538148, disc_loss = 0.08233812034971291
Trained batch 155 in epoch 11, gen_loss = 0.392649508248537, disc_loss = 0.08226786312074043
Trained batch 156 in epoch 11, gen_loss = 0.3920520208064158, disc_loss = 0.08321808750153917
Trained batch 157 in epoch 11, gen_loss = 0.3926232210065745, disc_loss = 0.08314952487125993
Trained batch 158 in epoch 11, gen_loss = 0.3929881479755138, disc_loss = 0.08321381840011421
Trained batch 159 in epoch 11, gen_loss = 0.39292750246822833, disc_loss = 0.08279376220307313
Trained batch 160 in epoch 11, gen_loss = 0.3926375919247266, disc_loss = 0.08291065798760015
Trained batch 161 in epoch 11, gen_loss = 0.39319468280415476, disc_loss = 0.08248869062941751
Trained batch 162 in epoch 11, gen_loss = 0.3928153353966087, disc_loss = 0.0822796491574656
Trained batch 163 in epoch 11, gen_loss = 0.39242870796744417, disc_loss = 0.08282069262208008
Trained batch 164 in epoch 11, gen_loss = 0.3928284643274365, disc_loss = 0.08325736531705567
Trained batch 165 in epoch 11, gen_loss = 0.39333251495677307, disc_loss = 0.08309078752904771
Trained batch 166 in epoch 11, gen_loss = 0.3931136689857095, disc_loss = 0.08285032429113359
Trained batch 167 in epoch 11, gen_loss = 0.39333509121622356, disc_loss = 0.08332071136239738
Trained batch 168 in epoch 11, gen_loss = 0.3931877195129733, disc_loss = 0.08312321339662258
Trained batch 169 in epoch 11, gen_loss = 0.392813163820435, disc_loss = 0.08294218296513838
Trained batch 170 in epoch 11, gen_loss = 0.39259750400370325, disc_loss = 0.0825859598205452
Trained batch 171 in epoch 11, gen_loss = 0.39235200940869575, disc_loss = 0.08233816991018694
Trained batch 172 in epoch 11, gen_loss = 0.3921713451774134, disc_loss = 0.08255015757214816
Trained batch 173 in epoch 11, gen_loss = 0.392761996936524, disc_loss = 0.08289436743348494
Trained batch 174 in epoch 11, gen_loss = 0.39307255608694897, disc_loss = 0.08262073508330754
Trained batch 175 in epoch 11, gen_loss = 0.3933579318902709, disc_loss = 0.08254650827835906
Trained batch 176 in epoch 11, gen_loss = 0.39349396518394775, disc_loss = 0.08223081065478635
Trained batch 177 in epoch 11, gen_loss = 0.39371580086397323, disc_loss = 0.08220861484872156
Trained batch 178 in epoch 11, gen_loss = 0.3934307278201567, disc_loss = 0.08332062467891077
Trained batch 179 in epoch 11, gen_loss = 0.3933121946122911, disc_loss = 0.08337264645637738
Trained batch 180 in epoch 11, gen_loss = 0.39358211551581956, disc_loss = 0.08311458805689166
Trained batch 181 in epoch 11, gen_loss = 0.39326657289332084, disc_loss = 0.08274288700668367
Trained batch 182 in epoch 11, gen_loss = 0.393032730439973, disc_loss = 0.08256956660112397
Trained batch 183 in epoch 11, gen_loss = 0.3931078606325647, disc_loss = 0.08234039641430844
Trained batch 184 in epoch 11, gen_loss = 0.39299390767071696, disc_loss = 0.08235812159003437
Trained batch 185 in epoch 11, gen_loss = 0.3931812124867593, disc_loss = 0.08232587323554101
Trained batch 186 in epoch 11, gen_loss = 0.39311804554679175, disc_loss = 0.08211580926881117
Trained batch 187 in epoch 11, gen_loss = 0.3929594637865716, disc_loss = 0.08190319195706794
Trained batch 188 in epoch 11, gen_loss = 0.39294276587546817, disc_loss = 0.08164911614681677
Trained batch 189 in epoch 11, gen_loss = 0.39307536278900346, disc_loss = 0.08227228926200615
Trained batch 190 in epoch 11, gen_loss = 0.39361620308216955, disc_loss = 0.08411557164959882
Trained batch 191 in epoch 11, gen_loss = 0.3937156793350975, disc_loss = 0.08402439098184307
Trained batch 192 in epoch 11, gen_loss = 0.3939832558594837, disc_loss = 0.08409223400558215
Trained batch 193 in epoch 11, gen_loss = 0.39398500016055155, disc_loss = 0.08408627063804067
Trained batch 194 in epoch 11, gen_loss = 0.39415677785873415, disc_loss = 0.08409676933899904
Trained batch 195 in epoch 11, gen_loss = 0.3939174514035789, disc_loss = 0.08380040086387676
Trained batch 196 in epoch 11, gen_loss = 0.3943769048313199, disc_loss = 0.08363286994851482
Trained batch 197 in epoch 11, gen_loss = 0.3941266086667475, disc_loss = 0.0840508917798147
Trained batch 198 in epoch 11, gen_loss = 0.39435547994608855, disc_loss = 0.08441613332822395
Trained batch 199 in epoch 11, gen_loss = 0.3945692919194698, disc_loss = 0.08422855741344393
Trained batch 200 in epoch 11, gen_loss = 0.39472864975976707, disc_loss = 0.0839033121178251
Trained batch 201 in epoch 11, gen_loss = 0.3949543363091969, disc_loss = 0.08362775969106963
Trained batch 202 in epoch 11, gen_loss = 0.3948400860349533, disc_loss = 0.08338413077401997
Trained batch 203 in epoch 11, gen_loss = 0.3946172827306916, disc_loss = 0.08332016353732814
Trained batch 204 in epoch 11, gen_loss = 0.3949828506969824, disc_loss = 0.08297840243705162
Trained batch 205 in epoch 11, gen_loss = 0.3950700318639718, disc_loss = 0.08271265297097344
Trained batch 206 in epoch 11, gen_loss = 0.3954690671773348, disc_loss = 0.08261039023004148
Trained batch 207 in epoch 11, gen_loss = 0.39518013324301976, disc_loss = 0.08337986467030042
Trained batch 208 in epoch 11, gen_loss = 0.39520193586509195, disc_loss = 0.08376055426057874
Trained batch 209 in epoch 11, gen_loss = 0.39529023936816626, disc_loss = 0.0834399949448804
Trained batch 210 in epoch 11, gen_loss = 0.3953105002217948, disc_loss = 0.08318941078426854
Trained batch 211 in epoch 11, gen_loss = 0.3949274133961156, disc_loss = 0.08291791171661385
Trained batch 212 in epoch 11, gen_loss = 0.3949878235378176, disc_loss = 0.0829973623042865
Trained batch 213 in epoch 11, gen_loss = 0.3951798653769716, disc_loss = 0.08351531255311359
Trained batch 214 in epoch 11, gen_loss = 0.3957603644493014, disc_loss = 0.08330743802754685
Trained batch 215 in epoch 11, gen_loss = 0.3953858459437335, disc_loss = 0.08325274431370888
Trained batch 216 in epoch 11, gen_loss = 0.39574029039128034, disc_loss = 0.08313519038551825
Trained batch 217 in epoch 11, gen_loss = 0.395924149713385, disc_loss = 0.08290549138253299
Trained batch 218 in epoch 11, gen_loss = 0.39635512042263327, disc_loss = 0.0826391069320579
Trained batch 219 in epoch 11, gen_loss = 0.39658544971184295, disc_loss = 0.08233735526234588
Trained batch 220 in epoch 11, gen_loss = 0.39674334585396953, disc_loss = 0.08205187085982227
Trained batch 221 in epoch 11, gen_loss = 0.396858856350452, disc_loss = 0.08181048974579384
Trained batch 222 in epoch 11, gen_loss = 0.39703828577503497, disc_loss = 0.08156270832408036
Trained batch 223 in epoch 11, gen_loss = 0.3965295014370765, disc_loss = 0.08141285059225213
Trained batch 224 in epoch 11, gen_loss = 0.3969737946987152, disc_loss = 0.08146001870019569
Trained batch 225 in epoch 11, gen_loss = 0.3966951784306923, disc_loss = 0.08172021365716262
Trained batch 226 in epoch 11, gen_loss = 0.39629177821365225, disc_loss = 0.08175458763582459
Trained batch 227 in epoch 11, gen_loss = 0.39645386434960783, disc_loss = 0.08144722992897425
Trained batch 228 in epoch 11, gen_loss = 0.396285077500031, disc_loss = 0.0813603526892295
Trained batch 229 in epoch 11, gen_loss = 0.39658024336980735, disc_loss = 0.08137736185656294
Trained batch 230 in epoch 11, gen_loss = 0.3962013872412892, disc_loss = 0.08115406562997536
Trained batch 231 in epoch 11, gen_loss = 0.3963205710310361, disc_loss = 0.08088141299607553
Trained batch 232 in epoch 11, gen_loss = 0.39636877690773664, disc_loss = 0.0806360498206618
Trained batch 233 in epoch 11, gen_loss = 0.3961952650903637, disc_loss = 0.08041665052326444
Trained batch 234 in epoch 11, gen_loss = 0.3961256590295345, disc_loss = 0.0806075223463964
Trained batch 235 in epoch 11, gen_loss = 0.3956069899565082, disc_loss = 0.08108751026329473
Trained batch 236 in epoch 11, gen_loss = 0.39587155487466963, disc_loss = 0.08183929128061493
Trained batch 237 in epoch 11, gen_loss = 0.395973607522099, disc_loss = 0.08160846980539065
Trained batch 238 in epoch 11, gen_loss = 0.3958905049946518, disc_loss = 0.08170851219881903
Trained batch 239 in epoch 11, gen_loss = 0.39599853157997134, disc_loss = 0.08164769665260489
Trained batch 240 in epoch 11, gen_loss = 0.39600793219700886, disc_loss = 0.0818587442612685
Trained batch 241 in epoch 11, gen_loss = 0.3964615908782344, disc_loss = 0.08177831334500643
Trained batch 242 in epoch 11, gen_loss = 0.39636530785403623, disc_loss = 0.08150498288848396
Trained batch 243 in epoch 11, gen_loss = 0.3961006163573656, disc_loss = 0.08135432947320162
Trained batch 244 in epoch 11, gen_loss = 0.39608095932979975, disc_loss = 0.08110312935421053
Trained batch 245 in epoch 11, gen_loss = 0.39595611987075185, disc_loss = 0.08092083503696614
Trained batch 246 in epoch 11, gen_loss = 0.3960034002659292, disc_loss = 0.08107487308728671
Trained batch 247 in epoch 11, gen_loss = 0.39564258052456763, disc_loss = 0.08176886422875067
Trained batch 248 in epoch 11, gen_loss = 0.39594866700440523, disc_loss = 0.0818842614189269
Trained batch 249 in epoch 11, gen_loss = 0.3958584510087967, disc_loss = 0.08160243993625045
Trained batch 250 in epoch 11, gen_loss = 0.3955376778703287, disc_loss = 0.0815399319074484
Trained batch 251 in epoch 11, gen_loss = 0.3957131567692, disc_loss = 0.08136198301208279
Trained batch 252 in epoch 11, gen_loss = 0.39563679353521747, disc_loss = 0.08118022832165477
Trained batch 253 in epoch 11, gen_loss = 0.39539585127605226, disc_loss = 0.08121521229393722
Trained batch 254 in epoch 11, gen_loss = 0.3952799003498227, disc_loss = 0.0811152804825528
Trained batch 255 in epoch 11, gen_loss = 0.3951297652674839, disc_loss = 0.08088897101333714
Trained batch 256 in epoch 11, gen_loss = 0.3949880705501319, disc_loss = 0.0808756109653222
Trained batch 257 in epoch 11, gen_loss = 0.39528323640657026, disc_loss = 0.080898374084441
Trained batch 258 in epoch 11, gen_loss = 0.3951629246063674, disc_loss = 0.08066439793650133
Trained batch 259 in epoch 11, gen_loss = 0.39494694700607885, disc_loss = 0.080575635137323
Trained batch 260 in epoch 11, gen_loss = 0.3948804450674532, disc_loss = 0.08062799597137618
Trained batch 261 in epoch 11, gen_loss = 0.3951688097178481, disc_loss = 0.08036965152732174
Trained batch 262 in epoch 11, gen_loss = 0.3951741758408202, disc_loss = 0.08017558479476225
Trained batch 263 in epoch 11, gen_loss = 0.39542299554203497, disc_loss = 0.08003577921243216
Trained batch 264 in epoch 11, gen_loss = 0.3954170936683439, disc_loss = 0.0801906827591219
Trained batch 265 in epoch 11, gen_loss = 0.39518566127110244, disc_loss = 0.08035035538872269
Trained batch 266 in epoch 11, gen_loss = 0.39547152621915727, disc_loss = 0.08058772267850485
Trained batch 267 in epoch 11, gen_loss = 0.39587152560255423, disc_loss = 0.08047780554060505
Trained batch 268 in epoch 11, gen_loss = 0.3955601819385826, disc_loss = 0.08085976201403872
Trained batch 269 in epoch 11, gen_loss = 0.39576306652139737, disc_loss = 0.08110944124766523
Trained batch 270 in epoch 11, gen_loss = 0.3959176891184381, disc_loss = 0.08087350447693105
Trained batch 271 in epoch 11, gen_loss = 0.39581738938303557, disc_loss = 0.08106089523404508
Trained batch 272 in epoch 11, gen_loss = 0.39585929737859593, disc_loss = 0.08125474871965227
Trained batch 273 in epoch 11, gen_loss = 0.39592159871202315, disc_loss = 0.08105723853868833
Trained batch 274 in epoch 11, gen_loss = 0.3961161809617823, disc_loss = 0.08089751196517185
Trained batch 275 in epoch 11, gen_loss = 0.39618297342372977, disc_loss = 0.08077030110955778
Trained batch 276 in epoch 11, gen_loss = 0.39584468999063926, disc_loss = 0.08128869512357113
Trained batch 277 in epoch 11, gen_loss = 0.3958003735370773, disc_loss = 0.08168794150738944
Trained batch 278 in epoch 11, gen_loss = 0.39569586248380734, disc_loss = 0.0815840313464777
Trained batch 279 in epoch 11, gen_loss = 0.39560796416231564, disc_loss = 0.08148244931029953
Trained batch 280 in epoch 11, gen_loss = 0.39540897548410814, disc_loss = 0.08138619847529405
Trained batch 281 in epoch 11, gen_loss = 0.3954585532770089, disc_loss = 0.08122843868885163
Trained batch 282 in epoch 11, gen_loss = 0.3953057964572637, disc_loss = 0.08106945052598159
Trained batch 283 in epoch 11, gen_loss = 0.3954001179253551, disc_loss = 0.08099373115528323
Trained batch 284 in epoch 11, gen_loss = 0.3952088542151869, disc_loss = 0.08148813493745892
Trained batch 285 in epoch 11, gen_loss = 0.3956245621601185, disc_loss = 0.08159027947112918
Trained batch 286 in epoch 11, gen_loss = 0.3957831535605188, disc_loss = 0.08140253624473195
Trained batch 287 in epoch 11, gen_loss = 0.39568332862108946, disc_loss = 0.08114288531133854
Trained batch 288 in epoch 11, gen_loss = 0.3959920269188996, disc_loss = 0.08090970912548652
Trained batch 289 in epoch 11, gen_loss = 0.39611673704509076, disc_loss = 0.08067210841570692
Trained batch 290 in epoch 11, gen_loss = 0.3959791205592991, disc_loss = 0.08047955398867067
Trained batch 291 in epoch 11, gen_loss = 0.3958848016719296, disc_loss = 0.08027252669873558
Trained batch 292 in epoch 11, gen_loss = 0.39616283479404124, disc_loss = 0.08019240296035751
Trained batch 293 in epoch 11, gen_loss = 0.3958928332645066, disc_loss = 0.08034064211616558
Trained batch 294 in epoch 11, gen_loss = 0.3959658751043223, disc_loss = 0.08057153888078311
Trained batch 295 in epoch 11, gen_loss = 0.3958621979565234, disc_loss = 0.08071289892541245
Trained batch 296 in epoch 11, gen_loss = 0.3958023050016024, disc_loss = 0.0804924742061557
Trained batch 297 in epoch 11, gen_loss = 0.39608083435353014, disc_loss = 0.08041141268909728
Trained batch 298 in epoch 11, gen_loss = 0.396086748228424, disc_loss = 0.08023096025332709
Trained batch 299 in epoch 11, gen_loss = 0.3959281080961227, disc_loss = 0.08004533811006695
Trained batch 300 in epoch 11, gen_loss = 0.39603927592898525, disc_loss = 0.07986305918748741
Trained batch 301 in epoch 11, gen_loss = 0.3957994087839758, disc_loss = 0.07963406452631565
Trained batch 302 in epoch 11, gen_loss = 0.39581962987141245, disc_loss = 0.0795484833287155
Trained batch 303 in epoch 11, gen_loss = 0.39577021253736394, disc_loss = 0.07953235113803346
Trained batch 304 in epoch 11, gen_loss = 0.396073151807316, disc_loss = 0.07993617506209211
Trained batch 305 in epoch 11, gen_loss = 0.3961806182378258, disc_loss = 0.07997710906803072
Trained batch 306 in epoch 11, gen_loss = 0.3961811984012492, disc_loss = 0.07986945602041745
Trained batch 307 in epoch 11, gen_loss = 0.39635964802333284, disc_loss = 0.07968536101723114
Trained batch 308 in epoch 11, gen_loss = 0.39615357761244174, disc_loss = 0.07950536208227277
Trained batch 309 in epoch 11, gen_loss = 0.396060239307342, disc_loss = 0.07940914027182566
Trained batch 310 in epoch 11, gen_loss = 0.39615260529364804, disc_loss = 0.07951993070740457
Trained batch 311 in epoch 11, gen_loss = 0.3961070163700825, disc_loss = 0.07960607643531731
Trained batch 312 in epoch 11, gen_loss = 0.3960499450231132, disc_loss = 0.07952484078616047
Trained batch 313 in epoch 11, gen_loss = 0.3960836566747374, disc_loss = 0.07934065940967838
Trained batch 314 in epoch 11, gen_loss = 0.3963333711737678, disc_loss = 0.07920495701717242
Trained batch 315 in epoch 11, gen_loss = 0.3962362701945667, disc_loss = 0.07914338301708096
Trained batch 316 in epoch 11, gen_loss = 0.39621233817906787, disc_loss = 0.0791197541692773
Trained batch 317 in epoch 11, gen_loss = 0.39648243353801704, disc_loss = 0.07895250528986396
Trained batch 318 in epoch 11, gen_loss = 0.3961946300017796, disc_loss = 0.0794250774489231
Trained batch 319 in epoch 11, gen_loss = 0.3963638414628804, disc_loss = 0.07959092901583062
Trained batch 320 in epoch 11, gen_loss = 0.3963002783487148, disc_loss = 0.07942415653899126
Trained batch 321 in epoch 11, gen_loss = 0.3961449614407853, disc_loss = 0.07943186796305018
Trained batch 322 in epoch 11, gen_loss = 0.3962932004832631, disc_loss = 0.07931544959989172
Trained batch 323 in epoch 11, gen_loss = 0.3961981394224697, disc_loss = 0.07915467930595493
Trained batch 324 in epoch 11, gen_loss = 0.3958999045078571, disc_loss = 0.07903875021550517
Trained batch 325 in epoch 11, gen_loss = 0.3962305248515006, disc_loss = 0.079021059646574
Trained batch 326 in epoch 11, gen_loss = 0.39631150594545067, disc_loss = 0.07882483909761004
Trained batch 327 in epoch 11, gen_loss = 0.3964477115106292, disc_loss = 0.07865978719058969
Trained batch 328 in epoch 11, gen_loss = 0.3964088074523265, disc_loss = 0.07855498415522708
Trained batch 329 in epoch 11, gen_loss = 0.3963120569785436, disc_loss = 0.07858527691780844
Trained batch 330 in epoch 11, gen_loss = 0.39607681131434946, disc_loss = 0.0786273902932075
Trained batch 331 in epoch 11, gen_loss = 0.39609667075326643, disc_loss = 0.07855217242529279
Trained batch 332 in epoch 11, gen_loss = 0.3961411560619916, disc_loss = 0.07840278529486544
Trained batch 333 in epoch 11, gen_loss = 0.3958223808311417, disc_loss = 0.07828189318436393
Trained batch 334 in epoch 11, gen_loss = 0.39613647229635895, disc_loss = 0.07861910508667577
Trained batch 335 in epoch 11, gen_loss = 0.39606316786791596, disc_loss = 0.07855179894388475
Trained batch 336 in epoch 11, gen_loss = 0.39595528738435015, disc_loss = 0.07858886306232134
Trained batch 337 in epoch 11, gen_loss = 0.39627076271017625, disc_loss = 0.07873975317622121
Trained batch 338 in epoch 11, gen_loss = 0.3962355545312606, disc_loss = 0.07854529511551633
Trained batch 339 in epoch 11, gen_loss = 0.3963350274983574, disc_loss = 0.07834106199032463
Trained batch 340 in epoch 11, gen_loss = 0.39632452775306365, disc_loss = 0.07838256558392448
Trained batch 341 in epoch 11, gen_loss = 0.39645413261407997, disc_loss = 0.07885300504909665
Trained batch 342 in epoch 11, gen_loss = 0.39636646432709766, disc_loss = 0.07910648059594083
Trained batch 343 in epoch 11, gen_loss = 0.3964645748221597, disc_loss = 0.0790229564015537
Trained batch 344 in epoch 11, gen_loss = 0.3966139964435412, disc_loss = 0.07881963737443953
Trained batch 345 in epoch 11, gen_loss = 0.39662745121241993, disc_loss = 0.07863522648967458
Trained batch 346 in epoch 11, gen_loss = 0.39649909751903084, disc_loss = 0.07843099445539395
Trained batch 347 in epoch 11, gen_loss = 0.39643131727459785, disc_loss = 0.07823799319977433
Trained batch 348 in epoch 11, gen_loss = 0.39648313354967657, disc_loss = 0.07805241223953045
Trained batch 349 in epoch 11, gen_loss = 0.39642651098115106, disc_loss = 0.07784814142355961
Trained batch 350 in epoch 11, gen_loss = 0.3966064668788529, disc_loss = 0.07767831862232837
Trained batch 351 in epoch 11, gen_loss = 0.39646297286857257, disc_loss = 0.07754784472291992
Trained batch 352 in epoch 11, gen_loss = 0.39633339609708057, disc_loss = 0.07778089657220093
Trained batch 353 in epoch 11, gen_loss = 0.3960709540689059, disc_loss = 0.07799144528180066
Trained batch 354 in epoch 11, gen_loss = 0.3959748408324282, disc_loss = 0.07784705705757082
Trained batch 355 in epoch 11, gen_loss = 0.3961914699901356, disc_loss = 0.07786102111718167
Trained batch 356 in epoch 11, gen_loss = 0.3961532509961382, disc_loss = 0.07784211986335594
Trained batch 357 in epoch 11, gen_loss = 0.3963774147146907, disc_loss = 0.07768849730517653
Trained batch 358 in epoch 11, gen_loss = 0.39637860249011964, disc_loss = 0.07759254404621245
Trained batch 359 in epoch 11, gen_loss = 0.39629456566439736, disc_loss = 0.07756344808084477
Trained batch 360 in epoch 11, gen_loss = 0.3963719339747178, disc_loss = 0.07760634173837766
Trained batch 361 in epoch 11, gen_loss = 0.39636448001005375, disc_loss = 0.07838976841795552
Trained batch 362 in epoch 11, gen_loss = 0.39671104514237604, disc_loss = 0.07833036765605006
Trained batch 363 in epoch 11, gen_loss = 0.3967061976973827, disc_loss = 0.07831512026841865
Trained batch 364 in epoch 11, gen_loss = 0.39652497049880353, disc_loss = 0.0781918602714902
Trained batch 365 in epoch 11, gen_loss = 0.39660129024357094, disc_loss = 0.07807413932022542
Trained batch 366 in epoch 11, gen_loss = 0.396773263609052, disc_loss = 0.07791573065650276
Trained batch 367 in epoch 11, gen_loss = 0.39692774285440857, disc_loss = 0.07774788663727636
Trained batch 368 in epoch 11, gen_loss = 0.39676923076634807, disc_loss = 0.07771676540662481
Trained batch 369 in epoch 11, gen_loss = 0.3968249528794675, disc_loss = 0.07754034516905006
Trained batch 370 in epoch 11, gen_loss = 0.3965090951829586, disc_loss = 0.07745558199299514
Trained batch 371 in epoch 11, gen_loss = 0.39654573726077236, disc_loss = 0.07728503343163519
Trained batch 372 in epoch 11, gen_loss = 0.3965369540468937, disc_loss = 0.07721973690091964
Trained batch 373 in epoch 11, gen_loss = 0.3960461343593776, disc_loss = 0.07741377106369697
Trained batch 374 in epoch 11, gen_loss = 0.39606210895379385, disc_loss = 0.07810535174732407
Trained batch 375 in epoch 11, gen_loss = 0.3960246761983379, disc_loss = 0.07812707502756545
Trained batch 376 in epoch 11, gen_loss = 0.3958525944214601, disc_loss = 0.07830884289959895
Trained batch 377 in epoch 11, gen_loss = 0.3958686161687765, disc_loss = 0.07856476728843831
Trained batch 378 in epoch 11, gen_loss = 0.3959852970920326, disc_loss = 0.07851618923625286
Trained batch 379 in epoch 11, gen_loss = 0.39565445000403804, disc_loss = 0.0788417412470536
Trained batch 380 in epoch 11, gen_loss = 0.39572438257416404, disc_loss = 0.07866642766038147
Trained batch 381 in epoch 11, gen_loss = 0.3958992878101883, disc_loss = 0.07879318467692438
Trained batch 382 in epoch 11, gen_loss = 0.39587355597679047, disc_loss = 0.07864719443144787
Trained batch 383 in epoch 11, gen_loss = 0.3955936225053544, disc_loss = 0.07892439976785681
Trained batch 384 in epoch 11, gen_loss = 0.3955700538762204, disc_loss = 0.07875195463587131
Trained batch 385 in epoch 11, gen_loss = 0.39557629016860163, disc_loss = 0.07888487881469333
Trained batch 386 in epoch 11, gen_loss = 0.39550746561482897, disc_loss = 0.07871425774752208
Trained batch 387 in epoch 11, gen_loss = 0.3955277501384622, disc_loss = 0.07903642782619819
Trained batch 388 in epoch 11, gen_loss = 0.39568846686180575, disc_loss = 0.07939200359097369
Trained batch 389 in epoch 11, gen_loss = 0.395448268032991, disc_loss = 0.07929747233716532
Trained batch 390 in epoch 11, gen_loss = 0.3954904413665347, disc_loss = 0.07927195048626617
Trained batch 391 in epoch 11, gen_loss = 0.39553440571287457, disc_loss = 0.07914934623915208
Trained batch 392 in epoch 11, gen_loss = 0.39556363274274586, disc_loss = 0.07909921567256707
Trained batch 393 in epoch 11, gen_loss = 0.3954886146986545, disc_loss = 0.07903066375954691
Trained batch 394 in epoch 11, gen_loss = 0.3953361289787896, disc_loss = 0.07894360674073612
Trained batch 395 in epoch 11, gen_loss = 0.3953449428457804, disc_loss = 0.07881360058555135
Trained batch 396 in epoch 11, gen_loss = 0.39531370723427695, disc_loss = 0.07876247658936181
Trained batch 397 in epoch 11, gen_loss = 0.3951580005899147, disc_loss = 0.07887467810879438
Trained batch 398 in epoch 11, gen_loss = 0.39550772761193137, disc_loss = 0.07957581508750643
Trained batch 399 in epoch 11, gen_loss = 0.39551421608775855, disc_loss = 0.07953741876059212
Trained batch 400 in epoch 11, gen_loss = 0.39546188975956076, disc_loss = 0.07948795384251306
Trained batch 401 in epoch 11, gen_loss = 0.39567218465146736, disc_loss = 0.0794932242096008
Trained batch 402 in epoch 11, gen_loss = 0.3955586266059142, disc_loss = 0.07937455522682213
Trained batch 403 in epoch 11, gen_loss = 0.3956103940485137, disc_loss = 0.07928436338592616
Trained batch 404 in epoch 11, gen_loss = 0.3955717413145819, disc_loss = 0.07912611541809675
Trained batch 405 in epoch 11, gen_loss = 0.3955644666047519, disc_loss = 0.07901675123698422
Trained batch 406 in epoch 11, gen_loss = 0.39554663617575786, disc_loss = 0.07938985231719198
Trained batch 407 in epoch 11, gen_loss = 0.3954369692752759, disc_loss = 0.07982410397266458
Trained batch 408 in epoch 11, gen_loss = 0.3953314467645216, disc_loss = 0.07971267381109169
Trained batch 409 in epoch 11, gen_loss = 0.3955420945112298, disc_loss = 0.07960944589023002
Trained batch 410 in epoch 11, gen_loss = 0.39559430322652894, disc_loss = 0.0794439172075377
Trained batch 411 in epoch 11, gen_loss = 0.39544751455338256, disc_loss = 0.0795143659179126
Trained batch 412 in epoch 11, gen_loss = 0.39539996204451267, disc_loss = 0.07975565963571318
Trained batch 413 in epoch 11, gen_loss = 0.3950862975584136, disc_loss = 0.08003374436028877
Trained batch 414 in epoch 11, gen_loss = 0.3950714409710413, disc_loss = 0.07995926615142498
Trained batch 415 in epoch 11, gen_loss = 0.3950750100283095, disc_loss = 0.079996933331131
Trained batch 416 in epoch 11, gen_loss = 0.39484444428547966, disc_loss = 0.08045752002908993
Trained batch 417 in epoch 11, gen_loss = 0.39476041021672165, disc_loss = 0.08038019641462946
Trained batch 418 in epoch 11, gen_loss = 0.3947906212121035, disc_loss = 0.08040205059741981
Trained batch 419 in epoch 11, gen_loss = 0.3947022693852584, disc_loss = 0.08049423770335991
Trained batch 420 in epoch 11, gen_loss = 0.3947765229362773, disc_loss = 0.08049347164383658
Trained batch 421 in epoch 11, gen_loss = 0.3948481037365317, disc_loss = 0.0804241617547869
Trained batch 422 in epoch 11, gen_loss = 0.394891527421931, disc_loss = 0.08041448314645576
Trained batch 423 in epoch 11, gen_loss = 0.39509830620350705, disc_loss = 0.0804804478769788
Trained batch 424 in epoch 11, gen_loss = 0.3947545677072862, disc_loss = 0.08142475180218325
Trained batch 425 in epoch 11, gen_loss = 0.39458836055417573, disc_loss = 0.08154014410000697
Trained batch 426 in epoch 11, gen_loss = 0.39446944773057585, disc_loss = 0.08148685775902254
Trained batch 427 in epoch 11, gen_loss = 0.3941769066536538, disc_loss = 0.08172692241316888
Trained batch 428 in epoch 11, gen_loss = 0.3942741961468072, disc_loss = 0.08208895599174298
Trained batch 429 in epoch 11, gen_loss = 0.3941690860099571, disc_loss = 0.08209041954278079
Trained batch 430 in epoch 11, gen_loss = 0.3942475238698265, disc_loss = 0.08192149642098634
Trained batch 431 in epoch 11, gen_loss = 0.3943688721154575, disc_loss = 0.08176788297822457
Trained batch 432 in epoch 11, gen_loss = 0.3943277135594612, disc_loss = 0.08166442345075017
Trained batch 433 in epoch 11, gen_loss = 0.39422119886095075, disc_loss = 0.08212741541521718
Trained batch 434 in epoch 11, gen_loss = 0.3942382230155769, disc_loss = 0.08226689256021175
Trained batch 435 in epoch 11, gen_loss = 0.3942882842427, disc_loss = 0.08219641182943324
Trained batch 436 in epoch 11, gen_loss = 0.3942554833141563, disc_loss = 0.08215478938008984
Trained batch 437 in epoch 11, gen_loss = 0.39431816080933835, disc_loss = 0.08200695177170206
Trained batch 438 in epoch 11, gen_loss = 0.3943064351288224, disc_loss = 0.08191226317880332
Trained batch 439 in epoch 11, gen_loss = 0.3943174263970418, disc_loss = 0.0818643918970007
Trained batch 440 in epoch 11, gen_loss = 0.39411348070687446, disc_loss = 0.0818238223421381
Trained batch 441 in epoch 11, gen_loss = 0.3940375009678068, disc_loss = 0.08173192330695082
Trained batch 442 in epoch 11, gen_loss = 0.39400535236632045, disc_loss = 0.08168916260764743
Trained batch 443 in epoch 11, gen_loss = 0.394041884656962, disc_loss = 0.08192795308134812
Trained batch 444 in epoch 11, gen_loss = 0.3940137920084964, disc_loss = 0.08245325665607044
Trained batch 445 in epoch 11, gen_loss = 0.3941422877958537, disc_loss = 0.08255010089344207
Trained batch 446 in epoch 11, gen_loss = 0.39404574236613793, disc_loss = 0.08246583997749075
Trained batch 447 in epoch 11, gen_loss = 0.39387743707214085, disc_loss = 0.0824605353024838
Trained batch 448 in epoch 11, gen_loss = 0.39406785680881323, disc_loss = 0.08229786013346373
Trained batch 449 in epoch 11, gen_loss = 0.39408196555243596, disc_loss = 0.08214927999820146
Trained batch 450 in epoch 11, gen_loss = 0.39399098292686985, disc_loss = 0.0820569880089894
Trained batch 451 in epoch 11, gen_loss = 0.3939890448762252, disc_loss = 0.08193900004602078
Trained batch 452 in epoch 11, gen_loss = 0.3939982387535356, disc_loss = 0.08205425078419364
Trained batch 453 in epoch 11, gen_loss = 0.3939925080353993, disc_loss = 0.08221300491460061
Trained batch 454 in epoch 11, gen_loss = 0.39400491937176213, disc_loss = 0.08205277055686155
Trained batch 455 in epoch 11, gen_loss = 0.3941466476310763, disc_loss = 0.08205667584664761
Trained batch 456 in epoch 11, gen_loss = 0.39407727291860517, disc_loss = 0.08218565539719794
Trained batch 457 in epoch 11, gen_loss = 0.39419472790180854, disc_loss = 0.08204415320687192
Trained batch 458 in epoch 11, gen_loss = 0.3944232023619359, disc_loss = 0.08205754945078998
Trained batch 459 in epoch 11, gen_loss = 0.39447061225124025, disc_loss = 0.08195131020721697
Trained batch 460 in epoch 11, gen_loss = 0.3942267676237607, disc_loss = 0.08201933196097322
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.41261613368988037, disc_loss = 0.15059857070446014
Trained batch 1 in epoch 12, gen_loss = 0.41378486156463623, disc_loss = 0.11187601834535599
Trained batch 2 in epoch 12, gen_loss = 0.4209366838137309, disc_loss = 0.11519355326890945
Trained batch 3 in epoch 12, gen_loss = 0.3947945386171341, disc_loss = 0.10999381728470325
Trained batch 4 in epoch 12, gen_loss = 0.42305052280426025, disc_loss = 0.17475996762514115
Trained batch 5 in epoch 12, gen_loss = 0.41719678044319153, disc_loss = 0.14921867909530798
Trained batch 6 in epoch 12, gen_loss = 0.3928853379828589, disc_loss = 0.14705803617835045
Trained batch 7 in epoch 12, gen_loss = 0.39087546057999134, disc_loss = 0.13738292129710317
Trained batch 8 in epoch 12, gen_loss = 0.39028026825851864, disc_loss = 0.12303015093008678
Trained batch 9 in epoch 12, gen_loss = 0.3864942565560341, disc_loss = 0.11386891640722752
Trained batch 10 in epoch 12, gen_loss = 0.385368830778382, disc_loss = 0.10553408685055646
Trained batch 11 in epoch 12, gen_loss = 0.3777337682743867, disc_loss = 0.09898115741088986
Trained batch 12 in epoch 12, gen_loss = 0.37852945350683653, disc_loss = 0.0924595954039922
Trained batch 13 in epoch 12, gen_loss = 0.38335677662066053, disc_loss = 0.0886202926880547
Trained batch 14 in epoch 12, gen_loss = 0.3811396509408951, disc_loss = 0.0974685891220967
Trained batch 15 in epoch 12, gen_loss = 0.3850257759913802, disc_loss = 0.1191314741736278
Trained batch 16 in epoch 12, gen_loss = 0.38871965075240417, disc_loss = 0.11533657012178618
Trained batch 17 in epoch 12, gen_loss = 0.38378814773427117, disc_loss = 0.11984061398026016
Trained batch 18 in epoch 12, gen_loss = 0.3796851219315278, disc_loss = 0.11906669122215949
Trained batch 19 in epoch 12, gen_loss = 0.3866595022380352, disc_loss = 0.11413555731996894
Trained batch 20 in epoch 12, gen_loss = 0.38214488327503204, disc_loss = 0.11144266818605718
Trained batch 21 in epoch 12, gen_loss = 0.38212285597216, disc_loss = 0.10755977534096349
Trained batch 22 in epoch 12, gen_loss = 0.38512639701366425, disc_loss = 0.10495019291082154
Trained batch 23 in epoch 12, gen_loss = 0.3841984861840804, disc_loss = 0.10254708436938624
Trained batch 24 in epoch 12, gen_loss = 0.3819860941171646, disc_loss = 0.09993558056652546
Trained batch 25 in epoch 12, gen_loss = 0.37973529960100466, disc_loss = 0.09675065356378372
Trained batch 26 in epoch 12, gen_loss = 0.37829901388397924, disc_loss = 0.09390089902336951
Trained batch 27 in epoch 12, gen_loss = 0.3795967735350132, disc_loss = 0.09259300539270043
Trained batch 28 in epoch 12, gen_loss = 0.38112855728330286, disc_loss = 0.08981670452089145
Trained batch 29 in epoch 12, gen_loss = 0.38060176024834314, disc_loss = 0.09228226455549399
Trained batch 30 in epoch 12, gen_loss = 0.3830387001076052, disc_loss = 0.09632435404965954
Trained batch 31 in epoch 12, gen_loss = 0.3839793340303004, disc_loss = 0.0939232490491122
Trained batch 32 in epoch 12, gen_loss = 0.3845904455943541, disc_loss = 0.09179924033356435
Trained batch 33 in epoch 12, gen_loss = 0.38612380229374943, disc_loss = 0.08939688378835425
Trained batch 34 in epoch 12, gen_loss = 0.38520052220140183, disc_loss = 0.09012331717780658
Trained batch 35 in epoch 12, gen_loss = 0.381834141496155, disc_loss = 0.09669118881639507
Trained batch 36 in epoch 12, gen_loss = 0.3832547604232221, disc_loss = 0.09950781563246572
Trained batch 37 in epoch 12, gen_loss = 0.38174826416530105, disc_loss = 0.09856844252269518
Trained batch 38 in epoch 12, gen_loss = 0.3803338756163915, disc_loss = 0.09713013823597859
Trained batch 39 in epoch 12, gen_loss = 0.3812780547887087, disc_loss = 0.09565319009125232
Trained batch 40 in epoch 12, gen_loss = 0.3835206740513081, disc_loss = 0.09571947048350078
Trained batch 41 in epoch 12, gen_loss = 0.3823793647544725, disc_loss = 0.09645086243039086
Trained batch 42 in epoch 12, gen_loss = 0.38378328466138173, disc_loss = 0.09583857239678849
Trained batch 43 in epoch 12, gen_loss = 0.38422780246897176, disc_loss = 0.09439684687690302
Trained batch 44 in epoch 12, gen_loss = 0.3846090591616101, disc_loss = 0.0934290885925293
Trained batch 45 in epoch 12, gen_loss = 0.38465361588675046, disc_loss = 0.09322583124689433
Trained batch 46 in epoch 12, gen_loss = 0.38495806715589886, disc_loss = 0.09215973444441532
Trained batch 47 in epoch 12, gen_loss = 0.3850842096532385, disc_loss = 0.09063818926612537
Trained batch 48 in epoch 12, gen_loss = 0.38592012044118373, disc_loss = 0.08915864459562059
Trained batch 49 in epoch 12, gen_loss = 0.3859672001004219, disc_loss = 0.08763533344492316
Trained batch 50 in epoch 12, gen_loss = 0.3854425564116123, disc_loss = 0.08659962730883967
Trained batch 51 in epoch 12, gen_loss = 0.3872978701614417, disc_loss = 0.08594416832336439
Trained batch 52 in epoch 12, gen_loss = 0.38663042744375625, disc_loss = 0.085148911202713
Trained batch 53 in epoch 12, gen_loss = 0.38605212916930515, disc_loss = 0.08607957517314288
Trained batch 54 in epoch 12, gen_loss = 0.387343137643554, disc_loss = 0.08559737847271291
Trained batch 55 in epoch 12, gen_loss = 0.3876785718436752, disc_loss = 0.08423839970159211
Trained batch 56 in epoch 12, gen_loss = 0.38780517039591805, disc_loss = 0.08336380236831151
Trained batch 57 in epoch 12, gen_loss = 0.38780650419407875, disc_loss = 0.08220394166057994
Trained batch 58 in epoch 12, gen_loss = 0.38714729047427743, disc_loss = 0.08140620114123923
Trained batch 59 in epoch 12, gen_loss = 0.3872049771249294, disc_loss = 0.08100426555611193
Trained batch 60 in epoch 12, gen_loss = 0.38645986626382733, disc_loss = 0.08068229861129991
Trained batch 61 in epoch 12, gen_loss = 0.388030175960833, disc_loss = 0.08020402213198043
Trained batch 62 in epoch 12, gen_loss = 0.3880722387915566, disc_loss = 0.07941960985402739
Trained batch 63 in epoch 12, gen_loss = 0.3882641608361155, disc_loss = 0.0784094213595381
Trained batch 64 in epoch 12, gen_loss = 0.38885885041493634, disc_loss = 0.07749888388296733
Trained batch 65 in epoch 12, gen_loss = 0.3884957705934842, disc_loss = 0.07694503807490974
Trained batch 66 in epoch 12, gen_loss = 0.3878591747871086, disc_loss = 0.07633042509264465
Trained batch 67 in epoch 12, gen_loss = 0.38843246352146654, disc_loss = 0.07564162943676553
Trained batch 68 in epoch 12, gen_loss = 0.3903065032285193, disc_loss = 0.07517795727682719
Trained batch 69 in epoch 12, gen_loss = 0.390855202291693, disc_loss = 0.07424563410292778
Trained batch 70 in epoch 12, gen_loss = 0.390113749764335, disc_loss = 0.07436246337028037
Trained batch 71 in epoch 12, gen_loss = 0.39101327479713494, disc_loss = 0.07493685668386105
Trained batch 72 in epoch 12, gen_loss = 0.39154224750930317, disc_loss = 0.07404692538643945
Trained batch 73 in epoch 12, gen_loss = 0.3920317185488907, disc_loss = 0.07375106730221494
Trained batch 74 in epoch 12, gen_loss = 0.39299120803674065, disc_loss = 0.07308516704787811
Trained batch 75 in epoch 12, gen_loss = 0.392351950273702, disc_loss = 0.07268685792376728
Trained batch 76 in epoch 12, gen_loss = 0.3930561888914604, disc_loss = 0.0719259896908294
Trained batch 77 in epoch 12, gen_loss = 0.393468205172282, disc_loss = 0.07157204881644784
Trained batch 78 in epoch 12, gen_loss = 0.39367690361753294, disc_loss = 0.07094798018990815
Trained batch 79 in epoch 12, gen_loss = 0.3937666555866599, disc_loss = 0.07023883648216725
Trained batch 80 in epoch 12, gen_loss = 0.3948047891443158, disc_loss = 0.06965280220740372
Trained batch 81 in epoch 12, gen_loss = 0.3952398839883688, disc_loss = 0.0689510445610234
Trained batch 82 in epoch 12, gen_loss = 0.39549181421837176, disc_loss = 0.0686549988788474
Trained batch 83 in epoch 12, gen_loss = 0.39599912170143353, disc_loss = 0.06901864220743023
Trained batch 84 in epoch 12, gen_loss = 0.3968451817246044, disc_loss = 0.06865403548102168
Trained batch 85 in epoch 12, gen_loss = 0.39728145318668945, disc_loss = 0.06854709091617964
Trained batch 86 in epoch 12, gen_loss = 0.3969248439046158, disc_loss = 0.06805940138325951
Trained batch 87 in epoch 12, gen_loss = 0.3974450161172585, disc_loss = 0.06768276046072556
Trained batch 88 in epoch 12, gen_loss = 0.39729581204023257, disc_loss = 0.06707637467201841
Trained batch 89 in epoch 12, gen_loss = 0.3976788356900215, disc_loss = 0.06674495868177878
Trained batch 90 in epoch 12, gen_loss = 0.39774974640254135, disc_loss = 0.06617464309374055
Trained batch 91 in epoch 12, gen_loss = 0.39801962268741237, disc_loss = 0.06552614498397578
Trained batch 92 in epoch 12, gen_loss = 0.39711481188574144, disc_loss = 0.06528543885196408
Trained batch 93 in epoch 12, gen_loss = 0.39735050959155915, disc_loss = 0.06564501613537048
Trained batch 94 in epoch 12, gen_loss = 0.39684233587039147, disc_loss = 0.06515018241970162
Trained batch 95 in epoch 12, gen_loss = 0.3958809939213097, disc_loss = 0.06637538837579389
Trained batch 96 in epoch 12, gen_loss = 0.3972637117216268, disc_loss = 0.06610646444497649
Trained batch 97 in epoch 12, gen_loss = 0.39728285022536103, disc_loss = 0.06682209488080472
Trained batch 98 in epoch 12, gen_loss = 0.3966163858921841, disc_loss = 0.06835755615523367
Trained batch 99 in epoch 12, gen_loss = 0.3963824801146984, disc_loss = 0.06806399028748274
Trained batch 100 in epoch 12, gen_loss = 0.3966569952150383, disc_loss = 0.06784802310094976
Trained batch 101 in epoch 12, gen_loss = 0.39603998015324277, disc_loss = 0.06750041702944859
Trained batch 102 in epoch 12, gen_loss = 0.39588879887918826, disc_loss = 0.06763515661208375
Trained batch 103 in epoch 12, gen_loss = 0.3966966258505216, disc_loss = 0.06871347075614792
Trained batch 104 in epoch 12, gen_loss = 0.39661361816383545, disc_loss = 0.06961581653782299
Trained batch 105 in epoch 12, gen_loss = 0.39690657002183627, disc_loss = 0.06924209355394233
Trained batch 106 in epoch 12, gen_loss = 0.3975619229479371, disc_loss = 0.0696106908721066
Trained batch 107 in epoch 12, gen_loss = 0.39726625231129153, disc_loss = 0.06950295369865166
Trained batch 108 in epoch 12, gen_loss = 0.3971423617470155, disc_loss = 0.06954828798429134
Trained batch 109 in epoch 12, gen_loss = 0.3984491674737497, disc_loss = 0.07038978167216886
Trained batch 110 in epoch 12, gen_loss = 0.3987100302904576, disc_loss = 0.07030732411186437
Trained batch 111 in epoch 12, gen_loss = 0.3991420959521617, disc_loss = 0.06988725159317255
Trained batch 112 in epoch 12, gen_loss = 0.3989337786900259, disc_loss = 0.06946313501525242
Trained batch 113 in epoch 12, gen_loss = 0.3995755344890712, disc_loss = 0.06910151805271182
Trained batch 114 in epoch 12, gen_loss = 0.3987558407628018, disc_loss = 0.06905857337557751
Trained batch 115 in epoch 12, gen_loss = 0.3987496791985528, disc_loss = 0.06977671513269687
Trained batch 116 in epoch 12, gen_loss = 0.3977816139276211, disc_loss = 0.07051332498717512
Trained batch 117 in epoch 12, gen_loss = 0.3977847224322416, disc_loss = 0.07024789873068615
Trained batch 118 in epoch 12, gen_loss = 0.3979242515413701, disc_loss = 0.06976048404961324
Trained batch 119 in epoch 12, gen_loss = 0.39751995044449967, disc_loss = 0.06947205561057974
Trained batch 120 in epoch 12, gen_loss = 0.3971939918177187, disc_loss = 0.06916138447420903
Trained batch 121 in epoch 12, gen_loss = 0.3973505165977556, disc_loss = 0.06895209122907187
Trained batch 122 in epoch 12, gen_loss = 0.39672388839043254, disc_loss = 0.06910307263970618
Trained batch 123 in epoch 12, gen_loss = 0.3969451279169129, disc_loss = 0.07001332104236128
Trained batch 124 in epoch 12, gen_loss = 0.3963271709680557, disc_loss = 0.07077080566436052
Trained batch 125 in epoch 12, gen_loss = 0.39658923269737334, disc_loss = 0.07066522373832644
Trained batch 126 in epoch 12, gen_loss = 0.3968747604315675, disc_loss = 0.0702735490906309
Trained batch 127 in epoch 12, gen_loss = 0.3972331889672205, disc_loss = 0.06981793580780504
Trained batch 128 in epoch 12, gen_loss = 0.39680220094300056, disc_loss = 0.06946196862633607
Trained batch 129 in epoch 12, gen_loss = 0.39696720299812466, disc_loss = 0.06914729228816353
Trained batch 130 in epoch 12, gen_loss = 0.3969890465035693, disc_loss = 0.06900059377049444
Trained batch 131 in epoch 12, gen_loss = 0.39696678507960204, disc_loss = 0.07042518164256983
Trained batch 132 in epoch 12, gen_loss = 0.3971538112351769, disc_loss = 0.07092028169339537
Trained batch 133 in epoch 12, gen_loss = 0.3970202119715178, disc_loss = 0.07083451727738799
Trained batch 134 in epoch 12, gen_loss = 0.3971083244791737, disc_loss = 0.07077281918652632
Trained batch 135 in epoch 12, gen_loss = 0.39725827064146013, disc_loss = 0.07052770620622836
Trained batch 136 in epoch 12, gen_loss = 0.3977217803688815, disc_loss = 0.07033932363328925
Trained batch 137 in epoch 12, gen_loss = 0.3974170482892921, disc_loss = 0.07037179228053361
Trained batch 138 in epoch 12, gen_loss = 0.39742602000562405, disc_loss = 0.07056262067405225
Trained batch 139 in epoch 12, gen_loss = 0.397431698760816, disc_loss = 0.0702654083725065
Trained batch 140 in epoch 12, gen_loss = 0.3972702483970223, disc_loss = 0.07040074909541835
Trained batch 141 in epoch 12, gen_loss = 0.397957105976595, disc_loss = 0.07045360893981767
Trained batch 142 in epoch 12, gen_loss = 0.3978409263845924, disc_loss = 0.07007267049324888
Trained batch 143 in epoch 12, gen_loss = 0.397309777740803, disc_loss = 0.07015332713490352
Trained batch 144 in epoch 12, gen_loss = 0.39831010976742054, disc_loss = 0.07019694919601596
Trained batch 145 in epoch 12, gen_loss = 0.39818697300267547, disc_loss = 0.0697807100129454
Trained batch 146 in epoch 12, gen_loss = 0.3976690565444985, disc_loss = 0.0697215364954504
Trained batch 147 in epoch 12, gen_loss = 0.3977971023603066, disc_loss = 0.06975059958829267
Trained batch 148 in epoch 12, gen_loss = 0.3975443553004489, disc_loss = 0.06956074759364128
Trained batch 149 in epoch 12, gen_loss = 0.39745137800772984, disc_loss = 0.06919767868394654
Trained batch 150 in epoch 12, gen_loss = 0.397567107681407, disc_loss = 0.06887692153231789
Trained batch 151 in epoch 12, gen_loss = 0.39719516519261033, disc_loss = 0.06885876947107088
Trained batch 152 in epoch 12, gen_loss = 0.39689188504141143, disc_loss = 0.07017077855595381
Trained batch 153 in epoch 12, gen_loss = 0.39762494364729173, disc_loss = 0.07181378105026368
Trained batch 154 in epoch 12, gen_loss = 0.3971941739320755, disc_loss = 0.07187592098188977
Trained batch 155 in epoch 12, gen_loss = 0.39686335117006916, disc_loss = 0.07194622084856607
Trained batch 156 in epoch 12, gen_loss = 0.3968018074134353, disc_loss = 0.07209484330764052
Trained batch 157 in epoch 12, gen_loss = 0.39626257885483246, disc_loss = 0.07190311713662895
Trained batch 158 in epoch 12, gen_loss = 0.3965324974097546, disc_loss = 0.07178774201340458
Trained batch 159 in epoch 12, gen_loss = 0.3967881561256945, disc_loss = 0.0716700586664956
Trained batch 160 in epoch 12, gen_loss = 0.39677175666604725, disc_loss = 0.07146891615475001
Trained batch 161 in epoch 12, gen_loss = 0.3968838711763606, disc_loss = 0.07140370423296168
Trained batch 162 in epoch 12, gen_loss = 0.3974117588228975, disc_loss = 0.07117527162804743
Trained batch 163 in epoch 12, gen_loss = 0.39771390079361635, disc_loss = 0.07080011478080074
Trained batch 164 in epoch 12, gen_loss = 0.397725569208463, disc_loss = 0.07055679639293388
Trained batch 165 in epoch 12, gen_loss = 0.3979607358215803, disc_loss = 0.07025771531422274
Trained batch 166 in epoch 12, gen_loss = 0.39786636588459245, disc_loss = 0.07003232584095108
Trained batch 167 in epoch 12, gen_loss = 0.3979887626178208, disc_loss = 0.0699340512122338
Trained batch 168 in epoch 12, gen_loss = 0.39839640533077647, disc_loss = 0.06960601160115391
Trained batch 169 in epoch 12, gen_loss = 0.39867079880307704, disc_loss = 0.06927186777705656
Trained batch 170 in epoch 12, gen_loss = 0.39855709053271, disc_loss = 0.06923294691532328
Trained batch 171 in epoch 12, gen_loss = 0.3981153312637362, disc_loss = 0.0707516415196276
Trained batch 172 in epoch 12, gen_loss = 0.3987897998852537, disc_loss = 0.0713233179116697
Trained batch 173 in epoch 12, gen_loss = 0.3987335976341675, disc_loss = 0.07130209798657003
Trained batch 174 in epoch 12, gen_loss = 0.39824227324553896, disc_loss = 0.07215511191104139
Trained batch 175 in epoch 12, gen_loss = 0.39829055075957015, disc_loss = 0.07194777367509562
Trained batch 176 in epoch 12, gen_loss = 0.3979948426538942, disc_loss = 0.0717847009983945
Trained batch 177 in epoch 12, gen_loss = 0.3978653574425183, disc_loss = 0.07174873635633273
Trained batch 178 in epoch 12, gen_loss = 0.39782678390015436, disc_loss = 0.07145726753596487
Trained batch 179 in epoch 12, gen_loss = 0.39751325390405123, disc_loss = 0.07115126016239325
Trained batch 180 in epoch 12, gen_loss = 0.3971221760656294, disc_loss = 0.07090031269176231
Trained batch 181 in epoch 12, gen_loss = 0.3972739023002949, disc_loss = 0.0706266792347798
Trained batch 182 in epoch 12, gen_loss = 0.3968415366984456, disc_loss = 0.07087978244316383
Trained batch 183 in epoch 12, gen_loss = 0.396199278290505, disc_loss = 0.07212670094779004
Trained batch 184 in epoch 12, gen_loss = 0.3962206746275361, disc_loss = 0.07279527755202474
Trained batch 185 in epoch 12, gen_loss = 0.39624716445643415, disc_loss = 0.07313017655284174
Trained batch 186 in epoch 12, gen_loss = 0.3958964192452915, disc_loss = 0.0734770594832094
Trained batch 187 in epoch 12, gen_loss = 0.39582054848049547, disc_loss = 0.07351910699396691
Trained batch 188 in epoch 12, gen_loss = 0.3959557648215975, disc_loss = 0.07340466595752529
Trained batch 189 in epoch 12, gen_loss = 0.3961578090724192, disc_loss = 0.07342271159746144
Trained batch 190 in epoch 12, gen_loss = 0.39631296553848927, disc_loss = 0.07314084776487026
Trained batch 191 in epoch 12, gen_loss = 0.39581929015306133, disc_loss = 0.07295084172316517
Trained batch 192 in epoch 12, gen_loss = 0.3960195223130093, disc_loss = 0.07277360454278907
Trained batch 193 in epoch 12, gen_loss = 0.39588063194886924, disc_loss = 0.0729569742436876
Trained batch 194 in epoch 12, gen_loss = 0.39600497751663893, disc_loss = 0.07298883081246645
Trained batch 195 in epoch 12, gen_loss = 0.3955218587450835, disc_loss = 0.07313631353329639
Trained batch 196 in epoch 12, gen_loss = 0.3958677619998225, disc_loss = 0.07319243490544673
Trained batch 197 in epoch 12, gen_loss = 0.39610757949677383, disc_loss = 0.07305845702913674
Trained batch 198 in epoch 12, gen_loss = 0.3964930289804037, disc_loss = 0.07276076074670906
Trained batch 199 in epoch 12, gen_loss = 0.3960739003866911, disc_loss = 0.07254376382566989
Trained batch 200 in epoch 12, gen_loss = 0.3966640497173243, disc_loss = 0.07235571565060177
Trained batch 201 in epoch 12, gen_loss = 0.39642883077411367, disc_loss = 0.07223648355702067
Trained batch 202 in epoch 12, gen_loss = 0.39710179242888105, disc_loss = 0.07194263338492128
Trained batch 203 in epoch 12, gen_loss = 0.39756300307664216, disc_loss = 0.07170985672878576
Trained batch 204 in epoch 12, gen_loss = 0.3975056175051666, disc_loss = 0.07140757614156094
Trained batch 205 in epoch 12, gen_loss = 0.39728636627347724, disc_loss = 0.07128524386043687
Trained batch 206 in epoch 12, gen_loss = 0.3971736440480043, disc_loss = 0.07114564215287494
Trained batch 207 in epoch 12, gen_loss = 0.39693179432875836, disc_loss = 0.07171162370090875
Trained batch 208 in epoch 12, gen_loss = 0.3971297436496287, disc_loss = 0.07157224949681018
Trained batch 209 in epoch 12, gen_loss = 0.39700104956115995, disc_loss = 0.07138584178118479
Trained batch 210 in epoch 12, gen_loss = 0.3972344239599897, disc_loss = 0.07108236194733901
Trained batch 211 in epoch 12, gen_loss = 0.3970025647783054, disc_loss = 0.07079512977814477
Trained batch 212 in epoch 12, gen_loss = 0.39702549429846484, disc_loss = 0.07054900094219636
Trained batch 213 in epoch 12, gen_loss = 0.39690160591190105, disc_loss = 0.07033415350662632
Trained batch 214 in epoch 12, gen_loss = 0.39690913315429244, disc_loss = 0.07014049247860216
Trained batch 215 in epoch 12, gen_loss = 0.3972499362986397, disc_loss = 0.07111286149032552
Trained batch 216 in epoch 12, gen_loss = 0.3967841812130493, disc_loss = 0.07144519094000076
Trained batch 217 in epoch 12, gen_loss = 0.39652701002468754, disc_loss = 0.0713853720327788
Trained batch 218 in epoch 12, gen_loss = 0.3964079510267467, disc_loss = 0.07130781735918701
Trained batch 219 in epoch 12, gen_loss = 0.39590066447854044, disc_loss = 0.07114722240631553
Trained batch 220 in epoch 12, gen_loss = 0.39569897936210374, disc_loss = 0.07102642588873659
Trained batch 221 in epoch 12, gen_loss = 0.3956908107743607, disc_loss = 0.0707877508767352
Trained batch 222 in epoch 12, gen_loss = 0.39579365599583083, disc_loss = 0.0704985476065544
Trained batch 223 in epoch 12, gen_loss = 0.396102609445474, disc_loss = 0.07023503100624241
Trained batch 224 in epoch 12, gen_loss = 0.39639592932330237, disc_loss = 0.07000595948555403
Trained batch 225 in epoch 12, gen_loss = 0.39663062007290073, disc_loss = 0.06984837216209719
Trained batch 226 in epoch 12, gen_loss = 0.39648019341907836, disc_loss = 0.06960135859761403
Trained batch 227 in epoch 12, gen_loss = 0.39648092518511574, disc_loss = 0.06943555956240743
Trained batch 228 in epoch 12, gen_loss = 0.39606641961757794, disc_loss = 0.06990412829899306
Trained batch 229 in epoch 12, gen_loss = 0.39643052473016405, disc_loss = 0.06985616007536326
Trained batch 230 in epoch 12, gen_loss = 0.39649629096190137, disc_loss = 0.0696476195471208
Trained batch 231 in epoch 12, gen_loss = 0.3964484045603152, disc_loss = 0.06953209827067973
Trained batch 232 in epoch 12, gen_loss = 0.3965961525752309, disc_loss = 0.06938007218731256
Trained batch 233 in epoch 12, gen_loss = 0.3962477265387519, disc_loss = 0.06968123848454501
Trained batch 234 in epoch 12, gen_loss = 0.3967350752429759, disc_loss = 0.07006736404678605
Trained batch 235 in epoch 12, gen_loss = 0.39658196529341955, disc_loss = 0.06988095641096706
Trained batch 236 in epoch 12, gen_loss = 0.3969077269864988, disc_loss = 0.06967095500801372
Trained batch 237 in epoch 12, gen_loss = 0.3970354256384513, disc_loss = 0.06970834301416802
Trained batch 238 in epoch 12, gen_loss = 0.39736529667257764, disc_loss = 0.07000738153015906
Trained batch 239 in epoch 12, gen_loss = 0.3974539014821251, disc_loss = 0.06983676533952045
Trained batch 240 in epoch 12, gen_loss = 0.3970923800315105, disc_loss = 0.07080462271795913
Trained batch 241 in epoch 12, gen_loss = 0.39727741633811275, disc_loss = 0.07095829920635428
Trained batch 242 in epoch 12, gen_loss = 0.397394190415924, disc_loss = 0.07076162827841233
Trained batch 243 in epoch 12, gen_loss = 0.3970387501672643, disc_loss = 0.07086161058205256
Trained batch 244 in epoch 12, gen_loss = 0.39744635498037145, disc_loss = 0.07060803172121546
Trained batch 245 in epoch 12, gen_loss = 0.39755113671223324, disc_loss = 0.0706304352052843
Trained batch 246 in epoch 12, gen_loss = 0.39764818132888935, disc_loss = 0.0705648574710405
Trained batch 247 in epoch 12, gen_loss = 0.39778756945123595, disc_loss = 0.07070244359220529
Trained batch 248 in epoch 12, gen_loss = 0.3977666003517358, disc_loss = 0.07133830129449446
Trained batch 249 in epoch 12, gen_loss = 0.3974497353434563, disc_loss = 0.07119888144917787
Trained batch 250 in epoch 12, gen_loss = 0.3974912169563818, disc_loss = 0.07113871189294405
Trained batch 251 in epoch 12, gen_loss = 0.39725284804663963, disc_loss = 0.07090196068332132
Trained batch 252 in epoch 12, gen_loss = 0.39721649608357623, disc_loss = 0.07128475313608648
Trained batch 253 in epoch 12, gen_loss = 0.39674760055119596, disc_loss = 0.07196222740137495
Trained batch 254 in epoch 12, gen_loss = 0.39686128315972347, disc_loss = 0.07185393408415656
Trained batch 255 in epoch 12, gen_loss = 0.3971769296913408, disc_loss = 0.07213489845344156
Trained batch 256 in epoch 12, gen_loss = 0.3968918144355024, disc_loss = 0.0723115959828031
Trained batch 257 in epoch 12, gen_loss = 0.39675013345572374, disc_loss = 0.07240562998805224
Trained batch 258 in epoch 12, gen_loss = 0.39680873432905056, disc_loss = 0.07231946676631519
Trained batch 259 in epoch 12, gen_loss = 0.39683370802264945, disc_loss = 0.07244043082464487
Trained batch 260 in epoch 12, gen_loss = 0.3967047979434331, disc_loss = 0.07230204355392705
Trained batch 261 in epoch 12, gen_loss = 0.39657812645189633, disc_loss = 0.07217289356848951
Trained batch 262 in epoch 12, gen_loss = 0.3965030245114642, disc_loss = 0.07212906636956357
Trained batch 263 in epoch 12, gen_loss = 0.3963757712168224, disc_loss = 0.0718801122451568
Trained batch 264 in epoch 12, gen_loss = 0.3960842126382972, disc_loss = 0.07179236645230426
Trained batch 265 in epoch 12, gen_loss = 0.3962529333574431, disc_loss = 0.0716867325459852
Trained batch 266 in epoch 12, gen_loss = 0.3961683236592718, disc_loss = 0.07144961121565338
Trained batch 267 in epoch 12, gen_loss = 0.3963929925725531, disc_loss = 0.07123805178892312
Trained batch 268 in epoch 12, gen_loss = 0.39640536765848394, disc_loss = 0.07102096714183245
Trained batch 269 in epoch 12, gen_loss = 0.3962810438540247, disc_loss = 0.07095980651642161
Trained batch 270 in epoch 12, gen_loss = 0.3963723499946489, disc_loss = 0.0708032061579565
Trained batch 271 in epoch 12, gen_loss = 0.396384769338457, disc_loss = 0.07060954544302898
Trained batch 272 in epoch 12, gen_loss = 0.39617952971886367, disc_loss = 0.07052916808108434
Trained batch 273 in epoch 12, gen_loss = 0.3963116282855507, disc_loss = 0.0704429306643913
Trained batch 274 in epoch 12, gen_loss = 0.3960404245961796, disc_loss = 0.07025450675155628
Trained batch 275 in epoch 12, gen_loss = 0.3960177813643131, disc_loss = 0.07004332639769638
Trained batch 276 in epoch 12, gen_loss = 0.39593228175967177, disc_loss = 0.0698959195619913
Trained batch 277 in epoch 12, gen_loss = 0.39587519735955506, disc_loss = 0.06998079715182723
Trained batch 278 in epoch 12, gen_loss = 0.3962622332423391, disc_loss = 0.06979232372408967
Trained batch 279 in epoch 12, gen_loss = 0.39635696352592537, disc_loss = 0.069861925634489
Trained batch 280 in epoch 12, gen_loss = 0.39626773168395846, disc_loss = 0.07033868025477936
Trained batch 281 in epoch 12, gen_loss = 0.3966437614661582, disc_loss = 0.07025502697591082
Trained batch 282 in epoch 12, gen_loss = 0.3965689121307838, disc_loss = 0.07030139572740707
Trained batch 283 in epoch 12, gen_loss = 0.39641845189559627, disc_loss = 0.0703505185173667
Trained batch 284 in epoch 12, gen_loss = 0.3964619003367006, disc_loss = 0.07017621791578438
Trained batch 285 in epoch 12, gen_loss = 0.3967079083090062, disc_loss = 0.07000450328337615
Trained batch 286 in epoch 12, gen_loss = 0.3965194372246074, disc_loss = 0.06995869509207299
Trained batch 287 in epoch 12, gen_loss = 0.39653248665854335, disc_loss = 0.07006383835525615
Trained batch 288 in epoch 12, gen_loss = 0.3966423693309606, disc_loss = 0.06992000997691676
Trained batch 289 in epoch 12, gen_loss = 0.3967158453731701, disc_loss = 0.06989224668881246
Trained batch 290 in epoch 12, gen_loss = 0.3966123000350605, disc_loss = 0.06987818712176583
Trained batch 291 in epoch 12, gen_loss = 0.3969862925985905, disc_loss = 0.0697093645751808
Trained batch 292 in epoch 12, gen_loss = 0.3970966781060443, disc_loss = 0.06951979078740238
Trained batch 293 in epoch 12, gen_loss = 0.39694348185443556, disc_loss = 0.06939038041453226
Trained batch 294 in epoch 12, gen_loss = 0.3970236356480647, disc_loss = 0.06926883620888752
Trained batch 295 in epoch 12, gen_loss = 0.39713542430183374, disc_loss = 0.06911922233789605
Trained batch 296 in epoch 12, gen_loss = 0.39731775936654923, disc_loss = 0.06893827714283107
Trained batch 297 in epoch 12, gen_loss = 0.3975152606832101, disc_loss = 0.06894888999659393
Trained batch 298 in epoch 12, gen_loss = 0.3972515564997459, disc_loss = 0.06915282356680486
Trained batch 299 in epoch 12, gen_loss = 0.3974002199868361, disc_loss = 0.06977572461745392
Trained batch 300 in epoch 12, gen_loss = 0.3971064577368011, disc_loss = 0.07012190603716083
Trained batch 301 in epoch 12, gen_loss = 0.39710191193203265, disc_loss = 0.07001755851172897
Trained batch 302 in epoch 12, gen_loss = 0.3971686422726502, disc_loss = 0.06984972358272463
Trained batch 303 in epoch 12, gen_loss = 0.3970828197014175, disc_loss = 0.0697597079790859
Trained batch 304 in epoch 12, gen_loss = 0.397669226370874, disc_loss = 0.06995905479721602
Trained batch 305 in epoch 12, gen_loss = 0.3974231109023094, disc_loss = 0.0705920343722515
Trained batch 306 in epoch 12, gen_loss = 0.3973493940570067, disc_loss = 0.07079546588718745
Trained batch 307 in epoch 12, gen_loss = 0.397251992692034, disc_loss = 0.07086266166766404
Trained batch 308 in epoch 12, gen_loss = 0.3972517782912671, disc_loss = 0.07070593053209791
Trained batch 309 in epoch 12, gen_loss = 0.39730305330407234, disc_loss = 0.07051115046375461
Trained batch 310 in epoch 12, gen_loss = 0.3973691671895061, disc_loss = 0.0704089933392439
Trained batch 311 in epoch 12, gen_loss = 0.39711204185508764, disc_loss = 0.07082162604768737
Trained batch 312 in epoch 12, gen_loss = 0.3970173944394809, disc_loss = 0.07092747173923701
Trained batch 313 in epoch 12, gen_loss = 0.39688546798980917, disc_loss = 0.07077576659151182
Trained batch 314 in epoch 12, gen_loss = 0.3969003740284178, disc_loss = 0.07058407783892656
Trained batch 315 in epoch 12, gen_loss = 0.39694820990479446, disc_loss = 0.07042434680882748
Trained batch 316 in epoch 12, gen_loss = 0.3965151710935196, disc_loss = 0.07057870277100792
Trained batch 317 in epoch 12, gen_loss = 0.3964601366681123, disc_loss = 0.07055450107978434
Trained batch 318 in epoch 12, gen_loss = 0.39637931681538824, disc_loss = 0.07048477686877394
Trained batch 319 in epoch 12, gen_loss = 0.39659070293419063, disc_loss = 0.07088640976144234
Trained batch 320 in epoch 12, gen_loss = 0.3962968330238467, disc_loss = 0.07138412351926028
Trained batch 321 in epoch 12, gen_loss = 0.3962889649205326, disc_loss = 0.07143211680730539
Trained batch 322 in epoch 12, gen_loss = 0.39635763176639016, disc_loss = 0.07129076810196135
Trained batch 323 in epoch 12, gen_loss = 0.3961671712681835, disc_loss = 0.07110174887462944
Trained batch 324 in epoch 12, gen_loss = 0.3959777939778108, disc_loss = 0.07122127949761657
Trained batch 325 in epoch 12, gen_loss = 0.39606378684563137, disc_loss = 0.07172964526586052
Trained batch 326 in epoch 12, gen_loss = 0.39612850852151166, disc_loss = 0.0716922734265959
Trained batch 327 in epoch 12, gen_loss = 0.3959164797987153, disc_loss = 0.07176453331286632
Trained batch 328 in epoch 12, gen_loss = 0.39609883952104574, disc_loss = 0.07236710509658992
Trained batch 329 in epoch 12, gen_loss = 0.39583737430247395, disc_loss = 0.07232198406603527
Trained batch 330 in epoch 12, gen_loss = 0.39572924668155046, disc_loss = 0.07220244160754848
Trained batch 331 in epoch 12, gen_loss = 0.3958635131368436, disc_loss = 0.07203037298076886
Trained batch 332 in epoch 12, gen_loss = 0.3959283689568351, disc_loss = 0.0718769299736185
Trained batch 333 in epoch 12, gen_loss = 0.39590372551165653, disc_loss = 0.07175160658512332
Trained batch 334 in epoch 12, gen_loss = 0.39588029976211375, disc_loss = 0.07168920108659277
Trained batch 335 in epoch 12, gen_loss = 0.39591246209151687, disc_loss = 0.07178262824752546
Trained batch 336 in epoch 12, gen_loss = 0.3957366122247911, disc_loss = 0.07172921405640881
Trained batch 337 in epoch 12, gen_loss = 0.39606304947264803, disc_loss = 0.07161661086069453
Trained batch 338 in epoch 12, gen_loss = 0.39603957037130993, disc_loss = 0.0715489421427184
Trained batch 339 in epoch 12, gen_loss = 0.3961681823958369, disc_loss = 0.07151425809133798
Trained batch 340 in epoch 12, gen_loss = 0.3961493413556706, disc_loss = 0.07152156959645603
Trained batch 341 in epoch 12, gen_loss = 0.3964224283893903, disc_loss = 0.07134102414939443
Trained batch 342 in epoch 12, gen_loss = 0.39666656941262346, disc_loss = 0.07116827274110635
Trained batch 343 in epoch 12, gen_loss = 0.3966388982655697, disc_loss = 0.07110763008592563
Trained batch 344 in epoch 12, gen_loss = 0.39655635404414025, disc_loss = 0.07101232781871289
Trained batch 345 in epoch 12, gen_loss = 0.3965948854998357, disc_loss = 0.0712180338420426
Trained batch 346 in epoch 12, gen_loss = 0.39668288444751276, disc_loss = 0.0712782781053152
Trained batch 347 in epoch 12, gen_loss = 0.39681682885549535, disc_loss = 0.07122791713590723
Trained batch 348 in epoch 12, gen_loss = 0.3969631449967879, disc_loss = 0.0710446513097808
Trained batch 349 in epoch 12, gen_loss = 0.39721764696495876, disc_loss = 0.07089170440366226
Trained batch 350 in epoch 12, gen_loss = 0.3971499661859284, disc_loss = 0.07074481948674192
Trained batch 351 in epoch 12, gen_loss = 0.39704095567999914, disc_loss = 0.07061335833251095
Trained batch 352 in epoch 12, gen_loss = 0.3969775095961925, disc_loss = 0.07044227209031878
Trained batch 353 in epoch 12, gen_loss = 0.3971167851218396, disc_loss = 0.07034971780606708
Trained batch 354 in epoch 12, gen_loss = 0.3969522965206227, disc_loss = 0.07046333350844576
Trained batch 355 in epoch 12, gen_loss = 0.39713967068309197, disc_loss = 0.07035694556870613
Trained batch 356 in epoch 12, gen_loss = 0.39733753630927965, disc_loss = 0.07042313130123734
Trained batch 357 in epoch 12, gen_loss = 0.39713248273347346, disc_loss = 0.07119567799329883
Trained batch 358 in epoch 12, gen_loss = 0.3971070514831038, disc_loss = 0.07118535642499171
Trained batch 359 in epoch 12, gen_loss = 0.39691792035268414, disc_loss = 0.07180863605268921
Trained batch 360 in epoch 12, gen_loss = 0.3967859331838312, disc_loss = 0.07173021223236113
Trained batch 361 in epoch 12, gen_loss = 0.3967078708071076, disc_loss = 0.07168316060949878
Trained batch 362 in epoch 12, gen_loss = 0.39672111311398917, disc_loss = 0.07164009241643811
Trained batch 363 in epoch 12, gen_loss = 0.39669384303820004, disc_loss = 0.07154170034714248
Trained batch 364 in epoch 12, gen_loss = 0.3966228584312413, disc_loss = 0.07144431656430641
Trained batch 365 in epoch 12, gen_loss = 0.3965893479399994, disc_loss = 0.07151889952556154
Trained batch 366 in epoch 12, gen_loss = 0.39644631511996165, disc_loss = 0.0713808879101451
Trained batch 367 in epoch 12, gen_loss = 0.3967592844577587, disc_loss = 0.07124240738820568
Trained batch 368 in epoch 12, gen_loss = 0.3966449046441856, disc_loss = 0.0711100195095367
Trained batch 369 in epoch 12, gen_loss = 0.39661094767821803, disc_loss = 0.071022673438278
Trained batch 370 in epoch 12, gen_loss = 0.39667464053695095, disc_loss = 0.07084782341133673
Trained batch 371 in epoch 12, gen_loss = 0.3966188528925501, disc_loss = 0.07071214547175514
Trained batch 372 in epoch 12, gen_loss = 0.3967350766502181, disc_loss = 0.07060224351525586
Trained batch 373 in epoch 12, gen_loss = 0.39669256155344257, disc_loss = 0.07063231563798207
Trained batch 374 in epoch 12, gen_loss = 0.3966263595819473, disc_loss = 0.07049218413606285
Trained batch 375 in epoch 12, gen_loss = 0.3967633056751591, disc_loss = 0.07034923961420761
Trained batch 376 in epoch 12, gen_loss = 0.3970394734915751, disc_loss = 0.07018856747589748
Trained batch 377 in epoch 12, gen_loss = 0.3969974756319687, disc_loss = 0.07004967591942106
Trained batch 378 in epoch 12, gen_loss = 0.39734340331327944, disc_loss = 0.0699900722605395
Trained batch 379 in epoch 12, gen_loss = 0.3972247335079469, disc_loss = 0.0701043043371388
Trained batch 380 in epoch 12, gen_loss = 0.3973244540882236, disc_loss = 0.07009964552524639
Trained batch 381 in epoch 12, gen_loss = 0.3973641999026868, disc_loss = 0.0699529629919912
Trained batch 382 in epoch 12, gen_loss = 0.39711121662322907, disc_loss = 0.06988272955397985
Trained batch 383 in epoch 12, gen_loss = 0.3971404313342646, disc_loss = 0.06974444387863817
Trained batch 384 in epoch 12, gen_loss = 0.3970962753156563, disc_loss = 0.06973258517077797
Trained batch 385 in epoch 12, gen_loss = 0.39696603407359493, disc_loss = 0.0696953105790917
Trained batch 386 in epoch 12, gen_loss = 0.3970390727276642, disc_loss = 0.06957273793500639
Trained batch 387 in epoch 12, gen_loss = 0.3971086446695107, disc_loss = 0.06953293996138171
Trained batch 388 in epoch 12, gen_loss = 0.39683984511156006, disc_loss = 0.06967556956260056
Trained batch 389 in epoch 12, gen_loss = 0.3968716643941708, disc_loss = 0.0696454876783089
Trained batch 390 in epoch 12, gen_loss = 0.396871860184328, disc_loss = 0.06951185042286277
Trained batch 391 in epoch 12, gen_loss = 0.3968544992029059, disc_loss = 0.0694712233736788
Trained batch 392 in epoch 12, gen_loss = 0.39687938138880496, disc_loss = 0.0693717974607783
Trained batch 393 in epoch 12, gen_loss = 0.39699192643921993, disc_loss = 0.06922941145647865
Trained batch 394 in epoch 12, gen_loss = 0.3970354358229456, disc_loss = 0.06921098940899667
Trained batch 395 in epoch 12, gen_loss = 0.39720513803338764, disc_loss = 0.06908600979997316
Trained batch 396 in epoch 12, gen_loss = 0.39722607789622144, disc_loss = 0.0689946865271167
Trained batch 397 in epoch 12, gen_loss = 0.3971629650074633, disc_loss = 0.06885527043799922
Trained batch 398 in epoch 12, gen_loss = 0.39715255587770226, disc_loss = 0.06903679914805189
Trained batch 399 in epoch 12, gen_loss = 0.397338296584785, disc_loss = 0.06941583386971616
Trained batch 400 in epoch 12, gen_loss = 0.39733131876461525, disc_loss = 0.06938115685151662
Trained batch 401 in epoch 12, gen_loss = 0.39694706228241994, disc_loss = 0.06961623791823006
Trained batch 402 in epoch 12, gen_loss = 0.3969660620239769, disc_loss = 0.06950308613955199
Trained batch 403 in epoch 12, gen_loss = 0.3969763914989953, disc_loss = 0.06946397219936705
Trained batch 404 in epoch 12, gen_loss = 0.39686346583896215, disc_loss = 0.06939190538186166
Trained batch 405 in epoch 12, gen_loss = 0.39667365674314825, disc_loss = 0.06967035149169049
Trained batch 406 in epoch 12, gen_loss = 0.39690125940472837, disc_loss = 0.06967870091461102
Trained batch 407 in epoch 12, gen_loss = 0.3970622055086435, disc_loss = 0.06970022222844373
Trained batch 408 in epoch 12, gen_loss = 0.3969334635000066, disc_loss = 0.06977435070588675
Trained batch 409 in epoch 12, gen_loss = 0.39679523830006763, disc_loss = 0.06967484375302929
Trained batch 410 in epoch 12, gen_loss = 0.39685147848442526, disc_loss = 0.06954186432258455
Trained batch 411 in epoch 12, gen_loss = 0.3970495431313237, disc_loss = 0.06940614913468186
Trained batch 412 in epoch 12, gen_loss = 0.3970790939815974, disc_loss = 0.06957297586693854
Trained batch 413 in epoch 12, gen_loss = 0.3969986616557347, disc_loss = 0.07036860294725548
Trained batch 414 in epoch 12, gen_loss = 0.39706941634775644, disc_loss = 0.07056796030444373
Trained batch 415 in epoch 12, gen_loss = 0.39721183127795273, disc_loss = 0.07089466268819077
Trained batch 416 in epoch 12, gen_loss = 0.3970666709992525, disc_loss = 0.07102286215643767
Trained batch 417 in epoch 12, gen_loss = 0.39698073909613507, disc_loss = 0.07110247162446985
Trained batch 418 in epoch 12, gen_loss = 0.39700307439221405, disc_loss = 0.07110405992827687
Trained batch 419 in epoch 12, gen_loss = 0.396996581412497, disc_loss = 0.07101001086134819
Trained batch 420 in epoch 12, gen_loss = 0.39699683520686313, disc_loss = 0.07096006094219247
Trained batch 421 in epoch 12, gen_loss = 0.39691283656240073, disc_loss = 0.07084556650789675
Trained batch 422 in epoch 12, gen_loss = 0.39688024897101926, disc_loss = 0.07070262189712331
Trained batch 423 in epoch 12, gen_loss = 0.39693580680298357, disc_loss = 0.07070740029756155
Trained batch 424 in epoch 12, gen_loss = 0.39710826004252714, disc_loss = 0.07089892343891895
Trained batch 425 in epoch 12, gen_loss = 0.3971963782265712, disc_loss = 0.07091584878956174
Trained batch 426 in epoch 12, gen_loss = 0.39710756417459847, disc_loss = 0.07080094358694043
Trained batch 427 in epoch 12, gen_loss = 0.3971685727483758, disc_loss = 0.07065371150329326
Trained batch 428 in epoch 12, gen_loss = 0.3971363584617357, disc_loss = 0.0705671370222661
Trained batch 429 in epoch 12, gen_loss = 0.3972515462442886, disc_loss = 0.07046888215618945
Trained batch 430 in epoch 12, gen_loss = 0.3972973701848785, disc_loss = 0.07036549006448302
Trained batch 431 in epoch 12, gen_loss = 0.39719875032703084, disc_loss = 0.07024908585892128
Trained batch 432 in epoch 12, gen_loss = 0.3975360803736275, disc_loss = 0.07018472697461071
Trained batch 433 in epoch 12, gen_loss = 0.3973081948982406, disc_loss = 0.07029722861984256
Trained batch 434 in epoch 12, gen_loss = 0.39746962251334356, disc_loss = 0.07019791216107792
Trained batch 435 in epoch 12, gen_loss = 0.3977096853179669, disc_loss = 0.0701325018260064
Trained batch 436 in epoch 12, gen_loss = 0.3977691802607521, disc_loss = 0.06999169721095493
Trained batch 437 in epoch 12, gen_loss = 0.3976715144501429, disc_loss = 0.06997880194714659
Trained batch 438 in epoch 12, gen_loss = 0.39762728055408714, disc_loss = 0.06985197530779351
Trained batch 439 in epoch 12, gen_loss = 0.39769909564744343, disc_loss = 0.06989978130758655
Trained batch 440 in epoch 12, gen_loss = 0.3975770699193959, disc_loss = 0.07016630891959717
Trained batch 441 in epoch 12, gen_loss = 0.39767628072074096, disc_loss = 0.07052312254151372
Trained batch 442 in epoch 12, gen_loss = 0.3977127893245516, disc_loss = 0.07038675086009348
Trained batch 443 in epoch 12, gen_loss = 0.3976468783509624, disc_loss = 0.0704800939189505
Trained batch 444 in epoch 12, gen_loss = 0.3976897383004092, disc_loss = 0.07042857299380925
Trained batch 445 in epoch 12, gen_loss = 0.39763932725239226, disc_loss = 0.07034359429336483
Trained batch 446 in epoch 12, gen_loss = 0.39770970968592084, disc_loss = 0.07024451516989527
Trained batch 447 in epoch 12, gen_loss = 0.3977288170052426, disc_loss = 0.07018362628566267
Trained batch 448 in epoch 12, gen_loss = 0.39778314169106344, disc_loss = 0.07012297811384888
Trained batch 449 in epoch 12, gen_loss = 0.3975868187348048, disc_loss = 0.0701520645380434
Trained batch 450 in epoch 12, gen_loss = 0.39765706010774077, disc_loss = 0.07010285215278853
Trained batch 451 in epoch 12, gen_loss = 0.3974910222191726, disc_loss = 0.07001573786621633
Trained batch 452 in epoch 12, gen_loss = 0.39765146216809355, disc_loss = 0.070507233996339
Trained batch 453 in epoch 12, gen_loss = 0.3975005990739436, disc_loss = 0.07102082088478895
Trained batch 454 in epoch 12, gen_loss = 0.39760779987324724, disc_loss = 0.071135283888901
Trained batch 455 in epoch 12, gen_loss = 0.3976601096883155, disc_loss = 0.07121364059633363
Trained batch 456 in epoch 12, gen_loss = 0.39772928393643586, disc_loss = 0.07113793022478207
Trained batch 457 in epoch 12, gen_loss = 0.3977291030915023, disc_loss = 0.07103170038152112
Trained batch 458 in epoch 12, gen_loss = 0.3976195797421574, disc_loss = 0.07090302599869945
Trained batch 459 in epoch 12, gen_loss = 0.3976512015513752, disc_loss = 0.07076737503419914
Trained batch 460 in epoch 12, gen_loss = 0.3975600299633506, disc_loss = 0.07071697408204126
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.28842082619667053, disc_loss = 0.16397009789943695
Trained batch 1 in epoch 13, gen_loss = 0.30736127495765686, disc_loss = 0.21456973999738693
Trained batch 2 in epoch 13, gen_loss = 0.3410537640253703, disc_loss = 0.16633252799510956
Trained batch 3 in epoch 13, gen_loss = 0.3625715970993042, disc_loss = 0.1284339977428317
Trained batch 4 in epoch 13, gen_loss = 0.36073959469795225, disc_loss = 0.10453604701906442
Trained batch 5 in epoch 13, gen_loss = 0.3535620520512263, disc_loss = 0.0897157817768554
Trained batch 6 in epoch 13, gen_loss = 0.35837580050740925, disc_loss = 0.08707911880420786
Trained batch 7 in epoch 13, gen_loss = 0.3565201424062252, disc_loss = 0.08277264644857496
Trained batch 8 in epoch 13, gen_loss = 0.3641646471288469, disc_loss = 0.07501481835626894
Trained batch 9 in epoch 13, gen_loss = 0.37015211284160615, disc_loss = 0.06922996854409576
Trained batch 10 in epoch 13, gen_loss = 0.3723570135506717, disc_loss = 0.06485074377534064
Trained batch 11 in epoch 13, gen_loss = 0.37297550092140835, disc_loss = 0.06159054930321872
Trained batch 12 in epoch 13, gen_loss = 0.3667913629458501, disc_loss = 0.06284381169825792
Trained batch 13 in epoch 13, gen_loss = 0.3724197340863092, disc_loss = 0.06165880370619042
Trained batch 14 in epoch 13, gen_loss = 0.36849579016367595, disc_loss = 0.058997988266249496
Trained batch 15 in epoch 13, gen_loss = 0.36403312534093857, disc_loss = 0.061294485873077065
Trained batch 16 in epoch 13, gen_loss = 0.3716419286587659, disc_loss = 0.061657177229576254
Trained batch 17 in epoch 13, gen_loss = 0.37230055199729073, disc_loss = 0.058808847278770476
Trained batch 18 in epoch 13, gen_loss = 0.3757875012724023, disc_loss = 0.05653165658249667
Trained batch 19 in epoch 13, gen_loss = 0.372707137465477, disc_loss = 0.06019081906415522
Trained batch 20 in epoch 13, gen_loss = 0.37931374992643085, disc_loss = 0.07268741145907413
Trained batch 21 in epoch 13, gen_loss = 0.3812058676372875, disc_loss = 0.07485858033495871
Trained batch 22 in epoch 13, gen_loss = 0.3831795959368996, disc_loss = 0.0797707744995537
Trained batch 23 in epoch 13, gen_loss = 0.38568639134367305, disc_loss = 0.07739152623495708
Trained batch 24 in epoch 13, gen_loss = 0.38973353266716004, disc_loss = 0.0748244084045291
Trained batch 25 in epoch 13, gen_loss = 0.393367948440405, disc_loss = 0.07231879925641876
Trained batch 26 in epoch 13, gen_loss = 0.3908747942359359, disc_loss = 0.07073695574783617
Trained batch 27 in epoch 13, gen_loss = 0.38989697077444624, disc_loss = 0.06886854411901108
Trained batch 28 in epoch 13, gen_loss = 0.38932402688881446, disc_loss = 0.06761894648059688
Trained batch 29 in epoch 13, gen_loss = 0.3870651493469874, disc_loss = 0.06579043741027514
Trained batch 30 in epoch 13, gen_loss = 0.3874903215515998, disc_loss = 0.06388493534177542
Trained batch 31 in epoch 13, gen_loss = 0.38756928220391273, disc_loss = 0.06290724154678173
Trained batch 32 in epoch 13, gen_loss = 0.38906924562020734, disc_loss = 0.06178695818578655
Trained batch 33 in epoch 13, gen_loss = 0.3866150782388799, disc_loss = 0.06159846777753795
Trained batch 34 in epoch 13, gen_loss = 0.38671061652047295, disc_loss = 0.061107972556991234
Trained batch 35 in epoch 13, gen_loss = 0.3874279906352361, disc_loss = 0.0631156856349359
Trained batch 36 in epoch 13, gen_loss = 0.38590535763147715, disc_loss = 0.06243900911932861
Trained batch 37 in epoch 13, gen_loss = 0.3836724632664731, disc_loss = 0.07004991720283502
Trained batch 38 in epoch 13, gen_loss = 0.3847452371548384, disc_loss = 0.07173650499242239
Trained batch 39 in epoch 13, gen_loss = 0.3836351722478867, disc_loss = 0.07113657442387193
Trained batch 40 in epoch 13, gen_loss = 0.3834587764449236, disc_loss = 0.07058550587787134
Trained batch 41 in epoch 13, gen_loss = 0.38432724631967996, disc_loss = 0.06941718809927504
Trained batch 42 in epoch 13, gen_loss = 0.3845716222774151, disc_loss = 0.06881111320974521
Trained batch 43 in epoch 13, gen_loss = 0.3838785697113384, disc_loss = 0.06848162173462863
Trained batch 44 in epoch 13, gen_loss = 0.3827155749003092, disc_loss = 0.06742500226116843
Trained batch 45 in epoch 13, gen_loss = 0.38483732226102246, disc_loss = 0.06639628280359118
Trained batch 46 in epoch 13, gen_loss = 0.38473479418044393, disc_loss = 0.06580664770321008
Trained batch 47 in epoch 13, gen_loss = 0.3855407442897558, disc_loss = 0.06498118883852537
Trained batch 48 in epoch 13, gen_loss = 0.38510415931137243, disc_loss = 0.0639089599669892
Trained batch 49 in epoch 13, gen_loss = 0.38423359513282773, disc_loss = 0.06398843316361308
Trained batch 50 in epoch 13, gen_loss = 0.3865947571455264, disc_loss = 0.06549516698235974
Trained batch 51 in epoch 13, gen_loss = 0.38620023200145137, disc_loss = 0.0646829845992705
Trained batch 52 in epoch 13, gen_loss = 0.38684193368227976, disc_loss = 0.064175298982212
Trained batch 53 in epoch 13, gen_loss = 0.38734324828342154, disc_loss = 0.06324391632720276
Trained batch 54 in epoch 13, gen_loss = 0.38639439832080497, disc_loss = 0.06419043175198814
Trained batch 55 in epoch 13, gen_loss = 0.3853568865784577, disc_loss = 0.06720940728804894
Trained batch 56 in epoch 13, gen_loss = 0.38586393260119256, disc_loss = 0.06780218555216204
Trained batch 57 in epoch 13, gen_loss = 0.3863910446906912, disc_loss = 0.0668173019035623
Trained batch 58 in epoch 13, gen_loss = 0.3852118829549369, disc_loss = 0.06592331552025625
Trained batch 59 in epoch 13, gen_loss = 0.3859446167945862, disc_loss = 0.0652337367956837
Trained batch 60 in epoch 13, gen_loss = 0.3848221243404951, disc_loss = 0.06473990199995823
Trained batch 61 in epoch 13, gen_loss = 0.3851006554980432, disc_loss = 0.0658213647623216
Trained batch 62 in epoch 13, gen_loss = 0.384584213060046, disc_loss = 0.06664226819125432
Trained batch 63 in epoch 13, gen_loss = 0.38539245165884495, disc_loss = 0.06575843101018108
Trained batch 64 in epoch 13, gen_loss = 0.3866996875176063, disc_loss = 0.06528495679107996
Trained batch 65 in epoch 13, gen_loss = 0.38710169900547375, disc_loss = 0.06483100758244593
Trained batch 66 in epoch 13, gen_loss = 0.3854273998025638, disc_loss = 0.06546608733930695
Trained batch 67 in epoch 13, gen_loss = 0.3868948286947082, disc_loss = 0.06482077726875157
Trained batch 68 in epoch 13, gen_loss = 0.38823225316794024, disc_loss = 0.06409861441647662
Trained batch 69 in epoch 13, gen_loss = 0.3874457116637911, disc_loss = 0.06461877836180585
Trained batch 70 in epoch 13, gen_loss = 0.388549740045843, disc_loss = 0.0666199613257613
Trained batch 71 in epoch 13, gen_loss = 0.3887241714530521, disc_loss = 0.06599551229737699
Trained batch 72 in epoch 13, gen_loss = 0.3886781163411598, disc_loss = 0.06622050628576377
Trained batch 73 in epoch 13, gen_loss = 0.38998772405289317, disc_loss = 0.06563288081638716
Trained batch 74 in epoch 13, gen_loss = 0.39168895562489825, disc_loss = 0.06492826431989669
Trained batch 75 in epoch 13, gen_loss = 0.39173354875100286, disc_loss = 0.0649240404171379
Trained batch 76 in epoch 13, gen_loss = 0.3911829184402119, disc_loss = 0.06697882663506965
Trained batch 77 in epoch 13, gen_loss = 0.3917582604365471, disc_loss = 0.06735854767836057
Trained batch 78 in epoch 13, gen_loss = 0.39156634181360656, disc_loss = 0.06738887642380557
Trained batch 79 in epoch 13, gen_loss = 0.3914093691855669, disc_loss = 0.06712565091438591
Trained batch 80 in epoch 13, gen_loss = 0.39289372239583803, disc_loss = 0.06679518640409281
Trained batch 81 in epoch 13, gen_loss = 0.39260759186453936, disc_loss = 0.0665567037081573
Trained batch 82 in epoch 13, gen_loss = 0.3925930200571037, disc_loss = 0.06704251436763499
Trained batch 83 in epoch 13, gen_loss = 0.39189232885837555, disc_loss = 0.06801747499654691
Trained batch 84 in epoch 13, gen_loss = 0.39309029368793263, disc_loss = 0.06787879971020362
Trained batch 85 in epoch 13, gen_loss = 0.3926802326080411, disc_loss = 0.06733796238725961
Trained batch 86 in epoch 13, gen_loss = 0.39296075016602705, disc_loss = 0.06686289595632718
Trained batch 87 in epoch 13, gen_loss = 0.39369090409441426, disc_loss = 0.06648188486525958
Trained batch 88 in epoch 13, gen_loss = 0.39271571428588264, disc_loss = 0.0673117394443978
Trained batch 89 in epoch 13, gen_loss = 0.39355612364080217, disc_loss = 0.07129901196393702
Trained batch 90 in epoch 13, gen_loss = 0.39411457914572495, disc_loss = 0.07157154377181452
Trained batch 91 in epoch 13, gen_loss = 0.393829294844814, disc_loss = 0.07199935878262571
Trained batch 92 in epoch 13, gen_loss = 0.3937680987260675, disc_loss = 0.07191346301346697
Trained batch 93 in epoch 13, gen_loss = 0.39445472936680975, disc_loss = 0.07131283581653174
Trained batch 94 in epoch 13, gen_loss = 0.39455409018616927, disc_loss = 0.07079237458345138
Trained batch 95 in epoch 13, gen_loss = 0.3941113942613204, disc_loss = 0.07029619502524535
Trained batch 96 in epoch 13, gen_loss = 0.3940003987440129, disc_loss = 0.06996978508289327
Trained batch 97 in epoch 13, gen_loss = 0.394000199072215, disc_loss = 0.07028988311637421
Trained batch 98 in epoch 13, gen_loss = 0.3935958556454591, disc_loss = 0.07038572870872238
Trained batch 99 in epoch 13, gen_loss = 0.39378409773111345, disc_loss = 0.06990638714283705
Trained batch 100 in epoch 13, gen_loss = 0.3935123363343796, disc_loss = 0.07030209069057267
Trained batch 101 in epoch 13, gen_loss = 0.3935053313479704, disc_loss = 0.07061866462668952
Trained batch 102 in epoch 13, gen_loss = 0.39307570602129965, disc_loss = 0.07011498579556502
Trained batch 103 in epoch 13, gen_loss = 0.3930250240059999, disc_loss = 0.06957892091192591
Trained batch 104 in epoch 13, gen_loss = 0.3923317455110096, disc_loss = 0.06971622179484084
Trained batch 105 in epoch 13, gen_loss = 0.39230349434996553, disc_loss = 0.07024857021411354
Trained batch 106 in epoch 13, gen_loss = 0.39254320447690016, disc_loss = 0.06990295313472782
Trained batch 107 in epoch 13, gen_loss = 0.3917727467638475, disc_loss = 0.06993865952137168
Trained batch 108 in epoch 13, gen_loss = 0.39169570776300694, disc_loss = 0.06962290630940723
Trained batch 109 in epoch 13, gen_loss = 0.39261594929478383, disc_loss = 0.06929588940163905
Trained batch 110 in epoch 13, gen_loss = 0.39336365541896307, disc_loss = 0.06887461606681615
Trained batch 111 in epoch 13, gen_loss = 0.3926331866532564, disc_loss = 0.06851357759608488
Trained batch 112 in epoch 13, gen_loss = 0.3935362828516327, disc_loss = 0.06798521034518439
Trained batch 113 in epoch 13, gen_loss = 0.39368462562561035, disc_loss = 0.06750649829770912
Trained batch 114 in epoch 13, gen_loss = 0.39412638726441757, disc_loss = 0.06705657593581987
Trained batch 115 in epoch 13, gen_loss = 0.3941820202202633, disc_loss = 0.06672836730963197
Trained batch 116 in epoch 13, gen_loss = 0.3944214169795697, disc_loss = 0.06627964975041711
Trained batch 117 in epoch 13, gen_loss = 0.3941377944360345, disc_loss = 0.0662788659239472
Trained batch 118 in epoch 13, gen_loss = 0.3944576422707373, disc_loss = 0.06612486356258893
Trained batch 119 in epoch 13, gen_loss = 0.3950186332066854, disc_loss = 0.0659731448472788
Trained batch 120 in epoch 13, gen_loss = 0.3949978213664914, disc_loss = 0.0670805049613734
Trained batch 121 in epoch 13, gen_loss = 0.3955768571525324, disc_loss = 0.06669339633806319
Trained batch 122 in epoch 13, gen_loss = 0.3964549613192799, disc_loss = 0.0664516606072827
Trained batch 123 in epoch 13, gen_loss = 0.3965217528804656, disc_loss = 0.0661818309867334
Trained batch 124 in epoch 13, gen_loss = 0.39621133685112, disc_loss = 0.06604200841486454
Trained batch 125 in epoch 13, gen_loss = 0.39595707162978155, disc_loss = 0.06563245336569491
Trained batch 126 in epoch 13, gen_loss = 0.3963411419879733, disc_loss = 0.06550067768791529
Trained batch 127 in epoch 13, gen_loss = 0.39603370404802263, disc_loss = 0.06564659281866625
Trained batch 128 in epoch 13, gen_loss = 0.3963624504647514, disc_loss = 0.06534756623324035
Trained batch 129 in epoch 13, gen_loss = 0.3964616190928679, disc_loss = 0.06511416161576143
Trained batch 130 in epoch 13, gen_loss = 0.3966517528049818, disc_loss = 0.06501614141725857
Trained batch 131 in epoch 13, gen_loss = 0.3969340787240953, disc_loss = 0.06458634231239557
Trained batch 132 in epoch 13, gen_loss = 0.39704170778281705, disc_loss = 0.0649961493349165
Trained batch 133 in epoch 13, gen_loss = 0.3962379126851238, disc_loss = 0.06624621756152431
Trained batch 134 in epoch 13, gen_loss = 0.39733831551339893, disc_loss = 0.06756620608546116
Trained batch 135 in epoch 13, gen_loss = 0.3973153428558041, disc_loss = 0.06732484342201668
Trained batch 136 in epoch 13, gen_loss = 0.39661606580671604, disc_loss = 0.06778698023000773
Trained batch 137 in epoch 13, gen_loss = 0.3970227796530378, disc_loss = 0.06822846381776575
Trained batch 138 in epoch 13, gen_loss = 0.39695508188480955, disc_loss = 0.06784897170987704
Trained batch 139 in epoch 13, gen_loss = 0.397505375955786, disc_loss = 0.06775043667294085
Trained batch 140 in epoch 13, gen_loss = 0.397453470433012, disc_loss = 0.06736993598784749
Trained batch 141 in epoch 13, gen_loss = 0.39742264256510934, disc_loss = 0.06717288283578737
Trained batch 142 in epoch 13, gen_loss = 0.3975992671676449, disc_loss = 0.06692249139679687
Trained batch 143 in epoch 13, gen_loss = 0.3972543631162908, disc_loss = 0.06681418645894155
Trained batch 144 in epoch 13, gen_loss = 0.3974786702928872, disc_loss = 0.06731092641451235
Trained batch 145 in epoch 13, gen_loss = 0.39746264276439197, disc_loss = 0.06711968883540329
Trained batch 146 in epoch 13, gen_loss = 0.39708793305215384, disc_loss = 0.06689802483104322
Trained batch 147 in epoch 13, gen_loss = 0.397008315332838, disc_loss = 0.06657758227398468
Trained batch 148 in epoch 13, gen_loss = 0.3973365784091437, disc_loss = 0.0662210479991248
Trained batch 149 in epoch 13, gen_loss = 0.39723236560821534, disc_loss = 0.06584951544180512
Trained batch 150 in epoch 13, gen_loss = 0.3971854854893211, disc_loss = 0.06568179306086917
Trained batch 151 in epoch 13, gen_loss = 0.3970248871727994, disc_loss = 0.06539162644797838
Trained batch 152 in epoch 13, gen_loss = 0.3971863447451124, disc_loss = 0.06500912398964263
Trained batch 153 in epoch 13, gen_loss = 0.39773947658476894, disc_loss = 0.06476741089098542
Trained batch 154 in epoch 13, gen_loss = 0.3976426801373882, disc_loss = 0.06487359431902728
Trained batch 155 in epoch 13, gen_loss = 0.3974253372886242, disc_loss = 0.06509525155445609
Trained batch 156 in epoch 13, gen_loss = 0.39725126980975933, disc_loss = 0.06498050557710468
Trained batch 157 in epoch 13, gen_loss = 0.3975795103779322, disc_loss = 0.06461789856275803
Trained batch 158 in epoch 13, gen_loss = 0.397650031923498, disc_loss = 0.06427194291151732
Trained batch 159 in epoch 13, gen_loss = 0.39794413447380067, disc_loss = 0.06393450216273777
Trained batch 160 in epoch 13, gen_loss = 0.3981138545533885, disc_loss = 0.0636224008761115
Trained batch 161 in epoch 13, gen_loss = 0.3979286527560081, disc_loss = 0.06338045786905253
Trained batch 162 in epoch 13, gen_loss = 0.39773601512967444, disc_loss = 0.06339584139569954
Trained batch 163 in epoch 13, gen_loss = 0.39846664267342263, disc_loss = 0.06404415821861022
Trained batch 164 in epoch 13, gen_loss = 0.3979363804513758, disc_loss = 0.0642683246314074
Trained batch 165 in epoch 13, gen_loss = 0.3979151153779892, disc_loss = 0.06396244852298713
Trained batch 166 in epoch 13, gen_loss = 0.39789503027579026, disc_loss = 0.06367110836314048
Trained batch 167 in epoch 13, gen_loss = 0.398030538998899, disc_loss = 0.06342193357358199
Trained batch 168 in epoch 13, gen_loss = 0.3981403606177787, disc_loss = 0.0632682155387906
Trained batch 169 in epoch 13, gen_loss = 0.39846179502851825, disc_loss = 0.06305063473718131
Trained batch 170 in epoch 13, gen_loss = 0.39852449367618004, disc_loss = 0.06281883163344965
Trained batch 171 in epoch 13, gen_loss = 0.3987978480236475, disc_loss = 0.06274144938973666
Trained batch 172 in epoch 13, gen_loss = 0.39889370413184855, disc_loss = 0.06254208913191378
Trained batch 173 in epoch 13, gen_loss = 0.3983486517407428, disc_loss = 0.06289849574302976
Trained batch 174 in epoch 13, gen_loss = 0.39872226681028095, disc_loss = 0.06505147915333509
Trained batch 175 in epoch 13, gen_loss = 0.3989066097208045, disc_loss = 0.06483533274149522
Trained batch 176 in epoch 13, gen_loss = 0.3981986015529956, disc_loss = 0.06492154580661974
Trained batch 177 in epoch 13, gen_loss = 0.39814422890711365, disc_loss = 0.06495927720529478
Trained batch 178 in epoch 13, gen_loss = 0.3987034317834417, disc_loss = 0.06467236010826
Trained batch 179 in epoch 13, gen_loss = 0.3989649012684822, disc_loss = 0.0646838557233827
Trained batch 180 in epoch 13, gen_loss = 0.39891315576779907, disc_loss = 0.06437227292017218
Trained batch 181 in epoch 13, gen_loss = 0.3984852338230217, disc_loss = 0.06415787813570964
Trained batch 182 in epoch 13, gen_loss = 0.39830237447889777, disc_loss = 0.06416010115132795
Trained batch 183 in epoch 13, gen_loss = 0.39856279268860817, disc_loss = 0.06390146005635514
Trained batch 184 in epoch 13, gen_loss = 0.3985978031480635, disc_loss = 0.0636113068743332
Trained batch 185 in epoch 13, gen_loss = 0.3986021935619334, disc_loss = 0.06341375261344896
Trained batch 186 in epoch 13, gen_loss = 0.3988437274879313, disc_loss = 0.06381654535186164
Trained batch 187 in epoch 13, gen_loss = 0.39906282073005717, disc_loss = 0.06430034278991058
Trained batch 188 in epoch 13, gen_loss = 0.39856995334700934, disc_loss = 0.06410920447497456
Trained batch 189 in epoch 13, gen_loss = 0.399033019103502, disc_loss = 0.06382288470080025
Trained batch 190 in epoch 13, gen_loss = 0.39914534697357895, disc_loss = 0.06359298370232445
Trained batch 191 in epoch 13, gen_loss = 0.3989938572049141, disc_loss = 0.06335258641047403
Trained batch 192 in epoch 13, gen_loss = 0.3990671429300555, disc_loss = 0.0631875314899368
Trained batch 193 in epoch 13, gen_loss = 0.3993658295918986, disc_loss = 0.06318632465278365
Trained batch 194 in epoch 13, gen_loss = 0.3999395815225748, disc_loss = 0.06324734907501783
Trained batch 195 in epoch 13, gen_loss = 0.3998051243168967, disc_loss = 0.06528798177154088
Trained batch 196 in epoch 13, gen_loss = 0.3999420765995374, disc_loss = 0.06515122229602131
Trained batch 197 in epoch 13, gen_loss = 0.4002661641800042, disc_loss = 0.06538944215410286
Trained batch 198 in epoch 13, gen_loss = 0.4003360542520207, disc_loss = 0.06535703065482217
Trained batch 199 in epoch 13, gen_loss = 0.40046030074357986, disc_loss = 0.0652277890779078
Trained batch 200 in epoch 13, gen_loss = 0.40096503940980827, disc_loss = 0.0649588874156647
Trained batch 201 in epoch 13, gen_loss = 0.40088135815492953, disc_loss = 0.06517900374376832
Trained batch 202 in epoch 13, gen_loss = 0.4008591402634024, disc_loss = 0.06622062993277177
Trained batch 203 in epoch 13, gen_loss = 0.40108001611980737, disc_loss = 0.06655835947387066
Trained batch 204 in epoch 13, gen_loss = 0.4012789910886346, disc_loss = 0.06632491007628964
Trained batch 205 in epoch 13, gen_loss = 0.4017613563433434, disc_loss = 0.06609485327329451
Trained batch 206 in epoch 13, gen_loss = 0.40167977210980105, disc_loss = 0.06597777853769381
Trained batch 207 in epoch 13, gen_loss = 0.40144467224868446, disc_loss = 0.06571116680816676
Trained batch 208 in epoch 13, gen_loss = 0.4015694166484632, disc_loss = 0.0654561400556108
Trained batch 209 in epoch 13, gen_loss = 0.4014398732355663, disc_loss = 0.06602765321731567
Trained batch 210 in epoch 13, gen_loss = 0.40088619736698566, disc_loss = 0.06757504595399468
Trained batch 211 in epoch 13, gen_loss = 0.40139556929187953, disc_loss = 0.06762975953378768
Trained batch 212 in epoch 13, gen_loss = 0.4011042309758809, disc_loss = 0.06766361746709672
Trained batch 213 in epoch 13, gen_loss = 0.4011889687765425, disc_loss = 0.06768581925708557
Trained batch 214 in epoch 13, gen_loss = 0.40137717654538707, disc_loss = 0.06755338974816855
Trained batch 215 in epoch 13, gen_loss = 0.4010121681623989, disc_loss = 0.06742912144572646
Trained batch 216 in epoch 13, gen_loss = 0.4010356937959996, disc_loss = 0.06727923440837091
Trained batch 217 in epoch 13, gen_loss = 0.40067814140144836, disc_loss = 0.06713572404253373
Trained batch 218 in epoch 13, gen_loss = 0.4010088868337135, disc_loss = 0.06712242971136145
Trained batch 219 in epoch 13, gen_loss = 0.4005268936807459, disc_loss = 0.06752843663773754
Trained batch 220 in epoch 13, gen_loss = 0.4008234723121332, disc_loss = 0.06756239778855268
Trained batch 221 in epoch 13, gen_loss = 0.4010611377857827, disc_loss = 0.06732506903207248
Trained batch 222 in epoch 13, gen_loss = 0.40057210684357203, disc_loss = 0.06737465866645088
Trained batch 223 in epoch 13, gen_loss = 0.40027471272540943, disc_loss = 0.0671643936158424
Trained batch 224 in epoch 13, gen_loss = 0.40022303885883753, disc_loss = 0.06702084982560741
Trained batch 225 in epoch 13, gen_loss = 0.3998297636224105, disc_loss = 0.06692492679190055
Trained batch 226 in epoch 13, gen_loss = 0.3996465275728755, disc_loss = 0.06669712500310286
Trained batch 227 in epoch 13, gen_loss = 0.39942878523939535, disc_loss = 0.06676061814569198
Trained batch 228 in epoch 13, gen_loss = 0.39896686277535287, disc_loss = 0.06768382334569266
Trained batch 229 in epoch 13, gen_loss = 0.3988085741582124, disc_loss = 0.06834733405595889
Trained batch 230 in epoch 13, gen_loss = 0.3989258377582996, disc_loss = 0.06835931285135287
Trained batch 231 in epoch 13, gen_loss = 0.39887303614924696, disc_loss = 0.06838886559025609
Trained batch 232 in epoch 13, gen_loss = 0.3989730038612186, disc_loss = 0.06827448356832685
Trained batch 233 in epoch 13, gen_loss = 0.39915422280120033, disc_loss = 0.06825262216182473
Trained batch 234 in epoch 13, gen_loss = 0.3989391552641037, disc_loss = 0.06823371024604173
Trained batch 235 in epoch 13, gen_loss = 0.3987633204561169, disc_loss = 0.06831070203413019
Trained batch 236 in epoch 13, gen_loss = 0.39885191726282176, disc_loss = 0.0691145004956091
Trained batch 237 in epoch 13, gen_loss = 0.39896602290017263, disc_loss = 0.0688879005063106
Trained batch 238 in epoch 13, gen_loss = 0.3991877002696113, disc_loss = 0.06876855335007402
Trained batch 239 in epoch 13, gen_loss = 0.39911016349991163, disc_loss = 0.06864038588634382
Trained batch 240 in epoch 13, gen_loss = 0.3994484720635711, disc_loss = 0.06895951624511436
Trained batch 241 in epoch 13, gen_loss = 0.39920257487572913, disc_loss = 0.06950035316423198
Trained batch 242 in epoch 13, gen_loss = 0.3993713947725885, disc_loss = 0.06941895710434688
Trained batch 243 in epoch 13, gen_loss = 0.3993652896558652, disc_loss = 0.0691986330174154
Trained batch 244 in epoch 13, gen_loss = 0.3993926370630459, disc_loss = 0.06898893076850443
Trained batch 245 in epoch 13, gen_loss = 0.39952885426156887, disc_loss = 0.06876361739208423
Trained batch 246 in epoch 13, gen_loss = 0.39944308441177556, disc_loss = 0.06858899719967895
Trained batch 247 in epoch 13, gen_loss = 0.39944231582264744, disc_loss = 0.0684847408687816
Trained batch 248 in epoch 13, gen_loss = 0.3994922327947425, disc_loss = 0.06878058258892901
Trained batch 249 in epoch 13, gen_loss = 0.3991239379644394, disc_loss = 0.06905438381060958
Trained batch 250 in epoch 13, gen_loss = 0.3994383689654301, disc_loss = 0.06910103855958855
Trained batch 251 in epoch 13, gen_loss = 0.39956726429481354, disc_loss = 0.06884747318228678
Trained batch 252 in epoch 13, gen_loss = 0.39941143070756213, disc_loss = 0.06868617968788378
Trained batch 253 in epoch 13, gen_loss = 0.3994362509156775, disc_loss = 0.0684891489231739
Trained batch 254 in epoch 13, gen_loss = 0.39924926442258496, disc_loss = 0.0684695042268026
Trained batch 255 in epoch 13, gen_loss = 0.39927703712601215, disc_loss = 0.06846054646666744
Trained batch 256 in epoch 13, gen_loss = 0.3993549814252074, disc_loss = 0.06830738490295202
Trained batch 257 in epoch 13, gen_loss = 0.3992363393537758, disc_loss = 0.06823401665315032
Trained batch 258 in epoch 13, gen_loss = 0.3992406434764273, disc_loss = 0.06820684580427223
Trained batch 259 in epoch 13, gen_loss = 0.39938619102423006, disc_loss = 0.06825448490607623
Trained batch 260 in epoch 13, gen_loss = 0.3991877871683274, disc_loss = 0.06843066413554995
Trained batch 261 in epoch 13, gen_loss = 0.39937126784379245, disc_loss = 0.06832930617361464
Trained batch 262 in epoch 13, gen_loss = 0.39924864227327556, disc_loss = 0.06811304472231026
Trained batch 263 in epoch 13, gen_loss = 0.39920465648174286, disc_loss = 0.0678986173729892
Trained batch 264 in epoch 13, gen_loss = 0.3994402179178202, disc_loss = 0.06766027399813229
Trained batch 265 in epoch 13, gen_loss = 0.39948995725104686, disc_loss = 0.06742948225062144
Trained batch 266 in epoch 13, gen_loss = 0.3997437974040428, disc_loss = 0.06724695904592003
Trained batch 267 in epoch 13, gen_loss = 0.39986954629421234, disc_loss = 0.06703663781396489
Trained batch 268 in epoch 13, gen_loss = 0.4002380976003342, disc_loss = 0.06682783399525075
Trained batch 269 in epoch 13, gen_loss = 0.4003432206533573, disc_loss = 0.06664174360188621
Trained batch 270 in epoch 13, gen_loss = 0.4004414298217675, disc_loss = 0.06644117906758376
Trained batch 271 in epoch 13, gen_loss = 0.4006684722707552, disc_loss = 0.0662794888314024
Trained batch 272 in epoch 13, gen_loss = 0.4005407460661598, disc_loss = 0.06613941649964332
Trained batch 273 in epoch 13, gen_loss = 0.40050142927326426, disc_loss = 0.06591913763800786
Trained batch 274 in epoch 13, gen_loss = 0.40068022966384886, disc_loss = 0.06591667252846739
Trained batch 275 in epoch 13, gen_loss = 0.40067271067612414, disc_loss = 0.06575337352325628
Trained batch 276 in epoch 13, gen_loss = 0.40072330305292286, disc_loss = 0.06567628330984808
Trained batch 277 in epoch 13, gen_loss = 0.4006134641470669, disc_loss = 0.06583512734233153
Trained batch 278 in epoch 13, gen_loss = 0.4002279676630506, disc_loss = 0.0659493238274609
Trained batch 279 in epoch 13, gen_loss = 0.400271286708968, disc_loss = 0.06606914804516627
Trained batch 280 in epoch 13, gen_loss = 0.4006263554308338, disc_loss = 0.06595211544031032
Trained batch 281 in epoch 13, gen_loss = 0.4004191150690647, disc_loss = 0.06606530642850285
Trained batch 282 in epoch 13, gen_loss = 0.40059834318531695, disc_loss = 0.06593781153839279
Trained batch 283 in epoch 13, gen_loss = 0.4006543336829669, disc_loss = 0.06585329253895497
Trained batch 284 in epoch 13, gen_loss = 0.4000203325560218, disc_loss = 0.06639940411571348
Trained batch 285 in epoch 13, gen_loss = 0.4003994617533017, disc_loss = 0.06670183862618112
Trained batch 286 in epoch 13, gen_loss = 0.40027808888656335, disc_loss = 0.06658312164000414
Trained batch 287 in epoch 13, gen_loss = 0.40011634134377044, disc_loss = 0.06690511872875504
Trained batch 288 in epoch 13, gen_loss = 0.40026185478512394, disc_loss = 0.06804226838683897
Trained batch 289 in epoch 13, gen_loss = 0.40028598755598066, disc_loss = 0.06798202377133843
Trained batch 290 in epoch 13, gen_loss = 0.40022749912083355, disc_loss = 0.06798469321002153
Trained batch 291 in epoch 13, gen_loss = 0.40010610421838827, disc_loss = 0.06793742474768158
Trained batch 292 in epoch 13, gen_loss = 0.40017872097752605, disc_loss = 0.06777836043870795
Trained batch 293 in epoch 13, gen_loss = 0.39993011023925273, disc_loss = 0.0677640462883425
Trained batch 294 in epoch 13, gen_loss = 0.40031974987458374, disc_loss = 0.06765142787500458
Trained batch 295 in epoch 13, gen_loss = 0.4001212279639534, disc_loss = 0.06794888488130292
Trained batch 296 in epoch 13, gen_loss = 0.40004373946374516, disc_loss = 0.06824582551452348
Trained batch 297 in epoch 13, gen_loss = 0.40022528816589575, disc_loss = 0.0681422129367172
Trained batch 298 in epoch 13, gen_loss = 0.3997650382211774, disc_loss = 0.06901219712389652
Trained batch 299 in epoch 13, gen_loss = 0.39984816844264665, disc_loss = 0.06939612970687449
Trained batch 300 in epoch 13, gen_loss = 0.3995279900952431, disc_loss = 0.06934718335622866
Trained batch 301 in epoch 13, gen_loss = 0.3996018280355346, disc_loss = 0.06955727222776473
Trained batch 302 in epoch 13, gen_loss = 0.39951530605456226, disc_loss = 0.06960638057711002
Trained batch 303 in epoch 13, gen_loss = 0.39950649082464607, disc_loss = 0.06962938556190286
Trained batch 304 in epoch 13, gen_loss = 0.3994816829435161, disc_loss = 0.06968784909695387
Trained batch 305 in epoch 13, gen_loss = 0.39964068301168143, disc_loss = 0.06956904528516472
Trained batch 306 in epoch 13, gen_loss = 0.3998814805225751, disc_loss = 0.06958354440144587
Trained batch 307 in epoch 13, gen_loss = 0.3999530522564015, disc_loss = 0.06944386008824524
Trained batch 308 in epoch 13, gen_loss = 0.39990573595835555, disc_loss = 0.06929101085163725
Trained batch 309 in epoch 13, gen_loss = 0.399712972342968, disc_loss = 0.06909946527392152
Trained batch 310 in epoch 13, gen_loss = 0.3995794374555637, disc_loss = 0.06893073046621881
Trained batch 311 in epoch 13, gen_loss = 0.3994495982829577, disc_loss = 0.06887207145934017
Trained batch 312 in epoch 13, gen_loss = 0.3996506271937404, disc_loss = 0.06910454792776904
Trained batch 313 in epoch 13, gen_loss = 0.3996147731212294, disc_loss = 0.06940093839683445
Trained batch 314 in epoch 13, gen_loss = 0.3998752213186688, disc_loss = 0.06940930929508
Trained batch 315 in epoch 13, gen_loss = 0.3997504105202005, disc_loss = 0.06922380227442312
Trained batch 316 in epoch 13, gen_loss = 0.39977985738015703, disc_loss = 0.06948053448722472
Trained batch 317 in epoch 13, gen_loss = 0.3996859393873305, disc_loss = 0.06949257770693808
Trained batch 318 in epoch 13, gen_loss = 0.39971005173873003, disc_loss = 0.06929789335820181
Trained batch 319 in epoch 13, gen_loss = 0.3998403705190867, disc_loss = 0.06911384882114362
Trained batch 320 in epoch 13, gen_loss = 0.39949109857884524, disc_loss = 0.06912657917648368
Trained batch 321 in epoch 13, gen_loss = 0.3993684614759795, disc_loss = 0.06902415041308503
Trained batch 322 in epoch 13, gen_loss = 0.3994418646067658, disc_loss = 0.06884349748526841
Trained batch 323 in epoch 13, gen_loss = 0.3991623806456725, disc_loss = 0.06871911262759915
Trained batch 324 in epoch 13, gen_loss = 0.39912297666072843, disc_loss = 0.06860671120480849
Trained batch 325 in epoch 13, gen_loss = 0.39921269520111613, disc_loss = 0.0684488960256103
Trained batch 326 in epoch 13, gen_loss = 0.39924395225645937, disc_loss = 0.06834791225042273
Trained batch 327 in epoch 13, gen_loss = 0.3995120283216238, disc_loss = 0.0685278058943634
Trained batch 328 in epoch 13, gen_loss = 0.3997187268860797, disc_loss = 0.06868389185721842
Trained batch 329 in epoch 13, gen_loss = 0.399955592778596, disc_loss = 0.0685392732449779
Trained batch 330 in epoch 13, gen_loss = 0.3999593683329954, disc_loss = 0.06840218188595645
Trained batch 331 in epoch 13, gen_loss = 0.39986272699323044, disc_loss = 0.06825712689826915
Trained batch 332 in epoch 13, gen_loss = 0.39987360093149693, disc_loss = 0.06807010990844385
Trained batch 333 in epoch 13, gen_loss = 0.3998600383272428, disc_loss = 0.06788045854703663
Trained batch 334 in epoch 13, gen_loss = 0.3999205926905817, disc_loss = 0.06770817853732786
Trained batch 335 in epoch 13, gen_loss = 0.3998542599646108, disc_loss = 0.06764810817826185
Trained batch 336 in epoch 13, gen_loss = 0.3998671713055772, disc_loss = 0.06766557768097795
Trained batch 337 in epoch 13, gen_loss = 0.3997360966526545, disc_loss = 0.06754975783578038
Trained batch 338 in epoch 13, gen_loss = 0.39964000080714884, disc_loss = 0.06743118337803358
Trained batch 339 in epoch 13, gen_loss = 0.39951167689526784, disc_loss = 0.06734155152979142
Trained batch 340 in epoch 13, gen_loss = 0.3992575194216893, disc_loss = 0.06722834389492913
Trained batch 341 in epoch 13, gen_loss = 0.39928042361436533, disc_loss = 0.06745679347574363
Trained batch 342 in epoch 13, gen_loss = 0.3991069440504552, disc_loss = 0.06754626405395502
Trained batch 343 in epoch 13, gen_loss = 0.398960038802998, disc_loss = 0.06737729557248395
Trained batch 344 in epoch 13, gen_loss = 0.3989633675502694, disc_loss = 0.0672755258022875
Trained batch 345 in epoch 13, gen_loss = 0.39917053562196003, disc_loss = 0.06710017456490051
Trained batch 346 in epoch 13, gen_loss = 0.3993930540528009, disc_loss = 0.06692269961792514
Trained batch 347 in epoch 13, gen_loss = 0.39927621626819687, disc_loss = 0.06679429051642917
Trained batch 348 in epoch 13, gen_loss = 0.399213020345543, disc_loss = 0.06662241769367482
Trained batch 349 in epoch 13, gen_loss = 0.3992104890942574, disc_loss = 0.06647078489751689
Trained batch 350 in epoch 13, gen_loss = 0.39946013081956794, disc_loss = 0.06635058122657855
Trained batch 351 in epoch 13, gen_loss = 0.39923303527757525, disc_loss = 0.06656029990964188
Trained batch 352 in epoch 13, gen_loss = 0.39921131455695663, disc_loss = 0.06669162145338256
Trained batch 353 in epoch 13, gen_loss = 0.39934949143289844, disc_loss = 0.06659809328578833
Trained batch 354 in epoch 13, gen_loss = 0.3994799731063171, disc_loss = 0.0664704276812853
Trained batch 355 in epoch 13, gen_loss = 0.39925700798630714, disc_loss = 0.06634892062467178
Trained batch 356 in epoch 13, gen_loss = 0.39956619229470314, disc_loss = 0.06628954493641562
Trained batch 357 in epoch 13, gen_loss = 0.39943440587327467, disc_loss = 0.06620862528125043
Trained batch 358 in epoch 13, gen_loss = 0.39937579810287294, disc_loss = 0.06612504550325879
Trained batch 359 in epoch 13, gen_loss = 0.39952704314556386, disc_loss = 0.06610765735127239
Trained batch 360 in epoch 13, gen_loss = 0.3993941691195866, disc_loss = 0.06604581221633712
Trained batch 361 in epoch 13, gen_loss = 0.3994276374166842, disc_loss = 0.06593269662988162
Trained batch 362 in epoch 13, gen_loss = 0.39957784937268775, disc_loss = 0.06579507029546071
Trained batch 363 in epoch 13, gen_loss = 0.3993319259485701, disc_loss = 0.06578530467519599
Trained batch 364 in epoch 13, gen_loss = 0.3991728287445356, disc_loss = 0.06589259580925924
Trained batch 365 in epoch 13, gen_loss = 0.3992070701848614, disc_loss = 0.06602885364554822
Trained batch 366 in epoch 13, gen_loss = 0.3992347812701311, disc_loss = 0.06588475721474606
Trained batch 367 in epoch 13, gen_loss = 0.39888248491384415, disc_loss = 0.06606638778390808
Trained batch 368 in epoch 13, gen_loss = 0.39891317886550254, disc_loss = 0.06595181780905138
Trained batch 369 in epoch 13, gen_loss = 0.3989506459316692, disc_loss = 0.06594217811409082
Trained batch 370 in epoch 13, gen_loss = 0.3988801846205385, disc_loss = 0.06581267762823768
Trained batch 371 in epoch 13, gen_loss = 0.3988177287242105, disc_loss = 0.06581073596958391
Trained batch 372 in epoch 13, gen_loss = 0.3987812688699037, disc_loss = 0.0657399290480998
Trained batch 373 in epoch 13, gen_loss = 0.398663981673233, disc_loss = 0.0656157413629546
Trained batch 374 in epoch 13, gen_loss = 0.3985999896128972, disc_loss = 0.06560308978582421
Trained batch 375 in epoch 13, gen_loss = 0.39854473886179165, disc_loss = 0.06550549805050399
Trained batch 376 in epoch 13, gen_loss = 0.3986679866949506, disc_loss = 0.06542360119704424
Trained batch 377 in epoch 13, gen_loss = 0.3987064163284327, disc_loss = 0.06536601183359467
Trained batch 378 in epoch 13, gen_loss = 0.39865082938784346, disc_loss = 0.06549437329453223
Trained batch 379 in epoch 13, gen_loss = 0.398796700529362, disc_loss = 0.06572293267756897
Trained batch 380 in epoch 13, gen_loss = 0.3990256730418193, disc_loss = 0.06560135316568136
Trained batch 381 in epoch 13, gen_loss = 0.39883176767857287, disc_loss = 0.06554828046489487
Trained batch 382 in epoch 13, gen_loss = 0.3987698511806543, disc_loss = 0.06539367154537269
Trained batch 383 in epoch 13, gen_loss = 0.39884793808838975, disc_loss = 0.0652865081950343
Trained batch 384 in epoch 13, gen_loss = 0.39863837102016847, disc_loss = 0.06518172832302653
Trained batch 385 in epoch 13, gen_loss = 0.39877407627247774, disc_loss = 0.0650822381438311
Trained batch 386 in epoch 13, gen_loss = 0.3985744209945664, disc_loss = 0.06519194066317545
Trained batch 387 in epoch 13, gen_loss = 0.39880575750445585, disc_loss = 0.0652253219303339
Trained batch 388 in epoch 13, gen_loss = 0.39884970346729065, disc_loss = 0.0650966999642934
Trained batch 389 in epoch 13, gen_loss = 0.39883538847550365, disc_loss = 0.06510160435349323
Trained batch 390 in epoch 13, gen_loss = 0.39888385490840655, disc_loss = 0.06499142761763824
Trained batch 391 in epoch 13, gen_loss = 0.3988571231994702, disc_loss = 0.06488688970436057
Trained batch 392 in epoch 13, gen_loss = 0.39873398044182146, disc_loss = 0.06483466538266484
Trained batch 393 in epoch 13, gen_loss = 0.39882741902534125, disc_loss = 0.0647787275206449
Trained batch 394 in epoch 13, gen_loss = 0.39881242192998717, disc_loss = 0.06467951495978462
Trained batch 395 in epoch 13, gen_loss = 0.3987194561220781, disc_loss = 0.0648050281828307
Trained batch 396 in epoch 13, gen_loss = 0.3984414506093681, disc_loss = 0.06530285158759963
Trained batch 397 in epoch 13, gen_loss = 0.39875295297734104, disc_loss = 0.06571816588780052
Trained batch 398 in epoch 13, gen_loss = 0.39875082514787974, disc_loss = 0.06560985779828557
Trained batch 399 in epoch 13, gen_loss = 0.3989446559175849, disc_loss = 0.06550329280435108
Trained batch 400 in epoch 13, gen_loss = 0.3989784888124228, disc_loss = 0.06547890220213672
Trained batch 401 in epoch 13, gen_loss = 0.3990121484173471, disc_loss = 0.06533851942385718
Trained batch 402 in epoch 13, gen_loss = 0.3990667507089397, disc_loss = 0.0652465998615709
Trained batch 403 in epoch 13, gen_loss = 0.3990303084328033, disc_loss = 0.06515768470385545
Trained batch 404 in epoch 13, gen_loss = 0.3989109916083607, disc_loss = 0.0651557191045104
Trained batch 405 in epoch 13, gen_loss = 0.39896347704045293, disc_loss = 0.0651318436807361
Trained batch 406 in epoch 13, gen_loss = 0.3988286853202731, disc_loss = 0.0650858696245792
Trained batch 407 in epoch 13, gen_loss = 0.3986877959367691, disc_loss = 0.0650958228415773
Trained batch 408 in epoch 13, gen_loss = 0.39847213441556123, disc_loss = 0.06516480950802601
Trained batch 409 in epoch 13, gen_loss = 0.39865418021998755, disc_loss = 0.06535935062438068
Trained batch 410 in epoch 13, gen_loss = 0.39860474965433135, disc_loss = 0.06545491002096711
Trained batch 411 in epoch 13, gen_loss = 0.39850024839194076, disc_loss = 0.06541715675707256
Trained batch 412 in epoch 13, gen_loss = 0.39849029127824104, disc_loss = 0.06534092815042661
Trained batch 413 in epoch 13, gen_loss = 0.3984894962342465, disc_loss = 0.0652145778902037
Trained batch 414 in epoch 13, gen_loss = 0.3983515784323934, disc_loss = 0.06530921359445496
Trained batch 415 in epoch 13, gen_loss = 0.39869376060624534, disc_loss = 0.06523620195646519
Trained batch 416 in epoch 13, gen_loss = 0.39889623460580975, disc_loss = 0.06513030346308787
Trained batch 417 in epoch 13, gen_loss = 0.3986092731356621, disc_loss = 0.06533852431580033
Trained batch 418 in epoch 13, gen_loss = 0.3986562278859655, disc_loss = 0.06585116807020187
Trained batch 419 in epoch 13, gen_loss = 0.3985991960834889, disc_loss = 0.0657631926183101
Trained batch 420 in epoch 13, gen_loss = 0.39854597064916425, disc_loss = 0.06587314874159433
Trained batch 421 in epoch 13, gen_loss = 0.39865114462177903, disc_loss = 0.06573961327907352
Trained batch 422 in epoch 13, gen_loss = 0.3987680946611062, disc_loss = 0.06575442729605886
Trained batch 423 in epoch 13, gen_loss = 0.3985835137724314, disc_loss = 0.06574902387076707
Trained batch 424 in epoch 13, gen_loss = 0.3984475871044047, disc_loss = 0.06561475511311608
Trained batch 425 in epoch 13, gen_loss = 0.39854771951694445, disc_loss = 0.06550251242503559
Trained batch 426 in epoch 13, gen_loss = 0.3988064576716836, disc_loss = 0.06536658193514763
Trained batch 427 in epoch 13, gen_loss = 0.3987399186834554, disc_loss = 0.06533972558426175
Trained batch 428 in epoch 13, gen_loss = 0.398611835840143, disc_loss = 0.0655032418698663
Trained batch 429 in epoch 13, gen_loss = 0.39849897217611935, disc_loss = 0.06560035164056476
Trained batch 430 in epoch 13, gen_loss = 0.3984147549851035, disc_loss = 0.06553867944838207
Trained batch 431 in epoch 13, gen_loss = 0.3983818391613938, disc_loss = 0.06550523378084311
Trained batch 432 in epoch 13, gen_loss = 0.3984117536497997, disc_loss = 0.06547524162953156
Trained batch 433 in epoch 13, gen_loss = 0.3982781675485422, disc_loss = 0.06538620569060818
Trained batch 434 in epoch 13, gen_loss = 0.39836120465021024, disc_loss = 0.06547447095528759
Trained batch 435 in epoch 13, gen_loss = 0.39823234323924833, disc_loss = 0.06550273911198687
Trained batch 436 in epoch 13, gen_loss = 0.39823055482156217, disc_loss = 0.06543341782199777
Trained batch 437 in epoch 13, gen_loss = 0.3981340461874117, disc_loss = 0.06546165522179442
Trained batch 438 in epoch 13, gen_loss = 0.3981828942453671, disc_loss = 0.06534243008049719
Trained batch 439 in epoch 13, gen_loss = 0.39825950457968495, disc_loss = 0.06526124890978363
Trained batch 440 in epoch 13, gen_loss = 0.3982237347331988, disc_loss = 0.06520697099838803
Trained batch 441 in epoch 13, gen_loss = 0.398009335934037, disc_loss = 0.06522711033077397
Trained batch 442 in epoch 13, gen_loss = 0.39809195448394286, disc_loss = 0.0651761146459905
Trained batch 443 in epoch 13, gen_loss = 0.39806587037605207, disc_loss = 0.06506338833017392
Trained batch 444 in epoch 13, gen_loss = 0.3979659882489215, disc_loss = 0.06496916645196046
Trained batch 445 in epoch 13, gen_loss = 0.3979651175205483, disc_loss = 0.06485812161994822
Trained batch 446 in epoch 13, gen_loss = 0.39788193507349195, disc_loss = 0.06474338354171989
Trained batch 447 in epoch 13, gen_loss = 0.3978953260728823, disc_loss = 0.06467403242589041
Trained batch 448 in epoch 13, gen_loss = 0.3977051207044873, disc_loss = 0.0647627763462591
Trained batch 449 in epoch 13, gen_loss = 0.3978776142663426, disc_loss = 0.06508787423993151
Trained batch 450 in epoch 13, gen_loss = 0.397849725943447, disc_loss = 0.06510595627699023
Trained batch 451 in epoch 13, gen_loss = 0.3979015818805294, disc_loss = 0.06499363039826266
Trained batch 452 in epoch 13, gen_loss = 0.3979598232781387, disc_loss = 0.06488515486813276
Trained batch 453 in epoch 13, gen_loss = 0.39796377531363575, disc_loss = 0.06482864936838328
Trained batch 454 in epoch 13, gen_loss = 0.3982891660797727, disc_loss = 0.06471952404417507
Trained batch 455 in epoch 13, gen_loss = 0.39843874388750183, disc_loss = 0.06463934889414527
Trained batch 456 in epoch 13, gen_loss = 0.3984530562579762, disc_loss = 0.06464071343377786
Trained batch 457 in epoch 13, gen_loss = 0.3986553394573224, disc_loss = 0.06455707241166952
Trained batch 458 in epoch 13, gen_loss = 0.39877412154913466, disc_loss = 0.06462094223650258
Trained batch 459 in epoch 13, gen_loss = 0.3988039684360442, disc_loss = 0.06465125641299654
Trained batch 460 in epoch 13, gen_loss = 0.3987289644179789, disc_loss = 0.06454085926333374
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.4221959710121155, disc_loss = 0.007649446837604046
Trained batch 1 in epoch 14, gen_loss = 0.4080124795436859, disc_loss = 0.013302689883857965
Trained batch 2 in epoch 14, gen_loss = 0.43180055419603985, disc_loss = 0.01228786197801431
Trained batch 3 in epoch 14, gen_loss = 0.4190971553325653, disc_loss = 0.01501286868005991
Trained batch 4 in epoch 14, gen_loss = 0.4236019909381866, disc_loss = 0.021619582176208497
Trained batch 5 in epoch 14, gen_loss = 0.4252418329318364, disc_loss = 0.02896170566479365
Trained batch 6 in epoch 14, gen_loss = 0.4229829694543566, disc_loss = 0.02649542715932642
Trained batch 7 in epoch 14, gen_loss = 0.4191686734557152, disc_loss = 0.0267761442810297
Trained batch 8 in epoch 14, gen_loss = 0.4220384491814507, disc_loss = 0.025740242666668363
Trained batch 9 in epoch 14, gen_loss = 0.43323572874069216, disc_loss = 0.025705423019826413
Trained batch 10 in epoch 14, gen_loss = 0.4134224057197571, disc_loss = 0.05107716454023665
Trained batch 11 in epoch 14, gen_loss = 0.4145629679163297, disc_loss = 0.05404541688039899
Trained batch 12 in epoch 14, gen_loss = 0.4166915279168349, disc_loss = 0.05355072293717127
Trained batch 13 in epoch 14, gen_loss = 0.41553342768124174, disc_loss = 0.05451380288494485
Trained batch 14 in epoch 14, gen_loss = 0.41050607164700825, disc_loss = 0.05376415140926838
Trained batch 15 in epoch 14, gen_loss = 0.4132651537656784, disc_loss = 0.0511401611729525
Trained batch 16 in epoch 14, gen_loss = 0.4136830235228819, disc_loss = 0.04968961804886075
Trained batch 17 in epoch 14, gen_loss = 0.41581930551264024, disc_loss = 0.0496916422723896
Trained batch 18 in epoch 14, gen_loss = 0.4153715921075721, disc_loss = 0.05043324862459773
Trained batch 19 in epoch 14, gen_loss = 0.41936432123184203, disc_loss = 0.054669150291010736
Trained batch 20 in epoch 14, gen_loss = 0.42057799299558, disc_loss = 0.05505210334169013
Trained batch 21 in epoch 14, gen_loss = 0.4198766594583338, disc_loss = 0.05416570006954399
Trained batch 22 in epoch 14, gen_loss = 0.4178995360498843, disc_loss = 0.05315159532524969
Trained batch 23 in epoch 14, gen_loss = 0.4208115339279175, disc_loss = 0.05248609072684
Trained batch 24 in epoch 14, gen_loss = 0.4183018493652344, disc_loss = 0.05442640852183103
Trained batch 25 in epoch 14, gen_loss = 0.4237249975021069, disc_loss = 0.05944358682833039
Trained batch 26 in epoch 14, gen_loss = 0.42157664453541793, disc_loss = 0.058636079611325706
Trained batch 27 in epoch 14, gen_loss = 0.4209210606557982, disc_loss = 0.057376098253631165
Trained batch 28 in epoch 14, gen_loss = 0.4211725479569928, disc_loss = 0.056614101414793526
Trained batch 29 in epoch 14, gen_loss = 0.417804287870725, disc_loss = 0.05656809108331799
Trained batch 30 in epoch 14, gen_loss = 0.41942553847066816, disc_loss = 0.05732428567904618
Trained batch 31 in epoch 14, gen_loss = 0.420468651689589, disc_loss = 0.05922792453202419
Trained batch 32 in epoch 14, gen_loss = 0.41947354692401306, disc_loss = 0.05950058271374666
Trained batch 33 in epoch 14, gen_loss = 0.41931283999891844, disc_loss = 0.05812551861848025
Trained batch 34 in epoch 14, gen_loss = 0.41912159834589274, disc_loss = 0.05672899678881679
Trained batch 35 in epoch 14, gen_loss = 0.41843971692853504, disc_loss = 0.05609639922881292
Trained batch 36 in epoch 14, gen_loss = 0.4182524495833629, disc_loss = 0.0564085072208498
Trained batch 37 in epoch 14, gen_loss = 0.4149090647697449, disc_loss = 0.05658866193047479
Trained batch 38 in epoch 14, gen_loss = 0.41516074003317416, disc_loss = 0.05552977977845913
Trained batch 39 in epoch 14, gen_loss = 0.41815122216939926, disc_loss = 0.05744986054487526
Trained batch 40 in epoch 14, gen_loss = 0.41683736370831004, disc_loss = 0.05961748453356871
Trained batch 41 in epoch 14, gen_loss = 0.41626520738715217, disc_loss = 0.059101692134780545
Trained batch 42 in epoch 14, gen_loss = 0.4174375125142031, disc_loss = 0.0588774201568476
Trained batch 43 in epoch 14, gen_loss = 0.4163510332053358, disc_loss = 0.057799246670170265
Trained batch 44 in epoch 14, gen_loss = 0.4148287104235755, disc_loss = 0.05756373976667722
Trained batch 45 in epoch 14, gen_loss = 0.4126215117133182, disc_loss = 0.05649780073081669
Trained batch 46 in epoch 14, gen_loss = 0.4144991820162915, disc_loss = 0.055506944814895064
Trained batch 47 in epoch 14, gen_loss = 0.41332284547388554, disc_loss = 0.05452571211693188
Trained batch 48 in epoch 14, gen_loss = 0.4127144485103841, disc_loss = 0.053537473016019375
Trained batch 49 in epoch 14, gen_loss = 0.4130777704715729, disc_loss = 0.053854012126103044
Trained batch 50 in epoch 14, gen_loss = 0.41122882740170347, disc_loss = 0.055669850806760436
Trained batch 51 in epoch 14, gen_loss = 0.4101602417918352, disc_loss = 0.05534800536966381
Trained batch 52 in epoch 14, gen_loss = 0.41048473569582095, disc_loss = 0.054727652452815814
Trained batch 53 in epoch 14, gen_loss = 0.4097445651336952, disc_loss = 0.05401677152797304
Trained batch 54 in epoch 14, gen_loss = 0.40894296873699537, disc_loss = 0.053563293044201356
Trained batch 55 in epoch 14, gen_loss = 0.40866456446903093, disc_loss = 0.052859682781023105
Trained batch 56 in epoch 14, gen_loss = 0.4090149637899901, disc_loss = 0.05217129984674485
Trained batch 57 in epoch 14, gen_loss = 0.4091146742475444, disc_loss = 0.05154696122165127
Trained batch 58 in epoch 14, gen_loss = 0.40915714330592395, disc_loss = 0.05121250421408627
Trained batch 59 in epoch 14, gen_loss = 0.4107547715306282, disc_loss = 0.050814516244766614
Trained batch 60 in epoch 14, gen_loss = 0.4103760098824736, disc_loss = 0.05028097834590761
Trained batch 61 in epoch 14, gen_loss = 0.40971574619893103, disc_loss = 0.04968544470536853
Trained batch 62 in epoch 14, gen_loss = 0.41046914978632854, disc_loss = 0.04919327345366279
Trained batch 63 in epoch 14, gen_loss = 0.41089092241600156, disc_loss = 0.049033481620426755
Trained batch 64 in epoch 14, gen_loss = 0.41015762182382437, disc_loss = 0.05190640618451513
Trained batch 65 in epoch 14, gen_loss = 0.41098438519420044, disc_loss = 0.05795576196925884
Trained batch 66 in epoch 14, gen_loss = 0.41102971247772674, disc_loss = 0.05802781501117704
Trained batch 67 in epoch 14, gen_loss = 0.40957994233159456, disc_loss = 0.05838879613507101
Trained batch 68 in epoch 14, gen_loss = 0.4092668173969656, disc_loss = 0.058077402406142675
Trained batch 69 in epoch 14, gen_loss = 0.4093646820102419, disc_loss = 0.05750141462444195
Trained batch 70 in epoch 14, gen_loss = 0.4093400949323681, disc_loss = 0.056981680540918886
Trained batch 71 in epoch 14, gen_loss = 0.40836190101173186, disc_loss = 0.056801931693270385
Trained batch 72 in epoch 14, gen_loss = 0.4087793316743145, disc_loss = 0.057760499079698976
Trained batch 73 in epoch 14, gen_loss = 0.4090449741563281, disc_loss = 0.062418183733432275
Trained batch 74 in epoch 14, gen_loss = 0.40884411573410034, disc_loss = 0.06322364446396629
Trained batch 75 in epoch 14, gen_loss = 0.4091517937026526, disc_loss = 0.06388075332966094
Trained batch 76 in epoch 14, gen_loss = 0.40803698324537896, disc_loss = 0.06432192382559955
Trained batch 77 in epoch 14, gen_loss = 0.4083058367937039, disc_loss = 0.0641782399541579
Trained batch 78 in epoch 14, gen_loss = 0.4085006200814549, disc_loss = 0.06462957070480231
Trained batch 79 in epoch 14, gen_loss = 0.4072899825870991, disc_loss = 0.06473901087301784
Trained batch 80 in epoch 14, gen_loss = 0.40728213021784654, disc_loss = 0.06429577537777799
Trained batch 81 in epoch 14, gen_loss = 0.40769194284590277, disc_loss = 0.06405800668999734
Trained batch 82 in epoch 14, gen_loss = 0.40676218486693966, disc_loss = 0.06437777599364698
Trained batch 83 in epoch 14, gen_loss = 0.4074014553001949, disc_loss = 0.06558917717276407
Trained batch 84 in epoch 14, gen_loss = 0.4068645386134877, disc_loss = 0.06658556607606657
Trained batch 85 in epoch 14, gen_loss = 0.4057633415904156, disc_loss = 0.06608274745278407
Trained batch 86 in epoch 14, gen_loss = 0.404952649412484, disc_loss = 0.06578694097162492
Trained batch 87 in epoch 14, gen_loss = 0.40449842742898245, disc_loss = 0.0651015739792704
Trained batch 88 in epoch 14, gen_loss = 0.40425603979089286, disc_loss = 0.06459889451585961
Trained batch 89 in epoch 14, gen_loss = 0.40350505775875517, disc_loss = 0.06398970398327543
Trained batch 90 in epoch 14, gen_loss = 0.4032154685848362, disc_loss = 0.06341135410264462
Trained batch 91 in epoch 14, gen_loss = 0.4021005717956502, disc_loss = 0.06309676257913689
Trained batch 92 in epoch 14, gen_loss = 0.4010446065215654, disc_loss = 0.06300890784690617
Trained batch 93 in epoch 14, gen_loss = 0.4015852060723812, disc_loss = 0.0628601650538993
Trained batch 94 in epoch 14, gen_loss = 0.4007861852645874, disc_loss = 0.06250631076430804
Trained batch 95 in epoch 14, gen_loss = 0.39999113449205953, disc_loss = 0.06211068551541151
Trained batch 96 in epoch 14, gen_loss = 0.4001868155199228, disc_loss = 0.06158467240573973
Trained batch 97 in epoch 14, gen_loss = 0.4010789783633485, disc_loss = 0.0611377886486981
Trained batch 98 in epoch 14, gen_loss = 0.4011489739923766, disc_loss = 0.061031063214283095
Trained batch 99 in epoch 14, gen_loss = 0.4013190308213234, disc_loss = 0.06070552066434175
Trained batch 100 in epoch 14, gen_loss = 0.4006744112708781, disc_loss = 0.060436210903975336
Trained batch 101 in epoch 14, gen_loss = 0.40101392012016446, disc_loss = 0.06006896105485365
Trained batch 102 in epoch 14, gen_loss = 0.4011646558358831, disc_loss = 0.05955656797815006
Trained batch 103 in epoch 14, gen_loss = 0.4012676626443863, disc_loss = 0.05914385984830845
Trained batch 104 in epoch 14, gen_loss = 0.40141875800632293, disc_loss = 0.05920307809220893
Trained batch 105 in epoch 14, gen_loss = 0.40160664185038153, disc_loss = 0.06009743210666303
Trained batch 106 in epoch 14, gen_loss = 0.40058165760797876, disc_loss = 0.061261365929984046
Trained batch 107 in epoch 14, gen_loss = 0.4011140783075933, disc_loss = 0.06124167457326419
Trained batch 108 in epoch 14, gen_loss = 0.401884708109252, disc_loss = 0.061123237483750245
Trained batch 109 in epoch 14, gen_loss = 0.4011225394227288, disc_loss = 0.06093196346509186
Trained batch 110 in epoch 14, gen_loss = 0.40156472668991433, disc_loss = 0.06083023211675453
Trained batch 111 in epoch 14, gen_loss = 0.40192525780626703, disc_loss = 0.06064048265605899
Trained batch 112 in epoch 14, gen_loss = 0.40249581384447825, disc_loss = 0.06019781831553025
Trained batch 113 in epoch 14, gen_loss = 0.4029700641046491, disc_loss = 0.06018677116943556
Trained batch 114 in epoch 14, gen_loss = 0.4032777731833251, disc_loss = 0.05998972594414068
Trained batch 115 in epoch 14, gen_loss = 0.40303950782479914, disc_loss = 0.059772615529725265
Trained batch 116 in epoch 14, gen_loss = 0.4023855094216828, disc_loss = 0.05954367872805168
Trained batch 117 in epoch 14, gen_loss = 0.4020398173291804, disc_loss = 0.05957021085955834
Trained batch 118 in epoch 14, gen_loss = 0.40154731223563184, disc_loss = 0.059200093275358696
Trained batch 119 in epoch 14, gen_loss = 0.40143538564443587, disc_loss = 0.05883443742835273
Trained batch 120 in epoch 14, gen_loss = 0.4006891457502507, disc_loss = 0.058583030300137916
Trained batch 121 in epoch 14, gen_loss = 0.4014797420775304, disc_loss = 0.05841261459148077
Trained batch 122 in epoch 14, gen_loss = 0.4011998554555381, disc_loss = 0.058583989550124824
Trained batch 123 in epoch 14, gen_loss = 0.4016959426864501, disc_loss = 0.05858176074651701
Trained batch 124 in epoch 14, gen_loss = 0.4021483974456787, disc_loss = 0.05828265749663115
Trained batch 125 in epoch 14, gen_loss = 0.40280519898921724, disc_loss = 0.05801879368456347
Trained batch 126 in epoch 14, gen_loss = 0.40336267427196654, disc_loss = 0.057633683694101226
Trained batch 127 in epoch 14, gen_loss = 0.4031340319197625, disc_loss = 0.05742902732890798
Trained batch 128 in epoch 14, gen_loss = 0.4032583717227906, disc_loss = 0.05715151638687812
Trained batch 129 in epoch 14, gen_loss = 0.4030539377377583, disc_loss = 0.05716480463026808
Trained batch 130 in epoch 14, gen_loss = 0.40324263217794987, disc_loss = 0.05687269081454013
Trained batch 131 in epoch 14, gen_loss = 0.40321574540752353, disc_loss = 0.05662576630570446
Trained batch 132 in epoch 14, gen_loss = 0.4032054447141805, disc_loss = 0.05639454063476253
Trained batch 133 in epoch 14, gen_loss = 0.4026474163158616, disc_loss = 0.05620304941992039
Trained batch 134 in epoch 14, gen_loss = 0.4027434466061769, disc_loss = 0.055901187113313766
Trained batch 135 in epoch 14, gen_loss = 0.4027629902257639, disc_loss = 0.05601569320595659
Trained batch 136 in epoch 14, gen_loss = 0.40373288801986806, disc_loss = 0.05645375237222353
Trained batch 137 in epoch 14, gen_loss = 0.4029191995876423, disc_loss = 0.05643077044194375
Trained batch 138 in epoch 14, gen_loss = 0.40321307602546197, disc_loss = 0.05609272588580418
Trained batch 139 in epoch 14, gen_loss = 0.4033425624881472, disc_loss = 0.05584578742273152
Trained batch 140 in epoch 14, gen_loss = 0.4026952375334205, disc_loss = 0.05595498494407598
Trained batch 141 in epoch 14, gen_loss = 0.40174903689135966, disc_loss = 0.05852058508210409
Trained batch 142 in epoch 14, gen_loss = 0.4025745706541555, disc_loss = 0.059023530535087305
Trained batch 143 in epoch 14, gen_loss = 0.40262740374439293, disc_loss = 0.05972146552651086
Trained batch 144 in epoch 14, gen_loss = 0.40235904537398237, disc_loss = 0.06335442373850222
Trained batch 145 in epoch 14, gen_loss = 0.40287594640091673, disc_loss = 0.06485894627945676
Trained batch 146 in epoch 14, gen_loss = 0.4033736562242313, disc_loss = 0.07284593277414438
Trained batch 147 in epoch 14, gen_loss = 0.40383933363734065, disc_loss = 0.07774998428224511
Trained batch 148 in epoch 14, gen_loss = 0.40353109112521945, disc_loss = 0.07917643712846024
Trained batch 149 in epoch 14, gen_loss = 0.40286382953325905, disc_loss = 0.08024492561196288
Trained batch 150 in epoch 14, gen_loss = 0.4021921684805131, disc_loss = 0.08112976507018536
Trained batch 151 in epoch 14, gen_loss = 0.4020816683769226, disc_loss = 0.08153679985920653
Trained batch 152 in epoch 14, gen_loss = 0.4019453430097867, disc_loss = 0.08176260017272499
Trained batch 153 in epoch 14, gen_loss = 0.40190420019162165, disc_loss = 0.08198903752007074
Trained batch 154 in epoch 14, gen_loss = 0.4013159788423969, disc_loss = 0.08253223280152006
Trained batch 155 in epoch 14, gen_loss = 0.40137690725999003, disc_loss = 0.08269642608073087
Trained batch 156 in epoch 14, gen_loss = 0.40097411214166384, disc_loss = 0.0827776378163012
Trained batch 157 in epoch 14, gen_loss = 0.4007309282882304, disc_loss = 0.08321080955122656
Trained batch 158 in epoch 14, gen_loss = 0.401327150797694, disc_loss = 0.0831250662640112
Trained batch 159 in epoch 14, gen_loss = 0.4012940699234605, disc_loss = 0.08330021919100546
Trained batch 160 in epoch 14, gen_loss = 0.4009083687148479, disc_loss = 0.08362402817269105
Trained batch 161 in epoch 14, gen_loss = 0.4006549452925906, disc_loss = 0.08484831902508934
Trained batch 162 in epoch 14, gen_loss = 0.3997809285400835, disc_loss = 0.08596088631547119
Trained batch 163 in epoch 14, gen_loss = 0.399122321932781, disc_loss = 0.08769921349111671
Trained batch 164 in epoch 14, gen_loss = 0.39899433490001796, disc_loss = 0.08863843823359771
Trained batch 165 in epoch 14, gen_loss = 0.39876946753048037, disc_loss = 0.08900086150269013
Trained batch 166 in epoch 14, gen_loss = 0.3988834980005276, disc_loss = 0.08928062012251801
Trained batch 167 in epoch 14, gen_loss = 0.3985968464542003, disc_loss = 0.08979320046602793
Trained batch 168 in epoch 14, gen_loss = 0.3979366605098431, disc_loss = 0.09011980485082907
Trained batch 169 in epoch 14, gen_loss = 0.3976928873973734, disc_loss = 0.09042944539447918
Trained batch 170 in epoch 14, gen_loss = 0.3976722246373606, disc_loss = 0.09037743621554814
Trained batch 171 in epoch 14, gen_loss = 0.39734808320915976, disc_loss = 0.09017676049518551
Trained batch 172 in epoch 14, gen_loss = 0.3971876469306174, disc_loss = 0.0901524421484398
Trained batch 173 in epoch 14, gen_loss = 0.39743087500676344, disc_loss = 0.091712877363095
Trained batch 174 in epoch 14, gen_loss = 0.3976868937696729, disc_loss = 0.09162479080791984
Trained batch 175 in epoch 14, gen_loss = 0.3969186195595698, disc_loss = 0.092062847556504
Trained batch 176 in epoch 14, gen_loss = 0.39715030166388904, disc_loss = 0.09198762800039376
Trained batch 177 in epoch 14, gen_loss = 0.39752360726340435, disc_loss = 0.0916015253548793
Trained batch 178 in epoch 14, gen_loss = 0.39745331526468586, disc_loss = 0.09134242812161172
Trained batch 179 in epoch 14, gen_loss = 0.39742374999655616, disc_loss = 0.09115323957780169
Trained batch 180 in epoch 14, gen_loss = 0.39746761684259657, disc_loss = 0.09098993533532758
Trained batch 181 in epoch 14, gen_loss = 0.3974116929284819, disc_loss = 0.09078255759879619
Trained batch 182 in epoch 14, gen_loss = 0.39731852930100237, disc_loss = 0.09062512342619602
Trained batch 183 in epoch 14, gen_loss = 0.39762830896222073, disc_loss = 0.09080499302818561
Trained batch 184 in epoch 14, gen_loss = 0.3970397792957924, disc_loss = 0.09062476075078185
Trained batch 185 in epoch 14, gen_loss = 0.3969024870023933, disc_loss = 0.09068800959115227
Trained batch 186 in epoch 14, gen_loss = 0.39704409401047036, disc_loss = 0.09187784314374714
Trained batch 187 in epoch 14, gen_loss = 0.39707417801973666, disc_loss = 0.09165442092443242
Trained batch 188 in epoch 14, gen_loss = 0.39707016850274707, disc_loss = 0.09154463957049071
Trained batch 189 in epoch 14, gen_loss = 0.3967091983870456, disc_loss = 0.09213242930311122
Trained batch 190 in epoch 14, gen_loss = 0.3964717542625847, disc_loss = 0.09262457364653262
Trained batch 191 in epoch 14, gen_loss = 0.39654151862487197, disc_loss = 0.09225599430404448
Trained batch 192 in epoch 14, gen_loss = 0.3962586543720621, disc_loss = 0.09228305218963272
Trained batch 193 in epoch 14, gen_loss = 0.39616737491691234, disc_loss = 0.09202221027796262
Trained batch 194 in epoch 14, gen_loss = 0.39618823451873586, disc_loss = 0.09196144234962188
Trained batch 195 in epoch 14, gen_loss = 0.3957442928637777, disc_loss = 0.09284737842556622
Trained batch 196 in epoch 14, gen_loss = 0.39605838287300266, disc_loss = 0.09320701718765316
Trained batch 197 in epoch 14, gen_loss = 0.3955718221688511, disc_loss = 0.09306047901492377
Trained batch 198 in epoch 14, gen_loss = 0.3957525915536449, disc_loss = 0.09289199850947863
Trained batch 199 in epoch 14, gen_loss = 0.395593354254961, disc_loss = 0.0926387515058741
Trained batch 200 in epoch 14, gen_loss = 0.39529936378868064, disc_loss = 0.09264212462643337
Trained batch 201 in epoch 14, gen_loss = 0.3954941845766389, disc_loss = 0.09248293498715404
Trained batch 202 in epoch 14, gen_loss = 0.39525903372341775, disc_loss = 0.09286931661310895
Trained batch 203 in epoch 14, gen_loss = 0.39578021522246154, disc_loss = 0.09309435224470992
Trained batch 204 in epoch 14, gen_loss = 0.3950735164851677, disc_loss = 0.09340431288157294
Trained batch 205 in epoch 14, gen_loss = 0.3947883977473361, disc_loss = 0.09322276387309421
Trained batch 206 in epoch 14, gen_loss = 0.39493046866522896, disc_loss = 0.09295369239730968
Trained batch 207 in epoch 14, gen_loss = 0.3951035663485527, disc_loss = 0.09276725492852095
Trained batch 208 in epoch 14, gen_loss = 0.39508814917226726, disc_loss = 0.092481196314346
Trained batch 209 in epoch 14, gen_loss = 0.3947788193112328, disc_loss = 0.09272949471626253
Trained batch 210 in epoch 14, gen_loss = 0.3948921260393061, disc_loss = 0.09338106818373593
Trained batch 211 in epoch 14, gen_loss = 0.39459330785386965, disc_loss = 0.09309935007015911
Trained batch 212 in epoch 14, gen_loss = 0.3946447857948536, disc_loss = 0.09299719403169944
Trained batch 213 in epoch 14, gen_loss = 0.39472231422072257, disc_loss = 0.09269081265447993
Trained batch 214 in epoch 14, gen_loss = 0.39501958683479665, disc_loss = 0.09232783292008694
Trained batch 215 in epoch 14, gen_loss = 0.39467829810800376, disc_loss = 0.09207659872266015
Trained batch 216 in epoch 14, gen_loss = 0.3945461834355983, disc_loss = 0.092049835623169
Trained batch 217 in epoch 14, gen_loss = 0.3946176104315924, disc_loss = 0.09175214436708377
Trained batch 218 in epoch 14, gen_loss = 0.39451774655411775, disc_loss = 0.09151059454179382
Trained batch 219 in epoch 14, gen_loss = 0.3944039451805028, disc_loss = 0.09155997126363218
Trained batch 220 in epoch 14, gen_loss = 0.39449718756373653, disc_loss = 0.09133227711029317
Trained batch 221 in epoch 14, gen_loss = 0.3947947095106314, disc_loss = 0.09096335451882165
Trained batch 222 in epoch 14, gen_loss = 0.3949806487079158, disc_loss = 0.09060066854455946
Trained batch 223 in epoch 14, gen_loss = 0.39543085678347517, disc_loss = 0.09036105178945165
Trained batch 224 in epoch 14, gen_loss = 0.3954722266727024, disc_loss = 0.09018937226384878
Trained batch 225 in epoch 14, gen_loss = 0.3953890920476576, disc_loss = 0.08994778729892805
Trained batch 226 in epoch 14, gen_loss = 0.3957432293156695, disc_loss = 0.08965505747789197
Trained batch 227 in epoch 14, gen_loss = 0.3958761714268149, disc_loss = 0.08940874580538978
Trained batch 228 in epoch 14, gen_loss = 0.39605785821723105, disc_loss = 0.08904912162116652
Trained batch 229 in epoch 14, gen_loss = 0.3959571840970413, disc_loss = 0.08922992872236216
Trained batch 230 in epoch 14, gen_loss = 0.39580717657035563, disc_loss = 0.09018189765238788
Trained batch 231 in epoch 14, gen_loss = 0.39562727986224766, disc_loss = 0.08986144924359717
Trained batch 232 in epoch 14, gen_loss = 0.39588344902951317, disc_loss = 0.08968881153513561
Trained batch 233 in epoch 14, gen_loss = 0.3960190551657962, disc_loss = 0.08934433828705014
Trained batch 234 in epoch 14, gen_loss = 0.39588666520220167, disc_loss = 0.08916318654776254
Trained batch 235 in epoch 14, gen_loss = 0.39632875282885666, disc_loss = 0.08893743422971565
Trained batch 236 in epoch 14, gen_loss = 0.3963194909478039, disc_loss = 0.08866286815737497
Trained batch 237 in epoch 14, gen_loss = 0.3961954889427714, disc_loss = 0.08836542610313837
Trained batch 238 in epoch 14, gen_loss = 0.39641887610427506, disc_loss = 0.08808626895809397
Trained batch 239 in epoch 14, gen_loss = 0.39643139963348706, disc_loss = 0.08787408277469998
Trained batch 240 in epoch 14, gen_loss = 0.3964091543092767, disc_loss = 0.0876354556955799
Trained batch 241 in epoch 14, gen_loss = 0.3963319553324014, disc_loss = 0.08733568695366137
Trained batch 242 in epoch 14, gen_loss = 0.3963587712113259, disc_loss = 0.08703694781556787
Trained batch 243 in epoch 14, gen_loss = 0.3962712352637385, disc_loss = 0.08679937389602915
Trained batch 244 in epoch 14, gen_loss = 0.39624407972608294, disc_loss = 0.08674132296321344
Trained batch 245 in epoch 14, gen_loss = 0.39613572780678913, disc_loss = 0.08725388828150141
Trained batch 246 in epoch 14, gen_loss = 0.3966147947890556, disc_loss = 0.08728810760234049
Trained batch 247 in epoch 14, gen_loss = 0.3968964195059192, disc_loss = 0.08702977739965483
Trained batch 248 in epoch 14, gen_loss = 0.39674584286279946, disc_loss = 0.08683613483535957
Trained batch 249 in epoch 14, gen_loss = 0.39641493558883667, disc_loss = 0.08670262687653303
Trained batch 250 in epoch 14, gen_loss = 0.39691690975926314, disc_loss = 0.08639414230754888
Trained batch 251 in epoch 14, gen_loss = 0.39679858254061806, disc_loss = 0.08616669903997154
Trained batch 252 in epoch 14, gen_loss = 0.3966089752116222, disc_loss = 0.08604023946456522
Trained batch 253 in epoch 14, gen_loss = 0.3967674597511141, disc_loss = 0.08573174698087643
Trained batch 254 in epoch 14, gen_loss = 0.3969457652054581, disc_loss = 0.08583848743754274
Trained batch 255 in epoch 14, gen_loss = 0.3968051529955119, disc_loss = 0.0865348467923468
Trained batch 256 in epoch 14, gen_loss = 0.3967205956288349, disc_loss = 0.0875516355124661
Trained batch 257 in epoch 14, gen_loss = 0.39683461755283117, disc_loss = 0.0873354528705741
Trained batch 258 in epoch 14, gen_loss = 0.39650325287262905, disc_loss = 0.08737324416982621
Trained batch 259 in epoch 14, gen_loss = 0.3966748777490396, disc_loss = 0.08729358103412849
Trained batch 260 in epoch 14, gen_loss = 0.39673881489655066, disc_loss = 0.08705294842321526
Trained batch 261 in epoch 14, gen_loss = 0.3967618502050866, disc_loss = 0.0868901799127232
Trained batch 262 in epoch 14, gen_loss = 0.39658830419692703, disc_loss = 0.08660851991221932
Trained batch 263 in epoch 14, gen_loss = 0.39665476955247647, disc_loss = 0.0865390570834279
Trained batch 264 in epoch 14, gen_loss = 0.39643477122738674, disc_loss = 0.08668863421903467
Trained batch 265 in epoch 14, gen_loss = 0.3963222294149542, disc_loss = 0.08640981941743005
Trained batch 266 in epoch 14, gen_loss = 0.39639837431550473, disc_loss = 0.08654127903422167
Trained batch 267 in epoch 14, gen_loss = 0.39627713554385885, disc_loss = 0.08644584261937373
Trained batch 268 in epoch 14, gen_loss = 0.3963106811932915, disc_loss = 0.08639147818143926
Trained batch 269 in epoch 14, gen_loss = 0.3965269492732154, disc_loss = 0.08624372624412731
Trained batch 270 in epoch 14, gen_loss = 0.39685887186289714, disc_loss = 0.08611551478395163
Trained batch 271 in epoch 14, gen_loss = 0.3966389862710939, disc_loss = 0.08622145084390308
Trained batch 272 in epoch 14, gen_loss = 0.39669305118885667, disc_loss = 0.08601620540896178
Trained batch 273 in epoch 14, gen_loss = 0.39678941993382727, disc_loss = 0.08613649765233489
Trained batch 274 in epoch 14, gen_loss = 0.396801526221362, disc_loss = 0.08628005508672107
Trained batch 275 in epoch 14, gen_loss = 0.39701052031655243, disc_loss = 0.08603972187130779
Trained batch 276 in epoch 14, gen_loss = 0.3971552708949423, disc_loss = 0.08593046877681133
Trained batch 277 in epoch 14, gen_loss = 0.3967434445516669, disc_loss = 0.08591589797958196
Trained batch 278 in epoch 14, gen_loss = 0.3966069391337774, disc_loss = 0.08577803776042009
Trained batch 279 in epoch 14, gen_loss = 0.3966485520558698, disc_loss = 0.08572302519210748
Trained batch 280 in epoch 14, gen_loss = 0.39666090126139414, disc_loss = 0.0859788408058818
Trained batch 281 in epoch 14, gen_loss = 0.3962666242257923, disc_loss = 0.08627501235786059
Trained batch 282 in epoch 14, gen_loss = 0.3961338386097561, disc_loss = 0.08607301054779085
Trained batch 283 in epoch 14, gen_loss = 0.39629541589340694, disc_loss = 0.08583015185767706
Trained batch 284 in epoch 14, gen_loss = 0.3961934356313003, disc_loss = 0.08557606295666151
Trained batch 285 in epoch 14, gen_loss = 0.39614338130800875, disc_loss = 0.08545035358935178
Trained batch 286 in epoch 14, gen_loss = 0.3959639813841843, disc_loss = 0.08528486512705216
Trained batch 287 in epoch 14, gen_loss = 0.3961057538787524, disc_loss = 0.0850342811188764
Trained batch 288 in epoch 14, gen_loss = 0.39630437051961165, disc_loss = 0.08488315120855004
Trained batch 289 in epoch 14, gen_loss = 0.3962308513707128, disc_loss = 0.08486081776690894
Trained batch 290 in epoch 14, gen_loss = 0.396710436163899, disc_loss = 0.0848279994915646
Trained batch 291 in epoch 14, gen_loss = 0.39656517726101287, disc_loss = 0.08476046647570312
Trained batch 292 in epoch 14, gen_loss = 0.39648447366297856, disc_loss = 0.08523131582771552
Trained batch 293 in epoch 14, gen_loss = 0.3966581999850111, disc_loss = 0.08507664618240733
Trained batch 294 in epoch 14, gen_loss = 0.396483777943304, disc_loss = 0.08525836907200894
Trained batch 295 in epoch 14, gen_loss = 0.3963311235042843, disc_loss = 0.08515961789148482
Trained batch 296 in epoch 14, gen_loss = 0.3964227317559599, disc_loss = 0.08500861944724815
Trained batch 297 in epoch 14, gen_loss = 0.39651215496479264, disc_loss = 0.08477365168361556
Trained batch 298 in epoch 14, gen_loss = 0.3965774172524545, disc_loss = 0.08451840153468593
Trained batch 299 in epoch 14, gen_loss = 0.39656756311655045, disc_loss = 0.08445422978761295
Trained batch 300 in epoch 14, gen_loss = 0.3964736627977948, disc_loss = 0.08478558871994085
Trained batch 301 in epoch 14, gen_loss = 0.3966082288137335, disc_loss = 0.0854769557967338
Trained batch 302 in epoch 14, gen_loss = 0.396698131714717, disc_loss = 0.08530773060463935
Trained batch 303 in epoch 14, gen_loss = 0.396557699104673, disc_loss = 0.08520032681438974
Trained batch 304 in epoch 14, gen_loss = 0.39665314662651935, disc_loss = 0.08501707950881758
Trained batch 305 in epoch 14, gen_loss = 0.396624885548174, disc_loss = 0.08490171303266501
Trained batch 306 in epoch 14, gen_loss = 0.3966142721595516, disc_loss = 0.08474651643102352
Trained batch 307 in epoch 14, gen_loss = 0.3964183801760921, disc_loss = 0.08459540160505899
Trained batch 308 in epoch 14, gen_loss = 0.39635991596866965, disc_loss = 0.08439274869774827
Trained batch 309 in epoch 14, gen_loss = 0.39625715786410914, disc_loss = 0.08431953985784804
Trained batch 310 in epoch 14, gen_loss = 0.39590369725534, disc_loss = 0.08464699131631295
Trained batch 311 in epoch 14, gen_loss = 0.39604932461411524, disc_loss = 0.08451282547918172
Trained batch 312 in epoch 14, gen_loss = 0.3963339792463345, disc_loss = 0.08444309817514005
Trained batch 313 in epoch 14, gen_loss = 0.39626115740864143, disc_loss = 0.08425730091644226
Trained batch 314 in epoch 14, gen_loss = 0.39662077455293565, disc_loss = 0.08413867609545825
Trained batch 315 in epoch 14, gen_loss = 0.39675009967405583, disc_loss = 0.08390888438524702
Trained batch 316 in epoch 14, gen_loss = 0.3967395753890558, disc_loss = 0.08380709998662163
Trained batch 317 in epoch 14, gen_loss = 0.396804208181939, disc_loss = 0.08373006085320464
Trained batch 318 in epoch 14, gen_loss = 0.3968181324229345, disc_loss = 0.08355376750908115
Trained batch 319 in epoch 14, gen_loss = 0.3966850471682847, disc_loss = 0.08339203359209932
Trained batch 320 in epoch 14, gen_loss = 0.39662851685675504, disc_loss = 0.083216687768837
Trained batch 321 in epoch 14, gen_loss = 0.3967681569712503, disc_loss = 0.08303677881286936
Trained batch 322 in epoch 14, gen_loss = 0.3969854806598864, disc_loss = 0.0828301929018169
Trained batch 323 in epoch 14, gen_loss = 0.39689506038471506, disc_loss = 0.08280716149458363
Trained batch 324 in epoch 14, gen_loss = 0.39695950948275055, disc_loss = 0.08345063560857223
Trained batch 325 in epoch 14, gen_loss = 0.3971790119182844, disc_loss = 0.08332595564539265
Trained batch 326 in epoch 14, gen_loss = 0.39699803461357724, disc_loss = 0.08334689245015292
Trained batch 327 in epoch 14, gen_loss = 0.39699361028104296, disc_loss = 0.0832126823128996
Trained batch 328 in epoch 14, gen_loss = 0.3970474347155145, disc_loss = 0.0830484730188698
Trained batch 329 in epoch 14, gen_loss = 0.3970822560967821, disc_loss = 0.08292575269147302
Trained batch 330 in epoch 14, gen_loss = 0.3968681240189832, disc_loss = 0.08283982286933146
Trained batch 331 in epoch 14, gen_loss = 0.39701882121433696, disc_loss = 0.08323754355064537
Trained batch 332 in epoch 14, gen_loss = 0.39681418674128194, disc_loss = 0.08324176527828246
Trained batch 333 in epoch 14, gen_loss = 0.3965565475696575, disc_loss = 0.08304604511529565
Trained batch 334 in epoch 14, gen_loss = 0.39655686670274876, disc_loss = 0.08284395248698655
Trained batch 335 in epoch 14, gen_loss = 0.39659141864450204, disc_loss = 0.08261904892805476
Trained batch 336 in epoch 14, gen_loss = 0.396354405568686, disc_loss = 0.08244794481834646
Trained batch 337 in epoch 14, gen_loss = 0.3963193027578162, disc_loss = 0.08226814084774511
Trained batch 338 in epoch 14, gen_loss = 0.3963276493338357, disc_loss = 0.08219060796425626
Trained batch 339 in epoch 14, gen_loss = 0.39611802591997036, disc_loss = 0.08248341743259088
Trained batch 340 in epoch 14, gen_loss = 0.39607473115417613, disc_loss = 0.08326194854999436
Trained batch 341 in epoch 14, gen_loss = 0.3960519703159555, disc_loss = 0.0830778576044246
Trained batch 342 in epoch 14, gen_loss = 0.39609341440673473, disc_loss = 0.08290229131855918
Trained batch 343 in epoch 14, gen_loss = 0.3959049425672653, disc_loss = 0.08299143499895108
Trained batch 344 in epoch 14, gen_loss = 0.3960368352523748, disc_loss = 0.08342432842009526
Trained batch 345 in epoch 14, gen_loss = 0.3958065192823465, disc_loss = 0.08379079147532711
Trained batch 346 in epoch 14, gen_loss = 0.3957021408190988, disc_loss = 0.08369670398345469
Trained batch 347 in epoch 14, gen_loss = 0.3955943509079944, disc_loss = 0.08362994725339586
Trained batch 348 in epoch 14, gen_loss = 0.395646598585014, disc_loss = 0.08347329942584251
Trained batch 349 in epoch 14, gen_loss = 0.39523704154150824, disc_loss = 0.08352979720836239
Trained batch 350 in epoch 14, gen_loss = 0.39564201125392207, disc_loss = 0.08353974669243068
Trained batch 351 in epoch 14, gen_loss = 0.39569495660676196, disc_loss = 0.08335806718969252
Trained batch 352 in epoch 14, gen_loss = 0.39535896036847795, disc_loss = 0.08326147922655046
Trained batch 353 in epoch 14, gen_loss = 0.39545868101429804, disc_loss = 0.08313683971452217
Trained batch 354 in epoch 14, gen_loss = 0.3954350338015758, disc_loss = 0.08296358417063741
Trained batch 355 in epoch 14, gen_loss = 0.39542846523978736, disc_loss = 0.08276815884982058
Trained batch 356 in epoch 14, gen_loss = 0.39563241734558124, disc_loss = 0.08264135757033356
Trained batch 357 in epoch 14, gen_loss = 0.39528165666084714, disc_loss = 0.08299758233124775
Trained batch 358 in epoch 14, gen_loss = 0.39535462333299326, disc_loss = 0.0830692599480842
Trained batch 359 in epoch 14, gen_loss = 0.39528401353292997, disc_loss = 0.08295891093374748
Trained batch 360 in epoch 14, gen_loss = 0.39513642371856605, disc_loss = 0.08277030425001751
Trained batch 361 in epoch 14, gen_loss = 0.39495555677795935, disc_loss = 0.08261143163139854
Trained batch 362 in epoch 14, gen_loss = 0.3950695495631741, disc_loss = 0.08241162967249833
Trained batch 363 in epoch 14, gen_loss = 0.39508262505898106, disc_loss = 0.08224293935383864
Trained batch 364 in epoch 14, gen_loss = 0.3952211843778009, disc_loss = 0.08208228381707856
Trained batch 365 in epoch 14, gen_loss = 0.3952326163079569, disc_loss = 0.08191434423632594
Trained batch 366 in epoch 14, gen_loss = 0.3951807725332089, disc_loss = 0.08172601267406134
Trained batch 367 in epoch 14, gen_loss = 0.39511086322043254, disc_loss = 0.08157494246995117
Trained batch 368 in epoch 14, gen_loss = 0.39531069323622436, disc_loss = 0.08143175135778016
Trained batch 369 in epoch 14, gen_loss = 0.3953752926878027, disc_loss = 0.08126948932815041
Trained batch 370 in epoch 14, gen_loss = 0.39551573276841095, disc_loss = 0.08122225704093305
Trained batch 371 in epoch 14, gen_loss = 0.3957113410516452, disc_loss = 0.08103157975836106
Trained batch 372 in epoch 14, gen_loss = 0.3959540804653321, disc_loss = 0.08087342348194435
Trained batch 373 in epoch 14, gen_loss = 0.39602009051623827, disc_loss = 0.08072135526622162
Trained batch 374 in epoch 14, gen_loss = 0.39608393200238545, disc_loss = 0.08065212769185504
Trained batch 375 in epoch 14, gen_loss = 0.3962673840529107, disc_loss = 0.08047922480569043
Trained batch 376 in epoch 14, gen_loss = 0.3964280513774811, disc_loss = 0.08045769417510228
Trained batch 377 in epoch 14, gen_loss = 0.3963893409128542, disc_loss = 0.08076509442944178
Trained batch 378 in epoch 14, gen_loss = 0.3965054155968739, disc_loss = 0.08069389701592379
Trained batch 379 in epoch 14, gen_loss = 0.39672030359506605, disc_loss = 0.08056976370586964
Trained batch 380 in epoch 14, gen_loss = 0.3966525328440929, disc_loss = 0.08040608390261299
Trained batch 381 in epoch 14, gen_loss = 0.39673227071762085, disc_loss = 0.0803767136573616
Trained batch 382 in epoch 14, gen_loss = 0.3968037380873379, disc_loss = 0.08020167395487117
Trained batch 383 in epoch 14, gen_loss = 0.39678253155822557, disc_loss = 0.08001613654899604
Trained batch 384 in epoch 14, gen_loss = 0.39668226149175073, disc_loss = 0.08039188418996993
Trained batch 385 in epoch 14, gen_loss = 0.3965144348113648, disc_loss = 0.08098164713372105
Trained batch 386 in epoch 14, gen_loss = 0.39678924328597015, disc_loss = 0.0808841838520646
Trained batch 387 in epoch 14, gen_loss = 0.3967624064726928, disc_loss = 0.080878982283223
Trained batch 388 in epoch 14, gen_loss = 0.396844288607183, disc_loss = 0.08083686090953131
Trained batch 389 in epoch 14, gen_loss = 0.39679667353630066, disc_loss = 0.08078044082802267
Trained batch 390 in epoch 14, gen_loss = 0.39672428476231175, disc_loss = 0.08065713344789717
Trained batch 391 in epoch 14, gen_loss = 0.39695521436479625, disc_loss = 0.08056292751428615
Trained batch 392 in epoch 14, gen_loss = 0.39702376245542337, disc_loss = 0.08053072771465088
Trained batch 393 in epoch 14, gen_loss = 0.39703407339033137, disc_loss = 0.08047965686262448
Trained batch 394 in epoch 14, gen_loss = 0.39694468967522245, disc_loss = 0.0804049468693571
Trained batch 395 in epoch 14, gen_loss = 0.3967815852074912, disc_loss = 0.08031953512008932
Trained batch 396 in epoch 14, gen_loss = 0.3967578284235985, disc_loss = 0.08022127449817448
Trained batch 397 in epoch 14, gen_loss = 0.3966831837467213, disc_loss = 0.08017467974273292
Trained batch 398 in epoch 14, gen_loss = 0.3965196751412891, disc_loss = 0.08064440252343402
Trained batch 399 in epoch 14, gen_loss = 0.3964259198307991, disc_loss = 0.08071287262369879
Trained batch 400 in epoch 14, gen_loss = 0.39646692555444196, disc_loss = 0.08055541233422044
Trained batch 401 in epoch 14, gen_loss = 0.39640411541829657, disc_loss = 0.08047370326390203
Trained batch 402 in epoch 14, gen_loss = 0.39650642295037547, disc_loss = 0.08031462554567986
Trained batch 403 in epoch 14, gen_loss = 0.3966017034974429, disc_loss = 0.08015746130068593
Trained batch 404 in epoch 14, gen_loss = 0.3966665573326158, disc_loss = 0.08005773150189607
Trained batch 405 in epoch 14, gen_loss = 0.39675110321620416, disc_loss = 0.0799015892974647
Trained batch 406 in epoch 14, gen_loss = 0.3967976240619688, disc_loss = 0.07975722759783598
Trained batch 407 in epoch 14, gen_loss = 0.39687514232069837, disc_loss = 0.07958948833288114
Trained batch 408 in epoch 14, gen_loss = 0.39689479334721645, disc_loss = 0.07949939209052469
Trained batch 409 in epoch 14, gen_loss = 0.3967643857002258, disc_loss = 0.07960989285464876
Trained batch 410 in epoch 14, gen_loss = 0.3969461337783331, disc_loss = 0.07971493197478119
Trained batch 411 in epoch 14, gen_loss = 0.3968588162973089, disc_loss = 0.07954612010705638
Trained batch 412 in epoch 14, gen_loss = 0.3967812098111714, disc_loss = 0.07944095782263624
Trained batch 413 in epoch 14, gen_loss = 0.39668773920927647, disc_loss = 0.07927811653623222
Trained batch 414 in epoch 14, gen_loss = 0.3966903126383402, disc_loss = 0.07938038595806224
Trained batch 415 in epoch 14, gen_loss = 0.3965161262939756, disc_loss = 0.07943373313509465
Trained batch 416 in epoch 14, gen_loss = 0.39651736281186845, disc_loss = 0.07926030456014782
Trained batch 417 in epoch 14, gen_loss = 0.39642327325195786, disc_loss = 0.07933108653743978
Trained batch 418 in epoch 14, gen_loss = 0.39649846701747193, disc_loss = 0.07922276825063944
Trained batch 419 in epoch 14, gen_loss = 0.3965432492750032, disc_loss = 0.07916534877315695
Trained batch 420 in epoch 14, gen_loss = 0.3965811489455207, disc_loss = 0.07936565713257906
Trained batch 421 in epoch 14, gen_loss = 0.39655300840664814, disc_loss = 0.07965901745505348
Trained batch 422 in epoch 14, gen_loss = 0.39640644573150796, disc_loss = 0.07964948627186265
Trained batch 423 in epoch 14, gen_loss = 0.3966537590999648, disc_loss = 0.07972630982194974
Trained batch 424 in epoch 14, gen_loss = 0.3966000880914576, disc_loss = 0.07969927446697565
Trained batch 425 in epoch 14, gen_loss = 0.39672071084450106, disc_loss = 0.07955483706480006
Trained batch 426 in epoch 14, gen_loss = 0.3967376427432692, disc_loss = 0.07948944078915397
Trained batch 427 in epoch 14, gen_loss = 0.39672459717665876, disc_loss = 0.07934271037539414
Trained batch 428 in epoch 14, gen_loss = 0.39685279179564165, disc_loss = 0.0794186371699896
Trained batch 429 in epoch 14, gen_loss = 0.39676489192386005, disc_loss = 0.07988532516390605
Trained batch 430 in epoch 14, gen_loss = 0.39694344112325436, disc_loss = 0.0797784976529394
Trained batch 431 in epoch 14, gen_loss = 0.39700927654350243, disc_loss = 0.07971125382270354
Trained batch 432 in epoch 14, gen_loss = 0.39702216912637406, disc_loss = 0.07963846183293789
Trained batch 433 in epoch 14, gen_loss = 0.396889601572318, disc_loss = 0.07949406692590821
Trained batch 434 in epoch 14, gen_loss = 0.39709003136075777, disc_loss = 0.07936570129153886
Trained batch 435 in epoch 14, gen_loss = 0.39707219853587106, disc_loss = 0.07959102352530004
Trained batch 436 in epoch 14, gen_loss = 0.39678566297622786, disc_loss = 0.0799434524172282
Trained batch 437 in epoch 14, gen_loss = 0.39686798334938206, disc_loss = 0.07988578374029805
Trained batch 438 in epoch 14, gen_loss = 0.396978562065572, disc_loss = 0.07981448580143902
Trained batch 439 in epoch 14, gen_loss = 0.39672861830754713, disc_loss = 0.07981380576754667
Trained batch 440 in epoch 14, gen_loss = 0.3967068900191595, disc_loss = 0.07969090698050364
Trained batch 441 in epoch 14, gen_loss = 0.3966238264045025, disc_loss = 0.07963110474401841
Trained batch 442 in epoch 14, gen_loss = 0.3963643486693535, disc_loss = 0.07970282536222859
Trained batch 443 in epoch 14, gen_loss = 0.3964608830508885, disc_loss = 0.07967702863079303
Trained batch 444 in epoch 14, gen_loss = 0.3967000723554847, disc_loss = 0.07953747483179643
Trained batch 445 in epoch 14, gen_loss = 0.3967493076896454, disc_loss = 0.07937993881117235
Trained batch 446 in epoch 14, gen_loss = 0.396950471987927, disc_loss = 0.0792285062849805
Trained batch 447 in epoch 14, gen_loss = 0.39690624736249447, disc_loss = 0.0791302638837286
Trained batch 448 in epoch 14, gen_loss = 0.3969246259909165, disc_loss = 0.0790297333285926
Trained batch 449 in epoch 14, gen_loss = 0.3969229214058982, disc_loss = 0.07889138442050252
Trained batch 450 in epoch 14, gen_loss = 0.3969009157162812, disc_loss = 0.0787632840751627
Trained batch 451 in epoch 14, gen_loss = 0.3970456381155326, disc_loss = 0.07861360953399599
Trained batch 452 in epoch 14, gen_loss = 0.39712513407597744, disc_loss = 0.07845649901247084
Trained batch 453 in epoch 14, gen_loss = 0.39708846157605426, disc_loss = 0.07832355493790416
Trained batch 454 in epoch 14, gen_loss = 0.39695767753726835, disc_loss = 0.07834577563802128
Trained batch 455 in epoch 14, gen_loss = 0.39678811275383885, disc_loss = 0.07866237201552283
Trained batch 456 in epoch 14, gen_loss = 0.39686622576588354, disc_loss = 0.07876524785778095
Trained batch 457 in epoch 14, gen_loss = 0.396623231372979, disc_loss = 0.07863035181224118
Trained batch 458 in epoch 14, gen_loss = 0.3966638267949256, disc_loss = 0.07859069890239173
Trained batch 459 in epoch 14, gen_loss = 0.3967936888985012, disc_loss = 0.07855519017143904
Trained batch 460 in epoch 14, gen_loss = 0.3969367452919354, disc_loss = 0.07841549759100387
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.3334711790084839, disc_loss = 0.06643230468034744
Trained batch 1 in epoch 15, gen_loss = 0.38072118163108826, disc_loss = 0.037274647038429976
Trained batch 2 in epoch 15, gen_loss = 0.3931192656358083, disc_loss = 0.03750777834405502
Trained batch 3 in epoch 15, gen_loss = 0.37617526203393936, disc_loss = 0.04575263406150043
Trained batch 4 in epoch 15, gen_loss = 0.400103360414505, disc_loss = 0.044457352720201015
Trained batch 5 in epoch 15, gen_loss = 0.3948434591293335, disc_loss = 0.0398950205805401
Trained batch 6 in epoch 15, gen_loss = 0.39556770239557537, disc_loss = 0.03938069899699518
Trained batch 7 in epoch 15, gen_loss = 0.40076664090156555, disc_loss = 0.03595287643838674
Trained batch 8 in epoch 15, gen_loss = 0.4036979675292969, disc_loss = 0.0385593239011036
Trained batch 9 in epoch 15, gen_loss = 0.3964747190475464, disc_loss = 0.04796902360394597
Trained batch 10 in epoch 15, gen_loss = 0.3973595283248208, disc_loss = 0.059480263174257496
Trained batch 11 in epoch 15, gen_loss = 0.39328818023204803, disc_loss = 0.057171023838842906
Trained batch 12 in epoch 15, gen_loss = 0.3911419235743009, disc_loss = 0.05652378879200954
Trained batch 13 in epoch 15, gen_loss = 0.39887192845344543, disc_loss = 0.0643438455382628
Trained batch 14 in epoch 15, gen_loss = 0.3969215472539266, disc_loss = 0.06276040878146887
Trained batch 15 in epoch 15, gen_loss = 0.39878103882074356, disc_loss = 0.06123884493717924
Trained batch 16 in epoch 15, gen_loss = 0.3982638751759249, disc_loss = 0.062018379185567886
Trained batch 17 in epoch 15, gen_loss = 0.39922865397400326, disc_loss = 0.06113217714139157
Trained batch 18 in epoch 15, gen_loss = 0.39429612379325063, disc_loss = 0.06155495919091137
Trained batch 19 in epoch 15, gen_loss = 0.39329017549753187, disc_loss = 0.05986823053099215
Trained batch 20 in epoch 15, gen_loss = 0.3913268744945526, disc_loss = 0.05969438049942255
Trained batch 21 in epoch 15, gen_loss = 0.39127893068573694, disc_loss = 0.06176893671297214
Trained batch 22 in epoch 15, gen_loss = 0.38657142416290613, disc_loss = 0.06290444266051054
Trained batch 23 in epoch 15, gen_loss = 0.3883938565850258, disc_loss = 0.06189212067207942
Trained batch 24 in epoch 15, gen_loss = 0.3883074975013733, disc_loss = 0.06040381524711847
Trained batch 25 in epoch 15, gen_loss = 0.38599371910095215, disc_loss = 0.058951150303563245
Trained batch 26 in epoch 15, gen_loss = 0.38536534265235617, disc_loss = 0.05801234542633648
Trained batch 27 in epoch 15, gen_loss = 0.3864328818661826, disc_loss = 0.05641247172440801
Trained batch 28 in epoch 15, gen_loss = 0.38753746398564043, disc_loss = 0.058619063732952906
Trained batch 29 in epoch 15, gen_loss = 0.3848104645808538, disc_loss = 0.0673169953127702
Trained batch 30 in epoch 15, gen_loss = 0.38643477328362, disc_loss = 0.06812110326943858
Trained batch 31 in epoch 15, gen_loss = 0.3861801056191325, disc_loss = 0.06689199863467366
Trained batch 32 in epoch 15, gen_loss = 0.38681977174498816, disc_loss = 0.06556734177425053
Trained batch 33 in epoch 15, gen_loss = 0.38755634865340066, disc_loss = 0.06529619276304455
Trained batch 34 in epoch 15, gen_loss = 0.38606973120144433, disc_loss = 0.06430326109485966
Trained batch 35 in epoch 15, gen_loss = 0.3849603748983807, disc_loss = 0.06520935173870789
Trained batch 36 in epoch 15, gen_loss = 0.3824720785424516, disc_loss = 0.0701411328706387
Trained batch 37 in epoch 15, gen_loss = 0.38472095288728414, disc_loss = 0.07162527607655839
Trained batch 38 in epoch 15, gen_loss = 0.38498549048717207, disc_loss = 0.07035070208784862
Trained batch 39 in epoch 15, gen_loss = 0.38373873829841615, disc_loss = 0.07016912689432502
Trained batch 40 in epoch 15, gen_loss = 0.3832716622003695, disc_loss = 0.06912486509578984
Trained batch 41 in epoch 15, gen_loss = 0.38223483590852647, disc_loss = 0.06843762516620613
Trained batch 42 in epoch 15, gen_loss = 0.3827253912770471, disc_loss = 0.0686170624265837
Trained batch 43 in epoch 15, gen_loss = 0.3815521272745999, disc_loss = 0.06991804111748934
Trained batch 44 in epoch 15, gen_loss = 0.38122276531325444, disc_loss = 0.07057737269335324
Trained batch 45 in epoch 15, gen_loss = 0.380772493455721, disc_loss = 0.07063838604675687
Trained batch 46 in epoch 15, gen_loss = 0.37842967218541085, disc_loss = 0.07442018223252703
Trained batch 47 in epoch 15, gen_loss = 0.37877086984614533, disc_loss = 0.07452621303188305
Trained batch 48 in epoch 15, gen_loss = 0.379274132908607, disc_loss = 0.0733412389016273
Trained batch 49 in epoch 15, gen_loss = 0.37838134706020354, disc_loss = 0.07275561813265086
Trained batch 50 in epoch 15, gen_loss = 0.3774358969108731, disc_loss = 0.07347107463169332
Trained batch 51 in epoch 15, gen_loss = 0.37841740995645523, disc_loss = 0.07335322425485803
Trained batch 52 in epoch 15, gen_loss = 0.37936885795503295, disc_loss = 0.07247362588092966
Trained batch 53 in epoch 15, gen_loss = 0.3802223045516897, disc_loss = 0.0739958474619521
Trained batch 54 in epoch 15, gen_loss = 0.37977680563926697, disc_loss = 0.07760096795179627
Trained batch 55 in epoch 15, gen_loss = 0.38136051541992594, disc_loss = 0.07703808375767299
Trained batch 56 in epoch 15, gen_loss = 0.38259325686254, disc_loss = 0.07589608502753994
Trained batch 57 in epoch 15, gen_loss = 0.3825084664698305, disc_loss = 0.07509298012431326
Trained batch 58 in epoch 15, gen_loss = 0.3820085318411811, disc_loss = 0.07477603436021482
Trained batch 59 in epoch 15, gen_loss = 0.3831162298719088, disc_loss = 0.07377311650974056
Trained batch 60 in epoch 15, gen_loss = 0.38255209610110424, disc_loss = 0.0732561701786567
Trained batch 61 in epoch 15, gen_loss = 0.38373549619028646, disc_loss = 0.07371771961991344
Trained batch 62 in epoch 15, gen_loss = 0.3833842495131114, disc_loss = 0.0779009721729727
Trained batch 63 in epoch 15, gen_loss = 0.3830201090313494, disc_loss = 0.07802117244864348
Trained batch 64 in epoch 15, gen_loss = 0.3839541238087874, disc_loss = 0.07787191147127977
Trained batch 65 in epoch 15, gen_loss = 0.3834228935566815, disc_loss = 0.07728481852929249
Trained batch 66 in epoch 15, gen_loss = 0.3822182332401845, disc_loss = 0.0768263753253355
Trained batch 67 in epoch 15, gen_loss = 0.38272108312915354, disc_loss = 0.0760655378073673
Trained batch 68 in epoch 15, gen_loss = 0.3831144372622172, disc_loss = 0.07530669475217229
Trained batch 69 in epoch 15, gen_loss = 0.38345579717840467, disc_loss = 0.07443762947139995
Trained batch 70 in epoch 15, gen_loss = 0.38226532390419865, disc_loss = 0.0742381986781535
Trained batch 71 in epoch 15, gen_loss = 0.3827393733792835, disc_loss = 0.07341835474491948
Trained batch 72 in epoch 15, gen_loss = 0.3831984270108889, disc_loss = 0.07252460289491366
Trained batch 73 in epoch 15, gen_loss = 0.38249935652758627, disc_loss = 0.07173965488736694
Trained batch 74 in epoch 15, gen_loss = 0.3823048146565755, disc_loss = 0.07146644487977027
Trained batch 75 in epoch 15, gen_loss = 0.38307711874183853, disc_loss = 0.07150076324806402
Trained batch 76 in epoch 15, gen_loss = 0.38217017635122524, disc_loss = 0.07094345181309558
Trained batch 77 in epoch 15, gen_loss = 0.3834168865130498, disc_loss = 0.07015267200767994
Trained batch 78 in epoch 15, gen_loss = 0.3830909762955919, disc_loss = 0.06984358243172682
Trained batch 79 in epoch 15, gen_loss = 0.3832874823361635, disc_loss = 0.07160824025049806
Trained batch 80 in epoch 15, gen_loss = 0.3853499951921863, disc_loss = 0.07235178434186512
Trained batch 81 in epoch 15, gen_loss = 0.38628956384775115, disc_loss = 0.071588447680924
Trained batch 82 in epoch 15, gen_loss = 0.3860223842672555, disc_loss = 0.0710139607629144
Trained batch 83 in epoch 15, gen_loss = 0.38610391070445377, disc_loss = 0.07049611095516455
Trained batch 84 in epoch 15, gen_loss = 0.38638215415618, disc_loss = 0.06982371276792358
Trained batch 85 in epoch 15, gen_loss = 0.38739054251548855, disc_loss = 0.06927674575600513
Trained batch 86 in epoch 15, gen_loss = 0.38830441510540314, disc_loss = 0.06858076950556588
Trained batch 87 in epoch 15, gen_loss = 0.3882479115643285, disc_loss = 0.06838057438885285
Trained batch 88 in epoch 15, gen_loss = 0.3883779661709003, disc_loss = 0.06842973086396965
Trained batch 89 in epoch 15, gen_loss = 0.38796161115169525, disc_loss = 0.06943598765258988
Trained batch 90 in epoch 15, gen_loss = 0.38889025692101364, disc_loss = 0.06997274798801639
Trained batch 91 in epoch 15, gen_loss = 0.38896050304174423, disc_loss = 0.0694297348736259
Trained batch 92 in epoch 15, gen_loss = 0.3889708592686602, disc_loss = 0.06894511668392087
Trained batch 93 in epoch 15, gen_loss = 0.3886765609396265, disc_loss = 0.0687762488056212
Trained batch 94 in epoch 15, gen_loss = 0.38987724153619063, disc_loss = 0.06821966582026921
Trained batch 95 in epoch 15, gen_loss = 0.39019121664265793, disc_loss = 0.06763352538109757
Trained batch 96 in epoch 15, gen_loss = 0.38978112512028096, disc_loss = 0.06702385776551421
Trained batch 97 in epoch 15, gen_loss = 0.3898326876212139, disc_loss = 0.06660479348038836
Trained batch 98 in epoch 15, gen_loss = 0.39014562332268915, disc_loss = 0.06653648745644876
Trained batch 99 in epoch 15, gen_loss = 0.3906823307275772, disc_loss = 0.06697102124802769
Trained batch 100 in epoch 15, gen_loss = 0.39131710375889694, disc_loss = 0.06672175216608413
Trained batch 101 in epoch 15, gen_loss = 0.39149362199446736, disc_loss = 0.06619480426660647
Trained batch 102 in epoch 15, gen_loss = 0.3918202944750925, disc_loss = 0.06575471386132599
Trained batch 103 in epoch 15, gen_loss = 0.3923857014339704, disc_loss = 0.06591565891777953
Trained batch 104 in epoch 15, gen_loss = 0.3917078702222733, disc_loss = 0.06733713220095351
Trained batch 105 in epoch 15, gen_loss = 0.39215136895764546, disc_loss = 0.06789966910761201
Trained batch 106 in epoch 15, gen_loss = 0.39193052081304175, disc_loss = 0.06750815634171818
Trained batch 107 in epoch 15, gen_loss = 0.39202878182684936, disc_loss = 0.06846563574099154
Trained batch 108 in epoch 15, gen_loss = 0.39258892219001, disc_loss = 0.06825021142567243
Trained batch 109 in epoch 15, gen_loss = 0.3924731270833449, disc_loss = 0.0685538678091358
Trained batch 110 in epoch 15, gen_loss = 0.39165702327951657, disc_loss = 0.06910064750191597
Trained batch 111 in epoch 15, gen_loss = 0.3922009869877781, disc_loss = 0.0686358465630162
Trained batch 112 in epoch 15, gen_loss = 0.39169182687734083, disc_loss = 0.06817749107207081
Trained batch 113 in epoch 15, gen_loss = 0.3909458667039871, disc_loss = 0.06803505718217868
Trained batch 114 in epoch 15, gen_loss = 0.3899991932122604, disc_loss = 0.06793422119934922
Trained batch 115 in epoch 15, gen_loss = 0.3903287947177887, disc_loss = 0.06752567673262594
Trained batch 116 in epoch 15, gen_loss = 0.3901548026463924, disc_loss = 0.067140123870574
Trained batch 117 in epoch 15, gen_loss = 0.3902213333521859, disc_loss = 0.06673737584565909
Trained batch 118 in epoch 15, gen_loss = 0.3908100408666274, disc_loss = 0.06637766948674156
Trained batch 119 in epoch 15, gen_loss = 0.39146916816631955, disc_loss = 0.06608819909549007
Trained batch 120 in epoch 15, gen_loss = 0.39135319659532597, disc_loss = 0.06579812963239172
Trained batch 121 in epoch 15, gen_loss = 0.39155105122777284, disc_loss = 0.06531541059404368
Trained batch 122 in epoch 15, gen_loss = 0.3912586291146472, disc_loss = 0.0649643476552716
Trained batch 123 in epoch 15, gen_loss = 0.3913360283740105, disc_loss = 0.06503959250215802
Trained batch 124 in epoch 15, gen_loss = 0.3917542667388916, disc_loss = 0.0647112882360816
Trained batch 125 in epoch 15, gen_loss = 0.39141630345866796, disc_loss = 0.06448956587100549
Trained batch 126 in epoch 15, gen_loss = 0.3911806488130975, disc_loss = 0.06417860229330974
Trained batch 127 in epoch 15, gen_loss = 0.39089418831281364, disc_loss = 0.06406398138642544
Trained batch 128 in epoch 15, gen_loss = 0.3900990950506787, disc_loss = 0.06476754999120338
Trained batch 129 in epoch 15, gen_loss = 0.3910464422060893, disc_loss = 0.06575796991729965
Trained batch 130 in epoch 15, gen_loss = 0.3916205224645047, disc_loss = 0.06531644986501632
Trained batch 131 in epoch 15, gen_loss = 0.39172493576100376, disc_loss = 0.06529776417565616
Trained batch 132 in epoch 15, gen_loss = 0.39200116951662795, disc_loss = 0.06492663307913712
Trained batch 133 in epoch 15, gen_loss = 0.3921128233422094, disc_loss = 0.06460800605700977
Trained batch 134 in epoch 15, gen_loss = 0.39224073003839566, disc_loss = 0.06429123318305723
Trained batch 135 in epoch 15, gen_loss = 0.39186039588907184, disc_loss = 0.06421742245883626
Trained batch 136 in epoch 15, gen_loss = 0.3925613341105245, disc_loss = 0.06405104930600981
Trained batch 137 in epoch 15, gen_loss = 0.3922356511803641, disc_loss = 0.06401293503417485
Trained batch 138 in epoch 15, gen_loss = 0.3920691939566633, disc_loss = 0.06453303429934619
Trained batch 139 in epoch 15, gen_loss = 0.3929126420191356, disc_loss = 0.06465731460068908
Trained batch 140 in epoch 15, gen_loss = 0.3928898211489332, disc_loss = 0.06447111926180252
Trained batch 141 in epoch 15, gen_loss = 0.39290035421579655, disc_loss = 0.06418378093660297
Trained batch 142 in epoch 15, gen_loss = 0.3930210073094268, disc_loss = 0.06385576833117675
Trained batch 143 in epoch 15, gen_loss = 0.3932640742924478, disc_loss = 0.06353196911772506
Trained batch 144 in epoch 15, gen_loss = 0.39284655945054414, disc_loss = 0.06359335766013326
Trained batch 145 in epoch 15, gen_loss = 0.3933171623781936, disc_loss = 0.06363741769008849
Trained batch 146 in epoch 15, gen_loss = 0.3933173197061837, disc_loss = 0.06350309370072926
Trained batch 147 in epoch 15, gen_loss = 0.39324190568279577, disc_loss = 0.06361319521140005
Trained batch 148 in epoch 15, gen_loss = 0.3938773776460814, disc_loss = 0.0636769042494113
Trained batch 149 in epoch 15, gen_loss = 0.3943562287092209, disc_loss = 0.06333214477325479
Trained batch 150 in epoch 15, gen_loss = 0.3940925256700705, disc_loss = 0.06319694668177935
Trained batch 151 in epoch 15, gen_loss = 0.3944445213204936, disc_loss = 0.06294311809132953
Trained batch 152 in epoch 15, gen_loss = 0.39441948934318194, disc_loss = 0.06275381891093418
Trained batch 153 in epoch 15, gen_loss = 0.3938968369326034, disc_loss = 0.06262571747451053
Trained batch 154 in epoch 15, gen_loss = 0.3943913263659323, disc_loss = 0.06259802671810312
Trained batch 155 in epoch 15, gen_loss = 0.3944158941889421, disc_loss = 0.06521494682424535
Trained batch 156 in epoch 15, gen_loss = 0.39377972825317625, disc_loss = 0.06628910101546794
Trained batch 157 in epoch 15, gen_loss = 0.394458942209618, disc_loss = 0.06609983669735398
Trained batch 158 in epoch 15, gen_loss = 0.3947280369839578, disc_loss = 0.06669016850749089
Trained batch 159 in epoch 15, gen_loss = 0.3940844343975186, disc_loss = 0.0666625044599641
Trained batch 160 in epoch 15, gen_loss = 0.39383166769276495, disc_loss = 0.06709282010539162
Trained batch 161 in epoch 15, gen_loss = 0.3941466537890611, disc_loss = 0.06681780935046666
Trained batch 162 in epoch 15, gen_loss = 0.3942488963984273, disc_loss = 0.06688531853281464
Trained batch 163 in epoch 15, gen_loss = 0.3937435986065283, disc_loss = 0.06685128802910628
Trained batch 164 in epoch 15, gen_loss = 0.39362572612184465, disc_loss = 0.06659695013341578
Trained batch 165 in epoch 15, gen_loss = 0.39373284686042603, disc_loss = 0.0662792613617627
Trained batch 166 in epoch 15, gen_loss = 0.3938950660699856, disc_loss = 0.0661303405677844
Trained batch 167 in epoch 15, gen_loss = 0.39377319404766675, disc_loss = 0.06603808650037363
Trained batch 168 in epoch 15, gen_loss = 0.39367696466530566, disc_loss = 0.0659030236568324
Trained batch 169 in epoch 15, gen_loss = 0.3932757083107443, disc_loss = 0.06679295641096199
Trained batch 170 in epoch 15, gen_loss = 0.39363095774288065, disc_loss = 0.06669725848045963
Trained batch 171 in epoch 15, gen_loss = 0.39392948895692825, disc_loss = 0.06639613184081607
Trained batch 172 in epoch 15, gen_loss = 0.39404029033087584, disc_loss = 0.0663258526043568
Trained batch 173 in epoch 15, gen_loss = 0.39376527824621094, disc_loss = 0.06645081278964363
Trained batch 174 in epoch 15, gen_loss = 0.39364075217928207, disc_loss = 0.06647973538509437
Trained batch 175 in epoch 15, gen_loss = 0.39335324039513414, disc_loss = 0.06630584228233519
Trained batch 176 in epoch 15, gen_loss = 0.3937998742370282, disc_loss = 0.06610076404097727
Trained batch 177 in epoch 15, gen_loss = 0.3939809747291415, disc_loss = 0.06589751449947277
Trained batch 178 in epoch 15, gen_loss = 0.3945517266928817, disc_loss = 0.06580873707819251
Trained batch 179 in epoch 15, gen_loss = 0.39432507107655207, disc_loss = 0.06663020062777732
Trained batch 180 in epoch 15, gen_loss = 0.39458812929648723, disc_loss = 0.06783165004701246
Trained batch 181 in epoch 15, gen_loss = 0.3946744429541158, disc_loss = 0.06751045673205466
Trained batch 182 in epoch 15, gen_loss = 0.3942257516045388, disc_loss = 0.06769959040780048
Trained batch 183 in epoch 15, gen_loss = 0.394167113725258, disc_loss = 0.0675383367140413
Trained batch 184 in epoch 15, gen_loss = 0.3944299572222942, disc_loss = 0.06752005721366888
Trained batch 185 in epoch 15, gen_loss = 0.3943776691793114, disc_loss = 0.06725836260324364
Trained batch 186 in epoch 15, gen_loss = 0.3943756990891727, disc_loss = 0.06727447902116386
Trained batch 187 in epoch 15, gen_loss = 0.3946869600009411, disc_loss = 0.06698469554589308
Trained batch 188 in epoch 15, gen_loss = 0.3949358832268488, disc_loss = 0.06685265765165684
Trained batch 189 in epoch 15, gen_loss = 0.3952881050737281, disc_loss = 0.0666547756887188
Trained batch 190 in epoch 15, gen_loss = 0.39517274389716345, disc_loss = 0.06686707083330885
Trained batch 191 in epoch 15, gen_loss = 0.39556714333593845, disc_loss = 0.06805361419780336
Trained batch 192 in epoch 15, gen_loss = 0.39556499342844276, disc_loss = 0.0677948672314768
Trained batch 193 in epoch 15, gen_loss = 0.39568648064873885, disc_loss = 0.06783189734482427
Trained batch 194 in epoch 15, gen_loss = 0.3957302150053856, disc_loss = 0.0677002475859645
Trained batch 195 in epoch 15, gen_loss = 0.39582095219164476, disc_loss = 0.06746941178143785
Trained batch 196 in epoch 15, gen_loss = 0.3955976987248145, disc_loss = 0.0674957634200375
Trained batch 197 in epoch 15, gen_loss = 0.39555595288373, disc_loss = 0.06781509545434153
Trained batch 198 in epoch 15, gen_loss = 0.39560702248434326, disc_loss = 0.06775093183913572
Trained batch 199 in epoch 15, gen_loss = 0.3957406072318554, disc_loss = 0.06748467488680035
Trained batch 200 in epoch 15, gen_loss = 0.3955735509371876, disc_loss = 0.0672744066774178
Trained batch 201 in epoch 15, gen_loss = 0.39509318459151993, disc_loss = 0.06763694462560044
Trained batch 202 in epoch 15, gen_loss = 0.39487947340082064, disc_loss = 0.06880531365996952
Trained batch 203 in epoch 15, gen_loss = 0.3955448966692476, disc_loss = 0.06922556545274954
Trained batch 204 in epoch 15, gen_loss = 0.3956726008799018, disc_loss = 0.06901693616244124
Trained batch 205 in epoch 15, gen_loss = 0.395394844192903, disc_loss = 0.06891586443011477
Trained batch 206 in epoch 15, gen_loss = 0.3948545817303773, disc_loss = 0.06887103829100943
Trained batch 207 in epoch 15, gen_loss = 0.39493437569874984, disc_loss = 0.06861449290031138
Trained batch 208 in epoch 15, gen_loss = 0.3950785091904362, disc_loss = 0.06845381516410688
Trained batch 209 in epoch 15, gen_loss = 0.39500260182789393, disc_loss = 0.06824982505114306
Trained batch 210 in epoch 15, gen_loss = 0.3947737879380231, disc_loss = 0.06846297841289598
Trained batch 211 in epoch 15, gen_loss = 0.39449947945914177, disc_loss = 0.06896159110836825
Trained batch 212 in epoch 15, gen_loss = 0.39467861143076366, disc_loss = 0.06875790605767512
Trained batch 213 in epoch 15, gen_loss = 0.39532738450531646, disc_loss = 0.06908625217206846
Trained batch 214 in epoch 15, gen_loss = 0.3953438926574796, disc_loss = 0.06888277504679768
Trained batch 215 in epoch 15, gen_loss = 0.395099694116248, disc_loss = 0.06872169839011298
Trained batch 216 in epoch 15, gen_loss = 0.3950328475319295, disc_loss = 0.06857598708590604
Trained batch 217 in epoch 15, gen_loss = 0.3949177189977891, disc_loss = 0.06840024715921747
Trained batch 218 in epoch 15, gen_loss = 0.395309407144921, disc_loss = 0.068220019595672
Trained batch 219 in epoch 15, gen_loss = 0.3952863922173327, disc_loss = 0.06795682617547837
Trained batch 220 in epoch 15, gen_loss = 0.3951285493589634, disc_loss = 0.06794116330834535
Trained batch 221 in epoch 15, gen_loss = 0.39534374682215956, disc_loss = 0.06791943289876522
Trained batch 222 in epoch 15, gen_loss = 0.3951121743751748, disc_loss = 0.06765563556749056
Trained batch 223 in epoch 15, gen_loss = 0.394852119764047, disc_loss = 0.06762837001172427
Trained batch 224 in epoch 15, gen_loss = 0.3951882305410173, disc_loss = 0.06736651023642884
Trained batch 225 in epoch 15, gen_loss = 0.39535618817384266, disc_loss = 0.06711171761946341
Trained batch 226 in epoch 15, gen_loss = 0.395332711777498, disc_loss = 0.06704291212269914
Trained batch 227 in epoch 15, gen_loss = 0.39501415271508067, disc_loss = 0.0669863140864069
Trained batch 228 in epoch 15, gen_loss = 0.3950710590749849, disc_loss = 0.066894016330289
Trained batch 229 in epoch 15, gen_loss = 0.3953569312458453, disc_loss = 0.0666429019290144
Trained batch 230 in epoch 15, gen_loss = 0.39540898464458846, disc_loss = 0.06653226177849166
Trained batch 231 in epoch 15, gen_loss = 0.3954360557013544, disc_loss = 0.06629278470665731
Trained batch 232 in epoch 15, gen_loss = 0.395516968719949, disc_loss = 0.06624389003338732
Trained batch 233 in epoch 15, gen_loss = 0.39557753808987445, disc_loss = 0.06623184459650108
Trained batch 234 in epoch 15, gen_loss = 0.3950936497525966, disc_loss = 0.06626823482678292
Trained batch 235 in epoch 15, gen_loss = 0.3952752296197212, disc_loss = 0.0660702810164983
Trained batch 236 in epoch 15, gen_loss = 0.3955488631242438, disc_loss = 0.06592326770823465
Trained batch 237 in epoch 15, gen_loss = 0.3956579618594226, disc_loss = 0.06583024524621853
Trained batch 238 in epoch 15, gen_loss = 0.3961009672496109, disc_loss = 0.06583423345938137
Trained batch 239 in epoch 15, gen_loss = 0.3963998402158419, disc_loss = 0.06560064688092097
Trained batch 240 in epoch 15, gen_loss = 0.3964899986116718, disc_loss = 0.06579569436965271
Trained batch 241 in epoch 15, gen_loss = 0.396708658288333, disc_loss = 0.06572090705456443
Trained batch 242 in epoch 15, gen_loss = 0.39683402075198454, disc_loss = 0.06550237448663745
Trained batch 243 in epoch 15, gen_loss = 0.39684121640490705, disc_loss = 0.06538998003911654
Trained batch 244 in epoch 15, gen_loss = 0.39690839794217325, disc_loss = 0.06527715411645417
Trained batch 245 in epoch 15, gen_loss = 0.3969317204583951, disc_loss = 0.06530349557401567
Trained batch 246 in epoch 15, gen_loss = 0.39677835524323496, disc_loss = 0.06537926533006826
Trained batch 247 in epoch 15, gen_loss = 0.39731358592548677, disc_loss = 0.06548321110031177
Trained batch 248 in epoch 15, gen_loss = 0.3974975798742838, disc_loss = 0.06530893206162505
Trained batch 249 in epoch 15, gen_loss = 0.3975054745674133, disc_loss = 0.06523083476349711
Trained batch 250 in epoch 15, gen_loss = 0.3979049493592099, disc_loss = 0.0651530481066065
Trained batch 251 in epoch 15, gen_loss = 0.39791238213342334, disc_loss = 0.06497136599916432
Trained batch 252 in epoch 15, gen_loss = 0.39738374394861603, disc_loss = 0.06509449473203054
Trained batch 253 in epoch 15, gen_loss = 0.3972840157784815, disc_loss = 0.06499297717791491
Trained batch 254 in epoch 15, gen_loss = 0.39720989360528836, disc_loss = 0.06572382917956394
Trained batch 255 in epoch 15, gen_loss = 0.39760667632799596, disc_loss = 0.06581549818292842
Trained batch 256 in epoch 15, gen_loss = 0.39784557914455576, disc_loss = 0.06571386140274746
Trained batch 257 in epoch 15, gen_loss = 0.39811894840510315, disc_loss = 0.06593902507623614
Trained batch 258 in epoch 15, gen_loss = 0.39798350787530995, disc_loss = 0.06675497509006943
Trained batch 259 in epoch 15, gen_loss = 0.3983380778477742, disc_loss = 0.06671892798935565
Trained batch 260 in epoch 15, gen_loss = 0.3982150778459863, disc_loss = 0.06678154007299764
Trained batch 261 in epoch 15, gen_loss = 0.39814384509133927, disc_loss = 0.06698017210863133
Trained batch 262 in epoch 15, gen_loss = 0.39831959136085365, disc_loss = 0.06685802417350473
Trained batch 263 in epoch 15, gen_loss = 0.3983366690350301, disc_loss = 0.06666885637043213
Trained batch 264 in epoch 15, gen_loss = 0.3983331097746795, disc_loss = 0.06660666681193518
Trained batch 265 in epoch 15, gen_loss = 0.3985310252895929, disc_loss = 0.06654222749691821
Trained batch 266 in epoch 15, gen_loss = 0.39848064885157325, disc_loss = 0.06694283799969414
Trained batch 267 in epoch 15, gen_loss = 0.39814050662428585, disc_loss = 0.06743286497571241
Trained batch 268 in epoch 15, gen_loss = 0.3981646197436024, disc_loss = 0.06786620060542813
Trained batch 269 in epoch 15, gen_loss = 0.39851504431830514, disc_loss = 0.06769497537709497
Trained batch 270 in epoch 15, gen_loss = 0.39815670163868977, disc_loss = 0.06784453781534715
Trained batch 271 in epoch 15, gen_loss = 0.39813512410311136, disc_loss = 0.0680072022951208
Trained batch 272 in epoch 15, gen_loss = 0.39819675050812325, disc_loss = 0.06783221607802661
Trained batch 273 in epoch 15, gen_loss = 0.39826925001005187, disc_loss = 0.06772951474821154
Trained batch 274 in epoch 15, gen_loss = 0.3981474309617823, disc_loss = 0.06758341496979649
Trained batch 275 in epoch 15, gen_loss = 0.39838542627251666, disc_loss = 0.06774261918094387
Trained batch 276 in epoch 15, gen_loss = 0.398112120503553, disc_loss = 0.06827063729737748
Trained batch 277 in epoch 15, gen_loss = 0.39822145792648944, disc_loss = 0.06841467224771706
Trained batch 278 in epoch 15, gen_loss = 0.39799638599905063, disc_loss = 0.06826912737568326
Trained batch 279 in epoch 15, gen_loss = 0.3980089352599212, disc_loss = 0.06811480972849365
Trained batch 280 in epoch 15, gen_loss = 0.39782824932044086, disc_loss = 0.06799896090254982
Trained batch 281 in epoch 15, gen_loss = 0.3980203911345056, disc_loss = 0.06792552231196711
Trained batch 282 in epoch 15, gen_loss = 0.3978226052156186, disc_loss = 0.06777229262417175
Trained batch 283 in epoch 15, gen_loss = 0.39814013746422783, disc_loss = 0.06761995835137934
Trained batch 284 in epoch 15, gen_loss = 0.3980305418633578, disc_loss = 0.06747347185420885
Trained batch 285 in epoch 15, gen_loss = 0.3978933612783472, disc_loss = 0.0677718620818968
Trained batch 286 in epoch 15, gen_loss = 0.39817741710549864, disc_loss = 0.06845175966503625
Trained batch 287 in epoch 15, gen_loss = 0.39826308832400376, disc_loss = 0.06829827691156727
Trained batch 288 in epoch 15, gen_loss = 0.39795489098786485, disc_loss = 0.06831561968336365
Trained batch 289 in epoch 15, gen_loss = 0.3980108435811668, disc_loss = 0.06820809374531281
Trained batch 290 in epoch 15, gen_loss = 0.39825934622295944, disc_loss = 0.06802800182842
Trained batch 291 in epoch 15, gen_loss = 0.3980599916348719, disc_loss = 0.06791394562715639
Trained batch 292 in epoch 15, gen_loss = 0.3981311481967314, disc_loss = 0.06777078709517424
Trained batch 293 in epoch 15, gen_loss = 0.3980811796829003, disc_loss = 0.06764916104080827
Trained batch 294 in epoch 15, gen_loss = 0.3981965642864421, disc_loss = 0.0676118229563206
Trained batch 295 in epoch 15, gen_loss = 0.3980235201684204, disc_loss = 0.0674395398645838
Trained batch 296 in epoch 15, gen_loss = 0.3979019584880533, disc_loss = 0.06733489290243548
Trained batch 297 in epoch 15, gen_loss = 0.39796829023617225, disc_loss = 0.0671990367821449
Trained batch 298 in epoch 15, gen_loss = 0.3979092754647883, disc_loss = 0.0670674707597265
Trained batch 299 in epoch 15, gen_loss = 0.3980954301357269, disc_loss = 0.06699886023687819
Trained batch 300 in epoch 15, gen_loss = 0.39790260682866424, disc_loss = 0.0668718972122699
Trained batch 301 in epoch 15, gen_loss = 0.3980222864458893, disc_loss = 0.06674277878964678
Trained batch 302 in epoch 15, gen_loss = 0.39822824215731606, disc_loss = 0.06665394694018777
Trained batch 303 in epoch 15, gen_loss = 0.39817891230708674, disc_loss = 0.06648652282188107
Trained batch 304 in epoch 15, gen_loss = 0.3981682705097511, disc_loss = 0.06651677554931308
Trained batch 305 in epoch 15, gen_loss = 0.39833417086819417, disc_loss = 0.06716852423010601
Trained batch 306 in epoch 15, gen_loss = 0.3983904490253436, disc_loss = 0.06702543260887606
Trained batch 307 in epoch 15, gen_loss = 0.398243353835174, disc_loss = 0.06724221215510813
Trained batch 308 in epoch 15, gen_loss = 0.39851708570344546, disc_loss = 0.06728967869636214
Trained batch 309 in epoch 15, gen_loss = 0.39853719597862614, disc_loss = 0.06712928085978473
Trained batch 310 in epoch 15, gen_loss = 0.39855835004634793, disc_loss = 0.06699553705524305
Trained batch 311 in epoch 15, gen_loss = 0.3984372081855933, disc_loss = 0.06686695776461886
Trained batch 312 in epoch 15, gen_loss = 0.3986767015327661, disc_loss = 0.06669486034661531
Trained batch 313 in epoch 15, gen_loss = 0.3988749040350033, disc_loss = 0.06655141184177653
Trained batch 314 in epoch 15, gen_loss = 0.3988051518561348, disc_loss = 0.06653831460114036
Trained batch 315 in epoch 15, gen_loss = 0.39853160158742834, disc_loss = 0.06642903265826215
Trained batch 316 in epoch 15, gen_loss = 0.398587437928287, disc_loss = 0.06625793681829603
Trained batch 317 in epoch 15, gen_loss = 0.39844706841984634, disc_loss = 0.06612818447123252
Trained batch 318 in epoch 15, gen_loss = 0.3986707364317018, disc_loss = 0.06621669480711409
Trained batch 319 in epoch 15, gen_loss = 0.39876510938629506, disc_loss = 0.06631974599149544
Trained batch 320 in epoch 15, gen_loss = 0.39882568249078554, disc_loss = 0.06628332092394802
Trained batch 321 in epoch 15, gen_loss = 0.3989143922277119, disc_loss = 0.06611023344944075
Trained batch 322 in epoch 15, gen_loss = 0.39895855540830655, disc_loss = 0.06615950307021662
Trained batch 323 in epoch 15, gen_loss = 0.3989640892839726, disc_loss = 0.06632139822640629
Trained batch 324 in epoch 15, gen_loss = 0.3989550652870765, disc_loss = 0.06652771614205379
Trained batch 325 in epoch 15, gen_loss = 0.3995935547571241, disc_loss = 0.06666866055992575
Trained batch 326 in epoch 15, gen_loss = 0.3996383292594816, disc_loss = 0.06657857889030414
Trained batch 327 in epoch 15, gen_loss = 0.39935216098660375, disc_loss = 0.06652862658417534
Trained batch 328 in epoch 15, gen_loss = 0.3990412292871794, disc_loss = 0.06647505813014996
Trained batch 329 in epoch 15, gen_loss = 0.3991683708898949, disc_loss = 0.06692580888047814
Trained batch 330 in epoch 15, gen_loss = 0.3990587560611909, disc_loss = 0.06740717027403886
Trained batch 331 in epoch 15, gen_loss = 0.39910178784146366, disc_loss = 0.06730083089198423
Trained batch 332 in epoch 15, gen_loss = 0.39922668822892793, disc_loss = 0.0672135793327077
Trained batch 333 in epoch 15, gen_loss = 0.3991787215906703, disc_loss = 0.0674097792211987
Trained batch 334 in epoch 15, gen_loss = 0.3995203495025635, disc_loss = 0.06738804039726061
Trained batch 335 in epoch 15, gen_loss = 0.3995070115086578, disc_loss = 0.06744038731890864
Trained batch 336 in epoch 15, gen_loss = 0.3991833566204377, disc_loss = 0.06799367787896791
Trained batch 337 in epoch 15, gen_loss = 0.39926018526215523, disc_loss = 0.06800866897697368
Trained batch 338 in epoch 15, gen_loss = 0.39944172283541135, disc_loss = 0.06789587802668501
Trained batch 339 in epoch 15, gen_loss = 0.3993097987245111, disc_loss = 0.06778146484044983
Trained batch 340 in epoch 15, gen_loss = 0.39948269829722094, disc_loss = 0.06766498065621884
Trained batch 341 in epoch 15, gen_loss = 0.39934493592608045, disc_loss = 0.06758289771938794
Trained batch 342 in epoch 15, gen_loss = 0.39952990056474424, disc_loss = 0.06754023404438972
Trained batch 343 in epoch 15, gen_loss = 0.3995185328084369, disc_loss = 0.06745702319312841
Trained batch 344 in epoch 15, gen_loss = 0.3994100339170815, disc_loss = 0.0679768343847515
Trained batch 345 in epoch 15, gen_loss = 0.3996638237051881, disc_loss = 0.06804610619515267
Trained batch 346 in epoch 15, gen_loss = 0.3996959198105232, disc_loss = 0.06830561284233497
Trained batch 347 in epoch 15, gen_loss = 0.39978821241650087, disc_loss = 0.06839998082214988
Trained batch 348 in epoch 15, gen_loss = 0.3997079329538482, disc_loss = 0.06831915642169537
Trained batch 349 in epoch 15, gen_loss = 0.399597225529807, disc_loss = 0.06816723303869367
Trained batch 350 in epoch 15, gen_loss = 0.39982820270407915, disc_loss = 0.06800831334819311
Trained batch 351 in epoch 15, gen_loss = 0.39967449356547813, disc_loss = 0.06792244810970839
Trained batch 352 in epoch 15, gen_loss = 0.3998612628948925, disc_loss = 0.06813682802021503
Trained batch 353 in epoch 15, gen_loss = 0.39989768532709885, disc_loss = 0.06812611443785119
Trained batch 354 in epoch 15, gen_loss = 0.3998449503535956, disc_loss = 0.06815187778376358
Trained batch 355 in epoch 15, gen_loss = 0.3998373573583164, disc_loss = 0.06808813444202703
Trained batch 356 in epoch 15, gen_loss = 0.40003012801084864, disc_loss = 0.0681644143896694
Trained batch 357 in epoch 15, gen_loss = 0.39984473144874894, disc_loss = 0.06882619691814956
Trained batch 358 in epoch 15, gen_loss = 0.4002677402290461, disc_loss = 0.06919387373606309
Trained batch 359 in epoch 15, gen_loss = 0.4004999991092417, disc_loss = 0.0691060289585342
Trained batch 360 in epoch 15, gen_loss = 0.40041815887858, disc_loss = 0.06896701340055367
Trained batch 361 in epoch 15, gen_loss = 0.4004688591423614, disc_loss = 0.0688356827810736
Trained batch 362 in epoch 15, gen_loss = 0.40043478654107445, disc_loss = 0.06877585862232141
Trained batch 363 in epoch 15, gen_loss = 0.40051486506894396, disc_loss = 0.06890812342740842
Trained batch 364 in epoch 15, gen_loss = 0.40027158546121155, disc_loss = 0.06887743914474363
Trained batch 365 in epoch 15, gen_loss = 0.40032523903038986, disc_loss = 0.06876444801830692
Trained batch 366 in epoch 15, gen_loss = 0.40039541643386967, disc_loss = 0.06904772351868958
Trained batch 367 in epoch 15, gen_loss = 0.4001737527711236, disc_loss = 0.06951268978477658
Trained batch 368 in epoch 15, gen_loss = 0.4003641635260285, disc_loss = 0.06950712007619339
Trained batch 369 in epoch 15, gen_loss = 0.40034574294412456, disc_loss = 0.06942032158274103
Trained batch 370 in epoch 15, gen_loss = 0.40036432288406354, disc_loss = 0.06927816172675141
Trained batch 371 in epoch 15, gen_loss = 0.4002833187740336, disc_loss = 0.06936430424872425
Trained batch 372 in epoch 15, gen_loss = 0.4005395228357801, disc_loss = 0.0692121929266857
Trained batch 373 in epoch 15, gen_loss = 0.4005523602114642, disc_loss = 0.06933727211264126
Trained batch 374 in epoch 15, gen_loss = 0.4003635330994924, disc_loss = 0.06974787016957998
Trained batch 375 in epoch 15, gen_loss = 0.40060341334406363, disc_loss = 0.06959500509819531
Trained batch 376 in epoch 15, gen_loss = 0.4010457134847616, disc_loss = 0.06966876227962006
Trained batch 377 in epoch 15, gen_loss = 0.400980122899883, disc_loss = 0.06954727573418822
Trained batch 378 in epoch 15, gen_loss = 0.40088170766830444, disc_loss = 0.06960430477148703
Trained batch 379 in epoch 15, gen_loss = 0.4009615596972014, disc_loss = 0.0694917959724798
Trained batch 380 in epoch 15, gen_loss = 0.4009275858796488, disc_loss = 0.06955708613438322
Trained batch 381 in epoch 15, gen_loss = 0.40063743363500265, disc_loss = 0.06940772799111863
Trained batch 382 in epoch 15, gen_loss = 0.40047542077754245, disc_loss = 0.06961506248425021
Trained batch 383 in epoch 15, gen_loss = 0.4004970324070503, disc_loss = 0.06948321075227189
Trained batch 384 in epoch 15, gen_loss = 0.40059242743950385, disc_loss = 0.06968536500081227
Trained batch 385 in epoch 15, gen_loss = 0.4003469301628943, disc_loss = 0.06983948351545115
Trained batch 386 in epoch 15, gen_loss = 0.40037426575825813, disc_loss = 0.06974356948068361
Trained batch 387 in epoch 15, gen_loss = 0.400499191096763, disc_loss = 0.06977449769643855
Trained batch 388 in epoch 15, gen_loss = 0.4003978311862308, disc_loss = 0.06970624839480018
Trained batch 389 in epoch 15, gen_loss = 0.40055003471863576, disc_loss = 0.06959191615908192
Trained batch 390 in epoch 15, gen_loss = 0.4005825381602168, disc_loss = 0.06949274931007715
Trained batch 391 in epoch 15, gen_loss = 0.4003984276585433, disc_loss = 0.06944918632744906
Trained batch 392 in epoch 15, gen_loss = 0.40032901700216394, disc_loss = 0.06959499145974109
Trained batch 393 in epoch 15, gen_loss = 0.400632945414122, disc_loss = 0.07010600678291797
Trained batch 394 in epoch 15, gen_loss = 0.40066233978995797, disc_loss = 0.06998803473867571
Trained batch 395 in epoch 15, gen_loss = 0.4007179288551061, disc_loss = 0.06998638210187882
Trained batch 396 in epoch 15, gen_loss = 0.40073853993896275, disc_loss = 0.06991155578588283
Trained batch 397 in epoch 15, gen_loss = 0.40070529222188883, disc_loss = 0.06981996033836774
Trained batch 398 in epoch 15, gen_loss = 0.4005528806444995, disc_loss = 0.0697095475712777
Trained batch 399 in epoch 15, gen_loss = 0.40062203332781793, disc_loss = 0.06967115456005558
Trained batch 400 in epoch 15, gen_loss = 0.40061156871610154, disc_loss = 0.06953011822196982
Trained batch 401 in epoch 15, gen_loss = 0.4006430540808398, disc_loss = 0.06949834451681716
Trained batch 402 in epoch 15, gen_loss = 0.400662664518167, disc_loss = 0.06971694155834227
Trained batch 403 in epoch 15, gen_loss = 0.4006788656115532, disc_loss = 0.07000943793601698
Trained batch 404 in epoch 15, gen_loss = 0.4005748667098858, disc_loss = 0.0699746949000307
Trained batch 405 in epoch 15, gen_loss = 0.40055299370453273, disc_loss = 0.06988756652471834
Trained batch 406 in epoch 15, gen_loss = 0.400549424587948, disc_loss = 0.06992640492966266
Trained batch 407 in epoch 15, gen_loss = 0.4005167388594618, disc_loss = 0.06980512403727819
Trained batch 408 in epoch 15, gen_loss = 0.40048616512480456, disc_loss = 0.06978781384012883
Trained batch 409 in epoch 15, gen_loss = 0.40067599721071195, disc_loss = 0.06972721927095114
Trained batch 410 in epoch 15, gen_loss = 0.40057444731974545, disc_loss = 0.06958653059971594
Trained batch 411 in epoch 15, gen_loss = 0.4005300289074194, disc_loss = 0.06951300250095072
Trained batch 412 in epoch 15, gen_loss = 0.400611858968296, disc_loss = 0.0693661987569553
Trained batch 413 in epoch 15, gen_loss = 0.4005038213470708, disc_loss = 0.06925817607150633
Trained batch 414 in epoch 15, gen_loss = 0.400522660562791, disc_loss = 0.06919713348195136
Trained batch 415 in epoch 15, gen_loss = 0.4004800278836718, disc_loss = 0.06916787978843786
Trained batch 416 in epoch 15, gen_loss = 0.40077276545748725, disc_loss = 0.06941731083173332
Trained batch 417 in epoch 15, gen_loss = 0.4006624975415508, disc_loss = 0.06938282152833908
Trained batch 418 in epoch 15, gen_loss = 0.40069542338000275, disc_loss = 0.06925859819510885
Trained batch 419 in epoch 15, gen_loss = 0.40057528998170583, disc_loss = 0.06916895557327994
Trained batch 420 in epoch 15, gen_loss = 0.4004008074129562, disc_loss = 0.06905443888741618
Trained batch 421 in epoch 15, gen_loss = 0.4004513595906479, disc_loss = 0.06894104382446944
Trained batch 422 in epoch 15, gen_loss = 0.40059908372008773, disc_loss = 0.06879982097519134
Trained batch 423 in epoch 15, gen_loss = 0.40060511976480484, disc_loss = 0.06867193853052087
Trained batch 424 in epoch 15, gen_loss = 0.4005996969166924, disc_loss = 0.06861254831228186
Trained batch 425 in epoch 15, gen_loss = 0.4005343563539881, disc_loss = 0.06850281779483801
Trained batch 426 in epoch 15, gen_loss = 0.40039614568828696, disc_loss = 0.06838780290619481
Trained batch 427 in epoch 15, gen_loss = 0.40033516705593214, disc_loss = 0.06828452943319402
Trained batch 428 in epoch 15, gen_loss = 0.40063805110526807, disc_loss = 0.06814277130949782
Trained batch 429 in epoch 15, gen_loss = 0.40048763814360594, disc_loss = 0.06808453751186472
Trained batch 430 in epoch 15, gen_loss = 0.4006032692722267, disc_loss = 0.06799321320111022
Trained batch 431 in epoch 15, gen_loss = 0.4006268061283562, disc_loss = 0.06787965146294381
Trained batch 432 in epoch 15, gen_loss = 0.40039081730413106, disc_loss = 0.06809605465014626
Trained batch 433 in epoch 15, gen_loss = 0.40073586650158405, disc_loss = 0.06876818612239362
Trained batch 434 in epoch 15, gen_loss = 0.4008819974016869, disc_loss = 0.06866553054223287
Trained batch 435 in epoch 15, gen_loss = 0.40074174557257136, disc_loss = 0.06867668003702554
Trained batch 436 in epoch 15, gen_loss = 0.40050339098653204, disc_loss = 0.06855792327287438
Trained batch 437 in epoch 15, gen_loss = 0.4006826382929876, disc_loss = 0.06848228706757126
Trained batch 438 in epoch 15, gen_loss = 0.40068723787479354, disc_loss = 0.0683789375441781
Trained batch 439 in epoch 15, gen_loss = 0.4005883243273605, disc_loss = 0.06831103377150033
Trained batch 440 in epoch 15, gen_loss = 0.40067532766703307, disc_loss = 0.0682321083563002
Trained batch 441 in epoch 15, gen_loss = 0.4005427957929637, disc_loss = 0.06841948036867199
Trained batch 442 in epoch 15, gen_loss = 0.400309626391456, disc_loss = 0.06853938153282682
Trained batch 443 in epoch 15, gen_loss = 0.4005394169204944, disc_loss = 0.06860122385095
Trained batch 444 in epoch 15, gen_loss = 0.4003876006335355, disc_loss = 0.06858169612359633
Trained batch 445 in epoch 15, gen_loss = 0.4003753101478243, disc_loss = 0.06866256630511729
Trained batch 446 in epoch 15, gen_loss = 0.40050727495677785, disc_loss = 0.0689154558844231
Trained batch 447 in epoch 15, gen_loss = 0.4004944155790976, disc_loss = 0.06892881851880313
Trained batch 448 in epoch 15, gen_loss = 0.400241883865709, disc_loss = 0.06889952827174474
Trained batch 449 in epoch 15, gen_loss = 0.40009794500139023, disc_loss = 0.06886834842566815
Trained batch 450 in epoch 15, gen_loss = 0.40004367164920546, disc_loss = 0.06879108974156682
Trained batch 451 in epoch 15, gen_loss = 0.40022080516920683, disc_loss = 0.0686565120529334
Trained batch 452 in epoch 15, gen_loss = 0.40026695786196137, disc_loss = 0.06856639801974822
Trained batch 453 in epoch 15, gen_loss = 0.4001094254496864, disc_loss = 0.06847428563994556
Trained batch 454 in epoch 15, gen_loss = 0.40010624940578754, disc_loss = 0.06851877474256761
Trained batch 455 in epoch 15, gen_loss = 0.4001422264335448, disc_loss = 0.06879480165866482
Trained batch 456 in epoch 15, gen_loss = 0.40005053993909573, disc_loss = 0.06875010997900653
Trained batch 457 in epoch 15, gen_loss = 0.4000453387415565, disc_loss = 0.06872420190166535
Trained batch 458 in epoch 15, gen_loss = 0.39991256951766335, disc_loss = 0.06895388625379578
Trained batch 459 in epoch 15, gen_loss = 0.39999288113220877, disc_loss = 0.06946507101048432
Trained batch 460 in epoch 15, gen_loss = 0.39977049187569197, disc_loss = 0.06985080754384398
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.4624273180961609, disc_loss = 0.04755229502916336
Trained batch 1 in epoch 16, gen_loss = 0.4165305197238922, disc_loss = 0.041090529412031174
Trained batch 2 in epoch 16, gen_loss = 0.3947797914346059, disc_loss = 0.03685826497773329
Trained batch 3 in epoch 16, gen_loss = 0.38093704730272293, disc_loss = 0.039164900314062834
Trained batch 4 in epoch 16, gen_loss = 0.38195628523826597, disc_loss = 0.035465704277157784
Trained batch 5 in epoch 16, gen_loss = 0.3854953149954478, disc_loss = 0.03718701532731453
Trained batch 6 in epoch 16, gen_loss = 0.4039656860487802, disc_loss = 0.0402283708431891
Trained batch 7 in epoch 16, gen_loss = 0.39424632489681244, disc_loss = 0.07383027649484575
Trained batch 8 in epoch 16, gen_loss = 0.4058770471149021, disc_loss = 0.11084212176501751
Trained batch 9 in epoch 16, gen_loss = 0.4074848711490631, disc_loss = 0.10321905296295882
Trained batch 10 in epoch 16, gen_loss = 0.40517896955663507, disc_loss = 0.10636229931630871
Trained batch 11 in epoch 16, gen_loss = 0.4020867198705673, disc_loss = 0.1027608512279888
Trained batch 12 in epoch 16, gen_loss = 0.41030993369909435, disc_loss = 0.0962164053836694
Trained batch 13 in epoch 16, gen_loss = 0.40735133843762533, disc_loss = 0.09100459555962256
Trained batch 14 in epoch 16, gen_loss = 0.404747074842453, disc_loss = 0.08775535685320696
Trained batch 15 in epoch 16, gen_loss = 0.3992747887969017, disc_loss = 0.08487952395807952
Trained batch 16 in epoch 16, gen_loss = 0.3966742578674765, disc_loss = 0.08094861424144577
Trained batch 17 in epoch 16, gen_loss = 0.39520324269930523, disc_loss = 0.07997658538321654
Trained batch 18 in epoch 16, gen_loss = 0.3947826216095372, disc_loss = 0.08697305796177764
Trained batch 19 in epoch 16, gen_loss = 0.38776995241642, disc_loss = 0.10669588092714548
Trained batch 20 in epoch 16, gen_loss = 0.3868348953269777, disc_loss = 0.1049606493186383
Trained batch 21 in epoch 16, gen_loss = 0.38833555714650586, disc_loss = 0.10405327701433138
Trained batch 22 in epoch 16, gen_loss = 0.38757670703141583, disc_loss = 0.1011325597115185
Trained batch 23 in epoch 16, gen_loss = 0.3868020760516326, disc_loss = 0.09942056409393747
Trained batch 24 in epoch 16, gen_loss = 0.3900801026821136, disc_loss = 0.09799251958727836
Trained batch 25 in epoch 16, gen_loss = 0.3888562252888313, disc_loss = 0.09688788408843371
Trained batch 26 in epoch 16, gen_loss = 0.39028991924391854, disc_loss = 0.09953739728640627
Trained batch 27 in epoch 16, gen_loss = 0.38695337091173443, disc_loss = 0.102650226626013
Trained batch 28 in epoch 16, gen_loss = 0.38870768300418196, disc_loss = 0.10308578828799314
Trained batch 29 in epoch 16, gen_loss = 0.3898778061072032, disc_loss = 0.09998477523525556
Trained batch 30 in epoch 16, gen_loss = 0.3902089211248582, disc_loss = 0.09723619948471746
Trained batch 31 in epoch 16, gen_loss = 0.3903876952826977, disc_loss = 0.09451783186523244
Trained batch 32 in epoch 16, gen_loss = 0.3909005911061258, disc_loss = 0.09252213630260843
Trained batch 33 in epoch 16, gen_loss = 0.3909276644973194, disc_loss = 0.09124608085874249
Trained batch 34 in epoch 16, gen_loss = 0.3904831741537367, disc_loss = 0.0892182098435504
Trained batch 35 in epoch 16, gen_loss = 0.39106204609076184, disc_loss = 0.08712941938493815
Trained batch 36 in epoch 16, gen_loss = 0.38980337091394374, disc_loss = 0.08589287316174926
Trained batch 37 in epoch 16, gen_loss = 0.391242683718079, disc_loss = 0.08506294979566806
Trained batch 38 in epoch 16, gen_loss = 0.38949799919739747, disc_loss = 0.08547848666039033
Trained batch 39 in epoch 16, gen_loss = 0.38828088864684107, disc_loss = 0.08413647033739835
Trained batch 40 in epoch 16, gen_loss = 0.38610054298145013, disc_loss = 0.08446440148371749
Trained batch 41 in epoch 16, gen_loss = 0.38856256788685206, disc_loss = 0.0886935333810037
Trained batch 42 in epoch 16, gen_loss = 0.3887120388274969, disc_loss = 0.08812372275996347
Trained batch 43 in epoch 16, gen_loss = 0.3883488814939152, disc_loss = 0.08654938614927232
Trained batch 44 in epoch 16, gen_loss = 0.38848942518234253, disc_loss = 0.08548203046537108
Trained batch 45 in epoch 16, gen_loss = 0.3888923247223315, disc_loss = 0.08412855889891153
Trained batch 46 in epoch 16, gen_loss = 0.39096295833587646, disc_loss = 0.08270689300162361
Trained batch 47 in epoch 16, gen_loss = 0.392274659126997, disc_loss = 0.08180633065057918
Trained batch 48 in epoch 16, gen_loss = 0.3913269055132963, disc_loss = 0.08098660525390688
Trained batch 49 in epoch 16, gen_loss = 0.3933926343917847, disc_loss = 0.07981790686026216
Trained batch 50 in epoch 16, gen_loss = 0.39238105334487616, disc_loss = 0.07895619336369575
Trained batch 51 in epoch 16, gen_loss = 0.3926537518317883, disc_loss = 0.07829876002282478
Trained batch 52 in epoch 16, gen_loss = 0.39554206267842706, disc_loss = 0.0772224500740193
Trained batch 53 in epoch 16, gen_loss = 0.39640530943870544, disc_loss = 0.07652161496311978
Trained batch 54 in epoch 16, gen_loss = 0.39634277332912793, disc_loss = 0.07765963841229677
Trained batch 55 in epoch 16, gen_loss = 0.3964384352522237, disc_loss = 0.07732785258641732
Trained batch 56 in epoch 16, gen_loss = 0.39773836731910706, disc_loss = 0.07664044225882542
Trained batch 57 in epoch 16, gen_loss = 0.39809892763351573, disc_loss = 0.07568257329343207
Trained batch 58 in epoch 16, gen_loss = 0.39912159210544523, disc_loss = 0.07456727510602293
Trained batch 59 in epoch 16, gen_loss = 0.39980861991643907, disc_loss = 0.07350575192831457
Trained batch 60 in epoch 16, gen_loss = 0.4020629979547907, disc_loss = 0.07258146318805511
Trained batch 61 in epoch 16, gen_loss = 0.40226948453534034, disc_loss = 0.07261126958614876
Trained batch 62 in epoch 16, gen_loss = 0.40422719433194115, disc_loss = 0.0742023503407836
Trained batch 63 in epoch 16, gen_loss = 0.40395487379282713, disc_loss = 0.07395168581570033
Trained batch 64 in epoch 16, gen_loss = 0.4032116417701428, disc_loss = 0.07420380311803176
Trained batch 65 in epoch 16, gen_loss = 0.4045949239622463, disc_loss = 0.07716005511412566
Trained batch 66 in epoch 16, gen_loss = 0.4053370583413252, disc_loss = 0.07627730328700881
Trained batch 67 in epoch 16, gen_loss = 0.40458301279474707, disc_loss = 0.07714923001442324
Trained batch 68 in epoch 16, gen_loss = 0.4050451737383138, disc_loss = 0.07850909158857404
Trained batch 69 in epoch 16, gen_loss = 0.4045805339302335, disc_loss = 0.07789537551413689
Trained batch 70 in epoch 16, gen_loss = 0.4033481541653754, disc_loss = 0.07750778368503695
Trained batch 71 in epoch 16, gen_loss = 0.4034814379281468, disc_loss = 0.07660991682981451
Trained batch 72 in epoch 16, gen_loss = 0.403894987824845, disc_loss = 0.07581858612494925
Trained batch 73 in epoch 16, gen_loss = 0.4040098258772412, disc_loss = 0.07513984192062069
Trained batch 74 in epoch 16, gen_loss = 0.4037430012226105, disc_loss = 0.07459854235251745
Trained batch 75 in epoch 16, gen_loss = 0.40290074991552455, disc_loss = 0.07429291935343492
Trained batch 76 in epoch 16, gen_loss = 0.40212444941718856, disc_loss = 0.07379245312957021
Trained batch 77 in epoch 16, gen_loss = 0.40272151736112743, disc_loss = 0.07308626724168277
Trained batch 78 in epoch 16, gen_loss = 0.4033894229538833, disc_loss = 0.07330232042866418
Trained batch 79 in epoch 16, gen_loss = 0.4020672757178545, disc_loss = 0.07564554228447377
Trained batch 80 in epoch 16, gen_loss = 0.4029525036429181, disc_loss = 0.07539849935306443
Trained batch 81 in epoch 16, gen_loss = 0.40374233046682867, disc_loss = 0.07468338083566689
Trained batch 82 in epoch 16, gen_loss = 0.4040894713028368, disc_loss = 0.07405747260045574
Trained batch 83 in epoch 16, gen_loss = 0.4039507277664684, disc_loss = 0.07330489331590277
Trained batch 84 in epoch 16, gen_loss = 0.403670054323533, disc_loss = 0.07299759177600636
Trained batch 85 in epoch 16, gen_loss = 0.40426592043665954, disc_loss = 0.07247977734131869
Trained batch 86 in epoch 16, gen_loss = 0.4035775603234083, disc_loss = 0.0723307029526124
Trained batch 87 in epoch 16, gen_loss = 0.40399198403412645, disc_loss = 0.07250280106778849
Trained batch 88 in epoch 16, gen_loss = 0.4035950078723136, disc_loss = 0.07233425999960202
Trained batch 89 in epoch 16, gen_loss = 0.40382984711064235, disc_loss = 0.07266323632664151
Trained batch 90 in epoch 16, gen_loss = 0.4039247248853956, disc_loss = 0.07308340514754201
Trained batch 91 in epoch 16, gen_loss = 0.4040131455530291, disc_loss = 0.07446206474433774
Trained batch 92 in epoch 16, gen_loss = 0.40305079792135506, disc_loss = 0.07447205692209223
Trained batch 93 in epoch 16, gen_loss = 0.40339247818956986, disc_loss = 0.0739229578683351
Trained batch 94 in epoch 16, gen_loss = 0.4037326499035484, disc_loss = 0.07323955033758753
Trained batch 95 in epoch 16, gen_loss = 0.4033124915634592, disc_loss = 0.07404524152904439
Trained batch 96 in epoch 16, gen_loss = 0.40282459326626097, disc_loss = 0.07563123217371014
Trained batch 97 in epoch 16, gen_loss = 0.4023876555111943, disc_loss = 0.075371852211122
Trained batch 98 in epoch 16, gen_loss = 0.4025106357805657, disc_loss = 0.07514126180210198
Trained batch 99 in epoch 16, gen_loss = 0.40289231777191165, disc_loss = 0.07515239122323691
Trained batch 100 in epoch 16, gen_loss = 0.402920675749826, disc_loss = 0.07512111654781764
Trained batch 101 in epoch 16, gen_loss = 0.4020223430558747, disc_loss = 0.07651403592899442
Trained batch 102 in epoch 16, gen_loss = 0.4022037123592154, disc_loss = 0.07623701805737122
Trained batch 103 in epoch 16, gen_loss = 0.4017369199830752, disc_loss = 0.07654506264505191
Trained batch 104 in epoch 16, gen_loss = 0.4014581935746329, disc_loss = 0.07635931063088633
Trained batch 105 in epoch 16, gen_loss = 0.4017384940723203, disc_loss = 0.07594026469643105
Trained batch 106 in epoch 16, gen_loss = 0.402226544707735, disc_loss = 0.07543098006536748
Trained batch 107 in epoch 16, gen_loss = 0.40281427927591185, disc_loss = 0.07526290681454595
Trained batch 108 in epoch 16, gen_loss = 0.40281776331980296, disc_loss = 0.0754239264824385
Trained batch 109 in epoch 16, gen_loss = 0.4034456047144803, disc_loss = 0.07493595703589645
Trained batch 110 in epoch 16, gen_loss = 0.40377069378758335, disc_loss = 0.07514834611231948
Trained batch 111 in epoch 16, gen_loss = 0.4030820453273399, disc_loss = 0.07682507557495098
Trained batch 112 in epoch 16, gen_loss = 0.4037835371177808, disc_loss = 0.07686599554180835
Trained batch 113 in epoch 16, gen_loss = 0.4028951627643485, disc_loss = 0.07672021311724134
Trained batch 114 in epoch 16, gen_loss = 0.4028165384479191, disc_loss = 0.076498608412626
Trained batch 115 in epoch 16, gen_loss = 0.4034948408089835, disc_loss = 0.0761244092056335
Trained batch 116 in epoch 16, gen_loss = 0.4034989183275109, disc_loss = 0.07557336466275474
Trained batch 117 in epoch 16, gen_loss = 0.402933488963014, disc_loss = 0.07522211756588797
Trained batch 118 in epoch 16, gen_loss = 0.403456652364811, disc_loss = 0.07465831022866133
Trained batch 119 in epoch 16, gen_loss = 0.4035217225551605, disc_loss = 0.07420792854391038
Trained batch 120 in epoch 16, gen_loss = 0.4035672208001791, disc_loss = 0.07410446180353973
Trained batch 121 in epoch 16, gen_loss = 0.40277714709766577, disc_loss = 0.07380787999231796
Trained batch 122 in epoch 16, gen_loss = 0.40256041482212096, disc_loss = 0.07349109920726074
Trained batch 123 in epoch 16, gen_loss = 0.40261880933277067, disc_loss = 0.07312395109704906
Trained batch 124 in epoch 16, gen_loss = 0.4028498933315277, disc_loss = 0.07259921482950449
Trained batch 125 in epoch 16, gen_loss = 0.4028866948589446, disc_loss = 0.07241405455750369
Trained batch 126 in epoch 16, gen_loss = 0.40250301196819216, disc_loss = 0.0730668670446502
Trained batch 127 in epoch 16, gen_loss = 0.4023212802130729, disc_loss = 0.07300710803974653
Trained batch 128 in epoch 16, gen_loss = 0.40192239252171774, disc_loss = 0.07266799870936215
Trained batch 129 in epoch 16, gen_loss = 0.40160693778441503, disc_loss = 0.07222269822915013
Trained batch 130 in epoch 16, gen_loss = 0.4010318679208974, disc_loss = 0.07178677225357476
Trained batch 131 in epoch 16, gen_loss = 0.4015275264779727, disc_loss = 0.07131471894822564
Trained batch 132 in epoch 16, gen_loss = 0.40122117427058684, disc_loss = 0.07093758117127463
Trained batch 133 in epoch 16, gen_loss = 0.4017319699276739, disc_loss = 0.07101414639697369
Trained batch 134 in epoch 16, gen_loss = 0.4011098932336878, disc_loss = 0.0713821896041433
Trained batch 135 in epoch 16, gen_loss = 0.40150921419262886, disc_loss = 0.07103549470604562
Trained batch 136 in epoch 16, gen_loss = 0.40190938419669214, disc_loss = 0.07079536185674641
Trained batch 137 in epoch 16, gen_loss = 0.4023139656021975, disc_loss = 0.07051278057548663
Trained batch 138 in epoch 16, gen_loss = 0.40233616091364577, disc_loss = 0.07039958375955013
Trained batch 139 in epoch 16, gen_loss = 0.4028501387153353, disc_loss = 0.07060189926331596
Trained batch 140 in epoch 16, gen_loss = 0.40253570231985536, disc_loss = 0.07081207335127372
Trained batch 141 in epoch 16, gen_loss = 0.40333459242968495, disc_loss = 0.0704750780501521
Trained batch 142 in epoch 16, gen_loss = 0.40340897086616995, disc_loss = 0.07103549661049685
Trained batch 143 in epoch 16, gen_loss = 0.402253232896328, disc_loss = 0.0717581650048184
Trained batch 144 in epoch 16, gen_loss = 0.40181805738087356, disc_loss = 0.07132742873168198
Trained batch 145 in epoch 16, gen_loss = 0.4024145341899297, disc_loss = 0.07095403737733014
Trained batch 146 in epoch 16, gen_loss = 0.4022851069362796, disc_loss = 0.07087997190628936
Trained batch 147 in epoch 16, gen_loss = 0.4016958144870964, disc_loss = 0.07198435320468569
Trained batch 148 in epoch 16, gen_loss = 0.4021365216514408, disc_loss = 0.07295623312285482
Trained batch 149 in epoch 16, gen_loss = 0.40242392162481944, disc_loss = 0.07263500288749734
Trained batch 150 in epoch 16, gen_loss = 0.4025361514249385, disc_loss = 0.07251840808262296
Trained batch 151 in epoch 16, gen_loss = 0.4022841571192992, disc_loss = 0.07225653387630653
Trained batch 152 in epoch 16, gen_loss = 0.4026923275071811, disc_loss = 0.07199371292627131
Trained batch 153 in epoch 16, gen_loss = 0.40261251992219454, disc_loss = 0.07171831528547329
Trained batch 154 in epoch 16, gen_loss = 0.40250477463968337, disc_loss = 0.07143278045639877
Trained batch 155 in epoch 16, gen_loss = 0.4019715071488649, disc_loss = 0.07122183978581467
Trained batch 156 in epoch 16, gen_loss = 0.4016024234947885, disc_loss = 0.07096306855677609
Trained batch 157 in epoch 16, gen_loss = 0.40112740235238137, disc_loss = 0.07091676914781521
Trained batch 158 in epoch 16, gen_loss = 0.4014991062617152, disc_loss = 0.07103418450474551
Trained batch 159 in epoch 16, gen_loss = 0.40109930876642463, disc_loss = 0.07112072244635784
Trained batch 160 in epoch 16, gen_loss = 0.4008863733051726, disc_loss = 0.07076624089053699
Trained batch 161 in epoch 16, gen_loss = 0.4008149673909317, disc_loss = 0.0704201033660843
Trained batch 162 in epoch 16, gen_loss = 0.4007163402493015, disc_loss = 0.07009343637233498
Trained batch 163 in epoch 16, gen_loss = 0.40094597401415427, disc_loss = 0.06972218193568108
Trained batch 164 in epoch 16, gen_loss = 0.40134658470298307, disc_loss = 0.06944889644104422
Trained batch 165 in epoch 16, gen_loss = 0.4010069517486067, disc_loss = 0.06923751062881875
Trained batch 166 in epoch 16, gen_loss = 0.4005005131224672, disc_loss = 0.0693005936075292
Trained batch 167 in epoch 16, gen_loss = 0.4003111571073532, disc_loss = 0.06914778826536522
Trained batch 168 in epoch 16, gen_loss = 0.40015450578469497, disc_loss = 0.0688544404665394
Trained batch 169 in epoch 16, gen_loss = 0.4002241427407545, disc_loss = 0.06860567783827291
Trained batch 170 in epoch 16, gen_loss = 0.4008301027685578, disc_loss = 0.06868467481033495
Trained batch 171 in epoch 16, gen_loss = 0.40045033932425256, disc_loss = 0.06943295347006169
Trained batch 172 in epoch 16, gen_loss = 0.40080565851547817, disc_loss = 0.07027428314046708
Trained batch 173 in epoch 16, gen_loss = 0.4007884207470664, disc_loss = 0.06999710250388959
Trained batch 174 in epoch 16, gen_loss = 0.4006942577021463, disc_loss = 0.070595491326281
Trained batch 175 in epoch 16, gen_loss = 0.4010918512940407, disc_loss = 0.07045649018519642
Trained batch 176 in epoch 16, gen_loss = 0.40178497059870577, disc_loss = 0.07015922169942977
Trained batch 177 in epoch 16, gen_loss = 0.40169743306181405, disc_loss = 0.06988036595912797
Trained batch 178 in epoch 16, gen_loss = 0.4018444572081113, disc_loss = 0.06971230820945189
Trained batch 179 in epoch 16, gen_loss = 0.40177718301614124, disc_loss = 0.06972649471006459
Trained batch 180 in epoch 16, gen_loss = 0.40154352438384, disc_loss = 0.07021058751115812
Trained batch 181 in epoch 16, gen_loss = 0.4009912677191116, disc_loss = 0.0709794009882179
Trained batch 182 in epoch 16, gen_loss = 0.4010220355674869, disc_loss = 0.07076223228187835
Trained batch 183 in epoch 16, gen_loss = 0.4009756920454295, disc_loss = 0.07054904357368208
Trained batch 184 in epoch 16, gen_loss = 0.40064006125604784, disc_loss = 0.07040148672421237
Trained batch 185 in epoch 16, gen_loss = 0.40061320620839314, disc_loss = 0.07009451460313573
Trained batch 186 in epoch 16, gen_loss = 0.4004800738816593, disc_loss = 0.0700239026022547
Trained batch 187 in epoch 16, gen_loss = 0.4005935922899145, disc_loss = 0.06972097981958947
Trained batch 188 in epoch 16, gen_loss = 0.40022718054907663, disc_loss = 0.06955323579213607
Trained batch 189 in epoch 16, gen_loss = 0.4005289673805237, disc_loss = 0.06940922942992887
Trained batch 190 in epoch 16, gen_loss = 0.40086102423243497, disc_loss = 0.06914697833242217
Trained batch 191 in epoch 16, gen_loss = 0.40105804009363055, disc_loss = 0.06890269386349246
Trained batch 192 in epoch 16, gen_loss = 0.40110944126554104, disc_loss = 0.06860793569159014
Trained batch 193 in epoch 16, gen_loss = 0.4007589452967201, disc_loss = 0.06845138575305644
Trained batch 194 in epoch 16, gen_loss = 0.4007183214028676, disc_loss = 0.06818205389456872
Trained batch 195 in epoch 16, gen_loss = 0.40135252734228055, disc_loss = 0.06870579328007843
Trained batch 196 in epoch 16, gen_loss = 0.4011979434393384, disc_loss = 0.06981363049164642
Trained batch 197 in epoch 16, gen_loss = 0.40097906448022286, disc_loss = 0.06952310877504071
Trained batch 198 in epoch 16, gen_loss = 0.40102073984529507, disc_loss = 0.06941655470086402
Trained batch 199 in epoch 16, gen_loss = 0.4013987523317337, disc_loss = 0.06921020517125726
Trained batch 200 in epoch 16, gen_loss = 0.40159157259547296, disc_loss = 0.06894107230137385
Trained batch 201 in epoch 16, gen_loss = 0.40188382787279564, disc_loss = 0.06875744134206141
Trained batch 202 in epoch 16, gen_loss = 0.4016788889621866, disc_loss = 0.06854992619087102
Trained batch 203 in epoch 16, gen_loss = 0.40216249899536954, disc_loss = 0.06851880577867668
Trained batch 204 in epoch 16, gen_loss = 0.40210671381252566, disc_loss = 0.06858898427155687
Trained batch 205 in epoch 16, gen_loss = 0.40185719554864086, disc_loss = 0.06899780784145866
Trained batch 206 in epoch 16, gen_loss = 0.40266210560637394, disc_loss = 0.06939735537583845
Trained batch 207 in epoch 16, gen_loss = 0.4028246875565786, disc_loss = 0.06914888608466405
Trained batch 208 in epoch 16, gen_loss = 0.40258978357155356, disc_loss = 0.06892958848902056
Trained batch 209 in epoch 16, gen_loss = 0.40252465903759005, disc_loss = 0.0689000689779364
Trained batch 210 in epoch 16, gen_loss = 0.4025259789132394, disc_loss = 0.0686120360215764
Trained batch 211 in epoch 16, gen_loss = 0.4024229461573205, disc_loss = 0.06853986219151544
Trained batch 212 in epoch 16, gen_loss = 0.40258959439438835, disc_loss = 0.06831173962987784
Trained batch 213 in epoch 16, gen_loss = 0.40210609110159296, disc_loss = 0.06858419251375805
Trained batch 214 in epoch 16, gen_loss = 0.40216347602910774, disc_loss = 0.06974609501573235
Trained batch 215 in epoch 16, gen_loss = 0.4019869666684557, disc_loss = 0.07013174871206973
Trained batch 216 in epoch 16, gen_loss = 0.40200636779657706, disc_loss = 0.07001826682552902
Trained batch 217 in epoch 16, gen_loss = 0.4018056577225344, disc_loss = 0.0699200734299599
Trained batch 218 in epoch 16, gen_loss = 0.4013156666331095, disc_loss = 0.07046533714911846
Trained batch 219 in epoch 16, gen_loss = 0.4018564141609452, disc_loss = 0.0708126590544866
Trained batch 220 in epoch 16, gen_loss = 0.4018626086312721, disc_loss = 0.07078021183626819
Trained batch 221 in epoch 16, gen_loss = 0.40166739206593316, disc_loss = 0.07104177382430649
Trained batch 222 in epoch 16, gen_loss = 0.40193992091401276, disc_loss = 0.07173653112749481
Trained batch 223 in epoch 16, gen_loss = 0.4018896408379078, disc_loss = 0.07147322256267737
Trained batch 224 in epoch 16, gen_loss = 0.40170026699701944, disc_loss = 0.07163884630219804
Trained batch 225 in epoch 16, gen_loss = 0.4018801310948566, disc_loss = 0.07141881042563941
Trained batch 226 in epoch 16, gen_loss = 0.4022767612062362, disc_loss = 0.07116959763830323
Trained batch 227 in epoch 16, gen_loss = 0.40204935494744987, disc_loss = 0.0709387309187533
Trained batch 228 in epoch 16, gen_loss = 0.4018523293551399, disc_loss = 0.07085107988779592
Trained batch 229 in epoch 16, gen_loss = 0.401802802733753, disc_loss = 0.07098492328482478
Trained batch 230 in epoch 16, gen_loss = 0.4014746465466239, disc_loss = 0.07123976264923036
Trained batch 231 in epoch 16, gen_loss = 0.40149511525343207, disc_loss = 0.07149740780205947
Trained batch 232 in epoch 16, gen_loss = 0.4016235692050836, disc_loss = 0.07152558942705137
Trained batch 233 in epoch 16, gen_loss = 0.40203423594307697, disc_loss = 0.0712957978925198
Trained batch 234 in epoch 16, gen_loss = 0.4020297080912489, disc_loss = 0.07108315686358416
Trained batch 235 in epoch 16, gen_loss = 0.40199203662953137, disc_loss = 0.07112506000814423
Trained batch 236 in epoch 16, gen_loss = 0.40181041468044876, disc_loss = 0.07122084907480056
Trained batch 237 in epoch 16, gen_loss = 0.4018302264333773, disc_loss = 0.07102408985208188
Trained batch 238 in epoch 16, gen_loss = 0.4018808211741587, disc_loss = 0.07079361761417474
Trained batch 239 in epoch 16, gen_loss = 0.4018239421149095, disc_loss = 0.07062315573372567
Trained batch 240 in epoch 16, gen_loss = 0.4018313216965228, disc_loss = 0.0704527797981231
Trained batch 241 in epoch 16, gen_loss = 0.40164762538326676, disc_loss = 0.07060927129927869
Trained batch 242 in epoch 16, gen_loss = 0.40180384634453575, disc_loss = 0.07058317133382637
Trained batch 243 in epoch 16, gen_loss = 0.40159964769101536, disc_loss = 0.07045678890951466
Trained batch 244 in epoch 16, gen_loss = 0.40148392721098297, disc_loss = 0.0702894268025245
Trained batch 245 in epoch 16, gen_loss = 0.4015923812379682, disc_loss = 0.07004023076421241
Trained batch 246 in epoch 16, gen_loss = 0.4016214694812713, disc_loss = 0.06987236078587258
Trained batch 247 in epoch 16, gen_loss = 0.40169864676652417, disc_loss = 0.0697289422462364
Trained batch 248 in epoch 16, gen_loss = 0.40187861881102904, disc_loss = 0.06953401750245367
Trained batch 249 in epoch 16, gen_loss = 0.402137926697731, disc_loss = 0.06932204151526093
Trained batch 250 in epoch 16, gen_loss = 0.4022632102329892, disc_loss = 0.06925256466084861
Trained batch 251 in epoch 16, gen_loss = 0.4017599247514255, disc_loss = 0.0696529087218796
Trained batch 252 in epoch 16, gen_loss = 0.4018797846179706, disc_loss = 0.07055359759658811
Trained batch 253 in epoch 16, gen_loss = 0.40191417791712003, disc_loss = 0.07036246256316155
Trained batch 254 in epoch 16, gen_loss = 0.4019202643749761, disc_loss = 0.07014088362966682
Trained batch 255 in epoch 16, gen_loss = 0.4019553150283173, disc_loss = 0.06991119615486241
Trained batch 256 in epoch 16, gen_loss = 0.40191747845378833, disc_loss = 0.06989280505156586
Trained batch 257 in epoch 16, gen_loss = 0.4016255518031675, disc_loss = 0.07026525624024198
Trained batch 258 in epoch 16, gen_loss = 0.40186177061791584, disc_loss = 0.070558468832789
Trained batch 259 in epoch 16, gen_loss = 0.40174216971947596, disc_loss = 0.07035282755342241
Trained batch 260 in epoch 16, gen_loss = 0.4013157139792753, disc_loss = 0.07026163925027824
Trained batch 261 in epoch 16, gen_loss = 0.4011809126338886, disc_loss = 0.07012079115459369
Trained batch 262 in epoch 16, gen_loss = 0.4011933782028155, disc_loss = 0.06988662818071394
Trained batch 263 in epoch 16, gen_loss = 0.40146627446467226, disc_loss = 0.06977279100101441
Trained batch 264 in epoch 16, gen_loss = 0.4014213513653233, disc_loss = 0.06961739055179762
Trained batch 265 in epoch 16, gen_loss = 0.40163862335502654, disc_loss = 0.06946572196788918
Trained batch 266 in epoch 16, gen_loss = 0.40121237660168707, disc_loss = 0.06940149530168441
Trained batch 267 in epoch 16, gen_loss = 0.40109059236832517, disc_loss = 0.06920732721450057
Trained batch 268 in epoch 16, gen_loss = 0.40091404662256347, disc_loss = 0.06912771362783629
Trained batch 269 in epoch 16, gen_loss = 0.4008294332910467, disc_loss = 0.0690581671031261
Trained batch 270 in epoch 16, gen_loss = 0.40082984260967297, disc_loss = 0.06886751229816367
Trained batch 271 in epoch 16, gen_loss = 0.40136826651937824, disc_loss = 0.06864953303695931
Trained batch 272 in epoch 16, gen_loss = 0.40124934835311693, disc_loss = 0.06848254098792325
Trained batch 273 in epoch 16, gen_loss = 0.40130077345962945, disc_loss = 0.06850507466911074
Trained batch 274 in epoch 16, gen_loss = 0.40097318985245445, disc_loss = 0.06854852419346572
Trained batch 275 in epoch 16, gen_loss = 0.40136459545380826, disc_loss = 0.06845793263325332
Trained batch 276 in epoch 16, gen_loss = 0.4013946124147422, disc_loss = 0.06825406769364534
Trained batch 277 in epoch 16, gen_loss = 0.4011569876465008, disc_loss = 0.0683866691902923
Trained batch 278 in epoch 16, gen_loss = 0.4014334522695097, disc_loss = 0.06875535288298215
Trained batch 279 in epoch 16, gen_loss = 0.40142065488866396, disc_loss = 0.06868119561113417
Trained batch 280 in epoch 16, gen_loss = 0.4013704702099023, disc_loss = 0.06851971387412412
Trained batch 281 in epoch 16, gen_loss = 0.40147724198111406, disc_loss = 0.06836203206330538
Trained batch 282 in epoch 16, gen_loss = 0.4014664772542542, disc_loss = 0.06818465234928965
Trained batch 283 in epoch 16, gen_loss = 0.4014666114054935, disc_loss = 0.06798891141407297
Trained batch 284 in epoch 16, gen_loss = 0.4012740576476381, disc_loss = 0.06795721488694349
Trained batch 285 in epoch 16, gen_loss = 0.4014312780195183, disc_loss = 0.06792593180117282
Trained batch 286 in epoch 16, gen_loss = 0.40161635817551034, disc_loss = 0.06861337833106518
Trained batch 287 in epoch 16, gen_loss = 0.40157402865588665, disc_loss = 0.06884325648166446
Trained batch 288 in epoch 16, gen_loss = 0.40185608707084786, disc_loss = 0.06866791998406802
Trained batch 289 in epoch 16, gen_loss = 0.4019646075265161, disc_loss = 0.06856115336433567
Trained batch 290 in epoch 16, gen_loss = 0.40208226309199513, disc_loss = 0.0683816186763679
Trained batch 291 in epoch 16, gen_loss = 0.40219221172267444, disc_loss = 0.06821791028399786
Trained batch 292 in epoch 16, gen_loss = 0.4019615959388811, disc_loss = 0.06805262087173633
Trained batch 293 in epoch 16, gen_loss = 0.4021192657298782, disc_loss = 0.0679463154389238
Trained batch 294 in epoch 16, gen_loss = 0.4022684333688122, disc_loss = 0.06785454325125378
Trained batch 295 in epoch 16, gen_loss = 0.40200065901956045, disc_loss = 0.06797140554172566
Trained batch 296 in epoch 16, gen_loss = 0.40220793870964433, disc_loss = 0.0681011885442216
Trained batch 297 in epoch 16, gen_loss = 0.401909403552945, disc_loss = 0.06809329523411173
Trained batch 298 in epoch 16, gen_loss = 0.40188185128081205, disc_loss = 0.06801524914701447
Trained batch 299 in epoch 16, gen_loss = 0.4019274969895681, disc_loss = 0.06796353744342923
Trained batch 300 in epoch 16, gen_loss = 0.4018162212696582, disc_loss = 0.06800964147322795
Trained batch 301 in epoch 16, gen_loss = 0.4018955186305457, disc_loss = 0.06792048763927837
Trained batch 302 in epoch 16, gen_loss = 0.40190356084615875, disc_loss = 0.06775108451890473
Trained batch 303 in epoch 16, gen_loss = 0.40192156363474696, disc_loss = 0.06759700058395729
Trained batch 304 in epoch 16, gen_loss = 0.401982363032513, disc_loss = 0.06752439587697631
Trained batch 305 in epoch 16, gen_loss = 0.402235078947996, disc_loss = 0.06741290831074022
Trained batch 306 in epoch 16, gen_loss = 0.4019685592441683, disc_loss = 0.06731188396167871
Trained batch 307 in epoch 16, gen_loss = 0.4020723352184543, disc_loss = 0.06713576862503859
Trained batch 308 in epoch 16, gen_loss = 0.4021376955856397, disc_loss = 0.06693962840272964
Trained batch 309 in epoch 16, gen_loss = 0.40208985440192685, disc_loss = 0.06686113137271135
Trained batch 310 in epoch 16, gen_loss = 0.40213654048956476, disc_loss = 0.06669923220536525
Trained batch 311 in epoch 16, gen_loss = 0.4019881612024246, disc_loss = 0.06682659299351656
Trained batch 312 in epoch 16, gen_loss = 0.401793686060098, disc_loss = 0.06715723944191164
Trained batch 313 in epoch 16, gen_loss = 0.4020065108112469, disc_loss = 0.06725631868407415
Trained batch 314 in epoch 16, gen_loss = 0.4019820289006309, disc_loss = 0.06708760189986418
Trained batch 315 in epoch 16, gen_loss = 0.40199927306627925, disc_loss = 0.06695512073303136
Trained batch 316 in epoch 16, gen_loss = 0.4020073000188882, disc_loss = 0.06677304815254188
Trained batch 317 in epoch 16, gen_loss = 0.40195289891470903, disc_loss = 0.06662406364116091
Trained batch 318 in epoch 16, gen_loss = 0.40205311840604463, disc_loss = 0.06649525907346074
Trained batch 319 in epoch 16, gen_loss = 0.4020242911763489, disc_loss = 0.06635454954812303
Trained batch 320 in epoch 16, gen_loss = 0.4020300198381192, disc_loss = 0.06637789008448429
Trained batch 321 in epoch 16, gen_loss = 0.4018770446133169, disc_loss = 0.06649691885719018
Trained batch 322 in epoch 16, gen_loss = 0.40220161331327337, disc_loss = 0.06641305672817924
Trained batch 323 in epoch 16, gen_loss = 0.40221474825600045, disc_loss = 0.06630626432367681
Trained batch 324 in epoch 16, gen_loss = 0.40207429436536934, disc_loss = 0.06629285843326495
Trained batch 325 in epoch 16, gen_loss = 0.40178608053301007, disc_loss = 0.06613082414710082
Trained batch 326 in epoch 16, gen_loss = 0.4020268875159984, disc_loss = 0.06595753199087644
Trained batch 327 in epoch 16, gen_loss = 0.4019840285181999, disc_loss = 0.06586784203593596
Trained batch 328 in epoch 16, gen_loss = 0.4020869780818742, disc_loss = 0.06590993419051805
Trained batch 329 in epoch 16, gen_loss = 0.4018654238093983, disc_loss = 0.06603144476980423
Trained batch 330 in epoch 16, gen_loss = 0.4017384455643392, disc_loss = 0.06609375421182896
Trained batch 331 in epoch 16, gen_loss = 0.4018251680466066, disc_loss = 0.066019912101665
Trained batch 332 in epoch 16, gen_loss = 0.40196966435816195, disc_loss = 0.06584489743949638
Trained batch 333 in epoch 16, gen_loss = 0.4022618773990049, disc_loss = 0.0656776665361364
Trained batch 334 in epoch 16, gen_loss = 0.40234174345856283, disc_loss = 0.06559591429141252
Trained batch 335 in epoch 16, gen_loss = 0.40219161278080373, disc_loss = 0.06554116934144293
Trained batch 336 in epoch 16, gen_loss = 0.4024219860485824, disc_loss = 0.0653832130125815
Trained batch 337 in epoch 16, gen_loss = 0.40261684895972527, disc_loss = 0.0652360484161078
Trained batch 338 in epoch 16, gen_loss = 0.40280614437255186, disc_loss = 0.06514323571597976
Trained batch 339 in epoch 16, gen_loss = 0.4029049023109324, disc_loss = 0.06511422935462392
Trained batch 340 in epoch 16, gen_loss = 0.40286639909590444, disc_loss = 0.0652772426848297
Trained batch 341 in epoch 16, gen_loss = 0.403221351622838, disc_loss = 0.06533548903204936
Trained batch 342 in epoch 16, gen_loss = 0.40340455462911734, disc_loss = 0.06517347354718835
Trained batch 343 in epoch 16, gen_loss = 0.4035295479346153, disc_loss = 0.06501745908429067
Trained batch 344 in epoch 16, gen_loss = 0.4037815791109334, disc_loss = 0.06490373804598398
Trained batch 345 in epoch 16, gen_loss = 0.40379791461318904, disc_loss = 0.06478397983578545
Trained batch 346 in epoch 16, gen_loss = 0.4039481253033069, disc_loss = 0.06463911578794593
Trained batch 347 in epoch 16, gen_loss = 0.4041621982194911, disc_loss = 0.06450301288471867
Trained batch 348 in epoch 16, gen_loss = 0.40416032776108446, disc_loss = 0.06445394633177742
Trained batch 349 in epoch 16, gen_loss = 0.40416505336761477, disc_loss = 0.06429865691145616
Trained batch 350 in epoch 16, gen_loss = 0.4041541370740983, disc_loss = 0.06447698285092103
Trained batch 351 in epoch 16, gen_loss = 0.4041106353767894, disc_loss = 0.06445474108675792
Trained batch 352 in epoch 16, gen_loss = 0.4043200947238771, disc_loss = 0.06431451453444767
Trained batch 353 in epoch 16, gen_loss = 0.40425875808222816, disc_loss = 0.06416057236098005
Trained batch 354 in epoch 16, gen_loss = 0.40434946233118085, disc_loss = 0.06412262881541966
Trained batch 355 in epoch 16, gen_loss = 0.4042557801925734, disc_loss = 0.06399013745216547
Trained batch 356 in epoch 16, gen_loss = 0.4040977312904112, disc_loss = 0.06391882348195219
Trained batch 357 in epoch 16, gen_loss = 0.4042455944435557, disc_loss = 0.06381227334768787
Trained batch 358 in epoch 16, gen_loss = 0.40409815253321507, disc_loss = 0.06394430524526906
Trained batch 359 in epoch 16, gen_loss = 0.4039272226393223, disc_loss = 0.06388405293045152
Trained batch 360 in epoch 16, gen_loss = 0.4038612206061461, disc_loss = 0.06388486749066911
Trained batch 361 in epoch 16, gen_loss = 0.4041022968720336, disc_loss = 0.06426446082826848
Trained batch 362 in epoch 16, gen_loss = 0.4041707939352871, disc_loss = 0.0645333547876332
Trained batch 363 in epoch 16, gen_loss = 0.4040945891168091, disc_loss = 0.06439579249958374
Trained batch 364 in epoch 16, gen_loss = 0.4042468213055232, disc_loss = 0.06426127884052184
Trained batch 365 in epoch 16, gen_loss = 0.4044032417685608, disc_loss = 0.06420007641579895
Trained batch 366 in epoch 16, gen_loss = 0.40433979407967924, disc_loss = 0.06407091697952037
Trained batch 367 in epoch 16, gen_loss = 0.4043925080610358, disc_loss = 0.06406649975890658
Trained batch 368 in epoch 16, gen_loss = 0.4043114552814463, disc_loss = 0.06394921424281266
Trained batch 369 in epoch 16, gen_loss = 0.4042066822986345, disc_loss = 0.06405544846217978
Trained batch 370 in epoch 16, gen_loss = 0.4040186057354241, disc_loss = 0.06408871048961005
Trained batch 371 in epoch 16, gen_loss = 0.4039926478458989, disc_loss = 0.06405809314756264
Trained batch 372 in epoch 16, gen_loss = 0.40407693489946567, disc_loss = 0.06402807594239512
Trained batch 373 in epoch 16, gen_loss = 0.40441023530488346, disc_loss = 0.06394706861076149
Trained batch 374 in epoch 16, gen_loss = 0.40410213088989255, disc_loss = 0.0639878801840047
Trained batch 375 in epoch 16, gen_loss = 0.4041015768146261, disc_loss = 0.06384955379651225
Trained batch 376 in epoch 16, gen_loss = 0.4040209683404361, disc_loss = 0.0637682971608793
Trained batch 377 in epoch 16, gen_loss = 0.4039402300560916, disc_loss = 0.06370045233237011
Trained batch 378 in epoch 16, gen_loss = 0.40408801647163634, disc_loss = 0.06380669845730105
Trained batch 379 in epoch 16, gen_loss = 0.40389444851561596, disc_loss = 0.06378315928710723
Trained batch 380 in epoch 16, gen_loss = 0.403664845337705, disc_loss = 0.06368427930321555
Trained batch 381 in epoch 16, gen_loss = 0.4036605369826262, disc_loss = 0.06379836510393905
Trained batch 382 in epoch 16, gen_loss = 0.4035670446820421, disc_loss = 0.06390789171982333
Trained batch 383 in epoch 16, gen_loss = 0.4037111420184374, disc_loss = 0.06378330390604485
Trained batch 384 in epoch 16, gen_loss = 0.4038459686489848, disc_loss = 0.0637720338746228
Trained batch 385 in epoch 16, gen_loss = 0.403971406462279, disc_loss = 0.06372345615675373
Trained batch 386 in epoch 16, gen_loss = 0.4040541954588828, disc_loss = 0.06361486503219073
Trained batch 387 in epoch 16, gen_loss = 0.4039571122410371, disc_loss = 0.06353204652604637
Trained batch 388 in epoch 16, gen_loss = 0.4039791726667654, disc_loss = 0.0634161468276845
Trained batch 389 in epoch 16, gen_loss = 0.4039422210974571, disc_loss = 0.06362565067501214
Trained batch 390 in epoch 16, gen_loss = 0.4039592567612143, disc_loss = 0.06403719463630977
Trained batch 391 in epoch 16, gen_loss = 0.4038576412261749, disc_loss = 0.06397887638043043
Trained batch 392 in epoch 16, gen_loss = 0.4037911740271493, disc_loss = 0.0639591724682912
Trained batch 393 in epoch 16, gen_loss = 0.4038303018675238, disc_loss = 0.06388844072530377
Trained batch 394 in epoch 16, gen_loss = 0.4037185969986493, disc_loss = 0.06378356468616218
Trained batch 395 in epoch 16, gen_loss = 0.40367095172405243, disc_loss = 0.0636732587061653
Trained batch 396 in epoch 16, gen_loss = 0.4034645464318225, disc_loss = 0.06365272715589224
Trained batch 397 in epoch 16, gen_loss = 0.40357976477948865, disc_loss = 0.06380712126157055
Trained batch 398 in epoch 16, gen_loss = 0.4033735263765904, disc_loss = 0.06423022425651811
Trained batch 399 in epoch 16, gen_loss = 0.40341598518192767, disc_loss = 0.06425697365193628
Trained batch 400 in epoch 16, gen_loss = 0.40326548016576697, disc_loss = 0.06430960605803533
Trained batch 401 in epoch 16, gen_loss = 0.40319391440099744, disc_loss = 0.0642076756617527
Trained batch 402 in epoch 16, gen_loss = 0.4029248425593743, disc_loss = 0.06416653345683336
Trained batch 403 in epoch 16, gen_loss = 0.4030268320647797, disc_loss = 0.06430417704419003
Trained batch 404 in epoch 16, gen_loss = 0.40300825002752705, disc_loss = 0.06446416484146023
Trained batch 405 in epoch 16, gen_loss = 0.40285263148141026, disc_loss = 0.06437958238687679
Trained batch 406 in epoch 16, gen_loss = 0.40289467463329326, disc_loss = 0.0646642544764467
Trained batch 407 in epoch 16, gen_loss = 0.40272493514360164, disc_loss = 0.06471683767363977
Trained batch 408 in epoch 16, gen_loss = 0.4026599782894759, disc_loss = 0.06462517674798306
Trained batch 409 in epoch 16, gen_loss = 0.4028907463317964, disc_loss = 0.06473354341848413
Trained batch 410 in epoch 16, gen_loss = 0.40270676534541333, disc_loss = 0.06504213854267178
Trained batch 411 in epoch 16, gen_loss = 0.4028372774714405, disc_loss = 0.06494041636147654
Trained batch 412 in epoch 16, gen_loss = 0.40286661882954705, disc_loss = 0.06481409273459858
Trained batch 413 in epoch 16, gen_loss = 0.4026473222867302, disc_loss = 0.0647932843019475
Trained batch 414 in epoch 16, gen_loss = 0.40276568481721076, disc_loss = 0.06491565579009882
Trained batch 415 in epoch 16, gen_loss = 0.4026162689551711, disc_loss = 0.06506600521410852
Trained batch 416 in epoch 16, gen_loss = 0.4025991393936624, disc_loss = 0.06509388433278
Trained batch 417 in epoch 16, gen_loss = 0.4026132545402746, disc_loss = 0.06498273592063507
Trained batch 418 in epoch 16, gen_loss = 0.40262123117298954, disc_loss = 0.06489121254537975
Trained batch 419 in epoch 16, gen_loss = 0.4025602735224224, disc_loss = 0.0647632176488904
Trained batch 420 in epoch 16, gen_loss = 0.40254045318537823, disc_loss = 0.0646914819912485
Trained batch 421 in epoch 16, gen_loss = 0.4025223272106659, disc_loss = 0.06470759786661026
Trained batch 422 in epoch 16, gen_loss = 0.402398611425508, disc_loss = 0.06470778973632213
Trained batch 423 in epoch 16, gen_loss = 0.4022986238014023, disc_loss = 0.06466215038737985
Trained batch 424 in epoch 16, gen_loss = 0.4023067960318397, disc_loss = 0.06453520282116883
Trained batch 425 in epoch 16, gen_loss = 0.4023341093684586, disc_loss = 0.06441283901003429
Trained batch 426 in epoch 16, gen_loss = 0.40234059604883754, disc_loss = 0.06489745372103689
Trained batch 427 in epoch 16, gen_loss = 0.40211750197911933, disc_loss = 0.06576505118750349
Trained batch 428 in epoch 16, gen_loss = 0.402210778150803, disc_loss = 0.06575240320602045
Trained batch 429 in epoch 16, gen_loss = 0.4020720488803331, disc_loss = 0.0658160885308631
Trained batch 430 in epoch 16, gen_loss = 0.40215872439043704, disc_loss = 0.06570918660874536
Trained batch 431 in epoch 16, gen_loss = 0.40200134387446773, disc_loss = 0.06569585291974901
Trained batch 432 in epoch 16, gen_loss = 0.40214356016066555, disc_loss = 0.0656147502119681
Trained batch 433 in epoch 16, gen_loss = 0.40196305012098654, disc_loss = 0.06556660138941821
Trained batch 434 in epoch 16, gen_loss = 0.4017570342140636, disc_loss = 0.06567886084125474
Trained batch 435 in epoch 16, gen_loss = 0.40180973831666716, disc_loss = 0.06597010941146403
Trained batch 436 in epoch 16, gen_loss = 0.40203403069443777, disc_loss = 0.0658646865057369
Trained batch 437 in epoch 16, gen_loss = 0.4021370299330585, disc_loss = 0.06573750582931895
Trained batch 438 in epoch 16, gen_loss = 0.4019363813764142, disc_loss = 0.06584714095857087
Trained batch 439 in epoch 16, gen_loss = 0.4019316220148043, disc_loss = 0.06575936041243205
Trained batch 440 in epoch 16, gen_loss = 0.40179311384419464, disc_loss = 0.06576202179108855
Trained batch 441 in epoch 16, gen_loss = 0.4019284769555562, disc_loss = 0.06566959244780647
Trained batch 442 in epoch 16, gen_loss = 0.4018187049280171, disc_loss = 0.06582776454863881
Trained batch 443 in epoch 16, gen_loss = 0.4019687182462967, disc_loss = 0.06600348741499926
Trained batch 444 in epoch 16, gen_loss = 0.40203019802489975, disc_loss = 0.06606800483665272
Trained batch 445 in epoch 16, gen_loss = 0.40197478221403643, disc_loss = 0.06631955649231815
Trained batch 446 in epoch 16, gen_loss = 0.4019876115807484, disc_loss = 0.06620533737797765
Trained batch 447 in epoch 16, gen_loss = 0.40198027196207214, disc_loss = 0.0661582579746859
Trained batch 448 in epoch 16, gen_loss = 0.40208703325957657, disc_loss = 0.06603487308566482
Trained batch 449 in epoch 16, gen_loss = 0.40194641093413036, disc_loss = 0.06596443806774914
Trained batch 450 in epoch 16, gen_loss = 0.4018927260803806, disc_loss = 0.06586432008138815
Trained batch 451 in epoch 16, gen_loss = 0.40197535037203175, disc_loss = 0.0657716155746556
Trained batch 452 in epoch 16, gen_loss = 0.4019717779380596, disc_loss = 0.06577067951842419
Trained batch 453 in epoch 16, gen_loss = 0.40203310332634373, disc_loss = 0.06627326596236997
Trained batch 454 in epoch 16, gen_loss = 0.40168196529477507, disc_loss = 0.06683580282318231
Trained batch 455 in epoch 16, gen_loss = 0.4016413981781194, disc_loss = 0.06693142341764383
Trained batch 456 in epoch 16, gen_loss = 0.40165613585149695, disc_loss = 0.06730759459806512
Trained batch 457 in epoch 16, gen_loss = 0.4017269059885537, disc_loss = 0.0672588241805107
Trained batch 458 in epoch 16, gen_loss = 0.40142293605539536, disc_loss = 0.06725153837998221
Trained batch 459 in epoch 16, gen_loss = 0.4014922999493454, disc_loss = 0.06718559940244355
Trained batch 460 in epoch 16, gen_loss = 0.4014805566656874, disc_loss = 0.06715901045395373
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.2946524918079376, disc_loss = 0.11564550548791885
Trained batch 1 in epoch 17, gen_loss = 0.34576961398124695, disc_loss = 0.1256556697189808
Trained batch 2 in epoch 17, gen_loss = 0.3913536270459493, disc_loss = 0.08901116997003555
Trained batch 3 in epoch 17, gen_loss = 0.3932104557752609, disc_loss = 0.07658857759088278
Trained batch 4 in epoch 17, gen_loss = 0.3830536186695099, disc_loss = 0.06713658012449741
Trained batch 5 in epoch 17, gen_loss = 0.37512440979480743, disc_loss = 0.05952829277763764
Trained batch 6 in epoch 17, gen_loss = 0.3902141494410379, disc_loss = 0.05410761173282351
Trained batch 7 in epoch 17, gen_loss = 0.4037228561937809, disc_loss = 0.049365483690053225
Trained batch 8 in epoch 17, gen_loss = 0.4014999568462372, disc_loss = 0.04770170607500606
Trained batch 9 in epoch 17, gen_loss = 0.39802529513835905, disc_loss = 0.04887378923594952
Trained batch 10 in epoch 17, gen_loss = 0.3867448243227872, disc_loss = 0.057824344458905136
Trained batch 11 in epoch 17, gen_loss = 0.39024444421132404, disc_loss = 0.058705723844468594
Trained batch 12 in epoch 17, gen_loss = 0.39236043508236224, disc_loss = 0.05488357907877518
Trained batch 13 in epoch 17, gen_loss = 0.3898513508694513, disc_loss = 0.05342902150005102
Trained batch 14 in epoch 17, gen_loss = 0.3901767631371816, disc_loss = 0.051836896066864334
Trained batch 15 in epoch 17, gen_loss = 0.3902031611651182, disc_loss = 0.05297209520358592
Trained batch 16 in epoch 17, gen_loss = 0.39187368399956646, disc_loss = 0.05245652586659964
Trained batch 17 in epoch 17, gen_loss = 0.3942916923099094, disc_loss = 0.05030493608986338
Trained batch 18 in epoch 17, gen_loss = 0.3954475694581082, disc_loss = 0.05808931750882613
Trained batch 19 in epoch 17, gen_loss = 0.3928597718477249, disc_loss = 0.06589222853071988
Trained batch 20 in epoch 17, gen_loss = 0.3963230493522826, disc_loss = 0.06668630424177363
Trained batch 21 in epoch 17, gen_loss = 0.3992447324774482, disc_loss = 0.06428799981420691
Trained batch 22 in epoch 17, gen_loss = 0.39921804485113727, disc_loss = 0.06332199129721393
Trained batch 23 in epoch 17, gen_loss = 0.3962104531625907, disc_loss = 0.06273624502743284
Trained batch 24 in epoch 17, gen_loss = 0.39601736783981323, disc_loss = 0.06252049431204795
Trained batch 25 in epoch 17, gen_loss = 0.3951544486559354, disc_loss = 0.06652331853715274
Trained batch 26 in epoch 17, gen_loss = 0.40034423934088814, disc_loss = 0.07141635580747216
Trained batch 27 in epoch 17, gen_loss = 0.40088907522814615, disc_loss = 0.06972957668559891
Trained batch 28 in epoch 17, gen_loss = 0.3976441179883891, disc_loss = 0.07127182982091246
Trained batch 29 in epoch 17, gen_loss = 0.3972547709941864, disc_loss = 0.07051855958998203
Trained batch 30 in epoch 17, gen_loss = 0.3974990085248024, disc_loss = 0.06979537082295265
Trained batch 31 in epoch 17, gen_loss = 0.3955244878306985, disc_loss = 0.07127395202405751
Trained batch 32 in epoch 17, gen_loss = 0.3953875005245209, disc_loss = 0.07098083423845696
Trained batch 33 in epoch 17, gen_loss = 0.3948778527624467, disc_loss = 0.06924753427943763
Trained batch 34 in epoch 17, gen_loss = 0.3975933679512569, disc_loss = 0.06782134888427598
Trained batch 35 in epoch 17, gen_loss = 0.39597387115160626, disc_loss = 0.06651757072864307
Trained batch 36 in epoch 17, gen_loss = 0.39828942031473724, disc_loss = 0.06588254249780565
Trained batch 37 in epoch 17, gen_loss = 0.3982379122784263, disc_loss = 0.06516809442913846
Trained batch 38 in epoch 17, gen_loss = 0.40056855709124833, disc_loss = 0.06521781643804832
Trained batch 39 in epoch 17, gen_loss = 0.3978544965386391, disc_loss = 0.06479389150626957
Trained batch 40 in epoch 17, gen_loss = 0.3973999655828243, disc_loss = 0.06915192783060597
Trained batch 41 in epoch 17, gen_loss = 0.4004540365366709, disc_loss = 0.06941753523867755
Trained batch 42 in epoch 17, gen_loss = 0.4003779368345128, disc_loss = 0.06931957329601743
Trained batch 43 in epoch 17, gen_loss = 0.40126707472584466, disc_loss = 0.0684900514527478
Trained batch 44 in epoch 17, gen_loss = 0.4006906204753452, disc_loss = 0.06795537525580989
Trained batch 45 in epoch 17, gen_loss = 0.39986662372298865, disc_loss = 0.06671097168051031
Trained batch 46 in epoch 17, gen_loss = 0.39821420070972846, disc_loss = 0.06655905908964416
Trained batch 47 in epoch 17, gen_loss = 0.39723673400779563, disc_loss = 0.06604730188458537
Trained batch 48 in epoch 17, gen_loss = 0.39731744722444184, disc_loss = 0.06520321149835173
Trained batch 49 in epoch 17, gen_loss = 0.39635491371154785, disc_loss = 0.06606972759589552
Trained batch 50 in epoch 17, gen_loss = 0.3966100677555683, disc_loss = 0.06566487988639697
Trained batch 51 in epoch 17, gen_loss = 0.3983476660572566, disc_loss = 0.06567218160041823
Trained batch 52 in epoch 17, gen_loss = 0.3960601220715721, disc_loss = 0.06812402583166675
Trained batch 53 in epoch 17, gen_loss = 0.3979641502654111, disc_loss = 0.06817008104796211
Trained batch 54 in epoch 17, gen_loss = 0.39901663335886867, disc_loss = 0.06714875193482095
Trained batch 55 in epoch 17, gen_loss = 0.3985581759895597, disc_loss = 0.06654968708088356
Trained batch 56 in epoch 17, gen_loss = 0.3987309310519904, disc_loss = 0.06614943917252515
Trained batch 57 in epoch 17, gen_loss = 0.39731569947867557, disc_loss = 0.06566772298437767
Trained batch 58 in epoch 17, gen_loss = 0.3970878715232267, disc_loss = 0.064925896698388
Trained batch 59 in epoch 17, gen_loss = 0.39761565973361335, disc_loss = 0.06428487778951725
Trained batch 60 in epoch 17, gen_loss = 0.3977830243892357, disc_loss = 0.06373842393399262
Trained batch 61 in epoch 17, gen_loss = 0.39767214223261804, disc_loss = 0.06377526399709525
Trained batch 62 in epoch 17, gen_loss = 0.3974940057784792, disc_loss = 0.06337989739600629
Trained batch 63 in epoch 17, gen_loss = 0.39725269516929984, disc_loss = 0.06321821149322204
Trained batch 64 in epoch 17, gen_loss = 0.39675469260949353, disc_loss = 0.06287761918054177
Trained batch 65 in epoch 17, gen_loss = 0.3970403219714309, disc_loss = 0.06428502062617829
Trained batch 66 in epoch 17, gen_loss = 0.395600682763911, disc_loss = 0.06740951196137648
Trained batch 67 in epoch 17, gen_loss = 0.3966851672705482, disc_loss = 0.0682956660988138
Trained batch 68 in epoch 17, gen_loss = 0.395759894364122, disc_loss = 0.06887577142080535
Trained batch 69 in epoch 17, gen_loss = 0.39604776884828297, disc_loss = 0.07106370662472078
Trained batch 70 in epoch 17, gen_loss = 0.3963997326266598, disc_loss = 0.0707822919259189
Trained batch 71 in epoch 17, gen_loss = 0.3961578305396769, disc_loss = 0.07005529403169122
Trained batch 72 in epoch 17, gen_loss = 0.39642511328605756, disc_loss = 0.06943895831091763
Trained batch 73 in epoch 17, gen_loss = 0.3956237769610173, disc_loss = 0.0693354023670828
Trained batch 74 in epoch 17, gen_loss = 0.3954257643222809, disc_loss = 0.07012591312328974
Trained batch 75 in epoch 17, gen_loss = 0.3943511690748365, disc_loss = 0.07261536848780356
Trained batch 76 in epoch 17, gen_loss = 0.3943237728112704, disc_loss = 0.07319358668544075
Trained batch 77 in epoch 17, gen_loss = 0.39414486900354045, disc_loss = 0.07289381592701642
Trained batch 78 in epoch 17, gen_loss = 0.39332443815243395, disc_loss = 0.07338076839341393
Trained batch 79 in epoch 17, gen_loss = 0.39414896070957184, disc_loss = 0.07310240375809371
Trained batch 80 in epoch 17, gen_loss = 0.39406446211132, disc_loss = 0.07260761593962893
Trained batch 81 in epoch 17, gen_loss = 0.3933786717129917, disc_loss = 0.07228373154634382
Trained batch 82 in epoch 17, gen_loss = 0.3936855933034276, disc_loss = 0.07246802459998303
Trained batch 83 in epoch 17, gen_loss = 0.3932590190143812, disc_loss = 0.07357517523424965
Trained batch 84 in epoch 17, gen_loss = 0.39399173540227556, disc_loss = 0.077262562863967
Trained batch 85 in epoch 17, gen_loss = 0.3935079404781031, disc_loss = 0.07700161874121011
Trained batch 86 in epoch 17, gen_loss = 0.39290443747893145, disc_loss = 0.07700835258282464
Trained batch 87 in epoch 17, gen_loss = 0.39377676526253874, disc_loss = 0.07724236464127898
Trained batch 88 in epoch 17, gen_loss = 0.3938537159662568, disc_loss = 0.07659107381791881
Trained batch 89 in epoch 17, gen_loss = 0.3938850575023227, disc_loss = 0.07596344451109568
Trained batch 90 in epoch 17, gen_loss = 0.394675069130384, disc_loss = 0.07529315092488305
Trained batch 91 in epoch 17, gen_loss = 0.3949739103731902, disc_loss = 0.07463293372774901
Trained batch 92 in epoch 17, gen_loss = 0.3950155162683097, disc_loss = 0.07435319184135365
Trained batch 93 in epoch 17, gen_loss = 0.39434542808126893, disc_loss = 0.07436211403221527
Trained batch 94 in epoch 17, gen_loss = 0.39345500218240836, disc_loss = 0.07596735903307011
Trained batch 95 in epoch 17, gen_loss = 0.3942459989339113, disc_loss = 0.07850661947547148
Trained batch 96 in epoch 17, gen_loss = 0.39403991232213287, disc_loss = 0.07791945067493572
Trained batch 97 in epoch 17, gen_loss = 0.39328465200200374, disc_loss = 0.07753363192765689
Trained batch 98 in epoch 17, gen_loss = 0.3923103592612527, disc_loss = 0.0774496187352472
Trained batch 99 in epoch 17, gen_loss = 0.3930621856451035, disc_loss = 0.07707378467544913
Trained batch 100 in epoch 17, gen_loss = 0.3931716485778884, disc_loss = 0.07671624224743631
Trained batch 101 in epoch 17, gen_loss = 0.3934764511444989, disc_loss = 0.07624335563285094
Trained batch 102 in epoch 17, gen_loss = 0.3937678209786276, disc_loss = 0.07569471148104923
Trained batch 103 in epoch 17, gen_loss = 0.3931530937552452, disc_loss = 0.07650560457617618
Trained batch 104 in epoch 17, gen_loss = 0.3925686353728885, disc_loss = 0.07907630462376844
Trained batch 105 in epoch 17, gen_loss = 0.39340551787952205, disc_loss = 0.07949573393770547
Trained batch 106 in epoch 17, gen_loss = 0.3930632870330989, disc_loss = 0.07911477594801755
Trained batch 107 in epoch 17, gen_loss = 0.392776970786077, disc_loss = 0.07890107422308237
Trained batch 108 in epoch 17, gen_loss = 0.39274721763549597, disc_loss = 0.07836781640391831
Trained batch 109 in epoch 17, gen_loss = 0.3926532341675325, disc_loss = 0.07806104902516711
Trained batch 110 in epoch 17, gen_loss = 0.3932070063578116, disc_loss = 0.07776725953360936
Trained batch 111 in epoch 17, gen_loss = 0.39341218237365994, disc_loss = 0.07746528242049473
Trained batch 112 in epoch 17, gen_loss = 0.3932961995622753, disc_loss = 0.07713808112703593
Trained batch 113 in epoch 17, gen_loss = 0.3936332788383752, disc_loss = 0.0779769651330354
Trained batch 114 in epoch 17, gen_loss = 0.3933159576809925, disc_loss = 0.07977231047723604
Trained batch 115 in epoch 17, gen_loss = 0.39392200497717694, disc_loss = 0.07948466910627382
Trained batch 116 in epoch 17, gen_loss = 0.39472439783251184, disc_loss = 0.07921313768268651
Trained batch 117 in epoch 17, gen_loss = 0.39421862262790486, disc_loss = 0.07916434563822665
Trained batch 118 in epoch 17, gen_loss = 0.3946036994457245, disc_loss = 0.07877312068428312
Trained batch 119 in epoch 17, gen_loss = 0.39436480949322383, disc_loss = 0.07836362544136742
Trained batch 120 in epoch 17, gen_loss = 0.39453791734600857, disc_loss = 0.07801827731396048
Trained batch 121 in epoch 17, gen_loss = 0.3949102114458553, disc_loss = 0.07816925869308046
Trained batch 122 in epoch 17, gen_loss = 0.39527187017890497, disc_loss = 0.0778849013604042
Trained batch 123 in epoch 17, gen_loss = 0.3948857003161984, disc_loss = 0.07755618501875189
Trained batch 124 in epoch 17, gen_loss = 0.3945355231761932, disc_loss = 0.07737021951377392
Trained batch 125 in epoch 17, gen_loss = 0.3948720478349262, disc_loss = 0.07720018028917294
Trained batch 126 in epoch 17, gen_loss = 0.39492161982641444, disc_loss = 0.07683388356442057
Trained batch 127 in epoch 17, gen_loss = 0.39460882428102195, disc_loss = 0.07643220339377876
Trained batch 128 in epoch 17, gen_loss = 0.39423319304636284, disc_loss = 0.07603400100975535
Trained batch 129 in epoch 17, gen_loss = 0.39507128917253936, disc_loss = 0.07576053679849093
Trained batch 130 in epoch 17, gen_loss = 0.39504635447764214, disc_loss = 0.07527224934226229
Trained batch 131 in epoch 17, gen_loss = 0.39472644730950845, disc_loss = 0.07501389409387202
Trained batch 132 in epoch 17, gen_loss = 0.39451521500608977, disc_loss = 0.07479206524453216
Trained batch 133 in epoch 17, gen_loss = 0.39421224482913514, disc_loss = 0.07480603774814908
Trained batch 134 in epoch 17, gen_loss = 0.3941352034056628, disc_loss = 0.07459876720828039
Trained batch 135 in epoch 17, gen_loss = 0.3939774012302651, disc_loss = 0.07428714689141248
Trained batch 136 in epoch 17, gen_loss = 0.394347579809871, disc_loss = 0.07379155400392674
Trained batch 137 in epoch 17, gen_loss = 0.3945100095824919, disc_loss = 0.07370777237498997
Trained batch 138 in epoch 17, gen_loss = 0.39467023645373556, disc_loss = 0.07477300355157299
Trained batch 139 in epoch 17, gen_loss = 0.39440873946462357, disc_loss = 0.07517807891791953
Trained batch 140 in epoch 17, gen_loss = 0.3944295196668476, disc_loss = 0.07488714236145218
Trained batch 141 in epoch 17, gen_loss = 0.39507028481490175, disc_loss = 0.0752620129668954
Trained batch 142 in epoch 17, gen_loss = 0.3946436970800787, disc_loss = 0.07538547698681901
Trained batch 143 in epoch 17, gen_loss = 0.39445203977326554, disc_loss = 0.07515588274367878
Trained batch 144 in epoch 17, gen_loss = 0.3950966169094217, disc_loss = 0.07471098751793134
Trained batch 145 in epoch 17, gen_loss = 0.3947238607765877, disc_loss = 0.0746852036099881
Trained batch 146 in epoch 17, gen_loss = 0.394374173514697, disc_loss = 0.0748475078005521
Trained batch 147 in epoch 17, gen_loss = 0.3948085589988812, disc_loss = 0.07458904927684548
Trained batch 148 in epoch 17, gen_loss = 0.3946594293885583, disc_loss = 0.0742070771497518
Trained batch 149 in epoch 17, gen_loss = 0.39435444196065267, disc_loss = 0.07398812205530703
Trained batch 150 in epoch 17, gen_loss = 0.3941841508379046, disc_loss = 0.07421209116386163
Trained batch 151 in epoch 17, gen_loss = 0.39356108499984993, disc_loss = 0.0750865624623226
Trained batch 152 in epoch 17, gen_loss = 0.3935731127371196, disc_loss = 0.0751143101864537
Trained batch 153 in epoch 17, gen_loss = 0.39320102159853104, disc_loss = 0.07484103536971107
Trained batch 154 in epoch 17, gen_loss = 0.39305088193185866, disc_loss = 0.07454977581998513
Trained batch 155 in epoch 17, gen_loss = 0.39342696983844805, disc_loss = 0.07425736798009333
Trained batch 156 in epoch 17, gen_loss = 0.3936627395213789, disc_loss = 0.07405257981662063
Trained batch 157 in epoch 17, gen_loss = 0.39403923101063015, disc_loss = 0.07373479917303577
Trained batch 158 in epoch 17, gen_loss = 0.3936421569413359, disc_loss = 0.07421491809083887
Trained batch 159 in epoch 17, gen_loss = 0.39399902801960707, disc_loss = 0.07499985483882483
Trained batch 160 in epoch 17, gen_loss = 0.39351728280878956, disc_loss = 0.07485753944236206
Trained batch 161 in epoch 17, gen_loss = 0.39313940832644334, disc_loss = 0.07462420816717233
Trained batch 162 in epoch 17, gen_loss = 0.3932454788977383, disc_loss = 0.07478374878995897
Trained batch 163 in epoch 17, gen_loss = 0.39335261957674494, disc_loss = 0.07463930625320844
Trained batch 164 in epoch 17, gen_loss = 0.39314244425658024, disc_loss = 0.07429786235037626
Trained batch 165 in epoch 17, gen_loss = 0.3936292162860732, disc_loss = 0.0740549983428679
Trained batch 166 in epoch 17, gen_loss = 0.393392880162793, disc_loss = 0.0741418288089335
Trained batch 167 in epoch 17, gen_loss = 0.39328868970984504, disc_loss = 0.07499556273077837
Trained batch 168 in epoch 17, gen_loss = 0.3929000265852234, disc_loss = 0.07509655049952442
Trained batch 169 in epoch 17, gen_loss = 0.39361904210904064, disc_loss = 0.07507112432435593
Trained batch 170 in epoch 17, gen_loss = 0.3934755142320666, disc_loss = 0.07475810943236738
Trained batch 171 in epoch 17, gen_loss = 0.3935085850399594, disc_loss = 0.07465449006697379
Trained batch 172 in epoch 17, gen_loss = 0.39390418536401206, disc_loss = 0.07463059290931318
Trained batch 173 in epoch 17, gen_loss = 0.39400373108085546, disc_loss = 0.07439325654333265
Trained batch 174 in epoch 17, gen_loss = 0.39426080788884843, disc_loss = 0.07419948040108595
Trained batch 175 in epoch 17, gen_loss = 0.3943699637258595, disc_loss = 0.07405741672317329
Trained batch 176 in epoch 17, gen_loss = 0.3938259191095492, disc_loss = 0.0738455720829888
Trained batch 177 in epoch 17, gen_loss = 0.3933037124323041, disc_loss = 0.07362406205626602
Trained batch 178 in epoch 17, gen_loss = 0.3933270596925107, disc_loss = 0.07369126178397063
Trained batch 179 in epoch 17, gen_loss = 0.39294496691889236, disc_loss = 0.07373305797939085
Trained batch 180 in epoch 17, gen_loss = 0.3928063482210781, disc_loss = 0.07342440199405366
Trained batch 181 in epoch 17, gen_loss = 0.3928981975212202, disc_loss = 0.07315150477186583
Trained batch 182 in epoch 17, gen_loss = 0.3930112747221045, disc_loss = 0.07327369576869686
Trained batch 183 in epoch 17, gen_loss = 0.3925982143567956, disc_loss = 0.0746658653825643
Trained batch 184 in epoch 17, gen_loss = 0.39300009978784095, disc_loss = 0.07458538542677824
Trained batch 185 in epoch 17, gen_loss = 0.3930173247091232, disc_loss = 0.07438945370445889
Trained batch 186 in epoch 17, gen_loss = 0.392933223177405, disc_loss = 0.0743197012707631
Trained batch 187 in epoch 17, gen_loss = 0.3934936252363185, disc_loss = 0.07415173599803622
Trained batch 188 in epoch 17, gen_loss = 0.3937935166888767, disc_loss = 0.07408181805331161
Trained batch 189 in epoch 17, gen_loss = 0.39394953501851937, disc_loss = 0.07417359033256377
Trained batch 190 in epoch 17, gen_loss = 0.3946117602717814, disc_loss = 0.07398138623148282
Trained batch 191 in epoch 17, gen_loss = 0.3945889192012449, disc_loss = 0.07376169130778483
Trained batch 192 in epoch 17, gen_loss = 0.39445572396634154, disc_loss = 0.07363706308663123
Trained batch 193 in epoch 17, gen_loss = 0.3947338626249549, disc_loss = 0.07348322300672454
Trained batch 194 in epoch 17, gen_loss = 0.39505955026699946, disc_loss = 0.0735149131443065
Trained batch 195 in epoch 17, gen_loss = 0.39540379661686564, disc_loss = 0.07354039258599206
Trained batch 196 in epoch 17, gen_loss = 0.39574851799132255, disc_loss = 0.07325305155038758
Trained batch 197 in epoch 17, gen_loss = 0.3957892218322465, disc_loss = 0.07340847359114148
Trained batch 198 in epoch 17, gen_loss = 0.39614505129842903, disc_loss = 0.07405524334669038
Trained batch 199 in epoch 17, gen_loss = 0.3958536873757839, disc_loss = 0.07388379006413742
Trained batch 200 in epoch 17, gen_loss = 0.39600685891227344, disc_loss = 0.07380906302268751
Trained batch 201 in epoch 17, gen_loss = 0.39593104959124387, disc_loss = 0.07375737573573421
Trained batch 202 in epoch 17, gen_loss = 0.39621169666938594, disc_loss = 0.07349530162216333
Trained batch 203 in epoch 17, gen_loss = 0.396201233799551, disc_loss = 0.07322115203429598
Trained batch 204 in epoch 17, gen_loss = 0.3961545887516766, disc_loss = 0.07299131664515632
Trained batch 205 in epoch 17, gen_loss = 0.39590981906478845, disc_loss = 0.07273702287947018
Trained batch 206 in epoch 17, gen_loss = 0.39601150025492127, disc_loss = 0.07250343622855734
Trained batch 207 in epoch 17, gen_loss = 0.39581933015814197, disc_loss = 0.07242160644874765
Trained batch 208 in epoch 17, gen_loss = 0.3959610102849714, disc_loss = 0.0721452596071555
Trained batch 209 in epoch 17, gen_loss = 0.39642791336490996, disc_loss = 0.07185692031246921
Trained batch 210 in epoch 17, gen_loss = 0.3966615139308134, disc_loss = 0.07162890983833732
Trained batch 211 in epoch 17, gen_loss = 0.3968997930861869, disc_loss = 0.07147635563215206
Trained batch 212 in epoch 17, gen_loss = 0.3966787937381458, disc_loss = 0.07129580866624143
Trained batch 213 in epoch 17, gen_loss = 0.3966579033392612, disc_loss = 0.07100109423284427
Trained batch 214 in epoch 17, gen_loss = 0.39655011226964554, disc_loss = 0.0707290425874986
Trained batch 215 in epoch 17, gen_loss = 0.39744179254328765, disc_loss = 0.07097176017231066
Trained batch 216 in epoch 17, gen_loss = 0.3974687654851219, disc_loss = 0.071178147833245
Trained batch 217 in epoch 17, gen_loss = 0.39750431327644836, disc_loss = 0.07092525257831525
Trained batch 218 in epoch 17, gen_loss = 0.3979539619461042, disc_loss = 0.07070545977849053
Trained batch 219 in epoch 17, gen_loss = 0.3982411666349931, disc_loss = 0.07046329993542962
Trained batch 220 in epoch 17, gen_loss = 0.39859834340363065, disc_loss = 0.07026482995270807
Trained batch 221 in epoch 17, gen_loss = 0.39878851900229584, disc_loss = 0.07000296853843506
Trained batch 222 in epoch 17, gen_loss = 0.39911886728932505, disc_loss = 0.06971923825477204
Trained batch 223 in epoch 17, gen_loss = 0.3991152761237962, disc_loss = 0.06950934165381893
Trained batch 224 in epoch 17, gen_loss = 0.39879700236850313, disc_loss = 0.06930161981739931
Trained batch 225 in epoch 17, gen_loss = 0.39890152426947534, disc_loss = 0.06904068237904097
Trained batch 226 in epoch 17, gen_loss = 0.3988085014967141, disc_loss = 0.06895570714428759
Trained batch 227 in epoch 17, gen_loss = 0.3985986092634368, disc_loss = 0.06890128890926574
Trained batch 228 in epoch 17, gen_loss = 0.39914397537448, disc_loss = 0.06868219500667859
Trained batch 229 in epoch 17, gen_loss = 0.3992906440859256, disc_loss = 0.06850220158331743
Trained batch 230 in epoch 17, gen_loss = 0.39924187474436573, disc_loss = 0.06828010462635717
Trained batch 231 in epoch 17, gen_loss = 0.3993115854160539, disc_loss = 0.06809016028700139
Trained batch 232 in epoch 17, gen_loss = 0.3992726989570094, disc_loss = 0.06790713176666859
Trained batch 233 in epoch 17, gen_loss = 0.3990110018823901, disc_loss = 0.06819319372208646
Trained batch 234 in epoch 17, gen_loss = 0.3988637310393313, disc_loss = 0.06866513285191453
Trained batch 235 in epoch 17, gen_loss = 0.39882742499901075, disc_loss = 0.0684764830502129
Trained batch 236 in epoch 17, gen_loss = 0.39947189283773366, disc_loss = 0.0686427741625861
Trained batch 237 in epoch 17, gen_loss = 0.39924985420804066, disc_loss = 0.0684817139540619
Trained batch 238 in epoch 17, gen_loss = 0.3991703514524085, disc_loss = 0.06856027203241838
Trained batch 239 in epoch 17, gen_loss = 0.3995000711331765, disc_loss = 0.06836419418881026
Trained batch 240 in epoch 17, gen_loss = 0.3994242295437334, disc_loss = 0.06828479719042964
Trained batch 241 in epoch 17, gen_loss = 0.39940569789941643, disc_loss = 0.06811609602348556
Trained batch 242 in epoch 17, gen_loss = 0.3994240143907414, disc_loss = 0.06809856632049867
Trained batch 243 in epoch 17, gen_loss = 0.39950863271951675, disc_loss = 0.06800833165637965
Trained batch 244 in epoch 17, gen_loss = 0.3990673628388619, disc_loss = 0.06824663748052351
Trained batch 245 in epoch 17, gen_loss = 0.3992087214700575, disc_loss = 0.06836186144765981
Trained batch 246 in epoch 17, gen_loss = 0.39938582618709517, disc_loss = 0.06812387492756551
Trained batch 247 in epoch 17, gen_loss = 0.3997013154289415, disc_loss = 0.06798207970719124
Trained batch 248 in epoch 17, gen_loss = 0.39998733303154327, disc_loss = 0.067747425035495
Trained batch 249 in epoch 17, gen_loss = 0.40010305774211885, disc_loss = 0.06751467481441796
Trained batch 250 in epoch 17, gen_loss = 0.40019066982060314, disc_loss = 0.06730895442146051
Trained batch 251 in epoch 17, gen_loss = 0.4000953763486847, disc_loss = 0.06715134495965368
Trained batch 252 in epoch 17, gen_loss = 0.3998428273342344, disc_loss = 0.06704351630083952
Trained batch 253 in epoch 17, gen_loss = 0.3998588300126744, disc_loss = 0.06693439193135935
Trained batch 254 in epoch 17, gen_loss = 0.39996337995809667, disc_loss = 0.06675051874572448
Trained batch 255 in epoch 17, gen_loss = 0.3999508055858314, disc_loss = 0.06668860453828529
Trained batch 256 in epoch 17, gen_loss = 0.40026230396927565, disc_loss = 0.06662993344880554
Trained batch 257 in epoch 17, gen_loss = 0.40052794543809667, disc_loss = 0.06640855770724169
Trained batch 258 in epoch 17, gen_loss = 0.4007229910854207, disc_loss = 0.06620758084551535
Trained batch 259 in epoch 17, gen_loss = 0.4004158830413452, disc_loss = 0.06614850859981604
Trained batch 260 in epoch 17, gen_loss = 0.40059895796337347, disc_loss = 0.06693212302772764
Trained batch 261 in epoch 17, gen_loss = 0.40048104206114327, disc_loss = 0.06677397718219413
Trained batch 262 in epoch 17, gen_loss = 0.40040355626167906, disc_loss = 0.06669873009991793
Trained batch 263 in epoch 17, gen_loss = 0.4002130991130164, disc_loss = 0.06652524203210222
Trained batch 264 in epoch 17, gen_loss = 0.40050638824139, disc_loss = 0.06641383426404505
Trained batch 265 in epoch 17, gen_loss = 0.40061429266194654, disc_loss = 0.06624081930586774
Trained batch 266 in epoch 17, gen_loss = 0.4009614647104499, disc_loss = 0.06603094434002868
Trained batch 267 in epoch 17, gen_loss = 0.4010061777349728, disc_loss = 0.06581866758382086
Trained batch 268 in epoch 17, gen_loss = 0.40117769292296085, disc_loss = 0.0656131624839646
Trained batch 269 in epoch 17, gen_loss = 0.4012542848233823, disc_loss = 0.06540999596903997
Trained batch 270 in epoch 17, gen_loss = 0.4012354071289851, disc_loss = 0.06534851988007717
Trained batch 271 in epoch 17, gen_loss = 0.4012060035020113, disc_loss = 0.06553625703878317
Trained batch 272 in epoch 17, gen_loss = 0.40117197311841524, disc_loss = 0.06541889436003981
Trained batch 273 in epoch 17, gen_loss = 0.4010521652054613, disc_loss = 0.06531286521909935
Trained batch 274 in epoch 17, gen_loss = 0.40121461673216385, disc_loss = 0.06550574952397833
Trained batch 275 in epoch 17, gen_loss = 0.4007491623793823, disc_loss = 0.06634318244987694
Trained batch 276 in epoch 17, gen_loss = 0.4008511429659296, disc_loss = 0.06658146699339097
Trained batch 277 in epoch 17, gen_loss = 0.4009734437191229, disc_loss = 0.06639995144030227
Trained batch 278 in epoch 17, gen_loss = 0.4010778903747545, disc_loss = 0.0662046760123717
Trained batch 279 in epoch 17, gen_loss = 0.4008367827960423, disc_loss = 0.06607540568636198
Trained batch 280 in epoch 17, gen_loss = 0.4008675195356281, disc_loss = 0.06590644769483242
Trained batch 281 in epoch 17, gen_loss = 0.4010009144214874, disc_loss = 0.06573831164674397
Trained batch 282 in epoch 17, gen_loss = 0.4011988586124178, disc_loss = 0.06553621328346984
Trained batch 283 in epoch 17, gen_loss = 0.40117814370863875, disc_loss = 0.06536609716352705
Trained batch 284 in epoch 17, gen_loss = 0.4012298266092936, disc_loss = 0.0651608792787189
Trained batch 285 in epoch 17, gen_loss = 0.4012551262870535, disc_loss = 0.06497709671445712
Trained batch 286 in epoch 17, gen_loss = 0.4011785723398787, disc_loss = 0.06486897860598533
Trained batch 287 in epoch 17, gen_loss = 0.401310106428961, disc_loss = 0.06470751397137064
Trained batch 288 in epoch 17, gen_loss = 0.40109644041341896, disc_loss = 0.0647717269031157
Trained batch 289 in epoch 17, gen_loss = 0.40143516587799993, disc_loss = 0.06458266323657129
Trained batch 290 in epoch 17, gen_loss = 0.4013752797010428, disc_loss = 0.06467732344353988
Trained batch 291 in epoch 17, gen_loss = 0.40159449267060787, disc_loss = 0.06464255941961573
Trained batch 292 in epoch 17, gen_loss = 0.40169847540481096, disc_loss = 0.06445474527719026
Trained batch 293 in epoch 17, gen_loss = 0.40162929862129443, disc_loss = 0.06440844332805651
Trained batch 294 in epoch 17, gen_loss = 0.401949127548832, disc_loss = 0.06500671487459439
Trained batch 295 in epoch 17, gen_loss = 0.40193335711956024, disc_loss = 0.06496107217547409
Trained batch 296 in epoch 17, gen_loss = 0.4019114041970635, disc_loss = 0.06486008375701229
Trained batch 297 in epoch 17, gen_loss = 0.4019173759742071, disc_loss = 0.0647062092641331
Trained batch 298 in epoch 17, gen_loss = 0.40168028412056606, disc_loss = 0.06453696404580637
Trained batch 299 in epoch 17, gen_loss = 0.40155647695064545, disc_loss = 0.06434755247862389
Trained batch 300 in epoch 17, gen_loss = 0.40176762378096975, disc_loss = 0.06418506334384166
Trained batch 301 in epoch 17, gen_loss = 0.40165189550017677, disc_loss = 0.06421692936915584
Trained batch 302 in epoch 17, gen_loss = 0.4019963327217417, disc_loss = 0.06466634002154564
Trained batch 303 in epoch 17, gen_loss = 0.40174166887606444, disc_loss = 0.06488311821196571
Trained batch 304 in epoch 17, gen_loss = 0.40160283925103357, disc_loss = 0.06473305776684743
Trained batch 305 in epoch 17, gen_loss = 0.4016905877909629, disc_loss = 0.06494091723108165
Trained batch 306 in epoch 17, gen_loss = 0.4015221676337214, disc_loss = 0.06508664732665455
Trained batch 307 in epoch 17, gen_loss = 0.4016534216798745, disc_loss = 0.06505758214179523
Trained batch 308 in epoch 17, gen_loss = 0.4016839556130776, disc_loss = 0.06510677114340045
Trained batch 309 in epoch 17, gen_loss = 0.40173509255532297, disc_loss = 0.06518828213184831
Trained batch 310 in epoch 17, gen_loss = 0.40183887182707956, disc_loss = 0.06516244214992384
Trained batch 311 in epoch 17, gen_loss = 0.4019929006313666, disc_loss = 0.06521803950622249
Trained batch 312 in epoch 17, gen_loss = 0.4017044878996218, disc_loss = 0.06565577427770336
Trained batch 313 in epoch 17, gen_loss = 0.4015517876406384, disc_loss = 0.06582859251499888
Trained batch 314 in epoch 17, gen_loss = 0.4018516426994687, disc_loss = 0.06633366675574391
Trained batch 315 in epoch 17, gen_loss = 0.40195827950027924, disc_loss = 0.0665686937163973
Trained batch 316 in epoch 17, gen_loss = 0.4016984548854527, disc_loss = 0.06667159124474373
Trained batch 317 in epoch 17, gen_loss = 0.4016620638610432, disc_loss = 0.06658379099062357
Trained batch 318 in epoch 17, gen_loss = 0.4018192547242096, disc_loss = 0.06648258031506477
Trained batch 319 in epoch 17, gen_loss = 0.4016710078343749, disc_loss = 0.06638854947377695
Trained batch 320 in epoch 17, gen_loss = 0.4016076360721826, disc_loss = 0.06668751503883447
Trained batch 321 in epoch 17, gen_loss = 0.40199726588607576, disc_loss = 0.0672480855064802
Trained batch 322 in epoch 17, gen_loss = 0.40197457931359115, disc_loss = 0.06708857708180975
Trained batch 323 in epoch 17, gen_loss = 0.4017756207857603, disc_loss = 0.06716783361273737
Trained batch 324 in epoch 17, gen_loss = 0.40186696987885695, disc_loss = 0.06725666899377337
Trained batch 325 in epoch 17, gen_loss = 0.40173539610728165, disc_loss = 0.06710676212817933
Trained batch 326 in epoch 17, gen_loss = 0.40150446109815474, disc_loss = 0.06706024308059513
Trained batch 327 in epoch 17, gen_loss = 0.4013424953672944, disc_loss = 0.06714833644076773
Trained batch 328 in epoch 17, gen_loss = 0.40148665758251784, disc_loss = 0.0676033825494666
Trained batch 329 in epoch 17, gen_loss = 0.40150541879914026, disc_loss = 0.06751360209574077
Trained batch 330 in epoch 17, gen_loss = 0.40116139733179096, disc_loss = 0.06752630184035963
Trained batch 331 in epoch 17, gen_loss = 0.4015159188623888, disc_loss = 0.06754817780393389
Trained batch 332 in epoch 17, gen_loss = 0.40158201355833906, disc_loss = 0.06737705140707416
Trained batch 333 in epoch 17, gen_loss = 0.40138962650727367, disc_loss = 0.0676014747004956
Trained batch 334 in epoch 17, gen_loss = 0.4017029187572536, disc_loss = 0.06787686683376556
Trained batch 335 in epoch 17, gen_loss = 0.4015763192659333, disc_loss = 0.0677167905530604
Trained batch 336 in epoch 17, gen_loss = 0.40138284503883, disc_loss = 0.06757209206397924
Trained batch 337 in epoch 17, gen_loss = 0.40116885260364715, disc_loss = 0.06749852561149415
Trained batch 338 in epoch 17, gen_loss = 0.4011549918876637, disc_loss = 0.06743656647883378
Trained batch 339 in epoch 17, gen_loss = 0.40099626858444776, disc_loss = 0.0672800247954643
Trained batch 340 in epoch 17, gen_loss = 0.4010336205931353, disc_loss = 0.06719023895059381
Trained batch 341 in epoch 17, gen_loss = 0.4010541567154098, disc_loss = 0.0671662746217886
Trained batch 342 in epoch 17, gen_loss = 0.4009782358265479, disc_loss = 0.06705253441076801
Trained batch 343 in epoch 17, gen_loss = 0.40091816136656805, disc_loss = 0.06699317276916401
Trained batch 344 in epoch 17, gen_loss = 0.40097563050795293, disc_loss = 0.06714607009772157
Trained batch 345 in epoch 17, gen_loss = 0.40087157255307787, disc_loss = 0.06701703398822231
Trained batch 346 in epoch 17, gen_loss = 0.40068604305429484, disc_loss = 0.06701116675178195
Trained batch 347 in epoch 17, gen_loss = 0.40071327667469264, disc_loss = 0.06716832087305642
Trained batch 348 in epoch 17, gen_loss = 0.4004470635963374, disc_loss = 0.06715405600166807
Trained batch 349 in epoch 17, gen_loss = 0.40032352694443296, disc_loss = 0.06703020940534771
Trained batch 350 in epoch 17, gen_loss = 0.4002324328293488, disc_loss = 0.06688453638766947
Trained batch 351 in epoch 17, gen_loss = 0.4002964687110348, disc_loss = 0.06686085065302905
Trained batch 352 in epoch 17, gen_loss = 0.4005619760275563, disc_loss = 0.0666961373785041
Trained batch 353 in epoch 17, gen_loss = 0.4008094842656184, disc_loss = 0.06653922785068257
Trained batch 354 in epoch 17, gen_loss = 0.4008627899935548, disc_loss = 0.06640773048676865
Trained batch 355 in epoch 17, gen_loss = 0.4007798285966509, disc_loss = 0.06641018652655394
Trained batch 356 in epoch 17, gen_loss = 0.40045156023081613, disc_loss = 0.06656278248651981
Trained batch 357 in epoch 17, gen_loss = 0.4007319509150596, disc_loss = 0.06665670095849262
Trained batch 358 in epoch 17, gen_loss = 0.40061851406163823, disc_loss = 0.06649833258557909
Trained batch 359 in epoch 17, gen_loss = 0.4004939002295335, disc_loss = 0.06661704605729836
Trained batch 360 in epoch 17, gen_loss = 0.40086597674771357, disc_loss = 0.06650059994624881
Trained batch 361 in epoch 17, gen_loss = 0.4010030334167059, disc_loss = 0.06650950490414725
Trained batch 362 in epoch 17, gen_loss = 0.4008727891386048, disc_loss = 0.066363751435442
Trained batch 363 in epoch 17, gen_loss = 0.40076273810732493, disc_loss = 0.0663353971980901
Trained batch 364 in epoch 17, gen_loss = 0.40079460650274196, disc_loss = 0.06617651942938771
Trained batch 365 in epoch 17, gen_loss = 0.40100569705494116, disc_loss = 0.06602375932378807
Trained batch 366 in epoch 17, gen_loss = 0.4009113253299807, disc_loss = 0.06638639579001784
Trained batch 367 in epoch 17, gen_loss = 0.40064780665156635, disc_loss = 0.06737332287340668
Trained batch 368 in epoch 17, gen_loss = 0.40045512546368733, disc_loss = 0.06780027873122554
Trained batch 369 in epoch 17, gen_loss = 0.4003535054825448, disc_loss = 0.06807445914333535
Trained batch 370 in epoch 17, gen_loss = 0.40041980982790737, disc_loss = 0.06825028615313358
Trained batch 371 in epoch 17, gen_loss = 0.4001979722931821, disc_loss = 0.06838599374512791
Trained batch 372 in epoch 17, gen_loss = 0.4000734745976752, disc_loss = 0.06844061665391754
Trained batch 373 in epoch 17, gen_loss = 0.4000605249149914, disc_loss = 0.06842371569772096
Trained batch 374 in epoch 17, gen_loss = 0.39999378299713134, disc_loss = 0.0683509755966564
Trained batch 375 in epoch 17, gen_loss = 0.40014361867562254, disc_loss = 0.06824284103733705
Trained batch 376 in epoch 17, gen_loss = 0.4000750203821956, disc_loss = 0.06815763611707154
Trained batch 377 in epoch 17, gen_loss = 0.3999945238311455, disc_loss = 0.06807301628462498
Trained batch 378 in epoch 17, gen_loss = 0.3999075067074758, disc_loss = 0.06806685928240576
Trained batch 379 in epoch 17, gen_loss = 0.40009321789992486, disc_loss = 0.06840124237473662
Trained batch 380 in epoch 17, gen_loss = 0.3999963637412064, disc_loss = 0.0685592223474575
Trained batch 381 in epoch 17, gen_loss = 0.400084169513268, disc_loss = 0.06843156812600401
Trained batch 382 in epoch 17, gen_loss = 0.4001099810432205, disc_loss = 0.0685708705304244
Trained batch 383 in epoch 17, gen_loss = 0.4000694521237165, disc_loss = 0.06857020788568964
Trained batch 384 in epoch 17, gen_loss = 0.39992162956819904, disc_loss = 0.06847797208768014
Trained batch 385 in epoch 17, gen_loss = 0.4000366079992581, disc_loss = 0.06844100655645248
Trained batch 386 in epoch 17, gen_loss = 0.3999752063467829, disc_loss = 0.06836615170133167
Trained batch 387 in epoch 17, gen_loss = 0.3999917161526139, disc_loss = 0.06831674795650598
Trained batch 388 in epoch 17, gen_loss = 0.4000708650807182, disc_loss = 0.06904533493349324
Trained batch 389 in epoch 17, gen_loss = 0.3998428838375287, disc_loss = 0.06962425200005945
Trained batch 390 in epoch 17, gen_loss = 0.39993850921121094, disc_loss = 0.06993759962160835
Trained batch 391 in epoch 17, gen_loss = 0.3999706245958805, disc_loss = 0.06982903544938344
Trained batch 392 in epoch 17, gen_loss = 0.3999453177888885, disc_loss = 0.06979174559708429
Trained batch 393 in epoch 17, gen_loss = 0.39993475929734673, disc_loss = 0.06966801168193786
Trained batch 394 in epoch 17, gen_loss = 0.39995003116281724, disc_loss = 0.06953517226266522
Trained batch 395 in epoch 17, gen_loss = 0.40010434787983845, disc_loss = 0.06939560796882054
Trained batch 396 in epoch 17, gen_loss = 0.39997313732764583, disc_loss = 0.06936075074025794
Trained batch 397 in epoch 17, gen_loss = 0.3997496977523344, disc_loss = 0.06935086648972077
Trained batch 398 in epoch 17, gen_loss = 0.3997632835741927, disc_loss = 0.0692651296013448
Trained batch 399 in epoch 17, gen_loss = 0.3998886041343212, disc_loss = 0.06915623073582537
Trained batch 400 in epoch 17, gen_loss = 0.3998517292990649, disc_loss = 0.06906908698626178
Trained batch 401 in epoch 17, gen_loss = 0.39996900880218145, disc_loss = 0.06898693475450635
Trained batch 402 in epoch 17, gen_loss = 0.40004632335442764, disc_loss = 0.0690635922503549
Trained batch 403 in epoch 17, gen_loss = 0.3998104510921063, disc_loss = 0.06931078041290477
Trained batch 404 in epoch 17, gen_loss = 0.39982050392362806, disc_loss = 0.06921396393581856
Trained batch 405 in epoch 17, gen_loss = 0.39974257408691743, disc_loss = 0.06920677137313401
Trained batch 406 in epoch 17, gen_loss = 0.3995716398266082, disc_loss = 0.06928568672164542
Trained batch 407 in epoch 17, gen_loss = 0.3995419268806775, disc_loss = 0.06920244565859035
Trained batch 408 in epoch 17, gen_loss = 0.3994199722495231, disc_loss = 0.06908538980946892
Trained batch 409 in epoch 17, gen_loss = 0.39946289142457453, disc_loss = 0.06895168303830049
Trained batch 410 in epoch 17, gen_loss = 0.3995426054273499, disc_loss = 0.06883459133175349
Trained batch 411 in epoch 17, gen_loss = 0.3994571517393427, disc_loss = 0.068796716107155
Trained batch 412 in epoch 17, gen_loss = 0.39957328858733465, disc_loss = 0.06888589048397346
Trained batch 413 in epoch 17, gen_loss = 0.3995511438247662, disc_loss = 0.06897545053515637
Trained batch 414 in epoch 17, gen_loss = 0.39975053905004476, disc_loss = 0.06887976320415555
Trained batch 415 in epoch 17, gen_loss = 0.3998413226352288, disc_loss = 0.06879077481593973
Trained batch 416 in epoch 17, gen_loss = 0.39988401632228915, disc_loss = 0.06879708273291624
Trained batch 417 in epoch 17, gen_loss = 0.39998662364825105, disc_loss = 0.06868816371762047
Trained batch 418 in epoch 17, gen_loss = 0.3998746659989004, disc_loss = 0.06862556836223296
Trained batch 419 in epoch 17, gen_loss = 0.39972466947067353, disc_loss = 0.06853987249612276
Trained batch 420 in epoch 17, gen_loss = 0.3997475046867996, disc_loss = 0.06874867192095681
Trained batch 421 in epoch 17, gen_loss = 0.39957669116026984, disc_loss = 0.06908825980565594
Trained batch 422 in epoch 17, gen_loss = 0.39967957730834364, disc_loss = 0.06900108912651455
Trained batch 423 in epoch 17, gen_loss = 0.3997560660091211, disc_loss = 0.06895285408684702
Trained batch 424 in epoch 17, gen_loss = 0.3998152592602898, disc_loss = 0.06881345434333472
Trained batch 425 in epoch 17, gen_loss = 0.3997041170306049, disc_loss = 0.06878136847050152
Trained batch 426 in epoch 17, gen_loss = 0.3998438474445209, disc_loss = 0.06864146524124214
Trained batch 427 in epoch 17, gen_loss = 0.3999134445580367, disc_loss = 0.06861876018854537
Trained batch 428 in epoch 17, gen_loss = 0.39980411446177877, disc_loss = 0.06856012797321785
Trained batch 429 in epoch 17, gen_loss = 0.39979212103888045, disc_loss = 0.06841763209573232
Trained batch 430 in epoch 17, gen_loss = 0.3997693502985961, disc_loss = 0.06831846978372771
Trained batch 431 in epoch 17, gen_loss = 0.39989428042813585, disc_loss = 0.06818455887238357
Trained batch 432 in epoch 17, gen_loss = 0.3999458152207161, disc_loss = 0.0681142750579012
Trained batch 433 in epoch 17, gen_loss = 0.3999156888728867, disc_loss = 0.06822388519721818
Trained batch 434 in epoch 17, gen_loss = 0.40010783274968464, disc_loss = 0.06826234024938667
Trained batch 435 in epoch 17, gen_loss = 0.4001422797184472, disc_loss = 0.06814224627232093
Trained batch 436 in epoch 17, gen_loss = 0.4001166804158715, disc_loss = 0.06807596622316223
Trained batch 437 in epoch 17, gen_loss = 0.3999934851034591, disc_loss = 0.06805133356576674
Trained batch 438 in epoch 17, gen_loss = 0.3999915070034105, disc_loss = 0.06856855349233353
Trained batch 439 in epoch 17, gen_loss = 0.39992499642751433, disc_loss = 0.06845047187843276
Trained batch 440 in epoch 17, gen_loss = 0.39976352966831924, disc_loss = 0.068440619764254
Trained batch 441 in epoch 17, gen_loss = 0.39977513476194837, disc_loss = 0.06849018219812053
Trained batch 442 in epoch 17, gen_loss = 0.3995302699624012, disc_loss = 0.0686191270478978
Trained batch 443 in epoch 17, gen_loss = 0.3996006175875664, disc_loss = 0.06869286065606552
Trained batch 444 in epoch 17, gen_loss = 0.3997008947843916, disc_loss = 0.06859076836910308
Trained batch 445 in epoch 17, gen_loss = 0.3995601664476865, disc_loss = 0.06867579745041048
Trained batch 446 in epoch 17, gen_loss = 0.3996048579013321, disc_loss = 0.06873371772222238
Trained batch 447 in epoch 17, gen_loss = 0.3994202209370477, disc_loss = 0.06863915975243019
Trained batch 448 in epoch 17, gen_loss = 0.3995737420822305, disc_loss = 0.06865956999448632
Trained batch 449 in epoch 17, gen_loss = 0.3998988166782591, disc_loss = 0.0686857615587198
Trained batch 450 in epoch 17, gen_loss = 0.3996704419013402, disc_loss = 0.0686700208300514
Trained batch 451 in epoch 17, gen_loss = 0.3996236770685795, disc_loss = 0.06856703698177682
Trained batch 452 in epoch 17, gen_loss = 0.3996612811193824, disc_loss = 0.06846217822723469
Trained batch 453 in epoch 17, gen_loss = 0.39977326542795494, disc_loss = 0.06836682588522557
Trained batch 454 in epoch 17, gen_loss = 0.39978469623314156, disc_loss = 0.06828005925987611
Trained batch 455 in epoch 17, gen_loss = 0.3996465678016345, disc_loss = 0.06832673795737751
Trained batch 456 in epoch 17, gen_loss = 0.3997989242134261, disc_loss = 0.06858650394114187
Trained batch 457 in epoch 17, gen_loss = 0.3997406362836538, disc_loss = 0.06848715449577629
Trained batch 458 in epoch 17, gen_loss = 0.3998817848224266, disc_loss = 0.0684582924435812
Trained batch 459 in epoch 17, gen_loss = 0.3998463944248531, disc_loss = 0.06845965660480863
Trained batch 460 in epoch 17, gen_loss = 0.3998964081100166, disc_loss = 0.06837207032165565
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.33558017015457153, disc_loss = 0.09193957597017288
Trained batch 1 in epoch 18, gen_loss = 0.36778560280799866, disc_loss = 0.053055981174111366
Trained batch 2 in epoch 18, gen_loss = 0.4022094706694285, disc_loss = 0.03713105681041876
Trained batch 3 in epoch 18, gen_loss = 0.402333103120327, disc_loss = 0.032178150955587626
Trained batch 4 in epoch 18, gen_loss = 0.395307320356369, disc_loss = 0.0322806429117918
Trained batch 5 in epoch 18, gen_loss = 0.40491726497809094, disc_loss = 0.028274713394542534
Trained batch 6 in epoch 18, gen_loss = 0.4042000983442579, disc_loss = 0.026567525629486357
Trained batch 7 in epoch 18, gen_loss = 0.4140547178685665, disc_loss = 0.02824444556608796
Trained batch 8 in epoch 18, gen_loss = 0.41562530729505753, disc_loss = 0.028650610397259395
Trained batch 9 in epoch 18, gen_loss = 0.42246687710285186, disc_loss = 0.030039828270673752
Trained batch 10 in epoch 18, gen_loss = 0.4206036166711287, disc_loss = 0.030495670708743008
Trained batch 11 in epoch 18, gen_loss = 0.4211572806040446, disc_loss = 0.03190546234448751
Trained batch 12 in epoch 18, gen_loss = 0.43001574736375076, disc_loss = 0.032189101267319456
Trained batch 13 in epoch 18, gen_loss = 0.4256268675838198, disc_loss = 0.03213142603635788
Trained batch 14 in epoch 18, gen_loss = 0.42406536142031354, disc_loss = 0.032393381496270496
Trained batch 15 in epoch 18, gen_loss = 0.4287935495376587, disc_loss = 0.03245059959590435
Trained batch 16 in epoch 18, gen_loss = 0.4277951910215266, disc_loss = 0.03223889901795808
Trained batch 17 in epoch 18, gen_loss = 0.4242323057519065, disc_loss = 0.033892436884343624
Trained batch 18 in epoch 18, gen_loss = 0.42550966927879735, disc_loss = 0.04205362802665485
Trained batch 19 in epoch 18, gen_loss = 0.42171165347099304, disc_loss = 0.04448669692501426
Trained batch 20 in epoch 18, gen_loss = 0.4179992874463399, disc_loss = 0.04480105948944887
Trained batch 21 in epoch 18, gen_loss = 0.41972536796873267, disc_loss = 0.045681541192937984
Trained batch 22 in epoch 18, gen_loss = 0.41875659771587537, disc_loss = 0.04435108593948509
Trained batch 23 in epoch 18, gen_loss = 0.4192069061100483, disc_loss = 0.04380624205805361
Trained batch 24 in epoch 18, gen_loss = 0.4144250547885895, disc_loss = 0.04595192693173886
Trained batch 25 in epoch 18, gen_loss = 0.412667453289032, disc_loss = 0.05211022345779034
Trained batch 26 in epoch 18, gen_loss = 0.40931714684874926, disc_loss = 0.05222435399062104
Trained batch 27 in epoch 18, gen_loss = 0.40724152433020727, disc_loss = 0.0513226317374834
Trained batch 28 in epoch 18, gen_loss = 0.40950377131330556, disc_loss = 0.05064794979989529
Trained batch 29 in epoch 18, gen_loss = 0.40914345482985176, disc_loss = 0.04978681287417809
Trained batch 30 in epoch 18, gen_loss = 0.4058230288567082, disc_loss = 0.0485555351140999
Trained batch 31 in epoch 18, gen_loss = 0.4052087413147092, disc_loss = 0.04767377901589498
Trained batch 32 in epoch 18, gen_loss = 0.4036717008460652, disc_loss = 0.047380403530868614
Trained batch 33 in epoch 18, gen_loss = 0.4027120909270118, disc_loss = 0.04750907799119458
Trained batch 34 in epoch 18, gen_loss = 0.40356148651668006, disc_loss = 0.048741628282836506
Trained batch 35 in epoch 18, gen_loss = 0.4011576755179299, disc_loss = 0.05302291058210863
Trained batch 36 in epoch 18, gen_loss = 0.4042041656133291, disc_loss = 0.052965396411112836
Trained batch 37 in epoch 18, gen_loss = 0.4068889633605355, disc_loss = 0.055121638910158685
Trained batch 38 in epoch 18, gen_loss = 0.4066488513579735, disc_loss = 0.054238579832972623
Trained batch 39 in epoch 18, gen_loss = 0.4066113904118538, disc_loss = 0.05421650377102196
Trained batch 40 in epoch 18, gen_loss = 0.40635718659656805, disc_loss = 0.05402489774292562
Trained batch 41 in epoch 18, gen_loss = 0.4079123976684752, disc_loss = 0.05344729041237207
Trained batch 42 in epoch 18, gen_loss = 0.4060766842476157, disc_loss = 0.05332803435970184
Trained batch 43 in epoch 18, gen_loss = 0.4066511263901537, disc_loss = 0.05248692678287625
Trained batch 44 in epoch 18, gen_loss = 0.40350505842102896, disc_loss = 0.0568739236642917
Trained batch 45 in epoch 18, gen_loss = 0.40548342142416083, disc_loss = 0.06465726908620285
Trained batch 46 in epoch 18, gen_loss = 0.4063522454271925, disc_loss = 0.06357570426498955
Trained batch 47 in epoch 18, gen_loss = 0.40582770605882007, disc_loss = 0.0638418659218587
Trained batch 48 in epoch 18, gen_loss = 0.4049024448102834, disc_loss = 0.06344557437589582
Trained batch 49 in epoch 18, gen_loss = 0.4048445934057236, disc_loss = 0.06269557939842343
Trained batch 50 in epoch 18, gen_loss = 0.40545382394510154, disc_loss = 0.06207370000215722
Trained batch 51 in epoch 18, gen_loss = 0.40326338662551, disc_loss = 0.061763868756735556
Trained batch 52 in epoch 18, gen_loss = 0.40415222914713733, disc_loss = 0.06094941695414062
Trained batch 53 in epoch 18, gen_loss = 0.4041570794803125, disc_loss = 0.059972747729194385
Trained batch 54 in epoch 18, gen_loss = 0.4031940086321397, disc_loss = 0.05927060607143424
Trained batch 55 in epoch 18, gen_loss = 0.4029987273471696, disc_loss = 0.05864431171877576
Trained batch 56 in epoch 18, gen_loss = 0.4017407674538462, disc_loss = 0.05834478311436741
Trained batch 57 in epoch 18, gen_loss = 0.40302109512789497, disc_loss = 0.05810199718087398
Trained batch 58 in epoch 18, gen_loss = 0.4019678790690535, disc_loss = 0.05747526888814518
Trained batch 59 in epoch 18, gen_loss = 0.40111925899982454, disc_loss = 0.056954859864587586
Trained batch 60 in epoch 18, gen_loss = 0.401809922984389, disc_loss = 0.056317854718473115
Trained batch 61 in epoch 18, gen_loss = 0.4017711498083607, disc_loss = 0.056750527778339964
Trained batch 62 in epoch 18, gen_loss = 0.4007443128124116, disc_loss = 0.05839630061139663
Trained batch 63 in epoch 18, gen_loss = 0.401190803386271, disc_loss = 0.057793761530774646
Trained batch 64 in epoch 18, gen_loss = 0.4018034013418051, disc_loss = 0.05723312724954807
Trained batch 65 in epoch 18, gen_loss = 0.40160478380593384, disc_loss = 0.05655109533814318
Trained batch 66 in epoch 18, gen_loss = 0.4005037123587594, disc_loss = 0.05609546336275873
Trained batch 67 in epoch 18, gen_loss = 0.3996918836937231, disc_loss = 0.05561548174249337
Trained batch 68 in epoch 18, gen_loss = 0.39928047553352686, disc_loss = 0.055146456129201084
Trained batch 69 in epoch 18, gen_loss = 0.399894562789372, disc_loss = 0.05463752681389451
Trained batch 70 in epoch 18, gen_loss = 0.4005883751620709, disc_loss = 0.05473004663231927
Trained batch 71 in epoch 18, gen_loss = 0.4007846924165885, disc_loss = 0.05805755100057771
Trained batch 72 in epoch 18, gen_loss = 0.40162080077275836, disc_loss = 0.05766793420818979
Trained batch 73 in epoch 18, gen_loss = 0.4015849711927208, disc_loss = 0.05814806712992691
Trained batch 74 in epoch 18, gen_loss = 0.4024321186542511, disc_loss = 0.05812314702818791
Trained batch 75 in epoch 18, gen_loss = 0.40322346750058624, disc_loss = 0.05752374367837451
Trained batch 76 in epoch 18, gen_loss = 0.40252954232228266, disc_loss = 0.056911297323932124
Trained batch 77 in epoch 18, gen_loss = 0.4014686265817055, disc_loss = 0.05656070647856746
Trained batch 78 in epoch 18, gen_loss = 0.4013158501703528, disc_loss = 0.056184530812256696
Trained batch 79 in epoch 18, gen_loss = 0.4003754172474146, disc_loss = 0.05652261012000963
Trained batch 80 in epoch 18, gen_loss = 0.4006244959654631, disc_loss = 0.059052294499620246
Trained batch 81 in epoch 18, gen_loss = 0.40018933975115056, disc_loss = 0.05925245954450674
Trained batch 82 in epoch 18, gen_loss = 0.4002370837941227, disc_loss = 0.0590442147846502
Trained batch 83 in epoch 18, gen_loss = 0.4007654626454626, disc_loss = 0.05987566460057029
Trained batch 84 in epoch 18, gen_loss = 0.3995518382857828, disc_loss = 0.06042401018168996
Trained batch 85 in epoch 18, gen_loss = 0.399395969371463, disc_loss = 0.06032115964998686
Trained batch 86 in epoch 18, gen_loss = 0.39941508434284695, disc_loss = 0.05983706496270566
Trained batch 87 in epoch 18, gen_loss = 0.3988470093093135, disc_loss = 0.05929678365249525
Trained batch 88 in epoch 18, gen_loss = 0.39844898594899125, disc_loss = 0.0589067137517621
Trained batch 89 in epoch 18, gen_loss = 0.39871570501062603, disc_loss = 0.058850608290069634
Trained batch 90 in epoch 18, gen_loss = 0.398980194068217, disc_loss = 0.05861697225207156
Trained batch 91 in epoch 18, gen_loss = 0.3985781867219054, disc_loss = 0.058150688611456884
Trained batch 92 in epoch 18, gen_loss = 0.39858642476861195, disc_loss = 0.057758337147133326
Trained batch 93 in epoch 18, gen_loss = 0.39804023092097424, disc_loss = 0.05754476119863226
Trained batch 94 in epoch 18, gen_loss = 0.3987160096043035, disc_loss = 0.05707572573109677
Trained batch 95 in epoch 18, gen_loss = 0.39863878302276134, disc_loss = 0.05679370363941416
Trained batch 96 in epoch 18, gen_loss = 0.3991893465371476, disc_loss = 0.057014565434806125
Trained batch 97 in epoch 18, gen_loss = 0.3979943461564122, disc_loss = 0.05694969156186799
Trained batch 98 in epoch 18, gen_loss = 0.39750716150409043, disc_loss = 0.056558187317216034
Trained batch 99 in epoch 18, gen_loss = 0.3981796455383301, disc_loss = 0.05612757129594684
Trained batch 100 in epoch 18, gen_loss = 0.39895070277818356, disc_loss = 0.05571407666153247
Trained batch 101 in epoch 18, gen_loss = 0.3989611642033446, disc_loss = 0.05536101816915998
Trained batch 102 in epoch 18, gen_loss = 0.39855555915138097, disc_loss = 0.055192852049197966
Trained batch 103 in epoch 18, gen_loss = 0.3989799406666022, disc_loss = 0.05606098243823418
Trained batch 104 in epoch 18, gen_loss = 0.39994855778557914, disc_loss = 0.05680332865033831
Trained batch 105 in epoch 18, gen_loss = 0.39965918772625475, disc_loss = 0.05656947434510825
Trained batch 106 in epoch 18, gen_loss = 0.3996529114023547, disc_loss = 0.05619678649807645
Trained batch 107 in epoch 18, gen_loss = 0.4001874396646464, disc_loss = 0.05588038431273566
Trained batch 108 in epoch 18, gen_loss = 0.40047189319899323, disc_loss = 0.05556324889900487
Trained batch 109 in epoch 18, gen_loss = 0.40097326257012106, disc_loss = 0.05532527484677054
Trained batch 110 in epoch 18, gen_loss = 0.40127665395135276, disc_loss = 0.054972721498694505
Trained batch 111 in epoch 18, gen_loss = 0.4010178798011371, disc_loss = 0.05525697273800948
Trained batch 112 in epoch 18, gen_loss = 0.4018063207643222, disc_loss = 0.057576845556629445
Trained batch 113 in epoch 18, gen_loss = 0.4020389177297291, disc_loss = 0.057280499765878186
Trained batch 114 in epoch 18, gen_loss = 0.4013328692187434, disc_loss = 0.0572714045157899
Trained batch 115 in epoch 18, gen_loss = 0.40105772018432617, disc_loss = 0.05696920274981651
Trained batch 116 in epoch 18, gen_loss = 0.4013811311660669, disc_loss = 0.05664270278862399
Trained batch 117 in epoch 18, gen_loss = 0.4015203421398745, disc_loss = 0.05628781112984328
Trained batch 118 in epoch 18, gen_loss = 0.4013951721311617, disc_loss = 0.05600350391620598
Trained batch 119 in epoch 18, gen_loss = 0.40081710964441297, disc_loss = 0.05559972116801267
Trained batch 120 in epoch 18, gen_loss = 0.4005015209194057, disc_loss = 0.055242161016357094
Trained batch 121 in epoch 18, gen_loss = 0.40045235367094884, disc_loss = 0.05498095173159706
Trained batch 122 in epoch 18, gen_loss = 0.40009405603253745, disc_loss = 0.054907859268984414
Trained batch 123 in epoch 18, gen_loss = 0.3992061581342451, disc_loss = 0.0549374298049858
Trained batch 124 in epoch 18, gen_loss = 0.39837561058998106, disc_loss = 0.05496637036278844
Trained batch 125 in epoch 18, gen_loss = 0.3986897726380636, disc_loss = 0.05482045820145498
Trained batch 126 in epoch 18, gen_loss = 0.39851211703668427, disc_loss = 0.05459280085097265
Trained batch 127 in epoch 18, gen_loss = 0.3983566181268543, disc_loss = 0.05463191868693684
Trained batch 128 in epoch 18, gen_loss = 0.39810843615568886, disc_loss = 0.055439450269088496
Trained batch 129 in epoch 18, gen_loss = 0.3980852707074239, disc_loss = 0.05583648030073024
Trained batch 130 in epoch 18, gen_loss = 0.3986089980329266, disc_loss = 0.055583369815082266
Trained batch 131 in epoch 18, gen_loss = 0.3988429382443428, disc_loss = 0.0556512781538803
Trained batch 132 in epoch 18, gen_loss = 0.39952710898298965, disc_loss = 0.0555665610687233
Trained batch 133 in epoch 18, gen_loss = 0.4000354080057856, disc_loss = 0.05536000752029246
Trained batch 134 in epoch 18, gen_loss = 0.40037448428295275, disc_loss = 0.05526473788820483
Trained batch 135 in epoch 18, gen_loss = 0.4011152458979803, disc_loss = 0.05493738505345605
Trained batch 136 in epoch 18, gen_loss = 0.40081078140404974, disc_loss = 0.05517204223119103
Trained batch 137 in epoch 18, gen_loss = 0.4006156865237416, disc_loss = 0.05483071409179357
Trained batch 138 in epoch 18, gen_loss = 0.4011028044515376, disc_loss = 0.05690015831345813
Trained batch 139 in epoch 18, gen_loss = 0.4003213290657316, disc_loss = 0.0577964879605653
Trained batch 140 in epoch 18, gen_loss = 0.40044659481826406, disc_loss = 0.058068116614925315
Trained batch 141 in epoch 18, gen_loss = 0.4006558669285035, disc_loss = 0.05793120958973509
Trained batch 142 in epoch 18, gen_loss = 0.4007476572390203, disc_loss = 0.05769714898384222
Trained batch 143 in epoch 18, gen_loss = 0.40083285089996123, disc_loss = 0.05782490381776976
Trained batch 144 in epoch 18, gen_loss = 0.4011901641714162, disc_loss = 0.057940572734665255
Trained batch 145 in epoch 18, gen_loss = 0.40118463398659066, disc_loss = 0.05760358845853336
Trained batch 146 in epoch 18, gen_loss = 0.40133837210077816, disc_loss = 0.057471674268266985
Trained batch 147 in epoch 18, gen_loss = 0.40110499472231476, disc_loss = 0.057547418152082815
Trained batch 148 in epoch 18, gen_loss = 0.4013944128215713, disc_loss = 0.05757229147953975
Trained batch 149 in epoch 18, gen_loss = 0.4011610372861226, disc_loss = 0.057317074341699484
Trained batch 150 in epoch 18, gen_loss = 0.40103178861125416, disc_loss = 0.057139535098404484
Trained batch 151 in epoch 18, gen_loss = 0.40134256509573835, disc_loss = 0.05711967809628205
Trained batch 152 in epoch 18, gen_loss = 0.40110477805137634, disc_loss = 0.05817197991559416
Trained batch 153 in epoch 18, gen_loss = 0.40176579414250013, disc_loss = 0.05875184326795498
Trained batch 154 in epoch 18, gen_loss = 0.4015526781159063, disc_loss = 0.05908518018080823
Trained batch 155 in epoch 18, gen_loss = 0.40099066438583225, disc_loss = 0.05941646467619695
Trained batch 156 in epoch 18, gen_loss = 0.40110831142990455, disc_loss = 0.05909935972552485
Trained batch 157 in epoch 18, gen_loss = 0.4012184003485909, disc_loss = 0.058897639085432586
Trained batch 158 in epoch 18, gen_loss = 0.4008552070308781, disc_loss = 0.058619489369082185
Trained batch 159 in epoch 18, gen_loss = 0.40048831310123206, disc_loss = 0.0583601637306856
Trained batch 160 in epoch 18, gen_loss = 0.400713826003282, disc_loss = 0.05817956771551174
Trained batch 161 in epoch 18, gen_loss = 0.40082726379235584, disc_loss = 0.05828740836673037
Trained batch 162 in epoch 18, gen_loss = 0.4008625277712301, disc_loss = 0.05829329066767009
Trained batch 163 in epoch 18, gen_loss = 0.4001530588763516, disc_loss = 0.058413154016839476
Trained batch 164 in epoch 18, gen_loss = 0.4007327482555852, disc_loss = 0.05865797761997039
Trained batch 165 in epoch 18, gen_loss = 0.40074364068996476, disc_loss = 0.05851372634621719
Trained batch 166 in epoch 18, gen_loss = 0.4005781951064835, disc_loss = 0.05835257885799169
Trained batch 167 in epoch 18, gen_loss = 0.4005855641194752, disc_loss = 0.05827055177706782
Trained batch 168 in epoch 18, gen_loss = 0.40076390984495713, disc_loss = 0.05816466837691573
Trained batch 169 in epoch 18, gen_loss = 0.40135956546839546, disc_loss = 0.05798198116450187
Trained batch 170 in epoch 18, gen_loss = 0.4017763739092308, disc_loss = 0.05771973586712054
Trained batch 171 in epoch 18, gen_loss = 0.40179134333549543, disc_loss = 0.05745367508998877
Trained batch 172 in epoch 18, gen_loss = 0.4015325578306452, disc_loss = 0.05733413156929475
Trained batch 173 in epoch 18, gen_loss = 0.40251369808597126, disc_loss = 0.05712420283816755
Trained batch 174 in epoch 18, gen_loss = 0.4025689113140106, disc_loss = 0.057008948733231854
Trained batch 175 in epoch 18, gen_loss = 0.40287138013677165, disc_loss = 0.05724626405175182
Trained batch 176 in epoch 18, gen_loss = 0.40228313796937804, disc_loss = 0.05801012563008794
Trained batch 177 in epoch 18, gen_loss = 0.4027932185805246, disc_loss = 0.05826915631311412
Trained batch 178 in epoch 18, gen_loss = 0.40305648918924386, disc_loss = 0.05800223982419465
Trained batch 179 in epoch 18, gen_loss = 0.4029642831948068, disc_loss = 0.05781535862479359
Trained batch 180 in epoch 18, gen_loss = 0.40297927217588897, disc_loss = 0.05755937574122574
Trained batch 181 in epoch 18, gen_loss = 0.4029947818963082, disc_loss = 0.05733946458293268
Trained batch 182 in epoch 18, gen_loss = 0.40298557558346315, disc_loss = 0.057170049162693526
Trained batch 183 in epoch 18, gen_loss = 0.4030115031029867, disc_loss = 0.057271745898659625
Trained batch 184 in epoch 18, gen_loss = 0.40314582231882456, disc_loss = 0.05719119390170719
Trained batch 185 in epoch 18, gen_loss = 0.4031390014194673, disc_loss = 0.057181642112892964
Trained batch 186 in epoch 18, gen_loss = 0.40343096262630934, disc_loss = 0.05705869424201668
Trained batch 187 in epoch 18, gen_loss = 0.4032557151736097, disc_loss = 0.05685172055877666
Trained batch 188 in epoch 18, gen_loss = 0.40305818404470173, disc_loss = 0.05665200233469328
Trained batch 189 in epoch 18, gen_loss = 0.4029997184088356, disc_loss = 0.05659639543461564
Trained batch 190 in epoch 18, gen_loss = 0.4035821655345837, disc_loss = 0.05707419915514857
Trained batch 191 in epoch 18, gen_loss = 0.4034988156830271, disc_loss = 0.05845076433858291
Trained batch 192 in epoch 18, gen_loss = 0.4041056416812956, disc_loss = 0.05884122692405637
Trained batch 193 in epoch 18, gen_loss = 0.4042237683669808, disc_loss = 0.059332254757989464
Trained batch 194 in epoch 18, gen_loss = 0.4039879881418668, disc_loss = 0.05967007384707148
Trained batch 195 in epoch 18, gen_loss = 0.4040612481078323, disc_loss = 0.05959150193458689
Trained batch 196 in epoch 18, gen_loss = 0.40390267589975737, disc_loss = 0.059522031737860234
Trained batch 197 in epoch 18, gen_loss = 0.4038122904421103, disc_loss = 0.05930075948973271
Trained batch 198 in epoch 18, gen_loss = 0.4036503196062155, disc_loss = 0.059207258476927205
Trained batch 199 in epoch 18, gen_loss = 0.4037221457064152, disc_loss = 0.05910860404605046
Trained batch 200 in epoch 18, gen_loss = 0.40414107943055644, disc_loss = 0.05892459286691908
Trained batch 201 in epoch 18, gen_loss = 0.4039811959656158, disc_loss = 0.05907328373586556
Trained batch 202 in epoch 18, gen_loss = 0.4041867962318101, disc_loss = 0.059088521019963945
Trained batch 203 in epoch 18, gen_loss = 0.4039788753086445, disc_loss = 0.05883437380486844
Trained batch 204 in epoch 18, gen_loss = 0.40401363852547434, disc_loss = 0.058775485325150374
Trained batch 205 in epoch 18, gen_loss = 0.4042035415045266, disc_loss = 0.05855899579027324
Trained batch 206 in epoch 18, gen_loss = 0.40422306386169027, disc_loss = 0.0585648317951799
Trained batch 207 in epoch 18, gen_loss = 0.4039649630968387, disc_loss = 0.058839589554386645
Trained batch 208 in epoch 18, gen_loss = 0.4039344871728614, disc_loss = 0.0585986177913809
Trained batch 209 in epoch 18, gen_loss = 0.4040951054720652, disc_loss = 0.059300348193695146
Trained batch 210 in epoch 18, gen_loss = 0.40377962038415305, disc_loss = 0.06001849157815155
Trained batch 211 in epoch 18, gen_loss = 0.4039111414326812, disc_loss = 0.059986694957533816
Trained batch 212 in epoch 18, gen_loss = 0.4040246716407543, disc_loss = 0.05985182985016298
Trained batch 213 in epoch 18, gen_loss = 0.4038159497708918, disc_loss = 0.05969449107874637
Trained batch 214 in epoch 18, gen_loss = 0.403817791716997, disc_loss = 0.05957724694162607
Trained batch 215 in epoch 18, gen_loss = 0.40384782905931826, disc_loss = 0.059540205837779296
Trained batch 216 in epoch 18, gen_loss = 0.4037753369676353, disc_loss = 0.05944858578544471
Trained batch 217 in epoch 18, gen_loss = 0.4039744989040795, disc_loss = 0.05950467840025048
Trained batch 218 in epoch 18, gen_loss = 0.4036951759090162, disc_loss = 0.05984686088395309
Trained batch 219 in epoch 18, gen_loss = 0.40395406457510863, disc_loss = 0.05970465295778757
Trained batch 220 in epoch 18, gen_loss = 0.40412753307981186, disc_loss = 0.05960892699237458
Trained batch 221 in epoch 18, gen_loss = 0.40446527006926836, disc_loss = 0.05937905865931162
Trained batch 222 in epoch 18, gen_loss = 0.40417709879811037, disc_loss = 0.059381452021544025
Trained batch 223 in epoch 18, gen_loss = 0.40399132535925936, disc_loss = 0.059306176857457364
Trained batch 224 in epoch 18, gen_loss = 0.40385289165708754, disc_loss = 0.05935893301748567
Trained batch 225 in epoch 18, gen_loss = 0.4035131351082726, disc_loss = 0.059941031084091
Trained batch 226 in epoch 18, gen_loss = 0.40371772843835635, disc_loss = 0.060171058307102336
Trained batch 227 in epoch 18, gen_loss = 0.4036668136454465, disc_loss = 0.05994582692112185
Trained batch 228 in epoch 18, gen_loss = 0.4035211543849462, disc_loss = 0.05981691038097747
Trained batch 229 in epoch 18, gen_loss = 0.4039651290230129, disc_loss = 0.0596467138187069
Trained batch 230 in epoch 18, gen_loss = 0.4035858915739761, disc_loss = 0.05977281423696837
Trained batch 231 in epoch 18, gen_loss = 0.4036680489521602, disc_loss = 0.0600905659134853
Trained batch 232 in epoch 18, gen_loss = 0.40376130948762523, disc_loss = 0.05993412313942873
Trained batch 233 in epoch 18, gen_loss = 0.40385096488345384, disc_loss = 0.05978193600128731
Trained batch 234 in epoch 18, gen_loss = 0.4037564365153617, disc_loss = 0.059566429507066594
Trained batch 235 in epoch 18, gen_loss = 0.4041478674290544, disc_loss = 0.05937465616123025
Trained batch 236 in epoch 18, gen_loss = 0.4038573756248136, disc_loss = 0.05950894648059888
Trained batch 237 in epoch 18, gen_loss = 0.4040079993360183, disc_loss = 0.0609696046449244
Trained batch 238 in epoch 18, gen_loss = 0.4038428174152534, disc_loss = 0.06102386819565022
Trained batch 239 in epoch 18, gen_loss = 0.40382598054905733, disc_loss = 0.06085247881322478
Trained batch 240 in epoch 18, gen_loss = 0.4036724296595546, disc_loss = 0.060664744069993004
Trained batch 241 in epoch 18, gen_loss = 0.40352426518586054, disc_loss = 0.060556788278420356
Trained batch 242 in epoch 18, gen_loss = 0.40303242844318654, disc_loss = 0.060453251008051656
Trained batch 243 in epoch 18, gen_loss = 0.40293158041160615, disc_loss = 0.06032735687588937
Trained batch 244 in epoch 18, gen_loss = 0.4025844870781412, disc_loss = 0.06021831880646701
Trained batch 245 in epoch 18, gen_loss = 0.4024115409550628, disc_loss = 0.06006793314742485
Trained batch 246 in epoch 18, gen_loss = 0.4025597696603551, disc_loss = 0.05992636731957738
Trained batch 247 in epoch 18, gen_loss = 0.40291736226889396, disc_loss = 0.05973001078687488
Trained batch 248 in epoch 18, gen_loss = 0.4031400046195371, disc_loss = 0.05954209647803421
Trained batch 249 in epoch 18, gen_loss = 0.4031374583244324, disc_loss = 0.05933304364979267
Trained batch 250 in epoch 18, gen_loss = 0.40298814270125916, disc_loss = 0.05923973887683861
Trained batch 251 in epoch 18, gen_loss = 0.4028187720548539, disc_loss = 0.059416837990283966
Trained batch 252 in epoch 18, gen_loss = 0.40306583035133575, disc_loss = 0.059287696001911354
Trained batch 253 in epoch 18, gen_loss = 0.4031816650563338, disc_loss = 0.059265537392788045
Trained batch 254 in epoch 18, gen_loss = 0.40317744823063123, disc_loss = 0.059097794531022804
Trained batch 255 in epoch 18, gen_loss = 0.40292350575327873, disc_loss = 0.05911331965762656
Trained batch 256 in epoch 18, gen_loss = 0.40315889384496073, disc_loss = 0.05904949417316032
Trained batch 257 in epoch 18, gen_loss = 0.4034456924874653, disc_loss = 0.05885395700068668
Trained batch 258 in epoch 18, gen_loss = 0.40360708793618044, disc_loss = 0.0587072968554888
Trained batch 259 in epoch 18, gen_loss = 0.40358246083442983, disc_loss = 0.05853016287661516
Trained batch 260 in epoch 18, gen_loss = 0.40392771477443506, disc_loss = 0.058355976210129216
Trained batch 261 in epoch 18, gen_loss = 0.40397701008629255, disc_loss = 0.058232451063929165
Trained batch 262 in epoch 18, gen_loss = 0.4038346369003615, disc_loss = 0.058123995241896736
Trained batch 263 in epoch 18, gen_loss = 0.40366679926713306, disc_loss = 0.05805297242477536
Trained batch 264 in epoch 18, gen_loss = 0.40351688299538957, disc_loss = 0.05789685166388188
Trained batch 265 in epoch 18, gen_loss = 0.40335672343135776, disc_loss = 0.05794079933679642
Trained batch 266 in epoch 18, gen_loss = 0.4028971909583731, disc_loss = 0.05868374605136418
Trained batch 267 in epoch 18, gen_loss = 0.40329833617850913, disc_loss = 0.05874918775160366
Trained batch 268 in epoch 18, gen_loss = 0.4029460572620307, disc_loss = 0.05886216939437345
Trained batch 269 in epoch 18, gen_loss = 0.4027128407248744, disc_loss = 0.058955424375556134
Trained batch 270 in epoch 18, gen_loss = 0.40251800824795264, disc_loss = 0.05886370966355299
Trained batch 271 in epoch 18, gen_loss = 0.4024957204785417, disc_loss = 0.0586785125265391
Trained batch 272 in epoch 18, gen_loss = 0.40238228887865396, disc_loss = 0.05850736589099352
Trained batch 273 in epoch 18, gen_loss = 0.4021834074145686, disc_loss = 0.058390943969117245
Trained batch 274 in epoch 18, gen_loss = 0.40224788308143616, disc_loss = 0.058245951435105366
Trained batch 275 in epoch 18, gen_loss = 0.4021562207220257, disc_loss = 0.058092127813944135
Trained batch 276 in epoch 18, gen_loss = 0.40199362478531653, disc_loss = 0.05820303074410353
Trained batch 277 in epoch 18, gen_loss = 0.4019788753428905, disc_loss = 0.05887133735667566
Trained batch 278 in epoch 18, gen_loss = 0.40188558458427376, disc_loss = 0.059561878285874816
Trained batch 279 in epoch 18, gen_loss = 0.40193883127399854, disc_loss = 0.059588891909723836
Trained batch 280 in epoch 18, gen_loss = 0.4018010686937176, disc_loss = 0.05965695896407994
Trained batch 281 in epoch 18, gen_loss = 0.401913454135259, disc_loss = 0.059525315223776916
Trained batch 282 in epoch 18, gen_loss = 0.4016075178506939, disc_loss = 0.0596111728562957
Trained batch 283 in epoch 18, gen_loss = 0.40181404499100964, disc_loss = 0.059573147278672585
Trained batch 284 in epoch 18, gen_loss = 0.40196886073079025, disc_loss = 0.0594761336222291
Trained batch 285 in epoch 18, gen_loss = 0.40194611532704816, disc_loss = 0.059459321894455
Trained batch 286 in epoch 18, gen_loss = 0.40195656871546437, disc_loss = 0.0597739733320755
Trained batch 287 in epoch 18, gen_loss = 0.4023040916977657, disc_loss = 0.06014484308414265
Trained batch 288 in epoch 18, gen_loss = 0.402391631194877, disc_loss = 0.06010424391169965
Trained batch 289 in epoch 18, gen_loss = 0.40223767942395705, disc_loss = 0.06000255243210443
Trained batch 290 in epoch 18, gen_loss = 0.4024498896910153, disc_loss = 0.06030271696150815
Trained batch 291 in epoch 18, gen_loss = 0.4022171365684026, disc_loss = 0.06084725862585825
Trained batch 292 in epoch 18, gen_loss = 0.4025383408565977, disc_loss = 0.060927431429688636
Trained batch 293 in epoch 18, gen_loss = 0.4026317554874485, disc_loss = 0.06077972037692358
Trained batch 294 in epoch 18, gen_loss = 0.4025007809622813, disc_loss = 0.060676418317450305
Trained batch 295 in epoch 18, gen_loss = 0.40233734189658554, disc_loss = 0.0605524083807108
Trained batch 296 in epoch 18, gen_loss = 0.40230125529998884, disc_loss = 0.06066833528367056
Trained batch 297 in epoch 18, gen_loss = 0.4025657699012116, disc_loss = 0.06096138856717504
Trained batch 298 in epoch 18, gen_loss = 0.4023582767882076, disc_loss = 0.06097994018719846
Trained batch 299 in epoch 18, gen_loss = 0.4022454424699147, disc_loss = 0.06084300412175556
Trained batch 300 in epoch 18, gen_loss = 0.4024440981818988, disc_loss = 0.06074571305966357
Trained batch 301 in epoch 18, gen_loss = 0.4023619093839696, disc_loss = 0.06068708182355722
Trained batch 302 in epoch 18, gen_loss = 0.40264541294315076, disc_loss = 0.06077727512840685
Trained batch 303 in epoch 18, gen_loss = 0.4024495526560043, disc_loss = 0.060753124812005184
Trained batch 304 in epoch 18, gen_loss = 0.40223885921181224, disc_loss = 0.060683344521361295
Trained batch 305 in epoch 18, gen_loss = 0.40212412509653306, disc_loss = 0.061558382180854194
Trained batch 306 in epoch 18, gen_loss = 0.4017140120753248, disc_loss = 0.06225571065158234
Trained batch 307 in epoch 18, gen_loss = 0.40176810198403023, disc_loss = 0.06236946480892986
Trained batch 308 in epoch 18, gen_loss = 0.4017917098158, disc_loss = 0.06256948548601186
Trained batch 309 in epoch 18, gen_loss = 0.4017474216799582, disc_loss = 0.06250613514153708
Trained batch 310 in epoch 18, gen_loss = 0.40175954772345124, disc_loss = 0.06243486104419281
Trained batch 311 in epoch 18, gen_loss = 0.4018635319020504, disc_loss = 0.06230991964455312
Trained batch 312 in epoch 18, gen_loss = 0.40178473165240913, disc_loss = 0.062249112948656274
Trained batch 313 in epoch 18, gen_loss = 0.40153838200553965, disc_loss = 0.062264601388578394
Trained batch 314 in epoch 18, gen_loss = 0.40128361298924403, disc_loss = 0.06235578416417988
Trained batch 315 in epoch 18, gen_loss = 0.4012970159514041, disc_loss = 0.062293787725576304
Trained batch 316 in epoch 18, gen_loss = 0.4015239222380641, disc_loss = 0.06252029241130273
Trained batch 317 in epoch 18, gen_loss = 0.40175373102509, disc_loss = 0.06337750655358786
Trained batch 318 in epoch 18, gen_loss = 0.40150791098331584, disc_loss = 0.06359382127017531
Trained batch 319 in epoch 18, gen_loss = 0.40138499401509764, disc_loss = 0.06389718771970365
Trained batch 320 in epoch 18, gen_loss = 0.4012392841952612, disc_loss = 0.06383302559745367
Trained batch 321 in epoch 18, gen_loss = 0.4010557354607197, disc_loss = 0.06380177673634997
Trained batch 322 in epoch 18, gen_loss = 0.4013538980631636, disc_loss = 0.06366392513073911
Trained batch 323 in epoch 18, gen_loss = 0.40132460513232665, disc_loss = 0.06373724129545376
Trained batch 324 in epoch 18, gen_loss = 0.40140766840714676, disc_loss = 0.06361328219851622
Trained batch 325 in epoch 18, gen_loss = 0.4012326578055423, disc_loss = 0.0639255684800446
Trained batch 326 in epoch 18, gen_loss = 0.40147432438824154, disc_loss = 0.06389914091608119
Trained batch 327 in epoch 18, gen_loss = 0.40140296173531836, disc_loss = 0.06413557583454815
Trained batch 328 in epoch 18, gen_loss = 0.4010502515774005, disc_loss = 0.06420357095921203
Trained batch 329 in epoch 18, gen_loss = 0.40072818172700475, disc_loss = 0.06418391260403124
Trained batch 330 in epoch 18, gen_loss = 0.40084071254802256, disc_loss = 0.06421196377158075
Trained batch 331 in epoch 18, gen_loss = 0.40091318888477534, disc_loss = 0.06411170381323311
Trained batch 332 in epoch 18, gen_loss = 0.40065485176381405, disc_loss = 0.06461320147086103
Trained batch 333 in epoch 18, gen_loss = 0.400946007071141, disc_loss = 0.06480349391464613
Trained batch 334 in epoch 18, gen_loss = 0.400948443875384, disc_loss = 0.06467314283294019
Trained batch 335 in epoch 18, gen_loss = 0.40061986162548974, disc_loss = 0.06473188524389462
Trained batch 336 in epoch 18, gen_loss = 0.4006581964407901, disc_loss = 0.0646424207046009
Trained batch 337 in epoch 18, gen_loss = 0.40075419305344306, disc_loss = 0.06479869321947532
Trained batch 338 in epoch 18, gen_loss = 0.4005404695824536, disc_loss = 0.06486866411898604
Trained batch 339 in epoch 18, gen_loss = 0.4002206184408244, disc_loss = 0.06493572272524675
Trained batch 340 in epoch 18, gen_loss = 0.4000231650742618, disc_loss = 0.06509112937872973
Trained batch 341 in epoch 18, gen_loss = 0.39991302317694616, disc_loss = 0.0651188597317284
Trained batch 342 in epoch 18, gen_loss = 0.4000047952718707, disc_loss = 0.06497967864166804
Trained batch 343 in epoch 18, gen_loss = 0.4000170476907908, disc_loss = 0.06485876364925833
Trained batch 344 in epoch 18, gen_loss = 0.40000261707582335, disc_loss = 0.06475086381415958
Trained batch 345 in epoch 18, gen_loss = 0.3998710078138836, disc_loss = 0.06473258640240297
Trained batch 346 in epoch 18, gen_loss = 0.3998390644015771, disc_loss = 0.06474172406338735
Trained batch 347 in epoch 18, gen_loss = 0.39978742582359533, disc_loss = 0.06467855290038747
Trained batch 348 in epoch 18, gen_loss = 0.3999000242924622, disc_loss = 0.06453243349238505
Trained batch 349 in epoch 18, gen_loss = 0.3999807280302048, disc_loss = 0.06438124284946493
Trained batch 350 in epoch 18, gen_loss = 0.40014753331485975, disc_loss = 0.06461048727733033
Trained batch 351 in epoch 18, gen_loss = 0.39998930997469206, disc_loss = 0.06544114885036834
Trained batch 352 in epoch 18, gen_loss = 0.3997810443298675, disc_loss = 0.06567833712720246
Trained batch 353 in epoch 18, gen_loss = 0.39990735112947257, disc_loss = 0.06602064573526972
Trained batch 354 in epoch 18, gen_loss = 0.40000789593642866, disc_loss = 0.0659573537546774
Trained batch 355 in epoch 18, gen_loss = 0.3999265662572357, disc_loss = 0.06597036464150284
Trained batch 356 in epoch 18, gen_loss = 0.39997191706291435, disc_loss = 0.065875390129743
Trained batch 357 in epoch 18, gen_loss = 0.4001207240133978, disc_loss = 0.0657549906943472
Trained batch 358 in epoch 18, gen_loss = 0.4000597518134582, disc_loss = 0.06562348271260936
Trained batch 359 in epoch 18, gen_loss = 0.39981728477610484, disc_loss = 0.06562425203155726
Trained batch 360 in epoch 18, gen_loss = 0.39991975722220463, disc_loss = 0.06552723276369542
Trained batch 361 in epoch 18, gen_loss = 0.3997940672201346, disc_loss = 0.06543319222892928
Trained batch 362 in epoch 18, gen_loss = 0.3995224292449058, disc_loss = 0.06554783288820469
Trained batch 363 in epoch 18, gen_loss = 0.39963919178142654, disc_loss = 0.0654545074026868
Trained batch 364 in epoch 18, gen_loss = 0.39976849155883265, disc_loss = 0.06530204614598865
Trained batch 365 in epoch 18, gen_loss = 0.3997621943390435, disc_loss = 0.06514090841859986
Trained batch 366 in epoch 18, gen_loss = 0.39967180272863734, disc_loss = 0.06499011203017319
Trained batch 367 in epoch 18, gen_loss = 0.399763229019616, disc_loss = 0.06483951254251777
Trained batch 368 in epoch 18, gen_loss = 0.3996671235496759, disc_loss = 0.06468249379523441
Trained batch 369 in epoch 18, gen_loss = 0.3995572893200694, disc_loss = 0.06455945222185472
Trained batch 370 in epoch 18, gen_loss = 0.39934218090499507, disc_loss = 0.06446516305594793
Trained batch 371 in epoch 18, gen_loss = 0.39933254513689265, disc_loss = 0.06435529682509881
Trained batch 372 in epoch 18, gen_loss = 0.39938009680116465, disc_loss = 0.06420968450860547
Trained batch 373 in epoch 18, gen_loss = 0.3993128851295155, disc_loss = 0.06412014477129249
Trained batch 374 in epoch 18, gen_loss = 0.39933078980445863, disc_loss = 0.06422025498126945
Trained batch 375 in epoch 18, gen_loss = 0.3992946056767981, disc_loss = 0.06432006609541899
Trained batch 376 in epoch 18, gen_loss = 0.3991384408992545, disc_loss = 0.06420163570011445
Trained batch 377 in epoch 18, gen_loss = 0.3991868842846502, disc_loss = 0.06408080296398747
Trained batch 378 in epoch 18, gen_loss = 0.3992352079904803, disc_loss = 0.06397027253372334
Trained batch 379 in epoch 18, gen_loss = 0.3994320430253681, disc_loss = 0.06388622380572519
Trained batch 380 in epoch 18, gen_loss = 0.39955596269897903, disc_loss = 0.06389428027282197
Trained batch 381 in epoch 18, gen_loss = 0.39951691741406603, disc_loss = 0.06394718768177506
Trained batch 382 in epoch 18, gen_loss = 0.39956806495046493, disc_loss = 0.06399789315772392
Trained batch 383 in epoch 18, gen_loss = 0.39938616325768334, disc_loss = 0.0638628767762081
Trained batch 384 in epoch 18, gen_loss = 0.3995015468690302, disc_loss = 0.0637972817925567
Trained batch 385 in epoch 18, gen_loss = 0.39949781181281097, disc_loss = 0.06369319749112999
Trained batch 386 in epoch 18, gen_loss = 0.3993562729475726, disc_loss = 0.06371256341262496
Trained batch 387 in epoch 18, gen_loss = 0.3995446721763955, disc_loss = 0.06394237923056617
Trained batch 388 in epoch 18, gen_loss = 0.3994859872256576, disc_loss = 0.06408535202505465
Trained batch 389 in epoch 18, gen_loss = 0.39952352727070833, disc_loss = 0.06400395350841184
Trained batch 390 in epoch 18, gen_loss = 0.39971076862891314, disc_loss = 0.06389583920574059
Trained batch 391 in epoch 18, gen_loss = 0.3996857387222806, disc_loss = 0.06380428717713993
Trained batch 392 in epoch 18, gen_loss = 0.3998868065784299, disc_loss = 0.06367910432370981
Trained batch 393 in epoch 18, gen_loss = 0.40004087750076645, disc_loss = 0.0637005655376269
Trained batch 394 in epoch 18, gen_loss = 0.3999072386494166, disc_loss = 0.06384044562030254
Trained batch 395 in epoch 18, gen_loss = 0.3999682373621247, disc_loss = 0.063899485590736
Trained batch 396 in epoch 18, gen_loss = 0.3999646575534974, disc_loss = 0.06379594359082412
Trained batch 397 in epoch 18, gen_loss = 0.4000054770827892, disc_loss = 0.06369341539579383
Trained batch 398 in epoch 18, gen_loss = 0.40005398506209966, disc_loss = 0.06361249888801299
Trained batch 399 in epoch 18, gen_loss = 0.40012275777757167, disc_loss = 0.06358274611993693
Trained batch 400 in epoch 18, gen_loss = 0.4002935641870237, disc_loss = 0.06355598365813679
Trained batch 401 in epoch 18, gen_loss = 0.40029243442846174, disc_loss = 0.06353985644594316
Trained batch 402 in epoch 18, gen_loss = 0.40043172136725624, disc_loss = 0.06358785837052144
Trained batch 403 in epoch 18, gen_loss = 0.4004760276120488, disc_loss = 0.06362218330821742
Trained batch 404 in epoch 18, gen_loss = 0.40058919000036924, disc_loss = 0.06370714430432813
Trained batch 405 in epoch 18, gen_loss = 0.4007348861600378, disc_loss = 0.06366940844102116
Trained batch 406 in epoch 18, gen_loss = 0.4007236675636188, disc_loss = 0.06357169361254178
Trained batch 407 in epoch 18, gen_loss = 0.4007631668127051, disc_loss = 0.0634681342989115
Trained batch 408 in epoch 18, gen_loss = 0.4006285328591074, disc_loss = 0.06339057650949924
Trained batch 409 in epoch 18, gen_loss = 0.400755162791508, disc_loss = 0.06342705251399156
Trained batch 410 in epoch 18, gen_loss = 0.4007301214547633, disc_loss = 0.06372166404482475
Trained batch 411 in epoch 18, gen_loss = 0.40072147157585736, disc_loss = 0.06374158697017442
Trained batch 412 in epoch 18, gen_loss = 0.40076605293710355, disc_loss = 0.0636079421720172
Trained batch 413 in epoch 18, gen_loss = 0.40072580027407495, disc_loss = 0.06358306321702394
Trained batch 414 in epoch 18, gen_loss = 0.40084193277071756, disc_loss = 0.06350713385134396
Trained batch 415 in epoch 18, gen_loss = 0.4006924373455919, disc_loss = 0.06337341778495241
Trained batch 416 in epoch 18, gen_loss = 0.40071685322754674, disc_loss = 0.06328956930109744
Trained batch 417 in epoch 18, gen_loss = 0.40061647769366726, disc_loss = 0.06320223583768536
Trained batch 418 in epoch 18, gen_loss = 0.4004719760935745, disc_loss = 0.06311276325120242
Trained batch 419 in epoch 18, gen_loss = 0.4004872611590794, disc_loss = 0.06302401276992722
Trained batch 420 in epoch 18, gen_loss = 0.40063682396734696, disc_loss = 0.06295769177532076
Trained batch 421 in epoch 18, gen_loss = 0.40069499541232934, disc_loss = 0.06290663352293532
Trained batch 422 in epoch 18, gen_loss = 0.40057297336294295, disc_loss = 0.06280387228962483
Trained batch 423 in epoch 18, gen_loss = 0.40089004233760656, disc_loss = 0.06298439653550784
Trained batch 424 in epoch 18, gen_loss = 0.40081204694860123, disc_loss = 0.06302651127362076
Trained batch 425 in epoch 18, gen_loss = 0.4011254155300033, disc_loss = 0.06290292633072136
Trained batch 426 in epoch 18, gen_loss = 0.4012098238395584, disc_loss = 0.06282387327389743
Trained batch 427 in epoch 18, gen_loss = 0.40127634465972956, disc_loss = 0.06270295468911911
Trained batch 428 in epoch 18, gen_loss = 0.40128014874069284, disc_loss = 0.06258315910283467
Trained batch 429 in epoch 18, gen_loss = 0.40134300631146097, disc_loss = 0.0624726771864347
Trained batch 430 in epoch 18, gen_loss = 0.4015244989550031, disc_loss = 0.06236054342598795
Trained batch 431 in epoch 18, gen_loss = 0.401575347063718, disc_loss = 0.06230224576386347
Trained batch 432 in epoch 18, gen_loss = 0.4014380511593323, disc_loss = 0.06221852321328281
Trained batch 433 in epoch 18, gen_loss = 0.4015520158725949, disc_loss = 0.06210507441436537
Trained batch 434 in epoch 18, gen_loss = 0.40161716951721016, disc_loss = 0.06224335112726723
Trained batch 435 in epoch 18, gen_loss = 0.4015112753034732, disc_loss = 0.0627138501453991
Trained batch 436 in epoch 18, gen_loss = 0.4017336564287714, disc_loss = 0.06271929553980583
Trained batch 437 in epoch 18, gen_loss = 0.40187778980492456, disc_loss = 0.06289979899791176
Trained batch 438 in epoch 18, gen_loss = 0.40167906866801356, disc_loss = 0.06339651925896628
Trained batch 439 in epoch 18, gen_loss = 0.40158853408965195, disc_loss = 0.06339661562921141
Trained batch 440 in epoch 18, gen_loss = 0.4017868481931232, disc_loss = 0.06330456730514732
Trained batch 441 in epoch 18, gen_loss = 0.4016708455204424, disc_loss = 0.06320365391170177
Trained batch 442 in epoch 18, gen_loss = 0.4014888290761556, disc_loss = 0.06311129971300136
Trained batch 443 in epoch 18, gen_loss = 0.40149110025382256, disc_loss = 0.06310141708403993
Trained batch 444 in epoch 18, gen_loss = 0.40129117925515334, disc_loss = 0.06312807474515579
Trained batch 445 in epoch 18, gen_loss = 0.4015294115639588, disc_loss = 0.06321579359175278
Trained batch 446 in epoch 18, gen_loss = 0.40159513326299273, disc_loss = 0.0631860852485285
Trained batch 447 in epoch 18, gen_loss = 0.40149336753945264, disc_loss = 0.06309050645566978
Trained batch 448 in epoch 18, gen_loss = 0.40142215061559444, disc_loss = 0.06304202845759839
Trained batch 449 in epoch 18, gen_loss = 0.40163437187671663, disc_loss = 0.0629396505250285
Trained batch 450 in epoch 18, gen_loss = 0.4015400707060905, disc_loss = 0.06285794439958925
Trained batch 451 in epoch 18, gen_loss = 0.4015554886607997, disc_loss = 0.0627394731133863
Trained batch 452 in epoch 18, gen_loss = 0.40166193286314705, disc_loss = 0.06278523540938434
Trained batch 453 in epoch 18, gen_loss = 0.4016273838307889, disc_loss = 0.0634769465300431
Trained batch 454 in epoch 18, gen_loss = 0.40163995649788403, disc_loss = 0.06362363523854823
Trained batch 455 in epoch 18, gen_loss = 0.4016250442517431, disc_loss = 0.0635685761787994
Trained batch 456 in epoch 18, gen_loss = 0.40155778143807624, disc_loss = 0.06356978627264141
Trained batch 457 in epoch 18, gen_loss = 0.4016481030846267, disc_loss = 0.06353701846003044
Trained batch 458 in epoch 18, gen_loss = 0.4014939731372468, disc_loss = 0.06373107670004884
Trained batch 459 in epoch 18, gen_loss = 0.4016519056066223, disc_loss = 0.06436984211550621
Trained batch 460 in epoch 18, gen_loss = 0.4015572449261092, disc_loss = 0.06426390731876915
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.3244647681713104, disc_loss = 0.07772735506296158
Trained batch 1 in epoch 19, gen_loss = 0.37744100391864777, disc_loss = 0.04597289953380823
Trained batch 2 in epoch 19, gen_loss = 0.3658684492111206, disc_loss = 0.05019037239253521
Trained batch 3 in epoch 19, gen_loss = 0.371607206761837, disc_loss = 0.04291891073808074
Trained batch 4 in epoch 19, gen_loss = 0.371558940410614, disc_loss = 0.037777675315737724
Trained batch 5 in epoch 19, gen_loss = 0.3594492624203364, disc_loss = 0.03769261917720238
Trained batch 6 in epoch 19, gen_loss = 0.3650748005935124, disc_loss = 0.04512383921870163
Trained batch 7 in epoch 19, gen_loss = 0.3570861220359802, disc_loss = 0.049933116184547544
Trained batch 8 in epoch 19, gen_loss = 0.3668444554011027, disc_loss = 0.04590469391809569
Trained batch 9 in epoch 19, gen_loss = 0.37432900071144104, disc_loss = 0.04335641972720623
Trained batch 10 in epoch 19, gen_loss = 0.3756637248125943, disc_loss = 0.04060874430632049
Trained batch 11 in epoch 19, gen_loss = 0.3771316632628441, disc_loss = 0.040261885384097695
Trained batch 12 in epoch 19, gen_loss = 0.3721603819957146, disc_loss = 0.04284555887660155
Trained batch 13 in epoch 19, gen_loss = 0.3750246231045042, disc_loss = 0.04048797827480095
Trained batch 14 in epoch 19, gen_loss = 0.3801329513390859, disc_loss = 0.03889321976651748
Trained batch 15 in epoch 19, gen_loss = 0.3816672060638666, disc_loss = 0.03842899779556319
Trained batch 16 in epoch 19, gen_loss = 0.38161035846261415, disc_loss = 0.04219811163185274
Trained batch 17 in epoch 19, gen_loss = 0.3856598354048199, disc_loss = 0.04157305048364732
Trained batch 18 in epoch 19, gen_loss = 0.38917413353919983, disc_loss = 0.04002661017799064
Trained batch 19 in epoch 19, gen_loss = 0.3904089882969856, disc_loss = 0.03845523241907358
Trained batch 20 in epoch 19, gen_loss = 0.395726162762869, disc_loss = 0.037032295062783216
Trained batch 21 in epoch 19, gen_loss = 0.39662259410728107, disc_loss = 0.03572389419952577
Trained batch 22 in epoch 19, gen_loss = 0.39768321229063947, disc_loss = 0.03454699784355319
Trained batch 23 in epoch 19, gen_loss = 0.39497627193729085, disc_loss = 0.03545632737223059
Trained batch 24 in epoch 19, gen_loss = 0.3932176685333252, disc_loss = 0.03897301342338324
Trained batch 25 in epoch 19, gen_loss = 0.3947086288378789, disc_loss = 0.042520216128860526
Trained batch 26 in epoch 19, gen_loss = 0.3927461593239396, disc_loss = 0.0426291162148118
Trained batch 27 in epoch 19, gen_loss = 0.3918433114886284, disc_loss = 0.04192580578715673
Trained batch 28 in epoch 19, gen_loss = 0.3919594832535448, disc_loss = 0.042320104026845815
Trained batch 29 in epoch 19, gen_loss = 0.3907124529282252, disc_loss = 0.04184922423834602
Trained batch 30 in epoch 19, gen_loss = 0.38919412801342623, disc_loss = 0.04178294392242547
Trained batch 31 in epoch 19, gen_loss = 0.3921094620600343, disc_loss = 0.04300508552114479
Trained batch 32 in epoch 19, gen_loss = 0.39370219093380554, disc_loss = 0.042327669505594356
Trained batch 33 in epoch 19, gen_loss = 0.392317038248567, disc_loss = 0.04275282206671203
Trained batch 34 in epoch 19, gen_loss = 0.3925884936537061, disc_loss = 0.04222800281963178
Trained batch 35 in epoch 19, gen_loss = 0.3951176421509849, disc_loss = 0.04145242074607975
Trained batch 36 in epoch 19, gen_loss = 0.39467477959555547, disc_loss = 0.04127380511144529
Trained batch 37 in epoch 19, gen_loss = 0.3932068991033654, disc_loss = 0.04904466021904036
Trained batch 38 in epoch 19, gen_loss = 0.3933506302344493, disc_loss = 0.049144518084059924
Trained batch 39 in epoch 19, gen_loss = 0.3949543297290802, disc_loss = 0.05144266874995083
Trained batch 40 in epoch 19, gen_loss = 0.39421451164454946, disc_loss = 0.05514349240991401
Trained batch 41 in epoch 19, gen_loss = 0.3960316046362832, disc_loss = 0.05517614231489244
Trained batch 42 in epoch 19, gen_loss = 0.39561889753785245, disc_loss = 0.056388955021840194
Trained batch 43 in epoch 19, gen_loss = 0.3958805650472641, disc_loss = 0.05751697149720381
Trained batch 44 in epoch 19, gen_loss = 0.3968922350141737, disc_loss = 0.057303666385511556
Trained batch 45 in epoch 19, gen_loss = 0.396337804586991, disc_loss = 0.05636328009321638
Trained batch 46 in epoch 19, gen_loss = 0.3981442413431533, disc_loss = 0.05551157479590558
Trained batch 47 in epoch 19, gen_loss = 0.39714188128709793, disc_loss = 0.054856454099838935
Trained batch 48 in epoch 19, gen_loss = 0.39914287535511717, disc_loss = 0.05502258583295102
Trained batch 49 in epoch 19, gen_loss = 0.39836609542369844, disc_loss = 0.05677351661026478
Trained batch 50 in epoch 19, gen_loss = 0.398834943187003, disc_loss = 0.05614576185596924
Trained batch 51 in epoch 19, gen_loss = 0.40065364367686784, disc_loss = 0.057017846641918786
Trained batch 52 in epoch 19, gen_loss = 0.40174864710501906, disc_loss = 0.05671809322007422
Trained batch 53 in epoch 19, gen_loss = 0.3997018011631789, disc_loss = 0.05845946670268421
Trained batch 54 in epoch 19, gen_loss = 0.40116356936368075, disc_loss = 0.061045084656639534
Trained batch 55 in epoch 19, gen_loss = 0.40038918065173285, disc_loss = 0.06052039580286613
Trained batch 56 in epoch 19, gen_loss = 0.39968100085593106, disc_loss = 0.06201861579820775
Trained batch 57 in epoch 19, gen_loss = 0.39954519374617214, disc_loss = 0.06197092929405385
Trained batch 58 in epoch 19, gen_loss = 0.39939650438599666, disc_loss = 0.06332763439139068
Trained batch 59 in epoch 19, gen_loss = 0.39834354917208353, disc_loss = 0.06557456965868672
Trained batch 60 in epoch 19, gen_loss = 0.39920422483663087, disc_loss = 0.0663001355638758
Trained batch 61 in epoch 19, gen_loss = 0.3979739902480956, disc_loss = 0.06558236681045063
Trained batch 62 in epoch 19, gen_loss = 0.39577129294001867, disc_loss = 0.06549791982840925
Trained batch 63 in epoch 19, gen_loss = 0.3950588842853904, disc_loss = 0.06506675478885882
Trained batch 64 in epoch 19, gen_loss = 0.39513776623285735, disc_loss = 0.06509892204060004
Trained batch 65 in epoch 19, gen_loss = 0.39402975638707477, disc_loss = 0.06469881622064294
Trained batch 66 in epoch 19, gen_loss = 0.39437439014662556, disc_loss = 0.06470051049185332
Trained batch 67 in epoch 19, gen_loss = 0.3955126698402798, disc_loss = 0.06465383703984759
Trained batch 68 in epoch 19, gen_loss = 0.3949716747670934, disc_loss = 0.06452450293885625
Trained batch 69 in epoch 19, gen_loss = 0.39578164901052204, disc_loss = 0.06399629922317607
Trained batch 70 in epoch 19, gen_loss = 0.3957560784380201, disc_loss = 0.0639851525373442
Trained batch 71 in epoch 19, gen_loss = 0.3963013630774286, disc_loss = 0.06410518710294531
Trained batch 72 in epoch 19, gen_loss = 0.395891790928906, disc_loss = 0.06424093029576622
Trained batch 73 in epoch 19, gen_loss = 0.3953477756397144, disc_loss = 0.06435075661519894
Trained batch 74 in epoch 19, gen_loss = 0.39604448874791465, disc_loss = 0.06377822858591875
Trained batch 75 in epoch 19, gen_loss = 0.39602376638274445, disc_loss = 0.06340349183760975
Trained batch 76 in epoch 19, gen_loss = 0.39641498242105755, disc_loss = 0.06279970274923684
Trained batch 77 in epoch 19, gen_loss = 0.3979696115622154, disc_loss = 0.06250697092559093
Trained batch 78 in epoch 19, gen_loss = 0.3975788916968092, disc_loss = 0.06297276286950594
Trained batch 79 in epoch 19, gen_loss = 0.3988844733685255, disc_loss = 0.06254582575056702
Trained batch 80 in epoch 19, gen_loss = 0.3992511950157307, disc_loss = 0.06347570027926086
Trained batch 81 in epoch 19, gen_loss = 0.4001526341932576, disc_loss = 0.06356224692540198
Trained batch 82 in epoch 19, gen_loss = 0.40021243332380274, disc_loss = 0.0630284931779985
Trained batch 83 in epoch 19, gen_loss = 0.3995012296807198, disc_loss = 0.0643090124774192
Trained batch 84 in epoch 19, gen_loss = 0.3984017729759216, disc_loss = 0.06521889407406835
Trained batch 85 in epoch 19, gen_loss = 0.3989732722903407, disc_loss = 0.0649801344329188
Trained batch 86 in epoch 19, gen_loss = 0.39942373249722624, disc_loss = 0.06478141353133766
Trained batch 87 in epoch 19, gen_loss = 0.39941164377060806, disc_loss = 0.0645848939576271
Trained batch 88 in epoch 19, gen_loss = 0.3992687279588721, disc_loss = 0.06423346298547943
Trained batch 89 in epoch 19, gen_loss = 0.39911358025338917, disc_loss = 0.06383451283391979
Trained batch 90 in epoch 19, gen_loss = 0.3993755831168248, disc_loss = 0.06389153849046963
Trained batch 91 in epoch 19, gen_loss = 0.39849259639563767, disc_loss = 0.06445436003496466
Trained batch 92 in epoch 19, gen_loss = 0.39898029931129947, disc_loss = 0.06536076372108793
Trained batch 93 in epoch 19, gen_loss = 0.3978118449449539, disc_loss = 0.06484005439709475
Trained batch 94 in epoch 19, gen_loss = 0.3973360899247621, disc_loss = 0.06445748145250897
Trained batch 95 in epoch 19, gen_loss = 0.39629886019974947, disc_loss = 0.06401165739710753
Trained batch 96 in epoch 19, gen_loss = 0.39595133404141847, disc_loss = 0.06364261902407888
Trained batch 97 in epoch 19, gen_loss = 0.39589689063782596, disc_loss = 0.06354378872760097
Trained batch 98 in epoch 19, gen_loss = 0.39509534715402006, disc_loss = 0.06470694605524492
Trained batch 99 in epoch 19, gen_loss = 0.3958522027730942, disc_loss = 0.06771984258666634
Trained batch 100 in epoch 19, gen_loss = 0.3961115892570798, disc_loss = 0.06755739791632288
Trained batch 101 in epoch 19, gen_loss = 0.3958801188889672, disc_loss = 0.06742769423141784
Trained batch 102 in epoch 19, gen_loss = 0.3952836460858873, disc_loss = 0.06702469985534265
Trained batch 103 in epoch 19, gen_loss = 0.39629493395869547, disc_loss = 0.0671616443253767
Trained batch 104 in epoch 19, gen_loss = 0.3962793361572992, disc_loss = 0.06721766344493343
Trained batch 105 in epoch 19, gen_loss = 0.3962364891227686, disc_loss = 0.06672176827659022
Trained batch 106 in epoch 19, gen_loss = 0.3963807615164284, disc_loss = 0.06677991454707127
Trained batch 107 in epoch 19, gen_loss = 0.3963927574179791, disc_loss = 0.06852832239949042
Trained batch 108 in epoch 19, gen_loss = 0.3964172896988895, disc_loss = 0.06972448948189752
Trained batch 109 in epoch 19, gen_loss = 0.3964710062200373, disc_loss = 0.06920644991438497
Trained batch 110 in epoch 19, gen_loss = 0.3960938945009902, disc_loss = 0.06926573489096251
Trained batch 111 in epoch 19, gen_loss = 0.3957870003900358, disc_loss = 0.06873448409273156
Trained batch 112 in epoch 19, gen_loss = 0.39528084856219, disc_loss = 0.0683279718907006
Trained batch 113 in epoch 19, gen_loss = 0.39497806576260347, disc_loss = 0.06818203621527605
Trained batch 114 in epoch 19, gen_loss = 0.39449261763821475, disc_loss = 0.06811551642806633
Trained batch 115 in epoch 19, gen_loss = 0.39395125672735015, disc_loss = 0.0677629351969166
Trained batch 116 in epoch 19, gen_loss = 0.39481532828420657, disc_loss = 0.06965859576613985
Trained batch 117 in epoch 19, gen_loss = 0.39424505880323507, disc_loss = 0.07018114107076899
Trained batch 118 in epoch 19, gen_loss = 0.3946984350180426, disc_loss = 0.06993219777628654
Trained batch 119 in epoch 19, gen_loss = 0.3945928660531839, disc_loss = 0.06956027687216798
Trained batch 120 in epoch 19, gen_loss = 0.3944206513649176, disc_loss = 0.069171388194827
Trained batch 121 in epoch 19, gen_loss = 0.39395953299569303, disc_loss = 0.06867128636565853
Trained batch 122 in epoch 19, gen_loss = 0.39408027762319986, disc_loss = 0.06833900116020586
Trained batch 123 in epoch 19, gen_loss = 0.3939500564048367, disc_loss = 0.0678755494074956
Trained batch 124 in epoch 19, gen_loss = 0.3941604499816895, disc_loss = 0.06742159529775381
Trained batch 125 in epoch 19, gen_loss = 0.394172424834872, disc_loss = 0.06704428050637481
Trained batch 126 in epoch 19, gen_loss = 0.3940073887663563, disc_loss = 0.06670358631114556
Trained batch 127 in epoch 19, gen_loss = 0.39476898219436407, disc_loss = 0.06643854073627153
Trained batch 128 in epoch 19, gen_loss = 0.3951344591702602, disc_loss = 0.06689064075462808
Trained batch 129 in epoch 19, gen_loss = 0.3947906386393767, disc_loss = 0.06751453587785364
Trained batch 130 in epoch 19, gen_loss = 0.3956602732188829, disc_loss = 0.06751825499085297
Trained batch 131 in epoch 19, gen_loss = 0.39626681149908993, disc_loss = 0.06707776334334278
Trained batch 132 in epoch 19, gen_loss = 0.39609160010976, disc_loss = 0.0666396310903076
Trained batch 133 in epoch 19, gen_loss = 0.39610440873388036, disc_loss = 0.06633252161207484
Trained batch 134 in epoch 19, gen_loss = 0.3964516588935146, disc_loss = 0.06657864495559974
Trained batch 135 in epoch 19, gen_loss = 0.39735813548459725, disc_loss = 0.06626145799151238
Trained batch 136 in epoch 19, gen_loss = 0.3973401258461667, disc_loss = 0.06673192417752134
Trained batch 137 in epoch 19, gen_loss = 0.3970206008441206, disc_loss = 0.06646024179307447
Trained batch 138 in epoch 19, gen_loss = 0.3959657757831134, disc_loss = 0.06830978385514493
Trained batch 139 in epoch 19, gen_loss = 0.39617607146501543, disc_loss = 0.06957038845866918
Trained batch 140 in epoch 19, gen_loss = 0.3963068930815298, disc_loss = 0.06940769850679324
Trained batch 141 in epoch 19, gen_loss = 0.3958843782754012, disc_loss = 0.06903783353963788
Trained batch 142 in epoch 19, gen_loss = 0.3961076944858044, disc_loss = 0.06889203661023736
Trained batch 143 in epoch 19, gen_loss = 0.3960433246360885, disc_loss = 0.06854012657681273
Trained batch 144 in epoch 19, gen_loss = 0.39614971917251063, disc_loss = 0.06812913580958185
Trained batch 145 in epoch 19, gen_loss = 0.39644774672103256, disc_loss = 0.06786438623723919
Trained batch 146 in epoch 19, gen_loss = 0.39637944467213687, disc_loss = 0.06758651266596755
Trained batch 147 in epoch 19, gen_loss = 0.3963958077334069, disc_loss = 0.06724800173243559
Trained batch 148 in epoch 19, gen_loss = 0.3955537396789397, disc_loss = 0.06732284871473808
Trained batch 149 in epoch 19, gen_loss = 0.3949003181854884, disc_loss = 0.06722090985625982
Trained batch 150 in epoch 19, gen_loss = 0.39471680182494867, disc_loss = 0.06746722655432509
Trained batch 151 in epoch 19, gen_loss = 0.3947358409825124, disc_loss = 0.06755398617028013
Trained batch 152 in epoch 19, gen_loss = 0.3943965822653054, disc_loss = 0.06751392761038409
Trained batch 153 in epoch 19, gen_loss = 0.39467992817426656, disc_loss = 0.06745646849226256
Trained batch 154 in epoch 19, gen_loss = 0.3948245433069045, disc_loss = 0.06740044606549124
Trained batch 155 in epoch 19, gen_loss = 0.3946404779950778, disc_loss = 0.06709749068921575
Trained batch 156 in epoch 19, gen_loss = 0.39444983669906664, disc_loss = 0.06682766880246864
Trained batch 157 in epoch 19, gen_loss = 0.3947707722081414, disc_loss = 0.06703649075772566
Trained batch 158 in epoch 19, gen_loss = 0.39437096617506734, disc_loss = 0.06737530082698513
Trained batch 159 in epoch 19, gen_loss = 0.39437540620565414, disc_loss = 0.0670649845036678
Trained batch 160 in epoch 19, gen_loss = 0.39434197452497777, disc_loss = 0.06686688472534189
Trained batch 161 in epoch 19, gen_loss = 0.394489308382258, disc_loss = 0.066565461134837
Trained batch 162 in epoch 19, gen_loss = 0.3944989276444254, disc_loss = 0.06641624815350661
Trained batch 163 in epoch 19, gen_loss = 0.39476299213200083, disc_loss = 0.06612430493597214
Trained batch 164 in epoch 19, gen_loss = 0.3952286250663526, disc_loss = 0.06606098547803634
Trained batch 165 in epoch 19, gen_loss = 0.3948997305818351, disc_loss = 0.0671285596305886
Trained batch 166 in epoch 19, gen_loss = 0.3951240206906895, disc_loss = 0.06701637410787409
Trained batch 167 in epoch 19, gen_loss = 0.3958073684147426, disc_loss = 0.06677752728795722
Trained batch 168 in epoch 19, gen_loss = 0.39547331992691087, disc_loss = 0.06664881632613713
Trained batch 169 in epoch 19, gen_loss = 0.39522072883213266, disc_loss = 0.06680886914186618
Trained batch 170 in epoch 19, gen_loss = 0.3953449997985572, disc_loss = 0.06670015429457028
Trained batch 171 in epoch 19, gen_loss = 0.39504765545906023, disc_loss = 0.06656148815310972
Trained batch 172 in epoch 19, gen_loss = 0.3952632885792352, disc_loss = 0.06647742890639802
Trained batch 173 in epoch 19, gen_loss = 0.39561117209237195, disc_loss = 0.06652096648240226
Trained batch 174 in epoch 19, gen_loss = 0.3958556624821254, disc_loss = 0.0662355090784175
Trained batch 175 in epoch 19, gen_loss = 0.3961505779827183, disc_loss = 0.06594430733556775
Trained batch 176 in epoch 19, gen_loss = 0.396475402985589, disc_loss = 0.06593725887143005
Trained batch 177 in epoch 19, gen_loss = 0.39613469129198053, disc_loss = 0.06728272569062335
Trained batch 178 in epoch 19, gen_loss = 0.39675796131847957, disc_loss = 0.06756961847234039
Trained batch 179 in epoch 19, gen_loss = 0.3972642206483417, disc_loss = 0.06740958125640949
Trained batch 180 in epoch 19, gen_loss = 0.3971028311476523, disc_loss = 0.06725804164017761
Trained batch 181 in epoch 19, gen_loss = 0.3970574664545583, disc_loss = 0.06692914495623292
Trained batch 182 in epoch 19, gen_loss = 0.3970059622180918, disc_loss = 0.06662126632325881
Trained batch 183 in epoch 19, gen_loss = 0.3967508014453494, disc_loss = 0.06639584082776033
Trained batch 184 in epoch 19, gen_loss = 0.39619216790070405, disc_loss = 0.06673126029152725
Trained batch 185 in epoch 19, gen_loss = 0.3964149016205982, disc_loss = 0.06763462363542007
Trained batch 186 in epoch 19, gen_loss = 0.396467460827394, disc_loss = 0.06738738612804741
Trained batch 187 in epoch 19, gen_loss = 0.39663096231983064, disc_loss = 0.06718512702525217
Trained batch 188 in epoch 19, gen_loss = 0.3964585166759592, disc_loss = 0.0669445561900459
Trained batch 189 in epoch 19, gen_loss = 0.39647051707694403, disc_loss = 0.0666871020349821
Trained batch 190 in epoch 19, gen_loss = 0.3960986667902682, disc_loss = 0.06649065782018591
Trained batch 191 in epoch 19, gen_loss = 0.3960315544779102, disc_loss = 0.06635037968468775
Trained batch 192 in epoch 19, gen_loss = 0.3962102106198128, disc_loss = 0.06610786475463158
Trained batch 193 in epoch 19, gen_loss = 0.39615692397982805, disc_loss = 0.06586077708280501
Trained batch 194 in epoch 19, gen_loss = 0.3961117203419025, disc_loss = 0.06568510836849992
Trained batch 195 in epoch 19, gen_loss = 0.39589136747681364, disc_loss = 0.06544879659278584
Trained batch 196 in epoch 19, gen_loss = 0.39577142024403295, disc_loss = 0.06518875216346631
Trained batch 197 in epoch 19, gen_loss = 0.39545338623451465, disc_loss = 0.06503674531628312
Trained batch 198 in epoch 19, gen_loss = 0.3953916726998947, disc_loss = 0.06487569662896757
Trained batch 199 in epoch 19, gen_loss = 0.39617154508829117, disc_loss = 0.06465816369978711
Trained batch 200 in epoch 19, gen_loss = 0.3958780612815079, disc_loss = 0.06487817353156594
Trained batch 201 in epoch 19, gen_loss = 0.3960842500523766, disc_loss = 0.06600397584342056
Trained batch 202 in epoch 19, gen_loss = 0.39613340273866515, disc_loss = 0.06597366371866444
Trained batch 203 in epoch 19, gen_loss = 0.39599693595778707, disc_loss = 0.06571783870686869
Trained batch 204 in epoch 19, gen_loss = 0.3957355366974342, disc_loss = 0.06577458022071457
Trained batch 205 in epoch 19, gen_loss = 0.39594736651888174, disc_loss = 0.06565578842707412
Trained batch 206 in epoch 19, gen_loss = 0.39611593695078495, disc_loss = 0.0653824105269415
Trained batch 207 in epoch 19, gen_loss = 0.39593524328218055, disc_loss = 0.06514534264883529
Trained batch 208 in epoch 19, gen_loss = 0.39596117783391305, disc_loss = 0.06502348915606951
Trained batch 209 in epoch 19, gen_loss = 0.3961496087766829, disc_loss = 0.06495973077780079
Trained batch 210 in epoch 19, gen_loss = 0.39587629971346017, disc_loss = 0.06497065716100883
Trained batch 211 in epoch 19, gen_loss = 0.39623443501175576, disc_loss = 0.06511020994490399
Trained batch 212 in epoch 19, gen_loss = 0.3964968981317511, disc_loss = 0.06498301993102325
Trained batch 213 in epoch 19, gen_loss = 0.39657700451735023, disc_loss = 0.06477611710613367
Trained batch 214 in epoch 19, gen_loss = 0.3966022734032121, disc_loss = 0.06474751168428812
Trained batch 215 in epoch 19, gen_loss = 0.39684415981173515, disc_loss = 0.06503551808849874
Trained batch 216 in epoch 19, gen_loss = 0.39675976136862406, disc_loss = 0.06491670148309818
Trained batch 217 in epoch 19, gen_loss = 0.39671688314971576, disc_loss = 0.06473371754998529
Trained batch 218 in epoch 19, gen_loss = 0.39729859812618934, disc_loss = 0.06453024505182556
Trained batch 219 in epoch 19, gen_loss = 0.39741046076471154, disc_loss = 0.06429142806975341
Trained batch 220 in epoch 19, gen_loss = 0.39714833325390364, disc_loss = 0.06406318836495685
Trained batch 221 in epoch 19, gen_loss = 0.39740038589314297, disc_loss = 0.06389015762194118
Trained batch 222 in epoch 19, gen_loss = 0.3976391083456476, disc_loss = 0.06372421032920346
Trained batch 223 in epoch 19, gen_loss = 0.3982603172106402, disc_loss = 0.06346694038074929
Trained batch 224 in epoch 19, gen_loss = 0.398467710547977, disc_loss = 0.063424862364514
Trained batch 225 in epoch 19, gen_loss = 0.3985647516967976, disc_loss = 0.06449549230417254
Trained batch 226 in epoch 19, gen_loss = 0.3985259655026087, disc_loss = 0.06532458508682605
Trained batch 227 in epoch 19, gen_loss = 0.3985138140749513, disc_loss = 0.06573694343719501
Trained batch 228 in epoch 19, gen_loss = 0.3987200340849864, disc_loss = 0.06601603290749364
Trained batch 229 in epoch 19, gen_loss = 0.39897023685600447, disc_loss = 0.06598880388773978
Trained batch 230 in epoch 19, gen_loss = 0.3988655757852447, disc_loss = 0.06598027580058871
Trained batch 231 in epoch 19, gen_loss = 0.3991031066097062, disc_loss = 0.06576820286914128
Trained batch 232 in epoch 19, gen_loss = 0.3989695435941475, disc_loss = 0.06563569546793088
Trained batch 233 in epoch 19, gen_loss = 0.39897072608144873, disc_loss = 0.06541289244062053
Trained batch 234 in epoch 19, gen_loss = 0.3992612489994536, disc_loss = 0.06517385466103541
Trained batch 235 in epoch 19, gen_loss = 0.3988481729717578, disc_loss = 0.06526560999129473
Trained batch 236 in epoch 19, gen_loss = 0.3990381986280031, disc_loss = 0.06565676956292132
Trained batch 237 in epoch 19, gen_loss = 0.3990686130122978, disc_loss = 0.06551394606705661
Trained batch 238 in epoch 19, gen_loss = 0.3990912441179842, disc_loss = 0.06553178353655974
Trained batch 239 in epoch 19, gen_loss = 0.39927558513979117, disc_loss = 0.06543265942600555
Trained batch 240 in epoch 19, gen_loss = 0.39934839982214804, disc_loss = 0.06523122918826849
Trained batch 241 in epoch 19, gen_loss = 0.39899504751213327, disc_loss = 0.06516546685795092
Trained batch 242 in epoch 19, gen_loss = 0.3991795373551639, disc_loss = 0.06494171246541319
Trained batch 243 in epoch 19, gen_loss = 0.39921646467486366, disc_loss = 0.06475379750644025
Trained batch 244 in epoch 19, gen_loss = 0.39921690931125564, disc_loss = 0.0646771543241125
Trained batch 245 in epoch 19, gen_loss = 0.3987537782366683, disc_loss = 0.06457007416463419
Trained batch 246 in epoch 19, gen_loss = 0.39885539419737903, disc_loss = 0.0644928354087478
Trained batch 247 in epoch 19, gen_loss = 0.39861076541485324, disc_loss = 0.06456292212392474
Trained batch 248 in epoch 19, gen_loss = 0.39873970057590896, disc_loss = 0.0644129888625838
Trained batch 249 in epoch 19, gen_loss = 0.39865005350112914, disc_loss = 0.06532326596044004
Trained batch 250 in epoch 19, gen_loss = 0.3984258133339217, disc_loss = 0.06693250171476567
Trained batch 251 in epoch 19, gen_loss = 0.3979463865832677, disc_loss = 0.067062648270087
Trained batch 252 in epoch 19, gen_loss = 0.39824167412260303, disc_loss = 0.067882936217789
Trained batch 253 in epoch 19, gen_loss = 0.3985519066570312, disc_loss = 0.06788641735581373
Trained batch 254 in epoch 19, gen_loss = 0.39843294258211176, disc_loss = 0.06791493383364058
Trained batch 255 in epoch 19, gen_loss = 0.3981343529885635, disc_loss = 0.06819619656562281
Trained batch 256 in epoch 19, gen_loss = 0.39797435718287755, disc_loss = 0.06820515693067519
Trained batch 257 in epoch 19, gen_loss = 0.3982678008402965, disc_loss = 0.06837358209304512
Trained batch 258 in epoch 19, gen_loss = 0.3983168240679737, disc_loss = 0.0682961887457052
Trained batch 259 in epoch 19, gen_loss = 0.3984036253048823, disc_loss = 0.06813735955287344
Trained batch 260 in epoch 19, gen_loss = 0.39851309547479125, disc_loss = 0.0679314848859848
Trained batch 261 in epoch 19, gen_loss = 0.3984184127500039, disc_loss = 0.06775863027690647
Trained batch 262 in epoch 19, gen_loss = 0.3983510959284387, disc_loss = 0.06766906597194733
Trained batch 263 in epoch 19, gen_loss = 0.3984243895745639, disc_loss = 0.06762915513668717
Trained batch 264 in epoch 19, gen_loss = 0.3982400119304657, disc_loss = 0.06752617858033978
Trained batch 265 in epoch 19, gen_loss = 0.39799254796558753, disc_loss = 0.06742950165959397
Trained batch 266 in epoch 19, gen_loss = 0.3979580860012926, disc_loss = 0.06725040037526787
Trained batch 267 in epoch 19, gen_loss = 0.3979418511266139, disc_loss = 0.06733494547869899
Trained batch 268 in epoch 19, gen_loss = 0.39746614481879877, disc_loss = 0.06859294594989113
Trained batch 269 in epoch 19, gen_loss = 0.39761123690340255, disc_loss = 0.068454874360382
Trained batch 270 in epoch 19, gen_loss = 0.3977878253178403, disc_loss = 0.06848993693818631
Trained batch 271 in epoch 19, gen_loss = 0.3979753770810716, disc_loss = 0.06834292973850525
Trained batch 272 in epoch 19, gen_loss = 0.39775548498709123, disc_loss = 0.06828912715137606
Trained batch 273 in epoch 19, gen_loss = 0.39782099045106095, disc_loss = 0.06816642606855254
Trained batch 274 in epoch 19, gen_loss = 0.3976782583106648, disc_loss = 0.06808468954637646
Trained batch 275 in epoch 19, gen_loss = 0.3974607430290485, disc_loss = 0.06796025546044922
Trained batch 276 in epoch 19, gen_loss = 0.3976046484945483, disc_loss = 0.06779304246791379
Trained batch 277 in epoch 19, gen_loss = 0.3977088152075843, disc_loss = 0.06758791524682381
Trained batch 278 in epoch 19, gen_loss = 0.39788857796713445, disc_loss = 0.06736804515383737
Trained batch 279 in epoch 19, gen_loss = 0.39806663979377066, disc_loss = 0.06720042446727997
Trained batch 280 in epoch 19, gen_loss = 0.3980366675667067, disc_loss = 0.06706482401197227
Trained batch 281 in epoch 19, gen_loss = 0.3979254863786359, disc_loss = 0.06697270131326472
Trained batch 282 in epoch 19, gen_loss = 0.3978868342751749, disc_loss = 0.06695944199654481
Trained batch 283 in epoch 19, gen_loss = 0.39789843391364726, disc_loss = 0.06683368696732787
Trained batch 284 in epoch 19, gen_loss = 0.3980153717492756, disc_loss = 0.06661946635137786
Trained batch 285 in epoch 19, gen_loss = 0.39791538415255245, disc_loss = 0.06646410908087619
Trained batch 286 in epoch 19, gen_loss = 0.397908418851447, disc_loss = 0.06626371626063973
Trained batch 287 in epoch 19, gen_loss = 0.39808967481884694, disc_loss = 0.0662259826931404
Trained batch 288 in epoch 19, gen_loss = 0.397803952330949, disc_loss = 0.06632711048234757
Trained batch 289 in epoch 19, gen_loss = 0.39786504424851515, disc_loss = 0.06615074169822037
Trained batch 290 in epoch 19, gen_loss = 0.39793420677742186, disc_loss = 0.06603226331430663
Trained batch 291 in epoch 19, gen_loss = 0.39769783330290287, disc_loss = 0.06588695065137509
Trained batch 292 in epoch 19, gen_loss = 0.3976007003222716, disc_loss = 0.06572206443773246
Trained batch 293 in epoch 19, gen_loss = 0.39763569020900597, disc_loss = 0.06554854122231252
Trained batch 294 in epoch 19, gen_loss = 0.39798793671494825, disc_loss = 0.06541723776450854
Trained batch 295 in epoch 19, gen_loss = 0.39786481394155604, disc_loss = 0.06554115944497942
Trained batch 296 in epoch 19, gen_loss = 0.39813395070307184, disc_loss = 0.06588014175877076
Trained batch 297 in epoch 19, gen_loss = 0.3983727192518695, disc_loss = 0.06572161451913416
Trained batch 298 in epoch 19, gen_loss = 0.39815413443539854, disc_loss = 0.06577181145330785
Trained batch 299 in epoch 19, gen_loss = 0.3985881361365318, disc_loss = 0.06563761253686001
Trained batch 300 in epoch 19, gen_loss = 0.39886559333120075, disc_loss = 0.06574767079990221
Trained batch 301 in epoch 19, gen_loss = 0.3988275462823198, disc_loss = 0.06636526938435307
Trained batch 302 in epoch 19, gen_loss = 0.3987956783755778, disc_loss = 0.06626208285914839
Trained batch 303 in epoch 19, gen_loss = 0.3988052890881112, disc_loss = 0.06612598330033698
Trained batch 304 in epoch 19, gen_loss = 0.39866614761899727, disc_loss = 0.0659957118408724
Trained batch 305 in epoch 19, gen_loss = 0.39862997401383965, disc_loss = 0.06593312815690011
Trained batch 306 in epoch 19, gen_loss = 0.3990025303845297, disc_loss = 0.06589165631627075
Trained batch 307 in epoch 19, gen_loss = 0.3991115614771843, disc_loss = 0.06582741906969239
Trained batch 308 in epoch 19, gen_loss = 0.3990207634697454, disc_loss = 0.0657964561897116
Trained batch 309 in epoch 19, gen_loss = 0.39937517700656766, disc_loss = 0.06586892049188815
Trained batch 310 in epoch 19, gen_loss = 0.39920479845004064, disc_loss = 0.06574889535527569
Trained batch 311 in epoch 19, gen_loss = 0.3991457215295388, disc_loss = 0.06559771419508764
Trained batch 312 in epoch 19, gen_loss = 0.3992753553504761, disc_loss = 0.06549803606314829
Trained batch 313 in epoch 19, gen_loss = 0.39930279818689746, disc_loss = 0.06539212959332119
Trained batch 314 in epoch 19, gen_loss = 0.3992930689501384, disc_loss = 0.06520227786774437
Trained batch 315 in epoch 19, gen_loss = 0.3996041278484501, disc_loss = 0.06510703603271395
Trained batch 316 in epoch 19, gen_loss = 0.39944889690221674, disc_loss = 0.06499877507278361
Trained batch 317 in epoch 19, gen_loss = 0.39929928654019936, disc_loss = 0.06498460097783157
Trained batch 318 in epoch 19, gen_loss = 0.39963172810578423, disc_loss = 0.06480739336186395
Trained batch 319 in epoch 19, gen_loss = 0.3996420589275658, disc_loss = 0.06527799040050013
Trained batch 320 in epoch 19, gen_loss = 0.3996274284670286, disc_loss = 0.06586925047551313
Trained batch 321 in epoch 19, gen_loss = 0.39967732298078, disc_loss = 0.06586316362549753
Trained batch 322 in epoch 19, gen_loss = 0.39954341426722406, disc_loss = 0.06578083668947912
Trained batch 323 in epoch 19, gen_loss = 0.3995290875066946, disc_loss = 0.06563734112991548
Trained batch 324 in epoch 19, gen_loss = 0.399471301482274, disc_loss = 0.0654937990855139
Trained batch 325 in epoch 19, gen_loss = 0.3996267499733556, disc_loss = 0.06533611990494277
Trained batch 326 in epoch 19, gen_loss = 0.3994624745043775, disc_loss = 0.06527770460591814
Trained batch 327 in epoch 19, gen_loss = 0.3994747422998998, disc_loss = 0.06521539535038401
Trained batch 328 in epoch 19, gen_loss = 0.39968079029607917, disc_loss = 0.06508871012347493
Trained batch 329 in epoch 19, gen_loss = 0.3997693507057248, disc_loss = 0.06528911835118903
Trained batch 330 in epoch 19, gen_loss = 0.4000074392539137, disc_loss = 0.06555682286378164
Trained batch 331 in epoch 19, gen_loss = 0.4000228019543441, disc_loss = 0.06552003850986485
Trained batch 332 in epoch 19, gen_loss = 0.3998914003014207, disc_loss = 0.06548126220462604
Trained batch 333 in epoch 19, gen_loss = 0.40002622040445934, disc_loss = 0.0655629984144969
Trained batch 334 in epoch 19, gen_loss = 0.39988374576639774, disc_loss = 0.06544014521415777
Trained batch 335 in epoch 19, gen_loss = 0.39991280117205213, disc_loss = 0.06529959683844243
Trained batch 336 in epoch 19, gen_loss = 0.39941971503662427, disc_loss = 0.06518559937865559
Trained batch 337 in epoch 19, gen_loss = 0.399662461594717, disc_loss = 0.06511130003870283
Trained batch 338 in epoch 19, gen_loss = 0.3994838419565409, disc_loss = 0.06521607828422678
Trained batch 339 in epoch 19, gen_loss = 0.39952872299096165, disc_loss = 0.0653686002622742
Trained batch 340 in epoch 19, gen_loss = 0.3996522626743988, disc_loss = 0.06531226770034677
Trained batch 341 in epoch 19, gen_loss = 0.39947749107901814, disc_loss = 0.06521446446953505
Trained batch 342 in epoch 19, gen_loss = 0.3995168883320889, disc_loss = 0.06508223975957005
Trained batch 343 in epoch 19, gen_loss = 0.3995464808026025, disc_loss = 0.06494030701456764
Trained batch 344 in epoch 19, gen_loss = 0.3995444240777389, disc_loss = 0.06481859626356458
Trained batch 345 in epoch 19, gen_loss = 0.39937226646552887, disc_loss = 0.06474346604677338
Trained batch 346 in epoch 19, gen_loss = 0.39951167781689667, disc_loss = 0.06460530177880648
Trained batch 347 in epoch 19, gen_loss = 0.3992949552063284, disc_loss = 0.06483998417388648
Trained batch 348 in epoch 19, gen_loss = 0.39951463893354794, disc_loss = 0.06510241558230923
Trained batch 349 in epoch 19, gen_loss = 0.39979045493262155, disc_loss = 0.06503593581196453
Trained batch 350 in epoch 19, gen_loss = 0.3997795671818942, disc_loss = 0.06501273917129789
Trained batch 351 in epoch 19, gen_loss = 0.3998787003484639, disc_loss = 0.06488785300726621
Trained batch 352 in epoch 19, gen_loss = 0.39994285177576644, disc_loss = 0.06472936287527592
Trained batch 353 in epoch 19, gen_loss = 0.39986776674197894, disc_loss = 0.06458406017614413
Trained batch 354 in epoch 19, gen_loss = 0.3997456887238462, disc_loss = 0.06453604756815123
Trained batch 355 in epoch 19, gen_loss = 0.399753033110265, disc_loss = 0.06452374886381283
Trained batch 356 in epoch 19, gen_loss = 0.39988453940851015, disc_loss = 0.06437334777129923
Trained batch 357 in epoch 19, gen_loss = 0.3996871705661273, disc_loss = 0.06427528181987394
Trained batch 358 in epoch 19, gen_loss = 0.39976633375401616, disc_loss = 0.06413429362107909
Trained batch 359 in epoch 19, gen_loss = 0.3997524858348899, disc_loss = 0.06400804585751353
Trained batch 360 in epoch 19, gen_loss = 0.3998512823000509, disc_loss = 0.06388552823694747
Trained batch 361 in epoch 19, gen_loss = 0.3998087872622421, disc_loss = 0.06377586413519612
Trained batch 362 in epoch 19, gen_loss = 0.400187568969963, disc_loss = 0.0637652224773854
Trained batch 363 in epoch 19, gen_loss = 0.4000848372067724, disc_loss = 0.06407875340344937
Trained batch 364 in epoch 19, gen_loss = 0.4003673260342585, disc_loss = 0.06403964840462559
Trained batch 365 in epoch 19, gen_loss = 0.4004809267696787, disc_loss = 0.06398017911998749
Trained batch 366 in epoch 19, gen_loss = 0.4005452934500307, disc_loss = 0.06382966024689478
Trained batch 367 in epoch 19, gen_loss = 0.4005868228395348, disc_loss = 0.06372298220673617
Trained batch 368 in epoch 19, gen_loss = 0.40070370647319287, disc_loss = 0.06358618328983827
Trained batch 369 in epoch 19, gen_loss = 0.400711098152238, disc_loss = 0.06344095434917993
Trained batch 370 in epoch 19, gen_loss = 0.40063059024733677, disc_loss = 0.06330077924371529
Trained batch 371 in epoch 19, gen_loss = 0.40044744280717703, disc_loss = 0.0631888199344738
Trained batch 372 in epoch 19, gen_loss = 0.40043385906129997, disc_loss = 0.0630766060041019
Trained batch 373 in epoch 19, gen_loss = 0.40046192139865244, disc_loss = 0.06297777725488227
Trained batch 374 in epoch 19, gen_loss = 0.4003818562030792, disc_loss = 0.06284957444791993
Trained batch 375 in epoch 19, gen_loss = 0.400340264385685, disc_loss = 0.06270154683721905
Trained batch 376 in epoch 19, gen_loss = 0.4002448490348988, disc_loss = 0.06259503636746334
Trained batch 377 in epoch 19, gen_loss = 0.4003543836414499, disc_loss = 0.06246737668921471
Trained batch 378 in epoch 19, gen_loss = 0.4003246510720819, disc_loss = 0.06236236857245418
Trained batch 379 in epoch 19, gen_loss = 0.4004838701141508, disc_loss = 0.06250483511554959
Trained batch 380 in epoch 19, gen_loss = 0.40022201229893944, disc_loss = 0.06354922987276253
Trained batch 381 in epoch 19, gen_loss = 0.400543562638822, disc_loss = 0.06359479268427684
Trained batch 382 in epoch 19, gen_loss = 0.4006128490904915, disc_loss = 0.06355902475034989
Trained batch 383 in epoch 19, gen_loss = 0.40052210617189604, disc_loss = 0.06360479357196407
Trained batch 384 in epoch 19, gen_loss = 0.40040591552660065, disc_loss = 0.06378572686006884
Trained batch 385 in epoch 19, gen_loss = 0.40014183003976556, disc_loss = 0.06424199564170112
Trained batch 386 in epoch 19, gen_loss = 0.40029968502293567, disc_loss = 0.06415240175165332
Trained batch 387 in epoch 19, gen_loss = 0.4003604837914103, disc_loss = 0.06414115073917837
Trained batch 388 in epoch 19, gen_loss = 0.40020907078426726, disc_loss = 0.06403328685429914
Trained batch 389 in epoch 19, gen_loss = 0.40027865095016285, disc_loss = 0.06395443609366432
Trained batch 390 in epoch 19, gen_loss = 0.4001820038651566, disc_loss = 0.06386568366080675
Trained batch 391 in epoch 19, gen_loss = 0.40011035225221087, disc_loss = 0.06381555680157047
Trained batch 392 in epoch 19, gen_loss = 0.4003007364182072, disc_loss = 0.06372239628602909
Trained batch 393 in epoch 19, gen_loss = 0.40044612312679967, disc_loss = 0.06357873252210051
Trained batch 394 in epoch 19, gen_loss = 0.4005343032788627, disc_loss = 0.06346029135858333
Trained batch 395 in epoch 19, gen_loss = 0.40058335195286104, disc_loss = 0.06332858735131043
Trained batch 396 in epoch 19, gen_loss = 0.4006298165627631, disc_loss = 0.06321808256640542
Trained batch 397 in epoch 19, gen_loss = 0.4006888423882537, disc_loss = 0.0631918493265183
Trained batch 398 in epoch 19, gen_loss = 0.40069081288830083, disc_loss = 0.06310674622841646
Trained batch 399 in epoch 19, gen_loss = 0.400792872980237, disc_loss = 0.06303266064263881
Trained batch 400 in epoch 19, gen_loss = 0.4009102761299533, disc_loss = 0.06289555262913579
Trained batch 401 in epoch 19, gen_loss = 0.4008161730285901, disc_loss = 0.06280841606099215
Trained batch 402 in epoch 19, gen_loss = 0.4009863934652977, disc_loss = 0.06267373704538674
Trained batch 403 in epoch 19, gen_loss = 0.40092542310162343, disc_loss = 0.06253816240633109
Trained batch 404 in epoch 19, gen_loss = 0.4008994124553822, disc_loss = 0.06266006236596976
Trained batch 405 in epoch 19, gen_loss = 0.4007337809049437, disc_loss = 0.06297718636058454
Trained batch 406 in epoch 19, gen_loss = 0.4007801298573796, disc_loss = 0.06286787692713723
Trained batch 407 in epoch 19, gen_loss = 0.4009235342781918, disc_loss = 0.06289598076175168
Trained batch 408 in epoch 19, gen_loss = 0.40110536025322446, disc_loss = 0.06277411225454513
Trained batch 409 in epoch 19, gen_loss = 0.4011322428540486, disc_loss = 0.0626584623690422
Trained batch 410 in epoch 19, gen_loss = 0.4009704238886961, disc_loss = 0.06256782411713235
Trained batch 411 in epoch 19, gen_loss = 0.4008739472014233, disc_loss = 0.06249459718525844
Trained batch 412 in epoch 19, gen_loss = 0.4010458532314901, disc_loss = 0.06237507987199193
Trained batch 413 in epoch 19, gen_loss = 0.4011523641537929, disc_loss = 0.06225692856705923
Trained batch 414 in epoch 19, gen_loss = 0.40123649512428833, disc_loss = 0.062131558912974526
Trained batch 415 in epoch 19, gen_loss = 0.4012679253489925, disc_loss = 0.0620133724117365
Trained batch 416 in epoch 19, gen_loss = 0.4011981390791831, disc_loss = 0.062038152579137744
Trained batch 417 in epoch 19, gen_loss = 0.40114372034677476, disc_loss = 0.06214258637118853
Trained batch 418 in epoch 19, gen_loss = 0.40112800394720566, disc_loss = 0.062039364836132045
Trained batch 419 in epoch 19, gen_loss = 0.40128221320254465, disc_loss = 0.0625829531190296
Trained batch 420 in epoch 19, gen_loss = 0.4011925607565746, disc_loss = 0.06256324660271902
Trained batch 421 in epoch 19, gen_loss = 0.4013165565322361, disc_loss = 0.06244198830303917
Trained batch 422 in epoch 19, gen_loss = 0.40153207501339294, disc_loss = 0.062328267554107426
Trained batch 423 in epoch 19, gen_loss = 0.40130364332558977, disc_loss = 0.06225342555015506
Trained batch 424 in epoch 19, gen_loss = 0.40107347824994255, disc_loss = 0.06234353901927962
Trained batch 425 in epoch 19, gen_loss = 0.4009829537829323, disc_loss = 0.062309044647192315
Trained batch 426 in epoch 19, gen_loss = 0.4010097533813405, disc_loss = 0.06219550828063376
Trained batch 427 in epoch 19, gen_loss = 0.4008055245068586, disc_loss = 0.06220061588318688
Trained batch 428 in epoch 19, gen_loss = 0.40080247954888776, disc_loss = 0.062074036131198315
Trained batch 429 in epoch 19, gen_loss = 0.40086332226908483, disc_loss = 0.06200591904912577
Trained batch 430 in epoch 19, gen_loss = 0.4008154831048784, disc_loss = 0.061890263339448415
Trained batch 431 in epoch 19, gen_loss = 0.4008094224802874, disc_loss = 0.0618125954211724
Trained batch 432 in epoch 19, gen_loss = 0.40080040844703657, disc_loss = 0.061769357351177556
Trained batch 433 in epoch 19, gen_loss = 0.4008588925484688, disc_loss = 0.06168340114782208
Trained batch 434 in epoch 19, gen_loss = 0.40062546634125984, disc_loss = 0.06160701444779319
Trained batch 435 in epoch 19, gen_loss = 0.40074957278343515, disc_loss = 0.0615477636541932
Trained batch 436 in epoch 19, gen_loss = 0.40076186298232874, disc_loss = 0.061472319944567755
Trained batch 437 in epoch 19, gen_loss = 0.4007784939928142, disc_loss = 0.061561445301594256
Trained batch 438 in epoch 19, gen_loss = 0.40082647948438865, disc_loss = 0.061480548258251375
Trained batch 439 in epoch 19, gen_loss = 0.40091006031090565, disc_loss = 0.0613802652975375
Trained batch 440 in epoch 19, gen_loss = 0.40104866879326956, disc_loss = 0.06127406064370254
Trained batch 441 in epoch 19, gen_loss = 0.4008479813509937, disc_loss = 0.06132742056909662
Trained batch 442 in epoch 19, gen_loss = 0.40104078963970763, disc_loss = 0.06126125012871307
Trained batch 443 in epoch 19, gen_loss = 0.40102523350500846, disc_loss = 0.061160162370232446
Trained batch 444 in epoch 19, gen_loss = 0.4010693768436989, disc_loss = 0.06105060990313801
Trained batch 445 in epoch 19, gen_loss = 0.40123469252222854, disc_loss = 0.060993542262006366
Trained batch 446 in epoch 19, gen_loss = 0.40108822402804756, disc_loss = 0.061006992432378414
Trained batch 447 in epoch 19, gen_loss = 0.4012190734834543, disc_loss = 0.060919998564973606
Trained batch 448 in epoch 19, gen_loss = 0.40135013592535246, disc_loss = 0.06081790399669207
Trained batch 449 in epoch 19, gen_loss = 0.4012564569711685, disc_loss = 0.06078246409487393
Trained batch 450 in epoch 19, gen_loss = 0.4012514982545984, disc_loss = 0.06084140251182069
Trained batch 451 in epoch 19, gen_loss = 0.4014794175735617, disc_loss = 0.06088234439483984
Trained batch 452 in epoch 19, gen_loss = 0.4016682462187003, disc_loss = 0.06076859960139258
Trained batch 453 in epoch 19, gen_loss = 0.40154846307989783, disc_loss = 0.06068860476278589
Trained batch 454 in epoch 19, gen_loss = 0.4016712621018127, disc_loss = 0.06061961220393142
Trained batch 455 in epoch 19, gen_loss = 0.4017671553189294, disc_loss = 0.06051933595485855
Trained batch 456 in epoch 19, gen_loss = 0.40167477589989126, disc_loss = 0.06040106179840716
Trained batch 457 in epoch 19, gen_loss = 0.40166793138960044, disc_loss = 0.060302682143664514
Trained batch 458 in epoch 19, gen_loss = 0.401651247264513, disc_loss = 0.060197570420038725
Trained batch 459 in epoch 19, gen_loss = 0.4017704138289327, disc_loss = 0.06008795041024037
Trained batch 460 in epoch 19, gen_loss = 0.4018270388213259, disc_loss = 0.06001432275565224
Testing Epoch 19
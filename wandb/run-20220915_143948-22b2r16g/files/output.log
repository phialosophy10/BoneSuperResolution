/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 2.7496285438537598, disc_loss = 0.6839773058891296
Trained batch 1 in epoch 0, gen_loss = 2.887171745300293, disc_loss = 0.9410662949085236
Trained batch 2 in epoch 0, gen_loss = 2.729827642440796, disc_loss = 0.8748032450675964
Trained batch 3 in epoch 0, gen_loss = 2.5774770379066467, disc_loss = 0.7646974548697472
Trained batch 4 in epoch 0, gen_loss = 2.5911679744720457, disc_loss = 0.6939679920673371
Trained batch 5 in epoch 0, gen_loss = 2.5470139185587564, disc_loss = 0.6278058985869089
Trained batch 6 in epoch 0, gen_loss = 2.547985110964094, disc_loss = 0.577545302254813
Trained batch 7 in epoch 0, gen_loss = 2.5121081173419952, disc_loss = 0.5345214158296585
Trained batch 8 in epoch 0, gen_loss = 2.483376635445489, disc_loss = 0.49676745136578876
Trained batch 9 in epoch 0, gen_loss = 2.473874020576477, disc_loss = 0.4636387646198273
Trained batch 10 in epoch 0, gen_loss = 2.47203972122886, disc_loss = 0.4348363456400958
Trained batch 11 in epoch 0, gen_loss = 2.4344780246416726, disc_loss = 0.4099673144519329
Trained batch 12 in epoch 0, gen_loss = 2.418038771702693, disc_loss = 0.386629003744859
Trained batch 13 in epoch 0, gen_loss = 2.405365926878793, disc_loss = 0.3663514900420393
Trained batch 14 in epoch 0, gen_loss = 2.384159517288208, disc_loss = 0.3484055613478025
Trained batch 15 in epoch 0, gen_loss = 2.3645531684160233, disc_loss = 0.3312625722028315
Trained batch 16 in epoch 0, gen_loss = 2.3616066820481243, disc_loss = 0.31655843994196725
Trained batch 17 in epoch 0, gen_loss = 2.3543443414900036, disc_loss = 0.30434520832366413
Trained batch 18 in epoch 0, gen_loss = 2.345683875836824, disc_loss = 0.296526914756549
Trained batch 19 in epoch 0, gen_loss = 2.3508788347244263, disc_loss = 0.2895424958318472
Trained batch 20 in epoch 0, gen_loss = 2.3748386133284796, disc_loss = 0.28338377213194255
Trained batch 21 in epoch 0, gen_loss = 2.369103355841203, disc_loss = 0.27413603561845695
Trained batch 22 in epoch 0, gen_loss = 2.3630646311718486, disc_loss = 0.2648917323221331
Trained batch 23 in epoch 0, gen_loss = 2.3477797706921897, disc_loss = 0.2564912149682641
Trained batch 24 in epoch 0, gen_loss = 2.341297492980957, disc_loss = 0.2480521246790886
Trained batch 25 in epoch 0, gen_loss = 2.3444809088340173, disc_loss = 0.24058204946609643
Trained batch 26 in epoch 0, gen_loss = 2.3603021921934904, disc_loss = 0.23327548443167298
Trained batch 27 in epoch 0, gen_loss = 2.3642350179808482, disc_loss = 0.2262836710682937
Trained batch 28 in epoch 0, gen_loss = 2.370240638995993, disc_loss = 0.2197650283061225
Trained batch 29 in epoch 0, gen_loss = 2.3628765821456907, disc_loss = 0.21363810847202938
Trained batch 30 in epoch 0, gen_loss = 2.3671933758643364, disc_loss = 0.20805965808610763
Trained batch 31 in epoch 0, gen_loss = 2.3710793927311897, disc_loss = 0.20253652636893094
Trained batch 32 in epoch 0, gen_loss = 2.3569806019465127, disc_loss = 0.19745259551387845
Trained batch 33 in epoch 0, gen_loss = 2.357361039694618, disc_loss = 0.19273659345858238
Trained batch 34 in epoch 0, gen_loss = 2.3612047706331527, disc_loss = 0.18820345572062902
Trained batch 35 in epoch 0, gen_loss = 2.357175406482485, disc_loss = 0.18410274583018488
Trained batch 36 in epoch 0, gen_loss = 2.3513860605858468, disc_loss = 0.1799625621454136
Trained batch 37 in epoch 0, gen_loss = 2.3495910387290153, disc_loss = 0.17610722505732587
Trained batch 38 in epoch 0, gen_loss = 2.349421424743457, disc_loss = 0.17233829649213034
Trained batch 39 in epoch 0, gen_loss = 2.350948652625084, disc_loss = 0.1688314407132566
Trained batch 40 in epoch 0, gen_loss = 2.3474653784821675, disc_loss = 0.1654017799329467
Trained batch 41 in epoch 0, gen_loss = 2.3438571208999273, disc_loss = 0.1621504116005131
Trained batch 42 in epoch 0, gen_loss = 2.3418078893838925, disc_loss = 0.15893712977683822
Trained batch 43 in epoch 0, gen_loss = 2.338559635660865, disc_loss = 0.1559053540060466
Trained batch 44 in epoch 0, gen_loss = 2.3270326058069863, disc_loss = 0.15302588020761806
Trained batch 45 in epoch 0, gen_loss = 2.323310849459275, disc_loss = 0.15018202048604903
Trained batch 46 in epoch 0, gen_loss = 2.3255446946367306, disc_loss = 0.1474948597556733
Trained batch 47 in epoch 0, gen_loss = 2.3227950210372605, disc_loss = 0.14500612788833678
Trained batch 48 in epoch 0, gen_loss = 2.3277200849688784, disc_loss = 0.14266101308927245
Trained batch 49 in epoch 0, gen_loss = 2.327330672740936, disc_loss = 0.14024043776094913
Trained batch 50 in epoch 0, gen_loss = 2.3277404191447237, disc_loss = 0.13791674642147972
Trained batch 51 in epoch 0, gen_loss = 2.316984630548037, disc_loss = 0.13596107291344267
Trained batch 52 in epoch 0, gen_loss = 2.3135576832969234, disc_loss = 0.13382102144917227
Trained batch 53 in epoch 0, gen_loss = 2.314473593676532, disc_loss = 0.13173474599089888
Trained batch 54 in epoch 0, gen_loss = 2.31008243560791, disc_loss = 0.12971405701881106
Trained batch 55 in epoch 0, gen_loss = 2.3119581043720245, disc_loss = 0.12777900898696057
Trained batch 56 in epoch 0, gen_loss = 2.3079445403918886, disc_loss = 0.12590979552713402
Trained batch 57 in epoch 0, gen_loss = 2.304305882289492, disc_loss = 0.12412971296700938
Trained batch 58 in epoch 0, gen_loss = 2.3019094224703514, disc_loss = 0.12230332378866308
Trained batch 59 in epoch 0, gen_loss = 2.296046390136083, disc_loss = 0.12053238715355595
Trained batch 60 in epoch 0, gen_loss = 2.2968999225585187, disc_loss = 0.11882599256932735
Trained batch 61 in epoch 0, gen_loss = 2.2923867875529873, disc_loss = 0.11720495115244581
Trained batch 62 in epoch 0, gen_loss = 2.294595027726794, disc_loss = 0.11565748404061037
Trained batch 63 in epoch 0, gen_loss = 2.3017359357327223, disc_loss = 0.11425007408251986
Trained batch 64 in epoch 0, gen_loss = 2.2979384917479293, disc_loss = 0.11307161559279148
Trained batch 65 in epoch 0, gen_loss = 2.2969096411358225, disc_loss = 0.11198738505217162
Trained batch 66 in epoch 0, gen_loss = 2.293428550905256, disc_loss = 0.11067755870632272
Trained batch 67 in epoch 0, gen_loss = 2.288765076328726, disc_loss = 0.10928268155411762
Trained batch 68 in epoch 0, gen_loss = 2.2841655793397324, disc_loss = 0.10798213566127031
Trained batch 69 in epoch 0, gen_loss = 2.2785308463232856, disc_loss = 0.10675168513719524
Trained batch 70 in epoch 0, gen_loss = 2.2808873787732193, disc_loss = 0.10545731712342568
Trained batch 71 in epoch 0, gen_loss = 2.2759710119830237, disc_loss = 0.10422441506913553
Trained batch 72 in epoch 0, gen_loss = 2.2766740909994465, disc_loss = 0.1029864408024778
Trained batch 73 in epoch 0, gen_loss = 2.27602164487581, disc_loss = 0.10174485746569731
Trained batch 74 in epoch 0, gen_loss = 2.277482255299886, disc_loss = 0.10052808030198018
Trained batch 75 in epoch 0, gen_loss = 2.2769274366529366, disc_loss = 0.09935650301754083
Trained batch 76 in epoch 0, gen_loss = 2.2771674379125817, disc_loss = 0.09821642101923754
Trained batch 77 in epoch 0, gen_loss = 2.2774946567339773, disc_loss = 0.09709301106154154
Trained batch 78 in epoch 0, gen_loss = 2.2744889078260977, disc_loss = 0.09601182492945014
Trained batch 79 in epoch 0, gen_loss = 2.2721206694841385, disc_loss = 0.0949507457902655
Trained batch 80 in epoch 0, gen_loss = 2.269743142304597, disc_loss = 0.09392695859028602
Trained batch 81 in epoch 0, gen_loss = 2.273083201268824, disc_loss = 0.09293555667078714
Trained batch 82 in epoch 0, gen_loss = 2.271679094038814, disc_loss = 0.09193622243467224
Trained batch 83 in epoch 0, gen_loss = 2.2650555627686635, disc_loss = 0.0909667781199373
Trained batch 84 in epoch 0, gen_loss = 2.2623432524064007, disc_loss = 0.09003116336158093
Trained batch 85 in epoch 0, gen_loss = 2.2631268445835557, disc_loss = 0.08909724691752778
Trained batch 86 in epoch 0, gen_loss = 2.259773703827255, disc_loss = 0.08821000252989517
Trained batch 87 in epoch 0, gen_loss = 2.256618170575662, disc_loss = 0.08729428103172475
Trained batch 88 in epoch 0, gen_loss = 2.2525876505991045, disc_loss = 0.086443571117445
Trained batch 89 in epoch 0, gen_loss = 2.248621173699697, disc_loss = 0.08561046107465195
Trained batch 90 in epoch 0, gen_loss = 2.2476948499679565, disc_loss = 0.08477285610266276
Trained batch 91 in epoch 0, gen_loss = 2.247627466917038, disc_loss = 0.08394528199088476
Trained batch 92 in epoch 0, gen_loss = 2.250464081764221, disc_loss = 0.08315402548259465
Trained batch 93 in epoch 0, gen_loss = 2.2532308444063713, disc_loss = 0.08237158808797757
Trained batch 94 in epoch 0, gen_loss = 2.2503932739558974, disc_loss = 0.08165241469580092
Trained batch 95 in epoch 0, gen_loss = 2.249716456979513, disc_loss = 0.08090611875619895
Trained batch 96 in epoch 0, gen_loss = 2.246568049352194, disc_loss = 0.08017447176533415
Trained batch 97 in epoch 0, gen_loss = 2.2457840381836403, disc_loss = 0.07944524787575463
Trained batch 98 in epoch 0, gen_loss = 2.246576611441795, disc_loss = 0.07874586274659243
Trained batch 99 in epoch 0, gen_loss = 2.2483582818508148, disc_loss = 0.07803983465302736
Trained batch 100 in epoch 0, gen_loss = 2.241582195357521, disc_loss = 0.07736067592378447
Trained batch 101 in epoch 0, gen_loss = 2.2422223652110382, disc_loss = 0.07669489822971325
Trained batch 102 in epoch 0, gen_loss = 2.2434991007869685, disc_loss = 0.07602775717624327
Trained batch 103 in epoch 0, gen_loss = 2.2412831760369816, disc_loss = 0.07536415339787848
Trained batch 104 in epoch 0, gen_loss = 2.241660824276152, disc_loss = 0.07471034029676091
Trained batch 105 in epoch 0, gen_loss = 2.237877201359227, disc_loss = 0.07412199419044521
Trained batch 106 in epoch 0, gen_loss = 2.2378850595973363, disc_loss = 0.0735341604999223
Trained batch 107 in epoch 0, gen_loss = 2.2337520586119757, disc_loss = 0.07293817054704521
Trained batch 108 in epoch 0, gen_loss = 2.234569757356556, disc_loss = 0.07236998756800633
Trained batch 109 in epoch 0, gen_loss = 2.231819140911102, disc_loss = 0.0717973501463844
Trained batch 110 in epoch 0, gen_loss = 2.2310069949777276, disc_loss = 0.07126028811861132
Trained batch 111 in epoch 0, gen_loss = 2.234016651553767, disc_loss = 0.07072344263932402
Trained batch 112 in epoch 0, gen_loss = 2.2307090695980376, disc_loss = 0.07018547672036607
Trained batch 113 in epoch 0, gen_loss = 2.2284359325442398, disc_loss = 0.06965198258771316
Trained batch 114 in epoch 0, gen_loss = 2.2300179958343507, disc_loss = 0.06913592472429508
Trained batch 115 in epoch 0, gen_loss = 2.2309526862769293, disc_loss = 0.06861456843687157
Trained batch 116 in epoch 0, gen_loss = 2.2284004993927784, disc_loss = 0.06810996538569403
Trained batch 117 in epoch 0, gen_loss = 2.226608460232363, disc_loss = 0.06760513472718076
Trained batch 118 in epoch 0, gen_loss = 2.2251095611508154, disc_loss = 0.06711258149525824
Trained batch 119 in epoch 0, gen_loss = 2.221303503712018, disc_loss = 0.06662798847925538
Trained batch 120 in epoch 0, gen_loss = 2.220767321665425, disc_loss = 0.0661541106725835
Trained batch 121 in epoch 0, gen_loss = 2.2201170227566704, disc_loss = 0.06566286853468808
Trained batch 122 in epoch 0, gen_loss = 2.221750985316145, disc_loss = 0.06518345612017967
Trained batch 123 in epoch 0, gen_loss = 2.220753905273253, disc_loss = 0.0647224590234879
Trained batch 124 in epoch 0, gen_loss = 2.2210315828323366, disc_loss = 0.06426701744273305
Trained batch 125 in epoch 0, gen_loss = 2.2210137134506587, disc_loss = 0.06380057265050709
Trained batch 126 in epoch 0, gen_loss = 2.2193097908665815, disc_loss = 0.06333426789079946
Trained batch 127 in epoch 0, gen_loss = 2.2202498177066445, disc_loss = 0.06288114966082503
Trained batch 128 in epoch 0, gen_loss = 2.2191785333692566, disc_loss = 0.062443715444397786
Trained batch 129 in epoch 0, gen_loss = 2.2175860414138207, disc_loss = 0.06200709635606752
Trained batch 130 in epoch 0, gen_loss = 2.2173162098149306, disc_loss = 0.06158020528289312
Trained batch 131 in epoch 0, gen_loss = 2.215361337770115, disc_loss = 0.06116891324618888
Trained batch 132 in epoch 0, gen_loss = 2.218277491124949, disc_loss = 0.06076888022664234
Trained batch 133 in epoch 0, gen_loss = 2.2169926068676054, disc_loss = 0.06040002333014203
Trained batch 134 in epoch 0, gen_loss = 2.216824890949108, disc_loss = 0.060024024791049735
Trained batch 135 in epoch 0, gen_loss = 2.2169092341380963, disc_loss = 0.05962629315977478
Trained batch 136 in epoch 0, gen_loss = 2.215781964524819, disc_loss = 0.05923094234368118
Trained batch 137 in epoch 0, gen_loss = 2.2147677247075066, disc_loss = 0.0588507499323105
Trained batch 138 in epoch 0, gen_loss = 2.212990787389467, disc_loss = 0.05847717845383629
Trained batch 139 in epoch 0, gen_loss = 2.2135350525379183, disc_loss = 0.05810130753088742
Trained batch 140 in epoch 0, gen_loss = 2.2140899254075177, disc_loss = 0.05772034248257888
Trained batch 141 in epoch 0, gen_loss = 2.211565183082097, disc_loss = 0.05734840552912841
Trained batch 142 in epoch 0, gen_loss = 2.212032635728796, disc_loss = 0.05699351089973967
Trained batch 143 in epoch 0, gen_loss = 2.212191781236066, disc_loss = 0.056645323606466666
Trained batch 144 in epoch 0, gen_loss = 2.212192172839724, disc_loss = 0.05629264981774934
Trained batch 145 in epoch 0, gen_loss = 2.213715524706122, disc_loss = 0.05594441864307817
Trained batch 146 in epoch 0, gen_loss = 2.212630425180708, disc_loss = 0.055610567961699095
Trained batch 147 in epoch 0, gen_loss = 2.211321974928315, disc_loss = 0.055280238588189555
Trained batch 148 in epoch 0, gen_loss = 2.208508874745977, disc_loss = 0.05495079686465179
Trained batch 149 in epoch 0, gen_loss = 2.208984911441803, disc_loss = 0.054631160122031966
Trained batch 150 in epoch 0, gen_loss = 2.2077310345820242, disc_loss = 0.05429815080337572
Trained batch 151 in epoch 0, gen_loss = 2.2058620727375935, disc_loss = 0.053971610632479974
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.2529215812683105, disc_loss = 0.0055664535611867905
Trained batch 1 in epoch 1, gen_loss = 2.1638481616973877, disc_loss = 0.00570713821798563
Trained batch 2 in epoch 1, gen_loss = 2.1488351821899414, disc_loss = 0.0060969361414511996
Trained batch 3 in epoch 1, gen_loss = 2.1282761096954346, disc_loss = 0.006374327233061194
Trained batch 4 in epoch 1, gen_loss = 2.138210582733154, disc_loss = 0.0064932102337479595
Trained batch 5 in epoch 1, gen_loss = 2.1324446201324463, disc_loss = 0.006675538451721271
Trained batch 6 in epoch 1, gen_loss = 2.14792605808803, disc_loss = 0.00705524959734508
Trained batch 7 in epoch 1, gen_loss = 2.1370070576667786, disc_loss = 0.007508918177336454
Trained batch 8 in epoch 1, gen_loss = 2.1693693002065024, disc_loss = 0.007470193474243085
Trained batch 9 in epoch 1, gen_loss = 2.1440229415893555, disc_loss = 0.007147312862798572
Trained batch 10 in epoch 1, gen_loss = 2.1962490515275435, disc_loss = 0.00687353846363046
Trained batch 11 in epoch 1, gen_loss = 2.184408187866211, disc_loss = 0.006693551627298196
Trained batch 12 in epoch 1, gen_loss = 2.1793986834012546, disc_loss = 0.006511308575192323
Trained batch 13 in epoch 1, gen_loss = 2.1801680667059764, disc_loss = 0.00639645366131195
Trained batch 14 in epoch 1, gen_loss = 2.1763439496358234, disc_loss = 0.006277246400713921
Trained batch 15 in epoch 1, gen_loss = 2.173203855752945, disc_loss = 0.006132555747171864
Trained batch 16 in epoch 1, gen_loss = 2.1674039784599755, disc_loss = 0.005974011632668621
Trained batch 17 in epoch 1, gen_loss = 2.189235713746813, disc_loss = 0.00585470265812344
Trained batch 18 in epoch 1, gen_loss = 2.184829774655794, disc_loss = 0.005799287194876294
Trained batch 19 in epoch 1, gen_loss = 2.1891010999679565, disc_loss = 0.00573130208067596
Trained batch 20 in epoch 1, gen_loss = 2.1838467915852866, disc_loss = 0.005772704569001992
Trained batch 21 in epoch 1, gen_loss = 2.173289488662373, disc_loss = 0.005767463134940375
Trained batch 22 in epoch 1, gen_loss = 2.165250627890877, disc_loss = 0.005704173312077056
Trained batch 23 in epoch 1, gen_loss = 2.154680609703064, disc_loss = 0.005622046844412883
Trained batch 24 in epoch 1, gen_loss = 2.133474225997925, disc_loss = 0.005603928379714489
Trained batch 25 in epoch 1, gen_loss = 2.111304819583893, disc_loss = 0.005710542775117434
Trained batch 26 in epoch 1, gen_loss = 2.117642256948683, disc_loss = 0.005735987142004349
Trained batch 27 in epoch 1, gen_loss = 2.119200191327504, disc_loss = 0.005774963763542473
Trained batch 28 in epoch 1, gen_loss = 2.106388309906269, disc_loss = 0.005795366917576255
Trained batch 29 in epoch 1, gen_loss = 2.1003949840863547, disc_loss = 0.005725254553059737
Trained batch 30 in epoch 1, gen_loss = 2.115212090553776, disc_loss = 0.005676918993553807
Trained batch 31 in epoch 1, gen_loss = 2.1106425002217293, disc_loss = 0.005664370313752443
Trained batch 32 in epoch 1, gen_loss = 2.1135464942816533, disc_loss = 0.00562093456303983
Trained batch 33 in epoch 1, gen_loss = 2.1109382965985466, disc_loss = 0.005571518230306751
Trained batch 34 in epoch 1, gen_loss = 2.1109095709664483, disc_loss = 0.005541584906833512
Trained batch 35 in epoch 1, gen_loss = 2.1169943279690213, disc_loss = 0.005504692594210307
Trained batch 36 in epoch 1, gen_loss = 2.1152845653327734, disc_loss = 0.005481323982412751
Trained batch 37 in epoch 1, gen_loss = 2.1165662690212854, disc_loss = 0.005466379715423835
Trained batch 38 in epoch 1, gen_loss = 2.120351051672911, disc_loss = 0.005447220809471149
Trained batch 39 in epoch 1, gen_loss = 2.1148275941610337, disc_loss = 0.005410256574396044
Trained batch 40 in epoch 1, gen_loss = 2.1172515502790126, disc_loss = 0.0053704822799418035
Trained batch 41 in epoch 1, gen_loss = 2.110992729663849, disc_loss = 0.005346497454281364
Trained batch 42 in epoch 1, gen_loss = 2.109398589577786, disc_loss = 0.0053265834183887
Trained batch 43 in epoch 1, gen_loss = 2.108627885580063, disc_loss = 0.0053452334620735864
Trained batch 44 in epoch 1, gen_loss = 2.1094515138202246, disc_loss = 0.005326920820193158
Trained batch 45 in epoch 1, gen_loss = 2.1088274121284485, disc_loss = 0.005301685396419919
Trained batch 46 in epoch 1, gen_loss = 2.1051038021736956, disc_loss = 0.005264234615172794
Trained batch 47 in epoch 1, gen_loss = 2.1015665953358016, disc_loss = 0.0052613748363607256
Trained batch 48 in epoch 1, gen_loss = 2.103627489537609, disc_loss = 0.005249363298965048
Trained batch 49 in epoch 1, gen_loss = 2.103890631198883, disc_loss = 0.00524542820174247
Trained batch 50 in epoch 1, gen_loss = 2.0969731503841924, disc_loss = 0.005297889170583849
Trained batch 51 in epoch 1, gen_loss = 2.104479287679379, disc_loss = 0.005294773830638195
Trained batch 52 in epoch 1, gen_loss = 2.105956102317234, disc_loss = 0.00531661166493201
Trained batch 53 in epoch 1, gen_loss = 2.1082259526959173, disc_loss = 0.005354009400535788
Trained batch 54 in epoch 1, gen_loss = 2.1009853428060357, disc_loss = 0.005433281481435353
Trained batch 55 in epoch 1, gen_loss = 2.0995243596179143, disc_loss = 0.005476738729547443
Trained batch 56 in epoch 1, gen_loss = 2.1027853635319493, disc_loss = 0.0055054212274977515
Trained batch 57 in epoch 1, gen_loss = 2.099553239756617, disc_loss = 0.005503469528148657
Trained batch 58 in epoch 1, gen_loss = 2.102492057670981, disc_loss = 0.005494818142694184
Trained batch 59 in epoch 1, gen_loss = 2.106390964984894, disc_loss = 0.005476848187390715
Trained batch 60 in epoch 1, gen_loss = 2.1068905846017305, disc_loss = 0.005462219301214228
Trained batch 61 in epoch 1, gen_loss = 2.103315349548094, disc_loss = 0.005442642910976804
Trained batch 62 in epoch 1, gen_loss = 2.1076874240996344, disc_loss = 0.0054296990154340625
Trained batch 63 in epoch 1, gen_loss = 2.105493763461709, disc_loss = 0.005438944255729439
Trained batch 64 in epoch 1, gen_loss = 2.101938922588642, disc_loss = 0.0054667390274027216
Trained batch 65 in epoch 1, gen_loss = 2.0998067151416433, disc_loss = 0.005504210250254608
Trained batch 66 in epoch 1, gen_loss = 2.100733153855623, disc_loss = 0.005533585140703997
Trained batch 67 in epoch 1, gen_loss = 2.1001621782779694, disc_loss = 0.005576196273870985
Trained batch 68 in epoch 1, gen_loss = 2.1035397000934766, disc_loss = 0.005631285878168284
Trained batch 69 in epoch 1, gen_loss = 2.1003356405666898, disc_loss = 0.005755390050554914
Trained batch 70 in epoch 1, gen_loss = 2.097225348714372, disc_loss = 0.005993508258309793
Trained batch 71 in epoch 1, gen_loss = 2.102563730544514, disc_loss = 0.006192361428273014
Trained batch 72 in epoch 1, gen_loss = 2.1061105711819375, disc_loss = 0.006356441412656887
Trained batch 73 in epoch 1, gen_loss = 2.1054802794714234, disc_loss = 0.006692931166145246
Trained batch 74 in epoch 1, gen_loss = 2.109458581606547, disc_loss = 0.006889371086532871
Trained batch 75 in epoch 1, gen_loss = 2.103932432438198, disc_loss = 0.006954090617670629
Trained batch 76 in epoch 1, gen_loss = 2.1011336143914754, disc_loss = 0.007017840446855921
Trained batch 77 in epoch 1, gen_loss = 2.0983247573559103, disc_loss = 0.007089763960371224
Trained batch 78 in epoch 1, gen_loss = 2.09820848175242, disc_loss = 0.007134534922558107
Trained batch 79 in epoch 1, gen_loss = 2.098747143149376, disc_loss = 0.007219877684838139
Trained batch 80 in epoch 1, gen_loss = 2.0980299166691156, disc_loss = 0.007307584256646626
Trained batch 81 in epoch 1, gen_loss = 2.1016491302629796, disc_loss = 0.007382194531468175
Trained batch 82 in epoch 1, gen_loss = 2.1063782192138305, disc_loss = 0.007452724700658975
Trained batch 83 in epoch 1, gen_loss = 2.1062729557355246, disc_loss = 0.007544306503231859
Trained batch 84 in epoch 1, gen_loss = 2.1059573145473705, disc_loss = 0.0076204858912045466
Trained batch 85 in epoch 1, gen_loss = 2.107214941534885, disc_loss = 0.007619350777700717
Trained batch 86 in epoch 1, gen_loss = 2.106441771847078, disc_loss = 0.00762776786129622
Trained batch 87 in epoch 1, gen_loss = 2.106414047154513, disc_loss = 0.007665606466947462
Trained batch 88 in epoch 1, gen_loss = 2.108690985133139, disc_loss = 0.007670044394084409
Trained batch 89 in epoch 1, gen_loss = 2.1100313584009807, disc_loss = 0.007687512575648725
Trained batch 90 in epoch 1, gen_loss = 2.109572410583496, disc_loss = 0.007667407191327804
Trained batch 91 in epoch 1, gen_loss = 2.1047957319280375, disc_loss = 0.007675033389165512
Trained batch 92 in epoch 1, gen_loss = 2.106775577350329, disc_loss = 0.007700877987669521
Trained batch 93 in epoch 1, gen_loss = 2.107938973193473, disc_loss = 0.007724899048124381
Trained batch 94 in epoch 1, gen_loss = 2.1059513857490137, disc_loss = 0.007759404998566759
Trained batch 95 in epoch 1, gen_loss = 2.105318627009789, disc_loss = 0.007760360849109323
Trained batch 96 in epoch 1, gen_loss = 2.1084305662469767, disc_loss = 0.007771289189701381
Trained batch 97 in epoch 1, gen_loss = 2.1070295730415656, disc_loss = 0.007877947688958019
Trained batch 98 in epoch 1, gen_loss = 2.1082465925602, disc_loss = 0.008074247083071657
Trained batch 99 in epoch 1, gen_loss = 2.107314862012863, disc_loss = 0.008179347740951925
Trained batch 100 in epoch 1, gen_loss = 2.105716078588278, disc_loss = 0.00826715355471588
Trained batch 101 in epoch 1, gen_loss = 2.1089242498079934, disc_loss = 0.008425255783139636
Trained batch 102 in epoch 1, gen_loss = 2.1073971408084757, disc_loss = 0.008695857022952252
Trained batch 103 in epoch 1, gen_loss = 2.1093655079603195, disc_loss = 0.009772567349360682
Trained batch 104 in epoch 1, gen_loss = 2.1094198260988506, disc_loss = 0.010122106102339568
Trained batch 105 in epoch 1, gen_loss = 2.107155826856505, disc_loss = 0.01019073209400236
Trained batch 106 in epoch 1, gen_loss = 2.1056699786230784, disc_loss = 0.010225750734402893
Trained batch 107 in epoch 1, gen_loss = 2.107909475211744, disc_loss = 0.01024679563879208
Trained batch 108 in epoch 1, gen_loss = 2.104882943520852, disc_loss = 0.010272330871501237
Trained batch 109 in epoch 1, gen_loss = 2.1048207120461897, disc_loss = 0.010260889308781109
Trained batch 110 in epoch 1, gen_loss = 2.105081378876626, disc_loss = 0.010231757563798948
Trained batch 111 in epoch 1, gen_loss = 2.104856902999537, disc_loss = 0.010186747604166158
Trained batch 112 in epoch 1, gen_loss = 2.1011437283153027, disc_loss = 0.010182419905142315
Trained batch 113 in epoch 1, gen_loss = 2.102479406616144, disc_loss = 0.010150030882326527
Trained batch 114 in epoch 1, gen_loss = 2.1012336782787155, disc_loss = 0.010114481379075543
Trained batch 115 in epoch 1, gen_loss = 2.1024670385081192, disc_loss = 0.01008709321593352
Trained batch 116 in epoch 1, gen_loss = 2.1038436105108667, disc_loss = 0.01005527501901946
Trained batch 117 in epoch 1, gen_loss = 2.102678134279736, disc_loss = 0.010028360224076374
Trained batch 118 in epoch 1, gen_loss = 2.101414521201318, disc_loss = 0.010030166584481838
Trained batch 119 in epoch 1, gen_loss = 2.1023890783389407, disc_loss = 0.010049818000212932
Trained batch 120 in epoch 1, gen_loss = 2.100966608228762, disc_loss = 0.010031032639609512
Trained batch 121 in epoch 1, gen_loss = 2.0964995378353555, disc_loss = 0.010077028712792108
Trained batch 122 in epoch 1, gen_loss = 2.100066246055975, disc_loss = 0.010085322214593368
Trained batch 123 in epoch 1, gen_loss = 2.101275477678545, disc_loss = 0.010055472400234711
Trained batch 124 in epoch 1, gen_loss = 2.099259128570557, disc_loss = 0.010024725610390306
Trained batch 125 in epoch 1, gen_loss = 2.0994617125344655, disc_loss = 0.009999793963432903
Trained batch 126 in epoch 1, gen_loss = 2.100319408056304, disc_loss = 0.010013111707512436
Trained batch 127 in epoch 1, gen_loss = 2.098722569644451, disc_loss = 0.010045807555798092
Trained batch 128 in epoch 1, gen_loss = 2.096689126288244, disc_loss = 0.010055212673998271
Trained batch 129 in epoch 1, gen_loss = 2.0968322460468, disc_loss = 0.01004621044983371
Trained batch 130 in epoch 1, gen_loss = 2.095977542054562, disc_loss = 0.010052752455355215
Trained batch 131 in epoch 1, gen_loss = 2.0964570000316156, disc_loss = 0.010012860108293931
Trained batch 132 in epoch 1, gen_loss = 2.0942677250482085, disc_loss = 0.009989384843624736
Trained batch 133 in epoch 1, gen_loss = 2.0931189193654416, disc_loss = 0.009944024302913293
Trained batch 134 in epoch 1, gen_loss = 2.092142770908497, disc_loss = 0.009903437232046768
Trained batch 135 in epoch 1, gen_loss = 2.090892676921452, disc_loss = 0.00986574572572649
Trained batch 136 in epoch 1, gen_loss = 2.0921479689813878, disc_loss = 0.009825946336584913
Trained batch 137 in epoch 1, gen_loss = 2.092533592728601, disc_loss = 0.00977731686240683
Trained batch 138 in epoch 1, gen_loss = 2.0923339317170835, disc_loss = 0.00973197132543319
Trained batch 139 in epoch 1, gen_loss = 2.092679937396731, disc_loss = 0.009708786853921732
Trained batch 140 in epoch 1, gen_loss = 2.092977169557666, disc_loss = 0.009670542297118627
Trained batch 141 in epoch 1, gen_loss = 2.0929913277357395, disc_loss = 0.009625104011666082
Trained batch 142 in epoch 1, gen_loss = 2.09165641727981, disc_loss = 0.009579511525408996
Trained batch 143 in epoch 1, gen_loss = 2.093069810834196, disc_loss = 0.009551065129926428
Trained batch 144 in epoch 1, gen_loss = 2.093206651457425, disc_loss = 0.009522514812776755
Trained batch 145 in epoch 1, gen_loss = 2.0917318855246454, disc_loss = 0.009498099349949458
Trained batch 146 in epoch 1, gen_loss = 2.0911024573708876, disc_loss = 0.0094874865901308
Trained batch 147 in epoch 1, gen_loss = 2.09229242479479, disc_loss = 0.009493351448327303
Trained batch 148 in epoch 1, gen_loss = 2.0938259195161346, disc_loss = 0.009497348619187438
Trained batch 149 in epoch 1, gen_loss = 2.094238975842794, disc_loss = 0.009482033718377351
Trained batch 150 in epoch 1, gen_loss = 2.094286394435049, disc_loss = 0.009458705357319077
Trained batch 151 in epoch 1, gen_loss = 2.092855398592196, disc_loss = 0.009438157743333201
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.9517364501953125, disc_loss = 0.010818098671734333
Trained batch 1 in epoch 2, gen_loss = 2.048733115196228, disc_loss = 0.011575231794267893
Trained batch 2 in epoch 2, gen_loss = 1.9968316555023193, disc_loss = 0.010768737954397997
Trained batch 3 in epoch 2, gen_loss = 2.0264424085617065, disc_loss = 0.009008661261759698
Trained batch 4 in epoch 2, gen_loss = 2.057715892791748, disc_loss = 0.0097010494209826
Trained batch 5 in epoch 2, gen_loss = 2.045736571153005, disc_loss = 0.012428366346284747
Trained batch 6 in epoch 2, gen_loss = 2.02040273802621, disc_loss = 0.012153694738766976
Trained batch 7 in epoch 2, gen_loss = 2.041834831237793, disc_loss = 0.011430431448388845
Trained batch 8 in epoch 2, gen_loss = 2.0269496705796985, disc_loss = 0.010931532571299208
Trained batch 9 in epoch 2, gen_loss = 2.0225264549255373, disc_loss = 0.010380085185170173
Trained batch 10 in epoch 2, gen_loss = 2.02528470212763, disc_loss = 0.009759608338671651
Trained batch 11 in epoch 2, gen_loss = 2.0241063833236694, disc_loss = 0.00929305343500649
Trained batch 12 in epoch 2, gen_loss = 2.038596905194796, disc_loss = 0.008825088313852366
Trained batch 13 in epoch 2, gen_loss = 2.039642861911229, disc_loss = 0.008440753045891012
Trained batch 14 in epoch 2, gen_loss = 2.0575599670410156, disc_loss = 0.008096239343285561
Trained batch 15 in epoch 2, gen_loss = 2.0830342769622803, disc_loss = 0.00788874487625435
Trained batch 16 in epoch 2, gen_loss = 2.079373331630931, disc_loss = 0.007679245653836166
Trained batch 17 in epoch 2, gen_loss = 2.0728664530648127, disc_loss = 0.007538390604572164
Trained batch 18 in epoch 2, gen_loss = 2.0760996090738395, disc_loss = 0.007465027983447439
Trained batch 19 in epoch 2, gen_loss = 2.0762323141098022, disc_loss = 0.007318457448855042
Trained batch 20 in epoch 2, gen_loss = 2.0761379287356423, disc_loss = 0.007164288888729754
Trained batch 21 in epoch 2, gen_loss = 2.0795463757081465, disc_loss = 0.007026938340541991
Trained batch 22 in epoch 2, gen_loss = 2.083999996599944, disc_loss = 0.006849943731061142
Trained batch 23 in epoch 2, gen_loss = 2.089026520649592, disc_loss = 0.006700691223765413
Trained batch 24 in epoch 2, gen_loss = 2.09246919631958, disc_loss = 0.006602427456527948
Trained batch 25 in epoch 2, gen_loss = 2.0926746680186343, disc_loss = 0.0065372734008213645
Trained batch 26 in epoch 2, gen_loss = 2.0897274017333984, disc_loss = 0.006521545729979321
Trained batch 27 in epoch 2, gen_loss = 2.0979476315634593, disc_loss = 0.006540410220623016
Trained batch 28 in epoch 2, gen_loss = 2.0963919409390153, disc_loss = 0.006585975691419223
Trained batch 29 in epoch 2, gen_loss = 2.1071616808573403, disc_loss = 0.006583524992068609
Trained batch 30 in epoch 2, gen_loss = 2.111426576491325, disc_loss = 0.006528543728974557
Trained batch 31 in epoch 2, gen_loss = 2.1100832000374794, disc_loss = 0.006462953228037804
Trained batch 32 in epoch 2, gen_loss = 2.106255227869207, disc_loss = 0.00648308593328252
Trained batch 33 in epoch 2, gen_loss = 2.1081514148151173, disc_loss = 0.006579127025735729
Trained batch 34 in epoch 2, gen_loss = 2.104311064311436, disc_loss = 0.006612295684005533
Trained batch 35 in epoch 2, gen_loss = 2.099433491627375, disc_loss = 0.006554150151916676
Trained batch 36 in epoch 2, gen_loss = 2.0912416077948905, disc_loss = 0.0064477793796843775
Trained batch 37 in epoch 2, gen_loss = 2.090023458003998, disc_loss = 0.006376689937161772
Trained batch 38 in epoch 2, gen_loss = 2.0873336761425705, disc_loss = 0.006343236682602229
Trained batch 39 in epoch 2, gen_loss = 2.083683905005455, disc_loss = 0.006412315892521292
Trained batch 40 in epoch 2, gen_loss = 2.0807474386401292, disc_loss = 0.006584083650079443
Trained batch 41 in epoch 2, gen_loss = 2.0831223811422075, disc_loss = 0.00682006380520761
Trained batch 42 in epoch 2, gen_loss = 2.0909388203953587, disc_loss = 0.006893727202834778
Trained batch 43 in epoch 2, gen_loss = 2.0852035365321417, disc_loss = 0.00681848790157925
Trained batch 44 in epoch 2, gen_loss = 2.0791707038879395, disc_loss = 0.0067203525867727066
Trained batch 45 in epoch 2, gen_loss = 2.0758130654044775, disc_loss = 0.006632188036430465
Trained batch 46 in epoch 2, gen_loss = 2.074645022128491, disc_loss = 0.006537867308732994
Trained batch 47 in epoch 2, gen_loss = 2.076120376586914, disc_loss = 0.006448424688035932
Trained batch 48 in epoch 2, gen_loss = 2.07421389161324, disc_loss = 0.006366111851316325
Trained batch 49 in epoch 2, gen_loss = 2.080751745700836, disc_loss = 0.006297110607847572
Trained batch 50 in epoch 2, gen_loss = 2.080112141721389, disc_loss = 0.006247652247182879
Trained batch 51 in epoch 2, gen_loss = 2.0786485511523027, disc_loss = 0.006196531328336837
Trained batch 52 in epoch 2, gen_loss = 2.0755463613654084, disc_loss = 0.006157179754051678
Trained batch 53 in epoch 2, gen_loss = 2.078494202207636, disc_loss = 0.006105395805746041
Trained batch 54 in epoch 2, gen_loss = 2.0786370342428033, disc_loss = 0.006056789423085072
Trained batch 55 in epoch 2, gen_loss = 2.0770919301680157, disc_loss = 0.006010701339359262
Trained batch 56 in epoch 2, gen_loss = 2.0776644526866446, disc_loss = 0.0059610463703345315
Trained batch 57 in epoch 2, gen_loss = 2.0778959434607933, disc_loss = 0.005897937093636599
Trained batch 58 in epoch 2, gen_loss = 2.082416827395811, disc_loss = 0.005835354785924241
Trained batch 59 in epoch 2, gen_loss = 2.0842911819616954, disc_loss = 0.005778307731573781
Trained batch 60 in epoch 2, gen_loss = 2.081867892234052, disc_loss = 0.005734056432838323
Trained batch 61 in epoch 2, gen_loss = 2.086054453926702, disc_loss = 0.0056998856448298016
Trained batch 62 in epoch 2, gen_loss = 2.080737206670973, disc_loss = 0.005692284957077059
Trained batch 63 in epoch 2, gen_loss = 2.0816698540002108, disc_loss = 0.005665527056407882
Trained batch 64 in epoch 2, gen_loss = 2.080870303740868, disc_loss = 0.005633241249821507
Trained batch 65 in epoch 2, gen_loss = 2.0835954041192024, disc_loss = 0.005610309199034942
Trained batch 66 in epoch 2, gen_loss = 2.085905994941939, disc_loss = 0.0055714496307130625
Trained batch 67 in epoch 2, gen_loss = 2.0847211287302128, disc_loss = 0.005531450233641355
Trained batch 68 in epoch 2, gen_loss = 2.0930157727089482, disc_loss = 0.005485168968637784
Trained batch 69 in epoch 2, gen_loss = 2.0941196118082317, disc_loss = 0.005443427685116018
Trained batch 70 in epoch 2, gen_loss = 2.0905258420487525, disc_loss = 0.005406296297147031
Trained batch 71 in epoch 2, gen_loss = 2.09075156516499, disc_loss = 0.005369253045905175
Trained batch 72 in epoch 2, gen_loss = 2.087463524243603, disc_loss = 0.005338583339311897
Trained batch 73 in epoch 2, gen_loss = 2.0887021551261076, disc_loss = 0.005305540924136703
Trained batch 74 in epoch 2, gen_loss = 2.0917271407445273, disc_loss = 0.005274165015046795
Trained batch 75 in epoch 2, gen_loss = 2.0894364385228408, disc_loss = 0.005248167775693889
Trained batch 76 in epoch 2, gen_loss = 2.089119420423136, disc_loss = 0.005224302807193879
Trained batch 77 in epoch 2, gen_loss = 2.0854090452194214, disc_loss = 0.0051873006995242
Trained batch 78 in epoch 2, gen_loss = 2.0851939177211327, disc_loss = 0.00515869082706167
Trained batch 79 in epoch 2, gen_loss = 2.0880375146865844, disc_loss = 0.005131195075227879
Trained batch 80 in epoch 2, gen_loss = 2.085385983372912, disc_loss = 0.005097920382625343
Trained batch 81 in epoch 2, gen_loss = 2.085722110620359, disc_loss = 0.005064384832910103
Trained batch 82 in epoch 2, gen_loss = 2.081815583160125, disc_loss = 0.005038108687892735
Trained batch 83 in epoch 2, gen_loss = 2.077168833641779, disc_loss = 0.005009976035494003
Trained batch 84 in epoch 2, gen_loss = 2.076613987193388, disc_loss = 0.004976134684265537
Trained batch 85 in epoch 2, gen_loss = 2.0750377982161767, disc_loss = 0.004940679763866112
Trained batch 86 in epoch 2, gen_loss = 2.0742183444143714, disc_loss = 0.0049086104685055285
Trained batch 87 in epoch 2, gen_loss = 2.0757666474038903, disc_loss = 0.004873344318845987
Trained batch 88 in epoch 2, gen_loss = 2.0767557808522428, disc_loss = 0.004840074247010889
Trained batch 89 in epoch 2, gen_loss = 2.076510704888238, disc_loss = 0.004809021824298219
Trained batch 90 in epoch 2, gen_loss = 2.07998388678163, disc_loss = 0.004779083706735337
Trained batch 91 in epoch 2, gen_loss = 2.0791664408600847, disc_loss = 0.004751010915598548
Trained batch 92 in epoch 2, gen_loss = 2.080061125498946, disc_loss = 0.004725575693682717
Trained batch 93 in epoch 2, gen_loss = 2.0795607414651425, disc_loss = 0.004701713388637105
Trained batch 94 in epoch 2, gen_loss = 2.085407779091283, disc_loss = 0.004678738797328582
Trained batch 95 in epoch 2, gen_loss = 2.086740590631962, disc_loss = 0.00466064158899826
Trained batch 96 in epoch 2, gen_loss = 2.0875737445870626, disc_loss = 0.004648881999190091
Trained batch 97 in epoch 2, gen_loss = 2.089371836915308, disc_loss = 0.0046393059358019765
Trained batch 98 in epoch 2, gen_loss = 2.0938091783812554, disc_loss = 0.004622116829550853
Trained batch 99 in epoch 2, gen_loss = 2.095195505619049, disc_loss = 0.004592420385451987
Trained batch 100 in epoch 2, gen_loss = 2.094761923988267, disc_loss = 0.004562681429042011
Trained batch 101 in epoch 2, gen_loss = 2.0956044126959408, disc_loss = 0.0045357212942440574
Trained batch 102 in epoch 2, gen_loss = 2.0941619560556504, disc_loss = 0.004511252736211619
Trained batch 103 in epoch 2, gen_loss = 2.0938499168707776, disc_loss = 0.004487696196660041
Trained batch 104 in epoch 2, gen_loss = 2.091538757369632, disc_loss = 0.004472465796529182
Trained batch 105 in epoch 2, gen_loss = 2.088977782231457, disc_loss = 0.00445778624106304
Trained batch 106 in epoch 2, gen_loss = 2.088008915152505, disc_loss = 0.004438223429328858
Trained batch 107 in epoch 2, gen_loss = 2.0871228719199144, disc_loss = 0.004419973390651177
Trained batch 108 in epoch 2, gen_loss = 2.084030712416413, disc_loss = 0.004402130191778303
Trained batch 109 in epoch 2, gen_loss = 2.0821893930435182, disc_loss = 0.0043789498751390385
Trained batch 110 in epoch 2, gen_loss = 2.081516611683476, disc_loss = 0.004353387680886364
Trained batch 111 in epoch 2, gen_loss = 2.0826242672545567, disc_loss = 0.004330631905759219
Trained batch 112 in epoch 2, gen_loss = 2.086437459540578, disc_loss = 0.004308530276814327
Trained batch 113 in epoch 2, gen_loss = 2.089739717935261, disc_loss = 0.004286048271113255
Trained batch 114 in epoch 2, gen_loss = 2.0888971090316772, disc_loss = 0.004262801317457596
Trained batch 115 in epoch 2, gen_loss = 2.0875823323068947, disc_loss = 0.004238937168526624
Trained batch 116 in epoch 2, gen_loss = 2.086291373285473, disc_loss = 0.004212942512697962
Trained batch 117 in epoch 2, gen_loss = 2.0853573407156993, disc_loss = 0.004188315227619862
Trained batch 118 in epoch 2, gen_loss = 2.0829445424200106, disc_loss = 0.004163707329641182
Trained batch 119 in epoch 2, gen_loss = 2.0857818096876146, disc_loss = 0.0041433315733835725
Trained batch 120 in epoch 2, gen_loss = 2.086794968478936, disc_loss = 0.004122970744097713
Trained batch 121 in epoch 2, gen_loss = 2.086061263670687, disc_loss = 0.004101549131131624
Trained batch 122 in epoch 2, gen_loss = 2.083859365160872, disc_loss = 0.0040845166545406715
Trained batch 123 in epoch 2, gen_loss = 2.0850138654631953, disc_loss = 0.004071882464960518
Trained batch 124 in epoch 2, gen_loss = 2.0837828006744386, disc_loss = 0.004051012647338211
Trained batch 125 in epoch 2, gen_loss = 2.0866683002502198, disc_loss = 0.004028915257621852
Trained batch 126 in epoch 2, gen_loss = 2.0872659063714694, disc_loss = 0.0040064385421134125
Trained batch 127 in epoch 2, gen_loss = 2.0871150624006987, disc_loss = 0.003984267983469181
Trained batch 128 in epoch 2, gen_loss = 2.086706599523855, disc_loss = 0.003962319564478573
Trained batch 129 in epoch 2, gen_loss = 2.086106716669523, disc_loss = 0.003947907852796981
Trained batch 130 in epoch 2, gen_loss = 2.084930489081463, disc_loss = 0.003934719466483434
Trained batch 131 in epoch 2, gen_loss = 2.085738601106586, disc_loss = 0.0039162389038017754
Trained batch 132 in epoch 2, gen_loss = 2.0857337363680504, disc_loss = 0.0038995227611910805
Trained batch 133 in epoch 2, gen_loss = 2.084519920954064, disc_loss = 0.003885200916122256
Trained batch 134 in epoch 2, gen_loss = 2.084789843912478, disc_loss = 0.0038691665270124322
Trained batch 135 in epoch 2, gen_loss = 2.0866871116792454, disc_loss = 0.0038539708749500707
Trained batch 136 in epoch 2, gen_loss = 2.0860331676302164, disc_loss = 0.0038364523746426743
Trained batch 137 in epoch 2, gen_loss = 2.0856144402338113, disc_loss = 0.0038158429450814383
Trained batch 138 in epoch 2, gen_loss = 2.0858914346146067, disc_loss = 0.0037967512683889314
Trained batch 139 in epoch 2, gen_loss = 2.085036908728736, disc_loss = 0.0037776111816388686
Trained batch 140 in epoch 2, gen_loss = 2.083098437769193, disc_loss = 0.00376226305251558
Trained batch 141 in epoch 2, gen_loss = 2.0814705247610386, disc_loss = 0.003749791379447397
Trained batch 142 in epoch 2, gen_loss = 2.0816163133074355, disc_loss = 0.0037337909884086543
Trained batch 143 in epoch 2, gen_loss = 2.0791904371645717, disc_loss = 0.0037189907994211856
Trained batch 144 in epoch 2, gen_loss = 2.0776858255780977, disc_loss = 0.0037044294860920516
Trained batch 145 in epoch 2, gen_loss = 2.076245029495187, disc_loss = 0.0036898720578915655
Trained batch 146 in epoch 2, gen_loss = 2.075528731151503, disc_loss = 0.003672345894623269
Trained batch 147 in epoch 2, gen_loss = 2.0764115944102004, disc_loss = 0.0036549580612257626
Trained batch 148 in epoch 2, gen_loss = 2.0787814583554365, disc_loss = 0.0036387579685902135
Trained batch 149 in epoch 2, gen_loss = 2.077907058397929, disc_loss = 0.0036227710746849578
Trained batch 150 in epoch 2, gen_loss = 2.079259305600299, disc_loss = 0.0036061802317715243
Trained batch 151 in epoch 2, gen_loss = 2.079368056435334, disc_loss = 0.0035902873121238755
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.8426862955093384, disc_loss = 0.001240912126377225
Trained batch 1 in epoch 3, gen_loss = 1.9732096791267395, disc_loss = 0.0012018912239000201
Trained batch 2 in epoch 3, gen_loss = 1.9044338464736938, disc_loss = 0.001273260257827739
Trained batch 3 in epoch 3, gen_loss = 1.9560751616954803, disc_loss = 0.0012265729019418359
Trained batch 4 in epoch 3, gen_loss = 2.0172229051589965, disc_loss = 0.0011876714648678898
Trained batch 5 in epoch 3, gen_loss = 2.0536898573239646, disc_loss = 0.0011850257093707721
Trained batch 6 in epoch 3, gen_loss = 2.0526117427008495, disc_loss = 0.001201310527643987
Trained batch 7 in epoch 3, gen_loss = 2.061603292822838, disc_loss = 0.0012136552977608517
Trained batch 8 in epoch 3, gen_loss = 2.0911289718416004, disc_loss = 0.0012431413892449604
Trained batch 9 in epoch 3, gen_loss = 2.062367284297943, disc_loss = 0.0012835063389502466
Trained batch 10 in epoch 3, gen_loss = 2.0490880012512207, disc_loss = 0.0013273139378394592
Trained batch 11 in epoch 3, gen_loss = 2.03156969944636, disc_loss = 0.0013580158217033993
Trained batch 12 in epoch 3, gen_loss = 2.028523041651799, disc_loss = 0.00138185908480619
Trained batch 13 in epoch 3, gen_loss = 2.0150165132113864, disc_loss = 0.0013737028015644423
Trained batch 14 in epoch 3, gen_loss = 2.0305243253707888, disc_loss = 0.0013582931676258644
Trained batch 15 in epoch 3, gen_loss = 2.0344331935048103, disc_loss = 0.0013719574926653877
Trained batch 16 in epoch 3, gen_loss = 2.029859353514279, disc_loss = 0.0013820789754390717
Trained batch 17 in epoch 3, gen_loss = 2.0393177999390497, disc_loss = 0.0013942801484113766
Trained batch 18 in epoch 3, gen_loss = 2.026745557785034, disc_loss = 0.0014306928312994148
Trained batch 19 in epoch 3, gen_loss = 2.028819000720978, disc_loss = 0.00145929575082846
Trained batch 20 in epoch 3, gen_loss = 2.030942235674177, disc_loss = 0.0014451484561764769
Trained batch 21 in epoch 3, gen_loss = 2.0338055437261406, disc_loss = 0.0014297367571006444
Trained batch 22 in epoch 3, gen_loss = 2.0424383619557256, disc_loss = 0.0014198691503185294
Trained batch 23 in epoch 3, gen_loss = 2.047450621922811, disc_loss = 0.0014084571254594873
Trained batch 24 in epoch 3, gen_loss = 2.047605276107788, disc_loss = 0.0013880514586344362
Trained batch 25 in epoch 3, gen_loss = 2.0473353771063, disc_loss = 0.0013709758506872905
Trained batch 26 in epoch 3, gen_loss = 2.067937630194205, disc_loss = 0.0013678163824671948
Trained batch 27 in epoch 3, gen_loss = 2.086425789764949, disc_loss = 0.0013631302031821438
Trained batch 28 in epoch 3, gen_loss = 2.089893628811014, disc_loss = 0.0013467265044114199
Trained batch 29 in epoch 3, gen_loss = 2.08853239218394, disc_loss = 0.00133203295020697
Trained batch 30 in epoch 3, gen_loss = 2.0825655229630007, disc_loss = 0.001333454129992113
Trained batch 31 in epoch 3, gen_loss = 2.0743789076805115, disc_loss = 0.0013479209683282534
Trained batch 32 in epoch 3, gen_loss = 2.0654183626174927, disc_loss = 0.0013566041651012545
Trained batch 33 in epoch 3, gen_loss = 2.062507415519041, disc_loss = 0.0013559001980705514
Trained batch 34 in epoch 3, gen_loss = 2.059283985410418, disc_loss = 0.0013573560447964286
Trained batch 35 in epoch 3, gen_loss = 2.0572566522492304, disc_loss = 0.001342717488619706
Trained batch 36 in epoch 3, gen_loss = 2.0503982692151457, disc_loss = 0.001344420269093904
Trained batch 37 in epoch 3, gen_loss = 2.0501801434316134, disc_loss = 0.001336605920713689
Trained batch 38 in epoch 3, gen_loss = 2.0539967188468347, disc_loss = 0.0013360368902795017
Trained batch 39 in epoch 3, gen_loss = 2.0537854939699174, disc_loss = 0.0013304193606018088
Trained batch 40 in epoch 3, gen_loss = 2.046756639713194, disc_loss = 0.0013176313950680196
Trained batch 41 in epoch 3, gen_loss = 2.0459482669830322, disc_loss = 0.0013053900509562698
Trained batch 42 in epoch 3, gen_loss = 2.0470924266549044, disc_loss = 0.0013005393110540543
Trained batch 43 in epoch 3, gen_loss = 2.0473063100468027, disc_loss = 0.0013033591769106517
Trained batch 44 in epoch 3, gen_loss = 2.0399533907572427, disc_loss = 0.0012968955445103348
Trained batch 45 in epoch 3, gen_loss = 2.045919179916382, disc_loss = 0.0012872639332351316
Trained batch 46 in epoch 3, gen_loss = 2.0528043838257486, disc_loss = 0.0012823134757320774
Trained batch 47 in epoch 3, gen_loss = 2.0597966810067496, disc_loss = 0.0012813865602462708
Trained batch 48 in epoch 3, gen_loss = 2.061926462212387, disc_loss = 0.0012766693098641628
Trained batch 49 in epoch 3, gen_loss = 2.05722802400589, disc_loss = 0.0012736578483600169
Trained batch 50 in epoch 3, gen_loss = 2.0501661440905403, disc_loss = 0.0012643333403484932
Trained batch 51 in epoch 3, gen_loss = 2.051459949750167, disc_loss = 0.001262128571397625
Trained batch 52 in epoch 3, gen_loss = 2.047829663978433, disc_loss = 0.0012636141761487244
Trained batch 53 in epoch 3, gen_loss = 2.045623666710324, disc_loss = 0.001259274169569835
Trained batch 54 in epoch 3, gen_loss = 2.0418346231633966, disc_loss = 0.0012570930909450082
Trained batch 55 in epoch 3, gen_loss = 2.0412110473428453, disc_loss = 0.0012480109663946287
Trained batch 56 in epoch 3, gen_loss = 2.0399854225024843, disc_loss = 0.0012427630197060736
Trained batch 57 in epoch 3, gen_loss = 2.039064543000583, disc_loss = 0.0012388449294717405
Trained batch 58 in epoch 3, gen_loss = 2.037122397099511, disc_loss = 0.0012315291185247695
Trained batch 59 in epoch 3, gen_loss = 2.0326811909675597, disc_loss = 0.001229040229615445
Trained batch 60 in epoch 3, gen_loss = 2.031633224643645, disc_loss = 0.0012276787177247347
Trained batch 61 in epoch 3, gen_loss = 2.039727968554343, disc_loss = 0.0012307704197272898
Trained batch 62 in epoch 3, gen_loss = 2.039084542365301, disc_loss = 0.0012263812084076188
Trained batch 63 in epoch 3, gen_loss = 2.0396422129124403, disc_loss = 0.0012224189813423436
Trained batch 64 in epoch 3, gen_loss = 2.0438118035976705, disc_loss = 0.0012169783075268452
Trained batch 65 in epoch 3, gen_loss = 2.041270427631609, disc_loss = 0.001214691719999819
Trained batch 66 in epoch 3, gen_loss = 2.03737162298231, disc_loss = 0.0012124350516876177
Trained batch 67 in epoch 3, gen_loss = 2.036384468569475, disc_loss = 0.0012102330014493097
Trained batch 68 in epoch 3, gen_loss = 2.0377612891404526, disc_loss = 0.001203996875066904
Trained batch 69 in epoch 3, gen_loss = 2.04108407327107, disc_loss = 0.0011965025033402656
Trained batch 70 in epoch 3, gen_loss = 2.042654509275732, disc_loss = 0.0011913514955126693
Trained batch 71 in epoch 3, gen_loss = 2.0469269769059286, disc_loss = 0.001198046877915557
Trained batch 72 in epoch 3, gen_loss = 2.0481446099607914, disc_loss = 0.0012102535756764142
Trained batch 73 in epoch 3, gen_loss = 2.046347755032617, disc_loss = 0.0012141275329741875
Trained batch 74 in epoch 3, gen_loss = 2.0458617703119915, disc_loss = 0.0012275792239233852
Trained batch 75 in epoch 3, gen_loss = 2.0458307909338096, disc_loss = 0.0012361964894042007
Trained batch 76 in epoch 3, gen_loss = 2.0458898343049086, disc_loss = 0.001237724897113036
Trained batch 77 in epoch 3, gen_loss = 2.0471648084811673, disc_loss = 0.0012352178515030597
Trained batch 78 in epoch 3, gen_loss = 2.0480068499528907, disc_loss = 0.0012300560365820043
Trained batch 79 in epoch 3, gen_loss = 2.046171595156193, disc_loss = 0.001224120389088057
Trained batch 80 in epoch 3, gen_loss = 2.045916458706797, disc_loss = 0.0012223204960011775
Trained batch 81 in epoch 3, gen_loss = 2.047095117045612, disc_loss = 0.0012179740943105482
Trained batch 82 in epoch 3, gen_loss = 2.046131755932268, disc_loss = 0.0012156520240816724
Trained batch 83 in epoch 3, gen_loss = 2.047385818901516, disc_loss = 0.0012148437561422941
Trained batch 84 in epoch 3, gen_loss = 2.048100646804361, disc_loss = 0.0012150139945066151
Trained batch 85 in epoch 3, gen_loss = 2.0457282856453296, disc_loss = 0.0012120799449824749
Trained batch 86 in epoch 3, gen_loss = 2.046311864907714, disc_loss = 0.0012071731763934695
Trained batch 87 in epoch 3, gen_loss = 2.0481695871461523, disc_loss = 0.001202584329637995
Trained batch 88 in epoch 3, gen_loss = 2.048211549105269, disc_loss = 0.0011997729228558332
Trained batch 89 in epoch 3, gen_loss = 2.045806258254581, disc_loss = 0.0012058575598833461
Trained batch 90 in epoch 3, gen_loss = 2.044865737904559, disc_loss = 0.00120764253481936
Trained batch 91 in epoch 3, gen_loss = 2.0456682067850362, disc_loss = 0.0012138029611062097
Trained batch 92 in epoch 3, gen_loss = 2.046135106394368, disc_loss = 0.0012171611825745271
Trained batch 93 in epoch 3, gen_loss = 2.045341168312316, disc_loss = 0.0012202346028680814
Trained batch 94 in epoch 3, gen_loss = 2.045605771165145, disc_loss = 0.0012148166626789853
Trained batch 95 in epoch 3, gen_loss = 2.0461942069232464, disc_loss = 0.0012092761802099024
Trained batch 96 in epoch 3, gen_loss = 2.046535444013851, disc_loss = 0.0012050718693158676
Trained batch 97 in epoch 3, gen_loss = 2.049667247704097, disc_loss = 0.001198657169434413
Trained batch 98 in epoch 3, gen_loss = 2.0508239811116997, disc_loss = 0.0011953841406861414
Trained batch 99 in epoch 3, gen_loss = 2.0511454951763155, disc_loss = 0.0011924377211835235
Trained batch 100 in epoch 3, gen_loss = 2.052085617981335, disc_loss = 0.0011892620748425327
Trained batch 101 in epoch 3, gen_loss = 2.0480523752231226, disc_loss = 0.0011858341293226853
Trained batch 102 in epoch 3, gen_loss = 2.0508719752135787, disc_loss = 0.0011814856541216446
Trained batch 103 in epoch 3, gen_loss = 2.0502279824935474, disc_loss = 0.0011798764837574428
Trained batch 104 in epoch 3, gen_loss = 2.0509670927411032, disc_loss = 0.001178035554143467
Trained batch 105 in epoch 3, gen_loss = 2.051494349848549, disc_loss = 0.0011751261789061762
Trained batch 106 in epoch 3, gen_loss = 2.050490920788774, disc_loss = 0.0011713892601160594
Trained batch 107 in epoch 3, gen_loss = 2.049720805000376, disc_loss = 0.0011678089283156657
Trained batch 108 in epoch 3, gen_loss = 2.0490578544249227, disc_loss = 0.0011654288989679734
Trained batch 109 in epoch 3, gen_loss = 2.048928953300823, disc_loss = 0.0011614981991111893
Trained batch 110 in epoch 3, gen_loss = 2.046450260523203, disc_loss = 0.001159079093381192
Trained batch 111 in epoch 3, gen_loss = 2.0455932351095334, disc_loss = 0.0011551808165677357
Trained batch 112 in epoch 3, gen_loss = 2.045214204661614, disc_loss = 0.0011537571337725144
Trained batch 113 in epoch 3, gen_loss = 2.0419123047276546, disc_loss = 0.00115577395333451
Trained batch 114 in epoch 3, gen_loss = 2.0436060967652696, disc_loss = 0.0011524023356564018
Trained batch 115 in epoch 3, gen_loss = 2.0433975869211656, disc_loss = 0.0011491580878320183
Trained batch 116 in epoch 3, gen_loss = 2.042754766268608, disc_loss = 0.0011468587749693384
Trained batch 117 in epoch 3, gen_loss = 2.0457249940451927, disc_loss = 0.0011450894886304197
Trained batch 118 in epoch 3, gen_loss = 2.0464562688555037, disc_loss = 0.00114109565282804
Trained batch 119 in epoch 3, gen_loss = 2.049392819404602, disc_loss = 0.001136282188720846
Trained batch 120 in epoch 3, gen_loss = 2.0520739102166545, disc_loss = 0.001133217528262291
Trained batch 121 in epoch 3, gen_loss = 2.050003649758511, disc_loss = 0.0011328312054994043
Trained batch 122 in epoch 3, gen_loss = 2.0520243198890995, disc_loss = 0.001134497860287566
Trained batch 123 in epoch 3, gen_loss = 2.0523153447335765, disc_loss = 0.0011351415577660045
Trained batch 124 in epoch 3, gen_loss = 2.0549117164611816, disc_loss = 0.0011344836307689548
Trained batch 125 in epoch 3, gen_loss = 2.0565632335723394, disc_loss = 0.0011321822465914818
Trained batch 126 in epoch 3, gen_loss = 2.0550855163514146, disc_loss = 0.0011325085244148852
Trained batch 127 in epoch 3, gen_loss = 2.0548430494964123, disc_loss = 0.0011324180841256748
Trained batch 128 in epoch 3, gen_loss = 2.0564683888309685, disc_loss = 0.0011288877716468459
Trained batch 129 in epoch 3, gen_loss = 2.058599072236281, disc_loss = 0.0011247786926105619
Trained batch 130 in epoch 3, gen_loss = 2.0553947823648233, disc_loss = 0.0011230592761643742
Trained batch 131 in epoch 3, gen_loss = 2.0545654351061042, disc_loss = 0.001120426434984741
Trained batch 132 in epoch 3, gen_loss = 2.056599502276657, disc_loss = 0.0011201694846692447
Trained batch 133 in epoch 3, gen_loss = 2.0568152292450863, disc_loss = 0.0011229386310781173
Trained batch 134 in epoch 3, gen_loss = 2.056535754380403, disc_loss = 0.0011239001669714021
Trained batch 135 in epoch 3, gen_loss = 2.057763159275055, disc_loss = 0.0011200526577714994
Trained batch 136 in epoch 3, gen_loss = 2.059804369933414, disc_loss = 0.00111734072030284
Trained batch 137 in epoch 3, gen_loss = 2.059337153814841, disc_loss = 0.001114486144312347
Trained batch 138 in epoch 3, gen_loss = 2.0609359029385685, disc_loss = 0.0011117159847083013
Trained batch 139 in epoch 3, gen_loss = 2.060736915894917, disc_loss = 0.0011077101304960836
Trained batch 140 in epoch 3, gen_loss = 2.059174693222587, disc_loss = 0.001106707330509122
Trained batch 141 in epoch 3, gen_loss = 2.0584183343699283, disc_loss = 0.0011245727278357766
Trained batch 142 in epoch 3, gen_loss = 2.0597036301672875, disc_loss = 0.00115377435516045
Trained batch 143 in epoch 3, gen_loss = 2.057445139520698, disc_loss = 0.0012006249849542251
Trained batch 144 in epoch 3, gen_loss = 2.057412792896402, disc_loss = 0.001249263471731081
Trained batch 145 in epoch 3, gen_loss = 2.056439843079815, disc_loss = 0.0012663539988626662
Trained batch 146 in epoch 3, gen_loss = 2.056194473286064, disc_loss = 0.0012661782148781987
Trained batch 147 in epoch 3, gen_loss = 2.0584879219532013, disc_loss = 0.001266064795640272
Trained batch 148 in epoch 3, gen_loss = 2.060274889805173, disc_loss = 0.0012713299904818702
Trained batch 149 in epoch 3, gen_loss = 2.06192617336909, disc_loss = 0.0012729129342672724
Trained batch 150 in epoch 3, gen_loss = 2.061312014693456, disc_loss = 0.0012707044042813414
Trained batch 151 in epoch 3, gen_loss = 2.0599551640058817, disc_loss = 0.0012689244356711004
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.2756757736206055, disc_loss = 0.0013360452139750123
Trained batch 1 in epoch 4, gen_loss = 1.9809072613716125, disc_loss = 0.0015380753902718425
Trained batch 2 in epoch 4, gen_loss = 2.0477346181869507, disc_loss = 0.0015463910919303696
Trained batch 3 in epoch 4, gen_loss = 2.0770850479602814, disc_loss = 0.0014517858217004687
Trained batch 4 in epoch 4, gen_loss = 2.0231196641922, disc_loss = 0.0014676552033051848
Trained batch 5 in epoch 4, gen_loss = 1.978149910767873, disc_loss = 0.001432907476555556
Trained batch 6 in epoch 4, gen_loss = 1.9747356346675329, disc_loss = 0.0013244337335761105
Trained batch 7 in epoch 4, gen_loss = 1.9741787165403366, disc_loss = 0.001232978618645575
Trained batch 8 in epoch 4, gen_loss = 1.9839348660575018, disc_loss = 0.0011709757834776407
Trained batch 9 in epoch 4, gen_loss = 2.0025445103645323, disc_loss = 0.0011352136207278818
Trained batch 10 in epoch 4, gen_loss = 2.0010627291419287, disc_loss = 0.0011360858387144451
Trained batch 11 in epoch 4, gen_loss = 2.0006507436434426, disc_loss = 0.0011463710543466732
Trained batch 12 in epoch 4, gen_loss = 2.0023991144620457, disc_loss = 0.001206367254221382
Trained batch 13 in epoch 4, gen_loss = 1.9803340775626046, disc_loss = 0.0012526988409393067
Trained batch 14 in epoch 4, gen_loss = 1.9846843401590983, disc_loss = 0.0013121866116610665
Trained batch 15 in epoch 4, gen_loss = 1.9633515179157257, disc_loss = 0.0014690611678815912
Trained batch 16 in epoch 4, gen_loss = 1.9543755334966324, disc_loss = 0.001717081166776445
Trained batch 17 in epoch 4, gen_loss = 1.9824592802259657, disc_loss = 0.0017645309077731024
Trained batch 18 in epoch 4, gen_loss = 1.9812924736424495, disc_loss = 0.0017198383912297064
Trained batch 19 in epoch 4, gen_loss = 1.9843441486358642, disc_loss = 0.0017387941741617396
Trained batch 20 in epoch 4, gen_loss = 1.9806227797553653, disc_loss = 0.0017039203777953627
Trained batch 21 in epoch 4, gen_loss = 1.9837724620645696, disc_loss = 0.0016638359203088012
Trained batch 22 in epoch 4, gen_loss = 1.9844676929971445, disc_loss = 0.0016500661605159225
Trained batch 23 in epoch 4, gen_loss = 2.0029261906941733, disc_loss = 0.0016545695883299534
Trained batch 24 in epoch 4, gen_loss = 2.001025047302246, disc_loss = 0.0016514437692239882
Trained batch 25 in epoch 4, gen_loss = 1.9956973516024077, disc_loss = 0.0016451926606420714
Trained batch 26 in epoch 4, gen_loss = 2.0082230038113065, disc_loss = 0.001660717120911512
Trained batch 27 in epoch 4, gen_loss = 2.0165954317365373, disc_loss = 0.00167500161582471
Trained batch 28 in epoch 4, gen_loss = 2.0194530651487153, disc_loss = 0.0016591766214897406
Trained batch 29 in epoch 4, gen_loss = 2.0218080441157023, disc_loss = 0.0016309104471777876
Trained batch 30 in epoch 4, gen_loss = 2.0172531643221454, disc_loss = 0.0016350405846512126
Trained batch 31 in epoch 4, gen_loss = 2.0353131853044033, disc_loss = 0.0016692149729351513
Trained batch 32 in epoch 4, gen_loss = 2.0301585739309136, disc_loss = 0.0017380028271652532
Trained batch 33 in epoch 4, gen_loss = 2.034178723307217, disc_loss = 0.0018213712541824754
Trained batch 34 in epoch 4, gen_loss = 2.0368045364107403, disc_loss = 0.0018268756435385772
Trained batch 35 in epoch 4, gen_loss = 2.039339234431585, disc_loss = 0.001799289906759643
Trained batch 36 in epoch 4, gen_loss = 2.046916836016887, disc_loss = 0.001773506698727205
Trained batch 37 in epoch 4, gen_loss = 2.036352054068917, disc_loss = 0.001745840286419384
Trained batch 38 in epoch 4, gen_loss = 2.0334640741348267, disc_loss = 0.0017210797045547038
Trained batch 39 in epoch 4, gen_loss = 2.035533019900322, disc_loss = 0.0017035816490533762
Trained batch 40 in epoch 4, gen_loss = 2.039221557175241, disc_loss = 0.0016850219832210823
Trained batch 41 in epoch 4, gen_loss = 2.0397566074416753, disc_loss = 0.001666244744445153
Trained batch 42 in epoch 4, gen_loss = 2.0437154575835828, disc_loss = 0.0016444425713162609
Trained batch 43 in epoch 4, gen_loss = 2.042184577746825, disc_loss = 0.0016240236635150557
Trained batch 44 in epoch 4, gen_loss = 2.037981383005778, disc_loss = 0.0016024662349890504
Trained batch 45 in epoch 4, gen_loss = 2.041285250497901, disc_loss = 0.0015826705304156665
Trained batch 46 in epoch 4, gen_loss = 2.0403004149173167, disc_loss = 0.0015617129182383576
Trained batch 47 in epoch 4, gen_loss = 2.0444388488928475, disc_loss = 0.0015430441744683776
Trained batch 48 in epoch 4, gen_loss = 2.0398387106097475, disc_loss = 0.0015235469743077243
Trained batch 49 in epoch 4, gen_loss = 2.042504470348358, disc_loss = 0.001503175846301019
Trained batch 50 in epoch 4, gen_loss = 2.0403981980155494, disc_loss = 0.0014847700584533752
Trained batch 51 in epoch 4, gen_loss = 2.0428806107777815, disc_loss = 0.0014673798286821693
Trained batch 52 in epoch 4, gen_loss = 2.041057143571242, disc_loss = 0.001452744472771883
Trained batch 53 in epoch 4, gen_loss = 2.036110529193172, disc_loss = 0.0014593429384856587
Trained batch 54 in epoch 4, gen_loss = 2.043506565960971, disc_loss = 0.0014704231447963552
Trained batch 55 in epoch 4, gen_loss = 2.032603928021022, disc_loss = 0.0014847106753482617
Trained batch 56 in epoch 4, gen_loss = 2.0342000743799042, disc_loss = 0.0014996390050407826
Trained batch 57 in epoch 4, gen_loss = 2.036439977843186, disc_loss = 0.0014993027675543622
Trained batch 58 in epoch 4, gen_loss = 2.0340938588320197, disc_loss = 0.0014895756168575105
Trained batch 59 in epoch 4, gen_loss = 2.0373582939306893, disc_loss = 0.001477712761455526
Trained batch 60 in epoch 4, gen_loss = 2.041676957099164, disc_loss = 0.0014689381913755273
Trained batch 61 in epoch 4, gen_loss = 2.0400804262007437, disc_loss = 0.0014723698071564637
Trained batch 62 in epoch 4, gen_loss = 2.041129409320771, disc_loss = 0.001482205652070069
Trained batch 63 in epoch 4, gen_loss = 2.0383716635406017, disc_loss = 0.0014826717124378774
Trained batch 64 in epoch 4, gen_loss = 2.03529358460353, disc_loss = 0.0014734304886168013
Trained batch 65 in epoch 4, gen_loss = 2.0378921086137947, disc_loss = 0.001467375728569812
Trained batch 66 in epoch 4, gen_loss = 2.036055324682549, disc_loss = 0.0014723185084954795
Trained batch 67 in epoch 4, gen_loss = 2.0327330073889565, disc_loss = 0.0015047282709822279
Trained batch 68 in epoch 4, gen_loss = 2.0318956064141314, disc_loss = 0.0015307277174450564
Trained batch 69 in epoch 4, gen_loss = 2.0310000828334265, disc_loss = 0.0015375815514874246
Trained batch 70 in epoch 4, gen_loss = 2.027131928524501, disc_loss = 0.0015340063009332394
Trained batch 71 in epoch 4, gen_loss = 2.0287779519955316, disc_loss = 0.0015318493517245063
Trained batch 72 in epoch 4, gen_loss = 2.029528691344065, disc_loss = 0.0015201746726931672
Trained batch 73 in epoch 4, gen_loss = 2.0313029530886055, disc_loss = 0.001517194215478879
Trained batch 74 in epoch 4, gen_loss = 2.029339567820231, disc_loss = 0.00152669908090805
Trained batch 75 in epoch 4, gen_loss = 2.02660692365546, disc_loss = 0.001538170384408563
Trained batch 76 in epoch 4, gen_loss = 2.0274074015679298, disc_loss = 0.0015477839692544144
Trained batch 77 in epoch 4, gen_loss = 2.0281146459090404, disc_loss = 0.0015463290358475673
Trained batch 78 in epoch 4, gen_loss = 2.02929196780241, disc_loss = 0.001536346517379478
Trained batch 79 in epoch 4, gen_loss = 2.027855010330677, disc_loss = 0.0015265295303834136
Trained batch 80 in epoch 4, gen_loss = 2.0275032873506897, disc_loss = 0.0015161722125255582
Trained batch 81 in epoch 4, gen_loss = 2.0285756064624323, disc_loss = 0.0015054864215482845
Trained batch 82 in epoch 4, gen_loss = 2.032560150307345, disc_loss = 0.0014939457893438906
Trained batch 83 in epoch 4, gen_loss = 2.0365362876937505, disc_loss = 0.0014819266652921215
Trained batch 84 in epoch 4, gen_loss = 2.0374922780429614, disc_loss = 0.001471473355366684
Trained batch 85 in epoch 4, gen_loss = 2.039730352024699, disc_loss = 0.0014635663226430931
Trained batch 86 in epoch 4, gen_loss = 2.040926324910131, disc_loss = 0.0014597184791486583
Trained batch 87 in epoch 4, gen_loss = 2.041180827400901, disc_loss = 0.0014579532666671598
Trained batch 88 in epoch 4, gen_loss = 2.03978486141462, disc_loss = 0.0014565677828092673
Trained batch 89 in epoch 4, gen_loss = 2.037186786863539, disc_loss = 0.001454052297372578
Trained batch 90 in epoch 4, gen_loss = 2.0363956729134363, disc_loss = 0.0014557971658727543
Trained batch 91 in epoch 4, gen_loss = 2.0373912246330925, disc_loss = 0.001461312553779546
Trained batch 92 in epoch 4, gen_loss = 2.0377705891927085, disc_loss = 0.0014660890015112536
Trained batch 93 in epoch 4, gen_loss = 2.039115768797854, disc_loss = 0.0014682434904240468
Trained batch 94 in epoch 4, gen_loss = 2.0376777372862165, disc_loss = 0.0014638289594777712
Trained batch 95 in epoch 4, gen_loss = 2.0407537867625556, disc_loss = 0.0014579349729804865
Trained batch 96 in epoch 4, gen_loss = 2.041105835708146, disc_loss = 0.001451886732481689
Trained batch 97 in epoch 4, gen_loss = 2.040749576626992, disc_loss = 0.0014521699815712944
Trained batch 98 in epoch 4, gen_loss = 2.041812398216941, disc_loss = 0.0014538820027467803
Trained batch 99 in epoch 4, gen_loss = 2.043337411880493, disc_loss = 0.0014513898821314796
Trained batch 100 in epoch 4, gen_loss = 2.048543861596891, disc_loss = 0.0014450634630295532
Trained batch 101 in epoch 4, gen_loss = 2.0523021151037777, disc_loss = 0.0014377295618246803
Trained batch 102 in epoch 4, gen_loss = 2.0552953099741518, disc_loss = 0.0014310804025034953
Trained batch 103 in epoch 4, gen_loss = 2.0522372963336797, disc_loss = 0.001423327309916763
Trained batch 104 in epoch 4, gen_loss = 2.0525250446228753, disc_loss = 0.0014140925647336102
Trained batch 105 in epoch 4, gen_loss = 2.053848200249222, disc_loss = 0.0014074062829714199
Trained batch 106 in epoch 4, gen_loss = 2.051491038821568, disc_loss = 0.0014012606959206827
Trained batch 107 in epoch 4, gen_loss = 2.0518471631738873, disc_loss = 0.001395789738227096
Trained batch 108 in epoch 4, gen_loss = 2.05449960975472, disc_loss = 0.0013937332022319966
Trained batch 109 in epoch 4, gen_loss = 2.0545741525563326, disc_loss = 0.0013928261649032885
Trained batch 110 in epoch 4, gen_loss = 2.0544437814403222, disc_loss = 0.0013920754080990682
Trained batch 111 in epoch 4, gen_loss = 2.0587116639528955, disc_loss = 0.0013959306182057065
Trained batch 112 in epoch 4, gen_loss = 2.0579832338653836, disc_loss = 0.001398040816204342
Trained batch 113 in epoch 4, gen_loss = 2.0585548375782214, disc_loss = 0.0013942809462988454
Trained batch 114 in epoch 4, gen_loss = 2.0597324785978897, disc_loss = 0.001387297251747678
Trained batch 115 in epoch 4, gen_loss = 2.0596476217796065, disc_loss = 0.0013818875384709701
Trained batch 116 in epoch 4, gen_loss = 2.0604702978052645, disc_loss = 0.0013771861041378644
Trained batch 117 in epoch 4, gen_loss = 2.0587792406647893, disc_loss = 0.0013725486420237032
Trained batch 118 in epoch 4, gen_loss = 2.0635636744378996, disc_loss = 0.0013693824064127413
Trained batch 119 in epoch 4, gen_loss = 2.063481731216113, disc_loss = 0.0013708659214898943
Trained batch 120 in epoch 4, gen_loss = 2.0620357773520728, disc_loss = 0.0013737115943573477
Trained batch 121 in epoch 4, gen_loss = 2.0619656121144527, disc_loss = 0.0013760688140240238
Trained batch 122 in epoch 4, gen_loss = 2.0614248291263735, disc_loss = 0.0013803118741427495
Trained batch 123 in epoch 4, gen_loss = 2.0592591637565243, disc_loss = 0.0013818084468854772
Trained batch 124 in epoch 4, gen_loss = 2.0593237257003785, disc_loss = 0.0013798313718289138
Trained batch 125 in epoch 4, gen_loss = 2.057412844801706, disc_loss = 0.0013777702789945854
Trained batch 126 in epoch 4, gen_loss = 2.0584544731876044, disc_loss = 0.0013815260429932612
Trained batch 127 in epoch 4, gen_loss = 2.059276225976646, disc_loss = 0.0013950551347079454
Trained batch 128 in epoch 4, gen_loss = 2.0603544906128284, disc_loss = 0.0014200838365729235
Trained batch 129 in epoch 4, gen_loss = 2.0594966769218446, disc_loss = 0.0014503486436576798
Trained batch 130 in epoch 4, gen_loss = 2.0620470838692353, disc_loss = 0.0014713896449143422
Trained batch 131 in epoch 4, gen_loss = 2.058993477712978, disc_loss = 0.001480685580507711
Trained batch 132 in epoch 4, gen_loss = 2.059127346017307, disc_loss = 0.0014849862370892126
Trained batch 133 in epoch 4, gen_loss = 2.056660589887135, disc_loss = 0.0014865544299706261
Trained batch 134 in epoch 4, gen_loss = 2.05971788653621, disc_loss = 0.0014827540722089233
Trained batch 135 in epoch 4, gen_loss = 2.0592262569595787, disc_loss = 0.0014787635574226871
Trained batch 136 in epoch 4, gen_loss = 2.05826631079625, disc_loss = 0.0014759265285760274
Trained batch 137 in epoch 4, gen_loss = 2.0599657953649326, disc_loss = 0.0014732695029427607
Trained batch 138 in epoch 4, gen_loss = 2.0596030581769327, disc_loss = 0.0014696555704602021
Trained batch 139 in epoch 4, gen_loss = 2.0587068046842303, disc_loss = 0.0014657053447860691
Trained batch 140 in epoch 4, gen_loss = 2.060572624206543, disc_loss = 0.0014600643375393082
Trained batch 141 in epoch 4, gen_loss = 2.060554007409324, disc_loss = 0.00145297659754517
Trained batch 142 in epoch 4, gen_loss = 2.0599861019974823, disc_loss = 0.0014472367368977177
Trained batch 143 in epoch 4, gen_loss = 2.058517010675536, disc_loss = 0.001444376532971445
Trained batch 144 in epoch 4, gen_loss = 2.0588056103936556, disc_loss = 0.001443164111596757
Trained batch 145 in epoch 4, gen_loss = 2.058280251614035, disc_loss = 0.0014416678052727287
Trained batch 146 in epoch 4, gen_loss = 2.0570741307978726, disc_loss = 0.001446131412510057
Trained batch 147 in epoch 4, gen_loss = 2.0541527198778615, disc_loss = 0.0014574874878382764
Trained batch 148 in epoch 4, gen_loss = 2.050710395678578, disc_loss = 0.001462118090724185
Trained batch 149 in epoch 4, gen_loss = 2.0515951641400654, disc_loss = 0.0014585987199097871
Trained batch 150 in epoch 4, gen_loss = 2.050481410216022, disc_loss = 0.0014537514799539716
Trained batch 151 in epoch 4, gen_loss = 2.0498110220620505, disc_loss = 0.0014497806145013065
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.8113296031951904, disc_loss = 0.0014223187463358045
Trained batch 1 in epoch 5, gen_loss = 2.023805022239685, disc_loss = 0.0014092963538132608
Trained batch 2 in epoch 5, gen_loss = 1.9536633491516113, disc_loss = 0.0013039537395040195
Trained batch 3 in epoch 5, gen_loss = 1.889491856098175, disc_loss = 0.001223945087986067
Trained batch 4 in epoch 5, gen_loss = 1.9139799118041991, disc_loss = 0.0013192824088037014
Trained batch 5 in epoch 5, gen_loss = 1.9199534058570862, disc_loss = 0.0013750286501211424
Trained batch 6 in epoch 5, gen_loss = 1.9130647693361555, disc_loss = 0.0013662612597857202
Trained batch 7 in epoch 5, gen_loss = 1.8909878879785538, disc_loss = 0.0013400687457760796
Trained batch 8 in epoch 5, gen_loss = 1.9194408920076158, disc_loss = 0.0013383925349141161
Trained batch 9 in epoch 5, gen_loss = 1.9108025074005126, disc_loss = 0.0013445520075038076
Trained batch 10 in epoch 5, gen_loss = 1.9666989066384055, disc_loss = 0.0013777194438840854
Trained batch 11 in epoch 5, gen_loss = 1.9828861951828003, disc_loss = 0.001400039967847988
Trained batch 12 in epoch 5, gen_loss = 1.9961367020240197, disc_loss = 0.0014254931235112823
Trained batch 13 in epoch 5, gen_loss = 1.9770111526761736, disc_loss = 0.0014275011490099132
Trained batch 14 in epoch 5, gen_loss = 1.9800743897755941, disc_loss = 0.001432779679695765
Trained batch 15 in epoch 5, gen_loss = 1.9992012083530426, disc_loss = 0.0014355845269165002
Trained batch 16 in epoch 5, gen_loss = 1.9872621087466968, disc_loss = 0.0014210773070397623
Trained batch 17 in epoch 5, gen_loss = 1.9807215134302776, disc_loss = 0.0014309922246158952
Trained batch 18 in epoch 5, gen_loss = 1.9789933719133075, disc_loss = 0.0014614256307188618
Trained batch 19 in epoch 5, gen_loss = 2.0115555107593535, disc_loss = 0.0015049280656967313
Trained batch 20 in epoch 5, gen_loss = 2.0194260563169206, disc_loss = 0.0015311473149007984
Trained batch 21 in epoch 5, gen_loss = 2.032614041458477, disc_loss = 0.0015230698098259215
Trained batch 22 in epoch 5, gen_loss = 2.040339848269587, disc_loss = 0.001491611676655062
Trained batch 23 in epoch 5, gen_loss = 2.032629589239756, disc_loss = 0.0014581842672972318
Trained batch 24 in epoch 5, gen_loss = 2.0369303226470947, disc_loss = 0.0014221863728016615
Trained batch 25 in epoch 5, gen_loss = 2.0427269843908458, disc_loss = 0.001396583675299413
Trained batch 26 in epoch 5, gen_loss = 2.041000520741498, disc_loss = 0.0013824017563213904
Trained batch 27 in epoch 5, gen_loss = 2.035528485264097, disc_loss = 0.001359978983860596
Trained batch 28 in epoch 5, gen_loss = 2.0372692099932967, disc_loss = 0.0013331827719631638
Trained batch 29 in epoch 5, gen_loss = 2.030972484747569, disc_loss = 0.0013054849405307323
Trained batch 30 in epoch 5, gen_loss = 2.0293602020509782, disc_loss = 0.0012820114197600032
Trained batch 31 in epoch 5, gen_loss = 2.029205299913883, disc_loss = 0.0012660925731324824
Trained batch 32 in epoch 5, gen_loss = 2.0222617496143687, disc_loss = 0.0012764189106581564
Trained batch 33 in epoch 5, gen_loss = 2.017479826422299, disc_loss = 0.001301533985978869
Trained batch 34 in epoch 5, gen_loss = 2.0230046136038644, disc_loss = 0.0013152656727470457
Trained batch 35 in epoch 5, gen_loss = 2.0201626817385354, disc_loss = 0.0013199440064555448
Trained batch 36 in epoch 5, gen_loss = 2.0308065092241443, disc_loss = 0.001308866252657026
Trained batch 37 in epoch 5, gen_loss = 2.0392838653765226, disc_loss = 0.0012896051814191435
Trained batch 38 in epoch 5, gen_loss = 2.0422093318058896, disc_loss = 0.001272194033775192
Trained batch 39 in epoch 5, gen_loss = 2.0493395209312437, disc_loss = 0.001258923656132538
Trained batch 40 in epoch 5, gen_loss = 2.046322837108519, disc_loss = 0.0012452512590509907
Trained batch 41 in epoch 5, gen_loss = 2.0503295291037786, disc_loss = 0.0012326327033363106
Trained batch 42 in epoch 5, gen_loss = 2.0424789439800173, disc_loss = 0.001224371918672046
Trained batch 43 in epoch 5, gen_loss = 2.0348727350885216, disc_loss = 0.0012205997958186674
Trained batch 44 in epoch 5, gen_loss = 2.034767010476854, disc_loss = 0.0012148631115754445
Trained batch 45 in epoch 5, gen_loss = 2.030061185359955, disc_loss = 0.0012092302609032588
Trained batch 46 in epoch 5, gen_loss = 2.0251571853110133, disc_loss = 0.0012249260957531156
Trained batch 47 in epoch 5, gen_loss = 2.025994636118412, disc_loss = 0.0012364058250871797
Trained batch 48 in epoch 5, gen_loss = 2.0328727814615988, disc_loss = 0.0012520185757276354
Trained batch 49 in epoch 5, gen_loss = 2.032937858104706, disc_loss = 0.0012610020861029624
Trained batch 50 in epoch 5, gen_loss = 2.034239402004317, disc_loss = 0.0012594628143215588
Trained batch 51 in epoch 5, gen_loss = 2.0358699628939996, disc_loss = 0.0012543619534251494
Trained batch 52 in epoch 5, gen_loss = 2.038270592689514, disc_loss = 0.001245016035544774
Trained batch 53 in epoch 5, gen_loss = 2.036409272087945, disc_loss = 0.0012392443205937053
Trained batch 54 in epoch 5, gen_loss = 2.037418911673806, disc_loss = 0.0012430721904489804
Trained batch 55 in epoch 5, gen_loss = 2.039366219724928, disc_loss = 0.0012675910974004573
Trained batch 56 in epoch 5, gen_loss = 2.04100619700917, disc_loss = 0.001311791592007993
Trained batch 57 in epoch 5, gen_loss = 2.041134710969596, disc_loss = 0.0013649491081415709
Trained batch 58 in epoch 5, gen_loss = 2.047534498117738, disc_loss = 0.001417624840110351
Trained batch 59 in epoch 5, gen_loss = 2.051030151049296, disc_loss = 0.0014640539389802142
Trained batch 60 in epoch 5, gen_loss = 2.0471165453801388, disc_loss = 0.0015006467602673734
Trained batch 61 in epoch 5, gen_loss = 2.045256995385693, disc_loss = 0.001515626318700191
Trained batch 62 in epoch 5, gen_loss = 2.0437979925246466, disc_loss = 0.0015150132332189335
Trained batch 63 in epoch 5, gen_loss = 2.050678450614214, disc_loss = 0.0015045754853417748
Trained batch 64 in epoch 5, gen_loss = 2.049628505339989, disc_loss = 0.0014915232510807422
Trained batch 65 in epoch 5, gen_loss = 2.042951974001798, disc_loss = 0.001488208373881538
Trained batch 66 in epoch 5, gen_loss = 2.038722109438768, disc_loss = 0.0014853650154962913
Trained batch 67 in epoch 5, gen_loss = 2.043822796905742, disc_loss = 0.001488022761323544
Trained batch 68 in epoch 5, gen_loss = 2.0486109498618306, disc_loss = 0.0014859472715255358
Trained batch 69 in epoch 5, gen_loss = 2.048649992261614, disc_loss = 0.0014780989465569812
Trained batch 70 in epoch 5, gen_loss = 2.0467702486145662, disc_loss = 0.001470133604016155
Trained batch 71 in epoch 5, gen_loss = 2.0492761350340314, disc_loss = 0.0014597597481851052
Trained batch 72 in epoch 5, gen_loss = 2.0527150810581363, disc_loss = 0.0014477299027183183
Trained batch 73 in epoch 5, gen_loss = 2.058240975882556, disc_loss = 0.0014368218473611854
Trained batch 74 in epoch 5, gen_loss = 2.058734443982442, disc_loss = 0.0014272656897082925
Trained batch 75 in epoch 5, gen_loss = 2.0546987888060118, disc_loss = 0.001427010297591455
Trained batch 76 in epoch 5, gen_loss = 2.051544754536121, disc_loss = 0.0014346770794046197
Trained batch 77 in epoch 5, gen_loss = 2.053545436797998, disc_loss = 0.0014491865026334731
Trained batch 78 in epoch 5, gen_loss = 2.0558950735043875, disc_loss = 0.0014770129397865149
Trained batch 79 in epoch 5, gen_loss = 2.055934597551823, disc_loss = 0.0015085465725860558
Trained batch 80 in epoch 5, gen_loss = 2.052578384493604, disc_loss = 0.0015270962612703443
Trained batch 81 in epoch 5, gen_loss = 2.0584727147730386, disc_loss = 0.0015293729900405174
Trained batch 82 in epoch 5, gen_loss = 2.0559062139097466, disc_loss = 0.0015217238975441959
Trained batch 83 in epoch 5, gen_loss = 2.055071772564025, disc_loss = 0.0015162172577609973
Trained batch 84 in epoch 5, gen_loss = 2.05145884401658, disc_loss = 0.00150843357653631
Trained batch 85 in epoch 5, gen_loss = 2.0498199878736982, disc_loss = 0.0014990132774475443
Trained batch 86 in epoch 5, gen_loss = 2.052417946957994, disc_loss = 0.0014907646223089133
Trained batch 87 in epoch 5, gen_loss = 2.05547294291583, disc_loss = 0.0014842454362554815
Trained batch 88 in epoch 5, gen_loss = 2.055820443657007, disc_loss = 0.0014843474327994699
Trained batch 89 in epoch 5, gen_loss = 2.0521265758408442, disc_loss = 0.0014880969499548276
Trained batch 90 in epoch 5, gen_loss = 2.051296578658806, disc_loss = 0.001488947803359274
Trained batch 91 in epoch 5, gen_loss = 2.049042270235393, disc_loss = 0.0014853511782585765
Trained batch 92 in epoch 5, gen_loss = 2.0459267554744596, disc_loss = 0.001478694543938443
Trained batch 93 in epoch 5, gen_loss = 2.0508038084557714, disc_loss = 0.0014702105000516043
Trained batch 94 in epoch 5, gen_loss = 2.0510777774610016, disc_loss = 0.0014610047740126518
Trained batch 95 in epoch 5, gen_loss = 2.0493776152531304, disc_loss = 0.0014515387235102632
Trained batch 96 in epoch 5, gen_loss = 2.0511043858282343, disc_loss = 0.0014432494392973784
Trained batch 97 in epoch 5, gen_loss = 2.0520494714075204, disc_loss = 0.0014361777136159338
Trained batch 98 in epoch 5, gen_loss = 2.050108461668997, disc_loss = 0.001430863519246229
Trained batch 99 in epoch 5, gen_loss = 2.0516127443313597, disc_loss = 0.0014287174795754253
Trained batch 100 in epoch 5, gen_loss = 2.0540607754546816, disc_loss = 0.0014310558188227144
Trained batch 101 in epoch 5, gen_loss = 2.0530202692630244, disc_loss = 0.0014345800120602636
Trained batch 102 in epoch 5, gen_loss = 2.050267426712999, disc_loss = 0.0014367820875881945
Trained batch 103 in epoch 5, gen_loss = 2.051469916334519, disc_loss = 0.0014407499447070921
Trained batch 104 in epoch 5, gen_loss = 2.0496249982288908, disc_loss = 0.0014431780758535578
Trained batch 105 in epoch 5, gen_loss = 2.0489346036371194, disc_loss = 0.0014392413849116496
Trained batch 106 in epoch 5, gen_loss = 2.049473377031701, disc_loss = 0.0014311902161913915
Trained batch 107 in epoch 5, gen_loss = 2.048219602417063, disc_loss = 0.001425431889300752
Trained batch 108 in epoch 5, gen_loss = 2.0472390990738476, disc_loss = 0.0014237847548712968
Trained batch 109 in epoch 5, gen_loss = 2.0465747529810123, disc_loss = 0.0014256756043654274
Trained batch 110 in epoch 5, gen_loss = 2.049070487151275, disc_loss = 0.0014272157337751475
Trained batch 111 in epoch 5, gen_loss = 2.051300483090537, disc_loss = 0.0014242300686808968
Trained batch 112 in epoch 5, gen_loss = 2.0501223686522088, disc_loss = 0.0014174513259193802
Trained batch 113 in epoch 5, gen_loss = 2.049223774357846, disc_loss = 0.0014099461167413545
Trained batch 114 in epoch 5, gen_loss = 2.048999129170957, disc_loss = 0.0014015865342630802
Trained batch 115 in epoch 5, gen_loss = 2.047997023524909, disc_loss = 0.0013969940570452057
Trained batch 116 in epoch 5, gen_loss = 2.050705515421354, disc_loss = 0.0013937286146554267
Trained batch 117 in epoch 5, gen_loss = 2.0508514228513683, disc_loss = 0.001392248609267033
Trained batch 118 in epoch 5, gen_loss = 2.0466926508590957, disc_loss = 0.0013897994877046615
Trained batch 119 in epoch 5, gen_loss = 2.0501790195703506, disc_loss = 0.0013855179507421174
Trained batch 120 in epoch 5, gen_loss = 2.053145750495028, disc_loss = 0.0013861772688471305
Trained batch 121 in epoch 5, gen_loss = 2.055132206346168, disc_loss = 0.0013914893648003183
Trained batch 122 in epoch 5, gen_loss = 2.0548991100574896, disc_loss = 0.0013992307464898814
Trained batch 123 in epoch 5, gen_loss = 2.0557361639315084, disc_loss = 0.001408883239726551
Trained batch 124 in epoch 5, gen_loss = 2.053505148887634, disc_loss = 0.0014195296771358698
Trained batch 125 in epoch 5, gen_loss = 2.055648950357286, disc_loss = 0.0014249366707637877
Trained batch 126 in epoch 5, gen_loss = 2.05629092971171, disc_loss = 0.0014236690630076644
Trained batch 127 in epoch 5, gen_loss = 2.0551292756572366, disc_loss = 0.001423572505473203
Trained batch 128 in epoch 5, gen_loss = 2.053975281789321, disc_loss = 0.0014223054133972889
Trained batch 129 in epoch 5, gen_loss = 2.0546870735975413, disc_loss = 0.001416009389840138
Trained batch 130 in epoch 5, gen_loss = 2.0527898209695596, disc_loss = 0.00140922742861124
Trained batch 131 in epoch 5, gen_loss = 2.0527814102895334, disc_loss = 0.0014049415395041278
Trained batch 132 in epoch 5, gen_loss = 2.0512858853304294, disc_loss = 0.0014010321042987105
Trained batch 133 in epoch 5, gen_loss = 2.0491400974899974, disc_loss = 0.0013995439671205857
Trained batch 134 in epoch 5, gen_loss = 2.0495491133795842, disc_loss = 0.0013988953844764856
Trained batch 135 in epoch 5, gen_loss = 2.0476424168137943, disc_loss = 0.001398053775440477
Trained batch 136 in epoch 5, gen_loss = 2.0460326132113047, disc_loss = 0.0013956434799130516
Trained batch 137 in epoch 5, gen_loss = 2.04439187568167, disc_loss = 0.0013915395874115031
Trained batch 138 in epoch 5, gen_loss = 2.043457225072298, disc_loss = 0.0013857421822420475
Trained batch 139 in epoch 5, gen_loss = 2.044451974119459, disc_loss = 0.0013826254599345184
Trained batch 140 in epoch 5, gen_loss = 2.0433639178039336, disc_loss = 0.001387317938414726
Trained batch 141 in epoch 5, gen_loss = 2.042241889826009, disc_loss = 0.0013978971673821716
Trained batch 142 in epoch 5, gen_loss = 2.040747518306012, disc_loss = 0.0014097206516376977
Trained batch 143 in epoch 5, gen_loss = 2.0419934516151748, disc_loss = 0.0014134386852270432
Trained batch 144 in epoch 5, gen_loss = 2.041986793485181, disc_loss = 0.0014105988066274158
Trained batch 145 in epoch 5, gen_loss = 2.0434117619305443, disc_loss = 0.0014051976918692587
Trained batch 146 in epoch 5, gen_loss = 2.0416496132506805, disc_loss = 0.001399535976222013
Trained batch 147 in epoch 5, gen_loss = 2.0408433498562992, disc_loss = 0.0013938915270390116
Trained batch 148 in epoch 5, gen_loss = 2.0409562907762977, disc_loss = 0.0013887054072427344
Trained batch 149 in epoch 5, gen_loss = 2.0415451272328693, disc_loss = 0.0013867836924813066
Trained batch 150 in epoch 5, gen_loss = 2.0423864465675607, disc_loss = 0.001391136662422414
Trained batch 151 in epoch 5, gen_loss = 2.0428776976309324, disc_loss = 0.0013951872547056012
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.9671286344528198, disc_loss = 0.0013567812275141478
Trained batch 1 in epoch 6, gen_loss = 1.9795172810554504, disc_loss = 0.0010300208232365549
Trained batch 2 in epoch 6, gen_loss = 1.9211697578430176, disc_loss = 0.0008271795619900028
Trained batch 3 in epoch 6, gen_loss = 1.9266147017478943, disc_loss = 0.0007331338274525478
Trained batch 4 in epoch 6, gen_loss = 1.9317954540252686, disc_loss = 0.0007079228875227272
Trained batch 5 in epoch 6, gen_loss = 1.9916472832361858, disc_loss = 0.0006946732270686576
Trained batch 6 in epoch 6, gen_loss = 2.049034833908081, disc_loss = 0.0007187768767055656
Trained batch 7 in epoch 6, gen_loss = 2.0072349160909653, disc_loss = 0.0008622484383522533
Trained batch 8 in epoch 6, gen_loss = 2.0389932923846774, disc_loss = 0.0010310523923382992
Trained batch 9 in epoch 6, gen_loss = 2.02939532995224, disc_loss = 0.0010827066435012966
Trained batch 10 in epoch 6, gen_loss = 2.0284775495529175, disc_loss = 0.0010672381348823283
Trained batch 11 in epoch 6, gen_loss = 2.007461041212082, disc_loss = 0.0010301613656338304
Trained batch 12 in epoch 6, gen_loss = 2.010143857735854, disc_loss = 0.000999666490735343
Trained batch 13 in epoch 6, gen_loss = 2.0331199765205383, disc_loss = 0.0009759179208361145
Trained batch 14 in epoch 6, gen_loss = 2.064991021156311, disc_loss = 0.0009419468658355375
Trained batch 15 in epoch 6, gen_loss = 2.0514649152755737, disc_loss = 0.0009117373483604752
Trained batch 16 in epoch 6, gen_loss = 2.054919817868401, disc_loss = 0.0008945022949346286
Trained batch 17 in epoch 6, gen_loss = 2.053427391582065, disc_loss = 0.0008754892785671271
Trained batch 18 in epoch 6, gen_loss = 2.0503608866741785, disc_loss = 0.0008591052028350532
Trained batch 19 in epoch 6, gen_loss = 2.052474170923233, disc_loss = 0.0008407038316363469
Trained batch 20 in epoch 6, gen_loss = 2.0574236540567306, disc_loss = 0.0008213397079435665
Trained batch 21 in epoch 6, gen_loss = 2.066879537972537, disc_loss = 0.0008013859200714664
Trained batch 22 in epoch 6, gen_loss = 2.0518314579258794, disc_loss = 0.0007900865444832522
Trained batch 23 in epoch 6, gen_loss = 2.0369482139746347, disc_loss = 0.000781351392409609
Trained batch 24 in epoch 6, gen_loss = 2.0248140239715577, disc_loss = 0.000774094162043184
Trained batch 25 in epoch 6, gen_loss = 2.0349951890798716, disc_loss = 0.0007616821486198415
Trained batch 26 in epoch 6, gen_loss = 2.034261253145006, disc_loss = 0.0007508693131428488
Trained batch 27 in epoch 6, gen_loss = 2.036276238305228, disc_loss = 0.0007374096624386896
Trained batch 28 in epoch 6, gen_loss = 2.0418654392505515, disc_loss = 0.0007236916170423401
Trained batch 29 in epoch 6, gen_loss = 2.0485735813776653, disc_loss = 0.0007113596773706376
Trained batch 30 in epoch 6, gen_loss = 2.0461661508006435, disc_loss = 0.0007099444478479845
Trained batch 31 in epoch 6, gen_loss = 2.047987185418606, disc_loss = 0.0007218922746687895
Trained batch 32 in epoch 6, gen_loss = 2.058395754207264, disc_loss = 0.0007367599455667942
Trained batch 33 in epoch 6, gen_loss = 2.0572036504745483, disc_loss = 0.0007657297349343186
Trained batch 34 in epoch 6, gen_loss = 2.060009138924735, disc_loss = 0.000794246348751975
Trained batch 35 in epoch 6, gen_loss = 2.053472618261973, disc_loss = 0.0008161957327198858
Trained batch 36 in epoch 6, gen_loss = 2.054948665000297, disc_loss = 0.0008258077054838272
Trained batch 37 in epoch 6, gen_loss = 2.0557729821456108, disc_loss = 0.0008230161696893015
Trained batch 38 in epoch 6, gen_loss = 2.0588311782250037, disc_loss = 0.0008215375993854534
Trained batch 39 in epoch 6, gen_loss = 2.0575741648674013, disc_loss = 0.0008316906561958604
Trained batch 40 in epoch 6, gen_loss = 2.054922319040066, disc_loss = 0.0008421005502275032
Trained batch 41 in epoch 6, gen_loss = 2.0578726870673045, disc_loss = 0.0008395956676741619
Trained batch 42 in epoch 6, gen_loss = 2.051195349804191, disc_loss = 0.0008309147527798751
Trained batch 43 in epoch 6, gen_loss = 2.0546011491255327, disc_loss = 0.0008193083174939437
Trained batch 44 in epoch 6, gen_loss = 2.053497372733222, disc_loss = 0.0008098149652748058
Trained batch 45 in epoch 6, gen_loss = 2.061529812605485, disc_loss = 0.0008043571313306609
Trained batch 46 in epoch 6, gen_loss = 2.058489497671736, disc_loss = 0.0008038111592078225
Trained batch 47 in epoch 6, gen_loss = 2.058640825251738, disc_loss = 0.0008068205722035297
Trained batch 48 in epoch 6, gen_loss = 2.0621882141852867, disc_loss = 0.0008040387070576223
Trained batch 49 in epoch 6, gen_loss = 2.069795768260956, disc_loss = 0.0008024354028748348
Trained batch 50 in epoch 6, gen_loss = 2.0698215470594516, disc_loss = 0.0008085246052930825
Trained batch 51 in epoch 6, gen_loss = 2.0608358727051663, disc_loss = 0.0008199961275050344
Trained batch 52 in epoch 6, gen_loss = 2.0597428803174003, disc_loss = 0.0008227325484973713
Trained batch 53 in epoch 6, gen_loss = 2.0577407633816756, disc_loss = 0.0008207757647916744
Trained batch 54 in epoch 6, gen_loss = 2.0620087320154363, disc_loss = 0.0008176445733459497
Trained batch 55 in epoch 6, gen_loss = 2.064519601208823, disc_loss = 0.0008177314599119459
Trained batch 56 in epoch 6, gen_loss = 2.067566913470887, disc_loss = 0.000818267833796869
Trained batch 57 in epoch 6, gen_loss = 2.067913162297216, disc_loss = 0.0008174410387913793
Trained batch 58 in epoch 6, gen_loss = 2.068116107229459, disc_loss = 0.0008199112494752379
Trained batch 59 in epoch 6, gen_loss = 2.0648776551087695, disc_loss = 0.0008299415722528163
Trained batch 60 in epoch 6, gen_loss = 2.0600177069179346, disc_loss = 0.0008415849025353606
Trained batch 61 in epoch 6, gen_loss = 2.062742148676226, disc_loss = 0.000842387841980634
Trained batch 62 in epoch 6, gen_loss = 2.0596322634863475, disc_loss = 0.0008357864234500402
Trained batch 63 in epoch 6, gen_loss = 2.056677984073758, disc_loss = 0.0008315414938806498
Trained batch 64 in epoch 6, gen_loss = 2.0548606597460233, disc_loss = 0.0008295148928972104
Trained batch 65 in epoch 6, gen_loss = 2.051936052062295, disc_loss = 0.0008290485486875034
Trained batch 66 in epoch 6, gen_loss = 2.058206181027996, disc_loss = 0.000826426631850955
Trained batch 67 in epoch 6, gen_loss = 2.057223512845881, disc_loss = 0.0008266142561778371
Trained batch 68 in epoch 6, gen_loss = 2.056726604268171, disc_loss = 0.0008310712076743822
Trained batch 69 in epoch 6, gen_loss = 2.0525177887507846, disc_loss = 0.0008389710760509063
Trained batch 70 in epoch 6, gen_loss = 2.0549243638213253, disc_loss = 0.0008532265344680562
Trained batch 71 in epoch 6, gen_loss = 2.0527338749832578, disc_loss = 0.0008644238546872253
Trained batch 72 in epoch 6, gen_loss = 2.0549505181508523, disc_loss = 0.0008704978952739286
Trained batch 73 in epoch 6, gen_loss = 2.0560541442922644, disc_loss = 0.0008682715348628777
Trained batch 74 in epoch 6, gen_loss = 2.062774518330892, disc_loss = 0.0008620885903170953
Trained batch 75 in epoch 6, gen_loss = 2.065787823576676, disc_loss = 0.0008570529665264889
Trained batch 76 in epoch 6, gen_loss = 2.059927965139414, disc_loss = 0.0008526874064352944
Trained batch 77 in epoch 6, gen_loss = 2.0606462283012195, disc_loss = 0.0008489555035246154
Trained batch 78 in epoch 6, gen_loss = 2.0601696243769005, disc_loss = 0.0008444142925016629
Trained batch 79 in epoch 6, gen_loss = 2.0573775440454485, disc_loss = 0.0008396158988034586
Trained batch 80 in epoch 6, gen_loss = 2.0533723257206105, disc_loss = 0.0008408215976992829
Trained batch 81 in epoch 6, gen_loss = 2.051502115842773, disc_loss = 0.0008467728078291501
Trained batch 82 in epoch 6, gen_loss = 2.052709253437548, disc_loss = 0.0008521913000275886
Trained batch 83 in epoch 6, gen_loss = 2.051518533911024, disc_loss = 0.0008553067853513529
Trained batch 84 in epoch 6, gen_loss = 2.0547533427967744, disc_loss = 0.0008557279275812427
Trained batch 85 in epoch 6, gen_loss = 2.053840814634811, disc_loss = 0.0008539312358723606
Trained batch 86 in epoch 6, gen_loss = 2.053741290651519, disc_loss = 0.0008505985803832568
Trained batch 87 in epoch 6, gen_loss = 2.056799842552705, disc_loss = 0.0008475631677191069
Trained batch 88 in epoch 6, gen_loss = 2.0561653308654098, disc_loss = 0.000845766707723751
Trained batch 89 in epoch 6, gen_loss = 2.053388158480326, disc_loss = 0.000849279020460219
Trained batch 90 in epoch 6, gen_loss = 2.054389075918512, disc_loss = 0.0008551575896550216
Trained batch 91 in epoch 6, gen_loss = 2.0529054144154424, disc_loss = 0.0008616249115616286
Trained batch 92 in epoch 6, gen_loss = 2.0495707424738074, disc_loss = 0.0008664493907808817
Trained batch 93 in epoch 6, gen_loss = 2.0502990813965494, disc_loss = 0.0008676214607437439
Trained batch 94 in epoch 6, gen_loss = 2.056711779142681, disc_loss = 0.0008662602217794445
Trained batch 95 in epoch 6, gen_loss = 2.056135723988215, disc_loss = 0.0008630019895766358
Trained batch 96 in epoch 6, gen_loss = 2.054024757798185, disc_loss = 0.0008602712189985113
Trained batch 97 in epoch 6, gen_loss = 2.056150137161722, disc_loss = 0.0008677634186638823
Trained batch 98 in epoch 6, gen_loss = 2.0596759343388107, disc_loss = 0.0008786846845377839
Trained batch 99 in epoch 6, gen_loss = 2.0561933445930483, disc_loss = 0.0008842724058195018
Trained batch 100 in epoch 6, gen_loss = 2.0554346684182043, disc_loss = 0.0008854258786495038
Trained batch 101 in epoch 6, gen_loss = 2.0546631497495316, disc_loss = 0.0008860367790261722
Trained batch 102 in epoch 6, gen_loss = 2.054982936498031, disc_loss = 0.0008927237406911021
Trained batch 103 in epoch 6, gen_loss = 2.0547091903594823, disc_loss = 0.0009037997870809005
Trained batch 104 in epoch 6, gen_loss = 2.0577390386944727, disc_loss = 0.000907910269008772
Trained batch 105 in epoch 6, gen_loss = 2.0579840158516505, disc_loss = 0.0009075794075198366
Trained batch 106 in epoch 6, gen_loss = 2.05927756010929, disc_loss = 0.0009062461161694411
Trained batch 107 in epoch 6, gen_loss = 2.0598566587324494, disc_loss = 0.0009020111468055768
Trained batch 108 in epoch 6, gen_loss = 2.058004206473674, disc_loss = 0.0008986582400153366
Trained batch 109 in epoch 6, gen_loss = 2.0574422587047922, disc_loss = 0.0009017429862234911
Trained batch 110 in epoch 6, gen_loss = 2.054997232583192, disc_loss = 0.0009137854157833735
Trained batch 111 in epoch 6, gen_loss = 2.055326560778277, disc_loss = 0.0009370317355725481
Trained batch 112 in epoch 6, gen_loss = 2.054619952640702, disc_loss = 0.0009757244948656257
Trained batch 113 in epoch 6, gen_loss = 2.0521634963520787, disc_loss = 0.0010286607213314263
Trained batch 114 in epoch 6, gen_loss = 2.0505885393723196, disc_loss = 0.0010822549419295367
Trained batch 115 in epoch 6, gen_loss = 2.0475177826552557, disc_loss = 0.0011327552269433689
Trained batch 116 in epoch 6, gen_loss = 2.044724579550262, disc_loss = 0.001167378738337459
Trained batch 117 in epoch 6, gen_loss = 2.046612972930326, disc_loss = 0.0011744316195244349
Trained batch 118 in epoch 6, gen_loss = 2.046845962019528, disc_loss = 0.0011734285129198978
Trained batch 119 in epoch 6, gen_loss = 2.0444473375876746, disc_loss = 0.00117714572964663
Trained batch 120 in epoch 6, gen_loss = 2.0454612241303627, disc_loss = 0.0011781882578872668
Trained batch 121 in epoch 6, gen_loss = 2.0450465923450034, disc_loss = 0.0011766657982781132
Trained batch 122 in epoch 6, gen_loss = 2.0428455593140145, disc_loss = 0.0011722324181791032
Trained batch 123 in epoch 6, gen_loss = 2.041156856283065, disc_loss = 0.00116676725930677
Trained batch 124 in epoch 6, gen_loss = 2.040056065559387, disc_loss = 0.0011621018422301858
Trained batch 125 in epoch 6, gen_loss = 2.038343089913565, disc_loss = 0.0011567885907540572
Trained batch 126 in epoch 6, gen_loss = 2.0372910546505545, disc_loss = 0.0011514313580875293
Trained batch 127 in epoch 6, gen_loss = 2.0358657455071807, disc_loss = 0.0011478408075618063
Trained batch 128 in epoch 6, gen_loss = 2.037377408308576, disc_loss = 0.0011510333358111626
Trained batch 129 in epoch 6, gen_loss = 2.036810450370495, disc_loss = 0.0011574491426402417
Trained batch 130 in epoch 6, gen_loss = 2.0389390619656513, disc_loss = 0.0011626785567282693
Trained batch 131 in epoch 6, gen_loss = 2.037724902232488, disc_loss = 0.00116402859985652
Trained batch 132 in epoch 6, gen_loss = 2.0369933673313687, disc_loss = 0.0011602168799031358
Trained batch 133 in epoch 6, gen_loss = 2.0382877339178056, disc_loss = 0.0011541233365441352
Trained batch 134 in epoch 6, gen_loss = 2.037672342194451, disc_loss = 0.0011479768097935313
Trained batch 135 in epoch 6, gen_loss = 2.038667344871689, disc_loss = 0.001142263188418891
Trained batch 136 in epoch 6, gen_loss = 2.0371496581683193, disc_loss = 0.0011374629427675484
Trained batch 137 in epoch 6, gen_loss = 2.0339676927829133, disc_loss = 0.001132459387746707
Trained batch 138 in epoch 6, gen_loss = 2.032237254458366, disc_loss = 0.0011273000289672623
Trained batch 139 in epoch 6, gen_loss = 2.0321026827607835, disc_loss = 0.0011247878648906148
Trained batch 140 in epoch 6, gen_loss = 2.032076489840839, disc_loss = 0.0011214718576817912
Trained batch 141 in epoch 6, gen_loss = 2.0299715634802697, disc_loss = 0.0011165189996614239
Trained batch 142 in epoch 6, gen_loss = 2.0300746439220188, disc_loss = 0.0011124607174367467
Trained batch 143 in epoch 6, gen_loss = 2.029791375829114, disc_loss = 0.0011097286917194854
Trained batch 144 in epoch 6, gen_loss = 2.027480196130687, disc_loss = 0.0011092411452535025
Trained batch 145 in epoch 6, gen_loss = 2.025300866936984, disc_loss = 0.0011077337754389577
Trained batch 146 in epoch 6, gen_loss = 2.023767895439044, disc_loss = 0.0011041890819902297
Trained batch 147 in epoch 6, gen_loss = 2.0231990290654673, disc_loss = 0.0010992774196721085
Trained batch 148 in epoch 6, gen_loss = 2.024158086552716, disc_loss = 0.0010935975525421934
Trained batch 149 in epoch 6, gen_loss = 2.0248341298103334, disc_loss = 0.001088198870032405
Trained batch 150 in epoch 6, gen_loss = 2.0223256839032206, disc_loss = 0.0010844557950834416
Trained batch 151 in epoch 6, gen_loss = 2.023188518066155, disc_loss = 0.001080560649202916
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.4253828525543213, disc_loss = 0.0005267362575978041
Trained batch 1 in epoch 7, gen_loss = 2.1893117427825928, disc_loss = 0.0005514126387424767
Trained batch 2 in epoch 7, gen_loss = 2.0331956148147583, disc_loss = 0.0005460796334470311
Trained batch 3 in epoch 7, gen_loss = 1.9871909618377686, disc_loss = 0.0005521494895219803
Trained batch 4 in epoch 7, gen_loss = 1.9577967405319214, disc_loss = 0.0006442172918468714
Trained batch 5 in epoch 7, gen_loss = 1.9925166567166646, disc_loss = 0.0007796854479238391
Trained batch 6 in epoch 7, gen_loss = 1.9804322378976005, disc_loss = 0.0008411916205659509
Trained batch 7 in epoch 7, gen_loss = 1.9940242171287537, disc_loss = 0.0008077155944192782
Trained batch 8 in epoch 7, gen_loss = 1.9699845843844943, disc_loss = 0.0007739090166675547
Trained batch 9 in epoch 7, gen_loss = 1.978620171546936, disc_loss = 0.0007542711507994681
Trained batch 10 in epoch 7, gen_loss = 1.9750810102982954, disc_loss = 0.0007448691969991407
Trained batch 11 in epoch 7, gen_loss = 2.033994476000468, disc_loss = 0.0007468737215579798
Trained batch 12 in epoch 7, gen_loss = 2.0088553520349355, disc_loss = 0.0007632418553559826
Trained batch 13 in epoch 7, gen_loss = 2.0187226789338246, disc_loss = 0.0007732375857553311
Trained batch 14 in epoch 7, gen_loss = 2.014822793006897, disc_loss = 0.0007577142290150126
Trained batch 15 in epoch 7, gen_loss = 2.008576177060604, disc_loss = 0.0007363057920883875
Trained batch 16 in epoch 7, gen_loss = 2.027110653765061, disc_loss = 0.0007148471503408954
Trained batch 17 in epoch 7, gen_loss = 2.0168528424368963, disc_loss = 0.0007031031062878254
Trained batch 18 in epoch 7, gen_loss = 2.0191519009439567, disc_loss = 0.0006912263067390182
Trained batch 19 in epoch 7, gen_loss = 2.026515543460846, disc_loss = 0.0006914761412190274
Trained batch 20 in epoch 7, gen_loss = 2.0293291296277727, disc_loss = 0.0006869345698283897
Trained batch 21 in epoch 7, gen_loss = 2.034677516330372, disc_loss = 0.0006781740177592093
Trained batch 22 in epoch 7, gen_loss = 2.0325719014458032, disc_loss = 0.000664520400080263
Trained batch 23 in epoch 7, gen_loss = 2.0463104595740638, disc_loss = 0.000659369331212171
Trained batch 24 in epoch 7, gen_loss = 2.04565815448761, disc_loss = 0.0006828953896183521
Trained batch 25 in epoch 7, gen_loss = 2.052715929654928, disc_loss = 0.000754803653063181
Trained batch 26 in epoch 7, gen_loss = 2.0407874716652765, disc_loss = 0.0008566430780639941
Trained batch 27 in epoch 7, gen_loss = 2.045199066400528, disc_loss = 0.0009322111488602656
Trained batch 28 in epoch 7, gen_loss = 2.046761837498895, disc_loss = 0.0009641785040128462
Trained batch 29 in epoch 7, gen_loss = 2.0420748551686603, disc_loss = 0.0009704438668753331
Trained batch 30 in epoch 7, gen_loss = 2.0367519124861686, disc_loss = 0.0009615049320047781
Trained batch 31 in epoch 7, gen_loss = 2.0429963506758213, disc_loss = 0.0009507534987278632
Trained batch 32 in epoch 7, gen_loss = 2.0432014934944385, disc_loss = 0.0009504151980350302
Trained batch 33 in epoch 7, gen_loss = 2.0473944895407734, disc_loss = 0.0009551797334364999
Trained batch 34 in epoch 7, gen_loss = 2.044344861166818, disc_loss = 0.0009522015287075191
Trained batch 35 in epoch 7, gen_loss = 2.030685239368015, disc_loss = 0.0009455185653577144
Trained batch 36 in epoch 7, gen_loss = 2.0340920332315804, disc_loss = 0.0009546300948509393
Trained batch 37 in epoch 7, gen_loss = 2.0328279106240523, disc_loss = 0.000970180697071268
Trained batch 38 in epoch 7, gen_loss = 2.0389280991676526, disc_loss = 0.0009765048975495097
Trained batch 39 in epoch 7, gen_loss = 2.037368047237396, disc_loss = 0.0009747022959345486
Trained batch 40 in epoch 7, gen_loss = 2.0336863965522953, disc_loss = 0.0009646171742266543
Trained batch 41 in epoch 7, gen_loss = 2.0281900394530523, disc_loss = 0.0009507536707955989
Trained batch 42 in epoch 7, gen_loss = 2.0267335259637167, disc_loss = 0.0009373565052830895
Trained batch 43 in epoch 7, gen_loss = 2.0249361856417223, disc_loss = 0.0009236470571274615
Trained batch 44 in epoch 7, gen_loss = 2.016882003678216, disc_loss = 0.0009102505398914218
Trained batch 45 in epoch 7, gen_loss = 2.0066254890483357, disc_loss = 0.0009013015457995883
Trained batch 46 in epoch 7, gen_loss = 1.9999858470673257, disc_loss = 0.0008969677939139148
Trained batch 47 in epoch 7, gen_loss = 2.000771403312683, disc_loss = 0.000904811565609028
Trained batch 48 in epoch 7, gen_loss = 1.9993945214213158, disc_loss = 0.0009167378754069915
Trained batch 49 in epoch 7, gen_loss = 1.99529705286026, disc_loss = 0.0009360820893198252
Trained batch 50 in epoch 7, gen_loss = 1.9903215473773432, disc_loss = 0.0009444569689495599
Trained batch 51 in epoch 7, gen_loss = 1.9940406129910395, disc_loss = 0.0009360837284475565
Trained batch 52 in epoch 7, gen_loss = 1.9980180353488561, disc_loss = 0.0009268958721186895
Trained batch 53 in epoch 7, gen_loss = 1.9938062915095576, disc_loss = 0.0009250831262087795
Trained batch 54 in epoch 7, gen_loss = 1.9947948412461713, disc_loss = 0.0009264066296798939
Trained batch 55 in epoch 7, gen_loss = 1.9937225239617484, disc_loss = 0.000931412799608162
Trained batch 56 in epoch 7, gen_loss = 1.9922083595342803, disc_loss = 0.0009326058789156377
Trained batch 57 in epoch 7, gen_loss = 1.9899470210075378, disc_loss = 0.0009274412938072506
Trained batch 58 in epoch 7, gen_loss = 1.9906485989942388, disc_loss = 0.0009215095384298998
Trained batch 59 in epoch 7, gen_loss = 1.9902408063411712, disc_loss = 0.0009144975241118422
Trained batch 60 in epoch 7, gen_loss = 1.992968846539982, disc_loss = 0.0009080184056790027
Trained batch 61 in epoch 7, gen_loss = 1.9931378114608027, disc_loss = 0.0009036885720918015
Trained batch 62 in epoch 7, gen_loss = 1.995498746160477, disc_loss = 0.0009008433830569542
Trained batch 63 in epoch 7, gen_loss = 1.9906326904892921, disc_loss = 0.0008975934888439951
Trained batch 64 in epoch 7, gen_loss = 1.9974264034858116, disc_loss = 0.0008931862503791658
Trained batch 65 in epoch 7, gen_loss = 1.998932957649231, disc_loss = 0.0008871505772483281
Trained batch 66 in epoch 7, gen_loss = 1.9976261765209598, disc_loss = 0.0008812678374919985
Trained batch 67 in epoch 7, gen_loss = 1.9954139660386478, disc_loss = 0.0008747289624914308
Trained batch 68 in epoch 7, gen_loss = 1.996081144913383, disc_loss = 0.0008692264867325624
Trained batch 69 in epoch 7, gen_loss = 2.0009096077510287, disc_loss = 0.0008645241306762078
Trained batch 70 in epoch 7, gen_loss = 1.9997521823560689, disc_loss = 0.0008595806200542605
Trained batch 71 in epoch 7, gen_loss = 2.0014794402652316, disc_loss = 0.0008520368278873826
Trained batch 72 in epoch 7, gen_loss = 2.005091125017976, disc_loss = 0.0008466768569682968
Trained batch 73 in epoch 7, gen_loss = 2.0100400673376546, disc_loss = 0.0008468269244641871
Trained batch 74 in epoch 7, gen_loss = 2.008789184888204, disc_loss = 0.0008572596358135343
Trained batch 75 in epoch 7, gen_loss = 2.005145112150594, disc_loss = 0.0008783146025196306
Trained batch 76 in epoch 7, gen_loss = 2.0068034583872016, disc_loss = 0.0009110325164246289
Trained batch 77 in epoch 7, gen_loss = 2.004169048407139, disc_loss = 0.0009590578758014509
Trained batch 78 in epoch 7, gen_loss = 2.0009040108209923, disc_loss = 0.0010025579190541861
Trained batch 79 in epoch 7, gen_loss = 1.9985890448093415, disc_loss = 0.001024239278922323
Trained batch 80 in epoch 7, gen_loss = 2.000795535099359, disc_loss = 0.0010274885061346455
Trained batch 81 in epoch 7, gen_loss = 2.003773072870766, disc_loss = 0.0010238416498617791
Trained batch 82 in epoch 7, gen_loss = 2.0028919412429076, disc_loss = 0.0010165541014824826
Trained batch 83 in epoch 7, gen_loss = 2.0006413871333715, disc_loss = 0.0010100555508480674
Trained batch 84 in epoch 7, gen_loss = 2.000641672751483, disc_loss = 0.0010034295980243342
Trained batch 85 in epoch 7, gen_loss = 1.9979732008867486, disc_loss = 0.0009971992471417802
Trained batch 86 in epoch 7, gen_loss = 1.9995948775061245, disc_loss = 0.0009895076997974224
Trained batch 87 in epoch 7, gen_loss = 2.001747339963913, disc_loss = 0.0009829332107487558
Trained batch 88 in epoch 7, gen_loss = 1.999406123429202, disc_loss = 0.0009786605630907115
Trained batch 89 in epoch 7, gen_loss = 2.0020948224597506, disc_loss = 0.0009808405173114603
Trained batch 90 in epoch 7, gen_loss = 2.0006705863135203, disc_loss = 0.0009855742650720608
Trained batch 91 in epoch 7, gen_loss = 2.0019014153791512, disc_loss = 0.0009904716786442568
Trained batch 92 in epoch 7, gen_loss = 2.0011841238185926, disc_loss = 0.0009967680464708997
Trained batch 93 in epoch 7, gen_loss = 2.006904699700944, disc_loss = 0.001004622575450451
Trained batch 94 in epoch 7, gen_loss = 2.007793365026775, disc_loss = 0.0010083074754986324
Trained batch 95 in epoch 7, gen_loss = 2.009497261295716, disc_loss = 0.0010048635109948616
Trained batch 96 in epoch 7, gen_loss = 2.0087440185940144, disc_loss = 0.0010038210509930613
Trained batch 97 in epoch 7, gen_loss = 2.012429879636181, disc_loss = 0.001003424263421484
Trained batch 98 in epoch 7, gen_loss = 2.011852093417235, disc_loss = 0.0010040813246788927
Trained batch 99 in epoch 7, gen_loss = 2.0102754032611845, disc_loss = 0.0010078985075233505
Trained batch 100 in epoch 7, gen_loss = 2.01625125124903, disc_loss = 0.0010087343139140543
Trained batch 101 in epoch 7, gen_loss = 2.0143356451801226, disc_loss = 0.001008532354128821
Trained batch 102 in epoch 7, gen_loss = 2.015208259369563, disc_loss = 0.0010053137310518368
Trained batch 103 in epoch 7, gen_loss = 2.0143111600325656, disc_loss = 0.0009997555179534873
Trained batch 104 in epoch 7, gen_loss = 2.009071070807321, disc_loss = 0.000996886824335282
Trained batch 105 in epoch 7, gen_loss = 2.0088370408651963, disc_loss = 0.0009928944266405625
Trained batch 106 in epoch 7, gen_loss = 2.0110274809543216, disc_loss = 0.0009868453775214849
Trained batch 107 in epoch 7, gen_loss = 2.0120852567531444, disc_loss = 0.0009810150502879103
Trained batch 108 in epoch 7, gen_loss = 2.0099661743969, disc_loss = 0.000976401710147978
Trained batch 109 in epoch 7, gen_loss = 2.007880712639202, disc_loss = 0.0009728525871072303
Trained batch 110 in epoch 7, gen_loss = 2.0055189465617276, disc_loss = 0.000971879768143366
Trained batch 111 in epoch 7, gen_loss = 2.0066101008227895, disc_loss = 0.0009692661504751803
Trained batch 112 in epoch 7, gen_loss = 2.008912015805202, disc_loss = 0.0009681263060795259
Trained batch 113 in epoch 7, gen_loss = 2.009728537316908, disc_loss = 0.0009697072438715974
Trained batch 114 in epoch 7, gen_loss = 2.011950321819471, disc_loss = 0.0009692413929809371
Trained batch 115 in epoch 7, gen_loss = 2.012008197348693, disc_loss = 0.0009677085196519078
Trained batch 116 in epoch 7, gen_loss = 2.0109127240303235, disc_loss = 0.0009659884132357298
Trained batch 117 in epoch 7, gen_loss = 2.0109791533421664, disc_loss = 0.0009667715881517062
Trained batch 118 in epoch 7, gen_loss = 2.0124419857473934, disc_loss = 0.0009695392453205623
Trained batch 119 in epoch 7, gen_loss = 2.0099101652701696, disc_loss = 0.0009732798066882727
Trained batch 120 in epoch 7, gen_loss = 2.009957653431853, disc_loss = 0.000979130423323767
Trained batch 121 in epoch 7, gen_loss = 2.010947539181006, disc_loss = 0.0009885306835563884
Trained batch 122 in epoch 7, gen_loss = 2.0107261417357902, disc_loss = 0.0010077112209528867
Trained batch 123 in epoch 7, gen_loss = 2.009442106370003, disc_loss = 0.001028603398627902
Trained batch 124 in epoch 7, gen_loss = 2.0093623323440553, disc_loss = 0.001040466861333698
Trained batch 125 in epoch 7, gen_loss = 2.0089023160556008, disc_loss = 0.0010393387642652092
Trained batch 126 in epoch 7, gen_loss = 2.0115944090790636, disc_loss = 0.0010336482121451487
Trained batch 127 in epoch 7, gen_loss = 2.0075875213369727, disc_loss = 0.0010324363900053868
Trained batch 128 in epoch 7, gen_loss = 2.00874322421791, disc_loss = 0.0010337798561550705
Trained batch 129 in epoch 7, gen_loss = 2.0056420115324167, disc_loss = 0.001033687776697871
Trained batch 130 in epoch 7, gen_loss = 2.006353568484765, disc_loss = 0.0010312222589059727
Trained batch 131 in epoch 7, gen_loss = 2.002780812256264, disc_loss = 0.0010291068855704825
Trained batch 132 in epoch 7, gen_loss = 2.0045937120466304, disc_loss = 0.0010290744688617472
Trained batch 133 in epoch 7, gen_loss = 2.0060410259374932, disc_loss = 0.0010325612907329184
Trained batch 134 in epoch 7, gen_loss = 2.004211280964039, disc_loss = 0.0010389593147448505
Trained batch 135 in epoch 7, gen_loss = 2.0064736078767216, disc_loss = 0.0010513352850359619
Trained batch 136 in epoch 7, gen_loss = 2.006741925747725, disc_loss = 0.0010623137755948289
Trained batch 137 in epoch 7, gen_loss = 2.00649856225304, disc_loss = 0.0010677579382478355
Trained batch 138 in epoch 7, gen_loss = 2.004976299169252, disc_loss = 0.0010658912735458518
Trained batch 139 in epoch 7, gen_loss = 2.0040548247950416, disc_loss = 0.0010613195650096584
Trained batch 140 in epoch 7, gen_loss = 2.0033379573348564, disc_loss = 0.001056915347865644
Trained batch 141 in epoch 7, gen_loss = 2.0031999324409053, disc_loss = 0.0010527512159044395
Trained batch 142 in epoch 7, gen_loss = 2.00373815073, disc_loss = 0.001048079760414646
Trained batch 143 in epoch 7, gen_loss = 2.0027823928329678, disc_loss = 0.0010429349456697106
Trained batch 144 in epoch 7, gen_loss = 2.0027411674631055, disc_loss = 0.0010375740490291782
Trained batch 145 in epoch 7, gen_loss = 2.0020607056683057, disc_loss = 0.001032778794505659
Trained batch 146 in epoch 7, gen_loss = 2.001562690248295, disc_loss = 0.0010285312280163396
Trained batch 147 in epoch 7, gen_loss = 2.0028561103988336, disc_loss = 0.0010235819348521102
Trained batch 148 in epoch 7, gen_loss = 2.0040370641938794, disc_loss = 0.0010183536345623558
Trained batch 149 in epoch 7, gen_loss = 2.0028509974479674, disc_loss = 0.0010134003332738454
Trained batch 150 in epoch 7, gen_loss = 2.003769823257497, disc_loss = 0.0010086846748360784
Trained batch 151 in epoch 7, gen_loss = 2.0016906120275197, disc_loss = 0.0010047218498871907
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.1968119144439697, disc_loss = 0.000445934827439487
Trained batch 1 in epoch 8, gen_loss = 2.114625573158264, disc_loss = 0.00045614044938702136
Trained batch 2 in epoch 8, gen_loss = 1.9270073175430298, disc_loss = 0.0007146188775853565
Trained batch 3 in epoch 8, gen_loss = 1.9444712102413177, disc_loss = 0.0008757952091400512
Trained batch 4 in epoch 8, gen_loss = 1.9291538000106812, disc_loss = 0.0010431570990476757
Trained batch 5 in epoch 8, gen_loss = 2.0002461870511374, disc_loss = 0.0013499673271629338
Trained batch 6 in epoch 8, gen_loss = 1.9580918380192347, disc_loss = 0.0016684141051622906
Trained batch 7 in epoch 8, gen_loss = 1.9322125315666199, disc_loss = 0.0017903489097079728
Trained batch 8 in epoch 8, gen_loss = 1.933346880806817, disc_loss = 0.0018036160650404377
Trained batch 9 in epoch 8, gen_loss = 1.9177248358726502, disc_loss = 0.0018523747829021886
Trained batch 10 in epoch 8, gen_loss = 1.9323857372457331, disc_loss = 0.0018362147675361484
Trained batch 11 in epoch 8, gen_loss = 1.9642175336678822, disc_loss = 0.001768837956963883
Trained batch 12 in epoch 8, gen_loss = 1.93946085526393, disc_loss = 0.0017681732670798039
Trained batch 13 in epoch 8, gen_loss = 1.9403540662356786, disc_loss = 0.0017984654259635136
Trained batch 14 in epoch 8, gen_loss = 1.925660498936971, disc_loss = 0.0018127430016951014
Trained batch 15 in epoch 8, gen_loss = 1.933433711528778, disc_loss = 0.0018203862946393201
Trained batch 16 in epoch 8, gen_loss = 1.9353455094730152, disc_loss = 0.0018089886306209817
Trained batch 17 in epoch 8, gen_loss = 1.9313331842422485, disc_loss = 0.001770264975170398
Trained batch 18 in epoch 8, gen_loss = 1.920802492844431, disc_loss = 0.0017108516323404682
Trained batch 19 in epoch 8, gen_loss = 1.9160613059997558, disc_loss = 0.0016609899917966685
Trained batch 20 in epoch 8, gen_loss = 1.9257116658346993, disc_loss = 0.0016169577235511194
Trained batch 21 in epoch 8, gen_loss = 1.9390815604816785, disc_loss = 0.0015691405926852233
Trained batch 22 in epoch 8, gen_loss = 1.9567268309385881, disc_loss = 0.001514633111503866
Trained batch 23 in epoch 8, gen_loss = 1.95715694129467, disc_loss = 0.0014732397042583518
Trained batch 24 in epoch 8, gen_loss = 1.954348726272583, disc_loss = 0.0014404125686269253
Trained batch 25 in epoch 8, gen_loss = 1.9365082108057463, disc_loss = 0.001414845293486276
Trained batch 26 in epoch 8, gen_loss = 1.9387858752851133, disc_loss = 0.0013831579934857371
Trained batch 27 in epoch 8, gen_loss = 1.95747794849532, disc_loss = 0.0013673385100056684
Trained batch 28 in epoch 8, gen_loss = 1.9664918184280396, disc_loss = 0.0013417633007489272
Trained batch 29 in epoch 8, gen_loss = 1.9660569151242575, disc_loss = 0.0013183757653071856
Trained batch 30 in epoch 8, gen_loss = 1.9643712812854397, disc_loss = 0.0012999985530416692
Trained batch 31 in epoch 8, gen_loss = 1.9775514602661133, disc_loss = 0.0012842619898947305
Trained batch 32 in epoch 8, gen_loss = 1.97603706518809, disc_loss = 0.001261655430866857
Trained batch 33 in epoch 8, gen_loss = 1.9766163720804102, disc_loss = 0.001239515040651895
Trained batch 34 in epoch 8, gen_loss = 1.9741873502731324, disc_loss = 0.0012179454888350198
Trained batch 35 in epoch 8, gen_loss = 1.9820071293248072, disc_loss = 0.0011960742138196817
Trained batch 36 in epoch 8, gen_loss = 1.9911124158549953, disc_loss = 0.001182817342703709
Trained batch 37 in epoch 8, gen_loss = 1.9935348378984552, disc_loss = 0.001175483978218644
Trained batch 38 in epoch 8, gen_loss = 1.9944767432335095, disc_loss = 0.0011722580634224683
Trained batch 39 in epoch 8, gen_loss = 1.9967911928892135, disc_loss = 0.0011688982354826293
Trained batch 40 in epoch 8, gen_loss = 1.9818343505626772, disc_loss = 0.0011717566876763069
Trained batch 41 in epoch 8, gen_loss = 1.9785355074065072, disc_loss = 0.0011793520936321112
Trained batch 42 in epoch 8, gen_loss = 1.9748574079469192, disc_loss = 0.0011837282908408967
Trained batch 43 in epoch 8, gen_loss = 1.9719094146381726, disc_loss = 0.0011840363295050338
Trained batch 44 in epoch 8, gen_loss = 1.9728813065422905, disc_loss = 0.0011712594695078829
Trained batch 45 in epoch 8, gen_loss = 1.9706022843070652, disc_loss = 0.0011568980901400842
Trained batch 46 in epoch 8, gen_loss = 1.9727462656954502, disc_loss = 0.0011468847032061757
Trained batch 47 in epoch 8, gen_loss = 1.9768769691387813, disc_loss = 0.0011429186852183193
Trained batch 48 in epoch 8, gen_loss = 1.972060675523719, disc_loss = 0.0011419026532723587
Trained batch 49 in epoch 8, gen_loss = 1.9746497440338135, disc_loss = 0.0011398902768269181
Trained batch 50 in epoch 8, gen_loss = 1.972662986493578, disc_loss = 0.0011363982464935557
Trained batch 51 in epoch 8, gen_loss = 1.9673005594657018, disc_loss = 0.0011378092548021902
Trained batch 52 in epoch 8, gen_loss = 1.96818072166083, disc_loss = 0.0011357886185166689
Trained batch 53 in epoch 8, gen_loss = 1.9642150821509186, disc_loss = 0.001130959230337154
Trained batch 54 in epoch 8, gen_loss = 1.9617053552107377, disc_loss = 0.00112439020939002
Trained batch 55 in epoch 8, gen_loss = 1.960804140993527, disc_loss = 0.001121744942793157
Trained batch 56 in epoch 8, gen_loss = 1.9628015923918338, disc_loss = 0.0011269468824346468
Trained batch 57 in epoch 8, gen_loss = 1.9713254283214439, disc_loss = 0.0011356237258135888
Trained batch 58 in epoch 8, gen_loss = 1.966858843625602, disc_loss = 0.0011384067277550318
Trained batch 59 in epoch 8, gen_loss = 1.9696879227956137, disc_loss = 0.0011346216352346042
Trained batch 60 in epoch 8, gen_loss = 1.9665143900230282, disc_loss = 0.0011229602115221137
Trained batch 61 in epoch 8, gen_loss = 1.9644872315468327, disc_loss = 0.0011154546138582631
Trained batch 62 in epoch 8, gen_loss = 1.9717407396861486, disc_loss = 0.0011132590427425587
Trained batch 63 in epoch 8, gen_loss = 1.9706757292151451, disc_loss = 0.001107181989482342
Trained batch 64 in epoch 8, gen_loss = 1.9753565091353196, disc_loss = 0.001099702956316133
Trained batch 65 in epoch 8, gen_loss = 1.9772410212141094, disc_loss = 0.0010906482943524184
Trained batch 66 in epoch 8, gen_loss = 1.9775457720258343, disc_loss = 0.0010804840786653612
Trained batch 67 in epoch 8, gen_loss = 1.9779185740386738, disc_loss = 0.0010726426746045677
Trained batch 68 in epoch 8, gen_loss = 1.9783313671747844, disc_loss = 0.001064523954561952
Trained batch 69 in epoch 8, gen_loss = 1.9803822432245528, disc_loss = 0.0010617964597518688
Trained batch 70 in epoch 8, gen_loss = 1.9816629063915199, disc_loss = 0.001059846945589041
Trained batch 71 in epoch 8, gen_loss = 1.981468207306332, disc_loss = 0.0010539395956988705
Trained batch 72 in epoch 8, gen_loss = 1.981581694459262, disc_loss = 0.0010462262375082515
Trained batch 73 in epoch 8, gen_loss = 1.9790901219522632, disc_loss = 0.0010390118715460285
Trained batch 74 in epoch 8, gen_loss = 1.9792893362045287, disc_loss = 0.0010311220590180407
Trained batch 75 in epoch 8, gen_loss = 1.9773696566882886, disc_loss = 0.0010222711464034785
Trained batch 76 in epoch 8, gen_loss = 1.972787603155359, disc_loss = 0.0010140779119759023
Trained batch 77 in epoch 8, gen_loss = 1.9687766952392383, disc_loss = 0.0010061854196604914
Trained batch 78 in epoch 8, gen_loss = 1.9714149387576911, disc_loss = 0.0009993143881453037
Trained batch 79 in epoch 8, gen_loss = 1.973503042757511, disc_loss = 0.0009927406514179892
Trained batch 80 in epoch 8, gen_loss = 1.9748857036048983, disc_loss = 0.0009859765101551871
Trained batch 81 in epoch 8, gen_loss = 1.9741856673868692, disc_loss = 0.0009807702505296642
Trained batch 82 in epoch 8, gen_loss = 1.9764105067195663, disc_loss = 0.0009785095332835588
Trained batch 83 in epoch 8, gen_loss = 1.9763328120822, disc_loss = 0.0009753863958481123
Trained batch 84 in epoch 8, gen_loss = 1.9796350423027487, disc_loss = 0.0009714021570021834
Trained batch 85 in epoch 8, gen_loss = 1.976552783056747, disc_loss = 0.000968602706940823
Trained batch 86 in epoch 8, gen_loss = 1.9802005126558502, disc_loss = 0.0009665544885451552
Trained batch 87 in epoch 8, gen_loss = 1.9814938767389818, disc_loss = 0.0009657196963168892
Trained batch 88 in epoch 8, gen_loss = 1.9836503039585072, disc_loss = 0.0009645022045732005
Trained batch 89 in epoch 8, gen_loss = 1.9843848546346028, disc_loss = 0.0009606122786256795
Trained batch 90 in epoch 8, gen_loss = 1.983991062248146, disc_loss = 0.0009556975177934414
Trained batch 91 in epoch 8, gen_loss = 1.983045887687932, disc_loss = 0.0009522498968062396
Trained batch 92 in epoch 8, gen_loss = 1.9850116481063187, disc_loss = 0.0009457561014074912
Trained batch 93 in epoch 8, gen_loss = 1.9822716408587517, disc_loss = 0.0009402212847217402
Trained batch 94 in epoch 8, gen_loss = 1.9891170727579217, disc_loss = 0.000937517580122834
Trained batch 95 in epoch 8, gen_loss = 1.9916321287552516, disc_loss = 0.0009343959545731195
Trained batch 96 in epoch 8, gen_loss = 1.9898935482674038, disc_loss = 0.0009293982707511288
Trained batch 97 in epoch 8, gen_loss = 1.9913522187544375, disc_loss = 0.0009252375415858946
Trained batch 98 in epoch 8, gen_loss = 1.992738618995204, disc_loss = 0.0009236217863302715
Trained batch 99 in epoch 8, gen_loss = 1.9918426179885864, disc_loss = 0.00092384610674344
Trained batch 100 in epoch 8, gen_loss = 1.9886353369986658, disc_loss = 0.0009303307333629173
Trained batch 101 in epoch 8, gen_loss = 1.9861703398180943, disc_loss = 0.0009459491953819844
Trained batch 102 in epoch 8, gen_loss = 1.984477257265628, disc_loss = 0.0009713348541499197
Trained batch 103 in epoch 8, gen_loss = 1.9851741664684737, disc_loss = 0.000997256155152662
Trained batch 104 in epoch 8, gen_loss = 1.98308314482371, disc_loss = 0.0010138775410485409
Trained batch 105 in epoch 8, gen_loss = 1.9828753741282337, disc_loss = 0.0010261966348274277
Trained batch 106 in epoch 8, gen_loss = 1.9859371363559617, disc_loss = 0.0010381677573128977
Trained batch 107 in epoch 8, gen_loss = 1.985838724507226, disc_loss = 0.0010502622020862032
Trained batch 108 in epoch 8, gen_loss = 1.9846800937565094, disc_loss = 0.001056597591591401
Trained batch 109 in epoch 8, gen_loss = 1.9839381575584412, disc_loss = 0.0010593797482380814
Trained batch 110 in epoch 8, gen_loss = 1.9853615105689109, disc_loss = 0.0010600192409411476
Trained batch 111 in epoch 8, gen_loss = 1.9834037433777536, disc_loss = 0.001057008290185227
Trained batch 112 in epoch 8, gen_loss = 1.9827814956681917, disc_loss = 0.0010521534291524604
Trained batch 113 in epoch 8, gen_loss = 1.982361096039153, disc_loss = 0.00104597951448931
Trained batch 114 in epoch 8, gen_loss = 1.9819055920061859, disc_loss = 0.001039340818533674
Trained batch 115 in epoch 8, gen_loss = 1.9820992196428364, disc_loss = 0.001033573460329629
Trained batch 116 in epoch 8, gen_loss = 1.9805893765555487, disc_loss = 0.001028567550327772
Trained batch 117 in epoch 8, gen_loss = 1.9835428878412409, disc_loss = 0.0010229016593026029
Trained batch 118 in epoch 8, gen_loss = 1.9844831408572798, disc_loss = 0.0010168522111132364
Trained batch 119 in epoch 8, gen_loss = 1.9849307785431545, disc_loss = 0.0010121040424564854
Trained batch 120 in epoch 8, gen_loss = 1.9844156267229192, disc_loss = 0.0010066113871529945
Trained batch 121 in epoch 8, gen_loss = 1.9833757398558445, disc_loss = 0.0010012071589236987
Trained batch 122 in epoch 8, gen_loss = 1.9844080597404543, disc_loss = 0.0009949468871260562
Trained batch 123 in epoch 8, gen_loss = 1.9818661337898624, disc_loss = 0.0009900386695892761
Trained batch 124 in epoch 8, gen_loss = 1.9809347591400146, disc_loss = 0.0009897503331303596
Trained batch 125 in epoch 8, gen_loss = 1.9801064199871488, disc_loss = 0.0009891117926657436
Trained batch 126 in epoch 8, gen_loss = 1.9784366239712934, disc_loss = 0.0009856001807626072
Trained batch 127 in epoch 8, gen_loss = 1.9787614345550537, disc_loss = 0.0009826069062910392
Trained batch 128 in epoch 8, gen_loss = 1.977456539176231, disc_loss = 0.0009791032734233164
Trained batch 129 in epoch 8, gen_loss = 1.9768117436995873, disc_loss = 0.0009745981024864774
Trained batch 130 in epoch 8, gen_loss = 1.9771476256028386, disc_loss = 0.0009697187869215939
Trained batch 131 in epoch 8, gen_loss = 1.9768126751437332, disc_loss = 0.0009654157009649542
Trained batch 132 in epoch 8, gen_loss = 1.9749292063533812, disc_loss = 0.000962217417379309
Trained batch 133 in epoch 8, gen_loss = 1.9766519060775416, disc_loss = 0.0009591020341813148
Trained batch 134 in epoch 8, gen_loss = 1.9760084311167398, disc_loss = 0.0009548546244062621
Trained batch 135 in epoch 8, gen_loss = 1.97744281502331, disc_loss = 0.0009510794126767638
Trained batch 136 in epoch 8, gen_loss = 1.9760021902348874, disc_loss = 0.0009495970046565779
Trained batch 137 in epoch 8, gen_loss = 1.974629855674246, disc_loss = 0.0009480842422488132
Trained batch 138 in epoch 8, gen_loss = 1.973592029201041, disc_loss = 0.0009459525549017135
Trained batch 139 in epoch 8, gen_loss = 1.9711662735257829, disc_loss = 0.0009471079257699395
Trained batch 140 in epoch 8, gen_loss = 1.9704993963241577, disc_loss = 0.0009503010385884434
Trained batch 141 in epoch 8, gen_loss = 1.9688319698185988, disc_loss = 0.0009534320214838708
Trained batch 142 in epoch 8, gen_loss = 1.968612009828741, disc_loss = 0.0009541182933046346
Trained batch 143 in epoch 8, gen_loss = 1.9714485133687656, disc_loss = 0.0009560562246204225
Trained batch 144 in epoch 8, gen_loss = 1.9734466791152954, disc_loss = 0.0009579823848165186
Trained batch 145 in epoch 8, gen_loss = 1.9724729787813473, disc_loss = 0.0009590162501322769
Trained batch 146 in epoch 8, gen_loss = 1.973417352656929, disc_loss = 0.0009585494105466547
Trained batch 147 in epoch 8, gen_loss = 1.9728708951859861, disc_loss = 0.0009562915733408158
Trained batch 148 in epoch 8, gen_loss = 1.975144035064134, disc_loss = 0.0009547828045445526
Trained batch 149 in epoch 8, gen_loss = 1.973126307328542, disc_loss = 0.0009540964556314672
Trained batch 150 in epoch 8, gen_loss = 1.9723840075612857, disc_loss = 0.0009530211190942872
Trained batch 151 in epoch 8, gen_loss = 1.9737828028829474, disc_loss = 0.0009518887682612618
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 1.792459487915039, disc_loss = 0.0007016478339210153
Trained batch 1 in epoch 9, gen_loss = 1.9132477045059204, disc_loss = 0.0006457176641561091
Trained batch 2 in epoch 9, gen_loss = 1.8629601399103801, disc_loss = 0.0005995112005621195
Trained batch 3 in epoch 9, gen_loss = 1.8417452275753021, disc_loss = 0.0005777515325462446
Trained batch 4 in epoch 9, gen_loss = 1.8417433261871339, disc_loss = 0.0005656732362695038
Trained batch 5 in epoch 9, gen_loss = 1.8473410209019978, disc_loss = 0.000557998864678666
Trained batch 6 in epoch 9, gen_loss = 1.8548213413783483, disc_loss = 0.0005913919636181422
Trained batch 7 in epoch 9, gen_loss = 1.9036456048488617, disc_loss = 0.0006421931611839682
Trained batch 8 in epoch 9, gen_loss = 1.8794087304009333, disc_loss = 0.0006886469329603844
Trained batch 9 in epoch 9, gen_loss = 1.897381639480591, disc_loss = 0.0007125125848688185
Trained batch 10 in epoch 9, gen_loss = 1.9075066176327793, disc_loss = 0.000704505755989389
Trained batch 11 in epoch 9, gen_loss = 1.919875939687093, disc_loss = 0.0006864701814871902
Trained batch 12 in epoch 9, gen_loss = 1.9187769706432636, disc_loss = 0.0006900175358168781
Trained batch 13 in epoch 9, gen_loss = 1.931464433670044, disc_loss = 0.0007012977730482817
Trained batch 14 in epoch 9, gen_loss = 1.9219956874847413, disc_loss = 0.0006960934066834549
Trained batch 15 in epoch 9, gen_loss = 1.8983810171484947, disc_loss = 0.000699093801813433
Trained batch 16 in epoch 9, gen_loss = 1.8819715906591976, disc_loss = 0.0007032033206675859
Trained batch 17 in epoch 9, gen_loss = 1.8884204824765523, disc_loss = 0.0006954343924816283
Trained batch 18 in epoch 9, gen_loss = 1.9078458798559088, disc_loss = 0.0007074184862798766
Trained batch 19 in epoch 9, gen_loss = 1.9117301821708679, disc_loss = 0.0007251263712532818
Trained batch 20 in epoch 9, gen_loss = 1.923986832300822, disc_loss = 0.0007662204471195028
Trained batch 21 in epoch 9, gen_loss = 1.936281074177135, disc_loss = 0.0008427260062572631
Trained batch 22 in epoch 9, gen_loss = 1.9265525237373684, disc_loss = 0.0009888655546566715
Trained batch 23 in epoch 9, gen_loss = 1.9286817014217377, disc_loss = 0.0011565960788478453
Trained batch 24 in epoch 9, gen_loss = 1.92769513130188, disc_loss = 0.001283225454390049
Trained batch 25 in epoch 9, gen_loss = 1.9260833171697764, disc_loss = 0.0013743735437926191
Trained batch 26 in epoch 9, gen_loss = 1.9192603958977594, disc_loss = 0.001419746584293467
Trained batch 27 in epoch 9, gen_loss = 1.90816644685609, disc_loss = 0.0014214594765300198
Trained batch 28 in epoch 9, gen_loss = 1.900505279672557, disc_loss = 0.0014113029023503948
Trained batch 29 in epoch 9, gen_loss = 1.900299064318339, disc_loss = 0.0013867245754227043
Trained batch 30 in epoch 9, gen_loss = 1.8991430651757024, disc_loss = 0.001353702505096613
Trained batch 31 in epoch 9, gen_loss = 1.9042434394359589, disc_loss = 0.0013238040492069558
Trained batch 32 in epoch 9, gen_loss = 1.8995964563254155, disc_loss = 0.0012966246709269894
Trained batch 33 in epoch 9, gen_loss = 1.9016912579536438, disc_loss = 0.0012734348137575366
Trained batch 34 in epoch 9, gen_loss = 1.8950499500547136, disc_loss = 0.0012557306418394937
Trained batch 35 in epoch 9, gen_loss = 1.8985970318317413, disc_loss = 0.0012564977538810733
Trained batch 36 in epoch 9, gen_loss = 1.8966793530696147, disc_loss = 0.0012563986702180292
Trained batch 37 in epoch 9, gen_loss = 1.901911381043886, disc_loss = 0.0012506792209981206
Trained batch 38 in epoch 9, gen_loss = 1.8988757867079515, disc_loss = 0.0012448280833315295
Trained batch 39 in epoch 9, gen_loss = 1.895190131664276, disc_loss = 0.0012319273089815396
Trained batch 40 in epoch 9, gen_loss = 1.8999111477921649, disc_loss = 0.0012112945068355014
Trained batch 41 in epoch 9, gen_loss = 1.8980394431522913, disc_loss = 0.0011901150199784233
Trained batch 42 in epoch 9, gen_loss = 1.900546905606292, disc_loss = 0.0011713513217833933
Trained batch 43 in epoch 9, gen_loss = 1.906642810864882, disc_loss = 0.0011529253507350486
Trained batch 44 in epoch 9, gen_loss = 1.9117526531219482, disc_loss = 0.0011353366710763011
Trained batch 45 in epoch 9, gen_loss = 1.9130530409190967, disc_loss = 0.0011178864338232772
Trained batch 46 in epoch 9, gen_loss = 1.9049644267305414, disc_loss = 0.0011033700275026816
Trained batch 47 in epoch 9, gen_loss = 1.910200556119283, disc_loss = 0.0010877952681767056
Trained batch 48 in epoch 9, gen_loss = 1.915480560185958, disc_loss = 0.001072145134272358
Trained batch 49 in epoch 9, gen_loss = 1.9157638478279113, disc_loss = 0.0010565965349087492
Trained batch 50 in epoch 9, gen_loss = 1.9177703413308835, disc_loss = 0.001041516626833518
Trained batch 51 in epoch 9, gen_loss = 1.9165984094142914, disc_loss = 0.0010260304101953248
Trained batch 52 in epoch 9, gen_loss = 1.915207028388977, disc_loss = 0.001013312703778282
Trained batch 53 in epoch 9, gen_loss = 1.9153785617263228, disc_loss = 0.0010050452954062537
Trained batch 54 in epoch 9, gen_loss = 1.915390844778581, disc_loss = 0.0010002966067986564
Trained batch 55 in epoch 9, gen_loss = 1.918780294912202, disc_loss = 0.0009957254855440364
Trained batch 56 in epoch 9, gen_loss = 1.913941607140658, disc_loss = 0.0009946326514309795
Trained batch 57 in epoch 9, gen_loss = 1.9177035771567246, disc_loss = 0.0009980936560294077
Trained batch 58 in epoch 9, gen_loss = 1.9201935812578363, disc_loss = 0.0009967459864436918
Trained batch 59 in epoch 9, gen_loss = 1.9240977903207144, disc_loss = 0.000990258298649375
Trained batch 60 in epoch 9, gen_loss = 1.9228246954620862, disc_loss = 0.0009811361066016109
Trained batch 61 in epoch 9, gen_loss = 1.9269490280459005, disc_loss = 0.0009740095605769555
Trained batch 62 in epoch 9, gen_loss = 1.9239589770634968, disc_loss = 0.0009652222208734159
Trained batch 63 in epoch 9, gen_loss = 1.9220599457621574, disc_loss = 0.0009543211151594733
Trained batch 64 in epoch 9, gen_loss = 1.9210125776437612, disc_loss = 0.0009465539221239921
Trained batch 65 in epoch 9, gen_loss = 1.923810059374029, disc_loss = 0.0009374820685038823
Trained batch 66 in epoch 9, gen_loss = 1.9224356466264867, disc_loss = 0.0009285080042031747
Trained batch 67 in epoch 9, gen_loss = 1.9223067970836865, disc_loss = 0.0009211293271458571
Trained batch 68 in epoch 9, gen_loss = 1.9195642713187397, disc_loss = 0.0009173424469485906
Trained batch 69 in epoch 9, gen_loss = 1.9213309458323888, disc_loss = 0.0009154709282613891
Trained batch 70 in epoch 9, gen_loss = 1.9243649596899328, disc_loss = 0.0009134665853425887
Trained batch 71 in epoch 9, gen_loss = 1.9263738460010953, disc_loss = 0.0009115269052320704
Trained batch 72 in epoch 9, gen_loss = 1.929195518363012, disc_loss = 0.000907940151566984
Trained batch 73 in epoch 9, gen_loss = 1.9269984525603217, disc_loss = 0.0009038366443820525
Trained batch 74 in epoch 9, gen_loss = 1.9309799337387086, disc_loss = 0.0009039011405548081
Trained batch 75 in epoch 9, gen_loss = 1.9315098414295597, disc_loss = 0.000910326733757852
Trained batch 76 in epoch 9, gen_loss = 1.9349985045272033, disc_loss = 0.0009242704573961265
Trained batch 77 in epoch 9, gen_loss = 1.9375501397328498, disc_loss = 0.0009512431340856262
Trained batch 78 in epoch 9, gen_loss = 1.9351975450032874, disc_loss = 0.0009834328041886439
Trained batch 79 in epoch 9, gen_loss = 1.9329232186079026, disc_loss = 0.001001752554475388
Trained batch 80 in epoch 9, gen_loss = 1.9321654505199857, disc_loss = 0.0010054165227583
Trained batch 81 in epoch 9, gen_loss = 1.9323267573263587, disc_loss = 0.0010005509363353912
Trained batch 82 in epoch 9, gen_loss = 1.9321116941520966, disc_loss = 0.0009950088901257322
Trained batch 83 in epoch 9, gen_loss = 1.9339424258186704, disc_loss = 0.0009903563264482987
Trained batch 84 in epoch 9, gen_loss = 1.9330507432713229, disc_loss = 0.0009861934370265397
Trained batch 85 in epoch 9, gen_loss = 1.9319291724715122, disc_loss = 0.0009797379304451847
Trained batch 86 in epoch 9, gen_loss = 1.9345665663138203, disc_loss = 0.0009713366789269615
Trained batch 87 in epoch 9, gen_loss = 1.9353471019051292, disc_loss = 0.000963486922046286
Trained batch 88 in epoch 9, gen_loss = 1.9354438929075606, disc_loss = 0.0009570436372638816
Trained batch 89 in epoch 9, gen_loss = 1.9345144377814398, disc_loss = 0.0009543590853960874
Trained batch 90 in epoch 9, gen_loss = 1.9336178459963955, disc_loss = 0.0009531312617972228
Trained batch 91 in epoch 9, gen_loss = 1.9323359015195265, disc_loss = 0.0009486851984389511
Trained batch 92 in epoch 9, gen_loss = 1.9302448393196188, disc_loss = 0.0009440598176649562
Trained batch 93 in epoch 9, gen_loss = 1.9299939959607226, disc_loss = 0.0009388190914289728
Trained batch 94 in epoch 9, gen_loss = 1.9314010256215146, disc_loss = 0.000935015577890322
Trained batch 95 in epoch 9, gen_loss = 1.9344531533618767, disc_loss = 0.0009296731100221223
Trained batch 96 in epoch 9, gen_loss = 1.938210080579384, disc_loss = 0.0009238769862255965
Trained batch 97 in epoch 9, gen_loss = 1.941527175660036, disc_loss = 0.0009177220545469175
Trained batch 98 in epoch 9, gen_loss = 1.9390554873630255, disc_loss = 0.0009126831132699876
Trained batch 99 in epoch 9, gen_loss = 1.938004070520401, disc_loss = 0.0009094340515730437
Trained batch 100 in epoch 9, gen_loss = 1.937164310181495, disc_loss = 0.0009040829037157081
Trained batch 101 in epoch 9, gen_loss = 1.9334878290400785, disc_loss = 0.000902644026306613
Trained batch 102 in epoch 9, gen_loss = 1.933254442168671, disc_loss = 0.0009058113242397808
Trained batch 103 in epoch 9, gen_loss = 1.938607856631279, disc_loss = 0.0009125393305741734
Trained batch 104 in epoch 9, gen_loss = 1.9389631271362304, disc_loss = 0.0009231010993798485
Trained batch 105 in epoch 9, gen_loss = 1.9428818833153203, disc_loss = 0.0009378002930975097
Trained batch 106 in epoch 9, gen_loss = 1.9417468420813018, disc_loss = 0.0009587594321830999
Trained batch 107 in epoch 9, gen_loss = 1.9414975477589502, disc_loss = 0.0009794161121169087
Trained batch 108 in epoch 9, gen_loss = 1.945911402002387, disc_loss = 0.0009982682209955357
Trained batch 109 in epoch 9, gen_loss = 1.9460606109012257, disc_loss = 0.0010133241206693295
Trained batch 110 in epoch 9, gen_loss = 1.9471566558958173, disc_loss = 0.0010253416807212456
Trained batch 111 in epoch 9, gen_loss = 1.9482151685016496, disc_loss = 0.0010316471014968037
Trained batch 112 in epoch 9, gen_loss = 1.9460285448395045, disc_loss = 0.001031042070337159
Trained batch 113 in epoch 9, gen_loss = 1.9446425688894171, disc_loss = 0.0010287797290641863
Trained batch 114 in epoch 9, gen_loss = 1.9455516234688137, disc_loss = 0.0010272634492772023
Trained batch 115 in epoch 9, gen_loss = 1.9452778285947339, disc_loss = 0.0010223866972002473
Trained batch 116 in epoch 9, gen_loss = 1.947432846085638, disc_loss = 0.00101708370332037
Trained batch 117 in epoch 9, gen_loss = 1.9504876601493966, disc_loss = 0.0010112115438244212
Trained batch 118 in epoch 9, gen_loss = 1.9533560075679748, disc_loss = 0.0010060756911177329
Trained batch 119 in epoch 9, gen_loss = 1.9517360170682272, disc_loss = 0.0010022677096761376
Trained batch 120 in epoch 9, gen_loss = 1.9497608212400075, disc_loss = 0.00100036033451815
Trained batch 121 in epoch 9, gen_loss = 1.950297185632049, disc_loss = 0.000999832984711784
Trained batch 122 in epoch 9, gen_loss = 1.9489630402588263, disc_loss = 0.0009984690145867672
Trained batch 123 in epoch 9, gen_loss = 1.9502741242608717, disc_loss = 0.0009962585166748237
Trained batch 124 in epoch 9, gen_loss = 1.951421290397644, disc_loss = 0.0009933532293653117
Trained batch 125 in epoch 9, gen_loss = 1.9543406234847174, disc_loss = 0.0009902158888594602
Trained batch 126 in epoch 9, gen_loss = 1.9548801709347823, disc_loss = 0.0009881994501627087
Trained batch 127 in epoch 9, gen_loss = 1.9555930932983756, disc_loss = 0.0009869424860653453
Trained batch 128 in epoch 9, gen_loss = 1.9539239508237025, disc_loss = 0.0009850738997627122
Trained batch 129 in epoch 9, gen_loss = 1.952522179713616, disc_loss = 0.0009825837362978536
Trained batch 130 in epoch 9, gen_loss = 1.9531161266428825, disc_loss = 0.0009797803811215306
Trained batch 131 in epoch 9, gen_loss = 1.9537048746239056, disc_loss = 0.0009774441117990523
Trained batch 132 in epoch 9, gen_loss = 1.95550182797855, disc_loss = 0.0009754549131397844
Trained batch 133 in epoch 9, gen_loss = 1.951738470525884, disc_loss = 0.0009740823144640481
Trained batch 134 in epoch 9, gen_loss = 1.951793501995228, disc_loss = 0.0009719065462747865
Trained batch 135 in epoch 9, gen_loss = 1.9534505474216797, disc_loss = 0.0009679527488247806
Trained batch 136 in epoch 9, gen_loss = 1.9547239193951127, disc_loss = 0.0009627875600674658
Trained batch 137 in epoch 9, gen_loss = 1.9536070063494253, disc_loss = 0.000957869302563241
Trained batch 138 in epoch 9, gen_loss = 1.9527556570313818, disc_loss = 0.0009535210750027218
Trained batch 139 in epoch 9, gen_loss = 1.9495116983141219, disc_loss = 0.0009492324464580244
Trained batch 140 in epoch 9, gen_loss = 1.949309322850924, disc_loss = 0.0009450313443415435
Trained batch 141 in epoch 9, gen_loss = 1.94921608626003, disc_loss = 0.0009410153088794405
Trained batch 142 in epoch 9, gen_loss = 1.9489447153531587, disc_loss = 0.0009366106326403617
Trained batch 143 in epoch 9, gen_loss = 1.9502291679382324, disc_loss = 0.0009319672914595382
Trained batch 144 in epoch 9, gen_loss = 1.9529808603484056, disc_loss = 0.0009281478708826713
Trained batch 145 in epoch 9, gen_loss = 1.951854162020226, disc_loss = 0.0009242284416870137
Trained batch 146 in epoch 9, gen_loss = 1.9504911258918087, disc_loss = 0.000921402167632612
Trained batch 147 in epoch 9, gen_loss = 1.9504320500670254, disc_loss = 0.0009174699537382096
Trained batch 148 in epoch 9, gen_loss = 1.9503651969384828, disc_loss = 0.0009145378907665848
Trained batch 149 in epoch 9, gen_loss = 1.951906799475352, disc_loss = 0.0009111149549911109
Trained batch 150 in epoch 9, gen_loss = 1.9528254744232885, disc_loss = 0.0009082389762432358
Trained batch 151 in epoch 9, gen_loss = 1.951718071573659, disc_loss = 0.0009050795933466073
Testing Epoch 9
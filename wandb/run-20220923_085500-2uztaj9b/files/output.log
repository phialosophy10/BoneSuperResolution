/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.3073110580444336, disc_loss = 0.5561223030090332
Trained batch 1 in epoch 0, gen_loss = 1.2107426524162292, disc_loss = 0.5308880507946014
Trained batch 2 in epoch 0, gen_loss = 1.2108479340871174, disc_loss = 0.5044873754183451
Trained batch 3 in epoch 0, gen_loss = 1.2454246580600739, disc_loss = 0.5040481984615326
Trained batch 4 in epoch 0, gen_loss = 1.1712766766548157, disc_loss = 0.44653681218624114
Trained batch 5 in epoch 0, gen_loss = 1.110066294670105, disc_loss = 0.4002632622917493
Trained batch 6 in epoch 0, gen_loss = 1.0224714108875819, disc_loss = 0.38032578357628416
Trained batch 7 in epoch 0, gen_loss = 0.9780594259500504, disc_loss = 0.36498355679214
Trained batch 8 in epoch 0, gen_loss = 0.9784573515256246, disc_loss = 0.36167821453677285
Trained batch 9 in epoch 0, gen_loss = 0.9631536543369293, disc_loss = 0.3498267397284508
Trained batch 10 in epoch 0, gen_loss = 0.9163733910430562, disc_loss = 0.3405831131068143
Trained batch 11 in epoch 0, gen_loss = 0.8951773022611936, disc_loss = 0.3263573224345843
Trained batch 12 in epoch 0, gen_loss = 0.8872367395804479, disc_loss = 0.3135879085614131
Trained batch 13 in epoch 0, gen_loss = 0.8714718925101417, disc_loss = 0.3009903409651348
Trained batch 14 in epoch 0, gen_loss = 0.8535087605317434, disc_loss = 0.29049610495567324
Trained batch 15 in epoch 0, gen_loss = 0.8538284283131361, disc_loss = 0.28035261295735836
Trained batch 16 in epoch 0, gen_loss = 0.8406948114142698, disc_loss = 0.2730184469152899
Trained batch 17 in epoch 0, gen_loss = 0.8424268712600073, disc_loss = 0.2657989768518342
Trained batch 18 in epoch 0, gen_loss = 0.8399773130291387, disc_loss = 0.2586836258047505
Trained batch 19 in epoch 0, gen_loss = 0.8355506286025047, disc_loss = 0.25106996968388556
Trained batch 20 in epoch 0, gen_loss = 0.8391654874597277, disc_loss = 0.2429902617420469
Trained batch 21 in epoch 0, gen_loss = 0.8415308472785082, disc_loss = 0.2350467084483667
Trained batch 22 in epoch 0, gen_loss = 0.8488010621589163, disc_loss = 0.22743809822460878
Trained batch 23 in epoch 0, gen_loss = 0.8474977103372415, disc_loss = 0.22101366659626365
Trained batch 24 in epoch 0, gen_loss = 0.8534648215770722, disc_loss = 0.21516882106661797
Trained batch 25 in epoch 0, gen_loss = 0.8598345139851937, disc_loss = 0.20964223963136858
Trained batch 26 in epoch 0, gen_loss = 0.8607394198576609, disc_loss = 0.20434662575523058
Trained batch 27 in epoch 0, gen_loss = 0.8620939371841294, disc_loss = 0.1997520142634
Trained batch 28 in epoch 0, gen_loss = 0.8646263634336406, disc_loss = 0.19582696837084046
Trained batch 29 in epoch 0, gen_loss = 0.8621447374423344, disc_loss = 0.19279547221958637
Trained batch 30 in epoch 0, gen_loss = 0.8707911593298758, disc_loss = 0.19010833494605556
Trained batch 31 in epoch 0, gen_loss = 0.8826760249212384, disc_loss = 0.18742393201682717
Trained batch 32 in epoch 0, gen_loss = 0.887884773088224, disc_loss = 0.18458225160385622
Trained batch 33 in epoch 0, gen_loss = 0.8969181258888805, disc_loss = 0.18111433844794245
Trained batch 34 in epoch 0, gen_loss = 0.897792203937258, disc_loss = 0.1780152402818203
Trained batch 35 in epoch 0, gen_loss = 0.9046700406405661, disc_loss = 0.17510828634517062
Trained batch 36 in epoch 0, gen_loss = 0.9064647676171483, disc_loss = 0.1721066382487078
Trained batch 37 in epoch 0, gen_loss = 0.9093159727360073, disc_loss = 0.16949142780351012
Trained batch 38 in epoch 0, gen_loss = 0.9104249668427002, disc_loss = 0.16752992083246893
Trained batch 39 in epoch 0, gen_loss = 0.9179435081779956, disc_loss = 0.16660496005788444
Trained batch 40 in epoch 0, gen_loss = 0.9224906760018047, disc_loss = 0.1653690651604315
Trained batch 41 in epoch 0, gen_loss = 0.9258396831296739, disc_loss = 0.16294463377978122
Trained batch 42 in epoch 0, gen_loss = 0.9260418200215628, disc_loss = 0.1601753644645214
Trained batch 43 in epoch 0, gen_loss = 0.9305194027044557, disc_loss = 0.1576849085871469
Trained batch 44 in epoch 0, gen_loss = 0.9288045095072852, disc_loss = 0.15548875273929702
Trained batch 45 in epoch 0, gen_loss = 0.9320455640554428, disc_loss = 0.15297471707605798
Trained batch 46 in epoch 0, gen_loss = 0.9333392996737297, disc_loss = 0.15059430588116038
Trained batch 47 in epoch 0, gen_loss = 0.9297784498582283, disc_loss = 0.14870930858887732
Trained batch 48 in epoch 0, gen_loss = 0.9377760041733177, disc_loss = 0.1477023392763673
Trained batch 49 in epoch 0, gen_loss = 0.9284769624471665, disc_loss = 0.1478861778229475
Trained batch 50 in epoch 0, gen_loss = 0.9350116714542988, disc_loss = 0.14647903549028377
Trained batch 51 in epoch 0, gen_loss = 0.9334975567001563, disc_loss = 0.14455404956466877
Trained batch 52 in epoch 0, gen_loss = 0.9335444406518396, disc_loss = 0.14267915880905008
Trained batch 53 in epoch 0, gen_loss = 0.9381261650058959, disc_loss = 0.14079725776833515
Trained batch 54 in epoch 0, gen_loss = 0.9380857657302509, disc_loss = 0.1388941224325787
Trained batch 55 in epoch 0, gen_loss = 0.9387376526636737, disc_loss = 0.13702132938695805
Trained batch 56 in epoch 0, gen_loss = 0.9404276844702268, disc_loss = 0.13523910338418527
Trained batch 57 in epoch 0, gen_loss = 0.9403087954069006, disc_loss = 0.13353912956241903
Trained batch 58 in epoch 0, gen_loss = 0.9423703566446142, disc_loss = 0.13194806962195088
Trained batch 59 in epoch 0, gen_loss = 0.94700178951025, disc_loss = 0.13064130910982688
Trained batch 60 in epoch 0, gen_loss = 0.9449970531659048, disc_loss = 0.12978275236291964
Trained batch 61 in epoch 0, gen_loss = 0.9490593157468303, disc_loss = 0.1289620753377676
Trained batch 62 in epoch 0, gen_loss = 0.9472010357985421, disc_loss = 0.1278330318866268
Trained batch 63 in epoch 0, gen_loss = 0.9493196639232337, disc_loss = 0.1266490662819706
Trained batch 64 in epoch 0, gen_loss = 0.9536272906340085, disc_loss = 0.12548042753568062
Trained batch 65 in epoch 0, gen_loss = 0.9519750317840865, disc_loss = 0.12473129695563605
Trained batch 66 in epoch 0, gen_loss = 0.9588767312355896, disc_loss = 0.12435646922285877
Trained batch 67 in epoch 0, gen_loss = 0.9531014276777997, disc_loss = 0.12443127231124569
Trained batch 68 in epoch 0, gen_loss = 0.9635563548924266, disc_loss = 0.12555720246788385
Trained batch 69 in epoch 0, gen_loss = 0.9622782209089824, disc_loss = 0.12552409353000776
Trained batch 70 in epoch 0, gen_loss = 0.9599412113008364, disc_loss = 0.1248875821770077
Trained batch 71 in epoch 0, gen_loss = 0.957308197600974, disc_loss = 0.12403605536868174
Trained batch 72 in epoch 0, gen_loss = 0.9599091349399254, disc_loss = 0.12341601993531397
Trained batch 73 in epoch 0, gen_loss = 0.9632024132722133, disc_loss = 0.12232152674649213
Trained batch 74 in epoch 0, gen_loss = 0.9622316579023997, disc_loss = 0.12126189216971398
Trained batch 75 in epoch 0, gen_loss = 0.957249072429381, disc_loss = 0.12069966148977217
Trained batch 76 in epoch 0, gen_loss = 0.9644849273291501, disc_loss = 0.12099785323847424
Trained batch 77 in epoch 0, gen_loss = 0.9589890337143189, disc_loss = 0.1207817509674873
Trained batch 78 in epoch 0, gen_loss = 0.9594289996201479, disc_loss = 0.11992140694320956
Trained batch 79 in epoch 0, gen_loss = 0.9600143041461706, disc_loss = 0.11914479923434555
Trained batch 80 in epoch 0, gen_loss = 0.9589829132144834, disc_loss = 0.11826883444999471
Trained batch 81 in epoch 0, gen_loss = 0.962961328829207, disc_loss = 0.11727317345396775
Trained batch 82 in epoch 0, gen_loss = 0.960235908447978, disc_loss = 0.11657572227967791
Trained batch 83 in epoch 0, gen_loss = 0.9643623513125238, disc_loss = 0.11614828898260991
Trained batch 84 in epoch 0, gen_loss = 0.9639563556979684, disc_loss = 0.11524203616906614
Trained batch 85 in epoch 0, gen_loss = 0.9602553764748019, disc_loss = 0.11485368364252323
Trained batch 86 in epoch 0, gen_loss = 0.9650705069646068, disc_loss = 0.11404885779852154
Trained batch 87 in epoch 0, gen_loss = 0.9688367968933149, disc_loss = 0.1131811962378296
Trained batch 88 in epoch 0, gen_loss = 0.9669661806540543, disc_loss = 0.11242398778709133
Trained batch 89 in epoch 0, gen_loss = 0.9658679581350751, disc_loss = 0.11158834389514394
Trained batch 90 in epoch 0, gen_loss = 0.9675045134602013, disc_loss = 0.11081472923467448
Trained batch 91 in epoch 0, gen_loss = 0.9645785167813301, disc_loss = 0.11021195007893055
Trained batch 92 in epoch 0, gen_loss = 0.9685577548319294, disc_loss = 0.10989704435711266
Trained batch 93 in epoch 0, gen_loss = 0.9626916218945321, disc_loss = 0.11035235174634356
Trained batch 94 in epoch 0, gen_loss = 0.9709743753859871, disc_loss = 0.11154804743434253
Trained batch 95 in epoch 0, gen_loss = 0.966561982097725, disc_loss = 0.11146628550098588
Trained batch 96 in epoch 0, gen_loss = 0.9651283932100866, disc_loss = 0.11092613218832262
Trained batch 97 in epoch 0, gen_loss = 0.9684926402203891, disc_loss = 0.11162723292957763
Trained batch 98 in epoch 0, gen_loss = 0.9617204383166149, disc_loss = 0.11360188050553052
Trained batch 99 in epoch 0, gen_loss = 0.9622342282533646, disc_loss = 0.11300911724567414
Trained batch 100 in epoch 0, gen_loss = 0.9635920530498618, disc_loss = 0.11276515086393545
Trained batch 101 in epoch 0, gen_loss = 0.9615979293982188, disc_loss = 0.1123700690473996
Trained batch 102 in epoch 0, gen_loss = 0.9591093289041982, disc_loss = 0.11193829434878617
Trained batch 103 in epoch 0, gen_loss = 0.9583378818172675, disc_loss = 0.11129550628650647
Trained batch 104 in epoch 0, gen_loss = 0.9580491962886992, disc_loss = 0.11083413099958783
Trained batch 105 in epoch 0, gen_loss = 0.9518302285446311, disc_loss = 0.11209999270877748
Trained batch 106 in epoch 0, gen_loss = 0.9584406001545559, disc_loss = 0.11466773000554503
Trained batch 107 in epoch 0, gen_loss = 0.9556690145421911, disc_loss = 0.11475246841156925
Trained batch 108 in epoch 0, gen_loss = 0.9505359888623613, disc_loss = 0.11572009817175909
Trained batch 109 in epoch 0, gen_loss = 0.9496486173434691, disc_loss = 0.11642282686450264
Trained batch 110 in epoch 0, gen_loss = 0.9482203595810108, disc_loss = 0.11632126442215464
Trained batch 111 in epoch 0, gen_loss = 0.9459971383746181, disc_loss = 0.11613747058436275
Trained batch 112 in epoch 0, gen_loss = 0.9436732512132257, disc_loss = 0.11599277685173845
Trained batch 113 in epoch 0, gen_loss = 0.9395736270306403, disc_loss = 0.11597460429919393
Trained batch 114 in epoch 0, gen_loss = 0.9403198597223862, disc_loss = 0.1163142935089443
Trained batch 115 in epoch 0, gen_loss = 0.9344737475802158, disc_loss = 0.11731750119862885
Trained batch 116 in epoch 0, gen_loss = 0.9367585220398047, disc_loss = 0.11877546975245842
Trained batch 117 in epoch 0, gen_loss = 0.9324772772142442, disc_loss = 0.11896451537386846
Trained batch 118 in epoch 0, gen_loss = 0.9269558439234725, disc_loss = 0.11978614367857701
Trained batch 119 in epoch 0, gen_loss = 0.9286782748997211, disc_loss = 0.12118086256086827
Trained batch 120 in epoch 0, gen_loss = 0.9261018394931289, disc_loss = 0.1216054397427346
Trained batch 121 in epoch 0, gen_loss = 0.9206844582909444, disc_loss = 0.12240296101472417
Trained batch 122 in epoch 0, gen_loss = 0.917660848881171, disc_loss = 0.12248517064059652
Trained batch 123 in epoch 0, gen_loss = 0.9160183696977554, disc_loss = 0.12260266561661998
Trained batch 124 in epoch 0, gen_loss = 0.9135369162559509, disc_loss = 0.12227170604467393
Trained batch 125 in epoch 0, gen_loss = 0.9124563397869231, disc_loss = 0.12189044123367658
Trained batch 126 in epoch 0, gen_loss = 0.9084329534703353, disc_loss = 0.12196707766591094
Trained batch 127 in epoch 0, gen_loss = 0.9091481701470912, disc_loss = 0.12294448033208027
Trained batch 128 in epoch 0, gen_loss = 0.9033408730991127, disc_loss = 0.12442781418099884
Trained batch 129 in epoch 0, gen_loss = 0.9005266641195003, disc_loss = 0.12446540576907304
Trained batch 130 in epoch 0, gen_loss = 0.9010293977406189, disc_loss = 0.1252076965365701
Trained batch 131 in epoch 0, gen_loss = 0.896850902700063, disc_loss = 0.12549372926128632
Trained batch 132 in epoch 0, gen_loss = 0.8939045400995957, disc_loss = 0.1256103124049373
Trained batch 133 in epoch 0, gen_loss = 0.8912212628481994, disc_loss = 0.12573568595211898
Trained batch 134 in epoch 0, gen_loss = 0.8893104250784274, disc_loss = 0.12594966408279207
Trained batch 135 in epoch 0, gen_loss = 0.8861903719165746, disc_loss = 0.12604356266777306
Trained batch 136 in epoch 0, gen_loss = 0.8851575107470046, disc_loss = 0.12593509501566852
Trained batch 137 in epoch 0, gen_loss = 0.8840519725412562, disc_loss = 0.1254270707891471
Trained batch 138 in epoch 0, gen_loss = 0.8803135928490179, disc_loss = 0.1255796752709279
Trained batch 139 in epoch 0, gen_loss = 0.882561435018267, disc_loss = 0.12698624064879757
Trained batch 140 in epoch 0, gen_loss = 0.8819681545521351, disc_loss = 0.12642157719807423
Trained batch 141 in epoch 0, gen_loss = 0.8770840138616697, disc_loss = 0.1277268000839042
Trained batch 142 in epoch 0, gen_loss = 0.8771152233744001, disc_loss = 0.128972948509288
Trained batch 143 in epoch 0, gen_loss = 0.8743564960443311, disc_loss = 0.1294394698149214
Trained batch 144 in epoch 0, gen_loss = 0.8710704205365016, disc_loss = 0.13014093398534018
Trained batch 145 in epoch 0, gen_loss = 0.8693728195886089, disc_loss = 0.13056012322131086
Trained batch 146 in epoch 0, gen_loss = 0.8663328567735192, disc_loss = 0.13085217548369552
Trained batch 147 in epoch 0, gen_loss = 0.8650327886681299, disc_loss = 0.13122129457927234
Trained batch 148 in epoch 0, gen_loss = 0.8633219609724595, disc_loss = 0.13114959989118097
Trained batch 149 in epoch 0, gen_loss = 0.8613031468788783, disc_loss = 0.130869976952672
Trained batch 150 in epoch 0, gen_loss = 0.8591785302620061, disc_loss = 0.13083578150300001
Trained batch 151 in epoch 0, gen_loss = 0.8588049080418912, disc_loss = 0.13079923486925268
Trained batch 152 in epoch 0, gen_loss = 0.8554764236110488, disc_loss = 0.13105023304134414
Trained batch 153 in epoch 0, gen_loss = 0.8564438593465012, disc_loss = 0.1315322227824431
Trained batch 154 in epoch 0, gen_loss = 0.8527545182935653, disc_loss = 0.13201270216415006
Trained batch 155 in epoch 0, gen_loss = 0.85308160002415, disc_loss = 0.1323772648540445
Trained batch 156 in epoch 0, gen_loss = 0.8497159629111077, disc_loss = 0.13275387055080407
Trained batch 157 in epoch 0, gen_loss = 0.849917858839035, disc_loss = 0.1327307206118786
Trained batch 158 in epoch 0, gen_loss = 0.848485880302933, disc_loss = 0.1325215496029119
Trained batch 159 in epoch 0, gen_loss = 0.8506538923829794, disc_loss = 0.13207497636321933
Trained batch 160 in epoch 0, gen_loss = 0.8475046185603053, disc_loss = 0.13223970142303046
Trained batch 161 in epoch 0, gen_loss = 0.8474776941685029, disc_loss = 0.13219940278357195
Trained batch 162 in epoch 0, gen_loss = 0.8450529939192204, disc_loss = 0.13215019204225276
Trained batch 163 in epoch 0, gen_loss = 0.8465639678079907, disc_loss = 0.13220182754008508
Trained batch 164 in epoch 0, gen_loss = 0.8442744347182187, disc_loss = 0.1320463220052647
Trained batch 165 in epoch 0, gen_loss = 0.8422171827181276, disc_loss = 0.13213063002261052
Trained batch 166 in epoch 0, gen_loss = 0.8413372783960696, disc_loss = 0.13215148553787592
Trained batch 167 in epoch 0, gen_loss = 0.8381064871237391, disc_loss = 0.13245903884637214
Trained batch 168 in epoch 0, gen_loss = 0.8377052841807259, disc_loss = 0.13239549971102962
Trained batch 169 in epoch 0, gen_loss = 0.8406226866385516, disc_loss = 0.13242398401831879
Trained batch 170 in epoch 0, gen_loss = 0.8366139588648813, disc_loss = 0.1336406557139946
Trained batch 171 in epoch 0, gen_loss = 0.8363226851405099, disc_loss = 0.13351644712045443
Trained batch 172 in epoch 0, gen_loss = 0.838281707784344, disc_loss = 0.13357001799293336
Trained batch 173 in epoch 0, gen_loss = 0.835788545766096, disc_loss = 0.13357658014129634
Trained batch 174 in epoch 0, gen_loss = 0.8338651015077319, disc_loss = 0.1335645527286189
Trained batch 175 in epoch 0, gen_loss = 0.8361969012767076, disc_loss = 0.1346390258986503
Trained batch 176 in epoch 0, gen_loss = 0.8325486745538011, disc_loss = 0.13555226283474156
Trained batch 177 in epoch 0, gen_loss = 0.8323692639222305, disc_loss = 0.13535091814616423
Trained batch 178 in epoch 0, gen_loss = 0.8312754211479059, disc_loss = 0.13557949718400086
Trained batch 179 in epoch 0, gen_loss = 0.8296214560667674, disc_loss = 0.135349323372874
Trained batch 180 in epoch 0, gen_loss = 0.8268851003923469, disc_loss = 0.13553562268450114
Trained batch 181 in epoch 0, gen_loss = 0.8276885818321627, disc_loss = 0.13603007369725914
Trained batch 182 in epoch 0, gen_loss = 0.8247833214496654, disc_loss = 0.13629351037203288
Trained batch 183 in epoch 0, gen_loss = 0.8245277795130792, disc_loss = 0.13646391983670386
Trained batch 184 in epoch 0, gen_loss = 0.8220870531894066, disc_loss = 0.1365512868238462
Trained batch 185 in epoch 0, gen_loss = 0.8208404473399603, disc_loss = 0.13660058982029397
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.3810378313064575, disc_loss = 0.1477685272693634
Trained batch 1 in epoch 1, gen_loss = 0.6594078540802002, disc_loss = 0.17573782801628113
Trained batch 2 in epoch 1, gen_loss = 0.5242168207963308, disc_loss = 0.18912636240323386
Trained batch 3 in epoch 1, gen_loss = 0.6274516806006432, disc_loss = 0.1867593713104725
Trained batch 4 in epoch 1, gen_loss = 0.602072685956955, disc_loss = 0.1692873328924179
Trained batch 5 in epoch 1, gen_loss = 0.6207801351944605, disc_loss = 0.15140611678361893
Trained batch 6 in epoch 1, gen_loss = 0.6316016955035073, disc_loss = 0.14043122317109788
Trained batch 7 in epoch 1, gen_loss = 0.6566914580762386, disc_loss = 0.13199856877326965
Trained batch 8 in epoch 1, gen_loss = 0.631730016734865, disc_loss = 0.1323112216260698
Trained batch 9 in epoch 1, gen_loss = 0.6773325473070144, disc_loss = 0.13319131284952163
Trained batch 10 in epoch 1, gen_loss = 0.6553657948970795, disc_loss = 0.13378482379696585
Trained batch 11 in epoch 1, gen_loss = 0.6783948416511217, disc_loss = 0.13105660925308862
Trained batch 12 in epoch 1, gen_loss = 0.6831796192205869, disc_loss = 0.12653536234910673
Trained batch 13 in epoch 1, gen_loss = 0.6711049484355109, disc_loss = 0.12423372002584594
Trained batch 14 in epoch 1, gen_loss = 0.6985612531503042, disc_loss = 0.12394519547621409
Trained batch 15 in epoch 1, gen_loss = 0.6846383828669786, disc_loss = 0.1253888225182891
Trained batch 16 in epoch 1, gen_loss = 0.6975428865236395, disc_loss = 0.1257144677288392
Trained batch 17 in epoch 1, gen_loss = 0.7000252389245563, disc_loss = 0.123492783970303
Trained batch 18 in epoch 1, gen_loss = 0.6881793941322126, disc_loss = 0.12315985952552996
Trained batch 19 in epoch 1, gen_loss = 0.7246920302510261, disc_loss = 0.13109115436673163
Trained batch 20 in epoch 1, gen_loss = 0.6969673818066007, disc_loss = 0.14475374065694355
Trained batch 21 in epoch 1, gen_loss = 0.7030940259044821, disc_loss = 0.14600744572552768
Trained batch 22 in epoch 1, gen_loss = 0.693194717168808, disc_loss = 0.1463100625121075
Trained batch 23 in epoch 1, gen_loss = 0.6778681340316931, disc_loss = 0.14878413702050844
Trained batch 24 in epoch 1, gen_loss = 0.6764563977718353, disc_loss = 0.14865760564804076
Trained batch 25 in epoch 1, gen_loss = 0.6735248462511942, disc_loss = 0.14866140943307143
Trained batch 26 in epoch 1, gen_loss = 0.6637085797610106, disc_loss = 0.1483706600136227
Trained batch 27 in epoch 1, gen_loss = 0.6594093090721539, disc_loss = 0.1483782439359597
Trained batch 28 in epoch 1, gen_loss = 0.6598732707829311, disc_loss = 0.1485923395074647
Trained batch 29 in epoch 1, gen_loss = 0.6566916912794113, disc_loss = 0.14684562707940738
Trained batch 30 in epoch 1, gen_loss = 0.6663687680998156, disc_loss = 0.14509279593344657
Trained batch 31 in epoch 1, gen_loss = 0.6599307134747505, disc_loss = 0.14403258985839784
Trained batch 32 in epoch 1, gen_loss = 0.6672856735460686, disc_loss = 0.14238507165150208
Trained batch 33 in epoch 1, gen_loss = 0.6660851029788747, disc_loss = 0.14066651945604997
Trained batch 34 in epoch 1, gen_loss = 0.6624310902186803, disc_loss = 0.1393767476081848
Trained batch 35 in epoch 1, gen_loss = 0.6687818864981333, disc_loss = 0.1387943263269133
Trained batch 36 in epoch 1, gen_loss = 0.6602597381617572, disc_loss = 0.13916943584744995
Trained batch 37 in epoch 1, gen_loss = 0.6713681393548062, disc_loss = 0.13991119967479454
Trained batch 38 in epoch 1, gen_loss = 0.6610045081529862, disc_loss = 0.141451266904672
Trained batch 39 in epoch 1, gen_loss = 0.6663885936141014, disc_loss = 0.14120368305593728
Trained batch 40 in epoch 1, gen_loss = 0.6684748661227342, disc_loss = 0.14001223317733624
Trained batch 41 in epoch 1, gen_loss = 0.6605302350861686, disc_loss = 0.14043500469554038
Trained batch 42 in epoch 1, gen_loss = 0.6661364879719046, disc_loss = 0.13975692834965017
Trained batch 43 in epoch 1, gen_loss = 0.6655273572965101, disc_loss = 0.1383627068928697
Trained batch 44 in epoch 1, gen_loss = 0.6606018397543165, disc_loss = 0.13781687335835563
Trained batch 45 in epoch 1, gen_loss = 0.6646302951418835, disc_loss = 0.1384113312739393
Trained batch 46 in epoch 1, gen_loss = 0.6581509170380044, disc_loss = 0.13869784280974815
Trained batch 47 in epoch 1, gen_loss = 0.6682226117700338, disc_loss = 0.138888667182376
Trained batch 48 in epoch 1, gen_loss = 0.6641333407285263, disc_loss = 0.1384276171423951
Trained batch 49 in epoch 1, gen_loss = 0.6639329743385315, disc_loss = 0.13792647942900657
Trained batch 50 in epoch 1, gen_loss = 0.6707435495713178, disc_loss = 0.13798669199733174
Trained batch 51 in epoch 1, gen_loss = 0.6655376289899533, disc_loss = 0.13791396511861911
Trained batch 52 in epoch 1, gen_loss = 0.6671894856219022, disc_loss = 0.13737511044403292
Trained batch 53 in epoch 1, gen_loss = 0.6706447501977285, disc_loss = 0.13583319827362342
Trained batch 54 in epoch 1, gen_loss = 0.672653632814234, disc_loss = 0.13399478725411676
Trained batch 55 in epoch 1, gen_loss = 0.672873643892152, disc_loss = 0.13267538490306055
Trained batch 56 in epoch 1, gen_loss = 0.6797055026941132, disc_loss = 0.1326734476575726
Trained batch 57 in epoch 1, gen_loss = 0.6715778415573055, disc_loss = 0.13465233872933635
Trained batch 58 in epoch 1, gen_loss = 0.6825545394824724, disc_loss = 0.1346515650087494
Trained batch 59 in epoch 1, gen_loss = 0.6790508384505908, disc_loss = 0.1342449755097429
Trained batch 60 in epoch 1, gen_loss = 0.6778977205518817, disc_loss = 0.13327949817796222
Trained batch 61 in epoch 1, gen_loss = 0.6835214490852048, disc_loss = 0.13245003315950593
Trained batch 62 in epoch 1, gen_loss = 0.6804877689906529, disc_loss = 0.13179028193865502
Trained batch 63 in epoch 1, gen_loss = 0.6840405073016882, disc_loss = 0.1306193246273324
Trained batch 64 in epoch 1, gen_loss = 0.6857300171485314, disc_loss = 0.1295506034906094
Trained batch 65 in epoch 1, gen_loss = 0.6855233401963206, disc_loss = 0.12839626667625975
Trained batch 66 in epoch 1, gen_loss = 0.688075867161822, disc_loss = 0.1280324525797545
Trained batch 67 in epoch 1, gen_loss = 0.6821516283294734, disc_loss = 0.12885786329998689
Trained batch 68 in epoch 1, gen_loss = 0.695102973692659, disc_loss = 0.13068549529365872
Trained batch 69 in epoch 1, gen_loss = 0.6893655274595533, disc_loss = 0.13161165416240692
Trained batch 70 in epoch 1, gen_loss = 0.6898007569178729, disc_loss = 0.13142913789816305
Trained batch 71 in epoch 1, gen_loss = 0.6905202708310552, disc_loss = 0.13260348493026364
Trained batch 72 in epoch 1, gen_loss = 0.6884078995822227, disc_loss = 0.13471012184881184
Trained batch 73 in epoch 1, gen_loss = 0.6900644560117979, disc_loss = 0.1382039062477447
Trained batch 74 in epoch 1, gen_loss = 0.6884648752212524, disc_loss = 0.1397109518448512
Trained batch 75 in epoch 1, gen_loss = 0.6859820081215156, disc_loss = 0.1405267295868773
Trained batch 76 in epoch 1, gen_loss = 0.6852611609093555, disc_loss = 0.141060976626037
Trained batch 77 in epoch 1, gen_loss = 0.6819918067791523, disc_loss = 0.14148700562043068
Trained batch 78 in epoch 1, gen_loss = 0.6826902126209645, disc_loss = 0.14186445519893984
Trained batch 79 in epoch 1, gen_loss = 0.6783416364341974, disc_loss = 0.14225968047976495
Trained batch 80 in epoch 1, gen_loss = 0.6802906537497485, disc_loss = 0.1420103868952504
Trained batch 81 in epoch 1, gen_loss = 0.6777493077807311, disc_loss = 0.14170501390244902
Trained batch 82 in epoch 1, gen_loss = 0.6788360774517059, disc_loss = 0.14121549702193364
Trained batch 83 in epoch 1, gen_loss = 0.6763734022776285, disc_loss = 0.14096033422365076
Trained batch 84 in epoch 1, gen_loss = 0.6817448363584631, disc_loss = 0.1408104527522536
Trained batch 85 in epoch 1, gen_loss = 0.6783256627792535, disc_loss = 0.14102802520921065
Trained batch 86 in epoch 1, gen_loss = 0.6819116055280313, disc_loss = 0.14022926035626182
Trained batch 87 in epoch 1, gen_loss = 0.6777080182324756, disc_loss = 0.1407242198051377
Trained batch 88 in epoch 1, gen_loss = 0.6897813543844759, disc_loss = 0.14360146818870909
Trained batch 89 in epoch 1, gen_loss = 0.6847139668133524, disc_loss = 0.1449498942328824
Trained batch 90 in epoch 1, gen_loss = 0.6829959159041499, disc_loss = 0.14460972483669007
Trained batch 91 in epoch 1, gen_loss = 0.6838286802496599, disc_loss = 0.14481843287206214
Trained batch 92 in epoch 1, gen_loss = 0.6816406895716985, disc_loss = 0.14483047164576027
Trained batch 93 in epoch 1, gen_loss = 0.6792095859951162, disc_loss = 0.1447286601871886
Trained batch 94 in epoch 1, gen_loss = 0.6789603131382089, disc_loss = 0.14434731273274673
Trained batch 95 in epoch 1, gen_loss = 0.6781707789438466, disc_loss = 0.14398444459463158
Trained batch 96 in epoch 1, gen_loss = 0.6771001851128549, disc_loss = 0.14340934203457587
Trained batch 97 in epoch 1, gen_loss = 0.6767305304505387, disc_loss = 0.14272731071224018
Trained batch 98 in epoch 1, gen_loss = 0.6767742505880318, disc_loss = 0.1420671058574108
Trained batch 99 in epoch 1, gen_loss = 0.675352010577917, disc_loss = 0.14165987275540828
Trained batch 100 in epoch 1, gen_loss = 0.6763429463204771, disc_loss = 0.1410466643548248
Trained batch 101 in epoch 1, gen_loss = 0.676431817605215, disc_loss = 0.14024839670780828
Trained batch 102 in epoch 1, gen_loss = 0.676019267983807, disc_loss = 0.13964695935544458
Trained batch 103 in epoch 1, gen_loss = 0.6779990412581426, disc_loss = 0.13966343390683716
Trained batch 104 in epoch 1, gen_loss = 0.6744475959312348, disc_loss = 0.14009505960912932
Trained batch 105 in epoch 1, gen_loss = 0.6776205148055868, disc_loss = 0.13957187136248597
Trained batch 106 in epoch 1, gen_loss = 0.6772536656288343, disc_loss = 0.1389228251423234
Trained batch 107 in epoch 1, gen_loss = 0.6780711433125867, disc_loss = 0.13835876997284316
Trained batch 108 in epoch 1, gen_loss = 0.6822728442216138, disc_loss = 0.1375875686970326
Trained batch 109 in epoch 1, gen_loss = 0.6818095243789933, disc_loss = 0.1369201348586516
Trained batch 110 in epoch 1, gen_loss = 0.6835482382291073, disc_loss = 0.13613456339986474
Trained batch 111 in epoch 1, gen_loss = 0.6857436425717813, disc_loss = 0.13544023313027406
Trained batch 112 in epoch 1, gen_loss = 0.686174259644694, disc_loss = 0.13464067226885695
Trained batch 113 in epoch 1, gen_loss = 0.6886235442862176, disc_loss = 0.13384596264937468
Trained batch 114 in epoch 1, gen_loss = 0.694206472972165, disc_loss = 0.1328909440856913
Trained batch 115 in epoch 1, gen_loss = 0.6971491080676687, disc_loss = 0.13197786617895652
Trained batch 116 in epoch 1, gen_loss = 0.6990979755790825, disc_loss = 0.13110135433574518
Trained batch 117 in epoch 1, gen_loss = 0.7033230762107897, disc_loss = 0.13020476504718348
Trained batch 118 in epoch 1, gen_loss = 0.7026358275603848, disc_loss = 0.12958084499197348
Trained batch 119 in epoch 1, gen_loss = 0.7068047775576513, disc_loss = 0.1291382311688115
Trained batch 120 in epoch 1, gen_loss = 0.703482044260364, disc_loss = 0.1294230355858064
Trained batch 121 in epoch 1, gen_loss = 0.7073130740738306, disc_loss = 0.1294261509186176
Trained batch 122 in epoch 1, gen_loss = 0.7047906899597587, disc_loss = 0.12932226463122581
Trained batch 123 in epoch 1, gen_loss = 0.7056913821687621, disc_loss = 0.12912529371979256
Trained batch 124 in epoch 1, gen_loss = 0.7081939700841904, disc_loss = 0.12839795331656934
Trained batch 125 in epoch 1, gen_loss = 0.7114534069384847, disc_loss = 0.12751404889341858
Trained batch 126 in epoch 1, gen_loss = 0.7105118739088689, disc_loss = 0.12708932391595185
Trained batch 127 in epoch 1, gen_loss = 0.7121877734316513, disc_loss = 0.1266322264127666
Trained batch 128 in epoch 1, gen_loss = 0.7108333354541497, disc_loss = 0.12625566403590893
Trained batch 129 in epoch 1, gen_loss = 0.7152527519143544, disc_loss = 0.1266760456017577
Trained batch 130 in epoch 1, gen_loss = 0.712747500029229, disc_loss = 0.12678717942695125
Trained batch 131 in epoch 1, gen_loss = 0.7141514374225428, disc_loss = 0.12608359916361445
Trained batch 132 in epoch 1, gen_loss = 0.7153627172224504, disc_loss = 0.12568594553136736
Trained batch 133 in epoch 1, gen_loss = 0.7174088793681629, disc_loss = 0.12506535111356581
Trained batch 134 in epoch 1, gen_loss = 0.719605920822532, disc_loss = 0.12428640709431082
Trained batch 135 in epoch 1, gen_loss = 0.7194219318163746, disc_loss = 0.12378105334937572
Trained batch 136 in epoch 1, gen_loss = 0.7209878345258045, disc_loss = 0.12331466270733053
Trained batch 137 in epoch 1, gen_loss = 0.7219105456834254, disc_loss = 0.12277781032025814
Trained batch 138 in epoch 1, gen_loss = 0.7235767973198307, disc_loss = 0.12204457535374937
Trained batch 139 in epoch 1, gen_loss = 0.7266375025468214, disc_loss = 0.12135851021323885
Trained batch 140 in epoch 1, gen_loss = 0.7273653562821395, disc_loss = 0.12067958145858125
Trained batch 141 in epoch 1, gen_loss = 0.7279961213049754, disc_loss = 0.12003617651078483
Trained batch 142 in epoch 1, gen_loss = 0.7321222256738823, disc_loss = 0.11941128035264832
Trained batch 143 in epoch 1, gen_loss = 0.7351482679239578, disc_loss = 0.11868237802991644
Trained batch 144 in epoch 1, gen_loss = 0.7338332134074178, disc_loss = 0.1184097600458511
Trained batch 145 in epoch 1, gen_loss = 0.7389750651096645, disc_loss = 0.1184572539777074
Trained batch 146 in epoch 1, gen_loss = 0.7367818954647803, disc_loss = 0.11842246856033599
Trained batch 147 in epoch 1, gen_loss = 0.7392171789464113, disc_loss = 0.11852484262498045
Trained batch 148 in epoch 1, gen_loss = 0.7362271998352652, disc_loss = 0.11887142827871862
Trained batch 149 in epoch 1, gen_loss = 0.7398408630490303, disc_loss = 0.11982979303225876
Trained batch 150 in epoch 1, gen_loss = 0.7368919664858192, disc_loss = 0.12027565913509257
Trained batch 151 in epoch 1, gen_loss = 0.734333846620039, disc_loss = 0.12058752555228573
Trained batch 152 in epoch 1, gen_loss = 0.7368142329205095, disc_loss = 0.1214815979653032
Trained batch 153 in epoch 1, gen_loss = 0.7340594906505052, disc_loss = 0.12186027836514177
Trained batch 154 in epoch 1, gen_loss = 0.732193747931911, disc_loss = 0.12190026588617794
Trained batch 155 in epoch 1, gen_loss = 0.7327638909411736, disc_loss = 0.12207180056840372
Trained batch 156 in epoch 1, gen_loss = 0.7309247089229571, disc_loss = 0.12206866160913069
Trained batch 157 in epoch 1, gen_loss = 0.7304282830674437, disc_loss = 0.12215415888784241
Trained batch 158 in epoch 1, gen_loss = 0.7290817492600506, disc_loss = 0.12200735786449422
Trained batch 159 in epoch 1, gen_loss = 0.7353870035149157, disc_loss = 0.12213444426306523
Trained batch 160 in epoch 1, gen_loss = 0.732364625294016, disc_loss = 0.12277005099755081
Trained batch 161 in epoch 1, gen_loss = 0.7328970958421259, disc_loss = 0.12286460368008709
Trained batch 162 in epoch 1, gen_loss = 0.7322640276394008, disc_loss = 0.12273507163591363
Trained batch 163 in epoch 1, gen_loss = 0.7298543371441888, disc_loss = 0.12287020452161569
Trained batch 164 in epoch 1, gen_loss = 0.7309664265675978, disc_loss = 0.12339943417658408
Trained batch 165 in epoch 1, gen_loss = 0.7286244672105973, disc_loss = 0.12363276501040323
Trained batch 166 in epoch 1, gen_loss = 0.729012536253044, disc_loss = 0.12351304886606104
Trained batch 167 in epoch 1, gen_loss = 0.7303105417106833, disc_loss = 0.12304392903267096
Trained batch 168 in epoch 1, gen_loss = 0.7270856460876013, disc_loss = 0.1238416564105266
Trained batch 169 in epoch 1, gen_loss = 0.7305631960139555, disc_loss = 0.12436547764193485
Trained batch 170 in epoch 1, gen_loss = 0.7301346558576439, disc_loss = 0.1239916387542385
Trained batch 171 in epoch 1, gen_loss = 0.7287525181160417, disc_loss = 0.12381427798441849
Trained batch 172 in epoch 1, gen_loss = 0.7281610724553896, disc_loss = 0.12359759360659502
Trained batch 173 in epoch 1, gen_loss = 0.7296429481999628, disc_loss = 0.1235908670511482
Trained batch 174 in epoch 1, gen_loss = 0.7322873885290964, disc_loss = 0.1229989372140595
Trained batch 175 in epoch 1, gen_loss = 0.7311100458556955, disc_loss = 0.1227977895336649
Trained batch 176 in epoch 1, gen_loss = 0.7315392305621993, disc_loss = 0.1222695771994143
Trained batch 177 in epoch 1, gen_loss = 0.7309082602516989, disc_loss = 0.12195282025011571
Trained batch 178 in epoch 1, gen_loss = 0.73266672322204, disc_loss = 0.1220364989088484
Trained batch 179 in epoch 1, gen_loss = 0.7300874777966075, disc_loss = 0.12240369151760307
Trained batch 180 in epoch 1, gen_loss = 0.7299502180755467, disc_loss = 0.12220880213754447
Trained batch 181 in epoch 1, gen_loss = 0.7318499220924063, disc_loss = 0.12213718982740909
Trained batch 182 in epoch 1, gen_loss = 0.7326696865219887, disc_loss = 0.121639080014833
Trained batch 183 in epoch 1, gen_loss = 0.7299321567558724, disc_loss = 0.12225905007622002
Trained batch 184 in epoch 1, gen_loss = 0.7324864859516557, disc_loss = 0.12235778895886364
Trained batch 185 in epoch 1, gen_loss = 0.7336681691869613, disc_loss = 0.1219396071198086
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.5339481234550476, disc_loss = 0.08377548307180405
Trained batch 1 in epoch 2, gen_loss = 0.5933459997177124, disc_loss = 0.07534803822636604
Trained batch 2 in epoch 2, gen_loss = 0.7298984527587891, disc_loss = 0.09705508997042973
Trained batch 3 in epoch 2, gen_loss = 0.6404882222414017, disc_loss = 0.10625170357525349
Trained batch 4 in epoch 2, gen_loss = 0.6755677103996277, disc_loss = 0.11165711134672165
Trained batch 5 in epoch 2, gen_loss = 0.6424180716276169, disc_loss = 0.11165906116366386
Trained batch 6 in epoch 2, gen_loss = 0.660073310136795, disc_loss = 0.1135970875620842
Trained batch 7 in epoch 2, gen_loss = 0.6518842689692974, disc_loss = 0.11255546100437641
Trained batch 8 in epoch 2, gen_loss = 0.6732187767823538, disc_loss = 0.10716859168476528
Trained batch 9 in epoch 2, gen_loss = 0.6866653293371201, disc_loss = 0.10406472906470299
Trained batch 10 in epoch 2, gen_loss = 0.708924415436658, disc_loss = 0.09644426066767085
Trained batch 11 in epoch 2, gen_loss = 0.7063566769162813, disc_loss = 0.09216591839989026
Trained batch 12 in epoch 2, gen_loss = 0.7478662752188169, disc_loss = 0.09102689532133248
Trained batch 13 in epoch 2, gen_loss = 0.7835154043776649, disc_loss = 0.0858612313334431
Trained batch 14 in epoch 2, gen_loss = 0.7541156311829885, disc_loss = 0.09034645929932594
Trained batch 15 in epoch 2, gen_loss = 0.7964492160826921, disc_loss = 0.09730195044539869
Trained batch 16 in epoch 2, gen_loss = 0.7625948506243089, disc_loss = 0.10518348107443136
Trained batch 17 in epoch 2, gen_loss = 0.7543023592895932, disc_loss = 0.10430900897416803
Trained batch 18 in epoch 2, gen_loss = 0.7672953260572333, disc_loss = 0.1050334249280001
Trained batch 19 in epoch 2, gen_loss = 0.7608753591775894, disc_loss = 0.10273450333625078
Trained batch 20 in epoch 2, gen_loss = 0.7511414601689294, disc_loss = 0.10193835500450361
Trained batch 21 in epoch 2, gen_loss = 0.7638282423669641, disc_loss = 0.10221835716881535
Trained batch 22 in epoch 2, gen_loss = 0.7601061385610829, disc_loss = 0.09953180360405342
Trained batch 23 in epoch 2, gen_loss = 0.7482385163505872, disc_loss = 0.09882159888123472
Trained batch 24 in epoch 2, gen_loss = 0.7691961073875427, disc_loss = 0.10464854463934899
Trained batch 25 in epoch 2, gen_loss = 0.7503012556296128, disc_loss = 0.10772215503339584
Trained batch 26 in epoch 2, gen_loss = 0.7468264522375884, disc_loss = 0.10772522939024148
Trained batch 27 in epoch 2, gen_loss = 0.7544015007359641, disc_loss = 0.10643612260797194
Trained batch 28 in epoch 2, gen_loss = 0.7490062754729698, disc_loss = 0.10497248930663898
Trained batch 29 in epoch 2, gen_loss = 0.7489759922027588, disc_loss = 0.10295429167648157
Trained batch 30 in epoch 2, gen_loss = 0.7533121455100275, disc_loss = 0.10085621728531775
Trained batch 31 in epoch 2, gen_loss = 0.7585734073072672, disc_loss = 0.09868825250305235
Trained batch 32 in epoch 2, gen_loss = 0.7653129498163859, disc_loss = 0.0962787622755224
Trained batch 33 in epoch 2, gen_loss = 0.7526046055204728, disc_loss = 0.09771407877697665
Trained batch 34 in epoch 2, gen_loss = 0.765147272178105, disc_loss = 0.09987427507128034
Trained batch 35 in epoch 2, gen_loss = 0.7540772673156526, disc_loss = 0.10088268915812175
Trained batch 36 in epoch 2, gen_loss = 0.7544333805909028, disc_loss = 0.10078053538863724
Trained batch 37 in epoch 2, gen_loss = 0.751283165655638, disc_loss = 0.1007904135867169
Trained batch 38 in epoch 2, gen_loss = 0.7506679724424313, disc_loss = 0.10084823538095523
Trained batch 39 in epoch 2, gen_loss = 0.7488702327013016, disc_loss = 0.10175191983580589
Trained batch 40 in epoch 2, gen_loss = 0.7494733842407785, disc_loss = 0.10183019954256894
Trained batch 41 in epoch 2, gen_loss = 0.7451328535874685, disc_loss = 0.10164760425686836
Trained batch 42 in epoch 2, gen_loss = 0.7559039412542831, disc_loss = 0.10077325809140537
Trained batch 43 in epoch 2, gen_loss = 0.7655314925042066, disc_loss = 0.0988767638125203
Trained batch 44 in epoch 2, gen_loss = 0.7553733501169416, disc_loss = 0.10067502723799812
Trained batch 45 in epoch 2, gen_loss = 0.7701979558105054, disc_loss = 0.10106799702929414
Trained batch 46 in epoch 2, gen_loss = 0.7807603586227336, disc_loss = 0.09935385056157062
Trained batch 47 in epoch 2, gen_loss = 0.7738808194796244, disc_loss = 0.09949460350132237
Trained batch 48 in epoch 2, gen_loss = 0.7717006401139863, disc_loss = 0.09856203620379068
Trained batch 49 in epoch 2, gen_loss = 0.7854919242858887, disc_loss = 0.10451961036771536
Trained batch 50 in epoch 2, gen_loss = 0.7755662752132789, disc_loss = 0.10648970126959623
Trained batch 51 in epoch 2, gen_loss = 0.7733244357200769, disc_loss = 0.1060210749721871
Trained batch 52 in epoch 2, gen_loss = 0.7740082077260287, disc_loss = 0.10687175530167121
Trained batch 53 in epoch 2, gen_loss = 0.7637622831044374, disc_loss = 0.10877834284609114
Trained batch 54 in epoch 2, gen_loss = 0.7672475782307712, disc_loss = 0.1092769649557092
Trained batch 55 in epoch 2, gen_loss = 0.7627955962504659, disc_loss = 0.10928101169078477
Trained batch 56 in epoch 2, gen_loss = 0.7605314307045519, disc_loss = 0.10844276789902595
Trained batch 57 in epoch 2, gen_loss = 0.7614229136499865, disc_loss = 0.10748003554883702
Trained batch 58 in epoch 2, gen_loss = 0.7600262468144044, disc_loss = 0.10676468091117124
Trained batch 59 in epoch 2, gen_loss = 0.7623559713363648, disc_loss = 0.10562266325578093
Trained batch 60 in epoch 2, gen_loss = 0.7563152963020763, disc_loss = 0.10580490935654914
Trained batch 61 in epoch 2, gen_loss = 0.761762606040124, disc_loss = 0.10648019410549633
Trained batch 62 in epoch 2, gen_loss = 0.7560233913716816, disc_loss = 0.10668604126170514
Trained batch 63 in epoch 2, gen_loss = 0.7570641874335706, disc_loss = 0.10672275759861805
Trained batch 64 in epoch 2, gen_loss = 0.7550654149972476, disc_loss = 0.10616957708620108
Trained batch 65 in epoch 2, gen_loss = 0.754686658581098, disc_loss = 0.10519667779744575
Trained batch 66 in epoch 2, gen_loss = 0.7525737085449162, disc_loss = 0.10471396267747701
Trained batch 67 in epoch 2, gen_loss = 0.7549624973360229, disc_loss = 0.10445693877580411
Trained batch 68 in epoch 2, gen_loss = 0.7523703657198644, disc_loss = 0.10382972017902395
Trained batch 69 in epoch 2, gen_loss = 0.755181387918336, disc_loss = 0.10295354018786124
Trained batch 70 in epoch 2, gen_loss = 0.7554706322475219, disc_loss = 0.10213105850131579
Trained batch 71 in epoch 2, gen_loss = 0.7587994573016962, disc_loss = 0.10102887420604627
Trained batch 72 in epoch 2, gen_loss = 0.7546880841255188, disc_loss = 0.10099757370883472
Trained batch 73 in epoch 2, gen_loss = 0.7674020730160378, disc_loss = 0.10325660939152176
Trained batch 74 in epoch 2, gen_loss = 0.759962085088094, disc_loss = 0.1052249010403951
Trained batch 75 in epoch 2, gen_loss = 0.7632122290761847, disc_loss = 0.10530390110062926
Trained batch 76 in epoch 2, gen_loss = 0.7592941987050044, disc_loss = 0.1053343474284395
Trained batch 77 in epoch 2, gen_loss = 0.7582628917999756, disc_loss = 0.10490661372358982
Trained batch 78 in epoch 2, gen_loss = 0.7592605631562728, disc_loss = 0.10450365328336064
Trained batch 79 in epoch 2, gen_loss = 0.7568858690559864, disc_loss = 0.10445491448044777
Trained batch 80 in epoch 2, gen_loss = 0.7548043198055692, disc_loss = 0.10405980703639395
Trained batch 81 in epoch 2, gen_loss = 0.755756660205562, disc_loss = 0.1037227823966887
Trained batch 82 in epoch 2, gen_loss = 0.753720794815615, disc_loss = 0.10323442796985786
Trained batch 83 in epoch 2, gen_loss = 0.7533993082387107, disc_loss = 0.10292667398850124
Trained batch 84 in epoch 2, gen_loss = 0.7537966237348669, disc_loss = 0.10261747083243201
Trained batch 85 in epoch 2, gen_loss = 0.7504990222149117, disc_loss = 0.10248544864183248
Trained batch 86 in epoch 2, gen_loss = 0.7538021826881102, disc_loss = 0.10279684590882268
Trained batch 87 in epoch 2, gen_loss = 0.7498978765850718, disc_loss = 0.10295683103190227
Trained batch 88 in epoch 2, gen_loss = 0.7546946021278252, disc_loss = 0.10357389599084854
Trained batch 89 in epoch 2, gen_loss = 0.7496163480811648, disc_loss = 0.10446956977248192
Trained batch 90 in epoch 2, gen_loss = 0.7522869902652699, disc_loss = 0.10523665712757425
Trained batch 91 in epoch 2, gen_loss = 0.7490454944579498, disc_loss = 0.10565144544386346
Trained batch 92 in epoch 2, gen_loss = 0.7476480007171631, disc_loss = 0.10628607556704552
Trained batch 93 in epoch 2, gen_loss = 0.7485742886015709, disc_loss = 0.1066790279397305
Trained batch 94 in epoch 2, gen_loss = 0.7497124182550531, disc_loss = 0.10614949147167958
Trained batch 95 in epoch 2, gen_loss = 0.7461355452736219, disc_loss = 0.10636442135243367
Trained batch 96 in epoch 2, gen_loss = 0.7507117900651755, disc_loss = 0.10705522359492853
Trained batch 97 in epoch 2, gen_loss = 0.7477286585739681, disc_loss = 0.10732336368943964
Trained batch 98 in epoch 2, gen_loss = 0.7479164100656606, disc_loss = 0.10707247840485187
Trained batch 99 in epoch 2, gen_loss = 0.7491606384515762, disc_loss = 0.10650835171341896
Trained batch 100 in epoch 2, gen_loss = 0.7495629893671168, disc_loss = 0.10581728454568598
Trained batch 101 in epoch 2, gen_loss = 0.7502561176524443, disc_loss = 0.10509059848446473
Trained batch 102 in epoch 2, gen_loss = 0.7536501977050188, disc_loss = 0.1045302113210692
Trained batch 103 in epoch 2, gen_loss = 0.7515548370205439, disc_loss = 0.10430412585488878
Trained batch 104 in epoch 2, gen_loss = 0.7546615129425412, disc_loss = 0.10363550296141988
Trained batch 105 in epoch 2, gen_loss = 0.7555733649235852, disc_loss = 0.10306683931288854
Trained batch 106 in epoch 2, gen_loss = 0.7569256369198594, disc_loss = 0.10228158726800825
Trained batch 107 in epoch 2, gen_loss = 0.7612579580810335, disc_loss = 0.1015227501694527
Trained batch 108 in epoch 2, gen_loss = 0.7602610063115391, disc_loss = 0.10101820848061951
Trained batch 109 in epoch 2, gen_loss = 0.7638336701826616, disc_loss = 0.10049377139657736
Trained batch 110 in epoch 2, gen_loss = 0.7645759598628895, disc_loss = 0.09980072218689832
Trained batch 111 in epoch 2, gen_loss = 0.7715070721294198, disc_loss = 0.09922901770499136
Trained batch 112 in epoch 2, gen_loss = 0.7724040741414095, disc_loss = 0.09866007928431561
Trained batch 113 in epoch 2, gen_loss = 0.7740399664954135, disc_loss = 0.0979764380475931
Trained batch 114 in epoch 2, gen_loss = 0.7785039606301681, disc_loss = 0.09739550718146822
Trained batch 115 in epoch 2, gen_loss = 0.779186664984144, disc_loss = 0.09676939716305712
Trained batch 116 in epoch 2, gen_loss = 0.7797882674086807, disc_loss = 0.0961481310490869
Trained batch 117 in epoch 2, gen_loss = 0.7833248230360322, disc_loss = 0.0955863088306229
Trained batch 118 in epoch 2, gen_loss = 0.7834736880134133, disc_loss = 0.09499996646988292
Trained batch 119 in epoch 2, gen_loss = 0.7879835327466329, disc_loss = 0.09437812647471826
Trained batch 120 in epoch 2, gen_loss = 0.7892898626563963, disc_loss = 0.09373288447699271
Trained batch 121 in epoch 2, gen_loss = 0.7899578252776724, disc_loss = 0.09332976056659809
Trained batch 122 in epoch 2, gen_loss = 0.7897263639341525, disc_loss = 0.09283480947700942
Trained batch 123 in epoch 2, gen_loss = 0.7928025741730967, disc_loss = 0.09254720536691527
Trained batch 124 in epoch 2, gen_loss = 0.7930411829948425, disc_loss = 0.092069709867239
Trained batch 125 in epoch 2, gen_loss = 0.7917637583755311, disc_loss = 0.091767603797572
Trained batch 126 in epoch 2, gen_loss = 0.7980164960613401, disc_loss = 0.09255612142912047
Trained batch 127 in epoch 2, gen_loss = 0.7930862670764327, disc_loss = 0.09408395446371287
Trained batch 128 in epoch 2, gen_loss = 0.7934196688408075, disc_loss = 0.09390279107777648
Trained batch 129 in epoch 2, gen_loss = 0.7958558073410621, disc_loss = 0.09401034701329011
Trained batch 130 in epoch 2, gen_loss = 0.7920756754074388, disc_loss = 0.09468019167885526
Trained batch 131 in epoch 2, gen_loss = 0.7897491726008329, disc_loss = 0.09500746428966522
Trained batch 132 in epoch 2, gen_loss = 0.7928335263316793, disc_loss = 0.09536160741533552
Trained batch 133 in epoch 2, gen_loss = 0.7904835883806001, disc_loss = 0.09544874138351697
Trained batch 134 in epoch 2, gen_loss = 0.7897965883767163, disc_loss = 0.09527564291600828
Trained batch 135 in epoch 2, gen_loss = 0.7904282674631652, disc_loss = 0.09512606663081576
Trained batch 136 in epoch 2, gen_loss = 0.7899436874546274, disc_loss = 0.09485521869067728
Trained batch 137 in epoch 2, gen_loss = 0.7892491469780604, disc_loss = 0.09465891997451367
Trained batch 138 in epoch 2, gen_loss = 0.7901772095573892, disc_loss = 0.09428906890985778
Trained batch 139 in epoch 2, gen_loss = 0.7878086992672512, disc_loss = 0.09425656609237194
Trained batch 140 in epoch 2, gen_loss = 0.7909331025806725, disc_loss = 0.09455270256767882
Trained batch 141 in epoch 2, gen_loss = 0.7879893248769599, disc_loss = 0.09488262850004182
Trained batch 142 in epoch 2, gen_loss = 0.7886150135443761, disc_loss = 0.09462842663059702
Trained batch 143 in epoch 2, gen_loss = 0.7884123646136787, disc_loss = 0.09454730686007275
Trained batch 144 in epoch 2, gen_loss = 0.7877327505884499, disc_loss = 0.09416686699822031
Trained batch 145 in epoch 2, gen_loss = 0.7893484306253798, disc_loss = 0.09401894888955437
Trained batch 146 in epoch 2, gen_loss = 0.7856596343371333, disc_loss = 0.09477324314972982
Trained batch 147 in epoch 2, gen_loss = 0.7885067704561595, disc_loss = 0.09518778553182208
Trained batch 148 in epoch 2, gen_loss = 0.7869258470983314, disc_loss = 0.09510150099260695
Trained batch 149 in epoch 2, gen_loss = 0.7859078693389893, disc_loss = 0.09492530889809131
Trained batch 150 in epoch 2, gen_loss = 0.7862866643248805, disc_loss = 0.0946308384026518
Trained batch 151 in epoch 2, gen_loss = 0.7873668529485401, disc_loss = 0.09445071565967642
Trained batch 152 in epoch 2, gen_loss = 0.7869965850917342, disc_loss = 0.09407064515878172
Trained batch 153 in epoch 2, gen_loss = 0.7869436303516487, disc_loss = 0.09378124379202143
Trained batch 154 in epoch 2, gen_loss = 0.7873463853713005, disc_loss = 0.09341425405394646
Trained batch 155 in epoch 2, gen_loss = 0.7878511219452589, disc_loss = 0.09306240325363782
Trained batch 156 in epoch 2, gen_loss = 0.7865836141975062, disc_loss = 0.09283958565277659
Trained batch 157 in epoch 2, gen_loss = 0.7889878644218927, disc_loss = 0.09288586723276332
Trained batch 158 in epoch 2, gen_loss = 0.7864421652922841, disc_loss = 0.09320910331213249
Trained batch 159 in epoch 2, gen_loss = 0.7870215186849236, disc_loss = 0.0929152527358383
Trained batch 160 in epoch 2, gen_loss = 0.7891716381407673, disc_loss = 0.09329888414337027
Trained batch 161 in epoch 2, gen_loss = 0.7858064434042683, disc_loss = 0.09406800177178265
Trained batch 162 in epoch 2, gen_loss = 0.7842032040920726, disc_loss = 0.09404986443146607
Trained batch 163 in epoch 2, gen_loss = 0.786152295404818, disc_loss = 0.0943729601709581
Trained batch 164 in epoch 2, gen_loss = 0.7844598547978835, disc_loss = 0.0944363788673372
Trained batch 165 in epoch 2, gen_loss = 0.7847389831959483, disc_loss = 0.09417109608829739
Trained batch 166 in epoch 2, gen_loss = 0.7851214896062177, disc_loss = 0.0939412960659958
Trained batch 167 in epoch 2, gen_loss = 0.7857962937227317, disc_loss = 0.09352513555703419
Trained batch 168 in epoch 2, gen_loss = 0.7849757641377534, disc_loss = 0.09323928185556768
Trained batch 169 in epoch 2, gen_loss = 0.7884036013308693, disc_loss = 0.0931357999715735
Trained batch 170 in epoch 2, gen_loss = 0.7867327574749439, disc_loss = 0.09313525915233015
Trained batch 171 in epoch 2, gen_loss = 0.7868435381110325, disc_loss = 0.09286204106066116
Trained batch 172 in epoch 2, gen_loss = 0.7903890980116893, disc_loss = 0.09314367532557835
Trained batch 173 in epoch 2, gen_loss = 0.7876811815404344, disc_loss = 0.09368380711510263
Trained batch 174 in epoch 2, gen_loss = 0.7885219791957311, disc_loss = 0.09342044602547372
Trained batch 175 in epoch 2, gen_loss = 0.788542159579017, disc_loss = 0.09315307618288154
Trained batch 176 in epoch 2, gen_loss = 0.7900462352623374, disc_loss = 0.09292016132066479
Trained batch 177 in epoch 2, gen_loss = 0.788530430432116, disc_loss = 0.09289218485355377
Trained batch 178 in epoch 2, gen_loss = 0.7895408385958751, disc_loss = 0.09271042960482603
Trained batch 179 in epoch 2, gen_loss = 0.7896989434957504, disc_loss = 0.09242562057657375
Trained batch 180 in epoch 2, gen_loss = 0.7905552532132818, disc_loss = 0.09232622033077709
Trained batch 181 in epoch 2, gen_loss = 0.7916662129727039, disc_loss = 0.09203410285760413
Trained batch 182 in epoch 2, gen_loss = 0.7912513125138204, disc_loss = 0.09174671091261458
Trained batch 183 in epoch 2, gen_loss = 0.791382664895576, disc_loss = 0.09137427021303902
Trained batch 184 in epoch 2, gen_loss = 0.7945016612877717, disc_loss = 0.09125206124138188
Trained batch 185 in epoch 2, gen_loss = 0.7925893156438746, disc_loss = 0.09132366719585593
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.9167076945304871, disc_loss = 0.043434567749500275
Trained batch 1 in epoch 3, gen_loss = 1.0030322968959808, disc_loss = 0.041376302018761635
Trained batch 2 in epoch 3, gen_loss = 0.9085920055707296, disc_loss = 0.038422382126251854
Trained batch 3 in epoch 3, gen_loss = 0.8926900923252106, disc_loss = 0.042328824289143085
Trained batch 4 in epoch 3, gen_loss = 0.9164980173110961, disc_loss = 0.038106204569339754
Trained batch 5 in epoch 3, gen_loss = 0.9721489548683167, disc_loss = 0.03468502343942722
Trained batch 6 in epoch 3, gen_loss = 0.9776908499853951, disc_loss = 0.03203555888363293
Trained batch 7 in epoch 3, gen_loss = 0.9543919786810875, disc_loss = 0.03136573173105717
Trained batch 8 in epoch 3, gen_loss = 1.0061168339517381, disc_loss = 0.0328392850028144
Trained batch 9 in epoch 3, gen_loss = 0.9765526115894317, disc_loss = 0.03289480991661549
Trained batch 10 in epoch 3, gen_loss = 0.9868670864538713, disc_loss = 0.0318187183954499
Trained batch 11 in epoch 3, gen_loss = 0.9985432773828506, disc_loss = 0.030496554138759773
Trained batch 12 in epoch 3, gen_loss = 1.0026084688993602, disc_loss = 0.029133343496001683
Trained batch 13 in epoch 3, gen_loss = 1.0156352647713252, disc_loss = 0.027875347661652734
Trained batch 14 in epoch 3, gen_loss = 1.0185147563616435, disc_loss = 0.027118578739464282
Trained batch 15 in epoch 3, gen_loss = 0.9923495203256607, disc_loss = 0.02902901655761525
Trained batch 16 in epoch 3, gen_loss = 1.0255869837368237, disc_loss = 0.03122993136810906
Trained batch 17 in epoch 3, gen_loss = 1.0028411083751254, disc_loss = 0.03271440618361036
Trained batch 18 in epoch 3, gen_loss = 0.9925084270929035, disc_loss = 0.033390726649055354
Trained batch 19 in epoch 3, gen_loss = 1.0034574657678603, disc_loss = 0.03796645249240101
Trained batch 20 in epoch 3, gen_loss = 0.9680880038511186, disc_loss = 0.045573472222756775
Trained batch 21 in epoch 3, gen_loss = 0.9583850516514345, disc_loss = 0.04574701422825456
Trained batch 22 in epoch 3, gen_loss = 0.9650211295355922, disc_loss = 0.0512682655826211
Trained batch 23 in epoch 3, gen_loss = 0.941008755316337, disc_loss = 0.054136355058290064
Trained batch 24 in epoch 3, gen_loss = 0.9372797596454621, disc_loss = 0.05403304513543844
Trained batch 25 in epoch 3, gen_loss = 0.9402505812736658, disc_loss = 0.05511909547763375
Trained batch 26 in epoch 3, gen_loss = 0.9198697772290971, disc_loss = 0.05788116153605558
Trained batch 27 in epoch 3, gen_loss = 0.9109628275036812, disc_loss = 0.057995705432923775
Trained batch 28 in epoch 3, gen_loss = 0.9279737914430684, disc_loss = 0.061264707835326934
Trained batch 29 in epoch 3, gen_loss = 0.9177959750096003, disc_loss = 0.06118859061971307
Trained batch 30 in epoch 3, gen_loss = 0.9079172024803777, disc_loss = 0.061331498616885756
Trained batch 31 in epoch 3, gen_loss = 0.9114029137417674, disc_loss = 0.0648832471051719
Trained batch 32 in epoch 3, gen_loss = 0.8938292337186409, disc_loss = 0.06760576827395143
Trained batch 33 in epoch 3, gen_loss = 0.8898265694870668, disc_loss = 0.06771608800901209
Trained batch 34 in epoch 3, gen_loss = 0.8906795978546143, disc_loss = 0.06872870695910284
Trained batch 35 in epoch 3, gen_loss = 0.8811865333053801, disc_loss = 0.06944574547621112
Trained batch 36 in epoch 3, gen_loss = 0.8799117207527161, disc_loss = 0.0709678785170655
Trained batch 37 in epoch 3, gen_loss = 0.8684228721417879, disc_loss = 0.07194305787255105
Trained batch 38 in epoch 3, gen_loss = 0.868358558569199, disc_loss = 0.07135812324495652
Trained batch 39 in epoch 3, gen_loss = 0.8698162376880646, disc_loss = 0.07154879753943533
Trained batch 40 in epoch 3, gen_loss = 0.8622190952301025, disc_loss = 0.07136383232456155
Trained batch 41 in epoch 3, gen_loss = 0.8625483768326896, disc_loss = 0.07057975939962835
Trained batch 42 in epoch 3, gen_loss = 0.8594196009081464, disc_loss = 0.07046190161951059
Trained batch 43 in epoch 3, gen_loss = 0.8565863411534916, disc_loss = 0.06985808297229762
Trained batch 44 in epoch 3, gen_loss = 0.8588053822517395, disc_loss = 0.06952056733684407
Trained batch 45 in epoch 3, gen_loss = 0.8538602033387059, disc_loss = 0.0691488522671811
Trained batch 46 in epoch 3, gen_loss = 0.8522410963443999, disc_loss = 0.06870033922902447
Trained batch 47 in epoch 3, gen_loss = 0.8525006348888079, disc_loss = 0.06854190442633505
Trained batch 48 in epoch 3, gen_loss = 0.8436799219676426, disc_loss = 0.06925848443821377
Trained batch 49 in epoch 3, gen_loss = 0.8484437489509582, disc_loss = 0.07012865794822573
Trained batch 50 in epoch 3, gen_loss = 0.8400609890619913, disc_loss = 0.07160530851094746
Trained batch 51 in epoch 3, gen_loss = 0.8468989065060248, disc_loss = 0.07292094180145516
Trained batch 52 in epoch 3, gen_loss = 0.8416568974279007, disc_loss = 0.073863664308106
Trained batch 53 in epoch 3, gen_loss = 0.8423103425237868, disc_loss = 0.07398901629710088
Trained batch 54 in epoch 3, gen_loss = 0.8451665910807523, disc_loss = 0.07330521262166174
Trained batch 55 in epoch 3, gen_loss = 0.8520595761282104, disc_loss = 0.07231444471316147
Trained batch 56 in epoch 3, gen_loss = 0.8478531868834245, disc_loss = 0.07198544080254801
Trained batch 57 in epoch 3, gen_loss = 0.8498439531901787, disc_loss = 0.07170961859860811
Trained batch 58 in epoch 3, gen_loss = 0.846957886623124, disc_loss = 0.07127637067273007
Trained batch 59 in epoch 3, gen_loss = 0.847822700937589, disc_loss = 0.07081504357047379
Trained batch 60 in epoch 3, gen_loss = 0.8511410394652945, disc_loss = 0.0698824961379659
Trained batch 61 in epoch 3, gen_loss = 0.8574670466684526, disc_loss = 0.06898995256051421
Trained batch 62 in epoch 3, gen_loss = 0.862803424161578, disc_loss = 0.06809281464666128
Trained batch 63 in epoch 3, gen_loss = 0.8637052988633513, disc_loss = 0.06729130395979155
Trained batch 64 in epoch 3, gen_loss = 0.8657078990569481, disc_loss = 0.0664261033042119
Trained batch 65 in epoch 3, gen_loss = 0.8685750049172025, disc_loss = 0.06556741944090887
Trained batch 66 in epoch 3, gen_loss = 0.8694260360589668, disc_loss = 0.06485974805346176
Trained batch 67 in epoch 3, gen_loss = 0.8812765119706883, disc_loss = 0.06468887577819474
Trained batch 68 in epoch 3, gen_loss = 0.8805352769036224, disc_loss = 0.06426194661121437
Trained batch 69 in epoch 3, gen_loss = 0.8798931326184954, disc_loss = 0.06367276034184864
Trained batch 70 in epoch 3, gen_loss = 0.882132459694231, disc_loss = 0.06299645569123014
Trained batch 71 in epoch 3, gen_loss = 0.8825474911265903, disc_loss = 0.06235987403326564
Trained batch 72 in epoch 3, gen_loss = 0.883100008311337, disc_loss = 0.06170973856614469
Trained batch 73 in epoch 3, gen_loss = 0.8835486463598303, disc_loss = 0.06109645304496627
Trained batch 74 in epoch 3, gen_loss = 0.8850875743230184, disc_loss = 0.06074209105223417
Trained batch 75 in epoch 3, gen_loss = 0.8818428249735581, disc_loss = 0.06052571154003473
Trained batch 76 in epoch 3, gen_loss = 0.8854294086431528, disc_loss = 0.060427793204881154
Trained batch 77 in epoch 3, gen_loss = 0.8773342779813669, disc_loss = 0.062127796276353106
Trained batch 78 in epoch 3, gen_loss = 0.8894688083401209, disc_loss = 0.06657431337133615
Trained batch 79 in epoch 3, gen_loss = 0.8803246865049005, disc_loss = 0.06953048981959001
Trained batch 80 in epoch 3, gen_loss = 0.8786036690444122, disc_loss = 0.06969140797715496
Trained batch 81 in epoch 3, gen_loss = 0.8808680949051205, disc_loss = 0.06997408632688769
Trained batch 82 in epoch 3, gen_loss = 0.877836950033544, disc_loss = 0.07050943326384547
Trained batch 83 in epoch 3, gen_loss = 0.8763172138659727, disc_loss = 0.07108694772856931
Trained batch 84 in epoch 3, gen_loss = 0.8773072686265496, disc_loss = 0.07133290124509264
Trained batch 85 in epoch 3, gen_loss = 0.8751120846285376, disc_loss = 0.07115400574971424
Trained batch 86 in epoch 3, gen_loss = 0.8732057373071539, disc_loss = 0.07101814188705437
Trained batch 87 in epoch 3, gen_loss = 0.8726449461484497, disc_loss = 0.0704897915288298
Trained batch 88 in epoch 3, gen_loss = 0.8720095608006703, disc_loss = 0.07024685482839856
Trained batch 89 in epoch 3, gen_loss = 0.8713686222831408, disc_loss = 0.06978257396775815
Trained batch 90 in epoch 3, gen_loss = 0.8719649716065481, disc_loss = 0.0692195272441585
Trained batch 91 in epoch 3, gen_loss = 0.8714927261614281, disc_loss = 0.06908764745837645
Trained batch 92 in epoch 3, gen_loss = 0.8674853099610216, disc_loss = 0.06920564438026118
Trained batch 93 in epoch 3, gen_loss = 0.8688167652234118, disc_loss = 0.06978996905518021
Trained batch 94 in epoch 3, gen_loss = 0.8659832316009621, disc_loss = 0.06970525402575731
Trained batch 95 in epoch 3, gen_loss = 0.8642537123523653, disc_loss = 0.06969540522550233
Trained batch 96 in epoch 3, gen_loss = 0.8638935139806, disc_loss = 0.06953748180194921
Trained batch 97 in epoch 3, gen_loss = 0.8613357241360509, disc_loss = 0.06942437006616775
Trained batch 98 in epoch 3, gen_loss = 0.8605539782179726, disc_loss = 0.07008930614613222
Trained batch 99 in epoch 3, gen_loss = 0.8560323472321033, disc_loss = 0.070546052781865
Trained batch 100 in epoch 3, gen_loss = 0.8558751847779397, disc_loss = 0.07032948122866968
Trained batch 101 in epoch 3, gen_loss = 0.858287934725191, disc_loss = 0.07078340287119442
Trained batch 102 in epoch 3, gen_loss = 0.8544072197768294, disc_loss = 0.0713276847455542
Trained batch 103 in epoch 3, gen_loss = 0.8566346427855583, disc_loss = 0.07097053394402163
Trained batch 104 in epoch 3, gen_loss = 0.8545671663114003, disc_loss = 0.07090751141132344
Trained batch 105 in epoch 3, gen_loss = 0.8552347822290547, disc_loss = 0.07123347957846972
Trained batch 106 in epoch 3, gen_loss = 0.8523678886834706, disc_loss = 0.07148883522218355
Trained batch 107 in epoch 3, gen_loss = 0.8528148996885176, disc_loss = 0.07163711039659877
Trained batch 108 in epoch 3, gen_loss = 0.8517639140743728, disc_loss = 0.07133873421357038
Trained batch 109 in epoch 3, gen_loss = 0.8581818544051864, disc_loss = 0.07130986397069963
Trained batch 110 in epoch 3, gen_loss = 0.8527132671427082, disc_loss = 0.07269618786904994
Trained batch 111 in epoch 3, gen_loss = 0.8553318531651583, disc_loss = 0.07290552482507857
Trained batch 112 in epoch 3, gen_loss = 0.8552992271374812, disc_loss = 0.07262338397084875
Trained batch 113 in epoch 3, gen_loss = 0.8589779767289496, disc_loss = 0.0721354459314362
Trained batch 114 in epoch 3, gen_loss = 0.8581865047631057, disc_loss = 0.07178300524373417
Trained batch 115 in epoch 3, gen_loss = 0.8628415112094633, disc_loss = 0.07137206279479995
Trained batch 116 in epoch 3, gen_loss = 0.8621441860738982, disc_loss = 0.07099464222884332
Trained batch 117 in epoch 3, gen_loss = 0.8634537550604949, disc_loss = 0.07061028514467811
Trained batch 118 in epoch 3, gen_loss = 0.8642345933603639, disc_loss = 0.0702005884367503
Trained batch 119 in epoch 3, gen_loss = 0.8634813985476891, disc_loss = 0.06985859632647286
Trained batch 120 in epoch 3, gen_loss = 0.8667763630467012, disc_loss = 0.06953331049962723
Trained batch 121 in epoch 3, gen_loss = 0.8665294746150736, disc_loss = 0.0691375547149753
Trained batch 122 in epoch 3, gen_loss = 0.8660268135429398, disc_loss = 0.0687489852506092
Trained batch 123 in epoch 3, gen_loss = 0.8673993186844934, disc_loss = 0.06849687595310952
Trained batch 124 in epoch 3, gen_loss = 0.8655265146493911, disc_loss = 0.0683357125595212
Trained batch 125 in epoch 3, gen_loss = 0.8680742776819638, disc_loss = 0.06819771479312627
Trained batch 126 in epoch 3, gen_loss = 0.8660985828619304, disc_loss = 0.06809462064979818
Trained batch 127 in epoch 3, gen_loss = 0.8659614144125953, disc_loss = 0.06778609340108233
Trained batch 128 in epoch 3, gen_loss = 0.8697206046461134, disc_loss = 0.06761087654086277
Trained batch 129 in epoch 3, gen_loss = 0.8674545059983547, disc_loss = 0.06755418483024607
Trained batch 130 in epoch 3, gen_loss = 0.869360103065731, disc_loss = 0.06720179507779028
Trained batch 131 in epoch 3, gen_loss = 0.8686744738934618, disc_loss = 0.0668910215538221
Trained batch 132 in epoch 3, gen_loss = 0.8730193489700332, disc_loss = 0.0671317675185943
Trained batch 133 in epoch 3, gen_loss = 0.869886344159717, disc_loss = 0.06739004415724037
Trained batch 134 in epoch 3, gen_loss = 0.8676343031503536, disc_loss = 0.06734326849519102
Trained batch 135 in epoch 3, gen_loss = 0.869836472960956, disc_loss = 0.06772361907368417
Trained batch 136 in epoch 3, gen_loss = 0.8688439710514388, disc_loss = 0.06752262262450735
Trained batch 137 in epoch 3, gen_loss = 0.8666797579414602, disc_loss = 0.0675170688646967
Trained batch 138 in epoch 3, gen_loss = 0.8673803605836072, disc_loss = 0.06838288702901534
Trained batch 139 in epoch 3, gen_loss = 0.8632928585367543, disc_loss = 0.06911896044787552
Trained batch 140 in epoch 3, gen_loss = 0.8622061915642826, disc_loss = 0.06897195106940278
Trained batch 141 in epoch 3, gen_loss = 0.8632565985473108, disc_loss = 0.06912950075454485
Trained batch 142 in epoch 3, gen_loss = 0.8620464961220334, disc_loss = 0.06900550235531755
Trained batch 143 in epoch 3, gen_loss = 0.8625485066117512, disc_loss = 0.06875403081196257
Trained batch 144 in epoch 3, gen_loss = 0.862628210926878, disc_loss = 0.06843364845704415
Trained batch 145 in epoch 3, gen_loss = 0.8627706787561717, disc_loss = 0.0681104428670688
Trained batch 146 in epoch 3, gen_loss = 0.8639082800166137, disc_loss = 0.06785705968813628
Trained batch 147 in epoch 3, gen_loss = 0.8639122502425233, disc_loss = 0.06753466218533749
Trained batch 148 in epoch 3, gen_loss = 0.8660882844420887, disc_loss = 0.06744022893050573
Trained batch 149 in epoch 3, gen_loss = 0.8654570568601291, disc_loss = 0.06720651284481088
Trained batch 150 in epoch 3, gen_loss = 0.8620069296352121, disc_loss = 0.06778286245114953
Trained batch 151 in epoch 3, gen_loss = 0.8668415029778292, disc_loss = 0.06881521902610793
Trained batch 152 in epoch 3, gen_loss = 0.8674630328915478, disc_loss = 0.06847969972790262
Trained batch 153 in epoch 3, gen_loss = 0.8637722029120891, disc_loss = 0.06908831793161763
Trained batch 154 in epoch 3, gen_loss = 0.8662719560246314, disc_loss = 0.06968734657932674
Trained batch 155 in epoch 3, gen_loss = 0.8627076698228334, disc_loss = 0.07033673023733382
Trained batch 156 in epoch 3, gen_loss = 0.863401934504509, disc_loss = 0.07018965045524062
Trained batch 157 in epoch 3, gen_loss = 0.864038803060598, disc_loss = 0.07032195798746205
Trained batch 158 in epoch 3, gen_loss = 0.863149124027798, disc_loss = 0.07014204572839369
Trained batch 159 in epoch 3, gen_loss = 0.8615588660351932, disc_loss = 0.07009047958417795
Trained batch 160 in epoch 3, gen_loss = 0.8618871324365924, disc_loss = 0.07002379180088361
Trained batch 161 in epoch 3, gen_loss = 0.8608814782382529, disc_loss = 0.06982701468959819
Trained batch 162 in epoch 3, gen_loss = 0.8609396883863613, disc_loss = 0.06960450941868172
Trained batch 163 in epoch 3, gen_loss = 0.8610358081031136, disc_loss = 0.06943723070435226
Trained batch 164 in epoch 3, gen_loss = 0.8610964351531231, disc_loss = 0.069146728351938
Trained batch 165 in epoch 3, gen_loss = 0.8604324462722583, disc_loss = 0.06890788736629737
Trained batch 166 in epoch 3, gen_loss = 0.8617116501052936, disc_loss = 0.06938071824989454
Trained batch 167 in epoch 3, gen_loss = 0.8589520740899301, disc_loss = 0.06973282788281462
Trained batch 168 in epoch 3, gen_loss = 0.8586824108686673, disc_loss = 0.06975025008570336
Trained batch 169 in epoch 3, gen_loss = 0.8590251522029148, disc_loss = 0.0697323263513253
Trained batch 170 in epoch 3, gen_loss = 0.8589963019765608, disc_loss = 0.06964523553826481
Trained batch 171 in epoch 3, gen_loss = 0.8585704099820104, disc_loss = 0.06960252160747904
Trained batch 172 in epoch 3, gen_loss = 0.8600148574982075, disc_loss = 0.06939275318896668
Trained batch 173 in epoch 3, gen_loss = 0.8620800169548769, disc_loss = 0.0691062923702786
Trained batch 174 in epoch 3, gen_loss = 0.8593732051338469, disc_loss = 0.06940301265567542
Trained batch 175 in epoch 3, gen_loss = 0.8605503156273202, disc_loss = 0.06937986464684152
Trained batch 176 in epoch 3, gen_loss = 0.8595882614622008, disc_loss = 0.06925348049861058
Trained batch 177 in epoch 3, gen_loss = 0.8597699451480019, disc_loss = 0.06909036477818416
Trained batch 178 in epoch 3, gen_loss = 0.858886276959707, disc_loss = 0.06897573086157358
Trained batch 179 in epoch 3, gen_loss = 0.8582167046765486, disc_loss = 0.06875087562431063
Trained batch 180 in epoch 3, gen_loss = 0.8607647660193523, disc_loss = 0.0689528939463404
Trained batch 181 in epoch 3, gen_loss = 0.8588218273861068, disc_loss = 0.06905497096294722
Trained batch 182 in epoch 3, gen_loss = 0.8574527975151448, disc_loss = 0.06908446478611621
Trained batch 183 in epoch 3, gen_loss = 0.8579428702106943, disc_loss = 0.06908279079842665
Trained batch 184 in epoch 3, gen_loss = 0.8576418539156785, disc_loss = 0.06888200396520866
Trained batch 185 in epoch 3, gen_loss = 0.8585312428173199, disc_loss = 0.06856457216625092
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9717622399330139, disc_loss = 0.013189099729061127
Trained batch 1 in epoch 4, gen_loss = 0.9614960849285126, disc_loss = 0.020769640803337097
Trained batch 2 in epoch 4, gen_loss = 0.8131663799285889, disc_loss = 0.04012539486090342
Trained batch 3 in epoch 4, gen_loss = 0.9195244312286377, disc_loss = 0.039262483827769756
Trained batch 4 in epoch 4, gen_loss = 0.9074941039085388, disc_loss = 0.03682857155799866
Trained batch 5 in epoch 4, gen_loss = 0.9701694150765737, disc_loss = 0.03677129621307055
Trained batch 6 in epoch 4, gen_loss = 0.9058801276343209, disc_loss = 0.04208631068468094
Trained batch 7 in epoch 4, gen_loss = 0.9236556142568588, disc_loss = 0.04408964095637202
Trained batch 8 in epoch 4, gen_loss = 0.9095097184181213, disc_loss = 0.04265695189436277
Trained batch 9 in epoch 4, gen_loss = 0.8823220431804657, disc_loss = 0.042993100360035896
Trained batch 10 in epoch 4, gen_loss = 0.9560689004984769, disc_loss = 0.058669047260826286
Trained batch 11 in epoch 4, gen_loss = 0.905304878950119, disc_loss = 0.06737296562641859
Trained batch 12 in epoch 4, gen_loss = 0.8765668181272653, disc_loss = 0.06974629226785439
Trained batch 13 in epoch 4, gen_loss = 0.9006974058491843, disc_loss = 0.08257922290691308
Trained batch 14 in epoch 4, gen_loss = 0.8532730837663015, disc_loss = 0.09505471164981524
Trained batch 15 in epoch 4, gen_loss = 0.8479147087782621, disc_loss = 0.09217522735707462
Trained batch 16 in epoch 4, gen_loss = 0.8483573391157038, disc_loss = 0.09797843830550418
Trained batch 17 in epoch 4, gen_loss = 0.8354415876997842, disc_loss = 0.09734959134625064
Trained batch 18 in epoch 4, gen_loss = 0.8121971723280454, disc_loss = 0.10318818276650027
Trained batch 19 in epoch 4, gen_loss = 0.8301518514752388, disc_loss = 0.10806945618242025
Trained batch 20 in epoch 4, gen_loss = 0.8165028989315033, disc_loss = 0.10777480847069196
Trained batch 21 in epoch 4, gen_loss = 0.8239466507326473, disc_loss = 0.10460383800620382
Trained batch 22 in epoch 4, gen_loss = 0.8187969365845555, disc_loss = 0.10342335360853569
Trained batch 23 in epoch 4, gen_loss = 0.8152626765271028, disc_loss = 0.10160998813807964
Trained batch 24 in epoch 4, gen_loss = 0.8045826852321625, disc_loss = 0.10006124794483184
Trained batch 25 in epoch 4, gen_loss = 0.8228136518826852, disc_loss = 0.09813629979124436
Trained batch 26 in epoch 4, gen_loss = 0.830098936955134, disc_loss = 0.09513561993285462
Trained batch 27 in epoch 4, gen_loss = 0.8252456092408725, disc_loss = 0.09330953058919736
Trained batch 28 in epoch 4, gen_loss = 0.8325764382707661, disc_loss = 0.09073351400679555
Trained batch 29 in epoch 4, gen_loss = 0.8403898586829504, disc_loss = 0.08817823293308417
Trained batch 30 in epoch 4, gen_loss = 0.8455874141185514, disc_loss = 0.08574693037136909
Trained batch 31 in epoch 4, gen_loss = 0.8410793216899037, disc_loss = 0.08441749296616763
Trained batch 32 in epoch 4, gen_loss = 0.8441780453378503, disc_loss = 0.08237613952069571
Trained batch 33 in epoch 4, gen_loss = 0.8520069060956731, disc_loss = 0.0814344444695641
Trained batch 34 in epoch 4, gen_loss = 0.8477306766169411, disc_loss = 0.08006352920617377
Trained batch 35 in epoch 4, gen_loss = 0.8464665503965484, disc_loss = 0.07855766333846582
Trained batch 36 in epoch 4, gen_loss = 0.8522964836777868, disc_loss = 0.07760650881037519
Trained batch 37 in epoch 4, gen_loss = 0.8530963714185514, disc_loss = 0.07595930334278628
Trained batch 38 in epoch 4, gen_loss = 0.857853115369112, disc_loss = 0.07425904410103193
Trained batch 39 in epoch 4, gen_loss = 0.8592115916311741, disc_loss = 0.07276834743097424
Trained batch 40 in epoch 4, gen_loss = 0.8703440289671828, disc_loss = 0.0720406934255507
Trained batch 41 in epoch 4, gen_loss = 0.8598442787215823, disc_loss = 0.07280512296018146
Trained batch 42 in epoch 4, gen_loss = 0.8704288837521575, disc_loss = 0.07197327903190325
Trained batch 43 in epoch 4, gen_loss = 0.8787922750819813, disc_loss = 0.07071699269793251
Trained batch 44 in epoch 4, gen_loss = 0.8948025253083971, disc_loss = 0.07013454205460018
Trained batch 45 in epoch 4, gen_loss = 0.9086627312328505, disc_loss = 0.06924843545193257
Trained batch 46 in epoch 4, gen_loss = 0.9136215955653089, disc_loss = 0.06831673504982858
Trained batch 47 in epoch 4, gen_loss = 0.913740873336792, disc_loss = 0.06736091652419418
Trained batch 48 in epoch 4, gen_loss = 0.915402004913408, disc_loss = 0.06629556921139663
Trained batch 49 in epoch 4, gen_loss = 0.9210394346714019, disc_loss = 0.06530097229406237
Trained batch 50 in epoch 4, gen_loss = 0.918378868523766, disc_loss = 0.06508504429503399
Trained batch 51 in epoch 4, gen_loss = 0.9250350445508957, disc_loss = 0.06420423027772743
Trained batch 52 in epoch 4, gen_loss = 0.9245243612325417, disc_loss = 0.06342817152375882
Trained batch 53 in epoch 4, gen_loss = 0.9263305818593061, disc_loss = 0.06264141483094406
Trained batch 54 in epoch 4, gen_loss = 0.928656775301153, disc_loss = 0.06224991928108714
Trained batch 55 in epoch 4, gen_loss = 0.9301416405609676, disc_loss = 0.06159303728158453
Trained batch 56 in epoch 4, gen_loss = 0.9253108752401251, disc_loss = 0.06139478013899766
Trained batch 57 in epoch 4, gen_loss = 0.9370676628474531, disc_loss = 0.061724613500951694
Trained batch 58 in epoch 4, gen_loss = 0.9295642562841965, disc_loss = 0.062100990770100534
Trained batch 59 in epoch 4, gen_loss = 0.9293459917108218, disc_loss = 0.061334241538619
Trained batch 60 in epoch 4, gen_loss = 0.934486878211381, disc_loss = 0.060987651393916764
Trained batch 61 in epoch 4, gen_loss = 0.9370485183692747, disc_loss = 0.06013905452263932
Trained batch 62 in epoch 4, gen_loss = 0.9385292137426043, disc_loss = 0.05932258646048251
Trained batch 63 in epoch 4, gen_loss = 0.9368718746118248, disc_loss = 0.05867837794357911
Trained batch 64 in epoch 4, gen_loss = 0.9407942950725555, disc_loss = 0.05792403845832898
Trained batch 65 in epoch 4, gen_loss = 0.9422649176734866, disc_loss = 0.05725667526889028
Trained batch 66 in epoch 4, gen_loss = 0.9413996716933464, disc_loss = 0.056629238274893655
Trained batch 67 in epoch 4, gen_loss = 0.9382570372784839, disc_loss = 0.056234213811181044
Trained batch 68 in epoch 4, gen_loss = 0.9399683635303939, disc_loss = 0.05573657070003126
Trained batch 69 in epoch 4, gen_loss = 0.9452491832630975, disc_loss = 0.05511501118806856
Trained batch 70 in epoch 4, gen_loss = 0.9434676124176509, disc_loss = 0.054624562256667814
Trained batch 71 in epoch 4, gen_loss = 0.9441196558376154, disc_loss = 0.053974459995515645
Trained batch 72 in epoch 4, gen_loss = 0.95054346608789, disc_loss = 0.05375188646506365
Trained batch 73 in epoch 4, gen_loss = 0.9468200049690298, disc_loss = 0.053503008471248115
Trained batch 74 in epoch 4, gen_loss = 0.9460085197289785, disc_loss = 0.052959495869775615
Trained batch 75 in epoch 4, gen_loss = 0.9475030173596583, disc_loss = 0.05265171047741253
Trained batch 76 in epoch 4, gen_loss = 0.9452648437642431, disc_loss = 0.05228590376239706
Trained batch 77 in epoch 4, gen_loss = 0.9467491946923428, disc_loss = 0.05186735567612908
Trained batch 78 in epoch 4, gen_loss = 0.9473285731635516, disc_loss = 0.051313556200247024
Trained batch 79 in epoch 4, gen_loss = 0.9442694839090109, disc_loss = 0.0510653082630597
Trained batch 80 in epoch 4, gen_loss = 0.9456340733133717, disc_loss = 0.05071555118271966
Trained batch 81 in epoch 4, gen_loss = 0.9463121131425951, disc_loss = 0.05023061167221607
Trained batch 82 in epoch 4, gen_loss = 0.9473495925047312, disc_loss = 0.04973730773676232
Trained batch 83 in epoch 4, gen_loss = 0.9469659786139216, disc_loss = 0.04927433161286726
Trained batch 84 in epoch 4, gen_loss = 0.945444871748195, disc_loss = 0.04897962960907642
Trained batch 85 in epoch 4, gen_loss = 0.9457679082487904, disc_loss = 0.04868271633939341
Trained batch 86 in epoch 4, gen_loss = 0.9458951891838819, disc_loss = 0.04827187748775742
Trained batch 87 in epoch 4, gen_loss = 0.9507935531437397, disc_loss = 0.047971012483520266
Trained batch 88 in epoch 4, gen_loss = 0.9495743275358436, disc_loss = 0.04771658419265171
Trained batch 89 in epoch 4, gen_loss = 0.9504626383384068, disc_loss = 0.047578189946297145
Trained batch 90 in epoch 4, gen_loss = 0.9546132745978596, disc_loss = 0.047345569879225974
Trained batch 91 in epoch 4, gen_loss = 0.9545424311705257, disc_loss = 0.04708014925658379
Trained batch 92 in epoch 4, gen_loss = 0.9558546341234638, disc_loss = 0.04682640570105724
Trained batch 93 in epoch 4, gen_loss = 0.9541805928691904, disc_loss = 0.04677927504947528
Trained batch 94 in epoch 4, gen_loss = 0.9524396705000024, disc_loss = 0.04654676242682495
Trained batch 95 in epoch 4, gen_loss = 0.9601152846589684, disc_loss = 0.04649979593038248
Trained batch 96 in epoch 4, gen_loss = 0.9622304190679923, disc_loss = 0.04612130703423748
Trained batch 97 in epoch 4, gen_loss = 0.9637508924518313, disc_loss = 0.045726726568132946
Trained batch 98 in epoch 4, gen_loss = 0.9607359565267659, disc_loss = 0.04571394589870716
Trained batch 99 in epoch 4, gen_loss = 0.9648417410254478, disc_loss = 0.04576283184345811
Trained batch 100 in epoch 4, gen_loss = 0.9688706831766827, disc_loss = 0.04548387948220762
Trained batch 101 in epoch 4, gen_loss = 0.9706569708445493, disc_loss = 0.04517705122684585
Trained batch 102 in epoch 4, gen_loss = 0.9693312208050663, disc_loss = 0.045221879043010546
Trained batch 103 in epoch 4, gen_loss = 0.97056125706205, disc_loss = 0.0450595081022654
Trained batch 104 in epoch 4, gen_loss = 0.9728127221266428, disc_loss = 0.0451214946052503
Trained batch 105 in epoch 4, gen_loss = 0.9721145896979098, disc_loss = 0.04497463262710228
Trained batch 106 in epoch 4, gen_loss = 0.9721225898399531, disc_loss = 0.04469624055096897
Trained batch 107 in epoch 4, gen_loss = 0.9748995820129359, disc_loss = 0.044390611984353096
Trained batch 108 in epoch 4, gen_loss = 0.9744778163389328, disc_loss = 0.04410151200403178
Trained batch 109 in epoch 4, gen_loss = 0.9750965337861668, disc_loss = 0.043803216783668504
Trained batch 110 in epoch 4, gen_loss = 0.9753265877564748, disc_loss = 0.04349585724491123
Trained batch 111 in epoch 4, gen_loss = 0.9738260840198824, disc_loss = 0.04327158594553891
Trained batch 112 in epoch 4, gen_loss = 0.9752332765971665, disc_loss = 0.043074750675267615
Trained batch 113 in epoch 4, gen_loss = 0.9799054832312099, disc_loss = 0.04293807386420667
Trained batch 114 in epoch 4, gen_loss = 0.9874165651590928, disc_loss = 0.0433199452276787
Trained batch 115 in epoch 4, gen_loss = 0.991644829768559, disc_loss = 0.04327268345715028
Trained batch 116 in epoch 4, gen_loss = 0.9907065780244322, disc_loss = 0.04306128902488157
Trained batch 117 in epoch 4, gen_loss = 0.9899177427514124, disc_loss = 0.04281217078836161
Trained batch 118 in epoch 4, gen_loss = 0.9905938889299121, disc_loss = 0.042521430089474975
Trained batch 119 in epoch 4, gen_loss = 0.9914251255492369, disc_loss = 0.04227666499791667
Trained batch 120 in epoch 4, gen_loss = 0.9920612984944966, disc_loss = 0.041981052849749644
Trained batch 121 in epoch 4, gen_loss = 0.9924184872967298, disc_loss = 0.041691487643592914
Trained batch 122 in epoch 4, gen_loss = 0.9932426580084048, disc_loss = 0.041408824654886635
Trained batch 123 in epoch 4, gen_loss = 0.992876157404915, disc_loss = 0.04117842043013943
Trained batch 124 in epoch 4, gen_loss = 0.9934951341152192, disc_loss = 0.040898137256503105
Trained batch 125 in epoch 4, gen_loss = 0.9970943556418495, disc_loss = 0.04074427550510755
Trained batch 126 in epoch 4, gen_loss = 0.9984547732852576, disc_loss = 0.04048216827653759
Trained batch 127 in epoch 4, gen_loss = 0.9977514988277107, disc_loss = 0.04024869533168385
Trained batch 128 in epoch 4, gen_loss = 0.9977441658807356, disc_loss = 0.04001316035440726
Trained batch 129 in epoch 4, gen_loss = 0.99742802633689, disc_loss = 0.03978051676486547
Trained batch 130 in epoch 4, gen_loss = 0.9982208657355709, disc_loss = 0.039532408196450645
Trained batch 131 in epoch 4, gen_loss = 0.9997080354527994, disc_loss = 0.03928963777214063
Trained batch 132 in epoch 4, gen_loss = 1.0000976958221062, disc_loss = 0.039039103174232
Trained batch 133 in epoch 4, gen_loss = 0.9999158228956052, disc_loss = 0.03880769758026546
Trained batch 134 in epoch 4, gen_loss = 1.0004845449218043, disc_loss = 0.03860570674555169
Trained batch 135 in epoch 4, gen_loss = 1.000868405270226, disc_loss = 0.038376863614436894
Trained batch 136 in epoch 4, gen_loss = 1.0006994067752448, disc_loss = 0.03818398655602967
Trained batch 137 in epoch 4, gen_loss = 1.0014412012221157, disc_loss = 0.037973947161673634
Trained batch 138 in epoch 4, gen_loss = 1.0031004061373017, disc_loss = 0.037774051452497785
Trained batch 139 in epoch 4, gen_loss = 1.0020228549838066, disc_loss = 0.03763899294925588
Trained batch 140 in epoch 4, gen_loss = 1.004203050060475, disc_loss = 0.03746304330118793
Trained batch 141 in epoch 4, gen_loss = 1.0054536086152976, disc_loss = 0.03724843302977757
Trained batch 142 in epoch 4, gen_loss = 1.0056467591882585, disc_loss = 0.03702695027540822
Trained batch 143 in epoch 4, gen_loss = 1.0055103436526325, disc_loss = 0.036824895094873175
Trained batch 144 in epoch 4, gen_loss = 1.0060610855447836, disc_loss = 0.0367149534025069
Trained batch 145 in epoch 4, gen_loss = 1.005039508824479, disc_loss = 0.03657647886964148
Trained batch 146 in epoch 4, gen_loss = 1.005665769179662, disc_loss = 0.0363938996986467
Trained batch 147 in epoch 4, gen_loss = 1.0059472819840587, disc_loss = 0.036195649227404314
Trained batch 148 in epoch 4, gen_loss = 1.0063064200366103, disc_loss = 0.03598926766719294
Trained batch 149 in epoch 4, gen_loss = 1.0068454851706823, disc_loss = 0.03581380206160247
Trained batch 150 in epoch 4, gen_loss = 1.0068027860676216, disc_loss = 0.0356199934073286
Trained batch 151 in epoch 4, gen_loss = 1.0071835751204115, disc_loss = 0.03555645104068773
Trained batch 152 in epoch 4, gen_loss = 1.0050339392976824, disc_loss = 0.03560678477344267
Trained batch 153 in epoch 4, gen_loss = 1.0075852025251884, disc_loss = 0.03567323767483331
Trained batch 154 in epoch 4, gen_loss = 1.0082300084252511, disc_loss = 0.035521763956715025
Trained batch 155 in epoch 4, gen_loss = 1.0079278309757893, disc_loss = 0.035364438513986386
Trained batch 156 in epoch 4, gen_loss = 1.0075131436442113, disc_loss = 0.035223907847432005
Trained batch 157 in epoch 4, gen_loss = 1.0085226955670346, disc_loss = 0.03506912428095842
Trained batch 158 in epoch 4, gen_loss = 1.009062483813028, disc_loss = 0.03498696925048277
Trained batch 159 in epoch 4, gen_loss = 1.007413518615067, disc_loss = 0.034962997215916405
Trained batch 160 in epoch 4, gen_loss = 1.007379311397209, disc_loss = 0.03483411444420492
Trained batch 161 in epoch 4, gen_loss = 1.0081153271006948, disc_loss = 0.034662502343524935
Trained batch 162 in epoch 4, gen_loss = 1.0100537072295792, disc_loss = 0.03453573339727301
Trained batch 163 in epoch 4, gen_loss = 1.0113738762532793, disc_loss = 0.034402587113152375
Trained batch 164 in epoch 4, gen_loss = 1.013272422913349, disc_loss = 0.034305698664463834
Trained batch 165 in epoch 4, gen_loss = 1.012335295598191, disc_loss = 0.034183899173513055
Trained batch 166 in epoch 4, gen_loss = 1.011690237386498, disc_loss = 0.034038040243245346
Trained batch 167 in epoch 4, gen_loss = 1.0111396477690764, disc_loss = 0.0339161419681096
Trained batch 168 in epoch 4, gen_loss = 1.0126041683572284, disc_loss = 0.03379241287013924
Trained batch 169 in epoch 4, gen_loss = 1.0104444866671283, disc_loss = 0.03384738775134525
Trained batch 170 in epoch 4, gen_loss = 1.0129682123661041, disc_loss = 0.03412325083610346
Trained batch 171 in epoch 4, gen_loss = 1.0097502333133719, disc_loss = 0.03441896891968628
Trained batch 172 in epoch 4, gen_loss = 1.00879605536516, disc_loss = 0.034351552080233834
Trained batch 173 in epoch 4, gen_loss = 1.009760421069189, disc_loss = 0.03468028401645521
Trained batch 174 in epoch 4, gen_loss = 1.00847326704434, disc_loss = 0.034658850923712764
Trained batch 175 in epoch 4, gen_loss = 1.0078436832197688, disc_loss = 0.034558638636636635
Trained batch 176 in epoch 4, gen_loss = 1.0069037061289878, disc_loss = 0.03446949162062699
Trained batch 177 in epoch 4, gen_loss = 1.006877789169215, disc_loss = 0.03461396437023212
Trained batch 178 in epoch 4, gen_loss = 1.0038138008650455, disc_loss = 0.035066037061598214
Trained batch 179 in epoch 4, gen_loss = 1.0045560399691265, disc_loss = 0.03524632166501963
Trained batch 180 in epoch 4, gen_loss = 1.0038392843462485, disc_loss = 0.03549124846152591
Trained batch 181 in epoch 4, gen_loss = 1.0036523004809579, disc_loss = 0.03548574183842392
Trained batch 182 in epoch 4, gen_loss = 1.0033972869153882, disc_loss = 0.035401214435798384
Trained batch 183 in epoch 4, gen_loss = 1.0020184941265895, disc_loss = 0.035484663668878216
Trained batch 184 in epoch 4, gen_loss = 1.0018930486730626, disc_loss = 0.035396862827946206
Trained batch 185 in epoch 4, gen_loss = 1.0005838691547353, disc_loss = 0.03534674991212625
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.8010743260383606, disc_loss = 0.034300848841667175
Trained batch 1 in epoch 5, gen_loss = 0.9675449430942535, disc_loss = 0.04776481166481972
Trained batch 2 in epoch 5, gen_loss = 0.7415643831094106, disc_loss = 0.08927443375190099
Trained batch 3 in epoch 5, gen_loss = 0.9734209403395653, disc_loss = 0.08237834367901087
Trained batch 4 in epoch 5, gen_loss = 0.9142592370510101, disc_loss = 0.07379822805523872
Trained batch 5 in epoch 5, gen_loss = 0.9089625130097071, disc_loss = 0.06746458448469639
Trained batch 6 in epoch 5, gen_loss = 0.9523613154888153, disc_loss = 0.07054979407361575
Trained batch 7 in epoch 5, gen_loss = 0.8715094290673733, disc_loss = 0.08150392910465598
Trained batch 8 in epoch 5, gen_loss = 0.8859520720110999, disc_loss = 0.08110396853751606
Trained batch 9 in epoch 5, gen_loss = 0.8658095449209213, disc_loss = 0.0844761785119772
Trained batch 10 in epoch 5, gen_loss = 0.8334085263989188, disc_loss = 0.08531510931524364
Trained batch 11 in epoch 5, gen_loss = 0.8685861304402351, disc_loss = 0.08341972064226866
Trained batch 12 in epoch 5, gen_loss = 0.8542513182530036, disc_loss = 0.08019268283477196
Trained batch 13 in epoch 5, gen_loss = 0.8490830255406243, disc_loss = 0.07807134091854095
Trained batch 14 in epoch 5, gen_loss = 0.8367649654547373, disc_loss = 0.07641668394207954
Trained batch 15 in epoch 5, gen_loss = 0.8585033807903528, disc_loss = 0.07354818633757532
Trained batch 16 in epoch 5, gen_loss = 0.8596712158006781, disc_loss = 0.07009412896107226
Trained batch 17 in epoch 5, gen_loss = 0.8510576734940211, disc_loss = 0.06825859451459514
Trained batch 18 in epoch 5, gen_loss = 0.8707434613453714, disc_loss = 0.07158838467378366
Trained batch 19 in epoch 5, gen_loss = 0.8444806441664696, disc_loss = 0.07673032004386186
Trained batch 20 in epoch 5, gen_loss = 0.8306362416063037, disc_loss = 0.07723990668143545
Trained batch 21 in epoch 5, gen_loss = 0.8495052741332487, disc_loss = 0.09156296893276951
Trained batch 22 in epoch 5, gen_loss = 0.8305439858332925, disc_loss = 0.09285426706723544
Trained batch 23 in epoch 5, gen_loss = 0.8159419683118662, disc_loss = 0.09376919067775209
Trained batch 24 in epoch 5, gen_loss = 0.8021754944324493, disc_loss = 0.09616547033190727
Trained batch 25 in epoch 5, gen_loss = 0.7911452272763619, disc_loss = 0.09827151822929199
Trained batch 26 in epoch 5, gen_loss = 0.7905405748773504, disc_loss = 0.10068850481399784
Trained batch 27 in epoch 5, gen_loss = 0.7960774717586381, disc_loss = 0.10037234571895429
Trained batch 28 in epoch 5, gen_loss = 0.782073221329985, disc_loss = 0.10204496864100983
Trained batch 29 in epoch 5, gen_loss = 0.7814289023478825, disc_loss = 0.10099054562548797
Trained batch 30 in epoch 5, gen_loss = 0.7861046916054141, disc_loss = 0.10252348826296868
Trained batch 31 in epoch 5, gen_loss = 0.7757960157468915, disc_loss = 0.10216395405586809
Trained batch 32 in epoch 5, gen_loss = 0.7695873912536737, disc_loss = 0.10102348040902254
Trained batch 33 in epoch 5, gen_loss = 0.7818267038639855, disc_loss = 0.10131667433854412
Trained batch 34 in epoch 5, gen_loss = 0.7743533228124891, disc_loss = 0.10044768399425916
Trained batch 35 in epoch 5, gen_loss = 0.7730294176273875, disc_loss = 0.09880688983119196
Trained batch 36 in epoch 5, gen_loss = 0.7697765738577456, disc_loss = 0.09967032668961061
Trained batch 37 in epoch 5, gen_loss = 0.7670181636747561, disc_loss = 0.10048462440700907
Trained batch 38 in epoch 5, gen_loss = 0.7664199097034259, disc_loss = 0.0988195732426949
Trained batch 39 in epoch 5, gen_loss = 0.7660666726529598, disc_loss = 0.09710502112284303
Trained batch 40 in epoch 5, gen_loss = 0.7695731833213713, disc_loss = 0.09533477474640055
Trained batch 41 in epoch 5, gen_loss = 0.7821075667937597, disc_loss = 0.09459379679035573
Trained batch 42 in epoch 5, gen_loss = 0.7730945549732031, disc_loss = 0.09570268775488056
Trained batch 43 in epoch 5, gen_loss = 0.7827790277925405, disc_loss = 0.09483617442575368
Trained batch 44 in epoch 5, gen_loss = 0.7918888946374257, disc_loss = 0.0932917281985283
Trained batch 45 in epoch 5, gen_loss = 0.7910766478465951, disc_loss = 0.09214692174092583
Trained batch 46 in epoch 5, gen_loss = 0.7917642295360565, disc_loss = 0.09072691408243586
Trained batch 47 in epoch 5, gen_loss = 0.7968454242994388, disc_loss = 0.08922554645687342
Trained batch 48 in epoch 5, gen_loss = 0.8044495734633231, disc_loss = 0.08791362399197354
Trained batch 49 in epoch 5, gen_loss = 0.8062855631113053, disc_loss = 0.08646057359874249
Trained batch 50 in epoch 5, gen_loss = 0.805333124071944, disc_loss = 0.08526501351711797
Trained batch 51 in epoch 5, gen_loss = 0.8107868507504463, disc_loss = 0.08687189536599013
Trained batch 52 in epoch 5, gen_loss = 0.8009574115276337, disc_loss = 0.08874887959012445
Trained batch 53 in epoch 5, gen_loss = 0.7965272659504855, disc_loss = 0.09050749131926784
Trained batch 54 in epoch 5, gen_loss = 0.7942335264249282, disc_loss = 0.09134845950386741
Trained batch 55 in epoch 5, gen_loss = 0.7867971515016896, disc_loss = 0.09196655319205352
Trained batch 56 in epoch 5, gen_loss = 0.7913380134523961, disc_loss = 0.09252280519719709
Trained batch 57 in epoch 5, gen_loss = 0.7843200394819523, disc_loss = 0.09473651313576205
Trained batch 58 in epoch 5, gen_loss = 0.7848337166390177, disc_loss = 0.09639882056389824
Trained batch 59 in epoch 5, gen_loss = 0.7953109289209048, disc_loss = 0.10016500179966291
Trained batch 60 in epoch 5, gen_loss = 0.7903533040500078, disc_loss = 0.10280484962658804
Trained batch 61 in epoch 5, gen_loss = 0.7881348498405949, disc_loss = 0.10314585028156158
Trained batch 62 in epoch 5, gen_loss = 0.7844176093737284, disc_loss = 0.10400376977428558
Trained batch 63 in epoch 5, gen_loss = 0.7889185668900609, disc_loss = 0.1038473176304251
Trained batch 64 in epoch 5, gen_loss = 0.7889684970562275, disc_loss = 0.1027758990915922
Trained batch 65 in epoch 5, gen_loss = 0.790780841401129, disc_loss = 0.10165063923958575
Trained batch 66 in epoch 5, gen_loss = 0.7889131512214889, disc_loss = 0.10070733147770611
Trained batch 67 in epoch 5, gen_loss = 0.7904771312194712, disc_loss = 0.09961817358784816
Trained batch 68 in epoch 5, gen_loss = 0.7932583603306093, disc_loss = 0.09889730821917023
Trained batch 69 in epoch 5, gen_loss = 0.7909947889191764, disc_loss = 0.09810890768255506
Trained batch 70 in epoch 5, gen_loss = 0.7933125151714808, disc_loss = 0.09717481331506246
Trained batch 71 in epoch 5, gen_loss = 0.79551183929046, disc_loss = 0.0959814813427834
Trained batch 72 in epoch 5, gen_loss = 0.7947289429298819, disc_loss = 0.09509038204352742
Trained batch 73 in epoch 5, gen_loss = 0.8004164800450608, disc_loss = 0.09397186503770787
Trained batch 74 in epoch 5, gen_loss = 0.8024889413515727, disc_loss = 0.09286168071130911
Trained batch 75 in epoch 5, gen_loss = 0.8001811794544521, disc_loss = 0.09239454241469502
Trained batch 76 in epoch 5, gen_loss = 0.8011124219213214, disc_loss = 0.09145278028853528
Trained batch 77 in epoch 5, gen_loss = 0.807173456136997, disc_loss = 0.09057621700832477
Trained batch 78 in epoch 5, gen_loss = 0.8109967052182064, disc_loss = 0.08960099379190162
Trained batch 79 in epoch 5, gen_loss = 0.8088598765432835, disc_loss = 0.08904454435687512
Trained batch 80 in epoch 5, gen_loss = 0.8070969772927555, disc_loss = 0.08846772404640545
Trained batch 81 in epoch 5, gen_loss = 0.816316529018123, disc_loss = 0.0884556478434583
Trained batch 82 in epoch 5, gen_loss = 0.8153030570731106, disc_loss = 0.08800954661186201
Trained batch 83 in epoch 5, gen_loss = 0.8091590227115721, disc_loss = 0.08903570253668087
Trained batch 84 in epoch 5, gen_loss = 0.8157847972477184, disc_loss = 0.08941280852784128
Trained batch 85 in epoch 5, gen_loss = 0.8133882991103238, disc_loss = 0.08891857058069734
Trained batch 86 in epoch 5, gen_loss = 0.8119302022046057, disc_loss = 0.08974599793296435
Trained batch 87 in epoch 5, gen_loss = 0.8081296980381012, disc_loss = 0.08965933286923576
Trained batch 88 in epoch 5, gen_loss = 0.8066955831613434, disc_loss = 0.08980748214329896
Trained batch 89 in epoch 5, gen_loss = 0.8082188718848758, disc_loss = 0.08920894991606473
Trained batch 90 in epoch 5, gen_loss = 0.806068540929438, disc_loss = 0.08875661357664145
Trained batch 91 in epoch 5, gen_loss = 0.8061326554288035, disc_loss = 0.08807870618108174
Trained batch 92 in epoch 5, gen_loss = 0.8054623699957325, disc_loss = 0.08816200552848719
Trained batch 93 in epoch 5, gen_loss = 0.8063394871163876, disc_loss = 0.08739949235732251
Trained batch 94 in epoch 5, gen_loss = 0.8061836255224127, disc_loss = 0.08670988192683772
Trained batch 95 in epoch 5, gen_loss = 0.807346218576034, disc_loss = 0.08607072980764012
Trained batch 96 in epoch 5, gen_loss = 0.806412130901494, disc_loss = 0.08575888669367918
Trained batch 97 in epoch 5, gen_loss = 0.8094503228761711, disc_loss = 0.08498737608481731
Trained batch 98 in epoch 5, gen_loss = 0.8098949759897559, disc_loss = 0.0846631835224201
Trained batch 99 in epoch 5, gen_loss = 0.8048851892352105, disc_loss = 0.08527176734991372
Trained batch 100 in epoch 5, gen_loss = 0.8110090644642858, disc_loss = 0.08627327816505538
Trained batch 101 in epoch 5, gen_loss = 0.8063639872798732, disc_loss = 0.08715172021594994
Trained batch 102 in epoch 5, gen_loss = 0.8033167378416339, disc_loss = 0.08713232325299562
Trained batch 103 in epoch 5, gen_loss = 0.8068021891208795, disc_loss = 0.08736867813142733
Trained batch 104 in epoch 5, gen_loss = 0.806380775996617, disc_loss = 0.08683488550817682
Trained batch 105 in epoch 5, gen_loss = 0.804417979604793, disc_loss = 0.08658529376119094
Trained batch 106 in epoch 5, gen_loss = 0.8028218612492641, disc_loss = 0.08694065140264336
Trained batch 107 in epoch 5, gen_loss = 0.807656282628024, disc_loss = 0.08691180325803105
Trained batch 108 in epoch 5, gen_loss = 0.8057334341040445, disc_loss = 0.08657816258353104
Trained batch 109 in epoch 5, gen_loss = 0.8058280478824269, disc_loss = 0.08598308333788406
Trained batch 110 in epoch 5, gen_loss = 0.8081249256391783, disc_loss = 0.08540126819767661
Trained batch 111 in epoch 5, gen_loss = 0.8076268317443984, disc_loss = 0.0848760636872612
Trained batch 112 in epoch 5, gen_loss = 0.8083690695003071, disc_loss = 0.08448760001302029
Trained batch 113 in epoch 5, gen_loss = 0.8113199247602831, disc_loss = 0.08384790563171632
Trained batch 114 in epoch 5, gen_loss = 0.8116702173067176, disc_loss = 0.08326564960019744
Trained batch 115 in epoch 5, gen_loss = 0.8105522805246813, disc_loss = 0.08291914844724896
Trained batch 116 in epoch 5, gen_loss = 0.8126644639887362, disc_loss = 0.08268387963533656
Trained batch 117 in epoch 5, gen_loss = 0.8106573016966804, disc_loss = 0.08246681094958873
Trained batch 118 in epoch 5, gen_loss = 0.8145724800454468, disc_loss = 0.08204999886171407
Trained batch 119 in epoch 5, gen_loss = 0.8147728741168976, disc_loss = 0.08151551592939844
Trained batch 120 in epoch 5, gen_loss = 0.8135983677935009, disc_loss = 0.08114449571325513
Trained batch 121 in epoch 5, gen_loss = 0.8197735000829227, disc_loss = 0.08126035457110552
Trained batch 122 in epoch 5, gen_loss = 0.8164751486080449, disc_loss = 0.08139052092877587
Trained batch 123 in epoch 5, gen_loss = 0.816180246491586, disc_loss = 0.08100248602098756
Trained batch 124 in epoch 5, gen_loss = 0.8199920091629028, disc_loss = 0.08082722394913434
Trained batch 125 in epoch 5, gen_loss = 0.820219549867842, disc_loss = 0.0803252675215758
Trained batch 126 in epoch 5, gen_loss = 0.8183558902402562, disc_loss = 0.08010611386133695
Trained batch 127 in epoch 5, gen_loss = 0.8212910913862288, disc_loss = 0.07974952508084243
Trained batch 128 in epoch 5, gen_loss = 0.8206544837286306, disc_loss = 0.07946207376500201
Trained batch 129 in epoch 5, gen_loss = 0.8210489080502437, disc_loss = 0.07897338322005593
Trained batch 130 in epoch 5, gen_loss = 0.82287557889487, disc_loss = 0.07849149914273551
Trained batch 131 in epoch 5, gen_loss = 0.8217573888374098, disc_loss = 0.07817037829028611
Trained batch 132 in epoch 5, gen_loss = 0.8246703282334751, disc_loss = 0.07807537870607655
Trained batch 133 in epoch 5, gen_loss = 0.8237041203833338, disc_loss = 0.07782000299793349
Trained batch 134 in epoch 5, gen_loss = 0.8226115964077138, disc_loss = 0.07762655350207179
Trained batch 135 in epoch 5, gen_loss = 0.827063620528754, disc_loss = 0.07823066818117
Trained batch 136 in epoch 5, gen_loss = 0.8242561508269206, disc_loss = 0.07853979350196837
Trained batch 137 in epoch 5, gen_loss = 0.825063758570215, disc_loss = 0.07838093626407394
Trained batch 138 in epoch 5, gen_loss = 0.8226500646673518, disc_loss = 0.07856651386849099
Trained batch 139 in epoch 5, gen_loss = 0.8216618908303125, disc_loss = 0.07876975442548947
Trained batch 140 in epoch 5, gen_loss = 0.8217403402565219, disc_loss = 0.07842063217536144
Trained batch 141 in epoch 5, gen_loss = 0.8217735177194568, disc_loss = 0.07854587700821354
Trained batch 142 in epoch 5, gen_loss = 0.8197839422659441, disc_loss = 0.07857504539790895
Trained batch 143 in epoch 5, gen_loss = 0.821458864129252, disc_loss = 0.0784974292295778
Trained batch 144 in epoch 5, gen_loss = 0.8234694665875928, disc_loss = 0.0782102741879122
Trained batch 145 in epoch 5, gen_loss = 0.8211117705253705, disc_loss = 0.07845892428662883
Trained batch 146 in epoch 5, gen_loss = 0.825849724464676, disc_loss = 0.0784026419135685
Trained batch 147 in epoch 5, gen_loss = 0.8246965488872012, disc_loss = 0.07822206820915076
Trained batch 148 in epoch 5, gen_loss = 0.825404042365567, disc_loss = 0.07779298292710476
Trained batch 149 in epoch 5, gen_loss = 0.8261171817779541, disc_loss = 0.07798248524467151
Trained batch 150 in epoch 5, gen_loss = 0.8250230894183481, disc_loss = 0.0778538358231254
Trained batch 151 in epoch 5, gen_loss = 0.8241459292016531, disc_loss = 0.07757999622998268
Trained batch 152 in epoch 5, gen_loss = 0.8294068134688084, disc_loss = 0.07774004956183869
Trained batch 153 in epoch 5, gen_loss = 0.8268685228638835, disc_loss = 0.07789065430013391
Trained batch 154 in epoch 5, gen_loss = 0.8249326671323468, disc_loss = 0.07784976754938402
Trained batch 155 in epoch 5, gen_loss = 0.8259497284889221, disc_loss = 0.07782205736312346
Trained batch 156 in epoch 5, gen_loss = 0.8309569738473103, disc_loss = 0.07787698068341632
Trained batch 157 in epoch 5, gen_loss = 0.8295765119262889, disc_loss = 0.07770215222446979
Trained batch 158 in epoch 5, gen_loss = 0.8294787661834333, disc_loss = 0.07735290543510104
Trained batch 159 in epoch 5, gen_loss = 0.8293863400816918, disc_loss = 0.07712771469959989
Trained batch 160 in epoch 5, gen_loss = 0.8300471842659186, disc_loss = 0.07686174102127552
Trained batch 161 in epoch 5, gen_loss = 0.8299312345039698, disc_loss = 0.07654287056698475
Trained batch 162 in epoch 5, gen_loss = 0.8309092181591899, disc_loss = 0.07620030931808466
Trained batch 163 in epoch 5, gen_loss = 0.8333209058860453, disc_loss = 0.07589087955562807
Trained batch 164 in epoch 5, gen_loss = 0.8338712096214295, disc_loss = 0.07556017537911733
Trained batch 165 in epoch 5, gen_loss = 0.8351922764117459, disc_loss = 0.07520322746271829
Trained batch 166 in epoch 5, gen_loss = 0.8342146213183146, disc_loss = 0.07496340287302783
Trained batch 167 in epoch 5, gen_loss = 0.8362176875982966, disc_loss = 0.07471134866188679
Trained batch 168 in epoch 5, gen_loss = 0.8350903529387254, disc_loss = 0.07452439230221969
Trained batch 169 in epoch 5, gen_loss = 0.8364217211218441, disc_loss = 0.07424225545323947
Trained batch 170 in epoch 5, gen_loss = 0.8381692923997578, disc_loss = 0.07419896745585908
Trained batch 171 in epoch 5, gen_loss = 0.8357208939485772, disc_loss = 0.07445567500842519
Trained batch 172 in epoch 5, gen_loss = 0.8360826338646729, disc_loss = 0.07428742044018527
Trained batch 173 in epoch 5, gen_loss = 0.836473612949766, disc_loss = 0.0742364866530587
Trained batch 174 in epoch 5, gen_loss = 0.8354325086729867, disc_loss = 0.07406870762152332
Trained batch 175 in epoch 5, gen_loss = 0.834613873199983, disc_loss = 0.07384888168466701
Trained batch 176 in epoch 5, gen_loss = 0.8368292016498113, disc_loss = 0.0737069435943823
Trained batch 177 in epoch 5, gen_loss = 0.8373958331145598, disc_loss = 0.07341227200133411
Trained batch 178 in epoch 5, gen_loss = 0.8364825035606682, disc_loss = 0.07320952433156235
Trained batch 179 in epoch 5, gen_loss = 0.8381435222095913, disc_loss = 0.07317547447358569
Trained batch 180 in epoch 5, gen_loss = 0.8396411133075946, disc_loss = 0.0728365954279241
Trained batch 181 in epoch 5, gen_loss = 0.8420870939453879, disc_loss = 0.07251236869206468
Trained batch 182 in epoch 5, gen_loss = 0.84164135833907, disc_loss = 0.07234730122641461
Trained batch 183 in epoch 5, gen_loss = 0.8433318708253943, disc_loss = 0.07203030013276832
Trained batch 184 in epoch 5, gen_loss = 0.8462873387981106, disc_loss = 0.07178002823446249
Trained batch 185 in epoch 5, gen_loss = 0.8460140952499964, disc_loss = 0.07151689976253496
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.1342002153396606, disc_loss = 0.01367434486746788
Trained batch 1 in epoch 6, gen_loss = 1.3089163303375244, disc_loss = 0.022375300526618958
Trained batch 2 in epoch 6, gen_loss = 1.0384874145189922, disc_loss = 0.046478137373924255
Trained batch 3 in epoch 6, gen_loss = 1.1014864891767502, disc_loss = 0.041853435803204775
Trained batch 4 in epoch 6, gen_loss = 1.1129153370857239, disc_loss = 0.03823600709438324
Trained batch 5 in epoch 6, gen_loss = 1.0523599982261658, disc_loss = 0.03651058177153269
Trained batch 6 in epoch 6, gen_loss = 1.1066280603408813, disc_loss = 0.037778583488294055
Trained batch 7 in epoch 6, gen_loss = 1.0569153651595116, disc_loss = 0.03722459776327014
Trained batch 8 in epoch 6, gen_loss = 1.0170919232898288, disc_loss = 0.036655497633748584
Trained batch 9 in epoch 6, gen_loss = 1.043055260181427, disc_loss = 0.04827124811708927
Trained batch 10 in epoch 6, gen_loss = 0.974119942296635, disc_loss = 0.06273438747633588
Trained batch 11 in epoch 6, gen_loss = 0.9753944054245949, disc_loss = 0.06113719195127487
Trained batch 12 in epoch 6, gen_loss = 0.9812030861010919, disc_loss = 0.0622452233846371
Trained batch 13 in epoch 6, gen_loss = 0.9406055105584008, disc_loss = 0.06545670383742877
Trained batch 14 in epoch 6, gen_loss = 0.9397900640964508, disc_loss = 0.06345180074373881
Trained batch 15 in epoch 6, gen_loss = 0.9381775241345167, disc_loss = 0.0616485548671335
Trained batch 16 in epoch 6, gen_loss = 0.9524462275645312, disc_loss = 0.060447629541158676
Trained batch 17 in epoch 6, gen_loss = 0.9411308881309297, disc_loss = 0.06195227491358916
Trained batch 18 in epoch 6, gen_loss = 0.9038446694612503, disc_loss = 0.07071147329713169
Trained batch 19 in epoch 6, gen_loss = 0.9180729143321514, disc_loss = 0.07336505930870771
Trained batch 20 in epoch 6, gen_loss = 0.9255755110865548, disc_loss = 0.07138418743298167
Trained batch 21 in epoch 6, gen_loss = 0.8975941044363108, disc_loss = 0.07514277930286797
Trained batch 22 in epoch 6, gen_loss = 0.8995579448731049, disc_loss = 0.07277315401512643
Trained batch 23 in epoch 6, gen_loss = 0.9022560783972343, disc_loss = 0.07111844482521217
Trained batch 24 in epoch 6, gen_loss = 0.9100010794401169, disc_loss = 0.06963041409850121
Trained batch 25 in epoch 6, gen_loss = 0.9007287822090663, disc_loss = 0.06845452106342866
Trained batch 26 in epoch 6, gen_loss = 0.8918631490733888, disc_loss = 0.06735844413439433
Trained batch 27 in epoch 6, gen_loss = 0.9058919096631664, disc_loss = 0.06575838044019681
Trained batch 28 in epoch 6, gen_loss = 0.9133498396339088, disc_loss = 0.06432321686939947
Trained batch 29 in epoch 6, gen_loss = 0.9040592784682909, disc_loss = 0.06366942046831052
Trained batch 30 in epoch 6, gen_loss = 0.9092740277128835, disc_loss = 0.06244407522101556
Trained batch 31 in epoch 6, gen_loss = 0.9101915671490133, disc_loss = 0.06086335578584112
Trained batch 32 in epoch 6, gen_loss = 0.9104924161325801, disc_loss = 0.05942631329438
Trained batch 33 in epoch 6, gen_loss = 0.9117984592038042, disc_loss = 0.05807516600607949
Trained batch 34 in epoch 6, gen_loss = 0.9153023817709514, disc_loss = 0.05680610846195902
Trained batch 35 in epoch 6, gen_loss = 0.916734155267477, disc_loss = 0.0556161576985485
Trained batch 36 in epoch 6, gen_loss = 0.9204855605557158, disc_loss = 0.05444898972338116
Trained batch 37 in epoch 6, gen_loss = 0.9177453137542072, disc_loss = 0.05408958642204341
Trained batch 38 in epoch 6, gen_loss = 0.9062714733374424, disc_loss = 0.0551609309294667
Trained batch 39 in epoch 6, gen_loss = 0.921322814002633, disc_loss = 0.056352233164943755
Trained batch 40 in epoch 6, gen_loss = 0.9132631177582392, disc_loss = 0.05614449876565032
Trained batch 41 in epoch 6, gen_loss = 0.9106645247056371, disc_loss = 0.05530726769939065
Trained batch 42 in epoch 6, gen_loss = 0.9179007345160772, disc_loss = 0.054549129138332465
Trained batch 43 in epoch 6, gen_loss = 0.9249828542498025, disc_loss = 0.054683659839528526
Trained batch 44 in epoch 6, gen_loss = 0.9173006365696589, disc_loss = 0.05520708074586259
Trained batch 45 in epoch 6, gen_loss = 0.9185690429547558, disc_loss = 0.054385123065794294
Trained batch 46 in epoch 6, gen_loss = 0.9173373773376993, disc_loss = 0.054012767356285386
Trained batch 47 in epoch 6, gen_loss = 0.9199848501011729, disc_loss = 0.0532889276316079
Trained batch 48 in epoch 6, gen_loss = 0.9235025647343421, disc_loss = 0.05277871897406116
Trained batch 49 in epoch 6, gen_loss = 0.9142529943585396, disc_loss = 0.05361375266686082
Trained batch 50 in epoch 6, gen_loss = 0.915587322676883, disc_loss = 0.0530116675859865
Trained batch 51 in epoch 6, gen_loss = 0.9324311525202714, disc_loss = 0.05374627010538601
Trained batch 52 in epoch 6, gen_loss = 0.9269381303269908, disc_loss = 0.05379871836037568
Trained batch 53 in epoch 6, gen_loss = 0.9232097315015616, disc_loss = 0.05376324211074798
Trained batch 54 in epoch 6, gen_loss = 0.9201887610283765, disc_loss = 0.053305820121683854
Trained batch 55 in epoch 6, gen_loss = 0.9242781850376299, disc_loss = 0.05283474165480584
Trained batch 56 in epoch 6, gen_loss = 0.9227167328721598, disc_loss = 0.05221459496635617
Trained batch 57 in epoch 6, gen_loss = 0.9171828188259026, disc_loss = 0.052107367584289147
Trained batch 58 in epoch 6, gen_loss = 0.9211427329455392, disc_loss = 0.052406172804786995
Trained batch 59 in epoch 6, gen_loss = 0.9251019053161145, disc_loss = 0.05172169051753978
Trained batch 60 in epoch 6, gen_loss = 0.9248328455647484, disc_loss = 0.05106129300337835
Trained batch 61 in epoch 6, gen_loss = 0.9223555742252257, disc_loss = 0.050819937845752124
Trained batch 62 in epoch 6, gen_loss = 0.9227608690659205, disc_loss = 0.05036929059064105
Trained batch 63 in epoch 6, gen_loss = 0.9330535235349089, disc_loss = 0.05037045407516416
Trained batch 64 in epoch 6, gen_loss = 0.9311311439825938, disc_loss = 0.050217124576178884
Trained batch 65 in epoch 6, gen_loss = 0.927359153149706, disc_loss = 0.05031811879157568
Trained batch 66 in epoch 6, gen_loss = 0.9319313873550785, disc_loss = 0.05025235628848201
Trained batch 67 in epoch 6, gen_loss = 0.9311559859882382, disc_loss = 0.049891566789215976
Trained batch 68 in epoch 6, gen_loss = 0.9224660683801209, disc_loss = 0.05118845601606628
Trained batch 69 in epoch 6, gen_loss = 0.9251341268420219, disc_loss = 0.051089993212372065
Trained batch 70 in epoch 6, gen_loss = 0.9279603884673454, disc_loss = 0.05064511206001043
Trained batch 71 in epoch 6, gen_loss = 0.9242953370428748, disc_loss = 0.050465723667811185
Trained batch 72 in epoch 6, gen_loss = 0.9235166101014778, disc_loss = 0.05000384444090193
Trained batch 73 in epoch 6, gen_loss = 0.9217773734315021, disc_loss = 0.05000197400364119
Trained batch 74 in epoch 6, gen_loss = 0.9240311870972315, disc_loss = 0.04950693426032861
Trained batch 75 in epoch 6, gen_loss = 0.9245258273654863, disc_loss = 0.04904993739910424
Trained batch 76 in epoch 6, gen_loss = 0.9292904388207894, disc_loss = 0.0485747204851601
Trained batch 77 in epoch 6, gen_loss = 0.9287905114201399, disc_loss = 0.04810875791530961
Trained batch 78 in epoch 6, gen_loss = 0.9296311058952839, disc_loss = 0.04761258301714176
Trained batch 79 in epoch 6, gen_loss = 0.9310404697433114, disc_loss = 0.047334513592068105
Trained batch 80 in epoch 6, gen_loss = 0.9347540178784618, disc_loss = 0.04695528753699712
Trained batch 81 in epoch 6, gen_loss = 0.9349606453282077, disc_loss = 0.046667906785065806
Trained batch 82 in epoch 6, gen_loss = 0.9327473010284355, disc_loss = 0.04651292596371418
Trained batch 83 in epoch 6, gen_loss = 0.935236185966503, disc_loss = 0.046495406433851236
Trained batch 84 in epoch 6, gen_loss = 0.931640065592878, disc_loss = 0.04658990794902339
Trained batch 85 in epoch 6, gen_loss = 0.931657109322936, disc_loss = 0.04639320735018267
Trained batch 86 in epoch 6, gen_loss = 0.9336184443070971, disc_loss = 0.04682015474543147
Trained batch 87 in epoch 6, gen_loss = 0.9303763171827252, disc_loss = 0.046907578097571706
Trained batch 88 in epoch 6, gen_loss = 0.9268362342976453, disc_loss = 0.04713142806601323
Trained batch 89 in epoch 6, gen_loss = 0.9306762332717577, disc_loss = 0.04788178256195452
Trained batch 90 in epoch 6, gen_loss = 0.9254856799002532, disc_loss = 0.04844997578638268
Trained batch 91 in epoch 6, gen_loss = 0.9222745488843193, disc_loss = 0.04876523109598328
Trained batch 92 in epoch 6, gen_loss = 0.9209914817925422, disc_loss = 0.04917593229241589
Trained batch 93 in epoch 6, gen_loss = 0.9215066022378333, disc_loss = 0.04923122924098626
Trained batch 94 in epoch 6, gen_loss = 0.9203440906185852, disc_loss = 0.04927001353353262
Trained batch 95 in epoch 6, gen_loss = 0.9185686988445619, disc_loss = 0.049541288298011445
Trained batch 96 in epoch 6, gen_loss = 0.9247352875692328, disc_loss = 0.05008857191261864
Trained batch 97 in epoch 6, gen_loss = 0.9207062455160278, disc_loss = 0.050312485099218936
Trained batch 98 in epoch 6, gen_loss = 0.9183221039446917, disc_loss = 0.05044327579401057
Trained batch 99 in epoch 6, gen_loss = 0.9145339919626713, disc_loss = 0.050960958385840055
Trained batch 100 in epoch 6, gen_loss = 0.9139565927262353, disc_loss = 0.051015723469012446
Trained batch 101 in epoch 6, gen_loss = 0.914335687516951, disc_loss = 0.05076511354897829
Trained batch 102 in epoch 6, gen_loss = 0.911990312841332, disc_loss = 0.05063610221033247
Trained batch 103 in epoch 6, gen_loss = 0.9128118886683996, disc_loss = 0.0503366621157441
Trained batch 104 in epoch 6, gen_loss = 0.9183743461256936, disc_loss = 0.050138511340178195
Trained batch 105 in epoch 6, gen_loss = 0.9183075569991795, disc_loss = 0.049783202380223095
Trained batch 106 in epoch 6, gen_loss = 0.9162138980404239, disc_loss = 0.04964842765687782
Trained batch 107 in epoch 6, gen_loss = 0.9182235014935335, disc_loss = 0.04942517648278563
Trained batch 108 in epoch 6, gen_loss = 0.9171563836686109, disc_loss = 0.049131224034439536
Trained batch 109 in epoch 6, gen_loss = 0.9177512988448143, disc_loss = 0.048850754800845275
Trained batch 110 in epoch 6, gen_loss = 0.9173159214021923, disc_loss = 0.04859466698054258
Trained batch 111 in epoch 6, gen_loss = 0.9160993132474167, disc_loss = 0.04844801887936358
Trained batch 112 in epoch 6, gen_loss = 0.9161527896613146, disc_loss = 0.04816162040605482
Trained batch 113 in epoch 6, gen_loss = 0.9177640228156458, disc_loss = 0.04802430739724323
Trained batch 114 in epoch 6, gen_loss = 0.9168309140464533, disc_loss = 0.04776847200549167
Trained batch 115 in epoch 6, gen_loss = 0.9174324126336081, disc_loss = 0.047462647668375026
Trained batch 116 in epoch 6, gen_loss = 0.9191977005993199, disc_loss = 0.04716143857401151
Trained batch 117 in epoch 6, gen_loss = 0.9227368484361697, disc_loss = 0.04691210813757222
Trained batch 118 in epoch 6, gen_loss = 0.9214168147129171, disc_loss = 0.04669876960145325
Trained batch 119 in epoch 6, gen_loss = 0.9213059585541487, disc_loss = 0.04645956573076546
Trained batch 120 in epoch 6, gen_loss = 0.9231013977084278, disc_loss = 0.04651615034388609
Trained batch 121 in epoch 6, gen_loss = 0.9221356101944799, disc_loss = 0.04631692627597539
Trained batch 122 in epoch 6, gen_loss = 0.9210255447684265, disc_loss = 0.04612509810888186
Trained batch 123 in epoch 6, gen_loss = 0.9240534114501169, disc_loss = 0.04623020066308879
Trained batch 124 in epoch 6, gen_loss = 0.919973456978798, disc_loss = 0.04675328050553799
Trained batch 125 in epoch 6, gen_loss = 0.9208572616889363, disc_loss = 0.04680817484086941
Trained batch 126 in epoch 6, gen_loss = 0.9199988092259159, disc_loss = 0.046604533144456194
Trained batch 127 in epoch 6, gen_loss = 0.9200073975371197, disc_loss = 0.046326797346409876
Trained batch 128 in epoch 6, gen_loss = 0.9210436530122461, disc_loss = 0.04603247527870559
Trained batch 129 in epoch 6, gen_loss = 0.9221506954385684, disc_loss = 0.04592052516169273
Trained batch 130 in epoch 6, gen_loss = 0.9202708057092346, disc_loss = 0.04585336553970821
Trained batch 131 in epoch 6, gen_loss = 0.9230159924111583, disc_loss = 0.045629294659716615
Trained batch 132 in epoch 6, gen_loss = 0.9243572158248801, disc_loss = 0.045373857231404545
Trained batch 133 in epoch 6, gen_loss = 0.9250431697982461, disc_loss = 0.04510630191818102
Trained batch 134 in epoch 6, gen_loss = 0.9259039972667341, disc_loss = 0.04499822057507656
Trained batch 135 in epoch 6, gen_loss = 0.9260138059582781, disc_loss = 0.044778632260311174
Trained batch 136 in epoch 6, gen_loss = 0.9259651839515589, disc_loss = 0.04462282059129572
Trained batch 137 in epoch 6, gen_loss = 0.928264028892137, disc_loss = 0.044431635286605015
Trained batch 138 in epoch 6, gen_loss = 0.9289351231117042, disc_loss = 0.044204116899439753
Trained batch 139 in epoch 6, gen_loss = 0.9334222607314586, disc_loss = 0.044121559829052005
Trained batch 140 in epoch 6, gen_loss = 0.9325779584494043, disc_loss = 0.04393808315144786
Trained batch 141 in epoch 6, gen_loss = 0.9324225834767583, disc_loss = 0.04371328527291476
Trained batch 142 in epoch 6, gen_loss = 0.9358678732093397, disc_loss = 0.04367109644715186
Trained batch 143 in epoch 6, gen_loss = 0.9369202166174849, disc_loss = 0.043508742741929986
Trained batch 144 in epoch 6, gen_loss = 0.9350575328900896, disc_loss = 0.04369268922199463
Trained batch 145 in epoch 6, gen_loss = 0.9388224250853878, disc_loss = 0.044374666712565784
Trained batch 146 in epoch 6, gen_loss = 0.9406983435762172, disc_loss = 0.04453566737574379
Trained batch 147 in epoch 6, gen_loss = 0.9412086498294328, disc_loss = 0.04435889356190691
Trained batch 148 in epoch 6, gen_loss = 0.9410519784928968, disc_loss = 0.044243212076741575
Trained batch 149 in epoch 6, gen_loss = 0.9405110829075177, disc_loss = 0.044103208941717945
Trained batch 150 in epoch 6, gen_loss = 0.9418275767801613, disc_loss = 0.044716168478723395
Trained batch 151 in epoch 6, gen_loss = 0.938552995555495, disc_loss = 0.045100955353853736
Trained batch 152 in epoch 6, gen_loss = 0.9372014355620527, disc_loss = 0.04504958821424082
Trained batch 153 in epoch 6, gen_loss = 0.9392090403994957, disc_loss = 0.04523233453706874
Trained batch 154 in epoch 6, gen_loss = 0.9389319645781671, disc_loss = 0.04505659195203935
Trained batch 155 in epoch 6, gen_loss = 0.9378528842368187, disc_loss = 0.04494610278365704
Trained batch 156 in epoch 6, gen_loss = 0.9390303438446325, disc_loss = 0.0449289072328692
Trained batch 157 in epoch 6, gen_loss = 0.9388606347426584, disc_loss = 0.04473257232221622
Trained batch 158 in epoch 6, gen_loss = 0.9360308531882628, disc_loss = 0.04500377353913379
Trained batch 159 in epoch 6, gen_loss = 0.9375686106272042, disc_loss = 0.046153397276066245
Trained batch 160 in epoch 6, gen_loss = 0.9337065620637088, disc_loss = 0.04690246013288172
Trained batch 161 in epoch 6, gen_loss = 0.9324425838795709, disc_loss = 0.04715954951574037
Trained batch 162 in epoch 6, gen_loss = 0.930275125463316, disc_loss = 0.0475910725357708
Trained batch 163 in epoch 6, gen_loss = 0.9316202915478043, disc_loss = 0.0475494863419998
Trained batch 164 in epoch 6, gen_loss = 0.9293887157331814, disc_loss = 0.047707178962953165
Trained batch 165 in epoch 6, gen_loss = 0.928531713963273, disc_loss = 0.04769007785313101
Trained batch 166 in epoch 6, gen_loss = 0.9294999906581319, disc_loss = 0.04766093433170975
Trained batch 167 in epoch 6, gen_loss = 0.9270579148793504, disc_loss = 0.047770199521134295
Trained batch 168 in epoch 6, gen_loss = 0.9283007214936985, disc_loss = 0.0476903194374234
Trained batch 169 in epoch 6, gen_loss = 0.9278433102895232, disc_loss = 0.047527411952614784
Trained batch 170 in epoch 6, gen_loss = 0.92582910076568, disc_loss = 0.04757657167855759
Trained batch 171 in epoch 6, gen_loss = 0.9278189190771691, disc_loss = 0.04763430584395348
Trained batch 172 in epoch 6, gen_loss = 0.9286545471132146, disc_loss = 0.047411635324272804
Trained batch 173 in epoch 6, gen_loss = 0.926921689390451, disc_loss = 0.047379220289916826
Trained batch 174 in epoch 6, gen_loss = 0.9268150292975562, disc_loss = 0.047260480544396806
Trained batch 175 in epoch 6, gen_loss = 0.9277655256234787, disc_loss = 0.04703871158099818
Trained batch 176 in epoch 6, gen_loss = 0.9260970513194294, disc_loss = 0.04704637084114181
Trained batch 177 in epoch 6, gen_loss = 0.9291220244564368, disc_loss = 0.04715109724823511
Trained batch 178 in epoch 6, gen_loss = 0.9277491510413879, disc_loss = 0.0471858221506856
Trained batch 179 in epoch 6, gen_loss = 0.927480612281296, disc_loss = 0.047024874746178585
Trained batch 180 in epoch 6, gen_loss = 0.9295243137613844, disc_loss = 0.046920319406819934
Trained batch 181 in epoch 6, gen_loss = 0.9288391101655069, disc_loss = 0.046788135302959236
Trained batch 182 in epoch 6, gen_loss = 0.9308210602386402, disc_loss = 0.04661478308828476
Trained batch 183 in epoch 6, gen_loss = 0.930931156501174, disc_loss = 0.046412802898608475
Trained batch 184 in epoch 6, gen_loss = 0.9306100295202152, disc_loss = 0.046241228493887024
Trained batch 185 in epoch 6, gen_loss = 0.9304127697181958, disc_loss = 0.04628494046428191
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.053574800491333, disc_loss = 0.008638104423880577
Trained batch 1 in epoch 7, gen_loss = 0.8750532865524292, disc_loss = 0.022146391682326794
Trained batch 2 in epoch 7, gen_loss = 0.9118779301643372, disc_loss = 0.022464798763394356
Trained batch 3 in epoch 7, gen_loss = 0.914514347910881, disc_loss = 0.019842167384922504
Trained batch 4 in epoch 7, gen_loss = 1.0162245631217957, disc_loss = 0.0465206004679203
Trained batch 5 in epoch 7, gen_loss = 0.8827535659074783, disc_loss = 0.07602172158658504
Trained batch 6 in epoch 7, gen_loss = 0.8556751821722303, disc_loss = 0.07586310431361198
Trained batch 7 in epoch 7, gen_loss = 0.8214631415903568, disc_loss = 0.0767499296925962
Trained batch 8 in epoch 7, gen_loss = 0.8753601743115319, disc_loss = 0.07364127039909363
Trained batch 9 in epoch 7, gen_loss = 0.8737386792898179, disc_loss = 0.0682508397847414
Trained batch 10 in epoch 7, gen_loss = 0.8541724438017065, disc_loss = 0.06577438048341057
Trained batch 11 in epoch 7, gen_loss = 0.8784468347827593, disc_loss = 0.06186873745173216
Trained batch 12 in epoch 7, gen_loss = 0.932351256792362, disc_loss = 0.05950421997560905
Trained batch 13 in epoch 7, gen_loss = 0.916986923132624, disc_loss = 0.057502555660903454
Trained batch 14 in epoch 7, gen_loss = 0.9114918132623037, disc_loss = 0.054789410034815474
Trained batch 15 in epoch 7, gen_loss = 0.9422758053988218, disc_loss = 0.054249001666903496
Trained batch 16 in epoch 7, gen_loss = 0.944485077086617, disc_loss = 0.051733624792712575
Trained batch 17 in epoch 7, gen_loss = 0.9257515652312173, disc_loss = 0.0518656093109813
Trained batch 18 in epoch 7, gen_loss = 0.9367152374041708, disc_loss = 0.0501733682559509
Trained batch 19 in epoch 7, gen_loss = 0.9515956327319145, disc_loss = 0.048541882121935484
Trained batch 20 in epoch 7, gen_loss = 0.9382159326757703, disc_loss = 0.047922003703812756
Trained batch 21 in epoch 7, gen_loss = 0.9471038214185021, disc_loss = 0.04684360913762992
Trained batch 22 in epoch 7, gen_loss = 0.9459267193856447, disc_loss = 0.045564080669504146
Trained batch 23 in epoch 7, gen_loss = 0.9457154137392839, disc_loss = 0.04427462175954133
Trained batch 24 in epoch 7, gen_loss = 0.9436921894550323, disc_loss = 0.043288570754230024
Trained batch 25 in epoch 7, gen_loss = 0.9383358072776061, disc_loss = 0.04250066874262232
Trained batch 26 in epoch 7, gen_loss = 0.9599377523969721, disc_loss = 0.04376631454323177
Trained batch 27 in epoch 7, gen_loss = 0.9398620916264397, disc_loss = 0.04644453156340335
Trained batch 28 in epoch 7, gen_loss = 0.9437889497855614, disc_loss = 0.04598812864900663
Trained batch 29 in epoch 7, gen_loss = 0.9428077201048534, disc_loss = 0.045679774787276986
Trained batch 30 in epoch 7, gen_loss = 0.9426221078441989, disc_loss = 0.04472602245908591
Trained batch 31 in epoch 7, gen_loss = 0.9405654333531857, disc_loss = 0.04384610036504455
Trained batch 32 in epoch 7, gen_loss = 0.9401529774521337, disc_loss = 0.044768397131878315
Trained batch 33 in epoch 7, gen_loss = 0.9448838865055758, disc_loss = 0.04375281094518654
Trained batch 34 in epoch 7, gen_loss = 0.9339893920081003, disc_loss = 0.04445050334823983
Trained batch 35 in epoch 7, gen_loss = 0.9409178594748179, disc_loss = 0.0453950729376326
Trained batch 36 in epoch 7, gen_loss = 0.9283317528866433, disc_loss = 0.04631482565624488
Trained batch 37 in epoch 7, gen_loss = 0.9285114901630502, disc_loss = 0.045860697147681526
Trained batch 38 in epoch 7, gen_loss = 0.9348052212825189, disc_loss = 0.04544977650332909
Trained batch 39 in epoch 7, gen_loss = 0.9339270107448101, disc_loss = 0.04461671190802008
Trained batch 40 in epoch 7, gen_loss = 0.9301846616151856, disc_loss = 0.044185101327191036
Trained batch 41 in epoch 7, gen_loss = 0.9303436116093681, disc_loss = 0.043474826185653605
Trained batch 42 in epoch 7, gen_loss = 0.9290405033632766, disc_loss = 0.04290831316435753
Trained batch 43 in epoch 7, gen_loss = 0.9307203286073424, disc_loss = 0.042646125742149626
Trained batch 44 in epoch 7, gen_loss = 0.9369436601797739, disc_loss = 0.041922122757467956
Trained batch 45 in epoch 7, gen_loss = 0.9320612271194872, disc_loss = 0.04165730214394305
Trained batch 46 in epoch 7, gen_loss = 0.9324106593081292, disc_loss = 0.04129173727507921
Trained batch 47 in epoch 7, gen_loss = 0.9258112342407306, disc_loss = 0.041622804497213416
Trained batch 48 in epoch 7, gen_loss = 0.9347195144818754, disc_loss = 0.04351006936738078
Trained batch 49 in epoch 7, gen_loss = 0.9257329767942428, disc_loss = 0.044834061730653046
Trained batch 50 in epoch 7, gen_loss = 0.9199817887708253, disc_loss = 0.04530371917302117
Trained batch 51 in epoch 7, gen_loss = 0.9273665598951853, disc_loss = 0.0508329276747715
Trained batch 52 in epoch 7, gen_loss = 0.9170347289094385, disc_loss = 0.056881183037920946
Trained batch 53 in epoch 7, gen_loss = 0.9231425363708425, disc_loss = 0.061052003823634654
Trained batch 54 in epoch 7, gen_loss = 0.9276673983443867, disc_loss = 0.06939442416822368
Trained batch 55 in epoch 7, gen_loss = 0.9261614972991603, disc_loss = 0.07690051346019443
Trained batch 56 in epoch 7, gen_loss = 0.930425095453597, disc_loss = 0.08342260790563989
Trained batch 57 in epoch 7, gen_loss = 0.929543567628696, disc_loss = 0.09126035652348194
Trained batch 58 in epoch 7, gen_loss = 0.9271210972535409, disc_loss = 0.09292714766589767
Trained batch 59 in epoch 7, gen_loss = 0.922028208275636, disc_loss = 0.09386015821558734
Trained batch 60 in epoch 7, gen_loss = 0.9116518302041976, disc_loss = 0.0958588591272958
Trained batch 61 in epoch 7, gen_loss = 0.9104938487852773, disc_loss = 0.09973738836725393
Trained batch 62 in epoch 7, gen_loss = 0.9039132656559111, disc_loss = 0.09999597440695479
Trained batch 63 in epoch 7, gen_loss = 0.8971092528663576, disc_loss = 0.10003108008822892
Trained batch 64 in epoch 7, gen_loss = 0.892441561130377, disc_loss = 0.09965651483776478
Trained batch 65 in epoch 7, gen_loss = 0.8880800681583809, disc_loss = 0.09953289333674492
Trained batch 66 in epoch 7, gen_loss = 0.8848931010979325, disc_loss = 0.09878431489941344
Trained batch 67 in epoch 7, gen_loss = 0.8811219549354385, disc_loss = 0.09884910730590277
Trained batch 68 in epoch 7, gen_loss = 0.8793633765932443, disc_loss = 0.09797370651115973
Trained batch 69 in epoch 7, gen_loss = 0.8797432120357241, disc_loss = 0.09690451293385455
Trained batch 70 in epoch 7, gen_loss = 0.8747557221164166, disc_loss = 0.09651456512248432
Trained batch 71 in epoch 7, gen_loss = 0.8794839485651917, disc_loss = 0.09601002042957892
Trained batch 72 in epoch 7, gen_loss = 0.8766295669013506, disc_loss = 0.09534015813969994
Trained batch 73 in epoch 7, gen_loss = 0.8731969913115373, disc_loss = 0.09498286882818148
Trained batch 74 in epoch 7, gen_loss = 0.872246055205663, disc_loss = 0.09404734990249078
Trained batch 75 in epoch 7, gen_loss = 0.8751673082772055, disc_loss = 0.09342706547804962
Trained batch 76 in epoch 7, gen_loss = 0.8745501037541922, disc_loss = 0.09245475107054045
Trained batch 77 in epoch 7, gen_loss = 0.8689211423580463, disc_loss = 0.09244398702270328
Trained batch 78 in epoch 7, gen_loss = 0.8737151230437846, disc_loss = 0.09246520336151501
Trained batch 79 in epoch 7, gen_loss = 0.8720912627875805, disc_loss = 0.09190754081355408
Trained batch 80 in epoch 7, gen_loss = 0.8681184362482142, disc_loss = 0.09152444531382234
Trained batch 81 in epoch 7, gen_loss = 0.8660973928323606, disc_loss = 0.09087036128678336
Trained batch 82 in epoch 7, gen_loss = 0.8694468528391367, disc_loss = 0.09058159721050277
Trained batch 83 in epoch 7, gen_loss = 0.8690746462061292, disc_loss = 0.08987361313553438
Trained batch 84 in epoch 7, gen_loss = 0.8708758487420923, disc_loss = 0.08903645258396864
Trained batch 85 in epoch 7, gen_loss = 0.8730010979397352, disc_loss = 0.08811024076110402
Trained batch 86 in epoch 7, gen_loss = 0.8731162712491792, disc_loss = 0.0872452627953099
Trained batch 87 in epoch 7, gen_loss = 0.8714842674407092, disc_loss = 0.08672634408470582
Trained batch 88 in epoch 7, gen_loss = 0.8736153131120661, disc_loss = 0.08617195116586229
Trained batch 89 in epoch 7, gen_loss = 0.8724628004762861, disc_loss = 0.08544106075747146
Trained batch 90 in epoch 7, gen_loss = 0.8732129466402662, disc_loss = 0.08486802468669939
Trained batch 91 in epoch 7, gen_loss = 0.8709944395915322, disc_loss = 0.08431794338495187
Trained batch 92 in epoch 7, gen_loss = 0.8692643988517023, disc_loss = 0.08381712931378554
Trained batch 93 in epoch 7, gen_loss = 0.8742082943307593, disc_loss = 0.08320388742821648
Trained batch 94 in epoch 7, gen_loss = 0.8753215883907519, disc_loss = 0.08243420289731339
Trained batch 95 in epoch 7, gen_loss = 0.8723864157994589, disc_loss = 0.08207003994417998
Trained batch 96 in epoch 7, gen_loss = 0.8758628810803915, disc_loss = 0.08157019755927865
Trained batch 97 in epoch 7, gen_loss = 0.8771075734070369, disc_loss = 0.08093010258803866
Trained batch 98 in epoch 7, gen_loss = 0.8733723494741652, disc_loss = 0.08083995647088747
Trained batch 99 in epoch 7, gen_loss = 0.8754561454057693, disc_loss = 0.08036128641106188
Trained batch 100 in epoch 7, gen_loss = 0.8770317612308087, disc_loss = 0.07968681808192246
Trained batch 101 in epoch 7, gen_loss = 0.8766574251885507, disc_loss = 0.07907697774798554
Trained batch 102 in epoch 7, gen_loss = 0.8794279052215872, disc_loss = 0.07860124958407821
Trained batch 103 in epoch 7, gen_loss = 0.8750087664677546, disc_loss = 0.07890302237445632
Trained batch 104 in epoch 7, gen_loss = 0.8768319743020194, disc_loss = 0.07823008062051875
Trained batch 105 in epoch 7, gen_loss = 0.8833547043350508, disc_loss = 0.07820237446400635
Trained batch 106 in epoch 7, gen_loss = 0.8815920631462169, disc_loss = 0.0777704014277486
Trained batch 107 in epoch 7, gen_loss = 0.8773271816748159, disc_loss = 0.07805578904743823
Trained batch 108 in epoch 7, gen_loss = 0.8825690593194524, disc_loss = 0.0779712349603619
Trained batch 109 in epoch 7, gen_loss = 0.8829777820543809, disc_loss = 0.07742732510139996
Trained batch 110 in epoch 7, gen_loss = 0.8838717792485211, disc_loss = 0.07685499484776645
Trained batch 111 in epoch 7, gen_loss = 0.8810982752059188, disc_loss = 0.07665648874327806
Trained batch 112 in epoch 7, gen_loss = 0.8814012239464616, disc_loss = 0.07619397473249552
Trained batch 113 in epoch 7, gen_loss = 0.8839672328087321, disc_loss = 0.07567402855248044
Trained batch 114 in epoch 7, gen_loss = 0.8852939942608709, disc_loss = 0.07528446884420903
Trained batch 115 in epoch 7, gen_loss = 0.8863146166349279, disc_loss = 0.07472410586116643
Trained batch 116 in epoch 7, gen_loss = 0.8819438616434733, disc_loss = 0.07508673327855575
Trained batch 117 in epoch 7, gen_loss = 0.8861000901561672, disc_loss = 0.07498129135218717
Trained batch 118 in epoch 7, gen_loss = 0.8849672830405355, disc_loss = 0.07453867431510897
Trained batch 119 in epoch 7, gen_loss = 0.8839908411105474, disc_loss = 0.07426053194018702
Trained batch 120 in epoch 7, gen_loss = 0.8860014874087877, disc_loss = 0.07443470866534828
Trained batch 121 in epoch 7, gen_loss = 0.8833138854777227, disc_loss = 0.0745197830904947
Trained batch 122 in epoch 7, gen_loss = 0.8838407935165777, disc_loss = 0.07408029204461633
Trained batch 123 in epoch 7, gen_loss = 0.8861691509523699, disc_loss = 0.0735874499735092
Trained batch 124 in epoch 7, gen_loss = 0.8848684158325195, disc_loss = 0.07321716804802418
Trained batch 125 in epoch 7, gen_loss = 0.8864776473196726, disc_loss = 0.0728901717368336
Trained batch 126 in epoch 7, gen_loss = 0.8856184529507254, disc_loss = 0.07248014697115722
Trained batch 127 in epoch 7, gen_loss = 0.8863296951167285, disc_loss = 0.0723768054303946
Trained batch 128 in epoch 7, gen_loss = 0.8835433679957723, disc_loss = 0.07230047155316024
Trained batch 129 in epoch 7, gen_loss = 0.88335223702284, disc_loss = 0.07188222664766587
Trained batch 130 in epoch 7, gen_loss = 0.8874017932942806, disc_loss = 0.07149106989266309
Trained batch 131 in epoch 7, gen_loss = 0.889581096443263, disc_loss = 0.07101599812846292
Trained batch 132 in epoch 7, gen_loss = 0.8896419226675105, disc_loss = 0.07057399178077851
Trained batch 133 in epoch 7, gen_loss = 0.8919415371631508, disc_loss = 0.07026592839453648
Trained batch 134 in epoch 7, gen_loss = 0.888178742814947, disc_loss = 0.07053535428863984
Trained batch 135 in epoch 7, gen_loss = 0.8897906817934093, disc_loss = 0.07006815560709904
Trained batch 136 in epoch 7, gen_loss = 0.8929301556879586, disc_loss = 0.07002967044058507
Trained batch 137 in epoch 7, gen_loss = 0.8911006623420162, disc_loss = 0.06990562768086143
Trained batch 138 in epoch 7, gen_loss = 0.8897138465222695, disc_loss = 0.06961479769657841
Trained batch 139 in epoch 7, gen_loss = 0.8889969996043614, disc_loss = 0.06925075213824
Trained batch 140 in epoch 7, gen_loss = 0.8910949576831033, disc_loss = 0.06912533516156757
Trained batch 141 in epoch 7, gen_loss = 0.8933766349940233, disc_loss = 0.0687097238940777
Trained batch 142 in epoch 7, gen_loss = 0.8936519272677548, disc_loss = 0.06829549165090898
Trained batch 143 in epoch 7, gen_loss = 0.8928412492904398, disc_loss = 0.06806954546158926
Trained batch 144 in epoch 7, gen_loss = 0.8947657457713423, disc_loss = 0.06769570811683762
Trained batch 145 in epoch 7, gen_loss = 0.8953414800232404, disc_loss = 0.06736690089846514
Trained batch 146 in epoch 7, gen_loss = 0.8940785519119834, disc_loss = 0.06709579096435486
Trained batch 147 in epoch 7, gen_loss = 0.8976511717648119, disc_loss = 0.06725353019538562
Trained batch 148 in epoch 7, gen_loss = 0.8953103227103316, disc_loss = 0.0672604128805883
Trained batch 149 in epoch 7, gen_loss = 0.896656330426534, disc_loss = 0.06688107333456476
Trained batch 150 in epoch 7, gen_loss = 0.8964175581932068, disc_loss = 0.06707822854032382
Trained batch 151 in epoch 7, gen_loss = 0.8953765360148329, disc_loss = 0.06683434344411485
Trained batch 152 in epoch 7, gen_loss = 0.8942747642012203, disc_loss = 0.0665786429156178
Trained batch 153 in epoch 7, gen_loss = 0.8964840758156467, disc_loss = 0.06712231603027745
Trained batch 154 in epoch 7, gen_loss = 0.8941347106810539, disc_loss = 0.06711311217157111
Trained batch 155 in epoch 7, gen_loss = 0.8927598889821615, disc_loss = 0.06692329050901417
Trained batch 156 in epoch 7, gen_loss = 0.8930161033466364, disc_loss = 0.06756938359800987
Trained batch 157 in epoch 7, gen_loss = 0.8906851195836369, disc_loss = 0.0676125993633855
Trained batch 158 in epoch 7, gen_loss = 0.8884615542003943, disc_loss = 0.06758276913783648
Trained batch 159 in epoch 7, gen_loss = 0.8903050806373358, disc_loss = 0.06750255878432654
Trained batch 160 in epoch 7, gen_loss = 0.8889863024587217, disc_loss = 0.0673805026985381
Trained batch 161 in epoch 7, gen_loss = 0.8888938655087977, disc_loss = 0.06725861156865219
Trained batch 162 in epoch 7, gen_loss = 0.8886003837995002, disc_loss = 0.06698524464561713
Trained batch 163 in epoch 7, gen_loss = 0.8864245709122681, disc_loss = 0.06702130180556418
Trained batch 164 in epoch 7, gen_loss = 0.8902455022840788, disc_loss = 0.06733657918080235
Trained batch 165 in epoch 7, gen_loss = 0.889217734336853, disc_loss = 0.0671303115325071
Trained batch 166 in epoch 7, gen_loss = 0.8895528295082961, disc_loss = 0.06680661706465804
Trained batch 167 in epoch 7, gen_loss = 0.888889403570266, disc_loss = 0.0665354368143848
Trained batch 168 in epoch 7, gen_loss = 0.8905364698206885, disc_loss = 0.06622680703167026
Trained batch 169 in epoch 7, gen_loss = 0.8900269087623147, disc_loss = 0.06594806417603703
Trained batch 170 in epoch 7, gen_loss = 0.8950550765321966, disc_loss = 0.0659232068022615
Trained batch 171 in epoch 7, gen_loss = 0.8935340930556142, disc_loss = 0.06583471881052436
Trained batch 172 in epoch 7, gen_loss = 0.8951926662053676, disc_loss = 0.06555439606093602
Trained batch 173 in epoch 7, gen_loss = 0.8948058126301601, disc_loss = 0.06527398338263062
Trained batch 174 in epoch 7, gen_loss = 0.8961430730138507, disc_loss = 0.06513327732682228
Trained batch 175 in epoch 7, gen_loss = 0.8949797481975772, disc_loss = 0.06495072552934289
Trained batch 176 in epoch 7, gen_loss = 0.8938546463594599, disc_loss = 0.06487703443331233
Trained batch 177 in epoch 7, gen_loss = 0.8949365716301994, disc_loss = 0.06465395053409123
Trained batch 178 in epoch 7, gen_loss = 0.8938929808206398, disc_loss = 0.06447140380282308
Trained batch 179 in epoch 7, gen_loss = 0.8955263091458214, disc_loss = 0.06437827784361111
Trained batch 180 in epoch 7, gen_loss = 0.8951952822959226, disc_loss = 0.06411075207162957
Trained batch 181 in epoch 7, gen_loss = 0.8931075914220495, disc_loss = 0.06413629317431005
Trained batch 182 in epoch 7, gen_loss = 0.8977696749030567, disc_loss = 0.064363434931131
Trained batch 183 in epoch 7, gen_loss = 0.8990099763740664, disc_loss = 0.06405330259028984
Trained batch 184 in epoch 7, gen_loss = 0.8984267627870715, disc_loss = 0.06384514974983962
Trained batch 185 in epoch 7, gen_loss = 0.8966690776168659, disc_loss = 0.06377600077339397
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.0440974235534668, disc_loss = 0.011158859357237816
Trained batch 1 in epoch 8, gen_loss = 1.049066960811615, disc_loss = 0.017941451631486416
Trained batch 2 in epoch 8, gen_loss = 1.0438222487767537, disc_loss = 0.014274065693219503
Trained batch 3 in epoch 8, gen_loss = 0.907665841281414, disc_loss = 0.030200397595763206
Trained batch 4 in epoch 8, gen_loss = 0.9630994260311126, disc_loss = 0.026820680126547813
Trained batch 5 in epoch 8, gen_loss = 1.0081411550442378, disc_loss = 0.04632127253959576
Trained batch 6 in epoch 8, gen_loss = 0.9731577166489193, disc_loss = 0.04474184795149735
Trained batch 7 in epoch 8, gen_loss = 0.8780203200876713, disc_loss = 0.06805476569570601
Trained batch 8 in epoch 8, gen_loss = 0.9398413267400529, disc_loss = 0.08060217586656411
Trained batch 9 in epoch 8, gen_loss = 0.9059354692697525, disc_loss = 0.08107776958495379
Trained batch 10 in epoch 8, gen_loss = 0.8895576569167051, disc_loss = 0.07666364125907421
Trained batch 11 in epoch 8, gen_loss = 0.9021763727068901, disc_loss = 0.07499950736140211
Trained batch 12 in epoch 8, gen_loss = 0.8823987681132096, disc_loss = 0.07237904647795054
Trained batch 13 in epoch 8, gen_loss = 0.8910081961325237, disc_loss = 0.07445317999060665
Trained batch 14 in epoch 8, gen_loss = 0.8709427734216054, disc_loss = 0.07303909150262673
Trained batch 15 in epoch 8, gen_loss = 0.86462670750916, disc_loss = 0.07040366798173636
Trained batch 16 in epoch 8, gen_loss = 0.8539200057001675, disc_loss = 0.07166970291120164
Trained batch 17 in epoch 8, gen_loss = 0.8492351356479857, disc_loss = 0.06917063798755407
Trained batch 18 in epoch 8, gen_loss = 0.8642110495190871, disc_loss = 0.06630927588986724
Trained batch 19 in epoch 8, gen_loss = 0.8462279185652732, disc_loss = 0.06664552232250572
Trained batch 20 in epoch 8, gen_loss = 0.8646151835010165, disc_loss = 0.06677843373091448
Trained batch 21 in epoch 8, gen_loss = 0.8478373478759419, disc_loss = 0.06729804478924382
Trained batch 22 in epoch 8, gen_loss = 0.8630605236343716, disc_loss = 0.06566634280202181
Trained batch 23 in epoch 8, gen_loss = 0.8685841610034307, disc_loss = 0.06373607592346768
Trained batch 24 in epoch 8, gen_loss = 0.8669349527359009, disc_loss = 0.06179676406085491
Trained batch 25 in epoch 8, gen_loss = 0.8667802673119765, disc_loss = 0.05990530170786839
Trained batch 26 in epoch 8, gen_loss = 0.8749414152569241, disc_loss = 0.060648972168564796
Trained batch 27 in epoch 8, gen_loss = 0.8595867188913482, disc_loss = 0.06219608196988702
Trained batch 28 in epoch 8, gen_loss = 0.8546268045902252, disc_loss = 0.06144034843249568
Trained batch 29 in epoch 8, gen_loss = 0.8716089497009913, disc_loss = 0.06515151939044396
Trained batch 30 in epoch 8, gen_loss = 0.8643777264702704, disc_loss = 0.06459623641304431
Trained batch 31 in epoch 8, gen_loss = 0.8618546454235911, disc_loss = 0.06344368075951934
Trained batch 32 in epoch 8, gen_loss = 0.861300752921538, disc_loss = 0.06349783661690625
Trained batch 33 in epoch 8, gen_loss = 0.8533696418299395, disc_loss = 0.0634900215355789
Trained batch 34 in epoch 8, gen_loss = 0.8467000458921705, disc_loss = 0.06366885751485825
Trained batch 35 in epoch 8, gen_loss = 0.8470121713148223, disc_loss = 0.06291172115339173
Trained batch 36 in epoch 8, gen_loss = 0.8405106510664966, disc_loss = 0.06253007890002148
Trained batch 37 in epoch 8, gen_loss = 0.8500935458823254, disc_loss = 0.06154569983482361
Trained batch 38 in epoch 8, gen_loss = 0.8471382023432316, disc_loss = 0.06062485984502695
Trained batch 39 in epoch 8, gen_loss = 0.8488610498607159, disc_loss = 0.06010112641379237
Trained batch 40 in epoch 8, gen_loss = 0.8612920939922333, disc_loss = 0.05913267025678623
Trained batch 41 in epoch 8, gen_loss = 0.8567253542797906, disc_loss = 0.05857955429348208
Trained batch 42 in epoch 8, gen_loss = 0.8611016516075578, disc_loss = 0.05737487064284641
Trained batch 43 in epoch 8, gen_loss = 0.8626392774961211, disc_loss = 0.05630798392336477
Trained batch 44 in epoch 8, gen_loss = 0.8675023337205251, disc_loss = 0.05523135407517354
Trained batch 45 in epoch 8, gen_loss = 0.8711702817160151, disc_loss = 0.054960768204182386
Trained batch 46 in epoch 8, gen_loss = 0.8685184863019497, disc_loss = 0.05464914530277886
Trained batch 47 in epoch 8, gen_loss = 0.8704528740296761, disc_loss = 0.05374652056101089
Trained batch 48 in epoch 8, gen_loss = 0.8668760030853505, disc_loss = 0.053292887722503166
Trained batch 49 in epoch 8, gen_loss = 0.8778996652364731, disc_loss = 0.052882366720587014
Trained batch 50 in epoch 8, gen_loss = 0.8742652751651465, disc_loss = 0.05246648274581222
Trained batch 51 in epoch 8, gen_loss = 0.8725309538153502, disc_loss = 0.05187300089388513
Trained batch 52 in epoch 8, gen_loss = 0.8797872724398127, disc_loss = 0.05128384952626701
Trained batch 53 in epoch 8, gen_loss = 0.8896491511000527, disc_loss = 0.05068904497764177
Trained batch 54 in epoch 8, gen_loss = 0.8890069381757216, disc_loss = 0.05008485447615385
Trained batch 55 in epoch 8, gen_loss = 0.8904735919620309, disc_loss = 0.04936260043177754
Trained batch 56 in epoch 8, gen_loss = 0.8972789514483067, disc_loss = 0.049096620314868916
Trained batch 57 in epoch 8, gen_loss = 0.8961667197531668, disc_loss = 0.04865875633048086
Trained batch 58 in epoch 8, gen_loss = 0.8978091836985895, disc_loss = 0.04826322120566994
Trained batch 59 in epoch 8, gen_loss = 0.9013242498040199, disc_loss = 0.04759927030342321
Trained batch 60 in epoch 8, gen_loss = 0.9120565042143962, disc_loss = 0.0473853820995962
Trained batch 61 in epoch 8, gen_loss = 0.9182340882478222, disc_loss = 0.046870970362496954
Trained batch 62 in epoch 8, gen_loss = 0.9131830159633879, disc_loss = 0.0471762472408868
Trained batch 63 in epoch 8, gen_loss = 0.9188281246460974, disc_loss = 0.04667046891700011
Trained batch 64 in epoch 8, gen_loss = 0.9271892001995674, disc_loss = 0.04705312542903882
Trained batch 65 in epoch 8, gen_loss = 0.925191040743481, disc_loss = 0.046766501921934614
Trained batch 66 in epoch 8, gen_loss = 0.924074953616555, disc_loss = 0.046323322301813914
Trained batch 67 in epoch 8, gen_loss = 0.922727936769233, disc_loss = 0.04590032552368939
Trained batch 68 in epoch 8, gen_loss = 0.9299424398636472, disc_loss = 0.04553879466771647
Trained batch 69 in epoch 8, gen_loss = 0.9278610404048647, disc_loss = 0.0452033905445465
Trained batch 70 in epoch 8, gen_loss = 0.9363855581048509, disc_loss = 0.04498125039513262
Trained batch 71 in epoch 8, gen_loss = 0.9431056268513203, disc_loss = 0.044689497069662645
Trained batch 72 in epoch 8, gen_loss = 0.9525465365142038, disc_loss = 0.04472846184436181
Trained batch 73 in epoch 8, gen_loss = 0.9476410968078149, disc_loss = 0.044876893717996975
Trained batch 74 in epoch 8, gen_loss = 0.949284276564916, disc_loss = 0.044526157391568025
Trained batch 75 in epoch 8, gen_loss = 0.948866421846967, disc_loss = 0.04418787420237143
Trained batch 76 in epoch 8, gen_loss = 0.9566055625290065, disc_loss = 0.04413904139602726
Trained batch 77 in epoch 8, gen_loss = 0.9607219279576571, disc_loss = 0.04375993010277549
Trained batch 78 in epoch 8, gen_loss = 0.9589418108704724, disc_loss = 0.043486484562200084
Trained batch 79 in epoch 8, gen_loss = 0.9602826308459044, disc_loss = 0.04305376285919919
Trained batch 80 in epoch 8, gen_loss = 0.9630114233788148, disc_loss = 0.04272841649520912
Trained batch 81 in epoch 8, gen_loss = 0.9595782854935018, disc_loss = 0.04261270784432205
Trained batch 82 in epoch 8, gen_loss = 0.9584108486951116, disc_loss = 0.04245915314384613
Trained batch 83 in epoch 8, gen_loss = 0.9573371470684097, disc_loss = 0.04234967483872814
Trained batch 84 in epoch 8, gen_loss = 0.9562477690332076, disc_loss = 0.0420107737512273
Trained batch 85 in epoch 8, gen_loss = 0.959167193881301, disc_loss = 0.041617838081059066
Trained batch 86 in epoch 8, gen_loss = 0.9642622145428055, disc_loss = 0.041349562591519846
Trained batch 87 in epoch 8, gen_loss = 0.9653290459378199, disc_loss = 0.04094979780810801
Trained batch 88 in epoch 8, gen_loss = 0.9657138294718238, disc_loss = 0.04059521424887556
Trained batch 89 in epoch 8, gen_loss = 0.9660051335891088, disc_loss = 0.04021578929904435
Trained batch 90 in epoch 8, gen_loss = 0.9653902489405412, disc_loss = 0.03989666533543841
Trained batch 91 in epoch 8, gen_loss = 0.9744014574781709, disc_loss = 0.040142688707893955
Trained batch 92 in epoch 8, gen_loss = 0.980376301593678, disc_loss = 0.039982189504449726
Trained batch 93 in epoch 8, gen_loss = 0.9765137912745171, disc_loss = 0.04019468952406277
Trained batch 94 in epoch 8, gen_loss = 0.9757960510881324, disc_loss = 0.039889794450841454
Trained batch 95 in epoch 8, gen_loss = 0.9772480468576153, disc_loss = 0.03998279142736768
Trained batch 96 in epoch 8, gen_loss = 0.9795058759831891, disc_loss = 0.03964566388983548
Trained batch 97 in epoch 8, gen_loss = 0.9781985243364256, disc_loss = 0.039403844829078535
Trained batch 98 in epoch 8, gen_loss = 0.9747198738835074, disc_loss = 0.039443286846043785
Trained batch 99 in epoch 8, gen_loss = 0.9733043619990349, disc_loss = 0.039272633618675175
Trained batch 100 in epoch 8, gen_loss = 0.9749525605451943, disc_loss = 0.03967475010967343
Trained batch 101 in epoch 8, gen_loss = 0.9781505322339488, disc_loss = 0.039512527079376226
Trained batch 102 in epoch 8, gen_loss = 0.9732752138549842, disc_loss = 0.03992242564546686
Trained batch 103 in epoch 8, gen_loss = 0.974207133341294, disc_loss = 0.039791243486643695
Trained batch 104 in epoch 8, gen_loss = 0.9728405722549983, disc_loss = 0.039566345277818896
Trained batch 105 in epoch 8, gen_loss = 0.9763996553308559, disc_loss = 0.03945249650750379
Trained batch 106 in epoch 8, gen_loss = 0.9718998542455869, disc_loss = 0.03988204751529287
Trained batch 107 in epoch 8, gen_loss = 0.972476671691294, disc_loss = 0.0397623394296884
Trained batch 108 in epoch 8, gen_loss = 0.9767925099495354, disc_loss = 0.0397419983632179
Trained batch 109 in epoch 8, gen_loss = 0.975705043294213, disc_loss = 0.039527744372290646
Trained batch 110 in epoch 8, gen_loss = 0.9735625053311253, disc_loss = 0.03938710252829903
Trained batch 111 in epoch 8, gen_loss = 0.9736231123762471, disc_loss = 0.03920372877785537
Trained batch 112 in epoch 8, gen_loss = 0.971456292983705, disc_loss = 0.03907418295131188
Trained batch 113 in epoch 8, gen_loss = 0.9751735345313424, disc_loss = 0.03959133820363173
Trained batch 114 in epoch 8, gen_loss = 0.9691422713839489, disc_loss = 0.040682289437593326
Trained batch 115 in epoch 8, gen_loss = 0.9706217988297857, disc_loss = 0.04049949782723882
Trained batch 116 in epoch 8, gen_loss = 0.9739950133694543, disc_loss = 0.040619792794792824
Trained batch 117 in epoch 8, gen_loss = 0.9701390491198685, disc_loss = 0.04081289395611039
Trained batch 118 in epoch 8, gen_loss = 0.9688077030562553, disc_loss = 0.04070464200379342
Trained batch 119 in epoch 8, gen_loss = 0.9703803099691868, disc_loss = 0.04051527971945082
Trained batch 120 in epoch 8, gen_loss = 0.9708004251491925, disc_loss = 0.04023538413649994
Trained batch 121 in epoch 8, gen_loss = 0.9713057326000245, disc_loss = 0.039949141507662954
Trained batch 122 in epoch 8, gen_loss = 0.9710843037299024, disc_loss = 0.03968171553489396
Trained batch 123 in epoch 8, gen_loss = 0.970470008590529, disc_loss = 0.03943884519169167
Trained batch 124 in epoch 8, gen_loss = 0.9711347734928131, disc_loss = 0.03917510325089097
Trained batch 125 in epoch 8, gen_loss = 0.9723214868988309, disc_loss = 0.03912721621981334
Trained batch 126 in epoch 8, gen_loss = 0.9715818751046038, disc_loss = 0.03890954322130309
Trained batch 127 in epoch 8, gen_loss = 0.9718134740833193, disc_loss = 0.03868904502087389
Trained batch 128 in epoch 8, gen_loss = 0.9690715603588164, disc_loss = 0.03877782240120131
Trained batch 129 in epoch 8, gen_loss = 0.9696728424384043, disc_loss = 0.03875964649666387
Trained batch 130 in epoch 8, gen_loss = 0.9689296354319303, disc_loss = 0.038560803926315244
Trained batch 131 in epoch 8, gen_loss = 0.9662371122024276, disc_loss = 0.03858974511438811
Trained batch 132 in epoch 8, gen_loss = 0.9689318136613172, disc_loss = 0.03841597614529774
Trained batch 133 in epoch 8, gen_loss = 0.9709098069970288, disc_loss = 0.038261393470856456
Trained batch 134 in epoch 8, gen_loss = 0.9711073294833854, disc_loss = 0.038024770954830776
Trained batch 135 in epoch 8, gen_loss = 0.9704082868993282, disc_loss = 0.03787182171842741
Trained batch 136 in epoch 8, gen_loss = 0.9720021579822484, disc_loss = 0.037716442967227995
Trained batch 137 in epoch 8, gen_loss = 0.9731469584116037, disc_loss = 0.03790355823677627
Trained batch 138 in epoch 8, gen_loss = 0.9698387579523402, disc_loss = 0.038142665621000445
Trained batch 139 in epoch 8, gen_loss = 0.967403260086264, disc_loss = 0.03830271801312587
Trained batch 140 in epoch 8, gen_loss = 0.9703476097144134, disc_loss = 0.038223448391105475
Trained batch 141 in epoch 8, gen_loss = 0.9690919927728008, disc_loss = 0.03809429908787806
Trained batch 142 in epoch 8, gen_loss = 0.9668930654342358, disc_loss = 0.03810590431680317
Trained batch 143 in epoch 8, gen_loss = 0.9713680936644474, disc_loss = 0.03808783552570579
Trained batch 144 in epoch 8, gen_loss = 0.9729913836923139, disc_loss = 0.037975186934887335
Trained batch 145 in epoch 8, gen_loss = 0.9706240727068627, disc_loss = 0.038071175300426884
Trained batch 146 in epoch 8, gen_loss = 0.9713469101052706, disc_loss = 0.03811129616244006
Trained batch 147 in epoch 8, gen_loss = 0.971374885254615, disc_loss = 0.0379400939611416
Trained batch 148 in epoch 8, gen_loss = 0.9708345722432105, disc_loss = 0.03780134173810182
Trained batch 149 in epoch 8, gen_loss = 0.9694885967175165, disc_loss = 0.03780078114631275
Trained batch 150 in epoch 8, gen_loss = 0.9717638135351092, disc_loss = 0.037706731642836964
Trained batch 151 in epoch 8, gen_loss = 0.9719339748354334, disc_loss = 0.037498313127894346
Trained batch 152 in epoch 8, gen_loss = 0.9705851672132031, disc_loss = 0.037400624370872
Trained batch 153 in epoch 8, gen_loss = 0.9727340543811972, disc_loss = 0.0372338401994293
Trained batch 154 in epoch 8, gen_loss = 0.9764812840569403, disc_loss = 0.03718612736932212
Trained batch 155 in epoch 8, gen_loss = 0.9754749867014396, disc_loss = 0.03707388802491224
Trained batch 156 in epoch 8, gen_loss = 0.9748747122895186, disc_loss = 0.036912946656322596
Trained batch 157 in epoch 8, gen_loss = 0.9761765352155589, disc_loss = 0.03672312118431341
Trained batch 158 in epoch 8, gen_loss = 0.9797642540256932, disc_loss = 0.036766990864028536
Trained batch 159 in epoch 8, gen_loss = 0.9777705768123269, disc_loss = 0.0367751512065297
Trained batch 160 in epoch 8, gen_loss = 0.9754381503747858, disc_loss = 0.036850297728102215
Trained batch 161 in epoch 8, gen_loss = 0.9781401501393613, disc_loss = 0.03701274939467786
Trained batch 162 in epoch 8, gen_loss = 0.9776990342359602, disc_loss = 0.037054709618785445
Trained batch 163 in epoch 8, gen_loss = 0.9746413307219017, disc_loss = 0.037322875506971484
Trained batch 164 in epoch 8, gen_loss = 0.9740893844402198, disc_loss = 0.03723112090462537
Trained batch 165 in epoch 8, gen_loss = 0.9760412785662226, disc_loss = 0.0371896966994482
Trained batch 166 in epoch 8, gen_loss = 0.9743854771117251, disc_loss = 0.037157328339282446
Trained batch 167 in epoch 8, gen_loss = 0.9742492618305343, disc_loss = 0.03700115765899509
Trained batch 168 in epoch 8, gen_loss = 0.9742820164155678, disc_loss = 0.036832876880956295
Trained batch 169 in epoch 8, gen_loss = 0.9767009798218222, disc_loss = 0.037000102311482326
Trained batch 170 in epoch 8, gen_loss = 0.9763999724248696, disc_loss = 0.03687816525248495
Trained batch 171 in epoch 8, gen_loss = 0.9753303624862848, disc_loss = 0.0367691156394823
Trained batch 172 in epoch 8, gen_loss = 0.9728830439506928, disc_loss = 0.0369626799506819
Trained batch 173 in epoch 8, gen_loss = 0.9741606390339205, disc_loss = 0.03691657291372018
Trained batch 174 in epoch 8, gen_loss = 0.9735098082678658, disc_loss = 0.036900966776801006
Trained batch 175 in epoch 8, gen_loss = 0.9723984910683199, disc_loss = 0.03682691234809516
Trained batch 176 in epoch 8, gen_loss = 0.9713728980155988, disc_loss = 0.03677536948389337
Trained batch 177 in epoch 8, gen_loss = 0.9726967141869363, disc_loss = 0.037020374395560184
Trained batch 178 in epoch 8, gen_loss = 0.9691369500240135, disc_loss = 0.037579094161222265
Trained batch 179 in epoch 8, gen_loss = 0.9705344127284156, disc_loss = 0.037639882324987814
Trained batch 180 in epoch 8, gen_loss = 0.971784234046936, disc_loss = 0.037490750320811464
Trained batch 181 in epoch 8, gen_loss = 0.969501983988416, disc_loss = 0.037593193825559465
Trained batch 182 in epoch 8, gen_loss = 0.969414783957226, disc_loss = 0.03781670871664022
Trained batch 183 in epoch 8, gen_loss = 0.9674596831850384, disc_loss = 0.037859061897388135
Trained batch 184 in epoch 8, gen_loss = 0.9702428128268268, disc_loss = 0.0378113171362595
Trained batch 185 in epoch 8, gen_loss = 0.9703947565247936, disc_loss = 0.03764913587390335
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8698218464851379, disc_loss = 0.01550688873976469
Trained batch 1 in epoch 9, gen_loss = 0.783982515335083, disc_loss = 0.02156881196424365
Trained batch 2 in epoch 9, gen_loss = 0.8802827199300131, disc_loss = 0.022183170231680076
Trained batch 3 in epoch 9, gen_loss = 0.929975688457489, disc_loss = 0.02353735943324864
Trained batch 4 in epoch 9, gen_loss = 0.8459383010864258, disc_loss = 0.032073825038969515
Trained batch 5 in epoch 9, gen_loss = 0.8185682992140452, disc_loss = 0.032284964652111135
Trained batch 6 in epoch 9, gen_loss = 0.9458828909056527, disc_loss = 0.05928481862481151
Trained batch 7 in epoch 9, gen_loss = 0.8753314577043056, disc_loss = 0.06665969791356474
Trained batch 8 in epoch 9, gen_loss = 0.8579242726167043, disc_loss = 0.06355828595244223
Trained batch 9 in epoch 9, gen_loss = 0.8839144676923751, disc_loss = 0.07067766832187772
Trained batch 10 in epoch 9, gen_loss = 0.8577619438821619, disc_loss = 0.0696275590664961
Trained batch 11 in epoch 9, gen_loss = 0.8499934449791908, disc_loss = 0.0670281332762291
Trained batch 12 in epoch 9, gen_loss = 0.8561540360634143, disc_loss = 0.06568778829219249
Trained batch 13 in epoch 9, gen_loss = 0.8559309563466481, disc_loss = 0.06283072136076433
Trained batch 14 in epoch 9, gen_loss = 0.8347737729549408, disc_loss = 0.06372291514029106
Trained batch 15 in epoch 9, gen_loss = 0.8660088870674372, disc_loss = 0.06742451264290139
Trained batch 16 in epoch 9, gen_loss = 0.8429998702862683, disc_loss = 0.07172531519523438
Trained batch 17 in epoch 9, gen_loss = 0.8426773498455683, disc_loss = 0.07257352991857463
Trained batch 18 in epoch 9, gen_loss = 0.8343721455649326, disc_loss = 0.07111256819610533
Trained batch 19 in epoch 9, gen_loss = 0.8649407640099526, disc_loss = 0.07450251928530634
Trained batch 20 in epoch 9, gen_loss = 0.8515850319748833, disc_loss = 0.07513709486063037
Trained batch 21 in epoch 9, gen_loss = 0.8476691828532652, disc_loss = 0.07361313002184033
Trained batch 22 in epoch 9, gen_loss = 0.8467641226623369, disc_loss = 0.07332495158619207
Trained batch 23 in epoch 9, gen_loss = 0.8496171794831753, disc_loss = 0.07168016051097463
Trained batch 24 in epoch 9, gen_loss = 0.8609553921222687, disc_loss = 0.06992752086371183
Trained batch 25 in epoch 9, gen_loss = 0.8594423337624624, disc_loss = 0.06818934304353136
Trained batch 26 in epoch 9, gen_loss = 0.865945064359241, disc_loss = 0.0675663281990974
Trained batch 27 in epoch 9, gen_loss = 0.8554226042968887, disc_loss = 0.06706754241271742
Trained batch 28 in epoch 9, gen_loss = 0.8605598016031857, disc_loss = 0.0649923757360927
Trained batch 29 in epoch 9, gen_loss = 0.8791825781265895, disc_loss = 0.06422097068279982
Trained batch 30 in epoch 9, gen_loss = 0.8875902439317396, disc_loss = 0.062401636984319456
Trained batch 31 in epoch 9, gen_loss = 0.8778232159093022, disc_loss = 0.06220024186768569
Trained batch 32 in epoch 9, gen_loss = 0.8835702348839153, disc_loss = 0.06054019355074023
Trained batch 33 in epoch 9, gen_loss = 0.8831843672429814, disc_loss = 0.05944134905824766
Trained batch 34 in epoch 9, gen_loss = 0.8855725228786469, disc_loss = 0.05795107485194292
Trained batch 35 in epoch 9, gen_loss = 0.8804499399330881, disc_loss = 0.057622799041887954
Trained batch 36 in epoch 9, gen_loss = 0.8917300048712138, disc_loss = 0.056532385696128416
Trained batch 37 in epoch 9, gen_loss = 0.898899425801478, disc_loss = 0.05533589894491199
Trained batch 38 in epoch 9, gen_loss = 0.891832438034889, disc_loss = 0.05494498128357988
Trained batch 39 in epoch 9, gen_loss = 0.8937947385013103, disc_loss = 0.05397344111697748
Trained batch 40 in epoch 9, gen_loss = 0.9015276570145677, disc_loss = 0.05409692092685074
Trained batch 41 in epoch 9, gen_loss = 0.8915604835464841, disc_loss = 0.05466924795126986
Trained batch 42 in epoch 9, gen_loss = 0.8961910619292148, disc_loss = 0.054638980530462296
Trained batch 43 in epoch 9, gen_loss = 0.902188777923584, disc_loss = 0.054070001732642675
Trained batch 44 in epoch 9, gen_loss = 0.9044875277413262, disc_loss = 0.05372602833021018
Trained batch 45 in epoch 9, gen_loss = 0.9017367233400759, disc_loss = 0.05301603121156602
Trained batch 46 in epoch 9, gen_loss = 0.9079744029552379, disc_loss = 0.052321575790088864
Trained batch 47 in epoch 9, gen_loss = 0.9023854496578375, disc_loss = 0.052179986581904814
Trained batch 48 in epoch 9, gen_loss = 0.9116707906431082, disc_loss = 0.051533712919953525
Trained batch 49 in epoch 9, gen_loss = 0.9126356661319732, disc_loss = 0.050982277216389774
Trained batch 50 in epoch 9, gen_loss = 0.9175288408410316, disc_loss = 0.050135569710868834
Trained batch 51 in epoch 9, gen_loss = 0.9191365734888957, disc_loss = 0.04930040190139642
Trained batch 52 in epoch 9, gen_loss = 0.9192693627105569, disc_loss = 0.04865164443288209
Trained batch 53 in epoch 9, gen_loss = 0.9245905843045976, disc_loss = 0.04811855019242675
Trained batch 54 in epoch 9, gen_loss = 0.9251071745699102, disc_loss = 0.047388671033761716
Trained batch 55 in epoch 9, gen_loss = 0.9331075900367328, disc_loss = 0.046827239716159444
Trained batch 56 in epoch 9, gen_loss = 0.9291896935094867, disc_loss = 0.046540038758202604
Trained batch 57 in epoch 9, gen_loss = 0.9338405759170137, disc_loss = 0.046187592317061175
Trained batch 58 in epoch 9, gen_loss = 0.9390255424935939, disc_loss = 0.04554602821057631
Trained batch 59 in epoch 9, gen_loss = 0.9358070095380148, disc_loss = 0.045197356942420205
Trained batch 60 in epoch 9, gen_loss = 0.9363315916452252, disc_loss = 0.04470702647002506
Trained batch 61 in epoch 9, gen_loss = 0.942149672777422, disc_loss = 0.0441628263572291
Trained batch 62 in epoch 9, gen_loss = 0.949286819450439, disc_loss = 0.04502629386704592
Trained batch 63 in epoch 9, gen_loss = 0.9392726300284266, disc_loss = 0.046697385419975035
Trained batch 64 in epoch 9, gen_loss = 0.9347889414200417, disc_loss = 0.047126742438055
Trained batch 65 in epoch 9, gen_loss = 0.9341481725374857, disc_loss = 0.0474041319226451
Trained batch 66 in epoch 9, gen_loss = 0.9322419887158409, disc_loss = 0.04703218305010849
Trained batch 67 in epoch 9, gen_loss = 0.9341368736589656, disc_loss = 0.046429729321971536
Trained batch 68 in epoch 9, gen_loss = 0.9293497645336649, disc_loss = 0.04670774560097767
Trained batch 69 in epoch 9, gen_loss = 0.9315076674733843, disc_loss = 0.04615925487929157
Trained batch 70 in epoch 9, gen_loss = 0.9319030130413216, disc_loss = 0.045621594427232175
Trained batch 71 in epoch 9, gen_loss = 0.9321493539545271, disc_loss = 0.04519325296860188
Trained batch 72 in epoch 9, gen_loss = 0.93767531603983, disc_loss = 0.045581621245468315
Trained batch 73 in epoch 9, gen_loss = 0.9345011517808244, disc_loss = 0.045394310463421246
Trained batch 74 in epoch 9, gen_loss = 0.9330554819107055, disc_loss = 0.04528357703238726
Trained batch 75 in epoch 9, gen_loss = 0.9342495469670546, disc_loss = 0.04488793187039463
Trained batch 76 in epoch 9, gen_loss = 0.9301232138237396, disc_loss = 0.04510106688196009
Trained batch 77 in epoch 9, gen_loss = 0.9329210512149029, disc_loss = 0.045420959496345274
Trained batch 78 in epoch 9, gen_loss = 0.9296083752113052, disc_loss = 0.04531339857774445
Trained batch 79 in epoch 9, gen_loss = 0.935682438313961, disc_loss = 0.04497631243430078
Trained batch 80 in epoch 9, gen_loss = 0.9326778650283813, disc_loss = 0.04479057029073621
Trained batch 81 in epoch 9, gen_loss = 0.9371660293602362, disc_loss = 0.04544587206186318
Trained batch 82 in epoch 9, gen_loss = 0.9344989061355591, disc_loss = 0.04527449580919312
Trained batch 83 in epoch 9, gen_loss = 0.9298435258013862, disc_loss = 0.045491217591223265
Trained batch 84 in epoch 9, gen_loss = 0.9285874275600209, disc_loss = 0.045799055344918196
Trained batch 85 in epoch 9, gen_loss = 0.9303920414558676, disc_loss = 0.04541267965768659
Trained batch 86 in epoch 9, gen_loss = 0.9266484503088326, disc_loss = 0.045589911483827676
Trained batch 87 in epoch 9, gen_loss = 0.9258539439602331, disc_loss = 0.04536922151138159
Trained batch 88 in epoch 9, gen_loss = 0.9282653967985947, disc_loss = 0.04498291691618689
Trained batch 89 in epoch 9, gen_loss = 0.9277139670319028, disc_loss = 0.04490392996619145
Trained batch 90 in epoch 9, gen_loss = 0.9261436757150587, disc_loss = 0.0449989247494019
Trained batch 91 in epoch 9, gen_loss = 0.9314080884923106, disc_loss = 0.044724385456546494
Trained batch 92 in epoch 9, gen_loss = 0.9281089921151439, disc_loss = 0.044728655408146564
Trained batch 93 in epoch 9, gen_loss = 0.9292443978025559, disc_loss = 0.04474497320962713
Trained batch 94 in epoch 9, gen_loss = 0.9288476027940449, disc_loss = 0.04447567704084673
Trained batch 95 in epoch 9, gen_loss = 0.9313567119340102, disc_loss = 0.04408275927805031
Trained batch 96 in epoch 9, gen_loss = 0.9329430147544625, disc_loss = 0.04376931791913878
Trained batch 97 in epoch 9, gen_loss = 0.9295101092786205, disc_loss = 0.04380925204984996
Trained batch 98 in epoch 9, gen_loss = 0.9317155871728454, disc_loss = 0.043624104348698046
Trained batch 99 in epoch 9, gen_loss = 0.9327740979194641, disc_loss = 0.04329974230378866
Trained batch 100 in epoch 9, gen_loss = 0.9314445581766638, disc_loss = 0.04306734906564845
Trained batch 101 in epoch 9, gen_loss = 0.9330522903040344, disc_loss = 0.04271512230693856
Trained batch 102 in epoch 9, gen_loss = 0.932668640775588, disc_loss = 0.04243278896291424
Trained batch 103 in epoch 9, gen_loss = 0.9351049581399331, disc_loss = 0.042149201863839365
Trained batch 104 in epoch 9, gen_loss = 0.9361226070494879, disc_loss = 0.0418101812890243
Trained batch 105 in epoch 9, gen_loss = 0.9362443781123971, disc_loss = 0.0415059964585487
Trained batch 106 in epoch 9, gen_loss = 0.9370995787816627, disc_loss = 0.04117562843782601
Trained batch 107 in epoch 9, gen_loss = 0.9385106513897578, disc_loss = 0.04091802297194523
Trained batch 108 in epoch 9, gen_loss = 0.9409144958224865, disc_loss = 0.04061418061717114
Trained batch 109 in epoch 9, gen_loss = 0.9400439712134274, disc_loss = 0.04037425198846243
Trained batch 110 in epoch 9, gen_loss = 0.9403665941040795, disc_loss = 0.04008409552913797
Trained batch 111 in epoch 9, gen_loss = 0.9471589779215199, disc_loss = 0.04017577277928857
Trained batch 112 in epoch 9, gen_loss = 0.9466195723651785, disc_loss = 0.039947903418369526
Trained batch 113 in epoch 9, gen_loss = 0.9464302355783027, disc_loss = 0.04010463024800023
Trained batch 114 in epoch 9, gen_loss = 0.9483705344407455, disc_loss = 0.03983391469101543
Trained batch 115 in epoch 9, gen_loss = 0.9479784703460233, disc_loss = 0.039630731158279656
Trained batch 116 in epoch 9, gen_loss = 0.9481815425758688, disc_loss = 0.03957725670507066
Trained batch 117 in epoch 9, gen_loss = 0.9472923410140862, disc_loss = 0.039362718903664815
Trained batch 118 in epoch 9, gen_loss = 0.948743610822854, disc_loss = 0.03913837214227484
Trained batch 119 in epoch 9, gen_loss = 0.9510091920693715, disc_loss = 0.038929005494962136
Trained batch 120 in epoch 9, gen_loss = 0.9506580066089788, disc_loss = 0.038872622538450335
Trained batch 121 in epoch 9, gen_loss = 0.9512936927256037, disc_loss = 0.03862364225272761
Trained batch 122 in epoch 9, gen_loss = 0.9537036375301641, disc_loss = 0.03841498474461761
Trained batch 123 in epoch 9, gen_loss = 0.9541603956491717, disc_loss = 0.0381686478823183
Trained batch 124 in epoch 9, gen_loss = 0.9552795586585998, disc_loss = 0.037911905895918606
Trained batch 125 in epoch 9, gen_loss = 0.9548115176813943, disc_loss = 0.03776426179822357
Trained batch 126 in epoch 9, gen_loss = 0.953458059960463, disc_loss = 0.03764164258219947
Trained batch 127 in epoch 9, gen_loss = 0.9551826012320817, disc_loss = 0.03753626998150139
Trained batch 128 in epoch 9, gen_loss = 0.9547860257385313, disc_loss = 0.03739241657547595
Trained batch 129 in epoch 9, gen_loss = 0.9562310223396008, disc_loss = 0.03718128668215986
Trained batch 130 in epoch 9, gen_loss = 0.9572452465996487, disc_loss = 0.03707683337710172
Trained batch 131 in epoch 9, gen_loss = 0.957737306302244, disc_loss = 0.03696448805699633
Trained batch 132 in epoch 9, gen_loss = 0.961657462711621, disc_loss = 0.03691442461712356
Trained batch 133 in epoch 9, gen_loss = 0.9632454243168902, disc_loss = 0.036757323943050715
Trained batch 134 in epoch 9, gen_loss = 0.9639469848738776, disc_loss = 0.036542645672819125
Trained batch 135 in epoch 9, gen_loss = 0.964427728425054, disc_loss = 0.03633107402471497
Trained batch 136 in epoch 9, gen_loss = 0.9651500669709088, disc_loss = 0.03627903072884048
Trained batch 137 in epoch 9, gen_loss = 0.9639725672162097, disc_loss = 0.03616204330076774
Trained batch 138 in epoch 9, gen_loss = 0.9637108668148946, disc_loss = 0.035972701017108324
Trained batch 139 in epoch 9, gen_loss = 0.9643002488783428, disc_loss = 0.035774801232452906
Trained batch 140 in epoch 9, gen_loss = 0.9657878803868666, disc_loss = 0.03559989055473331
Trained batch 141 in epoch 9, gen_loss = 0.964973399336909, disc_loss = 0.03546220064163208
Trained batch 142 in epoch 9, gen_loss = 0.9659858908686605, disc_loss = 0.035414073746521155
Trained batch 143 in epoch 9, gen_loss = 0.9644044062329663, disc_loss = 0.03538771364320484
Trained batch 144 in epoch 9, gen_loss = 0.9667362135032128, disc_loss = 0.03549149293324043
Trained batch 145 in epoch 9, gen_loss = 0.9677375795906538, disc_loss = 0.03593782789699019
Trained batch 146 in epoch 9, gen_loss = 0.9699877439712992, disc_loss = 0.03616053687066448
Trained batch 147 in epoch 9, gen_loss = 0.9704570725962922, disc_loss = 0.03604510449175093
Trained batch 148 in epoch 9, gen_loss = 0.9709970107014547, disc_loss = 0.03590513362030455
Trained batch 149 in epoch 9, gen_loss = 0.9710546020666758, disc_loss = 0.035774057805538176
Trained batch 150 in epoch 9, gen_loss = 0.9724534288147427, disc_loss = 0.036187652769862425
Trained batch 151 in epoch 9, gen_loss = 0.9681683614065772, disc_loss = 0.03705329913645983
Trained batch 152 in epoch 9, gen_loss = 0.9678060969496085, disc_loss = 0.037230926109295265
Trained batch 153 in epoch 9, gen_loss = 0.9688308246724018, disc_loss = 0.03744356464836505
Trained batch 154 in epoch 9, gen_loss = 0.9672729380669133, disc_loss = 0.03742565870765717
Trained batch 155 in epoch 9, gen_loss = 0.9689224679500629, disc_loss = 0.03735844812427576
Trained batch 156 in epoch 9, gen_loss = 0.9713511637821319, disc_loss = 0.03721483203635854
Trained batch 157 in epoch 9, gen_loss = 0.9686325845084612, disc_loss = 0.037388371374410916
Trained batch 158 in epoch 9, gen_loss = 0.9711427954757739, disc_loss = 0.03733723047160128
Trained batch 159 in epoch 9, gen_loss = 0.9697630278766155, disc_loss = 0.037303747737314555
Trained batch 160 in epoch 9, gen_loss = 0.9697421293080963, disc_loss = 0.037153845415768785
Trained batch 161 in epoch 9, gen_loss = 0.9711688138820507, disc_loss = 0.03711842304601529
Trained batch 162 in epoch 9, gen_loss = 0.9696267426379619, disc_loss = 0.03710661879369269
Trained batch 163 in epoch 9, gen_loss = 0.9686159313451953, disc_loss = 0.036992534455593404
Trained batch 164 in epoch 9, gen_loss = 0.9725024234164845, disc_loss = 0.037247172951924076
Trained batch 165 in epoch 9, gen_loss = 0.9686710717807333, disc_loss = 0.03777319408885865
Trained batch 166 in epoch 9, gen_loss = 0.9699560209305701, disc_loss = 0.037644203936313084
Trained batch 167 in epoch 9, gen_loss = 0.9702422993168944, disc_loss = 0.03751853840713877
Trained batch 168 in epoch 9, gen_loss = 0.9690487809787841, disc_loss = 0.03741251052902824
Trained batch 169 in epoch 9, gen_loss = 0.9697517677265055, disc_loss = 0.03727569364778259
Trained batch 170 in epoch 9, gen_loss = 0.9673894457301201, disc_loss = 0.03739039050360695
Trained batch 171 in epoch 9, gen_loss = 0.9701919827696889, disc_loss = 0.037359933060225704
Trained batch 172 in epoch 9, gen_loss = 0.9702789357976417, disc_loss = 0.037190555158808744
Trained batch 173 in epoch 9, gen_loss = 0.9696464156624914, disc_loss = 0.037158023362615325
Trained batch 174 in epoch 9, gen_loss = 0.9690139400959015, disc_loss = 0.037320497046623914
Trained batch 175 in epoch 9, gen_loss = 0.9672053962607275, disc_loss = 0.03739517631898211
Trained batch 176 in epoch 9, gen_loss = 0.9677933217105219, disc_loss = 0.03726154268524573
Trained batch 177 in epoch 9, gen_loss = 0.9684225861610991, disc_loss = 0.03731354974273048
Trained batch 178 in epoch 9, gen_loss = 0.9670994846181497, disc_loss = 0.03727435690543338
Trained batch 179 in epoch 9, gen_loss = 0.9655482422974374, disc_loss = 0.037245411172302234
Trained batch 180 in epoch 9, gen_loss = 0.968625096820336, disc_loss = 0.03768906449559479
Trained batch 181 in epoch 9, gen_loss = 0.9652825598860835, disc_loss = 0.03818947829531281
Trained batch 182 in epoch 9, gen_loss = 0.963030175595987, disc_loss = 0.03843776498478456
Trained batch 183 in epoch 9, gen_loss = 0.9624914097721162, disc_loss = 0.03860342587121641
Trained batch 184 in epoch 9, gen_loss = 0.9614356032899908, disc_loss = 0.03854837380853054
Trained batch 185 in epoch 9, gen_loss = 0.9585376905818139, disc_loss = 0.03898205695753937
Testing Epoch 9
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0877645015716553, disc_loss = 0.6893612146377563
Trained batch 1 in epoch 0, gen_loss = 0.9298561215400696, disc_loss = 0.6001641750335693
Trained batch 2 in epoch 0, gen_loss = 0.8718907833099365, disc_loss = 0.5703530311584473
Trained batch 3 in epoch 0, gen_loss = 0.851946085691452, disc_loss = 0.5427056178450584
Trained batch 4 in epoch 0, gen_loss = 0.8737180948257446, disc_loss = 0.5415440261363983
Trained batch 5 in epoch 0, gen_loss = 0.8660478194554647, disc_loss = 0.524766688545545
Trained batch 6 in epoch 0, gen_loss = 0.8844243628638131, disc_loss = 0.4922217684132712
Trained batch 7 in epoch 0, gen_loss = 0.8809584528207779, disc_loss = 0.4636303037405014
Trained batch 8 in epoch 0, gen_loss = 0.873108426729838, disc_loss = 0.4353049827946557
Trained batch 9 in epoch 0, gen_loss = 0.8653917193412781, disc_loss = 0.4129475325345993
Trained batch 10 in epoch 0, gen_loss = 0.8619558269327338, disc_loss = 0.3915420310063796
Trained batch 11 in epoch 0, gen_loss = 0.8513335833946863, disc_loss = 0.3731351097424825
Trained batch 12 in epoch 0, gen_loss = 0.8513908798878009, disc_loss = 0.3563739130130181
Trained batch 13 in epoch 0, gen_loss = 0.8659762867859432, disc_loss = 0.3432078819189753
Trained batch 14 in epoch 0, gen_loss = 0.8684512138366699, disc_loss = 0.32877915501594546
Trained batch 15 in epoch 0, gen_loss = 0.8796701580286026, disc_loss = 0.3195117451250553
Trained batch 16 in epoch 0, gen_loss = 0.883140388657065, disc_loss = 0.3085337439004113
Trained batch 17 in epoch 0, gen_loss = 0.8956362870004442, disc_loss = 0.29761292040348053
Trained batch 18 in epoch 0, gen_loss = 0.9082187727877968, disc_loss = 0.2889101544493123
Trained batch 19 in epoch 0, gen_loss = 0.9292234420776367, disc_loss = 0.28328479155898095
Trained batch 20 in epoch 0, gen_loss = 0.9402290298825219, disc_loss = 0.27310260988417123
Trained batch 21 in epoch 0, gen_loss = 0.9475510770624335, disc_loss = 0.2637546970085664
Trained batch 22 in epoch 0, gen_loss = 0.9564576148986816, disc_loss = 0.2550346404314041
Trained batch 23 in epoch 0, gen_loss = 0.9649699131647745, disc_loss = 0.24743203073740005
Trained batch 24 in epoch 0, gen_loss = 0.9739432811737061, disc_loss = 0.24015644699335098
Trained batch 25 in epoch 0, gen_loss = 0.9838968469546392, disc_loss = 0.23318065330386162
Trained batch 26 in epoch 0, gen_loss = 0.9926131080698084, disc_loss = 0.22661322134512443
Trained batch 27 in epoch 0, gen_loss = 1.0009174985545022, disc_loss = 0.22034751291253737
Trained batch 28 in epoch 0, gen_loss = 1.0079938461040627, disc_loss = 0.2144444460241959
Trained batch 29 in epoch 0, gen_loss = 1.0131254514058432, disc_loss = 0.2086189986517032
Trained batch 30 in epoch 0, gen_loss = 1.0184811930502615, disc_loss = 0.20329745630583457
Trained batch 31 in epoch 0, gen_loss = 1.0236958228051662, disc_loss = 0.1979905740590766
Trained batch 32 in epoch 0, gen_loss = 1.025121721354398, disc_loss = 0.1929897518094742
Trained batch 33 in epoch 0, gen_loss = 1.0314364082673018, disc_loss = 0.18896827430409543
Trained batch 34 in epoch 0, gen_loss = 1.0321776390075683, disc_loss = 0.18480791534696306
Trained batch 35 in epoch 0, gen_loss = 1.0396109422047932, disc_loss = 0.18135569555064043
Trained batch 36 in epoch 0, gen_loss = 1.0440701342917778, disc_loss = 0.17921051483702016
Trained batch 37 in epoch 0, gen_loss = 1.0452124131353278, disc_loss = 0.17643772653843226
Trained batch 38 in epoch 0, gen_loss = 1.0469073882469764, disc_loss = 0.17289215221236914
Trained batch 39 in epoch 0, gen_loss = 1.0480421870946883, disc_loss = 0.17000304711982608
Trained batch 40 in epoch 0, gen_loss = 1.0565076543063652, disc_loss = 0.168420237284608
Trained batch 41 in epoch 0, gen_loss = 1.0588729750542414, disc_loss = 0.1657129894232466
Trained batch 42 in epoch 0, gen_loss = 1.0588638505270316, disc_loss = 0.16270521482409434
Trained batch 43 in epoch 0, gen_loss = 1.0610587678172372, disc_loss = 0.15991834220899778
Trained batch 44 in epoch 0, gen_loss = 1.0610263639026218, disc_loss = 0.15717736697859233
Trained batch 45 in epoch 0, gen_loss = 1.0600838557533596, disc_loss = 0.1543363033105498
Trained batch 46 in epoch 0, gen_loss = 1.0621048567142892, disc_loss = 0.1516673114705593
Trained batch 47 in epoch 0, gen_loss = 1.0635686367750168, disc_loss = 0.14898943551816046
Trained batch 48 in epoch 0, gen_loss = 1.0670623049444081, disc_loss = 0.14650028894598388
Trained batch 49 in epoch 0, gen_loss = 1.0700023794174194, disc_loss = 0.14445275481790304
Trained batch 50 in epoch 0, gen_loss = 1.075313371770522, disc_loss = 0.14244497782897717
Trained batch 51 in epoch 0, gen_loss = 1.081521932895367, disc_loss = 0.1403326063703459
Trained batch 52 in epoch 0, gen_loss = 1.0801550982133397, disc_loss = 0.13813374680027646
Trained batch 53 in epoch 0, gen_loss = 1.0802392451851457, disc_loss = 0.13611669790137698
Trained batch 54 in epoch 0, gen_loss = 1.07965820052407, disc_loss = 0.1341684390875426
Trained batch 55 in epoch 0, gen_loss = 1.0798094549349375, disc_loss = 0.13222108162673457
Trained batch 56 in epoch 0, gen_loss = 1.0813202397865163, disc_loss = 0.13037191769271567
Trained batch 57 in epoch 0, gen_loss = 1.082323144222128, disc_loss = 0.12854588169861456
Trained batch 58 in epoch 0, gen_loss = 1.0822152060977484, disc_loss = 0.126741598060323
Trained batch 59 in epoch 0, gen_loss = 1.081587584813436, disc_loss = 0.12494672434404493
Trained batch 60 in epoch 0, gen_loss = 1.0834415095751402, disc_loss = 0.1232848124364849
Trained batch 61 in epoch 0, gen_loss = 1.0844645288682753, disc_loss = 0.12159018476884212
Trained batch 62 in epoch 0, gen_loss = 1.0849966491971696, disc_loss = 0.11993674496336588
Trained batch 63 in epoch 0, gen_loss = 1.0876546930521727, disc_loss = 0.11841991663095541
Trained batch 64 in epoch 0, gen_loss = 1.090156256235563, disc_loss = 0.11695096535751452
Trained batch 65 in epoch 0, gen_loss = 1.0888718167940776, disc_loss = 0.11543970360335978
Trained batch 66 in epoch 0, gen_loss = 1.0881039598094884, disc_loss = 0.11398671303333631
Trained batch 67 in epoch 0, gen_loss = 1.0883015306556927, disc_loss = 0.11254166376174372
Trained batch 68 in epoch 0, gen_loss = 1.0879189950832422, disc_loss = 0.11111476488303447
Trained batch 69 in epoch 0, gen_loss = 1.0877985903194973, disc_loss = 0.10974848458011235
Trained batch 70 in epoch 0, gen_loss = 1.0883620137899694, disc_loss = 0.10847570995052516
Trained batch 71 in epoch 0, gen_loss = 1.0874534199635189, disc_loss = 0.10724012311806695
Trained batch 72 in epoch 0, gen_loss = 1.0869749131268018, disc_loss = 0.10605103398788057
Trained batch 73 in epoch 0, gen_loss = 1.0889390159297634, disc_loss = 0.10490767047362956
Trained batch 74 in epoch 0, gen_loss = 1.0884215418497722, disc_loss = 0.10372895453125239
Trained batch 75 in epoch 0, gen_loss = 1.0893536586510508, disc_loss = 0.10261929715297331
Trained batch 76 in epoch 0, gen_loss = 1.091125200321148, disc_loss = 0.1015114981753679
Trained batch 77 in epoch 0, gen_loss = 1.092578955185719, disc_loss = 0.10043553985320987
Trained batch 78 in epoch 0, gen_loss = 1.0921067014525208, disc_loss = 0.09940898813354442
Trained batch 79 in epoch 0, gen_loss = 1.0915867567062378, disc_loss = 0.09834997188299895
Trained batch 80 in epoch 0, gen_loss = 1.0907695470032868, disc_loss = 0.09729812236755718
Trained batch 81 in epoch 0, gen_loss = 1.0907991165068092, disc_loss = 0.09627620707743051
Trained batch 82 in epoch 0, gen_loss = 1.091509248836931, disc_loss = 0.0953116909297834
Trained batch 83 in epoch 0, gen_loss = 1.0917547103904544, disc_loss = 0.09431435156702286
Trained batch 84 in epoch 0, gen_loss = 1.0931399121003993, disc_loss = 0.09338151830084183
Trained batch 85 in epoch 0, gen_loss = 1.0931493861730708, disc_loss = 0.0924579156562686
Trained batch 86 in epoch 0, gen_loss = 1.0947046690973743, disc_loss = 0.09155912500345843
Trained batch 87 in epoch 0, gen_loss = 1.0952118120410226, disc_loss = 0.09067867372438988
Trained batch 88 in epoch 0, gen_loss = 1.0940181914340243, disc_loss = 0.0897935229468714
Trained batch 89 in epoch 0, gen_loss = 1.0930277440283034, disc_loss = 0.0889500705525279
Trained batch 90 in epoch 0, gen_loss = 1.0943804350528088, disc_loss = 0.08811909221317414
Trained batch 91 in epoch 0, gen_loss = 1.0950691764769347, disc_loss = 0.08732002503846002
Trained batch 92 in epoch 0, gen_loss = 1.0950169242838377, disc_loss = 0.08653179148552559
Trained batch 93 in epoch 0, gen_loss = 1.0942653163950493, disc_loss = 0.08576523246085073
Trained batch 94 in epoch 0, gen_loss = 1.0944557001716213, disc_loss = 0.08506724880518098
Trained batch 95 in epoch 0, gen_loss = 1.0945106086631615, disc_loss = 0.08434732940319616
Trained batch 96 in epoch 0, gen_loss = 1.0934305375384301, disc_loss = 0.08360995210169517
Trained batch 97 in epoch 0, gen_loss = 1.0940300299196828, disc_loss = 0.08290223714572434
Trained batch 98 in epoch 0, gen_loss = 1.0945587615774135, disc_loss = 0.08222545726657515
Trained batch 99 in epoch 0, gen_loss = 1.0943839001655578, disc_loss = 0.08151667212136089
Trained batch 100 in epoch 0, gen_loss = 1.0943591098974246, disc_loss = 0.08081032859511894
Trained batch 101 in epoch 0, gen_loss = 1.0948619129610997, disc_loss = 0.08013407752721333
Trained batch 102 in epoch 0, gen_loss = 1.09557991930582, disc_loss = 0.07945090657986194
Trained batch 103 in epoch 0, gen_loss = 1.0949561653228908, disc_loss = 0.07877772628293875
Trained batch 104 in epoch 0, gen_loss = 1.094988247326442, disc_loss = 0.0781239567058427
Trained batch 105 in epoch 0, gen_loss = 1.094903049603948, disc_loss = 0.07747758898602904
Trained batch 106 in epoch 0, gen_loss = 1.0951149073716635, disc_loss = 0.0768747516150508
Trained batch 107 in epoch 0, gen_loss = 1.095572887747376, disc_loss = 0.07628047912967978
Trained batch 108 in epoch 0, gen_loss = 1.0958259707197138, disc_loss = 0.07572899059896622
Trained batch 109 in epoch 0, gen_loss = 1.0953516819260336, disc_loss = 0.07518416428091851
Trained batch 110 in epoch 0, gen_loss = 1.094965561016186, disc_loss = 0.07462689775537264
Trained batch 111 in epoch 0, gen_loss = 1.095018251666001, disc_loss = 0.07405438012210652
Trained batch 112 in epoch 0, gen_loss = 1.0949775170435947, disc_loss = 0.07347934822494213
Trained batch 113 in epoch 0, gen_loss = 1.0952609244145846, disc_loss = 0.07291892024672084
Trained batch 114 in epoch 0, gen_loss = 1.095323797930842, disc_loss = 0.07239382704314978
Trained batch 115 in epoch 0, gen_loss = 1.0953205155915227, disc_loss = 0.07188058443817086
Trained batch 116 in epoch 0, gen_loss = 1.0953183917917757, disc_loss = 0.0713336373018658
Trained batch 117 in epoch 0, gen_loss = 1.0949596217123128, disc_loss = 0.07079560862128008
Trained batch 118 in epoch 0, gen_loss = 1.0945531169907385, disc_loss = 0.0702847149379614
Trained batch 119 in epoch 0, gen_loss = 1.0953425159056982, disc_loss = 0.06978566478937864
Trained batch 120 in epoch 0, gen_loss = 1.094965426389836, disc_loss = 0.06929542590702369
Trained batch 121 in epoch 0, gen_loss = 1.0953975466431165, disc_loss = 0.06883566356340393
Trained batch 122 in epoch 0, gen_loss = 1.0960644473874472, disc_loss = 0.06838437981479537
Trained batch 123 in epoch 0, gen_loss = 1.0960573131038296, disc_loss = 0.06791397024907413
Trained batch 124 in epoch 0, gen_loss = 1.0961225185394288, disc_loss = 0.0674401867762208
Trained batch 125 in epoch 0, gen_loss = 1.0962606346796429, disc_loss = 0.06696383867205845
Trained batch 126 in epoch 0, gen_loss = 1.0964462672631572, disc_loss = 0.06650822488664407
Trained batch 127 in epoch 0, gen_loss = 1.0964736761525273, disc_loss = 0.06604428443461074
Trained batch 128 in epoch 0, gen_loss = 1.0961636267891226, disc_loss = 0.06558843648292181
Trained batch 129 in epoch 0, gen_loss = 1.096338012585273, disc_loss = 0.06513954154932156
Trained batch 130 in epoch 0, gen_loss = 1.0978136162721475, disc_loss = 0.06472545792881883
Trained batch 131 in epoch 0, gen_loss = 1.097703951777834, disc_loss = 0.06429848760352329
Trained batch 132 in epoch 0, gen_loss = 1.0972163551732113, disc_loss = 0.0638897598062859
Trained batch 133 in epoch 0, gen_loss = 1.0972072757891755, disc_loss = 0.06348472355114324
Trained batch 134 in epoch 0, gen_loss = 1.0976079720037955, disc_loss = 0.06309102076554188
Trained batch 135 in epoch 0, gen_loss = 1.0975121128208496, disc_loss = 0.06269877641941146
Trained batch 136 in epoch 0, gen_loss = 1.0968485365818887, disc_loss = 0.062307416777513974
Trained batch 137 in epoch 0, gen_loss = 1.0969053809193596, disc_loss = 0.06192775311258932
Trained batch 138 in epoch 0, gen_loss = 1.0979945548146748, disc_loss = 0.06154993037431896
Trained batch 139 in epoch 0, gen_loss = 1.0981317213603428, disc_loss = 0.06116305686799543
Trained batch 140 in epoch 0, gen_loss = 1.0983055238182664, disc_loss = 0.060777811640675396
Trained batch 141 in epoch 0, gen_loss = 1.0986310134471302, disc_loss = 0.06039666123753807
Trained batch 142 in epoch 0, gen_loss = 1.098699513848845, disc_loss = 0.06002147157409495
Trained batch 143 in epoch 0, gen_loss = 1.0986914485692978, disc_loss = 0.05965799883577145
Trained batch 144 in epoch 0, gen_loss = 1.0980587022057895, disc_loss = 0.059296834147695834
Trained batch 145 in epoch 0, gen_loss = 1.097899120147914, disc_loss = 0.058936163811778575
Trained batch 146 in epoch 0, gen_loss = 1.0972924435219797, disc_loss = 0.05859064950360632
Trained batch 147 in epoch 0, gen_loss = 1.0973326571889825, disc_loss = 0.058262665268360964
Trained batch 148 in epoch 0, gen_loss = 1.0981749432198953, disc_loss = 0.057949510999898986
Trained batch 149 in epoch 0, gen_loss = 1.097987445195516, disc_loss = 0.05761046285120149
Trained batch 150 in epoch 0, gen_loss = 1.0978890673214237, disc_loss = 0.05727076138499261
Trained batch 151 in epoch 0, gen_loss = 1.0976338488490958, disc_loss = 0.05693316685440215
Trained batch 152 in epoch 0, gen_loss = 1.0968351605670903, disc_loss = 0.05660188261090832
Trained batch 153 in epoch 0, gen_loss = 1.09638142043894, disc_loss = 0.05627370773596907
Trained batch 154 in epoch 0, gen_loss = 1.0960920403080603, disc_loss = 0.05595281041798092
Trained batch 155 in epoch 0, gen_loss = 1.0956962895699036, disc_loss = 0.05564635704892377
Trained batch 156 in epoch 0, gen_loss = 1.0950335328745995, disc_loss = 0.055338834536967765
Trained batch 157 in epoch 0, gen_loss = 1.0946964255616636, disc_loss = 0.05504387324157206
Trained batch 158 in epoch 0, gen_loss = 1.0946193914743338, disc_loss = 0.05475103145219245
Trained batch 159 in epoch 0, gen_loss = 1.0948724638670684, disc_loss = 0.054466120182769376
Trained batch 160 in epoch 0, gen_loss = 1.0945932128414604, disc_loss = 0.054174194528912166
Trained batch 161 in epoch 0, gen_loss = 1.093361429962111, disc_loss = 0.05389414908203446
Trained batch 162 in epoch 0, gen_loss = 1.0933918740851747, disc_loss = 0.05360998495544758
Trained batch 163 in epoch 0, gen_loss = 1.0939211234813784, disc_loss = 0.05332621778134347
Trained batch 164 in epoch 0, gen_loss = 1.0941653136051062, disc_loss = 0.053039631016100895
Trained batch 165 in epoch 0, gen_loss = 1.093962346214846, disc_loss = 0.05275694456467607
Trained batch 166 in epoch 0, gen_loss = 1.0940162814305927, disc_loss = 0.05247497997486484
Trained batch 167 in epoch 0, gen_loss = 1.0944945379382087, disc_loss = 0.05220734070531935
Trained batch 168 in epoch 0, gen_loss = 1.094021431087742, disc_loss = 0.05194242782174395
Trained batch 169 in epoch 0, gen_loss = 1.0932787015157588, disc_loss = 0.051683523547013895
Trained batch 170 in epoch 0, gen_loss = 1.0933320693105284, disc_loss = 0.051412367231991385
Trained batch 171 in epoch 0, gen_loss = 1.0941838778035586, disc_loss = 0.05115659985431405
Trained batch 172 in epoch 0, gen_loss = 1.0939678322373099, disc_loss = 0.05089229269685342
Trained batch 173 in epoch 0, gen_loss = 1.0931027302111702, disc_loss = 0.05062719676161891
Trained batch 174 in epoch 0, gen_loss = 1.0930929895809718, disc_loss = 0.0503888106053429
Trained batch 175 in epoch 0, gen_loss = 1.0934040766548028, disc_loss = 0.050155258539069277
Trained batch 176 in epoch 0, gen_loss = 1.0931412948053436, disc_loss = 0.049906932730438176
Trained batch 177 in epoch 0, gen_loss = 1.0937444557634632, disc_loss = 0.04969272091513855
Trained batch 178 in epoch 0, gen_loss = 1.0946607240085495, disc_loss = 0.04950633471020024
Trained batch 179 in epoch 0, gen_loss = 1.0938710583580864, disc_loss = 0.0492638731504687
Trained batch 180 in epoch 0, gen_loss = 1.094328367907698, disc_loss = 0.049050769508811154
Trained batch 181 in epoch 0, gen_loss = 1.0939709459032332, disc_loss = 0.04888802078286452
Trained batch 182 in epoch 0, gen_loss = 1.09468098937488, disc_loss = 0.0487481380426045
Trained batch 183 in epoch 0, gen_loss = 1.0947300364141879, disc_loss = 0.04866348690120503
Trained batch 184 in epoch 0, gen_loss = 1.095216703414917, disc_loss = 0.048545116420231155
Trained batch 185 in epoch 0, gen_loss = 1.0952450536912488, disc_loss = 0.048351620531751106
Trained batch 186 in epoch 0, gen_loss = 1.0957734807927342, disc_loss = 0.0481453490104865
Trained batch 187 in epoch 0, gen_loss = 1.0955035046060035, disc_loss = 0.047982590072391994
Trained batch 188 in epoch 0, gen_loss = 1.0950747804036216, disc_loss = 0.0478139084951075
Trained batch 189 in epoch 0, gen_loss = 1.0949580750967327, disc_loss = 0.04760344803186232
Trained batch 190 in epoch 0, gen_loss = 1.0950052994083983, disc_loss = 0.04739331132951753
Trained batch 191 in epoch 0, gen_loss = 1.0950586615751188, disc_loss = 0.047190884969798695
Trained batch 192 in epoch 0, gen_loss = 1.095225804210327, disc_loss = 0.046996194847565086
Trained batch 193 in epoch 0, gen_loss = 1.095099463290775, disc_loss = 0.04678933250660211
Trained batch 194 in epoch 0, gen_loss = 1.0954466581344604, disc_loss = 0.04657801151132354
Trained batch 195 in epoch 0, gen_loss = 1.0955412345273154, disc_loss = 0.04637028684373945
Trained batch 196 in epoch 0, gen_loss = 1.095705085599483, disc_loss = 0.04617754399993925
Trained batch 197 in epoch 0, gen_loss = 1.0957455496595363, disc_loss = 0.04598085314618668
Trained batch 198 in epoch 0, gen_loss = 1.0953902928673442, disc_loss = 0.04577672235602186
Trained batch 199 in epoch 0, gen_loss = 1.0953535640239715, disc_loss = 0.04557725674239919
Trained batch 200 in epoch 0, gen_loss = 1.0957783869842985, disc_loss = 0.045384711423768334
Trained batch 201 in epoch 0, gen_loss = 1.0957792295087683, disc_loss = 0.04519917749532378
Trained batch 202 in epoch 0, gen_loss = 1.0959635879018623, disc_loss = 0.04500502037811162
Trained batch 203 in epoch 0, gen_loss = 1.0956118784698785, disc_loss = 0.044816529926131755
Trained batch 204 in epoch 0, gen_loss = 1.0962941937330293, disc_loss = 0.044693078963858324
Trained batch 205 in epoch 0, gen_loss = 1.0963078228015344, disc_loss = 0.044549889301935444
Trained batch 206 in epoch 0, gen_loss = 1.0969136555989583, disc_loss = 0.04443783034089107
Trained batch 207 in epoch 0, gen_loss = 1.0971080374259214, disc_loss = 0.0443733988258128
Trained batch 208 in epoch 0, gen_loss = 1.0969900189404282, disc_loss = 0.04429431303301781
Trained batch 209 in epoch 0, gen_loss = 1.0968973239262898, disc_loss = 0.04415091568870204
Trained batch 210 in epoch 0, gen_loss = 1.0977457128994839, disc_loss = 0.04398014053031449
Trained batch 211 in epoch 0, gen_loss = 1.096823144071507, disc_loss = 0.04380536585923214
Trained batch 212 in epoch 0, gen_loss = 1.0972212810471584, disc_loss = 0.043638242159406065
Trained batch 213 in epoch 0, gen_loss = 1.0968144614005757, disc_loss = 0.043458242926781424
Trained batch 214 in epoch 0, gen_loss = 1.096909301225529, disc_loss = 0.0432856282652464
Trained batch 215 in epoch 0, gen_loss = 1.0973790321085188, disc_loss = 0.04312186018581054
Trained batch 216 in epoch 0, gen_loss = 1.0976216485423427, disc_loss = 0.04295394688303913
Trained batch 217 in epoch 0, gen_loss = 1.0974157928326809, disc_loss = 0.04278543597053087
Trained batch 218 in epoch 0, gen_loss = 1.0975886958919159, disc_loss = 0.04262546860914865
Trained batch 219 in epoch 0, gen_loss = 1.0975579619407654, disc_loss = 0.04246482362928377
Trained batch 220 in epoch 0, gen_loss = 1.097917360417983, disc_loss = 0.04230578942645796
Trained batch 221 in epoch 0, gen_loss = 1.0975637060027938, disc_loss = 0.04213936933366632
Trained batch 222 in epoch 0, gen_loss = 1.0977919112406505, disc_loss = 0.04197133700217166
Trained batch 223 in epoch 0, gen_loss = 1.0973350216767617, disc_loss = 0.04180814441393262
Trained batch 224 in epoch 0, gen_loss = 1.0975892154375713, disc_loss = 0.04165029519754979
Trained batch 225 in epoch 0, gen_loss = 1.0975403883288393, disc_loss = 0.04149231644948961
Trained batch 226 in epoch 0, gen_loss = 1.0971059568127872, disc_loss = 0.04133742299579117
Trained batch 227 in epoch 0, gen_loss = 1.0967847846056287, disc_loss = 0.041192801969468985
Trained batch 228 in epoch 0, gen_loss = 1.0970792484075222, disc_loss = 0.04104696008210034
Trained batch 229 in epoch 0, gen_loss = 1.0972490269204844, disc_loss = 0.04089309385491778
Trained batch 230 in epoch 0, gen_loss = 1.0966801839473443, disc_loss = 0.040731968559744036
Trained batch 231 in epoch 0, gen_loss = 1.0970358499165238, disc_loss = 0.040584491844818896
Trained batch 232 in epoch 0, gen_loss = 1.0970923573162423, disc_loss = 0.0404392007054849
Trained batch 233 in epoch 0, gen_loss = 1.0979252472901955, disc_loss = 0.040293756142083526
Trained batch 234 in epoch 0, gen_loss = 1.0984755627652432, disc_loss = 0.040143657949297355
Trained batch 235 in epoch 0, gen_loss = 1.098786332849729, disc_loss = 0.039998771808252245
Trained batch 236 in epoch 0, gen_loss = 1.0986194439578156, disc_loss = 0.03985109543309936
Trained batch 237 in epoch 0, gen_loss = 1.0987383738285352, disc_loss = 0.03970618155088369
Trained batch 238 in epoch 0, gen_loss = 1.0990398299245157, disc_loss = 0.039563949905709994
Trained batch 239 in epoch 0, gen_loss = 1.0990326647957167, disc_loss = 0.03942318872238199
Trained batch 240 in epoch 0, gen_loss = 1.0988235369757497, disc_loss = 0.03927765737956243
Trained batch 241 in epoch 0, gen_loss = 1.099030270556773, disc_loss = 0.03913202645903653
Trained batch 242 in epoch 0, gen_loss = 1.0991035385877508, disc_loss = 0.03898991306346876
Trained batch 243 in epoch 0, gen_loss = 1.098974796592212, disc_loss = 0.038844270356854456
Trained batch 244 in epoch 0, gen_loss = 1.0993808979890785, disc_loss = 0.038705184861865576
Trained batch 245 in epoch 0, gen_loss = 1.0990583310282327, disc_loss = 0.03856433741748333
Trained batch 246 in epoch 0, gen_loss = 1.0988092060513825, disc_loss = 0.03842231221798702
Trained batch 247 in epoch 0, gen_loss = 1.098465607531609, disc_loss = 0.03827992368737356
Trained batch 248 in epoch 0, gen_loss = 1.0986454663985226, disc_loss = 0.038143837723477056
Trained batch 249 in epoch 0, gen_loss = 1.0987077355384827, disc_loss = 0.03800601246580482
Trained batch 250 in epoch 0, gen_loss = 1.098735908113153, disc_loss = 0.03786930628028138
Trained batch 251 in epoch 0, gen_loss = 1.0980142473228394, disc_loss = 0.037731564225858105
Trained batch 252 in epoch 0, gen_loss = 1.0977373278659324, disc_loss = 0.03759686907996302
Trained batch 253 in epoch 0, gen_loss = 1.0975476320334308, disc_loss = 0.03746111398309792
Trained batch 254 in epoch 0, gen_loss = 1.0978102076287364, disc_loss = 0.03732943102516526
Trained batch 255 in epoch 0, gen_loss = 1.097815872170031, disc_loss = 0.037198843253463565
Trained batch 256 in epoch 0, gen_loss = 1.0974531257198943, disc_loss = 0.037070097627321164
Trained batch 257 in epoch 0, gen_loss = 1.0966609792653905, disc_loss = 0.03693803313798307
Trained batch 258 in epoch 0, gen_loss = 1.0964171778281222, disc_loss = 0.03680744205249121
Trained batch 259 in epoch 0, gen_loss = 1.0970027774572373, disc_loss = 0.03668354315092214
Trained batch 260 in epoch 0, gen_loss = 1.0973405963616354, disc_loss = 0.036557716974039416
Trained batch 261 in epoch 0, gen_loss = 1.096892270423074, disc_loss = 0.036430025585209025
Trained batch 262 in epoch 0, gen_loss = 1.0966877098772463, disc_loss = 0.03630653174218683
Trained batch 263 in epoch 0, gen_loss = 1.096364808805061, disc_loss = 0.036181870818836614
Trained batch 264 in epoch 0, gen_loss = 1.096290537996112, disc_loss = 0.03606847305606418
Trained batch 265 in epoch 0, gen_loss = 1.0963134039613538, disc_loss = 0.035970313302101216
Trained batch 266 in epoch 0, gen_loss = 1.0966069859065366, disc_loss = 0.03588204675228492
Trained batch 267 in epoch 0, gen_loss = 1.0965095696164602, disc_loss = 0.035781622335224396
Trained batch 268 in epoch 0, gen_loss = 1.0961175445730358, disc_loss = 0.03567019934059713
Trained batch 269 in epoch 0, gen_loss = 1.0963805090498042, disc_loss = 0.035558473476622665
Trained batch 270 in epoch 0, gen_loss = 1.0959647106508488, disc_loss = 0.03543965063896374
Trained batch 271 in epoch 0, gen_loss = 1.0959159052547287, disc_loss = 0.03532139065774733
Trained batch 272 in epoch 0, gen_loss = 1.095819571516016, disc_loss = 0.035202696813686644
Trained batch 273 in epoch 0, gen_loss = 1.0957245630939512, disc_loss = 0.03508704135374567
Trained batch 274 in epoch 0, gen_loss = 1.0959188474308361, disc_loss = 0.034972253241152926
Trained batch 275 in epoch 0, gen_loss = 1.0961491055246713, disc_loss = 0.03485890453178571
Trained batch 276 in epoch 0, gen_loss = 1.0956593655076698, disc_loss = 0.03474136188942334
Trained batch 277 in epoch 0, gen_loss = 1.095544331150947, disc_loss = 0.034626604052823334
Trained batch 278 in epoch 0, gen_loss = 1.0950165108967853, disc_loss = 0.034513584092780145
Trained batch 279 in epoch 0, gen_loss = 1.0949502942817553, disc_loss = 0.03440383571183442
Trained batch 280 in epoch 0, gen_loss = 1.0951055421948008, disc_loss = 0.034299533097471156
Trained batch 281 in epoch 0, gen_loss = 1.094746616503871, disc_loss = 0.034189906714365205
Trained batch 282 in epoch 0, gen_loss = 1.0945699912077969, disc_loss = 0.03408087445455916
Trained batch 283 in epoch 0, gen_loss = 1.094686050440224, disc_loss = 0.033973678430004546
Trained batch 284 in epoch 0, gen_loss = 1.094964449656637, disc_loss = 0.03386791493956065
Trained batch 285 in epoch 0, gen_loss = 1.095060428747764, disc_loss = 0.03376105983849042
Trained batch 286 in epoch 0, gen_loss = 1.0947389347212655, disc_loss = 0.03365534457267758
Trained batch 287 in epoch 0, gen_loss = 1.0945465666138463, disc_loss = 0.033547108996976424
Trained batch 288 in epoch 0, gen_loss = 1.094406438327578, disc_loss = 0.033446963287561256
Trained batch 289 in epoch 0, gen_loss = 1.0945740266092892, disc_loss = 0.033348490616531466
Trained batch 290 in epoch 0, gen_loss = 1.094669627364968, disc_loss = 0.03325309362534523
Trained batch 291 in epoch 0, gen_loss = 1.094774037395438, disc_loss = 0.033156885533459635
Trained batch 292 in epoch 0, gen_loss = 1.0945173971888962, disc_loss = 0.03305466914050434
Trained batch 293 in epoch 0, gen_loss = 1.0941515931872283, disc_loss = 0.03294946354272186
Trained batch 294 in epoch 0, gen_loss = 1.0935865691152669, disc_loss = 0.03284517796631208
Trained batch 295 in epoch 0, gen_loss = 1.0937539695485219, disc_loss = 0.03274498096859158
Trained batch 296 in epoch 0, gen_loss = 1.0934035717838941, disc_loss = 0.03264160172916598
Trained batch 297 in epoch 0, gen_loss = 1.093505357335878, disc_loss = 0.03254196389918934
Trained batch 298 in epoch 0, gen_loss = 1.0934370253795764, disc_loss = 0.032442724907671076
Trained batch 299 in epoch 0, gen_loss = 1.0933687222003936, disc_loss = 0.032344842510453116
Trained batch 300 in epoch 0, gen_loss = 1.0936638081192573, disc_loss = 0.03224888696889099
Trained batch 301 in epoch 0, gen_loss = 1.0935587555367425, disc_loss = 0.03214947795125329
Trained batch 302 in epoch 0, gen_loss = 1.0929699073923695, disc_loss = 0.032049953182944076
Trained batch 303 in epoch 0, gen_loss = 1.0925636650308181, disc_loss = 0.031950542177104295
Trained batch 304 in epoch 0, gen_loss = 1.0922352229962584, disc_loss = 0.0318522451712643
Trained batch 305 in epoch 0, gen_loss = 1.092421806520886, disc_loss = 0.031755828741463085
Trained batch 306 in epoch 0, gen_loss = 1.0927051847454778, disc_loss = 0.03166545262250819
Trained batch 307 in epoch 0, gen_loss = 1.0927341833904192, disc_loss = 0.03157627913955744
Trained batch 308 in epoch 0, gen_loss = 1.0931588328386201, disc_loss = 0.0314877250346334
Trained batch 309 in epoch 0, gen_loss = 1.0926957813001448, disc_loss = 0.031399463052530927
Trained batch 310 in epoch 0, gen_loss = 1.0923374987108532, disc_loss = 0.03131179746473957
Trained batch 311 in epoch 0, gen_loss = 1.0926121370150492, disc_loss = 0.031221323398103077
Trained batch 312 in epoch 0, gen_loss = 1.0925607178538752, disc_loss = 0.031128745480699424
Trained batch 313 in epoch 0, gen_loss = 1.0928670524791548, disc_loss = 0.031040715865618816
Trained batch 314 in epoch 0, gen_loss = 1.0933841406352935, disc_loss = 0.030955167176083678
Trained batch 315 in epoch 0, gen_loss = 1.093223418993286, disc_loss = 0.03086841653787849
Trained batch 316 in epoch 0, gen_loss = 1.0929763324629245, disc_loss = 0.030777382422738035
Trained batch 317 in epoch 0, gen_loss = 1.092811739669656, disc_loss = 0.03068648757260738
Trained batch 318 in epoch 0, gen_loss = 1.0926768439690522, disc_loss = 0.03059754665608176
Trained batch 319 in epoch 0, gen_loss = 1.0924807637929916, disc_loss = 0.030507722694892436
Trained batch 320 in epoch 0, gen_loss = 1.0927680222044853, disc_loss = 0.03042094343533374
Trained batch 321 in epoch 0, gen_loss = 1.0927500265725651, disc_loss = 0.030337184385587433
Trained batch 322 in epoch 0, gen_loss = 1.0929403522804426, disc_loss = 0.030257064028824724
Trained batch 323 in epoch 0, gen_loss = 1.0927435369403273, disc_loss = 0.030172601751810697
Trained batch 324 in epoch 0, gen_loss = 1.0927433131291315, disc_loss = 0.030087740808152234
Trained batch 325 in epoch 0, gen_loss = 1.0923500119542784, disc_loss = 0.03000092522978234
Trained batch 326 in epoch 0, gen_loss = 1.092362373247059, disc_loss = 0.029914926407881515
Trained batch 327 in epoch 0, gen_loss = 1.0922528214570952, disc_loss = 0.02983007436013417
Trained batch 328 in epoch 0, gen_loss = 1.0924295661659589, disc_loss = 0.029750177120835178
Trained batch 329 in epoch 0, gen_loss = 1.0919853022604278, disc_loss = 0.0296712542961662
Trained batch 330 in epoch 0, gen_loss = 1.0915584472371012, disc_loss = 0.02959550137130763
Trained batch 331 in epoch 0, gen_loss = 1.091353307466909, disc_loss = 0.029520583586593395
Trained batch 332 in epoch 0, gen_loss = 1.0915331520117797, disc_loss = 0.02944308310584934
Trained batch 333 in epoch 0, gen_loss = 1.0915544034835107, disc_loss = 0.029362708337125395
Trained batch 334 in epoch 0, gen_loss = 1.0913254152483014, disc_loss = 0.029282621627173093
Trained batch 335 in epoch 0, gen_loss = 1.0908555093975294, disc_loss = 0.029202126638015864
Trained batch 336 in epoch 0, gen_loss = 1.0907355596474442, disc_loss = 0.029124051315201453
Trained batch 337 in epoch 0, gen_loss = 1.0905898248655557, disc_loss = 0.029046851897077668
Trained batch 338 in epoch 0, gen_loss = 1.0902701400022592, disc_loss = 0.028972183780024887
Trained batch 339 in epoch 0, gen_loss = 1.090306860383819, disc_loss = 0.02889742532553261
Trained batch 340 in epoch 0, gen_loss = 1.0904286696064858, disc_loss = 0.02882628112517931
Trained batch 341 in epoch 0, gen_loss = 1.0902184762104212, disc_loss = 0.028755969585774588
Trained batch 342 in epoch 0, gen_loss = 1.0901833385142223, disc_loss = 0.028685912297109994
Trained batch 343 in epoch 0, gen_loss = 1.089843260167643, disc_loss = 0.02861300825958985
Trained batch 344 in epoch 0, gen_loss = 1.089698336953702, disc_loss = 0.028538238957011398
Trained batch 345 in epoch 0, gen_loss = 1.0895007867689077, disc_loss = 0.02846229801659682
Trained batch 346 in epoch 0, gen_loss = 1.0895046791013447, disc_loss = 0.028385361286835685
Trained batch 347 in epoch 0, gen_loss = 1.08951602978953, disc_loss = 0.028308601936542204
Trained batch 348 in epoch 0, gen_loss = 1.0895406320306837, disc_loss = 0.02823278022880658
Trained batch 349 in epoch 0, gen_loss = 1.0896254813671111, disc_loss = 0.02815860874784578
Trained batch 350 in epoch 0, gen_loss = 1.0892986200134298, disc_loss = 0.028084002066061348
Trained batch 351 in epoch 0, gen_loss = 1.0897026324475354, disc_loss = 0.028010853302641244
Trained batch 352 in epoch 0, gen_loss = 1.0896393876237842, disc_loss = 0.027938139300711623
Trained batch 353 in epoch 0, gen_loss = 1.0892601540196414, disc_loss = 0.027865613395371868
Trained batch 354 in epoch 0, gen_loss = 1.0892191700532403, disc_loss = 0.027792328727943166
Trained batch 355 in epoch 0, gen_loss = 1.089150503612636, disc_loss = 0.027719313916135475
Trained batch 356 in epoch 0, gen_loss = 1.0889340176635764, disc_loss = 0.02764795227230628
Trained batch 357 in epoch 0, gen_loss = 1.0885698846931564, disc_loss = 0.027575895855887454
Trained batch 358 in epoch 0, gen_loss = 1.088851183071774, disc_loss = 0.02750554451982239
Trained batch 359 in epoch 0, gen_loss = 1.088690868516763, disc_loss = 0.02743414817539613
Trained batch 360 in epoch 0, gen_loss = 1.0886813948689404, disc_loss = 0.027363034567300364
Trained batch 361 in epoch 0, gen_loss = 1.0888107335040582, disc_loss = 0.02729257050475867
Trained batch 362 in epoch 0, gen_loss = 1.0887080885818838, disc_loss = 0.02722156227062156
Trained batch 363 in epoch 0, gen_loss = 1.0885120841500524, disc_loss = 0.027151197434919835
Trained batch 364 in epoch 0, gen_loss = 1.0881982208931282, disc_loss = 0.027082701562584875
Trained batch 365 in epoch 0, gen_loss = 1.0883314003709887, disc_loss = 0.027015589436521256
Trained batch 366 in epoch 0, gen_loss = 1.0881998850799062, disc_loss = 0.026947722132051266
Trained batch 367 in epoch 0, gen_loss = 1.0881120620862297, disc_loss = 0.026882241275060274
Trained batch 368 in epoch 0, gen_loss = 1.087835074763311, disc_loss = 0.026818843278276727
Trained batch 369 in epoch 0, gen_loss = 1.0883128672032742, disc_loss = 0.026757438173769292
Trained batch 370 in epoch 0, gen_loss = 1.0880192863652005, disc_loss = 0.026696689307659543
Trained batch 371 in epoch 0, gen_loss = 1.0880871314194895, disc_loss = 0.026637151783522498
Trained batch 372 in epoch 0, gen_loss = 1.0878116750525406, disc_loss = 0.02657521937801515
Trained batch 373 in epoch 0, gen_loss = 1.0874878289227816, disc_loss = 0.026511702196607815
Trained batch 374 in epoch 0, gen_loss = 1.0872262813250224, disc_loss = 0.02644743011457225
Trained batch 375 in epoch 0, gen_loss = 1.0868934250258384, disc_loss = 0.02638260604370326
Trained batch 376 in epoch 0, gen_loss = 1.0864860649450387, disc_loss = 0.026317854349523665
Trained batch 377 in epoch 0, gen_loss = 1.0864257880304224, disc_loss = 0.02625463138428078
Trained batch 378 in epoch 0, gen_loss = 1.0862207876660892, disc_loss = 0.026193218142295496
Trained batch 379 in epoch 0, gen_loss = 1.0863169351690694, disc_loss = 0.02613203386212454
Trained batch 380 in epoch 0, gen_loss = 1.0860417161400862, disc_loss = 0.026068922597914934
Trained batch 381 in epoch 0, gen_loss = 1.0858655827831847, disc_loss = 0.02600510794418274
Trained batch 382 in epoch 0, gen_loss = 1.0857329679842718, disc_loss = 0.025942468595649686
Trained batch 383 in epoch 0, gen_loss = 1.085769844551881, disc_loss = 0.02588062345906413
Trained batch 384 in epoch 0, gen_loss = 1.0856875893357512, disc_loss = 0.025818373798997468
Trained batch 385 in epoch 0, gen_loss = 1.0855051899821029, disc_loss = 0.025756636865188517
Trained batch 386 in epoch 0, gen_loss = 1.085527523235449, disc_loss = 0.025695488834212167
Trained batch 387 in epoch 0, gen_loss = 1.0852894294507724, disc_loss = 0.025633153536527408
Trained batch 388 in epoch 0, gen_loss = 1.0851124500554141, disc_loss = 0.025571788273629634
Trained batch 389 in epoch 0, gen_loss = 1.0848545959362617, disc_loss = 0.02550984093805966
Trained batch 390 in epoch 0, gen_loss = 1.0848744365260423, disc_loss = 0.025451003074529282
Trained batch 391 in epoch 0, gen_loss = 1.0848400031729621, disc_loss = 0.025392620614908008
Trained batch 392 in epoch 0, gen_loss = 1.084589096274388, disc_loss = 0.025334263870637135
Trained batch 393 in epoch 0, gen_loss = 1.0841978234688037, disc_loss = 0.02527712605306217
Trained batch 394 in epoch 0, gen_loss = 1.0837922244132319, disc_loss = 0.025221813878905076
Trained batch 395 in epoch 0, gen_loss = 1.0840920447701154, disc_loss = 0.025167350240717312
Trained batch 396 in epoch 0, gen_loss = 1.0840695796145, disc_loss = 0.02511192806638655
Trained batch 397 in epoch 0, gen_loss = 1.08371304656992, disc_loss = 0.025054679261859805
Trained batch 398 in epoch 0, gen_loss = 1.0839321607336365, disc_loss = 0.025001051768317427
Trained batch 399 in epoch 0, gen_loss = 1.0837754678726197, disc_loss = 0.024948681185778695
Trained batch 400 in epoch 0, gen_loss = 1.0840233472220024, disc_loss = 0.02490031607292286
Trained batch 401 in epoch 0, gen_loss = 1.084276431828589, disc_loss = 0.024848175979050258
Trained batch 402 in epoch 0, gen_loss = 1.0841645144351364, disc_loss = 0.024792333869275086
Trained batch 403 in epoch 0, gen_loss = 1.0843818270333923, disc_loss = 0.02473565291366678
Trained batch 404 in epoch 0, gen_loss = 1.0839153810783668, disc_loss = 0.024680635918299724
Trained batch 405 in epoch 0, gen_loss = 1.0839176436363183, disc_loss = 0.024627604775286735
Trained batch 406 in epoch 0, gen_loss = 1.0838411440134634, disc_loss = 0.024573658522062863
Trained batch 407 in epoch 0, gen_loss = 1.083607654361164, disc_loss = 0.024519486854985065
Trained batch 408 in epoch 0, gen_loss = 1.0835099476765304, disc_loss = 0.024463260349644515
Trained batch 409 in epoch 0, gen_loss = 1.0835291711295523, disc_loss = 0.02440758361935434
Trained batch 410 in epoch 0, gen_loss = 1.0836104064672243, disc_loss = 0.024354242950841022
Trained batch 411 in epoch 0, gen_loss = 1.0836901404325245, disc_loss = 0.024301672410852845
Trained batch 412 in epoch 0, gen_loss = 1.0837214120075143, disc_loss = 0.02424802716323073
Trained batch 413 in epoch 0, gen_loss = 1.083635798111054, disc_loss = 0.024194271141181785
Trained batch 414 in epoch 0, gen_loss = 1.083353060268494, disc_loss = 0.0241398107995425
Trained batch 415 in epoch 0, gen_loss = 1.083118225232913, disc_loss = 0.02408554693465703
Trained batch 416 in epoch 0, gen_loss = 1.0832299302807815, disc_loss = 0.024033294755873902
Trained batch 417 in epoch 0, gen_loss = 1.0833914148750488, disc_loss = 0.023982761727710605
Trained batch 418 in epoch 0, gen_loss = 1.0834155321690233, disc_loss = 0.02393204243192427
Trained batch 419 in epoch 0, gen_loss = 1.083696549279349, disc_loss = 0.02388026211771094
Trained batch 420 in epoch 0, gen_loss = 1.0837773778376274, disc_loss = 0.02382995632522454
Trained batch 421 in epoch 0, gen_loss = 1.083723557786354, disc_loss = 0.023779571691132925
Trained batch 422 in epoch 0, gen_loss = 1.0837074478749125, disc_loss = 0.023727463760047744
Trained batch 423 in epoch 0, gen_loss = 1.0833304896950722, disc_loss = 0.023674768111822283
Trained batch 424 in epoch 0, gen_loss = 1.0830694581480587, disc_loss = 0.023623033124843942
Trained batch 425 in epoch 0, gen_loss = 1.0831774144385342, disc_loss = 0.02357353989205415
Trained batch 426 in epoch 0, gen_loss = 1.0829939737532122, disc_loss = 0.02352382680586598
Trained batch 427 in epoch 0, gen_loss = 1.0829702188199926, disc_loss = 0.02347591658564563
Trained batch 428 in epoch 0, gen_loss = 1.0828390934250571, disc_loss = 0.023425685259728476
Trained batch 429 in epoch 0, gen_loss = 1.0827951241371243, disc_loss = 0.02337534672196218
Trained batch 430 in epoch 0, gen_loss = 1.082975508303764, disc_loss = 0.023326950320885397
Trained batch 431 in epoch 0, gen_loss = 1.082560949165512, disc_loss = 0.02327830575571473
Trained batch 432 in epoch 0, gen_loss = 1.0823319872312127, disc_loss = 0.023231210847660538
Trained batch 433 in epoch 0, gen_loss = 1.0824014173674694, disc_loss = 0.023183763703419333
Trained batch 434 in epoch 0, gen_loss = 1.0825095406894025, disc_loss = 0.02313742119545952
Trained batch 435 in epoch 0, gen_loss = 1.0825708803780583, disc_loss = 0.023090871799910238
Trained batch 436 in epoch 0, gen_loss = 1.0823331618472696, disc_loss = 0.023042811998549757
Trained batch 437 in epoch 0, gen_loss = 1.0822418615153935, disc_loss = 0.02299445688476803
Trained batch 438 in epoch 0, gen_loss = 1.0822975133165955, disc_loss = 0.022947192222573676
Trained batch 439 in epoch 0, gen_loss = 1.0822286689823324, disc_loss = 0.022898292869054288
Trained batch 440 in epoch 0, gen_loss = 1.0819435010150986, disc_loss = 0.02284971168718793
Trained batch 441 in epoch 0, gen_loss = 1.081846080079877, disc_loss = 0.022801517768092958
Trained batch 442 in epoch 0, gen_loss = 1.0820899673024904, disc_loss = 0.022754025727281302
Trained batch 443 in epoch 0, gen_loss = 1.0819411177087475, disc_loss = 0.022706252073623694
Trained batch 444 in epoch 0, gen_loss = 1.0820572232932186, disc_loss = 0.022658464048591474
Trained batch 445 in epoch 0, gen_loss = 1.0819116415197005, disc_loss = 0.022610883354553912
Trained batch 446 in epoch 0, gen_loss = 1.081826960613797, disc_loss = 0.022563300962753646
Trained batch 447 in epoch 0, gen_loss = 1.0817910210628594, disc_loss = 0.022517645127144142
Trained batch 448 in epoch 0, gen_loss = 1.0819033770624937, disc_loss = 0.022474803446889555
Trained batch 449 in epoch 0, gen_loss = 1.0820867518583934, disc_loss = 0.022432593396968313
Trained batch 450 in epoch 0, gen_loss = 1.0820395863241208, disc_loss = 0.022388568432472992
Trained batch 451 in epoch 0, gen_loss = 1.0820306672722892, disc_loss = 0.022343584960141112
Trained batch 452 in epoch 0, gen_loss = 1.0817663239327489, disc_loss = 0.022297989739471055
Trained batch 453 in epoch 0, gen_loss = 1.0817698383383814, disc_loss = 0.022252492318935037
Trained batch 454 in epoch 0, gen_loss = 1.0815206555219796, disc_loss = 0.022207250338876723
Trained batch 455 in epoch 0, gen_loss = 1.0816736714097492, disc_loss = 0.022164229733773442
Trained batch 456 in epoch 0, gen_loss = 1.0817463628833612, disc_loss = 0.022119867393270102
Trained batch 457 in epoch 0, gen_loss = 1.0817355848035437, disc_loss = 0.022074584897219175
Trained batch 458 in epoch 0, gen_loss = 1.081553416963756, disc_loss = 0.02202911149002287
Trained batch 459 in epoch 0, gen_loss = 1.0813289507575656, disc_loss = 0.021983841442725742
Trained batch 460 in epoch 0, gen_loss = 1.0812598185011726, disc_loss = 0.02193890304184456
Trained batch 461 in epoch 0, gen_loss = 1.081428101568511, disc_loss = 0.021894184861924838
Trained batch 462 in epoch 0, gen_loss = 1.0813814862500515, disc_loss = 0.021850030385983654
Trained batch 463 in epoch 0, gen_loss = 1.081389157165741, disc_loss = 0.021806769417739343
Trained batch 464 in epoch 0, gen_loss = 1.081464675934084, disc_loss = 0.021763407936199537
Trained batch 465 in epoch 0, gen_loss = 1.0813118155422128, disc_loss = 0.02171995165301167
Trained batch 466 in epoch 0, gen_loss = 1.0813716047581055, disc_loss = 0.021676301391799265
Trained batch 467 in epoch 0, gen_loss = 1.0814242908078382, disc_loss = 0.021633191338171147
Trained batch 468 in epoch 0, gen_loss = 1.0813332478374815, disc_loss = 0.021590533352314013
Trained batch 469 in epoch 0, gen_loss = 1.081124478451749, disc_loss = 0.021548004724590623
Trained batch 470 in epoch 0, gen_loss = 1.080947245761847, disc_loss = 0.021504912488587644
Trained batch 471 in epoch 0, gen_loss = 1.0805725034768299, disc_loss = 0.021461515809494167
Trained batch 472 in epoch 0, gen_loss = 1.080376802866857, disc_loss = 0.021419537598001387
Trained batch 473 in epoch 0, gen_loss = 1.080418938197164, disc_loss = 0.02137746651168669
Trained batch 474 in epoch 0, gen_loss = 1.0804193884448001, disc_loss = 0.021335700337873086
Trained batch 475 in epoch 0, gen_loss = 1.0804245062485462, disc_loss = 0.021294775856228375
Trained batch 476 in epoch 0, gen_loss = 1.080528759481522, disc_loss = 0.021253484781085664
Trained batch 477 in epoch 0, gen_loss = 1.0804020257425109, disc_loss = 0.021211761955676454
Trained batch 478 in epoch 0, gen_loss = 1.0801860769755656, disc_loss = 0.021170778980912224
Trained batch 479 in epoch 0, gen_loss = 1.0801739177356164, disc_loss = 0.02113017013883412
Trained batch 480 in epoch 0, gen_loss = 1.0800073071229979, disc_loss = 0.021090768247875705
Trained batch 481 in epoch 0, gen_loss = 1.0798282540438087, disc_loss = 0.02105147258018209
Trained batch 482 in epoch 0, gen_loss = 1.0798094273847576, disc_loss = 0.021014322011681432
Trained batch 483 in epoch 0, gen_loss = 1.0797413716877788, disc_loss = 0.020979761178480185
Trained batch 484 in epoch 0, gen_loss = 1.0793738059161864, disc_loss = 0.02094447462190634
Trained batch 485 in epoch 0, gen_loss = 1.0792104171382055, disc_loss = 0.020909453746757314
Trained batch 486 in epoch 0, gen_loss = 1.0789137317414645, disc_loss = 0.020872037416731354
Trained batch 487 in epoch 0, gen_loss = 1.078865699592184, disc_loss = 0.02083287746445123
Trained batch 488 in epoch 0, gen_loss = 1.0787025319530432, disc_loss = 0.02079331139954862
Trained batch 489 in epoch 0, gen_loss = 1.0785258154479824, disc_loss = 0.02075484745912444
Trained batch 490 in epoch 0, gen_loss = 1.0787201056412428, disc_loss = 0.020718325361232
Trained batch 491 in epoch 0, gen_loss = 1.0785120868585942, disc_loss = 0.020678868816126274
Trained batch 492 in epoch 0, gen_loss = 1.0784189969482576, disc_loss = 0.020638888897553737
Trained batch 493 in epoch 0, gen_loss = 1.0784486575647887, disc_loss = 0.020598945085233574
Trained batch 494 in epoch 0, gen_loss = 1.0785393897933189, disc_loss = 0.020560296836915907
Trained batch 495 in epoch 0, gen_loss = 1.0785956450047032, disc_loss = 0.02052198966221993
Trained batch 496 in epoch 0, gen_loss = 1.0784971913101689, disc_loss = 0.020484299052874903
Trained batch 497 in epoch 0, gen_loss = 1.0784408648808796, disc_loss = 0.020448217716981586
Trained batch 498 in epoch 0, gen_loss = 1.0784524167945724, disc_loss = 0.020414126304025858
Trained batch 499 in epoch 0, gen_loss = 1.0784374248981476, disc_loss = 0.020378834222094157
Trained batch 500 in epoch 0, gen_loss = 1.0787860043272526, disc_loss = 0.020343800424946705
Trained batch 501 in epoch 0, gen_loss = 1.0788199186800012, disc_loss = 0.020307723808578176
Trained batch 502 in epoch 0, gen_loss = 1.0783926141901945, disc_loss = 0.020271456032129518
Trained batch 503 in epoch 0, gen_loss = 1.0782764296210001, disc_loss = 0.02023608756858194
Trained batch 504 in epoch 0, gen_loss = 1.0780310356971061, disc_loss = 0.0202022075764881
Trained batch 505 in epoch 0, gen_loss = 1.0781767302351035, disc_loss = 0.0201694237735728
Trained batch 506 in epoch 0, gen_loss = 1.0779926675781462, disc_loss = 0.02013680521140235
Trained batch 507 in epoch 0, gen_loss = 1.0778514125685053, disc_loss = 0.020102226982139763
Trained batch 508 in epoch 0, gen_loss = 1.0776099210169554, disc_loss = 0.020066373797535186
Trained batch 509 in epoch 0, gen_loss = 1.0775000212239285, disc_loss = 0.020029717712439415
Trained batch 510 in epoch 0, gen_loss = 1.0773228901473044, disc_loss = 0.01999238427202609
Trained batch 511 in epoch 0, gen_loss = 1.077319715404883, disc_loss = 0.019955278314455427
Trained batch 512 in epoch 0, gen_loss = 1.0772631839934381, disc_loss = 0.019918491349275973
Trained batch 513 in epoch 0, gen_loss = 1.0772567500400172, disc_loss = 0.019882877569297755
Trained batch 514 in epoch 0, gen_loss = 1.0771678688456712, disc_loss = 0.01984876222836161
Trained batch 515 in epoch 0, gen_loss = 1.077044586802638, disc_loss = 0.0198164521653364
Trained batch 516 in epoch 0, gen_loss = 1.0768573815633526, disc_loss = 0.019784481102074685
Trained batch 517 in epoch 0, gen_loss = 1.0768438523570543, disc_loss = 0.019752214019524802
Trained batch 518 in epoch 0, gen_loss = 1.0767546996675246, disc_loss = 0.019720364075337102
Trained batch 519 in epoch 0, gen_loss = 1.0764073233191784, disc_loss = 0.01969089053454809
Trained batch 520 in epoch 0, gen_loss = 1.076412726157915, disc_loss = 0.0196668955711058
Trained batch 521 in epoch 0, gen_loss = 1.0763048612980093, disc_loss = 0.019644107761029227
Trained batch 522 in epoch 0, gen_loss = 1.07597717557309, disc_loss = 0.01961817472227573
Trained batch 523 in epoch 0, gen_loss = 1.0762328088056041, disc_loss = 0.019590440929159948
Trained batch 524 in epoch 0, gen_loss = 1.0759129043987818, disc_loss = 0.019559516526669974
Trained batch 525 in epoch 0, gen_loss = 1.0757456262075402, disc_loss = 0.019526387867163653
Trained batch 526 in epoch 0, gen_loss = 1.0757180729446194, disc_loss = 0.0194913551400891
Trained batch 527 in epoch 0, gen_loss = 1.0757766538722948, disc_loss = 0.019457038620947224
Trained batch 528 in epoch 0, gen_loss = 1.0757079235998128, disc_loss = 0.019422615663718876
Trained batch 529 in epoch 0, gen_loss = 1.0753098251684656, disc_loss = 0.019387720854522415
Trained batch 530 in epoch 0, gen_loss = 1.0754903065507246, disc_loss = 0.01935511699324323
Trained batch 531 in epoch 0, gen_loss = 1.0753020414508374, disc_loss = 0.019322188559278874
Trained batch 532 in epoch 0, gen_loss = 1.0752247121275924, disc_loss = 0.01928920286365105
Trained batch 533 in epoch 0, gen_loss = 1.0750330703312092, disc_loss = 0.019255765482010703
Trained batch 534 in epoch 0, gen_loss = 1.075207002697704, disc_loss = 0.019224032251573403
Trained batch 535 in epoch 0, gen_loss = 1.0752877231631706, disc_loss = 0.01919237488499363
Trained batch 536 in epoch 0, gen_loss = 1.0753701944146965, disc_loss = 0.019160610719261346
Trained batch 537 in epoch 0, gen_loss = 1.0750291731942543, disc_loss = 0.019128241375881528
Trained batch 538 in epoch 0, gen_loss = 1.0751522831439086, disc_loss = 0.019096655305474997
Trained batch 539 in epoch 0, gen_loss = 1.0751169901203226, disc_loss = 0.01906441827908296
Trained batch 540 in epoch 0, gen_loss = 1.075056168486583, disc_loss = 0.019032333412443505
Trained batch 541 in epoch 0, gen_loss = 1.0750281246605835, disc_loss = 0.018999497469762046
Trained batch 542 in epoch 0, gen_loss = 1.0750145469800763, disc_loss = 0.018967495503977735
Trained batch 543 in epoch 0, gen_loss = 1.0749222650466597, disc_loss = 0.01893551001964678
Trained batch 544 in epoch 0, gen_loss = 1.075128558469475, disc_loss = 0.018905293300465913
Trained batch 545 in epoch 0, gen_loss = 1.0752514414079897, disc_loss = 0.018877094436476123
Trained batch 546 in epoch 0, gen_loss = 1.0751574618071045, disc_loss = 0.018850318858292723
Trained batch 547 in epoch 0, gen_loss = 1.0750756821710699, disc_loss = 0.01882373670988757
Trained batch 548 in epoch 0, gen_loss = 1.07482550302707, disc_loss = 0.018795540293157848
Trained batch 549 in epoch 0, gen_loss = 1.0747539181059058, disc_loss = 0.018765296603933994
Trained batch 550 in epoch 0, gen_loss = 1.0747042177160508, disc_loss = 0.018735945015383407
Trained batch 551 in epoch 0, gen_loss = 1.0747317420183748, disc_loss = 0.018706961964093403
Trained batch 552 in epoch 0, gen_loss = 1.0747423136428296, disc_loss = 0.018676937894371907
Trained batch 553 in epoch 0, gen_loss = 1.0745456948177048, disc_loss = 0.018645013307451542
Trained batch 554 in epoch 0, gen_loss = 1.0747290177388233, disc_loss = 0.018614120098032257
Trained batch 555 in epoch 0, gen_loss = 1.074851711448148, disc_loss = 0.018584332872758343
Trained batch 556 in epoch 0, gen_loss = 1.074696993057347, disc_loss = 0.01855479057834783
Trained batch 557 in epoch 0, gen_loss = 1.074750874845785, disc_loss = 0.018525207563767403
Trained batch 558 in epoch 0, gen_loss = 1.074579547790807, disc_loss = 0.01849440235414664
Trained batch 559 in epoch 0, gen_loss = 1.0744231712605272, disc_loss = 0.018462906077703727
Trained batch 560 in epoch 0, gen_loss = 1.0741725641563402, disc_loss = 0.01843169249478834
Trained batch 561 in epoch 0, gen_loss = 1.0739439767238508, disc_loss = 0.01840098502174073
Trained batch 562 in epoch 0, gen_loss = 1.073970438426172, disc_loss = 0.01837109924553766
Trained batch 563 in epoch 0, gen_loss = 1.0737412298190678, disc_loss = 0.01834245888410625
Trained batch 564 in epoch 0, gen_loss = 1.073658563710947, disc_loss = 0.01831396475755733
Trained batch 565 in epoch 0, gen_loss = 1.0736462902475161, disc_loss = 0.018284882035422348
Trained batch 566 in epoch 0, gen_loss = 1.073606110228853, disc_loss = 0.01825475690387866
Trained batch 567 in epoch 0, gen_loss = 1.0734496132378848, disc_loss = 0.01822472196609326
Trained batch 568 in epoch 0, gen_loss = 1.073478280450422, disc_loss = 0.018194911614189707
Trained batch 569 in epoch 0, gen_loss = 1.0733709963790157, disc_loss = 0.01816597878606173
Trained batch 570 in epoch 0, gen_loss = 1.0733076621062283, disc_loss = 0.018137717383853346
Trained batch 571 in epoch 0, gen_loss = 1.07315689387855, disc_loss = 0.018111843035728964
Trained batch 572 in epoch 0, gen_loss = 1.0730464000768478, disc_loss = 0.018088160709674627
Trained batch 573 in epoch 0, gen_loss = 1.0727586114863485, disc_loss = 0.01806508276233521
Trained batch 574 in epoch 0, gen_loss = 1.0726048901806706, disc_loss = 0.018041372894026016
Trained batch 575 in epoch 0, gen_loss = 1.0724793441800609, disc_loss = 0.018017462082449736
Trained batch 576 in epoch 0, gen_loss = 1.072279262480744, disc_loss = 0.01799105397511138
Trained batch 577 in epoch 0, gen_loss = 1.072255948938713, disc_loss = 0.01796290228202952
Trained batch 578 in epoch 0, gen_loss = 1.072127550994794, disc_loss = 0.017933761667611403
Trained batch 579 in epoch 0, gen_loss = 1.071911780587558, disc_loss = 0.01790423978848688
Trained batch 580 in epoch 0, gen_loss = 1.0721409581409265, disc_loss = 0.01787531104192487
Trained batch 581 in epoch 0, gen_loss = 1.0721756109257334, disc_loss = 0.017846796479691427
Trained batch 582 in epoch 0, gen_loss = 1.0721513016555158, disc_loss = 0.017818569955811398
Trained batch 583 in epoch 0, gen_loss = 1.072258202384596, disc_loss = 0.017790380735663944
Trained batch 584 in epoch 0, gen_loss = 1.0720464653438992, disc_loss = 0.0177617628657673
Trained batch 585 in epoch 0, gen_loss = 1.0721074649905182, disc_loss = 0.017732881697541603
Trained batch 586 in epoch 0, gen_loss = 1.0717838613706716, disc_loss = 0.017704228465794388
Trained batch 587 in epoch 0, gen_loss = 1.0716745483429253, disc_loss = 0.017676307939564758
Trained batch 588 in epoch 0, gen_loss = 1.0716623485796724, disc_loss = 0.017648454209044893
Trained batch 589 in epoch 0, gen_loss = 1.071552682225987, disc_loss = 0.017620805256518584
Trained batch 590 in epoch 0, gen_loss = 1.0715049828974728, disc_loss = 0.017593614066645263
Trained batch 591 in epoch 0, gen_loss = 1.0713001842031609, disc_loss = 0.017566540230709016
Trained batch 592 in epoch 0, gen_loss = 1.07138541355905, disc_loss = 0.0175391688030433
Trained batch 593 in epoch 0, gen_loss = 1.071390283830238, disc_loss = 0.017511888288599613
Trained batch 594 in epoch 0, gen_loss = 1.0713741492824393, disc_loss = 0.01748477745695556
Trained batch 595 in epoch 0, gen_loss = 1.0713489061634012, disc_loss = 0.017457667588773526
Trained batch 596 in epoch 0, gen_loss = 1.0710914496401047, disc_loss = 0.01743033364059488
Trained batch 597 in epoch 0, gen_loss = 1.071006938366587, disc_loss = 0.017403169941580716
Trained batch 598 in epoch 0, gen_loss = 1.0710396573619174, disc_loss = 0.01737594374440741
Trained batch 599 in epoch 0, gen_loss = 1.0711045839389166, disc_loss = 0.0173490214755293
Trained batch 600 in epoch 0, gen_loss = 1.0709207750199836, disc_loss = 0.017322342945479737
Trained batch 601 in epoch 0, gen_loss = 1.0706079735906417, disc_loss = 0.017295781512546703
Trained batch 602 in epoch 0, gen_loss = 1.0704020221237323, disc_loss = 0.017269845654999536
Trained batch 603 in epoch 0, gen_loss = 1.0699827780589362, disc_loss = 0.017244080706832574
Trained batch 604 in epoch 0, gen_loss = 1.069835801361021, disc_loss = 0.017218480035200837
Trained batch 605 in epoch 0, gen_loss = 1.0698134440793456, disc_loss = 0.017192495416653138
Trained batch 606 in epoch 0, gen_loss = 1.0698161629907774, disc_loss = 0.017166710179836123
Trained batch 607 in epoch 0, gen_loss = 1.0698025005036278, disc_loss = 0.017141443049790962
Trained batch 608 in epoch 0, gen_loss = 1.0696856567425093, disc_loss = 0.017115884403161374
Trained batch 609 in epoch 0, gen_loss = 1.0697464197385507, disc_loss = 0.0170899960487226
Trained batch 610 in epoch 0, gen_loss = 1.069701314265131, disc_loss = 0.017063654408563056
Trained batch 611 in epoch 0, gen_loss = 1.0696624789167852, disc_loss = 0.017037072889674213
Trained batch 612 in epoch 0, gen_loss = 1.0696639311644225, disc_loss = 0.017010578662339373
Trained batch 613 in epoch 0, gen_loss = 1.069575576226952, disc_loss = 0.016984423552052017
Trained batch 614 in epoch 0, gen_loss = 1.069467341899872, disc_loss = 0.016958775300233497
Trained batch 615 in epoch 0, gen_loss = 1.0693766603415662, disc_loss = 0.016933593621863773
Trained batch 616 in epoch 0, gen_loss = 1.0692626837779868, disc_loss = 0.01690803931973576
Trained batch 617 in epoch 0, gen_loss = 1.0690211103957834, disc_loss = 0.016881986359088354
Trained batch 618 in epoch 0, gen_loss = 1.0689997449637614, disc_loss = 0.016856456874596686
Trained batch 619 in epoch 0, gen_loss = 1.069148281505031, disc_loss = 0.01683290628218768
Trained batch 620 in epoch 0, gen_loss = 1.0691606954292014, disc_loss = 0.01680989829092639
Trained batch 621 in epoch 0, gen_loss = 1.069043306292445, disc_loss = 0.01678750108299744
Trained batch 622 in epoch 0, gen_loss = 1.0689031875918038, disc_loss = 0.01676529231561605
Trained batch 623 in epoch 0, gen_loss = 1.0685991152929954, disc_loss = 0.016743177048341842
Trained batch 624 in epoch 0, gen_loss = 1.0685653464317322, disc_loss = 0.016720634722243995
Trained batch 625 in epoch 0, gen_loss = 1.0684860336323516, disc_loss = 0.016698265134579334
Trained batch 626 in epoch 0, gen_loss = 1.068212007411549, disc_loss = 0.01667554583762545
Trained batch 627 in epoch 0, gen_loss = 1.0680316473078575, disc_loss = 0.016652052242447514
Trained batch 628 in epoch 0, gen_loss = 1.067869649403425, disc_loss = 0.016627283638882908
Trained batch 629 in epoch 0, gen_loss = 1.067841237121158, disc_loss = 0.016602174165780612
Trained batch 630 in epoch 0, gen_loss = 1.067734979034037, disc_loss = 0.016576854681921608
Trained batch 631 in epoch 0, gen_loss = 1.0676040832377687, disc_loss = 0.016551685789463706
Trained batch 632 in epoch 0, gen_loss = 1.0674753704153908, disc_loss = 0.016527059309881204
Trained batch 633 in epoch 0, gen_loss = 1.0673222397028084, disc_loss = 0.016502962358371568
Trained batch 634 in epoch 0, gen_loss = 1.0671876376069438, disc_loss = 0.016479306940198325
Trained batch 635 in epoch 0, gen_loss = 1.067236101664837, disc_loss = 0.01645565131298814
Trained batch 636 in epoch 0, gen_loss = 1.0670898703615557, disc_loss = 0.016431467786992008
Trained batch 637 in epoch 0, gen_loss = 1.0671344928233228, disc_loss = 0.016407344892725412
Trained batch 638 in epoch 0, gen_loss = 1.0671827502093965, disc_loss = 0.016383225512993267
Trained batch 639 in epoch 0, gen_loss = 1.0670537049882114, disc_loss = 0.01635960566263748
Trained batch 640 in epoch 0, gen_loss = 1.066810099178469, disc_loss = 0.016335886833639367
Trained batch 641 in epoch 0, gen_loss = 1.066675317157466, disc_loss = 0.016311882288145146
Trained batch 642 in epoch 0, gen_loss = 1.0665432873817848, disc_loss = 0.0162880895480993
Trained batch 643 in epoch 0, gen_loss = 1.066343722784001, disc_loss = 0.016264953610674558
Trained batch 644 in epoch 0, gen_loss = 1.0659541798192402, disc_loss = 0.016241694342745683
Trained batch 645 in epoch 0, gen_loss = 1.0658268263280946, disc_loss = 0.016218709321775483
Trained batch 646 in epoch 0, gen_loss = 1.0659491312927587, disc_loss = 0.01619594900498535
Trained batch 647 in epoch 0, gen_loss = 1.0658670035593303, disc_loss = 0.01617259775293074
Trained batch 648 in epoch 0, gen_loss = 1.0658746512351307, disc_loss = 0.016148678896082666
Trained batch 649 in epoch 0, gen_loss = 1.0661069546296047, disc_loss = 0.016125284293935133
Trained batch 650 in epoch 0, gen_loss = 1.0660279536027513, disc_loss = 0.016101673312757747
Trained batch 651 in epoch 0, gen_loss = 1.0658457792061238, disc_loss = 0.016078714974545244
Trained batch 652 in epoch 0, gen_loss = 1.0659962530158016, disc_loss = 0.016056999192551023
Trained batch 653 in epoch 0, gen_loss = 1.0656850947699417, disc_loss = 0.016035205207815657
Trained batch 654 in epoch 0, gen_loss = 1.0658209266553398, disc_loss = 0.016013647049029165
Trained batch 655 in epoch 0, gen_loss = 1.0659006424248219, disc_loss = 0.01599135307004894
Trained batch 656 in epoch 0, gen_loss = 1.0656459098355773, disc_loss = 0.01596846049414066
Trained batch 657 in epoch 0, gen_loss = 1.0655758704276794, disc_loss = 0.01594530798510385
Trained batch 658 in epoch 0, gen_loss = 1.0654922039085528, disc_loss = 0.015922215787961668
Trained batch 659 in epoch 0, gen_loss = 1.065428108609084, disc_loss = 0.0158993123661
Trained batch 660 in epoch 0, gen_loss = 1.06553302491126, disc_loss = 0.015876699828401168
Trained batch 661 in epoch 0, gen_loss = 1.065437055876608, disc_loss = 0.015853754176601367
Trained batch 662 in epoch 0, gen_loss = 1.0653043596093652, disc_loss = 0.015831025128816796
Trained batch 663 in epoch 0, gen_loss = 1.0649514220744731, disc_loss = 0.015808537489691108
Trained batch 664 in epoch 0, gen_loss = 1.0649159007502678, disc_loss = 0.015786364812340897
Trained batch 665 in epoch 0, gen_loss = 1.0647817612052322, disc_loss = 0.01576463209413406
Trained batch 666 in epoch 0, gen_loss = 1.0648173061625354, disc_loss = 0.015743035361634336
Trained batch 667 in epoch 0, gen_loss = 1.0647119928798277, disc_loss = 0.015721408176252585
Trained batch 668 in epoch 0, gen_loss = 1.0646914739958018, disc_loss = 0.01569955790226079
Trained batch 669 in epoch 0, gen_loss = 1.0645479519865406, disc_loss = 0.01567817013606485
Trained batch 670 in epoch 0, gen_loss = 1.0644853988276508, disc_loss = 0.015657211260053976
Trained batch 671 in epoch 0, gen_loss = 1.0644348502336514, disc_loss = 0.01563623413814986
Trained batch 672 in epoch 0, gen_loss = 1.064585133877764, disc_loss = 0.01561536172900991
Trained batch 673 in epoch 0, gen_loss = 1.0646496969620622, disc_loss = 0.015595774959948312
Trained batch 674 in epoch 0, gen_loss = 1.0645723583963183, disc_loss = 0.015577552628841388
Trained batch 675 in epoch 0, gen_loss = 1.0645450467365027, disc_loss = 0.015558063427500218
Trained batch 676 in epoch 0, gen_loss = 1.0644588615728798, disc_loss = 0.015537320658567319
Trained batch 677 in epoch 0, gen_loss = 1.064441467017199, disc_loss = 0.015516230854711283
Trained batch 678 in epoch 0, gen_loss = 1.0642892747283508, disc_loss = 0.01549459746872474
Trained batch 679 in epoch 0, gen_loss = 1.0642974140012966, disc_loss = 0.015473385054792742
Trained batch 680 in epoch 0, gen_loss = 1.0640226317222248, disc_loss = 0.015452544590804956
Trained batch 681 in epoch 0, gen_loss = 1.0638644475041945, disc_loss = 0.015431855856341957
Trained batch 682 in epoch 0, gen_loss = 1.0639503932453005, disc_loss = 0.015411072053300902
Trained batch 683 in epoch 0, gen_loss = 1.0639384624205137, disc_loss = 0.015389985832020133
Trained batch 684 in epoch 0, gen_loss = 1.0638221859061805, disc_loss = 0.01536876635224878
Trained batch 685 in epoch 0, gen_loss = 1.0636956696955178, disc_loss = 0.015347619570347781
Trained batch 686 in epoch 0, gen_loss = 1.0634466623114707, disc_loss = 0.0153264909341465
Trained batch 687 in epoch 0, gen_loss = 1.0632095919965312, disc_loss = 0.015305221113606443
Trained batch 688 in epoch 0, gen_loss = 1.0630254294771933, disc_loss = 0.015284130819640643
Trained batch 689 in epoch 0, gen_loss = 1.0628160214942435, disc_loss = 0.01526288694703776
Trained batch 690 in epoch 0, gen_loss = 1.062591907170678, disc_loss = 0.015241823631474229
Trained batch 691 in epoch 0, gen_loss = 1.0624509199678553, disc_loss = 0.015220985924010838
Trained batch 692 in epoch 0, gen_loss = 1.0622951482969618, disc_loss = 0.015200669949633724
Trained batch 693 in epoch 0, gen_loss = 1.0621182754506981, disc_loss = 0.015181034399962767
Trained batch 694 in epoch 0, gen_loss = 1.0621288569711096, disc_loss = 0.015161979934133643
Trained batch 695 in epoch 0, gen_loss = 1.0619164288215253, disc_loss = 0.015142385267797086
Trained batch 696 in epoch 0, gen_loss = 1.0620026584164142, disc_loss = 0.01512220018400331
Trained batch 697 in epoch 0, gen_loss = 1.0619137669702656, disc_loss = 0.015101995663203693
Trained batch 698 in epoch 0, gen_loss = 1.0617866754872947, disc_loss = 0.015081965980734222
Trained batch 699 in epoch 0, gen_loss = 1.0618394815921783, disc_loss = 0.015062034508446231
Trained batch 700 in epoch 0, gen_loss = 1.061655761511962, disc_loss = 0.015041803984890178
Trained batch 701 in epoch 0, gen_loss = 1.0615726824839231, disc_loss = 0.01502168627312882
Trained batch 702 in epoch 0, gen_loss = 1.0616703918614394, disc_loss = 0.015002192236939485
Trained batch 703 in epoch 0, gen_loss = 1.0616231394762343, disc_loss = 0.014983276614574688
Trained batch 704 in epoch 0, gen_loss = 1.0615764240846566, disc_loss = 0.014964647118930197
Trained batch 705 in epoch 0, gen_loss = 1.0614881372823255, disc_loss = 0.014945510148335244
Trained batch 706 in epoch 0, gen_loss = 1.061612543240295, disc_loss = 0.014926180628551857
Trained batch 707 in epoch 0, gen_loss = 1.0614690320134836, disc_loss = 0.014906789804364839
Trained batch 708 in epoch 0, gen_loss = 1.0614394974305028, disc_loss = 0.014887269743707042
Trained batch 709 in epoch 0, gen_loss = 1.0613767848048412, disc_loss = 0.014867960161801664
Trained batch 710 in epoch 0, gen_loss = 1.061235530466973, disc_loss = 0.014848491795470417
Trained batch 711 in epoch 0, gen_loss = 1.0610091740663132, disc_loss = 0.014828795270639173
Trained batch 712 in epoch 0, gen_loss = 1.0609590086829948, disc_loss = 0.014809367515595412
Trained batch 713 in epoch 0, gen_loss = 1.0608413904821838, disc_loss = 0.014790156532450076
Trained batch 714 in epoch 0, gen_loss = 1.0608467317961312, disc_loss = 0.014771418553252763
Trained batch 715 in epoch 0, gen_loss = 1.0605656322320747, disc_loss = 0.014752352741360273
Trained batch 716 in epoch 0, gen_loss = 1.0605636225750923, disc_loss = 0.014733201144876886
Trained batch 717 in epoch 0, gen_loss = 1.0605092839776307, disc_loss = 0.014714777806315254
Trained batch 718 in epoch 0, gen_loss = 1.060430100216156, disc_loss = 0.014697109293454923
Trained batch 719 in epoch 0, gen_loss = 1.0601783228417239, disc_loss = 0.014679451807185412
Trained batch 720 in epoch 0, gen_loss = 1.060139096146979, disc_loss = 0.014660872907255713
Trained batch 721 in epoch 0, gen_loss = 1.0600475018374478, disc_loss = 0.014641749445646305
Trained batch 722 in epoch 0, gen_loss = 1.0598724874388297, disc_loss = 0.01462235586000555
Trained batch 723 in epoch 0, gen_loss = 1.0599001843626328, disc_loss = 0.01460339994327672
Trained batch 724 in epoch 0, gen_loss = 1.0600703111188166, disc_loss = 0.014584477800667158
Trained batch 725 in epoch 0, gen_loss = 1.0600066273665625, disc_loss = 0.014565940540891331
Trained batch 726 in epoch 0, gen_loss = 1.0599553337451353, disc_loss = 0.014547202577529426
Trained batch 727 in epoch 0, gen_loss = 1.0600178649464806, disc_loss = 0.014529113761155104
Trained batch 728 in epoch 0, gen_loss = 1.0598210532151786, disc_loss = 0.014512002702935923
Trained batch 729 in epoch 0, gen_loss = 1.0597748156279734, disc_loss = 0.014495427152923346
Trained batch 730 in epoch 0, gen_loss = 1.059620341344669, disc_loss = 0.01447843796124162
Trained batch 731 in epoch 0, gen_loss = 1.0595551120941755, disc_loss = 0.014460566113375336
Trained batch 732 in epoch 0, gen_loss = 1.0594115549187706, disc_loss = 0.014442190484160946
Trained batch 733 in epoch 0, gen_loss = 1.05925822899517, disc_loss = 0.014423985163410313
Trained batch 734 in epoch 0, gen_loss = 1.05905016928303, disc_loss = 0.014406313519801336
Trained batch 735 in epoch 0, gen_loss = 1.0590087711487128, disc_loss = 0.014390152731404827
Trained batch 736 in epoch 0, gen_loss = 1.0589435959444602, disc_loss = 0.014375381815304735
Trained batch 737 in epoch 0, gen_loss = 1.0588317226749773, disc_loss = 0.014361388557719894
Trained batch 738 in epoch 0, gen_loss = 1.0587365158678552, disc_loss = 0.014347749969311416
Trained batch 739 in epoch 0, gen_loss = 1.0588694120581086, disc_loss = 0.014333561479469535
Trained batch 740 in epoch 0, gen_loss = 1.0589819724260554, disc_loss = 0.014318949694468109
Trained batch 741 in epoch 0, gen_loss = 1.0590395872001699, disc_loss = 0.014303114479912867
Trained batch 742 in epoch 0, gen_loss = 1.058908484505131, disc_loss = 0.014286387852856245
Trained batch 743 in epoch 0, gen_loss = 1.058908899464915, disc_loss = 0.014269181265341123
Trained batch 744 in epoch 0, gen_loss = 1.0585714614631345, disc_loss = 0.01425140301123474
Trained batch 745 in epoch 0, gen_loss = 1.0586714961094128, disc_loss = 0.014233662677949404
Trained batch 746 in epoch 0, gen_loss = 1.058520513445817, disc_loss = 0.014216350827480191
Trained batch 747 in epoch 0, gen_loss = 1.058481817019177, disc_loss = 0.01419881184609983
Trained batch 748 in epoch 0, gen_loss = 1.0584212730182347, disc_loss = 0.014181079287240493
Trained batch 749 in epoch 0, gen_loss = 1.058336043357849, disc_loss = 0.014162971018347889
Trained batch 750 in epoch 0, gen_loss = 1.0582396224557797, disc_loss = 0.01414488004142302
Trained batch 751 in epoch 0, gen_loss = 1.0582564592837018, disc_loss = 0.014127322753220723
Trained batch 752 in epoch 0, gen_loss = 1.0582540881427953, disc_loss = 0.014109727990944038
Trained batch 753 in epoch 0, gen_loss = 1.0581300302905177, disc_loss = 0.014092182133557394
Trained batch 754 in epoch 0, gen_loss = 1.057997820787872, disc_loss = 0.014074668381902827
Trained batch 755 in epoch 0, gen_loss = 1.0578191969445143, disc_loss = 0.01405722305396382
Trained batch 756 in epoch 0, gen_loss = 1.0576905038901647, disc_loss = 0.014039982857580617
Trained batch 757 in epoch 0, gen_loss = 1.0576170399824358, disc_loss = 0.01402266865496654
Trained batch 758 in epoch 0, gen_loss = 1.0575665888893118, disc_loss = 0.014006171554047247
Trained batch 759 in epoch 0, gen_loss = 1.0576682704059701, disc_loss = 0.013991206572513635
Trained batch 760 in epoch 0, gen_loss = 1.0576138267692536, disc_loss = 0.013976741259680197
Trained batch 761 in epoch 0, gen_loss = 1.0574162173771795, disc_loss = 0.013962312199400244
Trained batch 762 in epoch 0, gen_loss = 1.0573553007833298, disc_loss = 0.013947749667865656
Trained batch 763 in epoch 0, gen_loss = 1.0573911891557783, disc_loss = 0.013932956181191083
Trained batch 764 in epoch 0, gen_loss = 1.0572510832275441, disc_loss = 0.01391727923601257
Trained batch 765 in epoch 0, gen_loss = 1.0572445421399397, disc_loss = 0.013901061170361207
Trained batch 766 in epoch 0, gen_loss = 1.0571923558217762, disc_loss = 0.013884577808040772
Trained batch 767 in epoch 0, gen_loss = 1.057008915503199, disc_loss = 0.013868104771214954
Trained batch 768 in epoch 0, gen_loss = 1.0569077366660258, disc_loss = 0.013851322375524968
Trained batch 769 in epoch 0, gen_loss = 1.0569015646135653, disc_loss = 0.013834440241894359
Trained batch 770 in epoch 0, gen_loss = 1.056914384649576, disc_loss = 0.01381760113744244
Trained batch 771 in epoch 0, gen_loss = 1.0568756264262866, disc_loss = 0.013800711843602534
Trained batch 772 in epoch 0, gen_loss = 1.0568750397354016, disc_loss = 0.013783822682421693
Trained batch 773 in epoch 0, gen_loss = 1.0568932078451456, disc_loss = 0.013767166157194127
Trained batch 774 in epoch 0, gen_loss = 1.0567443869959923, disc_loss = 0.013750948584187897
Trained batch 775 in epoch 0, gen_loss = 1.0566088338334536, disc_loss = 0.013736744894653308
Trained batch 776 in epoch 0, gen_loss = 1.0565231842117113, disc_loss = 0.013723958458959998
Trained batch 777 in epoch 0, gen_loss = 1.0564899528853997, disc_loss = 0.013711814376271801
Trained batch 778 in epoch 0, gen_loss = 1.0564388269331397, disc_loss = 0.013699879333321889
Trained batch 779 in epoch 0, gen_loss = 1.056429448341712, disc_loss = 0.01368772857494127
Trained batch 780 in epoch 0, gen_loss = 1.0564255659467279, disc_loss = 0.013675255347675287
Trained batch 781 in epoch 0, gen_loss = 1.0563079321475894, disc_loss = 0.013660764280894815
Trained batch 782 in epoch 0, gen_loss = 1.0562540822558932, disc_loss = 0.013645197489949497
Trained batch 783 in epoch 0, gen_loss = 1.0562251865559695, disc_loss = 0.013629288279435986
Trained batch 784 in epoch 0, gen_loss = 1.056200426399328, disc_loss = 0.013613362801350226
Trained batch 785 in epoch 0, gen_loss = 1.0560241769288332, disc_loss = 0.01359759480277735
Trained batch 786 in epoch 0, gen_loss = 1.056073694550249, disc_loss = 0.013582383098466537
Trained batch 787 in epoch 0, gen_loss = 1.055930969300609, disc_loss = 0.01356773473367303
Trained batch 788 in epoch 0, gen_loss = 1.0558758989939672, disc_loss = 0.013552743569134496
Trained batch 789 in epoch 0, gen_loss = 1.055790885867952, disc_loss = 0.013537285993865963
Trained batch 790 in epoch 0, gen_loss = 1.0556733220175154, disc_loss = 0.013521891349853592
Trained batch 791 in epoch 0, gen_loss = 1.055477242803935, disc_loss = 0.013506925389384663
Trained batch 792 in epoch 0, gen_loss = 1.0554340594503346, disc_loss = 0.013492527732292066
Trained batch 793 in epoch 0, gen_loss = 1.0554767763734765, disc_loss = 0.013477508244937477
Trained batch 794 in epoch 0, gen_loss = 1.0552264403996978, disc_loss = 0.013463194167487464
Trained batch 795 in epoch 0, gen_loss = 1.0551987890921646, disc_loss = 0.013448692539100764
Trained batch 796 in epoch 0, gen_loss = 1.055078419642885, disc_loss = 0.013434184580039902
Trained batch 797 in epoch 0, gen_loss = 1.0551682089952599, disc_loss = 0.013419496771245775
Trained batch 798 in epoch 0, gen_loss = 1.0551184116675052, disc_loss = 0.01340452853551785
Trained batch 799 in epoch 0, gen_loss = 1.0550033239275216, disc_loss = 0.013389083768124692
Trained batch 800 in epoch 0, gen_loss = 1.0548631626270832, disc_loss = 0.013373636348043963
Trained batch 801 in epoch 0, gen_loss = 1.0548320530804614, disc_loss = 0.013358489610690234
Trained batch 802 in epoch 0, gen_loss = 1.0546945102633456, disc_loss = 0.013342824134703698
Trained batch 803 in epoch 0, gen_loss = 1.0547644022240568, disc_loss = 0.013327052202961867
Trained batch 804 in epoch 0, gen_loss = 1.0547214674653473, disc_loss = 0.013311410400009951
Trained batch 805 in epoch 0, gen_loss = 1.0547832118222495, disc_loss = 0.013295569573962373
Trained batch 806 in epoch 0, gen_loss = 1.0546213585647952, disc_loss = 0.01327981388975625
Trained batch 807 in epoch 0, gen_loss = 1.0546071752905846, disc_loss = 0.01326451314237755
Trained batch 808 in epoch 0, gen_loss = 1.0544385336827584, disc_loss = 0.013249120021504275
Trained batch 809 in epoch 0, gen_loss = 1.0544933631096358, disc_loss = 0.013233881087019396
Trained batch 810 in epoch 0, gen_loss = 1.0544802519307919, disc_loss = 0.013218911115192657
Trained batch 811 in epoch 0, gen_loss = 1.0544059928414857, disc_loss = 0.013204892602086233
Trained batch 812 in epoch 0, gen_loss = 1.0542510086613242, disc_loss = 0.01319158241366979
Trained batch 813 in epoch 0, gen_loss = 1.0543255658055992, disc_loss = 0.013178397409665954
Trained batch 814 in epoch 0, gen_loss = 1.0543008685843345, disc_loss = 0.013164325082743187
Trained batch 815 in epoch 0, gen_loss = 1.0542706427913087, disc_loss = 0.013149913604566417
Trained batch 816 in epoch 0, gen_loss = 1.0542383156032866, disc_loss = 0.013135946555960253
Trained batch 817 in epoch 0, gen_loss = 1.054105906002679, disc_loss = 0.01312224425316827
Trained batch 818 in epoch 0, gen_loss = 1.0540401970510518, disc_loss = 0.013108337854242159
Trained batch 819 in epoch 0, gen_loss = 1.0540827460405304, disc_loss = 0.013094533755296341
Trained batch 820 in epoch 0, gen_loss = 1.0538528364845954, disc_loss = 0.013080465685617038
Trained batch 821 in epoch 0, gen_loss = 1.0538425155509707, disc_loss = 0.013066355894442076
Trained batch 822 in epoch 0, gen_loss = 1.0537722758215513, disc_loss = 0.013051968860583673
Trained batch 823 in epoch 0, gen_loss = 1.0538160317731136, disc_loss = 0.013037977343734842
Trained batch 824 in epoch 0, gen_loss = 1.053776984648271, disc_loss = 0.01302335321296458
Trained batch 825 in epoch 0, gen_loss = 1.0536566036088126, disc_loss = 0.013008418922412905
Trained batch 826 in epoch 0, gen_loss = 1.053431489159147, disc_loss = 0.012993276757228963
Trained batch 827 in epoch 0, gen_loss = 1.053324546215039, disc_loss = 0.01297820682847869
Trained batch 828 in epoch 0, gen_loss = 1.0532853722716125, disc_loss = 0.012963412247158067
Trained batch 829 in epoch 0, gen_loss = 1.0532610361834607, disc_loss = 0.012948752694702931
Trained batch 830 in epoch 0, gen_loss = 1.0533923649472308, disc_loss = 0.012934698998289538
Trained batch 831 in epoch 0, gen_loss = 1.0531694606806223, disc_loss = 0.012920533732015498
Trained batch 832 in epoch 0, gen_loss = 1.0532511867681185, disc_loss = 0.012906567014437695
Trained batch 833 in epoch 0, gen_loss = 1.0530020225819925, disc_loss = 0.012893351896145891
Trained batch 834 in epoch 0, gen_loss = 1.053032370670113, disc_loss = 0.012880918148990084
Trained batch 835 in epoch 0, gen_loss = 1.0529133138474094, disc_loss = 0.012867656112410425
Trained batch 836 in epoch 0, gen_loss = 1.0530388084648616, disc_loss = 0.012854027022222912
Trained batch 837 in epoch 0, gen_loss = 1.052839277894514, disc_loss = 0.012840170783235532
Trained batch 838 in epoch 0, gen_loss = 1.0526487493401346, disc_loss = 0.012827082041378219
Trained batch 839 in epoch 0, gen_loss = 1.0526334133886155, disc_loss = 0.012814728942751008
Trained batch 840 in epoch 0, gen_loss = 1.0527278099842503, disc_loss = 0.012802640334006752
Trained batch 841 in epoch 0, gen_loss = 1.0526266069706716, disc_loss = 0.012789326930959763
Trained batch 842 in epoch 0, gen_loss = 1.0526911335624975, disc_loss = 0.012775931250247917
Trained batch 843 in epoch 0, gen_loss = 1.05249570536105, disc_loss = 0.012762012613709118
Trained batch 844 in epoch 0, gen_loss = 1.0524931812427454, disc_loss = 0.012749578998893908
Trained batch 845 in epoch 0, gen_loss = 1.0523883398120284, disc_loss = 0.012737540394734057
Trained batch 846 in epoch 0, gen_loss = 1.0521369054297771, disc_loss = 0.012725444652730877
Trained batch 847 in epoch 0, gen_loss = 1.0520450594430824, disc_loss = 0.01271471682278234
Trained batch 848 in epoch 0, gen_loss = 1.0520581482296416, disc_loss = 0.012707016407244743
Trained batch 849 in epoch 0, gen_loss = 1.0520214946830975, disc_loss = 0.012707041105947128
Trained batch 850 in epoch 0, gen_loss = 1.0521369542834622, disc_loss = 0.012718301260446884
Trained batch 851 in epoch 0, gen_loss = 1.052231418065062, disc_loss = 0.012723543106813581
Trained batch 852 in epoch 0, gen_loss = 1.0522729191243438, disc_loss = 0.012720099263307272
Trained batch 853 in epoch 0, gen_loss = 1.0521825924690211, disc_loss = 0.012710033359794782
Trained batch 854 in epoch 0, gen_loss = 1.052223209052058, disc_loss = 0.012699169009598516
Trained batch 855 in epoch 0, gen_loss = 1.0520213008901784, disc_loss = 0.012692064413275606
Trained batch 856 in epoch 0, gen_loss = 1.0519746723503327, disc_loss = 0.012684432849215449
Trained batch 857 in epoch 0, gen_loss = 1.0518926552264563, disc_loss = 0.012674468561621884
Trained batch 858 in epoch 0, gen_loss = 1.0518415271888928, disc_loss = 0.012670488446731092
Trained batch 859 in epoch 0, gen_loss = 1.05176651560983, disc_loss = 0.012666411622905249
Trained batch 860 in epoch 0, gen_loss = 1.052077960054218, disc_loss = 0.012663145242162908
Trained batch 861 in epoch 0, gen_loss = 1.052356897401699, disc_loss = 0.012667449844630788
Trained batch 862 in epoch 0, gen_loss = 1.0526056850495233, disc_loss = 0.012687666109405072
Trained batch 863 in epoch 0, gen_loss = 1.0529503598809242, disc_loss = 0.012734787903826617
Trained batch 864 in epoch 0, gen_loss = 1.0530460718739239, disc_loss = 0.012762486011717157
Trained batch 865 in epoch 0, gen_loss = 1.0532172325026357, disc_loss = 0.012775690717211017
Trained batch 866 in epoch 0, gen_loss = 1.0534490267160717, disc_loss = 0.01276817160818727
Trained batch 867 in epoch 0, gen_loss = 1.0537045287646456, disc_loss = 0.012762423281533448
Trained batch 868 in epoch 0, gen_loss = 1.0538381410824826, disc_loss = 0.012757377216510176
Trained batch 869 in epoch 0, gen_loss = 1.0541139510856277, disc_loss = 0.012747449931807698
Trained batch 870 in epoch 0, gen_loss = 1.0543532226444248, disc_loss = 0.012736929860747934
Trained batch 871 in epoch 0, gen_loss = 1.0544721786308726, disc_loss = 0.012726782471906242
Trained batch 872 in epoch 0, gen_loss = 1.0545972924325338, disc_loss = 0.01271636778745989
Trained batch 873 in epoch 0, gen_loss = 1.0548266732992788, disc_loss = 0.012705769964252189
Trained batch 874 in epoch 0, gen_loss = 1.0550246846335274, disc_loss = 0.012694313522461536
Trained batch 875 in epoch 0, gen_loss = 1.0550300190437873, disc_loss = 0.012682480793415737
Trained batch 876 in epoch 0, gen_loss = 1.0551329991156861, disc_loss = 0.012669678748286083
Trained batch 877 in epoch 0, gen_loss = 1.0552364116649149, disc_loss = 0.012656951101226594
Trained batch 878 in epoch 0, gen_loss = 1.0553561893881926, disc_loss = 0.01264478014446334
Trained batch 879 in epoch 0, gen_loss = 1.0553587248379535, disc_loss = 0.012632605586292233
Trained batch 880 in epoch 0, gen_loss = 1.055540826615627, disc_loss = 0.012620984461845907
Trained batch 881 in epoch 0, gen_loss = 1.0556364272997762, disc_loss = 0.012608765208595558
Trained batch 882 in epoch 0, gen_loss = 1.055604102117424, disc_loss = 0.012595881771150974
Trained batch 883 in epoch 0, gen_loss = 1.0556078460151794, disc_loss = 0.012582914877717954
Trained batch 884 in epoch 0, gen_loss = 1.0557345838870031, disc_loss = 0.012569971544711487
Trained batch 885 in epoch 0, gen_loss = 1.0556257011928085, disc_loss = 0.012557200693062077
Trained batch 886 in epoch 0, gen_loss = 1.0556956010848586, disc_loss = 0.01254650959806079
Trained batch 887 in epoch 0, gen_loss = 1.0557377350491446, disc_loss = 0.012535595986920016
Trained batch 888 in epoch 0, gen_loss = 1.055808783247983, disc_loss = 0.012530506083081006
Trained batch 889 in epoch 0, gen_loss = 1.0560076447015398, disc_loss = 0.01252423726035978
Trained batch 890 in epoch 0, gen_loss = 1.0559057846882796, disc_loss = 0.012515482402362993
Trained batch 891 in epoch 0, gen_loss = 1.056199540872745, disc_loss = 0.012507113294015302
Trained batch 892 in epoch 0, gen_loss = 1.0562834695632353, disc_loss = 0.01249759754926422
Trained batch 893 in epoch 0, gen_loss = 1.0563453655914972, disc_loss = 0.012486494972946911
Trained batch 894 in epoch 0, gen_loss = 1.0564706356165796, disc_loss = 0.012475632819738604
Trained batch 895 in epoch 0, gen_loss = 1.0566134471446276, disc_loss = 0.012464663016187063
Trained batch 896 in epoch 0, gen_loss = 1.0567099311811603, disc_loss = 0.012453650394092504
Trained batch 897 in epoch 0, gen_loss = 1.056568933223563, disc_loss = 0.012442336118561506
Trained batch 898 in epoch 0, gen_loss = 1.0565057427387217, disc_loss = 0.012430944112270657
Trained batch 899 in epoch 0, gen_loss = 1.0563752660486434, disc_loss = 0.012419103315753292
Trained batch 900 in epoch 0, gen_loss = 1.056386277493044, disc_loss = 0.012407612356365803
Trained batch 901 in epoch 0, gen_loss = 1.0562583722190688, disc_loss = 0.012395509445407127
Trained batch 902 in epoch 0, gen_loss = 1.0562047010508355, disc_loss = 0.012383066734294165
Trained batch 903 in epoch 0, gen_loss = 1.0560301356347261, disc_loss = 0.012370656081971113
Trained batch 904 in epoch 0, gen_loss = 1.0559213131830838, disc_loss = 0.012358532709523634
Trained batch 905 in epoch 0, gen_loss = 1.0557777548073144, disc_loss = 0.012346153509517604
Trained batch 906 in epoch 0, gen_loss = 1.0552280616208238, disc_loss = 0.01258322991068935
Trained batch 907 in epoch 0, gen_loss = 1.0557925208155805, disc_loss = 0.013810107002547882
Trained batch 908 in epoch 0, gen_loss = 1.0554065774507386, disc_loss = 0.014249918748947614
Trained batch 909 in epoch 0, gen_loss = 1.0550729536093197, disc_loss = 0.0149233370058937
Trained batch 910 in epoch 0, gen_loss = 1.0546947137322829, disc_loss = 0.015578943080991827
Trained batch 911 in epoch 0, gen_loss = 1.0543718247821456, disc_loss = 0.015864908926168778
Trained batch 912 in epoch 0, gen_loss = 1.054137111036566, disc_loss = 0.0162014817312599
Trained batch 913 in epoch 0, gen_loss = 1.0538187012630689, disc_loss = 0.01646718999317565
Trained batch 914 in epoch 0, gen_loss = 1.0534569348142446, disc_loss = 0.016719343153094424
Trained batch 915 in epoch 0, gen_loss = 1.0528269586149261, disc_loss = 0.016968305570569844
Trained batch 916 in epoch 0, gen_loss = 1.0523828984671877, disc_loss = 0.01721719323572776
Trained batch 917 in epoch 0, gen_loss = 1.0519177390664232, disc_loss = 0.017452763773107543
Trained batch 918 in epoch 0, gen_loss = 1.0514624254034186, disc_loss = 0.01768809051285964
Trained batch 919 in epoch 0, gen_loss = 1.0510695848452007, disc_loss = 0.017932513601345304
Trained batch 920 in epoch 0, gen_loss = 1.050730809035441, disc_loss = 0.01819756913674974
Trained batch 921 in epoch 0, gen_loss = 1.0503241449206615, disc_loss = 0.01841127405609403
Trained batch 922 in epoch 0, gen_loss = 1.0500368376142413, disc_loss = 0.018624308762396107
Trained batch 923 in epoch 0, gen_loss = 1.0498225434453456, disc_loss = 0.0188726830878358
Trained batch 924 in epoch 0, gen_loss = 1.049330922558501, disc_loss = 0.019120899698778837
Trained batch 925 in epoch 0, gen_loss = 1.048962622269441, disc_loss = 0.019324112436277782
Trained batch 926 in epoch 0, gen_loss = 1.0486244136525846, disc_loss = 0.01950559171360361
Trained batch 927 in epoch 0, gen_loss = 1.048361608148392, disc_loss = 0.019676422381304168
Trained batch 928 in epoch 0, gen_loss = 1.0480599489034954, disc_loss = 0.019838983682416576
Trained batch 929 in epoch 0, gen_loss = 1.0477536388943272, disc_loss = 0.019963903967647873
Trained batch 930 in epoch 0, gen_loss = 1.0474425906717586, disc_loss = 0.020079969913804018
Trained batch 931 in epoch 0, gen_loss = 1.0471683394947278, disc_loss = 0.020181335766792003
Trained batch 932 in epoch 0, gen_loss = 1.0468847136724928, disc_loss = 0.020268397877050967
Trained batch 933 in epoch 0, gen_loss = 1.0467944290385256, disc_loss = 0.0203115447611377
Trained batch 934 in epoch 0, gen_loss = 1.0466711460269071, disc_loss = 0.020347267630501317
Trained batch 935 in epoch 0, gen_loss = 1.0468230940656276, disc_loss = 0.0203974702233873
Trained batch 936 in epoch 0, gen_loss = 1.0468402346844607, disc_loss = 0.020538776820897508
Trained batch 937 in epoch 0, gen_loss = 1.0467001666455888, disc_loss = 0.020629326523156778
Trained batch 938 in epoch 0, gen_loss = 1.0466710856229988, disc_loss = 0.02068450454443607
Trained batch 939 in epoch 0, gen_loss = 1.0462803460499073, disc_loss = 0.020753526864133707
Trained batch 940 in epoch 0, gen_loss = 1.0464825332798182, disc_loss = 0.020792050433760076
Trained batch 941 in epoch 0, gen_loss = 1.0465216013086829, disc_loss = 0.020796320268805454
Trained batch 942 in epoch 0, gen_loss = 1.0465026232053467, disc_loss = 0.020797265585061817
Trained batch 943 in epoch 0, gen_loss = 1.0467313040931852, disc_loss = 0.020787689882342683
Trained batch 944 in epoch 0, gen_loss = 1.0468066126265854, disc_loss = 0.020774340412915787
Trained batch 945 in epoch 0, gen_loss = 1.0468427477439917, disc_loss = 0.020759296482070803
Trained batch 946 in epoch 0, gen_loss = 1.0470460453468995, disc_loss = 0.02074597949087015
Trained batch 947 in epoch 0, gen_loss = 1.0470832638159584, disc_loss = 0.020731178813920708
Trained batch 948 in epoch 0, gen_loss = 1.047186701673351, disc_loss = 0.020716243644483687
Trained batch 949 in epoch 0, gen_loss = 1.0471901350586037, disc_loss = 0.020698477596589854
Trained batch 950 in epoch 0, gen_loss = 1.0472180319697324, disc_loss = 0.020680995952964982
Trained batch 951 in epoch 0, gen_loss = 1.0473064949595128, disc_loss = 0.020662790439156434
Trained batch 952 in epoch 0, gen_loss = 1.0474675221120449, disc_loss = 0.020644726739774417
Trained batch 953 in epoch 0, gen_loss = 1.047589673717317, disc_loss = 0.020626597901503847
Trained batch 954 in epoch 0, gen_loss = 1.0476762552223904, disc_loss = 0.020607708580456723
Trained batch 955 in epoch 0, gen_loss = 1.0477878533958391, disc_loss = 0.020589098235828242
Trained batch 956 in epoch 0, gen_loss = 1.0479905894619794, disc_loss = 0.020570266384261834
Trained batch 957 in epoch 0, gen_loss = 1.047969285064301, disc_loss = 0.020551303742966997
Trained batch 958 in epoch 0, gen_loss = 1.0479616306186095, disc_loss = 0.020532489238250795
Trained batch 959 in epoch 0, gen_loss = 1.0479001147362093, disc_loss = 0.020513127416931336
Trained batch 960 in epoch 0, gen_loss = 1.0479359545209033, disc_loss = 0.020493938899328875
Trained batch 961 in epoch 0, gen_loss = 1.0477764429582628, disc_loss = 0.020475272043892996
Trained batch 962 in epoch 0, gen_loss = 1.0478229058803923, disc_loss = 0.020457271208629054
Trained batch 963 in epoch 0, gen_loss = 1.047852839826301, disc_loss = 0.02043834292751672
Trained batch 964 in epoch 0, gen_loss = 1.0480071674665639, disc_loss = 0.02041980281241185
Trained batch 965 in epoch 0, gen_loss = 1.0481311881579227, disc_loss = 0.020400967951156593
Trained batch 966 in epoch 0, gen_loss = 1.0480830975439335, disc_loss = 0.02038149920925079
Trained batch 967 in epoch 0, gen_loss = 1.0480831497279572, disc_loss = 0.020362254994670516
Trained batch 968 in epoch 0, gen_loss = 1.048123701099764, disc_loss = 0.020343369036179827
Trained batch 969 in epoch 0, gen_loss = 1.0480583708618105, disc_loss = 0.020324714747095508
Trained batch 970 in epoch 0, gen_loss = 1.0479661293488944, disc_loss = 0.02030572370376297
Trained batch 971 in epoch 0, gen_loss = 1.0478085377272754, disc_loss = 0.02028659814092596
Trained batch 972 in epoch 0, gen_loss = 1.0476599006405347, disc_loss = 0.020268108437938772
Trained batch 973 in epoch 0, gen_loss = 1.0476989877970557, disc_loss = 0.020249426052376132
Trained batch 974 in epoch 0, gen_loss = 1.04773131722059, disc_loss = 0.020230654582100657
Trained batch 975 in epoch 0, gen_loss = 1.047681689781488, disc_loss = 0.02021426504581511
Trained batch 976 in epoch 0, gen_loss = 1.0476757620166732, disc_loss = 0.020196171758555596
Trained batch 977 in epoch 0, gen_loss = 1.0476668184825004, disc_loss = 0.02017808790311645
Trained batch 978 in epoch 0, gen_loss = 1.0475022833303484, disc_loss = 0.02016026886581135
Trained batch 979 in epoch 0, gen_loss = 1.047446834524067, disc_loss = 0.020142586498042542
Trained batch 980 in epoch 0, gen_loss = 1.0474496380816176, disc_loss = 0.020123633808983493
Trained batch 981 in epoch 0, gen_loss = 1.047418657455085, disc_loss = 0.02010476230404813
Trained batch 982 in epoch 0, gen_loss = 1.0473584399642926, disc_loss = 0.020086147162229787
Trained batch 983 in epoch 0, gen_loss = 1.047218416431328, disc_loss = 0.020067675846418966
Trained batch 984 in epoch 0, gen_loss = 1.0471237924195789, disc_loss = 0.02004888344069749
Trained batch 985 in epoch 0, gen_loss = 1.0471246895091286, disc_loss = 0.020029945491628228
Trained batch 986 in epoch 0, gen_loss = 1.047205285309779, disc_loss = 0.020011450514239103
Trained batch 987 in epoch 0, gen_loss = 1.0472790134037555, disc_loss = 0.01999250591357511
Trained batch 988 in epoch 0, gen_loss = 1.0472268344357956, disc_loss = 0.01997329273779172
Trained batch 989 in epoch 0, gen_loss = 1.0472512980603208, disc_loss = 0.019954622656634932
Trained batch 990 in epoch 0, gen_loss = 1.0472234908254547, disc_loss = 0.01993627826297091
Trained batch 991 in epoch 0, gen_loss = 1.0472608344148724, disc_loss = 0.01991779878144664
Trained batch 992 in epoch 0, gen_loss = 1.0471423301031701, disc_loss = 0.019898970754919594
Trained batch 993 in epoch 0, gen_loss = 1.0472998402907814, disc_loss = 0.01988036662902448
Trained batch 994 in epoch 0, gen_loss = 1.0474336716098402, disc_loss = 0.019861656069742686
Trained batch 995 in epoch 0, gen_loss = 1.0475524248308445, disc_loss = 0.019844105531164422
Trained batch 996 in epoch 0, gen_loss = 1.0477187459841895, disc_loss = 0.019825917733941784
Trained batch 997 in epoch 0, gen_loss = 1.0476446231465062, disc_loss = 0.019807655067200107
Trained batch 998 in epoch 0, gen_loss = 1.0475474926862154, disc_loss = 0.019790012289349734
Trained batch 999 in epoch 0, gen_loss = 1.0476619004309178, disc_loss = 0.019772245788859437
Trained batch 1000 in epoch 0, gen_loss = 1.0476170114048948, disc_loss = 0.01975376419058385
Trained batch 1001 in epoch 0, gen_loss = 1.0474774289333415, disc_loss = 0.019735180598479406
Trained batch 1002 in epoch 0, gen_loss = 1.0474041902709934, disc_loss = 0.019716486595284355
Trained batch 1003 in epoch 0, gen_loss = 1.04734962172361, disc_loss = 0.019697888306416507
Trained batch 1004 in epoch 0, gen_loss = 1.047246585704794, disc_loss = 0.01967946823992748
Trained batch 1005 in epoch 0, gen_loss = 1.0472037830421512, disc_loss = 0.019661204137490593
Trained batch 1006 in epoch 0, gen_loss = 1.0471188752452336, disc_loss = 0.019642924817003606
Trained batch 1007 in epoch 0, gen_loss = 1.0471219897329334, disc_loss = 0.019624766951112958
Trained batch 1008 in epoch 0, gen_loss = 1.047159724387943, disc_loss = 0.019606227102179248
Trained batch 1009 in epoch 0, gen_loss = 1.047131684894609, disc_loss = 0.01958783411592047
Trained batch 1010 in epoch 0, gen_loss = 1.0471981849031327, disc_loss = 0.01956958614643152
Trained batch 1011 in epoch 0, gen_loss = 1.047223674479445, disc_loss = 0.019551357947730066
Trained batch 1012 in epoch 0, gen_loss = 1.0471520561279926, disc_loss = 0.019533016125326572
Trained batch 1013 in epoch 0, gen_loss = 1.0469971736213395, disc_loss = 0.01951479382731578
Trained batch 1014 in epoch 0, gen_loss = 1.0469656628047304, disc_loss = 0.01949661178224757
Trained batch 1015 in epoch 0, gen_loss = 1.0469332596389798, disc_loss = 0.019478329040178172
Trained batch 1016 in epoch 0, gen_loss = 1.046859803072002, disc_loss = 0.019460027548501676
Trained batch 1017 in epoch 0, gen_loss = 1.046966645800763, disc_loss = 0.019442169466745502
Trained batch 1018 in epoch 0, gen_loss = 1.046952807137028, disc_loss = 0.01942405563223832
Trained batch 1019 in epoch 0, gen_loss = 1.0469947785431264, disc_loss = 0.01940645726118579
Trained batch 1020 in epoch 0, gen_loss = 1.0469140901096188, disc_loss = 0.01938834355664157
Trained batch 1021 in epoch 0, gen_loss = 1.0467033886921149, disc_loss = 0.01937046974672186
Trained batch 1022 in epoch 0, gen_loss = 1.0468244355969416, disc_loss = 0.019352732568187002
Trained batch 1023 in epoch 0, gen_loss = 1.0468004673311953, disc_loss = 0.019335086951372205
Trained batch 1024 in epoch 0, gen_loss = 1.0468516971134558, disc_loss = 0.019317286794000056
Trained batch 1025 in epoch 0, gen_loss = 1.0467386808369825, disc_loss = 0.019299264640083715
Trained batch 1026 in epoch 0, gen_loss = 1.046708385139965, disc_loss = 0.01928156501359756
Trained batch 1027 in epoch 0, gen_loss = 1.0468742529995712, disc_loss = 0.019264101092609648
Trained batch 1028 in epoch 0, gen_loss = 1.0467724659062916, disc_loss = 0.01924627562815688
Trained batch 1029 in epoch 0, gen_loss = 1.0468779133650863, disc_loss = 0.019228845181930312
Trained batch 1030 in epoch 0, gen_loss = 1.0468954311830112, disc_loss = 0.019211048033005114
Trained batch 1031 in epoch 0, gen_loss = 1.0469168182318063, disc_loss = 0.019193286976686548
Trained batch 1032 in epoch 0, gen_loss = 1.046813932906508, disc_loss = 0.019175459143347517
Trained batch 1033 in epoch 0, gen_loss = 1.046744738228086, disc_loss = 0.01915763279265383
Trained batch 1034 in epoch 0, gen_loss = 1.0467829226007783, disc_loss = 0.01914015200058255
Trained batch 1035 in epoch 0, gen_loss = 1.0466626172878106, disc_loss = 0.019122541773744946
Trained batch 1036 in epoch 0, gen_loss = 1.0467156761809968, disc_loss = 0.01910510507908788
Trained batch 1037 in epoch 0, gen_loss = 1.0466838452914777, disc_loss = 0.01908764044364698
Trained batch 1038 in epoch 0, gen_loss = 1.0467445513339313, disc_loss = 0.019070061156778312
Trained batch 1039 in epoch 0, gen_loss = 1.0467433989334565, disc_loss = 0.01905241236160621
Trained batch 1040 in epoch 0, gen_loss = 1.0467082722672583, disc_loss = 0.01903471894883533
Trained batch 1041 in epoch 0, gen_loss = 1.0467161233331328, disc_loss = 0.019017027629698688
Trained batch 1042 in epoch 0, gen_loss = 1.0467313634640647, disc_loss = 0.018999495890804307
Trained batch 1043 in epoch 0, gen_loss = 1.0465890176280248, disc_loss = 0.018982500275798807
Trained batch 1044 in epoch 0, gen_loss = 1.0466076317301207, disc_loss = 0.018965626628562566
Trained batch 1045 in epoch 0, gen_loss = 1.046608975951348, disc_loss = 0.018948384430011275
Trained batch 1046 in epoch 0, gen_loss = 1.0466092184200213, disc_loss = 0.018931326092695176
Trained batch 1047 in epoch 0, gen_loss = 1.046637667527863, disc_loss = 0.018914285495052807
Trained batch 1048 in epoch 0, gen_loss = 1.0465270078273132, disc_loss = 0.01889696020693021
Trained batch 1049 in epoch 0, gen_loss = 1.0464510517744792, disc_loss = 0.018879769159331254
Trained batch 1050 in epoch 0, gen_loss = 1.046443864433795, disc_loss = 0.0188628929294391
Trained batch 1051 in epoch 0, gen_loss = 1.0464568112909567, disc_loss = 0.018845637899352292
Trained batch 1052 in epoch 0, gen_loss = 1.046375782259962, disc_loss = 0.018828378422284173
Trained batch 1053 in epoch 0, gen_loss = 1.0463653919083795, disc_loss = 0.018811246648357264
Trained batch 1054 in epoch 0, gen_loss = 1.0464041056508702, disc_loss = 0.018794282030074754
Trained batch 1055 in epoch 0, gen_loss = 1.0462800771505996, disc_loss = 0.01877758255175815
Trained batch 1056 in epoch 0, gen_loss = 1.0462111603740036, disc_loss = 0.018760412316572217
Trained batch 1057 in epoch 0, gen_loss = 1.0462458711997773, disc_loss = 0.018743423425471667
Trained batch 1058 in epoch 0, gen_loss = 1.0462302715008387, disc_loss = 0.0187267547073333
Trained batch 1059 in epoch 0, gen_loss = 1.046351504691367, disc_loss = 0.018709957805975067
Trained batch 1060 in epoch 0, gen_loss = 1.046330833215965, disc_loss = 0.01869312390342419
Trained batch 1061 in epoch 0, gen_loss = 1.0464358464753336, disc_loss = 0.0186763913718435
Trained batch 1062 in epoch 0, gen_loss = 1.0463959318730254, disc_loss = 0.018659509924006702
Trained batch 1063 in epoch 0, gen_loss = 1.046328468906476, disc_loss = 0.01864294427888721
Trained batch 1064 in epoch 0, gen_loss = 1.0463757159284583, disc_loss = 0.018626153930347247
Trained batch 1065 in epoch 0, gen_loss = 1.046236421193012, disc_loss = 0.01860934915509766
Trained batch 1066 in epoch 0, gen_loss = 1.0462474496485255, disc_loss = 0.018592588729813175
Trained batch 1067 in epoch 0, gen_loss = 1.046210708438457, disc_loss = 0.01857565461024306
Trained batch 1068 in epoch 0, gen_loss = 1.0461826011942748, disc_loss = 0.018558904443811093
Trained batch 1069 in epoch 0, gen_loss = 1.0461519223228792, disc_loss = 0.01854251560912289
Trained batch 1070 in epoch 0, gen_loss = 1.0460522826813183, disc_loss = 0.01852619570861379
Trained batch 1071 in epoch 0, gen_loss = 1.0460114872444477, disc_loss = 0.018509397307983573
Trained batch 1072 in epoch 0, gen_loss = 1.0459011636209177, disc_loss = 0.018492997936636012
Trained batch 1073 in epoch 0, gen_loss = 1.045867046358643, disc_loss = 0.018476406308208605
Trained batch 1074 in epoch 0, gen_loss = 1.0458188975411793, disc_loss = 0.018459868902627508
Trained batch 1075 in epoch 0, gen_loss = 1.0458006685163452, disc_loss = 0.018443290269519262
Trained batch 1076 in epoch 0, gen_loss = 1.0457822200924352, disc_loss = 0.018426915031894323
Trained batch 1077 in epoch 0, gen_loss = 1.0458370513785527, disc_loss = 0.018410409847927772
Trained batch 1078 in epoch 0, gen_loss = 1.045883945257604, disc_loss = 0.01839386555228656
Trained batch 1079 in epoch 0, gen_loss = 1.0459943748458669, disc_loss = 0.01837770022649676
Trained batch 1080 in epoch 0, gen_loss = 1.0458780062022195, disc_loss = 0.018361175508481976
Trained batch 1081 in epoch 0, gen_loss = 1.0458029435048923, disc_loss = 0.01834484999752479
Trained batch 1082 in epoch 0, gen_loss = 1.0459459291655822, disc_loss = 0.01832879152451986
Trained batch 1083 in epoch 0, gen_loss = 1.0457792049239483, disc_loss = 0.018312685542837225
Trained batch 1084 in epoch 0, gen_loss = 1.0458416321585255, disc_loss = 0.01829676780818043
Trained batch 1085 in epoch 0, gen_loss = 1.0457580417504406, disc_loss = 0.01828090096680764
Trained batch 1086 in epoch 0, gen_loss = 1.0457220694672218, disc_loss = 0.018264926473954744
Trained batch 1087 in epoch 0, gen_loss = 1.0456338675199623, disc_loss = 0.018248655357183452
Trained batch 1088 in epoch 0, gen_loss = 1.0455645346061366, disc_loss = 0.01823250602705116
Trained batch 1089 in epoch 0, gen_loss = 1.0455838435560192, disc_loss = 0.01821645512995887
Trained batch 1090 in epoch 0, gen_loss = 1.0454892655723582, disc_loss = 0.01820034160497803
Trained batch 1091 in epoch 0, gen_loss = 1.0454595176564467, disc_loss = 0.018184312097452138
Trained batch 1092 in epoch 0, gen_loss = 1.0454058337680594, disc_loss = 0.01816839698633611
Trained batch 1093 in epoch 0, gen_loss = 1.0452783311252403, disc_loss = 0.018152284325604662
Trained batch 1094 in epoch 0, gen_loss = 1.0451353640588996, disc_loss = 0.01813623185737854
Trained batch 1095 in epoch 0, gen_loss = 1.0450939152416956, disc_loss = 0.018120151146572724
Trained batch 1096 in epoch 0, gen_loss = 1.045032689841965, disc_loss = 0.0181043459889774
Trained batch 1097 in epoch 0, gen_loss = 1.0450239830492625, disc_loss = 0.018088515975177737
Trained batch 1098 in epoch 0, gen_loss = 1.0448111706532817, disc_loss = 0.01807261541915538
Trained batch 1099 in epoch 0, gen_loss = 1.0447455844824964, disc_loss = 0.018056726871952627
Trained batch 1100 in epoch 0, gen_loss = 1.044681033121251, disc_loss = 0.01804079963232147
Trained batch 1101 in epoch 0, gen_loss = 1.0447043460369543, disc_loss = 0.01802496174909745
Trained batch 1102 in epoch 0, gen_loss = 1.0447155586017443, disc_loss = 0.0180091422235841
Trained batch 1103 in epoch 0, gen_loss = 1.0446651859505884, disc_loss = 0.017993245879894686
Trained batch 1104 in epoch 0, gen_loss = 1.0447114897799168, disc_loss = 0.017977445655791048
Trained batch 1105 in epoch 0, gen_loss = 1.0447242116356845, disc_loss = 0.017961669857935833
Trained batch 1106 in epoch 0, gen_loss = 1.0448144374662622, disc_loss = 0.017946001310313715
Trained batch 1107 in epoch 0, gen_loss = 1.0447938828207957, disc_loss = 0.017930205224594816
Trained batch 1108 in epoch 0, gen_loss = 1.0447287889242818, disc_loss = 0.01791461922359658
Trained batch 1109 in epoch 0, gen_loss = 1.0446359532641936, disc_loss = 0.01789913001501207
Trained batch 1110 in epoch 0, gen_loss = 1.0445517770724722, disc_loss = 0.01788350325004947
Trained batch 1111 in epoch 0, gen_loss = 1.0444780116726597, disc_loss = 0.01786782453441218
Trained batch 1112 in epoch 0, gen_loss = 1.0444866864668392, disc_loss = 0.017852392730733836
Trained batch 1113 in epoch 0, gen_loss = 1.044396364041462, disc_loss = 0.017836808385349404
Trained batch 1114 in epoch 0, gen_loss = 1.0444698294983852, disc_loss = 0.017821396108859765
Trained batch 1115 in epoch 0, gen_loss = 1.044279664407708, disc_loss = 0.01780602166066251
Trained batch 1116 in epoch 0, gen_loss = 1.0443337237664174, disc_loss = 0.017790947642214654
Trained batch 1117 in epoch 0, gen_loss = 1.0443040367902285, disc_loss = 0.017775465199682813
Trained batch 1118 in epoch 0, gen_loss = 1.0443317687490137, disc_loss = 0.017760155190333145
Trained batch 1119 in epoch 0, gen_loss = 1.0443854823442442, disc_loss = 0.017745140643065888
Trained batch 1120 in epoch 0, gen_loss = 1.0443079488868696, disc_loss = 0.017729853888265132
Trained batch 1121 in epoch 0, gen_loss = 1.0443296220266458, disc_loss = 0.017714527344683713
Trained batch 1122 in epoch 0, gen_loss = 1.0442871640063989, disc_loss = 0.01769934525852339
Trained batch 1123 in epoch 0, gen_loss = 1.0442257948034175, disc_loss = 0.017684081974463143
Trained batch 1124 in epoch 0, gen_loss = 1.0442709675100115, disc_loss = 0.01766901152769828
Trained batch 1125 in epoch 0, gen_loss = 1.0441257478024142, disc_loss = 0.017653709241919193
Trained batch 1126 in epoch 0, gen_loss = 1.044049116368831, disc_loss = 0.017638697697959317
Trained batch 1127 in epoch 0, gen_loss = 1.0441035454736112, disc_loss = 0.017623500348474784
Trained batch 1128 in epoch 0, gen_loss = 1.0439908391242538, disc_loss = 0.017608365050365032
Trained batch 1129 in epoch 0, gen_loss = 1.0439754212588335, disc_loss = 0.01759331168545579
Trained batch 1130 in epoch 0, gen_loss = 1.0440168477443337, disc_loss = 0.0175781846050565
Trained batch 1131 in epoch 0, gen_loss = 1.0440251612147258, disc_loss = 0.01756328197612424
Trained batch 1132 in epoch 0, gen_loss = 1.0440415838126682, disc_loss = 0.01754822747967644
Trained batch 1133 in epoch 0, gen_loss = 1.0440007466855714, disc_loss = 0.017533318605171305
Trained batch 1134 in epoch 0, gen_loss = 1.0439605049362266, disc_loss = 0.017518264999549574
Trained batch 1135 in epoch 0, gen_loss = 1.0437010914139764, disc_loss = 0.017503876624225957
Trained batch 1136 in epoch 0, gen_loss = 1.0436426400876193, disc_loss = 0.017489103106155226
Trained batch 1137 in epoch 0, gen_loss = 1.043643174224872, disc_loss = 0.017474477573401034
Trained batch 1138 in epoch 0, gen_loss = 1.0437409866002696, disc_loss = 0.01745957417947733
Trained batch 1139 in epoch 0, gen_loss = 1.0436555006786397, disc_loss = 0.01744463351417819
Trained batch 1140 in epoch 0, gen_loss = 1.0436426817743951, disc_loss = 0.017429753879323318
Trained batch 1141 in epoch 0, gen_loss = 1.0436663000001172, disc_loss = 0.01741494672566521
Trained batch 1142 in epoch 0, gen_loss = 1.0437041957808084, disc_loss = 0.01740007606128329
Trained batch 1143 in epoch 0, gen_loss = 1.0436479436507176, disc_loss = 0.01738532581670357
Trained batch 1144 in epoch 0, gen_loss = 1.0434775475070988, disc_loss = 0.01737076063077657
Trained batch 1145 in epoch 0, gen_loss = 1.0434334094247686, disc_loss = 0.017356118362159858
Trained batch 1146 in epoch 0, gen_loss = 1.0434604843959876, disc_loss = 0.01734140016048324
Trained batch 1147 in epoch 0, gen_loss = 1.043424922648415, disc_loss = 0.01732672480798877
Trained batch 1148 in epoch 0, gen_loss = 1.0434348643656084, disc_loss = 0.017311977854107357
Trained batch 1149 in epoch 0, gen_loss = 1.043408177650493, disc_loss = 0.017297269443237305
Trained batch 1150 in epoch 0, gen_loss = 1.0432466633365425, disc_loss = 0.01728254748329008
Trained batch 1151 in epoch 0, gen_loss = 1.0431099576720346, disc_loss = 0.017267992631205844
Trained batch 1152 in epoch 0, gen_loss = 1.0430050631088479, disc_loss = 0.01725360839581743
Trained batch 1153 in epoch 0, gen_loss = 1.0430292652167727, disc_loss = 0.01723911867440582
Trained batch 1154 in epoch 0, gen_loss = 1.042991312112643, disc_loss = 0.017224752324712926
Trained batch 1155 in epoch 0, gen_loss = 1.0429916085617352, disc_loss = 0.01721056799183678
Trained batch 1156 in epoch 0, gen_loss = 1.0429202053138895, disc_loss = 0.01719622649490377
Trained batch 1157 in epoch 0, gen_loss = 1.0428001512877887, disc_loss = 0.01718248668503654
Trained batch 1158 in epoch 0, gen_loss = 1.042864769440051, disc_loss = 0.01716857637585393
Trained batch 1159 in epoch 0, gen_loss = 1.0429223874262694, disc_loss = 0.017154444334903082
Trained batch 1160 in epoch 0, gen_loss = 1.0429761844858028, disc_loss = 0.017140521758317612
Trained batch 1161 in epoch 0, gen_loss = 1.0428737265774388, disc_loss = 0.017126254990820936
Trained batch 1162 in epoch 0, gen_loss = 1.04292861934069, disc_loss = 0.017112551785612908
Trained batch 1163 in epoch 0, gen_loss = 1.0430525073531978, disc_loss = 0.017098531606114076
Trained batch 1164 in epoch 0, gen_loss = 1.0430231013778966, disc_loss = 0.017084738973487175
Trained batch 1165 in epoch 0, gen_loss = 1.0430714193840174, disc_loss = 0.017070700701797982
Trained batch 1166 in epoch 0, gen_loss = 1.0431529881357635, disc_loss = 0.017056541345771538
Trained batch 1167 in epoch 0, gen_loss = 1.043063298352573, disc_loss = 0.017042476930415332
Trained batch 1168 in epoch 0, gen_loss = 1.043041486608564, disc_loss = 0.01702840338644637
Trained batch 1169 in epoch 0, gen_loss = 1.0429812317475295, disc_loss = 0.017014207019227852
Trained batch 1170 in epoch 0, gen_loss = 1.042929240849973, disc_loss = 0.01700007060579884
Trained batch 1171 in epoch 0, gen_loss = 1.0428789666132308, disc_loss = 0.0169859531103298
Trained batch 1172 in epoch 0, gen_loss = 1.0427284470147185, disc_loss = 0.016972100480284164
Trained batch 1173 in epoch 0, gen_loss = 1.042711602032083, disc_loss = 0.016958068203584812
Trained batch 1174 in epoch 0, gen_loss = 1.04278362647016, disc_loss = 0.016944205936866793
Trained batch 1175 in epoch 0, gen_loss = 1.0427496316430926, disc_loss = 0.01693034733430408
Trained batch 1176 in epoch 0, gen_loss = 1.0427128424711316, disc_loss = 0.01691653933897322
Trained batch 1177 in epoch 0, gen_loss = 1.0426987963894632, disc_loss = 0.016902885731018714
Trained batch 1178 in epoch 0, gen_loss = 1.0426485396675178, disc_loss = 0.01688888198914294
Trained batch 1179 in epoch 0, gen_loss = 1.0426997625979326, disc_loss = 0.01687516569602895
Trained batch 1180 in epoch 0, gen_loss = 1.0426380756696738, disc_loss = 0.016861275643177107
Trained batch 1181 in epoch 0, gen_loss = 1.0426490228440355, disc_loss = 0.01684742188088532
Trained batch 1182 in epoch 0, gen_loss = 1.0425317455980603, disc_loss = 0.01683349602147508
Trained batch 1183 in epoch 0, gen_loss = 1.0425430615054998, disc_loss = 0.016819633260933484
Trained batch 1184 in epoch 0, gen_loss = 1.0425069975702068, disc_loss = 0.0168059010634578
Trained batch 1185 in epoch 0, gen_loss = 1.042439103252168, disc_loss = 0.016792072589613433
Trained batch 1186 in epoch 0, gen_loss = 1.0425448165837716, disc_loss = 0.016778460100504804
Trained batch 1187 in epoch 0, gen_loss = 1.0425417954321663, disc_loss = 0.01676494125260635
Trained batch 1188 in epoch 0, gen_loss = 1.042518064016249, disc_loss = 0.016751338736363863
Trained batch 1189 in epoch 0, gen_loss = 1.0424181740574476, disc_loss = 0.016737555748633375
Trained batch 1190 in epoch 0, gen_loss = 1.0424470816161029, disc_loss = 0.01672386666563868
Trained batch 1191 in epoch 0, gen_loss = 1.0425011510366962, disc_loss = 0.016710268778681727
Trained batch 1192 in epoch 0, gen_loss = 1.0423557359384872, disc_loss = 0.016696829987647502
Trained batch 1193 in epoch 0, gen_loss = 1.0422937848310374, disc_loss = 0.016683295903327858
Trained batch 1194 in epoch 0, gen_loss = 1.0423182368029111, disc_loss = 0.016669687107677873
Trained batch 1195 in epoch 0, gen_loss = 1.0423199345286076, disc_loss = 0.016656129925245462
Trained batch 1196 in epoch 0, gen_loss = 1.0422501141017142, disc_loss = 0.01664258610972541
Trained batch 1197 in epoch 0, gen_loss = 1.0423282409997934, disc_loss = 0.016629119968366923
Trained batch 1198 in epoch 0, gen_loss = 1.0423739518445168, disc_loss = 0.016615520297182457
Trained batch 1199 in epoch 0, gen_loss = 1.042283475920558, disc_loss = 0.016602075084253255
Trained batch 1200 in epoch 0, gen_loss = 1.0423073847277973, disc_loss = 0.01658890561201551
Trained batch 1201 in epoch 0, gen_loss = 1.0422750272340267, disc_loss = 0.01657558187677044
Trained batch 1202 in epoch 0, gen_loss = 1.0422300960704474, disc_loss = 0.016562174159485934
Trained batch 1203 in epoch 0, gen_loss = 1.0421800679988242, disc_loss = 0.01654879380099416
Trained batch 1204 in epoch 0, gen_loss = 1.042028168894938, disc_loss = 0.016535306570537513
Trained batch 1205 in epoch 0, gen_loss = 1.0419495148494666, disc_loss = 0.016522058002649966
Trained batch 1206 in epoch 0, gen_loss = 1.0419031811975308, disc_loss = 0.016508835534717155
Trained batch 1207 in epoch 0, gen_loss = 1.0418222633665366, disc_loss = 0.01649568997069481
Trained batch 1208 in epoch 0, gen_loss = 1.041792220498433, disc_loss = 0.016482518191662725
Trained batch 1209 in epoch 0, gen_loss = 1.0416432856774527, disc_loss = 0.016469212247382018
Trained batch 1210 in epoch 0, gen_loss = 1.0416188918540146, disc_loss = 0.01645593705259665
Trained batch 1211 in epoch 0, gen_loss = 1.041581221957608, disc_loss = 0.016442756914053797
Trained batch 1212 in epoch 0, gen_loss = 1.04159499740463, disc_loss = 0.01642958723161326
Trained batch 1213 in epoch 0, gen_loss = 1.0415557637884354, disc_loss = 0.016416315719848914
Trained batch 1214 in epoch 0, gen_loss = 1.0414887154789128, disc_loss = 0.01640331349824268
Trained batch 1215 in epoch 0, gen_loss = 1.0413480300309235, disc_loss = 0.01639016819913913
Trained batch 1216 in epoch 0, gen_loss = 1.0413161114825513, disc_loss = 0.016377059694931705
Trained batch 1217 in epoch 0, gen_loss = 1.0412350085323863, disc_loss = 0.01636392302809808
Trained batch 1218 in epoch 0, gen_loss = 1.041164359198524, disc_loss = 0.016350953501026156
Trained batch 1219 in epoch 0, gen_loss = 1.0409485163014442, disc_loss = 0.016338096980862395
Trained batch 1220 in epoch 0, gen_loss = 1.0408261457639674, disc_loss = 0.016325506076302888
Trained batch 1221 in epoch 0, gen_loss = 1.0408360812502095, disc_loss = 0.016313253216648935
Trained batch 1222 in epoch 0, gen_loss = 1.040907428655484, disc_loss = 0.016300817568236634
Trained batch 1223 in epoch 0, gen_loss = 1.0408533938910836, disc_loss = 0.016287949283757958
Trained batch 1224 in epoch 0, gen_loss = 1.0408984389353773, disc_loss = 0.016275164270060784
Trained batch 1225 in epoch 0, gen_loss = 1.0409363530345297, disc_loss = 0.01626227288562474
Trained batch 1226 in epoch 0, gen_loss = 1.040906259730859, disc_loss = 0.01624940003952681
Trained batch 1227 in epoch 0, gen_loss = 1.0408744583640503, disc_loss = 0.016236606586314224
Trained batch 1228 in epoch 0, gen_loss = 1.0409603003227585, disc_loss = 0.016224132196699628
Trained batch 1229 in epoch 0, gen_loss = 1.0410189043942506, disc_loss = 0.016211450749126118
Trained batch 1230 in epoch 0, gen_loss = 1.0409726192804007, disc_loss = 0.01619879955460471
Trained batch 1231 in epoch 0, gen_loss = 1.0409986888385052, disc_loss = 0.01618621550378875
Trained batch 1232 in epoch 0, gen_loss = 1.0409689853322863, disc_loss = 0.0161734706684575
Trained batch 1233 in epoch 0, gen_loss = 1.0410500504740634, disc_loss = 0.016160890793010276
Trained batch 1234 in epoch 0, gen_loss = 1.0411116595934278, disc_loss = 0.01614812106327229
Trained batch 1235 in epoch 0, gen_loss = 1.0411277133428936, disc_loss = 0.016135503507035968
Trained batch 1236 in epoch 0, gen_loss = 1.0411430191348037, disc_loss = 0.016122770744401105
Trained batch 1237 in epoch 0, gen_loss = 1.0410230977517916, disc_loss = 0.016110439260532742
Trained batch 1238 in epoch 0, gen_loss = 1.0410184078249265, disc_loss = 0.016097824379797617
Trained batch 1239 in epoch 0, gen_loss = 1.0410619065886544, disc_loss = 0.016085253977648643
Trained batch 1240 in epoch 0, gen_loss = 1.0409496409531853, disc_loss = 0.016072633768162425
Trained batch 1241 in epoch 0, gen_loss = 1.041017169225811, disc_loss = 0.016060044757377705
Trained batch 1242 in epoch 0, gen_loss = 1.0409911338446702, disc_loss = 0.016047422841709402
Trained batch 1243 in epoch 0, gen_loss = 1.0408945083378596, disc_loss = 0.01603472589307773
Trained batch 1244 in epoch 0, gen_loss = 1.040877170423906, disc_loss = 0.016022190897717108
Trained batch 1245 in epoch 0, gen_loss = 1.0407613407503544, disc_loss = 0.016009632791703633
Trained batch 1246 in epoch 0, gen_loss = 1.0407154877231708, disc_loss = 0.015997313901636587
Trained batch 1247 in epoch 0, gen_loss = 1.0408266388978331, disc_loss = 0.01598486372954656
Trained batch 1248 in epoch 0, gen_loss = 1.0408516323165573, disc_loss = 0.015972445520064014
Trained batch 1249 in epoch 0, gen_loss = 1.040904886698723, disc_loss = 0.015960068750963546
Trained batch 1250 in epoch 0, gen_loss = 1.0408789355644315, disc_loss = 0.01594763491399974
Trained batch 1251 in epoch 0, gen_loss = 1.040911768072139, disc_loss = 0.015935335524011808
Trained batch 1252 in epoch 0, gen_loss = 1.040786356114428, disc_loss = 0.015923022579342083
Trained batch 1253 in epoch 0, gen_loss = 1.0408115197549406, disc_loss = 0.0159107480875424
Trained batch 1254 in epoch 0, gen_loss = 1.0408554326728046, disc_loss = 0.015898648167953854
Trained batch 1255 in epoch 0, gen_loss = 1.0408714798747734, disc_loss = 0.01588642060503925
Trained batch 1256 in epoch 0, gen_loss = 1.040752127019773, disc_loss = 0.015874044551203278
Trained batch 1257 in epoch 0, gen_loss = 1.0406750069845272, disc_loss = 0.01586171252509936
Trained batch 1258 in epoch 0, gen_loss = 1.0407042266405984, disc_loss = 0.015849408769619083
Trained batch 1259 in epoch 0, gen_loss = 1.0405581733300573, disc_loss = 0.015837048656041068
Trained batch 1260 in epoch 0, gen_loss = 1.040525970503416, disc_loss = 0.015824814109394066
Trained batch 1261 in epoch 0, gen_loss = 1.0405021019622376, disc_loss = 0.015812582454926234
Trained batch 1262 in epoch 0, gen_loss = 1.040450821744952, disc_loss = 0.01580040049140975
Trained batch 1263 in epoch 0, gen_loss = 1.0403930525283647, disc_loss = 0.015788134495145458
Trained batch 1264 in epoch 0, gen_loss = 1.0403779003695537, disc_loss = 0.015775912407792095
Trained batch 1265 in epoch 0, gen_loss = 1.0403643121698645, disc_loss = 0.01576366838848286
Trained batch 1266 in epoch 0, gen_loss = 1.040353704011619, disc_loss = 0.015751465019933884
Trained batch 1267 in epoch 0, gen_loss = 1.0401808710457399, disc_loss = 0.015739253746598666
Trained batch 1268 in epoch 0, gen_loss = 1.0400932376031522, disc_loss = 0.015727151360149384
Trained batch 1269 in epoch 0, gen_loss = 1.0400800010116082, disc_loss = 0.015715110628965575
Trained batch 1270 in epoch 0, gen_loss = 1.0400665252580126, disc_loss = 0.015703144158500656
Trained batch 1271 in epoch 0, gen_loss = 1.0399761971015975, disc_loss = 0.01569106526107329
Trained batch 1272 in epoch 0, gen_loss = 1.0399675266956216, disc_loss = 0.015679313039842616
Trained batch 1273 in epoch 0, gen_loss = 1.0398881541831153, disc_loss = 0.015667263651517983
Trained batch 1274 in epoch 0, gen_loss = 1.039772110195721, disc_loss = 0.015655298072881265
Trained batch 1275 in epoch 0, gen_loss = 1.0397877219749094, disc_loss = 0.015643341762635404
Trained batch 1276 in epoch 0, gen_loss = 1.0397278719006242, disc_loss = 0.015631293345338644
Trained batch 1277 in epoch 0, gen_loss = 1.03965183843003, disc_loss = 0.015619304547851893
Trained batch 1278 in epoch 0, gen_loss = 1.0395128407964862, disc_loss = 0.015607363159000616
Trained batch 1279 in epoch 0, gen_loss = 1.0393344468669965, disc_loss = 0.01559552133815032
Trained batch 1280 in epoch 0, gen_loss = 1.0393068592451589, disc_loss = 0.015583634586841382
Trained batch 1281 in epoch 0, gen_loss = 1.0391737486986958, disc_loss = 0.015571868433209329
Trained batch 1282 in epoch 0, gen_loss = 1.0391901282946392, disc_loss = 0.015560141034399443
Trained batch 1283 in epoch 0, gen_loss = 1.0392816809711056, disc_loss = 0.015548805165538134
Trained batch 1284 in epoch 0, gen_loss = 1.0392042337456566, disc_loss = 0.01553716156982766
Trained batch 1285 in epoch 0, gen_loss = 1.039251415600673, disc_loss = 0.015525382204177901
Trained batch 1286 in epoch 0, gen_loss = 1.039244856983539, disc_loss = 0.01551363121627442
Trained batch 1287 in epoch 0, gen_loss = 1.0391585590167445, disc_loss = 0.01550181639623074
Trained batch 1288 in epoch 0, gen_loss = 1.0390798917706388, disc_loss = 0.0154899819192534
Trained batch 1289 in epoch 0, gen_loss = 1.0390609542297762, disc_loss = 0.015478165437108223
Trained batch 1290 in epoch 0, gen_loss = 1.0389847612537957, disc_loss = 0.015466388762047721
Trained batch 1291 in epoch 0, gen_loss = 1.0389873236187102, disc_loss = 0.015454658520908597
Trained batch 1292 in epoch 0, gen_loss = 1.0388944843482897, disc_loss = 0.0154429020256842
Trained batch 1293 in epoch 0, gen_loss = 1.0389276535885044, disc_loss = 0.015431327084746928
Trained batch 1294 in epoch 0, gen_loss = 1.03890012343878, disc_loss = 0.015419644861806608
Trained batch 1295 in epoch 0, gen_loss = 1.0388455080259362, disc_loss = 0.01540811053149091
Trained batch 1296 in epoch 0, gen_loss = 1.0388559125300638, disc_loss = 0.015396494665417393
Trained batch 1297 in epoch 0, gen_loss = 1.0388249604516477, disc_loss = 0.015385247118727487
Trained batch 1298 in epoch 0, gen_loss = 1.038818282586414, disc_loss = 0.015373638521960031
Trained batch 1299 in epoch 0, gen_loss = 1.0387677344221335, disc_loss = 0.015362034704594407
Trained batch 1300 in epoch 0, gen_loss = 1.0388461211431401, disc_loss = 0.015350684147380217
Trained batch 1301 in epoch 0, gen_loss = 1.0388592366478226, disc_loss = 0.015339183290862764
Trained batch 1302 in epoch 0, gen_loss = 1.0388321835584853, disc_loss = 0.015327582917936863
Trained batch 1303 in epoch 0, gen_loss = 1.0388671814526882, disc_loss = 0.015316036556175328
Trained batch 1304 in epoch 0, gen_loss = 1.0388292937671544, disc_loss = 0.015304587786112666
Trained batch 1305 in epoch 0, gen_loss = 1.0387747392948334, disc_loss = 0.015293425761015621
Trained batch 1306 in epoch 0, gen_loss = 1.0388135245353463, disc_loss = 0.0152823455993716
Trained batch 1307 in epoch 0, gen_loss = 1.0388123501741557, disc_loss = 0.015271291813160939
Trained batch 1308 in epoch 0, gen_loss = 1.0387537155422752, disc_loss = 0.015260135006380814
Trained batch 1309 in epoch 0, gen_loss = 1.0387093463244328, disc_loss = 0.015248985687548025
Trained batch 1310 in epoch 0, gen_loss = 1.0387143495199245, disc_loss = 0.015237699352440294
Trained batch 1311 in epoch 0, gen_loss = 1.0386907471253015, disc_loss = 0.015226458493155562
Trained batch 1312 in epoch 0, gen_loss = 1.0387917417700927, disc_loss = 0.01521514776040536
Trained batch 1313 in epoch 0, gen_loss = 1.0387289052548474, disc_loss = 0.015203812832906354
Trained batch 1314 in epoch 0, gen_loss = 1.0384842607231648, disc_loss = 0.015193020602747508
Trained batch 1315 in epoch 0, gen_loss = 1.0385450866854662, disc_loss = 0.015181954712199158
Trained batch 1316 in epoch 0, gen_loss = 1.0384978936446283, disc_loss = 0.015170814519907733
Trained batch 1317 in epoch 0, gen_loss = 1.0385079531957238, disc_loss = 0.015159561519517403
Trained batch 1318 in epoch 0, gen_loss = 1.0384554161864579, disc_loss = 0.015148364810994668
Trained batch 1319 in epoch 0, gen_loss = 1.0383401596410708, disc_loss = 0.015137226657216988
Trained batch 1320 in epoch 0, gen_loss = 1.0382887436574737, disc_loss = 0.015126045229570674
Trained batch 1321 in epoch 0, gen_loss = 1.0381839135816706, disc_loss = 0.015114883773995573
Trained batch 1322 in epoch 0, gen_loss = 1.0381367882137846, disc_loss = 0.015103675719896664
Trained batch 1323 in epoch 0, gen_loss = 1.0380481546604021, disc_loss = 0.015092458215617227
Trained batch 1324 in epoch 0, gen_loss = 1.0380443404080733, disc_loss = 0.015081256745176672
Trained batch 1325 in epoch 0, gen_loss = 1.0380320277733681, disc_loss = 0.015070128725038498
Trained batch 1326 in epoch 0, gen_loss = 1.0378872278990743, disc_loss = 0.015059038202953647
Trained batch 1327 in epoch 0, gen_loss = 1.0379241796277732, disc_loss = 0.015047905881651074
Trained batch 1328 in epoch 0, gen_loss = 1.0378657783710301, disc_loss = 0.015036838854809534
Trained batch 1329 in epoch 0, gen_loss = 1.0377536203404119, disc_loss = 0.0150257649381568
Trained batch 1330 in epoch 0, gen_loss = 1.0376466294816344, disc_loss = 0.015014708074419196
Trained batch 1331 in epoch 0, gen_loss = 1.0374888971716434, disc_loss = 0.01500405794457573
Trained batch 1332 in epoch 0, gen_loss = 1.0374106144824604, disc_loss = 0.014993129301453268
Trained batch 1333 in epoch 0, gen_loss = 1.0373778392126536, disc_loss = 0.014982310876863237
Trained batch 1334 in epoch 0, gen_loss = 1.037263262026319, disc_loss = 0.014971619354576667
Trained batch 1335 in epoch 0, gen_loss = 1.0373331787298896, disc_loss = 0.014960968964363722
Trained batch 1336 in epoch 0, gen_loss = 1.0373324459626234, disc_loss = 0.01495082456562473
Trained batch 1337 in epoch 0, gen_loss = 1.037220709638389, disc_loss = 0.014941450239138981
Trained batch 1338 in epoch 0, gen_loss = 1.0371148797048393, disc_loss = 0.014955048369437795
Trained batch 1339 in epoch 0, gen_loss = 1.0373714849797648, disc_loss = 0.014979022199291486
Trained batch 1340 in epoch 0, gen_loss = 1.0374943958255092, disc_loss = 0.01499582212885368
Trained batch 1341 in epoch 0, gen_loss = 1.0374731114786535, disc_loss = 0.015025376865585457
Trained batch 1342 in epoch 0, gen_loss = 1.03749993674274, disc_loss = 0.015038836270391149
Trained batch 1343 in epoch 0, gen_loss = 1.0376015153624827, disc_loss = 0.015036787972955304
Trained batch 1344 in epoch 0, gen_loss = 1.0376876773222672, disc_loss = 0.015031968459545818
Trained batch 1345 in epoch 0, gen_loss = 1.0373713035153067, disc_loss = 0.015226650643449576
Trained batch 1346 in epoch 0, gen_loss = 1.037625917015734, disc_loss = 0.015794209132794466
Trained batch 1347 in epoch 0, gen_loss = 1.0373732227644157, disc_loss = 0.01599084879750129
Trained batch 1348 in epoch 0, gen_loss = 1.0370609462703042, disc_loss = 0.01620655317210542
Trained batch 1349 in epoch 0, gen_loss = 1.036854915994185, disc_loss = 0.01638744629997139
Trained batch 1350 in epoch 0, gen_loss = 1.0365493016318865, disc_loss = 0.016532995648558722
Trained batch 1351 in epoch 0, gen_loss = 1.0363570749980104, disc_loss = 0.016672463743956402
Trained batch 1352 in epoch 0, gen_loss = 1.0361200110478834, disc_loss = 0.0167785171683188
Trained batch 1353 in epoch 0, gen_loss = 1.035769798664962, disc_loss = 0.016904912931047397
Trained batch 1354 in epoch 0, gen_loss = 1.0354172748173296, disc_loss = 0.016982588714342634
Trained batch 1355 in epoch 0, gen_loss = 1.035159818652281, disc_loss = 0.017030137712716272
Trained batch 1356 in epoch 0, gen_loss = 1.035005855951225, disc_loss = 0.01706634022993109
Trained batch 1357 in epoch 0, gen_loss = 1.0347994696979845, disc_loss = 0.01707840872805398
Trained batch 1358 in epoch 0, gen_loss = 1.0347554565046182, disc_loss = 0.017080639156024983
Trained batch 1359 in epoch 0, gen_loss = 1.0347005287733149, disc_loss = 0.017076801239625853
Trained batch 1360 in epoch 0, gen_loss = 1.0346244569432639, disc_loss = 0.01706943753020445
Trained batch 1361 in epoch 0, gen_loss = 1.034577914599805, disc_loss = 0.017060514131000896
Trained batch 1362 in epoch 0, gen_loss = 1.0343988966565751, disc_loss = 0.017055583803201133
Trained batch 1363 in epoch 0, gen_loss = 1.0343086882289554, disc_loss = 0.01708989327507506
Trained batch 1364 in epoch 0, gen_loss = 1.0343740568274544, disc_loss = 0.017513787979515943
Trained batch 1365 in epoch 0, gen_loss = 1.0342647396409843, disc_loss = 0.017713495737196
Trained batch 1366 in epoch 0, gen_loss = 1.0340927530355322, disc_loss = 0.0178548243717238
Trained batch 1367 in epoch 0, gen_loss = 1.0339401304416838, disc_loss = 0.01798607899553118
Trained batch 1368 in epoch 0, gen_loss = 1.033732570832972, disc_loss = 0.01806410645171143
Trained batch 1369 in epoch 0, gen_loss = 1.0336874490454249, disc_loss = 0.018134287117732295
Trained batch 1370 in epoch 0, gen_loss = 1.033533185763919, disc_loss = 0.01817389195426595
Trained batch 1371 in epoch 0, gen_loss = 1.0332910731956146, disc_loss = 0.01820109743441987
Trained batch 1372 in epoch 0, gen_loss = 1.0331005039261973, disc_loss = 0.018229474650423915
Trained batch 1373 in epoch 0, gen_loss = 1.033191635337112, disc_loss = 0.018250411732635412
Trained batch 1374 in epoch 0, gen_loss = 1.0333257094946775, disc_loss = 0.018248189562846993
Trained batch 1375 in epoch 0, gen_loss = 1.0332995359677561, disc_loss = 0.018240036091684002
Trained batch 1376 in epoch 0, gen_loss = 1.0333757501152345, disc_loss = 0.018236309858143854
Trained batch 1377 in epoch 0, gen_loss = 1.0334960158443935, disc_loss = 0.018228380106938988
Trained batch 1378 in epoch 0, gen_loss = 1.0336655178867102, disc_loss = 0.018218436746512277
Trained batch 1379 in epoch 0, gen_loss = 1.0337223201774168, disc_loss = 0.0182099430269285
Trained batch 1380 in epoch 0, gen_loss = 1.0338820572308576, disc_loss = 0.01820057110126204
Trained batch 1381 in epoch 0, gen_loss = 1.0339108981763574, disc_loss = 0.0181901023893175
Trained batch 1382 in epoch 0, gen_loss = 1.0340196722801922, disc_loss = 0.018179198918343586
Trained batch 1383 in epoch 0, gen_loss = 1.0340163346186193, disc_loss = 0.01817241332076848
Trained batch 1384 in epoch 0, gen_loss = 1.0340926108592685, disc_loss = 0.018163512150306482
Trained batch 1385 in epoch 0, gen_loss = 1.0340946417565298, disc_loss = 0.018152492183101367
Trained batch 1386 in epoch 0, gen_loss = 1.0341026074136859, disc_loss = 0.018142326861615248
Trained batch 1387 in epoch 0, gen_loss = 1.0341119915032249, disc_loss = 0.01813030527843906
Trained batch 1388 in epoch 0, gen_loss = 1.0341078982111187, disc_loss = 0.018118574199785697
Trained batch 1389 in epoch 0, gen_loss = 1.0341038202424702, disc_loss = 0.018106723636164324
Trained batch 1390 in epoch 0, gen_loss = 1.0340760046633604, disc_loss = 0.018094936758430446
Trained batch 1391 in epoch 0, gen_loss = 1.0341740945332694, disc_loss = 0.01808418131785684
Trained batch 1392 in epoch 0, gen_loss = 1.034261732523337, disc_loss = 0.018074534225113133
Trained batch 1393 in epoch 0, gen_loss = 1.0343280941076909, disc_loss = 0.018062923080020638
Trained batch 1394 in epoch 0, gen_loss = 1.0343152217326625, disc_loss = 0.018053209181294164
Trained batch 1395 in epoch 0, gen_loss = 1.034388297971306, disc_loss = 0.01804228798108693
Trained batch 1396 in epoch 0, gen_loss = 1.0343275424106342, disc_loss = 0.018032978828489758
Trained batch 1397 in epoch 0, gen_loss = 1.0343676097531176, disc_loss = 0.018022783747301284
Trained batch 1398 in epoch 0, gen_loss = 1.0343610394887195, disc_loss = 0.018011259977699784
Trained batch 1399 in epoch 0, gen_loss = 1.0344534986146858, disc_loss = 0.01799959295836743
Trained batch 1400 in epoch 0, gen_loss = 1.0344394697920074, disc_loss = 0.017989059875860178
Trained batch 1401 in epoch 0, gen_loss = 1.0344837061986434, disc_loss = 0.017977962693277238
Trained batch 1402 in epoch 0, gen_loss = 1.0345408369070788, disc_loss = 0.01796632405034919
Trained batch 1403 in epoch 0, gen_loss = 1.0346834992199203, disc_loss = 0.017954715194931505
Trained batch 1404 in epoch 0, gen_loss = 1.0346460271348308, disc_loss = 0.017942928929988864
Trained batch 1405 in epoch 0, gen_loss = 1.0345858024541887, disc_loss = 0.017931496990436575
Trained batch 1406 in epoch 0, gen_loss = 1.0345276058906347, disc_loss = 0.01792053505149488
Trained batch 1407 in epoch 0, gen_loss = 1.03449379443191, disc_loss = 0.01790857543743517
Trained batch 1408 in epoch 0, gen_loss = 1.0345277535187767, disc_loss = 0.017896880947960297
Trained batch 1409 in epoch 0, gen_loss = 1.0345291593607435, disc_loss = 0.017885797463377266
Trained batch 1410 in epoch 0, gen_loss = 1.034576755415709, disc_loss = 0.017874070548820082
Trained batch 1411 in epoch 0, gen_loss = 1.0346510879083328, disc_loss = 0.017864400408133106
Trained batch 1412 in epoch 0, gen_loss = 1.0347097456792695, disc_loss = 0.01785424784661626
Trained batch 1413 in epoch 0, gen_loss = 1.0347039660984252, disc_loss = 0.01784247213555039
Trained batch 1414 in epoch 0, gen_loss = 1.034634174622411, disc_loss = 0.017830699143681163
Trained batch 1415 in epoch 0, gen_loss = 1.0345957331191011, disc_loss = 0.017819533455889346
Trained batch 1416 in epoch 0, gen_loss = 1.0346314577082134, disc_loss = 0.017807538654483018
Trained batch 1417 in epoch 0, gen_loss = 1.03469876205215, disc_loss = 0.017795893326464106
Trained batch 1418 in epoch 0, gen_loss = 1.0346289444885428, disc_loss = 0.017785876036793588
Trained batch 1419 in epoch 0, gen_loss = 1.0346356550782498, disc_loss = 0.01777470332650717
Trained batch 1420 in epoch 0, gen_loss = 1.0346498279022884, disc_loss = 0.017764221133390948
Trained batch 1421 in epoch 0, gen_loss = 1.0346681001359066, disc_loss = 0.01775263389187725
Trained batch 1422 in epoch 0, gen_loss = 1.0346941751279382, disc_loss = 0.017742064269439552
Trained batch 1423 in epoch 0, gen_loss = 1.0346387951436002, disc_loss = 0.017730265058826567
Trained batch 1424 in epoch 0, gen_loss = 1.0347150359446542, disc_loss = 0.01771998329345431
Trained batch 1425 in epoch 0, gen_loss = 1.0347673502785961, disc_loss = 0.01770926132528954
Trained batch 1426 in epoch 0, gen_loss = 1.0347366444322723, disc_loss = 0.017698590194644273
Trained batch 1427 in epoch 0, gen_loss = 1.0347189924337952, disc_loss = 0.017686934769406318
Trained batch 1428 in epoch 0, gen_loss = 1.0346843369821304, disc_loss = 0.017675186057302623
Trained batch 1429 in epoch 0, gen_loss = 1.0345882782360891, disc_loss = 0.017663439066015783
Trained batch 1430 in epoch 0, gen_loss = 1.034605975233534, disc_loss = 0.01765213416933891
Trained batch 1431 in epoch 0, gen_loss = 1.0346649825864331, disc_loss = 0.017641447718868514
Trained batch 1432 in epoch 0, gen_loss = 1.0345842914196968, disc_loss = 0.017629765689019465
Trained batch 1433 in epoch 0, gen_loss = 1.0346540232790398, disc_loss = 0.017618746118752526
Trained batch 1434 in epoch 0, gen_loss = 1.0347786366939544, disc_loss = 0.01760774018106664
Trained batch 1435 in epoch 0, gen_loss = 1.0348437999823963, disc_loss = 0.017596223475174814
Trained batch 1436 in epoch 0, gen_loss = 1.0347805325779222, disc_loss = 0.01758485999999849
Trained batch 1437 in epoch 0, gen_loss = 1.0348000008099931, disc_loss = 0.017573138490796572
Trained batch 1438 in epoch 0, gen_loss = 1.0348152915291524, disc_loss = 0.017561623899352202
Trained batch 1439 in epoch 0, gen_loss = 1.0347975186796652, disc_loss = 0.01755001570903308
Trained batch 1440 in epoch 0, gen_loss = 1.0348000139887346, disc_loss = 0.017538494034702607
Trained batch 1441 in epoch 0, gen_loss = 1.0348167725930433, disc_loss = 0.01752681347100554
Trained batch 1442 in epoch 0, gen_loss = 1.0348135093930522, disc_loss = 0.01751540940031777
Trained batch 1443 in epoch 0, gen_loss = 1.0348742153299482, disc_loss = 0.017504032577139356
Trained batch 1444 in epoch 0, gen_loss = 1.0348840476526109, disc_loss = 0.01749282554005495
Trained batch 1445 in epoch 0, gen_loss = 1.03495511464146, disc_loss = 0.017481943704939818
Trained batch 1446 in epoch 0, gen_loss = 1.0349359812, disc_loss = 0.0174707420167974
Trained batch 1447 in epoch 0, gen_loss = 1.0349397301797378, disc_loss = 0.017459310502703405
Trained batch 1448 in epoch 0, gen_loss = 1.0349138804227422, disc_loss = 0.017447669245913275
Trained batch 1449 in epoch 0, gen_loss = 1.0348864603248136, disc_loss = 0.017436219340126062
Trained batch 1450 in epoch 0, gen_loss = 1.0348480660737915, disc_loss = 0.017424668480502857
Trained batch 1451 in epoch 0, gen_loss = 1.0348584639837262, disc_loss = 0.017413184908475245
Trained batch 1452 in epoch 0, gen_loss = 1.0347699124445524, disc_loss = 0.01740202043367023
Trained batch 1453 in epoch 0, gen_loss = 1.0347465101060709, disc_loss = 0.017390434483975425
Trained batch 1454 in epoch 0, gen_loss = 1.03480249219334, disc_loss = 0.017379137573650113
Trained batch 1455 in epoch 0, gen_loss = 1.0349139120675377, disc_loss = 0.017367956933082827
Trained batch 1456 in epoch 0, gen_loss = 1.0348786443942364, disc_loss = 0.01735711918469274
Trained batch 1457 in epoch 0, gen_loss = 1.0349359486369603, disc_loss = 0.017346377502186275
Trained batch 1458 in epoch 0, gen_loss = 1.0349392933621646, disc_loss = 0.017335326605799752
Trained batch 1459 in epoch 0, gen_loss = 1.0348696218982134, disc_loss = 0.017323901124134317
Trained batch 1460 in epoch 0, gen_loss = 1.0348876648819014, disc_loss = 0.017312727964852608
Trained batch 1461 in epoch 0, gen_loss = 1.0348585020704895, disc_loss = 0.01730125004968067
Trained batch 1462 in epoch 0, gen_loss = 1.0348427863008587, disc_loss = 0.01729011495261226
Trained batch 1463 in epoch 0, gen_loss = 1.0347727400561173, disc_loss = 0.017278792022206106
Trained batch 1464 in epoch 0, gen_loss = 1.0347873554498261, disc_loss = 0.01726756956978183
Trained batch 1465 in epoch 0, gen_loss = 1.0348438406096312, disc_loss = 0.017256337653472002
Trained batch 1466 in epoch 0, gen_loss = 1.034811532347074, disc_loss = 0.017245166089884738
Trained batch 1467 in epoch 0, gen_loss = 1.0348602260693867, disc_loss = 0.01723404693123358
Trained batch 1468 in epoch 0, gen_loss = 1.0349512707424293, disc_loss = 0.017222798179362446
Trained batch 1469 in epoch 0, gen_loss = 1.0350088972015445, disc_loss = 0.017211503005106647
Trained batch 1470 in epoch 0, gen_loss = 1.0349533438966194, disc_loss = 0.017200211317463316
Trained batch 1471 in epoch 0, gen_loss = 1.0350163871543887, disc_loss = 0.017189116585976317
Trained batch 1472 in epoch 0, gen_loss = 1.0350732282360475, disc_loss = 0.017178055626829898
Trained batch 1473 in epoch 0, gen_loss = 1.0349925404851763, disc_loss = 0.01716711621549394
Trained batch 1474 in epoch 0, gen_loss = 1.0350601346816046, disc_loss = 0.017156326863480637
Trained batch 1475 in epoch 0, gen_loss = 1.0349813342942455, disc_loss = 0.01714533599517731
Trained batch 1476 in epoch 0, gen_loss = 1.0349939782512938, disc_loss = 0.017134242399430788
Trained batch 1477 in epoch 0, gen_loss = 1.0348907673834786, disc_loss = 0.017122975787577467
Trained batch 1478 in epoch 0, gen_loss = 1.0348836065265599, disc_loss = 0.017111754583301428
Trained batch 1479 in epoch 0, gen_loss = 1.0348985003659854, disc_loss = 0.017100930981187784
Trained batch 1480 in epoch 0, gen_loss = 1.0349219077386862, disc_loss = 0.01708991221189741
Trained batch 1481 in epoch 0, gen_loss = 1.0349442677499472, disc_loss = 0.017078737315247193
Trained batch 1482 in epoch 0, gen_loss = 1.03493653934145, disc_loss = 0.017067538631819496
Trained batch 1483 in epoch 0, gen_loss = 1.0349777908217555, disc_loss = 0.017056480150832512
Trained batch 1484 in epoch 0, gen_loss = 1.0349669642922052, disc_loss = 0.017045627599985805
Trained batch 1485 in epoch 0, gen_loss = 1.0350231907930862, disc_loss = 0.01703468947239301
Trained batch 1486 in epoch 0, gen_loss = 1.0350628712270271, disc_loss = 0.01702418201706728
Trained batch 1487 in epoch 0, gen_loss = 1.0350993232581245, disc_loss = 0.01701324154421082
Trained batch 1488 in epoch 0, gen_loss = 1.0350974129901946, disc_loss = 0.017002309276006992
Trained batch 1489 in epoch 0, gen_loss = 1.0351687223519255, disc_loss = 0.01699136249440169
Trained batch 1490 in epoch 0, gen_loss = 1.0351665396765524, disc_loss = 0.016980335656085817
Trained batch 1491 in epoch 0, gen_loss = 1.0351359305488839, disc_loss = 0.01696941239164219
Trained batch 1492 in epoch 0, gen_loss = 1.0351325243771357, disc_loss = 0.016958373707235862
Trained batch 1493 in epoch 0, gen_loss = 1.0351368807844687, disc_loss = 0.016947514197008823
Trained batch 1494 in epoch 0, gen_loss = 1.0350403099753784, disc_loss = 0.016936735463165913
Trained batch 1495 in epoch 0, gen_loss = 1.0350601602007041, disc_loss = 0.016925997762824253
Trained batch 1496 in epoch 0, gen_loss = 1.0350166992617196, disc_loss = 0.016915115258097618
Trained batch 1497 in epoch 0, gen_loss = 1.035041381524147, disc_loss = 0.016904288370752717
Trained batch 1498 in epoch 0, gen_loss = 1.0351165174602905, disc_loss = 0.016893465962408365
Trained batch 1499 in epoch 0, gen_loss = 1.0351326065262159, disc_loss = 0.01688253875024384
Trained batch 1500 in epoch 0, gen_loss = 1.035208048163693, disc_loss = 0.016871847151915916
Trained batch 1501 in epoch 0, gen_loss = 1.035219348084117, disc_loss = 0.01686102728554796
Trained batch 1502 in epoch 0, gen_loss = 1.035220094168892, disc_loss = 0.016850186789415918
Trained batch 1503 in epoch 0, gen_loss = 1.0351180521612788, disc_loss = 0.016839490014562933
Trained batch 1504 in epoch 0, gen_loss = 1.035135026647403, disc_loss = 0.016828631999592242
Trained batch 1505 in epoch 0, gen_loss = 1.0351257515974728, disc_loss = 0.016817746807849386
Trained batch 1506 in epoch 0, gen_loss = 1.0352182397204832, disc_loss = 0.016807085291513254
Trained batch 1507 in epoch 0, gen_loss = 1.035118332216689, disc_loss = 0.016796413177596708
Trained batch 1508 in epoch 0, gen_loss = 1.0351233773274167, disc_loss = 0.01678572979384544
Trained batch 1509 in epoch 0, gen_loss = 1.0350091080199804, disc_loss = 0.016774989624715114
Trained batch 1510 in epoch 0, gen_loss = 1.0350119822432393, disc_loss = 0.016764434391971214
Trained batch 1511 in epoch 0, gen_loss = 1.0349402837849484, disc_loss = 0.01675359198946223
Trained batch 1512 in epoch 0, gen_loss = 1.0348806218327233, disc_loss = 0.016742919621845556
Trained batch 1513 in epoch 0, gen_loss = 1.0348445757573945, disc_loss = 0.016732180371348895
Trained batch 1514 in epoch 0, gen_loss = 1.0348225991914768, disc_loss = 0.01672148482346517
Trained batch 1515 in epoch 0, gen_loss = 1.0347896616778147, disc_loss = 0.016710707513062747
Trained batch 1516 in epoch 0, gen_loss = 1.0347787779691429, disc_loss = 0.016700078439905695
Trained batch 1517 in epoch 0, gen_loss = 1.0347701833142908, disc_loss = 0.016689373494603067
Trained batch 1518 in epoch 0, gen_loss = 1.034752364041697, disc_loss = 0.016678634393057272
Trained batch 1519 in epoch 0, gen_loss = 1.0347550084520327, disc_loss = 0.016667976350263895
Trained batch 1520 in epoch 0, gen_loss = 1.0348172712725765, disc_loss = 0.016658795332781178
Trained batch 1521 in epoch 0, gen_loss = 1.0348832699495922, disc_loss = 0.01664867633216725
Trained batch 1522 in epoch 0, gen_loss = 1.0350150942058838, disc_loss = 0.016638188999445403
Trained batch 1523 in epoch 0, gen_loss = 1.0349915097822042, disc_loss = 0.016627943666219946
Trained batch 1524 in epoch 0, gen_loss = 1.0350178103955066, disc_loss = 0.016617579021449124
Trained batch 1525 in epoch 0, gen_loss = 1.0349671151464608, disc_loss = 0.01660704482029797
Trained batch 1526 in epoch 0, gen_loss = 1.034943561949758, disc_loss = 0.016596451763135487
Trained batch 1527 in epoch 0, gen_loss = 1.034965622389972, disc_loss = 0.016585949458560817
Trained batch 1528 in epoch 0, gen_loss = 1.0349290994470457, disc_loss = 0.016575416216573925
Trained batch 1529 in epoch 0, gen_loss = 1.034971830560491, disc_loss = 0.01656487987365717
Trained batch 1530 in epoch 0, gen_loss = 1.0349905924381266, disc_loss = 0.016554535591422358
Trained batch 1531 in epoch 0, gen_loss = 1.034934218165613, disc_loss = 0.016544184418678297
Trained batch 1532 in epoch 0, gen_loss = 1.0350144416268792, disc_loss = 0.016534014490449896
Trained batch 1533 in epoch 0, gen_loss = 1.0349722721236314, disc_loss = 0.01652352194030629
Trained batch 1534 in epoch 0, gen_loss = 1.0349238349288605, disc_loss = 0.01651305986660478
Trained batch 1535 in epoch 0, gen_loss = 1.0348880321059066, disc_loss = 0.01650262925657368
Trained batch 1536 in epoch 0, gen_loss = 1.0348464702543843, disc_loss = 0.016492057820871743
Trained batch 1537 in epoch 0, gen_loss = 1.034885227118264, disc_loss = 0.016481785571383693
Trained batch 1538 in epoch 0, gen_loss = 1.034856435441599, disc_loss = 0.016471498410893414
Trained batch 1539 in epoch 0, gen_loss = 1.0349136329897037, disc_loss = 0.016461111031632943
Trained batch 1540 in epoch 0, gen_loss = 1.0350597924918497, disc_loss = 0.01645118501315366
Trained batch 1541 in epoch 0, gen_loss = 1.0350092561135187, disc_loss = 0.016441189051616633
Trained batch 1542 in epoch 0, gen_loss = 1.035096838558485, disc_loss = 0.016430916980573484
Trained batch 1543 in epoch 0, gen_loss = 1.0350285904974208, disc_loss = 0.01642061338264289
Trained batch 1544 in epoch 0, gen_loss = 1.0350709813891106, disc_loss = 0.016410269588439254
Trained batch 1545 in epoch 0, gen_loss = 1.0350353531009322, disc_loss = 0.016399945917428306
Trained batch 1546 in epoch 0, gen_loss = 1.0350766641021005, disc_loss = 0.016389600921648904
Trained batch 1547 in epoch 0, gen_loss = 1.0350177448040756, disc_loss = 0.01637920396178296
Trained batch 1548 in epoch 0, gen_loss = 1.0349826133774511, disc_loss = 0.016369213642264048
Trained batch 1549 in epoch 0, gen_loss = 1.0349903860207528, disc_loss = 0.016358955916009783
Trained batch 1550 in epoch 0, gen_loss = 1.0350426885675876, disc_loss = 0.016348643085913616
Trained batch 1551 in epoch 0, gen_loss = 1.0350247394754408, disc_loss = 0.016338335968424704
Trained batch 1552 in epoch 0, gen_loss = 1.0350216564752943, disc_loss = 0.016328113569463655
Trained batch 1553 in epoch 0, gen_loss = 1.0350518246376683, disc_loss = 0.016317867947404634
Trained batch 1554 in epoch 0, gen_loss = 1.0350503805557631, disc_loss = 0.016307562490673645
Trained batch 1555 in epoch 0, gen_loss = 1.0350594956303316, disc_loss = 0.016297350612326567
Trained batch 1556 in epoch 0, gen_loss = 1.03496972691117, disc_loss = 0.016287167079950246
Trained batch 1557 in epoch 0, gen_loss = 1.034978945252984, disc_loss = 0.01627694072866641
Trained batch 1558 in epoch 0, gen_loss = 1.0349393711593229, disc_loss = 0.016266732801162177
Trained batch 1559 in epoch 0, gen_loss = 1.034990560110563, disc_loss = 0.016256581071017233
Trained batch 1560 in epoch 0, gen_loss = 1.0349661134169088, disc_loss = 0.016246482125704353
Trained batch 1561 in epoch 0, gen_loss = 1.0349081173329286, disc_loss = 0.01623628882426833
Trained batch 1562 in epoch 0, gen_loss = 1.034950129225402, disc_loss = 0.01622628739847154
Trained batch 1563 in epoch 0, gen_loss = 1.0348746378517821, disc_loss = 0.016216254993038172
Trained batch 1564 in epoch 0, gen_loss = 1.0348381799059554, disc_loss = 0.016206517790149623
Trained batch 1565 in epoch 0, gen_loss = 1.0348341047269023, disc_loss = 0.01619646258103289
Trained batch 1566 in epoch 0, gen_loss = 1.0348310534674117, disc_loss = 0.01618644647013031
Trained batch 1567 in epoch 0, gen_loss = 1.0349626418165103, disc_loss = 0.01617644387353758
Trained batch 1568 in epoch 0, gen_loss = 1.0349965324403374, disc_loss = 0.01616631611398735
Trained batch 1569 in epoch 0, gen_loss = 1.035046453707537, disc_loss = 0.016156286396535564
Trained batch 1570 in epoch 0, gen_loss = 1.035103953791454, disc_loss = 0.016146420575089974
Trained batch 1571 in epoch 0, gen_loss = 1.035065830720745, disc_loss = 0.0161365180851894
Trained batch 1572 in epoch 0, gen_loss = 1.0350564943895322, disc_loss = 0.01612661685113714
Trained batch 1573 in epoch 0, gen_loss = 1.035033437185548, disc_loss = 0.01611668806555036
Trained batch 1574 in epoch 0, gen_loss = 1.0350180722229065, disc_loss = 0.016106728955452877
Trained batch 1575 in epoch 0, gen_loss = 1.0349639483401316, disc_loss = 0.01609678918412747
Trained batch 1576 in epoch 0, gen_loss = 1.0349113062241444, disc_loss = 0.016086766802822904
Trained batch 1577 in epoch 0, gen_loss = 1.0349732142022052, disc_loss = 0.016076827956922324
Trained batch 1578 in epoch 0, gen_loss = 1.0349634030599093, disc_loss = 0.01606694917488201
Trained batch 1579 in epoch 0, gen_loss = 1.0349752485940729, disc_loss = 0.016057009130102565
Trained batch 1580 in epoch 0, gen_loss = 1.0350037167186905, disc_loss = 0.01604709639477957
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0065276622772217, disc_loss = 0.0003825981984846294
Trained batch 1 in epoch 1, gen_loss = 1.0287554264068604, disc_loss = 0.0004894928133580834
Trained batch 2 in epoch 1, gen_loss = 1.0659834543863933, disc_loss = 0.0005131189633781711
Trained batch 3 in epoch 1, gen_loss = 1.0571486949920654, disc_loss = 0.0005600398435490206
Trained batch 4 in epoch 1, gen_loss = 1.0539048910140991, disc_loss = 0.0005834520794451237
Trained batch 5 in epoch 1, gen_loss = 1.045779526233673, disc_loss = 0.0005621448799502105
Trained batch 6 in epoch 1, gen_loss = 1.036189547606877, disc_loss = 0.000533820828422904
Trained batch 7 in epoch 1, gen_loss = 1.059978149831295, disc_loss = 0.0005459633321152069
Trained batch 8 in epoch 1, gen_loss = 1.0589289863904316, disc_loss = 0.0005334905258172916
Trained batch 9 in epoch 1, gen_loss = 1.0595116317272186, disc_loss = 0.0005351166939362884
Trained batch 10 in epoch 1, gen_loss = 1.057946427301927, disc_loss = 0.0005170117259364237
Trained batch 11 in epoch 1, gen_loss = 1.0584497302770615, disc_loss = 0.0004972877092465448
Trained batch 12 in epoch 1, gen_loss = 1.0562834327037518, disc_loss = 0.000483413488836959
Trained batch 13 in epoch 1, gen_loss = 1.055329327072416, disc_loss = 0.00047730708528043967
Trained batch 14 in epoch 1, gen_loss = 1.0564343889554342, disc_loss = 0.000467010511783883
Trained batch 15 in epoch 1, gen_loss = 1.0482832677662373, disc_loss = 0.0004588673564285273
Trained batch 16 in epoch 1, gen_loss = 1.0527780792292427, disc_loss = 0.00045582275967771075
Trained batch 17 in epoch 1, gen_loss = 1.0454186995824177, disc_loss = 0.00045077942033660493
Trained batch 18 in epoch 1, gen_loss = 1.0507433665426154, disc_loss = 0.0004467447181109731
Trained batch 19 in epoch 1, gen_loss = 1.0467213690280914, disc_loss = 0.0004454494017409161
Trained batch 20 in epoch 1, gen_loss = 1.0397646909668332, disc_loss = 0.00043705912373427836
Trained batch 21 in epoch 1, gen_loss = 1.0376813059503383, disc_loss = 0.0004309879533883015
Trained batch 22 in epoch 1, gen_loss = 1.0371230866598047, disc_loss = 0.0004464324890210739
Trained batch 23 in epoch 1, gen_loss = 1.0376340026656787, disc_loss = 0.0004506948231816447
Trained batch 24 in epoch 1, gen_loss = 1.037504494190216, disc_loss = 0.0004492840252351016
Trained batch 25 in epoch 1, gen_loss = 1.0339838014199183, disc_loss = 0.0004513615220695591
Trained batch 26 in epoch 1, gen_loss = 1.0294398952413488, disc_loss = 0.00045098592979936965
Trained batch 27 in epoch 1, gen_loss = 1.03304437654359, disc_loss = 0.00045016452973608727
Trained batch 28 in epoch 1, gen_loss = 1.033092946841799, disc_loss = 0.000447166760468149
Trained batch 29 in epoch 1, gen_loss = 1.0370290915171305, disc_loss = 0.0004501773025064419
Trained batch 30 in epoch 1, gen_loss = 1.0330771438537105, disc_loss = 0.00044870277164473887
Trained batch 31 in epoch 1, gen_loss = 1.0327109843492508, disc_loss = 0.00044554700161825167
Trained batch 32 in epoch 1, gen_loss = 1.033639163681955, disc_loss = 0.000442474614828825
Trained batch 33 in epoch 1, gen_loss = 1.0342894792556763, disc_loss = 0.00043840576665174654
Trained batch 34 in epoch 1, gen_loss = 1.0356998409543718, disc_loss = 0.000443149107741192
Trained batch 35 in epoch 1, gen_loss = 1.0363048877980974, disc_loss = 0.00044176962061707553
Trained batch 36 in epoch 1, gen_loss = 1.032970610502604, disc_loss = 0.00045730156046841795
Trained batch 37 in epoch 1, gen_loss = 1.0336424598568363, disc_loss = 0.00046342516725417227
Trained batch 38 in epoch 1, gen_loss = 1.0340961936192634, disc_loss = 0.0004608565657877196
Trained batch 39 in epoch 1, gen_loss = 1.0322304949164391, disc_loss = 0.0004613644785422366
Trained batch 40 in epoch 1, gen_loss = 1.0331989279607448, disc_loss = 0.0004638188139524129
Trained batch 41 in epoch 1, gen_loss = 1.0331522751422155, disc_loss = 0.0004630452811917556
Trained batch 42 in epoch 1, gen_loss = 1.035011351108551, disc_loss = 0.00046403547424043334
Trained batch 43 in epoch 1, gen_loss = 1.0328381522135301, disc_loss = 0.00046425096595405853
Trained batch 44 in epoch 1, gen_loss = 1.0314557366900974, disc_loss = 0.0004616443850358741
Trained batch 45 in epoch 1, gen_loss = 1.0293748041857844, disc_loss = 0.0004592986332009668
Trained batch 46 in epoch 1, gen_loss = 1.0291743405321812, disc_loss = 0.0004576225480203457
Trained batch 47 in epoch 1, gen_loss = 1.0291901305317879, disc_loss = 0.00045638667385598336
Trained batch 48 in epoch 1, gen_loss = 1.0294047886011553, disc_loss = 0.0004557085589372686
Trained batch 49 in epoch 1, gen_loss = 1.029296133518219, disc_loss = 0.00045289305155165493
Trained batch 50 in epoch 1, gen_loss = 1.0271589744324778, disc_loss = 0.0004513871156400544
Trained batch 51 in epoch 1, gen_loss = 1.0269007098216276, disc_loss = 0.00045183512702351436
Trained batch 52 in epoch 1, gen_loss = 1.0260800955430516, disc_loss = 0.00045113412241609593
Trained batch 53 in epoch 1, gen_loss = 1.0237830115689173, disc_loss = 0.0004477367555308673
Trained batch 54 in epoch 1, gen_loss = 1.0240577643567865, disc_loss = 0.00044708033198152076
Trained batch 55 in epoch 1, gen_loss = 1.0231735759547778, disc_loss = 0.0004491463550948538
Trained batch 56 in epoch 1, gen_loss = 1.0226216337137055, disc_loss = 0.00045757557432935165
Trained batch 57 in epoch 1, gen_loss = 1.0227330285927345, disc_loss = 0.00045574769269321756
Trained batch 58 in epoch 1, gen_loss = 1.024702288336673, disc_loss = 0.00045957549581683035
Trained batch 59 in epoch 1, gen_loss = 1.023430581887563, disc_loss = 0.00045605331785433616
Trained batch 60 in epoch 1, gen_loss = 1.022888252969648, disc_loss = 0.0004559467755616872
Trained batch 61 in epoch 1, gen_loss = 1.0185316512661595, disc_loss = 0.000477407185357034
Trained batch 62 in epoch 1, gen_loss = 1.019682696887425, disc_loss = 0.000480303486775873
Trained batch 63 in epoch 1, gen_loss = 1.0198125634342432, disc_loss = 0.0004838010895582556
Trained batch 64 in epoch 1, gen_loss = 1.0212552639154286, disc_loss = 0.0004831093636592134
Trained batch 65 in epoch 1, gen_loss = 1.0220688834334866, disc_loss = 0.00048255797424424213
Trained batch 66 in epoch 1, gen_loss = 1.0186082391596551, disc_loss = 0.0004884708562427993
Trained batch 67 in epoch 1, gen_loss = 1.0177932381629944, disc_loss = 0.00048797759860890974
Trained batch 68 in epoch 1, gen_loss = 1.0182092310725779, disc_loss = 0.0004884350034273297
Trained batch 69 in epoch 1, gen_loss = 1.017547493321555, disc_loss = 0.00048655428108759227
Trained batch 70 in epoch 1, gen_loss = 1.019428207840718, disc_loss = 0.0004856878339024392
Trained batch 71 in epoch 1, gen_loss = 1.019664974676238, disc_loss = 0.00048281483274574083
Trained batch 72 in epoch 1, gen_loss = 1.0199325362296954, disc_loss = 0.00048206095130833455
Trained batch 73 in epoch 1, gen_loss = 1.0199765981854618, disc_loss = 0.00048210227868293186
Trained batch 74 in epoch 1, gen_loss = 1.0198449563980103, disc_loss = 0.0004824754976046582
Trained batch 75 in epoch 1, gen_loss = 1.019050463249809, disc_loss = 0.00048077234417800546
Trained batch 76 in epoch 1, gen_loss = 1.017502981346923, disc_loss = 0.00047877889962612903
Trained batch 77 in epoch 1, gen_loss = 1.0178113717299242, disc_loss = 0.00047671614261045575
Trained batch 78 in epoch 1, gen_loss = 1.0172329975079886, disc_loss = 0.0004742547734846844
Trained batch 79 in epoch 1, gen_loss = 1.0175376862287522, disc_loss = 0.00047223973051586655
Trained batch 80 in epoch 1, gen_loss = 1.018956990889561, disc_loss = 0.0004709093241498196
Trained batch 81 in epoch 1, gen_loss = 1.0199783517093193, disc_loss = 0.0004701200697326851
Trained batch 82 in epoch 1, gen_loss = 1.0201286149312214, disc_loss = 0.00046921967555409725
Trained batch 83 in epoch 1, gen_loss = 1.0206940259252275, disc_loss = 0.00046744208313092325
Trained batch 84 in epoch 1, gen_loss = 1.0186211263432223, disc_loss = 0.00046749727300587386
Trained batch 85 in epoch 1, gen_loss = 1.019085631814114, disc_loss = 0.0004664070076487829
Trained batch 86 in epoch 1, gen_loss = 1.0215218368617969, disc_loss = 0.00046529874490606115
Trained batch 87 in epoch 1, gen_loss = 1.021712450818582, disc_loss = 0.00046406745406619103
Trained batch 88 in epoch 1, gen_loss = 1.021823116902555, disc_loss = 0.0004629977662220932
Trained batch 89 in epoch 1, gen_loss = 1.0212514890564812, disc_loss = 0.00046126831924387567
Trained batch 90 in epoch 1, gen_loss = 1.0217094355887109, disc_loss = 0.0004614829866133712
Trained batch 91 in epoch 1, gen_loss = 1.0216581769611524, disc_loss = 0.0004622013100584888
Trained batch 92 in epoch 1, gen_loss = 1.0213477150086434, disc_loss = 0.00046183436299093386
Trained batch 93 in epoch 1, gen_loss = 1.021393595857823, disc_loss = 0.0004602895425434442
Trained batch 94 in epoch 1, gen_loss = 1.0221756859829552, disc_loss = 0.00045943385308706445
Trained batch 95 in epoch 1, gen_loss = 1.0222357399761677, disc_loss = 0.0004574941513055819
Trained batch 96 in epoch 1, gen_loss = 1.0213864513279236, disc_loss = 0.00045572363107810855
Trained batch 97 in epoch 1, gen_loss = 1.0211688413911937, disc_loss = 0.0004541924566610203
Trained batch 98 in epoch 1, gen_loss = 1.0200457500688958, disc_loss = 0.00045222595552772736
Trained batch 99 in epoch 1, gen_loss = 1.020424221754074, disc_loss = 0.0004502757586305961
Trained batch 100 in epoch 1, gen_loss = 1.021312686476377, disc_loss = 0.00044953603110746437
Trained batch 101 in epoch 1, gen_loss = 1.0200846703613506, disc_loss = 0.00045092779556380624
Trained batch 102 in epoch 1, gen_loss = 1.0197705973699256, disc_loss = 0.0004495343490666484
Trained batch 103 in epoch 1, gen_loss = 1.0197400502287424, disc_loss = 0.00044876409363216505
Trained batch 104 in epoch 1, gen_loss = 1.0196810330663408, disc_loss = 0.0004475320600682781
Trained batch 105 in epoch 1, gen_loss = 1.0196638056692087, disc_loss = 0.0004463822675324133
Trained batch 106 in epoch 1, gen_loss = 1.0196303769806836, disc_loss = 0.0004458261317046899
Trained batch 107 in epoch 1, gen_loss = 1.0198994207161445, disc_loss = 0.0004452890018540159
Trained batch 108 in epoch 1, gen_loss = 1.0188488364219666, disc_loss = 0.00044330916997075185
Trained batch 109 in epoch 1, gen_loss = 1.019053499807011, disc_loss = 0.0004561024171628312
Trained batch 110 in epoch 1, gen_loss = 1.0197761869645334, disc_loss = 0.0004586907357201903
Trained batch 111 in epoch 1, gen_loss = 1.0206722696977002, disc_loss = 0.0005175194854538338
Trained batch 112 in epoch 1, gen_loss = 1.021838761536421, disc_loss = 0.0005497339513076601
Trained batch 113 in epoch 1, gen_loss = 1.022352086347446, disc_loss = 0.0007708537500308777
Trained batch 114 in epoch 1, gen_loss = 1.0232677454533785, disc_loss = 0.0009915070844885043
Trained batch 115 in epoch 1, gen_loss = 1.023945814062809, disc_loss = 0.0010968559527727534
Trained batch 116 in epoch 1, gen_loss = 1.0241035014136224, disc_loss = 0.0011415107241129249
Trained batch 117 in epoch 1, gen_loss = 1.0216818103345775, disc_loss = 0.0022722942456435335
Trained batch 118 in epoch 1, gen_loss = 1.0254688267948247, disc_loss = 0.0077445136510107685
Trained batch 119 in epoch 1, gen_loss = 1.0263008321324985, disc_loss = 0.009331883997826177
Trained batch 120 in epoch 1, gen_loss = 1.0268419286436286, disc_loss = 0.010700114513338497
Trained batch 121 in epoch 1, gen_loss = 1.026271356422393, disc_loss = 0.011964281695893943
Trained batch 122 in epoch 1, gen_loss = 1.025683559537903, disc_loss = 0.01263397999760426
Trained batch 123 in epoch 1, gen_loss = 1.0265139663411724, disc_loss = 0.013450647024001228
Trained batch 124 in epoch 1, gen_loss = 1.0275021443367005, disc_loss = 0.014407433818443678
Trained batch 125 in epoch 1, gen_loss = 1.027331231605439, disc_loss = 0.01500086954530118
Trained batch 126 in epoch 1, gen_loss = 1.0270870581386595, disc_loss = 0.015238539538851308
Trained batch 127 in epoch 1, gen_loss = 1.0280242529697716, disc_loss = 0.01538468578235097
Trained batch 128 in epoch 1, gen_loss = 1.0294522855632988, disc_loss = 0.015412521233954538
Trained batch 129 in epoch 1, gen_loss = 1.0295058915248283, disc_loss = 0.015473672972718934
Trained batch 130 in epoch 1, gen_loss = 1.0293536773164764, disc_loss = 0.01545490779083503
Trained batch 131 in epoch 1, gen_loss = 1.0285721877307603, disc_loss = 0.015570726382672243
Trained batch 132 in epoch 1, gen_loss = 1.0266823817912798, disc_loss = 0.016162030422807096
Trained batch 133 in epoch 1, gen_loss = 1.0267508319064753, disc_loss = 0.017346516775758762
Trained batch 134 in epoch 1, gen_loss = 1.0270173695352343, disc_loss = 0.017363226161385817
Trained batch 135 in epoch 1, gen_loss = 1.0246188219855814, disc_loss = 0.01967287630213832
Trained batch 136 in epoch 1, gen_loss = 1.0238421028547913, disc_loss = 0.020550970473631802
Trained batch 137 in epoch 1, gen_loss = 1.0228599737519803, disc_loss = 0.021518681005492934
Trained batch 138 in epoch 1, gen_loss = 1.020357784178617, disc_loss = 0.02259842619555751
Trained batch 139 in epoch 1, gen_loss = 1.0207961103745868, disc_loss = 0.0235857097925743
Trained batch 140 in epoch 1, gen_loss = 1.0211349687677749, disc_loss = 0.02429653384096521
Trained batch 141 in epoch 1, gen_loss = 1.0204171550945498, disc_loss = 0.02470538032872022
Trained batch 142 in epoch 1, gen_loss = 1.0178703886645657, disc_loss = 0.025713676674160423
Trained batch 143 in epoch 1, gen_loss = 1.0198615491390228, disc_loss = 0.02609285983503974
Trained batch 144 in epoch 1, gen_loss = 1.0184108413498978, disc_loss = 0.0262016917060025
Trained batch 145 in epoch 1, gen_loss = 1.0179184181232974, disc_loss = 0.026350839212931507
Trained batch 146 in epoch 1, gen_loss = 1.0206602864524945, disc_loss = 0.02707585339784087
Trained batch 147 in epoch 1, gen_loss = 1.0203645724702526, disc_loss = 0.02716416691544362
Trained batch 148 in epoch 1, gen_loss = 1.0198331759280006, disc_loss = 0.027128181247889915
Trained batch 149 in epoch 1, gen_loss = 1.0196202874183655, disc_loss = 0.02706737260906569
Trained batch 150 in epoch 1, gen_loss = 1.0194112662447998, disc_loss = 0.02695631853484823
Trained batch 151 in epoch 1, gen_loss = 1.0190086870601303, disc_loss = 0.026953070384192153
Trained batch 152 in epoch 1, gen_loss = 1.017484384814119, disc_loss = 0.027006697600073595
Trained batch 153 in epoch 1, gen_loss = 1.0168376534016101, disc_loss = 0.027066992459249494
Trained batch 154 in epoch 1, gen_loss = 1.016881690486785, disc_loss = 0.02695959583779181
Trained batch 155 in epoch 1, gen_loss = 1.0178041870777423, disc_loss = 0.026866125327498408
Trained batch 156 in epoch 1, gen_loss = 1.0186305661110362, disc_loss = 0.02675312769013104
Trained batch 157 in epoch 1, gen_loss = 1.018755438207071, disc_loss = 0.026652818459769138
Trained batch 158 in epoch 1, gen_loss = 1.0182237947511974, disc_loss = 0.026586960447178246
Trained batch 159 in epoch 1, gen_loss = 1.0192284159362317, disc_loss = 0.026499181935923842
Trained batch 160 in epoch 1, gen_loss = 1.0193034832521994, disc_loss = 0.026386431119999824
Trained batch 161 in epoch 1, gen_loss = 1.0205543129532426, disc_loss = 0.026252520255824224
Trained batch 162 in epoch 1, gen_loss = 1.020821449946772, disc_loss = 0.026110241946209353
Trained batch 163 in epoch 1, gen_loss = 1.0210196521224044, disc_loss = 0.025969123803828018
Trained batch 164 in epoch 1, gen_loss = 1.0209600101817737, disc_loss = 0.025892940508889628
Trained batch 165 in epoch 1, gen_loss = 1.0206131576055504, disc_loss = 0.025801754955897326
Trained batch 166 in epoch 1, gen_loss = 1.0218031199392443, disc_loss = 0.02568790577670969
Trained batch 167 in epoch 1, gen_loss = 1.0230154792467754, disc_loss = 0.025631067199875752
Trained batch 168 in epoch 1, gen_loss = 1.022755049389495, disc_loss = 0.02551632785999847
Trained batch 169 in epoch 1, gen_loss = 1.0228821186458363, disc_loss = 0.02539308871346293
Trained batch 170 in epoch 1, gen_loss = 1.02289420889135, disc_loss = 0.025260192131993296
Trained batch 171 in epoch 1, gen_loss = 1.0227665284345315, disc_loss = 0.02514002135869178
Trained batch 172 in epoch 1, gen_loss = 1.0223391242109972, disc_loss = 0.025038440636008564
Trained batch 173 in epoch 1, gen_loss = 1.0226576431044216, disc_loss = 0.024909554833085303
Trained batch 174 in epoch 1, gen_loss = 1.0230258866718838, disc_loss = 0.024787135383230633
Trained batch 175 in epoch 1, gen_loss = 1.023622919212688, disc_loss = 0.024671668100381794
Trained batch 176 in epoch 1, gen_loss = 1.0230424087599845, disc_loss = 0.024602539804063628
Trained batch 177 in epoch 1, gen_loss = 1.0228064328097226, disc_loss = 0.024560613440872257
Trained batch 178 in epoch 1, gen_loss = 1.0226159402112056, disc_loss = 0.02446885185676182
Trained batch 179 in epoch 1, gen_loss = 1.021238954199685, disc_loss = 0.02446435581619476
Trained batch 180 in epoch 1, gen_loss = 1.0220615494975727, disc_loss = 0.02437426784107634
Trained batch 181 in epoch 1, gen_loss = 1.0228551875103962, disc_loss = 0.024271226918774497
Trained batch 182 in epoch 1, gen_loss = 1.025105268577409, disc_loss = 0.024350444303651828
Trained batch 183 in epoch 1, gen_loss = 1.0247277060280675, disc_loss = 0.024340501906329377
Trained batch 184 in epoch 1, gen_loss = 1.0246529682262524, disc_loss = 0.024244306828886446
Trained batch 185 in epoch 1, gen_loss = 1.0245989734126675, disc_loss = 0.024143778554633916
Trained batch 186 in epoch 1, gen_loss = 1.0256213440614588, disc_loss = 0.024056662776352423
Trained batch 187 in epoch 1, gen_loss = 1.025207092787357, disc_loss = 0.024069866428923906
Trained batch 188 in epoch 1, gen_loss = 1.0245905912742412, disc_loss = 0.024086585757060828
Trained batch 189 in epoch 1, gen_loss = 1.0240504252283196, disc_loss = 0.02403240384814317
Trained batch 190 in epoch 1, gen_loss = 1.0242959978692818, disc_loss = 0.023926390013983594
Trained batch 191 in epoch 1, gen_loss = 1.0248147162298362, disc_loss = 0.023828164168283667
Trained batch 192 in epoch 1, gen_loss = 1.0245906253552808, disc_loss = 0.023721521085359208
Trained batch 193 in epoch 1, gen_loss = 1.024196663160914, disc_loss = 0.023642809266694365
Trained batch 194 in epoch 1, gen_loss = 1.0240123602060172, disc_loss = 0.023541975305161965
Trained batch 195 in epoch 1, gen_loss = 1.0243176191437, disc_loss = 0.023464612698058326
Trained batch 196 in epoch 1, gen_loss = 1.0246192392358926, disc_loss = 0.02337517376318704
Trained batch 197 in epoch 1, gen_loss = 1.023707944636393, disc_loss = 0.023343001263827025
Trained batch 198 in epoch 1, gen_loss = 1.0232299919703498, disc_loss = 0.02324771639812286
Trained batch 199 in epoch 1, gen_loss = 1.0236966556310654, disc_loss = 0.023153071987544536
Trained batch 200 in epoch 1, gen_loss = 1.0239818339324116, disc_loss = 0.02306188938092957
Trained batch 201 in epoch 1, gen_loss = 1.0239581831611029, disc_loss = 0.022960486095315098
Trained batch 202 in epoch 1, gen_loss = 1.0235740874201207, disc_loss = 0.022872552105550784
Trained batch 203 in epoch 1, gen_loss = 1.02325715971928, disc_loss = 0.022775607562139425
Trained batch 204 in epoch 1, gen_loss = 1.0230552533777748, disc_loss = 0.022678611125078664
Trained batch 205 in epoch 1, gen_loss = 1.0240952794991651, disc_loss = 0.02257850125184208
Trained batch 206 in epoch 1, gen_loss = 1.024301953361806, disc_loss = 0.022480100131993506
Trained batch 207 in epoch 1, gen_loss = 1.0243372338322492, disc_loss = 0.02238352854405653
Trained batch 208 in epoch 1, gen_loss = 1.0244916529176338, disc_loss = 0.0222873357054304
Trained batch 209 in epoch 1, gen_loss = 1.024477347873506, disc_loss = 0.022187903633416033
Trained batch 210 in epoch 1, gen_loss = 1.0245368514580748, disc_loss = 0.022088070791443672
Trained batch 211 in epoch 1, gen_loss = 1.024740992289669, disc_loss = 0.021988627160028973
Trained batch 212 in epoch 1, gen_loss = 1.0247747489544148, disc_loss = 0.02189314633326664
Trained batch 213 in epoch 1, gen_loss = 1.0247069591673734, disc_loss = 0.021930161231645127
Trained batch 214 in epoch 1, gen_loss = 1.0247663991395817, disc_loss = 0.021875296181357508
Trained batch 215 in epoch 1, gen_loss = 1.0250488536225424, disc_loss = 0.021810210804889922
Trained batch 216 in epoch 1, gen_loss = 1.0249366710812264, disc_loss = 0.02172335927300359
Trained batch 217 in epoch 1, gen_loss = 1.0245461463928223, disc_loss = 0.02163732032004024
Trained batch 218 in epoch 1, gen_loss = 1.0242949364936516, disc_loss = 0.021549962352752392
Trained batch 219 in epoch 1, gen_loss = 1.0238718577406623, disc_loss = 0.02151005050737612
Trained batch 220 in epoch 1, gen_loss = 1.0244057547992171, disc_loss = 0.021436296275074644
Trained batch 221 in epoch 1, gen_loss = 1.0248325840309933, disc_loss = 0.021355190566257964
Trained batch 222 in epoch 1, gen_loss = 1.0251308885390449, disc_loss = 0.021268123041641596
Trained batch 223 in epoch 1, gen_loss = 1.024664529200111, disc_loss = 0.02118706372980991
Trained batch 224 in epoch 1, gen_loss = 1.0250725984573363, disc_loss = 0.021106127594895142
Trained batch 225 in epoch 1, gen_loss = 1.0250616521961922, disc_loss = 0.021021621107251025
Trained batch 226 in epoch 1, gen_loss = 1.0243230288774432, disc_loss = 0.02098442199207906
Trained batch 227 in epoch 1, gen_loss = 1.0245534597258819, disc_loss = 0.020913938404734374
Trained batch 228 in epoch 1, gen_loss = 1.024672096733443, disc_loss = 0.020842896964729917
Trained batch 229 in epoch 1, gen_loss = 1.025175399624783, disc_loss = 0.020763584725627088
Trained batch 230 in epoch 1, gen_loss = 1.02551884542812, disc_loss = 0.020686667876353877
Trained batch 231 in epoch 1, gen_loss = 1.0255473099392036, disc_loss = 0.020604738533275567
Trained batch 232 in epoch 1, gen_loss = 1.0250919555901459, disc_loss = 0.02052627700647537
Trained batch 233 in epoch 1, gen_loss = 1.0246829803173358, disc_loss = 0.020451998211924508
Trained batch 234 in epoch 1, gen_loss = 1.0248568428323623, disc_loss = 0.020374570145120625
Trained batch 235 in epoch 1, gen_loss = 1.024720992577278, disc_loss = 0.020292412898277812
Trained batch 236 in epoch 1, gen_loss = 1.0247146841845935, disc_loss = 0.020210476746605335
Trained batch 237 in epoch 1, gen_loss = 1.0248079109592598, disc_loss = 0.02013231435722912
Trained batch 238 in epoch 1, gen_loss = 1.025192294659475, disc_loss = 0.020054436868597817
Trained batch 239 in epoch 1, gen_loss = 1.0254848713676135, disc_loss = 0.019990222873154075
Trained batch 240 in epoch 1, gen_loss = 1.0260622872356557, disc_loss = 0.019915986560945422
Trained batch 241 in epoch 1, gen_loss = 1.0256711692849467, disc_loss = 0.01985125386266544
Trained batch 242 in epoch 1, gen_loss = 1.0256696041719413, disc_loss = 0.019779275447585804
Trained batch 243 in epoch 1, gen_loss = 1.0262437814571819, disc_loss = 0.019705557443960627
Trained batch 244 in epoch 1, gen_loss = 1.0262466756664976, disc_loss = 0.019637278556925892
Trained batch 245 in epoch 1, gen_loss = 1.0265309233975604, disc_loss = 0.01956507574209169
Trained batch 246 in epoch 1, gen_loss = 1.026795301842786, disc_loss = 0.01950832545352668
Trained batch 247 in epoch 1, gen_loss = 1.0270135320963398, disc_loss = 0.019439286501848632
Trained batch 248 in epoch 1, gen_loss = 1.026961857056522, disc_loss = 0.019373052130931573
Trained batch 249 in epoch 1, gen_loss = 1.0266763963699341, disc_loss = 0.019304126512433867
Trained batch 250 in epoch 1, gen_loss = 1.0265350332298127, disc_loss = 0.01925257621981172
Trained batch 251 in epoch 1, gen_loss = 1.0263330917509774, disc_loss = 0.01921491362245722
Trained batch 252 in epoch 1, gen_loss = 1.0264939545642717, disc_loss = 0.019151696493734584
Trained batch 253 in epoch 1, gen_loss = 1.0259510630697717, disc_loss = 0.019085069925982166
Trained batch 254 in epoch 1, gen_loss = 1.0264972710141949, disc_loss = 0.019023405706827236
Trained batch 255 in epoch 1, gen_loss = 1.02647390589118, disc_loss = 0.01895496128616969
Trained batch 256 in epoch 1, gen_loss = 1.026717583493036, disc_loss = 0.018894037250091922
Trained batch 257 in epoch 1, gen_loss = 1.026708978553151, disc_loss = 0.018825708524052815
Trained batch 258 in epoch 1, gen_loss = 1.0268671029322856, disc_loss = 0.018758727961413573
Trained batch 259 in epoch 1, gen_loss = 1.0272240478258867, disc_loss = 0.018694958486762166
Trained batch 260 in epoch 1, gen_loss = 1.027596026088086, disc_loss = 0.01863151404067073
Trained batch 261 in epoch 1, gen_loss = 1.027152913217326, disc_loss = 0.0185671773925668
Trained batch 262 in epoch 1, gen_loss = 1.027585398561601, disc_loss = 0.01849993946580278
Trained batch 263 in epoch 1, gen_loss = 1.027982411962567, disc_loss = 0.01843604121319059
Trained batch 264 in epoch 1, gen_loss = 1.0278902854559557, disc_loss = 0.018372249181265943
Trained batch 265 in epoch 1, gen_loss = 1.0277472812878459, disc_loss = 0.01830651397488379
Trained batch 266 in epoch 1, gen_loss = 1.0280979717715402, disc_loss = 0.01824183962960799
Trained batch 267 in epoch 1, gen_loss = 1.028520763142785, disc_loss = 0.01817702520012103
Trained batch 268 in epoch 1, gen_loss = 1.0284539206320469, disc_loss = 0.018115251862734372
Trained batch 269 in epoch 1, gen_loss = 1.0288591038297723, disc_loss = 0.01805140615146633
Trained batch 270 in epoch 1, gen_loss = 1.0286680976843041, disc_loss = 0.01798778489816073
Trained batch 271 in epoch 1, gen_loss = 1.0285200327634811, disc_loss = 0.01792446571364374
Trained batch 272 in epoch 1, gen_loss = 1.0284118019180857, disc_loss = 0.017862907450442753
Trained batch 273 in epoch 1, gen_loss = 1.0282893122112664, disc_loss = 0.017800089577669667
Trained batch 274 in epoch 1, gen_loss = 1.0284399000081148, disc_loss = 0.017737867216188037
Trained batch 275 in epoch 1, gen_loss = 1.02854396186877, disc_loss = 0.017676224581932267
Trained batch 276 in epoch 1, gen_loss = 1.0282543497395429, disc_loss = 0.01761541931169395
Trained batch 277 in epoch 1, gen_loss = 1.027856470440789, disc_loss = 0.01755674330369199
Trained batch 278 in epoch 1, gen_loss = 1.0275765187424144, disc_loss = 0.01749690858108754
Trained batch 279 in epoch 1, gen_loss = 1.0282836169004441, disc_loss = 0.017437507106296834
Trained batch 280 in epoch 1, gen_loss = 1.028303393689763, disc_loss = 0.017378581448089833
Trained batch 281 in epoch 1, gen_loss = 1.0287064216661115, disc_loss = 0.017323286546440053
Trained batch 282 in epoch 1, gen_loss = 1.0285153797574262, disc_loss = 0.017270706476906542
Trained batch 283 in epoch 1, gen_loss = 1.0287090191538906, disc_loss = 0.017215051265787186
Trained batch 284 in epoch 1, gen_loss = 1.0290503539537128, disc_loss = 0.01715847365042448
Trained batch 285 in epoch 1, gen_loss = 1.028864861785115, disc_loss = 0.017101448769646557
Trained batch 286 in epoch 1, gen_loss = 1.0290945892965337, disc_loss = 0.017043950878810187
Trained batch 287 in epoch 1, gen_loss = 1.0289898245698876, disc_loss = 0.0169871434683652
Trained batch 288 in epoch 1, gen_loss = 1.0291452246966246, disc_loss = 0.0169304089340648
Trained batch 289 in epoch 1, gen_loss = 1.0288099601350982, disc_loss = 0.016877389256390825
Trained batch 290 in epoch 1, gen_loss = 1.0287902490379883, disc_loss = 0.016823029584806217
Trained batch 291 in epoch 1, gen_loss = 1.0284560281936437, disc_loss = 0.01676974640452512
Trained batch 292 in epoch 1, gen_loss = 1.0288202628340737, disc_loss = 0.016716751702232746
Trained batch 293 in epoch 1, gen_loss = 1.0287195373149145, disc_loss = 0.016666781424089783
Trained batch 294 in epoch 1, gen_loss = 1.0285548135385676, disc_loss = 0.01661514935899581
Trained batch 295 in epoch 1, gen_loss = 1.0285500439034927, disc_loss = 0.016563507933529467
Trained batch 296 in epoch 1, gen_loss = 1.0290691284619597, disc_loss = 0.016513113372185837
Trained batch 297 in epoch 1, gen_loss = 1.028917866665245, disc_loss = 0.016462225518484315
Trained batch 298 in epoch 1, gen_loss = 1.0288066202182833, disc_loss = 0.016409968375179676
Trained batch 299 in epoch 1, gen_loss = 1.029496272802353, disc_loss = 0.01637050414647092
Trained batch 300 in epoch 1, gen_loss = 1.028988979979607, disc_loss = 0.016322446939412837
Trained batch 301 in epoch 1, gen_loss = 1.0291769559809705, disc_loss = 0.016277372889058426
Trained batch 302 in epoch 1, gen_loss = 1.0291481623948604, disc_loss = 0.016226840211974115
Trained batch 303 in epoch 1, gen_loss = 1.0293284533055205, disc_loss = 0.016180321629690297
Trained batch 304 in epoch 1, gen_loss = 1.0298329185266963, disc_loss = 0.016132503920034354
Trained batch 305 in epoch 1, gen_loss = 1.0302194773761275, disc_loss = 0.016081925257239598
Trained batch 306 in epoch 1, gen_loss = 1.0300242759117475, disc_loss = 0.01603471882676771
Trained batch 307 in epoch 1, gen_loss = 1.0299577331775194, disc_loss = 0.015988449385537472
Trained batch 308 in epoch 1, gen_loss = 1.0302785606060214, disc_loss = 0.015940638739172244
Trained batch 309 in epoch 1, gen_loss = 1.0301993898807034, disc_loss = 0.015904240854856214
Trained batch 310 in epoch 1, gen_loss = 1.0299531631531056, disc_loss = 0.015860549732883627
Trained batch 311 in epoch 1, gen_loss = 1.0301116517721078, disc_loss = 0.015816764150235356
Trained batch 312 in epoch 1, gen_loss = 1.0297195231571745, disc_loss = 0.01577050529267697
Trained batch 313 in epoch 1, gen_loss = 1.0300155853389934, disc_loss = 0.015730557396885964
Trained batch 314 in epoch 1, gen_loss = 1.0301806164166285, disc_loss = 0.01568557232011309
Trained batch 315 in epoch 1, gen_loss = 1.0303383365839343, disc_loss = 0.015643376096796842
Trained batch 316 in epoch 1, gen_loss = 1.0302783263970625, disc_loss = 0.015597751065315635
Trained batch 317 in epoch 1, gen_loss = 1.0304955223446373, disc_loss = 0.01555310899944377
Trained batch 318 in epoch 1, gen_loss = 1.030925055843162, disc_loss = 0.015506801174778045
Trained batch 319 in epoch 1, gen_loss = 1.030986930988729, disc_loss = 0.015460499399841865
Trained batch 320 in epoch 1, gen_loss = 1.0307286500559418, disc_loss = 0.01541895310029444
Trained batch 321 in epoch 1, gen_loss = 1.0309295678360861, disc_loss = 0.015373377267136426
Trained batch 322 in epoch 1, gen_loss = 1.0306224385651273, disc_loss = 0.015328619207049022
Trained batch 323 in epoch 1, gen_loss = 1.0307370312052009, disc_loss = 0.015283952389488408
Trained batch 324 in epoch 1, gen_loss = 1.0305254747317387, disc_loss = 0.015239234749326267
Trained batch 325 in epoch 1, gen_loss = 1.030744983923216, disc_loss = 0.01520567778079232
Trained batch 326 in epoch 1, gen_loss = 1.0307606599017385, disc_loss = 0.015167051612921785
Trained batch 327 in epoch 1, gen_loss = 1.0310024377412912, disc_loss = 0.015124425394189041
Trained batch 328 in epoch 1, gen_loss = 1.030924018936679, disc_loss = 0.015083359595411882
Trained batch 329 in epoch 1, gen_loss = 1.0315138125058376, disc_loss = 0.015047207334260527
Trained batch 330 in epoch 1, gen_loss = 1.031480229333088, disc_loss = 0.015008312249737314
Trained batch 331 in epoch 1, gen_loss = 1.0316842422786965, disc_loss = 0.014966800557097058
Trained batch 332 in epoch 1, gen_loss = 1.031669348030835, disc_loss = 0.014925286250338224
Trained batch 333 in epoch 1, gen_loss = 1.03179309735755, disc_loss = 0.014884489621508038
Trained batch 334 in epoch 1, gen_loss = 1.0320354025755356, disc_loss = 0.01484455982906876
Trained batch 335 in epoch 1, gen_loss = 1.0324490047281696, disc_loss = 0.014804351716910398
Trained batch 336 in epoch 1, gen_loss = 1.0326015084362878, disc_loss = 0.014762451588229735
Trained batch 337 in epoch 1, gen_loss = 1.032746862906676, disc_loss = 0.014722737278016049
Trained batch 338 in epoch 1, gen_loss = 1.0331437234329965, disc_loss = 0.014682936435041654
Trained batch 339 in epoch 1, gen_loss = 1.0331096976995469, disc_loss = 0.014641654623204993
Trained batch 340 in epoch 1, gen_loss = 1.0331366920401275, disc_loss = 0.014608532319668492
Trained batch 341 in epoch 1, gen_loss = 1.0330845980267775, disc_loss = 0.014574146550038096
Trained batch 342 in epoch 1, gen_loss = 1.0338924252604604, disc_loss = 0.014547749124791502
Trained batch 343 in epoch 1, gen_loss = 1.03426666263231, disc_loss = 0.014517727509290887
Trained batch 344 in epoch 1, gen_loss = 1.034622281703396, disc_loss = 0.014483661117138462
Trained batch 345 in epoch 1, gen_loss = 1.0342601191446272, disc_loss = 0.014461901273356005
Trained batch 346 in epoch 1, gen_loss = 1.034358072177821, disc_loss = 0.014439400260278658
Trained batch 347 in epoch 1, gen_loss = 1.0344064285357792, disc_loss = 0.014407436230550078
Trained batch 348 in epoch 1, gen_loss = 1.0340041902481998, disc_loss = 0.014375487846456786
Trained batch 349 in epoch 1, gen_loss = 1.0336966047968184, disc_loss = 0.01434754585410701
Trained batch 350 in epoch 1, gen_loss = 1.0335860585215424, disc_loss = 0.014315044507674509
Trained batch 351 in epoch 1, gen_loss = 1.0338788699697365, disc_loss = 0.014281322276350362
Trained batch 352 in epoch 1, gen_loss = 1.033863552231289, disc_loss = 0.014247818648438866
Trained batch 353 in epoch 1, gen_loss = 1.0343594884468337, disc_loss = 0.014217083292674881
Trained batch 354 in epoch 1, gen_loss = 1.0343236553836876, disc_loss = 0.014180612355810066
Trained batch 355 in epoch 1, gen_loss = 1.0340239198020336, disc_loss = 0.014153888563158218
Trained batch 356 in epoch 1, gen_loss = 1.034154040472848, disc_loss = 0.014128460663888297
Trained batch 357 in epoch 1, gen_loss = 1.0342421348534483, disc_loss = 0.014092346267635197
Trained batch 358 in epoch 1, gen_loss = 1.0343031926407456, disc_loss = 0.014072778512109889
Trained batch 359 in epoch 1, gen_loss = 1.0344253768523535, disc_loss = 0.014041471280143015
Trained batch 360 in epoch 1, gen_loss = 1.0343756556841146, disc_loss = 0.014015631479947374
Trained batch 361 in epoch 1, gen_loss = 1.034377745501903, disc_loss = 0.013985447920638572
Trained batch 362 in epoch 1, gen_loss = 1.0347294505305855, disc_loss = 0.013954905510170337
Trained batch 363 in epoch 1, gen_loss = 1.0350869664779077, disc_loss = 0.013927931717562087
Trained batch 364 in epoch 1, gen_loss = 1.0353810133999342, disc_loss = 0.013899481045169922
Trained batch 365 in epoch 1, gen_loss = 1.0353760540159673, disc_loss = 0.01388274382953653
Trained batch 366 in epoch 1, gen_loss = 1.0362248946925274, disc_loss = 0.013952614778831375
Trained batch 367 in epoch 1, gen_loss = 1.0361183593454568, disc_loss = 0.013945725957732382
Trained batch 368 in epoch 1, gen_loss = 1.0358598726551707, disc_loss = 0.013952776515781614
Trained batch 369 in epoch 1, gen_loss = 1.035925088379834, disc_loss = 0.013937910156587227
Trained batch 370 in epoch 1, gen_loss = 1.0361312897700183, disc_loss = 0.01392035616929373
Trained batch 371 in epoch 1, gen_loss = 1.0363514631666162, disc_loss = 0.013889741838459984
Trained batch 372 in epoch 1, gen_loss = 1.0364681936141313, disc_loss = 0.013855864735775571
Trained batch 373 in epoch 1, gen_loss = 1.036618677371326, disc_loss = 0.013824834375613292
Trained batch 374 in epoch 1, gen_loss = 1.0365389267603555, disc_loss = 0.013791696940820353
Trained batch 375 in epoch 1, gen_loss = 1.0365456282458407, disc_loss = 0.013759238418757338
Trained batch 376 in epoch 1, gen_loss = 1.0362585694467357, disc_loss = 0.01376205276995397
Trained batch 377 in epoch 1, gen_loss = 1.0370452009811604, disc_loss = 0.01378224778142924
Trained batch 378 in epoch 1, gen_loss = 1.0373074741036408, disc_loss = 0.013827042166341163
Trained batch 379 in epoch 1, gen_loss = 1.0368529158203226, disc_loss = 0.013841397019898163
Trained batch 380 in epoch 1, gen_loss = 1.0368566417631515, disc_loss = 0.013852611749964336
Trained batch 381 in epoch 1, gen_loss = 1.037149446016831, disc_loss = 0.013825382103530034
Trained batch 382 in epoch 1, gen_loss = 1.0376864953389677, disc_loss = 0.013804366464345769
Trained batch 383 in epoch 1, gen_loss = 1.0376603465216856, disc_loss = 0.013787594310959625
Trained batch 384 in epoch 1, gen_loss = 1.037673658364779, disc_loss = 0.013759091195866598
Trained batch 385 in epoch 1, gen_loss = 1.0375092766136702, disc_loss = 0.013731091269350747
Trained batch 386 in epoch 1, gen_loss = 1.037485646493059, disc_loss = 0.013699645915895025
Trained batch 387 in epoch 1, gen_loss = 1.0377317060207583, disc_loss = 0.01367896375633847
Trained batch 388 in epoch 1, gen_loss = 1.037463178824643, disc_loss = 0.013649814445511941
Trained batch 389 in epoch 1, gen_loss = 1.0372102549442879, disc_loss = 0.013640109432274655
Trained batch 390 in epoch 1, gen_loss = 1.037091663883775, disc_loss = 0.013611653908368741
Trained batch 391 in epoch 1, gen_loss = 1.0368997866705971, disc_loss = 0.013584591099617906
Trained batch 392 in epoch 1, gen_loss = 1.0365975617452432, disc_loss = 0.013572369994198414
Trained batch 393 in epoch 1, gen_loss = 1.0365233359300545, disc_loss = 0.013556241294743462
Trained batch 394 in epoch 1, gen_loss = 1.0367031101939044, disc_loss = 0.013527039217407508
Trained batch 395 in epoch 1, gen_loss = 1.0364122472026132, disc_loss = 0.013499026658856298
Trained batch 396 in epoch 1, gen_loss = 1.0365198619419742, disc_loss = 0.0134691224082403
Trained batch 397 in epoch 1, gen_loss = 1.036867205521569, disc_loss = 0.013439110978633744
Trained batch 398 in epoch 1, gen_loss = 1.0368426076152868, disc_loss = 0.01340808556207256
Trained batch 399 in epoch 1, gen_loss = 1.0369727244973184, disc_loss = 0.013377436233822664
Trained batch 400 in epoch 1, gen_loss = 1.0365738607106958, disc_loss = 0.013348545396589893
Trained batch 401 in epoch 1, gen_loss = 1.0365713561945293, disc_loss = 0.013321330687991143
Trained batch 402 in epoch 1, gen_loss = 1.0366898038547032, disc_loss = 0.013291848622048423
Trained batch 403 in epoch 1, gen_loss = 1.036343116276335, disc_loss = 0.013300371943824028
Trained batch 404 in epoch 1, gen_loss = 1.03712765817289, disc_loss = 0.01331616254422072
Trained batch 405 in epoch 1, gen_loss = 1.0374948913827906, disc_loss = 0.013305693036402642
Trained batch 406 in epoch 1, gen_loss = 1.0374471640411114, disc_loss = 0.01328860685261194
Trained batch 407 in epoch 1, gen_loss = 1.0374820229469561, disc_loss = 0.013262020673637916
Trained batch 408 in epoch 1, gen_loss = 1.0371212338468556, disc_loss = 0.013683547230212822
Trained batch 409 in epoch 1, gen_loss = 1.0360888305233746, disc_loss = 0.01571489971712453
Trained batch 410 in epoch 1, gen_loss = 1.0354105398022635, disc_loss = 0.01652547411946778
Trained batch 411 in epoch 1, gen_loss = 1.0353617001216389, disc_loss = 0.017881614701658232
Trained batch 412 in epoch 1, gen_loss = 1.0351055732073564, disc_loss = 0.018503218305997098
Trained batch 413 in epoch 1, gen_loss = 1.0342404717120572, disc_loss = 0.018855651681656458
Trained batch 414 in epoch 1, gen_loss = 1.033542179343212, disc_loss = 0.019153500135941713
Trained batch 415 in epoch 1, gen_loss = 1.0326097199263482, disc_loss = 0.019348318324458748
Trained batch 416 in epoch 1, gen_loss = 1.031897744257673, disc_loss = 0.01950254020913045
Trained batch 417 in epoch 1, gen_loss = 1.0314487635233756, disc_loss = 0.01965615450391077
Trained batch 418 in epoch 1, gen_loss = 1.0305380366013557, disc_loss = 0.019839741710509808
Trained batch 419 in epoch 1, gen_loss = 1.03044261492434, disc_loss = 0.019853783561536276
Trained batch 420 in epoch 1, gen_loss = 1.030347238385479, disc_loss = 0.019845332767538706
Trained batch 421 in epoch 1, gen_loss = 1.0298161705805793, disc_loss = 0.0199981196085198
Trained batch 422 in epoch 1, gen_loss = 1.0291055263356959, disc_loss = 0.02014025068540103
Trained batch 423 in epoch 1, gen_loss = 1.0292093455791473, disc_loss = 0.020112287260520324
Trained batch 424 in epoch 1, gen_loss = 1.0293639500000897, disc_loss = 0.02030494475048994
Trained batch 425 in epoch 1, gen_loss = 1.0284755161390617, disc_loss = 0.021111280170613363
Trained batch 426 in epoch 1, gen_loss = 1.0281502150819228, disc_loss = 0.021220914276546595
Trained batch 427 in epoch 1, gen_loss = 1.0279154642441561, disc_loss = 0.0214955192654615
Trained batch 428 in epoch 1, gen_loss = 1.0273904357201014, disc_loss = 0.021579618549151053
Trained batch 429 in epoch 1, gen_loss = 1.0270454674266105, disc_loss = 0.021580757992037538
Trained batch 430 in epoch 1, gen_loss = 1.026595348133565, disc_loss = 0.021608773431719904
Trained batch 431 in epoch 1, gen_loss = 1.026500545580078, disc_loss = 0.02160852017708816
Trained batch 432 in epoch 1, gen_loss = 1.0271172646011546, disc_loss = 0.021643988098474662
Trained batch 433 in epoch 1, gen_loss = 1.026955543437861, disc_loss = 0.02163626185227652
Trained batch 434 in epoch 1, gen_loss = 1.0265721511566777, disc_loss = 0.02169133023403708
Trained batch 435 in epoch 1, gen_loss = 1.0259900638543138, disc_loss = 0.021915712823936184
Trained batch 436 in epoch 1, gen_loss = 1.0262133440927728, disc_loss = 0.02199288621595853
Trained batch 437 in epoch 1, gen_loss = 1.026170420183983, disc_loss = 0.021995768761898862
Trained batch 438 in epoch 1, gen_loss = 1.0261736199904683, disc_loss = 0.021971531635263546
Trained batch 439 in epoch 1, gen_loss = 1.0266826346516609, disc_loss = 0.02193733559023795
Trained batch 440 in epoch 1, gen_loss = 1.0263321369953977, disc_loss = 0.022013477764329704
Trained batch 441 in epoch 1, gen_loss = 1.0266161968265723, disc_loss = 0.02210940587793543
Trained batch 442 in epoch 1, gen_loss = 1.0267292414508071, disc_loss = 0.022107224237365893
Trained batch 443 in epoch 1, gen_loss = 1.0270274861438855, disc_loss = 0.022092263800266927
Trained batch 444 in epoch 1, gen_loss = 1.0270246945070416, disc_loss = 0.022064884788365876
Trained batch 445 in epoch 1, gen_loss = 1.0272450703676506, disc_loss = 0.022036416379591573
Trained batch 446 in epoch 1, gen_loss = 1.0280281003956293, disc_loss = 0.02201566742537142
Trained batch 447 in epoch 1, gen_loss = 1.0282015930861235, disc_loss = 0.021982928805268136
Trained batch 448 in epoch 1, gen_loss = 1.0280731284538729, disc_loss = 0.02197969411232095
Trained batch 449 in epoch 1, gen_loss = 1.0288079656494988, disc_loss = 0.0220563510067748
Trained batch 450 in epoch 1, gen_loss = 1.02943992112534, disc_loss = 0.022032457844429327
Trained batch 451 in epoch 1, gen_loss = 1.0296782877592914, disc_loss = 0.022023234904486946
Trained batch 452 in epoch 1, gen_loss = 1.0297321191686668, disc_loss = 0.021986594333930947
Trained batch 453 in epoch 1, gen_loss = 1.0298754662144027, disc_loss = 0.02194941519743056
Trained batch 454 in epoch 1, gen_loss = 1.0300142214848444, disc_loss = 0.02190875607196646
Trained batch 455 in epoch 1, gen_loss = 1.0302043157188516, disc_loss = 0.021880260885920603
Trained batch 456 in epoch 1, gen_loss = 1.030677281532037, disc_loss = 0.02184132090588207
Trained batch 457 in epoch 1, gen_loss = 1.0305003600609874, disc_loss = 0.02184081224972605
Trained batch 458 in epoch 1, gen_loss = 1.0310344227258936, disc_loss = 0.02185379640903189
Trained batch 459 in epoch 1, gen_loss = 1.031107039425684, disc_loss = 0.02183950587511746
Trained batch 460 in epoch 1, gen_loss = 1.0312162230433715, disc_loss = 0.02190383280843467
Trained batch 461 in epoch 1, gen_loss = 1.0321882213606979, disc_loss = 0.02196859092991754
Trained batch 462 in epoch 1, gen_loss = 1.0325051665821035, disc_loss = 0.021952046447233135
Trained batch 463 in epoch 1, gen_loss = 1.0325880424472793, disc_loss = 0.021983396012760278
Trained batch 464 in epoch 1, gen_loss = 1.0335706260896498, disc_loss = 0.021950781519333232
Trained batch 465 in epoch 1, gen_loss = 1.0339950170895573, disc_loss = 0.02192180903696294
Trained batch 466 in epoch 1, gen_loss = 1.0345471320111441, disc_loss = 0.021950688509975273
Trained batch 467 in epoch 1, gen_loss = 1.0344024984500346, disc_loss = 0.022093846949938493
Trained batch 468 in epoch 1, gen_loss = 1.0352345083568142, disc_loss = 0.022775330715523567
Trained batch 469 in epoch 1, gen_loss = 1.0351380978492981, disc_loss = 0.023001456484316223
Trained batch 470 in epoch 1, gen_loss = 1.0343564666507097, disc_loss = 0.023370890292573093
Trained batch 471 in epoch 1, gen_loss = 1.0346016306745804, disc_loss = 0.023542201684873455
Trained batch 472 in epoch 1, gen_loss = 1.034561566646205, disc_loss = 0.02370174749122207
Trained batch 473 in epoch 1, gen_loss = 1.0351146596645, disc_loss = 0.023713992478026084
Trained batch 474 in epoch 1, gen_loss = 1.035479522880755, disc_loss = 0.023709407230857515
Trained batch 475 in epoch 1, gen_loss = 1.035580035893857, disc_loss = 0.023697086548971496
Trained batch 476 in epoch 1, gen_loss = 1.0358841432965276, disc_loss = 0.023673683793187107
Trained batch 477 in epoch 1, gen_loss = 1.0362886730347718, disc_loss = 0.023635042939162434
Trained batch 478 in epoch 1, gen_loss = 1.036658355861218, disc_loss = 0.02359353871755414
Trained batch 479 in epoch 1, gen_loss = 1.0369669135659934, disc_loss = 0.02355206070615168
Trained batch 480 in epoch 1, gen_loss = 1.0374557938496436, disc_loss = 0.02351970208216175
Trained batch 481 in epoch 1, gen_loss = 1.03758377887896, disc_loss = 0.023486284986137137
Trained batch 482 in epoch 1, gen_loss = 1.037875753381978, disc_loss = 0.02344437601985617
Trained batch 483 in epoch 1, gen_loss = 1.0379648626096978, disc_loss = 0.023482978387950094
Trained batch 484 in epoch 1, gen_loss = 1.0375449940101387, disc_loss = 0.023505150701234972
Trained batch 485 in epoch 1, gen_loss = 1.037444455510795, disc_loss = 0.02347890113802208
Trained batch 486 in epoch 1, gen_loss = 1.0378413811111842, disc_loss = 0.02344699118840838
Trained batch 487 in epoch 1, gen_loss = 1.0378958075994351, disc_loss = 0.02341565890516203
Trained batch 488 in epoch 1, gen_loss = 1.0380181701880535, disc_loss = 0.023375174155141464
Trained batch 489 in epoch 1, gen_loss = 1.038102030389163, disc_loss = 0.02333688919918911
Trained batch 490 in epoch 1, gen_loss = 1.0381658488766967, disc_loss = 0.023299493830452593
Trained batch 491 in epoch 1, gen_loss = 1.0384802119276388, disc_loss = 0.02326624402730812
Trained batch 492 in epoch 1, gen_loss = 1.038570527735395, disc_loss = 0.02322723564682278
Trained batch 493 in epoch 1, gen_loss = 1.038506849212685, disc_loss = 0.02318685489627396
Trained batch 494 in epoch 1, gen_loss = 1.0384418686230978, disc_loss = 0.023148135386255684
Trained batch 495 in epoch 1, gen_loss = 1.0383409935860866, disc_loss = 0.02310725062497729
Trained batch 496 in epoch 1, gen_loss = 1.038123062558817, disc_loss = 0.023077547634731355
Trained batch 497 in epoch 1, gen_loss = 1.038398048126075, disc_loss = 0.02303809211114267
Trained batch 498 in epoch 1, gen_loss = 1.038026137796337, disc_loss = 0.023059529374335624
Trained batch 499 in epoch 1, gen_loss = 1.037940761446953, disc_loss = 0.02306536218218389
Trained batch 500 in epoch 1, gen_loss = 1.0373595621057614, disc_loss = 0.02307131771295552
Trained batch 501 in epoch 1, gen_loss = 1.0371860884337787, disc_loss = 0.023045213548650925
Trained batch 502 in epoch 1, gen_loss = 1.0373502219647583, disc_loss = 0.02305853818693114
Trained batch 503 in epoch 1, gen_loss = 1.0371802945931752, disc_loss = 0.023046496306426613
Trained batch 504 in epoch 1, gen_loss = 1.0371660060221606, disc_loss = 0.023018007526966044
Trained batch 505 in epoch 1, gen_loss = 1.0372378668295066, disc_loss = 0.022977997428062787
Trained batch 506 in epoch 1, gen_loss = 1.0370680600463522, disc_loss = 0.022991522159022133
Trained batch 507 in epoch 1, gen_loss = 1.0374205528985796, disc_loss = 0.022982479462428266
Trained batch 508 in epoch 1, gen_loss = 1.0374572603782175, disc_loss = 0.02295304576370363
Trained batch 509 in epoch 1, gen_loss = 1.0373819542866127, disc_loss = 0.0229242781768085
Trained batch 510 in epoch 1, gen_loss = 1.0374642407590862, disc_loss = 0.022898535549187523
Trained batch 511 in epoch 1, gen_loss = 1.0372994480421767, disc_loss = 0.022871206245980602
Trained batch 512 in epoch 1, gen_loss = 1.0375078011442114, disc_loss = 0.02283678680077285
Trained batch 513 in epoch 1, gen_loss = 1.0377583567502433, disc_loss = 0.02281491505590803
Trained batch 514 in epoch 1, gen_loss = 1.037887238877491, disc_loss = 0.022780867819465218
Trained batch 515 in epoch 1, gen_loss = 1.0378013782260953, disc_loss = 0.022750593006876867
Trained batch 516 in epoch 1, gen_loss = 1.0375331990723453, disc_loss = 0.022735099129601043
Trained batch 517 in epoch 1, gen_loss = 1.0378971751132067, disc_loss = 0.022793153415695436
Trained batch 518 in epoch 1, gen_loss = 1.0378186838245576, disc_loss = 0.02277371724629537
Trained batch 519 in epoch 1, gen_loss = 1.0381394425263772, disc_loss = 0.02274663983998135
Trained batch 520 in epoch 1, gen_loss = 1.0380081766626428, disc_loss = 0.022725185037709213
Trained batch 521 in epoch 1, gen_loss = 1.0382980211027737, disc_loss = 0.02269293873820528
Trained batch 522 in epoch 1, gen_loss = 1.0385496773637732, disc_loss = 0.02266753104848259
Trained batch 523 in epoch 1, gen_loss = 1.038569492693166, disc_loss = 0.022631308010294775
Trained batch 524 in epoch 1, gen_loss = 1.038181806518918, disc_loss = 0.02262418517374456
Trained batch 525 in epoch 1, gen_loss = 1.0383815307580926, disc_loss = 0.022609878023093728
Trained batch 526 in epoch 1, gen_loss = 1.0386073473961122, disc_loss = 0.022585623837278253
Trained batch 527 in epoch 1, gen_loss = 1.0385622262503162, disc_loss = 0.022552606718239655
Trained batch 528 in epoch 1, gen_loss = 1.0384095394543753, disc_loss = 0.022518556886976487
Trained batch 529 in epoch 1, gen_loss = 1.0386411359849965, disc_loss = 0.022487508413960657
Trained batch 530 in epoch 1, gen_loss = 1.0381407186585407, disc_loss = 0.02256733889749301
Trained batch 531 in epoch 1, gen_loss = 1.038417604520805, disc_loss = 0.022590007023513624
Trained batch 532 in epoch 1, gen_loss = 1.0386022178361831, disc_loss = 0.02294451588876506
Trained batch 533 in epoch 1, gen_loss = 1.0381183975868011, disc_loss = 0.0231081093781118
Trained batch 534 in epoch 1, gen_loss = 1.0374638570803347, disc_loss = 0.023515522918445234
Trained batch 535 in epoch 1, gen_loss = 1.0380957869451437, disc_loss = 0.023698583418787274
Trained batch 536 in epoch 1, gen_loss = 1.0385620567385712, disc_loss = 0.023808220474003272
Trained batch 537 in epoch 1, gen_loss = 1.0385383584685486, disc_loss = 0.02381063250932028
Trained batch 538 in epoch 1, gen_loss = 1.03829319656227, disc_loss = 0.02382923519916047
Trained batch 539 in epoch 1, gen_loss = 1.0383220536841287, disc_loss = 0.023817671583377956
Trained batch 540 in epoch 1, gen_loss = 1.0384769579619444, disc_loss = 0.023790620990172193
Trained batch 541 in epoch 1, gen_loss = 1.0382531374363002, disc_loss = 0.02385584481476228
Trained batch 542 in epoch 1, gen_loss = 1.0377012497812346, disc_loss = 0.02391748146762755
Trained batch 543 in epoch 1, gen_loss = 1.0374529152451193, disc_loss = 0.02397304165207756
Trained batch 544 in epoch 1, gen_loss = 1.0372391999314685, disc_loss = 0.024006667876495434
Trained batch 545 in epoch 1, gen_loss = 1.037725384746279, disc_loss = 0.02399771664636069
Trained batch 546 in epoch 1, gen_loss = 1.0377910401964971, disc_loss = 0.023978806083520297
Trained batch 547 in epoch 1, gen_loss = 1.037882902870213, disc_loss = 0.023944126873507197
Trained batch 548 in epoch 1, gen_loss = 1.0380965355098357, disc_loss = 0.02391644534486866
Trained batch 549 in epoch 1, gen_loss = 1.0380658621137793, disc_loss = 0.023883500153976705
Trained batch 550 in epoch 1, gen_loss = 1.038152533196278, disc_loss = 0.02386144177369438
Trained batch 551 in epoch 1, gen_loss = 1.038596300435239, disc_loss = 0.023829473605803578
Trained batch 552 in epoch 1, gen_loss = 1.03845712235349, disc_loss = 0.023814940227002576
Trained batch 553 in epoch 1, gen_loss = 1.0384682054338903, disc_loss = 0.023791681561342294
Trained batch 554 in epoch 1, gen_loss = 1.0384800808923738, disc_loss = 0.023757779508223966
Trained batch 555 in epoch 1, gen_loss = 1.0390451542979522, disc_loss = 0.0237415090792219
Trained batch 556 in epoch 1, gen_loss = 1.0392895191105307, disc_loss = 0.0237129251035572
Trained batch 557 in epoch 1, gen_loss = 1.0390903862146494, disc_loss = 0.023691720466685898
Trained batch 558 in epoch 1, gen_loss = 1.0394828261970834, disc_loss = 0.023666524775391853
Trained batch 559 in epoch 1, gen_loss = 1.039886431821755, disc_loss = 0.0236357694963382
Trained batch 560 in epoch 1, gen_loss = 1.0399448072634065, disc_loss = 0.02363895892545663
Trained batch 561 in epoch 1, gen_loss = 1.0400581898638361, disc_loss = 0.023608147555039788
Trained batch 562 in epoch 1, gen_loss = 1.0401397145239117, disc_loss = 0.02358809438284191
Trained batch 563 in epoch 1, gen_loss = 1.040316973172181, disc_loss = 0.023551212386524342
Trained batch 564 in epoch 1, gen_loss = 1.0403837001429195, disc_loss = 0.023514385023787904
Trained batch 565 in epoch 1, gen_loss = 1.0404376366534418, disc_loss = 0.023477844224415692
Trained batch 566 in epoch 1, gen_loss = 1.0403832592451172, disc_loss = 0.02344066809595015
Trained batch 567 in epoch 1, gen_loss = 1.0404732011153663, disc_loss = 0.023401847754581134
Trained batch 568 in epoch 1, gen_loss = 1.040455976144291, disc_loss = 0.023364670362882277
Trained batch 569 in epoch 1, gen_loss = 1.0403899188627277, disc_loss = 0.023327443860813347
Trained batch 570 in epoch 1, gen_loss = 1.040421191113634, disc_loss = 0.023290136742751984
Trained batch 571 in epoch 1, gen_loss = 1.0405641550367528, disc_loss = 0.023252532008189303
Trained batch 572 in epoch 1, gen_loss = 1.040601514188823, disc_loss = 0.02323498394838343
Trained batch 573 in epoch 1, gen_loss = 1.0403238221328017, disc_loss = 0.02322807079924896
Trained batch 574 in epoch 1, gen_loss = 1.0407993693973707, disc_loss = 0.023230220843891047
Trained batch 575 in epoch 1, gen_loss = 1.0409955287145243, disc_loss = 0.023195213972106405
Trained batch 576 in epoch 1, gen_loss = 1.0410490639288257, disc_loss = 0.02316567269385412
Trained batch 577 in epoch 1, gen_loss = 1.0412885932361378, disc_loss = 0.023131597292855032
Trained batch 578 in epoch 1, gen_loss = 1.0413476016649104, disc_loss = 0.023095551534371477
Trained batch 579 in epoch 1, gen_loss = 1.0416409301346745, disc_loss = 0.02305990684943591
Trained batch 580 in epoch 1, gen_loss = 1.0418926436396352, disc_loss = 0.023037728720853343
Trained batch 581 in epoch 1, gen_loss = 1.04200764845327, disc_loss = 0.023016710817241597
Trained batch 582 in epoch 1, gen_loss = 1.0421418939201132, disc_loss = 0.022984929248988335
Trained batch 583 in epoch 1, gen_loss = 1.0424491663093436, disc_loss = 0.022952282954738373
Trained batch 584 in epoch 1, gen_loss = 1.0424761175090431, disc_loss = 0.022968691422252788
Trained batch 585 in epoch 1, gen_loss = 1.042148892688263, disc_loss = 0.023313578116879743
Trained batch 586 in epoch 1, gen_loss = 1.042440470377875, disc_loss = 0.024099866706088425
Trained batch 587 in epoch 1, gen_loss = 1.0421180473703917, disc_loss = 0.024319882257927652
Trained batch 588 in epoch 1, gen_loss = 1.0417070508205628, disc_loss = 0.02456842677891377
Trained batch 589 in epoch 1, gen_loss = 1.0413706065234491, disc_loss = 0.024653194617786863
Trained batch 590 in epoch 1, gen_loss = 1.0411220237284948, disc_loss = 0.024746138949549752
Trained batch 591 in epoch 1, gen_loss = 1.04074054865821, disc_loss = 0.024794411405383545
Trained batch 592 in epoch 1, gen_loss = 1.040354352475821, disc_loss = 0.02484331361697276
Trained batch 593 in epoch 1, gen_loss = 1.0402051466281967, disc_loss = 0.024893178344642084
Trained batch 594 in epoch 1, gen_loss = 1.0402032141925908, disc_loss = 0.02493806008067072
Trained batch 595 in epoch 1, gen_loss = 1.0399979764983158, disc_loss = 0.02505905512481949
Trained batch 596 in epoch 1, gen_loss = 1.0402717538415087, disc_loss = 0.02539662998112623
Trained batch 597 in epoch 1, gen_loss = 1.0398587125998278, disc_loss = 0.025537200820651553
Trained batch 598 in epoch 1, gen_loss = 1.0394567566642379, disc_loss = 0.02572670307836689
Trained batch 599 in epoch 1, gen_loss = 1.0394312617182733, disc_loss = 0.02612396366930625
Trained batch 600 in epoch 1, gen_loss = 1.0390728239013431, disc_loss = 0.026403856704284873
Trained batch 601 in epoch 1, gen_loss = 1.0389264268534524, disc_loss = 0.026460484357486345
Trained batch 602 in epoch 1, gen_loss = 1.0386214142612755, disc_loss = 0.026624651239993965
Trained batch 603 in epoch 1, gen_loss = 1.0385900519738924, disc_loss = 0.026646402399632917
Trained batch 604 in epoch 1, gen_loss = 1.0381575580470819, disc_loss = 0.026736576264422995
Trained batch 605 in epoch 1, gen_loss = 1.038362233552209, disc_loss = 0.026883017345885447
Trained batch 606 in epoch 1, gen_loss = 1.037810854699702, disc_loss = 0.02695574335286626
Trained batch 607 in epoch 1, gen_loss = 1.0377724260876053, disc_loss = 0.0274266050641927
Trained batch 608 in epoch 1, gen_loss = 1.0372119002741547, disc_loss = 0.028075421434284833
Trained batch 609 in epoch 1, gen_loss = 1.037223116882512, disc_loss = 0.028160076307826562
Trained batch 610 in epoch 1, gen_loss = 1.037349848427281, disc_loss = 0.02842636133310078
Trained batch 611 in epoch 1, gen_loss = 1.037240982055664, disc_loss = 0.02851501986225272
Trained batch 612 in epoch 1, gen_loss = 1.0369215906152522, disc_loss = 0.02856039373789702
Trained batch 613 in epoch 1, gen_loss = 1.0362230281099822, disc_loss = 0.028837709502954643
Trained batch 614 in epoch 1, gen_loss = 1.0362625186036272, disc_loss = 0.029075413724626187
Trained batch 615 in epoch 1, gen_loss = 1.0361175424866862, disc_loss = 0.029142224085085395
Trained batch 616 in epoch 1, gen_loss = 1.036016953049448, disc_loss = 0.029142673195631626
Trained batch 617 in epoch 1, gen_loss = 1.0358733083437948, disc_loss = 0.029121459097409142
Trained batch 618 in epoch 1, gen_loss = 1.0361972910522066, disc_loss = 0.029101502271014587
Trained batch 619 in epoch 1, gen_loss = 1.0361790243656404, disc_loss = 0.029097717820508066
Trained batch 620 in epoch 1, gen_loss = 1.0362039111470638, disc_loss = 0.029099436945089024
Trained batch 621 in epoch 1, gen_loss = 1.036543482944513, disc_loss = 0.029217898298010577
Trained batch 622 in epoch 1, gen_loss = 1.0362331531403728, disc_loss = 0.029474859519421203
Trained batch 623 in epoch 1, gen_loss = 1.0367357779580813, disc_loss = 0.029625432270642287
Trained batch 624 in epoch 1, gen_loss = 1.0365554287910461, disc_loss = 0.029755292776576243
Trained batch 625 in epoch 1, gen_loss = 1.03605908936205, disc_loss = 0.02989340967834111
Trained batch 626 in epoch 1, gen_loss = 1.0361811019587175, disc_loss = 0.029912472689542675
Trained batch 627 in epoch 1, gen_loss = 1.0360451476399306, disc_loss = 0.02990874559149071
Trained batch 628 in epoch 1, gen_loss = 1.0363605360727053, disc_loss = 0.029910377495112793
Trained batch 629 in epoch 1, gen_loss = 1.0363210985584865, disc_loss = 0.029889451414101854
Trained batch 630 in epoch 1, gen_loss = 1.036357062082094, disc_loss = 0.029866541687467597
Trained batch 631 in epoch 1, gen_loss = 1.0370061277777334, disc_loss = 0.029944840435849916
Trained batch 632 in epoch 1, gen_loss = 1.0373976092202968, disc_loss = 0.029929126773556837
Trained batch 633 in epoch 1, gen_loss = 1.03747503793202, disc_loss = 0.029905055513309294
Trained batch 634 in epoch 1, gen_loss = 1.0374437689781189, disc_loss = 0.029869414030324015
Trained batch 635 in epoch 1, gen_loss = 1.0372511929123656, disc_loss = 0.029837654531930987
Trained batch 636 in epoch 1, gen_loss = 1.037087591794821, disc_loss = 0.029899583790600964
Trained batch 637 in epoch 1, gen_loss = 1.0371327240452124, disc_loss = 0.029945934988713573
Trained batch 638 in epoch 1, gen_loss = 1.0375132263173146, disc_loss = 0.030035382002957002
Trained batch 639 in epoch 1, gen_loss = 1.038253574911505, disc_loss = 0.03005640951193982
Trained batch 640 in epoch 1, gen_loss = 1.0386251355296179, disc_loss = 0.030028831296869736
Trained batch 641 in epoch 1, gen_loss = 1.0389291776860614, disc_loss = 0.030004213583296437
Trained batch 642 in epoch 1, gen_loss = 1.0388877350101204, disc_loss = 0.029986916163849898
Trained batch 643 in epoch 1, gen_loss = 1.0389594360723258, disc_loss = 0.029965738938326523
Trained batch 644 in epoch 1, gen_loss = 1.0389743545258692, disc_loss = 0.029927483969525968
Trained batch 645 in epoch 1, gen_loss = 1.0390137008653706, disc_loss = 0.02988733743976902
Trained batch 646 in epoch 1, gen_loss = 1.039060519965023, disc_loss = 0.02995150847828942
Trained batch 647 in epoch 1, gen_loss = 1.0389377210795143, disc_loss = 0.02996000234232292
Trained batch 648 in epoch 1, gen_loss = 1.0390961027843375, disc_loss = 0.02998320880065366
Trained batch 649 in epoch 1, gen_loss = 1.0388893236563757, disc_loss = 0.030156760445343725
Trained batch 650 in epoch 1, gen_loss = 1.0394528542978607, disc_loss = 0.03021503931170987
Trained batch 651 in epoch 1, gen_loss = 1.039668747892409, disc_loss = 0.030193920027616575
Trained batch 652 in epoch 1, gen_loss = 1.0394569770482927, disc_loss = 0.03074819645143323
Trained batch 653 in epoch 1, gen_loss = 1.0388866594625175, disc_loss = 0.031533052629643635
Trained batch 654 in epoch 1, gen_loss = 1.0388140213398533, disc_loss = 0.03201168704214097
Trained batch 655 in epoch 1, gen_loss = 1.038553452073801, disc_loss = 0.03236402041118975
Trained batch 656 in epoch 1, gen_loss = 1.038216951321612, disc_loss = 0.03264848179468028
Trained batch 657 in epoch 1, gen_loss = 1.0378380944120122, disc_loss = 0.03300757272807951
Trained batch 658 in epoch 1, gen_loss = 1.0373632843649985, disc_loss = 0.03330173976865561
Trained batch 659 in epoch 1, gen_loss = 1.0367948505914573, disc_loss = 0.03356633725129403
Trained batch 660 in epoch 1, gen_loss = 1.0366448867339049, disc_loss = 0.03380654147280075
Trained batch 661 in epoch 1, gen_loss = 1.0361405197767333, disc_loss = 0.03401232487484697
Trained batch 662 in epoch 1, gen_loss = 1.0357052046429158, disc_loss = 0.03420110378688925
Trained batch 663 in epoch 1, gen_loss = 1.035218977784536, disc_loss = 0.03442097389374082
Trained batch 664 in epoch 1, gen_loss = 1.0347943011979412, disc_loss = 0.03460507309167117
Trained batch 665 in epoch 1, gen_loss = 1.0342576000783537, disc_loss = 0.034776666716583506
Trained batch 666 in epoch 1, gen_loss = 1.0337259935653549, disc_loss = 0.03500220643436642
Trained batch 667 in epoch 1, gen_loss = 1.0334868316878816, disc_loss = 0.03515520708913504
Trained batch 668 in epoch 1, gen_loss = 1.0331779376273733, disc_loss = 0.03539244560292948
Trained batch 669 in epoch 1, gen_loss = 1.0325133745350055, disc_loss = 0.03561457165674595
Trained batch 670 in epoch 1, gen_loss = 1.0318302428669084, disc_loss = 0.03586285654904342
Trained batch 671 in epoch 1, gen_loss = 1.0311495399191266, disc_loss = 0.03609013301630035
Trained batch 672 in epoch 1, gen_loss = 1.0309141079879975, disc_loss = 0.03631871413156431
Trained batch 673 in epoch 1, gen_loss = 1.0305997099650013, disc_loss = 0.036416710730556925
Trained batch 674 in epoch 1, gen_loss = 1.0301046722906608, disc_loss = 0.03649570492990919
Trained batch 675 in epoch 1, gen_loss = 1.0296102105336782, disc_loss = 0.03664896488717958
Trained batch 676 in epoch 1, gen_loss = 1.0294169034352154, disc_loss = 0.03680161635755191
Trained batch 677 in epoch 1, gen_loss = 1.0292238192220704, disc_loss = 0.03682131144720124
Trained batch 678 in epoch 1, gen_loss = 1.028661296276351, disc_loss = 0.036944814589036944
Trained batch 679 in epoch 1, gen_loss = 1.028392770974075, disc_loss = 0.036999268942450085
Trained batch 680 in epoch 1, gen_loss = 1.0280896079522748, disc_loss = 0.03706808725510681
Trained batch 681 in epoch 1, gen_loss = 1.028051794012271, disc_loss = 0.0373133168834843
Trained batch 682 in epoch 1, gen_loss = 1.0280530647337873, disc_loss = 0.03730661609401571
Trained batch 683 in epoch 1, gen_loss = 1.0279538492884552, disc_loss = 0.03732493569648859
Trained batch 684 in epoch 1, gen_loss = 1.0276730632259898, disc_loss = 0.037434875701675634
Trained batch 685 in epoch 1, gen_loss = 1.0275957808550176, disc_loss = 0.03746458529404337
Trained batch 686 in epoch 1, gen_loss = 1.027731668133576, disc_loss = 0.03761185013505327
Trained batch 687 in epoch 1, gen_loss = 1.02739112087807, disc_loss = 0.03794795504077334
Trained batch 688 in epoch 1, gen_loss = 1.0278278114314696, disc_loss = 0.038050595165718806
Trained batch 689 in epoch 1, gen_loss = 1.0276839499024377, disc_loss = 0.038182256811115374
Trained batch 690 in epoch 1, gen_loss = 1.0269927870692461, disc_loss = 0.03862305455394248
Trained batch 691 in epoch 1, gen_loss = 1.02669621091013, disc_loss = 0.03870757236150063
Trained batch 692 in epoch 1, gen_loss = 1.0267474953230324, disc_loss = 0.039068215270270525
Trained batch 693 in epoch 1, gen_loss = 1.0266504927567859, disc_loss = 0.0390983177996259
Trained batch 694 in epoch 1, gen_loss = 1.026029215527953, disc_loss = 0.03941852767989894
Trained batch 695 in epoch 1, gen_loss = 1.0257992645961114, disc_loss = 0.0395257770188677
Trained batch 696 in epoch 1, gen_loss = 1.0254548344242693, disc_loss = 0.0398575092349634
Trained batch 697 in epoch 1, gen_loss = 1.0255067436435503, disc_loss = 0.039858269777707185
Trained batch 698 in epoch 1, gen_loss = 1.0253653972275096, disc_loss = 0.039833021066723644
Trained batch 699 in epoch 1, gen_loss = 1.0254224737201418, disc_loss = 0.039827473155933796
Trained batch 700 in epoch 1, gen_loss = 1.02507299235816, disc_loss = 0.039922797096176264
Trained batch 701 in epoch 1, gen_loss = 1.0246407623134788, disc_loss = 0.0400932364174199
Trained batch 702 in epoch 1, gen_loss = 1.024451399510819, disc_loss = 0.040436227879086066
Trained batch 703 in epoch 1, gen_loss = 1.024106460115449, disc_loss = 0.04059422405901552
Trained batch 704 in epoch 1, gen_loss = 1.023778314708818, disc_loss = 0.04069635037707201
Trained batch 705 in epoch 1, gen_loss = 1.023514776493267, disc_loss = 0.04088017264564991
Trained batch 706 in epoch 1, gen_loss = 1.0230063700777132, disc_loss = 0.04098597310430023
Trained batch 707 in epoch 1, gen_loss = 1.0224949392558491, disc_loss = 0.04110496979774325
Trained batch 708 in epoch 1, gen_loss = 1.0224113613156909, disc_loss = 0.04120419392253785
Trained batch 709 in epoch 1, gen_loss = 1.0223863110575877, disc_loss = 0.04122269237838262
Trained batch 710 in epoch 1, gen_loss = 1.0220593414393826, disc_loss = 0.0413317046093297
Trained batch 711 in epoch 1, gen_loss = 1.022149897442105, disc_loss = 0.04145070319513191
Trained batch 712 in epoch 1, gen_loss = 1.0219461314307021, disc_loss = 0.04155062165450181
Trained batch 713 in epoch 1, gen_loss = 1.0217408429340822, disc_loss = 0.04160816134023333
Trained batch 714 in epoch 1, gen_loss = 1.022031637005039, disc_loss = 0.041580851790572554
Trained batch 715 in epoch 1, gen_loss = 1.0221376826976265, disc_loss = 0.04154668569168666
Trained batch 716 in epoch 1, gen_loss = 1.0223496749976357, disc_loss = 0.04150340048629304
Trained batch 717 in epoch 1, gen_loss = 1.0223827157844076, disc_loss = 0.04147553992615205
Trained batch 718 in epoch 1, gen_loss = 1.0227097156813811, disc_loss = 0.04144982207125368
Trained batch 719 in epoch 1, gen_loss = 1.0229856092068883, disc_loss = 0.04140892387786153
Trained batch 720 in epoch 1, gen_loss = 1.023119896856988, disc_loss = 0.04140691567583629
Trained batch 721 in epoch 1, gen_loss = 1.023035926336727, disc_loss = 0.04137405706599785
Trained batch 722 in epoch 1, gen_loss = 1.0228955709423102, disc_loss = 0.041388832186270645
Trained batch 723 in epoch 1, gen_loss = 1.023168195183106, disc_loss = 0.04135954169488884
Trained batch 724 in epoch 1, gen_loss = 1.0234166518573102, disc_loss = 0.04131813435106747
Trained batch 725 in epoch 1, gen_loss = 1.023274889826446, disc_loss = 0.04128604509433415
Trained batch 726 in epoch 1, gen_loss = 1.0229229754890012, disc_loss = 0.0412735705865165
Trained batch 727 in epoch 1, gen_loss = 1.023222179039494, disc_loss = 0.041235167278880526
Trained batch 728 in epoch 1, gen_loss = 1.0235567052014407, disc_loss = 0.04119004726833335
Trained batch 729 in epoch 1, gen_loss = 1.0235865751357929, disc_loss = 0.04115166680100741
Trained batch 730 in epoch 1, gen_loss = 1.023730249965892, disc_loss = 0.04110514114369341
Trained batch 731 in epoch 1, gen_loss = 1.023928409717122, disc_loss = 0.04106190689624961
Trained batch 732 in epoch 1, gen_loss = 1.023993947496193, disc_loss = 0.04102355646225449
Trained batch 733 in epoch 1, gen_loss = 1.023786576957079, disc_loss = 0.04108150388532155
Trained batch 734 in epoch 1, gen_loss = 1.0241579543976558, disc_loss = 0.04113844345119025
Trained batch 735 in epoch 1, gen_loss = 1.0243469481558904, disc_loss = 0.041091641464627966
Trained batch 736 in epoch 1, gen_loss = 1.0244500895853443, disc_loss = 0.04104679023050163
Trained batch 737 in epoch 1, gen_loss = 1.0245593821776269, disc_loss = 0.04101454180904376
Trained batch 738 in epoch 1, gen_loss = 1.0247255134647044, disc_loss = 0.040976788411628176
Trained batch 739 in epoch 1, gen_loss = 1.0248988393190746, disc_loss = 0.04094267830508683
Trained batch 740 in epoch 1, gen_loss = 1.024926279559631, disc_loss = 0.04089512870966802
Trained batch 741 in epoch 1, gen_loss = 1.0252124614150055, disc_loss = 0.040846862517355476
Trained batch 742 in epoch 1, gen_loss = 1.0251799098254855, disc_loss = 0.04079883312773192
Trained batch 743 in epoch 1, gen_loss = 1.0251594464625082, disc_loss = 0.04074883002126186
Trained batch 744 in epoch 1, gen_loss = 1.02516909365686, disc_loss = 0.0407087051581346
Trained batch 745 in epoch 1, gen_loss = 1.025302509679871, disc_loss = 0.04066040381211734
Trained batch 746 in epoch 1, gen_loss = 1.0253969114947032, disc_loss = 0.040610312569276004
Trained batch 747 in epoch 1, gen_loss = 1.025545983391012, disc_loss = 0.04055976993894191
Trained batch 748 in epoch 1, gen_loss = 1.025545447149646, disc_loss = 0.04051555306536848
Trained batch 749 in epoch 1, gen_loss = 1.0255390332539875, disc_loss = 0.0404654657849848
Trained batch 750 in epoch 1, gen_loss = 1.0255461050254526, disc_loss = 0.0404149839935256
Trained batch 751 in epoch 1, gen_loss = 1.025435489701464, disc_loss = 0.04036649016437335
Trained batch 752 in epoch 1, gen_loss = 1.0251710286653375, disc_loss = 0.04032634929838485
Trained batch 753 in epoch 1, gen_loss = 1.0252482582782876, disc_loss = 0.04027921861975651
Trained batch 754 in epoch 1, gen_loss = 1.0257121011910848, disc_loss = 0.040235660034243406
Trained batch 755 in epoch 1, gen_loss = 1.0258959094998699, disc_loss = 0.04018879179790337
Trained batch 756 in epoch 1, gen_loss = 1.02616688424089, disc_loss = 0.04013915201511817
Trained batch 757 in epoch 1, gen_loss = 1.0263288516482452, disc_loss = 0.040089288336945306
Trained batch 758 in epoch 1, gen_loss = 1.0264789195871165, disc_loss = 0.04004068566270817
Trained batch 759 in epoch 1, gen_loss = 1.0265174368494436, disc_loss = 0.039990868676422424
Trained batch 760 in epoch 1, gen_loss = 1.026554474692777, disc_loss = 0.03994163082673232
Trained batch 761 in epoch 1, gen_loss = 1.0265380237984845, disc_loss = 0.03989163865843648
Trained batch 762 in epoch 1, gen_loss = 1.0265991686212281, disc_loss = 0.03984183984239745
Trained batch 763 in epoch 1, gen_loss = 1.026501547603707, disc_loss = 0.03979633529549779
Trained batch 764 in epoch 1, gen_loss = 1.0261980698778739, disc_loss = 0.0397715346627295
Trained batch 765 in epoch 1, gen_loss = 1.026402257596855, disc_loss = 0.039731138136113085
Trained batch 766 in epoch 1, gen_loss = 1.0263748214017925, disc_loss = 0.039682547171578764
Trained batch 767 in epoch 1, gen_loss = 1.0263743698596954, disc_loss = 0.03963513561800861
Trained batch 768 in epoch 1, gen_loss = 1.0264114946010674, disc_loss = 0.03958740953329308
Trained batch 769 in epoch 1, gen_loss = 1.0263588118862796, disc_loss = 0.039538789736299755
Trained batch 770 in epoch 1, gen_loss = 1.02645395671038, disc_loss = 0.03949115274278263
Trained batch 771 in epoch 1, gen_loss = 1.0262623083406162, disc_loss = 0.03944786120649989
Trained batch 772 in epoch 1, gen_loss = 1.0262130334645625, disc_loss = 0.03940352629479741
Trained batch 773 in epoch 1, gen_loss = 1.026222429457253, disc_loss = 0.039355199443950536
Trained batch 774 in epoch 1, gen_loss = 1.026262849915412, disc_loss = 0.03930786477535167
Trained batch 775 in epoch 1, gen_loss = 1.0263762282802886, disc_loss = 0.03925980103140881
Trained batch 776 in epoch 1, gen_loss = 1.0263086455362338, disc_loss = 0.0392117566847507
Trained batch 777 in epoch 1, gen_loss = 1.0261514543107972, disc_loss = 0.03916573400651018
Trained batch 778 in epoch 1, gen_loss = 1.0262864089746684, disc_loss = 0.039118667529005675
Trained batch 779 in epoch 1, gen_loss = 1.0262894331644743, disc_loss = 0.03907194857988193
Trained batch 780 in epoch 1, gen_loss = 1.026203939917756, disc_loss = 0.03902469492004573
Trained batch 781 in epoch 1, gen_loss = 1.026156934097295, disc_loss = 0.03897661594088565
Trained batch 782 in epoch 1, gen_loss = 1.026258208970914, disc_loss = 0.038929251743412024
Trained batch 783 in epoch 1, gen_loss = 1.02624003201419, disc_loss = 0.038885025094287456
Trained batch 784 in epoch 1, gen_loss = 1.0261029462905447, disc_loss = 0.03884300860651594
Trained batch 785 in epoch 1, gen_loss = 1.0263288777141475, disc_loss = 0.0387980444409934
Trained batch 786 in epoch 1, gen_loss = 1.0263417905440324, disc_loss = 0.03875104741758346
Trained batch 787 in epoch 1, gen_loss = 1.026527265077315, disc_loss = 0.0387058201713213
Trained batch 788 in epoch 1, gen_loss = 1.0265579555273359, disc_loss = 0.038658828843580184
Trained batch 789 in epoch 1, gen_loss = 1.0265745216532598, disc_loss = 0.0386137361568804
Trained batch 790 in epoch 1, gen_loss = 1.0267461240668363, disc_loss = 0.038569760359728776
Trained batch 791 in epoch 1, gen_loss = 1.0268102597558137, disc_loss = 0.03852479274584509
Trained batch 792 in epoch 1, gen_loss = 1.0267162871691498, disc_loss = 0.038479533991147355
Trained batch 793 in epoch 1, gen_loss = 1.026630204931014, disc_loss = 0.038433640368788775
Trained batch 794 in epoch 1, gen_loss = 1.0264019001954756, disc_loss = 0.03838972326047036
Trained batch 795 in epoch 1, gen_loss = 1.0262649200070444, disc_loss = 0.03834478697084267
Trained batch 796 in epoch 1, gen_loss = 1.0263047732852184, disc_loss = 0.03829931946912967
Trained batch 797 in epoch 1, gen_loss = 1.0264887950175388, disc_loss = 0.03825385981476221
Trained batch 798 in epoch 1, gen_loss = 1.0264693925318042, disc_loss = 0.03820840276828958
Trained batch 799 in epoch 1, gen_loss = 1.0263916758447886, disc_loss = 0.03816233861301953
Trained batch 800 in epoch 1, gen_loss = 1.0264263159773324, disc_loss = 0.03811653462130987
Trained batch 801 in epoch 1, gen_loss = 1.0266513530898866, disc_loss = 0.038070723011304
Trained batch 802 in epoch 1, gen_loss = 1.026538007954138, disc_loss = 0.03802746934173638
Trained batch 803 in epoch 1, gen_loss = 1.0264873265182202, disc_loss = 0.03798181761013253
Trained batch 804 in epoch 1, gen_loss = 1.0266349120910123, disc_loss = 0.03794144115868814
Trained batch 805 in epoch 1, gen_loss = 1.0265453374267512, disc_loss = 0.03789793225722754
Trained batch 806 in epoch 1, gen_loss = 1.0264120324984507, disc_loss = 0.03785437564643621
Trained batch 807 in epoch 1, gen_loss = 1.0264764987301118, disc_loss = 0.03781283010037009
Trained batch 808 in epoch 1, gen_loss = 1.0263242836493645, disc_loss = 0.03777022660654588
Trained batch 809 in epoch 1, gen_loss = 1.026194437786385, disc_loss = 0.03772583483805647
Trained batch 810 in epoch 1, gen_loss = 1.0261868291365674, disc_loss = 0.03768239396036233
Trained batch 811 in epoch 1, gen_loss = 1.026184450963448, disc_loss = 0.0376372521898124
Trained batch 812 in epoch 1, gen_loss = 1.0259986512482093, disc_loss = 0.03760239194179292
Trained batch 813 in epoch 1, gen_loss = 1.0260216945951635, disc_loss = 0.037559252283924184
Trained batch 814 in epoch 1, gen_loss = 1.025833316668411, disc_loss = 0.0375187636422889
Trained batch 815 in epoch 1, gen_loss = 1.0256960633776935, disc_loss = 0.03747667382026074
Trained batch 816 in epoch 1, gen_loss = 1.025560502760851, disc_loss = 0.03743369641470922
Trained batch 817 in epoch 1, gen_loss = 1.0254601745121636, disc_loss = 0.0373915005251667
Trained batch 818 in epoch 1, gen_loss = 1.0253423611759702, disc_loss = 0.03735110371997816
Trained batch 819 in epoch 1, gen_loss = 1.0254581885366905, disc_loss = 0.03731062784547869
Trained batch 820 in epoch 1, gen_loss = 1.0257910817462257, disc_loss = 0.037274091939955026
Trained batch 821 in epoch 1, gen_loss = 1.0260351778091885, disc_loss = 0.03723207647429477
Trained batch 822 in epoch 1, gen_loss = 1.0259592588877764, disc_loss = 0.03718935704903147
Trained batch 823 in epoch 1, gen_loss = 1.0259414339094486, disc_loss = 0.037147341545702164
Trained batch 824 in epoch 1, gen_loss = 1.0259220808925051, disc_loss = 0.03710669806380545
Trained batch 825 in epoch 1, gen_loss = 1.0258311284367745, disc_loss = 0.03706302223488568
Trained batch 826 in epoch 1, gen_loss = 1.0256303813321992, disc_loss = 0.037044878482030724
Trained batch 827 in epoch 1, gen_loss = 1.0254880828413986, disc_loss = 0.037005394553761575
Trained batch 828 in epoch 1, gen_loss = 1.0255206450190848, disc_loss = 0.03696228527749815
Trained batch 829 in epoch 1, gen_loss = 1.025395826331104, disc_loss = 0.03692031544911975
Trained batch 830 in epoch 1, gen_loss = 1.0252378910026825, disc_loss = 0.03687747305136319
Trained batch 831 in epoch 1, gen_loss = 1.0250906203515255, disc_loss = 0.03683586937738535
Trained batch 832 in epoch 1, gen_loss = 1.024970675001339, disc_loss = 0.03679359783089704
Trained batch 833 in epoch 1, gen_loss = 1.0248222631230344, disc_loss = 0.03675546705717156
Trained batch 834 in epoch 1, gen_loss = 1.0248960420756996, disc_loss = 0.03671398636155475
Trained batch 835 in epoch 1, gen_loss = 1.0248265439671191, disc_loss = 0.03667345597046585
Trained batch 836 in epoch 1, gen_loss = 1.024851948485722, disc_loss = 0.036633845797406535
Trained batch 837 in epoch 1, gen_loss = 1.024985558022178, disc_loss = 0.03659434375828752
Trained batch 838 in epoch 1, gen_loss = 1.0250881143775685, disc_loss = 0.036552521582598925
Trained batch 839 in epoch 1, gen_loss = 1.0251841447892642, disc_loss = 0.036510684310685194
Trained batch 840 in epoch 1, gen_loss = 1.0250693332142553, disc_loss = 0.03646829802381729
Trained batch 841 in epoch 1, gen_loss = 1.0249193296579737, disc_loss = 0.0364271092259942
Trained batch 842 in epoch 1, gen_loss = 1.0248921262553294, disc_loss = 0.03638532874863172
Trained batch 843 in epoch 1, gen_loss = 1.0249081587339464, disc_loss = 0.03634363327033515
Trained batch 844 in epoch 1, gen_loss = 1.0248415473650192, disc_loss = 0.03630236039038392
Trained batch 845 in epoch 1, gen_loss = 1.024908247921202, disc_loss = 0.036260897456045646
Trained batch 846 in epoch 1, gen_loss = 1.0249029794155917, disc_loss = 0.036220027603864766
Trained batch 847 in epoch 1, gen_loss = 1.024856956289062, disc_loss = 0.03617929445906311
Trained batch 848 in epoch 1, gen_loss = 1.0247987876651705, disc_loss = 0.03613803487239738
Trained batch 849 in epoch 1, gen_loss = 1.0247265754026524, disc_loss = 0.03609653563038377
Trained batch 850 in epoch 1, gen_loss = 1.0246244596818639, disc_loss = 0.036057235346583796
Trained batch 851 in epoch 1, gen_loss = 1.024637855204618, disc_loss = 0.03601598744076705
Trained batch 852 in epoch 1, gen_loss = 1.024727601588541, disc_loss = 0.03597542386626427
Trained batch 853 in epoch 1, gen_loss = 1.0245948875676274, disc_loss = 0.035937703948366956
Trained batch 854 in epoch 1, gen_loss = 1.0244369043941386, disc_loss = 0.03589910923852926
Trained batch 855 in epoch 1, gen_loss = 1.0243708299838494, disc_loss = 0.035862099991688504
Trained batch 856 in epoch 1, gen_loss = 1.024360971314487, disc_loss = 0.035822575297184224
Trained batch 857 in epoch 1, gen_loss = 1.0242629620161923, disc_loss = 0.035783894114056684
Trained batch 858 in epoch 1, gen_loss = 1.0242794459995763, disc_loss = 0.035743251667388204
Trained batch 859 in epoch 1, gen_loss = 1.0242145916057188, disc_loss = 0.03570308432429366
Trained batch 860 in epoch 1, gen_loss = 1.0243568857233976, disc_loss = 0.03566302094612534
Trained batch 861 in epoch 1, gen_loss = 1.0242768441718029, disc_loss = 0.03562521624946824
Trained batch 862 in epoch 1, gen_loss = 1.0243558061772122, disc_loss = 0.035586040647295605
Trained batch 863 in epoch 1, gen_loss = 1.024344848261939, disc_loss = 0.035546878077403324
Trained batch 864 in epoch 1, gen_loss = 1.0242906986633478, disc_loss = 0.03550679804304698
Trained batch 865 in epoch 1, gen_loss = 1.0241592663402646, disc_loss = 0.03546702852044843
Trained batch 866 in epoch 1, gen_loss = 1.0240165136127186, disc_loss = 0.03542822162328208
Trained batch 867 in epoch 1, gen_loss = 1.0240336995108337, disc_loss = 0.03538954067172379
Trained batch 868 in epoch 1, gen_loss = 1.023887376310636, disc_loss = 0.035350889105547914
Trained batch 869 in epoch 1, gen_loss = 1.0237068628442698, disc_loss = 0.03531211833688685
Trained batch 870 in epoch 1, gen_loss = 1.0236967379135324, disc_loss = 0.03527252733283134
Trained batch 871 in epoch 1, gen_loss = 1.02381021960066, disc_loss = 0.03523446170288689
Trained batch 872 in epoch 1, gen_loss = 1.023900765050864, disc_loss = 0.03519544690849197
Trained batch 873 in epoch 1, gen_loss = 1.0238956136616197, disc_loss = 0.03515664527748615
Trained batch 874 in epoch 1, gen_loss = 1.023967788696289, disc_loss = 0.035117573018900915
Trained batch 875 in epoch 1, gen_loss = 1.0238644264332235, disc_loss = 0.03508038441049555
Trained batch 876 in epoch 1, gen_loss = 1.0238929220317028, disc_loss = 0.03504137130392258
Trained batch 877 in epoch 1, gen_loss = 1.0238599391624432, disc_loss = 0.03500402137665447
Trained batch 878 in epoch 1, gen_loss = 1.0237699600616819, disc_loss = 0.03496686146367514
Trained batch 879 in epoch 1, gen_loss = 1.0239599375562234, disc_loss = 0.03493110926652166
Trained batch 880 in epoch 1, gen_loss = 1.0240048634207615, disc_loss = 0.03489606185169998
Trained batch 881 in epoch 1, gen_loss = 1.0239365496197526, disc_loss = 0.03485927893389151
Trained batch 882 in epoch 1, gen_loss = 1.0239282051947216, disc_loss = 0.03482234104312543
Trained batch 883 in epoch 1, gen_loss = 1.0239113057495781, disc_loss = 0.03478558056353266
Trained batch 884 in epoch 1, gen_loss = 1.0242180313094187, disc_loss = 0.034748807612140296
Trained batch 885 in epoch 1, gen_loss = 1.0242412010245614, disc_loss = 0.03471030265717433
Trained batch 886 in epoch 1, gen_loss = 1.024137544255649, disc_loss = 0.03467395300197002
Trained batch 887 in epoch 1, gen_loss = 1.0241609441267479, disc_loss = 0.034635759342924205
Trained batch 888 in epoch 1, gen_loss = 1.023967651870307, disc_loss = 0.03459952338954528
Trained batch 889 in epoch 1, gen_loss = 1.0239855521180656, disc_loss = 0.03456627400335267
Trained batch 890 in epoch 1, gen_loss = 1.024043142461081, disc_loss = 0.03452987153470549
Trained batch 891 in epoch 1, gen_loss = 1.0240835959066725, disc_loss = 0.034493942725763324
Trained batch 892 in epoch 1, gen_loss = 1.0242560167462134, disc_loss = 0.03445778083538755
Trained batch 893 in epoch 1, gen_loss = 1.0243352711600746, disc_loss = 0.034421747113924796
Trained batch 894 in epoch 1, gen_loss = 1.024457360779107, disc_loss = 0.034385052044773816
Trained batch 895 in epoch 1, gen_loss = 1.024550971308989, disc_loss = 0.03434769032646402
Trained batch 896 in epoch 1, gen_loss = 1.0244456980140713, disc_loss = 0.03431374657568649
Trained batch 897 in epoch 1, gen_loss = 1.024324195488524, disc_loss = 0.034276917360601546
Trained batch 898 in epoch 1, gen_loss = 1.0241858470559253, disc_loss = 0.03424154034456965
Trained batch 899 in epoch 1, gen_loss = 1.0240526704655752, disc_loss = 0.03420683421613325
Trained batch 900 in epoch 1, gen_loss = 1.024036018948973, disc_loss = 0.03417202620384282
Trained batch 901 in epoch 1, gen_loss = 1.024080528190025, disc_loss = 0.03413520801413023
Trained batch 902 in epoch 1, gen_loss = 1.0240532477300692, disc_loss = 0.03409924965286006
Trained batch 903 in epoch 1, gen_loss = 1.0239741989469107, disc_loss = 0.03406305719930068
Trained batch 904 in epoch 1, gen_loss = 1.0240488937546535, disc_loss = 0.03402761579393113
Trained batch 905 in epoch 1, gen_loss = 1.0241066443735927, disc_loss = 0.03399116531143643
Trained batch 906 in epoch 1, gen_loss = 1.024055213294718, disc_loss = 0.033954989178849475
Trained batch 907 in epoch 1, gen_loss = 1.024115765869355, disc_loss = 0.0339234075646678
Trained batch 908 in epoch 1, gen_loss = 1.024212885020983, disc_loss = 0.03388723183227783
Trained batch 909 in epoch 1, gen_loss = 1.0243027055001521, disc_loss = 0.033851728829792524
Trained batch 910 in epoch 1, gen_loss = 1.024202252062432, disc_loss = 0.03381574440956242
Trained batch 911 in epoch 1, gen_loss = 1.0242610041771019, disc_loss = 0.03377961114910521
Trained batch 912 in epoch 1, gen_loss = 1.0242872379173453, disc_loss = 0.033743655940168794
Trained batch 913 in epoch 1, gen_loss = 1.02417586851433, disc_loss = 0.033707895303621796
Trained batch 914 in epoch 1, gen_loss = 1.0240862180626458, disc_loss = 0.03367206557357081
Trained batch 915 in epoch 1, gen_loss = 1.0239345759283507, disc_loss = 0.033638188355143143
Trained batch 916 in epoch 1, gen_loss = 1.0238378005043371, disc_loss = 0.03360345089974604
Trained batch 917 in epoch 1, gen_loss = 1.0238265353610054, disc_loss = 0.033567931121204445
Trained batch 918 in epoch 1, gen_loss = 1.0239374081120787, disc_loss = 0.03353230628621437
Trained batch 919 in epoch 1, gen_loss = 1.023947109994681, disc_loss = 0.03349754423105206
Trained batch 920 in epoch 1, gen_loss = 1.023984313528908, disc_loss = 0.033462085098077604
Trained batch 921 in epoch 1, gen_loss = 1.0240486295259439, disc_loss = 0.033426777475385104
Trained batch 922 in epoch 1, gen_loss = 1.0240382756856254, disc_loss = 0.03339236026774789
Trained batch 923 in epoch 1, gen_loss = 1.0238991105582291, disc_loss = 0.033357200403321706
Trained batch 924 in epoch 1, gen_loss = 1.023693198062278, disc_loss = 0.03333616160062406
Trained batch 925 in epoch 1, gen_loss = 1.0236492833488704, disc_loss = 0.033307117702723925
Trained batch 926 in epoch 1, gen_loss = 1.023341919804854, disc_loss = 0.03328402214532579
Trained batch 927 in epoch 1, gen_loss = 1.0234242770820856, disc_loss = 0.033250375095137535
Trained batch 928 in epoch 1, gen_loss = 1.0233170844381925, disc_loss = 0.0332612455259091
Trained batch 929 in epoch 1, gen_loss = 1.0230176422544706, disc_loss = 0.03337401620953241
Trained batch 930 in epoch 1, gen_loss = 1.02289476968292, disc_loss = 0.033650776607738575
Trained batch 931 in epoch 1, gen_loss = 1.0227047813808459, disc_loss = 0.03363635455179935
Trained batch 932 in epoch 1, gen_loss = 1.022473852031356, disc_loss = 0.03368785582304823
Trained batch 933 in epoch 1, gen_loss = 1.0223622346970969, disc_loss = 0.03368664226809512
Trained batch 934 in epoch 1, gen_loss = 1.0221969486557863, disc_loss = 0.033726643020194395
Trained batch 935 in epoch 1, gen_loss = 1.0221451946303375, disc_loss = 0.03369821120495
Trained batch 936 in epoch 1, gen_loss = 1.022125165770377, disc_loss = 0.0336752427071938
Trained batch 937 in epoch 1, gen_loss = 1.0219934495018999, disc_loss = 0.033644163424368455
Trained batch 938 in epoch 1, gen_loss = 1.022131230376653, disc_loss = 0.03361373019153468
Trained batch 939 in epoch 1, gen_loss = 1.0220673497686994, disc_loss = 0.03358265580044393
Trained batch 940 in epoch 1, gen_loss = 1.0220584037073361, disc_loss = 0.03356455648337418
Trained batch 941 in epoch 1, gen_loss = 1.0220321638315852, disc_loss = 0.03354554680341866
Trained batch 942 in epoch 1, gen_loss = 1.021849539917069, disc_loss = 0.03352213950219037
Trained batch 943 in epoch 1, gen_loss = 1.021845479322187, disc_loss = 0.033490932966141355
Trained batch 944 in epoch 1, gen_loss = 1.0218755406046671, disc_loss = 0.03346036430871762
Trained batch 945 in epoch 1, gen_loss = 1.0221441766802402, disc_loss = 0.033430230870040455
Trained batch 946 in epoch 1, gen_loss = 1.0222362169746109, disc_loss = 0.03339952939546654
Trained batch 947 in epoch 1, gen_loss = 1.022350775227265, disc_loss = 0.03337385714130429
Trained batch 948 in epoch 1, gen_loss = 1.022348406003323, disc_loss = 0.0333442511093881
Trained batch 949 in epoch 1, gen_loss = 1.0226956457213352, disc_loss = 0.03331303643581984
Trained batch 950 in epoch 1, gen_loss = 1.0226707160786248, disc_loss = 0.03335232978674633
Trained batch 951 in epoch 1, gen_loss = 1.023025688190921, disc_loss = 0.033666390526798005
Trained batch 952 in epoch 1, gen_loss = 1.0229495230276462, disc_loss = 0.033655385517366576
Trained batch 953 in epoch 1, gen_loss = 1.0226344721747145, disc_loss = 0.03401951349918002
Trained batch 954 in epoch 1, gen_loss = 1.0226822535404985, disc_loss = 0.03427131486724738
Trained batch 955 in epoch 1, gen_loss = 1.0226347141560153, disc_loss = 0.03438110975577546
Trained batch 956 in epoch 1, gen_loss = 1.0222709824174425, disc_loss = 0.03441337551541766
Trained batch 957 in epoch 1, gen_loss = 1.0217953231613421, disc_loss = 0.034547461988401355
Trained batch 958 in epoch 1, gen_loss = 1.021712682480857, disc_loss = 0.03456228852836933
Trained batch 959 in epoch 1, gen_loss = 1.0219663373505077, disc_loss = 0.03461870091103568
Trained batch 960 in epoch 1, gen_loss = 1.0219340219582034, disc_loss = 0.03465588109617853
Trained batch 961 in epoch 1, gen_loss = 1.0215407191096126, disc_loss = 0.03492075046301438
Trained batch 962 in epoch 1, gen_loss = 1.0216298526692613, disc_loss = 0.034955880555649084
Trained batch 963 in epoch 1, gen_loss = 1.0218300042805335, disc_loss = 0.035114417372643245
Trained batch 964 in epoch 1, gen_loss = 1.0216698677428646, disc_loss = 0.03516403090990199
Trained batch 965 in epoch 1, gen_loss = 1.0215989939914727, disc_loss = 0.035173016585171385
Trained batch 966 in epoch 1, gen_loss = 1.0213987701558032, disc_loss = 0.03526563846343113
Trained batch 967 in epoch 1, gen_loss = 1.0216239461721468, disc_loss = 0.03550735683486042
Trained batch 968 in epoch 1, gen_loss = 1.021603409350841, disc_loss = 0.03554073809045071
Trained batch 969 in epoch 1, gen_loss = 1.0212134445450969, disc_loss = 0.03573812199688994
Trained batch 970 in epoch 1, gen_loss = 1.0212491094513607, disc_loss = 0.03574695375447469
Trained batch 971 in epoch 1, gen_loss = 1.0212247388843647, disc_loss = 0.036181443568542214
Trained batch 972 in epoch 1, gen_loss = 1.0212932164720494, disc_loss = 0.0362024947655341
Trained batch 973 in epoch 1, gen_loss = 1.0210749823332324, disc_loss = 0.03633318657324842
Trained batch 974 in epoch 1, gen_loss = 1.021017160965846, disc_loss = 0.0365607057419122
Trained batch 975 in epoch 1, gen_loss = 1.0209628865733498, disc_loss = 0.036655625139768534
Trained batch 976 in epoch 1, gen_loss = 1.020581871728692, disc_loss = 0.03689443744259265
Trained batch 977 in epoch 1, gen_loss = 1.020306960083468, disc_loss = 0.036973346659247903
Trained batch 978 in epoch 1, gen_loss = 1.0202251717798312, disc_loss = 0.03711000226648937
Trained batch 979 in epoch 1, gen_loss = 1.0199956606845466, disc_loss = 0.03721880505497897
Trained batch 980 in epoch 1, gen_loss = 1.0198151682494978, disc_loss = 0.03739142958881468
Trained batch 981 in epoch 1, gen_loss = 1.0196159747248996, disc_loss = 0.03744794125839119
Trained batch 982 in epoch 1, gen_loss = 1.0196332559823262, disc_loss = 0.03748186140530281
Trained batch 983 in epoch 1, gen_loss = 1.0193035116161757, disc_loss = 0.037564730599455275
Trained batch 984 in epoch 1, gen_loss = 1.019357637766049, disc_loss = 0.037928932521602746
Trained batch 985 in epoch 1, gen_loss = 1.0189782512236318, disc_loss = 0.038126388479977104
Trained batch 986 in epoch 1, gen_loss = 1.0188597388180556, disc_loss = 0.03818756202499728
Trained batch 987 in epoch 1, gen_loss = 1.0188454936752436, disc_loss = 0.03831191562513643
Trained batch 988 in epoch 1, gen_loss = 1.0184076814125955, disc_loss = 0.0383976283603713
Trained batch 989 in epoch 1, gen_loss = 1.0180701546596758, disc_loss = 0.03850885914346718
Trained batch 990 in epoch 1, gen_loss = 1.0179889340453625, disc_loss = 0.03856347722530177
Trained batch 991 in epoch 1, gen_loss = 1.0178652753032023, disc_loss = 0.03875306375059682
Trained batch 992 in epoch 1, gen_loss = 1.0173780678022064, disc_loss = 0.03889241799822559
Trained batch 993 in epoch 1, gen_loss = 1.0171350866136417, disc_loss = 0.03907148050025967
Trained batch 994 in epoch 1, gen_loss = 1.0172240901232963, disc_loss = 0.03925333604356684
Trained batch 995 in epoch 1, gen_loss = 1.0169694351264271, disc_loss = 0.03938193547653199
Trained batch 996 in epoch 1, gen_loss = 1.0171866583728504, disc_loss = 0.039398522943221735
Trained batch 997 in epoch 1, gen_loss = 1.017195589735895, disc_loss = 0.039394480885770654
Trained batch 998 in epoch 1, gen_loss = 1.017048902996071, disc_loss = 0.039380738064476
Trained batch 999 in epoch 1, gen_loss = 1.0169589910507202, disc_loss = 0.03939178575416736
Trained batch 1000 in epoch 1, gen_loss = 1.0168747067689659, disc_loss = 0.03938434742880205
Trained batch 1001 in epoch 1, gen_loss = 1.0167110605749066, disc_loss = 0.039367606110789856
Trained batch 1002 in epoch 1, gen_loss = 1.016842759439976, disc_loss = 0.03933846803385463
Trained batch 1003 in epoch 1, gen_loss = 1.0167772294396897, disc_loss = 0.03930978780543416
Trained batch 1004 in epoch 1, gen_loss = 1.0166005730628966, disc_loss = 0.0393024373598442
Trained batch 1005 in epoch 1, gen_loss = 1.0162190325099005, disc_loss = 0.03932846280186709
Trained batch 1006 in epoch 1, gen_loss = 1.016416005427693, disc_loss = 0.039318444670009556
Trained batch 1007 in epoch 1, gen_loss = 1.0168155426425594, disc_loss = 0.03929246295481587
Trained batch 1008 in epoch 1, gen_loss = 1.0168882660988656, disc_loss = 0.03926147513462328
Trained batch 1009 in epoch 1, gen_loss = 1.0170332801814126, disc_loss = 0.03923573861811206
Trained batch 1010 in epoch 1, gen_loss = 1.0172227461307386, disc_loss = 0.039203495971678756
Trained batch 1011 in epoch 1, gen_loss = 1.017293146417546, disc_loss = 0.03917420277143486
Trained batch 1012 in epoch 1, gen_loss = 1.0174224383150836, disc_loss = 0.03914097161496254
Trained batch 1013 in epoch 1, gen_loss = 1.0174369283564226, disc_loss = 0.03910714493544313
Trained batch 1014 in epoch 1, gen_loss = 1.017545840834162, disc_loss = 0.03907225466030249
Trained batch 1015 in epoch 1, gen_loss = 1.0176640520766964, disc_loss = 0.03903738391456113
Trained batch 1016 in epoch 1, gen_loss = 1.017744584245316, disc_loss = 0.03900368695610421
Trained batch 1017 in epoch 1, gen_loss = 1.0179975753565902, disc_loss = 0.038968326432686114
Trained batch 1018 in epoch 1, gen_loss = 1.0179182121400394, disc_loss = 0.038951412231089125
Trained batch 1019 in epoch 1, gen_loss = 1.0179777823242486, disc_loss = 0.03891940259986144
Trained batch 1020 in epoch 1, gen_loss = 1.0179473439579962, disc_loss = 0.038887755644580566
Trained batch 1021 in epoch 1, gen_loss = 1.0179471268579219, disc_loss = 0.03885171371935573
Trained batch 1022 in epoch 1, gen_loss = 1.0180532701553837, disc_loss = 0.03881554435321527
Trained batch 1023 in epoch 1, gen_loss = 1.0180444162106141, disc_loss = 0.03877927881937637
Trained batch 1024 in epoch 1, gen_loss = 1.0181707020503719, disc_loss = 0.038743294846059234
Trained batch 1025 in epoch 1, gen_loss = 1.0183394201550102, disc_loss = 0.03870801916851725
Trained batch 1026 in epoch 1, gen_loss = 1.018462801745711, disc_loss = 0.0386720369909313
Trained batch 1027 in epoch 1, gen_loss = 1.0184656604254756, disc_loss = 0.03863658906897548
Trained batch 1028 in epoch 1, gen_loss = 1.018430979421002, disc_loss = 0.038600573046659564
Trained batch 1029 in epoch 1, gen_loss = 1.018465042229995, disc_loss = 0.0385647597598806
Trained batch 1030 in epoch 1, gen_loss = 1.0184155919387663, disc_loss = 0.03852936625733299
Trained batch 1031 in epoch 1, gen_loss = 1.0184340255782587, disc_loss = 0.038493647134558606
Trained batch 1032 in epoch 1, gen_loss = 1.0185135703926973, disc_loss = 0.03845884414242492
Trained batch 1033 in epoch 1, gen_loss = 1.0183355571914687, disc_loss = 0.038423499009862784
Trained batch 1034 in epoch 1, gen_loss = 1.0186195533632656, disc_loss = 0.038388120283185424
Trained batch 1035 in epoch 1, gen_loss = 1.0186166937056655, disc_loss = 0.03835360093327843
Trained batch 1036 in epoch 1, gen_loss = 1.0185417192651314, disc_loss = 0.038318488170909104
Trained batch 1037 in epoch 1, gen_loss = 1.0184430864734686, disc_loss = 0.0382842465140739
Trained batch 1038 in epoch 1, gen_loss = 1.0184041567440785, disc_loss = 0.03824862134295278
Trained batch 1039 in epoch 1, gen_loss = 1.0183488520865256, disc_loss = 0.038214022021160275
Trained batch 1040 in epoch 1, gen_loss = 1.0183581349142004, disc_loss = 0.038179558782261126
Trained batch 1041 in epoch 1, gen_loss = 1.0185191036986756, disc_loss = 0.03814468370884781
Trained batch 1042 in epoch 1, gen_loss = 1.018568259357606, disc_loss = 0.03810976730020436
Trained batch 1043 in epoch 1, gen_loss = 1.0186981801443173, disc_loss = 0.03807605188101041
Trained batch 1044 in epoch 1, gen_loss = 1.0185366705273897, disc_loss = 0.03805099619928754
Trained batch 1045 in epoch 1, gen_loss = 1.0185524208709797, disc_loss = 0.03801798138023302
Trained batch 1046 in epoch 1, gen_loss = 1.01874266944847, disc_loss = 0.037984380464212646
Trained batch 1047 in epoch 1, gen_loss = 1.0186875287926833, disc_loss = 0.037952495780117515
Trained batch 1048 in epoch 1, gen_loss = 1.0187603896066504, disc_loss = 0.03791824448314103
Trained batch 1049 in epoch 1, gen_loss = 1.018966855378378, disc_loss = 0.037884846451356896
Trained batch 1050 in epoch 1, gen_loss = 1.0188532430823931, disc_loss = 0.037850368782528676
Trained batch 1051 in epoch 1, gen_loss = 1.0188565663851712, disc_loss = 0.03781633252185181
Trained batch 1052 in epoch 1, gen_loss = 1.0189376051156496, disc_loss = 0.03778212641470357
Trained batch 1053 in epoch 1, gen_loss = 1.0189959355391407, disc_loss = 0.03774748771555845
Trained batch 1054 in epoch 1, gen_loss = 1.0190716331603968, disc_loss = 0.03771286524099274
Trained batch 1055 in epoch 1, gen_loss = 1.0191163580413118, disc_loss = 0.03767821125101171
Trained batch 1056 in epoch 1, gen_loss = 1.0191743226691925, disc_loss = 0.037643849660305755
Trained batch 1057 in epoch 1, gen_loss = 1.0192426781685906, disc_loss = 0.037610012897778725
Trained batch 1058 in epoch 1, gen_loss = 1.0191714264403209, disc_loss = 0.037576362353063504
Trained batch 1059 in epoch 1, gen_loss = 1.019281198337393, disc_loss = 0.037542093202802856
Trained batch 1060 in epoch 1, gen_loss = 1.019311448350254, disc_loss = 0.03750826855921452
Trained batch 1061 in epoch 1, gen_loss = 1.019340899087166, disc_loss = 0.03747422438044013
Trained batch 1062 in epoch 1, gen_loss = 1.0193997710690899, disc_loss = 0.03744026677705063
Trained batch 1063 in epoch 1, gen_loss = 1.0194475791396056, disc_loss = 0.03740687751820601
Trained batch 1064 in epoch 1, gen_loss = 1.019670350171031, disc_loss = 0.037372658837315005
Trained batch 1065 in epoch 1, gen_loss = 1.0199122166655972, disc_loss = 0.03733915040029183
Trained batch 1066 in epoch 1, gen_loss = 1.0198530302275646, disc_loss = 0.03730550010444152
Trained batch 1067 in epoch 1, gen_loss = 1.0198473002245363, disc_loss = 0.037271786532577886
Trained batch 1068 in epoch 1, gen_loss = 1.019896911894528, disc_loss = 0.037238842502555554
Trained batch 1069 in epoch 1, gen_loss = 1.0198992887947047, disc_loss = 0.03720495221187376
Trained batch 1070 in epoch 1, gen_loss = 1.019878243030954, disc_loss = 0.037171490129165895
Trained batch 1071 in epoch 1, gen_loss = 1.0198813351566223, disc_loss = 0.03713775148613666
Trained batch 1072 in epoch 1, gen_loss = 1.019929332757596, disc_loss = 0.037104484172125536
Trained batch 1073 in epoch 1, gen_loss = 1.0198643521112658, disc_loss = 0.037071104180342554
Trained batch 1074 in epoch 1, gen_loss = 1.0196536516034327, disc_loss = 0.03703788583777401
Trained batch 1075 in epoch 1, gen_loss = 1.019725321560101, disc_loss = 0.03700508386529123
Trained batch 1076 in epoch 1, gen_loss = 1.0197623691961737, disc_loss = 0.03697293479161321
Trained batch 1077 in epoch 1, gen_loss = 1.0198156450475966, disc_loss = 0.03693988889834361
Trained batch 1078 in epoch 1, gen_loss = 1.0199561722859727, disc_loss = 0.03690723791272404
Trained batch 1079 in epoch 1, gen_loss = 1.020029610009105, disc_loss = 0.036874371811171404
Trained batch 1080 in epoch 1, gen_loss = 1.020009707842129, disc_loss = 0.0368417739275399
Trained batch 1081 in epoch 1, gen_loss = 1.0199819085448154, disc_loss = 0.03680893895435507
Trained batch 1082 in epoch 1, gen_loss = 1.019971698550086, disc_loss = 0.03677599209890237
Trained batch 1083 in epoch 1, gen_loss = 1.019933752963024, disc_loss = 0.036743320872045675
Trained batch 1084 in epoch 1, gen_loss = 1.0199416073236598, disc_loss = 0.03671042880161144
Trained batch 1085 in epoch 1, gen_loss = 1.0199302064450406, disc_loss = 0.03667743084532829
Trained batch 1086 in epoch 1, gen_loss = 1.019953668665864, disc_loss = 0.03664728710025996
Trained batch 1087 in epoch 1, gen_loss = 1.019930860520724, disc_loss = 0.036614758853281325
Trained batch 1088 in epoch 1, gen_loss = 1.0199941098416365, disc_loss = 0.03658258021177963
Trained batch 1089 in epoch 1, gen_loss = 1.0198762842274587, disc_loss = 0.03655126358887315
Trained batch 1090 in epoch 1, gen_loss = 1.0197922001728543, disc_loss = 0.036518665640511955
Trained batch 1091 in epoch 1, gen_loss = 1.0197868406663448, disc_loss = 0.036486825243907964
Trained batch 1092 in epoch 1, gen_loss = 1.0196860762549886, disc_loss = 0.03646393426524785
Trained batch 1093 in epoch 1, gen_loss = 1.019588613695375, disc_loss = 0.0364454288539468
Trained batch 1094 in epoch 1, gen_loss = 1.0194445288344605, disc_loss = 0.03642495129273122
Trained batch 1095 in epoch 1, gen_loss = 1.0193072221901296, disc_loss = 0.03642257735689277
Trained batch 1096 in epoch 1, gen_loss = 1.0194289435988246, disc_loss = 0.03639996663047034
Trained batch 1097 in epoch 1, gen_loss = 1.0196675086607698, disc_loss = 0.03637146609129996
Trained batch 1098 in epoch 1, gen_loss = 1.0196618685080205, disc_loss = 0.03634846180987943
Trained batch 1099 in epoch 1, gen_loss = 1.0196939927339554, disc_loss = 0.036321762265962954
Trained batch 1100 in epoch 1, gen_loss = 1.019635005878601, disc_loss = 0.03629147237652672
Trained batch 1101 in epoch 1, gen_loss = 1.0195846888633908, disc_loss = 0.03626153051062517
Trained batch 1102 in epoch 1, gen_loss = 1.019544064296124, disc_loss = 0.036232171306189324
Trained batch 1103 in epoch 1, gen_loss = 1.0196177535082982, disc_loss = 0.03620799823090857
Trained batch 1104 in epoch 1, gen_loss = 1.0197358239290402, disc_loss = 0.03617886016986858
Trained batch 1105 in epoch 1, gen_loss = 1.0196871772597107, disc_loss = 0.03614729323219304
Trained batch 1106 in epoch 1, gen_loss = 1.019556141481167, disc_loss = 0.03612149531203804
Trained batch 1107 in epoch 1, gen_loss = 1.0195683705677625, disc_loss = 0.03609018463603108
Trained batch 1108 in epoch 1, gen_loss = 1.0196352185592445, disc_loss = 0.036059236900936674
Trained batch 1109 in epoch 1, gen_loss = 1.0196520648561083, disc_loss = 0.03602862334997668
Trained batch 1110 in epoch 1, gen_loss = 1.0195053670451406, disc_loss = 0.03600244476998459
Trained batch 1111 in epoch 1, gen_loss = 1.0192801955042126, disc_loss = 0.03599465194616746
Trained batch 1112 in epoch 1, gen_loss = 1.0194588111845737, disc_loss = 0.03619846673275192
Trained batch 1113 in epoch 1, gen_loss = 1.01919089362052, disc_loss = 0.036247784975122245
Trained batch 1114 in epoch 1, gen_loss = 1.018820397201675, disc_loss = 0.036414479391820076
Trained batch 1115 in epoch 1, gen_loss = 1.0189173547384132, disc_loss = 0.03650536772474097
Trained batch 1116 in epoch 1, gen_loss = 1.0188313893366843, disc_loss = 0.036569884473164754
Trained batch 1117 in epoch 1, gen_loss = 1.0188610792586543, disc_loss = 0.03657211843574341
Trained batch 1118 in epoch 1, gen_loss = 1.0188841992344997, disc_loss = 0.036565783350583116
Trained batch 1119 in epoch 1, gen_loss = 1.0188479924840586, disc_loss = 0.036551143742261566
Trained batch 1120 in epoch 1, gen_loss = 1.0189571594362488, disc_loss = 0.03653140052471318
Trained batch 1121 in epoch 1, gen_loss = 1.019013287336856, disc_loss = 0.03650795845101899
Trained batch 1122 in epoch 1, gen_loss = 1.019256864927331, disc_loss = 0.03648408704298353
Trained batch 1123 in epoch 1, gen_loss = 1.0194781221104687, disc_loss = 0.036456286519201075
Trained batch 1124 in epoch 1, gen_loss = 1.0193682934443156, disc_loss = 0.036434898730561445
Trained batch 1125 in epoch 1, gen_loss = 1.0193424183034983, disc_loss = 0.03642584562451704
Trained batch 1126 in epoch 1, gen_loss = 1.0193523786823202, disc_loss = 0.03646459298545051
Trained batch 1127 in epoch 1, gen_loss = 1.01902182632727, disc_loss = 0.0367075758191367
Trained batch 1128 in epoch 1, gen_loss = 1.0193431455546296, disc_loss = 0.03713887186486229
Trained batch 1129 in epoch 1, gen_loss = 1.0195312074855365, disc_loss = 0.03713633212016481
Trained batch 1130 in epoch 1, gen_loss = 1.0195131602801653, disc_loss = 0.03712733822937667
Trained batch 1131 in epoch 1, gen_loss = 1.0193300243506582, disc_loss = 0.03711884219486909
Trained batch 1132 in epoch 1, gen_loss = 1.0192236930316039, disc_loss = 0.03710733973691131
Trained batch 1133 in epoch 1, gen_loss = 1.0190589941473025, disc_loss = 0.03710759695715793
Trained batch 1134 in epoch 1, gen_loss = 1.0188172350370936, disc_loss = 0.037139848050020845
Trained batch 1135 in epoch 1, gen_loss = 1.0187878667993444, disc_loss = 0.03714098008885243
Trained batch 1136 in epoch 1, gen_loss = 1.0185619363055065, disc_loss = 0.03716946075580678
Trained batch 1137 in epoch 1, gen_loss = 1.0185035295352365, disc_loss = 0.03721277916746209
Trained batch 1138 in epoch 1, gen_loss = 1.0183258811249034, disc_loss = 0.037305967218112884
Trained batch 1139 in epoch 1, gen_loss = 1.0184827864170074, disc_loss = 0.03731265939064191
Trained batch 1140 in epoch 1, gen_loss = 1.018194338713269, disc_loss = 0.03735328751523487
Trained batch 1141 in epoch 1, gen_loss = 1.0182312397113407, disc_loss = 0.0373378150691371
Trained batch 1142 in epoch 1, gen_loss = 1.0183048866760909, disc_loss = 0.037333558090890256
Trained batch 1143 in epoch 1, gen_loss = 1.0183046294467433, disc_loss = 0.03732710262458848
Trained batch 1144 in epoch 1, gen_loss = 1.0181562474721384, disc_loss = 0.03734910455409094
Trained batch 1145 in epoch 1, gen_loss = 1.0183979117849526, disc_loss = 0.03737184277715689
Trained batch 1146 in epoch 1, gen_loss = 1.018536613106, disc_loss = 0.037432883949547906
Trained batch 1147 in epoch 1, gen_loss = 1.0180621089004889, disc_loss = 0.03770813531340828
Trained batch 1148 in epoch 1, gen_loss = 1.01815564680141, disc_loss = 0.037850041261572105
Trained batch 1149 in epoch 1, gen_loss = 1.0181253365848375, disc_loss = 0.037939169094075305
Trained batch 1150 in epoch 1, gen_loss = 1.0178419497611728, disc_loss = 0.03798510211067131
Trained batch 1151 in epoch 1, gen_loss = 1.0179272304392524, disc_loss = 0.03797021510620703
Trained batch 1152 in epoch 1, gen_loss = 1.0176501671645504, disc_loss = 0.037997166848068926
Trained batch 1153 in epoch 1, gen_loss = 1.0176065133390642, disc_loss = 0.03808858866525273
Trained batch 1154 in epoch 1, gen_loss = 1.0174589813013613, disc_loss = 0.03825093176017074
Trained batch 1155 in epoch 1, gen_loss = 1.0174454583119357, disc_loss = 0.038374182363519596
Trained batch 1156 in epoch 1, gen_loss = 1.0173971267125683, disc_loss = 0.038381747258878905
Trained batch 1157 in epoch 1, gen_loss = 1.0170581170931998, disc_loss = 0.038464382208592926
Trained batch 1158 in epoch 1, gen_loss = 1.0170185866285955, disc_loss = 0.038503373237603465
Trained batch 1159 in epoch 1, gen_loss = 1.0167241902186952, disc_loss = 0.038564681487972347
Trained batch 1160 in epoch 1, gen_loss = 1.0165385567967384, disc_loss = 0.03863142362897195
Trained batch 1161 in epoch 1, gen_loss = 1.0165097057409007, disc_loss = 0.03871323721119026
Trained batch 1162 in epoch 1, gen_loss = 1.0161266130101343, disc_loss = 0.03879937801331869
Trained batch 1163 in epoch 1, gen_loss = 1.016069329378941, disc_loss = 0.03880481943434864
Trained batch 1164 in epoch 1, gen_loss = 1.0160043960988778, disc_loss = 0.03884268643337256
Trained batch 1165 in epoch 1, gen_loss = 1.0158278003565033, disc_loss = 0.03885021249344682
Trained batch 1166 in epoch 1, gen_loss = 1.0156072794931408, disc_loss = 0.038858590596291154
Trained batch 1167 in epoch 1, gen_loss = 1.01559575769591, disc_loss = 0.03893560103649042
Trained batch 1168 in epoch 1, gen_loss = 1.0155313855261758, disc_loss = 0.03892991659461277
Trained batch 1169 in epoch 1, gen_loss = 1.0154756598492973, disc_loss = 0.03891434032034923
Trained batch 1170 in epoch 1, gen_loss = 1.015326975096402, disc_loss = 0.038893645974245446
Trained batch 1171 in epoch 1, gen_loss = 1.015316664918291, disc_loss = 0.03889350488175963
Trained batch 1172 in epoch 1, gen_loss = 1.0155121373093647, disc_loss = 0.038868873646686376
Trained batch 1173 in epoch 1, gen_loss = 1.0159109840502731, disc_loss = 0.03885121578393055
Trained batch 1174 in epoch 1, gen_loss = 1.016133341839973, disc_loss = 0.03883006859391165
Trained batch 1175 in epoch 1, gen_loss = 1.0163151437834816, disc_loss = 0.038801953739190743
Trained batch 1176 in epoch 1, gen_loss = 1.0163708688752977, disc_loss = 0.03877297482854015
Trained batch 1177 in epoch 1, gen_loss = 1.016608802946395, disc_loss = 0.038746282156087525
Trained batch 1178 in epoch 1, gen_loss = 1.0167017272713834, disc_loss = 0.03871716955929007
Trained batch 1179 in epoch 1, gen_loss = 1.0168219721418317, disc_loss = 0.03868791936220694
Trained batch 1180 in epoch 1, gen_loss = 1.0168392837400864, disc_loss = 0.038657617030312286
Trained batch 1181 in epoch 1, gen_loss = 1.016759788273958, disc_loss = 0.03863675953632379
Trained batch 1182 in epoch 1, gen_loss = 1.0166879794603672, disc_loss = 0.03860764843071994
Trained batch 1183 in epoch 1, gen_loss = 1.0165693861105152, disc_loss = 0.038579204763356904
Trained batch 1184 in epoch 1, gen_loss = 1.0166251795704355, disc_loss = 0.03854976560121534
Trained batch 1185 in epoch 1, gen_loss = 1.0166440528219105, disc_loss = 0.03851971466742441
Trained batch 1186 in epoch 1, gen_loss = 1.0167225848855144, disc_loss = 0.03848923352273507
Trained batch 1187 in epoch 1, gen_loss = 1.016840531920343, disc_loss = 0.038458144317407246
Trained batch 1188 in epoch 1, gen_loss = 1.016875684261322, disc_loss = 0.038427081930926844
Trained batch 1189 in epoch 1, gen_loss = 1.016814363754096, disc_loss = 0.03839646103231094
Trained batch 1190 in epoch 1, gen_loss = 1.0167627788010412, disc_loss = 0.038366154154694104
Trained batch 1191 in epoch 1, gen_loss = 1.0167302230260515, disc_loss = 0.038336284210168166
Trained batch 1192 in epoch 1, gen_loss = 1.0167202199094953, disc_loss = 0.03830614568424742
Trained batch 1193 in epoch 1, gen_loss = 1.0167216779398958, disc_loss = 0.03827639595000493
Trained batch 1194 in epoch 1, gen_loss = 1.016732795966719, disc_loss = 0.03824598906223446
Trained batch 1195 in epoch 1, gen_loss = 1.0168038065417555, disc_loss = 0.03821599275878205
Trained batch 1196 in epoch 1, gen_loss = 1.0168775246356463, disc_loss = 0.03818638180313255
Trained batch 1197 in epoch 1, gen_loss = 1.0168163965460852, disc_loss = 0.03815574993178797
Trained batch 1198 in epoch 1, gen_loss = 1.0168136385105568, disc_loss = 0.03812645328704924
Trained batch 1199 in epoch 1, gen_loss = 1.0167203736305237, disc_loss = 0.038098149292721546
Trained batch 1200 in epoch 1, gen_loss = 1.0165980553547607, disc_loss = 0.03806886420346326
Trained batch 1201 in epoch 1, gen_loss = 1.0165954293208987, disc_loss = 0.03804013735511619
Trained batch 1202 in epoch 1, gen_loss = 1.016608518902104, disc_loss = 0.038010561813089705
Trained batch 1203 in epoch 1, gen_loss = 1.016579028528394, disc_loss = 0.03798058931337485
Trained batch 1204 in epoch 1, gen_loss = 1.0166277042068386, disc_loss = 0.03795054342598447
Trained batch 1205 in epoch 1, gen_loss = 1.0166348037533894, disc_loss = 0.03792044973904358
Trained batch 1206 in epoch 1, gen_loss = 1.0166792508581994, disc_loss = 0.037890460249853965
Trained batch 1207 in epoch 1, gen_loss = 1.0165847202405234, disc_loss = 0.03786065195904093
Trained batch 1208 in epoch 1, gen_loss = 1.016549510784244, disc_loss = 0.037830890326558404
Trained batch 1209 in epoch 1, gen_loss = 1.0164685546366636, disc_loss = 0.03780068887275218
Trained batch 1210 in epoch 1, gen_loss = 1.0164742886675575, disc_loss = 0.03777068912719107
Trained batch 1211 in epoch 1, gen_loss = 1.0163406209878796, disc_loss = 0.03774115001762748
Trained batch 1212 in epoch 1, gen_loss = 1.0163966093491839, disc_loss = 0.03771144959002206
Trained batch 1213 in epoch 1, gen_loss = 1.0164043585688514, disc_loss = 0.03768176147525106
Trained batch 1214 in epoch 1, gen_loss = 1.0162549490791288, disc_loss = 0.03765254634174513
Trained batch 1215 in epoch 1, gen_loss = 1.0162079358767522, disc_loss = 0.03762380060727896
Trained batch 1216 in epoch 1, gen_loss = 1.0160728693008423, disc_loss = 0.03759409639695818
Trained batch 1217 in epoch 1, gen_loss = 1.016047883014178, disc_loss = 0.037565423829919425
Trained batch 1218 in epoch 1, gen_loss = 1.015967104648155, disc_loss = 0.037535957276287384
Trained batch 1219 in epoch 1, gen_loss = 1.0160372769246335, disc_loss = 0.037506440428901965
Trained batch 1220 in epoch 1, gen_loss = 1.0159438481397263, disc_loss = 0.037476723069003494
Trained batch 1221 in epoch 1, gen_loss = 1.01585004987186, disc_loss = 0.03744734374979622
Trained batch 1222 in epoch 1, gen_loss = 1.0158196929918384, disc_loss = 0.03741782095920984
Trained batch 1223 in epoch 1, gen_loss = 1.0158172472337492, disc_loss = 0.037388357332875946
Trained batch 1224 in epoch 1, gen_loss = 1.0158822467862343, disc_loss = 0.03735943642139616
Trained batch 1225 in epoch 1, gen_loss = 1.0158034220313559, disc_loss = 0.03733002633230446
Trained batch 1226 in epoch 1, gen_loss = 1.0158266632073083, disc_loss = 0.03730076382344597
Trained batch 1227 in epoch 1, gen_loss = 1.015885950930732, disc_loss = 0.0372715069065116
Trained batch 1228 in epoch 1, gen_loss = 1.0159103389771804, disc_loss = 0.03724295431402055
Trained batch 1229 in epoch 1, gen_loss = 1.0159168401869332, disc_loss = 0.03721623238670872
Trained batch 1230 in epoch 1, gen_loss = 1.0158124850301797, disc_loss = 0.03718719378921703
Trained batch 1231 in epoch 1, gen_loss = 1.0158504535044943, disc_loss = 0.037158616185278534
Trained batch 1232 in epoch 1, gen_loss = 1.015808553349556, disc_loss = 0.037129995537647884
Trained batch 1233 in epoch 1, gen_loss = 1.0158148796767044, disc_loss = 0.03710132498020105
Trained batch 1234 in epoch 1, gen_loss = 1.01577798967902, disc_loss = 0.03707245566526585
Trained batch 1235 in epoch 1, gen_loss = 1.0157657641326725, disc_loss = 0.03704341490070656
Trained batch 1236 in epoch 1, gen_loss = 1.0156479459572147, disc_loss = 0.037014926565579434
Trained batch 1237 in epoch 1, gen_loss = 1.0155545601166893, disc_loss = 0.03698603360670284
Trained batch 1238 in epoch 1, gen_loss = 1.0155352051937359, disc_loss = 0.03695712301257313
Trained batch 1239 in epoch 1, gen_loss = 1.0154082678979444, disc_loss = 0.03692887900978085
Trained batch 1240 in epoch 1, gen_loss = 1.0153807857457329, disc_loss = 0.036900115017013235
Trained batch 1241 in epoch 1, gen_loss = 1.015385050656523, disc_loss = 0.036871540986927846
Trained batch 1242 in epoch 1, gen_loss = 1.0153874009727761, disc_loss = 0.03684276178135615
Trained batch 1243 in epoch 1, gen_loss = 1.0152717398964708, disc_loss = 0.03681408393122973
Trained batch 1244 in epoch 1, gen_loss = 1.0152222436115923, disc_loss = 0.03678524458338366
Trained batch 1245 in epoch 1, gen_loss = 1.0152960929595065, disc_loss = 0.036756712417846546
Trained batch 1246 in epoch 1, gen_loss = 1.0151557555271322, disc_loss = 0.03672801148625635
Trained batch 1247 in epoch 1, gen_loss = 1.0152120679999008, disc_loss = 0.03669937209329314
Trained batch 1248 in epoch 1, gen_loss = 1.015237473219848, disc_loss = 0.036671093558096904
Trained batch 1249 in epoch 1, gen_loss = 1.0152102950572968, disc_loss = 0.03664255744836992
Trained batch 1250 in epoch 1, gen_loss = 1.0151747741001687, disc_loss = 0.03661478841479793
Trained batch 1251 in epoch 1, gen_loss = 1.0151904743795577, disc_loss = 0.03658624873572606
Trained batch 1252 in epoch 1, gen_loss = 1.0150778723162646, disc_loss = 0.03655775834910833
Trained batch 1253 in epoch 1, gen_loss = 1.015128423865332, disc_loss = 0.036529532871600386
Trained batch 1254 in epoch 1, gen_loss = 1.015000159664458, disc_loss = 0.036501153153068185
Trained batch 1255 in epoch 1, gen_loss = 1.0149778366373603, disc_loss = 0.03647286774390916
Trained batch 1256 in epoch 1, gen_loss = 1.0149208168330985, disc_loss = 0.0364444664083939
Trained batch 1257 in epoch 1, gen_loss = 1.0150186496717184, disc_loss = 0.036416409145231414
Trained batch 1258 in epoch 1, gen_loss = 1.0151289522979257, disc_loss = 0.03638844514378974
Trained batch 1259 in epoch 1, gen_loss = 1.0150680233088751, disc_loss = 0.03636031762496079
Trained batch 1260 in epoch 1, gen_loss = 1.0150323055454136, disc_loss = 0.036332344989709886
Trained batch 1261 in epoch 1, gen_loss = 1.0150657632932798, disc_loss = 0.03630408279751765
Trained batch 1262 in epoch 1, gen_loss = 1.015006325448777, disc_loss = 0.036276251389417834
Trained batch 1263 in epoch 1, gen_loss = 1.0150416715518584, disc_loss = 0.03624832551166129
Trained batch 1264 in epoch 1, gen_loss = 1.0148552411629748, disc_loss = 0.036224830533382886
Trained batch 1265 in epoch 1, gen_loss = 1.0148125301699313, disc_loss = 0.03619792206960428
Trained batch 1266 in epoch 1, gen_loss = 1.014806128761951, disc_loss = 0.0361706116130507
Trained batch 1267 in epoch 1, gen_loss = 1.014832680768771, disc_loss = 0.036144308256914406
Trained batch 1268 in epoch 1, gen_loss = 1.0148338109982868, disc_loss = 0.03611714157431214
Trained batch 1269 in epoch 1, gen_loss = 1.014854078076956, disc_loss = 0.03608956696720213
Trained batch 1270 in epoch 1, gen_loss = 1.0148299871984192, disc_loss = 0.036061796964269206
Trained batch 1271 in epoch 1, gen_loss = 1.014698787211622, disc_loss = 0.03603422258923234
Trained batch 1272 in epoch 1, gen_loss = 1.0148142968587583, disc_loss = 0.03600802626928784
Trained batch 1273 in epoch 1, gen_loss = 1.0148133466157658, disc_loss = 0.03598070426557271
Trained batch 1274 in epoch 1, gen_loss = 1.0148207657009947, disc_loss = 0.03595307636183148
Trained batch 1275 in epoch 1, gen_loss = 1.014803164898415, disc_loss = 0.03592565072088699
Trained batch 1276 in epoch 1, gen_loss = 1.014858085192454, disc_loss = 0.03589818188301391
Trained batch 1277 in epoch 1, gen_loss = 1.0149017535091753, disc_loss = 0.035870669722703814
Trained batch 1278 in epoch 1, gen_loss = 1.0148670638884485, disc_loss = 0.035843278037535155
Trained batch 1279 in epoch 1, gen_loss = 1.014820969104767, disc_loss = 0.035815998167561244
Trained batch 1280 in epoch 1, gen_loss = 1.0148296766593807, disc_loss = 0.035788831019526075
Trained batch 1281 in epoch 1, gen_loss = 1.0148525375657818, disc_loss = 0.035761472164518755
Trained batch 1282 in epoch 1, gen_loss = 1.0149045888093515, disc_loss = 0.0357341438539747
Trained batch 1283 in epoch 1, gen_loss = 1.0148892322804697, disc_loss = 0.03570695704727887
Trained batch 1284 in epoch 1, gen_loss = 1.0148519941804939, disc_loss = 0.03567977236185888
Trained batch 1285 in epoch 1, gen_loss = 1.014720398243256, disc_loss = 0.03565286077242111
Trained batch 1286 in epoch 1, gen_loss = 1.0147548969994244, disc_loss = 0.035625998962300336
Trained batch 1287 in epoch 1, gen_loss = 1.014863530347436, disc_loss = 0.03559880388126901
Trained batch 1288 in epoch 1, gen_loss = 1.01482185006974, disc_loss = 0.03557156961920566
Trained batch 1289 in epoch 1, gen_loss = 1.0148006896177928, disc_loss = 0.03554455723329005
Trained batch 1290 in epoch 1, gen_loss = 1.0148722811967803, disc_loss = 0.035517551856122945
Trained batch 1291 in epoch 1, gen_loss = 1.0148362862436395, disc_loss = 0.03549058447858806
Trained batch 1292 in epoch 1, gen_loss = 1.0149196434279144, disc_loss = 0.03546367137422898
Trained batch 1293 in epoch 1, gen_loss = 1.0149303957520535, disc_loss = 0.03543680542064937
Trained batch 1294 in epoch 1, gen_loss = 1.0149748637409284, disc_loss = 0.03540983302872691
Trained batch 1295 in epoch 1, gen_loss = 1.0148902689049273, disc_loss = 0.035383868253917664
Trained batch 1296 in epoch 1, gen_loss = 1.0148375583963387, disc_loss = 0.03535695201351331
Trained batch 1297 in epoch 1, gen_loss = 1.014834386266435, disc_loss = 0.035330783195551205
Trained batch 1298 in epoch 1, gen_loss = 1.0148405554296422, disc_loss = 0.03530492048875349
Trained batch 1299 in epoch 1, gen_loss = 1.0149061377231892, disc_loss = 0.03527836831032451
Trained batch 1300 in epoch 1, gen_loss = 1.0148748635421068, disc_loss = 0.0352518049344553
Trained batch 1301 in epoch 1, gen_loss = 1.0148644811272072, disc_loss = 0.03522582489138295
Trained batch 1302 in epoch 1, gen_loss = 1.0148335417142211, disc_loss = 0.03519931758980398
Trained batch 1303 in epoch 1, gen_loss = 1.0148201929919558, disc_loss = 0.035173109335615675
Trained batch 1304 in epoch 1, gen_loss = 1.014819397277759, disc_loss = 0.0351467505962364
Trained batch 1305 in epoch 1, gen_loss = 1.0147869193535668, disc_loss = 0.03512058872458781
Trained batch 1306 in epoch 1, gen_loss = 1.014774910256255, disc_loss = 0.0350942714787474
Trained batch 1307 in epoch 1, gen_loss = 1.014768551249023, disc_loss = 0.035067800236649155
Trained batch 1308 in epoch 1, gen_loss = 1.0147904833370351, disc_loss = 0.035041330608888706
Trained batch 1309 in epoch 1, gen_loss = 1.0147336416572106, disc_loss = 0.035014896371607575
Trained batch 1310 in epoch 1, gen_loss = 1.0146997133617999, disc_loss = 0.03498863556602688
Trained batch 1311 in epoch 1, gen_loss = 1.0147016809390086, disc_loss = 0.03496233916599167
Trained batch 1312 in epoch 1, gen_loss = 1.0146894332841436, disc_loss = 0.03493624270414806
Trained batch 1313 in epoch 1, gen_loss = 1.0146403329466758, disc_loss = 0.03491048191802651
Trained batch 1314 in epoch 1, gen_loss = 1.0147116550927833, disc_loss = 0.0348846304714091
Trained batch 1315 in epoch 1, gen_loss = 1.014712681569227, disc_loss = 0.03485894633527967
Trained batch 1316 in epoch 1, gen_loss = 1.0145415836604328, disc_loss = 0.03483333242747531
Trained batch 1317 in epoch 1, gen_loss = 1.0145974622782157, disc_loss = 0.034807372601486496
Trained batch 1318 in epoch 1, gen_loss = 1.014635400712445, disc_loss = 0.03478164774097368
Trained batch 1319 in epoch 1, gen_loss = 1.014585195210847, disc_loss = 0.03475589310955635
Trained batch 1320 in epoch 1, gen_loss = 1.0146090222253301, disc_loss = 0.03473010976825226
Trained batch 1321 in epoch 1, gen_loss = 1.0146392403049296, disc_loss = 0.034704298155939076
Trained batch 1322 in epoch 1, gen_loss = 1.0145970618553624, disc_loss = 0.0346784173975772
Trained batch 1323 in epoch 1, gen_loss = 1.014520609982064, disc_loss = 0.03465283216278885
Trained batch 1324 in epoch 1, gen_loss = 1.0145216706563842, disc_loss = 0.03462737485991554
Trained batch 1325 in epoch 1, gen_loss = 1.0145310066853892, disc_loss = 0.03460165501017024
Trained batch 1326 in epoch 1, gen_loss = 1.0145457939447635, disc_loss = 0.034576280625976466
Trained batch 1327 in epoch 1, gen_loss = 1.014508932424956, disc_loss = 0.03455064677198234
Trained batch 1328 in epoch 1, gen_loss = 1.014434762383153, disc_loss = 0.03452509275106603
Trained batch 1329 in epoch 1, gen_loss = 1.0143711176581849, disc_loss = 0.03449948264161848
Trained batch 1330 in epoch 1, gen_loss = 1.0143481184449257, disc_loss = 0.034473986236732694
Trained batch 1331 in epoch 1, gen_loss = 1.0142938448591634, disc_loss = 0.034448492340186376
Trained batch 1332 in epoch 1, gen_loss = 1.0142349518516953, disc_loss = 0.034423072214431964
Trained batch 1333 in epoch 1, gen_loss = 1.0141525081340699, disc_loss = 0.034397736531276084
Trained batch 1334 in epoch 1, gen_loss = 1.0141487552432085, disc_loss = 0.034372605810612036
Trained batch 1335 in epoch 1, gen_loss = 1.0138750201660003, disc_loss = 0.034436894611666456
Trained batch 1336 in epoch 1, gen_loss = 1.0139944692913418, disc_loss = 0.034426589632538224
Trained batch 1337 in epoch 1, gen_loss = 1.0140334389580383, disc_loss = 0.03442560393329174
Trained batch 1338 in epoch 1, gen_loss = 1.0140698131916681, disc_loss = 0.03440460438232237
Trained batch 1339 in epoch 1, gen_loss = 1.014097301862133, disc_loss = 0.03438048725557877
Trained batch 1340 in epoch 1, gen_loss = 1.0140162745044803, disc_loss = 0.03435846971163929
Trained batch 1341 in epoch 1, gen_loss = 1.0140032072269791, disc_loss = 0.03433402696177518
Trained batch 1342 in epoch 1, gen_loss = 1.0140923108525535, disc_loss = 0.03430971203136148
Trained batch 1343 in epoch 1, gen_loss = 1.0141289459009255, disc_loss = 0.03428499521648865
Trained batch 1344 in epoch 1, gen_loss = 1.0140789204370577, disc_loss = 0.034260457183148275
Trained batch 1345 in epoch 1, gen_loss = 1.014116269208347, disc_loss = 0.03423589892383088
Trained batch 1346 in epoch 1, gen_loss = 1.01417606785816, disc_loss = 0.03421179353357035
Trained batch 1347 in epoch 1, gen_loss = 1.0142082580384586, disc_loss = 0.034187322461059835
Trained batch 1348 in epoch 1, gen_loss = 1.0143123432563093, disc_loss = 0.03416278943167856
Trained batch 1349 in epoch 1, gen_loss = 1.0143875358281311, disc_loss = 0.034139278131478934
Trained batch 1350 in epoch 1, gen_loss = 1.014358488609842, disc_loss = 0.034114637602749076
Trained batch 1351 in epoch 1, gen_loss = 1.0142955306101833, disc_loss = 0.034103876358313925
Trained batch 1352 in epoch 1, gen_loss = 1.01425221084403, disc_loss = 0.034081390990383244
Trained batch 1353 in epoch 1, gen_loss = 1.0142321148158175, disc_loss = 0.03406002605025475
Trained batch 1354 in epoch 1, gen_loss = 1.01423345060806, disc_loss = 0.03403711851714806
Trained batch 1355 in epoch 1, gen_loss = 1.0142380048391741, disc_loss = 0.03401291310631337
Trained batch 1356 in epoch 1, gen_loss = 1.0142625641453855, disc_loss = 0.033989389958135066
Trained batch 1357 in epoch 1, gen_loss = 1.0143667368193614, disc_loss = 0.03396508533581352
Trained batch 1358 in epoch 1, gen_loss = 1.0144095455924758, disc_loss = 0.03394106170420617
Trained batch 1359 in epoch 1, gen_loss = 1.0145211631760878, disc_loss = 0.03391694994036644
Trained batch 1360 in epoch 1, gen_loss = 1.0145523767099933, disc_loss = 0.033893034366534014
Trained batch 1361 in epoch 1, gen_loss = 1.0145601907665684, disc_loss = 0.03386870485464175
Trained batch 1362 in epoch 1, gen_loss = 1.0145982072708455, disc_loss = 0.033844778531273094
Trained batch 1363 in epoch 1, gen_loss = 1.0146383558375396, disc_loss = 0.033820578238450666
Trained batch 1364 in epoch 1, gen_loss = 1.0145385478005742, disc_loss = 0.033801082888673124
Trained batch 1365 in epoch 1, gen_loss = 1.014596598083767, disc_loss = 0.033777178800453916
Trained batch 1366 in epoch 1, gen_loss = 1.0145645570214334, disc_loss = 0.0337531830207432
Trained batch 1367 in epoch 1, gen_loss = 1.0146089519063632, disc_loss = 0.033728978994773645
Trained batch 1368 in epoch 1, gen_loss = 1.0146339654138787, disc_loss = 0.033705053865772924
Trained batch 1369 in epoch 1, gen_loss = 1.0147512892301935, disc_loss = 0.03368125374928792
Trained batch 1370 in epoch 1, gen_loss = 1.0147425814060989, disc_loss = 0.03365726457885356
Trained batch 1371 in epoch 1, gen_loss = 1.0147363844574715, disc_loss = 0.03363311117671815
Trained batch 1372 in epoch 1, gen_loss = 1.0147761455957507, disc_loss = 0.033609022930177056
Trained batch 1373 in epoch 1, gen_loss = 1.0147620188357007, disc_loss = 0.033584985996648116
Trained batch 1374 in epoch 1, gen_loss = 1.0147509950724516, disc_loss = 0.03356106568679256
Trained batch 1375 in epoch 1, gen_loss = 1.0147082496780988, disc_loss = 0.0335372171816955
Trained batch 1376 in epoch 1, gen_loss = 1.0147174621459445, disc_loss = 0.03351344795041904
Trained batch 1377 in epoch 1, gen_loss = 1.0147587648756444, disc_loss = 0.03348954755538361
Trained batch 1378 in epoch 1, gen_loss = 1.0146938886134151, disc_loss = 0.033465926214304054
Trained batch 1379 in epoch 1, gen_loss = 1.0147688092096991, disc_loss = 0.03344235955455983
Trained batch 1380 in epoch 1, gen_loss = 1.0148943909089865, disc_loss = 0.033418679265337856
Trained batch 1381 in epoch 1, gen_loss = 1.014892543319683, disc_loss = 0.03339510932800809
Trained batch 1382 in epoch 1, gen_loss = 1.0149013506961058, disc_loss = 0.03337158009693619
Trained batch 1383 in epoch 1, gen_loss = 1.01487896126302, disc_loss = 0.03334820399710761
Trained batch 1384 in epoch 1, gen_loss = 1.0149379138481747, disc_loss = 0.03332601988303353
Trained batch 1385 in epoch 1, gen_loss = 1.0149386323461629, disc_loss = 0.03330238358879505
Trained batch 1386 in epoch 1, gen_loss = 1.014980563390315, disc_loss = 0.03327914877242948
Trained batch 1387 in epoch 1, gen_loss = 1.0149721285537616, disc_loss = 0.03325553610087421
Trained batch 1388 in epoch 1, gen_loss = 1.0148888662875857, disc_loss = 0.033231990766665685
Trained batch 1389 in epoch 1, gen_loss = 1.0148333272059187, disc_loss = 0.03320842229581326
Trained batch 1390 in epoch 1, gen_loss = 1.0148333629458006, disc_loss = 0.03318505263640664
Trained batch 1391 in epoch 1, gen_loss = 1.0147749803018296, disc_loss = 0.033161601401780934
Trained batch 1392 in epoch 1, gen_loss = 1.014728381919587, disc_loss = 0.033138549017174786
Trained batch 1393 in epoch 1, gen_loss = 1.0146720252899049, disc_loss = 0.03311530089757141
Trained batch 1394 in epoch 1, gen_loss = 1.0146716368241122, disc_loss = 0.03309189602698234
Trained batch 1395 in epoch 1, gen_loss = 1.0146591478056757, disc_loss = 0.03306862311444189
Trained batch 1396 in epoch 1, gen_loss = 1.0146668242315948, disc_loss = 0.03304557762094868
Trained batch 1397 in epoch 1, gen_loss = 1.0146016114430025, disc_loss = 0.03302280909412576
Trained batch 1398 in epoch 1, gen_loss = 1.0145674752200646, disc_loss = 0.0329997460780048
Trained batch 1399 in epoch 1, gen_loss = 1.014611050571714, disc_loss = 0.032976811872452216
Trained batch 1400 in epoch 1, gen_loss = 1.0146467780998825, disc_loss = 0.032953904137728876
Trained batch 1401 in epoch 1, gen_loss = 1.014658699192096, disc_loss = 0.03293092739324711
Trained batch 1402 in epoch 1, gen_loss = 1.0147078106935248, disc_loss = 0.03290785337811864
Trained batch 1403 in epoch 1, gen_loss = 1.0146131895461314, disc_loss = 0.032884827070350696
Trained batch 1404 in epoch 1, gen_loss = 1.0146548708562748, disc_loss = 0.03286183683289293
Trained batch 1405 in epoch 1, gen_loss = 1.0145999143591646, disc_loss = 0.032838921503086954
Trained batch 1406 in epoch 1, gen_loss = 1.0145837145234646, disc_loss = 0.03281623282484165
Trained batch 1407 in epoch 1, gen_loss = 1.0146070400845597, disc_loss = 0.03279342510444911
Trained batch 1408 in epoch 1, gen_loss = 1.0145638396420151, disc_loss = 0.03277047315273558
Trained batch 1409 in epoch 1, gen_loss = 1.0145087255231031, disc_loss = 0.03274798586760055
Trained batch 1410 in epoch 1, gen_loss = 1.0145279170349926, disc_loss = 0.03272515658400288
Trained batch 1411 in epoch 1, gen_loss = 1.0145268194145252, disc_loss = 0.03270238203408334
Trained batch 1412 in epoch 1, gen_loss = 1.0144433920381766, disc_loss = 0.03267952564155928
Trained batch 1413 in epoch 1, gen_loss = 1.0143216421782886, disc_loss = 0.03265739268139148
Trained batch 1414 in epoch 1, gen_loss = 1.014288110952074, disc_loss = 0.032634681102426066
Trained batch 1415 in epoch 1, gen_loss = 1.0142805604106289, disc_loss = 0.032612058051430935
Trained batch 1416 in epoch 1, gen_loss = 1.0142176274523065, disc_loss = 0.032589515390971116
Trained batch 1417 in epoch 1, gen_loss = 1.0142828365223027, disc_loss = 0.03256695863990268
Trained batch 1418 in epoch 1, gen_loss = 1.0143275334433488, disc_loss = 0.03254454068157917
Trained batch 1419 in epoch 1, gen_loss = 1.0142710914074535, disc_loss = 0.032521915830486095
Trained batch 1420 in epoch 1, gen_loss = 1.0142139779439197, disc_loss = 0.03249991082490783
Trained batch 1421 in epoch 1, gen_loss = 1.0142668366599854, disc_loss = 0.03247747224193443
Trained batch 1422 in epoch 1, gen_loss = 1.0142371490733857, disc_loss = 0.032455148386131456
Trained batch 1423 in epoch 1, gen_loss = 1.0141613088715613, disc_loss = 0.03243291892266917
Trained batch 1424 in epoch 1, gen_loss = 1.014181951430806, disc_loss = 0.03241056342934985
Trained batch 1425 in epoch 1, gen_loss = 1.014060372181059, disc_loss = 0.03238832936602405
Trained batch 1426 in epoch 1, gen_loss = 1.0139467996070664, disc_loss = 0.03236648042169839
Trained batch 1427 in epoch 1, gen_loss = 1.0139971307846678, disc_loss = 0.03234415113271424
Trained batch 1428 in epoch 1, gen_loss = 1.0139622082653539, disc_loss = 0.032321901827798635
Trained batch 1429 in epoch 1, gen_loss = 1.0139183807623136, disc_loss = 0.032300352607273666
Trained batch 1430 in epoch 1, gen_loss = 1.0138079304948375, disc_loss = 0.032278238298176755
Trained batch 1431 in epoch 1, gen_loss = 1.0138144770730808, disc_loss = 0.032256286358491267
Trained batch 1432 in epoch 1, gen_loss = 1.0137520476146253, disc_loss = 0.032234076073786665
Trained batch 1433 in epoch 1, gen_loss = 1.0137511517546, disc_loss = 0.0322118019834626
Trained batch 1434 in epoch 1, gen_loss = 1.0136724501952061, disc_loss = 0.03219004383413908
Trained batch 1435 in epoch 1, gen_loss = 1.0136126447105807, disc_loss = 0.03216805447394673
Trained batch 1436 in epoch 1, gen_loss = 1.0135390387281578, disc_loss = 0.032146013585013976
Trained batch 1437 in epoch 1, gen_loss = 1.0134457527596363, disc_loss = 0.03212422766984916
Trained batch 1438 in epoch 1, gen_loss = 1.0134251376172583, disc_loss = 0.032102157021731526
Trained batch 1439 in epoch 1, gen_loss = 1.0134822552402813, disc_loss = 0.032080280907019997
Trained batch 1440 in epoch 1, gen_loss = 1.0134974907538197, disc_loss = 0.03205823044431059
Trained batch 1441 in epoch 1, gen_loss = 1.0134941375040645, disc_loss = 0.0320361979852319
Trained batch 1442 in epoch 1, gen_loss = 1.0134164381175923, disc_loss = 0.03201437143287071
Trained batch 1443 in epoch 1, gen_loss = 1.0134175468102056, disc_loss = 0.03199257020788131
Trained batch 1444 in epoch 1, gen_loss = 1.0133943866693438, disc_loss = 0.0319707404611335
Trained batch 1445 in epoch 1, gen_loss = 1.013419239064305, disc_loss = 0.031949246422879
Trained batch 1446 in epoch 1, gen_loss = 1.0133676086117995, disc_loss = 0.03192761616122083
Trained batch 1447 in epoch 1, gen_loss = 1.013329670203654, disc_loss = 0.03190593138962104
Trained batch 1448 in epoch 1, gen_loss = 1.0133831234040798, disc_loss = 0.03188433047999884
Trained batch 1449 in epoch 1, gen_loss = 1.013304616089525, disc_loss = 0.031862633600660425
Trained batch 1450 in epoch 1, gen_loss = 1.0132405970278975, disc_loss = 0.03184087860189915
Trained batch 1451 in epoch 1, gen_loss = 1.0131929822204526, disc_loss = 0.03181937943404829
Trained batch 1452 in epoch 1, gen_loss = 1.0131672157227214, disc_loss = 0.03179804693186774
Trained batch 1453 in epoch 1, gen_loss = 1.013285890570041, disc_loss = 0.031777079361744315
Trained batch 1454 in epoch 1, gen_loss = 1.0133634066663657, disc_loss = 0.03175598079246858
Trained batch 1455 in epoch 1, gen_loss = 1.0133178237375322, disc_loss = 0.0317345348953345
Trained batch 1456 in epoch 1, gen_loss = 1.0133369631692, disc_loss = 0.03171315852553012
Trained batch 1457 in epoch 1, gen_loss = 1.0132804163853, disc_loss = 0.031691756179398234
Trained batch 1458 in epoch 1, gen_loss = 1.013313726989924, disc_loss = 0.03167032866852718
Trained batch 1459 in epoch 1, gen_loss = 1.0133168060485631, disc_loss = 0.03164898091688958
Trained batch 1460 in epoch 1, gen_loss = 1.0132205061191244, disc_loss = 0.031627693749074745
Trained batch 1461 in epoch 1, gen_loss = 1.0131193131983036, disc_loss = 0.03160628898430731
Trained batch 1462 in epoch 1, gen_loss = 1.0131435433398839, disc_loss = 0.031585260051511015
Trained batch 1463 in epoch 1, gen_loss = 1.0130903300691823, disc_loss = 0.03156408226389883
Trained batch 1464 in epoch 1, gen_loss = 1.0130591958456072, disc_loss = 0.031542831280202376
Trained batch 1465 in epoch 1, gen_loss = 1.0130391472602442, disc_loss = 0.03152162253056085
Trained batch 1466 in epoch 1, gen_loss = 1.0130014864051107, disc_loss = 0.03150046425563451
Trained batch 1467 in epoch 1, gen_loss = 1.0129193538947066, disc_loss = 0.03147927186934524
Trained batch 1468 in epoch 1, gen_loss = 1.0130321001259952, disc_loss = 0.03145837859310081
Trained batch 1469 in epoch 1, gen_loss = 1.0130207443723873, disc_loss = 0.031437388072901036
Trained batch 1470 in epoch 1, gen_loss = 1.013019611606948, disc_loss = 0.03141641996849848
Trained batch 1471 in epoch 1, gen_loss = 1.0129928402602673, disc_loss = 0.031395356846656876
Trained batch 1472 in epoch 1, gen_loss = 1.0130259019537031, disc_loss = 0.03137439008113128
Trained batch 1473 in epoch 1, gen_loss = 1.0130508193490948, disc_loss = 0.03135338414823054
Trained batch 1474 in epoch 1, gen_loss = 1.0130506072610113, disc_loss = 0.031332463183848705
Trained batch 1475 in epoch 1, gen_loss = 1.0130491133143262, disc_loss = 0.03131156143788802
Trained batch 1476 in epoch 1, gen_loss = 1.0129612077307524, disc_loss = 0.03129063320933416
Trained batch 1477 in epoch 1, gen_loss = 1.0129363204936053, disc_loss = 0.031269862010042955
Trained batch 1478 in epoch 1, gen_loss = 1.0129341197787627, disc_loss = 0.031249113394024385
Trained batch 1479 in epoch 1, gen_loss = 1.0129819709304217, disc_loss = 0.0312281813086392
Trained batch 1480 in epoch 1, gen_loss = 1.0129697349810423, disc_loss = 0.031207335588231334
Trained batch 1481 in epoch 1, gen_loss = 1.0129382697596403, disc_loss = 0.031186557356660538
Trained batch 1482 in epoch 1, gen_loss = 1.0128581548010427, disc_loss = 0.031165902490029505
Trained batch 1483 in epoch 1, gen_loss = 1.0128393246719458, disc_loss = 0.031145126448337893
Trained batch 1484 in epoch 1, gen_loss = 1.0128010303083093, disc_loss = 0.031124539419086352
Trained batch 1485 in epoch 1, gen_loss = 1.012748154103355, disc_loss = 0.031103917794308922
Trained batch 1486 in epoch 1, gen_loss = 1.0126526546943244, disc_loss = 0.03108327125718624
Trained batch 1487 in epoch 1, gen_loss = 1.0125740505754948, disc_loss = 0.031062626638886676
Trained batch 1488 in epoch 1, gen_loss = 1.0125002507157899, disc_loss = 0.0310420242037917
Trained batch 1489 in epoch 1, gen_loss = 1.0125114023285424, disc_loss = 0.031021536962684296
Trained batch 1490 in epoch 1, gen_loss = 1.0125640773837155, disc_loss = 0.03100095599136335
Trained batch 1491 in epoch 1, gen_loss = 1.0125321694737146, disc_loss = 0.03098039546886925
Trained batch 1492 in epoch 1, gen_loss = 1.0124675215528223, disc_loss = 0.030959875548038304
Trained batch 1493 in epoch 1, gen_loss = 1.0124283442934514, disc_loss = 0.03093935781498597
Trained batch 1494 in epoch 1, gen_loss = 1.0123980989025587, disc_loss = 0.030919030996634823
Trained batch 1495 in epoch 1, gen_loss = 1.0122749033299359, disc_loss = 0.03089860865504384
Trained batch 1496 in epoch 1, gen_loss = 1.012315420285813, disc_loss = 0.030878301698507405
Trained batch 1497 in epoch 1, gen_loss = 1.0123215700500956, disc_loss = 0.030858101564752407
Trained batch 1498 in epoch 1, gen_loss = 1.0122213963272573, disc_loss = 0.03083797353717647
Trained batch 1499 in epoch 1, gen_loss = 1.0122384057044982, disc_loss = 0.030817891966211996
Trained batch 1500 in epoch 1, gen_loss = 1.0122166800546615, disc_loss = 0.030797653748815695
Trained batch 1501 in epoch 1, gen_loss = 1.012249947943478, disc_loss = 0.030777426349822962
Trained batch 1502 in epoch 1, gen_loss = 1.0122203596496455, disc_loss = 0.03075720883649472
Trained batch 1503 in epoch 1, gen_loss = 1.0121864397871367, disc_loss = 0.030736982141719483
Trained batch 1504 in epoch 1, gen_loss = 1.0121545512018806, disc_loss = 0.03071690889432573
Trained batch 1505 in epoch 1, gen_loss = 1.0120959455273542, disc_loss = 0.03069674099138191
Trained batch 1506 in epoch 1, gen_loss = 1.012022837986595, disc_loss = 0.03067661743890471
Trained batch 1507 in epoch 1, gen_loss = 1.0118910100716179, disc_loss = 0.03065680346761613
Trained batch 1508 in epoch 1, gen_loss = 1.011864873847873, disc_loss = 0.030636932126173026
Trained batch 1509 in epoch 1, gen_loss = 1.0118261260307388, disc_loss = 0.03061695438037767
Trained batch 1510 in epoch 1, gen_loss = 1.0117024158816081, disc_loss = 0.030597000824300093
Trained batch 1511 in epoch 1, gen_loss = 1.011699927073938, disc_loss = 0.030577092943025894
Trained batch 1512 in epoch 1, gen_loss = 1.011651689574487, disc_loss = 0.030557185108767638
Trained batch 1513 in epoch 1, gen_loss = 1.0116797954513344, disc_loss = 0.030537228619574388
Trained batch 1514 in epoch 1, gen_loss = 1.0116854558683466, disc_loss = 0.030517683131745157
Trained batch 1515 in epoch 1, gen_loss = 1.011645133113169, disc_loss = 0.030497749812581493
Trained batch 1516 in epoch 1, gen_loss = 1.011652301272516, disc_loss = 0.03047786316013919
Trained batch 1517 in epoch 1, gen_loss = 1.0116240147388342, disc_loss = 0.030458025118290145
Trained batch 1518 in epoch 1, gen_loss = 1.011561490188232, disc_loss = 0.03043827555112492
Trained batch 1519 in epoch 1, gen_loss = 1.0115174102940057, disc_loss = 0.030418530654165617
Trained batch 1520 in epoch 1, gen_loss = 1.0115445762147721, disc_loss = 0.030398726515201525
Trained batch 1521 in epoch 1, gen_loss = 1.0114950887398713, disc_loss = 0.030379039483876033
Trained batch 1522 in epoch 1, gen_loss = 1.0114382713230832, disc_loss = 0.030359480945722966
Trained batch 1523 in epoch 1, gen_loss = 1.0113322138395209, disc_loss = 0.030339866070622768
Trained batch 1524 in epoch 1, gen_loss = 1.0112821176794708, disc_loss = 0.03032025208163312
Trained batch 1525 in epoch 1, gen_loss = 1.011291956331283, disc_loss = 0.030300664497714635
Trained batch 1526 in epoch 1, gen_loss = 1.0112120142229726, disc_loss = 0.030281209614769874
Trained batch 1527 in epoch 1, gen_loss = 1.0111422363220084, disc_loss = 0.030261742904801266
Trained batch 1528 in epoch 1, gen_loss = 1.0110563384777116, disc_loss = 0.030242264581188432
Trained batch 1529 in epoch 1, gen_loss = 1.0110186606450797, disc_loss = 0.030222667501282535
Trained batch 1530 in epoch 1, gen_loss = 1.0109531812462287, disc_loss = 0.03020326655484795
Trained batch 1531 in epoch 1, gen_loss = 1.0109698532766835, disc_loss = 0.03018382952196012
Trained batch 1532 in epoch 1, gen_loss = 1.0108140037095554, disc_loss = 0.030164468234301415
Trained batch 1533 in epoch 1, gen_loss = 1.0106621132835727, disc_loss = 0.03014536609416052
Trained batch 1534 in epoch 1, gen_loss = 1.010639267713317, disc_loss = 0.030126250174864658
Trained batch 1535 in epoch 1, gen_loss = 1.0104919420555234, disc_loss = 0.03010761500726744
Trained batch 1536 in epoch 1, gen_loss = 1.010521167892873, disc_loss = 0.03008864914537939
Trained batch 1537 in epoch 1, gen_loss = 1.0104905981933807, disc_loss = 0.03006971130143678
Trained batch 1538 in epoch 1, gen_loss = 1.0104254216556041, disc_loss = 0.030050564400741362
Trained batch 1539 in epoch 1, gen_loss = 1.010422760596523, disc_loss = 0.030031288961731364
Trained batch 1540 in epoch 1, gen_loss = 1.0103336913797625, disc_loss = 0.030012048755770977
Trained batch 1541 in epoch 1, gen_loss = 1.010262243633295, disc_loss = 0.029992979907386693
Trained batch 1542 in epoch 1, gen_loss = 1.0102598622335062, disc_loss = 0.029973951254755018
Trained batch 1543 in epoch 1, gen_loss = 1.0101487203428783, disc_loss = 0.02995483211927676
Trained batch 1544 in epoch 1, gen_loss = 1.0101126325940624, disc_loss = 0.02993584852485765
Trained batch 1545 in epoch 1, gen_loss = 1.0100677398938256, disc_loss = 0.02991673797971223
Trained batch 1546 in epoch 1, gen_loss = 1.0100239096877648, disc_loss = 0.029897589929505797
Trained batch 1547 in epoch 1, gen_loss = 1.0099457042238817, disc_loss = 0.02987854561843638
Trained batch 1548 in epoch 1, gen_loss = 1.0098903170318432, disc_loss = 0.029859468968635262
Trained batch 1549 in epoch 1, gen_loss = 1.009899535679048, disc_loss = 0.029840649205453377
Trained batch 1550 in epoch 1, gen_loss = 1.009923752817625, disc_loss = 0.029821594720221844
Trained batch 1551 in epoch 1, gen_loss = 1.0098054808055617, disc_loss = 0.02980273181634102
Trained batch 1552 in epoch 1, gen_loss = 1.0098255382609689, disc_loss = 0.029783792657105186
Trained batch 1553 in epoch 1, gen_loss = 1.0097882292752407, disc_loss = 0.029764853185127015
Trained batch 1554 in epoch 1, gen_loss = 1.0097247638119762, disc_loss = 0.029746008771398685
Trained batch 1555 in epoch 1, gen_loss = 1.0096035129306862, disc_loss = 0.02972713877099387
Trained batch 1556 in epoch 1, gen_loss = 1.009531995541175, disc_loss = 0.02970832330691585
Trained batch 1557 in epoch 1, gen_loss = 1.0095283078443407, disc_loss = 0.029689526611275028
Trained batch 1558 in epoch 1, gen_loss = 1.0094615024507925, disc_loss = 0.02967106506222361
Trained batch 1559 in epoch 1, gen_loss = 1.0093253404666216, disc_loss = 0.029652586587279726
Trained batch 1560 in epoch 1, gen_loss = 1.0093735504578047, disc_loss = 0.02963387556042763
Trained batch 1561 in epoch 1, gen_loss = 1.0093315159389213, disc_loss = 0.029615140201021347
Trained batch 1562 in epoch 1, gen_loss = 1.0093636704574238, disc_loss = 0.029596452606849444
Trained batch 1563 in epoch 1, gen_loss = 1.009294202641758, disc_loss = 0.029577834180995327
Trained batch 1564 in epoch 1, gen_loss = 1.009223417542613, disc_loss = 0.029559217000775524
Trained batch 1565 in epoch 1, gen_loss = 1.0091984927045279, disc_loss = 0.029540630114760408
Trained batch 1566 in epoch 1, gen_loss = 1.0091538846911179, disc_loss = 0.02952199288203606
Trained batch 1567 in epoch 1, gen_loss = 1.0090004316702181, disc_loss = 0.02950702981848847
Trained batch 1568 in epoch 1, gen_loss = 1.0090233352702465, disc_loss = 0.02948886010680789
Trained batch 1569 in epoch 1, gen_loss = 1.0090761609897492, disc_loss = 0.029471090037972967
Trained batch 1570 in epoch 1, gen_loss = 1.009141874874875, disc_loss = 0.02945301186709339
Trained batch 1571 in epoch 1, gen_loss = 1.0091772635322793, disc_loss = 0.029434518001879358
Trained batch 1572 in epoch 1, gen_loss = 1.0092640923453378, disc_loss = 0.029416045682135544
Trained batch 1573 in epoch 1, gen_loss = 1.0092766300847298, disc_loss = 0.029397862181855527
Trained batch 1574 in epoch 1, gen_loss = 1.0094181489187573, disc_loss = 0.029379425529392423
Trained batch 1575 in epoch 1, gen_loss = 1.0094688424301632, disc_loss = 0.029361032458218504
Trained batch 1576 in epoch 1, gen_loss = 1.009587573113136, disc_loss = 0.029342742682688636
Trained batch 1577 in epoch 1, gen_loss = 1.0097123749355852, disc_loss = 0.029324367864803497
Trained batch 1578 in epoch 1, gen_loss = 1.0097752925789454, disc_loss = 0.02930604768757898
Trained batch 1579 in epoch 1, gen_loss = 1.0098335796519171, disc_loss = 0.029287771615127908
Trained batch 1580 in epoch 1, gen_loss = 1.009848012643702, disc_loss = 0.029269454342166653
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.0896588563919067, disc_loss = 0.0004622620763257146
Trained batch 1 in epoch 2, gen_loss = 1.1173328161239624, disc_loss = 0.0004681922437157482
Trained batch 2 in epoch 2, gen_loss = 1.1114692687988281, disc_loss = 0.00048389491469909746
Trained batch 3 in epoch 2, gen_loss = 1.0725006312131882, disc_loss = 0.0007349742518272251
Trained batch 4 in epoch 2, gen_loss = 1.0834006667137146, disc_loss = 0.0006692353694234043
Trained batch 5 in epoch 2, gen_loss = 1.066345324118932, disc_loss = 0.0006352785809819276
Trained batch 6 in epoch 2, gen_loss = 1.0952246955462865, disc_loss = 0.0006364693690557033
Trained batch 7 in epoch 2, gen_loss = 1.1114603504538536, disc_loss = 0.0006077549587644171
Trained batch 8 in epoch 2, gen_loss = 1.108558542198605, disc_loss = 0.0006028831865276314
Trained batch 9 in epoch 2, gen_loss = 1.1128656089305877, disc_loss = 0.0006012307159835473
Trained batch 10 in epoch 2, gen_loss = 1.1141890775073657, disc_loss = 0.0005973129803103141
Trained batch 11 in epoch 2, gen_loss = 1.1180464178323746, disc_loss = 0.0005948909407986017
Trained batch 12 in epoch 2, gen_loss = 1.1168050720141485, disc_loss = 0.0005825497635389463
Trained batch 13 in epoch 2, gen_loss = 1.1122880450316839, disc_loss = 0.0005739740175028731
Trained batch 14 in epoch 2, gen_loss = 1.1097398797671, disc_loss = 0.0005600826484927286
Trained batch 15 in epoch 2, gen_loss = 1.1069643460214138, disc_loss = 0.0005499671387951821
Trained batch 16 in epoch 2, gen_loss = 1.10673588514328, disc_loss = 0.0005403765449848245
Trained batch 17 in epoch 2, gen_loss = 1.1122326685322657, disc_loss = 0.00054657963078676
Trained batch 18 in epoch 2, gen_loss = 1.1184500738194114, disc_loss = 0.00053683959872854
Trained batch 19 in epoch 2, gen_loss = 1.1131207317113876, disc_loss = 0.0005277929332805798
Trained batch 20 in epoch 2, gen_loss = 1.1105764962378002, disc_loss = 0.0005226352105161087
Trained batch 21 in epoch 2, gen_loss = 1.1115429103374481, disc_loss = 0.0005151922351532531
Trained batch 22 in epoch 2, gen_loss = 1.1107696528020112, disc_loss = 0.0005100518604234347
Trained batch 23 in epoch 2, gen_loss = 1.1067843213677406, disc_loss = 0.000504995086278844
Trained batch 24 in epoch 2, gen_loss = 1.1012224078178405, disc_loss = 0.0004969364369753748
Trained batch 25 in epoch 2, gen_loss = 1.0970848844601557, disc_loss = 0.0004927960947567883
Trained batch 26 in epoch 2, gen_loss = 1.1000378176018044, disc_loss = 0.0004947015366741214
Trained batch 27 in epoch 2, gen_loss = 1.1004108914307185, disc_loss = 0.0004904908200842328
Trained batch 28 in epoch 2, gen_loss = 1.1030042212584923, disc_loss = 0.0004884390399293525
Trained batch 29 in epoch 2, gen_loss = 1.103473174571991, disc_loss = 0.0004892744502285496
Trained batch 30 in epoch 2, gen_loss = 1.1019777828647244, disc_loss = 0.0004850907810783434
Trained batch 31 in epoch 2, gen_loss = 1.1037266589701176, disc_loss = 0.0004894112134934403
Trained batch 32 in epoch 2, gen_loss = 1.1002769072850545, disc_loss = 0.00048518885336251873
Trained batch 33 in epoch 2, gen_loss = 1.0998557385276346, disc_loss = 0.0004825202238006408
Trained batch 34 in epoch 2, gen_loss = 1.0949502791677201, disc_loss = 0.00048026573744469457
Trained batch 35 in epoch 2, gen_loss = 1.0934391700559192, disc_loss = 0.0004757478568030314
Trained batch 36 in epoch 2, gen_loss = 1.0902162580876738, disc_loss = 0.00046980286463843405
Trained batch 37 in epoch 2, gen_loss = 1.088638718190946, disc_loss = 0.0004645067521395456
Trained batch 38 in epoch 2, gen_loss = 1.087422326589242, disc_loss = 0.0004606968185936029
Trained batch 39 in epoch 2, gen_loss = 1.0892654702067375, disc_loss = 0.00045678434980800375
Trained batch 40 in epoch 2, gen_loss = 1.0863919287193111, disc_loss = 0.00046204402190973845
Trained batch 41 in epoch 2, gen_loss = 1.0860934654871623, disc_loss = 0.0004620904018381788
Trained batch 42 in epoch 2, gen_loss = 1.0858744410581367, disc_loss = 0.00046449982179437094
Trained batch 43 in epoch 2, gen_loss = 1.0840993848713962, disc_loss = 0.0004623167611002414
Trained batch 44 in epoch 2, gen_loss = 1.0831793864568076, disc_loss = 0.00046767777789177167
Trained batch 45 in epoch 2, gen_loss = 1.0819434057111326, disc_loss = 0.0004651084486597582
Trained batch 46 in epoch 2, gen_loss = 1.080887312584735, disc_loss = 0.0004607083460444862
Trained batch 47 in epoch 2, gen_loss = 1.0766585916280746, disc_loss = 0.00045980546019563917
Trained batch 48 in epoch 2, gen_loss = 1.0753269803767302, disc_loss = 0.0004581114287934817
Trained batch 49 in epoch 2, gen_loss = 1.075371572971344, disc_loss = 0.00045425982971210034
Trained batch 50 in epoch 2, gen_loss = 1.0747056568370146, disc_loss = 0.00045254940507184787
Trained batch 51 in epoch 2, gen_loss = 1.0740224123001099, disc_loss = 0.0004502543032196207
Trained batch 52 in epoch 2, gen_loss = 1.074060044198666, disc_loss = 0.00045001755396062334
Trained batch 53 in epoch 2, gen_loss = 1.071521214864872, disc_loss = 0.0004503749358398771
Trained batch 54 in epoch 2, gen_loss = 1.07052917805585, disc_loss = 0.00044760288966988975
Trained batch 55 in epoch 2, gen_loss = 1.0696875995823316, disc_loss = 0.0004455853413674049
Trained batch 56 in epoch 2, gen_loss = 1.0678177204048425, disc_loss = 0.00044483029214142445
Trained batch 57 in epoch 2, gen_loss = 1.0659965800827946, disc_loss = 0.0004445476716400349
Trained batch 58 in epoch 2, gen_loss = 1.0657826550936296, disc_loss = 0.0004425085025397524
Trained batch 59 in epoch 2, gen_loss = 1.0650317003329595, disc_loss = 0.000440739888290409
Trained batch 60 in epoch 2, gen_loss = 1.0666743507150744, disc_loss = 0.00043933992188225393
Trained batch 61 in epoch 2, gen_loss = 1.064605442746993, disc_loss = 0.0004369491967560363
Trained batch 62 in epoch 2, gen_loss = 1.0634223847162156, disc_loss = 0.00043443116010166705
Trained batch 63 in epoch 2, gen_loss = 1.0633607171475887, disc_loss = 0.00043416925518613425
Trained batch 64 in epoch 2, gen_loss = 1.0657124501008255, disc_loss = 0.0004328894478161461
Trained batch 65 in epoch 2, gen_loss = 1.0641849140326183, disc_loss = 0.0004318138654167397
Trained batch 66 in epoch 2, gen_loss = 1.0622592025728368, disc_loss = 0.0004307813034566648
Trained batch 67 in epoch 2, gen_loss = 1.0626665458959692, disc_loss = 0.0004287878571845153
Trained batch 68 in epoch 2, gen_loss = 1.0641164537789165, disc_loss = 0.00042694379268484056
Trained batch 69 in epoch 2, gen_loss = 1.0639294419969831, disc_loss = 0.0004242777086411869
Trained batch 70 in epoch 2, gen_loss = 1.0642199214075652, disc_loss = 0.00042272900566491493
Trained batch 71 in epoch 2, gen_loss = 1.0647154731882944, disc_loss = 0.0004226813861249765
Trained batch 72 in epoch 2, gen_loss = 1.0645123997779742, disc_loss = 0.00042064523556403663
Trained batch 73 in epoch 2, gen_loss = 1.062768279700666, disc_loss = 0.0004183698755868308
Trained batch 74 in epoch 2, gen_loss = 1.059922600587209, disc_loss = 0.00041711792990099637
Trained batch 75 in epoch 2, gen_loss = 1.0590305100930364, disc_loss = 0.0004152493456786033
Trained batch 76 in epoch 2, gen_loss = 1.058277420409314, disc_loss = 0.0004137548001546582
Trained batch 77 in epoch 2, gen_loss = 1.0579021259760246, disc_loss = 0.00041202669019231765
Trained batch 78 in epoch 2, gen_loss = 1.0567465115197097, disc_loss = 0.0004111458818189493
Trained batch 79 in epoch 2, gen_loss = 1.0567223563790322, disc_loss = 0.00040974974599521373
Trained batch 80 in epoch 2, gen_loss = 1.056752614033075, disc_loss = 0.00040825883326850784
Trained batch 81 in epoch 2, gen_loss = 1.0553853904328696, disc_loss = 0.0004076152351733138
Trained batch 82 in epoch 2, gen_loss = 1.0536555784294404, disc_loss = 0.00040745716776940076
Trained batch 83 in epoch 2, gen_loss = 1.0517202956335885, disc_loss = 0.00040698998799641793
Trained batch 84 in epoch 2, gen_loss = 1.0511789616416483, disc_loss = 0.00040486544449402787
Trained batch 85 in epoch 2, gen_loss = 1.0512818721837776, disc_loss = 0.0004045945694764838
Trained batch 86 in epoch 2, gen_loss = 1.0503698765546425, disc_loss = 0.00040532958251557945
Trained batch 87 in epoch 2, gen_loss = 1.0511158379641445, disc_loss = 0.00040588526710714427
Trained batch 88 in epoch 2, gen_loss = 1.0508613626608687, disc_loss = 0.000405296235799193
Trained batch 89 in epoch 2, gen_loss = 1.0501248280207316, disc_loss = 0.0004039088757255942
Trained batch 90 in epoch 2, gen_loss = 1.0484622500754974, disc_loss = 0.00040286327446785317
Trained batch 91 in epoch 2, gen_loss = 1.0496258288621902, disc_loss = 0.0004022136334084359
Trained batch 92 in epoch 2, gen_loss = 1.0500396201687474, disc_loss = 0.00040114333935117007
Trained batch 93 in epoch 2, gen_loss = 1.0486614830950474, disc_loss = 0.0004006880439230875
Trained batch 94 in epoch 2, gen_loss = 1.0493515792645907, disc_loss = 0.00040124131743428544
Trained batch 95 in epoch 2, gen_loss = 1.0483113309989374, disc_loss = 0.0004002495854062242
Trained batch 96 in epoch 2, gen_loss = 1.0474256148043366, disc_loss = 0.0003996788484786071
Trained batch 97 in epoch 2, gen_loss = 1.047220772018238, disc_loss = 0.0003997822387478961
Trained batch 98 in epoch 2, gen_loss = 1.0473756422900191, disc_loss = 0.00039851569615873613
Trained batch 99 in epoch 2, gen_loss = 1.0462976753711701, disc_loss = 0.00039750504671246743
Trained batch 100 in epoch 2, gen_loss = 1.0464869442552622, disc_loss = 0.00039902524253247436
Trained batch 101 in epoch 2, gen_loss = 1.0454300156995362, disc_loss = 0.0003982670754981775
Trained batch 102 in epoch 2, gen_loss = 1.046537309595682, disc_loss = 0.0003966192642251681
Trained batch 103 in epoch 2, gen_loss = 1.0450956259782498, disc_loss = 0.0003967945017043698
Trained batch 104 in epoch 2, gen_loss = 1.0438793023427329, disc_loss = 0.0003980181261708605
Trained batch 105 in epoch 2, gen_loss = 1.0424148237930153, disc_loss = 0.00039671678252557713
Trained batch 106 in epoch 2, gen_loss = 1.0426204382816209, disc_loss = 0.0003949825284201826
Trained batch 107 in epoch 2, gen_loss = 1.042620489994685, disc_loss = 0.00039548054526137465
Trained batch 108 in epoch 2, gen_loss = 1.0418293465168105, disc_loss = 0.0003944770182021509
Trained batch 109 in epoch 2, gen_loss = 1.040995105830106, disc_loss = 0.00039381168872668326
Trained batch 110 in epoch 2, gen_loss = 1.0398294533695187, disc_loss = 0.00039352134246639235
Trained batch 111 in epoch 2, gen_loss = 1.039433850241559, disc_loss = 0.00039207926680059506
Trained batch 112 in epoch 2, gen_loss = 1.0389926491585453, disc_loss = 0.00039098697067526853
Trained batch 113 in epoch 2, gen_loss = 1.0385458741271705, disc_loss = 0.00038945658518953186
Trained batch 114 in epoch 2, gen_loss = 1.038411283493042, disc_loss = 0.0003888054453494513
Trained batch 115 in epoch 2, gen_loss = 1.038813264205538, disc_loss = 0.0003872365212310828
Trained batch 116 in epoch 2, gen_loss = 1.0391296616986267, disc_loss = 0.00038695258760534256
Trained batch 117 in epoch 2, gen_loss = 1.0383954573485812, disc_loss = 0.0003859755607525092
Trained batch 118 in epoch 2, gen_loss = 1.0390383686338152, disc_loss = 0.00038501646522796484
Trained batch 119 in epoch 2, gen_loss = 1.0387395113706588, disc_loss = 0.0003834616554134603
Trained batch 120 in epoch 2, gen_loss = 1.0392063245300418, disc_loss = 0.00038350844687940014
Trained batch 121 in epoch 2, gen_loss = 1.0395224377757213, disc_loss = 0.00038271122833916186
Trained batch 122 in epoch 2, gen_loss = 1.0388439854955285, disc_loss = 0.0003815821632960569
Trained batch 123 in epoch 2, gen_loss = 1.0390076396926757, disc_loss = 0.00038136609451143043
Trained batch 124 in epoch 2, gen_loss = 1.0380057172775268, disc_loss = 0.0003806274187518284
Trained batch 125 in epoch 2, gen_loss = 1.0371863075665064, disc_loss = 0.00037940862666656605
Trained batch 126 in epoch 2, gen_loss = 1.03633690349699, disc_loss = 0.00037835912669433177
Trained batch 127 in epoch 2, gen_loss = 1.0351138091646135, disc_loss = 0.00037750419380699896
Trained batch 128 in epoch 2, gen_loss = 1.035007941168408, disc_loss = 0.00037662420760706613
Trained batch 129 in epoch 2, gen_loss = 1.034729026372616, disc_loss = 0.0003753344329127755
Trained batch 130 in epoch 2, gen_loss = 1.0336067590094704, disc_loss = 0.0003744990714623074
Trained batch 131 in epoch 2, gen_loss = 1.032668266784061, disc_loss = 0.0003738551028866575
Trained batch 132 in epoch 2, gen_loss = 1.0319580865981883, disc_loss = 0.00037335584800571374
Trained batch 133 in epoch 2, gen_loss = 1.0319957399546211, disc_loss = 0.00037278664088112985
Trained batch 134 in epoch 2, gen_loss = 1.0303154102078191, disc_loss = 0.0003791325479849345
Trained batch 135 in epoch 2, gen_loss = 1.0297397870351286, disc_loss = 0.00038209678100161804
Trained batch 136 in epoch 2, gen_loss = 1.029666375504793, disc_loss = 0.00038414129207291415
Trained batch 137 in epoch 2, gen_loss = 1.0293558520683344, disc_loss = 0.000385416414760782
Trained batch 138 in epoch 2, gen_loss = 1.0292306147890984, disc_loss = 0.00038444808547773645
Trained batch 139 in epoch 2, gen_loss = 1.0281693113701684, disc_loss = 0.0003832707581750583
Trained batch 140 in epoch 2, gen_loss = 1.027920702247755, disc_loss = 0.00038244310902276385
Trained batch 141 in epoch 2, gen_loss = 1.026287339942556, disc_loss = 0.0003818676793254243
Trained batch 142 in epoch 2, gen_loss = 1.026148387602159, disc_loss = 0.0003815641889464227
Trained batch 143 in epoch 2, gen_loss = 1.024858121242788, disc_loss = 0.00038056956539852155
Trained batch 144 in epoch 2, gen_loss = 1.02508290800555, disc_loss = 0.00038239246661822985
Trained batch 145 in epoch 2, gen_loss = 1.0242145641209328, disc_loss = 0.00038200393265307793
Trained batch 146 in epoch 2, gen_loss = 1.022666327807368, disc_loss = 0.0003838957103046899
Trained batch 147 in epoch 2, gen_loss = 1.022303255023183, disc_loss = 0.000384155832639285
Trained batch 148 in epoch 2, gen_loss = 1.0214101532161637, disc_loss = 0.0003838798396669066
Trained batch 149 in epoch 2, gen_loss = 1.0218141754468282, disc_loss = 0.00038294607492086167
Trained batch 150 in epoch 2, gen_loss = 1.0209669991834274, disc_loss = 0.0003819458121287371
Trained batch 151 in epoch 2, gen_loss = 1.02004660940484, disc_loss = 0.00038168062316177193
Trained batch 152 in epoch 2, gen_loss = 1.0207081359196333, disc_loss = 0.0003868053408356359
Trained batch 153 in epoch 2, gen_loss = 1.0203162934873011, disc_loss = 0.00038651216201795655
Trained batch 154 in epoch 2, gen_loss = 1.0212702912669027, disc_loss = 0.00038631862346758883
Trained batch 155 in epoch 2, gen_loss = 1.020691644304838, disc_loss = 0.0003854835834854151
Trained batch 156 in epoch 2, gen_loss = 1.020382738037474, disc_loss = 0.0003847264743871263
Trained batch 157 in epoch 2, gen_loss = 1.0200535311729093, disc_loss = 0.000384495366579128
Trained batch 158 in epoch 2, gen_loss = 1.0202246855639812, disc_loss = 0.00038423596117308705
Trained batch 159 in epoch 2, gen_loss = 1.0197944052517414, disc_loss = 0.0003847375664008723
Trained batch 160 in epoch 2, gen_loss = 1.0198568661020408, disc_loss = 0.0003842176546477163
Trained batch 161 in epoch 2, gen_loss = 1.019521846447462, disc_loss = 0.00038549408934978815
Trained batch 162 in epoch 2, gen_loss = 1.0198033982259365, disc_loss = 0.00038519008715417053
Trained batch 163 in epoch 2, gen_loss = 1.0198145392464428, disc_loss = 0.0003846738915698796
Trained batch 164 in epoch 2, gen_loss = 1.019837626543912, disc_loss = 0.0003838564248960183
Trained batch 165 in epoch 2, gen_loss = 1.0192696671169925, disc_loss = 0.0003831245690473378
Trained batch 166 in epoch 2, gen_loss = 1.0193103405529866, disc_loss = 0.00038319695951810254
Trained batch 167 in epoch 2, gen_loss = 1.0191953494435264, disc_loss = 0.0003818650720426203
Trained batch 168 in epoch 2, gen_loss = 1.0185562636725296, disc_loss = 0.00038103673914681636
Trained batch 169 in epoch 2, gen_loss = 1.0186687157434575, disc_loss = 0.0003800435174044276
Trained batch 170 in epoch 2, gen_loss = 1.0189181611551876, disc_loss = 0.0003799199255500588
Trained batch 171 in epoch 2, gen_loss = 1.0186131766369177, disc_loss = 0.00037978771712893596
Trained batch 172 in epoch 2, gen_loss = 1.0180483046983708, disc_loss = 0.0003793541397704242
Trained batch 173 in epoch 2, gen_loss = 1.0182914353650192, disc_loss = 0.0003825879973411592
Trained batch 174 in epoch 2, gen_loss = 1.0181630553518022, disc_loss = 0.00038169726787600666
Trained batch 175 in epoch 2, gen_loss = 1.017128712412986, disc_loss = 0.00038130191230514106
Trained batch 176 in epoch 2, gen_loss = 1.016698911701892, disc_loss = 0.00038127963637372763
Trained batch 177 in epoch 2, gen_loss = 1.0169611636842235, disc_loss = 0.00038126269294919574
Trained batch 178 in epoch 2, gen_loss = 1.0165045244733715, disc_loss = 0.00038096023612595864
Trained batch 179 in epoch 2, gen_loss = 1.0164596137073305, disc_loss = 0.00038023727271744673
Trained batch 180 in epoch 2, gen_loss = 1.0166425194529538, disc_loss = 0.00038063645101401916
Trained batch 181 in epoch 2, gen_loss = 1.0159322563763504, disc_loss = 0.00038018068504982864
Trained batch 182 in epoch 2, gen_loss = 1.0152409304686583, disc_loss = 0.0003794375360947194
Trained batch 183 in epoch 2, gen_loss = 1.014885035869868, disc_loss = 0.0003783505663190938
Trained batch 184 in epoch 2, gen_loss = 1.014957559108734, disc_loss = 0.00037767739118567693
Trained batch 185 in epoch 2, gen_loss = 1.014650249032564, disc_loss = 0.0003770905123899631
Trained batch 186 in epoch 2, gen_loss = 1.015046748566755, disc_loss = 0.0003765705568413375
Trained batch 187 in epoch 2, gen_loss = 1.0148547155425904, disc_loss = 0.00037608763252253684
Trained batch 188 in epoch 2, gen_loss = 1.0147402904651783, disc_loss = 0.000375106970923731
Trained batch 189 in epoch 2, gen_loss = 1.0142131717581497, disc_loss = 0.00037478254908867377
Trained batch 190 in epoch 2, gen_loss = 1.013913120898901, disc_loss = 0.00037418730073627963
Trained batch 191 in epoch 2, gen_loss = 1.0133685320615768, disc_loss = 0.00037350397640996863
Trained batch 192 in epoch 2, gen_loss = 1.0125841553964763, disc_loss = 0.0003726784948294577
Trained batch 193 in epoch 2, gen_loss = 1.012488995937957, disc_loss = 0.0003718703770836018
Trained batch 194 in epoch 2, gen_loss = 1.0120030406193856, disc_loss = 0.00037196585811519374
Trained batch 195 in epoch 2, gen_loss = 1.011922992917956, disc_loss = 0.00037120555008390957
Trained batch 196 in epoch 2, gen_loss = 1.0112137301319142, disc_loss = 0.0003709491216140293
Trained batch 197 in epoch 2, gen_loss = 1.0108621499755166, disc_loss = 0.0003701789014898664
Trained batch 198 in epoch 2, gen_loss = 1.0104019941397049, disc_loss = 0.0003692731905486388
Trained batch 199 in epoch 2, gen_loss = 1.0099618995189668, disc_loss = 0.0003685421140107792
Trained batch 200 in epoch 2, gen_loss = 1.0098680738192887, disc_loss = 0.00036791255535437395
Trained batch 201 in epoch 2, gen_loss = 1.0088881319112117, disc_loss = 0.00036743278877399306
Trained batch 202 in epoch 2, gen_loss = 1.008557472029343, disc_loss = 0.0003667528480274162
Trained batch 203 in epoch 2, gen_loss = 1.0076947454728333, disc_loss = 0.00036632730324544905
Trained batch 204 in epoch 2, gen_loss = 1.0074972437649239, disc_loss = 0.0003654236159224926
Trained batch 205 in epoch 2, gen_loss = 1.0072538569135574, disc_loss = 0.0003645909864379735
Trained batch 206 in epoch 2, gen_loss = 1.0075860800950422, disc_loss = 0.00036415249056684454
Trained batch 207 in epoch 2, gen_loss = 1.0069432121056776, disc_loss = 0.0003636834135949567
Trained batch 208 in epoch 2, gen_loss = 1.006676522168246, disc_loss = 0.0003632692809959731
Trained batch 209 in epoch 2, gen_loss = 1.0058807089215234, disc_loss = 0.0003624064173588219
Trained batch 210 in epoch 2, gen_loss = 1.005911751381029, disc_loss = 0.0003615188801614788
Trained batch 211 in epoch 2, gen_loss = 1.005435123196188, disc_loss = 0.0003606748777767863
Trained batch 212 in epoch 2, gen_loss = 1.00448571964049, disc_loss = 0.00036042829134617384
Trained batch 213 in epoch 2, gen_loss = 1.0042370992286183, disc_loss = 0.0003599989203878713
Trained batch 214 in epoch 2, gen_loss = 1.0041809919268585, disc_loss = 0.00035940500634159287
Trained batch 215 in epoch 2, gen_loss = 1.0038855429048892, disc_loss = 0.0003585300355216195
Trained batch 216 in epoch 2, gen_loss = 1.00329261935801, disc_loss = 0.00035808537402705283
Trained batch 217 in epoch 2, gen_loss = 1.0028021915243306, disc_loss = 0.00035804329792981743
Trained batch 218 in epoch 2, gen_loss = 1.002338758070175, disc_loss = 0.00035780863294199313
Trained batch 219 in epoch 2, gen_loss = 1.0021738997914575, disc_loss = 0.0003576411209492521
Trained batch 220 in epoch 2, gen_loss = 1.0026054606178767, disc_loss = 0.00035850517056688533
Trained batch 221 in epoch 2, gen_loss = 1.0018342182979927, disc_loss = 0.0003589999982363519
Trained batch 222 in epoch 2, gen_loss = 1.001591313312941, disc_loss = 0.0003587693954043241
Trained batch 223 in epoch 2, gen_loss = 1.0020781571843795, disc_loss = 0.00035816946826473995
Trained batch 224 in epoch 2, gen_loss = 1.0021048214700488, disc_loss = 0.0003577679506270215
Trained batch 225 in epoch 2, gen_loss = 1.0016808143231721, disc_loss = 0.00035704891832258996
Trained batch 226 in epoch 2, gen_loss = 1.001425516500347, disc_loss = 0.0003571784489050647
Trained batch 227 in epoch 2, gen_loss = 1.0013206844267093, disc_loss = 0.0003569759218519545
Trained batch 228 in epoch 2, gen_loss = 1.0015193767943236, disc_loss = 0.00035649536292660394
Trained batch 229 in epoch 2, gen_loss = 1.0013578254243602, disc_loss = 0.0003559568829824338
Trained batch 230 in epoch 2, gen_loss = 1.0012971364058458, disc_loss = 0.00035513320472091436
Trained batch 231 in epoch 2, gen_loss = 1.000842331555383, disc_loss = 0.0003551466331279291
Trained batch 232 in epoch 2, gen_loss = 1.000366615635131, disc_loss = 0.0003543812234470293
Trained batch 233 in epoch 2, gen_loss = 1.0001268837696466, disc_loss = 0.00035444712930490286
Trained batch 234 in epoch 2, gen_loss = 1.0001678677315409, disc_loss = 0.00035459730474456667
Trained batch 235 in epoch 2, gen_loss = 0.9998341866974103, disc_loss = 0.00035397053468810645
Trained batch 236 in epoch 2, gen_loss = 0.9996834362106484, disc_loss = 0.0003539575911018966
Trained batch 237 in epoch 2, gen_loss = 0.999127799472889, disc_loss = 0.00035587568758075136
Trained batch 238 in epoch 2, gen_loss = 0.9989992277891566, disc_loss = 0.00035517497645022746
Trained batch 239 in epoch 2, gen_loss = 0.9989834961791834, disc_loss = 0.00035474953504793425
Trained batch 240 in epoch 2, gen_loss = 0.9988401655834246, disc_loss = 0.00035443570721108093
Trained batch 241 in epoch 2, gen_loss = 0.9979543323851814, disc_loss = 0.00035481484038495526
Trained batch 242 in epoch 2, gen_loss = 0.9978117493935573, disc_loss = 0.00035524080080361536
Trained batch 243 in epoch 2, gen_loss = 0.9980876311415532, disc_loss = 0.0003550514937488202
Trained batch 244 in epoch 2, gen_loss = 0.9978944654367408, disc_loss = 0.00035459001029470975
Trained batch 245 in epoch 2, gen_loss = 0.9980577833768798, disc_loss = 0.0003544417596436333
Trained batch 246 in epoch 2, gen_loss = 0.9975861863568727, disc_loss = 0.0003541080227054784
Trained batch 247 in epoch 2, gen_loss = 0.9978797640050611, disc_loss = 0.00035390966672087915
Trained batch 248 in epoch 2, gen_loss = 0.9971624983841156, disc_loss = 0.0003538426972227171
Trained batch 249 in epoch 2, gen_loss = 0.9965839264392853, disc_loss = 0.0003535389979952015
Trained batch 250 in epoch 2, gen_loss = 0.9959862035109227, disc_loss = 0.000353185907486303
Trained batch 251 in epoch 2, gen_loss = 0.9958220989931197, disc_loss = 0.0003533032844614585
Trained batch 252 in epoch 2, gen_loss = 0.9954813942607683, disc_loss = 0.0003527422097264034
Trained batch 253 in epoch 2, gen_loss = 0.9960827022556245, disc_loss = 0.0003523758298503858
Trained batch 254 in epoch 2, gen_loss = 0.9960187902637556, disc_loss = 0.00035175712734652575
Trained batch 255 in epoch 2, gen_loss = 0.9959596223197877, disc_loss = 0.00035087971195935097
Trained batch 256 in epoch 2, gen_loss = 0.9959363482805541, disc_loss = 0.00035041445069665503
Trained batch 257 in epoch 2, gen_loss = 0.9956022704294486, disc_loss = 0.00035000901100498287
Trained batch 258 in epoch 2, gen_loss = 0.9956478934490542, disc_loss = 0.0003495117418852753
Trained batch 259 in epoch 2, gen_loss = 0.9955236888848819, disc_loss = 0.00034872856609021813
Trained batch 260 in epoch 2, gen_loss = 0.9958526083336022, disc_loss = 0.000348412093681451
Trained batch 261 in epoch 2, gen_loss = 0.9962008891214851, disc_loss = 0.0003482417565839763
Trained batch 262 in epoch 2, gen_loss = 0.9960709400050087, disc_loss = 0.00034764105240068973
Trained batch 263 in epoch 2, gen_loss = 0.9966342225670815, disc_loss = 0.0003478321893150375
Trained batch 264 in epoch 2, gen_loss = 0.9969960997689445, disc_loss = 0.00034776896546937457
Trained batch 265 in epoch 2, gen_loss = 0.9969911292979592, disc_loss = 0.0003474713719464818
Trained batch 266 in epoch 2, gen_loss = 0.99700756957022, disc_loss = 0.00034706863532826473
Trained batch 267 in epoch 2, gen_loss = 0.9969945011743858, disc_loss = 0.0003468610757680387
Trained batch 268 in epoch 2, gen_loss = 0.9970843583677781, disc_loss = 0.000346994221593049
Trained batch 269 in epoch 2, gen_loss = 0.9965907379432961, disc_loss = 0.00034654244470099606
Trained batch 270 in epoch 2, gen_loss = 0.9965132393520256, disc_loss = 0.0003462412325421355
Trained batch 271 in epoch 2, gen_loss = 0.9959237470346338, disc_loss = 0.00034587809579320224
Trained batch 272 in epoch 2, gen_loss = 0.9958970437556396, disc_loss = 0.00034533161286182785
Trained batch 273 in epoch 2, gen_loss = 0.9958036733369757, disc_loss = 0.00034498915575057213
Trained batch 274 in epoch 2, gen_loss = 0.9953615580905567, disc_loss = 0.00034471986677751625
Trained batch 275 in epoch 2, gen_loss = 0.9950568974018097, disc_loss = 0.00034445948298578486
Trained batch 276 in epoch 2, gen_loss = 0.9955440570301097, disc_loss = 0.0003442332315189757
Trained batch 277 in epoch 2, gen_loss = 0.9956279577111169, disc_loss = 0.0003440565269033378
Trained batch 278 in epoch 2, gen_loss = 0.9957254172226007, disc_loss = 0.0003433732132199571
Trained batch 279 in epoch 2, gen_loss = 0.9953110558646066, disc_loss = 0.00034290654257347343
Trained batch 280 in epoch 2, gen_loss = 0.9952511851049403, disc_loss = 0.00034238669460554845
Trained batch 281 in epoch 2, gen_loss = 0.9948905205472987, disc_loss = 0.00034186494804411824
Trained batch 282 in epoch 2, gen_loss = 0.9949175947125304, disc_loss = 0.0003415568483982716
Trained batch 283 in epoch 2, gen_loss = 0.9948264580797141, disc_loss = 0.000341061993617266
Trained batch 284 in epoch 2, gen_loss = 0.9945292244877731, disc_loss = 0.00034034967748244015
Trained batch 285 in epoch 2, gen_loss = 0.9944384777462566, disc_loss = 0.00033974184414902635
Trained batch 286 in epoch 2, gen_loss = 0.9947816482404384, disc_loss = 0.00033994778945720805
Trained batch 287 in epoch 2, gen_loss = 0.994761779697405, disc_loss = 0.0003394700942812455
Trained batch 288 in epoch 2, gen_loss = 0.9948682263235732, disc_loss = 0.00033877468553120365
Trained batch 289 in epoch 2, gen_loss = 0.9950282148246108, disc_loss = 0.00033844910784833264
Trained batch 290 in epoch 2, gen_loss = 0.9948980175342756, disc_loss = 0.00033787157675779436
Trained batch 291 in epoch 2, gen_loss = 0.9946220817222987, disc_loss = 0.00033736059472861074
Trained batch 292 in epoch 2, gen_loss = 0.9944810686257919, disc_loss = 0.0003369823757240409
Trained batch 293 in epoch 2, gen_loss = 0.9941224348382885, disc_loss = 0.00033640477365416596
Trained batch 294 in epoch 2, gen_loss = 0.9936791365429506, disc_loss = 0.0003358777525136247
Trained batch 295 in epoch 2, gen_loss = 0.9934703033115413, disc_loss = 0.00033573688194116365
Trained batch 296 in epoch 2, gen_loss = 0.993447052308606, disc_loss = 0.00033531297897443374
Trained batch 297 in epoch 2, gen_loss = 0.9934893364474278, disc_loss = 0.00033470181277140527
Trained batch 298 in epoch 2, gen_loss = 0.9935603028157084, disc_loss = 0.00033421539760897104
Trained batch 299 in epoch 2, gen_loss = 0.9934635782241821, disc_loss = 0.000333714796336911
Trained batch 300 in epoch 2, gen_loss = 0.9938326848305737, disc_loss = 0.0003333075393700626
Trained batch 301 in epoch 2, gen_loss = 0.9937883518784252, disc_loss = 0.0003329929181113253
Trained batch 302 in epoch 2, gen_loss = 0.9937777765119823, disc_loss = 0.00033285330467905063
Trained batch 303 in epoch 2, gen_loss = 0.9935683755106047, disc_loss = 0.00033230818969873086
Trained batch 304 in epoch 2, gen_loss = 0.9938438843508236, disc_loss = 0.00033181074145059177
Trained batch 305 in epoch 2, gen_loss = 0.9933606964700362, disc_loss = 0.0003316798362956273
Trained batch 306 in epoch 2, gen_loss = 0.9935195203324483, disc_loss = 0.0003312561097983362
Trained batch 307 in epoch 2, gen_loss = 0.9936972134686136, disc_loss = 0.0003311690542632986
Trained batch 308 in epoch 2, gen_loss = 0.9935645164023711, disc_loss = 0.00033083175687446384
Trained batch 309 in epoch 2, gen_loss = 0.9936890150270155, disc_loss = 0.00033037238073677967
Trained batch 310 in epoch 2, gen_loss = 0.9936371493569525, disc_loss = 0.0003301814661067057
Trained batch 311 in epoch 2, gen_loss = 0.993458527020919, disc_loss = 0.00032996338711363467
Trained batch 312 in epoch 2, gen_loss = 0.9933006226445158, disc_loss = 0.00033042066783187525
Trained batch 313 in epoch 2, gen_loss = 0.9928834250398503, disc_loss = 0.0003303626965517089
Trained batch 314 in epoch 2, gen_loss = 0.9924502688740927, disc_loss = 0.0003302468148167319
Trained batch 315 in epoch 2, gen_loss = 0.9922371644385254, disc_loss = 0.0003300730803155464
Trained batch 316 in epoch 2, gen_loss = 0.9921193619255764, disc_loss = 0.000329630112792189
Trained batch 317 in epoch 2, gen_loss = 0.9920134293208333, disc_loss = 0.0003292621756298321
Trained batch 318 in epoch 2, gen_loss = 0.9917376377739503, disc_loss = 0.0003287348148415192
Trained batch 319 in epoch 2, gen_loss = 0.9918119285255671, disc_loss = 0.00032876038972062815
Trained batch 320 in epoch 2, gen_loss = 0.9919625750954649, disc_loss = 0.00032854385151218833
Trained batch 321 in epoch 2, gen_loss = 0.9913546492964584, disc_loss = 0.0003282979595954299
Trained batch 322 in epoch 2, gen_loss = 0.9912213971002183, disc_loss = 0.00032795207899701044
Trained batch 323 in epoch 2, gen_loss = 0.991082971478686, disc_loss = 0.0003277246455301209
Trained batch 324 in epoch 2, gen_loss = 0.9908391479345469, disc_loss = 0.0003271606779890135
Trained batch 325 in epoch 2, gen_loss = 0.9910222394334758, disc_loss = 0.0003267316712531478
Trained batch 326 in epoch 2, gen_loss = 0.9910546679744662, disc_loss = 0.00032651581795599925
Trained batch 327 in epoch 2, gen_loss = 0.9916010419043099, disc_loss = 0.0003270482262096044
Trained batch 328 in epoch 2, gen_loss = 0.9912947220642878, disc_loss = 0.00032745438144368184
Trained batch 329 in epoch 2, gen_loss = 0.9909821886004824, disc_loss = 0.0003273731058332928
Trained batch 330 in epoch 2, gen_loss = 0.9910370205104171, disc_loss = 0.0003280852285331239
Trained batch 331 in epoch 2, gen_loss = 0.9907948509397277, disc_loss = 0.0003278687995972802
Trained batch 332 in epoch 2, gen_loss = 0.9906535712448327, disc_loss = 0.0003273196001631535
Trained batch 333 in epoch 2, gen_loss = 0.9905152572486216, disc_loss = 0.0003269289634249753
Trained batch 334 in epoch 2, gen_loss = 0.9902438503592762, disc_loss = 0.00032680618716577595
Trained batch 335 in epoch 2, gen_loss = 0.9899392044615178, disc_loss = 0.0003264852894062642
Trained batch 336 in epoch 2, gen_loss = 0.9898971740145358, disc_loss = 0.00032608213493163845
Trained batch 337 in epoch 2, gen_loss = 0.9899318500383366, disc_loss = 0.00032568874087986487
Trained batch 338 in epoch 2, gen_loss = 0.9897402176814797, disc_loss = 0.00032585672802390713
Trained batch 339 in epoch 2, gen_loss = 0.9900740704115699, disc_loss = 0.0003258812856716652
Trained batch 340 in epoch 2, gen_loss = 0.9896879891845838, disc_loss = 0.0003258464537879119
Trained batch 341 in epoch 2, gen_loss = 0.9897428343170568, disc_loss = 0.00032576744021556466
Trained batch 342 in epoch 2, gen_loss = 0.989761041830302, disc_loss = 0.00032532190588036817
Trained batch 343 in epoch 2, gen_loss = 0.9898433047671651, disc_loss = 0.00032505850576007805
Trained batch 344 in epoch 2, gen_loss = 0.9893443290738092, disc_loss = 0.00032497391145190467
Trained batch 345 in epoch 2, gen_loss = 0.9892105520460647, disc_loss = 0.000324969872868636
Trained batch 346 in epoch 2, gen_loss = 0.988926545687299, disc_loss = 0.00032451749401521315
Trained batch 347 in epoch 2, gen_loss = 0.9891198839264355, disc_loss = 0.000324216125423929
Trained batch 348 in epoch 2, gen_loss = 0.9890531415925669, disc_loss = 0.000323678832501173
Trained batch 349 in epoch 2, gen_loss = 0.9890493943010058, disc_loss = 0.00032338576029620266
Trained batch 350 in epoch 2, gen_loss = 0.9888563103485651, disc_loss = 0.00032303453932358404
Trained batch 351 in epoch 2, gen_loss = 0.9887091212651946, disc_loss = 0.00032274248219850546
Trained batch 352 in epoch 2, gen_loss = 0.9883725237913915, disc_loss = 0.0003222477431959808
Trained batch 353 in epoch 2, gen_loss = 0.9885804387135694, disc_loss = 0.00032189957915751345
Trained batch 354 in epoch 2, gen_loss = 0.988353172658195, disc_loss = 0.0003217874936395469
Trained batch 355 in epoch 2, gen_loss = 0.9881892447056395, disc_loss = 0.00032191242329584005
Trained batch 356 in epoch 2, gen_loss = 0.98846762003351, disc_loss = 0.0003216744201073256
Trained batch 357 in epoch 2, gen_loss = 0.9887739787887595, disc_loss = 0.0003214144099073864
Trained batch 358 in epoch 2, gen_loss = 0.9888570675610832, disc_loss = 0.0003214449197177783
Trained batch 359 in epoch 2, gen_loss = 0.9887688760956128, disc_loss = 0.0003212747172559223
Trained batch 360 in epoch 2, gen_loss = 0.988763790546692, disc_loss = 0.00032105092442152026
Trained batch 361 in epoch 2, gen_loss = 0.9887202578025628, disc_loss = 0.00032073444299636543
Trained batch 362 in epoch 2, gen_loss = 0.988754979999269, disc_loss = 0.0003205235706277951
Trained batch 363 in epoch 2, gen_loss = 0.9885155401387058, disc_loss = 0.00032013212218701554
Trained batch 364 in epoch 2, gen_loss = 0.9882858127763826, disc_loss = 0.00031977444468544514
Trained batch 365 in epoch 2, gen_loss = 0.9880341167658404, disc_loss = 0.0003193548769270874
Trained batch 366 in epoch 2, gen_loss = 0.9877229864006146, disc_loss = 0.0003193139304531921
Trained batch 367 in epoch 2, gen_loss = 0.9876952832159789, disc_loss = 0.0003189859752756488
Trained batch 368 in epoch 2, gen_loss = 0.9873393975945346, disc_loss = 0.00031867072316357325
Trained batch 369 in epoch 2, gen_loss = 0.9871382386297793, disc_loss = 0.00031837470136501046
Trained batch 370 in epoch 2, gen_loss = 0.9864880130940049, disc_loss = 0.00031939812670267286
Trained batch 371 in epoch 2, gen_loss = 0.9863598596665167, disc_loss = 0.00031941952481922214
Trained batch 372 in epoch 2, gen_loss = 0.986371293943625, disc_loss = 0.00031907979199842577
Trained batch 373 in epoch 2, gen_loss = 0.9863389375056812, disc_loss = 0.000318809053290979
Trained batch 374 in epoch 2, gen_loss = 0.9864037496248881, disc_loss = 0.0003184821775648743
Trained batch 375 in epoch 2, gen_loss = 0.9864088916715156, disc_loss = 0.00031806596950658826
Trained batch 376 in epoch 2, gen_loss = 0.986001769332734, disc_loss = 0.0003178449489583264
Trained batch 377 in epoch 2, gen_loss = 0.9864263700114356, disc_loss = 0.00031788098325099173
Trained batch 378 in epoch 2, gen_loss = 0.9863172142046422, disc_loss = 0.0003173666878951723
Trained batch 379 in epoch 2, gen_loss = 0.9863387073341169, disc_loss = 0.00031714406313288856
Trained batch 380 in epoch 2, gen_loss = 0.9860799325106964, disc_loss = 0.0003168832418203887
Trained batch 381 in epoch 2, gen_loss = 0.9858911020281427, disc_loss = 0.0003170227289918435
Trained batch 382 in epoch 2, gen_loss = 0.9856602502865206, disc_loss = 0.0003168982364053111
Trained batch 383 in epoch 2, gen_loss = 0.9857774934110543, disc_loss = 0.00031669324619088
Trained batch 384 in epoch 2, gen_loss = 0.9857536989373046, disc_loss = 0.000316387295379763
Trained batch 385 in epoch 2, gen_loss = 0.9858596104105519, disc_loss = 0.00031610151607008803
Trained batch 386 in epoch 2, gen_loss = 0.9858545975167622, disc_loss = 0.0003159296776252878
Trained batch 387 in epoch 2, gen_loss = 0.9857055962700205, disc_loss = 0.00031558823879488946
Trained batch 388 in epoch 2, gen_loss = 0.9856727717774693, disc_loss = 0.0003153046143120322
Trained batch 389 in epoch 2, gen_loss = 0.9856967096145336, disc_loss = 0.00031491157416708006
Trained batch 390 in epoch 2, gen_loss = 0.9857575800412756, disc_loss = 0.00031452655737601516
Trained batch 391 in epoch 2, gen_loss = 0.9859355990679897, disc_loss = 0.00031414246724143966
Trained batch 392 in epoch 2, gen_loss = 0.9857475423934199, disc_loss = 0.0003136932846477478
Trained batch 393 in epoch 2, gen_loss = 0.9853852244500582, disc_loss = 0.00031336641205335274
Trained batch 394 in epoch 2, gen_loss = 0.9851581473893757, disc_loss = 0.00031311330481290913
Trained batch 395 in epoch 2, gen_loss = 0.9850091982369471, disc_loss = 0.0003126639953780345
Trained batch 396 in epoch 2, gen_loss = 0.985103168775813, disc_loss = 0.0003123044088231845
Trained batch 397 in epoch 2, gen_loss = 0.9851311469197872, disc_loss = 0.0003118714852297758
Trained batch 398 in epoch 2, gen_loss = 0.985159282845662, disc_loss = 0.0003115763967415612
Trained batch 399 in epoch 2, gen_loss = 0.9849117785692215, disc_loss = 0.0003111204129163525
Trained batch 400 in epoch 2, gen_loss = 0.9849288017672494, disc_loss = 0.00031071965513138934
Trained batch 401 in epoch 2, gen_loss = 0.9850758770805094, disc_loss = 0.0003106422204045296
Trained batch 402 in epoch 2, gen_loss = 0.9848076424586861, disc_loss = 0.00031068749950705305
Trained batch 403 in epoch 2, gen_loss = 0.9848828047218889, disc_loss = 0.00031054292059599166
Trained batch 404 in epoch 2, gen_loss = 0.9846034267802297, disc_loss = 0.00031016032469464625
Trained batch 405 in epoch 2, gen_loss = 0.9846177261157576, disc_loss = 0.0003100491225707409
Trained batch 406 in epoch 2, gen_loss = 0.9842102283048981, disc_loss = 0.0003098772077292607
Trained batch 407 in epoch 2, gen_loss = 0.9840875620058939, disc_loss = 0.0003095972484409097
Trained batch 408 in epoch 2, gen_loss = 0.984131964756982, disc_loss = 0.0003093609379002173
Trained batch 409 in epoch 2, gen_loss = 0.9842673018211272, disc_loss = 0.0003090615129444703
Trained batch 410 in epoch 2, gen_loss = 0.9842224450297019, disc_loss = 0.00030868974282891195
Trained batch 411 in epoch 2, gen_loss = 0.9838235486768981, disc_loss = 0.00030853987415151634
Trained batch 412 in epoch 2, gen_loss = 0.9839706973648533, disc_loss = 0.00030843590100952054
Trained batch 413 in epoch 2, gen_loss = 0.9838681663004096, disc_loss = 0.0003082571801609148
Trained batch 414 in epoch 2, gen_loss = 0.9839437118495803, disc_loss = 0.00030813576472665084
Trained batch 415 in epoch 2, gen_loss = 0.9838078023435978, disc_loss = 0.0003078258959109147
Trained batch 416 in epoch 2, gen_loss = 0.9840520070039397, disc_loss = 0.0003078347320818595
Trained batch 417 in epoch 2, gen_loss = 0.9840255309805346, disc_loss = 0.00030746646419710046
Trained batch 418 in epoch 2, gen_loss = 0.9837692246232226, disc_loss = 0.00030722110180060884
Trained batch 419 in epoch 2, gen_loss = 0.9839572476489203, disc_loss = 0.00030711026182481354
Trained batch 420 in epoch 2, gen_loss = 0.9838280871758268, disc_loss = 0.0003071610708740339
Trained batch 421 in epoch 2, gen_loss = 0.9836607280218206, disc_loss = 0.0003069114955255245
Trained batch 422 in epoch 2, gen_loss = 0.9836488864946027, disc_loss = 0.00030670014586950265
Trained batch 423 in epoch 2, gen_loss = 0.9835114449543773, disc_loss = 0.00030634009632400574
Trained batch 424 in epoch 2, gen_loss = 0.9835917617292965, disc_loss = 0.00030609925517209753
Trained batch 425 in epoch 2, gen_loss = 0.9832621956934952, disc_loss = 0.0003059162818274719
Trained batch 426 in epoch 2, gen_loss = 0.9834133583432897, disc_loss = 0.00030577862661155224
Trained batch 427 in epoch 2, gen_loss = 0.9834753891853528, disc_loss = 0.00030578815515063895
Trained batch 428 in epoch 2, gen_loss = 0.9830919083181795, disc_loss = 0.0003061388977580771
Trained batch 429 in epoch 2, gen_loss = 0.9828521948914195, disc_loss = 0.0003059704433706979
Trained batch 430 in epoch 2, gen_loss = 0.9826138935066985, disc_loss = 0.0003058445054657969
Trained batch 431 in epoch 2, gen_loss = 0.9825637783441279, disc_loss = 0.00030568858339932004
Trained batch 432 in epoch 2, gen_loss = 0.9826403050995314, disc_loss = 0.00030534310152379937
Trained batch 433 in epoch 2, gen_loss = 0.9825397659831333, disc_loss = 0.00030506162449271175
Trained batch 434 in epoch 2, gen_loss = 0.9822999722656163, disc_loss = 0.0003050048362554704
Trained batch 435 in epoch 2, gen_loss = 0.9825725991518126, disc_loss = 0.0003049427043585696
Trained batch 436 in epoch 2, gen_loss = 0.9824901816501225, disc_loss = 0.0003045903205713342
Trained batch 437 in epoch 2, gen_loss = 0.9824542806028775, disc_loss = 0.0003044420424208245
Trained batch 438 in epoch 2, gen_loss = 0.9829139516674033, disc_loss = 0.00030468706392809317
Trained batch 439 in epoch 2, gen_loss = 0.9826590971513228, disc_loss = 0.0003046491060641446
Trained batch 440 in epoch 2, gen_loss = 0.9825173305546075, disc_loss = 0.0003045755492952545
Trained batch 441 in epoch 2, gen_loss = 0.9823340211249045, disc_loss = 0.0003042938963710794
Trained batch 442 in epoch 2, gen_loss = 0.9819993495133875, disc_loss = 0.0003039659000998867
Trained batch 443 in epoch 2, gen_loss = 0.9821088003951151, disc_loss = 0.00030373291110253876
Trained batch 444 in epoch 2, gen_loss = 0.982370241706291, disc_loss = 0.0003035713412296655
Trained batch 445 in epoch 2, gen_loss = 0.9827631486103674, disc_loss = 0.0003039011563515842
Trained batch 446 in epoch 2, gen_loss = 0.9830764688101391, disc_loss = 0.0003037228917294667
Trained batch 447 in epoch 2, gen_loss = 0.98299835236477, disc_loss = 0.00030350248961700084
Trained batch 448 in epoch 2, gen_loss = 0.9830108762849412, disc_loss = 0.0003034336837451959
Trained batch 449 in epoch 2, gen_loss = 0.9828875988059573, disc_loss = 0.0003033841008436866
Trained batch 450 in epoch 2, gen_loss = 0.982908929663064, disc_loss = 0.00030326925588130513
Trained batch 451 in epoch 2, gen_loss = 0.9830156742735247, disc_loss = 0.00030311343981395065
Trained batch 452 in epoch 2, gen_loss = 0.9832132135005976, disc_loss = 0.0003028868788621485
Trained batch 453 in epoch 2, gen_loss = 0.9828416248250113, disc_loss = 0.00030315686773076973
Trained batch 454 in epoch 2, gen_loss = 0.9827587140785469, disc_loss = 0.00030312478816735424
Trained batch 455 in epoch 2, gen_loss = 0.9825465914450193, disc_loss = 0.0003028663614123504
Trained batch 456 in epoch 2, gen_loss = 0.9825568081774388, disc_loss = 0.00030263352666495477
Trained batch 457 in epoch 2, gen_loss = 0.9827445519022546, disc_loss = 0.00030231112562802186
Trained batch 458 in epoch 2, gen_loss = 0.982604639462656, disc_loss = 0.00030199730620934567
Trained batch 459 in epoch 2, gen_loss = 0.9824659810118054, disc_loss = 0.0003017383676310799
Trained batch 460 in epoch 2, gen_loss = 0.9823648137022254, disc_loss = 0.0003014678543851733
Trained batch 461 in epoch 2, gen_loss = 0.982197489573326, disc_loss = 0.00030109048100995724
Trained batch 462 in epoch 2, gen_loss = 0.9822150354251491, disc_loss = 0.00030086039853147504
Trained batch 463 in epoch 2, gen_loss = 0.9821244067159193, disc_loss = 0.000300551012169935
Trained batch 464 in epoch 2, gen_loss = 0.9820778778804246, disc_loss = 0.0003003109014287631
Trained batch 465 in epoch 2, gen_loss = 0.9822459426816441, disc_loss = 0.00030034499150718855
Trained batch 466 in epoch 2, gen_loss = 0.9822513983132242, disc_loss = 0.00030025163169589283
Trained batch 467 in epoch 2, gen_loss = 0.9819422939903716, disc_loss = 0.0002999832292368962
Trained batch 468 in epoch 2, gen_loss = 0.9818912680977697, disc_loss = 0.0002996962864884237
Trained batch 469 in epoch 2, gen_loss = 0.9816863917289896, disc_loss = 0.0002994775362473794
Trained batch 470 in epoch 2, gen_loss = 0.9815806228896868, disc_loss = 0.0002993518069093343
Trained batch 471 in epoch 2, gen_loss = 0.981533174923921, disc_loss = 0.00029922706405267164
Trained batch 472 in epoch 2, gen_loss = 0.9815843005765064, disc_loss = 0.00029936054470184914
Trained batch 473 in epoch 2, gen_loss = 0.9817343023507404, disc_loss = 0.0002992914913822445
Trained batch 474 in epoch 2, gen_loss = 0.9816719153052882, disc_loss = 0.0002991023624781519
Trained batch 475 in epoch 2, gen_loss = 0.9818212269734936, disc_loss = 0.00029877911339183297
Trained batch 476 in epoch 2, gen_loss = 0.9817420529119624, disc_loss = 0.0002985614873844724
Trained batch 477 in epoch 2, gen_loss = 0.9814967423303357, disc_loss = 0.0002983205008737462
Trained batch 478 in epoch 2, gen_loss = 0.981306445747925, disc_loss = 0.0002982492140267775
Trained batch 479 in epoch 2, gen_loss = 0.9814267177134752, disc_loss = 0.000298409745725318
Trained batch 480 in epoch 2, gen_loss = 0.9814215475952799, disc_loss = 0.00029834489484042656
Trained batch 481 in epoch 2, gen_loss = 0.98114497755573, disc_loss = 0.00029819758788390756
Trained batch 482 in epoch 2, gen_loss = 0.9810811636610801, disc_loss = 0.0002978960457417003
Trained batch 483 in epoch 2, gen_loss = 0.9808902230637133, disc_loss = 0.00029769028062655105
Trained batch 484 in epoch 2, gen_loss = 0.9811442571816985, disc_loss = 0.0002974354037618956
Trained batch 485 in epoch 2, gen_loss = 0.9808767317744439, disc_loss = 0.00029710193098534223
Trained batch 486 in epoch 2, gen_loss = 0.9806339504537641, disc_loss = 0.00029704832468082406
Trained batch 487 in epoch 2, gen_loss = 0.9803598223895323, disc_loss = 0.0002969575177049875
Trained batch 488 in epoch 2, gen_loss = 0.9803606773934238, disc_loss = 0.0002969040373265972
Trained batch 489 in epoch 2, gen_loss = 0.9803677942071642, disc_loss = 0.0002966092219065438
Trained batch 490 in epoch 2, gen_loss = 0.9803119525161634, disc_loss = 0.0002964601912222757
Trained batch 491 in epoch 2, gen_loss = 0.9801908750844196, disc_loss = 0.0002961875510870998
Trained batch 492 in epoch 2, gen_loss = 0.9802899916805554, disc_loss = 0.0002964933671264552
Trained batch 493 in epoch 2, gen_loss = 0.9802463644670572, disc_loss = 0.000297206104467934
Trained batch 494 in epoch 2, gen_loss = 0.9802484187212858, disc_loss = 0.00029725988387868673
Trained batch 495 in epoch 2, gen_loss = 0.980378293462338, disc_loss = 0.0002971812444581789
Trained batch 496 in epoch 2, gen_loss = 0.9804162035285827, disc_loss = 0.000297095795974587
Trained batch 497 in epoch 2, gen_loss = 0.9804920514664018, disc_loss = 0.00029702313377238606
Trained batch 498 in epoch 2, gen_loss = 0.9803644485607415, disc_loss = 0.0002967668220436738
Trained batch 499 in epoch 2, gen_loss = 0.9802060060501099, disc_loss = 0.00029677253143745475
Trained batch 500 in epoch 2, gen_loss = 0.9800893333619702, disc_loss = 0.0002965359054721925
Trained batch 501 in epoch 2, gen_loss = 0.9801943602552452, disc_loss = 0.0002963029793929772
Trained batch 502 in epoch 2, gen_loss = 0.9799792739316436, disc_loss = 0.0002960230133109254
Trained batch 503 in epoch 2, gen_loss = 0.9796334066324763, disc_loss = 0.000295712040165127
Trained batch 504 in epoch 2, gen_loss = 0.9797097042055414, disc_loss = 0.00029551784362699283
Trained batch 505 in epoch 2, gen_loss = 0.9798720393020645, disc_loss = 0.00029547643164916354
Trained batch 506 in epoch 2, gen_loss = 0.979852128663712, disc_loss = 0.00029514313269502076
Trained batch 507 in epoch 2, gen_loss = 0.9799344228712592, disc_loss = 0.0002950011650224099
Trained batch 508 in epoch 2, gen_loss = 0.9798015390023267, disc_loss = 0.00029474467863392797
Trained batch 509 in epoch 2, gen_loss = 0.979753984189501, disc_loss = 0.00029443667616065153
Trained batch 510 in epoch 2, gen_loss = 0.9795292506245951, disc_loss = 0.0002942512607167305
Trained batch 511 in epoch 2, gen_loss = 0.9796454613097012, disc_loss = 0.0002942764018598609
Trained batch 512 in epoch 2, gen_loss = 0.9793601063956991, disc_loss = 0.0002943497585935144
Trained batch 513 in epoch 2, gen_loss = 0.9792168597303011, disc_loss = 0.00029432960364202956
Trained batch 514 in epoch 2, gen_loss = 0.978837622832326, disc_loss = 0.00029435272156758216
Trained batch 515 in epoch 2, gen_loss = 0.9789461797290995, disc_loss = 0.00029417749437008975
Trained batch 516 in epoch 2, gen_loss = 0.978897333260431, disc_loss = 0.0002939655617549583
Trained batch 517 in epoch 2, gen_loss = 0.9788848526459403, disc_loss = 0.00029365654451467824
Trained batch 518 in epoch 2, gen_loss = 0.9789541545171498, disc_loss = 0.0002934413582202306
Trained batch 519 in epoch 2, gen_loss = 0.9789760641180552, disc_loss = 0.0002933401716570818
Trained batch 520 in epoch 2, gen_loss = 0.9787903826204691, disc_loss = 0.00029305347970788744
Trained batch 521 in epoch 2, gen_loss = 0.9787056990738573, disc_loss = 0.00029370363179943973
Trained batch 522 in epoch 2, gen_loss = 0.9787694456244518, disc_loss = 0.0002940016284266248
Trained batch 523 in epoch 2, gen_loss = 0.9787515578151659, disc_loss = 0.00029389134001472027
Trained batch 524 in epoch 2, gen_loss = 0.9788672909282503, disc_loss = 0.0002940998235273929
Trained batch 525 in epoch 2, gen_loss = 0.9787779562600212, disc_loss = 0.00029480950632433585
Trained batch 526 in epoch 2, gen_loss = 0.9787464848731908, disc_loss = 0.00029494412852171985
Trained batch 527 in epoch 2, gen_loss = 0.9784268785380956, disc_loss = 0.0002951422967739883
Trained batch 528 in epoch 2, gen_loss = 0.9784861348977837, disc_loss = 0.0002954691836200232
Trained batch 529 in epoch 2, gen_loss = 0.9784025426180858, disc_loss = 0.0002954205246049173
Trained batch 530 in epoch 2, gen_loss = 0.9781900942886841, disc_loss = 0.0002952707522685101
Trained batch 531 in epoch 2, gen_loss = 0.9780114203467405, disc_loss = 0.0002950604126604424
Trained batch 532 in epoch 2, gen_loss = 0.9779720051427272, disc_loss = 0.0002949638656400822
Trained batch 533 in epoch 2, gen_loss = 0.9780457872576481, disc_loss = 0.00029496610171618536
Trained batch 534 in epoch 2, gen_loss = 0.9779588073213524, disc_loss = 0.00029641134668768285
Trained batch 535 in epoch 2, gen_loss = 0.9777248966604916, disc_loss = 0.00029943245350133016
Trained batch 536 in epoch 2, gen_loss = 0.9775878828109088, disc_loss = 0.0003002403064212958
Trained batch 537 in epoch 2, gen_loss = 0.977583921753341, disc_loss = 0.0003011168745003613
Trained batch 538 in epoch 2, gen_loss = 0.9776829231205588, disc_loss = 0.0003013232447930952
Trained batch 539 in epoch 2, gen_loss = 0.9776149087482029, disc_loss = 0.0003014329754040335
Trained batch 540 in epoch 2, gen_loss = 0.9776699318242381, disc_loss = 0.0003013089028068314
Trained batch 541 in epoch 2, gen_loss = 0.977612127347186, disc_loss = 0.000301338889360311
Trained batch 542 in epoch 2, gen_loss = 0.9774817198679592, disc_loss = 0.0003013498317896222
Trained batch 543 in epoch 2, gen_loss = 0.977465417016955, disc_loss = 0.0003012356765686812
Trained batch 544 in epoch 2, gen_loss = 0.977535190057317, disc_loss = 0.00030116903205261214
Trained batch 545 in epoch 2, gen_loss = 0.9776702706630414, disc_loss = 0.0003009023866680154
Trained batch 546 in epoch 2, gen_loss = 0.9775116532986518, disc_loss = 0.00030078332666035274
Trained batch 547 in epoch 2, gen_loss = 0.9776937733166409, disc_loss = 0.00030084694325702984
Trained batch 548 in epoch 2, gen_loss = 0.977693448844069, disc_loss = 0.0003008490662855556
Trained batch 549 in epoch 2, gen_loss = 0.9777676769820126, disc_loss = 0.0003008392941079695
Trained batch 550 in epoch 2, gen_loss = 0.9775059295652566, disc_loss = 0.00030077972134343685
Trained batch 551 in epoch 2, gen_loss = 0.9773238213813823, disc_loss = 0.0003008068859449797
Trained batch 552 in epoch 2, gen_loss = 0.9771634459926681, disc_loss = 0.0003037122527165187
Trained batch 553 in epoch 2, gen_loss = 0.9769714993259967, disc_loss = 0.00030502580243477173
Trained batch 554 in epoch 2, gen_loss = 0.9768274888262019, disc_loss = 0.0003054572695652275
Trained batch 555 in epoch 2, gen_loss = 0.9770433074064392, disc_loss = 0.0003054889318702421
Trained batch 556 in epoch 2, gen_loss = 0.9770369187291692, disc_loss = 0.00030533683662264336
Trained batch 557 in epoch 2, gen_loss = 0.9770715439618702, disc_loss = 0.00030516732726529853
Trained batch 558 in epoch 2, gen_loss = 0.9770311801719325, disc_loss = 0.00030496111616041605
Trained batch 559 in epoch 2, gen_loss = 0.9767869266016143, disc_loss = 0.00030476104633895114
Trained batch 560 in epoch 2, gen_loss = 0.9765776152491782, disc_loss = 0.0003047527227048146
Trained batch 561 in epoch 2, gen_loss = 0.9764608935953459, disc_loss = 0.0003045449051556502
Trained batch 562 in epoch 2, gen_loss = 0.976788977958381, disc_loss = 0.00030502452246566035
Trained batch 563 in epoch 2, gen_loss = 0.976684108059457, disc_loss = 0.0003050514942450789
Trained batch 564 in epoch 2, gen_loss = 0.9765700457370387, disc_loss = 0.0003051625949740657
Trained batch 565 in epoch 2, gen_loss = 0.9764596570296338, disc_loss = 0.00030504952027201617
Trained batch 566 in epoch 2, gen_loss = 0.9763263532303839, disc_loss = 0.00030513010802370785
Trained batch 567 in epoch 2, gen_loss = 0.9760751618256032, disc_loss = 0.0003053635890109048
Trained batch 568 in epoch 2, gen_loss = 0.9762197922528942, disc_loss = 0.0003052521671685317
Trained batch 569 in epoch 2, gen_loss = 0.976116286662587, disc_loss = 0.0003053079884889405
Trained batch 570 in epoch 2, gen_loss = 0.9761372907984278, disc_loss = 0.00030522337123721466
Trained batch 571 in epoch 2, gen_loss = 0.9759777333144541, disc_loss = 0.0003049447656016051
Trained batch 572 in epoch 2, gen_loss = 0.9757736608204001, disc_loss = 0.00030468297358069986
Trained batch 573 in epoch 2, gen_loss = 0.975556024483272, disc_loss = 0.00030446441673031985
Trained batch 574 in epoch 2, gen_loss = 0.9755580632582955, disc_loss = 0.00030448226118966453
Trained batch 575 in epoch 2, gen_loss = 0.9753878605034616, disc_loss = 0.00030423747135601944
Trained batch 576 in epoch 2, gen_loss = 0.9754545738213604, disc_loss = 0.0003039164066791254
Trained batch 577 in epoch 2, gen_loss = 0.9756341962253346, disc_loss = 0.00030389544264527015
Trained batch 578 in epoch 2, gen_loss = 0.9758194827045183, disc_loss = 0.00030373377748202075
Trained batch 579 in epoch 2, gen_loss = 0.9757052946707298, disc_loss = 0.0003036177553063869
Trained batch 580 in epoch 2, gen_loss = 0.9756278580314321, disc_loss = 0.00030352975185335375
Trained batch 581 in epoch 2, gen_loss = 0.9756137810621884, disc_loss = 0.0003033425475217088
Trained batch 582 in epoch 2, gen_loss = 0.9752738871459895, disc_loss = 0.00030308326680930474
Trained batch 583 in epoch 2, gen_loss = 0.9753135961212523, disc_loss = 0.00030285168121399817
Trained batch 584 in epoch 2, gen_loss = 0.9751035716798571, disc_loss = 0.0003027691196403506
Trained batch 585 in epoch 2, gen_loss = 0.9750633484877824, disc_loss = 0.0003025340104182394
Trained batch 586 in epoch 2, gen_loss = 0.9752746626506266, disc_loss = 0.0003024405063335424
Trained batch 587 in epoch 2, gen_loss = 0.9751069569060592, disc_loss = 0.0003036115650459015
Trained batch 588 in epoch 2, gen_loss = 0.975151906697576, disc_loss = 0.00030729899417920474
Trained batch 589 in epoch 2, gen_loss = 0.9750732421875, disc_loss = 0.00030806642415404507
Trained batch 590 in epoch 2, gen_loss = 0.9752530857996287, disc_loss = 0.0003085927210938085
Trained batch 591 in epoch 2, gen_loss = 0.9751500672585255, disc_loss = 0.0003092841338543253
Trained batch 592 in epoch 2, gen_loss = 0.9750683604163223, disc_loss = 0.00031034346401155886
Trained batch 593 in epoch 2, gen_loss = 0.975172659664443, disc_loss = 0.0003105474702887682
Trained batch 594 in epoch 2, gen_loss = 0.975289508575151, disc_loss = 0.00031068201212040267
Trained batch 595 in epoch 2, gen_loss = 0.9754028403318968, disc_loss = 0.0003107902416650787
Trained batch 596 in epoch 2, gen_loss = 0.9754123298367064, disc_loss = 0.0003107974650022391
Trained batch 597 in epoch 2, gen_loss = 0.9753726365972921, disc_loss = 0.00031103471331617616
Trained batch 598 in epoch 2, gen_loss = 0.9751604606392785, disc_loss = 0.0003112966065700842
Trained batch 599 in epoch 2, gen_loss = 0.975065736869971, disc_loss = 0.0003132344347735246
Trained batch 600 in epoch 2, gen_loss = 0.9750320900498135, disc_loss = 0.0003140544823522737
Trained batch 601 in epoch 2, gen_loss = 0.9749655845355354, disc_loss = 0.00031493823622211046
Trained batch 602 in epoch 2, gen_loss = 0.9750257300500252, disc_loss = 0.0003156860301674191
Trained batch 603 in epoch 2, gen_loss = 0.974978563603976, disc_loss = 0.0003167086924443219
Trained batch 604 in epoch 2, gen_loss = 0.9750718784726355, disc_loss = 0.00031767746073786506
Trained batch 605 in epoch 2, gen_loss = 0.9750994753719556, disc_loss = 0.00031863886522199875
Trained batch 606 in epoch 2, gen_loss = 0.9750848638363293, disc_loss = 0.000319088537524465
Trained batch 607 in epoch 2, gen_loss = 0.9748847989463493, disc_loss = 0.0003194961661249277
Trained batch 608 in epoch 2, gen_loss = 0.9749592340051247, disc_loss = 0.00031997791104544757
Trained batch 609 in epoch 2, gen_loss = 0.9751633062714437, disc_loss = 0.0003206653258053311
Trained batch 610 in epoch 2, gen_loss = 0.9750384607408714, disc_loss = 0.0003218803290504834
Trained batch 611 in epoch 2, gen_loss = 0.9751750513229495, disc_loss = 0.0003265010816344894
Trained batch 612 in epoch 2, gen_loss = 0.9754329359745318, disc_loss = 0.0003288749298331484
Trained batch 613 in epoch 2, gen_loss = 0.975675565023764, disc_loss = 0.0003311137581761344
Trained batch 614 in epoch 2, gen_loss = 0.9758903319273537, disc_loss = 0.00033270145162591724
Trained batch 615 in epoch 2, gen_loss = 0.9763129939893623, disc_loss = 0.0003329110255766533
Trained batch 616 in epoch 2, gen_loss = 0.9767287160048029, disc_loss = 0.0003336220299028844
Trained batch 617 in epoch 2, gen_loss = 0.9769269924333566, disc_loss = 0.00033381227374681147
Trained batch 618 in epoch 2, gen_loss = 0.9774071509695592, disc_loss = 0.000334039898735948
Trained batch 619 in epoch 2, gen_loss = 0.9776231411964663, disc_loss = 0.00033433516669432604
Trained batch 620 in epoch 2, gen_loss = 0.977990769341756, disc_loss = 0.0003344551871955131
Trained batch 621 in epoch 2, gen_loss = 0.9783078780894877, disc_loss = 0.0003348694632497655
Trained batch 622 in epoch 2, gen_loss = 0.9786032430624311, disc_loss = 0.00033486778535812877
Trained batch 623 in epoch 2, gen_loss = 0.9786600468632503, disc_loss = 0.0003349424448690395
Trained batch 624 in epoch 2, gen_loss = 0.978796371269226, disc_loss = 0.0003349357834551483
Trained batch 625 in epoch 2, gen_loss = 0.9790136168559138, disc_loss = 0.00033521748594411563
Trained batch 626 in epoch 2, gen_loss = 0.9791152165457012, disc_loss = 0.00033515324018467844
Trained batch 627 in epoch 2, gen_loss = 0.9792274954212699, disc_loss = 0.00033503958529416044
Trained batch 628 in epoch 2, gen_loss = 0.9793438088912843, disc_loss = 0.00033502844817468537
Trained batch 629 in epoch 2, gen_loss = 0.979414911686428, disc_loss = 0.0003349270002679929
Trained batch 630 in epoch 2, gen_loss = 0.9796047516745735, disc_loss = 0.00033474370090290167
Trained batch 631 in epoch 2, gen_loss = 0.9797340782382821, disc_loss = 0.00033497319377084184
Trained batch 632 in epoch 2, gen_loss = 0.9799647052517811, disc_loss = 0.00033503286870167773
Trained batch 633 in epoch 2, gen_loss = 0.9799713420943131, disc_loss = 0.00033503215906797095
Trained batch 634 in epoch 2, gen_loss = 0.9800527028211459, disc_loss = 0.0003351058503182048
Trained batch 635 in epoch 2, gen_loss = 0.980270541126623, disc_loss = 0.0003349153114370738
Trained batch 636 in epoch 2, gen_loss = 0.9803157681760084, disc_loss = 0.00033465840722075293
Trained batch 637 in epoch 2, gen_loss = 0.9807112088024056, disc_loss = 0.00033452200120242696
Trained batch 638 in epoch 2, gen_loss = 0.9808221146907419, disc_loss = 0.0003344889515739427
Trained batch 639 in epoch 2, gen_loss = 0.980929858610034, disc_loss = 0.0003343804258520322
Trained batch 640 in epoch 2, gen_loss = 0.9810224059219479, disc_loss = 0.00033412301695782856
Trained batch 641 in epoch 2, gen_loss = 0.9810294963860438, disc_loss = 0.0003341497765044171
Trained batch 642 in epoch 2, gen_loss = 0.981278770262865, disc_loss = 0.0003341137713593001
Trained batch 643 in epoch 2, gen_loss = 0.9814832006922419, disc_loss = 0.00033399359044609505
Trained batch 644 in epoch 2, gen_loss = 0.9816133950107782, disc_loss = 0.00033391831194992764
Trained batch 645 in epoch 2, gen_loss = 0.9818420482124707, disc_loss = 0.0003337703283503868
Trained batch 646 in epoch 2, gen_loss = 0.9819277611545285, disc_loss = 0.0003336330537619127
Trained batch 647 in epoch 2, gen_loss = 0.981984206923732, disc_loss = 0.0003334716857577326
Trained batch 648 in epoch 2, gen_loss = 0.9820181495052273, disc_loss = 0.000333469166690003
Trained batch 649 in epoch 2, gen_loss = 0.9822222326352046, disc_loss = 0.00033340437532527946
Trained batch 650 in epoch 2, gen_loss = 0.9824086482623755, disc_loss = 0.00033324809244511284
Trained batch 651 in epoch 2, gen_loss = 0.9825105266702687, disc_loss = 0.00033307320646694546
Trained batch 652 in epoch 2, gen_loss = 0.9824859514535843, disc_loss = 0.0003337119156434122
Trained batch 653 in epoch 2, gen_loss = 0.9826199369510744, disc_loss = 0.0003339487641237374
Trained batch 654 in epoch 2, gen_loss = 0.9826516399856742, disc_loss = 0.00033374665143281107
Trained batch 655 in epoch 2, gen_loss = 0.982883225581268, disc_loss = 0.000333557243299388
Trained batch 656 in epoch 2, gen_loss = 0.982998688743539, disc_loss = 0.0003332601910178114
Trained batch 657 in epoch 2, gen_loss = 0.9831071212480134, disc_loss = 0.0003330384766011383
Trained batch 658 in epoch 2, gen_loss = 0.9830877729359454, disc_loss = 0.0003328195859228327
Trained batch 659 in epoch 2, gen_loss = 0.9832162776679704, disc_loss = 0.00033275415601868494
Trained batch 660 in epoch 2, gen_loss = 0.9833304006465444, disc_loss = 0.00033267739227759466
Trained batch 661 in epoch 2, gen_loss = 0.9834019087052417, disc_loss = 0.00033251357248022706
Trained batch 662 in epoch 2, gen_loss = 0.9836531427111561, disc_loss = 0.00033246402734160834
Trained batch 663 in epoch 2, gen_loss = 0.9836434919431986, disc_loss = 0.0003324295586321842
Trained batch 664 in epoch 2, gen_loss = 0.983708419656395, disc_loss = 0.00033231112632035675
Trained batch 665 in epoch 2, gen_loss = 0.98359504118338, disc_loss = 0.00033218556403356544
Trained batch 666 in epoch 2, gen_loss = 0.9834894991886133, disc_loss = 0.0003320957123899883
Trained batch 667 in epoch 2, gen_loss = 0.9835087862200366, disc_loss = 0.00033205015253095084
Trained batch 668 in epoch 2, gen_loss = 0.9835088146107079, disc_loss = 0.00033185842046054754
Trained batch 669 in epoch 2, gen_loss = 0.9835291072503844, disc_loss = 0.00033173332079452697
Trained batch 670 in epoch 2, gen_loss = 0.9835667531998431, disc_loss = 0.0003316007585890366
Trained batch 671 in epoch 2, gen_loss = 0.983731634914875, disc_loss = 0.0003313614579166737
Trained batch 672 in epoch 2, gen_loss = 0.9837061954997093, disc_loss = 0.00033126120538333844
Trained batch 673 in epoch 2, gen_loss = 0.983689817370576, disc_loss = 0.0003311607138143551
Trained batch 674 in epoch 2, gen_loss = 0.9835325098037719, disc_loss = 0.0003310424202182158
Trained batch 675 in epoch 2, gen_loss = 0.9834334966699048, disc_loss = 0.0003313300079559651
Trained batch 676 in epoch 2, gen_loss = 0.9833686644076597, disc_loss = 0.0003312599327939011
Trained batch 677 in epoch 2, gen_loss = 0.9835646560410131, disc_loss = 0.0003312228554315456
Trained batch 678 in epoch 2, gen_loss = 0.9836448353765991, disc_loss = 0.0003311671745894471
Trained batch 679 in epoch 2, gen_loss = 0.9837229185244616, disc_loss = 0.0003311374423527227
Trained batch 680 in epoch 2, gen_loss = 0.9838991004114809, disc_loss = 0.00033113216717092244
Trained batch 681 in epoch 2, gen_loss = 0.9840311196542555, disc_loss = 0.0003311848750345128
Trained batch 682 in epoch 2, gen_loss = 0.9840402556896908, disc_loss = 0.00033112870542333214
Trained batch 683 in epoch 2, gen_loss = 0.984167513007309, disc_loss = 0.00033105567728842567
Trained batch 684 in epoch 2, gen_loss = 0.9843574418638744, disc_loss = 0.0003308467777916672
Trained batch 685 in epoch 2, gen_loss = 0.9843843340352395, disc_loss = 0.0003306982456833741
Trained batch 686 in epoch 2, gen_loss = 0.9842482429577968, disc_loss = 0.0003305586847163848
Trained batch 687 in epoch 2, gen_loss = 0.9840834787072137, disc_loss = 0.00033062794117604216
Trained batch 688 in epoch 2, gen_loss = 0.9841492689918884, disc_loss = 0.00033058688460280833
Trained batch 689 in epoch 2, gen_loss = 0.9843880065973254, disc_loss = 0.00033062720872492163
Trained batch 690 in epoch 2, gen_loss = 0.9845493774855706, disc_loss = 0.0003306328532090222
Trained batch 691 in epoch 2, gen_loss = 0.9844861829039678, disc_loss = 0.0003304437411521061
Trained batch 692 in epoch 2, gen_loss = 0.9845706768882223, disc_loss = 0.0003309801925937302
Trained batch 693 in epoch 2, gen_loss = 0.9845447163245177, disc_loss = 0.0003317433622597263
Trained batch 694 in epoch 2, gen_loss = 0.9846244239978653, disc_loss = 0.0003316466265656188
Trained batch 695 in epoch 2, gen_loss = 0.9845975167278586, disc_loss = 0.00033156715381800885
Trained batch 696 in epoch 2, gen_loss = 0.9846355349808888, disc_loss = 0.0003315662222174818
Trained batch 697 in epoch 2, gen_loss = 0.9846812755638003, disc_loss = 0.000331329347865648
Trained batch 698 in epoch 2, gen_loss = 0.9845089959313771, disc_loss = 0.0003311790906719581
Trained batch 699 in epoch 2, gen_loss = 0.9845465216466359, disc_loss = 0.0003310639934248424
Trained batch 700 in epoch 2, gen_loss = 0.9844797228100296, disc_loss = 0.0003308317369197531
Trained batch 701 in epoch 2, gen_loss = 0.9844229354647829, disc_loss = 0.00033065810210225396
Trained batch 702 in epoch 2, gen_loss = 0.9844336941265958, disc_loss = 0.0003305049080306937
Trained batch 703 in epoch 2, gen_loss = 0.9843352659690109, disc_loss = 0.00033039138737546057
Trained batch 704 in epoch 2, gen_loss = 0.9844503176973222, disc_loss = 0.0003304430785182705
Trained batch 705 in epoch 2, gen_loss = 0.9843536678691086, disc_loss = 0.0003302724596115275
Trained batch 706 in epoch 2, gen_loss = 0.9844206955173228, disc_loss = 0.0003302492899861374
Trained batch 707 in epoch 2, gen_loss = 0.9842930224824087, disc_loss = 0.00033014666054040684
Trained batch 708 in epoch 2, gen_loss = 0.984224445644992, disc_loss = 0.00032998150521518243
Trained batch 709 in epoch 2, gen_loss = 0.9843357160897322, disc_loss = 0.0003298353990187383
Trained batch 710 in epoch 2, gen_loss = 0.9843005352717747, disc_loss = 0.00032977152646649575
Trained batch 711 in epoch 2, gen_loss = 0.9844043444046814, disc_loss = 0.00032972435478308745
Trained batch 712 in epoch 2, gen_loss = 0.9843290181514425, disc_loss = 0.00032965181270750766
Trained batch 713 in epoch 2, gen_loss = 0.9844081956131452, disc_loss = 0.0003295707753319776
Trained batch 714 in epoch 2, gen_loss = 0.9844995985497962, disc_loss = 0.00032946167184427457
Trained batch 715 in epoch 2, gen_loss = 0.9843876373501463, disc_loss = 0.00032958506672612557
Trained batch 716 in epoch 2, gen_loss = 0.9843347849872488, disc_loss = 0.00032959903690316474
Trained batch 717 in epoch 2, gen_loss = 0.984293844125397, disc_loss = 0.0003294396690427959
Trained batch 718 in epoch 2, gen_loss = 0.9843297289044536, disc_loss = 0.00032941330684836624
Trained batch 719 in epoch 2, gen_loss = 0.984267759985394, disc_loss = 0.00032935246201506947
Trained batch 720 in epoch 2, gen_loss = 0.9841917035649124, disc_loss = 0.0003292914405092145
Trained batch 721 in epoch 2, gen_loss = 0.9842422875340956, disc_loss = 0.00032933929943079076
Trained batch 722 in epoch 2, gen_loss = 0.9841725753715589, disc_loss = 0.0003292945884131114
Trained batch 723 in epoch 2, gen_loss = 0.9841230901894649, disc_loss = 0.00032916018290806033
Trained batch 724 in epoch 2, gen_loss = 0.9840751707142797, disc_loss = 0.00032895015173286585
Trained batch 725 in epoch 2, gen_loss = 0.9840728405750159, disc_loss = 0.0003290914830544222
Trained batch 726 in epoch 2, gen_loss = 0.9840204869864567, disc_loss = 0.0003288640841080114
Trained batch 727 in epoch 2, gen_loss = 0.9839354945080621, disc_loss = 0.0003288787036701131
Trained batch 728 in epoch 2, gen_loss = 0.9839659039702762, disc_loss = 0.0003288258589304018
Trained batch 729 in epoch 2, gen_loss = 0.9839432840477931, disc_loss = 0.0003286584461831858
Trained batch 730 in epoch 2, gen_loss = 0.9839454359297224, disc_loss = 0.000328562785825143
Trained batch 731 in epoch 2, gen_loss = 0.9840182183218784, disc_loss = 0.00032842991646755195
Trained batch 732 in epoch 2, gen_loss = 0.9840828334813554, disc_loss = 0.0003284977332761608
Trained batch 733 in epoch 2, gen_loss = 0.9840129163999324, disc_loss = 0.00032883347283711923
Trained batch 734 in epoch 2, gen_loss = 0.9842426486566764, disc_loss = 0.0003288880040271993
Trained batch 735 in epoch 2, gen_loss = 0.9842907932141552, disc_loss = 0.00032881937245885797
Trained batch 736 in epoch 2, gen_loss = 0.9842493739509841, disc_loss = 0.0003286644014285996
Trained batch 737 in epoch 2, gen_loss = 0.9840396174247349, disc_loss = 0.00032864847197765256
Trained batch 738 in epoch 2, gen_loss = 0.9839234181928054, disc_loss = 0.00032921102816675044
Trained batch 739 in epoch 2, gen_loss = 0.9838434812990395, disc_loss = 0.00032951922228282974
Trained batch 740 in epoch 2, gen_loss = 0.9838440143145047, disc_loss = 0.0003296634849326185
Trained batch 741 in epoch 2, gen_loss = 0.9838434347727228, disc_loss = 0.0003297271159043877
Trained batch 742 in epoch 2, gen_loss = 0.983639589629937, disc_loss = 0.0003310283105823551
Trained batch 743 in epoch 2, gen_loss = 0.9833913464700023, disc_loss = 0.0003326409241708461
Trained batch 744 in epoch 2, gen_loss = 0.9835441723765943, disc_loss = 0.000335574915965444
Trained batch 745 in epoch 2, gen_loss = 0.9837479827870632, disc_loss = 0.00033640383517877736
Trained batch 746 in epoch 2, gen_loss = 0.9835546809825871, disc_loss = 0.0003376932539419212
Trained batch 747 in epoch 2, gen_loss = 0.9836025660369485, disc_loss = 0.0003380692482008947
Trained batch 748 in epoch 2, gen_loss = 0.9837285270678185, disc_loss = 0.0003380658713048784
Trained batch 749 in epoch 2, gen_loss = 0.983826204776764, disc_loss = 0.0003381408550000439
Trained batch 750 in epoch 2, gen_loss = 0.9837046851330845, disc_loss = 0.0003383508478055712
Trained batch 751 in epoch 2, gen_loss = 0.9836062462405956, disc_loss = 0.000338317630674747
Trained batch 752 in epoch 2, gen_loss = 0.98361304746681, disc_loss = 0.0003385608296536508
Trained batch 753 in epoch 2, gen_loss = 0.9834117492567007, disc_loss = 0.0003388480034200425
Trained batch 754 in epoch 2, gen_loss = 0.9833589620148109, disc_loss = 0.0003393424981326136
Trained batch 755 in epoch 2, gen_loss = 0.9832157431929199, disc_loss = 0.00033992261495090106
Trained batch 756 in epoch 2, gen_loss = 0.9831736312202293, disc_loss = 0.0003401924425947063
Trained batch 757 in epoch 2, gen_loss = 0.9832735270025862, disc_loss = 0.00034022127345878885
Trained batch 758 in epoch 2, gen_loss = 0.9833574251852174, disc_loss = 0.0003401629462020965
Trained batch 759 in epoch 2, gen_loss = 0.983403201558088, disc_loss = 0.00034021571451663287
Trained batch 760 in epoch 2, gen_loss = 0.9832489276684223, disc_loss = 0.00034028458186889096
Trained batch 761 in epoch 2, gen_loss = 0.9830934697092362, disc_loss = 0.00034040415189302283
Trained batch 762 in epoch 2, gen_loss = 0.9832160737692607, disc_loss = 0.0003422109882693938
Trained batch 763 in epoch 2, gen_loss = 0.983217616199823, disc_loss = 0.00034318790572673494
Trained batch 764 in epoch 2, gen_loss = 0.9832079555474076, disc_loss = 0.00034481118946013594
Trained batch 765 in epoch 2, gen_loss = 0.9832817431218319, disc_loss = 0.000345123679709667
Trained batch 766 in epoch 2, gen_loss = 0.9832823529858944, disc_loss = 0.0003451506707105771
Trained batch 767 in epoch 2, gen_loss = 0.9833292686380446, disc_loss = 0.00034523415930228413
Trained batch 768 in epoch 2, gen_loss = 0.9832935268144148, disc_loss = 0.0003451754033468029
Trained batch 769 in epoch 2, gen_loss = 0.9832204398396728, disc_loss = 0.0003450770703274394
Trained batch 770 in epoch 2, gen_loss = 0.9832239957325808, disc_loss = 0.00034494088720632947
Trained batch 771 in epoch 2, gen_loss = 0.9830705640847202, disc_loss = 0.00034481461071367064
Trained batch 772 in epoch 2, gen_loss = 0.9830936432501631, disc_loss = 0.00034491530500435516
Trained batch 773 in epoch 2, gen_loss = 0.9831030822385497, disc_loss = 0.00034528900887991615
Trained batch 774 in epoch 2, gen_loss = 0.9829632741405118, disc_loss = 0.00034549160511232913
Trained batch 775 in epoch 2, gen_loss = 0.9829434176388475, disc_loss = 0.00034570336438920684
Trained batch 776 in epoch 2, gen_loss = 0.9829719519216275, disc_loss = 0.0003458821315344116
Trained batch 777 in epoch 2, gen_loss = 0.9828645403097098, disc_loss = 0.0003462568290784816
Trained batch 778 in epoch 2, gen_loss = 0.9827957036253423, disc_loss = 0.00034629948662423
Trained batch 779 in epoch 2, gen_loss = 0.9827809235988519, disc_loss = 0.00034650077282910786
Trained batch 780 in epoch 2, gen_loss = 0.9826210793703986, disc_loss = 0.00034734766165518395
Trained batch 781 in epoch 2, gen_loss = 0.9826058361231519, disc_loss = 0.0003476770791743794
Trained batch 782 in epoch 2, gen_loss = 0.9825820557459104, disc_loss = 0.00034785564331097545
Trained batch 783 in epoch 2, gen_loss = 0.9827121780539045, disc_loss = 0.0003482470547540436
Trained batch 784 in epoch 2, gen_loss = 0.9826803673604492, disc_loss = 0.00034861748958018364
Trained batch 785 in epoch 2, gen_loss = 0.9828408308914903, disc_loss = 0.00034874257755717003
Trained batch 786 in epoch 2, gen_loss = 0.9829265067053266, disc_loss = 0.0003491096006111115
Trained batch 787 in epoch 2, gen_loss = 0.9828392524404574, disc_loss = 0.0003493208452783818
Trained batch 788 in epoch 2, gen_loss = 0.9827455091839055, disc_loss = 0.0003511628353081795
Trained batch 789 in epoch 2, gen_loss = 0.9827255998985677, disc_loss = 0.00035173907394143696
Trained batch 790 in epoch 2, gen_loss = 0.9827872100280298, disc_loss = 0.0003527749515098535
Trained batch 791 in epoch 2, gen_loss = 0.98279116099531, disc_loss = 0.0003530506802795718
Trained batch 792 in epoch 2, gen_loss = 0.9828028041507678, disc_loss = 0.0003532651447911816
Trained batch 793 in epoch 2, gen_loss = 0.9828804256934063, disc_loss = 0.0003531217800206399
Trained batch 794 in epoch 2, gen_loss = 0.982709198103011, disc_loss = 0.0003532103024519769
Trained batch 795 in epoch 2, gen_loss = 0.9824814717074735, disc_loss = 0.00035444006983257465
Trained batch 796 in epoch 2, gen_loss = 0.982470508949969, disc_loss = 0.00035453930954651035
Trained batch 797 in epoch 2, gen_loss = 0.9823229143344668, disc_loss = 0.0003545773666737751
Trained batch 798 in epoch 2, gen_loss = 0.9824327540039569, disc_loss = 0.00035550748497085674
Trained batch 799 in epoch 2, gen_loss = 0.982399255335331, disc_loss = 0.00035574018522311235
Trained batch 800 in epoch 2, gen_loss = 0.9823928709036105, disc_loss = 0.00035619776815579466
Trained batch 801 in epoch 2, gen_loss = 0.9822973319122619, disc_loss = 0.0003563701504295079
Trained batch 802 in epoch 2, gen_loss = 0.9822335779147309, disc_loss = 0.00035635238915077583
Trained batch 803 in epoch 2, gen_loss = 0.9822556741943407, disc_loss = 0.0003564909756961464
Trained batch 804 in epoch 2, gen_loss = 0.9823125613402136, disc_loss = 0.0003565836821824474
Trained batch 805 in epoch 2, gen_loss = 0.982062664576263, disc_loss = 0.0003591073074573928
Trained batch 806 in epoch 2, gen_loss = 0.9820492300106838, disc_loss = 0.00036014480999719395
Trained batch 807 in epoch 2, gen_loss = 0.9820012869958831, disc_loss = 0.0003613673954424656
Trained batch 808 in epoch 2, gen_loss = 0.982085113693374, disc_loss = 0.0003615782629052115
Trained batch 809 in epoch 2, gen_loss = 0.9820771775863789, disc_loss = 0.00036172272424058366
Trained batch 810 in epoch 2, gen_loss = 0.9821061225913456, disc_loss = 0.00036325621080318405
Trained batch 811 in epoch 2, gen_loss = 0.9820792317537251, disc_loss = 0.00036315945288357943
Trained batch 812 in epoch 2, gen_loss = 0.9820918024392732, disc_loss = 0.0003637005538129228
Trained batch 813 in epoch 2, gen_loss = 0.981950683002097, disc_loss = 0.0003660736724300109
Trained batch 814 in epoch 2, gen_loss = 0.9820123394574124, disc_loss = 0.00036637341704339566
Trained batch 815 in epoch 2, gen_loss = 0.981877884005799, disc_loss = 0.0003782760043524082
Trained batch 816 in epoch 2, gen_loss = 0.982347517585521, disc_loss = 0.0003927960759100038
Trained batch 817 in epoch 2, gen_loss = 0.9827485233180971, disc_loss = 0.00039601587770252844
Trained batch 818 in epoch 2, gen_loss = 0.982789136842348, disc_loss = 0.00039911141761371656
Trained batch 819 in epoch 2, gen_loss = 0.9827188858171788, disc_loss = 0.00042347382734921513
Trained batch 820 in epoch 2, gen_loss = 0.9826885641855386, disc_loss = 0.0004459452916667814
Trained batch 821 in epoch 2, gen_loss = 0.982630191348185, disc_loss = 0.00045906236498484073
Trained batch 822 in epoch 2, gen_loss = 0.9821532692393584, disc_loss = 0.0008008395415945216
Trained batch 823 in epoch 2, gen_loss = 0.9825869151978817, disc_loss = 0.0012968051353895028
Trained batch 824 in epoch 2, gen_loss = 0.9825742150797988, disc_loss = 0.0013417380992111496
Trained batch 825 in epoch 2, gen_loss = 0.9822033044789663, disc_loss = 0.001419586960496054
Trained batch 826 in epoch 2, gen_loss = 0.9825738654027106, disc_loss = 0.0015499137619359952
Trained batch 827 in epoch 2, gen_loss = 0.9825791384718844, disc_loss = 0.0015897143864230892
Trained batch 828 in epoch 2, gen_loss = 0.9829612845966123, disc_loss = 0.0016535506522312728
Trained batch 829 in epoch 2, gen_loss = 0.9833622759365174, disc_loss = 0.0017430609776932992
Trained batch 830 in epoch 2, gen_loss = 0.9836632036990638, disc_loss = 0.0018100437622253415
Trained batch 831 in epoch 2, gen_loss = 0.9835850357866058, disc_loss = 0.0018461844514814192
Trained batch 832 in epoch 2, gen_loss = 0.9835102009315307, disc_loss = 0.0018633350513393052
Trained batch 833 in epoch 2, gen_loss = 0.9835240203413746, disc_loss = 0.0018711140518128644
Trained batch 834 in epoch 2, gen_loss = 0.9833838594173957, disc_loss = 0.0018838016182800453
Trained batch 835 in epoch 2, gen_loss = 0.9834197628441039, disc_loss = 0.0018862487412178689
Trained batch 836 in epoch 2, gen_loss = 0.9832328942514235, disc_loss = 0.0018869541233069995
Trained batch 837 in epoch 2, gen_loss = 0.9831345339521304, disc_loss = 0.0018878980003297885
Trained batch 838 in epoch 2, gen_loss = 0.9830195702727844, disc_loss = 0.0018905526781146647
Trained batch 839 in epoch 2, gen_loss = 0.983225662722474, disc_loss = 0.0018966727319431292
Trained batch 840 in epoch 2, gen_loss = 0.9832486215442879, disc_loss = 0.0019504825250501994
Trained batch 841 in epoch 2, gen_loss = 0.9836628889386274, disc_loss = 0.001968543302421812
Trained batch 842 in epoch 2, gen_loss = 0.9837800959392516, disc_loss = 0.001981580459292092
Trained batch 843 in epoch 2, gen_loss = 0.9837854765179033, disc_loss = 0.0020042548405563225
Trained batch 844 in epoch 2, gen_loss = 0.9835879213005834, disc_loss = 0.0020519146657502004
Trained batch 845 in epoch 2, gen_loss = 0.9832908153956663, disc_loss = 0.002215839862465984
Trained batch 846 in epoch 2, gen_loss = 0.9835841995625456, disc_loss = 0.0026642150551626632
Trained batch 847 in epoch 2, gen_loss = 0.9834509022393316, disc_loss = 0.002720698311779141
Trained batch 848 in epoch 2, gen_loss = 0.9835806856166629, disc_loss = 0.0027366237396012896
Trained batch 849 in epoch 2, gen_loss = 0.9836486664940329, disc_loss = 0.0027451835710021175
Trained batch 850 in epoch 2, gen_loss = 0.9837631610529683, disc_loss = 0.002750794806570465
Trained batch 851 in epoch 2, gen_loss = 0.9837249657357803, disc_loss = 0.002753539228990309
Trained batch 852 in epoch 2, gen_loss = 0.9841056454223597, disc_loss = 0.002755290652350397
Trained batch 853 in epoch 2, gen_loss = 0.9842425582001304, disc_loss = 0.002754973089007554
Trained batch 854 in epoch 2, gen_loss = 0.9842958369450262, disc_loss = 0.0027535368302055467
Trained batch 855 in epoch 2, gen_loss = 0.9845302216360502, disc_loss = 0.0027520905810021513
Trained batch 856 in epoch 2, gen_loss = 0.9845231516914857, disc_loss = 0.0027501999647853745
Trained batch 857 in epoch 2, gen_loss = 0.9845725614707787, disc_loss = 0.002748466323170266
Trained batch 858 in epoch 2, gen_loss = 0.9848273159877524, disc_loss = 0.0027483613333625263
Trained batch 859 in epoch 2, gen_loss = 0.985021335856859, disc_loss = 0.0027477143868752537
Trained batch 860 in epoch 2, gen_loss = 0.9851951734806464, disc_loss = 0.0027461832302498644
Trained batch 861 in epoch 2, gen_loss = 0.9851923950033785, disc_loss = 0.0027444791617674165
Trained batch 862 in epoch 2, gen_loss = 0.9853806816136437, disc_loss = 0.0027433970197724977
Trained batch 863 in epoch 2, gen_loss = 0.9854334027126983, disc_loss = 0.0027410777743339335
Trained batch 864 in epoch 2, gen_loss = 0.9854516739101079, disc_loss = 0.002739051011333113
Trained batch 865 in epoch 2, gen_loss = 0.9854437662051951, disc_loss = 0.0027370475290472754
Trained batch 866 in epoch 2, gen_loss = 0.9856018393097452, disc_loss = 0.0027348011880943867
Trained batch 867 in epoch 2, gen_loss = 0.9857276285298958, disc_loss = 0.002732793067874063
Trained batch 868 in epoch 2, gen_loss = 0.9857872402160434, disc_loss = 0.0027308130708951247
Trained batch 869 in epoch 2, gen_loss = 0.9858859389677815, disc_loss = 0.0027283935442676596
Trained batch 870 in epoch 2, gen_loss = 0.9859789281433403, disc_loss = 0.00272653125035769
Trained batch 871 in epoch 2, gen_loss = 0.9858002737848037, disc_loss = 0.0027251439903653975
Trained batch 872 in epoch 2, gen_loss = 0.9857439807736723, disc_loss = 0.0027230459684199353
Trained batch 873 in epoch 2, gen_loss = 0.9857170940536656, disc_loss = 0.00272104751976826
Trained batch 874 in epoch 2, gen_loss = 0.9856546207836696, disc_loss = 0.0027188304399605842
Trained batch 875 in epoch 2, gen_loss = 0.9857099979571556, disc_loss = 0.002716776203080006
Trained batch 876 in epoch 2, gen_loss = 0.9857145437085099, disc_loss = 0.0027143966702666313
Trained batch 877 in epoch 2, gen_loss = 0.9857902482729023, disc_loss = 0.002712284694808951
Trained batch 878 in epoch 2, gen_loss = 0.9857199111353686, disc_loss = 0.002709802007733074
Trained batch 879 in epoch 2, gen_loss = 0.9858508598398078, disc_loss = 0.002707282074863377
Trained batch 880 in epoch 2, gen_loss = 0.9859309176852024, disc_loss = 0.0027048647638331573
Trained batch 881 in epoch 2, gen_loss = 0.9859207067765346, disc_loss = 0.0027024651967797347
Trained batch 882 in epoch 2, gen_loss = 0.9859880486404099, disc_loss = 0.0027002601069595986
Trained batch 883 in epoch 2, gen_loss = 0.9859186795906784, disc_loss = 0.002697994213200193
Trained batch 884 in epoch 2, gen_loss = 0.9858492628329217, disc_loss = 0.002695450517789613
Trained batch 885 in epoch 2, gen_loss = 0.9858777917938362, disc_loss = 0.0026933263122268613
Trained batch 886 in epoch 2, gen_loss = 0.9858512185606371, disc_loss = 0.0026908855493300676
Trained batch 887 in epoch 2, gen_loss = 0.9858362553221686, disc_loss = 0.002688666789139346
Trained batch 888 in epoch 2, gen_loss = 0.9858288233942605, disc_loss = 0.0026861287249659196
Trained batch 889 in epoch 2, gen_loss = 0.9857659179173158, disc_loss = 0.002683729070449363
Trained batch 890 in epoch 2, gen_loss = 0.9856875208358037, disc_loss = 0.0026823310957927314
Trained batch 891 in epoch 2, gen_loss = 0.9856460243463516, disc_loss = 0.0026797760595322685
Trained batch 892 in epoch 2, gen_loss = 0.9856478172747579, disc_loss = 0.002677568188582444
Trained batch 893 in epoch 2, gen_loss = 0.9858091096883386, disc_loss = 0.002676109408029205
Trained batch 894 in epoch 2, gen_loss = 0.9858108527833523, disc_loss = 0.0026757390185990293
Trained batch 895 in epoch 2, gen_loss = 0.9857257242713656, disc_loss = 0.0026737871291321164
Trained batch 896 in epoch 2, gen_loss = 0.9855892464202914, disc_loss = 0.0026747579243459295
Trained batch 897 in epoch 2, gen_loss = 0.985752303775541, disc_loss = 0.002672841685741387
Trained batch 898 in epoch 2, gen_loss = 0.9856870994551958, disc_loss = 0.002670525511457648
Trained batch 899 in epoch 2, gen_loss = 0.9856335738632414, disc_loss = 0.0026684910387201753
Trained batch 900 in epoch 2, gen_loss = 0.9855660966842473, disc_loss = 0.0026664499404489245
Trained batch 901 in epoch 2, gen_loss = 0.9857387966300855, disc_loss = 0.0026644362933882625
Trained batch 902 in epoch 2, gen_loss = 0.9857205754498707, disc_loss = 0.0026620436955930755
Trained batch 903 in epoch 2, gen_loss = 0.9857323480918344, disc_loss = 0.0026596288331122387
Trained batch 904 in epoch 2, gen_loss = 0.985512647049203, disc_loss = 0.002658394406882799
Trained batch 905 in epoch 2, gen_loss = 0.985381598109441, disc_loss = 0.0026569624994426584
Trained batch 906 in epoch 2, gen_loss = 0.9852504305697591, disc_loss = 0.0026547744331556415
Trained batch 907 in epoch 2, gen_loss = 0.9852455804526543, disc_loss = 0.0026534438500371107
Trained batch 908 in epoch 2, gen_loss = 0.9854504492941207, disc_loss = 0.0026521710774667123
Trained batch 909 in epoch 2, gen_loss = 0.9854408428564176, disc_loss = 0.0026504922634858004
Trained batch 910 in epoch 2, gen_loss = 0.9853520731632848, disc_loss = 0.00264961240221092
Trained batch 911 in epoch 2, gen_loss = 0.9854476307437086, disc_loss = 0.0026477227700588786
Trained batch 912 in epoch 2, gen_loss = 0.9855814828146718, disc_loss = 0.0026462723693628323
Trained batch 913 in epoch 2, gen_loss = 0.9855708428363049, disc_loss = 0.0026441362995771015
Trained batch 914 in epoch 2, gen_loss = 0.985456151063325, disc_loss = 0.002643579484728201
Trained batch 915 in epoch 2, gen_loss = 0.9854604090405343, disc_loss = 0.0026417924652008774
Trained batch 916 in epoch 2, gen_loss = 0.9851573016027327, disc_loss = 0.0027091980841269284
Trained batch 917 in epoch 2, gen_loss = 0.9854545217323927, disc_loss = 0.0027264882243871955
Trained batch 918 in epoch 2, gen_loss = 0.9855554771241737, disc_loss = 0.002737975128202003
Trained batch 919 in epoch 2, gen_loss = 0.98553899805183, disc_loss = 0.0027509258707299443
Trained batch 920 in epoch 2, gen_loss = 0.9856404206522383, disc_loss = 0.002751681610774279
Trained batch 921 in epoch 2, gen_loss = 0.9854358812862777, disc_loss = 0.0027980212931364165
Trained batch 922 in epoch 2, gen_loss = 0.9854892964352766, disc_loss = 0.003107187097932778
Trained batch 923 in epoch 2, gen_loss = 0.9854005112663492, disc_loss = 0.0031746888776207484
Trained batch 924 in epoch 2, gen_loss = 0.9848436963558197, disc_loss = 0.003574216785570103
Trained batch 925 in epoch 2, gen_loss = 0.985033849499653, disc_loss = 0.004078613212901634
Trained batch 926 in epoch 2, gen_loss = 0.9848862493243933, disc_loss = 0.004326300521637639
Trained batch 927 in epoch 2, gen_loss = 0.9845000822418208, disc_loss = 0.0045700888158535236
Trained batch 928 in epoch 2, gen_loss = 0.9840445661891264, disc_loss = 0.0047584395820640365
Trained batch 929 in epoch 2, gen_loss = 0.9839023929449819, disc_loss = 0.004905936010688874
Trained batch 930 in epoch 2, gen_loss = 0.9837498803463965, disc_loss = 0.005048449919390253
Trained batch 931 in epoch 2, gen_loss = 0.9833590219141076, disc_loss = 0.005175856146827798
Trained batch 932 in epoch 2, gen_loss = 0.9832878738545912, disc_loss = 0.005257941871220925
Trained batch 933 in epoch 2, gen_loss = 0.9832402375512767, disc_loss = 0.005348981448756561
Trained batch 934 in epoch 2, gen_loss = 0.9832843226863739, disc_loss = 0.005421289085332095
Trained batch 935 in epoch 2, gen_loss = 0.9829477968697364, disc_loss = 0.00547563098461201
Trained batch 936 in epoch 2, gen_loss = 0.9826379604438835, disc_loss = 0.005553558167561406
Trained batch 937 in epoch 2, gen_loss = 0.9821336757717356, disc_loss = 0.005814063063826907
Trained batch 938 in epoch 2, gen_loss = 0.9825153134057062, disc_loss = 0.006311027530420331
Trained batch 939 in epoch 2, gen_loss = 0.9823533114917735, disc_loss = 0.006499507976603011
Trained batch 940 in epoch 2, gen_loss = 0.9820880361938578, disc_loss = 0.006783793935623747
Trained batch 941 in epoch 2, gen_loss = 0.9816944620981338, disc_loss = 0.006915379593336921
Trained batch 942 in epoch 2, gen_loss = 0.981560533872212, disc_loss = 0.007064279402816799
Trained batch 943 in epoch 2, gen_loss = 0.9813365781900741, disc_loss = 0.0071934562469539096
Trained batch 944 in epoch 2, gen_loss = 0.981125749450512, disc_loss = 0.007295437213236703
Trained batch 945 in epoch 2, gen_loss = 0.9808967948652977, disc_loss = 0.007350140549425857
Trained batch 946 in epoch 2, gen_loss = 0.9809878465051762, disc_loss = 0.00737517584428617
Trained batch 947 in epoch 2, gen_loss = 0.9808202931335204, disc_loss = 0.007413933553566168
Trained batch 948 in epoch 2, gen_loss = 0.9806071152111753, disc_loss = 0.007548590987491165
Trained batch 949 in epoch 2, gen_loss = 0.9807446759939193, disc_loss = 0.00786271371820476
Trained batch 950 in epoch 2, gen_loss = 0.9807087608253667, disc_loss = 0.00799207193973439
Trained batch 951 in epoch 2, gen_loss = 0.9805971103869066, disc_loss = 0.008036967766958635
Trained batch 952 in epoch 2, gen_loss = 0.9801220024182439, disc_loss = 0.008414022781738839
Trained batch 953 in epoch 2, gen_loss = 0.9800060284899965, disc_loss = 0.008671912406548025
Trained batch 954 in epoch 2, gen_loss = 0.9798823186552338, disc_loss = 0.008850906368897233
Trained batch 955 in epoch 2, gen_loss = 0.9796647220288859, disc_loss = 0.00898008951888674
Trained batch 956 in epoch 2, gen_loss = 0.9794483969266388, disc_loss = 0.009082443452501756
Trained batch 957 in epoch 2, gen_loss = 0.979170035189776, disc_loss = 0.009189216588145765
Trained batch 958 in epoch 2, gen_loss = 0.9789925688436805, disc_loss = 0.009331770778209509
Trained batch 959 in epoch 2, gen_loss = 0.9787749575140575, disc_loss = 0.009491546918585907
Trained batch 960 in epoch 2, gen_loss = 0.9785517847686851, disc_loss = 0.009616885160690302
Trained batch 961 in epoch 2, gen_loss = 0.9785397475016092, disc_loss = 0.009707775850749572
Trained batch 962 in epoch 2, gen_loss = 0.978471248042175, disc_loss = 0.009757752081449168
Trained batch 963 in epoch 2, gen_loss = 0.9785207693940376, disc_loss = 0.009797425798525217
Trained batch 964 in epoch 2, gen_loss = 0.9784577412617639, disc_loss = 0.009841919675803565
Trained batch 965 in epoch 2, gen_loss = 0.9784674432522021, disc_loss = 0.009865163388623718
Trained batch 966 in epoch 2, gen_loss = 0.9784126847889949, disc_loss = 0.009894041146996605
Trained batch 967 in epoch 2, gen_loss = 0.9783965381524287, disc_loss = 0.009910086563251737
Trained batch 968 in epoch 2, gen_loss = 0.9783854714918678, disc_loss = 0.009918288531420287
Trained batch 969 in epoch 2, gen_loss = 0.9780916344566444, disc_loss = 0.010035087971752461
Trained batch 970 in epoch 2, gen_loss = 0.9784239920049936, disc_loss = 0.010266322727838098
Trained batch 971 in epoch 2, gen_loss = 0.9782042453993004, disc_loss = 0.010323536008268972
Trained batch 972 in epoch 2, gen_loss = 0.9777997734306527, disc_loss = 0.010632458998552951
Trained batch 973 in epoch 2, gen_loss = 0.9777448667209496, disc_loss = 0.010718833927541553
Trained batch 974 in epoch 2, gen_loss = 0.9777987177249713, disc_loss = 0.01089172877266836
Trained batch 975 in epoch 2, gen_loss = 0.9775049177410661, disc_loss = 0.010930884099804241
Trained batch 976 in epoch 2, gen_loss = 0.9771365103909523, disc_loss = 0.011057186003269421
Trained batch 977 in epoch 2, gen_loss = 0.9770662720278972, disc_loss = 0.011094128824338356
Trained batch 978 in epoch 2, gen_loss = 0.9769822952391787, disc_loss = 0.011374266143604985
Trained batch 979 in epoch 2, gen_loss = 0.9765364051169279, disc_loss = 0.011551203032182197
Trained batch 980 in epoch 2, gen_loss = 0.9763634573975835, disc_loss = 0.011610019736464973
Trained batch 981 in epoch 2, gen_loss = 0.9761810774655061, disc_loss = 0.01171632115710778
Trained batch 982 in epoch 2, gen_loss = 0.9757169632133122, disc_loss = 0.011868790990469546
Trained batch 983 in epoch 2, gen_loss = 0.9756302183297106, disc_loss = 0.01197424932370342
Trained batch 984 in epoch 2, gen_loss = 0.9755623121249494, disc_loss = 0.011998410107772372
Trained batch 985 in epoch 2, gen_loss = 0.9755727988167177, disc_loss = 0.012041690973684231
Trained batch 986 in epoch 2, gen_loss = 0.9753282416494905, disc_loss = 0.01209609114708027
Trained batch 987 in epoch 2, gen_loss = 0.9754116835321492, disc_loss = 0.012278622454547215
Trained batch 988 in epoch 2, gen_loss = 0.9752843556859737, disc_loss = 0.012309290484613076
Trained batch 989 in epoch 2, gen_loss = 0.9747857334035815, disc_loss = 0.012616391518450756
Trained batch 990 in epoch 2, gen_loss = 0.9750664939673469, disc_loss = 0.012682420958974656
Trained batch 991 in epoch 2, gen_loss = 0.9751555970719745, disc_loss = 0.012807178424560745
Trained batch 992 in epoch 2, gen_loss = 0.9748813439111815, disc_loss = 0.01286597076554554
Trained batch 993 in epoch 2, gen_loss = 0.975200283035666, disc_loss = 0.01288018414696938
Trained batch 994 in epoch 2, gen_loss = 0.9753288130664346, disc_loss = 0.012904035484321162
Trained batch 995 in epoch 2, gen_loss = 0.9753682230969509, disc_loss = 0.012912862650760455
Trained batch 996 in epoch 2, gen_loss = 0.9754372573903236, disc_loss = 0.01291558509001881
Trained batch 997 in epoch 2, gen_loss = 0.9756335355117469, disc_loss = 0.01291786000508286
Trained batch 998 in epoch 2, gen_loss = 0.9756061496200027, disc_loss = 0.01291472402236842
Trained batch 999 in epoch 2, gen_loss = 0.9756831774711608, disc_loss = 0.01290962152267457
Trained batch 1000 in epoch 2, gen_loss = 0.9755712502248042, disc_loss = 0.012909548932954634
Trained batch 1001 in epoch 2, gen_loss = 0.9756092634981501, disc_loss = 0.012904240849606568
Trained batch 1002 in epoch 2, gen_loss = 0.975742021800276, disc_loss = 0.012899372117007282
Trained batch 1003 in epoch 2, gen_loss = 0.9758216560599339, disc_loss = 0.012889909112193591
Trained batch 1004 in epoch 2, gen_loss = 0.9758767021236135, disc_loss = 0.0128812549861938
Trained batch 1005 in epoch 2, gen_loss = 0.9758538193778536, disc_loss = 0.012881435227454696
Trained batch 1006 in epoch 2, gen_loss = 0.9757081284423571, disc_loss = 0.012886135839301559
Trained batch 1007 in epoch 2, gen_loss = 0.9756713074351114, disc_loss = 0.012881996830199367
Trained batch 1008 in epoch 2, gen_loss = 0.9755337089447839, disc_loss = 0.01289611149845692
Trained batch 1009 in epoch 2, gen_loss = 0.9755584464214816, disc_loss = 0.0129228398899172
Trained batch 1010 in epoch 2, gen_loss = 0.9757079872957677, disc_loss = 0.012918803840328669
Trained batch 1011 in epoch 2, gen_loss = 0.9758866783894098, disc_loss = 0.012962029042582188
Trained batch 1012 in epoch 2, gen_loss = 0.9754916259472839, disc_loss = 0.013283740449058966
Trained batch 1013 in epoch 2, gen_loss = 0.9756414587563547, disc_loss = 0.013429918742874827
Trained batch 1014 in epoch 2, gen_loss = 0.9753848704798468, disc_loss = 0.013521203629384642
Trained batch 1015 in epoch 2, gen_loss = 0.9756486935057039, disc_loss = 0.013557577420831118
Trained batch 1016 in epoch 2, gen_loss = 0.9757618400668442, disc_loss = 0.013573921095464707
Trained batch 1017 in epoch 2, gen_loss = 0.9759237621645562, disc_loss = 0.01357228960147176
Trained batch 1018 in epoch 2, gen_loss = 0.9759799372459651, disc_loss = 0.013568120447776423
Trained batch 1019 in epoch 2, gen_loss = 0.9760853298154532, disc_loss = 0.013560601576675397
Trained batch 1020 in epoch 2, gen_loss = 0.9760999664970756, disc_loss = 0.013551113436671966
Trained batch 1021 in epoch 2, gen_loss = 0.9761199846776264, disc_loss = 0.013541655054680662
Trained batch 1022 in epoch 2, gen_loss = 0.9761477873705233, disc_loss = 0.013533837503949563
Trained batch 1023 in epoch 2, gen_loss = 0.9761301975813694, disc_loss = 0.013523444040544064
Trained batch 1024 in epoch 2, gen_loss = 0.9762674151978842, disc_loss = 0.01351360962036202
Trained batch 1025 in epoch 2, gen_loss = 0.976332876707843, disc_loss = 0.013504290689273326
Trained batch 1026 in epoch 2, gen_loss = 0.976393433079167, disc_loss = 0.01349435869991229
Trained batch 1027 in epoch 2, gen_loss = 0.976547612580344, disc_loss = 0.013483298113412208
Trained batch 1028 in epoch 2, gen_loss = 0.9765879190929662, disc_loss = 0.013473023873993916
Trained batch 1029 in epoch 2, gen_loss = 0.9766741846950309, disc_loss = 0.01346176521780842
Trained batch 1030 in epoch 2, gen_loss = 0.9766640302397231, disc_loss = 0.013450748616768315
Trained batch 1031 in epoch 2, gen_loss = 0.9766921213893003, disc_loss = 0.013439698159599238
Trained batch 1032 in epoch 2, gen_loss = 0.9768550827565521, disc_loss = 0.013429033485835596
Trained batch 1033 in epoch 2, gen_loss = 0.9770060811098125, disc_loss = 0.013419171066048854
Trained batch 1034 in epoch 2, gen_loss = 0.9770476481764789, disc_loss = 0.013408896122223379
Trained batch 1035 in epoch 2, gen_loss = 0.977111927330724, disc_loss = 0.013398302772625584
Trained batch 1036 in epoch 2, gen_loss = 0.9771464077922855, disc_loss = 0.0133910431840541
Trained batch 1037 in epoch 2, gen_loss = 0.9771897875504687, disc_loss = 0.013379476537421275
Trained batch 1038 in epoch 2, gen_loss = 0.977381794812934, disc_loss = 0.013370776480885986
Trained batch 1039 in epoch 2, gen_loss = 0.9773077020851465, disc_loss = 0.013360422965874582
Trained batch 1040 in epoch 2, gen_loss = 0.9773761278499673, disc_loss = 0.013349961503110262
Trained batch 1041 in epoch 2, gen_loss = 0.9773424239167783, disc_loss = 0.013339496572751547
Trained batch 1042 in epoch 2, gen_loss = 0.9774205256057037, disc_loss = 0.01332966651509548
Trained batch 1043 in epoch 2, gen_loss = 0.9774210646006339, disc_loss = 0.013319025477208242
Trained batch 1044 in epoch 2, gen_loss = 0.9774052200134862, disc_loss = 0.013307669273556463
Trained batch 1045 in epoch 2, gen_loss = 0.9773809247673355, disc_loss = 0.013296328815476868
Trained batch 1046 in epoch 2, gen_loss = 0.9773624481877032, disc_loss = 0.013285208247436758
Trained batch 1047 in epoch 2, gen_loss = 0.9772934427356902, disc_loss = 0.013274967972281832
Trained batch 1048 in epoch 2, gen_loss = 0.9772429882741406, disc_loss = 0.013264601422413638
Trained batch 1049 in epoch 2, gen_loss = 0.9772653959478651, disc_loss = 0.013253078910195091
Trained batch 1050 in epoch 2, gen_loss = 0.9772942817630822, disc_loss = 0.013245359632293148
Trained batch 1051 in epoch 2, gen_loss = 0.9774128817900052, disc_loss = 0.013234756695321972
Trained batch 1052 in epoch 2, gen_loss = 0.977405062031995, disc_loss = 0.013223477115692989
Trained batch 1053 in epoch 2, gen_loss = 0.977439750360583, disc_loss = 0.013212697584681483
Trained batch 1054 in epoch 2, gen_loss = 0.9773536698513121, disc_loss = 0.0132013567714782
Trained batch 1055 in epoch 2, gen_loss = 0.9775061148472808, disc_loss = 0.013190015819335795
Trained batch 1056 in epoch 2, gen_loss = 0.9776090447250807, disc_loss = 0.01317918846252517
Trained batch 1057 in epoch 2, gen_loss = 0.9775429375342927, disc_loss = 0.013167937942244691
Trained batch 1058 in epoch 2, gen_loss = 0.9775138681963775, disc_loss = 0.013157684525073224
Trained batch 1059 in epoch 2, gen_loss = 0.9775654748363315, disc_loss = 0.013146947951847907
Trained batch 1060 in epoch 2, gen_loss = 0.9776208021526175, disc_loss = 0.013136009207882143
Trained batch 1061 in epoch 2, gen_loss = 0.9775721312354962, disc_loss = 0.013127260544498911
Trained batch 1062 in epoch 2, gen_loss = 0.9774766663056101, disc_loss = 0.013117738872743935
Trained batch 1063 in epoch 2, gen_loss = 0.9774121509346747, disc_loss = 0.013106428831996251
Trained batch 1064 in epoch 2, gen_loss = 0.9775238623081798, disc_loss = 0.013095783807710032
Trained batch 1065 in epoch 2, gen_loss = 0.9775589027391366, disc_loss = 0.013084965077143443
Trained batch 1066 in epoch 2, gen_loss = 0.9775624248952428, disc_loss = 0.013074071327689818
Trained batch 1067 in epoch 2, gen_loss = 0.9775288798166125, disc_loss = 0.013063436179524959
Trained batch 1068 in epoch 2, gen_loss = 0.9774710108343968, disc_loss = 0.013052427742794248
Trained batch 1069 in epoch 2, gen_loss = 0.9775280653873336, disc_loss = 0.013042153224102047
Trained batch 1070 in epoch 2, gen_loss = 0.9775797085267823, disc_loss = 0.013035014652749036
Trained batch 1071 in epoch 2, gen_loss = 0.9776153651191227, disc_loss = 0.013024732590972928
Trained batch 1072 in epoch 2, gen_loss = 0.9776184627194329, disc_loss = 0.013014321360969916
Trained batch 1073 in epoch 2, gen_loss = 0.9775621861052912, disc_loss = 0.013003125379571571
Trained batch 1074 in epoch 2, gen_loss = 0.97750438828801, disc_loss = 0.012992073234934143
Trained batch 1075 in epoch 2, gen_loss = 0.9775577722096532, disc_loss = 0.012981640772668335
Trained batch 1076 in epoch 2, gen_loss = 0.977507945499491, disc_loss = 0.012970705074674304
Trained batch 1077 in epoch 2, gen_loss = 0.9775144732617712, disc_loss = 0.012959814888360592
Trained batch 1078 in epoch 2, gen_loss = 0.9774787215528055, disc_loss = 0.01294895599165606
Trained batch 1079 in epoch 2, gen_loss = 0.9773927052815755, disc_loss = 0.012938437642798008
Trained batch 1080 in epoch 2, gen_loss = 0.9773739249368821, disc_loss = 0.012927664085262249
Trained batch 1081 in epoch 2, gen_loss = 0.9775123466735847, disc_loss = 0.012916920404105926
Trained batch 1082 in epoch 2, gen_loss = 0.9775474223954086, disc_loss = 0.012906532547835884
Trained batch 1083 in epoch 2, gen_loss = 0.9776039242854417, disc_loss = 0.012895775410567705
Trained batch 1084 in epoch 2, gen_loss = 0.9776030839862911, disc_loss = 0.012885908000970534
Trained batch 1085 in epoch 2, gen_loss = 0.9775617652286263, disc_loss = 0.012876020489771024
Trained batch 1086 in epoch 2, gen_loss = 0.9775563279422139, disc_loss = 0.012865401927208042
Trained batch 1087 in epoch 2, gen_loss = 0.9774421265567926, disc_loss = 0.01285449435157288
Trained batch 1088 in epoch 2, gen_loss = 0.9776129442907672, disc_loss = 0.012844653529696777
Trained batch 1089 in epoch 2, gen_loss = 0.9775817113731979, disc_loss = 0.012833896515610064
Trained batch 1090 in epoch 2, gen_loss = 0.9775822101439171, disc_loss = 0.012823055762530618
Trained batch 1091 in epoch 2, gen_loss = 0.9775454768767724, disc_loss = 0.012812333533544846
Trained batch 1092 in epoch 2, gen_loss = 0.9776255111572182, disc_loss = 0.012801725212370633
Trained batch 1093 in epoch 2, gen_loss = 0.9776451891148548, disc_loss = 0.012790789168824567
Trained batch 1094 in epoch 2, gen_loss = 0.9775773807747723, disc_loss = 0.012780024917486876
Trained batch 1095 in epoch 2, gen_loss = 0.9775381585868606, disc_loss = 0.01276916188535125
Trained batch 1096 in epoch 2, gen_loss = 0.9776279036848786, disc_loss = 0.012758273128132526
Trained batch 1097 in epoch 2, gen_loss = 0.9776178998482467, disc_loss = 0.012747440528840663
Trained batch 1098 in epoch 2, gen_loss = 0.9774542716658039, disc_loss = 0.0127366358980003
Trained batch 1099 in epoch 2, gen_loss = 0.9774085419286381, disc_loss = 0.01272574912828118
Trained batch 1100 in epoch 2, gen_loss = 0.9773942974347835, disc_loss = 0.01271486604634565
Trained batch 1101 in epoch 2, gen_loss = 0.9773205277491395, disc_loss = 0.012704400199292415
Trained batch 1102 in epoch 2, gen_loss = 0.9772601485900845, disc_loss = 0.012693564541595046
Trained batch 1103 in epoch 2, gen_loss = 0.9773109724232252, disc_loss = 0.012683163294649854
Trained batch 1104 in epoch 2, gen_loss = 0.9774765332360074, disc_loss = 0.012672677004580255
Trained batch 1105 in epoch 2, gen_loss = 0.9776004242961704, disc_loss = 0.012662493387725798
Trained batch 1106 in epoch 2, gen_loss = 0.9775488705600611, disc_loss = 0.012651906579834062
Trained batch 1107 in epoch 2, gen_loss = 0.9775565741079378, disc_loss = 0.012641204619955226
Trained batch 1108 in epoch 2, gen_loss = 0.9776470311812392, disc_loss = 0.012630468584636791
Trained batch 1109 in epoch 2, gen_loss = 0.9777665335852821, disc_loss = 0.012620273894060882
Trained batch 1110 in epoch 2, gen_loss = 0.97779670317467, disc_loss = 0.012609866983010991
Trained batch 1111 in epoch 2, gen_loss = 0.9777840272985774, disc_loss = 0.012600134681830084
Trained batch 1112 in epoch 2, gen_loss = 0.9777736992099108, disc_loss = 0.012591178516543747
Trained batch 1113 in epoch 2, gen_loss = 0.9776048143419372, disc_loss = 0.01258109252370791
Trained batch 1114 in epoch 2, gen_loss = 0.9776794682703746, disc_loss = 0.012571341092223218
Trained batch 1115 in epoch 2, gen_loss = 0.9777949812378081, disc_loss = 0.012562079575981178
Trained batch 1116 in epoch 2, gen_loss = 0.9777222463565953, disc_loss = 0.012551582899598502
Trained batch 1117 in epoch 2, gen_loss = 0.9776958381234, disc_loss = 0.012541074060837236
Trained batch 1118 in epoch 2, gen_loss = 0.9776685757760601, disc_loss = 0.012531755941705046
Trained batch 1119 in epoch 2, gen_loss = 0.9777853292013917, disc_loss = 0.012521354749515013
Trained batch 1120 in epoch 2, gen_loss = 0.9777094127874519, disc_loss = 0.012511390636326749
Trained batch 1121 in epoch 2, gen_loss = 0.9776715194796496, disc_loss = 0.012501885676286482
Trained batch 1122 in epoch 2, gen_loss = 0.9777010362379698, disc_loss = 0.01249167550757311
Trained batch 1123 in epoch 2, gen_loss = 0.9777247973078086, disc_loss = 0.012481553853277963
Trained batch 1124 in epoch 2, gen_loss = 0.9777704058223301, disc_loss = 0.012471182864702618
Trained batch 1125 in epoch 2, gen_loss = 0.9777999664813968, disc_loss = 0.012460663487402131
Trained batch 1126 in epoch 2, gen_loss = 0.9777563826743755, disc_loss = 0.012450396075987108
Trained batch 1127 in epoch 2, gen_loss = 0.9777319874640897, disc_loss = 0.012440049719790547
Trained batch 1128 in epoch 2, gen_loss = 0.9777017188769088, disc_loss = 0.012429632788485467
Trained batch 1129 in epoch 2, gen_loss = 0.9777458397688064, disc_loss = 0.012419383576221195
Trained batch 1130 in epoch 2, gen_loss = 0.977856760315933, disc_loss = 0.012409567360569222
Trained batch 1131 in epoch 2, gen_loss = 0.9778891245804912, disc_loss = 0.012399426837623089
Trained batch 1132 in epoch 2, gen_loss = 0.9778498067123534, disc_loss = 0.01238921401555862
Trained batch 1133 in epoch 2, gen_loss = 0.977800978081567, disc_loss = 0.012378870813153246
Trained batch 1134 in epoch 2, gen_loss = 0.9777843464838776, disc_loss = 0.012368869960296793
Trained batch 1135 in epoch 2, gen_loss = 0.97775275916071, disc_loss = 0.012358714996647084
Trained batch 1136 in epoch 2, gen_loss = 0.9777759235473505, disc_loss = 0.012348721762030716
Trained batch 1137 in epoch 2, gen_loss = 0.9776241525824334, disc_loss = 0.012338704249087307
Trained batch 1138 in epoch 2, gen_loss = 0.9775461106053354, disc_loss = 0.01232880967543166
Trained batch 1139 in epoch 2, gen_loss = 0.9775337883777786, disc_loss = 0.012318628502365307
Trained batch 1140 in epoch 2, gen_loss = 0.9775732298570177, disc_loss = 0.012308902657856287
Trained batch 1141 in epoch 2, gen_loss = 0.9776839570594126, disc_loss = 0.012298941353239948
Trained batch 1142 in epoch 2, gen_loss = 0.9777284861132437, disc_loss = 0.012289309372384165
Trained batch 1143 in epoch 2, gen_loss = 0.9777083706397277, disc_loss = 0.012279654381406156
Trained batch 1144 in epoch 2, gen_loss = 0.9777334193475382, disc_loss = 0.012269865247084429
Trained batch 1145 in epoch 2, gen_loss = 0.9777221360859862, disc_loss = 0.012260527172769715
Trained batch 1146 in epoch 2, gen_loss = 0.9777469285280682, disc_loss = 0.01225057706726961
Trained batch 1147 in epoch 2, gen_loss = 0.9776870486316781, disc_loss = 0.012241105174769295
Trained batch 1148 in epoch 2, gen_loss = 0.9778433506441074, disc_loss = 0.012232176721339407
Trained batch 1149 in epoch 2, gen_loss = 0.9778374925903652, disc_loss = 0.012222027919159028
Trained batch 1150 in epoch 2, gen_loss = 0.9778740050790623, disc_loss = 0.012212138794309749
Trained batch 1151 in epoch 2, gen_loss = 0.9777852032954494, disc_loss = 0.01220270759967611
Trained batch 1152 in epoch 2, gen_loss = 0.9777999824786952, disc_loss = 0.012193316268626195
Trained batch 1153 in epoch 2, gen_loss = 0.9777934193817747, disc_loss = 0.012183343557879188
Trained batch 1154 in epoch 2, gen_loss = 0.9777387187078401, disc_loss = 0.012173976894549712
Trained batch 1155 in epoch 2, gen_loss = 0.9776943066128397, disc_loss = 0.01216454632022071
Trained batch 1156 in epoch 2, gen_loss = 0.9778701177216236, disc_loss = 0.01215498138289249
Trained batch 1157 in epoch 2, gen_loss = 0.9779243996312169, disc_loss = 0.012145126304841143
Trained batch 1158 in epoch 2, gen_loss = 0.9779049220838045, disc_loss = 0.012135212923400305
Trained batch 1159 in epoch 2, gen_loss = 0.9778476077934791, disc_loss = 0.012125340342779588
Trained batch 1160 in epoch 2, gen_loss = 0.9778165911724607, disc_loss = 0.012115712482822116
Trained batch 1161 in epoch 2, gen_loss = 0.9777121090437582, disc_loss = 0.012105928737326146
Trained batch 1162 in epoch 2, gen_loss = 0.9776852968327464, disc_loss = 0.012096199454127684
Trained batch 1163 in epoch 2, gen_loss = 0.9775661910112781, disc_loss = 0.01208655057279245
Trained batch 1164 in epoch 2, gen_loss = 0.9775575122096508, disc_loss = 0.012076691144556726
Trained batch 1165 in epoch 2, gen_loss = 0.9775414628393654, disc_loss = 0.012067053162942699
Trained batch 1166 in epoch 2, gen_loss = 0.9775470039634083, disc_loss = 0.012058245985484032
Trained batch 1167 in epoch 2, gen_loss = 0.9775572346702014, disc_loss = 0.012048489768908252
Trained batch 1168 in epoch 2, gen_loss = 0.9775193475881533, disc_loss = 0.01203862906082006
Trained batch 1169 in epoch 2, gen_loss = 0.9775084698302114, disc_loss = 0.01202899391867885
Trained batch 1170 in epoch 2, gen_loss = 0.9774851257428463, disc_loss = 0.012019102809216826
Trained batch 1171 in epoch 2, gen_loss = 0.9775134235518784, disc_loss = 0.01200926737508116
Trained batch 1172 in epoch 2, gen_loss = 0.9775302442646596, disc_loss = 0.011999703827587005
Trained batch 1173 in epoch 2, gen_loss = 0.9775660600532259, disc_loss = 0.011990207297140629
Trained batch 1174 in epoch 2, gen_loss = 0.9775001686684629, disc_loss = 0.011980799462997968
Trained batch 1175 in epoch 2, gen_loss = 0.9774223141828362, disc_loss = 0.011971179610406339
Trained batch 1176 in epoch 2, gen_loss = 0.9774619769827227, disc_loss = 0.011962017679491857
Trained batch 1177 in epoch 2, gen_loss = 0.9775230358837012, disc_loss = 0.01195268464249109
Trained batch 1178 in epoch 2, gen_loss = 0.9774391901402073, disc_loss = 0.01194365523065649
Trained batch 1179 in epoch 2, gen_loss = 0.9773895111629518, disc_loss = 0.011934019851481533
Trained batch 1180 in epoch 2, gen_loss = 0.9773733651203992, disc_loss = 0.011924472077897333
Trained batch 1181 in epoch 2, gen_loss = 0.9773600676842349, disc_loss = 0.011915092340719968
Trained batch 1182 in epoch 2, gen_loss = 0.9773711836751194, disc_loss = 0.01190639665861148
Trained batch 1183 in epoch 2, gen_loss = 0.9773625361959677, disc_loss = 0.011897305619321423
Trained batch 1184 in epoch 2, gen_loss = 0.9774707408896981, disc_loss = 0.011887823797164108
Trained batch 1185 in epoch 2, gen_loss = 0.9774213776017522, disc_loss = 0.011879104400491601
Trained batch 1186 in epoch 2, gen_loss = 0.9774500879803524, disc_loss = 0.011869739865372821
Trained batch 1187 in epoch 2, gen_loss = 0.9774907930732175, disc_loss = 0.011860456482903375
Trained batch 1188 in epoch 2, gen_loss = 0.9774643119590637, disc_loss = 0.011851579493231472
Trained batch 1189 in epoch 2, gen_loss = 0.9774014095298382, disc_loss = 0.011842290325478667
Trained batch 1190 in epoch 2, gen_loss = 0.977292703941627, disc_loss = 0.011833108106574692
Trained batch 1191 in epoch 2, gen_loss = 0.9772390689725844, disc_loss = 0.01182410360667788
Trained batch 1192 in epoch 2, gen_loss = 0.9771923741570862, disc_loss = 0.011814828057917247
Trained batch 1193 in epoch 2, gen_loss = 0.9772313787809369, disc_loss = 0.01180604827874305
Trained batch 1194 in epoch 2, gen_loss = 0.9771948741070895, disc_loss = 0.011796943126192753
Trained batch 1195 in epoch 2, gen_loss = 0.9772191995063354, disc_loss = 0.01178766351168758
Trained batch 1196 in epoch 2, gen_loss = 0.9773198353716405, disc_loss = 0.011778302786442114
Trained batch 1197 in epoch 2, gen_loss = 0.9773086342767802, disc_loss = 0.011769006288738086
Trained batch 1198 in epoch 2, gen_loss = 0.9773541880310128, disc_loss = 0.011759640798024138
Trained batch 1199 in epoch 2, gen_loss = 0.9774583232899506, disc_loss = 0.011750485275576162
Trained batch 1200 in epoch 2, gen_loss = 0.9774635897190942, disc_loss = 0.0117412965519997
Trained batch 1201 in epoch 2, gen_loss = 0.9776049425915355, disc_loss = 0.011732617522408362
Trained batch 1202 in epoch 2, gen_loss = 0.977602930288957, disc_loss = 0.011723407071397515
Trained batch 1203 in epoch 2, gen_loss = 0.9776609715730249, disc_loss = 0.011714258478967777
Trained batch 1204 in epoch 2, gen_loss = 0.9776877976552085, disc_loss = 0.011705306683656377
Trained batch 1205 in epoch 2, gen_loss = 0.9776451547644032, disc_loss = 0.011696016301444784
Trained batch 1206 in epoch 2, gen_loss = 0.9777569992540291, disc_loss = 0.011686978321882233
Trained batch 1207 in epoch 2, gen_loss = 0.9777012244853752, disc_loss = 0.011677725756867974
Trained batch 1208 in epoch 2, gen_loss = 0.9778076135688226, disc_loss = 0.011668607113609241
Trained batch 1209 in epoch 2, gen_loss = 0.9777787464709321, disc_loss = 0.01165949531846722
Trained batch 1210 in epoch 2, gen_loss = 0.9777909615726927, disc_loss = 0.011651029608649426
Trained batch 1211 in epoch 2, gen_loss = 0.977795420896889, disc_loss = 0.011641861294595435
Trained batch 1212 in epoch 2, gen_loss = 0.9777519333883444, disc_loss = 0.01163314338791244
Trained batch 1213 in epoch 2, gen_loss = 0.9777516328424363, disc_loss = 0.011624089822628999
Trained batch 1214 in epoch 2, gen_loss = 0.9776772767918591, disc_loss = 0.011615098281758704
Trained batch 1215 in epoch 2, gen_loss = 0.9775482610260186, disc_loss = 0.0116060820276193
Trained batch 1216 in epoch 2, gen_loss = 0.9774046261093121, disc_loss = 0.011597021454020197
Trained batch 1217 in epoch 2, gen_loss = 0.9773570086764193, disc_loss = 0.011587944469633146
Trained batch 1218 in epoch 2, gen_loss = 0.977371599216555, disc_loss = 0.011578874441124064
Trained batch 1219 in epoch 2, gen_loss = 0.9773058134024261, disc_loss = 0.011570090444669792
Trained batch 1220 in epoch 2, gen_loss = 0.9771853229923388, disc_loss = 0.011561049219066609
Trained batch 1221 in epoch 2, gen_loss = 0.9770594713828372, disc_loss = 0.01155205616459678
Trained batch 1222 in epoch 2, gen_loss = 0.9769969449019881, disc_loss = 0.011543714509061739
Trained batch 1223 in epoch 2, gen_loss = 0.9769894657960905, disc_loss = 0.011535506480582875
Trained batch 1224 in epoch 2, gen_loss = 0.9769941855450066, disc_loss = 0.01152659932391395
Trained batch 1225 in epoch 2, gen_loss = 0.9769744987783385, disc_loss = 0.011518051464219432
Trained batch 1226 in epoch 2, gen_loss = 0.9770209138337053, disc_loss = 0.011509061278353128
Trained batch 1227 in epoch 2, gen_loss = 0.9770842843995421, disc_loss = 0.011500092910994974
Trained batch 1228 in epoch 2, gen_loss = 0.9771309138508324, disc_loss = 0.011491078525993624
Trained batch 1229 in epoch 2, gen_loss = 0.9771510745451703, disc_loss = 0.011482226952784544
Trained batch 1230 in epoch 2, gen_loss = 0.9771534548262868, disc_loss = 0.011473490459182292
Trained batch 1231 in epoch 2, gen_loss = 0.9770364192882915, disc_loss = 0.011464556271368873
Trained batch 1232 in epoch 2, gen_loss = 0.9770903181759014, disc_loss = 0.011455998084667823
Trained batch 1233 in epoch 2, gen_loss = 0.9770745728255478, disc_loss = 0.01144754195831036
Trained batch 1234 in epoch 2, gen_loss = 0.9769705372783336, disc_loss = 0.011439327212962085
Trained batch 1235 in epoch 2, gen_loss = 0.9770108609909378, disc_loss = 0.011430426023091064
Trained batch 1236 in epoch 2, gen_loss = 0.9771085415719108, disc_loss = 0.011421516386218175
Trained batch 1237 in epoch 2, gen_loss = 0.9770707255996679, disc_loss = 0.01141262624829068
Trained batch 1238 in epoch 2, gen_loss = 0.9769845238801834, disc_loss = 0.011403719789518233
Trained batch 1239 in epoch 2, gen_loss = 0.9770459870176931, disc_loss = 0.011394920852152638
Trained batch 1240 in epoch 2, gen_loss = 0.9769951373122566, disc_loss = 0.011386890650287272
Trained batch 1241 in epoch 2, gen_loss = 0.9770898091428329, disc_loss = 0.011378388523888824
Trained batch 1242 in epoch 2, gen_loss = 0.9770394072643903, disc_loss = 0.011369814055147434
Trained batch 1243 in epoch 2, gen_loss = 0.9770950279243507, disc_loss = 0.011361218618850973
Trained batch 1244 in epoch 2, gen_loss = 0.9770199535362213, disc_loss = 0.011352617514528237
Trained batch 1245 in epoch 2, gen_loss = 0.9770060726000448, disc_loss = 0.011344001416299517
Trained batch 1246 in epoch 2, gen_loss = 0.9769785937635824, disc_loss = 0.011335971490495877
Trained batch 1247 in epoch 2, gen_loss = 0.976877021531646, disc_loss = 0.011327236354843943
Trained batch 1248 in epoch 2, gen_loss = 0.9768124229436497, disc_loss = 0.011319017961289096
Trained batch 1249 in epoch 2, gen_loss = 0.9767494220256805, disc_loss = 0.011310368058690802
Trained batch 1250 in epoch 2, gen_loss = 0.9767262487293338, disc_loss = 0.01130166125702869
Trained batch 1251 in epoch 2, gen_loss = 0.9767128082986076, disc_loss = 0.011292922394448733
Trained batch 1252 in epoch 2, gen_loss = 0.9766299757877541, disc_loss = 0.011284285372746358
Trained batch 1253 in epoch 2, gen_loss = 0.9766480295281661, disc_loss = 0.011275757151968522
Trained batch 1254 in epoch 2, gen_loss = 0.9766254776502511, disc_loss = 0.011267316766756687
Trained batch 1255 in epoch 2, gen_loss = 0.9766225957661677, disc_loss = 0.011258634543447691
Trained batch 1256 in epoch 2, gen_loss = 0.9766963442925337, disc_loss = 0.01125006072806004
Trained batch 1257 in epoch 2, gen_loss = 0.976665194965129, disc_loss = 0.011241682396903863
Trained batch 1258 in epoch 2, gen_loss = 0.9766200980181917, disc_loss = 0.011233125875928314
Trained batch 1259 in epoch 2, gen_loss = 0.9766723646531029, disc_loss = 0.01122519023846262
Trained batch 1260 in epoch 2, gen_loss = 0.9766571555319142, disc_loss = 0.011216815814774145
Trained batch 1261 in epoch 2, gen_loss = 0.9766057359907782, disc_loss = 0.011208348578186566
Trained batch 1262 in epoch 2, gen_loss = 0.9766480102958136, disc_loss = 0.011199882379429775
Trained batch 1263 in epoch 2, gen_loss = 0.9767970195205151, disc_loss = 0.011191397352261826
Trained batch 1264 in epoch 2, gen_loss = 0.9767640586427078, disc_loss = 0.011183373767605581
Trained batch 1265 in epoch 2, gen_loss = 0.9766688629820072, disc_loss = 0.011174937036570924
Trained batch 1266 in epoch 2, gen_loss = 0.9766548407670542, disc_loss = 0.011167290573255155
Trained batch 1267 in epoch 2, gen_loss = 0.9765515831836766, disc_loss = 0.011159176596311656
Trained batch 1268 in epoch 2, gen_loss = 0.9764983361400517, disc_loss = 0.011150919062998609
Trained batch 1269 in epoch 2, gen_loss = 0.9764757126335084, disc_loss = 0.011142556033373122
Trained batch 1270 in epoch 2, gen_loss = 0.9765376164911301, disc_loss = 0.011134332280735544
Trained batch 1271 in epoch 2, gen_loss = 0.9765196186285349, disc_loss = 0.011126103244974306
Trained batch 1272 in epoch 2, gen_loss = 0.976424822026318, disc_loss = 0.011117727751125753
Trained batch 1273 in epoch 2, gen_loss = 0.9763734441256411, disc_loss = 0.011109414918956222
Trained batch 1274 in epoch 2, gen_loss = 0.9764069691358828, disc_loss = 0.011101081380711905
Trained batch 1275 in epoch 2, gen_loss = 0.9763659754984058, disc_loss = 0.011092812181123807
Trained batch 1276 in epoch 2, gen_loss = 0.9763817409098662, disc_loss = 0.011084598443022738
Trained batch 1277 in epoch 2, gen_loss = 0.9764297243574975, disc_loss = 0.011076400772508464
Trained batch 1278 in epoch 2, gen_loss = 0.9764757116293888, disc_loss = 0.011068043064777874
Trained batch 1279 in epoch 2, gen_loss = 0.9763968672603369, disc_loss = 0.011059725958125455
Trained batch 1280 in epoch 2, gen_loss = 0.9764448055338804, disc_loss = 0.011051501505305717
Trained batch 1281 in epoch 2, gen_loss = 0.976413828952822, disc_loss = 0.011043379486075533
Trained batch 1282 in epoch 2, gen_loss = 0.9765248494230019, disc_loss = 0.011035378761514215
Trained batch 1283 in epoch 2, gen_loss = 0.9766651334885125, disc_loss = 0.01102718547548438
Trained batch 1284 in epoch 2, gen_loss = 0.9766714009793352, disc_loss = 0.011018956908802158
Trained batch 1285 in epoch 2, gen_loss = 0.9766995624101736, disc_loss = 0.011010730925476334
Trained batch 1286 in epoch 2, gen_loss = 0.9767148510003701, disc_loss = 0.011003043936435626
Trained batch 1287 in epoch 2, gen_loss = 0.976801032836763, disc_loss = 0.0109949861325957
Trained batch 1288 in epoch 2, gen_loss = 0.976750331344856, disc_loss = 0.010986726044401197
Trained batch 1289 in epoch 2, gen_loss = 0.9766870285189428, disc_loss = 0.010978611261861818
Trained batch 1290 in epoch 2, gen_loss = 0.9766005517714343, disc_loss = 0.010970420164967246
Trained batch 1291 in epoch 2, gen_loss = 0.9765836996006154, disc_loss = 0.010962330343543434
Trained batch 1292 in epoch 2, gen_loss = 0.9764765330459937, disc_loss = 0.010954768833223865
Trained batch 1293 in epoch 2, gen_loss = 0.9764818592454771, disc_loss = 0.010946638652433352
Trained batch 1294 in epoch 2, gen_loss = 0.9764978932137655, disc_loss = 0.01093868038695284
Trained batch 1295 in epoch 2, gen_loss = 0.9764283873876671, disc_loss = 0.010930604047093822
Trained batch 1296 in epoch 2, gen_loss = 0.9763249494336437, disc_loss = 0.0109225349335532
Trained batch 1297 in epoch 2, gen_loss = 0.9763675178695349, disc_loss = 0.010914475841399996
Trained batch 1298 in epoch 2, gen_loss = 0.976418161502336, disc_loss = 0.010906736393112494
Trained batch 1299 in epoch 2, gen_loss = 0.9765184263082651, disc_loss = 0.010898829467478208
Trained batch 1300 in epoch 2, gen_loss = 0.9765120507844314, disc_loss = 0.010890876796702531
Trained batch 1301 in epoch 2, gen_loss = 0.9765716543486958, disc_loss = 0.010883177723592511
Trained batch 1302 in epoch 2, gen_loss = 0.976579301602458, disc_loss = 0.010875317453998567
Trained batch 1303 in epoch 2, gen_loss = 0.9765768913677865, disc_loss = 0.010867458180621898
Trained batch 1304 in epoch 2, gen_loss = 0.9764742969096392, disc_loss = 0.010859553789464807
Trained batch 1305 in epoch 2, gen_loss = 0.9764281673781905, disc_loss = 0.010851736755429798
Trained batch 1306 in epoch 2, gen_loss = 0.9764777136469216, disc_loss = 0.010843987702787515
Trained batch 1307 in epoch 2, gen_loss = 0.9764334466934933, disc_loss = 0.010836403492702148
Trained batch 1308 in epoch 2, gen_loss = 0.9764458328098445, disc_loss = 0.010828434628672112
Trained batch 1309 in epoch 2, gen_loss = 0.9764157788444111, disc_loss = 0.010820697314943051
Trained batch 1310 in epoch 2, gen_loss = 0.9763776137572404, disc_loss = 0.010812757990353554
Trained batch 1311 in epoch 2, gen_loss = 0.9763812491352238, disc_loss = 0.010804996139241423
Trained batch 1312 in epoch 2, gen_loss = 0.9763988457557725, disc_loss = 0.01079748879255612
Trained batch 1313 in epoch 2, gen_loss = 0.9763927588089053, disc_loss = 0.010789675973416015
Trained batch 1314 in epoch 2, gen_loss = 0.9763926225470047, disc_loss = 0.010781987369885605
Trained batch 1315 in epoch 2, gen_loss = 0.9763717234225259, disc_loss = 0.010774108699540074
Trained batch 1316 in epoch 2, gen_loss = 0.9763501789321841, disc_loss = 0.010766212813805997
Trained batch 1317 in epoch 2, gen_loss = 0.9763829880853343, disc_loss = 0.010758528172575348
Trained batch 1318 in epoch 2, gen_loss = 0.9764713862341764, disc_loss = 0.010750773971833442
Trained batch 1319 in epoch 2, gen_loss = 0.9764273163947192, disc_loss = 0.010742926156561942
Trained batch 1320 in epoch 2, gen_loss = 0.9764217256055827, disc_loss = 0.010735090814204252
Trained batch 1321 in epoch 2, gen_loss = 0.9763840918461602, disc_loss = 0.010727616447197878
Trained batch 1322 in epoch 2, gen_loss = 0.9760698576542977, disc_loss = 0.010848526089294347
Trained batch 1323 in epoch 2, gen_loss = 0.9760503188180779, disc_loss = 0.010874482420718212
Trained batch 1324 in epoch 2, gen_loss = 0.9762071025596475, disc_loss = 0.010893035542619642
Trained batch 1325 in epoch 2, gen_loss = 0.9762454854596974, disc_loss = 0.01089816587008476
Trained batch 1326 in epoch 2, gen_loss = 0.9763819759019623, disc_loss = 0.010892113906147307
Trained batch 1327 in epoch 2, gen_loss = 0.9764134056237807, disc_loss = 0.010892822575826073
Trained batch 1328 in epoch 2, gen_loss = 0.9764076273992064, disc_loss = 0.010890643184869169
Trained batch 1329 in epoch 2, gen_loss = 0.9763544981192825, disc_loss = 0.010887300472726688
Trained batch 1330 in epoch 2, gen_loss = 0.9763821650500767, disc_loss = 0.010882270102214053
Trained batch 1331 in epoch 2, gen_loss = 0.9763314269326471, disc_loss = 0.010896191581594793
Trained batch 1332 in epoch 2, gen_loss = 0.9762925807462093, disc_loss = 0.010894392128307714
Trained batch 1333 in epoch 2, gen_loss = 0.9764514297380976, disc_loss = 0.010896020535723657
Trained batch 1334 in epoch 2, gen_loss = 0.9763841572772252, disc_loss = 0.010893997449880424
Trained batch 1335 in epoch 2, gen_loss = 0.9764380457693945, disc_loss = 0.010887293000390975
Trained batch 1336 in epoch 2, gen_loss = 0.9763621314747082, disc_loss = 0.010891109935168028
Trained batch 1337 in epoch 2, gen_loss = 0.9764072001425853, disc_loss = 0.010892206424636166
Trained batch 1338 in epoch 2, gen_loss = 0.9763788020459461, disc_loss = 0.010901773162373072
Trained batch 1339 in epoch 2, gen_loss = 0.9763066479519232, disc_loss = 0.01090337960290594
Trained batch 1340 in epoch 2, gen_loss = 0.9761159119990048, disc_loss = 0.010962522707060557
Trained batch 1341 in epoch 2, gen_loss = 0.9762907279141791, disc_loss = 0.010998389405702746
Trained batch 1342 in epoch 2, gen_loss = 0.9763775358693598, disc_loss = 0.011004671982481031
Trained batch 1343 in epoch 2, gen_loss = 0.9762613190160621, disc_loss = 0.011020117820083084
Trained batch 1344 in epoch 2, gen_loss = 0.9761682453208697, disc_loss = 0.011030700690261016
Trained batch 1345 in epoch 2, gen_loss = 0.9763290679738214, disc_loss = 0.011059410760384488
Trained batch 1346 in epoch 2, gen_loss = 0.9763463660798076, disc_loss = 0.011057117608518104
Trained batch 1347 in epoch 2, gen_loss = 0.9762415315966931, disc_loss = 0.011061906056299507
Trained batch 1348 in epoch 2, gen_loss = 0.9762065221505133, disc_loss = 0.011073783784599911
Trained batch 1349 in epoch 2, gen_loss = 0.9763544834101642, disc_loss = 0.01107445827959088
Trained batch 1350 in epoch 2, gen_loss = 0.9764806077182072, disc_loss = 0.011073666991786425
Trained batch 1351 in epoch 2, gen_loss = 0.9765946332519576, disc_loss = 0.01108541592544261
Trained batch 1352 in epoch 2, gen_loss = 0.9762830683591184, disc_loss = 0.011251419336229243
Trained batch 1353 in epoch 2, gen_loss = 0.9765212753762875, disc_loss = 0.011617335970622715
Trained batch 1354 in epoch 2, gen_loss = 0.9765829412259739, disc_loss = 0.011665596958310808
Trained batch 1355 in epoch 2, gen_loss = 0.9764304342610998, disc_loss = 0.011710776416851849
Trained batch 1356 in epoch 2, gen_loss = 0.976231193972934, disc_loss = 0.011755360829483138
Trained batch 1357 in epoch 2, gen_loss = 0.9760515599872297, disc_loss = 0.01178091847533151
Trained batch 1358 in epoch 2, gen_loss = 0.9760564434519579, disc_loss = 0.011801657428966857
Trained batch 1359 in epoch 2, gen_loss = 0.9761033485479215, disc_loss = 0.011812841467305107
Trained batch 1360 in epoch 2, gen_loss = 0.9760194404172512, disc_loss = 0.011933040798638833
Trained batch 1361 in epoch 2, gen_loss = 0.9758079504914221, disc_loss = 0.01198783277520871
Trained batch 1362 in epoch 2, gen_loss = 0.9755758965006666, disc_loss = 0.012043086457593565
Trained batch 1363 in epoch 2, gen_loss = 0.975591890929032, disc_loss = 0.012060628212144963
Trained batch 1364 in epoch 2, gen_loss = 0.9756541042974144, disc_loss = 0.012124679362782595
Trained batch 1365 in epoch 2, gen_loss = 0.975516601109749, disc_loss = 0.012188179690797682
Trained batch 1366 in epoch 2, gen_loss = 0.9754607685744195, disc_loss = 0.01219136329180317
Trained batch 1367 in epoch 2, gen_loss = 0.9756447451069341, disc_loss = 0.0122221989515406
Trained batch 1368 in epoch 2, gen_loss = 0.9758166010750742, disc_loss = 0.012219328837008492
Trained batch 1369 in epoch 2, gen_loss = 0.975713703188583, disc_loss = 0.01221971675499944
Trained batch 1370 in epoch 2, gen_loss = 0.9757616261249906, disc_loss = 0.012215399293698212
Trained batch 1371 in epoch 2, gen_loss = 0.9757041832535329, disc_loss = 0.012232005741064873
Trained batch 1372 in epoch 2, gen_loss = 0.9758011042333743, disc_loss = 0.012265056793238643
Trained batch 1373 in epoch 2, gen_loss = 0.9758252222551876, disc_loss = 0.01226000110257408
Trained batch 1374 in epoch 2, gen_loss = 0.9758213803117926, disc_loss = 0.012267609681574289
Trained batch 1375 in epoch 2, gen_loss = 0.9759341526430013, disc_loss = 0.012268375395505309
Trained batch 1376 in epoch 2, gen_loss = 0.9760059416510527, disc_loss = 0.012261755829561162
Trained batch 1377 in epoch 2, gen_loss = 0.9761401908404596, disc_loss = 0.01225683405058555
Trained batch 1378 in epoch 2, gen_loss = 0.976225492096708, disc_loss = 0.01225004590872761
Trained batch 1379 in epoch 2, gen_loss = 0.9762789571198864, disc_loss = 0.01224569590537441
Trained batch 1380 in epoch 2, gen_loss = 0.9763088254372682, disc_loss = 0.012239097856614195
Trained batch 1381 in epoch 2, gen_loss = 0.976375195595359, disc_loss = 0.012231483845832534
Trained batch 1382 in epoch 2, gen_loss = 0.9764178427163881, disc_loss = 0.012223951717085606
Trained batch 1383 in epoch 2, gen_loss = 0.9764920835291719, disc_loss = 0.012216347730139
Trained batch 1384 in epoch 2, gen_loss = 0.9765125577200191, disc_loss = 0.012208389641447262
Trained batch 1385 in epoch 2, gen_loss = 0.9764726149485397, disc_loss = 0.012201893495604589
Trained batch 1386 in epoch 2, gen_loss = 0.9765164959147068, disc_loss = 0.0121947442823791
Trained batch 1387 in epoch 2, gen_loss = 0.9766543138697099, disc_loss = 0.012187441396781127
Trained batch 1388 in epoch 2, gen_loss = 0.976796860528387, disc_loss = 0.012179815556777406
Trained batch 1389 in epoch 2, gen_loss = 0.9767443694656701, disc_loss = 0.01217264710033979
Trained batch 1390 in epoch 2, gen_loss = 0.9767502217220797, disc_loss = 0.012164974032035352
Trained batch 1391 in epoch 2, gen_loss = 0.976655712501071, disc_loss = 0.012157739391218404
Trained batch 1392 in epoch 2, gen_loss = 0.9766201561334231, disc_loss = 0.012149992246796361
Trained batch 1393 in epoch 2, gen_loss = 0.9766656561424606, disc_loss = 0.012142446576620164
Trained batch 1394 in epoch 2, gen_loss = 0.9766450347866209, disc_loss = 0.012134738172230054
Trained batch 1395 in epoch 2, gen_loss = 0.9766835378200072, disc_loss = 0.012126898082712216
Trained batch 1396 in epoch 2, gen_loss = 0.9766969970916115, disc_loss = 0.012119178944023168
Trained batch 1397 in epoch 2, gen_loss = 0.9766181630638024, disc_loss = 0.012111264861615019
Trained batch 1398 in epoch 2, gen_loss = 0.9766954532088852, disc_loss = 0.0121046247539216
Trained batch 1399 in epoch 2, gen_loss = 0.9767228530134473, disc_loss = 0.012096615038608434
Trained batch 1400 in epoch 2, gen_loss = 0.9767340625889551, disc_loss = 0.012088559901947222
Trained batch 1401 in epoch 2, gen_loss = 0.9766754483785507, disc_loss = 0.012080991963839148
Trained batch 1402 in epoch 2, gen_loss = 0.9766381449216787, disc_loss = 0.012073761577739036
Trained batch 1403 in epoch 2, gen_loss = 0.9766145337510992, disc_loss = 0.012066079346718302
Trained batch 1404 in epoch 2, gen_loss = 0.9766724252191726, disc_loss = 0.012058149341778047
Trained batch 1405 in epoch 2, gen_loss = 0.9767281597064196, disc_loss = 0.012050293826452221
Trained batch 1406 in epoch 2, gen_loss = 0.9767232007309318, disc_loss = 0.012042592294568291
Trained batch 1407 in epoch 2, gen_loss = 0.976643224797127, disc_loss = 0.012035174943589895
Trained batch 1408 in epoch 2, gen_loss = 0.976650793768989, disc_loss = 0.012027504903044071
Trained batch 1409 in epoch 2, gen_loss = 0.9766187916833459, disc_loss = 0.012019673907854396
Trained batch 1410 in epoch 2, gen_loss = 0.9766328543910399, disc_loss = 0.012012067775704557
Trained batch 1411 in epoch 2, gen_loss = 0.9766836285844404, disc_loss = 0.012004169978598949
Trained batch 1412 in epoch 2, gen_loss = 0.9766347234922357, disc_loss = 0.011996204428609904
Trained batch 1413 in epoch 2, gen_loss = 0.9766253334545179, disc_loss = 0.011988854718399023
Trained batch 1414 in epoch 2, gen_loss = 0.9765594218729241, disc_loss = 0.01198091841684967
Trained batch 1415 in epoch 2, gen_loss = 0.9765271817223501, disc_loss = 0.011973077540398848
Trained batch 1416 in epoch 2, gen_loss = 0.976492549806055, disc_loss = 0.011965014848702186
Trained batch 1417 in epoch 2, gen_loss = 0.9764379786671638, disc_loss = 0.01195710581406404
Trained batch 1418 in epoch 2, gen_loss = 0.9763352941088982, disc_loss = 0.011950188429189854
Trained batch 1419 in epoch 2, gen_loss = 0.97633513014921, disc_loss = 0.011942772960850254
Trained batch 1420 in epoch 2, gen_loss = 0.9763609894474655, disc_loss = 0.011935161553135006
Trained batch 1421 in epoch 2, gen_loss = 0.9763766652504938, disc_loss = 0.011928560964103477
Trained batch 1422 in epoch 2, gen_loss = 0.9763653528413887, disc_loss = 0.011920761772470211
Trained batch 1423 in epoch 2, gen_loss = 0.9762954809441325, disc_loss = 0.011912853111527838
Trained batch 1424 in epoch 2, gen_loss = 0.9762909489765502, disc_loss = 0.011905003241242907
Trained batch 1425 in epoch 2, gen_loss = 0.9764146327052845, disc_loss = 0.011897219656115145
Trained batch 1426 in epoch 2, gen_loss = 0.9763468494345111, disc_loss = 0.011889663353137648
Trained batch 1427 in epoch 2, gen_loss = 0.9763522228690422, disc_loss = 0.011882094950409488
Trained batch 1428 in epoch 2, gen_loss = 0.9764661372250156, disc_loss = 0.011874396684977922
Trained batch 1429 in epoch 2, gen_loss = 0.9763916361165214, disc_loss = 0.011866980832223976
Trained batch 1430 in epoch 2, gen_loss = 0.9763747310821699, disc_loss = 0.011859552730184802
Trained batch 1431 in epoch 2, gen_loss = 0.9763338034712402, disc_loss = 0.011852171300106724
Trained batch 1432 in epoch 2, gen_loss = 0.9763173512537331, disc_loss = 0.01184454573540063
Trained batch 1433 in epoch 2, gen_loss = 0.9763083103394741, disc_loss = 0.011837632574678939
Trained batch 1434 in epoch 2, gen_loss = 0.9762557223283456, disc_loss = 0.011829942997763233
Trained batch 1435 in epoch 2, gen_loss = 0.9763037654516756, disc_loss = 0.011822309673762677
Trained batch 1436 in epoch 2, gen_loss = 0.9763667187760419, disc_loss = 0.01181441917290416
Trained batch 1437 in epoch 2, gen_loss = 0.9764338134061312, disc_loss = 0.011806670465707061
Trained batch 1438 in epoch 2, gen_loss = 0.9763879960323888, disc_loss = 0.011799103159815347
Trained batch 1439 in epoch 2, gen_loss = 0.9763829468852944, disc_loss = 0.011791838833354025
Trained batch 1440 in epoch 2, gen_loss = 0.976199825384152, disc_loss = 0.011802361378207735
Trained batch 1441 in epoch 2, gen_loss = 0.9761228296859255, disc_loss = 0.01180427715651518
Trained batch 1442 in epoch 2, gen_loss = 0.9761408412943924, disc_loss = 0.01180546816829876
Trained batch 1443 in epoch 2, gen_loss = 0.97625363236319, disc_loss = 0.011805640245027392
Trained batch 1444 in epoch 2, gen_loss = 0.9763264977808229, disc_loss = 0.011801702847340141
Trained batch 1445 in epoch 2, gen_loss = 0.9763462630874719, disc_loss = 0.01183660094824943
Trained batch 1446 in epoch 2, gen_loss = 0.9761079530017328, disc_loss = 0.012049605531612207
Trained batch 1447 in epoch 2, gen_loss = 0.9761008519000112, disc_loss = 0.012199792613224538
Trained batch 1448 in epoch 2, gen_loss = 0.976163745666883, disc_loss = 0.01236059758183916
Trained batch 1449 in epoch 2, gen_loss = 0.9761174517664416, disc_loss = 0.012381010421407249
Trained batch 1450 in epoch 2, gen_loss = 0.9759595938422284, disc_loss = 0.012394474454491761
Trained batch 1451 in epoch 2, gen_loss = 0.9758883492595236, disc_loss = 0.012394502357218656
Trained batch 1452 in epoch 2, gen_loss = 0.975928727750194, disc_loss = 0.012390135785264168
Trained batch 1453 in epoch 2, gen_loss = 0.9759222114512485, disc_loss = 0.012383428582472617
Trained batch 1454 in epoch 2, gen_loss = 0.9759352922849229, disc_loss = 0.0123760275610745
Trained batch 1455 in epoch 2, gen_loss = 0.9758603186807134, disc_loss = 0.012368333895430404
Trained batch 1456 in epoch 2, gen_loss = 0.9758749235224544, disc_loss = 0.012361619844198528
Trained batch 1457 in epoch 2, gen_loss = 0.9759772096559998, disc_loss = 0.012354617377801252
Trained batch 1458 in epoch 2, gen_loss = 0.9759678879447634, disc_loss = 0.012347089130775472
Trained batch 1459 in epoch 2, gen_loss = 0.9758786211683326, disc_loss = 0.012339405970223732
Trained batch 1460 in epoch 2, gen_loss = 0.9758319866567503, disc_loss = 0.012332777306166574
Trained batch 1461 in epoch 2, gen_loss = 0.975929516162494, disc_loss = 0.012325161820208774
Trained batch 1462 in epoch 2, gen_loss = 0.975765167322374, disc_loss = 0.012386705840333675
Trained batch 1463 in epoch 2, gen_loss = 0.9757457796911724, disc_loss = 0.012402193663422975
Trained batch 1464 in epoch 2, gen_loss = 0.9757231491417608, disc_loss = 0.012423241397194284
Trained batch 1465 in epoch 2, gen_loss = 0.9758263369780771, disc_loss = 0.012426795476684181
Trained batch 1466 in epoch 2, gen_loss = 0.9758194894228326, disc_loss = 0.01242648814147784
Trained batch 1467 in epoch 2, gen_loss = 0.9759138968318944, disc_loss = 0.012421105443043203
Trained batch 1468 in epoch 2, gen_loss = 0.9759358578672856, disc_loss = 0.012416444044595697
Trained batch 1469 in epoch 2, gen_loss = 0.9761214186139658, disc_loss = 0.012412646087203301
Trained batch 1470 in epoch 2, gen_loss = 0.9761856292316818, disc_loss = 0.012408911771591142
Trained batch 1471 in epoch 2, gen_loss = 0.9763129050236034, disc_loss = 0.012403750322055597
Trained batch 1472 in epoch 2, gen_loss = 0.9764279087870119, disc_loss = 0.012398609855811024
Trained batch 1473 in epoch 2, gen_loss = 0.9764755722059485, disc_loss = 0.012393513103957152
Trained batch 1474 in epoch 2, gen_loss = 0.9766052786374496, disc_loss = 0.012387767449905307
Trained batch 1475 in epoch 2, gen_loss = 0.9767221290325407, disc_loss = 0.012381857750384606
Trained batch 1476 in epoch 2, gen_loss = 0.9768600503011741, disc_loss = 0.012378827646341914
Trained batch 1477 in epoch 2, gen_loss = 0.9769177374320359, disc_loss = 0.01237264603215077
Trained batch 1478 in epoch 2, gen_loss = 0.9770849083548385, disc_loss = 0.012366156686478981
Trained batch 1479 in epoch 2, gen_loss = 0.9771044016287134, disc_loss = 0.012359704404937204
Trained batch 1480 in epoch 2, gen_loss = 0.9772516496675712, disc_loss = 0.012355270818634252
Trained batch 1481 in epoch 2, gen_loss = 0.977309433675488, disc_loss = 0.01234813441469632
Trained batch 1482 in epoch 2, gen_loss = 0.9774444463762655, disc_loss = 0.012340781263757776
Trained batch 1483 in epoch 2, gen_loss = 0.977443760778062, disc_loss = 0.01233406652465169
Trained batch 1484 in epoch 2, gen_loss = 0.9775149812602033, disc_loss = 0.012326674930585127
Trained batch 1485 in epoch 2, gen_loss = 0.9775933438804236, disc_loss = 0.012318982291637016
Trained batch 1486 in epoch 2, gen_loss = 0.9775999531941519, disc_loss = 0.012313451269258218
Trained batch 1487 in epoch 2, gen_loss = 0.977609556128261, disc_loss = 0.012307190552062195
Trained batch 1488 in epoch 2, gen_loss = 0.9778202987501812, disc_loss = 0.012302118168563362
Trained batch 1489 in epoch 2, gen_loss = 0.9778823044476093, disc_loss = 0.012302584163125779
Trained batch 1490 in epoch 2, gen_loss = 0.9779368102510531, disc_loss = 0.01229664501059478
Trained batch 1491 in epoch 2, gen_loss = 0.9779276067226246, disc_loss = 0.012293032164986298
Trained batch 1492 in epoch 2, gen_loss = 0.977990470711848, disc_loss = 0.012286548768323007
Trained batch 1493 in epoch 2, gen_loss = 0.9781153410314077, disc_loss = 0.012279888034026467
Trained batch 1494 in epoch 2, gen_loss = 0.9782389025225687, disc_loss = 0.012274059221883581
Trained batch 1495 in epoch 2, gen_loss = 0.9781817074287384, disc_loss = 0.012268074840135415
Trained batch 1496 in epoch 2, gen_loss = 0.9781886558574123, disc_loss = 0.01226133761806793
Trained batch 1497 in epoch 2, gen_loss = 0.9782183095912271, disc_loss = 0.012256242932928341
Trained batch 1498 in epoch 2, gen_loss = 0.9782095530018797, disc_loss = 0.012249048388677415
Trained batch 1499 in epoch 2, gen_loss = 0.9781718978087107, disc_loss = 0.01224273924320005
Trained batch 1500 in epoch 2, gen_loss = 0.9782509355049464, disc_loss = 0.01223523039655415
Trained batch 1501 in epoch 2, gen_loss = 0.9783726025834064, disc_loss = 0.012228873127830536
Trained batch 1502 in epoch 2, gen_loss = 0.9783494643029259, disc_loss = 0.012221801321693595
Trained batch 1503 in epoch 2, gen_loss = 0.9783774752249109, disc_loss = 0.012214607263810282
Trained batch 1504 in epoch 2, gen_loss = 0.9784392112117273, disc_loss = 0.012207408272467888
Trained batch 1505 in epoch 2, gen_loss = 0.978469996813284, disc_loss = 0.01220036957271188
Trained batch 1506 in epoch 2, gen_loss = 0.9785812726935252, disc_loss = 0.012194347770366442
Trained batch 1507 in epoch 2, gen_loss = 0.9786107710881322, disc_loss = 0.012187109928908856
Trained batch 1508 in epoch 2, gen_loss = 0.9786385743328876, disc_loss = 0.012181268847367564
Trained batch 1509 in epoch 2, gen_loss = 0.9785870466405983, disc_loss = 0.01217511417602485
Trained batch 1510 in epoch 2, gen_loss = 0.9786488780669232, disc_loss = 0.012170158540618913
Trained batch 1511 in epoch 2, gen_loss = 0.978667216444457, disc_loss = 0.012163093929798354
Trained batch 1512 in epoch 2, gen_loss = 0.9786481961302622, disc_loss = 0.0121593682688411
Trained batch 1513 in epoch 2, gen_loss = 0.9788091532305335, disc_loss = 0.012158072127859432
Trained batch 1514 in epoch 2, gen_loss = 0.9789129079371789, disc_loss = 0.012152219495448674
Trained batch 1515 in epoch 2, gen_loss = 0.9789367055515501, disc_loss = 0.012145023679600029
Trained batch 1516 in epoch 2, gen_loss = 0.9789344262510989, disc_loss = 0.012137864343814328
Trained batch 1517 in epoch 2, gen_loss = 0.9789897017328164, disc_loss = 0.012130629450608258
Trained batch 1518 in epoch 2, gen_loss = 0.9791070803597697, disc_loss = 0.012123082270007335
Trained batch 1519 in epoch 2, gen_loss = 0.9790859823164187, disc_loss = 0.01211845721091346
Trained batch 1520 in epoch 2, gen_loss = 0.9791087237413897, disc_loss = 0.012111562221116012
Trained batch 1521 in epoch 2, gen_loss = 0.9791525495819914, disc_loss = 0.012105212512503485
Trained batch 1522 in epoch 2, gen_loss = 0.9791938380355986, disc_loss = 0.012098006956676451
Trained batch 1523 in epoch 2, gen_loss = 0.9793068391131604, disc_loss = 0.012091566787400464
Trained batch 1524 in epoch 2, gen_loss = 0.979379002852518, disc_loss = 0.012084672039519751
Trained batch 1525 in epoch 2, gen_loss = 0.9794356387845811, disc_loss = 0.012077492476814167
Trained batch 1526 in epoch 2, gen_loss = 0.9795099482789255, disc_loss = 0.012070374751682184
Trained batch 1527 in epoch 2, gen_loss = 0.9795501497403489, disc_loss = 0.012063668640545285
Trained batch 1528 in epoch 2, gen_loss = 0.9795783609249297, disc_loss = 0.012056522204946029
Trained batch 1529 in epoch 2, gen_loss = 0.9796092247651293, disc_loss = 0.01204906846963484
Trained batch 1530 in epoch 2, gen_loss = 0.9796307895948184, disc_loss = 0.012041669954247115
Trained batch 1531 in epoch 2, gen_loss = 0.9796335315112968, disc_loss = 0.01203478995141301
Trained batch 1532 in epoch 2, gen_loss = 0.9796727026356488, disc_loss = 0.01202773565043126
Trained batch 1533 in epoch 2, gen_loss = 0.9796786244565225, disc_loss = 0.01202069101669987
Trained batch 1534 in epoch 2, gen_loss = 0.9797312817278436, disc_loss = 0.012014162932835058
Trained batch 1535 in epoch 2, gen_loss = 0.9798021720101436, disc_loss = 0.012006964765002218
Trained batch 1536 in epoch 2, gen_loss = 0.979915298031923, disc_loss = 0.012000292799542806
Trained batch 1537 in epoch 2, gen_loss = 0.9799371684171133, disc_loss = 0.011993200815511657
Trained batch 1538 in epoch 2, gen_loss = 0.9799741672338643, disc_loss = 0.01198699521512045
Trained batch 1539 in epoch 2, gen_loss = 0.9799053413527352, disc_loss = 0.01198162512230844
Trained batch 1540 in epoch 2, gen_loss = 0.9799204763075812, disc_loss = 0.011974939004029163
Trained batch 1541 in epoch 2, gen_loss = 0.9800202125241321, disc_loss = 0.011969665778243984
Trained batch 1542 in epoch 2, gen_loss = 0.9800137776642439, disc_loss = 0.011963062565978943
Trained batch 1543 in epoch 2, gen_loss = 0.980073323212757, disc_loss = 0.01195722422999851
Trained batch 1544 in epoch 2, gen_loss = 0.9800423128319404, disc_loss = 0.01195031325694499
Trained batch 1545 in epoch 2, gen_loss = 0.9800904207365325, disc_loss = 0.011943731945171293
Trained batch 1546 in epoch 2, gen_loss = 0.9801003086852041, disc_loss = 0.011936556651126341
Trained batch 1547 in epoch 2, gen_loss = 0.9801445180593535, disc_loss = 0.011929534736795722
Trained batch 1548 in epoch 2, gen_loss = 0.9800907205658008, disc_loss = 0.011922695888720424
Trained batch 1549 in epoch 2, gen_loss = 0.9801280000901992, disc_loss = 0.01191559126251377
Trained batch 1550 in epoch 2, gen_loss = 0.9800422781133252, disc_loss = 0.011909586643861087
Trained batch 1551 in epoch 2, gen_loss = 0.9800635952617704, disc_loss = 0.011904403831461413
Trained batch 1552 in epoch 2, gen_loss = 0.9801687071266592, disc_loss = 0.011899501870691246
Trained batch 1553 in epoch 2, gen_loss = 0.9802048650487509, disc_loss = 0.011893064071500118
Trained batch 1554 in epoch 2, gen_loss = 0.9801982618221516, disc_loss = 0.011886868468999348
Trained batch 1555 in epoch 2, gen_loss = 0.9802153619212173, disc_loss = 0.011880002024900443
Trained batch 1556 in epoch 2, gen_loss = 0.9802432214899865, disc_loss = 0.0118732027767131
Trained batch 1557 in epoch 2, gen_loss = 0.9802888895795037, disc_loss = 0.01186839377489485
Trained batch 1558 in epoch 2, gen_loss = 0.9803405949670279, disc_loss = 0.011862256349701521
Trained batch 1559 in epoch 2, gen_loss = 0.980409043492415, disc_loss = 0.011856725082981986
Trained batch 1560 in epoch 2, gen_loss = 0.9804651180495825, disc_loss = 0.011851092303178615
Trained batch 1561 in epoch 2, gen_loss = 0.9805796363900169, disc_loss = 0.011844816099649305
Trained batch 1562 in epoch 2, gen_loss = 0.980615246623888, disc_loss = 0.011838407130393254
Trained batch 1563 in epoch 2, gen_loss = 0.9806368370037859, disc_loss = 0.011841769872494983
Trained batch 1564 in epoch 2, gen_loss = 0.9807368282312021, disc_loss = 0.011838498275791006
Trained batch 1565 in epoch 2, gen_loss = 0.9807645817064843, disc_loss = 0.011832941953284014
Trained batch 1566 in epoch 2, gen_loss = 0.9807925395472611, disc_loss = 0.011826350793725945
Trained batch 1567 in epoch 2, gen_loss = 0.9807946935144006, disc_loss = 0.011819738551060496
Trained batch 1568 in epoch 2, gen_loss = 0.9807624231105097, disc_loss = 0.011813210720222187
Trained batch 1569 in epoch 2, gen_loss = 0.9808943437922533, disc_loss = 0.011807229676822224
Trained batch 1570 in epoch 2, gen_loss = 0.9808903393056422, disc_loss = 0.01180069637718272
Trained batch 1571 in epoch 2, gen_loss = 0.9808706223358028, disc_loss = 0.011799708432178771
Trained batch 1572 in epoch 2, gen_loss = 0.9807672001947207, disc_loss = 0.011804147744076166
Trained batch 1573 in epoch 2, gen_loss = 0.9807862015358223, disc_loss = 0.011798102059364591
Trained batch 1574 in epoch 2, gen_loss = 0.9807679538499742, disc_loss = 0.011791448987214752
Trained batch 1575 in epoch 2, gen_loss = 0.9807664411246474, disc_loss = 0.011786290723025304
Trained batch 1576 in epoch 2, gen_loss = 0.9807949718902893, disc_loss = 0.011779775886320124
Trained batch 1577 in epoch 2, gen_loss = 0.9808297789973149, disc_loss = 0.011774647359345853
Trained batch 1578 in epoch 2, gen_loss = 0.980819333535799, disc_loss = 0.011767745152483869
Trained batch 1579 in epoch 2, gen_loss = 0.9808872471504574, disc_loss = 0.01176123718739947
Trained batch 1580 in epoch 2, gen_loss = 0.9809066979738823, disc_loss = 0.011754380171441996
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.1504936218261719, disc_loss = 0.0008959223632700741
Trained batch 1 in epoch 3, gen_loss = 1.0237562656402588, disc_loss = 0.0008020089589990675
Trained batch 2 in epoch 3, gen_loss = 0.9983441034952799, disc_loss = 0.001153252514389654
Trained batch 3 in epoch 3, gen_loss = 1.0085965991020203, disc_loss = 0.0012010523350909352
Trained batch 4 in epoch 3, gen_loss = 1.0149579048156738, disc_loss = 0.001945280097424984
Trained batch 5 in epoch 3, gen_loss = 1.013499140739441, disc_loss = 0.0022325042712812624
Trained batch 6 in epoch 3, gen_loss = 1.022085496357509, disc_loss = 0.002380215795710683
Trained batch 7 in epoch 3, gen_loss = 1.0256119668483734, disc_loss = 0.002247279684524983
Trained batch 8 in epoch 3, gen_loss = 1.0269447962443035, disc_loss = 0.0020967382782449326
Trained batch 9 in epoch 3, gen_loss = 1.0176626980304717, disc_loss = 0.0020477043348364533
Trained batch 10 in epoch 3, gen_loss = 0.9980758699503812, disc_loss = 0.006198506622405892
Trained batch 11 in epoch 3, gen_loss = 0.9748761355876923, disc_loss = 0.012205252569401637
Trained batch 12 in epoch 3, gen_loss = 0.9863850887005146, disc_loss = 0.011467468969595548
Trained batch 13 in epoch 3, gen_loss = 0.9858029655047825, disc_loss = 0.010830743013814623
Trained batch 14 in epoch 3, gen_loss = 0.9924758831659953, disc_loss = 0.010624528435679773
Trained batch 15 in epoch 3, gen_loss = 1.0012477859854698, disc_loss = 0.010388857925136108
Trained batch 16 in epoch 3, gen_loss = 1.0072147916345036, disc_loss = 0.009990000693291864
Trained batch 17 in epoch 3, gen_loss = 1.011705133650038, disc_loss = 0.009529886288671859
Trained batch 18 in epoch 3, gen_loss = 1.0130056142807007, disc_loss = 0.009173141718891106
Trained batch 19 in epoch 3, gen_loss = 1.0063117027282715, disc_loss = 0.008814968261867761
Trained batch 20 in epoch 3, gen_loss = 1.0089811143420993, disc_loss = 0.008516682932774225
Trained batch 21 in epoch 3, gen_loss = 1.00747088952498, disc_loss = 0.008188659812069753
Trained batch 22 in epoch 3, gen_loss = 1.0045796269955842, disc_loss = 0.007880227549163543
Trained batch 23 in epoch 3, gen_loss = 1.005777935187022, disc_loss = 0.007617923411695908
Trained batch 24 in epoch 3, gen_loss = 1.0110304260253906, disc_loss = 0.007356233010068536
Trained batch 25 in epoch 3, gen_loss = 1.007605607693012, disc_loss = 0.0071159821326056355
Trained batch 26 in epoch 3, gen_loss = 1.0099819412937872, disc_loss = 0.006887029160107313
Trained batch 27 in epoch 3, gen_loss = 1.0113330227988107, disc_loss = 0.006686870305981886
Trained batch 28 in epoch 3, gen_loss = 1.0067704258293941, disc_loss = 0.0064909536660456195
Trained batch 29 in epoch 3, gen_loss = 1.0061790585517882, disc_loss = 0.0063103768567088995
Trained batch 30 in epoch 3, gen_loss = 1.008494654009419, disc_loss = 0.0061252463980758145
Trained batch 31 in epoch 3, gen_loss = 1.0039704889059067, disc_loss = 0.005963270745269256
Trained batch 32 in epoch 3, gen_loss = 1.0039040933955798, disc_loss = 0.00580338696652854
Trained batch 33 in epoch 3, gen_loss = 1.0070976614952087, disc_loss = 0.005661372848622063
Trained batch 34 in epoch 3, gen_loss = 1.0075179815292359, disc_loss = 0.005532270769721695
Trained batch 35 in epoch 3, gen_loss = 1.0067517062028248, disc_loss = 0.005413544535662772
Trained batch 36 in epoch 3, gen_loss = 1.0066878505655237, disc_loss = 0.005287498621131621
Trained batch 37 in epoch 3, gen_loss = 1.0031055337504338, disc_loss = 0.005170414576576532
Trained batch 38 in epoch 3, gen_loss = 0.999206393192976, disc_loss = 0.00506178378754367
Trained batch 39 in epoch 3, gen_loss = 0.9984175488352776, disc_loss = 0.004953335963364225
Trained batch 40 in epoch 3, gen_loss = 0.9972191089537086, disc_loss = 0.004872188152370565
Trained batch 41 in epoch 3, gen_loss = 0.9967951632681347, disc_loss = 0.004782097434924383
Trained batch 42 in epoch 3, gen_loss = 0.9936633276384931, disc_loss = 0.0046982233409856465
Trained batch 43 in epoch 3, gen_loss = 0.991433625871485, disc_loss = 0.004606464826131493
Trained batch 44 in epoch 3, gen_loss = 0.9911547011799282, disc_loss = 0.0045213727422782945
Trained batch 45 in epoch 3, gen_loss = 0.989759905182797, disc_loss = 0.004436436380036985
Trained batch 46 in epoch 3, gen_loss = 0.9913383811078174, disc_loss = 0.004392604970254321
Trained batch 47 in epoch 3, gen_loss = 0.9900472151736418, disc_loss = 0.004330210268866115
Trained batch 48 in epoch 3, gen_loss = 0.9882944396563939, disc_loss = 0.004271110008964885
Trained batch 49 in epoch 3, gen_loss = 0.9860549628734588, disc_loss = 0.004394386711064726
Trained batch 50 in epoch 3, gen_loss = 0.9900195025930217, disc_loss = 0.004416052756520609
Trained batch 51 in epoch 3, gen_loss = 0.9897020654036448, disc_loss = 0.0043591152934823185
Trained batch 52 in epoch 3, gen_loss = 0.9839013814926147, disc_loss = 0.005046353818198561
Trained batch 53 in epoch 3, gen_loss = 0.9859338137838576, disc_loss = 0.007196845092241549
Trained batch 54 in epoch 3, gen_loss = 0.9866716081445868, disc_loss = 0.007242708672261374
Trained batch 55 in epoch 3, gen_loss = 0.9818006423967225, disc_loss = 0.008076593631163373
Trained batch 56 in epoch 3, gen_loss = 0.9747594417187205, disc_loss = 0.011483488197993944
Trained batch 57 in epoch 3, gen_loss = 0.9810350547576773, disc_loss = 0.016597012846714592
Trained batch 58 in epoch 3, gen_loss = 0.9824264867831085, disc_loss = 0.016731640910019434
Trained batch 59 in epoch 3, gen_loss = 0.9787954419851304, disc_loss = 0.01705728643767846
Trained batch 60 in epoch 3, gen_loss = 0.9735197737568715, disc_loss = 0.018679243850246927
Trained batch 61 in epoch 3, gen_loss = 0.9737754569899651, disc_loss = 0.018639446072836196
Trained batch 62 in epoch 3, gen_loss = 0.9734223541759309, disc_loss = 0.018789150280922297
Trained batch 63 in epoch 3, gen_loss = 0.9770349832251668, disc_loss = 0.019079714011240867
Trained batch 64 in epoch 3, gen_loss = 0.9766907224288354, disc_loss = 0.018934646694777676
Trained batch 65 in epoch 3, gen_loss = 0.9799563731207992, disc_loss = 0.018838651832828127
Trained batch 66 in epoch 3, gen_loss = 0.9793795498449411, disc_loss = 0.018956185570473214
Trained batch 67 in epoch 3, gen_loss = 0.97756426737589, disc_loss = 0.019002304318265113
Trained batch 68 in epoch 3, gen_loss = 0.9801209448040396, disc_loss = 0.01896030446548231
Trained batch 69 in epoch 3, gen_loss = 0.9816945901938847, disc_loss = 0.01875222072703764
Trained batch 70 in epoch 3, gen_loss = 0.9828445835852287, disc_loss = 0.018619996326660712
Trained batch 71 in epoch 3, gen_loss = 0.983254703382651, disc_loss = 0.018436267385065246
Trained batch 72 in epoch 3, gen_loss = 0.9835084880868049, disc_loss = 0.0182502174906254
Trained batch 73 in epoch 3, gen_loss = 0.9852025790794475, disc_loss = 0.018080008035286557
Trained batch 74 in epoch 3, gen_loss = 0.9858737333615621, disc_loss = 0.017874302067793904
Trained batch 75 in epoch 3, gen_loss = 0.9883237473274532, disc_loss = 0.01773160934834251
Trained batch 76 in epoch 3, gen_loss = 0.9889882036617824, disc_loss = 0.017539329565275315
Trained batch 77 in epoch 3, gen_loss = 0.9901295862136743, disc_loss = 0.017346073125596516
Trained batch 78 in epoch 3, gen_loss = 0.9895232742345785, disc_loss = 0.017186120923172354
Trained batch 79 in epoch 3, gen_loss = 0.9884517692029476, disc_loss = 0.01716509758698521
Trained batch 80 in epoch 3, gen_loss = 0.990875216913812, disc_loss = 0.017053091224501438
Trained batch 81 in epoch 3, gen_loss = 0.9929541894575444, disc_loss = 0.016983916283096756
Trained batch 82 in epoch 3, gen_loss = 0.9951277892273592, disc_loss = 0.016840997863145746
Trained batch 83 in epoch 3, gen_loss = 0.9948453328439167, disc_loss = 0.016816963334955897
Trained batch 84 in epoch 3, gen_loss = 0.9969795191989226, disc_loss = 0.016695762243505347
Trained batch 85 in epoch 3, gen_loss = 0.9975254722805911, disc_loss = 0.01738536682082773
Trained batch 86 in epoch 3, gen_loss = 0.9972067187572348, disc_loss = 0.01762439408366322
Trained batch 87 in epoch 3, gen_loss = 0.9929508519443598, disc_loss = 0.018611034752790478
Trained batch 88 in epoch 3, gen_loss = 0.9891433796186125, disc_loss = 0.021305618529061505
Trained batch 89 in epoch 3, gen_loss = 0.9939780804846022, disc_loss = 0.026266587643314982
Trained batch 90 in epoch 3, gen_loss = 0.992794889670152, disc_loss = 0.027704426582524002
Trained batch 91 in epoch 3, gen_loss = 0.9889879388653714, disc_loss = 0.02848560609424527
Trained batch 92 in epoch 3, gen_loss = 0.9867680547057941, disc_loss = 0.029183453483436938
Trained batch 93 in epoch 3, gen_loss = 0.9875841812884554, disc_loss = 0.02940516129626516
Trained batch 94 in epoch 3, gen_loss = 0.9888511356554534, disc_loss = 0.031331638946492026
Trained batch 95 in epoch 3, gen_loss = 0.9885292686522007, disc_loss = 0.031689285643854724
Trained batch 96 in epoch 3, gen_loss = 0.9871625353380576, disc_loss = 0.03198454382507726
Trained batch 97 in epoch 3, gen_loss = 0.9859529983024208, disc_loss = 0.031837513512333056
Trained batch 98 in epoch 3, gen_loss = 0.9841037549153723, disc_loss = 0.03368730838716293
Trained batch 99 in epoch 3, gen_loss = 0.9821760135889054, disc_loss = 0.034489992590388284
Trained batch 100 in epoch 3, gen_loss = 0.9792265236967861, disc_loss = 0.03466935067940134
Trained batch 101 in epoch 3, gen_loss = 0.9778402476918464, disc_loss = 0.03466985918303002
Trained batch 102 in epoch 3, gen_loss = 0.9763932419054716, disc_loss = 0.03497103865154413
Trained batch 103 in epoch 3, gen_loss = 0.978683586877126, disc_loss = 0.03496288636569471
Trained batch 104 in epoch 3, gen_loss = 0.9771477914991833, disc_loss = 0.0348322327947244
Trained batch 105 in epoch 3, gen_loss = 0.9779210709175974, disc_loss = 0.0345831803553562
Trained batch 106 in epoch 3, gen_loss = 0.9781324350945303, disc_loss = 0.034324435450824274
Trained batch 107 in epoch 3, gen_loss = 0.9775691871289853, disc_loss = 0.034045632733506394
Trained batch 108 in epoch 3, gen_loss = 0.9785728738942278, disc_loss = 0.03378712991145739
Trained batch 109 in epoch 3, gen_loss = 0.978667064146562, disc_loss = 0.03352248133054342
Trained batch 110 in epoch 3, gen_loss = 0.9766994274414338, disc_loss = 0.03338211527627029
Trained batch 111 in epoch 3, gen_loss = 0.9766096589820725, disc_loss = 0.033112531264902954
Trained batch 112 in epoch 3, gen_loss = 0.9767567657791407, disc_loss = 0.032846131888465475
Trained batch 113 in epoch 3, gen_loss = 0.9776827358362967, disc_loss = 0.032595946150219164
Trained batch 114 in epoch 3, gen_loss = 0.978092973128609, disc_loss = 0.03234363039449343
Trained batch 115 in epoch 3, gen_loss = 0.9781458156889883, disc_loss = 0.03293034874187815
Trained batch 116 in epoch 3, gen_loss = 0.974076070337214, disc_loss = 0.03452605024899523
Trained batch 117 in epoch 3, gen_loss = 0.9738989113751104, disc_loss = 0.03442754031265533
Trained batch 118 in epoch 3, gen_loss = 0.9759518554230698, disc_loss = 0.037651923804997836
Trained batch 119 in epoch 3, gen_loss = 0.9761168842514356, disc_loss = 0.03742280497584337
Trained batch 120 in epoch 3, gen_loss = 0.9753906899247288, disc_loss = 0.03728005604737646
Trained batch 121 in epoch 3, gen_loss = 0.9738452185372837, disc_loss = 0.03733463179926983
Trained batch 122 in epoch 3, gen_loss = 0.9713604140087841, disc_loss = 0.039234655272268604
Trained batch 123 in epoch 3, gen_loss = 0.9717938380856668, disc_loss = 0.04077530974398307
Trained batch 124 in epoch 3, gen_loss = 0.9710720043182373, disc_loss = 0.04162690792139619
Trained batch 125 in epoch 3, gen_loss = 0.9675250933283851, disc_loss = 0.04242416752764719
Trained batch 126 in epoch 3, gen_loss = 0.9640847036219019, disc_loss = 0.04347691512538311
Trained batch 127 in epoch 3, gen_loss = 0.961663834284991, disc_loss = 0.04389778435051994
Trained batch 128 in epoch 3, gen_loss = 0.9635774751966314, disc_loss = 0.043800393660018554
Trained batch 129 in epoch 3, gen_loss = 0.9633376988080832, disc_loss = 0.044417226636030066
Trained batch 130 in epoch 3, gen_loss = 0.9619576098354718, disc_loss = 0.04419572031363589
Trained batch 131 in epoch 3, gen_loss = 0.9590586676742091, disc_loss = 0.0456457599198488
Trained batch 132 in epoch 3, gen_loss = 0.9598031761054706, disc_loss = 0.045597505747844796
Trained batch 133 in epoch 3, gen_loss = 0.9611068661533185, disc_loss = 0.04573817556609275
Trained batch 134 in epoch 3, gen_loss = 0.9610520287796304, disc_loss = 0.045546818634115714
Trained batch 135 in epoch 3, gen_loss = 0.9588843886466587, disc_loss = 0.04621845952094779
Trained batch 136 in epoch 3, gen_loss = 0.9589494331909793, disc_loss = 0.04774213802446713
Trained batch 137 in epoch 3, gen_loss = 0.9586054134196129, disc_loss = 0.04759235397922685
Trained batch 138 in epoch 3, gen_loss = 0.9560597324542862, disc_loss = 0.048006641979181884
Trained batch 139 in epoch 3, gen_loss = 0.9560975926262992, disc_loss = 0.04770394321447904
Trained batch 140 in epoch 3, gen_loss = 0.9570358847895413, disc_loss = 0.04739398400196872
Trained batch 141 in epoch 3, gen_loss = 0.9568790877369088, disc_loss = 0.04711130658135106
Trained batch 142 in epoch 3, gen_loss = 0.9583735607720755, disc_loss = 0.04721177445473866
Trained batch 143 in epoch 3, gen_loss = 0.9572614497608609, disc_loss = 0.04712837500442725
Trained batch 144 in epoch 3, gen_loss = 0.9560293912887573, disc_loss = 0.0478416175734059
Trained batch 145 in epoch 3, gen_loss = 0.9578225530990182, disc_loss = 0.047694378040494936
Trained batch 146 in epoch 3, gen_loss = 0.9580655560201529, disc_loss = 0.047799978968307226
Trained batch 147 in epoch 3, gen_loss = 0.957343102306933, disc_loss = 0.047592424226742286
Trained batch 148 in epoch 3, gen_loss = 0.9561632595606299, disc_loss = 0.04731327073957971
Trained batch 149 in epoch 3, gen_loss = 0.9555577826499939, disc_loss = 0.04728222654433921
Trained batch 150 in epoch 3, gen_loss = 0.9544140850471345, disc_loss = 0.047116050619280446
Trained batch 151 in epoch 3, gen_loss = 0.9541528032798516, disc_loss = 0.047047734223030456
Trained batch 152 in epoch 3, gen_loss = 0.953767724286497, disc_loss = 0.04685653624310481
Trained batch 153 in epoch 3, gen_loss = 0.9544566265948407, disc_loss = 0.046586046656805345
Trained batch 154 in epoch 3, gen_loss = 0.954375341246205, disc_loss = 0.04642637423314755
Trained batch 155 in epoch 3, gen_loss = 0.9532114534805982, disc_loss = 0.04644108600302552
Trained batch 156 in epoch 3, gen_loss = 0.9547079421912029, disc_loss = 0.046205400936394504
Trained batch 157 in epoch 3, gen_loss = 0.9554232343842711, disc_loss = 0.04622036512407675
Trained batch 158 in epoch 3, gen_loss = 0.9547748648145664, disc_loss = 0.046586310586880356
Trained batch 159 in epoch 3, gen_loss = 0.9557794161140919, disc_loss = 0.04633384129483602
Trained batch 160 in epoch 3, gen_loss = 0.9572283459005889, disc_loss = 0.046074525403257995
Trained batch 161 in epoch 3, gen_loss = 0.9580589694741332, disc_loss = 0.04605555953098645
Trained batch 162 in epoch 3, gen_loss = 0.9575144615641401, disc_loss = 0.04587702668183397
Trained batch 163 in epoch 3, gen_loss = 0.9562368044039098, disc_loss = 0.04577922075064058
Trained batch 164 in epoch 3, gen_loss = 0.9571688348596746, disc_loss = 0.04557425626059712
Trained batch 165 in epoch 3, gen_loss = 0.958551330738757, disc_loss = 0.045323562204518004
Trained batch 166 in epoch 3, gen_loss = 0.9584904766368295, disc_loss = 0.04507696699604816
Trained batch 167 in epoch 3, gen_loss = 0.9591856123436064, disc_loss = 0.04485134173314907
Trained batch 168 in epoch 3, gen_loss = 0.9590485117139196, disc_loss = 0.044620691913665
Trained batch 169 in epoch 3, gen_loss = 0.9590150822611416, disc_loss = 0.04438150138799649
Trained batch 170 in epoch 3, gen_loss = 0.9582958650170711, disc_loss = 0.044176571043235476
Trained batch 171 in epoch 3, gen_loss = 0.9587740936251574, disc_loss = 0.04393543926579336
Trained batch 172 in epoch 3, gen_loss = 0.9595011834464321, disc_loss = 0.04370669880410861
Trained batch 173 in epoch 3, gen_loss = 0.95923327440503, disc_loss = 0.04347647021420236
Trained batch 174 in epoch 3, gen_loss = 0.9594493062155587, disc_loss = 0.043347596976506926
Trained batch 175 in epoch 3, gen_loss = 0.9584562663327564, disc_loss = 0.04329398520282914
Trained batch 176 in epoch 3, gen_loss = 0.9589446971645463, disc_loss = 0.043087420083377195
Trained batch 177 in epoch 3, gen_loss = 0.9597879226288099, disc_loss = 0.042912446604021354
Trained batch 178 in epoch 3, gen_loss = 0.9601510003958335, disc_loss = 0.04269876555661936
Trained batch 179 in epoch 3, gen_loss = 0.9603404449092017, disc_loss = 0.04248108228008884
Trained batch 180 in epoch 3, gen_loss = 0.9608217095801843, disc_loss = 0.0422635202158438
Trained batch 181 in epoch 3, gen_loss = 0.9610425607188717, disc_loss = 0.0420409283443395
Trained batch 182 in epoch 3, gen_loss = 0.9620350677458966, disc_loss = 0.04182693264332646
Trained batch 183 in epoch 3, gen_loss = 0.962177268512871, disc_loss = 0.041612400760008626
Trained batch 184 in epoch 3, gen_loss = 0.9625505747021855, disc_loss = 0.041397148704886234
Trained batch 185 in epoch 3, gen_loss = 0.9622703922051256, disc_loss = 0.041311473377244244
Trained batch 186 in epoch 3, gen_loss = 0.9629107149527034, disc_loss = 0.04113600114895838
Trained batch 187 in epoch 3, gen_loss = 0.9627591726627756, disc_loss = 0.04095515741984003
Trained batch 188 in epoch 3, gen_loss = 0.9635102439809728, disc_loss = 0.04075596268256761
Trained batch 189 in epoch 3, gen_loss = 0.9629945836569134, disc_loss = 0.040555125451034034
Trained batch 190 in epoch 3, gen_loss = 0.9629134688701929, disc_loss = 0.04034976028052222
Trained batch 191 in epoch 3, gen_loss = 0.9630981432273984, disc_loss = 0.04014825921573598
Trained batch 192 in epoch 3, gen_loss = 0.9630525692756929, disc_loss = 0.039944238752643024
Trained batch 193 in epoch 3, gen_loss = 0.963608038794134, disc_loss = 0.039745758587048034
Trained batch 194 in epoch 3, gen_loss = 0.9644545432848808, disc_loss = 0.03955371101589825
Trained batch 195 in epoch 3, gen_loss = 0.9645144775205728, disc_loss = 0.03935616383832708
Trained batch 196 in epoch 3, gen_loss = 0.9641615751431073, disc_loss = 0.03916940621577846
Trained batch 197 in epoch 3, gen_loss = 0.9632188602529391, disc_loss = 0.03897762956154166
Trained batch 198 in epoch 3, gen_loss = 0.9633553300670643, disc_loss = 0.038787099739873605
Trained batch 199 in epoch 3, gen_loss = 0.9633515563607216, disc_loss = 0.03859705464623403
Trained batch 200 in epoch 3, gen_loss = 0.9634182159580401, disc_loss = 0.038412882888513564
Trained batch 201 in epoch 3, gen_loss = 0.9637323561871406, disc_loss = 0.03822718810758065
Trained batch 202 in epoch 3, gen_loss = 0.9644278631421733, disc_loss = 0.03804585004507523
Trained batch 203 in epoch 3, gen_loss = 0.9643349109911451, disc_loss = 0.037863998189933745
Trained batch 204 in epoch 3, gen_loss = 0.9649665803444095, disc_loss = 0.037686763589111404
Trained batch 205 in epoch 3, gen_loss = 0.9654119755457906, disc_loss = 0.03750804105679758
Trained batch 206 in epoch 3, gen_loss = 0.9652161172046754, disc_loss = 0.037333373774173735
Trained batch 207 in epoch 3, gen_loss = 0.965680062197722, disc_loss = 0.03715640395743181
Trained batch 208 in epoch 3, gen_loss = 0.9659265188509197, disc_loss = 0.036982153110099183
Trained batch 209 in epoch 3, gen_loss = 0.9661171964236668, disc_loss = 0.03681151286443873
Trained batch 210 in epoch 3, gen_loss = 0.9656902300238044, disc_loss = 0.03663973469382055
Trained batch 211 in epoch 3, gen_loss = 0.9652573446620185, disc_loss = 0.036470764840212826
Trained batch 212 in epoch 3, gen_loss = 0.9654875431262272, disc_loss = 0.036302444372028814
Trained batch 213 in epoch 3, gen_loss = 0.9658287465572357, disc_loss = 0.03613716850593625
Trained batch 214 in epoch 3, gen_loss = 0.9658409534498703, disc_loss = 0.03597534197886193
Trained batch 215 in epoch 3, gen_loss = 0.9662009113364749, disc_loss = 0.03581216677277418
Trained batch 216 in epoch 3, gen_loss = 0.9660071417483317, disc_loss = 0.03564978245707993
Trained batch 217 in epoch 3, gen_loss = 0.966006491709193, disc_loss = 0.03549134460814007
Trained batch 218 in epoch 3, gen_loss = 0.9659068894712892, disc_loss = 0.035333232876268474
Trained batch 219 in epoch 3, gen_loss = 0.9648310376839204, disc_loss = 0.03521762427487622
Trained batch 220 in epoch 3, gen_loss = 0.9645034956716304, disc_loss = 0.03507670898667886
Trained batch 221 in epoch 3, gen_loss = 0.9638403812507251, disc_loss = 0.034929802553961053
Trained batch 222 in epoch 3, gen_loss = 0.9639247540935807, disc_loss = 0.034776334635414304
Trained batch 223 in epoch 3, gen_loss = 0.9638501658503499, disc_loss = 0.03462413321228398
Trained batch 224 in epoch 3, gen_loss = 0.9638267278671264, disc_loss = 0.03447309156129551
Trained batch 225 in epoch 3, gen_loss = 0.9633762190299752, disc_loss = 0.034322996456660246
Trained batch 226 in epoch 3, gen_loss = 0.9640147347282207, disc_loss = 0.034176423203349855
Trained batch 227 in epoch 3, gen_loss = 0.9639411451000917, disc_loss = 0.03402979626078281
Trained batch 228 in epoch 3, gen_loss = 0.9634121755325118, disc_loss = 0.03388530726917698
Trained batch 229 in epoch 3, gen_loss = 0.9641657435375711, disc_loss = 0.033742229065746476
Trained batch 230 in epoch 3, gen_loss = 0.9648691658333782, disc_loss = 0.03359842923589784
Trained batch 231 in epoch 3, gen_loss = 0.9652366288777056, disc_loss = 0.03345758612051903
Trained batch 232 in epoch 3, gen_loss = 0.9649070992490253, disc_loss = 0.03331975279352928
Trained batch 233 in epoch 3, gen_loss = 0.9649380939638513, disc_loss = 0.03318130860998669
Trained batch 234 in epoch 3, gen_loss = 0.9651631522685924, disc_loss = 0.03304249586121358
Trained batch 235 in epoch 3, gen_loss = 0.9652742788953296, disc_loss = 0.03290473637161224
Trained batch 236 in epoch 3, gen_loss = 0.9649803070076407, disc_loss = 0.0327676554357354
Trained batch 237 in epoch 3, gen_loss = 0.9648620371057206, disc_loss = 0.03263200385710753
Trained batch 238 in epoch 3, gen_loss = 0.9645018096249472, disc_loss = 0.032499307086939676
Trained batch 239 in epoch 3, gen_loss = 0.9642183549702168, disc_loss = 0.03236548302932837
Trained batch 240 in epoch 3, gen_loss = 0.9641888831660955, disc_loss = 0.03223392169360319
Trained batch 241 in epoch 3, gen_loss = 0.9642226934925584, disc_loss = 0.03210273083931505
Trained batch 242 in epoch 3, gen_loss = 0.9639270555825881, disc_loss = 0.03197373229212132
Trained batch 243 in epoch 3, gen_loss = 0.9636948748690183, disc_loss = 0.031844322620242164
Trained batch 244 in epoch 3, gen_loss = 0.9638741892211291, disc_loss = 0.031720017063032305
Trained batch 245 in epoch 3, gen_loss = 0.9637561125483939, disc_loss = 0.031594095742651755
Trained batch 246 in epoch 3, gen_loss = 0.9635416983592848, disc_loss = 0.03146762379962642
Trained batch 247 in epoch 3, gen_loss = 0.9634323074452339, disc_loss = 0.031342373704378146
Trained batch 248 in epoch 3, gen_loss = 0.9637262067162847, disc_loss = 0.031218553176776218
Trained batch 249 in epoch 3, gen_loss = 0.9640126421451568, disc_loss = 0.031095646858680992
Trained batch 250 in epoch 3, gen_loss = 0.964021905009965, disc_loss = 0.030974983381695555
Trained batch 251 in epoch 3, gen_loss = 0.963653949281526, disc_loss = 0.030853943210945183
Trained batch 252 in epoch 3, gen_loss = 0.9636922563488776, disc_loss = 0.03073497870964598
Trained batch 253 in epoch 3, gen_loss = 0.9634262614362822, disc_loss = 0.030615513363195856
Trained batch 254 in epoch 3, gen_loss = 0.9627600581038231, disc_loss = 0.0304977745346168
Trained batch 255 in epoch 3, gen_loss = 0.9624561013188213, disc_loss = 0.03038154768671575
Trained batch 256 in epoch 3, gen_loss = 0.9624142298902519, disc_loss = 0.030265475960891398
Trained batch 257 in epoch 3, gen_loss = 0.9625629537789396, disc_loss = 0.03015014510175354
Trained batch 258 in epoch 3, gen_loss = 0.9625062436210603, disc_loss = 0.030035569774378882
Trained batch 259 in epoch 3, gen_loss = 0.962402206659317, disc_loss = 0.029922154270416987
Trained batch 260 in epoch 3, gen_loss = 0.9626227818229646, disc_loss = 0.029809458243037962
Trained batch 261 in epoch 3, gen_loss = 0.9624244156684584, disc_loss = 0.029698005557737404
Trained batch 262 in epoch 3, gen_loss = 0.9622258364927633, disc_loss = 0.029586397699468164
Trained batch 263 in epoch 3, gen_loss = 0.9618594328110869, disc_loss = 0.029475688935649072
Trained batch 264 in epoch 3, gen_loss = 0.9617730354363063, disc_loss = 0.029365852130093736
Trained batch 265 in epoch 3, gen_loss = 0.9619454976759458, disc_loss = 0.029256944263203393
Trained batch 266 in epoch 3, gen_loss = 0.961422227071912, disc_loss = 0.029148609245768033
Trained batch 267 in epoch 3, gen_loss = 0.9614995295432076, disc_loss = 0.029042252919327383
Trained batch 268 in epoch 3, gen_loss = 0.9613364855152967, disc_loss = 0.028936437985056587
Trained batch 269 in epoch 3, gen_loss = 0.9610338500252477, disc_loss = 0.028831373934884108
Trained batch 270 in epoch 3, gen_loss = 0.9610611114554739, disc_loss = 0.028726360156321965
Trained batch 271 in epoch 3, gen_loss = 0.9607606777811751, disc_loss = 0.028622077577571927
Trained batch 272 in epoch 3, gen_loss = 0.9605232889835651, disc_loss = 0.028519122702800482
Trained batch 273 in epoch 3, gen_loss = 0.9603185172933731, disc_loss = 0.0284172597377991
Trained batch 274 in epoch 3, gen_loss = 0.9599782484227961, disc_loss = 0.028315752749860455
Trained batch 275 in epoch 3, gen_loss = 0.9601265209308569, disc_loss = 0.028214904255182246
Trained batch 276 in epoch 3, gen_loss = 0.9605314068845894, disc_loss = 0.028114632614581452
Trained batch 277 in epoch 3, gen_loss = 0.9600751541501327, disc_loss = 0.028015388559115374
Trained batch 278 in epoch 3, gen_loss = 0.9594497343118046, disc_loss = 0.027916298549656514
Trained batch 279 in epoch 3, gen_loss = 0.959129228762218, disc_loss = 0.027818639316267633
Trained batch 280 in epoch 3, gen_loss = 0.9595128565072165, disc_loss = 0.027723154481985104
Trained batch 281 in epoch 3, gen_loss = 0.9590348755636959, disc_loss = 0.02762708909438464
Trained batch 282 in epoch 3, gen_loss = 0.9595547040443959, disc_loss = 0.02753136759426843
Trained batch 283 in epoch 3, gen_loss = 0.959459631165988, disc_loss = 0.027435690493623786
Trained batch 284 in epoch 3, gen_loss = 0.9594145933787028, disc_loss = 0.027341098721821284
Trained batch 285 in epoch 3, gen_loss = 0.9591634088046067, disc_loss = 0.027246553853697182
Trained batch 286 in epoch 3, gen_loss = 0.9595080342026953, disc_loss = 0.027152849856471213
Trained batch 287 in epoch 3, gen_loss = 0.959391100746062, disc_loss = 0.0270610362263647
Trained batch 288 in epoch 3, gen_loss = 0.959218362829677, disc_loss = 0.026969683582062275
Trained batch 289 in epoch 3, gen_loss = 0.9591453052800277, disc_loss = 0.026878771237157897
Trained batch 290 in epoch 3, gen_loss = 0.9590967119354563, disc_loss = 0.02678892225388332
Trained batch 291 in epoch 3, gen_loss = 0.9590326637437899, disc_loss = 0.026698829696576703
Trained batch 292 in epoch 3, gen_loss = 0.9592947707648163, disc_loss = 0.026609416845562128
Trained batch 293 in epoch 3, gen_loss = 0.959210955975007, disc_loss = 0.02652202439872583
Trained batch 294 in epoch 3, gen_loss = 0.9591619125867294, disc_loss = 0.02643434054729276
Trained batch 295 in epoch 3, gen_loss = 0.9591026038334176, disc_loss = 0.026346308275655296
Trained batch 296 in epoch 3, gen_loss = 0.9593306589206863, disc_loss = 0.026258885730406807
Trained batch 297 in epoch 3, gen_loss = 0.9596544414158635, disc_loss = 0.026172322059075985
Trained batch 298 in epoch 3, gen_loss = 0.9599273701176596, disc_loss = 0.026086629192865793
Trained batch 299 in epoch 3, gen_loss = 0.9600633229811987, disc_loss = 0.02600229353576045
Trained batch 300 in epoch 3, gen_loss = 0.960095677066879, disc_loss = 0.025917778916612882
Trained batch 301 in epoch 3, gen_loss = 0.9601036939794654, disc_loss = 0.025833782206142217
Trained batch 302 in epoch 3, gen_loss = 0.960651186236454, disc_loss = 0.02575026718269889
Trained batch 303 in epoch 3, gen_loss = 0.9605641541512389, disc_loss = 0.02566700218726749
Trained batch 304 in epoch 3, gen_loss = 0.9604153883261759, disc_loss = 0.025584578255218163
Trained batch 305 in epoch 3, gen_loss = 0.9606896607704412, disc_loss = 0.025502736774083757
Trained batch 306 in epoch 3, gen_loss = 0.96066071175597, disc_loss = 0.025421283049611314
Trained batch 307 in epoch 3, gen_loss = 0.9603975703576942, disc_loss = 0.02533987669165355
Trained batch 308 in epoch 3, gen_loss = 0.9603071642925053, disc_loss = 0.025259775328103296
Trained batch 309 in epoch 3, gen_loss = 0.9597982073983838, disc_loss = 0.02518045925009515
Trained batch 310 in epoch 3, gen_loss = 0.960030885946329, disc_loss = 0.025101148482963107
Trained batch 311 in epoch 3, gen_loss = 0.9599617903049176, disc_loss = 0.025021878627366954
Trained batch 312 in epoch 3, gen_loss = 0.9598731903222423, disc_loss = 0.0249431235073231
Trained batch 313 in epoch 3, gen_loss = 0.9596048418883305, disc_loss = 0.024864954551460167
Trained batch 314 in epoch 3, gen_loss = 0.9591196082887196, disc_loss = 0.02478801559126522
Trained batch 315 in epoch 3, gen_loss = 0.9591001775823061, disc_loss = 0.024711134125234683
Trained batch 316 in epoch 3, gen_loss = 0.9591191988262092, disc_loss = 0.02463546167621727
Trained batch 317 in epoch 3, gen_loss = 0.959211751912375, disc_loss = 0.024559267987947435
Trained batch 318 in epoch 3, gen_loss = 0.9587223677425922, disc_loss = 0.02448516637592308
Trained batch 319 in epoch 3, gen_loss = 0.9583018952980638, disc_loss = 0.024409999285762752
Trained batch 320 in epoch 3, gen_loss = 0.9584443229381169, disc_loss = 0.024335125239723365
Trained batch 321 in epoch 3, gen_loss = 0.958630154036587, disc_loss = 0.024260591224786066
Trained batch 322 in epoch 3, gen_loss = 0.9588756186674254, disc_loss = 0.024194292061141875
Trained batch 323 in epoch 3, gen_loss = 0.959146652508665, disc_loss = 0.024122519573637997
Trained batch 324 in epoch 3, gen_loss = 0.9590738566105182, disc_loss = 0.02405147218843922
Trained batch 325 in epoch 3, gen_loss = 0.9592457587367917, disc_loss = 0.023978982816387447
Trained batch 326 in epoch 3, gen_loss = 0.9595877502671805, disc_loss = 0.023907928209928424
Trained batch 327 in epoch 3, gen_loss = 0.9595677856265045, disc_loss = 0.023836747565904415
Trained batch 328 in epoch 3, gen_loss = 0.9599116341321302, disc_loss = 0.02376750737692634
Trained batch 329 in epoch 3, gen_loss = 0.9599020260753054, disc_loss = 0.02369677768914368
Trained batch 330 in epoch 3, gen_loss = 0.9599115358738741, disc_loss = 0.023626850110765693
Trained batch 331 in epoch 3, gen_loss = 0.9596293938447193, disc_loss = 0.023556699719825613
Trained batch 332 in epoch 3, gen_loss = 0.9594858598422717, disc_loss = 0.023488281723132845
Trained batch 333 in epoch 3, gen_loss = 0.9594655593712172, disc_loss = 0.023420099492992057
Trained batch 334 in epoch 3, gen_loss = 0.9594841814752835, disc_loss = 0.023351362560451755
Trained batch 335 in epoch 3, gen_loss = 0.9596507457040605, disc_loss = 0.023283302446846694
Trained batch 336 in epoch 3, gen_loss = 0.9598986685099163, disc_loss = 0.023215194621561398
Trained batch 337 in epoch 3, gen_loss = 0.9598096106532057, disc_loss = 0.023147491015943
Trained batch 338 in epoch 3, gen_loss = 0.959532248059557, disc_loss = 0.02307991209910574
Trained batch 339 in epoch 3, gen_loss = 0.9592443890431348, disc_loss = 0.02301309898693409
Trained batch 340 in epoch 3, gen_loss = 0.9590605598740564, disc_loss = 0.02294683655159093
Trained batch 341 in epoch 3, gen_loss = 0.9592446918376007, disc_loss = 0.022881024627619876
Trained batch 342 in epoch 3, gen_loss = 0.9592549978122766, disc_loss = 0.022815455349239264
Trained batch 343 in epoch 3, gen_loss = 0.959077802854915, disc_loss = 0.022750020689907318
Trained batch 344 in epoch 3, gen_loss = 0.9588557232981143, disc_loss = 0.02268589131826825
Trained batch 345 in epoch 3, gen_loss = 0.9587493702510878, disc_loss = 0.02262155171627592
Trained batch 346 in epoch 3, gen_loss = 0.9588552924672877, disc_loss = 0.02255754911347315
Trained batch 347 in epoch 3, gen_loss = 0.9587942291607802, disc_loss = 0.022493885706395284
Trained batch 348 in epoch 3, gen_loss = 0.9588836629616155, disc_loss = 0.02243059452446838
Trained batch 349 in epoch 3, gen_loss = 0.9588455261502947, disc_loss = 0.022367875462722234
Trained batch 350 in epoch 3, gen_loss = 0.9586738860844887, disc_loss = 0.02230496740178769
Trained batch 351 in epoch 3, gen_loss = 0.9583385925401341, disc_loss = 0.022242553865536054
Trained batch 352 in epoch 3, gen_loss = 0.9580823085125715, disc_loss = 0.02218096373011932
Trained batch 353 in epoch 3, gen_loss = 0.9580245843041415, disc_loss = 0.022119510091986247
Trained batch 354 in epoch 3, gen_loss = 0.957772958278656, disc_loss = 0.022058448957280964
Trained batch 355 in epoch 3, gen_loss = 0.9579168251726065, disc_loss = 0.021998282047513456
Trained batch 356 in epoch 3, gen_loss = 0.957759396368716, disc_loss = 0.02194505528432248
Trained batch 357 in epoch 3, gen_loss = 0.9580984342031639, disc_loss = 0.02189444816205813
Trained batch 358 in epoch 3, gen_loss = 0.9579875842774479, disc_loss = 0.0218386285806423
Trained batch 359 in epoch 3, gen_loss = 0.9583077591326502, disc_loss = 0.021780925042670183
Trained batch 360 in epoch 3, gen_loss = 0.958408235678052, disc_loss = 0.021730804200314174
Trained batch 361 in epoch 3, gen_loss = 0.9586477650133944, disc_loss = 0.02167681490302823
Trained batch 362 in epoch 3, gen_loss = 0.9585772376743559, disc_loss = 0.02162117409791968
Trained batch 363 in epoch 3, gen_loss = 0.957979277758808, disc_loss = 0.021633062494771906
Trained batch 364 in epoch 3, gen_loss = 0.9581772760169147, disc_loss = 0.021583073578291725
Trained batch 365 in epoch 3, gen_loss = 0.9583026055104095, disc_loss = 0.021528030430512882
Trained batch 366 in epoch 3, gen_loss = 0.958809450634169, disc_loss = 0.021500777839265867
Trained batch 367 in epoch 3, gen_loss = 0.9593395647471366, disc_loss = 0.021464089278750813
Trained batch 368 in epoch 3, gen_loss = 0.9596266874129856, disc_loss = 0.02141521652365579
Trained batch 369 in epoch 3, gen_loss = 0.9596951589391038, disc_loss = 0.021361967809915203
Trained batch 370 in epoch 3, gen_loss = 0.9598539230637152, disc_loss = 0.021308614951509774
Trained batch 371 in epoch 3, gen_loss = 0.959686229145655, disc_loss = 0.021254680976961673
Trained batch 372 in epoch 3, gen_loss = 0.9595965819767909, disc_loss = 0.021199398035386105
Trained batch 373 in epoch 3, gen_loss = 0.9595194447805537, disc_loss = 0.021214576246832276
Trained batch 374 in epoch 3, gen_loss = 0.9598999101320903, disc_loss = 0.021184898799168878
Trained batch 375 in epoch 3, gen_loss = 0.9600175608028757, disc_loss = 0.021136873826996652
Trained batch 376 in epoch 3, gen_loss = 0.9602135927354626, disc_loss = 0.0210898085891418
Trained batch 377 in epoch 3, gen_loss = 0.9602554451536249, disc_loss = 0.021040596080109015
Trained batch 378 in epoch 3, gen_loss = 0.9605584957668838, disc_loss = 0.020991562538122018
Trained batch 379 in epoch 3, gen_loss = 0.9605625141608087, disc_loss = 0.02093858545371117
Trained batch 380 in epoch 3, gen_loss = 0.9606083836455358, disc_loss = 0.020886608415530455
Trained batch 381 in epoch 3, gen_loss = 0.9605572985104865, disc_loss = 0.020834361224080843
Trained batch 382 in epoch 3, gen_loss = 0.960555681516234, disc_loss = 0.02078333349085222
Trained batch 383 in epoch 3, gen_loss = 0.9607143052853644, disc_loss = 0.020731067255117825
Trained batch 384 in epoch 3, gen_loss = 0.960814820946037, disc_loss = 0.020679616997231632
Trained batch 385 in epoch 3, gen_loss = 0.960889689199665, disc_loss = 0.020629328131680846
Trained batch 386 in epoch 3, gen_loss = 0.9608590119260842, disc_loss = 0.020577457138628685
Trained batch 387 in epoch 3, gen_loss = 0.9609087152579396, disc_loss = 0.020525914907658573
Trained batch 388 in epoch 3, gen_loss = 0.9608318054890571, disc_loss = 0.020475381623678554
Trained batch 389 in epoch 3, gen_loss = 0.9609958991026267, disc_loss = 0.020425106001792488
Trained batch 390 in epoch 3, gen_loss = 0.9612229522841665, disc_loss = 0.020375462206084428
Trained batch 391 in epoch 3, gen_loss = 0.9611429450463276, disc_loss = 0.0203272540898348
Trained batch 392 in epoch 3, gen_loss = 0.9607214155694608, disc_loss = 0.020283185205111014
Trained batch 393 in epoch 3, gen_loss = 0.9605960625077262, disc_loss = 0.020234576644540498
Trained batch 394 in epoch 3, gen_loss = 0.9601666213590887, disc_loss = 0.020195889044471994
Trained batch 395 in epoch 3, gen_loss = 0.9603775584637516, disc_loss = 0.02015363179489581
Trained batch 396 in epoch 3, gen_loss = 0.960553117453001, disc_loss = 0.020106548151995116
Trained batch 397 in epoch 3, gen_loss = 0.9606141340193437, disc_loss = 0.020062396256640688
Trained batch 398 in epoch 3, gen_loss = 0.960202301654003, disc_loss = 0.020030383541773045
Trained batch 399 in epoch 3, gen_loss = 0.9605020663142204, disc_loss = 0.019991998624209372
Trained batch 400 in epoch 3, gen_loss = 0.9602563840492705, disc_loss = 0.02011109266882011
Trained batch 401 in epoch 3, gen_loss = 0.9602135993651489, disc_loss = 0.020102115744756434
Trained batch 402 in epoch 3, gen_loss = 0.9590812294418107, disc_loss = 0.02036528237382552
Trained batch 403 in epoch 3, gen_loss = 0.9580851182489112, disc_loss = 0.0207839407895056
Trained batch 404 in epoch 3, gen_loss = 0.9590189239125193, disc_loss = 0.021283373087795487
Trained batch 405 in epoch 3, gen_loss = 0.9590406429591437, disc_loss = 0.021393008601860077
Trained batch 406 in epoch 3, gen_loss = 0.9591522497978492, disc_loss = 0.02136154598285443
Trained batch 407 in epoch 3, gen_loss = 0.9593514823446087, disc_loss = 0.02131982061698235
Trained batch 408 in epoch 3, gen_loss = 0.9591950608057614, disc_loss = 0.021303608831996498
Trained batch 409 in epoch 3, gen_loss = 0.9587256831366842, disc_loss = 0.021308158493136543
Trained batch 410 in epoch 3, gen_loss = 0.9582993784090028, disc_loss = 0.021339148927148298
Trained batch 411 in epoch 3, gen_loss = 0.9584100503944656, disc_loss = 0.021336180113350072
Trained batch 412 in epoch 3, gen_loss = 0.9586111878656013, disc_loss = 0.021307499770935653
Trained batch 413 in epoch 3, gen_loss = 0.9588141818553353, disc_loss = 0.021269778404442496
Trained batch 414 in epoch 3, gen_loss = 0.9585094260882182, disc_loss = 0.0212362894222087
Trained batch 415 in epoch 3, gen_loss = 0.9574893519568902, disc_loss = 0.021613276469032335
Trained batch 416 in epoch 3, gen_loss = 0.9580815445890816, disc_loss = 0.0216640667578139
Trained batch 417 in epoch 3, gen_loss = 0.9585352518626947, disc_loss = 0.02252037507211305
Trained batch 418 in epoch 3, gen_loss = 0.9581351435269831, disc_loss = 0.022519007551369617
Trained batch 419 in epoch 3, gen_loss = 0.9576260502849306, disc_loss = 0.02256328204062551
Trained batch 420 in epoch 3, gen_loss = 0.9572254090864132, disc_loss = 0.0226193512530321
Trained batch 421 in epoch 3, gen_loss = 0.9571009459088764, disc_loss = 0.022692752246761757
Trained batch 422 in epoch 3, gen_loss = 0.9569264237480525, disc_loss = 0.022667277222929962
Trained batch 423 in epoch 3, gen_loss = 0.9565838469930414, disc_loss = 0.02263821491190888
Trained batch 424 in epoch 3, gen_loss = 0.9563974963917452, disc_loss = 0.02260185828052379
Trained batch 425 in epoch 3, gen_loss = 0.9558109366837801, disc_loss = 0.022600188579754914
Trained batch 426 in epoch 3, gen_loss = 0.9556900606222398, disc_loss = 0.022576430739991125
Trained batch 427 in epoch 3, gen_loss = 0.955419834529128, disc_loss = 0.022534726211012646
Trained batch 428 in epoch 3, gen_loss = 0.955325419252569, disc_loss = 0.02249019524402887
Trained batch 429 in epoch 3, gen_loss = 0.9554980103359666, disc_loss = 0.022451096125587357
Trained batch 430 in epoch 3, gen_loss = 0.9556431728836555, disc_loss = 0.022403346801160733
Trained batch 431 in epoch 3, gen_loss = 0.9557275009100084, disc_loss = 0.02235654908040656
Trained batch 432 in epoch 3, gen_loss = 0.9554165974775582, disc_loss = 0.02237206700559212
Trained batch 433 in epoch 3, gen_loss = 0.9561048604650981, disc_loss = 0.022338889428493
Trained batch 434 in epoch 3, gen_loss = 0.9565986251008922, disc_loss = 0.022308528957247532
Trained batch 435 in epoch 3, gen_loss = 0.9568176861476461, disc_loss = 0.022270191664608044
Trained batch 436 in epoch 3, gen_loss = 0.9569510225573176, disc_loss = 0.022230829054456964
Trained batch 437 in epoch 3, gen_loss = 0.9567901734347757, disc_loss = 0.022188091517478435
Trained batch 438 in epoch 3, gen_loss = 0.956782940308434, disc_loss = 0.022146202575879178
Trained batch 439 in epoch 3, gen_loss = 0.9569273366169496, disc_loss = 0.02209942888085524
Trained batch 440 in epoch 3, gen_loss = 0.9567636123049557, disc_loss = 0.0220552003473403
Trained batch 441 in epoch 3, gen_loss = 0.9569861280702358, disc_loss = 0.02200907962089241
Trained batch 442 in epoch 3, gen_loss = 0.9571596441903987, disc_loss = 0.021973735804525815
Trained batch 443 in epoch 3, gen_loss = 0.9570069854055439, disc_loss = 0.021931052696976344
Trained batch 444 in epoch 3, gen_loss = 0.956849132361037, disc_loss = 0.021899491768582788
Trained batch 445 in epoch 3, gen_loss = 0.9568355887994638, disc_loss = 0.02185837159405338
Trained batch 446 in epoch 3, gen_loss = 0.9566142659059307, disc_loss = 0.02186731249540008
Trained batch 447 in epoch 3, gen_loss = 0.9569642545123186, disc_loss = 0.021891219130111494
Trained batch 448 in epoch 3, gen_loss = 0.9568810432419214, disc_loss = 0.021905648541038613
Trained batch 449 in epoch 3, gen_loss = 0.956189306444592, disc_loss = 0.022161851980910998
Trained batch 450 in epoch 3, gen_loss = 0.956142855457086, disc_loss = 0.022128039588223774
Trained batch 451 in epoch 3, gen_loss = 0.9565388698757222, disc_loss = 0.022116466607998663
Trained batch 452 in epoch 3, gen_loss = 0.9566332180768449, disc_loss = 0.022146724831914502
Trained batch 453 in epoch 3, gen_loss = 0.9563018922501199, disc_loss = 0.02213234857208991
Trained batch 454 in epoch 3, gen_loss = 0.9558765364217234, disc_loss = 0.02213694704520634
Trained batch 455 in epoch 3, gen_loss = 0.9560461070453912, disc_loss = 0.022106121003449324
Trained batch 456 in epoch 3, gen_loss = 0.9562542475026338, disc_loss = 0.022071066152802934
Trained batch 457 in epoch 3, gen_loss = 0.9568221287956404, disc_loss = 0.022034889465589614
Trained batch 458 in epoch 3, gen_loss = 0.9567492377004851, disc_loss = 0.021998025133298082
Trained batch 459 in epoch 3, gen_loss = 0.956630570344303, disc_loss = 0.02195924468387207
Trained batch 460 in epoch 3, gen_loss = 0.956516770245972, disc_loss = 0.02191704554903627
Trained batch 461 in epoch 3, gen_loss = 0.9566556970020393, disc_loss = 0.021875309977899417
Trained batch 462 in epoch 3, gen_loss = 0.95639723642341, disc_loss = 0.021831514803396256
Trained batch 463 in epoch 3, gen_loss = 0.9564425581745033, disc_loss = 0.021792615156457407
Trained batch 464 in epoch 3, gen_loss = 0.9563566662931955, disc_loss = 0.02174918012851874
Trained batch 465 in epoch 3, gen_loss = 0.9562930009395779, disc_loss = 0.021707099185670205
Trained batch 466 in epoch 3, gen_loss = 0.9561009754205414, disc_loss = 0.02167812819277685
Trained batch 467 in epoch 3, gen_loss = 0.9563415720422044, disc_loss = 0.021643107242338235
Trained batch 468 in epoch 3, gen_loss = 0.9562226485596028, disc_loss = 0.021600225887506822
Trained batch 469 in epoch 3, gen_loss = 0.9565250203964558, disc_loss = 0.021567313001333844
Trained batch 470 in epoch 3, gen_loss = 0.9565464256928479, disc_loss = 0.02152817145575381
Trained batch 471 in epoch 3, gen_loss = 0.9565750948958478, disc_loss = 0.021492483101518068
Trained batch 472 in epoch 3, gen_loss = 0.9563086975452512, disc_loss = 0.021460618005936766
Trained batch 473 in epoch 3, gen_loss = 0.9563452429157772, disc_loss = 0.021421297081778826
Trained batch 474 in epoch 3, gen_loss = 0.9565649402768989, disc_loss = 0.021389012796295757
Trained batch 475 in epoch 3, gen_loss = 0.9563843460143113, disc_loss = 0.021357662865028475
Trained batch 476 in epoch 3, gen_loss = 0.9563593295885082, disc_loss = 0.021323948992940742
Trained batch 477 in epoch 3, gen_loss = 0.9560686398500179, disc_loss = 0.021296080480268563
Trained batch 478 in epoch 3, gen_loss = 0.9565500370644826, disc_loss = 0.02125946221373599
Trained batch 479 in epoch 3, gen_loss = 0.9560362132887046, disc_loss = 0.021258961120020105
Trained batch 480 in epoch 3, gen_loss = 0.9563269810964065, disc_loss = 0.02122168565871946
Trained batch 481 in epoch 3, gen_loss = 0.9565355033300724, disc_loss = 0.021185702173585407
Trained batch 482 in epoch 3, gen_loss = 0.9569831859497797, disc_loss = 0.021166627793545126
Trained batch 483 in epoch 3, gen_loss = 0.956918253140016, disc_loss = 0.021132546146805563
Trained batch 484 in epoch 3, gen_loss = 0.9569443250439831, disc_loss = 0.021105273554525242
Trained batch 485 in epoch 3, gen_loss = 0.956635188296008, disc_loss = 0.0210877608787472
Trained batch 486 in epoch 3, gen_loss = 0.9569609053815414, disc_loss = 0.02105063338622616
Trained batch 487 in epoch 3, gen_loss = 0.9567318580678252, disc_loss = 0.02108642609471376
Trained batch 488 in epoch 3, gen_loss = 0.957059998941324, disc_loss = 0.02105445819857491
Trained batch 489 in epoch 3, gen_loss = 0.9573027238553884, disc_loss = 0.021019417988118592
Trained batch 490 in epoch 3, gen_loss = 0.9575336079005069, disc_loss = 0.02099817959180262
Trained batch 491 in epoch 3, gen_loss = 0.9573566231543456, disc_loss = 0.021005245370250166
Trained batch 492 in epoch 3, gen_loss = 0.9575034697931146, disc_loss = 0.02097162593354572
Trained batch 493 in epoch 3, gen_loss = 0.9577799698843165, disc_loss = 0.020938971449192358
Trained batch 494 in epoch 3, gen_loss = 0.9577035063444966, disc_loss = 0.020928904094123
Trained batch 495 in epoch 3, gen_loss = 0.9577538395120252, disc_loss = 0.020892559287623895
Trained batch 496 in epoch 3, gen_loss = 0.9578476827629135, disc_loss = 0.020860866047386913
Trained batch 497 in epoch 3, gen_loss = 0.9577082281849949, disc_loss = 0.020830294326581032
Trained batch 498 in epoch 3, gen_loss = 0.9577674721190351, disc_loss = 0.020790773674871126
Trained batch 499 in epoch 3, gen_loss = 0.9577154148817062, disc_loss = 0.020752181783813283
Trained batch 500 in epoch 3, gen_loss = 0.9577415205999287, disc_loss = 0.0207182768855289
Trained batch 501 in epoch 3, gen_loss = 0.9578100321777313, disc_loss = 0.020679083915801387
Trained batch 502 in epoch 3, gen_loss = 0.9578936084601325, disc_loss = 0.020639807375285184
Trained batch 503 in epoch 3, gen_loss = 0.958107647796472, disc_loss = 0.020601093689990756
Trained batch 504 in epoch 3, gen_loss = 0.958355176920938, disc_loss = 0.020563367966678923
Trained batch 505 in epoch 3, gen_loss = 0.9585434331488704, disc_loss = 0.020528686104859768
Trained batch 506 in epoch 3, gen_loss = 0.958604778881374, disc_loss = 0.020489984887374954
Trained batch 507 in epoch 3, gen_loss = 0.9587823529177764, disc_loss = 0.020453180740483145
Trained batch 508 in epoch 3, gen_loss = 0.9589481945122155, disc_loss = 0.020415112655615564
Trained batch 509 in epoch 3, gen_loss = 0.9591407921968722, disc_loss = 0.020376787507734216
Trained batch 510 in epoch 3, gen_loss = 0.9592052779785575, disc_loss = 0.020338260105551575
Trained batch 511 in epoch 3, gen_loss = 0.9592252026777714, disc_loss = 0.0202998030415813
Trained batch 512 in epoch 3, gen_loss = 0.9590667189910398, disc_loss = 0.020261634373952286
Trained batch 513 in epoch 3, gen_loss = 0.9588687082440936, disc_loss = 0.020224957350612725
Trained batch 514 in epoch 3, gen_loss = 0.9589439064553641, disc_loss = 0.020187324195002767
Trained batch 515 in epoch 3, gen_loss = 0.9589995157349017, disc_loss = 0.020150050506260394
Trained batch 516 in epoch 3, gen_loss = 0.9590884811412435, disc_loss = 0.02011223159718838
Trained batch 517 in epoch 3, gen_loss = 0.9594156900888244, disc_loss = 0.02007479878793885
Trained batch 518 in epoch 3, gen_loss = 0.9594162107662428, disc_loss = 0.020037150137788826
Trained batch 519 in epoch 3, gen_loss = 0.9597889308746045, disc_loss = 0.019999821665791947
Trained batch 520 in epoch 3, gen_loss = 0.9595700524132449, disc_loss = 0.01996285914083797
Trained batch 521 in epoch 3, gen_loss = 0.9593005084443367, disc_loss = 0.019926443007259258
Trained batch 522 in epoch 3, gen_loss = 0.9593489736489539, disc_loss = 0.019889789701148512
Trained batch 523 in epoch 3, gen_loss = 0.9594347644170732, disc_loss = 0.01985298474664193
Trained batch 524 in epoch 3, gen_loss = 0.9597271246001834, disc_loss = 0.019816602741706275
Trained batch 525 in epoch 3, gen_loss = 0.9598894569130452, disc_loss = 0.019780263947456866
Trained batch 526 in epoch 3, gen_loss = 0.9599231634239545, disc_loss = 0.01974391008476418
Trained batch 527 in epoch 3, gen_loss = 0.95990920744159, disc_loss = 0.019708141147461763
Trained batch 528 in epoch 3, gen_loss = 0.9598608992726231, disc_loss = 0.01967218754809664
Trained batch 529 in epoch 3, gen_loss = 0.9598479923212303, disc_loss = 0.019636300785652636
Trained batch 530 in epoch 3, gen_loss = 0.9598176526484516, disc_loss = 0.01960052354040397
Trained batch 531 in epoch 3, gen_loss = 0.9597811601439813, disc_loss = 0.019565695523674105
Trained batch 532 in epoch 3, gen_loss = 0.9596183084189109, disc_loss = 0.01952987898688385
Trained batch 533 in epoch 3, gen_loss = 0.9598864076959059, disc_loss = 0.019494912774891335
Trained batch 534 in epoch 3, gen_loss = 0.959836077801535, disc_loss = 0.019459754858186653
Trained batch 535 in epoch 3, gen_loss = 0.9599336168881673, disc_loss = 0.019424563702498867
Trained batch 536 in epoch 3, gen_loss = 0.960058595548129, disc_loss = 0.01939011231110647
Trained batch 537 in epoch 3, gen_loss = 0.9599427949761813, disc_loss = 0.019355991400394644
Trained batch 538 in epoch 3, gen_loss = 0.960158831887431, disc_loss = 0.019321432836816633
Trained batch 539 in epoch 3, gen_loss = 0.9600566724936167, disc_loss = 0.019286921574099256
Trained batch 540 in epoch 3, gen_loss = 0.960108184990733, disc_loss = 0.019251958046567045
Trained batch 541 in epoch 3, gen_loss = 0.9601681628350403, disc_loss = 0.019218137031424287
Trained batch 542 in epoch 3, gen_loss = 0.960331445460381, disc_loss = 0.01918412345335806
Trained batch 543 in epoch 3, gen_loss = 0.9604356367798412, disc_loss = 0.019149966776213286
Trained batch 544 in epoch 3, gen_loss = 0.9605350072230768, disc_loss = 0.01911632573515617
Trained batch 545 in epoch 3, gen_loss = 0.9606863334502056, disc_loss = 0.01908222368157502
Trained batch 546 in epoch 3, gen_loss = 0.9605214180632526, disc_loss = 0.019048313239807053
Trained batch 547 in epoch 3, gen_loss = 0.9604909510290536, disc_loss = 0.019014451215437735
Trained batch 548 in epoch 3, gen_loss = 0.9605343362455594, disc_loss = 0.018982019785910173
Trained batch 549 in epoch 3, gen_loss = 0.9606774870915846, disc_loss = 0.01894931007142242
Trained batch 550 in epoch 3, gen_loss = 0.9606572154862045, disc_loss = 0.01891610755537279
Trained batch 551 in epoch 3, gen_loss = 0.9607853529893834, disc_loss = 0.01888307192825448
Trained batch 552 in epoch 3, gen_loss = 0.9607593070102644, disc_loss = 0.018850904245094387
Trained batch 553 in epoch 3, gen_loss = 0.9605693174828691, disc_loss = 0.018818125263942255
Trained batch 554 in epoch 3, gen_loss = 0.960665754477183, disc_loss = 0.018791173342987685
Trained batch 555 in epoch 3, gen_loss = 0.9605500977888382, disc_loss = 0.01875867322398741
Trained batch 556 in epoch 3, gen_loss = 0.9603765854073598, disc_loss = 0.018726056540706547
Trained batch 557 in epoch 3, gen_loss = 0.960403407773664, disc_loss = 0.01869351071729404
Trained batch 558 in epoch 3, gen_loss = 0.9605663897526285, disc_loss = 0.018661296496259205
Trained batch 559 in epoch 3, gen_loss = 0.9606478627238955, disc_loss = 0.01863233511027959
Trained batch 560 in epoch 3, gen_loss = 0.96090700154636, disc_loss = 0.01861083315138696
Trained batch 561 in epoch 3, gen_loss = 0.9605496107895604, disc_loss = 0.018622917681678695
Trained batch 562 in epoch 3, gen_loss = 0.9608490371788797, disc_loss = 0.018609735143794198
Trained batch 563 in epoch 3, gen_loss = 0.9612872936624162, disc_loss = 0.018584534113128392
Trained batch 564 in epoch 3, gen_loss = 0.9613886693937589, disc_loss = 0.01856058148955164
Trained batch 565 in epoch 3, gen_loss = 0.961365800548358, disc_loss = 0.018535414164429883
Trained batch 566 in epoch 3, gen_loss = 0.9612947619360801, disc_loss = 0.018508585379002133
Trained batch 567 in epoch 3, gen_loss = 0.961192395380685, disc_loss = 0.01848697095574351
Trained batch 568 in epoch 3, gen_loss = 0.9614052251897922, disc_loss = 0.018456767035621834
Trained batch 569 in epoch 3, gen_loss = 0.9616002667368504, disc_loss = 0.018427841154028245
Trained batch 570 in epoch 3, gen_loss = 0.9615047307857908, disc_loss = 0.018399426261660964
Trained batch 571 in epoch 3, gen_loss = 0.9612891894954068, disc_loss = 0.01837157015106132
Trained batch 572 in epoch 3, gen_loss = 0.9611783221129971, disc_loss = 0.018343043591485628
Trained batch 573 in epoch 3, gen_loss = 0.9610939283404201, disc_loss = 0.018315328318232838
Trained batch 574 in epoch 3, gen_loss = 0.9612931367625361, disc_loss = 0.01828472448085212
Trained batch 575 in epoch 3, gen_loss = 0.9614611429472765, disc_loss = 0.018254433596439412
Trained batch 576 in epoch 3, gen_loss = 0.96141392870627, disc_loss = 0.018227519000172446
Trained batch 577 in epoch 3, gen_loss = 0.9613364815299487, disc_loss = 0.018197137799377233
Trained batch 578 in epoch 3, gen_loss = 0.9614554886579102, disc_loss = 0.01816683998785327
Trained batch 579 in epoch 3, gen_loss = 0.9617268601368214, disc_loss = 0.018136621407380704
Trained batch 580 in epoch 3, gen_loss = 0.9618697375725961, disc_loss = 0.01810636103536237
Trained batch 581 in epoch 3, gen_loss = 0.9621516511202678, disc_loss = 0.01807673095804587
Trained batch 582 in epoch 3, gen_loss = 0.9622893202570658, disc_loss = 0.018046792335767343
Trained batch 583 in epoch 3, gen_loss = 0.9627333056845077, disc_loss = 0.018018612566128755
Trained batch 584 in epoch 3, gen_loss = 0.9625348512942974, disc_loss = 0.017989494171342813
Trained batch 585 in epoch 3, gen_loss = 0.9625836443982434, disc_loss = 0.017961329416745962
Trained batch 586 in epoch 3, gen_loss = 0.9627613728862808, disc_loss = 0.017933272522590773
Trained batch 587 in epoch 3, gen_loss = 0.9630118194891482, disc_loss = 0.017904178919261726
Trained batch 588 in epoch 3, gen_loss = 0.9630296335560357, disc_loss = 0.0178746472664819
Trained batch 589 in epoch 3, gen_loss = 0.9630541669110121, disc_loss = 0.01784596229305045
Trained batch 590 in epoch 3, gen_loss = 0.9631729074541082, disc_loss = 0.01781667022210528
Trained batch 591 in epoch 3, gen_loss = 0.9631699121280296, disc_loss = 0.01778880142491461
Trained batch 592 in epoch 3, gen_loss = 0.963316594267776, disc_loss = 0.017759830862279585
Trained batch 593 in epoch 3, gen_loss = 0.963223008194355, disc_loss = 0.01773119140343379
Trained batch 594 in epoch 3, gen_loss = 0.9632000108726886, disc_loss = 0.01770246575149696
Trained batch 595 in epoch 3, gen_loss = 0.9631782395127636, disc_loss = 0.017673485768401657
Trained batch 596 in epoch 3, gen_loss = 0.9631448060623565, disc_loss = 0.017644706777201605
Trained batch 597 in epoch 3, gen_loss = 0.9633450822088631, disc_loss = 0.01761600084913436
Trained batch 598 in epoch 3, gen_loss = 0.9634205792503484, disc_loss = 0.017587586888087835
Trained batch 599 in epoch 3, gen_loss = 0.9636095713575681, disc_loss = 0.01755914132379985
Trained batch 600 in epoch 3, gen_loss = 0.9635109470013572, disc_loss = 0.017531560159755363
Trained batch 601 in epoch 3, gen_loss = 0.9636602295791588, disc_loss = 0.017503360884748145
Trained batch 602 in epoch 3, gen_loss = 0.9637062406263146, disc_loss = 0.017476338310591734
Trained batch 603 in epoch 3, gen_loss = 0.9640052432058662, disc_loss = 0.017448508905262082
Trained batch 604 in epoch 3, gen_loss = 0.9638572431792898, disc_loss = 0.017420931560182675
Trained batch 605 in epoch 3, gen_loss = 0.9637672066098393, disc_loss = 0.017393006378739247
Trained batch 606 in epoch 3, gen_loss = 0.9636068995152117, disc_loss = 0.01736530795851335
Trained batch 607 in epoch 3, gen_loss = 0.9636083799169252, disc_loss = 0.01733764888728585
Trained batch 608 in epoch 3, gen_loss = 0.9635484926219057, disc_loss = 0.017310690127284655
Trained batch 609 in epoch 3, gen_loss = 0.9635344848281048, disc_loss = 0.017283394268678587
Trained batch 610 in epoch 3, gen_loss = 0.9634377130119773, disc_loss = 0.017256264552414385
Trained batch 611 in epoch 3, gen_loss = 0.9636028969015171, disc_loss = 0.017228647691000434
Trained batch 612 in epoch 3, gen_loss = 0.9637055757773059, disc_loss = 0.01720130236852716
Trained batch 613 in epoch 3, gen_loss = 0.9638159208072513, disc_loss = 0.017174071725206685
Trained batch 614 in epoch 3, gen_loss = 0.9639365249532994, disc_loss = 0.017147048083640353
Trained batch 615 in epoch 3, gen_loss = 0.9639626644648515, disc_loss = 0.0171201207668945
Trained batch 616 in epoch 3, gen_loss = 0.9639838468313604, disc_loss = 0.017093008274226253
Trained batch 617 in epoch 3, gen_loss = 0.9638989793444143, disc_loss = 0.0170663413455347
Trained batch 618 in epoch 3, gen_loss = 0.963730751408899, disc_loss = 0.017039868963085097
Trained batch 619 in epoch 3, gen_loss = 0.9635366733035734, disc_loss = 0.01701303826189213
Trained batch 620 in epoch 3, gen_loss = 0.9635733007040961, disc_loss = 0.016986418824642708
Trained batch 621 in epoch 3, gen_loss = 0.9633760222284741, disc_loss = 0.01696549285336759
Trained batch 622 in epoch 3, gen_loss = 0.9633650694574628, disc_loss = 0.016940347938405022
Trained batch 623 in epoch 3, gen_loss = 0.9636468458443116, disc_loss = 0.016914746924880885
Trained batch 624 in epoch 3, gen_loss = 0.9635156487464904, disc_loss = 0.016888594313128853
Trained batch 625 in epoch 3, gen_loss = 0.9635375898105268, disc_loss = 0.016863084382565577
Trained batch 626 in epoch 3, gen_loss = 0.9637703906976435, disc_loss = 0.01683735323360504
Trained batch 627 in epoch 3, gen_loss = 0.9637564754789802, disc_loss = 0.016811155925305955
Trained batch 628 in epoch 3, gen_loss = 0.9637012765024728, disc_loss = 0.01678532451144231
Trained batch 629 in epoch 3, gen_loss = 0.9635893711021968, disc_loss = 0.016759637863414976
Trained batch 630 in epoch 3, gen_loss = 0.9634847942320556, disc_loss = 0.01673376368764709
Trained batch 631 in epoch 3, gen_loss = 0.9635079772789267, disc_loss = 0.016707821080752736
Trained batch 632 in epoch 3, gen_loss = 0.96354879041042, disc_loss = 0.01668207916818904
Trained batch 633 in epoch 3, gen_loss = 0.9636451921628477, disc_loss = 0.01665653542203521
Trained batch 634 in epoch 3, gen_loss = 0.9636487358198391, disc_loss = 0.01663186648408204
Trained batch 635 in epoch 3, gen_loss = 0.9638010595204696, disc_loss = 0.0166067484605945
Trained batch 636 in epoch 3, gen_loss = 0.9637897989626395, disc_loss = 0.016581963271592903
Trained batch 637 in epoch 3, gen_loss = 0.9636456377827636, disc_loss = 0.016557397191609997
Trained batch 638 in epoch 3, gen_loss = 0.9635545260656234, disc_loss = 0.016532320235018744
Trained batch 639 in epoch 3, gen_loss = 0.9636319094337523, disc_loss = 0.016507875274351137
Trained batch 640 in epoch 3, gen_loss = 0.963909773577394, disc_loss = 0.0164851368708086
Trained batch 641 in epoch 3, gen_loss = 0.9638260243652023, disc_loss = 0.016460440328332552
Trained batch 642 in epoch 3, gen_loss = 0.9636540045819795, disc_loss = 0.016438737781060257
Trained batch 643 in epoch 3, gen_loss = 0.9634233078230983, disc_loss = 0.016415699851151985
Trained batch 644 in epoch 3, gen_loss = 0.9633906295133191, disc_loss = 0.016392632591914452
Trained batch 645 in epoch 3, gen_loss = 0.9635121456056187, disc_loss = 0.01636900239620569
Trained batch 646 in epoch 3, gen_loss = 0.9634559710022103, disc_loss = 0.01634494309572066
Trained batch 647 in epoch 3, gen_loss = 0.9631634504522806, disc_loss = 0.01632103006284771
Trained batch 648 in epoch 3, gen_loss = 0.9633452898732319, disc_loss = 0.016299575740994006
Trained batch 649 in epoch 3, gen_loss = 0.9635392837341015, disc_loss = 0.016277143490935068
Trained batch 650 in epoch 3, gen_loss = 0.9635291173710802, disc_loss = 0.01625340270138608
Trained batch 651 in epoch 3, gen_loss = 0.9635567933869508, disc_loss = 0.01622953556919134
Trained batch 652 in epoch 3, gen_loss = 0.9628632490339177, disc_loss = 0.01633976954032341
Trained batch 653 in epoch 3, gen_loss = 0.962817998836529, disc_loss = 0.016988941421772357
Trained batch 654 in epoch 3, gen_loss = 0.962505545779949, disc_loss = 0.016987377662991018
Trained batch 655 in epoch 3, gen_loss = 0.9620982414883811, disc_loss = 0.016996973749750083
Trained batch 656 in epoch 3, gen_loss = 0.9618340127362871, disc_loss = 0.017021370622620186
Trained batch 657 in epoch 3, gen_loss = 0.9619083327544135, disc_loss = 0.017008957719628657
Trained batch 658 in epoch 3, gen_loss = 0.9618008814198113, disc_loss = 0.016995492916062584
Trained batch 659 in epoch 3, gen_loss = 0.9614763589519443, disc_loss = 0.017014881170281583
Trained batch 660 in epoch 3, gen_loss = 0.9613790237957699, disc_loss = 0.016996497026742042
Trained batch 661 in epoch 3, gen_loss = 0.9614725943058279, disc_loss = 0.016974602899556518
Trained batch 662 in epoch 3, gen_loss = 0.961622090361237, disc_loss = 0.016951427783162634
Trained batch 663 in epoch 3, gen_loss = 0.9616976383938847, disc_loss = 0.016928387831877084
Trained batch 664 in epoch 3, gen_loss = 0.9618644707184986, disc_loss = 0.01691834144515276
Trained batch 665 in epoch 3, gen_loss = 0.9620170405319145, disc_loss = 0.016895330535264878
Trained batch 666 in epoch 3, gen_loss = 0.9619561330131863, disc_loss = 0.016871916041630068
Trained batch 667 in epoch 3, gen_loss = 0.9618149162409548, disc_loss = 0.01684791521036535
Trained batch 668 in epoch 3, gen_loss = 0.9616754678689132, disc_loss = 0.016823991464252754
Trained batch 669 in epoch 3, gen_loss = 0.9616254607243324, disc_loss = 0.01680065897233009
Trained batch 670 in epoch 3, gen_loss = 0.9617370667294134, disc_loss = 0.016777339179420824
Trained batch 671 in epoch 3, gen_loss = 0.9617627819201776, disc_loss = 0.016754358710667952
Trained batch 672 in epoch 3, gen_loss = 0.9617824067332592, disc_loss = 0.016731725368783864
Trained batch 673 in epoch 3, gen_loss = 0.9615126806656755, disc_loss = 0.016720898172740226
Trained batch 674 in epoch 3, gen_loss = 0.961287484963735, disc_loss = 0.016709500161814505
Trained batch 675 in epoch 3, gen_loss = 0.9615059568155446, disc_loss = 0.016690567156842244
Trained batch 676 in epoch 3, gen_loss = 0.9617423936394505, disc_loss = 0.016674394748556948
Trained batch 677 in epoch 3, gen_loss = 0.9616279980074339, disc_loss = 0.016663583042602306
Trained batch 678 in epoch 3, gen_loss = 0.9615845490625575, disc_loss = 0.01664840535122976
Trained batch 679 in epoch 3, gen_loss = 0.9615794940906413, disc_loss = 0.016630093972151587
Trained batch 680 in epoch 3, gen_loss = 0.9616345179413559, disc_loss = 0.01660745325394432
Trained batch 681 in epoch 3, gen_loss = 0.9613432806433121, disc_loss = 0.01659469010875184
Trained batch 682 in epoch 3, gen_loss = 0.9614097250851845, disc_loss = 0.016573658072421876
Trained batch 683 in epoch 3, gen_loss = 0.9614365877289521, disc_loss = 0.016555230340047102
Trained batch 684 in epoch 3, gen_loss = 0.9614020595585343, disc_loss = 0.016533715838934364
Trained batch 685 in epoch 3, gen_loss = 0.9616039705519773, disc_loss = 0.016512211171405982
Trained batch 686 in epoch 3, gen_loss = 0.9616279857127427, disc_loss = 0.016496127175989566
Trained batch 687 in epoch 3, gen_loss = 0.9616174544532632, disc_loss = 0.01647615716317591
Trained batch 688 in epoch 3, gen_loss = 0.9615960289847176, disc_loss = 0.01645528214038887
Trained batch 689 in epoch 3, gen_loss = 0.9616572742012964, disc_loss = 0.01643416647686694
Trained batch 690 in epoch 3, gen_loss = 0.9617462919865952, disc_loss = 0.016417351569907097
Trained batch 691 in epoch 3, gen_loss = 0.9618652112394399, disc_loss = 0.0163977276392739
Trained batch 692 in epoch 3, gen_loss = 0.9617892948407976, disc_loss = 0.016382763160260435
Trained batch 693 in epoch 3, gen_loss = 0.9618937252062542, disc_loss = 0.01636262654841583
Trained batch 694 in epoch 3, gen_loss = 0.9619849909123757, disc_loss = 0.016342666291605794
Trained batch 695 in epoch 3, gen_loss = 0.9620111914372992, disc_loss = 0.016328231250251218
Trained batch 696 in epoch 3, gen_loss = 0.962209692387875, disc_loss = 0.01630684257142324
Trained batch 697 in epoch 3, gen_loss = 0.9621977373146396, disc_loss = 0.016286659751970217
Trained batch 698 in epoch 3, gen_loss = 0.9622712818338124, disc_loss = 0.016268858068559527
Trained batch 699 in epoch 3, gen_loss = 0.962271790759904, disc_loss = 0.01625172343639341
Trained batch 700 in epoch 3, gen_loss = 0.9623186741337797, disc_loss = 0.016232220619438135
Trained batch 701 in epoch 3, gen_loss = 0.9624144253228125, disc_loss = 0.016211515940790313
Trained batch 702 in epoch 3, gen_loss = 0.9624119400978088, disc_loss = 0.016208094466070428
Trained batch 703 in epoch 3, gen_loss = 0.9622642904181372, disc_loss = 0.016195500288900308
Trained batch 704 in epoch 3, gen_loss = 0.9622208662912355, disc_loss = 0.016177250099626818
Trained batch 705 in epoch 3, gen_loss = 0.9621897574524704, disc_loss = 0.01615806028830028
Trained batch 706 in epoch 3, gen_loss = 0.9622312216812684, disc_loss = 0.01615478190357709
Trained batch 707 in epoch 3, gen_loss = 0.962670137400681, disc_loss = 0.016216750154298853
Trained batch 708 in epoch 3, gen_loss = 0.9629849524188613, disc_loss = 0.016208244384055773
Trained batch 709 in epoch 3, gen_loss = 0.9624054415964745, disc_loss = 0.01680157578004685
Trained batch 710 in epoch 3, gen_loss = 0.961976749400717, disc_loss = 0.017037486548964673
Trained batch 711 in epoch 3, gen_loss = 0.96225427936637, disc_loss = 0.017380561375012916
Trained batch 712 in epoch 3, gen_loss = 0.9620388159410816, disc_loss = 0.0176024518342015
Trained batch 713 in epoch 3, gen_loss = 0.9621429009263923, disc_loss = 0.017687595127391237
Trained batch 714 in epoch 3, gen_loss = 0.9619383563528527, disc_loss = 0.017692750790241903
Trained batch 715 in epoch 3, gen_loss = 0.9617021406829024, disc_loss = 0.017689739026353783
Trained batch 716 in epoch 3, gen_loss = 0.9615003824067747, disc_loss = 0.017684998707911563
Trained batch 717 in epoch 3, gen_loss = 0.9613964360902568, disc_loss = 0.017728965877527585
Trained batch 718 in epoch 3, gen_loss = 0.9610265543132565, disc_loss = 0.01777350917342038
Trained batch 719 in epoch 3, gen_loss = 0.9611768633127212, disc_loss = 0.01776174486037942
Trained batch 720 in epoch 3, gen_loss = 0.9612825348373921, disc_loss = 0.01790389597521925
Trained batch 721 in epoch 3, gen_loss = 0.9614497920152554, disc_loss = 0.017897400934265447
Trained batch 722 in epoch 3, gen_loss = 0.9615641233832015, disc_loss = 0.017889488784888247
Trained batch 723 in epoch 3, gen_loss = 0.9612929685998358, disc_loss = 0.01788191563462744
Trained batch 724 in epoch 3, gen_loss = 0.9612264121811965, disc_loss = 0.017860130870510055
Trained batch 725 in epoch 3, gen_loss = 0.9607703410725291, disc_loss = 0.017908348234809874
Trained batch 726 in epoch 3, gen_loss = 0.960177018767046, disc_loss = 0.0180377171051913
Trained batch 727 in epoch 3, gen_loss = 0.9604771346017554, disc_loss = 0.018147623470772836
Trained batch 728 in epoch 3, gen_loss = 0.9605966753266312, disc_loss = 0.018140906515162834
Trained batch 729 in epoch 3, gen_loss = 0.9604193733979578, disc_loss = 0.01823641450500374
Trained batch 730 in epoch 3, gen_loss = 0.9603485205757308, disc_loss = 0.018570036479424356
Trained batch 731 in epoch 3, gen_loss = 0.9599973058602849, disc_loss = 0.01866760141395692
Trained batch 732 in epoch 3, gen_loss = 0.9596531372441114, disc_loss = 0.018681299844605048
Trained batch 733 in epoch 3, gen_loss = 0.9595819451828419, disc_loss = 0.018675066534372214
Trained batch 734 in epoch 3, gen_loss = 0.9596400410139642, disc_loss = 0.01868967713812306
Trained batch 735 in epoch 3, gen_loss = 0.9595339358176874, disc_loss = 0.01871071302232098
Trained batch 736 in epoch 3, gen_loss = 0.959659468852681, disc_loss = 0.018693416580176987
Trained batch 737 in epoch 3, gen_loss = 0.9597357269225082, disc_loss = 0.018845003671038845
Trained batch 738 in epoch 3, gen_loss = 0.9591352963802456, disc_loss = 0.019027724395669444
Trained batch 739 in epoch 3, gen_loss = 0.9585842353266638, disc_loss = 0.019345738554890173
Trained batch 740 in epoch 3, gen_loss = 0.9588559042265219, disc_loss = 0.020003005356846633
Trained batch 741 in epoch 3, gen_loss = 0.9584646695707686, disc_loss = 0.020291185782045768
Trained batch 742 in epoch 3, gen_loss = 0.9579660291626829, disc_loss = 0.02046812537036072
Trained batch 743 in epoch 3, gen_loss = 0.9576337411999702, disc_loss = 0.02058936014347187
Trained batch 744 in epoch 3, gen_loss = 0.9570320979060742, disc_loss = 0.020797042496015643
Trained batch 745 in epoch 3, gen_loss = 0.9566116209963371, disc_loss = 0.020996359791020686
Trained batch 746 in epoch 3, gen_loss = 0.9565192512878612, disc_loss = 0.021261213810970587
Trained batch 747 in epoch 3, gen_loss = 0.9560475362175926, disc_loss = 0.021673027522984754
Trained batch 748 in epoch 3, gen_loss = 0.9555602473155838, disc_loss = 0.021848294060685527
Trained batch 749 in epoch 3, gen_loss = 0.9555069533189138, disc_loss = 0.022271984097722453
Trained batch 750 in epoch 3, gen_loss = 0.9549364725378319, disc_loss = 0.022591620403269556
Trained batch 751 in epoch 3, gen_loss = 0.9546316488784679, disc_loss = 0.022774578188410544
Trained batch 752 in epoch 3, gen_loss = 0.9541235649253268, disc_loss = 0.022991594424209828
Trained batch 753 in epoch 3, gen_loss = 0.9537419170852681, disc_loss = 0.023115231339197972
Trained batch 754 in epoch 3, gen_loss = 0.9539350640694827, disc_loss = 0.023209401775041244
Trained batch 755 in epoch 3, gen_loss = 0.9539347615822282, disc_loss = 0.023375563468728197
Trained batch 756 in epoch 3, gen_loss = 0.9534058164573881, disc_loss = 0.02358081563555588
Trained batch 757 in epoch 3, gen_loss = 0.9533232116290321, disc_loss = 0.023620043758237348
Trained batch 758 in epoch 3, gen_loss = 0.9534223421289044, disc_loss = 0.023753903926325176
Trained batch 759 in epoch 3, gen_loss = 0.9532968843453808, disc_loss = 0.02377008502848376
Trained batch 760 in epoch 3, gen_loss = 0.9530950633517703, disc_loss = 0.023806884965472168
Trained batch 761 in epoch 3, gen_loss = 0.9532140059264627, disc_loss = 0.02380883121199425
Trained batch 762 in epoch 3, gen_loss = 0.9530725392414108, disc_loss = 0.02393946654563736
Trained batch 763 in epoch 3, gen_loss = 0.9525631939241399, disc_loss = 0.02416120153102193
Trained batch 764 in epoch 3, gen_loss = 0.9523781401659149, disc_loss = 0.024351850770329416
Trained batch 765 in epoch 3, gen_loss = 0.9520293744207985, disc_loss = 0.02439735405250497
Trained batch 766 in epoch 3, gen_loss = 0.9515786504341384, disc_loss = 0.02451695396394983
Trained batch 767 in epoch 3, gen_loss = 0.9514546698580185, disc_loss = 0.024518518366543656
Trained batch 768 in epoch 3, gen_loss = 0.9511534766195965, disc_loss = 0.02457769280734399
Trained batch 769 in epoch 3, gen_loss = 0.9511458485157459, disc_loss = 0.024809293601190968
Trained batch 770 in epoch 3, gen_loss = 0.9507211530254973, disc_loss = 0.02495617899503852
Trained batch 771 in epoch 3, gen_loss = 0.9503266314150756, disc_loss = 0.025080278658036203
Trained batch 772 in epoch 3, gen_loss = 0.9504838856503387, disc_loss = 0.02506814064037607
Trained batch 773 in epoch 3, gen_loss = 0.9507996617053522, disc_loss = 0.0252754561173393
Trained batch 774 in epoch 3, gen_loss = 0.9506303864909756, disc_loss = 0.025400236332958053
Trained batch 775 in epoch 3, gen_loss = 0.9504679323932559, disc_loss = 0.025408177451608185
Trained batch 776 in epoch 3, gen_loss = 0.9503360462771726, disc_loss = 0.025510268750801434
Trained batch 777 in epoch 3, gen_loss = 0.9497758975218991, disc_loss = 0.025608286287763203
Trained batch 778 in epoch 3, gen_loss = 0.9496276172808107, disc_loss = 0.025740696762740614
Trained batch 779 in epoch 3, gen_loss = 0.9491835860105661, disc_loss = 0.026074678648896784
Trained batch 780 in epoch 3, gen_loss = 0.9492657231918218, disc_loss = 0.026115373323008055
Trained batch 781 in epoch 3, gen_loss = 0.9495299531675666, disc_loss = 0.026180957162817802
Trained batch 782 in epoch 3, gen_loss = 0.9497021862982485, disc_loss = 0.02616072038596625
Trained batch 783 in epoch 3, gen_loss = 0.9497727306217564, disc_loss = 0.026136001186999665
Trained batch 784 in epoch 3, gen_loss = 0.949672745519383, disc_loss = 0.026121795986453516
Trained batch 785 in epoch 3, gen_loss = 0.9492747749536092, disc_loss = 0.02619750060497812
Trained batch 786 in epoch 3, gen_loss = 0.9493554855544201, disc_loss = 0.026326944275122055
Trained batch 787 in epoch 3, gen_loss = 0.9492667310582805, disc_loss = 0.026306586014923108
Trained batch 788 in epoch 3, gen_loss = 0.9491705207770315, disc_loss = 0.02632006417937575
Trained batch 789 in epoch 3, gen_loss = 0.9490524224088162, disc_loss = 0.026300611168818835
Trained batch 790 in epoch 3, gen_loss = 0.9491134114120763, disc_loss = 0.02627882076350883
Trained batch 791 in epoch 3, gen_loss = 0.9491065772193851, disc_loss = 0.02625835183736321
Trained batch 792 in epoch 3, gen_loss = 0.9490513300985887, disc_loss = 0.026232685092684678
Trained batch 793 in epoch 3, gen_loss = 0.9491177801821634, disc_loss = 0.026207370774326194
Trained batch 794 in epoch 3, gen_loss = 0.9492321605202537, disc_loss = 0.026179313690583926
Trained batch 795 in epoch 3, gen_loss = 0.9494792399693973, disc_loss = 0.0261524917595166
Trained batch 796 in epoch 3, gen_loss = 0.9498086520090905, disc_loss = 0.026124212645343214
Trained batch 797 in epoch 3, gen_loss = 0.9499989134028441, disc_loss = 0.026098071592720606
Trained batch 798 in epoch 3, gen_loss = 0.9499129437385722, disc_loss = 0.026080284247721092
Trained batch 799 in epoch 3, gen_loss = 0.9500956225395203, disc_loss = 0.026058073384792806
Trained batch 800 in epoch 3, gen_loss = 0.9501912826009458, disc_loss = 0.02603360634521606
Trained batch 801 in epoch 3, gen_loss = 0.9503273990683425, disc_loss = 0.02600661863994502
Trained batch 802 in epoch 3, gen_loss = 0.9505187417026771, disc_loss = 0.02597907462445013
Trained batch 803 in epoch 3, gen_loss = 0.9503289313606955, disc_loss = 0.02595400089149051
Trained batch 804 in epoch 3, gen_loss = 0.9505511379390029, disc_loss = 0.025930074050386945
Trained batch 805 in epoch 3, gen_loss = 0.9504762683849477, disc_loss = 0.025909189839556927
Trained batch 806 in epoch 3, gen_loss = 0.9503497966603276, disc_loss = 0.025886268218070566
Trained batch 807 in epoch 3, gen_loss = 0.9504234961944051, disc_loss = 0.025857775139445607
Trained batch 808 in epoch 3, gen_loss = 0.9505506448898976, disc_loss = 0.025831450723625787
Trained batch 809 in epoch 3, gen_loss = 0.9506946787422086, disc_loss = 0.0258057056579999
Trained batch 810 in epoch 3, gen_loss = 0.9507463588373581, disc_loss = 0.02578001674171724
Trained batch 811 in epoch 3, gen_loss = 0.9508063219157346, disc_loss = 0.025752265623810368
Trained batch 812 in epoch 3, gen_loss = 0.9510040866786117, disc_loss = 0.02572765069007991
Trained batch 813 in epoch 3, gen_loss = 0.9512985991611528, disc_loss = 0.02570126293882735
Trained batch 814 in epoch 3, gen_loss = 0.951242535172796, disc_loss = 0.025682636865638226
Trained batch 815 in epoch 3, gen_loss = 0.9512280913836816, disc_loss = 0.0256620355407993
Trained batch 816 in epoch 3, gen_loss = 0.9512943303716372, disc_loss = 0.025640957831363637
Trained batch 817 in epoch 3, gen_loss = 0.9514368434407018, disc_loss = 0.025633468243571978
Trained batch 818 in epoch 3, gen_loss = 0.9512997592034066, disc_loss = 0.025628483062656228
Trained batch 819 in epoch 3, gen_loss = 0.9511948027261874, disc_loss = 0.025608208838998617
Trained batch 820 in epoch 3, gen_loss = 0.9511490742268719, disc_loss = 0.025611097108670988
Trained batch 821 in epoch 3, gen_loss = 0.95109188759704, disc_loss = 0.02562949388137344
Trained batch 822 in epoch 3, gen_loss = 0.9515909971906956, disc_loss = 0.025635461185913547
Trained batch 823 in epoch 3, gen_loss = 0.9520439629994549, disc_loss = 0.025644923329627558
Trained batch 824 in epoch 3, gen_loss = 0.9522332257935495, disc_loss = 0.025645116739077354
Trained batch 825 in epoch 3, gen_loss = 0.952450710116518, disc_loss = 0.0256273215049073
Trained batch 826 in epoch 3, gen_loss = 0.9523865600018576, disc_loss = 0.0256295215130026
Trained batch 827 in epoch 3, gen_loss = 0.9524482479993848, disc_loss = 0.025606356769146264
Trained batch 828 in epoch 3, gen_loss = 0.9526352187836559, disc_loss = 0.025582364014821297
Trained batch 829 in epoch 3, gen_loss = 0.9528061053839074, disc_loss = 0.02556114439301667
Trained batch 830 in epoch 3, gen_loss = 0.9528971260635432, disc_loss = 0.025535525760135534
Trained batch 831 in epoch 3, gen_loss = 0.9527383651584387, disc_loss = 0.02552216736612186
Trained batch 832 in epoch 3, gen_loss = 0.9528244390350287, disc_loss = 0.025496505943674395
Trained batch 833 in epoch 3, gen_loss = 0.9528066275788726, disc_loss = 0.025470981755611743
Trained batch 834 in epoch 3, gen_loss = 0.952989214908577, disc_loss = 0.02545110413591687
Trained batch 835 in epoch 3, gen_loss = 0.9533151690469405, disc_loss = 0.025428164442188612
Trained batch 836 in epoch 3, gen_loss = 0.9532626687839467, disc_loss = 0.025402165772026853
Trained batch 837 in epoch 3, gen_loss = 0.9532318079670744, disc_loss = 0.025376458520221558
Trained batch 838 in epoch 3, gen_loss = 0.9533796823351545, disc_loss = 0.025348918876157384
Trained batch 839 in epoch 3, gen_loss = 0.9533900666094962, disc_loss = 0.025320224495971204
Trained batch 840 in epoch 3, gen_loss = 0.953269671954383, disc_loss = 0.02531271661851097
Trained batch 841 in epoch 3, gen_loss = 0.9533899778283407, disc_loss = 0.025288161655629828
Trained batch 842 in epoch 3, gen_loss = 0.9533838197005601, disc_loss = 0.02526674580373699
Trained batch 843 in epoch 3, gen_loss = 0.953597310383173, disc_loss = 0.025240039753759203
Trained batch 844 in epoch 3, gen_loss = 0.95358562772796, disc_loss = 0.025217257605568703
Trained batch 845 in epoch 3, gen_loss = 0.9535460999107812, disc_loss = 0.025190293393858094
Trained batch 846 in epoch 3, gen_loss = 0.9536403117804769, disc_loss = 0.025164184097735704
Trained batch 847 in epoch 3, gen_loss = 0.9535466917562034, disc_loss = 0.02513697994547912
Trained batch 848 in epoch 3, gen_loss = 0.9534199250460513, disc_loss = 0.025113159302091834
Trained batch 849 in epoch 3, gen_loss = 0.9534791162434746, disc_loss = 0.025093023326292443
Trained batch 850 in epoch 3, gen_loss = 0.9535720554277843, disc_loss = 0.025066060454713386
Trained batch 851 in epoch 3, gen_loss = 0.953928120259388, disc_loss = 0.02504217852809985
Trained batch 852 in epoch 3, gen_loss = 0.9538217112858718, disc_loss = 0.025018980270372415
Trained batch 853 in epoch 3, gen_loss = 0.9536371397190406, disc_loss = 0.02501221619718787
Trained batch 854 in epoch 3, gen_loss = 0.953761428978011, disc_loss = 0.024997007474456424
Trained batch 855 in epoch 3, gen_loss = 0.9538114297195016, disc_loss = 0.02497675165301257
Trained batch 856 in epoch 3, gen_loss = 0.9538680223906749, disc_loss = 0.024979599284393524
Trained batch 857 in epoch 3, gen_loss = 0.9540191661644649, disc_loss = 0.02495475396277377
Trained batch 858 in epoch 3, gen_loss = 0.9540080652941925, disc_loss = 0.024929894106907796
Trained batch 859 in epoch 3, gen_loss = 0.9540579731381217, disc_loss = 0.024903790559771953
Trained batch 860 in epoch 3, gen_loss = 0.9542892695719357, disc_loss = 0.024879573498930024
Trained batch 861 in epoch 3, gen_loss = 0.9544583826634834, disc_loss = 0.024852446770137353
Trained batch 862 in epoch 3, gen_loss = 0.9546423239475882, disc_loss = 0.024825095832267607
Trained batch 863 in epoch 3, gen_loss = 0.9547460724220231, disc_loss = 0.024799199115999794
Trained batch 864 in epoch 3, gen_loss = 0.954954360330725, disc_loss = 0.024771845153808147
Trained batch 865 in epoch 3, gen_loss = 0.9549060121832489, disc_loss = 0.024744921887372637
Trained batch 866 in epoch 3, gen_loss = 0.9550733499598476, disc_loss = 0.02471735626625957
Trained batch 867 in epoch 3, gen_loss = 0.9550255577547759, disc_loss = 0.02468988396694966
Trained batch 868 in epoch 3, gen_loss = 0.955040559875677, disc_loss = 0.02466328485429266
Trained batch 869 in epoch 3, gen_loss = 0.9549731323773833, disc_loss = 0.024636393940245502
Trained batch 870 in epoch 3, gen_loss = 0.9549231471068276, disc_loss = 0.024609368677354894
Trained batch 871 in epoch 3, gen_loss = 0.9549844852144566, disc_loss = 0.024582337611651933
Trained batch 872 in epoch 3, gen_loss = 0.9549204722849091, disc_loss = 0.024555637395649615
Trained batch 873 in epoch 3, gen_loss = 0.9548762459094792, disc_loss = 0.024528032853135553
Trained batch 874 in epoch 3, gen_loss = 0.9548965017454965, disc_loss = 0.024500941868089803
Trained batch 875 in epoch 3, gen_loss = 0.9548926905273847, disc_loss = 0.02447474222248125
Trained batch 876 in epoch 3, gen_loss = 0.9548871547085666, disc_loss = 0.024448874797194823
Trained batch 877 in epoch 3, gen_loss = 0.9548259863549322, disc_loss = 0.024421607983099846
Trained batch 878 in epoch 3, gen_loss = 0.9547205110323171, disc_loss = 0.02439523092750844
Trained batch 879 in epoch 3, gen_loss = 0.9545705017041076, disc_loss = 0.02436837420459183
Trained batch 880 in epoch 3, gen_loss = 0.9546299510456783, disc_loss = 0.02434252929718434
Trained batch 881 in epoch 3, gen_loss = 0.9546577777721985, disc_loss = 0.024315744501981665
Trained batch 882 in epoch 3, gen_loss = 0.954747414804936, disc_loss = 0.02428922417104871
Trained batch 883 in epoch 3, gen_loss = 0.9547249258103954, disc_loss = 0.024263187686400303
Trained batch 884 in epoch 3, gen_loss = 0.9548442874251113, disc_loss = 0.024236604022167985
Trained batch 885 in epoch 3, gen_loss = 0.954794408505442, disc_loss = 0.024210231301365404
Trained batch 886 in epoch 3, gen_loss = 0.9549873259586305, disc_loss = 0.024183890275112373
Trained batch 887 in epoch 3, gen_loss = 0.9550108019564603, disc_loss = 0.024157390873599298
Trained batch 888 in epoch 3, gen_loss = 0.955040874845936, disc_loss = 0.024131177624515877
Trained batch 889 in epoch 3, gen_loss = 0.9549457649836379, disc_loss = 0.024104900121917096
Trained batch 890 in epoch 3, gen_loss = 0.9550037384702167, disc_loss = 0.024078659347967844
Trained batch 891 in epoch 3, gen_loss = 0.9550737462637136, disc_loss = 0.024052469768382493
Trained batch 892 in epoch 3, gen_loss = 0.9550006948286315, disc_loss = 0.024026150201384863
Trained batch 893 in epoch 3, gen_loss = 0.9549380049476154, disc_loss = 0.024002666420762826
Trained batch 894 in epoch 3, gen_loss = 0.9548832570374345, disc_loss = 0.023977055715207744
Trained batch 895 in epoch 3, gen_loss = 0.9548854496596115, disc_loss = 0.02395140274550808
Trained batch 896 in epoch 3, gen_loss = 0.9547914418089749, disc_loss = 0.023925398166451436
Trained batch 897 in epoch 3, gen_loss = 0.9548329355191016, disc_loss = 0.02390001507425478
Trained batch 898 in epoch 3, gen_loss = 0.9549061431237668, disc_loss = 0.023874325244027723
Trained batch 899 in epoch 3, gen_loss = 0.954941182202763, disc_loss = 0.02384863611972024
Trained batch 900 in epoch 3, gen_loss = 0.954970166699074, disc_loss = 0.02382279299613366
Trained batch 901 in epoch 3, gen_loss = 0.9548408665968944, disc_loss = 0.023798167577585513
Trained batch 902 in epoch 3, gen_loss = 0.9548010603666042, disc_loss = 0.023773044778954196
Trained batch 903 in epoch 3, gen_loss = 0.9548554554317905, disc_loss = 0.023747819778216467
Trained batch 904 in epoch 3, gen_loss = 0.9548825359476205, disc_loss = 0.023722357622194053
Trained batch 905 in epoch 3, gen_loss = 0.9549042591064445, disc_loss = 0.02369681504490093
Trained batch 906 in epoch 3, gen_loss = 0.9548307711129151, disc_loss = 0.023671695714908993
Trained batch 907 in epoch 3, gen_loss = 0.9549209451885475, disc_loss = 0.02364626079814733
Trained batch 908 in epoch 3, gen_loss = 0.9550003656590863, disc_loss = 0.02362126176532963
Trained batch 909 in epoch 3, gen_loss = 0.9549684258607718, disc_loss = 0.023595945899848758
Trained batch 910 in epoch 3, gen_loss = 0.9549768712334785, disc_loss = 0.023571087264650223
Trained batch 911 in epoch 3, gen_loss = 0.9550428163717714, disc_loss = 0.023546182434856427
Trained batch 912 in epoch 3, gen_loss = 0.9550194230424353, disc_loss = 0.02352108443911054
Trained batch 913 in epoch 3, gen_loss = 0.9550299632731882, disc_loss = 0.023495929636353757
Trained batch 914 in epoch 3, gen_loss = 0.954986083898388, disc_loss = 0.023470856967179203
Trained batch 915 in epoch 3, gen_loss = 0.9549983740503611, disc_loss = 0.023445692092072097
Trained batch 916 in epoch 3, gen_loss = 0.9550155769777662, disc_loss = 0.02342101050200382
Trained batch 917 in epoch 3, gen_loss = 0.9549623959594302, disc_loss = 0.02339611070846983
Trained batch 918 in epoch 3, gen_loss = 0.9548690838575103, disc_loss = 0.023371256734967212
Trained batch 919 in epoch 3, gen_loss = 0.9549239319951638, disc_loss = 0.023347129091147823
Trained batch 920 in epoch 3, gen_loss = 0.9549339532722738, disc_loss = 0.023323200964705738
Trained batch 921 in epoch 3, gen_loss = 0.9549486262162181, disc_loss = 0.023298700634429133
Trained batch 922 in epoch 3, gen_loss = 0.9548224420614646, disc_loss = 0.02327411268364584
Trained batch 923 in epoch 3, gen_loss = 0.954861343616531, disc_loss = 0.023249494164426295
Trained batch 924 in epoch 3, gen_loss = 0.9547700384500865, disc_loss = 0.023225206231739296
Trained batch 925 in epoch 3, gen_loss = 0.9549057875029726, disc_loss = 0.02320069345461366
Trained batch 926 in epoch 3, gen_loss = 0.9549050291250696, disc_loss = 0.023179895480461905
Trained batch 927 in epoch 3, gen_loss = 0.9549602528327498, disc_loss = 0.02315732383062666
Trained batch 928 in epoch 3, gen_loss = 0.9548960453214121, disc_loss = 0.023133558674369722
Trained batch 929 in epoch 3, gen_loss = 0.954837514251791, disc_loss = 0.023111659031619835
Trained batch 930 in epoch 3, gen_loss = 0.9547413885913525, disc_loss = 0.023099813136729416
Trained batch 931 in epoch 3, gen_loss = 0.9547129251670428, disc_loss = 0.02307687670249073
Trained batch 932 in epoch 3, gen_loss = 0.9548168437912788, disc_loss = 0.023058840872534344
Trained batch 933 in epoch 3, gen_loss = 0.9548669341289512, disc_loss = 0.023037868263566994
Trained batch 934 in epoch 3, gen_loss = 0.9548061500896107, disc_loss = 0.023015383177609334
Trained batch 935 in epoch 3, gen_loss = 0.9547732182038136, disc_loss = 0.022992523851320987
Trained batch 936 in epoch 3, gen_loss = 0.9547215387177442, disc_loss = 0.022970547020043846
Trained batch 937 in epoch 3, gen_loss = 0.9547042806011273, disc_loss = 0.02294714193734867
Trained batch 938 in epoch 3, gen_loss = 0.9547476905603378, disc_loss = 0.022924374037894473
Trained batch 939 in epoch 3, gen_loss = 0.9547448519696581, disc_loss = 0.02290156198923409
Trained batch 940 in epoch 3, gen_loss = 0.9547023075166595, disc_loss = 0.02288001553372539
Trained batch 941 in epoch 3, gen_loss = 0.9547005610228091, disc_loss = 0.022857122914127205
Trained batch 942 in epoch 3, gen_loss = 0.9546734899250852, disc_loss = 0.02283443105407368
Trained batch 943 in epoch 3, gen_loss = 0.9546423741947796, disc_loss = 0.022811451984002275
Trained batch 944 in epoch 3, gen_loss = 0.954551273552829, disc_loss = 0.022790372737750496
Trained batch 945 in epoch 3, gen_loss = 0.9544061630901273, disc_loss = 0.022787037145508966
Trained batch 946 in epoch 3, gen_loss = 0.9540843854735997, disc_loss = 0.022789344114304663
Trained batch 947 in epoch 3, gen_loss = 0.9541106216515167, disc_loss = 0.022767001706697286
Trained batch 948 in epoch 3, gen_loss = 0.9540699939582069, disc_loss = 0.022745993625703495
Trained batch 949 in epoch 3, gen_loss = 0.9541354226438623, disc_loss = 0.022724130724167672
Trained batch 950 in epoch 3, gen_loss = 0.9541869913741994, disc_loss = 0.02270383284898579
Trained batch 951 in epoch 3, gen_loss = 0.9544187714697934, disc_loss = 0.022682450696762516
Trained batch 952 in epoch 3, gen_loss = 0.9544873168185776, disc_loss = 0.022660996461659595
Trained batch 953 in epoch 3, gen_loss = 0.9544968383242249, disc_loss = 0.02263934916076975
Trained batch 954 in epoch 3, gen_loss = 0.9543620182581597, disc_loss = 0.022617331328536678
Trained batch 955 in epoch 3, gen_loss = 0.9545150144204934, disc_loss = 0.022595182956670918
Trained batch 956 in epoch 3, gen_loss = 0.954397974156287, disc_loss = 0.022572327613366
Trained batch 957 in epoch 3, gen_loss = 0.9543235452538492, disc_loss = 0.022549508451081307
Trained batch 958 in epoch 3, gen_loss = 0.9542553575866787, disc_loss = 0.02252693728447493
Trained batch 959 in epoch 3, gen_loss = 0.9541565055648485, disc_loss = 0.022504632011941795
Trained batch 960 in epoch 3, gen_loss = 0.9541251939739819, disc_loss = 0.022481719969869803
Trained batch 961 in epoch 3, gen_loss = 0.9541549819546777, disc_loss = 0.022459043335901565
Trained batch 962 in epoch 3, gen_loss = 0.9543035048314468, disc_loss = 0.022437497408728035
Trained batch 963 in epoch 3, gen_loss = 0.954347727828006, disc_loss = 0.02241524101456995
Trained batch 964 in epoch 3, gen_loss = 0.9543313786155819, disc_loss = 0.02239297480882481
Trained batch 965 in epoch 3, gen_loss = 0.9543907737386399, disc_loss = 0.022371097504550914
Trained batch 966 in epoch 3, gen_loss = 0.9544403364394543, disc_loss = 0.022348617869234862
Trained batch 967 in epoch 3, gen_loss = 0.9545733176233354, disc_loss = 0.022327344900640887
Trained batch 968 in epoch 3, gen_loss = 0.9546105251469725, disc_loss = 0.022305553143662477
Trained batch 969 in epoch 3, gen_loss = 0.9544871869775438, disc_loss = 0.02228378268679155
Trained batch 970 in epoch 3, gen_loss = 0.9544993001818043, disc_loss = 0.022261478818644796
Trained batch 971 in epoch 3, gen_loss = 0.9543622447016799, disc_loss = 0.022239154372357694
Trained batch 972 in epoch 3, gen_loss = 0.9543031945380498, disc_loss = 0.02221788802942539
Trained batch 973 in epoch 3, gen_loss = 0.9543900990388232, disc_loss = 0.02219588514455956
Trained batch 974 in epoch 3, gen_loss = 0.9544779040263249, disc_loss = 0.022173600850749212
Trained batch 975 in epoch 3, gen_loss = 0.9544528187786947, disc_loss = 0.022151494705332106
Trained batch 976 in epoch 3, gen_loss = 0.9544649183323097, disc_loss = 0.022129501997493327
Trained batch 977 in epoch 3, gen_loss = 0.954288741013755, disc_loss = 0.02210893892609109
Trained batch 978 in epoch 3, gen_loss = 0.9542918169340148, disc_loss = 0.022086804902383298
Trained batch 979 in epoch 3, gen_loss = 0.9542311895866783, disc_loss = 0.02206502100620573
Trained batch 980 in epoch 3, gen_loss = 0.9542155779829813, disc_loss = 0.022043877953410583
Trained batch 981 in epoch 3, gen_loss = 0.9541928345705487, disc_loss = 0.02202220929757459
Trained batch 982 in epoch 3, gen_loss = 0.9543107076190859, disc_loss = 0.022000401240747088
Trained batch 983 in epoch 3, gen_loss = 0.9543437659134709, disc_loss = 0.02197856645974886
Trained batch 984 in epoch 3, gen_loss = 0.9544648230378397, disc_loss = 0.02195718637515429
Trained batch 985 in epoch 3, gen_loss = 0.9543942630774592, disc_loss = 0.02193562077371884
Trained batch 986 in epoch 3, gen_loss = 0.9544953196606738, disc_loss = 0.021914015933326935
Trained batch 987 in epoch 3, gen_loss = 0.9546117417604817, disc_loss = 0.021892747823232035
Trained batch 988 in epoch 3, gen_loss = 0.9545709946399029, disc_loss = 0.021871108699254377
Trained batch 989 in epoch 3, gen_loss = 0.9546434584892157, disc_loss = 0.021849783515569994
Trained batch 990 in epoch 3, gen_loss = 0.9546276884892153, disc_loss = 0.02182833039289959
Trained batch 991 in epoch 3, gen_loss = 0.9545612702326428, disc_loss = 0.02180720547885944
Trained batch 992 in epoch 3, gen_loss = 0.9544845567969277, disc_loss = 0.021785912919224593
Trained batch 993 in epoch 3, gen_loss = 0.9545845387567217, disc_loss = 0.021764911867934538
Trained batch 994 in epoch 3, gen_loss = 0.9545800971625439, disc_loss = 0.021743888163839084
Trained batch 995 in epoch 3, gen_loss = 0.9546222401311598, disc_loss = 0.02172313281552631
Trained batch 996 in epoch 3, gen_loss = 0.9546875259582114, disc_loss = 0.021702472641371092
Trained batch 997 in epoch 3, gen_loss = 0.9546811695925458, disc_loss = 0.02168143412769543
Trained batch 998 in epoch 3, gen_loss = 0.9547817115788465, disc_loss = 0.021660488375637506
Trained batch 999 in epoch 3, gen_loss = 0.954767297744751, disc_loss = 0.021639337588407217
Trained batch 1000 in epoch 3, gen_loss = 0.9548198295520854, disc_loss = 0.02161890211334923
Trained batch 1001 in epoch 3, gen_loss = 0.9547060169502647, disc_loss = 0.02159775972707969
Trained batch 1002 in epoch 3, gen_loss = 0.9547879000009591, disc_loss = 0.021576990507272534
Trained batch 1003 in epoch 3, gen_loss = 0.9548368965130878, disc_loss = 0.021556673481387567
Trained batch 1004 in epoch 3, gen_loss = 0.9548141380447653, disc_loss = 0.021535522949291667
Trained batch 1005 in epoch 3, gen_loss = 0.9549339524438794, disc_loss = 0.02151456311791841
Trained batch 1006 in epoch 3, gen_loss = 0.9548953368505158, disc_loss = 0.02149364632086899
Trained batch 1007 in epoch 3, gen_loss = 0.9547336543244975, disc_loss = 0.021473123937987167
Trained batch 1008 in epoch 3, gen_loss = 0.9546876688542286, disc_loss = 0.02145299749259735
Trained batch 1009 in epoch 3, gen_loss = 0.9547014190418885, disc_loss = 0.021432159017955327
Trained batch 1010 in epoch 3, gen_loss = 0.9546718436461882, disc_loss = 0.021411383285704317
Trained batch 1011 in epoch 3, gen_loss = 0.9546858235427984, disc_loss = 0.021390579739119512
Trained batch 1012 in epoch 3, gen_loss = 0.9547351406333713, disc_loss = 0.021369957220998614
Trained batch 1013 in epoch 3, gen_loss = 0.9548460933466164, disc_loss = 0.021349319649959113
Trained batch 1014 in epoch 3, gen_loss = 0.9548279435176568, disc_loss = 0.021328580898351466
Trained batch 1015 in epoch 3, gen_loss = 0.9547474949261335, disc_loss = 0.02130797905239859
Trained batch 1016 in epoch 3, gen_loss = 0.9547498196275537, disc_loss = 0.021287392246403095
Trained batch 1017 in epoch 3, gen_loss = 0.9545626921363336, disc_loss = 0.02126752046315804
Trained batch 1018 in epoch 3, gen_loss = 0.9546128702116902, disc_loss = 0.02124715800933991
Trained batch 1019 in epoch 3, gen_loss = 0.954553370031656, disc_loss = 0.02122698841899275
Trained batch 1020 in epoch 3, gen_loss = 0.9543612790271188, disc_loss = 0.021206810831155123
Trained batch 1021 in epoch 3, gen_loss = 0.9543280613165779, disc_loss = 0.021186577836836987
Trained batch 1022 in epoch 3, gen_loss = 0.9544080198685095, disc_loss = 0.021166465373935458
Trained batch 1023 in epoch 3, gen_loss = 0.9543347114231437, disc_loss = 0.021146184851446037
Trained batch 1024 in epoch 3, gen_loss = 0.954393345786304, disc_loss = 0.021126692084064595
Trained batch 1025 in epoch 3, gen_loss = 0.954328449497446, disc_loss = 0.021106805458482102
Trained batch 1026 in epoch 3, gen_loss = 0.9543278936401894, disc_loss = 0.0210865563149216
Trained batch 1027 in epoch 3, gen_loss = 0.9544370082217896, disc_loss = 0.021066484513302657
Trained batch 1028 in epoch 3, gen_loss = 0.9543566868882137, disc_loss = 0.021046318804164257
Trained batch 1029 in epoch 3, gen_loss = 0.9543209861783148, disc_loss = 0.021026395070233756
Trained batch 1030 in epoch 3, gen_loss = 0.9542327456169054, disc_loss = 0.021006352684462725
Trained batch 1031 in epoch 3, gen_loss = 0.9540788893436276, disc_loss = 0.02098654448298109
Trained batch 1032 in epoch 3, gen_loss = 0.954100103715267, disc_loss = 0.020967362117964305
Trained batch 1033 in epoch 3, gen_loss = 0.9540937753895035, disc_loss = 0.020948029805906005
Trained batch 1034 in epoch 3, gen_loss = 0.9541101031833225, disc_loss = 0.02092829891428484
Trained batch 1035 in epoch 3, gen_loss = 0.9541271522238448, disc_loss = 0.020908806176963925
Trained batch 1036 in epoch 3, gen_loss = 0.9541980509817772, disc_loss = 0.020889097985802213
Trained batch 1037 in epoch 3, gen_loss = 0.9541430720818984, disc_loss = 0.020869251950139826
Trained batch 1038 in epoch 3, gen_loss = 0.9539963238737237, disc_loss = 0.020849942338106237
Trained batch 1039 in epoch 3, gen_loss = 0.9540414390655664, disc_loss = 0.020830262428591175
Trained batch 1040 in epoch 3, gen_loss = 0.9540012916845272, disc_loss = 0.020810820149505707
Trained batch 1041 in epoch 3, gen_loss = 0.9540874080557283, disc_loss = 0.020791617227562828
Trained batch 1042 in epoch 3, gen_loss = 0.9540135460983415, disc_loss = 0.020772509265551856
Trained batch 1043 in epoch 3, gen_loss = 0.9539279809285854, disc_loss = 0.02075288629718716
Trained batch 1044 in epoch 3, gen_loss = 0.9539795133485749, disc_loss = 0.02073382466952662
Trained batch 1045 in epoch 3, gen_loss = 0.953889317653831, disc_loss = 0.02071434829456041
Trained batch 1046 in epoch 3, gen_loss = 0.953889535457152, disc_loss = 0.020694867018456242
Trained batch 1047 in epoch 3, gen_loss = 0.9538099762933855, disc_loss = 0.020675564242339937
Trained batch 1048 in epoch 3, gen_loss = 0.9538942914672757, disc_loss = 0.02065632191867143
Trained batch 1049 in epoch 3, gen_loss = 0.953962865500223, disc_loss = 0.020637284804792475
Trained batch 1050 in epoch 3, gen_loss = 0.9539249293243851, disc_loss = 0.020618090248730615
Trained batch 1051 in epoch 3, gen_loss = 0.9538658307192444, disc_loss = 0.020598759991019993
Trained batch 1052 in epoch 3, gen_loss = 0.954001342638945, disc_loss = 0.02057983618676992
Trained batch 1053 in epoch 3, gen_loss = 0.9539791038524946, disc_loss = 0.020560663982153234
Trained batch 1054 in epoch 3, gen_loss = 0.9539378851510902, disc_loss = 0.020541514526907535
Trained batch 1055 in epoch 3, gen_loss = 0.9539015339969685, disc_loss = 0.020522317972832257
Trained batch 1056 in epoch 3, gen_loss = 0.953962603434145, disc_loss = 0.020503334459020358
Trained batch 1057 in epoch 3, gen_loss = 0.9540025547343977, disc_loss = 0.02048450950978512
Trained batch 1058 in epoch 3, gen_loss = 0.9540007193770692, disc_loss = 0.020465662394936867
Trained batch 1059 in epoch 3, gen_loss = 0.9539760923048235, disc_loss = 0.020447007524888008
Trained batch 1060 in epoch 3, gen_loss = 0.9539353723350726, disc_loss = 0.020428150716304324
Trained batch 1061 in epoch 3, gen_loss = 0.9539462762925135, disc_loss = 0.0204096107880896
Trained batch 1062 in epoch 3, gen_loss = 0.9539683070927438, disc_loss = 0.02039113911151041
Trained batch 1063 in epoch 3, gen_loss = 0.9539509347282854, disc_loss = 0.020372470193237825
Trained batch 1064 in epoch 3, gen_loss = 0.9537795850368732, disc_loss = 0.02035434525584345
Trained batch 1065 in epoch 3, gen_loss = 0.9539398356405476, disc_loss = 0.020336327165223576
Trained batch 1066 in epoch 3, gen_loss = 0.9537985352790568, disc_loss = 0.02031809497410953
Trained batch 1067 in epoch 3, gen_loss = 0.9537813897882954, disc_loss = 0.020299862041737084
Trained batch 1068 in epoch 3, gen_loss = 0.9536649046153861, disc_loss = 0.02028125916699754
Trained batch 1069 in epoch 3, gen_loss = 0.9536781173443126, disc_loss = 0.020263048583490963
Trained batch 1070 in epoch 3, gen_loss = 0.9536580427242817, disc_loss = 0.020244885250522423
Trained batch 1071 in epoch 3, gen_loss = 0.9536427818794748, disc_loss = 0.020226636104875503
Trained batch 1072 in epoch 3, gen_loss = 0.9536561163807182, disc_loss = 0.020208110577475784
Trained batch 1073 in epoch 3, gen_loss = 0.9536312838506432, disc_loss = 0.020189817927073098
Trained batch 1074 in epoch 3, gen_loss = 0.9535809751444084, disc_loss = 0.02017189030149724
Trained batch 1075 in epoch 3, gen_loss = 0.9536210558339122, disc_loss = 0.02015374032566036
Trained batch 1076 in epoch 3, gen_loss = 0.953468912933973, disc_loss = 0.020135456117035103
Trained batch 1077 in epoch 3, gen_loss = 0.9534947014584834, disc_loss = 0.0201171224117373
Trained batch 1078 in epoch 3, gen_loss = 0.9535096911394121, disc_loss = 0.020099117975272356
Trained batch 1079 in epoch 3, gen_loss = 0.9534180857517102, disc_loss = 0.020080815757561748
Trained batch 1080 in epoch 3, gen_loss = 0.9534049696882603, disc_loss = 0.02006261101099768
Trained batch 1081 in epoch 3, gen_loss = 0.9533618076010685, disc_loss = 0.020044423858738954
Trained batch 1082 in epoch 3, gen_loss = 0.9533754316943724, disc_loss = 0.02002642528604192
Trained batch 1083 in epoch 3, gen_loss = 0.9533660934750005, disc_loss = 0.0200085215295032
Trained batch 1084 in epoch 3, gen_loss = 0.9533590422797313, disc_loss = 0.01999040562502583
Trained batch 1085 in epoch 3, gen_loss = 0.9532963691166093, disc_loss = 0.01997260102461867
Trained batch 1086 in epoch 3, gen_loss = 0.9532742430665895, disc_loss = 0.019954862932563953
Trained batch 1087 in epoch 3, gen_loss = 0.9532990107751068, disc_loss = 0.019936996031460427
Trained batch 1088 in epoch 3, gen_loss = 0.9533384196576555, disc_loss = 0.019919080842962286
Trained batch 1089 in epoch 3, gen_loss = 0.953387581427163, disc_loss = 0.019901607103297088
Trained batch 1090 in epoch 3, gen_loss = 0.9532294275561787, disc_loss = 0.019884400843152555
Trained batch 1091 in epoch 3, gen_loss = 0.9531294381443834, disc_loss = 0.019867429299782274
Trained batch 1092 in epoch 3, gen_loss = 0.9530013655154724, disc_loss = 0.019851260663289554
Trained batch 1093 in epoch 3, gen_loss = 0.9528825366954699, disc_loss = 0.019834456011910785
Trained batch 1094 in epoch 3, gen_loss = 0.9529227769538148, disc_loss = 0.01981721940362926
Trained batch 1095 in epoch 3, gen_loss = 0.9528672011011708, disc_loss = 0.019799793853245935
Trained batch 1096 in epoch 3, gen_loss = 0.9529421163235563, disc_loss = 0.019784820499256787
Trained batch 1097 in epoch 3, gen_loss = 0.952810913541495, disc_loss = 0.019768729395139687
Trained batch 1098 in epoch 3, gen_loss = 0.9526983900326181, disc_loss = 0.01975523641650928
Trained batch 1099 in epoch 3, gen_loss = 0.952669983831319, disc_loss = 0.0197399235789172
Trained batch 1100 in epoch 3, gen_loss = 0.9526963297829207, disc_loss = 0.019722890051448786
Trained batch 1101 in epoch 3, gen_loss = 0.9529650236214571, disc_loss = 0.019710333594612793
Trained batch 1102 in epoch 3, gen_loss = 0.9530325886993547, disc_loss = 0.019697421769218806
Trained batch 1103 in epoch 3, gen_loss = 0.9530335004994834, disc_loss = 0.019681158562190725
Trained batch 1104 in epoch 3, gen_loss = 0.9529180674531341, disc_loss = 0.019664195623199827
Trained batch 1105 in epoch 3, gen_loss = 0.952830150534835, disc_loss = 0.019655239112292788
Trained batch 1106 in epoch 3, gen_loss = 0.9527918335652718, disc_loss = 0.01964052582057157
Trained batch 1107 in epoch 3, gen_loss = 0.952812705713489, disc_loss = 0.019623533351405584
Trained batch 1108 in epoch 3, gen_loss = 0.9528753654821377, disc_loss = 0.019607143057486637
Trained batch 1109 in epoch 3, gen_loss = 0.9527843153154528, disc_loss = 0.0195915099406832
Trained batch 1110 in epoch 3, gen_loss = 0.9527355962567883, disc_loss = 0.019579032802063964
Trained batch 1111 in epoch 3, gen_loss = 0.9526996823737948, disc_loss = 0.01956273231245969
Trained batch 1112 in epoch 3, gen_loss = 0.9529136783457617, disc_loss = 0.01954611039620639
Trained batch 1113 in epoch 3, gen_loss = 0.9529765568258947, disc_loss = 0.019533568775676642
Trained batch 1114 in epoch 3, gen_loss = 0.9529897042988662, disc_loss = 0.019517901327892734
Trained batch 1115 in epoch 3, gen_loss = 0.9530539539338867, disc_loss = 0.019502040370273897
Trained batch 1116 in epoch 3, gen_loss = 0.9529901866733548, disc_loss = 0.01948607161135595
Trained batch 1117 in epoch 3, gen_loss = 0.9530302400772388, disc_loss = 0.019469315169209075
Trained batch 1118 in epoch 3, gen_loss = 0.952924558208711, disc_loss = 0.019452524718857524
Trained batch 1119 in epoch 3, gen_loss = 0.9530719593699489, disc_loss = 0.019436276175357696
Trained batch 1120 in epoch 3, gen_loss = 0.9531736861479059, disc_loss = 0.01941975040801763
Trained batch 1121 in epoch 3, gen_loss = 0.9532555684367603, disc_loss = 0.019403401677309036
Trained batch 1122 in epoch 3, gen_loss = 0.9532353186437517, disc_loss = 0.01938704293727274
Trained batch 1123 in epoch 3, gen_loss = 0.9532332684964048, disc_loss = 0.019370417048828074
Trained batch 1124 in epoch 3, gen_loss = 0.9530946349567837, disc_loss = 0.01935464923946549
Trained batch 1125 in epoch 3, gen_loss = 0.953225133844633, disc_loss = 0.01933816039039566
Trained batch 1126 in epoch 3, gen_loss = 0.9531972215253903, disc_loss = 0.01932411910697209
Trained batch 1127 in epoch 3, gen_loss = 0.9530879076808056, disc_loss = 0.01931539534492629
Trained batch 1128 in epoch 3, gen_loss = 0.953091313872747, disc_loss = 0.019299129126475405
Trained batch 1129 in epoch 3, gen_loss = 0.9530352377786045, disc_loss = 0.019283538864164684
Trained batch 1130 in epoch 3, gen_loss = 0.9530083565560197, disc_loss = 0.019267221123194112
Trained batch 1131 in epoch 3, gen_loss = 0.9529290242456294, disc_loss = 0.019257995469617314
Trained batch 1132 in epoch 3, gen_loss = 0.9529535243286038, disc_loss = 0.019244189417650468
Trained batch 1133 in epoch 3, gen_loss = 0.9528819691567194, disc_loss = 0.01923063861070818
Trained batch 1134 in epoch 3, gen_loss = 0.9528519688198746, disc_loss = 0.019215259569046284
Trained batch 1135 in epoch 3, gen_loss = 0.95281219429953, disc_loss = 0.019203811628691433
Trained batch 1136 in epoch 3, gen_loss = 0.9529106202834304, disc_loss = 0.019190132990169743
Trained batch 1137 in epoch 3, gen_loss = 0.9529381368721725, disc_loss = 0.019174824045315408
Trained batch 1138 in epoch 3, gen_loss = 0.9529272128972597, disc_loss = 0.01915921538698381
Trained batch 1139 in epoch 3, gen_loss = 0.9529306540886561, disc_loss = 0.019145051732885533
Trained batch 1140 in epoch 3, gen_loss = 0.9528504986704492, disc_loss = 0.019130904561168952
Trained batch 1141 in epoch 3, gen_loss = 0.9531323643052223, disc_loss = 0.01911673485203318
Trained batch 1142 in epoch 3, gen_loss = 0.9531344912183566, disc_loss = 0.01910092471308152
Trained batch 1143 in epoch 3, gen_loss = 0.9530870946762445, disc_loss = 0.01908512571032582
Trained batch 1144 in epoch 3, gen_loss = 0.9530454275389426, disc_loss = 0.01906940513782307
Trained batch 1145 in epoch 3, gen_loss = 0.9530811792476848, disc_loss = 0.019055491902360697
Trained batch 1146 in epoch 3, gen_loss = 0.9530723276820096, disc_loss = 0.019040003175980293
Trained batch 1147 in epoch 3, gen_loss = 0.9529247876347565, disc_loss = 0.019030995081088693
Trained batch 1148 in epoch 3, gen_loss = 0.9528713587888746, disc_loss = 0.019016555433902297
Trained batch 1149 in epoch 3, gen_loss = 0.9528506286247916, disc_loss = 0.019001804868445184
Trained batch 1150 in epoch 3, gen_loss = 0.9528227771084584, disc_loss = 0.018987674663426636
Trained batch 1151 in epoch 3, gen_loss = 0.9529780115311345, disc_loss = 0.018972549550135734
Trained batch 1152 in epoch 3, gen_loss = 0.9530072871333913, disc_loss = 0.018960121977289898
Trained batch 1153 in epoch 3, gen_loss = 0.9530061918796658, disc_loss = 0.018944544596147125
Trained batch 1154 in epoch 3, gen_loss = 0.9529437986287204, disc_loss = 0.01893002886310758
Trained batch 1155 in epoch 3, gen_loss = 0.9530091506902735, disc_loss = 0.018914813859322067
Trained batch 1156 in epoch 3, gen_loss = 0.9529128925184186, disc_loss = 0.01890050044157045
Trained batch 1157 in epoch 3, gen_loss = 0.9530594346333868, disc_loss = 0.01888596967346184
Trained batch 1158 in epoch 3, gen_loss = 0.9530431414288215, disc_loss = 0.018870566332910343
Trained batch 1159 in epoch 3, gen_loss = 0.953064995901338, disc_loss = 0.018855546773870472
Trained batch 1160 in epoch 3, gen_loss = 0.9529653245985867, disc_loss = 0.01884206312318851
Trained batch 1161 in epoch 3, gen_loss = 0.953042520662183, disc_loss = 0.01882677380127178
Trained batch 1162 in epoch 3, gen_loss = 0.9531285267191926, disc_loss = 0.01881405400940442
Trained batch 1163 in epoch 3, gen_loss = 0.9532091010784366, disc_loss = 0.01879893650880227
Trained batch 1164 in epoch 3, gen_loss = 0.9532904901729633, disc_loss = 0.018783839186391187
Trained batch 1165 in epoch 3, gen_loss = 0.9533094848101994, disc_loss = 0.01876882530391561
Trained batch 1166 in epoch 3, gen_loss = 0.953248355208857, disc_loss = 0.018754220339439187
Trained batch 1167 in epoch 3, gen_loss = 0.9531956490588515, disc_loss = 0.018738903166494097
Trained batch 1168 in epoch 3, gen_loss = 0.9532840900486407, disc_loss = 0.018724443271699507
Trained batch 1169 in epoch 3, gen_loss = 0.9533174390466804, disc_loss = 0.018709178626202503
Trained batch 1170 in epoch 3, gen_loss = 0.9533177201407877, disc_loss = 0.018694059623342803
Trained batch 1171 in epoch 3, gen_loss = 0.9533079268073873, disc_loss = 0.018679516983254547
Trained batch 1172 in epoch 3, gen_loss = 0.9532726223104954, disc_loss = 0.018664296557993322
Trained batch 1173 in epoch 3, gen_loss = 0.9532189368693954, disc_loss = 0.018649320650563257
Trained batch 1174 in epoch 3, gen_loss = 0.953185888046914, disc_loss = 0.018634281910676013
Trained batch 1175 in epoch 3, gen_loss = 0.9531240303601537, disc_loss = 0.018620760923725783
Trained batch 1176 in epoch 3, gen_loss = 0.9530776059009711, disc_loss = 0.018606682024385677
Trained batch 1177 in epoch 3, gen_loss = 0.9529868710931574, disc_loss = 0.018592140221126208
Trained batch 1178 in epoch 3, gen_loss = 0.952952159573407, disc_loss = 0.018577683074346017
Trained batch 1179 in epoch 3, gen_loss = 0.9529555528345754, disc_loss = 0.01856338162160374
Trained batch 1180 in epoch 3, gen_loss = 0.9529599991519001, disc_loss = 0.018548985170714526
Trained batch 1181 in epoch 3, gen_loss = 0.9531070893085144, disc_loss = 0.018535607836309993
Trained batch 1182 in epoch 3, gen_loss = 0.9531576810302315, disc_loss = 0.018520541642774318
Trained batch 1183 in epoch 3, gen_loss = 0.9531411743546659, disc_loss = 0.01850577200687169
Trained batch 1184 in epoch 3, gen_loss = 0.953141327799624, disc_loss = 0.018490714763567728
Trained batch 1185 in epoch 3, gen_loss = 0.9531127780826658, disc_loss = 0.01847578641435304
Trained batch 1186 in epoch 3, gen_loss = 0.953055410748685, disc_loss = 0.018460928230142247
Trained batch 1187 in epoch 3, gen_loss = 0.9529548698302471, disc_loss = 0.018446371662416257
Trained batch 1188 in epoch 3, gen_loss = 0.9530555640979411, disc_loss = 0.01843350999524276
Trained batch 1189 in epoch 3, gen_loss = 0.9529882496645471, disc_loss = 0.018419130241139812
Trained batch 1190 in epoch 3, gen_loss = 0.9529400240664317, disc_loss = 0.018404323746421213
Trained batch 1191 in epoch 3, gen_loss = 0.9528422572168728, disc_loss = 0.01839049733585462
Trained batch 1192 in epoch 3, gen_loss = 0.9529282341758843, disc_loss = 0.018376143371441115
Trained batch 1193 in epoch 3, gen_loss = 0.9530472668071888, disc_loss = 0.018361656770900955
Trained batch 1194 in epoch 3, gen_loss = 0.9529899697922264, disc_loss = 0.01834683644220722
Trained batch 1195 in epoch 3, gen_loss = 0.9529708234661798, disc_loss = 0.018331906051130362
Trained batch 1196 in epoch 3, gen_loss = 0.9529756663138407, disc_loss = 0.01831707411572645
Trained batch 1197 in epoch 3, gen_loss = 0.9530746234279244, disc_loss = 0.01830229609953743
Trained batch 1198 in epoch 3, gen_loss = 0.9529745371964099, disc_loss = 0.018288205404106347
Trained batch 1199 in epoch 3, gen_loss = 0.9529374789198239, disc_loss = 0.018273609601443846
Trained batch 1200 in epoch 3, gen_loss = 0.9529302603100659, disc_loss = 0.018261195564206644
Trained batch 1201 in epoch 3, gen_loss = 0.9529238403240179, disc_loss = 0.01824746880945066
Trained batch 1202 in epoch 3, gen_loss = 0.9529114661866788, disc_loss = 0.01823331001255085
Trained batch 1203 in epoch 3, gen_loss = 0.9528728494810503, disc_loss = 0.0182190925004888
Trained batch 1204 in epoch 3, gen_loss = 0.9528366669085016, disc_loss = 0.018204464197110026
Trained batch 1205 in epoch 3, gen_loss = 0.9529267573732246, disc_loss = 0.018189763858670445
Trained batch 1206 in epoch 3, gen_loss = 0.9529686841771142, disc_loss = 0.018175171884631816
Trained batch 1207 in epoch 3, gen_loss = 0.9530211162586876, disc_loss = 0.018161197698971242
Trained batch 1208 in epoch 3, gen_loss = 0.95295421385982, disc_loss = 0.01814657803759916
Trained batch 1209 in epoch 3, gen_loss = 0.9528836725664532, disc_loss = 0.01813236874695877
Trained batch 1210 in epoch 3, gen_loss = 0.9528193907930672, disc_loss = 0.018118132028037442
Trained batch 1211 in epoch 3, gen_loss = 0.9528010386248232, disc_loss = 0.018103714450610677
Trained batch 1212 in epoch 3, gen_loss = 0.9527190167945176, disc_loss = 0.018089597070398578
Trained batch 1213 in epoch 3, gen_loss = 0.9527333235426436, disc_loss = 0.018075403570555877
Trained batch 1214 in epoch 3, gen_loss = 0.952620706293318, disc_loss = 0.0180610528274812
Trained batch 1215 in epoch 3, gen_loss = 0.9526142175064275, disc_loss = 0.01804672951437313
Trained batch 1216 in epoch 3, gen_loss = 0.9527505865426169, disc_loss = 0.018033014310200258
Trained batch 1217 in epoch 3, gen_loss = 0.9527885224333733, disc_loss = 0.018019427156803863
Trained batch 1218 in epoch 3, gen_loss = 0.9527301607902564, disc_loss = 0.018008070690250327
Trained batch 1219 in epoch 3, gen_loss = 0.952700450625576, disc_loss = 0.01799553780246108
Trained batch 1220 in epoch 3, gen_loss = 0.9525810788148353, disc_loss = 0.017981638252889308
Trained batch 1221 in epoch 3, gen_loss = 0.9525609997309952, disc_loss = 0.017967755029036768
Trained batch 1222 in epoch 3, gen_loss = 0.9525771996376462, disc_loss = 0.017953707532786713
Trained batch 1223 in epoch 3, gen_loss = 0.9526063739474303, disc_loss = 0.017939596585777692
Trained batch 1224 in epoch 3, gen_loss = 0.9525686016861273, disc_loss = 0.017925624329209498
Trained batch 1225 in epoch 3, gen_loss = 0.9525743171596994, disc_loss = 0.01791177754476562
Trained batch 1226 in epoch 3, gen_loss = 0.9525698712907774, disc_loss = 0.017898181948053024
Trained batch 1227 in epoch 3, gen_loss = 0.9526181754926129, disc_loss = 0.017884482404267654
Trained batch 1228 in epoch 3, gen_loss = 0.952681958529889, disc_loss = 0.017870646841243683
Trained batch 1229 in epoch 3, gen_loss = 0.952654742322317, disc_loss = 0.017858729672079198
Trained batch 1230 in epoch 3, gen_loss = 0.9525884156978586, disc_loss = 0.017846912151347913
Trained batch 1231 in epoch 3, gen_loss = 0.9526023890387703, disc_loss = 0.017834519569680504
Trained batch 1232 in epoch 3, gen_loss = 0.9526117152057811, disc_loss = 0.01782113963501146
Trained batch 1233 in epoch 3, gen_loss = 0.9527772655846427, disc_loss = 0.01780895811424342
Trained batch 1234 in epoch 3, gen_loss = 0.9528826217902334, disc_loss = 0.0177963497705012
Trained batch 1235 in epoch 3, gen_loss = 0.9528347523370607, disc_loss = 0.01778462963720754
Trained batch 1236 in epoch 3, gen_loss = 0.9528207269616925, disc_loss = 0.01777177110260773
Trained batch 1237 in epoch 3, gen_loss = 0.952821727956439, disc_loss = 0.0177596401779632
Trained batch 1238 in epoch 3, gen_loss = 0.95283652001374, disc_loss = 0.017746385743019292
Trained batch 1239 in epoch 3, gen_loss = 0.952797643840313, disc_loss = 0.0177331212842898
Trained batch 1240 in epoch 3, gen_loss = 0.952763361281488, disc_loss = 0.017719399640046297
Trained batch 1241 in epoch 3, gen_loss = 0.9528142862657802, disc_loss = 0.017705502223809556
Trained batch 1242 in epoch 3, gen_loss = 0.9528293804305269, disc_loss = 0.017691820495830207
Trained batch 1243 in epoch 3, gen_loss = 0.9528231355346667, disc_loss = 0.017678076034712466
Trained batch 1244 in epoch 3, gen_loss = 0.9528509890698046, disc_loss = 0.017665680870238457
Trained batch 1245 in epoch 3, gen_loss = 0.952802890902729, disc_loss = 0.017651958383233822
Trained batch 1246 in epoch 3, gen_loss = 0.9527941490519782, disc_loss = 0.01763862045128214
Trained batch 1247 in epoch 3, gen_loss = 0.9528220878579677, disc_loss = 0.017625156671375663
Trained batch 1248 in epoch 3, gen_loss = 0.9527023358283948, disc_loss = 0.017618450261604468
Trained batch 1249 in epoch 3, gen_loss = 0.9525484775066376, disc_loss = 0.01761205993668409
Trained batch 1250 in epoch 3, gen_loss = 0.952448793881231, disc_loss = 0.017599625518180444
Trained batch 1251 in epoch 3, gen_loss = 0.9523770834405583, disc_loss = 0.01758792594663277
Trained batch 1252 in epoch 3, gen_loss = 0.9523757176216564, disc_loss = 0.01757544266779902
Trained batch 1253 in epoch 3, gen_loss = 0.9524169891739956, disc_loss = 0.01756240879890349
Trained batch 1254 in epoch 3, gen_loss = 0.9524045958936926, disc_loss = 0.017549127697412657
Trained batch 1255 in epoch 3, gen_loss = 0.9523795283144447, disc_loss = 0.017535646519839937
Trained batch 1256 in epoch 3, gen_loss = 0.9523848573556474, disc_loss = 0.017522303173782037
Trained batch 1257 in epoch 3, gen_loss = 0.9524021125465205, disc_loss = 0.017511417273634585
Trained batch 1258 in epoch 3, gen_loss = 0.9524991576211428, disc_loss = 0.01749956914068803
Trained batch 1259 in epoch 3, gen_loss = 0.9525959031449424, disc_loss = 0.01748666216256439
Trained batch 1260 in epoch 3, gen_loss = 0.9526248053366186, disc_loss = 0.017474024927622196
Trained batch 1261 in epoch 3, gen_loss = 0.9527295046204055, disc_loss = 0.01746109172693026
Trained batch 1262 in epoch 3, gen_loss = 0.9527034763296918, disc_loss = 0.01745495323200925
Trained batch 1263 in epoch 3, gen_loss = 0.9527521082494832, disc_loss = 0.017443944935943756
Trained batch 1264 in epoch 3, gen_loss = 0.9527893875427397, disc_loss = 0.017431716310707467
Trained batch 1265 in epoch 3, gen_loss = 0.9529492956296339, disc_loss = 0.01741913719785094
Trained batch 1266 in epoch 3, gen_loss = 0.9528757783965793, disc_loss = 0.01740666169826143
Trained batch 1267 in epoch 3, gen_loss = 0.9529023127694988, disc_loss = 0.017393624333429097
Trained batch 1268 in epoch 3, gen_loss = 0.9529030905923476, disc_loss = 0.017380754003550148
Trained batch 1269 in epoch 3, gen_loss = 0.9529379218582094, disc_loss = 0.017368868334683145
Trained batch 1270 in epoch 3, gen_loss = 0.9529632472504226, disc_loss = 0.017356195080189388
Trained batch 1271 in epoch 3, gen_loss = 0.9529165920315299, disc_loss = 0.01734345529295305
Trained batch 1272 in epoch 3, gen_loss = 0.9530460646746202, disc_loss = 0.017330659894206932
Trained batch 1273 in epoch 3, gen_loss = 0.9529849810166112, disc_loss = 0.017318449308860444
Trained batch 1274 in epoch 3, gen_loss = 0.9530170281260621, disc_loss = 0.017306234462006364
Trained batch 1275 in epoch 3, gen_loss = 0.9529638288069668, disc_loss = 0.01729446925569063
Trained batch 1276 in epoch 3, gen_loss = 0.9529019265130058, disc_loss = 0.017282394758998978
Trained batch 1277 in epoch 3, gen_loss = 0.9529507459142772, disc_loss = 0.01726999907564754
Trained batch 1278 in epoch 3, gen_loss = 0.9529792578822472, disc_loss = 0.01725793751266352
Trained batch 1279 in epoch 3, gen_loss = 0.952986327977851, disc_loss = 0.0172478410123972
Trained batch 1280 in epoch 3, gen_loss = 0.9528758027514473, disc_loss = 0.017235838615150222
Trained batch 1281 in epoch 3, gen_loss = 0.9528375912847088, disc_loss = 0.01722346757649266
Trained batch 1282 in epoch 3, gen_loss = 0.9529790322202681, disc_loss = 0.01721275648638101
Trained batch 1283 in epoch 3, gen_loss = 0.9530157363767564, disc_loss = 0.01720253950561046
Trained batch 1284 in epoch 3, gen_loss = 0.9530024993280493, disc_loss = 0.017190408607700693
Trained batch 1285 in epoch 3, gen_loss = 0.9529845311333937, disc_loss = 0.017179523572012217
Trained batch 1286 in epoch 3, gen_loss = 0.9530795700529702, disc_loss = 0.017166932108957214
Trained batch 1287 in epoch 3, gen_loss = 0.9530841457362501, disc_loss = 0.0171551563994427
Trained batch 1288 in epoch 3, gen_loss = 0.9530306711411458, disc_loss = 0.01714377694069312
Trained batch 1289 in epoch 3, gen_loss = 0.9530729702276777, disc_loss = 0.01713138314798996
Trained batch 1290 in epoch 3, gen_loss = 0.9530857561818395, disc_loss = 0.017119002908946263
Trained batch 1291 in epoch 3, gen_loss = 0.9530484280534574, disc_loss = 0.017106576811175972
Trained batch 1292 in epoch 3, gen_loss = 0.9530597534736551, disc_loss = 0.017095686699118706
Trained batch 1293 in epoch 3, gen_loss = 0.953049801048208, disc_loss = 0.017083767780842394
Trained batch 1294 in epoch 3, gen_loss = 0.9531875250422356, disc_loss = 0.01707156999064762
Trained batch 1295 in epoch 3, gen_loss = 0.9532515855483067, disc_loss = 0.017059479177549765
Trained batch 1296 in epoch 3, gen_loss = 0.9533218829192468, disc_loss = 0.01704729468930477
Trained batch 1297 in epoch 3, gen_loss = 0.9533503145576442, disc_loss = 0.017034982563759606
Trained batch 1298 in epoch 3, gen_loss = 0.9533891296093054, disc_loss = 0.017022862481527345
Trained batch 1299 in epoch 3, gen_loss = 0.9534844511288862, disc_loss = 0.01701251534540251
Trained batch 1300 in epoch 3, gen_loss = 0.953550384834489, disc_loss = 0.017001512734503357
Trained batch 1301 in epoch 3, gen_loss = 0.953502577387609, disc_loss = 0.01699273377082594
Trained batch 1302 in epoch 3, gen_loss = 0.9535109113933302, disc_loss = 0.01699064066304126
Trained batch 1303 in epoch 3, gen_loss = 0.9536014899520054, disc_loss = 0.016980934913757708
Trained batch 1304 in epoch 3, gen_loss = 0.9537605090159565, disc_loss = 0.016969411065313567
Trained batch 1305 in epoch 3, gen_loss = 0.9537637328663428, disc_loss = 0.016958353440195716
Trained batch 1306 in epoch 3, gen_loss = 0.9537471189878328, disc_loss = 0.016946280833224442
Trained batch 1307 in epoch 3, gen_loss = 0.9537459730372881, disc_loss = 0.016934508619864633
Trained batch 1308 in epoch 3, gen_loss = 0.9537092588893141, disc_loss = 0.016922306607369667
Trained batch 1309 in epoch 3, gen_loss = 0.9536047421793902, disc_loss = 0.016910635078877287
Trained batch 1310 in epoch 3, gen_loss = 0.9537127890448639, disc_loss = 0.016900086107665677
Trained batch 1311 in epoch 3, gen_loss = 0.9536260644473681, disc_loss = 0.016888727128400383
Trained batch 1312 in epoch 3, gen_loss = 0.9536536059030938, disc_loss = 0.016876777779621353
Trained batch 1313 in epoch 3, gen_loss = 0.9537028174512825, disc_loss = 0.01686764185624865
Trained batch 1314 in epoch 3, gen_loss = 0.9536714784999311, disc_loss = 0.016857123552007556
Trained batch 1315 in epoch 3, gen_loss = 0.9537972350432156, disc_loss = 0.016847548582092635
Trained batch 1316 in epoch 3, gen_loss = 0.9538293805824778, disc_loss = 0.016835544714039873
Trained batch 1317 in epoch 3, gen_loss = 0.9537327315358725, disc_loss = 0.016824938795785543
Trained batch 1318 in epoch 3, gen_loss = 0.9536258704378534, disc_loss = 0.016812701643384317
Trained batch 1319 in epoch 3, gen_loss = 0.9536094279903354, disc_loss = 0.01680050075516523
Trained batch 1320 in epoch 3, gen_loss = 0.9536071600199287, disc_loss = 0.0167901278878489
Trained batch 1321 in epoch 3, gen_loss = 0.9536200591818107, disc_loss = 0.016779165482115506
Trained batch 1322 in epoch 3, gen_loss = 0.9536717901694801, disc_loss = 0.01677437355521743
Trained batch 1323 in epoch 3, gen_loss = 0.9535738916285449, disc_loss = 0.01676524000265785
Trained batch 1324 in epoch 3, gen_loss = 0.9534502831495033, disc_loss = 0.016757021480611138
Trained batch 1325 in epoch 3, gen_loss = 0.9533654244596962, disc_loss = 0.016747679703570512
Trained batch 1326 in epoch 3, gen_loss = 0.953231343130645, disc_loss = 0.0167638734561717
Trained batch 1327 in epoch 3, gen_loss = 0.9533492700163141, disc_loss = 0.017082029803839167
Trained batch 1328 in epoch 3, gen_loss = 0.9533930716432065, disc_loss = 0.017076409573544907
Trained batch 1329 in epoch 3, gen_loss = 0.9531097500844109, disc_loss = 0.017367517241923213
Trained batch 1330 in epoch 3, gen_loss = 0.9531690066779672, disc_loss = 0.017622462223628295
Trained batch 1331 in epoch 3, gen_loss = 0.9531038245102307, disc_loss = 0.017652171084627334
Trained batch 1332 in epoch 3, gen_loss = 0.9529551062830748, disc_loss = 0.01766328768737117
Trained batch 1333 in epoch 3, gen_loss = 0.9528756940561435, disc_loss = 0.017675347561598317
Trained batch 1334 in epoch 3, gen_loss = 0.9526894480994578, disc_loss = 0.017705759394546352
Trained batch 1335 in epoch 3, gen_loss = 0.9524625579040208, disc_loss = 0.01771363945818211
Trained batch 1336 in epoch 3, gen_loss = 0.9523640661517809, disc_loss = 0.017717709721269546
Trained batch 1337 in epoch 3, gen_loss = 0.9522823431210311, disc_loss = 0.017799985053135455
Trained batch 1338 in epoch 3, gen_loss = 0.9520051790939684, disc_loss = 0.018027929787695234
Trained batch 1339 in epoch 3, gen_loss = 0.9519173085689545, disc_loss = 0.01806457983430887
Trained batch 1340 in epoch 3, gen_loss = 0.9518884203044626, disc_loss = 0.01809197285304467
Trained batch 1341 in epoch 3, gen_loss = 0.9518602363842965, disc_loss = 0.018108326561047453
Trained batch 1342 in epoch 3, gen_loss = 0.9516790978338677, disc_loss = 0.01820237071604469
Trained batch 1343 in epoch 3, gen_loss = 0.9517164766078904, disc_loss = 0.018280407089161513
Trained batch 1344 in epoch 3, gen_loss = 0.9515817915196756, disc_loss = 0.018278389947186398
Trained batch 1345 in epoch 3, gen_loss = 0.9514528264971048, disc_loss = 0.01828164075163131
Trained batch 1346 in epoch 3, gen_loss = 0.9515710326593366, disc_loss = 0.01827442780259657
Trained batch 1347 in epoch 3, gen_loss = 0.9515073445766545, disc_loss = 0.018283898174904445
Trained batch 1348 in epoch 3, gen_loss = 0.9514823178170433, disc_loss = 0.01831172344639555
Trained batch 1349 in epoch 3, gen_loss = 0.9514623378824305, disc_loss = 0.018311718810938248
Trained batch 1350 in epoch 3, gen_loss = 0.9515959792098322, disc_loss = 0.01830411699047868
Trained batch 1351 in epoch 3, gen_loss = 0.9516866771427132, disc_loss = 0.01829923645930288
Trained batch 1352 in epoch 3, gen_loss = 0.9515419844689408, disc_loss = 0.018354925738941586
Trained batch 1353 in epoch 3, gen_loss = 0.9515110957305576, disc_loss = 0.01840675508420018
Trained batch 1354 in epoch 3, gen_loss = 0.9514647385730954, disc_loss = 0.018412716333065748
Trained batch 1355 in epoch 3, gen_loss = 0.9515465675993303, disc_loss = 0.01840332239536113
Trained batch 1356 in epoch 3, gen_loss = 0.951372158158414, disc_loss = 0.018419041033382027
Trained batch 1357 in epoch 3, gen_loss = 0.9513682976299253, disc_loss = 0.018419291953687314
Trained batch 1358 in epoch 3, gen_loss = 0.9515587252409166, disc_loss = 0.018414840241279498
Trained batch 1359 in epoch 3, gen_loss = 0.9516938112676143, disc_loss = 0.018404708694470175
Trained batch 1360 in epoch 3, gen_loss = 0.9516771894706513, disc_loss = 0.018394708663841807
Trained batch 1361 in epoch 3, gen_loss = 0.9516782879216731, disc_loss = 0.018387015273341266
Trained batch 1362 in epoch 3, gen_loss = 0.9517846236487827, disc_loss = 0.018377174695707144
Trained batch 1363 in epoch 3, gen_loss = 0.9518237073313106, disc_loss = 0.018367289321716343
Trained batch 1364 in epoch 3, gen_loss = 0.9518411214971717, disc_loss = 0.018356505999029885
Trained batch 1365 in epoch 3, gen_loss = 0.9519042645418802, disc_loss = 0.018345919004909502
Trained batch 1366 in epoch 3, gen_loss = 0.951975647559023, disc_loss = 0.01833405857476746
Trained batch 1367 in epoch 3, gen_loss = 0.9519948836917068, disc_loss = 0.018322292678346206
Trained batch 1368 in epoch 3, gen_loss = 0.9521068345464173, disc_loss = 0.018310617484389825
Trained batch 1369 in epoch 3, gen_loss = 0.9522517510139159, disc_loss = 0.01829844279768987
Trained batch 1370 in epoch 3, gen_loss = 0.9523129454065986, disc_loss = 0.01828669325325152
Trained batch 1371 in epoch 3, gen_loss = 0.9524145620296718, disc_loss = 0.018274078886254177
Trained batch 1372 in epoch 3, gen_loss = 0.9524198249145225, disc_loss = 0.01826190420917399
Trained batch 1373 in epoch 3, gen_loss = 0.9524300657592313, disc_loss = 0.018249389222432744
Trained batch 1374 in epoch 3, gen_loss = 0.9524935613545504, disc_loss = 0.01823771615805824
Trained batch 1375 in epoch 3, gen_loss = 0.9524944487439339, disc_loss = 0.01822566720880617
Trained batch 1376 in epoch 3, gen_loss = 0.9525844133584155, disc_loss = 0.01821355975594058
Trained batch 1377 in epoch 3, gen_loss = 0.9526871031444892, disc_loss = 0.018201376771957243
Trained batch 1378 in epoch 3, gen_loss = 0.9527920231687754, disc_loss = 0.0181890345076755
Trained batch 1379 in epoch 3, gen_loss = 0.952875595205072, disc_loss = 0.018177279660132783
Trained batch 1380 in epoch 3, gen_loss = 0.9529067652109824, disc_loss = 0.01816487998236856
Trained batch 1381 in epoch 3, gen_loss = 0.9528321172670069, disc_loss = 0.018153517689526315
Trained batch 1382 in epoch 3, gen_loss = 0.9527921731370304, disc_loss = 0.018142083622951655
Trained batch 1383 in epoch 3, gen_loss = 0.9529535215283405, disc_loss = 0.018130816972188768
Trained batch 1384 in epoch 3, gen_loss = 0.95310903486362, disc_loss = 0.018119347589445597
Trained batch 1385 in epoch 3, gen_loss = 0.953122171961728, disc_loss = 0.01810761010948131
Trained batch 1386 in epoch 3, gen_loss = 0.9531110419415706, disc_loss = 0.01809519330300359
Trained batch 1387 in epoch 3, gen_loss = 0.9531421996331009, disc_loss = 0.018082984706260862
Trained batch 1388 in epoch 3, gen_loss = 0.9532667504874299, disc_loss = 0.018071006777308846
Trained batch 1389 in epoch 3, gen_loss = 0.9532986699248389, disc_loss = 0.01805856365953587
Trained batch 1390 in epoch 3, gen_loss = 0.9532527779607273, disc_loss = 0.018046408864111862
Trained batch 1391 in epoch 3, gen_loss = 0.9532225684359156, disc_loss = 0.01803406158919172
Trained batch 1392 in epoch 3, gen_loss = 0.9531872516386987, disc_loss = 0.018021918223025957
Trained batch 1393 in epoch 3, gen_loss = 0.9531316540846695, disc_loss = 0.01800961562128074
Trained batch 1394 in epoch 3, gen_loss = 0.9530885250337662, disc_loss = 0.01799711264515718
Trained batch 1395 in epoch 3, gen_loss = 0.9530073220716165, disc_loss = 0.017985450747425958
Trained batch 1396 in epoch 3, gen_loss = 0.9531027169080828, disc_loss = 0.017973382448045982
Trained batch 1397 in epoch 3, gen_loss = 0.9531094953737546, disc_loss = 0.01796118251248258
Trained batch 1398 in epoch 3, gen_loss = 0.9530540363885744, disc_loss = 0.01794915858675848
Trained batch 1399 in epoch 3, gen_loss = 0.9530762345450265, disc_loss = 0.017937473734917667
Trained batch 1400 in epoch 3, gen_loss = 0.9531120601336842, disc_loss = 0.01792533290713102
Trained batch 1401 in epoch 3, gen_loss = 0.9531514593605989, disc_loss = 0.01791314914366591
Trained batch 1402 in epoch 3, gen_loss = 0.9530587648376769, disc_loss = 0.01790174579337488
Trained batch 1403 in epoch 3, gen_loss = 0.9531203316487478, disc_loss = 0.01789009019339159
Trained batch 1404 in epoch 3, gen_loss = 0.9531093656804638, disc_loss = 0.017878732277385748
Trained batch 1405 in epoch 3, gen_loss = 0.9530386020075715, disc_loss = 0.017866770087656945
Trained batch 1406 in epoch 3, gen_loss = 0.9531101588247173, disc_loss = 0.017855229309880257
Trained batch 1407 in epoch 3, gen_loss = 0.9531199707310986, disc_loss = 0.01784342565680287
Trained batch 1408 in epoch 3, gen_loss = 0.9530619405701788, disc_loss = 0.017832051747474993
Trained batch 1409 in epoch 3, gen_loss = 0.953104101935177, disc_loss = 0.017820136854517957
Trained batch 1410 in epoch 3, gen_loss = 0.953118903851526, disc_loss = 0.017808462943777217
Trained batch 1411 in epoch 3, gen_loss = 0.9531663532973011, disc_loss = 0.01779669974308315
Trained batch 1412 in epoch 3, gen_loss = 0.9532519587370325, disc_loss = 0.017785035233931226
Trained batch 1413 in epoch 3, gen_loss = 0.9532083957502158, disc_loss = 0.01777315274810017
Trained batch 1414 in epoch 3, gen_loss = 0.9531821378970736, disc_loss = 0.017761295767224974
Trained batch 1415 in epoch 3, gen_loss = 0.9532272997549025, disc_loss = 0.017750177312028444
Trained batch 1416 in epoch 3, gen_loss = 0.9532086769711744, disc_loss = 0.017738121312454454
Trained batch 1417 in epoch 3, gen_loss = 0.9533080285880058, disc_loss = 0.01772753280268009
Trained batch 1418 in epoch 3, gen_loss = 0.9533672192888079, disc_loss = 0.017715822050533417
Trained batch 1419 in epoch 3, gen_loss = 0.9533307950681364, disc_loss = 0.01770393270807559
Trained batch 1420 in epoch 3, gen_loss = 0.9532894076888281, disc_loss = 0.017692430426642633
Trained batch 1421 in epoch 3, gen_loss = 0.95330757602693, disc_loss = 0.017680545911111765
Trained batch 1422 in epoch 3, gen_loss = 0.953237020919127, disc_loss = 0.017670299432004242
Trained batch 1423 in epoch 3, gen_loss = 0.9532968049052726, disc_loss = 0.017660425789574545
Trained batch 1424 in epoch 3, gen_loss = 0.9532814879584731, disc_loss = 0.01764915586674888
Trained batch 1425 in epoch 3, gen_loss = 0.9533008601605307, disc_loss = 0.017639684205913414
Trained batch 1426 in epoch 3, gen_loss = 0.9532387735297317, disc_loss = 0.017628312334156016
Trained batch 1427 in epoch 3, gen_loss = 0.9530108371535603, disc_loss = 0.0176387276717499
Trained batch 1428 in epoch 3, gen_loss = 0.953067650154306, disc_loss = 0.017706201647109242
Trained batch 1429 in epoch 3, gen_loss = 0.953081856949346, disc_loss = 0.017697745991817438
Trained batch 1430 in epoch 3, gen_loss = 0.9530336923485948, disc_loss = 0.017691587638499193
Trained batch 1431 in epoch 3, gen_loss = 0.9531173218228963, disc_loss = 0.01768121079777053
Trained batch 1432 in epoch 3, gen_loss = 0.9530854938501091, disc_loss = 0.01767125557716723
Trained batch 1433 in epoch 3, gen_loss = 0.9532081983993907, disc_loss = 0.017661992948282867
Trained batch 1434 in epoch 3, gen_loss = 0.9531360260285567, disc_loss = 0.017652349584893718
Trained batch 1435 in epoch 3, gen_loss = 0.953103901408509, disc_loss = 0.017641831136587568
Trained batch 1436 in epoch 3, gen_loss = 0.953104914354631, disc_loss = 0.017630192187371132
Trained batch 1437 in epoch 3, gen_loss = 0.9531196074376351, disc_loss = 0.017618606780914824
Trained batch 1438 in epoch 3, gen_loss = 0.9531460541913375, disc_loss = 0.017607668804701257
Trained batch 1439 in epoch 3, gen_loss = 0.9531104988108079, disc_loss = 0.017596126787541126
Trained batch 1440 in epoch 3, gen_loss = 0.9530655463729609, disc_loss = 0.017584985373466176
Trained batch 1441 in epoch 3, gen_loss = 0.9530357370016148, disc_loss = 0.01757338033884645
Trained batch 1442 in epoch 3, gen_loss = 0.9531179419095864, disc_loss = 0.017561797715505447
Trained batch 1443 in epoch 3, gen_loss = 0.9531588403719614, disc_loss = 0.0175500834218767
Trained batch 1444 in epoch 3, gen_loss = 0.9531720925779904, disc_loss = 0.0175384357827494
Trained batch 1445 in epoch 3, gen_loss = 0.9532486556888781, disc_loss = 0.017526662374813547
Trained batch 1446 in epoch 3, gen_loss = 0.9532845061897984, disc_loss = 0.017514880405010126
Trained batch 1447 in epoch 3, gen_loss = 0.9532553130832825, disc_loss = 0.017503548837058232
Trained batch 1448 in epoch 3, gen_loss = 0.9532182197310828, disc_loss = 0.017491873748127832
Trained batch 1449 in epoch 3, gen_loss = 0.9532442691408355, disc_loss = 0.01748085150094743
Trained batch 1450 in epoch 3, gen_loss = 0.9532574466144028, disc_loss = 0.01746911730156638
Trained batch 1451 in epoch 3, gen_loss = 0.95324765609644, disc_loss = 0.017457548453353976
Trained batch 1452 in epoch 3, gen_loss = 0.953390933445053, disc_loss = 0.017446306549865225
Trained batch 1453 in epoch 3, gen_loss = 0.9534171487229071, disc_loss = 0.017434960764431587
Trained batch 1454 in epoch 3, gen_loss = 0.9533963900661141, disc_loss = 0.017423436900409164
Trained batch 1455 in epoch 3, gen_loss = 0.9533963598065324, disc_loss = 0.01741173962265028
Trained batch 1456 in epoch 3, gen_loss = 0.9533548167329499, disc_loss = 0.0174005056567147
Trained batch 1457 in epoch 3, gen_loss = 0.9532893087883545, disc_loss = 0.017389012517221736
Trained batch 1458 in epoch 3, gen_loss = 0.9532756644458784, disc_loss = 0.01737734807442851
Trained batch 1459 in epoch 3, gen_loss = 0.953270970142051, disc_loss = 0.01736587742910671
Trained batch 1460 in epoch 3, gen_loss = 0.9533752698265143, disc_loss = 0.017354389163611688
Trained batch 1461 in epoch 3, gen_loss = 0.9533487244441636, disc_loss = 0.01734305969091674
Trained batch 1462 in epoch 3, gen_loss = 0.9533923570211832, disc_loss = 0.017331572095010895
Trained batch 1463 in epoch 3, gen_loss = 0.9533949749635868, disc_loss = 0.01732025600136953
Trained batch 1464 in epoch 3, gen_loss = 0.9534349452513476, disc_loss = 0.01730880705440463
Trained batch 1465 in epoch 3, gen_loss = 0.9534349138219554, disc_loss = 0.01729727267959045
Trained batch 1466 in epoch 3, gen_loss = 0.9534512837484083, disc_loss = 0.01728574715413024
Trained batch 1467 in epoch 3, gen_loss = 0.9533941553707669, disc_loss = 0.017274862766151755
Trained batch 1468 in epoch 3, gen_loss = 0.9533893573113734, disc_loss = 0.0172633973899651
Trained batch 1469 in epoch 3, gen_loss = 0.953433232850769, disc_loss = 0.01725249726211036
Trained batch 1470 in epoch 3, gen_loss = 0.9533792912433295, disc_loss = 0.01724108169772347
Trained batch 1471 in epoch 3, gen_loss = 0.9533390175227238, disc_loss = 0.017229686646942355
Trained batch 1472 in epoch 3, gen_loss = 0.9534095409202964, disc_loss = 0.01721825788214824
Trained batch 1473 in epoch 3, gen_loss = 0.95348209385309, disc_loss = 0.017207095431949513
Trained batch 1474 in epoch 3, gen_loss = 0.9534803897243435, disc_loss = 0.017195672788844697
Trained batch 1475 in epoch 3, gen_loss = 0.9534783923852088, disc_loss = 0.017184221012510947
Trained batch 1476 in epoch 3, gen_loss = 0.9535123138066152, disc_loss = 0.017172998708807837
Trained batch 1477 in epoch 3, gen_loss = 0.9533900481841561, disc_loss = 0.017163263600578682
Trained batch 1478 in epoch 3, gen_loss = 0.9534345658507357, disc_loss = 0.01715195182133099
Trained batch 1479 in epoch 3, gen_loss = 0.9533796171481544, disc_loss = 0.017140619191441393
Trained batch 1480 in epoch 3, gen_loss = 0.9533867843242854, disc_loss = 0.017129361754931256
Trained batch 1481 in epoch 3, gen_loss = 0.953423711532845, disc_loss = 0.017118009372832938
Trained batch 1482 in epoch 3, gen_loss = 0.9534710175429979, disc_loss = 0.017107088403697082
Trained batch 1483 in epoch 3, gen_loss = 0.9534934821797189, disc_loss = 0.017095794222832483
Trained batch 1484 in epoch 3, gen_loss = 0.9534563298979993, disc_loss = 0.017084519858524966
Trained batch 1485 in epoch 3, gen_loss = 0.9534710810129928, disc_loss = 0.017073291277547458
Trained batch 1486 in epoch 3, gen_loss = 0.9534123194001229, disc_loss = 0.017062045723169234
Trained batch 1487 in epoch 3, gen_loss = 0.953352883658422, disc_loss = 0.017051122494429423
Trained batch 1488 in epoch 3, gen_loss = 0.9533127883763182, disc_loss = 0.01704006538123946
Trained batch 1489 in epoch 3, gen_loss = 0.9532699905385907, disc_loss = 0.017029020403937247
Trained batch 1490 in epoch 3, gen_loss = 0.953283317811852, disc_loss = 0.017018677362364294
Trained batch 1491 in epoch 3, gen_loss = 0.9532776023123922, disc_loss = 0.017008041953861894
Trained batch 1492 in epoch 3, gen_loss = 0.9533105609166247, disc_loss = 0.01699740660523789
Trained batch 1493 in epoch 3, gen_loss = 0.953274127988611, disc_loss = 0.016986734813077758
Trained batch 1494 in epoch 3, gen_loss = 0.9533060452212458, disc_loss = 0.01697562518289171
Trained batch 1495 in epoch 3, gen_loss = 0.9533439867078939, disc_loss = 0.016964828151189562
Trained batch 1496 in epoch 3, gen_loss = 0.9533408887400656, disc_loss = 0.016953765936200904
Trained batch 1497 in epoch 3, gen_loss = 0.9533269011449114, disc_loss = 0.016942735401676418
Trained batch 1498 in epoch 3, gen_loss = 0.9533038319071744, disc_loss = 0.016931784046434313
Trained batch 1499 in epoch 3, gen_loss = 0.953322700937589, disc_loss = 0.016921005062108935
Trained batch 1500 in epoch 3, gen_loss = 0.9533338612274358, disc_loss = 0.016910017743106166
Trained batch 1501 in epoch 3, gen_loss = 0.9533486154758819, disc_loss = 0.01689935325938545
Trained batch 1502 in epoch 3, gen_loss = 0.9534158047960348, disc_loss = 0.01688844749568805
Trained batch 1503 in epoch 3, gen_loss = 0.9533397461426385, disc_loss = 0.01687744023026058
Trained batch 1504 in epoch 3, gen_loss = 0.9533349584107383, disc_loss = 0.01686638373464069
Trained batch 1505 in epoch 3, gen_loss = 0.9533898845057722, disc_loss = 0.01685550179673431
Trained batch 1506 in epoch 3, gen_loss = 0.953375053943667, disc_loss = 0.016844560996264756
Trained batch 1507 in epoch 3, gen_loss = 0.9533726849274546, disc_loss = 0.016833648258084553
Trained batch 1508 in epoch 3, gen_loss = 0.9534276913853968, disc_loss = 0.016822708011454794
Trained batch 1509 in epoch 3, gen_loss = 0.9533829332582209, disc_loss = 0.016811732901713197
Trained batch 1510 in epoch 3, gen_loss = 0.9533689763670643, disc_loss = 0.016800729614837126
Trained batch 1511 in epoch 3, gen_loss = 0.9533776254959838, disc_loss = 0.016789772499823667
Trained batch 1512 in epoch 3, gen_loss = 0.9533514170873583, disc_loss = 0.01677885493305344
Trained batch 1513 in epoch 3, gen_loss = 0.9533506084228601, disc_loss = 0.016768009074112966
Trained batch 1514 in epoch 3, gen_loss = 0.9533247073097985, disc_loss = 0.01675742258454739
Trained batch 1515 in epoch 3, gen_loss = 0.9532812568789107, disc_loss = 0.016746608581470212
Trained batch 1516 in epoch 3, gen_loss = 0.9532353920455661, disc_loss = 0.01673579095865223
Trained batch 1517 in epoch 3, gen_loss = 0.9532761529029122, disc_loss = 0.016725044986059413
Trained batch 1518 in epoch 3, gen_loss = 0.9533073482268574, disc_loss = 0.01671438393629056
Trained batch 1519 in epoch 3, gen_loss = 0.95332544100912, disc_loss = 0.016703560171481512
Trained batch 1520 in epoch 3, gen_loss = 0.9533678767400537, disc_loss = 0.016692782826161788
Trained batch 1521 in epoch 3, gen_loss = 0.9533166619857256, disc_loss = 0.016681950159078942
Trained batch 1522 in epoch 3, gen_loss = 0.9532739904783153, disc_loss = 0.016671219715162992
Trained batch 1523 in epoch 3, gen_loss = 0.9532315473700446, disc_loss = 0.016660659766766006
Trained batch 1524 in epoch 3, gen_loss = 0.9532315953442307, disc_loss = 0.016650013194322112
Trained batch 1525 in epoch 3, gen_loss = 0.9532668203466997, disc_loss = 0.016639529127938636
Trained batch 1526 in epoch 3, gen_loss = 0.9532744582369191, disc_loss = 0.01662900026246075
Trained batch 1527 in epoch 3, gen_loss = 0.9532523968534944, disc_loss = 0.016618416002453368
Trained batch 1528 in epoch 3, gen_loss = 0.9533188104083757, disc_loss = 0.016607976773263203
Trained batch 1529 in epoch 3, gen_loss = 0.9533080266192069, disc_loss = 0.01659767612579219
Trained batch 1530 in epoch 3, gen_loss = 0.9532739061845198, disc_loss = 0.016587218815331307
Trained batch 1531 in epoch 3, gen_loss = 0.9532512034977696, disc_loss = 0.01657665694893972
Trained batch 1532 in epoch 3, gen_loss = 0.9531791228837463, disc_loss = 0.016566222796059186
Trained batch 1533 in epoch 3, gen_loss = 0.9531519809322532, disc_loss = 0.016555768550750256
Trained batch 1534 in epoch 3, gen_loss = 0.9531104229948808, disc_loss = 0.016545196887322228
Trained batch 1535 in epoch 3, gen_loss = 0.9532053847021112, disc_loss = 0.016534699219287557
Trained batch 1536 in epoch 3, gen_loss = 0.9531865420477997, disc_loss = 0.01652436374114845
Trained batch 1537 in epoch 3, gen_loss = 0.9530837874961302, disc_loss = 0.016513832457521728
Trained batch 1538 in epoch 3, gen_loss = 0.953096160066058, disc_loss = 0.016503443590800224
Trained batch 1539 in epoch 3, gen_loss = 0.9530933396769808, disc_loss = 0.016493171512297816
Trained batch 1540 in epoch 3, gen_loss = 0.9531079111433431, disc_loss = 0.016482762329368083
Trained batch 1541 in epoch 3, gen_loss = 0.9530036600569961, disc_loss = 0.016472485992922274
Trained batch 1542 in epoch 3, gen_loss = 0.952995514413867, disc_loss = 0.01646220137522885
Trained batch 1543 in epoch 3, gen_loss = 0.9530381187796593, disc_loss = 0.016451710251674863
Trained batch 1544 in epoch 3, gen_loss = 0.9530339241413622, disc_loss = 0.01644121927445043
Trained batch 1545 in epoch 3, gen_loss = 0.9530509599661611, disc_loss = 0.016430736175336694
Trained batch 1546 in epoch 3, gen_loss = 0.952986615468551, disc_loss = 0.016420340991907322
Trained batch 1547 in epoch 3, gen_loss = 0.9529124371303145, disc_loss = 0.016409913706850788
Trained batch 1548 in epoch 3, gen_loss = 0.9528288812772777, disc_loss = 0.01639971285501714
Trained batch 1549 in epoch 3, gen_loss = 0.952912925212614, disc_loss = 0.01638953319605207
Trained batch 1550 in epoch 3, gen_loss = 0.9529456903210461, disc_loss = 0.016379410130561236
Trained batch 1551 in epoch 3, gen_loss = 0.9530245617953772, disc_loss = 0.016369160004868127
Trained batch 1552 in epoch 3, gen_loss = 0.9530016865871526, disc_loss = 0.016358985593947623
Trained batch 1553 in epoch 3, gen_loss = 0.9530138197706166, disc_loss = 0.01634870542650927
Trained batch 1554 in epoch 3, gen_loss = 0.9530443005239848, disc_loss = 0.01633849432402765
Trained batch 1555 in epoch 3, gen_loss = 0.95301641002872, disc_loss = 0.016328239810762937
Trained batch 1556 in epoch 3, gen_loss = 0.9529863055807394, disc_loss = 0.016317975634816892
Trained batch 1557 in epoch 3, gen_loss = 0.9530613478631814, disc_loss = 0.016307796629751205
Trained batch 1558 in epoch 3, gen_loss = 0.9530666893380356, disc_loss = 0.016297487667493293
Trained batch 1559 in epoch 3, gen_loss = 0.9530960672940963, disc_loss = 0.016287284901054824
Trained batch 1560 in epoch 3, gen_loss = 0.9530678398711494, disc_loss = 0.016277008197272347
Trained batch 1561 in epoch 3, gen_loss = 0.9530285249980556, disc_loss = 0.01626671493415017
Trained batch 1562 in epoch 3, gen_loss = 0.9530697271218302, disc_loss = 0.016256654381898224
Trained batch 1563 in epoch 3, gen_loss = 0.9531224134099453, disc_loss = 0.016246515306132553
Trained batch 1564 in epoch 3, gen_loss = 0.9530850771517038, disc_loss = 0.016236346092801498
Trained batch 1565 in epoch 3, gen_loss = 0.9530350890957381, disc_loss = 0.01622626545179362
Trained batch 1566 in epoch 3, gen_loss = 0.9530950899556251, disc_loss = 0.016216122564292768
Trained batch 1567 in epoch 3, gen_loss = 0.9531489812902042, disc_loss = 0.016206058981053352
Trained batch 1568 in epoch 3, gen_loss = 0.9531620774320769, disc_loss = 0.016195930420909502
Trained batch 1569 in epoch 3, gen_loss = 0.9531461279863005, disc_loss = 0.016185874040125482
Trained batch 1570 in epoch 3, gen_loss = 0.9531431458392468, disc_loss = 0.016175778209983418
Trained batch 1571 in epoch 3, gen_loss = 0.9531537452499375, disc_loss = 0.01616572500251519
Trained batch 1572 in epoch 3, gen_loss = 0.953215993178247, disc_loss = 0.016155684359523158
Trained batch 1573 in epoch 3, gen_loss = 0.9532329303791138, disc_loss = 0.016145581190515085
Trained batch 1574 in epoch 3, gen_loss = 0.9532517569784135, disc_loss = 0.016135508476503357
Trained batch 1575 in epoch 3, gen_loss = 0.9531608130120989, disc_loss = 0.01612564965281368
Trained batch 1576 in epoch 3, gen_loss = 0.953126426694056, disc_loss = 0.016115614302123375
Trained batch 1577 in epoch 3, gen_loss = 0.953087670305987, disc_loss = 0.01610569151569931
Trained batch 1578 in epoch 3, gen_loss = 0.9530429928041546, disc_loss = 0.016095609673730346
Trained batch 1579 in epoch 3, gen_loss = 0.9530222412151627, disc_loss = 0.016085533471906978
Trained batch 1580 in epoch 3, gen_loss = 0.9530364071772417, disc_loss = 0.01607556874504985
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9887301921844482, disc_loss = 0.0003198895137757063
Trained batch 1 in epoch 4, gen_loss = 0.9529747366905212, disc_loss = 0.0003207384725101292
Trained batch 2 in epoch 4, gen_loss = 0.9583905935287476, disc_loss = 0.00028741068187324953
Trained batch 3 in epoch 4, gen_loss = 0.922518402338028, disc_loss = 0.00026656832415028475
Trained batch 4 in epoch 4, gen_loss = 0.9137165307998657, disc_loss = 0.0002569754171418026
Trained batch 5 in epoch 4, gen_loss = 0.9070204496383667, disc_loss = 0.00025641060832034174
Trained batch 6 in epoch 4, gen_loss = 0.9069850785391671, disc_loss = 0.0002518121348527659
Trained batch 7 in epoch 4, gen_loss = 0.9082575440406799, disc_loss = 0.00024997325635922607
Trained batch 8 in epoch 4, gen_loss = 0.910160137547387, disc_loss = 0.0002521447976404387
Trained batch 9 in epoch 4, gen_loss = 0.9201400697231292, disc_loss = 0.00026224781322525814
Trained batch 10 in epoch 4, gen_loss = 0.9186307896267284, disc_loss = 0.00025806285636711186
Trained batch 11 in epoch 4, gen_loss = 0.9163983017206192, disc_loss = 0.0002553037957113702
Trained batch 12 in epoch 4, gen_loss = 0.9244116590573237, disc_loss = 0.00025522901537792326
Trained batch 13 in epoch 4, gen_loss = 0.9296599669115884, disc_loss = 0.00025790135571566807
Trained batch 14 in epoch 4, gen_loss = 0.9208284576733907, disc_loss = 0.0002625949981544788
Trained batch 15 in epoch 4, gen_loss = 0.9214884899556637, disc_loss = 0.00026019898086815374
Trained batch 16 in epoch 4, gen_loss = 0.9219442641033846, disc_loss = 0.0002751582796918228
Trained batch 17 in epoch 4, gen_loss = 0.9253855579429202, disc_loss = 0.00027156719119779556
Trained batch 18 in epoch 4, gen_loss = 0.91837141388341, disc_loss = 0.0002779766946332529
Trained batch 19 in epoch 4, gen_loss = 0.9135508447885513, disc_loss = 0.00028892185000586326
Trained batch 20 in epoch 4, gen_loss = 0.9164997793379284, disc_loss = 0.0002955822267159376
Trained batch 21 in epoch 4, gen_loss = 0.9179964553226124, disc_loss = 0.00030397009223551407
Trained batch 22 in epoch 4, gen_loss = 0.9212137719859248, disc_loss = 0.00029988376089655185
Trained batch 23 in epoch 4, gen_loss = 0.921141525109609, disc_loss = 0.0002939970988033262
Trained batch 24 in epoch 4, gen_loss = 0.9166711783409118, disc_loss = 0.0002909279428422451
Trained batch 25 in epoch 4, gen_loss = 0.9195114167836996, disc_loss = 0.00029548210127709003
Trained batch 26 in epoch 4, gen_loss = 0.9207540529745596, disc_loss = 0.00029559511286034076
Trained batch 27 in epoch 4, gen_loss = 0.9230158754757473, disc_loss = 0.0003040174862170326
Trained batch 28 in epoch 4, gen_loss = 0.9212247441554892, disc_loss = 0.0003086847779019896
Trained batch 29 in epoch 4, gen_loss = 0.9230339368184407, disc_loss = 0.00030682952298472324
Trained batch 30 in epoch 4, gen_loss = 0.9249967029017787, disc_loss = 0.0003165029582657641
Trained batch 31 in epoch 4, gen_loss = 0.9255304839462042, disc_loss = 0.0003168524035572773
Trained batch 32 in epoch 4, gen_loss = 0.9263326742432334, disc_loss = 0.0003220728531508057
Trained batch 33 in epoch 4, gen_loss = 0.9254630611223333, disc_loss = 0.0003189337923472254
Trained batch 34 in epoch 4, gen_loss = 0.9263309121131897, disc_loss = 0.00031789534966394835
Trained batch 35 in epoch 4, gen_loss = 0.9270942310492197, disc_loss = 0.00031495356920964294
Trained batch 36 in epoch 4, gen_loss = 0.9260328750352602, disc_loss = 0.0003114677780792369
Trained batch 37 in epoch 4, gen_loss = 0.9256433091665569, disc_loss = 0.0003097488113685119
Trained batch 38 in epoch 4, gen_loss = 0.9229864585093963, disc_loss = 0.0003090677122460105
Trained batch 39 in epoch 4, gen_loss = 0.9237615570425988, disc_loss = 0.00030987002719484735
Trained batch 40 in epoch 4, gen_loss = 0.9218365346513143, disc_loss = 0.000309901626102013
Trained batch 41 in epoch 4, gen_loss = 0.9218092276936486, disc_loss = 0.00030941439555525515
Trained batch 42 in epoch 4, gen_loss = 0.9196692926939144, disc_loss = 0.0003073585242016761
Trained batch 43 in epoch 4, gen_loss = 0.918594020334157, disc_loss = 0.00030909417182556354
Trained batch 44 in epoch 4, gen_loss = 0.9208778712484572, disc_loss = 0.0003132762882160023
Trained batch 45 in epoch 4, gen_loss = 0.921851335660271, disc_loss = 0.0003143397641353026
Trained batch 46 in epoch 4, gen_loss = 0.9214458985531584, disc_loss = 0.0003137907432516086
Trained batch 47 in epoch 4, gen_loss = 0.9244758374989033, disc_loss = 0.0003211879244796971
Trained batch 48 in epoch 4, gen_loss = 0.9230814515327921, disc_loss = 0.0003201033607035001
Trained batch 49 in epoch 4, gen_loss = 0.9211508452892303, disc_loss = 0.0003252233206876554
Trained batch 50 in epoch 4, gen_loss = 0.9218220290015725, disc_loss = 0.0003239268265258265
Trained batch 51 in epoch 4, gen_loss = 0.9209636724912204, disc_loss = 0.00032587122041149996
Trained batch 52 in epoch 4, gen_loss = 0.9194832185529312, disc_loss = 0.00032497630734655585
Trained batch 53 in epoch 4, gen_loss = 0.9186704622374641, disc_loss = 0.0003228942950954661
Trained batch 54 in epoch 4, gen_loss = 0.9178493207151239, disc_loss = 0.00032150336456569756
Trained batch 55 in epoch 4, gen_loss = 0.918471807880061, disc_loss = 0.0003192151982927628
Trained batch 56 in epoch 4, gen_loss = 0.9171965279077229, disc_loss = 0.00031685944020609256
Trained batch 57 in epoch 4, gen_loss = 0.9163445326788672, disc_loss = 0.00032055501174783847
Trained batch 58 in epoch 4, gen_loss = 0.9159092943547136, disc_loss = 0.00031942088463761983
Trained batch 59 in epoch 4, gen_loss = 0.9177679618199667, disc_loss = 0.00031778354920485675
Trained batch 60 in epoch 4, gen_loss = 0.9168189451342723, disc_loss = 0.0003184411208599531
Trained batch 61 in epoch 4, gen_loss = 0.9158517276087115, disc_loss = 0.0003175989162803988
Trained batch 62 in epoch 4, gen_loss = 0.9155110707358708, disc_loss = 0.00031614603935777843
Trained batch 63 in epoch 4, gen_loss = 0.9139711521565914, disc_loss = 0.00031559344256493205
Trained batch 64 in epoch 4, gen_loss = 0.9127951209361737, disc_loss = 0.00031424612836697353
Trained batch 65 in epoch 4, gen_loss = 0.9122434881600466, disc_loss = 0.0003158190974676417
Trained batch 66 in epoch 4, gen_loss = 0.9121304225565782, disc_loss = 0.00031933899744719603
Trained batch 67 in epoch 4, gen_loss = 0.9136622539337944, disc_loss = 0.00032031041251577656
Trained batch 68 in epoch 4, gen_loss = 0.9113379284955453, disc_loss = 0.0003193669937267576
Trained batch 69 in epoch 4, gen_loss = 0.911334879057748, disc_loss = 0.0003233114332293293
Trained batch 70 in epoch 4, gen_loss = 0.9117757031615351, disc_loss = 0.0003232007455179127
Trained batch 71 in epoch 4, gen_loss = 0.9134044994910558, disc_loss = 0.0003280731855031465
Trained batch 72 in epoch 4, gen_loss = 0.9152806833998798, disc_loss = 0.000328528308485035
Trained batch 73 in epoch 4, gen_loss = 0.9158118198046813, disc_loss = 0.00032769177050795406
Trained batch 74 in epoch 4, gen_loss = 0.9160062503814698, disc_loss = 0.0003252139854400108
Trained batch 75 in epoch 4, gen_loss = 0.916763396639573, disc_loss = 0.0003241053334357658
Trained batch 76 in epoch 4, gen_loss = 0.9171380029096232, disc_loss = 0.00032239924064027026
Trained batch 77 in epoch 4, gen_loss = 0.9178212735897455, disc_loss = 0.00032138988638344483
Trained batch 78 in epoch 4, gen_loss = 0.9175179774248148, disc_loss = 0.0003203567124083874
Trained batch 79 in epoch 4, gen_loss = 0.9180789299309253, disc_loss = 0.00031904399638733595
Trained batch 80 in epoch 4, gen_loss = 0.9184842006659802, disc_loss = 0.00031711055159160616
Trained batch 81 in epoch 4, gen_loss = 0.918316051727388, disc_loss = 0.0003152380998405378
Trained batch 82 in epoch 4, gen_loss = 0.9183706662741052, disc_loss = 0.00031509993777397165
Trained batch 83 in epoch 4, gen_loss = 0.9168929791166669, disc_loss = 0.00031967085808338157
Trained batch 84 in epoch 4, gen_loss = 0.9177809953689575, disc_loss = 0.0003207727804478696
Trained batch 85 in epoch 4, gen_loss = 0.9190104867136756, disc_loss = 0.0003198041451342274
Trained batch 86 in epoch 4, gen_loss = 0.9198486955686548, disc_loss = 0.0003186862430021424
Trained batch 87 in epoch 4, gen_loss = 0.9200481718236749, disc_loss = 0.000318371567779898
Trained batch 88 in epoch 4, gen_loss = 0.9199481867672352, disc_loss = 0.0003162582147882184
Trained batch 89 in epoch 4, gen_loss = 0.9196193363931444, disc_loss = 0.0003151184961704227
Trained batch 90 in epoch 4, gen_loss = 0.9201000529331166, disc_loss = 0.0003160126729558764
Trained batch 91 in epoch 4, gen_loss = 0.9205395579338074, disc_loss = 0.0003166711348572078
Trained batch 92 in epoch 4, gen_loss = 0.9206600490436759, disc_loss = 0.0003168263467296617
Trained batch 93 in epoch 4, gen_loss = 0.9206321765767768, disc_loss = 0.00031622276846393746
Trained batch 94 in epoch 4, gen_loss = 0.9198701162087289, disc_loss = 0.0003153981651657408
Trained batch 95 in epoch 4, gen_loss = 0.9183569382876158, disc_loss = 0.00031495311623075395
Trained batch 96 in epoch 4, gen_loss = 0.9187942356178441, disc_loss = 0.00031522086376837964
Trained batch 97 in epoch 4, gen_loss = 0.9186977896155143, disc_loss = 0.000315972157351302
Trained batch 98 in epoch 4, gen_loss = 0.9197001740185902, disc_loss = 0.0003155600669090589
Trained batch 99 in epoch 4, gen_loss = 0.91948515355587, disc_loss = 0.00031700772597105243
Trained batch 100 in epoch 4, gen_loss = 0.9191425619739118, disc_loss = 0.00031615045145822526
Trained batch 101 in epoch 4, gen_loss = 0.920120883806079, disc_loss = 0.0003160118644968059
Trained batch 102 in epoch 4, gen_loss = 0.9207057472571586, disc_loss = 0.00031567577035867075
Trained batch 103 in epoch 4, gen_loss = 0.9208290525353872, disc_loss = 0.0003153121521721075
Trained batch 104 in epoch 4, gen_loss = 0.9205776702790033, disc_loss = 0.0003141478281967076
Trained batch 105 in epoch 4, gen_loss = 0.9203108346687173, disc_loss = 0.00031272057918304544
Trained batch 106 in epoch 4, gen_loss = 0.9206912461842331, disc_loss = 0.00031185361883650907
Trained batch 107 in epoch 4, gen_loss = 0.9210644949365545, disc_loss = 0.0003112516894395446
Trained batch 108 in epoch 4, gen_loss = 0.9212620635645106, disc_loss = 0.00030986439231612265
Trained batch 109 in epoch 4, gen_loss = 0.9207901336930014, disc_loss = 0.00031086081369060344
Trained batch 110 in epoch 4, gen_loss = 0.9208774265942273, disc_loss = 0.000310079695138795
Trained batch 111 in epoch 4, gen_loss = 0.9202874329473291, disc_loss = 0.0003096006296670696
Trained batch 112 in epoch 4, gen_loss = 0.9195495796414603, disc_loss = 0.00030901967957347996
Trained batch 113 in epoch 4, gen_loss = 0.9191470318718961, disc_loss = 0.00030847859919671655
Trained batch 114 in epoch 4, gen_loss = 0.9188392633977144, disc_loss = 0.0003080789671714782
Trained batch 115 in epoch 4, gen_loss = 0.9187051556233702, disc_loss = 0.0003073229490837548
Trained batch 116 in epoch 4, gen_loss = 0.9192975703467671, disc_loss = 0.0003073626917012784
Trained batch 117 in epoch 4, gen_loss = 0.919598195512416, disc_loss = 0.0003067956273236817
Trained batch 118 in epoch 4, gen_loss = 0.9196005769136573, disc_loss = 0.000307322053376687
Trained batch 119 in epoch 4, gen_loss = 0.9196179533998171, disc_loss = 0.0003060093445431752
Trained batch 120 in epoch 4, gen_loss = 0.9198520188489236, disc_loss = 0.0003054604681847571
Trained batch 121 in epoch 4, gen_loss = 0.9209307036438926, disc_loss = 0.0003048314642090518
Trained batch 122 in epoch 4, gen_loss = 0.9206707327346492, disc_loss = 0.000303986511662663
Trained batch 123 in epoch 4, gen_loss = 0.9207938385586585, disc_loss = 0.00030271238668525083
Trained batch 124 in epoch 4, gen_loss = 0.9201774444580079, disc_loss = 0.00030262401851359754
Trained batch 125 in epoch 4, gen_loss = 0.9204917124339512, disc_loss = 0.0003030126241529139
Trained batch 126 in epoch 4, gen_loss = 0.9198027126432404, disc_loss = 0.0003029378826544789
Trained batch 127 in epoch 4, gen_loss = 0.9201174126937985, disc_loss = 0.00030332912808717083
Trained batch 128 in epoch 4, gen_loss = 0.9197643879772157, disc_loss = 0.0003029627319607638
Trained batch 129 in epoch 4, gen_loss = 0.920641952753067, disc_loss = 0.0003040604021337528
Trained batch 130 in epoch 4, gen_loss = 0.9221064084358798, disc_loss = 0.0003163466050746346
Trained batch 131 in epoch 4, gen_loss = 0.9226986960028157, disc_loss = 0.0003194166273522459
Trained batch 132 in epoch 4, gen_loss = 0.922572734660672, disc_loss = 0.00031953535812532293
Trained batch 133 in epoch 4, gen_loss = 0.9228879373465011, disc_loss = 0.00031974710124013113
Trained batch 134 in epoch 4, gen_loss = 0.9226672746517041, disc_loss = 0.00031872478742756087
Trained batch 135 in epoch 4, gen_loss = 0.9217855080085642, disc_loss = 0.00031875228299160134
Trained batch 136 in epoch 4, gen_loss = 0.9226412625208388, disc_loss = 0.0003184932782221246
Trained batch 137 in epoch 4, gen_loss = 0.9239202357720637, disc_loss = 0.0003192894873791374
Trained batch 138 in epoch 4, gen_loss = 0.9244078076143059, disc_loss = 0.00031873587007624294
Trained batch 139 in epoch 4, gen_loss = 0.9238834040505546, disc_loss = 0.00031865836759347333
Trained batch 140 in epoch 4, gen_loss = 0.9241625104390138, disc_loss = 0.000317708784710213
Trained batch 141 in epoch 4, gen_loss = 0.9243941676448768, disc_loss = 0.0003171318394507439
Trained batch 142 in epoch 4, gen_loss = 0.9235449996027913, disc_loss = 0.00031607600132091347
Trained batch 143 in epoch 4, gen_loss = 0.9233320044974486, disc_loss = 0.00031725834146022354
Trained batch 144 in epoch 4, gen_loss = 0.9229640792156087, disc_loss = 0.0003168881082995634
Trained batch 145 in epoch 4, gen_loss = 0.9234552991716829, disc_loss = 0.0003156110474701065
Trained batch 146 in epoch 4, gen_loss = 0.9234911410176024, disc_loss = 0.000314614837011164
Trained batch 147 in epoch 4, gen_loss = 0.923562331376849, disc_loss = 0.0003149088420409621
Trained batch 148 in epoch 4, gen_loss = 0.9247646087768094, disc_loss = 0.00031475231980032995
Trained batch 149 in epoch 4, gen_loss = 0.9249511710802714, disc_loss = 0.00031548686277043693
Trained batch 150 in epoch 4, gen_loss = 0.9255769971190699, disc_loss = 0.00031528749091886847
Trained batch 151 in epoch 4, gen_loss = 0.926008429574339, disc_loss = 0.00031511692319135794
Trained batch 152 in epoch 4, gen_loss = 0.9252912152826397, disc_loss = 0.0003143557250534726
Trained batch 153 in epoch 4, gen_loss = 0.9248797390368078, disc_loss = 0.00031380918762924804
Trained batch 154 in epoch 4, gen_loss = 0.924841316669218, disc_loss = 0.0003130517301014474
Trained batch 155 in epoch 4, gen_loss = 0.9254933293813314, disc_loss = 0.0003123526256762815
Trained batch 156 in epoch 4, gen_loss = 0.9249319164616288, disc_loss = 0.0003112028762594364
Trained batch 157 in epoch 4, gen_loss = 0.925222427784642, disc_loss = 0.0003124139416458887
Trained batch 158 in epoch 4, gen_loss = 0.9246428110314615, disc_loss = 0.00031212358072886255
Trained batch 159 in epoch 4, gen_loss = 0.924697571247816, disc_loss = 0.0003122456244454952
Trained batch 160 in epoch 4, gen_loss = 0.9241073220412924, disc_loss = 0.00031179043105355125
Trained batch 161 in epoch 4, gen_loss = 0.9238457823241198, disc_loss = 0.0003107493648263856
Trained batch 162 in epoch 4, gen_loss = 0.9239847857527937, disc_loss = 0.00031067332100377426
Trained batch 163 in epoch 4, gen_loss = 0.9240925322945525, disc_loss = 0.00031116242329206706
Trained batch 164 in epoch 4, gen_loss = 0.9239862604574723, disc_loss = 0.00031034630912031526
Trained batch 165 in epoch 4, gen_loss = 0.9239714752478771, disc_loss = 0.00031026030484943213
Trained batch 166 in epoch 4, gen_loss = 0.9240869865446033, disc_loss = 0.00031032557290780753
Trained batch 167 in epoch 4, gen_loss = 0.9242199336489042, disc_loss = 0.000309352696733965
Trained batch 168 in epoch 4, gen_loss = 0.9234856702166901, disc_loss = 0.00030859841952395224
Trained batch 169 in epoch 4, gen_loss = 0.92364161400234, disc_loss = 0.00030809636013787785
Trained batch 170 in epoch 4, gen_loss = 0.923437057531368, disc_loss = 0.00033536218493095766
Trained batch 171 in epoch 4, gen_loss = 0.923872948732487, disc_loss = 0.0003551653440639669
Trained batch 172 in epoch 4, gen_loss = 0.9255375831113385, disc_loss = 0.00037044757831440644
Trained batch 173 in epoch 4, gen_loss = 0.9262911687637198, disc_loss = 0.0003745521688211613
Trained batch 174 in epoch 4, gen_loss = 0.9266626490865435, disc_loss = 0.000381391079614072
Trained batch 175 in epoch 4, gen_loss = 0.9277347857979211, disc_loss = 0.0003835882151344611
Trained batch 176 in epoch 4, gen_loss = 0.9286705171321071, disc_loss = 0.00038646881514305175
Trained batch 177 in epoch 4, gen_loss = 0.9299476813064532, disc_loss = 0.00038756332168907577
Trained batch 178 in epoch 4, gen_loss = 0.9312809828939385, disc_loss = 0.0003880456621809368
Trained batch 179 in epoch 4, gen_loss = 0.9319715893930859, disc_loss = 0.0003885334149850274
Trained batch 180 in epoch 4, gen_loss = 0.9322652635653375, disc_loss = 0.0003890533816906783
Trained batch 181 in epoch 4, gen_loss = 0.93334937783388, disc_loss = 0.0003894109095499216
Trained batch 182 in epoch 4, gen_loss = 0.9341186399016875, disc_loss = 0.0003904743255096961
Trained batch 183 in epoch 4, gen_loss = 0.93425735960836, disc_loss = 0.00039318415885803836
Trained batch 184 in epoch 4, gen_loss = 0.9345294765523962, disc_loss = 0.00039382185606046805
Trained batch 185 in epoch 4, gen_loss = 0.9352461388034206, disc_loss = 0.0003953704427238003
Trained batch 186 in epoch 4, gen_loss = 0.9363226750317741, disc_loss = 0.00039692204870485305
Trained batch 187 in epoch 4, gen_loss = 0.9369631194053812, disc_loss = 0.00039730360553453755
Trained batch 188 in epoch 4, gen_loss = 0.9373166378212985, disc_loss = 0.00039825636455259486
Trained batch 189 in epoch 4, gen_loss = 0.9380998730659484, disc_loss = 0.00040049170929705723
Trained batch 190 in epoch 4, gen_loss = 0.9389574359224729, disc_loss = 0.00040548591893129735
Trained batch 191 in epoch 4, gen_loss = 0.9390311017632484, disc_loss = 0.0004073968730911777
Trained batch 192 in epoch 4, gen_loss = 0.9401870008577337, disc_loss = 0.0004099856741959229
Trained batch 193 in epoch 4, gen_loss = 0.9407738041631954, disc_loss = 0.00041149490935663143
Trained batch 194 in epoch 4, gen_loss = 0.941204676261315, disc_loss = 0.0004126864575739138
Trained batch 195 in epoch 4, gen_loss = 0.9418260217929373, disc_loss = 0.0004150957759019529
Trained batch 196 in epoch 4, gen_loss = 0.9426018641079743, disc_loss = 0.000416370866383511
Trained batch 197 in epoch 4, gen_loss = 0.9425629880091156, disc_loss = 0.0004170211167997831
Trained batch 198 in epoch 4, gen_loss = 0.9427597154324977, disc_loss = 0.0004182591386889365
Trained batch 199 in epoch 4, gen_loss = 0.9424776783585549, disc_loss = 0.00041840914265776517
Trained batch 200 in epoch 4, gen_loss = 0.9426439772197857, disc_loss = 0.00041951429290263754
Trained batch 201 in epoch 4, gen_loss = 0.9428212928890002, disc_loss = 0.0004193805917287199
Trained batch 202 in epoch 4, gen_loss = 0.943527687065707, disc_loss = 0.00042090256386746196
Trained batch 203 in epoch 4, gen_loss = 0.9434681724683911, disc_loss = 0.000421365670869515
Trained batch 204 in epoch 4, gen_loss = 0.9442038108662861, disc_loss = 0.0004220841092585654
Trained batch 205 in epoch 4, gen_loss = 0.944418043187521, disc_loss = 0.0004239239059846387
Trained batch 206 in epoch 4, gen_loss = 0.9446239615408119, disc_loss = 0.0004254536777605406
Trained batch 207 in epoch 4, gen_loss = 0.9438564290220921, disc_loss = 0.0005320588979884633
Trained batch 208 in epoch 4, gen_loss = 0.9444609121842817, disc_loss = 0.0005497043687347812
Trained batch 209 in epoch 4, gen_loss = 0.9451507852191017, disc_loss = 0.0005606296170818885
Trained batch 210 in epoch 4, gen_loss = 0.9467878980094223, disc_loss = 0.0005642578645937048
Trained batch 211 in epoch 4, gen_loss = 0.9472429026972573, disc_loss = 0.0005663706565342782
Trained batch 212 in epoch 4, gen_loss = 0.9478261862562296, disc_loss = 0.0005708851252639876
Trained batch 213 in epoch 4, gen_loss = 0.9481277649647721, disc_loss = 0.0005715018757493844
Trained batch 214 in epoch 4, gen_loss = 0.9497302681900734, disc_loss = 0.000579024259296116
Trained batch 215 in epoch 4, gen_loss = 0.9499448907596094, disc_loss = 0.0005802104454536069
Trained batch 216 in epoch 4, gen_loss = 0.9505591002477479, disc_loss = 0.00058016150500164
Trained batch 217 in epoch 4, gen_loss = 0.950572519127382, disc_loss = 0.0005805072516289437
Trained batch 218 in epoch 4, gen_loss = 0.9510242280350428, disc_loss = 0.0005813257394121432
Trained batch 219 in epoch 4, gen_loss = 0.9510939259420742, disc_loss = 0.0005812231938762125
Trained batch 220 in epoch 4, gen_loss = 0.9520401175205524, disc_loss = 0.0005830587294164463
Trained batch 221 in epoch 4, gen_loss = 0.9520446591012113, disc_loss = 0.0005844767160974821
Trained batch 222 in epoch 4, gen_loss = 0.9522916022437571, disc_loss = 0.000585997692059262
Trained batch 223 in epoch 4, gen_loss = 0.9527832293616874, disc_loss = 0.0005854625080376406
Trained batch 224 in epoch 4, gen_loss = 0.9530244739850362, disc_loss = 0.0005857883430629348
Trained batch 225 in epoch 4, gen_loss = 0.9529626029255116, disc_loss = 0.000586939926748061
Trained batch 226 in epoch 4, gen_loss = 0.9532887071764942, disc_loss = 0.0005868363593800387
Trained batch 227 in epoch 4, gen_loss = 0.9533127175088514, disc_loss = 0.0005884874868538566
Trained batch 228 in epoch 4, gen_loss = 0.9533984676719233, disc_loss = 0.0005893617745526502
Trained batch 229 in epoch 4, gen_loss = 0.9543051175449205, disc_loss = 0.0005926229903074589
Trained batch 230 in epoch 4, gen_loss = 0.9546930351298609, disc_loss = 0.0005983640997316809
Trained batch 231 in epoch 4, gen_loss = 0.9558641874584658, disc_loss = 0.000611830026361437
Trained batch 232 in epoch 4, gen_loss = 0.9568626251343494, disc_loss = 0.0006191304432305152
Trained batch 233 in epoch 4, gen_loss = 0.9570992558430402, disc_loss = 0.0006222469132303053
Trained batch 234 in epoch 4, gen_loss = 0.9575293804736847, disc_loss = 0.0006242442468027684
Trained batch 235 in epoch 4, gen_loss = 0.9580347750146511, disc_loss = 0.0006251371780955983
Trained batch 236 in epoch 4, gen_loss = 0.9581256056133705, disc_loss = 0.0006261989435614264
Trained batch 237 in epoch 4, gen_loss = 0.9585468330804039, disc_loss = 0.0006253928769191046
Trained batch 238 in epoch 4, gen_loss = 0.9589961275894772, disc_loss = 0.0006246853847651856
Trained batch 239 in epoch 4, gen_loss = 0.9592886440455913, disc_loss = 0.0006239271964659565
Trained batch 240 in epoch 4, gen_loss = 0.9594343178499783, disc_loss = 0.0006235825927146514
Trained batch 241 in epoch 4, gen_loss = 0.9599487436704399, disc_loss = 0.0006228632488829653
Trained batch 242 in epoch 4, gen_loss = 0.9601608966113118, disc_loss = 0.0006222530827333445
Trained batch 243 in epoch 4, gen_loss = 0.9605176141027545, disc_loss = 0.0006211559857994692
Trained batch 244 in epoch 4, gen_loss = 0.9609840816381027, disc_loss = 0.0006203930988332865
Trained batch 245 in epoch 4, gen_loss = 0.9614394292598818, disc_loss = 0.0006195499139484889
Trained batch 246 in epoch 4, gen_loss = 0.9617962161539054, disc_loss = 0.0006193816343106533
Trained batch 247 in epoch 4, gen_loss = 0.9622069097334339, disc_loss = 0.000620042608012051
Trained batch 248 in epoch 4, gen_loss = 0.9630961078237817, disc_loss = 0.0006213481252219146
Trained batch 249 in epoch 4, gen_loss = 0.9637631621360779, disc_loss = 0.0006218711332767271
Trained batch 250 in epoch 4, gen_loss = 0.9638170155870962, disc_loss = 0.0006223803235239264
Trained batch 251 in epoch 4, gen_loss = 0.9643716712792715, disc_loss = 0.0006236603964810326
Trained batch 252 in epoch 4, gen_loss = 0.964883047601451, disc_loss = 0.0006267293399497094
Trained batch 253 in epoch 4, gen_loss = 0.9645322434545502, disc_loss = 0.0006279743763624588
Trained batch 254 in epoch 4, gen_loss = 0.9644394453834085, disc_loss = 0.0006279380891047527
Trained batch 255 in epoch 4, gen_loss = 0.9646063423715532, disc_loss = 0.0006280812578438599
Trained batch 256 in epoch 4, gen_loss = 0.9642902056066907, disc_loss = 0.000630228904948809
Trained batch 257 in epoch 4, gen_loss = 0.9642166523046272, disc_loss = 0.0006300471020865168
Trained batch 258 in epoch 4, gen_loss = 0.964379104408058, disc_loss = 0.0006298997637102898
Trained batch 259 in epoch 4, gen_loss = 0.9648266443839439, disc_loss = 0.0006333363870978176
Trained batch 260 in epoch 4, gen_loss = 0.9648302482919218, disc_loss = 0.0006346770053639316
Trained batch 261 in epoch 4, gen_loss = 0.965167235327131, disc_loss = 0.0006408741484277967
Trained batch 262 in epoch 4, gen_loss = 0.9662614453428146, disc_loss = 0.0006531977703677094
Trained batch 263 in epoch 4, gen_loss = 0.9670666763276765, disc_loss = 0.0006570895362859698
Trained batch 264 in epoch 4, gen_loss = 0.9668423349002622, disc_loss = 0.0006594127682718571
Trained batch 265 in epoch 4, gen_loss = 0.9665402619910419, disc_loss = 0.0006633291396385065
Trained batch 266 in epoch 4, gen_loss = 0.967160553298193, disc_loss = 0.0006646215354858929
Trained batch 267 in epoch 4, gen_loss = 0.9677103671120174, disc_loss = 0.0006665154913533305
Trained batch 268 in epoch 4, gen_loss = 0.9676679858044621, disc_loss = 0.0006684763769798334
Trained batch 269 in epoch 4, gen_loss = 0.9679357963579672, disc_loss = 0.0006694808737611985
Trained batch 270 in epoch 4, gen_loss = 0.9679927350850123, disc_loss = 0.000669942076936127
Trained batch 271 in epoch 4, gen_loss = 0.9678524335955873, disc_loss = 0.0006750974949575132
Trained batch 272 in epoch 4, gen_loss = 0.9681072730721135, disc_loss = 0.0006765675188478035
Trained batch 273 in epoch 4, gen_loss = 0.9681547371140362, disc_loss = 0.0006769315005993015
Trained batch 274 in epoch 4, gen_loss = 0.9683895154432817, disc_loss = 0.0006773031561698934
Trained batch 275 in epoch 4, gen_loss = 0.9670563782902731, disc_loss = 0.0009841289146330066
Trained batch 276 in epoch 4, gen_loss = 0.9682963339860688, disc_loss = 0.0010725407707668833
Trained batch 277 in epoch 4, gen_loss = 0.9690922642354485, disc_loss = 0.001264944336686548
Trained batch 278 in epoch 4, gen_loss = 0.9698191567133831, disc_loss = 0.0012993354969019551
Trained batch 279 in epoch 4, gen_loss = 0.97005602398089, disc_loss = 0.0013073950315239406
Trained batch 280 in epoch 4, gen_loss = 0.9703201727935004, disc_loss = 0.0013146329665655152
Trained batch 281 in epoch 4, gen_loss = 0.9707220731474829, disc_loss = 0.001317500713863823
Trained batch 282 in epoch 4, gen_loss = 0.9711581647606705, disc_loss = 0.0013191707225252345
Trained batch 283 in epoch 4, gen_loss = 0.9715610161213808, disc_loss = 0.0013187380058631059
Trained batch 284 in epoch 4, gen_loss = 0.971691638335847, disc_loss = 0.0013181942498225621
Trained batch 285 in epoch 4, gen_loss = 0.9722178534611122, disc_loss = 0.0013177160159306164
Trained batch 286 in epoch 4, gen_loss = 0.9728492932452557, disc_loss = 0.0013158168279763006
Trained batch 287 in epoch 4, gen_loss = 0.973541289774908, disc_loss = 0.0013154773922299985
Trained batch 288 in epoch 4, gen_loss = 0.9734302231184752, disc_loss = 0.0013126733228560235
Trained batch 289 in epoch 4, gen_loss = 0.9736942657108965, disc_loss = 0.0013103045608972778
Trained batch 290 in epoch 4, gen_loss = 0.9739198385645024, disc_loss = 0.0013077343154288157
Trained batch 291 in epoch 4, gen_loss = 0.9743332773038785, disc_loss = 0.0013053393063086807
Trained batch 292 in epoch 4, gen_loss = 0.9742777420799074, disc_loss = 0.0013034111043297664
Trained batch 293 in epoch 4, gen_loss = 0.9740889260963518, disc_loss = 0.0013005952385937648
Trained batch 294 in epoch 4, gen_loss = 0.974260836738651, disc_loss = 0.001298298443799791
Trained batch 295 in epoch 4, gen_loss = 0.9739577929313118, disc_loss = 0.001296771335251538
Trained batch 296 in epoch 4, gen_loss = 0.9741785949729509, disc_loss = 0.0012946126628130116
Trained batch 297 in epoch 4, gen_loss = 0.9743902249224234, disc_loss = 0.0012931160918564298
Trained batch 298 in epoch 4, gen_loss = 0.974375138514018, disc_loss = 0.0012901420291823904
Trained batch 299 in epoch 4, gen_loss = 0.9740691399574279, disc_loss = 0.0012880186720576603
Trained batch 300 in epoch 4, gen_loss = 0.9742873324904331, disc_loss = 0.001285410983489124
Trained batch 301 in epoch 4, gen_loss = 0.9744868033769115, disc_loss = 0.0012830467458597743
Trained batch 302 in epoch 4, gen_loss = 0.9742238421251278, disc_loss = 0.001280538763467871
Trained batch 303 in epoch 4, gen_loss = 0.9737675835035349, disc_loss = 0.0012810905260553945
Trained batch 304 in epoch 4, gen_loss = 0.9733473943882301, disc_loss = 0.001281379465897354
Trained batch 305 in epoch 4, gen_loss = 0.9736130029157876, disc_loss = 0.0012823547851701352
Trained batch 306 in epoch 4, gen_loss = 0.9732888395312554, disc_loss = 0.0012816909532550364
Trained batch 307 in epoch 4, gen_loss = 0.9735739453659429, disc_loss = 0.0012795993027427724
Trained batch 308 in epoch 4, gen_loss = 0.9735432986688459, disc_loss = 0.0012767122879765271
Trained batch 309 in epoch 4, gen_loss = 0.9735776303275939, disc_loss = 0.001275155736619772
Trained batch 310 in epoch 4, gen_loss = 0.9736656255277407, disc_loss = 0.0012730599518687917
Trained batch 311 in epoch 4, gen_loss = 0.9738464410870503, disc_loss = 0.0012703216848771821
Trained batch 312 in epoch 4, gen_loss = 0.9741879992972547, disc_loss = 0.0012680082694912246
Trained batch 313 in epoch 4, gen_loss = 0.9742632977142456, disc_loss = 0.0012654052641050695
Trained batch 314 in epoch 4, gen_loss = 0.9739859461784363, disc_loss = 0.0012629199683913844
Trained batch 315 in epoch 4, gen_loss = 0.9739294974487039, disc_loss = 0.0012603695942306318
Trained batch 316 in epoch 4, gen_loss = 0.9737544052232328, disc_loss = 0.0012586472639266831
Trained batch 317 in epoch 4, gen_loss = 0.9739574497600771, disc_loss = 0.0012561198462254029
Trained batch 318 in epoch 4, gen_loss = 0.9737248674829178, disc_loss = 0.0012532227116926692
Trained batch 319 in epoch 4, gen_loss = 0.9739976249635219, disc_loss = 0.0012504645627359422
Trained batch 320 in epoch 4, gen_loss = 0.973884746850094, disc_loss = 0.001248265626433021
Trained batch 321 in epoch 4, gen_loss = 0.9736436899774563, disc_loss = 0.0012453981743990271
Trained batch 322 in epoch 4, gen_loss = 0.9737471332860067, disc_loss = 0.0012428522855241642
Trained batch 323 in epoch 4, gen_loss = 0.9734423171590876, disc_loss = 0.001240289989108993
Trained batch 324 in epoch 4, gen_loss = 0.9735042645381047, disc_loss = 0.001237751316288128
Trained batch 325 in epoch 4, gen_loss = 0.9735519425269284, disc_loss = 0.0012359399846387153
Trained batch 326 in epoch 4, gen_loss = 0.9736320359991231, disc_loss = 0.0012331073196332144
Trained batch 327 in epoch 4, gen_loss = 0.9733644752967648, disc_loss = 0.0012327451355171122
Trained batch 328 in epoch 4, gen_loss = 0.9735441581094156, disc_loss = 0.0012323750345490019
Trained batch 329 in epoch 4, gen_loss = 0.9734784682591756, disc_loss = 0.0012298461648187543
Trained batch 330 in epoch 4, gen_loss = 0.9739384240614324, disc_loss = 0.0012284816899832782
Trained batch 331 in epoch 4, gen_loss = 0.9743381598627711, disc_loss = 0.001227760224482844
Trained batch 332 in epoch 4, gen_loss = 0.9744068837022638, disc_loss = 0.0012256991231898628
Trained batch 333 in epoch 4, gen_loss = 0.9747603690909769, disc_loss = 0.0012235813445225497
Trained batch 334 in epoch 4, gen_loss = 0.9750480710570492, disc_loss = 0.0012210796594553724
Trained batch 335 in epoch 4, gen_loss = 0.9750850908458233, disc_loss = 0.0012187757633693678
Trained batch 336 in epoch 4, gen_loss = 0.9755414867613366, disc_loss = 0.001218196727345471
Trained batch 337 in epoch 4, gen_loss = 0.9756148815507719, disc_loss = 0.0012162052000305869
Trained batch 338 in epoch 4, gen_loss = 0.9757057869680511, disc_loss = 0.0012144948607657495
Trained batch 339 in epoch 4, gen_loss = 0.9755577793892692, disc_loss = 0.0012123842070115428
Trained batch 340 in epoch 4, gen_loss = 0.9756980929906067, disc_loss = 0.0012101794097929663
Trained batch 341 in epoch 4, gen_loss = 0.9759001897441016, disc_loss = 0.00120828450807712
Trained batch 342 in epoch 4, gen_loss = 0.9760435466863671, disc_loss = 0.0012058392385582224
Trained batch 343 in epoch 4, gen_loss = 0.9759838309052379, disc_loss = 0.0012040847841278666
Trained batch 344 in epoch 4, gen_loss = 0.9759170710176661, disc_loss = 0.0012020005281437594
Trained batch 345 in epoch 4, gen_loss = 0.9765988707197883, disc_loss = 0.0012007515835511832
Trained batch 346 in epoch 4, gen_loss = 0.9765207281373763, disc_loss = 0.001198476480740466
Trained batch 347 in epoch 4, gen_loss = 0.9765464798814949, disc_loss = 0.0011979882882111144
Trained batch 348 in epoch 4, gen_loss = 0.9765504911157669, disc_loss = 0.0011957180895192153
Trained batch 349 in epoch 4, gen_loss = 0.9766568308217185, disc_loss = 0.0011933522617826903
Trained batch 350 in epoch 4, gen_loss = 0.9763001779205779, disc_loss = 0.0011928824971458526
Trained batch 351 in epoch 4, gen_loss = 0.9761977029794996, disc_loss = 0.0011918724524713814
Trained batch 352 in epoch 4, gen_loss = 0.9763132401296167, disc_loss = 0.0011913371700697866
Trained batch 353 in epoch 4, gen_loss = 0.9765234781523883, disc_loss = 0.001189955326491417
Trained batch 354 in epoch 4, gen_loss = 0.9768944132495934, disc_loss = 0.0011886895182919622
Trained batch 355 in epoch 4, gen_loss = 0.9767606482746896, disc_loss = 0.0011865192897316315
Trained batch 356 in epoch 4, gen_loss = 0.976899954785152, disc_loss = 0.0011855170349782875
Trained batch 357 in epoch 4, gen_loss = 0.9765054914871407, disc_loss = 0.0011847707959247737
Trained batch 358 in epoch 4, gen_loss = 0.9765216741389219, disc_loss = 0.001182719533586898
Trained batch 359 in epoch 4, gen_loss = 0.9762756026453442, disc_loss = 0.0011827796609900866
Trained batch 360 in epoch 4, gen_loss = 0.9762932735797111, disc_loss = 0.0011815740437865377
Trained batch 361 in epoch 4, gen_loss = 0.9763138406184497, disc_loss = 0.0011793075390118277
Trained batch 362 in epoch 4, gen_loss = 0.9763375492792156, disc_loss = 0.0011770666298952298
Trained batch 363 in epoch 4, gen_loss = 0.9762322884667051, disc_loss = 0.0011767789348975915
Trained batch 364 in epoch 4, gen_loss = 0.9760464869133414, disc_loss = 0.0011797177366520062
Trained batch 365 in epoch 4, gen_loss = 0.9764541770265402, disc_loss = 0.0011781608441967359
Trained batch 366 in epoch 4, gen_loss = 0.9763775968096886, disc_loss = 0.0011780285286385318
Trained batch 367 in epoch 4, gen_loss = 0.9764182682594528, disc_loss = 0.0011766598760874806
Trained batch 368 in epoch 4, gen_loss = 0.9767720730001042, disc_loss = 0.001175024464379726
Trained batch 369 in epoch 4, gen_loss = 0.9763461936164547, disc_loss = 0.001174438995744945
Trained batch 370 in epoch 4, gen_loss = 0.976706504661118, disc_loss = 0.0011729276433509882
Trained batch 371 in epoch 4, gen_loss = 0.9768023216916669, disc_loss = 0.0011731693485544578
Trained batch 372 in epoch 4, gen_loss = 0.9767403231868795, disc_loss = 0.0011726288841903115
Trained batch 373 in epoch 4, gen_loss = 0.9766075254124116, disc_loss = 0.001170451998628768
Trained batch 374 in epoch 4, gen_loss = 0.9766541714668274, disc_loss = 0.001171153296289655
Trained batch 375 in epoch 4, gen_loss = 0.9769360998526533, disc_loss = 0.0011711231248401864
Trained batch 376 in epoch 4, gen_loss = 0.9772975832144841, disc_loss = 0.001169770921029914
Trained batch 377 in epoch 4, gen_loss = 0.9772815037341345, disc_loss = 0.0011682217719637612
Trained batch 378 in epoch 4, gen_loss = 0.9772169567978791, disc_loss = 0.0011674611813325489
Trained batch 379 in epoch 4, gen_loss = 0.9771921625262813, disc_loss = 0.001165991188157166
Trained batch 380 in epoch 4, gen_loss = 0.9768211414494853, disc_loss = 0.001165883537277083
Trained batch 381 in epoch 4, gen_loss = 0.9764293887852374, disc_loss = 0.0011657816548761668
Trained batch 382 in epoch 4, gen_loss = 0.9764507868893775, disc_loss = 0.001165903875716432
Trained batch 383 in epoch 4, gen_loss = 0.9761848154788216, disc_loss = 0.0011661039742421053
Trained batch 384 in epoch 4, gen_loss = 0.9762662314749383, disc_loss = 0.0011665535372963128
Trained batch 385 in epoch 4, gen_loss = 0.9763272957480633, disc_loss = 0.0011646189267938314
Trained batch 386 in epoch 4, gen_loss = 0.9764869638191637, disc_loss = 0.0011638531975224928
Trained batch 387 in epoch 4, gen_loss = 0.9762135834730777, disc_loss = 0.0011621569409698235
Trained batch 388 in epoch 4, gen_loss = 0.9762650406452561, disc_loss = 0.0011622012030003486
Trained batch 389 in epoch 4, gen_loss = 0.9764409135549497, disc_loss = 0.0011622138360577923
Trained batch 390 in epoch 4, gen_loss = 0.9765171922381272, disc_loss = 0.0011618726350062782
Trained batch 391 in epoch 4, gen_loss = 0.9765244120237778, disc_loss = 0.001160749292058445
Trained batch 392 in epoch 4, gen_loss = 0.976503825369682, disc_loss = 0.0011595472169204073
Trained batch 393 in epoch 4, gen_loss = 0.9767575499975136, disc_loss = 0.0011580690823458158
Trained batch 394 in epoch 4, gen_loss = 0.9766984068894689, disc_loss = 0.0011572083623717314
Trained batch 395 in epoch 4, gen_loss = 0.9767074431433822, disc_loss = 0.0011556138159343244
Trained batch 396 in epoch 4, gen_loss = 0.9764258561266459, disc_loss = 0.0011537375262664555
Trained batch 397 in epoch 4, gen_loss = 0.9763220319496327, disc_loss = 0.001152304208425901
Trained batch 398 in epoch 4, gen_loss = 0.9763921112344977, disc_loss = 0.0011515350914096348
Trained batch 399 in epoch 4, gen_loss = 0.9763868820667266, disc_loss = 0.0011504846322714002
Trained batch 400 in epoch 4, gen_loss = 0.9761255450379521, disc_loss = 0.0011492640976785355
Trained batch 401 in epoch 4, gen_loss = 0.9761887489266656, disc_loss = 0.0011483185849078949
Trained batch 402 in epoch 4, gen_loss = 0.976554573913366, disc_loss = 0.001146740331547046
Trained batch 403 in epoch 4, gen_loss = 0.9760376299076742, disc_loss = 0.0011464179093885526
Trained batch 404 in epoch 4, gen_loss = 0.9757632841298609, disc_loss = 0.0011458183042661943
Trained batch 405 in epoch 4, gen_loss = 0.9757665146160596, disc_loss = 0.0011443321477622368
Trained batch 406 in epoch 4, gen_loss = 0.9761895547627817, disc_loss = 0.0011430480240352786
Trained batch 407 in epoch 4, gen_loss = 0.9764115109163172, disc_loss = 0.001141084100619956
Trained batch 408 in epoch 4, gen_loss = 0.9763245066687064, disc_loss = 0.001139117044365104
Trained batch 409 in epoch 4, gen_loss = 0.9762948280427514, disc_loss = 0.0011384769668305724
Trained batch 410 in epoch 4, gen_loss = 0.9760731067100581, disc_loss = 0.0011370597413807332
Trained batch 411 in epoch 4, gen_loss = 0.9763003362035289, disc_loss = 0.0011374727962778777
Trained batch 412 in epoch 4, gen_loss = 0.9760306037367111, disc_loss = 0.0011355560965293152
Trained batch 413 in epoch 4, gen_loss = 0.9762840979341147, disc_loss = 0.0011338972708911652
Trained batch 414 in epoch 4, gen_loss = 0.9762354566390256, disc_loss = 0.0011319852057151518
Trained batch 415 in epoch 4, gen_loss = 0.9761993223084853, disc_loss = 0.0011303943150988533
Trained batch 416 in epoch 4, gen_loss = 0.9764642906989411, disc_loss = 0.0011285615751530408
Trained batch 417 in epoch 4, gen_loss = 0.9765995327365455, disc_loss = 0.0011276167816508663
Trained batch 418 in epoch 4, gen_loss = 0.976511354662638, disc_loss = 0.001125709205911148
Trained batch 419 in epoch 4, gen_loss = 0.9766415641421363, disc_loss = 0.001124001731451634
Trained batch 420 in epoch 4, gen_loss = 0.9765011618652706, disc_loss = 0.0011222072539426886
Trained batch 421 in epoch 4, gen_loss = 0.976702328824319, disc_loss = 0.0011204458780101748
Trained batch 422 in epoch 4, gen_loss = 0.9765850488739375, disc_loss = 0.0011193195192309
Trained batch 423 in epoch 4, gen_loss = 0.9765718189894028, disc_loss = 0.001117532142501968
Trained batch 424 in epoch 4, gen_loss = 0.9762070971376756, disc_loss = 0.0011164395616951343
Trained batch 425 in epoch 4, gen_loss = 0.9761942175912185, disc_loss = 0.0011149420401372755
Trained batch 426 in epoch 4, gen_loss = 0.9763861438150429, disc_loss = 0.0011145168597020963
Trained batch 427 in epoch 4, gen_loss = 0.9764159318999709, disc_loss = 0.0011125527412119804
Trained batch 428 in epoch 4, gen_loss = 0.9766058346608302, disc_loss = 0.0011112599538724397
Trained batch 429 in epoch 4, gen_loss = 0.9767316693483397, disc_loss = 0.001109242190939894
Trained batch 430 in epoch 4, gen_loss = 0.9766568169516366, disc_loss = 0.0011079939136420984
Trained batch 431 in epoch 4, gen_loss = 0.9766597372514231, disc_loss = 0.00110671056993144
Trained batch 432 in epoch 4, gen_loss = 0.9767182357867376, disc_loss = 0.0011052039293136758
Trained batch 433 in epoch 4, gen_loss = 0.9767317483502049, disc_loss = 0.0011034739477488037
Trained batch 434 in epoch 4, gen_loss = 0.9765869287238724, disc_loss = 0.001101905629828294
Trained batch 435 in epoch 4, gen_loss = 0.9764226296352684, disc_loss = 0.00110000872966105
Trained batch 436 in epoch 4, gen_loss = 0.9763405329848318, disc_loss = 0.001098162337425815
Trained batch 437 in epoch 4, gen_loss = 0.9763741121716696, disc_loss = 0.001096869872555511
Trained batch 438 in epoch 4, gen_loss = 0.9765196352993437, disc_loss = 0.0010958004641826084
Trained batch 439 in epoch 4, gen_loss = 0.9765850187702613, disc_loss = 0.001093918655797924
Trained batch 440 in epoch 4, gen_loss = 0.9765701716989617, disc_loss = 0.0010921676540768402
Trained batch 441 in epoch 4, gen_loss = 0.9766290615316969, disc_loss = 0.0010909408194484922
Trained batch 442 in epoch 4, gen_loss = 0.9770078544692046, disc_loss = 0.0010904218916388115
Trained batch 443 in epoch 4, gen_loss = 0.9770672075651787, disc_loss = 0.0010888991277792851
Trained batch 444 in epoch 4, gen_loss = 0.9772096605783098, disc_loss = 0.0010872242518365802
Trained batch 445 in epoch 4, gen_loss = 0.9771977963736239, disc_loss = 0.0010857890521759803
Trained batch 446 in epoch 4, gen_loss = 0.9769670736603022, disc_loss = 0.0010842486882766697
Trained batch 447 in epoch 4, gen_loss = 0.9767636568950755, disc_loss = 0.0010826738245798748
Trained batch 448 in epoch 4, gen_loss = 0.9766589065968061, disc_loss = 0.0010810831969656788
Trained batch 449 in epoch 4, gen_loss = 0.9769570877816942, disc_loss = 0.0010797984599937788
Trained batch 450 in epoch 4, gen_loss = 0.9771647392514011, disc_loss = 0.001078395915778866
Trained batch 451 in epoch 4, gen_loss = 0.9770298787450369, disc_loss = 0.001077131979851015
Trained batch 452 in epoch 4, gen_loss = 0.9769004378097736, disc_loss = 0.0010753437445861868
Trained batch 453 in epoch 4, gen_loss = 0.9768140976386973, disc_loss = 0.0010734983074472651
Trained batch 454 in epoch 4, gen_loss = 0.9768140684117328, disc_loss = 0.001071907322249979
Trained batch 455 in epoch 4, gen_loss = 0.9768347933627012, disc_loss = 0.0010707160430396662
Trained batch 456 in epoch 4, gen_loss = 0.9765958290392251, disc_loss = 0.0010700969302393007
Trained batch 457 in epoch 4, gen_loss = 0.9767058561983066, disc_loss = 0.001068812520911726
Trained batch 458 in epoch 4, gen_loss = 0.9768426192352195, disc_loss = 0.001067371545843922
Trained batch 459 in epoch 4, gen_loss = 0.9767241361348525, disc_loss = 0.0010663072923426111
Trained batch 460 in epoch 4, gen_loss = 0.9766207661907998, disc_loss = 0.0010649052472813398
Trained batch 461 in epoch 4, gen_loss = 0.9766278959713973, disc_loss = 0.0010639473897187256
Trained batch 462 in epoch 4, gen_loss = 0.9768893130397178, disc_loss = 0.0010624927318741448
Trained batch 463 in epoch 4, gen_loss = 0.9767599477079408, disc_loss = 0.001061002115201173
Trained batch 464 in epoch 4, gen_loss = 0.9768726329649648, disc_loss = 0.0010593712132083632
Trained batch 465 in epoch 4, gen_loss = 0.9770298680778225, disc_loss = 0.0010583290280404504
Trained batch 466 in epoch 4, gen_loss = 0.9767572092295204, disc_loss = 0.0010569495119292058
Trained batch 467 in epoch 4, gen_loss = 0.9766694512377437, disc_loss = 0.0010551871604019473
Trained batch 468 in epoch 4, gen_loss = 0.9763753783982446, disc_loss = 0.0010537787815054526
Trained batch 469 in epoch 4, gen_loss = 0.9763794839382172, disc_loss = 0.0010524762631517815
Trained batch 470 in epoch 4, gen_loss = 0.976237862985858, disc_loss = 0.001050869911336172
Trained batch 471 in epoch 4, gen_loss = 0.9761848839915405, disc_loss = 0.00104936225212996
Trained batch 472 in epoch 4, gen_loss = 0.9761818494907645, disc_loss = 0.0010480580633126168
Trained batch 473 in epoch 4, gen_loss = 0.9761810207165746, disc_loss = 0.001046282253503202
Trained batch 474 in epoch 4, gen_loss = 0.9763943014646831, disc_loss = 0.0010448795152632028
Trained batch 475 in epoch 4, gen_loss = 0.9765992412547103, disc_loss = 0.0010433277253285558
Trained batch 476 in epoch 4, gen_loss = 0.9764873317952426, disc_loss = 0.0010418535579450865
Trained batch 477 in epoch 4, gen_loss = 0.9764416022031377, disc_loss = 0.0010406395197465087
Trained batch 478 in epoch 4, gen_loss = 0.9766932338911706, disc_loss = 0.001039072282691068
Trained batch 479 in epoch 4, gen_loss = 0.9768054672827323, disc_loss = 0.0010374392334294195
Trained batch 480 in epoch 4, gen_loss = 0.9768012174697527, disc_loss = 0.0010358443924926779
Trained batch 481 in epoch 4, gen_loss = 0.976781338700615, disc_loss = 0.0010343606337901066
Trained batch 482 in epoch 4, gen_loss = 0.9768278745637424, disc_loss = 0.0010338401937458133
Trained batch 483 in epoch 4, gen_loss = 0.976914369986077, disc_loss = 0.0010324195286519787
Trained batch 484 in epoch 4, gen_loss = 0.9767159552918268, disc_loss = 0.0010311386683600542
Trained batch 485 in epoch 4, gen_loss = 0.9767956888234174, disc_loss = 0.0010303009353882782
Trained batch 486 in epoch 4, gen_loss = 0.9768764798890883, disc_loss = 0.0010288831424321865
Trained batch 487 in epoch 4, gen_loss = 0.976887335787054, disc_loss = 0.0010277869176982183
Trained batch 488 in epoch 4, gen_loss = 0.9769986070738248, disc_loss = 0.0010269547117243622
Trained batch 489 in epoch 4, gen_loss = 0.977208678576411, disc_loss = 0.0010256106991377869
Trained batch 490 in epoch 4, gen_loss = 0.9772374920106954, disc_loss = 0.0010241752394020763
Trained batch 491 in epoch 4, gen_loss = 0.9773794513165466, disc_loss = 0.0010227579686164145
Trained batch 492 in epoch 4, gen_loss = 0.9775203755370986, disc_loss = 0.0010212002416296237
Trained batch 493 in epoch 4, gen_loss = 0.9776830097683046, disc_loss = 0.0010195419219473794
Trained batch 494 in epoch 4, gen_loss = 0.9775646833458332, disc_loss = 0.0010179160750468704
Trained batch 495 in epoch 4, gen_loss = 0.9776685949294798, disc_loss = 0.0010166116550951096
Trained batch 496 in epoch 4, gen_loss = 0.9775574238487412, disc_loss = 0.0010152753221816936
Trained batch 497 in epoch 4, gen_loss = 0.977357999747058, disc_loss = 0.001014153798685613
Trained batch 498 in epoch 4, gen_loss = 0.9773587500881814, disc_loss = 0.0010128700327375934
Trained batch 499 in epoch 4, gen_loss = 0.9774752539396286, disc_loss = 0.0010115030473971274
Trained batch 500 in epoch 4, gen_loss = 0.9776309610840803, disc_loss = 0.0010103591862253142
Trained batch 501 in epoch 4, gen_loss = 0.977484639066149, disc_loss = 0.001008857311561483
Trained batch 502 in epoch 4, gen_loss = 0.9775593014171062, disc_loss = 0.0010076080826233803
Trained batch 503 in epoch 4, gen_loss = 0.977673751375978, disc_loss = 0.001006741624858853
Trained batch 504 in epoch 4, gen_loss = 0.9775832835990603, disc_loss = 0.0010052240544141703
Trained batch 505 in epoch 4, gen_loss = 0.9774082763628527, disc_loss = 0.0010037573638580106
Trained batch 506 in epoch 4, gen_loss = 0.9773652604110612, disc_loss = 0.0010023640319006977
Trained batch 507 in epoch 4, gen_loss = 0.9772815561200691, disc_loss = 0.0010008964852927672
Trained batch 508 in epoch 4, gen_loss = 0.9773801771268863, disc_loss = 0.0009994313919853624
Trained batch 509 in epoch 4, gen_loss = 0.977107246950561, disc_loss = 0.0009988372625586777
Trained batch 510 in epoch 4, gen_loss = 0.9772882816142998, disc_loss = 0.0009981782869649997
Trained batch 511 in epoch 4, gen_loss = 0.9772772755241022, disc_loss = 0.000996799110680513
Trained batch 512 in epoch 4, gen_loss = 0.9774128655244035, disc_loss = 0.000995633861124443
Trained batch 513 in epoch 4, gen_loss = 0.9774100988059656, disc_loss = 0.0009947600306767304
Trained batch 514 in epoch 4, gen_loss = 0.9774466365286447, disc_loss = 0.0009941485410926917
Trained batch 515 in epoch 4, gen_loss = 0.9769666444423587, disc_loss = 0.0009994033768966203
Trained batch 516 in epoch 4, gen_loss = 0.9768806924211219, disc_loss = 0.0009987350394300813
Trained batch 517 in epoch 4, gen_loss = 0.9768176656432134, disc_loss = 0.0010000334598185157
Trained batch 518 in epoch 4, gen_loss = 0.9767373745152027, disc_loss = 0.0009991804111806357
Trained batch 519 in epoch 4, gen_loss = 0.976362864100016, disc_loss = 0.0009999255884814864
Trained batch 520 in epoch 4, gen_loss = 0.9763017351705144, disc_loss = 0.000998743828920104
Trained batch 521 in epoch 4, gen_loss = 0.9762666420689945, disc_loss = 0.0009973877741508293
Trained batch 522 in epoch 4, gen_loss = 0.9759929106066834, disc_loss = 0.0009969033976552925
Trained batch 523 in epoch 4, gen_loss = 0.9761630905266027, disc_loss = 0.0009956739798236197
Trained batch 524 in epoch 4, gen_loss = 0.9761590947423663, disc_loss = 0.0009947187222895167
Trained batch 525 in epoch 4, gen_loss = 0.976083644556002, disc_loss = 0.0009932885779853123
Trained batch 526 in epoch 4, gen_loss = 0.976103593660713, disc_loss = 0.0009919358068366713
Trained batch 527 in epoch 4, gen_loss = 0.9759568620586034, disc_loss = 0.0009910952617109147
Trained batch 528 in epoch 4, gen_loss = 0.9758541283174814, disc_loss = 0.0009897946208316678
Trained batch 529 in epoch 4, gen_loss = 0.9756197766313013, disc_loss = 0.00098842674803718
Trained batch 530 in epoch 4, gen_loss = 0.975600750769599, disc_loss = 0.0009872309062581707
Trained batch 531 in epoch 4, gen_loss = 0.9756350629311755, disc_loss = 0.0009866712826170215
Trained batch 532 in epoch 4, gen_loss = 0.9756116808914557, disc_loss = 0.0009856814355087094
Trained batch 533 in epoch 4, gen_loss = 0.9757594037591741, disc_loss = 0.000984390843574617
Trained batch 534 in epoch 4, gen_loss = 0.9755943268258995, disc_loss = 0.0009830859915144464
Trained batch 535 in epoch 4, gen_loss = 0.9758397150617927, disc_loss = 0.0009834867433615292
Trained batch 536 in epoch 4, gen_loss = 0.9757942595073409, disc_loss = 0.0009828616677023804
Trained batch 537 in epoch 4, gen_loss = 0.9758160170790874, disc_loss = 0.000981935681853111
Trained batch 538 in epoch 4, gen_loss = 0.975647671656175, disc_loss = 0.0009806887725072675
Trained batch 539 in epoch 4, gen_loss = 0.9757028236433312, disc_loss = 0.0009794057845418272
Trained batch 540 in epoch 4, gen_loss = 0.9756083603046297, disc_loss = 0.000978149830498397
Trained batch 541 in epoch 4, gen_loss = 0.9755381145600464, disc_loss = 0.0009769592367583453
Trained batch 542 in epoch 4, gen_loss = 0.9753157335091691, disc_loss = 0.0009755128517827966
Trained batch 543 in epoch 4, gen_loss = 0.9751732828205123, disc_loss = 0.0009742740640189475
Trained batch 544 in epoch 4, gen_loss = 0.9752051740611365, disc_loss = 0.0009733333228072664
Trained batch 545 in epoch 4, gen_loss = 0.9748753476273883, disc_loss = 0.000972652598801231
Trained batch 546 in epoch 4, gen_loss = 0.9747784907028924, disc_loss = 0.0009719909579159822
Trained batch 547 in epoch 4, gen_loss = 0.9747964019757988, disc_loss = 0.000970808508000583
Trained batch 548 in epoch 4, gen_loss = 0.9748556822375521, disc_loss = 0.0009700116498757558
Trained batch 549 in epoch 4, gen_loss = 0.9750136345083064, disc_loss = 0.0009689545215753076
Trained batch 550 in epoch 4, gen_loss = 0.9750467953145395, disc_loss = 0.0009680549606366908
Trained batch 551 in epoch 4, gen_loss = 0.9752469424536263, disc_loss = 0.0009669756734934788
Trained batch 552 in epoch 4, gen_loss = 0.9751325497575521, disc_loss = 0.0009659534530172286
Trained batch 553 in epoch 4, gen_loss = 0.9751214947726322, disc_loss = 0.0009651079300098838
Trained batch 554 in epoch 4, gen_loss = 0.9753464669794649, disc_loss = 0.0009639754121323947
Trained batch 555 in epoch 4, gen_loss = 0.9753361752779364, disc_loss = 0.000962730587861901
Trained batch 556 in epoch 4, gen_loss = 0.97506272664404, disc_loss = 0.0009623486208769157
Trained batch 557 in epoch 4, gen_loss = 0.9751163913357642, disc_loss = 0.0009621050923937134
Trained batch 558 in epoch 4, gen_loss = 0.9749940360807988, disc_loss = 0.0009607880857924319
Trained batch 559 in epoch 4, gen_loss = 0.975104579116617, disc_loss = 0.0009597659491191735
Trained batch 560 in epoch 4, gen_loss = 0.9751345960426671, disc_loss = 0.0009586105892053305
Trained batch 561 in epoch 4, gen_loss = 0.974946633776736, disc_loss = 0.0009577261733549508
Trained batch 562 in epoch 4, gen_loss = 0.9748414466901952, disc_loss = 0.000956458951493181
Trained batch 563 in epoch 4, gen_loss = 0.9746715831207046, disc_loss = 0.0009552618867277204
Trained batch 564 in epoch 4, gen_loss = 0.974522243453338, disc_loss = 0.0009543277406951709
Trained batch 565 in epoch 4, gen_loss = 0.9745707392903183, disc_loss = 0.0009543682672398069
Trained batch 566 in epoch 4, gen_loss = 0.9746862529026348, disc_loss = 0.000955104695168419
Trained batch 567 in epoch 4, gen_loss = 0.9746956253345583, disc_loss = 0.0009550796889605305
Trained batch 568 in epoch 4, gen_loss = 0.9744913956192969, disc_loss = 0.0009545678699068702
Trained batch 569 in epoch 4, gen_loss = 0.9744136324054317, disc_loss = 0.0009534701736380444
Trained batch 570 in epoch 4, gen_loss = 0.9744135085004015, disc_loss = 0.0009531234098211398
Trained batch 571 in epoch 4, gen_loss = 0.9744952025113406, disc_loss = 0.0009521538226804582
Trained batch 572 in epoch 4, gen_loss = 0.9743691660970918, disc_loss = 0.000951265351801914
Trained batch 573 in epoch 4, gen_loss = 0.9745325416015, disc_loss = 0.0009502917882823709
Trained batch 574 in epoch 4, gen_loss = 0.9743765597758086, disc_loss = 0.0009495002601002141
Trained batch 575 in epoch 4, gen_loss = 0.974237080766923, disc_loss = 0.0009485852102291877
Trained batch 576 in epoch 4, gen_loss = 0.9744357423311296, disc_loss = 0.0009476196197532618
Trained batch 577 in epoch 4, gen_loss = 0.9744063858136174, disc_loss = 0.0009466098249331197
Trained batch 578 in epoch 4, gen_loss = 0.974167802276183, disc_loss = 0.0009455370804665301
Trained batch 579 in epoch 4, gen_loss = 0.9742101390813959, disc_loss = 0.0009446275496006349
Trained batch 580 in epoch 4, gen_loss = 0.9742344105920775, disc_loss = 0.0009435638903831364
Trained batch 581 in epoch 4, gen_loss = 0.9742107490698496, disc_loss = 0.0009424303604249484
Trained batch 582 in epoch 4, gen_loss = 0.9742614471482985, disc_loss = 0.0009421560819023952
Trained batch 583 in epoch 4, gen_loss = 0.9739664030605799, disc_loss = 0.0009410884919803994
Trained batch 584 in epoch 4, gen_loss = 0.9738191507820391, disc_loss = 0.0009399266013801974
Trained batch 585 in epoch 4, gen_loss = 0.9736514035548773, disc_loss = 0.0009388682559268063
Trained batch 586 in epoch 4, gen_loss = 0.9735207225638719, disc_loss = 0.0009379325637300745
Trained batch 587 in epoch 4, gen_loss = 0.9738269380363477, disc_loss = 0.0009370259411261198
Trained batch 588 in epoch 4, gen_loss = 0.973890639828907, disc_loss = 0.0009359241004846279
Trained batch 589 in epoch 4, gen_loss = 0.9736986306764311, disc_loss = 0.0009352314561927075
Trained batch 590 in epoch 4, gen_loss = 0.9735440248765316, disc_loss = 0.0009342425277737535
Trained batch 591 in epoch 4, gen_loss = 0.9736767247117855, disc_loss = 0.0009331426303155289
Trained batch 592 in epoch 4, gen_loss = 0.9734753144129131, disc_loss = 0.0009328920785979639
Trained batch 593 in epoch 4, gen_loss = 0.9735878122976733, disc_loss = 0.0009326191697383742
Trained batch 594 in epoch 4, gen_loss = 0.9735532062394279, disc_loss = 0.0009320207328306699
Trained batch 595 in epoch 4, gen_loss = 0.9736572477041475, disc_loss = 0.000931297159133965
Trained batch 596 in epoch 4, gen_loss = 0.9734045551649889, disc_loss = 0.0009312036659923839
Trained batch 597 in epoch 4, gen_loss = 0.9731906968414983, disc_loss = 0.0009302718447430611
Trained batch 598 in epoch 4, gen_loss = 0.9731961600171505, disc_loss = 0.0009290941624125957
Trained batch 599 in epoch 4, gen_loss = 0.9730603258808453, disc_loss = 0.0009285383658667949
Trained batch 600 in epoch 4, gen_loss = 0.9730135237119361, disc_loss = 0.000927721172761592
Trained batch 601 in epoch 4, gen_loss = 0.973224569099686, disc_loss = 0.0009268513859446514
Trained batch 602 in epoch 4, gen_loss = 0.9730265092098496, disc_loss = 0.0009265773998240201
Trained batch 603 in epoch 4, gen_loss = 0.9728591573356793, disc_loss = 0.0009258203165320794
Trained batch 604 in epoch 4, gen_loss = 0.9727894245100416, disc_loss = 0.0009252366390750812
Trained batch 605 in epoch 4, gen_loss = 0.9727079367676977, disc_loss = 0.0009241076944391674
Trained batch 606 in epoch 4, gen_loss = 0.9726351885465656, disc_loss = 0.0009231405081490171
Trained batch 607 in epoch 4, gen_loss = 0.9727235039401996, disc_loss = 0.0009221243483711748
Trained batch 608 in epoch 4, gen_loss = 0.9725563114108319, disc_loss = 0.0009209711351416613
Trained batch 609 in epoch 4, gen_loss = 0.9726468186886584, disc_loss = 0.0009198841247631267
Trained batch 610 in epoch 4, gen_loss = 0.9725393386597329, disc_loss = 0.000918762079006977
Trained batch 611 in epoch 4, gen_loss = 0.9723937770510032, disc_loss = 0.0009177847957461874
Trained batch 612 in epoch 4, gen_loss = 0.9724282465790068, disc_loss = 0.0009167692950441689
Trained batch 613 in epoch 4, gen_loss = 0.9722461609188042, disc_loss = 0.0009157752385884387
Trained batch 614 in epoch 4, gen_loss = 0.9721788576947964, disc_loss = 0.000914803746074052
Trained batch 615 in epoch 4, gen_loss = 0.9722990598771479, disc_loss = 0.0009137085868699957
Trained batch 616 in epoch 4, gen_loss = 0.9721957137944053, disc_loss = 0.0009125175037882796
Trained batch 617 in epoch 4, gen_loss = 0.9723813039971015, disc_loss = 0.0009117926804875898
Trained batch 618 in epoch 4, gen_loss = 0.9722930501081254, disc_loss = 0.0009107698110879741
Trained batch 619 in epoch 4, gen_loss = 0.9722219528690461, disc_loss = 0.0009097874814019193
Trained batch 620 in epoch 4, gen_loss = 0.972226839998494, disc_loss = 0.0009091552281097978
Trained batch 621 in epoch 4, gen_loss = 0.9722099603180717, disc_loss = 0.0009084057185315628
Trained batch 622 in epoch 4, gen_loss = 0.9721048961290387, disc_loss = 0.0009081674631384917
Trained batch 623 in epoch 4, gen_loss = 0.972103642920653, disc_loss = 0.0009072233282821776
Trained batch 624 in epoch 4, gen_loss = 0.9721128577232361, disc_loss = 0.0009064148054225371
Trained batch 625 in epoch 4, gen_loss = 0.9721844934236509, disc_loss = 0.000905413039138551
Trained batch 626 in epoch 4, gen_loss = 0.972133898754059, disc_loss = 0.0009045031569362284
Trained batch 627 in epoch 4, gen_loss = 0.9722330231385626, disc_loss = 0.0009035223484038194
Trained batch 628 in epoch 4, gen_loss = 0.9720317465512286, disc_loss = 0.0009027893124238939
Trained batch 629 in epoch 4, gen_loss = 0.9721418510353754, disc_loss = 0.0009018333691831989
Trained batch 630 in epoch 4, gen_loss = 0.9722073468277836, disc_loss = 0.000901135155808796
Trained batch 631 in epoch 4, gen_loss = 0.9721873292251478, disc_loss = 0.0009002583750471682
Trained batch 632 in epoch 4, gen_loss = 0.9720446198095831, disc_loss = 0.0008991051805369324
Trained batch 633 in epoch 4, gen_loss = 0.971967820019376, disc_loss = 0.0008980019681566257
Trained batch 634 in epoch 4, gen_loss = 0.9716622258734515, disc_loss = 0.0008980113346089324
Trained batch 635 in epoch 4, gen_loss = 0.9717166967361978, disc_loss = 0.0008975440636185678
Trained batch 636 in epoch 4, gen_loss = 0.9714080388167964, disc_loss = 0.0008981446660174206
Trained batch 637 in epoch 4, gen_loss = 0.9714405894466328, disc_loss = 0.0008977468537081319
Trained batch 638 in epoch 4, gen_loss = 0.9712796230831057, disc_loss = 0.0008974334837468735
Trained batch 639 in epoch 4, gen_loss = 0.971359680686146, disc_loss = 0.0008964450686107739
Trained batch 640 in epoch 4, gen_loss = 0.9712705747013717, disc_loss = 0.0008957806674348752
Trained batch 641 in epoch 4, gen_loss = 0.9712901404156492, disc_loss = 0.0008950543416173682
Trained batch 642 in epoch 4, gen_loss = 0.9712243844895488, disc_loss = 0.0008946042343131144
Trained batch 643 in epoch 4, gen_loss = 0.9712690130709121, disc_loss = 0.0008936818284727343
Trained batch 644 in epoch 4, gen_loss = 0.9711206707843515, disc_loss = 0.0008927162212334111
Trained batch 645 in epoch 4, gen_loss = 0.97106407762681, disc_loss = 0.0008916800101298475
Trained batch 646 in epoch 4, gen_loss = 0.9708779427515115, disc_loss = 0.0008908022628104605
Trained batch 647 in epoch 4, gen_loss = 0.9706688183877203, disc_loss = 0.0008899077016664065
Trained batch 648 in epoch 4, gen_loss = 0.9707426483899309, disc_loss = 0.0008890563249462449
Trained batch 649 in epoch 4, gen_loss = 0.9705359089374542, disc_loss = 0.0008884020876408054
Trained batch 650 in epoch 4, gen_loss = 0.9705637450774877, disc_loss = 0.0008875114937400883
Trained batch 651 in epoch 4, gen_loss = 0.9703915914509194, disc_loss = 0.0008863910594199816
Trained batch 652 in epoch 4, gen_loss = 0.9702510357268189, disc_loss = 0.0008853511011871904
Trained batch 653 in epoch 4, gen_loss = 0.9702848338205879, disc_loss = 0.0008844615462494569
Trained batch 654 in epoch 4, gen_loss = 0.9702872609364167, disc_loss = 0.0008835755436563907
Trained batch 655 in epoch 4, gen_loss = 0.9702655874737879, disc_loss = 0.0008828392137507851
Trained batch 656 in epoch 4, gen_loss = 0.9703205283192557, disc_loss = 0.0008818101904188783
Trained batch 657 in epoch 4, gen_loss = 0.9703118643499797, disc_loss = 0.0008809346331969558
Trained batch 658 in epoch 4, gen_loss = 0.9700901530038605, disc_loss = 0.0008812943754648105
Trained batch 659 in epoch 4, gen_loss = 0.9698012293288202, disc_loss = 0.0008806151533490541
Trained batch 660 in epoch 4, gen_loss = 0.9697132100676624, disc_loss = 0.0008799904035117249
Trained batch 661 in epoch 4, gen_loss = 0.9696506196098386, disc_loss = 0.0008792422698528275
Trained batch 662 in epoch 4, gen_loss = 0.9694844489723309, disc_loss = 0.0008789188075829283
Trained batch 663 in epoch 4, gen_loss = 0.9695446243487209, disc_loss = 0.0008780591426592907
Trained batch 664 in epoch 4, gen_loss = 0.9693227228365446, disc_loss = 0.0008776426946620029
Trained batch 665 in epoch 4, gen_loss = 0.9690871063295428, disc_loss = 0.0008767395427874597
Trained batch 666 in epoch 4, gen_loss = 0.9690014051533175, disc_loss = 0.0008760890427977196
Trained batch 667 in epoch 4, gen_loss = 0.9686692094731474, disc_loss = 0.000875216180089726
Trained batch 668 in epoch 4, gen_loss = 0.9687928488792682, disc_loss = 0.000874346487074624
Trained batch 669 in epoch 4, gen_loss = 0.9687442512654546, disc_loss = 0.0008741548560505886
Trained batch 670 in epoch 4, gen_loss = 0.9687665293184726, disc_loss = 0.0008731499097569209
Trained batch 671 in epoch 4, gen_loss = 0.9684419827979236, disc_loss = 0.0008722403616784071
Trained batch 672 in epoch 4, gen_loss = 0.9685183929121689, disc_loss = 0.0008713526309066193
Trained batch 673 in epoch 4, gen_loss = 0.968354789191962, disc_loss = 0.0008704455182098269
Trained batch 674 in epoch 4, gen_loss = 0.9686635700861613, disc_loss = 0.0008703512961208751
Trained batch 675 in epoch 4, gen_loss = 0.9685342033233868, disc_loss = 0.0008694081041636773
Trained batch 676 in epoch 4, gen_loss = 0.9684486848741022, disc_loss = 0.0008684805478055327
Trained batch 677 in epoch 4, gen_loss = 0.968323097116476, disc_loss = 0.0008679969617180048
Trained batch 678 in epoch 4, gen_loss = 0.9682744457022958, disc_loss = 0.0008677383691476402
Trained batch 679 in epoch 4, gen_loss = 0.9682514013612972, disc_loss = 0.0008669089737368802
Trained batch 680 in epoch 4, gen_loss = 0.9683444491216965, disc_loss = 0.0008658775800761114
Trained batch 681 in epoch 4, gen_loss = 0.9682026435552804, disc_loss = 0.0008651709539185571
Trained batch 682 in epoch 4, gen_loss = 0.9680760416419055, disc_loss = 0.0008644149081776735
Trained batch 683 in epoch 4, gen_loss = 0.9682215321482274, disc_loss = 0.0008633953285100938
Trained batch 684 in epoch 4, gen_loss = 0.9682480194272786, disc_loss = 0.0008625495686649555
Trained batch 685 in epoch 4, gen_loss = 0.9682626927559299, disc_loss = 0.0008614976101399823
Trained batch 686 in epoch 4, gen_loss = 0.9681929845303253, disc_loss = 0.0008605306759367194
Trained batch 687 in epoch 4, gen_loss = 0.9681844769348932, disc_loss = 0.0008596687934567494
Trained batch 688 in epoch 4, gen_loss = 0.9682549529740011, disc_loss = 0.000858910915990771
Trained batch 689 in epoch 4, gen_loss = 0.9681976952414582, disc_loss = 0.0008581606633041688
Trained batch 690 in epoch 4, gen_loss = 0.9682486172867926, disc_loss = 0.0008571688131492938
Trained batch 691 in epoch 4, gen_loss = 0.9681204891618277, disc_loss = 0.0008562041627498199
Trained batch 692 in epoch 4, gen_loss = 0.9681671314253264, disc_loss = 0.0008553053461291396
Trained batch 693 in epoch 4, gen_loss = 0.968210630956232, disc_loss = 0.0008543704352318108
Trained batch 694 in epoch 4, gen_loss = 0.9681682583239438, disc_loss = 0.0008536489946322127
Trained batch 695 in epoch 4, gen_loss = 0.9681027091440113, disc_loss = 0.0008529271807433935
Trained batch 696 in epoch 4, gen_loss = 0.9681609147248343, disc_loss = 0.0008519921290879959
Trained batch 697 in epoch 4, gen_loss = 0.9681874899604601, disc_loss = 0.0008510474186618466
Trained batch 698 in epoch 4, gen_loss = 0.9680456247111418, disc_loss = 0.0008502240082339313
Trained batch 699 in epoch 4, gen_loss = 0.9678507045337132, disc_loss = 0.0008493020423546633
Trained batch 700 in epoch 4, gen_loss = 0.9677610262994589, disc_loss = 0.000848472341306384
Trained batch 701 in epoch 4, gen_loss = 0.9675810416879138, disc_loss = 0.0008476732741798237
Trained batch 702 in epoch 4, gen_loss = 0.9675821906981055, disc_loss = 0.0008468837695649016
Trained batch 703 in epoch 4, gen_loss = 0.9673903529447588, disc_loss = 0.000846190181432989
Trained batch 704 in epoch 4, gen_loss = 0.9672884568254998, disc_loss = 0.0008453457710186204
Trained batch 705 in epoch 4, gen_loss = 0.9672158753905689, disc_loss = 0.0008445124312496227
Trained batch 706 in epoch 4, gen_loss = 0.9671536959718275, disc_loss = 0.000843822639833186
Trained batch 707 in epoch 4, gen_loss = 0.9668443641588513, disc_loss = 0.0008453610929287904
Trained batch 708 in epoch 4, gen_loss = 0.9668750244236127, disc_loss = 0.0008456626487592083
Trained batch 709 in epoch 4, gen_loss = 0.9668164043359353, disc_loss = 0.0008448612340275054
Trained batch 710 in epoch 4, gen_loss = 0.9667802831962307, disc_loss = 0.0008441913557481532
Trained batch 711 in epoch 4, gen_loss = 0.9667229822344994, disc_loss = 0.0008433637056727645
Trained batch 712 in epoch 4, gen_loss = 0.9667209299048736, disc_loss = 0.0008426928584508632
Trained batch 713 in epoch 4, gen_loss = 0.9666737926607373, disc_loss = 0.0008419389160131809
Trained batch 714 in epoch 4, gen_loss = 0.9667278824152646, disc_loss = 0.0008412901191423497
Trained batch 715 in epoch 4, gen_loss = 0.9666804181796879, disc_loss = 0.0008405870136695292
Trained batch 716 in epoch 4, gen_loss = 0.9665641657478141, disc_loss = 0.000839691992121394
Trained batch 717 in epoch 4, gen_loss = 0.9665480551613407, disc_loss = 0.0008388591558487001
Trained batch 718 in epoch 4, gen_loss = 0.9665935341273959, disc_loss = 0.0008379170634351174
Trained batch 719 in epoch 4, gen_loss = 0.9663660865690973, disc_loss = 0.0008376973297142993
Trained batch 720 in epoch 4, gen_loss = 0.9662813348346875, disc_loss = 0.0008370243034702719
Trained batch 721 in epoch 4, gen_loss = 0.9663320216775931, disc_loss = 0.0008364645835580407
Trained batch 722 in epoch 4, gen_loss = 0.9663219014144042, disc_loss = 0.0008357005851745172
Trained batch 723 in epoch 4, gen_loss = 0.9661505605140444, disc_loss = 0.0008366601527166857
Trained batch 724 in epoch 4, gen_loss = 0.9661237270256569, disc_loss = 0.0008361995257116084
Trained batch 725 in epoch 4, gen_loss = 0.9662487190781217, disc_loss = 0.0008363379534339076
Trained batch 726 in epoch 4, gen_loss = 0.9663173879357119, disc_loss = 0.0008359120846783648
Trained batch 727 in epoch 4, gen_loss = 0.9662215512368705, disc_loss = 0.0008360339122521179
Trained batch 728 in epoch 4, gen_loss = 0.9660746206635474, disc_loss = 0.0008383848402101102
Trained batch 729 in epoch 4, gen_loss = 0.966329833987641, disc_loss = 0.0008396766756897257
Trained batch 730 in epoch 4, gen_loss = 0.9664409445183385, disc_loss = 0.0008400269313753619
Trained batch 731 in epoch 4, gen_loss = 0.9665789197865731, disc_loss = 0.000841588792985921
Trained batch 732 in epoch 4, gen_loss = 0.96672589123493, disc_loss = 0.0008418425066507133
Trained batch 733 in epoch 4, gen_loss = 0.9666293133506982, disc_loss = 0.0008418059235214122
Trained batch 734 in epoch 4, gen_loss = 0.9666669753133034, disc_loss = 0.0008413225596099078
Trained batch 735 in epoch 4, gen_loss = 0.9664355490518652, disc_loss = 0.0008413204606926149
Trained batch 736 in epoch 4, gen_loss = 0.9665651923118809, disc_loss = 0.0008409840941430402
Trained batch 737 in epoch 4, gen_loss = 0.9664641219749037, disc_loss = 0.0008404914027147454
Trained batch 738 in epoch 4, gen_loss = 0.9664048187142296, disc_loss = 0.0008398000538366165
Trained batch 739 in epoch 4, gen_loss = 0.9664557471468642, disc_loss = 0.0008401921578616886
Trained batch 740 in epoch 4, gen_loss = 0.9666179740316311, disc_loss = 0.0008420911362673082
Trained batch 741 in epoch 4, gen_loss = 0.9668584743921326, disc_loss = 0.0008443489160769647
Trained batch 742 in epoch 4, gen_loss = 0.9669018338859322, disc_loss = 0.0008444420426998107
Trained batch 743 in epoch 4, gen_loss = 0.9667673252763287, disc_loss = 0.0008501630136477185
Trained batch 744 in epoch 4, gen_loss = 0.9668194829217539, disc_loss = 0.0008520042929632726
Trained batch 745 in epoch 4, gen_loss = 0.9666134584844911, disc_loss = 0.0008543131254028514
Trained batch 746 in epoch 4, gen_loss = 0.9665840997434205, disc_loss = 0.000854103796804633
Trained batch 747 in epoch 4, gen_loss = 0.9665210065357188, disc_loss = 0.0008536928511466855
Trained batch 748 in epoch 4, gen_loss = 0.9664550991020152, disc_loss = 0.0008532349898797573
Trained batch 749 in epoch 4, gen_loss = 0.9664753735860189, disc_loss = 0.000853466032887809
Trained batch 750 in epoch 4, gen_loss = 0.9665000247415626, disc_loss = 0.0008558285038266579
Trained batch 751 in epoch 4, gen_loss = 0.9665444306236632, disc_loss = 0.0008608912465864163
Trained batch 752 in epoch 4, gen_loss = 0.966719980733803, disc_loss = 0.0008659342124611065
Trained batch 753 in epoch 4, gen_loss = 0.966743143942375, disc_loss = 0.0008673733968392078
Trained batch 754 in epoch 4, gen_loss = 0.9668041004250382, disc_loss = 0.0008680918994467606
Trained batch 755 in epoch 4, gen_loss = 0.9668618718940745, disc_loss = 0.0008690941436465696
Trained batch 756 in epoch 4, gen_loss = 0.9670207997294367, disc_loss = 0.0008690720815823599
Trained batch 757 in epoch 4, gen_loss = 0.9670481401886348, disc_loss = 0.0008685922312429224
Trained batch 758 in epoch 4, gen_loss = 0.9669766645971808, disc_loss = 0.0008684592591080205
Trained batch 759 in epoch 4, gen_loss = 0.9668585165550835, disc_loss = 0.0008925455266618978
Trained batch 760 in epoch 4, gen_loss = 0.9668380628277532, disc_loss = 0.0008978049733028006
Trained batch 761 in epoch 4, gen_loss = 0.9667648547903447, disc_loss = 0.0009003526077338732
Trained batch 762 in epoch 4, gen_loss = 0.966717391620301, disc_loss = 0.000899765348085721
Trained batch 763 in epoch 4, gen_loss = 0.9666624545114827, disc_loss = 0.0008994006807489214
Trained batch 764 in epoch 4, gen_loss = 0.9666596639390085, disc_loss = 0.0008989157486901759
Trained batch 765 in epoch 4, gen_loss = 0.9666811041825745, disc_loss = 0.0008985773166617277
Trained batch 766 in epoch 4, gen_loss = 0.9666285854430366, disc_loss = 0.0008978898828391427
Trained batch 767 in epoch 4, gen_loss = 0.9664429113424072, disc_loss = 0.0008974180094204106
Trained batch 768 in epoch 4, gen_loss = 0.9665322490569364, disc_loss = 0.0008968490091732598
Trained batch 769 in epoch 4, gen_loss = 0.9664791535247456, disc_loss = 0.0008965096849186177
Trained batch 770 in epoch 4, gen_loss = 0.9663666305065773, disc_loss = 0.0008960711446937401
Trained batch 771 in epoch 4, gen_loss = 0.9662479402333344, disc_loss = 0.0008956468471089485
Trained batch 772 in epoch 4, gen_loss = 0.9663709365843492, disc_loss = 0.0008951226382770541
Trained batch 773 in epoch 4, gen_loss = 0.9664166955522788, disc_loss = 0.0008944335769776505
Trained batch 774 in epoch 4, gen_loss = 0.9663212655436608, disc_loss = 0.0008937092343976181
Trained batch 775 in epoch 4, gen_loss = 0.9663204883330876, disc_loss = 0.0008931053920811613
Trained batch 776 in epoch 4, gen_loss = 0.9662619961888327, disc_loss = 0.0008926295141280153
Trained batch 777 in epoch 4, gen_loss = 0.9662372824618627, disc_loss = 0.000891777997845299
Trained batch 778 in epoch 4, gen_loss = 0.9660783390178607, disc_loss = 0.0008910792910283795
Trained batch 779 in epoch 4, gen_loss = 0.9660599383788231, disc_loss = 0.0008903097040251268
Trained batch 780 in epoch 4, gen_loss = 0.965946939171658, disc_loss = 0.0008894441377731677
Trained batch 781 in epoch 4, gen_loss = 0.9659101998866977, disc_loss = 0.0008887311781916168
Trained batch 782 in epoch 4, gen_loss = 0.9656546916693716, disc_loss = 0.0008880480500440664
Trained batch 783 in epoch 4, gen_loss = 0.9654504836974095, disc_loss = 0.0008873478126755503
Trained batch 784 in epoch 4, gen_loss = 0.9654112146918181, disc_loss = 0.0008864984447195842
Trained batch 785 in epoch 4, gen_loss = 0.9652881671605826, disc_loss = 0.000886006008921921
Trained batch 786 in epoch 4, gen_loss = 0.9651742326107534, disc_loss = 0.0008854100722455676
Trained batch 787 in epoch 4, gen_loss = 0.9650897991838794, disc_loss = 0.0008847962364718096
Trained batch 788 in epoch 4, gen_loss = 0.964924994077066, disc_loss = 0.0008842399527471635
Trained batch 789 in epoch 4, gen_loss = 0.9648200118089024, disc_loss = 0.0008835845488371162
Trained batch 790 in epoch 4, gen_loss = 0.9648319092472043, disc_loss = 0.00088288447625085
Trained batch 791 in epoch 4, gen_loss = 0.9649715736658886, disc_loss = 0.0008824397829647006
Trained batch 792 in epoch 4, gen_loss = 0.9649700689285731, disc_loss = 0.0008818396628957035
Trained batch 793 in epoch 4, gen_loss = 0.9649060681574891, disc_loss = 0.0008818647512736184
Trained batch 794 in epoch 4, gen_loss = 0.9650448792385605, disc_loss = 0.000881202899339849
Trained batch 795 in epoch 4, gen_loss = 0.9648099286322618, disc_loss = 0.000880777981328537
Trained batch 796 in epoch 4, gen_loss = 0.9648986590402189, disc_loss = 0.0008802150033687217
Trained batch 797 in epoch 4, gen_loss = 0.9648165847723347, disc_loss = 0.0008794752017517263
Trained batch 798 in epoch 4, gen_loss = 0.9648941712027348, disc_loss = 0.0008788237195795353
Trained batch 799 in epoch 4, gen_loss = 0.9648651951551437, disc_loss = 0.0008782589951442788
Trained batch 800 in epoch 4, gen_loss = 0.9649155509010534, disc_loss = 0.0008776414047661569
Trained batch 801 in epoch 4, gen_loss = 0.9648280372643411, disc_loss = 0.0008768287866258473
Trained batch 802 in epoch 4, gen_loss = 0.9648822508891522, disc_loss = 0.0008761147670328947
Trained batch 803 in epoch 4, gen_loss = 0.9649272325323589, disc_loss = 0.0008753362494802904
Trained batch 804 in epoch 4, gen_loss = 0.9647750762678822, disc_loss = 0.000874693593139014
Trained batch 805 in epoch 4, gen_loss = 0.9645520467172486, disc_loss = 0.0008743568508791629
Trained batch 806 in epoch 4, gen_loss = 0.9643667217671797, disc_loss = 0.0008736411608334935
Trained batch 807 in epoch 4, gen_loss = 0.9644078415366683, disc_loss = 0.0008729515821410177
Trained batch 808 in epoch 4, gen_loss = 0.9644689264491992, disc_loss = 0.0008725478774056354
Trained batch 809 in epoch 4, gen_loss = 0.9642961739757915, disc_loss = 0.0008718941896797422
Trained batch 810 in epoch 4, gen_loss = 0.9644538701389045, disc_loss = 0.0008711252365411751
Trained batch 811 in epoch 4, gen_loss = 0.9645276839656783, disc_loss = 0.0008705717690972603
Trained batch 812 in epoch 4, gen_loss = 0.9646298126540941, disc_loss = 0.0008699422905741084
Trained batch 813 in epoch 4, gen_loss = 0.964537479514279, disc_loss = 0.0008692006697518985
Trained batch 814 in epoch 4, gen_loss = 0.9645211292922131, disc_loss = 0.0008686265046851127
Trained batch 815 in epoch 4, gen_loss = 0.9645644862423924, disc_loss = 0.0008679699954775381
Trained batch 816 in epoch 4, gen_loss = 0.9645052231218999, disc_loss = 0.0008671491703524675
Trained batch 817 in epoch 4, gen_loss = 0.9644272782837557, disc_loss = 0.0008662505546440416
Trained batch 818 in epoch 4, gen_loss = 0.9643437279449715, disc_loss = 0.0008655125780751183
Trained batch 819 in epoch 4, gen_loss = 0.9643558183821236, disc_loss = 0.0008646664052432199
Trained batch 820 in epoch 4, gen_loss = 0.9644138100086264, disc_loss = 0.0008639674242027218
Trained batch 821 in epoch 4, gen_loss = 0.9643335944254613, disc_loss = 0.0008632236558231899
Trained batch 822 in epoch 4, gen_loss = 0.9643057875181317, disc_loss = 0.0008624321118217552
Trained batch 823 in epoch 4, gen_loss = 0.9643009190709846, disc_loss = 0.0008616326930792833
Trained batch 824 in epoch 4, gen_loss = 0.9642839041623202, disc_loss = 0.0008608938278242325
Trained batch 825 in epoch 4, gen_loss = 0.964263006647909, disc_loss = 0.0008604365866807443
Trained batch 826 in epoch 4, gen_loss = 0.9642960842171776, disc_loss = 0.0008598940150198238
Trained batch 827 in epoch 4, gen_loss = 0.964225155863785, disc_loss = 0.0008591164169838125
Trained batch 828 in epoch 4, gen_loss = 0.9641872640829466, disc_loss = 0.0008582866987490418
Trained batch 829 in epoch 4, gen_loss = 0.9642934774059847, disc_loss = 0.0008575484443439104
Trained batch 830 in epoch 4, gen_loss = 0.9643756764460126, disc_loss = 0.0008567327720846613
Trained batch 831 in epoch 4, gen_loss = 0.9643625973079067, disc_loss = 0.000855992453545276
Trained batch 832 in epoch 4, gen_loss = 0.9643132376785324, disc_loss = 0.0008552463073500053
Trained batch 833 in epoch 4, gen_loss = 0.9643597726484568, disc_loss = 0.000854575306068122
Trained batch 834 in epoch 4, gen_loss = 0.9644224386015338, disc_loss = 0.0008538939036647817
Trained batch 835 in epoch 4, gen_loss = 0.9643908567263179, disc_loss = 0.0008530196464040125
Trained batch 836 in epoch 4, gen_loss = 0.9643707108753984, disc_loss = 0.0008521728703221963
Trained batch 837 in epoch 4, gen_loss = 0.9642233002868643, disc_loss = 0.0008513871824514979
Trained batch 838 in epoch 4, gen_loss = 0.9641913959891918, disc_loss = 0.0008505598851590594
Trained batch 839 in epoch 4, gen_loss = 0.9642100383128439, disc_loss = 0.0008497859513140394
Trained batch 840 in epoch 4, gen_loss = 0.9641647217673439, disc_loss = 0.0008490466814575103
Trained batch 841 in epoch 4, gen_loss = 0.9642206826147728, disc_loss = 0.0008485446077582898
Trained batch 842 in epoch 4, gen_loss = 0.9640950399361471, disc_loss = 0.0008478776339045477
Trained batch 843 in epoch 4, gen_loss = 0.96399709066791, disc_loss = 0.0008470115893278618
Trained batch 844 in epoch 4, gen_loss = 0.9639287378661026, disc_loss = 0.0008463987468837584
Trained batch 845 in epoch 4, gen_loss = 0.9639176166931225, disc_loss = 0.0008456364668732763
Trained batch 846 in epoch 4, gen_loss = 0.9637879910125642, disc_loss = 0.0008450505262665608
Trained batch 847 in epoch 4, gen_loss = 0.9637904950892026, disc_loss = 0.0008442827583819036
Trained batch 848 in epoch 4, gen_loss = 0.9638319528706644, disc_loss = 0.0008435339697977957
Trained batch 849 in epoch 4, gen_loss = 0.9637042936858009, disc_loss = 0.0008427588204829269
Trained batch 850 in epoch 4, gen_loss = 0.9636119601309089, disc_loss = 0.0008419700204406386
Trained batch 851 in epoch 4, gen_loss = 0.963502706286493, disc_loss = 0.0008412013939618567
Trained batch 852 in epoch 4, gen_loss = 0.9635910404385324, disc_loss = 0.0008406255891834438
Trained batch 853 in epoch 4, gen_loss = 0.9635028213053174, disc_loss = 0.0008398728577383446
Trained batch 854 in epoch 4, gen_loss = 0.9632970127445912, disc_loss = 0.0008392832889640295
Trained batch 855 in epoch 4, gen_loss = 0.9631036995588061, disc_loss = 0.0008384763449501866
Trained batch 856 in epoch 4, gen_loss = 0.9631368555432858, disc_loss = 0.0008377979081787649
Trained batch 857 in epoch 4, gen_loss = 0.9630636847241497, disc_loss = 0.0008371573711351555
Trained batch 858 in epoch 4, gen_loss = 0.9630701609207393, disc_loss = 0.0008365330863403177
Trained batch 859 in epoch 4, gen_loss = 0.9630653379268425, disc_loss = 0.0008358165665836274
Trained batch 860 in epoch 4, gen_loss = 0.9629731525804385, disc_loss = 0.0008350518827546852
Trained batch 861 in epoch 4, gen_loss = 0.9630476727286513, disc_loss = 0.000834326042247471
Trained batch 862 in epoch 4, gen_loss = 0.9628427333931243, disc_loss = 0.0008336992413630447
Trained batch 863 in epoch 4, gen_loss = 0.9627880816934286, disc_loss = 0.0008329335949434204
Trained batch 864 in epoch 4, gen_loss = 0.9627401620666416, disc_loss = 0.0008323327136798654
Trained batch 865 in epoch 4, gen_loss = 0.962583861780497, disc_loss = 0.0008316888090990796
Trained batch 866 in epoch 4, gen_loss = 0.9625357213454813, disc_loss = 0.0008311194134725074
Trained batch 867 in epoch 4, gen_loss = 0.962377345575715, disc_loss = 0.000830354448808569
Trained batch 868 in epoch 4, gen_loss = 0.9622718183574522, disc_loss = 0.0008295991875248548
Trained batch 869 in epoch 4, gen_loss = 0.962121001742352, disc_loss = 0.0008290891063311966
Trained batch 870 in epoch 4, gen_loss = 0.9621039438740394, disc_loss = 0.0008284667605536468
Trained batch 871 in epoch 4, gen_loss = 0.9620763060696628, disc_loss = 0.0008277189847355716
Trained batch 872 in epoch 4, gen_loss = 0.9620653022195875, disc_loss = 0.0008269935400653412
Trained batch 873 in epoch 4, gen_loss = 0.9620981099130905, disc_loss = 0.0008264312677247768
Trained batch 874 in epoch 4, gen_loss = 0.9620057899611337, disc_loss = 0.0008256307049305179
Trained batch 875 in epoch 4, gen_loss = 0.9620173356440513, disc_loss = 0.0008248739256184005
Trained batch 876 in epoch 4, gen_loss = 0.9620175849616596, disc_loss = 0.0008241410590016003
Trained batch 877 in epoch 4, gen_loss = 0.9619271901854078, disc_loss = 0.0008233444506607039
Trained batch 878 in epoch 4, gen_loss = 0.9618564543056813, disc_loss = 0.0008226886157434994
Trained batch 879 in epoch 4, gen_loss = 0.9617280453443527, disc_loss = 0.0008220002274191013
Trained batch 880 in epoch 4, gen_loss = 0.9616979174527354, disc_loss = 0.000821325693333484
Trained batch 881 in epoch 4, gen_loss = 0.9615898515496936, disc_loss = 0.0008206362251593978
Trained batch 882 in epoch 4, gen_loss = 0.9613920766796963, disc_loss = 0.0008199247994600839
Trained batch 883 in epoch 4, gen_loss = 0.9612743538294443, disc_loss = 0.0008192524056453274
Trained batch 884 in epoch 4, gen_loss = 0.9611532857189071, disc_loss = 0.0008185156310844699
Trained batch 885 in epoch 4, gen_loss = 0.9611016001981214, disc_loss = 0.0008178097675101802
Trained batch 886 in epoch 4, gen_loss = 0.960929849102102, disc_loss = 0.000817156014313988
Trained batch 887 in epoch 4, gen_loss = 0.9608365391960015, disc_loss = 0.0008164706031829491
Trained batch 888 in epoch 4, gen_loss = 0.9608180640250679, disc_loss = 0.0008157578688289701
Trained batch 889 in epoch 4, gen_loss = 0.9608334337057692, disc_loss = 0.0008150123430496432
Trained batch 890 in epoch 4, gen_loss = 0.9608414427332338, disc_loss = 0.0008142993162093056
Trained batch 891 in epoch 4, gen_loss = 0.960977044741669, disc_loss = 0.0008138716062367085
Trained batch 892 in epoch 4, gen_loss = 0.9608934982893582, disc_loss = 0.0008131558650078994
Trained batch 893 in epoch 4, gen_loss = 0.9607916914376636, disc_loss = 0.0008124744760283916
Trained batch 894 in epoch 4, gen_loss = 0.9607737006421861, disc_loss = 0.0008119084212754062
Trained batch 895 in epoch 4, gen_loss = 0.9607661239403699, disc_loss = 0.0008111979172927672
Trained batch 896 in epoch 4, gen_loss = 0.9608276063781916, disc_loss = 0.0008104220108696105
Trained batch 897 in epoch 4, gen_loss = 0.9606350915203646, disc_loss = 0.0008097213360456722
Trained batch 898 in epoch 4, gen_loss = 0.9605616197835352, disc_loss = 0.0008089755382256099
Trained batch 899 in epoch 4, gen_loss = 0.9605860170390871, disc_loss = 0.0008082936488871281
Trained batch 900 in epoch 4, gen_loss = 0.9604550504128756, disc_loss = 0.0008076559662023382
Trained batch 901 in epoch 4, gen_loss = 0.9603381561995081, disc_loss = 0.0008069013957495769
Trained batch 902 in epoch 4, gen_loss = 0.9602925192610106, disc_loss = 0.0008064753502595871
Trained batch 903 in epoch 4, gen_loss = 0.9602321639525152, disc_loss = 0.0008058442743888524
Trained batch 904 in epoch 4, gen_loss = 0.9602057482656194, disc_loss = 0.0008052017342042594
Trained batch 905 in epoch 4, gen_loss = 0.960129316345219, disc_loss = 0.0008044867909180744
Trained batch 906 in epoch 4, gen_loss = 0.9600880881391524, disc_loss = 0.0008038391575888914
Trained batch 907 in epoch 4, gen_loss = 0.959962341163127, disc_loss = 0.0008032813339855339
Trained batch 908 in epoch 4, gen_loss = 0.9598733306717951, disc_loss = 0.0008026109862919846
Trained batch 909 in epoch 4, gen_loss = 0.9597820615375435, disc_loss = 0.0008020399905505186
Trained batch 910 in epoch 4, gen_loss = 0.959707452816445, disc_loss = 0.000801479601175445
Trained batch 911 in epoch 4, gen_loss = 0.9596543125808239, disc_loss = 0.0008008460321546233
Trained batch 912 in epoch 4, gen_loss = 0.9596434875359802, disc_loss = 0.0008002714454262061
Trained batch 913 in epoch 4, gen_loss = 0.9595975245245176, disc_loss = 0.0007998001767959648
Trained batch 914 in epoch 4, gen_loss = 0.9597269796282867, disc_loss = 0.0007993038113867035
Trained batch 915 in epoch 4, gen_loss = 0.959674920837952, disc_loss = 0.0007988489587461718
Trained batch 916 in epoch 4, gen_loss = 0.9596634225080941, disc_loss = 0.0007983935777056173
Trained batch 917 in epoch 4, gen_loss = 0.9595806031185558, disc_loss = 0.0007980291187924394
Trained batch 918 in epoch 4, gen_loss = 0.9596134544845764, disc_loss = 0.0007977779837163956
Trained batch 919 in epoch 4, gen_loss = 0.9595618412546489, disc_loss = 0.0007972666902234145
Trained batch 920 in epoch 4, gen_loss = 0.9595467160889691, disc_loss = 0.0007967688944556672
Trained batch 921 in epoch 4, gen_loss = 0.9595031978122066, disc_loss = 0.0007961539956307318
Trained batch 922 in epoch 4, gen_loss = 0.9594234970124804, disc_loss = 0.0007954395361972306
Trained batch 923 in epoch 4, gen_loss = 0.9594276437124649, disc_loss = 0.0007947485438933937
Trained batch 924 in epoch 4, gen_loss = 0.959334021323436, disc_loss = 0.0007941380051213216
Trained batch 925 in epoch 4, gen_loss = 0.9592470768718431, disc_loss = 0.0007936155806130505
Trained batch 926 in epoch 4, gen_loss = 0.9591771814944031, disc_loss = 0.0007929446104755841
Trained batch 927 in epoch 4, gen_loss = 0.9590679947286844, disc_loss = 0.0007924103403779712
Trained batch 928 in epoch 4, gen_loss = 0.9590443999569691, disc_loss = 0.0007919483981161043
Trained batch 929 in epoch 4, gen_loss = 0.9589964343014584, disc_loss = 0.000791348667256096
Trained batch 930 in epoch 4, gen_loss = 0.9588714366184525, disc_loss = 0.000790696625220957
Trained batch 931 in epoch 4, gen_loss = 0.9588075908212703, disc_loss = 0.0007900426682345734
Trained batch 932 in epoch 4, gen_loss = 0.9588081556245572, disc_loss = 0.0007893902464232124
Trained batch 933 in epoch 4, gen_loss = 0.9587377712481537, disc_loss = 0.00078871922105035
Trained batch 934 in epoch 4, gen_loss = 0.9587028557604009, disc_loss = 0.0007880920244123722
Trained batch 935 in epoch 4, gen_loss = 0.9585818541992424, disc_loss = 0.0007873561933313165
Trained batch 936 in epoch 4, gen_loss = 0.958584160026135, disc_loss = 0.0007867150885846765
Trained batch 937 in epoch 4, gen_loss = 0.9586023106249665, disc_loss = 0.0007860952972396359
Trained batch 938 in epoch 4, gen_loss = 0.9585846166133373, disc_loss = 0.0007854625499552275
Trained batch 939 in epoch 4, gen_loss = 0.9585110697340458, disc_loss = 0.0007847698781799718
Trained batch 940 in epoch 4, gen_loss = 0.9585475900094643, disc_loss = 0.0007841255258472253
Trained batch 941 in epoch 4, gen_loss = 0.9584298639413911, disc_loss = 0.0007834771876662724
Trained batch 942 in epoch 4, gen_loss = 0.9583528205546948, disc_loss = 0.0007830143355564333
Trained batch 943 in epoch 4, gen_loss = 0.958322261286489, disc_loss = 0.0007823518859537618
Trained batch 944 in epoch 4, gen_loss = 0.9582563189602403, disc_loss = 0.0007816994677851514
Trained batch 945 in epoch 4, gen_loss = 0.9582102509180033, disc_loss = 0.000781064841835196
Trained batch 946 in epoch 4, gen_loss = 0.9583058912373899, disc_loss = 0.000780445346132709
Trained batch 947 in epoch 4, gen_loss = 0.9582439186955303, disc_loss = 0.0007797788383933703
Trained batch 948 in epoch 4, gen_loss = 0.9582786409947844, disc_loss = 0.0007791215309165285
Trained batch 949 in epoch 4, gen_loss = 0.9583133836168992, disc_loss = 0.0007784671796635896
Trained batch 950 in epoch 4, gen_loss = 0.9582136319137396, disc_loss = 0.0007777783376073292
Trained batch 951 in epoch 4, gen_loss = 0.9581214506335619, disc_loss = 0.0007771244906713846
Trained batch 952 in epoch 4, gen_loss = 0.9580720272794726, disc_loss = 0.0007764428601903056
Trained batch 953 in epoch 4, gen_loss = 0.9580447278307669, disc_loss = 0.0007757473746778964
Trained batch 954 in epoch 4, gen_loss = 0.9579074346582303, disc_loss = 0.0007750741171443967
Trained batch 955 in epoch 4, gen_loss = 0.9578656874690594, disc_loss = 0.0007744069025039193
Trained batch 956 in epoch 4, gen_loss = 0.9578036883283434, disc_loss = 0.0007738151340132901
Trained batch 957 in epoch 4, gen_loss = 0.9578315277189203, disc_loss = 0.00077316032392273
Trained batch 958 in epoch 4, gen_loss = 0.9577002611722141, disc_loss = 0.0007724813184797656
Trained batch 959 in epoch 4, gen_loss = 0.9575843155384064, disc_loss = 0.0007718175534212908
Trained batch 960 in epoch 4, gen_loss = 0.9576644855284914, disc_loss = 0.0007712754243118064
Trained batch 961 in epoch 4, gen_loss = 0.9577778557977656, disc_loss = 0.0007708372518710289
Trained batch 962 in epoch 4, gen_loss = 0.9577910684722235, disc_loss = 0.0007702619426338914
Trained batch 963 in epoch 4, gen_loss = 0.9578083446906316, disc_loss = 0.00076969064193464
Trained batch 964 in epoch 4, gen_loss = 0.9577867137335743, disc_loss = 0.0007690336092370997
Trained batch 965 in epoch 4, gen_loss = 0.9578016910000123, disc_loss = 0.0007685139939489878
Trained batch 966 in epoch 4, gen_loss = 0.9577330249171963, disc_loss = 0.0007679435259078325
Trained batch 967 in epoch 4, gen_loss = 0.957786182295685, disc_loss = 0.0007673732832038447
Trained batch 968 in epoch 4, gen_loss = 0.9577053498065385, disc_loss = 0.0007667872915065451
Trained batch 969 in epoch 4, gen_loss = 0.957568648979836, disc_loss = 0.0007661191112009002
Trained batch 970 in epoch 4, gen_loss = 0.9576382998580422, disc_loss = 0.0007654675861317511
Trained batch 971 in epoch 4, gen_loss = 0.9575771715783288, disc_loss = 0.0007648864185685242
Trained batch 972 in epoch 4, gen_loss = 0.9575219706298146, disc_loss = 0.0007642618025916763
Trained batch 973 in epoch 4, gen_loss = 0.9573885440459241, disc_loss = 0.0007636520219572344
Trained batch 974 in epoch 4, gen_loss = 0.9572682996896597, disc_loss = 0.0007630246255296068
Trained batch 975 in epoch 4, gen_loss = 0.9571536551611345, disc_loss = 0.0007623309717674885
Trained batch 976 in epoch 4, gen_loss = 0.9571041394036527, disc_loss = 0.0007617144184617207
Trained batch 977 in epoch 4, gen_loss = 0.9571098777292208, disc_loss = 0.0007611110829289932
Trained batch 978 in epoch 4, gen_loss = 0.9571458289401645, disc_loss = 0.0007605038145710443
Trained batch 979 in epoch 4, gen_loss = 0.9570568054306264, disc_loss = 0.00075992038418546
Trained batch 980 in epoch 4, gen_loss = 0.9570199068290135, disc_loss = 0.0007593628210242255
Trained batch 981 in epoch 4, gen_loss = 0.957024081843448, disc_loss = 0.0007588914339329864
Trained batch 982 in epoch 4, gen_loss = 0.956962276329708, disc_loss = 0.0007584358066836058
Trained batch 983 in epoch 4, gen_loss = 0.9569454392403122, disc_loss = 0.000757838613314628
Trained batch 984 in epoch 4, gen_loss = 0.9568963989388519, disc_loss = 0.000757288491589178
Trained batch 985 in epoch 4, gen_loss = 0.9567808118964306, disc_loss = 0.0007567919384324252
Trained batch 986 in epoch 4, gen_loss = 0.9566429314763109, disc_loss = 0.0007562841391036373
Trained batch 987 in epoch 4, gen_loss = 0.9564682434686282, disc_loss = 0.0007558062980061082
Trained batch 988 in epoch 4, gen_loss = 0.95652492861174, disc_loss = 0.0007555736166584429
Trained batch 989 in epoch 4, gen_loss = 0.9565325146371668, disc_loss = 0.0007552589353490292
Trained batch 990 in epoch 4, gen_loss = 0.9565160488023767, disc_loss = 0.0007547211008963779
Trained batch 991 in epoch 4, gen_loss = 0.9564958802394329, disc_loss = 0.000754220686567644
Trained batch 992 in epoch 4, gen_loss = 0.9563684554738701, disc_loss = 0.0007536119002782508
Trained batch 993 in epoch 4, gen_loss = 0.9564223200742388, disc_loss = 0.0007530907443187001
Trained batch 994 in epoch 4, gen_loss = 0.9563681491655321, disc_loss = 0.0007525506947831901
Trained batch 995 in epoch 4, gen_loss = 0.9562403477100004, disc_loss = 0.0007519820232060504
Trained batch 996 in epoch 4, gen_loss = 0.9562293294678958, disc_loss = 0.0007514324666514905
Trained batch 997 in epoch 4, gen_loss = 0.9562794361898082, disc_loss = 0.0007510241085038435
Trained batch 998 in epoch 4, gen_loss = 0.956286857793997, disc_loss = 0.000750570449942804
Trained batch 999 in epoch 4, gen_loss = 0.9561133720874786, disc_loss = 0.0007499249062529997
Trained batch 1000 in epoch 4, gen_loss = 0.956196714709927, disc_loss = 0.0007493286808624959
Trained batch 1001 in epoch 4, gen_loss = 0.9561452764474941, disc_loss = 0.000748755982427527
Trained batch 1002 in epoch 4, gen_loss = 0.9560430224015491, disc_loss = 0.0007481306366586932
Trained batch 1003 in epoch 4, gen_loss = 0.9559723370934863, disc_loss = 0.0007475128489266107
Trained batch 1004 in epoch 4, gen_loss = 0.9559435814174253, disc_loss = 0.0007469206679333233
Trained batch 1005 in epoch 4, gen_loss = 0.9559239989246573, disc_loss = 0.0007463284829293774
Trained batch 1006 in epoch 4, gen_loss = 0.9557489018809594, disc_loss = 0.0007458177420078077
Trained batch 1007 in epoch 4, gen_loss = 0.9557179758354785, disc_loss = 0.0007452582037316576
Trained batch 1008 in epoch 4, gen_loss = 0.9556709397418057, disc_loss = 0.0007447954677716839
Trained batch 1009 in epoch 4, gen_loss = 0.9555390124863917, disc_loss = 0.0007442356580015419
Trained batch 1010 in epoch 4, gen_loss = 0.9554824011380075, disc_loss = 0.000743666449963584
Trained batch 1011 in epoch 4, gen_loss = 0.9553518744089858, disc_loss = 0.0007431181513217992
Trained batch 1012 in epoch 4, gen_loss = 0.955351795872484, disc_loss = 0.0007426276113660979
Trained batch 1013 in epoch 4, gen_loss = 0.9553340585274104, disc_loss = 0.0007420812403513174
Trained batch 1014 in epoch 4, gen_loss = 0.9552751999183241, disc_loss = 0.0007415404382707743
Trained batch 1015 in epoch 4, gen_loss = 0.9552918406218056, disc_loss = 0.0007409665655774637
Trained batch 1016 in epoch 4, gen_loss = 0.9551351509966329, disc_loss = 0.000740340111312212
Trained batch 1017 in epoch 4, gen_loss = 0.9550866579494214, disc_loss = 0.0007397204618143972
Trained batch 1018 in epoch 4, gen_loss = 0.9551087854771899, disc_loss = 0.0007391648386440343
Trained batch 1019 in epoch 4, gen_loss = 0.9550375211472605, disc_loss = 0.0007385683937172871
Trained batch 1020 in epoch 4, gen_loss = 0.9549321776856171, disc_loss = 0.0007379699673465554
Trained batch 1021 in epoch 4, gen_loss = 0.9548961288658373, disc_loss = 0.0007374137528795419
Trained batch 1022 in epoch 4, gen_loss = 0.954817757753333, disc_loss = 0.0007370925430459483
Trained batch 1023 in epoch 4, gen_loss = 0.9548376077436842, disc_loss = 0.0007364974767796184
Trained batch 1024 in epoch 4, gen_loss = 0.9548292540922397, disc_loss = 0.0007359900389423185
Trained batch 1025 in epoch 4, gen_loss = 0.9547988853143204, disc_loss = 0.0007353752132286871
Trained batch 1026 in epoch 4, gen_loss = 0.9546897964445038, disc_loss = 0.0007347625739438987
Trained batch 1027 in epoch 4, gen_loss = 0.9545942615674163, disc_loss = 0.0007341713106228222
Trained batch 1028 in epoch 4, gen_loss = 0.9545414345257484, disc_loss = 0.0007336031164658555
Trained batch 1029 in epoch 4, gen_loss = 0.95460830400291, disc_loss = 0.0007330347209839937
Trained batch 1030 in epoch 4, gen_loss = 0.954580514784812, disc_loss = 0.0007325063048028383
Trained batch 1031 in epoch 4, gen_loss = 0.9545215396571529, disc_loss = 0.0007319255983302426
Trained batch 1032 in epoch 4, gen_loss = 0.9543257817871227, disc_loss = 0.0007313476605488471
Trained batch 1033 in epoch 4, gen_loss = 0.9542102258025562, disc_loss = 0.0007307481381981823
Trained batch 1034 in epoch 4, gen_loss = 0.9540955457134523, disc_loss = 0.0007301387379051676
Trained batch 1035 in epoch 4, gen_loss = 0.9541548839176944, disc_loss = 0.0007295770556505267
Trained batch 1036 in epoch 4, gen_loss = 0.9541571308124951, disc_loss = 0.0007289471564171862
Trained batch 1037 in epoch 4, gen_loss = 0.9541688520669478, disc_loss = 0.0007283530370165192
Trained batch 1038 in epoch 4, gen_loss = 0.9542168574452515, disc_loss = 0.0007279310095758348
Trained batch 1039 in epoch 4, gen_loss = 0.954132893968087, disc_loss = 0.0007274120119361144
Trained batch 1040 in epoch 4, gen_loss = 0.9540000782347321, disc_loss = 0.0007268353546386957
Trained batch 1041 in epoch 4, gen_loss = 0.9540029438695157, disc_loss = 0.0007263083348203551
Trained batch 1042 in epoch 4, gen_loss = 0.9540174252577733, disc_loss = 0.0007257805130429288
Trained batch 1043 in epoch 4, gen_loss = 0.9539980392232252, disc_loss = 0.0007252720681201333
Trained batch 1044 in epoch 4, gen_loss = 0.9540669810258601, disc_loss = 0.0007247238744965991
Trained batch 1045 in epoch 4, gen_loss = 0.9540695427822565, disc_loss = 0.0007241363473266388
Trained batch 1046 in epoch 4, gen_loss = 0.9540457574093809, disc_loss = 0.0007235754624357378
Trained batch 1047 in epoch 4, gen_loss = 0.9540877209137414, disc_loss = 0.0007230305527627934
Trained batch 1048 in epoch 4, gen_loss = 0.9541129185201102, disc_loss = 0.0007224436742331841
Trained batch 1049 in epoch 4, gen_loss = 0.9540773816903432, disc_loss = 0.0007218710008947667
Trained batch 1050 in epoch 4, gen_loss = 0.953904506028209, disc_loss = 0.0007213758433120924
Trained batch 1051 in epoch 4, gen_loss = 0.9538371459839462, disc_loss = 0.0007208209096008342
Trained batch 1052 in epoch 4, gen_loss = 0.9536931364737797, disc_loss = 0.0007203762545942436
Trained batch 1053 in epoch 4, gen_loss = 0.9535978310361533, disc_loss = 0.0007198168573069582
Trained batch 1054 in epoch 4, gen_loss = 0.9534842034086797, disc_loss = 0.0007194352812923809
Trained batch 1055 in epoch 4, gen_loss = 0.9535158704401869, disc_loss = 0.0007189567969004256
Trained batch 1056 in epoch 4, gen_loss = 0.9534362261320131, disc_loss = 0.0007183987621632964
Trained batch 1057 in epoch 4, gen_loss = 0.9533857264906337, disc_loss = 0.0007178448746492514
Trained batch 1058 in epoch 4, gen_loss = 0.9533372113342213, disc_loss = 0.0007172650314408102
Trained batch 1059 in epoch 4, gen_loss = 0.9532954453297381, disc_loss = 0.0007167450208005491
Trained batch 1060 in epoch 4, gen_loss = 0.9533668212683891, disc_loss = 0.0007162609306745285
Trained batch 1061 in epoch 4, gen_loss = 0.9532516058779931, disc_loss = 0.0007158055207543553
Trained batch 1062 in epoch 4, gen_loss = 0.9531926118531321, disc_loss = 0.0007152653219585608
Trained batch 1063 in epoch 4, gen_loss = 0.9531438821240475, disc_loss = 0.0007146995400185382
Trained batch 1064 in epoch 4, gen_loss = 0.9531128328730802, disc_loss = 0.0007141719740037172
Trained batch 1065 in epoch 4, gen_loss = 0.9531117030200994, disc_loss = 0.0007136382392070765
Trained batch 1066 in epoch 4, gen_loss = 0.9530717037834625, disc_loss = 0.00071311319183498
Trained batch 1067 in epoch 4, gen_loss = 0.9529885044705109, disc_loss = 0.0007125542762285763
Trained batch 1068 in epoch 4, gen_loss = 0.9529445206483353, disc_loss = 0.0007119844523455619
Trained batch 1069 in epoch 4, gen_loss = 0.9529057937804783, disc_loss = 0.0007114543822957376
Trained batch 1070 in epoch 4, gen_loss = 0.9528709055662823, disc_loss = 0.0007109852364582655
Trained batch 1071 in epoch 4, gen_loss = 0.9527776321924445, disc_loss = 0.0007106158491568301
Trained batch 1072 in epoch 4, gen_loss = 0.9526790657670056, disc_loss = 0.0007102142532484325
Trained batch 1073 in epoch 4, gen_loss = 0.9526374710227746, disc_loss = 0.0007097809249367193
Trained batch 1074 in epoch 4, gen_loss = 0.9525882356665856, disc_loss = 0.0007092506862868186
Trained batch 1075 in epoch 4, gen_loss = 0.9525476924548805, disc_loss = 0.0007087213020269944
Trained batch 1076 in epoch 4, gen_loss = 0.9525357956341715, disc_loss = 0.0007082226362254275
Trained batch 1077 in epoch 4, gen_loss = 0.9525994675057717, disc_loss = 0.0007076950786100288
Trained batch 1078 in epoch 4, gen_loss = 0.952537288922088, disc_loss = 0.0007071994169716843
Trained batch 1079 in epoch 4, gen_loss = 0.9524590561787287, disc_loss = 0.0007067221347150971
Trained batch 1080 in epoch 4, gen_loss = 0.9525988422864902, disc_loss = 0.000706230745476151
Trained batch 1081 in epoch 4, gen_loss = 0.9525962902746007, disc_loss = 0.0007058916395422943
Trained batch 1082 in epoch 4, gen_loss = 0.9525121605627425, disc_loss = 0.0007054555830031906
Trained batch 1083 in epoch 4, gen_loss = 0.9524997758689402, disc_loss = 0.0007049840069191214
Trained batch 1084 in epoch 4, gen_loss = 0.9524619385394083, disc_loss = 0.0007044946391394036
Trained batch 1085 in epoch 4, gen_loss = 0.9524557394546699, disc_loss = 0.0007039673587188989
Trained batch 1086 in epoch 4, gen_loss = 0.9523672718133198, disc_loss = 0.0007034583107352843
Trained batch 1087 in epoch 4, gen_loss = 0.9522341840407428, disc_loss = 0.0007028915508258518
Trained batch 1088 in epoch 4, gen_loss = 0.9521358488238766, disc_loss = 0.0007023683408485522
Trained batch 1089 in epoch 4, gen_loss = 0.9521004961718113, disc_loss = 0.000701838692722558
Trained batch 1090 in epoch 4, gen_loss = 0.9521573838239192, disc_loss = 0.0007013006507195289
Trained batch 1091 in epoch 4, gen_loss = 0.9520871399632304, disc_loss = 0.0007007498583727497
Trained batch 1092 in epoch 4, gen_loss = 0.9520075662029193, disc_loss = 0.000700270130061994
Trained batch 1093 in epoch 4, gen_loss = 0.951897610802973, disc_loss = 0.0006997897974923623
Trained batch 1094 in epoch 4, gen_loss = 0.9518056415531734, disc_loss = 0.0006992508353214694
Trained batch 1095 in epoch 4, gen_loss = 0.9517484989805813, disc_loss = 0.0006987401458873867
Trained batch 1096 in epoch 4, gen_loss = 0.9517174395736826, disc_loss = 0.0006982056553649173
Trained batch 1097 in epoch 4, gen_loss = 0.9516737731970941, disc_loss = 0.000697682929029756
Trained batch 1098 in epoch 4, gen_loss = 0.9515848862137765, disc_loss = 0.0006971709618558455
Trained batch 1099 in epoch 4, gen_loss = 0.9514970947937532, disc_loss = 0.0006966980835237667
Trained batch 1100 in epoch 4, gen_loss = 0.9514393103220158, disc_loss = 0.0006962041956744538
Trained batch 1101 in epoch 4, gen_loss = 0.9514071014853441, disc_loss = 0.0006957025022600683
Trained batch 1102 in epoch 4, gen_loss = 0.9513254025689278, disc_loss = 0.000695201236790963
Trained batch 1103 in epoch 4, gen_loss = 0.9513028646832791, disc_loss = 0.0006946659591910471
Trained batch 1104 in epoch 4, gen_loss = 0.951277825897096, disc_loss = 0.0006941304860159341
Trained batch 1105 in epoch 4, gen_loss = 0.9513401010260659, disc_loss = 0.000693646024012219
Trained batch 1106 in epoch 4, gen_loss = 0.9513069309947075, disc_loss = 0.0006931173160551566
Trained batch 1107 in epoch 4, gen_loss = 0.9512860748096493, disc_loss = 0.0006926784025896984
Trained batch 1108 in epoch 4, gen_loss = 0.9512650768320446, disc_loss = 0.0006923043331645393
Trained batch 1109 in epoch 4, gen_loss = 0.9511938504270605, disc_loss = 0.0006918734048930027
Trained batch 1110 in epoch 4, gen_loss = 0.9512054769977807, disc_loss = 0.000691378095167495
Trained batch 1111 in epoch 4, gen_loss = 0.9511697999865031, disc_loss = 0.0006909344257640199
Trained batch 1112 in epoch 4, gen_loss = 0.9511019947929417, disc_loss = 0.000690473551988869
Trained batch 1113 in epoch 4, gen_loss = 0.9510708165553998, disc_loss = 0.00069001267783502
Trained batch 1114 in epoch 4, gen_loss = 0.9510229782673275, disc_loss = 0.0006894812057569472
Trained batch 1115 in epoch 4, gen_loss = 0.9510621456796551, disc_loss = 0.0006889872721105975
Trained batch 1116 in epoch 4, gen_loss = 0.9510133131444721, disc_loss = 0.0006884566817432434
Trained batch 1117 in epoch 4, gen_loss = 0.9509668012744412, disc_loss = 0.000687986074523852
Trained batch 1118 in epoch 4, gen_loss = 0.9508284235554577, disc_loss = 0.0006874774359619696
Trained batch 1119 in epoch 4, gen_loss = 0.9508652512516295, disc_loss = 0.0006870449997287714
Trained batch 1120 in epoch 4, gen_loss = 0.9508407129760729, disc_loss = 0.000686594984270302
Trained batch 1121 in epoch 4, gen_loss = 0.9507712760073616, disc_loss = 0.0006862091598215196
Trained batch 1122 in epoch 4, gen_loss = 0.9507028597970149, disc_loss = 0.0006857808053765412
Trained batch 1123 in epoch 4, gen_loss = 0.9506620121490065, disc_loss = 0.0006852869506066419
Trained batch 1124 in epoch 4, gen_loss = 0.9505844313833448, disc_loss = 0.0006847887212190674
Trained batch 1125 in epoch 4, gen_loss = 0.950559023112641, disc_loss = 0.0006842847750369699
Trained batch 1126 in epoch 4, gen_loss = 0.9504551663267581, disc_loss = 0.0006837334859848809
Trained batch 1127 in epoch 4, gen_loss = 0.9503582422720626, disc_loss = 0.0006832513172605801
Trained batch 1128 in epoch 4, gen_loss = 0.9502623005711578, disc_loss = 0.0006827716527386994
Trained batch 1129 in epoch 4, gen_loss = 0.9502836122449521, disc_loss = 0.0006823008285515501
Trained batch 1130 in epoch 4, gen_loss = 0.9501061315140189, disc_loss = 0.0006818265907447781
Trained batch 1131 in epoch 4, gen_loss = 0.9501114507656636, disc_loss = 0.0006813635298597743
Trained batch 1132 in epoch 4, gen_loss = 0.9501088056959942, disc_loss = 0.0006809858808517214
Trained batch 1133 in epoch 4, gen_loss = 0.9500934902112109, disc_loss = 0.0006806809520203644
Trained batch 1134 in epoch 4, gen_loss = 0.950027154563282, disc_loss = 0.0006802536356726985
Trained batch 1135 in epoch 4, gen_loss = 0.950076090040761, disc_loss = 0.0006798892736248528
Trained batch 1136 in epoch 4, gen_loss = 0.9501821448012413, disc_loss = 0.000679560724794367
Trained batch 1137 in epoch 4, gen_loss = 0.9501279708266468, disc_loss = 0.0006791752098627517
Trained batch 1138 in epoch 4, gen_loss = 0.9500863847761849, disc_loss = 0.0006787406710589029
Trained batch 1139 in epoch 4, gen_loss = 0.9500146866367575, disc_loss = 0.0006783077277009796
Trained batch 1140 in epoch 4, gen_loss = 0.9499777098374864, disc_loss = 0.0006778550447692983
Trained batch 1141 in epoch 4, gen_loss = 0.9498352340557947, disc_loss = 0.0006773945912712147
Trained batch 1142 in epoch 4, gen_loss = 0.9498244085962692, disc_loss = 0.0006768935272766604
Trained batch 1143 in epoch 4, gen_loss = 0.9497675820664092, disc_loss = 0.0006764212237269365
Trained batch 1144 in epoch 4, gen_loss = 0.9496838156312835, disc_loss = 0.0006759243600698814
Trained batch 1145 in epoch 4, gen_loss = 0.9495949092439748, disc_loss = 0.0006755509772979984
Trained batch 1146 in epoch 4, gen_loss = 0.9494784856840331, disc_loss = 0.0006750970740638975
Trained batch 1147 in epoch 4, gen_loss = 0.9495609151880916, disc_loss = 0.0006746325324922687
Trained batch 1148 in epoch 4, gen_loss = 0.9494538512615871, disc_loss = 0.0006741541391704637
Trained batch 1149 in epoch 4, gen_loss = 0.9494786186840223, disc_loss = 0.0006736643890516184
Trained batch 1150 in epoch 4, gen_loss = 0.9494872152753543, disc_loss = 0.0006732225853156421
Trained batch 1151 in epoch 4, gen_loss = 0.9494783170003858, disc_loss = 0.0006727516052807106
Trained batch 1152 in epoch 4, gen_loss = 0.9494331536454319, disc_loss = 0.0006723469836073577
Trained batch 1153 in epoch 4, gen_loss = 0.9494529146978719, disc_loss = 0.000671869468046199
Trained batch 1154 in epoch 4, gen_loss = 0.9494924576251538, disc_loss = 0.0006714394820291645
Trained batch 1155 in epoch 4, gen_loss = 0.9494130533562399, disc_loss = 0.0006710255100527959
Trained batch 1156 in epoch 4, gen_loss = 0.9492475873659475, disc_loss = 0.0006705517028633493
Trained batch 1157 in epoch 4, gen_loss = 0.9493140407897442, disc_loss = 0.0006700643521016492
Trained batch 1158 in epoch 4, gen_loss = 0.9492962318211409, disc_loss = 0.0006695884443305045
Trained batch 1159 in epoch 4, gen_loss = 0.9491767318084322, disc_loss = 0.0006691288158090801
Trained batch 1160 in epoch 4, gen_loss = 0.9491952280357518, disc_loss = 0.0006687207613917449
Trained batch 1161 in epoch 4, gen_loss = 0.9492085102605737, disc_loss = 0.0006682690383495543
Trained batch 1162 in epoch 4, gen_loss = 0.9492226618174736, disc_loss = 0.0006678013749710329
Trained batch 1163 in epoch 4, gen_loss = 0.9491873159236515, disc_loss = 0.0006674108034284038
Trained batch 1164 in epoch 4, gen_loss = 0.949049257208861, disc_loss = 0.0006670209014080784
Trained batch 1165 in epoch 4, gen_loss = 0.9490296546734013, disc_loss = 0.0006665986328921721
Trained batch 1166 in epoch 4, gen_loss = 0.9488886244907886, disc_loss = 0.0006661499222263099
Trained batch 1167 in epoch 4, gen_loss = 0.9488657543001926, disc_loss = 0.0006656794185078506
Trained batch 1168 in epoch 4, gen_loss = 0.9488014476333958, disc_loss = 0.0006651975479764387
Trained batch 1169 in epoch 4, gen_loss = 0.94882753827633, disc_loss = 0.0006647440049840579
Trained batch 1170 in epoch 4, gen_loss = 0.9488299846343766, disc_loss = 0.0006642829234468556
Trained batch 1171 in epoch 4, gen_loss = 0.9488138504097486, disc_loss = 0.0006638217944615189
Trained batch 1172 in epoch 4, gen_loss = 0.9487098916818826, disc_loss = 0.0006633913166861594
Trained batch 1173 in epoch 4, gen_loss = 0.948545634340387, disc_loss = 0.0006629494899466695
Trained batch 1174 in epoch 4, gen_loss = 0.9485070233649396, disc_loss = 0.0006629147944895135
Trained batch 1175 in epoch 4, gen_loss = 0.9484684951856833, disc_loss = 0.0006625686689471722
Trained batch 1176 in epoch 4, gen_loss = 0.9483982833543874, disc_loss = 0.000662173204315708
Trained batch 1177 in epoch 4, gen_loss = 0.9483173458705734, disc_loss = 0.000661723580262938
Trained batch 1178 in epoch 4, gen_loss = 0.948405315807252, disc_loss = 0.0006613303221942579
Trained batch 1179 in epoch 4, gen_loss = 0.9483695898520744, disc_loss = 0.000660855640486816
Trained batch 1180 in epoch 4, gen_loss = 0.948471880433521, disc_loss = 0.0006604915498943655
Trained batch 1181 in epoch 4, gen_loss = 0.9484567928132672, disc_loss = 0.0006601418498685357
Trained batch 1182 in epoch 4, gen_loss = 0.948425359324893, disc_loss = 0.0006596732848837664
Trained batch 1183 in epoch 4, gen_loss = 0.9484549109396097, disc_loss = 0.0006592123415024666
Trained batch 1184 in epoch 4, gen_loss = 0.9484038948509763, disc_loss = 0.000658745267455474
Trained batch 1185 in epoch 4, gen_loss = 0.9483537113083554, disc_loss = 0.0006582618462417312
Trained batch 1186 in epoch 4, gen_loss = 0.9482957507344787, disc_loss = 0.0006578134312955451
Trained batch 1187 in epoch 4, gen_loss = 0.9483089718955133, disc_loss = 0.000657365996002922
Trained batch 1188 in epoch 4, gen_loss = 0.9482957683158983, disc_loss = 0.0006569208755667805
Trained batch 1189 in epoch 4, gen_loss = 0.9483076060519499, disc_loss = 0.0006564523181080732
Trained batch 1190 in epoch 4, gen_loss = 0.9481904420604433, disc_loss = 0.0006559849580367488
Trained batch 1191 in epoch 4, gen_loss = 0.9482423722143941, disc_loss = 0.0006555919173979724
Trained batch 1192 in epoch 4, gen_loss = 0.9483550344308883, disc_loss = 0.0006552688227547801
Trained batch 1193 in epoch 4, gen_loss = 0.9484061979169223, disc_loss = 0.0006549394213040889
Trained batch 1194 in epoch 4, gen_loss = 0.948432382180601, disc_loss = 0.0006545511749597407
Trained batch 1195 in epoch 4, gen_loss = 0.9483803522626691, disc_loss = 0.0006541269044752932
Trained batch 1196 in epoch 4, gen_loss = 0.9483382726273342, disc_loss = 0.0006537617302703754
Trained batch 1197 in epoch 4, gen_loss = 0.9482423942753787, disc_loss = 0.0006532879979477457
Trained batch 1198 in epoch 4, gen_loss = 0.9481366350811854, disc_loss = 0.0006527947921863115
Trained batch 1199 in epoch 4, gen_loss = 0.9480752901236216, disc_loss = 0.0006523399436931262
Trained batch 1200 in epoch 4, gen_loss = 0.9480704954522139, disc_loss = 0.0006518679458575171
Trained batch 1201 in epoch 4, gen_loss = 0.9480173473746923, disc_loss = 0.0006513922901448527
Trained batch 1202 in epoch 4, gen_loss = 0.9480017105540135, disc_loss = 0.0006509550998269186
Trained batch 1203 in epoch 4, gen_loss = 0.9479249501941212, disc_loss = 0.0006505432844592647
Trained batch 1204 in epoch 4, gen_loss = 0.9479137257421659, disc_loss = 0.0006501307871378185
Trained batch 1205 in epoch 4, gen_loss = 0.9479096778985082, disc_loss = 0.0006498029527891888
Trained batch 1206 in epoch 4, gen_loss = 0.9478371874201663, disc_loss = 0.0006494360603069016
Trained batch 1207 in epoch 4, gen_loss = 0.9477834342331286, disc_loss = 0.0006491326618339637
Trained batch 1208 in epoch 4, gen_loss = 0.9476893879935404, disc_loss = 0.0006487465430623247
Trained batch 1209 in epoch 4, gen_loss = 0.9476069142995787, disc_loss = 0.0006483306283874953
Trained batch 1210 in epoch 4, gen_loss = 0.9475339794336125, disc_loss = 0.0006479758677684412
Trained batch 1211 in epoch 4, gen_loss = 0.9475045989547232, disc_loss = 0.0006477003875915645
Trained batch 1212 in epoch 4, gen_loss = 0.9474830078567636, disc_loss = 0.0006472621092931556
Trained batch 1213 in epoch 4, gen_loss = 0.9474714912437332, disc_loss = 0.0006469110348272441
Trained batch 1214 in epoch 4, gen_loss = 0.9475475146937272, disc_loss = 0.0006466142954319186
Trained batch 1215 in epoch 4, gen_loss = 0.9475482775780716, disc_loss = 0.0006462358460219931
Trained batch 1216 in epoch 4, gen_loss = 0.9475254510011257, disc_loss = 0.0006458229470236422
Trained batch 1217 in epoch 4, gen_loss = 0.9475028895587952, disc_loss = 0.0006454175464002827
Trained batch 1218 in epoch 4, gen_loss = 0.9474338451010756, disc_loss = 0.0006449806180061013
Trained batch 1219 in epoch 4, gen_loss = 0.947425699282865, disc_loss = 0.000644622815257133
Trained batch 1220 in epoch 4, gen_loss = 0.9473873358784299, disc_loss = 0.0006443168232262243
Trained batch 1221 in epoch 4, gen_loss = 0.9473215665930422, disc_loss = 0.0006440156413919183
Trained batch 1222 in epoch 4, gen_loss = 0.9473638040845938, disc_loss = 0.0006436740486048397
Trained batch 1223 in epoch 4, gen_loss = 0.9473287240644686, disc_loss = 0.000643388399884928
Trained batch 1224 in epoch 4, gen_loss = 0.9472967961856297, disc_loss = 0.0006430338218698887
Trained batch 1225 in epoch 4, gen_loss = 0.9472399779381215, disc_loss = 0.0006426497248773764
Trained batch 1226 in epoch 4, gen_loss = 0.9471546552389156, disc_loss = 0.0006423209474577448
Trained batch 1227 in epoch 4, gen_loss = 0.9471765548864483, disc_loss = 0.0006419088421314568
Trained batch 1228 in epoch 4, gen_loss = 0.9471230794978006, disc_loss = 0.0006415584887433995
Trained batch 1229 in epoch 4, gen_loss = 0.9470457305268544, disc_loss = 0.0006411484337830159
Trained batch 1230 in epoch 4, gen_loss = 0.9469649189860718, disc_loss = 0.0006407125757829472
Trained batch 1231 in epoch 4, gen_loss = 0.9469087403993328, disc_loss = 0.0006402635920541751
Trained batch 1232 in epoch 4, gen_loss = 0.9468579020136657, disc_loss = 0.0006398124820445604
Trained batch 1233 in epoch 4, gen_loss = 0.946829950548648, disc_loss = 0.0006393556834635423
Trained batch 1234 in epoch 4, gen_loss = 0.9468585599771878, disc_loss = 0.0006389125009554699
Trained batch 1235 in epoch 4, gen_loss = 0.9468388660633063, disc_loss = 0.0006384680341059568
Trained batch 1236 in epoch 4, gen_loss = 0.9468481500204667, disc_loss = 0.0006380200554988394
Trained batch 1237 in epoch 4, gen_loss = 0.946796483099942, disc_loss = 0.000637567465882423
Trained batch 1238 in epoch 4, gen_loss = 0.9467722823583281, disc_loss = 0.000637123697621083
Trained batch 1239 in epoch 4, gen_loss = 0.9466582518912131, disc_loss = 0.0006366691865555514
Trained batch 1240 in epoch 4, gen_loss = 0.9465823764766444, disc_loss = 0.0006362407670274158
Trained batch 1241 in epoch 4, gen_loss = 0.9464651705658186, disc_loss = 0.0006358018930674862
Trained batch 1242 in epoch 4, gen_loss = 0.9464764387398502, disc_loss = 0.0006353951726867034
Trained batch 1243 in epoch 4, gen_loss = 0.9464241461738513, disc_loss = 0.0006349775848119075
Trained batch 1244 in epoch 4, gen_loss = 0.9464511417002084, disc_loss = 0.0006345797427621368
Trained batch 1245 in epoch 4, gen_loss = 0.9464173632678404, disc_loss = 0.0006341792543892962
Trained batch 1246 in epoch 4, gen_loss = 0.9463316790084411, disc_loss = 0.0006337498216467828
Trained batch 1247 in epoch 4, gen_loss = 0.9463873163629801, disc_loss = 0.0006333783176976282
Trained batch 1248 in epoch 4, gen_loss = 0.946301701070787, disc_loss = 0.0006330437339626825
Trained batch 1249 in epoch 4, gen_loss = 0.9462564800739288, disc_loss = 0.0006327884547412396
Trained batch 1250 in epoch 4, gen_loss = 0.9461672873996335, disc_loss = 0.0006325012316732264
Trained batch 1251 in epoch 4, gen_loss = 0.9460516041650558, disc_loss = 0.0006321428791415646
Trained batch 1252 in epoch 4, gen_loss = 0.9459394717920521, disc_loss = 0.0006317171495421199
Trained batch 1253 in epoch 4, gen_loss = 0.9457856113925885, disc_loss = 0.0006313995906277901
Trained batch 1254 in epoch 4, gen_loss = 0.9457235420367632, disc_loss = 0.0006309963567613762
Trained batch 1255 in epoch 4, gen_loss = 0.9458155214881442, disc_loss = 0.000630569584546911
Trained batch 1256 in epoch 4, gen_loss = 0.9458489654646474, disc_loss = 0.0006301809982496685
Trained batch 1257 in epoch 4, gen_loss = 0.9458527674451352, disc_loss = 0.0006297734544031501
Trained batch 1258 in epoch 4, gen_loss = 0.945823032151526, disc_loss = 0.0006293697511168205
Trained batch 1259 in epoch 4, gen_loss = 0.9457032429793525, disc_loss = 0.0006290386298739274
Trained batch 1260 in epoch 4, gen_loss = 0.9456208345910843, disc_loss = 0.0006286824102811039
Trained batch 1261 in epoch 4, gen_loss = 0.9455380451565877, disc_loss = 0.0006282392792010174
Trained batch 1262 in epoch 4, gen_loss = 0.9454431347401484, disc_loss = 0.0006278281586125983
Trained batch 1263 in epoch 4, gen_loss = 0.9454253297063369, disc_loss = 0.000627470564170294
Trained batch 1264 in epoch 4, gen_loss = 0.9454316480357656, disc_loss = 0.000627798037516071
Trained batch 1265 in epoch 4, gen_loss = 0.945388142578598, disc_loss = 0.0006277997726120281
Trained batch 1266 in epoch 4, gen_loss = 0.9453986030257209, disc_loss = 0.0006275011035694572
Trained batch 1267 in epoch 4, gen_loss = 0.9454232576047584, disc_loss = 0.0006272345157016997
Trained batch 1268 in epoch 4, gen_loss = 0.9454062513895538, disc_loss = 0.000626991175688837
Trained batch 1269 in epoch 4, gen_loss = 0.9453136056426942, disc_loss = 0.000626634545605923
Trained batch 1270 in epoch 4, gen_loss = 0.9452612091480138, disc_loss = 0.0006262763333012277
Trained batch 1271 in epoch 4, gen_loss = 0.9452388913563963, disc_loss = 0.0006259251800290698
Trained batch 1272 in epoch 4, gen_loss = 0.9452240103731357, disc_loss = 0.000625621647072315
Trained batch 1273 in epoch 4, gen_loss = 0.9451541109960906, disc_loss = 0.0006252845797666386
Trained batch 1274 in epoch 4, gen_loss = 0.9450352325626448, disc_loss = 0.0006248855344065484
Trained batch 1275 in epoch 4, gen_loss = 0.9449049450667301, disc_loss = 0.0006244919546748451
Trained batch 1276 in epoch 4, gen_loss = 0.9448006423357976, disc_loss = 0.0006241150458449805
Trained batch 1277 in epoch 4, gen_loss = 0.94479241230305, disc_loss = 0.0006237176101205594
Trained batch 1278 in epoch 4, gen_loss = 0.9447362707218591, disc_loss = 0.00062337019929155
Trained batch 1279 in epoch 4, gen_loss = 0.9447045122738927, disc_loss = 0.0006230268301521847
Trained batch 1280 in epoch 4, gen_loss = 0.9446891125154905, disc_loss = 0.0006226638354581256
Trained batch 1281 in epoch 4, gen_loss = 0.9445461125437071, disc_loss = 0.0006223810582718025
Trained batch 1282 in epoch 4, gen_loss = 0.9444894768349936, disc_loss = 0.0006220742841447639
Trained batch 1283 in epoch 4, gen_loss = 0.944498996311259, disc_loss = 0.0006217871428601247
Trained batch 1284 in epoch 4, gen_loss = 0.9444438591541483, disc_loss = 0.0006214687209302317
Trained batch 1285 in epoch 4, gen_loss = 0.9444388195663737, disc_loss = 0.0006212122210271676
Trained batch 1286 in epoch 4, gen_loss = 0.9443596515807424, disc_loss = 0.0006208636618988453
Trained batch 1287 in epoch 4, gen_loss = 0.9442998231938167, disc_loss = 0.0006204703947293202
Trained batch 1288 in epoch 4, gen_loss = 0.9442133779577547, disc_loss = 0.0006201331113542169
Trained batch 1289 in epoch 4, gen_loss = 0.9442358149114505, disc_loss = 0.0006197567912242321
Trained batch 1290 in epoch 4, gen_loss = 0.9441445136051784, disc_loss = 0.000619383625253376
Trained batch 1291 in epoch 4, gen_loss = 0.9441202978600659, disc_loss = 0.0006190250851347737
Trained batch 1292 in epoch 4, gen_loss = 0.9440457664159316, disc_loss = 0.0006186392773535663
Trained batch 1293 in epoch 4, gen_loss = 0.9439461593742164, disc_loss = 0.0006182541790740134
Trained batch 1294 in epoch 4, gen_loss = 0.943912572289986, disc_loss = 0.0006179083571384991
Trained batch 1295 in epoch 4, gen_loss = 0.9439688867624895, disc_loss = 0.0006175862889859325
Trained batch 1296 in epoch 4, gen_loss = 0.9439817081530828, disc_loss = 0.0006172713693546842
Trained batch 1297 in epoch 4, gen_loss = 0.9438692350600644, disc_loss = 0.0006169668058015873
Trained batch 1298 in epoch 4, gen_loss = 0.9439420039328912, disc_loss = 0.0006166631891300311
Trained batch 1299 in epoch 4, gen_loss = 0.9439276652152722, disc_loss = 0.0006163118980643609
Trained batch 1300 in epoch 4, gen_loss = 0.9438985613196927, disc_loss = 0.0006159788375740694
Trained batch 1301 in epoch 4, gen_loss = 0.9438867760327189, disc_loss = 0.0006155959498282084
Trained batch 1302 in epoch 4, gen_loss = 0.9437685452876233, disc_loss = 0.0006152280602733343
Trained batch 1303 in epoch 4, gen_loss = 0.9438056509736126, disc_loss = 0.0006148484263894437
Trained batch 1304 in epoch 4, gen_loss = 0.9436940224234629, disc_loss = 0.0006144560202503474
Trained batch 1305 in epoch 4, gen_loss = 0.9436819678426337, disc_loss = 0.0006140706774269325
Trained batch 1306 in epoch 4, gen_loss = 0.9436399015471875, disc_loss = 0.0006136759315847096
Trained batch 1307 in epoch 4, gen_loss = 0.9436459028666172, disc_loss = 0.0006132836451602936
Trained batch 1308 in epoch 4, gen_loss = 0.9435095158672405, disc_loss = 0.0006129207481733578
Trained batch 1309 in epoch 4, gen_loss = 0.9434951871406031, disc_loss = 0.00061256287312104
Trained batch 1310 in epoch 4, gen_loss = 0.9434935576492007, disc_loss = 0.0006122112203275122
Trained batch 1311 in epoch 4, gen_loss = 0.943533186687202, disc_loss = 0.0006118937117706791
Trained batch 1312 in epoch 4, gen_loss = 0.9435889423120503, disc_loss = 0.0006115878122513004
Trained batch 1313 in epoch 4, gen_loss = 0.9435802165141026, disc_loss = 0.000611210137309446
Trained batch 1314 in epoch 4, gen_loss = 0.9436495816752938, disc_loss = 0.0006110149409195688
Trained batch 1315 in epoch 4, gen_loss = 0.9437548471529795, disc_loss = 0.0006108437525092976
Trained batch 1316 in epoch 4, gen_loss = 0.9438150776726962, disc_loss = 0.0006105380014003461
Trained batch 1317 in epoch 4, gen_loss = 0.9437325286575804, disc_loss = 0.0006102298683053104
Trained batch 1318 in epoch 4, gen_loss = 0.9435654279406637, disc_loss = 0.0006098894964790355
Trained batch 1319 in epoch 4, gen_loss = 0.9435530194730469, disc_loss = 0.0006095445411560693
Trained batch 1320 in epoch 4, gen_loss = 0.9435512889162507, disc_loss = 0.000609190550848553
Trained batch 1321 in epoch 4, gen_loss = 0.9434428303847695, disc_loss = 0.0006088106478625643
Trained batch 1322 in epoch 4, gen_loss = 0.9433210987713151, disc_loss = 0.0006084138412703109
Trained batch 1323 in epoch 4, gen_loss = 0.9432409832484773, disc_loss = 0.0006080132204516274
Trained batch 1324 in epoch 4, gen_loss = 0.943249377304653, disc_loss = 0.000607690834462256
Trained batch 1325 in epoch 4, gen_loss = 0.9432748059431711, disc_loss = 0.0006074317119080435
Trained batch 1326 in epoch 4, gen_loss = 0.9432452611215328, disc_loss = 0.0006070811709055022
Trained batch 1327 in epoch 4, gen_loss = 0.9432597336729607, disc_loss = 0.0006067397678700481
Trained batch 1328 in epoch 4, gen_loss = 0.943276030215399, disc_loss = 0.0006063757661271573
Trained batch 1329 in epoch 4, gen_loss = 0.9431998286032139, disc_loss = 0.0006059812834395334
Trained batch 1330 in epoch 4, gen_loss = 0.9431676552494517, disc_loss = 0.0006056434444404067
Trained batch 1331 in epoch 4, gen_loss = 0.9431681709515082, disc_loss = 0.0006052631788488807
Trained batch 1332 in epoch 4, gen_loss = 0.9431883266163517, disc_loss = 0.00060492326874007
Trained batch 1333 in epoch 4, gen_loss = 0.9431548020739605, disc_loss = 0.0006046092861832132
Trained batch 1334 in epoch 4, gen_loss = 0.9431156254439764, disc_loss = 0.0006042544634575426
Trained batch 1335 in epoch 4, gen_loss = 0.9430645191651619, disc_loss = 0.000603953408440765
Trained batch 1336 in epoch 4, gen_loss = 0.9430976901468093, disc_loss = 0.0006036591939962045
Trained batch 1337 in epoch 4, gen_loss = 0.9431424106628549, disc_loss = 0.0006033628802315067
Trained batch 1338 in epoch 4, gen_loss = 0.9431306673930242, disc_loss = 0.000603051887051739
Trained batch 1339 in epoch 4, gen_loss = 0.9430209910691674, disc_loss = 0.0006027105104566096
Trained batch 1340 in epoch 4, gen_loss = 0.9430067111181732, disc_loss = 0.0006023727542872917
Trained batch 1341 in epoch 4, gen_loss = 0.9429880710632365, disc_loss = 0.000602003905189851
Trained batch 1342 in epoch 4, gen_loss = 0.9429108131224774, disc_loss = 0.0006021300745493096
Trained batch 1343 in epoch 4, gen_loss = 0.9429619470611215, disc_loss = 0.0006023895392726921
Trained batch 1344 in epoch 4, gen_loss = 0.9430594584755738, disc_loss = 0.0006023381057075921
Trained batch 1345 in epoch 4, gen_loss = 0.9432174242357619, disc_loss = 0.0006021787810534098
Trained batch 1346 in epoch 4, gen_loss = 0.9433506029397359, disc_loss = 0.0006022649916255696
Trained batch 1347 in epoch 4, gen_loss = 0.9433602362163697, disc_loss = 0.0006022413023697414
Trained batch 1348 in epoch 4, gen_loss = 0.9434383179277204, disc_loss = 0.0006021709167172413
Trained batch 1349 in epoch 4, gen_loss = 0.9435319865632941, disc_loss = 0.0006023668985236092
Trained batch 1350 in epoch 4, gen_loss = 0.9435114704353733, disc_loss = 0.0006027063112066566
Trained batch 1351 in epoch 4, gen_loss = 0.9435636774146345, disc_loss = 0.0006032611054897697
Trained batch 1352 in epoch 4, gen_loss = 0.9436860572648594, disc_loss = 0.0006049327638231876
Trained batch 1353 in epoch 4, gen_loss = 0.9436844033539912, disc_loss = 0.000608198477652239
Trained batch 1354 in epoch 4, gen_loss = 0.9437704813876275, disc_loss = 0.0006120926781507669
Trained batch 1355 in epoch 4, gen_loss = 0.9438149680254382, disc_loss = 0.0006139382035452611
Trained batch 1356 in epoch 4, gen_loss = 0.9438214438226878, disc_loss = 0.0006138794966786345
Trained batch 1357 in epoch 4, gen_loss = 0.9438531583117455, disc_loss = 0.0006139257824227052
Trained batch 1358 in epoch 4, gen_loss = 0.9438661054445594, disc_loss = 0.0006140956052808903
Trained batch 1359 in epoch 4, gen_loss = 0.9438248176346807, disc_loss = 0.0006144707398668877
Trained batch 1360 in epoch 4, gen_loss = 0.9440714761581953, disc_loss = 0.0006152361560269745
Trained batch 1361 in epoch 4, gen_loss = 0.9442865668677023, disc_loss = 0.0006167508367759828
Trained batch 1362 in epoch 4, gen_loss = 0.9445627608984949, disc_loss = 0.0006193664824183188
Trained batch 1363 in epoch 4, gen_loss = 0.944798535309579, disc_loss = 0.0006227012063471172
Trained batch 1364 in epoch 4, gen_loss = 0.9449333756397932, disc_loss = 0.0006257346451952849
Trained batch 1365 in epoch 4, gen_loss = 0.9450933168346327, disc_loss = 0.000627861738428753
Trained batch 1366 in epoch 4, gen_loss = 0.9451944382851718, disc_loss = 0.0006285145228032715
Trained batch 1367 in epoch 4, gen_loss = 0.9453471665929633, disc_loss = 0.0006285719818369913
Trained batch 1368 in epoch 4, gen_loss = 0.945472267572683, disc_loss = 0.0006289544065764896
Trained batch 1369 in epoch 4, gen_loss = 0.9455680875447545, disc_loss = 0.0006289517155374285
Trained batch 1370 in epoch 4, gen_loss = 0.9457008893867204, disc_loss = 0.000628815248495995
Trained batch 1371 in epoch 4, gen_loss = 0.9458952477913208, disc_loss = 0.0006286797530800797
Trained batch 1372 in epoch 4, gen_loss = 0.9459975579752161, disc_loss = 0.0006286111456256914
Trained batch 1373 in epoch 4, gen_loss = 0.9461289452933849, disc_loss = 0.0006286948686931622
Trained batch 1374 in epoch 4, gen_loss = 0.9463494210243225, disc_loss = 0.0006286067857026038
Trained batch 1375 in epoch 4, gen_loss = 0.9464884131367124, disc_loss = 0.0006284402345129841
Trained batch 1376 in epoch 4, gen_loss = 0.9465750007847555, disc_loss = 0.0006286043132849433
Trained batch 1377 in epoch 4, gen_loss = 0.9466846534666026, disc_loss = 0.0006296277482634348
Trained batch 1378 in epoch 4, gen_loss = 0.9468791507741002, disc_loss = 0.0006298660702511744
Trained batch 1379 in epoch 4, gen_loss = 0.9470257942659267, disc_loss = 0.0006297842017796727
Trained batch 1380 in epoch 4, gen_loss = 0.9471625866102706, disc_loss = 0.0006297973708224676
Trained batch 1381 in epoch 4, gen_loss = 0.9473073256084784, disc_loss = 0.0006297890799606621
Trained batch 1382 in epoch 4, gen_loss = 0.9474352665854293, disc_loss = 0.0006297099855135849
Trained batch 1383 in epoch 4, gen_loss = 0.9475441652140176, disc_loss = 0.0006298942927044353
Trained batch 1384 in epoch 4, gen_loss = 0.947755107079172, disc_loss = 0.0006299953620682474
Trained batch 1385 in epoch 4, gen_loss = 0.9478225129593331, disc_loss = 0.0006300401030169481
Trained batch 1386 in epoch 4, gen_loss = 0.9479525830561769, disc_loss = 0.0006299666258729403
Trained batch 1387 in epoch 4, gen_loss = 0.9480186542361889, disc_loss = 0.0006298039792328993
Trained batch 1388 in epoch 4, gen_loss = 0.9480886216898288, disc_loss = 0.0006298485742643867
Trained batch 1389 in epoch 4, gen_loss = 0.948255058372621, disc_loss = 0.0006295811810585998
Trained batch 1390 in epoch 4, gen_loss = 0.9483410985156154, disc_loss = 0.0006293642590025616
Trained batch 1391 in epoch 4, gen_loss = 0.9483880697396295, disc_loss = 0.0006292102262841059
Trained batch 1392 in epoch 4, gen_loss = 0.9484622153718952, disc_loss = 0.0006290152167731913
Trained batch 1393 in epoch 4, gen_loss = 0.9484818104435416, disc_loss = 0.0006286860031521394
Trained batch 1394 in epoch 4, gen_loss = 0.9486190169942849, disc_loss = 0.0006283968380789229
Trained batch 1395 in epoch 4, gen_loss = 0.9487207321434104, disc_loss = 0.0006280943496176275
Trained batch 1396 in epoch 4, gen_loss = 0.9488343228676017, disc_loss = 0.0006277864388199877
Trained batch 1397 in epoch 4, gen_loss = 0.9489048330142604, disc_loss = 0.0006275279812587395
Trained batch 1398 in epoch 4, gen_loss = 0.9491396498646031, disc_loss = 0.0006274508113548122
Trained batch 1399 in epoch 4, gen_loss = 0.9492155748179981, disc_loss = 0.0006276273740305832
Trained batch 1400 in epoch 4, gen_loss = 0.9494511758234567, disc_loss = 0.0006278450168296296
Trained batch 1401 in epoch 4, gen_loss = 0.9495283200720408, disc_loss = 0.0006279972586239397
Trained batch 1402 in epoch 4, gen_loss = 0.9495737548819289, disc_loss = 0.0006277887658873229
Trained batch 1403 in epoch 4, gen_loss = 0.9496598915751503, disc_loss = 0.0006275943586275451
Trained batch 1404 in epoch 4, gen_loss = 0.949793143077253, disc_loss = 0.0006273869863169407
Trained batch 1405 in epoch 4, gen_loss = 0.9498836194214068, disc_loss = 0.0006271928700045146
Trained batch 1406 in epoch 4, gen_loss = 0.94999768438285, disc_loss = 0.0006275832542049809
Trained batch 1407 in epoch 4, gen_loss = 0.9502189998853613, disc_loss = 0.0006280693499279137
Trained batch 1408 in epoch 4, gen_loss = 0.9503068277140387, disc_loss = 0.0006281055163731236
Trained batch 1409 in epoch 4, gen_loss = 0.9503485525330753, disc_loss = 0.0006280097601223566
Trained batch 1410 in epoch 4, gen_loss = 0.9503883242100203, disc_loss = 0.0006278909045949111
Trained batch 1411 in epoch 4, gen_loss = 0.9504377991805333, disc_loss = 0.0006276690699183184
Trained batch 1412 in epoch 4, gen_loss = 0.9506164846146942, disc_loss = 0.0006275568831786487
Trained batch 1413 in epoch 4, gen_loss = 0.9507854076305239, disc_loss = 0.0006274088374821501
Trained batch 1414 in epoch 4, gen_loss = 0.9508347223588519, disc_loss = 0.0006271734919691913
Trained batch 1415 in epoch 4, gen_loss = 0.950891639932064, disc_loss = 0.0006269374909997512
Trained batch 1416 in epoch 4, gen_loss = 0.9509296022255654, disc_loss = 0.0006266359256494373
Trained batch 1417 in epoch 4, gen_loss = 0.9509804414004633, disc_loss = 0.0006262989418079672
Trained batch 1418 in epoch 4, gen_loss = 0.9510417730981318, disc_loss = 0.0006259675173181121
Trained batch 1419 in epoch 4, gen_loss = 0.9511471983832372, disc_loss = 0.0006256972888954357
Trained batch 1420 in epoch 4, gen_loss = 0.9513760593304913, disc_loss = 0.0006254745665355176
Trained batch 1421 in epoch 4, gen_loss = 0.9514984464595087, disc_loss = 0.0006252157403492309
Trained batch 1422 in epoch 4, gen_loss = 0.9516055343105855, disc_loss = 0.0006249690909847225
Trained batch 1423 in epoch 4, gen_loss = 0.9516827591768141, disc_loss = 0.0006246878492879404
Trained batch 1424 in epoch 4, gen_loss = 0.9517814708592599, disc_loss = 0.0006243832493834034
Trained batch 1425 in epoch 4, gen_loss = 0.9518351068754183, disc_loss = 0.0006241846362909799
Trained batch 1426 in epoch 4, gen_loss = 0.9518892538238424, disc_loss = 0.0006239300211182598
Trained batch 1427 in epoch 4, gen_loss = 0.9519195289087563, disc_loss = 0.0006235990816805054
Trained batch 1428 in epoch 4, gen_loss = 0.9519587771470435, disc_loss = 0.0006232669673153109
Trained batch 1429 in epoch 4, gen_loss = 0.952017902535992, disc_loss = 0.0006230856033576932
Trained batch 1430 in epoch 4, gen_loss = 0.9520980746574456, disc_loss = 0.0006230854144510094
Trained batch 1431 in epoch 4, gen_loss = 0.9522409120668246, disc_loss = 0.000622953207215555
Trained batch 1432 in epoch 4, gen_loss = 0.9524219532322401, disc_loss = 0.0006227688606447766
Trained batch 1433 in epoch 4, gen_loss = 0.9525311979539225, disc_loss = 0.0006224358313454892
Trained batch 1434 in epoch 4, gen_loss = 0.9526390615240622, disc_loss = 0.0006221280507467532
Trained batch 1435 in epoch 4, gen_loss = 0.9526991931757887, disc_loss = 0.0006218314572271643
Trained batch 1436 in epoch 4, gen_loss = 0.9528378417861901, disc_loss = 0.0006215004416382091
Trained batch 1437 in epoch 4, gen_loss = 0.9529207583843252, disc_loss = 0.0006212004287370289
Trained batch 1438 in epoch 4, gen_loss = 0.9529670522890628, disc_loss = 0.0006209183248289673
Trained batch 1439 in epoch 4, gen_loss = 0.9530996939788262, disc_loss = 0.0006206415677297627
Trained batch 1440 in epoch 4, gen_loss = 0.9531317321398786, disc_loss = 0.0006204667168871049
Trained batch 1441 in epoch 4, gen_loss = 0.9532537636412992, disc_loss = 0.0006202740591555774
Trained batch 1442 in epoch 4, gen_loss = 0.953338556378894, disc_loss = 0.0006200123598942874
Trained batch 1443 in epoch 4, gen_loss = 0.9533809686796817, disc_loss = 0.0006197144167972284
Trained batch 1444 in epoch 4, gen_loss = 0.9534497093576874, disc_loss = 0.0006194454144181322
Trained batch 1445 in epoch 4, gen_loss = 0.9535272926875334, disc_loss = 0.0006191479899890091
Trained batch 1446 in epoch 4, gen_loss = 0.9535238448306455, disc_loss = 0.0006188441518128257
Trained batch 1447 in epoch 4, gen_loss = 0.9535919390412984, disc_loss = 0.0006185562451216823
Trained batch 1448 in epoch 4, gen_loss = 0.9535441478833896, disc_loss = 0.0006187343217037699
Trained batch 1449 in epoch 4, gen_loss = 0.9537810093369977, disc_loss = 0.0006195486772801438
Trained batch 1450 in epoch 4, gen_loss = 0.9539684641780235, disc_loss = 0.0006194908815165044
Trained batch 1451 in epoch 4, gen_loss = 0.9541124104221991, disc_loss = 0.0006195397887274863
Trained batch 1452 in epoch 4, gen_loss = 0.954218673484537, disc_loss = 0.00061951090600904
Trained batch 1453 in epoch 4, gen_loss = 0.9543226137039914, disc_loss = 0.0006194465532635487
Trained batch 1454 in epoch 4, gen_loss = 0.9543824097135223, disc_loss = 0.0006191470764783016
Trained batch 1455 in epoch 4, gen_loss = 0.9544874599592371, disc_loss = 0.0006189408210387797
Trained batch 1456 in epoch 4, gen_loss = 0.9546170182725544, disc_loss = 0.0006186796003141151
Trained batch 1457 in epoch 4, gen_loss = 0.9546561123821143, disc_loss = 0.0006184877947891714
Trained batch 1458 in epoch 4, gen_loss = 0.9547902512746449, disc_loss = 0.0006184488628243146
Trained batch 1459 in epoch 4, gen_loss = 0.9549017829029527, disc_loss = 0.0006184287443206875
Trained batch 1460 in epoch 4, gen_loss = 0.9550430961947667, disc_loss = 0.0006182241458098374
Trained batch 1461 in epoch 4, gen_loss = 0.9551082028002158, disc_loss = 0.0006180392328930685
Trained batch 1462 in epoch 4, gen_loss = 0.9550848760510339, disc_loss = 0.0006178836607178819
Trained batch 1463 in epoch 4, gen_loss = 0.9551416436424021, disc_loss = 0.0006178125023906746
Trained batch 1464 in epoch 4, gen_loss = 0.9551514553535514, disc_loss = 0.0006177077239336376
Trained batch 1465 in epoch 4, gen_loss = 0.9552932598337145, disc_loss = 0.000617505645243315
Trained batch 1466 in epoch 4, gen_loss = 0.9553542833955578, disc_loss = 0.0006173253301621542
Trained batch 1467 in epoch 4, gen_loss = 0.9553590570386165, disc_loss = 0.0006170953079423365
Trained batch 1468 in epoch 4, gen_loss = 0.9555569453820475, disc_loss = 0.000616796194071155
Trained batch 1469 in epoch 4, gen_loss = 0.9555907890910194, disc_loss = 0.0006166757484458444
Trained batch 1470 in epoch 4, gen_loss = 0.9556668667790033, disc_loss = 0.0006167553215754395
Trained batch 1471 in epoch 4, gen_loss = 0.9557652526089678, disc_loss = 0.000616601807025844
Trained batch 1472 in epoch 4, gen_loss = 0.955852742593303, disc_loss = 0.0006163740696559217
Trained batch 1473 in epoch 4, gen_loss = 0.9558368679464592, disc_loss = 0.0006161408377235554
Trained batch 1474 in epoch 4, gen_loss = 0.9559023630012901, disc_loss = 0.0006158493493656012
Trained batch 1475 in epoch 4, gen_loss = 0.9560645065979583, disc_loss = 0.0006155950286878219
Trained batch 1476 in epoch 4, gen_loss = 0.9561211302543542, disc_loss = 0.0006155008900107137
Trained batch 1477 in epoch 4, gen_loss = 0.9561914441872675, disc_loss = 0.0006152826842280257
Trained batch 1478 in epoch 4, gen_loss = 0.9563018829134206, disc_loss = 0.0006152312536458652
Trained batch 1479 in epoch 4, gen_loss = 0.9563456695627521, disc_loss = 0.0006150963834099113
Trained batch 1480 in epoch 4, gen_loss = 0.9564000925125905, disc_loss = 0.0006148674603081406
Trained batch 1481 in epoch 4, gen_loss = 0.9564048869889757, disc_loss = 0.0006145936654915678
Trained batch 1482 in epoch 4, gen_loss = 0.9564132280069996, disc_loss = 0.0006142741005553877
Trained batch 1483 in epoch 4, gen_loss = 0.9565500579673968, disc_loss = 0.0006139927522695562
Trained batch 1484 in epoch 4, gen_loss = 0.9566382146844961, disc_loss = 0.0006136713563507698
Trained batch 1485 in epoch 4, gen_loss = 0.956752720182388, disc_loss = 0.0006133385296412906
Trained batch 1486 in epoch 4, gen_loss = 0.9568548733625303, disc_loss = 0.0006129990556654216
Trained batch 1487 in epoch 4, gen_loss = 0.956920815531605, disc_loss = 0.0006127342341094708
Trained batch 1488 in epoch 4, gen_loss = 0.9569625838880494, disc_loss = 0.0006124665385824888
Trained batch 1489 in epoch 4, gen_loss = 0.9569929964990423, disc_loss = 0.0006121807810600422
Trained batch 1490 in epoch 4, gen_loss = 0.9570392932690365, disc_loss = 0.0006118934077793504
Trained batch 1491 in epoch 4, gen_loss = 0.9572669327179165, disc_loss = 0.0006116962360499686
Trained batch 1492 in epoch 4, gen_loss = 0.9573569823572959, disc_loss = 0.0006114969564379085
Trained batch 1493 in epoch 4, gen_loss = 0.9574581726567652, disc_loss = 0.0006112611592405038
Trained batch 1494 in epoch 4, gen_loss = 0.9575771266800105, disc_loss = 0.0006109877781129527
Trained batch 1495 in epoch 4, gen_loss = 0.9576003968237555, disc_loss = 0.0006107388602355389
Trained batch 1496 in epoch 4, gen_loss = 0.9577425307405736, disc_loss = 0.0006104584766168312
Trained batch 1497 in epoch 4, gen_loss = 0.9578284099996488, disc_loss = 0.000610160356551006
Trained batch 1498 in epoch 4, gen_loss = 0.9578669086307426, disc_loss = 0.0006098433766332955
Trained batch 1499 in epoch 4, gen_loss = 0.9579708637396495, disc_loss = 0.0006095338276160571
Trained batch 1500 in epoch 4, gen_loss = 0.9581246810464522, disc_loss = 0.0006092523443386198
Trained batch 1501 in epoch 4, gen_loss = 0.958298859281959, disc_loss = 0.0006090490369703007
Trained batch 1502 in epoch 4, gen_loss = 0.9584224683319975, disc_loss = 0.0006087797144692018
Trained batch 1503 in epoch 4, gen_loss = 0.9584679658267092, disc_loss = 0.0006084945779587136
Trained batch 1504 in epoch 4, gen_loss = 0.9586360483866594, disc_loss = 0.0006082600996805591
Trained batch 1505 in epoch 4, gen_loss = 0.9586373087102832, disc_loss = 0.0006080491366833455
Trained batch 1506 in epoch 4, gen_loss = 0.9587776330265686, disc_loss = 0.0006077703386783111
Trained batch 1507 in epoch 4, gen_loss = 0.9587992343567411, disc_loss = 0.0006075462417926242
Trained batch 1508 in epoch 4, gen_loss = 0.9589086070291407, disc_loss = 0.0006074267891820426
Trained batch 1509 in epoch 4, gen_loss = 0.9589674565965766, disc_loss = 0.0006071909281250941
Trained batch 1510 in epoch 4, gen_loss = 0.9590950199975469, disc_loss = 0.000607007881067909
Trained batch 1511 in epoch 4, gen_loss = 0.9592310009652345, disc_loss = 0.0006067811077940783
Trained batch 1512 in epoch 4, gen_loss = 0.9593126004843703, disc_loss = 0.0006065074879471741
Trained batch 1513 in epoch 4, gen_loss = 0.9593690230635388, disc_loss = 0.0006062142529838277
Trained batch 1514 in epoch 4, gen_loss = 0.9594364618704264, disc_loss = 0.0006059308067519716
Trained batch 1515 in epoch 4, gen_loss = 0.9595995639748184, disc_loss = 0.0006056677436983332
Trained batch 1516 in epoch 4, gen_loss = 0.9597022225374285, disc_loss = 0.0006054640631747801
Trained batch 1517 in epoch 4, gen_loss = 0.959799254364647, disc_loss = 0.0006052310912720632
Trained batch 1518 in epoch 4, gen_loss = 0.959883796690011, disc_loss = 0.0006050575765350544
Trained batch 1519 in epoch 4, gen_loss = 0.9599620757134337, disc_loss = 0.0006049348901222785
Trained batch 1520 in epoch 4, gen_loss = 0.9601573985630866, disc_loss = 0.0006047819132606953
Trained batch 1521 in epoch 4, gen_loss = 0.960198493025776, disc_loss = 0.0006045583472667481
Trained batch 1522 in epoch 4, gen_loss = 0.9602176603406805, disc_loss = 0.0006043529414388523
Trained batch 1523 in epoch 4, gen_loss = 0.9602778599722179, disc_loss = 0.0006040820555517474
Trained batch 1524 in epoch 4, gen_loss = 0.9603559424056382, disc_loss = 0.0006037938482696801
Trained batch 1525 in epoch 4, gen_loss = 0.9604842263233615, disc_loss = 0.0006035416042238417
Trained batch 1526 in epoch 4, gen_loss = 0.9604958709970985, disc_loss = 0.0006033383306143617
Trained batch 1527 in epoch 4, gen_loss = 0.9605878109005109, disc_loss = 0.0006031481231363485
Trained batch 1528 in epoch 4, gen_loss = 0.960632216119548, disc_loss = 0.0006029351556626745
Trained batch 1529 in epoch 4, gen_loss = 0.960634114929274, disc_loss = 0.0006027381375448754
Trained batch 1530 in epoch 4, gen_loss = 0.9607689340935277, disc_loss = 0.000602610196123188
Trained batch 1531 in epoch 4, gen_loss = 0.9608250523360529, disc_loss = 0.0006023408398554993
Trained batch 1532 in epoch 4, gen_loss = 0.9609058153683736, disc_loss = 0.0006020961479074732
Trained batch 1533 in epoch 4, gen_loss = 0.9610042440689216, disc_loss = 0.0006019107859506274
Trained batch 1534 in epoch 4, gen_loss = 0.9609839352412022, disc_loss = 0.000601853912607888
Trained batch 1535 in epoch 4, gen_loss = 0.9610473406501114, disc_loss = 0.0006016418527773718
Trained batch 1536 in epoch 4, gen_loss = 0.9611195778024608, disc_loss = 0.000601469960051047
Trained batch 1537 in epoch 4, gen_loss = 0.9611313775162393, disc_loss = 0.000601324939628974
Trained batch 1538 in epoch 4, gen_loss = 0.9611795011706907, disc_loss = 0.0006010991057125813
Trained batch 1539 in epoch 4, gen_loss = 0.961174424631255, disc_loss = 0.0006008433658185917
Trained batch 1540 in epoch 4, gen_loss = 0.961299129502484, disc_loss = 0.0006006773146816561
Trained batch 1541 in epoch 4, gen_loss = 0.9613699791264442, disc_loss = 0.0006004955877336896
Trained batch 1542 in epoch 4, gen_loss = 0.9613689306642974, disc_loss = 0.000600363616192184
Trained batch 1543 in epoch 4, gen_loss = 0.9615261527309146, disc_loss = 0.0006002104448289833
Trained batch 1544 in epoch 4, gen_loss = 0.9617182127866158, disc_loss = 0.0006000286287007986
Trained batch 1545 in epoch 4, gen_loss = 0.9617411333098911, disc_loss = 0.0005999334978668187
Trained batch 1546 in epoch 4, gen_loss = 0.9617750339532716, disc_loss = 0.0005997317632075259
Trained batch 1547 in epoch 4, gen_loss = 0.9618604729187888, disc_loss = 0.0005994975156327036
Trained batch 1548 in epoch 4, gen_loss = 0.9619260889395658, disc_loss = 0.0005992660817420086
Trained batch 1549 in epoch 4, gen_loss = 0.9620004671619784, disc_loss = 0.0005990528932964099
Trained batch 1550 in epoch 4, gen_loss = 0.9620789562326182, disc_loss = 0.0005987560724551195
Trained batch 1551 in epoch 4, gen_loss = 0.9620786425993615, disc_loss = 0.0005984439514399241
Trained batch 1552 in epoch 4, gen_loss = 0.9621037610177448, disc_loss = 0.0005981695060368225
Trained batch 1553 in epoch 4, gen_loss = 0.9622199852187354, disc_loss = 0.0005979530901272114
Trained batch 1554 in epoch 4, gen_loss = 0.962378942161511, disc_loss = 0.0005976723312818403
Trained batch 1555 in epoch 4, gen_loss = 0.9623943017197145, disc_loss = 0.0005973994949461691
Trained batch 1556 in epoch 4, gen_loss = 0.9625284806535117, disc_loss = 0.0005971729682193421
Trained batch 1557 in epoch 4, gen_loss = 0.9625242912570381, disc_loss = 0.0005969761717614054
Trained batch 1558 in epoch 4, gen_loss = 0.9626351561280226, disc_loss = 0.000596766789712278
Trained batch 1559 in epoch 4, gen_loss = 0.962710867401881, disc_loss = 0.0005965434139934354
Trained batch 1560 in epoch 4, gen_loss = 0.962790022974668, disc_loss = 0.000596299732894949
Trained batch 1561 in epoch 4, gen_loss = 0.9628218441400271, disc_loss = 0.0005960308719921942
Trained batch 1562 in epoch 4, gen_loss = 0.9628542110238103, disc_loss = 0.0005957793519817372
Trained batch 1563 in epoch 4, gen_loss = 0.96292294763848, disc_loss = 0.0005954996780500925
Trained batch 1564 in epoch 4, gen_loss = 0.9630174012991567, disc_loss = 0.0005952156396791377
Trained batch 1565 in epoch 4, gen_loss = 0.9631822070399464, disc_loss = 0.0005949277751946374
Trained batch 1566 in epoch 4, gen_loss = 0.9632320029003725, disc_loss = 0.0005946095625589998
Trained batch 1567 in epoch 4, gen_loss = 0.9632925016387385, disc_loss = 0.0005943292271323878
Trained batch 1568 in epoch 4, gen_loss = 0.9632474536573605, disc_loss = 0.0005940863625907712
Trained batch 1569 in epoch 4, gen_loss = 0.9633009570419409, disc_loss = 0.0005938429001419935
Trained batch 1570 in epoch 4, gen_loss = 0.9634035598844726, disc_loss = 0.000593586716653686
Trained batch 1571 in epoch 4, gen_loss = 0.9634721576409182, disc_loss = 0.0005933793266590432
Trained batch 1572 in epoch 4, gen_loss = 0.9635292744075729, disc_loss = 0.000593149698927696
Trained batch 1573 in epoch 4, gen_loss = 0.9635713141331073, disc_loss = 0.0005929494869018541
Trained batch 1574 in epoch 4, gen_loss = 0.9636326728548322, disc_loss = 0.0005927012932010083
Trained batch 1575 in epoch 4, gen_loss = 0.9636905555646431, disc_loss = 0.0005924850305155136
Trained batch 1576 in epoch 4, gen_loss = 0.9638045902258244, disc_loss = 0.0005922946744553713
Trained batch 1577 in epoch 4, gen_loss = 0.9639011579170276, disc_loss = 0.0005920329652214658
Trained batch 1578 in epoch 4, gen_loss = 0.9640055009275391, disc_loss = 0.0005917794502737205
Trained batch 1579 in epoch 4, gen_loss = 0.9641439653650115, disc_loss = 0.0005914975934616979
Trained batch 1580 in epoch 4, gen_loss = 0.9642513041101175, disc_loss = 0.0005912310202851371
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0691777467727661, disc_loss = 0.00019165067351423204
Trained batch 1 in epoch 5, gen_loss = 1.1036001443862915, disc_loss = 0.0001895645254990086
Trained batch 2 in epoch 5, gen_loss = 1.1046160062154133, disc_loss = 0.0001636049176643913
Trained batch 3 in epoch 5, gen_loss = 1.0790300965309143, disc_loss = 0.0001583940647833515
Trained batch 4 in epoch 5, gen_loss = 1.0725900650024414, disc_loss = 0.0001480568913393654
Trained batch 5 in epoch 5, gen_loss = 1.0611724853515625, disc_loss = 0.00014174971389972293
Trained batch 6 in epoch 5, gen_loss = 1.047561662537711, disc_loss = 0.0001419684537852715
Trained batch 7 in epoch 5, gen_loss = 1.0382180660963058, disc_loss = 0.000162030699357274
Trained batch 8 in epoch 5, gen_loss = 1.0427505042817857, disc_loss = 0.00019738756398308196
Trained batch 9 in epoch 5, gen_loss = 1.045310914516449, disc_loss = 0.0002198791000409983
Trained batch 10 in epoch 5, gen_loss = 1.044967998157848, disc_loss = 0.00022745323605539107
Trained batch 11 in epoch 5, gen_loss = 1.0543844203154247, disc_loss = 0.0002371906848566141
Trained batch 12 in epoch 5, gen_loss = 1.0541431445341845, disc_loss = 0.00023600942670152738
Trained batch 13 in epoch 5, gen_loss = 1.057133138179779, disc_loss = 0.00024218493490479887
Trained batch 14 in epoch 5, gen_loss = 1.0529671351114909, disc_loss = 0.0002463626772320519
Trained batch 15 in epoch 5, gen_loss = 1.0498729944229126, disc_loss = 0.00024535279590054415
Trained batch 16 in epoch 5, gen_loss = 1.042967505314771, disc_loss = 0.00025612765389001547
Trained batch 17 in epoch 5, gen_loss = 1.0443318982919056, disc_loss = 0.0002633665895296468
Trained batch 18 in epoch 5, gen_loss = 1.051568423446856, disc_loss = 0.00027073822351858805
Trained batch 19 in epoch 5, gen_loss = 1.0536262482404708, disc_loss = 0.00027756617055274546
Trained batch 20 in epoch 5, gen_loss = 1.0520680262928916, disc_loss = 0.00029056313880054016
Trained batch 21 in epoch 5, gen_loss = 1.0498456494374708, disc_loss = 0.00029645520077213985
Trained batch 22 in epoch 5, gen_loss = 1.0513579715853152, disc_loss = 0.00029785613119399744
Trained batch 23 in epoch 5, gen_loss = 1.0570561662316322, disc_loss = 0.00030276612960733473
Trained batch 24 in epoch 5, gen_loss = 1.0525316882133484, disc_loss = 0.00030354423564858733
Trained batch 25 in epoch 5, gen_loss = 1.0520777633556953, disc_loss = 0.00029913423909769894
Trained batch 26 in epoch 5, gen_loss = 1.0496520046834592, disc_loss = 0.00029223778956630095
Trained batch 27 in epoch 5, gen_loss = 1.0531288364103861, disc_loss = 0.00028769354451339623
Trained batch 28 in epoch 5, gen_loss = 1.0546760291888797, disc_loss = 0.00028367299443022507
Trained batch 29 in epoch 5, gen_loss = 1.0568667431672414, disc_loss = 0.00028138999890264436
Trained batch 30 in epoch 5, gen_loss = 1.0558689621187025, disc_loss = 0.00027681406866195764
Trained batch 31 in epoch 5, gen_loss = 1.0575863923877478, disc_loss = 0.00027223295705880446
Trained batch 32 in epoch 5, gen_loss = 1.0606802467143897, disc_loss = 0.0002678775986582464
Trained batch 33 in epoch 5, gen_loss = 1.0586930022520178, disc_loss = 0.0002681824611071908
Trained batch 34 in epoch 5, gen_loss = 1.0581743785313198, disc_loss = 0.00026677539052408455
Trained batch 35 in epoch 5, gen_loss = 1.0544511311584048, disc_loss = 0.0002684517528703307
Trained batch 36 in epoch 5, gen_loss = 1.061483309075639, disc_loss = 0.00027319472467973575
Trained batch 37 in epoch 5, gen_loss = 1.0589410725392794, disc_loss = 0.0002748250636183289
Trained batch 38 in epoch 5, gen_loss = 1.0595261530998425, disc_loss = 0.00027729539131262124
Trained batch 39 in epoch 5, gen_loss = 1.0601580768823624, disc_loss = 0.0002766061797956354
Trained batch 40 in epoch 5, gen_loss = 1.0592152025641464, disc_loss = 0.0002768951233564422
Trained batch 41 in epoch 5, gen_loss = 1.0637363536017281, disc_loss = 0.00027888950699846084
Trained batch 42 in epoch 5, gen_loss = 1.06189179974933, disc_loss = 0.00027803346960734966
Trained batch 43 in epoch 5, gen_loss = 1.0629877691919154, disc_loss = 0.0002780255617835792
Trained batch 44 in epoch 5, gen_loss = 1.0605075743463304, disc_loss = 0.00027820866073145425
Trained batch 45 in epoch 5, gen_loss = 1.061172981625018, disc_loss = 0.00027684274407321305
Trained batch 46 in epoch 5, gen_loss = 1.0630229014031432, disc_loss = 0.0002742393883230026
Trained batch 47 in epoch 5, gen_loss = 1.0646879511574905, disc_loss = 0.00027271265101565706
Trained batch 48 in epoch 5, gen_loss = 1.0631884713562167, disc_loss = 0.00027045300803551147
Trained batch 49 in epoch 5, gen_loss = 1.0655957138538361, disc_loss = 0.0002699375904921908
Trained batch 50 in epoch 5, gen_loss = 1.0627337121496014, disc_loss = 0.00026963953075441986
Trained batch 51 in epoch 5, gen_loss = 1.0644394675126443, disc_loss = 0.00027004267884387024
Trained batch 52 in epoch 5, gen_loss = 1.0627318755635675, disc_loss = 0.0002679345847320532
Trained batch 53 in epoch 5, gen_loss = 1.0634798297175654, disc_loss = 0.0002676936593262427
Trained batch 54 in epoch 5, gen_loss = 1.064262860471552, disc_loss = 0.00026688161107647995
Trained batch 55 in epoch 5, gen_loss = 1.0644003642456872, disc_loss = 0.0002649229789832524
Trained batch 56 in epoch 5, gen_loss = 1.0640799601872761, disc_loss = 0.0002625548425528809
Trained batch 57 in epoch 5, gen_loss = 1.0648135131803051, disc_loss = 0.00026305131792343735
Trained batch 58 in epoch 5, gen_loss = 1.067111280004857, disc_loss = 0.0002693569940520782
Trained batch 59 in epoch 5, gen_loss = 1.0670044481754304, disc_loss = 0.00027466348583402576
Trained batch 60 in epoch 5, gen_loss = 1.0677598480318413, disc_loss = 0.0002754011088132965
Trained batch 61 in epoch 5, gen_loss = 1.0678725473342403, disc_loss = 0.00027668447928003696
Trained batch 62 in epoch 5, gen_loss = 1.0686277094341459, disc_loss = 0.0002776903190626024
Trained batch 63 in epoch 5, gen_loss = 1.0678662862628698, disc_loss = 0.0002774129119416102
Trained batch 64 in epoch 5, gen_loss = 1.0683499336242677, disc_loss = 0.0002778328251084671
Trained batch 65 in epoch 5, gen_loss = 1.0679670644528938, disc_loss = 0.00027539180904789123
Trained batch 66 in epoch 5, gen_loss = 1.067567604691235, disc_loss = 0.00027320644824327763
Trained batch 67 in epoch 5, gen_loss = 1.0672872960567474, disc_loss = 0.0002705374566122533
Trained batch 68 in epoch 5, gen_loss = 1.0644045618997104, disc_loss = 0.0002684434740871623
Trained batch 69 in epoch 5, gen_loss = 1.0652487295014517, disc_loss = 0.0002664129761147446
Trained batch 70 in epoch 5, gen_loss = 1.0644614243171584, disc_loss = 0.00026553933665280976
Trained batch 71 in epoch 5, gen_loss = 1.063589397403929, disc_loss = 0.0002657151924520602
Trained batch 72 in epoch 5, gen_loss = 1.063395418532907, disc_loss = 0.0002648232832442561
Trained batch 73 in epoch 5, gen_loss = 1.0637555895624935, disc_loss = 0.0002630161791269013
Trained batch 74 in epoch 5, gen_loss = 1.0638900820414225, disc_loss = 0.0002619414933724329
Trained batch 75 in epoch 5, gen_loss = 1.0636618262843083, disc_loss = 0.00026181202797727706
Trained batch 76 in epoch 5, gen_loss = 1.0625933362292004, disc_loss = 0.00026388340172291337
Trained batch 77 in epoch 5, gen_loss = 1.0628537489817693, disc_loss = 0.00026337398706415953
Trained batch 78 in epoch 5, gen_loss = 1.0636114606374427, disc_loss = 0.00026232952858421573
Trained batch 79 in epoch 5, gen_loss = 1.0638592138886451, disc_loss = 0.0002627301690154127
Trained batch 80 in epoch 5, gen_loss = 1.0644305811987982, disc_loss = 0.00026252465433998745
Trained batch 81 in epoch 5, gen_loss = 1.0638474691204909, disc_loss = 0.0002617874083736707
Trained batch 82 in epoch 5, gen_loss = 1.0647577521312668, disc_loss = 0.0002602809485740937
Trained batch 83 in epoch 5, gen_loss = 1.0647747686931066, disc_loss = 0.0002591231899541093
Trained batch 84 in epoch 5, gen_loss = 1.0641850078807158, disc_loss = 0.0002575189042973387
Trained batch 85 in epoch 5, gen_loss = 1.065492599509483, disc_loss = 0.0002563385716585313
Trained batch 86 in epoch 5, gen_loss = 1.065580861321811, disc_loss = 0.0002549510160139922
Trained batch 87 in epoch 5, gen_loss = 1.065572221170772, disc_loss = 0.00025352635665595614
Trained batch 88 in epoch 5, gen_loss = 1.0651239880015342, disc_loss = 0.0002522341471447955
Trained batch 89 in epoch 5, gen_loss = 1.064943540096283, disc_loss = 0.00025148709860837293
Trained batch 90 in epoch 5, gen_loss = 1.06493813257951, disc_loss = 0.00025010030751198447
Trained batch 91 in epoch 5, gen_loss = 1.0641610272552655, disc_loss = 0.00024929895754093707
Trained batch 92 in epoch 5, gen_loss = 1.063066215284409, disc_loss = 0.0002493631709316966
Trained batch 93 in epoch 5, gen_loss = 1.0618639880038323, disc_loss = 0.0002513779853619239
Trained batch 94 in epoch 5, gen_loss = 1.0631431353719611, disc_loss = 0.0002525092718363004
Trained batch 95 in epoch 5, gen_loss = 1.0631243127087753, disc_loss = 0.00025319661957231193
Trained batch 96 in epoch 5, gen_loss = 1.062263889411061, disc_loss = 0.0002530178264594762
Trained batch 97 in epoch 5, gen_loss = 1.0608386105420637, disc_loss = 0.00025274686703021274
Trained batch 98 in epoch 5, gen_loss = 1.0604801876376373, disc_loss = 0.0002529237726867914
Trained batch 99 in epoch 5, gen_loss = 1.0616781949996947, disc_loss = 0.000253443096880801
Trained batch 100 in epoch 5, gen_loss = 1.0610995044802676, disc_loss = 0.000253460462214333
Trained batch 101 in epoch 5, gen_loss = 1.0610671195329404, disc_loss = 0.0002536008131060311
Trained batch 102 in epoch 5, gen_loss = 1.060797411261253, disc_loss = 0.0002531059114861492
Trained batch 103 in epoch 5, gen_loss = 1.0632532387971878, disc_loss = 0.00025543779464407213
Trained batch 104 in epoch 5, gen_loss = 1.063679331824893, disc_loss = 0.0002560298475492302
Trained batch 105 in epoch 5, gen_loss = 1.063825195690371, disc_loss = 0.0002563829180391347
Trained batch 106 in epoch 5, gen_loss = 1.0636883361317286, disc_loss = 0.000255681932430549
Trained batch 107 in epoch 5, gen_loss = 1.0644955303933885, disc_loss = 0.0002546164823461031
Trained batch 108 in epoch 5, gen_loss = 1.0639440357138257, disc_loss = 0.00025375393299928466
Trained batch 109 in epoch 5, gen_loss = 1.064472612467679, disc_loss = 0.00025284153208221223
Trained batch 110 in epoch 5, gen_loss = 1.0647511374843013, disc_loss = 0.000252666772261413
Trained batch 111 in epoch 5, gen_loss = 1.0643211773463659, disc_loss = 0.000252637854958136
Trained batch 112 in epoch 5, gen_loss = 1.0634551174872744, disc_loss = 0.00025280507588429396
Trained batch 113 in epoch 5, gen_loss = 1.063609058396858, disc_loss = 0.0002529984745993524
Trained batch 114 in epoch 5, gen_loss = 1.062799963225489, disc_loss = 0.00025217616310565854
Trained batch 115 in epoch 5, gen_loss = 1.0619587923946052, disc_loss = 0.0002523185779362644
Trained batch 116 in epoch 5, gen_loss = 1.0621354116333857, disc_loss = 0.0002520474753020188
Trained batch 117 in epoch 5, gen_loss = 1.06080406954733, disc_loss = 0.0002529921160095324
Trained batch 118 in epoch 5, gen_loss = 1.0618293380536954, disc_loss = 0.00025390235251285324
Trained batch 119 in epoch 5, gen_loss = 1.0616338784495989, disc_loss = 0.0002533864117140183
Trained batch 120 in epoch 5, gen_loss = 1.0611452401176957, disc_loss = 0.0002524395408840034
Trained batch 121 in epoch 5, gen_loss = 1.0607580215227408, disc_loss = 0.0002527118085112545
Trained batch 122 in epoch 5, gen_loss = 1.0606721450642842, disc_loss = 0.00025283208928956856
Trained batch 123 in epoch 5, gen_loss = 1.0586036559074157, disc_loss = 0.0002532843763249055
Trained batch 124 in epoch 5, gen_loss = 1.0594175930023193, disc_loss = 0.00025427509052678945
Trained batch 125 in epoch 5, gen_loss = 1.059527337551117, disc_loss = 0.0002539267959599827
Trained batch 126 in epoch 5, gen_loss = 1.0591641927328634, disc_loss = 0.0002536123377173831
Trained batch 127 in epoch 5, gen_loss = 1.0592248337343335, disc_loss = 0.0002534571675596453
Trained batch 128 in epoch 5, gen_loss = 1.0581348482952562, disc_loss = 0.000254544081475925
Trained batch 129 in epoch 5, gen_loss = 1.0570633567296541, disc_loss = 0.0002558829772169702
Trained batch 130 in epoch 5, gen_loss = 1.0562742470784952, disc_loss = 0.0002552043743883011
Trained batch 131 in epoch 5, gen_loss = 1.055244557333715, disc_loss = 0.0002551884123628649
Trained batch 132 in epoch 5, gen_loss = 1.0548552655635919, disc_loss = 0.0002550774072717063
Trained batch 133 in epoch 5, gen_loss = 1.0546814554662847, disc_loss = 0.0002546629464686431
Trained batch 134 in epoch 5, gen_loss = 1.0557405767617403, disc_loss = 0.0002546903020831653
Trained batch 135 in epoch 5, gen_loss = 1.0562088222188108, disc_loss = 0.0002547226269919466
Trained batch 136 in epoch 5, gen_loss = 1.0562804741580991, disc_loss = 0.0002551149723696162
Trained batch 137 in epoch 5, gen_loss = 1.0556069163308628, disc_loss = 0.0002552196002806591
Trained batch 138 in epoch 5, gen_loss = 1.0555482390973208, disc_loss = 0.000255213649554024
Trained batch 139 in epoch 5, gen_loss = 1.0553331221852984, disc_loss = 0.0002543252430249205
Trained batch 140 in epoch 5, gen_loss = 1.05530472681032, disc_loss = 0.00025456476180916586
Trained batch 141 in epoch 5, gen_loss = 1.0548003332715639, disc_loss = 0.00025498822036701006
Trained batch 142 in epoch 5, gen_loss = 1.0542590768187197, disc_loss = 0.0002550143978299599
Trained batch 143 in epoch 5, gen_loss = 1.054953175286452, disc_loss = 0.00025490833245890424
Trained batch 144 in epoch 5, gen_loss = 1.0550272407202885, disc_loss = 0.0002544393287249038
Trained batch 145 in epoch 5, gen_loss = 1.0549321133796483, disc_loss = 0.0002542200898161566
Trained batch 146 in epoch 5, gen_loss = 1.0556718613825689, disc_loss = 0.0002538352626808254
Trained batch 147 in epoch 5, gen_loss = 1.0557854715231303, disc_loss = 0.00025341400494751824
Trained batch 148 in epoch 5, gen_loss = 1.0554679056142, disc_loss = 0.00025308208046684154
Trained batch 149 in epoch 5, gen_loss = 1.0545976134141286, disc_loss = 0.0002543439623938563
Trained batch 150 in epoch 5, gen_loss = 1.0542468160193488, disc_loss = 0.000253853030404113
Trained batch 151 in epoch 5, gen_loss = 1.053966944547076, disc_loss = 0.00025322793111339897
Trained batch 152 in epoch 5, gen_loss = 1.0529218888750262, disc_loss = 0.0002530053455011274
Trained batch 153 in epoch 5, gen_loss = 1.053059382872148, disc_loss = 0.0002531034338239629
Trained batch 154 in epoch 5, gen_loss = 1.052905947162259, disc_loss = 0.0002541440985946646
Trained batch 155 in epoch 5, gen_loss = 1.053847801226836, disc_loss = 0.0002558316198888068
Trained batch 156 in epoch 5, gen_loss = 1.0540338891327001, disc_loss = 0.00025642446018340196
Trained batch 157 in epoch 5, gen_loss = 1.0538727874997296, disc_loss = 0.000256491048759604
Trained batch 158 in epoch 5, gen_loss = 1.0539453299540393, disc_loss = 0.0002564106567809651
Trained batch 159 in epoch 5, gen_loss = 1.0535695858299732, disc_loss = 0.0002559173271947657
Trained batch 160 in epoch 5, gen_loss = 1.0535530903324577, disc_loss = 0.00025562491786365415
Trained batch 161 in epoch 5, gen_loss = 1.054018861717648, disc_loss = 0.00025486092609180896
Trained batch 162 in epoch 5, gen_loss = 1.0533632884727666, disc_loss = 0.00025409700335046287
Trained batch 163 in epoch 5, gen_loss = 1.0540406773003137, disc_loss = 0.00025441906269051975
Trained batch 164 in epoch 5, gen_loss = 1.0542820999116609, disc_loss = 0.00025429573954280577
Trained batch 165 in epoch 5, gen_loss = 1.0539234916129745, disc_loss = 0.00025447372523142045
Trained batch 166 in epoch 5, gen_loss = 1.05394585796459, disc_loss = 0.0002544792733241631
Trained batch 167 in epoch 5, gen_loss = 1.0535986512189819, disc_loss = 0.0002556976162720405
Trained batch 168 in epoch 5, gen_loss = 1.054377960382834, disc_loss = 0.0002578584948821908
Trained batch 169 in epoch 5, gen_loss = 1.0544182998292586, disc_loss = 0.00026048752838773103
Trained batch 170 in epoch 5, gen_loss = 1.0550296093985352, disc_loss = 0.0002626951816913873
Trained batch 171 in epoch 5, gen_loss = 1.0553105269060579, disc_loss = 0.00026312884065826143
Trained batch 172 in epoch 5, gen_loss = 1.0551758332748633, disc_loss = 0.00026352449728719716
Trained batch 173 in epoch 5, gen_loss = 1.0547709310876912, disc_loss = 0.00026371275929830455
Trained batch 174 in epoch 5, gen_loss = 1.0548312973976135, disc_loss = 0.00026410147714029465
Trained batch 175 in epoch 5, gen_loss = 1.0544417067007585, disc_loss = 0.0002649587411063046
Trained batch 176 in epoch 5, gen_loss = 1.0547494787280842, disc_loss = 0.00026613555152737404
Trained batch 177 in epoch 5, gen_loss = 1.0546314883767889, disc_loss = 0.00026724339277075414
Trained batch 178 in epoch 5, gen_loss = 1.0542737561897193, disc_loss = 0.000267715092524678
Trained batch 179 in epoch 5, gen_loss = 1.0550225956572428, disc_loss = 0.0002673289527592715
Trained batch 180 in epoch 5, gen_loss = 1.0549292561099015, disc_loss = 0.0002665253045283083
Trained batch 181 in epoch 5, gen_loss = 1.0549701357280814, disc_loss = 0.00026575209367265515
Trained batch 182 in epoch 5, gen_loss = 1.0547039440420807, disc_loss = 0.0002656275120371688
Trained batch 183 in epoch 5, gen_loss = 1.0549170021777567, disc_loss = 0.0002656407253633243
Trained batch 184 in epoch 5, gen_loss = 1.055099751176061, disc_loss = 0.0002653739088674302
Trained batch 185 in epoch 5, gen_loss = 1.0558194213656968, disc_loss = 0.00026515000354265794
Trained batch 186 in epoch 5, gen_loss = 1.0559010413241259, disc_loss = 0.0002644477784228984
Trained batch 187 in epoch 5, gen_loss = 1.0557455163686833, disc_loss = 0.0002639175815621708
Trained batch 188 in epoch 5, gen_loss = 1.0552045028045696, disc_loss = 0.00026360779845774194
Trained batch 189 in epoch 5, gen_loss = 1.0548643999978116, disc_loss = 0.0002630625767970311
Trained batch 190 in epoch 5, gen_loss = 1.0546283544046093, disc_loss = 0.0002623278929099821
Trained batch 191 in epoch 5, gen_loss = 1.0543951004122694, disc_loss = 0.0002617354359699675
Trained batch 192 in epoch 5, gen_loss = 1.054983047314876, disc_loss = 0.0002615071517666271
Trained batch 193 in epoch 5, gen_loss = 1.0545263305767296, disc_loss = 0.00026074482953732775
Trained batch 194 in epoch 5, gen_loss = 1.055125152453398, disc_loss = 0.0002604049308082232
Trained batch 195 in epoch 5, gen_loss = 1.0557327164070947, disc_loss = 0.0002600572224022174
Trained batch 196 in epoch 5, gen_loss = 1.0553678464768501, disc_loss = 0.0002593745901202074
Trained batch 197 in epoch 5, gen_loss = 1.0555695635501785, disc_loss = 0.0002585291059780631
Trained batch 198 in epoch 5, gen_loss = 1.0552259632690468, disc_loss = 0.0002576572853523709
Trained batch 199 in epoch 5, gen_loss = 1.0554231241345406, disc_loss = 0.00025706368785904487
Trained batch 200 in epoch 5, gen_loss = 1.0554930597395447, disc_loss = 0.0002566857725125274
Trained batch 201 in epoch 5, gen_loss = 1.0550070369597708, disc_loss = 0.00025631898969018805
Trained batch 202 in epoch 5, gen_loss = 1.0543736084341415, disc_loss = 0.000256217244573527
Trained batch 203 in epoch 5, gen_loss = 1.0541338347921185, disc_loss = 0.000255978613209913
Trained batch 204 in epoch 5, gen_loss = 1.0539447464594027, disc_loss = 0.0002557075654494394
Trained batch 205 in epoch 5, gen_loss = 1.0530179348385449, disc_loss = 0.0002566807319789343
Trained batch 206 in epoch 5, gen_loss = 1.0533704311375456, disc_loss = 0.00025736059762783805
Trained batch 207 in epoch 5, gen_loss = 1.0531470222541919, disc_loss = 0.00025805357455073344
Trained batch 208 in epoch 5, gen_loss = 1.052849190372029, disc_loss = 0.000258727478993885
Trained batch 209 in epoch 5, gen_loss = 1.052919975632713, disc_loss = 0.0002593881613782807
Trained batch 210 in epoch 5, gen_loss = 1.0524329625034785, disc_loss = 0.0002597388882789721
Trained batch 211 in epoch 5, gen_loss = 1.0522327726742007, disc_loss = 0.00025949830678483814
Trained batch 212 in epoch 5, gen_loss = 1.0518034097734192, disc_loss = 0.00025899397539813293
Trained batch 213 in epoch 5, gen_loss = 1.0524971819369593, disc_loss = 0.0002586841196674205
Trained batch 214 in epoch 5, gen_loss = 1.0518181806386904, disc_loss = 0.0002585134748166405
Trained batch 215 in epoch 5, gen_loss = 1.0512274909350607, disc_loss = 0.00025810580313258535
Trained batch 216 in epoch 5, gen_loss = 1.0510745573153693, disc_loss = 0.00025734873292061034
Trained batch 217 in epoch 5, gen_loss = 1.0512770444428154, disc_loss = 0.00025665865892116106
Trained batch 218 in epoch 5, gen_loss = 1.0513921586890198, disc_loss = 0.00025606635997425895
Trained batch 219 in epoch 5, gen_loss = 1.051347146521915, disc_loss = 0.0002556807670771377
Trained batch 220 in epoch 5, gen_loss = 1.0512533341597647, disc_loss = 0.00025530354656743694
Trained batch 221 in epoch 5, gen_loss = 1.0516004318052583, disc_loss = 0.0002553745572833315
Trained batch 222 in epoch 5, gen_loss = 1.0514393897869128, disc_loss = 0.00025520440728864067
Trained batch 223 in epoch 5, gen_loss = 1.0509106354521853, disc_loss = 0.0002556039084668425
Trained batch 224 in epoch 5, gen_loss = 1.050738086965349, disc_loss = 0.0002559829726103797
Trained batch 225 in epoch 5, gen_loss = 1.0504077406583634, disc_loss = 0.00025605156557841546
Trained batch 226 in epoch 5, gen_loss = 1.0508543035007258, disc_loss = 0.0002566257134064035
Trained batch 227 in epoch 5, gen_loss = 1.0510688698605488, disc_loss = 0.00025699289277294986
Trained batch 228 in epoch 5, gen_loss = 1.0508783313905308, disc_loss = 0.0002572706174656981
Trained batch 229 in epoch 5, gen_loss = 1.0510382603044095, disc_loss = 0.00025706781183860425
Trained batch 230 in epoch 5, gen_loss = 1.0511207629591872, disc_loss = 0.0002567129696528347
Trained batch 231 in epoch 5, gen_loss = 1.050408630792437, disc_loss = 0.0002564889500090744
Trained batch 232 in epoch 5, gen_loss = 1.0500315947082421, disc_loss = 0.0002557994926669595
Trained batch 233 in epoch 5, gen_loss = 1.0493856997061999, disc_loss = 0.00025523117257498053
Trained batch 234 in epoch 5, gen_loss = 1.0496772905613514, disc_loss = 0.00025507001193274964
Trained batch 235 in epoch 5, gen_loss = 1.0495564854246076, disc_loss = 0.0002554225476329921
Trained batch 236 in epoch 5, gen_loss = 1.0500070794725216, disc_loss = 0.0002561244872123109
Trained batch 237 in epoch 5, gen_loss = 1.0499711880663865, disc_loss = 0.00025632017545334547
Trained batch 238 in epoch 5, gen_loss = 1.0500445827280627, disc_loss = 0.00025594200166044603
Trained batch 239 in epoch 5, gen_loss = 1.0498533335824807, disc_loss = 0.0002555597625359951
Trained batch 240 in epoch 5, gen_loss = 1.05026959259975, disc_loss = 0.000255420133760112
Trained batch 241 in epoch 5, gen_loss = 1.0502775107040878, disc_loss = 0.0002553620656087806
Trained batch 242 in epoch 5, gen_loss = 1.0504168828819023, disc_loss = 0.00025528329869501347
Trained batch 243 in epoch 5, gen_loss = 1.0500263009892135, disc_loss = 0.00025522591174388355
Trained batch 244 in epoch 5, gen_loss = 1.0493237665721349, disc_loss = 0.0002553883247132109
Trained batch 245 in epoch 5, gen_loss = 1.049646593206297, disc_loss = 0.0002558157478241019
Trained batch 246 in epoch 5, gen_loss = 1.0495717250383818, disc_loss = 0.0002561328871784117
Trained batch 247 in epoch 5, gen_loss = 1.0499010898413197, disc_loss = 0.000256373222503997
Trained batch 248 in epoch 5, gen_loss = 1.0498511958792507, disc_loss = 0.00025661664567378173
Trained batch 249 in epoch 5, gen_loss = 1.0501061244010925, disc_loss = 0.00025701301064691505
Trained batch 250 in epoch 5, gen_loss = 1.0500642042236024, disc_loss = 0.0002573093495819165
Trained batch 251 in epoch 5, gen_loss = 1.0503840025455233, disc_loss = 0.00025759996866067274
Trained batch 252 in epoch 5, gen_loss = 1.050115445150217, disc_loss = 0.00025758373867071566
Trained batch 253 in epoch 5, gen_loss = 1.0499874609192525, disc_loss = 0.0002573651971062187
Trained batch 254 in epoch 5, gen_loss = 1.049841541636224, disc_loss = 0.00025709020130806513
Trained batch 255 in epoch 5, gen_loss = 1.0496455591637641, disc_loss = 0.00025713072201938303
Trained batch 256 in epoch 5, gen_loss = 1.0492846395255062, disc_loss = 0.0002568567245924603
Trained batch 257 in epoch 5, gen_loss = 1.0492906043695849, disc_loss = 0.0002568215508248148
Trained batch 258 in epoch 5, gen_loss = 1.0491079635141438, disc_loss = 0.00025679314286878663
Trained batch 259 in epoch 5, gen_loss = 1.048630692408635, disc_loss = 0.00025670336687583657
Trained batch 260 in epoch 5, gen_loss = 1.0493311014211955, disc_loss = 0.00025697325076305726
Trained batch 261 in epoch 5, gen_loss = 1.0495954392520526, disc_loss = 0.00025711150799157234
Trained batch 262 in epoch 5, gen_loss = 1.0492504001117025, disc_loss = 0.00025697986260804566
Trained batch 263 in epoch 5, gen_loss = 1.0493129622755628, disc_loss = 0.00025653326870131866
Trained batch 264 in epoch 5, gen_loss = 1.0487963210861637, disc_loss = 0.00025593981979840945
Trained batch 265 in epoch 5, gen_loss = 1.048377286894877, disc_loss = 0.0002555173965461142
Trained batch 266 in epoch 5, gen_loss = 1.0481696215908178, disc_loss = 0.0002552115500715826
Trained batch 267 in epoch 5, gen_loss = 1.0478043409425821, disc_loss = 0.0002548268115951127
Trained batch 268 in epoch 5, gen_loss = 1.0477638510523233, disc_loss = 0.0002543126195541507
Trained batch 269 in epoch 5, gen_loss = 1.0475267624413525, disc_loss = 0.00025376980077082946
Trained batch 270 in epoch 5, gen_loss = 1.0472924001102517, disc_loss = 0.0002531477242533798
Trained batch 271 in epoch 5, gen_loss = 1.0470748449511387, disc_loss = 0.00025272185864784713
Trained batch 272 in epoch 5, gen_loss = 1.0468915506596967, disc_loss = 0.00025235381001485475
Trained batch 273 in epoch 5, gen_loss = 1.046769542633182, disc_loss = 0.0002519029403363701
Trained batch 274 in epoch 5, gen_loss = 1.0469114492156288, disc_loss = 0.00025135855288350615
Trained batch 275 in epoch 5, gen_loss = 1.0468472326579301, disc_loss = 0.00025101813654422904
Trained batch 276 in epoch 5, gen_loss = 1.0469448779464199, disc_loss = 0.00025077286842619556
Trained batch 277 in epoch 5, gen_loss = 1.0467370133176983, disc_loss = 0.0002505948934622407
Trained batch 278 in epoch 5, gen_loss = 1.0467616172247036, disc_loss = 0.000250354641709455
Trained batch 279 in epoch 5, gen_loss = 1.0469498304384095, disc_loss = 0.00025006334864363975
Trained batch 280 in epoch 5, gen_loss = 1.0476146077346122, disc_loss = 0.0002497582007570315
Trained batch 281 in epoch 5, gen_loss = 1.0474666845291218, disc_loss = 0.00024932355998007167
Trained batch 282 in epoch 5, gen_loss = 1.0474067212414826, disc_loss = 0.00024878290228261003
Trained batch 283 in epoch 5, gen_loss = 1.047333891332989, disc_loss = 0.0002483289638508774
Trained batch 284 in epoch 5, gen_loss = 1.047293490066863, disc_loss = 0.00024790675343594335
Trained batch 285 in epoch 5, gen_loss = 1.0479251719438112, disc_loss = 0.0002479020100012845
Trained batch 286 in epoch 5, gen_loss = 1.0477363076774917, disc_loss = 0.0002475984336545477
Trained batch 287 in epoch 5, gen_loss = 1.047411648142669, disc_loss = 0.00024741666417564073
Trained batch 288 in epoch 5, gen_loss = 1.0472891658647663, disc_loss = 0.0002469142807174674
Trained batch 289 in epoch 5, gen_loss = 1.0470154922584007, disc_loss = 0.00024641264713738627
Trained batch 290 in epoch 5, gen_loss = 1.0471784159080268, disc_loss = 0.0002460309753456086
Trained batch 291 in epoch 5, gen_loss = 1.046846110730955, disc_loss = 0.000245618044423842
Trained batch 292 in epoch 5, gen_loss = 1.0467008460096938, disc_loss = 0.0002452818852743617
Trained batch 293 in epoch 5, gen_loss = 1.0465749629906245, disc_loss = 0.0002449178103722638
Trained batch 294 in epoch 5, gen_loss = 1.0462379093897545, disc_loss = 0.0002446588091808766
Trained batch 295 in epoch 5, gen_loss = 1.046457402005389, disc_loss = 0.0002445233069895924
Trained batch 296 in epoch 5, gen_loss = 1.046176379979259, disc_loss = 0.00024407399239262365
Trained batch 297 in epoch 5, gen_loss = 1.046200730856633, disc_loss = 0.00024363441694951336
Trained batch 298 in epoch 5, gen_loss = 1.0466220899170458, disc_loss = 0.00024336366072245702
Trained batch 299 in epoch 5, gen_loss = 1.046615364352862, disc_loss = 0.00024325124541064725
Trained batch 300 in epoch 5, gen_loss = 1.046628582319152, disc_loss = 0.00024306728196929077
Trained batch 301 in epoch 5, gen_loss = 1.046385197055261, disc_loss = 0.00024267018123896828
Trained batch 302 in epoch 5, gen_loss = 1.046420967224801, disc_loss = 0.0002422168479272604
Trained batch 303 in epoch 5, gen_loss = 1.0464181174573146, disc_loss = 0.00024200847029102364
Trained batch 304 in epoch 5, gen_loss = 1.0467755223883957, disc_loss = 0.0002420283817270099
Trained batch 305 in epoch 5, gen_loss = 1.0463358987780178, disc_loss = 0.00024188796075036616
Trained batch 306 in epoch 5, gen_loss = 1.0465135595697534, disc_loss = 0.00024198587731297464
Trained batch 307 in epoch 5, gen_loss = 1.0462382902185638, disc_loss = 0.00024179310833448664
Trained batch 308 in epoch 5, gen_loss = 1.0463078344138308, disc_loss = 0.00024190391801918545
Trained batch 309 in epoch 5, gen_loss = 1.04669596437485, disc_loss = 0.00024192575384081612
Trained batch 310 in epoch 5, gen_loss = 1.046467416347798, disc_loss = 0.00024208187374924204
Trained batch 311 in epoch 5, gen_loss = 1.0464977108133144, disc_loss = 0.00024240650637717082
Trained batch 312 in epoch 5, gen_loss = 1.0463164734383361, disc_loss = 0.0002422200662966151
Trained batch 313 in epoch 5, gen_loss = 1.0464158063861215, disc_loss = 0.00024181776311156595
Trained batch 314 in epoch 5, gen_loss = 1.0459837143383328, disc_loss = 0.0002413426466990218
Trained batch 315 in epoch 5, gen_loss = 1.0456554120099997, disc_loss = 0.0002408319645308185
Trained batch 316 in epoch 5, gen_loss = 1.045795415478174, disc_loss = 0.00024062787256169072
Trained batch 317 in epoch 5, gen_loss = 1.0456894846082483, disc_loss = 0.00024055593359044683
Trained batch 318 in epoch 5, gen_loss = 1.0456981800940344, disc_loss = 0.0002405312037335192
Trained batch 319 in epoch 5, gen_loss = 1.0456225663423537, disc_loss = 0.0002404956635700728
Trained batch 320 in epoch 5, gen_loss = 1.0453805370122844, disc_loss = 0.00024016590011860983
Trained batch 321 in epoch 5, gen_loss = 1.0451678046898811, disc_loss = 0.0002397743547640767
Trained batch 322 in epoch 5, gen_loss = 1.0450979602226163, disc_loss = 0.0002394609104659215
Trained batch 323 in epoch 5, gen_loss = 1.0446074238897842, disc_loss = 0.00023914809259431533
Trained batch 324 in epoch 5, gen_loss = 1.0444702388690068, disc_loss = 0.00023889036340943466
Trained batch 325 in epoch 5, gen_loss = 1.0445194118227696, disc_loss = 0.00023858127886542988
Trained batch 326 in epoch 5, gen_loss = 1.0441394907618882, disc_loss = 0.00023845474410425467
Trained batch 327 in epoch 5, gen_loss = 1.0438052039684318, disc_loss = 0.00023847707272091988
Trained batch 328 in epoch 5, gen_loss = 1.0437410658616062, disc_loss = 0.0002382210379359907
Trained batch 329 in epoch 5, gen_loss = 1.043643165176565, disc_loss = 0.00023780617773423506
Trained batch 330 in epoch 5, gen_loss = 1.043718673491406, disc_loss = 0.0002375664354101164
Trained batch 331 in epoch 5, gen_loss = 1.0435123720082893, disc_loss = 0.00023734451554128648
Trained batch 332 in epoch 5, gen_loss = 1.0433096962648112, disc_loss = 0.00023694310057016828
Trained batch 333 in epoch 5, gen_loss = 1.0440152192900995, disc_loss = 0.00023691420169135217
Trained batch 334 in epoch 5, gen_loss = 1.044267710465104, disc_loss = 0.0002368490714032495
Trained batch 335 in epoch 5, gen_loss = 1.0441877581179142, disc_loss = 0.00023702521938113414
Trained batch 336 in epoch 5, gen_loss = 1.0442799002551184, disc_loss = 0.00023736929155569053
Trained batch 337 in epoch 5, gen_loss = 1.0442450831275014, disc_loss = 0.00023771673138270612
Trained batch 338 in epoch 5, gen_loss = 1.0440563279970558, disc_loss = 0.000238148140063225
Trained batch 339 in epoch 5, gen_loss = 1.043786934193443, disc_loss = 0.00023965907434210428
Trained batch 340 in epoch 5, gen_loss = 1.0435689572365052, disc_loss = 0.00024281696224318205
Trained batch 341 in epoch 5, gen_loss = 1.0436940876364011, disc_loss = 0.00024438817054458773
Trained batch 342 in epoch 5, gen_loss = 1.0438904685807298, disc_loss = 0.00024630510650521534
Trained batch 343 in epoch 5, gen_loss = 1.0438071773495785, disc_loss = 0.0002469078052071868
Trained batch 344 in epoch 5, gen_loss = 1.043586788661238, disc_loss = 0.00024729881242028964
Trained batch 345 in epoch 5, gen_loss = 1.0437533111241513, disc_loss = 0.0002473524754681568
Trained batch 346 in epoch 5, gen_loss = 1.0436528038222783, disc_loss = 0.00024720488173765685
Trained batch 347 in epoch 5, gen_loss = 1.043782802833908, disc_loss = 0.0002470035655194848
Trained batch 348 in epoch 5, gen_loss = 1.0437696263578355, disc_loss = 0.00024663106393503335
Trained batch 349 in epoch 5, gen_loss = 1.043893758569445, disc_loss = 0.0002463215262936761
Trained batch 350 in epoch 5, gen_loss = 1.043666250006086, disc_loss = 0.0002460322089957941
Trained batch 351 in epoch 5, gen_loss = 1.043527659706094, disc_loss = 0.0002458198285611698
Trained batch 352 in epoch 5, gen_loss = 1.0435440810476417, disc_loss = 0.0002455465022051409
Trained batch 353 in epoch 5, gen_loss = 1.0433816562938152, disc_loss = 0.0002453817890295667
Trained batch 354 in epoch 5, gen_loss = 1.0435772472703961, disc_loss = 0.00024522675136120624
Trained batch 355 in epoch 5, gen_loss = 1.0434970042009033, disc_loss = 0.00024489718600123297
Trained batch 356 in epoch 5, gen_loss = 1.0432646665252556, disc_loss = 0.00024463316414349373
Trained batch 357 in epoch 5, gen_loss = 1.0431356185308382, disc_loss = 0.00024440604317416283
Trained batch 358 in epoch 5, gen_loss = 1.043100200489703, disc_loss = 0.00024439058399776745
Trained batch 359 in epoch 5, gen_loss = 1.0428966311944856, disc_loss = 0.00024464694019520213
Trained batch 360 in epoch 5, gen_loss = 1.0428273230378318, disc_loss = 0.0002449542715772406
Trained batch 361 in epoch 5, gen_loss = 1.043011130713626, disc_loss = 0.00024530795847502466
Trained batch 362 in epoch 5, gen_loss = 1.0429256187325995, disc_loss = 0.0002453382829607967
Trained batch 363 in epoch 5, gen_loss = 1.0428171244623896, disc_loss = 0.00024536851182906853
Trained batch 364 in epoch 5, gen_loss = 1.0426469134957823, disc_loss = 0.00024535054759974016
Trained batch 365 in epoch 5, gen_loss = 1.042671420372249, disc_loss = 0.0002452799641214568
Trained batch 366 in epoch 5, gen_loss = 1.0428105399459195, disc_loss = 0.0002453093693475239
Trained batch 367 in epoch 5, gen_loss = 1.042827213425999, disc_loss = 0.0002455760610523019
Trained batch 368 in epoch 5, gen_loss = 1.0425735292072864, disc_loss = 0.00024609582563423675
Trained batch 369 in epoch 5, gen_loss = 1.0429885004017805, disc_loss = 0.00024693393963782395
Trained batch 370 in epoch 5, gen_loss = 1.042900445647638, disc_loss = 0.0002473893537441196
Trained batch 371 in epoch 5, gen_loss = 1.0425306058699084, disc_loss = 0.00024779935861309933
Trained batch 372 in epoch 5, gen_loss = 1.0426431149643804, disc_loss = 0.00024800033693781734
Trained batch 373 in epoch 5, gen_loss = 1.0425911819871096, disc_loss = 0.00024790335117038065
Trained batch 374 in epoch 5, gen_loss = 1.0425659958521525, disc_loss = 0.00024762652148880687
Trained batch 375 in epoch 5, gen_loss = 1.0426091849803925, disc_loss = 0.00024760138615207285
Trained batch 376 in epoch 5, gen_loss = 1.0426554720977257, disc_loss = 0.0002481820610027936
Trained batch 377 in epoch 5, gen_loss = 1.0425865829937042, disc_loss = 0.00024907000418847904
Trained batch 378 in epoch 5, gen_loss = 1.042675526286807, disc_loss = 0.00025020588797472276
Trained batch 379 in epoch 5, gen_loss = 1.0425234184453362, disc_loss = 0.0002519538409902261
Trained batch 380 in epoch 5, gen_loss = 1.0424796075332823, disc_loss = 0.0002536878872317814
Trained batch 381 in epoch 5, gen_loss = 1.042338860908728, disc_loss = 0.0002549780500223507
Trained batch 382 in epoch 5, gen_loss = 1.0423774905989127, disc_loss = 0.00025546088940193437
Trained batch 383 in epoch 5, gen_loss = 1.042137320463856, disc_loss = 0.00025560142093657606
Trained batch 384 in epoch 5, gen_loss = 1.041907775866521, disc_loss = 0.00025560389710937976
Trained batch 385 in epoch 5, gen_loss = 1.0416273366601974, disc_loss = 0.000255405406721408
Trained batch 386 in epoch 5, gen_loss = 1.0414721910343614, disc_loss = 0.000255499568295416
Trained batch 387 in epoch 5, gen_loss = 1.0414525362634168, disc_loss = 0.000255463976462068
Trained batch 388 in epoch 5, gen_loss = 1.0413217330040232, disc_loss = 0.00025512537177024256
Trained batch 389 in epoch 5, gen_loss = 1.0411205791510068, disc_loss = 0.00025499641291949396
Trained batch 390 in epoch 5, gen_loss = 1.0412516708264266, disc_loss = 0.0002546982335299194
Trained batch 391 in epoch 5, gen_loss = 1.0412146836823346, disc_loss = 0.00025438162634711667
Trained batch 392 in epoch 5, gen_loss = 1.0416430873421918, disc_loss = 0.00025411146529194837
Trained batch 393 in epoch 5, gen_loss = 1.0416193188447032, disc_loss = 0.0002538833664241188
Trained batch 394 in epoch 5, gen_loss = 1.0414521252052693, disc_loss = 0.00025388506630544635
Trained batch 395 in epoch 5, gen_loss = 1.0416106869174977, disc_loss = 0.0002546949970638532
Trained batch 396 in epoch 5, gen_loss = 1.0415163981524163, disc_loss = 0.00025575301693579397
Trained batch 397 in epoch 5, gen_loss = 1.0415670768399934, disc_loss = 0.00025623394166492044
Trained batch 398 in epoch 5, gen_loss = 1.0414292982646398, disc_loss = 0.00025628462936311963
Trained batch 399 in epoch 5, gen_loss = 1.041058940589428, disc_loss = 0.00025625168573242265
Trained batch 400 in epoch 5, gen_loss = 1.0409734026154973, disc_loss = 0.0002561132023129856
Trained batch 401 in epoch 5, gen_loss = 1.041089312650671, disc_loss = 0.0002563224908809203
Trained batch 402 in epoch 5, gen_loss = 1.0411393964852649, disc_loss = 0.0002569237140750584
Trained batch 403 in epoch 5, gen_loss = 1.0411194831427961, disc_loss = 0.0002577076081999423
Trained batch 404 in epoch 5, gen_loss = 1.0410201175713245, disc_loss = 0.00025784142100163105
Trained batch 405 in epoch 5, gen_loss = 1.0407280209910106, disc_loss = 0.00025782369148101444
Trained batch 406 in epoch 5, gen_loss = 1.0411802824650702, disc_loss = 0.00025777249358247174
Trained batch 407 in epoch 5, gen_loss = 1.04099038067986, disc_loss = 0.00025754390596785905
Trained batch 408 in epoch 5, gen_loss = 1.041261686963965, disc_loss = 0.00025729804077686077
Trained batch 409 in epoch 5, gen_loss = 1.0413343534237, disc_loss = 0.00025718299135716244
Trained batch 410 in epoch 5, gen_loss = 1.0415724164958127, disc_loss = 0.00025749082446289236
Trained batch 411 in epoch 5, gen_loss = 1.0415338040555564, disc_loss = 0.0002578214618234129
Trained batch 412 in epoch 5, gen_loss = 1.0414076936735657, disc_loss = 0.0002578163069942639
Trained batch 413 in epoch 5, gen_loss = 1.0416860925978508, disc_loss = 0.00025801424848229023
Trained batch 414 in epoch 5, gen_loss = 1.0416488365954664, disc_loss = 0.00025841159283545385
Trained batch 415 in epoch 5, gen_loss = 1.0416994186548085, disc_loss = 0.0002585758850273123
Trained batch 416 in epoch 5, gen_loss = 1.0417156774077199, disc_loss = 0.00025846251484151257
Trained batch 417 in epoch 5, gen_loss = 1.0414849966051476, disc_loss = 0.00025831408026607584
Trained batch 418 in epoch 5, gen_loss = 1.0414731387306797, disc_loss = 0.00025821434805763723
Trained batch 419 in epoch 5, gen_loss = 1.0413202610753831, disc_loss = 0.0002581458343878954
Trained batch 420 in epoch 5, gen_loss = 1.0415429818375377, disc_loss = 0.0002582091350580406
Trained batch 421 in epoch 5, gen_loss = 1.0414154951888803, disc_loss = 0.00025796092770730535
Trained batch 422 in epoch 5, gen_loss = 1.041276297811639, disc_loss = 0.000258045327578188
Trained batch 423 in epoch 5, gen_loss = 1.0409534901099384, disc_loss = 0.00025798554749067163
Trained batch 424 in epoch 5, gen_loss = 1.041004463784835, disc_loss = 0.0002579673595199197
Trained batch 425 in epoch 5, gen_loss = 1.0411111475996009, disc_loss = 0.0002577355614487036
Trained batch 426 in epoch 5, gen_loss = 1.04092544833726, disc_loss = 0.00025754552908103796
Trained batch 427 in epoch 5, gen_loss = 1.0407314829737226, disc_loss = 0.00025751732692552763
Trained batch 428 in epoch 5, gen_loss = 1.0406444345042978, disc_loss = 0.0002573418333394603
Trained batch 429 in epoch 5, gen_loss = 1.040955538805141, disc_loss = 0.00025721261070345443
Trained batch 430 in epoch 5, gen_loss = 1.0409829511443314, disc_loss = 0.00025712748898775047
Trained batch 431 in epoch 5, gen_loss = 1.041037286873217, disc_loss = 0.00025715026938794635
Trained batch 432 in epoch 5, gen_loss = 1.040924991250864, disc_loss = 0.0002571597825108025
Trained batch 433 in epoch 5, gen_loss = 1.0406907373859036, disc_loss = 0.00025733763113371653
Trained batch 434 in epoch 5, gen_loss = 1.0406453861587348, disc_loss = 0.00025766774466403107
Trained batch 435 in epoch 5, gen_loss = 1.0405532250163751, disc_loss = 0.0002581334339676119
Trained batch 436 in epoch 5, gen_loss = 1.0405554337687024, disc_loss = 0.0002583803720933436
Trained batch 437 in epoch 5, gen_loss = 1.040756600360348, disc_loss = 0.0002585659240970237
Trained batch 438 in epoch 5, gen_loss = 1.0409528853409926, disc_loss = 0.00025883836144062207
Trained batch 439 in epoch 5, gen_loss = 1.0407113862308588, disc_loss = 0.00025899252519924297
Trained batch 440 in epoch 5, gen_loss = 1.0404871714358428, disc_loss = 0.00025921873934738564
Trained batch 441 in epoch 5, gen_loss = 1.0404595550638518, disc_loss = 0.0002590897092228277
Trained batch 442 in epoch 5, gen_loss = 1.0406437526976282, disc_loss = 0.0002589287116862655
Trained batch 443 in epoch 5, gen_loss = 1.0407065181313335, disc_loss = 0.00025878666262239375
Trained batch 444 in epoch 5, gen_loss = 1.0408120151316183, disc_loss = 0.00025857522263874434
Trained batch 445 in epoch 5, gen_loss = 1.0410681079588664, disc_loss = 0.0002584660582166351
Trained batch 446 in epoch 5, gen_loss = 1.0408713562909921, disc_loss = 0.00025821069234440943
Trained batch 447 in epoch 5, gen_loss = 1.0410550863349013, disc_loss = 0.00025801900302927346
Trained batch 448 in epoch 5, gen_loss = 1.0408801367394378, disc_loss = 0.000257794613505165
Trained batch 449 in epoch 5, gen_loss = 1.0409496716658275, disc_loss = 0.00025757509295039604
Trained batch 450 in epoch 5, gen_loss = 1.040754344933842, disc_loss = 0.0002573802216517214
Trained batch 451 in epoch 5, gen_loss = 1.040993943414857, disc_loss = 0.00025715231305965434
Trained batch 452 in epoch 5, gen_loss = 1.0408381206573503, disc_loss = 0.00025710203653321216
Trained batch 453 in epoch 5, gen_loss = 1.0408591335302932, disc_loss = 0.0002572553959811806
Trained batch 454 in epoch 5, gen_loss = 1.041076240827749, disc_loss = 0.0002577253123700547
Trained batch 455 in epoch 5, gen_loss = 1.0411041048273706, disc_loss = 0.00025794765368022796
Trained batch 456 in epoch 5, gen_loss = 1.0413097034919705, disc_loss = 0.00025795920173032823
Trained batch 457 in epoch 5, gen_loss = 1.0411617293888824, disc_loss = 0.00025785175539686867
Trained batch 458 in epoch 5, gen_loss = 1.0411762670494114, disc_loss = 0.0002578287037775024
Trained batch 459 in epoch 5, gen_loss = 1.0411975408377854, disc_loss = 0.0002580704336255819
Trained batch 460 in epoch 5, gen_loss = 1.0414295619325369, disc_loss = 0.000257996974763316
Trained batch 461 in epoch 5, gen_loss = 1.0414780168048232, disc_loss = 0.0002577279739451516
Trained batch 462 in epoch 5, gen_loss = 1.0413043137245508, disc_loss = 0.0002573499255118435
Trained batch 463 in epoch 5, gen_loss = 1.04119574882347, disc_loss = 0.0002570468200560597
Trained batch 464 in epoch 5, gen_loss = 1.0410391560164831, disc_loss = 0.00025679462823093
Trained batch 465 in epoch 5, gen_loss = 1.0410019841061129, disc_loss = 0.00025644867335655524
Trained batch 466 in epoch 5, gen_loss = 1.041082654698758, disc_loss = 0.0002561375560220012
Trained batch 467 in epoch 5, gen_loss = 1.0411871481909711, disc_loss = 0.0002558960802713807
Trained batch 468 in epoch 5, gen_loss = 1.0409021373750813, disc_loss = 0.00025563935024057157
Trained batch 469 in epoch 5, gen_loss = 1.0410333733609383, disc_loss = 0.0002555226167463301
Trained batch 470 in epoch 5, gen_loss = 1.0412064614822405, disc_loss = 0.00025551511399767257
Trained batch 471 in epoch 5, gen_loss = 1.041174590713897, disc_loss = 0.0002554487736988911
Trained batch 472 in epoch 5, gen_loss = 1.0413253041452888, disc_loss = 0.0002551856651325291
Trained batch 473 in epoch 5, gen_loss = 1.0414494008203097, disc_loss = 0.0002549922608039519
Trained batch 474 in epoch 5, gen_loss = 1.0416613708044353, disc_loss = 0.0002547973130314954
Trained batch 475 in epoch 5, gen_loss = 1.0415894084868311, disc_loss = 0.0002545894862765528
Trained batch 476 in epoch 5, gen_loss = 1.0416055896497123, disc_loss = 0.00025436089148249993
Trained batch 477 in epoch 5, gen_loss = 1.0414578139033777, disc_loss = 0.0002540464574621141
Trained batch 478 in epoch 5, gen_loss = 1.0417090325863227, disc_loss = 0.00025394926173806905
Trained batch 479 in epoch 5, gen_loss = 1.0414973933249712, disc_loss = 0.0002538954895499046
Trained batch 480 in epoch 5, gen_loss = 1.0416187235074827, disc_loss = 0.00025412477378630835
Trained batch 481 in epoch 5, gen_loss = 1.0415338373035812, disc_loss = 0.0002551177635893257
Trained batch 482 in epoch 5, gen_loss = 1.041881625573334, disc_loss = 0.0002566309415351592
Trained batch 483 in epoch 5, gen_loss = 1.0419841286810962, disc_loss = 0.00025826425691835645
Trained batch 484 in epoch 5, gen_loss = 1.0416994459850273, disc_loss = 0.0002598622905032844
Trained batch 485 in epoch 5, gen_loss = 1.0418003200258248, disc_loss = 0.0002609102777397038
Trained batch 486 in epoch 5, gen_loss = 1.0416433078062852, disc_loss = 0.0002612737820194977
Trained batch 487 in epoch 5, gen_loss = 1.041580354458973, disc_loss = 0.0002612121253881268
Trained batch 488 in epoch 5, gen_loss = 1.041516013062561, disc_loss = 0.0002609764059787951
Trained batch 489 in epoch 5, gen_loss = 1.0413773810376927, disc_loss = 0.00026064805249322433
Trained batch 490 in epoch 5, gen_loss = 1.0415666213831931, disc_loss = 0.00026058219313951564
Trained batch 491 in epoch 5, gen_loss = 1.0414378835660656, disc_loss = 0.0002603712353861997
Trained batch 492 in epoch 5, gen_loss = 1.041305457481748, disc_loss = 0.0002601953112009278
Trained batch 493 in epoch 5, gen_loss = 1.0411098130077485, disc_loss = 0.0002600925543646211
Trained batch 494 in epoch 5, gen_loss = 1.0410087572203741, disc_loss = 0.0002602691242396079
Trained batch 495 in epoch 5, gen_loss = 1.0408977009356022, disc_loss = 0.00026059744196836913
Trained batch 496 in epoch 5, gen_loss = 1.0409059213920377, disc_loss = 0.00026102660248904924
Trained batch 497 in epoch 5, gen_loss = 1.0408684748961743, disc_loss = 0.00026148333417365784
Trained batch 498 in epoch 5, gen_loss = 1.0410749246935567, disc_loss = 0.0002620199295474713
Trained batch 499 in epoch 5, gen_loss = 1.0413958758115769, disc_loss = 0.00026233542780391874
Trained batch 500 in epoch 5, gen_loss = 1.041370731033013, disc_loss = 0.0002623172687759768
Trained batch 501 in epoch 5, gen_loss = 1.041321527791688, disc_loss = 0.00026211893192698354
Trained batch 502 in epoch 5, gen_loss = 1.041339066227672, disc_loss = 0.0002618554715603168
Trained batch 503 in epoch 5, gen_loss = 1.041466830387002, disc_loss = 0.00026161742261181296
Trained batch 504 in epoch 5, gen_loss = 1.0410879373550415, disc_loss = 0.00026146023016132525
Trained batch 505 in epoch 5, gen_loss = 1.0411149786395046, disc_loss = 0.00026173488375120667
Trained batch 506 in epoch 5, gen_loss = 1.0411308115050637, disc_loss = 0.00026239578879536617
Trained batch 507 in epoch 5, gen_loss = 1.0412092359047236, disc_loss = 0.0002631092563284814
Trained batch 508 in epoch 5, gen_loss = 1.0410542164898107, disc_loss = 0.00026361560710309683
Trained batch 509 in epoch 5, gen_loss = 1.0407375214146632, disc_loss = 0.00026372350485853887
Trained batch 510 in epoch 5, gen_loss = 1.0408144221147213, disc_loss = 0.00026359906755118957
Trained batch 511 in epoch 5, gen_loss = 1.0409926087595522, disc_loss = 0.00026350230521643425
Trained batch 512 in epoch 5, gen_loss = 1.0407533795512907, disc_loss = 0.000263465888083179
Trained batch 513 in epoch 5, gen_loss = 1.0406376129226462, disc_loss = 0.00026349853567397656
Trained batch 514 in epoch 5, gen_loss = 1.0407129825897588, disc_loss = 0.0002633529517164418
Trained batch 515 in epoch 5, gen_loss = 1.0407076797975126, disc_loss = 0.0002634301812957896
Trained batch 516 in epoch 5, gen_loss = 1.0407794620589546, disc_loss = 0.00026404365896165363
Trained batch 517 in epoch 5, gen_loss = 1.0409817425210504, disc_loss = 0.0002652857147602627
Trained batch 518 in epoch 5, gen_loss = 1.0410175343010009, disc_loss = 0.00026668953708294953
Trained batch 519 in epoch 5, gen_loss = 1.0410285166822948, disc_loss = 0.0002680042505324729
Trained batch 520 in epoch 5, gen_loss = 1.0408904754955344, disc_loss = 0.0002685145654788441
Trained batch 521 in epoch 5, gen_loss = 1.0408058354909393, disc_loss = 0.00026841437410861184
Trained batch 522 in epoch 5, gen_loss = 1.0407266596307263, disc_loss = 0.0002681882018610714
Trained batch 523 in epoch 5, gen_loss = 1.0405051446597995, disc_loss = 0.0002682659872105516
Trained batch 524 in epoch 5, gen_loss = 1.0404131516956148, disc_loss = 0.00026816286440450876
Trained batch 525 in epoch 5, gen_loss = 1.0405207904119456, disc_loss = 0.00026798745153158433
Trained batch 526 in epoch 5, gen_loss = 1.0403574071753863, disc_loss = 0.00026791415020887096
Trained batch 527 in epoch 5, gen_loss = 1.0406814759427852, disc_loss = 0.00026822546990870524
Trained batch 528 in epoch 5, gen_loss = 1.040701001262845, disc_loss = 0.00026868375472456835
Trained batch 529 in epoch 5, gen_loss = 1.040647299334688, disc_loss = 0.000268989372427382
Trained batch 530 in epoch 5, gen_loss = 1.0406369327825342, disc_loss = 0.0002689456939653418
Trained batch 531 in epoch 5, gen_loss = 1.0405614723388414, disc_loss = 0.0002686603619711372
Trained batch 532 in epoch 5, gen_loss = 1.0406432860787769, disc_loss = 0.00026895823422928584
Trained batch 533 in epoch 5, gen_loss = 1.0406162828095398, disc_loss = 0.0002703692004346631
Trained batch 534 in epoch 5, gen_loss = 1.0405195173816146, disc_loss = 0.0002719598594088995
Trained batch 535 in epoch 5, gen_loss = 1.0404782777846748, disc_loss = 0.0002725997124635701
Trained batch 536 in epoch 5, gen_loss = 1.0404495475900462, disc_loss = 0.00027283554233014897
Trained batch 537 in epoch 5, gen_loss = 1.0405419413485049, disc_loss = 0.0002730382610119786
Trained batch 538 in epoch 5, gen_loss = 1.0405737831773918, disc_loss = 0.0002730020457381514
Trained batch 539 in epoch 5, gen_loss = 1.0404501833297588, disc_loss = 0.0002728638705405131
Trained batch 540 in epoch 5, gen_loss = 1.0403701560554575, disc_loss = 0.0002725376907081684
Trained batch 541 in epoch 5, gen_loss = 1.0403752140013494, disc_loss = 0.00027222380736003786
Trained batch 542 in epoch 5, gen_loss = 1.040585547081893, disc_loss = 0.000271950455458683
Trained batch 543 in epoch 5, gen_loss = 1.0404841299442684, disc_loss = 0.00027165267223448183
Trained batch 544 in epoch 5, gen_loss = 1.0405835042306042, disc_loss = 0.00027145435826675623
Trained batch 545 in epoch 5, gen_loss = 1.0405681412735266, disc_loss = 0.0002716834174735419
Trained batch 546 in epoch 5, gen_loss = 1.0406790642677322, disc_loss = 0.0002723607644265291
Trained batch 547 in epoch 5, gen_loss = 1.0404827656754612, disc_loss = 0.00027303714442449657
Trained batch 548 in epoch 5, gen_loss = 1.0402622700606106, disc_loss = 0.0002731558864704886
Trained batch 549 in epoch 5, gen_loss = 1.0401602655107325, disc_loss = 0.00027313987953344953
Trained batch 550 in epoch 5, gen_loss = 1.0401655806603751, disc_loss = 0.00027331041864141865
Trained batch 551 in epoch 5, gen_loss = 1.0399112315929455, disc_loss = 0.00027346616671043125
Trained batch 552 in epoch 5, gen_loss = 1.0400004368578546, disc_loss = 0.00027405663817259106
Trained batch 553 in epoch 5, gen_loss = 1.0400402514727969, disc_loss = 0.00027547814561626103
Trained batch 554 in epoch 5, gen_loss = 1.0398562713786288, disc_loss = 0.00027754939375455737
Trained batch 555 in epoch 5, gen_loss = 1.0396254413205086, disc_loss = 0.00027874600849788145
Trained batch 556 in epoch 5, gen_loss = 1.039474719730699, disc_loss = 0.00027896434157140824
Trained batch 557 in epoch 5, gen_loss = 1.0395606158027513, disc_loss = 0.00027904433173915675
Trained batch 558 in epoch 5, gen_loss = 1.039374215231812, disc_loss = 0.0002796313784790995
Trained batch 559 in epoch 5, gen_loss = 1.0395827074136053, disc_loss = 0.0002809492682640017
Trained batch 560 in epoch 5, gen_loss = 1.0397202673230366, disc_loss = 0.00028229300117665077
Trained batch 561 in epoch 5, gen_loss = 1.0396950022181581, disc_loss = 0.00028297673789728385
Trained batch 562 in epoch 5, gen_loss = 1.0396065404952948, disc_loss = 0.0002832831658380971
Trained batch 563 in epoch 5, gen_loss = 1.0395319542140826, disc_loss = 0.00028339112735056594
Trained batch 564 in epoch 5, gen_loss = 1.0397323184308753, disc_loss = 0.0002834747424498571
Trained batch 565 in epoch 5, gen_loss = 1.0399938792306205, disc_loss = 0.0002834380831938219
Trained batch 566 in epoch 5, gen_loss = 1.0398493251472554, disc_loss = 0.00028361299719525555
Trained batch 567 in epoch 5, gen_loss = 1.0401626121200307, disc_loss = 0.0002839373204244086
Trained batch 568 in epoch 5, gen_loss = 1.039930234265453, disc_loss = 0.00028423610699507496
Trained batch 569 in epoch 5, gen_loss = 1.0397533444981826, disc_loss = 0.00028427265628635183
Trained batch 570 in epoch 5, gen_loss = 1.0397311399989286, disc_loss = 0.0002841608413017433
Trained batch 571 in epoch 5, gen_loss = 1.0398638655880947, disc_loss = 0.00028417021272693013
Trained batch 572 in epoch 5, gen_loss = 1.0398149842991256, disc_loss = 0.0002842422705522599
Trained batch 573 in epoch 5, gen_loss = 1.0398267003925004, disc_loss = 0.00028442812715472494
Trained batch 574 in epoch 5, gen_loss = 1.039881257492563, disc_loss = 0.00028444141722739794
Trained batch 575 in epoch 5, gen_loss = 1.0396328325279884, disc_loss = 0.00028432093420683994
Trained batch 576 in epoch 5, gen_loss = 1.0394726690014686, disc_loss = 0.0002841769632617249
Trained batch 577 in epoch 5, gen_loss = 1.0392720500284414, disc_loss = 0.000283882196803914
Trained batch 578 in epoch 5, gen_loss = 1.0393140506456142, disc_loss = 0.00028357380791607477
Trained batch 579 in epoch 5, gen_loss = 1.0390402258470142, disc_loss = 0.0002833898477296441
Trained batch 580 in epoch 5, gen_loss = 1.0388633798609093, disc_loss = 0.0002832413555772914
Trained batch 581 in epoch 5, gen_loss = 1.0388547763791691, disc_loss = 0.00028300819649677915
Trained batch 582 in epoch 5, gen_loss = 1.0387894223934586, disc_loss = 0.0002827609385108962
Trained batch 583 in epoch 5, gen_loss = 1.0387370149566704, disc_loss = 0.0002824360191930095
Trained batch 584 in epoch 5, gen_loss = 1.038798743027907, disc_loss = 0.0002822812274745148
Trained batch 585 in epoch 5, gen_loss = 1.0389722180854746, disc_loss = 0.0002822602867657786
Trained batch 586 in epoch 5, gen_loss = 1.0388575030754128, disc_loss = 0.00028257551756223387
Trained batch 587 in epoch 5, gen_loss = 1.0387952372330387, disc_loss = 0.0002827302502124922
Trained batch 588 in epoch 5, gen_loss = 1.0387697070078048, disc_loss = 0.0002828463604912899
Trained batch 589 in epoch 5, gen_loss = 1.039001859648753, disc_loss = 0.0002828301929215648
Trained batch 590 in epoch 5, gen_loss = 1.038862444220864, disc_loss = 0.0002827095151723279
Trained batch 591 in epoch 5, gen_loss = 1.0389852509708017, disc_loss = 0.0002826013697149638
Trained batch 592 in epoch 5, gen_loss = 1.0390053838742723, disc_loss = 0.00028258647743088756
Trained batch 593 in epoch 5, gen_loss = 1.0390756449314078, disc_loss = 0.00028276365324921487
Trained batch 594 in epoch 5, gen_loss = 1.0390302213300175, disc_loss = 0.00028280459998367244
Trained batch 595 in epoch 5, gen_loss = 1.0391294884201665, disc_loss = 0.00028254529920773073
Trained batch 596 in epoch 5, gen_loss = 1.0391693199100207, disc_loss = 0.0002823443661400599
Trained batch 597 in epoch 5, gen_loss = 1.039224444025735, disc_loss = 0.0002821552204164789
Trained batch 598 in epoch 5, gen_loss = 1.039326809483498, disc_loss = 0.0002819107724588834
Trained batch 599 in epoch 5, gen_loss = 1.0392075591286023, disc_loss = 0.0002816827275334314
Trained batch 600 in epoch 5, gen_loss = 1.0392248619614346, disc_loss = 0.00028145859037241594
Trained batch 601 in epoch 5, gen_loss = 1.0392060912526724, disc_loss = 0.00028118591713954995
Trained batch 602 in epoch 5, gen_loss = 1.0392183121757128, disc_loss = 0.00028095058474676595
Trained batch 603 in epoch 5, gen_loss = 1.0392120724284886, disc_loss = 0.00028076164197660087
Trained batch 604 in epoch 5, gen_loss = 1.0390600803469823, disc_loss = 0.00028065381259445777
Trained batch 605 in epoch 5, gen_loss = 1.0390557735273154, disc_loss = 0.0002804690770116764
Trained batch 606 in epoch 5, gen_loss = 1.0388750955339712, disc_loss = 0.0002802768522956757
Trained batch 607 in epoch 5, gen_loss = 1.0390060067568954, disc_loss = 0.00028014071904181037
Trained batch 608 in epoch 5, gen_loss = 1.038814234616134, disc_loss = 0.000280150711509263
Trained batch 609 in epoch 5, gen_loss = 1.0387662356017067, disc_loss = 0.00028053897659133996
Trained batch 610 in epoch 5, gen_loss = 1.0388978791900234, disc_loss = 0.0002809383435523116
Trained batch 611 in epoch 5, gen_loss = 1.0388698905122047, disc_loss = 0.0002812195744375345
Trained batch 612 in epoch 5, gen_loss = 1.0387383551620932, disc_loss = 0.00028132007998181885
Trained batch 613 in epoch 5, gen_loss = 1.0386940945631518, disc_loss = 0.00028124276838903937
Trained batch 614 in epoch 5, gen_loss = 1.038745879157772, disc_loss = 0.0002813040609641864
Trained batch 615 in epoch 5, gen_loss = 1.0387882545783922, disc_loss = 0.0002813552634872938
Trained batch 616 in epoch 5, gen_loss = 1.0386130564409872, disc_loss = 0.0002815754863118822
Trained batch 617 in epoch 5, gen_loss = 1.0386148511784747, disc_loss = 0.00028143499025277805
Trained batch 618 in epoch 5, gen_loss = 1.0385148378874451, disc_loss = 0.00028128343002768367
Trained batch 619 in epoch 5, gen_loss = 1.0387317495961343, disc_loss = 0.000281257206863243
Trained batch 620 in epoch 5, gen_loss = 1.03855428085235, disc_loss = 0.0002811174528450584
Trained batch 621 in epoch 5, gen_loss = 1.0385641804462078, disc_loss = 0.0002810768789175293
Trained batch 622 in epoch 5, gen_loss = 1.0385084804715543, disc_loss = 0.0002808892682910767
Trained batch 623 in epoch 5, gen_loss = 1.038601627907692, disc_loss = 0.00028084351470170077
Trained batch 624 in epoch 5, gen_loss = 1.0384678384780883, disc_loss = 0.0002815196323674172
Trained batch 625 in epoch 5, gen_loss = 1.038164941552348, disc_loss = 0.00028260621890691985
Trained batch 626 in epoch 5, gen_loss = 1.0380430311867686, disc_loss = 0.00028334882659384567
Trained batch 627 in epoch 5, gen_loss = 1.038165769854169, disc_loss = 0.00028391239782209524
Trained batch 628 in epoch 5, gen_loss = 1.038099463111077, disc_loss = 0.000283899946763463
Trained batch 629 in epoch 5, gen_loss = 1.038130245322273, disc_loss = 0.0002836857453480156
Trained batch 630 in epoch 5, gen_loss = 1.0380498941651237, disc_loss = 0.00028349801706314005
Trained batch 631 in epoch 5, gen_loss = 1.0379552629929554, disc_loss = 0.00028331452124837574
Trained batch 632 in epoch 5, gen_loss = 1.037882091403949, disc_loss = 0.00028299476487354607
Trained batch 633 in epoch 5, gen_loss = 1.0378140667071478, disc_loss = 0.00028272660511394535
Trained batch 634 in epoch 5, gen_loss = 1.037638145638263, disc_loss = 0.0002827481039906082
Trained batch 635 in epoch 5, gen_loss = 1.0375938230902895, disc_loss = 0.00028269055931691266
Trained batch 636 in epoch 5, gen_loss = 1.0377199139849544, disc_loss = 0.0002825806634058354
Trained batch 637 in epoch 5, gen_loss = 1.0378659622609427, disc_loss = 0.0002824258629753047
Trained batch 638 in epoch 5, gen_loss = 1.0379779181196842, disc_loss = 0.0002822902664638391
Trained batch 639 in epoch 5, gen_loss = 1.037901130039245, disc_loss = 0.00028222458583968544
Trained batch 640 in epoch 5, gen_loss = 1.0379386614897694, disc_loss = 0.00028211754960496145
Trained batch 641 in epoch 5, gen_loss = 1.037816505194453, disc_loss = 0.00028199427261567064
Trained batch 642 in epoch 5, gen_loss = 1.038090586476897, disc_loss = 0.0002819336599541443
Trained batch 643 in epoch 5, gen_loss = 1.0382131095628562, disc_loss = 0.000281779417276971
Trained batch 644 in epoch 5, gen_loss = 1.0383012762365416, disc_loss = 0.0002817327232693878
Trained batch 645 in epoch 5, gen_loss = 1.0383312739085855, disc_loss = 0.0002819018933538927
Trained batch 646 in epoch 5, gen_loss = 1.0381763607862375, disc_loss = 0.0002820112708881512
Trained batch 647 in epoch 5, gen_loss = 1.038382644638603, disc_loss = 0.0002820123248472364
Trained batch 648 in epoch 5, gen_loss = 1.0383420025439034, disc_loss = 0.00028188364543591145
Trained batch 649 in epoch 5, gen_loss = 1.0382658266104186, disc_loss = 0.000281749890888862
Trained batch 650 in epoch 5, gen_loss = 1.0383173724473347, disc_loss = 0.0002816526376212748
Trained batch 651 in epoch 5, gen_loss = 1.0382827007514568, disc_loss = 0.0002814663569948228
Trained batch 652 in epoch 5, gen_loss = 1.0381006216929847, disc_loss = 0.00028122882715730886
Trained batch 653 in epoch 5, gen_loss = 1.0379104883116683, disc_loss = 0.00028097693319663845
Trained batch 654 in epoch 5, gen_loss = 1.0378018460200944, disc_loss = 0.0002807383012970312
Trained batch 655 in epoch 5, gen_loss = 1.0378422505426697, disc_loss = 0.000280492865075336
Trained batch 656 in epoch 5, gen_loss = 1.0380797338086538, disc_loss = 0.0002803518980829388
Trained batch 657 in epoch 5, gen_loss = 1.0381447507074177, disc_loss = 0.0002800720216560257
Trained batch 658 in epoch 5, gen_loss = 1.0381855647191292, disc_loss = 0.0002798346414791465
Trained batch 659 in epoch 5, gen_loss = 1.0380979455781705, disc_loss = 0.0002798545488930717
Trained batch 660 in epoch 5, gen_loss = 1.038187560353445, disc_loss = 0.00028023002427490497
Trained batch 661 in epoch 5, gen_loss = 1.038233908011474, disc_loss = 0.0002804827596385558
Trained batch 662 in epoch 5, gen_loss = 1.0383014518031528, disc_loss = 0.00028049690400191963
Trained batch 663 in epoch 5, gen_loss = 1.038210245589894, disc_loss = 0.00028045081465728777
Trained batch 664 in epoch 5, gen_loss = 1.0379750238325363, disc_loss = 0.00028049163421864544
Trained batch 665 in epoch 5, gen_loss = 1.0378641000202111, disc_loss = 0.00028045805721832494
Trained batch 666 in epoch 5, gen_loss = 1.0379329354151794, disc_loss = 0.000280514196697811
Trained batch 667 in epoch 5, gen_loss = 1.03798722872834, disc_loss = 0.00028044969357308254
Trained batch 668 in epoch 5, gen_loss = 1.0379440300667766, disc_loss = 0.00028029761483084676
Trained batch 669 in epoch 5, gen_loss = 1.0380098991429627, disc_loss = 0.0002800629620176198
Trained batch 670 in epoch 5, gen_loss = 1.0381008355521588, disc_loss = 0.00027978690982830603
Trained batch 671 in epoch 5, gen_loss = 1.0379147287458181, disc_loss = 0.00027963666873022575
Trained batch 672 in epoch 5, gen_loss = 1.0378553287235448, disc_loss = 0.0002795639251427826
Trained batch 673 in epoch 5, gen_loss = 1.0376053059843953, disc_loss = 0.0002795179158590633
Trained batch 674 in epoch 5, gen_loss = 1.0377474440468681, disc_loss = 0.0002793836592226634
Trained batch 675 in epoch 5, gen_loss = 1.0378018210272817, disc_loss = 0.0002792430333914573
Trained batch 676 in epoch 5, gen_loss = 1.037665894323825, disc_loss = 0.00027922628344625766
Trained batch 677 in epoch 5, gen_loss = 1.0376313773580006, disc_loss = 0.0002791055518055333
Trained batch 678 in epoch 5, gen_loss = 1.0375847302059011, disc_loss = 0.0002789975110900421
Trained batch 679 in epoch 5, gen_loss = 1.0376174851375468, disc_loss = 0.0002789012879207696
Trained batch 680 in epoch 5, gen_loss = 1.0376333849020467, disc_loss = 0.0002787772499047262
Trained batch 681 in epoch 5, gen_loss = 1.0376122509978734, disc_loss = 0.00027875361565827893
Trained batch 682 in epoch 5, gen_loss = 1.0377113827849203, disc_loss = 0.00027875940671105736
Trained batch 683 in epoch 5, gen_loss = 1.037557243952277, disc_loss = 0.0002787469392393039
Trained batch 684 in epoch 5, gen_loss = 1.0376045178322897, disc_loss = 0.00027878409582759544
Trained batch 685 in epoch 5, gen_loss = 1.037400350452512, disc_loss = 0.0002787371445358113
Trained batch 686 in epoch 5, gen_loss = 1.0375045343604496, disc_loss = 0.00027867295470922773
Trained batch 687 in epoch 5, gen_loss = 1.0376292290382607, disc_loss = 0.00027866348133567614
Trained batch 688 in epoch 5, gen_loss = 1.0376354949048712, disc_loss = 0.00027855416908831483
Trained batch 689 in epoch 5, gen_loss = 1.0377104382584061, disc_loss = 0.0002783664055839282
Trained batch 690 in epoch 5, gen_loss = 1.0376678213541828, disc_loss = 0.0002784179427030742
Trained batch 691 in epoch 5, gen_loss = 1.0377214011773899, disc_loss = 0.00027846160388813755
Trained batch 692 in epoch 5, gen_loss = 1.037786794603301, disc_loss = 0.00027848509585101514
Trained batch 693 in epoch 5, gen_loss = 1.037649429239526, disc_loss = 0.00027833772728312557
Trained batch 694 in epoch 5, gen_loss = 1.0375810248388662, disc_loss = 0.00027812899396253965
Trained batch 695 in epoch 5, gen_loss = 1.0375524218911412, disc_loss = 0.0002779465538638426
Trained batch 696 in epoch 5, gen_loss = 1.0376830553392768, disc_loss = 0.00027775781039274505
Trained batch 697 in epoch 5, gen_loss = 1.037780900483145, disc_loss = 0.0002775320221903803
Trained batch 698 in epoch 5, gen_loss = 1.0378621522449116, disc_loss = 0.00027732841084855816
Trained batch 699 in epoch 5, gen_loss = 1.037999740924154, disc_loss = 0.0002771322041683431
Trained batch 700 in epoch 5, gen_loss = 1.0381730601893002, disc_loss = 0.000277050985714232
Trained batch 701 in epoch 5, gen_loss = 1.038114859592541, disc_loss = 0.00027702882217788574
Trained batch 702 in epoch 5, gen_loss = 1.0380069846618565, disc_loss = 0.00027696211508688534
Trained batch 703 in epoch 5, gen_loss = 1.0379743791100653, disc_loss = 0.0002768889918033065
Trained batch 704 in epoch 5, gen_loss = 1.0378893225751025, disc_loss = 0.00027676081152365326
Trained batch 705 in epoch 5, gen_loss = 1.037820921150213, disc_loss = 0.00027661970118637836
Trained batch 706 in epoch 5, gen_loss = 1.037827661469094, disc_loss = 0.000276437469052027
Trained batch 707 in epoch 5, gen_loss = 1.037743389185539, disc_loss = 0.000276380070415457
Trained batch 708 in epoch 5, gen_loss = 1.0380593498772055, disc_loss = 0.00027651887791617466
Trained batch 709 in epoch 5, gen_loss = 1.0380139168719171, disc_loss = 0.0002765226934570819
Trained batch 710 in epoch 5, gen_loss = 1.0380177956425523, disc_loss = 0.00027654157879758424
Trained batch 711 in epoch 5, gen_loss = 1.0379897388681938, disc_loss = 0.00027658852007569684
Trained batch 712 in epoch 5, gen_loss = 1.0379864784143082, disc_loss = 0.00027660299871354603
Trained batch 713 in epoch 5, gen_loss = 1.0378863009251131, disc_loss = 0.0002765133130724127
Trained batch 714 in epoch 5, gen_loss = 1.0376407560768661, disc_loss = 0.0002764347332148728
Trained batch 715 in epoch 5, gen_loss = 1.037576340347029, disc_loss = 0.00027639133135096155
Trained batch 716 in epoch 5, gen_loss = 1.0376064997670373, disc_loss = 0.0002766859345365383
Trained batch 717 in epoch 5, gen_loss = 1.0376089802193442, disc_loss = 0.0002771672942062119
Trained batch 718 in epoch 5, gen_loss = 1.0374327604561755, disc_loss = 0.00027768602753407807
Trained batch 719 in epoch 5, gen_loss = 1.037322166396512, disc_loss = 0.00027803414850495755
Trained batch 720 in epoch 5, gen_loss = 1.037234045100113, disc_loss = 0.000278174621488992
Trained batch 721 in epoch 5, gen_loss = 1.0370551389009999, disc_loss = 0.0002781223886705344
Trained batch 722 in epoch 5, gen_loss = 1.0371757646813926, disc_loss = 0.0002780780544590506
Trained batch 723 in epoch 5, gen_loss = 1.0371259758814921, disc_loss = 0.0002779802307486534
Trained batch 724 in epoch 5, gen_loss = 1.0370790498010043, disc_loss = 0.00027787283665083094
Trained batch 725 in epoch 5, gen_loss = 1.0369881583639413, disc_loss = 0.00027785715718398296
Trained batch 726 in epoch 5, gen_loss = 1.0371213303635505, disc_loss = 0.0002781652711012223
Trained batch 727 in epoch 5, gen_loss = 1.0370832714405689, disc_loss = 0.0002787469395396049
Trained batch 728 in epoch 5, gen_loss = 1.0369945439128065, disc_loss = 0.00027910338026287474
Trained batch 729 in epoch 5, gen_loss = 1.0368535497417188, disc_loss = 0.00027900370043600363
Trained batch 730 in epoch 5, gen_loss = 1.0369876946046153, disc_loss = 0.0002787983427074242
Trained batch 731 in epoch 5, gen_loss = 1.0368184013282016, disc_loss = 0.00027886382135154826
Trained batch 732 in epoch 5, gen_loss = 1.0369245777513938, disc_loss = 0.0002789689836577966
Trained batch 733 in epoch 5, gen_loss = 1.0369258325658637, disc_loss = 0.0002788820539939608
Trained batch 734 in epoch 5, gen_loss = 1.0368127124650137, disc_loss = 0.00027869846646081607
Trained batch 735 in epoch 5, gen_loss = 1.0368429967404709, disc_loss = 0.00027842222199148597
Trained batch 736 in epoch 5, gen_loss = 1.0367402038063092, disc_loss = 0.00027814791190510315
Trained batch 737 in epoch 5, gen_loss = 1.0366468173540058, disc_loss = 0.00027785843632516493
Trained batch 738 in epoch 5, gen_loss = 1.036692299362126, disc_loss = 0.00027768380486822895
Trained batch 739 in epoch 5, gen_loss = 1.0365132028186643, disc_loss = 0.00027753219391515074
Trained batch 740 in epoch 5, gen_loss = 1.036469115178112, disc_loss = 0.0002774769546653869
Trained batch 741 in epoch 5, gen_loss = 1.036329194863209, disc_loss = 0.0002774497455427162
Trained batch 742 in epoch 5, gen_loss = 1.036303106580095, disc_loss = 0.0002773588609130875
Trained batch 743 in epoch 5, gen_loss = 1.0362254800975963, disc_loss = 0.00027716651775042394
Trained batch 744 in epoch 5, gen_loss = 1.0362213746013258, disc_loss = 0.00027695173094316304
Trained batch 745 in epoch 5, gen_loss = 1.0360882632214645, disc_loss = 0.00027673850919972997
Trained batch 746 in epoch 5, gen_loss = 1.0361698664814594, disc_loss = 0.0002765488001754678
Trained batch 747 in epoch 5, gen_loss = 1.0361347501290674, disc_loss = 0.000276406905523182
Trained batch 748 in epoch 5, gen_loss = 1.0360308839418542, disc_loss = 0.0002763410696100962
Trained batch 749 in epoch 5, gen_loss = 1.0359442443052929, disc_loss = 0.00027672030218915705
Trained batch 750 in epoch 5, gen_loss = 1.0359719943270067, disc_loss = 0.00027691038681689303
Trained batch 751 in epoch 5, gen_loss = 1.0358308790687552, disc_loss = 0.00027681140478849327
Trained batch 752 in epoch 5, gen_loss = 1.0357625023777266, disc_loss = 0.0002766440098968107
Trained batch 753 in epoch 5, gen_loss = 1.0355595574771062, disc_loss = 0.00027648991463693237
Trained batch 754 in epoch 5, gen_loss = 1.0355767480584959, disc_loss = 0.0002763787515300314
Trained batch 755 in epoch 5, gen_loss = 1.0354524076615692, disc_loss = 0.00027631823705974657
Trained batch 756 in epoch 5, gen_loss = 1.035378185099623, disc_loss = 0.0002762076598689756
Trained batch 757 in epoch 5, gen_loss = 1.035389527167368, disc_loss = 0.00027602801271546865
Trained batch 758 in epoch 5, gen_loss = 1.0354871033679827, disc_loss = 0.00027583758371468934
Trained batch 759 in epoch 5, gen_loss = 1.0352662176678056, disc_loss = 0.00027562901868805056
Trained batch 760 in epoch 5, gen_loss = 1.0351512067108053, disc_loss = 0.00027544856132548145
Trained batch 761 in epoch 5, gen_loss = 1.0350317623358698, disc_loss = 0.00027522683068029793
Trained batch 762 in epoch 5, gen_loss = 1.0351155426055387, disc_loss = 0.0002751816347052055
Trained batch 763 in epoch 5, gen_loss = 1.0351156030649915, disc_loss = 0.0002751289407355578
Trained batch 764 in epoch 5, gen_loss = 1.0351305561128006, disc_loss = 0.0002750244895829454
Trained batch 765 in epoch 5, gen_loss = 1.0349859870756264, disc_loss = 0.0002748332990354867
Trained batch 766 in epoch 5, gen_loss = 1.0350240703667313, disc_loss = 0.0002746132502762323
Trained batch 767 in epoch 5, gen_loss = 1.0349757914276172, disc_loss = 0.0002745334014756888
Trained batch 768 in epoch 5, gen_loss = 1.0348197731767117, disc_loss = 0.0002743902706598799
Trained batch 769 in epoch 5, gen_loss = 1.034876953781425, disc_loss = 0.0002741940239124611
Trained batch 770 in epoch 5, gen_loss = 1.0349555323250716, disc_loss = 0.00027409229285378753
Trained batch 771 in epoch 5, gen_loss = 1.0348584970044348, disc_loss = 0.0002738319460569201
Trained batch 772 in epoch 5, gen_loss = 1.0348891275820418, disc_loss = 0.0002735882994425477
Trained batch 773 in epoch 5, gen_loss = 1.0348086622796318, disc_loss = 0.0002734070202412122
Trained batch 774 in epoch 5, gen_loss = 1.0347047616589453, disc_loss = 0.0002733255602652207
Trained batch 775 in epoch 5, gen_loss = 1.034658715359329, disc_loss = 0.00027326276654797036
Trained batch 776 in epoch 5, gen_loss = 1.0347803080097282, disc_loss = 0.00027308364593102674
Trained batch 777 in epoch 5, gen_loss = 1.0346325728611345, disc_loss = 0.0002729097267474852
Trained batch 778 in epoch 5, gen_loss = 1.03478370099992, disc_loss = 0.0002728276757339006
Trained batch 779 in epoch 5, gen_loss = 1.034689652079191, disc_loss = 0.00027280386598133006
Trained batch 780 in epoch 5, gen_loss = 1.0347365811753364, disc_loss = 0.0002731152605162528
Trained batch 781 in epoch 5, gen_loss = 1.0346141263194706, disc_loss = 0.00027340176089740026
Trained batch 782 in epoch 5, gen_loss = 1.034555055096384, disc_loss = 0.00027344011889201484
Trained batch 783 in epoch 5, gen_loss = 1.0344431572878847, disc_loss = 0.0002733944047577097
Trained batch 784 in epoch 5, gen_loss = 1.034363015669926, disc_loss = 0.0002732913932061582
Trained batch 785 in epoch 5, gen_loss = 1.0342111829431306, disc_loss = 0.00027316986254292584
Trained batch 786 in epoch 5, gen_loss = 1.0341276794558407, disc_loss = 0.00027300658256520805
Trained batch 787 in epoch 5, gen_loss = 1.0339589399583449, disc_loss = 0.00027286582913747305
Trained batch 788 in epoch 5, gen_loss = 1.0339192881028159, disc_loss = 0.00027266589583709825
Trained batch 789 in epoch 5, gen_loss = 1.0337167839460735, disc_loss = 0.00027258687918266
Trained batch 790 in epoch 5, gen_loss = 1.0338255632692281, disc_loss = 0.0002726274049658665
Trained batch 791 in epoch 5, gen_loss = 1.0337780595126778, disc_loss = 0.00027262658394730266
Trained batch 792 in epoch 5, gen_loss = 1.0338913442808924, disc_loss = 0.00027266272146904825
Trained batch 793 in epoch 5, gen_loss = 1.0339069900945093, disc_loss = 0.00027254378275449624
Trained batch 794 in epoch 5, gen_loss = 1.033861188618642, disc_loss = 0.0002724008072927629
Trained batch 795 in epoch 5, gen_loss = 1.0339322633779229, disc_loss = 0.00027235824449573426
Trained batch 796 in epoch 5, gen_loss = 1.0338459024614792, disc_loss = 0.0002722307864969206
Trained batch 797 in epoch 5, gen_loss = 1.0337939529042495, disc_loss = 0.0002720553064063824
Trained batch 798 in epoch 5, gen_loss = 1.0337562084347196, disc_loss = 0.00027182473895345137
Trained batch 799 in epoch 5, gen_loss = 1.0335931769013404, disc_loss = 0.00027169671613592073
Trained batch 800 in epoch 5, gen_loss = 1.0335210499245575, disc_loss = 0.00027157502300768725
Trained batch 801 in epoch 5, gen_loss = 1.033522466620305, disc_loss = 0.00027164967270931485
Trained batch 802 in epoch 5, gen_loss = 1.0334662419475922, disc_loss = 0.0002720321576527968
Trained batch 803 in epoch 5, gen_loss = 1.0334712653166025, disc_loss = 0.000272817790659726
Trained batch 804 in epoch 5, gen_loss = 1.0332995625756543, disc_loss = 0.0002737801191932088
Trained batch 805 in epoch 5, gen_loss = 1.0331593910162857, disc_loss = 0.0002746369534651067
Trained batch 806 in epoch 5, gen_loss = 1.0330964445033777, disc_loss = 0.00027504451629876525
Trained batch 807 in epoch 5, gen_loss = 1.033110436088968, disc_loss = 0.00027527231973766507
Trained batch 808 in epoch 5, gen_loss = 1.0329705511389027, disc_loss = 0.00027551223970437365
Trained batch 809 in epoch 5, gen_loss = 1.0328959353912024, disc_loss = 0.00027562741583276446
Trained batch 810 in epoch 5, gen_loss = 1.0329477005763354, disc_loss = 0.0002756926811942727
Trained batch 811 in epoch 5, gen_loss = 1.0329242111573667, disc_loss = 0.0002758702444740722
Trained batch 812 in epoch 5, gen_loss = 1.0328470420866729, disc_loss = 0.0002761991063234835
Trained batch 813 in epoch 5, gen_loss = 1.032919618436101, disc_loss = 0.00027659338753366114
Trained batch 814 in epoch 5, gen_loss = 1.0328042055931559, disc_loss = 0.00027687415084944457
Trained batch 815 in epoch 5, gen_loss = 1.0326730775482513, disc_loss = 0.0002770202204284906
Trained batch 816 in epoch 5, gen_loss = 1.0326578371965462, disc_loss = 0.0002770215515708471
Trained batch 817 in epoch 5, gen_loss = 1.0326737691545835, disc_loss = 0.00027698003854898596
Trained batch 818 in epoch 5, gen_loss = 1.0325992610282804, disc_loss = 0.00027686554254632514
Trained batch 819 in epoch 5, gen_loss = 1.032523166115691, disc_loss = 0.0002767493629085593
Trained batch 820 in epoch 5, gen_loss = 1.0326150313074203, disc_loss = 0.0002767173545901583
Trained batch 821 in epoch 5, gen_loss = 1.0326008595109275, disc_loss = 0.0002767207542183093
Trained batch 822 in epoch 5, gen_loss = 1.0325513540756948, disc_loss = 0.0002766424405946139
Trained batch 823 in epoch 5, gen_loss = 1.0325808238635943, disc_loss = 0.00027645589461738304
Trained batch 824 in epoch 5, gen_loss = 1.032630784294822, disc_loss = 0.00027628062322919227
Trained batch 825 in epoch 5, gen_loss = 1.0325816222455253, disc_loss = 0.0002761728614369987
Trained batch 826 in epoch 5, gen_loss = 1.0325711232575137, disc_loss = 0.0002761103103280534
Trained batch 827 in epoch 5, gen_loss = 1.0325940725740028, disc_loss = 0.00027622948805247616
Trained batch 828 in epoch 5, gen_loss = 1.032642286491049, disc_loss = 0.00027651167833833283
Trained batch 829 in epoch 5, gen_loss = 1.0324673980833536, disc_loss = 0.00027693703773092054
Trained batch 830 in epoch 5, gen_loss = 1.0323338899514878, disc_loss = 0.00027713136193491
Trained batch 831 in epoch 5, gen_loss = 1.0323497172301779, disc_loss = 0.00027727171406975406
Trained batch 832 in epoch 5, gen_loss = 1.03249218605575, disc_loss = 0.0002774641227927719
Trained batch 833 in epoch 5, gen_loss = 1.0323772305350223, disc_loss = 0.00027759980210519065
Trained batch 834 in epoch 5, gen_loss = 1.0322995397858992, disc_loss = 0.0002776070087165209
Trained batch 835 in epoch 5, gen_loss = 1.0323837773794193, disc_loss = 0.00027759360312358875
Trained batch 836 in epoch 5, gen_loss = 1.0323430081137335, disc_loss = 0.00027743309294026605
Trained batch 837 in epoch 5, gen_loss = 1.0323286180991262, disc_loss = 0.00027728508872761857
Trained batch 838 in epoch 5, gen_loss = 1.0322815698434968, disc_loss = 0.00027714463041224476
Trained batch 839 in epoch 5, gen_loss = 1.0323683097248986, disc_loss = 0.00027699868769559544
Trained batch 840 in epoch 5, gen_loss = 1.0322759775145867, disc_loss = 0.0002768168489030129
Trained batch 841 in epoch 5, gen_loss = 1.0322793191232478, disc_loss = 0.00027661973081086433
Trained batch 842 in epoch 5, gen_loss = 1.0321989943265633, disc_loss = 0.00027639905912689764
Trained batch 843 in epoch 5, gen_loss = 1.032286796383383, disc_loss = 0.0002761891110300476
Trained batch 844 in epoch 5, gen_loss = 1.032206873710339, disc_loss = 0.0002759912819756586
Trained batch 845 in epoch 5, gen_loss = 1.032115804176804, disc_loss = 0.00027589539449570326
Trained batch 846 in epoch 5, gen_loss = 1.0319502071478572, disc_loss = 0.00027589817143504705
Trained batch 847 in epoch 5, gen_loss = 1.0319416142718971, disc_loss = 0.00027588863351308456
Trained batch 848 in epoch 5, gen_loss = 1.031804581764028, disc_loss = 0.00027592774984053556
Trained batch 849 in epoch 5, gen_loss = 1.0317318824459525, disc_loss = 0.00027596045712604845
Trained batch 850 in epoch 5, gen_loss = 1.0317013728072304, disc_loss = 0.0002759319662507574
Trained batch 851 in epoch 5, gen_loss = 1.0316216071166902, disc_loss = 0.0002759818344287757
Trained batch 852 in epoch 5, gen_loss = 1.031624724129859, disc_loss = 0.0002759624955774305
Trained batch 853 in epoch 5, gen_loss = 1.0315647010780888, disc_loss = 0.0002759535106678577
Trained batch 854 in epoch 5, gen_loss = 1.0314909326402764, disc_loss = 0.00027593833690322666
Trained batch 855 in epoch 5, gen_loss = 1.0315188809393723, disc_loss = 0.00027588814584951504
Trained batch 856 in epoch 5, gen_loss = 1.0314880818858865, disc_loss = 0.0002758228053895636
Trained batch 857 in epoch 5, gen_loss = 1.031416968101666, disc_loss = 0.0002757300550968409
Trained batch 858 in epoch 5, gen_loss = 1.0314705618185547, disc_loss = 0.00027556764398129846
Trained batch 859 in epoch 5, gen_loss = 1.031385069461756, disc_loss = 0.0002753383351244888
Trained batch 860 in epoch 5, gen_loss = 1.031560583050935, disc_loss = 0.000275135147267667
Trained batch 861 in epoch 5, gen_loss = 1.0314705365633468, disc_loss = 0.0002750074726233924
Trained batch 862 in epoch 5, gen_loss = 1.031654398590499, disc_loss = 0.00027496270351932056
Trained batch 863 in epoch 5, gen_loss = 1.031570402905345, disc_loss = 0.00027507147064574785
Trained batch 864 in epoch 5, gen_loss = 1.031600251432099, disc_loss = 0.0002753259904811837
Trained batch 865 in epoch 5, gen_loss = 1.031613665351141, disc_loss = 0.00027531746107607426
Trained batch 866 in epoch 5, gen_loss = 1.0316968771963109, disc_loss = 0.0002752280235136113
Trained batch 867 in epoch 5, gen_loss = 1.031699460978332, disc_loss = 0.0002750407645184722
Trained batch 868 in epoch 5, gen_loss = 1.0317721984877548, disc_loss = 0.0002748418282674598
Trained batch 869 in epoch 5, gen_loss = 1.0317600938780553, disc_loss = 0.0002746386206294035
Trained batch 870 in epoch 5, gen_loss = 1.031932607789264, disc_loss = 0.00027449646702434026
Trained batch 871 in epoch 5, gen_loss = 1.0318989383928272, disc_loss = 0.0002744057133611999
Trained batch 872 in epoch 5, gen_loss = 1.0319656493464422, disc_loss = 0.00027431050237955765
Trained batch 873 in epoch 5, gen_loss = 1.0319042514745376, disc_loss = 0.00027429019572819077
Trained batch 874 in epoch 5, gen_loss = 1.0317960448265076, disc_loss = 0.0002742756678489968
Trained batch 875 in epoch 5, gen_loss = 1.0319012977080801, disc_loss = 0.00027432576217967697
Trained batch 876 in epoch 5, gen_loss = 1.031819979916141, disc_loss = 0.0002743486559291677
Trained batch 877 in epoch 5, gen_loss = 1.0318140743941, disc_loss = 0.0002743163758352906
Trained batch 878 in epoch 5, gen_loss = 1.031779349257108, disc_loss = 0.0002742715446821195
Trained batch 879 in epoch 5, gen_loss = 1.0318184950812297, disc_loss = 0.00027425715966687263
Trained batch 880 in epoch 5, gen_loss = 1.0317962519427029, disc_loss = 0.00027429364334168727
Trained batch 881 in epoch 5, gen_loss = 1.0317718123767923, disc_loss = 0.0002743347765303158
Trained batch 882 in epoch 5, gen_loss = 1.0318610577054095, disc_loss = 0.00027430637062662774
Trained batch 883 in epoch 5, gen_loss = 1.0317930930475303, disc_loss = 0.0002741750997705311
Trained batch 884 in epoch 5, gen_loss = 1.0317971774413761, disc_loss = 0.00027398053517382285
Trained batch 885 in epoch 5, gen_loss = 1.031950883954158, disc_loss = 0.0002738613210060464
Trained batch 886 in epoch 5, gen_loss = 1.0318848461147898, disc_loss = 0.00027368047696999204
Trained batch 887 in epoch 5, gen_loss = 1.031876131825082, disc_loss = 0.0002734934196924515
Trained batch 888 in epoch 5, gen_loss = 1.031833901649385, disc_loss = 0.00027333088285787054
Trained batch 889 in epoch 5, gen_loss = 1.031816006979246, disc_loss = 0.000273198124030775
Trained batch 890 in epoch 5, gen_loss = 1.031769081598982, disc_loss = 0.0002730953027761445
Trained batch 891 in epoch 5, gen_loss = 1.0317274404213568, disc_loss = 0.0002730711997748846
Trained batch 892 in epoch 5, gen_loss = 1.0318695991597278, disc_loss = 0.0002731431846944005
Trained batch 893 in epoch 5, gen_loss = 1.0319059495157843, disc_loss = 0.0002733287109563807
Trained batch 894 in epoch 5, gen_loss = 1.0320161054920218, disc_loss = 0.0002735601071877712
Trained batch 895 in epoch 5, gen_loss = 1.0319871854569231, disc_loss = 0.00027361587487868225
Trained batch 896 in epoch 5, gen_loss = 1.0319528832217655, disc_loss = 0.0002736701542403733
Trained batch 897 in epoch 5, gen_loss = 1.0319521043507718, disc_loss = 0.0002737872162668521
Trained batch 898 in epoch 5, gen_loss = 1.0318809002472111, disc_loss = 0.0002739197659520282
Trained batch 899 in epoch 5, gen_loss = 1.0318981409072876, disc_loss = 0.00027396504881229094
Trained batch 900 in epoch 5, gen_loss = 1.0319106023134323, disc_loss = 0.00027399562759001633
Trained batch 901 in epoch 5, gen_loss = 1.0317550549353833, disc_loss = 0.00027404882984129793
Trained batch 902 in epoch 5, gen_loss = 1.0318232850642959, disc_loss = 0.0002742152937249217
Trained batch 903 in epoch 5, gen_loss = 1.0319651479346563, disc_loss = 0.00027435006745489554
Trained batch 904 in epoch 5, gen_loss = 1.0319636287610174, disc_loss = 0.0002744956274316852
Trained batch 905 in epoch 5, gen_loss = 1.0320571935334741, disc_loss = 0.00027467509392330527
Trained batch 906 in epoch 5, gen_loss = 1.0320093673145627, disc_loss = 0.0002746976871478429
Trained batch 907 in epoch 5, gen_loss = 1.0320110982078812, disc_loss = 0.00027469133592082753
Trained batch 908 in epoch 5, gen_loss = 1.0321252264074234, disc_loss = 0.0002747118671064683
Trained batch 909 in epoch 5, gen_loss = 1.0320860506414058, disc_loss = 0.0002748733353535619
Trained batch 910 in epoch 5, gen_loss = 1.0320846757040851, disc_loss = 0.0002751312402126729
Trained batch 911 in epoch 5, gen_loss = 1.0320103677610557, disc_loss = 0.00027537485460957294
Trained batch 912 in epoch 5, gen_loss = 1.0321100641445942, disc_loss = 0.00027565808856237816
Trained batch 913 in epoch 5, gen_loss = 1.032162861503188, disc_loss = 0.00027599496992782046
Trained batch 914 in epoch 5, gen_loss = 1.032095004105177, disc_loss = 0.0002763797614047217
Trained batch 915 in epoch 5, gen_loss = 1.0321389774438074, disc_loss = 0.0002768839284484442
Trained batch 916 in epoch 5, gen_loss = 1.0320357806419989, disc_loss = 0.00027751824210608386
Trained batch 917 in epoch 5, gen_loss = 1.0321550569892708, disc_loss = 0.00027808794235281313
Trained batch 918 in epoch 5, gen_loss = 1.0321036583710548, disc_loss = 0.00027831651370495333
Trained batch 919 in epoch 5, gen_loss = 1.0320583754259607, disc_loss = 0.00027830322494043247
Trained batch 920 in epoch 5, gen_loss = 1.0320408962966305, disc_loss = 0.0002783480397518244
Trained batch 921 in epoch 5, gen_loss = 1.032002929234453, disc_loss = 0.0002786027144357474
Trained batch 922 in epoch 5, gen_loss = 1.031954239145777, disc_loss = 0.00027901927808523917
Trained batch 923 in epoch 5, gen_loss = 1.0318542983366814, disc_loss = 0.000279472715656832
Trained batch 924 in epoch 5, gen_loss = 1.0318356870960546, disc_loss = 0.0002798425467650255
Trained batch 925 in epoch 5, gen_loss = 1.031769595444846, disc_loss = 0.0002800976643837273
Trained batch 926 in epoch 5, gen_loss = 1.0316793175319767, disc_loss = 0.00028015990138784537
Trained batch 927 in epoch 5, gen_loss = 1.0316829767463536, disc_loss = 0.00028003980267793193
Trained batch 928 in epoch 5, gen_loss = 1.0316598054795527, disc_loss = 0.00027984117835979917
Trained batch 929 in epoch 5, gen_loss = 1.0316041236923588, disc_loss = 0.00027962554974878277
Trained batch 930 in epoch 5, gen_loss = 1.0315492110272868, disc_loss = 0.0002794347675212721
Trained batch 931 in epoch 5, gen_loss = 1.0315942406782266, disc_loss = 0.00027927959395382434
Trained batch 932 in epoch 5, gen_loss = 1.0315728952263712, disc_loss = 0.00027918887669728403
Trained batch 933 in epoch 5, gen_loss = 1.0315143767848005, disc_loss = 0.0002790800207134359
Trained batch 934 in epoch 5, gen_loss = 1.0314203688167634, disc_loss = 0.0002789519670189677
Trained batch 935 in epoch 5, gen_loss = 1.0314550435441172, disc_loss = 0.0002789797203631601
Trained batch 936 in epoch 5, gen_loss = 1.031399263261858, disc_loss = 0.0002793111896281888
Trained batch 937 in epoch 5, gen_loss = 1.0313628835718769, disc_loss = 0.00027971080373142356
Trained batch 938 in epoch 5, gen_loss = 1.0313529249705191, disc_loss = 0.00027990216262437973
Trained batch 939 in epoch 5, gen_loss = 1.03137315866795, disc_loss = 0.0002798604737998833
Trained batch 940 in epoch 5, gen_loss = 1.0312981334426832, disc_loss = 0.00027988786366959936
Trained batch 941 in epoch 5, gen_loss = 1.0313190926665208, disc_loss = 0.00028013129979331244
Trained batch 942 in epoch 5, gen_loss = 1.0313166384985186, disc_loss = 0.00028034452981978985
Trained batch 943 in epoch 5, gen_loss = 1.0313597454105394, disc_loss = 0.0002803513508852274
Trained batch 944 in epoch 5, gen_loss = 1.0314108135838989, disc_loss = 0.00028020588017565264
Trained batch 945 in epoch 5, gen_loss = 1.031390387588525, disc_loss = 0.0002801224574688246
Trained batch 946 in epoch 5, gen_loss = 1.0313331533258794, disc_loss = 0.00027999180277219187
Trained batch 947 in epoch 5, gen_loss = 1.0312810528881942, disc_loss = 0.0002798719856918633
Trained batch 948 in epoch 5, gen_loss = 1.031121459348938, disc_loss = 0.000279706053707704
Trained batch 949 in epoch 5, gen_loss = 1.031209095151801, disc_loss = 0.0002797037586768918
Trained batch 950 in epoch 5, gen_loss = 1.0312717976254244, disc_loss = 0.0002798701649545555
Trained batch 951 in epoch 5, gen_loss = 1.0312717895047003, disc_loss = 0.00028012046451073095
Trained batch 952 in epoch 5, gen_loss = 1.0311386843543238, disc_loss = 0.0002803451104160102
Trained batch 953 in epoch 5, gen_loss = 1.0309989295540616, disc_loss = 0.000280685400374859
Trained batch 954 in epoch 5, gen_loss = 1.031080252025764, disc_loss = 0.00028130338523148056
Trained batch 955 in epoch 5, gen_loss = 1.0312036192940868, disc_loss = 0.00028193628812720465
Trained batch 956 in epoch 5, gen_loss = 1.0312636047445993, disc_loss = 0.0002824701592713607
Trained batch 957 in epoch 5, gen_loss = 1.0312136619474295, disc_loss = 0.0002827248848430421
Trained batch 958 in epoch 5, gen_loss = 1.0311588904159037, disc_loss = 0.0002828755525183695
Trained batch 959 in epoch 5, gen_loss = 1.0311779920011759, disc_loss = 0.0002828973731160052
Trained batch 960 in epoch 5, gen_loss = 1.0311738565238533, disc_loss = 0.0002828665165830637
Trained batch 961 in epoch 5, gen_loss = 1.0310614858124707, disc_loss = 0.0002827737204263518
Trained batch 962 in epoch 5, gen_loss = 1.0311838452194586, disc_loss = 0.0002826396053651979
Trained batch 963 in epoch 5, gen_loss = 1.0311480515107079, disc_loss = 0.00028248647976099344
Trained batch 964 in epoch 5, gen_loss = 1.031059974771707, disc_loss = 0.00028234887469307776
Trained batch 965 in epoch 5, gen_loss = 1.0310677557134726, disc_loss = 0.0002822256295529737
Trained batch 966 in epoch 5, gen_loss = 1.0310333782292695, disc_loss = 0.0002820751277529182
Trained batch 967 in epoch 5, gen_loss = 1.0308891074839703, disc_loss = 0.00028195997554365565
Trained batch 968 in epoch 5, gen_loss = 1.0310609878893362, disc_loss = 0.0002819088845204642
Trained batch 969 in epoch 5, gen_loss = 1.0309656951230826, disc_loss = 0.0002819702216377842
Trained batch 970 in epoch 5, gen_loss = 1.0310122083439026, disc_loss = 0.0002821929239972838
Trained batch 971 in epoch 5, gen_loss = 1.0308840633542449, disc_loss = 0.00028257138987804555
Trained batch 972 in epoch 5, gen_loss = 1.03082049199268, disc_loss = 0.00028289845522428753
Trained batch 973 in epoch 5, gen_loss = 1.0307506702274267, disc_loss = 0.00028305697808436833
Trained batch 974 in epoch 5, gen_loss = 1.0307121223058455, disc_loss = 0.0002832223097599732
Trained batch 975 in epoch 5, gen_loss = 1.0306859254592755, disc_loss = 0.0002840950546595225
Trained batch 976 in epoch 5, gen_loss = 1.0307020440682417, disc_loss = 0.00028530066317878424
Trained batch 977 in epoch 5, gen_loss = 1.0306427018042723, disc_loss = 0.00028611039494492584
Trained batch 978 in epoch 5, gen_loss = 1.0306870182395833, disc_loss = 0.00028655149805994774
Trained batch 979 in epoch 5, gen_loss = 1.0307093613001765, disc_loss = 0.0002867416965365956
Trained batch 980 in epoch 5, gen_loss = 1.0305878572872291, disc_loss = 0.0002868542435507681
Trained batch 981 in epoch 5, gen_loss = 1.0305096550774429, disc_loss = 0.0002869341960776092
Trained batch 982 in epoch 5, gen_loss = 1.0304621153663642, disc_loss = 0.0002868966531457445
Trained batch 983 in epoch 5, gen_loss = 1.0304557215876695, disc_loss = 0.0002868162735141847
Trained batch 984 in epoch 5, gen_loss = 1.0305218916859118, disc_loss = 0.00028676993279631586
Trained batch 985 in epoch 5, gen_loss = 1.0305016514737515, disc_loss = 0.00028675068226947757
Trained batch 986 in epoch 5, gen_loss = 1.0305535819875917, disc_loss = 0.00028684196696684413
Trained batch 987 in epoch 5, gen_loss = 1.0306286375049638, disc_loss = 0.0002868837128491268
Trained batch 988 in epoch 5, gen_loss = 1.0304569450740988, disc_loss = 0.0002869647302232467
Trained batch 989 in epoch 5, gen_loss = 1.0304010931891625, disc_loss = 0.00028698829794508365
Trained batch 990 in epoch 5, gen_loss = 1.0303234006273518, disc_loss = 0.0002868681253706656
Trained batch 991 in epoch 5, gen_loss = 1.0303064670053221, disc_loss = 0.0002868357943674299
Trained batch 992 in epoch 5, gen_loss = 1.0302659889002221, disc_loss = 0.00028667811441995166
Trained batch 993 in epoch 5, gen_loss = 1.0301409337362293, disc_loss = 0.0002865380807099859
Trained batch 994 in epoch 5, gen_loss = 1.0301919007421139, disc_loss = 0.000286434774821444
Trained batch 995 in epoch 5, gen_loss = 1.030149969829613, disc_loss = 0.00028633566852290807
Trained batch 996 in epoch 5, gen_loss = 1.0302032601749647, disc_loss = 0.0002863151759625349
Trained batch 997 in epoch 5, gen_loss = 1.0301523013917622, disc_loss = 0.00028630217714968907
Trained batch 998 in epoch 5, gen_loss = 1.0302269263071817, disc_loss = 0.00028620002945194963
Trained batch 999 in epoch 5, gen_loss = 1.030214068889618, disc_loss = 0.0002861500336948666
Trained batch 1000 in epoch 5, gen_loss = 1.0302857160568237, disc_loss = 0.0002861859271700911
Trained batch 1001 in epoch 5, gen_loss = 1.03023523984555, disc_loss = 0.000286176026767822
Trained batch 1002 in epoch 5, gen_loss = 1.0302839982782974, disc_loss = 0.0002862107811691467
Trained batch 1003 in epoch 5, gen_loss = 1.0303045478000108, disc_loss = 0.00028635649832142507
Trained batch 1004 in epoch 5, gen_loss = 1.0303078088001232, disc_loss = 0.000286591884126106
Trained batch 1005 in epoch 5, gen_loss = 1.0303117318845412, disc_loss = 0.0002868575478204879
Trained batch 1006 in epoch 5, gen_loss = 1.0303191635554219, disc_loss = 0.000286865769687505
Trained batch 1007 in epoch 5, gen_loss = 1.0302139253961662, disc_loss = 0.0002867581198939112
Trained batch 1008 in epoch 5, gen_loss = 1.0301057909595954, disc_loss = 0.0002866130260217264
Trained batch 1009 in epoch 5, gen_loss = 1.0299480044015563, disc_loss = 0.00028647095933043637
Trained batch 1010 in epoch 5, gen_loss = 1.0299753197104948, disc_loss = 0.00028643298970712033
Trained batch 1011 in epoch 5, gen_loss = 1.0299775656975305, disc_loss = 0.00028716484467647814
Trained batch 1012 in epoch 5, gen_loss = 1.0299223391348376, disc_loss = 0.00028789606997195076
Trained batch 1013 in epoch 5, gen_loss = 1.0300360162700186, disc_loss = 0.0002881823810096072
Trained batch 1014 in epoch 5, gen_loss = 1.0300642182087076, disc_loss = 0.0002881179818108774
Trained batch 1015 in epoch 5, gen_loss = 1.0300439525190301, disc_loss = 0.0002880059230123811
Trained batch 1016 in epoch 5, gen_loss = 1.0300088701815497, disc_loss = 0.00028793309685333897
Trained batch 1017 in epoch 5, gen_loss = 1.0301172688222822, disc_loss = 0.00028790327852454875
Trained batch 1018 in epoch 5, gen_loss = 1.0301181593282884, disc_loss = 0.00028786516903427323
Trained batch 1019 in epoch 5, gen_loss = 1.0301386277465259, disc_loss = 0.0002878231101217976
Trained batch 1020 in epoch 5, gen_loss = 1.0301251461059877, disc_loss = 0.0002878208051679768
Trained batch 1021 in epoch 5, gen_loss = 1.0301551597808905, disc_loss = 0.00028779531546478584
Trained batch 1022 in epoch 5, gen_loss = 1.0303342189140916, disc_loss = 0.0002878551376985913
Trained batch 1023 in epoch 5, gen_loss = 1.0302197928540409, disc_loss = 0.00028780323280130915
Trained batch 1024 in epoch 5, gen_loss = 1.0302130729396168, disc_loss = 0.0002877739648882686
Trained batch 1025 in epoch 5, gen_loss = 1.03015993852132, disc_loss = 0.00028776594419759646
Trained batch 1026 in epoch 5, gen_loss = 1.030076917794106, disc_loss = 0.0002877850506340558
Trained batch 1027 in epoch 5, gen_loss = 1.0299763976367995, disc_loss = 0.0002879692770585219
Trained batch 1028 in epoch 5, gen_loss = 1.0299653543559408, disc_loss = 0.00028810424085343764
Trained batch 1029 in epoch 5, gen_loss = 1.0299219979823215, disc_loss = 0.000288165871510836
Trained batch 1030 in epoch 5, gen_loss = 1.0299057766260393, disc_loss = 0.00028814084427870466
Trained batch 1031 in epoch 5, gen_loss = 1.0299610331539035, disc_loss = 0.0002881206428637668
Trained batch 1032 in epoch 5, gen_loss = 1.0298951189146384, disc_loss = 0.00028799481687873254
Trained batch 1033 in epoch 5, gen_loss = 1.0300287969799522, disc_loss = 0.00028785301109489255
Trained batch 1034 in epoch 5, gen_loss = 1.030039093690218, disc_loss = 0.00028781573701360837
Trained batch 1035 in epoch 5, gen_loss = 1.029930751698818, disc_loss = 0.0002878324228795007
Trained batch 1036 in epoch 5, gen_loss = 1.0299784444567093, disc_loss = 0.00028783898797552366
Trained batch 1037 in epoch 5, gen_loss = 1.0300721329186464, disc_loss = 0.0002878432501636707
Trained batch 1038 in epoch 5, gen_loss = 1.0301838058250472, disc_loss = 0.00028797047026808345
Trained batch 1039 in epoch 5, gen_loss = 1.0301589875840225, disc_loss = 0.0002879924682299763
Trained batch 1040 in epoch 5, gen_loss = 1.0301539959183803, disc_loss = 0.0002880483605047553
Trained batch 1041 in epoch 5, gen_loss = 1.0300974255559998, disc_loss = 0.0002880832628040747
Trained batch 1042 in epoch 5, gen_loss = 1.0299971609993384, disc_loss = 0.0002880158475886478
Trained batch 1043 in epoch 5, gen_loss = 1.0300392518783439, disc_loss = 0.00028794627972786855
Trained batch 1044 in epoch 5, gen_loss = 1.0300856757962533, disc_loss = 0.0002877995592603821
Trained batch 1045 in epoch 5, gen_loss = 1.030039948954409, disc_loss = 0.00028765439857606574
Trained batch 1046 in epoch 5, gen_loss = 1.0299705417245029, disc_loss = 0.00028760903011372583
Trained batch 1047 in epoch 5, gen_loss = 1.0300260815229125, disc_loss = 0.0002875689699400402
Trained batch 1048 in epoch 5, gen_loss = 1.03011509722136, disc_loss = 0.00028762251436911226
Trained batch 1049 in epoch 5, gen_loss = 1.0301464586030868, disc_loss = 0.0002878594541315189
Trained batch 1050 in epoch 5, gen_loss = 1.030164289542542, disc_loss = 0.0002881744361233226
Trained batch 1051 in epoch 5, gen_loss = 1.030124582208608, disc_loss = 0.00028872196022701094
Trained batch 1052 in epoch 5, gen_loss = 1.0301036763961047, disc_loss = 0.0002892802669110059
Trained batch 1053 in epoch 5, gen_loss = 1.0301426256064898, disc_loss = 0.00028987609758489123
Trained batch 1054 in epoch 5, gen_loss = 1.0300813857977988, disc_loss = 0.0002903536815978079
Trained batch 1055 in epoch 5, gen_loss = 1.0300842832886812, disc_loss = 0.0002906385011487366
Trained batch 1056 in epoch 5, gen_loss = 1.0299715472485733, disc_loss = 0.0002907596507617766
Trained batch 1057 in epoch 5, gen_loss = 1.0298859559295308, disc_loss = 0.0002907959825882714
Trained batch 1058 in epoch 5, gen_loss = 1.0297994685690846, disc_loss = 0.0002906778350284361
Trained batch 1059 in epoch 5, gen_loss = 1.0296501737720563, disc_loss = 0.0002906851331060335
Trained batch 1060 in epoch 5, gen_loss = 1.0296840054263043, disc_loss = 0.000290869166772002
Trained batch 1061 in epoch 5, gen_loss = 1.0296905076660903, disc_loss = 0.00029107361705738065
Trained batch 1062 in epoch 5, gen_loss = 1.0297639648082226, disc_loss = 0.000291274947518457
Trained batch 1063 in epoch 5, gen_loss = 1.0296430420830733, disc_loss = 0.00029141675226730196
Trained batch 1064 in epoch 5, gen_loss = 1.0296091841979766, disc_loss = 0.00029149941828548955
Trained batch 1065 in epoch 5, gen_loss = 1.0295499753325785, disc_loss = 0.0002914809016764752
Trained batch 1066 in epoch 5, gen_loss = 1.0294405572751804, disc_loss = 0.0002913954477972044
Trained batch 1067 in epoch 5, gen_loss = 1.0294733501775435, disc_loss = 0.00029127894911939263
Trained batch 1068 in epoch 5, gen_loss = 1.0294616207884673, disc_loss = 0.00029109940326092434
Trained batch 1069 in epoch 5, gen_loss = 1.0295105812705565, disc_loss = 0.0002910059895847867
Trained batch 1070 in epoch 5, gen_loss = 1.0294352154883126, disc_loss = 0.00029092812407541154
Trained batch 1071 in epoch 5, gen_loss = 1.029409868114475, disc_loss = 0.0002907691326262425
Trained batch 1072 in epoch 5, gen_loss = 1.0293895792205647, disc_loss = 0.0002906542322409074
Trained batch 1073 in epoch 5, gen_loss = 1.029330402945673, disc_loss = 0.0002905472790275755
Trained batch 1074 in epoch 5, gen_loss = 1.0293687691244968, disc_loss = 0.00029043915154287854
Trained batch 1075 in epoch 5, gen_loss = 1.0293667752392672, disc_loss = 0.00029032581168559913
Trained batch 1076 in epoch 5, gen_loss = 1.029398565670906, disc_loss = 0.00029019864639160314
Trained batch 1077 in epoch 5, gen_loss = 1.029385383087098, disc_loss = 0.00029006212454636715
Trained batch 1078 in epoch 5, gen_loss = 1.0294395526655302, disc_loss = 0.00028997003995370854
Trained batch 1079 in epoch 5, gen_loss = 1.0294914356536335, disc_loss = 0.00028989966289777333
Trained batch 1080 in epoch 5, gen_loss = 1.0294446054153372, disc_loss = 0.00028991090293789963
Trained batch 1081 in epoch 5, gen_loss = 1.029351776827285, disc_loss = 0.0002897972875208979
Trained batch 1082 in epoch 5, gen_loss = 1.029324004744779, disc_loss = 0.0002897182092699308
Trained batch 1083 in epoch 5, gen_loss = 1.0292981350553871, disc_loss = 0.00028966765241615595
Trained batch 1084 in epoch 5, gen_loss = 1.0292707559150485, disc_loss = 0.00028957156308208836
Trained batch 1085 in epoch 5, gen_loss = 1.029241271605149, disc_loss = 0.0002895145331844186
Trained batch 1086 in epoch 5, gen_loss = 1.0292185025688916, disc_loss = 0.00028947115286448097
Trained batch 1087 in epoch 5, gen_loss = 1.0291442775770145, disc_loss = 0.0002894240404483593
Trained batch 1088 in epoch 5, gen_loss = 1.0290436229101554, disc_loss = 0.0002893436366587529
Trained batch 1089 in epoch 5, gen_loss = 1.0290292430361476, disc_loss = 0.00028933721881946165
Trained batch 1090 in epoch 5, gen_loss = 1.0289633710596344, disc_loss = 0.00028937675590260043
Trained batch 1091 in epoch 5, gen_loss = 1.0289616049318524, disc_loss = 0.00028947711562135066
Trained batch 1092 in epoch 5, gen_loss = 1.0288707193495044, disc_loss = 0.000289652830278486
Trained batch 1093 in epoch 5, gen_loss = 1.028859646054465, disc_loss = 0.0002897324377819968
Trained batch 1094 in epoch 5, gen_loss = 1.0288349690502636, disc_loss = 0.0002897700618383194
Trained batch 1095 in epoch 5, gen_loss = 1.0288628943427636, disc_loss = 0.00028970998525178703
Trained batch 1096 in epoch 5, gen_loss = 1.0288608183943366, disc_loss = 0.0002895656408702911
Trained batch 1097 in epoch 5, gen_loss = 1.0287975573366022, disc_loss = 0.00028940340941561933
Trained batch 1098 in epoch 5, gen_loss = 1.028707409794489, disc_loss = 0.00028923800735048197
Trained batch 1099 in epoch 5, gen_loss = 1.028807230537588, disc_loss = 0.0002891035569336964
Trained batch 1100 in epoch 5, gen_loss = 1.028858969040506, disc_loss = 0.00028900232131925577
Trained batch 1101 in epoch 5, gen_loss = 1.0289540025802792, disc_loss = 0.0002889549890190288
Trained batch 1102 in epoch 5, gen_loss = 1.0288455946707011, disc_loss = 0.00028894363636616826
Trained batch 1103 in epoch 5, gen_loss = 1.028811923943568, disc_loss = 0.0002889121073813062
Trained batch 1104 in epoch 5, gen_loss = 1.028786839942587, disc_loss = 0.00028886681189365494
Trained batch 1105 in epoch 5, gen_loss = 1.0289313397614477, disc_loss = 0.00028887794429090447
Trained batch 1106 in epoch 5, gen_loss = 1.0289381797397685, disc_loss = 0.00028902588330480364
Trained batch 1107 in epoch 5, gen_loss = 1.028879524568358, disc_loss = 0.000289333120209557
Trained batch 1108 in epoch 5, gen_loss = 1.028832926096628, disc_loss = 0.0002895751969403935
Trained batch 1109 in epoch 5, gen_loss = 1.0288659180606807, disc_loss = 0.00028974325027078735
Trained batch 1110 in epoch 5, gen_loss = 1.028874493203219, disc_loss = 0.000289847201680143
Trained batch 1111 in epoch 5, gen_loss = 1.02887403868514, disc_loss = 0.00028988154176560864
Trained batch 1112 in epoch 5, gen_loss = 1.0287580885334477, disc_loss = 0.0002898734817583125
Trained batch 1113 in epoch 5, gen_loss = 1.0287191650597796, disc_loss = 0.00028979318716407156
Trained batch 1114 in epoch 5, gen_loss = 1.028794455955916, disc_loss = 0.000289685201144416
Trained batch 1115 in epoch 5, gen_loss = 1.0287660787609743, disc_loss = 0.00028961025539805024
Trained batch 1116 in epoch 5, gen_loss = 1.0288580884438279, disc_loss = 0.00028957692938595187
Trained batch 1117 in epoch 5, gen_loss = 1.0288612540804636, disc_loss = 0.0002894802714381155
Trained batch 1118 in epoch 5, gen_loss = 1.028875820012472, disc_loss = 0.0002893111281191295
Trained batch 1119 in epoch 5, gen_loss = 1.0289501606353693, disc_loss = 0.0002891490102488855
Trained batch 1120 in epoch 5, gen_loss = 1.0288462274633914, disc_loss = 0.0002889738818670558
Trained batch 1121 in epoch 5, gen_loss = 1.0290714752546606, disc_loss = 0.00028887039147394814
Trained batch 1122 in epoch 5, gen_loss = 1.0290338369957168, disc_loss = 0.0002887760032923002
Trained batch 1123 in epoch 5, gen_loss = 1.029049741733965, disc_loss = 0.00028868658093376596
Trained batch 1124 in epoch 5, gen_loss = 1.029041434288025, disc_loss = 0.0002885917923348542
Trained batch 1125 in epoch 5, gen_loss = 1.029069654577367, disc_loss = 0.0002885702494138477
Trained batch 1126 in epoch 5, gen_loss = 1.0291147661505278, disc_loss = 0.00028865469764427845
Trained batch 1127 in epoch 5, gen_loss = 1.0291066115840952, disc_loss = 0.00028869328777823253
Trained batch 1128 in epoch 5, gen_loss = 1.0290984338738414, disc_loss = 0.0002888388069347269
Trained batch 1129 in epoch 5, gen_loss = 1.0290335618816646, disc_loss = 0.0002889801761425467
Trained batch 1130 in epoch 5, gen_loss = 1.0290160760428397, disc_loss = 0.00028907223458843025
Trained batch 1131 in epoch 5, gen_loss = 1.029123842347637, disc_loss = 0.0002892227416449081
Trained batch 1132 in epoch 5, gen_loss = 1.029187715011472, disc_loss = 0.00028931501571869724
Trained batch 1133 in epoch 5, gen_loss = 1.0291241344320712, disc_loss = 0.0002892782092991148
Trained batch 1134 in epoch 5, gen_loss = 1.0292070099960864, disc_loss = 0.00028931690299332694
Trained batch 1135 in epoch 5, gen_loss = 1.0292545840354033, disc_loss = 0.0002892950084560012
Trained batch 1136 in epoch 5, gen_loss = 1.0292206473170191, disc_loss = 0.0002894631650436751
Trained batch 1137 in epoch 5, gen_loss = 1.0291223453197411, disc_loss = 0.00028981632926915234
Trained batch 1138 in epoch 5, gen_loss = 1.0291663370078021, disc_loss = 0.00029020611441111
Trained batch 1139 in epoch 5, gen_loss = 1.0291832094129763, disc_loss = 0.0002906750428800271
Trained batch 1140 in epoch 5, gen_loss = 1.0290840477090881, disc_loss = 0.000290998623694514
Trained batch 1141 in epoch 5, gen_loss = 1.029132028960096, disc_loss = 0.0002913349735392678
Trained batch 1142 in epoch 5, gen_loss = 1.0290766859513465, disc_loss = 0.0002914201919873382
Trained batch 1143 in epoch 5, gen_loss = 1.0291466054382858, disc_loss = 0.0002914417453695449
Trained batch 1144 in epoch 5, gen_loss = 1.0290967133367948, disc_loss = 0.00029136219220647717
Trained batch 1145 in epoch 5, gen_loss = 1.0290287999374497, disc_loss = 0.0002912720712889689
Trained batch 1146 in epoch 5, gen_loss = 1.0289046993022808, disc_loss = 0.00029119005693164764
Trained batch 1147 in epoch 5, gen_loss = 1.0289126512065583, disc_loss = 0.0002910353116832981
Trained batch 1148 in epoch 5, gen_loss = 1.028941621253343, disc_loss = 0.00029091559722659916
Trained batch 1149 in epoch 5, gen_loss = 1.0290338870753413, disc_loss = 0.00029076669114621597
Trained batch 1150 in epoch 5, gen_loss = 1.0291148882964505, disc_loss = 0.0002906260115883801
Trained batch 1151 in epoch 5, gen_loss = 1.0291470281986728, disc_loss = 0.0002904689533617481
Trained batch 1152 in epoch 5, gen_loss = 1.029177417056207, disc_loss = 0.0002903120304366064
Trained batch 1153 in epoch 5, gen_loss = 1.0291576016713677, disc_loss = 0.0002901922542677181
Trained batch 1154 in epoch 5, gen_loss = 1.029164825992667, disc_loss = 0.00029006311160313707
Trained batch 1155 in epoch 5, gen_loss = 1.0290223532275757, disc_loss = 0.00028995848267491636
Trained batch 1156 in epoch 5, gen_loss = 1.0289755027255005, disc_loss = 0.00028994142200441405
Trained batch 1157 in epoch 5, gen_loss = 1.0290167944213064, disc_loss = 0.0002900146564806225
Trained batch 1158 in epoch 5, gen_loss = 1.028937580104117, disc_loss = 0.00028999698988502084
Trained batch 1159 in epoch 5, gen_loss = 1.0288730490824272, disc_loss = 0.0002899085234307206
Trained batch 1160 in epoch 5, gen_loss = 1.0288035744844481, disc_loss = 0.00028984229702489053
Trained batch 1161 in epoch 5, gen_loss = 1.0287687539438783, disc_loss = 0.000289800758232379
Trained batch 1162 in epoch 5, gen_loss = 1.0288153566990244, disc_loss = 0.0002897623753292155
Trained batch 1163 in epoch 5, gen_loss = 1.0287852745080732, disc_loss = 0.00028978739786238844
Trained batch 1164 in epoch 5, gen_loss = 1.0287847984502243, disc_loss = 0.0002898533183837993
Trained batch 1165 in epoch 5, gen_loss = 1.0287058494001065, disc_loss = 0.0002899222361498674
Trained batch 1166 in epoch 5, gen_loss = 1.0286793755790364, disc_loss = 0.0002898909706260148
Trained batch 1167 in epoch 5, gen_loss = 1.028595343946594, disc_loss = 0.0002897911490498239
Trained batch 1168 in epoch 5, gen_loss = 1.02857104084041, disc_loss = 0.0002896437887861704
Trained batch 1169 in epoch 5, gen_loss = 1.0286273710748068, disc_loss = 0.0002894808660083725
Trained batch 1170 in epoch 5, gen_loss = 1.0285405868347846, disc_loss = 0.000289343560627635
Trained batch 1171 in epoch 5, gen_loss = 1.0285140155932195, disc_loss = 0.00028922557573420445
Trained batch 1172 in epoch 5, gen_loss = 1.0286174168062332, disc_loss = 0.0002891281771824222
Trained batch 1173 in epoch 5, gen_loss = 1.028566709368964, disc_loss = 0.00028904020155793306
Trained batch 1174 in epoch 5, gen_loss = 1.0285123408094365, disc_loss = 0.0002889868259823762
Trained batch 1175 in epoch 5, gen_loss = 1.0285611499329002, disc_loss = 0.0002889343392106187
Trained batch 1176 in epoch 5, gen_loss = 1.0286395305683782, disc_loss = 0.00028882393562742337
Trained batch 1177 in epoch 5, gen_loss = 1.028648674892853, disc_loss = 0.00028873454637795646
Trained batch 1178 in epoch 5, gen_loss = 1.0285939884650899, disc_loss = 0.0002887085705928515
Trained batch 1179 in epoch 5, gen_loss = 1.0285806018922288, disc_loss = 0.0002886622413039361
Trained batch 1180 in epoch 5, gen_loss = 1.0285407348167683, disc_loss = 0.0002886265906373494
Trained batch 1181 in epoch 5, gen_loss = 1.0285219476509417, disc_loss = 0.0002885183315866847
Trained batch 1182 in epoch 5, gen_loss = 1.028540191565745, disc_loss = 0.0002883954786749959
Trained batch 1183 in epoch 5, gen_loss = 1.0285675538754142, disc_loss = 0.0002883179286871726
Trained batch 1184 in epoch 5, gen_loss = 1.0284725255604033, disc_loss = 0.000288334948003129
Trained batch 1185 in epoch 5, gen_loss = 1.028378781440085, disc_loss = 0.0002886615933626706
Trained batch 1186 in epoch 5, gen_loss = 1.0283044018259346, disc_loss = 0.0002889038535290933
Trained batch 1187 in epoch 5, gen_loss = 1.028315435655992, disc_loss = 0.00028904291210087176
Trained batch 1188 in epoch 5, gen_loss = 1.0282349173415097, disc_loss = 0.0002890025986611817
Trained batch 1189 in epoch 5, gen_loss = 1.0280952775177836, disc_loss = 0.00028890493384463626
Trained batch 1190 in epoch 5, gen_loss = 1.0279954500702826, disc_loss = 0.00028883474655006604
Trained batch 1191 in epoch 5, gen_loss = 1.027977683700171, disc_loss = 0.00028877591112238507
Trained batch 1192 in epoch 5, gen_loss = 1.0279707610856956, disc_loss = 0.0002887383344971492
Trained batch 1193 in epoch 5, gen_loss = 1.0279417930535935, disc_loss = 0.00028878117397959326
Trained batch 1194 in epoch 5, gen_loss = 1.027758877347204, disc_loss = 0.0002888677850895109
Trained batch 1195 in epoch 5, gen_loss = 1.0276574876196807, disc_loss = 0.0002889912525050472
Trained batch 1196 in epoch 5, gen_loss = 1.027592733041784, disc_loss = 0.00028905105489961076
Trained batch 1197 in epoch 5, gen_loss = 1.0275776144956708, disc_loss = 0.0002890586348046733
Trained batch 1198 in epoch 5, gen_loss = 1.0275169405666762, disc_loss = 0.00028902755599010473
Trained batch 1199 in epoch 5, gen_loss = 1.0276013297339281, disc_loss = 0.00028902528726879
Trained batch 1200 in epoch 5, gen_loss = 1.0275171889452812, disc_loss = 0.0002890939863092269
Trained batch 1201 in epoch 5, gen_loss = 1.0276134954811929, disc_loss = 0.00028920364586849305
Trained batch 1202 in epoch 5, gen_loss = 1.0276601027669454, disc_loss = 0.0002894194999646147
Trained batch 1203 in epoch 5, gen_loss = 1.0276317806338946, disc_loss = 0.00028971194418972364
Trained batch 1204 in epoch 5, gen_loss = 1.0275422568143155, disc_loss = 0.00029008763559579005
Trained batch 1205 in epoch 5, gen_loss = 1.0276272356213623, disc_loss = 0.0002903846709482325
Trained batch 1206 in epoch 5, gen_loss = 1.027608994916143, disc_loss = 0.0002904966264559892
Trained batch 1207 in epoch 5, gen_loss = 1.0275059655703456, disc_loss = 0.0002905415737062723
Trained batch 1208 in epoch 5, gen_loss = 1.0274494809489096, disc_loss = 0.0002905378111886462
Trained batch 1209 in epoch 5, gen_loss = 1.0273206366980372, disc_loss = 0.0002904820073314669
Trained batch 1210 in epoch 5, gen_loss = 1.0272322733671975, disc_loss = 0.0002904892583003419
Trained batch 1211 in epoch 5, gen_loss = 1.0272048763906207, disc_loss = 0.0002907366714779447
Trained batch 1212 in epoch 5, gen_loss = 1.0271757883860468, disc_loss = 0.0002911546355948257
Trained batch 1213 in epoch 5, gen_loss = 1.027237058618709, disc_loss = 0.00029163674632146997
Trained batch 1214 in epoch 5, gen_loss = 1.0272187499352443, disc_loss = 0.00029196918564403063
Trained batch 1215 in epoch 5, gen_loss = 1.0270967231083072, disc_loss = 0.0002920656737255979
Trained batch 1216 in epoch 5, gen_loss = 1.0271704972231104, disc_loss = 0.000292037102896152
Trained batch 1217 in epoch 5, gen_loss = 1.0270966514088642, disc_loss = 0.0002919319391092236
Trained batch 1218 in epoch 5, gen_loss = 1.0270849904924069, disc_loss = 0.0002918669088431626
Trained batch 1219 in epoch 5, gen_loss = 1.0271564176336663, disc_loss = 0.00029179575578352536
Trained batch 1220 in epoch 5, gen_loss = 1.0271466904541784, disc_loss = 0.00029175135225709186
Trained batch 1221 in epoch 5, gen_loss = 1.0271523454868268, disc_loss = 0.00029166213347329436
Trained batch 1222 in epoch 5, gen_loss = 1.0270967285163268, disc_loss = 0.0002915833875367388
Trained batch 1223 in epoch 5, gen_loss = 1.0272590659704863, disc_loss = 0.0002915021166141397
Trained batch 1224 in epoch 5, gen_loss = 1.0271851646656893, disc_loss = 0.0002914205216505679
Trained batch 1225 in epoch 5, gen_loss = 1.0272170951860375, disc_loss = 0.00029144441651545583
Trained batch 1226 in epoch 5, gen_loss = 1.0271386694597247, disc_loss = 0.0002914864040708443
Trained batch 1227 in epoch 5, gen_loss = 1.0270759331772303, disc_loss = 0.0002915103377863755
Trained batch 1228 in epoch 5, gen_loss = 1.0271767608221223, disc_loss = 0.00029161027965488815
Trained batch 1229 in epoch 5, gen_loss = 1.0271952563669624, disc_loss = 0.0002917989686155612
Trained batch 1230 in epoch 5, gen_loss = 1.027173434061117, disc_loss = 0.0002920076556998467
Trained batch 1231 in epoch 5, gen_loss = 1.0272272770571245, disc_loss = 0.00029210319793751945
Trained batch 1232 in epoch 5, gen_loss = 1.0273290835351163, disc_loss = 0.0002922493697554141
Trained batch 1233 in epoch 5, gen_loss = 1.0272398823374094, disc_loss = 0.00029237205756867243
Trained batch 1234 in epoch 5, gen_loss = 1.0271510297470248, disc_loss = 0.000292502464588707
Trained batch 1235 in epoch 5, gen_loss = 1.0271473679824168, disc_loss = 0.0002925020477362561
Trained batch 1236 in epoch 5, gen_loss = 1.0271571522387364, disc_loss = 0.0002924550150561285
Trained batch 1237 in epoch 5, gen_loss = 1.027112891966769, disc_loss = 0.00029241767919543183
Trained batch 1238 in epoch 5, gen_loss = 1.0270697722231024, disc_loss = 0.00029244968375578015
Trained batch 1239 in epoch 5, gen_loss = 1.0270340641660074, disc_loss = 0.00029254402822017814
Trained batch 1240 in epoch 5, gen_loss = 1.0270990098704262, disc_loss = 0.00029271088776738316
Trained batch 1241 in epoch 5, gen_loss = 1.0271585587526098, disc_loss = 0.0002928835475884716
Trained batch 1242 in epoch 5, gen_loss = 1.0271312908500985, disc_loss = 0.00029296484336567737
Trained batch 1243 in epoch 5, gen_loss = 1.027109339785346, disc_loss = 0.00029291188673836283
Trained batch 1244 in epoch 5, gen_loss = 1.0271060437083723, disc_loss = 0.0002927727711991964
Trained batch 1245 in epoch 5, gen_loss = 1.0271520303684865, disc_loss = 0.0002926140742291051
Trained batch 1246 in epoch 5, gen_loss = 1.0271290853296937, disc_loss = 0.00029245963212636277
Trained batch 1247 in epoch 5, gen_loss = 1.0270828074083114, disc_loss = 0.000292286951942235
Trained batch 1248 in epoch 5, gen_loss = 1.02715741876987, disc_loss = 0.0002921695826090298
Trained batch 1249 in epoch 5, gen_loss = 1.0271469235897064, disc_loss = 0.0002921160960686393
Trained batch 1250 in epoch 5, gen_loss = 1.0271551528518243, disc_loss = 0.00029220765540169716
Trained batch 1251 in epoch 5, gen_loss = 1.0270230645855394, disc_loss = 0.00029231461638165563
Trained batch 1252 in epoch 5, gen_loss = 1.0270783056855106, disc_loss = 0.0002923672691888621
Trained batch 1253 in epoch 5, gen_loss = 1.0270454168224639, disc_loss = 0.00029223939920333696
Trained batch 1254 in epoch 5, gen_loss = 1.0270416950799555, disc_loss = 0.0002921586125867397
Trained batch 1255 in epoch 5, gen_loss = 1.0270004464657443, disc_loss = 0.00029209800317646584
Trained batch 1256 in epoch 5, gen_loss = 1.026888761192252, disc_loss = 0.0002919774784153815
Trained batch 1257 in epoch 5, gen_loss = 1.0267960134011194, disc_loss = 0.00029195298983779143
Trained batch 1258 in epoch 5, gen_loss = 1.0266791104418214, disc_loss = 0.0002919619153897301
Trained batch 1259 in epoch 5, gen_loss = 1.0266530559649543, disc_loss = 0.0002920008213665809
Trained batch 1260 in epoch 5, gen_loss = 1.0267062367284987, disc_loss = 0.0002919676707921628
Trained batch 1261 in epoch 5, gen_loss = 1.0267120457583487, disc_loss = 0.0002918690876021838
Trained batch 1262 in epoch 5, gen_loss = 1.0267187778381535, disc_loss = 0.000291792274724566
Trained batch 1263 in epoch 5, gen_loss = 1.0266591961719567, disc_loss = 0.00029184849876101804
Trained batch 1264 in epoch 5, gen_loss = 1.0266719524568249, disc_loss = 0.00029208671243855796
Trained batch 1265 in epoch 5, gen_loss = 1.026700534197203, disc_loss = 0.00029238538295782787
Trained batch 1266 in epoch 5, gen_loss = 1.026709584664809, disc_loss = 0.00029265600205948553
Trained batch 1267 in epoch 5, gen_loss = 1.0267366308613155, disc_loss = 0.00029285853525613765
Trained batch 1268 in epoch 5, gen_loss = 1.026770114382014, disc_loss = 0.0002929641707702903
Trained batch 1269 in epoch 5, gen_loss = 1.0267627715595125, disc_loss = 0.0002930037447321962
Trained batch 1270 in epoch 5, gen_loss = 1.0267177925252426, disc_loss = 0.00029303321026510724
Trained batch 1271 in epoch 5, gen_loss = 1.0267406740466003, disc_loss = 0.0002930788118847091
Trained batch 1272 in epoch 5, gen_loss = 1.026697993934014, disc_loss = 0.00029305602252698823
Trained batch 1273 in epoch 5, gen_loss = 1.0266895374660403, disc_loss = 0.0002929180702618565
Trained batch 1274 in epoch 5, gen_loss = 1.0266724519168628, disc_loss = 0.00029275810424758886
Trained batch 1275 in epoch 5, gen_loss = 1.0266799808109068, disc_loss = 0.0002925949887821701
Trained batch 1276 in epoch 5, gen_loss = 1.0267415907388566, disc_loss = 0.0002925040902092286
Trained batch 1277 in epoch 5, gen_loss = 1.026757216882631, disc_loss = 0.00029243494948236155
Trained batch 1278 in epoch 5, gen_loss = 1.026723521122996, disc_loss = 0.0002923398112142848
Trained batch 1279 in epoch 5, gen_loss = 1.026730660907924, disc_loss = 0.0002922261230935419
Trained batch 1280 in epoch 5, gen_loss = 1.026731430972395, disc_loss = 0.0002920693440501764
Trained batch 1281 in epoch 5, gen_loss = 1.0266795263461501, disc_loss = 0.00029189948582653626
Trained batch 1282 in epoch 5, gen_loss = 1.026618302890498, disc_loss = 0.0002917376269952689
Trained batch 1283 in epoch 5, gen_loss = 1.0265397614222078, disc_loss = 0.0002915728937154415
Trained batch 1284 in epoch 5, gen_loss = 1.0264815773481526, disc_loss = 0.0002914244877045398
Trained batch 1285 in epoch 5, gen_loss = 1.0264764641807016, disc_loss = 0.00029127738210151747
Trained batch 1286 in epoch 5, gen_loss = 1.0265143545172246, disc_loss = 0.000291170697722482
Trained batch 1287 in epoch 5, gen_loss = 1.0265268501565323, disc_loss = 0.00029111604764343527
Trained batch 1288 in epoch 5, gen_loss = 1.0265921630352575, disc_loss = 0.0002911184594629237
Trained batch 1289 in epoch 5, gen_loss = 1.0265806308550427, disc_loss = 0.00029111344559260737
Trained batch 1290 in epoch 5, gen_loss = 1.026559155039045, disc_loss = 0.000291106090939093
Trained batch 1291 in epoch 5, gen_loss = 1.0265337020251035, disc_loss = 0.0002910610842277929
Trained batch 1292 in epoch 5, gen_loss = 1.0264646738237497, disc_loss = 0.00029095073653234146
Trained batch 1293 in epoch 5, gen_loss = 1.0264085313359959, disc_loss = 0.00029081568158616006
Trained batch 1294 in epoch 5, gen_loss = 1.0263666729209047, disc_loss = 0.000290757097615357
Trained batch 1295 in epoch 5, gen_loss = 1.0264056102361208, disc_loss = 0.00029067455228487456
Trained batch 1296 in epoch 5, gen_loss = 1.0264229434402337, disc_loss = 0.00029058901212024145
Trained batch 1297 in epoch 5, gen_loss = 1.026380482917574, disc_loss = 0.00029059803241460966
Trained batch 1298 in epoch 5, gen_loss = 1.0264790811568063, disc_loss = 0.0002907853513359027
Trained batch 1299 in epoch 5, gen_loss = 1.0264025027935322, disc_loss = 0.0002909348008800477
Trained batch 1300 in epoch 5, gen_loss = 1.0264911892595519, disc_loss = 0.0002911209790534494
Trained batch 1301 in epoch 5, gen_loss = 1.0264827671322039, disc_loss = 0.0002912913112849828
Trained batch 1302 in epoch 5, gen_loss = 1.0263978545243064, disc_loss = 0.000291407094358042
Trained batch 1303 in epoch 5, gen_loss = 1.0263438431397538, disc_loss = 0.0002915744901829552
Trained batch 1304 in epoch 5, gen_loss = 1.026347401498378, disc_loss = 0.0002916898090330798
Trained batch 1305 in epoch 5, gen_loss = 1.0264456003767426, disc_loss = 0.00029179607782536793
Trained batch 1306 in epoch 5, gen_loss = 1.0264321581133469, disc_loss = 0.00029191858845368504
Trained batch 1307 in epoch 5, gen_loss = 1.0264030319470514, disc_loss = 0.0002920028339783606
Trained batch 1308 in epoch 5, gen_loss = 1.026476078128159, disc_loss = 0.0002923512815566651
Trained batch 1309 in epoch 5, gen_loss = 1.0263965555729757, disc_loss = 0.00029259620549624703
Trained batch 1310 in epoch 5, gen_loss = 1.0263620837784104, disc_loss = 0.0002929136044771853
Trained batch 1311 in epoch 5, gen_loss = 1.0263018072014902, disc_loss = 0.0002930643970391496
Trained batch 1312 in epoch 5, gen_loss = 1.0262362424054403, disc_loss = 0.00029310097252981636
Trained batch 1313 in epoch 5, gen_loss = 1.0262374730052106, disc_loss = 0.00029306578248304414
Trained batch 1314 in epoch 5, gen_loss = 1.0262846481664099, disc_loss = 0.0002930238801244993
Trained batch 1315 in epoch 5, gen_loss = 1.0262297936304725, disc_loss = 0.0002928986211226316
Trained batch 1316 in epoch 5, gen_loss = 1.026306422080791, disc_loss = 0.00029278409369380037
Trained batch 1317 in epoch 5, gen_loss = 1.0263429624176894, disc_loss = 0.00029275371938933617
Trained batch 1318 in epoch 5, gen_loss = 1.0262761815105812, disc_loss = 0.00029285466823830334
Trained batch 1319 in epoch 5, gen_loss = 1.0263086553324352, disc_loss = 0.0002930394335580235
Trained batch 1320 in epoch 5, gen_loss = 1.0263146922319428, disc_loss = 0.0002933006585625167
Trained batch 1321 in epoch 5, gen_loss = 1.0263523422914265, disc_loss = 0.0002935866405082262
Trained batch 1322 in epoch 5, gen_loss = 1.0263508345174321, disc_loss = 0.0002938222497173156
Trained batch 1323 in epoch 5, gen_loss = 1.0263432119818252, disc_loss = 0.0002939640013385864
Trained batch 1324 in epoch 5, gen_loss = 1.0264317221461603, disc_loss = 0.0002940120224353313
Trained batch 1325 in epoch 5, gen_loss = 1.026418753743711, disc_loss = 0.0002939786661935508
Trained batch 1326 in epoch 5, gen_loss = 1.026421962910877, disc_loss = 0.0002941273651848152
Trained batch 1327 in epoch 5, gen_loss = 1.0264248904962856, disc_loss = 0.0002941479384740471
Trained batch 1328 in epoch 5, gen_loss = 1.0263783069729715, disc_loss = 0.00029412386940462493
Trained batch 1329 in epoch 5, gen_loss = 1.0264760936113229, disc_loss = 0.00029405382284815806
Trained batch 1330 in epoch 5, gen_loss = 1.02645237646454, disc_loss = 0.00029394500044632456
Trained batch 1331 in epoch 5, gen_loss = 1.02636445025066, disc_loss = 0.00029382040914818964
Trained batch 1332 in epoch 5, gen_loss = 1.026311355207705, disc_loss = 0.0002936664479826151
Trained batch 1333 in epoch 5, gen_loss = 1.0262448413261231, disc_loss = 0.0002934966037371297
Trained batch 1334 in epoch 5, gen_loss = 1.0261789106697625, disc_loss = 0.00029335723702524606
Trained batch 1335 in epoch 5, gen_loss = 1.02614561008836, disc_loss = 0.00029326993217999376
Trained batch 1336 in epoch 5, gen_loss = 1.0260957979228662, disc_loss = 0.0002931534385555647
Trained batch 1337 in epoch 5, gen_loss = 1.0261819788069646, disc_loss = 0.00029302508082166515
Trained batch 1338 in epoch 5, gen_loss = 1.0261642102700193, disc_loss = 0.00029289796606859586
Trained batch 1339 in epoch 5, gen_loss = 1.0261569662325418, disc_loss = 0.00029280222445763753
Trained batch 1340 in epoch 5, gen_loss = 1.0261665330637222, disc_loss = 0.0002927021142296298
Trained batch 1341 in epoch 5, gen_loss = 1.0260545350666728, disc_loss = 0.00029258101279933205
Trained batch 1342 in epoch 5, gen_loss = 1.026113566540997, disc_loss = 0.00029247080606240424
Trained batch 1343 in epoch 5, gen_loss = 1.0260619622256075, disc_loss = 0.0002923838810548183
Trained batch 1344 in epoch 5, gen_loss = 1.025979257073101, disc_loss = 0.0002922707780917369
Trained batch 1345 in epoch 5, gen_loss = 1.0259295694895343, disc_loss = 0.00029217342153074115
Trained batch 1346 in epoch 5, gen_loss = 1.025831693176349, disc_loss = 0.0002920831771462975
Trained batch 1347 in epoch 5, gen_loss = 1.0257536624765538, disc_loss = 0.0002920013663534041
Trained batch 1348 in epoch 5, gen_loss = 1.0257829549667834, disc_loss = 0.00029197278290653386
Trained batch 1349 in epoch 5, gen_loss = 1.0257846426963806, disc_loss = 0.0002919771617948923
Trained batch 1350 in epoch 5, gen_loss = 1.0257696730396997, disc_loss = 0.00029194875889305933
Trained batch 1351 in epoch 5, gen_loss = 1.0257712076225225, disc_loss = 0.0002919286451976765
Trained batch 1352 in epoch 5, gen_loss = 1.0257871181808043, disc_loss = 0.0002918794265791553
Trained batch 1353 in epoch 5, gen_loss = 1.0256934891423235, disc_loss = 0.0002917942750749424
Trained batch 1354 in epoch 5, gen_loss = 1.0257074736141192, disc_loss = 0.00029171936465165237
Trained batch 1355 in epoch 5, gen_loss = 1.0256462379806512, disc_loss = 0.00029168378257797583
Trained batch 1356 in epoch 5, gen_loss = 1.0255105037766514, disc_loss = 0.00029167455965655635
Trained batch 1357 in epoch 5, gen_loss = 1.0254464728403865, disc_loss = 0.0002916144407214134
Trained batch 1358 in epoch 5, gen_loss = 1.0253885427847604, disc_loss = 0.00029152271919905204
Trained batch 1359 in epoch 5, gen_loss = 1.0253766277695404, disc_loss = 0.00029141632967901604
Trained batch 1360 in epoch 5, gen_loss = 1.0253753114237145, disc_loss = 0.00029129342961652495
Trained batch 1361 in epoch 5, gen_loss = 1.0254278074889807, disc_loss = 0.0002912063365421383
Trained batch 1362 in epoch 5, gen_loss = 1.0254369994689678, disc_loss = 0.0002911300608360513
Trained batch 1363 in epoch 5, gen_loss = 1.0253957409925125, disc_loss = 0.00029107566408657156
Trained batch 1364 in epoch 5, gen_loss = 1.0253917695401789, disc_loss = 0.0002910270422538009
Trained batch 1365 in epoch 5, gen_loss = 1.0253807291890307, disc_loss = 0.0002909823916507745
Trained batch 1366 in epoch 5, gen_loss = 1.025281516888234, disc_loss = 0.000291003732639169
Trained batch 1367 in epoch 5, gen_loss = 1.0252012800839212, disc_loss = 0.0002910069349515562
Trained batch 1368 in epoch 5, gen_loss = 1.025229906800718, disc_loss = 0.00029097483973739084
Trained batch 1369 in epoch 5, gen_loss = 1.025322933571182, disc_loss = 0.00029096851168590405
Trained batch 1370 in epoch 5, gen_loss = 1.0253866478355151, disc_loss = 0.0002910299352471673
Trained batch 1371 in epoch 5, gen_loss = 1.025394894421622, disc_loss = 0.0002912098861732788
Trained batch 1372 in epoch 5, gen_loss = 1.0254257936939564, disc_loss = 0.00029145156600300084
Trained batch 1373 in epoch 5, gen_loss = 1.0254148655670006, disc_loss = 0.0002916971315094558
Trained batch 1374 in epoch 5, gen_loss = 1.0254141829664056, disc_loss = 0.00029186705594607206
Trained batch 1375 in epoch 5, gen_loss = 1.0253694334262333, disc_loss = 0.00029198953455856694
Trained batch 1376 in epoch 5, gen_loss = 1.0253638755002572, disc_loss = 0.0002921055006201057
Trained batch 1377 in epoch 5, gen_loss = 1.0253404988778867, disc_loss = 0.00029219820112335844
Trained batch 1378 in epoch 5, gen_loss = 1.0252995504859221, disc_loss = 0.0002922905120208702
Trained batch 1379 in epoch 5, gen_loss = 1.0252805528865345, disc_loss = 0.000292347872707161
Trained batch 1380 in epoch 5, gen_loss = 1.0252228115538944, disc_loss = 0.00029243812118979795
Trained batch 1381 in epoch 5, gen_loss = 1.0251012343573673, disc_loss = 0.00029254023275113536
Trained batch 1382 in epoch 5, gen_loss = 1.0250506015334195, disc_loss = 0.0002925838402248781
Trained batch 1383 in epoch 5, gen_loss = 1.0250717763697481, disc_loss = 0.00029257651598096353
Trained batch 1384 in epoch 5, gen_loss = 1.0250914038733885, disc_loss = 0.00029256193509761625
Trained batch 1385 in epoch 5, gen_loss = 1.025088032989791, disc_loss = 0.0002925766450145922
Trained batch 1386 in epoch 5, gen_loss = 1.0251319022941865, disc_loss = 0.0002926458219663783
Trained batch 1387 in epoch 5, gen_loss = 1.0250687624947825, disc_loss = 0.0002927750605894491
Trained batch 1388 in epoch 5, gen_loss = 1.0250836259774634, disc_loss = 0.0002929997173839221
Trained batch 1389 in epoch 5, gen_loss = 1.0250681977477862, disc_loss = 0.0002932854804489678
Trained batch 1390 in epoch 5, gen_loss = 1.0250921291382855, disc_loss = 0.0002938211947111001
Trained batch 1391 in epoch 5, gen_loss = 1.025048193875058, disc_loss = 0.0002946235228497746
Trained batch 1392 in epoch 5, gen_loss = 1.0249995178912752, disc_loss = 0.00029536976622381966
Trained batch 1393 in epoch 5, gen_loss = 1.024900471035343, disc_loss = 0.0002958995024564658
Trained batch 1394 in epoch 5, gen_loss = 1.0249610976933579, disc_loss = 0.0002961996157007295
Trained batch 1395 in epoch 5, gen_loss = 1.0249623719464058, disc_loss = 0.00029632795931294227
Trained batch 1396 in epoch 5, gen_loss = 1.0249633195149361, disc_loss = 0.0002962545462307432
Trained batch 1397 in epoch 5, gen_loss = 1.0249308120027631, disc_loss = 0.0002961096735520023
Trained batch 1398 in epoch 5, gen_loss = 1.024926766146073, disc_loss = 0.00029598794439057784
Trained batch 1399 in epoch 5, gen_loss = 1.0249630429063525, disc_loss = 0.0002958555372970295
Trained batch 1400 in epoch 5, gen_loss = 1.0249337250636699, disc_loss = 0.00029575810027234807
Trained batch 1401 in epoch 5, gen_loss = 1.024967884541238, disc_loss = 0.00029578176424097097
Trained batch 1402 in epoch 5, gen_loss = 1.0249925825482, disc_loss = 0.00029585512993532496
Trained batch 1403 in epoch 5, gen_loss = 1.0249898836144016, disc_loss = 0.00029596622010899087
Trained batch 1404 in epoch 5, gen_loss = 1.0249492135760623, disc_loss = 0.0002961315085323862
Trained batch 1405 in epoch 5, gen_loss = 1.0248316243651243, disc_loss = 0.00029631909412201223
Trained batch 1406 in epoch 5, gen_loss = 1.0246836424466983, disc_loss = 0.00029691160031637855
Trained batch 1407 in epoch 5, gen_loss = 1.0246708713556556, disc_loss = 0.0002975915730975099
Trained batch 1408 in epoch 5, gen_loss = 1.0246861698866059, disc_loss = 0.0002977904820061789
Trained batch 1409 in epoch 5, gen_loss = 1.0247465511163076, disc_loss = 0.0002979646152798136
Trained batch 1410 in epoch 5, gen_loss = 1.0248176676850214, disc_loss = 0.00029801803303552954
Trained batch 1411 in epoch 5, gen_loss = 1.0248087275213966, disc_loss = 0.00029798735451379825
Trained batch 1412 in epoch 5, gen_loss = 1.024814565174983, disc_loss = 0.00029793158896831447
Trained batch 1413 in epoch 5, gen_loss = 1.0247716590909675, disc_loss = 0.0002978731795061229
Trained batch 1414 in epoch 5, gen_loss = 1.0247665273005886, disc_loss = 0.0002978917588872667
Trained batch 1415 in epoch 5, gen_loss = 1.0247519420365157, disc_loss = 0.0002978950546309796
Trained batch 1416 in epoch 5, gen_loss = 1.0247675438707953, disc_loss = 0.0002979416957654729
Trained batch 1417 in epoch 5, gen_loss = 1.0246932206856683, disc_loss = 0.00029813865881736854
Trained batch 1418 in epoch 5, gen_loss = 1.0246402356639726, disc_loss = 0.00029832752691882935
Trained batch 1419 in epoch 5, gen_loss = 1.0246083328841438, disc_loss = 0.00029840760783462057
Trained batch 1420 in epoch 5, gen_loss = 1.0246372884381916, disc_loss = 0.0002984424896390711
Trained batch 1421 in epoch 5, gen_loss = 1.024584708795601, disc_loss = 0.0002983957372957257
Trained batch 1422 in epoch 5, gen_loss = 1.0244948768481685, disc_loss = 0.00029833658784132966
Trained batch 1423 in epoch 5, gen_loss = 1.0243942326123125, disc_loss = 0.00029830633761622683
Trained batch 1424 in epoch 5, gen_loss = 1.0242789585130256, disc_loss = 0.0002982918977106333
Trained batch 1425 in epoch 5, gen_loss = 1.024326836034593, disc_loss = 0.00029827463396410665
Trained batch 1426 in epoch 5, gen_loss = 1.024304488069458, disc_loss = 0.00029832902613967057
Trained batch 1427 in epoch 5, gen_loss = 1.0242765898547586, disc_loss = 0.00029840740537839447
Trained batch 1428 in epoch 5, gen_loss = 1.0242645214536625, disc_loss = 0.0002983795433919704
Trained batch 1429 in epoch 5, gen_loss = 1.0242351875855373, disc_loss = 0.000298344038264668
Trained batch 1430 in epoch 5, gen_loss = 1.0241899863978852, disc_loss = 0.00029842795194792943
Trained batch 1431 in epoch 5, gen_loss = 1.0242045059300668, disc_loss = 0.0002985527787574059
Trained batch 1432 in epoch 5, gen_loss = 1.0242485143634212, disc_loss = 0.0002985386701146955
Trained batch 1433 in epoch 5, gen_loss = 1.024216792157837, disc_loss = 0.00029847920316314835
Trained batch 1434 in epoch 5, gen_loss = 1.0242341844877716, disc_loss = 0.00029851943002474245
Trained batch 1435 in epoch 5, gen_loss = 1.0241594413777912, disc_loss = 0.0002985933416643913
Trained batch 1436 in epoch 5, gen_loss = 1.0241107207748237, disc_loss = 0.00029875150238851245
Trained batch 1437 in epoch 5, gen_loss = 1.0240036644590746, disc_loss = 0.00029890784356215747
Trained batch 1438 in epoch 5, gen_loss = 1.0239998364796483, disc_loss = 0.00029893378441297574
Trained batch 1439 in epoch 5, gen_loss = 1.0239480689581897, disc_loss = 0.0002988572029254202
Trained batch 1440 in epoch 5, gen_loss = 1.0239642835755385, disc_loss = 0.00029886478451764895
Trained batch 1441 in epoch 5, gen_loss = 1.0239202774926792, disc_loss = 0.00029914814014152957
Trained batch 1442 in epoch 5, gen_loss = 1.0239664558643942, disc_loss = 0.0002995072818162034
Trained batch 1443 in epoch 5, gen_loss = 1.023896549918645, disc_loss = 0.00029979311827781584
Trained batch 1444 in epoch 5, gen_loss = 1.023882634788236, disc_loss = 0.0002999972137306321
Trained batch 1445 in epoch 5, gen_loss = 1.0238248477915346, disc_loss = 0.00030021738171680343
Trained batch 1446 in epoch 5, gen_loss = 1.0237736209722412, disc_loss = 0.00030043977302184223
Trained batch 1447 in epoch 5, gen_loss = 1.0237808903030927, disc_loss = 0.0003004195399907432
Trained batch 1448 in epoch 5, gen_loss = 1.0237590802217698, disc_loss = 0.0003003687464393559
Trained batch 1449 in epoch 5, gen_loss = 1.0236591927758578, disc_loss = 0.00030044598436155677
Trained batch 1450 in epoch 5, gen_loss = 1.0239144207115094, disc_loss = 0.0003006843156609309
Trained batch 1451 in epoch 5, gen_loss = 1.0239745660918476, disc_loss = 0.0003009273953744728
Trained batch 1452 in epoch 5, gen_loss = 1.0240417637664208, disc_loss = 0.00030122815350567183
Trained batch 1453 in epoch 5, gen_loss = 1.0241135483430865, disc_loss = 0.00030142671519875535
Trained batch 1454 in epoch 5, gen_loss = 1.0241902569315278, disc_loss = 0.00030164258418859965
Trained batch 1455 in epoch 5, gen_loss = 1.0242343577709827, disc_loss = 0.00030194026423767075
Trained batch 1456 in epoch 5, gen_loss = 1.0242409477024432, disc_loss = 0.00030226987148004674
Trained batch 1457 in epoch 5, gen_loss = 1.024297724208387, disc_loss = 0.0003026116134540005
Trained batch 1458 in epoch 5, gen_loss = 1.0243861363961977, disc_loss = 0.0003025767235692978
Trained batch 1459 in epoch 5, gen_loss = 1.024441866923685, disc_loss = 0.0003025118247571972
Trained batch 1460 in epoch 5, gen_loss = 1.0245054921085586, disc_loss = 0.00030248142155023575
Trained batch 1461 in epoch 5, gen_loss = 1.0245310266269052, disc_loss = 0.00030256976241531093
Trained batch 1462 in epoch 5, gen_loss = 1.0245917801651658, disc_loss = 0.00030269144821853326
Trained batch 1463 in epoch 5, gen_loss = 1.024635104370899, disc_loss = 0.0003028258888512997
Trained batch 1464 in epoch 5, gen_loss = 1.0245532564742574, disc_loss = 0.00030295410315778724
Trained batch 1465 in epoch 5, gen_loss = 1.0245493086103203, disc_loss = 0.00030300008181553546
Trained batch 1466 in epoch 5, gen_loss = 1.0245721596962916, disc_loss = 0.00030292137088227904
Trained batch 1467 in epoch 5, gen_loss = 1.0245886631005467, disc_loss = 0.00030284187275730293
Trained batch 1468 in epoch 5, gen_loss = 1.0245766736277924, disc_loss = 0.00030278244451829693
Trained batch 1469 in epoch 5, gen_loss = 1.0245241921775194, disc_loss = 0.00030270841119270044
Trained batch 1470 in epoch 5, gen_loss = 1.024572498128983, disc_loss = 0.00030261609957401973
Trained batch 1471 in epoch 5, gen_loss = 1.0247171590023714, disc_loss = 0.0003025461440687571
Trained batch 1472 in epoch 5, gen_loss = 1.024711059293857, disc_loss = 0.00030247295663164274
Trained batch 1473 in epoch 5, gen_loss = 1.024750011908636, disc_loss = 0.00030235842880076575
Trained batch 1474 in epoch 5, gen_loss = 1.024762371839103, disc_loss = 0.0003023813151945834
Trained batch 1475 in epoch 5, gen_loss = 1.0247343171256666, disc_loss = 0.00030250540257247476
Trained batch 1476 in epoch 5, gen_loss = 1.024678351028432, disc_loss = 0.0003026227497984151
Trained batch 1477 in epoch 5, gen_loss = 1.0246574591557938, disc_loss = 0.0003026838469201606
Trained batch 1478 in epoch 5, gen_loss = 1.0246698456571424, disc_loss = 0.00030267092673237227
Trained batch 1479 in epoch 5, gen_loss = 1.02470870887911, disc_loss = 0.00030265788483685923
Trained batch 1480 in epoch 5, gen_loss = 1.0247002396528821, disc_loss = 0.00030267107227690935
Trained batch 1481 in epoch 5, gen_loss = 1.0246632362184254, disc_loss = 0.0003027695435976032
Trained batch 1482 in epoch 5, gen_loss = 1.0247030321681974, disc_loss = 0.00030290060090730833
Trained batch 1483 in epoch 5, gen_loss = 1.0246559321639352, disc_loss = 0.0003031193721769054
Trained batch 1484 in epoch 5, gen_loss = 1.024687243270553, disc_loss = 0.0003034393726865705
Trained batch 1485 in epoch 5, gen_loss = 1.024663337347164, disc_loss = 0.0003035801626533263
Trained batch 1486 in epoch 5, gen_loss = 1.024682667284262, disc_loss = 0.0003035197454409078
Trained batch 1487 in epoch 5, gen_loss = 1.0247176528698014, disc_loss = 0.00030335318924503503
Trained batch 1488 in epoch 5, gen_loss = 1.024694094368081, disc_loss = 0.0003032510674375552
Trained batch 1489 in epoch 5, gen_loss = 1.0246563426200175, disc_loss = 0.0003031969933148283
Trained batch 1490 in epoch 5, gen_loss = 1.0247140406842683, disc_loss = 0.0003033219598658682
Trained batch 1491 in epoch 5, gen_loss = 1.0247274397924822, disc_loss = 0.00030360740911955703
Trained batch 1492 in epoch 5, gen_loss = 1.0247030813903195, disc_loss = 0.000303944890448449
Trained batch 1493 in epoch 5, gen_loss = 1.0246021355012334, disc_loss = 0.0003042956253278292
Trained batch 1494 in epoch 5, gen_loss = 1.024608121986772, disc_loss = 0.0003045700390947388
Trained batch 1495 in epoch 5, gen_loss = 1.0245463562442019, disc_loss = 0.00030474238670931446
Trained batch 1496 in epoch 5, gen_loss = 1.0245392433627096, disc_loss = 0.00030489658551664995
Trained batch 1497 in epoch 5, gen_loss = 1.0245080897025018, disc_loss = 0.0003050988895662153
Trained batch 1498 in epoch 5, gen_loss = 1.02444365714056, disc_loss = 0.0003052447420045012
Trained batch 1499 in epoch 5, gen_loss = 1.0244287710587183, disc_loss = 0.0003054457970574731
Trained batch 1500 in epoch 5, gen_loss = 1.0245073567939393, disc_loss = 0.0003056840744476594
Trained batch 1501 in epoch 5, gen_loss = 1.0244715743153772, disc_loss = 0.0003058725001095356
Trained batch 1502 in epoch 5, gen_loss = 1.0244506083562703, disc_loss = 0.0003059721951340313
Trained batch 1503 in epoch 5, gen_loss = 1.0244242767307987, disc_loss = 0.00030599842467923506
Trained batch 1504 in epoch 5, gen_loss = 1.0243972954956004, disc_loss = 0.00030599435672153905
Trained batch 1505 in epoch 5, gen_loss = 1.0243670940003389, disc_loss = 0.0003058947435079515
Trained batch 1506 in epoch 5, gen_loss = 1.0243421019349734, disc_loss = 0.0003057785888294647
Trained batch 1507 in epoch 5, gen_loss = 1.0243456462492044, disc_loss = 0.0003056891687904606
Trained batch 1508 in epoch 5, gen_loss = 1.0243360717380339, disc_loss = 0.0003056407636166902
Trained batch 1509 in epoch 5, gen_loss = 1.0243550992169916, disc_loss = 0.0003056148535042727
Trained batch 1510 in epoch 5, gen_loss = 1.02431813282812, disc_loss = 0.000305585974946174
Trained batch 1511 in epoch 5, gen_loss = 1.0242860399226033, disc_loss = 0.00030559944543566664
Trained batch 1512 in epoch 5, gen_loss = 1.0242811831432073, disc_loss = 0.00030549369724495865
Trained batch 1513 in epoch 5, gen_loss = 1.024258447094984, disc_loss = 0.00030555042208088877
Trained batch 1514 in epoch 5, gen_loss = 1.0242082017876528, disc_loss = 0.0003057346519679461
Trained batch 1515 in epoch 5, gen_loss = 1.0242026203304608, disc_loss = 0.0003059060491740444
Trained batch 1516 in epoch 5, gen_loss = 1.0242377233961026, disc_loss = 0.00030602709225787344
Trained batch 1517 in epoch 5, gen_loss = 1.0242154938665775, disc_loss = 0.00030609337293745534
Trained batch 1518 in epoch 5, gen_loss = 1.0242393298946453, disc_loss = 0.0003060390928909541
Trained batch 1519 in epoch 5, gen_loss = 1.0242124480636496, disc_loss = 0.00030598526583210177
Trained batch 1520 in epoch 5, gen_loss = 1.0242159034295117, disc_loss = 0.0003058956641375723
Trained batch 1521 in epoch 5, gen_loss = 1.0242435499810358, disc_loss = 0.00030578716166369325
Trained batch 1522 in epoch 5, gen_loss = 1.024204012444359, disc_loss = 0.0003057140712847567
Trained batch 1523 in epoch 5, gen_loss = 1.0242107505091218, disc_loss = 0.00030562480599815765
Trained batch 1524 in epoch 5, gen_loss = 1.0242734841049694, disc_loss = 0.0003055396552443825
Trained batch 1525 in epoch 5, gen_loss = 1.0242484125991012, disc_loss = 0.0003056566945322088
Trained batch 1526 in epoch 5, gen_loss = 1.0242461192506391, disc_loss = 0.00030589353845390864
Trained batch 1527 in epoch 5, gen_loss = 1.0242630245641888, disc_loss = 0.00030605879830869546
Trained batch 1528 in epoch 5, gen_loss = 1.0242824433596793, disc_loss = 0.0003060923753686732
Trained batch 1529 in epoch 5, gen_loss = 1.0242830031058368, disc_loss = 0.00030606936481632934
Trained batch 1530 in epoch 5, gen_loss = 1.0242918528893818, disc_loss = 0.0003059980560823406
Trained batch 1531 in epoch 5, gen_loss = 1.0242223054870925, disc_loss = 0.0003058813106989857
Trained batch 1532 in epoch 5, gen_loss = 1.0241962556192008, disc_loss = 0.00030576629003903095
Trained batch 1533 in epoch 5, gen_loss = 1.0241828361887975, disc_loss = 0.00030562380949118614
Trained batch 1534 in epoch 5, gen_loss = 1.0241827308549167, disc_loss = 0.00030547172658836334
Trained batch 1535 in epoch 5, gen_loss = 1.0241384715773165, disc_loss = 0.0003053305702991338
Trained batch 1536 in epoch 5, gen_loss = 1.0241080275897323, disc_loss = 0.0003052216787243801
Trained batch 1537 in epoch 5, gen_loss = 1.024108050626028, disc_loss = 0.0003051819622611475
Trained batch 1538 in epoch 5, gen_loss = 1.0240769830518455, disc_loss = 0.0003051649076741051
Trained batch 1539 in epoch 5, gen_loss = 1.0239918732410902, disc_loss = 0.0003051786361704051
Trained batch 1540 in epoch 5, gen_loss = 1.0239962356806884, disc_loss = 0.0003052525805218534
Trained batch 1541 in epoch 5, gen_loss = 1.0239563056699033, disc_loss = 0.00030542464088018166
Trained batch 1542 in epoch 5, gen_loss = 1.0239947897925905, disc_loss = 0.0003057456133749933
Trained batch 1543 in epoch 5, gen_loss = 1.0239553320670376, disc_loss = 0.00030605129024121393
Trained batch 1544 in epoch 5, gen_loss = 1.024028672022341, disc_loss = 0.00030617263256349904
Trained batch 1545 in epoch 5, gen_loss = 1.0239732400026236, disc_loss = 0.00030620003126810585
Trained batch 1546 in epoch 5, gen_loss = 1.0239895376067971, disc_loss = 0.0003061575613301937
Trained batch 1547 in epoch 5, gen_loss = 1.024019097981527, disc_loss = 0.000306119427853843
Trained batch 1548 in epoch 5, gen_loss = 1.0240597151955764, disc_loss = 0.00030612611122345345
Trained batch 1549 in epoch 5, gen_loss = 1.0241419131909648, disc_loss = 0.00030627606750649943
Trained batch 1550 in epoch 5, gen_loss = 1.0240971989050593, disc_loss = 0.0003065570668557339
Trained batch 1551 in epoch 5, gen_loss = 1.024107943183368, disc_loss = 0.0003069111580724397
Trained batch 1552 in epoch 5, gen_loss = 1.0240406041289636, disc_loss = 0.00030707167566554377
Trained batch 1553 in epoch 5, gen_loss = 1.0240489971683753, disc_loss = 0.0003070574384905231
Trained batch 1554 in epoch 5, gen_loss = 1.024047713801025, disc_loss = 0.00030705841463392336
Trained batch 1555 in epoch 5, gen_loss = 1.024038233992986, disc_loss = 0.0003070317581290356
Trained batch 1556 in epoch 5, gen_loss = 1.0240218483949979, disc_loss = 0.00030697013933133656
Trained batch 1557 in epoch 5, gen_loss = 1.024041221980412, disc_loss = 0.00030694963096276217
Trained batch 1558 in epoch 5, gen_loss = 1.02398262790872, disc_loss = 0.00030697427770657394
Trained batch 1559 in epoch 5, gen_loss = 1.0239904064016465, disc_loss = 0.00030714079221536684
Trained batch 1560 in epoch 5, gen_loss = 1.0239254829213071, disc_loss = 0.0003075215518445867
Trained batch 1561 in epoch 5, gen_loss = 1.0239617607428688, disc_loss = 0.00030787696633034057
Trained batch 1562 in epoch 5, gen_loss = 1.023917612210345, disc_loss = 0.0003080542488406104
Trained batch 1563 in epoch 5, gen_loss = 1.0239507224020141, disc_loss = 0.00030806330369741213
Trained batch 1564 in epoch 5, gen_loss = 1.0238322193630207, disc_loss = 0.00030809904043930923
Trained batch 1565 in epoch 5, gen_loss = 1.023795238514056, disc_loss = 0.0003082334421063838
Trained batch 1566 in epoch 5, gen_loss = 1.0236709472778578, disc_loss = 0.0003084072265119872
Trained batch 1567 in epoch 5, gen_loss = 1.0236569536963895, disc_loss = 0.00030862985433987905
Trained batch 1568 in epoch 5, gen_loss = 1.0235913363211167, disc_loss = 0.0003088403147472193
Trained batch 1569 in epoch 5, gen_loss = 1.0236761558967031, disc_loss = 0.0003089815915544046
Trained batch 1570 in epoch 5, gen_loss = 1.0236794615080218, disc_loss = 0.00030915968060426927
Trained batch 1571 in epoch 5, gen_loss = 1.0236557392218641, disc_loss = 0.0003093143773543854
Trained batch 1572 in epoch 5, gen_loss = 1.0236106735085198, disc_loss = 0.0003094115987448131
Trained batch 1573 in epoch 5, gen_loss = 1.0236130574909825, disc_loss = 0.00030945467493632777
Trained batch 1574 in epoch 5, gen_loss = 1.0235797644039941, disc_loss = 0.0003094455796166412
Trained batch 1575 in epoch 5, gen_loss = 1.0235815084903372, disc_loss = 0.0003094217912027678
Trained batch 1576 in epoch 5, gen_loss = 1.0235330367209265, disc_loss = 0.0003094447110729016
Trained batch 1577 in epoch 5, gen_loss = 1.0234687596899474, disc_loss = 0.00030944311981798676
Trained batch 1578 in epoch 5, gen_loss = 1.0235031964357628, disc_loss = 0.00030943207345569525
Trained batch 1579 in epoch 5, gen_loss = 1.0235071246759802, disc_loss = 0.0003094616345462575
Trained batch 1580 in epoch 5, gen_loss = 1.0234566098674047, disc_loss = 0.00030955682728868266
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.0705668926239014, disc_loss = 0.0003399706620257348
Trained batch 1 in epoch 6, gen_loss = 0.9606335163116455, disc_loss = 0.0003120740002486855
Trained batch 2 in epoch 6, gen_loss = 0.9675239721934, disc_loss = 0.0002940904426698883
Trained batch 3 in epoch 6, gen_loss = 0.9969773292541504, disc_loss = 0.0002877818187698722
Trained batch 4 in epoch 6, gen_loss = 0.9769463300704956, disc_loss = 0.00032933609327301383
Trained batch 5 in epoch 6, gen_loss = 0.9822051922480265, disc_loss = 0.00031818352969518554
Trained batch 6 in epoch 6, gen_loss = 0.9874310152871268, disc_loss = 0.00030633752300803153
Trained batch 7 in epoch 6, gen_loss = 0.9885334298014641, disc_loss = 0.0003210264112567529
Trained batch 8 in epoch 6, gen_loss = 0.9898333483272128, disc_loss = 0.00033224224009447626
Trained batch 9 in epoch 6, gen_loss = 0.9841095089912415, disc_loss = 0.00034020681341644375
Trained batch 10 in epoch 6, gen_loss = 0.9827622175216675, disc_loss = 0.0003444293318104676
Trained batch 11 in epoch 6, gen_loss = 0.9919289449850718, disc_loss = 0.0003510258660147277
Trained batch 12 in epoch 6, gen_loss = 0.9926657676696777, disc_loss = 0.000365180749213323
Trained batch 13 in epoch 6, gen_loss = 0.9922796828406197, disc_loss = 0.0003800954915017688
Trained batch 14 in epoch 6, gen_loss = 0.9979340076446533, disc_loss = 0.0003928361673994611
Trained batch 15 in epoch 6, gen_loss = 0.9955516457557678, disc_loss = 0.0003943217798223486
Trained batch 16 in epoch 6, gen_loss = 0.9922440262401805, disc_loss = 0.00038739463300718107
Trained batch 17 in epoch 6, gen_loss = 0.9907536605993906, disc_loss = 0.00038681242828412604
Trained batch 18 in epoch 6, gen_loss = 0.9960612842911168, disc_loss = 0.00039169801503272827
Trained batch 19 in epoch 6, gen_loss = 0.9885977596044541, disc_loss = 0.0004115569099667482
Trained batch 20 in epoch 6, gen_loss = 0.9873617745581127, disc_loss = 0.0004396789604687088
Trained batch 21 in epoch 6, gen_loss = 0.9904928559606726, disc_loss = 0.0004505540326301178
Trained batch 22 in epoch 6, gen_loss = 0.9914383603178937, disc_loss = 0.0004664740876962795
Trained batch 23 in epoch 6, gen_loss = 0.9953625227014223, disc_loss = 0.00048548956571418483
Trained batch 24 in epoch 6, gen_loss = 0.9966763806343079, disc_loss = 0.0004960008116904646
Trained batch 25 in epoch 6, gen_loss = 1.0002731657945192, disc_loss = 0.0005092457162950618
Trained batch 26 in epoch 6, gen_loss = 0.9983321030934652, disc_loss = 0.0005212602738066818
Trained batch 27 in epoch 6, gen_loss = 0.9959896292005267, disc_loss = 0.0005347748675766135
Trained batch 28 in epoch 6, gen_loss = 0.9995929989321478, disc_loss = 0.0005373221266099477
Trained batch 29 in epoch 6, gen_loss = 0.9994178652763367, disc_loss = 0.0005291808600304648
Trained batch 30 in epoch 6, gen_loss = 1.0001962723270539, disc_loss = 0.0005228433010709141
Trained batch 31 in epoch 6, gen_loss = 1.0008692666888237, disc_loss = 0.0005211874467931921
Trained batch 32 in epoch 6, gen_loss = 1.0010498509262546, disc_loss = 0.0005183940432316651
Trained batch 33 in epoch 6, gen_loss = 0.9967724154977238, disc_loss = 0.0005120646528666839
Trained batch 34 in epoch 6, gen_loss = 0.9975162778581892, disc_loss = 0.0005066911656675594
Trained batch 35 in epoch 6, gen_loss = 0.9985972179306878, disc_loss = 0.0005071833050654581
Trained batch 36 in epoch 6, gen_loss = 0.995468384510762, disc_loss = 0.0005089567354376855
Trained batch 37 in epoch 6, gen_loss = 0.9970960711178026, disc_loss = 0.0005077091934110381
Trained batch 38 in epoch 6, gen_loss = 0.9965286896778986, disc_loss = 0.0004999249116129553
Trained batch 39 in epoch 6, gen_loss = 0.9961335569620132, disc_loss = 0.0004965635253029177
Trained batch 40 in epoch 6, gen_loss = 0.9942708088130485, disc_loss = 0.000494150369976102
Trained batch 41 in epoch 6, gen_loss = 0.9939822370097751, disc_loss = 0.0004889971962603297
Trained batch 42 in epoch 6, gen_loss = 0.9970228408658227, disc_loss = 0.0004889279232376667
Trained batch 43 in epoch 6, gen_loss = 0.9976397630843249, disc_loss = 0.00048655289885408075
Trained batch 44 in epoch 6, gen_loss = 0.9995535943243239, disc_loss = 0.00048753754979568637
Trained batch 45 in epoch 6, gen_loss = 0.9991126021613246, disc_loss = 0.0004908014313474743
Trained batch 46 in epoch 6, gen_loss = 0.9989652874621939, disc_loss = 0.0004985112077036396
Trained batch 47 in epoch 6, gen_loss = 0.9989442055424055, disc_loss = 0.0005070743679122339
Trained batch 48 in epoch 6, gen_loss = 0.9985990086380316, disc_loss = 0.0005128674077853674
Trained batch 49 in epoch 6, gen_loss = 0.9958574640750885, disc_loss = 0.0005121153665822931
Trained batch 50 in epoch 6, gen_loss = 0.9968539254338133, disc_loss = 0.0005063867306578722
Trained batch 51 in epoch 6, gen_loss = 0.9963337412247291, disc_loss = 0.0004998491570474401
Trained batch 52 in epoch 6, gen_loss = 0.9979489119547718, disc_loss = 0.0004939550565740199
Trained batch 53 in epoch 6, gen_loss = 0.9982397821214464, disc_loss = 0.0004893742195606508
Trained batch 54 in epoch 6, gen_loss = 0.9977223613045433, disc_loss = 0.0004883069989525459
Trained batch 55 in epoch 6, gen_loss = 0.9958011188677379, disc_loss = 0.00048731849424906874
Trained batch 56 in epoch 6, gen_loss = 0.9937089451572352, disc_loss = 0.000486330309445692
Trained batch 57 in epoch 6, gen_loss = 0.9926375931706922, disc_loss = 0.0004838005717891943
Trained batch 58 in epoch 6, gen_loss = 0.9950992697376316, disc_loss = 0.0004802832954121217
Trained batch 59 in epoch 6, gen_loss = 0.9951046337683995, disc_loss = 0.000476039211692599
Trained batch 60 in epoch 6, gen_loss = 0.994543264146711, disc_loss = 0.0004706092433599358
Trained batch 61 in epoch 6, gen_loss = 0.994517114854628, disc_loss = 0.000465488642681345
Trained batch 62 in epoch 6, gen_loss = 0.996973401024228, disc_loss = 0.00046062977713835795
Trained batch 63 in epoch 6, gen_loss = 0.9965035151690245, disc_loss = 0.00045556895361187344
Trained batch 64 in epoch 6, gen_loss = 0.996465449149792, disc_loss = 0.00045052803358815326
Trained batch 65 in epoch 6, gen_loss = 0.9964490541906068, disc_loss = 0.00044742562771937105
Trained batch 66 in epoch 6, gen_loss = 0.9962976592690197, disc_loss = 0.0004451216818372121
Trained batch 67 in epoch 6, gen_loss = 0.9980283914243474, disc_loss = 0.000442850876638926
Trained batch 68 in epoch 6, gen_loss = 0.9999497152756953, disc_loss = 0.00044203135400058943
Trained batch 69 in epoch 6, gen_loss = 0.9991714145456042, disc_loss = 0.0004429769384192436
Trained batch 70 in epoch 6, gen_loss = 0.999550568385863, disc_loss = 0.00044416347137344085
Trained batch 71 in epoch 6, gen_loss = 0.9990779575374391, disc_loss = 0.00044323631724788964
Trained batch 72 in epoch 6, gen_loss = 0.9992673560364606, disc_loss = 0.0004422230957385331
Trained batch 73 in epoch 6, gen_loss = 0.9980566195539526, disc_loss = 0.00044185592107808317
Trained batch 74 in epoch 6, gen_loss = 0.9995070870717366, disc_loss = 0.00044193280880184226
Trained batch 75 in epoch 6, gen_loss = 0.9999458805510872, disc_loss = 0.00044123261594856896
Trained batch 76 in epoch 6, gen_loss = 0.9990624986685716, disc_loss = 0.000439009212476032
Trained batch 77 in epoch 6, gen_loss = 1.0009422187621777, disc_loss = 0.000436427694624469
Trained batch 78 in epoch 6, gen_loss = 0.9998658261721647, disc_loss = 0.0004349774133953372
Trained batch 79 in epoch 6, gen_loss = 1.0011826053261756, disc_loss = 0.0004350367251390708
Trained batch 80 in epoch 6, gen_loss = 1.0009632110595703, disc_loss = 0.00043597170543414253
Trained batch 81 in epoch 6, gen_loss = 1.0015179180517428, disc_loss = 0.00043578686994051835
Trained batch 82 in epoch 6, gen_loss = 1.000512231545276, disc_loss = 0.0004350389720358695
Trained batch 83 in epoch 6, gen_loss = 1.0012276506140119, disc_loss = 0.0004344018353939256
Trained batch 84 in epoch 6, gen_loss = 1.0006925765205832, disc_loss = 0.0004344789614312022
Trained batch 85 in epoch 6, gen_loss = 0.9994515333064767, disc_loss = 0.00043582719250522597
Trained batch 86 in epoch 6, gen_loss = 0.9984421743743721, disc_loss = 0.0004351234738246655
Trained batch 87 in epoch 6, gen_loss = 0.9973447221246633, disc_loss = 0.0004321243187322662
Trained batch 88 in epoch 6, gen_loss = 0.9962552638536089, disc_loss = 0.0004291887600445764
Trained batch 89 in epoch 6, gen_loss = 0.9948640333281623, disc_loss = 0.0004267764027139896
Trained batch 90 in epoch 6, gen_loss = 0.9960791016672994, disc_loss = 0.0004244939100117535
Trained batch 91 in epoch 6, gen_loss = 0.995368695129519, disc_loss = 0.0004224654344991153
Trained batch 92 in epoch 6, gen_loss = 0.9954015766420672, disc_loss = 0.0004208177014852383
Trained batch 93 in epoch 6, gen_loss = 0.9951656289557194, disc_loss = 0.00041909295612911477
Trained batch 94 in epoch 6, gen_loss = 0.9953424058462444, disc_loss = 0.0004173728363208571
Trained batch 95 in epoch 6, gen_loss = 0.9957525786012411, disc_loss = 0.0004166770724320183
Trained batch 96 in epoch 6, gen_loss = 0.9963771885203332, disc_loss = 0.0004172476013635103
Trained batch 97 in epoch 6, gen_loss = 0.9964676663583639, disc_loss = 0.0004194907065093688
Trained batch 98 in epoch 6, gen_loss = 0.9967230817284247, disc_loss = 0.00042125628158718234
Trained batch 99 in epoch 6, gen_loss = 0.9974506956338882, disc_loss = 0.0004218485749152023
Trained batch 100 in epoch 6, gen_loss = 0.9981084678432729, disc_loss = 0.0004207399908031365
Trained batch 101 in epoch 6, gen_loss = 0.997472040793475, disc_loss = 0.0004182494961366733
Trained batch 102 in epoch 6, gen_loss = 0.9972371528449567, disc_loss = 0.0004158572838313932
Trained batch 103 in epoch 6, gen_loss = 0.997135670712361, disc_loss = 0.00041384738114384864
Trained batch 104 in epoch 6, gen_loss = 0.996482941650209, disc_loss = 0.00041464951604471673
Trained batch 105 in epoch 6, gen_loss = 0.997557170548529, disc_loss = 0.00042059302976890905
Trained batch 106 in epoch 6, gen_loss = 0.9978388653737362, disc_loss = 0.0004279711906619753
Trained batch 107 in epoch 6, gen_loss = 0.9984694989743056, disc_loss = 0.0004317009214126436
Trained batch 108 in epoch 6, gen_loss = 0.9994009312139739, disc_loss = 0.0004313947016655237
Trained batch 109 in epoch 6, gen_loss = 0.9999141850254752, disc_loss = 0.0004290162377980199
Trained batch 110 in epoch 6, gen_loss = 1.00170443992357, disc_loss = 0.0004273495637666988
Trained batch 111 in epoch 6, gen_loss = 1.0019184036978654, disc_loss = 0.0004259000489972615
Trained batch 112 in epoch 6, gen_loss = 1.0028173559534865, disc_loss = 0.0004242649162806307
Trained batch 113 in epoch 6, gen_loss = 1.0028007955927598, disc_loss = 0.0004227332971998278
Trained batch 114 in epoch 6, gen_loss = 1.0028775406920392, disc_loss = 0.0004214362180589334
Trained batch 115 in epoch 6, gen_loss = 1.0026507115569607, disc_loss = 0.0004207790013330443
Trained batch 116 in epoch 6, gen_loss = 1.0031658181777368, disc_loss = 0.00042091044433152256
Trained batch 117 in epoch 6, gen_loss = 1.0034439104088282, disc_loss = 0.00042115881179767203
Trained batch 118 in epoch 6, gen_loss = 1.0029116593489127, disc_loss = 0.0004212685668461432
Trained batch 119 in epoch 6, gen_loss = 1.0016865670680999, disc_loss = 0.00042094823850978477
Trained batch 120 in epoch 6, gen_loss = 1.002467970217555, disc_loss = 0.0004207704982081474
Trained batch 121 in epoch 6, gen_loss = 1.0021382174530968, disc_loss = 0.00042118285935311046
Trained batch 122 in epoch 6, gen_loss = 1.0010972725666636, disc_loss = 0.00042167786230537583
Trained batch 123 in epoch 6, gen_loss = 1.0008140725474204, disc_loss = 0.0004208642187164045
Trained batch 124 in epoch 6, gen_loss = 1.001156310081482, disc_loss = 0.0004191614310257137
Trained batch 125 in epoch 6, gen_loss = 1.00212314866838, disc_loss = 0.00041835266881481937
Trained batch 126 in epoch 6, gen_loss = 1.0022031876045887, disc_loss = 0.0004186074601900654
Trained batch 127 in epoch 6, gen_loss = 1.0022428054362535, disc_loss = 0.0004183064304470463
Trained batch 128 in epoch 6, gen_loss = 1.0019520243933036, disc_loss = 0.00041734065671899005
Trained batch 129 in epoch 6, gen_loss = 1.0023471282078669, disc_loss = 0.0004162819973246839
Trained batch 130 in epoch 6, gen_loss = 1.0020236796095172, disc_loss = 0.0004141398064369151
Trained batch 131 in epoch 6, gen_loss = 1.0019836796052528, disc_loss = 0.0004120667052285915
Trained batch 132 in epoch 6, gen_loss = 1.0023778058532486, disc_loss = 0.00041007001436126414
Trained batch 133 in epoch 6, gen_loss = 1.0022195279598236, disc_loss = 0.0004087153911449835
Trained batch 134 in epoch 6, gen_loss = 1.0016786592978018, disc_loss = 0.00040836954107766765
Trained batch 135 in epoch 6, gen_loss = 1.0009107344290789, disc_loss = 0.00040803999378541075
Trained batch 136 in epoch 6, gen_loss = 1.0009224649763455, disc_loss = 0.0004074045124057558
Trained batch 137 in epoch 6, gen_loss = 1.0001585198485332, disc_loss = 0.0004074481809199653
Trained batch 138 in epoch 6, gen_loss = 1.000346983937051, disc_loss = 0.00040826425841999437
Trained batch 139 in epoch 6, gen_loss = 1.0010288230010442, disc_loss = 0.00040961846357926595
Trained batch 140 in epoch 6, gen_loss = 1.0004053301845037, disc_loss = 0.00041059151501147116
Trained batch 141 in epoch 6, gen_loss = 1.0005066697026643, disc_loss = 0.0004120497880495337
Trained batch 142 in epoch 6, gen_loss = 1.00154986998418, disc_loss = 0.0004128245086290294
Trained batch 143 in epoch 6, gen_loss = 1.0019385268290837, disc_loss = 0.00041271435545948206
Trained batch 144 in epoch 6, gen_loss = 1.002557688745959, disc_loss = 0.00041191579587356156
Trained batch 145 in epoch 6, gen_loss = 1.0025314676435026, disc_loss = 0.0004100110774544029
Trained batch 146 in epoch 6, gen_loss = 1.0026208117705624, disc_loss = 0.0004083835678238447
Trained batch 147 in epoch 6, gen_loss = 1.0026127337603956, disc_loss = 0.0004072675464330304
Trained batch 148 in epoch 6, gen_loss = 1.002592824049444, disc_loss = 0.00040596665241427393
Trained batch 149 in epoch 6, gen_loss = 1.0023392633597057, disc_loss = 0.0004053397401973295
Trained batch 150 in epoch 6, gen_loss = 1.002508176478329, disc_loss = 0.0004051991553155286
Trained batch 151 in epoch 6, gen_loss = 1.002135950091638, disc_loss = 0.0004062136235198092
Trained batch 152 in epoch 6, gen_loss = 1.0023701187052758, disc_loss = 0.0004060748302388413
Trained batch 153 in epoch 6, gen_loss = 1.0023820396367606, disc_loss = 0.00040531492054646885
Trained batch 154 in epoch 6, gen_loss = 1.0022248798801052, disc_loss = 0.00040392722773005166
Trained batch 155 in epoch 6, gen_loss = 1.0021742444771986, disc_loss = 0.0004021787813727338
Trained batch 156 in epoch 6, gen_loss = 1.0020703221582303, disc_loss = 0.00040137559671554073
Trained batch 157 in epoch 6, gen_loss = 1.0022969185551511, disc_loss = 0.00040063632341231446
Trained batch 158 in epoch 6, gen_loss = 1.0020742386392079, disc_loss = 0.0003993316645420643
Trained batch 159 in epoch 6, gen_loss = 1.0025401696562768, disc_loss = 0.00039807645425753434
Trained batch 160 in epoch 6, gen_loss = 1.0017825572387031, disc_loss = 0.0003968643371459756
Trained batch 161 in epoch 6, gen_loss = 1.00180709435616, disc_loss = 0.00039583065733529146
Trained batch 162 in epoch 6, gen_loss = 1.0020867571508958, disc_loss = 0.00039476238823555796
Trained batch 163 in epoch 6, gen_loss = 1.0023506429137252, disc_loss = 0.0003934187490547008
Trained batch 164 in epoch 6, gen_loss = 1.0030535979704422, disc_loss = 0.0003919254529826117
Trained batch 165 in epoch 6, gen_loss = 1.002634839839246, disc_loss = 0.00039044916959400904
Trained batch 166 in epoch 6, gen_loss = 1.0028846513725327, disc_loss = 0.0003895448479999392
Trained batch 167 in epoch 6, gen_loss = 1.0026932103293282, disc_loss = 0.0003888075492189576
Trained batch 168 in epoch 6, gen_loss = 1.0027138939975986, disc_loss = 0.000388688934118261
Trained batch 169 in epoch 6, gen_loss = 1.0031352527001325, disc_loss = 0.00038846434207003125
Trained batch 170 in epoch 6, gen_loss = 1.0027149378904823, disc_loss = 0.000388369882923186
Trained batch 171 in epoch 6, gen_loss = 1.004249928302543, disc_loss = 0.000388861607609934
Trained batch 172 in epoch 6, gen_loss = 1.0039563799180047, disc_loss = 0.0003881591910192194
Trained batch 173 in epoch 6, gen_loss = 1.004256336168311, disc_loss = 0.00038745033774851423
Trained batch 174 in epoch 6, gen_loss = 1.0042916291100639, disc_loss = 0.000386893587087148
Trained batch 175 in epoch 6, gen_loss = 1.004046270115809, disc_loss = 0.0003861578997285423
Trained batch 176 in epoch 6, gen_loss = 1.0035255972274952, disc_loss = 0.00038611256691106294
Trained batch 177 in epoch 6, gen_loss = 1.0037723759586892, disc_loss = 0.00038554969477843954
Trained batch 178 in epoch 6, gen_loss = 1.0040876812109067, disc_loss = 0.0003845819768654547
Trained batch 179 in epoch 6, gen_loss = 1.0036741846137576, disc_loss = 0.0003833340809150185
Trained batch 180 in epoch 6, gen_loss = 1.0036969659078188, disc_loss = 0.00038180155304128055
Trained batch 181 in epoch 6, gen_loss = 1.0035724194495232, disc_loss = 0.00038019347478409173
Trained batch 182 in epoch 6, gen_loss = 1.0038918706237292, disc_loss = 0.0003789485439920895
Trained batch 183 in epoch 6, gen_loss = 1.0049783127463383, disc_loss = 0.00037791299778093713
Trained batch 184 in epoch 6, gen_loss = 1.004949992089658, disc_loss = 0.00037657496243293675
Trained batch 185 in epoch 6, gen_loss = 1.0052750453513155, disc_loss = 0.0003757616941975455
Trained batch 186 in epoch 6, gen_loss = 1.005251387542582, disc_loss = 0.0003752694808007069
Trained batch 187 in epoch 6, gen_loss = 1.004758446457538, disc_loss = 0.0003746682210243926
Trained batch 188 in epoch 6, gen_loss = 1.005084907882428, disc_loss = 0.00037362124952124235
Trained batch 189 in epoch 6, gen_loss = 1.0050473781008469, disc_loss = 0.00037222027994606544
Trained batch 190 in epoch 6, gen_loss = 1.0050241426023514, disc_loss = 0.00037067048250866993
Trained batch 191 in epoch 6, gen_loss = 1.005794804232816, disc_loss = 0.000369547876478767
Trained batch 192 in epoch 6, gen_loss = 1.0060072065635048, disc_loss = 0.0003694575384378052
Trained batch 193 in epoch 6, gen_loss = 1.0068007231373148, disc_loss = 0.00037107881376569003
Trained batch 194 in epoch 6, gen_loss = 1.006289496482947, disc_loss = 0.0003746178295561829
Trained batch 195 in epoch 6, gen_loss = 1.006637950028692, disc_loss = 0.00038235500587503263
Trained batch 196 in epoch 6, gen_loss = 1.0064380919267684, disc_loss = 0.0003880995036848008
Trained batch 197 in epoch 6, gen_loss = 1.0067014874834004, disc_loss = 0.000391112599526873
Trained batch 198 in epoch 6, gen_loss = 1.0061882356902463, disc_loss = 0.00039224708751902856
Trained batch 199 in epoch 6, gen_loss = 1.0054727825522423, disc_loss = 0.00039445218881155596
Trained batch 200 in epoch 6, gen_loss = 1.0056672858361582, disc_loss = 0.0003955233163407086
Trained batch 201 in epoch 6, gen_loss = 1.0056506947125539, disc_loss = 0.00039543478311261963
Trained batch 202 in epoch 6, gen_loss = 1.0057579610735325, disc_loss = 0.0003948981278782981
Trained batch 203 in epoch 6, gen_loss = 1.0059417681951148, disc_loss = 0.0003945991401825963
Trained batch 204 in epoch 6, gen_loss = 1.006156967035154, disc_loss = 0.00039377971300315795
Trained batch 205 in epoch 6, gen_loss = 1.0058286071402356, disc_loss = 0.00039291288876748933
Trained batch 206 in epoch 6, gen_loss = 1.0056244129144052, disc_loss = 0.00039218401763130403
Trained batch 207 in epoch 6, gen_loss = 1.0062492375190442, disc_loss = 0.0003912404588915636
Trained batch 208 in epoch 6, gen_loss = 1.0067365814053841, disc_loss = 0.00039025470424353245
Trained batch 209 in epoch 6, gen_loss = 1.0067665673437574, disc_loss = 0.00038926844229406147
Trained batch 210 in epoch 6, gen_loss = 1.0068509832942656, disc_loss = 0.0003881891825585626
Trained batch 211 in epoch 6, gen_loss = 1.006829005929659, disc_loss = 0.00038738512159638185
Trained batch 212 in epoch 6, gen_loss = 1.0066765099064285, disc_loss = 0.00038671122295885817
Trained batch 213 in epoch 6, gen_loss = 1.0072286463229456, disc_loss = 0.0003855569946982737
Trained batch 214 in epoch 6, gen_loss = 1.007276330992233, disc_loss = 0.00038432596514656665
Trained batch 215 in epoch 6, gen_loss = 1.0067787504306547, disc_loss = 0.0003831512678381707
Trained batch 216 in epoch 6, gen_loss = 1.0068889425097522, disc_loss = 0.00038179425512760245
Trained batch 217 in epoch 6, gen_loss = 1.0076068079252856, disc_loss = 0.0003805188098340295
Trained batch 218 in epoch 6, gen_loss = 1.0073646293383212, disc_loss = 0.00037944808180526867
Trained batch 219 in epoch 6, gen_loss = 1.007426189563491, disc_loss = 0.00037896550010455856
Trained batch 220 in epoch 6, gen_loss = 1.0070061543408562, disc_loss = 0.0003794159002605261
Trained batch 221 in epoch 6, gen_loss = 1.0069129593200512, disc_loss = 0.000381832164101332
Trained batch 222 in epoch 6, gen_loss = 1.0064934751378047, disc_loss = 0.0003881543449146022
Trained batch 223 in epoch 6, gen_loss = 1.0064627860805817, disc_loss = 0.0003945944600413246
Trained batch 224 in epoch 6, gen_loss = 1.0067176418834263, disc_loss = 0.0004014886671858322
Trained batch 225 in epoch 6, gen_loss = 1.006239326390545, disc_loss = 0.0004088573215866206
Trained batch 226 in epoch 6, gen_loss = 1.006809795217892, disc_loss = 0.0004143240786078571
Trained batch 227 in epoch 6, gen_loss = 1.0070551714876241, disc_loss = 0.0004159848372581652
Trained batch 228 in epoch 6, gen_loss = 1.0073905571579413, disc_loss = 0.00041561879823340193
Trained batch 229 in epoch 6, gen_loss = 1.007726006663364, disc_loss = 0.00041467845332353255
Trained batch 230 in epoch 6, gen_loss = 1.0074543676851115, disc_loss = 0.00041359136173616516
Trained batch 231 in epoch 6, gen_loss = 1.0075497917574028, disc_loss = 0.00041264761339648273
Trained batch 232 in epoch 6, gen_loss = 1.0072844005449646, disc_loss = 0.00041172713055795
Trained batch 233 in epoch 6, gen_loss = 1.0067960912855263, disc_loss = 0.0004113628944425852
Trained batch 234 in epoch 6, gen_loss = 1.0066000030395832, disc_loss = 0.0004112539837691695
Trained batch 235 in epoch 6, gen_loss = 1.0067049078011916, disc_loss = 0.0004102255281118155
Trained batch 236 in epoch 6, gen_loss = 1.0068387452057141, disc_loss = 0.00040900030494854246
Trained batch 237 in epoch 6, gen_loss = 1.0065233394378374, disc_loss = 0.0004082405989223645
Trained batch 238 in epoch 6, gen_loss = 1.007086720676103, disc_loss = 0.00040903884512479477
Trained batch 239 in epoch 6, gen_loss = 1.006614383806785, disc_loss = 0.00041105940138853235
Trained batch 240 in epoch 6, gen_loss = 1.006060073731846, disc_loss = 0.00041342138210591703
Trained batch 241 in epoch 6, gen_loss = 1.0063296810161968, disc_loss = 0.00041404436252220374
Trained batch 242 in epoch 6, gen_loss = 1.006150516217628, disc_loss = 0.0004131572745398354
Trained batch 243 in epoch 6, gen_loss = 1.0062515982350364, disc_loss = 0.00041222522045021923
Trained batch 244 in epoch 6, gen_loss = 1.0069810597264037, disc_loss = 0.000412582655553706
Trained batch 245 in epoch 6, gen_loss = 1.0075256429552062, disc_loss = 0.0004131928358034882
Trained batch 246 in epoch 6, gen_loss = 1.0079851693469986, disc_loss = 0.0004132640252181099
Trained batch 247 in epoch 6, gen_loss = 1.0078682961963839, disc_loss = 0.00041286333368090357
Trained batch 248 in epoch 6, gen_loss = 1.007744096847902, disc_loss = 0.0004120588272339646
Trained batch 249 in epoch 6, gen_loss = 1.0082913527488708, disc_loss = 0.00041140273358905685
Trained batch 250 in epoch 6, gen_loss = 1.0082067545666638, disc_loss = 0.00041076795338788457
Trained batch 251 in epoch 6, gen_loss = 1.008384655865412, disc_loss = 0.00041029043166504594
Trained batch 252 in epoch 6, gen_loss = 1.0083541380086907, disc_loss = 0.00040980066379151225
Trained batch 253 in epoch 6, gen_loss = 1.008224181772217, disc_loss = 0.0004093583066985341
Trained batch 254 in epoch 6, gen_loss = 1.0086554013046565, disc_loss = 0.0004087229577171635
Trained batch 255 in epoch 6, gen_loss = 1.0086164781823754, disc_loss = 0.0004077887330140584
Trained batch 256 in epoch 6, gen_loss = 1.0086308587849835, disc_loss = 0.00040724466689354973
Trained batch 257 in epoch 6, gen_loss = 1.0089562729347583, disc_loss = 0.0004066866638667723
Trained batch 258 in epoch 6, gen_loss = 1.008951024659352, disc_loss = 0.0004058072344479996
Trained batch 259 in epoch 6, gen_loss = 1.0086478746854342, disc_loss = 0.0004046915653396774
Trained batch 260 in epoch 6, gen_loss = 1.0086652501789546, disc_loss = 0.000403460800165794
Trained batch 261 in epoch 6, gen_loss = 1.0086693941181852, disc_loss = 0.00040235865718102126
Trained batch 262 in epoch 6, gen_loss = 1.0092317990023827, disc_loss = 0.0004016012823148967
Trained batch 263 in epoch 6, gen_loss = 1.0089089674028484, disc_loss = 0.00040098755573236497
Trained batch 264 in epoch 6, gen_loss = 1.0090460572602613, disc_loss = 0.0004009360584808197
Trained batch 265 in epoch 6, gen_loss = 1.008787914550394, disc_loss = 0.0004007247931112122
Trained batch 266 in epoch 6, gen_loss = 1.0088011792090055, disc_loss = 0.0004006213004297964
Trained batch 267 in epoch 6, gen_loss = 1.0088531208127292, disc_loss = 0.0003997889886989863
Trained batch 268 in epoch 6, gen_loss = 1.008989945884974, disc_loss = 0.00039925807110011423
Trained batch 269 in epoch 6, gen_loss = 1.008767948989515, disc_loss = 0.00039850905277826653
Trained batch 270 in epoch 6, gen_loss = 1.0090539114501644, disc_loss = 0.00039758771047729833
Trained batch 271 in epoch 6, gen_loss = 1.0087815832127542, disc_loss = 0.0003966295117232435
Trained batch 272 in epoch 6, gen_loss = 1.0088760689064697, disc_loss = 0.00039643786819660253
Trained batch 273 in epoch 6, gen_loss = 1.0090074467397954, disc_loss = 0.00039685677455943825
Trained batch 274 in epoch 6, gen_loss = 1.0094240229780023, disc_loss = 0.00039701892946719783
Trained batch 275 in epoch 6, gen_loss = 1.0098886055790859, disc_loss = 0.00039654751073111834
Trained batch 276 in epoch 6, gen_loss = 1.0098738539089795, disc_loss = 0.000395716603650772
Trained batch 277 in epoch 6, gen_loss = 1.0096082976824945, disc_loss = 0.00039521602886727266
Trained batch 278 in epoch 6, gen_loss = 1.0096002229652952, disc_loss = 0.00039502421111714656
Trained batch 279 in epoch 6, gen_loss = 1.0095069159354482, disc_loss = 0.00039497144851858527
Trained batch 280 in epoch 6, gen_loss = 1.0100774652593076, disc_loss = 0.0003946809682997567
Trained batch 281 in epoch 6, gen_loss = 1.0097977030784526, disc_loss = 0.0003943323812151083
Trained batch 282 in epoch 6, gen_loss = 1.0099400528328157, disc_loss = 0.00039407877255002424
Trained batch 283 in epoch 6, gen_loss = 1.0102124497504301, disc_loss = 0.00039385126877623664
Trained batch 284 in epoch 6, gen_loss = 1.0101376487497697, disc_loss = 0.0003936364134189493
Trained batch 285 in epoch 6, gen_loss = 1.009847640991211, disc_loss = 0.0003932809428791385
Trained batch 286 in epoch 6, gen_loss = 1.0097589212427571, disc_loss = 0.0003928238042173518
Trained batch 287 in epoch 6, gen_loss = 1.0099046886381176, disc_loss = 0.00039286485485313786
Trained batch 288 in epoch 6, gen_loss = 1.0094511626500984, disc_loss = 0.0003925893435300615
Trained batch 289 in epoch 6, gen_loss = 1.0092317928527963, disc_loss = 0.0003923641146935426
Trained batch 290 in epoch 6, gen_loss = 1.0091895827722712, disc_loss = 0.0003918630819182837
Trained batch 291 in epoch 6, gen_loss = 1.009210037858519, disc_loss = 0.0003911224401684331
Trained batch 292 in epoch 6, gen_loss = 1.0090963299363953, disc_loss = 0.00039050178030194276
Trained batch 293 in epoch 6, gen_loss = 1.0088216277206836, disc_loss = 0.00039023476839699105
Trained batch 294 in epoch 6, gen_loss = 1.008768684379125, disc_loss = 0.00039016326299426543
Trained batch 295 in epoch 6, gen_loss = 1.009056469677268, disc_loss = 0.0003899344276735949
Trained batch 296 in epoch 6, gen_loss = 1.0089725613192677, disc_loss = 0.0003892833935151736
Trained batch 297 in epoch 6, gen_loss = 1.0087116492674655, disc_loss = 0.00038878207851666957
Trained batch 298 in epoch 6, gen_loss = 1.0087327678068028, disc_loss = 0.0003881294090093665
Trained batch 299 in epoch 6, gen_loss = 1.0093913547197977, disc_loss = 0.0003876534799928777
Trained batch 300 in epoch 6, gen_loss = 1.009739035387768, disc_loss = 0.00038789563738443947
Trained batch 301 in epoch 6, gen_loss = 1.0102105503840162, disc_loss = 0.00038860243945983884
Trained batch 302 in epoch 6, gen_loss = 1.0099395946307543, disc_loss = 0.00038943540375209457
Trained batch 303 in epoch 6, gen_loss = 1.009557587143622, disc_loss = 0.00038990131179161835
Trained batch 304 in epoch 6, gen_loss = 1.00941710628447, disc_loss = 0.00038956459354013817
Trained batch 305 in epoch 6, gen_loss = 1.009016540315416, disc_loss = 0.0003892910460183653
Trained batch 306 in epoch 6, gen_loss = 1.0097001884193295, disc_loss = 0.00038982507168294116
Trained batch 307 in epoch 6, gen_loss = 1.0100165690694536, disc_loss = 0.0003907166626652122
Trained batch 308 in epoch 6, gen_loss = 1.0103746857072158, disc_loss = 0.0003918173333364735
Trained batch 309 in epoch 6, gen_loss = 1.010225917639271, disc_loss = 0.00039335759750927887
Trained batch 310 in epoch 6, gen_loss = 1.009798446652207, disc_loss = 0.0003949273007074401
Trained batch 311 in epoch 6, gen_loss = 1.0102907648453345, disc_loss = 0.0003969875751630379
Trained batch 312 in epoch 6, gen_loss = 1.009971671020642, disc_loss = 0.00040058195985222874
Trained batch 313 in epoch 6, gen_loss = 1.0103137092605519, disc_loss = 0.00040492311877845106
Trained batch 314 in epoch 6, gen_loss = 1.0102563492835515, disc_loss = 0.00040824840636184765
Trained batch 315 in epoch 6, gen_loss = 1.009935923580882, disc_loss = 0.00040976693699006696
Trained batch 316 in epoch 6, gen_loss = 1.0097107599586344, disc_loss = 0.0004102612852209985
Trained batch 317 in epoch 6, gen_loss = 1.0092256406568132, disc_loss = 0.00041113738131668396
Trained batch 318 in epoch 6, gen_loss = 1.009309219342414, disc_loss = 0.0004147770489802508
Trained batch 319 in epoch 6, gen_loss = 1.009489243105054, disc_loss = 0.00041882293116941583
Trained batch 320 in epoch 6, gen_loss = 1.0095714430942713, disc_loss = 0.00042408113288069346
Trained batch 321 in epoch 6, gen_loss = 1.009390883379101, disc_loss = 0.00042806089796438256
Trained batch 322 in epoch 6, gen_loss = 1.009596989066239, disc_loss = 0.00042963660741657386
Trained batch 323 in epoch 6, gen_loss = 1.009654908820435, disc_loss = 0.0004309594974692129
Trained batch 324 in epoch 6, gen_loss = 1.0093247646551866, disc_loss = 0.00043192766624717757
Trained batch 325 in epoch 6, gen_loss = 1.0090941386354482, disc_loss = 0.00043261330235503797
Trained batch 326 in epoch 6, gen_loss = 1.0091064776484755, disc_loss = 0.00043328644459303867
Trained batch 327 in epoch 6, gen_loss = 1.0090538085233876, disc_loss = 0.00043354159442526174
Trained batch 328 in epoch 6, gen_loss = 1.0090031846678367, disc_loss = 0.0004342574299607528
Trained batch 329 in epoch 6, gen_loss = 1.008713208545338, disc_loss = 0.0004360813275332365
Trained batch 330 in epoch 6, gen_loss = 1.008927178887082, disc_loss = 0.0004371685240406464
Trained batch 331 in epoch 6, gen_loss = 1.0083919862307698, disc_loss = 0.0004389443496489022
Trained batch 332 in epoch 6, gen_loss = 1.0087908887648367, disc_loss = 0.0004416607535659551
Trained batch 333 in epoch 6, gen_loss = 1.0090460986077427, disc_loss = 0.00044463906704844116
Trained batch 334 in epoch 6, gen_loss = 1.0086830092899834, disc_loss = 0.0004459428394199419
Trained batch 335 in epoch 6, gen_loss = 1.0086443266343503, disc_loss = 0.00044605575316208635
Trained batch 336 in epoch 6, gen_loss = 1.008590287023199, disc_loss = 0.0004457544592569806
Trained batch 337 in epoch 6, gen_loss = 1.0087693162571043, disc_loss = 0.00044535246590557425
Trained batch 338 in epoch 6, gen_loss = 1.0088213919538311, disc_loss = 0.0004447620486700495
Trained batch 339 in epoch 6, gen_loss = 1.008860208181774, disc_loss = 0.00044383579036494825
Trained batch 340 in epoch 6, gen_loss = 1.0087481637504443, disc_loss = 0.0004429902892564546
Trained batch 341 in epoch 6, gen_loss = 1.0092031093020188, disc_loss = 0.000442056591703886
Trained batch 342 in epoch 6, gen_loss = 1.0092996336280777, disc_loss = 0.00044117133227637197
Trained batch 343 in epoch 6, gen_loss = 1.0091351140723672, disc_loss = 0.00044036849223714873
Trained batch 344 in epoch 6, gen_loss = 1.0091916614684506, disc_loss = 0.0004395708454809948
Trained batch 345 in epoch 6, gen_loss = 1.0089060565984318, disc_loss = 0.00043878719496447864
Trained batch 346 in epoch 6, gen_loss = 1.0091851913619798, disc_loss = 0.00043805595214769876
Trained batch 347 in epoch 6, gen_loss = 1.009164010142458, disc_loss = 0.00043728706408017743
Trained batch 348 in epoch 6, gen_loss = 1.009233780269295, disc_loss = 0.0004365751363856072
Trained batch 349 in epoch 6, gen_loss = 1.0093856622491564, disc_loss = 0.0004357608162432111
Trained batch 350 in epoch 6, gen_loss = 1.0095270218332948, disc_loss = 0.00043498104692077225
Trained batch 351 in epoch 6, gen_loss = 1.0096784052862362, disc_loss = 0.0004346507155539505
Trained batch 352 in epoch 6, gen_loss = 1.0097088383209942, disc_loss = 0.0004348021592841307
Trained batch 353 in epoch 6, gen_loss = 1.0094977059943528, disc_loss = 0.0004345365199553096
Trained batch 354 in epoch 6, gen_loss = 1.0096078316930315, disc_loss = 0.0004338955554232316
Trained batch 355 in epoch 6, gen_loss = 1.0095069122113538, disc_loss = 0.0004331019574258309
Trained batch 356 in epoch 6, gen_loss = 1.0093748258943318, disc_loss = 0.0004323457371957433
Trained batch 357 in epoch 6, gen_loss = 1.0094302789459015, disc_loss = 0.00043164381386507977
Trained batch 358 in epoch 6, gen_loss = 1.009418098707385, disc_loss = 0.00043120760139704406
Trained batch 359 in epoch 6, gen_loss = 1.009298178056876, disc_loss = 0.000430761731089054
Trained batch 360 in epoch 6, gen_loss = 1.0091001222998812, disc_loss = 0.0004303337976873731
Trained batch 361 in epoch 6, gen_loss = 1.008893528201962, disc_loss = 0.0004307861031545712
Trained batch 362 in epoch 6, gen_loss = 1.0084248625214107, disc_loss = 0.0004338563275000737
Trained batch 363 in epoch 6, gen_loss = 1.0084853828935834, disc_loss = 0.0004363289030712062
Trained batch 364 in epoch 6, gen_loss = 1.008532281281197, disc_loss = 0.0004396831357216922
Trained batch 365 in epoch 6, gen_loss = 1.0085845890918064, disc_loss = 0.0004422190996180187
Trained batch 366 in epoch 6, gen_loss = 1.0085665849963716, disc_loss = 0.0004431565255462763
Trained batch 367 in epoch 6, gen_loss = 1.0085434047100337, disc_loss = 0.00044407558431450286
Trained batch 368 in epoch 6, gen_loss = 1.009066630346665, disc_loss = 0.00044503361956048555
Trained batch 369 in epoch 6, gen_loss = 1.0088615116235373, disc_loss = 0.000444677120390839
Trained batch 370 in epoch 6, gen_loss = 1.0087205820649139, disc_loss = 0.0004446078227180862
Trained batch 371 in epoch 6, gen_loss = 1.0087443122299768, disc_loss = 0.00044483528804986595
Trained batch 372 in epoch 6, gen_loss = 1.0088587858721654, disc_loss = 0.00044459059622092547
Trained batch 373 in epoch 6, gen_loss = 1.0088197506047825, disc_loss = 0.0004449651444210661
Trained batch 374 in epoch 6, gen_loss = 1.00860023244222, disc_loss = 0.00044510643770142146
Trained batch 375 in epoch 6, gen_loss = 1.0086493064114388, disc_loss = 0.0004448010951161082
Trained batch 376 in epoch 6, gen_loss = 1.0086461305618286, disc_loss = 0.0004445673790633733
Trained batch 377 in epoch 6, gen_loss = 1.0089092081186002, disc_loss = 0.0004443346642320557
Trained batch 378 in epoch 6, gen_loss = 1.009012701328952, disc_loss = 0.0004438309118813297
Trained batch 379 in epoch 6, gen_loss = 1.0086583077907563, disc_loss = 0.00044374231905461975
Trained batch 380 in epoch 6, gen_loss = 1.0085375258928835, disc_loss = 0.000443232936634599
Trained batch 381 in epoch 6, gen_loss = 1.0085889706436877, disc_loss = 0.00044277835341264296
Trained batch 382 in epoch 6, gen_loss = 1.008556223724903, disc_loss = 0.00044223425233421733
Trained batch 383 in epoch 6, gen_loss = 1.0084811214668055, disc_loss = 0.00044180766133194993
Trained batch 384 in epoch 6, gen_loss = 1.0082886706699024, disc_loss = 0.0004415079588811337
Trained batch 385 in epoch 6, gen_loss = 1.0082088795350623, disc_loss = 0.0004411071060219939
Trained batch 386 in epoch 6, gen_loss = 1.0083009186333156, disc_loss = 0.00044099159113243365
Trained batch 387 in epoch 6, gen_loss = 1.0082442602238704, disc_loss = 0.0004409799818024543
Trained batch 388 in epoch 6, gen_loss = 1.008252171593644, disc_loss = 0.0004405082900518226
Trained batch 389 in epoch 6, gen_loss = 1.0084559289308694, disc_loss = 0.00043971778818209154
Trained batch 390 in epoch 6, gen_loss = 1.0086322765216194, disc_loss = 0.00043883058566289245
Trained batch 391 in epoch 6, gen_loss = 1.0084908505787655, disc_loss = 0.00043808058759094246
Trained batch 392 in epoch 6, gen_loss = 1.0086283051330625, disc_loss = 0.0004376589886606588
Trained batch 393 in epoch 6, gen_loss = 1.0084782658797231, disc_loss = 0.0004373397070575898
Trained batch 394 in epoch 6, gen_loss = 1.0085088067416903, disc_loss = 0.0004370299475547516
Trained batch 395 in epoch 6, gen_loss = 1.0084871560937227, disc_loss = 0.0004365135705162597
Trained batch 396 in epoch 6, gen_loss = 1.0082221912496936, disc_loss = 0.00043655220009075705
Trained batch 397 in epoch 6, gen_loss = 1.008327863773509, disc_loss = 0.00043681196805678225
Trained batch 398 in epoch 6, gen_loss = 1.0081657647787778, disc_loss = 0.00043639750464237004
Trained batch 399 in epoch 6, gen_loss = 1.008246809989214, disc_loss = 0.0004363735974402516
Trained batch 400 in epoch 6, gen_loss = 1.0080724718267484, disc_loss = 0.0004358010787076719
Trained batch 401 in epoch 6, gen_loss = 1.0080955756540915, disc_loss = 0.0004352638367271
Trained batch 402 in epoch 6, gen_loss = 1.00832180808259, disc_loss = 0.0004349505710724635
Trained batch 403 in epoch 6, gen_loss = 1.0083118888116118, disc_loss = 0.00043490802920924843
Trained batch 404 in epoch 6, gen_loss = 1.0083623940562025, disc_loss = 0.00043485338938347763
Trained batch 405 in epoch 6, gen_loss = 1.0084771876558294, disc_loss = 0.00043453081831963404
Trained batch 406 in epoch 6, gen_loss = 1.008397189200071, disc_loss = 0.0004340099531276774
Trained batch 407 in epoch 6, gen_loss = 1.0082999095320702, disc_loss = 0.0004333248904788657
Trained batch 408 in epoch 6, gen_loss = 1.0082265743416503, disc_loss = 0.000432463924360375
Trained batch 409 in epoch 6, gen_loss = 1.008224725287135, disc_loss = 0.0004315772371738581
Trained batch 410 in epoch 6, gen_loss = 1.0082754982939022, disc_loss = 0.00043072487752549823
Trained batch 411 in epoch 6, gen_loss = 1.0079893602908236, disc_loss = 0.0004300007141723345
Trained batch 412 in epoch 6, gen_loss = 1.008144809316492, disc_loss = 0.00042944665954599935
Trained batch 413 in epoch 6, gen_loss = 1.0080775730851768, disc_loss = 0.0004290290175497606
Trained batch 414 in epoch 6, gen_loss = 1.0080754446696085, disc_loss = 0.00042862377856389607
Trained batch 415 in epoch 6, gen_loss = 1.008184046126329, disc_loss = 0.0004281160760316337
Trained batch 416 in epoch 6, gen_loss = 1.0084070487559842, disc_loss = 0.00042767839669096406
Trained batch 417 in epoch 6, gen_loss = 1.0085961924215252, disc_loss = 0.0004273420304365503
Trained batch 418 in epoch 6, gen_loss = 1.0087521158710016, disc_loss = 0.00042692798105146854
Trained batch 419 in epoch 6, gen_loss = 1.0085283414238975, disc_loss = 0.00042663088106131733
Trained batch 420 in epoch 6, gen_loss = 1.008667406588439, disc_loss = 0.0004263214614788997
Trained batch 421 in epoch 6, gen_loss = 1.0086638493842988, disc_loss = 0.00042595381838376014
Trained batch 422 in epoch 6, gen_loss = 1.0087335649393412, disc_loss = 0.000425542738285476
Trained batch 423 in epoch 6, gen_loss = 1.0088771805167198, disc_loss = 0.0004252547309559579
Trained batch 424 in epoch 6, gen_loss = 1.0087975473964916, disc_loss = 0.0004248895881841343
Trained batch 425 in epoch 6, gen_loss = 1.0089003261825849, disc_loss = 0.00042484316483597457
Trained batch 426 in epoch 6, gen_loss = 1.0087966366171557, disc_loss = 0.00042504320589160824
Trained batch 427 in epoch 6, gen_loss = 1.0088448226451874, disc_loss = 0.0004247504313293873
Trained batch 428 in epoch 6, gen_loss = 1.0087860779606657, disc_loss = 0.0004246219238956971
Trained batch 429 in epoch 6, gen_loss = 1.008771142710087, disc_loss = 0.00042468093067940955
Trained batch 430 in epoch 6, gen_loss = 1.008913207081797, disc_loss = 0.00042450856849923405
Trained batch 431 in epoch 6, gen_loss = 1.0087850144891828, disc_loss = 0.00042442447565244274
Trained batch 432 in epoch 6, gen_loss = 1.0088163321067776, disc_loss = 0.0004242023087100461
Trained batch 433 in epoch 6, gen_loss = 1.008726452215476, disc_loss = 0.0004237308196594975
Trained batch 434 in epoch 6, gen_loss = 1.0086496335336532, disc_loss = 0.0004233867225227824
Trained batch 435 in epoch 6, gen_loss = 1.0085746526991555, disc_loss = 0.0004228898753453988
Trained batch 436 in epoch 6, gen_loss = 1.008711718449058, disc_loss = 0.00042224692005130785
Trained batch 437 in epoch 6, gen_loss = 1.0086630316085468, disc_loss = 0.0004215500862114387
Trained batch 438 in epoch 6, gen_loss = 1.008461400832565, disc_loss = 0.00042127706731005587
Trained batch 439 in epoch 6, gen_loss = 1.0084804528138853, disc_loss = 0.0004209208073999352
Trained batch 440 in epoch 6, gen_loss = 1.008434596650995, disc_loss = 0.0004203695266152776
Trained batch 441 in epoch 6, gen_loss = 1.0085541920154881, disc_loss = 0.0004196985865989489
Trained batch 442 in epoch 6, gen_loss = 1.0087527952936917, disc_loss = 0.0004189523244337084
Trained batch 443 in epoch 6, gen_loss = 1.0091245148901467, disc_loss = 0.00041834588691844974
Trained batch 444 in epoch 6, gen_loss = 1.009133078141159, disc_loss = 0.0004177616723078
Trained batch 445 in epoch 6, gen_loss = 1.009137592641762, disc_loss = 0.00041742831972483
Trained batch 446 in epoch 6, gen_loss = 1.0089246250639026, disc_loss = 0.00041706668842876626
Trained batch 447 in epoch 6, gen_loss = 1.0090103764086962, disc_loss = 0.00041648056981102854
Trained batch 448 in epoch 6, gen_loss = 1.0089633217898668, disc_loss = 0.00041588380073175404
Trained batch 449 in epoch 6, gen_loss = 1.0087537125746409, disc_loss = 0.0004153528977702889
Trained batch 450 in epoch 6, gen_loss = 1.0088081266028919, disc_loss = 0.0004148294657733118
Trained batch 451 in epoch 6, gen_loss = 1.0090186344047563, disc_loss = 0.0004143305401656719
Trained batch 452 in epoch 6, gen_loss = 1.008986482557082, disc_loss = 0.00041378206197197076
Trained batch 453 in epoch 6, gen_loss = 1.0089710630509297, disc_loss = 0.00041316907194141497
Trained batch 454 in epoch 6, gen_loss = 1.0090669956836071, disc_loss = 0.0004131337684696888
Trained batch 455 in epoch 6, gen_loss = 1.009454936311956, disc_loss = 0.00041352780138830686
Trained batch 456 in epoch 6, gen_loss = 1.009396810500314, disc_loss = 0.00041375305719879463
Trained batch 457 in epoch 6, gen_loss = 1.0092517954813862, disc_loss = 0.00041378121580328697
Trained batch 458 in epoch 6, gen_loss = 1.0093013162446698, disc_loss = 0.00041329878390500876
Trained batch 459 in epoch 6, gen_loss = 1.0094291725884312, disc_loss = 0.0004128799839236308
Trained batch 460 in epoch 6, gen_loss = 1.0094299406912217, disc_loss = 0.0004127012963652704
Trained batch 461 in epoch 6, gen_loss = 1.0094678881880526, disc_loss = 0.0004126680584322536
Trained batch 462 in epoch 6, gen_loss = 1.0093770132723947, disc_loss = 0.0004123003061065756
Trained batch 463 in epoch 6, gen_loss = 1.0093135879985218, disc_loss = 0.0004117594133841239
Trained batch 464 in epoch 6, gen_loss = 1.009358904438634, disc_loss = 0.00041108470548117054
Trained batch 465 in epoch 6, gen_loss = 1.0094966289823146, disc_loss = 0.0004104275314696683
Trained batch 466 in epoch 6, gen_loss = 1.0095836039018324, disc_loss = 0.00040991012861354406
Trained batch 467 in epoch 6, gen_loss = 1.0093881723463025, disc_loss = 0.0004094431517290252
Trained batch 468 in epoch 6, gen_loss = 1.0094371397358013, disc_loss = 0.00040890820597649425
Trained batch 469 in epoch 6, gen_loss = 1.009320089030773, disc_loss = 0.000408265848091105
Trained batch 470 in epoch 6, gen_loss = 1.0094674783907118, disc_loss = 0.00040757675235806776
Trained batch 471 in epoch 6, gen_loss = 1.0096779194171146, disc_loss = 0.00040690720544585865
Trained batch 472 in epoch 6, gen_loss = 1.0097669104693052, disc_loss = 0.0004062083222825537
Trained batch 473 in epoch 6, gen_loss = 1.0097130428889634, disc_loss = 0.0004055228219775263
Trained batch 474 in epoch 6, gen_loss = 1.0096188801213315, disc_loss = 0.0004048421001214975
Trained batch 475 in epoch 6, gen_loss = 1.0096555502474809, disc_loss = 0.0004041169792929265
Trained batch 476 in epoch 6, gen_loss = 1.0097916326182943, disc_loss = 0.0004033880308331469
Trained batch 477 in epoch 6, gen_loss = 1.0095701798734307, disc_loss = 0.000402696604971242
Trained batch 478 in epoch 6, gen_loss = 1.0094802445559015, disc_loss = 0.0004020576641565803
Trained batch 479 in epoch 6, gen_loss = 1.0094322089105845, disc_loss = 0.00040187409003920036
Trained batch 480 in epoch 6, gen_loss = 1.0092591053482896, disc_loss = 0.0004016959116943742
Trained batch 481 in epoch 6, gen_loss = 1.0093834918316964, disc_loss = 0.00040142168293932174
Trained batch 482 in epoch 6, gen_loss = 1.00927434105804, disc_loss = 0.0004008699304124873
Trained batch 483 in epoch 6, gen_loss = 1.0092483332827071, disc_loss = 0.0004001793160027736
Trained batch 484 in epoch 6, gen_loss = 1.0092903144580803, disc_loss = 0.00039964485178418344
Trained batch 485 in epoch 6, gen_loss = 1.0096771278008512, disc_loss = 0.0003995454646855374
Trained batch 486 in epoch 6, gen_loss = 1.0097623074568762, disc_loss = 0.00039952165586180655
Trained batch 487 in epoch 6, gen_loss = 1.0094970152026317, disc_loss = 0.0003994241861455223
Trained batch 488 in epoch 6, gen_loss = 1.0094832445214863, disc_loss = 0.00039912312061707767
Trained batch 489 in epoch 6, gen_loss = 1.0094288012202906, disc_loss = 0.00039859569084483714
Trained batch 490 in epoch 6, gen_loss = 1.0090823699160651, disc_loss = 0.0003981248020322978
Trained batch 491 in epoch 6, gen_loss = 1.0090109129262164, disc_loss = 0.00039776360734514475
Trained batch 492 in epoch 6, gen_loss = 1.009056348104264, disc_loss = 0.00039747519969149603
Trained batch 493 in epoch 6, gen_loss = 1.0092801994640335, disc_loss = 0.0003973014004609118
Trained batch 494 in epoch 6, gen_loss = 1.0091472433070945, disc_loss = 0.0003972670316491558
Trained batch 495 in epoch 6, gen_loss = 1.009258812233325, disc_loss = 0.0003972885531531515
Trained batch 496 in epoch 6, gen_loss = 1.0092004067461255, disc_loss = 0.0003972968479941207
Trained batch 497 in epoch 6, gen_loss = 1.0091224679027695, disc_loss = 0.0003972920405584477
Trained batch 498 in epoch 6, gen_loss = 1.0090004664384769, disc_loss = 0.0003973290117801389
Trained batch 499 in epoch 6, gen_loss = 1.008932572364807, disc_loss = 0.00039711805296246895
Trained batch 500 in epoch 6, gen_loss = 1.008937897320517, disc_loss = 0.0003967222598118302
Trained batch 501 in epoch 6, gen_loss = 1.0088337872370305, disc_loss = 0.000396184516826921
Trained batch 502 in epoch 6, gen_loss = 1.0087945885497107, disc_loss = 0.00039555408265029687
Trained batch 503 in epoch 6, gen_loss = 1.0086396286884944, disc_loss = 0.0003948984831367852
Trained batch 504 in epoch 6, gen_loss = 1.0086506619311795, disc_loss = 0.00039422786775872683
Trained batch 505 in epoch 6, gen_loss = 1.0087222131815823, disc_loss = 0.0003935831138136449
Trained batch 506 in epoch 6, gen_loss = 1.0086124770975207, disc_loss = 0.0003929888297080639
Trained batch 507 in epoch 6, gen_loss = 1.0084866026020425, disc_loss = 0.0003924068756374956
Trained batch 508 in epoch 6, gen_loss = 1.0084713825074068, disc_loss = 0.00039180988636968405
Trained batch 509 in epoch 6, gen_loss = 1.0084909578164418, disc_loss = 0.00039137320894880366
Trained batch 510 in epoch 6, gen_loss = 1.0083767580426135, disc_loss = 0.00039119191560370265
Trained batch 511 in epoch 6, gen_loss = 1.0084899846697226, disc_loss = 0.0003911711379771532
Trained batch 512 in epoch 6, gen_loss = 1.0086631083581414, disc_loss = 0.00039155731812418125
Trained batch 513 in epoch 6, gen_loss = 1.008599250928901, disc_loss = 0.00039234872425997864
Trained batch 514 in epoch 6, gen_loss = 1.0084123405438026, disc_loss = 0.0003930189686621657
Trained batch 515 in epoch 6, gen_loss = 1.0084318691907928, disc_loss = 0.00039345634007098177
Trained batch 516 in epoch 6, gen_loss = 1.0083970500145476, disc_loss = 0.0003936283517080833
Trained batch 517 in epoch 6, gen_loss = 1.008294444401752, disc_loss = 0.00039379989821486296
Trained batch 518 in epoch 6, gen_loss = 1.0083451664976073, disc_loss = 0.00039410785389350824
Trained batch 519 in epoch 6, gen_loss = 1.0083031114477379, disc_loss = 0.00039452219400398184
Trained batch 520 in epoch 6, gen_loss = 1.0084332091565782, disc_loss = 0.0003949116021736602
Trained batch 521 in epoch 6, gen_loss = 1.0083184470618822, disc_loss = 0.0003953589883000033
Trained batch 522 in epoch 6, gen_loss = 1.008321907506618, disc_loss = 0.000395574235922949
Trained batch 523 in epoch 6, gen_loss = 1.008229033410094, disc_loss = 0.000395657258973153
Trained batch 524 in epoch 6, gen_loss = 1.00830058937981, disc_loss = 0.0003956850826285691
Trained batch 525 in epoch 6, gen_loss = 1.0082675984603824, disc_loss = 0.0003956680385227237
Trained batch 526 in epoch 6, gen_loss = 1.008124506450921, disc_loss = 0.00039551156201109156
Trained batch 527 in epoch 6, gen_loss = 1.0080438688623183, disc_loss = 0.00039523020338740685
Trained batch 528 in epoch 6, gen_loss = 1.0081385303084476, disc_loss = 0.0003947457821570101
Trained batch 529 in epoch 6, gen_loss = 1.0080589605952208, disc_loss = 0.000394313144338326
Trained batch 530 in epoch 6, gen_loss = 1.0082196992893901, disc_loss = 0.0003943102562915369
Trained batch 531 in epoch 6, gen_loss = 1.0079597450960847, disc_loss = 0.0003942546078397392
Trained batch 532 in epoch 6, gen_loss = 1.007964498665722, disc_loss = 0.0003940753653651194
Trained batch 533 in epoch 6, gen_loss = 1.0077767788470908, disc_loss = 0.00039422460318842123
Trained batch 534 in epoch 6, gen_loss = 1.0077490100236697, disc_loss = 0.00039515312025040634
Trained batch 535 in epoch 6, gen_loss = 1.0076447684151024, disc_loss = 0.0003961593532704995
Trained batch 536 in epoch 6, gen_loss = 1.0074097787201737, disc_loss = 0.00039624631395879993
Trained batch 537 in epoch 6, gen_loss = 1.0072906222263676, disc_loss = 0.000395999471082475
Trained batch 538 in epoch 6, gen_loss = 1.0072922835987, disc_loss = 0.0003960229708207944
Trained batch 539 in epoch 6, gen_loss = 1.0071798065194377, disc_loss = 0.0003961966919262152
Trained batch 540 in epoch 6, gen_loss = 1.0073226680376612, disc_loss = 0.0003965525215613447
Trained batch 541 in epoch 6, gen_loss = 1.0070077258942312, disc_loss = 0.0003975441529167682
Trained batch 542 in epoch 6, gen_loss = 1.0070791902024003, disc_loss = 0.00039946083915801497
Trained batch 543 in epoch 6, gen_loss = 1.0071611219250105, disc_loss = 0.0004012952010591963
Trained batch 544 in epoch 6, gen_loss = 1.007192021444303, disc_loss = 0.0004019720079067565
Trained batch 545 in epoch 6, gen_loss = 1.0071599502048212, disc_loss = 0.00040181789326207754
Trained batch 546 in epoch 6, gen_loss = 1.0068500956190134, disc_loss = 0.00040183546853407543
Trained batch 547 in epoch 6, gen_loss = 1.0066482420385319, disc_loss = 0.0004022404906328472
Trained batch 548 in epoch 6, gen_loss = 1.006537586179153, disc_loss = 0.0004023933696604244
Trained batch 549 in epoch 6, gen_loss = 1.0064562379230153, disc_loss = 0.0004020676413413391
Trained batch 550 in epoch 6, gen_loss = 1.0064008343025042, disc_loss = 0.0004016803028478208
Trained batch 551 in epoch 6, gen_loss = 1.0065528835723365, disc_loss = 0.00040134706588118655
Trained batch 552 in epoch 6, gen_loss = 1.0064489187211283, disc_loss = 0.00040127203898621426
Trained batch 553 in epoch 6, gen_loss = 1.0065695823099639, disc_loss = 0.00040166752377927595
Trained batch 554 in epoch 6, gen_loss = 1.0065201416745917, disc_loss = 0.00040273988136480486
Trained batch 555 in epoch 6, gen_loss = 1.0064277914788227, disc_loss = 0.00040417273009925406
Trained batch 556 in epoch 6, gen_loss = 1.0063469656065935, disc_loss = 0.0004049388542501724
Trained batch 557 in epoch 6, gen_loss = 1.0063614591048182, disc_loss = 0.0004049396704568187
Trained batch 558 in epoch 6, gen_loss = 1.0063613177625352, disc_loss = 0.0004047065548595018
Trained batch 559 in epoch 6, gen_loss = 1.0063274251563208, disc_loss = 0.0004043469396232727
Trained batch 560 in epoch 6, gen_loss = 1.0062352043847136, disc_loss = 0.0004041122013529507
Trained batch 561 in epoch 6, gen_loss = 1.0062350305161867, disc_loss = 0.00040380870598700607
Trained batch 562 in epoch 6, gen_loss = 1.0060794456178723, disc_loss = 0.0004034706131217267
Trained batch 563 in epoch 6, gen_loss = 1.0059821245306773, disc_loss = 0.0004031916402277441
Trained batch 564 in epoch 6, gen_loss = 1.0056738387166926, disc_loss = 0.0004028911564027297
Trained batch 565 in epoch 6, gen_loss = 1.005341420851832, disc_loss = 0.00040262774248091607
Trained batch 566 in epoch 6, gen_loss = 1.0052107853233498, disc_loss = 0.0004022913380344094
Trained batch 567 in epoch 6, gen_loss = 1.004983281270719, disc_loss = 0.00040200435063858275
Trained batch 568 in epoch 6, gen_loss = 1.0049494721767982, disc_loss = 0.000401763594530315
Trained batch 569 in epoch 6, gen_loss = 1.0048234643643363, disc_loss = 0.00040134275117643963
Trained batch 570 in epoch 6, gen_loss = 1.004834972308939, disc_loss = 0.0004010341544225796
Trained batch 571 in epoch 6, gen_loss = 1.004660318677242, disc_loss = 0.000400747668749687
Trained batch 572 in epoch 6, gen_loss = 1.0047520212894128, disc_loss = 0.00040034985775818776
Trained batch 573 in epoch 6, gen_loss = 1.0047979279054582, disc_loss = 0.00039995016545570013
Trained batch 574 in epoch 6, gen_loss = 1.0049212388370348, disc_loss = 0.0003994861908722669
Trained batch 575 in epoch 6, gen_loss = 1.0046396090959508, disc_loss = 0.0003991859416348436
Trained batch 576 in epoch 6, gen_loss = 1.0047861386213186, disc_loss = 0.00039898712068261094
Trained batch 577 in epoch 6, gen_loss = 1.0048837671024164, disc_loss = 0.0003988189959065154
Trained batch 578 in epoch 6, gen_loss = 1.0049110929994798, disc_loss = 0.0003985031995486423
Trained batch 579 in epoch 6, gen_loss = 1.0049752859206036, disc_loss = 0.0003981232714381647
Trained batch 580 in epoch 6, gen_loss = 1.0047295288456901, disc_loss = 0.0003979028104010989
Trained batch 581 in epoch 6, gen_loss = 1.0048177993993987, disc_loss = 0.0003982602908272821
Trained batch 582 in epoch 6, gen_loss = 1.0045949287111926, disc_loss = 0.0003990194093121302
Trained batch 583 in epoch 6, gen_loss = 1.0046570183683747, disc_loss = 0.00040031121738736634
Trained batch 584 in epoch 6, gen_loss = 1.004727904511313, disc_loss = 0.0004011660260068746
Trained batch 585 in epoch 6, gen_loss = 1.0047075008979836, disc_loss = 0.00040147559015627047
Trained batch 586 in epoch 6, gen_loss = 1.004562610560422, disc_loss = 0.0004015066199840778
Trained batch 587 in epoch 6, gen_loss = 1.0044770568203765, disc_loss = 0.00040140334323926063
Trained batch 588 in epoch 6, gen_loss = 1.0045350817346816, disc_loss = 0.00040119536485284224
Trained batch 589 in epoch 6, gen_loss = 1.0045975663904416, disc_loss = 0.0004011085059126776
Trained batch 590 in epoch 6, gen_loss = 1.0045155145593505, disc_loss = 0.00040103031641271046
Trained batch 591 in epoch 6, gen_loss = 1.0045335461964477, disc_loss = 0.0004008863031993167
Trained batch 592 in epoch 6, gen_loss = 1.004524775138392, disc_loss = 0.00040088565538175605
Trained batch 593 in epoch 6, gen_loss = 1.0045178751351456, disc_loss = 0.00040089467853763976
Trained batch 594 in epoch 6, gen_loss = 1.0045874387276272, disc_loss = 0.0004009450362220469
Trained batch 595 in epoch 6, gen_loss = 1.0045491987026778, disc_loss = 0.0004008583220650892
Trained batch 596 in epoch 6, gen_loss = 1.0044554243335373, disc_loss = 0.0004006282167943659
Trained batch 597 in epoch 6, gen_loss = 1.0046219471904347, disc_loss = 0.000400264672393814
Trained batch 598 in epoch 6, gen_loss = 1.0047536207757928, disc_loss = 0.00039987562368864907
Trained batch 599 in epoch 6, gen_loss = 1.0048376302917799, disc_loss = 0.000399670284629489
Trained batch 600 in epoch 6, gen_loss = 1.005078940443112, disc_loss = 0.00039973768481935145
Trained batch 601 in epoch 6, gen_loss = 1.0051162824084197, disc_loss = 0.00039972680060237805
Trained batch 602 in epoch 6, gen_loss = 1.0050518627388165, disc_loss = 0.00039955752035471644
Trained batch 603 in epoch 6, gen_loss = 1.0050828966083905, disc_loss = 0.00039928021819742444
Trained batch 604 in epoch 6, gen_loss = 1.0051246083472385, disc_loss = 0.0003989665855389966
Trained batch 605 in epoch 6, gen_loss = 1.0051333316088509, disc_loss = 0.00039859825540921825
Trained batch 606 in epoch 6, gen_loss = 1.0049993754218791, disc_loss = 0.00039814253566820016
Trained batch 607 in epoch 6, gen_loss = 1.004680690404616, disc_loss = 0.00039771494906697054
Trained batch 608 in epoch 6, gen_loss = 1.004769743565464, disc_loss = 0.0003974323017171535
Trained batch 609 in epoch 6, gen_loss = 1.0047830288527442, disc_loss = 0.00039733893081276737
Trained batch 610 in epoch 6, gen_loss = 1.004747967282996, disc_loss = 0.00039730768436373556
Trained batch 611 in epoch 6, gen_loss = 1.0046039587921567, disc_loss = 0.00039728193717095253
Trained batch 612 in epoch 6, gen_loss = 1.004620442577132, disc_loss = 0.00039720448753771827
Trained batch 613 in epoch 6, gen_loss = 1.0045381530100048, disc_loss = 0.0003969396450851645
Trained batch 614 in epoch 6, gen_loss = 1.0043128350885904, disc_loss = 0.0003965854817387133
Trained batch 615 in epoch 6, gen_loss = 1.0044217473500734, disc_loss = 0.00039635399065587846
Trained batch 616 in epoch 6, gen_loss = 1.0045062092946453, disc_loss = 0.0003963023765257717
Trained batch 617 in epoch 6, gen_loss = 1.0045771861153514, disc_loss = 0.0003963014683274599
Trained batch 618 in epoch 6, gen_loss = 1.0047190096921412, disc_loss = 0.00039610152695091405
Trained batch 619 in epoch 6, gen_loss = 1.004661729162739, disc_loss = 0.00039571903634491573
Trained batch 620 in epoch 6, gen_loss = 1.0048242361073332, disc_loss = 0.00039527421705314183
Trained batch 621 in epoch 6, gen_loss = 1.0046200442735789, disc_loss = 0.00039484020591561137
Trained batch 622 in epoch 6, gen_loss = 1.0046462376465959, disc_loss = 0.00039445255624653955
Trained batch 623 in epoch 6, gen_loss = 1.0045803017341173, disc_loss = 0.00039403458328170253
Trained batch 624 in epoch 6, gen_loss = 1.0044042728424072, disc_loss = 0.0003935632690321654
Trained batch 625 in epoch 6, gen_loss = 1.0044657867937423, disc_loss = 0.00039310995703453375
Trained batch 626 in epoch 6, gen_loss = 1.0044045587095538, disc_loss = 0.00039268706272257064
Trained batch 627 in epoch 6, gen_loss = 1.0041801178721106, disc_loss = 0.0003922607892415906
Trained batch 628 in epoch 6, gen_loss = 1.0039660042723335, disc_loss = 0.00039187340476113004
Trained batch 629 in epoch 6, gen_loss = 1.0040781595404187, disc_loss = 0.00039154266304981393
Trained batch 630 in epoch 6, gen_loss = 1.0041500610519325, disc_loss = 0.00039117098137673225
Trained batch 631 in epoch 6, gen_loss = 1.0040696120903463, disc_loss = 0.0003907266445591481
Trained batch 632 in epoch 6, gen_loss = 1.0039046747612916, disc_loss = 0.00039033000651016126
Trained batch 633 in epoch 6, gen_loss = 1.0038147917493285, disc_loss = 0.00038989688168022393
Trained batch 634 in epoch 6, gen_loss = 1.0037144720085023, disc_loss = 0.0003894103181435668
Trained batch 635 in epoch 6, gen_loss = 1.0036683681438554, disc_loss = 0.00038892077787727286
Trained batch 636 in epoch 6, gen_loss = 1.0036377430523584, disc_loss = 0.0003885024851906293
Trained batch 637 in epoch 6, gen_loss = 1.0037680855925928, disc_loss = 0.00038810178459962086
Trained batch 638 in epoch 6, gen_loss = 1.003779305445383, disc_loss = 0.0003876081327362101
Trained batch 639 in epoch 6, gen_loss = 1.0036626474000514, disc_loss = 0.000387165492099939
Trained batch 640 in epoch 6, gen_loss = 1.0036168641493584, disc_loss = 0.0003867757765084248
Trained batch 641 in epoch 6, gen_loss = 1.0036369812822787, disc_loss = 0.0003864290480474931
Trained batch 642 in epoch 6, gen_loss = 1.0035784000742305, disc_loss = 0.000386241145842889
Trained batch 643 in epoch 6, gen_loss = 1.0036267890878345, disc_loss = 0.0003860536553192506
Trained batch 644 in epoch 6, gen_loss = 1.0035331066264663, disc_loss = 0.000385789046898329
Trained batch 645 in epoch 6, gen_loss = 1.0034981650464676, disc_loss = 0.00038548602873105165
Trained batch 646 in epoch 6, gen_loss = 1.003555360127822, disc_loss = 0.0003852259008719664
Trained batch 647 in epoch 6, gen_loss = 1.003511588330622, disc_loss = 0.0003850440999249932
Trained batch 648 in epoch 6, gen_loss = 1.0032961937973421, disc_loss = 0.00038489987459118036
Trained batch 649 in epoch 6, gen_loss = 1.0032988069607662, disc_loss = 0.0003849098712201409
Trained batch 650 in epoch 6, gen_loss = 1.0032609032778879, disc_loss = 0.00038482325229843503
Trained batch 651 in epoch 6, gen_loss = 1.0031884956213595, disc_loss = 0.00038470093451147154
Trained batch 652 in epoch 6, gen_loss = 1.0032526920984568, disc_loss = 0.0003845865119124369
Trained batch 653 in epoch 6, gen_loss = 1.0032022586291718, disc_loss = 0.00038447674842106695
Trained batch 654 in epoch 6, gen_loss = 1.0032272930363662, disc_loss = 0.00038458975399657726
Trained batch 655 in epoch 6, gen_loss = 1.0033307053693912, disc_loss = 0.00038497264002705
Trained batch 656 in epoch 6, gen_loss = 1.0033008448065144, disc_loss = 0.00038511572853593677
Trained batch 657 in epoch 6, gen_loss = 1.0030181868098065, disc_loss = 0.00038534616064915425
Trained batch 658 in epoch 6, gen_loss = 1.003092040422292, disc_loss = 0.0003854002935414581
Trained batch 659 in epoch 6, gen_loss = 1.0031546795006954, disc_loss = 0.0003856263423200069
Trained batch 660 in epoch 6, gen_loss = 1.003218309421222, disc_loss = 0.00038630086378010876
Trained batch 661 in epoch 6, gen_loss = 1.0031266957971625, disc_loss = 0.00038663620863901523
Trained batch 662 in epoch 6, gen_loss = 1.0029196392177278, disc_loss = 0.0003866950747149443
Trained batch 663 in epoch 6, gen_loss = 1.0029361835086201, disc_loss = 0.00038697955301632834
Trained batch 664 in epoch 6, gen_loss = 1.0029245511929792, disc_loss = 0.0003870150379296497
Trained batch 665 in epoch 6, gen_loss = 1.0028409960570637, disc_loss = 0.0003871514001495363
Trained batch 666 in epoch 6, gen_loss = 1.0026509202402392, disc_loss = 0.00038712827064090995
Trained batch 667 in epoch 6, gen_loss = 1.0026771515429378, disc_loss = 0.0003870112880517019
Trained batch 668 in epoch 6, gen_loss = 1.0028252063488925, disc_loss = 0.00038694251167178305
Trained batch 669 in epoch 6, gen_loss = 1.0027037022718743, disc_loss = 0.0003867719368379278
Trained batch 670 in epoch 6, gen_loss = 1.0027836708660098, disc_loss = 0.0003865581127713801
Trained batch 671 in epoch 6, gen_loss = 1.0028120793756985, disc_loss = 0.0003862648416088632
Trained batch 672 in epoch 6, gen_loss = 1.0028890373093944, disc_loss = 0.0003859963103646051
Trained batch 673 in epoch 6, gen_loss = 1.0027867829764279, disc_loss = 0.00038580532333281964
Trained batch 674 in epoch 6, gen_loss = 1.0027066219294514, disc_loss = 0.00038576194155245534
Trained batch 675 in epoch 6, gen_loss = 1.002711125467656, disc_loss = 0.0003855374147833949
Trained batch 676 in epoch 6, gen_loss = 1.0025161352432286, disc_loss = 0.00038514142079226207
Trained batch 677 in epoch 6, gen_loss = 1.002570770395189, disc_loss = 0.00038484962714228514
Trained batch 678 in epoch 6, gen_loss = 1.002625282365549, disc_loss = 0.0003845347022225042
Trained batch 679 in epoch 6, gen_loss = 1.0024918842841597, disc_loss = 0.0003842473534592393
Trained batch 680 in epoch 6, gen_loss = 1.002293134400848, disc_loss = 0.0003840433738772038
Trained batch 681 in epoch 6, gen_loss = 1.002276277437238, disc_loss = 0.0003838764044402073
Trained batch 682 in epoch 6, gen_loss = 1.0021207953092819, disc_loss = 0.0003837638329621643
Trained batch 683 in epoch 6, gen_loss = 1.0019941247171826, disc_loss = 0.00038381297865633005
Trained batch 684 in epoch 6, gen_loss = 1.0021071821233651, disc_loss = 0.0003839684248265443
Trained batch 685 in epoch 6, gen_loss = 1.0020737211836324, disc_loss = 0.0003838097914874672
Trained batch 686 in epoch 6, gen_loss = 1.0020229873698872, disc_loss = 0.0003836340145179981
Trained batch 687 in epoch 6, gen_loss = 1.002173946000809, disc_loss = 0.0003834807322417937
Trained batch 688 in epoch 6, gen_loss = 1.0021641090058104, disc_loss = 0.0003832835979476343
Trained batch 689 in epoch 6, gen_loss = 1.002109336161959, disc_loss = 0.00038304723504183313
Trained batch 690 in epoch 6, gen_loss = 1.0020563249650118, disc_loss = 0.00038280767855861504
Trained batch 691 in epoch 6, gen_loss = 1.0020697277922161, disc_loss = 0.0003826766903903315
Trained batch 692 in epoch 6, gen_loss = 1.002247592501482, disc_loss = 0.0003823632239532915
Trained batch 693 in epoch 6, gen_loss = 1.0022500086071169, disc_loss = 0.0003820950656696337
Trained batch 694 in epoch 6, gen_loss = 1.0023173492589443, disc_loss = 0.00038182569893618055
Trained batch 695 in epoch 6, gen_loss = 1.0024297781202984, disc_loss = 0.00038142207903411483
Trained batch 696 in epoch 6, gen_loss = 1.0022195858969065, disc_loss = 0.0003810002602938458
Trained batch 697 in epoch 6, gen_loss = 1.0022854272991333, disc_loss = 0.0003807199641271297
Trained batch 698 in epoch 6, gen_loss = 1.0023240798362165, disc_loss = 0.00038044511170099186
Trained batch 699 in epoch 6, gen_loss = 1.0022188161952155, disc_loss = 0.0003802043144034022
Trained batch 700 in epoch 6, gen_loss = 1.0022238055071375, disc_loss = 0.0003800233102182043
Trained batch 701 in epoch 6, gen_loss = 1.0022471573447909, disc_loss = 0.0003800719589908061
Trained batch 702 in epoch 6, gen_loss = 1.0021317177273301, disc_loss = 0.0003802985001819415
Trained batch 703 in epoch 6, gen_loss = 1.0022800563919274, disc_loss = 0.0003803657358606539
Trained batch 704 in epoch 6, gen_loss = 1.0021623368804335, disc_loss = 0.0003801259028078024
Trained batch 705 in epoch 6, gen_loss = 1.0022562878158883, disc_loss = 0.0003797585308523262
Trained batch 706 in epoch 6, gen_loss = 1.0021967160313943, disc_loss = 0.0003793870588117266
Trained batch 707 in epoch 6, gen_loss = 1.0022210232113715, disc_loss = 0.00037905328757154933
Trained batch 708 in epoch 6, gen_loss = 1.0021643283000619, disc_loss = 0.0003786741423548517
Trained batch 709 in epoch 6, gen_loss = 1.002230572112849, disc_loss = 0.0003782718052758022
Trained batch 710 in epoch 6, gen_loss = 1.0023824190288657, disc_loss = 0.0003779128000198152
Trained batch 711 in epoch 6, gen_loss = 1.0025799971785438, disc_loss = 0.00037751275168589884
Trained batch 712 in epoch 6, gen_loss = 1.0024375204117066, disc_loss = 0.00037710706478534696
Trained batch 713 in epoch 6, gen_loss = 1.0024644053783738, disc_loss = 0.00037670257221556825
Trained batch 714 in epoch 6, gen_loss = 1.0025284177773481, disc_loss = 0.00037624673702969
Trained batch 715 in epoch 6, gen_loss = 1.0023438816463481, disc_loss = 0.00037577820985563206
Trained batch 716 in epoch 6, gen_loss = 1.002350259608637, disc_loss = 0.00037530594104593273
Trained batch 717 in epoch 6, gen_loss = 1.0023448748674897, disc_loss = 0.0003749042638634026
Trained batch 718 in epoch 6, gen_loss = 1.002372757532998, disc_loss = 0.00037469937253594614
Trained batch 719 in epoch 6, gen_loss = 1.0023074328899384, disc_loss = 0.0003746093285826646
Trained batch 720 in epoch 6, gen_loss = 1.0024072927178689, disc_loss = 0.0003746786716468157
Trained batch 721 in epoch 6, gen_loss = 1.0023239215325122, disc_loss = 0.0003748294018709873
Trained batch 722 in epoch 6, gen_loss = 1.0022683549224094, disc_loss = 0.0003749475215509277
Trained batch 723 in epoch 6, gen_loss = 1.0022082822757532, disc_loss = 0.0003749170950340967
Trained batch 724 in epoch 6, gen_loss = 1.0021174716949464, disc_loss = 0.00037471966067798723
Trained batch 725 in epoch 6, gen_loss = 1.0021161487936645, disc_loss = 0.00037446487177543876
Trained batch 726 in epoch 6, gen_loss = 1.0022697765200796, disc_loss = 0.0003740979299195283
Trained batch 727 in epoch 6, gen_loss = 1.0022874079890303, disc_loss = 0.00037381467541058806
Trained batch 728 in epoch 6, gen_loss = 1.0021894766306518, disc_loss = 0.0003737513211845859
Trained batch 729 in epoch 6, gen_loss = 1.0021983380187047, disc_loss = 0.00037373033909255494
Trained batch 730 in epoch 6, gen_loss = 1.0023127671957994, disc_loss = 0.0003737615132894289
Trained batch 731 in epoch 6, gen_loss = 1.0022546370498469, disc_loss = 0.00037409852786089677
Trained batch 732 in epoch 6, gen_loss = 1.0021823189268333, disc_loss = 0.0003750321238083237
Trained batch 733 in epoch 6, gen_loss = 1.002078181716337, disc_loss = 0.00037571192593923586
Trained batch 734 in epoch 6, gen_loss = 1.0021675889994823, disc_loss = 0.0003763008778837595
Trained batch 735 in epoch 6, gen_loss = 1.0020997935663098, disc_loss = 0.0003767044990690524
Trained batch 736 in epoch 6, gen_loss = 1.0019568902828315, disc_loss = 0.00037678391860345134
Trained batch 737 in epoch 6, gen_loss = 1.001823550721171, disc_loss = 0.00037661298980128284
Trained batch 738 in epoch 6, gen_loss = 1.0016634078729136, disc_loss = 0.00037655469400989217
Trained batch 739 in epoch 6, gen_loss = 1.0015920225832913, disc_loss = 0.0003767517204618638
Trained batch 740 in epoch 6, gen_loss = 1.001589945372943, disc_loss = 0.0003770690961798176
Trained batch 741 in epoch 6, gen_loss = 1.0015958500197635, disc_loss = 0.00037724941411963883
Trained batch 742 in epoch 6, gen_loss = 1.001473969678378, disc_loss = 0.00037710487720523495
Trained batch 743 in epoch 6, gen_loss = 1.001361553867658, disc_loss = 0.00037685635650984385
Trained batch 744 in epoch 6, gen_loss = 1.0013719024274172, disc_loss = 0.00037659537785974856
Trained batch 745 in epoch 6, gen_loss = 1.0013861141639484, disc_loss = 0.00037636075213576644
Trained batch 746 in epoch 6, gen_loss = 1.001259348638246, disc_loss = 0.0003762849298402199
Trained batch 747 in epoch 6, gen_loss = 1.0012902630204186, disc_loss = 0.0003763406331810673
Trained batch 748 in epoch 6, gen_loss = 1.0012734186187764, disc_loss = 0.0003762420349330775
Trained batch 749 in epoch 6, gen_loss = 1.0012032461166382, disc_loss = 0.00037607979350044236
Trained batch 750 in epoch 6, gen_loss = 1.0010904124510114, disc_loss = 0.00037593618166399965
Trained batch 751 in epoch 6, gen_loss = 1.0010893214890297, disc_loss = 0.0003758473229152785
Trained batch 752 in epoch 6, gen_loss = 1.0012328993593396, disc_loss = 0.0003759354026363943
Trained batch 753 in epoch 6, gen_loss = 1.0011685538038968, disc_loss = 0.00037597048046893845
Trained batch 754 in epoch 6, gen_loss = 1.000967204097091, disc_loss = 0.000376346915296706
Trained batch 755 in epoch 6, gen_loss = 1.0010655130501147, disc_loss = 0.00037673831771614636
Trained batch 756 in epoch 6, gen_loss = 1.0011177525180177, disc_loss = 0.000376883153523181
Trained batch 757 in epoch 6, gen_loss = 1.0011438399474666, disc_loss = 0.0003770619280425365
Trained batch 758 in epoch 6, gen_loss = 1.001190494093185, disc_loss = 0.00037730546884993504
Trained batch 759 in epoch 6, gen_loss = 1.0012822514301851, disc_loss = 0.0003776918216173822
Trained batch 760 in epoch 6, gen_loss = 1.001256860430388, disc_loss = 0.00037805840282725584
Trained batch 761 in epoch 6, gen_loss = 1.00134430571491, disc_loss = 0.00037837750693295655
Trained batch 762 in epoch 6, gen_loss = 1.0013328297735042, disc_loss = 0.0003788489300866662
Trained batch 763 in epoch 6, gen_loss = 1.0013356315683943, disc_loss = 0.0003795064856470529
Trained batch 764 in epoch 6, gen_loss = 1.0012534692396526, disc_loss = 0.0003801313300666116
Trained batch 765 in epoch 6, gen_loss = 1.0013528588390848, disc_loss = 0.00038056062231653864
Trained batch 766 in epoch 6, gen_loss = 1.0014854148127421, disc_loss = 0.00038104432109489734
Trained batch 767 in epoch 6, gen_loss = 1.0015452944207937, disc_loss = 0.0003811578544864839
Trained batch 768 in epoch 6, gen_loss = 1.0016005263216938, disc_loss = 0.00038111339404611175
Trained batch 769 in epoch 6, gen_loss = 1.0017114479046363, disc_loss = 0.0003810130149912612
Trained batch 770 in epoch 6, gen_loss = 1.001677401257551, disc_loss = 0.00038087675868943196
Trained batch 771 in epoch 6, gen_loss = 1.0018013909536323, disc_loss = 0.0003810608355244975
Trained batch 772 in epoch 6, gen_loss = 1.001724988492001, disc_loss = 0.0003810503276256332
Trained batch 773 in epoch 6, gen_loss = 1.001720315803237, disc_loss = 0.00038141970977326883
Trained batch 774 in epoch 6, gen_loss = 1.0018092882248664, disc_loss = 0.0003816318007856382
Trained batch 775 in epoch 6, gen_loss = 1.0018012115789443, disc_loss = 0.0003815219885893253
Trained batch 776 in epoch 6, gen_loss = 1.0016987842329066, disc_loss = 0.000381494741946223
Trained batch 777 in epoch 6, gen_loss = 1.0017011303521675, disc_loss = 0.00038136801056886017
Trained batch 778 in epoch 6, gen_loss = 1.0017652364689211, disc_loss = 0.00038108829439911947
Trained batch 779 in epoch 6, gen_loss = 1.0016207294586377, disc_loss = 0.00038097626054364714
Trained batch 780 in epoch 6, gen_loss = 1.0014578945047572, disc_loss = 0.00038099421363324077
Trained batch 781 in epoch 6, gen_loss = 1.0013974886721053, disc_loss = 0.0003807586318960421
Trained batch 782 in epoch 6, gen_loss = 1.0014200533334627, disc_loss = 0.0003805134840328428
Trained batch 783 in epoch 6, gen_loss = 1.0013962495996027, disc_loss = 0.0003802949859210476
Trained batch 784 in epoch 6, gen_loss = 1.0015074944040578, disc_loss = 0.0003801269914480712
Trained batch 785 in epoch 6, gen_loss = 1.0015376765309398, disc_loss = 0.00037988347273842644
Trained batch 786 in epoch 6, gen_loss = 1.0016059424098596, disc_loss = 0.000379836281460393
Trained batch 787 in epoch 6, gen_loss = 1.001747333004995, disc_loss = 0.000379660015985487
Trained batch 788 in epoch 6, gen_loss = 1.001778302083904, disc_loss = 0.00037967402865660626
Trained batch 789 in epoch 6, gen_loss = 1.001816392095783, disc_loss = 0.0003798294845090581
Trained batch 790 in epoch 6, gen_loss = 1.0019010799723842, disc_loss = 0.00037979448994144937
Trained batch 791 in epoch 6, gen_loss = 1.0018314646199495, disc_loss = 0.00037976477477224597
Trained batch 792 in epoch 6, gen_loss = 1.0018581549577124, disc_loss = 0.0003797053763388423
Trained batch 793 in epoch 6, gen_loss = 1.0019551869153376, disc_loss = 0.0003795851234758114
Trained batch 794 in epoch 6, gen_loss = 1.0019257861113398, disc_loss = 0.0003794209536543166
Trained batch 795 in epoch 6, gen_loss = 1.0017395942804201, disc_loss = 0.000379217456392138
Trained batch 796 in epoch 6, gen_loss = 1.0016259068676938, disc_loss = 0.0003789877014030826
Trained batch 797 in epoch 6, gen_loss = 1.0016407301850188, disc_loss = 0.00037873784851016304
Trained batch 798 in epoch 6, gen_loss = 1.0015469553771992, disc_loss = 0.00037854404856605447
Trained batch 799 in epoch 6, gen_loss = 1.001673093289137, disc_loss = 0.0003785469859258228
Trained batch 800 in epoch 6, gen_loss = 1.001742393485318, disc_loss = 0.0003786461331058464
Trained batch 801 in epoch 6, gen_loss = 1.0016911764097334, disc_loss = 0.0003786305932183602
Trained batch 802 in epoch 6, gen_loss = 1.0017621913555996, disc_loss = 0.0003783465228122146
Trained batch 803 in epoch 6, gen_loss = 1.001899071742053, disc_loss = 0.00037818534686569666
Trained batch 804 in epoch 6, gen_loss = 1.0018880269542243, disc_loss = 0.00037818959307577026
Trained batch 805 in epoch 6, gen_loss = 1.0019699179800805, disc_loss = 0.00037824365847907113
Trained batch 806 in epoch 6, gen_loss = 1.0020430215081613, disc_loss = 0.0003782117801142901
Trained batch 807 in epoch 6, gen_loss = 1.0020539019957628, disc_loss = 0.000378222006155297
Trained batch 808 in epoch 6, gen_loss = 1.0020314470504506, disc_loss = 0.0003783718983945883
Trained batch 809 in epoch 6, gen_loss = 1.0020072890652552, disc_loss = 0.0003784980062823987
Trained batch 810 in epoch 6, gen_loss = 1.0019670227305957, disc_loss = 0.00037853622461905855
Trained batch 811 in epoch 6, gen_loss = 1.0019723421393945, disc_loss = 0.00037858294248051185
Trained batch 812 in epoch 6, gen_loss = 1.0019604824712502, disc_loss = 0.00037859447637311847
Trained batch 813 in epoch 6, gen_loss = 1.0019810204863255, disc_loss = 0.00037850958303264795
Trained batch 814 in epoch 6, gen_loss = 1.001880310137579, disc_loss = 0.00037831697099934263
Trained batch 815 in epoch 6, gen_loss = 1.0017318484537743, disc_loss = 0.00037805162477364804
Trained batch 816 in epoch 6, gen_loss = 1.0016657925294108, disc_loss = 0.00037779069308441893
Trained batch 817 in epoch 6, gen_loss = 1.001730818765962, disc_loss = 0.0003776745710291454
Trained batch 818 in epoch 6, gen_loss = 1.0017027348389118, disc_loss = 0.000377523885344666
Trained batch 819 in epoch 6, gen_loss = 1.001712290833636, disc_loss = 0.00037758027174720886
Trained batch 820 in epoch 6, gen_loss = 1.0016500346553165, disc_loss = 0.0003784583454661882
Trained batch 821 in epoch 6, gen_loss = 1.001686916516645, disc_loss = 0.00037915827149606434
Trained batch 822 in epoch 6, gen_loss = 1.0015531944185676, disc_loss = 0.00037985265907936305
Trained batch 823 in epoch 6, gen_loss = 1.0014996248686199, disc_loss = 0.00038118912823723874
Trained batch 824 in epoch 6, gen_loss = 1.0014039137146689, disc_loss = 0.00038263793615359726
Trained batch 825 in epoch 6, gen_loss = 1.0014602604703233, disc_loss = 0.00038385186793715167
Trained batch 826 in epoch 6, gen_loss = 1.0014438353109534, disc_loss = 0.00038460546043103064
Trained batch 827 in epoch 6, gen_loss = 1.0014726197805957, disc_loss = 0.00038525088331994633
Trained batch 828 in epoch 6, gen_loss = 1.0013961908469298, disc_loss = 0.0003861527212372567
Trained batch 829 in epoch 6, gen_loss = 1.001444983051484, disc_loss = 0.00038700914140583816
Trained batch 830 in epoch 6, gen_loss = 1.001348696173887, disc_loss = 0.00038741039550151124
Trained batch 831 in epoch 6, gen_loss = 1.0013379498313253, disc_loss = 0.0003876105002929692
Trained batch 832 in epoch 6, gen_loss = 1.0013295021377693, disc_loss = 0.0003878281130440411
Trained batch 833 in epoch 6, gen_loss = 1.0011970816756324, disc_loss = 0.0003880300453130998
Trained batch 834 in epoch 6, gen_loss = 1.0012487205916536, disc_loss = 0.0003882132122451007
Trained batch 835 in epoch 6, gen_loss = 1.0012333125018618, disc_loss = 0.00038832380609051686
Trained batch 836 in epoch 6, gen_loss = 1.0012576198350003, disc_loss = 0.0003884108779228194
Trained batch 837 in epoch 6, gen_loss = 1.0010664585382103, disc_loss = 0.00038864512950908376
Trained batch 838 in epoch 6, gen_loss = 1.0011429016581592, disc_loss = 0.00038908846469067233
Trained batch 839 in epoch 6, gen_loss = 1.0010948951755252, disc_loss = 0.0003894935947972131
Trained batch 840 in epoch 6, gen_loss = 1.0010660049039317, disc_loss = 0.0003896361922151528
Trained batch 841 in epoch 6, gen_loss = 1.000920871232864, disc_loss = 0.0003896581509991258
Trained batch 842 in epoch 6, gen_loss = 1.0010089114891676, disc_loss = 0.00038959870754326427
Trained batch 843 in epoch 6, gen_loss = 1.001107977606109, disc_loss = 0.00038946833832579654
Trained batch 844 in epoch 6, gen_loss = 1.00114916132752, disc_loss = 0.00038919010394292104
Trained batch 845 in epoch 6, gen_loss = 1.001289511262384, disc_loss = 0.00038888285395689446
Trained batch 846 in epoch 6, gen_loss = 1.001158371585319, disc_loss = 0.00038856406039552163
Trained batch 847 in epoch 6, gen_loss = 1.0012220946966477, disc_loss = 0.0003882684042275527
Trained batch 848 in epoch 6, gen_loss = 1.0013951122128921, disc_loss = 0.0003879913536631746
Trained batch 849 in epoch 6, gen_loss = 1.0013256583494299, disc_loss = 0.0003876528979205485
Trained batch 850 in epoch 6, gen_loss = 1.0014866928096102, disc_loss = 0.0003874638582938271
Trained batch 851 in epoch 6, gen_loss = 1.0014809526048356, disc_loss = 0.0003874126754231719
Trained batch 852 in epoch 6, gen_loss = 1.0015019861083796, disc_loss = 0.0003872778237573019
Trained batch 853 in epoch 6, gen_loss = 1.001472804390016, disc_loss = 0.0003871104124345202
Trained batch 854 in epoch 6, gen_loss = 1.0015989363542077, disc_loss = 0.000387039436787341
Trained batch 855 in epoch 6, gen_loss = 1.0016194729604453, disc_loss = 0.00038707659052017554
Trained batch 856 in epoch 6, gen_loss = 1.0016804005746385, disc_loss = 0.0003871859908890799
Trained batch 857 in epoch 6, gen_loss = 1.0015514769476332, disc_loss = 0.00038759802401518053
Trained batch 858 in epoch 6, gen_loss = 1.0015331855752831, disc_loss = 0.00038832109534400256
Trained batch 859 in epoch 6, gen_loss = 1.0015388611444207, disc_loss = 0.00038909144303372244
Trained batch 860 in epoch 6, gen_loss = 1.0014363451840294, disc_loss = 0.00038994961973263083
Trained batch 861 in epoch 6, gen_loss = 1.0014423447944172, disc_loss = 0.0003903301512722097
Trained batch 862 in epoch 6, gen_loss = 1.0014713838920948, disc_loss = 0.0003902247877885479
Trained batch 863 in epoch 6, gen_loss = 1.0013332753269761, disc_loss = 0.000390270444031389
Trained batch 864 in epoch 6, gen_loss = 1.0013676008048085, disc_loss = 0.00039056176151908704
Trained batch 865 in epoch 6, gen_loss = 1.0013597604859508, disc_loss = 0.0003908744716938377
Trained batch 866 in epoch 6, gen_loss = 1.0013398228357133, disc_loss = 0.00039100812532581985
Trained batch 867 in epoch 6, gen_loss = 1.0011963900607852, disc_loss = 0.0003910328135256023
Trained batch 868 in epoch 6, gen_loss = 1.0012621819218503, disc_loss = 0.00039107169138131125
Trained batch 869 in epoch 6, gen_loss = 1.001175407842658, disc_loss = 0.0003911047385801125
Trained batch 870 in epoch 6, gen_loss = 1.0010038698444959, disc_loss = 0.00039123145249810834
Trained batch 871 in epoch 6, gen_loss = 1.0010834435394051, disc_loss = 0.0003912817132329836
Trained batch 872 in epoch 6, gen_loss = 1.0010006945977097, disc_loss = 0.0003911013255817061
Trained batch 873 in epoch 6, gen_loss = 1.0010226462334735, disc_loss = 0.00039093187964352584
Trained batch 874 in epoch 6, gen_loss = 1.0010280101639883, disc_loss = 0.0003910172211513522
Trained batch 875 in epoch 6, gen_loss = 1.001117686090404, disc_loss = 0.0003916501559262426
Trained batch 876 in epoch 6, gen_loss = 1.0010860939526096, disc_loss = 0.00039247287120612335
Trained batch 877 in epoch 6, gen_loss = 1.0010801215649738, disc_loss = 0.0003929198291663524
Trained batch 878 in epoch 6, gen_loss = 1.001210864222226, disc_loss = 0.0003929243378254913
Trained batch 879 in epoch 6, gen_loss = 1.0012505884874952, disc_loss = 0.0003927819589948327
Trained batch 880 in epoch 6, gen_loss = 1.0013057504961358, disc_loss = 0.0003925000285590292
Trained batch 881 in epoch 6, gen_loss = 1.0012595983319272, disc_loss = 0.00039216528077918824
Trained batch 882 in epoch 6, gen_loss = 1.001220124494179, disc_loss = 0.00039181808109827246
Trained batch 883 in epoch 6, gen_loss = 1.0013961065139165, disc_loss = 0.0003914909077459871
Trained batch 884 in epoch 6, gen_loss = 1.001430446010525, disc_loss = 0.00039114047453615755
Trained batch 885 in epoch 6, gen_loss = 1.0014393583915573, disc_loss = 0.00039079971627513463
Trained batch 886 in epoch 6, gen_loss = 1.001367649405758, disc_loss = 0.0003904813002562872
Trained batch 887 in epoch 6, gen_loss = 1.001331326056708, disc_loss = 0.0003901950793463969
Trained batch 888 in epoch 6, gen_loss = 1.001341890229417, disc_loss = 0.0003900030108651079
Trained batch 889 in epoch 6, gen_loss = 1.0013096409567286, disc_loss = 0.000390061367040054
Trained batch 890 in epoch 6, gen_loss = 1.0011803045551115, disc_loss = 0.00039027954024605963
Trained batch 891 in epoch 6, gen_loss = 1.001077371261045, disc_loss = 0.00039065997295964256
Trained batch 892 in epoch 6, gen_loss = 1.0011116197501693, disc_loss = 0.00039110780795649595
Trained batch 893 in epoch 6, gen_loss = 1.0010367785257515, disc_loss = 0.00039127092568215656
Trained batch 894 in epoch 6, gen_loss = 1.0011197443114979, disc_loss = 0.0003913742915410796
Trained batch 895 in epoch 6, gen_loss = 1.0011133886873722, disc_loss = 0.0003916360137696172
Trained batch 896 in epoch 6, gen_loss = 1.0010294556750634, disc_loss = 0.0003917365856744791
Trained batch 897 in epoch 6, gen_loss = 1.0009282482227928, disc_loss = 0.0003917594763364698
Trained batch 898 in epoch 6, gen_loss = 1.0010437594107182, disc_loss = 0.0003916576378863215
Trained batch 899 in epoch 6, gen_loss = 1.0010703660382165, disc_loss = 0.00039177720062677203
Trained batch 900 in epoch 6, gen_loss = 1.0009749703084456, disc_loss = 0.0003920007294758606
Trained batch 901 in epoch 6, gen_loss = 1.0008856778398585, disc_loss = 0.00039213096458364064
Trained batch 902 in epoch 6, gen_loss = 1.0009328377735311, disc_loss = 0.00039244614503611833
Trained batch 903 in epoch 6, gen_loss = 1.0009503049396835, disc_loss = 0.0003930115822105567
Trained batch 904 in epoch 6, gen_loss = 1.0009913981948768, disc_loss = 0.000393249947948025
Trained batch 905 in epoch 6, gen_loss = 1.00094746234138, disc_loss = 0.0003935026683509964
Trained batch 906 in epoch 6, gen_loss = 1.000843521778481, disc_loss = 0.00039391998362802805
Trained batch 907 in epoch 6, gen_loss = 1.0009035125440437, disc_loss = 0.0003939299606142136
Trained batch 908 in epoch 6, gen_loss = 1.0008858924913984, disc_loss = 0.00039400814328791815
Trained batch 909 in epoch 6, gen_loss = 1.0009043823231707, disc_loss = 0.000394010389568943
Trained batch 910 in epoch 6, gen_loss = 1.0009160720948722, disc_loss = 0.00039401987007303235
Trained batch 911 in epoch 6, gen_loss = 1.0010138848110248, disc_loss = 0.00039396100305566506
Trained batch 912 in epoch 6, gen_loss = 1.0010291270071157, disc_loss = 0.0003941299956747311
Trained batch 913 in epoch 6, gen_loss = 1.0010435167757115, disc_loss = 0.0003939655762263795
Trained batch 914 in epoch 6, gen_loss = 1.001020996492417, disc_loss = 0.0003937685840196661
Trained batch 915 in epoch 6, gen_loss = 1.0009402065948627, disc_loss = 0.0003935201047920898
Trained batch 916 in epoch 6, gen_loss = 1.0009063748132963, disc_loss = 0.0003932812423290085
Trained batch 917 in epoch 6, gen_loss = 1.0009345934931229, disc_loss = 0.00039302023678095704
Trained batch 918 in epoch 6, gen_loss = 1.0010052541264771, disc_loss = 0.00039275667972842325
Trained batch 919 in epoch 6, gen_loss = 1.0010437623962112, disc_loss = 0.0003925418564864705
Trained batch 920 in epoch 6, gen_loss = 1.001072548693865, disc_loss = 0.0003923212440641651
Trained batch 921 in epoch 6, gen_loss = 1.0010469012172516, disc_loss = 0.0003920618998214242
Trained batch 922 in epoch 6, gen_loss = 1.000935564513842, disc_loss = 0.00039184279170313994
Trained batch 923 in epoch 6, gen_loss = 1.0009731323301019, disc_loss = 0.00039173555719709395
Trained batch 924 in epoch 6, gen_loss = 1.0010145845284333, disc_loss = 0.00039176085272825926
Trained batch 925 in epoch 6, gen_loss = 1.001029076702394, disc_loss = 0.0003916949489458852
Trained batch 926 in epoch 6, gen_loss = 1.00090927207097, disc_loss = 0.0003914563015558641
Trained batch 927 in epoch 6, gen_loss = 1.000872496772429, disc_loss = 0.0003911894366449909
Trained batch 928 in epoch 6, gen_loss = 1.0008328945182496, disc_loss = 0.000390907308695991
Trained batch 929 in epoch 6, gen_loss = 1.0007307064148687, disc_loss = 0.0003906303020881086
Trained batch 930 in epoch 6, gen_loss = 1.0005905778016235, disc_loss = 0.00039032144174415537
Trained batch 931 in epoch 6, gen_loss = 1.0005341931346148, disc_loss = 0.00038996186221720175
Trained batch 932 in epoch 6, gen_loss = 1.0005319561861208, disc_loss = 0.0003896201618234372
Trained batch 933 in epoch 6, gen_loss = 1.0006333225799577, disc_loss = 0.000389320427290492
Trained batch 934 in epoch 6, gen_loss = 1.0006794562314283, disc_loss = 0.00038900218222646374
Trained batch 935 in epoch 6, gen_loss = 1.0007728300033472, disc_loss = 0.0003886679106883995
Trained batch 936 in epoch 6, gen_loss = 1.00069086388819, disc_loss = 0.0003883339032424433
Trained batch 937 in epoch 6, gen_loss = 1.0005602532866666, disc_loss = 0.00038804092771602795
Trained batch 938 in epoch 6, gen_loss = 1.0005019953964363, disc_loss = 0.00038780150625573797
Trained batch 939 in epoch 6, gen_loss = 1.000381294083088, disc_loss = 0.0003875946522733083
Trained batch 940 in epoch 6, gen_loss = 1.00050536643686, disc_loss = 0.0003875187796746048
Trained batch 941 in epoch 6, gen_loss = 1.0004689797221222, disc_loss = 0.0003875061119425248
Trained batch 942 in epoch 6, gen_loss = 1.0007432835731627, disc_loss = 0.0003875684860923025
Trained batch 943 in epoch 6, gen_loss = 1.0008684293193333, disc_loss = 0.0003873332786836619
Trained batch 944 in epoch 6, gen_loss = 1.000954474090899, disc_loss = 0.00038706609181149383
Trained batch 945 in epoch 6, gen_loss = 1.0009980257167372, disc_loss = 0.00038673897673570097
Trained batch 946 in epoch 6, gen_loss = 1.001078635485648, disc_loss = 0.00038639968619926527
Trained batch 947 in epoch 6, gen_loss = 1.0011180581422798, disc_loss = 0.00038614739311736455
Trained batch 948 in epoch 6, gen_loss = 1.0011955787308977, disc_loss = 0.0003859632505323896
Trained batch 949 in epoch 6, gen_loss = 1.0011539604789332, disc_loss = 0.000385801848797679
Trained batch 950 in epoch 6, gen_loss = 1.0010768938515842, disc_loss = 0.0003857510373783817
Trained batch 951 in epoch 6, gen_loss = 1.0009835795695041, disc_loss = 0.0003857217623269261
Trained batch 952 in epoch 6, gen_loss = 1.0009392570598679, disc_loss = 0.0003856649187641831
Trained batch 953 in epoch 6, gen_loss = 1.0009347903278638, disc_loss = 0.00038550741491363133
Trained batch 954 in epoch 6, gen_loss = 1.0008165106723446, disc_loss = 0.0003853113936697357
Trained batch 955 in epoch 6, gen_loss = 1.0007793693861702, disc_loss = 0.00038508020365781446
Trained batch 956 in epoch 6, gen_loss = 1.00066427352411, disc_loss = 0.0003848288523020732
Trained batch 957 in epoch 6, gen_loss = 1.000619094282202, disc_loss = 0.00038460529890898876
Trained batch 958 in epoch 6, gen_loss = 1.0006792604985402, disc_loss = 0.00038438739281139705
Trained batch 959 in epoch 6, gen_loss = 1.0007335934787989, disc_loss = 0.0003841832651460209
Trained batch 960 in epoch 6, gen_loss = 1.0007406788239495, disc_loss = 0.00038393822576421576
Trained batch 961 in epoch 6, gen_loss = 1.000683996446911, disc_loss = 0.0003836503202665482
Trained batch 962 in epoch 6, gen_loss = 1.0006682565774254, disc_loss = 0.00038336326167267155
Trained batch 963 in epoch 6, gen_loss = 1.0006208932375018, disc_loss = 0.00038307160082476306
Trained batch 964 in epoch 6, gen_loss = 1.0004481618886167, disc_loss = 0.00038281527882136666
Trained batch 965 in epoch 6, gen_loss = 1.000530462519229, disc_loss = 0.00038264167432736665
Trained batch 966 in epoch 6, gen_loss = 1.0004801727993164, disc_loss = 0.00038250693021915926
Trained batch 967 in epoch 6, gen_loss = 1.0005434187483195, disc_loss = 0.0003823610799492809
Trained batch 968 in epoch 6, gen_loss = 1.0006404496321861, disc_loss = 0.0003821928709471128
Trained batch 969 in epoch 6, gen_loss = 1.0007029378537051, disc_loss = 0.0003819921923085409
Trained batch 970 in epoch 6, gen_loss = 1.0006587142556385, disc_loss = 0.0003818180900539826
Trained batch 971 in epoch 6, gen_loss = 1.000644292299149, disc_loss = 0.0003816835491037367
Trained batch 972 in epoch 6, gen_loss = 1.0006181350224799, disc_loss = 0.0003815944526506179
Trained batch 973 in epoch 6, gen_loss = 1.0005276416728628, disc_loss = 0.0003814152744685341
Trained batch 974 in epoch 6, gen_loss = 1.0005423028041156, disc_loss = 0.0003812038599146315
Trained batch 975 in epoch 6, gen_loss = 1.0005284645518318, disc_loss = 0.0003809316448138413
Trained batch 976 in epoch 6, gen_loss = 1.0004845684358017, disc_loss = 0.00038062508386357694
Trained batch 977 in epoch 6, gen_loss = 1.0003355843279746, disc_loss = 0.00038036487391647066
Trained batch 978 in epoch 6, gen_loss = 1.0003739817636859, disc_loss = 0.0003802810560871939
Trained batch 979 in epoch 6, gen_loss = 1.0002999166444857, disc_loss = 0.0003804167269310933
Trained batch 980 in epoch 6, gen_loss = 1.0002045342803123, disc_loss = 0.0003806345072094537
Trained batch 981 in epoch 6, gen_loss = 1.0001708910081635, disc_loss = 0.00038075644022390594
Trained batch 982 in epoch 6, gen_loss = 1.0001451362792255, disc_loss = 0.000380762882157876
Trained batch 983 in epoch 6, gen_loss = 1.0002169195956332, disc_loss = 0.0003806472143072661
Trained batch 984 in epoch 6, gen_loss = 1.000161046788172, disc_loss = 0.0003804610637052051
Trained batch 985 in epoch 6, gen_loss = 1.0000567321361442, disc_loss = 0.00038030439773838946
Trained batch 986 in epoch 6, gen_loss = 1.0001583978639428, disc_loss = 0.0003802345319261365
Trained batch 987 in epoch 6, gen_loss = 1.0000439299504285, disc_loss = 0.0003802026684152298
Trained batch 988 in epoch 6, gen_loss = 1.0001602072807365, disc_loss = 0.00038019868686368653
Trained batch 989 in epoch 6, gen_loss = 1.000242318769898, disc_loss = 0.00038018305494915696
Trained batch 990 in epoch 6, gen_loss = 1.000272898332382, disc_loss = 0.00038008423148904385
Trained batch 991 in epoch 6, gen_loss = 1.000253072609344, disc_loss = 0.00037995993933427304
Trained batch 992 in epoch 6, gen_loss = 1.0001383222121847, disc_loss = 0.0003797834993960019
Trained batch 993 in epoch 6, gen_loss = 1.000148509169968, disc_loss = 0.0003796150267297042
Trained batch 994 in epoch 6, gen_loss = 1.0001305599907535, disc_loss = 0.0003793818786788273
Trained batch 995 in epoch 6, gen_loss = 1.0000386388306637, disc_loss = 0.0003791805766269249
Trained batch 996 in epoch 6, gen_loss = 0.9999986643657283, disc_loss = 0.0003790251796168612
Trained batch 997 in epoch 6, gen_loss = 1.000041185674782, disc_loss = 0.0003789134156002051
Trained batch 998 in epoch 6, gen_loss = 1.0000064138535623, disc_loss = 0.00037884818934739935
Trained batch 999 in epoch 6, gen_loss = 1.0002160128951072, disc_loss = 0.00037892096971336287
Trained batch 1000 in epoch 6, gen_loss = 1.0002428267623757, disc_loss = 0.00037916941194877414
Trained batch 1001 in epoch 6, gen_loss = 1.000341343011209, disc_loss = 0.0003794941053247802
Trained batch 1002 in epoch 6, gen_loss = 1.0004074088003438, disc_loss = 0.00037979750587534836
Trained batch 1003 in epoch 6, gen_loss = 1.0004275504692617, disc_loss = 0.0003800644533122209
Trained batch 1004 in epoch 6, gen_loss = 1.0004627509496697, disc_loss = 0.0003801961662102982
Trained batch 1005 in epoch 6, gen_loss = 1.0005214959086766, disc_loss = 0.00038023285486350744
Trained batch 1006 in epoch 6, gen_loss = 1.000522955349446, disc_loss = 0.00038024100380852106
Trained batch 1007 in epoch 6, gen_loss = 1.0006700804427502, disc_loss = 0.00038028812717144205
Trained batch 1008 in epoch 6, gen_loss = 1.0006991723484042, disc_loss = 0.00038031464671576257
Trained batch 1009 in epoch 6, gen_loss = 1.0006541615075404, disc_loss = 0.0003802776696145452
Trained batch 1010 in epoch 6, gen_loss = 1.0006485684571234, disc_loss = 0.0003802065069424025
Trained batch 1011 in epoch 6, gen_loss = 1.000732020780503, disc_loss = 0.0003801697238677194
Trained batch 1012 in epoch 6, gen_loss = 1.0007733763264528, disc_loss = 0.0003800796854581182
Trained batch 1013 in epoch 6, gen_loss = 1.0007957951321875, disc_loss = 0.0003799519488452272
Trained batch 1014 in epoch 6, gen_loss = 1.0009515351262586, disc_loss = 0.00037980828737596903
Trained batch 1015 in epoch 6, gen_loss = 1.000961024812826, disc_loss = 0.0003796124749603373
Trained batch 1016 in epoch 6, gen_loss = 1.0009937470407027, disc_loss = 0.00037940113310784107
Trained batch 1017 in epoch 6, gen_loss = 1.0008922191172076, disc_loss = 0.0003793147377104202
Trained batch 1018 in epoch 6, gen_loss = 1.0009273190025727, disc_loss = 0.0003795693558657915
Trained batch 1019 in epoch 6, gen_loss = 1.0009424685263166, disc_loss = 0.00037970775782584907
Trained batch 1020 in epoch 6, gen_loss = 1.0011200070030892, disc_loss = 0.00037965600376930016
Trained batch 1021 in epoch 6, gen_loss = 1.0010818461149407, disc_loss = 0.0003794407848741015
Trained batch 1022 in epoch 6, gen_loss = 1.0010569897331916, disc_loss = 0.0003792720787998249
Trained batch 1023 in epoch 6, gen_loss = 1.0011510259937495, disc_loss = 0.0003791327083320084
Trained batch 1024 in epoch 6, gen_loss = 1.0011169278912428, disc_loss = 0.00037887619529345366
Trained batch 1025 in epoch 6, gen_loss = 1.00102654273747, disc_loss = 0.00037872315633418645
Trained batch 1026 in epoch 6, gen_loss = 1.0010971877335806, disc_loss = 0.00037857159589646934
Trained batch 1027 in epoch 6, gen_loss = 1.001388464630346, disc_loss = 0.00037832043188543
Trained batch 1028 in epoch 6, gen_loss = 1.00136721893001, disc_loss = 0.00037806457081905576
Trained batch 1029 in epoch 6, gen_loss = 1.0013847123650672, disc_loss = 0.00037787185368146206
Trained batch 1030 in epoch 6, gen_loss = 1.0012901909251912, disc_loss = 0.00037773388182061474
Trained batch 1031 in epoch 6, gen_loss = 1.0013405316790869, disc_loss = 0.0003775617950067985
Trained batch 1032 in epoch 6, gen_loss = 1.0012473658462924, disc_loss = 0.0003773593696533898
Trained batch 1033 in epoch 6, gen_loss = 1.0012654534160976, disc_loss = 0.0003771115498274125
Trained batch 1034 in epoch 6, gen_loss = 1.0012520686439845, disc_loss = 0.00037687866906927907
Trained batch 1035 in epoch 6, gen_loss = 1.001241584657242, disc_loss = 0.0003767127315722798
Trained batch 1036 in epoch 6, gen_loss = 1.00128304268608, disc_loss = 0.00037672973637919955
Trained batch 1037 in epoch 6, gen_loss = 1.0013230246615548, disc_loss = 0.00037703199527089115
Trained batch 1038 in epoch 6, gen_loss = 1.0014047994420894, disc_loss = 0.0003775327795674115
Trained batch 1039 in epoch 6, gen_loss = 1.001384705534348, disc_loss = 0.00037800659335446724
Trained batch 1040 in epoch 6, gen_loss = 1.0014846160020197, disc_loss = 0.00037832711057806355
Trained batch 1041 in epoch 6, gen_loss = 1.0014631119547788, disc_loss = 0.0003784015951416725
Trained batch 1042 in epoch 6, gen_loss = 1.0014347399755499, disc_loss = 0.0003783016286237649
Trained batch 1043 in epoch 6, gen_loss = 1.001435154071256, disc_loss = 0.0003781573042622321
Trained batch 1044 in epoch 6, gen_loss = 1.0014536846767772, disc_loss = 0.00037816067866236865
Trained batch 1045 in epoch 6, gen_loss = 1.0015080923901918, disc_loss = 0.0003784012243814542
Trained batch 1046 in epoch 6, gen_loss = 1.0015482962302287, disc_loss = 0.0003786905450577854
Trained batch 1047 in epoch 6, gen_loss = 1.001615697134087, disc_loss = 0.0003789800644075971
Trained batch 1048 in epoch 6, gen_loss = 1.0015282847406297, disc_loss = 0.00037931106724151304
Trained batch 1049 in epoch 6, gen_loss = 1.0014380745660691, disc_loss = 0.00037969897287742547
Trained batch 1050 in epoch 6, gen_loss = 1.0014915758944147, disc_loss = 0.0003799764335287963
Trained batch 1051 in epoch 6, gen_loss = 1.0017034830702576, disc_loss = 0.0003801956816791989
Trained batch 1052 in epoch 6, gen_loss = 1.0017806197616563, disc_loss = 0.0003804407861198282
Trained batch 1053 in epoch 6, gen_loss = 1.001794926129437, disc_loss = 0.000380474626974899
Trained batch 1054 in epoch 6, gen_loss = 1.001656470423061, disc_loss = 0.000380434328386719
Trained batch 1055 in epoch 6, gen_loss = 1.0015697144536357, disc_loss = 0.0003803467027341178
Trained batch 1056 in epoch 6, gen_loss = 1.0015802676088987, disc_loss = 0.0003802327482913539
Trained batch 1057 in epoch 6, gen_loss = 1.001672215802007, disc_loss = 0.0003801490600962044
Trained batch 1058 in epoch 6, gen_loss = 1.0016486954869135, disc_loss = 0.00038015090717957815
Trained batch 1059 in epoch 6, gen_loss = 1.0015291508076325, disc_loss = 0.0003804006777431394
Trained batch 1060 in epoch 6, gen_loss = 1.0015729086563117, disc_loss = 0.0003806533435452642
Trained batch 1061 in epoch 6, gen_loss = 1.0015606253272844, disc_loss = 0.0003808003963407992
Trained batch 1062 in epoch 6, gen_loss = 1.0015927212819218, disc_loss = 0.000380855562528534
Trained batch 1063 in epoch 6, gen_loss = 1.001779470060553, disc_loss = 0.0003808398735265272
Trained batch 1064 in epoch 6, gen_loss = 1.0017973846672845, disc_loss = 0.00038085426143785945
Trained batch 1065 in epoch 6, gen_loss = 1.0017553056829642, disc_loss = 0.00038085035768103406
Trained batch 1066 in epoch 6, gen_loss = 1.0017944178853844, disc_loss = 0.0003807901554763223
Trained batch 1067 in epoch 6, gen_loss = 1.0018527201945415, disc_loss = 0.0003807157855395887
Trained batch 1068 in epoch 6, gen_loss = 1.001820659447876, disc_loss = 0.00038057726527907486
Trained batch 1069 in epoch 6, gen_loss = 1.0018475736970098, disc_loss = 0.0003803815520488196
Trained batch 1070 in epoch 6, gen_loss = 1.0018455151861567, disc_loss = 0.00038020792963978055
Trained batch 1071 in epoch 6, gen_loss = 1.001895640768222, disc_loss = 0.0003799735106386196
Trained batch 1072 in epoch 6, gen_loss = 1.001917120683782, disc_loss = 0.0003797235461004002
Trained batch 1073 in epoch 6, gen_loss = 1.0018555191753076, disc_loss = 0.00037949368363565867
Trained batch 1074 in epoch 6, gen_loss = 1.0018915386532627, disc_loss = 0.00037929622399577396
Trained batch 1075 in epoch 6, gen_loss = 1.0019273655454466, disc_loss = 0.00037909874539033834
Trained batch 1076 in epoch 6, gen_loss = 1.0019456717629287, disc_loss = 0.00037890727670228554
Trained batch 1077 in epoch 6, gen_loss = 1.0018618403759427, disc_loss = 0.00037873778342103483
Trained batch 1078 in epoch 6, gen_loss = 1.001844521580856, disc_loss = 0.00037863549157183884
Trained batch 1079 in epoch 6, gen_loss = 1.0018209529695687, disc_loss = 0.0003784905695485779
Trained batch 1080 in epoch 6, gen_loss = 1.0018047662822325, disc_loss = 0.00037826283093251955
Trained batch 1081 in epoch 6, gen_loss = 1.0018799855286005, disc_loss = 0.00037805418412202395
Trained batch 1082 in epoch 6, gen_loss = 1.0020001446991635, disc_loss = 0.0003778191523539162
Trained batch 1083 in epoch 6, gen_loss = 1.0019350570396304, disc_loss = 0.0003775567379290396
Trained batch 1084 in epoch 6, gen_loss = 1.0018968182774732, disc_loss = 0.00037726928567951586
Trained batch 1085 in epoch 6, gen_loss = 1.001871552311474, disc_loss = 0.0003769916055721774
Trained batch 1086 in epoch 6, gen_loss = 1.0018632368637863, disc_loss = 0.00037674431266261415
Trained batch 1087 in epoch 6, gen_loss = 1.0018401805530577, disc_loss = 0.000376502973688944
Trained batch 1088 in epoch 6, gen_loss = 1.0018180147347042, disc_loss = 0.0003762685471205588
Trained batch 1089 in epoch 6, gen_loss = 1.0018739166062907, disc_loss = 0.00037601909009043403
Trained batch 1090 in epoch 6, gen_loss = 1.001773158363199, disc_loss = 0.0003758152987724546
Trained batch 1091 in epoch 6, gen_loss = 1.0018065308149045, disc_loss = 0.00037563124593968195
Trained batch 1092 in epoch 6, gen_loss = 1.001767969578641, disc_loss = 0.0003754316497313358
Trained batch 1093 in epoch 6, gen_loss = 1.0017450829419619, disc_loss = 0.0003751975289084974
Trained batch 1094 in epoch 6, gen_loss = 1.0016845898541142, disc_loss = 0.00037497105540709833
Trained batch 1095 in epoch 6, gen_loss = 1.0017031734115887, disc_loss = 0.00037499282811651513
Trained batch 1096 in epoch 6, gen_loss = 1.0016350946648076, disc_loss = 0.0003759400433600297
Trained batch 1097 in epoch 6, gen_loss = 1.001648526645532, disc_loss = 0.00037724921101153335
Trained batch 1098 in epoch 6, gen_loss = 1.001666360220332, disc_loss = 0.0003782310999902999
Trained batch 1099 in epoch 6, gen_loss = 1.0017568784952164, disc_loss = 0.0003787987956655508
Trained batch 1100 in epoch 6, gen_loss = 1.0017845006448154, disc_loss = 0.00037891042702837673
Trained batch 1101 in epoch 6, gen_loss = 1.00175722129981, disc_loss = 0.00037878170348965847
Trained batch 1102 in epoch 6, gen_loss = 1.0017771446369825, disc_loss = 0.0003788637944918501
Trained batch 1103 in epoch 6, gen_loss = 1.0017191857315493, disc_loss = 0.00037907885901707533
Trained batch 1104 in epoch 6, gen_loss = 1.001694094433504, disc_loss = 0.0003791715795431303
Trained batch 1105 in epoch 6, gen_loss = 1.0016892772255497, disc_loss = 0.00037907485048194835
Trained batch 1106 in epoch 6, gen_loss = 1.0016260826598447, disc_loss = 0.0003792060820805203
Trained batch 1107 in epoch 6, gen_loss = 1.0015618121688548, disc_loss = 0.0003792531732925792
Trained batch 1108 in epoch 6, gen_loss = 1.0015321494331222, disc_loss = 0.000379871763378202
Trained batch 1109 in epoch 6, gen_loss = 1.0014804344993453, disc_loss = 0.00038074796354956085
Trained batch 1110 in epoch 6, gen_loss = 1.0016697107618935, disc_loss = 0.0003814386934702956
Trained batch 1111 in epoch 6, gen_loss = 1.001658749237335, disc_loss = 0.0003818594266691081
Trained batch 1112 in epoch 6, gen_loss = 1.0016767137883915, disc_loss = 0.0003819132069132466
Trained batch 1113 in epoch 6, gen_loss = 1.0016931176613648, disc_loss = 0.0003818339134522177
Trained batch 1114 in epoch 6, gen_loss = 1.0016278032764725, disc_loss = 0.0003817406846857692
Trained batch 1115 in epoch 6, gen_loss = 1.0016377408017394, disc_loss = 0.0003815747258807516
Trained batch 1116 in epoch 6, gen_loss = 1.0015716344625052, disc_loss = 0.0003814529356846441
Trained batch 1117 in epoch 6, gen_loss = 1.0015439680629212, disc_loss = 0.0003815175119022321
Trained batch 1118 in epoch 6, gen_loss = 1.0015651202287068, disc_loss = 0.0003816181780232351
Trained batch 1119 in epoch 6, gen_loss = 1.0015895824879408, disc_loss = 0.0003815648640998656
Trained batch 1120 in epoch 6, gen_loss = 1.0014707362088213, disc_loss = 0.0003815099966318083
Trained batch 1121 in epoch 6, gen_loss = 1.0015381184172503, disc_loss = 0.0003814917559054416
Trained batch 1122 in epoch 6, gen_loss = 1.0015341504705026, disc_loss = 0.0003814533169780222
Trained batch 1123 in epoch 6, gen_loss = 1.0015112816545038, disc_loss = 0.0003812600531039662
Trained batch 1124 in epoch 6, gen_loss = 1.001484124024709, disc_loss = 0.000381047148270429
Trained batch 1125 in epoch 6, gen_loss = 1.0014532970175227, disc_loss = 0.0003808189710780199
Trained batch 1126 in epoch 6, gen_loss = 1.0014356216605829, disc_loss = 0.0003806117109975223
Trained batch 1127 in epoch 6, gen_loss = 1.001455322911976, disc_loss = 0.00038043653895580604
Trained batch 1128 in epoch 6, gen_loss = 1.0014896397573743, disc_loss = 0.0003803306993332579
Trained batch 1129 in epoch 6, gen_loss = 1.0015478615739704, disc_loss = 0.00038023325954605127
Trained batch 1130 in epoch 6, gen_loss = 1.0015728370896702, disc_loss = 0.00038014315974002725
Trained batch 1131 in epoch 6, gen_loss = 1.0015643678157995, disc_loss = 0.00037999336935609396
Trained batch 1132 in epoch 6, gen_loss = 1.0015954733526191, disc_loss = 0.00038038014696495045
Trained batch 1133 in epoch 6, gen_loss = 1.0015806873218933, disc_loss = 0.00038152114558813856
Trained batch 1134 in epoch 6, gen_loss = 1.0016114204465556, disc_loss = 0.0003826183486434463
Trained batch 1135 in epoch 6, gen_loss = 1.0015890864314327, disc_loss = 0.0003832278024687261
Trained batch 1136 in epoch 6, gen_loss = 1.0016241163251267, disc_loss = 0.00038321396714181247
Trained batch 1137 in epoch 6, gen_loss = 1.0017038981294382, disc_loss = 0.00038305550832804685
Trained batch 1138 in epoch 6, gen_loss = 1.001636686976067, disc_loss = 0.0003831838956460458
Trained batch 1139 in epoch 6, gen_loss = 1.0017485793745309, disc_loss = 0.0003834587250981202
Trained batch 1140 in epoch 6, gen_loss = 1.001822140058021, disc_loss = 0.00038370530827172545
Trained batch 1141 in epoch 6, gen_loss = 1.001839158570495, disc_loss = 0.00038381907636819213
Trained batch 1142 in epoch 6, gen_loss = 1.0018627589873232, disc_loss = 0.00038402469436905315
Trained batch 1143 in epoch 6, gen_loss = 1.0018727074448879, disc_loss = 0.00038510834110002816
Trained batch 1144 in epoch 6, gen_loss = 1.0019247141987997, disc_loss = 0.00038619532555394593
Trained batch 1145 in epoch 6, gen_loss = 1.0018491238407647, disc_loss = 0.0003870316572297595
Trained batch 1146 in epoch 6, gen_loss = 1.0017180941680668, disc_loss = 0.0003874821289949551
Trained batch 1147 in epoch 6, gen_loss = 1.0017900118013707, disc_loss = 0.0003875848004999668
Trained batch 1148 in epoch 6, gen_loss = 1.0018750270415224, disc_loss = 0.00038749691979085023
Trained batch 1149 in epoch 6, gen_loss = 1.0019323896325152, disc_loss = 0.000387295985483038
Trained batch 1150 in epoch 6, gen_loss = 1.0020029851398087, disc_loss = 0.00038706284295979943
Trained batch 1151 in epoch 6, gen_loss = 1.0020385653608375, disc_loss = 0.0003870054734989026
Trained batch 1152 in epoch 6, gen_loss = 1.002026325603826, disc_loss = 0.00038703854025088345
Trained batch 1153 in epoch 6, gen_loss = 1.0020528752840991, disc_loss = 0.00038697613883943927
Trained batch 1154 in epoch 6, gen_loss = 1.0019945478026484, disc_loss = 0.0003875591462952774
Trained batch 1155 in epoch 6, gen_loss = 1.0020241040259497, disc_loss = 0.00038941017572136007
Trained batch 1156 in epoch 6, gen_loss = 1.001933024788892, disc_loss = 0.0003909306226163586
Trained batch 1157 in epoch 6, gen_loss = 1.0019313214356418, disc_loss = 0.00039223373446294665
Trained batch 1158 in epoch 6, gen_loss = 1.001889049338307, disc_loss = 0.0003926429100995771
Trained batch 1159 in epoch 6, gen_loss = 1.001923273452397, disc_loss = 0.00039309589657681625
Trained batch 1160 in epoch 6, gen_loss = 1.0020070520585, disc_loss = 0.0003936437895924814
Trained batch 1161 in epoch 6, gen_loss = 1.001969252416476, disc_loss = 0.0003949199573523782
Trained batch 1162 in epoch 6, gen_loss = 1.0019553058227382, disc_loss = 0.0003971375300350174
Trained batch 1163 in epoch 6, gen_loss = 1.0020439468093754, disc_loss = 0.0003978737229872391
Trained batch 1164 in epoch 6, gen_loss = 1.002038411521093, disc_loss = 0.00039808818816393214
Trained batch 1165 in epoch 6, gen_loss = 1.0020735755588341, disc_loss = 0.00039810419302442916
Trained batch 1166 in epoch 6, gen_loss = 1.0020862655345455, disc_loss = 0.0003980131150206755
Trained batch 1167 in epoch 6, gen_loss = 1.0020066475215024, disc_loss = 0.00039787770551250615
Trained batch 1168 in epoch 6, gen_loss = 1.0019694666662615, disc_loss = 0.00039792125876331695
Trained batch 1169 in epoch 6, gen_loss = 1.001999273768857, disc_loss = 0.00039779342012977403
Trained batch 1170 in epoch 6, gen_loss = 1.0020116465810422, disc_loss = 0.0003975434422264922
Trained batch 1171 in epoch 6, gen_loss = 1.002068823311516, disc_loss = 0.00039741598178583685
Trained batch 1172 in epoch 6, gen_loss = 1.0021067761195996, disc_loss = 0.0003972142835900756
Trained batch 1173 in epoch 6, gen_loss = 1.0021112810001667, disc_loss = 0.00039711832536405884
Trained batch 1174 in epoch 6, gen_loss = 1.002124493578647, disc_loss = 0.00039699493981699676
Trained batch 1175 in epoch 6, gen_loss = 1.00209448456156, disc_loss = 0.0003969968509372105
Trained batch 1176 in epoch 6, gen_loss = 1.002023128047269, disc_loss = 0.0003968450644733218
Trained batch 1177 in epoch 6, gen_loss = 1.0020577099509473, disc_loss = 0.0003969084019539482
Trained batch 1178 in epoch 6, gen_loss = 1.0020688125599837, disc_loss = 0.00039684610902248826
Trained batch 1179 in epoch 6, gen_loss = 1.002092616790432, disc_loss = 0.0003966758559064316
Trained batch 1180 in epoch 6, gen_loss = 1.002070458333034, disc_loss = 0.0003965285411974964
Trained batch 1181 in epoch 6, gen_loss = 1.002081951009844, disc_loss = 0.0003964146515826282
Trained batch 1182 in epoch 6, gen_loss = 1.0021334703151996, disc_loss = 0.00039643805911412206
Trained batch 1183 in epoch 6, gen_loss = 1.002127439790481, disc_loss = 0.0003966580969038635
Trained batch 1184 in epoch 6, gen_loss = 1.002284345143958, disc_loss = 0.0003968065158185993
Trained batch 1185 in epoch 6, gen_loss = 1.0022672754516087, disc_loss = 0.0003969821437407469
Trained batch 1186 in epoch 6, gen_loss = 1.0023186022028163, disc_loss = 0.00039731264496137796
Trained batch 1187 in epoch 6, gen_loss = 1.002252910474334, disc_loss = 0.0003974829609561688
Trained batch 1188 in epoch 6, gen_loss = 1.0022709136053332, disc_loss = 0.0003974747118794479
Trained batch 1189 in epoch 6, gen_loss = 1.0022120884486607, disc_loss = 0.0003972848783029016
Trained batch 1190 in epoch 6, gen_loss = 1.0022101829174084, disc_loss = 0.00039702652865887083
Trained batch 1191 in epoch 6, gen_loss = 1.002216160747429, disc_loss = 0.00039691685532604895
Trained batch 1192 in epoch 6, gen_loss = 1.0022009064046056, disc_loss = 0.00039695033955614945
Trained batch 1193 in epoch 6, gen_loss = 1.0021511455077423, disc_loss = 0.00039713320585000494
Trained batch 1194 in epoch 6, gen_loss = 1.0020982459998031, disc_loss = 0.00039741727080250694
Trained batch 1195 in epoch 6, gen_loss = 1.0020596722396322, disc_loss = 0.00039757386650648714
Trained batch 1196 in epoch 6, gen_loss = 1.001994216551657, disc_loss = 0.00039757374897186854
Trained batch 1197 in epoch 6, gen_loss = 1.001975477836367, disc_loss = 0.0003974245698064898
Trained batch 1198 in epoch 6, gen_loss = 1.0019611576579828, disc_loss = 0.0003972127921980269
Trained batch 1199 in epoch 6, gen_loss = 1.0018894822895528, disc_loss = 0.00039700916205523146
Trained batch 1200 in epoch 6, gen_loss = 1.0019655557695177, disc_loss = 0.0003970325015112874
Trained batch 1201 in epoch 6, gen_loss = 1.0019150439296507, disc_loss = 0.00039712265905520854
Trained batch 1202 in epoch 6, gen_loss = 1.0018844378063902, disc_loss = 0.00039706568619832846
Trained batch 1203 in epoch 6, gen_loss = 1.001854434015347, disc_loss = 0.00039698803570189985
Trained batch 1204 in epoch 6, gen_loss = 1.001863644677079, disc_loss = 0.0003967839602938432
Trained batch 1205 in epoch 6, gen_loss = 1.0017982121328415, disc_loss = 0.000396515125236028
Trained batch 1206 in epoch 6, gen_loss = 1.001801848510325, disc_loss = 0.0003962735783939239
Trained batch 1207 in epoch 6, gen_loss = 1.0018637549403488, disc_loss = 0.0003960281245908002
Trained batch 1208 in epoch 6, gen_loss = 1.0018310634630392, disc_loss = 0.0003957797494505392
Trained batch 1209 in epoch 6, gen_loss = 1.001840611331719, disc_loss = 0.000395540708845793
Trained batch 1210 in epoch 6, gen_loss = 1.0018711856925517, disc_loss = 0.00039534988223287044
Trained batch 1211 in epoch 6, gen_loss = 1.0018380837570322, disc_loss = 0.00039523361366645206
Trained batch 1212 in epoch 6, gen_loss = 1.0018942064720053, disc_loss = 0.00039515489866058376
Trained batch 1213 in epoch 6, gen_loss = 1.001847456177141, disc_loss = 0.0003950232899661676
Trained batch 1214 in epoch 6, gen_loss = 1.0018448930218387, disc_loss = 0.0003948318237130273
Trained batch 1215 in epoch 6, gen_loss = 1.0018673528868116, disc_loss = 0.0003946327204080023
Trained batch 1216 in epoch 6, gen_loss = 1.0018198931912663, disc_loss = 0.0003944469984027158
Trained batch 1217 in epoch 6, gen_loss = 1.001863727722262, disc_loss = 0.00039432516671789427
Trained batch 1218 in epoch 6, gen_loss = 1.001840340983584, disc_loss = 0.0003942618528613057
Trained batch 1219 in epoch 6, gen_loss = 1.0017576914830286, disc_loss = 0.0003943631352859618
Trained batch 1220 in epoch 6, gen_loss = 1.0017495480938878, disc_loss = 0.00039451670782923937
Trained batch 1221 in epoch 6, gen_loss = 1.001770641673021, disc_loss = 0.00039453254984289713
Trained batch 1222 in epoch 6, gen_loss = 1.0017575708355753, disc_loss = 0.0003945230414527594
Trained batch 1223 in epoch 6, gen_loss = 1.0016621247518296, disc_loss = 0.0003949178755611487
Trained batch 1224 in epoch 6, gen_loss = 1.0016683959474368, disc_loss = 0.000396250845182554
Trained batch 1225 in epoch 6, gen_loss = 1.0017882615181983, disc_loss = 0.0003974115096594186
Trained batch 1226 in epoch 6, gen_loss = 1.001823458179965, disc_loss = 0.0003982239378565549
Trained batch 1227 in epoch 6, gen_loss = 1.001881560450268, disc_loss = 0.00039851475081223377
Trained batch 1228 in epoch 6, gen_loss = 1.001827931821201, disc_loss = 0.00039847653976630607
Trained batch 1229 in epoch 6, gen_loss = 1.001991165798854, disc_loss = 0.00039870450520420415
Trained batch 1230 in epoch 6, gen_loss = 1.0019962669968314, disc_loss = 0.00039947020143823157
Trained batch 1231 in epoch 6, gen_loss = 1.0019934770542305, disc_loss = 0.0004001213912441064
Trained batch 1232 in epoch 6, gen_loss = 1.001926687028673, disc_loss = 0.00040031499808379625
Trained batch 1233 in epoch 6, gen_loss = 1.0019196162733885, disc_loss = 0.0004001968533105015
Trained batch 1234 in epoch 6, gen_loss = 1.001862619039018, disc_loss = 0.0004000285847620616
Trained batch 1235 in epoch 6, gen_loss = 1.001887802987037, disc_loss = 0.00039984035598553797
Trained batch 1236 in epoch 6, gen_loss = 1.001843913919808, disc_loss = 0.00039964663412530357
Trained batch 1237 in epoch 6, gen_loss = 1.0017700146685125, disc_loss = 0.0003994217141157995
Trained batch 1238 in epoch 6, gen_loss = 1.0016869578369207, disc_loss = 0.00039918577396403883
Trained batch 1239 in epoch 6, gen_loss = 1.0017425862531508, disc_loss = 0.0003989634694775187
Trained batch 1240 in epoch 6, gen_loss = 1.0016447674065805, disc_loss = 0.0003987404166320343
Trained batch 1241 in epoch 6, gen_loss = 1.0016177992985829, disc_loss = 0.00039851965066513246
Trained batch 1242 in epoch 6, gen_loss = 1.0016171305484571, disc_loss = 0.0003982972876500426
Trained batch 1243 in epoch 6, gen_loss = 1.0015289231032805, disc_loss = 0.00039810234807410925
Trained batch 1244 in epoch 6, gen_loss = 1.0015365904593563, disc_loss = 0.0003979067907289482
Trained batch 1245 in epoch 6, gen_loss = 1.0015512955035673, disc_loss = 0.0003977095520559322
Trained batch 1246 in epoch 6, gen_loss = 1.0015118278401702, disc_loss = 0.0003975711755214895
Trained batch 1247 in epoch 6, gen_loss = 1.0013700236972325, disc_loss = 0.0003974667278539411
Trained batch 1248 in epoch 6, gen_loss = 1.0014126734603779, disc_loss = 0.00039759109458507483
Trained batch 1249 in epoch 6, gen_loss = 1.0013937254428864, disc_loss = 0.0003975477261992637
Trained batch 1250 in epoch 6, gen_loss = 1.0012925918534887, disc_loss = 0.0003975204627531086
Trained batch 1251 in epoch 6, gen_loss = 1.0012952005520415, disc_loss = 0.0003975661482562749
Trained batch 1252 in epoch 6, gen_loss = 1.0014066591513984, disc_loss = 0.00039770435013330573
Trained batch 1253 in epoch 6, gen_loss = 1.0013762863629172, disc_loss = 0.00039778993977758286
Trained batch 1254 in epoch 6, gen_loss = 1.0014591767018535, disc_loss = 0.00039784840222441617
Trained batch 1255 in epoch 6, gen_loss = 1.0014059687875638, disc_loss = 0.00039784630874115687
Trained batch 1256 in epoch 6, gen_loss = 1.0014357426475702, disc_loss = 0.0003978469328162136
Trained batch 1257 in epoch 6, gen_loss = 1.0014052855380957, disc_loss = 0.00039777707676307906
Trained batch 1258 in epoch 6, gen_loss = 1.0014136064800598, disc_loss = 0.0003976220250016613
Trained batch 1259 in epoch 6, gen_loss = 1.0014593282389261, disc_loss = 0.00039744833415574654
Trained batch 1260 in epoch 6, gen_loss = 1.0016269252755923, disc_loss = 0.0003973708235979332
Trained batch 1261 in epoch 6, gen_loss = 1.001702204370272, disc_loss = 0.0003973263594130126
Trained batch 1262 in epoch 6, gen_loss = 1.0017447078973645, disc_loss = 0.0003972420714995514
Trained batch 1263 in epoch 6, gen_loss = 1.0017433174048798, disc_loss = 0.00039708130906305247
Trained batch 1264 in epoch 6, gen_loss = 1.0017838434739545, disc_loss = 0.0003970043494731
Trained batch 1265 in epoch 6, gen_loss = 1.0017195262991798, disc_loss = 0.00039684482644545464
Trained batch 1266 in epoch 6, gen_loss = 1.0016762684345621, disc_loss = 0.0003966371839631833
Trained batch 1267 in epoch 6, gen_loss = 1.0015931842078922, disc_loss = 0.00039641187432731063
Trained batch 1268 in epoch 6, gen_loss = 1.0016104904472405, disc_loss = 0.0003962320410298812
Trained batch 1269 in epoch 6, gen_loss = 1.0016169969491133, disc_loss = 0.00039607736679191856
Trained batch 1270 in epoch 6, gen_loss = 1.001553800282377, disc_loss = 0.00039588441162016226
Trained batch 1271 in epoch 6, gen_loss = 1.001611666531308, disc_loss = 0.0003956395677857283
Trained batch 1272 in epoch 6, gen_loss = 1.0016005265366255, disc_loss = 0.0003954946359218309
Trained batch 1273 in epoch 6, gen_loss = 1.0016843168009395, disc_loss = 0.00039563690805030085
Trained batch 1274 in epoch 6, gen_loss = 1.0016343019055385, disc_loss = 0.00039596557117857077
Trained batch 1275 in epoch 6, gen_loss = 1.001714125836157, disc_loss = 0.00039616418485410203
Trained batch 1276 in epoch 6, gen_loss = 1.0017105970610467, disc_loss = 0.00039617968421086074
Trained batch 1277 in epoch 6, gen_loss = 1.0017717687270264, disc_loss = 0.0003960936994192825
Trained batch 1278 in epoch 6, gen_loss = 1.0017968471671008, disc_loss = 0.00039594071153049816
Trained batch 1279 in epoch 6, gen_loss = 1.0017457834910601, disc_loss = 0.00039570389924392657
Trained batch 1280 in epoch 6, gen_loss = 1.0018109796477146, disc_loss = 0.00039547207453522604
Trained batch 1281 in epoch 6, gen_loss = 1.0017691526602657, disc_loss = 0.00039526182975772227
Trained batch 1282 in epoch 6, gen_loss = 1.0017621167822917, disc_loss = 0.00039505099560862184
Trained batch 1283 in epoch 6, gen_loss = 1.0016714234682629, disc_loss = 0.0003948844794400299
Trained batch 1284 in epoch 6, gen_loss = 1.0016669160661067, disc_loss = 0.00039478748492535986
Trained batch 1285 in epoch 6, gen_loss = 1.0017036340006773, disc_loss = 0.0003946049027761385
Trained batch 1286 in epoch 6, gen_loss = 1.0016069316363836, disc_loss = 0.00039442697104250055
Trained batch 1287 in epoch 6, gen_loss = 1.0017597035313985, disc_loss = 0.0003942657109088393
Trained batch 1288 in epoch 6, gen_loss = 1.0017135445233738, disc_loss = 0.00039408185933234314
Trained batch 1289 in epoch 6, gen_loss = 1.0017707268859064, disc_loss = 0.00039393218833630065
Trained batch 1290 in epoch 6, gen_loss = 1.001844452620476, disc_loss = 0.00039387560082034304
Trained batch 1291 in epoch 6, gen_loss = 1.0017768660842818, disc_loss = 0.00039453408952296753
Trained batch 1292 in epoch 6, gen_loss = 1.0017540559506841, disc_loss = 0.00039503495487352443
Trained batch 1293 in epoch 6, gen_loss = 1.001793261427415, disc_loss = 0.0003955167098661958
Trained batch 1294 in epoch 6, gen_loss = 1.0016978908689786, disc_loss = 0.00039596997551362905
Trained batch 1295 in epoch 6, gen_loss = 1.0016920973121384, disc_loss = 0.0003962813972616403
Trained batch 1296 in epoch 6, gen_loss = 1.0017816282366456, disc_loss = 0.00039647721202619327
Trained batch 1297 in epoch 6, gen_loss = 1.001881746279624, disc_loss = 0.00039654776385315523
Trained batch 1298 in epoch 6, gen_loss = 1.0018880510440324, disc_loss = 0.0003965050240734297
Trained batch 1299 in epoch 6, gen_loss = 1.0018924414194548, disc_loss = 0.0003963437862582326
Trained batch 1300 in epoch 6, gen_loss = 1.0018687300916638, disc_loss = 0.00039612383325870576
Trained batch 1301 in epoch 6, gen_loss = 1.0019591615954486, disc_loss = 0.00039588505698364557
Trained batch 1302 in epoch 6, gen_loss = 1.001929992725551, disc_loss = 0.00039570977333542684
Trained batch 1303 in epoch 6, gen_loss = 1.0019056810740312, disc_loss = 0.0003955245849752225
Trained batch 1304 in epoch 6, gen_loss = 1.0019296161059676, disc_loss = 0.0003953278417597789
Trained batch 1305 in epoch 6, gen_loss = 1.0020100072733658, disc_loss = 0.00039516746900827913
Trained batch 1306 in epoch 6, gen_loss = 1.0020390708845994, disc_loss = 0.00039494174013689036
Trained batch 1307 in epoch 6, gen_loss = 1.0019927451825652, disc_loss = 0.0003947589836601436
Trained batch 1308 in epoch 6, gen_loss = 1.0019650829484938, disc_loss = 0.0003947288263022186
Trained batch 1309 in epoch 6, gen_loss = 1.0018959160979468, disc_loss = 0.00039481871592201727
Trained batch 1310 in epoch 6, gen_loss = 1.0018344470147047, disc_loss = 0.000395054076894385
Trained batch 1311 in epoch 6, gen_loss = 1.001810298369425, disc_loss = 0.0003950913957085992
Trained batch 1312 in epoch 6, gen_loss = 1.0017936795337092, disc_loss = 0.0003950244811039807
Trained batch 1313 in epoch 6, gen_loss = 1.0018421516752316, disc_loss = 0.0003948971304759086
Trained batch 1314 in epoch 6, gen_loss = 1.0018834182064795, disc_loss = 0.0003947515163303728
Trained batch 1315 in epoch 6, gen_loss = 1.0019711849356132, disc_loss = 0.00039458322689576053
Trained batch 1316 in epoch 6, gen_loss = 1.0019302162693229, disc_loss = 0.00039454180101969934
Trained batch 1317 in epoch 6, gen_loss = 1.0018684542052483, disc_loss = 0.00039449945521007973
Trained batch 1318 in epoch 6, gen_loss = 1.001879237744734, disc_loss = 0.0003944438609789822
Trained batch 1319 in epoch 6, gen_loss = 1.0019437859455744, disc_loss = 0.00039435404828096085
Trained batch 1320 in epoch 6, gen_loss = 1.001952375362174, disc_loss = 0.0003942983888923247
Trained batch 1321 in epoch 6, gen_loss = 1.0019665043941965, disc_loss = 0.00039422793711605905
Trained batch 1322 in epoch 6, gen_loss = 1.0019359807128358, disc_loss = 0.00039409480971094673
Trained batch 1323 in epoch 6, gen_loss = 1.0018299073431067, disc_loss = 0.00039393015284356947
Trained batch 1324 in epoch 6, gen_loss = 1.0018035081647476, disc_loss = 0.00039371152484749954
Trained batch 1325 in epoch 6, gen_loss = 1.0018240611657478, disc_loss = 0.00039348516679946774
Trained batch 1326 in epoch 6, gen_loss = 1.001765973691933, disc_loss = 0.00039330178982792803
Trained batch 1327 in epoch 6, gen_loss = 1.0017658099532127, disc_loss = 0.00039311099478901127
Trained batch 1328 in epoch 6, gen_loss = 1.0017419888436838, disc_loss = 0.00039289487233512283
Trained batch 1329 in epoch 6, gen_loss = 1.0017202935272589, disc_loss = 0.00039266106973798713
Trained batch 1330 in epoch 6, gen_loss = 1.0016459250790477, disc_loss = 0.0003924447934968998
Trained batch 1331 in epoch 6, gen_loss = 1.0016262285165243, disc_loss = 0.00039231118800573214
Trained batch 1332 in epoch 6, gen_loss = 1.0017016746008744, disc_loss = 0.0003921805984464709
Trained batch 1333 in epoch 6, gen_loss = 1.0018213227771033, disc_loss = 0.0003920329008756273
Trained batch 1334 in epoch 6, gen_loss = 1.0017778070678425, disc_loss = 0.00039189362007150536
Trained batch 1335 in epoch 6, gen_loss = 1.0017884763593445, disc_loss = 0.0003916608469383331
Trained batch 1336 in epoch 6, gen_loss = 1.0017242626904905, disc_loss = 0.00039147631944036677
Trained batch 1337 in epoch 6, gen_loss = 1.0017021129127754, disc_loss = 0.0003914799702110852
Trained batch 1338 in epoch 6, gen_loss = 1.0017188741165457, disc_loss = 0.00039149041969573946
Trained batch 1339 in epoch 6, gen_loss = 1.0016650070005388, disc_loss = 0.0003914540447207835
Trained batch 1340 in epoch 6, gen_loss = 1.0015896340966848, disc_loss = 0.00039132102662817235
Trained batch 1341 in epoch 6, gen_loss = 1.0014935854028484, disc_loss = 0.0003911270021235233
Trained batch 1342 in epoch 6, gen_loss = 1.001462260512212, disc_loss = 0.00039090492041595696
Trained batch 1343 in epoch 6, gen_loss = 1.001428616676657, disc_loss = 0.00039073192662423634
Trained batch 1344 in epoch 6, gen_loss = 1.001478519359929, disc_loss = 0.0003905943522383857
Trained batch 1345 in epoch 6, gen_loss = 1.0014759833975675, disc_loss = 0.00039083402008209154
Trained batch 1346 in epoch 6, gen_loss = 1.0014746832068797, disc_loss = 0.0003916490854359762
Trained batch 1347 in epoch 6, gen_loss = 1.0014265138954366, disc_loss = 0.00039256767901189166
Trained batch 1348 in epoch 6, gen_loss = 1.0014752424408366, disc_loss = 0.000393382991285956
Trained batch 1349 in epoch 6, gen_loss = 1.0014056527614594, disc_loss = 0.00039388452106828075
Trained batch 1350 in epoch 6, gen_loss = 1.0014515770619927, disc_loss = 0.0003939013461178054
Trained batch 1351 in epoch 6, gen_loss = 1.0013674123311889, disc_loss = 0.00039385873283181733
Trained batch 1352 in epoch 6, gen_loss = 1.0013843856294862, disc_loss = 0.00039451807826060146
Trained batch 1353 in epoch 6, gen_loss = 1.0014285035376358, disc_loss = 0.00039598611910415446
Trained batch 1354 in epoch 6, gen_loss = 1.0013665775531333, disc_loss = 0.00039723586611968646
Trained batch 1355 in epoch 6, gen_loss = 1.0013775579345614, disc_loss = 0.00039774586274793404
Trained batch 1356 in epoch 6, gen_loss = 1.001365732602012, disc_loss = 0.0003978047414316316
Trained batch 1357 in epoch 6, gen_loss = 1.0013802950441926, disc_loss = 0.0003977643647138578
Trained batch 1358 in epoch 6, gen_loss = 1.00138840708687, disc_loss = 0.00039777457781325866
Trained batch 1359 in epoch 6, gen_loss = 1.0013334003879744, disc_loss = 0.00039779069139673514
Trained batch 1360 in epoch 6, gen_loss = 1.001359785461496, disc_loss = 0.00039777521273339525
Trained batch 1361 in epoch 6, gen_loss = 1.0013945724558024, disc_loss = 0.00039775349800139884
Trained batch 1362 in epoch 6, gen_loss = 1.0014159986838118, disc_loss = 0.0003977851713365265
Trained batch 1363 in epoch 6, gen_loss = 1.0014483727230703, disc_loss = 0.0003979070626504452
Trained batch 1364 in epoch 6, gen_loss = 1.001473509479355, disc_loss = 0.0003979955402445116
Trained batch 1365 in epoch 6, gen_loss = 1.0015099127592837, disc_loss = 0.0003981183845591411
Trained batch 1366 in epoch 6, gen_loss = 1.0015913543251194, disc_loss = 0.0003982573625769251
Trained batch 1367 in epoch 6, gen_loss = 1.0015665773324103, disc_loss = 0.0003984523027824178
Trained batch 1368 in epoch 6, gen_loss = 1.001459402398875, disc_loss = 0.00039864217989531755
Trained batch 1369 in epoch 6, gen_loss = 1.0014575546675355, disc_loss = 0.00039875705787626494
Trained batch 1370 in epoch 6, gen_loss = 1.0013530361313268, disc_loss = 0.00039876389727257954
Trained batch 1371 in epoch 6, gen_loss = 1.0013862878692394, disc_loss = 0.0003986932825091439
Trained batch 1372 in epoch 6, gen_loss = 1.0014026429821605, disc_loss = 0.0003985959138346121
Trained batch 1373 in epoch 6, gen_loss = 1.0013714269606133, disc_loss = 0.00039846841832414455
Trained batch 1374 in epoch 6, gen_loss = 1.0013555052930658, disc_loss = 0.00039829355685717683
Trained batch 1375 in epoch 6, gen_loss = 1.0013851017019777, disc_loss = 0.00039814841892261624
Trained batch 1376 in epoch 6, gen_loss = 1.00136145007896, disc_loss = 0.000397958371099832
Trained batch 1377 in epoch 6, gen_loss = 1.0014331701531984, disc_loss = 0.00039777613293485314
Trained batch 1378 in epoch 6, gen_loss = 1.001451153008293, disc_loss = 0.00039772145135692533
Trained batch 1379 in epoch 6, gen_loss = 1.0014047303061555, disc_loss = 0.0003978470862447453
Trained batch 1380 in epoch 6, gen_loss = 1.001374842203846, disc_loss = 0.000398087773409606
Trained batch 1381 in epoch 6, gen_loss = 1.001351056757953, disc_loss = 0.00039839105647185
Trained batch 1382 in epoch 6, gen_loss = 1.0013584031286398, disc_loss = 0.000398679715365327
Trained batch 1383 in epoch 6, gen_loss = 1.0013667699057243, disc_loss = 0.0003987334969999757
Trained batch 1384 in epoch 6, gen_loss = 1.0013238434757137, disc_loss = 0.0003985656153125729
Trained batch 1385 in epoch 6, gen_loss = 1.0012926639932576, disc_loss = 0.00039837848034398064
Trained batch 1386 in epoch 6, gen_loss = 1.001331248297138, disc_loss = 0.00039818292559353163
Trained batch 1387 in epoch 6, gen_loss = 1.0013400005332331, disc_loss = 0.00039799841380550965
Trained batch 1388 in epoch 6, gen_loss = 1.001316403209777, disc_loss = 0.00039783211532771345
Trained batch 1389 in epoch 6, gen_loss = 1.0012447774839057, disc_loss = 0.0003976343833822958
Trained batch 1390 in epoch 6, gen_loss = 1.001218562199862, disc_loss = 0.0003974722672763028
Trained batch 1391 in epoch 6, gen_loss = 1.0011493853967766, disc_loss = 0.0003973396925729681
Trained batch 1392 in epoch 6, gen_loss = 1.0010652573777887, disc_loss = 0.00039719861719993995
Trained batch 1393 in epoch 6, gen_loss = 1.0009928829700738, disc_loss = 0.0003969798792548858
Trained batch 1394 in epoch 6, gen_loss = 1.0009837444537857, disc_loss = 0.0003967452880477459
Trained batch 1395 in epoch 6, gen_loss = 1.0009659611990938, disc_loss = 0.00039655945485125545
Trained batch 1396 in epoch 6, gen_loss = 1.0009441067255986, disc_loss = 0.0003963994900509315
Trained batch 1397 in epoch 6, gen_loss = 1.0008963981752572, disc_loss = 0.0003961856186736171
Trained batch 1398 in epoch 6, gen_loss = 1.0008763547792359, disc_loss = 0.00039602133701197614
Trained batch 1399 in epoch 6, gen_loss = 1.0008947214058468, disc_loss = 0.00039586235313825976
Trained batch 1400 in epoch 6, gen_loss = 1.000962152555957, disc_loss = 0.00039566593747559424
Trained batch 1401 in epoch 6, gen_loss = 1.0009689240924982, disc_loss = 0.0003954937301399937
Trained batch 1402 in epoch 6, gen_loss = 1.000967907761134, disc_loss = 0.00039534865341377286
Trained batch 1403 in epoch 6, gen_loss = 1.0009620655381102, disc_loss = 0.00039527035798859897
Trained batch 1404 in epoch 6, gen_loss = 1.0009937802667719, disc_loss = 0.00039521274077117745
Trained batch 1405 in epoch 6, gen_loss = 1.0010489968537946, disc_loss = 0.0003951188343772327
Trained batch 1406 in epoch 6, gen_loss = 1.0010611511496847, disc_loss = 0.0003949731600298907
Trained batch 1407 in epoch 6, gen_loss = 1.0010854316960005, disc_loss = 0.00039478906217027543
Trained batch 1408 in epoch 6, gen_loss = 1.0010905992993233, disc_loss = 0.0003945854971449058
Trained batch 1409 in epoch 6, gen_loss = 1.0011498132073287, disc_loss = 0.00039438836700497656
Trained batch 1410 in epoch 6, gen_loss = 1.001229762988763, disc_loss = 0.0003941904993207688
Trained batch 1411 in epoch 6, gen_loss = 1.0012060500491442, disc_loss = 0.0003940170837981625
Trained batch 1412 in epoch 6, gen_loss = 1.001229025376071, disc_loss = 0.00039382115023254145
Trained batch 1413 in epoch 6, gen_loss = 1.0013626691222697, disc_loss = 0.0003936320286912019
Trained batch 1414 in epoch 6, gen_loss = 1.001314196022155, disc_loss = 0.00039346488005507986
Trained batch 1415 in epoch 6, gen_loss = 1.0012838811439984, disc_loss = 0.00039333713345004686
Trained batch 1416 in epoch 6, gen_loss = 1.001305407971333, disc_loss = 0.0003932671034107236
Trained batch 1417 in epoch 6, gen_loss = 1.0012442638995114, disc_loss = 0.0003932433313531184
Trained batch 1418 in epoch 6, gen_loss = 1.0012105120748933, disc_loss = 0.0003931523956046023
Trained batch 1419 in epoch 6, gen_loss = 1.0011273716117295, disc_loss = 0.0003930140047089826
Trained batch 1420 in epoch 6, gen_loss = 1.0011085259671113, disc_loss = 0.0003928532537797441
Trained batch 1421 in epoch 6, gen_loss = 1.0011324596220599, disc_loss = 0.0003926687649665361
Trained batch 1422 in epoch 6, gen_loss = 1.0011247287982799, disc_loss = 0.00039244877070680035
Trained batch 1423 in epoch 6, gen_loss = 1.001106732723753, disc_loss = 0.00039223807372886616
Trained batch 1424 in epoch 6, gen_loss = 1.0010944464750458, disc_loss = 0.0003920339948085153
Trained batch 1425 in epoch 6, gen_loss = 1.0011466364957506, disc_loss = 0.0003918319188673843
Trained batch 1426 in epoch 6, gen_loss = 1.0011137367631475, disc_loss = 0.00039160451792945273
Trained batch 1427 in epoch 6, gen_loss = 1.0011087803363132, disc_loss = 0.00039136923163930667
Trained batch 1428 in epoch 6, gen_loss = 1.0011500401710447, disc_loss = 0.0003911351398638602
Trained batch 1429 in epoch 6, gen_loss = 1.001158349872469, disc_loss = 0.000390888325855994
Trained batch 1430 in epoch 6, gen_loss = 1.001154118072395, disc_loss = 0.00039066559510877595
Trained batch 1431 in epoch 6, gen_loss = 1.0011546327498373, disc_loss = 0.00039046393699183744
Trained batch 1432 in epoch 6, gen_loss = 1.0012263490117186, disc_loss = 0.0003902713296145645
Trained batch 1433 in epoch 6, gen_loss = 1.0012877373598943, disc_loss = 0.00039012638846398664
Trained batch 1434 in epoch 6, gen_loss = 1.0012859575009097, disc_loss = 0.0003900464112872018
Trained batch 1435 in epoch 6, gen_loss = 1.0013310737845624, disc_loss = 0.0003901062906826107
Trained batch 1436 in epoch 6, gen_loss = 1.0014743375628876, disc_loss = 0.0003900893707224994
Trained batch 1437 in epoch 6, gen_loss = 1.0015894467625068, disc_loss = 0.0003901218213574891
Trained batch 1438 in epoch 6, gen_loss = 1.0016919969683973, disc_loss = 0.0003900319213703562
Trained batch 1439 in epoch 6, gen_loss = 1.001715357063545, disc_loss = 0.0003898961522685972
Trained batch 1440 in epoch 6, gen_loss = 1.0017547282719266, disc_loss = 0.0003897601245644927
Trained batch 1441 in epoch 6, gen_loss = 1.0017942884179987, disc_loss = 0.00038962323418516477
Trained batch 1442 in epoch 6, gen_loss = 1.0018426360393347, disc_loss = 0.00038955922749247504
Trained batch 1443 in epoch 6, gen_loss = 1.001874011928355, disc_loss = 0.0003895338885944854
Trained batch 1444 in epoch 6, gen_loss = 1.0018886888315934, disc_loss = 0.0003895368068225224
Trained batch 1445 in epoch 6, gen_loss = 1.0018346471245687, disc_loss = 0.0003894727152613968
Trained batch 1446 in epoch 6, gen_loss = 1.001811862362609, disc_loss = 0.0003893334317184713
Trained batch 1447 in epoch 6, gen_loss = 1.0018618845725586, disc_loss = 0.00038925180968724625
Trained batch 1448 in epoch 6, gen_loss = 1.001898683746409, disc_loss = 0.0003892318477467367
Trained batch 1449 in epoch 6, gen_loss = 1.001832019625039, disc_loss = 0.00038914276063161226
Trained batch 1450 in epoch 6, gen_loss = 1.0019318032971256, disc_loss = 0.0003891369973823298
Trained batch 1451 in epoch 6, gen_loss = 1.0019731136557155, disc_loss = 0.00038956261690173324
Trained batch 1452 in epoch 6, gen_loss = 1.002002245708736, disc_loss = 0.00039003698975679444
Trained batch 1453 in epoch 6, gen_loss = 1.0020249485969543, disc_loss = 0.0003903629178109392
Trained batch 1454 in epoch 6, gen_loss = 1.0020709156580396, disc_loss = 0.00039050378931703887
Trained batch 1455 in epoch 6, gen_loss = 1.0020709802488705, disc_loss = 0.0003904810938855427
Trained batch 1456 in epoch 6, gen_loss = 1.0020291987313092, disc_loss = 0.0003903625751133623
Trained batch 1457 in epoch 6, gen_loss = 1.0020478918473907, disc_loss = 0.00039023423266155706
Trained batch 1458 in epoch 6, gen_loss = 1.0019997702305083, disc_loss = 0.00039011202898608027
Trained batch 1459 in epoch 6, gen_loss = 1.0019702446379073, disc_loss = 0.00038994411997296145
Trained batch 1460 in epoch 6, gen_loss = 1.0018980846594328, disc_loss = 0.0003897782854916251
Trained batch 1461 in epoch 6, gen_loss = 1.0018727315434353, disc_loss = 0.00038967643150274303
Trained batch 1462 in epoch 6, gen_loss = 1.0020200051596453, disc_loss = 0.0003896300760985837
Trained batch 1463 in epoch 6, gen_loss = 1.0019442478978569, disc_loss = 0.0003895071432984605
Trained batch 1464 in epoch 6, gen_loss = 1.0020008763355606, disc_loss = 0.00038934401371563964
Trained batch 1465 in epoch 6, gen_loss = 1.001981073479698, disc_loss = 0.000389239120474298
Trained batch 1466 in epoch 6, gen_loss = 1.0019505646412439, disc_loss = 0.0003892039747056586
Trained batch 1467 in epoch 6, gen_loss = 1.0018896092267386, disc_loss = 0.00038910747533043964
Trained batch 1468 in epoch 6, gen_loss = 1.001892429091153, disc_loss = 0.0003889342188002881
Trained batch 1469 in epoch 6, gen_loss = 1.001815202244285, disc_loss = 0.00038875791302218487
Trained batch 1470 in epoch 6, gen_loss = 1.001883271881547, disc_loss = 0.00038858218045976774
Trained batch 1471 in epoch 6, gen_loss = 1.001881648948335, disc_loss = 0.00038840682902011156
Trained batch 1472 in epoch 6, gen_loss = 1.0018142193495134, disc_loss = 0.0003882783979057503
Trained batch 1473 in epoch 6, gen_loss = 1.0017643151564708, disc_loss = 0.00038818885599936864
Trained batch 1474 in epoch 6, gen_loss = 1.0017589078919362, disc_loss = 0.0003880946663843657
Trained batch 1475 in epoch 6, gen_loss = 1.0017747734862614, disc_loss = 0.000388066458439238
Trained batch 1476 in epoch 6, gen_loss = 1.0017662471665993, disc_loss = 0.00038807841049803306
Trained batch 1477 in epoch 6, gen_loss = 1.0017390376176176, disc_loss = 0.0003880859430803267
Trained batch 1478 in epoch 6, gen_loss = 1.0017339824582372, disc_loss = 0.0003880435136612662
Trained batch 1479 in epoch 6, gen_loss = 1.0016623653270103, disc_loss = 0.0003880385486735503
Trained batch 1480 in epoch 6, gen_loss = 1.001685410878853, disc_loss = 0.0003881704111725493
Trained batch 1481 in epoch 6, gen_loss = 1.0016853043585814, disc_loss = 0.00038840638420960266
Trained batch 1482 in epoch 6, gen_loss = 1.0016105937057465, disc_loss = 0.0003885604567923605
Trained batch 1483 in epoch 6, gen_loss = 1.0016014491612057, disc_loss = 0.00038866326533535035
Trained batch 1484 in epoch 6, gen_loss = 1.0016058439357514, disc_loss = 0.00038869823269375135
Trained batch 1485 in epoch 6, gen_loss = 1.0015504494971255, disc_loss = 0.00038863105800597894
Trained batch 1486 in epoch 6, gen_loss = 1.0015792020952934, disc_loss = 0.00038854460147682017
Trained batch 1487 in epoch 6, gen_loss = 1.001490912530371, disc_loss = 0.00038856956403853025
Trained batch 1488 in epoch 6, gen_loss = 1.0014706001416238, disc_loss = 0.00038879694555073917
Trained batch 1489 in epoch 6, gen_loss = 1.0014295866025373, disc_loss = 0.00038899694755556213
Trained batch 1490 in epoch 6, gen_loss = 1.001395422048332, disc_loss = 0.0003891344050572133
Trained batch 1491 in epoch 6, gen_loss = 1.001351457498668, disc_loss = 0.0003892397273653505
Trained batch 1492 in epoch 6, gen_loss = 1.0013553435101417, disc_loss = 0.00038934859028811225
Trained batch 1493 in epoch 6, gen_loss = 1.0013644917103819, disc_loss = 0.0003895457853816999
Trained batch 1494 in epoch 6, gen_loss = 1.001330548146098, disc_loss = 0.00038966912824705706
Trained batch 1495 in epoch 6, gen_loss = 1.001288872351621, disc_loss = 0.00038962269901339383
Trained batch 1496 in epoch 6, gen_loss = 1.001271239781109, disc_loss = 0.00038948578194826446
Trained batch 1497 in epoch 6, gen_loss = 1.0013122130856813, disc_loss = 0.00038925447454303004
Trained batch 1498 in epoch 6, gen_loss = 1.0013110774846932, disc_loss = 0.00038903388465391853
Trained batch 1499 in epoch 6, gen_loss = 1.0013128726085028, disc_loss = 0.000388832682321663
Trained batch 1500 in epoch 6, gen_loss = 1.0012343290406494, disc_loss = 0.00038865216850388583
Trained batch 1501 in epoch 6, gen_loss = 1.0011977108912207, disc_loss = 0.0003885150548977422
Trained batch 1502 in epoch 6, gen_loss = 1.0011846868101946, disc_loss = 0.0003883940283588539
Trained batch 1503 in epoch 6, gen_loss = 1.0012168880710577, disc_loss = 0.00038825138792762643
Trained batch 1504 in epoch 6, gen_loss = 1.0012016477378896, disc_loss = 0.00038808981263472475
Trained batch 1505 in epoch 6, gen_loss = 1.0011481586522157, disc_loss = 0.0003879085131941359
Trained batch 1506 in epoch 6, gen_loss = 1.0010637599028098, disc_loss = 0.0003877383916677494
Trained batch 1507 in epoch 6, gen_loss = 1.001063991249082, disc_loss = 0.0003875976705232982
Trained batch 1508 in epoch 6, gen_loss = 1.0010838813146588, disc_loss = 0.0003874817894457474
Trained batch 1509 in epoch 6, gen_loss = 1.0010563533432437, disc_loss = 0.00038732900197015587
Trained batch 1510 in epoch 6, gen_loss = 1.001022412515018, disc_loss = 0.0003871968720597277
Trained batch 1511 in epoch 6, gen_loss = 1.0010116265485527, disc_loss = 0.00038708610285750916
Trained batch 1512 in epoch 6, gen_loss = 1.0009897826368732, disc_loss = 0.0003869555931984538
Trained batch 1513 in epoch 6, gen_loss = 1.0009866569442194, disc_loss = 0.00038679274849279455
Trained batch 1514 in epoch 6, gen_loss = 1.0009970782220168, disc_loss = 0.00038660534025226006
Trained batch 1515 in epoch 6, gen_loss = 1.00105091992343, disc_loss = 0.0003864415014319851
Trained batch 1516 in epoch 6, gen_loss = 1.001070799840149, disc_loss = 0.0003862909235680815
Trained batch 1517 in epoch 6, gen_loss = 1.0010610955505974, disc_loss = 0.0003861448707004806
Trained batch 1518 in epoch 6, gen_loss = 1.0010796892085776, disc_loss = 0.00038600487159585784
Trained batch 1519 in epoch 6, gen_loss = 1.001050055497571, disc_loss = 0.00038584026175924105
Trained batch 1520 in epoch 6, gen_loss = 1.0011175134164734, disc_loss = 0.0003856851976805484
Trained batch 1521 in epoch 6, gen_loss = 1.0011143040563055, disc_loss = 0.00038559376789228935
Trained batch 1522 in epoch 6, gen_loss = 1.0011155105936473, disc_loss = 0.0003855515667460923
Trained batch 1523 in epoch 6, gen_loss = 1.0011196572949568, disc_loss = 0.00038549809667008796
Trained batch 1524 in epoch 6, gen_loss = 1.0011058340697991, disc_loss = 0.00038548072722270995
Trained batch 1525 in epoch 6, gen_loss = 1.0010947610103913, disc_loss = 0.00038545708230707757
Trained batch 1526 in epoch 6, gen_loss = 1.0010984308515098, disc_loss = 0.0003854773726037791
Trained batch 1527 in epoch 6, gen_loss = 1.0010847721190352, disc_loss = 0.00038557611779266077
Trained batch 1528 in epoch 6, gen_loss = 1.001078821460432, disc_loss = 0.0003856647970588336
Trained batch 1529 in epoch 6, gen_loss = 1.0010327284632166, disc_loss = 0.000385775359247977
Trained batch 1530 in epoch 6, gen_loss = 1.0010248212390753, disc_loss = 0.00038592618293145485
Trained batch 1531 in epoch 6, gen_loss = 1.0009480372421424, disc_loss = 0.0003858667323607833
Trained batch 1532 in epoch 6, gen_loss = 1.0008952237388626, disc_loss = 0.00038570722738519796
Trained batch 1533 in epoch 6, gen_loss = 1.0008252187689093, disc_loss = 0.00038561319993983263
Trained batch 1534 in epoch 6, gen_loss = 1.000799625393622, disc_loss = 0.00038552690822656147
Trained batch 1535 in epoch 6, gen_loss = 1.0007918984241162, disc_loss = 0.0003854279443894863
Trained batch 1536 in epoch 6, gen_loss = 1.000750777856359, disc_loss = 0.0003853860507921374
Trained batch 1537 in epoch 6, gen_loss = 1.0007000383382036, disc_loss = 0.0003852591281193984
Trained batch 1538 in epoch 6, gen_loss = 1.0007723031530449, disc_loss = 0.00038537539826537974
Trained batch 1539 in epoch 6, gen_loss = 1.000828427463383, disc_loss = 0.00038535818382481554
Trained batch 1540 in epoch 6, gen_loss = 1.000801908204031, disc_loss = 0.00038531250049261736
Trained batch 1541 in epoch 6, gen_loss = 1.000823960461969, disc_loss = 0.0003852823003667909
Trained batch 1542 in epoch 6, gen_loss = 1.0008167576187244, disc_loss = 0.00038561998022789177
Trained batch 1543 in epoch 6, gen_loss = 1.000740591880571, disc_loss = 0.0003862643661469458
Trained batch 1544 in epoch 6, gen_loss = 1.0006907510525973, disc_loss = 0.0003868457495657242
Trained batch 1545 in epoch 6, gen_loss = 1.000747316828983, disc_loss = 0.00038710840962611693
Trained batch 1546 in epoch 6, gen_loss = 1.0007341965676586, disc_loss = 0.0003871689907885963
Trained batch 1547 in epoch 6, gen_loss = 1.0006522135448086, disc_loss = 0.0003870930287527725
Trained batch 1548 in epoch 6, gen_loss = 1.000676315818932, disc_loss = 0.0003869233153327314
Trained batch 1549 in epoch 6, gen_loss = 1.000750909197715, disc_loss = 0.0003867537092329228
Trained batch 1550 in epoch 6, gen_loss = 1.000733733215615, disc_loss = 0.00038657309421973735
Trained batch 1551 in epoch 6, gen_loss = 1.0007616975488736, disc_loss = 0.00038639495716273175
Trained batch 1552 in epoch 6, gen_loss = 1.0008903904952928, disc_loss = 0.0003862321077169762
Trained batch 1553 in epoch 6, gen_loss = 1.0008749003345903, disc_loss = 0.0003860557829060947
Trained batch 1554 in epoch 6, gen_loss = 1.0008799125527261, disc_loss = 0.0003858870605762578
Trained batch 1555 in epoch 6, gen_loss = 1.000863795070538, disc_loss = 0.0003857224153360076
Trained batch 1556 in epoch 6, gen_loss = 1.000866944734761, disc_loss = 0.0003855583833386017
Trained batch 1557 in epoch 6, gen_loss = 1.000854850159683, disc_loss = 0.0003853865173427207
Trained batch 1558 in epoch 6, gen_loss = 1.0008077120230394, disc_loss = 0.00038525511379264245
Trained batch 1559 in epoch 6, gen_loss = 1.0008217400847337, disc_loss = 0.00038517410527837896
Trained batch 1560 in epoch 6, gen_loss = 1.00085587172383, disc_loss = 0.0003850590480019966
Trained batch 1561 in epoch 6, gen_loss = 1.0009284116776134, disc_loss = 0.00038495761129359545
Trained batch 1562 in epoch 6, gen_loss = 1.0009653332976294, disc_loss = 0.0003848846176055931
Trained batch 1563 in epoch 6, gen_loss = 1.0009428963560583, disc_loss = 0.00038480023410540615
Trained batch 1564 in epoch 6, gen_loss = 1.0009663712483245, disc_loss = 0.00038468489085771176
Trained batch 1565 in epoch 6, gen_loss = 1.000992801720764, disc_loss = 0.00038454947143702856
Trained batch 1566 in epoch 6, gen_loss = 1.000913569215155, disc_loss = 0.00038442538188405344
Trained batch 1567 in epoch 6, gen_loss = 1.0008902759196199, disc_loss = 0.00038427199306819863
Trained batch 1568 in epoch 6, gen_loss = 1.0007648656442714, disc_loss = 0.0003841659459601147
Trained batch 1569 in epoch 6, gen_loss = 1.000760349650292, disc_loss = 0.00038416108631756556
Trained batch 1570 in epoch 6, gen_loss = 1.0007988698614547, disc_loss = 0.0003841181461367549
Trained batch 1571 in epoch 6, gen_loss = 1.0007823598748855, disc_loss = 0.00038403101663682675
Trained batch 1572 in epoch 6, gen_loss = 1.0007917908294446, disc_loss = 0.00038392006683568764
Trained batch 1573 in epoch 6, gen_loss = 1.0008392972443276, disc_loss = 0.0003837894204886896
Trained batch 1574 in epoch 6, gen_loss = 1.0007630532885354, disc_loss = 0.0003836482764630105
Trained batch 1575 in epoch 6, gen_loss = 1.0008304445876688, disc_loss = 0.0003835044197118348
Trained batch 1576 in epoch 6, gen_loss = 1.0010933469350232, disc_loss = 0.0003834200544891741
Trained batch 1577 in epoch 6, gen_loss = 1.001216297291682, disc_loss = 0.0003833523242917996
Trained batch 1578 in epoch 6, gen_loss = 1.0012632326056037, disc_loss = 0.000383276662266301
Trained batch 1579 in epoch 6, gen_loss = 1.0012874631187585, disc_loss = 0.00038317590984615315
Trained batch 1580 in epoch 6, gen_loss = 1.0012663953444536, disc_loss = 0.00038307669562425914
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.013641595840454, disc_loss = 0.0002717051247600466
Trained batch 1 in epoch 7, gen_loss = 1.016978919506073, disc_loss = 0.00032196586835198104
Trained batch 2 in epoch 7, gen_loss = 1.0232234001159668, disc_loss = 0.0002853984624380246
Trained batch 3 in epoch 7, gen_loss = 1.0172113329172134, disc_loss = 0.00025546789402142167
Trained batch 4 in epoch 7, gen_loss = 1.0403080582618713, disc_loss = 0.00023398230841849
Trained batch 5 in epoch 7, gen_loss = 1.0539467831452687, disc_loss = 0.00022210200889579332
Trained batch 6 in epoch 7, gen_loss = 1.0619046092033386, disc_loss = 0.0002088508876373193
Trained batch 7 in epoch 7, gen_loss = 1.0667186304926872, disc_loss = 0.00019836542378470767
Trained batch 8 in epoch 7, gen_loss = 1.0714492864078946, disc_loss = 0.00018424203315387585
Trained batch 9 in epoch 7, gen_loss = 1.0653874814510345, disc_loss = 0.00017160799252451396
Trained batch 10 in epoch 7, gen_loss = 1.0691391283815557, disc_loss = 0.0001654601080438376
Trained batch 11 in epoch 7, gen_loss = 1.0575735916694005, disc_loss = 0.00016442192342462172
Trained batch 12 in epoch 7, gen_loss = 1.0488828741587126, disc_loss = 0.0001663143053659811
Trained batch 13 in epoch 7, gen_loss = 1.0451622435024805, disc_loss = 0.00017212600765300782
Trained batch 14 in epoch 7, gen_loss = 1.0413092891375224, disc_loss = 0.00018050897100086634
Trained batch 15 in epoch 7, gen_loss = 1.0407778732478619, disc_loss = 0.00018486383351046243
Trained batch 16 in epoch 7, gen_loss = 1.0375671667211197, disc_loss = 0.00018298142522861084
Trained batch 17 in epoch 7, gen_loss = 1.03659102651808, disc_loss = 0.00018038166429808675
Trained batch 18 in epoch 7, gen_loss = 1.035744503924721, disc_loss = 0.00017979406440740844
Trained batch 19 in epoch 7, gen_loss = 1.033100074529648, disc_loss = 0.0001776532251824392
Trained batch 20 in epoch 7, gen_loss = 1.032690235546657, disc_loss = 0.0001746112694880659
Trained batch 21 in epoch 7, gen_loss = 1.0283746909011493, disc_loss = 0.0001723768486540807
Trained batch 22 in epoch 7, gen_loss = 1.0247167374776758, disc_loss = 0.0001695812404606208
Trained batch 23 in epoch 7, gen_loss = 1.020153932273388, disc_loss = 0.00016613179316967339
Trained batch 24 in epoch 7, gen_loss = 1.0194746804237367, disc_loss = 0.00016176350050955079
Trained batch 25 in epoch 7, gen_loss = 1.016787907251945, disc_loss = 0.0001582526105126957
Trained batch 26 in epoch 7, gen_loss = 1.0148436559571161, disc_loss = 0.0001561918183546772
Trained batch 27 in epoch 7, gen_loss = 1.0181996886219298, disc_loss = 0.00015763841020088876
Trained batch 28 in epoch 7, gen_loss = 1.0198358564541257, disc_loss = 0.00016083702199654813
Trained batch 29 in epoch 7, gen_loss = 1.0200739363829294, disc_loss = 0.00016256886677486668
Trained batch 30 in epoch 7, gen_loss = 1.0214280601470702, disc_loss = 0.00016259140372107316
Trained batch 31 in epoch 7, gen_loss = 1.0201784800738096, disc_loss = 0.0001629918168646327
Trained batch 32 in epoch 7, gen_loss = 1.023210422559218, disc_loss = 0.000165444038429996
Trained batch 33 in epoch 7, gen_loss = 1.0231613288907444, disc_loss = 0.0001708610822842114
Trained batch 34 in epoch 7, gen_loss = 1.020359400340489, disc_loss = 0.0001758019497044318
Trained batch 35 in epoch 7, gen_loss = 1.0183666663037405, disc_loss = 0.00017996495676521186
Trained batch 36 in epoch 7, gen_loss = 1.021447470059266, disc_loss = 0.00018304659553561233
Trained batch 37 in epoch 7, gen_loss = 1.020204385644511, disc_loss = 0.00018529112266581874
Trained batch 38 in epoch 7, gen_loss = 1.0196665005806165, disc_loss = 0.00018663886322218997
Trained batch 39 in epoch 7, gen_loss = 1.0195757925510407, disc_loss = 0.00018836556109818047
Trained batch 40 in epoch 7, gen_loss = 1.017144179925686, disc_loss = 0.00019072774624119784
Trained batch 41 in epoch 7, gen_loss = 1.0171516679582142, disc_loss = 0.00019203594092687126
Trained batch 42 in epoch 7, gen_loss = 1.0173274084579114, disc_loss = 0.00019270006279924038
Trained batch 43 in epoch 7, gen_loss = 1.0150622075254268, disc_loss = 0.00019338687302065821
Trained batch 44 in epoch 7, gen_loss = 1.015359542104933, disc_loss = 0.00019436478477372375
Trained batch 45 in epoch 7, gen_loss = 1.0158942497294883, disc_loss = 0.00019527166572832198
Trained batch 46 in epoch 7, gen_loss = 1.01753409619027, disc_loss = 0.00019697434920012613
Trained batch 47 in epoch 7, gen_loss = 1.0147642542918522, disc_loss = 0.00020045231205282713
Trained batch 48 in epoch 7, gen_loss = 1.0171947673875459, disc_loss = 0.00020522850068768354
Trained batch 49 in epoch 7, gen_loss = 1.015032128095627, disc_loss = 0.00021111172500241083
Trained batch 50 in epoch 7, gen_loss = 1.0135036695237254, disc_loss = 0.0002194732089051018
Trained batch 51 in epoch 7, gen_loss = 1.0122075963478823, disc_loss = 0.00022848993152225515
Trained batch 52 in epoch 7, gen_loss = 1.013549490919653, disc_loss = 0.00023584877230602597
Trained batch 53 in epoch 7, gen_loss = 1.013240420156055, disc_loss = 0.00024183258338544638
Trained batch 54 in epoch 7, gen_loss = 1.0134223276918584, disc_loss = 0.0002452400845703034
Trained batch 55 in epoch 7, gen_loss = 1.0136814873133386, disc_loss = 0.0002467460720773878
Trained batch 56 in epoch 7, gen_loss = 1.0123698439514428, disc_loss = 0.00024782063324860166
Trained batch 57 in epoch 7, gen_loss = 1.0114823107061715, disc_loss = 0.00024897671410771777
Trained batch 58 in epoch 7, gen_loss = 1.009798838930615, disc_loss = 0.0002502533478314112
Trained batch 59 in epoch 7, gen_loss = 1.0086201677719753, disc_loss = 0.0002542864171725038
Trained batch 60 in epoch 7, gen_loss = 1.010348500775509, disc_loss = 0.00025999002232832727
Trained batch 61 in epoch 7, gen_loss = 1.0098625738774576, disc_loss = 0.00026627974822927613
Trained batch 62 in epoch 7, gen_loss = 1.011672384209103, disc_loss = 0.0002706346493228228
Trained batch 63 in epoch 7, gen_loss = 1.0109922401607037, disc_loss = 0.00027143477694835383
Trained batch 64 in epoch 7, gen_loss = 1.0108194699654212, disc_loss = 0.0002700965676362662
Trained batch 65 in epoch 7, gen_loss = 1.0113745115020059, disc_loss = 0.0002679916406398688
Trained batch 66 in epoch 7, gen_loss = 1.0102199654080974, disc_loss = 0.0002661612822127758
Trained batch 67 in epoch 7, gen_loss = 1.0107427029048695, disc_loss = 0.0002645889616734862
Trained batch 68 in epoch 7, gen_loss = 1.0091666553331458, disc_loss = 0.000263780390831517
Trained batch 69 in epoch 7, gen_loss = 1.009609968321664, disc_loss = 0.0002662231346870872
Trained batch 70 in epoch 7, gen_loss = 1.0086704366643664, disc_loss = 0.0002728730028074622
Trained batch 71 in epoch 7, gen_loss = 1.0089374507466953, disc_loss = 0.00028387312012354314
Trained batch 72 in epoch 7, gen_loss = 1.0087519598333803, disc_loss = 0.0002971496057759632
Trained batch 73 in epoch 7, gen_loss = 1.0083817751020998, disc_loss = 0.0003051176002839851
Trained batch 74 in epoch 7, gen_loss = 1.0078865520159404, disc_loss = 0.00030721834778281237
Trained batch 75 in epoch 7, gen_loss = 1.0076136973343397, disc_loss = 0.00030544536577125606
Trained batch 76 in epoch 7, gen_loss = 1.0080114579820014, disc_loss = 0.00030421470657600297
Trained batch 77 in epoch 7, gen_loss = 1.0077257591944475, disc_loss = 0.00030383909600063
Trained batch 78 in epoch 7, gen_loss = 1.0085370487804655, disc_loss = 0.0003031255526573521
Trained batch 79 in epoch 7, gen_loss = 1.0077280715107917, disc_loss = 0.00030131110138427176
Trained batch 80 in epoch 7, gen_loss = 1.0083245980886766, disc_loss = 0.0002992578083200145
Trained batch 81 in epoch 7, gen_loss = 1.0092794691644065, disc_loss = 0.00029833749923876364
Trained batch 82 in epoch 7, gen_loss = 1.0082236298595566, disc_loss = 0.00029765992755517755
Trained batch 83 in epoch 7, gen_loss = 1.00711105125291, disc_loss = 0.00029647631557357573
Trained batch 84 in epoch 7, gen_loss = 1.006926874553456, disc_loss = 0.00029497397665502776
Trained batch 85 in epoch 7, gen_loss = 1.006108893904575, disc_loss = 0.0002934278973678078
Trained batch 86 in epoch 7, gen_loss = 1.00694722279735, disc_loss = 0.0002921589945182713
Trained batch 87 in epoch 7, gen_loss = 1.0064340233802795, disc_loss = 0.0002906955014209829
Trained batch 88 in epoch 7, gen_loss = 1.0054186595959609, disc_loss = 0.0002891844727692137
Trained batch 89 in epoch 7, gen_loss = 1.0050747050179376, disc_loss = 0.00028778571266027735
Trained batch 90 in epoch 7, gen_loss = 1.0053825011620154, disc_loss = 0.00028621230080466627
Trained batch 91 in epoch 7, gen_loss = 1.0057225382846335, disc_loss = 0.0002847406822974849
Trained batch 92 in epoch 7, gen_loss = 1.0049728437136578, disc_loss = 0.00028344932082203036
Trained batch 93 in epoch 7, gen_loss = 1.0055563893723996, disc_loss = 0.0002819678397150091
Trained batch 94 in epoch 7, gen_loss = 1.005207079335263, disc_loss = 0.00028010785459436623
Trained batch 95 in epoch 7, gen_loss = 1.0057337333758671, disc_loss = 0.00027873186274973705
Trained batch 96 in epoch 7, gen_loss = 1.0050666258507168, disc_loss = 0.0002775029136397823
Trained batch 97 in epoch 7, gen_loss = 1.0038120935157853, disc_loss = 0.00027589711335538746
Trained batch 98 in epoch 7, gen_loss = 1.0045311758012483, disc_loss = 0.00027470168597482363
Trained batch 99 in epoch 7, gen_loss = 1.0043532478809356, disc_loss = 0.0002730388201234746
Trained batch 100 in epoch 7, gen_loss = 1.0034961063082855, disc_loss = 0.0002710369384532338
Trained batch 101 in epoch 7, gen_loss = 1.0049855101342295, disc_loss = 0.0002703642501229279
Trained batch 102 in epoch 7, gen_loss = 1.005105616976914, disc_loss = 0.00027387524273012563
Trained batch 103 in epoch 7, gen_loss = 1.0052182720257685, disc_loss = 0.00027701814532030345
Trained batch 104 in epoch 7, gen_loss = 1.0040651940164111, disc_loss = 0.0002787216099802338
Trained batch 105 in epoch 7, gen_loss = 1.0036699316411648, disc_loss = 0.0002792073088164885
Trained batch 106 in epoch 7, gen_loss = 1.0037446016463163, disc_loss = 0.00028004200284387784
Trained batch 107 in epoch 7, gen_loss = 1.0032168996554833, disc_loss = 0.0002845808810350179
Trained batch 108 in epoch 7, gen_loss = 1.0033587900870438, disc_loss = 0.0002916114841154755
Trained batch 109 in epoch 7, gen_loss = 1.0034324185414747, disc_loss = 0.00029751232323178557
Trained batch 110 in epoch 7, gen_loss = 1.0036682916117143, disc_loss = 0.00030243130068966976
Trained batch 111 in epoch 7, gen_loss = 1.0039220095745154, disc_loss = 0.0003080830908857024
Trained batch 112 in epoch 7, gen_loss = 1.0034402951730037, disc_loss = 0.0003141605439021528
Trained batch 113 in epoch 7, gen_loss = 1.0037333520880916, disc_loss = 0.0003180724045370497
Trained batch 114 in epoch 7, gen_loss = 1.0034078950467318, disc_loss = 0.0003214264755787672
Trained batch 115 in epoch 7, gen_loss = 1.00358657076441, disc_loss = 0.0003240662879385315
Trained batch 116 in epoch 7, gen_loss = 1.0046821537180843, disc_loss = 0.00032459558789348666
Trained batch 117 in epoch 7, gen_loss = 1.0038443773479786, disc_loss = 0.0003242294623290082
Trained batch 118 in epoch 7, gen_loss = 1.002865089087927, disc_loss = 0.00032297666997188005
Trained batch 119 in epoch 7, gen_loss = 1.002876232067744, disc_loss = 0.00032144160750249286
Trained batch 120 in epoch 7, gen_loss = 1.0027503794875026, disc_loss = 0.0003198425449137018
Trained batch 121 in epoch 7, gen_loss = 1.0021265715849204, disc_loss = 0.000318445451277333
Trained batch 122 in epoch 7, gen_loss = 1.0018083666398274, disc_loss = 0.00031769561418166527
Trained batch 123 in epoch 7, gen_loss = 1.0012050025886106, disc_loss = 0.00031710796414582515
Trained batch 124 in epoch 7, gen_loss = 1.0011696200370788, disc_loss = 0.0003163102446414996
Trained batch 125 in epoch 7, gen_loss = 1.0019647370255182, disc_loss = 0.0003148535588335353
Trained batch 126 in epoch 7, gen_loss = 1.0013227795991373, disc_loss = 0.00031304914531445565
Trained batch 127 in epoch 7, gen_loss = 1.0015278882347047, disc_loss = 0.000311576888776699
Trained batch 128 in epoch 7, gen_loss = 1.0019902457562528, disc_loss = 0.00031179452329976014
Trained batch 129 in epoch 7, gen_loss = 1.0013442232058598, disc_loss = 0.00031182146398910283
Trained batch 130 in epoch 7, gen_loss = 1.0016548606275602, disc_loss = 0.0003109302572856696
Trained batch 131 in epoch 7, gen_loss = 1.0016014964291544, disc_loss = 0.00030973801274354406
Trained batch 132 in epoch 7, gen_loss = 1.0013350190076613, disc_loss = 0.0003087552901608187
Trained batch 133 in epoch 7, gen_loss = 1.000768821630905, disc_loss = 0.00030902017476649627
Trained batch 134 in epoch 7, gen_loss = 1.0008497767978244, disc_loss = 0.0003102377383954633
Trained batch 135 in epoch 7, gen_loss = 1.0004420929095323, disc_loss = 0.0003108993167135101
Trained batch 136 in epoch 7, gen_loss = 0.9998223973016669, disc_loss = 0.00031094014042683363
Trained batch 137 in epoch 7, gen_loss = 0.9998608412949935, disc_loss = 0.0003104041183362732
Trained batch 138 in epoch 7, gen_loss = 0.9991436420584754, disc_loss = 0.0003098795116804088
Trained batch 139 in epoch 7, gen_loss = 0.9990927887814386, disc_loss = 0.0003091091481629909
Trained batch 140 in epoch 7, gen_loss = 0.9985563615535168, disc_loss = 0.00030787485709569935
Trained batch 141 in epoch 7, gen_loss = 0.9993276927672642, disc_loss = 0.00030639704107696315
Trained batch 142 in epoch 7, gen_loss = 0.9997472717211797, disc_loss = 0.00030505315569482607
Trained batch 143 in epoch 7, gen_loss = 0.9998164528773891, disc_loss = 0.0003051498983192384
Trained batch 144 in epoch 7, gen_loss = 0.9998884032512533, disc_loss = 0.00030865367621901957
Trained batch 145 in epoch 7, gen_loss = 0.9995626043783475, disc_loss = 0.0003122440819125798
Trained batch 146 in epoch 7, gen_loss = 0.9992892973277033, disc_loss = 0.00031546142425361966
Trained batch 147 in epoch 7, gen_loss = 0.9989618816085764, disc_loss = 0.00031867507707805063
Trained batch 148 in epoch 7, gen_loss = 0.9986900851230494, disc_loss = 0.00032143812749559064
Trained batch 149 in epoch 7, gen_loss = 0.998225197394689, disc_loss = 0.0003241406300367089
Trained batch 150 in epoch 7, gen_loss = 0.9982455428072948, disc_loss = 0.00032769850214202394
Trained batch 151 in epoch 7, gen_loss = 0.9992687862954641, disc_loss = 0.0003362900350734172
Trained batch 152 in epoch 7, gen_loss = 0.9992746983478272, disc_loss = 0.00035664135881899734
Trained batch 153 in epoch 7, gen_loss = 0.9996076934523397, disc_loss = 0.00037196236964471657
Trained batch 154 in epoch 7, gen_loss = 0.9987270220633476, disc_loss = 0.0003779089736194545
Trained batch 155 in epoch 7, gen_loss = 0.9987239222495984, disc_loss = 0.0003798385834250859
Trained batch 156 in epoch 7, gen_loss = 0.9990153339258425, disc_loss = 0.0003796854256576292
Trained batch 157 in epoch 7, gen_loss = 0.9987626698198198, disc_loss = 0.00037914519466712476
Trained batch 158 in epoch 7, gen_loss = 0.9991865011880983, disc_loss = 0.000378131009333543
Trained batch 159 in epoch 7, gen_loss = 0.9985774412751198, disc_loss = 0.00037640720645413237
Trained batch 160 in epoch 7, gen_loss = 0.9978657064970976, disc_loss = 0.0003747381951205464
Trained batch 161 in epoch 7, gen_loss = 0.9979153356434386, disc_loss = 0.0003740526460688547
Trained batch 162 in epoch 7, gen_loss = 0.9978595120043843, disc_loss = 0.000375706661560257
Trained batch 163 in epoch 7, gen_loss = 0.9977110257235969, disc_loss = 0.0003778105031792287
Trained batch 164 in epoch 7, gen_loss = 0.9979180216789245, disc_loss = 0.0003785615841369497
Trained batch 165 in epoch 7, gen_loss = 0.9980455518486988, disc_loss = 0.0003787388066550456
Trained batch 166 in epoch 7, gen_loss = 0.9973600799452045, disc_loss = 0.0003779147494182445
Trained batch 167 in epoch 7, gen_loss = 0.9972486946554411, disc_loss = 0.0003767789237697018
Trained batch 168 in epoch 7, gen_loss = 0.9970250344840732, disc_loss = 0.0003756004798399304
Trained batch 169 in epoch 7, gen_loss = 0.9975682556629181, disc_loss = 0.0003748996066646856
Trained batch 170 in epoch 7, gen_loss = 0.997379109524844, disc_loss = 0.0003744454261748466
Trained batch 171 in epoch 7, gen_loss = 0.9971503182206043, disc_loss = 0.00037437323837451024
Trained batch 172 in epoch 7, gen_loss = 0.9967897882351296, disc_loss = 0.0003743638952841075
Trained batch 173 in epoch 7, gen_loss = 0.9969642176025215, disc_loss = 0.00037395817643060247
Trained batch 174 in epoch 7, gen_loss = 0.99688659123012, disc_loss = 0.000373160067392746
Trained batch 175 in epoch 7, gen_loss = 0.9968201805922118, disc_loss = 0.0003722812408051885
Trained batch 176 in epoch 7, gen_loss = 0.997263021051547, disc_loss = 0.00037185525510372665
Trained batch 177 in epoch 7, gen_loss = 0.9968127075875743, disc_loss = 0.00037193973808274
Trained batch 178 in epoch 7, gen_loss = 0.9966190344128529, disc_loss = 0.00037040835474965724
Trained batch 179 in epoch 7, gen_loss = 0.9961867951684528, disc_loss = 0.00036912590033656066
Trained batch 180 in epoch 7, gen_loss = 0.9964641335919417, disc_loss = 0.0003676591015130459
Trained batch 181 in epoch 7, gen_loss = 0.9956975431887658, disc_loss = 0.0003666065155042676
Trained batch 182 in epoch 7, gen_loss = 0.9960822892970727, disc_loss = 0.00036792640921057333
Trained batch 183 in epoch 7, gen_loss = 0.9960207641124725, disc_loss = 0.0003689701217373785
Trained batch 184 in epoch 7, gen_loss = 0.9959792185474087, disc_loss = 0.0003692537518037244
Trained batch 185 in epoch 7, gen_loss = 0.9954038778299926, disc_loss = 0.0003687816015665322
Trained batch 186 in epoch 7, gen_loss = 0.9956327973202588, disc_loss = 0.0003679377662976967
Trained batch 187 in epoch 7, gen_loss = 0.996213141590991, disc_loss = 0.0003670965796195657
Trained batch 188 in epoch 7, gen_loss = 0.9963267483408489, disc_loss = 0.00036646663237849085
Trained batch 189 in epoch 7, gen_loss = 0.996179375523015, disc_loss = 0.00036625865799770076
Trained batch 190 in epoch 7, gen_loss = 0.9960238303189503, disc_loss = 0.000365539940631935
Trained batch 191 in epoch 7, gen_loss = 0.9953488189106187, disc_loss = 0.00036456460901490573
Trained batch 192 in epoch 7, gen_loss = 0.9955539372918519, disc_loss = 0.0003638019539071114
Trained batch 193 in epoch 7, gen_loss = 0.9957522144637156, disc_loss = 0.0003630070351419752
Trained batch 194 in epoch 7, gen_loss = 0.9956382454969944, disc_loss = 0.00036212440614830343
Trained batch 195 in epoch 7, gen_loss = 0.9956336182599165, disc_loss = 0.0003611388327935485
Trained batch 196 in epoch 7, gen_loss = 0.9954721407236786, disc_loss = 0.00036008029230731435
Trained batch 197 in epoch 7, gen_loss = 0.9960238277310073, disc_loss = 0.0003591671824636646
Trained batch 198 in epoch 7, gen_loss = 0.9959596209789641, disc_loss = 0.000358149032498243
Trained batch 199 in epoch 7, gen_loss = 0.9958885741233826, disc_loss = 0.0003577937546106114
Trained batch 200 in epoch 7, gen_loss = 0.9957759466337327, disc_loss = 0.00036084439034764286
Trained batch 201 in epoch 7, gen_loss = 0.9952076340075766, disc_loss = 0.00036593067620337437
Trained batch 202 in epoch 7, gen_loss = 0.9955600174189788, disc_loss = 0.0003690734502821851
Trained batch 203 in epoch 7, gen_loss = 0.9958110922107509, disc_loss = 0.000369587665862163
Trained batch 204 in epoch 7, gen_loss = 0.9956149115795042, disc_loss = 0.0003690432459889718
Trained batch 205 in epoch 7, gen_loss = 0.9951300091535142, disc_loss = 0.0003679572887758519
Trained batch 206 in epoch 7, gen_loss = 0.9956968409427698, disc_loss = 0.00036748938084535577
Trained batch 207 in epoch 7, gen_loss = 0.9955988469032141, disc_loss = 0.00036833038933974213
Trained batch 208 in epoch 7, gen_loss = 0.9957189616974461, disc_loss = 0.0003692213041268113
Trained batch 209 in epoch 7, gen_loss = 0.9959152011644272, disc_loss = 0.0003699933806014347
Trained batch 210 in epoch 7, gen_loss = 0.9957016034148881, disc_loss = 0.0003710656647849883
Trained batch 211 in epoch 7, gen_loss = 0.9954424522957712, disc_loss = 0.0003713627175389809
Trained batch 212 in epoch 7, gen_loss = 0.99523973129165, disc_loss = 0.00037070367075166743
Trained batch 213 in epoch 7, gen_loss = 0.9956251956592096, disc_loss = 0.0003697180740023086
Trained batch 214 in epoch 7, gen_loss = 0.9958076671112416, disc_loss = 0.0003687660699354236
Trained batch 215 in epoch 7, gen_loss = 0.9961693800157971, disc_loss = 0.00036791578809748497
Trained batch 216 in epoch 7, gen_loss = 0.9960141780739007, disc_loss = 0.00036689349744763454
Trained batch 217 in epoch 7, gen_loss = 0.996523544329022, disc_loss = 0.0003661427200071507
Trained batch 218 in epoch 7, gen_loss = 0.996619375873374, disc_loss = 0.0003659784383111002
Trained batch 219 in epoch 7, gen_loss = 0.9963124432347038, disc_loss = 0.00036615831302862554
Trained batch 220 in epoch 7, gen_loss = 0.996103727979358, disc_loss = 0.00036618909357725093
Trained batch 221 in epoch 7, gen_loss = 0.9962037259393984, disc_loss = 0.0003663449116248631
Trained batch 222 in epoch 7, gen_loss = 0.9961845634229515, disc_loss = 0.0003664766366948789
Trained batch 223 in epoch 7, gen_loss = 0.9959210157394409, disc_loss = 0.0003666561845453283
Trained batch 224 in epoch 7, gen_loss = 0.9960893779330784, disc_loss = 0.0003668240041426745
Trained batch 225 in epoch 7, gen_loss = 0.9958226211303103, disc_loss = 0.000366381276311972
Trained batch 226 in epoch 7, gen_loss = 0.9956321238421133, disc_loss = 0.00036556193440506903
Trained batch 227 in epoch 7, gen_loss = 0.9956055388116, disc_loss = 0.00036442762937663806
Trained batch 228 in epoch 7, gen_loss = 0.9950369146192959, disc_loss = 0.0003633540614812348
Trained batch 229 in epoch 7, gen_loss = 0.9946329264537148, disc_loss = 0.0003624267944004437
Trained batch 230 in epoch 7, gen_loss = 0.9948784130992312, disc_loss = 0.00036147488359559944
Trained batch 231 in epoch 7, gen_loss = 0.994724720973393, disc_loss = 0.0003602860318347541
Trained batch 232 in epoch 7, gen_loss = 0.9946131831586617, disc_loss = 0.00035934417326237645
Trained batch 233 in epoch 7, gen_loss = 0.9951175856284606, disc_loss = 0.0003583407405651678
Trained batch 234 in epoch 7, gen_loss = 0.994890847104661, disc_loss = 0.0003573293281078804
Trained batch 235 in epoch 7, gen_loss = 0.9948513677059594, disc_loss = 0.00035631109545585974
Trained batch 236 in epoch 7, gen_loss = 0.9947954489208978, disc_loss = 0.0003552086580131362
Trained batch 237 in epoch 7, gen_loss = 0.9947282752069104, disc_loss = 0.00035413808760464586
Trained batch 238 in epoch 7, gen_loss = 0.9949289176254592, disc_loss = 0.000353282612530348
Trained batch 239 in epoch 7, gen_loss = 0.9941043163339297, disc_loss = 0.00035527489024692234
Trained batch 240 in epoch 7, gen_loss = 0.9936261142437883, disc_loss = 0.00035781014106669697
Trained batch 241 in epoch 7, gen_loss = 0.9933349608389799, disc_loss = 0.000359277958500758
Trained batch 242 in epoch 7, gen_loss = 0.9932734301551379, disc_loss = 0.0003594217509868001
Trained batch 243 in epoch 7, gen_loss = 0.9935750748778953, disc_loss = 0.0003597144589056385
Trained batch 244 in epoch 7, gen_loss = 0.9937641851756037, disc_loss = 0.0003597068462113384
Trained batch 245 in epoch 7, gen_loss = 0.9938908027924174, disc_loss = 0.0003594035218164327
Trained batch 246 in epoch 7, gen_loss = 0.993858842473281, disc_loss = 0.0003592284417765164
Trained batch 247 in epoch 7, gen_loss = 0.9936485456362847, disc_loss = 0.0003595511599204685
Trained batch 248 in epoch 7, gen_loss = 0.9934421406692291, disc_loss = 0.0003594182442714054
Trained batch 249 in epoch 7, gen_loss = 0.9934045457839966, disc_loss = 0.00035868056218896525
Trained batch 250 in epoch 7, gen_loss = 0.9936013744171872, disc_loss = 0.0003577975980318068
Trained batch 251 in epoch 7, gen_loss = 0.9934580056440263, disc_loss = 0.0003571139427188586
Trained batch 252 in epoch 7, gen_loss = 0.9932014640612093, disc_loss = 0.00035664779786630203
Trained batch 253 in epoch 7, gen_loss = 0.9933720634678217, disc_loss = 0.00035582639403995513
Trained batch 254 in epoch 7, gen_loss = 0.9935044017492556, disc_loss = 0.0003550039066884018
Trained batch 255 in epoch 7, gen_loss = 0.9937174050137401, disc_loss = 0.0003540944233151322
Trained batch 256 in epoch 7, gen_loss = 0.9940161333937589, disc_loss = 0.000353052702126866
Trained batch 257 in epoch 7, gen_loss = 0.9940631611402645, disc_loss = 0.0003519999281424973
Trained batch 258 in epoch 7, gen_loss = 0.9941419008615855, disc_loss = 0.00035098047940113086
Trained batch 259 in epoch 7, gen_loss = 0.9938651990432006, disc_loss = 0.0003501118683673737
Trained batch 260 in epoch 7, gen_loss = 0.9935055742775344, disc_loss = 0.00034962537351041634
Trained batch 261 in epoch 7, gen_loss = 0.9937236459200619, disc_loss = 0.00034958739286052677
Trained batch 262 in epoch 7, gen_loss = 0.9938047661980749, disc_loss = 0.00035012149580494506
Trained batch 263 in epoch 7, gen_loss = 0.9936380207990155, disc_loss = 0.00035079963390671765
Trained batch 264 in epoch 7, gen_loss = 0.9936186381106107, disc_loss = 0.00035130775256031894
Trained batch 265 in epoch 7, gen_loss = 0.9938974967576507, disc_loss = 0.0003515266149557113
Trained batch 266 in epoch 7, gen_loss = 0.9945395751838827, disc_loss = 0.000351317870454738
Trained batch 267 in epoch 7, gen_loss = 0.9942233782650819, disc_loss = 0.0003507379115714019
Trained batch 268 in epoch 7, gen_loss = 0.9944550634316796, disc_loss = 0.0003501550414904365
Trained batch 269 in epoch 7, gen_loss = 0.9945011141123595, disc_loss = 0.00034961676812801873
Trained batch 270 in epoch 7, gen_loss = 0.9949266085765458, disc_loss = 0.0003493847208518777
Trained batch 271 in epoch 7, gen_loss = 0.9951569133383387, disc_loss = 0.0003496722990535893
Trained batch 272 in epoch 7, gen_loss = 0.9950840639107393, disc_loss = 0.00035100602454494345
Trained batch 273 in epoch 7, gen_loss = 0.9952872460776002, disc_loss = 0.000352287312696478
Trained batch 274 in epoch 7, gen_loss = 0.9950397981296886, disc_loss = 0.0003528890715493948
Trained batch 275 in epoch 7, gen_loss = 0.9949191337910251, disc_loss = 0.00035322915569533666
Trained batch 276 in epoch 7, gen_loss = 0.9944683827648094, disc_loss = 0.0003540866325668434
Trained batch 277 in epoch 7, gen_loss = 0.993988786884349, disc_loss = 0.00035537231730336155
Trained batch 278 in epoch 7, gen_loss = 0.993329087252258, disc_loss = 0.00035701797515753485
Trained batch 279 in epoch 7, gen_loss = 0.9939464017748832, disc_loss = 0.00035797031504054236
Trained batch 280 in epoch 7, gen_loss = 0.9936909898320126, disc_loss = 0.0003584473847840984
Trained batch 281 in epoch 7, gen_loss = 0.9939266005729107, disc_loss = 0.0003582393295130179
Trained batch 282 in epoch 7, gen_loss = 0.9939711015974254, disc_loss = 0.0003579717709411589
Trained batch 283 in epoch 7, gen_loss = 0.9941041962781423, disc_loss = 0.0003584574683308872
Trained batch 284 in epoch 7, gen_loss = 0.9942385010551988, disc_loss = 0.00035934256821954543
Trained batch 285 in epoch 7, gen_loss = 0.9947160797102468, disc_loss = 0.00035936409277872793
Trained batch 286 in epoch 7, gen_loss = 0.9943287366358661, disc_loss = 0.00035864716385442923
Trained batch 287 in epoch 7, gen_loss = 0.9941471183879508, disc_loss = 0.0003581150726985369
Trained batch 288 in epoch 7, gen_loss = 0.994001840431385, disc_loss = 0.0003573663154610708
Trained batch 289 in epoch 7, gen_loss = 0.9940889175595908, disc_loss = 0.0003571671435879423
Trained batch 290 in epoch 7, gen_loss = 0.993955959569138, disc_loss = 0.0003581686574399441
Trained batch 291 in epoch 7, gen_loss = 0.9940737134789768, disc_loss = 0.00035929863784138884
Trained batch 292 in epoch 7, gen_loss = 0.9940525334035984, disc_loss = 0.00036005583257661135
Trained batch 293 in epoch 7, gen_loss = 0.9939869520615559, disc_loss = 0.0003606606543038973
Trained batch 294 in epoch 7, gen_loss = 0.9939209220773083, disc_loss = 0.00036085306202363363
Trained batch 295 in epoch 7, gen_loss = 0.9940490152787518, disc_loss = 0.00036069412396033375
Trained batch 296 in epoch 7, gen_loss = 0.9941147921061275, disc_loss = 0.0003601850814313231
Trained batch 297 in epoch 7, gen_loss = 0.9944810069247381, disc_loss = 0.00035973435273714717
Trained batch 298 in epoch 7, gen_loss = 0.9945294253004833, disc_loss = 0.00035947733143327777
Trained batch 299 in epoch 7, gen_loss = 0.9946868127584457, disc_loss = 0.0003591803805829841
Trained batch 300 in epoch 7, gen_loss = 0.994592952965898, disc_loss = 0.00035883614580362397
Trained batch 301 in epoch 7, gen_loss = 0.9946003599672129, disc_loss = 0.0003583934908931873
Trained batch 302 in epoch 7, gen_loss = 0.994698967870706, disc_loss = 0.0003578204174935026
Trained batch 303 in epoch 7, gen_loss = 0.9947285561969406, disc_loss = 0.0003570337108780414
Trained batch 304 in epoch 7, gen_loss = 0.9945880528356208, disc_loss = 0.00035606333674609157
Trained batch 305 in epoch 7, gen_loss = 0.9943409951683743, disc_loss = 0.0003549950086535259
Trained batch 306 in epoch 7, gen_loss = 0.9943112247541596, disc_loss = 0.0003539642670746598
Trained batch 307 in epoch 7, gen_loss = 0.9948685331778093, disc_loss = 0.00035311985046465957
Trained batch 308 in epoch 7, gen_loss = 0.9950435906166397, disc_loss = 0.0003523615055951489
Trained batch 309 in epoch 7, gen_loss = 0.9949715033654244, disc_loss = 0.00035184577547272877
Trained batch 310 in epoch 7, gen_loss = 0.9950013578513044, disc_loss = 0.0003515617149948274
Trained batch 311 in epoch 7, gen_loss = 0.9949078408953471, disc_loss = 0.0003515420006433254
Trained batch 312 in epoch 7, gen_loss = 0.9947920405445769, disc_loss = 0.00035153515016256173
Trained batch 313 in epoch 7, gen_loss = 0.9945304241909343, disc_loss = 0.0003513847921938253
Trained batch 314 in epoch 7, gen_loss = 0.9947448821294875, disc_loss = 0.0003510088634183852
Trained batch 315 in epoch 7, gen_loss = 0.9945372403422489, disc_loss = 0.0003504417513622799
Trained batch 316 in epoch 7, gen_loss = 0.9946112377034377, disc_loss = 0.00034998220528644137
Trained batch 317 in epoch 7, gen_loss = 0.9947622084767563, disc_loss = 0.00034984000241431503
Trained batch 318 in epoch 7, gen_loss = 0.9946539542144369, disc_loss = 0.0003496678382989244
Trained batch 319 in epoch 7, gen_loss = 0.9948351653292775, disc_loss = 0.00034922545867175356
Trained batch 320 in epoch 7, gen_loss = 0.9949137483059061, disc_loss = 0.0003485370146441041
Trained batch 321 in epoch 7, gen_loss = 0.9946744491965134, disc_loss = 0.0003478458457941302
Trained batch 322 in epoch 7, gen_loss = 0.994291224900414, disc_loss = 0.00034728299309813126
Trained batch 323 in epoch 7, gen_loss = 0.9946046561738591, disc_loss = 0.0003469165461596007
Trained batch 324 in epoch 7, gen_loss = 0.9944643748723544, disc_loss = 0.0003468188257270063
Trained batch 325 in epoch 7, gen_loss = 0.9946503297317247, disc_loss = 0.00034739782053393745
Trained batch 326 in epoch 7, gen_loss = 0.9947495980000277, disc_loss = 0.0003480991247472843
Trained batch 327 in epoch 7, gen_loss = 0.9945689479752284, disc_loss = 0.0003483656417568166
Trained batch 328 in epoch 7, gen_loss = 0.9947832554669366, disc_loss = 0.0003479906605030438
Trained batch 329 in epoch 7, gen_loss = 0.9947192578604727, disc_loss = 0.000347338522326688
Trained batch 330 in epoch 7, gen_loss = 0.9950810386335022, disc_loss = 0.000346688560527233
Trained batch 331 in epoch 7, gen_loss = 0.99531765623265, disc_loss = 0.0003467343918513156
Trained batch 332 in epoch 7, gen_loss = 0.9956067750403831, disc_loss = 0.00034717766862336756
Trained batch 333 in epoch 7, gen_loss = 0.9952875161599256, disc_loss = 0.0003474406891878524
Trained batch 334 in epoch 7, gen_loss = 0.9951541587487975, disc_loss = 0.0003475572595697716
Trained batch 335 in epoch 7, gen_loss = 0.9952610731124878, disc_loss = 0.0003473909954057793
Trained batch 336 in epoch 7, gen_loss = 0.9949460577894035, disc_loss = 0.0003470081110073472
Trained batch 337 in epoch 7, gen_loss = 0.9946842890166672, disc_loss = 0.00034679398931285296
Trained batch 338 in epoch 7, gen_loss = 0.9944731278405429, disc_loss = 0.00034650985224417665
Trained batch 339 in epoch 7, gen_loss = 0.9946967303752899, disc_loss = 0.00034600062253422735
Trained batch 340 in epoch 7, gen_loss = 0.9948019817078219, disc_loss = 0.00034544563229974836
Trained batch 341 in epoch 7, gen_loss = 0.9946890262483853, disc_loss = 0.00034485368319083827
Trained batch 342 in epoch 7, gen_loss = 0.9946883220019216, disc_loss = 0.0003444215663311305
Trained batch 343 in epoch 7, gen_loss = 0.9947577390906422, disc_loss = 0.0003439981877141521
Trained batch 344 in epoch 7, gen_loss = 0.9949528111927751, disc_loss = 0.00034353201924165223
Trained batch 345 in epoch 7, gen_loss = 0.9945853240572649, disc_loss = 0.0003431558270571616
Trained batch 346 in epoch 7, gen_loss = 0.994765864497303, disc_loss = 0.0003431661228150443
Trained batch 347 in epoch 7, gen_loss = 0.9945506419258556, disc_loss = 0.00034343730091688027
Trained batch 348 in epoch 7, gen_loss = 0.9946867172902498, disc_loss = 0.00034377389665600315
Trained batch 349 in epoch 7, gen_loss = 0.994767757824489, disc_loss = 0.0003439725748570968
Trained batch 350 in epoch 7, gen_loss = 0.994619353883966, disc_loss = 0.00034416753638610696
Trained batch 351 in epoch 7, gen_loss = 0.9942815832116387, disc_loss = 0.0003441277102328141
Trained batch 352 in epoch 7, gen_loss = 0.9942553975426779, disc_loss = 0.0003437512549817385
Trained batch 353 in epoch 7, gen_loss = 0.9940289013129843, disc_loss = 0.00034312858768080436
Trained batch 354 in epoch 7, gen_loss = 0.9937895217411955, disc_loss = 0.0003424685296740278
Trained batch 355 in epoch 7, gen_loss = 0.9935825629515594, disc_loss = 0.00034210785717855136
Trained batch 356 in epoch 7, gen_loss = 0.9938569277608428, disc_loss = 0.0003417926497760044
Trained batch 357 in epoch 7, gen_loss = 0.9942211264005586, disc_loss = 0.00034146280167429244
Trained batch 358 in epoch 7, gen_loss = 0.9939775901916631, disc_loss = 0.0003411554133786734
Trained batch 359 in epoch 7, gen_loss = 0.9940347827143139, disc_loss = 0.0003412266979770114
Trained batch 360 in epoch 7, gen_loss = 0.9940589091784406, disc_loss = 0.00034142462135204875
Trained batch 361 in epoch 7, gen_loss = 0.9941589950856583, disc_loss = 0.0003413643438892583
Trained batch 362 in epoch 7, gen_loss = 0.9942370994688723, disc_loss = 0.0003411452497288934
Trained batch 363 in epoch 7, gen_loss = 0.994113320505226, disc_loss = 0.00034083829954257596
Trained batch 364 in epoch 7, gen_loss = 0.9939526312971768, disc_loss = 0.0003411342081699954
Trained batch 365 in epoch 7, gen_loss = 0.9939819769781144, disc_loss = 0.0003425277501349134
Trained batch 366 in epoch 7, gen_loss = 0.9939254611649371, disc_loss = 0.00034443887006282064
Trained batch 367 in epoch 7, gen_loss = 0.9937229750920897, disc_loss = 0.0003445480690219404
Trained batch 368 in epoch 7, gen_loss = 0.9936147450108516, disc_loss = 0.00034490708492192765
Trained batch 369 in epoch 7, gen_loss = 0.9936963793393728, disc_loss = 0.00034597014392430365
Trained batch 370 in epoch 7, gen_loss = 0.9933891294780125, disc_loss = 0.00034683925712969394
Trained batch 371 in epoch 7, gen_loss = 0.9933763955549527, disc_loss = 0.00034740532521359993
Trained batch 372 in epoch 7, gen_loss = 0.9933268753836686, disc_loss = 0.0003479596066439085
Trained batch 373 in epoch 7, gen_loss = 0.9931205978049314, disc_loss = 0.0003484067500318042
Trained batch 374 in epoch 7, gen_loss = 0.992949257214864, disc_loss = 0.00034887021675240247
Trained batch 375 in epoch 7, gen_loss = 0.9928367721273544, disc_loss = 0.0003490526067911018
Trained batch 376 in epoch 7, gen_loss = 0.9927667515347428, disc_loss = 0.00034993678947882256
Trained batch 377 in epoch 7, gen_loss = 0.9927003926070279, disc_loss = 0.00035327593072979077
Trained batch 378 in epoch 7, gen_loss = 0.9924639954101442, disc_loss = 0.00035781850907023956
Trained batch 379 in epoch 7, gen_loss = 0.992702496365497, disc_loss = 0.0003626826544381114
Trained batch 380 in epoch 7, gen_loss = 0.992358722868241, disc_loss = 0.0003658346010245544
Trained batch 381 in epoch 7, gen_loss = 0.992166545222567, disc_loss = 0.00036770287912286557
Trained batch 382 in epoch 7, gen_loss = 0.991946450568366, disc_loss = 0.00036882770609617595
Trained batch 383 in epoch 7, gen_loss = 0.9917404712177813, disc_loss = 0.00036905096783357294
Trained batch 384 in epoch 7, gen_loss = 0.9916959824500146, disc_loss = 0.00036918957019980704
Trained batch 385 in epoch 7, gen_loss = 0.9917508098127928, disc_loss = 0.00036951542233745445
Trained batch 386 in epoch 7, gen_loss = 0.9913145651805001, disc_loss = 0.0003702125009477201
Trained batch 387 in epoch 7, gen_loss = 0.9910780016294459, disc_loss = 0.0003711365436137169
Trained batch 388 in epoch 7, gen_loss = 0.9911093907981422, disc_loss = 0.00037152490239371344
Trained batch 389 in epoch 7, gen_loss = 0.9910039796279027, disc_loss = 0.0003712898790791559
Trained batch 390 in epoch 7, gen_loss = 0.9911694555636257, disc_loss = 0.0003709436937719417
Trained batch 391 in epoch 7, gen_loss = 0.9911688561646306, disc_loss = 0.00037069246102372727
Trained batch 392 in epoch 7, gen_loss = 0.9908771665041683, disc_loss = 0.00037040846244136994
Trained batch 393 in epoch 7, gen_loss = 0.9905723722150483, disc_loss = 0.0003700871029050269
Trained batch 394 in epoch 7, gen_loss = 0.9903904231288765, disc_loss = 0.0003699168727565203
Trained batch 395 in epoch 7, gen_loss = 0.9899324487255077, disc_loss = 0.0003696855663182567
Trained batch 396 in epoch 7, gen_loss = 0.9896984663357963, disc_loss = 0.0003693016042234376
Trained batch 397 in epoch 7, gen_loss = 0.9896302340018689, disc_loss = 0.00036873009332851153
Trained batch 398 in epoch 7, gen_loss = 0.9893356818603095, disc_loss = 0.00036800185689731224
Trained batch 399 in epoch 7, gen_loss = 0.9891777887940407, disc_loss = 0.0003673709057875385
Trained batch 400 in epoch 7, gen_loss = 0.9892883690218082, disc_loss = 0.00036691622196379094
Trained batch 401 in epoch 7, gen_loss = 0.9892747385881433, disc_loss = 0.0003663830782047332
Trained batch 402 in epoch 7, gen_loss = 0.9892790196255478, disc_loss = 0.00036584177926063155
Trained batch 403 in epoch 7, gen_loss = 0.9896481252542817, disc_loss = 0.00036542414125164
Trained batch 404 in epoch 7, gen_loss = 0.9898291705567159, disc_loss = 0.00036493260882303327
Trained batch 405 in epoch 7, gen_loss = 0.9898850283599252, disc_loss = 0.0003645698026258767
Trained batch 406 in epoch 7, gen_loss = 0.989725694316611, disc_loss = 0.0003639897648197901
Trained batch 407 in epoch 7, gen_loss = 0.989680657784144, disc_loss = 0.0003633987808629457
Trained batch 408 in epoch 7, gen_loss = 0.9897939905269222, disc_loss = 0.00036290762298111406
Trained batch 409 in epoch 7, gen_loss = 0.9900181473755255, disc_loss = 0.00036245375836520776
Trained batch 410 in epoch 7, gen_loss = 0.9899918824216746, disc_loss = 0.00036193141529272557
Trained batch 411 in epoch 7, gen_loss = 0.9898299230533896, disc_loss = 0.00036131876638216797
Trained batch 412 in epoch 7, gen_loss = 0.9899166418334185, disc_loss = 0.0003606571421138807
Trained batch 413 in epoch 7, gen_loss = 0.9895958904770837, disc_loss = 0.00036021390195051885
Trained batch 414 in epoch 7, gen_loss = 0.9898157968578568, disc_loss = 0.00035991184532653585
Trained batch 415 in epoch 7, gen_loss = 0.9897484296502975, disc_loss = 0.00035951880972089176
Trained batch 416 in epoch 7, gen_loss = 0.9899752590296079, disc_loss = 0.00035905810974748263
Trained batch 417 in epoch 7, gen_loss = 0.9901486462668369, disc_loss = 0.00035894775549261766
Trained batch 418 in epoch 7, gen_loss = 0.990194034889376, disc_loss = 0.00035904376958730255
Trained batch 419 in epoch 7, gen_loss = 0.9900734136501949, disc_loss = 0.0003588164875899175
Trained batch 420 in epoch 7, gen_loss = 0.9899041853721238, disc_loss = 0.0003588247611220581
Trained batch 421 in epoch 7, gen_loss = 0.990015978779273, disc_loss = 0.00035921624454479857
Trained batch 422 in epoch 7, gen_loss = 0.9902133034194333, disc_loss = 0.0003592160188573155
Trained batch 423 in epoch 7, gen_loss = 0.989872120883105, disc_loss = 0.00035912894154020215
Trained batch 424 in epoch 7, gen_loss = 0.9898854015855229, disc_loss = 0.0003591684133553987
Trained batch 425 in epoch 7, gen_loss = 0.9896564815245884, disc_loss = 0.00035949298427953986
Trained batch 426 in epoch 7, gen_loss = 0.9897061333723314, disc_loss = 0.0003603149007921886
Trained batch 427 in epoch 7, gen_loss = 0.9897262997159334, disc_loss = 0.00036094193658236606
Trained batch 428 in epoch 7, gen_loss = 0.9897660089261604, disc_loss = 0.0003611016934433635
Trained batch 429 in epoch 7, gen_loss = 0.9899633626605189, disc_loss = 0.000360873622175436
Trained batch 430 in epoch 7, gen_loss = 0.9899456431860161, disc_loss = 0.00036047864887645155
Trained batch 431 in epoch 7, gen_loss = 0.9900488417457651, disc_loss = 0.00036022797899527685
Trained batch 432 in epoch 7, gen_loss = 0.9903642509055193, disc_loss = 0.00036009425858216353
Trained batch 433 in epoch 7, gen_loss = 0.9904129131598407, disc_loss = 0.00035986473380420614
Trained batch 434 in epoch 7, gen_loss = 0.9902533824416413, disc_loss = 0.0003597825543483955
Trained batch 435 in epoch 7, gen_loss = 0.9903831872918191, disc_loss = 0.00036017507020439613
Trained batch 436 in epoch 7, gen_loss = 0.9902842171677736, disc_loss = 0.0003607583697618878
Trained batch 437 in epoch 7, gen_loss = 0.9902287848191719, disc_loss = 0.0003612007742182067
Trained batch 438 in epoch 7, gen_loss = 0.9902885553505535, disc_loss = 0.0003614121219853962
Trained batch 439 in epoch 7, gen_loss = 0.9902636442672123, disc_loss = 0.00036135115144795486
Trained batch 440 in epoch 7, gen_loss = 0.9902471314752453, disc_loss = 0.00036130721047003235
Trained batch 441 in epoch 7, gen_loss = 0.9900998849404883, disc_loss = 0.0003613219577350287
Trained batch 442 in epoch 7, gen_loss = 0.9899797376337762, disc_loss = 0.0003614152103539506
Trained batch 443 in epoch 7, gen_loss = 0.9899708620599799, disc_loss = 0.00036126341860057566
Trained batch 444 in epoch 7, gen_loss = 0.9902672264013398, disc_loss = 0.0003607253505772482
Trained batch 445 in epoch 7, gen_loss = 0.9902632162977227, disc_loss = 0.0003600773821671539
Trained batch 446 in epoch 7, gen_loss = 0.9900236040420447, disc_loss = 0.00035957932274036477
Trained batch 447 in epoch 7, gen_loss = 0.9898659247638923, disc_loss = 0.0003589489712274891
Trained batch 448 in epoch 7, gen_loss = 0.9897378279530923, disc_loss = 0.0003583301424607842
Trained batch 449 in epoch 7, gen_loss = 0.9896212632126279, disc_loss = 0.00035775404704812294
Trained batch 450 in epoch 7, gen_loss = 0.9896567617181664, disc_loss = 0.00035728176819143026
Trained batch 451 in epoch 7, gen_loss = 0.9897986543653285, disc_loss = 0.00035673896339747735
Trained batch 452 in epoch 7, gen_loss = 0.9900547846263608, disc_loss = 0.0003561151421654077
Trained batch 453 in epoch 7, gen_loss = 0.9901936299737855, disc_loss = 0.00035546663743423276
Trained batch 454 in epoch 7, gen_loss = 0.9900674303809365, disc_loss = 0.00035486865331672113
Trained batch 455 in epoch 7, gen_loss = 0.9899631160915944, disc_loss = 0.00035434281918449476
Trained batch 456 in epoch 7, gen_loss = 0.9899753196495106, disc_loss = 0.00035381787490324857
Trained batch 457 in epoch 7, gen_loss = 0.9900055767146781, disc_loss = 0.0003532608876475814
Trained batch 458 in epoch 7, gen_loss = 0.990010802522464, disc_loss = 0.00035265987543483043
Trained batch 459 in epoch 7, gen_loss = 0.9900109142065048, disc_loss = 0.00035203534281880936
Trained batch 460 in epoch 7, gen_loss = 0.9899187446157741, disc_loss = 0.0003513830000599806
Trained batch 461 in epoch 7, gen_loss = 0.9897922903170318, disc_loss = 0.0003507953520548768
Trained batch 462 in epoch 7, gen_loss = 0.9897965920151696, disc_loss = 0.0003502087553777756
Trained batch 463 in epoch 7, gen_loss = 0.9895271561269102, disc_loss = 0.0003495900768939464
Trained batch 464 in epoch 7, gen_loss = 0.989391379971658, disc_loss = 0.00034895443974966583
Trained batch 465 in epoch 7, gen_loss = 0.9891980374831498, disc_loss = 0.00034832685049538314
Trained batch 466 in epoch 7, gen_loss = 0.9893717553937206, disc_loss = 0.00034770424228721964
Trained batch 467 in epoch 7, gen_loss = 0.9895440052207719, disc_loss = 0.00034716105639947474
Trained batch 468 in epoch 7, gen_loss = 0.9894974469376017, disc_loss = 0.00034667187600149845
Trained batch 469 in epoch 7, gen_loss = 0.9894321663582578, disc_loss = 0.0003463273172104543
Trained batch 470 in epoch 7, gen_loss = 0.989546961465459, disc_loss = 0.0003462217759689259
Trained batch 471 in epoch 7, gen_loss = 0.9895150748602415, disc_loss = 0.00034608845405689526
Trained batch 472 in epoch 7, gen_loss = 0.9896937216815183, disc_loss = 0.0003458712584626798
Trained batch 473 in epoch 7, gen_loss = 0.9897275648791076, disc_loss = 0.00034544998073480327
Trained batch 474 in epoch 7, gen_loss = 0.989724230389846, disc_loss = 0.00034503992535112624
Trained batch 475 in epoch 7, gen_loss = 0.9897737466738004, disc_loss = 0.00034467984587841904
Trained batch 476 in epoch 7, gen_loss = 0.9899026306670167, disc_loss = 0.000344329054339372
Trained batch 477 in epoch 7, gen_loss = 0.99009027179315, disc_loss = 0.00034412741811766295
Trained batch 478 in epoch 7, gen_loss = 0.9899845299989545, disc_loss = 0.00034407592961058654
Trained batch 479 in epoch 7, gen_loss = 0.9899277893205484, disc_loss = 0.00034385612472457677
Trained batch 480 in epoch 7, gen_loss = 0.9898272319048209, disc_loss = 0.0003436728861922807
Trained batch 481 in epoch 7, gen_loss = 0.9897143924879336, disc_loss = 0.0003434953342016286
Trained batch 482 in epoch 7, gen_loss = 0.9897754271331535, disc_loss = 0.00034361777493142567
Trained batch 483 in epoch 7, gen_loss = 0.9898538163378219, disc_loss = 0.00034371960569571893
Trained batch 484 in epoch 7, gen_loss = 0.9898975822114453, disc_loss = 0.00034378213778236575
Trained batch 485 in epoch 7, gen_loss = 0.9896872450785382, disc_loss = 0.0003437977799348803
Trained batch 486 in epoch 7, gen_loss = 0.9895814991340011, disc_loss = 0.00034368611375040623
Trained batch 487 in epoch 7, gen_loss = 0.9897490127897653, disc_loss = 0.0003435571182412563
Trained batch 488 in epoch 7, gen_loss = 0.9898668311856276, disc_loss = 0.0003433277793610726
Trained batch 489 in epoch 7, gen_loss = 0.9899629153767411, disc_loss = 0.00034342500434924694
Trained batch 490 in epoch 7, gen_loss = 0.989961034654357, disc_loss = 0.0003441599270860217
Trained batch 491 in epoch 7, gen_loss = 0.9897812344436723, disc_loss = 0.00034524551740948325
Trained batch 492 in epoch 7, gen_loss = 0.9896986904057238, disc_loss = 0.0003465880558767704
Trained batch 493 in epoch 7, gen_loss = 0.9897880219978842, disc_loss = 0.0003478424464686357
Trained batch 494 in epoch 7, gen_loss = 0.9897903679597257, disc_loss = 0.00034847474656117175
Trained batch 495 in epoch 7, gen_loss = 0.9898038583417093, disc_loss = 0.0003487406937775602
Trained batch 496 in epoch 7, gen_loss = 0.9898872488221412, disc_loss = 0.00034877211443709317
Trained batch 497 in epoch 7, gen_loss = 0.9899493104003998, disc_loss = 0.00034846041594264023
Trained batch 498 in epoch 7, gen_loss = 0.9897915784247174, disc_loss = 0.0003479846135613076
Trained batch 499 in epoch 7, gen_loss = 0.9896374757289886, disc_loss = 0.00034742959649884143
Trained batch 500 in epoch 7, gen_loss = 0.990033261076419, disc_loss = 0.00034696833691685207
Trained batch 501 in epoch 7, gen_loss = 0.989850075833826, disc_loss = 0.0003464712104013383
Trained batch 502 in epoch 7, gen_loss = 0.9899557655895681, disc_loss = 0.0003459649245993227
Trained batch 503 in epoch 7, gen_loss = 0.9898117897765977, disc_loss = 0.0003455113089171752
Trained batch 504 in epoch 7, gen_loss = 0.9896299852002965, disc_loss = 0.00034523399320251244
Trained batch 505 in epoch 7, gen_loss = 0.9896510136221709, disc_loss = 0.00034513257258353576
Trained batch 506 in epoch 7, gen_loss = 0.9897816401026422, disc_loss = 0.0003450866038068354
Trained batch 507 in epoch 7, gen_loss = 0.9895763525108653, disc_loss = 0.0003450480055150587
Trained batch 508 in epoch 7, gen_loss = 0.9895565909112132, disc_loss = 0.00034503224466479987
Trained batch 509 in epoch 7, gen_loss = 0.9893963229422476, disc_loss = 0.00034489250595238537
Trained batch 510 in epoch 7, gen_loss = 0.9892972768402846, disc_loss = 0.00034483400997163547
Trained batch 511 in epoch 7, gen_loss = 0.9895038444083184, disc_loss = 0.000344688268654636
Trained batch 512 in epoch 7, gen_loss = 0.9896983596084178, disc_loss = 0.00034431338024422793
Trained batch 513 in epoch 7, gen_loss = 0.9896641552216348, disc_loss = 0.00034379774908642084
Trained batch 514 in epoch 7, gen_loss = 0.9898432203866903, disc_loss = 0.00034328322453272884
Trained batch 515 in epoch 7, gen_loss = 0.9900116366009379, disc_loss = 0.000342735890506644
Trained batch 516 in epoch 7, gen_loss = 0.9898444433738001, disc_loss = 0.00034226573774243416
Trained batch 517 in epoch 7, gen_loss = 0.9898977971215046, disc_loss = 0.00034194320638513044
Trained batch 518 in epoch 7, gen_loss = 0.9897563409254041, disc_loss = 0.0003417053878211339
Trained batch 519 in epoch 7, gen_loss = 0.9896802394435956, disc_loss = 0.00034141277826095647
Trained batch 520 in epoch 7, gen_loss = 0.9895865572848842, disc_loss = 0.00034108327342163337
Trained batch 521 in epoch 7, gen_loss = 0.9897220071933278, disc_loss = 0.0003407738693435391
Trained batch 522 in epoch 7, gen_loss = 0.9897170558030474, disc_loss = 0.0003403900072657918
Trained batch 523 in epoch 7, gen_loss = 0.9896631801628885, disc_loss = 0.0003399966223092522
Trained batch 524 in epoch 7, gen_loss = 0.989600673970722, disc_loss = 0.00033961259305388447
Trained batch 525 in epoch 7, gen_loss = 0.9894452466710892, disc_loss = 0.0003392849808982432
Trained batch 526 in epoch 7, gen_loss = 0.9892961780984216, disc_loss = 0.0003390131217873332
Trained batch 527 in epoch 7, gen_loss = 0.9892245800883481, disc_loss = 0.00033860104258565116
Trained batch 528 in epoch 7, gen_loss = 0.9890869964047957, disc_loss = 0.00033841358716650257
Trained batch 529 in epoch 7, gen_loss = 0.9891480659538845, disc_loss = 0.0003381633297359035
Trained batch 530 in epoch 7, gen_loss = 0.9891065691375014, disc_loss = 0.00033769319278726057
Trained batch 531 in epoch 7, gen_loss = 0.9891614432173564, disc_loss = 0.0003372160316162867
Trained batch 532 in epoch 7, gen_loss = 0.9893995778421971, disc_loss = 0.0003367503592651643
Trained batch 533 in epoch 7, gen_loss = 0.9892892218037938, disc_loss = 0.0003364834784348504
Trained batch 534 in epoch 7, gen_loss = 0.9892655396015845, disc_loss = 0.000336417994746464
Trained batch 535 in epoch 7, gen_loss = 0.9893109061157526, disc_loss = 0.00033635343982889787
Trained batch 536 in epoch 7, gen_loss = 0.9892571266581004, disc_loss = 0.00033633068344133925
Trained batch 537 in epoch 7, gen_loss = 0.9893862626144877, disc_loss = 0.0003360345438364019
Trained batch 538 in epoch 7, gen_loss = 0.989183298400249, disc_loss = 0.0003355681914001391
Trained batch 539 in epoch 7, gen_loss = 0.9891475135529483, disc_loss = 0.0003350892138836638
Trained batch 540 in epoch 7, gen_loss = 0.988994507384168, disc_loss = 0.00033459516715070287
Trained batch 541 in epoch 7, gen_loss = 0.9889664377233639, disc_loss = 0.0003340926449679309
Trained batch 542 in epoch 7, gen_loss = 0.9888094022568199, disc_loss = 0.0003336137099556872
Trained batch 543 in epoch 7, gen_loss = 0.9889144882121507, disc_loss = 0.0003332052407291913
Trained batch 544 in epoch 7, gen_loss = 0.9889554699626537, disc_loss = 0.000332904788649453
Trained batch 545 in epoch 7, gen_loss = 0.988990476716569, disc_loss = 0.0003325890637701804
Trained batch 546 in epoch 7, gen_loss = 0.9888696744629408, disc_loss = 0.00033217903439013434
Trained batch 547 in epoch 7, gen_loss = 0.9889922973013272, disc_loss = 0.0003316962769013714
Trained batch 548 in epoch 7, gen_loss = 0.988981642575429, disc_loss = 0.0003312275460191777
Trained batch 549 in epoch 7, gen_loss = 0.9889600973779505, disc_loss = 0.0003308675369639373
Trained batch 550 in epoch 7, gen_loss = 0.9889018798480232, disc_loss = 0.0003305264354489926
Trained batch 551 in epoch 7, gen_loss = 0.9890292313867721, disc_loss = 0.00033019117873281823
Trained batch 552 in epoch 7, gen_loss = 0.9893063991237937, disc_loss = 0.00032982872020656154
Trained batch 553 in epoch 7, gen_loss = 0.9890911498439872, disc_loss = 0.00032947287260805215
Trained batch 554 in epoch 7, gen_loss = 0.9890339165120512, disc_loss = 0.00032924108012151476
Trained batch 555 in epoch 7, gen_loss = 0.9888750471228318, disc_loss = 0.00032936380289389465
Trained batch 556 in epoch 7, gen_loss = 0.988865269578766, disc_loss = 0.0003295735309433018
Trained batch 557 in epoch 7, gen_loss = 0.988984784131409, disc_loss = 0.00032971363713277176
Trained batch 558 in epoch 7, gen_loss = 0.9887253716721305, disc_loss = 0.0003297789935947251
Trained batch 559 in epoch 7, gen_loss = 0.9886294089257717, disc_loss = 0.0003297494673461188
Trained batch 560 in epoch 7, gen_loss = 0.9885421035124019, disc_loss = 0.00032960884996238303
Trained batch 561 in epoch 7, gen_loss = 0.9884236187697305, disc_loss = 0.00032945442874853756
Trained batch 562 in epoch 7, gen_loss = 0.9885068361119733, disc_loss = 0.00032933103740004387
Trained batch 563 in epoch 7, gen_loss = 0.9886626837946845, disc_loss = 0.00032910475621316976
Trained batch 564 in epoch 7, gen_loss = 0.98875748203919, disc_loss = 0.00032888585425999874
Trained batch 565 in epoch 7, gen_loss = 0.9887809081549358, disc_loss = 0.00032867849618319897
Trained batch 566 in epoch 7, gen_loss = 0.9889025885802307, disc_loss = 0.0003283862145683306
Trained batch 567 in epoch 7, gen_loss = 0.9890514221829427, disc_loss = 0.00032808778320339143
Trained batch 568 in epoch 7, gen_loss = 0.9889255719151354, disc_loss = 0.0003278014806448277
Trained batch 569 in epoch 7, gen_loss = 0.9890349288781484, disc_loss = 0.00032752827190275286
Trained batch 570 in epoch 7, gen_loss = 0.9890438344349168, disc_loss = 0.0003272881831801717
Trained batch 571 in epoch 7, gen_loss = 0.98894449807964, disc_loss = 0.00032702732565743567
Trained batch 572 in epoch 7, gen_loss = 0.9891361866737951, disc_loss = 0.0003267249799637046
Trained batch 573 in epoch 7, gen_loss = 0.9889714447878795, disc_loss = 0.00032649519445637456
Trained batch 574 in epoch 7, gen_loss = 0.9887751268303913, disc_loss = 0.0003263118496903664
Trained batch 575 in epoch 7, gen_loss = 0.9886252693831921, disc_loss = 0.00032601884090076457
Trained batch 576 in epoch 7, gen_loss = 0.9885436752020177, disc_loss = 0.00032575267819611863
Trained batch 577 in epoch 7, gen_loss = 0.9886211791046763, disc_loss = 0.0003255559862120025
Trained batch 578 in epoch 7, gen_loss = 0.9884886129120677, disc_loss = 0.00032540196099978855
Trained batch 579 in epoch 7, gen_loss = 0.9885921563567787, disc_loss = 0.00032529974903746766
Trained batch 580 in epoch 7, gen_loss = 0.9885825745620334, disc_loss = 0.0003250745250997751
Trained batch 581 in epoch 7, gen_loss = 0.9885099597812927, disc_loss = 0.0003247669246837839
Trained batch 582 in epoch 7, gen_loss = 0.9885730453052816, disc_loss = 0.00032439017297454834
Trained batch 583 in epoch 7, gen_loss = 0.9883366854835863, disc_loss = 0.0003241117776444099
Trained batch 584 in epoch 7, gen_loss = 0.9883414860464569, disc_loss = 0.0003241002691002228
Trained batch 585 in epoch 7, gen_loss = 0.9883657489416949, disc_loss = 0.0003242271177751988
Trained batch 586 in epoch 7, gen_loss = 0.9885501612796491, disc_loss = 0.0003245858094984986
Trained batch 587 in epoch 7, gen_loss = 0.9884647892243197, disc_loss = 0.00032487809256140495
Trained batch 588 in epoch 7, gen_loss = 0.9886183944137068, disc_loss = 0.00032494292609909064
Trained batch 589 in epoch 7, gen_loss = 0.9887480936818204, disc_loss = 0.0003247234337446201
Trained batch 590 in epoch 7, gen_loss = 0.9889037232915359, disc_loss = 0.00032433552392021725
Trained batch 591 in epoch 7, gen_loss = 0.9888377239977991, disc_loss = 0.00032395066725527885
Trained batch 592 in epoch 7, gen_loss = 0.9887155191894326, disc_loss = 0.0003236053215995868
Trained batch 593 in epoch 7, gen_loss = 0.9887941654282387, disc_loss = 0.0003232968223595957
Trained batch 594 in epoch 7, gen_loss = 0.9890127600741987, disc_loss = 0.0003230741384738524
Trained batch 595 in epoch 7, gen_loss = 0.9890423987135791, disc_loss = 0.0003229878027483918
Trained batch 596 in epoch 7, gen_loss = 0.989001472791036, disc_loss = 0.00032295697080373135
Trained batch 597 in epoch 7, gen_loss = 0.9889654019803905, disc_loss = 0.0003229910808326879
Trained batch 598 in epoch 7, gen_loss = 0.9889339904156272, disc_loss = 0.00032326593317883633
Trained batch 599 in epoch 7, gen_loss = 0.9887247891227404, disc_loss = 0.0003236408565377739
Trained batch 600 in epoch 7, gen_loss = 0.9887038244185551, disc_loss = 0.0003239038486694979
Trained batch 601 in epoch 7, gen_loss = 0.9886216292547625, disc_loss = 0.0003240221985018243
Trained batch 602 in epoch 7, gen_loss = 0.988685142835772, disc_loss = 0.0003239186542179315
Trained batch 603 in epoch 7, gen_loss = 0.9886768508628504, disc_loss = 0.00032382067433147483
Trained batch 604 in epoch 7, gen_loss = 0.9887292391997724, disc_loss = 0.0003237759118874688
Trained batch 605 in epoch 7, gen_loss = 0.9886434671312275, disc_loss = 0.00032373790696156503
Trained batch 606 in epoch 7, gen_loss = 0.9887794029378812, disc_loss = 0.0003237074028013605
Trained batch 607 in epoch 7, gen_loss = 0.9887546592048908, disc_loss = 0.000323875866079585
Trained batch 608 in epoch 7, gen_loss = 0.9886446362254263, disc_loss = 0.00032397770300971677
Trained batch 609 in epoch 7, gen_loss = 0.9885069035115789, disc_loss = 0.00032400704663128544
Trained batch 610 in epoch 7, gen_loss = 0.9884716733777972, disc_loss = 0.0003240157435154664
Trained batch 611 in epoch 7, gen_loss = 0.9883833522695342, disc_loss = 0.0003239523682043678
Trained batch 612 in epoch 7, gen_loss = 0.9883679962469353, disc_loss = 0.0003237909148893506
Trained batch 613 in epoch 7, gen_loss = 0.9885989901297255, disc_loss = 0.0003236235570274779
Trained batch 614 in epoch 7, gen_loss = 0.9884815154036856, disc_loss = 0.00032338602451808233
Trained batch 615 in epoch 7, gen_loss = 0.988400590013374, disc_loss = 0.0003232013735084495
Trained batch 616 in epoch 7, gen_loss = 0.988359793368576, disc_loss = 0.00032325945047882796
Trained batch 617 in epoch 7, gen_loss = 0.9884935689782633, disc_loss = 0.0003234145299030067
Trained batch 618 in epoch 7, gen_loss = 0.9887439313920904, disc_loss = 0.00032354027962576155
Trained batch 619 in epoch 7, gen_loss = 0.9886936565560679, disc_loss = 0.00032381950584221483
Trained batch 620 in epoch 7, gen_loss = 0.9885157610675179, disc_loss = 0.00032429460307411493
Trained batch 621 in epoch 7, gen_loss = 0.9885967798363358, disc_loss = 0.0003246300252949163
Trained batch 622 in epoch 7, gen_loss = 0.9886799900527942, disc_loss = 0.00032472717188456417
Trained batch 623 in epoch 7, gen_loss = 0.9886723465453355, disc_loss = 0.0003246846994769816
Trained batch 624 in epoch 7, gen_loss = 0.9887149102210998, disc_loss = 0.00032446765240747483
Trained batch 625 in epoch 7, gen_loss = 0.9886135503697319, disc_loss = 0.0003241199348512412
Trained batch 626 in epoch 7, gen_loss = 0.9885475906458768, disc_loss = 0.0003238802804194608
Trained batch 627 in epoch 7, gen_loss = 0.9884949254382188, disc_loss = 0.0003239930322874637
Trained batch 628 in epoch 7, gen_loss = 0.9887035863388134, disc_loss = 0.00032442343695291326
Trained batch 629 in epoch 7, gen_loss = 0.9887174015953427, disc_loss = 0.00032479616054352224
Trained batch 630 in epoch 7, gen_loss = 0.9885542203809493, disc_loss = 0.00032515845392227746
Trained batch 631 in epoch 7, gen_loss = 0.9884798632392401, disc_loss = 0.00032547840359418127
Trained batch 632 in epoch 7, gen_loss = 0.9884250394729265, disc_loss = 0.00032556875279018033
Trained batch 633 in epoch 7, gen_loss = 0.9884084009033648, disc_loss = 0.0003255714809223466
Trained batch 634 in epoch 7, gen_loss = 0.9885883437366936, disc_loss = 0.0003255385791609709
Trained batch 635 in epoch 7, gen_loss = 0.9886941451509044, disc_loss = 0.00032554470613923176
Trained batch 636 in epoch 7, gen_loss = 0.9887038137137983, disc_loss = 0.0003254320650437139
Trained batch 637 in epoch 7, gen_loss = 0.9887274304714323, disc_loss = 0.0003251877953351306
Trained batch 638 in epoch 7, gen_loss = 0.9888549991803177, disc_loss = 0.00032495452432783177
Trained batch 639 in epoch 7, gen_loss = 0.9887915720231831, disc_loss = 0.00032481564801400964
Trained batch 640 in epoch 7, gen_loss = 0.9886424360148807, disc_loss = 0.00032471455239989415
Trained batch 641 in epoch 7, gen_loss = 0.9885914312716214, disc_loss = 0.00032453763059694376
Trained batch 642 in epoch 7, gen_loss = 0.9885348674854261, disc_loss = 0.00032431821020727057
Trained batch 643 in epoch 7, gen_loss = 0.9886622908322708, disc_loss = 0.0003240278724802265
Trained batch 644 in epoch 7, gen_loss = 0.9886467582495637, disc_loss = 0.000323779064017644
Trained batch 645 in epoch 7, gen_loss = 0.9886209010708812, disc_loss = 0.00032367923950427573
Trained batch 646 in epoch 7, gen_loss = 0.9886315106608584, disc_loss = 0.00032363342656717973
Trained batch 647 in epoch 7, gen_loss = 0.9884956738463154, disc_loss = 0.0003236903657922579
Trained batch 648 in epoch 7, gen_loss = 0.9884374138019485, disc_loss = 0.0003239080872751187
Trained batch 649 in epoch 7, gen_loss = 0.9882785427570343, disc_loss = 0.00032403599587269125
Trained batch 650 in epoch 7, gen_loss = 0.9881861415876222, disc_loss = 0.00032400508451822015
Trained batch 651 in epoch 7, gen_loss = 0.9882477972587925, disc_loss = 0.00032387729850686953
Trained batch 652 in epoch 7, gen_loss = 0.9883606717743516, disc_loss = 0.00032359197111636297
Trained batch 653 in epoch 7, gen_loss = 0.9883587144383597, disc_loss = 0.00032323893764934185
Trained batch 654 in epoch 7, gen_loss = 0.9884642083226269, disc_loss = 0.00032297077254154046
Trained batch 655 in epoch 7, gen_loss = 0.9885853791563977, disc_loss = 0.0003229746428520984
Trained batch 656 in epoch 7, gen_loss = 0.98866552422943, disc_loss = 0.0003231344717319791
Trained batch 657 in epoch 7, gen_loss = 0.9887871735907615, disc_loss = 0.00032364492134157833
Trained batch 658 in epoch 7, gen_loss = 0.9887892535134404, disc_loss = 0.0003243744177809155
Trained batch 659 in epoch 7, gen_loss = 0.9888534142212434, disc_loss = 0.000324969805065352
Trained batch 660 in epoch 7, gen_loss = 0.9888117604645226, disc_loss = 0.0003250847347498112
Trained batch 661 in epoch 7, gen_loss = 0.9888064246343342, disc_loss = 0.00032502396276739095
Trained batch 662 in epoch 7, gen_loss = 0.9889391828805972, disc_loss = 0.0003249781815499154
Trained batch 663 in epoch 7, gen_loss = 0.9889617433928581, disc_loss = 0.0003248864183430658
Trained batch 664 in epoch 7, gen_loss = 0.9888498649561316, disc_loss = 0.00032498292212244966
Trained batch 665 in epoch 7, gen_loss = 0.9889642668736948, disc_loss = 0.00032517530848485396
Trained batch 666 in epoch 7, gen_loss = 0.9888247474022712, disc_loss = 0.0003249545979711145
Trained batch 667 in epoch 7, gen_loss = 0.9886160165428401, disc_loss = 0.00032470996200049875
Trained batch 668 in epoch 7, gen_loss = 0.988570707261295, disc_loss = 0.00032443708429733914
Trained batch 669 in epoch 7, gen_loss = 0.9887113626323529, disc_loss = 0.00032435928144728516
Trained batch 670 in epoch 7, gen_loss = 0.9886810870177699, disc_loss = 0.00032423814657510673
Trained batch 671 in epoch 7, gen_loss = 0.9885955445823216, disc_loss = 0.00032402940520287737
Trained batch 672 in epoch 7, gen_loss = 0.9887932462819795, disc_loss = 0.000323870874277799
Trained batch 673 in epoch 7, gen_loss = 0.9887382338591783, disc_loss = 0.0003240285411052881
Trained batch 674 in epoch 7, gen_loss = 0.9888424894544814, disc_loss = 0.0003246614083440767
Trained batch 675 in epoch 7, gen_loss = 0.9886842580765662, disc_loss = 0.0003257455097955029
Trained batch 676 in epoch 7, gen_loss = 0.9884763264937803, disc_loss = 0.00032660314359975927
Trained batch 677 in epoch 7, gen_loss = 0.988431350231874, disc_loss = 0.0003271196150855549
Trained batch 678 in epoch 7, gen_loss = 0.9883760592196581, disc_loss = 0.0003271647594819073
Trained batch 679 in epoch 7, gen_loss = 0.9883097654756378, disc_loss = 0.00032712141379734555
Trained batch 680 in epoch 7, gen_loss = 0.9884125826642377, disc_loss = 0.0003270238647155365
Trained batch 681 in epoch 7, gen_loss = 0.988395461588661, disc_loss = 0.00032685588353280733
Trained batch 682 in epoch 7, gen_loss = 0.98846177335714, disc_loss = 0.0003266163584268291
Trained batch 683 in epoch 7, gen_loss = 0.9885269741565861, disc_loss = 0.0003263331448776057
Trained batch 684 in epoch 7, gen_loss = 0.9885106199849261, disc_loss = 0.000326013779327151
Trained batch 685 in epoch 7, gen_loss = 0.9885248155183765, disc_loss = 0.00032567687092884174
Trained batch 686 in epoch 7, gen_loss = 0.988529487728552, disc_loss = 0.00032531077962487685
Trained batch 687 in epoch 7, gen_loss = 0.9885900636571784, disc_loss = 0.0003249867760809308
Trained batch 688 in epoch 7, gen_loss = 0.9885361394446197, disc_loss = 0.0003247173313781888
Trained batch 689 in epoch 7, gen_loss = 0.9885454872380133, disc_loss = 0.00032454214105846535
Trained batch 690 in epoch 7, gen_loss = 0.9884426426438968, disc_loss = 0.00032436202020816
Trained batch 691 in epoch 7, gen_loss = 0.9884235278374887, disc_loss = 0.0003241816508107465
Trained batch 692 in epoch 7, gen_loss = 0.9884066554203006, disc_loss = 0.0003239490294708564
Trained batch 693 in epoch 7, gen_loss = 0.9883302541218848, disc_loss = 0.0003238492360051221
Trained batch 694 in epoch 7, gen_loss = 0.9882123834795231, disc_loss = 0.0003239771964178394
Trained batch 695 in epoch 7, gen_loss = 0.9882232401220278, disc_loss = 0.0003239045709574123
Trained batch 696 in epoch 7, gen_loss = 0.9880469853600949, disc_loss = 0.000323854335812151
Trained batch 697 in epoch 7, gen_loss = 0.9879751398433587, disc_loss = 0.00032391678119726404
Trained batch 698 in epoch 7, gen_loss = 0.9880577044425605, disc_loss = 0.0003239481630434485
Trained batch 699 in epoch 7, gen_loss = 0.9882048184531076, disc_loss = 0.0003238580755818735
Trained batch 700 in epoch 7, gen_loss = 0.9881130342986887, disc_loss = 0.0003238194332202829
Trained batch 701 in epoch 7, gen_loss = 0.9881151490062051, disc_loss = 0.00032384193242961036
Trained batch 702 in epoch 7, gen_loss = 0.9880290868272144, disc_loss = 0.00032377524536682934
Trained batch 703 in epoch 7, gen_loss = 0.9880224009975791, disc_loss = 0.0003235786433813039
Trained batch 704 in epoch 7, gen_loss = 0.9881206224150691, disc_loss = 0.00032333660149799846
Trained batch 705 in epoch 7, gen_loss = 0.9880634510821054, disc_loss = 0.0003230754607615144
Trained batch 706 in epoch 7, gen_loss = 0.9880741061550555, disc_loss = 0.00032292187263172507
Trained batch 707 in epoch 7, gen_loss = 0.9880652340960367, disc_loss = 0.0003227257380107619
Trained batch 708 in epoch 7, gen_loss = 0.9882059950586435, disc_loss = 0.000322438548988553
Trained batch 709 in epoch 7, gen_loss = 0.9881296778228921, disc_loss = 0.00032218243406378845
Trained batch 710 in epoch 7, gen_loss = 0.9882309256559015, disc_loss = 0.00032202815338381425
Trained batch 711 in epoch 7, gen_loss = 0.9882125411643071, disc_loss = 0.0003221436296534898
Trained batch 712 in epoch 7, gen_loss = 0.9883065202794603, disc_loss = 0.00032227849370846
Trained batch 713 in epoch 7, gen_loss = 0.9882767303150242, disc_loss = 0.0003223489096222076
Trained batch 714 in epoch 7, gen_loss = 0.9883656332542846, disc_loss = 0.00032253399389751996
Trained batch 715 in epoch 7, gen_loss = 0.9883335817959056, disc_loss = 0.0003229490863182875
Trained batch 716 in epoch 7, gen_loss = 0.9883674585170825, disc_loss = 0.0003234830744649125
Trained batch 717 in epoch 7, gen_loss = 0.9883894974308758, disc_loss = 0.0003241123690067701
Trained batch 718 in epoch 7, gen_loss = 0.9884102600671983, disc_loss = 0.00032437059866442244
Trained batch 719 in epoch 7, gen_loss = 0.9884171980122726, disc_loss = 0.00032487262216010195
Trained batch 720 in epoch 7, gen_loss = 0.9884507258457549, disc_loss = 0.0003249894833921561
Trained batch 721 in epoch 7, gen_loss = 0.9885418199601266, disc_loss = 0.0003252076930444658
Trained batch 722 in epoch 7, gen_loss = 0.9884180872601922, disc_loss = 0.0003257976587138649
Trained batch 723 in epoch 7, gen_loss = 0.9884280625792498, disc_loss = 0.00032658652968337124
Trained batch 724 in epoch 7, gen_loss = 0.9883860738524075, disc_loss = 0.00032773975689357534
Trained batch 725 in epoch 7, gen_loss = 0.9885721961164606, disc_loss = 0.0003285720535527854
Trained batch 726 in epoch 7, gen_loss = 0.9884552964646026, disc_loss = 0.00032934004904203016
Trained batch 727 in epoch 7, gen_loss = 0.9882911943963596, disc_loss = 0.0003298665951461062
Trained batch 728 in epoch 7, gen_loss = 0.9882282177280169, disc_loss = 0.00033014085559522226
Trained batch 729 in epoch 7, gen_loss = 0.9879843034156381, disc_loss = 0.0003303500033587326
Trained batch 730 in epoch 7, gen_loss = 0.9879336136962744, disc_loss = 0.0003306503344373236
Trained batch 731 in epoch 7, gen_loss = 0.9878483011585767, disc_loss = 0.0003308220932380547
Trained batch 732 in epoch 7, gen_loss = 0.9878444831823424, disc_loss = 0.0003312904892304606
Trained batch 733 in epoch 7, gen_loss = 0.987839659244553, disc_loss = 0.0003319558649462976
Trained batch 734 in epoch 7, gen_loss = 0.9878646742729914, disc_loss = 0.0003325137225487333
Trained batch 735 in epoch 7, gen_loss = 0.9877400207130805, disc_loss = 0.0003330150541189695
Trained batch 736 in epoch 7, gen_loss = 0.9877252145247026, disc_loss = 0.00033358475973893127
Trained batch 737 in epoch 7, gen_loss = 0.9878422454766788, disc_loss = 0.000334449797075038
Trained batch 738 in epoch 7, gen_loss = 0.9879035330270398, disc_loss = 0.00033555251925420303
Trained batch 739 in epoch 7, gen_loss = 0.9879854865976282, disc_loss = 0.00033612985041415685
Trained batch 740 in epoch 7, gen_loss = 0.9879298761949526, disc_loss = 0.0003363747101808287
Trained batch 741 in epoch 7, gen_loss = 0.987999253677872, disc_loss = 0.00033627192525613887
Trained batch 742 in epoch 7, gen_loss = 0.9879099877493539, disc_loss = 0.00033629740597807125
Trained batch 743 in epoch 7, gen_loss = 0.9880233750708641, disc_loss = 0.00033618712511455944
Trained batch 744 in epoch 7, gen_loss = 0.9881301435848211, disc_loss = 0.00033606855198154974
Trained batch 745 in epoch 7, gen_loss = 0.9881414887732539, disc_loss = 0.00033611988897247166
Trained batch 746 in epoch 7, gen_loss = 0.988153412958066, disc_loss = 0.0003362952850400121
Trained batch 747 in epoch 7, gen_loss = 0.9881596013027079, disc_loss = 0.00033621009415923557
Trained batch 748 in epoch 7, gen_loss = 0.9881868541479429, disc_loss = 0.000336052136446672
Trained batch 749 in epoch 7, gen_loss = 0.9882278859615325, disc_loss = 0.00033653166654403323
Trained batch 750 in epoch 7, gen_loss = 0.9882108320726377, disc_loss = 0.00033711003584388244
Trained batch 751 in epoch 7, gen_loss = 0.9882338476624895, disc_loss = 0.00033734690918634517
Trained batch 752 in epoch 7, gen_loss = 0.9882003570774479, disc_loss = 0.00033739987825289933
Trained batch 753 in epoch 7, gen_loss = 0.9882421956770616, disc_loss = 0.0003374313901149049
Trained batch 754 in epoch 7, gen_loss = 0.9882755309540704, disc_loss = 0.0003374840277929433
Trained batch 755 in epoch 7, gen_loss = 0.9882583044193409, disc_loss = 0.000337500897200828
Trained batch 756 in epoch 7, gen_loss = 0.9883440164467775, disc_loss = 0.0003373429754520877
Trained batch 757 in epoch 7, gen_loss = 0.9883113766880337, disc_loss = 0.00033714151378936934
Trained batch 758 in epoch 7, gen_loss = 0.9883042464771447, disc_loss = 0.00033689937558709505
Trained batch 759 in epoch 7, gen_loss = 0.9883687936161694, disc_loss = 0.0003366572013156225
Trained batch 760 in epoch 7, gen_loss = 0.9882901588971292, disc_loss = 0.00033643200003051564
Trained batch 761 in epoch 7, gen_loss = 0.988161111128299, disc_loss = 0.0003362178625441932
Trained batch 762 in epoch 7, gen_loss = 0.9882037494316951, disc_loss = 0.00033607501324718126
Trained batch 763 in epoch 7, gen_loss = 0.9881832708863063, disc_loss = 0.00033593651750717736
Trained batch 764 in epoch 7, gen_loss = 0.9882110539604636, disc_loss = 0.0003356895381657048
Trained batch 765 in epoch 7, gen_loss = 0.9883364744037001, disc_loss = 0.00033545434362595164
Trained batch 766 in epoch 7, gen_loss = 0.9882936467558651, disc_loss = 0.0003352321918500251
Trained batch 767 in epoch 7, gen_loss = 0.9882540839413801, disc_loss = 0.00033497435266364545
Trained batch 768 in epoch 7, gen_loss = 0.98819897590285, disc_loss = 0.0003347929012138906
Trained batch 769 in epoch 7, gen_loss = 0.9881738159563634, disc_loss = 0.0003345941884617787
Trained batch 770 in epoch 7, gen_loss = 0.9881993430133923, disc_loss = 0.0003343295322406654
Trained batch 771 in epoch 7, gen_loss = 0.9880632175991573, disc_loss = 0.0003339792722873082
Trained batch 772 in epoch 7, gen_loss = 0.988041520735579, disc_loss = 0.0003335955369587142
Trained batch 773 in epoch 7, gen_loss = 0.9881320121368389, disc_loss = 0.0003334597768069507
Trained batch 774 in epoch 7, gen_loss = 0.987981950236905, disc_loss = 0.0003339814935480395
Trained batch 775 in epoch 7, gen_loss = 0.9880013676341047, disc_loss = 0.0003348473182245705
Trained batch 776 in epoch 7, gen_loss = 0.9879320862977508, disc_loss = 0.0003357096602169358
Trained batch 777 in epoch 7, gen_loss = 0.9878647489841922, disc_loss = 0.00033610735455489595
Trained batch 778 in epoch 7, gen_loss = 0.9878964193060095, disc_loss = 0.00033626311889936876
Trained batch 779 in epoch 7, gen_loss = 0.9881341520028236, disc_loss = 0.00033623032146491683
Trained batch 780 in epoch 7, gen_loss = 0.9880325692716543, disc_loss = 0.0003366444009313272
Trained batch 781 in epoch 7, gen_loss = 0.9879065639984882, disc_loss = 0.0003373570542376431
Trained batch 782 in epoch 7, gen_loss = 0.9879501597482431, disc_loss = 0.0003376917316314275
Trained batch 783 in epoch 7, gen_loss = 0.9879229551523315, disc_loss = 0.00033776182280401986
Trained batch 784 in epoch 7, gen_loss = 0.987885545089746, disc_loss = 0.0003377849243545703
Trained batch 785 in epoch 7, gen_loss = 0.9878231644933764, disc_loss = 0.0003376774316663681
Trained batch 786 in epoch 7, gen_loss = 0.9876956501940154, disc_loss = 0.0003375228879523015
Trained batch 787 in epoch 7, gen_loss = 0.9877751752507263, disc_loss = 0.00033734782305215176
Trained batch 788 in epoch 7, gen_loss = 0.9875958859542779, disc_loss = 0.00033723596869749507
Trained batch 789 in epoch 7, gen_loss = 0.9876180900048606, disc_loss = 0.000337182293473625
Trained batch 790 in epoch 7, gen_loss = 0.9874735485889516, disc_loss = 0.00033716803685056724
Trained batch 791 in epoch 7, gen_loss = 0.987353485341024, disc_loss = 0.00033710947720483277
Trained batch 792 in epoch 7, gen_loss = 0.9873579454151409, disc_loss = 0.0003370492164783114
Trained batch 793 in epoch 7, gen_loss = 0.9875082369865639, disc_loss = 0.0003370340317968626
Trained batch 794 in epoch 7, gen_loss = 0.9875233640460848, disc_loss = 0.00033690102730435465
Trained batch 795 in epoch 7, gen_loss = 0.9873877856599625, disc_loss = 0.00033670139838528967
Trained batch 796 in epoch 7, gen_loss = 0.9872484046362874, disc_loss = 0.00033644012775031995
Trained batch 797 in epoch 7, gen_loss = 0.9873082820783582, disc_loss = 0.0003362958417263846
Trained batch 798 in epoch 7, gen_loss = 0.9872803567944838, disc_loss = 0.00033609011723442544
Trained batch 799 in epoch 7, gen_loss = 0.9870906057953834, disc_loss = 0.0003357733642587846
Trained batch 800 in epoch 7, gen_loss = 0.9871714301174798, disc_loss = 0.0003355052125307827
Trained batch 801 in epoch 7, gen_loss = 0.9870157837867737, disc_loss = 0.0003351980528334519
Trained batch 802 in epoch 7, gen_loss = 0.9870401945981112, disc_loss = 0.000335000114623648
Trained batch 803 in epoch 7, gen_loss = 0.9869687625424779, disc_loss = 0.00033502350916973935
Trained batch 804 in epoch 7, gen_loss = 0.9870324282912735, disc_loss = 0.0003353137275011001
Trained batch 805 in epoch 7, gen_loss = 0.9872492960014059, disc_loss = 0.00033553689574713304
Trained batch 806 in epoch 7, gen_loss = 0.9875095280572828, disc_loss = 0.00033588867551478924
Trained batch 807 in epoch 7, gen_loss = 0.98747020886086, disc_loss = 0.0003359446639001587
Trained batch 808 in epoch 7, gen_loss = 0.9875735051847064, disc_loss = 0.000336043594304109
Trained batch 809 in epoch 7, gen_loss = 0.9875050755194675, disc_loss = 0.00033620739637559314
Trained batch 810 in epoch 7, gen_loss = 0.9875141759982974, disc_loss = 0.0003361365111730907
Trained batch 811 in epoch 7, gen_loss = 0.9874172215097643, disc_loss = 0.00033595369085349805
Trained batch 812 in epoch 7, gen_loss = 0.9876386871490385, disc_loss = 0.00033573316071569965
Trained batch 813 in epoch 7, gen_loss = 0.9876132947953385, disc_loss = 0.00033554261046281846
Trained batch 814 in epoch 7, gen_loss = 0.9876604351529314, disc_loss = 0.00033567787841372364
Trained batch 815 in epoch 7, gen_loss = 0.9876928184108407, disc_loss = 0.0003366421667801749
Trained batch 816 in epoch 7, gen_loss = 0.9877450461049121, disc_loss = 0.00033807408262061006
Trained batch 817 in epoch 7, gen_loss = 0.9877359251375595, disc_loss = 0.0003392702931378687
Trained batch 818 in epoch 7, gen_loss = 0.9877752843648377, disc_loss = 0.00033969571144979333
Trained batch 819 in epoch 7, gen_loss = 0.9876861389817261, disc_loss = 0.00033964330607154917
Trained batch 820 in epoch 7, gen_loss = 0.9876416666789409, disc_loss = 0.000339514631509651
Trained batch 821 in epoch 7, gen_loss = 0.9876292616926551, disc_loss = 0.0003393933597105638
Trained batch 822 in epoch 7, gen_loss = 0.9874185507671221, disc_loss = 0.000339223289548463
Trained batch 823 in epoch 7, gen_loss = 0.9874744107132977, disc_loss = 0.0003391388958405214
Trained batch 824 in epoch 7, gen_loss = 0.9874531896909078, disc_loss = 0.0003390697578486817
Trained batch 825 in epoch 7, gen_loss = 0.9876135810668474, disc_loss = 0.000339003093722127
Trained batch 826 in epoch 7, gen_loss = 0.9877239870044888, disc_loss = 0.00033895353241135255
Trained batch 827 in epoch 7, gen_loss = 0.9878896153059559, disc_loss = 0.00033880377553423345
Trained batch 828 in epoch 7, gen_loss = 0.9877122396151609, disc_loss = 0.0003385569627965639
Trained batch 829 in epoch 7, gen_loss = 0.9877757760415594, disc_loss = 0.0003382860423249462
Trained batch 830 in epoch 7, gen_loss = 0.9876458369437537, disc_loss = 0.0003380300169823261
Trained batch 831 in epoch 7, gen_loss = 0.9876936642596355, disc_loss = 0.0003378463530645184
Trained batch 832 in epoch 7, gen_loss = 0.987627677055968, disc_loss = 0.0003376539959509366
Trained batch 833 in epoch 7, gen_loss = 0.9874720265396493, disc_loss = 0.00033746305489854
Trained batch 834 in epoch 7, gen_loss = 0.9874337639637336, disc_loss = 0.0003373912673458892
Trained batch 835 in epoch 7, gen_loss = 0.9874467359918156, disc_loss = 0.000337291625241329
Trained batch 836 in epoch 7, gen_loss = 0.9873324324295655, disc_loss = 0.000337226948949949
Trained batch 837 in epoch 7, gen_loss = 0.9873309149662464, disc_loss = 0.0003371998006420995
Trained batch 838 in epoch 7, gen_loss = 0.9872607463022807, disc_loss = 0.0003374074249081835
Trained batch 839 in epoch 7, gen_loss = 0.9872549017979986, disc_loss = 0.00033768791588608153
Trained batch 840 in epoch 7, gen_loss = 0.9872449648507852, disc_loss = 0.00033793349862948623
Trained batch 841 in epoch 7, gen_loss = 0.9870484810402161, disc_loss = 0.0003387785964885189
Trained batch 842 in epoch 7, gen_loss = 0.9871647449150629, disc_loss = 0.00034105904200592126
Trained batch 843 in epoch 7, gen_loss = 0.9872091772008281, disc_loss = 0.000344176961175112
Trained batch 844 in epoch 7, gen_loss = 0.9871666015252559, disc_loss = 0.0003470784928560114
Trained batch 845 in epoch 7, gen_loss = 0.9871324921471571, disc_loss = 0.0003491703785500978
Trained batch 846 in epoch 7, gen_loss = 0.987303237495625, disc_loss = 0.000350354743679274
Trained batch 847 in epoch 7, gen_loss = 0.9872146078719283, disc_loss = 0.0003510991669003797
Trained batch 848 in epoch 7, gen_loss = 0.9871647030782081, disc_loss = 0.0003516585203248281
Trained batch 849 in epoch 7, gen_loss = 0.987032071352005, disc_loss = 0.0003517969881067984
Trained batch 850 in epoch 7, gen_loss = 0.9869674491125885, disc_loss = 0.0003519560657292506
Trained batch 851 in epoch 7, gen_loss = 0.9870075280537628, disc_loss = 0.0003520315709260692
Trained batch 852 in epoch 7, gen_loss = 0.9869749047132896, disc_loss = 0.00035185190243182477
Trained batch 853 in epoch 7, gen_loss = 0.9868446996815031, disc_loss = 0.0003517326675720766
Trained batch 854 in epoch 7, gen_loss = 0.9867809056538588, disc_loss = 0.0003516913352844616
Trained batch 855 in epoch 7, gen_loss = 0.9868115023057037, disc_loss = 0.00035175637506050815
Trained batch 856 in epoch 7, gen_loss = 0.9867843299791165, disc_loss = 0.00035179971470475813
Trained batch 857 in epoch 7, gen_loss = 0.9868411650329759, disc_loss = 0.00035171365494419775
Trained batch 858 in epoch 7, gen_loss = 0.9868950290785402, disc_loss = 0.0003514762279226274
Trained batch 859 in epoch 7, gen_loss = 0.9869637715955113, disc_loss = 0.0003511845254251966
Trained batch 860 in epoch 7, gen_loss = 0.9868929598666512, disc_loss = 0.0003510426351449422
Trained batch 861 in epoch 7, gen_loss = 0.9870011479423106, disc_loss = 0.0003510986923940643
Trained batch 862 in epoch 7, gen_loss = 0.9870623127057682, disc_loss = 0.00035137453400668864
Trained batch 863 in epoch 7, gen_loss = 0.9870382038945401, disc_loss = 0.00035147649186405435
Trained batch 864 in epoch 7, gen_loss = 0.9869898630015422, disc_loss = 0.0003513923251911906
Trained batch 865 in epoch 7, gen_loss = 0.9870639779964165, disc_loss = 0.00035118741932475356
Trained batch 866 in epoch 7, gen_loss = 0.9869433761055494, disc_loss = 0.00035086507263848226
Trained batch 867 in epoch 7, gen_loss = 0.986807846322587, disc_loss = 0.00035059924611052193
Trained batch 868 in epoch 7, gen_loss = 0.9868619931032249, disc_loss = 0.0003505243348145683
Trained batch 869 in epoch 7, gen_loss = 0.9870021790608593, disc_loss = 0.00035052269876328424
Trained batch 870 in epoch 7, gen_loss = 0.9869455700626877, disc_loss = 0.0003504930804124723
Trained batch 871 in epoch 7, gen_loss = 0.9869508243618755, disc_loss = 0.00035036159956814675
Trained batch 872 in epoch 7, gen_loss = 0.9871066029675365, disc_loss = 0.00035017372142767027
Trained batch 873 in epoch 7, gen_loss = 0.9870212135380411, disc_loss = 0.0003498556758772616
Trained batch 874 in epoch 7, gen_loss = 0.9870121380942208, disc_loss = 0.0003495441014778667
Trained batch 875 in epoch 7, gen_loss = 0.9869635528353251, disc_loss = 0.0003492064673136484
Trained batch 876 in epoch 7, gen_loss = 0.9869328994163765, disc_loss = 0.00034886344070388363
Trained batch 877 in epoch 7, gen_loss = 0.9869666311355278, disc_loss = 0.0003485219098871138
Trained batch 878 in epoch 7, gen_loss = 0.986834283100189, disc_loss = 0.0003482083315221117
Trained batch 879 in epoch 7, gen_loss = 0.9867851814763112, disc_loss = 0.0003479008607593476
Trained batch 880 in epoch 7, gen_loss = 0.986706634723369, disc_loss = 0.00034758525268385076
Trained batch 881 in epoch 7, gen_loss = 0.986676109012833, disc_loss = 0.0003473426040727645
Trained batch 882 in epoch 7, gen_loss = 0.9866945678083435, disc_loss = 0.00034709664595356616
Trained batch 883 in epoch 7, gen_loss = 0.9867219744899154, disc_loss = 0.00034682404579168313
Trained batch 884 in epoch 7, gen_loss = 0.9866253278349753, disc_loss = 0.0003465280483597179
Trained batch 885 in epoch 7, gen_loss = 0.9867620954529696, disc_loss = 0.0003463039553666284
Trained batch 886 in epoch 7, gen_loss = 0.9866963817812544, disc_loss = 0.00034619500803840717
Trained batch 887 in epoch 7, gen_loss = 0.9866707706236625, disc_loss = 0.0003461113389864483
Trained batch 888 in epoch 7, gen_loss = 0.9867150335665897, disc_loss = 0.0003458778109949232
Trained batch 889 in epoch 7, gen_loss = 0.9867952952224217, disc_loss = 0.00034560377465455084
Trained batch 890 in epoch 7, gen_loss = 0.9867662539251993, disc_loss = 0.00034531558688313726
Trained batch 891 in epoch 7, gen_loss = 0.9868025992216016, disc_loss = 0.00034504085427790673
Trained batch 892 in epoch 7, gen_loss = 0.9868913293552292, disc_loss = 0.0003449341295708611
Trained batch 893 in epoch 7, gen_loss = 0.9868509460748975, disc_loss = 0.0003449747721114825
Trained batch 894 in epoch 7, gen_loss = 0.9868068168283175, disc_loss = 0.00034481735850291526
Trained batch 895 in epoch 7, gen_loss = 0.986803099712623, disc_loss = 0.0003446022504119485
Trained batch 896 in epoch 7, gen_loss = 0.986654872014504, disc_loss = 0.00034440954589859114
Trained batch 897 in epoch 7, gen_loss = 0.9865158353589957, disc_loss = 0.00034433916091342314
Trained batch 898 in epoch 7, gen_loss = 0.9866185507201511, disc_loss = 0.0003441873059162064
Trained batch 899 in epoch 7, gen_loss = 0.9865020416842567, disc_loss = 0.00034403399871532907
Trained batch 900 in epoch 7, gen_loss = 0.9863984912931588, disc_loss = 0.00034380975099847433
Trained batch 901 in epoch 7, gen_loss = 0.9863472393901808, disc_loss = 0.00034361871805025507
Trained batch 902 in epoch 7, gen_loss = 0.9862879478390166, disc_loss = 0.0003434603990381532
Trained batch 903 in epoch 7, gen_loss = 0.9863047374956375, disc_loss = 0.00034320536188369686
Trained batch 904 in epoch 7, gen_loss = 0.9863261295945605, disc_loss = 0.00034290299919216495
Trained batch 905 in epoch 7, gen_loss = 0.986335592883049, disc_loss = 0.00034262048996948726
Trained batch 906 in epoch 7, gen_loss = 0.9863353128470028, disc_loss = 0.00034232064804837236
Trained batch 907 in epoch 7, gen_loss = 0.98639785199701, disc_loss = 0.00034200842225844515
Trained batch 908 in epoch 7, gen_loss = 0.9864613129229698, disc_loss = 0.00034174199721670803
Trained batch 909 in epoch 7, gen_loss = 0.9863735863795647, disc_loss = 0.0003416021594802969
Trained batch 910 in epoch 7, gen_loss = 0.9862790275876269, disc_loss = 0.0003416352709233605
Trained batch 911 in epoch 7, gen_loss = 0.9863855282596329, disc_loss = 0.0003415570644464376
Trained batch 912 in epoch 7, gen_loss = 0.9862474307564759, disc_loss = 0.00034130103658763756
Trained batch 913 in epoch 7, gen_loss = 0.9863682661849508, disc_loss = 0.00034111605796458466
Trained batch 914 in epoch 7, gen_loss = 0.9862825179360604, disc_loss = 0.000341126765708962
Trained batch 915 in epoch 7, gen_loss = 0.9862217127495978, disc_loss = 0.0003412542981087669
Trained batch 916 in epoch 7, gen_loss = 0.9862563651676657, disc_loss = 0.0003412967006314529
Trained batch 917 in epoch 7, gen_loss = 0.9863381572798187, disc_loss = 0.00034115501483599885
Trained batch 918 in epoch 7, gen_loss = 0.9863684854517824, disc_loss = 0.0003409222465153098
Trained batch 919 in epoch 7, gen_loss = 0.9862850007803544, disc_loss = 0.0003406547492965689
Trained batch 920 in epoch 7, gen_loss = 0.9862360705123016, disc_loss = 0.0003404021324071541
Trained batch 921 in epoch 7, gen_loss = 0.9861775727825413, disc_loss = 0.0003401353603142499
Trained batch 922 in epoch 7, gen_loss = 0.986101107439783, disc_loss = 0.0003399644389102235
Trained batch 923 in epoch 7, gen_loss = 0.9862468545183991, disc_loss = 0.0003398886560894248
Trained batch 924 in epoch 7, gen_loss = 0.9862773156166077, disc_loss = 0.00033972266431806636
Trained batch 925 in epoch 7, gen_loss = 0.9862325696785558, disc_loss = 0.00033956996449135464
Trained batch 926 in epoch 7, gen_loss = 0.9862537595575038, disc_loss = 0.00033959123524286515
Trained batch 927 in epoch 7, gen_loss = 0.9862312595520554, disc_loss = 0.0003396545000080958
Trained batch 928 in epoch 7, gen_loss = 0.9863251507346417, disc_loss = 0.00033964311935288146
Trained batch 929 in epoch 7, gen_loss = 0.9864145783326959, disc_loss = 0.0003395527225513179
Trained batch 930 in epoch 7, gen_loss = 0.9863631232340533, disc_loss = 0.00033948103004136066
Trained batch 931 in epoch 7, gen_loss = 0.9862976408055923, disc_loss = 0.0003393385248413785
Trained batch 932 in epoch 7, gen_loss = 0.9861969803434987, disc_loss = 0.00033912473936594043
Trained batch 933 in epoch 7, gen_loss = 0.9860769956984918, disc_loss = 0.0003388624412865601
Trained batch 934 in epoch 7, gen_loss = 0.9860062996333934, disc_loss = 0.0003385969919622888
Trained batch 935 in epoch 7, gen_loss = 0.9860323037729304, disc_loss = 0.00033846194986074255
Trained batch 936 in epoch 7, gen_loss = 0.9860712104698637, disc_loss = 0.0003383583768744957
Trained batch 937 in epoch 7, gen_loss = 0.9860091117907689, disc_loss = 0.00033816877884456075
Trained batch 938 in epoch 7, gen_loss = 0.9859289139096602, disc_loss = 0.0003379760444221244
Trained batch 939 in epoch 7, gen_loss = 0.9859860369499693, disc_loss = 0.0003378521147556541
Trained batch 940 in epoch 7, gen_loss = 0.9859368516712209, disc_loss = 0.0003376977591339326
Trained batch 941 in epoch 7, gen_loss = 0.985858777526078, disc_loss = 0.00033748575226084807
Trained batch 942 in epoch 7, gen_loss = 0.9859357158300859, disc_loss = 0.0003372665786544295
Trained batch 943 in epoch 7, gen_loss = 0.9859560629573919, disc_loss = 0.00033704176638111986
Trained batch 944 in epoch 7, gen_loss = 0.9860085696770401, disc_loss = 0.0003367616269094118
Trained batch 945 in epoch 7, gen_loss = 0.9859626608847564, disc_loss = 0.0003364436695762358
Trained batch 946 in epoch 7, gen_loss = 0.9860014097869333, disc_loss = 0.0003362194190011163
Trained batch 947 in epoch 7, gen_loss = 0.9858835267240991, disc_loss = 0.00033599367933778853
Trained batch 948 in epoch 7, gen_loss = 0.9859689645571251, disc_loss = 0.00033575418033907967
Trained batch 949 in epoch 7, gen_loss = 0.9858875993051027, disc_loss = 0.00033555137279970377
Trained batch 950 in epoch 7, gen_loss = 0.985847858851139, disc_loss = 0.0003353236898347504
Trained batch 951 in epoch 7, gen_loss = 0.9859071649423167, disc_loss = 0.0003351169205324513
Trained batch 952 in epoch 7, gen_loss = 0.9859317074542531, disc_loss = 0.0003349862622689839
Trained batch 953 in epoch 7, gen_loss = 0.9859566611064056, disc_loss = 0.00033492992239891
Trained batch 954 in epoch 7, gen_loss = 0.9859440789796919, disc_loss = 0.00033483536781728543
Trained batch 955 in epoch 7, gen_loss = 0.9861264341047119, disc_loss = 0.0003348161276696819
Trained batch 956 in epoch 7, gen_loss = 0.9862087477960059, disc_loss = 0.00033481409461208294
Trained batch 957 in epoch 7, gen_loss = 0.98629537044338, disc_loss = 0.00033475436605751274
Trained batch 958 in epoch 7, gen_loss = 0.9862450215192482, disc_loss = 0.00033459083705327674
Trained batch 959 in epoch 7, gen_loss = 0.9861071016018589, disc_loss = 0.00033446777544365126
Trained batch 960 in epoch 7, gen_loss = 0.9861091192381439, disc_loss = 0.00033438977862392823
Trained batch 961 in epoch 7, gen_loss = 0.9860973661134248, disc_loss = 0.00033436387656859203
Trained batch 962 in epoch 7, gen_loss = 0.9860890892683407, disc_loss = 0.0003342878533947221
Trained batch 963 in epoch 7, gen_loss = 0.9861182405369905, disc_loss = 0.00033424253851386404
Trained batch 964 in epoch 7, gen_loss = 0.986202792244254, disc_loss = 0.00033417878410998503
Trained batch 965 in epoch 7, gen_loss = 0.9861835270934964, disc_loss = 0.000334140893767128
Trained batch 966 in epoch 7, gen_loss = 0.9862319070772646, disc_loss = 0.0003340711654832051
Trained batch 967 in epoch 7, gen_loss = 0.9861973192204129, disc_loss = 0.0003342136425082331
Trained batch 968 in epoch 7, gen_loss = 0.9861373488625014, disc_loss = 0.00033433855974326394
Trained batch 969 in epoch 7, gen_loss = 0.9860677327691895, disc_loss = 0.0003342818258031387
Trained batch 970 in epoch 7, gen_loss = 0.9860496320881632, disc_loss = 0.0003342607570254607
Trained batch 971 in epoch 7, gen_loss = 0.9861176630842342, disc_loss = 0.0003343438400728618
Trained batch 972 in epoch 7, gen_loss = 0.9861193831630993, disc_loss = 0.0003345795349501033
Trained batch 973 in epoch 7, gen_loss = 0.9861187441637873, disc_loss = 0.00033492675795183024
Trained batch 974 in epoch 7, gen_loss = 0.9861657915359888, disc_loss = 0.0003352815612929706
Trained batch 975 in epoch 7, gen_loss = 0.9860667774423224, disc_loss = 0.00033551102541289274
Trained batch 976 in epoch 7, gen_loss = 0.9860046649296428, disc_loss = 0.00033562337897635497
Trained batch 977 in epoch 7, gen_loss = 0.9859343495349455, disc_loss = 0.00033578705905300065
Trained batch 978 in epoch 7, gen_loss = 0.9858761286711182, disc_loss = 0.0003357813142275008
Trained batch 979 in epoch 7, gen_loss = 0.9858253880422942, disc_loss = 0.0003356655714386
Trained batch 980 in epoch 7, gen_loss = 0.9860141989409498, disc_loss = 0.0003356054759978115
Trained batch 981 in epoch 7, gen_loss = 0.9859883615295659, disc_loss = 0.0003355659650480555
Trained batch 982 in epoch 7, gen_loss = 0.9858770250425213, disc_loss = 0.0003354972366702867
Trained batch 983 in epoch 7, gen_loss = 0.9858216135724773, disc_loss = 0.0003353613760330377
Trained batch 984 in epoch 7, gen_loss = 0.9858352503195632, disc_loss = 0.000335179944212435
Trained batch 985 in epoch 7, gen_loss = 0.9857973336085345, disc_loss = 0.0003349175931066799
Trained batch 986 in epoch 7, gen_loss = 0.9857918040972229, disc_loss = 0.00033466277987475196
Trained batch 987 in epoch 7, gen_loss = 0.9858734132307261, disc_loss = 0.00033444351831592216
Trained batch 988 in epoch 7, gen_loss = 0.9857932023018509, disc_loss = 0.0003342791889875744
Trained batch 989 in epoch 7, gen_loss = 0.9857310869477012, disc_loss = 0.00033416164498170604
Trained batch 990 in epoch 7, gen_loss = 0.9856971419302655, disc_loss = 0.0003339911276010226
Trained batch 991 in epoch 7, gen_loss = 0.9858011593741756, disc_loss = 0.0003338317954316036
Trained batch 992 in epoch 7, gen_loss = 0.9857401872449532, disc_loss = 0.0003337506452431243
Trained batch 993 in epoch 7, gen_loss = 0.9856707349389612, disc_loss = 0.0003336928560785828
Trained batch 994 in epoch 7, gen_loss = 0.9856914903650331, disc_loss = 0.0003338083871344839
Trained batch 995 in epoch 7, gen_loss = 0.9856719886921496, disc_loss = 0.0003337558562152371
Trained batch 996 in epoch 7, gen_loss = 0.9857471428041831, disc_loss = 0.0003338470788323554
Trained batch 997 in epoch 7, gen_loss = 0.9856502429277959, disc_loss = 0.00033374756235853985
Trained batch 998 in epoch 7, gen_loss = 0.9857207635740141, disc_loss = 0.0003337507498856924
Trained batch 999 in epoch 7, gen_loss = 0.9857424590587616, disc_loss = 0.0003339234891391243
Trained batch 1000 in epoch 7, gen_loss = 0.9856197439230882, disc_loss = 0.000333834024728334
Trained batch 1001 in epoch 7, gen_loss = 0.9855791139388512, disc_loss = 0.00033367443688757793
Trained batch 1002 in epoch 7, gen_loss = 0.9855175995874262, disc_loss = 0.0003334842066100988
Trained batch 1003 in epoch 7, gen_loss = 0.985555408782218, disc_loss = 0.000333328506593285
Trained batch 1004 in epoch 7, gen_loss = 0.985537273433078, disc_loss = 0.00033315398962154697
Trained batch 1005 in epoch 7, gen_loss = 0.9855710645437714, disc_loss = 0.00033300283882253394
Trained batch 1006 in epoch 7, gen_loss = 0.9855324332384983, disc_loss = 0.0003328726684894619
Trained batch 1007 in epoch 7, gen_loss = 0.9854139339119669, disc_loss = 0.0003327495956433441
Trained batch 1008 in epoch 7, gen_loss = 0.9852829235868955, disc_loss = 0.0003326392755535066
Trained batch 1009 in epoch 7, gen_loss = 0.9852735805629503, disc_loss = 0.00033259326814688827
Trained batch 1010 in epoch 7, gen_loss = 0.9851273100760524, disc_loss = 0.0003325851394074166
Trained batch 1011 in epoch 7, gen_loss = 0.9850731353632546, disc_loss = 0.00033262332183914674
Trained batch 1012 in epoch 7, gen_loss = 0.984941425881287, disc_loss = 0.00033275690102824016
Trained batch 1013 in epoch 7, gen_loss = 0.9849353141685915, disc_loss = 0.00033301953657575485
Trained batch 1014 in epoch 7, gen_loss = 0.9849344122585992, disc_loss = 0.00033328071669727025
Trained batch 1015 in epoch 7, gen_loss = 0.9849548047100465, disc_loss = 0.000333469911124917
Trained batch 1016 in epoch 7, gen_loss = 0.9848920452090726, disc_loss = 0.0003335615577448765
Trained batch 1017 in epoch 7, gen_loss = 0.984880914095577, disc_loss = 0.0003335606499554151
Trained batch 1018 in epoch 7, gen_loss = 0.9848683933865451, disc_loss = 0.00033348895232171465
Trained batch 1019 in epoch 7, gen_loss = 0.984819632710195, disc_loss = 0.000333371697278755
Trained batch 1020 in epoch 7, gen_loss = 0.9847329556650093, disc_loss = 0.0003332394750623592
Trained batch 1021 in epoch 7, gen_loss = 0.9848103808446873, disc_loss = 0.0003333200713381633
Trained batch 1022 in epoch 7, gen_loss = 0.9849080279076204, disc_loss = 0.0003341435469394638
Trained batch 1023 in epoch 7, gen_loss = 0.9848199571715668, disc_loss = 0.0003350378583988345
Trained batch 1024 in epoch 7, gen_loss = 0.9848997454526948, disc_loss = 0.0003356308781857057
Trained batch 1025 in epoch 7, gen_loss = 0.9849157098673473, disc_loss = 0.00033590633132771615
Trained batch 1026 in epoch 7, gen_loss = 0.9849059955518922, disc_loss = 0.00033634633506178274
Trained batch 1027 in epoch 7, gen_loss = 0.9848381852013591, disc_loss = 0.00033698830361484147
Trained batch 1028 in epoch 7, gen_loss = 0.984744364712514, disc_loss = 0.0003378407913528856
Trained batch 1029 in epoch 7, gen_loss = 0.9847370027338417, disc_loss = 0.00033870691317557447
Trained batch 1030 in epoch 7, gen_loss = 0.9847408119737234, disc_loss = 0.0003393499814508556
Trained batch 1031 in epoch 7, gen_loss = 0.984642219982406, disc_loss = 0.0003397663576975027
Trained batch 1032 in epoch 7, gen_loss = 0.9845955210295213, disc_loss = 0.0003397975473356251
Trained batch 1033 in epoch 7, gen_loss = 0.984552826134333, disc_loss = 0.00033969348843838356
Trained batch 1034 in epoch 7, gen_loss = 0.9845728131308071, disc_loss = 0.0003401249917440571
Trained batch 1035 in epoch 7, gen_loss = 0.9844882160885454, disc_loss = 0.00034151722758773105
Trained batch 1036 in epoch 7, gen_loss = 0.9843611985071415, disc_loss = 0.0003426837521482716
Trained batch 1037 in epoch 7, gen_loss = 0.9843815340012714, disc_loss = 0.00034380306067984407
Trained batch 1038 in epoch 7, gen_loss = 0.9842240177632755, disc_loss = 0.0003451088290694403
Trained batch 1039 in epoch 7, gen_loss = 0.9841989317192481, disc_loss = 0.0003462843092445557
Trained batch 1040 in epoch 7, gen_loss = 0.9842123349164107, disc_loss = 0.00034697765747840516
Trained batch 1041 in epoch 7, gen_loss = 0.9842176531761484, disc_loss = 0.00034726391450039224
Trained batch 1042 in epoch 7, gen_loss = 0.9841978477380191, disc_loss = 0.00034730602901975635
Trained batch 1043 in epoch 7, gen_loss = 0.9842123047259576, disc_loss = 0.0003472232380643834
Trained batch 1044 in epoch 7, gen_loss = 0.9841447666501314, disc_loss = 0.0003472043755065993
Trained batch 1045 in epoch 7, gen_loss = 0.9842617237659075, disc_loss = 0.0003476492418148212
Trained batch 1046 in epoch 7, gen_loss = 0.98431175070483, disc_loss = 0.00034856782438939105
Trained batch 1047 in epoch 7, gen_loss = 0.9843359087373464, disc_loss = 0.0003494247343777861
Trained batch 1048 in epoch 7, gen_loss = 0.9843342496282834, disc_loss = 0.0003498504462755006
Trained batch 1049 in epoch 7, gen_loss = 0.9842943911325364, disc_loss = 0.0003499100070205584
Trained batch 1050 in epoch 7, gen_loss = 0.9842739902599781, disc_loss = 0.0003497439123381423
Trained batch 1051 in epoch 7, gen_loss = 0.9842252161339662, disc_loss = 0.00034960574853374975
Trained batch 1052 in epoch 7, gen_loss = 0.9841452366040077, disc_loss = 0.0003494333545353988
Trained batch 1053 in epoch 7, gen_loss = 0.9841695269552082, disc_loss = 0.0003493391604951262
Trained batch 1054 in epoch 7, gen_loss = 0.9841038616347652, disc_loss = 0.00034939533968371124
Trained batch 1055 in epoch 7, gen_loss = 0.9840491448500843, disc_loss = 0.0003493562196581479
Trained batch 1056 in epoch 7, gen_loss = 0.9840839499556578, disc_loss = 0.0003492989713964784
Trained batch 1057 in epoch 7, gen_loss = 0.9840609683656963, disc_loss = 0.00034907916664200463
Trained batch 1058 in epoch 7, gen_loss = 0.9842126236646326, disc_loss = 0.0003489607085600914
Trained batch 1059 in epoch 7, gen_loss = 0.984153318798767, disc_loss = 0.00034943646803511447
Trained batch 1060 in epoch 7, gen_loss = 0.984048298852383, disc_loss = 0.0003502719532151976
Trained batch 1061 in epoch 7, gen_loss = 0.9840928243715211, disc_loss = 0.00035082929834645424
Trained batch 1062 in epoch 7, gen_loss = 0.9840734038056905, disc_loss = 0.0003509878231353115
Trained batch 1063 in epoch 7, gen_loss = 0.9840572800739367, disc_loss = 0.00035089950209734715
Trained batch 1064 in epoch 7, gen_loss = 0.9841128327477147, disc_loss = 0.00035077738958222903
Trained batch 1065 in epoch 7, gen_loss = 0.9840941624279094, disc_loss = 0.0003507214591914428
Trained batch 1066 in epoch 7, gen_loss = 0.9840458429854052, disc_loss = 0.0003508328501453262
Trained batch 1067 in epoch 7, gen_loss = 0.9841608119926203, disc_loss = 0.0003507106046574731
Trained batch 1068 in epoch 7, gen_loss = 0.9841568622776456, disc_loss = 0.0003504809136849839
Trained batch 1069 in epoch 7, gen_loss = 0.9841973596644179, disc_loss = 0.00035029449332864504
Trained batch 1070 in epoch 7, gen_loss = 0.9841680513933148, disc_loss = 0.0003500908000720143
Trained batch 1071 in epoch 7, gen_loss = 0.9842176380108542, disc_loss = 0.0003498623373636645
Trained batch 1072 in epoch 7, gen_loss = 0.9841006298211836, disc_loss = 0.00034962218666245433
Trained batch 1073 in epoch 7, gen_loss = 0.9841287995738912, disc_loss = 0.0003493922987341594
Trained batch 1074 in epoch 7, gen_loss = 0.9840406357410342, disc_loss = 0.00034917947143819835
Trained batch 1075 in epoch 7, gen_loss = 0.9840323237016741, disc_loss = 0.0003490350382893409
Trained batch 1076 in epoch 7, gen_loss = 0.9838498686902923, disc_loss = 0.000348937038623046
Trained batch 1077 in epoch 7, gen_loss = 0.9838720923894412, disc_loss = 0.00034880396691031095
Trained batch 1078 in epoch 7, gen_loss = 0.983817108590035, disc_loss = 0.00034860667220427526
Trained batch 1079 in epoch 7, gen_loss = 0.9838109096995107, disc_loss = 0.0003483700114210714
Trained batch 1080 in epoch 7, gen_loss = 0.9838236561536128, disc_loss = 0.00034815005233149914
Trained batch 1081 in epoch 7, gen_loss = 0.9838391345221542, disc_loss = 0.00034790371052476245
Trained batch 1082 in epoch 7, gen_loss = 0.9838278409736859, disc_loss = 0.00034764951504346643
Trained batch 1083 in epoch 7, gen_loss = 0.9839224785126444, disc_loss = 0.0003474000134456789
Trained batch 1084 in epoch 7, gen_loss = 0.9839611880240902, disc_loss = 0.0003471698438156448
Trained batch 1085 in epoch 7, gen_loss = 0.9840193012691554, disc_loss = 0.00034700381954077934
Trained batch 1086 in epoch 7, gen_loss = 0.9840430580045284, disc_loss = 0.0003469366742072673
Trained batch 1087 in epoch 7, gen_loss = 0.9840309853829882, disc_loss = 0.00034690744022929505
Trained batch 1088 in epoch 7, gen_loss = 0.9839701174704496, disc_loss = 0.000346733104546415
Trained batch 1089 in epoch 7, gen_loss = 0.9839787971535954, disc_loss = 0.0003466254606983975
Trained batch 1090 in epoch 7, gen_loss = 0.9839858029218685, disc_loss = 0.00034648137477928247
Trained batch 1091 in epoch 7, gen_loss = 0.9840328793276797, disc_loss = 0.0003463855990868159
Trained batch 1092 in epoch 7, gen_loss = 0.9839703298880218, disc_loss = 0.0003462196445306218
Trained batch 1093 in epoch 7, gen_loss = 0.9839536774855863, disc_loss = 0.0003460576962020931
Trained batch 1094 in epoch 7, gen_loss = 0.9838641404561256, disc_loss = 0.0003460067036624394
Trained batch 1095 in epoch 7, gen_loss = 0.9838522376261488, disc_loss = 0.00034591699541190783
Trained batch 1096 in epoch 7, gen_loss = 0.9839592468445151, disc_loss = 0.0003457386324421138
Trained batch 1097 in epoch 7, gen_loss = 0.9839056934923857, disc_loss = 0.00034553722882086073
Trained batch 1098 in epoch 7, gen_loss = 0.9838359699236251, disc_loss = 0.000345321927196378
Trained batch 1099 in epoch 7, gen_loss = 0.9839374910159544, disc_loss = 0.0003451282475924183
Trained batch 1100 in epoch 7, gen_loss = 0.9838717068789982, disc_loss = 0.00034490929560884487
Trained batch 1101 in epoch 7, gen_loss = 0.9837515332521415, disc_loss = 0.00034473447021562395
Trained batch 1102 in epoch 7, gen_loss = 0.9837339647445263, disc_loss = 0.0003445819998996443
Trained batch 1103 in epoch 7, gen_loss = 0.983707913669987, disc_loss = 0.0003445142879040825
Trained batch 1104 in epoch 7, gen_loss = 0.9836429887227882, disc_loss = 0.0003445381194954144
Trained batch 1105 in epoch 7, gen_loss = 0.9836450925140657, disc_loss = 0.00034453731659694767
Trained batch 1106 in epoch 7, gen_loss = 0.983651071113838, disc_loss = 0.0003444230149951957
Trained batch 1107 in epoch 7, gen_loss = 0.9835695756148776, disc_loss = 0.00034425170325130073
Trained batch 1108 in epoch 7, gen_loss = 0.9836430250254701, disc_loss = 0.0003440540606225589
Trained batch 1109 in epoch 7, gen_loss = 0.9836138209781131, disc_loss = 0.0003439052568930558
Trained batch 1110 in epoch 7, gen_loss = 0.9836108599773513, disc_loss = 0.0003438024854744469
Trained batch 1111 in epoch 7, gen_loss = 0.9835480397982563, disc_loss = 0.0003436988156163548
Trained batch 1112 in epoch 7, gen_loss = 0.9835256617666898, disc_loss = 0.00034352049573113544
Trained batch 1113 in epoch 7, gen_loss = 0.9835530371811488, disc_loss = 0.00034340856711858177
Trained batch 1114 in epoch 7, gen_loss = 0.9835617811690531, disc_loss = 0.00034328046157061344
Trained batch 1115 in epoch 7, gen_loss = 0.9835193932163245, disc_loss = 0.0003431945131387204
Trained batch 1116 in epoch 7, gen_loss = 0.9835711908105664, disc_loss = 0.0003431683869745508
Trained batch 1117 in epoch 7, gen_loss = 0.9835671146461916, disc_loss = 0.00034312460791524325
Trained batch 1118 in epoch 7, gen_loss = 0.983549785198539, disc_loss = 0.0003429934116251749
Trained batch 1119 in epoch 7, gen_loss = 0.983598215292607, disc_loss = 0.0003428796453785513
Trained batch 1120 in epoch 7, gen_loss = 0.9834590866882603, disc_loss = 0.0003429116575953669
Trained batch 1121 in epoch 7, gen_loss = 0.9833378931524069, disc_loss = 0.00034333546039350154
Trained batch 1122 in epoch 7, gen_loss = 0.9833202097209988, disc_loss = 0.000343711750203433
Trained batch 1123 in epoch 7, gen_loss = 0.9832428489609545, disc_loss = 0.0003437935962644468
Trained batch 1124 in epoch 7, gen_loss = 0.9831390388276842, disc_loss = 0.00034376728226197885
Trained batch 1125 in epoch 7, gen_loss = 0.9830362447413415, disc_loss = 0.0003436697469160418
Trained batch 1126 in epoch 7, gen_loss = 0.9830233879393989, disc_loss = 0.00034358737768921233
Trained batch 1127 in epoch 7, gen_loss = 0.9830408942826251, disc_loss = 0.0003435301630570845
Trained batch 1128 in epoch 7, gen_loss = 0.9830445559073382, disc_loss = 0.00034346447404841313
Trained batch 1129 in epoch 7, gen_loss = 0.9830501550594263, disc_loss = 0.00034327386277423867
Trained batch 1130 in epoch 7, gen_loss = 0.9829418230752414, disc_loss = 0.00034313679821745005
Trained batch 1131 in epoch 7, gen_loss = 0.9829910677123828, disc_loss = 0.00034311173065091846
Trained batch 1132 in epoch 7, gen_loss = 0.9828684660889675, disc_loss = 0.00034318413853318374
Trained batch 1133 in epoch 7, gen_loss = 0.9829893216779834, disc_loss = 0.00034362013266891827
Trained batch 1134 in epoch 7, gen_loss = 0.9830612566502609, disc_loss = 0.00034426834933907986
Trained batch 1135 in epoch 7, gen_loss = 0.9830477427114064, disc_loss = 0.0003449163022017107
Trained batch 1136 in epoch 7, gen_loss = 0.9830681921729102, disc_loss = 0.00034554379261468425
Trained batch 1137 in epoch 7, gen_loss = 0.9830580194511815, disc_loss = 0.00034604460584833075
Trained batch 1138 in epoch 7, gen_loss = 0.9830524378224775, disc_loss = 0.00034629018033824615
Trained batch 1139 in epoch 7, gen_loss = 0.9829377844668271, disc_loss = 0.00034648647760740573
Trained batch 1140 in epoch 7, gen_loss = 0.9828970570714718, disc_loss = 0.0003468136158156067
Trained batch 1141 in epoch 7, gen_loss = 0.9828860044166211, disc_loss = 0.0003471551910842481
Trained batch 1142 in epoch 7, gen_loss = 0.9829506653500354, disc_loss = 0.0003473721565108861
Trained batch 1143 in epoch 7, gen_loss = 0.9829386131434174, disc_loss = 0.00034735953513073117
Trained batch 1144 in epoch 7, gen_loss = 0.9829235246087786, disc_loss = 0.0003472798322004624
Trained batch 1145 in epoch 7, gen_loss = 0.9828635497347015, disc_loss = 0.0003472125473145065
Trained batch 1146 in epoch 7, gen_loss = 0.9828939984025598, disc_loss = 0.00034724630891783294
Trained batch 1147 in epoch 7, gen_loss = 0.9829458107827848, disc_loss = 0.00034726522513183573
Trained batch 1148 in epoch 7, gen_loss = 0.9828420490986166, disc_loss = 0.00034719357341922067
Trained batch 1149 in epoch 7, gen_loss = 0.9828561427800552, disc_loss = 0.00034701864483751074
Trained batch 1150 in epoch 7, gen_loss = 0.9829514361691413, disc_loss = 0.00034681476114315147
Trained batch 1151 in epoch 7, gen_loss = 0.9829334738250408, disc_loss = 0.0003465942339428491
Trained batch 1152 in epoch 7, gen_loss = 0.982942196977521, disc_loss = 0.0003463789346288742
Trained batch 1153 in epoch 7, gen_loss = 0.9829145534096392, disc_loss = 0.0003462295301891181
Trained batch 1154 in epoch 7, gen_loss = 0.9829136661120823, disc_loss = 0.00034617605511158567
Trained batch 1155 in epoch 7, gen_loss = 0.9829151920690669, disc_loss = 0.00034611979779294107
Trained batch 1156 in epoch 7, gen_loss = 0.9828736514703096, disc_loss = 0.00034600979178618077
Trained batch 1157 in epoch 7, gen_loss = 0.9827346040486055, disc_loss = 0.00034584935838054016
Trained batch 1158 in epoch 7, gen_loss = 0.9826306958873278, disc_loss = 0.0003456961989462134
Trained batch 1159 in epoch 7, gen_loss = 0.9826773381952582, disc_loss = 0.0003455895777670807
Trained batch 1160 in epoch 7, gen_loss = 0.9826267489475181, disc_loss = 0.0003455132953621568
Trained batch 1161 in epoch 7, gen_loss = 0.982506365866341, disc_loss = 0.000345594897432597
Trained batch 1162 in epoch 7, gen_loss = 0.982466446820355, disc_loss = 0.0003457011572378712
Trained batch 1163 in epoch 7, gen_loss = 0.9825621037856, disc_loss = 0.0003458089224383202
Trained batch 1164 in epoch 7, gen_loss = 0.9825379124526814, disc_loss = 0.00034592503947460655
Trained batch 1165 in epoch 7, gen_loss = 0.9825724340323518, disc_loss = 0.0003460365357535902
Trained batch 1166 in epoch 7, gen_loss = 0.9825568504076078, disc_loss = 0.0003460871687664406
Trained batch 1167 in epoch 7, gen_loss = 0.9824974352672492, disc_loss = 0.00034600930045711073
Trained batch 1168 in epoch 7, gen_loss = 0.982564885510248, disc_loss = 0.0003461310493972824
Trained batch 1169 in epoch 7, gen_loss = 0.9824640885377541, disc_loss = 0.00034616232103281097
Trained batch 1170 in epoch 7, gen_loss = 0.98237333818952, disc_loss = 0.0003530381817833829
Trained batch 1171 in epoch 7, gen_loss = 0.9826269595289393, disc_loss = 0.000379055469480783
Trained batch 1172 in epoch 7, gen_loss = 0.9825959020156892, disc_loss = 0.0004309753138037142
Trained batch 1173 in epoch 7, gen_loss = 0.9826934761550195, disc_loss = 0.000542944031857536
Trained batch 1174 in epoch 7, gen_loss = 0.9826008697773548, disc_loss = 0.0007430280186421674
Trained batch 1175 in epoch 7, gen_loss = 0.9827843694155719, disc_loss = 0.0009049817862105061
Trained batch 1176 in epoch 7, gen_loss = 0.982949554109938, disc_loss = 0.0011383413603222618
Trained batch 1177 in epoch 7, gen_loss = 0.9827946395643296, disc_loss = 0.0012212286419649738
Trained batch 1178 in epoch 7, gen_loss = 0.9829358821505707, disc_loss = 0.0012846765190743972
Trained batch 1179 in epoch 7, gen_loss = 0.9829684581291878, disc_loss = 0.0013947952645463313
Trained batch 1180 in epoch 7, gen_loss = 0.9830012481460927, disc_loss = 0.0014949086324278179
Trained batch 1181 in epoch 7, gen_loss = 0.9830180950677133, disc_loss = 0.0015217709081832382
Trained batch 1182 in epoch 7, gen_loss = 0.9830258418620892, disc_loss = 0.0015303110739436935
Trained batch 1183 in epoch 7, gen_loss = 0.9829150549060589, disc_loss = 0.0015347351920440447
Trained batch 1184 in epoch 7, gen_loss = 0.9829109169762849, disc_loss = 0.001538978036480046
Trained batch 1185 in epoch 7, gen_loss = 0.9829726002067579, disc_loss = 0.001540829212789125
Trained batch 1186 in epoch 7, gen_loss = 0.9829673656617882, disc_loss = 0.001542046288574001
Trained batch 1187 in epoch 7, gen_loss = 0.982916896090363, disc_loss = 0.0015425841800067617
Trained batch 1188 in epoch 7, gen_loss = 0.9829390467065438, disc_loss = 0.0015437930651800492
Trained batch 1189 in epoch 7, gen_loss = 0.9829438842144333, disc_loss = 0.0015434754968553825
Trained batch 1190 in epoch 7, gen_loss = 0.9829669144351777, disc_loss = 0.0015434307713240152
Trained batch 1191 in epoch 7, gen_loss = 0.9829553670231128, disc_loss = 0.0015431566035359666
Trained batch 1192 in epoch 7, gen_loss = 0.9828558484246924, disc_loss = 0.0015428434818118403
Trained batch 1193 in epoch 7, gen_loss = 0.9829651457280969, disc_loss = 0.001544404789255072
Trained batch 1194 in epoch 7, gen_loss = 0.9829147819694615, disc_loss = 0.001544179922381609
Trained batch 1195 in epoch 7, gen_loss = 0.982934540729459, disc_loss = 0.001543856888111199
Trained batch 1196 in epoch 7, gen_loss = 0.982873280942689, disc_loss = 0.0015454146428272083
Trained batch 1197 in epoch 7, gen_loss = 0.9828034860263882, disc_loss = 0.0015537874812779863
Trained batch 1198 in epoch 7, gen_loss = 0.9828671444645517, disc_loss = 0.0015569775744334615
Trained batch 1199 in epoch 7, gen_loss = 0.9829092533389727, disc_loss = 0.0015568017140018735
Trained batch 1200 in epoch 7, gen_loss = 0.9830003382264327, disc_loss = 0.0015565470126030526
Trained batch 1201 in epoch 7, gen_loss = 0.9830164537453612, disc_loss = 0.0015562859507569228
Trained batch 1202 in epoch 7, gen_loss = 0.9830382489603159, disc_loss = 0.0015555238050933837
Trained batch 1203 in epoch 7, gen_loss = 0.9831037288686366, disc_loss = 0.0015547987938930796
Trained batch 1204 in epoch 7, gen_loss = 0.9830835646118861, disc_loss = 0.0015540177469840757
Trained batch 1205 in epoch 7, gen_loss = 0.9831110055173807, disc_loss = 0.0015532278170149174
Trained batch 1206 in epoch 7, gen_loss = 0.9831117793065808, disc_loss = 0.0015531381362880459
Trained batch 1207 in epoch 7, gen_loss = 0.9830910901458848, disc_loss = 0.0015524722423815667
Trained batch 1208 in epoch 7, gen_loss = 0.9830440780759548, disc_loss = 0.0015516105449301185
Trained batch 1209 in epoch 7, gen_loss = 0.9830613178655135, disc_loss = 0.001551215791917735
Trained batch 1210 in epoch 7, gen_loss = 0.9830194616691816, disc_loss = 0.0015512791764372086
Trained batch 1211 in epoch 7, gen_loss = 0.9829525919538913, disc_loss = 0.0015504119567627916
Trained batch 1212 in epoch 7, gen_loss = 0.982931626255809, disc_loss = 0.001549759770700889
Trained batch 1213 in epoch 7, gen_loss = 0.982951114411409, disc_loss = 0.0015490030600271542
Trained batch 1214 in epoch 7, gen_loss = 0.9828593982099996, disc_loss = 0.0015479199463080465
Trained batch 1215 in epoch 7, gen_loss = 0.9828962203311292, disc_loss = 0.0015468972034233574
Trained batch 1216 in epoch 7, gen_loss = 0.9828591742472464, disc_loss = 0.001546229686979145
Trained batch 1217 in epoch 7, gen_loss = 0.9828515339563242, disc_loss = 0.001545826831578718
Trained batch 1218 in epoch 7, gen_loss = 0.982776637004965, disc_loss = 0.001546392990386282
Trained batch 1219 in epoch 7, gen_loss = 0.9826755620905611, disc_loss = 0.0015458764232894058
Trained batch 1220 in epoch 7, gen_loss = 0.9826367894808451, disc_loss = 0.0015451974620201005
Trained batch 1221 in epoch 7, gen_loss = 0.9826088450641757, disc_loss = 0.001544379335375849
Trained batch 1222 in epoch 7, gen_loss = 0.98254895497811, disc_loss = 0.0015438543282155018
Trained batch 1223 in epoch 7, gen_loss = 0.9825400826490782, disc_loss = 0.0015429563537372518
Trained batch 1224 in epoch 7, gen_loss = 0.9824876961416128, disc_loss = 0.001542023540413891
Trained batch 1225 in epoch 7, gen_loss = 0.9825188196697204, disc_loss = 0.001541018602396728
Trained batch 1226 in epoch 7, gen_loss = 0.9824769317180817, disc_loss = 0.0015399655109135638
Trained batch 1227 in epoch 7, gen_loss = 0.9825239314512632, disc_loss = 0.0015390234876556132
Trained batch 1228 in epoch 7, gen_loss = 0.9825088490403892, disc_loss = 0.0015379674904194033
Trained batch 1229 in epoch 7, gen_loss = 0.9825037165870512, disc_loss = 0.0015370908532894077
Trained batch 1230 in epoch 7, gen_loss = 0.9824508618378813, disc_loss = 0.0015361285339161896
Trained batch 1231 in epoch 7, gen_loss = 0.9824995517537192, disc_loss = 0.0015354629087490244
Trained batch 1232 in epoch 7, gen_loss = 0.9824382481493799, disc_loss = 0.0015352895784244
Trained batch 1233 in epoch 7, gen_loss = 0.9824194607703767, disc_loss = 0.0015350385948152314
Trained batch 1234 in epoch 7, gen_loss = 0.9823237918166496, disc_loss = 0.0015343843776931107
Trained batch 1235 in epoch 7, gen_loss = 0.9825637146685887, disc_loss = 0.0015354171442171702
Trained batch 1236 in epoch 7, gen_loss = 0.9827015229358534, disc_loss = 0.0015352029995182013
Trained batch 1237 in epoch 7, gen_loss = 0.9826438912282275, disc_loss = 0.0015357889987640508
Trained batch 1238 in epoch 7, gen_loss = 0.9826732570842162, disc_loss = 0.0015354352679385584
Trained batch 1239 in epoch 7, gen_loss = 0.982632377743721, disc_loss = 0.0015397906324588187
Trained batch 1240 in epoch 7, gen_loss = 0.9827712749301378, disc_loss = 0.001542910293966622
Trained batch 1241 in epoch 7, gen_loss = 0.9829409208850585, disc_loss = 0.001544590081341931
Trained batch 1242 in epoch 7, gen_loss = 0.9828876001836787, disc_loss = 0.0015546867442008709
Trained batch 1243 in epoch 7, gen_loss = 0.9829682653164941, disc_loss = 0.0015782514361852658
Trained batch 1244 in epoch 7, gen_loss = 0.9828576099441713, disc_loss = 0.001628894963537588
Trained batch 1245 in epoch 7, gen_loss = 0.9831193231082077, disc_loss = 0.0020427529584397513
Trained batch 1246 in epoch 7, gen_loss = 0.9832099168512853, disc_loss = 0.002100956842315459
Trained batch 1247 in epoch 7, gen_loss = 0.9831258972676901, disc_loss = 0.0021425053802058523
Trained batch 1248 in epoch 7, gen_loss = 0.9830661894704362, disc_loss = 0.0021634509608903477
Trained batch 1249 in epoch 7, gen_loss = 0.9829639235496521, disc_loss = 0.002276246996462578
Trained batch 1250 in epoch 7, gen_loss = 0.9829796794697726, disc_loss = 0.0023119236835594317
Trained batch 1251 in epoch 7, gen_loss = 0.9829717487477647, disc_loss = 0.0023195010451632033
Trained batch 1252 in epoch 7, gen_loss = 0.9832156406149137, disc_loss = 0.0023218458100816766
Trained batch 1253 in epoch 7, gen_loss = 0.9833692279443786, disc_loss = 0.00232547544935174
Trained batch 1254 in epoch 7, gen_loss = 0.9835257278020638, disc_loss = 0.002330768663688717
Trained batch 1255 in epoch 7, gen_loss = 0.9836099843975086, disc_loss = 0.0023323535969020496
Trained batch 1256 in epoch 7, gen_loss = 0.9836975257834842, disc_loss = 0.002332435889953687
Trained batch 1257 in epoch 7, gen_loss = 0.983703878896225, disc_loss = 0.0023317062896153046
Trained batch 1258 in epoch 7, gen_loss = 0.9837315498220248, disc_loss = 0.002331250082609949
Trained batch 1259 in epoch 7, gen_loss = 0.9836258189545737, disc_loss = 0.0023346389213815748
Trained batch 1260 in epoch 7, gen_loss = 0.983571426722854, disc_loss = 0.002339644832322627
Trained batch 1261 in epoch 7, gen_loss = 0.9833196336418248, disc_loss = 0.0024581765452115823
Trained batch 1262 in epoch 7, gen_loss = 0.983484332653991, disc_loss = 0.002864332960215307
Trained batch 1263 in epoch 7, gen_loss = 0.9833142969615852, disc_loss = 0.0029507993042760155
Trained batch 1264 in epoch 7, gen_loss = 0.9831005746196853, disc_loss = 0.003103038804701542
Trained batch 1265 in epoch 7, gen_loss = 0.9830553877692652, disc_loss = 0.0031116766674302195
Trained batch 1266 in epoch 7, gen_loss = 0.9831192335841593, disc_loss = 0.0031240849159719056
Trained batch 1267 in epoch 7, gen_loss = 0.9831810829109198, disc_loss = 0.003127699620061275
Trained batch 1268 in epoch 7, gen_loss = 0.983195644133292, disc_loss = 0.0031315132268245143
Trained batch 1269 in epoch 7, gen_loss = 0.9832690252563147, disc_loss = 0.003137386257914454
Trained batch 1270 in epoch 7, gen_loss = 0.983252228338075, disc_loss = 0.0031367305541789964
Trained batch 1271 in epoch 7, gen_loss = 0.9831996377815241, disc_loss = 0.003137883150953232
Trained batch 1272 in epoch 7, gen_loss = 0.9831792248671952, disc_loss = 0.0031459028908117485
Trained batch 1273 in epoch 7, gen_loss = 0.9834279440916501, disc_loss = 0.0031472073568346356
Trained batch 1274 in epoch 7, gen_loss = 0.9834446498926948, disc_loss = 0.003160501734459745
Trained batch 1275 in epoch 7, gen_loss = 0.9835279643255341, disc_loss = 0.003161777936223083
Trained batch 1276 in epoch 7, gen_loss = 0.9836093257812195, disc_loss = 0.003165947125922933
Trained batch 1277 in epoch 7, gen_loss = 0.9837049477630191, disc_loss = 0.003166779783075096
Trained batch 1278 in epoch 7, gen_loss = 0.9837710093575777, disc_loss = 0.0031675553622281384
Trained batch 1279 in epoch 7, gen_loss = 0.9840168853756041, disc_loss = 0.0031848972094451256
Trained batch 1280 in epoch 7, gen_loss = 0.9841941137689804, disc_loss = 0.003191576143603339
Trained batch 1281 in epoch 7, gen_loss = 0.9841849036317162, disc_loss = 0.003192600922226296
Trained batch 1282 in epoch 7, gen_loss = 0.9841742844945829, disc_loss = 0.0031933096832861534
Trained batch 1283 in epoch 7, gen_loss = 0.9842218829556789, disc_loss = 0.0031943799124313377
Trained batch 1284 in epoch 7, gen_loss = 0.984281487270088, disc_loss = 0.0031932809861734282
Trained batch 1285 in epoch 7, gen_loss = 0.9842982791352606, disc_loss = 0.0031917485712072285
Trained batch 1286 in epoch 7, gen_loss = 0.9843546288737791, disc_loss = 0.003190688660405455
Trained batch 1287 in epoch 7, gen_loss = 0.9843195542137816, disc_loss = 0.003189524826706
Trained batch 1288 in epoch 7, gen_loss = 0.9843725378056475, disc_loss = 0.003188043759584716
Trained batch 1289 in epoch 7, gen_loss = 0.9844402010588683, disc_loss = 0.0031862158497559475
Trained batch 1290 in epoch 7, gen_loss = 0.9844128732806855, disc_loss = 0.003184416395966492
Trained batch 1291 in epoch 7, gen_loss = 0.9845716890535856, disc_loss = 0.0031827732501445638
Trained batch 1292 in epoch 7, gen_loss = 0.9846022310684747, disc_loss = 0.0031809224992973297
Trained batch 1293 in epoch 7, gen_loss = 0.9844924179719073, disc_loss = 0.0031808219477482565
Trained batch 1294 in epoch 7, gen_loss = 0.9844962639237923, disc_loss = 0.0031793737951290803
Trained batch 1295 in epoch 7, gen_loss = 0.9845659108257588, disc_loss = 0.003177688556246003
Trained batch 1296 in epoch 7, gen_loss = 0.9845865376655561, disc_loss = 0.0031761250393370468
Trained batch 1297 in epoch 7, gen_loss = 0.9845356955917665, disc_loss = 0.0031741876082995047
Trained batch 1298 in epoch 7, gen_loss = 0.9845626185360645, disc_loss = 0.0031722601249298634
Trained batch 1299 in epoch 7, gen_loss = 0.9846669277778038, disc_loss = 0.003170223473621613
Trained batch 1300 in epoch 7, gen_loss = 0.9845157448462941, disc_loss = 0.0031699229230595376
Trained batch 1301 in epoch 7, gen_loss = 0.984487701396239, disc_loss = 0.0031681538993829717
Trained batch 1302 in epoch 7, gen_loss = 0.9844698383089038, disc_loss = 0.0031664811221045813
Trained batch 1303 in epoch 7, gen_loss = 0.9844757277358529, disc_loss = 0.003165024002700656
Trained batch 1304 in epoch 7, gen_loss = 0.9845075465710227, disc_loss = 0.003163499418621342
Trained batch 1305 in epoch 7, gen_loss = 0.9844732423288717, disc_loss = 0.0031616994238494317
Trained batch 1306 in epoch 7, gen_loss = 0.9845403288736905, disc_loss = 0.003159678476063334
Trained batch 1307 in epoch 7, gen_loss = 0.9843982037965675, disc_loss = 0.003158663533694427
Trained batch 1308 in epoch 7, gen_loss = 0.9844994426593241, disc_loss = 0.0031569502894100774
Trained batch 1309 in epoch 7, gen_loss = 0.9845118537203956, disc_loss = 0.0031554704187724486
Trained batch 1310 in epoch 7, gen_loss = 0.984548240468122, disc_loss = 0.0031535646645230145
Trained batch 1311 in epoch 7, gen_loss = 0.98449409730369, disc_loss = 0.0031515561975416725
Trained batch 1312 in epoch 7, gen_loss = 0.9844666465220339, disc_loss = 0.0031498000228400973
Trained batch 1313 in epoch 7, gen_loss = 0.9845576838815593, disc_loss = 0.0031483204393682428
Trained batch 1314 in epoch 7, gen_loss = 0.9845430276239779, disc_loss = 0.0031462496155910567
Trained batch 1315 in epoch 7, gen_loss = 0.9845198612082693, disc_loss = 0.003144499683171862
Trained batch 1316 in epoch 7, gen_loss = 0.9845811095125493, disc_loss = 0.003142771282249076
Trained batch 1317 in epoch 7, gen_loss = 0.9845401844594837, disc_loss = 0.0031407983486641043
Trained batch 1318 in epoch 7, gen_loss = 0.9845028449587067, disc_loss = 0.003138716350956013
Trained batch 1319 in epoch 7, gen_loss = 0.9844269211545135, disc_loss = 0.0031369164406428217
Trained batch 1320 in epoch 7, gen_loss = 0.9843525706954656, disc_loss = 0.003134926299385511
Trained batch 1321 in epoch 7, gen_loss = 0.9842459911567901, disc_loss = 0.003133035312489187
Trained batch 1322 in epoch 7, gen_loss = 0.9842677876432105, disc_loss = 0.0031309729344690643
Trained batch 1323 in epoch 7, gen_loss = 0.9843247842122421, disc_loss = 0.0031295602689430787
Trained batch 1324 in epoch 7, gen_loss = 0.9843218275735963, disc_loss = 0.003128100985574387
Trained batch 1325 in epoch 7, gen_loss = 0.9843102450374385, disc_loss = 0.003127093979444463
Trained batch 1326 in epoch 7, gen_loss = 0.9843268254778846, disc_loss = 0.0031251687140158133
Trained batch 1327 in epoch 7, gen_loss = 0.9843445366854409, disc_loss = 0.0031233829646631225
Trained batch 1328 in epoch 7, gen_loss = 0.9844254157074956, disc_loss = 0.0031213831487047366
Trained batch 1329 in epoch 7, gen_loss = 0.9844036002804463, disc_loss = 0.003119504726120959
Trained batch 1330 in epoch 7, gen_loss = 0.9844352906131816, disc_loss = 0.0031175451620188816
Trained batch 1331 in epoch 7, gen_loss = 0.9845005448337074, disc_loss = 0.0031158310373846595
Trained batch 1332 in epoch 7, gen_loss = 0.9843729152235874, disc_loss = 0.0031137955558251966
Trained batch 1333 in epoch 7, gen_loss = 0.9843626476746091, disc_loss = 0.0031118992412829095
Trained batch 1334 in epoch 7, gen_loss = 0.9842965724762905, disc_loss = 0.003109922244376808
Trained batch 1335 in epoch 7, gen_loss = 0.9843202631719812, disc_loss = 0.0031078870290089807
Trained batch 1336 in epoch 7, gen_loss = 0.9842944767997616, disc_loss = 0.003106410536242563
Trained batch 1337 in epoch 7, gen_loss = 0.9843201907671799, disc_loss = 0.0031046331015124277
Trained batch 1338 in epoch 7, gen_loss = 0.9843028176178052, disc_loss = 0.0031026498251135984
Trained batch 1339 in epoch 7, gen_loss = 0.9843129178481316, disc_loss = 0.003100701301071294
Trained batch 1340 in epoch 7, gen_loss = 0.984224387552203, disc_loss = 0.0030987936006432264
Trained batch 1341 in epoch 7, gen_loss = 0.9842434781318983, disc_loss = 0.003097077072177531
Trained batch 1342 in epoch 7, gen_loss = 0.9841253593708275, disc_loss = 0.003095329825473439
Trained batch 1343 in epoch 7, gen_loss = 0.9841365095316654, disc_loss = 0.0030937501827890757
Trained batch 1344 in epoch 7, gen_loss = 0.9840738441421197, disc_loss = 0.0030920075918091238
Trained batch 1345 in epoch 7, gen_loss = 0.9841095324699805, disc_loss = 0.003090066754918957
Trained batch 1346 in epoch 7, gen_loss = 0.9840438138049181, disc_loss = 0.003088274220460011
Trained batch 1347 in epoch 7, gen_loss = 0.9839786059867027, disc_loss = 0.0030863935332628295
Trained batch 1348 in epoch 7, gen_loss = 0.9839879756861037, disc_loss = 0.0030844992803547512
Trained batch 1349 in epoch 7, gen_loss = 0.9839231200571413, disc_loss = 0.0030825594201073898
Trained batch 1350 in epoch 7, gen_loss = 0.9838725808900344, disc_loss = 0.0030805683481520533
Trained batch 1351 in epoch 7, gen_loss = 0.9837896948647217, disc_loss = 0.003079189337660552
Trained batch 1352 in epoch 7, gen_loss = 0.9838583405513016, disc_loss = 0.0030776758865066196
Trained batch 1353 in epoch 7, gen_loss = 0.9839176111682655, disc_loss = 0.003076032297200177
Trained batch 1354 in epoch 7, gen_loss = 0.9839669681123262, disc_loss = 0.0030740961594461136
Trained batch 1355 in epoch 7, gen_loss = 0.983994536475446, disc_loss = 0.0030721960981944553
Trained batch 1356 in epoch 7, gen_loss = 0.9839762433012708, disc_loss = 0.0030705218716264517
Trained batch 1357 in epoch 7, gen_loss = 0.983868749002996, disc_loss = 0.0030702030494902505
Trained batch 1358 in epoch 7, gen_loss = 0.9839591754105619, disc_loss = 0.003069468206906805
Trained batch 1359 in epoch 7, gen_loss = 0.9839671502218527, disc_loss = 0.00306983924281346
Trained batch 1360 in epoch 7, gen_loss = 0.9841316038856254, disc_loss = 0.0030704539138049214
Trained batch 1361 in epoch 7, gen_loss = 0.9841822302639047, disc_loss = 0.0030698302505754033
Trained batch 1362 in epoch 7, gen_loss = 0.9842178637021094, disc_loss = 0.0030683885542565244
Trained batch 1363 in epoch 7, gen_loss = 0.9842410069232113, disc_loss = 0.0030669175945186957
Trained batch 1364 in epoch 7, gen_loss = 0.9842078588821076, disc_loss = 0.003065152414789766
Trained batch 1365 in epoch 7, gen_loss = 0.9842037506194276, disc_loss = 0.003063730269302193
Trained batch 1366 in epoch 7, gen_loss = 0.984008539917701, disc_loss = 0.0030689035343426014
Trained batch 1367 in epoch 7, gen_loss = 0.9840455230390817, disc_loss = 0.00306737221965529
Trained batch 1368 in epoch 7, gen_loss = 0.9840594363787298, disc_loss = 0.003066094595535379
Trained batch 1369 in epoch 7, gen_loss = 0.9840614949264666, disc_loss = 0.003065255397500982
Trained batch 1370 in epoch 7, gen_loss = 0.9840872562948932, disc_loss = 0.003065072166291091
Trained batch 1371 in epoch 7, gen_loss = 0.9841374308739738, disc_loss = 0.0030640506919773526
Trained batch 1372 in epoch 7, gen_loss = 0.98418830961358, disc_loss = 0.00306268692107347
Trained batch 1373 in epoch 7, gen_loss = 0.9842146776041784, disc_loss = 0.003061115624811346
Trained batch 1374 in epoch 7, gen_loss = 0.9842711320790377, disc_loss = 0.003059360549875154
Trained batch 1375 in epoch 7, gen_loss = 0.9841962880779838, disc_loss = 0.0030579697760416357
Trained batch 1376 in epoch 7, gen_loss = 0.984203093408586, disc_loss = 0.0030561237091815473
Trained batch 1377 in epoch 7, gen_loss = 0.984121382539262, disc_loss = 0.003054720831158916
Trained batch 1378 in epoch 7, gen_loss = 0.984099559502121, disc_loss = 0.003052934821807748
Trained batch 1379 in epoch 7, gen_loss = 0.9840430251066236, disc_loss = 0.003051723929319701
Trained batch 1380 in epoch 7, gen_loss = 0.9839737723479661, disc_loss = 0.0030517908113175825
Trained batch 1381 in epoch 7, gen_loss = 0.9839801507127268, disc_loss = 0.003050152912900243
Trained batch 1382 in epoch 7, gen_loss = 0.9839753105600761, disc_loss = 0.0030485101690533468
Trained batch 1383 in epoch 7, gen_loss = 0.9840364009141922, disc_loss = 0.003046713883795641
Trained batch 1384 in epoch 7, gen_loss = 0.9840444865209531, disc_loss = 0.003044867452024104
Trained batch 1385 in epoch 7, gen_loss = 0.9839812395892618, disc_loss = 0.0030441900497236644
Trained batch 1386 in epoch 7, gen_loss = 0.9840176156208338, disc_loss = 0.0030434482585605274
Trained batch 1387 in epoch 7, gen_loss = 0.9840083625972786, disc_loss = 0.0030417897031018567
Trained batch 1388 in epoch 7, gen_loss = 0.9841113635925529, disc_loss = 0.003040320484027881
Trained batch 1389 in epoch 7, gen_loss = 0.9841016959800994, disc_loss = 0.003038542088890229
Trained batch 1390 in epoch 7, gen_loss = 0.9840310220235033, disc_loss = 0.003036802502703747
Trained batch 1391 in epoch 7, gen_loss = 0.9840458393867674, disc_loss = 0.0030348788002382875
Trained batch 1392 in epoch 7, gen_loss = 0.984051426023523, disc_loss = 0.0030329261329393163
Trained batch 1393 in epoch 7, gen_loss = 0.9839968417946201, disc_loss = 0.0030312536608947957
Trained batch 1394 in epoch 7, gen_loss = 0.9839514174341728, disc_loss = 0.003029402658931859
Trained batch 1395 in epoch 7, gen_loss = 0.9839164350811594, disc_loss = 0.0030282926279394757
Trained batch 1396 in epoch 7, gen_loss = 0.9839152304206308, disc_loss = 0.0030269316997777475
Trained batch 1397 in epoch 7, gen_loss = 0.9839046625620306, disc_loss = 0.003025019131998276
Trained batch 1398 in epoch 7, gen_loss = 0.9838146663632369, disc_loss = 0.0030231210094267217
Trained batch 1399 in epoch 7, gen_loss = 0.9837687769532204, disc_loss = 0.003021268302488482
Trained batch 1400 in epoch 7, gen_loss = 0.983831517233498, disc_loss = 0.0030193510004409407
Trained batch 1401 in epoch 7, gen_loss = 0.9839395031694339, disc_loss = 0.003017478364158115
Trained batch 1402 in epoch 7, gen_loss = 0.9839674419194396, disc_loss = 0.003015541298520419
Trained batch 1403 in epoch 7, gen_loss = 0.9838997463979612, disc_loss = 0.0030136741667782688
Trained batch 1404 in epoch 7, gen_loss = 0.9838386162744298, disc_loss = 0.00301248626218503
Trained batch 1405 in epoch 7, gen_loss = 0.9839101323108076, disc_loss = 0.003010766575758812
Trained batch 1406 in epoch 7, gen_loss = 0.9838803920156157, disc_loss = 0.003009165485475622
Trained batch 1407 in epoch 7, gen_loss = 0.9838423246348446, disc_loss = 0.003008238641112629
Trained batch 1408 in epoch 7, gen_loss = 0.9838528118715631, disc_loss = 0.0030065744104567534
Trained batch 1409 in epoch 7, gen_loss = 0.983881409962972, disc_loss = 0.003005299125889899
Trained batch 1410 in epoch 7, gen_loss = 0.983796454084249, disc_loss = 0.003003939462839558
Trained batch 1411 in epoch 7, gen_loss = 0.983780180259737, disc_loss = 0.0030030326577683494
Trained batch 1412 in epoch 7, gen_loss = 0.9837143843847223, disc_loss = 0.003001938345989745
Trained batch 1413 in epoch 7, gen_loss = 0.983754585875143, disc_loss = 0.003000799035089714
Trained batch 1414 in epoch 7, gen_loss = 0.9836612307140769, disc_loss = 0.0029990484809937767
Trained batch 1415 in epoch 7, gen_loss = 0.9836881484015513, disc_loss = 0.0029976715055803817
Trained batch 1416 in epoch 7, gen_loss = 0.9837497273379846, disc_loss = 0.0029961306286704053
Trained batch 1417 in epoch 7, gen_loss = 0.983729348448335, disc_loss = 0.0029944915341372043
Trained batch 1418 in epoch 7, gen_loss = 0.9837744221710839, disc_loss = 0.0029927995879035474
Trained batch 1419 in epoch 7, gen_loss = 0.9836831240586832, disc_loss = 0.0029916100337878805
Trained batch 1420 in epoch 7, gen_loss = 0.9835783593005315, disc_loss = 0.002990440278255109
Trained batch 1421 in epoch 7, gen_loss = 0.9836063296986028, disc_loss = 0.002988953403148804
Trained batch 1422 in epoch 7, gen_loss = 0.983529734762303, disc_loss = 0.002987181265882499
Trained batch 1423 in epoch 7, gen_loss = 0.9835906720228409, disc_loss = 0.0029858431647359763
Trained batch 1424 in epoch 7, gen_loss = 0.9836053932758799, disc_loss = 0.0029843641520659603
Trained batch 1425 in epoch 7, gen_loss = 0.9835422799764475, disc_loss = 0.002982948496617936
Trained batch 1426 in epoch 7, gen_loss = 0.9836722080241406, disc_loss = 0.0029812763895372893
Trained batch 1427 in epoch 7, gen_loss = 0.9836361158628758, disc_loss = 0.0029809131397227303
Trained batch 1428 in epoch 7, gen_loss = 0.983485099692041, disc_loss = 0.002995102262698797
Trained batch 1429 in epoch 7, gen_loss = 0.9836824380851292, disc_loss = 0.003392086058031398
Trained batch 1430 in epoch 7, gen_loss = 0.9837681096304888, disc_loss = 0.0035954138390939297
Trained batch 1431 in epoch 7, gen_loss = 0.9836007302533315, disc_loss = 0.0037972997643111496
Trained batch 1432 in epoch 7, gen_loss = 0.9836326592965136, disc_loss = 0.003828056910334115
Trained batch 1433 in epoch 7, gen_loss = 0.9836872224195898, disc_loss = 0.0038369856383153444
Trained batch 1434 in epoch 7, gen_loss = 0.9837111983980451, disc_loss = 0.0038582411608936587
Trained batch 1435 in epoch 7, gen_loss = 0.983769858530969, disc_loss = 0.0038633008542619234
Trained batch 1436 in epoch 7, gen_loss = 0.9837020328663751, disc_loss = 0.003892712283192085
Trained batch 1437 in epoch 7, gen_loss = 0.9837521044369035, disc_loss = 0.003894840873404374
Trained batch 1438 in epoch 7, gen_loss = 0.9837531331017914, disc_loss = 0.0038966026195295265
Trained batch 1439 in epoch 7, gen_loss = 0.9838149256176418, disc_loss = 0.0038956489639986104
Trained batch 1440 in epoch 7, gen_loss = 0.9838653610118308, disc_loss = 0.0038943545977146907
Trained batch 1441 in epoch 7, gen_loss = 0.9838159503867325, disc_loss = 0.0038926735031259057
Trained batch 1442 in epoch 7, gen_loss = 0.9837210950385508, disc_loss = 0.003943670988360613
Trained batch 1443 in epoch 7, gen_loss = 0.9836929429353439, disc_loss = 0.004308997563820616
Trained batch 1444 in epoch 7, gen_loss = 0.9835995926164013, disc_loss = 0.004489485997507054
Trained batch 1445 in epoch 7, gen_loss = 0.9834503580096022, disc_loss = 0.004537230747234262
Trained batch 1446 in epoch 7, gen_loss = 0.9833937913035226, disc_loss = 0.004556838225466661
Trained batch 1447 in epoch 7, gen_loss = 0.9832112948868156, disc_loss = 0.004575324271212775
Trained batch 1448 in epoch 7, gen_loss = 0.9830988801866667, disc_loss = 0.004581492473310468
Trained batch 1449 in epoch 7, gen_loss = 0.9829468477183375, disc_loss = 0.004590229278411274
Trained batch 1450 in epoch 7, gen_loss = 0.982809342736626, disc_loss = 0.004599237313306867
Trained batch 1451 in epoch 7, gen_loss = 0.9826722397948756, disc_loss = 0.004615042256698285
Trained batch 1452 in epoch 7, gen_loss = 0.9825372176997348, disc_loss = 0.00462774862459684
Trained batch 1453 in epoch 7, gen_loss = 0.9825041788070369, disc_loss = 0.00462844663597484
Trained batch 1454 in epoch 7, gen_loss = 0.9823510607493292, disc_loss = 0.004640320994491374
Trained batch 1455 in epoch 7, gen_loss = 0.9823580397354378, disc_loss = 0.00463993700896026
Trained batch 1456 in epoch 7, gen_loss = 0.9824125593299315, disc_loss = 0.004640393482991831
Trained batch 1457 in epoch 7, gen_loss = 0.9823463685064486, disc_loss = 0.004638945381265891
Trained batch 1458 in epoch 7, gen_loss = 0.982389667575044, disc_loss = 0.004638032885785577
Trained batch 1459 in epoch 7, gen_loss = 0.9822224954627965, disc_loss = 0.004646706587698969
Trained batch 1460 in epoch 7, gen_loss = 0.9823292029140585, disc_loss = 0.004646155838073927
Trained batch 1461 in epoch 7, gen_loss = 0.9823500385607317, disc_loss = 0.004645258817986291
Trained batch 1462 in epoch 7, gen_loss = 0.9824731563837334, disc_loss = 0.004646611636484359
Trained batch 1463 in epoch 7, gen_loss = 0.9825545450458761, disc_loss = 0.004644814142245041
Trained batch 1464 in epoch 7, gen_loss = 0.9826321176701438, disc_loss = 0.004643327769559749
Trained batch 1465 in epoch 7, gen_loss = 0.9826821268905884, disc_loss = 0.004641922555799257
Trained batch 1466 in epoch 7, gen_loss = 0.9826857480128444, disc_loss = 0.004640567531357397
Trained batch 1467 in epoch 7, gen_loss = 0.982651770399117, disc_loss = 0.004638823348666138
Trained batch 1468 in epoch 7, gen_loss = 0.9825724537393689, disc_loss = 0.00463705597427003
Trained batch 1469 in epoch 7, gen_loss = 0.9825991282252228, disc_loss = 0.004635103024764273
Trained batch 1470 in epoch 7, gen_loss = 0.9825947200012077, disc_loss = 0.004632949931316154
Trained batch 1471 in epoch 7, gen_loss = 0.9825840892027253, disc_loss = 0.004630516944105338
Trained batch 1472 in epoch 7, gen_loss = 0.9825444998420668, disc_loss = 0.004628232931946042
Trained batch 1473 in epoch 7, gen_loss = 0.982489824537668, disc_loss = 0.004625556617608969
Trained batch 1474 in epoch 7, gen_loss = 0.9824364947464507, disc_loss = 0.0046234578606564065
Trained batch 1475 in epoch 7, gen_loss = 0.9824176945983556, disc_loss = 0.004620910867871245
Trained batch 1476 in epoch 7, gen_loss = 0.9824228892071311, disc_loss = 0.004618683070332052
Trained batch 1477 in epoch 7, gen_loss = 0.982372836145561, disc_loss = 0.004616731680359281
Trained batch 1478 in epoch 7, gen_loss = 0.982336179923173, disc_loss = 0.004614280782987455
Trained batch 1479 in epoch 7, gen_loss = 0.9824042348845585, disc_loss = 0.004611888848174548
Trained batch 1480 in epoch 7, gen_loss = 0.9823999964732081, disc_loss = 0.004609332821377077
Trained batch 1481 in epoch 7, gen_loss = 0.9823870892145051, disc_loss = 0.0046069843419838915
Trained batch 1482 in epoch 7, gen_loss = 0.9823770399280118, disc_loss = 0.004604631323615299
Trained batch 1483 in epoch 7, gen_loss = 0.9824333386922461, disc_loss = 0.004602776482380493
Trained batch 1484 in epoch 7, gen_loss = 0.9824063292657486, disc_loss = 0.0046009293570066015
Trained batch 1485 in epoch 7, gen_loss = 0.982271339057432, disc_loss = 0.004600559952056412
Trained batch 1486 in epoch 7, gen_loss = 0.9821994374803673, disc_loss = 0.0045997050504587925
Trained batch 1487 in epoch 7, gen_loss = 0.9822206558479417, disc_loss = 0.0045994954095026856
Trained batch 1488 in epoch 7, gen_loss = 0.9822804811338677, disc_loss = 0.004598165674235672
Trained batch 1489 in epoch 7, gen_loss = 0.9822810915892556, disc_loss = 0.004596555882041544
Trained batch 1490 in epoch 7, gen_loss = 0.9822222409353889, disc_loss = 0.004595106825444138
Trained batch 1491 in epoch 7, gen_loss = 0.9823318784582071, disc_loss = 0.004593381932463964
Trained batch 1492 in epoch 7, gen_loss = 0.9822679805979183, disc_loss = 0.004591326226861949
Trained batch 1493 in epoch 7, gen_loss = 0.9823438857134725, disc_loss = 0.004589098223369612
Trained batch 1494 in epoch 7, gen_loss = 0.9823207658270131, disc_loss = 0.004588448354297117
Trained batch 1495 in epoch 7, gen_loss = 0.982238126390758, disc_loss = 0.004588643818482874
Trained batch 1496 in epoch 7, gen_loss = 0.9819148983569964, disc_loss = 0.0047755996330733986
Trained batch 1497 in epoch 7, gen_loss = 0.9820740646291002, disc_loss = 0.0051612548842715385
Trained batch 1498 in epoch 7, gen_loss = 0.9819989330057624, disc_loss = 0.0053885497221662386
Trained batch 1499 in epoch 7, gen_loss = 0.9817841649055481, disc_loss = 0.005543623549170055
Trained batch 1500 in epoch 7, gen_loss = 0.9815450859101592, disc_loss = 0.005670652073858777
Trained batch 1501 in epoch 7, gen_loss = 0.9812402931574022, disc_loss = 0.005784992165741247
Trained batch 1502 in epoch 7, gen_loss = 0.980949313459758, disc_loss = 0.005909914268493531
Trained batch 1503 in epoch 7, gen_loss = 0.9807486413641179, disc_loss = 0.00598716058394491
Trained batch 1504 in epoch 7, gen_loss = 0.9806684892042927, disc_loss = 0.006023261545035885
Trained batch 1505 in epoch 7, gen_loss = 0.9806514385132834, disc_loss = 0.006044551507456565
Trained batch 1506 in epoch 7, gen_loss = 0.9806515999637697, disc_loss = 0.006056993900569486
Trained batch 1507 in epoch 7, gen_loss = 0.9805718306995513, disc_loss = 0.006065765408039921
Trained batch 1508 in epoch 7, gen_loss = 0.980353603306158, disc_loss = 0.006167552034521077
Trained batch 1509 in epoch 7, gen_loss = 0.9805019550765587, disc_loss = 0.0064463565557077605
Trained batch 1510 in epoch 7, gen_loss = 0.9805213141173105, disc_loss = 0.006575349964804753
Trained batch 1511 in epoch 7, gen_loss = 0.9803311734130142, disc_loss = 0.006596995470726811
Trained batch 1512 in epoch 7, gen_loss = 0.9802747807672934, disc_loss = 0.006627190779263539
Trained batch 1513 in epoch 7, gen_loss = 0.9799932280415116, disc_loss = 0.006744025998444229
Trained batch 1514 in epoch 7, gen_loss = 0.9800514205060776, disc_loss = 0.006808332289825924
Trained batch 1515 in epoch 7, gen_loss = 0.9800922875747202, disc_loss = 0.006821344436951589
Trained batch 1516 in epoch 7, gen_loss = 0.9800414881505067, disc_loss = 0.00682482718996724
Trained batch 1517 in epoch 7, gen_loss = 0.9801600809860607, disc_loss = 0.006823956188385546
Trained batch 1518 in epoch 7, gen_loss = 0.9800949452581023, disc_loss = 0.006824438339928718
Trained batch 1519 in epoch 7, gen_loss = 0.9800433097701323, disc_loss = 0.006829258605864054
Trained batch 1520 in epoch 7, gen_loss = 0.9798786344299342, disc_loss = 0.006904315967518626
Trained batch 1521 in epoch 7, gen_loss = 0.9799378564808905, disc_loss = 0.0070654238094978415
Trained batch 1522 in epoch 7, gen_loss = 0.9800160693167388, disc_loss = 0.0070865128142134325
Trained batch 1523 in epoch 7, gen_loss = 0.9800393196150387, disc_loss = 0.007087402560815878
Trained batch 1524 in epoch 7, gen_loss = 0.9800197811595729, disc_loss = 0.007089408207307837
Trained batch 1525 in epoch 7, gen_loss = 0.979983091041895, disc_loss = 0.007087804208563826
Trained batch 1526 in epoch 7, gen_loss = 0.9799952796259657, disc_loss = 0.007087961000519536
Trained batch 1527 in epoch 7, gen_loss = 0.9799781635169583, disc_loss = 0.007087908238674039
Trained batch 1528 in epoch 7, gen_loss = 0.9799540020267195, disc_loss = 0.007086126684055149
Trained batch 1529 in epoch 7, gen_loss = 0.9799249188572753, disc_loss = 0.0070841775567233155
Trained batch 1530 in epoch 7, gen_loss = 0.9798417609163081, disc_loss = 0.007081092230583154
Trained batch 1531 in epoch 7, gen_loss = 0.9797786759801073, disc_loss = 0.0070787020991682865
Trained batch 1532 in epoch 7, gen_loss = 0.9798226347952518, disc_loss = 0.007075522220042157
Trained batch 1533 in epoch 7, gen_loss = 0.9797711179262656, disc_loss = 0.007072047043579482
Trained batch 1534 in epoch 7, gen_loss = 0.9798270548205422, disc_loss = 0.007069431695673222
Trained batch 1535 in epoch 7, gen_loss = 0.9798089785811802, disc_loss = 0.007066157078502518
Trained batch 1536 in epoch 7, gen_loss = 0.979885987903518, disc_loss = 0.007063353486926161
Trained batch 1537 in epoch 7, gen_loss = 0.9799474016587663, disc_loss = 0.007060068054099167
Trained batch 1538 in epoch 7, gen_loss = 0.9798349908530674, disc_loss = 0.007110589021238215
Trained batch 1539 in epoch 7, gen_loss = 0.9800151021062554, disc_loss = 0.007113865734076667
Trained batch 1540 in epoch 7, gen_loss = 0.9800659910492275, disc_loss = 0.007115397386718126
Trained batch 1541 in epoch 7, gen_loss = 0.9801248379641161, disc_loss = 0.007112896590964603
Trained batch 1542 in epoch 7, gen_loss = 0.9801053009246435, disc_loss = 0.007113876313003595
Trained batch 1543 in epoch 7, gen_loss = 0.980000058604028, disc_loss = 0.007129276801512217
Trained batch 1544 in epoch 7, gen_loss = 0.9800031427040841, disc_loss = 0.007207205798029546
Trained batch 1545 in epoch 7, gen_loss = 0.9799471656378614, disc_loss = 0.007210459723864915
Trained batch 1546 in epoch 7, gen_loss = 0.9797863471716084, disc_loss = 0.007364752533101998
Trained batch 1547 in epoch 7, gen_loss = 0.9799074381204846, disc_loss = 0.007437408297569246
Trained batch 1548 in epoch 7, gen_loss = 0.9796926577372886, disc_loss = 0.007564649091535565
Trained batch 1549 in epoch 7, gen_loss = 0.9797024300790602, disc_loss = 0.007767823261453867
Trained batch 1550 in epoch 7, gen_loss = 0.9795350060395315, disc_loss = 0.007850756362982362
Trained batch 1551 in epoch 7, gen_loss = 0.9794871008273253, disc_loss = 0.007854212844627798
Trained batch 1552 in epoch 7, gen_loss = 0.9794128884519981, disc_loss = 0.00785881387629803
Trained batch 1553 in epoch 7, gen_loss = 0.9793968130876353, disc_loss = 0.007860857636032411
Trained batch 1554 in epoch 7, gen_loss = 0.9793196020019016, disc_loss = 0.007868462389974571
Trained batch 1555 in epoch 7, gen_loss = 0.9790584046230831, disc_loss = 0.007936079913227059
Trained batch 1556 in epoch 7, gen_loss = 0.9789712905654099, disc_loss = 0.007978416626258386
Trained batch 1557 in epoch 7, gen_loss = 0.9788539282623703, disc_loss = 0.008042367451245496
Trained batch 1558 in epoch 7, gen_loss = 0.9789143360295763, disc_loss = 0.008043153357688964
Trained batch 1559 in epoch 7, gen_loss = 0.9789653874360598, disc_loss = 0.008043039677734972
Trained batch 1560 in epoch 7, gen_loss = 0.9787847933900578, disc_loss = 0.008138360102885768
Trained batch 1561 in epoch 7, gen_loss = 0.9788136701272483, disc_loss = 0.00848479340167612
Trained batch 1562 in epoch 7, gen_loss = 0.9787548956242572, disc_loss = 0.008729823473970737
Trained batch 1563 in epoch 7, gen_loss = 0.9785983327709501, disc_loss = 0.008896309112309297
Trained batch 1564 in epoch 7, gen_loss = 0.9783865647574964, disc_loss = 0.009013929488677599
Trained batch 1565 in epoch 7, gen_loss = 0.9781460874305983, disc_loss = 0.009146105257072165
Trained batch 1566 in epoch 7, gen_loss = 0.9779183642454945, disc_loss = 0.009278543005079803
Trained batch 1567 in epoch 7, gen_loss = 0.9776418306009502, disc_loss = 0.009365509950046135
Trained batch 1568 in epoch 7, gen_loss = 0.9775023577394115, disc_loss = 0.00940710318677705
Trained batch 1569 in epoch 7, gen_loss = 0.977464497089386, disc_loss = 0.009448826305163546
Trained batch 1570 in epoch 7, gen_loss = 0.9772487746766234, disc_loss = 0.009487957930621443
Trained batch 1571 in epoch 7, gen_loss = 0.9770402781684283, disc_loss = 0.009531446347940772
Trained batch 1572 in epoch 7, gen_loss = 0.9768188674208925, disc_loss = 0.009580473100430134
Trained batch 1573 in epoch 7, gen_loss = 0.9767709321790911, disc_loss = 0.009597773176594143
Trained batch 1574 in epoch 7, gen_loss = 0.976702405271076, disc_loss = 0.009619845039999327
Trained batch 1575 in epoch 7, gen_loss = 0.9765906341487381, disc_loss = 0.009641942546115416
Trained batch 1576 in epoch 7, gen_loss = 0.9764727555125593, disc_loss = 0.009661805528836638
Trained batch 1577 in epoch 7, gen_loss = 0.9764438919694705, disc_loss = 0.009662287920471335
Trained batch 1578 in epoch 7, gen_loss = 0.9764744226052234, disc_loss = 0.009671819951782686
Trained batch 1579 in epoch 7, gen_loss = 0.9765159942681276, disc_loss = 0.009670482834222133
Trained batch 1580 in epoch 7, gen_loss = 0.9764863151602169, disc_loss = 0.009700136846065608
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.8541202545166016, disc_loss = 0.022093988955020905
Trained batch 1 in epoch 8, gen_loss = 0.8446927964687347, disc_loss = 0.017957893665879965
Trained batch 2 in epoch 8, gen_loss = 0.8783342440923055, disc_loss = 0.016243029696245987
Trained batch 3 in epoch 8, gen_loss = 0.9320986568927765, disc_loss = 0.013917301781475544
Trained batch 4 in epoch 8, gen_loss = 0.9327269554138183, disc_loss = 0.01632159948348999
Trained batch 5 in epoch 8, gen_loss = 0.8964565594991049, disc_loss = 0.02312900312244892
Trained batch 6 in epoch 8, gen_loss = 0.9530118192945208, disc_loss = 0.025099354663065503
Trained batch 7 in epoch 8, gen_loss = 0.9464864432811737, disc_loss = 0.030152275692671537
Trained batch 8 in epoch 8, gen_loss = 0.9097125795152452, disc_loss = 0.0550482931236426
Trained batch 9 in epoch 8, gen_loss = 0.931534492969513, disc_loss = 0.053786749765276906
Trained batch 10 in epoch 8, gen_loss = 0.9464705423875288, disc_loss = 0.06911749562079256
Trained batch 11 in epoch 8, gen_loss = 0.949246754248937, disc_loss = 0.06358437628174822
Trained batch 12 in epoch 8, gen_loss = 0.9409083953270545, disc_loss = 0.05920321143303926
Trained batch 13 in epoch 8, gen_loss = 0.9342706203460693, disc_loss = 0.055476505775004625
Trained batch 14 in epoch 8, gen_loss = 0.9314855694770813, disc_loss = 0.0522518885632356
Trained batch 15 in epoch 8, gen_loss = 0.9283045269548893, disc_loss = 0.04925460528465919
Trained batch 16 in epoch 8, gen_loss = 0.9292308407671311, disc_loss = 0.04645496793776093
Trained batch 17 in epoch 8, gen_loss = 0.9258131881554922, disc_loss = 0.043996423644582845
Trained batch 18 in epoch 8, gen_loss = 0.9255266032720867, disc_loss = 0.041893282911348105
Trained batch 19 in epoch 8, gen_loss = 0.9279969722032547, disc_loss = 0.039853626914555206
Trained batch 20 in epoch 8, gen_loss = 0.9243230053356716, disc_loss = 0.03804547764316556
Trained batch 21 in epoch 8, gen_loss = 0.9258689365603707, disc_loss = 0.036407653337598524
Trained batch 22 in epoch 8, gen_loss = 0.9192088894222094, disc_loss = 0.037818283905558615
Trained batch 23 in epoch 8, gen_loss = 0.917639414469401, disc_loss = 0.037411096127470955
Trained batch 24 in epoch 8, gen_loss = 0.9086180686950683, disc_loss = 0.03748308920301497
Trained batch 25 in epoch 8, gen_loss = 0.8977928895216721, disc_loss = 0.03801558475690679
Trained batch 26 in epoch 8, gen_loss = 0.8985181009327924, disc_loss = 0.036929666349250406
Trained batch 27 in epoch 8, gen_loss = 0.8982706580843244, disc_loss = 0.036797062668483704
Trained batch 28 in epoch 8, gen_loss = 0.8934241019446274, disc_loss = 0.03689255132661041
Trained batch 29 in epoch 8, gen_loss = 0.8925230820973714, disc_loss = 0.03694425713426123
Trained batch 30 in epoch 8, gen_loss = 0.8860771732945596, disc_loss = 0.03764899186940203
Trained batch 31 in epoch 8, gen_loss = 0.8905772790312767, disc_loss = 0.051966054052172694
Trained batch 32 in epoch 8, gen_loss = 0.8959906859831377, disc_loss = 0.05071284540816012
Trained batch 33 in epoch 8, gen_loss = 0.9012024437679964, disc_loss = 0.0494681337971569
Trained batch 34 in epoch 8, gen_loss = 0.9065938438688006, disc_loss = 0.048272998637652824
Trained batch 35 in epoch 8, gen_loss = 0.9079205393791199, disc_loss = 0.047028219708914146
Trained batch 36 in epoch 8, gen_loss = 0.9078995537113499, disc_loss = 0.04588786720902332
Trained batch 37 in epoch 8, gen_loss = 0.9117618077679684, disc_loss = 0.04476740569685047
Trained batch 38 in epoch 8, gen_loss = 0.912571751154386, disc_loss = 0.043736641838525735
Trained batch 39 in epoch 8, gen_loss = 0.9148758232593537, disc_loss = 0.04268069369718432
Trained batch 40 in epoch 8, gen_loss = 0.9165324815889684, disc_loss = 0.04168082143339079
Trained batch 41 in epoch 8, gen_loss = 0.9181009758086431, disc_loss = 0.04072376560430885
Trained batch 42 in epoch 8, gen_loss = 0.9181508421897888, disc_loss = 0.039823877205530746
Trained batch 43 in epoch 8, gen_loss = 0.9196254760026932, disc_loss = 0.038941498859044674
Trained batch 44 in epoch 8, gen_loss = 0.9171482205390931, disc_loss = 0.038197167209970455
Trained batch 45 in epoch 8, gen_loss = 0.9158433014931886, disc_loss = 0.03774281971045244
Trained batch 46 in epoch 8, gen_loss = 0.9127723714138599, disc_loss = 0.03717123995723322
Trained batch 47 in epoch 8, gen_loss = 0.9134105357031027, disc_loss = 0.036637211870887164
Trained batch 48 in epoch 8, gen_loss = 0.9155999239610166, disc_loss = 0.03595427827843066
Trained batch 49 in epoch 8, gen_loss = 0.9185408651828766, disc_loss = 0.03529488657834008
Trained batch 50 in epoch 8, gen_loss = 0.9198561123773163, disc_loss = 0.034657943366077165
Trained batch 51 in epoch 8, gen_loss = 0.9176112975065525, disc_loss = 0.034085823547614455
Trained batch 52 in epoch 8, gen_loss = 0.9206837022079611, disc_loss = 0.033524131835086866
Trained batch 53 in epoch 8, gen_loss = 0.9215152075997105, disc_loss = 0.03306888926265485
Trained batch 54 in epoch 8, gen_loss = 0.9230692765929482, disc_loss = 0.032693778090602296
Trained batch 55 in epoch 8, gen_loss = 0.9219985806516239, disc_loss = 0.032404533863882534
Trained batch 56 in epoch 8, gen_loss = 0.9241700371106466, disc_loss = 0.031937962555195806
Trained batch 57 in epoch 8, gen_loss = 0.9247598843327884, disc_loss = 0.031483655725204354
Trained batch 58 in epoch 8, gen_loss = 0.9254675820722418, disc_loss = 0.03103511105883488
Trained batch 59 in epoch 8, gen_loss = 0.9246663014094035, disc_loss = 0.030862026454027122
Trained batch 60 in epoch 8, gen_loss = 0.9227636182894472, disc_loss = 0.03043814889941609
Trained batch 61 in epoch 8, gen_loss = 0.9254565210111679, disc_loss = 0.029991238229652686
Trained batch 62 in epoch 8, gen_loss = 0.9273905498640878, disc_loss = 0.029543224805300788
Trained batch 63 in epoch 8, gen_loss = 0.9284506952390075, disc_loss = 0.029099640347340028
Trained batch 64 in epoch 8, gen_loss = 0.9297878714708182, disc_loss = 0.028683464001649273
Trained batch 65 in epoch 8, gen_loss = 0.93039163405245, disc_loss = 0.02838321773963275
Trained batch 66 in epoch 8, gen_loss = 0.9302421550252544, disc_loss = 0.028016239281312853
Trained batch 67 in epoch 8, gen_loss = 0.9287585291792365, disc_loss = 0.027752182201605618
Trained batch 68 in epoch 8, gen_loss = 0.926605963188669, disc_loss = 0.02745270760277745
Trained batch 69 in epoch 8, gen_loss = 0.9265907875129155, disc_loss = 0.02708061610381784
Trained batch 70 in epoch 8, gen_loss = 0.9284978928700299, disc_loss = 0.02676396284573777
Trained batch 71 in epoch 8, gen_loss = 0.9293349070681466, disc_loss = 0.026441760899615474
Trained batch 72 in epoch 8, gen_loss = 0.9312159623185249, disc_loss = 0.02611609562523408
Trained batch 73 in epoch 8, gen_loss = 0.9272141086088644, disc_loss = 0.026706530072260648
Trained batch 74 in epoch 8, gen_loss = 0.9291563590367635, disc_loss = 0.029979204375607273
Trained batch 75 in epoch 8, gen_loss = 0.9306047323502993, disc_loss = 0.02969024174901853
Trained batch 76 in epoch 8, gen_loss = 0.9325471264975411, disc_loss = 0.0294114476592921
Trained batch 77 in epoch 8, gen_loss = 0.9285071140680557, disc_loss = 0.030266657711949963
Trained batch 78 in epoch 8, gen_loss = 0.9309325701073755, disc_loss = 0.031926961310644035
Trained batch 79 in epoch 8, gen_loss = 0.9327960938215256, disc_loss = 0.03165060466999421
Trained batch 80 in epoch 8, gen_loss = 0.931217274548095, disc_loss = 0.03219754487005879
Trained batch 81 in epoch 8, gen_loss = 0.9256595216873216, disc_loss = 0.036285338504523854
Trained batch 82 in epoch 8, gen_loss = 0.9263020233217493, disc_loss = 0.03941903836851244
Trained batch 83 in epoch 8, gen_loss = 0.9269318491930053, disc_loss = 0.04045756452944174
Trained batch 84 in epoch 8, gen_loss = 0.9282412329140831, disc_loss = 0.04043598577298005
Trained batch 85 in epoch 8, gen_loss = 0.9295773932407069, disc_loss = 0.040113770057782966
Trained batch 86 in epoch 8, gen_loss = 0.9273229169434515, disc_loss = 0.04019026875886638
Trained batch 87 in epoch 8, gen_loss = 0.9234412641010501, disc_loss = 0.042514209446380846
Trained batch 88 in epoch 8, gen_loss = 0.925410591149598, disc_loss = 0.043296212792197725
Trained batch 89 in epoch 8, gen_loss = 0.9265919357538224, disc_loss = 0.04418928215616486
Trained batch 90 in epoch 8, gen_loss = 0.9270973012342558, disc_loss = 0.04381778422911948
Trained batch 91 in epoch 8, gen_loss = 0.9246524692229603, disc_loss = 0.04433125018714117
Trained batch 92 in epoch 8, gen_loss = 0.9267479569040319, disc_loss = 0.043932651701603605
Trained batch 93 in epoch 8, gen_loss = 0.9279023120377926, disc_loss = 0.04407076456489913
Trained batch 94 in epoch 8, gen_loss = 0.9287899033019417, disc_loss = 0.04363204691387517
Trained batch 95 in epoch 8, gen_loss = 0.9299497321868936, disc_loss = 0.043238542926701484
Trained batch 96 in epoch 8, gen_loss = 0.9307093439028435, disc_loss = 0.0428343414744247
Trained batch 97 in epoch 8, gen_loss = 0.9314342399640959, disc_loss = 0.04243084927664462
Trained batch 98 in epoch 8, gen_loss = 0.931527359618081, disc_loss = 0.04203826865543508
Trained batch 99 in epoch 8, gen_loss = 0.9323175004124642, disc_loss = 0.041635239569004626
Trained batch 100 in epoch 8, gen_loss = 0.9330013910732647, disc_loss = 0.041240673784240345
Trained batch 101 in epoch 8, gen_loss = 0.9327959941298354, disc_loss = 0.04085228549700011
Trained batch 102 in epoch 8, gen_loss = 0.9340042984022677, disc_loss = 0.04046658661727368
Trained batch 103 in epoch 8, gen_loss = 0.9346502913305392, disc_loss = 0.0400886746188357
Trained batch 104 in epoch 8, gen_loss = 0.9348363805384863, disc_loss = 0.0397167670052676
Trained batch 105 in epoch 8, gen_loss = 0.9350832366156128, disc_loss = 0.03934955507745298
Trained batch 106 in epoch 8, gen_loss = 0.9353349829945609, disc_loss = 0.0389916136769456
Trained batch 107 in epoch 8, gen_loss = 0.9356589060690668, disc_loss = 0.03864531642089046
Trained batch 108 in epoch 8, gen_loss = 0.9365237707938623, disc_loss = 0.03830118662434194
Trained batch 109 in epoch 8, gen_loss = 0.9374060508879748, disc_loss = 0.037965924360535364
Trained batch 110 in epoch 8, gen_loss = 0.9383835510627644, disc_loss = 0.03763565099651313
Trained batch 111 in epoch 8, gen_loss = 0.9390460729066815, disc_loss = 0.037305808957171394
Trained batch 112 in epoch 8, gen_loss = 0.9391450932068107, disc_loss = 0.036986563105931486
Trained batch 113 in epoch 8, gen_loss = 0.9396858139519106, disc_loss = 0.03666968072668584
Trained batch 114 in epoch 8, gen_loss = 0.9397680943426878, disc_loss = 0.036355084790746964
Trained batch 115 in epoch 8, gen_loss = 0.9401453648661745, disc_loss = 0.03604869802576763
Trained batch 116 in epoch 8, gen_loss = 0.9407380480542142, disc_loss = 0.035758715422931485
Trained batch 117 in epoch 8, gen_loss = 0.9403763875617819, disc_loss = 0.035465262766623616
Trained batch 118 in epoch 8, gen_loss = 0.9400297380796, disc_loss = 0.03517470273292944
Trained batch 119 in epoch 8, gen_loss = 0.9405045129358769, disc_loss = 0.03488828717575719
Trained batch 120 in epoch 8, gen_loss = 0.9416902378078335, disc_loss = 0.03460868879140563
Trained batch 121 in epoch 8, gen_loss = 0.9414692020318547, disc_loss = 0.03433699747375747
Trained batch 122 in epoch 8, gen_loss = 0.9417594688210061, disc_loss = 0.03407124640624516
Trained batch 123 in epoch 8, gen_loss = 0.9431586743843171, disc_loss = 0.03380447178478203
Trained batch 124 in epoch 8, gen_loss = 0.9432069222927093, disc_loss = 0.03354281315580011
Trained batch 125 in epoch 8, gen_loss = 0.9424283421701856, disc_loss = 0.03328525740560883
Trained batch 126 in epoch 8, gen_loss = 0.9425087249654485, disc_loss = 0.033031196963210684
Trained batch 127 in epoch 8, gen_loss = 0.9427046647761017, disc_loss = 0.0327782125923477
Trained batch 128 in epoch 8, gen_loss = 0.9433013267757356, disc_loss = 0.03252860666803164
Trained batch 129 in epoch 8, gen_loss = 0.9429748060611578, disc_loss = 0.03228417568652031
Trained batch 130 in epoch 8, gen_loss = 0.9427788469172617, disc_loss = 0.03204135357900807
Trained batch 131 in epoch 8, gen_loss = 0.9441921361016504, disc_loss = 0.03180262788968817
Trained batch 132 in epoch 8, gen_loss = 0.9442968679998154, disc_loss = 0.031568442864555346
Trained batch 133 in epoch 8, gen_loss = 0.943860661405236, disc_loss = 0.03133794141663134
Trained batch 134 in epoch 8, gen_loss = 0.9440083311663734, disc_loss = 0.031113076625021035
Trained batch 135 in epoch 8, gen_loss = 0.9429447429583353, disc_loss = 0.030894462848022265
Trained batch 136 in epoch 8, gen_loss = 0.9425918070504266, disc_loss = 0.030674049187405714
Trained batch 137 in epoch 8, gen_loss = 0.942750435160554, disc_loss = 0.030456714225600583
Trained batch 138 in epoch 8, gen_loss = 0.9433405710210045, disc_loss = 0.030241276861776484
Trained batch 139 in epoch 8, gen_loss = 0.9432666644454002, disc_loss = 0.03002952158546707
Trained batch 140 in epoch 8, gen_loss = 0.9433987535906176, disc_loss = 0.029820151857211062
Trained batch 141 in epoch 8, gen_loss = 0.9434014111757278, disc_loss = 0.029613362239718003
Trained batch 142 in epoch 8, gen_loss = 0.9440066028725017, disc_loss = 0.029413849260076765
Trained batch 143 in epoch 8, gen_loss = 0.943390292632911, disc_loss = 0.029214427416566952
Trained batch 144 in epoch 8, gen_loss = 0.942968102775771, disc_loss = 0.02901776763510184
Trained batch 145 in epoch 8, gen_loss = 0.9436745078188099, disc_loss = 0.028822813041736246
Trained batch 146 in epoch 8, gen_loss = 0.9440590157395318, disc_loss = 0.02863114407594113
Trained batch 147 in epoch 8, gen_loss = 0.9437318232816618, disc_loss = 0.028444878692696237
Trained batch 148 in epoch 8, gen_loss = 0.9434021581339356, disc_loss = 0.028258304208737404
Trained batch 149 in epoch 8, gen_loss = 0.9431415834029515, disc_loss = 0.02807441682574184
Trained batch 150 in epoch 8, gen_loss = 0.9429993422220875, disc_loss = 0.027891251702626414
Trained batch 151 in epoch 8, gen_loss = 0.9429697161050219, disc_loss = 0.027710518070020236
Trained batch 152 in epoch 8, gen_loss = 0.9434041643843931, disc_loss = 0.02753686304512324
Trained batch 153 in epoch 8, gen_loss = 0.9426017366833501, disc_loss = 0.027360904422269638
Trained batch 154 in epoch 8, gen_loss = 0.9424561387108218, disc_loss = 0.027188349161635064
Trained batch 155 in epoch 8, gen_loss = 0.9423592726771648, disc_loss = 0.02701878210008055
Trained batch 156 in epoch 8, gen_loss = 0.9426574541884623, disc_loss = 0.026849642587836037
Trained batch 157 in epoch 8, gen_loss = 0.9420968741178513, disc_loss = 0.02668294486205854
Trained batch 158 in epoch 8, gen_loss = 0.9423029023521351, disc_loss = 0.026517374045471807
Trained batch 159 in epoch 8, gen_loss = 0.9416427051648497, disc_loss = 0.02635339979769924
Trained batch 160 in epoch 8, gen_loss = 0.9416449501277497, disc_loss = 0.02619198891164313
Trained batch 161 in epoch 8, gen_loss = 0.9415503583940459, disc_loss = 0.026032732066124917
Trained batch 162 in epoch 8, gen_loss = 0.9412179660577715, disc_loss = 0.02587456801999789
Trained batch 163 in epoch 8, gen_loss = 0.9419528516690906, disc_loss = 0.02572041385641702
Trained batch 164 in epoch 8, gen_loss = 0.941273821664579, disc_loss = 0.02556818630740357
Trained batch 165 in epoch 8, gen_loss = 0.9409811706787132, disc_loss = 0.02541892024592345
Trained batch 166 in epoch 8, gen_loss = 0.9411915281932511, disc_loss = 0.02527090261427513
Trained batch 167 in epoch 8, gen_loss = 0.9412171235751539, disc_loss = 0.02512344440159116
Trained batch 168 in epoch 8, gen_loss = 0.9409852900801325, disc_loss = 0.024977126052691298
Trained batch 169 in epoch 8, gen_loss = 0.9409631082240273, disc_loss = 0.02483287753420882
Trained batch 170 in epoch 8, gen_loss = 0.9406710321094558, disc_loss = 0.024689709906921074
Trained batch 171 in epoch 8, gen_loss = 0.9412786629657413, disc_loss = 0.024548281336455
Trained batch 172 in epoch 8, gen_loss = 0.9414146199736292, disc_loss = 0.024409132142553934
Trained batch 173 in epoch 8, gen_loss = 0.9408421771622252, disc_loss = 0.024271957182536844
Trained batch 174 in epoch 8, gen_loss = 0.9401088920661381, disc_loss = 0.024137367499393544
Trained batch 175 in epoch 8, gen_loss = 0.9405946381051432, disc_loss = 0.024004287097671873
Trained batch 176 in epoch 8, gen_loss = 0.9399217911022532, disc_loss = 0.023871085641045377
Trained batch 177 in epoch 8, gen_loss = 0.9398574241426554, disc_loss = 0.023739521910653587
Trained batch 178 in epoch 8, gen_loss = 0.9396176616239814, disc_loss = 0.023609068634426845
Trained batch 179 in epoch 8, gen_loss = 0.9399015676644114, disc_loss = 0.02348033385836364
Trained batch 180 in epoch 8, gen_loss = 0.9399800331882351, disc_loss = 0.023352765736108366
Trained batch 181 in epoch 8, gen_loss = 0.9397502549729504, disc_loss = 0.023227414885436053
Trained batch 182 in epoch 8, gen_loss = 0.9401334936175841, disc_loss = 0.023103000500107114
Trained batch 183 in epoch 8, gen_loss = 0.9400715573650339, disc_loss = 0.02298073241494738
Trained batch 184 in epoch 8, gen_loss = 0.9399081879370922, disc_loss = 0.022858974790968302
Trained batch 185 in epoch 8, gen_loss = 0.9396939949002318, disc_loss = 0.022737479552761803
Trained batch 186 in epoch 8, gen_loss = 0.9398011385119535, disc_loss = 0.02261812814802708
Trained batch 187 in epoch 8, gen_loss = 0.9397108169629219, disc_loss = 0.02249983745067321
Trained batch 188 in epoch 8, gen_loss = 0.9394472656111238, disc_loss = 0.022383515847472366
Trained batch 189 in epoch 8, gen_loss = 0.9390219940950996, disc_loss = 0.022268219518561016
Trained batch 190 in epoch 8, gen_loss = 0.9388887091144842, disc_loss = 0.022153204799439583
Trained batch 191 in epoch 8, gen_loss = 0.9385072776737312, disc_loss = 0.0220396741873022
Trained batch 192 in epoch 8, gen_loss = 0.9385315304901933, disc_loss = 0.021926792432135453
Trained batch 193 in epoch 8, gen_loss = 0.9384810944500658, disc_loss = 0.021816688402677097
Trained batch 194 in epoch 8, gen_loss = 0.9382490190175864, disc_loss = 0.02170628984384119
Trained batch 195 in epoch 8, gen_loss = 0.9377344422498528, disc_loss = 0.021598014419117934
Trained batch 196 in epoch 8, gen_loss = 0.9378578833819646, disc_loss = 0.021490528196986377
Trained batch 197 in epoch 8, gen_loss = 0.9379355568777431, disc_loss = 0.02138507765123381
Trained batch 198 in epoch 8, gen_loss = 0.937796242422794, disc_loss = 0.021280405963519496
Trained batch 199 in epoch 8, gen_loss = 0.9371918751299382, disc_loss = 0.021176232140715002
Trained batch 200 in epoch 8, gen_loss = 0.937195735042961, disc_loss = 0.02107223311270615
Trained batch 201 in epoch 8, gen_loss = 0.9375485304263559, disc_loss = 0.0209745361804236
Trained batch 202 in epoch 8, gen_loss = 0.9378947546623023, disc_loss = 0.020872822025213896
Trained batch 203 in epoch 8, gen_loss = 0.9378303083426812, disc_loss = 0.020772739840122442
Trained batch 204 in epoch 8, gen_loss = 0.9378515684023137, disc_loss = 0.020674108750067605
Trained batch 205 in epoch 8, gen_loss = 0.9381023123137002, disc_loss = 0.020575369872832084
Trained batch 206 in epoch 8, gen_loss = 0.9377292732973606, disc_loss = 0.020478373340129682
Trained batch 207 in epoch 8, gen_loss = 0.9374802753042716, disc_loss = 0.020381432866997784
Trained batch 208 in epoch 8, gen_loss = 0.9368267360201292, disc_loss = 0.020285253232549965
Trained batch 209 in epoch 8, gen_loss = 0.9376470513287045, disc_loss = 0.02019045781538201
Trained batch 210 in epoch 8, gen_loss = 0.9375189287120133, disc_loss = 0.020096266656695817
Trained batch 211 in epoch 8, gen_loss = 0.9372923085993191, disc_loss = 0.020003091298177716
Trained batch 212 in epoch 8, gen_loss = 0.9373396840733541, disc_loss = 0.019911606445473493
Trained batch 213 in epoch 8, gen_loss = 0.9375811744237614, disc_loss = 0.019819897104209186
Trained batch 214 in epoch 8, gen_loss = 0.9375729944816855, disc_loss = 0.01972984633554683
Trained batch 215 in epoch 8, gen_loss = 0.9372607995238569, disc_loss = 0.019639662745046534
Trained batch 216 in epoch 8, gen_loss = 0.9375173505824832, disc_loss = 0.019550748959115023
Trained batch 217 in epoch 8, gen_loss = 0.9378591347998435, disc_loss = 0.019464211643902038
Trained batch 218 in epoch 8, gen_loss = 0.9382317685373297, disc_loss = 0.019376896769494098
Trained batch 219 in epoch 8, gen_loss = 0.9382357146252286, disc_loss = 0.019289961259743325
Trained batch 220 in epoch 8, gen_loss = 0.9381276437869439, disc_loss = 0.01920366707307706
Trained batch 221 in epoch 8, gen_loss = 0.9384207058328766, disc_loss = 0.019118910522773327
Trained batch 222 in epoch 8, gen_loss = 0.9376459318158873, disc_loss = 0.019035500104472795
Trained batch 223 in epoch 8, gen_loss = 0.9372731560309019, disc_loss = 0.018951769251478772
Trained batch 224 in epoch 8, gen_loss = 0.9368661023510827, disc_loss = 0.018869237729878578
Trained batch 225 in epoch 8, gen_loss = 0.9366468693566533, disc_loss = 0.018787512889317858
Trained batch 226 in epoch 8, gen_loss = 0.93626949217351, disc_loss = 0.018705923552894122
Trained batch 227 in epoch 8, gen_loss = 0.9359383189625907, disc_loss = 0.018624750268300932
Trained batch 228 in epoch 8, gen_loss = 0.9358463556745688, disc_loss = 0.01854436497934016
Trained batch 229 in epoch 8, gen_loss = 0.9356521929087847, disc_loss = 0.018464784033953355
Trained batch 230 in epoch 8, gen_loss = 0.9355000743876288, disc_loss = 0.01838606500145687
Trained batch 231 in epoch 8, gen_loss = 0.9358977450635927, disc_loss = 0.018308642000004604
Trained batch 232 in epoch 8, gen_loss = 0.9363923299210266, disc_loss = 0.018231790414808994
Trained batch 233 in epoch 8, gen_loss = 0.9367724357761888, disc_loss = 0.018155352770125505
Trained batch 234 in epoch 8, gen_loss = 0.9367131373983748, disc_loss = 0.018079371609355997
Trained batch 235 in epoch 8, gen_loss = 0.9365720578421981, disc_loss = 0.018004852581078135
Trained batch 236 in epoch 8, gen_loss = 0.9368691626731857, disc_loss = 0.01793164002530047
Trained batch 237 in epoch 8, gen_loss = 0.9372158267167436, disc_loss = 0.01786089194599811
Trained batch 238 in epoch 8, gen_loss = 0.9368029497407969, disc_loss = 0.017787178625363883
Trained batch 239 in epoch 8, gen_loss = 0.936720281218489, disc_loss = 0.01771567728640851
Trained batch 240 in epoch 8, gen_loss = 0.93623621322802, disc_loss = 0.017644865890176043
Trained batch 241 in epoch 8, gen_loss = 0.9363374388661266, disc_loss = 0.01757371258191439
Trained batch 242 in epoch 8, gen_loss = 0.9359888151104068, disc_loss = 0.017502552957775613
Trained batch 243 in epoch 8, gen_loss = 0.9360364239479675, disc_loss = 0.0174327163215031
Trained batch 244 in epoch 8, gen_loss = 0.9360459190242144, disc_loss = 0.01736281995479806
Trained batch 245 in epoch 8, gen_loss = 0.9356379468993443, disc_loss = 0.017294544472188284
Trained batch 246 in epoch 8, gen_loss = 0.9357364398506489, disc_loss = 0.017226136574978367
Trained batch 247 in epoch 8, gen_loss = 0.9354187306617537, disc_loss = 0.01715853029617715
Trained batch 248 in epoch 8, gen_loss = 0.9354721170113268, disc_loss = 0.017091726901953624
Trained batch 249 in epoch 8, gen_loss = 0.9351630626916886, disc_loss = 0.01702470465603983
Trained batch 250 in epoch 8, gen_loss = 0.9353466526683109, disc_loss = 0.016958995758353145
Trained batch 251 in epoch 8, gen_loss = 0.9351425429894811, disc_loss = 0.01689449320393679
Trained batch 252 in epoch 8, gen_loss = 0.9345357049359635, disc_loss = 0.01682908890032432
Trained batch 253 in epoch 8, gen_loss = 0.9342468924175097, disc_loss = 0.016764189394575444
Trained batch 254 in epoch 8, gen_loss = 0.9338612669823216, disc_loss = 0.016700169800805822
Trained batch 255 in epoch 8, gen_loss = 0.9338725415291265, disc_loss = 0.01663664730239134
Trained batch 256 in epoch 8, gen_loss = 0.9339684692106358, disc_loss = 0.01657476129094347
Trained batch 257 in epoch 8, gen_loss = 0.9336599808099658, disc_loss = 0.0165126572140062
Trained batch 258 in epoch 8, gen_loss = 0.9340392644571062, disc_loss = 0.016451023973631997
Trained batch 259 in epoch 8, gen_loss = 0.9335214437200473, disc_loss = 0.016389830205130587
Trained batch 260 in epoch 8, gen_loss = 0.9334008767915412, disc_loss = 0.016329373870795624
Trained batch 261 in epoch 8, gen_loss = 0.933444113108038, disc_loss = 0.016269163990547463
Trained batch 262 in epoch 8, gen_loss = 0.9332376499819665, disc_loss = 0.01620944047685555
Trained batch 263 in epoch 8, gen_loss = 0.9330225093572428, disc_loss = 0.01614982221965902
Trained batch 264 in epoch 8, gen_loss = 0.9330278611408089, disc_loss = 0.016090559611867956
Trained batch 265 in epoch 8, gen_loss = 0.93303969692915, disc_loss = 0.01603130809388332
Trained batch 266 in epoch 8, gen_loss = 0.9328099338526137, disc_loss = 0.01597281333078911
Trained batch 267 in epoch 8, gen_loss = 0.9328663116737977, disc_loss = 0.01591573484213076
Trained batch 268 in epoch 8, gen_loss = 0.9326957104152906, disc_loss = 0.01585772079568171
Trained batch 269 in epoch 8, gen_loss = 0.9327618213715376, disc_loss = 0.01580021467768044
Trained batch 270 in epoch 8, gen_loss = 0.933116613168998, disc_loss = 0.01574406991662274
Trained batch 271 in epoch 8, gen_loss = 0.9334487436229691, disc_loss = 0.015687486151524783
Trained batch 272 in epoch 8, gen_loss = 0.9336421442774189, disc_loss = 0.01563202358609374
Trained batch 273 in epoch 8, gen_loss = 0.9334717739890092, disc_loss = 0.015576763327811747
Trained batch 274 in epoch 8, gen_loss = 0.9331977795470845, disc_loss = 0.015521307766215284
Trained batch 275 in epoch 8, gen_loss = 0.9333958272700724, disc_loss = 0.015466982550171215
Trained batch 276 in epoch 8, gen_loss = 0.9332364370461406, disc_loss = 0.015411939200516941
Trained batch 277 in epoch 8, gen_loss = 0.9332656520519326, disc_loss = 0.01535806177210577
Trained batch 278 in epoch 8, gen_loss = 0.9331199681673426, disc_loss = 0.015304639057632232
Trained batch 279 in epoch 8, gen_loss = 0.9332314436989171, disc_loss = 0.015252490792824704
Trained batch 280 in epoch 8, gen_loss = 0.933235108322096, disc_loss = 0.015199054621735479
Trained batch 281 in epoch 8, gen_loss = 0.9329335876601808, disc_loss = 0.015146169138538522
Trained batch 282 in epoch 8, gen_loss = 0.9326942035461062, disc_loss = 0.015094100622871197
Trained batch 283 in epoch 8, gen_loss = 0.9323366006285372, disc_loss = 0.015041777452135878
Trained batch 284 in epoch 8, gen_loss = 0.9321500559647878, disc_loss = 0.014990765440049009
Trained batch 285 in epoch 8, gen_loss = 0.9322058369854948, disc_loss = 0.014939961352115302
Trained batch 286 in epoch 8, gen_loss = 0.93246634984681, disc_loss = 0.014888944433988251
Trained batch 287 in epoch 8, gen_loss = 0.9325590163676275, disc_loss = 0.014838869477595532
Trained batch 288 in epoch 8, gen_loss = 0.9325692724810339, disc_loss = 0.014788920447414831
Trained batch 289 in epoch 8, gen_loss = 0.9324490009710706, disc_loss = 0.0147394586696715
Trained batch 290 in epoch 8, gen_loss = 0.9323890281911568, disc_loss = 0.014690044887793567
Trained batch 291 in epoch 8, gen_loss = 0.9322655185648839, disc_loss = 0.014641214060347546
Trained batch 292 in epoch 8, gen_loss = 0.9321977194055355, disc_loss = 0.014592172146187587
Trained batch 293 in epoch 8, gen_loss = 0.9324583919072638, disc_loss = 0.014543867569819067
Trained batch 294 in epoch 8, gen_loss = 0.9323440217365653, disc_loss = 0.014495639379286223
Trained batch 295 in epoch 8, gen_loss = 0.9319258534626381, disc_loss = 0.014449024094918403
Trained batch 296 in epoch 8, gen_loss = 0.9321565693275695, disc_loss = 0.014401812322640805
Trained batch 297 in epoch 8, gen_loss = 0.9320879959620085, disc_loss = 0.014356508815599349
Trained batch 298 in epoch 8, gen_loss = 0.9321381759683424, disc_loss = 0.01431004201008683
Trained batch 299 in epoch 8, gen_loss = 0.9323391637206078, disc_loss = 0.014263188142407065
Trained batch 300 in epoch 8, gen_loss = 0.9326952265148543, disc_loss = 0.014217504568589832
Trained batch 301 in epoch 8, gen_loss = 0.9322724615698619, disc_loss = 0.014172310258812326
Trained batch 302 in epoch 8, gen_loss = 0.9325796626385289, disc_loss = 0.01412825572816194
Trained batch 303 in epoch 8, gen_loss = 0.9325692299753428, disc_loss = 0.014083804575325064
Trained batch 304 in epoch 8, gen_loss = 0.9321391644047909, disc_loss = 0.014039203977177958
Trained batch 305 in epoch 8, gen_loss = 0.9323893924748975, disc_loss = 0.013994896413874051
Trained batch 306 in epoch 8, gen_loss = 0.9325563518348656, disc_loss = 0.013951005766597495
Trained batch 307 in epoch 8, gen_loss = 0.9327806546897083, disc_loss = 0.013907383700648274
Trained batch 308 in epoch 8, gen_loss = 0.9327958898444006, disc_loss = 0.013863869784301912
Trained batch 309 in epoch 8, gen_loss = 0.9325163778758818, disc_loss = 0.013823375555934504
Trained batch 310 in epoch 8, gen_loss = 0.9320301617648441, disc_loss = 0.013890540286624606
Trained batch 311 in epoch 8, gen_loss = 0.9328743447669041, disc_loss = 0.013854422929841511
Trained batch 312 in epoch 8, gen_loss = 0.9330808626005824, disc_loss = 0.013830711991643718
Trained batch 313 in epoch 8, gen_loss = 0.933167698941413, disc_loss = 0.013790311927093003
Trained batch 314 in epoch 8, gen_loss = 0.933590117617259, disc_loss = 0.01375170310918567
Trained batch 315 in epoch 8, gen_loss = 0.9341991440970686, disc_loss = 0.013710947244397153
Trained batch 316 in epoch 8, gen_loss = 0.9346345444018909, disc_loss = 0.013670197910407399
Trained batch 317 in epoch 8, gen_loss = 0.9351326170020133, disc_loss = 0.013629874550962949
Trained batch 318 in epoch 8, gen_loss = 0.9354793460204683, disc_loss = 0.013589991514606044
Trained batch 319 in epoch 8, gen_loss = 0.9356002097018064, disc_loss = 0.013549996561050649
Trained batch 320 in epoch 8, gen_loss = 0.9357358957191123, disc_loss = 0.01352039733655008
Trained batch 321 in epoch 8, gen_loss = 0.9359889020275626, disc_loss = 0.01348318565804627
Trained batch 322 in epoch 8, gen_loss = 0.9364680185591104, disc_loss = 0.013445906228264765
Trained batch 323 in epoch 8, gen_loss = 0.9367021393076873, disc_loss = 0.01340869236967446
Trained batch 324 in epoch 8, gen_loss = 0.9366062376132378, disc_loss = 0.013369464000973564
Trained batch 325 in epoch 8, gen_loss = 0.9367916332614934, disc_loss = 0.01333012580057389
Trained batch 326 in epoch 8, gen_loss = 0.9371420331868922, disc_loss = 0.013299708810011182
Trained batch 327 in epoch 8, gen_loss = 0.9371034095018376, disc_loss = 0.01326037105643148
Trained batch 328 in epoch 8, gen_loss = 0.9372083429688741, disc_loss = 0.013221924181614993
Trained batch 329 in epoch 8, gen_loss = 0.937136510014534, disc_loss = 0.013183525755250064
Trained batch 330 in epoch 8, gen_loss = 0.9370986573465642, disc_loss = 0.013144630306133763
Trained batch 331 in epoch 8, gen_loss = 0.9373097987957748, disc_loss = 0.013107171131130337
Trained batch 332 in epoch 8, gen_loss = 0.9376029442917477, disc_loss = 0.013071070563390028
Trained batch 333 in epoch 8, gen_loss = 0.9380618645224029, disc_loss = 0.013033421576377924
Trained batch 334 in epoch 8, gen_loss = 0.9376123443468293, disc_loss = 0.013001729150514688
Trained batch 335 in epoch 8, gen_loss = 0.9376509882332313, disc_loss = 0.012965614806879395
Trained batch 336 in epoch 8, gen_loss = 0.9375139564187307, disc_loss = 0.012930028454123551
Trained batch 337 in epoch 8, gen_loss = 0.9374626600707071, disc_loss = 0.012893800677875603
Trained batch 338 in epoch 8, gen_loss = 0.9375682152302216, disc_loss = 0.012857292605969907
Trained batch 339 in epoch 8, gen_loss = 0.9375749154125943, disc_loss = 0.012820830419300096
Trained batch 340 in epoch 8, gen_loss = 0.9377125675552401, disc_loss = 0.01278487456932765
Trained batch 341 in epoch 8, gen_loss = 0.937848731701137, disc_loss = 0.012748427908715781
Trained batch 342 in epoch 8, gen_loss = 0.9378133623836339, disc_loss = 0.012712743398804712
Trained batch 343 in epoch 8, gen_loss = 0.9379646316343961, disc_loss = 0.012676686859946173
Trained batch 344 in epoch 8, gen_loss = 0.9380763516045999, disc_loss = 0.01264116789865564
Trained batch 345 in epoch 8, gen_loss = 0.9379962857575775, disc_loss = 0.01260559787944153
Trained batch 346 in epoch 8, gen_loss = 0.938181540378576, disc_loss = 0.012570265852826076
Trained batch 347 in epoch 8, gen_loss = 0.938410059730897, disc_loss = 0.012535124903677926
Trained batch 348 in epoch 8, gen_loss = 0.9384730884373017, disc_loss = 0.01250042366392625
Trained batch 349 in epoch 8, gen_loss = 0.9386051625013352, disc_loss = 0.01246629046284527
Trained batch 350 in epoch 8, gen_loss = 0.9385851732855849, disc_loss = 0.012431895854286558
Trained batch 351 in epoch 8, gen_loss = 0.9384363504465331, disc_loss = 0.012397385224589512
Trained batch 352 in epoch 8, gen_loss = 0.9388163198661534, disc_loss = 0.012363277211875679
Trained batch 353 in epoch 8, gen_loss = 0.9392904161901797, disc_loss = 0.012329049875905822
Trained batch 354 in epoch 8, gen_loss = 0.9395334624068837, disc_loss = 0.01229536237644399
Trained batch 355 in epoch 8, gen_loss = 0.939605980358097, disc_loss = 0.012262227848234974
Trained batch 356 in epoch 8, gen_loss = 0.9396509235145665, disc_loss = 0.012228457743152963
Trained batch 357 in epoch 8, gen_loss = 0.9395896528519732, disc_loss = 0.012195029431460074
Trained batch 358 in epoch 8, gen_loss = 0.9396580086611107, disc_loss = 0.012162359576702473
Trained batch 359 in epoch 8, gen_loss = 0.9399209698869122, disc_loss = 0.012129636341018744
Trained batch 360 in epoch 8, gen_loss = 0.9397852796431724, disc_loss = 0.012096707595096593
Trained batch 361 in epoch 8, gen_loss = 0.9398796982363443, disc_loss = 0.012064854439451855
Trained batch 362 in epoch 8, gen_loss = 0.9402110996160954, disc_loss = 0.01203339075160209
Trained batch 363 in epoch 8, gen_loss = 0.9400490984975637, disc_loss = 0.012001065216191908
Trained batch 364 in epoch 8, gen_loss = 0.9400768241653704, disc_loss = 0.011969523106531037
Trained batch 365 in epoch 8, gen_loss = 0.9400228340931929, disc_loss = 0.011937791077858105
Trained batch 366 in epoch 8, gen_loss = 0.9402509938306315, disc_loss = 0.011905974455960335
Trained batch 367 in epoch 8, gen_loss = 0.9404053277457538, disc_loss = 0.011874573813735839
Trained batch 368 in epoch 8, gen_loss = 0.9405683861353856, disc_loss = 0.01184303324579212
Trained batch 369 in epoch 8, gen_loss = 0.9403445127042565, disc_loss = 0.01181181596416659
Trained batch 370 in epoch 8, gen_loss = 0.940132184089676, disc_loss = 0.011780678673458757
Trained batch 371 in epoch 8, gen_loss = 0.9400023695441985, disc_loss = 0.011749744417043516
Trained batch 372 in epoch 8, gen_loss = 0.9400148464431711, disc_loss = 0.011719206986668266
Trained batch 373 in epoch 8, gen_loss = 0.9398806907117048, disc_loss = 0.011688512115638745
Trained batch 374 in epoch 8, gen_loss = 0.9398260503609975, disc_loss = 0.011658421958913095
Trained batch 375 in epoch 8, gen_loss = 0.9402191295744257, disc_loss = 0.01162897863689571
Trained batch 376 in epoch 8, gen_loss = 0.940435040139393, disc_loss = 0.0115988008403982
Trained batch 377 in epoch 8, gen_loss = 0.9406147803421374, disc_loss = 0.011569392209200906
Trained batch 378 in epoch 8, gen_loss = 0.9405937168874967, disc_loss = 0.011539958322924159
Trained batch 379 in epoch 8, gen_loss = 0.9405823087221697, disc_loss = 0.011510395062941825
Trained batch 380 in epoch 8, gen_loss = 0.9405416419969144, disc_loss = 0.011481132941802395
Trained batch 381 in epoch 8, gen_loss = 0.9404833174032691, disc_loss = 0.011452059840339453
Trained batch 382 in epoch 8, gen_loss = 0.9406977643698998, disc_loss = 0.011423240009096194
Trained batch 383 in epoch 8, gen_loss = 0.9408899794798344, disc_loss = 0.011394464294085083
Trained batch 384 in epoch 8, gen_loss = 0.9408999666765139, disc_loss = 0.011366151369066437
Trained batch 385 in epoch 8, gen_loss = 0.9408726728487509, disc_loss = 0.011338023625190884
Trained batch 386 in epoch 8, gen_loss = 0.9408922347141483, disc_loss = 0.011309422082224083
Trained batch 387 in epoch 8, gen_loss = 0.9406584660263405, disc_loss = 0.011280900163891949
Trained batch 388 in epoch 8, gen_loss = 0.9409308892442512, disc_loss = 0.011252746886370528
Trained batch 389 in epoch 8, gen_loss = 0.9404999775000108, disc_loss = 0.011224694076950889
Trained batch 390 in epoch 8, gen_loss = 0.940758449570907, disc_loss = 0.011196901160746377
Trained batch 391 in epoch 8, gen_loss = 0.9405132753356379, disc_loss = 0.011168961422893572
Trained batch 392 in epoch 8, gen_loss = 0.9407799112736117, disc_loss = 0.011141284537964036
Trained batch 393 in epoch 8, gen_loss = 0.940630996514698, disc_loss = 0.011114424576654588
Trained batch 394 in epoch 8, gen_loss = 0.9405781690832935, disc_loss = 0.011086960416839788
Trained batch 395 in epoch 8, gen_loss = 0.9403295552339217, disc_loss = 0.011060203590177203
Trained batch 396 in epoch 8, gen_loss = 0.940256882299404, disc_loss = 0.011033122536955901
Trained batch 397 in epoch 8, gen_loss = 0.9402598842753837, disc_loss = 0.0110062658861727
Trained batch 398 in epoch 8, gen_loss = 0.9399414996903642, disc_loss = 0.01097922921258773
Trained batch 399 in epoch 8, gen_loss = 0.939967145845294, disc_loss = 0.010952308781525063
Trained batch 400 in epoch 8, gen_loss = 0.940097826303092, disc_loss = 0.01092546862183415
Trained batch 401 in epoch 8, gen_loss = 0.9402789665543618, disc_loss = 0.01089908485597669
Trained batch 402 in epoch 8, gen_loss = 0.9402896635437722, disc_loss = 0.01087283863724734
Trained batch 403 in epoch 8, gen_loss = 0.9403795513628733, disc_loss = 0.01084654076508417
Trained batch 404 in epoch 8, gen_loss = 0.9405704838994109, disc_loss = 0.010820371832735952
Trained batch 405 in epoch 8, gen_loss = 0.9408788871148537, disc_loss = 0.010794513603371884
Trained batch 406 in epoch 8, gen_loss = 0.9410554729310535, disc_loss = 0.010768790069752412
Trained batch 407 in epoch 8, gen_loss = 0.94099155879196, disc_loss = 0.010743117650218112
Trained batch 408 in epoch 8, gen_loss = 0.9407157757317233, disc_loss = 0.010717638290426318
Trained batch 409 in epoch 8, gen_loss = 0.9406744464868453, disc_loss = 0.010692437921463308
Trained batch 410 in epoch 8, gen_loss = 0.940645231165155, disc_loss = 0.010667039940831615
Trained batch 411 in epoch 8, gen_loss = 0.9406068224496055, disc_loss = 0.010641987518168923
Trained batch 412 in epoch 8, gen_loss = 0.9406244588100304, disc_loss = 0.01061688853454828
Trained batch 413 in epoch 8, gen_loss = 0.9406222822729516, disc_loss = 0.01059250369151168
Trained batch 414 in epoch 8, gen_loss = 0.9405108900673418, disc_loss = 0.010567619312969765
Trained batch 415 in epoch 8, gen_loss = 0.940534057883689, disc_loss = 0.01054276651019301
Trained batch 416 in epoch 8, gen_loss = 0.9404232551296838, disc_loss = 0.010517998193225955
Trained batch 417 in epoch 8, gen_loss = 0.9400657416102989, disc_loss = 0.010493570384828477
Trained batch 418 in epoch 8, gen_loss = 0.9399150371693769, disc_loss = 0.010469512604421497
Trained batch 419 in epoch 8, gen_loss = 0.9400027781015351, disc_loss = 0.010445198868789399
Trained batch 420 in epoch 8, gen_loss = 0.9400014296138655, disc_loss = 0.010421105878534915
Trained batch 421 in epoch 8, gen_loss = 0.9398085344317965, disc_loss = 0.010397344339507637
Trained batch 422 in epoch 8, gen_loss = 0.9396233417040912, disc_loss = 0.0103735542794509
Trained batch 423 in epoch 8, gen_loss = 0.9398149715139056, disc_loss = 0.010349862273801162
Trained batch 424 in epoch 8, gen_loss = 0.9398310331036063, disc_loss = 0.010326174129937391
Trained batch 425 in epoch 8, gen_loss = 0.9398619235261505, disc_loss = 0.010302428347191132
Trained batch 426 in epoch 8, gen_loss = 0.9401034936832321, disc_loss = 0.010279116581434839
Trained batch 427 in epoch 8, gen_loss = 0.9399765787698399, disc_loss = 0.010255485511016075
Trained batch 428 in epoch 8, gen_loss = 0.940126371480924, disc_loss = 0.010232244477534585
Trained batch 429 in epoch 8, gen_loss = 0.9402590321246967, disc_loss = 0.010208909139226646
Trained batch 430 in epoch 8, gen_loss = 0.9402252079577568, disc_loss = 0.010186162127372042
Trained batch 431 in epoch 8, gen_loss = 0.9401573415293738, disc_loss = 0.010163565850504071
Trained batch 432 in epoch 8, gen_loss = 0.9401217914481086, disc_loss = 0.010140706957092049
Trained batch 433 in epoch 8, gen_loss = 0.9402520552895586, disc_loss = 0.010118382616831775
Trained batch 434 in epoch 8, gen_loss = 0.9400125219219032, disc_loss = 0.010096490441958003
Trained batch 435 in epoch 8, gen_loss = 0.9397816289592227, disc_loss = 0.010073955251646779
Trained batch 436 in epoch 8, gen_loss = 0.9395217566113723, disc_loss = 0.010051231206678711
Trained batch 437 in epoch 8, gen_loss = 0.9396128355776339, disc_loss = 0.010028931887761359
Trained batch 438 in epoch 8, gen_loss = 0.939553302010534, disc_loss = 0.0100067153822043
Trained batch 439 in epoch 8, gen_loss = 0.9396014715460214, disc_loss = 0.009984589343697404
Trained batch 440 in epoch 8, gen_loss = 0.9396336733483944, disc_loss = 0.009962450990758523
Trained batch 441 in epoch 8, gen_loss = 0.9395002658685409, disc_loss = 0.009941419496330563
Trained batch 442 in epoch 8, gen_loss = 0.9397102355553388, disc_loss = 0.009919797905203602
Trained batch 443 in epoch 8, gen_loss = 0.9397572015185613, disc_loss = 0.009898042689307765
Trained batch 444 in epoch 8, gen_loss = 0.939952238423101, disc_loss = 0.009877071323545566
Trained batch 445 in epoch 8, gen_loss = 0.9396469656528379, disc_loss = 0.009855425579177379
Trained batch 446 in epoch 8, gen_loss = 0.9395142736984312, disc_loss = 0.009833877251920514
Trained batch 447 in epoch 8, gen_loss = 0.9395340983755887, disc_loss = 0.009812444191343925
Trained batch 448 in epoch 8, gen_loss = 0.9398235323567168, disc_loss = 0.009791211362898075
Trained batch 449 in epoch 8, gen_loss = 0.9400223659806781, disc_loss = 0.009770090818249932
Trained batch 450 in epoch 8, gen_loss = 0.9398702559476417, disc_loss = 0.009748951987637788
Trained batch 451 in epoch 8, gen_loss = 0.9402022603734405, disc_loss = 0.009728270834132842
Trained batch 452 in epoch 8, gen_loss = 0.9404775216747857, disc_loss = 0.009707325048720008
Trained batch 453 in epoch 8, gen_loss = 0.9405595349714094, disc_loss = 0.009686386221232577
Trained batch 454 in epoch 8, gen_loss = 0.9408228210695497, disc_loss = 0.00966560795422193
Trained batch 455 in epoch 8, gen_loss = 0.9408404272245733, disc_loss = 0.009645138359158872
Trained batch 456 in epoch 8, gen_loss = 0.9408384416113797, disc_loss = 0.00962466245982796
Trained batch 457 in epoch 8, gen_loss = 0.940670421485297, disc_loss = 0.009604104614855242
Trained batch 458 in epoch 8, gen_loss = 0.9406553813964453, disc_loss = 0.00958362195334166
Trained batch 459 in epoch 8, gen_loss = 0.9405971605492675, disc_loss = 0.009563233862813238
Trained batch 460 in epoch 8, gen_loss = 0.9404594050700131, disc_loss = 0.009543550819074716
Trained batch 461 in epoch 8, gen_loss = 0.9404010925587122, disc_loss = 0.009524188147307459
Trained batch 462 in epoch 8, gen_loss = 0.9405456215593779, disc_loss = 0.00950407345639567
Trained batch 463 in epoch 8, gen_loss = 0.9403290095385807, disc_loss = 0.009484290301927479
Trained batch 464 in epoch 8, gen_loss = 0.9401298031371127, disc_loss = 0.009464431240227103
Trained batch 465 in epoch 8, gen_loss = 0.9406087977308061, disc_loss = 0.009445384517605586
Trained batch 466 in epoch 8, gen_loss = 0.9403552298755156, disc_loss = 0.009425757285545289
Trained batch 467 in epoch 8, gen_loss = 0.9403606818145157, disc_loss = 0.009407020018590987
Trained batch 468 in epoch 8, gen_loss = 0.9402375052859788, disc_loss = 0.009387289152336942
Trained batch 469 in epoch 8, gen_loss = 0.9402704526135262, disc_loss = 0.009367849233905795
Trained batch 470 in epoch 8, gen_loss = 0.9400568553216898, disc_loss = 0.0093488822750895
Trained batch 471 in epoch 8, gen_loss = 0.9402914474702487, disc_loss = 0.009329712113852157
Trained batch 472 in epoch 8, gen_loss = 0.9400290195962088, disc_loss = 0.009310400097250168
Trained batch 473 in epoch 8, gen_loss = 0.939804559329894, disc_loss = 0.009291270158274733
Trained batch 474 in epoch 8, gen_loss = 0.9397789584335527, disc_loss = 0.009272300846764425
Trained batch 475 in epoch 8, gen_loss = 0.9395369966866589, disc_loss = 0.009253624206562448
Trained batch 476 in epoch 8, gen_loss = 0.9398756134060194, disc_loss = 0.009234791585506356
Trained batch 477 in epoch 8, gen_loss = 0.9397600816258825, disc_loss = 0.009215928416927617
Trained batch 478 in epoch 8, gen_loss = 0.9398189994014629, disc_loss = 0.009197156169631135
Trained batch 479 in epoch 8, gen_loss = 0.9397530376290282, disc_loss = 0.00917887824477172
Trained batch 480 in epoch 8, gen_loss = 0.9400494048476467, disc_loss = 0.009160210803589685
Trained batch 481 in epoch 8, gen_loss = 0.9398168008233502, disc_loss = 0.00914187365802318
Trained batch 482 in epoch 8, gen_loss = 0.9396329342578509, disc_loss = 0.00912379173045654
Trained batch 483 in epoch 8, gen_loss = 0.9395218041440672, disc_loss = 0.009105353716297618
Trained batch 484 in epoch 8, gen_loss = 0.9394498901883351, disc_loss = 0.009087694002394613
Trained batch 485 in epoch 8, gen_loss = 0.939372030611882, disc_loss = 0.009070151704979136
Trained batch 486 in epoch 8, gen_loss = 0.939426901220541, disc_loss = 0.009052099573205548
Trained batch 487 in epoch 8, gen_loss = 0.9394394445736878, disc_loss = 0.009034284217854233
Trained batch 488 in epoch 8, gen_loss = 0.9395891223826535, disc_loss = 0.009016906208554398
Trained batch 489 in epoch 8, gen_loss = 0.939412427495937, disc_loss = 0.008999269668604438
Trained batch 490 in epoch 8, gen_loss = 0.9391760559650157, disc_loss = 0.00898172639693511
Trained batch 491 in epoch 8, gen_loss = 0.9390104628069614, disc_loss = 0.008963943316413817
Trained batch 492 in epoch 8, gen_loss = 0.9389440171254334, disc_loss = 0.00894658077431703
Trained batch 493 in epoch 8, gen_loss = 0.9389491751488404, disc_loss = 0.008929810129593386
Trained batch 494 in epoch 8, gen_loss = 0.9389800085563852, disc_loss = 0.008912166898112951
Trained batch 495 in epoch 8, gen_loss = 0.9390606228262186, disc_loss = 0.00889458261712383
Trained batch 496 in epoch 8, gen_loss = 0.9391362378654825, disc_loss = 0.008877468229457923
Trained batch 497 in epoch 8, gen_loss = 0.9392635520083837, disc_loss = 0.008860168156651667
Trained batch 498 in epoch 8, gen_loss = 0.9392873234524278, disc_loss = 0.008843155712391323
Trained batch 499 in epoch 8, gen_loss = 0.9394150916934013, disc_loss = 0.008826195633329917
Trained batch 500 in epoch 8, gen_loss = 0.9393794778697268, disc_loss = 0.008809343281821506
Trained batch 501 in epoch 8, gen_loss = 0.9395368017879615, disc_loss = 0.008792335888165869
Trained batch 502 in epoch 8, gen_loss = 0.9393548009765315, disc_loss = 0.008775395362799483
Trained batch 503 in epoch 8, gen_loss = 0.9396142445741191, disc_loss = 0.00876066796043897
Trained batch 504 in epoch 8, gen_loss = 0.9396567615542082, disc_loss = 0.008743969587053606
Trained batch 505 in epoch 8, gen_loss = 0.9398249076171354, disc_loss = 0.008727284601745527
Trained batch 506 in epoch 8, gen_loss = 0.9398058031555229, disc_loss = 0.00871070028649858
Trained batch 507 in epoch 8, gen_loss = 0.9396859752967601, disc_loss = 0.00869398053889493
Trained batch 508 in epoch 8, gen_loss = 0.9397267722076423, disc_loss = 0.008677324910163523
Trained batch 509 in epoch 8, gen_loss = 0.9397970249255498, disc_loss = 0.008660822698085194
Trained batch 510 in epoch 8, gen_loss = 0.9400500055045298, disc_loss = 0.008644376791005092
Trained batch 511 in epoch 8, gen_loss = 0.9400593325844966, disc_loss = 0.00862794677343004
Trained batch 512 in epoch 8, gen_loss = 0.9402372562281105, disc_loss = 0.008611483189137108
Trained batch 513 in epoch 8, gen_loss = 0.9402282107548955, disc_loss = 0.00859522815368633
Trained batch 514 in epoch 8, gen_loss = 0.9401701706705742, disc_loss = 0.008579284862956503
Trained batch 515 in epoch 8, gen_loss = 0.9403626024145488, disc_loss = 0.008563326143846006
Trained batch 516 in epoch 8, gen_loss = 0.9404257210241757, disc_loss = 0.0085473469294931
Trained batch 517 in epoch 8, gen_loss = 0.9404796184144886, disc_loss = 0.008531696435446585
Trained batch 518 in epoch 8, gen_loss = 0.9403104588590375, disc_loss = 0.008515686994228513
Trained batch 519 in epoch 8, gen_loss = 0.9400951348245143, disc_loss = 0.008499747908186132
Trained batch 520 in epoch 8, gen_loss = 0.940288674980116, disc_loss = 0.00848422935183362
Trained batch 521 in epoch 8, gen_loss = 0.9404276426153622, disc_loss = 0.008468488996308315
Trained batch 522 in epoch 8, gen_loss = 0.9407315538558632, disc_loss = 0.008453002398249107
Trained batch 523 in epoch 8, gen_loss = 0.9405982476723103, disc_loss = 0.008437170896577854
Trained batch 524 in epoch 8, gen_loss = 0.9405806931427547, disc_loss = 0.008421615704040354
Trained batch 525 in epoch 8, gen_loss = 0.9405982397468371, disc_loss = 0.008406237136435823
Trained batch 526 in epoch 8, gen_loss = 0.9407093804859799, disc_loss = 0.008390625571137103
Trained batch 527 in epoch 8, gen_loss = 0.9409649732776664, disc_loss = 0.00837544889503933
Trained batch 528 in epoch 8, gen_loss = 0.9408603533116541, disc_loss = 0.008360326140320161
Trained batch 529 in epoch 8, gen_loss = 0.9409487052346176, disc_loss = 0.008345201079412978
Trained batch 530 in epoch 8, gen_loss = 0.9408511809597806, disc_loss = 0.008329961504594278
Trained batch 531 in epoch 8, gen_loss = 0.9407696281944898, disc_loss = 0.008314632467533412
Trained batch 532 in epoch 8, gen_loss = 0.9409687502858339, disc_loss = 0.008299665131316107
Trained batch 533 in epoch 8, gen_loss = 0.9411214725689941, disc_loss = 0.008284886736594567
Trained batch 534 in epoch 8, gen_loss = 0.9409547908840893, disc_loss = 0.00826984759519164
Trained batch 535 in epoch 8, gen_loss = 0.9409597692316147, disc_loss = 0.00825468184376038
Trained batch 536 in epoch 8, gen_loss = 0.9408842732009497, disc_loss = 0.008239679870720749
Trained batch 537 in epoch 8, gen_loss = 0.9409762429814357, disc_loss = 0.008224789120172942
Trained batch 538 in epoch 8, gen_loss = 0.9410286760838885, disc_loss = 0.008210052251705645
Trained batch 539 in epoch 8, gen_loss = 0.9412894135823956, disc_loss = 0.008195202867257952
Trained batch 540 in epoch 8, gen_loss = 0.9414654855036251, disc_loss = 0.008180646882313923
Trained batch 541 in epoch 8, gen_loss = 0.941346077186595, disc_loss = 0.008165780365038783
Trained batch 542 in epoch 8, gen_loss = 0.9413254439391704, disc_loss = 0.008151013427258566
Trained batch 543 in epoch 8, gen_loss = 0.9412188744172454, disc_loss = 0.008136515899289353
Trained batch 544 in epoch 8, gen_loss = 0.9412197057807118, disc_loss = 0.008121952558830253
Trained batch 545 in epoch 8, gen_loss = 0.9412517520861748, disc_loss = 0.008107487811921667
Trained batch 546 in epoch 8, gen_loss = 0.9413040843153785, disc_loss = 0.008093009134990774
Trained batch 547 in epoch 8, gen_loss = 0.9414544283364811, disc_loss = 0.008078674311899618
Trained batch 548 in epoch 8, gen_loss = 0.9413897610644391, disc_loss = 0.00806430028391008
Trained batch 549 in epoch 8, gen_loss = 0.9415238147974014, disc_loss = 0.00805012116039341
Trained batch 550 in epoch 8, gen_loss = 0.9415380768139868, disc_loss = 0.008036075611993883
Trained batch 551 in epoch 8, gen_loss = 0.9414162006823049, disc_loss = 0.008021891703390504
Trained batch 552 in epoch 8, gen_loss = 0.9412250815744211, disc_loss = 0.008007856973168604
Trained batch 553 in epoch 8, gen_loss = 0.9410997417752063, disc_loss = 0.007993713958222093
Trained batch 554 in epoch 8, gen_loss = 0.9411101893798725, disc_loss = 0.007979787968734681
Trained batch 555 in epoch 8, gen_loss = 0.9410304705337654, disc_loss = 0.007965792590465813
Trained batch 556 in epoch 8, gen_loss = 0.940955008328282, disc_loss = 0.007951959408109062
Trained batch 557 in epoch 8, gen_loss = 0.9411307468102397, disc_loss = 0.007938276632316745
Trained batch 558 in epoch 8, gen_loss = 0.9411367960074294, disc_loss = 0.007924708050853957
Trained batch 559 in epoch 8, gen_loss = 0.9412649492600135, disc_loss = 0.007911514798927653
Trained batch 560 in epoch 8, gen_loss = 0.9413379852040779, disc_loss = 0.007898091576593378
Trained batch 561 in epoch 8, gen_loss = 0.9414113194174614, disc_loss = 0.007884461998511139
Trained batch 562 in epoch 8, gen_loss = 0.941616677528588, disc_loss = 0.00787096823334899
Trained batch 563 in epoch 8, gen_loss = 0.9416420464503005, disc_loss = 0.007857371729935671
Trained batch 564 in epoch 8, gen_loss = 0.9415761146397718, disc_loss = 0.007843711794909312
Trained batch 565 in epoch 8, gen_loss = 0.941444051086692, disc_loss = 0.007830113590397344
Trained batch 566 in epoch 8, gen_loss = 0.9412737947607798, disc_loss = 0.007816590510288827
Trained batch 567 in epoch 8, gen_loss = 0.9413574244039999, disc_loss = 0.007803700032370767
Trained batch 568 in epoch 8, gen_loss = 0.9414645337576606, disc_loss = 0.007790365339946722
Trained batch 569 in epoch 8, gen_loss = 0.9414208906261544, disc_loss = 0.007777086339008651
Trained batch 570 in epoch 8, gen_loss = 0.9415893663771308, disc_loss = 0.007763985864738175
Trained batch 571 in epoch 8, gen_loss = 0.9416637892177054, disc_loss = 0.007750762448496742
Trained batch 572 in epoch 8, gen_loss = 0.941782810769156, disc_loss = 0.0077375825006670415
Trained batch 573 in epoch 8, gen_loss = 0.9418075045745963, disc_loss = 0.007724513459606105
Trained batch 574 in epoch 8, gen_loss = 0.9417127698919048, disc_loss = 0.00771142129814151
Trained batch 575 in epoch 8, gen_loss = 0.9417040582435826, disc_loss = 0.007698373622158922
Trained batch 576 in epoch 8, gen_loss = 0.9416722253972157, disc_loss = 0.007685310536932177
Trained batch 577 in epoch 8, gen_loss = 0.9418530588434642, disc_loss = 0.007672359209451711
Trained batch 578 in epoch 8, gen_loss = 0.9418505535739279, disc_loss = 0.00765945233852202
Trained batch 579 in epoch 8, gen_loss = 0.9416023497437609, disc_loss = 0.007646559027288558
Trained batch 580 in epoch 8, gen_loss = 0.9415161898439804, disc_loss = 0.007633627415870127
Trained batch 581 in epoch 8, gen_loss = 0.9417123685485309, disc_loss = 0.007620903238381301
Trained batch 582 in epoch 8, gen_loss = 0.9416354251051031, disc_loss = 0.007608296639285183
Trained batch 583 in epoch 8, gen_loss = 0.9417142009183969, disc_loss = 0.0075955526736423
Trained batch 584 in epoch 8, gen_loss = 0.9416833073155493, disc_loss = 0.007583143649837719
Trained batch 585 in epoch 8, gen_loss = 0.9414000395723577, disc_loss = 0.007570843464407256
Trained batch 586 in epoch 8, gen_loss = 0.9413775892537944, disc_loss = 0.007558175380842671
Trained batch 587 in epoch 8, gen_loss = 0.9412993773007069, disc_loss = 0.0075456198459270575
Trained batch 588 in epoch 8, gen_loss = 0.9412677343207426, disc_loss = 0.007533050860633682
Trained batch 589 in epoch 8, gen_loss = 0.9411958418155121, disc_loss = 0.007520844643270613
Trained batch 590 in epoch 8, gen_loss = 0.9412410734772884, disc_loss = 0.007508464527559465
Trained batch 591 in epoch 8, gen_loss = 0.9411588326801319, disc_loss = 0.0074960914098483045
Trained batch 592 in epoch 8, gen_loss = 0.9409391105577073, disc_loss = 0.007483827311438225
Trained batch 593 in epoch 8, gen_loss = 0.9409887900557181, disc_loss = 0.007471483589599014
Trained batch 594 in epoch 8, gen_loss = 0.9408754620732379, disc_loss = 0.00745922809101332
Trained batch 595 in epoch 8, gen_loss = 0.9409999750904589, disc_loss = 0.007446972368384286
Trained batch 596 in epoch 8, gen_loss = 0.9410797519799653, disc_loss = 0.007434821924564415
Trained batch 597 in epoch 8, gen_loss = 0.9410415696958235, disc_loss = 0.007422640048127846
Trained batch 598 in epoch 8, gen_loss = 0.941351746328685, disc_loss = 0.007410663659318983
Trained batch 599 in epoch 8, gen_loss = 0.9414439337948958, disc_loss = 0.00739862332190872
Trained batch 600 in epoch 8, gen_loss = 0.9413423675566466, disc_loss = 0.0073866464613418495
Trained batch 601 in epoch 8, gen_loss = 0.941363855008271, disc_loss = 0.0073745841454549
Trained batch 602 in epoch 8, gen_loss = 0.9414826140771457, disc_loss = 0.00736274089796274
Trained batch 603 in epoch 8, gen_loss = 0.9414969476939037, disc_loss = 0.00735081641504326
Trained batch 604 in epoch 8, gen_loss = 0.9413959151949765, disc_loss = 0.007338974422612612
Trained batch 605 in epoch 8, gen_loss = 0.9415518879005225, disc_loss = 0.007327488980849816
Trained batch 606 in epoch 8, gen_loss = 0.9417439553352714, disc_loss = 0.0073159546028203955
Trained batch 607 in epoch 8, gen_loss = 0.9415386814722105, disc_loss = 0.007304393467285608
Trained batch 608 in epoch 8, gen_loss = 0.9415039636916519, disc_loss = 0.007292853102718988
Trained batch 609 in epoch 8, gen_loss = 0.9414001703750892, disc_loss = 0.007281246010336231
Trained batch 610 in epoch 8, gen_loss = 0.9412831182663257, disc_loss = 0.007269623818534462
Trained batch 611 in epoch 8, gen_loss = 0.941168083231044, disc_loss = 0.007258111294028935
Trained batch 612 in epoch 8, gen_loss = 0.9411721757049467, disc_loss = 0.007246607210805038
Trained batch 613 in epoch 8, gen_loss = 0.9408575935647231, disc_loss = 0.007235195879406957
Trained batch 614 in epoch 8, gen_loss = 0.9408602039503857, disc_loss = 0.0072240196821957495
Trained batch 615 in epoch 8, gen_loss = 0.9408278834413398, disc_loss = 0.0072127784320849524
Trained batch 616 in epoch 8, gen_loss = 0.940792852079849, disc_loss = 0.00720156299107296
Trained batch 617 in epoch 8, gen_loss = 0.9408423515295905, disc_loss = 0.007190207563708747
Trained batch 618 in epoch 8, gen_loss = 0.9407992358642941, disc_loss = 0.007180015034196892
Trained batch 619 in epoch 8, gen_loss = 0.9409220698860383, disc_loss = 0.007169533310685262
Trained batch 620 in epoch 8, gen_loss = 0.9408356233015537, disc_loss = 0.0071588127481381466
Trained batch 621 in epoch 8, gen_loss = 0.9409107132260822, disc_loss = 0.0071484545528663354
Trained batch 622 in epoch 8, gen_loss = 0.9409317361313497, disc_loss = 0.007137334265514093
Trained batch 623 in epoch 8, gen_loss = 0.9408046592217989, disc_loss = 0.007126169059423167
Trained batch 624 in epoch 8, gen_loss = 0.9407097595691681, disc_loss = 0.007115032222890295
Trained batch 625 in epoch 8, gen_loss = 0.9407301381849252, disc_loss = 0.007104475029615705
Trained batch 626 in epoch 8, gen_loss = 0.9406178549431158, disc_loss = 0.0070933841100275265
Trained batch 627 in epoch 8, gen_loss = 0.940528876984575, disc_loss = 0.007082354266898689
Trained batch 628 in epoch 8, gen_loss = 0.9404297628823448, disc_loss = 0.007071499562017554
Trained batch 629 in epoch 8, gen_loss = 0.9403054544376949, disc_loss = 0.007060700756523551
Trained batch 630 in epoch 8, gen_loss = 0.9401535967544973, disc_loss = 0.007049880133039228
Trained batch 631 in epoch 8, gen_loss = 0.9400929916602901, disc_loss = 0.0070390400863438625
Trained batch 632 in epoch 8, gen_loss = 0.9401609351943832, disc_loss = 0.0070283612833216
Trained batch 633 in epoch 8, gen_loss = 0.9401356011441078, disc_loss = 0.00701752954172481
Trained batch 634 in epoch 8, gen_loss = 0.9400146677268771, disc_loss = 0.007006785603662711
Trained batch 635 in epoch 8, gen_loss = 0.9399250992720232, disc_loss = 0.006996079871278885
Trained batch 636 in epoch 8, gen_loss = 0.9398606728815022, disc_loss = 0.006985348881582519
Trained batch 637 in epoch 8, gen_loss = 0.9396879377316532, disc_loss = 0.006974767780969311
Trained batch 638 in epoch 8, gen_loss = 0.9396837443719634, disc_loss = 0.006964086414936417
Trained batch 639 in epoch 8, gen_loss = 0.9396448269020766, disc_loss = 0.006953504187413273
Trained batch 640 in epoch 8, gen_loss = 0.9395859239160922, disc_loss = 0.0069429538356283365
Trained batch 641 in epoch 8, gen_loss = 0.9396148077516913, disc_loss = 0.006932467121279666
Trained batch 642 in epoch 8, gen_loss = 0.9395666117338148, disc_loss = 0.006921995765924081
Trained batch 643 in epoch 8, gen_loss = 0.9395223262239687, disc_loss = 0.006911696718534077
Trained batch 644 in epoch 8, gen_loss = 0.9394201480603033, disc_loss = 0.006901384732174297
Trained batch 645 in epoch 8, gen_loss = 0.939370723931413, disc_loss = 0.0068919845975349055
Trained batch 646 in epoch 8, gen_loss = 0.9393194612155926, disc_loss = 0.006881754588911711
Trained batch 647 in epoch 8, gen_loss = 0.939223267275978, disc_loss = 0.0068717788615259325
Trained batch 648 in epoch 8, gen_loss = 0.9392312242088406, disc_loss = 0.006861884832303815
Trained batch 649 in epoch 8, gen_loss = 0.9391962568118022, disc_loss = 0.006852515833877707
Trained batch 650 in epoch 8, gen_loss = 0.9393172183069766, disc_loss = 0.006842757022621135
Trained batch 651 in epoch 8, gen_loss = 0.9392801756782034, disc_loss = 0.006832917311393614
Trained batch 652 in epoch 8, gen_loss = 0.9393596798409729, disc_loss = 0.006823079944241494
Trained batch 653 in epoch 8, gen_loss = 0.9393501525534038, disc_loss = 0.006813054984110224
Trained batch 654 in epoch 8, gen_loss = 0.9393249851601725, disc_loss = 0.006803132575836196
Trained batch 655 in epoch 8, gen_loss = 0.9391539385315122, disc_loss = 0.00679346847979415
Trained batch 656 in epoch 8, gen_loss = 0.9391981487132642, disc_loss = 0.0067836179263024024
Trained batch 657 in epoch 8, gen_loss = 0.9393251955418601, disc_loss = 0.00677415108447346
Trained batch 658 in epoch 8, gen_loss = 0.9392755328704446, disc_loss = 0.006764344557636977
Trained batch 659 in epoch 8, gen_loss = 0.9391607182043972, disc_loss = 0.0067543953546688
Trained batch 660 in epoch 8, gen_loss = 0.9390931422970118, disc_loss = 0.006744656747723253
Trained batch 661 in epoch 8, gen_loss = 0.9391362225451139, disc_loss = 0.006734971129575503
Trained batch 662 in epoch 8, gen_loss = 0.938991143467919, disc_loss = 0.006726433298267673
Trained batch 663 in epoch 8, gen_loss = 0.9389375809535204, disc_loss = 0.006717260176508234
Trained batch 664 in epoch 8, gen_loss = 0.9389323025269616, disc_loss = 0.006707871663432281
Trained batch 665 in epoch 8, gen_loss = 0.9387899752225246, disc_loss = 0.0067582776626093416
Trained batch 666 in epoch 8, gen_loss = 0.9388195905817681, disc_loss = 0.006758464021534754
Trained batch 667 in epoch 8, gen_loss = 0.9389574587077438, disc_loss = 0.0067531450302470795
Trained batch 668 in epoch 8, gen_loss = 0.9392464362719668, disc_loss = 0.006745402915040428
Trained batch 669 in epoch 8, gen_loss = 0.9390465181710115, disc_loss = 0.006752640999477433
Trained batch 670 in epoch 8, gen_loss = 0.9391739059755948, disc_loss = 0.00675196982741036
Trained batch 671 in epoch 8, gen_loss = 0.9389725790935612, disc_loss = 0.00674748973703269
Trained batch 672 in epoch 8, gen_loss = 0.9382105589267227, disc_loss = 0.007257903210781923
Trained batch 673 in epoch 8, gen_loss = 0.9382627435713918, disc_loss = 0.007898374449734428
Trained batch 674 in epoch 8, gen_loss = 0.9379985622123436, disc_loss = 0.00831966297233184
Trained batch 675 in epoch 8, gen_loss = 0.9375997442289217, disc_loss = 0.008470998986185212
Trained batch 676 in epoch 8, gen_loss = 0.937740764114318, disc_loss = 0.008478294113083287
Trained batch 677 in epoch 8, gen_loss = 0.9375044442383589, disc_loss = 0.008543200160535211
Trained batch 678 in epoch 8, gen_loss = 0.9371681138763371, disc_loss = 0.008729655878694313
Trained batch 679 in epoch 8, gen_loss = 0.9376877417459207, disc_loss = 0.00874111341080981
Trained batch 680 in epoch 8, gen_loss = 0.938153278722637, disc_loss = 0.00876417301374945
Trained batch 681 in epoch 8, gen_loss = 0.9385893866638284, disc_loss = 0.008764146728989227
Trained batch 682 in epoch 8, gen_loss = 0.9385514517654262, disc_loss = 0.00878809705816975
Trained batch 683 in epoch 8, gen_loss = 0.938665358120935, disc_loss = 0.008788987757427561
Trained batch 684 in epoch 8, gen_loss = 0.9386321849196496, disc_loss = 0.008783381893346256
Trained batch 685 in epoch 8, gen_loss = 0.9385294196557026, disc_loss = 0.00877387916857873
Trained batch 686 in epoch 8, gen_loss = 0.9385495130325162, disc_loss = 0.008763272849532974
Trained batch 687 in epoch 8, gen_loss = 0.9384975284337997, disc_loss = 0.008752059910410365
Trained batch 688 in epoch 8, gen_loss = 0.9385087028124163, disc_loss = 0.008741341485804608
Trained batch 689 in epoch 8, gen_loss = 0.9387426464453987, disc_loss = 0.00873071129188748
Trained batch 690 in epoch 8, gen_loss = 0.9387253179563972, disc_loss = 0.008719063319302738
Trained batch 691 in epoch 8, gen_loss = 0.9387528480305148, disc_loss = 0.008708126756820709
Trained batch 692 in epoch 8, gen_loss = 0.9386754635436538, disc_loss = 0.008697425781944558
Trained batch 693 in epoch 8, gen_loss = 0.938676897232402, disc_loss = 0.008687497048835192
Trained batch 694 in epoch 8, gen_loss = 0.9385546819769222, disc_loss = 0.008702224468215194
Trained batch 695 in epoch 8, gen_loss = 0.9387786927922018, disc_loss = 0.008701847896264062
Trained batch 696 in epoch 8, gen_loss = 0.9389065360407234, disc_loss = 0.008714538461065563
Trained batch 697 in epoch 8, gen_loss = 0.9382104054306845, disc_loss = 0.009063328472865888
Trained batch 698 in epoch 8, gen_loss = 0.9385448735585711, disc_loss = 0.009636627057831547
Trained batch 699 in epoch 8, gen_loss = 0.938571728851114, disc_loss = 0.00978517046262693
Trained batch 700 in epoch 8, gen_loss = 0.9383442108114164, disc_loss = 0.009792284442811171
Trained batch 701 in epoch 8, gen_loss = 0.9376166929037143, disc_loss = 0.010064538229273286
Trained batch 702 in epoch 8, gen_loss = 0.937399662660162, disc_loss = 0.010095475716455932
Trained batch 703 in epoch 8, gen_loss = 0.9369822712615132, disc_loss = 0.010136836579456278
Trained batch 704 in epoch 8, gen_loss = 0.9367224437125186, disc_loss = 0.010203236632741796
Trained batch 705 in epoch 8, gen_loss = 0.9366834119764333, disc_loss = 0.010234504284464296
Trained batch 706 in epoch 8, gen_loss = 0.9365011697274118, disc_loss = 0.0102352619986338
Trained batch 707 in epoch 8, gen_loss = 0.9364132119269021, disc_loss = 0.010232226794833378
Trained batch 708 in epoch 8, gen_loss = 0.9365790652791603, disc_loss = 0.010220587879467108
Trained batch 709 in epoch 8, gen_loss = 0.9362196436230565, disc_loss = 0.01031854673758933
Trained batch 710 in epoch 8, gen_loss = 0.9361157984840887, disc_loss = 0.010402282933735173
Trained batch 711 in epoch 8, gen_loss = 0.9362169990546247, disc_loss = 0.01039039419328822
Trained batch 712 in epoch 8, gen_loss = 0.9357699901492532, disc_loss = 0.010449532825651782
Trained batch 713 in epoch 8, gen_loss = 0.935519033286418, disc_loss = 0.01047307124922847
Trained batch 714 in epoch 8, gen_loss = 0.9355142621727256, disc_loss = 0.010465432888436639
Trained batch 715 in epoch 8, gen_loss = 0.9354563808307967, disc_loss = 0.010453824354146247
Trained batch 716 in epoch 8, gen_loss = 0.9355789901821184, disc_loss = 0.010441399115244753
Trained batch 717 in epoch 8, gen_loss = 0.935568966739357, disc_loss = 0.010430653811532785
Trained batch 718 in epoch 8, gen_loss = 0.9354491498274664, disc_loss = 0.010421847096061941
Trained batch 719 in epoch 8, gen_loss = 0.9353267418841521, disc_loss = 0.010443269511011346
Trained batch 720 in epoch 8, gen_loss = 0.9353728310079746, disc_loss = 0.01046605140854228
Trained batch 721 in epoch 8, gen_loss = 0.9352169712989945, disc_loss = 0.010455133242304779
Trained batch 722 in epoch 8, gen_loss = 0.9351119323225272, disc_loss = 0.010453778718201924
Trained batch 723 in epoch 8, gen_loss = 0.9348882081923564, disc_loss = 0.010489507015994383
Trained batch 724 in epoch 8, gen_loss = 0.9350460454513286, disc_loss = 0.010503646624575626
Trained batch 725 in epoch 8, gen_loss = 0.9354210235691596, disc_loss = 0.010513430464955544
Trained batch 726 in epoch 8, gen_loss = 0.9355302275948872, disc_loss = 0.010503728084721439
Trained batch 727 in epoch 8, gen_loss = 0.9355711593896479, disc_loss = 0.010499312249241765
Trained batch 728 in epoch 8, gen_loss = 0.9356039927656595, disc_loss = 0.01049169544840793
Trained batch 729 in epoch 8, gen_loss = 0.9355482674624822, disc_loss = 0.010490318851315015
Trained batch 730 in epoch 8, gen_loss = 0.935378117372171, disc_loss = 0.010513966660206868
Trained batch 731 in epoch 8, gen_loss = 0.9355726909767734, disc_loss = 0.010812993486273665
Trained batch 732 in epoch 8, gen_loss = 0.9351681410697115, disc_loss = 0.010926606369090945
Trained batch 733 in epoch 8, gen_loss = 0.935114152587402, disc_loss = 0.010917004588140494
Trained batch 734 in epoch 8, gen_loss = 0.9350822330332127, disc_loss = 0.010952064556645413
Trained batch 735 in epoch 8, gen_loss = 0.9344592801416698, disc_loss = 0.01121241666084208
Trained batch 736 in epoch 8, gen_loss = 0.9347123450307704, disc_loss = 0.011284060907161421
Trained batch 737 in epoch 8, gen_loss = 0.934892896471954, disc_loss = 0.011286226178967894
Trained batch 738 in epoch 8, gen_loss = 0.9348476625908373, disc_loss = 0.011282760830902802
Trained batch 739 in epoch 8, gen_loss = 0.9348508638304633, disc_loss = 0.011282806846803224
Trained batch 740 in epoch 8, gen_loss = 0.9349836614611339, disc_loss = 0.011287247708805537
Trained batch 741 in epoch 8, gen_loss = 0.9349280371659529, disc_loss = 0.011325813728996404
Trained batch 742 in epoch 8, gen_loss = 0.9349976737919599, disc_loss = 0.011335154187602798
Trained batch 743 in epoch 8, gen_loss = 0.935256072590428, disc_loss = 0.011330237097158666
Trained batch 744 in epoch 8, gen_loss = 0.9351489865539858, disc_loss = 0.011328906256642237
Trained batch 745 in epoch 8, gen_loss = 0.9344129788492065, disc_loss = 0.011837981617084894
Trained batch 746 in epoch 8, gen_loss = 0.9347683343702211, disc_loss = 0.012075808687942693
Trained batch 747 in epoch 8, gen_loss = 0.9348748132666165, disc_loss = 0.012198264253173082
Trained batch 748 in epoch 8, gen_loss = 0.934277065645391, disc_loss = 0.012647113456428567
Trained batch 749 in epoch 8, gen_loss = 0.9337362532218297, disc_loss = 0.012974673455716887
Trained batch 750 in epoch 8, gen_loss = 0.9335709092382108, disc_loss = 0.013252532499768405
Trained batch 751 in epoch 8, gen_loss = 0.9332205445129187, disc_loss = 0.01352924340915977
Trained batch 752 in epoch 8, gen_loss = 0.9327879403612687, disc_loss = 0.013798052814378957
Trained batch 753 in epoch 8, gen_loss = 0.9324829294210404, disc_loss = 0.01402115197902819
Trained batch 754 in epoch 8, gen_loss = 0.9321282652434923, disc_loss = 0.014265726778840504
Trained batch 755 in epoch 8, gen_loss = 0.93180853305828, disc_loss = 0.014475680932798515
Trained batch 756 in epoch 8, gen_loss = 0.9313636374520815, disc_loss = 0.014690204003844699
Trained batch 757 in epoch 8, gen_loss = 0.9311292434509323, disc_loss = 0.01479840393211262
Trained batch 758 in epoch 8, gen_loss = 0.9312217173133444, disc_loss = 0.014858193686476612
Trained batch 759 in epoch 8, gen_loss = 0.9310526992537473, disc_loss = 0.01487315534198531
Trained batch 760 in epoch 8, gen_loss = 0.9305402992511077, disc_loss = 0.015102087313984092
Trained batch 761 in epoch 8, gen_loss = 0.93057211142356, disc_loss = 0.015703529196013262
Trained batch 762 in epoch 8, gen_loss = 0.9303644974062983, disc_loss = 0.01588838702559561
Trained batch 763 in epoch 8, gen_loss = 0.9300621755382154, disc_loss = 0.016071383083855254
Trained batch 764 in epoch 8, gen_loss = 0.9300732249917548, disc_loss = 0.016082659926934296
Trained batch 765 in epoch 8, gen_loss = 0.929892433024262, disc_loss = 0.016094187037014266
Trained batch 766 in epoch 8, gen_loss = 0.9298547869633198, disc_loss = 0.0161169934563812
Trained batch 767 in epoch 8, gen_loss = 0.9298035354586318, disc_loss = 0.016176340287358926
Trained batch 768 in epoch 8, gen_loss = 0.9295848699090384, disc_loss = 0.0161907839655544
Trained batch 769 in epoch 8, gen_loss = 0.9296799770810388, disc_loss = 0.016196363848197885
Trained batch 770 in epoch 8, gen_loss = 0.9298004602721075, disc_loss = 0.016201957575408363
Trained batch 771 in epoch 8, gen_loss = 0.9298892196827602, disc_loss = 0.01619200507213812
Trained batch 772 in epoch 8, gen_loss = 0.9301472343649007, disc_loss = 0.01618048722747238
Trained batch 773 in epoch 8, gen_loss = 0.9302786272548582, disc_loss = 0.01616827440605657
Trained batch 774 in epoch 8, gen_loss = 0.9305660959597557, disc_loss = 0.016152490307257752
Trained batch 775 in epoch 8, gen_loss = 0.9307030915215457, disc_loss = 0.016137212786844365
Trained batch 776 in epoch 8, gen_loss = 0.9307866187399418, disc_loss = 0.01612012001532301
Trained batch 777 in epoch 8, gen_loss = 0.9308994691675304, disc_loss = 0.01610237030280023
Trained batch 778 in epoch 8, gen_loss = 0.9310728607266491, disc_loss = 0.016085519945673823
Trained batch 779 in epoch 8, gen_loss = 0.9311903865291522, disc_loss = 0.016068326198411597
Trained batch 780 in epoch 8, gen_loss = 0.931195669725213, disc_loss = 0.016050863031561908
Trained batch 781 in epoch 8, gen_loss = 0.9311406416127749, disc_loss = 0.016032489609279787
Trained batch 782 in epoch 8, gen_loss = 0.9311466567589406, disc_loss = 0.016013717741953325
Trained batch 783 in epoch 8, gen_loss = 0.9311343340621311, disc_loss = 0.015994855634670208
Trained batch 784 in epoch 8, gen_loss = 0.9311615077932929, disc_loss = 0.015976723843045788
Trained batch 785 in epoch 8, gen_loss = 0.9311441064411751, disc_loss = 0.01595797276705472
Trained batch 786 in epoch 8, gen_loss = 0.9310845093093955, disc_loss = 0.01593913399734433
Trained batch 787 in epoch 8, gen_loss = 0.9312087927146007, disc_loss = 0.015920905639200445
Trained batch 788 in epoch 8, gen_loss = 0.931255185596541, disc_loss = 0.01590223721679963
Trained batch 789 in epoch 8, gen_loss = 0.9313156445946874, disc_loss = 0.015884417194937196
Trained batch 790 in epoch 8, gen_loss = 0.9312783093503694, disc_loss = 0.015867071139976333
Trained batch 791 in epoch 8, gen_loss = 0.9312096393544866, disc_loss = 0.015848643864919354
Trained batch 792 in epoch 8, gen_loss = 0.9312009365306075, disc_loss = 0.015830408400646177
Trained batch 793 in epoch 8, gen_loss = 0.931141631766891, disc_loss = 0.015813393080799862
Trained batch 794 in epoch 8, gen_loss = 0.9312717956941833, disc_loss = 0.015794766220573846
Trained batch 795 in epoch 8, gen_loss = 0.9312009481554056, disc_loss = 0.01577578912427033
Trained batch 796 in epoch 8, gen_loss = 0.9310573042934781, disc_loss = 0.01575732215187805
Trained batch 797 in epoch 8, gen_loss = 0.9310629312929354, disc_loss = 0.015739708635115028
Trained batch 798 in epoch 8, gen_loss = 0.9308869247517091, disc_loss = 0.015722968320819625
Trained batch 799 in epoch 8, gen_loss = 0.9308472594246269, disc_loss = 0.01570489789095518
Trained batch 800 in epoch 8, gen_loss = 0.9309691991029161, disc_loss = 0.015687156645487383
Trained batch 801 in epoch 8, gen_loss = 0.9309075596252284, disc_loss = 0.015670118739774325
Trained batch 802 in epoch 8, gen_loss = 0.9309150209536736, disc_loss = 0.015651870091082
Trained batch 803 in epoch 8, gen_loss = 0.9309466954561608, disc_loss = 0.015633459219650977
Trained batch 804 in epoch 8, gen_loss = 0.9309413427521723, disc_loss = 0.015615016000214473
Trained batch 805 in epoch 8, gen_loss = 0.9309197789608101, disc_loss = 0.015597110746971305
Trained batch 806 in epoch 8, gen_loss = 0.9309225324287438, disc_loss = 0.015579076972497942
Trained batch 807 in epoch 8, gen_loss = 0.9310433102937619, disc_loss = 0.015562178367989612
Trained batch 808 in epoch 8, gen_loss = 0.931056117134719, disc_loss = 0.015544182793532984
Trained batch 809 in epoch 8, gen_loss = 0.9310795653381465, disc_loss = 0.01552635842988506
Trained batch 810 in epoch 8, gen_loss = 0.9310918465422056, disc_loss = 0.01550847654360873
Trained batch 811 in epoch 8, gen_loss = 0.9310749760035224, disc_loss = 0.015490494349972418
Trained batch 812 in epoch 8, gen_loss = 0.9310838514515102, disc_loss = 0.015472394817744022
Trained batch 813 in epoch 8, gen_loss = 0.9309360861265689, disc_loss = 0.0154545794463199
Trained batch 814 in epoch 8, gen_loss = 0.9308326578944739, disc_loss = 0.015436947413422367
Trained batch 815 in epoch 8, gen_loss = 0.9308902419300056, disc_loss = 0.015419157671792217
Trained batch 816 in epoch 8, gen_loss = 0.930859774788853, disc_loss = 0.015401263007744685
Trained batch 817 in epoch 8, gen_loss = 0.9309052148410335, disc_loss = 0.015383274928511667
Trained batch 818 in epoch 8, gen_loss = 0.9308343256422306, disc_loss = 0.015365340851396703
Trained batch 819 in epoch 8, gen_loss = 0.9308305820677338, disc_loss = 0.015347677752394769
Trained batch 820 in epoch 8, gen_loss = 0.9306874838946944, disc_loss = 0.015329896625871975
Trained batch 821 in epoch 8, gen_loss = 0.9307308023355884, disc_loss = 0.015312230901974916
Trained batch 822 in epoch 8, gen_loss = 0.9306946838973938, disc_loss = 0.015294460758035986
Trained batch 823 in epoch 8, gen_loss = 0.9307664894290919, disc_loss = 0.015276827355795195
Trained batch 824 in epoch 8, gen_loss = 0.930839777173418, disc_loss = 0.015259712378787243
Trained batch 825 in epoch 8, gen_loss = 0.9309708418698923, disc_loss = 0.01524205513879672
Trained batch 826 in epoch 8, gen_loss = 0.9310348927974701, disc_loss = 0.015224402856039916
Trained batch 827 in epoch 8, gen_loss = 0.9310117886910116, disc_loss = 0.015206812490404169
Trained batch 828 in epoch 8, gen_loss = 0.9309584047236402, disc_loss = 0.015189344342204683
Trained batch 829 in epoch 8, gen_loss = 0.9309155242629799, disc_loss = 0.015171758756262435
Trained batch 830 in epoch 8, gen_loss = 0.9309149039135943, disc_loss = 0.015154385377669614
Trained batch 831 in epoch 8, gen_loss = 0.9309803042202615, disc_loss = 0.015137203240538629
Trained batch 832 in epoch 8, gen_loss = 0.9309863911456421, disc_loss = 0.015119690445792193
Trained batch 833 in epoch 8, gen_loss = 0.9310367545849986, disc_loss = 0.015102467517523017
Trained batch 834 in epoch 8, gen_loss = 0.9310432009711237, disc_loss = 0.015085802427029466
Trained batch 835 in epoch 8, gen_loss = 0.9310760910502461, disc_loss = 0.015068571573539283
Trained batch 836 in epoch 8, gen_loss = 0.9310913405324396, disc_loss = 0.015051427785609126
Trained batch 837 in epoch 8, gen_loss = 0.931098215797636, disc_loss = 0.015034017010742931
Trained batch 838 in epoch 8, gen_loss = 0.9310638649884225, disc_loss = 0.015016652542094675
Trained batch 839 in epoch 8, gen_loss = 0.9310177721792743, disc_loss = 0.014999544007653076
Trained batch 840 in epoch 8, gen_loss = 0.931032543835827, disc_loss = 0.014982800465059858
Trained batch 841 in epoch 8, gen_loss = 0.9310900348453227, disc_loss = 0.014965920359395514
Trained batch 842 in epoch 8, gen_loss = 0.9310510663728838, disc_loss = 0.01494905307170814
Trained batch 843 in epoch 8, gen_loss = 0.9309528932257851, disc_loss = 0.014931844967206795
Trained batch 844 in epoch 8, gen_loss = 0.9310721568454652, disc_loss = 0.014915729466272579
Trained batch 845 in epoch 8, gen_loss = 0.9311350633700689, disc_loss = 0.014898903468276575
Trained batch 846 in epoch 8, gen_loss = 0.9310050514892817, disc_loss = 0.014882524971594707
Trained batch 847 in epoch 8, gen_loss = 0.9311119855363976, disc_loss = 0.014865847063618893
Trained batch 848 in epoch 8, gen_loss = 0.9309890731835674, disc_loss = 0.014849043954019127
Trained batch 849 in epoch 8, gen_loss = 0.9308584154002807, disc_loss = 0.014832415159822523
Trained batch 850 in epoch 8, gen_loss = 0.930891333084409, disc_loss = 0.014815991591544111
Trained batch 851 in epoch 8, gen_loss = 0.9308850597677656, disc_loss = 0.014799227459431203
Trained batch 852 in epoch 8, gen_loss = 0.9307838334917043, disc_loss = 0.014782546932639412
Trained batch 853 in epoch 8, gen_loss = 0.9307045398118624, disc_loss = 0.014766000351186028
Trained batch 854 in epoch 8, gen_loss = 0.9306719942051068, disc_loss = 0.014749675900801304
Trained batch 855 in epoch 8, gen_loss = 0.9306235614572173, disc_loss = 0.01473293873225026
Trained batch 856 in epoch 8, gen_loss = 0.9305917013832123, disc_loss = 0.014716639054090555
Trained batch 857 in epoch 8, gen_loss = 0.9305023237333431, disc_loss = 0.014700064105503419
Trained batch 858 in epoch 8, gen_loss = 0.9305959115969288, disc_loss = 0.014685144907501753
Trained batch 859 in epoch 8, gen_loss = 0.9305015420844388, disc_loss = 0.014668634707574478
Trained batch 860 in epoch 8, gen_loss = 0.9305302489994571, disc_loss = 0.014652244963375046
Trained batch 861 in epoch 8, gen_loss = 0.9304958255205243, disc_loss = 0.014636631263585425
Trained batch 862 in epoch 8, gen_loss = 0.9304336152996691, disc_loss = 0.014620614230411147
Trained batch 863 in epoch 8, gen_loss = 0.9303963143999378, disc_loss = 0.014605559894014866
Trained batch 864 in epoch 8, gen_loss = 0.930430835278737, disc_loss = 0.014589295190213264
Trained batch 865 in epoch 8, gen_loss = 0.9303635988926502, disc_loss = 0.014573183439473173
Trained batch 866 in epoch 8, gen_loss = 0.9303821511265866, disc_loss = 0.014557235281098223
Trained batch 867 in epoch 8, gen_loss = 0.9303743944670747, disc_loss = 0.014541295615244417
Trained batch 868 in epoch 8, gen_loss = 0.9303940771569865, disc_loss = 0.014525187743969837
Trained batch 869 in epoch 8, gen_loss = 0.9303747711167938, disc_loss = 0.014508936057371039
Trained batch 870 in epoch 8, gen_loss = 0.9303877773501159, disc_loss = 0.01449277152081919
Trained batch 871 in epoch 8, gen_loss = 0.930501387582733, disc_loss = 0.014476623674963442
Trained batch 872 in epoch 8, gen_loss = 0.9305598509475538, disc_loss = 0.01446049238233691
Trained batch 873 in epoch 8, gen_loss = 0.9305253374290139, disc_loss = 0.014444822618586371
Trained batch 874 in epoch 8, gen_loss = 0.9305494398730142, disc_loss = 0.01442893032801138
Trained batch 875 in epoch 8, gen_loss = 0.9305203208980495, disc_loss = 0.014412888058151739
Trained batch 876 in epoch 8, gen_loss = 0.9305401003686977, disc_loss = 0.014396934546558786
Trained batch 877 in epoch 8, gen_loss = 0.9305303326568191, disc_loss = 0.014380926313167114
Trained batch 878 in epoch 8, gen_loss = 0.9304413493379391, disc_loss = 0.0143649684065701
Trained batch 879 in epoch 8, gen_loss = 0.930513611537489, disc_loss = 0.0143490742017093
Trained batch 880 in epoch 8, gen_loss = 0.930487282734859, disc_loss = 0.014333198579146778
Trained batch 881 in epoch 8, gen_loss = 0.9306042988081368, disc_loss = 0.014317374032568487
Trained batch 882 in epoch 8, gen_loss = 0.9305505580094771, disc_loss = 0.014301544765420105
Trained batch 883 in epoch 8, gen_loss = 0.9305526775000322, disc_loss = 0.014285710499786147
Trained batch 884 in epoch 8, gen_loss = 0.9306123939947893, disc_loss = 0.014269993901907172
Trained batch 885 in epoch 8, gen_loss = 0.9306649671653054, disc_loss = 0.014254319913493881
Trained batch 886 in epoch 8, gen_loss = 0.930724361199537, disc_loss = 0.014238662619893533
Trained batch 887 in epoch 8, gen_loss = 0.9307669731075162, disc_loss = 0.014223200300982277
Trained batch 888 in epoch 8, gen_loss = 0.9308175283355306, disc_loss = 0.014207652349646896
Trained batch 889 in epoch 8, gen_loss = 0.9309205391768659, disc_loss = 0.014192753163342274
Trained batch 890 in epoch 8, gen_loss = 0.9308476001525969, disc_loss = 0.014177490675597301
Trained batch 891 in epoch 8, gen_loss = 0.930758944908867, disc_loss = 0.014162279083540338
Trained batch 892 in epoch 8, gen_loss = 0.9305982012697991, disc_loss = 0.01414691663100079
Trained batch 893 in epoch 8, gen_loss = 0.9305556500184723, disc_loss = 0.014131566698111983
Trained batch 894 in epoch 8, gen_loss = 0.9305534895238929, disc_loss = 0.014116260282517744
Trained batch 895 in epoch 8, gen_loss = 0.9306724857472416, disc_loss = 0.014103950530998841
Trained batch 896 in epoch 8, gen_loss = 0.9306284421463077, disc_loss = 0.014089024527456664
Trained batch 897 in epoch 8, gen_loss = 0.9307065410643218, disc_loss = 0.014073873814216785
Trained batch 898 in epoch 8, gen_loss = 0.9307644813755596, disc_loss = 0.014059115663286452
Trained batch 899 in epoch 8, gen_loss = 0.9308628785279062, disc_loss = 0.014043969244182032
Trained batch 900 in epoch 8, gen_loss = 0.9309349742435853, disc_loss = 0.014028882526465822
Trained batch 901 in epoch 8, gen_loss = 0.9307782900108731, disc_loss = 0.014013764879165115
Trained batch 902 in epoch 8, gen_loss = 0.9307889081248941, disc_loss = 0.013998649330847228
Trained batch 903 in epoch 8, gen_loss = 0.9306531490807513, disc_loss = 0.013983481233199441
Trained batch 904 in epoch 8, gen_loss = 0.9306223353298988, disc_loss = 0.01396832556638401
Trained batch 905 in epoch 8, gen_loss = 0.9306001855640222, disc_loss = 0.013953462397320803
Trained batch 906 in epoch 8, gen_loss = 0.9306261978772404, disc_loss = 0.013938513104638927
Trained batch 907 in epoch 8, gen_loss = 0.9304639642262249, disc_loss = 0.013923665020257282
Trained batch 908 in epoch 8, gen_loss = 0.9303379523413147, disc_loss = 0.013908760510194853
Trained batch 909 in epoch 8, gen_loss = 0.9303111633429161, disc_loss = 0.013893831544699644
Trained batch 910 in epoch 8, gen_loss = 0.9303127968546849, disc_loss = 0.013879118808003988
Trained batch 911 in epoch 8, gen_loss = 0.9303783558374434, disc_loss = 0.01386443632447098
Trained batch 912 in epoch 8, gen_loss = 0.9303789359128749, disc_loss = 0.013849570379303162
Trained batch 913 in epoch 8, gen_loss = 0.9302022962849302, disc_loss = 0.013834833472844746
Trained batch 914 in epoch 8, gen_loss = 0.9302110929632448, disc_loss = 0.013820079425868293
Trained batch 915 in epoch 8, gen_loss = 0.9301753330113586, disc_loss = 0.013805652164274448
Trained batch 916 in epoch 8, gen_loss = 0.9301300551600129, disc_loss = 0.013791285081336304
Trained batch 917 in epoch 8, gen_loss = 0.9302240703295519, disc_loss = 0.013776714640183447
Trained batch 918 in epoch 8, gen_loss = 0.930323050998889, disc_loss = 0.013762111080141198
Trained batch 919 in epoch 8, gen_loss = 0.9302709925757802, disc_loss = 0.013747597849720952
Trained batch 920 in epoch 8, gen_loss = 0.9300275671818616, disc_loss = 0.013733697192540294
Trained batch 921 in epoch 8, gen_loss = 0.9300209733449456, disc_loss = 0.013719540533770423
Trained batch 922 in epoch 8, gen_loss = 0.9299170008395372, disc_loss = 0.013705192497361452
Trained batch 923 in epoch 8, gen_loss = 0.9298029621635681, disc_loss = 0.013690895238177255
Trained batch 924 in epoch 8, gen_loss = 0.9298814992324727, disc_loss = 0.01367650175295657
Trained batch 925 in epoch 8, gen_loss = 0.9296437972758296, disc_loss = 0.013665752803760839
Trained batch 926 in epoch 8, gen_loss = 0.9295926358643216, disc_loss = 0.013651476528212612
Trained batch 927 in epoch 8, gen_loss = 0.9296275373098666, disc_loss = 0.013637886436440724
Trained batch 928 in epoch 8, gen_loss = 0.9296750886640456, disc_loss = 0.013623593087447582
Trained batch 929 in epoch 8, gen_loss = 0.9296048961980369, disc_loss = 0.013609393872430183
Trained batch 930 in epoch 8, gen_loss = 0.9296239540541082, disc_loss = 0.013595059441192357
Trained batch 931 in epoch 8, gen_loss = 0.929542107099883, disc_loss = 0.013580768026715437
Trained batch 932 in epoch 8, gen_loss = 0.929531823751883, disc_loss = 0.01356648621508402
Trained batch 933 in epoch 8, gen_loss = 0.929592918564727, disc_loss = 0.013552278741416785
Trained batch 934 in epoch 8, gen_loss = 0.929613282623138, disc_loss = 0.01353830467698844
Trained batch 935 in epoch 8, gen_loss = 0.9296709410209432, disc_loss = 0.013524211709961344
Trained batch 936 in epoch 8, gen_loss = 0.9297201862775402, disc_loss = 0.01351002988109145
Trained batch 937 in epoch 8, gen_loss = 0.9296452291548125, disc_loss = 0.013495927979837162
Trained batch 938 in epoch 8, gen_loss = 0.9296995329336364, disc_loss = 0.013481874424052083
Trained batch 939 in epoch 8, gen_loss = 0.9297432836382947, disc_loss = 0.013467803122082532
Trained batch 940 in epoch 8, gen_loss = 0.9296973148453882, disc_loss = 0.0134538103867077
Trained batch 941 in epoch 8, gen_loss = 0.9295745615683291, disc_loss = 0.013439982310871148
Trained batch 942 in epoch 8, gen_loss = 0.9295619541299178, disc_loss = 0.013426081408366432
Trained batch 943 in epoch 8, gen_loss = 0.9295645844570156, disc_loss = 0.013412195077808836
Trained batch 944 in epoch 8, gen_loss = 0.9294208247510214, disc_loss = 0.013398270606923795
Trained batch 945 in epoch 8, gen_loss = 0.9293865462879298, disc_loss = 0.01338447094598062
Trained batch 946 in epoch 8, gen_loss = 0.92941571254413, disc_loss = 0.013370879257459625
Trained batch 947 in epoch 8, gen_loss = 0.9294577879430372, disc_loss = 0.013357140073603198
Trained batch 948 in epoch 8, gen_loss = 0.9294710425292981, disc_loss = 0.013343366040210672
Trained batch 949 in epoch 8, gen_loss = 0.9293733215018323, disc_loss = 0.013329574263326848
Trained batch 950 in epoch 8, gen_loss = 0.9293483282301328, disc_loss = 0.013315886104179886
Trained batch 951 in epoch 8, gen_loss = 0.9294715338081372, disc_loss = 0.013302293121471718
Trained batch 952 in epoch 8, gen_loss = 0.9294505101498627, disc_loss = 0.013288610008160303
Trained batch 953 in epoch 8, gen_loss = 0.9293403987552135, disc_loss = 0.01327505374967159
Trained batch 954 in epoch 8, gen_loss = 0.9292469516162473, disc_loss = 0.013261533548420964
Trained batch 955 in epoch 8, gen_loss = 0.9293434453746265, disc_loss = 0.01324805136928985
Trained batch 956 in epoch 8, gen_loss = 0.929358804456368, disc_loss = 0.01323450927286204
Trained batch 957 in epoch 8, gen_loss = 0.9293332167420855, disc_loss = 0.013221148333767072
Trained batch 958 in epoch 8, gen_loss = 0.9291705527382673, disc_loss = 0.01320764381924731
Trained batch 959 in epoch 8, gen_loss = 0.9291715788654983, disc_loss = 0.013194261783170683
Trained batch 960 in epoch 8, gen_loss = 0.9292155068511149, disc_loss = 0.013181011554087671
Trained batch 961 in epoch 8, gen_loss = 0.9291502377657286, disc_loss = 0.013167632259827242
Trained batch 962 in epoch 8, gen_loss = 0.9291057664966781, disc_loss = 0.01315421514328352
Trained batch 963 in epoch 8, gen_loss = 0.9291165659350973, disc_loss = 0.013140821055122346
Trained batch 964 in epoch 8, gen_loss = 0.9291192607867286, disc_loss = 0.013127408269626918
Trained batch 965 in epoch 8, gen_loss = 0.9290055666836152, disc_loss = 0.013114064057474145
Trained batch 966 in epoch 8, gen_loss = 0.9290723890343521, disc_loss = 0.013100860944642462
Trained batch 967 in epoch 8, gen_loss = 0.9290394785790896, disc_loss = 0.013087501025062717
Trained batch 968 in epoch 8, gen_loss = 0.9290476874116773, disc_loss = 0.013074342048981311
Trained batch 969 in epoch 8, gen_loss = 0.9290485022301527, disc_loss = 0.013061170350323965
Trained batch 970 in epoch 8, gen_loss = 0.9289333654910971, disc_loss = 0.013047971763990624
Trained batch 971 in epoch 8, gen_loss = 0.9289703298927334, disc_loss = 0.013034997209899991
Trained batch 972 in epoch 8, gen_loss = 0.9288889494670013, disc_loss = 0.013021787129743249
Trained batch 973 in epoch 8, gen_loss = 0.9289485016948633, disc_loss = 0.013008718029431567
Trained batch 974 in epoch 8, gen_loss = 0.9289299438855587, disc_loss = 0.012995579387852325
Trained batch 975 in epoch 8, gen_loss = 0.9289402513780066, disc_loss = 0.012982514692742027
Trained batch 976 in epoch 8, gen_loss = 0.9289376033182154, disc_loss = 0.012969587645255732
Trained batch 977 in epoch 8, gen_loss = 0.9289422752849895, disc_loss = 0.012956514074176084
Trained batch 978 in epoch 8, gen_loss = 0.9289146429489046, disc_loss = 0.01294358023308254
Trained batch 979 in epoch 8, gen_loss = 0.9289449838047125, disc_loss = 0.012930745386939653
Trained batch 980 in epoch 8, gen_loss = 0.928815071219455, disc_loss = 0.012917940441197307
Trained batch 981 in epoch 8, gen_loss = 0.92889032268597, disc_loss = 0.012905091349335549
Trained batch 982 in epoch 8, gen_loss = 0.9288872632284252, disc_loss = 0.012892310730552197
Trained batch 983 in epoch 8, gen_loss = 0.9288506797113554, disc_loss = 0.012879455503727839
Trained batch 984 in epoch 8, gen_loss = 0.9289856682876645, disc_loss = 0.01286695365719249
Trained batch 985 in epoch 8, gen_loss = 0.9288247662613406, disc_loss = 0.012854265627295037
Trained batch 986 in epoch 8, gen_loss = 0.9288474351258263, disc_loss = 0.01284159268800718
Trained batch 987 in epoch 8, gen_loss = 0.9288228759579813, disc_loss = 0.01282891688198485
Trained batch 988 in epoch 8, gen_loss = 0.928813473972199, disc_loss = 0.012816208359424361
Trained batch 989 in epoch 8, gen_loss = 0.9287677056560613, disc_loss = 0.012803501297391696
Trained batch 990 in epoch 8, gen_loss = 0.9287205149920509, disc_loss = 0.012790903932487547
Trained batch 991 in epoch 8, gen_loss = 0.9286171538274615, disc_loss = 0.0127783225431314
Trained batch 992 in epoch 8, gen_loss = 0.9286450836413577, disc_loss = 0.012765734182411151
Trained batch 993 in epoch 8, gen_loss = 0.9286245665619791, disc_loss = 0.012753053865549145
Trained batch 994 in epoch 8, gen_loss = 0.9286803356666661, disc_loss = 0.012740459993695746
Trained batch 995 in epoch 8, gen_loss = 0.9287561305974382, disc_loss = 0.012728034424539198
Trained batch 996 in epoch 8, gen_loss = 0.9287016298790035, disc_loss = 0.012715513863708915
Trained batch 997 in epoch 8, gen_loss = 0.928571905574961, disc_loss = 0.012703029249649203
Trained batch 998 in epoch 8, gen_loss = 0.9286619991929204, disc_loss = 0.012690541137453146
Trained batch 999 in epoch 8, gen_loss = 0.9286462788283825, disc_loss = 0.012678087080668775
Trained batch 1000 in epoch 8, gen_loss = 0.928650777269672, disc_loss = 0.012665673577492209
Trained batch 1001 in epoch 8, gen_loss = 0.9287174808348486, disc_loss = 0.012653324689014703
Trained batch 1002 in epoch 8, gen_loss = 0.9285984119235102, disc_loss = 0.012640919413190434
Trained batch 1003 in epoch 8, gen_loss = 0.9285457476498596, disc_loss = 0.012628498943197328
Trained batch 1004 in epoch 8, gen_loss = 0.9286449949836256, disc_loss = 0.012616731206042604
Trained batch 1005 in epoch 8, gen_loss = 0.9286346988637689, disc_loss = 0.012604509561085286
Trained batch 1006 in epoch 8, gen_loss = 0.9285155208309689, disc_loss = 0.012592302105706181
Trained batch 1007 in epoch 8, gen_loss = 0.9284434634009524, disc_loss = 0.012580072648320527
Trained batch 1008 in epoch 8, gen_loss = 0.9285089021808919, disc_loss = 0.012567929010974992
Trained batch 1009 in epoch 8, gen_loss = 0.9285508271196101, disc_loss = 0.01255576716239465
Trained batch 1010 in epoch 8, gen_loss = 0.9285070846330754, disc_loss = 0.01254375730895377
Trained batch 1011 in epoch 8, gen_loss = 0.9283623393521949, disc_loss = 0.012531610015573706
Trained batch 1012 in epoch 8, gen_loss = 0.9284140158440966, disc_loss = 0.012519477084607735
Trained batch 1013 in epoch 8, gen_loss = 0.9283523059631946, disc_loss = 0.012507361700414832
Trained batch 1014 in epoch 8, gen_loss = 0.9282898956038095, disc_loss = 0.012495255783966427
Trained batch 1015 in epoch 8, gen_loss = 0.9281977817826853, disc_loss = 0.012483132076777396
Trained batch 1016 in epoch 8, gen_loss = 0.9281052166088727, disc_loss = 0.012471006128988747
Trained batch 1017 in epoch 8, gen_loss = 0.928120182486789, disc_loss = 0.012458994357007527
Trained batch 1018 in epoch 8, gen_loss = 0.928055571766901, disc_loss = 0.01244693196995741
Trained batch 1019 in epoch 8, gen_loss = 0.9279909974511932, disc_loss = 0.012434879890226475
Trained batch 1020 in epoch 8, gen_loss = 0.9280427325659237, disc_loss = 0.012423070329297325
Trained batch 1021 in epoch 8, gen_loss = 0.9280865065563915, disc_loss = 0.012411230631689122
Trained batch 1022 in epoch 8, gen_loss = 0.9281369087924473, disc_loss = 0.012399421010366918
Trained batch 1023 in epoch 8, gen_loss = 0.9280787890020292, disc_loss = 0.01238751782850045
Trained batch 1024 in epoch 8, gen_loss = 0.9281180257041279, disc_loss = 0.012375662711977096
Trained batch 1025 in epoch 8, gen_loss = 0.9280176538879643, disc_loss = 0.012363847428879457
Trained batch 1026 in epoch 8, gen_loss = 0.9279317263560959, disc_loss = 0.012352033017198451
Trained batch 1027 in epoch 8, gen_loss = 0.9277783474279748, disc_loss = 0.012340224517521458
Trained batch 1028 in epoch 8, gen_loss = 0.9279108147984922, disc_loss = 0.01232859966393157
Trained batch 1029 in epoch 8, gen_loss = 0.9278374354526835, disc_loss = 0.012316837452831837
Trained batch 1030 in epoch 8, gen_loss = 0.9278041823585559, disc_loss = 0.01230523065836013
Trained batch 1031 in epoch 8, gen_loss = 0.9278389439275561, disc_loss = 0.012293673526101891
Trained batch 1032 in epoch 8, gen_loss = 0.9276327523984382, disc_loss = 0.012282177835187535
Trained batch 1033 in epoch 8, gen_loss = 0.9275311053202738, disc_loss = 0.012270519128817424
Trained batch 1034 in epoch 8, gen_loss = 0.927464700465041, disc_loss = 0.012258994189225438
Trained batch 1035 in epoch 8, gen_loss = 0.927479524208542, disc_loss = 0.012247438067065226
Trained batch 1036 in epoch 8, gen_loss = 0.9274753297938675, disc_loss = 0.012235879004679116
Trained batch 1037 in epoch 8, gen_loss = 0.9275616126310848, disc_loss = 0.012224502065195994
Trained batch 1038 in epoch 8, gen_loss = 0.9274678175499854, disc_loss = 0.012212971471306865
Trained batch 1039 in epoch 8, gen_loss = 0.9274468807360301, disc_loss = 0.012201532056203107
Trained batch 1040 in epoch 8, gen_loss = 0.9274508581209595, disc_loss = 0.012189959727096175
Trained batch 1041 in epoch 8, gen_loss = 0.9274013160000378, disc_loss = 0.01217843440592364
Trained batch 1042 in epoch 8, gen_loss = 0.9273837373617855, disc_loss = 0.012167061211060008
Trained batch 1043 in epoch 8, gen_loss = 0.9274295140557363, disc_loss = 0.012155684428786862
Trained batch 1044 in epoch 8, gen_loss = 0.9273961552877745, disc_loss = 0.012144264616626405
Trained batch 1045 in epoch 8, gen_loss = 0.927295321744669, disc_loss = 0.012132846984332165
Trained batch 1046 in epoch 8, gen_loss = 0.9272039990655103, disc_loss = 0.012121469427226268
Trained batch 1047 in epoch 8, gen_loss = 0.9270440194158609, disc_loss = 0.012110164634300105
Trained batch 1048 in epoch 8, gen_loss = 0.927013470202656, disc_loss = 0.012099032868486136
Trained batch 1049 in epoch 8, gen_loss = 0.926973077030409, disc_loss = 0.012087724258668633
Trained batch 1050 in epoch 8, gen_loss = 0.9270500043649882, disc_loss = 0.012076478460988608
Trained batch 1051 in epoch 8, gen_loss = 0.926949754782276, disc_loss = 0.012068167336110491
Trained batch 1052 in epoch 8, gen_loss = 0.9269601391081796, disc_loss = 0.012057392444904471
Trained batch 1053 in epoch 8, gen_loss = 0.9269059866214386, disc_loss = 0.012046505134130574
Trained batch 1054 in epoch 8, gen_loss = 0.9268540674758748, disc_loss = 0.012035717689228063
Trained batch 1055 in epoch 8, gen_loss = 0.9268709851541754, disc_loss = 0.012025060632395529
Trained batch 1056 in epoch 8, gen_loss = 0.9268807211402688, disc_loss = 0.012014206488866336
Trained batch 1057 in epoch 8, gen_loss = 0.9268099326774168, disc_loss = 0.012003128431058076
Trained batch 1058 in epoch 8, gen_loss = 0.9268196812488765, disc_loss = 0.011992094146629278
Trained batch 1059 in epoch 8, gen_loss = 0.9269393234039253, disc_loss = 0.011981085577006627
Trained batch 1060 in epoch 8, gen_loss = 0.926889954902, disc_loss = 0.01197008535489317
Trained batch 1061 in epoch 8, gen_loss = 0.9268127783375272, disc_loss = 0.011959109092453537
Trained batch 1062 in epoch 8, gen_loss = 0.9267343244850916, disc_loss = 0.011948058782477214
Trained batch 1063 in epoch 8, gen_loss = 0.9266485210816214, disc_loss = 0.011937117107321737
Trained batch 1064 in epoch 8, gen_loss = 0.9267330603700289, disc_loss = 0.011926134460823754
Trained batch 1065 in epoch 8, gen_loss = 0.9267574264956236, disc_loss = 0.011915107939379114
Trained batch 1066 in epoch 8, gen_loss = 0.9267202753996112, disc_loss = 0.011904266972004545
Trained batch 1067 in epoch 8, gen_loss = 0.9266869847415092, disc_loss = 0.011893348299135948
Trained batch 1068 in epoch 8, gen_loss = 0.9265750278313657, disc_loss = 0.011882355766802903
Trained batch 1069 in epoch 8, gen_loss = 0.9264933922301943, disc_loss = 0.011871388536906762
Trained batch 1070 in epoch 8, gen_loss = 0.9265593601708987, disc_loss = 0.011860619921530823
Trained batch 1071 in epoch 8, gen_loss = 0.926443807586138, disc_loss = 0.011849899676493426
Trained batch 1072 in epoch 8, gen_loss = 0.9264637303207928, disc_loss = 0.011839078629013686
Trained batch 1073 in epoch 8, gen_loss = 0.9264263336718416, disc_loss = 0.011828262243057632
Trained batch 1074 in epoch 8, gen_loss = 0.9264939656091291, disc_loss = 0.01181798049825417
Trained batch 1075 in epoch 8, gen_loss = 0.9265926898799864, disc_loss = 0.011807296357402573
Trained batch 1076 in epoch 8, gen_loss = 0.92670334511702, disc_loss = 0.011796602276675948
Trained batch 1077 in epoch 8, gen_loss = 0.9266796708936372, disc_loss = 0.011785909389088436
Trained batch 1078 in epoch 8, gen_loss = 0.9266424040146952, disc_loss = 0.011775220432504322
Trained batch 1079 in epoch 8, gen_loss = 0.9266362472540802, disc_loss = 0.011764542698303423
Trained batch 1080 in epoch 8, gen_loss = 0.9265197610601466, disc_loss = 0.011753873244339018
Trained batch 1081 in epoch 8, gen_loss = 0.9264673727001589, disc_loss = 0.011743215943437371
Trained batch 1082 in epoch 8, gen_loss = 0.9265049594426089, disc_loss = 0.01173264099482418
Trained batch 1083 in epoch 8, gen_loss = 0.9264814012110013, disc_loss = 0.01172205662086395
Trained batch 1084 in epoch 8, gen_loss = 0.9265174490790213, disc_loss = 0.011711502650767149
Trained batch 1085 in epoch 8, gen_loss = 0.9264753048975384, disc_loss = 0.011700994678853705
Trained batch 1086 in epoch 8, gen_loss = 0.9264975577565433, disc_loss = 0.011690391206906306
Trained batch 1087 in epoch 8, gen_loss = 0.9265318876406288, disc_loss = 0.01167984299230043
Trained batch 1088 in epoch 8, gen_loss = 0.9265233102306737, disc_loss = 0.011669349196707233
Trained batch 1089 in epoch 8, gen_loss = 0.9265296167463337, disc_loss = 0.011658929465346598
Trained batch 1090 in epoch 8, gen_loss = 0.9265213000402879, disc_loss = 0.011648447999079164
Trained batch 1091 in epoch 8, gen_loss = 0.9265937252522825, disc_loss = 0.01163795006639689
Trained batch 1092 in epoch 8, gen_loss = 0.9265145028226439, disc_loss = 0.011627478888880357
Trained batch 1093 in epoch 8, gen_loss = 0.9264565538717144, disc_loss = 0.011617083092727928
Trained batch 1094 in epoch 8, gen_loss = 0.926606205527641, disc_loss = 0.011607756883120718
Trained batch 1095 in epoch 8, gen_loss = 0.9265925309138141, disc_loss = 0.011597819362431816
Trained batch 1096 in epoch 8, gen_loss = 0.9265555566348265, disc_loss = 0.011587659824571004
Trained batch 1097 in epoch 8, gen_loss = 0.9266222351398624, disc_loss = 0.011577344919466465
Trained batch 1098 in epoch 8, gen_loss = 0.9265834547857245, disc_loss = 0.011567197091425358
Trained batch 1099 in epoch 8, gen_loss = 0.9266084591096098, disc_loss = 0.011556873709579866
Trained batch 1100 in epoch 8, gen_loss = 0.9267154435316721, disc_loss = 0.011546649997116559
Trained batch 1101 in epoch 8, gen_loss = 0.9267873521995631, disc_loss = 0.011536390135032923
Trained batch 1102 in epoch 8, gen_loss = 0.9267216881134244, disc_loss = 0.01152614806078179
Trained batch 1103 in epoch 8, gen_loss = 0.9266459086396988, disc_loss = 0.011515860940233035
Trained batch 1104 in epoch 8, gen_loss = 0.9265778161551618, disc_loss = 0.01150566426681816
Trained batch 1105 in epoch 8, gen_loss = 0.9265146975221944, disc_loss = 0.011495393249669906
Trained batch 1106 in epoch 8, gen_loss = 0.9264180485525967, disc_loss = 0.011485173504240874
Trained batch 1107 in epoch 8, gen_loss = 0.9263786224628183, disc_loss = 0.011474995897206691
Trained batch 1108 in epoch 8, gen_loss = 0.9263020505283844, disc_loss = 0.011464801032252663
Trained batch 1109 in epoch 8, gen_loss = 0.9263556597737579, disc_loss = 0.011454759388760902
Trained batch 1110 in epoch 8, gen_loss = 0.9263118914555688, disc_loss = 0.011444584485391238
Trained batch 1111 in epoch 8, gen_loss = 0.9263007823351047, disc_loss = 0.011434446901822418
Trained batch 1112 in epoch 8, gen_loss = 0.9262795115470458, disc_loss = 0.011424404165818086
Trained batch 1113 in epoch 8, gen_loss = 0.9262900949862102, disc_loss = 0.011414928898195752
Trained batch 1114 in epoch 8, gen_loss = 0.9263054978419847, disc_loss = 0.01140610702042708
Trained batch 1115 in epoch 8, gen_loss = 0.9261665029925258, disc_loss = 0.011408268840304733
Trained batch 1116 in epoch 8, gen_loss = 0.9264668186487849, disc_loss = 0.011402654281793718
Trained batch 1117 in epoch 8, gen_loss = 0.9267036115920607, disc_loss = 0.011395505829939676
Trained batch 1118 in epoch 8, gen_loss = 0.9268825734641746, disc_loss = 0.011386298470589137
Trained batch 1119 in epoch 8, gen_loss = 0.9269402947010739, disc_loss = 0.011377634123151178
Trained batch 1120 in epoch 8, gen_loss = 0.9270667181442509, disc_loss = 0.011368210489889603
Trained batch 1121 in epoch 8, gen_loss = 0.927233251153679, disc_loss = 0.011359242442157472
Trained batch 1122 in epoch 8, gen_loss = 0.9272580230915429, disc_loss = 0.011349727481192385
Trained batch 1123 in epoch 8, gen_loss = 0.9273328271253678, disc_loss = 0.01134021492748535
Trained batch 1124 in epoch 8, gen_loss = 0.9273664056195153, disc_loss = 0.011332287587704033
Trained batch 1125 in epoch 8, gen_loss = 0.9274018671277573, disc_loss = 0.011324319331623969
Trained batch 1126 in epoch 8, gen_loss = 0.9274444127093402, disc_loss = 0.011314983946024258
Trained batch 1127 in epoch 8, gen_loss = 0.9274946862025887, disc_loss = 0.011305633565006511
Trained batch 1128 in epoch 8, gen_loss = 0.9274932107796597, disc_loss = 0.011296401892024533
Trained batch 1129 in epoch 8, gen_loss = 0.9275412471684734, disc_loss = 0.011287008070366858
Trained batch 1130 in epoch 8, gen_loss = 0.9275381325568698, disc_loss = 0.011278961258759754
Trained batch 1131 in epoch 8, gen_loss = 0.9274269740225569, disc_loss = 0.011315895231122784
Trained batch 1132 in epoch 8, gen_loss = 0.9276759355918349, disc_loss = 0.01132581948175739
Trained batch 1133 in epoch 8, gen_loss = 0.9279511907060731, disc_loss = 0.011324536505191093
Trained batch 1134 in epoch 8, gen_loss = 0.928110653372063, disc_loss = 0.011318840071497924
Trained batch 1135 in epoch 8, gen_loss = 0.9281551244235794, disc_loss = 0.011322018773837404
Trained batch 1136 in epoch 8, gen_loss = 0.9283139674466434, disc_loss = 0.011321237776646035
Trained batch 1137 in epoch 8, gen_loss = 0.9284935727951187, disc_loss = 0.011316990364242777
Trained batch 1138 in epoch 8, gen_loss = 0.9287062969461044, disc_loss = 0.011308634997120343
Trained batch 1139 in epoch 8, gen_loss = 0.9288966223074678, disc_loss = 0.011300093518468458
Trained batch 1140 in epoch 8, gen_loss = 0.9290758810421545, disc_loss = 0.01129088946394951
Trained batch 1141 in epoch 8, gen_loss = 0.9292029099842295, disc_loss = 0.01128169242880071
Trained batch 1142 in epoch 8, gen_loss = 0.9293551334715265, disc_loss = 0.011272657958722726
Trained batch 1143 in epoch 8, gen_loss = 0.9294880951878491, disc_loss = 0.011263373906560218
Trained batch 1144 in epoch 8, gen_loss = 0.9295575753309842, disc_loss = 0.011254147853355094
Trained batch 1145 in epoch 8, gen_loss = 0.9296935205112161, disc_loss = 0.011244791165233673
Trained batch 1146 in epoch 8, gen_loss = 0.929843051727689, disc_loss = 0.011235856556357655
Trained batch 1147 in epoch 8, gen_loss = 0.9298308778047977, disc_loss = 0.011226749176842275
Trained batch 1148 in epoch 8, gen_loss = 0.9299319682430454, disc_loss = 0.011217575931846727
Trained batch 1149 in epoch 8, gen_loss = 0.9301877328364745, disc_loss = 0.011208386637748766
Trained batch 1150 in epoch 8, gen_loss = 0.9303354373659702, disc_loss = 0.011199049269012338
Trained batch 1151 in epoch 8, gen_loss = 0.9305881245010015, disc_loss = 0.011189828431737523
Trained batch 1152 in epoch 8, gen_loss = 0.9306894791767273, disc_loss = 0.011180527258326836
Trained batch 1153 in epoch 8, gen_loss = 0.9308780036879577, disc_loss = 0.01117128890858
Trained batch 1154 in epoch 8, gen_loss = 0.9309903677149769, disc_loss = 0.011162263598180682
Trained batch 1155 in epoch 8, gen_loss = 0.9311125822700431, disc_loss = 0.011153119860534097
Trained batch 1156 in epoch 8, gen_loss = 0.931282347687999, disc_loss = 0.01114397539584179
Trained batch 1157 in epoch 8, gen_loss = 0.9314089218518071, disc_loss = 0.011134793308864823
Trained batch 1158 in epoch 8, gen_loss = 0.9316074426211192, disc_loss = 0.01112611662791377
Trained batch 1159 in epoch 8, gen_loss = 0.9317147969942668, disc_loss = 0.011116980220422505
Trained batch 1160 in epoch 8, gen_loss = 0.9318844621855057, disc_loss = 0.011107830182991824
Trained batch 1161 in epoch 8, gen_loss = 0.932028406330107, disc_loss = 0.011098731958438869
Trained batch 1162 in epoch 8, gen_loss = 0.9321957673630833, disc_loss = 0.01108971582278451
Trained batch 1163 in epoch 8, gen_loss = 0.9322655476194477, disc_loss = 0.011080568976029917
Trained batch 1164 in epoch 8, gen_loss = 0.932410729775613, disc_loss = 0.011071639066192825
Trained batch 1165 in epoch 8, gen_loss = 0.9325350139347603, disc_loss = 0.011062706690835252
Trained batch 1166 in epoch 8, gen_loss = 0.9327292720936462, disc_loss = 0.01105448146085181
Trained batch 1167 in epoch 8, gen_loss = 0.9328383848020066, disc_loss = 0.011046033264168205
Trained batch 1168 in epoch 8, gen_loss = 0.9330337086072633, disc_loss = 0.011037015968536255
Trained batch 1169 in epoch 8, gen_loss = 0.9332047842251949, disc_loss = 0.011028273814742386
Trained batch 1170 in epoch 8, gen_loss = 0.9332884165031293, disc_loss = 0.011019425331514005
Trained batch 1171 in epoch 8, gen_loss = 0.9332872922866011, disc_loss = 0.011010449859709498
Trained batch 1172 in epoch 8, gen_loss = 0.9334600838401433, disc_loss = 0.011001737262626998
Trained batch 1173 in epoch 8, gen_loss = 0.933506365706811, disc_loss = 0.010993006759824639
Trained batch 1174 in epoch 8, gen_loss = 0.9334914586645492, disc_loss = 0.01098477774603104
Trained batch 1175 in epoch 8, gen_loss = 0.9334751621750342, disc_loss = 0.010975779440970383
Trained batch 1176 in epoch 8, gen_loss = 0.9335979974512945, disc_loss = 0.010966827222822134
Trained batch 1177 in epoch 8, gen_loss = 0.9336338053585516, disc_loss = 0.010958388575628152
Trained batch 1178 in epoch 8, gen_loss = 0.9336618449700091, disc_loss = 0.010949531997068891
Trained batch 1179 in epoch 8, gen_loss = 0.9337550351932897, disc_loss = 0.010941032283202947
Trained batch 1180 in epoch 8, gen_loss = 0.9337992556866299, disc_loss = 0.010932592715541943
Trained batch 1181 in epoch 8, gen_loss = 0.9339742753055899, disc_loss = 0.010923976286874542
Trained batch 1182 in epoch 8, gen_loss = 0.9339548977924824, disc_loss = 0.010915670501237396
Trained batch 1183 in epoch 8, gen_loss = 0.9339530407325238, disc_loss = 0.010906994299578376
Trained batch 1184 in epoch 8, gen_loss = 0.9339022644712955, disc_loss = 0.010898407800592196
Trained batch 1185 in epoch 8, gen_loss = 0.9338014907066979, disc_loss = 0.010890570689111215
Trained batch 1186 in epoch 8, gen_loss = 0.9338323259765396, disc_loss = 0.010882394823024348
Trained batch 1187 in epoch 8, gen_loss = 0.9338521061070038, disc_loss = 0.010873663595715214
Trained batch 1188 in epoch 8, gen_loss = 0.9339814493644127, disc_loss = 0.010865379510780964
Trained batch 1189 in epoch 8, gen_loss = 0.934092175033914, disc_loss = 0.010856784427498893
Trained batch 1190 in epoch 8, gen_loss = 0.9340685867992997, disc_loss = 0.010848190650092395
Trained batch 1191 in epoch 8, gen_loss = 0.9340711308255691, disc_loss = 0.010839699806290308
Trained batch 1192 in epoch 8, gen_loss = 0.9341873110639679, disc_loss = 0.010832426954873749
Trained batch 1193 in epoch 8, gen_loss = 0.9342574304721663, disc_loss = 0.01082432031660671
Trained batch 1194 in epoch 8, gen_loss = 0.9341655559370209, disc_loss = 0.010827114234888385
Trained batch 1195 in epoch 8, gen_loss = 0.9343864307505231, disc_loss = 0.01082240767292178
Trained batch 1196 in epoch 8, gen_loss = 0.9346140798122163, disc_loss = 0.01081740112297901
Trained batch 1197 in epoch 8, gen_loss = 0.9347732760422616, disc_loss = 0.010809710703001421
Trained batch 1198 in epoch 8, gen_loss = 0.9347777291324558, disc_loss = 0.010805631324103093
Trained batch 1199 in epoch 8, gen_loss = 0.934832770054539, disc_loss = 0.010799770539633755
Trained batch 1200 in epoch 8, gen_loss = 0.9349555535727397, disc_loss = 0.010791724342429723
Trained batch 1201 in epoch 8, gen_loss = 0.9348534194135825, disc_loss = 0.010802596101808821
Trained batch 1202 in epoch 8, gen_loss = 0.9350116524662658, disc_loss = 0.010803573827749581
Trained batch 1203 in epoch 8, gen_loss = 0.9351811509245258, disc_loss = 0.010803223228838857
Trained batch 1204 in epoch 8, gen_loss = 0.9353086563808789, disc_loss = 0.010795618877811377
Trained batch 1205 in epoch 8, gen_loss = 0.9354122781486653, disc_loss = 0.010790064232894485
Trained batch 1206 in epoch 8, gen_loss = 0.9353794830588141, disc_loss = 0.010782245697897578
Trained batch 1207 in epoch 8, gen_loss = 0.9354815640246237, disc_loss = 0.01077460647896362
Trained batch 1208 in epoch 8, gen_loss = 0.9354942741474896, disc_loss = 0.010769835802482544
Trained batch 1209 in epoch 8, gen_loss = 0.9354525028920371, disc_loss = 0.010761518014124921
Trained batch 1210 in epoch 8, gen_loss = 0.9354582374544798, disc_loss = 0.010755839525643813
Trained batch 1211 in epoch 8, gen_loss = 0.9354747079632463, disc_loss = 0.010748155877729797
Trained batch 1212 in epoch 8, gen_loss = 0.9355548008207634, disc_loss = 0.010740097772789468
Trained batch 1213 in epoch 8, gen_loss = 0.9356324182949113, disc_loss = 0.010731677088943173
Trained batch 1214 in epoch 8, gen_loss = 0.9356440588525293, disc_loss = 0.010723269033404316
Trained batch 1215 in epoch 8, gen_loss = 0.9356985289456421, disc_loss = 0.0107149649955581
Trained batch 1216 in epoch 8, gen_loss = 0.9357568388261458, disc_loss = 0.010706579882359141
Trained batch 1217 in epoch 8, gen_loss = 0.9357300331488815, disc_loss = 0.01069835179996681
Trained batch 1218 in epoch 8, gen_loss = 0.9357899182198769, disc_loss = 0.01069005129343291
Trained batch 1219 in epoch 8, gen_loss = 0.9359033188126126, disc_loss = 0.010684587997439238
Trained batch 1220 in epoch 8, gen_loss = 0.9360106931808637, disc_loss = 0.010678101068167233
Trained batch 1221 in epoch 8, gen_loss = 0.9360539915372424, disc_loss = 0.010671190623821878
Trained batch 1222 in epoch 8, gen_loss = 0.9360156923118227, disc_loss = 0.01066376454760528
Trained batch 1223 in epoch 8, gen_loss = 0.936005748248373, disc_loss = 0.010655699578112236
Trained batch 1224 in epoch 8, gen_loss = 0.9360478234047792, disc_loss = 0.010649530511404083
Trained batch 1225 in epoch 8, gen_loss = 0.936191683419377, disc_loss = 0.010642720767857373
Trained batch 1226 in epoch 8, gen_loss = 0.9363317461691937, disc_loss = 0.01063487259048455
Trained batch 1227 in epoch 8, gen_loss = 0.9363964773010741, disc_loss = 0.010627753743315507
Trained batch 1228 in epoch 8, gen_loss = 0.9362851325286123, disc_loss = 0.010620600107844227
Trained batch 1229 in epoch 8, gen_loss = 0.9361134362656895, disc_loss = 0.010635317626967174
Trained batch 1230 in epoch 8, gen_loss = 0.9363429112757831, disc_loss = 0.010749066348058917
Trained batch 1231 in epoch 8, gen_loss = 0.9364344350171167, disc_loss = 0.010743840644095911
Trained batch 1232 in epoch 8, gen_loss = 0.9364840695506078, disc_loss = 0.010738520582815249
Trained batch 1233 in epoch 8, gen_loss = 0.9365294154739457, disc_loss = 0.010734303615950225
Trained batch 1234 in epoch 8, gen_loss = 0.9366214315176975, disc_loss = 0.010728737204050483
Trained batch 1235 in epoch 8, gen_loss = 0.9366742233869327, disc_loss = 0.010721855124412613
Trained batch 1236 in epoch 8, gen_loss = 0.9367509416591379, disc_loss = 0.010714420303624713
Trained batch 1237 in epoch 8, gen_loss = 0.9368736834682054, disc_loss = 0.01070797014932375
Trained batch 1238 in epoch 8, gen_loss = 0.9369092852815301, disc_loss = 0.010700852238785764
Trained batch 1239 in epoch 8, gen_loss = 0.9370157940974159, disc_loss = 0.010693465052451844
Trained batch 1240 in epoch 8, gen_loss = 0.937078151296551, disc_loss = 0.010686924230544393
Trained batch 1241 in epoch 8, gen_loss = 0.93701849748259, disc_loss = 0.010679340843111182
Trained batch 1242 in epoch 8, gen_loss = 0.9371178281805924, disc_loss = 0.01067376088053698
Trained batch 1243 in epoch 8, gen_loss = 0.937171478483263, disc_loss = 0.010665831242205026
Trained batch 1244 in epoch 8, gen_loss = 0.937228967985475, disc_loss = 0.010658091340664247
Trained batch 1245 in epoch 8, gen_loss = 0.9372532870231816, disc_loss = 0.010650045565386205
Trained batch 1246 in epoch 8, gen_loss = 0.9372934335551457, disc_loss = 0.010642036771191805
Trained batch 1247 in epoch 8, gen_loss = 0.937263917297316, disc_loss = 0.010634142973837394
Trained batch 1248 in epoch 8, gen_loss = 0.937253470727212, disc_loss = 0.01062609384282989
Trained batch 1249 in epoch 8, gen_loss = 0.9372957513093948, disc_loss = 0.010618128583708312
Trained batch 1250 in epoch 8, gen_loss = 0.9373335829979891, disc_loss = 0.010610056876650748
Trained batch 1251 in epoch 8, gen_loss = 0.9373133411279883, disc_loss = 0.010602192609410897
Trained batch 1252 in epoch 8, gen_loss = 0.9372944274570879, disc_loss = 0.01059469875194798
Trained batch 1253 in epoch 8, gen_loss = 0.9372903778554911, disc_loss = 0.01058686708316771
Trained batch 1254 in epoch 8, gen_loss = 0.9372546881556036, disc_loss = 0.010578830685664573
Trained batch 1255 in epoch 8, gen_loss = 0.937248581320427, disc_loss = 0.01057141919895941
Trained batch 1256 in epoch 8, gen_loss = 0.9372450896881835, disc_loss = 0.010563316126231325
Trained batch 1257 in epoch 8, gen_loss = 0.9373325355149604, disc_loss = 0.010555356130407312
Trained batch 1258 in epoch 8, gen_loss = 0.9372708435045338, disc_loss = 0.010547690562172194
Trained batch 1259 in epoch 8, gen_loss = 0.937302636366988, disc_loss = 0.01053976438811838
Trained batch 1260 in epoch 8, gen_loss = 0.937362074592017, disc_loss = 0.010531744106921875
Trained batch 1261 in epoch 8, gen_loss = 0.9374098161179366, disc_loss = 0.01052365833976671
Trained batch 1262 in epoch 8, gen_loss = 0.9374512995837325, disc_loss = 0.010515585023352064
Trained batch 1263 in epoch 8, gen_loss = 0.9375085480086789, disc_loss = 0.010507690299187121
Trained batch 1264 in epoch 8, gen_loss = 0.9374209409410303, disc_loss = 0.010499926915278625
Trained batch 1265 in epoch 8, gen_loss = 0.9373904133059591, disc_loss = 0.01049210924899478
Trained batch 1266 in epoch 8, gen_loss = 0.9373834694617361, disc_loss = 0.010484199891149047
Trained batch 1267 in epoch 8, gen_loss = 0.9374155578224065, disc_loss = 0.010476171253593796
Trained batch 1268 in epoch 8, gen_loss = 0.9373868823380241, disc_loss = 0.010468102997280177
Trained batch 1269 in epoch 8, gen_loss = 0.9374062868788486, disc_loss = 0.010460446670197233
Trained batch 1270 in epoch 8, gen_loss = 0.9372660950775882, disc_loss = 0.010455899385810591
Trained batch 1271 in epoch 8, gen_loss = 0.937201393826765, disc_loss = 0.01044950310686362
Trained batch 1272 in epoch 8, gen_loss = 0.9371918659695283, disc_loss = 0.010442724243111969
Trained batch 1273 in epoch 8, gen_loss = 0.9371231346854609, disc_loss = 0.010435028309894822
Trained batch 1274 in epoch 8, gen_loss = 0.9372680138372907, disc_loss = 0.01042741684194006
Trained batch 1275 in epoch 8, gen_loss = 0.9372691301202699, disc_loss = 0.010419584780318467
Trained batch 1276 in epoch 8, gen_loss = 0.9373700099945442, disc_loss = 0.010412120965365325
Trained batch 1277 in epoch 8, gen_loss = 0.9372923069390147, disc_loss = 0.010404381616648556
Trained batch 1278 in epoch 8, gen_loss = 0.9373245002283912, disc_loss = 0.010396575238692656
Trained batch 1279 in epoch 8, gen_loss = 0.937345715216361, disc_loss = 0.010388651822324846
Trained batch 1280 in epoch 8, gen_loss = 0.93731352482151, disc_loss = 0.01038073825595708
Trained batch 1281 in epoch 8, gen_loss = 0.9373267314130914, disc_loss = 0.010372895052506789
Trained batch 1282 in epoch 8, gen_loss = 0.9373148531766953, disc_loss = 0.010365100288669729
Trained batch 1283 in epoch 8, gen_loss = 0.9372931730663665, disc_loss = 0.010357328480934362
Trained batch 1284 in epoch 8, gen_loss = 0.9373839392968188, disc_loss = 0.010349470977084838
Trained batch 1285 in epoch 8, gen_loss = 0.937399715857224, disc_loss = 0.010341607055479797
Trained batch 1286 in epoch 8, gen_loss = 0.9373376359519054, disc_loss = 0.01033376006136081
Trained batch 1287 in epoch 8, gen_loss = 0.9373983891900652, disc_loss = 0.010325866960726066
Trained batch 1288 in epoch 8, gen_loss = 0.9373568932477405, disc_loss = 0.010318041727395874
Trained batch 1289 in epoch 8, gen_loss = 0.9373603599709134, disc_loss = 0.010310252702974556
Trained batch 1290 in epoch 8, gen_loss = 0.9373465230952484, disc_loss = 0.010302432081006549
Trained batch 1291 in epoch 8, gen_loss = 0.9373690114347928, disc_loss = 0.010294619159807322
Trained batch 1292 in epoch 8, gen_loss = 0.9374971939488519, disc_loss = 0.010286858555351129
Trained batch 1293 in epoch 8, gen_loss = 0.9374687361892261, disc_loss = 0.010279103144234563
Trained batch 1294 in epoch 8, gen_loss = 0.9374636536629504, disc_loss = 0.010271452248541901
Trained batch 1295 in epoch 8, gen_loss = 0.9374681882974174, disc_loss = 0.010263697311776563
Trained batch 1296 in epoch 8, gen_loss = 0.9373987028712756, disc_loss = 0.010256030469202582
Trained batch 1297 in epoch 8, gen_loss = 0.9373711684405895, disc_loss = 0.010248367372556383
Trained batch 1298 in epoch 8, gen_loss = 0.9373477950428338, disc_loss = 0.010240615132770513
Trained batch 1299 in epoch 8, gen_loss = 0.9373462023872595, disc_loss = 0.010232965270261048
Trained batch 1300 in epoch 8, gen_loss = 0.9372755368107745, disc_loss = 0.010225221238282565
Trained batch 1301 in epoch 8, gen_loss = 0.9373763371402034, disc_loss = 0.010217555166923062
Trained batch 1302 in epoch 8, gen_loss = 0.9373186328323273, disc_loss = 0.010209959275651626
Trained batch 1303 in epoch 8, gen_loss = 0.9372725838029677, disc_loss = 0.010202308897103291
Trained batch 1304 in epoch 8, gen_loss = 0.9372315124305272, disc_loss = 0.010194677864261582
Trained batch 1305 in epoch 8, gen_loss = 0.9371972335288572, disc_loss = 0.01018699985124311
Trained batch 1306 in epoch 8, gen_loss = 0.9371192369327895, disc_loss = 0.010179348922702117
Trained batch 1307 in epoch 8, gen_loss = 0.9371274892662279, disc_loss = 0.010171862362500563
Trained batch 1308 in epoch 8, gen_loss = 0.9371224960769015, disc_loss = 0.010164244612158618
Trained batch 1309 in epoch 8, gen_loss = 0.9370834863140383, disc_loss = 0.010156637256789974
Trained batch 1310 in epoch 8, gen_loss = 0.9370840209345159, disc_loss = 0.010149064054410737
Trained batch 1311 in epoch 8, gen_loss = 0.9370891970877604, disc_loss = 0.010141540721478366
Trained batch 1312 in epoch 8, gen_loss = 0.9370937340375766, disc_loss = 0.010133923692975416
Trained batch 1313 in epoch 8, gen_loss = 0.937091133388573, disc_loss = 0.010126406335683158
Trained batch 1314 in epoch 8, gen_loss = 0.9370193671590928, disc_loss = 0.01011893585487623
Trained batch 1315 in epoch 8, gen_loss = 0.9370057803655105, disc_loss = 0.010111411717985007
Trained batch 1316 in epoch 8, gen_loss = 0.9370319613608431, disc_loss = 0.010103881191791989
Trained batch 1317 in epoch 8, gen_loss = 0.9370035168478811, disc_loss = 0.010096361047492189
Trained batch 1318 in epoch 8, gen_loss = 0.9369459447533548, disc_loss = 0.010088941060646329
Trained batch 1319 in epoch 8, gen_loss = 0.9369294840503822, disc_loss = 0.01008144582267436
Trained batch 1320 in epoch 8, gen_loss = 0.937025021662954, disc_loss = 0.010073996811947344
Trained batch 1321 in epoch 8, gen_loss = 0.9370926899240887, disc_loss = 0.010066590687016017
Trained batch 1322 in epoch 8, gen_loss = 0.9370138548083676, disc_loss = 0.010059177793453916
Trained batch 1323 in epoch 8, gen_loss = 0.9369758955706643, disc_loss = 0.010051756575947179
Trained batch 1324 in epoch 8, gen_loss = 0.9368821593725456, disc_loss = 0.010044340835291155
Trained batch 1325 in epoch 8, gen_loss = 0.9369194869676866, disc_loss = 0.010036932931265473
Trained batch 1326 in epoch 8, gen_loss = 0.9369190074082326, disc_loss = 0.01002949767531492
Trained batch 1327 in epoch 8, gen_loss = 0.9369691628065094, disc_loss = 0.010022257491916854
Trained batch 1328 in epoch 8, gen_loss = 0.9368564719046929, disc_loss = 0.010014926921473336
Trained batch 1329 in epoch 8, gen_loss = 0.9368485107681805, disc_loss = 0.010007510585005788
Trained batch 1330 in epoch 8, gen_loss = 0.93674311212003, disc_loss = 0.010000143204248042
Trained batch 1331 in epoch 8, gen_loss = 0.936836151501259, disc_loss = 0.009993046606196385
Trained batch 1332 in epoch 8, gen_loss = 0.9367752851665423, disc_loss = 0.009985766885741017
Trained batch 1333 in epoch 8, gen_loss = 0.9367540501270337, disc_loss = 0.009978428643396752
Trained batch 1334 in epoch 8, gen_loss = 0.9367267744148269, disc_loss = 0.009971114271135097
Trained batch 1335 in epoch 8, gen_loss = 0.9367080682632095, disc_loss = 0.009963755595640169
Trained batch 1336 in epoch 8, gen_loss = 0.9367164287133812, disc_loss = 0.009956443323967971
Trained batch 1337 in epoch 8, gen_loss = 0.936736281654938, disc_loss = 0.009949108767777373
Trained batch 1338 in epoch 8, gen_loss = 0.9367446104166132, disc_loss = 0.0099418109884142
Trained batch 1339 in epoch 8, gen_loss = 0.9367211531569709, disc_loss = 0.009934542808115288
Trained batch 1340 in epoch 8, gen_loss = 0.9367698488130577, disc_loss = 0.009927273897628115
Trained batch 1341 in epoch 8, gen_loss = 0.9367477397938244, disc_loss = 0.00992002722196265
Trained batch 1342 in epoch 8, gen_loss = 0.9367289186100949, disc_loss = 0.009912818359698332
Trained batch 1343 in epoch 8, gen_loss = 0.9367640544660389, disc_loss = 0.00990554084805375
Trained batch 1344 in epoch 8, gen_loss = 0.9366990004108741, disc_loss = 0.009898333927593973
Trained batch 1345 in epoch 8, gen_loss = 0.9367401840561035, disc_loss = 0.009891124587025346
Trained batch 1346 in epoch 8, gen_loss = 0.9367249422411433, disc_loss = 0.009883951761071178
Trained batch 1347 in epoch 8, gen_loss = 0.9366381012500217, disc_loss = 0.009876781310605902
Trained batch 1348 in epoch 8, gen_loss = 0.9366609828617062, disc_loss = 0.009869560454767995
Trained batch 1349 in epoch 8, gen_loss = 0.9366637480479699, disc_loss = 0.009862413966146523
Trained batch 1350 in epoch 8, gen_loss = 0.9366923152165092, disc_loss = 0.00985526189569599
Trained batch 1351 in epoch 8, gen_loss = 0.9366877639126143, disc_loss = 0.009848123530330469
Trained batch 1352 in epoch 8, gen_loss = 0.9367249202525625, disc_loss = 0.009840993086664772
Trained batch 1353 in epoch 8, gen_loss = 0.9366605099802355, disc_loss = 0.009833890513793471
Trained batch 1354 in epoch 8, gen_loss = 0.9366539960637743, disc_loss = 0.009826847236789076
Trained batch 1355 in epoch 8, gen_loss = 0.9366448797439404, disc_loss = 0.009819756863902067
Trained batch 1356 in epoch 8, gen_loss = 0.936601271744414, disc_loss = 0.00981263424345006
Trained batch 1357 in epoch 8, gen_loss = 0.9365129924443755, disc_loss = 0.009805515873727159
Trained batch 1358 in epoch 8, gen_loss = 0.9364952396127211, disc_loss = 0.00979840963057121
Trained batch 1359 in epoch 8, gen_loss = 0.936421025916934, disc_loss = 0.009791434962757835
Trained batch 1360 in epoch 8, gen_loss = 0.9364369213143138, disc_loss = 0.009784405983914843
Trained batch 1361 in epoch 8, gen_loss = 0.9364158313136094, disc_loss = 0.009777344272199902
Trained batch 1362 in epoch 8, gen_loss = 0.9364217265904693, disc_loss = 0.009770332987571694
Trained batch 1363 in epoch 8, gen_loss = 0.9363712901549954, disc_loss = 0.00976329089352638
Trained batch 1364 in epoch 8, gen_loss = 0.9362944891382923, disc_loss = 0.009756298446426536
Trained batch 1365 in epoch 8, gen_loss = 0.9363009040605271, disc_loss = 0.009749334790084429
Trained batch 1366 in epoch 8, gen_loss = 0.936230068256494, disc_loss = 0.009742349388897786
Trained batch 1367 in epoch 8, gen_loss = 0.9361999424621027, disc_loss = 0.00973533742871312
Trained batch 1368 in epoch 8, gen_loss = 0.936200417093851, disc_loss = 0.009728373384886453
Trained batch 1369 in epoch 8, gen_loss = 0.9362547873798078, disc_loss = 0.009721422517021275
Trained batch 1370 in epoch 8, gen_loss = 0.9362576052405206, disc_loss = 0.009714464012224004
Trained batch 1371 in epoch 8, gen_loss = 0.9363005380458457, disc_loss = 0.009707541691703852
Trained batch 1372 in epoch 8, gen_loss = 0.936381266335024, disc_loss = 0.009700616492803082
Trained batch 1373 in epoch 8, gen_loss = 0.9362794311155919, disc_loss = 0.009693726383855742
Trained batch 1374 in epoch 8, gen_loss = 0.936246763381091, disc_loss = 0.009686789223839613
Trained batch 1375 in epoch 8, gen_loss = 0.936320987703322, disc_loss = 0.009679927115855186
Trained batch 1376 in epoch 8, gen_loss = 0.9362855271186704, disc_loss = 0.009673082921763892
Trained batch 1377 in epoch 8, gen_loss = 0.936291332622917, disc_loss = 0.009666154801802296
Trained batch 1378 in epoch 8, gen_loss = 0.9362508413193449, disc_loss = 0.009659260090057582
Trained batch 1379 in epoch 8, gen_loss = 0.9361914774861888, disc_loss = 0.009652388068270344
Trained batch 1380 in epoch 8, gen_loss = 0.9361924805950204, disc_loss = 0.00964550969934529
Trained batch 1381 in epoch 8, gen_loss = 0.9361852464601721, disc_loss = 0.009638683883733653
Trained batch 1382 in epoch 8, gen_loss = 0.9362390830261674, disc_loss = 0.00963181077164028
Trained batch 1383 in epoch 8, gen_loss = 0.9361884881004777, disc_loss = 0.009624999224561075
Trained batch 1384 in epoch 8, gen_loss = 0.9362148324720265, disc_loss = 0.009618239699810783
Trained batch 1385 in epoch 8, gen_loss = 0.9361490453949566, disc_loss = 0.009611423021731066
Trained batch 1386 in epoch 8, gen_loss = 0.9361481957712359, disc_loss = 0.009604638744420177
Trained batch 1387 in epoch 8, gen_loss = 0.9361677424665487, disc_loss = 0.009597859114590246
Trained batch 1388 in epoch 8, gen_loss = 0.9361370461419644, disc_loss = 0.009591059948612222
Trained batch 1389 in epoch 8, gen_loss = 0.9361452100302675, disc_loss = 0.009584278243375278
Trained batch 1390 in epoch 8, gen_loss = 0.9360959820615397, disc_loss = 0.009577508887666392
Trained batch 1391 in epoch 8, gen_loss = 0.9361686031066481, disc_loss = 0.009570785028302652
Trained batch 1392 in epoch 8, gen_loss = 0.9362567037836049, disc_loss = 0.009564054364014092
Trained batch 1393 in epoch 8, gen_loss = 0.9362278762173276, disc_loss = 0.009557347014936227
Trained batch 1394 in epoch 8, gen_loss = 0.9361593206509894, disc_loss = 0.009550656210332792
Trained batch 1395 in epoch 8, gen_loss = 0.936119198606998, disc_loss = 0.00954395753761702
Trained batch 1396 in epoch 8, gen_loss = 0.9361468683034928, disc_loss = 0.00953724486355849
Trained batch 1397 in epoch 8, gen_loss = 0.9361407531475987, disc_loss = 0.00953056249051063
Trained batch 1398 in epoch 8, gen_loss = 0.9361380367427319, disc_loss = 0.009523919564068102
Trained batch 1399 in epoch 8, gen_loss = 0.9362113352119923, disc_loss = 0.009517194104550332
Trained batch 1400 in epoch 8, gen_loss = 0.9362296253804391, disc_loss = 0.009510512952224362
Trained batch 1401 in epoch 8, gen_loss = 0.9362259322030738, disc_loss = 0.009503891195269435
Trained batch 1402 in epoch 8, gen_loss = 0.9362586329897556, disc_loss = 0.009497314543955212
Trained batch 1403 in epoch 8, gen_loss = 0.9361754445905699, disc_loss = 0.00949065989486327
Trained batch 1404 in epoch 8, gen_loss = 0.9361565548966364, disc_loss = 0.009483971402998408
Trained batch 1405 in epoch 8, gen_loss = 0.9361565414694261, disc_loss = 0.009477325242130437
Trained batch 1406 in epoch 8, gen_loss = 0.9361265063836546, disc_loss = 0.009470702204632173
Trained batch 1407 in epoch 8, gen_loss = 0.9361075906040655, disc_loss = 0.009464066663569652
Trained batch 1408 in epoch 8, gen_loss = 0.9359861123934123, disc_loss = 0.009457491790482962
Trained batch 1409 in epoch 8, gen_loss = 0.9359287715761374, disc_loss = 0.009450930494164712
Trained batch 1410 in epoch 8, gen_loss = 0.9359371843150455, disc_loss = 0.009444330116050309
Trained batch 1411 in epoch 8, gen_loss = 0.9359510025753516, disc_loss = 0.009437767360068598
Trained batch 1412 in epoch 8, gen_loss = 0.9359199728049543, disc_loss = 0.009431272867876254
Trained batch 1413 in epoch 8, gen_loss = 0.9359024487636045, disc_loss = 0.009424715997934065
Trained batch 1414 in epoch 8, gen_loss = 0.9359423133804604, disc_loss = 0.009418185277488831
Trained batch 1415 in epoch 8, gen_loss = 0.9359174848318437, disc_loss = 0.009411677331986976
Trained batch 1416 in epoch 8, gen_loss = 0.935952336353236, disc_loss = 0.009405166870936704
Trained batch 1417 in epoch 8, gen_loss = 0.9360359821610458, disc_loss = 0.009398648237292279
Trained batch 1418 in epoch 8, gen_loss = 0.936080343354496, disc_loss = 0.009392236751257752
Trained batch 1419 in epoch 8, gen_loss = 0.9360564262304507, disc_loss = 0.009385738992840372
Trained batch 1420 in epoch 8, gen_loss = 0.9360346494007916, disc_loss = 0.00937924542501735
Trained batch 1421 in epoch 8, gen_loss = 0.9359477095505021, disc_loss = 0.009372869188152605
Trained batch 1422 in epoch 8, gen_loss = 0.9359030422197625, disc_loss = 0.009366428603652598
Trained batch 1423 in epoch 8, gen_loss = 0.9358212591431448, disc_loss = 0.009359958507083616
Trained batch 1424 in epoch 8, gen_loss = 0.9357282442168185, disc_loss = 0.009353575467662028
Trained batch 1425 in epoch 8, gen_loss = 0.9356499643889249, disc_loss = 0.009347140051736645
Trained batch 1426 in epoch 8, gen_loss = 0.9356116419207741, disc_loss = 0.009340732381437436
Trained batch 1427 in epoch 8, gen_loss = 0.9357289980982199, disc_loss = 0.009334371076795984
Trained batch 1428 in epoch 8, gen_loss = 0.9357512643947895, disc_loss = 0.009328026328191833
Trained batch 1429 in epoch 8, gen_loss = 0.9358089005405252, disc_loss = 0.00932165861767908
Trained batch 1430 in epoch 8, gen_loss = 0.9357199394186421, disc_loss = 0.009315272646917382
Trained batch 1431 in epoch 8, gen_loss = 0.935598480447544, disc_loss = 0.009308896353709137
Trained batch 1432 in epoch 8, gen_loss = 0.935559355517991, disc_loss = 0.009302493678559625
Trained batch 1433 in epoch 8, gen_loss = 0.9354759163146571, disc_loss = 0.009296144508011485
Trained batch 1434 in epoch 8, gen_loss = 0.9354956281932805, disc_loss = 0.009289790322349646
Trained batch 1435 in epoch 8, gen_loss = 0.9354178784492952, disc_loss = 0.009283446478768692
Trained batch 1436 in epoch 8, gen_loss = 0.9354334279697806, disc_loss = 0.009277127241384974
Trained batch 1437 in epoch 8, gen_loss = 0.9354653835752578, disc_loss = 0.00927076937420549
Trained batch 1438 in epoch 8, gen_loss = 0.9355280312959977, disc_loss = 0.009264483540428324
Trained batch 1439 in epoch 8, gen_loss = 0.9355017910194066, disc_loss = 0.009258148306399663
Trained batch 1440 in epoch 8, gen_loss = 0.9355367740808801, disc_loss = 0.009251838341745892
Trained batch 1441 in epoch 8, gen_loss = 0.935582344496465, disc_loss = 0.009245523523472741
Trained batch 1442 in epoch 8, gen_loss = 0.9355687850767428, disc_loss = 0.009239280528189205
Trained batch 1443 in epoch 8, gen_loss = 0.9355011062485029, disc_loss = 0.009233019750704482
Trained batch 1444 in epoch 8, gen_loss = 0.9354031936313867, disc_loss = 0.009226760850977804
Trained batch 1445 in epoch 8, gen_loss = 0.9355127488882545, disc_loss = 0.009220573089593247
Trained batch 1446 in epoch 8, gen_loss = 0.9354290505607291, disc_loss = 0.00921441716831661
Trained batch 1447 in epoch 8, gen_loss = 0.9353943523739913, disc_loss = 0.009208202787508099
Trained batch 1448 in epoch 8, gen_loss = 0.9354766678653806, disc_loss = 0.009201954129658194
Trained batch 1449 in epoch 8, gen_loss = 0.9353986751416634, disc_loss = 0.009195722005383216
Trained batch 1450 in epoch 8, gen_loss = 0.9352944862382483, disc_loss = 0.009189524260059496
Trained batch 1451 in epoch 8, gen_loss = 0.9353338898911292, disc_loss = 0.009183287483589063
Trained batch 1452 in epoch 8, gen_loss = 0.9352911417638525, disc_loss = 0.00917705886415346
Trained batch 1453 in epoch 8, gen_loss = 0.9352179883557796, disc_loss = 0.009170979866728966
Trained batch 1454 in epoch 8, gen_loss = 0.9352511016568777, disc_loss = 0.009164784282560522
Trained batch 1455 in epoch 8, gen_loss = 0.9351739016167082, disc_loss = 0.009158687242638784
Trained batch 1456 in epoch 8, gen_loss = 0.9351062194361781, disc_loss = 0.009152565692275896
Trained batch 1457 in epoch 8, gen_loss = 0.9351402506620632, disc_loss = 0.009146372355563323
Trained batch 1458 in epoch 8, gen_loss = 0.9351034340301223, disc_loss = 0.009140231547112753
Trained batch 1459 in epoch 8, gen_loss = 0.9350136931832522, disc_loss = 0.009134165251109078
Trained batch 1460 in epoch 8, gen_loss = 0.9349832419130102, disc_loss = 0.009128023680840522
Trained batch 1461 in epoch 8, gen_loss = 0.9349472222877756, disc_loss = 0.0091218736680324
Trained batch 1462 in epoch 8, gen_loss = 0.9349485719888404, disc_loss = 0.009115768217379461
Trained batch 1463 in epoch 8, gen_loss = 0.934937700934586, disc_loss = 0.009109625467720091
Trained batch 1464 in epoch 8, gen_loss = 0.9349243172809939, disc_loss = 0.009103567515707093
Trained batch 1465 in epoch 8, gen_loss = 0.9348640560819215, disc_loss = 0.009097451424282109
Trained batch 1466 in epoch 8, gen_loss = 0.9348402827998449, disc_loss = 0.009091438741486714
Trained batch 1467 in epoch 8, gen_loss = 0.9347937871430485, disc_loss = 0.009085355522652097
Trained batch 1468 in epoch 8, gen_loss = 0.9347494050829974, disc_loss = 0.009079287977857045
Trained batch 1469 in epoch 8, gen_loss = 0.9347902217487088, disc_loss = 0.009073215900615631
Trained batch 1470 in epoch 8, gen_loss = 0.9347452115518231, disc_loss = 0.00906717312135494
Trained batch 1471 in epoch 8, gen_loss = 0.9347625700959369, disc_loss = 0.009061101846372288
Trained batch 1472 in epoch 8, gen_loss = 0.9347110209178536, disc_loss = 0.009055115154309767
Trained batch 1473 in epoch 8, gen_loss = 0.9347490274639272, disc_loss = 0.009049135726098256
Trained batch 1474 in epoch 8, gen_loss = 0.9348271392765691, disc_loss = 0.009043112873663077
Trained batch 1475 in epoch 8, gen_loss = 0.9347932640977992, disc_loss = 0.009037101248844215
Trained batch 1476 in epoch 8, gen_loss = 0.934787927423689, disc_loss = 0.009031078831700616
Trained batch 1477 in epoch 8, gen_loss = 0.9347071547025918, disc_loss = 0.009025115268869495
Trained batch 1478 in epoch 8, gen_loss = 0.93465829598815, disc_loss = 0.009019147959454802
Trained batch 1479 in epoch 8, gen_loss = 0.93468974242742, disc_loss = 0.009013165192590275
Trained batch 1480 in epoch 8, gen_loss = 0.9346336951576159, disc_loss = 0.009007157730154989
Trained batch 1481 in epoch 8, gen_loss = 0.9345631626574135, disc_loss = 0.009001228363620136
Trained batch 1482 in epoch 8, gen_loss = 0.9345343986517339, disc_loss = 0.008995240348901994
Trained batch 1483 in epoch 8, gen_loss = 0.9344838883958737, disc_loss = 0.00898930831729894
Trained batch 1484 in epoch 8, gen_loss = 0.9344576724249907, disc_loss = 0.008983352925728964
Trained batch 1485 in epoch 8, gen_loss = 0.9344079570085171, disc_loss = 0.008977399421577499
Trained batch 1486 in epoch 8, gen_loss = 0.9343928096473979, disc_loss = 0.00897147031967047
Trained batch 1487 in epoch 8, gen_loss = 0.934443385550572, disc_loss = 0.008965633832465228
Trained batch 1488 in epoch 8, gen_loss = 0.9343661371896217, disc_loss = 0.008959773545448153
Trained batch 1489 in epoch 8, gen_loss = 0.9343918065296724, disc_loss = 0.008953884450099377
Trained batch 1490 in epoch 8, gen_loss = 0.9343386114762983, disc_loss = 0.008947982403859354
Trained batch 1491 in epoch 8, gen_loss = 0.9342453923805469, disc_loss = 0.008942093739208078
Trained batch 1492 in epoch 8, gen_loss = 0.934219845073461, disc_loss = 0.008936191339857902
Trained batch 1493 in epoch 8, gen_loss = 0.9341824783817672, disc_loss = 0.008930338743342692
Trained batch 1494 in epoch 8, gen_loss = 0.9341010269712047, disc_loss = 0.0089244567796681
Trained batch 1495 in epoch 8, gen_loss = 0.9341055500435638, disc_loss = 0.008918559341859715
Trained batch 1496 in epoch 8, gen_loss = 0.9341221630334376, disc_loss = 0.008912688686629486
Trained batch 1497 in epoch 8, gen_loss = 0.9340801405532656, disc_loss = 0.008906851510233993
Trained batch 1498 in epoch 8, gen_loss = 0.934079010797549, disc_loss = 0.008900993023004379
Trained batch 1499 in epoch 8, gen_loss = 0.934045239786307, disc_loss = 0.008895160352398913
Trained batch 1500 in epoch 8, gen_loss = 0.9340981199970093, disc_loss = 0.008889328138430259
Trained batch 1501 in epoch 8, gen_loss = 0.9340115004825529, disc_loss = 0.008883619311656243
Trained batch 1502 in epoch 8, gen_loss = 0.933691029281356, disc_loss = 0.009047079045863328
Trained batch 1503 in epoch 8, gen_loss = 0.9337576425416355, disc_loss = 0.00909208433545052
Trained batch 1504 in epoch 8, gen_loss = 0.9337404889719827, disc_loss = 0.009237950708788852
Trained batch 1505 in epoch 8, gen_loss = 0.9337445203249515, disc_loss = 0.009239787510636992
Trained batch 1506 in epoch 8, gen_loss = 0.9337279477614635, disc_loss = 0.00924691407855129
Trained batch 1507 in epoch 8, gen_loss = 0.9336883186384917, disc_loss = 0.009247082513062842
Trained batch 1508 in epoch 8, gen_loss = 0.9337362401172608, disc_loss = 0.00924479299368465
Trained batch 1509 in epoch 8, gen_loss = 0.9337548546246346, disc_loss = 0.009244552682305568
Trained batch 1510 in epoch 8, gen_loss = 0.9334273678352311, disc_loss = 0.009512841300463142
Trained batch 1511 in epoch 8, gen_loss = 0.9332159136338208, disc_loss = 0.009611909571754161
Trained batch 1512 in epoch 8, gen_loss = 0.933370791833604, disc_loss = 0.009720571455675566
Trained batch 1513 in epoch 8, gen_loss = 0.9335629153440619, disc_loss = 0.009819496578843229
Trained batch 1514 in epoch 8, gen_loss = 0.9335835600056664, disc_loss = 0.00982110511114196
Trained batch 1515 in epoch 8, gen_loss = 0.933579130427504, disc_loss = 0.00983010393853411
Trained batch 1516 in epoch 8, gen_loss = 0.9334761776968139, disc_loss = 0.00983255890991606
Trained batch 1517 in epoch 8, gen_loss = 0.9335392193282231, disc_loss = 0.009831134431645707
Trained batch 1518 in epoch 8, gen_loss = 0.9336308583450443, disc_loss = 0.009827423021538172
Trained batch 1519 in epoch 8, gen_loss = 0.9336678597095766, disc_loss = 0.009822311229431523
Trained batch 1520 in epoch 8, gen_loss = 0.9337244630643681, disc_loss = 0.009817251400495452
Trained batch 1521 in epoch 8, gen_loss = 0.9337538511696689, disc_loss = 0.00981160776518066
Trained batch 1522 in epoch 8, gen_loss = 0.9337601219441495, disc_loss = 0.009805987820033502
Trained batch 1523 in epoch 8, gen_loss = 0.933689126114207, disc_loss = 0.009800813258054758
Trained batch 1524 in epoch 8, gen_loss = 0.9337309684128058, disc_loss = 0.009796108927050047
Trained batch 1525 in epoch 8, gen_loss = 0.9333705118372744, disc_loss = 0.009908348967515255
Trained batch 1526 in epoch 8, gen_loss = 0.9334316839754933, disc_loss = 0.010002075592547462
Trained batch 1527 in epoch 8, gen_loss = 0.9333751561871062, disc_loss = 0.010052377242173142
Trained batch 1528 in epoch 8, gen_loss = 0.9332990760776715, disc_loss = 0.010056155298153683
Trained batch 1529 in epoch 8, gen_loss = 0.9330718156364229, disc_loss = 0.0101207355365035
Trained batch 1530 in epoch 8, gen_loss = 0.9329601867497941, disc_loss = 0.0101434772870899
Trained batch 1531 in epoch 8, gen_loss = 0.9328266962895817, disc_loss = 0.01020949935973144
Trained batch 1532 in epoch 8, gen_loss = 0.9329964953820378, disc_loss = 0.010287020450135909
Trained batch 1533 in epoch 8, gen_loss = 0.9327935349327333, disc_loss = 0.010470990999714668
Trained batch 1534 in epoch 8, gen_loss = 0.9328592503692118, disc_loss = 0.010723563426769382
Trained batch 1535 in epoch 8, gen_loss = 0.9328577490329432, disc_loss = 0.010771581970909475
Trained batch 1536 in epoch 8, gen_loss = 0.9326801404560551, disc_loss = 0.010795280312996855
Trained batch 1537 in epoch 8, gen_loss = 0.9324749742861067, disc_loss = 0.010837403836867144
Trained batch 1538 in epoch 8, gen_loss = 0.9324000220046251, disc_loss = 0.010841501753162397
Trained batch 1539 in epoch 8, gen_loss = 0.9323770930821246, disc_loss = 0.01084337256923556
Trained batch 1540 in epoch 8, gen_loss = 0.9323730552103673, disc_loss = 0.010844489665195491
Trained batch 1541 in epoch 8, gen_loss = 0.9323408578736309, disc_loss = 0.010846814185272183
Trained batch 1542 in epoch 8, gen_loss = 0.9322078558082173, disc_loss = 0.010867531204223112
Trained batch 1543 in epoch 8, gen_loss = 0.9323583812949879, disc_loss = 0.010866102524162015
Trained batch 1544 in epoch 8, gen_loss = 0.9322147843328494, disc_loss = 0.010917103534592068
Trained batch 1545 in epoch 8, gen_loss = 0.932328494080134, disc_loss = 0.010922245126369372
Trained batch 1546 in epoch 8, gen_loss = 0.9322974823063701, disc_loss = 0.010937960337298392
Trained batch 1547 in epoch 8, gen_loss = 0.9321291311343203, disc_loss = 0.010967026025954433
Trained batch 1548 in epoch 8, gen_loss = 0.9321924381251486, disc_loss = 0.01099612186439548
Trained batch 1549 in epoch 8, gen_loss = 0.9319584896679848, disc_loss = 0.011022307100577182
Trained batch 1550 in epoch 8, gen_loss = 0.9318590523311202, disc_loss = 0.011034268100943491
Trained batch 1551 in epoch 8, gen_loss = 0.9320394702678182, disc_loss = 0.011046158782823319
Trained batch 1552 in epoch 8, gen_loss = 0.9321136253730604, disc_loss = 0.0110451799390018
Trained batch 1553 in epoch 8, gen_loss = 0.9321080599090461, disc_loss = 0.011042582519503423
Trained batch 1554 in epoch 8, gen_loss = 0.9320753971288441, disc_loss = 0.011061957987508073
Trained batch 1555 in epoch 8, gen_loss = 0.9320259761342966, disc_loss = 0.011084027833669172
Trained batch 1556 in epoch 8, gen_loss = 0.9319622427627071, disc_loss = 0.011092952421996118
Trained batch 1557 in epoch 8, gen_loss = 0.9320339153261331, disc_loss = 0.01109346179389397
Trained batch 1558 in epoch 8, gen_loss = 0.9320030249679142, disc_loss = 0.01109883638663719
Trained batch 1559 in epoch 8, gen_loss = 0.9321320963784671, disc_loss = 0.011101537261012522
Trained batch 1560 in epoch 8, gen_loss = 0.9321347241558989, disc_loss = 0.011110543986251404
Trained batch 1561 in epoch 8, gen_loss = 0.9323042737422619, disc_loss = 0.01113032733608706
Trained batch 1562 in epoch 8, gen_loss = 0.932386752759045, disc_loss = 0.011135623378489636
Trained batch 1563 in epoch 8, gen_loss = 0.932416579245454, disc_loss = 0.011137985487316062
Trained batch 1564 in epoch 8, gen_loss = 0.9324686967717192, disc_loss = 0.011137240342460178
Trained batch 1565 in epoch 8, gen_loss = 0.9324420910723517, disc_loss = 0.011133550427099926
Trained batch 1566 in epoch 8, gen_loss = 0.9324153488467435, disc_loss = 0.011134502203858063
Trained batch 1567 in epoch 8, gen_loss = 0.932313468022158, disc_loss = 0.011140101469185983
Trained batch 1568 in epoch 8, gen_loss = 0.932455639785228, disc_loss = 0.011191594435090792
Trained batch 1569 in epoch 8, gen_loss = 0.9324769366888483, disc_loss = 0.011186553817293362
Trained batch 1570 in epoch 8, gen_loss = 0.9326008479926026, disc_loss = 0.01119147515774865
Trained batch 1571 in epoch 8, gen_loss = 0.9326859701794522, disc_loss = 0.01119193536917019
Trained batch 1572 in epoch 8, gen_loss = 0.9327143341094464, disc_loss = 0.011189207566736225
Trained batch 1573 in epoch 8, gen_loss = 0.9328253209174361, disc_loss = 0.011188838664100266
Trained batch 1574 in epoch 8, gen_loss = 0.932872285596908, disc_loss = 0.011183766917864208
Trained batch 1575 in epoch 8, gen_loss = 0.932942824750231, disc_loss = 0.011181499666956259
Trained batch 1576 in epoch 8, gen_loss = 0.9327545827260558, disc_loss = 0.011356125404186552
Trained batch 1577 in epoch 8, gen_loss = 0.9327586975198886, disc_loss = 0.011503880836193487
Trained batch 1578 in epoch 8, gen_loss = 0.9328112671502109, disc_loss = 0.011581184461402556
Trained batch 1579 in epoch 8, gen_loss = 0.9329667014223111, disc_loss = 0.011587994000807227
Trained batch 1580 in epoch 8, gen_loss = 0.9330236720066143, disc_loss = 0.011584402963034842
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8850116729736328, disc_loss = 0.011297754943370819
Trained batch 1 in epoch 9, gen_loss = 0.8859318792819977, disc_loss = 0.007133177248761058
Trained batch 2 in epoch 9, gen_loss = 0.9155720671017965, disc_loss = 0.006472370897730191
Trained batch 3 in epoch 9, gen_loss = 0.9607236236333847, disc_loss = 0.005585470469668508
Trained batch 4 in epoch 9, gen_loss = 0.9561983942985535, disc_loss = 0.004786658403463662
Trained batch 5 in epoch 9, gen_loss = 0.9558334648609161, disc_loss = 0.004183843324426562
Trained batch 6 in epoch 9, gen_loss = 0.9813158426965986, disc_loss = 0.0038001464646575706
Trained batch 7 in epoch 9, gen_loss = 0.9846020266413689, disc_loss = 0.00360950110189151
Trained batch 8 in epoch 9, gen_loss = 0.9863956438170539, disc_loss = 0.0037581308925938276
Trained batch 9 in epoch 9, gen_loss = 0.9764277279376984, disc_loss = 0.0037114292965270577
Trained batch 10 in epoch 9, gen_loss = 0.9664268005977977, disc_loss = 0.003630785578438504
Trained batch 11 in epoch 9, gen_loss = 0.9513356983661652, disc_loss = 0.004431703021206583
Trained batch 12 in epoch 9, gen_loss = 0.9502154038502619, disc_loss = 0.004179808875330939
Trained batch 13 in epoch 9, gen_loss = 0.9456956131117684, disc_loss = 0.006030368144690458
Trained batch 14 in epoch 9, gen_loss = 0.9296626249949137, disc_loss = 0.010292415996082127
Trained batch 15 in epoch 9, gen_loss = 0.9540888071060181, disc_loss = 0.01932635081902845
Trained batch 16 in epoch 9, gen_loss = 0.9614023741553811, disc_loss = 0.0190904313520364
Trained batch 17 in epoch 9, gen_loss = 0.9650905264748467, disc_loss = 0.018496195054871753
Trained batch 18 in epoch 9, gen_loss = 0.9630500987956399, disc_loss = 0.01771081615803077
Trained batch 19 in epoch 9, gen_loss = 0.9647050201892853, disc_loss = 0.017135213589062913
Trained batch 20 in epoch 9, gen_loss = 0.9721070925394694, disc_loss = 0.016416994217295377
Trained batch 21 in epoch 9, gen_loss = 0.9791163856332953, disc_loss = 0.015755711843005636
Trained batch 22 in epoch 9, gen_loss = 0.9823777105497278, disc_loss = 0.015214587905970604
Trained batch 23 in epoch 9, gen_loss = 0.9889874011278152, disc_loss = 0.01463381679301771
Trained batch 24 in epoch 9, gen_loss = 0.9857257246971131, disc_loss = 0.014169049086049199
Trained batch 25 in epoch 9, gen_loss = 0.9857288300991058, disc_loss = 0.013661318637717228
Trained batch 26 in epoch 9, gen_loss = 0.9851054769975168, disc_loss = 0.01321512253748046
Trained batch 27 in epoch 9, gen_loss = 0.9872034128223147, disc_loss = 0.012805130199662276
Trained batch 28 in epoch 9, gen_loss = 0.9862842313174544, disc_loss = 0.012386653736908117
Trained batch 29 in epoch 9, gen_loss = 0.9843397418657939, disc_loss = 0.012004441026753436
Trained batch 30 in epoch 9, gen_loss = 0.9822455836880591, disc_loss = 0.011648938187488144
Trained batch 31 in epoch 9, gen_loss = 0.9841392412781715, disc_loss = 0.011332121765008196
Trained batch 32 in epoch 9, gen_loss = 0.9831620671532371, disc_loss = 0.01106225967294339
Trained batch 33 in epoch 9, gen_loss = 0.9867594557649949, disc_loss = 0.010777782898752348
Trained batch 34 in epoch 9, gen_loss = 0.9881985085351127, disc_loss = 0.010521202527784875
Trained batch 35 in epoch 9, gen_loss = 0.9865567220581902, disc_loss = 0.010276567029197596
Trained batch 36 in epoch 9, gen_loss = 0.9720639513956534, disc_loss = 0.01458600429641838
Trained batch 37 in epoch 9, gen_loss = 0.9739764654322675, disc_loss = 0.014859326275702762
Trained batch 38 in epoch 9, gen_loss = 0.9781434727020752, disc_loss = 0.018223236094061762
Trained batch 39 in epoch 9, gen_loss = 0.9804649241268635, disc_loss = 0.01785389892756939
Trained batch 40 in epoch 9, gen_loss = 0.9779103652733129, disc_loss = 0.01766045200752049
Trained batch 41 in epoch 9, gen_loss = 0.9754412011021659, disc_loss = 0.017460795695937815
Trained batch 42 in epoch 9, gen_loss = 0.9765186815760857, disc_loss = 0.017167468403660974
Trained batch 43 in epoch 9, gen_loss = 0.9767706888643178, disc_loss = 0.016846697724593632
Trained batch 44 in epoch 9, gen_loss = 0.9731280439429812, disc_loss = 0.016680901528646548
Trained batch 45 in epoch 9, gen_loss = 0.9733065917440082, disc_loss = 0.0164183069769617
Trained batch 46 in epoch 9, gen_loss = 0.9673229119879134, disc_loss = 0.017290646497635766
Trained batch 47 in epoch 9, gen_loss = 0.9579346620788177, disc_loss = 0.0202238228424297
Trained batch 48 in epoch 9, gen_loss = 0.9611340195548778, disc_loss = 0.026733081341169928
Trained batch 49 in epoch 9, gen_loss = 0.9643328756093978, disc_loss = 0.027251063296571374
Trained batch 50 in epoch 9, gen_loss = 0.9646874076011134, disc_loss = 0.02680951681024596
Trained batch 51 in epoch 9, gen_loss = 0.9639315106547796, disc_loss = 0.02643839439126448
Trained batch 52 in epoch 9, gen_loss = 0.9638722398371067, disc_loss = 0.02602416859447675
Trained batch 53 in epoch 9, gen_loss = 0.9651304246098907, disc_loss = 0.025605992073434645
Trained batch 54 in epoch 9, gen_loss = 0.965411548722874, disc_loss = 0.025181094586679883
Trained batch 55 in epoch 9, gen_loss = 0.9651218477104392, disc_loss = 0.024748458949034102
Trained batch 56 in epoch 9, gen_loss = 0.9634400580013007, disc_loss = 0.02434720313625835
Trained batch 57 in epoch 9, gen_loss = 0.9626142058906884, disc_loss = 0.023946661217106056
Trained batch 58 in epoch 9, gen_loss = 0.9625606056997331, disc_loss = 0.02356885420947762
Trained batch 59 in epoch 9, gen_loss = 0.9635725781321526, disc_loss = 0.023193711273294563
Trained batch 60 in epoch 9, gen_loss = 0.9630140344627568, disc_loss = 0.022828979247829832
Trained batch 61 in epoch 9, gen_loss = 0.9625340310796615, disc_loss = 0.022473030353731084
Trained batch 62 in epoch 9, gen_loss = 0.9632593180452075, disc_loss = 0.022129035187101673
Trained batch 63 in epoch 9, gen_loss = 0.9616068783216178, disc_loss = 0.021793643942146446
Trained batch 64 in epoch 9, gen_loss = 0.9628388803738814, disc_loss = 0.021476238545101996
Trained batch 65 in epoch 9, gen_loss = 0.9630380295442812, disc_loss = 0.021168456658029532
Trained batch 66 in epoch 9, gen_loss = 0.9635397840791674, disc_loss = 0.02085903453651065
Trained batch 67 in epoch 9, gen_loss = 0.9623361988102689, disc_loss = 0.02056307662261294
Trained batch 68 in epoch 9, gen_loss = 0.96166952667029, disc_loss = 0.02027678791352588
Trained batch 69 in epoch 9, gen_loss = 0.9618429460695812, disc_loss = 0.019994130311533808
Trained batch 70 in epoch 9, gen_loss = 0.9621581162365389, disc_loss = 0.019720601252424464
Trained batch 71 in epoch 9, gen_loss = 0.9623645680646101, disc_loss = 0.01945453050817984
Trained batch 72 in epoch 9, gen_loss = 0.9642584425945805, disc_loss = 0.01919863129446079
Trained batch 73 in epoch 9, gen_loss = 0.9656891150249017, disc_loss = 0.018946169647451088
Trained batch 74 in epoch 9, gen_loss = 0.9671802000204722, disc_loss = 0.01870634526014328
Trained batch 75 in epoch 9, gen_loss = 0.9650528544658109, disc_loss = 0.01847210123914441
Trained batch 76 in epoch 9, gen_loss = 0.9638884837751265, disc_loss = 0.01824536718815178
Trained batch 77 in epoch 9, gen_loss = 0.9642629420910126, disc_loss = 0.018021146435505495
Trained batch 78 in epoch 9, gen_loss = 0.9620106261742266, disc_loss = 0.017800179874536262
Trained batch 79 in epoch 9, gen_loss = 0.9610094118863344, disc_loss = 0.01758358766128367
Trained batch 80 in epoch 9, gen_loss = 0.9598958378220782, disc_loss = 0.017373865805523196
Trained batch 81 in epoch 9, gen_loss = 0.959993657905881, disc_loss = 0.017168148334504377
Trained batch 82 in epoch 9, gen_loss = 0.9611615075404385, disc_loss = 0.01697361581230884
Trained batch 83 in epoch 9, gen_loss = 0.9610816201283818, disc_loss = 0.016775080262353487
Trained batch 84 in epoch 9, gen_loss = 0.9600648413686191, disc_loss = 0.016584900958011583
Trained batch 85 in epoch 9, gen_loss = 0.9586958951035212, disc_loss = 0.016399739016061322
Trained batch 86 in epoch 9, gen_loss = 0.9584310133566801, disc_loss = 0.016215502981286517
Trained batch 87 in epoch 9, gen_loss = 0.9578895585780794, disc_loss = 0.01603637519457896
Trained batch 88 in epoch 9, gen_loss = 0.9582570312398203, disc_loss = 0.015860715158299406
Trained batch 89 in epoch 9, gen_loss = 0.9589090668492847, disc_loss = 0.015688571885564467
Trained batch 90 in epoch 9, gen_loss = 0.9583693955625806, disc_loss = 0.015520311763464054
Trained batch 91 in epoch 9, gen_loss = 0.9569002807788227, disc_loss = 0.015365447716802642
Trained batch 92 in epoch 9, gen_loss = 0.9558403386223701, disc_loss = 0.015205174420399451
Trained batch 93 in epoch 9, gen_loss = 0.9552130188713682, disc_loss = 0.015050473463216281
Trained batch 94 in epoch 9, gen_loss = 0.9544986232330924, disc_loss = 0.01489641413883012
Trained batch 95 in epoch 9, gen_loss = 0.9538671346381307, disc_loss = 0.014744180230688167
Trained batch 96 in epoch 9, gen_loss = 0.9537062051984453, disc_loss = 0.014595174248937574
Trained batch 97 in epoch 9, gen_loss = 0.9535810920048733, disc_loss = 0.014449445514735405
Trained batch 98 in epoch 9, gen_loss = 0.9529571102725135, disc_loss = 0.01430820892247456
Trained batch 99 in epoch 9, gen_loss = 0.9530814453959465, disc_loss = 0.014168364023207687
Trained batch 100 in epoch 9, gen_loss = 0.9520361798234506, disc_loss = 0.01403595616817382
Trained batch 101 in epoch 9, gen_loss = 0.952316420043216, disc_loss = 0.013902700767514533
Trained batch 102 in epoch 9, gen_loss = 0.9524677155665981, disc_loss = 0.0137706700954315
Trained batch 103 in epoch 9, gen_loss = 0.9513298963698057, disc_loss = 0.013651551490721222
Trained batch 104 in epoch 9, gen_loss = 0.9501122369652703, disc_loss = 0.013525067077993991
Trained batch 105 in epoch 9, gen_loss = 0.9503500458766829, disc_loss = 0.013402449482731204
Trained batch 106 in epoch 9, gen_loss = 0.9503036010488172, disc_loss = 0.0132802604476238
Trained batch 107 in epoch 9, gen_loss = 0.9503754253188769, disc_loss = 0.013159976061110178
Trained batch 108 in epoch 9, gen_loss = 0.9505183868998781, disc_loss = 0.013041792797894481
Trained batch 109 in epoch 9, gen_loss = 0.9504566114057195, disc_loss = 0.0129270850593457
Trained batch 110 in epoch 9, gen_loss = 0.9503873326219954, disc_loss = 0.012815262490688395
Trained batch 111 in epoch 9, gen_loss = 0.9497765848147017, disc_loss = 0.0127048699975733
Trained batch 112 in epoch 9, gen_loss = 0.9481703093094108, disc_loss = 0.012717529380564224
Trained batch 113 in epoch 9, gen_loss = 0.9436652550571843, disc_loss = 0.014170361494108332
Trained batch 114 in epoch 9, gen_loss = 0.9428849536439646, disc_loss = 0.01455348238435007
Trained batch 115 in epoch 9, gen_loss = 0.945613749582192, disc_loss = 0.01469655123720917
Trained batch 116 in epoch 9, gen_loss = 0.9479479122365642, disc_loss = 0.014701002579168456
Trained batch 117 in epoch 9, gen_loss = 0.9487325907763788, disc_loss = 0.01460034274264294
Trained batch 118 in epoch 9, gen_loss = 0.9489011443963572, disc_loss = 0.015379903762955453
Trained batch 119 in epoch 9, gen_loss = 0.9489207550883293, disc_loss = 0.01551924807645264
Trained batch 120 in epoch 9, gen_loss = 0.9486339909971253, disc_loss = 0.015560982690417892
Trained batch 121 in epoch 9, gen_loss = 0.9488695561885834, disc_loss = 0.015463495813357857
Trained batch 122 in epoch 9, gen_loss = 0.9489744092390789, disc_loss = 0.01536328934168072
Trained batch 123 in epoch 9, gen_loss = 0.9488119011925112, disc_loss = 0.015259246350568344
Trained batch 124 in epoch 9, gen_loss = 0.9495377159118652, disc_loss = 0.015153984877513722
Trained batch 125 in epoch 9, gen_loss = 0.9505108083997454, disc_loss = 0.01504689991027893
Trained batch 126 in epoch 9, gen_loss = 0.9502936967714565, disc_loss = 0.014938016118908918
Trained batch 127 in epoch 9, gen_loss = 0.9494872526265681, disc_loss = 0.014830442115680853
Trained batch 128 in epoch 9, gen_loss = 0.9485877743063047, disc_loss = 0.014725603994619202
Trained batch 129 in epoch 9, gen_loss = 0.9478779856975262, disc_loss = 0.014623447049346466
Trained batch 130 in epoch 9, gen_loss = 0.9474764862133347, disc_loss = 0.014521106848544761
Trained batch 131 in epoch 9, gen_loss = 0.9469809459917473, disc_loss = 0.014416427315595545
Trained batch 132 in epoch 9, gen_loss = 0.947813397959659, disc_loss = 0.014319531809708411
Trained batch 133 in epoch 9, gen_loss = 0.9479246619922012, disc_loss = 0.014226893212606282
Trained batch 134 in epoch 9, gen_loss = 0.9466617425282796, disc_loss = 0.01419421349483956
Trained batch 135 in epoch 9, gen_loss = 0.9478315991513869, disc_loss = 0.014113335777116898
Trained batch 136 in epoch 9, gen_loss = 0.9481118491096218, disc_loss = 0.014027037755730665
Trained batch 137 in epoch 9, gen_loss = 0.9491938922716223, disc_loss = 0.013988480494278348
Trained batch 138 in epoch 9, gen_loss = 0.9455320706470407, disc_loss = 0.017034677168222063
Trained batch 139 in epoch 9, gen_loss = 0.9476733999592918, disc_loss = 0.017397251388631827
Trained batch 140 in epoch 9, gen_loss = 0.9486614093712881, disc_loss = 0.01780493745967541
Trained batch 141 in epoch 9, gen_loss = 0.9496464082892512, disc_loss = 0.017870224378781694
Trained batch 142 in epoch 9, gen_loss = 0.9495023130536913, disc_loss = 0.017799716165421166
Trained batch 143 in epoch 9, gen_loss = 0.9490409116778109, disc_loss = 0.017735034469296806
Trained batch 144 in epoch 9, gen_loss = 0.9462852736999249, disc_loss = 0.01867924377197753
Trained batch 145 in epoch 9, gen_loss = 0.9462879165394665, disc_loss = 0.018623229322918333
Trained batch 146 in epoch 9, gen_loss = 0.946473608617069, disc_loss = 0.01996084677984425
Trained batch 147 in epoch 9, gen_loss = 0.945839645492064, disc_loss = 0.01986236696236144
Trained batch 148 in epoch 9, gen_loss = 0.9449692352506138, disc_loss = 0.019805048651182273
Trained batch 149 in epoch 9, gen_loss = 0.9442032655080159, disc_loss = 0.019713173160368268
Trained batch 150 in epoch 9, gen_loss = 0.9438199693004027, disc_loss = 0.01960522450282337
Trained batch 151 in epoch 9, gen_loss = 0.9433928935935623, disc_loss = 0.01948631252947196
Trained batch 152 in epoch 9, gen_loss = 0.9441572119987088, disc_loss = 0.019374300700078225
Trained batch 153 in epoch 9, gen_loss = 0.9442842637563681, disc_loss = 0.019253724290008125
Trained batch 154 in epoch 9, gen_loss = 0.9452037668997242, disc_loss = 0.019139616055256357
Trained batch 155 in epoch 9, gen_loss = 0.942957437191254, disc_loss = 0.01988872189208334
Trained batch 156 in epoch 9, gen_loss = 0.9450302632750979, disc_loss = 0.0198586556641904
Trained batch 157 in epoch 9, gen_loss = 0.9460045499137685, disc_loss = 0.019950377680265485
Trained batch 158 in epoch 9, gen_loss = 0.9470682953888515, disc_loss = 0.01984183278001417
Trained batch 159 in epoch 9, gen_loss = 0.947030770778656, disc_loss = 0.01973453411974333
Trained batch 160 in epoch 9, gen_loss = 0.9474371886401443, disc_loss = 0.019629049287517467
Trained batch 161 in epoch 9, gen_loss = 0.9480726328896888, disc_loss = 0.01955240269182221
Trained batch 162 in epoch 9, gen_loss = 0.9488820663990418, disc_loss = 0.019444156066547404
Trained batch 163 in epoch 9, gen_loss = 0.9489210582360988, disc_loss = 0.019339266242906623
Trained batch 164 in epoch 9, gen_loss = 0.9492019642483104, disc_loss = 0.01923173437738142
Trained batch 165 in epoch 9, gen_loss = 0.9496733312865338, disc_loss = 0.019121610358075507
Trained batch 166 in epoch 9, gen_loss = 0.9504728920445471, disc_loss = 0.019013561964178638
Trained batch 167 in epoch 9, gen_loss = 0.9512503924114364, disc_loss = 0.018908130126094744
Trained batch 168 in epoch 9, gen_loss = 0.9518531726662224, disc_loss = 0.01880364161526878
Trained batch 169 in epoch 9, gen_loss = 0.9520347924793467, disc_loss = 0.018696738603038658
Trained batch 170 in epoch 9, gen_loss = 0.9524337875912761, disc_loss = 0.01859580280483232
Trained batch 171 in epoch 9, gen_loss = 0.9527458014876343, disc_loss = 0.01849153031798778
Trained batch 172 in epoch 9, gen_loss = 0.9527900852908978, disc_loss = 0.01838979716200753
Trained batch 173 in epoch 9, gen_loss = 0.9526899539191147, disc_loss = 0.01828803491210645
Trained batch 174 in epoch 9, gen_loss = 0.9523971496309553, disc_loss = 0.01820595932442562
Trained batch 175 in epoch 9, gen_loss = 0.951951648701321, disc_loss = 0.01812768980330888
Trained batch 176 in epoch 9, gen_loss = 0.9530465724104542, disc_loss = 0.018030059920975117
Trained batch 177 in epoch 9, gen_loss = 0.9532214470123976, disc_loss = 0.01793895486733756
Trained batch 178 in epoch 9, gen_loss = 0.9529226402330665, disc_loss = 0.017844627049261205
Trained batch 179 in epoch 9, gen_loss = 0.9528230140606563, disc_loss = 0.01775252306947045
Trained batch 180 in epoch 9, gen_loss = 0.9534228154308888, disc_loss = 0.017657451145254455
Trained batch 181 in epoch 9, gen_loss = 0.9539475070906209, disc_loss = 0.0175633083935891
Trained batch 182 in epoch 9, gen_loss = 0.9539637738238267, disc_loss = 0.017470647544502102
Trained batch 183 in epoch 9, gen_loss = 0.954218251225741, disc_loss = 0.017379691929818364
Trained batch 184 in epoch 9, gen_loss = 0.9548621677063607, disc_loss = 0.017289601752024798
Trained batch 185 in epoch 9, gen_loss = 0.9549721008346926, disc_loss = 0.017199742794756636
Trained batch 186 in epoch 9, gen_loss = 0.9553304518607848, disc_loss = 0.01711425076305423
Trained batch 187 in epoch 9, gen_loss = 0.9553997833678063, disc_loss = 0.017026632138251754
Trained batch 188 in epoch 9, gen_loss = 0.9551656198880029, disc_loss = 0.016940076012384866
Trained batch 189 in epoch 9, gen_loss = 0.9550276953923075, disc_loss = 0.016854054555388805
Trained batch 190 in epoch 9, gen_loss = 0.9545081139234972, disc_loss = 0.016768295494796883
Trained batch 191 in epoch 9, gen_loss = 0.9542954172939062, disc_loss = 0.016683296134488046
Trained batch 192 in epoch 9, gen_loss = 0.954647512015901, disc_loss = 0.016599856833523198
Trained batch 193 in epoch 9, gen_loss = 0.9545846040715876, disc_loss = 0.016522624073388083
Trained batch 194 in epoch 9, gen_loss = 0.9551913560965122, disc_loss = 0.016448060850141187
Trained batch 195 in epoch 9, gen_loss = 0.9549086191216294, disc_loss = 0.016367540688388173
Trained batch 196 in epoch 9, gen_loss = 0.9545334973916184, disc_loss = 0.016287684584359124
Trained batch 197 in epoch 9, gen_loss = 0.9545317370482166, disc_loss = 0.01620794949018881
Trained batch 198 in epoch 9, gen_loss = 0.954513040319759, disc_loss = 0.016128338644212
Trained batch 199 in epoch 9, gen_loss = 0.9549527671933175, disc_loss = 0.016052359017339767
Trained batch 200 in epoch 9, gen_loss = 0.9545555206673655, disc_loss = 0.015978806802281295
Trained batch 201 in epoch 9, gen_loss = 0.9541768233964939, disc_loss = 0.01590486357318777
Trained batch 202 in epoch 9, gen_loss = 0.9547142310095538, disc_loss = 0.015831771153145758
Trained batch 203 in epoch 9, gen_loss = 0.9549744950205672, disc_loss = 0.015757273172294292
Trained batch 204 in epoch 9, gen_loss = 0.9550971185288778, disc_loss = 0.015683249661148094
Trained batch 205 in epoch 9, gen_loss = 0.9553205830958283, disc_loss = 0.015610203645514206
Trained batch 206 in epoch 9, gen_loss = 0.9555985821042083, disc_loss = 0.015536911358324594
Trained batch 207 in epoch 9, gen_loss = 0.9557836620280376, disc_loss = 0.015465433693512191
Trained batch 208 in epoch 9, gen_loss = 0.9555886664459009, disc_loss = 0.015395219723385442
Trained batch 209 in epoch 9, gen_loss = 0.9561282067071823, disc_loss = 0.015325713996259895
Trained batch 210 in epoch 9, gen_loss = 0.9564187775290973, disc_loss = 0.01525657594033464
Trained batch 211 in epoch 9, gen_loss = 0.9568369579765031, disc_loss = 0.015187388827847448
Trained batch 212 in epoch 9, gen_loss = 0.9572369649376667, disc_loss = 0.015118893061435514
Trained batch 213 in epoch 9, gen_loss = 0.9567229848041713, disc_loss = 0.015053059664640845
Trained batch 214 in epoch 9, gen_loss = 0.9570113908412845, disc_loss = 0.014986243934051112
Trained batch 215 in epoch 9, gen_loss = 0.956496685191437, disc_loss = 0.014921274026602515
Trained batch 216 in epoch 9, gen_loss = 0.9559168711235996, disc_loss = 0.014901919280900941
Trained batch 217 in epoch 9, gen_loss = 0.9554527073825171, disc_loss = 0.014840055711128442
Trained batch 218 in epoch 9, gen_loss = 0.9554012287152956, disc_loss = 0.014776589162993249
Trained batch 219 in epoch 9, gen_loss = 0.9550575665452263, disc_loss = 0.014713369776224929
Trained batch 220 in epoch 9, gen_loss = 0.954948484358205, disc_loss = 0.014652316130479646
Trained batch 221 in epoch 9, gen_loss = 0.9547400195319373, disc_loss = 0.014591060325672204
Trained batch 222 in epoch 9, gen_loss = 0.9546250358825307, disc_loss = 0.014529872248330333
Trained batch 223 in epoch 9, gen_loss = 0.9544247199914285, disc_loss = 0.014471978642047491
Trained batch 224 in epoch 9, gen_loss = 0.954933939245012, disc_loss = 0.014415728389932256
Trained batch 225 in epoch 9, gen_loss = 0.9549677704287841, disc_loss = 0.014354968325681037
Trained batch 226 in epoch 9, gen_loss = 0.95495647270774, disc_loss = 0.014303995766764145
Trained batch 227 in epoch 9, gen_loss = 0.9554889568111353, disc_loss = 0.01424698981013774
Trained batch 228 in epoch 9, gen_loss = 0.9561920551233417, disc_loss = 0.014189245552561697
Trained batch 229 in epoch 9, gen_loss = 0.9560164443824603, disc_loss = 0.014131012521608246
Trained batch 230 in epoch 9, gen_loss = 0.9565507898599038, disc_loss = 0.014074436431368652
Trained batch 231 in epoch 9, gen_loss = 0.9567734360181052, disc_loss = 0.014021281355812319
Trained batch 232 in epoch 9, gen_loss = 0.956713931499121, disc_loss = 0.013964891717134668
Trained batch 233 in epoch 9, gen_loss = 0.9568013408754625, disc_loss = 0.01391081910186873
Trained batch 234 in epoch 9, gen_loss = 0.9567291865957545, disc_loss = 0.013855112274053526
Trained batch 235 in epoch 9, gen_loss = 0.9568649204605717, disc_loss = 0.013800057888764027
Trained batch 236 in epoch 9, gen_loss = 0.9572342757434281, disc_loss = 0.013748532497959667
Trained batch 237 in epoch 9, gen_loss = 0.9569901100226811, disc_loss = 0.013699836428194041
Trained batch 238 in epoch 9, gen_loss = 0.9570863785604053, disc_loss = 0.01364789797257628
Trained batch 239 in epoch 9, gen_loss = 0.9572017468512058, disc_loss = 0.013593754024259396
Trained batch 240 in epoch 9, gen_loss = 0.9569436074292511, disc_loss = 0.013553949396963583
Trained batch 241 in epoch 9, gen_loss = 0.957220831685815, disc_loss = 0.013506307485412367
Trained batch 242 in epoch 9, gen_loss = 0.9572393869666896, disc_loss = 0.013460086400255583
Trained batch 243 in epoch 9, gen_loss = 0.9573480907033701, disc_loss = 0.013408406063285465
Trained batch 244 in epoch 9, gen_loss = 0.9572468078866296, disc_loss = 0.013356583471509762
Trained batch 245 in epoch 9, gen_loss = 0.9564478877114087, disc_loss = 0.013477642737576033
Trained batch 246 in epoch 9, gen_loss = 0.9570913671964576, disc_loss = 0.01344734879867136
Trained batch 247 in epoch 9, gen_loss = 0.9577649860612808, disc_loss = 0.013418050634138654
Trained batch 248 in epoch 9, gen_loss = 0.9576539598315595, disc_loss = 0.01354682122473605
Trained batch 249 in epoch 9, gen_loss = 0.9574839212894439, disc_loss = 0.013508818012778647
Trained batch 250 in epoch 9, gen_loss = 0.9569703072190759, disc_loss = 0.013469162694966064
Trained batch 251 in epoch 9, gen_loss = 0.9574097170243188, disc_loss = 0.013426824205943997
Trained batch 252 in epoch 9, gen_loss = 0.9574961996832384, disc_loss = 0.013384878888598316
Trained batch 253 in epoch 9, gen_loss = 0.9572437382119847, disc_loss = 0.013334641193784956
Trained batch 254 in epoch 9, gen_loss = 0.9571751795563044, disc_loss = 0.013284693137336266
Trained batch 255 in epoch 9, gen_loss = 0.9574607103131711, disc_loss = 0.013240604996440197
Trained batch 256 in epoch 9, gen_loss = 0.9573175774937938, disc_loss = 0.013191610693289257
Trained batch 257 in epoch 9, gen_loss = 0.9575809127138567, disc_loss = 0.013143075301691839
Trained batch 258 in epoch 9, gen_loss = 0.9573373819870378, disc_loss = 0.013095060311384592
Trained batch 259 in epoch 9, gen_loss = 0.957612869143486, disc_loss = 0.013046616769973369
Trained batch 260 in epoch 9, gen_loss = 0.9574917116384397, disc_loss = 0.01299853856290398
Trained batch 261 in epoch 9, gen_loss = 0.9571141013662323, disc_loss = 0.012950554553962327
Trained batch 262 in epoch 9, gen_loss = 0.956993524112629, disc_loss = 0.012903685484434737
Trained batch 263 in epoch 9, gen_loss = 0.9570631344210018, disc_loss = 0.012857399060136011
Trained batch 264 in epoch 9, gen_loss = 0.9570534166300072, disc_loss = 0.01281120507057563
Trained batch 265 in epoch 9, gen_loss = 0.9571822890661713, disc_loss = 0.012765948658811692
Trained batch 266 in epoch 9, gen_loss = 0.9568611305304681, disc_loss = 0.012720007856733127
Trained batch 267 in epoch 9, gen_loss = 0.95730783668027, disc_loss = 0.012674397601830293
Trained batch 268 in epoch 9, gen_loss = 0.9571671257674915, disc_loss = 0.0126285557627555
Trained batch 269 in epoch 9, gen_loss = 0.9572200468292943, disc_loss = 0.012583243443751363
Trained batch 270 in epoch 9, gen_loss = 0.9572036495067977, disc_loss = 0.012538203813446638
Trained batch 271 in epoch 9, gen_loss = 0.9573765883550924, disc_loss = 0.0124992502227114
Trained batch 272 in epoch 9, gen_loss = 0.9578742684025467, disc_loss = 0.012455892037419473
Trained batch 273 in epoch 9, gen_loss = 0.957704641088082, disc_loss = 0.012414146402517647
Trained batch 274 in epoch 9, gen_loss = 0.9573486299948258, disc_loss = 0.012373296670107678
Trained batch 275 in epoch 9, gen_loss = 0.957350410413051, disc_loss = 0.01232976850081721
Trained batch 276 in epoch 9, gen_loss = 0.9574240878600937, disc_loss = 0.012286817002285016
Trained batch 277 in epoch 9, gen_loss = 0.9578542732935158, disc_loss = 0.012246681832483963
Trained batch 278 in epoch 9, gen_loss = 0.9576929433798704, disc_loss = 0.01220397001856731
Trained batch 279 in epoch 9, gen_loss = 0.9575177045805113, disc_loss = 0.012162298900407872
Trained batch 280 in epoch 9, gen_loss = 0.9575926784518775, disc_loss = 0.012121620346473868
Trained batch 281 in epoch 9, gen_loss = 0.9577509665742834, disc_loss = 0.012080083400752489
Trained batch 282 in epoch 9, gen_loss = 0.9575828278022605, disc_loss = 0.012038854497086665
Trained batch 283 in epoch 9, gen_loss = 0.9574647799763881, disc_loss = 0.011998021141088954
Trained batch 284 in epoch 9, gen_loss = 0.957178130693603, disc_loss = 0.011960133286131743
Trained batch 285 in epoch 9, gen_loss = 0.9572202281935231, disc_loss = 0.01191924073457819
Trained batch 286 in epoch 9, gen_loss = 0.9571387904861662, disc_loss = 0.011879603453414541
Trained batch 287 in epoch 9, gen_loss = 0.9570762039058738, disc_loss = 0.011839227381541504
Trained batch 288 in epoch 9, gen_loss = 0.9572819727102365, disc_loss = 0.011800513811555296
Trained batch 289 in epoch 9, gen_loss = 0.9572870513488506, disc_loss = 0.011760456973771115
Trained batch 290 in epoch 9, gen_loss = 0.9571222980407506, disc_loss = 0.011721166236709348
Trained batch 291 in epoch 9, gen_loss = 0.9569450337184618, disc_loss = 0.011682263111726744
Trained batch 292 in epoch 9, gen_loss = 0.9571466199773977, disc_loss = 0.011643717727689835
Trained batch 293 in epoch 9, gen_loss = 0.9572297896252198, disc_loss = 0.011605115812592569
Trained batch 294 in epoch 9, gen_loss = 0.957412972086567, disc_loss = 0.011568091924882383
Trained batch 295 in epoch 9, gen_loss = 0.9571710700118864, disc_loss = 0.01153047049759865
Trained batch 296 in epoch 9, gen_loss = 0.9574516682512431, disc_loss = 0.011493591900686781
Trained batch 297 in epoch 9, gen_loss = 0.9571856880348001, disc_loss = 0.011457304759423761
Trained batch 298 in epoch 9, gen_loss = 0.9568075567583575, disc_loss = 0.011420848847224368
Trained batch 299 in epoch 9, gen_loss = 0.9569155271848043, disc_loss = 0.01138441944795583
Trained batch 300 in epoch 9, gen_loss = 0.9565765845815208, disc_loss = 0.011347837033631292
Trained batch 301 in epoch 9, gen_loss = 0.9561876822386356, disc_loss = 0.011311410889372582
Trained batch 302 in epoch 9, gen_loss = 0.955968966185063, disc_loss = 0.011275285685211328
Trained batch 303 in epoch 9, gen_loss = 0.9555784634461528, disc_loss = 0.011239469355993941
Trained batch 304 in epoch 9, gen_loss = 0.9558002423067562, disc_loss = 0.011204685929009965
Trained batch 305 in epoch 9, gen_loss = 0.9556751471329359, disc_loss = 0.01116926425510981
Trained batch 306 in epoch 9, gen_loss = 0.9559033412110145, disc_loss = 0.01113424973136894
Trained batch 307 in epoch 9, gen_loss = 0.9559251567373028, disc_loss = 0.011098889797911208
Trained batch 308 in epoch 9, gen_loss = 0.9558041157460135, disc_loss = 0.01106459053986198
Trained batch 309 in epoch 9, gen_loss = 0.9557632703934946, disc_loss = 0.011029614240631477
Trained batch 310 in epoch 9, gen_loss = 0.9555127222055024, disc_loss = 0.010995275759891685
Trained batch 311 in epoch 9, gen_loss = 0.95517330769545, disc_loss = 0.010960665220129439
Trained batch 312 in epoch 9, gen_loss = 0.9552340532263247, disc_loss = 0.010927373328450368
Trained batch 313 in epoch 9, gen_loss = 0.9552993958543061, disc_loss = 0.010893123913554483
Trained batch 314 in epoch 9, gen_loss = 0.9552188305627732, disc_loss = 0.010859822072061001
Trained batch 315 in epoch 9, gen_loss = 0.9551783698269084, disc_loss = 0.010826345512271738
Trained batch 316 in epoch 9, gen_loss = 0.9550910266791984, disc_loss = 0.010796233460559416
Trained batch 317 in epoch 9, gen_loss = 0.9547187511651021, disc_loss = 0.010763074231431776
Trained batch 318 in epoch 9, gen_loss = 0.9550200355090318, disc_loss = 0.010731128840128815
Trained batch 319 in epoch 9, gen_loss = 0.9546435669064521, disc_loss = 0.010698615287265057
Trained batch 320 in epoch 9, gen_loss = 0.9546678055112607, disc_loss = 0.01066621944129306
Trained batch 321 in epoch 9, gen_loss = 0.954904169769761, disc_loss = 0.010634973599882407
Trained batch 322 in epoch 9, gen_loss = 0.9549282375873058, disc_loss = 0.010602975153407851
Trained batch 323 in epoch 9, gen_loss = 0.9548102019377697, disc_loss = 0.01057190006444508
Trained batch 324 in epoch 9, gen_loss = 0.9546237459549537, disc_loss = 0.010540153490907799
Trained batch 325 in epoch 9, gen_loss = 0.9545446552016252, disc_loss = 0.01050867569864766
Trained batch 326 in epoch 9, gen_loss = 0.9545106222505598, disc_loss = 0.010477427597681348
Trained batch 327 in epoch 9, gen_loss = 0.9544788666251229, disc_loss = 0.010446033924958234
Trained batch 328 in epoch 9, gen_loss = 0.9545267072129757, disc_loss = 0.010415578664711812
Trained batch 329 in epoch 9, gen_loss = 0.954246847557299, disc_loss = 0.010384930830993901
Trained batch 330 in epoch 9, gen_loss = 0.9542177850746316, disc_loss = 0.010354279049714744
Trained batch 331 in epoch 9, gen_loss = 0.9542726062866579, disc_loss = 0.01032395262334458
Trained batch 332 in epoch 9, gen_loss = 0.9541978571150038, disc_loss = 0.010293722217603636
Trained batch 333 in epoch 9, gen_loss = 0.9539728596538841, disc_loss = 0.010263504719382227
Trained batch 334 in epoch 9, gen_loss = 0.9540240542212529, disc_loss = 0.010233667970299652
Trained batch 335 in epoch 9, gen_loss = 0.9540744345812571, disc_loss = 0.01020374648777804
Trained batch 336 in epoch 9, gen_loss = 0.9538189066623721, disc_loss = 0.010174224354815185
Trained batch 337 in epoch 9, gen_loss = 0.9538249680276453, disc_loss = 0.010145206472453436
Trained batch 338 in epoch 9, gen_loss = 0.9536180640392247, disc_loss = 0.010115689069304304
Trained batch 339 in epoch 9, gen_loss = 0.9533682891551186, disc_loss = 0.01008641665090074
Trained batch 340 in epoch 9, gen_loss = 0.9531776008368238, disc_loss = 0.010057649962698612
Trained batch 341 in epoch 9, gen_loss = 0.9533467768577107, disc_loss = 0.010029416169696529
Trained batch 342 in epoch 9, gen_loss = 0.9533875018097568, disc_loss = 0.010001523030961527
Trained batch 343 in epoch 9, gen_loss = 0.9534903948390206, disc_loss = 0.009973307718567857
Trained batch 344 in epoch 9, gen_loss = 0.9538372893264329, disc_loss = 0.009949281321462257
Trained batch 345 in epoch 9, gen_loss = 0.9537901866298191, disc_loss = 0.009921703142131815
Trained batch 346 in epoch 9, gen_loss = 0.9537246520993345, disc_loss = 0.00989461554619799
Trained batch 347 in epoch 9, gen_loss = 0.9535765217981119, disc_loss = 0.009867013440741394
Trained batch 348 in epoch 9, gen_loss = 0.9535749131082464, disc_loss = 0.00983967988143567
Trained batch 349 in epoch 9, gen_loss = 0.9536445186819349, disc_loss = 0.009812275093738988
Trained batch 350 in epoch 9, gen_loss = 0.9537664373376091, disc_loss = 0.009785159506881145
Trained batch 351 in epoch 9, gen_loss = 0.953606499528343, disc_loss = 0.009758249596540158
Trained batch 352 in epoch 9, gen_loss = 0.9534000921519552, disc_loss = 0.009732251335487822
Trained batch 353 in epoch 9, gen_loss = 0.9532999815577168, disc_loss = 0.00970521297151753
Trained batch 354 in epoch 9, gen_loss = 0.9535253059696144, disc_loss = 0.009678533072312834
Trained batch 355 in epoch 9, gen_loss = 0.9535161124521427, disc_loss = 0.009651814608056728
Trained batch 356 in epoch 9, gen_loss = 0.9533893619598794, disc_loss = 0.009625510149121778
Trained batch 357 in epoch 9, gen_loss = 0.9533188001736582, disc_loss = 0.009599445839927924
Trained batch 358 in epoch 9, gen_loss = 0.9529973180513196, disc_loss = 0.009573485949820926
Trained batch 359 in epoch 9, gen_loss = 0.9532189456952943, disc_loss = 0.009548009952696803
Trained batch 360 in epoch 9, gen_loss = 0.9531165237572055, disc_loss = 0.009522081501756142
Trained batch 361 in epoch 9, gen_loss = 0.9534612283192946, disc_loss = 0.009498442758584797
Trained batch 362 in epoch 9, gen_loss = 0.9535210974945509, disc_loss = 0.009473833733157463
Trained batch 363 in epoch 9, gen_loss = 0.9536154451933536, disc_loss = 0.009448416412911623
Trained batch 364 in epoch 9, gen_loss = 0.9535845042908029, disc_loss = 0.00942344522814917
Trained batch 365 in epoch 9, gen_loss = 0.9536091318873109, disc_loss = 0.009398847733925814
Trained batch 366 in epoch 9, gen_loss = 0.9536965716762179, disc_loss = 0.009373956344696904
Trained batch 367 in epoch 9, gen_loss = 0.9538147830120896, disc_loss = 0.00934948988635923
Trained batch 368 in epoch 9, gen_loss = 0.9536929913975682, disc_loss = 0.009324659725277606
Trained batch 369 in epoch 9, gen_loss = 0.9534320472060023, disc_loss = 0.009299954580539536
Trained batch 370 in epoch 9, gen_loss = 0.9533042176714484, disc_loss = 0.009275334473869405
Trained batch 371 in epoch 9, gen_loss = 0.9530200181148385, disc_loss = 0.009250853596469863
Trained batch 372 in epoch 9, gen_loss = 0.9526799557675625, disc_loss = 0.00922665766399134
Trained batch 373 in epoch 9, gen_loss = 0.9525960506921146, disc_loss = 0.009202530548206212
Trained batch 374 in epoch 9, gen_loss = 0.9524264861742655, disc_loss = 0.009178453256026842
Trained batch 375 in epoch 9, gen_loss = 0.9523163350655678, disc_loss = 0.00915461989666739
Trained batch 376 in epoch 9, gen_loss = 0.9525622776079558, disc_loss = 0.009130866748428427
Trained batch 377 in epoch 9, gen_loss = 0.9522752318748091, disc_loss = 0.009107330133528671
Trained batch 378 in epoch 9, gen_loss = 0.9524649968247929, disc_loss = 0.009083876373307131
Trained batch 379 in epoch 9, gen_loss = 0.9521312897142611, disc_loss = 0.009061089159436769
Trained batch 380 in epoch 9, gen_loss = 0.9524271032941622, disc_loss = 0.009037949067230025
Trained batch 381 in epoch 9, gen_loss = 0.9525469458852139, disc_loss = 0.009015598133235624
Trained batch 382 in epoch 9, gen_loss = 0.9524839893956097, disc_loss = 0.008992842014382932
Trained batch 383 in epoch 9, gen_loss = 0.9522226452827454, disc_loss = 0.00897004068485785
Trained batch 384 in epoch 9, gen_loss = 0.9525987086358009, disc_loss = 0.008948608313032498
Trained batch 385 in epoch 9, gen_loss = 0.9527677763929021, disc_loss = 0.008926634691193293
Trained batch 386 in epoch 9, gen_loss = 0.9524234348489332, disc_loss = 0.008904163498295778
Trained batch 387 in epoch 9, gen_loss = 0.952396451505189, disc_loss = 0.008882713736853738
Trained batch 388 in epoch 9, gen_loss = 0.9522424038394252, disc_loss = 0.008860384277187786
Trained batch 389 in epoch 9, gen_loss = 0.9522607928667313, disc_loss = 0.00883858165008207
Trained batch 390 in epoch 9, gen_loss = 0.9520331081526968, disc_loss = 0.008816602042146132
Trained batch 391 in epoch 9, gen_loss = 0.9519437186572016, disc_loss = 0.008794545057530833
Trained batch 392 in epoch 9, gen_loss = 0.9521733379849344, disc_loss = 0.008772641906983387
Trained batch 393 in epoch 9, gen_loss = 0.9521093348863766, disc_loss = 0.008750780904362732
Trained batch 394 in epoch 9, gen_loss = 0.9520216478577143, disc_loss = 0.008729127278776921
Trained batch 395 in epoch 9, gen_loss = 0.9517950162743077, disc_loss = 0.008707601423733962
Trained batch 396 in epoch 9, gen_loss = 0.9516608519878436, disc_loss = 0.008685991370576018
Trained batch 397 in epoch 9, gen_loss = 0.9517815586310535, disc_loss = 0.00866490936858273
Trained batch 398 in epoch 9, gen_loss = 0.9513904274555675, disc_loss = 0.00864374284455401
Trained batch 399 in epoch 9, gen_loss = 0.9515001630783081, disc_loss = 0.008622583307587774
Trained batch 400 in epoch 9, gen_loss = 0.951337669258403, disc_loss = 0.0086021708690926
Trained batch 401 in epoch 9, gen_loss = 0.9515119058575796, disc_loss = 0.008582716273139255
Trained batch 402 in epoch 9, gen_loss = 0.9515623691360057, disc_loss = 0.008562112473562087
Trained batch 403 in epoch 9, gen_loss = 0.9514096576978665, disc_loss = 0.008541468746758742
Trained batch 404 in epoch 9, gen_loss = 0.9511464648776584, disc_loss = 0.008520989927404308
Trained batch 405 in epoch 9, gen_loss = 0.9509398546712152, disc_loss = 0.008500743236742842
Trained batch 406 in epoch 9, gen_loss = 0.9511383648879405, disc_loss = 0.008480350556368631
Trained batch 407 in epoch 9, gen_loss = 0.9514442097906973, disc_loss = 0.008460352933801842
Trained batch 408 in epoch 9, gen_loss = 0.9515739387871293, disc_loss = 0.008440352430038295
Trained batch 409 in epoch 9, gen_loss = 0.951596172553737, disc_loss = 0.008420481132031078
Trained batch 410 in epoch 9, gen_loss = 0.9514132964350012, disc_loss = 0.00840035610776474
Trained batch 411 in epoch 9, gen_loss = 0.9512018175090401, disc_loss = 0.008380853222740715
Trained batch 412 in epoch 9, gen_loss = 0.9513165604404329, disc_loss = 0.008361087900870558
Trained batch 413 in epoch 9, gen_loss = 0.9514207747823374, disc_loss = 0.008341580980000703
Trained batch 414 in epoch 9, gen_loss = 0.9511095480746533, disc_loss = 0.0083219973967938
Trained batch 415 in epoch 9, gen_loss = 0.9511494857187455, disc_loss = 0.008302401088957804
Trained batch 416 in epoch 9, gen_loss = 0.9511796058796579, disc_loss = 0.008282972250565913
Trained batch 417 in epoch 9, gen_loss = 0.9510088789691195, disc_loss = 0.00826404584918737
Trained batch 418 in epoch 9, gen_loss = 0.9509777564706552, disc_loss = 0.00824609248293786
Trained batch 419 in epoch 9, gen_loss = 0.9508846094210942, disc_loss = 0.008227122994070496
Trained batch 420 in epoch 9, gen_loss = 0.9510252213817877, disc_loss = 0.008208398740462662
Trained batch 421 in epoch 9, gen_loss = 0.9512592321041071, disc_loss = 0.008189467162436473
Trained batch 422 in epoch 9, gen_loss = 0.9512803751807968, disc_loss = 0.00817049035276688
Trained batch 423 in epoch 9, gen_loss = 0.9512101487731034, disc_loss = 0.008151829274658736
Trained batch 424 in epoch 9, gen_loss = 0.9508678192250869, disc_loss = 0.008133128976675353
Trained batch 425 in epoch 9, gen_loss = 0.9508725683174223, disc_loss = 0.00811443549801952
Trained batch 426 in epoch 9, gen_loss = 0.9508649123357107, disc_loss = 0.008095928682374225
Trained batch 427 in epoch 9, gen_loss = 0.9509167377358285, disc_loss = 0.008077525903517598
Trained batch 428 in epoch 9, gen_loss = 0.950797270922672, disc_loss = 0.00805897484935108
Trained batch 429 in epoch 9, gen_loss = 0.9510106603766597, disc_loss = 0.008040786813064695
Trained batch 430 in epoch 9, gen_loss = 0.9511209900583856, disc_loss = 0.008022620123515302
Trained batch 431 in epoch 9, gen_loss = 0.9510851819758062, disc_loss = 0.008005169294342017
Trained batch 432 in epoch 9, gen_loss = 0.9512106378414339, disc_loss = 0.007987773381532535
Trained batch 433 in epoch 9, gen_loss = 0.9511490997081528, disc_loss = 0.007969939115816407
Trained batch 434 in epoch 9, gen_loss = 0.9508552638963721, disc_loss = 0.007951990650443564
Trained batch 435 in epoch 9, gen_loss = 0.9505963448537599, disc_loss = 0.007934307317905514
Trained batch 436 in epoch 9, gen_loss = 0.950546776129943, disc_loss = 0.00791666237127917
Trained batch 437 in epoch 9, gen_loss = 0.9503674298933108, disc_loss = 0.007899276496884764
Trained batch 438 in epoch 9, gen_loss = 0.9503404003884092, disc_loss = 0.007881598673626443
Trained batch 439 in epoch 9, gen_loss = 0.9504133322022178, disc_loss = 0.007864014975315182
Trained batch 440 in epoch 9, gen_loss = 0.9502332456528194, disc_loss = 0.007846605367574455
Trained batch 441 in epoch 9, gen_loss = 0.950149914258206, disc_loss = 0.0078292296886206
Trained batch 442 in epoch 9, gen_loss = 0.9499788635471336, disc_loss = 0.007812060075433626
Trained batch 443 in epoch 9, gen_loss = 0.9500452799571527, disc_loss = 0.0077950681464301905
Trained batch 444 in epoch 9, gen_loss = 0.9499892435716779, disc_loss = 0.0077780677540962885
Trained batch 445 in epoch 9, gen_loss = 0.9498192526299857, disc_loss = 0.007761234253734473
Trained batch 446 in epoch 9, gen_loss = 0.9499820153451872, disc_loss = 0.007744789434724771
Trained batch 447 in epoch 9, gen_loss = 0.9497124055134398, disc_loss = 0.007727977225126129
Trained batch 448 in epoch 9, gen_loss = 0.9497732417886136, disc_loss = 0.007711340844131309
Trained batch 449 in epoch 9, gen_loss = 0.9495680157343547, disc_loss = 0.00769466028134856
Trained batch 450 in epoch 9, gen_loss = 0.9495208683669435, disc_loss = 0.007678389085207378
Trained batch 451 in epoch 9, gen_loss = 0.9494595660836296, disc_loss = 0.007662172879149573
Trained batch 452 in epoch 9, gen_loss = 0.9491954622152888, disc_loss = 0.007645584773340377
Trained batch 453 in epoch 9, gen_loss = 0.9493868549227189, disc_loss = 0.007629491348251124
Trained batch 454 in epoch 9, gen_loss = 0.9492686765534537, disc_loss = 0.007613144947758333
Trained batch 455 in epoch 9, gen_loss = 0.9495424752434095, disc_loss = 0.007598250851866365
Trained batch 456 in epoch 9, gen_loss = 0.9493017657058765, disc_loss = 0.007582148758821135
Trained batch 457 in epoch 9, gen_loss = 0.9491223892009935, disc_loss = 0.007565858295913933
Trained batch 458 in epoch 9, gen_loss = 0.9492381186526845, disc_loss = 0.007549942446627714
Trained batch 459 in epoch 9, gen_loss = 0.9489990595890128, disc_loss = 0.007534080364063772
Trained batch 460 in epoch 9, gen_loss = 0.9490255757422871, disc_loss = 0.007518180658549769
Trained batch 461 in epoch 9, gen_loss = 0.9489045753365472, disc_loss = 0.007502177821561614
Trained batch 462 in epoch 9, gen_loss = 0.9489206167070706, disc_loss = 0.007486287400921124
Trained batch 463 in epoch 9, gen_loss = 0.9489440744550064, disc_loss = 0.007470490853644025
Trained batch 464 in epoch 9, gen_loss = 0.9489215723929867, disc_loss = 0.007454701060612601
Trained batch 465 in epoch 9, gen_loss = 0.948729541296611, disc_loss = 0.007439308466373912
Trained batch 466 in epoch 9, gen_loss = 0.9487429804924469, disc_loss = 0.007423915392203816
Trained batch 467 in epoch 9, gen_loss = 0.9487007470467151, disc_loss = 0.007408593751644466
Trained batch 468 in epoch 9, gen_loss = 0.948736018844759, disc_loss = 0.0073930186817165846
Trained batch 469 in epoch 9, gen_loss = 0.9487305883397448, disc_loss = 0.007377596520614424
Trained batch 470 in epoch 9, gen_loss = 0.9484698151074145, disc_loss = 0.0073625318577941684
Trained batch 471 in epoch 9, gen_loss = 0.9483777308615587, disc_loss = 0.0073472985736231546
Trained batch 472 in epoch 9, gen_loss = 0.9481890408231642, disc_loss = 0.007332045751971825
Trained batch 473 in epoch 9, gen_loss = 0.9480401843408995, disc_loss = 0.007316979424345684
Trained batch 474 in epoch 9, gen_loss = 0.9479617691040039, disc_loss = 0.007301861054331407
Trained batch 475 in epoch 9, gen_loss = 0.947898042051732, disc_loss = 0.007286778037551744
Trained batch 476 in epoch 9, gen_loss = 0.9475512914437668, disc_loss = 0.00727192805557091
Trained batch 477 in epoch 9, gen_loss = 0.9475104546945963, disc_loss = 0.007257005683291084
Trained batch 478 in epoch 9, gen_loss = 0.9475925378112554, disc_loss = 0.007242289922452417
Trained batch 479 in epoch 9, gen_loss = 0.947632173076272, disc_loss = 0.007227613869933217
Trained batch 480 in epoch 9, gen_loss = 0.9475760706497082, disc_loss = 0.007212934173484334
Trained batch 481 in epoch 9, gen_loss = 0.9474821733735904, disc_loss = 0.007198226310448485
Trained batch 482 in epoch 9, gen_loss = 0.9474281600790241, disc_loss = 0.007183782088989199
Trained batch 483 in epoch 9, gen_loss = 0.9474436538524864, disc_loss = 0.007169802662337291
Trained batch 484 in epoch 9, gen_loss = 0.947365901642239, disc_loss = 0.007155328698230658
Trained batch 485 in epoch 9, gen_loss = 0.947397329066516, disc_loss = 0.007141084246346516
Trained batch 486 in epoch 9, gen_loss = 0.9473731876398749, disc_loss = 0.007126810748318451
Trained batch 487 in epoch 9, gen_loss = 0.9473309195676788, disc_loss = 0.00711257805766659
Trained batch 488 in epoch 9, gen_loss = 0.9473392875647983, disc_loss = 0.007098308538917808
Trained batch 489 in epoch 9, gen_loss = 0.9470841264238163, disc_loss = 0.007084115475477955
Trained batch 490 in epoch 9, gen_loss = 0.9470367846809434, disc_loss = 0.007069961671765359
Trained batch 491 in epoch 9, gen_loss = 0.9470247958249193, disc_loss = 0.007055874595829575
Trained batch 492 in epoch 9, gen_loss = 0.9468901023178024, disc_loss = 0.007042026105361639
Trained batch 493 in epoch 9, gen_loss = 0.9467286441007606, disc_loss = 0.007028132773963367
Trained batch 494 in epoch 9, gen_loss = 0.946677216375717, disc_loss = 0.007014417951700814
Trained batch 495 in epoch 9, gen_loss = 0.9467544955832343, disc_loss = 0.007000599696531877
Trained batch 496 in epoch 9, gen_loss = 0.9467150222367684, disc_loss = 0.00698680277747267
Trained batch 497 in epoch 9, gen_loss = 0.9466704167276022, disc_loss = 0.0069731679390805
Trained batch 498 in epoch 9, gen_loss = 0.9465869534947351, disc_loss = 0.006959492410643946
Trained batch 499 in epoch 9, gen_loss = 0.9465402715206146, disc_loss = 0.006945995836518705
Trained batch 500 in epoch 9, gen_loss = 0.94637249615378, disc_loss = 0.006932381184145664
Trained batch 501 in epoch 9, gen_loss = 0.9462141985912247, disc_loss = 0.006918910880816824
Trained batch 502 in epoch 9, gen_loss = 0.9463705270001239, disc_loss = 0.006905609006255404
Trained batch 503 in epoch 9, gen_loss = 0.946319732992422, disc_loss = 0.0068924071757565895
Trained batch 504 in epoch 9, gen_loss = 0.9462813527277201, disc_loss = 0.00687901232726434
Trained batch 505 in epoch 9, gen_loss = 0.9461218527418823, disc_loss = 0.006865710234576643
Trained batch 506 in epoch 9, gen_loss = 0.9461430501655714, disc_loss = 0.0068526486228704655
Trained batch 507 in epoch 9, gen_loss = 0.9459434003811183, disc_loss = 0.006839432654738258
Trained batch 508 in epoch 9, gen_loss = 0.9460495956285998, disc_loss = 0.006826265772355424
Trained batch 509 in epoch 9, gen_loss = 0.94592579275954, disc_loss = 0.00681310481862359
Trained batch 510 in epoch 9, gen_loss = 0.945896833260232, disc_loss = 0.0068003697674763625
Trained batch 511 in epoch 9, gen_loss = 0.9458279508398846, disc_loss = 0.006787354552997726
Trained batch 512 in epoch 9, gen_loss = 0.9456728773507458, disc_loss = 0.006774708771379551
Trained batch 513 in epoch 9, gen_loss = 0.9456060384961882, disc_loss = 0.006762008097643692
Trained batch 514 in epoch 9, gen_loss = 0.9455967104550704, disc_loss = 0.006749302550211653
Trained batch 515 in epoch 9, gen_loss = 0.9454543545495632, disc_loss = 0.006736541038119959
Trained batch 516 in epoch 9, gen_loss = 0.9454849302422839, disc_loss = 0.006724089272603428
Trained batch 517 in epoch 9, gen_loss = 0.9453243072428759, disc_loss = 0.006711431638827942
Trained batch 518 in epoch 9, gen_loss = 0.9451327048285159, disc_loss = 0.006698737239426648
Trained batch 519 in epoch 9, gen_loss = 0.9452115629728024, disc_loss = 0.006686307282912961
Trained batch 520 in epoch 9, gen_loss = 0.9451385044319387, disc_loss = 0.006673814047946557
Trained batch 521 in epoch 9, gen_loss = 0.9448676611728595, disc_loss = 0.006661581920452173
Trained batch 522 in epoch 9, gen_loss = 0.9446338984979954, disc_loss = 0.006649307346267623
Trained batch 523 in epoch 9, gen_loss = 0.9446333965272394, disc_loss = 0.0066369804819870985
Trained batch 524 in epoch 9, gen_loss = 0.944425330616179, disc_loss = 0.006624673767295289
Trained batch 525 in epoch 9, gen_loss = 0.944502335197572, disc_loss = 0.006612534222349426
Trained batch 526 in epoch 9, gen_loss = 0.9445553744314291, disc_loss = 0.006600438236680073
Trained batch 527 in epoch 9, gen_loss = 0.9445301638633916, disc_loss = 0.006588306970487875
Trained batch 528 in epoch 9, gen_loss = 0.9443531387920415, disc_loss = 0.006576367209000105
Trained batch 529 in epoch 9, gen_loss = 0.9442446724423822, disc_loss = 0.006564281994648792
Trained batch 530 in epoch 9, gen_loss = 0.9441550851092725, disc_loss = 0.006552304256337027
Trained batch 531 in epoch 9, gen_loss = 0.9442301316368849, disc_loss = 0.0065407247232480885
Trained batch 532 in epoch 9, gen_loss = 0.9440408331144594, disc_loss = 0.006528809774544384
Trained batch 533 in epoch 9, gen_loss = 0.9438410049743866, disc_loss = 0.006516960599137167
Trained batch 534 in epoch 9, gen_loss = 0.9435717576018003, disc_loss = 0.006504958805290299
Trained batch 535 in epoch 9, gen_loss = 0.94357311747857, disc_loss = 0.006493083936939952
Trained batch 536 in epoch 9, gen_loss = 0.9434912740851248, disc_loss = 0.006481336851002587
Trained batch 537 in epoch 9, gen_loss = 0.943696325042434, disc_loss = 0.006469736130127305
Trained batch 538 in epoch 9, gen_loss = 0.9434587249950487, disc_loss = 0.006458095853526991
Trained batch 539 in epoch 9, gen_loss = 0.9432200116139872, disc_loss = 0.006446495387421304
Trained batch 540 in epoch 9, gen_loss = 0.9432101679377106, disc_loss = 0.006434898881882179
Trained batch 541 in epoch 9, gen_loss = 0.9431530981706078, disc_loss = 0.006423300750652088
Trained batch 542 in epoch 9, gen_loss = 0.9431265011896306, disc_loss = 0.006411811749567814
Trained batch 543 in epoch 9, gen_loss = 0.9431612676776507, disc_loss = 0.006400557828395476
Trained batch 544 in epoch 9, gen_loss = 0.943016785875373, disc_loss = 0.006389122799296817
Trained batch 545 in epoch 9, gen_loss = 0.9430869400719584, disc_loss = 0.006377702943566311
Trained batch 546 in epoch 9, gen_loss = 0.9427790311616343, disc_loss = 0.006366538694807839
Trained batch 547 in epoch 9, gen_loss = 0.942564483215339, disc_loss = 0.006355531444715401
Trained batch 548 in epoch 9, gen_loss = 0.9426265035387814, disc_loss = 0.006344394645917561
Trained batch 549 in epoch 9, gen_loss = 0.9426543522964824, disc_loss = 0.006333278380347606
Trained batch 550 in epoch 9, gen_loss = 0.9425632848713662, disc_loss = 0.006322165792263362
Trained batch 551 in epoch 9, gen_loss = 0.9423657829562823, disc_loss = 0.006311488544191018
Trained batch 552 in epoch 9, gen_loss = 0.9424312150284352, disc_loss = 0.00630037305958135
Trained batch 553 in epoch 9, gen_loss = 0.9424179324389365, disc_loss = 0.006289381960634162
Trained batch 554 in epoch 9, gen_loss = 0.94227877017614, disc_loss = 0.006278417605069269
Trained batch 555 in epoch 9, gen_loss = 0.9424359602250642, disc_loss = 0.006267476479950333
Trained batch 556 in epoch 9, gen_loss = 0.9422179165177542, disc_loss = 0.006256498757490526
Trained batch 557 in epoch 9, gen_loss = 0.9421931528703287, disc_loss = 0.006245465206508491
Trained batch 558 in epoch 9, gen_loss = 0.9424620583146971, disc_loss = 0.006235340591872024
Trained batch 559 in epoch 9, gen_loss = 0.9424233864460673, disc_loss = 0.006224525000652648
Trained batch 560 in epoch 9, gen_loss = 0.9422655762198137, disc_loss = 0.0062138502395366535
Trained batch 561 in epoch 9, gen_loss = 0.9422996998681716, disc_loss = 0.006203012188505655
Trained batch 562 in epoch 9, gen_loss = 0.9422639737544221, disc_loss = 0.006192285520919734
Trained batch 563 in epoch 9, gen_loss = 0.9423048849224199, disc_loss = 0.006181645152176167
Trained batch 564 in epoch 9, gen_loss = 0.9423481331462353, disc_loss = 0.006171073536007393
Trained batch 565 in epoch 9, gen_loss = 0.9421357391369216, disc_loss = 0.00616072556942861
Trained batch 566 in epoch 9, gen_loss = 0.9420595067098237, disc_loss = 0.006150070549564488
Trained batch 567 in epoch 9, gen_loss = 0.9418878388446821, disc_loss = 0.006139678592083162
Trained batch 568 in epoch 9, gen_loss = 0.9419706274210254, disc_loss = 0.006129048091008247
Trained batch 569 in epoch 9, gen_loss = 0.9418499358913355, disc_loss = 0.006118468498403162
Trained batch 570 in epoch 9, gen_loss = 0.941979802636048, disc_loss = 0.006108025520022705
Trained batch 571 in epoch 9, gen_loss = 0.942113536429572, disc_loss = 0.006097646731463724
Trained batch 572 in epoch 9, gen_loss = 0.9421677919166458, disc_loss = 0.006087267384315328
Trained batch 573 in epoch 9, gen_loss = 0.9423531519203652, disc_loss = 0.006077030252111903
Trained batch 574 in epoch 9, gen_loss = 0.9425821504385575, disc_loss = 0.006066754839178073
Trained batch 575 in epoch 9, gen_loss = 0.9424740012942089, disc_loss = 0.006056515829249697
Trained batch 576 in epoch 9, gen_loss = 0.9425809708790308, disc_loss = 0.0060464981459271835
Trained batch 577 in epoch 9, gen_loss = 0.9423733412394474, disc_loss = 0.006036274500735927
Trained batch 578 in epoch 9, gen_loss = 0.9424140129064649, disc_loss = 0.0060261714755178875
Trained batch 579 in epoch 9, gen_loss = 0.9423155134094172, disc_loss = 0.006016187083539613
Trained batch 580 in epoch 9, gen_loss = 0.9422280805861888, disc_loss = 0.006006084507152021
Trained batch 581 in epoch 9, gen_loss = 0.9421754634052617, disc_loss = 0.005996014681212981
Trained batch 582 in epoch 9, gen_loss = 0.942108591976951, disc_loss = 0.005986705719517591
Trained batch 583 in epoch 9, gen_loss = 0.942041681951856, disc_loss = 0.00597673638727329
Trained batch 584 in epoch 9, gen_loss = 0.9419720093409221, disc_loss = 0.005966918769381586
Trained batch 585 in epoch 9, gen_loss = 0.9420408573980624, disc_loss = 0.005956964081763858
Trained batch 586 in epoch 9, gen_loss = 0.9420006745312446, disc_loss = 0.005947650289642438
Trained batch 587 in epoch 9, gen_loss = 0.9418949428058806, disc_loss = 0.0059379029849000306
Trained batch 588 in epoch 9, gen_loss = 0.9419243075649281, disc_loss = 0.005928236695941074
Trained batch 589 in epoch 9, gen_loss = 0.9418817256466817, disc_loss = 0.005918512968146696
Trained batch 590 in epoch 9, gen_loss = 0.9418847168560964, disc_loss = 0.005908674308266385
Trained batch 591 in epoch 9, gen_loss = 0.941755723006822, disc_loss = 0.005899000549512444
Trained batch 592 in epoch 9, gen_loss = 0.9416143579587567, disc_loss = 0.005889196687735383
Trained batch 593 in epoch 9, gen_loss = 0.9415917265094089, disc_loss = 0.005879539818467588
Trained batch 594 in epoch 9, gen_loss = 0.9414567498599782, disc_loss = 0.005869881737551225
Trained batch 595 in epoch 9, gen_loss = 0.9414062934033822, disc_loss = 0.005860323290022316
Trained batch 596 in epoch 9, gen_loss = 0.9413344935955514, disc_loss = 0.005850783010962372
Trained batch 597 in epoch 9, gen_loss = 0.941401207327444, disc_loss = 0.005841294847468999
Trained batch 598 in epoch 9, gen_loss = 0.941367265975137, disc_loss = 0.00583180845955856
Trained batch 599 in epoch 9, gen_loss = 0.9412745519479115, disc_loss = 0.0058223601436354026
Trained batch 600 in epoch 9, gen_loss = 0.941184612756561, disc_loss = 0.00581293473273317
Trained batch 601 in epoch 9, gen_loss = 0.9410969453594613, disc_loss = 0.005803452745244174
Trained batch 602 in epoch 9, gen_loss = 0.9410960687135977, disc_loss = 0.0057940213003078635
Trained batch 603 in epoch 9, gen_loss = 0.9408750665306256, disc_loss = 0.00578470698863818
Trained batch 604 in epoch 9, gen_loss = 0.9409134343635938, disc_loss = 0.005775328566804182
Trained batch 605 in epoch 9, gen_loss = 0.9408052352198674, disc_loss = 0.005766030956869799
Trained batch 606 in epoch 9, gen_loss = 0.9407447591252146, disc_loss = 0.005756718209953583
Trained batch 607 in epoch 9, gen_loss = 0.9408470126555154, disc_loss = 0.0057475699087191105
Trained batch 608 in epoch 9, gen_loss = 0.9410640742195455, disc_loss = 0.005738379130371153
Trained batch 609 in epoch 9, gen_loss = 0.9409335944496218, disc_loss = 0.005729217185139308
Trained batch 610 in epoch 9, gen_loss = 0.9408450377358157, disc_loss = 0.00572016017441514
Trained batch 611 in epoch 9, gen_loss = 0.940786446426429, disc_loss = 0.005711036436289707
Trained batch 612 in epoch 9, gen_loss = 0.9406455503396848, disc_loss = 0.005701858190334209
Trained batch 613 in epoch 9, gen_loss = 0.9404941073069744, disc_loss = 0.00569271854435341
Trained batch 614 in epoch 9, gen_loss = 0.9402192960909712, disc_loss = 0.005683911914465858
Trained batch 615 in epoch 9, gen_loss = 0.9401458197019317, disc_loss = 0.0056749191146271
Trained batch 616 in epoch 9, gen_loss = 0.9399809710790118, disc_loss = 0.005665969597750247
Trained batch 617 in epoch 9, gen_loss = 0.9399478548360103, disc_loss = 0.005657015219597337
Trained batch 618 in epoch 9, gen_loss = 0.9397936736824825, disc_loss = 0.005648099055181984
Trained batch 619 in epoch 9, gen_loss = 0.9397986601437291, disc_loss = 0.005639193792927883
Trained batch 620 in epoch 9, gen_loss = 0.9397758146606974, disc_loss = 0.005630357620915947
Trained batch 621 in epoch 9, gen_loss = 0.9397492730732516, disc_loss = 0.00562161082459705
Trained batch 622 in epoch 9, gen_loss = 0.9396874469317748, disc_loss = 0.005612753825024874
Trained batch 623 in epoch 9, gen_loss = 0.9398999942991978, disc_loss = 0.00560414732787579
Trained batch 624 in epoch 9, gen_loss = 0.940122726726532, disc_loss = 0.00559559470443055
Trained batch 625 in epoch 9, gen_loss = 0.9400211678335841, disc_loss = 0.005586883848424802
Trained batch 626 in epoch 9, gen_loss = 0.9399818774235495, disc_loss = 0.005578209633188488
Trained batch 627 in epoch 9, gen_loss = 0.939838369655761, disc_loss = 0.005569511830411328
Trained batch 628 in epoch 9, gen_loss = 0.9397563367655623, disc_loss = 0.005560926524023688
Trained batch 629 in epoch 9, gen_loss = 0.9395790115235344, disc_loss = 0.005552386543283882
Trained batch 630 in epoch 9, gen_loss = 0.9393963780720525, disc_loss = 0.005543813628377762
Trained batch 631 in epoch 9, gen_loss = 0.9393573227939727, disc_loss = 0.005535307427589366
Trained batch 632 in epoch 9, gen_loss = 0.9393181041895308, disc_loss = 0.005526746943888937
Trained batch 633 in epoch 9, gen_loss = 0.9394232123056044, disc_loss = 0.0055182223576958345
Trained batch 634 in epoch 9, gen_loss = 0.9394478187786313, disc_loss = 0.005509719577781566
Trained batch 635 in epoch 9, gen_loss = 0.9393229345855473, disc_loss = 0.005501438283523762
Trained batch 636 in epoch 9, gen_loss = 0.9393402307149566, disc_loss = 0.005493022501183103
Trained batch 637 in epoch 9, gen_loss = 0.9392881233677222, disc_loss = 0.0054846592102081
Trained batch 638 in epoch 9, gen_loss = 0.9392626430133886, disc_loss = 0.005476278343091916
Trained batch 639 in epoch 9, gen_loss = 0.9392678891308606, disc_loss = 0.00546803408225287
Trained batch 640 in epoch 9, gen_loss = 0.939353775959491, disc_loss = 0.005459834101497557
Trained batch 641 in epoch 9, gen_loss = 0.9394374492569505, disc_loss = 0.005451569065334753
Trained batch 642 in epoch 9, gen_loss = 0.939639762901407, disc_loss = 0.0054434544271066195
Trained batch 643 in epoch 9, gen_loss = 0.9396982954710907, disc_loss = 0.005435176125044468
Trained batch 644 in epoch 9, gen_loss = 0.9396436974983807, disc_loss = 0.005426996690040642
Trained batch 645 in epoch 9, gen_loss = 0.9395166068069706, disc_loss = 0.0054188203098124105
Trained batch 646 in epoch 9, gen_loss = 0.9394291133563707, disc_loss = 0.005410768798672288
Trained batch 647 in epoch 9, gen_loss = 0.9394010948362174, disc_loss = 0.005402652705487088
Trained batch 648 in epoch 9, gen_loss = 0.9392865837446898, disc_loss = 0.005394562027039177
Trained batch 649 in epoch 9, gen_loss = 0.9392240658173194, disc_loss = 0.005386461982584129
Trained batch 650 in epoch 9, gen_loss = 0.9391830410642374, disc_loss = 0.005378437961997842
Trained batch 651 in epoch 9, gen_loss = 0.9389833125965726, disc_loss = 0.005370415038228509
Trained batch 652 in epoch 9, gen_loss = 0.9390396002058231, disc_loss = 0.00536239697391297
Trained batch 653 in epoch 9, gen_loss = 0.9388961215996232, disc_loss = 0.005354348085222578
Trained batch 654 in epoch 9, gen_loss = 0.9387041238428072, disc_loss = 0.0053464151566976125
Trained batch 655 in epoch 9, gen_loss = 0.9385866785376538, disc_loss = 0.00533842897720006
Trained batch 656 in epoch 9, gen_loss = 0.9384186858455884, disc_loss = 0.00533043863282371
Trained batch 657 in epoch 9, gen_loss = 0.9383805255578281, disc_loss = 0.00532250685182451
Trained batch 658 in epoch 9, gen_loss = 0.9385316602557853, disc_loss = 0.005315077190261973
Trained batch 659 in epoch 9, gen_loss = 0.938561481869582, disc_loss = 0.005307222117985613
Trained batch 660 in epoch 9, gen_loss = 0.9383608819677322, disc_loss = 0.005299389081181636
Trained batch 661 in epoch 9, gen_loss = 0.9383322398468087, disc_loss = 0.005291665465798014
Trained batch 662 in epoch 9, gen_loss = 0.9383484313930321, disc_loss = 0.005283900150850304
Trained batch 663 in epoch 9, gen_loss = 0.9381734142640987, disc_loss = 0.005276157979600809
Trained batch 664 in epoch 9, gen_loss = 0.9381007047524129, disc_loss = 0.005268346639945263
Trained batch 665 in epoch 9, gen_loss = 0.9379235722639181, disc_loss = 0.005260610495844395
Trained batch 666 in epoch 9, gen_loss = 0.93766707512571, disc_loss = 0.005252868727309371
Trained batch 667 in epoch 9, gen_loss = 0.9376570321842582, disc_loss = 0.005245179696800902
Trained batch 668 in epoch 9, gen_loss = 0.9377274433059009, disc_loss = 0.0052375160543121375
Trained batch 669 in epoch 9, gen_loss = 0.937688719158742, disc_loss = 0.005229865675123144
Trained batch 670 in epoch 9, gen_loss = 0.9375578344490063, disc_loss = 0.0052222434240729925
Trained batch 671 in epoch 9, gen_loss = 0.9373739935635101, disc_loss = 0.00521471692343853
Trained batch 672 in epoch 9, gen_loss = 0.9373082426469358, disc_loss = 0.005207092237839908
Trained batch 673 in epoch 9, gen_loss = 0.9375707479718884, disc_loss = 0.005199582633208822
Trained batch 674 in epoch 9, gen_loss = 0.9373846379915873, disc_loss = 0.005192094119416585
Trained batch 675 in epoch 9, gen_loss = 0.9373927700096334, disc_loss = 0.005184690527211167
Trained batch 676 in epoch 9, gen_loss = 0.9373593548728233, disc_loss = 0.005177278674740353
Trained batch 677 in epoch 9, gen_loss = 0.9371432974978534, disc_loss = 0.005169841209981126
Trained batch 678 in epoch 9, gen_loss = 0.9371668912349639, disc_loss = 0.0051625003150612145
Trained batch 679 in epoch 9, gen_loss = 0.93711328129558, disc_loss = 0.005155142924024189
Trained batch 680 in epoch 9, gen_loss = 0.937156641535822, disc_loss = 0.005147763751657466
Trained batch 681 in epoch 9, gen_loss = 0.9371948807645054, disc_loss = 0.005140358420777052
Trained batch 682 in epoch 9, gen_loss = 0.9373037653646566, disc_loss = 0.005133097648844658
Trained batch 683 in epoch 9, gen_loss = 0.9372538812676369, disc_loss = 0.005125952391247064
Trained batch 684 in epoch 9, gen_loss = 0.9373315683246529, disc_loss = 0.005118661746265873
Trained batch 685 in epoch 9, gen_loss = 0.9372764685063598, disc_loss = 0.005111353271828782
Trained batch 686 in epoch 9, gen_loss = 0.9372121215387202, disc_loss = 0.0051040898017647805
Trained batch 687 in epoch 9, gen_loss = 0.9373153730533844, disc_loss = 0.005096838737001743
Trained batch 688 in epoch 9, gen_loss = 0.9372432098679342, disc_loss = 0.005089574945041827
Trained batch 689 in epoch 9, gen_loss = 0.9372950428637905, disc_loss = 0.005082425072391018
Trained batch 690 in epoch 9, gen_loss = 0.9372685164342568, disc_loss = 0.005075271565910373
Trained batch 691 in epoch 9, gen_loss = 0.9373579983077297, disc_loss = 0.005068187800985849
Trained batch 692 in epoch 9, gen_loss = 0.9374202329875071, disc_loss = 0.005061033544426113
Trained batch 693 in epoch 9, gen_loss = 0.9372851070478257, disc_loss = 0.005053989241855496
Trained batch 694 in epoch 9, gen_loss = 0.937110707999991, disc_loss = 0.00504687726162642
Trained batch 695 in epoch 9, gen_loss = 0.9369364513576716, disc_loss = 0.005039764923957978
Trained batch 696 in epoch 9, gen_loss = 0.936974072986559, disc_loss = 0.005032849344661241
Trained batch 697 in epoch 9, gen_loss = 0.9368455018047617, disc_loss = 0.0050258635126993615
Trained batch 698 in epoch 9, gen_loss = 0.9367576843508665, disc_loss = 0.005018842305727596
Trained batch 699 in epoch 9, gen_loss = 0.9366800821678979, disc_loss = 0.00501183972421651
Trained batch 700 in epoch 9, gen_loss = 0.9367136255480594, disc_loss = 0.005004811111093049
Trained batch 701 in epoch 9, gen_loss = 0.9366226180156751, disc_loss = 0.004997842571628231
Trained batch 702 in epoch 9, gen_loss = 0.936582938112202, disc_loss = 0.004990864290717468
Trained batch 703 in epoch 9, gen_loss = 0.9365991639312018, disc_loss = 0.004983909575147746
Trained batch 704 in epoch 9, gen_loss = 0.936646549752418, disc_loss = 0.004976988510981678
Trained batch 705 in epoch 9, gen_loss = 0.9366478283412059, disc_loss = 0.004970168692545264
Trained batch 706 in epoch 9, gen_loss = 0.9366072274670743, disc_loss = 0.004963329927159323
Trained batch 707 in epoch 9, gen_loss = 0.9365074898900285, disc_loss = 0.004956454697977962
Trained batch 708 in epoch 9, gen_loss = 0.9365745587812997, disc_loss = 0.004949687916981858
Trained batch 709 in epoch 9, gen_loss = 0.9365289190285643, disc_loss = 0.004942925671331952
Trained batch 710 in epoch 9, gen_loss = 0.936347769198706, disc_loss = 0.004936124917875213
Trained batch 711 in epoch 9, gen_loss = 0.936405388910449, disc_loss = 0.004929366851530595
Trained batch 712 in epoch 9, gen_loss = 0.9363020626726191, disc_loss = 0.0049225924554586915
Trained batch 713 in epoch 9, gen_loss = 0.936156278147417, disc_loss = 0.0049159211896641014
Trained batch 714 in epoch 9, gen_loss = 0.9359730297868902, disc_loss = 0.004909234979760611
Trained batch 715 in epoch 9, gen_loss = 0.9360111784502114, disc_loss = 0.004902546332405058
Trained batch 716 in epoch 9, gen_loss = 0.9359279193472496, disc_loss = 0.004895944073797084
Trained batch 717 in epoch 9, gen_loss = 0.9359288036325184, disc_loss = 0.0048892607068572284
Trained batch 718 in epoch 9, gen_loss = 0.9359369831721872, disc_loss = 0.004882643334147383
Trained batch 719 in epoch 9, gen_loss = 0.9359228810502424, disc_loss = 0.004876071324825817
Trained batch 720 in epoch 9, gen_loss = 0.9358838992542102, disc_loss = 0.004869481131969531
Trained batch 721 in epoch 9, gen_loss = 0.9358598807842117, disc_loss = 0.004862883008686455
Trained batch 722 in epoch 9, gen_loss = 0.9356972071474848, disc_loss = 0.004856285797427235
Trained batch 723 in epoch 9, gen_loss = 0.9356114960671789, disc_loss = 0.004849796793200892
Trained batch 724 in epoch 9, gen_loss = 0.9355519394216867, disc_loss = 0.004843282225593957
Trained batch 725 in epoch 9, gen_loss = 0.9354096630552255, disc_loss = 0.004836752436309957
Trained batch 726 in epoch 9, gen_loss = 0.9352896189755225, disc_loss = 0.0048302189116555165
Trained batch 727 in epoch 9, gen_loss = 0.9351943895875753, disc_loss = 0.0048238001793404215
Trained batch 728 in epoch 9, gen_loss = 0.9350892804941195, disc_loss = 0.00481736790332132
Trained batch 729 in epoch 9, gen_loss = 0.9350582095041667, disc_loss = 0.0048109858172223265
Trained batch 730 in epoch 9, gen_loss = 0.9350007286476208, disc_loss = 0.004804499692757513
Trained batch 731 in epoch 9, gen_loss = 0.9349102427562078, disc_loss = 0.004798126801976596
Trained batch 732 in epoch 9, gen_loss = 0.9349260087878447, disc_loss = 0.004791697055074951
Trained batch 733 in epoch 9, gen_loss = 0.9349456417300721, disc_loss = 0.004785283631341813
Trained batch 734 in epoch 9, gen_loss = 0.9348508890794248, disc_loss = 0.0047789365493793035
Trained batch 735 in epoch 9, gen_loss = 0.934760783434562, disc_loss = 0.004772625835980564
Trained batch 736 in epoch 9, gen_loss = 0.9345136231450892, disc_loss = 0.00476631008889951
Trained batch 737 in epoch 9, gen_loss = 0.9343963392220216, disc_loss = 0.004760083929475237
Trained batch 738 in epoch 9, gen_loss = 0.9345799978918249, disc_loss = 0.004753987344278571
Trained batch 739 in epoch 9, gen_loss = 0.9344875677211865, disc_loss = 0.00474773593837076
Trained batch 740 in epoch 9, gen_loss = 0.9344541186745833, disc_loss = 0.0047415424449553595
Trained batch 741 in epoch 9, gen_loss = 0.9344318997506504, disc_loss = 0.004735364863828889
Trained batch 742 in epoch 9, gen_loss = 0.9344636384763756, disc_loss = 0.004729142254695166
Trained batch 743 in epoch 9, gen_loss = 0.9344839303083318, disc_loss = 0.0047229670530585825
Trained batch 744 in epoch 9, gen_loss = 0.9345415701002082, disc_loss = 0.004716881142506116
Trained batch 745 in epoch 9, gen_loss = 0.9344988053030366, disc_loss = 0.004710792740653616
Trained batch 746 in epoch 9, gen_loss = 0.9344446094160578, disc_loss = 0.00470462397244172
Trained batch 747 in epoch 9, gen_loss = 0.9343851224623899, disc_loss = 0.004698449231194812
Trained batch 748 in epoch 9, gen_loss = 0.9344235825761457, disc_loss = 0.00469231543412147
Trained batch 749 in epoch 9, gen_loss = 0.9343631618817647, disc_loss = 0.004686247056650852
Trained batch 750 in epoch 9, gen_loss = 0.9342799566080979, disc_loss = 0.004680124827821137
Trained batch 751 in epoch 9, gen_loss = 0.9341345296261159, disc_loss = 0.004674161188718922
Trained batch 752 in epoch 9, gen_loss = 0.9341256635914128, disc_loss = 0.004668167177070217
Trained batch 753 in epoch 9, gen_loss = 0.9340980070339274, disc_loss = 0.004662319149997469
Trained batch 754 in epoch 9, gen_loss = 0.934064317223252, disc_loss = 0.0046563356176241525
Trained batch 755 in epoch 9, gen_loss = 0.9339886337676376, disc_loss = 0.004650354374606405
Trained batch 756 in epoch 9, gen_loss = 0.9339886091186946, disc_loss = 0.0046443826690673136
Trained batch 757 in epoch 9, gen_loss = 0.9339439148638683, disc_loss = 0.004638417241066258
Trained batch 758 in epoch 9, gen_loss = 0.9337956834687546, disc_loss = 0.00463242433512237
Trained batch 759 in epoch 9, gen_loss = 0.9337805536232496, disc_loss = 0.004626490973772122
Trained batch 760 in epoch 9, gen_loss = 0.9336417717626624, disc_loss = 0.004620543629790087
Trained batch 761 in epoch 9, gen_loss = 0.93355043353684, disc_loss = 0.004614648028269451
Trained batch 762 in epoch 9, gen_loss = 0.9334479533672958, disc_loss = 0.004608742384426403
Trained batch 763 in epoch 9, gen_loss = 0.9334296577888009, disc_loss = 0.004602853961241921
Trained batch 764 in epoch 9, gen_loss = 0.9334821217200335, disc_loss = 0.0045971069572736155
Trained batch 765 in epoch 9, gen_loss = 0.933336879814885, disc_loss = 0.00459132726807395
Trained batch 766 in epoch 9, gen_loss = 0.9333544164468599, disc_loss = 0.004585464776862738
Trained batch 767 in epoch 9, gen_loss = 0.9331605196930468, disc_loss = 0.004579623184251129
Trained batch 768 in epoch 9, gen_loss = 0.9331730421249826, disc_loss = 0.004573821716272619
Trained batch 769 in epoch 9, gen_loss = 0.9331447084228713, disc_loss = 0.004568026159965969
Trained batch 770 in epoch 9, gen_loss = 0.933164774830394, disc_loss = 0.004562657298573432
Trained batch 771 in epoch 9, gen_loss = 0.9330770506142335, disc_loss = 0.004556961067620236
Trained batch 772 in epoch 9, gen_loss = 0.9330073380686179, disc_loss = 0.004551300593302209
Trained batch 773 in epoch 9, gen_loss = 0.9330097119629537, disc_loss = 0.004545573336760756
Trained batch 774 in epoch 9, gen_loss = 0.9329559150818856, disc_loss = 0.004539834457278747
Trained batch 775 in epoch 9, gen_loss = 0.932877582142648, disc_loss = 0.0045341494169687645
Trained batch 776 in epoch 9, gen_loss = 0.9327188918182442, disc_loss = 0.00452850811604503
Trained batch 777 in epoch 9, gen_loss = 0.9326847637680319, disc_loss = 0.0045228469789248575
Trained batch 778 in epoch 9, gen_loss = 0.932493078004717, disc_loss = 0.004517223914411288
Trained batch 779 in epoch 9, gen_loss = 0.932558823395998, disc_loss = 0.0045115716725819925
Trained batch 780 in epoch 9, gen_loss = 0.9324123712111069, disc_loss = 0.004505917040581091
Trained batch 781 in epoch 9, gen_loss = 0.9323987307603402, disc_loss = 0.00450026931814783
Trained batch 782 in epoch 9, gen_loss = 0.9323255697581655, disc_loss = 0.004494807571022921
Trained batch 783 in epoch 9, gen_loss = 0.9323730291608645, disc_loss = 0.0044892373409812555
Trained batch 784 in epoch 9, gen_loss = 0.9323785500161966, disc_loss = 0.004483644356908481
Trained batch 785 in epoch 9, gen_loss = 0.9322245967297154, disc_loss = 0.004478086242638143
Trained batch 786 in epoch 9, gen_loss = 0.9322248601095497, disc_loss = 0.004472549122379084
Trained batch 787 in epoch 9, gen_loss = 0.9321196610249843, disc_loss = 0.00446710113777178
Trained batch 788 in epoch 9, gen_loss = 0.932167336212516, disc_loss = 0.00446158264832927
Trained batch 789 in epoch 9, gen_loss = 0.932108765312388, disc_loss = 0.004456104534269971
Trained batch 790 in epoch 9, gen_loss = 0.9321061298910496, disc_loss = 0.004450626663624353
Trained batch 791 in epoch 9, gen_loss = 0.9319628726954412, disc_loss = 0.004445366588054576
Trained batch 792 in epoch 9, gen_loss = 0.9319874631501688, disc_loss = 0.004439911590723208
Trained batch 793 in epoch 9, gen_loss = 0.931890078470749, disc_loss = 0.004434492149826031
Trained batch 794 in epoch 9, gen_loss = 0.931936742749604, disc_loss = 0.004429113986970031
Trained batch 795 in epoch 9, gen_loss = 0.9318994922404313, disc_loss = 0.004423658214345687
Trained batch 796 in epoch 9, gen_loss = 0.9318756498536621, disc_loss = 0.004418274477420584
Trained batch 797 in epoch 9, gen_loss = 0.9318380488787678, disc_loss = 0.0044128641974769435
Trained batch 798 in epoch 9, gen_loss = 0.9318940006895865, disc_loss = 0.0044074637657142875
Trained batch 799 in epoch 9, gen_loss = 0.9319712102413178, disc_loss = 0.004402143434517712
Trained batch 800 in epoch 9, gen_loss = 0.9318532175041465, disc_loss = 0.004396828292173519
Trained batch 801 in epoch 9, gen_loss = 0.9318642859298392, disc_loss = 0.004391709251703879
Trained batch 802 in epoch 9, gen_loss = 0.9316626978692498, disc_loss = 0.004386466365366792
Trained batch 803 in epoch 9, gen_loss = 0.9316388143235771, disc_loss = 0.004381150196920557
Trained batch 804 in epoch 9, gen_loss = 0.9316448055439114, disc_loss = 0.004375819922292892
Trained batch 805 in epoch 9, gen_loss = 0.9317103774464751, disc_loss = 0.0043706089831441934
Trained batch 806 in epoch 9, gen_loss = 0.9315480253067159, disc_loss = 0.004365321064048794
Trained batch 807 in epoch 9, gen_loss = 0.9316564571886959, disc_loss = 0.004360313379677764
Trained batch 808 in epoch 9, gen_loss = 0.9316868046747592, disc_loss = 0.00435510355709679
Trained batch 809 in epoch 9, gen_loss = 0.9316728565427992, disc_loss = 0.00434989454515744
Trained batch 810 in epoch 9, gen_loss = 0.9317890767251519, disc_loss = 0.004344766350072159
Trained batch 811 in epoch 9, gen_loss = 0.9317124249606297, disc_loss = 0.004339566389650016
Trained batch 812 in epoch 9, gen_loss = 0.9317513082593423, disc_loss = 0.004334363274954701
Trained batch 813 in epoch 9, gen_loss = 0.931619334718812, disc_loss = 0.004329218166904336
Trained batch 814 in epoch 9, gen_loss = 0.9316533918029691, disc_loss = 0.004324037569772846
Trained batch 815 in epoch 9, gen_loss = 0.9317169773081938, disc_loss = 0.004318829000487099
Trained batch 816 in epoch 9, gen_loss = 0.9317003797142421, disc_loss = 0.004313661064233031
Trained batch 817 in epoch 9, gen_loss = 0.931778070031868, disc_loss = 0.004308499112698716
Trained batch 818 in epoch 9, gen_loss = 0.9317649257925403, disc_loss = 0.004303363497442977
Trained batch 819 in epoch 9, gen_loss = 0.9316739447233153, disc_loss = 0.004298239555992484
Trained batch 820 in epoch 9, gen_loss = 0.9316754821737849, disc_loss = 0.004293100919122025
Trained batch 821 in epoch 9, gen_loss = 0.9317420720328959, disc_loss = 0.004288023926658369
Trained batch 822 in epoch 9, gen_loss = 0.9316494934179369, disc_loss = 0.0042829362427369375
Trained batch 823 in epoch 9, gen_loss = 0.9316554089773048, disc_loss = 0.004277892742747214
Trained batch 824 in epoch 9, gen_loss = 0.9316214955936779, disc_loss = 0.00427281923318691
Trained batch 825 in epoch 9, gen_loss = 0.9316505897997656, disc_loss = 0.004267798056468716
Trained batch 826 in epoch 9, gen_loss = 0.9316907416952565, disc_loss = 0.004262772056428891
Trained batch 827 in epoch 9, gen_loss = 0.9316066913126747, disc_loss = 0.004257715163054156
Trained batch 828 in epoch 9, gen_loss = 0.9316767919336786, disc_loss = 0.004252706226597939
Trained batch 829 in epoch 9, gen_loss = 0.9317286826759936, disc_loss = 0.0042478364488444465
Trained batch 830 in epoch 9, gen_loss = 0.931670551767705, disc_loss = 0.004242988455818647
Trained batch 831 in epoch 9, gen_loss = 0.9317307487273445, disc_loss = 0.004238060220280624
Trained batch 832 in epoch 9, gen_loss = 0.9316973756341373, disc_loss = 0.0042331228285226695
Trained batch 833 in epoch 9, gen_loss = 0.9316085479814086, disc_loss = 0.00422838266822335
Trained batch 834 in epoch 9, gen_loss = 0.931614131413534, disc_loss = 0.004223543293047404
Trained batch 835 in epoch 9, gen_loss = 0.9315906519952574, disc_loss = 0.004218707967632209
Trained batch 836 in epoch 9, gen_loss = 0.9315550721104712, disc_loss = 0.004213799047984476
Trained batch 837 in epoch 9, gen_loss = 0.9315196711009898, disc_loss = 0.0042090154275295204
Trained batch 838 in epoch 9, gen_loss = 0.9315814910827291, disc_loss = 0.004204194374757897
Trained batch 839 in epoch 9, gen_loss = 0.9317126003049668, disc_loss = 0.0041993113096136115
Trained batch 840 in epoch 9, gen_loss = 0.9317378335135161, disc_loss = 0.00419443159117387
Trained batch 841 in epoch 9, gen_loss = 0.9316656803291937, disc_loss = 0.004189536010254672
Trained batch 842 in epoch 9, gen_loss = 0.931626534971054, disc_loss = 0.004184700783878904
Trained batch 843 in epoch 9, gen_loss = 0.9315307770295166, disc_loss = 0.004179850027496665
Trained batch 844 in epoch 9, gen_loss = 0.9314847551153962, disc_loss = 0.0041750206350460485
Trained batch 845 in epoch 9, gen_loss = 0.9315090560603085, disc_loss = 0.004170210089383636
Trained batch 846 in epoch 9, gen_loss = 0.9314761217397669, disc_loss = 0.004165380804502892
Trained batch 847 in epoch 9, gen_loss = 0.9316107854949978, disc_loss = 0.004160768308621591
Trained batch 848 in epoch 9, gen_loss = 0.9314956619405353, disc_loss = 0.00415605242291846
Trained batch 849 in epoch 9, gen_loss = 0.9314658809409422, disc_loss = 0.004151324780575712
Trained batch 850 in epoch 9, gen_loss = 0.9314721970524547, disc_loss = 0.004146671957874941
Trained batch 851 in epoch 9, gen_loss = 0.9313798386586104, disc_loss = 0.004141933106387716
Trained batch 852 in epoch 9, gen_loss = 0.9313634604669819, disc_loss = 0.004137188175557086
Trained batch 853 in epoch 9, gen_loss = 0.931300525642949, disc_loss = 0.0041324975482708625
Trained batch 854 in epoch 9, gen_loss = 0.9312581176646272, disc_loss = 0.004127788396037527
Trained batch 855 in epoch 9, gen_loss = 0.9312944000012406, disc_loss = 0.004123100236437129
Trained batch 856 in epoch 9, gen_loss = 0.9313003880557547, disc_loss = 0.004118443864871517
Trained batch 857 in epoch 9, gen_loss = 0.9312224847314519, disc_loss = 0.004113740691630086
Trained batch 858 in epoch 9, gen_loss = 0.9313598551350506, disc_loss = 0.004109130211449466
Trained batch 859 in epoch 9, gen_loss = 0.9313382891721503, disc_loss = 0.004104458749582612
Trained batch 860 in epoch 9, gen_loss = 0.9313571227413714, disc_loss = 0.004099904481672036
Trained batch 861 in epoch 9, gen_loss = 0.9313367368035416, disc_loss = 0.004095321422659013
Trained batch 862 in epoch 9, gen_loss = 0.9312499211119059, disc_loss = 0.004090676638887233
Trained batch 863 in epoch 9, gen_loss = 0.9311955564965805, disc_loss = 0.0040860286224213066
Trained batch 864 in epoch 9, gen_loss = 0.931047979806889, disc_loss = 0.004081507534464294
Trained batch 865 in epoch 9, gen_loss = 0.9310834858626746, disc_loss = 0.004076923449159042
Trained batch 866 in epoch 9, gen_loss = 0.9311673694140908, disc_loss = 0.004072463478177497
Trained batch 867 in epoch 9, gen_loss = 0.9310889071720536, disc_loss = 0.00406790764889777
Trained batch 868 in epoch 9, gen_loss = 0.931056447558628, disc_loss = 0.004063334731397906
Trained batch 869 in epoch 9, gen_loss = 0.9309015737867904, disc_loss = 0.004058849272990918
Trained batch 870 in epoch 9, gen_loss = 0.9308173431320935, disc_loss = 0.004054336696074264
Trained batch 871 in epoch 9, gen_loss = 0.9306572874614952, disc_loss = 0.0040498543043997765
Trained batch 872 in epoch 9, gen_loss = 0.9306340031197801, disc_loss = 0.004045379211206215
Trained batch 873 in epoch 9, gen_loss = 0.9306761549457533, disc_loss = 0.00404091969975269
Trained batch 874 in epoch 9, gen_loss = 0.9307597783633641, disc_loss = 0.004036542176726341
Trained batch 875 in epoch 9, gen_loss = 0.9306383377204747, disc_loss = 0.004032053836507985
Trained batch 876 in epoch 9, gen_loss = 0.9305807255556809, disc_loss = 0.004027576031026411
Trained batch 877 in epoch 9, gen_loss = 0.9305380965012353, disc_loss = 0.004023110372041724
Trained batch 878 in epoch 9, gen_loss = 0.9304105366863081, disc_loss = 0.0040186622032754105
Trained batch 879 in epoch 9, gen_loss = 0.9304683534936471, disc_loss = 0.004014185019919255
Trained batch 880 in epoch 9, gen_loss = 0.930374303010211, disc_loss = 0.004009799520523358
Trained batch 881 in epoch 9, gen_loss = 0.930252357742954, disc_loss = 0.004005425445460717
Trained batch 882 in epoch 9, gen_loss = 0.9302498499102393, disc_loss = 0.004001026048966341
Trained batch 883 in epoch 9, gen_loss = 0.930124794668202, disc_loss = 0.003996672877000249
Trained batch 884 in epoch 9, gen_loss = 0.9300911553835465, disc_loss = 0.003992280035927868
Trained batch 885 in epoch 9, gen_loss = 0.9300433294364077, disc_loss = 0.003987906135388221
Trained batch 886 in epoch 9, gen_loss = 0.9299855644162639, disc_loss = 0.0039835459176980415
Trained batch 887 in epoch 9, gen_loss = 0.9299861598793451, disc_loss = 0.0039791750638484315
Trained batch 888 in epoch 9, gen_loss = 0.9299434485800221, disc_loss = 0.003974820705095274
Trained batch 889 in epoch 9, gen_loss = 0.9298270759287844, disc_loss = 0.0039704604469140954
Trained batch 890 in epoch 9, gen_loss = 0.9298514181917364, disc_loss = 0.00396608691966164
Trained batch 891 in epoch 9, gen_loss = 0.929872182987196, disc_loss = 0.003961769351301764
Trained batch 892 in epoch 9, gen_loss = 0.9300004947359057, disc_loss = 0.00395801885264119
Trained batch 893 in epoch 9, gen_loss = 0.9299162826282066, disc_loss = 0.00395368979936812
Trained batch 894 in epoch 9, gen_loss = 0.9297692770398529, disc_loss = 0.003949411975154159
Trained batch 895 in epoch 9, gen_loss = 0.9298828818968364, disc_loss = 0.003945246036453552
Trained batch 896 in epoch 9, gen_loss = 0.9297349551316754, disc_loss = 0.003941041574343741
Trained batch 897 in epoch 9, gen_loss = 0.9297650977471358, disc_loss = 0.003936796616536657
Trained batch 898 in epoch 9, gen_loss = 0.9297550581851446, disc_loss = 0.00393255308815269
Trained batch 899 in epoch 9, gen_loss = 0.9297415784332488, disc_loss = 0.003928282393939703
Trained batch 900 in epoch 9, gen_loss = 0.9297573999744674, disc_loss = 0.003924001539586661
Trained batch 901 in epoch 9, gen_loss = 0.9295803864224258, disc_loss = 0.003919941663675339
Trained batch 902 in epoch 9, gen_loss = 0.9295409395713214, disc_loss = 0.003915758014621537
Trained batch 903 in epoch 9, gen_loss = 0.9294908806286027, disc_loss = 0.003911690123402926
Trained batch 904 in epoch 9, gen_loss = 0.9293919660768456, disc_loss = 0.003907490185680941
Trained batch 905 in epoch 9, gen_loss = 0.9292842666834396, disc_loss = 0.0039032947589650625
Trained batch 906 in epoch 9, gen_loss = 0.9292172291444444, disc_loss = 0.0038991168202749424
Trained batch 907 in epoch 9, gen_loss = 0.9291953378837015, disc_loss = 0.003894960104960549
Trained batch 908 in epoch 9, gen_loss = 0.9292229523490889, disc_loss = 0.0038908045795510242
Trained batch 909 in epoch 9, gen_loss = 0.929173254770237, disc_loss = 0.00388668461011628
Trained batch 910 in epoch 9, gen_loss = 0.9292148179594432, disc_loss = 0.003882540993073124
Trained batch 911 in epoch 9, gen_loss = 0.9291517833215103, disc_loss = 0.0038784428043072694
Trained batch 912 in epoch 9, gen_loss = 0.9290204911216327, disc_loss = 0.0038743186961461766
Trained batch 913 in epoch 9, gen_loss = 0.9288814298694452, disc_loss = 0.00387016513579403
Trained batch 914 in epoch 9, gen_loss = 0.9289303894251422, disc_loss = 0.0038660858831984814
Trained batch 915 in epoch 9, gen_loss = 0.9289482088849014, disc_loss = 0.003862046454527619
Trained batch 916 in epoch 9, gen_loss = 0.9288891132681294, disc_loss = 0.003857937344904893
Trained batch 917 in epoch 9, gen_loss = 0.9288990994943772, disc_loss = 0.003853832573294112
Trained batch 918 in epoch 9, gen_loss = 0.9288580228895824, disc_loss = 0.0038498350947596726
Trained batch 919 in epoch 9, gen_loss = 0.9288099148999089, disc_loss = 0.003845749553163288
Trained batch 920 in epoch 9, gen_loss = 0.9287299788218238, disc_loss = 0.003841694441336929
Trained batch 921 in epoch 9, gen_loss = 0.9286258845163788, disc_loss = 0.003837670029164115
Trained batch 922 in epoch 9, gen_loss = 0.9285812596200218, disc_loss = 0.0038336207417770966
Trained batch 923 in epoch 9, gen_loss = 0.9286356991503661, disc_loss = 0.003829587859017999
Trained batch 924 in epoch 9, gen_loss = 0.9285601369754688, disc_loss = 0.003825554769113345
Trained batch 925 in epoch 9, gen_loss = 0.9284927644173476, disc_loss = 0.0038216246226731435
Trained batch 926 in epoch 9, gen_loss = 0.9283758362005701, disc_loss = 0.003817657845800513
Trained batch 927 in epoch 9, gen_loss = 0.9283894184848358, disc_loss = 0.003813653626335069
Trained batch 928 in epoch 9, gen_loss = 0.9284495502806582, disc_loss = 0.0038097108546927654
Trained batch 929 in epoch 9, gen_loss = 0.9283724333009412, disc_loss = 0.003805781239412114
Trained batch 930 in epoch 9, gen_loss = 0.9282637692419722, disc_loss = 0.0038017866406269635
Trained batch 931 in epoch 9, gen_loss = 0.9283077565897176, disc_loss = 0.0037979042924035744
Trained batch 932 in epoch 9, gen_loss = 0.9283400085322471, disc_loss = 0.0037940251398911463
Trained batch 933 in epoch 9, gen_loss = 0.9282600559310178, disc_loss = 0.003790304746229014
Trained batch 934 in epoch 9, gen_loss = 0.9282808868005314, disc_loss = 0.003786378599574757
Trained batch 935 in epoch 9, gen_loss = 0.928266110137487, disc_loss = 0.0037825082265868317
Trained batch 936 in epoch 9, gen_loss = 0.9283298144600053, disc_loss = 0.0037785717911498094
Trained batch 937 in epoch 9, gen_loss = 0.9282326883217419, disc_loss = 0.0037746890683144976
Trained batch 938 in epoch 9, gen_loss = 0.9282774052426965, disc_loss = 0.003770831250274121
Trained batch 939 in epoch 9, gen_loss = 0.9283132898046615, disc_loss = 0.0037669342441655857
Trained batch 940 in epoch 9, gen_loss = 0.9283681148296968, disc_loss = 0.003763090830463478
Trained batch 941 in epoch 9, gen_loss = 0.9282930937542277, disc_loss = 0.0037592014168405085
Trained batch 942 in epoch 9, gen_loss = 0.9281377375821167, disc_loss = 0.00375532150648139
Trained batch 943 in epoch 9, gen_loss = 0.9282669118779191, disc_loss = 0.003751651217198279
Trained batch 944 in epoch 9, gen_loss = 0.9282118049248186, disc_loss = 0.003747842972228124
Trained batch 945 in epoch 9, gen_loss = 0.9282053667445516, disc_loss = 0.003744076876375929
Trained batch 946 in epoch 9, gen_loss = 0.9283064243785935, disc_loss = 0.0037403952574998228
Trained batch 947 in epoch 9, gen_loss = 0.9281494998479192, disc_loss = 0.003736661422941777
Trained batch 948 in epoch 9, gen_loss = 0.9280961941617558, disc_loss = 0.0037328627610782646
Trained batch 949 in epoch 9, gen_loss = 0.9281516306023848, disc_loss = 0.0037292767994605174
Trained batch 950 in epoch 9, gen_loss = 0.9280691381884674, disc_loss = 0.0037254997067574925
Trained batch 951 in epoch 9, gen_loss = 0.9280245080590248, disc_loss = 0.0037218194086203805
Trained batch 952 in epoch 9, gen_loss = 0.9279158471263593, disc_loss = 0.0037180325379642803
Trained batch 953 in epoch 9, gen_loss = 0.9278300141513472, disc_loss = 0.00371421804291542
Trained batch 954 in epoch 9, gen_loss = 0.9277002307757033, disc_loss = 0.0037104176342988957
Trained batch 955 in epoch 9, gen_loss = 0.9277363405192747, disc_loss = 0.003706733815264647
Trained batch 956 in epoch 9, gen_loss = 0.9276488810123694, disc_loss = 0.003702988435535012
Trained batch 957 in epoch 9, gen_loss = 0.9277682076665206, disc_loss = 0.003699326616321413
Trained batch 958 in epoch 9, gen_loss = 0.9277422801670118, disc_loss = 0.003695578542429948
Trained batch 959 in epoch 9, gen_loss = 0.9276324864476919, disc_loss = 0.0036917996120564567
Trained batch 960 in epoch 9, gen_loss = 0.9275279344678793, disc_loss = 0.003688030970723438
Trained batch 961 in epoch 9, gen_loss = 0.9274907553270304, disc_loss = 0.003684298756141254
Trained batch 962 in epoch 9, gen_loss = 0.9275444578282682, disc_loss = 0.003680549419291551
Trained batch 963 in epoch 9, gen_loss = 0.9275493845034437, disc_loss = 0.0036768688465275002
Trained batch 964 in epoch 9, gen_loss = 0.9277208333806053, disc_loss = 0.003673445615578754
Trained batch 965 in epoch 9, gen_loss = 0.927697840993202, disc_loss = 0.003669768939394946
Trained batch 966 in epoch 9, gen_loss = 0.9276665353602436, disc_loss = 0.0036661082842306477
Trained batch 967 in epoch 9, gen_loss = 0.9275615497930976, disc_loss = 0.0036624512430467457
Trained batch 968 in epoch 9, gen_loss = 0.9275377812277299, disc_loss = 0.003658784764366341
Trained batch 969 in epoch 9, gen_loss = 0.9275208856641631, disc_loss = 0.0036550779903599196
Trained batch 970 in epoch 9, gen_loss = 0.9275561874362148, disc_loss = 0.003651445264195861
Trained batch 971 in epoch 9, gen_loss = 0.9276517820946965, disc_loss = 0.0036479030072001824
Trained batch 972 in epoch 9, gen_loss = 0.9278337231397874, disc_loss = 0.0036443451416391815
Trained batch 973 in epoch 9, gen_loss = 0.9278101084535861, disc_loss = 0.0036406882753099927
Trained batch 974 in epoch 9, gen_loss = 0.9278098761729705, disc_loss = 0.003637051225016013
Trained batch 975 in epoch 9, gen_loss = 0.9277827122905216, disc_loss = 0.0036334755222775187
Trained batch 976 in epoch 9, gen_loss = 0.9278021313883021, disc_loss = 0.0036298501862455142
Trained batch 977 in epoch 9, gen_loss = 0.9277895030799819, disc_loss = 0.0036262432309472864
Trained batch 978 in epoch 9, gen_loss = 0.927674556533455, disc_loss = 0.003622640457186661
Trained batch 979 in epoch 9, gen_loss = 0.9277008483604509, disc_loss = 0.00361904163320866
Trained batch 980 in epoch 9, gen_loss = 0.9277374935806344, disc_loss = 0.0036154572652323195
Trained batch 981 in epoch 9, gen_loss = 0.927695333290003, disc_loss = 0.0036118639165871893
Trained batch 982 in epoch 9, gen_loss = 0.9277532791315236, disc_loss = 0.003608335198823939
Trained batch 983 in epoch 9, gen_loss = 0.9276630847555835, disc_loss = 0.0036047368269472037
Trained batch 984 in epoch 9, gen_loss = 0.9275774886160333, disc_loss = 0.0036011683248039004
Trained batch 985 in epoch 9, gen_loss = 0.9274922056202957, disc_loss = 0.003597595634316845
Trained batch 986 in epoch 9, gen_loss = 0.9274758599328656, disc_loss = 0.0035940600225055335
Trained batch 987 in epoch 9, gen_loss = 0.9273970078842843, disc_loss = 0.0035905165847211554
Trained batch 988 in epoch 9, gen_loss = 0.9273830020632614, disc_loss = 0.003586976028111242
Trained batch 989 in epoch 9, gen_loss = 0.927403683855076, disc_loss = 0.0035834066808882823
Trained batch 990 in epoch 9, gen_loss = 0.9274499474091439, disc_loss = 0.00357989081058592
Trained batch 991 in epoch 9, gen_loss = 0.9272601984801793, disc_loss = 0.0035764032343488525
Trained batch 992 in epoch 9, gen_loss = 0.9273566112657569, disc_loss = 0.003572955211658326
Trained batch 993 in epoch 9, gen_loss = 0.9273458141796066, disc_loss = 0.0035695121488084768
Trained batch 994 in epoch 9, gen_loss = 0.9273481543938719, disc_loss = 0.00356606061356967
Trained batch 995 in epoch 9, gen_loss = 0.9273227719537704, disc_loss = 0.003562619321759901
Trained batch 996 in epoch 9, gen_loss = 0.9273800772793195, disc_loss = 0.0035591985600248633
Trained batch 997 in epoch 9, gen_loss = 0.9275905893059198, disc_loss = 0.0035561609418178187
Trained batch 998 in epoch 9, gen_loss = 0.9276363198702281, disc_loss = 0.0035527106208881284
Trained batch 999 in epoch 9, gen_loss = 0.9275883677601814, disc_loss = 0.003549237501109019
Trained batch 1000 in epoch 9, gen_loss = 0.9275361047638999, disc_loss = 0.0035458472066874766
Trained batch 1001 in epoch 9, gen_loss = 0.9273994157533207, disc_loss = 0.003542485832375081
Trained batch 1002 in epoch 9, gen_loss = 0.9274484689903639, disc_loss = 0.003539133886409137
Trained batch 1003 in epoch 9, gen_loss = 0.9273245047881784, disc_loss = 0.0035358335042553926
Trained batch 1004 in epoch 9, gen_loss = 0.9272372654421412, disc_loss = 0.003532427781686043
Trained batch 1005 in epoch 9, gen_loss = 0.9272123726295903, disc_loss = 0.0035290075163209415
Trained batch 1006 in epoch 9, gen_loss = 0.9271885733145114, disc_loss = 0.003525640339177722
Trained batch 1007 in epoch 9, gen_loss = 0.9270499889103193, disc_loss = 0.003522318346977189
Trained batch 1008 in epoch 9, gen_loss = 0.9269863227668437, disc_loss = 0.00351890302303438
Trained batch 1009 in epoch 9, gen_loss = 0.9270880365135646, disc_loss = 0.0035155369269319853
Trained batch 1010 in epoch 9, gen_loss = 0.9270627509238812, disc_loss = 0.0035121647000936796
Trained batch 1011 in epoch 9, gen_loss = 0.9270105304218563, disc_loss = 0.003508932492234171
Trained batch 1012 in epoch 9, gen_loss = 0.9269676600368685, disc_loss = 0.003505794789759258
Trained batch 1013 in epoch 9, gen_loss = 0.9270348445433366, disc_loss = 0.0035024470987927085
Trained batch 1014 in epoch 9, gen_loss = 0.9270560709713715, disc_loss = 0.0034990716987163897
Trained batch 1015 in epoch 9, gen_loss = 0.9271560342997078, disc_loss = 0.003495796949345828
Trained batch 1016 in epoch 9, gen_loss = 0.9273164688427306, disc_loss = 0.0034927418136183603
Trained batch 1017 in epoch 9, gen_loss = 0.9272407906931369, disc_loss = 0.00348944666595794
Trained batch 1018 in epoch 9, gen_loss = 0.9272225974703443, disc_loss = 0.003486182526353131
Trained batch 1019 in epoch 9, gen_loss = 0.9271807228817659, disc_loss = 0.0034828612784265573
Trained batch 1020 in epoch 9, gen_loss = 0.9270929674910752, disc_loss = 0.00347954721818889
Trained batch 1021 in epoch 9, gen_loss = 0.9270484137208495, disc_loss = 0.003476261266562682
Trained batch 1022 in epoch 9, gen_loss = 0.9270559103607782, disc_loss = 0.0034730456691258746
Trained batch 1023 in epoch 9, gen_loss = 0.9270200206083246, disc_loss = 0.0034698184914958574
Trained batch 1024 in epoch 9, gen_loss = 0.92704274892807, disc_loss = 0.003466595120106188
Trained batch 1025 in epoch 9, gen_loss = 0.9269200452470873, disc_loss = 0.0034633368186281176
Trained batch 1026 in epoch 9, gen_loss = 0.926920843971739, disc_loss = 0.003460107578324338
Trained batch 1027 in epoch 9, gen_loss = 0.9268080655354934, disc_loss = 0.003456850379090455
Trained batch 1028 in epoch 9, gen_loss = 0.9267809666743895, disc_loss = 0.0034536194199656246
Trained batch 1029 in epoch 9, gen_loss = 0.9268799644072079, disc_loss = 0.003450594726717947
Trained batch 1030 in epoch 9, gen_loss = 0.9268491666485799, disc_loss = 0.003447409793717331
Trained batch 1031 in epoch 9, gen_loss = 0.9268493175853131, disc_loss = 0.0034442181286067353
Trained batch 1032 in epoch 9, gen_loss = 0.9269181650928929, disc_loss = 0.0034409968286561905
Trained batch 1033 in epoch 9, gen_loss = 0.9268970906273308, disc_loss = 0.0034377820841055315
Trained batch 1034 in epoch 9, gen_loss = 0.9268890252435841, disc_loss = 0.003434519785514567
Trained batch 1035 in epoch 9, gen_loss = 0.9268865299961282, disc_loss = 0.0034312661305913486
Trained batch 1036 in epoch 9, gen_loss = 0.9268166913130934, disc_loss = 0.003428028574154841
Trained batch 1037 in epoch 9, gen_loss = 0.9268097430754718, disc_loss = 0.0034248151685053914
Trained batch 1038 in epoch 9, gen_loss = 0.9267066383270028, disc_loss = 0.003421614016676548
Trained batch 1039 in epoch 9, gen_loss = 0.9267635845794128, disc_loss = 0.003418484691015832
Trained batch 1040 in epoch 9, gen_loss = 0.9267611831684277, disc_loss = 0.003415340467524282
Trained batch 1041 in epoch 9, gen_loss = 0.9267067447619337, disc_loss = 0.0034121955148419324
Trained batch 1042 in epoch 9, gen_loss = 0.9266155620435055, disc_loss = 0.003409023907431881
Trained batch 1043 in epoch 9, gen_loss = 0.9265492678944636, disc_loss = 0.003405912821428947
Trained batch 1044 in epoch 9, gen_loss = 0.9265803982196242, disc_loss = 0.003402798643045219
Trained batch 1045 in epoch 9, gen_loss = 0.9266411871230853, disc_loss = 0.0033997463294638017
Trained batch 1046 in epoch 9, gen_loss = 0.9266370374926409, disc_loss = 0.0033967115944400967
Trained batch 1047 in epoch 9, gen_loss = 0.9266573923803468, disc_loss = 0.0033937743451515276
Trained batch 1048 in epoch 9, gen_loss = 0.9265884011557718, disc_loss = 0.0033906587456543113
Trained batch 1049 in epoch 9, gen_loss = 0.9266406328905197, disc_loss = 0.003387523752053745
Trained batch 1050 in epoch 9, gen_loss = 0.9265280050623428, disc_loss = 0.0033844097356999724
Trained batch 1051 in epoch 9, gen_loss = 0.9264016841527627, disc_loss = 0.0033813567541475156
Trained batch 1052 in epoch 9, gen_loss = 0.926315130105159, disc_loss = 0.003378354546377457
Trained batch 1053 in epoch 9, gen_loss = 0.9263439593550377, disc_loss = 0.0033752829662904225
Trained batch 1054 in epoch 9, gen_loss = 0.926228981673435, disc_loss = 0.003372217153944682
Trained batch 1055 in epoch 9, gen_loss = 0.9261926448706425, disc_loss = 0.0033691257505338535
Trained batch 1056 in epoch 9, gen_loss = 0.9261306391195407, disc_loss = 0.0033660128741372464
Trained batch 1057 in epoch 9, gen_loss = 0.9260784483924931, disc_loss = 0.003362910903341677
Trained batch 1058 in epoch 9, gen_loss = 0.9261192769459444, disc_loss = 0.003359838692162538
Trained batch 1059 in epoch 9, gen_loss = 0.926146388897356, disc_loss = 0.0033567557501813115
Trained batch 1060 in epoch 9, gen_loss = 0.926152470255662, disc_loss = 0.0033537110969747708
Trained batch 1061 in epoch 9, gen_loss = 0.9261578545395264, disc_loss = 0.0033507029316262008
Trained batch 1062 in epoch 9, gen_loss = 0.9261335155252903, disc_loss = 0.0033476389558920777
Trained batch 1063 in epoch 9, gen_loss = 0.9260327902839596, disc_loss = 0.003344568215084964
Trained batch 1064 in epoch 9, gen_loss = 0.9260625768155559, disc_loss = 0.00334164529464682
Trained batch 1065 in epoch 9, gen_loss = 0.9259482314058809, disc_loss = 0.0033386066825119047
Trained batch 1066 in epoch 9, gen_loss = 0.9259655594602297, disc_loss = 0.0033355617652472192
Trained batch 1067 in epoch 9, gen_loss = 0.9258077326003978, disc_loss = 0.0033325517472255345
Trained batch 1068 in epoch 9, gen_loss = 0.9257766086437414, disc_loss = 0.0033295346869171446
Trained batch 1069 in epoch 9, gen_loss = 0.9258597988948644, disc_loss = 0.003326576689767399
Trained batch 1070 in epoch 9, gen_loss = 0.9259440951209331, disc_loss = 0.003323555794165652
Trained batch 1071 in epoch 9, gen_loss = 0.9258886120323815, disc_loss = 0.0033205258389681323
Trained batch 1072 in epoch 9, gen_loss = 0.9258854501956219, disc_loss = 0.003317543864837413
Trained batch 1073 in epoch 9, gen_loss = 0.9259138196651274, disc_loss = 0.0033145708232847396
Trained batch 1074 in epoch 9, gen_loss = 0.9258030068042666, disc_loss = 0.0033115705837790726
Trained batch 1075 in epoch 9, gen_loss = 0.9256955635591954, disc_loss = 0.003308555222085089
Trained batch 1076 in epoch 9, gen_loss = 0.9257611725877144, disc_loss = 0.0033055752208513687
Trained batch 1077 in epoch 9, gen_loss = 0.9256912733053232, disc_loss = 0.0033026149397340004
Trained batch 1078 in epoch 9, gen_loss = 0.9257422221601838, disc_loss = 0.0032996453707513917
Trained batch 1079 in epoch 9, gen_loss = 0.9257536417908139, disc_loss = 0.0032966939217321514
Trained batch 1080 in epoch 9, gen_loss = 0.9257012779904559, disc_loss = 0.00329373230898176
Trained batch 1081 in epoch 9, gen_loss = 0.9257102155861705, disc_loss = 0.0032908271533716167
Trained batch 1082 in epoch 9, gen_loss = 0.9257020070282046, disc_loss = 0.0032879975372444906
Trained batch 1083 in epoch 9, gen_loss = 0.9257395979553131, disc_loss = 0.0032850495087932427
Trained batch 1084 in epoch 9, gen_loss = 0.9257397549492973, disc_loss = 0.0032820946551174834
Trained batch 1085 in epoch 9, gen_loss = 0.925700480876487, disc_loss = 0.0032791354924065303
Trained batch 1086 in epoch 9, gen_loss = 0.9256465252978932, disc_loss = 0.0032762423162819264
Trained batch 1087 in epoch 9, gen_loss = 0.9255918256171486, disc_loss = 0.0032733661569917627
Trained batch 1088 in epoch 9, gen_loss = 0.9255253766193863, disc_loss = 0.0032705353653661655
Trained batch 1089 in epoch 9, gen_loss = 0.9254286816907585, disc_loss = 0.003267629352815283
Trained batch 1090 in epoch 9, gen_loss = 0.9253613757060057, disc_loss = 0.003264724758440222
Trained batch 1091 in epoch 9, gen_loss = 0.9253256953570432, disc_loss = 0.003261801710243242
Trained batch 1092 in epoch 9, gen_loss = 0.9253620121420139, disc_loss = 0.003259485156445428
Trained batch 1093 in epoch 9, gen_loss = 0.9254605768476587, disc_loss = 0.0032566411247543126
Trained batch 1094 in epoch 9, gen_loss = 0.925512688072849, disc_loss = 0.0032538916464213527
Trained batch 1095 in epoch 9, gen_loss = 0.9256940944677722, disc_loss = 0.003251379966583629
Trained batch 1096 in epoch 9, gen_loss = 0.925731392317505, disc_loss = 0.0032485341745288237
Trained batch 1097 in epoch 9, gen_loss = 0.9257204806761229, disc_loss = 0.0032456921403097388
Trained batch 1098 in epoch 9, gen_loss = 0.925728283490345, disc_loss = 0.003242826448320547
Trained batch 1099 in epoch 9, gen_loss = 0.9256869915940544, disc_loss = 0.0032399526146764403
Trained batch 1100 in epoch 9, gen_loss = 0.9255873639945221, disc_loss = 0.003237138116085876
Trained batch 1101 in epoch 9, gen_loss = 0.9256107246269981, disc_loss = 0.003234311677473779
Trained batch 1102 in epoch 9, gen_loss = 0.925514865602457, disc_loss = 0.003231561594921441
Trained batch 1103 in epoch 9, gen_loss = 0.9254696939842425, disc_loss = 0.003228712944351371
Trained batch 1104 in epoch 9, gen_loss = 0.9253743638280291, disc_loss = 0.0032259093632495423
Trained batch 1105 in epoch 9, gen_loss = 0.9253189851534949, disc_loss = 0.0032230486364707403
Trained batch 1106 in epoch 9, gen_loss = 0.9252399670291614, disc_loss = 0.0032203031062783063
Trained batch 1107 in epoch 9, gen_loss = 0.9251710308803117, disc_loss = 0.003217516387504419
Trained batch 1108 in epoch 9, gen_loss = 0.9250843772165833, disc_loss = 0.0032147068834520445
Trained batch 1109 in epoch 9, gen_loss = 0.9251132673508412, disc_loss = 0.0032119225732851584
Trained batch 1110 in epoch 9, gen_loss = 0.9250594319039696, disc_loss = 0.0032091248861775366
Trained batch 1111 in epoch 9, gen_loss = 0.9249921920809815, disc_loss = 0.0032066780923552295
Trained batch 1112 in epoch 9, gen_loss = 0.9249431524101079, disc_loss = 0.003203960444647145
Trained batch 1113 in epoch 9, gen_loss = 0.925064811854217, disc_loss = 0.0032013005064732455
Trained batch 1114 in epoch 9, gen_loss = 0.9249646667942338, disc_loss = 0.0031985359916799167
Trained batch 1115 in epoch 9, gen_loss = 0.9249057116047028, disc_loss = 0.003195801954914903
Trained batch 1116 in epoch 9, gen_loss = 0.9248727530160971, disc_loss = 0.003193047529837334
Trained batch 1117 in epoch 9, gen_loss = 0.9249867615631526, disc_loss = 0.0031904330373992533
Trained batch 1118 in epoch 9, gen_loss = 0.9248745300814549, disc_loss = 0.0031877181478922206
Trained batch 1119 in epoch 9, gen_loss = 0.9248335346579551, disc_loss = 0.003184983656053321
Trained batch 1120 in epoch 9, gen_loss = 0.9247649163140663, disc_loss = 0.0031822294463393864
Trained batch 1121 in epoch 9, gen_loss = 0.924671112428587, disc_loss = 0.0031794974559111026
Trained batch 1122 in epoch 9, gen_loss = 0.9246876135747133, disc_loss = 0.003176761545412029
Trained batch 1123 in epoch 9, gen_loss = 0.9246882119636943, disc_loss = 0.003174092574430869
Trained batch 1124 in epoch 9, gen_loss = 0.924697819603814, disc_loss = 0.0031713871037354693
Trained batch 1125 in epoch 9, gen_loss = 0.9246759172231224, disc_loss = 0.0031687267737926916
Trained batch 1126 in epoch 9, gen_loss = 0.9246257599625, disc_loss = 0.0031660800219484348
Trained batch 1127 in epoch 9, gen_loss = 0.9246454027527613, disc_loss = 0.0031633843869029285
Trained batch 1128 in epoch 9, gen_loss = 0.9247441082744075, disc_loss = 0.0031606996250801832
Trained batch 1129 in epoch 9, gen_loss = 0.9247549980615093, disc_loss = 0.003158382363671507
Trained batch 1130 in epoch 9, gen_loss = 0.9247306263836794, disc_loss = 0.0031557376266313653
Trained batch 1131 in epoch 9, gen_loss = 0.9246945548605161, disc_loss = 0.0031530766380057536
Trained batch 1132 in epoch 9, gen_loss = 0.9246825111301621, disc_loss = 0.0031504774073165343
Trained batch 1133 in epoch 9, gen_loss = 0.9246592889597387, disc_loss = 0.0031478218868876006
Trained batch 1134 in epoch 9, gen_loss = 0.9246811935555043, disc_loss = 0.003145243640589561
Trained batch 1135 in epoch 9, gen_loss = 0.9246150583133731, disc_loss = 0.003142755376001345
Trained batch 1136 in epoch 9, gen_loss = 0.9245899264080648, disc_loss = 0.0031401742039933937
Trained batch 1137 in epoch 9, gen_loss = 0.9244672671248498, disc_loss = 0.003137694200513531
Trained batch 1138 in epoch 9, gen_loss = 0.9244920556957623, disc_loss = 0.0031351760491570156
Trained batch 1139 in epoch 9, gen_loss = 0.9244725697396095, disc_loss = 0.0031325435794235345
Trained batch 1140 in epoch 9, gen_loss = 0.9243906974583525, disc_loss = 0.0031299731356266678
Trained batch 1141 in epoch 9, gen_loss = 0.9243741966588276, disc_loss = 0.00312743792103674
Trained batch 1142 in epoch 9, gen_loss = 0.9243301923923709, disc_loss = 0.0031249366367164686
Trained batch 1143 in epoch 9, gen_loss = 0.9244200587272644, disc_loss = 0.003122446105369856
Trained batch 1144 in epoch 9, gen_loss = 0.9243962556514157, disc_loss = 0.0031199095622401513
Trained batch 1145 in epoch 9, gen_loss = 0.9243867073279609, disc_loss = 0.003117368323715744
Trained batch 1146 in epoch 9, gen_loss = 0.9244010966553725, disc_loss = 0.003114985461070636
Trained batch 1147 in epoch 9, gen_loss = 0.9243033833100821, disc_loss = 0.0031124593509203563
Trained batch 1148 in epoch 9, gen_loss = 0.9242412859299994, disc_loss = 0.003109874087309844
Trained batch 1149 in epoch 9, gen_loss = 0.924242980013723, disc_loss = 0.0031072681773335006
Trained batch 1150 in epoch 9, gen_loss = 0.9242036760008718, disc_loss = 0.003104685418949077
Trained batch 1151 in epoch 9, gen_loss = 0.9242291157651279, disc_loss = 0.003102299068921689
Trained batch 1152 in epoch 9, gen_loss = 0.9241098832381051, disc_loss = 0.0031000038737755576
Trained batch 1153 in epoch 9, gen_loss = 0.9242322806469077, disc_loss = 0.003098044543380236
Trained batch 1154 in epoch 9, gen_loss = 0.9242314183350765, disc_loss = 0.0030956129775620953
Trained batch 1155 in epoch 9, gen_loss = 0.9243283623951941, disc_loss = 0.003093251028280896
Trained batch 1156 in epoch 9, gen_loss = 0.9243739118015549, disc_loss = 0.0030908256424323805
Trained batch 1157 in epoch 9, gen_loss = 0.9243325888081124, disc_loss = 0.0030883580233003693
Trained batch 1158 in epoch 9, gen_loss = 0.9242463847807093, disc_loss = 0.00308594731867993
Trained batch 1159 in epoch 9, gen_loss = 0.9241575875158967, disc_loss = 0.0030835500926043786
Trained batch 1160 in epoch 9, gen_loss = 0.9241220282645805, disc_loss = 0.0030810903939690734
Trained batch 1161 in epoch 9, gen_loss = 0.9241366681872054, disc_loss = 0.0030787313223586328
Trained batch 1162 in epoch 9, gen_loss = 0.9242336294923685, disc_loss = 0.003076412500248794
Trained batch 1163 in epoch 9, gen_loss = 0.9242589480893308, disc_loss = 0.0030740908539733072
Trained batch 1164 in epoch 9, gen_loss = 0.9242193502417961, disc_loss = 0.0030730056414985728
Trained batch 1165 in epoch 9, gen_loss = 0.9242010929367759, disc_loss = 0.003070946233342815
Trained batch 1166 in epoch 9, gen_loss = 0.9241777642118492, disc_loss = 0.0030687528633092684
Trained batch 1167 in epoch 9, gen_loss = 0.924145409760818, disc_loss = 0.0030663754864815006
Trained batch 1168 in epoch 9, gen_loss = 0.9241773834383519, disc_loss = 0.0030640130848838417
Trained batch 1169 in epoch 9, gen_loss = 0.9241278340673854, disc_loss = 0.0030615795653899953
Trained batch 1170 in epoch 9, gen_loss = 0.9241607828999462, disc_loss = 0.0030591914011759507
Trained batch 1171 in epoch 9, gen_loss = 0.9243038795608709, disc_loss = 0.003057054975196954
Trained batch 1172 in epoch 9, gen_loss = 0.9244606695618268, disc_loss = 0.0030552411010924658
Trained batch 1173 in epoch 9, gen_loss = 0.9244390649933628, disc_loss = 0.0030531622973598246
Trained batch 1174 in epoch 9, gen_loss = 0.9244126586203879, disc_loss = 0.0030508457785014043
Trained batch 1175 in epoch 9, gen_loss = 0.9244960011774991, disc_loss = 0.003048643288449818
Trained batch 1176 in epoch 9, gen_loss = 0.9244889117138003, disc_loss = 0.0030469271967943877
Trained batch 1177 in epoch 9, gen_loss = 0.9245332048380517, disc_loss = 0.003044849252691704
Trained batch 1178 in epoch 9, gen_loss = 0.9244747594618211, disc_loss = 0.003042559430265175
Trained batch 1179 in epoch 9, gen_loss = 0.9244710875264669, disc_loss = 0.0030402207626678518
Trained batch 1180 in epoch 9, gen_loss = 0.9245512300280572, disc_loss = 0.0030381197651319744
Trained batch 1181 in epoch 9, gen_loss = 0.9246361407430845, disc_loss = 0.0030368878170211155
Trained batch 1182 in epoch 9, gen_loss = 0.9244757057848565, disc_loss = 0.0030448499019688252
Trained batch 1183 in epoch 9, gen_loss = 0.9245333753626894, disc_loss = 0.003044570365822487
Trained batch 1184 in epoch 9, gen_loss = 0.924563236880403, disc_loss = 0.003042923406994251
Trained batch 1185 in epoch 9, gen_loss = 0.9247205110665718, disc_loss = 0.0030412292422965373
Trained batch 1186 in epoch 9, gen_loss = 0.9247705749131695, disc_loss = 0.0030390491317535424
Trained batch 1187 in epoch 9, gen_loss = 0.9248692194119046, disc_loss = 0.0030369187891539653
Trained batch 1188 in epoch 9, gen_loss = 0.9249202831639675, disc_loss = 0.003034681569530264
Trained batch 1189 in epoch 9, gen_loss = 0.9248807479854392, disc_loss = 0.003032745639498868
Trained batch 1190 in epoch 9, gen_loss = 0.9249069910405765, disc_loss = 0.0030304040052256224
Trained batch 1191 in epoch 9, gen_loss = 0.9249593536025725, disc_loss = 0.003028203585396211
Trained batch 1192 in epoch 9, gen_loss = 0.9249690977945512, disc_loss = 0.0030259015456687373
Trained batch 1193 in epoch 9, gen_loss = 0.9249915906931687, disc_loss = 0.003023558804331029
Trained batch 1194 in epoch 9, gen_loss = 0.9249398512321536, disc_loss = 0.003021210793822967
Trained batch 1195 in epoch 9, gen_loss = 0.9248493209132382, disc_loss = 0.003018792670448733
Trained batch 1196 in epoch 9, gen_loss = 0.9248619007387058, disc_loss = 0.003016362422610154
Trained batch 1197 in epoch 9, gen_loss = 0.9247826960727648, disc_loss = 0.0030140582797220437
Trained batch 1198 in epoch 9, gen_loss = 0.9247299981574598, disc_loss = 0.003011856110745121
Trained batch 1199 in epoch 9, gen_loss = 0.9248043035467466, disc_loss = 0.0030097075838602903
Trained batch 1200 in epoch 9, gen_loss = 0.9247902577167546, disc_loss = 0.00300732534610798
Trained batch 1201 in epoch 9, gen_loss = 0.9248456475937029, disc_loss = 0.003004951190603957
Trained batch 1202 in epoch 9, gen_loss = 0.9247978406455848, disc_loss = 0.0030026639658155586
Trained batch 1203 in epoch 9, gen_loss = 0.9248052674076486, disc_loss = 0.0030002700947152094
Trained batch 1204 in epoch 9, gen_loss = 0.9246997000270859, disc_loss = 0.0029979261955093203
Trained batch 1205 in epoch 9, gen_loss = 0.9246413000978245, disc_loss = 0.0029955550815438936
Trained batch 1206 in epoch 9, gen_loss = 0.9246495785353691, disc_loss = 0.0029932251868057436
Trained batch 1207 in epoch 9, gen_loss = 0.9245956738954348, disc_loss = 0.002990919814565975
Trained batch 1208 in epoch 9, gen_loss = 0.924627788260123, disc_loss = 0.0029892981504254304
Trained batch 1209 in epoch 9, gen_loss = 0.9245849985229082, disc_loss = 0.002986994943652958
Trained batch 1210 in epoch 9, gen_loss = 0.9246951854002564, disc_loss = 0.002984713894019892
Trained batch 1211 in epoch 9, gen_loss = 0.924621765615523, disc_loss = 0.0029823686590353575
Trained batch 1212 in epoch 9, gen_loss = 0.924626144562884, disc_loss = 0.002980081102260059
Trained batch 1213 in epoch 9, gen_loss = 0.9246287308571955, disc_loss = 0.0029777632874190326
Trained batch 1214 in epoch 9, gen_loss = 0.9246195052386311, disc_loss = 0.002975420445751604
Trained batch 1215 in epoch 9, gen_loss = 0.924682584248091, disc_loss = 0.002973069396429501
Trained batch 1216 in epoch 9, gen_loss = 0.9246703081671684, disc_loss = 0.0029707180624991797
Trained batch 1217 in epoch 9, gen_loss = 0.9246552972175022, disc_loss = 0.0029683879671234784
Trained batch 1218 in epoch 9, gen_loss = 0.9246657934220136, disc_loss = 0.0029660559666749007
Trained batch 1219 in epoch 9, gen_loss = 0.9245474793871895, disc_loss = 0.0029637322370781177
Trained batch 1220 in epoch 9, gen_loss = 0.9245581691817706, disc_loss = 0.002961393627790043
Trained batch 1221 in epoch 9, gen_loss = 0.9245284466033287, disc_loss = 0.0029590509743200604
Trained batch 1222 in epoch 9, gen_loss = 0.9244503638633235, disc_loss = 0.002956749371652317
Trained batch 1223 in epoch 9, gen_loss = 0.9243969830617406, disc_loss = 0.002954414253865395
Trained batch 1224 in epoch 9, gen_loss = 0.9243855175680044, disc_loss = 0.0029520916324928498
Trained batch 1225 in epoch 9, gen_loss = 0.9242772872257389, disc_loss = 0.00294979840000273
Trained batch 1226 in epoch 9, gen_loss = 0.9242746026514017, disc_loss = 0.002947457524269065
Trained batch 1227 in epoch 9, gen_loss = 0.9242454222630988, disc_loss = 0.0029451706738361757
Trained batch 1228 in epoch 9, gen_loss = 0.9242014091998412, disc_loss = 0.0029428575712903476
Trained batch 1229 in epoch 9, gen_loss = 0.9241195257117109, disc_loss = 0.002940523651909089
Trained batch 1230 in epoch 9, gen_loss = 0.9240381768038368, disc_loss = 0.002938245071273777
Trained batch 1231 in epoch 9, gen_loss = 0.9241103075154415, disc_loss = 0.002936235782602704
Trained batch 1232 in epoch 9, gen_loss = 0.9241731193910647, disc_loss = 0.0029340151598602356
Trained batch 1233 in epoch 9, gen_loss = 0.9240057199855292, disc_loss = 0.002932092870225101
Trained batch 1234 in epoch 9, gen_loss = 0.9240231542452144, disc_loss = 0.0029300648672470862
Trained batch 1235 in epoch 9, gen_loss = 0.9241063382151058, disc_loss = 0.002927813099051909
Trained batch 1236 in epoch 9, gen_loss = 0.924062684214491, disc_loss = 0.002925544680038472
Trained batch 1237 in epoch 9, gen_loss = 0.9240842987820868, disc_loss = 0.00292329637252575
Trained batch 1238 in epoch 9, gen_loss = 0.9240422311860578, disc_loss = 0.0029210224821474393
Trained batch 1239 in epoch 9, gen_loss = 0.9239924050146534, disc_loss = 0.0029187392733283266
Trained batch 1240 in epoch 9, gen_loss = 0.9238648970793756, disc_loss = 0.002916564964222152
Trained batch 1241 in epoch 9, gen_loss = 0.9237468033405126, disc_loss = 0.0029143300933109884
Trained batch 1242 in epoch 9, gen_loss = 0.9237565381432961, disc_loss = 0.0029122324316278743
Trained batch 1243 in epoch 9, gen_loss = 0.9237009028146504, disc_loss = 0.002909988738965431
Trained batch 1244 in epoch 9, gen_loss = 0.923632002068332, disc_loss = 0.0029077392756302156
Trained batch 1245 in epoch 9, gen_loss = 0.9236761918037316, disc_loss = 0.002905538945165362
Trained batch 1246 in epoch 9, gen_loss = 0.9236118621891177, disc_loss = 0.0029033236713669583
Trained batch 1247 in epoch 9, gen_loss = 0.9236382453296429, disc_loss = 0.0029011045094776843
Trained batch 1248 in epoch 9, gen_loss = 0.9235960582049013, disc_loss = 0.00289884699763282
Trained batch 1249 in epoch 9, gen_loss = 0.9237107593536377, disc_loss = 0.0028966336624813268
Trained batch 1250 in epoch 9, gen_loss = 0.9237460246284326, disc_loss = 0.002894397939713871
Trained batch 1251 in epoch 9, gen_loss = 0.9236564341539772, disc_loss = 0.0028921810396732267
Trained batch 1252 in epoch 9, gen_loss = 0.9236448970872311, disc_loss = 0.002889996523595055
Trained batch 1253 in epoch 9, gen_loss = 0.9236167937374571, disc_loss = 0.0028878039120172616
Trained batch 1254 in epoch 9, gen_loss = 0.9235955067364818, disc_loss = 0.0028855965545053586
Trained batch 1255 in epoch 9, gen_loss = 0.9235811187962818, disc_loss = 0.00288338621962533
Trained batch 1256 in epoch 9, gen_loss = 0.9234918305678508, disc_loss = 0.00288123685342216
Trained batch 1257 in epoch 9, gen_loss = 0.9234198644070254, disc_loss = 0.002879059347489257
Trained batch 1258 in epoch 9, gen_loss = 0.92338295731874, disc_loss = 0.0028768698422035176
Trained batch 1259 in epoch 9, gen_loss = 0.9232841978470484, disc_loss = 0.002874690721953465
Trained batch 1260 in epoch 9, gen_loss = 0.9233138523907249, disc_loss = 0.002872503660431388
Trained batch 1261 in epoch 9, gen_loss = 0.9232776784197843, disc_loss = 0.0028703349722641013
Trained batch 1262 in epoch 9, gen_loss = 0.9232249852219745, disc_loss = 0.0028681630986702672
Trained batch 1263 in epoch 9, gen_loss = 0.9232239127630675, disc_loss = 0.002866020963987858
Trained batch 1264 in epoch 9, gen_loss = 0.9231651648702358, disc_loss = 0.002863842159511499
Trained batch 1265 in epoch 9, gen_loss = 0.9231511638345311, disc_loss = 0.0028616689531501135
Trained batch 1266 in epoch 9, gen_loss = 0.9230919949822098, disc_loss = 0.0028594908994413405
Trained batch 1267 in epoch 9, gen_loss = 0.9229726871763494, disc_loss = 0.0028573001098048056
Trained batch 1268 in epoch 9, gen_loss = 0.9230562054425173, disc_loss = 0.0028551874094588756
Trained batch 1269 in epoch 9, gen_loss = 0.9231665034463087, disc_loss = 0.00285306707394445
Trained batch 1270 in epoch 9, gen_loss = 0.9232423036798166, disc_loss = 0.0028510069080542725
Trained batch 1271 in epoch 9, gen_loss = 0.9232945446885606, disc_loss = 0.0028489099151453767
Trained batch 1272 in epoch 9, gen_loss = 0.9233497205158901, disc_loss = 0.002846760233175207
Trained batch 1273 in epoch 9, gen_loss = 0.9234059315461379, disc_loss = 0.002844632197213666
Trained batch 1274 in epoch 9, gen_loss = 0.9232744081347597, disc_loss = 0.0028428902941545946
Trained batch 1275 in epoch 9, gen_loss = 0.923342762602534, disc_loss = 0.0028418129585129734
Trained batch 1276 in epoch 9, gen_loss = 0.9233941130089218, disc_loss = 0.002840108885851885
Trained batch 1277 in epoch 9, gen_loss = 0.9234555931718137, disc_loss = 0.0028382508281710544
Trained batch 1278 in epoch 9, gen_loss = 0.9235155465921636, disc_loss = 0.0028362694555979827
Trained batch 1279 in epoch 9, gen_loss = 0.9235537757631391, disc_loss = 0.002834239558319496
Trained batch 1280 in epoch 9, gen_loss = 0.9236077213082623, disc_loss = 0.0028322239113641886
Trained batch 1281 in epoch 9, gen_loss = 0.92365680395534, disc_loss = 0.002830211777622701
Trained batch 1282 in epoch 9, gen_loss = 0.9236674741293802, disc_loss = 0.0028282008684827895
Trained batch 1283 in epoch 9, gen_loss = 0.923660258034308, disc_loss = 0.0028261936610741206
Trained batch 1284 in epoch 9, gen_loss = 0.923773530624256, disc_loss = 0.002824154451597257
Trained batch 1285 in epoch 9, gen_loss = 0.9238335144000699, disc_loss = 0.0028220888449554077
Trained batch 1286 in epoch 9, gen_loss = 0.9238447414504157, disc_loss = 0.0028200191323534698
Trained batch 1287 in epoch 9, gen_loss = 0.9238693408714318, disc_loss = 0.0028181056242478834
Trained batch 1288 in epoch 9, gen_loss = 0.9239001186713403, disc_loss = 0.0028166143827666325
Trained batch 1289 in epoch 9, gen_loss = 0.9238602272761884, disc_loss = 0.002816753241941044
Trained batch 1290 in epoch 9, gen_loss = 0.9241447234966328, disc_loss = 0.0028149292006120906
Trained batch 1291 in epoch 9, gen_loss = 0.9242248609431388, disc_loss = 0.0028134442976632318
Trained batch 1292 in epoch 9, gen_loss = 0.924326051461632, disc_loss = 0.0028115663412885995
Trained batch 1293 in epoch 9, gen_loss = 0.9243802497339028, disc_loss = 0.002809751467627957
Trained batch 1294 in epoch 9, gen_loss = 0.9244467655203977, disc_loss = 0.0028078662273590903
Trained batch 1295 in epoch 9, gen_loss = 0.9244334096617904, disc_loss = 0.0028058842601666706
Trained batch 1296 in epoch 9, gen_loss = 0.9244819691113169, disc_loss = 0.0028040101455934574
Trained batch 1297 in epoch 9, gen_loss = 0.9244455035735719, disc_loss = 0.002802159944664004
Trained batch 1298 in epoch 9, gen_loss = 0.9244717461407598, disc_loss = 0.002800281336129549
Trained batch 1299 in epoch 9, gen_loss = 0.924516881612631, disc_loss = 0.0027983047057261084
Trained batch 1300 in epoch 9, gen_loss = 0.9245381352536776, disc_loss = 0.002796453290862256
Trained batch 1301 in epoch 9, gen_loss = 0.9246085962758452, disc_loss = 0.0027944793266589545
Trained batch 1302 in epoch 9, gen_loss = 0.9246657608292785, disc_loss = 0.002792661974897822
Trained batch 1303 in epoch 9, gen_loss = 0.9247510814410778, disc_loss = 0.002790708387982721
Trained batch 1304 in epoch 9, gen_loss = 0.9247653299821291, disc_loss = 0.00278876446272466
Trained batch 1305 in epoch 9, gen_loss = 0.9247045388265555, disc_loss = 0.0027868050883695624
Trained batch 1306 in epoch 9, gen_loss = 0.9248154169745179, disc_loss = 0.0027848088517236397
Trained batch 1307 in epoch 9, gen_loss = 0.9247917787197533, disc_loss = 0.002782801008330792
Trained batch 1308 in epoch 9, gen_loss = 0.9247047629768016, disc_loss = 0.0027808436646849784
Trained batch 1309 in epoch 9, gen_loss = 0.9246850743093563, disc_loss = 0.0027788501770505754
Trained batch 1310 in epoch 9, gen_loss = 0.9247319409176196, disc_loss = 0.0027768816554506505
Trained batch 1311 in epoch 9, gen_loss = 0.9247603388276042, disc_loss = 0.0027749365539775903
Trained batch 1312 in epoch 9, gen_loss = 0.9248264475987327, disc_loss = 0.002773050877502541
Trained batch 1313 in epoch 9, gen_loss = 0.9248682323565404, disc_loss = 0.0027711324940298794
Trained batch 1314 in epoch 9, gen_loss = 0.9248301147508077, disc_loss = 0.002769210489361437
Trained batch 1315 in epoch 9, gen_loss = 0.9248540115664433, disc_loss = 0.002767377168844747
Trained batch 1316 in epoch 9, gen_loss = 0.9248138174652238, disc_loss = 0.0027655410120377196
Trained batch 1317 in epoch 9, gen_loss = 0.9248847918011169, disc_loss = 0.00276367376001226
Trained batch 1318 in epoch 9, gen_loss = 0.9249399641953787, disc_loss = 0.0027618059920079276
Trained batch 1319 in epoch 9, gen_loss = 0.9249207338600448, disc_loss = 0.0027598865847694195
Trained batch 1320 in epoch 9, gen_loss = 0.9248232946172075, disc_loss = 0.0027579559161146064
Trained batch 1321 in epoch 9, gen_loss = 0.9247662788891035, disc_loss = 0.002756038048721053
Trained batch 1322 in epoch 9, gen_loss = 0.9247513745917755, disc_loss = 0.0027541860469881105
Trained batch 1323 in epoch 9, gen_loss = 0.9247041442333032, disc_loss = 0.002752621136794343
Trained batch 1324 in epoch 9, gen_loss = 0.9246168474431308, disc_loss = 0.00275657808923224
Trained batch 1325 in epoch 9, gen_loss = 0.9247368203299078, disc_loss = 0.0027581412357308545
Trained batch 1326 in epoch 9, gen_loss = 0.9247168467380809, disc_loss = 0.002758367341235031
Trained batch 1327 in epoch 9, gen_loss = 0.9247061158249895, disc_loss = 0.0027574415920402734
Trained batch 1328 in epoch 9, gen_loss = 0.924754021533725, disc_loss = 0.002755966070634131
Trained batch 1329 in epoch 9, gen_loss = 0.9248372465596163, disc_loss = 0.002754483927713963
Trained batch 1330 in epoch 9, gen_loss = 0.9247646529275076, disc_loss = 0.0027527909576974194
Trained batch 1331 in epoch 9, gen_loss = 0.9247659370079413, disc_loss = 0.002750984212942019
Trained batch 1332 in epoch 9, gen_loss = 0.924730846645773, disc_loss = 0.002749089425956671
Trained batch 1333 in epoch 9, gen_loss = 0.9247222122760012, disc_loss = 0.0027471958473861474
Trained batch 1334 in epoch 9, gen_loss = 0.9247147763266546, disc_loss = 0.0027453354798010567
Trained batch 1335 in epoch 9, gen_loss = 0.9245933831898038, disc_loss = 0.0027437567366619107
Trained batch 1336 in epoch 9, gen_loss = 0.9246241777533458, disc_loss = 0.002742153519626359
Trained batch 1337 in epoch 9, gen_loss = 0.9246164088559258, disc_loss = 0.00274036264307656
Trained batch 1338 in epoch 9, gen_loss = 0.9246110040541458, disc_loss = 0.0027400491041974827
Trained batch 1339 in epoch 9, gen_loss = 0.924701514217391, disc_loss = 0.0027391425163529417
Trained batch 1340 in epoch 9, gen_loss = 0.9247562257235482, disc_loss = 0.0027378511437544622
Trained batch 1341 in epoch 9, gen_loss = 0.9248206439121291, disc_loss = 0.002736180178232851
Trained batch 1342 in epoch 9, gen_loss = 0.9249378685532269, disc_loss = 0.002734498056102969
Trained batch 1343 in epoch 9, gen_loss = 0.9249669811910107, disc_loss = 0.0027327326245085715
Trained batch 1344 in epoch 9, gen_loss = 0.9249242142673761, disc_loss = 0.002730954701410257
Trained batch 1345 in epoch 9, gen_loss = 0.9248820363058201, disc_loss = 0.0027292359779019946
Trained batch 1346 in epoch 9, gen_loss = 0.9249165213453212, disc_loss = 0.0027273838331178073
Trained batch 1347 in epoch 9, gen_loss = 0.9249500342664096, disc_loss = 0.002725439417141922
Trained batch 1348 in epoch 9, gen_loss = 0.924992966554711, disc_loss = 0.0027235245688077446
Trained batch 1349 in epoch 9, gen_loss = 0.9249140503229918, disc_loss = 0.0027216679559097868
Trained batch 1350 in epoch 9, gen_loss = 0.9248031363674308, disc_loss = 0.002720260313176257
Trained batch 1351 in epoch 9, gen_loss = 0.92472504480527, disc_loss = 0.0027183921549143925
Trained batch 1352 in epoch 9, gen_loss = 0.9246773944901961, disc_loss = 0.002716620019726102
Trained batch 1353 in epoch 9, gen_loss = 0.9246991355098685, disc_loss = 0.002714783189177463
Trained batch 1354 in epoch 9, gen_loss = 0.9247345163813376, disc_loss = 0.002712930642539632
Trained batch 1355 in epoch 9, gen_loss = 0.9246947485349172, disc_loss = 0.0027109983094415788
Trained batch 1356 in epoch 9, gen_loss = 0.9248150325735088, disc_loss = 0.002709512587236462
Trained batch 1357 in epoch 9, gen_loss = 0.9248044818683647, disc_loss = 0.0027078045533661128
Trained batch 1358 in epoch 9, gen_loss = 0.9248058434967787, disc_loss = 0.0027059828986383708
Trained batch 1359 in epoch 9, gen_loss = 0.9247386178987868, disc_loss = 0.0027041584930135713
Trained batch 1360 in epoch 9, gen_loss = 0.9247443835845683, disc_loss = 0.002702353815801952
Trained batch 1361 in epoch 9, gen_loss = 0.9247217691679883, disc_loss = 0.002700521644861422
Trained batch 1362 in epoch 9, gen_loss = 0.9246735925719918, disc_loss = 0.002698629271981991
Trained batch 1363 in epoch 9, gen_loss = 0.9246585202619128, disc_loss = 0.002696747157090578
Trained batch 1364 in epoch 9, gen_loss = 0.9246897348117479, disc_loss = 0.002695053842445561
Trained batch 1365 in epoch 9, gen_loss = 0.9246706150984869, disc_loss = 0.002693235045190913
Trained batch 1366 in epoch 9, gen_loss = 0.9246780483846518, disc_loss = 0.0026913826476873937
Trained batch 1367 in epoch 9, gen_loss = 0.9246367413485259, disc_loss = 0.0026895160611897346
Trained batch 1368 in epoch 9, gen_loss = 0.9245388966306793, disc_loss = 0.002687637450863273
Trained batch 1369 in epoch 9, gen_loss = 0.9244378528020678, disc_loss = 0.0026858176892599088
Trained batch 1370 in epoch 9, gen_loss = 0.9244630809338052, disc_loss = 0.002684020733767616
Trained batch 1371 in epoch 9, gen_loss = 0.9243887775840982, disc_loss = 0.0026821749237166707
Trained batch 1372 in epoch 9, gen_loss = 0.9243269711624335, disc_loss = 0.002680320718156054
Trained batch 1373 in epoch 9, gen_loss = 0.9243190685907999, disc_loss = 0.0026784371547056113
Trained batch 1374 in epoch 9, gen_loss = 0.9243710686076771, disc_loss = 0.0026765611523720013
Trained batch 1375 in epoch 9, gen_loss = 0.9243240801747455, disc_loss = 0.0026747040882646404
Trained batch 1376 in epoch 9, gen_loss = 0.9242623979489528, disc_loss = 0.0026728175069810705
Trained batch 1377 in epoch 9, gen_loss = 0.9242938592575805, disc_loss = 0.0026709447814889926
Trained batch 1378 in epoch 9, gen_loss = 0.9243066728417644, disc_loss = 0.002669096799185383
Trained batch 1379 in epoch 9, gen_loss = 0.9243751475776452, disc_loss = 0.002667313263083233
Trained batch 1380 in epoch 9, gen_loss = 0.9243594628153807, disc_loss = 0.002665536842470748
Trained batch 1381 in epoch 9, gen_loss = 0.9243546194692079, disc_loss = 0.002663673570377888
Trained batch 1382 in epoch 9, gen_loss = 0.9242964421418467, disc_loss = 0.00266185002341601
Trained batch 1383 in epoch 9, gen_loss = 0.9243428231233117, disc_loss = 0.0026601243481398583
Trained batch 1384 in epoch 9, gen_loss = 0.9243507293587557, disc_loss = 0.0026583277283159473
Trained batch 1385 in epoch 9, gen_loss = 0.9243441190984514, disc_loss = 0.0026564692717299123
Trained batch 1386 in epoch 9, gen_loss = 0.9243730983892274, disc_loss = 0.002654652066773924
Trained batch 1387 in epoch 9, gen_loss = 0.9243026311356327, disc_loss = 0.0026528718890063245
Trained batch 1388 in epoch 9, gen_loss = 0.9242155956140604, disc_loss = 0.0026510556712757934
Trained batch 1389 in epoch 9, gen_loss = 0.9242445108701857, disc_loss = 0.0026492676622661003
Trained batch 1390 in epoch 9, gen_loss = 0.9242284626175739, disc_loss = 0.0026474820583719224
Trained batch 1391 in epoch 9, gen_loss = 0.9242346101793749, disc_loss = 0.002645731880357775
Trained batch 1392 in epoch 9, gen_loss = 0.9242615033976055, disc_loss = 0.0026439352458257582
Trained batch 1393 in epoch 9, gen_loss = 0.9243194781553796, disc_loss = 0.002642235230202304
Trained batch 1394 in epoch 9, gen_loss = 0.9243254107813681, disc_loss = 0.002640458729111224
Trained batch 1395 in epoch 9, gen_loss = 0.9243030953287736, disc_loss = 0.0026387183308470203
Trained batch 1396 in epoch 9, gen_loss = 0.9243319421985274, disc_loss = 0.0026369169077306567
Trained batch 1397 in epoch 9, gen_loss = 0.9243179631335541, disc_loss = 0.002635089348866661
Trained batch 1398 in epoch 9, gen_loss = 0.924257090681361, disc_loss = 0.0026333017003441397
Trained batch 1399 in epoch 9, gen_loss = 0.9242172599264553, disc_loss = 0.0026315359659097987
Trained batch 1400 in epoch 9, gen_loss = 0.9242330846575479, disc_loss = 0.0026297420475908323
Trained batch 1401 in epoch 9, gen_loss = 0.9241223243860988, disc_loss = 0.0026280319689404846
Trained batch 1402 in epoch 9, gen_loss = 0.924106977662272, disc_loss = 0.0026262377187496327
Trained batch 1403 in epoch 9, gen_loss = 0.9240824880762997, disc_loss = 0.0026244697494717897
Trained batch 1404 in epoch 9, gen_loss = 0.9240273210925988, disc_loss = 0.0026227290247230594
Trained batch 1405 in epoch 9, gen_loss = 0.9240808316942299, disc_loss = 0.0026209803891390896
Trained batch 1406 in epoch 9, gen_loss = 0.9240920735574735, disc_loss = 0.0026192236189067223
Trained batch 1407 in epoch 9, gen_loss = 0.9240685681050474, disc_loss = 0.002617494464640334
Trained batch 1408 in epoch 9, gen_loss = 0.9240269805202254, disc_loss = 0.0026157112337337877
Trained batch 1409 in epoch 9, gen_loss = 0.9239869000641167, disc_loss = 0.002613972571941839
Trained batch 1410 in epoch 9, gen_loss = 0.9239277990045148, disc_loss = 0.0026121913105046275
Trained batch 1411 in epoch 9, gen_loss = 0.9238761811182113, disc_loss = 0.0026104026320707
Trained batch 1412 in epoch 9, gen_loss = 0.9239581762605412, disc_loss = 0.0026087366286208767
Trained batch 1413 in epoch 9, gen_loss = 0.9238713700666792, disc_loss = 0.002606987892817199
Trained batch 1414 in epoch 9, gen_loss = 0.923957520575911, disc_loss = 0.0026052175059481835
Trained batch 1415 in epoch 9, gen_loss = 0.9239610481565281, disc_loss = 0.0026034218972867586
Trained batch 1416 in epoch 9, gen_loss = 0.9239407673046971, disc_loss = 0.0026016479763199493
Trained batch 1417 in epoch 9, gen_loss = 0.9239277216291898, disc_loss = 0.002599876994438158
Trained batch 1418 in epoch 9, gen_loss = 0.9238768582868273, disc_loss = 0.0025981437001800917
Trained batch 1419 in epoch 9, gen_loss = 0.9238089383068219, disc_loss = 0.002596417811126768
Trained batch 1420 in epoch 9, gen_loss = 0.923820960068686, disc_loss = 0.0025946732790002574
Trained batch 1421 in epoch 9, gen_loss = 0.9238166873213611, disc_loss = 0.002592931343542979
Trained batch 1422 in epoch 9, gen_loss = 0.923871860358385, disc_loss = 0.002591207513038543
Trained batch 1423 in epoch 9, gen_loss = 0.9237474396071407, disc_loss = 0.0025894669593838167
Trained batch 1424 in epoch 9, gen_loss = 0.9237780376066241, disc_loss = 0.002587744361555547
Trained batch 1425 in epoch 9, gen_loss = 0.9236515834823062, disc_loss = 0.002586033651519937
Trained batch 1426 in epoch 9, gen_loss = 0.9236196157142008, disc_loss = 0.002584354010182263
Trained batch 1427 in epoch 9, gen_loss = 0.9235731382079485, disc_loss = 0.00258264940798055
Trained batch 1428 in epoch 9, gen_loss = 0.9235913616281193, disc_loss = 0.0025809564629499264
Trained batch 1429 in epoch 9, gen_loss = 0.9235158527647699, disc_loss = 0.002579225881146902
Trained batch 1430 in epoch 9, gen_loss = 0.9234318149248093, disc_loss = 0.002577527374900688
Trained batch 1431 in epoch 9, gen_loss = 0.923336245743922, disc_loss = 0.002575808129334205
Trained batch 1432 in epoch 9, gen_loss = 0.9232766921921203, disc_loss = 0.002574057469983824
Trained batch 1433 in epoch 9, gen_loss = 0.9232739751309031, disc_loss = 0.002572358800184759
Trained batch 1434 in epoch 9, gen_loss = 0.9232798284769889, disc_loss = 0.002570603183817073
Trained batch 1435 in epoch 9, gen_loss = 0.9233222287511427, disc_loss = 0.002568907817902042
Trained batch 1436 in epoch 9, gen_loss = 0.9232854965916092, disc_loss = 0.0025671745731371616
Trained batch 1437 in epoch 9, gen_loss = 0.9233049437382954, disc_loss = 0.0025654727186683354
Trained batch 1438 in epoch 9, gen_loss = 0.9232773982542434, disc_loss = 0.0025638341808224344
Trained batch 1439 in epoch 9, gen_loss = 0.9232533964845869, disc_loss = 0.0025621932823519777
Trained batch 1440 in epoch 9, gen_loss = 0.9231559209406666, disc_loss = 0.002560521611674171
Trained batch 1441 in epoch 9, gen_loss = 0.923129069697675, disc_loss = 0.0025588502323845254
Trained batch 1442 in epoch 9, gen_loss = 0.9231553989735561, disc_loss = 0.002557203876324468
Trained batch 1443 in epoch 9, gen_loss = 0.9230784138979344, disc_loss = 0.002555510041763386
Trained batch 1444 in epoch 9, gen_loss = 0.9230529842904694, disc_loss = 0.002553811544399575
Trained batch 1445 in epoch 9, gen_loss = 0.9230387686116732, disc_loss = 0.0025521192272240987
Trained batch 1446 in epoch 9, gen_loss = 0.9230227448978173, disc_loss = 0.0025504386675164427
Trained batch 1447 in epoch 9, gen_loss = 0.9230069963477593, disc_loss = 0.0025488406642344063
Trained batch 1448 in epoch 9, gen_loss = 0.9230227986231107, disc_loss = 0.002547158988839751
Trained batch 1449 in epoch 9, gen_loss = 0.9230108809882197, disc_loss = 0.0025454879476857406
Trained batch 1450 in epoch 9, gen_loss = 0.9229932629922437, disc_loss = 0.002543788566061525
Trained batch 1451 in epoch 9, gen_loss = 0.92298256517606, disc_loss = 0.002542087331290311
Trained batch 1452 in epoch 9, gen_loss = 0.9229082173917184, disc_loss = 0.0025403865709077936
Trained batch 1453 in epoch 9, gen_loss = 0.9228940297435697, disc_loss = 0.00253869932554876
Trained batch 1454 in epoch 9, gen_loss = 0.9228367295461831, disc_loss = 0.0025370762302551046
Trained batch 1455 in epoch 9, gen_loss = 0.9228020273149014, disc_loss = 0.0025353951895800034
Trained batch 1456 in epoch 9, gen_loss = 0.9227063954081041, disc_loss = 0.0025337189198304214
Trained batch 1457 in epoch 9, gen_loss = 0.9227516248065912, disc_loss = 0.0025320901224381766
Trained batch 1458 in epoch 9, gen_loss = 0.9227914603464076, disc_loss = 0.002530416613196336
Trained batch 1459 in epoch 9, gen_loss = 0.9228219129451334, disc_loss = 0.0025287555588127436
Trained batch 1460 in epoch 9, gen_loss = 0.9228965727781939, disc_loss = 0.002527099527783915
Trained batch 1461 in epoch 9, gen_loss = 0.9229035503887119, disc_loss = 0.0025254524673904433
Trained batch 1462 in epoch 9, gen_loss = 0.9228338064270646, disc_loss = 0.0025238287152736165
Trained batch 1463 in epoch 9, gen_loss = 0.9227764237203885, disc_loss = 0.002522153629484581
Trained batch 1464 in epoch 9, gen_loss = 0.9228356956621893, disc_loss = 0.0025205203842366933
Trained batch 1465 in epoch 9, gen_loss = 0.9228758069941975, disc_loss = 0.002518943429276243
Trained batch 1466 in epoch 9, gen_loss = 0.9228596764514457, disc_loss = 0.00251726620660595
Trained batch 1467 in epoch 9, gen_loss = 0.9228275633475436, disc_loss = 0.0025156227509484483
Trained batch 1468 in epoch 9, gen_loss = 0.9228140215146614, disc_loss = 0.0025139856997218333
Trained batch 1469 in epoch 9, gen_loss = 0.922851909423361, disc_loss = 0.0025124582209581584
Trained batch 1470 in epoch 9, gen_loss = 0.9228207076349524, disc_loss = 0.0025108509210129393
Trained batch 1471 in epoch 9, gen_loss = 0.9227092355975638, disc_loss = 0.0025092122231616604
Trained batch 1472 in epoch 9, gen_loss = 0.9226795315175985, disc_loss = 0.002507601268580408
Trained batch 1473 in epoch 9, gen_loss = 0.9226450968629794, disc_loss = 0.00250598463074483
Trained batch 1474 in epoch 9, gen_loss = 0.9225824023101289, disc_loss = 0.0025043494754985875
Trained batch 1475 in epoch 9, gen_loss = 0.9225262261341581, disc_loss = 0.0025027569817012126
Trained batch 1476 in epoch 9, gen_loss = 0.9224434543398481, disc_loss = 0.0025012404089764795
Trained batch 1477 in epoch 9, gen_loss = 0.9223707995411508, disc_loss = 0.0024996009893001056
Trained batch 1478 in epoch 9, gen_loss = 0.922347659352182, disc_loss = 0.002498038246391706
Trained batch 1479 in epoch 9, gen_loss = 0.92230354398489, disc_loss = 0.0024964237691017695
Trained batch 1480 in epoch 9, gen_loss = 0.9223629657599187, disc_loss = 0.002494840525754482
Trained batch 1481 in epoch 9, gen_loss = 0.9223120887028543, disc_loss = 0.0024932810607404834
Trained batch 1482 in epoch 9, gen_loss = 0.9223505137582446, disc_loss = 0.002491719773530749
Trained batch 1483 in epoch 9, gen_loss = 0.9222787549955183, disc_loss = 0.002490084523649397
Trained batch 1484 in epoch 9, gen_loss = 0.9223090580015472, disc_loss = 0.002488489867957671
Trained batch 1485 in epoch 9, gen_loss = 0.9223429798518343, disc_loss = 0.002486885234179344
Trained batch 1486 in epoch 9, gen_loss = 0.9222533292391994, disc_loss = 0.0024852998194754626
Trained batch 1487 in epoch 9, gen_loss = 0.9222218193995055, disc_loss = 0.0024837060627369185
Trained batch 1488 in epoch 9, gen_loss = 0.9222113962058176, disc_loss = 0.002482115972541137
Trained batch 1489 in epoch 9, gen_loss = 0.9222016083314115, disc_loss = 0.0024805149031141244
Trained batch 1490 in epoch 9, gen_loss = 0.922205348929489, disc_loss = 0.002478951888622236
Trained batch 1491 in epoch 9, gen_loss = 0.9221369069638904, disc_loss = 0.002477356126728312
Trained batch 1492 in epoch 9, gen_loss = 0.92213752831857, disc_loss = 0.0024757526432971745
Trained batch 1493 in epoch 9, gen_loss = 0.9220604450109015, disc_loss = 0.002474165094481894
Trained batch 1494 in epoch 9, gen_loss = 0.9220182455503023, disc_loss = 0.0024725795903474397
Trained batch 1495 in epoch 9, gen_loss = 0.9219975973514312, disc_loss = 0.002470989300880144
Trained batch 1496 in epoch 9, gen_loss = 0.9219300683212025, disc_loss = 0.002469416926339066
Trained batch 1497 in epoch 9, gen_loss = 0.9218514284320444, disc_loss = 0.0024678151777275024
Trained batch 1498 in epoch 9, gen_loss = 0.9218735140192262, disc_loss = 0.0024662528074979972
Trained batch 1499 in epoch 9, gen_loss = 0.9219112540880839, disc_loss = 0.002464662048495181
Trained batch 1500 in epoch 9, gen_loss = 0.9218518773688228, disc_loss = 0.0024631202975144164
Trained batch 1501 in epoch 9, gen_loss = 0.9218288296151574, disc_loss = 0.0024615325725781696
Trained batch 1502 in epoch 9, gen_loss = 0.9217398054426857, disc_loss = 0.002459994093247371
Trained batch 1503 in epoch 9, gen_loss = 0.9217224247119529, disc_loss = 0.0024584094296013527
Trained batch 1504 in epoch 9, gen_loss = 0.9216697081378924, disc_loss = 0.002456840550031148
Trained batch 1505 in epoch 9, gen_loss = 0.9217563395797811, disc_loss = 0.0024552712668449855
Trained batch 1506 in epoch 9, gen_loss = 0.9217359813223157, disc_loss = 0.002453705202593059
Trained batch 1507 in epoch 9, gen_loss = 0.9217291076714543, disc_loss = 0.0024521576159079257
Trained batch 1508 in epoch 9, gen_loss = 0.9217798671949928, disc_loss = 0.002450612743378656
Trained batch 1509 in epoch 9, gen_loss = 0.9217110516219739, disc_loss = 0.002449076805722095
Trained batch 1510 in epoch 9, gen_loss = 0.9216862531547748, disc_loss = 0.0024475616611119495
Trained batch 1511 in epoch 9, gen_loss = 0.9217986322978817, disc_loss = 0.0024462076237377626
Trained batch 1512 in epoch 9, gen_loss = 0.9216976282774654, disc_loss = 0.0024447248858540187
Trained batch 1513 in epoch 9, gen_loss = 0.921638413535399, disc_loss = 0.0024431892633686473
Trained batch 1514 in epoch 9, gen_loss = 0.9215097539102284, disc_loss = 0.0024417623012959067
Trained batch 1515 in epoch 9, gen_loss = 0.9215054341781108, disc_loss = 0.0024402703326710747
Trained batch 1516 in epoch 9, gen_loss = 0.9214874168092982, disc_loss = 0.0024387345357409964
Trained batch 1517 in epoch 9, gen_loss = 0.9214697485698856, disc_loss = 0.0024371812236188557
Trained batch 1518 in epoch 9, gen_loss = 0.921491212676904, disc_loss = 0.002435653204785953
Trained batch 1519 in epoch 9, gen_loss = 0.9215338659129645, disc_loss = 0.0024341279221708214
Trained batch 1520 in epoch 9, gen_loss = 0.9215331242948203, disc_loss = 0.0024326114082159176
Trained batch 1521 in epoch 9, gen_loss = 0.9215296087064505, disc_loss = 0.0024310876841655486
Trained batch 1522 in epoch 9, gen_loss = 0.9214626618771669, disc_loss = 0.002429564184155806
Trained batch 1523 in epoch 9, gen_loss = 0.9214763570176022, disc_loss = 0.002428072934653899
Trained batch 1524 in epoch 9, gen_loss = 0.9214743881929116, disc_loss = 0.002426620374207545
Trained batch 1525 in epoch 9, gen_loss = 0.9214457224659026, disc_loss = 0.0024252256218965794
Trained batch 1526 in epoch 9, gen_loss = 0.9215002073598361, disc_loss = 0.0024237638871988953
Trained batch 1527 in epoch 9, gen_loss = 0.9215149478840579, disc_loss = 0.00242229501556093
Trained batch 1528 in epoch 9, gen_loss = 0.9215439464080716, disc_loss = 0.0024207785637587313
Trained batch 1529 in epoch 9, gen_loss = 0.9215633952150157, disc_loss = 0.0024192443242664844
Trained batch 1530 in epoch 9, gen_loss = 0.9214735768107633, disc_loss = 0.0024177252566311867
Trained batch 1531 in epoch 9, gen_loss = 0.921475992034683, disc_loss = 0.002416238839200904
Trained batch 1532 in epoch 9, gen_loss = 0.921544136444261, disc_loss = 0.002414763423385474
Trained batch 1533 in epoch 9, gen_loss = 0.9215409763477928, disc_loss = 0.002413247334052559
Trained batch 1534 in epoch 9, gen_loss = 0.9215351506242535, disc_loss = 0.0024117101846213135
Trained batch 1535 in epoch 9, gen_loss = 0.9215785080644613, disc_loss = 0.0024102718072119464
Trained batch 1536 in epoch 9, gen_loss = 0.9216182594494767, disc_loss = 0.0024089281911842137
Trained batch 1537 in epoch 9, gen_loss = 0.9216152571810238, disc_loss = 0.0024075158156745755
Trained batch 1538 in epoch 9, gen_loss = 0.9216081973327453, disc_loss = 0.0024060247514105754
Trained batch 1539 in epoch 9, gen_loss = 0.9215607114039458, disc_loss = 0.0024045026155883015
Trained batch 1540 in epoch 9, gen_loss = 0.9215541090538253, disc_loss = 0.0024029976770254292
Trained batch 1541 in epoch 9, gen_loss = 0.9215399530920383, disc_loss = 0.002401624113678704
Trained batch 1542 in epoch 9, gen_loss = 0.9215497519779885, disc_loss = 0.0024001286913311395
Trained batch 1543 in epoch 9, gen_loss = 0.9215186176908449, disc_loss = 0.0023986310667696953
Trained batch 1544 in epoch 9, gen_loss = 0.9215401522549996, disc_loss = 0.00239713117839602
Trained batch 1545 in epoch 9, gen_loss = 0.9215457543518688, disc_loss = 0.0023956263046556185
Trained batch 1546 in epoch 9, gen_loss = 0.921548049258816, disc_loss = 0.0023941697452423004
Trained batch 1547 in epoch 9, gen_loss = 0.9215734495519051, disc_loss = 0.0023926685696710063
Trained batch 1548 in epoch 9, gen_loss = 0.9215958475527877, disc_loss = 0.002391181549397742
Trained batch 1549 in epoch 9, gen_loss = 0.921595942627999, disc_loss = 0.002389687519645386
Trained batch 1550 in epoch 9, gen_loss = 0.9215764485583007, disc_loss = 0.002388210004575328
Trained batch 1551 in epoch 9, gen_loss = 0.9215610385632392, disc_loss = 0.0023867268704934664
Trained batch 1552 in epoch 9, gen_loss = 0.9214477273086847, disc_loss = 0.0023852388360555204
Trained batch 1553 in epoch 9, gen_loss = 0.9214347145655594, disc_loss = 0.002383763473722161
Trained batch 1554 in epoch 9, gen_loss = 0.9213689762296401, disc_loss = 0.00238226927451713
Trained batch 1555 in epoch 9, gen_loss = 0.9213844810859096, disc_loss = 0.0023808523991972223
Trained batch 1556 in epoch 9, gen_loss = 0.92136375783113, disc_loss = 0.0023794457293481925
Trained batch 1557 in epoch 9, gen_loss = 0.9213992177445408, disc_loss = 0.0023779955674833706
Trained batch 1558 in epoch 9, gen_loss = 0.9213585776729106, disc_loss = 0.0023765343164405626
Trained batch 1559 in epoch 9, gen_loss = 0.9213613414993653, disc_loss = 0.0023750767016677762
Trained batch 1560 in epoch 9, gen_loss = 0.9213982991191686, disc_loss = 0.0023736242600360543
Trained batch 1561 in epoch 9, gen_loss = 0.9213533649142359, disc_loss = 0.002372173860508115
Trained batch 1562 in epoch 9, gen_loss = 0.9213728283508725, disc_loss = 0.0023707286320297227
Trained batch 1563 in epoch 9, gen_loss = 0.9212988550629457, disc_loss = 0.002369259431891915
Trained batch 1564 in epoch 9, gen_loss = 0.9212500813670051, disc_loss = 0.002367801650617154
Trained batch 1565 in epoch 9, gen_loss = 0.9212182088068771, disc_loss = 0.0023663192275411044
Trained batch 1566 in epoch 9, gen_loss = 0.9212522753957129, disc_loss = 0.002364884383402221
Trained batch 1567 in epoch 9, gen_loss = 0.9212346167436668, disc_loss = 0.0023634232185374957
Trained batch 1568 in epoch 9, gen_loss = 0.9212923234553, disc_loss = 0.002361973204798639
Trained batch 1569 in epoch 9, gen_loss = 0.9212483379491575, disc_loss = 0.002360518282400978
Trained batch 1570 in epoch 9, gen_loss = 0.9212081164102658, disc_loss = 0.0023590571704699423
Trained batch 1571 in epoch 9, gen_loss = 0.9211892403339915, disc_loss = 0.00235759449197427
Trained batch 1572 in epoch 9, gen_loss = 0.921094809113531, disc_loss = 0.002356183952509822
Trained batch 1573 in epoch 9, gen_loss = 0.920994386626017, disc_loss = 0.0023547249522907275
Trained batch 1574 in epoch 9, gen_loss = 0.9210177440870376, disc_loss = 0.002353293521351473
Trained batch 1575 in epoch 9, gen_loss = 0.9210034502944365, disc_loss = 0.0023518528270135806
Trained batch 1576 in epoch 9, gen_loss = 0.9209686059625223, disc_loss = 0.002350402280424875
Trained batch 1577 in epoch 9, gen_loss = 0.9209752828071628, disc_loss = 0.0023489913312168915
Trained batch 1578 in epoch 9, gen_loss = 0.9210630698699299, disc_loss = 0.0023475688293123666
Trained batch 1579 in epoch 9, gen_loss = 0.9210735694894308, disc_loss = 0.002346132456137017
Trained batch 1580 in epoch 9, gen_loss = 0.9210452743906676, disc_loss = 0.002344694543695106
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.9316287040710449, disc_loss = 8.523989527020603e-05
Trained batch 1 in epoch 10, gen_loss = 0.9481440782546997, disc_loss = 0.0001372759070363827
Trained batch 2 in epoch 10, gen_loss = 0.9463481307029724, disc_loss = 0.00011348837870173156
Trained batch 3 in epoch 10, gen_loss = 0.9436491876840591, disc_loss = 0.0001028220995067386
Trained batch 4 in epoch 10, gen_loss = 0.9289163231849671, disc_loss = 0.00011256040161242709
Trained batch 5 in epoch 10, gen_loss = 0.9137257834275564, disc_loss = 0.00010654062377094912
Trained batch 6 in epoch 10, gen_loss = 0.9018512538501194, disc_loss = 0.00011378157796571031
Trained batch 7 in epoch 10, gen_loss = 0.8930575028061867, disc_loss = 0.00010665640456863912
Trained batch 8 in epoch 10, gen_loss = 0.9146956139140658, disc_loss = 0.00012065750666402487
Trained batch 9 in epoch 10, gen_loss = 0.9062870085239411, disc_loss = 0.00011651961322058923
Trained batch 10 in epoch 10, gen_loss = 0.90880347923799, disc_loss = 0.00011520058218262751
Trained batch 11 in epoch 10, gen_loss = 0.9121567457914352, disc_loss = 0.00011285996273121175
Trained batch 12 in epoch 10, gen_loss = 0.9113228825422434, disc_loss = 0.00010968469499717825
Trained batch 13 in epoch 10, gen_loss = 0.9010920183999198, disc_loss = 0.00010628947867579492
Trained batch 14 in epoch 10, gen_loss = 0.9000936627388001, disc_loss = 0.00010382123194479694
Trained batch 15 in epoch 10, gen_loss = 0.898482333868742, disc_loss = 0.00010650809781509452
Trained batch 16 in epoch 10, gen_loss = 0.900298206245198, disc_loss = 0.0001051956248428563
Trained batch 17 in epoch 10, gen_loss = 0.8946719666322073, disc_loss = 0.00010293471172594259
Trained batch 18 in epoch 10, gen_loss = 0.8949604504986813, disc_loss = 0.000102505162909725
Trained batch 19 in epoch 10, gen_loss = 0.8929118990898133, disc_loss = 0.00010234919827780686
Trained batch 20 in epoch 10, gen_loss = 0.8986960138593402, disc_loss = 0.00010332250912185936
Trained batch 21 in epoch 10, gen_loss = 0.8989825384183363, disc_loss = 0.0001023970061479221
Trained batch 22 in epoch 10, gen_loss = 0.8969916623571644, disc_loss = 0.0001036949618972595
Trained batch 23 in epoch 10, gen_loss = 0.8980376422405243, disc_loss = 0.00010498640828397281
Trained batch 24 in epoch 10, gen_loss = 0.8932837820053101, disc_loss = 0.00010505974001716823
Trained batch 25 in epoch 10, gen_loss = 0.8938018014797797, disc_loss = 0.00010503625610279135
Trained batch 26 in epoch 10, gen_loss = 0.8927989094345657, disc_loss = 0.00010445015100736378
Trained batch 27 in epoch 10, gen_loss = 0.8963231167622975, disc_loss = 0.00010451789291567235
Trained batch 28 in epoch 10, gen_loss = 0.8976549218440878, disc_loss = 0.00010319225412817544
Trained batch 29 in epoch 10, gen_loss = 0.8959359228610992, disc_loss = 0.00010224221235451599
Trained batch 30 in epoch 10, gen_loss = 0.8962365869552859, disc_loss = 0.00010162727853786501
Trained batch 31 in epoch 10, gen_loss = 0.8957972843199968, disc_loss = 0.0001015307414036215
Trained batch 32 in epoch 10, gen_loss = 0.8977528214454651, disc_loss = 0.00010055421025202976
Trained batch 33 in epoch 10, gen_loss = 0.895762901095783, disc_loss = 9.998947194510358e-05
Trained batch 34 in epoch 10, gen_loss = 0.8960567831993103, disc_loss = 9.929731916469921e-05
Trained batch 35 in epoch 10, gen_loss = 0.8978375295797983, disc_loss = 9.868848469017798e-05
Trained batch 36 in epoch 10, gen_loss = 0.8993733025885917, disc_loss = 9.823850839008653e-05
Trained batch 37 in epoch 10, gen_loss = 0.8953145114999068, disc_loss = 9.85654059102097e-05
Trained batch 38 in epoch 10, gen_loss = 0.893690899396554, disc_loss = 9.962345995098495e-05
Trained batch 39 in epoch 10, gen_loss = 0.8945986300706863, disc_loss = 9.871517959254561e-05
Trained batch 40 in epoch 10, gen_loss = 0.8958866189165813, disc_loss = 9.868088658904748e-05
Trained batch 41 in epoch 10, gen_loss = 0.8985910585948399, disc_loss = 9.894537825381295e-05
Trained batch 42 in epoch 10, gen_loss = 0.8971559696419295, disc_loss = 9.826047827901189e-05
Trained batch 43 in epoch 10, gen_loss = 0.8986808454448526, disc_loss = 9.825176642731425e-05
Trained batch 44 in epoch 10, gen_loss = 0.8997129599253336, disc_loss = 9.708263298509539e-05
Trained batch 45 in epoch 10, gen_loss = 0.901457728251167, disc_loss = 9.80236136851802e-05
Trained batch 46 in epoch 10, gen_loss = 0.9007714999482986, disc_loss = 9.809730785336603e-05
Trained batch 47 in epoch 10, gen_loss = 0.9003825175265471, disc_loss = 9.872570088494588e-05
Trained batch 48 in epoch 10, gen_loss = 0.8997665947797348, disc_loss = 9.878791863638052e-05
Trained batch 49 in epoch 10, gen_loss = 0.9019553625583648, disc_loss = 9.869208959571551e-05
Trained batch 50 in epoch 10, gen_loss = 0.901901364326477, disc_loss = 9.882292593544003e-05
Trained batch 51 in epoch 10, gen_loss = 0.9018044746839083, disc_loss = 0.00010211858835436242
Trained batch 52 in epoch 10, gen_loss = 0.8998773109238103, disc_loss = 0.0001049614170283949
Trained batch 53 in epoch 10, gen_loss = 0.9005939927366045, disc_loss = 0.00010582694671433678
Trained batch 54 in epoch 10, gen_loss = 0.8997180570255626, disc_loss = 0.00010682560301078907
Trained batch 55 in epoch 10, gen_loss = 0.8991828763059208, disc_loss = 0.00010766240062106849
Trained batch 56 in epoch 10, gen_loss = 0.9004966763027927, disc_loss = 0.00010887270438711551
Trained batch 57 in epoch 10, gen_loss = 0.8998391083602247, disc_loss = 0.00010982736139026358
Trained batch 58 in epoch 10, gen_loss = 0.8989617369942746, disc_loss = 0.00010996016973907807
Trained batch 59 in epoch 10, gen_loss = 0.8971992562214534, disc_loss = 0.00011012556878995384
Trained batch 60 in epoch 10, gen_loss = 0.8981540515774586, disc_loss = 0.00011118231802848626
Trained batch 61 in epoch 10, gen_loss = 0.8994829260533855, disc_loss = 0.00011120614263129556
Trained batch 62 in epoch 10, gen_loss = 0.8987386330725655, disc_loss = 0.00011218865193003448
Trained batch 63 in epoch 10, gen_loss = 0.8990425830706954, disc_loss = 0.00011209561415626013
Trained batch 64 in epoch 10, gen_loss = 0.8976129430990952, disc_loss = 0.00011173898691105514
Trained batch 65 in epoch 10, gen_loss = 0.8958827726768724, disc_loss = 0.00011209190597583074
Trained batch 66 in epoch 10, gen_loss = 0.8952718234773892, disc_loss = 0.00011220183144210587
Trained batch 67 in epoch 10, gen_loss = 0.8955716499510933, disc_loss = 0.00011181086232253994
Trained batch 68 in epoch 10, gen_loss = 0.8942917403967484, disc_loss = 0.00011191896671822389
Trained batch 69 in epoch 10, gen_loss = 0.8943091792719705, disc_loss = 0.0001116410243412247
Trained batch 70 in epoch 10, gen_loss = 0.8955924720831321, disc_loss = 0.00011375412705861045
Trained batch 71 in epoch 10, gen_loss = 0.8949125616086854, disc_loss = 0.00011476166890942195
Trained batch 72 in epoch 10, gen_loss = 0.8944976762549518, disc_loss = 0.00011544827454961032
Trained batch 73 in epoch 10, gen_loss = 0.8944929999274176, disc_loss = 0.00011569220633474115
Trained batch 74 in epoch 10, gen_loss = 0.8942850009600322, disc_loss = 0.00011521476044435985
Trained batch 75 in epoch 10, gen_loss = 0.8938553811688172, disc_loss = 0.00011493702947375009
Trained batch 76 in epoch 10, gen_loss = 0.8924639650753566, disc_loss = 0.00011516889467852057
Trained batch 77 in epoch 10, gen_loss = 0.8907734224429498, disc_loss = 0.0001160221894772407
Trained batch 78 in epoch 10, gen_loss = 0.8897142131117326, disc_loss = 0.00011613329203285076
Trained batch 79 in epoch 10, gen_loss = 0.8896561689674855, disc_loss = 0.00011589788732635498
Trained batch 80 in epoch 10, gen_loss = 0.8884787640453856, disc_loss = 0.00011696976699893662
Trained batch 81 in epoch 10, gen_loss = 0.8891114439906144, disc_loss = 0.00011724244483580483
Trained batch 82 in epoch 10, gen_loss = 0.8887736495718899, disc_loss = 0.00011780863575720093
Trained batch 83 in epoch 10, gen_loss = 0.8895452639886311, disc_loss = 0.00011756385871800983
Trained batch 84 in epoch 10, gen_loss = 0.8891648783403284, disc_loss = 0.00011789082880782456
Trained batch 85 in epoch 10, gen_loss = 0.8895068390424862, disc_loss = 0.00011828410462713205
Trained batch 86 in epoch 10, gen_loss = 0.8890520087603865, disc_loss = 0.00011755184973951364
Trained batch 87 in epoch 10, gen_loss = 0.8891039775176481, disc_loss = 0.00011759883893153693
Trained batch 88 in epoch 10, gen_loss = 0.8875798844219593, disc_loss = 0.00011757084518720741
Trained batch 89 in epoch 10, gen_loss = 0.8868518736627367, disc_loss = 0.00011774360342921378
Trained batch 90 in epoch 10, gen_loss = 0.885672390460968, disc_loss = 0.00011977951122629507
Trained batch 91 in epoch 10, gen_loss = 0.8865027570206186, disc_loss = 0.00012026256579543849
Trained batch 92 in epoch 10, gen_loss = 0.8866137509704918, disc_loss = 0.00012093559741505711
Trained batch 93 in epoch 10, gen_loss = 0.8858076803227688, disc_loss = 0.00012031837112327265
Trained batch 94 in epoch 10, gen_loss = 0.8853884772250527, disc_loss = 0.00012005928713877342
Trained batch 95 in epoch 10, gen_loss = 0.8845519920190176, disc_loss = 0.00012092574979760684
Trained batch 96 in epoch 10, gen_loss = 0.883524672272279, disc_loss = 0.00012063073773253901
Trained batch 97 in epoch 10, gen_loss = 0.8839947958381809, disc_loss = 0.00012030543142345221
Trained batch 98 in epoch 10, gen_loss = 0.8842012978563405, disc_loss = 0.00011962949910678553
Trained batch 99 in epoch 10, gen_loss = 0.8836565268039703, disc_loss = 0.00011934424466744531
Trained batch 100 in epoch 10, gen_loss = 0.8831114108019537, disc_loss = 0.00011893999886740515
Trained batch 101 in epoch 10, gen_loss = 0.8829274539854012, disc_loss = 0.00011885335426960213
Trained batch 102 in epoch 10, gen_loss = 0.8830812064189355, disc_loss = 0.00011845513124604375
Trained batch 103 in epoch 10, gen_loss = 0.8826262968090864, disc_loss = 0.00011842123778758553
Trained batch 104 in epoch 10, gen_loss = 0.8825444181760153, disc_loss = 0.00011802457932693262
Trained batch 105 in epoch 10, gen_loss = 0.8827237649908606, disc_loss = 0.00011778641336999465
Trained batch 106 in epoch 10, gen_loss = 0.8825958861368839, disc_loss = 0.0001173446788050008
Trained batch 107 in epoch 10, gen_loss = 0.8830010294914246, disc_loss = 0.00011702508129895216
Trained batch 108 in epoch 10, gen_loss = 0.8836077921981111, disc_loss = 0.00011788904434604006
Trained batch 109 in epoch 10, gen_loss = 0.882845612005754, disc_loss = 0.00011765334235282023
Trained batch 110 in epoch 10, gen_loss = 0.8834068399291855, disc_loss = 0.00011714897413480071
Trained batch 111 in epoch 10, gen_loss = 0.8841947679008756, disc_loss = 0.00011720564940073277
Trained batch 112 in epoch 10, gen_loss = 0.8840016654107423, disc_loss = 0.00011700567590027421
Trained batch 113 in epoch 10, gen_loss = 0.883909287159903, disc_loss = 0.00011663213100339482
Trained batch 114 in epoch 10, gen_loss = 0.883919678563657, disc_loss = 0.00011639685550977922
Trained batch 115 in epoch 10, gen_loss = 0.8836365311310209, disc_loss = 0.00011598960259891164
Trained batch 116 in epoch 10, gen_loss = 0.8825498676707602, disc_loss = 0.00011564544889614241
Trained batch 117 in epoch 10, gen_loss = 0.883343289464207, disc_loss = 0.00011581197451066099
Trained batch 118 in epoch 10, gen_loss = 0.883012046834, disc_loss = 0.00011616845188678063
Trained batch 119 in epoch 10, gen_loss = 0.8827525208393733, disc_loss = 0.00011566954375060352
Trained batch 120 in epoch 10, gen_loss = 0.8835632062155353, disc_loss = 0.00011570037787343368
Trained batch 121 in epoch 10, gen_loss = 0.8826888545614774, disc_loss = 0.0001172875302875239
Trained batch 122 in epoch 10, gen_loss = 0.8820475000676101, disc_loss = 0.00011750459473445724
Trained batch 123 in epoch 10, gen_loss = 0.8823931188352646, disc_loss = 0.00011812789383721764
Trained batch 124 in epoch 10, gen_loss = 0.8816673622131348, disc_loss = 0.00011870073660975323
Trained batch 125 in epoch 10, gen_loss = 0.881204881365337, disc_loss = 0.00011901996006758603
Trained batch 126 in epoch 10, gen_loss = 0.8816281068982101, disc_loss = 0.0001196676155842848
Trained batch 127 in epoch 10, gen_loss = 0.8816237887367606, disc_loss = 0.00011975977378142488
Trained batch 128 in epoch 10, gen_loss = 0.8810147786325262, disc_loss = 0.00012077505718564701
Trained batch 129 in epoch 10, gen_loss = 0.8816739609608284, disc_loss = 0.00012222449256044527
Trained batch 130 in epoch 10, gen_loss = 0.8813747658984352, disc_loss = 0.00012265734248110343
Trained batch 131 in epoch 10, gen_loss = 0.8820955789450443, disc_loss = 0.0001225740418731496
Trained batch 132 in epoch 10, gen_loss = 0.8828099150406686, disc_loss = 0.0001233668028594947
Trained batch 133 in epoch 10, gen_loss = 0.8821913644449034, disc_loss = 0.0001238607711904967
Trained batch 134 in epoch 10, gen_loss = 0.8823255265200579, disc_loss = 0.00012408146668113423
Trained batch 135 in epoch 10, gen_loss = 0.8826163542621276, disc_loss = 0.00012513504979698851
Trained batch 136 in epoch 10, gen_loss = 0.8824821710586548, disc_loss = 0.00012631965162747464
Trained batch 137 in epoch 10, gen_loss = 0.8820312601932581, disc_loss = 0.00012651802962468736
Trained batch 138 in epoch 10, gen_loss = 0.8829251570667295, disc_loss = 0.0001267548707559229
Trained batch 139 in epoch 10, gen_loss = 0.8826768338680268, disc_loss = 0.00012642347688337656
Trained batch 140 in epoch 10, gen_loss = 0.8825054908475132, disc_loss = 0.00012607167162007738
Trained batch 141 in epoch 10, gen_loss = 0.8820580953443554, disc_loss = 0.0001262986777771697
Trained batch 142 in epoch 10, gen_loss = 0.8817108052593845, disc_loss = 0.0001260989508021727
Trained batch 143 in epoch 10, gen_loss = 0.8817340114878284, disc_loss = 0.00012553688937562887
Trained batch 144 in epoch 10, gen_loss = 0.8819920708393229, disc_loss = 0.00012541306639142366
Trained batch 145 in epoch 10, gen_loss = 0.8815252964627253, disc_loss = 0.00012564430715877417
Trained batch 146 in epoch 10, gen_loss = 0.881573439049883, disc_loss = 0.00012537917477331364
Trained batch 147 in epoch 10, gen_loss = 0.8819045098246755, disc_loss = 0.00012544938930954527
Trained batch 148 in epoch 10, gen_loss = 0.881400072734628, disc_loss = 0.00012565233555505984
Trained batch 149 in epoch 10, gen_loss = 0.8817483115196229, disc_loss = 0.00012557412393410534
Trained batch 150 in epoch 10, gen_loss = 0.8818990165824132, disc_loss = 0.00012674801035137347
Trained batch 151 in epoch 10, gen_loss = 0.8819781063418639, disc_loss = 0.00012649781980431535
Trained batch 152 in epoch 10, gen_loss = 0.8819339236402823, disc_loss = 0.00012661494664962744
Trained batch 153 in epoch 10, gen_loss = 0.881732367075883, disc_loss = 0.00012646041552641265
Trained batch 154 in epoch 10, gen_loss = 0.881304415195219, disc_loss = 0.00012639810492175692
Trained batch 155 in epoch 10, gen_loss = 0.8813858269116818, disc_loss = 0.00012604040096984812
Trained batch 156 in epoch 10, gen_loss = 0.8816196045298486, disc_loss = 0.0001255984617232947
Trained batch 157 in epoch 10, gen_loss = 0.8808953980856304, disc_loss = 0.00012549546630032614
Trained batch 158 in epoch 10, gen_loss = 0.8813103632357135, disc_loss = 0.0001253830395507518
Trained batch 159 in epoch 10, gen_loss = 0.8814259555190802, disc_loss = 0.00012569251450713636
Trained batch 160 in epoch 10, gen_loss = 0.8813494255083688, disc_loss = 0.00012547966013376903
Trained batch 161 in epoch 10, gen_loss = 0.8812140965903247, disc_loss = 0.0001251660707544314
Trained batch 162 in epoch 10, gen_loss = 0.8815540071645397, disc_loss = 0.00012523383894443162
Trained batch 163 in epoch 10, gen_loss = 0.8815323285213331, disc_loss = 0.0001248632685773617
Trained batch 164 in epoch 10, gen_loss = 0.881595020944422, disc_loss = 0.00012486681197046754
Trained batch 165 in epoch 10, gen_loss = 0.8819406208503677, disc_loss = 0.00012464163090219492
Trained batch 166 in epoch 10, gen_loss = 0.8822034533152323, disc_loss = 0.00012430033710918357
Trained batch 167 in epoch 10, gen_loss = 0.881985909882046, disc_loss = 0.00012386154328071695
Trained batch 168 in epoch 10, gen_loss = 0.8818636691781896, disc_loss = 0.00012352006985119146
Trained batch 169 in epoch 10, gen_loss = 0.8816062471445869, disc_loss = 0.00012338489530734745
Trained batch 170 in epoch 10, gen_loss = 0.8817990028370194, disc_loss = 0.00012339711913376725
Trained batch 171 in epoch 10, gen_loss = 0.8817818324233211, disc_loss = 0.00012330227732596796
Trained batch 172 in epoch 10, gen_loss = 0.8818063642937324, disc_loss = 0.00012311119394194513
Trained batch 173 in epoch 10, gen_loss = 0.8813492111090956, disc_loss = 0.00012331769408021877
Trained batch 174 in epoch 10, gen_loss = 0.881593451159341, disc_loss = 0.00012300791719878492
Trained batch 175 in epoch 10, gen_loss = 0.8814758556810293, disc_loss = 0.00012276581126322773
Trained batch 176 in epoch 10, gen_loss = 0.8809060252318948, disc_loss = 0.00012266818942659335
Trained batch 177 in epoch 10, gen_loss = 0.8807697915629055, disc_loss = 0.0001227179225761472
Trained batch 178 in epoch 10, gen_loss = 0.881425062038379, disc_loss = 0.00012280940539226347
Trained batch 179 in epoch 10, gen_loss = 0.8812139494551553, disc_loss = 0.00012260893407882475
Trained batch 180 in epoch 10, gen_loss = 0.8822005937771243, disc_loss = 0.00012276069642136578
Trained batch 181 in epoch 10, gen_loss = 0.8820275268056891, disc_loss = 0.00012236382425036716
Trained batch 182 in epoch 10, gen_loss = 0.8823160389082028, disc_loss = 0.00012251971995402662
Trained batch 183 in epoch 10, gen_loss = 0.8822258581285891, disc_loss = 0.00012260309918217345
Trained batch 184 in epoch 10, gen_loss = 0.8822590686179496, disc_loss = 0.00012244626298008764
Trained batch 185 in epoch 10, gen_loss = 0.8819185149285101, disc_loss = 0.00012251421446885077
Trained batch 186 in epoch 10, gen_loss = 0.8820082558030113, disc_loss = 0.0001224700667819738
Trained batch 187 in epoch 10, gen_loss = 0.8816405740824151, disc_loss = 0.0001232269751392565
Trained batch 188 in epoch 10, gen_loss = 0.8815327378177138, disc_loss = 0.00012352287029941743
Trained batch 189 in epoch 10, gen_loss = 0.8813447422102878, disc_loss = 0.00012344200124636318
Trained batch 190 in epoch 10, gen_loss = 0.8813837239255455, disc_loss = 0.00012330168442412388
Trained batch 191 in epoch 10, gen_loss = 0.8815406911695997, disc_loss = 0.00012336135051782549
Trained batch 192 in epoch 10, gen_loss = 0.8817522621525384, disc_loss = 0.00012336090314392015
Trained batch 193 in epoch 10, gen_loss = 0.881541608227897, disc_loss = 0.00012306247755105622
Trained batch 194 in epoch 10, gen_loss = 0.8815001307389675, disc_loss = 0.00012287093729052383
Trained batch 195 in epoch 10, gen_loss = 0.8812659860265498, disc_loss = 0.00012285096920318118
Trained batch 196 in epoch 10, gen_loss = 0.8812398066375461, disc_loss = 0.00012259535322826814
Trained batch 197 in epoch 10, gen_loss = 0.8815085541720342, disc_loss = 0.00012235850776087687
Trained batch 198 in epoch 10, gen_loss = 0.8816664156003214, disc_loss = 0.00012228210354220924
Trained batch 199 in epoch 10, gen_loss = 0.882595212161541, disc_loss = 0.00012207316854983218
Trained batch 200 in epoch 10, gen_loss = 0.8822815664372041, disc_loss = 0.00012199395264609513
Trained batch 201 in epoch 10, gen_loss = 0.8822929466714954, disc_loss = 0.00012185056887277158
Trained batch 202 in epoch 10, gen_loss = 0.8822350860229267, disc_loss = 0.00012157309662107392
Trained batch 203 in epoch 10, gen_loss = 0.8824255337902144, disc_loss = 0.00012126824142743477
Trained batch 204 in epoch 10, gen_loss = 0.8824601554289097, disc_loss = 0.0001209495695259581
Trained batch 205 in epoch 10, gen_loss = 0.8821712813331085, disc_loss = 0.00012060306579266218
Trained batch 206 in epoch 10, gen_loss = 0.8823614270214873, disc_loss = 0.00012042330552169778
Trained batch 207 in epoch 10, gen_loss = 0.8827897636936262, disc_loss = 0.00012028695529737048
Trained batch 208 in epoch 10, gen_loss = 0.8834289124137477, disc_loss = 0.0001202996858819243
Trained batch 209 in epoch 10, gen_loss = 0.883064334449314, disc_loss = 0.00012008591946228296
Trained batch 210 in epoch 10, gen_loss = 0.8828148669541165, disc_loss = 0.00012002534304275972
Trained batch 211 in epoch 10, gen_loss = 0.8827361939650662, disc_loss = 0.00011991468710341064
Trained batch 212 in epoch 10, gen_loss = 0.8829044445019932, disc_loss = 0.00011965275047379196
Trained batch 213 in epoch 10, gen_loss = 0.8826612663046222, disc_loss = 0.00011944600696679287
Trained batch 214 in epoch 10, gen_loss = 0.8830599640691004, disc_loss = 0.00011965436690018599
Trained batch 215 in epoch 10, gen_loss = 0.8833925955825381, disc_loss = 0.00011960127878612386
Trained batch 216 in epoch 10, gen_loss = 0.8835115784324259, disc_loss = 0.00011950169980924573
Trained batch 217 in epoch 10, gen_loss = 0.883501222921074, disc_loss = 0.00011939668836413323
Trained batch 218 in epoch 10, gen_loss = 0.8836660698124262, disc_loss = 0.00011969947990188992
Trained batch 219 in epoch 10, gen_loss = 0.8836305994879116, disc_loss = 0.00011973963289413157
Trained batch 220 in epoch 10, gen_loss = 0.8837774803196143, disc_loss = 0.00011968056838767186
Trained batch 221 in epoch 10, gen_loss = 0.8835536177093918, disc_loss = 0.00011950225419790152
Trained batch 222 in epoch 10, gen_loss = 0.8834727345026128, disc_loss = 0.00011947434046762503
Trained batch 223 in epoch 10, gen_loss = 0.8841056440557752, disc_loss = 0.00011938665717739891
Trained batch 224 in epoch 10, gen_loss = 0.8846093228128221, disc_loss = 0.0001191203341133789
Trained batch 225 in epoch 10, gen_loss = 0.884800716575268, disc_loss = 0.00011893765384277773
Trained batch 226 in epoch 10, gen_loss = 0.8847807674681037, disc_loss = 0.00011866713789999915
Trained batch 227 in epoch 10, gen_loss = 0.8849530510212246, disc_loss = 0.00011864141061666662
Trained batch 228 in epoch 10, gen_loss = 0.8846124090482054, disc_loss = 0.00011879805075835872
Trained batch 229 in epoch 10, gen_loss = 0.8844219420267188, disc_loss = 0.00011870225354631776
Trained batch 230 in epoch 10, gen_loss = 0.8841628344544085, disc_loss = 0.00011853547740031691
Trained batch 231 in epoch 10, gen_loss = 0.8844360542194597, disc_loss = 0.00011867575949509046
Trained batch 232 in epoch 10, gen_loss = 0.88435729353213, disc_loss = 0.00011913405981825669
Trained batch 233 in epoch 10, gen_loss = 0.8840830858446594, disc_loss = 0.00011896014408022862
Trained batch 234 in epoch 10, gen_loss = 0.8842871414854171, disc_loss = 0.00011892965435919827
Trained batch 235 in epoch 10, gen_loss = 0.8846568083864147, disc_loss = 0.00011882495230457931
Trained batch 236 in epoch 10, gen_loss = 0.8843647246622335, disc_loss = 0.00011857949833217163
Trained batch 237 in epoch 10, gen_loss = 0.8846180025769883, disc_loss = 0.0001183927616090054
Trained batch 238 in epoch 10, gen_loss = 0.8842029648844667, disc_loss = 0.00011810146102734849
Trained batch 239 in epoch 10, gen_loss = 0.8844466413060824, disc_loss = 0.00011800982175979395
Trained batch 240 in epoch 10, gen_loss = 0.8843880602432979, disc_loss = 0.00011831404559695378
Trained batch 241 in epoch 10, gen_loss = 0.8843528487958199, disc_loss = 0.00011845788494686207
Trained batch 242 in epoch 10, gen_loss = 0.88450620301957, disc_loss = 0.00011856525832724397
Trained batch 243 in epoch 10, gen_loss = 0.8850571689058523, disc_loss = 0.00011914796362018888
Trained batch 244 in epoch 10, gen_loss = 0.8849744589961305, disc_loss = 0.00011919374509099206
Trained batch 245 in epoch 10, gen_loss = 0.8846207387079068, disc_loss = 0.00011913176524281082
Trained batch 246 in epoch 10, gen_loss = 0.8845220683557302, disc_loss = 0.00011916294289380029
Trained batch 247 in epoch 10, gen_loss = 0.8839451134685548, disc_loss = 0.00012004065708806007
Trained batch 248 in epoch 10, gen_loss = 0.8838326698804955, disc_loss = 0.00012079771988509488
Trained batch 249 in epoch 10, gen_loss = 0.8840670623779296, disc_loss = 0.00012090059516776819
Trained batch 250 in epoch 10, gen_loss = 0.8842950719761183, disc_loss = 0.00012130116454181372
Trained batch 251 in epoch 10, gen_loss = 0.8841254176601531, disc_loss = 0.00012122534908918343
Trained batch 252 in epoch 10, gen_loss = 0.8837078197200308, disc_loss = 0.00012118578337746297
Trained batch 253 in epoch 10, gen_loss = 0.8840820946562009, disc_loss = 0.00012133669844742838
Trained batch 254 in epoch 10, gen_loss = 0.8847047102217581, disc_loss = 0.00012171591220334556
Trained batch 255 in epoch 10, gen_loss = 0.8850025858264416, disc_loss = 0.00012227215133009395
Trained batch 256 in epoch 10, gen_loss = 0.8855789531065796, disc_loss = 0.0001234540654576686
Trained batch 257 in epoch 10, gen_loss = 0.886058759088664, disc_loss = 0.000123628812426157
Trained batch 258 in epoch 10, gen_loss = 0.8859589168924162, disc_loss = 0.00012375413339091087
Trained batch 259 in epoch 10, gen_loss = 0.8856377853797033, disc_loss = 0.00012358310099303848
Trained batch 260 in epoch 10, gen_loss = 0.8855747639904534, disc_loss = 0.00012335186732263426
Trained batch 261 in epoch 10, gen_loss = 0.8854321243653771, disc_loss = 0.00012331965167192255
Trained batch 262 in epoch 10, gen_loss = 0.8857705631636849, disc_loss = 0.0001231053820827811
Trained batch 263 in epoch 10, gen_loss = 0.88580900679032, disc_loss = 0.00012286526621072412
Trained batch 264 in epoch 10, gen_loss = 0.8860299960622248, disc_loss = 0.00012274914202038727
Trained batch 265 in epoch 10, gen_loss = 0.8861843522329976, disc_loss = 0.00012261252263293923
Trained batch 266 in epoch 10, gen_loss = 0.8858654220005993, disc_loss = 0.00012240551540402221
Trained batch 267 in epoch 10, gen_loss = 0.8863446897090371, disc_loss = 0.0001224064769724179
Trained batch 268 in epoch 10, gen_loss = 0.8859484906976551, disc_loss = 0.00012228274030362508
Trained batch 269 in epoch 10, gen_loss = 0.8864267634020911, disc_loss = 0.00012213644909530154
Trained batch 270 in epoch 10, gen_loss = 0.8862518723160578, disc_loss = 0.00012186456015148815
Trained batch 271 in epoch 10, gen_loss = 0.8864688145763734, disc_loss = 0.00012167642283683937
Trained batch 272 in epoch 10, gen_loss = 0.8863621131404416, disc_loss = 0.0001214233783245148
Trained batch 273 in epoch 10, gen_loss = 0.8860906608348346, disc_loss = 0.00012135163695639828
Trained batch 274 in epoch 10, gen_loss = 0.8858437011458657, disc_loss = 0.00012125487095380032
Trained batch 275 in epoch 10, gen_loss = 0.8860088083623112, disc_loss = 0.00012102266157234081
Trained batch 276 in epoch 10, gen_loss = 0.8862881714256231, disc_loss = 0.00012103005300090221
Trained batch 277 in epoch 10, gen_loss = 0.8866586380725284, disc_loss = 0.00012167036501844012
Trained batch 278 in epoch 10, gen_loss = 0.8866807342002896, disc_loss = 0.00012183908128916489
Trained batch 279 in epoch 10, gen_loss = 0.8866256098662104, disc_loss = 0.0001224414992975653
Trained batch 280 in epoch 10, gen_loss = 0.886892414177864, disc_loss = 0.00012309996653460067
Trained batch 281 in epoch 10, gen_loss = 0.8866395645953239, disc_loss = 0.00012529483535108222
Trained batch 282 in epoch 10, gen_loss = 0.8868039528388438, disc_loss = 0.0001270222340991421
Trained batch 283 in epoch 10, gen_loss = 0.8866886267779579, disc_loss = 0.00012863524168263302
Trained batch 284 in epoch 10, gen_loss = 0.8868824046954774, disc_loss = 0.00012925335769276052
Trained batch 285 in epoch 10, gen_loss = 0.8872932304035533, disc_loss = 0.00012936868421042214
Trained batch 286 in epoch 10, gen_loss = 0.8873669181135889, disc_loss = 0.00012944038406818397
Trained batch 287 in epoch 10, gen_loss = 0.8873356123351388, disc_loss = 0.00012945282699345425
Trained batch 288 in epoch 10, gen_loss = 0.8870667672899768, disc_loss = 0.00012931657579822538
Trained batch 289 in epoch 10, gen_loss = 0.8866615895567269, disc_loss = 0.00012913512327941134
Trained batch 290 in epoch 10, gen_loss = 0.8868527969543877, disc_loss = 0.00012896194785718944
Trained batch 291 in epoch 10, gen_loss = 0.886943226399487, disc_loss = 0.0001287169011385692
Trained batch 292 in epoch 10, gen_loss = 0.8867444430601882, disc_loss = 0.00012848258427039915
Trained batch 293 in epoch 10, gen_loss = 0.8867726139470834, disc_loss = 0.00012831016654821055
Trained batch 294 in epoch 10, gen_loss = 0.8865464119587915, disc_loss = 0.00012808066656639388
Trained batch 295 in epoch 10, gen_loss = 0.8864858794856716, disc_loss = 0.00012783867982393162
Trained batch 296 in epoch 10, gen_loss = 0.8867166536022918, disc_loss = 0.00012780100990401154
Trained batch 297 in epoch 10, gen_loss = 0.886714853696375, disc_loss = 0.00012762533346872353
Trained batch 298 in epoch 10, gen_loss = 0.8872056206731892, disc_loss = 0.00012755715520857804
Trained batch 299 in epoch 10, gen_loss = 0.8874581378698349, disc_loss = 0.00012742705551014902
Trained batch 300 in epoch 10, gen_loss = 0.8873982504752783, disc_loss = 0.00012718269006479485
Trained batch 301 in epoch 10, gen_loss = 0.8873115549024367, disc_loss = 0.00012702645704511397
Trained batch 302 in epoch 10, gen_loss = 0.8871002822819323, disc_loss = 0.0001267895502966741
Trained batch 303 in epoch 10, gen_loss = 0.8871861286461353, disc_loss = 0.00012658509827863447
Trained batch 304 in epoch 10, gen_loss = 0.8868278155561353, disc_loss = 0.00012643335230379425
Trained batch 305 in epoch 10, gen_loss = 0.8867582098331327, disc_loss = 0.00012621802919241066
Trained batch 306 in epoch 10, gen_loss = 0.8872216687528629, disc_loss = 0.0001262767700639027
Trained batch 307 in epoch 10, gen_loss = 0.8875882362390494, disc_loss = 0.00012630972941661203
Trained batch 308 in epoch 10, gen_loss = 0.887828591957833, disc_loss = 0.00012616299305962244
Trained batch 309 in epoch 10, gen_loss = 0.8879195520954747, disc_loss = 0.00012591221425428822
Trained batch 310 in epoch 10, gen_loss = 0.8881341715334312, disc_loss = 0.00012569346310433457
Trained batch 311 in epoch 10, gen_loss = 0.8879032985140116, disc_loss = 0.00012541398631909918
Trained batch 312 in epoch 10, gen_loss = 0.8878482764902206, disc_loss = 0.0001252035297558103
Trained batch 313 in epoch 10, gen_loss = 0.8879197000697919, disc_loss = 0.00012492612676726875
Trained batch 314 in epoch 10, gen_loss = 0.8883809785994272, disc_loss = 0.0001248826690864498
Trained batch 315 in epoch 10, gen_loss = 0.8881606127642379, disc_loss = 0.00012471036249815922
Trained batch 316 in epoch 10, gen_loss = 0.8881018329117952, disc_loss = 0.0001245379898128282
Trained batch 317 in epoch 10, gen_loss = 0.887946532769773, disc_loss = 0.00012448094111157775
Trained batch 318 in epoch 10, gen_loss = 0.8878072262931394, disc_loss = 0.00012439109575602614
Trained batch 319 in epoch 10, gen_loss = 0.8877245308831334, disc_loss = 0.00012435063019893277
Trained batch 320 in epoch 10, gen_loss = 0.8879003075424384, disc_loss = 0.00012427297570580194
Trained batch 321 in epoch 10, gen_loss = 0.8879014499809431, disc_loss = 0.00012406949392006146
Trained batch 322 in epoch 10, gen_loss = 0.8877505017876994, disc_loss = 0.00012386875798943417
Trained batch 323 in epoch 10, gen_loss = 0.8873003660528748, disc_loss = 0.00012650088523020523
Trained batch 324 in epoch 10, gen_loss = 0.8873231521019569, disc_loss = 0.00012718991596977083
Trained batch 325 in epoch 10, gen_loss = 0.8875122501806247, disc_loss = 0.00012778841024287905
Trained batch 326 in epoch 10, gen_loss = 0.8876631686446863, disc_loss = 0.00012813176073866257
Trained batch 327 in epoch 10, gen_loss = 0.8876539937606672, disc_loss = 0.0001283333076238838
Trained batch 328 in epoch 10, gen_loss = 0.887766861988056, disc_loss = 0.00012824946237449523
Trained batch 329 in epoch 10, gen_loss = 0.8878009592041824, disc_loss = 0.0001280642194284486
Trained batch 330 in epoch 10, gen_loss = 0.8874580120031927, disc_loss = 0.0001279051720003458
Trained batch 331 in epoch 10, gen_loss = 0.8875172236956745, disc_loss = 0.00012792504722130112
Trained batch 332 in epoch 10, gen_loss = 0.8873465614275889, disc_loss = 0.00012797255200072046
Trained batch 333 in epoch 10, gen_loss = 0.887592384736695, disc_loss = 0.0001280310700962447
Trained batch 334 in epoch 10, gen_loss = 0.8876107383130202, disc_loss = 0.00012786096213220397
Trained batch 335 in epoch 10, gen_loss = 0.8881146545921054, disc_loss = 0.00012793082759171304
Trained batch 336 in epoch 10, gen_loss = 0.8878448968117598, disc_loss = 0.00012787664267042783
Trained batch 337 in epoch 10, gen_loss = 0.8875012568820863, disc_loss = 0.00012792795987156725
Trained batch 338 in epoch 10, gen_loss = 0.8877276945254796, disc_loss = 0.00012783617695172285
Trained batch 339 in epoch 10, gen_loss = 0.8876279902808807, disc_loss = 0.00012785272559567067
Trained batch 340 in epoch 10, gen_loss = 0.8877690712377823, disc_loss = 0.00012781449616092934
Trained batch 341 in epoch 10, gen_loss = 0.887837204668257, disc_loss = 0.00012766767128080344
Trained batch 342 in epoch 10, gen_loss = 0.8879143312443102, disc_loss = 0.0001274607809081113
Trained batch 343 in epoch 10, gen_loss = 0.8876528431509816, disc_loss = 0.00012737793105220907
Trained batch 344 in epoch 10, gen_loss = 0.887429850688879, disc_loss = 0.00012735143967986822
Trained batch 345 in epoch 10, gen_loss = 0.8872524927117232, disc_loss = 0.00012720754597666793
Trained batch 346 in epoch 10, gen_loss = 0.887511189458006, disc_loss = 0.00012700467248457639
Trained batch 347 in epoch 10, gen_loss = 0.8873668734369606, disc_loss = 0.0001268499750824111
Trained batch 348 in epoch 10, gen_loss = 0.8872703909873962, disc_loss = 0.0001266137204059756
Trained batch 349 in epoch 10, gen_loss = 0.887402903522764, disc_loss = 0.0001264294420564381
Trained batch 350 in epoch 10, gen_loss = 0.887372856635993, disc_loss = 0.0001262297897441764
Trained batch 351 in epoch 10, gen_loss = 0.8870572137900374, disc_loss = 0.00012606577547558118
Trained batch 352 in epoch 10, gen_loss = 0.8870448213461101, disc_loss = 0.00012583426419698643
Trained batch 353 in epoch 10, gen_loss = 0.8870694071559583, disc_loss = 0.0001256169463146253
Trained batch 354 in epoch 10, gen_loss = 0.8870849234957091, disc_loss = 0.0001254151222844523
Trained batch 355 in epoch 10, gen_loss = 0.8873961469095745, disc_loss = 0.00012540177155305368
Trained batch 356 in epoch 10, gen_loss = 0.8872652372726205, disc_loss = 0.00012532242297066745
Trained batch 357 in epoch 10, gen_loss = 0.8870847886168091, disc_loss = 0.00012516130652974878
Trained batch 358 in epoch 10, gen_loss = 0.8871006638558794, disc_loss = 0.00012493924387806216
Trained batch 359 in epoch 10, gen_loss = 0.887252572675546, disc_loss = 0.00012482750305732932
Trained batch 360 in epoch 10, gen_loss = 0.8870562128413086, disc_loss = 0.0001247033123492097
Trained batch 361 in epoch 10, gen_loss = 0.8868945020338448, disc_loss = 0.00012467432664766797
Trained batch 362 in epoch 10, gen_loss = 0.8866746507728723, disc_loss = 0.00012452185133957308
Trained batch 363 in epoch 10, gen_loss = 0.8867044868050041, disc_loss = 0.0001244028975294326
Trained batch 364 in epoch 10, gen_loss = 0.8869409384792798, disc_loss = 0.0001242534055837832
Trained batch 365 in epoch 10, gen_loss = 0.8873052961839353, disc_loss = 0.00012421428442901177
Trained batch 366 in epoch 10, gen_loss = 0.8875197458007356, disc_loss = 0.00012426387661744774
Trained batch 367 in epoch 10, gen_loss = 0.8875354311388471, disc_loss = 0.00012427186049495978
Trained batch 368 in epoch 10, gen_loss = 0.8872959578263404, disc_loss = 0.0001242673122435259
Trained batch 369 in epoch 10, gen_loss = 0.8873152462211815, disc_loss = 0.00012440571693799496
Trained batch 370 in epoch 10, gen_loss = 0.8875938522205199, disc_loss = 0.00012444632212486122
Trained batch 371 in epoch 10, gen_loss = 0.887563635104446, disc_loss = 0.00012426440712114264
Trained batch 372 in epoch 10, gen_loss = 0.8877423383275561, disc_loss = 0.00012415206399345183
Trained batch 373 in epoch 10, gen_loss = 0.8876959287865277, disc_loss = 0.00012405899162166116
Trained batch 374 in epoch 10, gen_loss = 0.8876034391721089, disc_loss = 0.00012389481324741306
Trained batch 375 in epoch 10, gen_loss = 0.8874214698976659, disc_loss = 0.00012382549577059183
Trained batch 376 in epoch 10, gen_loss = 0.8875380183720778, disc_loss = 0.00012375988812204043
Trained batch 377 in epoch 10, gen_loss = 0.8877825139376222, disc_loss = 0.00012366814304119476
Trained batch 378 in epoch 10, gen_loss = 0.8875053595741694, disc_loss = 0.00012356782271052185
Trained batch 379 in epoch 10, gen_loss = 0.8878994264100727, disc_loss = 0.00012361557320745257
Trained batch 380 in epoch 10, gen_loss = 0.8880990252407204, disc_loss = 0.00012378022318186173
Trained batch 381 in epoch 10, gen_loss = 0.8883565895220372, disc_loss = 0.00012393310041609038
Trained batch 382 in epoch 10, gen_loss = 0.888290151759165, disc_loss = 0.0001238571665918925
Trained batch 383 in epoch 10, gen_loss = 0.8882653277056912, disc_loss = 0.00012370251362388748
Trained batch 384 in epoch 10, gen_loss = 0.8882529924442242, disc_loss = 0.00012356690799193034
Trained batch 385 in epoch 10, gen_loss = 0.8882561503605522, disc_loss = 0.00012354673358011287
Trained batch 386 in epoch 10, gen_loss = 0.8881522199904271, disc_loss = 0.0001236553382128026
Trained batch 387 in epoch 10, gen_loss = 0.8879713168770996, disc_loss = 0.00012369151010585184
Trained batch 388 in epoch 10, gen_loss = 0.888310976843601, disc_loss = 0.00012388085402109287
Trained batch 389 in epoch 10, gen_loss = 0.8880431026984483, disc_loss = 0.00012390095833278536
Trained batch 390 in epoch 10, gen_loss = 0.8880260001363047, disc_loss = 0.0001238750200826571
Trained batch 391 in epoch 10, gen_loss = 0.8876526244744962, disc_loss = 0.00012404911438686529
Trained batch 392 in epoch 10, gen_loss = 0.8877970805301618, disc_loss = 0.00012391598310856843
Trained batch 393 in epoch 10, gen_loss = 0.8878346294315939, disc_loss = 0.0001238255398338371
Trained batch 394 in epoch 10, gen_loss = 0.8877488054806673, disc_loss = 0.00012372456946155305
Trained batch 395 in epoch 10, gen_loss = 0.8877802575477446, disc_loss = 0.00012357763566199931
Trained batch 396 in epoch 10, gen_loss = 0.8876264539713824, disc_loss = 0.00012342581928903248
Trained batch 397 in epoch 10, gen_loss = 0.8875507538642117, disc_loss = 0.00012325067575659718
Trained batch 398 in epoch 10, gen_loss = 0.8874183766226422, disc_loss = 0.00012312917605593606
Trained batch 399 in epoch 10, gen_loss = 0.8872290447354316, disc_loss = 0.00012329803289503615
Trained batch 400 in epoch 10, gen_loss = 0.8873297441332715, disc_loss = 0.00012359776503258115
Trained batch 401 in epoch 10, gen_loss = 0.8874692675189593, disc_loss = 0.00012384241451956715
Trained batch 402 in epoch 10, gen_loss = 0.8876725717750436, disc_loss = 0.00012404263367399483
Trained batch 403 in epoch 10, gen_loss = 0.8878100704733688, disc_loss = 0.00012419524209870378
Trained batch 404 in epoch 10, gen_loss = 0.8877839217951269, disc_loss = 0.00012430595784673732
Trained batch 405 in epoch 10, gen_loss = 0.8877162782135856, disc_loss = 0.00012419378401829433
Trained batch 406 in epoch 10, gen_loss = 0.8878102522224407, disc_loss = 0.0001241541824343469
Trained batch 407 in epoch 10, gen_loss = 0.8879744743599611, disc_loss = 0.00012411474851129847
Trained batch 408 in epoch 10, gen_loss = 0.8882692256591722, disc_loss = 0.0001242923392816179
Trained batch 409 in epoch 10, gen_loss = 0.8883414937228691, disc_loss = 0.0001243290464339136
Trained batch 410 in epoch 10, gen_loss = 0.8885971763128202, disc_loss = 0.00012437752297015265
Trained batch 411 in epoch 10, gen_loss = 0.8886252404416649, disc_loss = 0.00012430635144959772
Trained batch 412 in epoch 10, gen_loss = 0.8886226034626257, disc_loss = 0.00012426685899887606
Trained batch 413 in epoch 10, gen_loss = 0.8886539593410953, disc_loss = 0.00012442515481968922
Trained batch 414 in epoch 10, gen_loss = 0.8887606060648539, disc_loss = 0.00012493512891436343
Trained batch 415 in epoch 10, gen_loss = 0.8888997057309518, disc_loss = 0.0001252428968602824
Trained batch 416 in epoch 10, gen_loss = 0.8887697525447507, disc_loss = 0.00012527153418016648
Trained batch 417 in epoch 10, gen_loss = 0.8889872018230018, disc_loss = 0.0001251849218150662
Trained batch 418 in epoch 10, gen_loss = 0.8886867768724664, disc_loss = 0.0001252044904137309
Trained batch 419 in epoch 10, gen_loss = 0.8884626686573028, disc_loss = 0.00012508263658847206
Trained batch 420 in epoch 10, gen_loss = 0.8882688293830799, disc_loss = 0.00012489381823540806
Trained batch 421 in epoch 10, gen_loss = 0.8884605042177354, disc_loss = 0.00012481299826594774
Trained batch 422 in epoch 10, gen_loss = 0.8884449949219435, disc_loss = 0.00012468059314380456
Trained batch 423 in epoch 10, gen_loss = 0.8883241880333649, disc_loss = 0.00012449433014344836
Trained batch 424 in epoch 10, gen_loss = 0.8881852061608259, disc_loss = 0.0001243188083069125
Trained batch 425 in epoch 10, gen_loss = 0.888152390438626, disc_loss = 0.0001242014092805592
Trained batch 426 in epoch 10, gen_loss = 0.8878660650108123, disc_loss = 0.00012413033142680982
Trained batch 427 in epoch 10, gen_loss = 0.8879888123162439, disc_loss = 0.00012422879409084692
Trained batch 428 in epoch 10, gen_loss = 0.888048749842566, disc_loss = 0.000124849825677552
Trained batch 429 in epoch 10, gen_loss = 0.8881931767907254, disc_loss = 0.00012482684660637967
Trained batch 430 in epoch 10, gen_loss = 0.8880670343087057, disc_loss = 0.0001256771321114576
Trained batch 431 in epoch 10, gen_loss = 0.8884294754653065, disc_loss = 0.00012639229404427438
Trained batch 432 in epoch 10, gen_loss = 0.8883491695340181, disc_loss = 0.0001262503511743678
Trained batch 433 in epoch 10, gen_loss = 0.8882323178003461, disc_loss = 0.00012631266542363265
Trained batch 434 in epoch 10, gen_loss = 0.8882611951608768, disc_loss = 0.00012637715625788096
Trained batch 435 in epoch 10, gen_loss = 0.8882749955588525, disc_loss = 0.00012641579115727527
Trained batch 436 in epoch 10, gen_loss = 0.8883626193694719, disc_loss = 0.00012634903749222473
Trained batch 437 in epoch 10, gen_loss = 0.8881204619527407, disc_loss = 0.000126290985824435
Trained batch 438 in epoch 10, gen_loss = 0.8881908842534302, disc_loss = 0.00012630948775719982
Trained batch 439 in epoch 10, gen_loss = 0.888277183337645, disc_loss = 0.0001261596549738897
Trained batch 440 in epoch 10, gen_loss = 0.8880476444756904, disc_loss = 0.0001262005664634702
Trained batch 441 in epoch 10, gen_loss = 0.8880467236851135, disc_loss = 0.00012625426405485577
Trained batch 442 in epoch 10, gen_loss = 0.8881608802093609, disc_loss = 0.00012612310931944283
Trained batch 443 in epoch 10, gen_loss = 0.8882309605140943, disc_loss = 0.00012609521644179467
Trained batch 444 in epoch 10, gen_loss = 0.888211824518911, disc_loss = 0.0001260594200287956
Trained batch 445 in epoch 10, gen_loss = 0.8882509059702869, disc_loss = 0.00012613095223956903
Trained batch 446 in epoch 10, gen_loss = 0.8882936615271856, disc_loss = 0.0001260901652057749
Trained batch 447 in epoch 10, gen_loss = 0.8881559020706585, disc_loss = 0.00012592462750912352
Trained batch 448 in epoch 10, gen_loss = 0.8882232641589668, disc_loss = 0.00012588705295661333
Trained batch 449 in epoch 10, gen_loss = 0.8880673233668009, disc_loss = 0.00012585696920319202
Trained batch 450 in epoch 10, gen_loss = 0.8881570599031554, disc_loss = 0.0001256767576375172
Trained batch 451 in epoch 10, gen_loss = 0.8885352457255389, disc_loss = 0.00012570652000579532
Trained batch 452 in epoch 10, gen_loss = 0.8885033872743316, disc_loss = 0.00012571564664974014
Trained batch 453 in epoch 10, gen_loss = 0.8885038122206532, disc_loss = 0.00012561749265277154
Trained batch 454 in epoch 10, gen_loss = 0.8882835880740658, disc_loss = 0.00012553840304582872
Trained batch 455 in epoch 10, gen_loss = 0.8883834188444573, disc_loss = 0.00012564773671105636
Trained batch 456 in epoch 10, gen_loss = 0.8883741751019751, disc_loss = 0.0001258603762787501
Trained batch 457 in epoch 10, gen_loss = 0.8883412091232283, disc_loss = 0.00012583521053017834
Trained batch 458 in epoch 10, gen_loss = 0.8883294283954146, disc_loss = 0.0001256473348163396
Trained batch 459 in epoch 10, gen_loss = 0.8883497065824011, disc_loss = 0.00012556866621035506
Trained batch 460 in epoch 10, gen_loss = 0.8881404207223408, disc_loss = 0.00012547094596330422
Trained batch 461 in epoch 10, gen_loss = 0.8878846764564514, disc_loss = 0.0001253717245403158
Trained batch 462 in epoch 10, gen_loss = 0.887891938052991, disc_loss = 0.00012525588045791586
Trained batch 463 in epoch 10, gen_loss = 0.8877821759930973, disc_loss = 0.00012532707543461334
Trained batch 464 in epoch 10, gen_loss = 0.88778160079833, disc_loss = 0.00012519468005868026
Trained batch 465 in epoch 10, gen_loss = 0.8876018797890822, disc_loss = 0.0001250378420956052
Trained batch 466 in epoch 10, gen_loss = 0.8877798091676047, disc_loss = 0.00012486924163234865
Trained batch 467 in epoch 10, gen_loss = 0.8878829899506692, disc_loss = 0.0001247518511162424
Trained batch 468 in epoch 10, gen_loss = 0.8879914568431342, disc_loss = 0.00012471942223736575
Trained batch 469 in epoch 10, gen_loss = 0.888050226708676, disc_loss = 0.00012469257469885944
Trained batch 470 in epoch 10, gen_loss = 0.887989818037442, disc_loss = 0.0001245851402726833
Trained batch 471 in epoch 10, gen_loss = 0.8878843961125713, disc_loss = 0.00012442761336557343
Trained batch 472 in epoch 10, gen_loss = 0.8878148038089906, disc_loss = 0.00012429815628253274
Trained batch 473 in epoch 10, gen_loss = 0.8876621168625506, disc_loss = 0.00012424885390993436
Trained batch 474 in epoch 10, gen_loss = 0.8875445121213009, disc_loss = 0.00012417124726772798
Trained batch 475 in epoch 10, gen_loss = 0.8877082693727076, disc_loss = 0.00012403655868749273
Trained batch 476 in epoch 10, gen_loss = 0.8876073596612463, disc_loss = 0.00012393868542187242
Trained batch 477 in epoch 10, gen_loss = 0.8878273392820957, disc_loss = 0.00012395399328749617
Trained batch 478 in epoch 10, gen_loss = 0.8879735011895166, disc_loss = 0.00012416205366839856
Trained batch 479 in epoch 10, gen_loss = 0.887919400135676, disc_loss = 0.00012428137869543814
Trained batch 480 in epoch 10, gen_loss = 0.8879119891386765, disc_loss = 0.00012417376479210204
Trained batch 481 in epoch 10, gen_loss = 0.8878132320043952, disc_loss = 0.00012417169361556658
Trained batch 482 in epoch 10, gen_loss = 0.8878998382491354, disc_loss = 0.00012417030215086696
Trained batch 483 in epoch 10, gen_loss = 0.8881441203276973, disc_loss = 0.00012417104119604044
Trained batch 484 in epoch 10, gen_loss = 0.8879881837933334, disc_loss = 0.00012408506803150942
Trained batch 485 in epoch 10, gen_loss = 0.8879515094521605, disc_loss = 0.00012405297522132002
Trained batch 486 in epoch 10, gen_loss = 0.887664123727066, disc_loss = 0.00012394871750041637
Trained batch 487 in epoch 10, gen_loss = 0.8875262858193429, disc_loss = 0.00012379253125725911
Trained batch 488 in epoch 10, gen_loss = 0.887287055422192, disc_loss = 0.00012363566963185637
Trained batch 489 in epoch 10, gen_loss = 0.8873573292274864, disc_loss = 0.00012353856159743557
Trained batch 490 in epoch 10, gen_loss = 0.8872798534371945, disc_loss = 0.00012336897479813373
Trained batch 491 in epoch 10, gen_loss = 0.8875652516518182, disc_loss = 0.00012338471824330008
Trained batch 492 in epoch 10, gen_loss = 0.8877805692670795, disc_loss = 0.00012343747040374217
Trained batch 493 in epoch 10, gen_loss = 0.8879106804909493, disc_loss = 0.00012335648771776272
Trained batch 494 in epoch 10, gen_loss = 0.8879834641109813, disc_loss = 0.00012333961905567023
Trained batch 495 in epoch 10, gen_loss = 0.8878430500626564, disc_loss = 0.00012325163764569056
Trained batch 496 in epoch 10, gen_loss = 0.8880137157152356, disc_loss = 0.00012323784542986064
Trained batch 497 in epoch 10, gen_loss = 0.8877725124837883, disc_loss = 0.00012335359497959156
Trained batch 498 in epoch 10, gen_loss = 0.8878436198454343, disc_loss = 0.0001234164526481354
Trained batch 499 in epoch 10, gen_loss = 0.888111605167389, disc_loss = 0.0001235683916384005
Trained batch 500 in epoch 10, gen_loss = 0.8881057593636884, disc_loss = 0.00012349743231093025
Trained batch 501 in epoch 10, gen_loss = 0.8881199122425094, disc_loss = 0.00012346463602107432
Trained batch 502 in epoch 10, gen_loss = 0.8879995143437244, disc_loss = 0.0001234372183559606
Trained batch 503 in epoch 10, gen_loss = 0.8879592268476411, disc_loss = 0.00012343729322166172
Trained batch 504 in epoch 10, gen_loss = 0.8879478089880235, disc_loss = 0.00012345875642639308
Trained batch 505 in epoch 10, gen_loss = 0.887980754314204, disc_loss = 0.00012341453848672864
Trained batch 506 in epoch 10, gen_loss = 0.8878071436280094, disc_loss = 0.00012325811596017623
Trained batch 507 in epoch 10, gen_loss = 0.8876527733220829, disc_loss = 0.0001232047701791533
Trained batch 508 in epoch 10, gen_loss = 0.8875616742023551, disc_loss = 0.00012304295382988714
Trained batch 509 in epoch 10, gen_loss = 0.8878042592721826, disc_loss = 0.00012300190228059222
Trained batch 510 in epoch 10, gen_loss = 0.8877990237654072, disc_loss = 0.00012290061960185225
Trained batch 511 in epoch 10, gen_loss = 0.8877176189562306, disc_loss = 0.0001227932021024003
Trained batch 512 in epoch 10, gen_loss = 0.8880270743927761, disc_loss = 0.0001231186754409143
Trained batch 513 in epoch 10, gen_loss = 0.8879060268634025, disc_loss = 0.00012336112979969603
Trained batch 514 in epoch 10, gen_loss = 0.8879209095991931, disc_loss = 0.00012341985956949942
Trained batch 515 in epoch 10, gen_loss = 0.8879721943260164, disc_loss = 0.00012351861272507858
Trained batch 516 in epoch 10, gen_loss = 0.8881489898526692, disc_loss = 0.00012382283634739221
Trained batch 517 in epoch 10, gen_loss = 0.8884884174265917, disc_loss = 0.0001242424576076599
Trained batch 518 in epoch 10, gen_loss = 0.8882802955677055, disc_loss = 0.00012495701629209767
Trained batch 519 in epoch 10, gen_loss = 0.8881906273273321, disc_loss = 0.0001260400220766874
Trained batch 520 in epoch 10, gen_loss = 0.8882865449288527, disc_loss = 0.00012610454861030666
Trained batch 521 in epoch 10, gen_loss = 0.8882976548881824, disc_loss = 0.00012614237757972165
Trained batch 522 in epoch 10, gen_loss = 0.8882478031100096, disc_loss = 0.00012622793657582985
Trained batch 523 in epoch 10, gen_loss = 0.8880603026797753, disc_loss = 0.00012643115369011853
Trained batch 524 in epoch 10, gen_loss = 0.8881579869134085, disc_loss = 0.0001263811545366133
Trained batch 525 in epoch 10, gen_loss = 0.8882079824748601, disc_loss = 0.0001262169186456993
Trained batch 526 in epoch 10, gen_loss = 0.8880364304475585, disc_loss = 0.00012607500307766485
Trained batch 527 in epoch 10, gen_loss = 0.8881137460244425, disc_loss = 0.00012594089719531246
Trained batch 528 in epoch 10, gen_loss = 0.8880837468433921, disc_loss = 0.0001258028081696593
Trained batch 529 in epoch 10, gen_loss = 0.8879361847661577, disc_loss = 0.00012580957274690692
Trained batch 530 in epoch 10, gen_loss = 0.8878485130500434, disc_loss = 0.00012569174410778812
Trained batch 531 in epoch 10, gen_loss = 0.8879711049839967, disc_loss = 0.0001255734923209897
Trained batch 532 in epoch 10, gen_loss = 0.8877637909679879, disc_loss = 0.00012542957406546518
Trained batch 533 in epoch 10, gen_loss = 0.8875740480780155, disc_loss = 0.00012528685015632355
Trained batch 534 in epoch 10, gen_loss = 0.8875522076526535, disc_loss = 0.00012517702313157443
Trained batch 535 in epoch 10, gen_loss = 0.8877143913240575, disc_loss = 0.00012507517028518747
Trained batch 536 in epoch 10, gen_loss = 0.8877222533554561, disc_loss = 0.00012502644850145782
Trained batch 537 in epoch 10, gen_loss = 0.8879602932575467, disc_loss = 0.00012509267039655025
Trained batch 538 in epoch 10, gen_loss = 0.8879754232564088, disc_loss = 0.00012500573180534693
Trained batch 539 in epoch 10, gen_loss = 0.887795568395544, disc_loss = 0.0001250279534832333
Trained batch 540 in epoch 10, gen_loss = 0.8879691974953671, disc_loss = 0.0001254308700446184
Trained batch 541 in epoch 10, gen_loss = 0.8880431931397131, disc_loss = 0.0001257369570765727
Trained batch 542 in epoch 10, gen_loss = 0.8881848408372363, disc_loss = 0.00012624708698285507
Trained batch 543 in epoch 10, gen_loss = 0.8881024436696487, disc_loss = 0.0001271677621094996
Trained batch 544 in epoch 10, gen_loss = 0.8880939564573656, disc_loss = 0.0001285756496528864
Trained batch 545 in epoch 10, gen_loss = 0.8881158596211738, disc_loss = 0.0001302136820097089
Trained batch 546 in epoch 10, gen_loss = 0.8882110039320463, disc_loss = 0.00013128863555001235
Trained batch 547 in epoch 10, gen_loss = 0.888164753787709, disc_loss = 0.00013190188118423178
Trained batch 548 in epoch 10, gen_loss = 0.8881442576158242, disc_loss = 0.0001322718543714703
Trained batch 549 in epoch 10, gen_loss = 0.8883968308838931, disc_loss = 0.0001325847647703168
Trained batch 550 in epoch 10, gen_loss = 0.8883103979261298, disc_loss = 0.00013273974991286894
Trained batch 551 in epoch 10, gen_loss = 0.888256820431654, disc_loss = 0.00013280019234314196
Trained batch 552 in epoch 10, gen_loss = 0.888108051168121, disc_loss = 0.00013287307223630143
Trained batch 553 in epoch 10, gen_loss = 0.888197688957414, disc_loss = 0.00013298138550361653
Trained batch 554 in epoch 10, gen_loss = 0.8881038196452029, disc_loss = 0.00013319461172245242
Trained batch 555 in epoch 10, gen_loss = 0.8877968333607955, disc_loss = 0.00013332763562090327
Trained batch 556 in epoch 10, gen_loss = 0.8877829403166712, disc_loss = 0.00013331880722332017
Trained batch 557 in epoch 10, gen_loss = 0.8877499565001457, disc_loss = 0.00013351125983140802
Trained batch 558 in epoch 10, gen_loss = 0.887861434163689, disc_loss = 0.0001336823121043945
Trained batch 559 in epoch 10, gen_loss = 0.8877700170235975, disc_loss = 0.00013382256376124653
Trained batch 560 in epoch 10, gen_loss = 0.8875499106345968, disc_loss = 0.00013384451407880263
Trained batch 561 in epoch 10, gen_loss = 0.8878223415583478, disc_loss = 0.00013426063886078844
Trained batch 562 in epoch 10, gen_loss = 0.8877575966011779, disc_loss = 0.00013465932182174468
Trained batch 563 in epoch 10, gen_loss = 0.8879982969650986, disc_loss = 0.00013521420146550832
Trained batch 564 in epoch 10, gen_loss = 0.8881094066442642, disc_loss = 0.0001359142532285748
Trained batch 565 in epoch 10, gen_loss = 0.887972105939481, disc_loss = 0.0001365674828319455
Trained batch 566 in epoch 10, gen_loss = 0.8878707828975859, disc_loss = 0.00013688334229059775
Trained batch 567 in epoch 10, gen_loss = 0.8879894696071114, disc_loss = 0.00013714676829359106
Trained batch 568 in epoch 10, gen_loss = 0.8879598073255408, disc_loss = 0.00013714623585325356
Trained batch 569 in epoch 10, gen_loss = 0.8878630009659549, disc_loss = 0.00013711849013608963
Trained batch 570 in epoch 10, gen_loss = 0.8877130138268613, disc_loss = 0.00013705962506773672
Trained batch 571 in epoch 10, gen_loss = 0.887759846094605, disc_loss = 0.00013706409528593442
Trained batch 572 in epoch 10, gen_loss = 0.8877785733232948, disc_loss = 0.00013718018358566003
Trained batch 573 in epoch 10, gen_loss = 0.8878991513509784, disc_loss = 0.00013729002639973367
Trained batch 574 in epoch 10, gen_loss = 0.8878769343832265, disc_loss = 0.0001373158044019795
Trained batch 575 in epoch 10, gen_loss = 0.8877934743132856, disc_loss = 0.00013737938929302295
Trained batch 576 in epoch 10, gen_loss = 0.887677742662215, disc_loss = 0.00013739940158754871
Trained batch 577 in epoch 10, gen_loss = 0.8877103542167836, disc_loss = 0.00013740333440676524
Trained batch 578 in epoch 10, gen_loss = 0.8876488922173495, disc_loss = 0.0001376658565560211
Trained batch 579 in epoch 10, gen_loss = 0.8875780585510977, disc_loss = 0.00013765581935676265
Trained batch 580 in epoch 10, gen_loss = 0.8874092116413346, disc_loss = 0.00013767988552265638
Trained batch 581 in epoch 10, gen_loss = 0.8873157036263508, disc_loss = 0.00013780664891417416
Trained batch 582 in epoch 10, gen_loss = 0.8874022842066979, disc_loss = 0.00013832072442833583
Trained batch 583 in epoch 10, gen_loss = 0.8872678463589655, disc_loss = 0.00013842686032198613
Trained batch 584 in epoch 10, gen_loss = 0.8872835477193196, disc_loss = 0.00013926973298757187
Trained batch 585 in epoch 10, gen_loss = 0.8871340978471085, disc_loss = 0.00013965174278447804
Trained batch 586 in epoch 10, gen_loss = 0.8873388140733645, disc_loss = 0.0001413777739910672
Trained batch 587 in epoch 10, gen_loss = 0.8872217207538838, disc_loss = 0.00014541944513433189
Trained batch 588 in epoch 10, gen_loss = 0.8874029965473558, disc_loss = 0.00014878537941483721
Trained batch 589 in epoch 10, gen_loss = 0.8875694260758868, disc_loss = 0.00015115409367323174
Trained batch 590 in epoch 10, gen_loss = 0.8876619764592644, disc_loss = 0.0001553772610270256
Trained batch 591 in epoch 10, gen_loss = 0.8875812077643098, disc_loss = 0.00015864778578287696
Trained batch 592 in epoch 10, gen_loss = 0.8881012901889936, disc_loss = 0.00017687277479684624
Trained batch 593 in epoch 10, gen_loss = 0.8883547571171012, disc_loss = 0.00018450625100477225
Trained batch 594 in epoch 10, gen_loss = 0.8887566238892178, disc_loss = 0.00019251599520476176
Trained batch 595 in epoch 10, gen_loss = 0.8887745969047482, disc_loss = 0.0001953386323879654
Trained batch 596 in epoch 10, gen_loss = 0.88902217329447, disc_loss = 0.00019582037340500197
Trained batch 597 in epoch 10, gen_loss = 0.8889402751141169, disc_loss = 0.0001969866363688319
Trained batch 598 in epoch 10, gen_loss = 0.8888986511700141, disc_loss = 0.00019770631670037623
Trained batch 599 in epoch 10, gen_loss = 0.889016572634379, disc_loss = 0.00019786159396365595
Trained batch 600 in epoch 10, gen_loss = 0.889088840730575, disc_loss = 0.0001979865853948993
Trained batch 601 in epoch 10, gen_loss = 0.8891161953492022, disc_loss = 0.0001995917624311268
Trained batch 602 in epoch 10, gen_loss = 0.8889581298155966, disc_loss = 0.00020001230946360511
Trained batch 603 in epoch 10, gen_loss = 0.8888631143317317, disc_loss = 0.00020094580882050047
Trained batch 604 in epoch 10, gen_loss = 0.8891202437976176, disc_loss = 0.00020134431764114
Trained batch 605 in epoch 10, gen_loss = 0.8891522868631696, disc_loss = 0.00020185142354778453
Trained batch 606 in epoch 10, gen_loss = 0.8890015597791217, disc_loss = 0.00020230495797844583
Trained batch 607 in epoch 10, gen_loss = 0.8890606376685595, disc_loss = 0.0002027789365743765
Trained batch 608 in epoch 10, gen_loss = 0.8891761594609479, disc_loss = 0.00020271776229611863
Trained batch 609 in epoch 10, gen_loss = 0.8892794673560096, disc_loss = 0.0002026180339763399
Trained batch 610 in epoch 10, gen_loss = 0.8892009815295667, disc_loss = 0.0002027082279550884
Trained batch 611 in epoch 10, gen_loss = 0.8894527697680044, disc_loss = 0.00020283595212770237
Trained batch 612 in epoch 10, gen_loss = 0.8893903918795251, disc_loss = 0.0002028431739015459
Trained batch 613 in epoch 10, gen_loss = 0.8894219986778905, disc_loss = 0.0002030658040609793
Trained batch 614 in epoch 10, gen_loss = 0.8894353824902356, disc_loss = 0.0002035330030764264
Trained batch 615 in epoch 10, gen_loss = 0.8892698434072656, disc_loss = 0.00020441797559297729
Trained batch 616 in epoch 10, gen_loss = 0.8892677065039376, disc_loss = 0.00020548048624663193
Trained batch 617 in epoch 10, gen_loss = 0.8888872477036078, disc_loss = 0.0002401332044295822
Trained batch 618 in epoch 10, gen_loss = 0.8892734284739887, disc_loss = 0.00026465911491170693
Trained batch 619 in epoch 10, gen_loss = 0.8894119034851751, disc_loss = 0.00026807910593737276
Trained batch 620 in epoch 10, gen_loss = 0.8895677659246657, disc_loss = 0.0002715599221880765
Trained batch 621 in epoch 10, gen_loss = 0.8895985513829725, disc_loss = 0.000279540042400396
Trained batch 622 in epoch 10, gen_loss = 0.8895245181040817, disc_loss = 0.0002906264452843734
Trained batch 623 in epoch 10, gen_loss = 0.8895321268683825, disc_loss = 0.0002966092163264059
Trained batch 624 in epoch 10, gen_loss = 0.8896089012145996, disc_loss = 0.00029970107208937406
Trained batch 625 in epoch 10, gen_loss = 0.8898028443796566, disc_loss = 0.0003025470888792588
Trained batch 626 in epoch 10, gen_loss = 0.8900236961754125, disc_loss = 0.0003027544780953697
Trained batch 627 in epoch 10, gen_loss = 0.8901716503937533, disc_loss = 0.0003037889216282067
Trained batch 628 in epoch 10, gen_loss = 0.8901696121749514, disc_loss = 0.0003039493166844528
Trained batch 629 in epoch 10, gen_loss = 0.89021546887973, disc_loss = 0.0003037745660837991
Trained batch 630 in epoch 10, gen_loss = 0.8902946957128739, disc_loss = 0.00030379114998080185
Trained batch 631 in epoch 10, gen_loss = 0.8902848252578627, disc_loss = 0.000303660560636177
Trained batch 632 in epoch 10, gen_loss = 0.8903493136402931, disc_loss = 0.00030369880939517494
Trained batch 633 in epoch 10, gen_loss = 0.8903278952893399, disc_loss = 0.0003035931940212896
Trained batch 634 in epoch 10, gen_loss = 0.8904495066545141, disc_loss = 0.0003037574964320639
Trained batch 635 in epoch 10, gen_loss = 0.8904813552427592, disc_loss = 0.00030403235533590277
Trained batch 636 in epoch 10, gen_loss = 0.890661421151513, disc_loss = 0.00030400738990635375
Trained batch 637 in epoch 10, gen_loss = 0.8905472860067242, disc_loss = 0.00030409669841411247
Trained batch 638 in epoch 10, gen_loss = 0.8906783328183193, disc_loss = 0.0003040678061445423
Trained batch 639 in epoch 10, gen_loss = 0.8905126328580082, disc_loss = 0.00030569860698506093
Trained batch 640 in epoch 10, gen_loss = 0.8905929260990363, disc_loss = 0.00030740220137372723
Trained batch 641 in epoch 10, gen_loss = 0.890716564525325, disc_loss = 0.00030832759378390166
Trained batch 642 in epoch 10, gen_loss = 0.890631630947208, disc_loss = 0.00030944885350282206
Trained batch 643 in epoch 10, gen_loss = 0.890655853733513, disc_loss = 0.0003097532303258704
Trained batch 644 in epoch 10, gen_loss = 0.8906470353289168, disc_loss = 0.0003101814454087497
Trained batch 645 in epoch 10, gen_loss = 0.890653142526792, disc_loss = 0.0003102612201653885
Trained batch 646 in epoch 10, gen_loss = 0.8904594978003819, disc_loss = 0.0003116075560593419
Trained batch 647 in epoch 10, gen_loss = 0.8904171217186951, disc_loss = 0.0003127721198706925
Trained batch 648 in epoch 10, gen_loss = 0.8903803135654408, disc_loss = 0.0003128052036518673
Trained batch 649 in epoch 10, gen_loss = 0.890295744400758, disc_loss = 0.0003133907096344046
Trained batch 650 in epoch 10, gen_loss = 0.8902800258952901, disc_loss = 0.0003133694374261098
Trained batch 651 in epoch 10, gen_loss = 0.8902245224253532, disc_loss = 0.00031319385614250413
Trained batch 652 in epoch 10, gen_loss = 0.8904591367949388, disc_loss = 0.000313254166635147
Trained batch 653 in epoch 10, gen_loss = 0.8905639848942422, disc_loss = 0.0003129983821605042
Trained batch 654 in epoch 10, gen_loss = 0.8904880972308967, disc_loss = 0.00031300427888445413
Trained batch 655 in epoch 10, gen_loss = 0.8904399223989103, disc_loss = 0.00031297168245545456
Trained batch 656 in epoch 10, gen_loss = 0.8906344499217865, disc_loss = 0.0003133732966607
Trained batch 657 in epoch 10, gen_loss = 0.8907828952403779, disc_loss = 0.0003136290200551799
Trained batch 658 in epoch 10, gen_loss = 0.8908096542850431, disc_loss = 0.00031351472873559393
Trained batch 659 in epoch 10, gen_loss = 0.8909882267316183, disc_loss = 0.0003137511662234002
Trained batch 660 in epoch 10, gen_loss = 0.8909791423044479, disc_loss = 0.0003138506322852216
Trained batch 661 in epoch 10, gen_loss = 0.8909853292555967, disc_loss = 0.0003140482940882363
Trained batch 662 in epoch 10, gen_loss = 0.8910469373247023, disc_loss = 0.0003140744671138105
Trained batch 663 in epoch 10, gen_loss = 0.8909879272063095, disc_loss = 0.00031385592712949913
Trained batch 664 in epoch 10, gen_loss = 0.8908489090159424, disc_loss = 0.000313694387585926
Trained batch 665 in epoch 10, gen_loss = 0.8907318812411826, disc_loss = 0.00031360738408453233
Trained batch 666 in epoch 10, gen_loss = 0.8906219124436557, disc_loss = 0.0003135171810308516
Trained batch 667 in epoch 10, gen_loss = 0.890765205917958, disc_loss = 0.000313473169620931
Trained batch 668 in epoch 10, gen_loss = 0.890660548869448, disc_loss = 0.0003212032761045082
Trained batch 669 in epoch 10, gen_loss = 0.8908303501890666, disc_loss = 0.0003324471093729875
Trained batch 670 in epoch 10, gen_loss = 0.890980634532991, disc_loss = 0.00033422442522727856
Trained batch 671 in epoch 10, gen_loss = 0.8909256059144225, disc_loss = 0.0003361594580209861
Trained batch 672 in epoch 10, gen_loss = 0.8910785297050873, disc_loss = 0.0003370155998649917
Trained batch 673 in epoch 10, gen_loss = 0.8910520693138021, disc_loss = 0.0003372637437940133
Trained batch 674 in epoch 10, gen_loss = 0.8911625654609115, disc_loss = 0.0003372382325404841
Trained batch 675 in epoch 10, gen_loss = 0.8912847243998883, disc_loss = 0.00033738251669851086
Trained batch 676 in epoch 10, gen_loss = 0.8912446814942747, disc_loss = 0.00033746502347833213
Trained batch 677 in epoch 10, gen_loss = 0.8912953833738962, disc_loss = 0.00033741290079670815
Trained batch 678 in epoch 10, gen_loss = 0.8914788228422623, disc_loss = 0.00033729939710123216
Trained batch 679 in epoch 10, gen_loss = 0.8916599395520547, disc_loss = 0.00033712155899967696
Trained batch 680 in epoch 10, gen_loss = 0.8916822977353123, disc_loss = 0.00033721672627878634
Trained batch 681 in epoch 10, gen_loss = 0.8917535615981149, disc_loss = 0.0003370768227366952
Trained batch 682 in epoch 10, gen_loss = 0.8917662157495758, disc_loss = 0.0003369288608040811
Trained batch 683 in epoch 10, gen_loss = 0.8919633953717717, disc_loss = 0.0003368605938336706
Trained batch 684 in epoch 10, gen_loss = 0.8920112609863281, disc_loss = 0.0003366745708435502
Trained batch 685 in epoch 10, gen_loss = 0.8919664704764897, disc_loss = 0.0003368472394077976
Trained batch 686 in epoch 10, gen_loss = 0.8920220403865609, disc_loss = 0.0003370439641437259
Trained batch 687 in epoch 10, gen_loss = 0.8919597242114156, disc_loss = 0.0003368201857674014
Trained batch 688 in epoch 10, gen_loss = 0.8920421264687194, disc_loss = 0.00033669772937489035
Trained batch 689 in epoch 10, gen_loss = 0.8919599194457566, disc_loss = 0.00033754732687974457
Trained batch 690 in epoch 10, gen_loss = 0.891843546144179, disc_loss = 0.0003376177937042052
Trained batch 691 in epoch 10, gen_loss = 0.8919267899039164, disc_loss = 0.00033778292875157566
Trained batch 692 in epoch 10, gen_loss = 0.8919656505488386, disc_loss = 0.0003377012080070462
Trained batch 693 in epoch 10, gen_loss = 0.8920609550792133, disc_loss = 0.000337562954426684
Trained batch 694 in epoch 10, gen_loss = 0.892183440023189, disc_loss = 0.00033811971938016444
Trained batch 695 in epoch 10, gen_loss = 0.8923625925491596, disc_loss = 0.00033866817558327446
Trained batch 696 in epoch 10, gen_loss = 0.8924536380056329, disc_loss = 0.0003385235778404496
Trained batch 697 in epoch 10, gen_loss = 0.8927221469004721, disc_loss = 0.0003389844914688462
Trained batch 698 in epoch 10, gen_loss = 0.8927571483606603, disc_loss = 0.00033884524887871364
Trained batch 699 in epoch 10, gen_loss = 0.8927868868623461, disc_loss = 0.00033871387243769797
Trained batch 700 in epoch 10, gen_loss = 0.8928584578033861, disc_loss = 0.00033850511547627086
Trained batch 701 in epoch 10, gen_loss = 0.8928652747913643, disc_loss = 0.00033862476127336275
Trained batch 702 in epoch 10, gen_loss = 0.8929045731109033, disc_loss = 0.00033890547296747695
Trained batch 703 in epoch 10, gen_loss = 0.8930402812124654, disc_loss = 0.0003389349698905293
Trained batch 704 in epoch 10, gen_loss = 0.8931083324107718, disc_loss = 0.0003387233572442362
Trained batch 705 in epoch 10, gen_loss = 0.8932389917522247, disc_loss = 0.00033856228988854447
Trained batch 706 in epoch 10, gen_loss = 0.8932256092445179, disc_loss = 0.00033857049092388933
Trained batch 707 in epoch 10, gen_loss = 0.8929330207365381, disc_loss = 0.00038383594967900396
Trained batch 708 in epoch 10, gen_loss = 0.8933325438472549, disc_loss = 0.0007229827468016491
Trained batch 709 in epoch 10, gen_loss = 0.8931604362709421, disc_loss = 0.0008320605993708661
Trained batch 710 in epoch 10, gen_loss = 0.893061215783641, disc_loss = 0.0008791848899377117
Trained batch 711 in epoch 10, gen_loss = 0.8931487048609873, disc_loss = 0.0009293085118627183
Trained batch 712 in epoch 10, gen_loss = 0.8932304069671524, disc_loss = 0.0009634606731031155
Trained batch 713 in epoch 10, gen_loss = 0.8926208719652908, disc_loss = 0.0013114631898739997
Trained batch 714 in epoch 10, gen_loss = 0.8926280255084271, disc_loss = 0.0026405680984693375
Trained batch 715 in epoch 10, gen_loss = 0.8924051296777565, disc_loss = 0.00296062823495481
Trained batch 716 in epoch 10, gen_loss = 0.8920159738100389, disc_loss = 0.0032714852159302175
Trained batch 717 in epoch 10, gen_loss = 0.8916019578996143, disc_loss = 0.0036054047839033476
Trained batch 718 in epoch 10, gen_loss = 0.8913222933511906, disc_loss = 0.0038789827539933643
Trained batch 719 in epoch 10, gen_loss = 0.8910468941761388, disc_loss = 0.004090420273920851
Trained batch 720 in epoch 10, gen_loss = 0.8907167916489706, disc_loss = 0.004282975260144256
Trained batch 721 in epoch 10, gen_loss = 0.8905033870416995, disc_loss = 0.004396647744542962
Trained batch 722 in epoch 10, gen_loss = 0.8902474612121265, disc_loss = 0.004475656451919389
Trained batch 723 in epoch 10, gen_loss = 0.8899331466598406, disc_loss = 0.004680169698182019
Trained batch 724 in epoch 10, gen_loss = 0.8896877672754485, disc_loss = 0.004948202662695809
Trained batch 725 in epoch 10, gen_loss = 0.8893154578760636, disc_loss = 0.005128039435313382
Trained batch 726 in epoch 10, gen_loss = 0.889311010276763, disc_loss = 0.005274679366526568
Trained batch 727 in epoch 10, gen_loss = 0.8890510754107119, disc_loss = 0.005356753995439139
Trained batch 728 in epoch 10, gen_loss = 0.8885686290444006, disc_loss = 0.005573959602885407
Trained batch 729 in epoch 10, gen_loss = 0.888601756830738, disc_loss = 0.005812551584617037
Trained batch 730 in epoch 10, gen_loss = 0.8882693672799868, disc_loss = 0.006008600765945442
Trained batch 731 in epoch 10, gen_loss = 0.8879912663352946, disc_loss = 0.00612341467358469
Trained batch 732 in epoch 10, gen_loss = 0.8879451544353126, disc_loss = 0.006233424754599065
Trained batch 733 in epoch 10, gen_loss = 0.8878654738537947, disc_loss = 0.006309840131095992
Trained batch 734 in epoch 10, gen_loss = 0.8879134100310656, disc_loss = 0.006354448912157614
Trained batch 735 in epoch 10, gen_loss = 0.8879391940553552, disc_loss = 0.006426549089689576
Trained batch 736 in epoch 10, gen_loss = 0.8878804007734664, disc_loss = 0.006471201927340943
Trained batch 737 in epoch 10, gen_loss = 0.8878557452664466, disc_loss = 0.006504034543507588
Trained batch 738 in epoch 10, gen_loss = 0.8876980364887253, disc_loss = 0.006526216550292075
Trained batch 739 in epoch 10, gen_loss = 0.8874033000823613, disc_loss = 0.006585782517917372
Trained batch 740 in epoch 10, gen_loss = 0.887523512447733, disc_loss = 0.0066327625734902175
Trained batch 741 in epoch 10, gen_loss = 0.887322476851651, disc_loss = 0.006667102075311653
Trained batch 742 in epoch 10, gen_loss = 0.8873431998659752, disc_loss = 0.006686538195407205
Trained batch 743 in epoch 10, gen_loss = 0.8874088932750046, disc_loss = 0.006701772895613303
Trained batch 744 in epoch 10, gen_loss = 0.8877057285116823, disc_loss = 0.006736955274933255
Trained batch 745 in epoch 10, gen_loss = 0.8878095169169653, disc_loss = 0.00673921802594191
Trained batch 746 in epoch 10, gen_loss = 0.8877199813224864, disc_loss = 0.006742705156666805
Trained batch 747 in epoch 10, gen_loss = 0.8875979983551617, disc_loss = 0.006745695404939193
Trained batch 748 in epoch 10, gen_loss = 0.8877578875092225, disc_loss = 0.00674747647383037
Trained batch 749 in epoch 10, gen_loss = 0.8879256059328715, disc_loss = 0.006747429885726888
Trained batch 750 in epoch 10, gen_loss = 0.8878978824171023, disc_loss = 0.006752728727148113
Trained batch 751 in epoch 10, gen_loss = 0.8879592835586122, disc_loss = 0.0067634754574062254
Trained batch 752 in epoch 10, gen_loss = 0.8881873721937101, disc_loss = 0.006763183558309497
Trained batch 753 in epoch 10, gen_loss = 0.8881168448482332, disc_loss = 0.0070843993809772965
Trained batch 754 in epoch 10, gen_loss = 0.8877627372741699, disc_loss = 0.007378032782083432
Trained batch 755 in epoch 10, gen_loss = 0.8877005532935813, disc_loss = 0.007431290973058413
Trained batch 756 in epoch 10, gen_loss = 0.8875100494533423, disc_loss = 0.0074887962175385235
Trained batch 757 in epoch 10, gen_loss = 0.8874134677695725, disc_loss = 0.007602352922484199
Trained batch 758 in epoch 10, gen_loss = 0.8871998504216492, disc_loss = 0.007663899650551073
Trained batch 759 in epoch 10, gen_loss = 0.8869416296482087, disc_loss = 0.007689696715322881
Trained batch 760 in epoch 10, gen_loss = 0.8868447119240379, disc_loss = 0.007725414112172794
Trained batch 761 in epoch 10, gen_loss = 0.8869197078420734, disc_loss = 0.0077280913232854725
Trained batch 762 in epoch 10, gen_loss = 0.8869345746690293, disc_loss = 0.007775191258684718
Trained batch 763 in epoch 10, gen_loss = 0.8868011094980839, disc_loss = 0.0077861628456262775
Trained batch 764 in epoch 10, gen_loss = 0.886602503256081, disc_loss = 0.007830338661685993
Trained batch 765 in epoch 10, gen_loss = 0.8865606703117062, disc_loss = 0.007853595230632794
Trained batch 766 in epoch 10, gen_loss = 0.8865550130100573, disc_loss = 0.007865762925260419
Trained batch 767 in epoch 10, gen_loss = 0.8865266152036687, disc_loss = 0.007886016740921301
Trained batch 768 in epoch 10, gen_loss = 0.8864500320314276, disc_loss = 0.007898943253618881
Trained batch 769 in epoch 10, gen_loss = 0.8863970582361346, disc_loss = 0.007924905564018385
Trained batch 770 in epoch 10, gen_loss = 0.8863967337806247, disc_loss = 0.0079701956207029
Trained batch 771 in epoch 10, gen_loss = 0.8862253313237521, disc_loss = 0.008048404601216044
Trained batch 772 in epoch 10, gen_loss = 0.8859942151380541, disc_loss = 0.008233307514538931
Trained batch 773 in epoch 10, gen_loss = 0.8862073862737463, disc_loss = 0.008863224110815606
Trained batch 774 in epoch 10, gen_loss = 0.8862368470622647, disc_loss = 0.009345996182303005
Trained batch 775 in epoch 10, gen_loss = 0.8859669007744986, disc_loss = 0.00959273676830749
Trained batch 776 in epoch 10, gen_loss = 0.8856469710361083, disc_loss = 0.009866230961239052
Trained batch 777 in epoch 10, gen_loss = 0.8851439277126734, disc_loss = 0.01012458879654975
Trained batch 778 in epoch 10, gen_loss = 0.8846322311057359, disc_loss = 0.010388092750716154
Trained batch 779 in epoch 10, gen_loss = 0.8842478687182451, disc_loss = 0.010661040164828032
Trained batch 780 in epoch 10, gen_loss = 0.8837914977427787, disc_loss = 0.010930091652567689
Trained batch 781 in epoch 10, gen_loss = 0.883424724230681, disc_loss = 0.011192511466564461
Trained batch 782 in epoch 10, gen_loss = 0.8830164236279435, disc_loss = 0.011436960777209978
Trained batch 783 in epoch 10, gen_loss = 0.8826541761506577, disc_loss = 0.0116847099646163
Trained batch 784 in epoch 10, gen_loss = 0.8822082808822583, disc_loss = 0.011942600059767172
Trained batch 785 in epoch 10, gen_loss = 0.8819293455616511, disc_loss = 0.012213857000368278
Trained batch 786 in epoch 10, gen_loss = 0.8816026638544803, disc_loss = 0.012488981814926468
Trained batch 787 in epoch 10, gen_loss = 0.8812194698050543, disc_loss = 0.012679308969160362
Trained batch 788 in epoch 10, gen_loss = 0.8808240502203977, disc_loss = 0.012858511617533947
Trained batch 789 in epoch 10, gen_loss = 0.8805978289133386, disc_loss = 0.01303702100027939
Trained batch 790 in epoch 10, gen_loss = 0.8803114068191663, disc_loss = 0.013226733209314938
Trained batch 791 in epoch 10, gen_loss = 0.8799001437546027, disc_loss = 0.013481726639002599
Trained batch 792 in epoch 10, gen_loss = 0.8796019633811479, disc_loss = 0.013637900159412832
Trained batch 793 in epoch 10, gen_loss = 0.8796104090640167, disc_loss = 0.013795869133589286
Trained batch 794 in epoch 10, gen_loss = 0.8792374231530435, disc_loss = 0.013879032971453853
Trained batch 795 in epoch 10, gen_loss = 0.879077801377929, disc_loss = 0.013920584173612595
Trained batch 796 in epoch 10, gen_loss = 0.8787811217523429, disc_loss = 0.01397377369386612
Trained batch 797 in epoch 10, gen_loss = 0.8784924511772051, disc_loss = 0.014046613733414159
Trained batch 798 in epoch 10, gen_loss = 0.87854504436068, disc_loss = 0.01411613575760925
Trained batch 799 in epoch 10, gen_loss = 0.8784755194187164, disc_loss = 0.014250823445163405
Trained batch 800 in epoch 10, gen_loss = 0.8785337039296249, disc_loss = 0.014419589949301304
Trained batch 801 in epoch 10, gen_loss = 0.8785259702110528, disc_loss = 0.014463703368250902
Trained batch 802 in epoch 10, gen_loss = 0.8782359870848887, disc_loss = 0.014524432017036903
Trained batch 803 in epoch 10, gen_loss = 0.8784533820638609, disc_loss = 0.014533496421971909
Trained batch 804 in epoch 10, gen_loss = 0.8785876838316828, disc_loss = 0.014552427226260321
Trained batch 805 in epoch 10, gen_loss = 0.8786901179377553, disc_loss = 0.01454704971106942
Trained batch 806 in epoch 10, gen_loss = 0.8784091589323798, disc_loss = 0.014595258420821865
Trained batch 807 in epoch 10, gen_loss = 0.8788108765193732, disc_loss = 0.014665766230260344
Trained batch 808 in epoch 10, gen_loss = 0.8789582536895432, disc_loss = 0.014665054466599992
Trained batch 809 in epoch 10, gen_loss = 0.8789281420501662, disc_loss = 0.014701481534431855
Trained batch 810 in epoch 10, gen_loss = 0.8791606110944407, disc_loss = 0.014823791207630117
Trained batch 811 in epoch 10, gen_loss = 0.8792501474395761, disc_loss = 0.014824256420907825
Trained batch 812 in epoch 10, gen_loss = 0.8792036341418493, disc_loss = 0.01484233626723447
Trained batch 813 in epoch 10, gen_loss = 0.8792944807531793, disc_loss = 0.014850237620295813
Trained batch 814 in epoch 10, gen_loss = 0.8790285845475694, disc_loss = 0.014945876791032655
Trained batch 815 in epoch 10, gen_loss = 0.8791340518669755, disc_loss = 0.014959880026004149
Trained batch 816 in epoch 10, gen_loss = 0.8791947978362897, disc_loss = 0.014991531194844728
Trained batch 817 in epoch 10, gen_loss = 0.8792196720619948, disc_loss = 0.014987488143603019
Trained batch 818 in epoch 10, gen_loss = 0.8792754079832699, disc_loss = 0.014983229053254929
Trained batch 819 in epoch 10, gen_loss = 0.87928381663997, disc_loss = 0.014979290232618151
Trained batch 820 in epoch 10, gen_loss = 0.8794194457011159, disc_loss = 0.014970549912714166
Trained batch 821 in epoch 10, gen_loss = 0.879493854269204, disc_loss = 0.01496041959068846
Trained batch 822 in epoch 10, gen_loss = 0.8796495363605124, disc_loss = 0.014950789414008289
Trained batch 823 in epoch 10, gen_loss = 0.87975032179101, disc_loss = 0.014937949954719
Trained batch 824 in epoch 10, gen_loss = 0.8797244645610001, disc_loss = 0.01492663498980233
Trained batch 825 in epoch 10, gen_loss = 0.8797557943525384, disc_loss = 0.014916212056812376
Trained batch 826 in epoch 10, gen_loss = 0.8797922534406402, disc_loss = 0.014903210210618833
Trained batch 827 in epoch 10, gen_loss = 0.8800048994413321, disc_loss = 0.014888436711349852
Trained batch 828 in epoch 10, gen_loss = 0.8801156666367994, disc_loss = 0.014874447961275374
Trained batch 829 in epoch 10, gen_loss = 0.8801976710917002, disc_loss = 0.014861930352590097
Trained batch 830 in epoch 10, gen_loss = 0.8801797596843091, disc_loss = 0.014848838665753924
Trained batch 831 in epoch 10, gen_loss = 0.8802880798108302, disc_loss = 0.014836392300594525
Trained batch 832 in epoch 10, gen_loss = 0.8804148259569331, disc_loss = 0.014822305717749666
Trained batch 833 in epoch 10, gen_loss = 0.8804904757786712, disc_loss = 0.014807597450515991
Trained batch 834 in epoch 10, gen_loss = 0.8806464821278692, disc_loss = 0.01479271299463298
Trained batch 835 in epoch 10, gen_loss = 0.8808007276657095, disc_loss = 0.014778784913596174
Trained batch 836 in epoch 10, gen_loss = 0.880789776287056, disc_loss = 0.01476523771520363
Trained batch 837 in epoch 10, gen_loss = 0.8808043760587606, disc_loss = 0.014750249660917729
Trained batch 838 in epoch 10, gen_loss = 0.880869392203489, disc_loss = 0.014734673873377499
Trained batch 839 in epoch 10, gen_loss = 0.8808041657010715, disc_loss = 0.01472523335457178
Trained batch 840 in epoch 10, gen_loss = 0.8807529288296467, disc_loss = 0.01471053468276025
Trained batch 841 in epoch 10, gen_loss = 0.8809558735748935, disc_loss = 0.014699308762852642
Trained batch 842 in epoch 10, gen_loss = 0.8812776437009356, disc_loss = 0.01468604538559818
Trained batch 843 in epoch 10, gen_loss = 0.8813321634915203, disc_loss = 0.014671404003915327
Trained batch 844 in epoch 10, gen_loss = 0.8814699055880485, disc_loss = 0.014657684353151988
Trained batch 845 in epoch 10, gen_loss = 0.8816606357306171, disc_loss = 0.014641980032488703
Trained batch 846 in epoch 10, gen_loss = 0.8817799264452956, disc_loss = 0.014627628528810306
Trained batch 847 in epoch 10, gen_loss = 0.8819675669074059, disc_loss = 0.014612985107803225
Trained batch 848 in epoch 10, gen_loss = 0.8820193430279394, disc_loss = 0.014598105910811569
Trained batch 849 in epoch 10, gen_loss = 0.8819957471595091, disc_loss = 0.014583746148667106
Trained batch 850 in epoch 10, gen_loss = 0.8821034003508778, disc_loss = 0.014568880742500463
Trained batch 851 in epoch 10, gen_loss = 0.8821226089073458, disc_loss = 0.014554012165346238
Trained batch 852 in epoch 10, gen_loss = 0.8820329300823413, disc_loss = 0.014540234274909327
Trained batch 853 in epoch 10, gen_loss = 0.8821585126727192, disc_loss = 0.014525427326512446
Trained batch 854 in epoch 10, gen_loss = 0.8822479555481358, disc_loss = 0.014510064396162365
Trained batch 855 in epoch 10, gen_loss = 0.8824696806128894, disc_loss = 0.014494955494262635
Trained batch 856 in epoch 10, gen_loss = 0.8826210740149508, disc_loss = 0.014479846177092762
Trained batch 857 in epoch 10, gen_loss = 0.8826857079992761, disc_loss = 0.014464303358312938
Trained batch 858 in epoch 10, gen_loss = 0.8827537836656582, disc_loss = 0.014450344747095422
Trained batch 859 in epoch 10, gen_loss = 0.8827484318683314, disc_loss = 0.014435330579760566
Trained batch 860 in epoch 10, gen_loss = 0.8828056111983721, disc_loss = 0.014420215847493532
Trained batch 861 in epoch 10, gen_loss = 0.8828219431873817, disc_loss = 0.014404953724127064
Trained batch 862 in epoch 10, gen_loss = 0.8828143239159435, disc_loss = 0.014389928028311636
Trained batch 863 in epoch 10, gen_loss = 0.8829242410483183, disc_loss = 0.014374405154925355
Trained batch 864 in epoch 10, gen_loss = 0.882983026614768, disc_loss = 0.014359254689165123
Trained batch 865 in epoch 10, gen_loss = 0.8829608037895749, disc_loss = 0.014344704998925293
Trained batch 866 in epoch 10, gen_loss = 0.883079190567703, disc_loss = 0.014329068453196567
Trained batch 867 in epoch 10, gen_loss = 0.8831122908998744, disc_loss = 0.014314149736655712
Trained batch 868 in epoch 10, gen_loss = 0.8831961773618867, disc_loss = 0.014298951199290427
Trained batch 869 in epoch 10, gen_loss = 0.8832286552451123, disc_loss = 0.014283664976149642
Trained batch 870 in epoch 10, gen_loss = 0.8832807018069805, disc_loss = 0.014268303818472909
Trained batch 871 in epoch 10, gen_loss = 0.883281733874881, disc_loss = 0.014253060439416104
Trained batch 872 in epoch 10, gen_loss = 0.8834153994798387, disc_loss = 0.014238637881624867
Trained batch 873 in epoch 10, gen_loss = 0.8835411142702779, disc_loss = 0.014224599386992021
Trained batch 874 in epoch 10, gen_loss = 0.8835690174102783, disc_loss = 0.014209697735878372
Trained batch 875 in epoch 10, gen_loss = 0.8835870979447343, disc_loss = 0.014194476212460318
Trained batch 876 in epoch 10, gen_loss = 0.883696280700179, disc_loss = 0.014179703565919055
Trained batch 877 in epoch 10, gen_loss = 0.8837043767909526, disc_loss = 0.014164602752691553
Trained batch 878 in epoch 10, gen_loss = 0.8837427649481712, disc_loss = 0.014149690554799768
Trained batch 879 in epoch 10, gen_loss = 0.883756951581348, disc_loss = 0.01413571600157659
Trained batch 880 in epoch 10, gen_loss = 0.8841017878420913, disc_loss = 0.014123233120949125
Trained batch 881 in epoch 10, gen_loss = 0.8841730225113243, disc_loss = 0.014108710528425676
Trained batch 882 in epoch 10, gen_loss = 0.8841491041205073, disc_loss = 0.014093770797818341
Trained batch 883 in epoch 10, gen_loss = 0.8842919880178719, disc_loss = 0.01407931794922278
Trained batch 884 in epoch 10, gen_loss = 0.884323467103775, disc_loss = 0.014064233674451388
Trained batch 885 in epoch 10, gen_loss = 0.8842919182965772, disc_loss = 0.014050077728812954
Trained batch 886 in epoch 10, gen_loss = 0.884361658383921, disc_loss = 0.01403598631024421
Trained batch 887 in epoch 10, gen_loss = 0.8845267230728725, disc_loss = 0.01402113311651028
Trained batch 888 in epoch 10, gen_loss = 0.884625480266202, disc_loss = 0.014006512590703771
Trained batch 889 in epoch 10, gen_loss = 0.8847006804487678, disc_loss = 0.01399233922343688
Trained batch 890 in epoch 10, gen_loss = 0.8847942940982771, disc_loss = 0.013977584817903937
Trained batch 891 in epoch 10, gen_loss = 0.8848441747672889, disc_loss = 0.013963608861040932
Trained batch 892 in epoch 10, gen_loss = 0.8848642741579225, disc_loss = 0.013949246618078425
Trained batch 893 in epoch 10, gen_loss = 0.8850288559793092, disc_loss = 0.013934933510644782
Trained batch 894 in epoch 10, gen_loss = 0.8850445958489146, disc_loss = 0.01392018995103075
Trained batch 895 in epoch 10, gen_loss = 0.8850921007937619, disc_loss = 0.01390545188183166
Trained batch 896 in epoch 10, gen_loss = 0.8852695851288778, disc_loss = 0.013890728871363377
Trained batch 897 in epoch 10, gen_loss = 0.8853314613180862, disc_loss = 0.013876029609866261
Trained batch 898 in epoch 10, gen_loss = 0.885428310965537, disc_loss = 0.013861419059873198
Trained batch 899 in epoch 10, gen_loss = 0.8854364117648866, disc_loss = 0.013846916622310851
Trained batch 900 in epoch 10, gen_loss = 0.8854219365067011, disc_loss = 0.013833030662276487
Trained batch 901 in epoch 10, gen_loss = 0.8853989530957723, disc_loss = 0.013818603552391463
Trained batch 902 in epoch 10, gen_loss = 0.885342389972239, disc_loss = 0.013804810182812184
Trained batch 903 in epoch 10, gen_loss = 0.8854359861760013, disc_loss = 0.013790800584944668
Trained batch 904 in epoch 10, gen_loss = 0.8854893690973356, disc_loss = 0.013776390223030016
Trained batch 905 in epoch 10, gen_loss = 0.8856808972148179, disc_loss = 0.013762083469805123
Trained batch 906 in epoch 10, gen_loss = 0.8856775426154888, disc_loss = 0.013748177060227336
Trained batch 907 in epoch 10, gen_loss = 0.8857782613732216, disc_loss = 0.013734089626336654
Trained batch 908 in epoch 10, gen_loss = 0.8858434471360134, disc_loss = 0.013719667174670373
Trained batch 909 in epoch 10, gen_loss = 0.8860103486003457, disc_loss = 0.01370541859502267
Trained batch 910 in epoch 10, gen_loss = 0.8860152305546498, disc_loss = 0.013691611230496954
Trained batch 911 in epoch 10, gen_loss = 0.8861693543823141, disc_loss = 0.013677954505446746
Trained batch 912 in epoch 10, gen_loss = 0.8860900382483776, disc_loss = 0.013664010886471033
Trained batch 913 in epoch 10, gen_loss = 0.8861737079119526, disc_loss = 0.013649877029899952
Trained batch 914 in epoch 10, gen_loss = 0.8862849419234229, disc_loss = 0.013635556018053137
Trained batch 915 in epoch 10, gen_loss = 0.8863394497263379, disc_loss = 0.013621864102418738
Trained batch 916 in epoch 10, gen_loss = 0.8864505255235321, disc_loss = 0.013607680040988395
Trained batch 917 in epoch 10, gen_loss = 0.8866012756730995, disc_loss = 0.013593737831795644
Trained batch 918 in epoch 10, gen_loss = 0.8865958371152037, disc_loss = 0.01357980556804745
Trained batch 919 in epoch 10, gen_loss = 0.8866901410014733, disc_loss = 0.01356583817495962
Trained batch 920 in epoch 10, gen_loss = 0.8867901402498302, disc_loss = 0.013551751510643988
Trained batch 921 in epoch 10, gen_loss = 0.8867822447852303, disc_loss = 0.01353779831075616
Trained batch 922 in epoch 10, gen_loss = 0.8869074247898544, disc_loss = 0.013523802675799576
Trained batch 923 in epoch 10, gen_loss = 0.8869776530957325, disc_loss = 0.013509775220488426
Trained batch 924 in epoch 10, gen_loss = 0.8871121232574051, disc_loss = 0.013496559571610084
Trained batch 925 in epoch 10, gen_loss = 0.887213791034649, disc_loss = 0.013483256668457233
Trained batch 926 in epoch 10, gen_loss = 0.8873042011595338, disc_loss = 0.013469849645190655
Trained batch 927 in epoch 10, gen_loss = 0.8873956232363808, disc_loss = 0.013455964354275709
Trained batch 928 in epoch 10, gen_loss = 0.8874305197317454, disc_loss = 0.013442314011658204
Trained batch 929 in epoch 10, gen_loss = 0.887460712079079, disc_loss = 0.01342882146476455
Trained batch 930 in epoch 10, gen_loss = 0.887587836938565, disc_loss = 0.013415302114110919
Trained batch 931 in epoch 10, gen_loss = 0.8876566153994957, disc_loss = 0.013401567751811913
Trained batch 932 in epoch 10, gen_loss = 0.8876895074036855, disc_loss = 0.01338814672516319
Trained batch 933 in epoch 10, gen_loss = 0.8876943828845177, disc_loss = 0.01337441805507018
Trained batch 934 in epoch 10, gen_loss = 0.8876557258998646, disc_loss = 0.013361232882701135
Trained batch 935 in epoch 10, gen_loss = 0.887695804811441, disc_loss = 0.01334782085113979
Trained batch 936 in epoch 10, gen_loss = 0.8876644317597437, disc_loss = 0.013334166435168866
Trained batch 937 in epoch 10, gen_loss = 0.8875612454500788, disc_loss = 0.013320859053902808
Trained batch 938 in epoch 10, gen_loss = 0.8875058970004479, disc_loss = 0.013307431292011852
Trained batch 939 in epoch 10, gen_loss = 0.8875130675574566, disc_loss = 0.013294012789869003
Trained batch 940 in epoch 10, gen_loss = 0.8876462949956515, disc_loss = 0.013280624456566463
Trained batch 941 in epoch 10, gen_loss = 0.8878801888341357, disc_loss = 0.013267697175680349
Trained batch 942 in epoch 10, gen_loss = 0.8878509269539397, disc_loss = 0.013254807258309615
Trained batch 943 in epoch 10, gen_loss = 0.887921600586782, disc_loss = 0.013241524757778294
Trained batch 944 in epoch 10, gen_loss = 0.8880547546835803, disc_loss = 0.013228538519965864
Trained batch 945 in epoch 10, gen_loss = 0.8880421447451472, disc_loss = 0.013215288016341512
Trained batch 946 in epoch 10, gen_loss = 0.8880517521780673, disc_loss = 0.013202260673011569
Trained batch 947 in epoch 10, gen_loss = 0.8880366317707779, disc_loss = 0.013189221668630747
Trained batch 948 in epoch 10, gen_loss = 0.8881693129418898, disc_loss = 0.013176255519373674
Trained batch 949 in epoch 10, gen_loss = 0.8882306899522481, disc_loss = 0.01316365029428485
Trained batch 950 in epoch 10, gen_loss = 0.88819268712486, disc_loss = 0.013150647622099186
Trained batch 951 in epoch 10, gen_loss = 0.8882810389544783, disc_loss = 0.013138132639707555
Trained batch 952 in epoch 10, gen_loss = 0.888201236599765, disc_loss = 0.013125210109538524
Trained batch 953 in epoch 10, gen_loss = 0.8881854929139279, disc_loss = 0.013112176654589351
Trained batch 954 in epoch 10, gen_loss = 0.8882100962219438, disc_loss = 0.013098913478053722
Trained batch 955 in epoch 10, gen_loss = 0.8881586009488445, disc_loss = 0.013085859257995885
Trained batch 956 in epoch 10, gen_loss = 0.8881761520758442, disc_loss = 0.013073006111137932
Trained batch 957 in epoch 10, gen_loss = 0.888144106046143, disc_loss = 0.013060009286674891
Trained batch 958 in epoch 10, gen_loss = 0.8882231990164835, disc_loss = 0.01304728954157205
Trained batch 959 in epoch 10, gen_loss = 0.8881562101344268, disc_loss = 0.01303455179060317
Trained batch 960 in epoch 10, gen_loss = 0.8884193357642309, disc_loss = 0.013026433616553038
Trained batch 961 in epoch 10, gen_loss = 0.8885030195024058, disc_loss = 0.013013822148305827
Trained batch 962 in epoch 10, gen_loss = 0.8885001023362854, disc_loss = 0.013002425133142943
Trained batch 963 in epoch 10, gen_loss = 0.8884620833446376, disc_loss = 0.012990005458797511
Trained batch 964 in epoch 10, gen_loss = 0.8885742770575489, disc_loss = 0.012977880966222913
Trained batch 965 in epoch 10, gen_loss = 0.8885608394447074, disc_loss = 0.012965032584340612
Trained batch 966 in epoch 10, gen_loss = 0.8884873306369091, disc_loss = 0.01295369710167256
Trained batch 967 in epoch 10, gen_loss = 0.8885600073032143, disc_loss = 0.012941094189894906
Trained batch 968 in epoch 10, gen_loss = 0.8885876167915431, disc_loss = 0.012928387999811048
Trained batch 969 in epoch 10, gen_loss = 0.8886746545427854, disc_loss = 0.012915813251588729
Trained batch 970 in epoch 10, gen_loss = 0.8888473141205667, disc_loss = 0.012903115971448033
Trained batch 971 in epoch 10, gen_loss = 0.8888768756095274, disc_loss = 0.012890479647377318
Trained batch 972 in epoch 10, gen_loss = 0.8888691791772597, disc_loss = 0.012877809691529664
Trained batch 973 in epoch 10, gen_loss = 0.888961276356934, disc_loss = 0.01286514438699811
Trained batch 974 in epoch 10, gen_loss = 0.8889486408233642, disc_loss = 0.012852286327531777
Trained batch 975 in epoch 10, gen_loss = 0.8890186935418942, disc_loss = 0.012839860615787953
Trained batch 976 in epoch 10, gen_loss = 0.8890726088013351, disc_loss = 0.012827522396724246
Trained batch 977 in epoch 10, gen_loss = 0.8889635960382918, disc_loss = 0.012815987147163607
Trained batch 978 in epoch 10, gen_loss = 0.8888543604343246, disc_loss = 0.012803606100106803
Trained batch 979 in epoch 10, gen_loss = 0.8888494038460206, disc_loss = 0.012791368773320514
Trained batch 980 in epoch 10, gen_loss = 0.8889144825522202, disc_loss = 0.012779067806534875
Trained batch 981 in epoch 10, gen_loss = 0.889000928814688, disc_loss = 0.01276647169810097
Trained batch 982 in epoch 10, gen_loss = 0.8890389194929952, disc_loss = 0.012754231080017196
Trained batch 983 in epoch 10, gen_loss = 0.8889286579882226, disc_loss = 0.012743232327846908
Trained batch 984 in epoch 10, gen_loss = 0.8889699451814448, disc_loss = 0.012730670097117964
Trained batch 985 in epoch 10, gen_loss = 0.8890547484582626, disc_loss = 0.012718230281200503
Trained batch 986 in epoch 10, gen_loss = 0.8891079584636707, disc_loss = 0.012705821711138923
Trained batch 987 in epoch 10, gen_loss = 0.8889582345963489, disc_loss = 0.012694971974770495
Trained batch 988 in epoch 10, gen_loss = 0.8890707447627678, disc_loss = 0.012682981269495422
Trained batch 989 in epoch 10, gen_loss = 0.8891043436045598, disc_loss = 0.012670747325194158
Trained batch 990 in epoch 10, gen_loss = 0.8891396487035857, disc_loss = 0.012658390231815489
Trained batch 991 in epoch 10, gen_loss = 0.8891914689973477, disc_loss = 0.012646184045699498
Trained batch 992 in epoch 10, gen_loss = 0.8892194067483462, disc_loss = 0.012633944529651858
Trained batch 993 in epoch 10, gen_loss = 0.8892813595967514, disc_loss = 0.012621638078955907
Trained batch 994 in epoch 10, gen_loss = 0.8892591046328521, disc_loss = 0.012609573657698719
Trained batch 995 in epoch 10, gen_loss = 0.8892896022183828, disc_loss = 0.012597651488154572
Trained batch 996 in epoch 10, gen_loss = 0.8893611025786328, disc_loss = 0.012585717537112831
Trained batch 997 in epoch 10, gen_loss = 0.8893935771767266, disc_loss = 0.012573618753257377
Trained batch 998 in epoch 10, gen_loss = 0.8894572953084806, disc_loss = 0.012561557206109766
Trained batch 999 in epoch 10, gen_loss = 0.8895445201396942, disc_loss = 0.012549513428049977
Trained batch 1000 in epoch 10, gen_loss = 0.8896169032488431, disc_loss = 0.012537326888989198
Trained batch 1001 in epoch 10, gen_loss = 0.8896671942846028, disc_loss = 0.0125252523526096
Trained batch 1002 in epoch 10, gen_loss = 0.8897405326188146, disc_loss = 0.012513261960563668
Trained batch 1003 in epoch 10, gen_loss = 0.8897726608818746, disc_loss = 0.012501270007099182
Trained batch 1004 in epoch 10, gen_loss = 0.8898725029840991, disc_loss = 0.012489588355627582
Trained batch 1005 in epoch 10, gen_loss = 0.8899480816028701, disc_loss = 0.012477720260938234
Trained batch 1006 in epoch 10, gen_loss = 0.8899295697619448, disc_loss = 0.01246584415235619
Trained batch 1007 in epoch 10, gen_loss = 0.8899266949248692, disc_loss = 0.0124542554865998
Trained batch 1008 in epoch 10, gen_loss = 0.8899073669293709, disc_loss = 0.012442502903427704
Trained batch 1009 in epoch 10, gen_loss = 0.8898738863444564, disc_loss = 0.012430656981832546
Trained batch 1010 in epoch 10, gen_loss = 0.8898689438516143, disc_loss = 0.012418959416985318
Trained batch 1011 in epoch 10, gen_loss = 0.8897828191165397, disc_loss = 0.012407297322418097
Trained batch 1012 in epoch 10, gen_loss = 0.8898865965958997, disc_loss = 0.012395630352342615
Trained batch 1013 in epoch 10, gen_loss = 0.8898492694136189, disc_loss = 0.012383834725629636
Trained batch 1014 in epoch 10, gen_loss = 0.8898639631976047, disc_loss = 0.012372073904726439
Trained batch 1015 in epoch 10, gen_loss = 0.8898686298469859, disc_loss = 0.012360432941946555
Trained batch 1016 in epoch 10, gen_loss = 0.8899052374599723, disc_loss = 0.012348732506901995
Trained batch 1017 in epoch 10, gen_loss = 0.8899394964656567, disc_loss = 0.012336963392071512
Trained batch 1018 in epoch 10, gen_loss = 0.8899444000058834, disc_loss = 0.012325205361470923
Trained batch 1019 in epoch 10, gen_loss = 0.8899205127767488, disc_loss = 0.012313716610429657
Trained batch 1020 in epoch 10, gen_loss = 0.8898212342257598, disc_loss = 0.012302193338909218
Trained batch 1021 in epoch 10, gen_loss = 0.8898529686806487, disc_loss = 0.012290889617094269
Trained batch 1022 in epoch 10, gen_loss = 0.8898670700754705, disc_loss = 0.012279288580955575
Trained batch 1023 in epoch 10, gen_loss = 0.8897335925721563, disc_loss = 0.012268056368142766
Trained batch 1024 in epoch 10, gen_loss = 0.889728133794738, disc_loss = 0.012256452004757437
Trained batch 1025 in epoch 10, gen_loss = 0.8898228180919707, disc_loss = 0.012245334474441706
Trained batch 1026 in epoch 10, gen_loss = 0.8898351635301472, disc_loss = 0.012233800580331166
Trained batch 1027 in epoch 10, gen_loss = 0.8900777942823529, disc_loss = 0.012224485164120134
Trained batch 1028 in epoch 10, gen_loss = 0.8900737837174196, disc_loss = 0.012213600610747262
Trained batch 1029 in epoch 10, gen_loss = 0.8901116826580566, disc_loss = 0.01220256195159785
Trained batch 1030 in epoch 10, gen_loss = 0.8901793905881629, disc_loss = 0.012191129561373535
Trained batch 1031 in epoch 10, gen_loss = 0.8902808329047158, disc_loss = 0.01217984890467079
Trained batch 1032 in epoch 10, gen_loss = 0.8902573929982402, disc_loss = 0.012168385449396054
Trained batch 1033 in epoch 10, gen_loss = 0.8903778174052617, disc_loss = 0.012157052994758765
Trained batch 1034 in epoch 10, gen_loss = 0.8905254369196685, disc_loss = 0.012146155703078915
Trained batch 1035 in epoch 10, gen_loss = 0.8905682005132027, disc_loss = 0.012135100930633764
Trained batch 1036 in epoch 10, gen_loss = 0.8906057017748473, disc_loss = 0.0121240276883471
Trained batch 1037 in epoch 10, gen_loss = 0.8906227322672143, disc_loss = 0.012112758839311708
Trained batch 1038 in epoch 10, gen_loss = 0.8906868870609419, disc_loss = 0.01210155849882791
Trained batch 1039 in epoch 10, gen_loss = 0.8906178822311072, disc_loss = 0.012090766722884347
Trained batch 1040 in epoch 10, gen_loss = 0.8906692538435476, disc_loss = 0.012079588766095155
Trained batch 1041 in epoch 10, gen_loss = 0.8907909824042769, disc_loss = 0.01206853014800817
Trained batch 1042 in epoch 10, gen_loss = 0.8907195757128019, disc_loss = 0.012057539196534833
Trained batch 1043 in epoch 10, gen_loss = 0.8907545121579334, disc_loss = 0.012046372795363658
Trained batch 1044 in epoch 10, gen_loss = 0.890827211980044, disc_loss = 0.012035233121458329
Trained batch 1045 in epoch 10, gen_loss = 0.8908413848047275, disc_loss = 0.012024066004103355
Trained batch 1046 in epoch 10, gen_loss = 0.8908643711717673, disc_loss = 0.012012890264244128
Trained batch 1047 in epoch 10, gen_loss = 0.890946003146299, disc_loss = 0.012002010321471097
Trained batch 1048 in epoch 10, gen_loss = 0.8909261481209637, disc_loss = 0.01199089083824743
Trained batch 1049 in epoch 10, gen_loss = 0.8910571786335536, disc_loss = 0.011979868401942354
Trained batch 1050 in epoch 10, gen_loss = 0.8912232756954959, disc_loss = 0.011969161854267009
Trained batch 1051 in epoch 10, gen_loss = 0.8912600489057062, disc_loss = 0.011958128121920429
Trained batch 1052 in epoch 10, gen_loss = 0.8912144050299272, disc_loss = 0.01194718932058383
Trained batch 1053 in epoch 10, gen_loss = 0.8911104741766059, disc_loss = 0.011936455294508085
Trained batch 1054 in epoch 10, gen_loss = 0.8911047345089121, disc_loss = 0.011925611321020416
Trained batch 1055 in epoch 10, gen_loss = 0.8911216912057364, disc_loss = 0.011914875240894286
Trained batch 1056 in epoch 10, gen_loss = 0.8911230972947777, disc_loss = 0.011904045392599115
Trained batch 1057 in epoch 10, gen_loss = 0.891136397091788, disc_loss = 0.01189305569491266
Trained batch 1058 in epoch 10, gen_loss = 0.8911515787820753, disc_loss = 0.011882102395352562
Trained batch 1059 in epoch 10, gen_loss = 0.8912241634895217, disc_loss = 0.01187128719256231
Trained batch 1060 in epoch 10, gen_loss = 0.89131599361328, disc_loss = 0.011860419469347341
Trained batch 1061 in epoch 10, gen_loss = 0.8912766609488234, disc_loss = 0.011849601751535087
Trained batch 1062 in epoch 10, gen_loss = 0.891369066032058, disc_loss = 0.011838892371428676
Trained batch 1063 in epoch 10, gen_loss = 0.8913489568950539, disc_loss = 0.01182810295231457
Trained batch 1064 in epoch 10, gen_loss = 0.8914172794337564, disc_loss = 0.011817353261903064
Trained batch 1065 in epoch 10, gen_loss = 0.8914068087963405, disc_loss = 0.011806515367148732
Trained batch 1066 in epoch 10, gen_loss = 0.8914452491235599, disc_loss = 0.011795881917951005
Trained batch 1067 in epoch 10, gen_loss = 0.891328167547001, disc_loss = 0.011785193794266445
Trained batch 1068 in epoch 10, gen_loss = 0.8913323307728745, disc_loss = 0.011774467693493567
Trained batch 1069 in epoch 10, gen_loss = 0.8914427571764616, disc_loss = 0.011763796452027592
Trained batch 1070 in epoch 10, gen_loss = 0.8913955661206464, disc_loss = 0.01175311443051721
Trained batch 1071 in epoch 10, gen_loss = 0.8913383650690762, disc_loss = 0.011742373055122738
Trained batch 1072 in epoch 10, gen_loss = 0.8913126922275902, disc_loss = 0.011731679867485448
Trained batch 1073 in epoch 10, gen_loss = 0.891346346566131, disc_loss = 0.01172116218839106
Trained batch 1074 in epoch 10, gen_loss = 0.8912333384225535, disc_loss = 0.011710779653580555
Trained batch 1075 in epoch 10, gen_loss = 0.8912395159108045, disc_loss = 0.011700272803796588
Trained batch 1076 in epoch 10, gen_loss = 0.8911871084374416, disc_loss = 0.011689730927545081
Trained batch 1077 in epoch 10, gen_loss = 0.8912171086154754, disc_loss = 0.011679297761017749
Trained batch 1078 in epoch 10, gen_loss = 0.8911196706027649, disc_loss = 0.011669088039398099
Trained batch 1079 in epoch 10, gen_loss = 0.8911124127330603, disc_loss = 0.011658794078970526
Trained batch 1080 in epoch 10, gen_loss = 0.8911510436872329, disc_loss = 0.011648279208154482
Trained batch 1081 in epoch 10, gen_loss = 0.8911618024606581, disc_loss = 0.01163782943269305
Trained batch 1082 in epoch 10, gen_loss = 0.8912326110697188, disc_loss = 0.011627393871674139
Trained batch 1083 in epoch 10, gen_loss = 0.8912002321099003, disc_loss = 0.011617007261990334
Trained batch 1084 in epoch 10, gen_loss = 0.8912005730488334, disc_loss = 0.011606621294961556
Trained batch 1085 in epoch 10, gen_loss = 0.8913106055000649, disc_loss = 0.011596226433154177
Trained batch 1086 in epoch 10, gen_loss = 0.8913652311253131, disc_loss = 0.011585886664642536
Trained batch 1087 in epoch 10, gen_loss = 0.8913909508024945, disc_loss = 0.01157555643850869
Trained batch 1088 in epoch 10, gen_loss = 0.8914615592352286, disc_loss = 0.011565226585906994
Trained batch 1089 in epoch 10, gen_loss = 0.8915108312160597, disc_loss = 0.01155507788777676
Trained batch 1090 in epoch 10, gen_loss = 0.8914772997636734, disc_loss = 0.011544867577777123
Trained batch 1091 in epoch 10, gen_loss = 0.8914536116542396, disc_loss = 0.011534712480519934
Trained batch 1092 in epoch 10, gen_loss = 0.8914675565346162, disc_loss = 0.011524504574321633
Trained batch 1093 in epoch 10, gen_loss = 0.8914297884517439, disc_loss = 0.011514385662448527
Trained batch 1094 in epoch 10, gen_loss = 0.8913948373163127, disc_loss = 0.01150412144831522
Trained batch 1095 in epoch 10, gen_loss = 0.891313740806858, disc_loss = 0.011494014909319719
Trained batch 1096 in epoch 10, gen_loss = 0.8913381718024408, disc_loss = 0.011483877560777723
Trained batch 1097 in epoch 10, gen_loss = 0.8912477682197029, disc_loss = 0.011473719336765519
Trained batch 1098 in epoch 10, gen_loss = 0.8913306990355334, disc_loss = 0.01146362223230248
Trained batch 1099 in epoch 10, gen_loss = 0.8913147978349165, disc_loss = 0.01145353869426551
Trained batch 1100 in epoch 10, gen_loss = 0.8912936512932357, disc_loss = 0.011443436945437308
Trained batch 1101 in epoch 10, gen_loss = 0.8912911476760075, disc_loss = 0.011433441295703034
Trained batch 1102 in epoch 10, gen_loss = 0.891370455243862, disc_loss = 0.011423417395511675
Trained batch 1103 in epoch 10, gen_loss = 0.8914221665565518, disc_loss = 0.011413400902935224
Trained batch 1104 in epoch 10, gen_loss = 0.891459338697373, disc_loss = 0.01140341320247874
Trained batch 1105 in epoch 10, gen_loss = 0.891488266249893, disc_loss = 0.0113936958126248
Trained batch 1106 in epoch 10, gen_loss = 0.8914485466620248, disc_loss = 0.011383740301301801
Trained batch 1107 in epoch 10, gen_loss = 0.8914438162792461, disc_loss = 0.011373690826384836
Trained batch 1108 in epoch 10, gen_loss = 0.8913686116930598, disc_loss = 0.011363890586664222
Trained batch 1109 in epoch 10, gen_loss = 0.8913306874734861, disc_loss = 0.011354024390305124
Trained batch 1110 in epoch 10, gen_loss = 0.8913431894553877, disc_loss = 0.011344264732246454
Trained batch 1111 in epoch 10, gen_loss = 0.8914123729085751, disc_loss = 0.011334333543764325
Trained batch 1112 in epoch 10, gen_loss = 0.891443503727703, disc_loss = 0.01132460110709435
Trained batch 1113 in epoch 10, gen_loss = 0.8914623109613757, disc_loss = 0.011314742101522127
Trained batch 1114 in epoch 10, gen_loss = 0.8915774999712615, disc_loss = 0.01130499826932656
Trained batch 1115 in epoch 10, gen_loss = 0.8916990878761456, disc_loss = 0.011295351837716844
Trained batch 1116 in epoch 10, gen_loss = 0.8917207785130827, disc_loss = 0.011285565493512905
Trained batch 1117 in epoch 10, gen_loss = 0.8917399859705637, disc_loss = 0.011275735327412502
Trained batch 1118 in epoch 10, gen_loss = 0.8918026712880377, disc_loss = 0.011265902049591684
Trained batch 1119 in epoch 10, gen_loss = 0.8917326830327511, disc_loss = 0.011256125899412188
Trained batch 1120 in epoch 10, gen_loss = 0.8918060364200003, disc_loss = 0.0112465060539095
Trained batch 1121 in epoch 10, gen_loss = 0.8917267945148516, disc_loss = 0.01123688780576482
Trained batch 1122 in epoch 10, gen_loss = 0.8916528542871891, disc_loss = 0.011227253489661755
Trained batch 1123 in epoch 10, gen_loss = 0.8915939654001562, disc_loss = 0.01121771763575705
Trained batch 1124 in epoch 10, gen_loss = 0.8915235517289903, disc_loss = 0.011208218014514488
Trained batch 1125 in epoch 10, gen_loss = 0.8915481902989782, disc_loss = 0.011198799836361031
Trained batch 1126 in epoch 10, gen_loss = 0.8915605323443713, disc_loss = 0.011189144013534047
Trained batch 1127 in epoch 10, gen_loss = 0.8915489207662589, disc_loss = 0.011179645894794412
Trained batch 1128 in epoch 10, gen_loss = 0.8915580753946432, disc_loss = 0.011170105719466614
Trained batch 1129 in epoch 10, gen_loss = 0.8915767050949873, disc_loss = 0.011160718929125573
Trained batch 1130 in epoch 10, gen_loss = 0.8915857348581208, disc_loss = 0.011151195174648413
Trained batch 1131 in epoch 10, gen_loss = 0.8916358762410841, disc_loss = 0.011141638501641684
Trained batch 1132 in epoch 10, gen_loss = 0.8917037738916207, disc_loss = 0.011132008464481794
Trained batch 1133 in epoch 10, gen_loss = 0.8917596629792841, disc_loss = 0.0111225984933852
Trained batch 1134 in epoch 10, gen_loss = 0.8917369196068348, disc_loss = 0.011113128610919969
Trained batch 1135 in epoch 10, gen_loss = 0.8917827136604719, disc_loss = 0.011103620355934766
Trained batch 1136 in epoch 10, gen_loss = 0.8918233516977456, disc_loss = 0.011094092010509033
Trained batch 1137 in epoch 10, gen_loss = 0.8918910577029042, disc_loss = 0.011084658468686072
Trained batch 1138 in epoch 10, gen_loss = 0.8920021793421578, disc_loss = 0.011075356377342768
Trained batch 1139 in epoch 10, gen_loss = 0.8920334817547547, disc_loss = 0.011065990392978021
Trained batch 1140 in epoch 10, gen_loss = 0.8920233712501425, disc_loss = 0.011056597838998082
Trained batch 1141 in epoch 10, gen_loss = 0.892060849378489, disc_loss = 0.01104714371962116
Trained batch 1142 in epoch 10, gen_loss = 0.8920417188659427, disc_loss = 0.01103781865539112
Trained batch 1143 in epoch 10, gen_loss = 0.8920796207197896, disc_loss = 0.01102852083037563
Trained batch 1144 in epoch 10, gen_loss = 0.8920221191306301, disc_loss = 0.011019142591544451
Trained batch 1145 in epoch 10, gen_loss = 0.8920726204001674, disc_loss = 0.011009786664168485
Trained batch 1146 in epoch 10, gen_loss = 0.8920492300700393, disc_loss = 0.011000507577081778
Trained batch 1147 in epoch 10, gen_loss = 0.8920075518536651, disc_loss = 0.010991192792828957
Trained batch 1148 in epoch 10, gen_loss = 0.8919455746757766, disc_loss = 0.010981956879908541
Trained batch 1149 in epoch 10, gen_loss = 0.891932810700458, disc_loss = 0.010972719302327554
Trained batch 1150 in epoch 10, gen_loss = 0.8918729215782689, disc_loss = 0.010963425365381115
Trained batch 1151 in epoch 10, gen_loss = 0.8918821504339576, disc_loss = 0.010954156875578115
Trained batch 1152 in epoch 10, gen_loss = 0.8919419973494174, disc_loss = 0.010944829098426949
Trained batch 1153 in epoch 10, gen_loss = 0.891915409569104, disc_loss = 0.010935636609434586
Trained batch 1154 in epoch 10, gen_loss = 0.8918388828570708, disc_loss = 0.010926549697271649
Trained batch 1155 in epoch 10, gen_loss = 0.8917908673158567, disc_loss = 0.01091731453527818
Trained batch 1156 in epoch 10, gen_loss = 0.8919008446337338, disc_loss = 0.010908227065879354
Trained batch 1157 in epoch 10, gen_loss = 0.8919283719363402, disc_loss = 0.010899118784933097
Trained batch 1158 in epoch 10, gen_loss = 0.8919374623413843, disc_loss = 0.010890134347623216
Trained batch 1159 in epoch 10, gen_loss = 0.8919959380708892, disc_loss = 0.010881112664932954
Trained batch 1160 in epoch 10, gen_loss = 0.8919159144702192, disc_loss = 0.0108722779795503
Trained batch 1161 in epoch 10, gen_loss = 0.8918905317167817, disc_loss = 0.01086316494676008
Trained batch 1162 in epoch 10, gen_loss = 0.8919333354830229, disc_loss = 0.010854188078151165
Trained batch 1163 in epoch 10, gen_loss = 0.8919660201187396, disc_loss = 0.010845270864861534
Trained batch 1164 in epoch 10, gen_loss = 0.8920527817353671, disc_loss = 0.010836350032734952
Trained batch 1165 in epoch 10, gen_loss = 0.8920223498221737, disc_loss = 0.010827405424474093
Trained batch 1166 in epoch 10, gen_loss = 0.8921277336105896, disc_loss = 0.01081857101111625
Trained batch 1167 in epoch 10, gen_loss = 0.892140795361914, disc_loss = 0.010809983269273413
Trained batch 1168 in epoch 10, gen_loss = 0.8921862015161278, disc_loss = 0.010801136406221991
Trained batch 1169 in epoch 10, gen_loss = 0.8921037797744458, disc_loss = 0.010792358752820665
Trained batch 1170 in epoch 10, gen_loss = 0.8920880425291933, disc_loss = 0.010783723683229088
Trained batch 1171 in epoch 10, gen_loss = 0.8920210244915998, disc_loss = 0.010775044193232485
Trained batch 1172 in epoch 10, gen_loss = 0.8920444837514905, disc_loss = 0.010766383769991629
Trained batch 1173 in epoch 10, gen_loss = 0.891952164839236, disc_loss = 0.010757724104386284
Trained batch 1174 in epoch 10, gen_loss = 0.8919739339199472, disc_loss = 0.01074891122721849
Trained batch 1175 in epoch 10, gen_loss = 0.8919980880253169, disc_loss = 0.010740084313523407
Trained batch 1176 in epoch 10, gen_loss = 0.8920191595791352, disc_loss = 0.010731254205303133
Trained batch 1177 in epoch 10, gen_loss = 0.8920916546585199, disc_loss = 0.010722568934701908
Trained batch 1178 in epoch 10, gen_loss = 0.8920649341145646, disc_loss = 0.010713835215189892
Trained batch 1179 in epoch 10, gen_loss = 0.8920467828795061, disc_loss = 0.010705175437255155
Trained batch 1180 in epoch 10, gen_loss = 0.8921182786984326, disc_loss = 0.010696455087802734
Trained batch 1181 in epoch 10, gen_loss = 0.8920136975556259, disc_loss = 0.010688234488640333
Trained batch 1182 in epoch 10, gen_loss = 0.8921477960915457, disc_loss = 0.010679869236583393
Trained batch 1183 in epoch 10, gen_loss = 0.892104846752576, disc_loss = 0.01067127283462272
Trained batch 1184 in epoch 10, gen_loss = 0.8921181402628935, disc_loss = 0.010662565462464144
Trained batch 1185 in epoch 10, gen_loss = 0.8921694093671255, disc_loss = 0.010653879671975182
Trained batch 1186 in epoch 10, gen_loss = 0.8921130263413716, disc_loss = 0.010645220353711975
Trained batch 1187 in epoch 10, gen_loss = 0.8920600360090082, disc_loss = 0.01063660893295084
Trained batch 1188 in epoch 10, gen_loss = 0.8920841031559783, disc_loss = 0.010627998466798495
Trained batch 1189 in epoch 10, gen_loss = 0.892151415348053, disc_loss = 0.010619540824339638
Trained batch 1190 in epoch 10, gen_loss = 0.892080354250148, disc_loss = 0.01061109538234248
Trained batch 1191 in epoch 10, gen_loss = 0.8921037548340407, disc_loss = 0.010602654759528353
Trained batch 1192 in epoch 10, gen_loss = 0.8920943474230003, disc_loss = 0.01059413568808776
Trained batch 1193 in epoch 10, gen_loss = 0.8921730497873808, disc_loss = 0.010585713157858513
Trained batch 1194 in epoch 10, gen_loss = 0.8921236486614499, disc_loss = 0.010577093879740965
Trained batch 1195 in epoch 10, gen_loss = 0.8922240160480391, disc_loss = 0.010568603114703869
Trained batch 1196 in epoch 10, gen_loss = 0.89222503599766, disc_loss = 0.010560054734341276
Trained batch 1197 in epoch 10, gen_loss = 0.8922793080094262, disc_loss = 0.010551547015995177
Trained batch 1198 in epoch 10, gen_loss = 0.8922426509698099, disc_loss = 0.010543114830340936
Trained batch 1199 in epoch 10, gen_loss = 0.8923012101650238, disc_loss = 0.01053472006552814
Trained batch 1200 in epoch 10, gen_loss = 0.8922426927397392, disc_loss = 0.010526276932229411
Trained batch 1201 in epoch 10, gen_loss = 0.8922151543336383, disc_loss = 0.010517788015668413
Trained batch 1202 in epoch 10, gen_loss = 0.8922319857160548, disc_loss = 0.010509402867808593
Trained batch 1203 in epoch 10, gen_loss = 0.8923524644881784, disc_loss = 0.010501276193701227
Trained batch 1204 in epoch 10, gen_loss = 0.8924244409774844, disc_loss = 0.010492986832050745
Trained batch 1205 in epoch 10, gen_loss = 0.8924118518631652, disc_loss = 0.010484560089306304
Trained batch 1206 in epoch 10, gen_loss = 0.8925669762153909, disc_loss = 0.010476339077376379
Trained batch 1207 in epoch 10, gen_loss = 0.892575807918776, disc_loss = 0.01046803931750755
Trained batch 1208 in epoch 10, gen_loss = 0.8927569435685996, disc_loss = 0.010461417455984954
Trained batch 1209 in epoch 10, gen_loss = 0.8928039968506364, disc_loss = 0.010453831949675347
Trained batch 1210 in epoch 10, gen_loss = 0.8928975442733575, disc_loss = 0.010445844006365508
Trained batch 1211 in epoch 10, gen_loss = 0.8929398590975469, disc_loss = 0.010438399461713517
Trained batch 1212 in epoch 10, gen_loss = 0.8930096518177684, disc_loss = 0.010430426545038448
Trained batch 1213 in epoch 10, gen_loss = 0.893030115367946, disc_loss = 0.010422269407173779
Trained batch 1214 in epoch 10, gen_loss = 0.893055721222128, disc_loss = 0.010414160551635526
Trained batch 1215 in epoch 10, gen_loss = 0.8931256567471122, disc_loss = 0.010405948074118274
Trained batch 1216 in epoch 10, gen_loss = 0.8931710010389863, disc_loss = 0.010397736677033682
Trained batch 1217 in epoch 10, gen_loss = 0.893145581918397, disc_loss = 0.010389625713466598
Trained batch 1218 in epoch 10, gen_loss = 0.8931790472935026, disc_loss = 0.010381393996392048
Trained batch 1219 in epoch 10, gen_loss = 0.8932170479024043, disc_loss = 0.010373878198843755
Trained batch 1220 in epoch 10, gen_loss = 0.8932248255349299, disc_loss = 0.010367394770883834
Trained batch 1221 in epoch 10, gen_loss = 0.8931180638689457, disc_loss = 0.01036143853499077
Trained batch 1222 in epoch 10, gen_loss = 0.8931928922773285, disc_loss = 0.010354006689617551
Trained batch 1223 in epoch 10, gen_loss = 0.8932297501006937, disc_loss = 0.010348016719160346
Trained batch 1224 in epoch 10, gen_loss = 0.8932293129453853, disc_loss = 0.010342885297628081
Trained batch 1225 in epoch 10, gen_loss = 0.8931988126690975, disc_loss = 0.010335913578999422
Trained batch 1226 in epoch 10, gen_loss = 0.8931666971613161, disc_loss = 0.010328594459897816
Trained batch 1227 in epoch 10, gen_loss = 0.8932238088659821, disc_loss = 0.010321120477845764
Trained batch 1228 in epoch 10, gen_loss = 0.8931402613517228, disc_loss = 0.01031333380575808
Trained batch 1229 in epoch 10, gen_loss = 0.8931369204831318, disc_loss = 0.010305618123497768
Trained batch 1230 in epoch 10, gen_loss = 0.893176632185083, disc_loss = 0.01029789721407715
Trained batch 1231 in epoch 10, gen_loss = 0.8931619097756875, disc_loss = 0.010290072823456238
Trained batch 1232 in epoch 10, gen_loss = 0.8931241956843851, disc_loss = 0.010282353870655634
Trained batch 1233 in epoch 10, gen_loss = 0.8931999642226839, disc_loss = 0.010274870422994416
Trained batch 1234 in epoch 10, gen_loss = 0.8931035335247334, disc_loss = 0.010267676322142167
Trained batch 1235 in epoch 10, gen_loss = 0.8931988545220261, disc_loss = 0.010261823615301506
Trained batch 1236 in epoch 10, gen_loss = 0.8932871190212192, disc_loss = 0.010257549798061504
Trained batch 1237 in epoch 10, gen_loss = 0.8933019134455236, disc_loss = 0.010250681732385908
Trained batch 1238 in epoch 10, gen_loss = 0.8933699158914057, disc_loss = 0.010243603840962285
Trained batch 1239 in epoch 10, gen_loss = 0.8933025980668683, disc_loss = 0.010235885227795675
Trained batch 1240 in epoch 10, gen_loss = 0.8933710790179988, disc_loss = 0.010228103535513617
Trained batch 1241 in epoch 10, gen_loss = 0.8935129604573795, disc_loss = 0.010220505747895
Trained batch 1242 in epoch 10, gen_loss = 0.8935759298665238, disc_loss = 0.0102127266292234
Trained batch 1243 in epoch 10, gen_loss = 0.8935872447164879, disc_loss = 0.01020503705089509
Trained batch 1244 in epoch 10, gen_loss = 0.8936043760862695, disc_loss = 0.010197095708111788
Trained batch 1245 in epoch 10, gen_loss = 0.893635726520376, disc_loss = 0.010189155527260857
Trained batch 1246 in epoch 10, gen_loss = 0.8935990755617284, disc_loss = 0.010181256420831938
Trained batch 1247 in epoch 10, gen_loss = 0.8936454456012982, disc_loss = 0.010173518391802179
Trained batch 1248 in epoch 10, gen_loss = 0.8937130896829433, disc_loss = 0.010165695323926837
Trained batch 1249 in epoch 10, gen_loss = 0.8937680095672608, disc_loss = 0.010157827308471314
Trained batch 1250 in epoch 10, gen_loss = 0.893784641552505, disc_loss = 0.010150142890887132
Trained batch 1251 in epoch 10, gen_loss = 0.8939264249116087, disc_loss = 0.010142583784102589
Trained batch 1252 in epoch 10, gen_loss = 0.8939750895724712, disc_loss = 0.010134816058085049
Trained batch 1253 in epoch 10, gen_loss = 0.8938457778100952, disc_loss = 0.010127420953841266
Trained batch 1254 in epoch 10, gen_loss = 0.893834546220255, disc_loss = 0.010120052606515786
Trained batch 1255 in epoch 10, gen_loss = 0.8937779833461829, disc_loss = 0.010112320373788926
Trained batch 1256 in epoch 10, gen_loss = 0.8937898815958483, disc_loss = 0.010104781647475641
Trained batch 1257 in epoch 10, gen_loss = 0.8938594220268329, disc_loss = 0.010097126073524355
Trained batch 1258 in epoch 10, gen_loss = 0.8938866901530265, disc_loss = 0.010089352037113144
Trained batch 1259 in epoch 10, gen_loss = 0.8938761634959115, disc_loss = 0.010081583302443116
Trained batch 1260 in epoch 10, gen_loss = 0.8939043627099136, disc_loss = 0.010073758009715009
Trained batch 1261 in epoch 10, gen_loss = 0.8939578346612903, disc_loss = 0.010065999763287904
Trained batch 1262 in epoch 10, gen_loss = 0.8939575733217283, disc_loss = 0.0100582416625098
Trained batch 1263 in epoch 10, gen_loss = 0.8938594682590116, disc_loss = 0.010050609542856906
Trained batch 1264 in epoch 10, gen_loss = 0.8938935156867438, disc_loss = 0.010042962897131809
Trained batch 1265 in epoch 10, gen_loss = 0.893780645977641, disc_loss = 0.010035475129159543
Trained batch 1266 in epoch 10, gen_loss = 0.8938127617809654, disc_loss = 0.010027829087539646
Trained batch 1267 in epoch 10, gen_loss = 0.8937416526985469, disc_loss = 0.010020229578835667
Trained batch 1268 in epoch 10, gen_loss = 0.893778662732307, disc_loss = 0.010012654954371416
Trained batch 1269 in epoch 10, gen_loss = 0.893889793401628, disc_loss = 0.010005047897428758
Trained batch 1270 in epoch 10, gen_loss = 0.8939862317404909, disc_loss = 0.009997557162084265
Trained batch 1271 in epoch 10, gen_loss = 0.8940998253488691, disc_loss = 0.009989972470112038
Trained batch 1272 in epoch 10, gen_loss = 0.8939937660755928, disc_loss = 0.009982561058049674
Trained batch 1273 in epoch 10, gen_loss = 0.8940208674974307, disc_loss = 0.009974999792040128
Trained batch 1274 in epoch 10, gen_loss = 0.8940274900548598, disc_loss = 0.009967394452701853
Trained batch 1275 in epoch 10, gen_loss = 0.8939905130190535, disc_loss = 0.009959752143354835
Trained batch 1276 in epoch 10, gen_loss = 0.894012483471338, disc_loss = 0.009952238082498116
Trained batch 1277 in epoch 10, gen_loss = 0.8940224337372609, disc_loss = 0.009944691976783025
Trained batch 1278 in epoch 10, gen_loss = 0.8940349995763718, disc_loss = 0.00993712617747833
Trained batch 1279 in epoch 10, gen_loss = 0.8939282545819879, disc_loss = 0.00992960571995809
Trained batch 1280 in epoch 10, gen_loss = 0.8939819448539561, disc_loss = 0.009922058395192588
Trained batch 1281 in epoch 10, gen_loss = 0.8939776203933633, disc_loss = 0.009914511962343907
Trained batch 1282 in epoch 10, gen_loss = 0.8940337310985764, disc_loss = 0.009906941918721652
Trained batch 1283 in epoch 10, gen_loss = 0.8938683397673373, disc_loss = 0.009900292939207
Trained batch 1284 in epoch 10, gen_loss = 0.8938502078854157, disc_loss = 0.009893148732274239
Trained batch 1285 in epoch 10, gen_loss = 0.8938467253237082, disc_loss = 0.009885692274376542
Trained batch 1286 in epoch 10, gen_loss = 0.8939046544813795, disc_loss = 0.00987832939485676
Trained batch 1287 in epoch 10, gen_loss = 0.893943297751942, disc_loss = 0.009870884014637104
Trained batch 1288 in epoch 10, gen_loss = 0.8938851626553769, disc_loss = 0.009863531674320096
Trained batch 1289 in epoch 10, gen_loss = 0.8938879824886027, disc_loss = 0.009856196903736897
Trained batch 1290 in epoch 10, gen_loss = 0.8938290582988541, disc_loss = 0.009848799195423658
Trained batch 1291 in epoch 10, gen_loss = 0.8939528534932771, disc_loss = 0.00984156122151609
Trained batch 1292 in epoch 10, gen_loss = 0.8940427806242804, disc_loss = 0.009834371798284901
Trained batch 1293 in epoch 10, gen_loss = 0.8940035836681884, disc_loss = 0.009827143950157075
Trained batch 1294 in epoch 10, gen_loss = 0.8940259760871357, disc_loss = 0.009819749053884531
Trained batch 1295 in epoch 10, gen_loss = 0.8939853357036173, disc_loss = 0.009812536385124762
Trained batch 1296 in epoch 10, gen_loss = 0.8939910361926742, disc_loss = 0.009805327773192641
Trained batch 1297 in epoch 10, gen_loss = 0.8940436372587971, disc_loss = 0.009797960503814934
Trained batch 1298 in epoch 10, gen_loss = 0.8940714672035763, disc_loss = 0.009790587322772559
Trained batch 1299 in epoch 10, gen_loss = 0.8939559222184694, disc_loss = 0.009783500879208217
Trained batch 1300 in epoch 10, gen_loss = 0.8938799506421277, disc_loss = 0.00977631443286224
Trained batch 1301 in epoch 10, gen_loss = 0.8937713287301511, disc_loss = 0.009768997345542369
Trained batch 1302 in epoch 10, gen_loss = 0.893758223638659, disc_loss = 0.009761762350689278
Trained batch 1303 in epoch 10, gen_loss = 0.893775852682766, disc_loss = 0.009754476285243797
Trained batch 1304 in epoch 10, gen_loss = 0.8938153574749884, disc_loss = 0.009747278767624974
Trained batch 1305 in epoch 10, gen_loss = 0.8938260856120182, disc_loss = 0.009740084246645384
Trained batch 1306 in epoch 10, gen_loss = 0.8937695241649368, disc_loss = 0.009732878902753265
Trained batch 1307 in epoch 10, gen_loss = 0.8937488905515875, disc_loss = 0.009725661557301717
Trained batch 1308 in epoch 10, gen_loss = 0.8938101122541405, disc_loss = 0.009718445191735517
Trained batch 1309 in epoch 10, gen_loss = 0.8937318254973142, disc_loss = 0.009711959928095088
Trained batch 1310 in epoch 10, gen_loss = 0.8936532993156614, disc_loss = 0.009705350577530152
Trained batch 1311 in epoch 10, gen_loss = 0.8936217141042395, disc_loss = 0.009698511481263534
Trained batch 1312 in epoch 10, gen_loss = 0.8936079065035248, disc_loss = 0.00969146026646364
Trained batch 1313 in epoch 10, gen_loss = 0.8935886516690799, disc_loss = 0.00968445770276501
Trained batch 1314 in epoch 10, gen_loss = 0.8936311846903522, disc_loss = 0.009677468372401321
Trained batch 1315 in epoch 10, gen_loss = 0.8936788082394557, disc_loss = 0.009670267588359259
Trained batch 1316 in epoch 10, gen_loss = 0.8936696129942266, disc_loss = 0.009663139682653574
Trained batch 1317 in epoch 10, gen_loss = 0.8936147457822502, disc_loss = 0.009656019062819139
Trained batch 1318 in epoch 10, gen_loss = 0.8936187798458125, disc_loss = 0.009648872900672484
Trained batch 1319 in epoch 10, gen_loss = 0.8935707558736656, disc_loss = 0.009641765057180732
Trained batch 1320 in epoch 10, gen_loss = 0.8935651897842644, disc_loss = 0.009634676811611034
Trained batch 1321 in epoch 10, gen_loss = 0.8935328577271748, disc_loss = 0.009627664756556796
Trained batch 1322 in epoch 10, gen_loss = 0.8935846024089389, disc_loss = 0.0096206834997073
Trained batch 1323 in epoch 10, gen_loss = 0.8935876555763342, disc_loss = 0.009613759102715001
Trained batch 1324 in epoch 10, gen_loss = 0.8936058315241112, disc_loss = 0.009606835637834661
Trained batch 1325 in epoch 10, gen_loss = 0.8935920519706531, disc_loss = 0.009599781331809365
Trained batch 1326 in epoch 10, gen_loss = 0.8935397912796584, disc_loss = 0.009592749677583036
Trained batch 1327 in epoch 10, gen_loss = 0.8936059686792902, disc_loss = 0.009585831596246775
Trained batch 1328 in epoch 10, gen_loss = 0.893605256995552, disc_loss = 0.009578838289566086
Trained batch 1329 in epoch 10, gen_loss = 0.89354366050627, disc_loss = 0.009571823057293177
Trained batch 1330 in epoch 10, gen_loss = 0.8935491800935174, disc_loss = 0.009564823294025205
Trained batch 1331 in epoch 10, gen_loss = 0.8935885978890611, disc_loss = 0.009557864134666277
Trained batch 1332 in epoch 10, gen_loss = 0.8935963597319132, disc_loss = 0.00955136711129308
Trained batch 1333 in epoch 10, gen_loss = 0.8935770609121452, disc_loss = 0.009545528244037276
Trained batch 1334 in epoch 10, gen_loss = 0.8935683820578043, disc_loss = 0.009538979755064006
Trained batch 1335 in epoch 10, gen_loss = 0.8934938062183158, disc_loss = 0.009532176640223152
Trained batch 1336 in epoch 10, gen_loss = 0.8935182797614549, disc_loss = 0.00952541578515616
Trained batch 1337 in epoch 10, gen_loss = 0.8934148273393178, disc_loss = 0.00951870255775559
Trained batch 1338 in epoch 10, gen_loss = 0.8934377721657586, disc_loss = 0.009511923898455546
Trained batch 1339 in epoch 10, gen_loss = 0.8933766387291808, disc_loss = 0.009505103723777619
Trained batch 1340 in epoch 10, gen_loss = 0.8933748595310982, disc_loss = 0.009498312200699488
Trained batch 1341 in epoch 10, gen_loss = 0.8933825329412469, disc_loss = 0.009491415491778558
Trained batch 1342 in epoch 10, gen_loss = 0.8933452826689537, disc_loss = 0.00948449966526498
Trained batch 1343 in epoch 10, gen_loss = 0.8932919958162875, disc_loss = 0.009477622148259408
Trained batch 1344 in epoch 10, gen_loss = 0.8932786396001795, disc_loss = 0.009470760792424144
Trained batch 1345 in epoch 10, gen_loss = 0.8932960052015523, disc_loss = 0.009463955877365818
Trained batch 1346 in epoch 10, gen_loss = 0.8932744940298968, disc_loss = 0.009457113963608255
Trained batch 1347 in epoch 10, gen_loss = 0.8932947848511733, disc_loss = 0.00945028725795654
Trained batch 1348 in epoch 10, gen_loss = 0.8933124192738374, disc_loss = 0.009443489680506564
Trained batch 1349 in epoch 10, gen_loss = 0.8934250987459113, disc_loss = 0.009436748214788234
Trained batch 1350 in epoch 10, gen_loss = 0.8934231935210972, disc_loss = 0.009429892657045826
Trained batch 1351 in epoch 10, gen_loss = 0.8933765754632695, disc_loss = 0.009423173663190728
Trained batch 1352 in epoch 10, gen_loss = 0.8933656284391484, disc_loss = 0.00941640605418843
Trained batch 1353 in epoch 10, gen_loss = 0.8933558451284158, disc_loss = 0.009409626742674536
Trained batch 1354 in epoch 10, gen_loss = 0.893369170968383, disc_loss = 0.009402918142863254
Trained batch 1355 in epoch 10, gen_loss = 0.8933825890662748, disc_loss = 0.009396172660524607
Trained batch 1356 in epoch 10, gen_loss = 0.8934945580093142, disc_loss = 0.009389568391408653
Trained batch 1357 in epoch 10, gen_loss = 0.893443485510718, disc_loss = 0.009382822328943307
Trained batch 1358 in epoch 10, gen_loss = 0.8934880741560082, disc_loss = 0.009376225586322437
Trained batch 1359 in epoch 10, gen_loss = 0.8934554950279348, disc_loss = 0.009369520171832632
Trained batch 1360 in epoch 10, gen_loss = 0.8934440031198786, disc_loss = 0.009362854697347843
Trained batch 1361 in epoch 10, gen_loss = 0.8934747783710603, disc_loss = 0.00935623190670574
Trained batch 1362 in epoch 10, gen_loss = 0.8934407152415896, disc_loss = 0.00934954459614292
Trained batch 1363 in epoch 10, gen_loss = 0.8934341818094254, disc_loss = 0.009342878227258003
Trained batch 1364 in epoch 10, gen_loss = 0.8933754184307197, disc_loss = 0.009336218758696868
Trained batch 1365 in epoch 10, gen_loss = 0.8933518880195533, disc_loss = 0.009329563993284797
Trained batch 1366 in epoch 10, gen_loss = 0.8932891008447537, disc_loss = 0.009322880600476379
Trained batch 1367 in epoch 10, gen_loss = 0.8931247384140366, disc_loss = 0.009317476922011838
Trained batch 1368 in epoch 10, gen_loss = 0.8931202587635523, disc_loss = 0.00931128768358428
Trained batch 1369 in epoch 10, gen_loss = 0.8930770157462489, disc_loss = 0.009304804701262909
Trained batch 1370 in epoch 10, gen_loss = 0.8930898833935665, disc_loss = 0.009298326756964308
Trained batch 1371 in epoch 10, gen_loss = 0.8930614526348281, disc_loss = 0.009292080885760043
Trained batch 1372 in epoch 10, gen_loss = 0.8930420595542063, disc_loss = 0.009285789834451946
Trained batch 1373 in epoch 10, gen_loss = 0.893032084949846, disc_loss = 0.009279458421336526
Trained batch 1374 in epoch 10, gen_loss = 0.892959196914326, disc_loss = 0.009273114803310653
Trained batch 1375 in epoch 10, gen_loss = 0.8929341164699127, disc_loss = 0.009266679703106875
Trained batch 1376 in epoch 10, gen_loss = 0.8929280433519733, disc_loss = 0.00926030593692662
Trained batch 1377 in epoch 10, gen_loss = 0.8929992069872785, disc_loss = 0.00925426854234049
Trained batch 1378 in epoch 10, gen_loss = 0.8929857731816386, disc_loss = 0.009248160900322024
Trained batch 1379 in epoch 10, gen_loss = 0.8930710686721663, disc_loss = 0.009241965638732611
Trained batch 1380 in epoch 10, gen_loss = 0.8930709028399396, disc_loss = 0.009235530984631802
Trained batch 1381 in epoch 10, gen_loss = 0.8931577224203543, disc_loss = 0.009229258559389827
Trained batch 1382 in epoch 10, gen_loss = 0.8932567666340633, disc_loss = 0.009223133991113833
Trained batch 1383 in epoch 10, gen_loss = 0.893258496989749, disc_loss = 0.009216976503274979
Trained batch 1384 in epoch 10, gen_loss = 0.893302079959897, disc_loss = 0.009210732252637953
Trained batch 1385 in epoch 10, gen_loss = 0.893341829078366, disc_loss = 0.009204517977006806
Trained batch 1386 in epoch 10, gen_loss = 0.8932732339376327, disc_loss = 0.009198609456813087
Trained batch 1387 in epoch 10, gen_loss = 0.8933108525420472, disc_loss = 0.009192352215412224
Trained batch 1388 in epoch 10, gen_loss = 0.8932979250657979, disc_loss = 0.009186122042508802
Trained batch 1389 in epoch 10, gen_loss = 0.8932506461366475, disc_loss = 0.009180186945306834
Trained batch 1390 in epoch 10, gen_loss = 0.8932508455601466, disc_loss = 0.009174141266579405
Trained batch 1391 in epoch 10, gen_loss = 0.8932684602579851, disc_loss = 0.009167822749641973
Trained batch 1392 in epoch 10, gen_loss = 0.8933226624924933, disc_loss = 0.009162092759273611
Trained batch 1393 in epoch 10, gen_loss = 0.8932986657964961, disc_loss = 0.00915622435563773
Trained batch 1394 in epoch 10, gen_loss = 0.8932517682779647, disc_loss = 0.009150419257185672
Trained batch 1395 in epoch 10, gen_loss = 0.8932948587275508, disc_loss = 0.009144524685956102
Trained batch 1396 in epoch 10, gen_loss = 0.8932549831008775, disc_loss = 0.009138472475252816
Trained batch 1397 in epoch 10, gen_loss = 0.8933115119756718, disc_loss = 0.009132614906819655
Trained batch 1398 in epoch 10, gen_loss = 0.8933028455629274, disc_loss = 0.009126578814679926
Trained batch 1399 in epoch 10, gen_loss = 0.8933303406834603, disc_loss = 0.009120435569077797
Trained batch 1400 in epoch 10, gen_loss = 0.8933701740257405, disc_loss = 0.009114250492808614
Trained batch 1401 in epoch 10, gen_loss = 0.8933893989309265, disc_loss = 0.009108266855903753
Trained batch 1402 in epoch 10, gen_loss = 0.8934657168830197, disc_loss = 0.009102447531226703
Trained batch 1403 in epoch 10, gen_loss = 0.893387580019796, disc_loss = 0.009096495767225654
Trained batch 1404 in epoch 10, gen_loss = 0.8933032340002229, disc_loss = 0.009090314890250558
Trained batch 1405 in epoch 10, gen_loss = 0.8933496282755227, disc_loss = 0.009084246485393228
Trained batch 1406 in epoch 10, gen_loss = 0.8932804092076457, disc_loss = 0.009078193969233424
Trained batch 1407 in epoch 10, gen_loss = 0.8932690540836616, disc_loss = 0.00907214940564865
Trained batch 1408 in epoch 10, gen_loss = 0.8932938407379486, disc_loss = 0.009066162261902206
Trained batch 1409 in epoch 10, gen_loss = 0.8932947563364151, disc_loss = 0.009060083896541763
Trained batch 1410 in epoch 10, gen_loss = 0.8933481214571979, disc_loss = 0.009054209893412754
Trained batch 1411 in epoch 10, gen_loss = 0.8933701152166631, disc_loss = 0.009048356799086095
Trained batch 1412 in epoch 10, gen_loss = 0.8934306800154532, disc_loss = 0.009042322021586589
Trained batch 1413 in epoch 10, gen_loss = 0.8935034095482239, disc_loss = 0.00903630157578371
Trained batch 1414 in epoch 10, gen_loss = 0.8935541951614218, disc_loss = 0.009030785434982203
Trained batch 1415 in epoch 10, gen_loss = 0.8935016004715935, disc_loss = 0.009025223378824908
Trained batch 1416 in epoch 10, gen_loss = 0.893429060847135, disc_loss = 0.009019420900331658
Trained batch 1417 in epoch 10, gen_loss = 0.8934162236403342, disc_loss = 0.009013692934197579
Trained batch 1418 in epoch 10, gen_loss = 0.8935289671926787, disc_loss = 0.009008209499284537
Trained batch 1419 in epoch 10, gen_loss = 0.8934502598265527, disc_loss = 0.009002786582605553
Trained batch 1420 in epoch 10, gen_loss = 0.8934324288519229, disc_loss = 0.008997117959428742
Trained batch 1421 in epoch 10, gen_loss = 0.893462468509768, disc_loss = 0.008992852321373195
Trained batch 1422 in epoch 10, gen_loss = 0.8934350669258343, disc_loss = 0.008987246191164922
Trained batch 1423 in epoch 10, gen_loss = 0.8934391731542818, disc_loss = 0.008981372743670526
Trained batch 1424 in epoch 10, gen_loss = 0.8934859399209942, disc_loss = 0.008975534742399887
Trained batch 1425 in epoch 10, gen_loss = 0.8935677337696643, disc_loss = 0.008969698924496006
Trained batch 1426 in epoch 10, gen_loss = 0.8935638073448042, disc_loss = 0.00896382429824242
Trained batch 1427 in epoch 10, gen_loss = 0.8935960317943611, disc_loss = 0.008958259359433698
Trained batch 1428 in epoch 10, gen_loss = 0.8935977284352707, disc_loss = 0.008952853358897332
Trained batch 1429 in epoch 10, gen_loss = 0.8936581700415044, disc_loss = 0.008947094693398135
Trained batch 1430 in epoch 10, gen_loss = 0.8937026011952147, disc_loss = 0.008941297297320244
Trained batch 1431 in epoch 10, gen_loss = 0.8937908331525393, disc_loss = 0.008935462570377377
Trained batch 1432 in epoch 10, gen_loss = 0.8937673928516359, disc_loss = 0.008929607569770848
Trained batch 1433 in epoch 10, gen_loss = 0.8937899984076432, disc_loss = 0.008923887844713608
Trained batch 1434 in epoch 10, gen_loss = 0.8937526208183076, disc_loss = 0.00891810633233612
Trained batch 1435 in epoch 10, gen_loss = 0.8937864244233267, disc_loss = 0.008912872216769807
Trained batch 1436 in epoch 10, gen_loss = 0.8938277980977658, disc_loss = 0.008907428064098239
Trained batch 1437 in epoch 10, gen_loss = 0.8937971024503296, disc_loss = 0.008902104733840004
Trained batch 1438 in epoch 10, gen_loss = 0.8937726901835084, disc_loss = 0.008896488873326058
Trained batch 1439 in epoch 10, gen_loss = 0.8938447479986482, disc_loss = 0.008891032009523769
Trained batch 1440 in epoch 10, gen_loss = 0.8938517722299246, disc_loss = 0.008885722231932758
Trained batch 1441 in epoch 10, gen_loss = 0.8938509969456682, disc_loss = 0.008880053761885205
Trained batch 1442 in epoch 10, gen_loss = 0.8937983424070388, disc_loss = 0.008874512701999617
Trained batch 1443 in epoch 10, gen_loss = 0.8937672707677878, disc_loss = 0.008868974603625006
Trained batch 1444 in epoch 10, gen_loss = 0.8937211021007551, disc_loss = 0.008863517474387144
Trained batch 1445 in epoch 10, gen_loss = 0.8937779417671109, disc_loss = 0.008858135432530004
Trained batch 1446 in epoch 10, gen_loss = 0.893822633116181, disc_loss = 0.00885250659982684
Trained batch 1447 in epoch 10, gen_loss = 0.8937987434929906, disc_loss = 0.008847024031366944
Trained batch 1448 in epoch 10, gen_loss = 0.8938245800464544, disc_loss = 0.008841339260966564
Trained batch 1449 in epoch 10, gen_loss = 0.8938629803986385, disc_loss = 0.00883572793933001
Trained batch 1450 in epoch 10, gen_loss = 0.8938057226694345, disc_loss = 0.00883148802069419
Trained batch 1451 in epoch 10, gen_loss = 0.8938033419042908, disc_loss = 0.00882614120635696
Trained batch 1452 in epoch 10, gen_loss = 0.893785169472468, disc_loss = 0.00882103428109908
Trained batch 1453 in epoch 10, gen_loss = 0.8937826348466099, disc_loss = 0.00881591354767959
Trained batch 1454 in epoch 10, gen_loss = 0.8937377237372383, disc_loss = 0.008812242535345379
Trained batch 1455 in epoch 10, gen_loss = 0.893795539103039, disc_loss = 0.008809573883999102
Trained batch 1456 in epoch 10, gen_loss = 0.8935946341074732, disc_loss = 0.00887639823346271
Trained batch 1457 in epoch 10, gen_loss = 0.8936800637444678, disc_loss = 0.008990307513138807
Trained batch 1458 in epoch 10, gen_loss = 0.8938320035637037, disc_loss = 0.008998297924309747
Trained batch 1459 in epoch 10, gen_loss = 0.8938791050486369, disc_loss = 0.008995341238057822
Trained batch 1460 in epoch 10, gen_loss = 0.8939273726197646, disc_loss = 0.008991829392513449
Trained batch 1461 in epoch 10, gen_loss = 0.8940123878979976, disc_loss = 0.008991769013066251
Trained batch 1462 in epoch 10, gen_loss = 0.8940848521964646, disc_loss = 0.008987651025504478
Trained batch 1463 in epoch 10, gen_loss = 0.8941485436399126, disc_loss = 0.008985006937860031
Trained batch 1464 in epoch 10, gen_loss = 0.8942189384645977, disc_loss = 0.008980624029892036
Trained batch 1465 in epoch 10, gen_loss = 0.89421462589852, disc_loss = 0.00897629668743246
Trained batch 1466 in epoch 10, gen_loss = 0.8942413640493589, disc_loss = 0.008971655428254515
Trained batch 1467 in epoch 10, gen_loss = 0.8941302992586219, disc_loss = 0.008981617353376787
Trained batch 1468 in epoch 10, gen_loss = 0.8941592348522682, disc_loss = 0.008980999597920602
Trained batch 1469 in epoch 10, gen_loss = 0.89423999522819, disc_loss = 0.00897712874387432
Trained batch 1470 in epoch 10, gen_loss = 0.894292219288085, disc_loss = 0.008977407962997886
Trained batch 1471 in epoch 10, gen_loss = 0.8944148565844997, disc_loss = 0.008975132469636857
Trained batch 1472 in epoch 10, gen_loss = 0.8944778942932341, disc_loss = 0.008973130827844086
Trained batch 1473 in epoch 10, gen_loss = 0.8944354936015493, disc_loss = 0.008969799380617885
Trained batch 1474 in epoch 10, gen_loss = 0.8945297146247605, disc_loss = 0.00896461646836172
Trained batch 1475 in epoch 10, gen_loss = 0.8944973746531701, disc_loss = 0.008959622207588452
Trained batch 1476 in epoch 10, gen_loss = 0.8945014850868918, disc_loss = 0.008954455607507496
Trained batch 1477 in epoch 10, gen_loss = 0.8945761362093227, disc_loss = 0.008948909763880207
Trained batch 1478 in epoch 10, gen_loss = 0.8946574446395735, disc_loss = 0.008943644927269442
Trained batch 1479 in epoch 10, gen_loss = 0.8945601164891913, disc_loss = 0.008939206435418266
Trained batch 1480 in epoch 10, gen_loss = 0.8946152314151323, disc_loss = 0.008934974346494939
Trained batch 1481 in epoch 10, gen_loss = 0.8946824083846269, disc_loss = 0.008929645692774562
Trained batch 1482 in epoch 10, gen_loss = 0.8947546418180999, disc_loss = 0.008924145727751673
Trained batch 1483 in epoch 10, gen_loss = 0.8948377475664622, disc_loss = 0.00891906058340383
Trained batch 1484 in epoch 10, gen_loss = 0.8947973325597718, disc_loss = 0.00891382351456138
Trained batch 1485 in epoch 10, gen_loss = 0.8948248005089817, disc_loss = 0.008908269014913798
Trained batch 1486 in epoch 10, gen_loss = 0.894901453326353, disc_loss = 0.008903006158474608
Trained batch 1487 in epoch 10, gen_loss = 0.8949827033906214, disc_loss = 0.00889747318008934
Trained batch 1488 in epoch 10, gen_loss = 0.8950971953015426, disc_loss = 0.008892312440660778
Trained batch 1489 in epoch 10, gen_loss = 0.8950646708475664, disc_loss = 0.008886949452645796
Trained batch 1490 in epoch 10, gen_loss = 0.8950575899949895, disc_loss = 0.008881484870707534
Trained batch 1491 in epoch 10, gen_loss = 0.8950579309431541, disc_loss = 0.008875969820371086
Trained batch 1492 in epoch 10, gen_loss = 0.8951869326314907, disc_loss = 0.008870667727915657
Trained batch 1493 in epoch 10, gen_loss = 0.8951376491441944, disc_loss = 0.008865212509669632
Trained batch 1494 in epoch 10, gen_loss = 0.8951474155869372, disc_loss = 0.00886001282441274
Trained batch 1495 in epoch 10, gen_loss = 0.8952193750656224, disc_loss = 0.008854915218110748
Trained batch 1496 in epoch 10, gen_loss = 0.8952147224463856, disc_loss = 0.00884996909809855
Trained batch 1497 in epoch 10, gen_loss = 0.895228190399776, disc_loss = 0.008844428968300157
Trained batch 1498 in epoch 10, gen_loss = 0.8951647303118715, disc_loss = 0.008839361454669126
Trained batch 1499 in epoch 10, gen_loss = 0.8952652651468913, disc_loss = 0.008834080439429575
Trained batch 1500 in epoch 10, gen_loss = 0.8953084360353951, disc_loss = 0.008828787432027531
Trained batch 1501 in epoch 10, gen_loss = 0.8952981781229357, disc_loss = 0.008823346844152733
Trained batch 1502 in epoch 10, gen_loss = 0.8953158312135748, disc_loss = 0.008818186940403013
Trained batch 1503 in epoch 10, gen_loss = 0.8952653635134722, disc_loss = 0.008812699366647761
Trained batch 1504 in epoch 10, gen_loss = 0.8952813693059243, disc_loss = 0.008807105394146031
Trained batch 1505 in epoch 10, gen_loss = 0.8953058425569598, disc_loss = 0.008801544273044429
Trained batch 1506 in epoch 10, gen_loss = 0.8953663461557982, disc_loss = 0.008796065187613326
Trained batch 1507 in epoch 10, gen_loss = 0.8954422715409048, disc_loss = 0.008790562719954159
Trained batch 1508 in epoch 10, gen_loss = 0.8955059073238361, disc_loss = 0.008785019029808867
Trained batch 1509 in epoch 10, gen_loss = 0.8954550816918051, disc_loss = 0.008780074991295052
Trained batch 1510 in epoch 10, gen_loss = 0.895534138463334, disc_loss = 0.008774759859984776
Trained batch 1511 in epoch 10, gen_loss = 0.8956035938133639, disc_loss = 0.008769427843583765
Trained batch 1512 in epoch 10, gen_loss = 0.8955009306257163, disc_loss = 0.008764209824624076
Trained batch 1513 in epoch 10, gen_loss = 0.8955379182391626, disc_loss = 0.008758721793714948
Trained batch 1514 in epoch 10, gen_loss = 0.8956799568122763, disc_loss = 0.00875351061768255
Trained batch 1515 in epoch 10, gen_loss = 0.8956964483833565, disc_loss = 0.008748266702898905
Trained batch 1516 in epoch 10, gen_loss = 0.8957429340031875, disc_loss = 0.008742750882041095
Trained batch 1517 in epoch 10, gen_loss = 0.8956942192336473, disc_loss = 0.008737279554293398
Trained batch 1518 in epoch 10, gen_loss = 0.8957721873127057, disc_loss = 0.008732099758327458
Trained batch 1519 in epoch 10, gen_loss = 0.8958196557666126, disc_loss = 0.008726642145407632
Trained batch 1520 in epoch 10, gen_loss = 0.8957984852681107, disc_loss = 0.00872133501736021
Trained batch 1521 in epoch 10, gen_loss = 0.8958121049811429, disc_loss = 0.008715858930124045
Trained batch 1522 in epoch 10, gen_loss = 0.8957823847988602, disc_loss = 0.00871053581441418
Trained batch 1523 in epoch 10, gen_loss = 0.8957128443821208, disc_loss = 0.008705090221301457
Trained batch 1524 in epoch 10, gen_loss = 0.8957749268266021, disc_loss = 0.008699671763136647
Trained batch 1525 in epoch 10, gen_loss = 0.8958389304802896, disc_loss = 0.008694190535230378
Trained batch 1526 in epoch 10, gen_loss = 0.89586876944615, disc_loss = 0.008688851654694702
Trained batch 1527 in epoch 10, gen_loss = 0.8958813949483228, disc_loss = 0.008683450862294318
Trained batch 1528 in epoch 10, gen_loss = 0.8958449497809201, disc_loss = 0.008677996467635861
Trained batch 1529 in epoch 10, gen_loss = 0.8958253299099168, disc_loss = 0.008672600367895534
Trained batch 1530 in epoch 10, gen_loss = 0.895917916243408, disc_loss = 0.008667275023447888
Trained batch 1531 in epoch 10, gen_loss = 0.8959263518413738, disc_loss = 0.008661889063109135
Trained batch 1532 in epoch 10, gen_loss = 0.896000606323175, disc_loss = 0.008656641781181723
Trained batch 1533 in epoch 10, gen_loss = 0.8960103274868241, disc_loss = 0.008651328659682435
Trained batch 1534 in epoch 10, gen_loss = 0.8961553932789482, disc_loss = 0.00864626785627633
Trained batch 1535 in epoch 10, gen_loss = 0.8961623803867648, disc_loss = 0.008641213734316958
Trained batch 1536 in epoch 10, gen_loss = 0.8961230874759621, disc_loss = 0.008636051219138642
Trained batch 1537 in epoch 10, gen_loss = 0.8961471623810122, disc_loss = 0.008630796217235314
Trained batch 1538 in epoch 10, gen_loss = 0.8962056279724646, disc_loss = 0.008625455441729022
Trained batch 1539 in epoch 10, gen_loss = 0.8962799713983164, disc_loss = 0.008620121831685916
Trained batch 1540 in epoch 10, gen_loss = 0.8962496495107642, disc_loss = 0.008614810153161762
Trained batch 1541 in epoch 10, gen_loss = 0.896253194790406, disc_loss = 0.008609486448654939
Trained batch 1542 in epoch 10, gen_loss = 0.8963026945960266, disc_loss = 0.008604299874195549
Trained batch 1543 in epoch 10, gen_loss = 0.896329851039333, disc_loss = 0.008599164460399948
Trained batch 1544 in epoch 10, gen_loss = 0.8963816454881217, disc_loss = 0.00859402849140779
Trained batch 1545 in epoch 10, gen_loss = 0.8964551096977268, disc_loss = 0.008588834954419668
Trained batch 1546 in epoch 10, gen_loss = 0.8964247589891159, disc_loss = 0.008583679248331417
Trained batch 1547 in epoch 10, gen_loss = 0.8964106115952942, disc_loss = 0.008578696085156053
Trained batch 1548 in epoch 10, gen_loss = 0.8964609246318612, disc_loss = 0.008573477582853008
Trained batch 1549 in epoch 10, gen_loss = 0.8964202887012113, disc_loss = 0.008568396816901382
Trained batch 1550 in epoch 10, gen_loss = 0.896369843848823, disc_loss = 0.008563198254135667
Trained batch 1551 in epoch 10, gen_loss = 0.8964219896372446, disc_loss = 0.008558085656031179
Trained batch 1552 in epoch 10, gen_loss = 0.8964078633614839, disc_loss = 0.008552931862927047
Trained batch 1553 in epoch 10, gen_loss = 0.8963949129541562, disc_loss = 0.008547774882222426
Trained batch 1554 in epoch 10, gen_loss = 0.896378331015731, disc_loss = 0.00854264109929233
Trained batch 1555 in epoch 10, gen_loss = 0.8963925681031455, disc_loss = 0.008537451063462648
Trained batch 1556 in epoch 10, gen_loss = 0.8964723499830365, disc_loss = 0.00853275200556192
Trained batch 1557 in epoch 10, gen_loss = 0.8964520650359877, disc_loss = 0.008527835205706035
Trained batch 1558 in epoch 10, gen_loss = 0.8964868264369585, disc_loss = 0.008523175530592631
Trained batch 1559 in epoch 10, gen_loss = 0.8965038355726462, disc_loss = 0.008518032006208952
Trained batch 1560 in epoch 10, gen_loss = 0.8966017247086377, disc_loss = 0.008513027004690865
Trained batch 1561 in epoch 10, gen_loss = 0.8965932046863395, disc_loss = 0.00850866962405054
Trained batch 1562 in epoch 10, gen_loss = 0.8965100311195705, disc_loss = 0.008514131159157869
Trained batch 1563 in epoch 10, gen_loss = 0.8966352112991426, disc_loss = 0.008513838044599072
Trained batch 1564 in epoch 10, gen_loss = 0.8967550105180222, disc_loss = 0.008510690704679873
Trained batch 1565 in epoch 10, gen_loss = 0.8968911942470423, disc_loss = 0.008506429310860398
Trained batch 1566 in epoch 10, gen_loss = 0.8969591500352885, disc_loss = 0.008508630957471976
Trained batch 1567 in epoch 10, gen_loss = 0.8970579875595107, disc_loss = 0.008513814678178964
Trained batch 1568 in epoch 10, gen_loss = 0.8970673547344196, disc_loss = 0.008512201437296571
Trained batch 1569 in epoch 10, gen_loss = 0.8971600479001453, disc_loss = 0.008508374622191011
Trained batch 1570 in epoch 10, gen_loss = 0.8972908686028401, disc_loss = 0.008504021403616571
Trained batch 1571 in epoch 10, gen_loss = 0.8974352950282376, disc_loss = 0.008499670419647979
Trained batch 1572 in epoch 10, gen_loss = 0.8975706256201369, disc_loss = 0.00849524996854283
Trained batch 1573 in epoch 10, gen_loss = 0.8976699342948812, disc_loss = 0.008490825543324185
Trained batch 1574 in epoch 10, gen_loss = 0.8976795930332607, disc_loss = 0.008485866824852391
Trained batch 1575 in epoch 10, gen_loss = 0.8977021967169597, disc_loss = 0.008480918286784864
Trained batch 1576 in epoch 10, gen_loss = 0.8977076905999821, disc_loss = 0.008475835530099753
Trained batch 1577 in epoch 10, gen_loss = 0.8976852095701244, disc_loss = 0.00847111048325318
Trained batch 1578 in epoch 10, gen_loss = 0.897746679449172, disc_loss = 0.008466597621481302
Trained batch 1579 in epoch 10, gen_loss = 0.8978355457511129, disc_loss = 0.008461599055931114
Trained batch 1580 in epoch 10, gen_loss = 0.8979048021679661, disc_loss = 0.008456741984236153
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.9136411547660828, disc_loss = 0.0006247480632737279
Trained batch 1 in epoch 11, gen_loss = 0.9353291094303131, disc_loss = 0.0005177808634471148
Trained batch 2 in epoch 11, gen_loss = 0.9348488450050354, disc_loss = 0.0005182304885238409
Trained batch 3 in epoch 11, gen_loss = 0.9465918242931366, disc_loss = 0.0004682716462411918
Trained batch 4 in epoch 11, gen_loss = 0.9567548990249634, disc_loss = 0.00044939726358279587
Trained batch 5 in epoch 11, gen_loss = 0.9619774123032888, disc_loss = 0.0004622441580674301
Trained batch 6 in epoch 11, gen_loss = 0.9673181687082563, disc_loss = 0.0004857482937430697
Trained batch 7 in epoch 11, gen_loss = 0.9714905098080635, disc_loss = 0.0005122222428326495
Trained batch 8 in epoch 11, gen_loss = 0.9729406237602234, disc_loss = 0.0005050651929599957
Trained batch 9 in epoch 11, gen_loss = 0.9664639174938202, disc_loss = 0.0005152263125637546
Trained batch 10 in epoch 11, gen_loss = 0.975342560898174, disc_loss = 0.0005386730110992423
Trained batch 11 in epoch 11, gen_loss = 0.9891546020905176, disc_loss = 0.0005589141971237647
Trained batch 12 in epoch 11, gen_loss = 0.9840057446406438, disc_loss = 0.0005716305749956518
Trained batch 13 in epoch 11, gen_loss = 0.9866638013294765, disc_loss = 0.0005776298452734149
Trained batch 14 in epoch 11, gen_loss = 0.9818280895551046, disc_loss = 0.000563196917452539
Trained batch 15 in epoch 11, gen_loss = 0.9795504957437515, disc_loss = 0.0005544774594454793
Trained batch 16 in epoch 11, gen_loss = 0.981279730796814, disc_loss = 0.0005412706163684454
Trained batch 17 in epoch 11, gen_loss = 0.9793311357498169, disc_loss = 0.000532940510311164
Trained batch 18 in epoch 11, gen_loss = 0.97923323355223, disc_loss = 0.0005268124652119647
Trained batch 19 in epoch 11, gen_loss = 0.9771453410387039, disc_loss = 0.0005179678060812876
Trained batch 20 in epoch 11, gen_loss = 0.9789734539531526, disc_loss = 0.0005037395257247789
Trained batch 21 in epoch 11, gen_loss = 0.9772546860304746, disc_loss = 0.000490237887954043
Trained batch 22 in epoch 11, gen_loss = 0.9726198885751807, disc_loss = 0.0004836146842495984
Trained batch 23 in epoch 11, gen_loss = 0.9696647450327873, disc_loss = 0.00047582459410477895
Trained batch 24 in epoch 11, gen_loss = 0.971551821231842, disc_loss = 0.0004720997408730909
Trained batch 25 in epoch 11, gen_loss = 0.972535653756215, disc_loss = 0.00046173531770294247
Trained batch 26 in epoch 11, gen_loss = 0.9686131455280163, disc_loss = 0.0004662280558410135
Trained batch 27 in epoch 11, gen_loss = 0.9663186435188565, disc_loss = 0.00046606288950507794
Trained batch 28 in epoch 11, gen_loss = 0.9640412330627441, disc_loss = 0.0004633279574497057
Trained batch 29 in epoch 11, gen_loss = 0.9670047918955486, disc_loss = 0.0004588557712850161
Trained batch 30 in epoch 11, gen_loss = 0.9652271847571096, disc_loss = 0.000452887786518512
Trained batch 31 in epoch 11, gen_loss = 0.9632029663771391, disc_loss = 0.0004474596148611454
Trained batch 32 in epoch 11, gen_loss = 0.965981561126131, disc_loss = 0.0004484518250330549
Trained batch 33 in epoch 11, gen_loss = 0.9633078767972834, disc_loss = 0.0004489782573621008
Trained batch 34 in epoch 11, gen_loss = 0.9659387162753514, disc_loss = 0.0004519183500503589
Trained batch 35 in epoch 11, gen_loss = 0.9666300581561195, disc_loss = 0.00044990354985606647
Trained batch 36 in epoch 11, gen_loss = 0.9650758182680285, disc_loss = 0.00044488712690607016
Trained batch 37 in epoch 11, gen_loss = 0.9622931166699058, disc_loss = 0.00044978860463934804
Trained batch 38 in epoch 11, gen_loss = 0.9598407470262967, disc_loss = 0.0004652448350008434
Trained batch 39 in epoch 11, gen_loss = 0.9577798053622246, disc_loss = 0.00046449419496639164
Trained batch 40 in epoch 11, gen_loss = 0.9569089688905855, disc_loss = 0.00046537054323579933
Trained batch 41 in epoch 11, gen_loss = 0.9576406322774433, disc_loss = 0.0004605987775167229
Trained batch 42 in epoch 11, gen_loss = 0.9559871374174606, disc_loss = 0.00046477836271109017
Trained batch 43 in epoch 11, gen_loss = 0.9574078050526705, disc_loss = 0.00046216084295090036
Trained batch 44 in epoch 11, gen_loss = 0.9554098884264628, disc_loss = 0.000456508893532575
Trained batch 45 in epoch 11, gen_loss = 0.9560682164586108, disc_loss = 0.00045367209183851906
Trained batch 46 in epoch 11, gen_loss = 0.9551624985451393, disc_loss = 0.0004507616224842384
Trained batch 47 in epoch 11, gen_loss = 0.955564501384894, disc_loss = 0.0004463374001109817
Trained batch 48 in epoch 11, gen_loss = 0.9564275705084508, disc_loss = 0.0004448905041944996
Trained batch 49 in epoch 11, gen_loss = 0.956017142534256, disc_loss = 0.00044113379379268736
Trained batch 50 in epoch 11, gen_loss = 0.9551414566881516, disc_loss = 0.00043636840806963545
Trained batch 51 in epoch 11, gen_loss = 0.9563817943517978, disc_loss = 0.00043650335842707695
Trained batch 52 in epoch 11, gen_loss = 0.955803060306693, disc_loss = 0.0004332420852184647
Trained batch 53 in epoch 11, gen_loss = 0.953157263773459, disc_loss = 0.00043329165782779455
Trained batch 54 in epoch 11, gen_loss = 0.955273920839483, disc_loss = 0.0004493911665948954
Trained batch 55 in epoch 11, gen_loss = 0.9554999619722366, disc_loss = 0.0004498754393093155
Trained batch 56 in epoch 11, gen_loss = 0.9545884979398627, disc_loss = 0.00045438045370310807
Trained batch 57 in epoch 11, gen_loss = 0.9545865171942217, disc_loss = 0.00045299297098295185
Trained batch 58 in epoch 11, gen_loss = 0.9535910083075702, disc_loss = 0.00045146301814939007
Trained batch 59 in epoch 11, gen_loss = 0.9542103419701259, disc_loss = 0.0004526147376357888
Trained batch 60 in epoch 11, gen_loss = 0.9536407834193745, disc_loss = 0.00045380929817033353
Trained batch 61 in epoch 11, gen_loss = 0.9529774842723724, disc_loss = 0.0004582206386276671
Trained batch 62 in epoch 11, gen_loss = 0.9537740813361274, disc_loss = 0.0004597659110062061
Trained batch 63 in epoch 11, gen_loss = 0.9537266390398145, disc_loss = 0.0004578502530421247
Trained batch 64 in epoch 11, gen_loss = 0.9528330692878136, disc_loss = 0.0004567227586029241
Trained batch 65 in epoch 11, gen_loss = 0.952794791171045, disc_loss = 0.0004561540100081457
Trained batch 66 in epoch 11, gen_loss = 0.9538972155371709, disc_loss = 0.00045432329417637257
Trained batch 67 in epoch 11, gen_loss = 0.9526534790501875, disc_loss = 0.0004554908981149578
Trained batch 68 in epoch 11, gen_loss = 0.9537731210390726, disc_loss = 0.00045489339728205317
Trained batch 69 in epoch 11, gen_loss = 0.9527045624596732, disc_loss = 0.00045309311826713383
Trained batch 70 in epoch 11, gen_loss = 0.9535884941127938, disc_loss = 0.00044976356853304665
Trained batch 71 in epoch 11, gen_loss = 0.951634986533059, disc_loss = 0.00045133019840351254
Trained batch 72 in epoch 11, gen_loss = 0.9506214759121202, disc_loss = 0.00044977484643299846
Trained batch 73 in epoch 11, gen_loss = 0.950490536721977, disc_loss = 0.0004461630103194054
Trained batch 74 in epoch 11, gen_loss = 0.9494858924547831, disc_loss = 0.0004498252080520615
Trained batch 75 in epoch 11, gen_loss = 0.9484131759718845, disc_loss = 0.0004487543209458971
Trained batch 76 in epoch 11, gen_loss = 0.9492098216886644, disc_loss = 0.000447629892921934
Trained batch 77 in epoch 11, gen_loss = 0.9485820967417496, disc_loss = 0.00044532313003377896
Trained batch 78 in epoch 11, gen_loss = 0.9476953080937832, disc_loss = 0.0004439433398170255
Trained batch 79 in epoch 11, gen_loss = 0.946840813010931, disc_loss = 0.0004435350701896823
Trained batch 80 in epoch 11, gen_loss = 0.944830232196384, disc_loss = 0.00044151216498892294
Trained batch 81 in epoch 11, gen_loss = 0.9430279848052234, disc_loss = 0.00043930069535612923
Trained batch 82 in epoch 11, gen_loss = 0.9435284180813525, disc_loss = 0.0004370642094157569
Trained batch 83 in epoch 11, gen_loss = 0.9424907763799032, disc_loss = 0.00043416614633835185
Trained batch 84 in epoch 11, gen_loss = 0.9422066898906932, disc_loss = 0.00043100668220123387
Trained batch 85 in epoch 11, gen_loss = 0.942967273468195, disc_loss = 0.0004294093351047703
Trained batch 86 in epoch 11, gen_loss = 0.943527131245054, disc_loss = 0.00042699033363679444
Trained batch 87 in epoch 11, gen_loss = 0.9447037225419824, disc_loss = 0.00042498700978202663
Trained batch 88 in epoch 11, gen_loss = 0.9449698148148783, disc_loss = 0.0004221580687483898
Trained batch 89 in epoch 11, gen_loss = 0.9448649843533834, disc_loss = 0.00041980587670372593
Trained batch 90 in epoch 11, gen_loss = 0.9438997795293619, disc_loss = 0.0004171360878000077
Trained batch 91 in epoch 11, gen_loss = 0.944839455511259, disc_loss = 0.0004157454040187472
Trained batch 92 in epoch 11, gen_loss = 0.945839169204876, disc_loss = 0.00041769691370552786
Trained batch 93 in epoch 11, gen_loss = 0.9452142170135011, disc_loss = 0.0004155702899492524
Trained batch 94 in epoch 11, gen_loss = 0.9446793549939205, disc_loss = 0.0004149429996399895
Trained batch 95 in epoch 11, gen_loss = 0.9451544228941202, disc_loss = 0.0004154068398444603
Trained batch 96 in epoch 11, gen_loss = 0.9448751770343977, disc_loss = 0.00041343359418871055
Trained batch 97 in epoch 11, gen_loss = 0.9456261134877497, disc_loss = 0.00041238711544013185
Trained batch 98 in epoch 11, gen_loss = 0.9459606270597438, disc_loss = 0.0004097993901314571
Trained batch 99 in epoch 11, gen_loss = 0.9448985332250595, disc_loss = 0.0004113546057487838
Trained batch 100 in epoch 11, gen_loss = 0.9445202917155653, disc_loss = 0.0004105401685862516
Trained batch 101 in epoch 11, gen_loss = 0.9449119147132424, disc_loss = 0.0004085602135198903
Trained batch 102 in epoch 11, gen_loss = 0.9437120574191936, disc_loss = 0.0004068258879943615
Trained batch 103 in epoch 11, gen_loss = 0.9430302060567416, disc_loss = 0.00040451468381574017
Trained batch 104 in epoch 11, gen_loss = 0.9432226725987025, disc_loss = 0.0004028449626362306
Trained batch 105 in epoch 11, gen_loss = 0.9427776415393038, disc_loss = 0.00040130278387739553
Trained batch 106 in epoch 11, gen_loss = 0.9418788836381146, disc_loss = 0.0003992982464951298
Trained batch 107 in epoch 11, gen_loss = 0.9422509195627989, disc_loss = 0.0003974210253714032
Trained batch 108 in epoch 11, gen_loss = 0.9419695423283708, disc_loss = 0.00039617469616516263
Trained batch 109 in epoch 11, gen_loss = 0.9416238313371484, disc_loss = 0.00039395109223815697
Trained batch 110 in epoch 11, gen_loss = 0.9411029037054595, disc_loss = 0.0003924297289723564
Trained batch 111 in epoch 11, gen_loss = 0.9410386293062142, disc_loss = 0.0003904681963311824
Trained batch 112 in epoch 11, gen_loss = 0.9397264012193258, disc_loss = 0.00039067616945326296
Trained batch 113 in epoch 11, gen_loss = 0.940408894890233, disc_loss = 0.0003894282656307169
Trained batch 114 in epoch 11, gen_loss = 0.939785677453746, disc_loss = 0.000390160060614226
Trained batch 115 in epoch 11, gen_loss = 0.9401868263195301, disc_loss = 0.00039024972509901876
Trained batch 116 in epoch 11, gen_loss = 0.94161050238161, disc_loss = 0.00039156070329810085
Trained batch 117 in epoch 11, gen_loss = 0.9410953572240927, disc_loss = 0.0003914642388196425
Trained batch 118 in epoch 11, gen_loss = 0.9406089942996242, disc_loss = 0.00039001821296704353
Trained batch 119 in epoch 11, gen_loss = 0.9406487102309863, disc_loss = 0.00038802659813275874
Trained batch 120 in epoch 11, gen_loss = 0.9399836299833187, disc_loss = 0.0003868603779672653
Trained batch 121 in epoch 11, gen_loss = 0.9401363349351727, disc_loss = 0.00038613255238771193
Trained batch 122 in epoch 11, gen_loss = 0.9398753415278303, disc_loss = 0.00038509179716854076
Trained batch 123 in epoch 11, gen_loss = 0.940195189849023, disc_loss = 0.0003837144656919859
Trained batch 124 in epoch 11, gen_loss = 0.9392316164970398, disc_loss = 0.0003829354179324582
Trained batch 125 in epoch 11, gen_loss = 0.9398964941501617, disc_loss = 0.0003824442952348378
Trained batch 126 in epoch 11, gen_loss = 0.940182748272663, disc_loss = 0.00038112394131745733
Trained batch 127 in epoch 11, gen_loss = 0.9398746439255774, disc_loss = 0.0003798243253640976
Trained batch 128 in epoch 11, gen_loss = 0.9400178827056589, disc_loss = 0.0003793612332354018
Trained batch 129 in epoch 11, gen_loss = 0.9403823756254637, disc_loss = 0.000377579168707598
Trained batch 130 in epoch 11, gen_loss = 0.9400251434959528, disc_loss = 0.00037681022296812497
Trained batch 131 in epoch 11, gen_loss = 0.9395623748952692, disc_loss = 0.00037524512718488097
Trained batch 132 in epoch 11, gen_loss = 0.9387639895417637, disc_loss = 0.00037342833273665965
Trained batch 133 in epoch 11, gen_loss = 0.938976006276572, disc_loss = 0.00037193227849931996
Trained batch 134 in epoch 11, gen_loss = 0.9386651833852132, disc_loss = 0.00037195644895459903
Trained batch 135 in epoch 11, gen_loss = 0.9384239727959913, disc_loss = 0.00037089723991812207
Trained batch 136 in epoch 11, gen_loss = 0.939059636018572, disc_loss = 0.0003708181609603556
Trained batch 137 in epoch 11, gen_loss = 0.93945781433064, disc_loss = 0.0003699610297453414
Trained batch 138 in epoch 11, gen_loss = 0.9395607246769418, disc_loss = 0.0003695410777640482
Trained batch 139 in epoch 11, gen_loss = 0.9400724317346301, disc_loss = 0.000367968526448489
Trained batch 140 in epoch 11, gen_loss = 0.9394480852370567, disc_loss = 0.0003672549605298563
Trained batch 141 in epoch 11, gen_loss = 0.9385760023560322, disc_loss = 0.0003679337980788083
Trained batch 142 in epoch 11, gen_loss = 0.9390530302808001, disc_loss = 0.00036921585456979416
Trained batch 143 in epoch 11, gen_loss = 0.9394083304537667, disc_loss = 0.00036781235758098774
Trained batch 144 in epoch 11, gen_loss = 0.9394589563895916, disc_loss = 0.0003671773289860194
Trained batch 145 in epoch 11, gen_loss = 0.9401055019195765, disc_loss = 0.00036641877851838065
Trained batch 146 in epoch 11, gen_loss = 0.9392303808205793, disc_loss = 0.0003670988844780467
Trained batch 147 in epoch 11, gen_loss = 0.9387894582909506, disc_loss = 0.00036587818180418546
Trained batch 148 in epoch 11, gen_loss = 0.938751364314316, disc_loss = 0.0003644461128641945
Trained batch 149 in epoch 11, gen_loss = 0.9386326547463735, disc_loss = 0.00036299075756687674
Trained batch 150 in epoch 11, gen_loss = 0.939268288628155, disc_loss = 0.000362175078202958
Trained batch 151 in epoch 11, gen_loss = 0.9384799964333835, disc_loss = 0.0003618752704680542
Trained batch 152 in epoch 11, gen_loss = 0.93839570782543, disc_loss = 0.00036136111047870657
Trained batch 153 in epoch 11, gen_loss = 0.9385510145069716, disc_loss = 0.0003599057710342496
Trained batch 154 in epoch 11, gen_loss = 0.9392833313634319, disc_loss = 0.00035965811149517616
Trained batch 155 in epoch 11, gen_loss = 0.9393740483583548, disc_loss = 0.0003589480624307329
Trained batch 156 in epoch 11, gen_loss = 0.9404468555359324, disc_loss = 0.000358082479289377
Trained batch 157 in epoch 11, gen_loss = 0.9408631630336182, disc_loss = 0.0003570576002777118
Trained batch 158 in epoch 11, gen_loss = 0.9396329379681522, disc_loss = 0.00035669419781960923
Trained batch 159 in epoch 11, gen_loss = 0.9394226737320424, disc_loss = 0.00035554360765672756
Trained batch 160 in epoch 11, gen_loss = 0.939881235916422, disc_loss = 0.00035493125034906896
Trained batch 161 in epoch 11, gen_loss = 0.9392230617411342, disc_loss = 0.00035413644433935623
Trained batch 162 in epoch 11, gen_loss = 0.9402913890001964, disc_loss = 0.0003538294340001042
Trained batch 163 in epoch 11, gen_loss = 0.9401236350943403, disc_loss = 0.0003528126431863312
Trained batch 164 in epoch 11, gen_loss = 0.9394438458211494, disc_loss = 0.0003526350741705039
Trained batch 165 in epoch 11, gen_loss = 0.9393489271043295, disc_loss = 0.0003515313089655499
Trained batch 166 in epoch 11, gen_loss = 0.9393831734171885, disc_loss = 0.00035020987327910493
Trained batch 167 in epoch 11, gen_loss = 0.9388295585910479, disc_loss = 0.0003493758705146666
Trained batch 168 in epoch 11, gen_loss = 0.9385901957573975, disc_loss = 0.0003486188305452323
Trained batch 169 in epoch 11, gen_loss = 0.9385514932520249, disc_loss = 0.00034809394111267895
Trained batch 170 in epoch 11, gen_loss = 0.9384021563836705, disc_loss = 0.0003474706973491117
Trained batch 171 in epoch 11, gen_loss = 0.9380204327577768, disc_loss = 0.00034706297463894456
Trained batch 172 in epoch 11, gen_loss = 0.9383536408402328, disc_loss = 0.000346123602919582
Trained batch 173 in epoch 11, gen_loss = 0.9379401272055746, disc_loss = 0.0003448705082383253
Trained batch 174 in epoch 11, gen_loss = 0.9375081174714225, disc_loss = 0.0003434996006295218
Trained batch 175 in epoch 11, gen_loss = 0.9374109171330929, disc_loss = 0.000342621471190796
Trained batch 176 in epoch 11, gen_loss = 0.9368493977913075, disc_loss = 0.00034122270342695267
Trained batch 177 in epoch 11, gen_loss = 0.9373412925875588, disc_loss = 0.0003409333598784961
Trained batch 178 in epoch 11, gen_loss = 0.9363751374809436, disc_loss = 0.00033980080463264043
Trained batch 179 in epoch 11, gen_loss = 0.9360988063944711, disc_loss = 0.00033904351104057344
Trained batch 180 in epoch 11, gen_loss = 0.9360975099531985, disc_loss = 0.0003386864967104588
Trained batch 181 in epoch 11, gen_loss = 0.9358794322380652, disc_loss = 0.00033767499461556416
Trained batch 182 in epoch 11, gen_loss = 0.9360468241034962, disc_loss = 0.00033668135716662556
Trained batch 183 in epoch 11, gen_loss = 0.934977599784084, disc_loss = 0.00033669841369650703
Trained batch 184 in epoch 11, gen_loss = 0.9348967394313297, disc_loss = 0.00033599379636831833
Trained batch 185 in epoch 11, gen_loss = 0.9351051965708373, disc_loss = 0.00033502782272051027
Trained batch 186 in epoch 11, gen_loss = 0.9349811689101438, disc_loss = 0.0003349031041949654
Trained batch 187 in epoch 11, gen_loss = 0.9347963092174936, disc_loss = 0.0003339757832362282
Trained batch 188 in epoch 11, gen_loss = 0.934955011599909, disc_loss = 0.0003331350767415229
Trained batch 189 in epoch 11, gen_loss = 0.9349509477615356, disc_loss = 0.00033237397189000864
Trained batch 190 in epoch 11, gen_loss = 0.9347907932016862, disc_loss = 0.00033155366843438304
Trained batch 191 in epoch 11, gen_loss = 0.9350204706812898, disc_loss = 0.0003304635753238472
Trained batch 192 in epoch 11, gen_loss = 0.9345456068379892, disc_loss = 0.00033008402729632543
Trained batch 193 in epoch 11, gen_loss = 0.9349729077717692, disc_loss = 0.00033008113644324654
Trained batch 194 in epoch 11, gen_loss = 0.93541568395419, disc_loss = 0.00032949811560310755
Trained batch 195 in epoch 11, gen_loss = 0.9353531523018467, disc_loss = 0.0003284920569837725
Trained batch 196 in epoch 11, gen_loss = 0.9354497306237971, disc_loss = 0.00032784142199789084
Trained batch 197 in epoch 11, gen_loss = 0.9350118953170199, disc_loss = 0.00032736311958146734
Trained batch 198 in epoch 11, gen_loss = 0.9349031708947378, disc_loss = 0.00032622393070171404
Trained batch 199 in epoch 11, gen_loss = 0.934170881807804, disc_loss = 0.00032558516028075246
Trained batch 200 in epoch 11, gen_loss = 0.9348701378006247, disc_loss = 0.0003249846692113044
Trained batch 201 in epoch 11, gen_loss = 0.9340300905232383, disc_loss = 0.0003245561939446915
Trained batch 202 in epoch 11, gen_loss = 0.9340027004039934, disc_loss = 0.00032424096721585775
Trained batch 203 in epoch 11, gen_loss = 0.9337326004809025, disc_loss = 0.0003235258370527756
Trained batch 204 in epoch 11, gen_loss = 0.9338702134969757, disc_loss = 0.0003232302606636772
Trained batch 205 in epoch 11, gen_loss = 0.9344177318429484, disc_loss = 0.0003228606360563805
Trained batch 206 in epoch 11, gen_loss = 0.9342775664467743, disc_loss = 0.0003226001830678771
Trained batch 207 in epoch 11, gen_loss = 0.9344792477786541, disc_loss = 0.00032182157054614014
Trained batch 208 in epoch 11, gen_loss = 0.9342771634530793, disc_loss = 0.00032112538172171615
Trained batch 209 in epoch 11, gen_loss = 0.9342307422842299, disc_loss = 0.00032045303658898255
Trained batch 210 in epoch 11, gen_loss = 0.9343563298478511, disc_loss = 0.00031992047359605247
Trained batch 211 in epoch 11, gen_loss = 0.9337862069314381, disc_loss = 0.0003190262404526913
Trained batch 212 in epoch 11, gen_loss = 0.9338826853344698, disc_loss = 0.0003183465707539406
Trained batch 213 in epoch 11, gen_loss = 0.933847812570144, disc_loss = 0.0003175458789024628
Trained batch 214 in epoch 11, gen_loss = 0.9338037504706271, disc_loss = 0.0003168243368299743
Trained batch 215 in epoch 11, gen_loss = 0.9334127315216594, disc_loss = 0.00031610079440724803
Trained batch 216 in epoch 11, gen_loss = 0.9333349416882212, disc_loss = 0.00031526939271362325
Trained batch 217 in epoch 11, gen_loss = 0.9327759217778477, disc_loss = 0.0003152141780947621
Trained batch 218 in epoch 11, gen_loss = 0.9334818968489834, disc_loss = 0.00031490807786831615
Trained batch 219 in epoch 11, gen_loss = 0.9338056206703186, disc_loss = 0.00031471749829176007
Trained batch 220 in epoch 11, gen_loss = 0.9340391558219944, disc_loss = 0.000314256276931915
Trained batch 221 in epoch 11, gen_loss = 0.9344050798330221, disc_loss = 0.00031375971957459114
Trained batch 222 in epoch 11, gen_loss = 0.9344351743368825, disc_loss = 0.0003133586971279789
Trained batch 223 in epoch 11, gen_loss = 0.9342574761914355, disc_loss = 0.0003127699644664972
Trained batch 224 in epoch 11, gen_loss = 0.9342291193538242, disc_loss = 0.0003120452054685706
Trained batch 225 in epoch 11, gen_loss = 0.9334762927177733, disc_loss = 0.0003124312700178841
Trained batch 226 in epoch 11, gen_loss = 0.933568865192094, disc_loss = 0.0003116037110356503
Trained batch 227 in epoch 11, gen_loss = 0.933087697677445, disc_loss = 0.00031113400048828527
Trained batch 228 in epoch 11, gen_loss = 0.9330453586370143, disc_loss = 0.0003104284621445222
Trained batch 229 in epoch 11, gen_loss = 0.9323500394821167, disc_loss = 0.0003102500383608023
Trained batch 230 in epoch 11, gen_loss = 0.9324394954747451, disc_loss = 0.0003094959908527387
Trained batch 231 in epoch 11, gen_loss = 0.9330133996133146, disc_loss = 0.0003095998152212846
Trained batch 232 in epoch 11, gen_loss = 0.933106807680089, disc_loss = 0.0003093350194971669
Trained batch 233 in epoch 11, gen_loss = 0.9333531403134012, disc_loss = 0.0003088872390513161
Trained batch 234 in epoch 11, gen_loss = 0.9334765452019712, disc_loss = 0.0003082440327295657
Trained batch 235 in epoch 11, gen_loss = 0.9340630368155948, disc_loss = 0.0003078415106216907
Trained batch 236 in epoch 11, gen_loss = 0.9343678154019867, disc_loss = 0.00030717261467509184
Trained batch 237 in epoch 11, gen_loss = 0.9338697983938105, disc_loss = 0.00030647583220603077
Trained batch 238 in epoch 11, gen_loss = 0.9333981504998945, disc_loss = 0.0003062462515212794
Trained batch 239 in epoch 11, gen_loss = 0.9330510670940081, disc_loss = 0.00030577357377599884
Trained batch 240 in epoch 11, gen_loss = 0.9330829893899656, disc_loss = 0.0003050662809560226
Trained batch 241 in epoch 11, gen_loss = 0.9329740597196847, disc_loss = 0.00030446156901129415
Trained batch 242 in epoch 11, gen_loss = 0.933288366706283, disc_loss = 0.000304144237269772
Trained batch 243 in epoch 11, gen_loss = 0.9329675020741635, disc_loss = 0.0003041415007440965
Trained batch 244 in epoch 11, gen_loss = 0.9327449878867792, disc_loss = 0.0003036436198661769
Trained batch 245 in epoch 11, gen_loss = 0.9324526156836409, disc_loss = 0.0003028959889467465
Trained batch 246 in epoch 11, gen_loss = 0.9324763074577579, disc_loss = 0.0003020423860677993
Trained batch 247 in epoch 11, gen_loss = 0.9325406022610203, disc_loss = 0.00030137868690226536
Trained batch 248 in epoch 11, gen_loss = 0.9321253675533586, disc_loss = 0.00030130912070223373
Trained batch 249 in epoch 11, gen_loss = 0.9320115168094635, disc_loss = 0.0003006746913015377
Trained batch 250 in epoch 11, gen_loss = 0.9317190150815652, disc_loss = 0.0003001922629349234
Trained batch 251 in epoch 11, gen_loss = 0.930994887910192, disc_loss = 0.00030199625143723097
Trained batch 252 in epoch 11, gen_loss = 0.9305940833487529, disc_loss = 0.00030185138934274414
Trained batch 253 in epoch 11, gen_loss = 0.9307259424464909, disc_loss = 0.0003016719799527741
Trained batch 254 in epoch 11, gen_loss = 0.9306684019518834, disc_loss = 0.0003012070334436573
Trained batch 255 in epoch 11, gen_loss = 0.930485627381131, disc_loss = 0.00030074921804157384
Trained batch 256 in epoch 11, gen_loss = 0.9301319648783495, disc_loss = 0.00030028098820575517
Trained batch 257 in epoch 11, gen_loss = 0.9300486789655316, disc_loss = 0.0002994836308231285
Trained batch 258 in epoch 11, gen_loss = 0.9297739219021153, disc_loss = 0.0002987474729507014
Trained batch 259 in epoch 11, gen_loss = 0.9297707211512786, disc_loss = 0.00029820817007230986
Trained batch 260 in epoch 11, gen_loss = 0.9300587289178052, disc_loss = 0.0002975653970676075
Trained batch 261 in epoch 11, gen_loss = 0.9298896191229347, disc_loss = 0.0002968786628408098
Trained batch 262 in epoch 11, gen_loss = 0.929504032823976, disc_loss = 0.00029625529019996886
Trained batch 263 in epoch 11, gen_loss = 0.9293409590468262, disc_loss = 0.00029576037534504644
Trained batch 264 in epoch 11, gen_loss = 0.9291712940863843, disc_loss = 0.0002954890362573524
Trained batch 265 in epoch 11, gen_loss = 0.9292319174995995, disc_loss = 0.0002950048818954536
Trained batch 266 in epoch 11, gen_loss = 0.92919646465823, disc_loss = 0.0002942982811621593
Trained batch 267 in epoch 11, gen_loss = 0.9292921570699606, disc_loss = 0.00029387349968601484
Trained batch 268 in epoch 11, gen_loss = 0.9294331200060791, disc_loss = 0.00029322380905661067
Trained batch 269 in epoch 11, gen_loss = 0.9296804584838726, disc_loss = 0.0002925348780991044
Trained batch 270 in epoch 11, gen_loss = 0.9293563871805958, disc_loss = 0.0002920159444651511
Trained batch 271 in epoch 11, gen_loss = 0.9291928290005993, disc_loss = 0.000291524561442416
Trained batch 272 in epoch 11, gen_loss = 0.9291450944575634, disc_loss = 0.0002913742753749137
Trained batch 273 in epoch 11, gen_loss = 0.9289582778502555, disc_loss = 0.00029090134026826846
Trained batch 274 in epoch 11, gen_loss = 0.9288539979674599, disc_loss = 0.00029015717543767424
Trained batch 275 in epoch 11, gen_loss = 0.9291823486918989, disc_loss = 0.00028975661128545954
Trained batch 276 in epoch 11, gen_loss = 0.9297484432747217, disc_loss = 0.00028925572944042655
Trained batch 277 in epoch 11, gen_loss = 0.9301799160542248, disc_loss = 0.0002890747392425739
Trained batch 278 in epoch 11, gen_loss = 0.9304586715168424, disc_loss = 0.0002885267338922037
Trained batch 279 in epoch 11, gen_loss = 0.9300546927111489, disc_loss = 0.0002880651410513175
Trained batch 280 in epoch 11, gen_loss = 0.9298675361477183, disc_loss = 0.0002875668017160118
Trained batch 281 in epoch 11, gen_loss = 0.9303508705281197, disc_loss = 0.000287665676606071
Trained batch 282 in epoch 11, gen_loss = 0.9301633588416838, disc_loss = 0.00028702595565602176
Trained batch 283 in epoch 11, gen_loss = 0.9301519809474408, disc_loss = 0.0002865724054316442
Trained batch 284 in epoch 11, gen_loss = 0.9308396945919907, disc_loss = 0.0002866957564644205
Trained batch 285 in epoch 11, gen_loss = 0.9312076947905801, disc_loss = 0.00028619613872219845
Trained batch 286 in epoch 11, gen_loss = 0.9318004040767922, disc_loss = 0.0002863827299252428
Trained batch 287 in epoch 11, gen_loss = 0.9316900086899599, disc_loss = 0.0002860541597379375
Trained batch 288 in epoch 11, gen_loss = 0.9316517999427953, disc_loss = 0.00028549023248012755
Trained batch 289 in epoch 11, gen_loss = 0.9316046677786728, disc_loss = 0.000285054239517696
Trained batch 290 in epoch 11, gen_loss = 0.931416035927448, disc_loss = 0.00028486353790973986
Trained batch 291 in epoch 11, gen_loss = 0.9310562249324094, disc_loss = 0.00028521098316210955
Trained batch 292 in epoch 11, gen_loss = 0.9312488713362111, disc_loss = 0.0002848663285234387
Trained batch 293 in epoch 11, gen_loss = 0.9312674676885411, disc_loss = 0.0002847468068608998
Trained batch 294 in epoch 11, gen_loss = 0.9310545393976114, disc_loss = 0.0002845452273396728
Trained batch 295 in epoch 11, gen_loss = 0.9309799298644066, disc_loss = 0.00028444996887382995
Trained batch 296 in epoch 11, gen_loss = 0.9308442256667397, disc_loss = 0.0002840009912829266
Trained batch 297 in epoch 11, gen_loss = 0.9309956957429848, disc_loss = 0.0002836558106482332
Trained batch 298 in epoch 11, gen_loss = 0.9308345220160723, disc_loss = 0.0002830755647391012
Trained batch 299 in epoch 11, gen_loss = 0.9304858219623565, disc_loss = 0.00028253619304450693
Trained batch 300 in epoch 11, gen_loss = 0.9301020207991235, disc_loss = 0.0002822161631987808
Trained batch 301 in epoch 11, gen_loss = 0.9303122018741457, disc_loss = 0.00028188226574246266
Trained batch 302 in epoch 11, gen_loss = 0.9301160792313, disc_loss = 0.0002812691109584223
Trained batch 303 in epoch 11, gen_loss = 0.9301219027685491, disc_loss = 0.0002806315273071385
Trained batch 304 in epoch 11, gen_loss = 0.9302115336793368, disc_loss = 0.00028017983844858734
Trained batch 305 in epoch 11, gen_loss = 0.9301064213116964, disc_loss = 0.0002796487234602454
Trained batch 306 in epoch 11, gen_loss = 0.9301442899999091, disc_loss = 0.0002790822994293105
Trained batch 307 in epoch 11, gen_loss = 0.9301083031799886, disc_loss = 0.00027847489875128234
Trained batch 308 in epoch 11, gen_loss = 0.9304541197023731, disc_loss = 0.0002784897205444327
Trained batch 309 in epoch 11, gen_loss = 0.9306866213198631, disc_loss = 0.00027817613513287786
Trained batch 310 in epoch 11, gen_loss = 0.9303462329018154, disc_loss = 0.0002781805467286141
Trained batch 311 in epoch 11, gen_loss = 0.9300813587048115, disc_loss = 0.00027787019324676244
Trained batch 312 in epoch 11, gen_loss = 0.9299723146060785, disc_loss = 0.0002774078875343827
Trained batch 313 in epoch 11, gen_loss = 0.929797733665272, disc_loss = 0.0002769379938237449
Trained batch 314 in epoch 11, gen_loss = 0.9296350759173196, disc_loss = 0.0002764519510304718
Trained batch 315 in epoch 11, gen_loss = 0.929523371631586, disc_loss = 0.0002758383238236818
Trained batch 316 in epoch 11, gen_loss = 0.9293807145172865, disc_loss = 0.0002752559661249372
Trained batch 317 in epoch 11, gen_loss = 0.9295689469238497, disc_loss = 0.0002750778721003726
Trained batch 318 in epoch 11, gen_loss = 0.9295006013215522, disc_loss = 0.00027457314699802103
Trained batch 319 in epoch 11, gen_loss = 0.9295023331418634, disc_loss = 0.0002740640800766414
Trained batch 320 in epoch 11, gen_loss = 0.9296745981011435, disc_loss = 0.0002738199359682937
Trained batch 321 in epoch 11, gen_loss = 0.9296893793973864, disc_loss = 0.0002734352374374895
Trained batch 322 in epoch 11, gen_loss = 0.9296111235677642, disc_loss = 0.00027281339551522556
Trained batch 323 in epoch 11, gen_loss = 0.9297688542692749, disc_loss = 0.0002723369535589073
Trained batch 324 in epoch 11, gen_loss = 0.9299152907958398, disc_loss = 0.00027188115059219016
Trained batch 325 in epoch 11, gen_loss = 0.9300363255790406, disc_loss = 0.00027152515631426194
Trained batch 326 in epoch 11, gen_loss = 0.929959906350582, disc_loss = 0.0002709591648153696
Trained batch 327 in epoch 11, gen_loss = 0.9298686339724355, disc_loss = 0.0002705761816531133
Trained batch 328 in epoch 11, gen_loss = 0.929772281538027, disc_loss = 0.0002702497069306012
Trained batch 329 in epoch 11, gen_loss = 0.9296450822642355, disc_loss = 0.00026970019043250375
Trained batch 330 in epoch 11, gen_loss = 0.9293080073108846, disc_loss = 0.0002694342709334604
Trained batch 331 in epoch 11, gen_loss = 0.9293736542563841, disc_loss = 0.0002688772727700977
Trained batch 332 in epoch 11, gen_loss = 0.9295110781271536, disc_loss = 0.00026853773985883116
Trained batch 333 in epoch 11, gen_loss = 0.9294308561407877, disc_loss = 0.0002681427418019394
Trained batch 334 in epoch 11, gen_loss = 0.9295852098891985, disc_loss = 0.00026768704836340206
Trained batch 335 in epoch 11, gen_loss = 0.9293110833636352, disc_loss = 0.0002672846553434196
Trained batch 336 in epoch 11, gen_loss = 0.9291423361096255, disc_loss = 0.0002669037590635863
Trained batch 337 in epoch 11, gen_loss = 0.9289262047886143, disc_loss = 0.00026677083865547904
Trained batch 338 in epoch 11, gen_loss = 0.9290554713358922, disc_loss = 0.00026651243705839566
Trained batch 339 in epoch 11, gen_loss = 0.9288712498019723, disc_loss = 0.0002660774882636307
Trained batch 340 in epoch 11, gen_loss = 0.9286323471153237, disc_loss = 0.0002656089866530803
Trained batch 341 in epoch 11, gen_loss = 0.9287287463918764, disc_loss = 0.0002653590922047485
Trained batch 342 in epoch 11, gen_loss = 0.9284110674010074, disc_loss = 0.0002653456293513154
Trained batch 343 in epoch 11, gen_loss = 0.9283678178177324, disc_loss = 0.00026485175977689133
Trained batch 344 in epoch 11, gen_loss = 0.9285476767498514, disc_loss = 0.00026450551001513646
Trained batch 345 in epoch 11, gen_loss = 0.9280555353343831, disc_loss = 0.0002643273377007431
Trained batch 346 in epoch 11, gen_loss = 0.9277613147534967, disc_loss = 0.00026404708339976984
Trained batch 347 in epoch 11, gen_loss = 0.9278959837453119, disc_loss = 0.00026361021354069246
Trained batch 348 in epoch 11, gen_loss = 0.9279572080746079, disc_loss = 0.00026312410264552164
Trained batch 349 in epoch 11, gen_loss = 0.9277763882705143, disc_loss = 0.00026280690304702147
Trained batch 350 in epoch 11, gen_loss = 0.9282303520417281, disc_loss = 0.0002634809591672768
Trained batch 351 in epoch 11, gen_loss = 0.9283050347796895, disc_loss = 0.0002634572449344639
Trained batch 352 in epoch 11, gen_loss = 0.9282699602183809, disc_loss = 0.00026328042646699845
Trained batch 353 in epoch 11, gen_loss = 0.9282867435344868, disc_loss = 0.0002628368349620246
Trained batch 354 in epoch 11, gen_loss = 0.9282738606694718, disc_loss = 0.00026247898070797535
Trained batch 355 in epoch 11, gen_loss = 0.9278307024682506, disc_loss = 0.000262252226052675
Trained batch 356 in epoch 11, gen_loss = 0.9278553443796494, disc_loss = 0.00026194682766759054
Trained batch 357 in epoch 11, gen_loss = 0.9277778166299425, disc_loss = 0.000261675419005261
Trained batch 358 in epoch 11, gen_loss = 0.9278028554238981, disc_loss = 0.00026120621933793767
Trained batch 359 in epoch 11, gen_loss = 0.9277274040712251, disc_loss = 0.00026068167189805533
Trained batch 360 in epoch 11, gen_loss = 0.927512861850189, disc_loss = 0.0002601960454198372
Trained batch 361 in epoch 11, gen_loss = 0.9275883319298865, disc_loss = 0.0002598506278907996
Trained batch 362 in epoch 11, gen_loss = 0.9273924018069075, disc_loss = 0.0002598073429512386
Trained batch 363 in epoch 11, gen_loss = 0.9270532502905353, disc_loss = 0.0002597328280839125
Trained batch 364 in epoch 11, gen_loss = 0.9269294851446805, disc_loss = 0.00025931403638112475
Trained batch 365 in epoch 11, gen_loss = 0.9266459876722325, disc_loss = 0.00025925179255605914
Trained batch 366 in epoch 11, gen_loss = 0.9269737508706241, disc_loss = 0.00025913732193603257
Trained batch 367 in epoch 11, gen_loss = 0.9269806517531043, disc_loss = 0.00025882936820973714
Trained batch 368 in epoch 11, gen_loss = 0.9267230786605256, disc_loss = 0.00025848088139885164
Trained batch 369 in epoch 11, gen_loss = 0.9268095100248183, disc_loss = 0.00025813528784940875
Trained batch 370 in epoch 11, gen_loss = 0.9267902232887288, disc_loss = 0.0002576785955464811
Trained batch 371 in epoch 11, gen_loss = 0.9266168891742665, disc_loss = 0.00025735900922999494
Trained batch 372 in epoch 11, gen_loss = 0.9262818861902559, disc_loss = 0.0002574573412243259
Trained batch 373 in epoch 11, gen_loss = 0.9262290134786922, disc_loss = 0.00025720898015533556
Trained batch 374 in epoch 11, gen_loss = 0.9260185499191285, disc_loss = 0.00025681657163659113
Trained batch 375 in epoch 11, gen_loss = 0.9258854557225045, disc_loss = 0.0002563671096334261
Trained batch 376 in epoch 11, gen_loss = 0.9260748944168697, disc_loss = 0.00025604973558045614
Trained batch 377 in epoch 11, gen_loss = 0.9260921219669321, disc_loss = 0.0002556633767704221
Trained batch 378 in epoch 11, gen_loss = 0.9261914922568288, disc_loss = 0.00025551352097568687
Trained batch 379 in epoch 11, gen_loss = 0.9262979589010539, disc_loss = 0.00025530388932230906
Trained batch 380 in epoch 11, gen_loss = 0.9260274304805465, disc_loss = 0.0002548449839551791
Trained batch 381 in epoch 11, gen_loss = 0.9259353443902201, disc_loss = 0.0002546461395401549
Trained batch 382 in epoch 11, gen_loss = 0.9257911639798715, disc_loss = 0.00025433005239463755
Trained batch 383 in epoch 11, gen_loss = 0.9257403928786516, disc_loss = 0.000253971390653381
Trained batch 384 in epoch 11, gen_loss = 0.9255062679191688, disc_loss = 0.0002537621365665071
Trained batch 385 in epoch 11, gen_loss = 0.9253965959030112, disc_loss = 0.00025347673621525086
Trained batch 386 in epoch 11, gen_loss = 0.9257035141459423, disc_loss = 0.00025323923629902916
Trained batch 387 in epoch 11, gen_loss = 0.9260438941803175, disc_loss = 0.00025337095941778767
Trained batch 388 in epoch 11, gen_loss = 0.925910272757621, disc_loss = 0.00025296642039220177
Trained batch 389 in epoch 11, gen_loss = 0.9256880971101614, disc_loss = 0.0002529134836573249
Trained batch 390 in epoch 11, gen_loss = 0.9257160280366687, disc_loss = 0.0002527314222544608
Trained batch 391 in epoch 11, gen_loss = 0.9255732411936838, disc_loss = 0.00025230960465928454
Trained batch 392 in epoch 11, gen_loss = 0.9258015339307809, disc_loss = 0.00025194022136073294
Trained batch 393 in epoch 11, gen_loss = 0.9255891773603895, disc_loss = 0.00025152367843151905
Trained batch 394 in epoch 11, gen_loss = 0.9252536145946647, disc_loss = 0.0002512510712671129
Trained batch 395 in epoch 11, gen_loss = 0.9252185914853607, disc_loss = 0.0002510007846035708
Trained batch 396 in epoch 11, gen_loss = 0.9253964243968128, disc_loss = 0.0002507519010869054
Trained batch 397 in epoch 11, gen_loss = 0.9255145211615156, disc_loss = 0.0002505090180521213
Trained batch 398 in epoch 11, gen_loss = 0.9256010576895902, disc_loss = 0.000250330187937882
Trained batch 399 in epoch 11, gen_loss = 0.9258312161266804, disc_loss = 0.00025012682566739387
Trained batch 400 in epoch 11, gen_loss = 0.9260573888062836, disc_loss = 0.0002497596886273743
Trained batch 401 in epoch 11, gen_loss = 0.925952177439163, disc_loss = 0.00024959402038965986
Trained batch 402 in epoch 11, gen_loss = 0.9260530397850586, disc_loss = 0.0002491700792816299
Trained batch 403 in epoch 11, gen_loss = 0.9260138798468184, disc_loss = 0.0002489209678735801
Trained batch 404 in epoch 11, gen_loss = 0.9259142660800321, disc_loss = 0.0002485494305419931
Trained batch 405 in epoch 11, gen_loss = 0.926181523083466, disc_loss = 0.00024820868487313865
Trained batch 406 in epoch 11, gen_loss = 0.9262612387354895, disc_loss = 0.00024787501573373267
Trained batch 407 in epoch 11, gen_loss = 0.9263815348054848, disc_loss = 0.00024754288334210574
Trained batch 408 in epoch 11, gen_loss = 0.9263483418520622, disc_loss = 0.00024730703837370894
Trained batch 409 in epoch 11, gen_loss = 0.9263821383801902, disc_loss = 0.00024698008752993035
Trained batch 410 in epoch 11, gen_loss = 0.9263714522920966, disc_loss = 0.00024684298825815635
Trained batch 411 in epoch 11, gen_loss = 0.9263453011952557, disc_loss = 0.0002465463038461873
Trained batch 412 in epoch 11, gen_loss = 0.926357420968663, disc_loss = 0.00024620049336621287
Trained batch 413 in epoch 11, gen_loss = 0.9261963174538912, disc_loss = 0.0002459260793567291
Trained batch 414 in epoch 11, gen_loss = 0.92603180236127, disc_loss = 0.00024574359905897607
Trained batch 415 in epoch 11, gen_loss = 0.9261005661235406, disc_loss = 0.00024546030329894653
Trained batch 416 in epoch 11, gen_loss = 0.9260779576335879, disc_loss = 0.00024507281044735385
Trained batch 417 in epoch 11, gen_loss = 0.9260720564988241, disc_loss = 0.0002447370972131205
Trained batch 418 in epoch 11, gen_loss = 0.9259909233500678, disc_loss = 0.00024436663610911827
Trained batch 419 in epoch 11, gen_loss = 0.9260436341876075, disc_loss = 0.00024412618780237
Trained batch 420 in epoch 11, gen_loss = 0.925961625830861, disc_loss = 0.00024375690926309353
Trained batch 421 in epoch 11, gen_loss = 0.9259571071484642, disc_loss = 0.00024337326066463114
Trained batch 422 in epoch 11, gen_loss = 0.9260918197902381, disc_loss = 0.00024315231838101196
Trained batch 423 in epoch 11, gen_loss = 0.9259365070259796, disc_loss = 0.0002428293931720787
Trained batch 424 in epoch 11, gen_loss = 0.9257008969082552, disc_loss = 0.0002427161915008636
Trained batch 425 in epoch 11, gen_loss = 0.9257744778769676, disc_loss = 0.0002423429034938358
Trained batch 426 in epoch 11, gen_loss = 0.9257055131557116, disc_loss = 0.00024203855816078037
Trained batch 427 in epoch 11, gen_loss = 0.9258516607719047, disc_loss = 0.0002416851018445575
Trained batch 428 in epoch 11, gen_loss = 0.9257236748308568, disc_loss = 0.00024145959679331493
Trained batch 429 in epoch 11, gen_loss = 0.9258154848287272, disc_loss = 0.00024117974115692642
Trained batch 430 in epoch 11, gen_loss = 0.9260168602461052, disc_loss = 0.00024087248885817176
Trained batch 431 in epoch 11, gen_loss = 0.9260886380517924, disc_loss = 0.00024055487139978341
Trained batch 432 in epoch 11, gen_loss = 0.9260070739662399, disc_loss = 0.00024016911017936472
Trained batch 433 in epoch 11, gen_loss = 0.9258375371106758, disc_loss = 0.0002400150551693514
Trained batch 434 in epoch 11, gen_loss = 0.9259685475250771, disc_loss = 0.00023984030530060075
Trained batch 435 in epoch 11, gen_loss = 0.9260684914818598, disc_loss = 0.00023959961764801746
Trained batch 436 in epoch 11, gen_loss = 0.9259651732935785, disc_loss = 0.00023951885703758248
Trained batch 437 in epoch 11, gen_loss = 0.9262049113778763, disc_loss = 0.0002392883256123482
Trained batch 438 in epoch 11, gen_loss = 0.9261119668467441, disc_loss = 0.0002390007246582682
Trained batch 439 in epoch 11, gen_loss = 0.9259828663685105, disc_loss = 0.0002388051644216334
Trained batch 440 in epoch 11, gen_loss = 0.9260048489181363, disc_loss = 0.00023842215969764718
Trained batch 441 in epoch 11, gen_loss = 0.9256623392730816, disc_loss = 0.00023836633196438776
Trained batch 442 in epoch 11, gen_loss = 0.9255580385436323, disc_loss = 0.00023817040614045854
Trained batch 443 in epoch 11, gen_loss = 0.9254773280642055, disc_loss = 0.00023804557195608714
Trained batch 444 in epoch 11, gen_loss = 0.9253194157996875, disc_loss = 0.0002378278087858592
Trained batch 445 in epoch 11, gen_loss = 0.9252745526521196, disc_loss = 0.00023753884290329352
Trained batch 446 in epoch 11, gen_loss = 0.9252567120579799, disc_loss = 0.00023733726996924285
Trained batch 447 in epoch 11, gen_loss = 0.9251327131475721, disc_loss = 0.0002370521943768316
Trained batch 448 in epoch 11, gen_loss = 0.9249617745456823, disc_loss = 0.00023688148473283662
Trained batch 449 in epoch 11, gen_loss = 0.9249639621045854, disc_loss = 0.0002366173702951831
Trained batch 450 in epoch 11, gen_loss = 0.9249478807206164, disc_loss = 0.00023646909228454812
Trained batch 451 in epoch 11, gen_loss = 0.924900116382447, disc_loss = 0.00023613969623294053
Trained batch 452 in epoch 11, gen_loss = 0.9247582998233652, disc_loss = 0.00023579574061586433
Trained batch 453 in epoch 11, gen_loss = 0.9247504411027295, disc_loss = 0.00023556210096548045
Trained batch 454 in epoch 11, gen_loss = 0.9248400532282316, disc_loss = 0.00023532425728882406
Trained batch 455 in epoch 11, gen_loss = 0.9247308241432173, disc_loss = 0.00023510602228557937
Trained batch 456 in epoch 11, gen_loss = 0.9248200017200778, disc_loss = 0.00023482343597445613
Trained batch 457 in epoch 11, gen_loss = 0.9251553110420444, disc_loss = 0.0002347577493076058
Trained batch 458 in epoch 11, gen_loss = 0.925273939285403, disc_loss = 0.00023467671017701207
Trained batch 459 in epoch 11, gen_loss = 0.9251721135948016, disc_loss = 0.00023462380714076774
Trained batch 460 in epoch 11, gen_loss = 0.925127446780753, disc_loss = 0.00023457887798392188
Trained batch 461 in epoch 11, gen_loss = 0.9250199165179099, disc_loss = 0.00023427299533210176
Trained batch 462 in epoch 11, gen_loss = 0.924834973868747, disc_loss = 0.00023426792580776668
Trained batch 463 in epoch 11, gen_loss = 0.9247428619399153, disc_loss = 0.00023404232673595384
Trained batch 464 in epoch 11, gen_loss = 0.9245282602566545, disc_loss = 0.00023418676659842872
Trained batch 465 in epoch 11, gen_loss = 0.9244355606674637, disc_loss = 0.00023385714190585395
Trained batch 466 in epoch 11, gen_loss = 0.9243952351157619, disc_loss = 0.00023399792428749634
Trained batch 467 in epoch 11, gen_loss = 0.9244145534486852, disc_loss = 0.00023406217824075665
Trained batch 468 in epoch 11, gen_loss = 0.9244242961218616, disc_loss = 0.00023382472783214906
Trained batch 469 in epoch 11, gen_loss = 0.9244946486138282, disc_loss = 0.0002336217449950748
Trained batch 470 in epoch 11, gen_loss = 0.9244626938917075, disc_loss = 0.0002335033865115109
Trained batch 471 in epoch 11, gen_loss = 0.9243546106805236, disc_loss = 0.00023332703158765501
Trained batch 472 in epoch 11, gen_loss = 0.9244457087607515, disc_loss = 0.00023381224875638644
Trained batch 473 in epoch 11, gen_loss = 0.924635006908626, disc_loss = 0.00023401331528947583
Trained batch 474 in epoch 11, gen_loss = 0.9244730244184796, disc_loss = 0.00023379400614526516
Trained batch 475 in epoch 11, gen_loss = 0.9243716645140608, disc_loss = 0.0002337516796752662
Trained batch 476 in epoch 11, gen_loss = 0.9240952422783809, disc_loss = 0.00023369308661394197
Trained batch 477 in epoch 11, gen_loss = 0.924217750587224, disc_loss = 0.00023368149821667943
Trained batch 478 in epoch 11, gen_loss = 0.924400110832087, disc_loss = 0.00023360488659727516
Trained batch 479 in epoch 11, gen_loss = 0.9244290115932624, disc_loss = 0.00023372089350838602
Trained batch 480 in epoch 11, gen_loss = 0.9244612139376682, disc_loss = 0.00023442850850683225
Trained batch 481 in epoch 11, gen_loss = 0.9242953638318169, disc_loss = 0.00023449171917547793
Trained batch 482 in epoch 11, gen_loss = 0.9239853957424993, disc_loss = 0.00023442560900388358
Trained batch 483 in epoch 11, gen_loss = 0.9237462118391163, disc_loss = 0.00023429125862139323
Trained batch 484 in epoch 11, gen_loss = 0.9236284899957401, disc_loss = 0.0002341097017651731
Trained batch 485 in epoch 11, gen_loss = 0.9236892303566874, disc_loss = 0.00023386225067742586
Trained batch 486 in epoch 11, gen_loss = 0.9236821177314194, disc_loss = 0.00023367893253704075
Trained batch 487 in epoch 11, gen_loss = 0.9236928029138534, disc_loss = 0.0002335080440299534
Trained batch 488 in epoch 11, gen_loss = 0.9234984294037146, disc_loss = 0.00023330453473368492
Trained batch 489 in epoch 11, gen_loss = 0.9234264655989044, disc_loss = 0.00023304718341357646
Trained batch 490 in epoch 11, gen_loss = 0.9234739640336901, disc_loss = 0.00023290424719663876
Trained batch 491 in epoch 11, gen_loss = 0.9231199240539132, disc_loss = 0.0002330720683421828
Trained batch 492 in epoch 11, gen_loss = 0.9229522120154654, disc_loss = 0.00023295035280023266
Trained batch 493 in epoch 11, gen_loss = 0.9228912216690388, disc_loss = 0.00023291317685891362
Trained batch 494 in epoch 11, gen_loss = 0.9227915401410575, disc_loss = 0.00023275033267734647
Trained batch 495 in epoch 11, gen_loss = 0.9225622296573655, disc_loss = 0.0002326684454982892
Trained batch 496 in epoch 11, gen_loss = 0.9224931997072768, disc_loss = 0.00023245195671904296
Trained batch 497 in epoch 11, gen_loss = 0.9222043941777394, disc_loss = 0.0002322841447680566
Trained batch 498 in epoch 11, gen_loss = 0.9223906451571203, disc_loss = 0.00023239410379637901
Trained batch 499 in epoch 11, gen_loss = 0.9224231110811234, disc_loss = 0.00023252331429102923
Trained batch 500 in epoch 11, gen_loss = 0.9221470906824885, disc_loss = 0.00023294480913632387
Trained batch 501 in epoch 11, gen_loss = 0.9222082435134873, disc_loss = 0.00023321348012123996
Trained batch 502 in epoch 11, gen_loss = 0.9222994724040477, disc_loss = 0.0002331851036457954
Trained batch 503 in epoch 11, gen_loss = 0.9222512790371501, disc_loss = 0.00023303958985505032
Trained batch 504 in epoch 11, gen_loss = 0.922257944971028, disc_loss = 0.00023302991088136274
Trained batch 505 in epoch 11, gen_loss = 0.9221079911403505, disc_loss = 0.0002327818167010523
Trained batch 506 in epoch 11, gen_loss = 0.9219763022672965, disc_loss = 0.00023283250143402945
Trained batch 507 in epoch 11, gen_loss = 0.9218867688667117, disc_loss = 0.0002327315770365769
Trained batch 508 in epoch 11, gen_loss = 0.9220543945233808, disc_loss = 0.00023301994212876094
Trained batch 509 in epoch 11, gen_loss = 0.9218057011856752, disc_loss = 0.00023363614016881342
Trained batch 510 in epoch 11, gen_loss = 0.9218503628691582, disc_loss = 0.0002334641940180265
Trained batch 511 in epoch 11, gen_loss = 0.9218375587370247, disc_loss = 0.00023326593613148816
Trained batch 512 in epoch 11, gen_loss = 0.9218614182741786, disc_loss = 0.00023321022007981548
Trained batch 513 in epoch 11, gen_loss = 0.9217125323495976, disc_loss = 0.00023304735305449556
Trained batch 514 in epoch 11, gen_loss = 0.921764012679313, disc_loss = 0.0002327943306774561
Trained batch 515 in epoch 11, gen_loss = 0.921866021299547, disc_loss = 0.00023265710705902532
Trained batch 516 in epoch 11, gen_loss = 0.9216079144689977, disc_loss = 0.00023404806809838974
Trained batch 517 in epoch 11, gen_loss = 0.921852230795562, disc_loss = 0.00023415674829712176
Trained batch 518 in epoch 11, gen_loss = 0.9218731437574692, disc_loss = 0.0002344607189864051
Trained batch 519 in epoch 11, gen_loss = 0.9217649804858061, disc_loss = 0.00023436980987193796
Trained batch 520 in epoch 11, gen_loss = 0.921727972730794, disc_loss = 0.00023452074287583043
Trained batch 521 in epoch 11, gen_loss = 0.9215199530581405, disc_loss = 0.00023445044375161668
Trained batch 522 in epoch 11, gen_loss = 0.9212093556132417, disc_loss = 0.0002342319395710326
Trained batch 523 in epoch 11, gen_loss = 0.9211420375882214, disc_loss = 0.00023395788325927708
Trained batch 524 in epoch 11, gen_loss = 0.92119431858971, disc_loss = 0.00023364759033678897
Trained batch 525 in epoch 11, gen_loss = 0.9211667005553446, disc_loss = 0.00023335329266191998
Trained batch 526 in epoch 11, gen_loss = 0.9210779246161965, disc_loss = 0.00023304882122301347
Trained batch 527 in epoch 11, gen_loss = 0.9211128034600706, disc_loss = 0.0002328027637138968
Trained batch 528 in epoch 11, gen_loss = 0.9209959110375389, disc_loss = 0.00023250930611614582
Trained batch 529 in epoch 11, gen_loss = 0.9210882958376183, disc_loss = 0.000232216982002906
Trained batch 530 in epoch 11, gen_loss = 0.9209245799175988, disc_loss = 0.00023206068743164993
Trained batch 531 in epoch 11, gen_loss = 0.9206019659015469, disc_loss = 0.00023188206923668644
Trained batch 532 in epoch 11, gen_loss = 0.9205450792473655, disc_loss = 0.00023175217162103062
Trained batch 533 in epoch 11, gen_loss = 0.9209763994824127, disc_loss = 0.00023262140591592223
Trained batch 534 in epoch 11, gen_loss = 0.9208757438392282, disc_loss = 0.00023247915859743256
Trained batch 535 in epoch 11, gen_loss = 0.920856038025066, disc_loss = 0.00023236632035543913
Trained batch 536 in epoch 11, gen_loss = 0.9209990744484203, disc_loss = 0.00023236761003055434
Trained batch 537 in epoch 11, gen_loss = 0.9209873783765672, disc_loss = 0.00023213800429764677
Trained batch 538 in epoch 11, gen_loss = 0.9209478495293513, disc_loss = 0.00023195978617688713
Trained batch 539 in epoch 11, gen_loss = 0.9208071867624918, disc_loss = 0.00023174390741958093
Trained batch 540 in epoch 11, gen_loss = 0.9208587225175389, disc_loss = 0.00023150818043226178
Trained batch 541 in epoch 11, gen_loss = 0.9207353143234535, disc_loss = 0.00023134618244364573
Trained batch 542 in epoch 11, gen_loss = 0.9206681431547273, disc_loss = 0.00023109406612791604
Trained batch 543 in epoch 11, gen_loss = 0.9207431554575177, disc_loss = 0.00023089286227171696
Trained batch 544 in epoch 11, gen_loss = 0.9207051568075058, disc_loss = 0.0002306530563296417
Trained batch 545 in epoch 11, gen_loss = 0.9204624177335383, disc_loss = 0.0002304957511297712
Trained batch 546 in epoch 11, gen_loss = 0.9204885323261213, disc_loss = 0.00023037584865807557
Trained batch 547 in epoch 11, gen_loss = 0.9204046771909199, disc_loss = 0.00023024773493017847
Trained batch 548 in epoch 11, gen_loss = 0.9203285827879915, disc_loss = 0.00022997937833369524
Trained batch 549 in epoch 11, gen_loss = 0.9203556200591001, disc_loss = 0.00022990363163196228
Trained batch 550 in epoch 11, gen_loss = 0.920391647439254, disc_loss = 0.00022990368153986954
Trained batch 551 in epoch 11, gen_loss = 0.9204967402029729, disc_loss = 0.00022991043308296787
Trained batch 552 in epoch 11, gen_loss = 0.920315391870778, disc_loss = 0.000229901987534045
Trained batch 553 in epoch 11, gen_loss = 0.9200554179155439, disc_loss = 0.0002298260804552363
Trained batch 554 in epoch 11, gen_loss = 0.9200052807996939, disc_loss = 0.00022980402908623555
Trained batch 555 in epoch 11, gen_loss = 0.9199674212032085, disc_loss = 0.00022969182723401978
Trained batch 556 in epoch 11, gen_loss = 0.9198932317043763, disc_loss = 0.00022950951001942126
Trained batch 557 in epoch 11, gen_loss = 0.9199245292226046, disc_loss = 0.00022957348687750352
Trained batch 558 in epoch 11, gen_loss = 0.9199432801048743, disc_loss = 0.00023029197595429596
Trained batch 559 in epoch 11, gen_loss = 0.9198864832520485, disc_loss = 0.00023067968616357704
Trained batch 560 in epoch 11, gen_loss = 0.9197483440983955, disc_loss = 0.0002306117528085406
Trained batch 561 in epoch 11, gen_loss = 0.9198059040880713, disc_loss = 0.00023058577005364485
Trained batch 562 in epoch 11, gen_loss = 0.9197368280925717, disc_loss = 0.00023044557262565213
Trained batch 563 in epoch 11, gen_loss = 0.9196988294521967, disc_loss = 0.00023033538554503635
Trained batch 564 in epoch 11, gen_loss = 0.919526771634026, disc_loss = 0.00023077615272496885
Trained batch 565 in epoch 11, gen_loss = 0.9194830259038366, disc_loss = 0.00023104937638829926
Trained batch 566 in epoch 11, gen_loss = 0.9194937993819962, disc_loss = 0.00023118908857582614
Trained batch 567 in epoch 11, gen_loss = 0.9194677219214574, disc_loss = 0.00023114429198576033
Trained batch 568 in epoch 11, gen_loss = 0.9193068184416826, disc_loss = 0.0002309355024155884
Trained batch 569 in epoch 11, gen_loss = 0.919012046696847, disc_loss = 0.0002307969386476958
Trained batch 570 in epoch 11, gen_loss = 0.9190273671141856, disc_loss = 0.0002306654369690979
Trained batch 571 in epoch 11, gen_loss = 0.9190226699505653, disc_loss = 0.00023752432386757205
Trained batch 572 in epoch 11, gen_loss = 0.9191668622364757, disc_loss = 0.0002384174468965281
Trained batch 573 in epoch 11, gen_loss = 0.919365705305691, disc_loss = 0.0002386952874202846
Trained batch 574 in epoch 11, gen_loss = 0.9193401218497235, disc_loss = 0.0002386766566854456
Trained batch 575 in epoch 11, gen_loss = 0.9192565788204471, disc_loss = 0.00023905004187933324
Trained batch 576 in epoch 11, gen_loss = 0.9194367261445295, disc_loss = 0.000239024042504746
Trained batch 577 in epoch 11, gen_loss = 0.9195439064791459, disc_loss = 0.000238909111903041
Trained batch 578 in epoch 11, gen_loss = 0.9193563333653003, disc_loss = 0.00023903119128373563
Trained batch 579 in epoch 11, gen_loss = 0.9194194431962638, disc_loss = 0.00023911440760551565
Trained batch 580 in epoch 11, gen_loss = 0.9195693604096693, disc_loss = 0.0002388838694152172
Trained batch 581 in epoch 11, gen_loss = 0.9195598589185997, disc_loss = 0.00023864480508845444
Trained batch 582 in epoch 11, gen_loss = 0.9194209696293695, disc_loss = 0.00023845747001854524
Trained batch 583 in epoch 11, gen_loss = 0.9193101293624264, disc_loss = 0.00023820057156452294
Trained batch 584 in epoch 11, gen_loss = 0.9191144453154669, disc_loss = 0.00023817930759366553
Trained batch 585 in epoch 11, gen_loss = 0.9189755062194408, disc_loss = 0.00023803816071114306
Trained batch 586 in epoch 11, gen_loss = 0.9190900646645125, disc_loss = 0.0002379580177895263
Trained batch 587 in epoch 11, gen_loss = 0.9190595597028732, disc_loss = 0.0002381052218836322
Trained batch 588 in epoch 11, gen_loss = 0.919207155299713, disc_loss = 0.00023796024319649783
Trained batch 589 in epoch 11, gen_loss = 0.9193365661774652, disc_loss = 0.00023790872908617622
Trained batch 590 in epoch 11, gen_loss = 0.9194481567481246, disc_loss = 0.00023788820838962656
Trained batch 591 in epoch 11, gen_loss = 0.9195054964842023, disc_loss = 0.00023773418140105628
Trained batch 592 in epoch 11, gen_loss = 0.919493602258962, disc_loss = 0.0002375379833868865
Trained batch 593 in epoch 11, gen_loss = 0.9194693471044804, disc_loss = 0.00023735011728123374
Trained batch 594 in epoch 11, gen_loss = 0.9194172121897465, disc_loss = 0.00023711843341745498
Trained batch 595 in epoch 11, gen_loss = 0.9194087466137522, disc_loss = 0.0002369195048622287
Trained batch 596 in epoch 11, gen_loss = 0.9193497321114468, disc_loss = 0.00023678318738556736
Trained batch 597 in epoch 11, gen_loss = 0.9192968679710375, disc_loss = 0.00023657261824632845
Trained batch 598 in epoch 11, gen_loss = 0.9193109248038723, disc_loss = 0.0002362647240736385
Trained batch 599 in epoch 11, gen_loss = 0.9192245781421662, disc_loss = 0.00023602063172196115
Trained batch 600 in epoch 11, gen_loss = 0.9193013101171534, disc_loss = 0.00023581074958637329
Trained batch 601 in epoch 11, gen_loss = 0.9194969229919966, disc_loss = 0.00023570807987023098
Trained batch 602 in epoch 11, gen_loss = 0.9194421255173375, disc_loss = 0.00023568932472210405
Trained batch 603 in epoch 11, gen_loss = 0.9195565999738428, disc_loss = 0.00023566591418230681
Trained batch 604 in epoch 11, gen_loss = 0.9196617405276654, disc_loss = 0.00023542438398744557
Trained batch 605 in epoch 11, gen_loss = 0.9194712319193107, disc_loss = 0.0002353582909059282
Trained batch 606 in epoch 11, gen_loss = 0.9194919001525866, disc_loss = 0.00023521979937943228
Trained batch 607 in epoch 11, gen_loss = 0.9195871620782112, disc_loss = 0.00023504156348807506
Trained batch 608 in epoch 11, gen_loss = 0.9196331876839323, disc_loss = 0.00023487132468785746
Trained batch 609 in epoch 11, gen_loss = 0.9195412771623642, disc_loss = 0.0002346907008642552
Trained batch 610 in epoch 11, gen_loss = 0.919595195989562, disc_loss = 0.000234494422127149
Trained batch 611 in epoch 11, gen_loss = 0.9196451721238155, disc_loss = 0.0002343628604969982
Trained batch 612 in epoch 11, gen_loss = 0.9196189968659866, disc_loss = 0.00023419166200626778
Trained batch 613 in epoch 11, gen_loss = 0.9196459949987331, disc_loss = 0.00023394718155980032
Trained batch 614 in epoch 11, gen_loss = 0.9197814516904878, disc_loss = 0.00023369119113133237
Trained batch 615 in epoch 11, gen_loss = 0.9199068879152273, disc_loss = 0.00023344970877469794
Trained batch 616 in epoch 11, gen_loss = 0.9198962242328946, disc_loss = 0.0002333160546495816
Trained batch 617 in epoch 11, gen_loss = 0.9201219455131049, disc_loss = 0.00023311388863078816
Trained batch 618 in epoch 11, gen_loss = 0.9199992392290389, disc_loss = 0.00023295863614092627
Trained batch 619 in epoch 11, gen_loss = 0.9197823840764261, disc_loss = 0.00023272370740268079
Trained batch 620 in epoch 11, gen_loss = 0.9196825166639306, disc_loss = 0.0002325110548665528
Trained batch 621 in epoch 11, gen_loss = 0.9197990613543335, disc_loss = 0.00023225050244946033
Trained batch 622 in epoch 11, gen_loss = 0.9198423186810403, disc_loss = 0.00023211148578429185
Trained batch 623 in epoch 11, gen_loss = 0.9198598335377681, disc_loss = 0.00023195015922120103
Trained batch 624 in epoch 11, gen_loss = 0.9197583844184876, disc_loss = 0.00023238055147230626
Trained batch 625 in epoch 11, gen_loss = 0.9196785877878293, disc_loss = 0.00023228825218644524
Trained batch 626 in epoch 11, gen_loss = 0.919758156821298, disc_loss = 0.00023222117089429512
Trained batch 627 in epoch 11, gen_loss = 0.9195423888362897, disc_loss = 0.00023199328332883603
Trained batch 628 in epoch 11, gen_loss = 0.9194577546680675, disc_loss = 0.00023177839783320147
Trained batch 629 in epoch 11, gen_loss = 0.9193308785794273, disc_loss = 0.00023155363140551978
Trained batch 630 in epoch 11, gen_loss = 0.9192816910766384, disc_loss = 0.0002314155298697898
Trained batch 631 in epoch 11, gen_loss = 0.9193269657560542, disc_loss = 0.00023123990816697465
Trained batch 632 in epoch 11, gen_loss = 0.9193974931093188, disc_loss = 0.00023101252498589588
Trained batch 633 in epoch 11, gen_loss = 0.9192664128748776, disc_loss = 0.00023089277966629952
Trained batch 634 in epoch 11, gen_loss = 0.9193246380550655, disc_loss = 0.00023084915577439502
Trained batch 635 in epoch 11, gen_loss = 0.9192697228688114, disc_loss = 0.00023076660890978214
Trained batch 636 in epoch 11, gen_loss = 0.9193173365278559, disc_loss = 0.0002307112018503373
Trained batch 637 in epoch 11, gen_loss = 0.9193499345203926, disc_loss = 0.00023055310242892926
Trained batch 638 in epoch 11, gen_loss = 0.9194735050761084, disc_loss = 0.0002305459068698775
Trained batch 639 in epoch 11, gen_loss = 0.9194040167145431, disc_loss = 0.00023044682592399113
Trained batch 640 in epoch 11, gen_loss = 0.9193534922674182, disc_loss = 0.00023036992167877818
Trained batch 641 in epoch 11, gen_loss = 0.9191483798613801, disc_loss = 0.00023020853242821298
Trained batch 642 in epoch 11, gen_loss = 0.9194621408523335, disc_loss = 0.00023176776046126364
Trained batch 643 in epoch 11, gen_loss = 0.919383231342209, disc_loss = 0.0002323423911169676
Trained batch 644 in epoch 11, gen_loss = 0.9192949437355811, disc_loss = 0.00023240384045860175
Trained batch 645 in epoch 11, gen_loss = 0.9192148242203444, disc_loss = 0.00023225292019611268
Trained batch 646 in epoch 11, gen_loss = 0.9193015179641464, disc_loss = 0.00023207409811662106
Trained batch 647 in epoch 11, gen_loss = 0.9193241273363432, disc_loss = 0.0002319219792758461
Trained batch 648 in epoch 11, gen_loss = 0.9194645735626045, disc_loss = 0.00023178618237114682
Trained batch 649 in epoch 11, gen_loss = 0.9195291501742143, disc_loss = 0.0002316131405286097
Trained batch 650 in epoch 11, gen_loss = 0.9194635394531461, disc_loss = 0.0002313994726377322
Trained batch 651 in epoch 11, gen_loss = 0.9196995659474215, disc_loss = 0.00023124275775795926
Trained batch 652 in epoch 11, gen_loss = 0.9196460783755432, disc_loss = 0.00023109057738709905
Trained batch 653 in epoch 11, gen_loss = 0.919630224916184, disc_loss = 0.00023093735182628288
Trained batch 654 in epoch 11, gen_loss = 0.9194657259315024, disc_loss = 0.0002306969214398734
Trained batch 655 in epoch 11, gen_loss = 0.9193593408094674, disc_loss = 0.00023051587951580053
Trained batch 656 in epoch 11, gen_loss = 0.9194834329403336, disc_loss = 0.0002302893601148673
Trained batch 657 in epoch 11, gen_loss = 0.9194729167820834, disc_loss = 0.00023010257145842484
Trained batch 658 in epoch 11, gen_loss = 0.9195513150037149, disc_loss = 0.00022997901359053996
Trained batch 659 in epoch 11, gen_loss = 0.9196887503970753, disc_loss = 0.000229802276733222
Trained batch 660 in epoch 11, gen_loss = 0.9195895673828298, disc_loss = 0.00022973799649402343
Trained batch 661 in epoch 11, gen_loss = 0.9196823413098326, disc_loss = 0.000229618848865346
Trained batch 662 in epoch 11, gen_loss = 0.9195491579862741, disc_loss = 0.0002294771065135686
Trained batch 663 in epoch 11, gen_loss = 0.9196087995386986, disc_loss = 0.00022930306195450108
Trained batch 664 in epoch 11, gen_loss = 0.9195248169110234, disc_loss = 0.00022909542391622874
Trained batch 665 in epoch 11, gen_loss = 0.9194316110453448, disc_loss = 0.0002290064997480925
Trained batch 666 in epoch 11, gen_loss = 0.9192905078406098, disc_loss = 0.00022884754551647196
Trained batch 667 in epoch 11, gen_loss = 0.919188291726712, disc_loss = 0.00022876426308488329
Trained batch 668 in epoch 11, gen_loss = 0.9190961293575475, disc_loss = 0.00022851683738239816
Trained batch 669 in epoch 11, gen_loss = 0.9190353617739322, disc_loss = 0.000228278784262913
Trained batch 670 in epoch 11, gen_loss = 0.918948797994861, disc_loss = 0.00022806352401366
Trained batch 671 in epoch 11, gen_loss = 0.9190366595451321, disc_loss = 0.00022783640019952145
Trained batch 672 in epoch 11, gen_loss = 0.9191515471393251, disc_loss = 0.00022775824637753187
Trained batch 673 in epoch 11, gen_loss = 0.918958648376012, disc_loss = 0.00022757561808151125
Trained batch 674 in epoch 11, gen_loss = 0.9189467490160906, disc_loss = 0.0002274116650288407
Trained batch 675 in epoch 11, gen_loss = 0.9189975706077892, disc_loss = 0.0002272684877097211
Trained batch 676 in epoch 11, gen_loss = 0.9189339589156992, disc_loss = 0.00022702745731861194
Trained batch 677 in epoch 11, gen_loss = 0.9188486131067473, disc_loss = 0.00022683514667454089
Trained batch 678 in epoch 11, gen_loss = 0.9190075888198325, disc_loss = 0.00022663926883898633
Trained batch 679 in epoch 11, gen_loss = 0.9188479255227482, disc_loss = 0.00022648226446001312
Trained batch 680 in epoch 11, gen_loss = 0.9188062442731927, disc_loss = 0.00022631289305826294
Trained batch 681 in epoch 11, gen_loss = 0.9187119008858533, disc_loss = 0.00022612605590649465
Trained batch 682 in epoch 11, gen_loss = 0.9185608517198577, disc_loss = 0.00022591386425191616
Trained batch 683 in epoch 11, gen_loss = 0.9182734895519346, disc_loss = 0.00022578456596340657
Trained batch 684 in epoch 11, gen_loss = 0.9180899329429125, disc_loss = 0.00022561446061259284
Trained batch 685 in epoch 11, gen_loss = 0.9179676043048892, disc_loss = 0.00022543731641131942
Trained batch 686 in epoch 11, gen_loss = 0.9178924314146306, disc_loss = 0.00022532656069533503
Trained batch 687 in epoch 11, gen_loss = 0.9177710999583089, disc_loss = 0.0002251499733765106
Trained batch 688 in epoch 11, gen_loss = 0.9178456817206174, disc_loss = 0.00022497634530214104
Trained batch 689 in epoch 11, gen_loss = 0.9180422501287598, disc_loss = 0.0002247968825163232
Trained batch 690 in epoch 11, gen_loss = 0.9180975429573556, disc_loss = 0.00022461600499746543
Trained batch 691 in epoch 11, gen_loss = 0.9180558303188038, disc_loss = 0.00022458841683036201
Trained batch 692 in epoch 11, gen_loss = 0.9180426509865435, disc_loss = 0.00022439675842682947
Trained batch 693 in epoch 11, gen_loss = 0.9181861228145852, disc_loss = 0.00022432870121989116
Trained batch 694 in epoch 11, gen_loss = 0.9180997672698481, disc_loss = 0.00022418175336340335
Trained batch 695 in epoch 11, gen_loss = 0.9180744306623251, disc_loss = 0.00022404978165144418
Trained batch 696 in epoch 11, gen_loss = 0.9178897298904539, disc_loss = 0.00022429978030316539
Trained batch 697 in epoch 11, gen_loss = 0.9178741592220044, disc_loss = 0.00022431703698716293
Trained batch 698 in epoch 11, gen_loss = 0.9178380888589632, disc_loss = 0.00022417415780202153
Trained batch 699 in epoch 11, gen_loss = 0.917676392197609, disc_loss = 0.00022397703744770427
Trained batch 700 in epoch 11, gen_loss = 0.9176352145668444, disc_loss = 0.00022380623652623998
Trained batch 701 in epoch 11, gen_loss = 0.9176137360752138, disc_loss = 0.0002236532604198623
Trained batch 702 in epoch 11, gen_loss = 0.9175819668118679, disc_loss = 0.00022351412251990773
Trained batch 703 in epoch 11, gen_loss = 0.9177076583728194, disc_loss = 0.00022334832163489244
Trained batch 704 in epoch 11, gen_loss = 0.9175943774534455, disc_loss = 0.0002231574523822464
Trained batch 705 in epoch 11, gen_loss = 0.9176427765034414, disc_loss = 0.00022291749437937676
Trained batch 706 in epoch 11, gen_loss = 0.9176634400872227, disc_loss = 0.0002227430695853024
Trained batch 707 in epoch 11, gen_loss = 0.9174764759122989, disc_loss = 0.0002226439626117669
Trained batch 708 in epoch 11, gen_loss = 0.9175709637331189, disc_loss = 0.0002224935032770071
Trained batch 709 in epoch 11, gen_loss = 0.9174750328063965, disc_loss = 0.0002223779680361089
Trained batch 710 in epoch 11, gen_loss = 0.9174588434136199, disc_loss = 0.00022224203477682887
Trained batch 711 in epoch 11, gen_loss = 0.9174663045265702, disc_loss = 0.00022211592864918652
Trained batch 712 in epoch 11, gen_loss = 0.9172610170710805, disc_loss = 0.00022213204442809967
Trained batch 713 in epoch 11, gen_loss = 0.9173082180049907, disc_loss = 0.00022194128640079042
Trained batch 714 in epoch 11, gen_loss = 0.9173156279783983, disc_loss = 0.000221820945988476
Trained batch 715 in epoch 11, gen_loss = 0.9174200830845859, disc_loss = 0.00022162677205364283
Trained batch 716 in epoch 11, gen_loss = 0.9172950171692767, disc_loss = 0.000221485820958497
Trained batch 717 in epoch 11, gen_loss = 0.9173930252494918, disc_loss = 0.00022135467073372805
Trained batch 718 in epoch 11, gen_loss = 0.917468627155739, disc_loss = 0.00022117642292464494
Trained batch 719 in epoch 11, gen_loss = 0.9172484214107196, disc_loss = 0.00022133393960454366
Trained batch 720 in epoch 11, gen_loss = 0.9173149434273518, disc_loss = 0.00022118941408945486
Trained batch 721 in epoch 11, gen_loss = 0.9172983049025496, disc_loss = 0.00022102267554811354
Trained batch 722 in epoch 11, gen_loss = 0.9172424304699667, disc_loss = 0.00022090404614915507
Trained batch 723 in epoch 11, gen_loss = 0.9174345278114245, disc_loss = 0.00022084496644944132
Trained batch 724 in epoch 11, gen_loss = 0.9175678974184497, disc_loss = 0.00022076736619306632
Trained batch 725 in epoch 11, gen_loss = 0.9175842786130827, disc_loss = 0.0002207451692530831
Trained batch 726 in epoch 11, gen_loss = 0.9178320626117177, disc_loss = 0.00022070934334807475
Trained batch 727 in epoch 11, gen_loss = 0.9177266161192904, disc_loss = 0.0002207357460675057
Trained batch 728 in epoch 11, gen_loss = 0.9176897771237482, disc_loss = 0.0002207291908794934
Trained batch 729 in epoch 11, gen_loss = 0.9178106364322035, disc_loss = 0.0002206414302223767
Trained batch 730 in epoch 11, gen_loss = 0.9176993344779217, disc_loss = 0.00022048454614112978
Trained batch 731 in epoch 11, gen_loss = 0.9175779212042282, disc_loss = 0.00022037211399579635
Trained batch 732 in epoch 11, gen_loss = 0.9176269375285868, disc_loss = 0.0002202532184486945
Trained batch 733 in epoch 11, gen_loss = 0.9177626258508386, disc_loss = 0.00022016115720582553
Trained batch 734 in epoch 11, gen_loss = 0.9177142899863574, disc_loss = 0.0002200405940036907
Trained batch 735 in epoch 11, gen_loss = 0.9176966032094281, disc_loss = 0.00021990677040993552
Trained batch 736 in epoch 11, gen_loss = 0.9178595503279118, disc_loss = 0.00021976637547285854
Trained batch 737 in epoch 11, gen_loss = 0.9177929577304096, disc_loss = 0.00021970517717002604
Trained batch 738 in epoch 11, gen_loss = 0.9177194524843735, disc_loss = 0.00021956350675689376
Trained batch 739 in epoch 11, gen_loss = 0.9174662382216067, disc_loss = 0.00021966652284636685
Trained batch 740 in epoch 11, gen_loss = 0.9176115832026349, disc_loss = 0.00021980330023493375
Trained batch 741 in epoch 11, gen_loss = 0.9175826065302538, disc_loss = 0.00022000994206392214
Trained batch 742 in epoch 11, gen_loss = 0.917539810107502, disc_loss = 0.00021995965295409676
Trained batch 743 in epoch 11, gen_loss = 0.9175091896967221, disc_loss = 0.00021986300525015629
Trained batch 744 in epoch 11, gen_loss = 0.9175944681935663, disc_loss = 0.00021980247610610371
Trained batch 745 in epoch 11, gen_loss = 0.9174785582853067, disc_loss = 0.00021974623589644592
Trained batch 746 in epoch 11, gen_loss = 0.9175125123506569, disc_loss = 0.00021969278732845665
Trained batch 747 in epoch 11, gen_loss = 0.9173138943266741, disc_loss = 0.00021964370575356068
Trained batch 748 in epoch 11, gen_loss = 0.9172954447915621, disc_loss = 0.00021956674414135867
Trained batch 749 in epoch 11, gen_loss = 0.9172501098314921, disc_loss = 0.00021939964067132679
Trained batch 750 in epoch 11, gen_loss = 0.9174056753178887, disc_loss = 0.00021944108048579334
Trained batch 751 in epoch 11, gen_loss = 0.9175418063681177, disc_loss = 0.00021941895785490255
Trained batch 752 in epoch 11, gen_loss = 0.9175463142306365, disc_loss = 0.00021938732318994638
Trained batch 753 in epoch 11, gen_loss = 0.9176006817533103, disc_loss = 0.00021930386058265
Trained batch 754 in epoch 11, gen_loss = 0.9175564370407964, disc_loss = 0.00021916350023763173
Trained batch 755 in epoch 11, gen_loss = 0.9174540857316325, disc_loss = 0.0002189545639531971
Trained batch 756 in epoch 11, gen_loss = 0.917170844509548, disc_loss = 0.00021918671999805327
Trained batch 757 in epoch 11, gen_loss = 0.9170963201170547, disc_loss = 0.00021911454820590945
Trained batch 758 in epoch 11, gen_loss = 0.9168689949867439, disc_loss = 0.00021931404796385573
Trained batch 759 in epoch 11, gen_loss = 0.9167001910899815, disc_loss = 0.00021937215761729596
Trained batch 760 in epoch 11, gen_loss = 0.916609845947812, disc_loss = 0.0002192389157135422
Trained batch 761 in epoch 11, gen_loss = 0.9167350445363153, disc_loss = 0.00021919298537043894
Trained batch 762 in epoch 11, gen_loss = 0.9169721385442101, disc_loss = 0.00021937170529407436
Trained batch 763 in epoch 11, gen_loss = 0.9168580130756837, disc_loss = 0.0002194756810369073
Trained batch 764 in epoch 11, gen_loss = 0.9169228995547575, disc_loss = 0.00021939591554186026
Trained batch 765 in epoch 11, gen_loss = 0.9168565214925273, disc_loss = 0.00021938420705350302
Trained batch 766 in epoch 11, gen_loss = 0.9166758310686034, disc_loss = 0.00021929333590350061
Trained batch 767 in epoch 11, gen_loss = 0.9165618603583425, disc_loss = 0.0002192877534573275
Trained batch 768 in epoch 11, gen_loss = 0.9167377901480319, disc_loss = 0.0002198628873141711
Trained batch 769 in epoch 11, gen_loss = 0.9166931056357049, disc_loss = 0.00022022379094046123
Trained batch 770 in epoch 11, gen_loss = 0.9167162118100316, disc_loss = 0.00022016855682133594
Trained batch 771 in epoch 11, gen_loss = 0.9168346794466898, disc_loss = 0.00022014541441256962
Trained batch 772 in epoch 11, gen_loss = 0.9167921887023945, disc_loss = 0.00022012297547818283
Trained batch 773 in epoch 11, gen_loss = 0.9168397032629304, disc_loss = 0.00021997746266759312
Trained batch 774 in epoch 11, gen_loss = 0.916793546753545, disc_loss = 0.00021983379584027365
Trained batch 775 in epoch 11, gen_loss = 0.9166131551886342, disc_loss = 0.00021966892332671967
Trained batch 776 in epoch 11, gen_loss = 0.9165917778414036, disc_loss = 0.00021951006071493264
Trained batch 777 in epoch 11, gen_loss = 0.916528992603861, disc_loss = 0.00021935696056639208
Trained batch 778 in epoch 11, gen_loss = 0.916498544280428, disc_loss = 0.0002191611187701339
Trained batch 779 in epoch 11, gen_loss = 0.916543907385606, disc_loss = 0.00021909565719584068
Trained batch 780 in epoch 11, gen_loss = 0.916445873000405, disc_loss = 0.00021910984214721277
Trained batch 781 in epoch 11, gen_loss = 0.9163609492351942, disc_loss = 0.00021929873509344893
Trained batch 782 in epoch 11, gen_loss = 0.9164235594933365, disc_loss = 0.00022008594080887107
Trained batch 783 in epoch 11, gen_loss = 0.9163055476181361, disc_loss = 0.00022109346733319697
Trained batch 784 in epoch 11, gen_loss = 0.916280860885693, disc_loss = 0.00022250414365041662
Trained batch 785 in epoch 11, gen_loss = 0.916354238986969, disc_loss = 0.0002229868044568929
Trained batch 786 in epoch 11, gen_loss = 0.9161728193375177, disc_loss = 0.00022318274692881211
Trained batch 787 in epoch 11, gen_loss = 0.9161130258728405, disc_loss = 0.00022313529147888707
Trained batch 788 in epoch 11, gen_loss = 0.9163116965305972, disc_loss = 0.0002230571914518164
Trained batch 789 in epoch 11, gen_loss = 0.9161625607104241, disc_loss = 0.00022312384870111843
Trained batch 790 in epoch 11, gen_loss = 0.9160642364685213, disc_loss = 0.00022301771690816307
Trained batch 791 in epoch 11, gen_loss = 0.9160657216503163, disc_loss = 0.00022283727028737146
Trained batch 792 in epoch 11, gen_loss = 0.9158367446963153, disc_loss = 0.00022284547985014787
Trained batch 793 in epoch 11, gen_loss = 0.9156522873216673, disc_loss = 0.00022267954231238243
Trained batch 794 in epoch 11, gen_loss = 0.9155607663610447, disc_loss = 0.00022252931218113276
Trained batch 795 in epoch 11, gen_loss = 0.9156254813748987, disc_loss = 0.00022240721221776163
Trained batch 796 in epoch 11, gen_loss = 0.9158107324256801, disc_loss = 0.00022227174025466414
Trained batch 797 in epoch 11, gen_loss = 0.9158026279512802, disc_loss = 0.00022212721167781004
Trained batch 798 in epoch 11, gen_loss = 0.9157628712427333, disc_loss = 0.00022209737943647837
Trained batch 799 in epoch 11, gen_loss = 0.9156986919045448, disc_loss = 0.00022259580218360496
Trained batch 800 in epoch 11, gen_loss = 0.915610466631462, disc_loss = 0.00022259222762553824
Trained batch 801 in epoch 11, gen_loss = 0.9156309245084586, disc_loss = 0.00022243891939899838
Trained batch 802 in epoch 11, gen_loss = 0.9154611022059677, disc_loss = 0.00022249931216414336
Trained batch 803 in epoch 11, gen_loss = 0.9155135623999496, disc_loss = 0.0002223422001524662
Trained batch 804 in epoch 11, gen_loss = 0.9154326084237662, disc_loss = 0.00022222387703567286
Trained batch 805 in epoch 11, gen_loss = 0.9156414163171801, disc_loss = 0.0002223420056460495
Trained batch 806 in epoch 11, gen_loss = 0.9156763120802509, disc_loss = 0.00022247064630262226
Trained batch 807 in epoch 11, gen_loss = 0.9157209022357913, disc_loss = 0.00022282217874853454
Trained batch 808 in epoch 11, gen_loss = 0.9156494430912145, disc_loss = 0.00022315892971778254
Trained batch 809 in epoch 11, gen_loss = 0.9156488069045691, disc_loss = 0.00022311776519029397
Trained batch 810 in epoch 11, gen_loss = 0.9156155711919547, disc_loss = 0.00022322157220031438
Trained batch 811 in epoch 11, gen_loss = 0.9154867545284074, disc_loss = 0.0002235725995632685
Trained batch 812 in epoch 11, gen_loss = 0.9153852330069407, disc_loss = 0.00022381504298993823
Trained batch 813 in epoch 11, gen_loss = 0.915285044498467, disc_loss = 0.00022393495333427476
Trained batch 814 in epoch 11, gen_loss = 0.9151639257471985, disc_loss = 0.00022409854916462165
Trained batch 815 in epoch 11, gen_loss = 0.9151200200704968, disc_loss = 0.00022437555911910393
Trained batch 816 in epoch 11, gen_loss = 0.9152104196525116, disc_loss = 0.00022469782887923364
Trained batch 817 in epoch 11, gen_loss = 0.9151248661550742, disc_loss = 0.0002252182343075337
Trained batch 818 in epoch 11, gen_loss = 0.9151743769063472, disc_loss = 0.00022600794007356496
Trained batch 819 in epoch 11, gen_loss = 0.9151431251589844, disc_loss = 0.00022614377362404457
Trained batch 820 in epoch 11, gen_loss = 0.9151597971892966, disc_loss = 0.00022682567456744677
Trained batch 821 in epoch 11, gen_loss = 0.9151385189407933, disc_loss = 0.0002272306471867127
Trained batch 822 in epoch 11, gen_loss = 0.9150391401381278, disc_loss = 0.00022829323583119153
Trained batch 823 in epoch 11, gen_loss = 0.9150806937402892, disc_loss = 0.00022922911429066394
Trained batch 824 in epoch 11, gen_loss = 0.9150501298904419, disc_loss = 0.00022967202554079422
Trained batch 825 in epoch 11, gen_loss = 0.9148685732274598, disc_loss = 0.0002334389539528032
Trained batch 826 in epoch 11, gen_loss = 0.9149322720219751, disc_loss = 0.00023487756729392452
Trained batch 827 in epoch 11, gen_loss = 0.9149293750524521, disc_loss = 0.00023517587741686888
Trained batch 828 in epoch 11, gen_loss = 0.9149682779220103, disc_loss = 0.000235679212836185
Trained batch 829 in epoch 11, gen_loss = 0.9151200903467385, disc_loss = 0.00023576773911120554
Trained batch 830 in epoch 11, gen_loss = 0.9152140475352318, disc_loss = 0.0002356726522099691
Trained batch 831 in epoch 11, gen_loss = 0.9152739581723626, disc_loss = 0.00023551592709754215
Trained batch 832 in epoch 11, gen_loss = 0.9152954099129658, disc_loss = 0.00023562564512708174
Trained batch 833 in epoch 11, gen_loss = 0.915257585205906, disc_loss = 0.00023554538829535904
Trained batch 834 in epoch 11, gen_loss = 0.915398694869287, disc_loss = 0.00023550088512575292
Trained batch 835 in epoch 11, gen_loss = 0.9153409328614696, disc_loss = 0.00023536936530588404
Trained batch 836 in epoch 11, gen_loss = 0.9153669960752325, disc_loss = 0.00023525462773776103
Trained batch 837 in epoch 11, gen_loss = 0.9152253023337635, disc_loss = 0.00023539030606329006
Trained batch 838 in epoch 11, gen_loss = 0.9151734158450002, disc_loss = 0.0002353703477271792
Trained batch 839 in epoch 11, gen_loss = 0.9151029871333213, disc_loss = 0.00023540623851658893
Trained batch 840 in epoch 11, gen_loss = 0.9151628100347575, disc_loss = 0.00023534000644286044
Trained batch 841 in epoch 11, gen_loss = 0.9150960542385482, disc_loss = 0.00023521481304805678
Trained batch 842 in epoch 11, gen_loss = 0.9149449343217508, disc_loss = 0.00023532189728009563
Trained batch 843 in epoch 11, gen_loss = 0.914984168811432, disc_loss = 0.00023523282263375144
Trained batch 844 in epoch 11, gen_loss = 0.9149327618835946, disc_loss = 0.00023520827945132364
Trained batch 845 in epoch 11, gen_loss = 0.9150162173642052, disc_loss = 0.00023518483286044957
Trained batch 846 in epoch 11, gen_loss = 0.914921931421039, disc_loss = 0.00023523148718288518
Trained batch 847 in epoch 11, gen_loss = 0.9149785490249688, disc_loss = 0.00023519821040693232
Trained batch 848 in epoch 11, gen_loss = 0.914850493903997, disc_loss = 0.00023502702906443815
Trained batch 849 in epoch 11, gen_loss = 0.9148549705393174, disc_loss = 0.00023486215971762944
Trained batch 850 in epoch 11, gen_loss = 0.9149580667217806, disc_loss = 0.00023494388900675207
Trained batch 851 in epoch 11, gen_loss = 0.9149508241196753, disc_loss = 0.0002348184430410639
Trained batch 852 in epoch 11, gen_loss = 0.9148001756086719, disc_loss = 0.00023482618517971026
Trained batch 853 in epoch 11, gen_loss = 0.9149554600760306, disc_loss = 0.00023485913200110205
Trained batch 854 in epoch 11, gen_loss = 0.91504504806117, disc_loss = 0.00023490885474391647
Trained batch 855 in epoch 11, gen_loss = 0.915078054939475, disc_loss = 0.00023487779176703554
Trained batch 856 in epoch 11, gen_loss = 0.9152224609147988, disc_loss = 0.00023483738135404492
Trained batch 857 in epoch 11, gen_loss = 0.9153034790551468, disc_loss = 0.00023471060567974392
Trained batch 858 in epoch 11, gen_loss = 0.9152354830496525, disc_loss = 0.00023456489708140028
Trained batch 859 in epoch 11, gen_loss = 0.9151745031046313, disc_loss = 0.00023444547076546452
Trained batch 860 in epoch 11, gen_loss = 0.9150278898481709, disc_loss = 0.0002343773758121018
Trained batch 861 in epoch 11, gen_loss = 0.9149812094158474, disc_loss = 0.00023422746681588677
Trained batch 862 in epoch 11, gen_loss = 0.9149925854501691, disc_loss = 0.00023405241048863123
Trained batch 863 in epoch 11, gen_loss = 0.9149907424494073, disc_loss = 0.0002339299279415004
Trained batch 864 in epoch 11, gen_loss = 0.915011686603458, disc_loss = 0.00023374845552802588
Trained batch 865 in epoch 11, gen_loss = 0.9151340846239007, disc_loss = 0.00023366611696797607
Trained batch 866 in epoch 11, gen_loss = 0.9150946283972937, disc_loss = 0.00023361589456079263
Trained batch 867 in epoch 11, gen_loss = 0.9149720427764726, disc_loss = 0.00023344642276272004
Trained batch 868 in epoch 11, gen_loss = 0.9149382373680317, disc_loss = 0.00023331659479463668
Trained batch 869 in epoch 11, gen_loss = 0.91493416051755, disc_loss = 0.00023317789765869016
Trained batch 870 in epoch 11, gen_loss = 0.9150412757415859, disc_loss = 0.00023308235932117884
Trained batch 871 in epoch 11, gen_loss = 0.9150922713339875, disc_loss = 0.0002330117607083043
Trained batch 872 in epoch 11, gen_loss = 0.91503596654053, disc_loss = 0.0002329728985890383
Trained batch 873 in epoch 11, gen_loss = 0.9150854187508197, disc_loss = 0.0002328456897722854
Trained batch 874 in epoch 11, gen_loss = 0.9150592258998326, disc_loss = 0.00023279825294074337
Trained batch 875 in epoch 11, gen_loss = 0.9151219352739587, disc_loss = 0.00023260670712502214
Trained batch 876 in epoch 11, gen_loss = 0.915061426407391, disc_loss = 0.00023260534657572264
Trained batch 877 in epoch 11, gen_loss = 0.914971494321671, disc_loss = 0.00023255927999033077
Trained batch 878 in epoch 11, gen_loss = 0.9150363547267631, disc_loss = 0.0002325039738715365
Trained batch 879 in epoch 11, gen_loss = 0.9151116495782678, disc_loss = 0.00023256693432978698
Trained batch 880 in epoch 11, gen_loss = 0.9149896267729639, disc_loss = 0.00023260029154742072
Trained batch 881 in epoch 11, gen_loss = 0.9150534465469741, disc_loss = 0.00023253379286971822
Trained batch 882 in epoch 11, gen_loss = 0.9150321856900493, disc_loss = 0.00023239139347057815
Trained batch 883 in epoch 11, gen_loss = 0.9150929566287347, disc_loss = 0.00023222468677157936
Trained batch 884 in epoch 11, gen_loss = 0.9150504276577363, disc_loss = 0.00023209246614665756
Trained batch 885 in epoch 11, gen_loss = 0.9149470930713025, disc_loss = 0.00023191336797650575
Trained batch 886 in epoch 11, gen_loss = 0.914925112799566, disc_loss = 0.00023177626334541432
Trained batch 887 in epoch 11, gen_loss = 0.9148118862429181, disc_loss = 0.0002316132874085753
Trained batch 888 in epoch 11, gen_loss = 0.9146609519544415, disc_loss = 0.0002315153807656815
Trained batch 889 in epoch 11, gen_loss = 0.9145901820632849, disc_loss = 0.0002314127596159625
Trained batch 890 in epoch 11, gen_loss = 0.9144287245174584, disc_loss = 0.00023133883861813502
Trained batch 891 in epoch 11, gen_loss = 0.9144966226121235, disc_loss = 0.00023119870550263462
Trained batch 892 in epoch 11, gen_loss = 0.9144680099551381, disc_loss = 0.00023123594357563399
Trained batch 893 in epoch 11, gen_loss = 0.9144534508653935, disc_loss = 0.00023112807205037116
Trained batch 894 in epoch 11, gen_loss = 0.9145090070516704, disc_loss = 0.00023104358982251223
Trained batch 895 in epoch 11, gen_loss = 0.9144984743823963, disc_loss = 0.00023091516272951855
Trained batch 896 in epoch 11, gen_loss = 0.9144173926998806, disc_loss = 0.00023079836540526466
Trained batch 897 in epoch 11, gen_loss = 0.9143799622366848, disc_loss = 0.00023074816617695847
Trained batch 898 in epoch 11, gen_loss = 0.9143053128138533, disc_loss = 0.00023070279503341798
Trained batch 899 in epoch 11, gen_loss = 0.9141989526483748, disc_loss = 0.00023063059450376184
Trained batch 900 in epoch 11, gen_loss = 0.9142182900029732, disc_loss = 0.0002306063169706574
Trained batch 901 in epoch 11, gen_loss = 0.9142519088251363, disc_loss = 0.0002305498744403758
Trained batch 902 in epoch 11, gen_loss = 0.9141586068460712, disc_loss = 0.00023041011200105056
Trained batch 903 in epoch 11, gen_loss = 0.9141149892084366, disc_loss = 0.00023028226494523196
Trained batch 904 in epoch 11, gen_loss = 0.914066992280233, disc_loss = 0.00023015245217755976
Trained batch 905 in epoch 11, gen_loss = 0.914121576821304, disc_loss = 0.00023003148524499643
Trained batch 906 in epoch 11, gen_loss = 0.9140218393805272, disc_loss = 0.00023005059312424127
Trained batch 907 in epoch 11, gen_loss = 0.9140205060332882, disc_loss = 0.00022998336892705672
Trained batch 908 in epoch 11, gen_loss = 0.9139410742569809, disc_loss = 0.0002298658778237492
Trained batch 909 in epoch 11, gen_loss = 0.9140220637504871, disc_loss = 0.00022988735813219587
Trained batch 910 in epoch 11, gen_loss = 0.9139887279658103, disc_loss = 0.00022979003016368086
Trained batch 911 in epoch 11, gen_loss = 0.9140305722361071, disc_loss = 0.00022972184673993693
Trained batch 912 in epoch 11, gen_loss = 0.9139388170325874, disc_loss = 0.00022966553748868736
Trained batch 913 in epoch 11, gen_loss = 0.9138991069089402, disc_loss = 0.00022949023972757958
Trained batch 914 in epoch 11, gen_loss = 0.9138518403788082, disc_loss = 0.00022956845178405622
Trained batch 915 in epoch 11, gen_loss = 0.9138723480389108, disc_loss = 0.00022949837533831185
Trained batch 916 in epoch 11, gen_loss = 0.913926729459149, disc_loss = 0.00022936189640443514
Trained batch 917 in epoch 11, gen_loss = 0.9139842261156486, disc_loss = 0.00022935058721225158
Trained batch 918 in epoch 11, gen_loss = 0.9139885203233871, disc_loss = 0.00022932481011204138
Trained batch 919 in epoch 11, gen_loss = 0.9140543880669967, disc_loss = 0.00022927143917632234
Trained batch 920 in epoch 11, gen_loss = 0.914079869479491, disc_loss = 0.00022925644050733122
Trained batch 921 in epoch 11, gen_loss = 0.913964242454206, disc_loss = 0.00022912961923829284
Trained batch 922 in epoch 11, gen_loss = 0.9139896753937297, disc_loss = 0.00022900003485036897
Trained batch 923 in epoch 11, gen_loss = 0.9139042427658519, disc_loss = 0.00022888533981111646
Trained batch 924 in epoch 11, gen_loss = 0.9137791893288896, disc_loss = 0.00022873592571232695
Trained batch 925 in epoch 11, gen_loss = 0.9138702870573905, disc_loss = 0.0002285902083942983
Trained batch 926 in epoch 11, gen_loss = 0.9136401513247814, disc_loss = 0.00022908643593232673
Trained batch 927 in epoch 11, gen_loss = 0.9136726548574094, disc_loss = 0.00022919401127919942
Trained batch 928 in epoch 11, gen_loss = 0.9137578151069493, disc_loss = 0.00022921933379642433
Trained batch 929 in epoch 11, gen_loss = 0.9136827220198929, disc_loss = 0.00022917345064264716
Trained batch 930 in epoch 11, gen_loss = 0.9136449994257262, disc_loss = 0.00022906059723250017
Trained batch 931 in epoch 11, gen_loss = 0.9136270171455048, disc_loss = 0.00022904601344385194
Trained batch 932 in epoch 11, gen_loss = 0.9136268270360696, disc_loss = 0.00022892554921627974
Trained batch 933 in epoch 11, gen_loss = 0.9135390434581667, disc_loss = 0.00022883142975075604
Trained batch 934 in epoch 11, gen_loss = 0.9136769538257211, disc_loss = 0.00022891964775464686
Trained batch 935 in epoch 11, gen_loss = 0.9135547964236675, disc_loss = 0.0002288609730735166
Trained batch 936 in epoch 11, gen_loss = 0.9134402543528993, disc_loss = 0.00022875743689064086
Trained batch 937 in epoch 11, gen_loss = 0.9134777223885949, disc_loss = 0.00022875465217901187
Trained batch 938 in epoch 11, gen_loss = 0.9134225698070912, disc_loss = 0.0002286314541072358
Trained batch 939 in epoch 11, gen_loss = 0.9133221482342863, disc_loss = 0.00022864049159134663
Trained batch 940 in epoch 11, gen_loss = 0.9131716627243601, disc_loss = 0.00022867235646689658
Trained batch 941 in epoch 11, gen_loss = 0.9129807046138051, disc_loss = 0.00022861944053301933
Trained batch 942 in epoch 11, gen_loss = 0.9129722883820155, disc_loss = 0.00022871887128028453
Trained batch 943 in epoch 11, gen_loss = 0.9128275283817517, disc_loss = 0.00022864062006485288
Trained batch 944 in epoch 11, gen_loss = 0.9130156221843901, disc_loss = 0.00022904960735883962
Trained batch 945 in epoch 11, gen_loss = 0.9128849925374883, disc_loss = 0.00022931826895317107
Trained batch 946 in epoch 11, gen_loss = 0.9128599938520534, disc_loss = 0.00022942455913154227
Trained batch 947 in epoch 11, gen_loss = 0.9128398911610938, disc_loss = 0.0002294358362878522
Trained batch 948 in epoch 11, gen_loss = 0.9128625498430998, disc_loss = 0.0002294538764518161
Trained batch 949 in epoch 11, gen_loss = 0.9128104333501114, disc_loss = 0.00022944478249548028
Trained batch 950 in epoch 11, gen_loss = 0.9129184892500989, disc_loss = 0.00022945271811860448
Trained batch 951 in epoch 11, gen_loss = 0.9128907488799897, disc_loss = 0.00022945076108892658
Trained batch 952 in epoch 11, gen_loss = 0.9128101570033327, disc_loss = 0.00022943686371611639
Trained batch 953 in epoch 11, gen_loss = 0.912851569662554, disc_loss = 0.0002293725790713967
Trained batch 954 in epoch 11, gen_loss = 0.9129999467839746, disc_loss = 0.0002295720142792942
Trained batch 955 in epoch 11, gen_loss = 0.9128248695299715, disc_loss = 0.00022970628302482128
Trained batch 956 in epoch 11, gen_loss = 0.9129467122607097, disc_loss = 0.00022959867614952634
Trained batch 957 in epoch 11, gen_loss = 0.912934975982459, disc_loss = 0.000229525840094043
Trained batch 958 in epoch 11, gen_loss = 0.9128920738590149, disc_loss = 0.00022937319157870288
Trained batch 959 in epoch 11, gen_loss = 0.9127580052862565, disc_loss = 0.00022942570256342758
Trained batch 960 in epoch 11, gen_loss = 0.9127901701971842, disc_loss = 0.0002294415357705527
Trained batch 961 in epoch 11, gen_loss = 0.9127753592578388, disc_loss = 0.00022931904054237525
Trained batch 962 in epoch 11, gen_loss = 0.9126411478343659, disc_loss = 0.0002292210284599912
Trained batch 963 in epoch 11, gen_loss = 0.9125698697270199, disc_loss = 0.0002291040485399653
Trained batch 964 in epoch 11, gen_loss = 0.9124848342312433, disc_loss = 0.00022903452871275048
Trained batch 965 in epoch 11, gen_loss = 0.9124547533737206, disc_loss = 0.0002289200333177797
Trained batch 966 in epoch 11, gen_loss = 0.9124769450713338, disc_loss = 0.00022883000043912447
Trained batch 967 in epoch 11, gen_loss = 0.9124235087189793, disc_loss = 0.00022873832184145125
Trained batch 968 in epoch 11, gen_loss = 0.9123408854684347, disc_loss = 0.00022864685263533372
Trained batch 969 in epoch 11, gen_loss = 0.9123879158619753, disc_loss = 0.000228575116537839
Trained batch 970 in epoch 11, gen_loss = 0.9123577121971319, disc_loss = 0.0002284930467571841
Trained batch 971 in epoch 11, gen_loss = 0.9124679331794198, disc_loss = 0.00022839744207227085
Trained batch 972 in epoch 11, gen_loss = 0.9123740318745283, disc_loss = 0.00022828929339426538
Trained batch 973 in epoch 11, gen_loss = 0.9124070845345452, disc_loss = 0.00022817375508250713
Trained batch 974 in epoch 11, gen_loss = 0.9124248498525375, disc_loss = 0.0002280616734321647
Trained batch 975 in epoch 11, gen_loss = 0.9122926167777328, disc_loss = 0.0002279782834305434
Trained batch 976 in epoch 11, gen_loss = 0.9121588262345188, disc_loss = 0.00022784327574557685
Trained batch 977 in epoch 11, gen_loss = 0.9120054715493949, disc_loss = 0.0002277150821037567
Trained batch 978 in epoch 11, gen_loss = 0.9119826631964897, disc_loss = 0.0002275455327111116
Trained batch 979 in epoch 11, gen_loss = 0.9119312639747347, disc_loss = 0.00022740501547615372
Trained batch 980 in epoch 11, gen_loss = 0.9119752957186568, disc_loss = 0.0002273806990971886
Trained batch 981 in epoch 11, gen_loss = 0.9120470492393082, disc_loss = 0.00022744351099205536
Trained batch 982 in epoch 11, gen_loss = 0.9120330096261304, disc_loss = 0.00022739453106531318
Trained batch 983 in epoch 11, gen_loss = 0.9119501010916098, disc_loss = 0.00022730208134018494
Trained batch 984 in epoch 11, gen_loss = 0.9119100698359727, disc_loss = 0.00022713720986042242
Trained batch 985 in epoch 11, gen_loss = 0.9120201091858243, disc_loss = 0.00022709979698659722
Trained batch 986 in epoch 11, gen_loss = 0.91200855739694, disc_loss = 0.00022701405417966126
Trained batch 987 in epoch 11, gen_loss = 0.9118705184353508, disc_loss = 0.00022702455334209243
Trained batch 988 in epoch 11, gen_loss = 0.9117486102033795, disc_loss = 0.00022691642026692046
Trained batch 989 in epoch 11, gen_loss = 0.9118261597373268, disc_loss = 0.0002268622996265861
Trained batch 990 in epoch 11, gen_loss = 0.9118080840462032, disc_loss = 0.0002269648036328471
Trained batch 991 in epoch 11, gen_loss = 0.911848692463771, disc_loss = 0.00022689649017226452
Trained batch 992 in epoch 11, gen_loss = 0.9118871370711236, disc_loss = 0.00022694218687787358
Trained batch 993 in epoch 11, gen_loss = 0.9117930476934137, disc_loss = 0.00022693575280372422
Trained batch 994 in epoch 11, gen_loss = 0.9116746993520152, disc_loss = 0.00022684395335273626
Trained batch 995 in epoch 11, gen_loss = 0.911509411880769, disc_loss = 0.00022686583969951164
Trained batch 996 in epoch 11, gen_loss = 0.9114523235271305, disc_loss = 0.00022696148472691095
Trained batch 997 in epoch 11, gen_loss = 0.9114801869960968, disc_loss = 0.0002269592431127124
Trained batch 998 in epoch 11, gen_loss = 0.9114234193905935, disc_loss = 0.000226869112520216
Trained batch 999 in epoch 11, gen_loss = 0.9113600850701332, disc_loss = 0.0002268155319216021
Trained batch 1000 in epoch 11, gen_loss = 0.9113514435874832, disc_loss = 0.00022672912143264454
Trained batch 1001 in epoch 11, gen_loss = 0.9113508389738505, disc_loss = 0.000226609864644805
Trained batch 1002 in epoch 11, gen_loss = 0.9113428923686742, disc_loss = 0.00022647718541305684
Trained batch 1003 in epoch 11, gen_loss = 0.9113519007110026, disc_loss = 0.00022635524295533304
Trained batch 1004 in epoch 11, gen_loss = 0.9112997852154632, disc_loss = 0.0002265697193645643
Trained batch 1005 in epoch 11, gen_loss = 0.9110987341664657, disc_loss = 0.00022651093145602713
Trained batch 1006 in epoch 11, gen_loss = 0.9110807290498645, disc_loss = 0.00022644753073123764
Trained batch 1007 in epoch 11, gen_loss = 0.9111091578527103, disc_loss = 0.0002263668755165868
Trained batch 1008 in epoch 11, gen_loss = 0.9109839212788108, disc_loss = 0.00022651085260954023
Trained batch 1009 in epoch 11, gen_loss = 0.9110654475665328, disc_loss = 0.00022668839434244196
Trained batch 1010 in epoch 11, gen_loss = 0.9111064506213814, disc_loss = 0.0002265764169612198
Trained batch 1011 in epoch 11, gen_loss = 0.9110191955632372, disc_loss = 0.00022648931868971263
Trained batch 1012 in epoch 11, gen_loss = 0.9109286352300691, disc_loss = 0.00022643492707152582
Trained batch 1013 in epoch 11, gen_loss = 0.9108810069763214, disc_loss = 0.0002263794899617629
Trained batch 1014 in epoch 11, gen_loss = 0.9109041053673317, disc_loss = 0.00022629108664529797
Trained batch 1015 in epoch 11, gen_loss = 0.9107597572362329, disc_loss = 0.00022628186524178908
Trained batch 1016 in epoch 11, gen_loss = 0.9107317876440703, disc_loss = 0.00022618280428259922
Trained batch 1017 in epoch 11, gen_loss = 0.9107616461213305, disc_loss = 0.00022603027957020084
Trained batch 1018 in epoch 11, gen_loss = 0.9107775177525117, disc_loss = 0.00022588596457764128
Trained batch 1019 in epoch 11, gen_loss = 0.9107153544823329, disc_loss = 0.00022580180558340063
Trained batch 1020 in epoch 11, gen_loss = 0.910607327735389, disc_loss = 0.00022571224748261522
Trained batch 1021 in epoch 11, gen_loss = 0.9105034073388273, disc_loss = 0.00022559431217565387
Trained batch 1022 in epoch 11, gen_loss = 0.9105028410461291, disc_loss = 0.00022547681656135687
Trained batch 1023 in epoch 11, gen_loss = 0.9104333991999738, disc_loss = 0.00022534147005259797
Trained batch 1024 in epoch 11, gen_loss = 0.9104292335161349, disc_loss = 0.00022520799796372403
Trained batch 1025 in epoch 11, gen_loss = 0.910280293598045, disc_loss = 0.00022515736155684054
Trained batch 1026 in epoch 11, gen_loss = 0.9101984563565649, disc_loss = 0.00022503453851707516
Trained batch 1027 in epoch 11, gen_loss = 0.9101659028794515, disc_loss = 0.0002249999994367956
Trained batch 1028 in epoch 11, gen_loss = 0.9101635123249161, disc_loss = 0.0002250321325230848
Trained batch 1029 in epoch 11, gen_loss = 0.9101121994476874, disc_loss = 0.00022508785948657445
Trained batch 1030 in epoch 11, gen_loss = 0.9101355901976215, disc_loss = 0.0002249879552402647
Trained batch 1031 in epoch 11, gen_loss = 0.9101001986468485, disc_loss = 0.000224903300086014
Trained batch 1032 in epoch 11, gen_loss = 0.9100292224620918, disc_loss = 0.00022483229054181904
Trained batch 1033 in epoch 11, gen_loss = 0.9101367604916977, disc_loss = 0.0002247752622283585
Trained batch 1034 in epoch 11, gen_loss = 0.9100744489886334, disc_loss = 0.00022469541203955543
Trained batch 1035 in epoch 11, gen_loss = 0.9100977749092699, disc_loss = 0.00022461051432408314
Trained batch 1036 in epoch 11, gen_loss = 0.9101933872573286, disc_loss = 0.0002246421952746782
Trained batch 1037 in epoch 11, gen_loss = 0.9100469032119465, disc_loss = 0.00022468598072430203
Trained batch 1038 in epoch 11, gen_loss = 0.9099087144344099, disc_loss = 0.00022461961050302393
Trained batch 1039 in epoch 11, gen_loss = 0.9099092927689736, disc_loss = 0.00022451164698115742
Trained batch 1040 in epoch 11, gen_loss = 0.9097564517020263, disc_loss = 0.00022460690095396573
Trained batch 1041 in epoch 11, gen_loss = 0.909836429208803, disc_loss = 0.00022458840048819535
Trained batch 1042 in epoch 11, gen_loss = 0.9097663279576361, disc_loss = 0.00022449702914693832
Trained batch 1043 in epoch 11, gen_loss = 0.9097591274314456, disc_loss = 0.0002244617848909249
Trained batch 1044 in epoch 11, gen_loss = 0.9097408512562656, disc_loss = 0.0002244081927576764
Trained batch 1045 in epoch 11, gen_loss = 0.9097468221620666, disc_loss = 0.0002248745821752213
Trained batch 1046 in epoch 11, gen_loss = 0.9094343292451292, disc_loss = 0.00040731063614456083
Trained batch 1047 in epoch 11, gen_loss = 0.909768839260094, disc_loss = 0.0009066123448377322
Trained batch 1048 in epoch 11, gen_loss = 0.9098894277905373, disc_loss = 0.0009600837913501794
Trained batch 1049 in epoch 11, gen_loss = 0.910015560558864, disc_loss = 0.0010114807469342071
Trained batch 1050 in epoch 11, gen_loss = 0.9100720484862432, disc_loss = 0.0010669045196905664
Trained batch 1051 in epoch 11, gen_loss = 0.9100890752820461, disc_loss = 0.0010987362010462178
Trained batch 1052 in epoch 11, gen_loss = 0.9101313632211567, disc_loss = 0.001123774914587232
Trained batch 1053 in epoch 11, gen_loss = 0.9103060326268596, disc_loss = 0.0011418046197026208
Trained batch 1054 in epoch 11, gen_loss = 0.910379916796752, disc_loss = 0.0011612700724468613
Trained batch 1055 in epoch 11, gen_loss = 0.9103940625985464, disc_loss = 0.0011724164847574877
Trained batch 1056 in epoch 11, gen_loss = 0.9104721619480606, disc_loss = 0.0011790384881763356
Trained batch 1057 in epoch 11, gen_loss = 0.9105225873579375, disc_loss = 0.0011827281004252053
Trained batch 1058 in epoch 11, gen_loss = 0.9107275797129804, disc_loss = 0.0011861723989819194
Trained batch 1059 in epoch 11, gen_loss = 0.9107073278921956, disc_loss = 0.0011887743702384298
Trained batch 1060 in epoch 11, gen_loss = 0.9107119523613775, disc_loss = 0.0011916579632674184
Trained batch 1061 in epoch 11, gen_loss = 0.910667461751769, disc_loss = 0.0011972723695027883
Trained batch 1062 in epoch 11, gen_loss = 0.9105942729275291, disc_loss = 0.0012044691516282
Trained batch 1063 in epoch 11, gen_loss = 0.9106239987383211, disc_loss = 0.001208584310796524
Trained batch 1064 in epoch 11, gen_loss = 0.9107947252725771, disc_loss = 0.0012095226484405241
Trained batch 1065 in epoch 11, gen_loss = 0.9108449066893021, disc_loss = 0.0012132626022166068
Trained batch 1066 in epoch 11, gen_loss = 0.9110013207991545, disc_loss = 0.0012147012432998047
Trained batch 1067 in epoch 11, gen_loss = 0.911156341991621, disc_loss = 0.00122027178836634
Trained batch 1068 in epoch 11, gen_loss = 0.9112047004967343, disc_loss = 0.0012285052803146551
Trained batch 1069 in epoch 11, gen_loss = 0.9112481236457824, disc_loss = 0.0012314009388888888
Trained batch 1070 in epoch 11, gen_loss = 0.9112080974516525, disc_loss = 0.0012348379368580915
Trained batch 1071 in epoch 11, gen_loss = 0.9111055858544449, disc_loss = 0.0012409525911369933
Trained batch 1072 in epoch 11, gen_loss = 0.9110166825985975, disc_loss = 0.0012476440052232951
Trained batch 1073 in epoch 11, gen_loss = 0.9110889365442194, disc_loss = 0.0012501728698518636
Trained batch 1074 in epoch 11, gen_loss = 0.9111361556274946, disc_loss = 0.001254374811999083
Trained batch 1075 in epoch 11, gen_loss = 0.9109821453081187, disc_loss = 0.0012833561867812368
Trained batch 1076 in epoch 11, gen_loss = 0.9111566960313526, disc_loss = 0.0013023097156375954
Trained batch 1077 in epoch 11, gen_loss = 0.911222403036199, disc_loss = 0.0013187026219796
Trained batch 1078 in epoch 11, gen_loss = 0.9113342098000979, disc_loss = 0.0013253768402027633
Trained batch 1079 in epoch 11, gen_loss = 0.9113806926541859, disc_loss = 0.0013507168972965802
Trained batch 1080 in epoch 11, gen_loss = 0.9114630743930121, disc_loss = 0.001371392350443754
Trained batch 1081 in epoch 11, gen_loss = 0.9112724398508971, disc_loss = 0.0013965237326332308
Trained batch 1082 in epoch 11, gen_loss = 0.9115113298428466, disc_loss = 0.001419788963469888
Trained batch 1083 in epoch 11, gen_loss = 0.9116319884233369, disc_loss = 0.0014329241404953535
Trained batch 1084 in epoch 11, gen_loss = 0.911740732852215, disc_loss = 0.0014359144442536373
Trained batch 1085 in epoch 11, gen_loss = 0.9118690918822315, disc_loss = 0.0014395215612993278
Trained batch 1086 in epoch 11, gen_loss = 0.9118932633084119, disc_loss = 0.0014416254453355197
Trained batch 1087 in epoch 11, gen_loss = 0.9120065056554535, disc_loss = 0.0014432761608552081
Trained batch 1088 in epoch 11, gen_loss = 0.9120400731885401, disc_loss = 0.001447251383430461
Trained batch 1089 in epoch 11, gen_loss = 0.9120133267083299, disc_loss = 0.001454448017703317
Trained batch 1090 in epoch 11, gen_loss = 0.9120941187786903, disc_loss = 0.0014562126194541934
Trained batch 1091 in epoch 11, gen_loss = 0.9121583586101567, disc_loss = 0.001457411657274894
Trained batch 1092 in epoch 11, gen_loss = 0.912220786878633, disc_loss = 0.00145871389900248
Trained batch 1093 in epoch 11, gen_loss = 0.9122590381223061, disc_loss = 0.0014588113102167357
Trained batch 1094 in epoch 11, gen_loss = 0.9121869775258242, disc_loss = 0.0014623613581671348
Trained batch 1095 in epoch 11, gen_loss = 0.9121282811473755, disc_loss = 0.0014649904205692567
Trained batch 1096 in epoch 11, gen_loss = 0.912145370826356, disc_loss = 0.0014648282027808614
Trained batch 1097 in epoch 11, gen_loss = 0.912125860569907, disc_loss = 0.0014653797749230773
Trained batch 1098 in epoch 11, gen_loss = 0.9122069813209409, disc_loss = 0.001465664086305553
Trained batch 1099 in epoch 11, gen_loss = 0.912163901925087, disc_loss = 0.001465838134976035
Trained batch 1100 in epoch 11, gen_loss = 0.9122396790905501, disc_loss = 0.0014654815757067883
Trained batch 1101 in epoch 11, gen_loss = 0.9121549262000948, disc_loss = 0.0014657691300154641
Trained batch 1102 in epoch 11, gen_loss = 0.912326772809569, disc_loss = 0.001466503239657023
Trained batch 1103 in epoch 11, gen_loss = 0.9123475864205671, disc_loss = 0.0014662908878912328
Trained batch 1104 in epoch 11, gen_loss = 0.9123896730971013, disc_loss = 0.001465876434720411
Trained batch 1105 in epoch 11, gen_loss = 0.9124235961363932, disc_loss = 0.0014654332649896742
Trained batch 1106 in epoch 11, gen_loss = 0.9123368565844542, disc_loss = 0.0014645847144034573
Trained batch 1107 in epoch 11, gen_loss = 0.912353158104721, disc_loss = 0.0014636405147075986
Trained batch 1108 in epoch 11, gen_loss = 0.9124541762070789, disc_loss = 0.001462794895929017
Trained batch 1109 in epoch 11, gen_loss = 0.9125227690280021, disc_loss = 0.001462329784418044
Trained batch 1110 in epoch 11, gen_loss = 0.9125971341862752, disc_loss = 0.001461953652569743
Trained batch 1111 in epoch 11, gen_loss = 0.9125507699607087, disc_loss = 0.0014611406764029951
Trained batch 1112 in epoch 11, gen_loss = 0.9126264118762671, disc_loss = 0.0014602975920568354
Trained batch 1113 in epoch 11, gen_loss = 0.9126765438534413, disc_loss = 0.0014594579444267013
Trained batch 1114 in epoch 11, gen_loss = 0.9126842898103689, disc_loss = 0.0014585661556828305
Trained batch 1115 in epoch 11, gen_loss = 0.9127419579734084, disc_loss = 0.001457593839958753
Trained batch 1116 in epoch 11, gen_loss = 0.9127459649326765, disc_loss = 0.0014573851134621544
Trained batch 1117 in epoch 11, gen_loss = 0.9127237185276045, disc_loss = 0.001457035333652245
Trained batch 1118 in epoch 11, gen_loss = 0.9127079903067383, disc_loss = 0.0014571096424973984
Trained batch 1119 in epoch 11, gen_loss = 0.912670101704342, disc_loss = 0.0014567098361599814
Trained batch 1120 in epoch 11, gen_loss = 0.9127784555347555, disc_loss = 0.0014560237632086697
Trained batch 1121 in epoch 11, gen_loss = 0.9128776505562923, disc_loss = 0.0014552036614263661
Trained batch 1122 in epoch 11, gen_loss = 0.912904242532973, disc_loss = 0.0014547312873113103
Trained batch 1123 in epoch 11, gen_loss = 0.912898457188199, disc_loss = 0.0014543355783122975
Trained batch 1124 in epoch 11, gen_loss = 0.9129861294958327, disc_loss = 0.001455150314461207
Trained batch 1125 in epoch 11, gen_loss = 0.9129635010900549, disc_loss = 0.001455272013237335
Trained batch 1126 in epoch 11, gen_loss = 0.9130679967663621, disc_loss = 0.0014553410980964652
Trained batch 1127 in epoch 11, gen_loss = 0.9130267759798266, disc_loss = 0.001454552471464109
Trained batch 1128 in epoch 11, gen_loss = 0.9130814340496823, disc_loss = 0.001454117293194681
Trained batch 1129 in epoch 11, gen_loss = 0.9129907062623354, disc_loss = 0.0014545003432399064
Trained batch 1130 in epoch 11, gen_loss = 0.9129530905517828, disc_loss = 0.001454543727060349
Trained batch 1131 in epoch 11, gen_loss = 0.9129129450228526, disc_loss = 0.0014604431829699255
Trained batch 1132 in epoch 11, gen_loss = 0.9130254564091682, disc_loss = 0.0014618382399253346
Trained batch 1133 in epoch 11, gen_loss = 0.9129456365234637, disc_loss = 0.0014623737069948302
Trained batch 1134 in epoch 11, gen_loss = 0.9130101452840057, disc_loss = 0.0014618053225207291
Trained batch 1135 in epoch 11, gen_loss = 0.912958052481564, disc_loss = 0.0014636641720686308
Trained batch 1136 in epoch 11, gen_loss = 0.9130461291461632, disc_loss = 0.001463685966050718
Trained batch 1137 in epoch 11, gen_loss = 0.9130585597458121, disc_loss = 0.0014633535241242652
Trained batch 1138 in epoch 11, gen_loss = 0.913117525345197, disc_loss = 0.0014625584886237785
Trained batch 1139 in epoch 11, gen_loss = 0.9131745384450545, disc_loss = 0.0014615726960600067
Trained batch 1140 in epoch 11, gen_loss = 0.9131642169434182, disc_loss = 0.0014616308343552832
Trained batch 1141 in epoch 11, gen_loss = 0.9131733325233393, disc_loss = 0.0014609362454707487
Trained batch 1142 in epoch 11, gen_loss = 0.9130916457789464, disc_loss = 0.0014600745467658284
Trained batch 1143 in epoch 11, gen_loss = 0.9132056102886067, disc_loss = 0.001459550798318032
Trained batch 1144 in epoch 11, gen_loss = 0.9132533249376122, disc_loss = 0.0014594059990200175
Trained batch 1145 in epoch 11, gen_loss = 0.9132758402907619, disc_loss = 0.0014587828769613645
Trained batch 1146 in epoch 11, gen_loss = 0.9132289273279485, disc_loss = 0.0014581409944929562
Trained batch 1147 in epoch 11, gen_loss = 0.9132744306990493, disc_loss = 0.001457062669204018
Trained batch 1148 in epoch 11, gen_loss = 0.9132820412944564, disc_loss = 0.0014560464701053309
Trained batch 1149 in epoch 11, gen_loss = 0.9133077728748321, disc_loss = 0.0014552514531754677
Trained batch 1150 in epoch 11, gen_loss = 0.9132463503256764, disc_loss = 0.0014548325042392188
Trained batch 1151 in epoch 11, gen_loss = 0.9132363172248006, disc_loss = 0.001455374565703475
Trained batch 1152 in epoch 11, gen_loss = 0.9133166349771636, disc_loss = 0.0014551648159546674
Trained batch 1153 in epoch 11, gen_loss = 0.9133263831535287, disc_loss = 0.001455172534109967
Trained batch 1154 in epoch 11, gen_loss = 0.91331603795419, disc_loss = 0.0014542708820324479
Trained batch 1155 in epoch 11, gen_loss = 0.9133013263086959, disc_loss = 0.001453384164476236
Trained batch 1156 in epoch 11, gen_loss = 0.9132436199134655, disc_loss = 0.001452819769622857
Trained batch 1157 in epoch 11, gen_loss = 0.9133708440475101, disc_loss = 0.0014521908513491237
Trained batch 1158 in epoch 11, gen_loss = 0.9133541066138471, disc_loss = 0.0014512109589333636
Trained batch 1159 in epoch 11, gen_loss = 0.9134222766962544, disc_loss = 0.0014503947052554426
Trained batch 1160 in epoch 11, gen_loss = 0.9134874787441519, disc_loss = 0.001449424591897276
Trained batch 1161 in epoch 11, gen_loss = 0.9134087062436004, disc_loss = 0.0014485795542712933
Trained batch 1162 in epoch 11, gen_loss = 0.9133839825567047, disc_loss = 0.001447830753241539
Trained batch 1163 in epoch 11, gen_loss = 0.9133808227236738, disc_loss = 0.0014469514862710802
Trained batch 1164 in epoch 11, gen_loss = 0.9133378103567296, disc_loss = 0.0014464523083006497
Trained batch 1165 in epoch 11, gen_loss = 0.913299390269798, disc_loss = 0.0014458705138719965
Trained batch 1166 in epoch 11, gen_loss = 0.9132991204327155, disc_loss = 0.0014453699940622988
Trained batch 1167 in epoch 11, gen_loss = 0.9133520582052943, disc_loss = 0.0014446718950120942
Trained batch 1168 in epoch 11, gen_loss = 0.9133296754749746, disc_loss = 0.0014443174675106752
Trained batch 1169 in epoch 11, gen_loss = 0.9133140369867667, disc_loss = 0.001443428499907087
Trained batch 1170 in epoch 11, gen_loss = 0.9132038411882369, disc_loss = 0.0014427307216385902
Trained batch 1171 in epoch 11, gen_loss = 0.9131836989837295, disc_loss = 0.0014416883277683509
Trained batch 1172 in epoch 11, gen_loss = 0.9132289298050239, disc_loss = 0.0014409367103119055
Trained batch 1173 in epoch 11, gen_loss = 0.9131957162584113, disc_loss = 0.0014399334256068176
Trained batch 1174 in epoch 11, gen_loss = 0.9131445844122704, disc_loss = 0.001439064430116869
Trained batch 1175 in epoch 11, gen_loss = 0.9132335806379512, disc_loss = 0.0014382722495079148
Trained batch 1176 in epoch 11, gen_loss = 0.9132446362087052, disc_loss = 0.0014378005227500274
Trained batch 1177 in epoch 11, gen_loss = 0.9131797943738604, disc_loss = 0.0014371702900786236
Trained batch 1178 in epoch 11, gen_loss = 0.9131553369725125, disc_loss = 0.0014362497856086655
Trained batch 1179 in epoch 11, gen_loss = 0.9130966459290456, disc_loss = 0.0014354330567307365
Trained batch 1180 in epoch 11, gen_loss = 0.912987794440041, disc_loss = 0.0014381843827278985
Trained batch 1181 in epoch 11, gen_loss = 0.9131723630246777, disc_loss = 0.0014381624021186593
Trained batch 1182 in epoch 11, gen_loss = 0.9131171549162619, disc_loss = 0.0014381232772251332
Trained batch 1183 in epoch 11, gen_loss = 0.9132841578810602, disc_loss = 0.0014373681837628897
Trained batch 1184 in epoch 11, gen_loss = 0.9132980161578343, disc_loss = 0.0014366070343861071
Trained batch 1185 in epoch 11, gen_loss = 0.9132598134458165, disc_loss = 0.0014359173246012821
Trained batch 1186 in epoch 11, gen_loss = 0.9132327396224905, disc_loss = 0.0014351804779999956
Trained batch 1187 in epoch 11, gen_loss = 0.913286909962744, disc_loss = 0.0014343759634669762
Trained batch 1188 in epoch 11, gen_loss = 0.9132426938557444, disc_loss = 0.0014336893610057589
Trained batch 1189 in epoch 11, gen_loss = 0.9132809732641493, disc_loss = 0.0014329948911912683
Trained batch 1190 in epoch 11, gen_loss = 0.913296903711122, disc_loss = 0.0014319866488411415
Trained batch 1191 in epoch 11, gen_loss = 0.9132365542370201, disc_loss = 0.0014310817824883045
Trained batch 1192 in epoch 11, gen_loss = 0.9131796123695693, disc_loss = 0.001430679620108336
Trained batch 1193 in epoch 11, gen_loss = 0.9131206065865617, disc_loss = 0.0014304683096891873
Trained batch 1194 in epoch 11, gen_loss = 0.9131591213796927, disc_loss = 0.001429663715546412
Trained batch 1195 in epoch 11, gen_loss = 0.9132586184851701, disc_loss = 0.0014289173310913174
Trained batch 1196 in epoch 11, gen_loss = 0.9133228884703334, disc_loss = 0.0014280074550334274
Trained batch 1197 in epoch 11, gen_loss = 0.9132479281477219, disc_loss = 0.0014273273535519565
Trained batch 1198 in epoch 11, gen_loss = 0.9133009761944724, disc_loss = 0.0014265598408206496
Trained batch 1199 in epoch 11, gen_loss = 0.9133994895716508, disc_loss = 0.0014257760186198235
Trained batch 1200 in epoch 11, gen_loss = 0.9132777334847716, disc_loss = 0.001425335545086981
Trained batch 1201 in epoch 11, gen_loss = 0.9134025348105566, disc_loss = 0.0014247225299822126
Trained batch 1202 in epoch 11, gen_loss = 0.9133799833648917, disc_loss = 0.0014240692343554084
Trained batch 1203 in epoch 11, gen_loss = 0.913400163187141, disc_loss = 0.0014234239393844958
Trained batch 1204 in epoch 11, gen_loss = 0.9134044073429345, disc_loss = 0.0014227629799913389
Trained batch 1205 in epoch 11, gen_loss = 0.9134192835434555, disc_loss = 0.001421894200347729
Trained batch 1206 in epoch 11, gen_loss = 0.9132871935460424, disc_loss = 0.0014238064820023804
Trained batch 1207 in epoch 11, gen_loss = 0.9132967902631159, disc_loss = 0.0014242476632529998
Trained batch 1208 in epoch 11, gen_loss = 0.9133206004934729, disc_loss = 0.0014274777820613995
Trained batch 1209 in epoch 11, gen_loss = 0.9133324580251678, disc_loss = 0.0014287454588284615
Trained batch 1210 in epoch 11, gen_loss = 0.913350591179165, disc_loss = 0.0014291298702923444
Trained batch 1211 in epoch 11, gen_loss = 0.913393572169562, disc_loss = 0.0014283650301660942
Trained batch 1212 in epoch 11, gen_loss = 0.9134617280783185, disc_loss = 0.0014276961039184136
Trained batch 1213 in epoch 11, gen_loss = 0.913635496890918, disc_loss = 0.001427147511515552
Trained batch 1214 in epoch 11, gen_loss = 0.9135969186025392, disc_loss = 0.0014263184310300918
Trained batch 1215 in epoch 11, gen_loss = 0.9136689746948449, disc_loss = 0.0014254573942989019
Trained batch 1216 in epoch 11, gen_loss = 0.913628567411161, disc_loss = 0.001424532222912769
Trained batch 1217 in epoch 11, gen_loss = 0.9135051348134997, disc_loss = 0.0014237972246356565
Trained batch 1218 in epoch 11, gen_loss = 0.9135332353981525, disc_loss = 0.0014229643781989317
Trained batch 1219 in epoch 11, gen_loss = 0.9135227674343547, disc_loss = 0.0014222179291731455
Trained batch 1220 in epoch 11, gen_loss = 0.9136131915960226, disc_loss = 0.0014213590155712744
Trained batch 1221 in epoch 11, gen_loss = 0.9136102444899258, disc_loss = 0.001420372623097777
Trained batch 1222 in epoch 11, gen_loss = 0.9135208992517492, disc_loss = 0.0014196015471247346
Trained batch 1223 in epoch 11, gen_loss = 0.91343383710174, disc_loss = 0.0014187688784570091
Trained batch 1224 in epoch 11, gen_loss = 0.9134622307699554, disc_loss = 0.0014180548315035056
Trained batch 1225 in epoch 11, gen_loss = 0.9134199324187019, disc_loss = 0.0014172018049033897
Trained batch 1226 in epoch 11, gen_loss = 0.9134411684069677, disc_loss = 0.0014162878307442308
Trained batch 1227 in epoch 11, gen_loss = 0.9133984790659883, disc_loss = 0.0014155358258912904
Trained batch 1228 in epoch 11, gen_loss = 0.9134082172923791, disc_loss = 0.0014147349285303346
Trained batch 1229 in epoch 11, gen_loss = 0.9132833294267577, disc_loss = 0.001413770480638316
Trained batch 1230 in epoch 11, gen_loss = 0.9132527909464802, disc_loss = 0.0014128090433461603
Trained batch 1231 in epoch 11, gen_loss = 0.9133063433329006, disc_loss = 0.001411810767182954
Trained batch 1232 in epoch 11, gen_loss = 0.9131997614881419, disc_loss = 0.0014110085764255317
Trained batch 1233 in epoch 11, gen_loss = 0.913238543455566, disc_loss = 0.0014100990018056547
Trained batch 1234 in epoch 11, gen_loss = 0.9131722726319965, disc_loss = 0.0014091651050673435
Trained batch 1235 in epoch 11, gen_loss = 0.9131426737918051, disc_loss = 0.001408151878160401
Trained batch 1236 in epoch 11, gen_loss = 0.9132017650812406, disc_loss = 0.001407457031757926
Trained batch 1237 in epoch 11, gen_loss = 0.913198111852652, disc_loss = 0.0014064992155791297
Trained batch 1238 in epoch 11, gen_loss = 0.9132098724420654, disc_loss = 0.0014055456699617387
Trained batch 1239 in epoch 11, gen_loss = 0.9132135179734999, disc_loss = 0.0014045646496983423
Trained batch 1240 in epoch 11, gen_loss = 0.9130896289534957, disc_loss = 0.0014035733298496443
Trained batch 1241 in epoch 11, gen_loss = 0.9132115064419793, disc_loss = 0.0014029157786567435
Trained batch 1242 in epoch 11, gen_loss = 0.9131182439847042, disc_loss = 0.0014020193330517212
Trained batch 1243 in epoch 11, gen_loss = 0.9131068059294171, disc_loss = 0.0014010946600128912
Trained batch 1244 in epoch 11, gen_loss = 0.9131690961768828, disc_loss = 0.0014001460353642596
Trained batch 1245 in epoch 11, gen_loss = 0.9131254549967918, disc_loss = 0.0013991768935426535
Trained batch 1246 in epoch 11, gen_loss = 0.9131518664509177, disc_loss = 0.001398411297514461
Trained batch 1247 in epoch 11, gen_loss = 0.9131102719559119, disc_loss = 0.0013975590594379984
Trained batch 1248 in epoch 11, gen_loss = 0.9131926356362189, disc_loss = 0.0013968902768174943
Trained batch 1249 in epoch 11, gen_loss = 0.9132444849014282, disc_loss = 0.0013960795498423977
Trained batch 1250 in epoch 11, gen_loss = 0.9132587115446346, disc_loss = 0.0013952697943381213
Trained batch 1251 in epoch 11, gen_loss = 0.9131584815419139, disc_loss = 0.001394382625154792
Trained batch 1252 in epoch 11, gen_loss = 0.9130418150784583, disc_loss = 0.0013935253133147713
Trained batch 1253 in epoch 11, gen_loss = 0.9129723284328193, disc_loss = 0.0013925700653915098
Trained batch 1254 in epoch 11, gen_loss = 0.9128687462958681, disc_loss = 0.001391676143462843
Trained batch 1255 in epoch 11, gen_loss = 0.9128810447302593, disc_loss = 0.001390653989428003
Trained batch 1256 in epoch 11, gen_loss = 0.9129306212624768, disc_loss = 0.0013896947857950802
Trained batch 1257 in epoch 11, gen_loss = 0.912968390838899, disc_loss = 0.0013887900474816232
Trained batch 1258 in epoch 11, gen_loss = 0.9129361900381856, disc_loss = 0.0013878675857478169
Trained batch 1259 in epoch 11, gen_loss = 0.9128607148688938, disc_loss = 0.001386902621174707
Trained batch 1260 in epoch 11, gen_loss = 0.9128042168318516, disc_loss = 0.0013861217913176069
Trained batch 1261 in epoch 11, gen_loss = 0.9128275490033835, disc_loss = 0.0013854544911264556
Trained batch 1262 in epoch 11, gen_loss = 0.912743986455203, disc_loss = 0.0013845053939730168
Trained batch 1263 in epoch 11, gen_loss = 0.9127366886108736, disc_loss = 0.0013835921687287633
Trained batch 1264 in epoch 11, gen_loss = 0.9127709825519517, disc_loss = 0.00138268105536108
Trained batch 1265 in epoch 11, gen_loss = 0.9128307136596662, disc_loss = 0.0013817053786337097
Trained batch 1266 in epoch 11, gen_loss = 0.9127187182231503, disc_loss = 0.001380836702196306
Trained batch 1267 in epoch 11, gen_loss = 0.9127229565889677, disc_loss = 0.001379981078918448
Trained batch 1268 in epoch 11, gen_loss = 0.9127431489803173, disc_loss = 0.0013789910793102758
Trained batch 1269 in epoch 11, gen_loss = 0.9126573086723568, disc_loss = 0.001378022362307923
Trained batch 1270 in epoch 11, gen_loss = 0.9127406004748881, disc_loss = 0.0013771834173100317
Trained batch 1271 in epoch 11, gen_loss = 0.9125460420014724, disc_loss = 0.0014089870878935082
Trained batch 1272 in epoch 11, gen_loss = 0.9126303065787688, disc_loss = 0.0014927376301864552
Trained batch 1273 in epoch 11, gen_loss = 0.9127617540127442, disc_loss = 0.001500756447072216
Trained batch 1274 in epoch 11, gen_loss = 0.9128003001680561, disc_loss = 0.0015143379358906874
Trained batch 1275 in epoch 11, gen_loss = 0.9128258871994795, disc_loss = 0.0015290401312730378
Trained batch 1276 in epoch 11, gen_loss = 0.9128391034171837, disc_loss = 0.001540076574836102
Trained batch 1277 in epoch 11, gen_loss = 0.9127912653817071, disc_loss = 0.0015414502678868017
Trained batch 1278 in epoch 11, gen_loss = 0.9128704993775154, disc_loss = 0.0015455230386265595
Trained batch 1279 in epoch 11, gen_loss = 0.9128251636400819, disc_loss = 0.0015476054953836639
Trained batch 1280 in epoch 11, gen_loss = 0.9127458016636035, disc_loss = 0.0015485383976097257
Trained batch 1281 in epoch 11, gen_loss = 0.9126997641207834, disc_loss = 0.001549347502298924
Trained batch 1282 in epoch 11, gen_loss = 0.9126400585204293, disc_loss = 0.001550315751150788
Trained batch 1283 in epoch 11, gen_loss = 0.9125230793269624, disc_loss = 0.0015502728346152572
Trained batch 1284 in epoch 11, gen_loss = 0.9125149969924748, disc_loss = 0.0015509209262087337
Trained batch 1285 in epoch 11, gen_loss = 0.9125611194370323, disc_loss = 0.001551724720839316
Trained batch 1286 in epoch 11, gen_loss = 0.9125051971267338, disc_loss = 0.0015533778316286118
Trained batch 1287 in epoch 11, gen_loss = 0.9124525842366752, disc_loss = 0.0015527982752602206
Trained batch 1288 in epoch 11, gen_loss = 0.9124364234663147, disc_loss = 0.0015521261470086496
Trained batch 1289 in epoch 11, gen_loss = 0.912424133406129, disc_loss = 0.0015519546871762787
Trained batch 1290 in epoch 11, gen_loss = 0.9124681169353281, disc_loss = 0.0015513358033740975
Trained batch 1291 in epoch 11, gen_loss = 0.912537870853678, disc_loss = 0.0015507835052022774
Trained batch 1292 in epoch 11, gen_loss = 0.9124948656660405, disc_loss = 0.0015498529810246435
Trained batch 1293 in epoch 11, gen_loss = 0.9125754847961378, disc_loss = 0.0015494065190229046
Trained batch 1294 in epoch 11, gen_loss = 0.9125938207486421, disc_loss = 0.0015486168005708451
Trained batch 1295 in epoch 11, gen_loss = 0.912646935355884, disc_loss = 0.0015477826503167396
Trained batch 1296 in epoch 11, gen_loss = 0.912617039799966, disc_loss = 0.0015468774738892942
Trained batch 1297 in epoch 11, gen_loss = 0.9126066506735533, disc_loss = 0.00154633545066918
Trained batch 1298 in epoch 11, gen_loss = 0.9126364346923417, disc_loss = 0.0015458184348661416
Trained batch 1299 in epoch 11, gen_loss = 0.9126601116473858, disc_loss = 0.0015458468460033496
Trained batch 1300 in epoch 11, gen_loss = 0.9127043700969558, disc_loss = 0.0015450864468652997
Trained batch 1301 in epoch 11, gen_loss = 0.9126561057915519, disc_loss = 0.001545188388908789
Trained batch 1302 in epoch 11, gen_loss = 0.9126512484649284, disc_loss = 0.0015444631188455816
Trained batch 1303 in epoch 11, gen_loss = 0.9126813611918432, disc_loss = 0.0015436549366603701
Trained batch 1304 in epoch 11, gen_loss = 0.9126380762377918, disc_loss = 0.001543084039406693
Trained batch 1305 in epoch 11, gen_loss = 0.9126303499909674, disc_loss = 0.0015420958785247977
Trained batch 1306 in epoch 11, gen_loss = 0.912634297190683, disc_loss = 0.0015414529240746241
Trained batch 1307 in epoch 11, gen_loss = 0.9126128079512068, disc_loss = 0.0015406770955412128
Trained batch 1308 in epoch 11, gen_loss = 0.9125430906338032, disc_loss = 0.001540060271717432
Trained batch 1309 in epoch 11, gen_loss = 0.9124698050149525, disc_loss = 0.0015391377051300254
Trained batch 1310 in epoch 11, gen_loss = 0.912470519406299, disc_loss = 0.0015382376017779014
Trained batch 1311 in epoch 11, gen_loss = 0.9124570483932408, disc_loss = 0.0015377115068404014
Trained batch 1312 in epoch 11, gen_loss = 0.9124910728403021, disc_loss = 0.0015367759895668217
Trained batch 1313 in epoch 11, gen_loss = 0.9124752448664771, disc_loss = 0.001536352504537698
Trained batch 1314 in epoch 11, gen_loss = 0.9125053011419202, disc_loss = 0.001535778095358217
Trained batch 1315 in epoch 11, gen_loss = 0.9124921433922005, disc_loss = 0.0015349885483882891
Trained batch 1316 in epoch 11, gen_loss = 0.9124947116514364, disc_loss = 0.0015348347600152524
Trained batch 1317 in epoch 11, gen_loss = 0.9125158046464095, disc_loss = 0.0015341032934268893
Trained batch 1318 in epoch 11, gen_loss = 0.9125596203977543, disc_loss = 0.0015334435191712741
Trained batch 1319 in epoch 11, gen_loss = 0.9126519024823652, disc_loss = 0.0015325430842246782
Trained batch 1320 in epoch 11, gen_loss = 0.9126646835004444, disc_loss = 0.0015318309455404063
Trained batch 1321 in epoch 11, gen_loss = 0.9126800528633071, disc_loss = 0.0015311365644591704
Trained batch 1322 in epoch 11, gen_loss = 0.912627106350836, disc_loss = 0.0015302344829460509
Trained batch 1323 in epoch 11, gen_loss = 0.9125508952356898, disc_loss = 0.001529334492524895
Trained batch 1324 in epoch 11, gen_loss = 0.912470821524566, disc_loss = 0.001528459758295146
Trained batch 1325 in epoch 11, gen_loss = 0.9124693532065569, disc_loss = 0.0015274381600852154
Trained batch 1326 in epoch 11, gen_loss = 0.9123809465179789, disc_loss = 0.0015265608681127008
Trained batch 1327 in epoch 11, gen_loss = 0.912350359675755, disc_loss = 0.001525604564282062
Trained batch 1328 in epoch 11, gen_loss = 0.9123908743721996, disc_loss = 0.0015247265861011708
Trained batch 1329 in epoch 11, gen_loss = 0.9124085282024584, disc_loss = 0.001523845174088457
Trained batch 1330 in epoch 11, gen_loss = 0.9124324820616655, disc_loss = 0.0015228873789780795
Trained batch 1331 in epoch 11, gen_loss = 0.9123705106454568, disc_loss = 0.0015220952996619977
Trained batch 1332 in epoch 11, gen_loss = 0.9122421831809213, disc_loss = 0.00152150322237701
Trained batch 1333 in epoch 11, gen_loss = 0.9122538263204395, disc_loss = 0.001520652505399315
Trained batch 1334 in epoch 11, gen_loss = 0.9122425095865343, disc_loss = 0.00151971037215272
Trained batch 1335 in epoch 11, gen_loss = 0.9121525052064907, disc_loss = 0.0015187938679636847
Trained batch 1336 in epoch 11, gen_loss = 0.9121856511575389, disc_loss = 0.0015178452746071004
Trained batch 1337 in epoch 11, gen_loss = 0.9121022508194272, disc_loss = 0.0015168505980287042
Trained batch 1338 in epoch 11, gen_loss = 0.9120781583248277, disc_loss = 0.001515915891070028
Trained batch 1339 in epoch 11, gen_loss = 0.9121229199776009, disc_loss = 0.0015150442592700407
Trained batch 1340 in epoch 11, gen_loss = 0.9121161181032436, disc_loss = 0.0015141492956840354
Trained batch 1341 in epoch 11, gen_loss = 0.9121111904100228, disc_loss = 0.0015134374935076675
Trained batch 1342 in epoch 11, gen_loss = 0.9121207385833638, disc_loss = 0.0015126051880302535
Trained batch 1343 in epoch 11, gen_loss = 0.9121192561107732, disc_loss = 0.0015117094736129253
Trained batch 1344 in epoch 11, gen_loss = 0.9120466394052187, disc_loss = 0.0015108092840224094
Trained batch 1345 in epoch 11, gen_loss = 0.9120738063046341, disc_loss = 0.001509865714719772
Trained batch 1346 in epoch 11, gen_loss = 0.9120080517501237, disc_loss = 0.0015089483887988702
Trained batch 1347 in epoch 11, gen_loss = 0.9119395336871331, disc_loss = 0.001508024271390257
Trained batch 1348 in epoch 11, gen_loss = 0.9119734827724538, disc_loss = 0.0015070614985041168
Trained batch 1349 in epoch 11, gen_loss = 0.9120424071947734, disc_loss = 0.001506088820113089
Trained batch 1350 in epoch 11, gen_loss = 0.9119963339749837, disc_loss = 0.0015053434835136242
Trained batch 1351 in epoch 11, gen_loss = 0.9120352843985755, disc_loss = 0.0015044993244518775
Trained batch 1352 in epoch 11, gen_loss = 0.9118757089331515, disc_loss = 0.0015040563841321596
Trained batch 1353 in epoch 11, gen_loss = 0.9118229328617563, disc_loss = 0.0015032222811223591
Trained batch 1354 in epoch 11, gen_loss = 0.9117207969686641, disc_loss = 0.001502354914799648
Trained batch 1355 in epoch 11, gen_loss = 0.9117565605580631, disc_loss = 0.0015015281124548857
Trained batch 1356 in epoch 11, gen_loss = 0.9117793114025451, disc_loss = 0.001500635177894922
Trained batch 1357 in epoch 11, gen_loss = 0.9117745736035051, disc_loss = 0.0014996527335291688
Trained batch 1358 in epoch 11, gen_loss = 0.9117394690131159, disc_loss = 0.001498691690663273
Trained batch 1359 in epoch 11, gen_loss = 0.9116289767710601, disc_loss = 0.001497786234751723
Trained batch 1360 in epoch 11, gen_loss = 0.911674272611157, disc_loss = 0.0014968527866104503
Trained batch 1361 in epoch 11, gen_loss = 0.9116323302758422, disc_loss = 0.0014959512733217018
Trained batch 1362 in epoch 11, gen_loss = 0.9116081369771558, disc_loss = 0.0014950683654630986
Trained batch 1363 in epoch 11, gen_loss = 0.9116416134792339, disc_loss = 0.0014941373152380405
Trained batch 1364 in epoch 11, gen_loss = 0.9116701863187573, disc_loss = 0.0014932196404998772
Trained batch 1365 in epoch 11, gen_loss = 0.911761014737287, disc_loss = 0.0014923334826774223
Trained batch 1366 in epoch 11, gen_loss = 0.9117551646096566, disc_loss = 0.0014914009233172728
Trained batch 1367 in epoch 11, gen_loss = 0.9117788743467359, disc_loss = 0.0014904673957971681
Trained batch 1368 in epoch 11, gen_loss = 0.9117475880855536, disc_loss = 0.0014894759754014518
Trained batch 1369 in epoch 11, gen_loss = 0.9116839149137483, disc_loss = 0.0014885808162094412
Trained batch 1370 in epoch 11, gen_loss = 0.9116400107252258, disc_loss = 0.001487575801008463
Trained batch 1371 in epoch 11, gen_loss = 0.9115590492681581, disc_loss = 0.00148661002617369
Trained batch 1372 in epoch 11, gen_loss = 0.9114468744091109, disc_loss = 0.0014857550916882924
Trained batch 1373 in epoch 11, gen_loss = 0.9114894561979274, disc_loss = 0.0014848372318333155
Trained batch 1374 in epoch 11, gen_loss = 0.9114614448113875, disc_loss = 0.0014838611235476987
Trained batch 1375 in epoch 11, gen_loss = 0.9114187570332095, disc_loss = 0.0014829026876568181
Trained batch 1376 in epoch 11, gen_loss = 0.9114014471278471, disc_loss = 0.0014820619406331911
Trained batch 1377 in epoch 11, gen_loss = 0.9114652317563404, disc_loss = 0.0014812493791633867
Trained batch 1378 in epoch 11, gen_loss = 0.9114413167187232, disc_loss = 0.0014803009845197673
Trained batch 1379 in epoch 11, gen_loss = 0.9113998530567556, disc_loss = 0.0014793579877020776
Trained batch 1380 in epoch 11, gen_loss = 0.9113314999004449, disc_loss = 0.001478412717945784
Trained batch 1381 in epoch 11, gen_loss = 0.9113360819785536, disc_loss = 0.0014775238916137504
Trained batch 1382 in epoch 11, gen_loss = 0.9114159168493722, disc_loss = 0.001476596459875129
Trained batch 1383 in epoch 11, gen_loss = 0.9114110017184577, disc_loss = 0.001475780455171644
Trained batch 1384 in epoch 11, gen_loss = 0.9113095583037779, disc_loss = 0.0014748568349871542
Trained batch 1385 in epoch 11, gen_loss = 0.9112192039279883, disc_loss = 0.0014740208441934482
Trained batch 1386 in epoch 11, gen_loss = 0.9112012575406692, disc_loss = 0.0014731190495100301
Trained batch 1387 in epoch 11, gen_loss = 0.9112580998744333, disc_loss = 0.0014722632422935853
Trained batch 1388 in epoch 11, gen_loss = 0.9113287224968704, disc_loss = 0.001471371171424125
Trained batch 1389 in epoch 11, gen_loss = 0.9114538280655154, disc_loss = 0.0014707696588060664
Trained batch 1390 in epoch 11, gen_loss = 0.9113958673799406, disc_loss = 0.0014698834891050362
Trained batch 1391 in epoch 11, gen_loss = 0.9113387728388282, disc_loss = 0.0014689430441288504
Trained batch 1392 in epoch 11, gen_loss = 0.9112946424052943, disc_loss = 0.001467965357069842
Trained batch 1393 in epoch 11, gen_loss = 0.9112404955168879, disc_loss = 0.0014670422952520917
Trained batch 1394 in epoch 11, gen_loss = 0.9112222161344302, disc_loss = 0.0014661114313926566
Trained batch 1395 in epoch 11, gen_loss = 0.9111950297581091, disc_loss = 0.0014651630427738188
Trained batch 1396 in epoch 11, gen_loss = 0.9112483366267887, disc_loss = 0.0014642208776824534
Trained batch 1397 in epoch 11, gen_loss = 0.9112370986283593, disc_loss = 0.001463276613297074
Trained batch 1398 in epoch 11, gen_loss = 0.9111789277061724, disc_loss = 0.0014625462057063577
Trained batch 1399 in epoch 11, gen_loss = 0.9111155864596366, disc_loss = 0.0014616494218119313
Trained batch 1400 in epoch 11, gen_loss = 0.911107237427512, disc_loss = 0.00146082645309477
Trained batch 1401 in epoch 11, gen_loss = 0.9110514267365024, disc_loss = 0.0014601005811908157
Trained batch 1402 in epoch 11, gen_loss = 0.910981453663098, disc_loss = 0.0014592157891697886
Trained batch 1403 in epoch 11, gen_loss = 0.9109448613943877, disc_loss = 0.001458258653482623
Trained batch 1404 in epoch 11, gen_loss = 0.9109228182093528, disc_loss = 0.001457409175088297
Trained batch 1405 in epoch 11, gen_loss = 0.9109907125256649, disc_loss = 0.0014565891337221092
Trained batch 1406 in epoch 11, gen_loss = 0.9109539970406083, disc_loss = 0.0014558602612903605
Trained batch 1407 in epoch 11, gen_loss = 0.9109878821129148, disc_loss = 0.0014551291384117865
Trained batch 1408 in epoch 11, gen_loss = 0.9110043444812848, disc_loss = 0.0014543019452839658
Trained batch 1409 in epoch 11, gen_loss = 0.9109702841609928, disc_loss = 0.0014534185410031168
Trained batch 1410 in epoch 11, gen_loss = 0.9109671624479017, disc_loss = 0.0014525748233341694
Trained batch 1411 in epoch 11, gen_loss = 0.9108982598224376, disc_loss = 0.0014516262151786316
Trained batch 1412 in epoch 11, gen_loss = 0.9108604422631368, disc_loss = 0.0014507314732875758
Trained batch 1413 in epoch 11, gen_loss = 0.9107749395525607, disc_loss = 0.00144989894416222
Trained batch 1414 in epoch 11, gen_loss = 0.9107364621684745, disc_loss = 0.0014489713431369512
Trained batch 1415 in epoch 11, gen_loss = 0.9107814019514342, disc_loss = 0.0014481515643992525
Trained batch 1416 in epoch 11, gen_loss = 0.910773911270863, disc_loss = 0.001447241132852572
Trained batch 1417 in epoch 11, gen_loss = 0.910867708946653, disc_loss = 0.0014465395650145266
Trained batch 1418 in epoch 11, gen_loss = 0.9108639452304531, disc_loss = 0.0014458082906644517
Trained batch 1419 in epoch 11, gen_loss = 0.9108643017184567, disc_loss = 0.0014448580830016715
Trained batch 1420 in epoch 11, gen_loss = 0.9108789311925095, disc_loss = 0.001443936720394583
Trained batch 1421 in epoch 11, gen_loss = 0.9108634381941435, disc_loss = 0.0014430905129661567
Trained batch 1422 in epoch 11, gen_loss = 0.9108877159388067, disc_loss = 0.0014422521367062691
Trained batch 1423 in epoch 11, gen_loss = 0.9108695519690433, disc_loss = 0.0014413461823796444
Trained batch 1424 in epoch 11, gen_loss = 0.9108097828061957, disc_loss = 0.001440404378479702
Trained batch 1425 in epoch 11, gen_loss = 0.9107874584649421, disc_loss = 0.0014394783531269703
Trained batch 1426 in epoch 11, gen_loss = 0.9106828648891997, disc_loss = 0.0014385602609538115
Trained batch 1427 in epoch 11, gen_loss = 0.9106782626788489, disc_loss = 0.0014377253516616112
Trained batch 1428 in epoch 11, gen_loss = 0.9106086888790464, disc_loss = 0.0014368926403405785
Trained batch 1429 in epoch 11, gen_loss = 0.9107209779165841, disc_loss = 0.0014360167607322125
Trained batch 1430 in epoch 11, gen_loss = 0.9106854463606594, disc_loss = 0.0014350986209686267
Trained batch 1431 in epoch 11, gen_loss = 0.9105815741353195, disc_loss = 0.0014342935077614805
Trained batch 1432 in epoch 11, gen_loss = 0.9105651468059356, disc_loss = 0.0014334500111809574
Trained batch 1433 in epoch 11, gen_loss = 0.9104980214120952, disc_loss = 0.0014325365506388716
Trained batch 1434 in epoch 11, gen_loss = 0.9104649185303612, disc_loss = 0.0014316497568217738
Trained batch 1435 in epoch 11, gen_loss = 0.9103469284962147, disc_loss = 0.0014307793984202398
Trained batch 1436 in epoch 11, gen_loss = 0.9103439241212196, disc_loss = 0.0014299091616203408
Trained batch 1437 in epoch 11, gen_loss = 0.9103048267633096, disc_loss = 0.0014290238839733602
Trained batch 1438 in epoch 11, gen_loss = 0.9102641802599565, disc_loss = 0.0014281107946598145
Trained batch 1439 in epoch 11, gen_loss = 0.9102377361307542, disc_loss = 0.0014272863524512206
Trained batch 1440 in epoch 11, gen_loss = 0.9102162914008088, disc_loss = 0.0014263718410570275
Trained batch 1441 in epoch 11, gen_loss = 0.9101542660168239, disc_loss = 0.0014255085412330575
Trained batch 1442 in epoch 11, gen_loss = 0.9101844915729055, disc_loss = 0.0014246358204711778
Trained batch 1443 in epoch 11, gen_loss = 0.9101374406893827, disc_loss = 0.0014237441692379448
Trained batch 1444 in epoch 11, gen_loss = 0.9101527048229758, disc_loss = 0.0014228706703317685
Trained batch 1445 in epoch 11, gen_loss = 0.9101592732250773, disc_loss = 0.0014220240052858406
Trained batch 1446 in epoch 11, gen_loss = 0.9101795368797629, disc_loss = 0.0014211510354131063
Trained batch 1447 in epoch 11, gen_loss = 0.910111708741491, disc_loss = 0.0014202258270395668
Trained batch 1448 in epoch 11, gen_loss = 0.9099955484322468, disc_loss = 0.001419365583795202
Trained batch 1449 in epoch 11, gen_loss = 0.9099704927411573, disc_loss = 0.0014185433440910983
Trained batch 1450 in epoch 11, gen_loss = 0.9098962303854365, disc_loss = 0.001417740691453078
Trained batch 1451 in epoch 11, gen_loss = 0.9099315065818713, disc_loss = 0.0014169385105670892
Trained batch 1452 in epoch 11, gen_loss = 0.9099839068410812, disc_loss = 0.0014161714225400669
Trained batch 1453 in epoch 11, gen_loss = 0.9099841783594397, disc_loss = 0.0014153699277982988
Trained batch 1454 in epoch 11, gen_loss = 0.9099721694729992, disc_loss = 0.0014146022455526965
Trained batch 1455 in epoch 11, gen_loss = 0.909946036699054, disc_loss = 0.001418773220336164
Trained batch 1456 in epoch 11, gen_loss = 0.9101932909526315, disc_loss = 0.0014327500798968528
Trained batch 1457 in epoch 11, gen_loss = 0.9103666780253333, disc_loss = 0.001447299731536041
Trained batch 1458 in epoch 11, gen_loss = 0.9104122119541442, disc_loss = 0.001452139227531393
Trained batch 1459 in epoch 11, gen_loss = 0.9105924078046459, disc_loss = 0.0014550177634129347
Trained batch 1460 in epoch 11, gen_loss = 0.9107381818557259, disc_loss = 0.001457716840823264
Trained batch 1461 in epoch 11, gen_loss = 0.9107665439963177, disc_loss = 0.0014606657523783722
Trained batch 1462 in epoch 11, gen_loss = 0.9106170051894771, disc_loss = 0.0014931246104009995
Trained batch 1463 in epoch 11, gen_loss = 0.9108073551390992, disc_loss = 0.0015328739780377505
Trained batch 1464 in epoch 11, gen_loss = 0.9108724948489219, disc_loss = 0.0015443029812003332
Trained batch 1465 in epoch 11, gen_loss = 0.9108650096035263, disc_loss = 0.0015498042688987927
Trained batch 1466 in epoch 11, gen_loss = 0.9109305652453937, disc_loss = 0.0015526924391312885
Trained batch 1467 in epoch 11, gen_loss = 0.9111906873513957, disc_loss = 0.0015665655402268281
Trained batch 1468 in epoch 11, gen_loss = 0.91128295489604, disc_loss = 0.0015790141373172404
Trained batch 1469 in epoch 11, gen_loss = 0.9113073743525005, disc_loss = 0.0015823171504257053
Trained batch 1470 in epoch 11, gen_loss = 0.9114221590137417, disc_loss = 0.0015862204489452845
Trained batch 1471 in epoch 11, gen_loss = 0.9114624685810312, disc_loss = 0.0015884293453782645
Trained batch 1472 in epoch 11, gen_loss = 0.9115956392485676, disc_loss = 0.0015893338530562327
Trained batch 1473 in epoch 11, gen_loss = 0.911678368031089, disc_loss = 0.0015899155722179975
Trained batch 1474 in epoch 11, gen_loss = 0.9118047427727004, disc_loss = 0.0015908741168169723
Trained batch 1475 in epoch 11, gen_loss = 0.9118551045333144, disc_loss = 0.0015927916370723012
Trained batch 1476 in epoch 11, gen_loss = 0.9118922472242253, disc_loss = 0.001593413393888718
Trained batch 1477 in epoch 11, gen_loss = 0.9119106378300426, disc_loss = 0.0015942284893254153
Trained batch 1478 in epoch 11, gen_loss = 0.9119580537181516, disc_loss = 0.0015945566213416652
Trained batch 1479 in epoch 11, gen_loss = 0.9118309005692199, disc_loss = 0.0016166970673505087
Trained batch 1480 in epoch 11, gen_loss = 0.9119704388670629, disc_loss = 0.0016323416042758083
Trained batch 1481 in epoch 11, gen_loss = 0.9120540536045224, disc_loss = 0.001634063917933323
Trained batch 1482 in epoch 11, gen_loss = 0.9121513022656226, disc_loss = 0.001636785364785488
Trained batch 1483 in epoch 11, gen_loss = 0.9122255884733483, disc_loss = 0.0016379648236984161
Trained batch 1484 in epoch 11, gen_loss = 0.9121960002163845, disc_loss = 0.0016407750997037168
Trained batch 1485 in epoch 11, gen_loss = 0.9122535089384338, disc_loss = 0.001647633121707114
Trained batch 1486 in epoch 11, gen_loss = 0.9122207368791063, disc_loss = 0.0016487884100789192
Trained batch 1487 in epoch 11, gen_loss = 0.9122902137698025, disc_loss = 0.0016488576679167118
Trained batch 1488 in epoch 11, gen_loss = 0.9122634819484221, disc_loss = 0.00165056858914753
Trained batch 1489 in epoch 11, gen_loss = 0.9122291265718089, disc_loss = 0.0016509699822844345
Trained batch 1490 in epoch 11, gen_loss = 0.9122069935763466, disc_loss = 0.0016514295374935452
Trained batch 1491 in epoch 11, gen_loss = 0.9121758870321048, disc_loss = 0.0016676931967955881
Trained batch 1492 in epoch 11, gen_loss = 0.9122637807724066, disc_loss = 0.0016708665029114783
Trained batch 1493 in epoch 11, gen_loss = 0.9123642651670908, disc_loss = 0.0016712282050068909
Trained batch 1494 in epoch 11, gen_loss = 0.9124378046064473, disc_loss = 0.001672728935947792
Trained batch 1495 in epoch 11, gen_loss = 0.9124454613675408, disc_loss = 0.0017659841186393938
Trained batch 1496 in epoch 11, gen_loss = 0.9121752409196011, disc_loss = 0.002122810955931133
Trained batch 1497 in epoch 11, gen_loss = 0.9122304477901739, disc_loss = 0.0021943710327956235
Trained batch 1498 in epoch 11, gen_loss = 0.9124606677577685, disc_loss = 0.0023196102850126287
Trained batch 1499 in epoch 11, gen_loss = 0.9124149609406789, disc_loss = 0.0023486023452254207
Trained batch 1500 in epoch 11, gen_loss = 0.9122147713400062, disc_loss = 0.0024165344852169453
Trained batch 1501 in epoch 11, gen_loss = 0.9121835774651539, disc_loss = 0.0024648381529940974
Trained batch 1502 in epoch 11, gen_loss = 0.9122409283995866, disc_loss = 0.002474025457598975
Trained batch 1503 in epoch 11, gen_loss = 0.9123153495899541, disc_loss = 0.002480862010158605
Trained batch 1504 in epoch 11, gen_loss = 0.912396956797058, disc_loss = 0.0024860201880110133
Trained batch 1505 in epoch 11, gen_loss = 0.9124977803562742, disc_loss = 0.0024884739274880947
Trained batch 1506 in epoch 11, gen_loss = 0.9125710110752964, disc_loss = 0.0024902900420225283
Trained batch 1507 in epoch 11, gen_loss = 0.9125714080324223, disc_loss = 0.0024898333399614204
Trained batch 1508 in epoch 11, gen_loss = 0.9126522915895764, disc_loss = 0.002489867480931239
Trained batch 1509 in epoch 11, gen_loss = 0.9126532351339101, disc_loss = 0.002490012235535229
Trained batch 1510 in epoch 11, gen_loss = 0.9127414776030792, disc_loss = 0.0024897704922827307
Trained batch 1511 in epoch 11, gen_loss = 0.9127359098937146, disc_loss = 0.002491672927628613
Trained batch 1512 in epoch 11, gen_loss = 0.91271539768161, disc_loss = 0.0024912051958357155
Trained batch 1513 in epoch 11, gen_loss = 0.9126981960183878, disc_loss = 0.0024948531253318296
Trained batch 1514 in epoch 11, gen_loss = 0.9125564571654442, disc_loss = 0.0025001715144213395
Trained batch 1515 in epoch 11, gen_loss = 0.912644146418194, disc_loss = 0.0025053796369123704
Trained batch 1516 in epoch 11, gen_loss = 0.9126947547309715, disc_loss = 0.0025080433165364344
Trained batch 1517 in epoch 11, gen_loss = 0.912695828751613, disc_loss = 0.0025140486016764826
Trained batch 1518 in epoch 11, gen_loss = 0.9128572522142044, disc_loss = 0.002521381125560723
Trained batch 1519 in epoch 11, gen_loss = 0.9128955076791738, disc_loss = 0.002522809508247136
Trained batch 1520 in epoch 11, gen_loss = 0.9129182593670431, disc_loss = 0.002525654751626533
Trained batch 1521 in epoch 11, gen_loss = 0.9129406385290169, disc_loss = 0.002525694438457354
Trained batch 1522 in epoch 11, gen_loss = 0.912932822051521, disc_loss = 0.0025277560055149066
Trained batch 1523 in epoch 11, gen_loss = 0.9129123332228247, disc_loss = 0.002531016196531576
Trained batch 1524 in epoch 11, gen_loss = 0.91287118419272, disc_loss = 0.002540410308744167
Trained batch 1525 in epoch 11, gen_loss = 0.9129112738613063, disc_loss = 0.002540790158177795
Trained batch 1526 in epoch 11, gen_loss = 0.9129707948319961, disc_loss = 0.0025420919729127922
Trained batch 1527 in epoch 11, gen_loss = 0.9130258455638486, disc_loss = 0.002541842796904705
Trained batch 1528 in epoch 11, gen_loss = 0.9130957988916152, disc_loss = 0.0025429166453821254
Trained batch 1529 in epoch 11, gen_loss = 0.9131991901428871, disc_loss = 0.0025437315897921934
Trained batch 1530 in epoch 11, gen_loss = 0.9132011178503778, disc_loss = 0.0025435298098769087
Trained batch 1531 in epoch 11, gen_loss = 0.9131803802426116, disc_loss = 0.0025443616258701033
Trained batch 1532 in epoch 11, gen_loss = 0.9132228744862053, disc_loss = 0.002544664793394814
Trained batch 1533 in epoch 11, gen_loss = 0.913236251516168, disc_loss = 0.0025469662432466133
Trained batch 1534 in epoch 11, gen_loss = 0.9132918408716929, disc_loss = 0.0025474613384653304
Trained batch 1535 in epoch 11, gen_loss = 0.9132861303708827, disc_loss = 0.002548279619771184
Trained batch 1536 in epoch 11, gen_loss = 0.9133035407953628, disc_loss = 0.002548670053336953
Trained batch 1537 in epoch 11, gen_loss = 0.913483936431659, disc_loss = 0.0025497459927274245
Trained batch 1538 in epoch 11, gen_loss = 0.9134237650852067, disc_loss = 0.0025514292270166212
Trained batch 1539 in epoch 11, gen_loss = 0.9134463987954251, disc_loss = 0.002553089088303443
Trained batch 1540 in epoch 11, gen_loss = 0.9134496515405248, disc_loss = 0.0025529794560230027
Trained batch 1541 in epoch 11, gen_loss = 0.9134898515449579, disc_loss = 0.0025523890834600865
Trained batch 1542 in epoch 11, gen_loss = 0.9134603741102534, disc_loss = 0.0025518467543252745
Trained batch 1543 in epoch 11, gen_loss = 0.9133866055255727, disc_loss = 0.002551145720053447
Trained batch 1544 in epoch 11, gen_loss = 0.9134314560581566, disc_loss = 0.002550511397086525
Trained batch 1545 in epoch 11, gen_loss = 0.9135463289039409, disc_loss = 0.0025502135218985755
Trained batch 1546 in epoch 11, gen_loss = 0.9135325113341511, disc_loss = 0.0025512003114940237
Trained batch 1547 in epoch 11, gen_loss = 0.9136318454677744, disc_loss = 0.0025520234344643426
Trained batch 1548 in epoch 11, gen_loss = 0.9137034325772059, disc_loss = 0.002552441333425103
Trained batch 1549 in epoch 11, gen_loss = 0.9138055134973219, disc_loss = 0.002552661908456714
Trained batch 1550 in epoch 11, gen_loss = 0.9138185911452209, disc_loss = 0.0025529021771590645
Trained batch 1551 in epoch 11, gen_loss = 0.9138170069410014, disc_loss = 0.002552350949355931
Trained batch 1552 in epoch 11, gen_loss = 0.9137812539292242, disc_loss = 0.0025528771619244286
Trained batch 1553 in epoch 11, gen_loss = 0.9137874223013795, disc_loss = 0.0025519147594672297
Trained batch 1554 in epoch 11, gen_loss = 0.9137646362329219, disc_loss = 0.0025512952089630303
Trained batch 1555 in epoch 11, gen_loss = 0.9138497760792318, disc_loss = 0.002550436677240335
Trained batch 1556 in epoch 11, gen_loss = 0.9138894522886821, disc_loss = 0.002549202271021189
Trained batch 1557 in epoch 11, gen_loss = 0.9138650163453412, disc_loss = 0.002547943032430372
Trained batch 1558 in epoch 11, gen_loss = 0.9138794514978444, disc_loss = 0.0025472537030354378
Trained batch 1559 in epoch 11, gen_loss = 0.9138594265549611, disc_loss = 0.0025459736995799174
Trained batch 1560 in epoch 11, gen_loss = 0.9138402224808913, disc_loss = 0.0025447652325037906
Trained batch 1561 in epoch 11, gen_loss = 0.9138767923802023, disc_loss = 0.0025437373759966916
Trained batch 1562 in epoch 11, gen_loss = 0.9138179574726639, disc_loss = 0.002544434034205415
Trained batch 1563 in epoch 11, gen_loss = 0.9138251888706251, disc_loss = 0.0025435765590703496
Trained batch 1564 in epoch 11, gen_loss = 0.9138264056211843, disc_loss = 0.002542396515921467
Trained batch 1565 in epoch 11, gen_loss = 0.9138988095453415, disc_loss = 0.0025417275627965764
Trained batch 1566 in epoch 11, gen_loss = 0.9138976053668194, disc_loss = 0.002541053893441625
Trained batch 1567 in epoch 11, gen_loss = 0.9139452898988918, disc_loss = 0.0025398752865157803
Trained batch 1568 in epoch 11, gen_loss = 0.9139827997765015, disc_loss = 0.0025391342355038887
Trained batch 1569 in epoch 11, gen_loss = 0.9139406093746234, disc_loss = 0.002538260450200819
Trained batch 1570 in epoch 11, gen_loss = 0.9140470840990126, disc_loss = 0.002537477209527695
Trained batch 1571 in epoch 11, gen_loss = 0.9140619227980232, disc_loss = 0.002536431641069392
Trained batch 1572 in epoch 11, gen_loss = 0.9140475738677566, disc_loss = 0.0025351956431755303
Trained batch 1573 in epoch 11, gen_loss = 0.9140606065111512, disc_loss = 0.0025341347663416776
Trained batch 1574 in epoch 11, gen_loss = 0.9140201475506737, disc_loss = 0.0025329834318997906
Trained batch 1575 in epoch 11, gen_loss = 0.9139774953426444, disc_loss = 0.002532059675286753
Trained batch 1576 in epoch 11, gen_loss = 0.9140002026010633, disc_loss = 0.002532284184191607
Trained batch 1577 in epoch 11, gen_loss = 0.913991218737323, disc_loss = 0.002531464244778781
Trained batch 1578 in epoch 11, gen_loss = 0.9139327580148167, disc_loss = 0.0025306178089328757
Trained batch 1579 in epoch 11, gen_loss = 0.9139334804649595, disc_loss = 0.0025302323506216856
Trained batch 1580 in epoch 11, gen_loss = 0.9139292922900645, disc_loss = 0.002530114788642486
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.8243529200553894, disc_loss = 0.0025989627465605736
Trained batch 1 in epoch 12, gen_loss = 0.8540638089179993, disc_loss = 0.004369080998003483
Trained batch 2 in epoch 12, gen_loss = 0.9155750672022501, disc_loss = 0.0033056077857812247
Trained batch 3 in epoch 12, gen_loss = 0.9377670288085938, disc_loss = 0.0034040622413158417
Trained batch 4 in epoch 12, gen_loss = 0.9638630867004394, disc_loss = 0.003304980508983135
Trained batch 5 in epoch 12, gen_loss = 0.9695063928763071, disc_loss = 0.0029926347003007927
Trained batch 6 in epoch 12, gen_loss = 0.9574278933661324, disc_loss = 0.0028054328369242804
Trained batch 7 in epoch 12, gen_loss = 0.9548126608133316, disc_loss = 0.0027451327187009156
Trained batch 8 in epoch 12, gen_loss = 0.9521294567320082, disc_loss = 0.0025726642666591536
Trained batch 9 in epoch 12, gen_loss = 0.942441713809967, disc_loss = 0.0024724386166781187
Trained batch 10 in epoch 12, gen_loss = 0.950851321220398, disc_loss = 0.002329807950776409
Trained batch 11 in epoch 12, gen_loss = 0.95184093217055, disc_loss = 0.0021731005350981527
Trained batch 12 in epoch 12, gen_loss = 0.9513349670630235, disc_loss = 0.0020515662394105815
Trained batch 13 in epoch 12, gen_loss = 0.9492094729627881, disc_loss = 0.001943419808022944
Trained batch 14 in epoch 12, gen_loss = 0.9483039100964864, disc_loss = 0.0018702631855073075
Trained batch 15 in epoch 12, gen_loss = 0.9422538839280605, disc_loss = 0.001814040351746371
Trained batch 16 in epoch 12, gen_loss = 0.9407360027818119, disc_loss = 0.001747938948135604
Trained batch 17 in epoch 12, gen_loss = 0.9431616564591726, disc_loss = 0.0016763742751209065
Trained batch 18 in epoch 12, gen_loss = 0.9436878311006647, disc_loss = 0.0016387686712397752
Trained batch 19 in epoch 12, gen_loss = 0.9414661854505539, disc_loss = 0.001585690265346784
Trained batch 20 in epoch 12, gen_loss = 0.9433718579156058, disc_loss = 0.0015424010080529289
Trained batch 21 in epoch 12, gen_loss = 0.9475164034149863, disc_loss = 0.0015106945714003152
Trained batch 22 in epoch 12, gen_loss = 0.9442032990248307, disc_loss = 0.0014773395517334827
Trained batch 23 in epoch 12, gen_loss = 0.9402183865507444, disc_loss = 0.0014518618493942388
Trained batch 24 in epoch 12, gen_loss = 0.9385891151428223, disc_loss = 0.001472442428348586
Trained batch 25 in epoch 12, gen_loss = 0.9373337213809674, disc_loss = 0.0014618101536493318
Trained batch 26 in epoch 12, gen_loss = 0.9419663658848515, disc_loss = 0.0015154440997220161
Trained batch 27 in epoch 12, gen_loss = 0.9399486780166626, disc_loss = 0.0015610835887075933
Trained batch 28 in epoch 12, gen_loss = 0.9403187098174259, disc_loss = 0.0015471757756915457
Trained batch 29 in epoch 12, gen_loss = 0.9410222252209981, disc_loss = 0.0017120677463632699
Trained batch 30 in epoch 12, gen_loss = 0.9374591765865203, disc_loss = 0.00213162710180416
Trained batch 31 in epoch 12, gen_loss = 0.9363670721650124, disc_loss = 0.003192714541910391
Trained batch 32 in epoch 12, gen_loss = 0.9367144035570549, disc_loss = 0.003380955686390569
Trained batch 33 in epoch 12, gen_loss = 0.9333606099381166, disc_loss = 0.004552795561133227
Trained batch 34 in epoch 12, gen_loss = 0.9299887895584107, disc_loss = 0.004740694919434775
Trained batch 35 in epoch 12, gen_loss = 0.9170023260845078, disc_loss = 0.012709313288117604
Trained batch 36 in epoch 12, gen_loss = 0.9241884262175173, disc_loss = 0.02306835021984109
Trained batch 37 in epoch 12, gen_loss = 0.9155286134857881, disc_loss = 0.024011635965220386
Trained batch 38 in epoch 12, gen_loss = 0.9133835335572561, disc_loss = 0.023624258171856545
Trained batch 39 in epoch 12, gen_loss = 0.9103909321129322, disc_loss = 0.023626880216033895
Trained batch 40 in epoch 12, gen_loss = 0.9070220495142588, disc_loss = 0.0235803226859411
Trained batch 41 in epoch 12, gen_loss = 0.9071569903975442, disc_loss = 0.02373936786413348
Trained batch 42 in epoch 12, gen_loss = 0.8999186650265095, disc_loss = 0.024307833472131425
Trained batch 43 in epoch 12, gen_loss = 0.8998050533912398, disc_loss = 0.0243730778370677
Trained batch 44 in epoch 12, gen_loss = 0.8948108573754628, disc_loss = 0.02471153244259767
Trained batch 45 in epoch 12, gen_loss = 0.8944793492555618, disc_loss = 0.024288013442697855
Trained batch 46 in epoch 12, gen_loss = 0.8958759250793051, disc_loss = 0.024711583708190023
Trained batch 47 in epoch 12, gen_loss = 0.8946931107590596, disc_loss = 0.024672490725909785
Trained batch 48 in epoch 12, gen_loss = 0.8881795801678483, disc_loss = 0.028844118295878893
Trained batch 49 in epoch 12, gen_loss = 0.8921814233064651, disc_loss = 0.029524732853169554
Trained batch 50 in epoch 12, gen_loss = 0.8958556774784537, disc_loss = 0.029835295175800247
Trained batch 51 in epoch 12, gen_loss = 0.8963258501428825, disc_loss = 0.029381676019021634
Trained batch 52 in epoch 12, gen_loss = 0.8949791895893385, disc_loss = 0.028960935320630495
Trained batch 53 in epoch 12, gen_loss = 0.8942699857332088, disc_loss = 0.028558557660694026
Trained batch 54 in epoch 12, gen_loss = 0.8940286468375813, disc_loss = 0.028116008670556105
Trained batch 55 in epoch 12, gen_loss = 0.8922284240169185, disc_loss = 0.027730486486169475
Trained batch 56 in epoch 12, gen_loss = 0.8899254218528145, disc_loss = 0.027565734817854765
Trained batch 57 in epoch 12, gen_loss = 0.8937450241425942, disc_loss = 0.027140353864022724
Trained batch 58 in epoch 12, gen_loss = 0.896468167082738, disc_loss = 0.026776958905630036
Trained batch 59 in epoch 12, gen_loss = 0.897361321747303, disc_loss = 0.026355982080470616
Trained batch 60 in epoch 12, gen_loss = 0.8984952710691045, disc_loss = 0.026009676563381753
Trained batch 61 in epoch 12, gen_loss = 0.9000506194368485, disc_loss = 0.02560594576671945
Trained batch 62 in epoch 12, gen_loss = 0.8992452493735722, disc_loss = 0.025241467423112472
Trained batch 63 in epoch 12, gen_loss = 0.9007619027979672, disc_loss = 0.02487273699398429
Trained batch 64 in epoch 12, gen_loss = 0.898704921740752, disc_loss = 0.02511250920047482
Trained batch 65 in epoch 12, gen_loss = 0.8923191825548807, disc_loss = 0.028498947327148704
Trained batch 66 in epoch 12, gen_loss = 0.8926836874947619, disc_loss = 0.028309691158286642
Trained batch 67 in epoch 12, gen_loss = 0.8936495596871656, disc_loss = 0.028114614723616635
Trained batch 68 in epoch 12, gen_loss = 0.8933967775192814, disc_loss = 0.02782614933001215
Trained batch 69 in epoch 12, gen_loss = 0.8928573855331966, disc_loss = 0.027575769158595775
Trained batch 70 in epoch 12, gen_loss = 0.8920219406275682, disc_loss = 0.027241270873994028
Trained batch 71 in epoch 12, gen_loss = 0.8897704242004288, disc_loss = 0.027542778177222418
Trained batch 72 in epoch 12, gen_loss = 0.8907493859121244, disc_loss = 0.031775705608434034
Trained batch 73 in epoch 12, gen_loss = 0.8911898659693228, disc_loss = 0.03145210134342149
Trained batch 74 in epoch 12, gen_loss = 0.8923623609542847, disc_loss = 0.031138085638716197
Trained batch 75 in epoch 12, gen_loss = 0.8906843505407634, disc_loss = 0.030814630368120943
Trained batch 76 in epoch 12, gen_loss = 0.8884406314267741, disc_loss = 0.031129890251163903
Trained batch 77 in epoch 12, gen_loss = 0.8898528287043939, disc_loss = 0.0309189354537431
Trained batch 78 in epoch 12, gen_loss = 0.8899240320241903, disc_loss = 0.03131542335628367
Trained batch 79 in epoch 12, gen_loss = 0.8880179785192013, disc_loss = 0.03107669453274866
Trained batch 80 in epoch 12, gen_loss = 0.8873488402660982, disc_loss = 0.030875066521988584
Trained batch 81 in epoch 12, gen_loss = 0.8861801188166548, disc_loss = 0.03059483697409344
Trained batch 82 in epoch 12, gen_loss = 0.887070340564452, disc_loss = 0.030274382564842318
Trained batch 83 in epoch 12, gen_loss = 0.8873412885836193, disc_loss = 0.029945065286440132
Trained batch 84 in epoch 12, gen_loss = 0.8882516825900358, disc_loss = 0.02961091009372681
Trained batch 85 in epoch 12, gen_loss = 0.8872262336486993, disc_loss = 0.02929310016787535
Trained batch 86 in epoch 12, gen_loss = 0.8862992593611794, disc_loss = 0.02898481560184556
Trained batch 87 in epoch 12, gen_loss = 0.8845891505479813, disc_loss = 0.02911450001854312
Trained batch 88 in epoch 12, gen_loss = 0.8864996888664332, disc_loss = 0.028917775251000095
Trained batch 89 in epoch 12, gen_loss = 0.8882643355263604, disc_loss = 0.028988084799493663
Trained batch 90 in epoch 12, gen_loss = 0.8896398164413788, disc_loss = 0.028756726074869142
Trained batch 91 in epoch 12, gen_loss = 0.8906050441057786, disc_loss = 0.028539561820608746
Trained batch 92 in epoch 12, gen_loss = 0.8912423163331965, disc_loss = 0.02829432008025657
Trained batch 93 in epoch 12, gen_loss = 0.8910131524217889, disc_loss = 0.02805691504413807
Trained batch 94 in epoch 12, gen_loss = 0.8930341613920112, disc_loss = 0.02781693833653423
Trained batch 95 in epoch 12, gen_loss = 0.8944051334013542, disc_loss = 0.027559426416398008
Trained batch 96 in epoch 12, gen_loss = 0.8931385008330198, disc_loss = 0.02747445261392733
Trained batch 97 in epoch 12, gen_loss = 0.8940668422348645, disc_loss = 0.02725672076322015
Trained batch 98 in epoch 12, gen_loss = 0.8952511994525639, disc_loss = 0.026998608528031976
Trained batch 99 in epoch 12, gen_loss = 0.8953738451004029, disc_loss = 0.02673851952975383
Trained batch 100 in epoch 12, gen_loss = 0.8941413848706992, disc_loss = 0.026664557941384743
Trained batch 101 in epoch 12, gen_loss = 0.8954354068812203, disc_loss = 0.026423468641131
Trained batch 102 in epoch 12, gen_loss = 0.8957208059366467, disc_loss = 0.026209145398681657
Trained batch 103 in epoch 12, gen_loss = 0.8968097040286431, disc_loss = 0.02603516648294037
Trained batch 104 in epoch 12, gen_loss = 0.8962233554749262, disc_loss = 0.025867876431272765
Trained batch 105 in epoch 12, gen_loss = 0.8964423481023537, disc_loss = 0.025708490107065718
Trained batch 106 in epoch 12, gen_loss = 0.8973756387969044, disc_loss = 0.025492732609767973
Trained batch 107 in epoch 12, gen_loss = 0.8978255026870303, disc_loss = 0.025268770747600314
Trained batch 108 in epoch 12, gen_loss = 0.898754657408513, disc_loss = 0.025048556341095443
Trained batch 109 in epoch 12, gen_loss = 0.8995396494865417, disc_loss = 0.024832381228440104
Trained batch 110 in epoch 12, gen_loss = 0.9004940589269003, disc_loss = 0.024619441025057674
Trained batch 111 in epoch 12, gen_loss = 0.9009529064808574, disc_loss = 0.024405107895550567
Trained batch 112 in epoch 12, gen_loss = 0.9009778531251755, disc_loss = 0.02419443944169299
Trained batch 113 in epoch 12, gen_loss = 0.9005638423718905, disc_loss = 0.023986454567516614
Trained batch 114 in epoch 12, gen_loss = 0.900780973745429, disc_loss = 0.023783541855442784
Trained batch 115 in epoch 12, gen_loss = 0.9002550054213097, disc_loss = 0.023582390073991925
Trained batch 116 in epoch 12, gen_loss = 0.9007575160417801, disc_loss = 0.023386825178053357
Trained batch 117 in epoch 12, gen_loss = 0.9000396198135311, disc_loss = 0.023199448559800225
Trained batch 118 in epoch 12, gen_loss = 0.8994874763889473, disc_loss = 0.023010246593606884
Trained batch 119 in epoch 12, gen_loss = 0.9001984069744746, disc_loss = 0.022834179071166243
Trained batch 120 in epoch 12, gen_loss = 0.89993932424498, disc_loss = 0.02271900815727605
Trained batch 121 in epoch 12, gen_loss = 0.8997391848290552, disc_loss = 0.02256438133238097
Trained batch 122 in epoch 12, gen_loss = 0.8997112720962462, disc_loss = 0.022388252951166917
Trained batch 123 in epoch 12, gen_loss = 0.9005073852116062, disc_loss = 0.022224234303482058
Trained batch 124 in epoch 12, gen_loss = 0.9000084142684937, disc_loss = 0.022104065573774277
Trained batch 125 in epoch 12, gen_loss = 0.90059799239749, disc_loss = 0.02193537555886285
Trained batch 126 in epoch 12, gen_loss = 0.9004718384404821, disc_loss = 0.021768393700825065
Trained batch 127 in epoch 12, gen_loss = 0.9007552382536232, disc_loss = 0.021605025894587016
Trained batch 128 in epoch 12, gen_loss = 0.9013210114582565, disc_loss = 0.021443046594233534
Trained batch 129 in epoch 12, gen_loss = 0.900937858911661, disc_loss = 0.021282155817159667
Trained batch 130 in epoch 12, gen_loss = 0.9018869718522516, disc_loss = 0.021153303263140202
Trained batch 131 in epoch 12, gen_loss = 0.9004117254958008, disc_loss = 0.02103285349475107
Trained batch 132 in epoch 12, gen_loss = 0.9009902051516941, disc_loss = 0.020945507099964004
Trained batch 133 in epoch 12, gen_loss = 0.9019319028107088, disc_loss = 0.02079497442890042
Trained batch 134 in epoch 12, gen_loss = 0.9019638374999718, disc_loss = 0.020647834797165598
Trained batch 135 in epoch 12, gen_loss = 0.901809948770439, disc_loss = 0.020512618999739916
Trained batch 136 in epoch 12, gen_loss = 0.90227575067186, disc_loss = 0.020372086833825975
Trained batch 137 in epoch 12, gen_loss = 0.9023679581241332, disc_loss = 0.020233524889445634
Trained batch 138 in epoch 12, gen_loss = 0.9030633688830644, disc_loss = 0.02009812951391134
Trained batch 139 in epoch 12, gen_loss = 0.9040776078190123, disc_loss = 0.019964541239148405
Trained batch 140 in epoch 12, gen_loss = 0.90407594932732, disc_loss = 0.019833063743496644
Trained batch 141 in epoch 12, gen_loss = 0.9021155397656938, disc_loss = 0.0200444160289177
Trained batch 142 in epoch 12, gen_loss = 0.902689949615852, disc_loss = 0.020546036684914927
Trained batch 143 in epoch 12, gen_loss = 0.9038234750429789, disc_loss = 0.020421834910343425
Trained batch 144 in epoch 12, gen_loss = 0.9037537550104076, disc_loss = 0.020296188311025115
Trained batch 145 in epoch 12, gen_loss = 0.9045277017436616, disc_loss = 0.020170919803267805
Trained batch 146 in epoch 12, gen_loss = 0.904791352700214, disc_loss = 0.0200417169197906
Trained batch 147 in epoch 12, gen_loss = 0.9050080671503737, disc_loss = 0.019911719989141676
Trained batch 148 in epoch 12, gen_loss = 0.9046531835658438, disc_loss = 0.019782187690608355
Trained batch 149 in epoch 12, gen_loss = 0.9048512188593546, disc_loss = 0.019654152983178696
Trained batch 150 in epoch 12, gen_loss = 0.904597408724147, disc_loss = 0.01952684072959576
Trained batch 151 in epoch 12, gen_loss = 0.9047261413774992, disc_loss = 0.019404382404708917
Trained batch 152 in epoch 12, gen_loss = 0.9056112555896535, disc_loss = 0.019282341155975304
Trained batch 153 in epoch 12, gen_loss = 0.9049177146577215, disc_loss = 0.019163266664171324
Trained batch 154 in epoch 12, gen_loss = 0.9047772861296131, disc_loss = 0.01904446266538974
Trained batch 155 in epoch 12, gen_loss = 0.9041066421912267, disc_loss = 0.018925418320764154
Trained batch 156 in epoch 12, gen_loss = 0.9041126533678383, disc_loss = 0.01880785268394033
Trained batch 157 in epoch 12, gen_loss = 0.9046061850046809, disc_loss = 0.01869128397028581
Trained batch 158 in epoch 12, gen_loss = 0.9045029533734111, disc_loss = 0.018577757625915285
Trained batch 159 in epoch 12, gen_loss = 0.9047721937298775, disc_loss = 0.01846436848063604
Trained batch 160 in epoch 12, gen_loss = 0.9052027837830301, disc_loss = 0.01835333889058172
Trained batch 161 in epoch 12, gen_loss = 0.9049666108172617, disc_loss = 0.018244661094712806
Trained batch 162 in epoch 12, gen_loss = 0.9046634549012214, disc_loss = 0.01813551971861704
Trained batch 163 in epoch 12, gen_loss = 0.9050411294873167, disc_loss = 0.018028230816991887
Trained batch 164 in epoch 12, gen_loss = 0.9048845059943922, disc_loss = 0.017922666510849287
Trained batch 165 in epoch 12, gen_loss = 0.9052257214684084, disc_loss = 0.017817444993107275
Trained batch 166 in epoch 12, gen_loss = 0.9052771950910191, disc_loss = 0.017716470226773737
Trained batch 167 in epoch 12, gen_loss = 0.906166455575398, disc_loss = 0.017615093311178498
Trained batch 168 in epoch 12, gen_loss = 0.906730777413182, disc_loss = 0.017513767239216098
Trained batch 169 in epoch 12, gen_loss = 0.9070402885184569, disc_loss = 0.01741423600230037
Trained batch 170 in epoch 12, gen_loss = 0.906217811051865, disc_loss = 0.017315634563075083
Trained batch 171 in epoch 12, gen_loss = 0.9059548561656198, disc_loss = 0.017218763533259504
Trained batch 172 in epoch 12, gen_loss = 0.9053165109860415, disc_loss = 0.0171256077925357
Trained batch 173 in epoch 12, gen_loss = 0.9056341757719544, disc_loss = 0.017033507054586006
Trained batch 174 in epoch 12, gen_loss = 0.9066884885515486, disc_loss = 0.016940399456237043
Trained batch 175 in epoch 12, gen_loss = 0.9068648930300366, disc_loss = 0.016847177695043767
Trained batch 176 in epoch 12, gen_loss = 0.9064104031708281, disc_loss = 0.016754314017621535
Trained batch 177 in epoch 12, gen_loss = 0.9068228930569766, disc_loss = 0.016664252643279857
Trained batch 178 in epoch 12, gen_loss = 0.9066358921248153, disc_loss = 0.016574473255873245
Trained batch 179 in epoch 12, gen_loss = 0.9066154052813847, disc_loss = 0.01648656349279918
Trained batch 180 in epoch 12, gen_loss = 0.9063948224921253, disc_loss = 0.01639874321434297
Trained batch 181 in epoch 12, gen_loss = 0.9062599936029413, disc_loss = 0.01631212537048978
Trained batch 182 in epoch 12, gen_loss = 0.906243152957145, disc_loss = 0.01622569620611828
Trained batch 183 in epoch 12, gen_loss = 0.9051818705123403, disc_loss = 0.016254140252029807
Trained batch 184 in epoch 12, gen_loss = 0.9030124983272036, disc_loss = 0.017426331487887012
Trained batch 185 in epoch 12, gen_loss = 0.904308654608265, disc_loss = 0.01887479987839157
Trained batch 186 in epoch 12, gen_loss = 0.904237335059732, disc_loss = 0.018848363973105693
Trained batch 187 in epoch 12, gen_loss = 0.9042526917888764, disc_loss = 0.01881536893965181
Trained batch 188 in epoch 12, gen_loss = 0.9043220959643208, disc_loss = 0.018757841979133744
Trained batch 189 in epoch 12, gen_loss = 0.9038780692376589, disc_loss = 0.018705497133717136
Trained batch 190 in epoch 12, gen_loss = 0.9030494565114925, disc_loss = 0.01864732826111536
Trained batch 191 in epoch 12, gen_loss = 0.9029902123535672, disc_loss = 0.01857329022520086
Trained batch 192 in epoch 12, gen_loss = 0.9032887056701542, disc_loss = 0.0186674200762015
Trained batch 193 in epoch 12, gen_loss = 0.9034662464844812, disc_loss = 0.018597651748874792
Trained batch 194 in epoch 12, gen_loss = 0.9037807125311631, disc_loss = 0.018523948831268802
Trained batch 195 in epoch 12, gen_loss = 0.9037039769547326, disc_loss = 0.018457894888825297
Trained batch 196 in epoch 12, gen_loss = 0.9044632951015144, disc_loss = 0.018386585527421142
Trained batch 197 in epoch 12, gen_loss = 0.9032773619348352, disc_loss = 0.018597927351947874
Trained batch 198 in epoch 12, gen_loss = 0.9043640296662873, disc_loss = 0.018917076844820312
Trained batch 199 in epoch 12, gen_loss = 0.9038339260220528, disc_loss = 0.01890511563338805
Trained batch 200 in epoch 12, gen_loss = 0.9023743781877395, disc_loss = 0.019356400759737772
Trained batch 201 in epoch 12, gen_loss = 0.9028863744570477, disc_loss = 0.019372661001542307
Trained batch 202 in epoch 12, gen_loss = 0.9034354149414401, disc_loss = 0.019352356213365174
Trained batch 203 in epoch 12, gen_loss = 0.9037476713750877, disc_loss = 0.01941206000628881
Trained batch 204 in epoch 12, gen_loss = 0.9036962003242679, disc_loss = 0.019385808141243348
Trained batch 205 in epoch 12, gen_loss = 0.90328949284785, disc_loss = 0.0193485997066815
Trained batch 206 in epoch 12, gen_loss = 0.9032641142462763, disc_loss = 0.019322739462458174
Trained batch 207 in epoch 12, gen_loss = 0.9033433282031462, disc_loss = 0.01925190142411828
Trained batch 208 in epoch 12, gen_loss = 0.9042909764216848, disc_loss = 0.019170645921286106
Trained batch 209 in epoch 12, gen_loss = 0.9046858029706137, disc_loss = 0.019091184750487586
Trained batch 210 in epoch 12, gen_loss = 0.9044826290618752, disc_loss = 0.01904277728872718
Trained batch 211 in epoch 12, gen_loss = 0.9042801109125029, disc_loss = 0.01901434186487986
Trained batch 212 in epoch 12, gen_loss = 0.9039374276505949, disc_loss = 0.018932893993048774
Trained batch 213 in epoch 12, gen_loss = 0.903744082306033, disc_loss = 0.018866606072466124
Trained batch 214 in epoch 12, gen_loss = 0.9037884623505349, disc_loss = 0.018790542947799832
Trained batch 215 in epoch 12, gen_loss = 0.9037429767626303, disc_loss = 0.018706997163934393
Trained batch 216 in epoch 12, gen_loss = 0.9027453389035941, disc_loss = 0.019235514616701015
Trained batch 217 in epoch 12, gen_loss = 0.9031762937340168, disc_loss = 0.019211610579978538
Trained batch 218 in epoch 12, gen_loss = 0.9034366637604422, disc_loss = 0.019402348803734773
Trained batch 219 in epoch 12, gen_loss = 0.9035222614353353, disc_loss = 0.019327658795307137
Trained batch 220 in epoch 12, gen_loss = 0.9043839848958529, disc_loss = 0.01925703372365934
Trained batch 221 in epoch 12, gen_loss = 0.904344991252229, disc_loss = 0.019183130571429896
Trained batch 222 in epoch 12, gen_loss = 0.9038447956867817, disc_loss = 0.0191124146360478
Trained batch 223 in epoch 12, gen_loss = 0.9041247788284507, disc_loss = 0.019034111806312076
Trained batch 224 in epoch 12, gen_loss = 0.9043824288580152, disc_loss = 0.018955981857143343
Trained batch 225 in epoch 12, gen_loss = 0.9044117278757349, disc_loss = 0.018880580444779017
Trained batch 226 in epoch 12, gen_loss = 0.9040217683178737, disc_loss = 0.018803029477551154
Trained batch 227 in epoch 12, gen_loss = 0.9047964168222327, disc_loss = 0.01872466597118897
Trained batch 228 in epoch 12, gen_loss = 0.9046114477528234, disc_loss = 0.018645860730847303
Trained batch 229 in epoch 12, gen_loss = 0.904904205902763, disc_loss = 0.018569117550910248
Trained batch 230 in epoch 12, gen_loss = 0.9052771479536444, disc_loss = 0.018491443749305538
Trained batch 231 in epoch 12, gen_loss = 0.905435181897262, disc_loss = 0.018414067339045718
Trained batch 232 in epoch 12, gen_loss = 0.9056665575043837, disc_loss = 0.018337247687613776
Trained batch 233 in epoch 12, gen_loss = 0.9063960532856803, disc_loss = 0.01826652346510225
Trained batch 234 in epoch 12, gen_loss = 0.9061922184964444, disc_loss = 0.01819255956810245
Trained batch 235 in epoch 12, gen_loss = 0.9065629791910366, disc_loss = 0.018118740159572277
Trained batch 236 in epoch 12, gen_loss = 0.9072919110708599, disc_loss = 0.018049301571244146
Trained batch 237 in epoch 12, gen_loss = 0.9069571725460661, disc_loss = 0.01797780138342602
Trained batch 238 in epoch 12, gen_loss = 0.9071827358780545, disc_loss = 0.01790544538121577
Trained batch 239 in epoch 12, gen_loss = 0.9066732766727607, disc_loss = 0.017832955927102982
Trained batch 240 in epoch 12, gen_loss = 0.9066359744527033, disc_loss = 0.017762159970704915
Trained batch 241 in epoch 12, gen_loss = 0.9063538687288268, disc_loss = 0.017690996622593595
Trained batch 242 in epoch 12, gen_loss = 0.9068360024518928, disc_loss = 0.01762920731358583
Trained batch 243 in epoch 12, gen_loss = 0.9069026811201064, disc_loss = 0.017561982120539932
Trained batch 244 in epoch 12, gen_loss = 0.9071916443961007, disc_loss = 0.017500474300159483
Trained batch 245 in epoch 12, gen_loss = 0.9070892106226789, disc_loss = 0.01743131387497041
Trained batch 246 in epoch 12, gen_loss = 0.9073672494907611, disc_loss = 0.017363170720589714
Trained batch 247 in epoch 12, gen_loss = 0.9072899628550776, disc_loss = 0.017295279453748896
Trained batch 248 in epoch 12, gen_loss = 0.9072014445281891, disc_loss = 0.017227722532920032
Trained batch 249 in epoch 12, gen_loss = 0.9070824084281921, disc_loss = 0.017160752137657255
Trained batch 250 in epoch 12, gen_loss = 0.9071950653634698, disc_loss = 0.0170939368719005
Trained batch 251 in epoch 12, gen_loss = 0.9076479794014067, disc_loss = 0.017028732473836353
Trained batch 252 in epoch 12, gen_loss = 0.9078481216204496, disc_loss = 0.016962704360195188
Trained batch 253 in epoch 12, gen_loss = 0.9075290051501567, disc_loss = 0.016897645685684273
Trained batch 254 in epoch 12, gen_loss = 0.9076336414206262, disc_loss = 0.016834109693573896
Trained batch 255 in epoch 12, gen_loss = 0.908305145567283, disc_loss = 0.016770843364156462
Trained batch 256 in epoch 12, gen_loss = 0.9085494198687809, disc_loss = 0.016707826291160216
Trained batch 257 in epoch 12, gen_loss = 0.9088341901006625, disc_loss = 0.016646689800328986
Trained batch 258 in epoch 12, gen_loss = 0.9089009876877184, disc_loss = 0.016584314447495023
Trained batch 259 in epoch 12, gen_loss = 0.9089933906610196, disc_loss = 0.016522818210740718
Trained batch 260 in epoch 12, gen_loss = 0.909331001541167, disc_loss = 0.01646081901856134
Trained batch 261 in epoch 12, gen_loss = 0.9090883092570851, disc_loss = 0.016403442728026584
Trained batch 262 in epoch 12, gen_loss = 0.9092520144502473, disc_loss = 0.01634320877229055
Trained batch 263 in epoch 12, gen_loss = 0.9093968563459136, disc_loss = 0.01628296294857688
Trained batch 264 in epoch 12, gen_loss = 0.9095657449848247, disc_loss = 0.016223151194160138
Trained batch 265 in epoch 12, gen_loss = 0.9096415175082988, disc_loss = 0.01616445139025975
Trained batch 266 in epoch 12, gen_loss = 0.909423279628325, disc_loss = 0.01610607740709956
Trained batch 267 in epoch 12, gen_loss = 0.9089089229480544, disc_loss = 0.016048991466471024
Trained batch 268 in epoch 12, gen_loss = 0.9089898655405718, disc_loss = 0.01599063388968655
Trained batch 269 in epoch 12, gen_loss = 0.9088284050976788, disc_loss = 0.015937969298101963
Trained batch 270 in epoch 12, gen_loss = 0.9091123573454544, disc_loss = 0.01588247304462666
Trained batch 271 in epoch 12, gen_loss = 0.909320351174649, disc_loss = 0.015832696143393953
Trained batch 272 in epoch 12, gen_loss = 0.9092274583303012, disc_loss = 0.015776872146199203
Trained batch 273 in epoch 12, gen_loss = 0.9094981705620341, disc_loss = 0.015721017900020746
Trained batch 274 in epoch 12, gen_loss = 0.9089446958628568, disc_loss = 0.015665725871222093
Trained batch 275 in epoch 12, gen_loss = 0.9085962262706481, disc_loss = 0.015610263361283443
Trained batch 276 in epoch 12, gen_loss = 0.9088500501446776, disc_loss = 0.015555072078941095
Trained batch 277 in epoch 12, gen_loss = 0.9093207712653729, disc_loss = 0.015502060466532247
Trained batch 278 in epoch 12, gen_loss = 0.9097629046354669, disc_loss = 0.015449827061160751
Trained batch 279 in epoch 12, gen_loss = 0.9099310436419078, disc_loss = 0.015396275396259235
Trained batch 280 in epoch 12, gen_loss = 0.9098840005881421, disc_loss = 0.015343622857161211
Trained batch 281 in epoch 12, gen_loss = 0.9097580818842489, disc_loss = 0.015291320196359504
Trained batch 282 in epoch 12, gen_loss = 0.9095683142068951, disc_loss = 0.015238999898274768
Trained batch 283 in epoch 12, gen_loss = 0.9098836993667442, disc_loss = 0.01518713173767614
Trained batch 284 in epoch 12, gen_loss = 0.91001029809316, disc_loss = 0.015134809101551868
Trained batch 285 in epoch 12, gen_loss = 0.9104254650069283, disc_loss = 0.015084190774563263
Trained batch 286 in epoch 12, gen_loss = 0.9102251633534448, disc_loss = 0.015032733373894788
Trained batch 287 in epoch 12, gen_loss = 0.9101952045328088, disc_loss = 0.014981735324504876
Trained batch 288 in epoch 12, gen_loss = 0.909966621019436, disc_loss = 0.014931809928737078
Trained batch 289 in epoch 12, gen_loss = 0.9096613230376408, disc_loss = 0.014882389186070589
Trained batch 290 in epoch 12, gen_loss = 0.9099266209553197, disc_loss = 0.014832187227343122
Trained batch 291 in epoch 12, gen_loss = 0.9098905169800536, disc_loss = 0.014783921139833059
Trained batch 292 in epoch 12, gen_loss = 0.9097314999778929, disc_loss = 0.014734816007294657
Trained batch 293 in epoch 12, gen_loss = 0.9098262304351443, disc_loss = 0.014685629016571666
Trained batch 294 in epoch 12, gen_loss = 0.9100340285543668, disc_loss = 0.014638117476765035
Trained batch 295 in epoch 12, gen_loss = 0.9099374361134864, disc_loss = 0.014589394171461873
Trained batch 296 in epoch 12, gen_loss = 0.9095850976227912, disc_loss = 0.014541372360786273
Trained batch 297 in epoch 12, gen_loss = 0.9097659497853093, disc_loss = 0.014493739447769735
Trained batch 298 in epoch 12, gen_loss = 0.9097174842620773, disc_loss = 0.014448395450650107
Trained batch 299 in epoch 12, gen_loss = 0.9095405308405559, disc_loss = 0.014403864156629425
Trained batch 300 in epoch 12, gen_loss = 0.9096890588931467, disc_loss = 0.014357167683550283
Trained batch 301 in epoch 12, gen_loss = 0.9099074996859822, disc_loss = 0.014311129239808755
Trained batch 302 in epoch 12, gen_loss = 0.9096614893513544, disc_loss = 0.01426512736793709
Trained batch 303 in epoch 12, gen_loss = 0.9097878427097672, disc_loss = 0.014218830282899083
Trained batch 304 in epoch 12, gen_loss = 0.9095969090696241, disc_loss = 0.01417330787665035
Trained batch 305 in epoch 12, gen_loss = 0.9093939328894896, disc_loss = 0.014128299600022824
Trained batch 306 in epoch 12, gen_loss = 0.9094850560741238, disc_loss = 0.014083328984246638
Trained batch 307 in epoch 12, gen_loss = 0.9093934974887155, disc_loss = 0.014038788948131365
Trained batch 308 in epoch 12, gen_loss = 0.9088366322918617, disc_loss = 0.013994680962332789
Trained batch 309 in epoch 12, gen_loss = 0.9090681827837421, disc_loss = 0.013951651128281223
Trained batch 310 in epoch 12, gen_loss = 0.9086585512498567, disc_loss = 0.013910344708308509
Trained batch 311 in epoch 12, gen_loss = 0.9087738769176679, disc_loss = 0.013866707566240878
Trained batch 312 in epoch 12, gen_loss = 0.9088840532226684, disc_loss = 0.013823453518039451
Trained batch 313 in epoch 12, gen_loss = 0.9087302606956215, disc_loss = 0.013782511148955836
Trained batch 314 in epoch 12, gen_loss = 0.9084812608976213, disc_loss = 0.013739308766006226
Trained batch 315 in epoch 12, gen_loss = 0.9086644938097724, disc_loss = 0.013696658667580363
Trained batch 316 in epoch 12, gen_loss = 0.9085636422837194, disc_loss = 0.013654411546524236
Trained batch 317 in epoch 12, gen_loss = 0.9085533954437424, disc_loss = 0.01361252133068797
Trained batch 318 in epoch 12, gen_loss = 0.9084367337271712, disc_loss = 0.01357057893129254
Trained batch 319 in epoch 12, gen_loss = 0.908338662609458, disc_loss = 0.013531800928876691
Trained batch 320 in epoch 12, gen_loss = 0.9084987363711324, disc_loss = 0.013491004130651092
Trained batch 321 in epoch 12, gen_loss = 0.9084298906859404, disc_loss = 0.013451556453919862
Trained batch 322 in epoch 12, gen_loss = 0.9084154369292244, disc_loss = 0.013411737624932463
Trained batch 323 in epoch 12, gen_loss = 0.9082012351280377, disc_loss = 0.01337176766164815
Trained batch 324 in epoch 12, gen_loss = 0.9079903068909279, disc_loss = 0.013331811511396573
Trained batch 325 in epoch 12, gen_loss = 0.907937985439242, disc_loss = 0.013292162228874546
Trained batch 326 in epoch 12, gen_loss = 0.90768207705349, disc_loss = 0.013252492797952957
Trained batch 327 in epoch 12, gen_loss = 0.9080253804965717, disc_loss = 0.01321283067480225
Trained batch 328 in epoch 12, gen_loss = 0.9080170452775926, disc_loss = 0.013174404077400668
Trained batch 329 in epoch 12, gen_loss = 0.9073852768450072, disc_loss = 0.013142164635770094
Trained batch 330 in epoch 12, gen_loss = 0.9074129604500947, disc_loss = 0.013103619532343465
Trained batch 331 in epoch 12, gen_loss = 0.9071912198181612, disc_loss = 0.013065903035249541
Trained batch 332 in epoch 12, gen_loss = 0.907056753520851, disc_loss = 0.013027572621863725
Trained batch 333 in epoch 12, gen_loss = 0.9068799925421527, disc_loss = 0.01298940427289212
Trained batch 334 in epoch 12, gen_loss = 0.9070799546455269, disc_loss = 0.012951850544082683
Trained batch 335 in epoch 12, gen_loss = 0.907394891338689, disc_loss = 0.012914176794765808
Trained batch 336 in epoch 12, gen_loss = 0.9073931771145376, disc_loss = 0.01287639018181692
Trained batch 337 in epoch 12, gen_loss = 0.9072258262591955, disc_loss = 0.012839099831091097
Trained batch 338 in epoch 12, gen_loss = 0.9069061295121117, disc_loss = 0.012801796931239081
Trained batch 339 in epoch 12, gen_loss = 0.9066132014288621, disc_loss = 0.012767547043211595
Trained batch 340 in epoch 12, gen_loss = 0.9064206323665608, disc_loss = 0.012731018338435741
Trained batch 341 in epoch 12, gen_loss = 0.9063944961243903, disc_loss = 0.012694966184160513
Trained batch 342 in epoch 12, gen_loss = 0.906674523569057, disc_loss = 0.012659737987256454
Trained batch 343 in epoch 12, gen_loss = 0.9063826932810074, disc_loss = 0.012623762693269676
Trained batch 344 in epoch 12, gen_loss = 0.9061164214991141, disc_loss = 0.012587739613777755
Trained batch 345 in epoch 12, gen_loss = 0.9062499615842896, disc_loss = 0.012557060313929206
Trained batch 346 in epoch 12, gen_loss = 0.9059335914056652, disc_loss = 0.012522595679764542
Trained batch 347 in epoch 12, gen_loss = 0.9057609146011287, disc_loss = 0.012487787504873811
Trained batch 348 in epoch 12, gen_loss = 0.9057118706511905, disc_loss = 0.01245298993624987
Trained batch 349 in epoch 12, gen_loss = 0.9058476671150753, disc_loss = 0.012418155813024247
Trained batch 350 in epoch 12, gen_loss = 0.9056545086735673, disc_loss = 0.012383902625199355
Trained batch 351 in epoch 12, gen_loss = 0.9054337057539008, disc_loss = 0.012349709182093317
Trained batch 352 in epoch 12, gen_loss = 0.9052796319929128, disc_loss = 0.012315514711738978
Trained batch 353 in epoch 12, gen_loss = 0.9050845254612507, disc_loss = 0.012281360188004164
Trained batch 354 in epoch 12, gen_loss = 0.904815152161558, disc_loss = 0.012251092592036208
Trained batch 355 in epoch 12, gen_loss = 0.9049709754043751, disc_loss = 0.012217438818317553
Trained batch 356 in epoch 12, gen_loss = 0.9047849044746378, disc_loss = 0.012184246303277229
Trained batch 357 in epoch 12, gen_loss = 0.9047851802250526, disc_loss = 0.012151158726427837
Trained batch 358 in epoch 12, gen_loss = 0.9047432417324991, disc_loss = 0.01212169709082785
Trained batch 359 in epoch 12, gen_loss = 0.904511591957675, disc_loss = 0.012089089230034409
Trained batch 360 in epoch 12, gen_loss = 0.9044334809205539, disc_loss = 0.01205765145449155
Trained batch 361 in epoch 12, gen_loss = 0.9043461772618373, disc_loss = 0.012024914177883293
Trained batch 362 in epoch 12, gen_loss = 0.9041977165159115, disc_loss = 0.011992501524840186
Trained batch 363 in epoch 12, gen_loss = 0.9045472793526702, disc_loss = 0.011963410228318126
Trained batch 364 in epoch 12, gen_loss = 0.9042819068856436, disc_loss = 0.011931855937670151
Trained batch 365 in epoch 12, gen_loss = 0.9041253139412468, disc_loss = 0.011900195237322293
Trained batch 366 in epoch 12, gen_loss = 0.9042009134708373, disc_loss = 0.01187194432047886
Trained batch 367 in epoch 12, gen_loss = 0.9038588158462358, disc_loss = 0.01184089398212445
Trained batch 368 in epoch 12, gen_loss = 0.9039726399470797, disc_loss = 0.01181051023498488
Trained batch 369 in epoch 12, gen_loss = 0.9040558963208585, disc_loss = 0.011779589864592118
Trained batch 370 in epoch 12, gen_loss = 0.9037193888923871, disc_loss = 0.011748610135068052
Trained batch 371 in epoch 12, gen_loss = 0.9038058806170699, disc_loss = 0.011718384708513841
Trained batch 372 in epoch 12, gen_loss = 0.9038556293252327, disc_loss = 0.011688009780537007
Trained batch 373 in epoch 12, gen_loss = 0.9037221172914148, disc_loss = 0.01165794533161312
Trained batch 374 in epoch 12, gen_loss = 0.9037626686096192, disc_loss = 0.011628092247682313
Trained batch 375 in epoch 12, gen_loss = 0.9038265463202557, disc_loss = 0.011597767009469804
Trained batch 376 in epoch 12, gen_loss = 0.9035828753871058, disc_loss = 0.011567583230734167
Trained batch 377 in epoch 12, gen_loss = 0.9040575543093303, disc_loss = 0.011538799941754116
Trained batch 378 in epoch 12, gen_loss = 0.904637230260391, disc_loss = 0.011511819403358098
Trained batch 379 in epoch 12, gen_loss = 0.904325825760239, disc_loss = 0.011482740299451458
Trained batch 380 in epoch 12, gen_loss = 0.9041344332569853, disc_loss = 0.011453479134188623
Trained batch 381 in epoch 12, gen_loss = 0.9042570168123195, disc_loss = 0.011424055252226036
Trained batch 382 in epoch 12, gen_loss = 0.9045219239304645, disc_loss = 0.011396659438376127
Trained batch 383 in epoch 12, gen_loss = 0.9043424907140434, disc_loss = 0.011371238584843013
Trained batch 384 in epoch 12, gen_loss = 0.9044740954002777, disc_loss = 0.01134258496715663
Trained batch 385 in epoch 12, gen_loss = 0.9044481818540109, disc_loss = 0.011313976722916013
Trained batch 386 in epoch 12, gen_loss = 0.9042825193676222, disc_loss = 0.011285674179939057
Trained batch 387 in epoch 12, gen_loss = 0.9042034092330441, disc_loss = 0.011257414068017375
Trained batch 388 in epoch 12, gen_loss = 0.9043160794939664, disc_loss = 0.011229931527705609
Trained batch 389 in epoch 12, gen_loss = 0.9043334187605442, disc_loss = 0.011202027158623633
Trained batch 390 in epoch 12, gen_loss = 0.904061791537058, disc_loss = 0.011174013970218494
Trained batch 391 in epoch 12, gen_loss = 0.9042913816413101, disc_loss = 0.011146859972819695
Trained batch 392 in epoch 12, gen_loss = 0.9044107127432301, disc_loss = 0.011119466733676796
Trained batch 393 in epoch 12, gen_loss = 0.9040944605006784, disc_loss = 0.011091849492955302
Trained batch 394 in epoch 12, gen_loss = 0.9042527399485625, disc_loss = 0.011064223414088033
Trained batch 395 in epoch 12, gen_loss = 0.9043235239958523, disc_loss = 0.011036633445811928
Trained batch 396 in epoch 12, gen_loss = 0.9042057797350271, disc_loss = 0.01100954418574983
Trained batch 397 in epoch 12, gen_loss = 0.904014919570942, disc_loss = 0.010982392241066233
Trained batch 398 in epoch 12, gen_loss = 0.9039754237148696, disc_loss = 0.010955477017999152
Trained batch 399 in epoch 12, gen_loss = 0.904078024327755, disc_loss = 0.01092886086225917
Trained batch 400 in epoch 12, gen_loss = 0.903853340339185, disc_loss = 0.01090223715834243
Trained batch 401 in epoch 12, gen_loss = 0.9038813805105674, disc_loss = 0.010881474628145066
Trained batch 402 in epoch 12, gen_loss = 0.9039938281250947, disc_loss = 0.01085535575895427
Trained batch 403 in epoch 12, gen_loss = 0.9038539720643864, disc_loss = 0.010829349509702584
Trained batch 404 in epoch 12, gen_loss = 0.9035720887007537, disc_loss = 0.010803113776233254
Trained batch 405 in epoch 12, gen_loss = 0.9033995816860293, disc_loss = 0.010777035475804027
Trained batch 406 in epoch 12, gen_loss = 0.9033664318501803, disc_loss = 0.010751056473973066
Trained batch 407 in epoch 12, gen_loss = 0.9030071974677198, disc_loss = 0.010725678340795818
Trained batch 408 in epoch 12, gen_loss = 0.902959790089894, disc_loss = 0.010699939077365961
Trained batch 409 in epoch 12, gen_loss = 0.9029813440834603, disc_loss = 0.010674898400363262
Trained batch 410 in epoch 12, gen_loss = 0.9031735880531534, disc_loss = 0.010649522571170753
Trained batch 411 in epoch 12, gen_loss = 0.9032424853264707, disc_loss = 0.01062402831571622
Trained batch 412 in epoch 12, gen_loss = 0.9035290266064697, disc_loss = 0.010599598898729941
Trained batch 413 in epoch 12, gen_loss = 0.9035279133181641, disc_loss = 0.01057548219556549
Trained batch 414 in epoch 12, gen_loss = 0.9034253541245518, disc_loss = 0.010552552382599181
Trained batch 415 in epoch 12, gen_loss = 0.9036003427150158, disc_loss = 0.010527627955560512
Trained batch 416 in epoch 12, gen_loss = 0.9037131787204057, disc_loss = 0.010503037030786573
Trained batch 417 in epoch 12, gen_loss = 0.9039141386034386, disc_loss = 0.010478541806333811
Trained batch 418 in epoch 12, gen_loss = 0.9043058587998365, disc_loss = 0.010454742994798772
Trained batch 419 in epoch 12, gen_loss = 0.9042392781802586, disc_loss = 0.010430464973095306
Trained batch 420 in epoch 12, gen_loss = 0.9040448911965885, disc_loss = 0.010406927657008088
Trained batch 421 in epoch 12, gen_loss = 0.9039407445921153, disc_loss = 0.010382831212788626
Trained batch 422 in epoch 12, gen_loss = 0.9037262965037749, disc_loss = 0.01035883473324585
Trained batch 423 in epoch 12, gen_loss = 0.9034098809901273, disc_loss = 0.01033497350963787
Trained batch 424 in epoch 12, gen_loss = 0.9033073244375341, disc_loss = 0.010310932704134542
Trained batch 425 in epoch 12, gen_loss = 0.903329654618608, disc_loss = 0.01028719377799816
Trained batch 426 in epoch 12, gen_loss = 0.903631176965298, disc_loss = 0.010263655028217751
Trained batch 427 in epoch 12, gen_loss = 0.9035769117491268, disc_loss = 0.010240293518049457
Trained batch 428 in epoch 12, gen_loss = 0.9033542205959489, disc_loss = 0.010217218739005692
Trained batch 429 in epoch 12, gen_loss = 0.9030347627262737, disc_loss = 0.010193892700890713
Trained batch 430 in epoch 12, gen_loss = 0.9027059574691436, disc_loss = 0.01017260935260245
Trained batch 431 in epoch 12, gen_loss = 0.9026030126821112, disc_loss = 0.010150015225092459
Trained batch 432 in epoch 12, gen_loss = 0.9022603650291302, disc_loss = 0.010128248802093304
Trained batch 433 in epoch 12, gen_loss = 0.9022552306476277, disc_loss = 0.010105612594570587
Trained batch 434 in epoch 12, gen_loss = 0.9024094232197466, disc_loss = 0.010083248960633692
Trained batch 435 in epoch 12, gen_loss = 0.9024198323214819, disc_loss = 0.010061432024143736
Trained batch 436 in epoch 12, gen_loss = 0.9026042048390998, disc_loss = 0.010038994387228673
Trained batch 437 in epoch 12, gen_loss = 0.9025087966222197, disc_loss = 0.010016540759962693
Trained batch 438 in epoch 12, gen_loss = 0.9028256189307211, disc_loss = 0.00999436059944872
Trained batch 439 in epoch 12, gen_loss = 0.9025606878779151, disc_loss = 0.009972193804539778
Trained batch 440 in epoch 12, gen_loss = 0.9027982569065224, disc_loss = 0.00995167843023589
Trained batch 441 in epoch 12, gen_loss = 0.902674621046938, disc_loss = 0.00992954497391053
Trained batch 442 in epoch 12, gen_loss = 0.9027012454736851, disc_loss = 0.009907766896643352
Trained batch 443 in epoch 12, gen_loss = 0.9025446713507712, disc_loss = 0.009885911861839541
Trained batch 444 in epoch 12, gen_loss = 0.9025671282511079, disc_loss = 0.009864598642357787
Trained batch 445 in epoch 12, gen_loss = 0.9026714548669054, disc_loss = 0.009843117289022348
Trained batch 446 in epoch 12, gen_loss = 0.9025397950104153, disc_loss = 0.009821473122892773
Trained batch 447 in epoch 12, gen_loss = 0.9030480535168733, disc_loss = 0.009800890080457845
Trained batch 448 in epoch 12, gen_loss = 0.9029045427562399, disc_loss = 0.009779386922750412
Trained batch 449 in epoch 12, gen_loss = 0.9030363814036051, disc_loss = 0.00975803862987151
Trained batch 450 in epoch 12, gen_loss = 0.9032815010214592, disc_loss = 0.009737039695663854
Trained batch 451 in epoch 12, gen_loss = 0.9031462447833171, disc_loss = 0.009715711789513321
Trained batch 452 in epoch 12, gen_loss = 0.9031939114429567, disc_loss = 0.00969495900451305
Trained batch 453 in epoch 12, gen_loss = 0.9031610526965053, disc_loss = 0.009673983917758408
Trained batch 454 in epoch 12, gen_loss = 0.9031980162138468, disc_loss = 0.009653270250818932
Trained batch 455 in epoch 12, gen_loss = 0.9029174662734333, disc_loss = 0.009632747324535
Trained batch 456 in epoch 12, gen_loss = 0.9029734040767411, disc_loss = 0.009612187847263394
Trained batch 457 in epoch 12, gen_loss = 0.9025919447819739, disc_loss = 0.00959164566942427
Trained batch 458 in epoch 12, gen_loss = 0.9026693973146492, disc_loss = 0.009571229661300638
Trained batch 459 in epoch 12, gen_loss = 0.9024434024872987, disc_loss = 0.009552268706260214
Trained batch 460 in epoch 12, gen_loss = 0.9023320455096032, disc_loss = 0.009532151838420226
Trained batch 461 in epoch 12, gen_loss = 0.902219188935829, disc_loss = 0.009512179176635195
Trained batch 462 in epoch 12, gen_loss = 0.9021551812441766, disc_loss = 0.009492213087907332
Trained batch 463 in epoch 12, gen_loss = 0.9019643218609793, disc_loss = 0.009471983966971588
Trained batch 464 in epoch 12, gen_loss = 0.9019821601529275, disc_loss = 0.009451891088098418
Trained batch 465 in epoch 12, gen_loss = 0.9018390341122263, disc_loss = 0.009431916343960301
Trained batch 466 in epoch 12, gen_loss = 0.9019477092990018, disc_loss = 0.009412416665570768
Trained batch 467 in epoch 12, gen_loss = 0.9018199862832696, disc_loss = 0.009392690635323584
Trained batch 468 in epoch 12, gen_loss = 0.901993634985454, disc_loss = 0.009373134893976074
Trained batch 469 in epoch 12, gen_loss = 0.9018177405316778, disc_loss = 0.009353461100947745
Trained batch 470 in epoch 12, gen_loss = 0.9019873754740267, disc_loss = 0.009333996010824125
Trained batch 471 in epoch 12, gen_loss = 0.9020441669528767, disc_loss = 0.009315154060582784
Trained batch 472 in epoch 12, gen_loss = 0.901842027587568, disc_loss = 0.009295799094535328
Trained batch 473 in epoch 12, gen_loss = 0.9018772677027224, disc_loss = 0.009277126289617254
Trained batch 474 in epoch 12, gen_loss = 0.901738560325221, disc_loss = 0.009257935899199526
Trained batch 475 in epoch 12, gen_loss = 0.9019320669795284, disc_loss = 0.009238969916348178
Trained batch 476 in epoch 12, gen_loss = 0.9018599522188775, disc_loss = 0.009220414833176444
Trained batch 477 in epoch 12, gen_loss = 0.9015888866021543, disc_loss = 0.00920182684298593
Trained batch 478 in epoch 12, gen_loss = 0.9016076423429995, disc_loss = 0.009182953845269907
Trained batch 479 in epoch 12, gen_loss = 0.9016969343026479, disc_loss = 0.009164762120569018
Trained batch 480 in epoch 12, gen_loss = 0.9015054269045157, disc_loss = 0.0091461813137656
Trained batch 481 in epoch 12, gen_loss = 0.9014858646758859, disc_loss = 0.00912803953156166
Trained batch 482 in epoch 12, gen_loss = 0.9015562328245822, disc_loss = 0.009109623393198854
Trained batch 483 in epoch 12, gen_loss = 0.9014819128946825, disc_loss = 0.009091303818182074
Trained batch 484 in epoch 12, gen_loss = 0.9016697184326723, disc_loss = 0.0090733863657266
Trained batch 485 in epoch 12, gen_loss = 0.901626963551643, disc_loss = 0.009055433099927264
Trained batch 486 in epoch 12, gen_loss = 0.9018190485985617, disc_loss = 0.009037532676347184
Trained batch 487 in epoch 12, gen_loss = 0.9018716282043301, disc_loss = 0.009019731274002268
Trained batch 488 in epoch 12, gen_loss = 0.9020907559521603, disc_loss = 0.009001613869471048
Trained batch 489 in epoch 12, gen_loss = 0.9019265364627449, disc_loss = 0.008983987852680373
Trained batch 490 in epoch 12, gen_loss = 0.9017127048216623, disc_loss = 0.008966000830237053
Trained batch 491 in epoch 12, gen_loss = 0.9015867058339158, disc_loss = 0.008948044981945891
Trained batch 492 in epoch 12, gen_loss = 0.9014827777115859, disc_loss = 0.008930216181851379
Trained batch 493 in epoch 12, gen_loss = 0.9016902557751427, disc_loss = 0.008912967799407211
Trained batch 494 in epoch 12, gen_loss = 0.9018341997657159, disc_loss = 0.008895500035805986
Trained batch 495 in epoch 12, gen_loss = 0.9016783708526243, disc_loss = 0.008877953755502184
Trained batch 496 in epoch 12, gen_loss = 0.901422346501763, disc_loss = 0.00886064558407063
Trained batch 497 in epoch 12, gen_loss = 0.9011869584939566, disc_loss = 0.008843427417431883
Trained batch 498 in epoch 12, gen_loss = 0.9013228515584866, disc_loss = 0.008826212953710331
Trained batch 499 in epoch 12, gen_loss = 0.9014190367460251, disc_loss = 0.008809500398521778
Trained batch 500 in epoch 12, gen_loss = 0.901230695480834, disc_loss = 0.008792190125625453
Trained batch 501 in epoch 12, gen_loss = 0.9012282826748502, disc_loss = 0.008775092927518484
Trained batch 502 in epoch 12, gen_loss = 0.9012783288244699, disc_loss = 0.008758003819119611
Trained batch 503 in epoch 12, gen_loss = 0.9009979448857761, disc_loss = 0.00874131029686107
Trained batch 504 in epoch 12, gen_loss = 0.9008914370347958, disc_loss = 0.008724475192052479
Trained batch 505 in epoch 12, gen_loss = 0.9010246057990983, disc_loss = 0.008707598331189953
Trained batch 506 in epoch 12, gen_loss = 0.9010328017983446, disc_loss = 0.008690760335482012
Trained batch 507 in epoch 12, gen_loss = 0.9010162254956764, disc_loss = 0.008673966996064437
Trained batch 508 in epoch 12, gen_loss = 0.9010162325411274, disc_loss = 0.008657450883182484
Trained batch 509 in epoch 12, gen_loss = 0.9010527765049654, disc_loss = 0.008640835494374829
Trained batch 510 in epoch 12, gen_loss = 0.9008751771687995, disc_loss = 0.008624536644854425
Trained batch 511 in epoch 12, gen_loss = 0.9008608703734353, disc_loss = 0.008607939438945778
Trained batch 512 in epoch 12, gen_loss = 0.9007327260329709, disc_loss = 0.00859141217991274
Trained batch 513 in epoch 12, gen_loss = 0.9007236736061972, disc_loss = 0.008575199631276969
Trained batch 514 in epoch 12, gen_loss = 0.9005478602011227, disc_loss = 0.00855882930901643
Trained batch 515 in epoch 12, gen_loss = 0.9005298325719759, disc_loss = 0.008542553052224278
Trained batch 516 in epoch 12, gen_loss = 0.9002549752045416, disc_loss = 0.008526381128180521
Trained batch 517 in epoch 12, gen_loss = 0.9003083505685725, disc_loss = 0.008510083307562784
Trained batch 518 in epoch 12, gen_loss = 0.9002568544909674, disc_loss = 0.008494024539020595
Trained batch 519 in epoch 12, gen_loss = 0.9002564833714412, disc_loss = 0.008478125054996502
Trained batch 520 in epoch 12, gen_loss = 0.9004869662411153, disc_loss = 0.008462250398702882
Trained batch 521 in epoch 12, gen_loss = 0.9004690440450135, disc_loss = 0.008446270037356918
Trained batch 522 in epoch 12, gen_loss = 0.9005672031333296, disc_loss = 0.00843114515103012
Trained batch 523 in epoch 12, gen_loss = 0.900420437332328, disc_loss = 0.008415284764087396
Trained batch 524 in epoch 12, gen_loss = 0.900331054642087, disc_loss = 0.008399457459884054
Trained batch 525 in epoch 12, gen_loss = 0.9003558473895258, disc_loss = 0.00838372573068535
Trained batch 526 in epoch 12, gen_loss = 0.9003240946800478, disc_loss = 0.008368045498116209
Trained batch 527 in epoch 12, gen_loss = 0.9001370178479137, disc_loss = 0.008352531412928136
Trained batch 528 in epoch 12, gen_loss = 0.8999276918364383, disc_loss = 0.008337032172746608
Trained batch 529 in epoch 12, gen_loss = 0.8999082428104472, disc_loss = 0.0083218931451106
Trained batch 530 in epoch 12, gen_loss = 0.9000499987108335, disc_loss = 0.008306451356906634
Trained batch 531 in epoch 12, gen_loss = 0.9000699473054785, disc_loss = 0.008291205786788072
Trained batch 532 in epoch 12, gen_loss = 0.9001442625643389, disc_loss = 0.008275861861017152
Trained batch 533 in epoch 12, gen_loss = 0.8999836623445432, disc_loss = 0.008260687694758176
Trained batch 534 in epoch 12, gen_loss = 0.8998354016063369, disc_loss = 0.00824550940115527
Trained batch 535 in epoch 12, gen_loss = 0.8999699075052987, disc_loss = 0.00823057788997474
Trained batch 536 in epoch 12, gen_loss = 0.899901913752991, disc_loss = 0.00821562362394189
Trained batch 537 in epoch 12, gen_loss = 0.8998886026635933, disc_loss = 0.008200682353193276
Trained batch 538 in epoch 12, gen_loss = 0.8999073277599073, disc_loss = 0.008185623951233813
Trained batch 539 in epoch 12, gen_loss = 0.8999745137161679, disc_loss = 0.008170700459083524
Trained batch 540 in epoch 12, gen_loss = 0.8999985062040374, disc_loss = 0.008155944303767808
Trained batch 541 in epoch 12, gen_loss = 0.8998393977260237, disc_loss = 0.008141211738920129
Trained batch 542 in epoch 12, gen_loss = 0.8995762439942052, disc_loss = 0.008126964207825896
Trained batch 543 in epoch 12, gen_loss = 0.8996422534041545, disc_loss = 0.0081124256829325
Trained batch 544 in epoch 12, gen_loss = 0.8996705175539769, disc_loss = 0.008098191028613588
Trained batch 545 in epoch 12, gen_loss = 0.8997072828558338, disc_loss = 0.008083850938792473
Trained batch 546 in epoch 12, gen_loss = 0.8996279223309575, disc_loss = 0.008069354419099973
Trained batch 547 in epoch 12, gen_loss = 0.8996866894681959, disc_loss = 0.008054917078129786
Trained batch 548 in epoch 12, gen_loss = 0.8995852761364157, disc_loss = 0.008040559525258681
Trained batch 549 in epoch 12, gen_loss = 0.8997126212987033, disc_loss = 0.008026197480953257
Trained batch 550 in epoch 12, gen_loss = 0.8997420265107752, disc_loss = 0.008011960905250635
Trained batch 551 in epoch 12, gen_loss = 0.8996494425379712, disc_loss = 0.007997753397791277
Trained batch 552 in epoch 12, gen_loss = 0.8996215610348941, disc_loss = 0.007983501311130552
Trained batch 553 in epoch 12, gen_loss = 0.8996288142694894, disc_loss = 0.007969299629844943
Trained batch 554 in epoch 12, gen_loss = 0.8995401437218125, disc_loss = 0.00795537667706355
Trained batch 555 in epoch 12, gen_loss = 0.8995621586017472, disc_loss = 0.007941443410011828
Trained batch 556 in epoch 12, gen_loss = 0.8995609664403343, disc_loss = 0.00792763918682695
Trained batch 557 in epoch 12, gen_loss = 0.8993076770749998, disc_loss = 0.007913698635380035
Trained batch 558 in epoch 12, gen_loss = 0.899357063292604, disc_loss = 0.007899810573909693
Trained batch 559 in epoch 12, gen_loss = 0.8992819248565606, disc_loss = 0.00788587241600648
Trained batch 560 in epoch 12, gen_loss = 0.8991343858195286, disc_loss = 0.007872049240459237
Trained batch 561 in epoch 12, gen_loss = 0.8991089366721089, disc_loss = 0.007858377372251191
Trained batch 562 in epoch 12, gen_loss = 0.8991080907902963, disc_loss = 0.007844614717338815
Trained batch 563 in epoch 12, gen_loss = 0.8991694079434618, disc_loss = 0.007830973824361568
Trained batch 564 in epoch 12, gen_loss = 0.8992745854158317, disc_loss = 0.007817302336859665
Trained batch 565 in epoch 12, gen_loss = 0.8993093142871722, disc_loss = 0.00780401331874523
Trained batch 566 in epoch 12, gen_loss = 0.8991903023534772, disc_loss = 0.007790473902251446
Trained batch 567 in epoch 12, gen_loss = 0.8991729332737519, disc_loss = 0.007776896777869925
Trained batch 568 in epoch 12, gen_loss = 0.8991740312433829, disc_loss = 0.007763484349156266
Trained batch 569 in epoch 12, gen_loss = 0.8992127241795523, disc_loss = 0.007750046633353984
Trained batch 570 in epoch 12, gen_loss = 0.8992972315506008, disc_loss = 0.00773664492558031
Trained batch 571 in epoch 12, gen_loss = 0.8991379152227948, disc_loss = 0.007723373541291669
Trained batch 572 in epoch 12, gen_loss = 0.8992466310764067, disc_loss = 0.007710136181619941
Trained batch 573 in epoch 12, gen_loss = 0.8992568263816502, disc_loss = 0.007697335898884607
Trained batch 574 in epoch 12, gen_loss = 0.8990804791450501, disc_loss = 0.007684186992106413
Trained batch 575 in epoch 12, gen_loss = 0.8991090448366271, disc_loss = 0.007671259425440742
Trained batch 576 in epoch 12, gen_loss = 0.8993325576418607, disc_loss = 0.007658529055516774
Trained batch 577 in epoch 12, gen_loss = 0.899468803694504, disc_loss = 0.007645603112855166
Trained batch 578 in epoch 12, gen_loss = 0.8995888098328019, disc_loss = 0.007632606237725534
Trained batch 579 in epoch 12, gen_loss = 0.8996462514688228, disc_loss = 0.007619679357883107
Trained batch 580 in epoch 12, gen_loss = 0.8995994414602008, disc_loss = 0.007606772657823645
Trained batch 581 in epoch 12, gen_loss = 0.8996625403358355, disc_loss = 0.0075938722446878505
Trained batch 582 in epoch 12, gen_loss = 0.8996921320722198, disc_loss = 0.007581013659479362
Trained batch 583 in epoch 12, gen_loss = 0.8996498564334765, disc_loss = 0.0075683502132487274
Trained batch 584 in epoch 12, gen_loss = 0.8996564100950192, disc_loss = 0.007555680908138354
Trained batch 585 in epoch 12, gen_loss = 0.8996778047125494, disc_loss = 0.007543115020882968
Trained batch 586 in epoch 12, gen_loss = 0.8997680043240016, disc_loss = 0.007530523825873537
Trained batch 587 in epoch 12, gen_loss = 0.8998913504436713, disc_loss = 0.007518593448447459
Trained batch 588 in epoch 12, gen_loss = 0.8999127186012592, disc_loss = 0.0075063756037071026
Trained batch 589 in epoch 12, gen_loss = 0.8997034309274059, disc_loss = 0.007494047666422359
Trained batch 590 in epoch 12, gen_loss = 0.8996447378205366, disc_loss = 0.007481580087058199
Trained batch 591 in epoch 12, gen_loss = 0.8998124574285906, disc_loss = 0.007469481094262478
Trained batch 592 in epoch 12, gen_loss = 0.8998167974148794, disc_loss = 0.0074570401563274
Trained batch 593 in epoch 12, gen_loss = 0.8998079119306622, disc_loss = 0.007444958025333334
Trained batch 594 in epoch 12, gen_loss = 0.8998078741947142, disc_loss = 0.007432658329374693
Trained batch 595 in epoch 12, gen_loss = 0.899925689869279, disc_loss = 0.007420405503776024
Trained batch 596 in epoch 12, gen_loss = 0.8999446188185483, disc_loss = 0.0074082490093096386
Trained batch 597 in epoch 12, gen_loss = 0.8998429596822796, disc_loss = 0.007396209180391768
Trained batch 598 in epoch 12, gen_loss = 0.8998048943350828, disc_loss = 0.007384146062566573
Trained batch 599 in epoch 12, gen_loss = 0.8996836641430854, disc_loss = 0.007372032709378497
Trained batch 600 in epoch 12, gen_loss = 0.89971301549683, disc_loss = 0.007359918402957292
Trained batch 601 in epoch 12, gen_loss = 0.8996670999598265, disc_loss = 0.0073479011429951795
Trained batch 602 in epoch 12, gen_loss = 0.8997286501808546, disc_loss = 0.007335889503236912
Trained batch 603 in epoch 12, gen_loss = 0.8996824746495051, disc_loss = 0.007323910748245968
Trained batch 604 in epoch 12, gen_loss = 0.8994266359274052, disc_loss = 0.00731290859252759
Trained batch 605 in epoch 12, gen_loss = 0.8993192615091997, disc_loss = 0.007301638616944287
Trained batch 606 in epoch 12, gen_loss = 0.8993998378073363, disc_loss = 0.007289921428369687
Trained batch 607 in epoch 12, gen_loss = 0.8993274456772365, disc_loss = 0.007278230399474762
Trained batch 608 in epoch 12, gen_loss = 0.899189278507859, disc_loss = 0.007266548643441973
Trained batch 609 in epoch 12, gen_loss = 0.8991550708403353, disc_loss = 0.007255098312822663
Trained batch 610 in epoch 12, gen_loss = 0.8990253093004617, disc_loss = 0.0072439318862458826
Trained batch 611 in epoch 12, gen_loss = 0.8987892362611746, disc_loss = 0.007232581861483125
Trained batch 612 in epoch 12, gen_loss = 0.8985139297816727, disc_loss = 0.007221000204996079
Trained batch 613 in epoch 12, gen_loss = 0.8985120967661518, disc_loss = 0.0072099955686771335
Trained batch 614 in epoch 12, gen_loss = 0.898319956442205, disc_loss = 0.007198617457990947
Trained batch 615 in epoch 12, gen_loss = 0.8983870337342287, disc_loss = 0.007187184088618412
Trained batch 616 in epoch 12, gen_loss = 0.8984407946781362, disc_loss = 0.007175769587120511
Trained batch 617 in epoch 12, gen_loss = 0.8984648933495518, disc_loss = 0.00716430389587336
Trained batch 618 in epoch 12, gen_loss = 0.8984007782427675, disc_loss = 0.007152897274978395
Trained batch 619 in epoch 12, gen_loss = 0.8984026248416593, disc_loss = 0.007141517827321584
Trained batch 620 in epoch 12, gen_loss = 0.8983665877494259, disc_loss = 0.007131160598150481
Trained batch 621 in epoch 12, gen_loss = 0.8982464929868937, disc_loss = 0.007120036024374643
Trained batch 622 in epoch 12, gen_loss = 0.898187362171865, disc_loss = 0.007109023353233384
Trained batch 623 in epoch 12, gen_loss = 0.8984727475505608, disc_loss = 0.0070983651542472865
Trained batch 624 in epoch 12, gen_loss = 0.8984300441741944, disc_loss = 0.007087641906284262
Trained batch 625 in epoch 12, gen_loss = 0.8985866604331202, disc_loss = 0.007076952240793663
Trained batch 626 in epoch 12, gen_loss = 0.8985632907070421, disc_loss = 0.0070660417257696565
Trained batch 627 in epoch 12, gen_loss = 0.8986089578859365, disc_loss = 0.007055028499035772
Trained batch 628 in epoch 12, gen_loss = 0.8984555544269482, disc_loss = 0.007044039834115379
Trained batch 629 in epoch 12, gen_loss = 0.8985176353227524, disc_loss = 0.0070331962267421964
Trained batch 630 in epoch 12, gen_loss = 0.898312154171395, disc_loss = 0.007022419666708428
Trained batch 631 in epoch 12, gen_loss = 0.8980910602626921, disc_loss = 0.0070116179605998075
Trained batch 632 in epoch 12, gen_loss = 0.8982570790943188, disc_loss = 0.007000998310679198
Trained batch 633 in epoch 12, gen_loss = 0.8981522033079189, disc_loss = 0.006990210497301503
Trained batch 634 in epoch 12, gen_loss = 0.8982340978825186, disc_loss = 0.006979538269391866
Trained batch 635 in epoch 12, gen_loss = 0.898143267762736, disc_loss = 0.006968717250913772
Trained batch 636 in epoch 12, gen_loss = 0.8981592831095122, disc_loss = 0.006957998931068642
Trained batch 637 in epoch 12, gen_loss = 0.8981215697844575, disc_loss = 0.006947820759241065
Trained batch 638 in epoch 12, gen_loss = 0.8981405842658686, disc_loss = 0.0069370986629151395
Trained batch 639 in epoch 12, gen_loss = 0.8979923852719367, disc_loss = 0.006926415048633316
Trained batch 640 in epoch 12, gen_loss = 0.8977210093028087, disc_loss = 0.006915785312971232
Trained batch 641 in epoch 12, gen_loss = 0.897714008237714, disc_loss = 0.006905181864714899
Trained batch 642 in epoch 12, gen_loss = 0.8977493407381453, disc_loss = 0.006894803385262129
Trained batch 643 in epoch 12, gen_loss = 0.8975930517504674, disc_loss = 0.00688423781577501
Trained batch 644 in epoch 12, gen_loss = 0.8976759308068327, disc_loss = 0.0068737370239425446
Trained batch 645 in epoch 12, gen_loss = 0.897621271872299, disc_loss = 0.00686331888015954
Trained batch 646 in epoch 12, gen_loss = 0.8975458958602209, disc_loss = 0.006852843717536893
Trained batch 647 in epoch 12, gen_loss = 0.8975634518780826, disc_loss = 0.006842436472405457
Trained batch 648 in epoch 12, gen_loss = 0.8976244716137326, disc_loss = 0.006832600476930402
Trained batch 649 in epoch 12, gen_loss = 0.8975726704414074, disc_loss = 0.006822236942792257
Trained batch 650 in epoch 12, gen_loss = 0.8976533152906943, disc_loss = 0.006812141573533774
Trained batch 651 in epoch 12, gen_loss = 0.8975749839485788, disc_loss = 0.006801849910700597
Trained batch 652 in epoch 12, gen_loss = 0.8972748013221834, disc_loss = 0.006792102874250698
Trained batch 653 in epoch 12, gen_loss = 0.8973649604422601, disc_loss = 0.006782152180286962
Trained batch 654 in epoch 12, gen_loss = 0.8973739078936686, disc_loss = 0.0067719415259878115
Trained batch 655 in epoch 12, gen_loss = 0.8973927132603599, disc_loss = 0.0067617737772818105
Trained batch 656 in epoch 12, gen_loss = 0.8976165560645418, disc_loss = 0.006752559607778534
Trained batch 657 in epoch 12, gen_loss = 0.89766999445063, disc_loss = 0.006742846493215242
Trained batch 658 in epoch 12, gen_loss = 0.8975969320544704, disc_loss = 0.006732936277824817
Trained batch 659 in epoch 12, gen_loss = 0.8975172451951287, disc_loss = 0.006722955452322353
Trained batch 660 in epoch 12, gen_loss = 0.8975499539259884, disc_loss = 0.006712980440589874
Trained batch 661 in epoch 12, gen_loss = 0.8976634280739234, disc_loss = 0.006703118710179695
Trained batch 662 in epoch 12, gen_loss = 0.8977639366778493, disc_loss = 0.006693284620482968
Trained batch 663 in epoch 12, gen_loss = 0.8978671342673072, disc_loss = 0.0066834185439670745
Trained batch 664 in epoch 12, gen_loss = 0.8978453517856454, disc_loss = 0.006673521446186657
Trained batch 665 in epoch 12, gen_loss = 0.8977902657813854, disc_loss = 0.006663690269188801
Trained batch 666 in epoch 12, gen_loss = 0.8978334606319354, disc_loss = 0.0066538975477907
Trained batch 667 in epoch 12, gen_loss = 0.8978737493653497, disc_loss = 0.006644118093968
Trained batch 668 in epoch 12, gen_loss = 0.8977493290052998, disc_loss = 0.006634466013894539
Trained batch 669 in epoch 12, gen_loss = 0.8977435462510408, disc_loss = 0.006624691231361305
Trained batch 670 in epoch 12, gen_loss = 0.8976402323576448, disc_loss = 0.006615024823888868
Trained batch 671 in epoch 12, gen_loss = 0.8975538944914228, disc_loss = 0.006605471040572974
Trained batch 672 in epoch 12, gen_loss = 0.8975565909099437, disc_loss = 0.006597398772891431
Trained batch 673 in epoch 12, gen_loss = 0.8972516145656654, disc_loss = 0.006618270871116509
Trained batch 674 in epoch 12, gen_loss = 0.8972372091258014, disc_loss = 0.006609355848739613
Trained batch 675 in epoch 12, gen_loss = 0.8972126797458829, disc_loss = 0.00660040385785379
Trained batch 676 in epoch 12, gen_loss = 0.8971946940288233, disc_loss = 0.006592845522853281
Trained batch 677 in epoch 12, gen_loss = 0.8972080789484457, disc_loss = 0.006583733526001833
Trained batch 678 in epoch 12, gen_loss = 0.8972662531047928, disc_loss = 0.006574727051223756
Trained batch 679 in epoch 12, gen_loss = 0.8973948718870387, disc_loss = 0.006565490340589723
Trained batch 680 in epoch 12, gen_loss = 0.8972669332212989, disc_loss = 0.006556381792409234
Trained batch 681 in epoch 12, gen_loss = 0.8972835455122581, disc_loss = 0.006547076493230938
Trained batch 682 in epoch 12, gen_loss = 0.8971988025556371, disc_loss = 0.006537840541802949
Trained batch 683 in epoch 12, gen_loss = 0.8972825146557992, disc_loss = 0.0065287526082336
Trained batch 684 in epoch 12, gen_loss = 0.8971320958033095, disc_loss = 0.006519551914296602
Trained batch 685 in epoch 12, gen_loss = 0.8972447280807329, disc_loss = 0.006510520856675615
Trained batch 686 in epoch 12, gen_loss = 0.8972716937939673, disc_loss = 0.0065015629888571505
Trained batch 687 in epoch 12, gen_loss = 0.8970524711144525, disc_loss = 0.00649267764461107
Trained batch 688 in epoch 12, gen_loss = 0.8971347713678081, disc_loss = 0.006483529250956808
Trained batch 689 in epoch 12, gen_loss = 0.8969719710557357, disc_loss = 0.0064743583541923624
Trained batch 690 in epoch 12, gen_loss = 0.897035742116561, disc_loss = 0.006465203805682391
Trained batch 691 in epoch 12, gen_loss = 0.897056499226934, disc_loss = 0.006456068804801504
Trained batch 692 in epoch 12, gen_loss = 0.8969667189221018, disc_loss = 0.006446961353551112
Trained batch 693 in epoch 12, gen_loss = 0.8967627377090949, disc_loss = 0.0064384150507515005
Trained batch 694 in epoch 12, gen_loss = 0.8965983531457915, disc_loss = 0.006429424687546658
Trained batch 695 in epoch 12, gen_loss = 0.8967233678732796, disc_loss = 0.006420723125333537
Trained batch 696 in epoch 12, gen_loss = 0.8965096473693848, disc_loss = 0.006412370381080125
Trained batch 697 in epoch 12, gen_loss = 0.8965624014081108, disc_loss = 0.00640344130848321
Trained batch 698 in epoch 12, gen_loss = 0.8967246681835518, disc_loss = 0.006394617883652583
Trained batch 699 in epoch 12, gen_loss = 0.8967177242040634, disc_loss = 0.006385653962611936
Trained batch 700 in epoch 12, gen_loss = 0.8966302074141237, disc_loss = 0.006376797038761281
Trained batch 701 in epoch 12, gen_loss = 0.8965407893528626, disc_loss = 0.0063680836944987615
Trained batch 702 in epoch 12, gen_loss = 0.8965669180217543, disc_loss = 0.006359227065929357
Trained batch 703 in epoch 12, gen_loss = 0.8966786493970589, disc_loss = 0.0063505617353030175
Trained batch 704 in epoch 12, gen_loss = 0.8965891444091256, disc_loss = 0.0063417156987038365
Trained batch 705 in epoch 12, gen_loss = 0.8965137849110719, disc_loss = 0.006333062755837776
Trained batch 706 in epoch 12, gen_loss = 0.8965686890158323, disc_loss = 0.00632445471642397
Trained batch 707 in epoch 12, gen_loss = 0.8965360474283413, disc_loss = 0.006315723567230362
Trained batch 708 in epoch 12, gen_loss = 0.8967158978513333, disc_loss = 0.006307128859626485
Trained batch 709 in epoch 12, gen_loss = 0.8967441042544136, disc_loss = 0.006298536553142288
Trained batch 710 in epoch 12, gen_loss = 0.8966287009826692, disc_loss = 0.006289892532725104
Trained batch 711 in epoch 12, gen_loss = 0.8965878277347329, disc_loss = 0.006281230977559092
Trained batch 712 in epoch 12, gen_loss = 0.8965674911274315, disc_loss = 0.006272750563512907
Trained batch 713 in epoch 12, gen_loss = 0.8965709574249279, disc_loss = 0.006264615000697379
Trained batch 714 in epoch 12, gen_loss = 0.8964618561984776, disc_loss = 0.006256195248242621
Trained batch 715 in epoch 12, gen_loss = 0.8964103809115607, disc_loss = 0.006247667612216657
Trained batch 716 in epoch 12, gen_loss = 0.8964860632163544, disc_loss = 0.00623928027541412
Trained batch 717 in epoch 12, gen_loss = 0.8963993693128601, disc_loss = 0.006230705873585114
Trained batch 718 in epoch 12, gen_loss = 0.8963636790761033, disc_loss = 0.006222456278545284
Trained batch 719 in epoch 12, gen_loss = 0.8962497187157472, disc_loss = 0.006214110452007541
Trained batch 720 in epoch 12, gen_loss = 0.8961792354279516, disc_loss = 0.0062056606326026335
Trained batch 721 in epoch 12, gen_loss = 0.8959840627753504, disc_loss = 0.006197212704076736
Trained batch 722 in epoch 12, gen_loss = 0.8960150672357277, disc_loss = 0.006188769957470855
Trained batch 723 in epoch 12, gen_loss = 0.8959228833571323, disc_loss = 0.0061804007179203
Trained batch 724 in epoch 12, gen_loss = 0.8959528748742466, disc_loss = 0.006172127476642471
Trained batch 725 in epoch 12, gen_loss = 0.8960429435754939, disc_loss = 0.0061638927033449906
Trained batch 726 in epoch 12, gen_loss = 0.896100165427469, disc_loss = 0.006155865769040277
Trained batch 727 in epoch 12, gen_loss = 0.8960631583090667, disc_loss = 0.006147667168179296
Trained batch 728 in epoch 12, gen_loss = 0.8960021467692895, disc_loss = 0.006139933846006473
Trained batch 729 in epoch 12, gen_loss = 0.8960738959377759, disc_loss = 0.006131732405060887
Trained batch 730 in epoch 12, gen_loss = 0.8960628214352108, disc_loss = 0.006123524509285046
Trained batch 731 in epoch 12, gen_loss = 0.896113159552298, disc_loss = 0.0061161135933114645
Trained batch 732 in epoch 12, gen_loss = 0.8960992164533753, disc_loss = 0.0061080678258265755
Trained batch 733 in epoch 12, gen_loss = 0.8961324492007575, disc_loss = 0.0061000007568925655
Trained batch 734 in epoch 12, gen_loss = 0.8960101175470417, disc_loss = 0.006091993613507944
Trained batch 735 in epoch 12, gen_loss = 0.8958601376608663, disc_loss = 0.006084030543295581
Trained batch 736 in epoch 12, gen_loss = 0.8956092578261646, disc_loss = 0.006094245832604012
Trained batch 737 in epoch 12, gen_loss = 0.8957517468509312, disc_loss = 0.006087150133611539
Trained batch 738 in epoch 12, gen_loss = 0.8956596947329293, disc_loss = 0.006079634351533991
Trained batch 739 in epoch 12, gen_loss = 0.8959371185786015, disc_loss = 0.006072259978070695
Trained batch 740 in epoch 12, gen_loss = 0.89591891410058, disc_loss = 0.006064691807231134
Trained batch 741 in epoch 12, gen_loss = 0.8959808790619482, disc_loss = 0.006056882675178678
Trained batch 742 in epoch 12, gen_loss = 0.8959207243585651, disc_loss = 0.006048988821502404
Trained batch 743 in epoch 12, gen_loss = 0.895939835697733, disc_loss = 0.006041625378192518
Trained batch 744 in epoch 12, gen_loss = 0.8957183862692558, disc_loss = 0.006033776461894096
Trained batch 745 in epoch 12, gen_loss = 0.8957962420926336, disc_loss = 0.006026347684490213
Trained batch 746 in epoch 12, gen_loss = 0.895886813620806, disc_loss = 0.006019504619909184
Trained batch 747 in epoch 12, gen_loss = 0.8959201583887804, disc_loss = 0.006012354209299842
Trained batch 748 in epoch 12, gen_loss = 0.8961386967087301, disc_loss = 0.006005201590703555
Trained batch 749 in epoch 12, gen_loss = 0.8963157599767049, disc_loss = 0.0059977892571769185
Trained batch 750 in epoch 12, gen_loss = 0.8962707825094343, disc_loss = 0.005990070788544828
Trained batch 751 in epoch 12, gen_loss = 0.8963688706305433, disc_loss = 0.005982483421527658
Trained batch 752 in epoch 12, gen_loss = 0.8964562987584676, disc_loss = 0.005974785368078296
Trained batch 753 in epoch 12, gen_loss = 0.8964850602953124, disc_loss = 0.005967118970533559
Trained batch 754 in epoch 12, gen_loss = 0.8963153280959224, disc_loss = 0.005959646645148935
Trained batch 755 in epoch 12, gen_loss = 0.896208650930218, disc_loss = 0.0059521165926357585
Trained batch 756 in epoch 12, gen_loss = 0.8961511992872785, disc_loss = 0.005945607209275584
Trained batch 757 in epoch 12, gen_loss = 0.8961396137925755, disc_loss = 0.005938153933650537
Trained batch 758 in epoch 12, gen_loss = 0.8961430424443975, disc_loss = 0.005930780828311166
Trained batch 759 in epoch 12, gen_loss = 0.8961212721310163, disc_loss = 0.005923244578614111
Trained batch 760 in epoch 12, gen_loss = 0.8961904327753496, disc_loss = 0.005915646572812181
Trained batch 761 in epoch 12, gen_loss = 0.8961954309245733, disc_loss = 0.005908238297706703
Trained batch 762 in epoch 12, gen_loss = 0.8960365321814311, disc_loss = 0.005900913950640279
Trained batch 763 in epoch 12, gen_loss = 0.8961068117961833, disc_loss = 0.005893380053872648
Trained batch 764 in epoch 12, gen_loss = 0.8961113050093059, disc_loss = 0.0058858771094450505
Trained batch 765 in epoch 12, gen_loss = 0.896179386125221, disc_loss = 0.005878500746881547
Trained batch 766 in epoch 12, gen_loss = 0.8961961724767473, disc_loss = 0.005871535965614188
Trained batch 767 in epoch 12, gen_loss = 0.8962166999311497, disc_loss = 0.005864381765746884
Trained batch 768 in epoch 12, gen_loss = 0.8960820007851282, disc_loss = 0.0058569957626076275
Trained batch 769 in epoch 12, gen_loss = 0.8960953761230815, disc_loss = 0.005849700092060972
Trained batch 770 in epoch 12, gen_loss = 0.8962555611179961, disc_loss = 0.005842444091645657
Trained batch 771 in epoch 12, gen_loss = 0.8963301854275669, disc_loss = 0.0058350936077013246
Trained batch 772 in epoch 12, gen_loss = 0.8962625108591797, disc_loss = 0.005827692732061916
Trained batch 773 in epoch 12, gen_loss = 0.8961839162256059, disc_loss = 0.0058217840554982
Trained batch 774 in epoch 12, gen_loss = 0.8962195344125071, disc_loss = 0.005814788918942213
Trained batch 775 in epoch 12, gen_loss = 0.8960952513764814, disc_loss = 0.005807739285918399
Trained batch 776 in epoch 12, gen_loss = 0.8961960474650065, disc_loss = 0.0058005624497564036
Trained batch 777 in epoch 12, gen_loss = 0.8962064972267053, disc_loss = 0.0057934162056453315
Trained batch 778 in epoch 12, gen_loss = 0.8962438489108397, disc_loss = 0.0057861525738551745
Trained batch 779 in epoch 12, gen_loss = 0.896099279782711, disc_loss = 0.005779192712249754
Trained batch 780 in epoch 12, gen_loss = 0.8960247806031328, disc_loss = 0.005771993813657192
Trained batch 781 in epoch 12, gen_loss = 0.8960082538597419, disc_loss = 0.005764782914220888
Trained batch 782 in epoch 12, gen_loss = 0.8959362258704077, disc_loss = 0.005757605899048768
Trained batch 783 in epoch 12, gen_loss = 0.8960104867511866, disc_loss = 0.005750589142067207
Trained batch 784 in epoch 12, gen_loss = 0.8959074623265844, disc_loss = 0.005743503720228187
Trained batch 785 in epoch 12, gen_loss = 0.8959097205530899, disc_loss = 0.005736383335986565
Trained batch 786 in epoch 12, gen_loss = 0.8959926795474759, disc_loss = 0.005729452134041989
Trained batch 787 in epoch 12, gen_loss = 0.8959616539139433, disc_loss = 0.005722651855404333
Trained batch 788 in epoch 12, gen_loss = 0.8961114640169422, disc_loss = 0.00571558135286837
Trained batch 789 in epoch 12, gen_loss = 0.8960831278487097, disc_loss = 0.005708668789995062
Trained batch 790 in epoch 12, gen_loss = 0.8959129064634688, disc_loss = 0.005704984502686869
Trained batch 791 in epoch 12, gen_loss = 0.8960431261797144, disc_loss = 0.005698571403498669
Trained batch 792 in epoch 12, gen_loss = 0.8959511629720354, disc_loss = 0.005692168819521492
Trained batch 793 in epoch 12, gen_loss = 0.8958543364136886, disc_loss = 0.005685367680550465
Trained batch 794 in epoch 12, gen_loss = 0.8957872236299814, disc_loss = 0.005678495294513304
Trained batch 795 in epoch 12, gen_loss = 0.8958520599495825, disc_loss = 0.005671594530021089
Trained batch 796 in epoch 12, gen_loss = 0.895766742630316, disc_loss = 0.0056646675742514675
Trained batch 797 in epoch 12, gen_loss = 0.895822379747429, disc_loss = 0.005658690861091053
Trained batch 798 in epoch 12, gen_loss = 0.8959017643642068, disc_loss = 0.0056519077214976544
Trained batch 799 in epoch 12, gen_loss = 0.8960185235738755, disc_loss = 0.005645182300759189
Trained batch 800 in epoch 12, gen_loss = 0.8959034141083335, disc_loss = 0.005638601224279129
Trained batch 801 in epoch 12, gen_loss = 0.8959272101781612, disc_loss = 0.0056318695890439086
Trained batch 802 in epoch 12, gen_loss = 0.8960021153036714, disc_loss = 0.005625128383557735
Trained batch 803 in epoch 12, gen_loss = 0.8961340262373881, disc_loss = 0.005618519932736784
Trained batch 804 in epoch 12, gen_loss = 0.8958681555268186, disc_loss = 0.005615409073435777
Trained batch 805 in epoch 12, gen_loss = 0.8958995734935363, disc_loss = 0.005608920249007596
Trained batch 806 in epoch 12, gen_loss = 0.8959692195150193, disc_loss = 0.005602730351414813
Trained batch 807 in epoch 12, gen_loss = 0.8960017089058857, disc_loss = 0.0055961497267765815
Trained batch 808 in epoch 12, gen_loss = 0.8958880875549741, disc_loss = 0.005589650189909826
Trained batch 809 in epoch 12, gen_loss = 0.8959085765444202, disc_loss = 0.0055829952291125305
Trained batch 810 in epoch 12, gen_loss = 0.8960262393686833, disc_loss = 0.005576590691019468
Trained batch 811 in epoch 12, gen_loss = 0.8959518871430693, disc_loss = 0.005570102450005587
Trained batch 812 in epoch 12, gen_loss = 0.8959504434103456, disc_loss = 0.00556343433219578
Trained batch 813 in epoch 12, gen_loss = 0.8958437354178042, disc_loss = 0.00555698562539523
Trained batch 814 in epoch 12, gen_loss = 0.8958379531199215, disc_loss = 0.005550334693048367
Trained batch 815 in epoch 12, gen_loss = 0.8959578582469154, disc_loss = 0.005543712107996102
Trained batch 816 in epoch 12, gen_loss = 0.8958363354279041, disc_loss = 0.005537083179736538
Trained batch 817 in epoch 12, gen_loss = 0.8958438886989882, disc_loss = 0.005530559247600719
Trained batch 818 in epoch 12, gen_loss = 0.8958713170664069, disc_loss = 0.00552415789421409
Trained batch 819 in epoch 12, gen_loss = 0.8964118793970202, disc_loss = 0.005527508441463862
Trained batch 820 in epoch 12, gen_loss = 0.8963997756810484, disc_loss = 0.005522049357504873
Trained batch 821 in epoch 12, gen_loss = 0.8962760681508521, disc_loss = 0.00551772310740967
Trained batch 822 in epoch 12, gen_loss = 0.8961561014411806, disc_loss = 0.00551277563494448
Trained batch 823 in epoch 12, gen_loss = 0.8961960097539772, disc_loss = 0.0055069853121485985
Trained batch 824 in epoch 12, gen_loss = 0.8961623173049001, disc_loss = 0.0055009514323407505
Trained batch 825 in epoch 12, gen_loss = 0.8962309582758758, disc_loss = 0.005494977778120341
Trained batch 826 in epoch 12, gen_loss = 0.8961623213023056, disc_loss = 0.005488598004787707
Trained batch 827 in epoch 12, gen_loss = 0.8961567306432171, disc_loss = 0.005482304125441748
Trained batch 828 in epoch 12, gen_loss = 0.8963445612691137, disc_loss = 0.005476084884399502
Trained batch 829 in epoch 12, gen_loss = 0.8967152706829898, disc_loss = 0.005472522632920896
Trained batch 830 in epoch 12, gen_loss = 0.8967037959075863, disc_loss = 0.0054663419120595655
Trained batch 831 in epoch 12, gen_loss = 0.8966978367847892, disc_loss = 0.005460971664660974
Trained batch 832 in epoch 12, gen_loss = 0.8967516416547393, disc_loss = 0.005454789805471297
Trained batch 833 in epoch 12, gen_loss = 0.8967475569505485, disc_loss = 0.0054488134388363816
Trained batch 834 in epoch 12, gen_loss = 0.8967119585254235, disc_loss = 0.005442508047796552
Trained batch 835 in epoch 12, gen_loss = 0.8965723297812722, disc_loss = 0.005437300397598677
Trained batch 836 in epoch 12, gen_loss = 0.8964773429337368, disc_loss = 0.00543111967160856
Trained batch 837 in epoch 12, gen_loss = 0.8965349883054492, disc_loss = 0.005424866979043744
Trained batch 838 in epoch 12, gen_loss = 0.8964797345759331, disc_loss = 0.0054186327333039805
Trained batch 839 in epoch 12, gen_loss = 0.8968758053013257, disc_loss = 0.005413720772187281
Trained batch 840 in epoch 12, gen_loss = 0.896974802158959, disc_loss = 0.005407586120719347
Trained batch 841 in epoch 12, gen_loss = 0.8970365740907447, disc_loss = 0.005401896789866044
Trained batch 842 in epoch 12, gen_loss = 0.8971261428061471, disc_loss = 0.005396033799523501
Trained batch 843 in epoch 12, gen_loss = 0.8972669081382841, disc_loss = 0.005390233104468943
Trained batch 844 in epoch 12, gen_loss = 0.8973125538177039, disc_loss = 0.005384316417380352
Trained batch 845 in epoch 12, gen_loss = 0.897305675573101, disc_loss = 0.0053782454495324835
Trained batch 846 in epoch 12, gen_loss = 0.897207597070489, disc_loss = 0.005372121672122245
Trained batch 847 in epoch 12, gen_loss = 0.8973049559402015, disc_loss = 0.005366114683931541
Trained batch 848 in epoch 12, gen_loss = 0.8972765371572002, disc_loss = 0.005360071641599784
Trained batch 849 in epoch 12, gen_loss = 0.8973301498328938, disc_loss = 0.005353962735577678
Trained batch 850 in epoch 12, gen_loss = 0.8973437617724427, disc_loss = 0.005347829757398651
Trained batch 851 in epoch 12, gen_loss = 0.8974913376877566, disc_loss = 0.0053419188508928425
Trained batch 852 in epoch 12, gen_loss = 0.8975357015694712, disc_loss = 0.005335881061969895
Trained batch 853 in epoch 12, gen_loss = 0.8974343273762517, disc_loss = 0.005329816380347479
Trained batch 854 in epoch 12, gen_loss = 0.8975978645664907, disc_loss = 0.005324195524199719
Trained batch 855 in epoch 12, gen_loss = 0.8974397290393571, disc_loss = 0.005318897707660075
Trained batch 856 in epoch 12, gen_loss = 0.8974369418662793, disc_loss = 0.00531293222750442
Trained batch 857 in epoch 12, gen_loss = 0.8974458498832507, disc_loss = 0.005307065759264318
Trained batch 858 in epoch 12, gen_loss = 0.8975056460489356, disc_loss = 0.005301077118399851
Trained batch 859 in epoch 12, gen_loss = 0.8974538950726043, disc_loss = 0.005295083153370882
Trained batch 860 in epoch 12, gen_loss = 0.897518695508423, disc_loss = 0.005289137333180727
Trained batch 861 in epoch 12, gen_loss = 0.8975043296122496, disc_loss = 0.005283195396719566
Trained batch 862 in epoch 12, gen_loss = 0.897614367591133, disc_loss = 0.005277256831758913
Trained batch 863 in epoch 12, gen_loss = 0.8975427578444835, disc_loss = 0.00527134235998919
Trained batch 864 in epoch 12, gen_loss = 0.8974513039423552, disc_loss = 0.005265375165744197
Trained batch 865 in epoch 12, gen_loss = 0.8973285356927965, disc_loss = 0.005259446519983604
Trained batch 866 in epoch 12, gen_loss = 0.8971770585889497, disc_loss = 0.005253963923269269
Trained batch 867 in epoch 12, gen_loss = 0.8971926302129772, disc_loss = 0.005248022602002237
Trained batch 868 in epoch 12, gen_loss = 0.8971566868596577, disc_loss = 0.005242103428975867
Trained batch 869 in epoch 12, gen_loss = 0.8970787323754409, disc_loss = 0.005236231701079911
Trained batch 870 in epoch 12, gen_loss = 0.897116844881279, disc_loss = 0.005230370289625372
Trained batch 871 in epoch 12, gen_loss = 0.8971728020168226, disc_loss = 0.0052246525457296834
Trained batch 872 in epoch 12, gen_loss = 0.897114657113096, disc_loss = 0.005219293237354565
Trained batch 873 in epoch 12, gen_loss = 0.8970611918572703, disc_loss = 0.005213601015619662
Trained batch 874 in epoch 12, gen_loss = 0.897191177708762, disc_loss = 0.005207900483909595
Trained batch 875 in epoch 12, gen_loss = 0.8972118328151093, disc_loss = 0.0052022949908095886
Trained batch 876 in epoch 12, gen_loss = 0.8971612196555839, disc_loss = 0.00519655535999856
Trained batch 877 in epoch 12, gen_loss = 0.8971674266464347, disc_loss = 0.0051909053289899785
Trained batch 878 in epoch 12, gen_loss = 0.8971525612409069, disc_loss = 0.005185313412608537
Trained batch 879 in epoch 12, gen_loss = 0.8972367702559991, disc_loss = 0.00517962798375348
Trained batch 880 in epoch 12, gen_loss = 0.8972602879689852, disc_loss = 0.005174171974404534
Trained batch 881 in epoch 12, gen_loss = 0.8972249620355446, disc_loss = 0.005168493196256421
Trained batch 882 in epoch 12, gen_loss = 0.8973585105293335, disc_loss = 0.00516285907349189
Trained batch 883 in epoch 12, gen_loss = 0.8974918348217442, disc_loss = 0.005157239565886405
Trained batch 884 in epoch 12, gen_loss = 0.8975307681466227, disc_loss = 0.005151605024577992
Trained batch 885 in epoch 12, gen_loss = 0.8975504520380739, disc_loss = 0.005145919671963845
Trained batch 886 in epoch 12, gen_loss = 0.8976502228347667, disc_loss = 0.00514023753886519
Trained batch 887 in epoch 12, gen_loss = 0.8978447015355299, disc_loss = 0.005134732639399354
Trained batch 888 in epoch 12, gen_loss = 0.8979381921589039, disc_loss = 0.005129183779164328
Trained batch 889 in epoch 12, gen_loss = 0.8979772623335378, disc_loss = 0.00512358463023334
Trained batch 890 in epoch 12, gen_loss = 0.8979400751566646, disc_loss = 0.005117949806484663
Trained batch 891 in epoch 12, gen_loss = 0.8979181164182355, disc_loss = 0.005112349686798895
Trained batch 892 in epoch 12, gen_loss = 0.897922912543725, disc_loss = 0.005106773760097327
Trained batch 893 in epoch 12, gen_loss = 0.8979052143208932, disc_loss = 0.005101255387726635
Trained batch 894 in epoch 12, gen_loss = 0.8978857354744852, disc_loss = 0.005095672306432987
Trained batch 895 in epoch 12, gen_loss = 0.8978397275454232, disc_loss = 0.005090093352529428
Trained batch 896 in epoch 12, gen_loss = 0.8978599058080012, disc_loss = 0.005084578874310709
Trained batch 897 in epoch 12, gen_loss = 0.8979139964538057, disc_loss = 0.0050790123388128805
Trained batch 898 in epoch 12, gen_loss = 0.8978796273768279, disc_loss = 0.0050734598967205275
Trained batch 899 in epoch 12, gen_loss = 0.8978382088740666, disc_loss = 0.005067949806947985
Trained batch 900 in epoch 12, gen_loss = 0.8978159823904556, disc_loss = 0.005062618855014599
Trained batch 901 in epoch 12, gen_loss = 0.8978160098360277, disc_loss = 0.005057186170745984
Trained batch 902 in epoch 12, gen_loss = 0.8978119504412148, disc_loss = 0.005051741402351673
Trained batch 903 in epoch 12, gen_loss = 0.8978325691634574, disc_loss = 0.005046472225934592
Trained batch 904 in epoch 12, gen_loss = 0.8978210112007942, disc_loss = 0.005041090152126696
Trained batch 905 in epoch 12, gen_loss = 0.8978588340956117, disc_loss = 0.005035637731639598
Trained batch 906 in epoch 12, gen_loss = 0.8980150040744289, disc_loss = 0.005030219758487391
Trained batch 907 in epoch 12, gen_loss = 0.8979284194860164, disc_loss = 0.0050249574399695044
Trained batch 908 in epoch 12, gen_loss = 0.8980628687425284, disc_loss = 0.0050196391412831035
Trained batch 909 in epoch 12, gen_loss = 0.8981418718348493, disc_loss = 0.005014317973253348
Trained batch 910 in epoch 12, gen_loss = 0.8980852632438836, disc_loss = 0.005008946113599184
Trained batch 911 in epoch 12, gen_loss = 0.8981441110372543, disc_loss = 0.0050035478065693865
Trained batch 912 in epoch 12, gen_loss = 0.8981550100207459, disc_loss = 0.004998175507879126
Trained batch 913 in epoch 12, gen_loss = 0.8981767347005055, disc_loss = 0.004992853185108517
Trained batch 914 in epoch 12, gen_loss = 0.8980656391935922, disc_loss = 0.0049875436573116935
Trained batch 915 in epoch 12, gen_loss = 0.8981288788620562, disc_loss = 0.004982261030047847
Trained batch 916 in epoch 12, gen_loss = 0.8981337603201913, disc_loss = 0.004976905004316298
Trained batch 917 in epoch 12, gen_loss = 0.898309166005494, disc_loss = 0.004971857133881919
Trained batch 918 in epoch 12, gen_loss = 0.8984578724654637, disc_loss = 0.004967121076598797
Trained batch 919 in epoch 12, gen_loss = 0.8984130181696104, disc_loss = 0.00496192590311219
Trained batch 920 in epoch 12, gen_loss = 0.8983997223043286, disc_loss = 0.004956808354964125
Trained batch 921 in epoch 12, gen_loss = 0.8983748176351286, disc_loss = 0.004951640493039826
Trained batch 922 in epoch 12, gen_loss = 0.8983565186627637, disc_loss = 0.004946433750692519
Trained batch 923 in epoch 12, gen_loss = 0.8983182816794424, disc_loss = 0.004941225498524463
Trained batch 924 in epoch 12, gen_loss = 0.8982307077098537, disc_loss = 0.0049361033398088545
Trained batch 925 in epoch 12, gen_loss = 0.898265813905786, disc_loss = 0.00493095721545815
Trained batch 926 in epoch 12, gen_loss = 0.8980921737713078, disc_loss = 0.004925828500879824
Trained batch 927 in epoch 12, gen_loss = 0.8980525159116449, disc_loss = 0.004920796759812407
Trained batch 928 in epoch 12, gen_loss = 0.8980757988051014, disc_loss = 0.0049157135244233974
Trained batch 929 in epoch 12, gen_loss = 0.8980175189433559, disc_loss = 0.00491054031049854
Trained batch 930 in epoch 12, gen_loss = 0.897968537889413, disc_loss = 0.004905547745879772
Trained batch 931 in epoch 12, gen_loss = 0.8979357475886529, disc_loss = 0.004900555787864403
Trained batch 932 in epoch 12, gen_loss = 0.8979650347434694, disc_loss = 0.00489552959930687
Trained batch 933 in epoch 12, gen_loss = 0.8979922844459974, disc_loss = 0.004890825598349167
Trained batch 934 in epoch 12, gen_loss = 0.8980509478778125, disc_loss = 0.004885765151713693
Trained batch 935 in epoch 12, gen_loss = 0.8980562021462326, disc_loss = 0.004880693910300991
Trained batch 936 in epoch 12, gen_loss = 0.8981453846332994, disc_loss = 0.00487562448308057
Trained batch 937 in epoch 12, gen_loss = 0.8980751240304284, disc_loss = 0.004870546708882688
Trained batch 938 in epoch 12, gen_loss = 0.8979054494533802, disc_loss = 0.004865821556810411
Trained batch 939 in epoch 12, gen_loss = 0.8978991696809201, disc_loss = 0.004860978570108505
Trained batch 940 in epoch 12, gen_loss = 0.8979428998342103, disc_loss = 0.004856148560823528
Trained batch 941 in epoch 12, gen_loss = 0.8979954136784669, disc_loss = 0.004851211076212435
Trained batch 942 in epoch 12, gen_loss = 0.8979923632213193, disc_loss = 0.004846278123091166
Trained batch 943 in epoch 12, gen_loss = 0.8980045532018451, disc_loss = 0.004841488459610214
Trained batch 944 in epoch 12, gen_loss = 0.8979034389768328, disc_loss = 0.004836517053954402
Trained batch 945 in epoch 12, gen_loss = 0.89786092410884, disc_loss = 0.0048315514272670055
Trained batch 946 in epoch 12, gen_loss = 0.897838994467271, disc_loss = 0.004826575148939313
Trained batch 947 in epoch 12, gen_loss = 0.8978809642012109, disc_loss = 0.004821622718030657
Trained batch 948 in epoch 12, gen_loss = 0.8979296885878318, disc_loss = 0.004816659850737134
Trained batch 949 in epoch 12, gen_loss = 0.8978833802750236, disc_loss = 0.004811794996042552
Trained batch 950 in epoch 12, gen_loss = 0.897900010697097, disc_loss = 0.004806871403078291
Trained batch 951 in epoch 12, gen_loss = 0.897888773066156, disc_loss = 0.004801964518180797
Trained batch 952 in epoch 12, gen_loss = 0.8979223541923235, disc_loss = 0.004797080739054417
Trained batch 953 in epoch 12, gen_loss = 0.8979163063647112, disc_loss = 0.004792155055979616
Trained batch 954 in epoch 12, gen_loss = 0.8979037669316636, disc_loss = 0.004787308862996629
Trained batch 955 in epoch 12, gen_loss = 0.8979143272758029, disc_loss = 0.0047824145380804435
Trained batch 956 in epoch 12, gen_loss = 0.8979678860901541, disc_loss = 0.004777769431125559
Trained batch 957 in epoch 12, gen_loss = 0.8979673062087599, disc_loss = 0.004772900207035206
Trained batch 958 in epoch 12, gen_loss = 0.8978766037599883, disc_loss = 0.004768313022081974
Trained batch 959 in epoch 12, gen_loss = 0.8979692359765371, disc_loss = 0.004763558411203424
Trained batch 960 in epoch 12, gen_loss = 0.8979499674364382, disc_loss = 0.004758938113287148
Trained batch 961 in epoch 12, gen_loss = 0.897880369623089, disc_loss = 0.00475419099315929
Trained batch 962 in epoch 12, gen_loss = 0.8979060012974843, disc_loss = 0.004749530525806445
Trained batch 963 in epoch 12, gen_loss = 0.8978647780739915, disc_loss = 0.0047447151946735594
Trained batch 964 in epoch 12, gen_loss = 0.897736564263161, disc_loss = 0.004742642078924757
Trained batch 965 in epoch 12, gen_loss = 0.8977807391874538, disc_loss = 0.004738228009330332
Trained batch 966 in epoch 12, gen_loss = 0.8977683520612944, disc_loss = 0.00473388421096623
Trained batch 967 in epoch 12, gen_loss = 0.8978034908121283, disc_loss = 0.004729214810538921
Trained batch 968 in epoch 12, gen_loss = 0.8978132299840512, disc_loss = 0.004724961292878708
Trained batch 969 in epoch 12, gen_loss = 0.8977162602636003, disc_loss = 0.004720428950606651
Trained batch 970 in epoch 12, gen_loss = 0.8978429338467968, disc_loss = 0.004715992398607705
Trained batch 971 in epoch 12, gen_loss = 0.8978915941200138, disc_loss = 0.004711363150088374
Trained batch 972 in epoch 12, gen_loss = 0.8979357100586729, disc_loss = 0.0047067876661260125
Trained batch 973 in epoch 12, gen_loss = 0.8980208847679396, disc_loss = 0.004702172420111983
Trained batch 974 in epoch 12, gen_loss = 0.8981341284360641, disc_loss = 0.004697751765600585
Trained batch 975 in epoch 12, gen_loss = 0.8982123715467141, disc_loss = 0.004693209381248827
Trained batch 976 in epoch 12, gen_loss = 0.8981681339816403, disc_loss = 0.004688646839836581
Trained batch 977 in epoch 12, gen_loss = 0.8982682700415574, disc_loss = 0.004684076369757031
Trained batch 978 in epoch 12, gen_loss = 0.898285934520815, disc_loss = 0.004679493333818117
Trained batch 979 in epoch 12, gen_loss = 0.8983446157100249, disc_loss = 0.004674915155570785
Trained batch 980 in epoch 12, gen_loss = 0.8983005389768657, disc_loss = 0.004670402154417637
Trained batch 981 in epoch 12, gen_loss = 0.8982149978033637, disc_loss = 0.004666202848369899
Trained batch 982 in epoch 12, gen_loss = 0.8982128491236744, disc_loss = 0.004662257539062978
Trained batch 983 in epoch 12, gen_loss = 0.8981853577543081, disc_loss = 0.004657935972170343
Trained batch 984 in epoch 12, gen_loss = 0.8983204765973357, disc_loss = 0.004653635862270703
Trained batch 985 in epoch 12, gen_loss = 0.8984939599254794, disc_loss = 0.004649292027210152
Trained batch 986 in epoch 12, gen_loss = 0.8986166984356162, disc_loss = 0.004644759276947217
Trained batch 987 in epoch 12, gen_loss = 0.8986337309182897, disc_loss = 0.00464059192934744
Trained batch 988 in epoch 12, gen_loss = 0.8985921639282373, disc_loss = 0.00463616248806902
Trained batch 989 in epoch 12, gen_loss = 0.8984552113094715, disc_loss = 0.004631659495072484
Trained batch 990 in epoch 12, gen_loss = 0.8983422342150291, disc_loss = 0.004627183415654398
Trained batch 991 in epoch 12, gen_loss = 0.8984574188868846, disc_loss = 0.004622824563262662
Trained batch 992 in epoch 12, gen_loss = 0.898543760015405, disc_loss = 0.00461861803785921
Trained batch 993 in epoch 12, gen_loss = 0.8984868965998022, disc_loss = 0.004614094821971331
Trained batch 994 in epoch 12, gen_loss = 0.8984178838418356, disc_loss = 0.004610251011021246
Trained batch 995 in epoch 12, gen_loss = 0.8984856910135851, disc_loss = 0.004605925951423215
Trained batch 996 in epoch 12, gen_loss = 0.8983205913779968, disc_loss = 0.004601526577042875
Trained batch 997 in epoch 12, gen_loss = 0.898313658450075, disc_loss = 0.004597081949551231
Trained batch 998 in epoch 12, gen_loss = 0.8983183027029753, disc_loss = 0.004592614999246116
Trained batch 999 in epoch 12, gen_loss = 0.8983351041674614, disc_loss = 0.0045882558403609434
Trained batch 1000 in epoch 12, gen_loss = 0.8983885299313914, disc_loss = 0.004583850030277725
Trained batch 1001 in epoch 12, gen_loss = 0.898380168719206, disc_loss = 0.0045794975393112615
Trained batch 1002 in epoch 12, gen_loss = 0.89857875201424, disc_loss = 0.004575232792009239
Trained batch 1003 in epoch 12, gen_loss = 0.8985580311590932, disc_loss = 0.004570826561151866
Trained batch 1004 in epoch 12, gen_loss = 0.8985602853310048, disc_loss = 0.004566386476628522
Trained batch 1005 in epoch 12, gen_loss = 0.8986105380901996, disc_loss = 0.004562101654872305
Trained batch 1006 in epoch 12, gen_loss = 0.8985716664447804, disc_loss = 0.004557707001927784
Trained batch 1007 in epoch 12, gen_loss = 0.8985134865792971, disc_loss = 0.004553358844496249
Trained batch 1008 in epoch 12, gen_loss = 0.8986128907728242, disc_loss = 0.0045489534294204225
Trained batch 1009 in epoch 12, gen_loss = 0.8986691339181201, disc_loss = 0.004544616906203751
Trained batch 1010 in epoch 12, gen_loss = 0.8986710313519668, disc_loss = 0.0045402936804467935
Trained batch 1011 in epoch 12, gen_loss = 0.8985949528547144, disc_loss = 0.004535955934303138
Trained batch 1012 in epoch 12, gen_loss = 0.8984720466873606, disc_loss = 0.004533220375376937
Trained batch 1013 in epoch 12, gen_loss = 0.8984280203338676, disc_loss = 0.004529547529260702
Trained batch 1014 in epoch 12, gen_loss = 0.8984563258481143, disc_loss = 0.004525378121103543
Trained batch 1015 in epoch 12, gen_loss = 0.898389697602884, disc_loss = 0.004521283818003284
Trained batch 1016 in epoch 12, gen_loss = 0.8983554691222799, disc_loss = 0.00451699769797726
Trained batch 1017 in epoch 12, gen_loss = 0.8983497871397053, disc_loss = 0.004512708822205173
Trained batch 1018 in epoch 12, gen_loss = 0.8981840836873115, disc_loss = 0.004536158541031284
Trained batch 1019 in epoch 12, gen_loss = 0.8982551168577344, disc_loss = 0.0045330733315994635
Trained batch 1020 in epoch 12, gen_loss = 0.8983425681317821, disc_loss = 0.004533913731707561
Trained batch 1021 in epoch 12, gen_loss = 0.8984288740064766, disc_loss = 0.004546619974457034
Trained batch 1022 in epoch 12, gen_loss = 0.8984986403237806, disc_loss = 0.0045496796886371205
Trained batch 1023 in epoch 12, gen_loss = 0.8985357889323495, disc_loss = 0.004548641488050009
Trained batch 1024 in epoch 12, gen_loss = 0.8984515127903078, disc_loss = 0.00454506217179076
Trained batch 1025 in epoch 12, gen_loss = 0.898530117891453, disc_loss = 0.00454181885218356
Trained batch 1026 in epoch 12, gen_loss = 0.8985347768115904, disc_loss = 0.004538004838121829
Trained batch 1027 in epoch 12, gen_loss = 0.8986533819353534, disc_loss = 0.004534174866640792
Trained batch 1028 in epoch 12, gen_loss = 0.898710440442444, disc_loss = 0.004530264847340622
Trained batch 1029 in epoch 12, gen_loss = 0.8986594149788607, disc_loss = 0.004526375021873939
Trained batch 1030 in epoch 12, gen_loss = 0.8987330105209905, disc_loss = 0.00452278256971439
Trained batch 1031 in epoch 12, gen_loss = 0.898769349264082, disc_loss = 0.004518862001518297
Trained batch 1032 in epoch 12, gen_loss = 0.8987633032004808, disc_loss = 0.00451515370120511
Trained batch 1033 in epoch 12, gen_loss = 0.898759020078113, disc_loss = 0.00451111644534742
Trained batch 1034 in epoch 12, gen_loss = 0.8986815116255755, disc_loss = 0.004507641448024357
Trained batch 1035 in epoch 12, gen_loss = 0.8986501923859349, disc_loss = 0.004504573737851465
Trained batch 1036 in epoch 12, gen_loss = 0.8987325608672838, disc_loss = 0.004500927849788196
Trained batch 1037 in epoch 12, gen_loss = 0.8988237753079805, disc_loss = 0.004496888185315238
Trained batch 1038 in epoch 12, gen_loss = 0.8988923725884505, disc_loss = 0.0044928990744655
Trained batch 1039 in epoch 12, gen_loss = 0.8987880345720511, disc_loss = 0.004489718727290893
Trained batch 1040 in epoch 12, gen_loss = 0.8988562970065246, disc_loss = 0.004485810822007946
Trained batch 1041 in epoch 12, gen_loss = 0.8988682598504819, disc_loss = 0.00448443395033933
Trained batch 1042 in epoch 12, gen_loss = 0.8989606421951594, disc_loss = 0.004480507542659189
Trained batch 1043 in epoch 12, gen_loss = 0.8989824615561642, disc_loss = 0.004476734739885778
Trained batch 1044 in epoch 12, gen_loss = 0.8990767182915975, disc_loss = 0.00447310368956148
Trained batch 1045 in epoch 12, gen_loss = 0.8990858720889738, disc_loss = 0.00446931591187921
Trained batch 1046 in epoch 12, gen_loss = 0.8990881751578768, disc_loss = 0.004465400719881574
Trained batch 1047 in epoch 12, gen_loss = 0.8991525980807443, disc_loss = 0.004461383243775511
Trained batch 1048 in epoch 12, gen_loss = 0.8992240855077883, disc_loss = 0.00445740819816484
Trained batch 1049 in epoch 12, gen_loss = 0.8992780401593163, disc_loss = 0.004453518715211734
Trained batch 1050 in epoch 12, gen_loss = 0.8992330744990159, disc_loss = 0.004449483294693319
Trained batch 1051 in epoch 12, gen_loss = 0.899268712097701, disc_loss = 0.004445389394647322
Trained batch 1052 in epoch 12, gen_loss = 0.8992407766842095, disc_loss = 0.004441412887946428
Trained batch 1053 in epoch 12, gen_loss = 0.8991703429529744, disc_loss = 0.004437325810366613
Trained batch 1054 in epoch 12, gen_loss = 0.8991511236434864, disc_loss = 0.004433291160629266
Trained batch 1055 in epoch 12, gen_loss = 0.899139740363215, disc_loss = 0.004429800996307897
Trained batch 1056 in epoch 12, gen_loss = 0.8992001739107671, disc_loss = 0.004425881336194601
Trained batch 1057 in epoch 12, gen_loss = 0.8991549371658967, disc_loss = 0.004421927765208362
Trained batch 1058 in epoch 12, gen_loss = 0.899213482063823, disc_loss = 0.004418096640765347
Trained batch 1059 in epoch 12, gen_loss = 0.8993143871707736, disc_loss = 0.004414171985146548
Trained batch 1060 in epoch 12, gen_loss = 0.8993058582165688, disc_loss = 0.004410136511502886
Trained batch 1061 in epoch 12, gen_loss = 0.89937886034477, disc_loss = 0.004406320592734084
Trained batch 1062 in epoch 12, gen_loss = 0.8993865661428205, disc_loss = 0.004402395805349954
Trained batch 1063 in epoch 12, gen_loss = 0.8994336934354072, disc_loss = 0.0043985186125028945
Trained batch 1064 in epoch 12, gen_loss = 0.8994257868735444, disc_loss = 0.004394492424130625
Trained batch 1065 in epoch 12, gen_loss = 0.8994898500854034, disc_loss = 0.004390588298221401
Trained batch 1066 in epoch 12, gen_loss = 0.8993958016925586, disc_loss = 0.0043867946555120624
Trained batch 1067 in epoch 12, gen_loss = 0.8994293338462208, disc_loss = 0.004382859357978073
Trained batch 1068 in epoch 12, gen_loss = 0.8993093795147424, disc_loss = 0.004379151468861369
Trained batch 1069 in epoch 12, gen_loss = 0.8993612640371946, disc_loss = 0.004375250235089225
Trained batch 1070 in epoch 12, gen_loss = 0.8992339372634888, disc_loss = 0.004371571212832894
Trained batch 1071 in epoch 12, gen_loss = 0.8992626809918168, disc_loss = 0.004367786484092889
Trained batch 1072 in epoch 12, gen_loss = 0.899310154550451, disc_loss = 0.004363966369640418
Trained batch 1073 in epoch 12, gen_loss = 0.8992434753386002, disc_loss = 0.004360055660417755
Trained batch 1074 in epoch 12, gen_loss = 0.8991365356777989, disc_loss = 0.004356264522154328
Trained batch 1075 in epoch 12, gen_loss = 0.8990985124084586, disc_loss = 0.004352372924528757
Trained batch 1076 in epoch 12, gen_loss = 0.899211131430602, disc_loss = 0.0043496316213084765
Trained batch 1077 in epoch 12, gen_loss = 0.8991722747655879, disc_loss = 0.004345763507863113
Trained batch 1078 in epoch 12, gen_loss = 0.8991106865138672, disc_loss = 0.004342215688969774
Trained batch 1079 in epoch 12, gen_loss = 0.8991724555691083, disc_loss = 0.004338380153832851
Trained batch 1080 in epoch 12, gen_loss = 0.8991211612504683, disc_loss = 0.004334621835209179
Trained batch 1081 in epoch 12, gen_loss = 0.8990268853257192, disc_loss = 0.004330960104685841
Trained batch 1082 in epoch 12, gen_loss = 0.8990391055302607, disc_loss = 0.004327203947770986
Trained batch 1083 in epoch 12, gen_loss = 0.8989495847277975, disc_loss = 0.0043233613635584
Trained batch 1084 in epoch 12, gen_loss = 0.8989571535092894, disc_loss = 0.004319539195599092
Trained batch 1085 in epoch 12, gen_loss = 0.898839325261599, disc_loss = 0.004315732388375711
Trained batch 1086 in epoch 12, gen_loss = 0.8989450755531676, disc_loss = 0.004311924584990073
Trained batch 1087 in epoch 12, gen_loss = 0.899058028781677, disc_loss = 0.004308164109736079
Trained batch 1088 in epoch 12, gen_loss = 0.8991826535694308, disc_loss = 0.004304476154823987
Trained batch 1089 in epoch 12, gen_loss = 0.8992626447743232, disc_loss = 0.004300740666503521
Trained batch 1090 in epoch 12, gen_loss = 0.8990906212004252, disc_loss = 0.004297402017735921
Trained batch 1091 in epoch 12, gen_loss = 0.8989604105115373, disc_loss = 0.004293754555451231
Trained batch 1092 in epoch 12, gen_loss = 0.8989418169717012, disc_loss = 0.00429003715460364
Trained batch 1093 in epoch 12, gen_loss = 0.8988754928547896, disc_loss = 0.004286300131784387
Trained batch 1094 in epoch 12, gen_loss = 0.8989207785423488, disc_loss = 0.00428257714962979
Trained batch 1095 in epoch 12, gen_loss = 0.8988466869196753, disc_loss = 0.004278849269637388
Trained batch 1096 in epoch 12, gen_loss = 0.8988041236059385, disc_loss = 0.004275422264963659
Trained batch 1097 in epoch 12, gen_loss = 0.8988710329180858, disc_loss = 0.004271851792718288
Trained batch 1098 in epoch 12, gen_loss = 0.8988523360704487, disc_loss = 0.004268218934200664
Trained batch 1099 in epoch 12, gen_loss = 0.898778392997655, disc_loss = 0.0042645252232548295
Trained batch 1100 in epoch 12, gen_loss = 0.8988597428224825, disc_loss = 0.004260815663631321
Trained batch 1101 in epoch 12, gen_loss = 0.8989443855255356, disc_loss = 0.0042571210608147985
Trained batch 1102 in epoch 12, gen_loss = 0.8988927300151434, disc_loss = 0.004253355887731322
Trained batch 1103 in epoch 12, gen_loss = 0.8989539195014082, disc_loss = 0.00424969323157843
Trained batch 1104 in epoch 12, gen_loss = 0.8989230176442349, disc_loss = 0.004245989889385046
Trained batch 1105 in epoch 12, gen_loss = 0.8989899566979779, disc_loss = 0.004242305022972616
Trained batch 1106 in epoch 12, gen_loss = 0.8989082834907987, disc_loss = 0.004238878587377205
Trained batch 1107 in epoch 12, gen_loss = 0.8988853713988397, disc_loss = 0.004235422898724892
Trained batch 1108 in epoch 12, gen_loss = 0.8988862947583521, disc_loss = 0.004231751234355083
Trained batch 1109 in epoch 12, gen_loss = 0.8989649417701068, disc_loss = 0.00422825127919881
Trained batch 1110 in epoch 12, gen_loss = 0.8989184683341362, disc_loss = 0.004224675728403869
Trained batch 1111 in epoch 12, gen_loss = 0.8988898192271054, disc_loss = 0.004220974228832242
Trained batch 1112 in epoch 12, gen_loss = 0.8988114265525866, disc_loss = 0.004217334094154052
Trained batch 1113 in epoch 12, gen_loss = 0.8988407168075897, disc_loss = 0.004213694455237678
Trained batch 1114 in epoch 12, gen_loss = 0.8987799868989953, disc_loss = 0.004210090931945307
Trained batch 1115 in epoch 12, gen_loss = 0.8987401223951771, disc_loss = 0.004206582277079977
Trained batch 1116 in epoch 12, gen_loss = 0.8986997097437149, disc_loss = 0.004202962050985075
Trained batch 1117 in epoch 12, gen_loss = 0.8986171222223579, disc_loss = 0.004199463244444953
Trained batch 1118 in epoch 12, gen_loss = 0.8985577698687126, disc_loss = 0.004195830160000545
Trained batch 1119 in epoch 12, gen_loss = 0.8985533887786524, disc_loss = 0.004192322188431977
Trained batch 1120 in epoch 12, gen_loss = 0.8984434387707264, disc_loss = 0.004188960169275164
Trained batch 1121 in epoch 12, gen_loss = 0.8984525350325885, disc_loss = 0.0041854202832827744
Trained batch 1122 in epoch 12, gen_loss = 0.8983582485390899, disc_loss = 0.004182134953337377
Trained batch 1123 in epoch 12, gen_loss = 0.8985348619600207, disc_loss = 0.00417869441274584
Trained batch 1124 in epoch 12, gen_loss = 0.8985782321823967, disc_loss = 0.004175174295533604
Trained batch 1125 in epoch 12, gen_loss = 0.8986330692446253, disc_loss = 0.004171982850686043
Trained batch 1126 in epoch 12, gen_loss = 0.8985813470572207, disc_loss = 0.004168770577113308
Trained batch 1127 in epoch 12, gen_loss = 0.8986974314700628, disc_loss = 0.00416546262489814
Trained batch 1128 in epoch 12, gen_loss = 0.8987077538475091, disc_loss = 0.004162421083494934
Trained batch 1129 in epoch 12, gen_loss = 0.8986916573174232, disc_loss = 0.004159040054231954
Trained batch 1130 in epoch 12, gen_loss = 0.8986843113452327, disc_loss = 0.00415553756929504
Trained batch 1131 in epoch 12, gen_loss = 0.8986199422880955, disc_loss = 0.004151964316490078
Trained batch 1132 in epoch 12, gen_loss = 0.8985847147923072, disc_loss = 0.004148443421413507
Trained batch 1133 in epoch 12, gen_loss = 0.8986131181477239, disc_loss = 0.004144973553129876
Trained batch 1134 in epoch 12, gen_loss = 0.8986013927123621, disc_loss = 0.004141591832041484
Trained batch 1135 in epoch 12, gen_loss = 0.8987025505220386, disc_loss = 0.004138280959645092
Trained batch 1136 in epoch 12, gen_loss = 0.8987324635712012, disc_loss = 0.004134845733528672
Trained batch 1137 in epoch 12, gen_loss = 0.8987085213246371, disc_loss = 0.004131472381310337
Trained batch 1138 in epoch 12, gen_loss = 0.8987256923299594, disc_loss = 0.004127977453474488
Trained batch 1139 in epoch 12, gen_loss = 0.8986884063795993, disc_loss = 0.004124464269383074
Trained batch 1140 in epoch 12, gen_loss = 0.8985970102831734, disc_loss = 0.004121018215257821
Trained batch 1141 in epoch 12, gen_loss = 0.8985447624205708, disc_loss = 0.004117518079692354
Trained batch 1142 in epoch 12, gen_loss = 0.898552107112197, disc_loss = 0.004114000464258978
Trained batch 1143 in epoch 12, gen_loss = 0.8986156621908808, disc_loss = 0.004110482129394736
Trained batch 1144 in epoch 12, gen_loss = 0.8986642832839333, disc_loss = 0.0041070020962486195
Trained batch 1145 in epoch 12, gen_loss = 0.8986270445907719, disc_loss = 0.004103547232787297
Trained batch 1146 in epoch 12, gen_loss = 0.8986265954497387, disc_loss = 0.004100066142141699
Trained batch 1147 in epoch 12, gen_loss = 0.8985799358904569, disc_loss = 0.0040966181656272105
Trained batch 1148 in epoch 12, gen_loss = 0.8985568358651237, disc_loss = 0.004093128726125154
Trained batch 1149 in epoch 12, gen_loss = 0.8985823028502257, disc_loss = 0.0040896752914768115
Trained batch 1150 in epoch 12, gen_loss = 0.8985620243563847, disc_loss = 0.00408619213100091
Trained batch 1151 in epoch 12, gen_loss = 0.8985711818871399, disc_loss = 0.004082793905202682
Trained batch 1152 in epoch 12, gen_loss = 0.8985738095157786, disc_loss = 0.004079380767699715
Trained batch 1153 in epoch 12, gen_loss = 0.8985411279432902, disc_loss = 0.00407598362232343
Trained batch 1154 in epoch 12, gen_loss = 0.8984649443007134, disc_loss = 0.0040726559820486175
Trained batch 1155 in epoch 12, gen_loss = 0.898509258165904, disc_loss = 0.00406929356486657
Trained batch 1156 in epoch 12, gen_loss = 0.8985469446886998, disc_loss = 0.0040659510663523584
Trained batch 1157 in epoch 12, gen_loss = 0.8985556262659491, disc_loss = 0.004062610641328959
Trained batch 1158 in epoch 12, gen_loss = 0.8985371750629185, disc_loss = 0.004059231017985019
Trained batch 1159 in epoch 12, gen_loss = 0.8984548204417886, disc_loss = 0.004055988350617178
Trained batch 1160 in epoch 12, gen_loss = 0.8984796317048775, disc_loss = 0.00405262457377307
Trained batch 1161 in epoch 12, gen_loss = 0.8985183787838317, disc_loss = 0.004049243039108705
Trained batch 1162 in epoch 12, gen_loss = 0.8985674529883335, disc_loss = 0.004045946943575756
Trained batch 1163 in epoch 12, gen_loss = 0.8984713796078134, disc_loss = 0.004042638120629214
Trained batch 1164 in epoch 12, gen_loss = 0.8984645194761743, disc_loss = 0.004039260618340688
Trained batch 1165 in epoch 12, gen_loss = 0.8984456534655589, disc_loss = 0.004035869481642425
Trained batch 1166 in epoch 12, gen_loss = 0.8984297606918479, disc_loss = 0.0040326038310443445
Trained batch 1167 in epoch 12, gen_loss = 0.8984326528870079, disc_loss = 0.004029270678242876
Trained batch 1168 in epoch 12, gen_loss = 0.898509320741642, disc_loss = 0.004025966365184264
Trained batch 1169 in epoch 12, gen_loss = 0.8984958046012455, disc_loss = 0.004022617604511116
Trained batch 1170 in epoch 12, gen_loss = 0.8984865894895858, disc_loss = 0.0040193466238020266
Trained batch 1171 in epoch 12, gen_loss = 0.8983880811380445, disc_loss = 0.004016020361858997
Trained batch 1172 in epoch 12, gen_loss = 0.8983907668080374, disc_loss = 0.004012765798541626
Trained batch 1173 in epoch 12, gen_loss = 0.8983232152015225, disc_loss = 0.0040094893617220635
Trained batch 1174 in epoch 12, gen_loss = 0.8982312550950557, disc_loss = 0.00400632232357624
Trained batch 1175 in epoch 12, gen_loss = 0.8983017914250594, disc_loss = 0.004003078910871557
Trained batch 1176 in epoch 12, gen_loss = 0.8982353825739308, disc_loss = 0.004000015901996821
Trained batch 1177 in epoch 12, gen_loss = 0.8982888176809547, disc_loss = 0.003996773901670875
Trained batch 1178 in epoch 12, gen_loss = 0.898257799124293, disc_loss = 0.003993470724305011
Trained batch 1179 in epoch 12, gen_loss = 0.8981752185498254, disc_loss = 0.003990182049553476
Trained batch 1180 in epoch 12, gen_loss = 0.8982839013034262, disc_loss = 0.003986941500326922
Trained batch 1181 in epoch 12, gen_loss = 0.8983795306000815, disc_loss = 0.0039837175669461666
Trained batch 1182 in epoch 12, gen_loss = 0.8983047530495909, disc_loss = 0.0039805867380233
Trained batch 1183 in epoch 12, gen_loss = 0.8983926281735704, disc_loss = 0.003977322046497451
Trained batch 1184 in epoch 12, gen_loss = 0.8983329189980583, disc_loss = 0.003974118494883795
Trained batch 1185 in epoch 12, gen_loss = 0.8982910578709228, disc_loss = 0.003970884868458612
Trained batch 1186 in epoch 12, gen_loss = 0.8982485824507028, disc_loss = 0.003967626160933829
Trained batch 1187 in epoch 12, gen_loss = 0.8982082486453683, disc_loss = 0.003964374101972739
Trained batch 1188 in epoch 12, gen_loss = 0.8982759450442456, disc_loss = 0.003961149815318366
Trained batch 1189 in epoch 12, gen_loss = 0.8982537530550436, disc_loss = 0.003957922066379184
Trained batch 1190 in epoch 12, gen_loss = 0.8983039938032277, disc_loss = 0.003954740849741776
Trained batch 1191 in epoch 12, gen_loss = 0.8983514780966227, disc_loss = 0.003951492800950401
Trained batch 1192 in epoch 12, gen_loss = 0.8984800055560602, disc_loss = 0.003948532530504348
Trained batch 1193 in epoch 12, gen_loss = 0.8985451981050885, disc_loss = 0.003945367773163126
Trained batch 1194 in epoch 12, gen_loss = 0.8983996551405935, disc_loss = 0.003942439437378198
Trained batch 1195 in epoch 12, gen_loss = 0.8984265451546896, disc_loss = 0.0039393088069197765
Trained batch 1196 in epoch 12, gen_loss = 0.8984321459393354, disc_loss = 0.003936138229661795
Trained batch 1197 in epoch 12, gen_loss = 0.8984044084763885, disc_loss = 0.0039329622191683474
Trained batch 1198 in epoch 12, gen_loss = 0.8984877562105308, disc_loss = 0.003929776375889446
Trained batch 1199 in epoch 12, gen_loss = 0.8984340666731199, disc_loss = 0.003926714663933429
Trained batch 1200 in epoch 12, gen_loss = 0.8983714754238018, disc_loss = 0.003923550076267462
Trained batch 1201 in epoch 12, gen_loss = 0.8983770573198696, disc_loss = 0.003925523135971912
Trained batch 1202 in epoch 12, gen_loss = 0.8982637040533825, disc_loss = 0.003923101025206609
Trained batch 1203 in epoch 12, gen_loss = 0.89838944806213, disc_loss = 0.003920235231554182
Trained batch 1204 in epoch 12, gen_loss = 0.8983350324432879, disc_loss = 0.003917516452214184
Trained batch 1205 in epoch 12, gen_loss = 0.8984174504011226, disc_loss = 0.0039146658374716444
Trained batch 1206 in epoch 12, gen_loss = 0.8985301244328016, disc_loss = 0.003911802340480459
Trained batch 1207 in epoch 12, gen_loss = 0.89852974035882, disc_loss = 0.003908767658372771
Trained batch 1208 in epoch 12, gen_loss = 0.8984304480162211, disc_loss = 0.0039057714937948945
Trained batch 1209 in epoch 12, gen_loss = 0.8984384155470477, disc_loss = 0.003902808551693168
Trained batch 1210 in epoch 12, gen_loss = 0.8984263982780702, disc_loss = 0.0038997308262550307
Trained batch 1211 in epoch 12, gen_loss = 0.8984412955667319, disc_loss = 0.003896790261771259
Trained batch 1212 in epoch 12, gen_loss = 0.8983581758488924, disc_loss = 0.0038938749968670736
Trained batch 1213 in epoch 12, gen_loss = 0.8983535373819719, disc_loss = 0.00389091279003703
Trained batch 1214 in epoch 12, gen_loss = 0.8982982830746183, disc_loss = 0.003887928585317551
Trained batch 1215 in epoch 12, gen_loss = 0.8983211009518096, disc_loss = 0.003884912041275799
Trained batch 1216 in epoch 12, gen_loss = 0.898313932469759, disc_loss = 0.003882009081636284
Trained batch 1217 in epoch 12, gen_loss = 0.8982243443455407, disc_loss = 0.0038791790197770953
Trained batch 1218 in epoch 12, gen_loss = 0.8983561624455785, disc_loss = 0.003876221325740356
Trained batch 1219 in epoch 12, gen_loss = 0.8983645972169814, disc_loss = 0.0038735060116763275
Trained batch 1220 in epoch 12, gen_loss = 0.8984610741983956, disc_loss = 0.0038705398485026463
Trained batch 1221 in epoch 12, gen_loss = 0.8984871015513587, disc_loss = 0.0038675280366897062
Trained batch 1222 in epoch 12, gen_loss = 0.8985487658862491, disc_loss = 0.003864532040324961
Trained batch 1223 in epoch 12, gen_loss = 0.8986197610209191, disc_loss = 0.003861492459031533
Trained batch 1224 in epoch 12, gen_loss = 0.8986591526440212, disc_loss = 0.0038584686468215185
Trained batch 1225 in epoch 12, gen_loss = 0.898563910415472, disc_loss = 0.003855648597953873
Trained batch 1226 in epoch 12, gen_loss = 0.8985296718551555, disc_loss = 0.0038527100513410374
Trained batch 1227 in epoch 12, gen_loss = 0.8984762689383876, disc_loss = 0.0038499721101173203
Trained batch 1228 in epoch 12, gen_loss = 0.8983891901686678, disc_loss = 0.0038469536131514716
Trained batch 1229 in epoch 12, gen_loss = 0.8984257387921093, disc_loss = 0.0038439964605185366
Trained batch 1230 in epoch 12, gen_loss = 0.8983973787142725, disc_loss = 0.0038409668558142805
Trained batch 1231 in epoch 12, gen_loss = 0.8983508092532684, disc_loss = 0.0038379605514039994
Trained batch 1232 in epoch 12, gen_loss = 0.8983722473679765, disc_loss = 0.0038349912108686626
Trained batch 1233 in epoch 12, gen_loss = 0.8983458626405539, disc_loss = 0.0038320513449434657
Trained batch 1234 in epoch 12, gen_loss = 0.8983804047349011, disc_loss = 0.0038290725910467252
Trained batch 1235 in epoch 12, gen_loss = 0.8983749645041802, disc_loss = 0.003826222162070267
Trained batch 1236 in epoch 12, gen_loss = 0.898366847439167, disc_loss = 0.003823289381770092
Trained batch 1237 in epoch 12, gen_loss = 0.8983424051705393, disc_loss = 0.003820285035588736
Trained batch 1238 in epoch 12, gen_loss = 0.898366067850176, disc_loss = 0.003817343081926573
Trained batch 1239 in epoch 12, gen_loss = 0.8984155077126719, disc_loss = 0.003814649277134571
Trained batch 1240 in epoch 12, gen_loss = 0.8983368021072062, disc_loss = 0.0038117514707633154
Trained batch 1241 in epoch 12, gen_loss = 0.8983625570933024, disc_loss = 0.0038088662452781972
Trained batch 1242 in epoch 12, gen_loss = 0.8983707775152794, disc_loss = 0.0038059159342668505
Trained batch 1243 in epoch 12, gen_loss = 0.898350925020083, disc_loss = 0.003803041999844205
Trained batch 1244 in epoch 12, gen_loss = 0.8983663846211261, disc_loss = 0.0038002477229858492
Trained batch 1245 in epoch 12, gen_loss = 0.8984190976638855, disc_loss = 0.0037973533273447228
Trained batch 1246 in epoch 12, gen_loss = 0.8983697177604761, disc_loss = 0.0037944997881334997
Trained batch 1247 in epoch 12, gen_loss = 0.8983336463092993, disc_loss = 0.003791603831913539
Trained batch 1248 in epoch 12, gen_loss = 0.8983281293423105, disc_loss = 0.003788803117118824
Trained batch 1249 in epoch 12, gen_loss = 0.8983355837345123, disc_loss = 0.0037859379958186763
Trained batch 1250 in epoch 12, gen_loss = 0.8982911968974473, disc_loss = 0.00378313065705964
Trained batch 1251 in epoch 12, gen_loss = 0.8983716340586781, disc_loss = 0.0037806710938915345
Trained batch 1252 in epoch 12, gen_loss = 0.8983157393176938, disc_loss = 0.003777938871659535
Trained batch 1253 in epoch 12, gen_loss = 0.8984472676042164, disc_loss = 0.0037752076403939805
Trained batch 1254 in epoch 12, gen_loss = 0.8984251552369015, disc_loss = 0.0037724080486781987
Trained batch 1255 in epoch 12, gen_loss = 0.8984523021681293, disc_loss = 0.0037696355665890907
Trained batch 1256 in epoch 12, gen_loss = 0.8984690340341038, disc_loss = 0.003766782032335357
Trained batch 1257 in epoch 12, gen_loss = 0.8985168242113389, disc_loss = 0.0037639483147914226
Trained batch 1258 in epoch 12, gen_loss = 0.8984557163440774, disc_loss = 0.0037611027945597644
Trained batch 1259 in epoch 12, gen_loss = 0.8984882650394288, disc_loss = 0.003758488836152422
Trained batch 1260 in epoch 12, gen_loss = 0.898390162189644, disc_loss = 0.0037558503886109163
Trained batch 1261 in epoch 12, gen_loss = 0.8983480594993204, disc_loss = 0.0037531177419959255
Trained batch 1262 in epoch 12, gen_loss = 0.8982784169492322, disc_loss = 0.0037502824787323044
Trained batch 1263 in epoch 12, gen_loss = 0.8982389461296268, disc_loss = 0.0037474597923829616
Trained batch 1264 in epoch 12, gen_loss = 0.8982302641208935, disc_loss = 0.0037446278271119466
Trained batch 1265 in epoch 12, gen_loss = 0.8982065683480875, disc_loss = 0.0037418780116132908
Trained batch 1266 in epoch 12, gen_loss = 0.8982291361339091, disc_loss = 0.0037391027518297324
Trained batch 1267 in epoch 12, gen_loss = 0.8981715820565208, disc_loss = 0.0037363388108861964
Trained batch 1268 in epoch 12, gen_loss = 0.8980719730833367, disc_loss = 0.0037335216586015787
Trained batch 1269 in epoch 12, gen_loss = 0.89813630242986, disc_loss = 0.0037307483147713816
Trained batch 1270 in epoch 12, gen_loss = 0.8979978532794889, disc_loss = 0.0037284255339406387
Trained batch 1271 in epoch 12, gen_loss = 0.8980220658411769, disc_loss = 0.003725670875347252
Trained batch 1272 in epoch 12, gen_loss = 0.8980339914443263, disc_loss = 0.003722985132411241
Trained batch 1273 in epoch 12, gen_loss = 0.8980554156999573, disc_loss = 0.003720246668065669
Trained batch 1274 in epoch 12, gen_loss = 0.8979306477191401, disc_loss = 0.003717515417049392
Trained batch 1275 in epoch 12, gen_loss = 0.8979045585218268, disc_loss = 0.003714784375009126
Trained batch 1276 in epoch 12, gen_loss = 0.8979577924837427, disc_loss = 0.0037119832070450554
Trained batch 1277 in epoch 12, gen_loss = 0.8979298393584566, disc_loss = 0.0037092462497780553
Trained batch 1278 in epoch 12, gen_loss = 0.8978945062065423, disc_loss = 0.003706506832105796
Trained batch 1279 in epoch 12, gen_loss = 0.8979136569891125, disc_loss = 0.0037037581721790502
Trained batch 1280 in epoch 12, gen_loss = 0.897875801228993, disc_loss = 0.0037009806388890124
Trained batch 1281 in epoch 12, gen_loss = 0.8978243775654137, disc_loss = 0.003698382167554562
Trained batch 1282 in epoch 12, gen_loss = 0.8977710208387367, disc_loss = 0.0036958435055351453
Trained batch 1283 in epoch 12, gen_loss = 0.8978771634190996, disc_loss = 0.0036932511507457603
Trained batch 1284 in epoch 12, gen_loss = 0.8977973355857315, disc_loss = 0.0036906693059783916
Trained batch 1285 in epoch 12, gen_loss = 0.8978741492027443, disc_loss = 0.003687908048261057
Trained batch 1286 in epoch 12, gen_loss = 0.8978701376044297, disc_loss = 0.003685259281522361
Trained batch 1287 in epoch 12, gen_loss = 0.8978124330780521, disc_loss = 0.0036826271788701678
Trained batch 1288 in epoch 12, gen_loss = 0.8978122869048404, disc_loss = 0.0036799795731949176
Trained batch 1289 in epoch 12, gen_loss = 0.8977835532768752, disc_loss = 0.003677351796953775
Trained batch 1290 in epoch 12, gen_loss = 0.8977909754358642, disc_loss = 0.003674629223335267
Trained batch 1291 in epoch 12, gen_loss = 0.8977939751771951, disc_loss = 0.0036719410335122023
Trained batch 1292 in epoch 12, gen_loss = 0.8977678144337683, disc_loss = 0.003669231848460408
Trained batch 1293 in epoch 12, gen_loss = 0.8977884761240604, disc_loss = 0.0036665653588128914
Trained batch 1294 in epoch 12, gen_loss = 0.8977508031723582, disc_loss = 0.003663873408814761
Trained batch 1295 in epoch 12, gen_loss = 0.8978453989106195, disc_loss = 0.0036612769643476367
Trained batch 1296 in epoch 12, gen_loss = 0.8978966500727875, disc_loss = 0.0036586094944237994
Trained batch 1297 in epoch 12, gen_loss = 0.897811793077892, disc_loss = 0.0036559792022248685
Trained batch 1298 in epoch 12, gen_loss = 0.8977437421759795, disc_loss = 0.0036533593770606875
Trained batch 1299 in epoch 12, gen_loss = 0.8977745521527071, disc_loss = 0.0036506940777438174
Trained batch 1300 in epoch 12, gen_loss = 0.8977843191328643, disc_loss = 0.0036480920404897946
Trained batch 1301 in epoch 12, gen_loss = 0.8978899439908392, disc_loss = 0.0036456592032637503
Trained batch 1302 in epoch 12, gen_loss = 0.8978664103326482, disc_loss = 0.003643085245702711
Trained batch 1303 in epoch 12, gen_loss = 0.8979115785996606, disc_loss = 0.0036404443737934966
Trained batch 1304 in epoch 12, gen_loss = 0.8978681406298816, disc_loss = 0.0036378466358871764
Trained batch 1305 in epoch 12, gen_loss = 0.8979655680393552, disc_loss = 0.0036353940563033506
Trained batch 1306 in epoch 12, gen_loss = 0.897989815852071, disc_loss = 0.0036327122930727607
Trained batch 1307 in epoch 12, gen_loss = 0.8979301355118416, disc_loss = 0.0036300705378602876
Trained batch 1308 in epoch 12, gen_loss = 0.8979800672272492, disc_loss = 0.0036273988766285428
Trained batch 1309 in epoch 12, gen_loss = 0.8979795032330141, disc_loss = 0.0036247874772918627
Trained batch 1310 in epoch 12, gen_loss = 0.8980114341327746, disc_loss = 0.0036222547308238052
Trained batch 1311 in epoch 12, gen_loss = 0.8980445123572902, disc_loss = 0.0036196300584212687
Trained batch 1312 in epoch 12, gen_loss = 0.8980349765782673, disc_loss = 0.003617084807869831
Trained batch 1313 in epoch 12, gen_loss = 0.8981675819084162, disc_loss = 0.0036145793259149766
Trained batch 1314 in epoch 12, gen_loss = 0.8981361763105646, disc_loss = 0.003612059242920481
Trained batch 1315 in epoch 12, gen_loss = 0.8981600141543385, disc_loss = 0.0036095510709513385
Trained batch 1316 in epoch 12, gen_loss = 0.8981611614165744, disc_loss = 0.003607060133693052
Trained batch 1317 in epoch 12, gen_loss = 0.8981804957610523, disc_loss = 0.0036045605769070986
Trained batch 1318 in epoch 12, gen_loss = 0.8981163175021093, disc_loss = 0.003601999933028622
Trained batch 1319 in epoch 12, gen_loss = 0.8980875359791698, disc_loss = 0.0035993498445102226
Trained batch 1320 in epoch 12, gen_loss = 0.8980844744130755, disc_loss = 0.003596774405332911
Trained batch 1321 in epoch 12, gen_loss = 0.898050845165296, disc_loss = 0.0035941835202735676
Trained batch 1322 in epoch 12, gen_loss = 0.8981181387187672, disc_loss = 0.0035916470876949094
Trained batch 1323 in epoch 12, gen_loss = 0.898100680004794, disc_loss = 0.0035890671050108672
Trained batch 1324 in epoch 12, gen_loss = 0.8981935036857173, disc_loss = 0.003586535208456587
Trained batch 1325 in epoch 12, gen_loss = 0.8981760975372378, disc_loss = 0.0035839253766863427
Trained batch 1326 in epoch 12, gen_loss = 0.8981193711906784, disc_loss = 0.0035814002340750035
Trained batch 1327 in epoch 12, gen_loss = 0.8980988974133169, disc_loss = 0.003578854374072433
Trained batch 1328 in epoch 12, gen_loss = 0.8981007307072705, disc_loss = 0.003576255337827635
Trained batch 1329 in epoch 12, gen_loss = 0.898118437591352, disc_loss = 0.003573656871447014
Trained batch 1330 in epoch 12, gen_loss = 0.8981256548127763, disc_loss = 0.0035710720110469995
Trained batch 1331 in epoch 12, gen_loss = 0.8980892708262166, disc_loss = 0.0035684636140057547
Trained batch 1332 in epoch 12, gen_loss = 0.8980132340490594, disc_loss = 0.003565953156363213
Trained batch 1333 in epoch 12, gen_loss = 0.8980130998269729, disc_loss = 0.003563958334891994
Trained batch 1334 in epoch 12, gen_loss = 0.8979715344164702, disc_loss = 0.003561620022494421
Trained batch 1335 in epoch 12, gen_loss = 0.8979566272593544, disc_loss = 0.0035593338956089442
Trained batch 1336 in epoch 12, gen_loss = 0.8979026615040108, disc_loss = 0.003556845647310718
Trained batch 1337 in epoch 12, gen_loss = 0.8979515562944883, disc_loss = 0.0035544923585233566
Trained batch 1338 in epoch 12, gen_loss = 0.8979446302606955, disc_loss = 0.003552054730590662
Trained batch 1339 in epoch 12, gen_loss = 0.8979708364205574, disc_loss = 0.0035495977011218635
Trained batch 1340 in epoch 12, gen_loss = 0.8979370353561476, disc_loss = 0.0035472099326444963
Trained batch 1341 in epoch 12, gen_loss = 0.8979281941664734, disc_loss = 0.00354473626358696
Trained batch 1342 in epoch 12, gen_loss = 0.8979792846997816, disc_loss = 0.0035422891456146563
Trained batch 1343 in epoch 12, gen_loss = 0.8979904265808207, disc_loss = 0.003539810928156753
Trained batch 1344 in epoch 12, gen_loss = 0.8979062704348653, disc_loss = 0.00353733723764944
Trained batch 1345 in epoch 12, gen_loss = 0.8978006736130453, disc_loss = 0.003534860017896555
Trained batch 1346 in epoch 12, gen_loss = 0.8979031819277723, disc_loss = 0.0035325428715715776
Trained batch 1347 in epoch 12, gen_loss = 0.8979217010365041, disc_loss = 0.003530163802315116
Trained batch 1348 in epoch 12, gen_loss = 0.8978265390473883, disc_loss = 0.0035277811695846695
Trained batch 1349 in epoch 12, gen_loss = 0.8977556032163125, disc_loss = 0.003525401750160166
Trained batch 1350 in epoch 12, gen_loss = 0.8977936904665103, disc_loss = 0.0035229066358781406
Trained batch 1351 in epoch 12, gen_loss = 0.8977205701745473, disc_loss = 0.0035204593163703415
Trained batch 1352 in epoch 12, gen_loss = 0.8978329227751304, disc_loss = 0.0035181172797867236
Trained batch 1353 in epoch 12, gen_loss = 0.8978283099356923, disc_loss = 0.0035157475601625097
Trained batch 1354 in epoch 12, gen_loss = 0.8978081646440654, disc_loss = 0.003513243909412093
Trained batch 1355 in epoch 12, gen_loss = 0.8978100296406619, disc_loss = 0.0035108814101482404
Trained batch 1356 in epoch 12, gen_loss = 0.8977988881931291, disc_loss = 0.0035084061099540367
Trained batch 1357 in epoch 12, gen_loss = 0.8977557188983518, disc_loss = 0.0035060196221737613
Trained batch 1358 in epoch 12, gen_loss = 0.8977679169028888, disc_loss = 0.0035035172707154165
Trained batch 1359 in epoch 12, gen_loss = 0.8977148279109421, disc_loss = 0.003501090894775082
Trained batch 1360 in epoch 12, gen_loss = 0.897704574178896, disc_loss = 0.003498737461550858
Trained batch 1361 in epoch 12, gen_loss = 0.8976913987714988, disc_loss = 0.0034962703410017053
Trained batch 1362 in epoch 12, gen_loss = 0.897559446704274, disc_loss = 0.003494119352221377
Trained batch 1363 in epoch 12, gen_loss = 0.8975500112230127, disc_loss = 0.0034917932367918444
Trained batch 1364 in epoch 12, gen_loss = 0.8975552628328513, disc_loss = 0.003489484596441435
Trained batch 1365 in epoch 12, gen_loss = 0.8976210950059738, disc_loss = 0.003487109031120355
Trained batch 1366 in epoch 12, gen_loss = 0.8977130252074916, disc_loss = 0.003484772538588108
Trained batch 1367 in epoch 12, gen_loss = 0.8976985336831439, disc_loss = 0.0034824240240367123
Trained batch 1368 in epoch 12, gen_loss = 0.8977343712173473, disc_loss = 0.00347998742365329
Trained batch 1369 in epoch 12, gen_loss = 0.8977126274665777, disc_loss = 0.0034775954229441935
Trained batch 1370 in epoch 12, gen_loss = 0.8976987590327218, disc_loss = 0.0034751548653393425
Trained batch 1371 in epoch 12, gen_loss = 0.8977043890223211, disc_loss = 0.003472767799479056
Trained batch 1372 in epoch 12, gen_loss = 0.8977242405624696, disc_loss = 0.0034704059544495916
Trained batch 1373 in epoch 12, gen_loss = 0.8977556701917663, disc_loss = 0.003468121008915634
Trained batch 1374 in epoch 12, gen_loss = 0.8977557855085894, disc_loss = 0.003465692773927003
Trained batch 1375 in epoch 12, gen_loss = 0.8977973697663739, disc_loss = 0.0034632781820894093
Trained batch 1376 in epoch 12, gen_loss = 0.8977111601362041, disc_loss = 0.0034608547852754885
Trained batch 1377 in epoch 12, gen_loss = 0.8976861723794647, disc_loss = 0.0034584602483005685
Trained batch 1378 in epoch 12, gen_loss = 0.8976308554302876, disc_loss = 0.0034560769234830042
Trained batch 1379 in epoch 12, gen_loss = 0.8975976425668467, disc_loss = 0.0034537683065919093
Trained batch 1380 in epoch 12, gen_loss = 0.8976297713897092, disc_loss = 0.003451374800570035
Trained batch 1381 in epoch 12, gen_loss = 0.8975505831013885, disc_loss = 0.0034490108903424675
Trained batch 1382 in epoch 12, gen_loss = 0.8974936908772262, disc_loss = 0.003446658559613077
Trained batch 1383 in epoch 12, gen_loss = 0.8974936554972837, disc_loss = 0.0034443506389303536
Trained batch 1384 in epoch 12, gen_loss = 0.8975316697079352, disc_loss = 0.003442066715145988
Trained batch 1385 in epoch 12, gen_loss = 0.8975157874057131, disc_loss = 0.003439668880140872
Trained batch 1386 in epoch 12, gen_loss = 0.8975284565844464, disc_loss = 0.0034373427858830413
Trained batch 1387 in epoch 12, gen_loss = 0.8974909360281672, disc_loss = 0.0034349291618599393
Trained batch 1388 in epoch 12, gen_loss = 0.897482016517414, disc_loss = 0.003432750015439435
Trained batch 1389 in epoch 12, gen_loss = 0.8974731214183698, disc_loss = 0.003430518370457563
Trained batch 1390 in epoch 12, gen_loss = 0.8974828441566396, disc_loss = 0.0034281521313066347
Trained batch 1391 in epoch 12, gen_loss = 0.8974463278534769, disc_loss = 0.0034258180728217154
Trained batch 1392 in epoch 12, gen_loss = 0.8973996163013592, disc_loss = 0.003423493848846572
Trained batch 1393 in epoch 12, gen_loss = 0.89740059472396, disc_loss = 0.003421257679188077
Trained batch 1394 in epoch 12, gen_loss = 0.8974007795788481, disc_loss = 0.0034189991821016695
Trained batch 1395 in epoch 12, gen_loss = 0.8974002292299681, disc_loss = 0.0034166756680636882
Trained batch 1396 in epoch 12, gen_loss = 0.8974578480850225, disc_loss = 0.0034143649069444024
Trained batch 1397 in epoch 12, gen_loss = 0.897449597652378, disc_loss = 0.003412058073828278
Trained batch 1398 in epoch 12, gen_loss = 0.8973429834868245, disc_loss = 0.003409778823391378
Trained batch 1399 in epoch 12, gen_loss = 0.8973272672721317, disc_loss = 0.0034075138157641047
Trained batch 1400 in epoch 12, gen_loss = 0.8973819434344982, disc_loss = 0.003405475409628842
Trained batch 1401 in epoch 12, gen_loss = 0.8974418025809245, disc_loss = 0.003403241177855595
Trained batch 1402 in epoch 12, gen_loss = 0.8973750197624022, disc_loss = 0.003400977861662847
Trained batch 1403 in epoch 12, gen_loss = 0.8973010282146285, disc_loss = 0.0033986685383029114
Trained batch 1404 in epoch 12, gen_loss = 0.8971911241575492, disc_loss = 0.003396381675922378
Trained batch 1405 in epoch 12, gen_loss = 0.8971499219049262, disc_loss = 0.003394068770446688
Trained batch 1406 in epoch 12, gen_loss = 0.8972421798116362, disc_loss = 0.0033919425092351426
Trained batch 1407 in epoch 12, gen_loss = 0.8972619272429835, disc_loss = 0.0033896772335476107
Trained batch 1408 in epoch 12, gen_loss = 0.8972863156039128, disc_loss = 0.003387406143736021
Trained batch 1409 in epoch 12, gen_loss = 0.897275489019164, disc_loss = 0.0033851341659398024
Trained batch 1410 in epoch 12, gen_loss = 0.8973155978045338, disc_loss = 0.0033828974390005748
Trained batch 1411 in epoch 12, gen_loss = 0.8973102093418327, disc_loss = 0.003380613138319769
Trained batch 1412 in epoch 12, gen_loss = 0.8972853643204081, disc_loss = 0.003378314562744569
Trained batch 1413 in epoch 12, gen_loss = 0.8971900236825795, disc_loss = 0.003376037006482862
Trained batch 1414 in epoch 12, gen_loss = 0.8972465345800554, disc_loss = 0.0033737522200064226
Trained batch 1415 in epoch 12, gen_loss = 0.8972414267265191, disc_loss = 0.0033714924502213773
Trained batch 1416 in epoch 12, gen_loss = 0.8972713921216482, disc_loss = 0.0033692208810964267
Trained batch 1417 in epoch 12, gen_loss = 0.8973019385791801, disc_loss = 0.0033669124603553408
Trained batch 1418 in epoch 12, gen_loss = 0.897296839864259, disc_loss = 0.003364804286939726
Trained batch 1419 in epoch 12, gen_loss = 0.8973640328981507, disc_loss = 0.0033625760745617044
Trained batch 1420 in epoch 12, gen_loss = 0.8973899122109974, disc_loss = 0.003360349293311574
Trained batch 1421 in epoch 12, gen_loss = 0.8974489110683087, disc_loss = 0.003358097982070731
Trained batch 1422 in epoch 12, gen_loss = 0.8973833657199032, disc_loss = 0.0033558436735122983
Trained batch 1423 in epoch 12, gen_loss = 0.8973302886810866, disc_loss = 0.0033536487755677475
Trained batch 1424 in epoch 12, gen_loss = 0.8973106092737432, disc_loss = 0.003351386888391796
Trained batch 1425 in epoch 12, gen_loss = 0.8972949797358118, disc_loss = 0.0033491274045616536
Trained batch 1426 in epoch 12, gen_loss = 0.8973008931393213, disc_loss = 0.003346884019239923
Trained batch 1427 in epoch 12, gen_loss = 0.8973358735149982, disc_loss = 0.00334464724352986
Trained batch 1428 in epoch 12, gen_loss = 0.8974041127090775, disc_loss = 0.003342401786244043
Trained batch 1429 in epoch 12, gen_loss = 0.8973708624606366, disc_loss = 0.0033401618700660113
Trained batch 1430 in epoch 12, gen_loss = 0.8973452176437938, disc_loss = 0.003337910038475079
Trained batch 1431 in epoch 12, gen_loss = 0.8972784067249165, disc_loss = 0.0033357142882366577
Trained batch 1432 in epoch 12, gen_loss = 0.8973426467791689, disc_loss = 0.0033335937292432293
Trained batch 1433 in epoch 12, gen_loss = 0.8972198319318737, disc_loss = 0.0033317159021161143
Trained batch 1434 in epoch 12, gen_loss = 0.8971050016140688, disc_loss = 0.0033296549642401366
Trained batch 1435 in epoch 12, gen_loss = 0.8971288210834302, disc_loss = 0.003327669944386327
Trained batch 1436 in epoch 12, gen_loss = 0.897218284295015, disc_loss = 0.0033255080595123126
Trained batch 1437 in epoch 12, gen_loss = 0.897216762305964, disc_loss = 0.003323316617534855
Trained batch 1438 in epoch 12, gen_loss = 0.8972047320084906, disc_loss = 0.003321122253691505
Trained batch 1439 in epoch 12, gen_loss = 0.8971986492060953, disc_loss = 0.0033189085484435863
Trained batch 1440 in epoch 12, gen_loss = 0.8972241018151013, disc_loss = 0.0033167173370062877
Trained batch 1441 in epoch 12, gen_loss = 0.8972154387819288, disc_loss = 0.003314574071776402
Trained batch 1442 in epoch 12, gen_loss = 0.8971879825935708, disc_loss = 0.003312416005888636
Trained batch 1443 in epoch 12, gen_loss = 0.8972175005317725, disc_loss = 0.00331022579840084
Trained batch 1444 in epoch 12, gen_loss = 0.8971591970499824, disc_loss = 0.003308099389196475
Trained batch 1445 in epoch 12, gen_loss = 0.8971045757147946, disc_loss = 0.003305906298330862
Trained batch 1446 in epoch 12, gen_loss = 0.8971518717227348, disc_loss = 0.0033037095275816877
Trained batch 1447 in epoch 12, gen_loss = 0.8971833709359828, disc_loss = 0.00330169694673347
Trained batch 1448 in epoch 12, gen_loss = 0.897201707192007, disc_loss = 0.003299620853182598
Trained batch 1449 in epoch 12, gen_loss = 0.8972826635015422, disc_loss = 0.003297532849301833
Trained batch 1450 in epoch 12, gen_loss = 0.8973380937237808, disc_loss = 0.003295425614479088
Trained batch 1451 in epoch 12, gen_loss = 0.897220076977714, disc_loss = 0.0032933927443342783
Trained batch 1452 in epoch 12, gen_loss = 0.8972310374624879, disc_loss = 0.0032912251726740314
Trained batch 1453 in epoch 12, gen_loss = 0.8971958818347123, disc_loss = 0.0032892816077101225
Trained batch 1454 in epoch 12, gen_loss = 0.8971352442433335, disc_loss = 0.003287220381955813
Trained batch 1455 in epoch 12, gen_loss = 0.897162076904551, disc_loss = 0.003285064788577494
Trained batch 1456 in epoch 12, gen_loss = 0.8971641025235576, disc_loss = 0.0032829629750877978
Trained batch 1457 in epoch 12, gen_loss = 0.8971977536815675, disc_loss = 0.0032807856042420575
Trained batch 1458 in epoch 12, gen_loss = 0.8971288205418708, disc_loss = 0.0032787145024782377
Trained batch 1459 in epoch 12, gen_loss = 0.8970941997145954, disc_loss = 0.0032765857026701367
Trained batch 1460 in epoch 12, gen_loss = 0.8970843819948519, disc_loss = 0.003274452632049398
Trained batch 1461 in epoch 12, gen_loss = 0.8970898174962332, disc_loss = 0.003272338876329009
Trained batch 1462 in epoch 12, gen_loss = 0.8970261565317296, disc_loss = 0.0032702625098139553
Trained batch 1463 in epoch 12, gen_loss = 0.8969539795986942, disc_loss = 0.0032682484953198343
Trained batch 1464 in epoch 12, gen_loss = 0.896993866023757, disc_loss = 0.003266216184112121
Trained batch 1465 in epoch 12, gen_loss = 0.8969568595554461, disc_loss = 0.003264059346594435
Trained batch 1466 in epoch 12, gen_loss = 0.896985768377984, disc_loss = 0.0032619334418209885
Trained batch 1467 in epoch 12, gen_loss = 0.8969357574830588, disc_loss = 0.003259856462391921
Trained batch 1468 in epoch 12, gen_loss = 0.8969721077980031, disc_loss = 0.0032577198791489846
Trained batch 1469 in epoch 12, gen_loss = 0.896985677026567, disc_loss = 0.003255577327351547
Trained batch 1470 in epoch 12, gen_loss = 0.8970531511679545, disc_loss = 0.0032534827497273126
Trained batch 1471 in epoch 12, gen_loss = 0.897050142004762, disc_loss = 0.003251372359465637
Trained batch 1472 in epoch 12, gen_loss = 0.8970699614193354, disc_loss = 0.0032493378994560033
Trained batch 1473 in epoch 12, gen_loss = 0.897021153362991, disc_loss = 0.0032474389383715077
Trained batch 1474 in epoch 12, gen_loss = 0.8971127179921684, disc_loss = 0.003245379950429936
Trained batch 1475 in epoch 12, gen_loss = 0.8970960296670273, disc_loss = 0.0032434652570629482
Trained batch 1476 in epoch 12, gen_loss = 0.8971318223626531, disc_loss = 0.0032414247403043093
Trained batch 1477 in epoch 12, gen_loss = 0.897107936169685, disc_loss = 0.0032393770976902533
Trained batch 1478 in epoch 12, gen_loss = 0.8971189269751935, disc_loss = 0.003237377339780217
Trained batch 1479 in epoch 12, gen_loss = 0.8971893141801293, disc_loss = 0.003235359605895536
Trained batch 1480 in epoch 12, gen_loss = 0.8971444497150316, disc_loss = 0.00323329800364836
Trained batch 1481 in epoch 12, gen_loss = 0.8971741319346203, disc_loss = 0.00323128688400268
Trained batch 1482 in epoch 12, gen_loss = 0.8972051662122247, disc_loss = 0.0032292328762437753
Trained batch 1483 in epoch 12, gen_loss = 0.8971793430674109, disc_loss = 0.00322715251656158
Trained batch 1484 in epoch 12, gen_loss = 0.8971663390345846, disc_loss = 0.0032251491162897344
Trained batch 1485 in epoch 12, gen_loss = 0.8970795059589165, disc_loss = 0.0032237891651947202
Trained batch 1486 in epoch 12, gen_loss = 0.8971164865868959, disc_loss = 0.0032219717897469364
Trained batch 1487 in epoch 12, gen_loss = 0.8970653432751855, disc_loss = 0.003220168237974928
Trained batch 1488 in epoch 12, gen_loss = 0.897070707091555, disc_loss = 0.0032183248290667873
Trained batch 1489 in epoch 12, gen_loss = 0.8970547720089855, disc_loss = 0.0032165258410048825
Trained batch 1490 in epoch 12, gen_loss = 0.8971135201348626, disc_loss = 0.003214575281882767
Trained batch 1491 in epoch 12, gen_loss = 0.8971438848940361, disc_loss = 0.0032125864859336682
Trained batch 1492 in epoch 12, gen_loss = 0.8971642174340699, disc_loss = 0.003210624186478626
Trained batch 1493 in epoch 12, gen_loss = 0.8971503455555901, disc_loss = 0.0032087138438322022
Trained batch 1494 in epoch 12, gen_loss = 0.8971344262859893, disc_loss = 0.0032066961257034418
Trained batch 1495 in epoch 12, gen_loss = 0.8971737532771845, disc_loss = 0.0032048057059302255
Trained batch 1496 in epoch 12, gen_loss = 0.8971597847734679, disc_loss = 0.003202807447962603
Trained batch 1497 in epoch 12, gen_loss = 0.8970939546863291, disc_loss = 0.003200759465308779
Trained batch 1498 in epoch 12, gen_loss = 0.8971221319351934, disc_loss = 0.003198778815168505
Trained batch 1499 in epoch 12, gen_loss = 0.8970439511140188, disc_loss = 0.003197434668589267
Trained batch 1500 in epoch 12, gen_loss = 0.8970126686772849, disc_loss = 0.0031958483028516676
Trained batch 1501 in epoch 12, gen_loss = 0.8970272529537923, disc_loss = 0.0031940485686440838
Trained batch 1502 in epoch 12, gen_loss = 0.896998805755468, disc_loss = 0.00319216493484726
Trained batch 1503 in epoch 12, gen_loss = 0.8970717631597468, disc_loss = 0.0031903407993680998
Trained batch 1504 in epoch 12, gen_loss = 0.8969797780743469, disc_loss = 0.003188403595829316
Trained batch 1505 in epoch 12, gen_loss = 0.8969669156815426, disc_loss = 0.0031863867589078144
Trained batch 1506 in epoch 12, gen_loss = 0.8969818813641022, disc_loss = 0.003184448169594281
Trained batch 1507 in epoch 12, gen_loss = 0.8970553706195057, disc_loss = 0.0031825374195969245
Trained batch 1508 in epoch 12, gen_loss = 0.8970182757649381, disc_loss = 0.0031805682839451043
Trained batch 1509 in epoch 12, gen_loss = 0.8970064845306195, disc_loss = 0.0031785758605062274
Trained batch 1510 in epoch 12, gen_loss = 0.8969329661048067, disc_loss = 0.0031765935348791303
Trained batch 1511 in epoch 12, gen_loss = 0.8968892400226895, disc_loss = 0.0031746420745548676
Trained batch 1512 in epoch 12, gen_loss = 0.8968844761221281, disc_loss = 0.003172704767171989
Trained batch 1513 in epoch 12, gen_loss = 0.8968949277775763, disc_loss = 0.0031707458036125203
Trained batch 1514 in epoch 12, gen_loss = 0.8968482441634629, disc_loss = 0.0031688247902175526
Trained batch 1515 in epoch 12, gen_loss = 0.8968714509444375, disc_loss = 0.003166894675310605
Trained batch 1516 in epoch 12, gen_loss = 0.8968416984802653, disc_loss = 0.003164951013577539
Trained batch 1517 in epoch 12, gen_loss = 0.896760953941207, disc_loss = 0.0031631256803101846
Trained batch 1518 in epoch 12, gen_loss = 0.8968105752111816, disc_loss = 0.003161487587272713
Trained batch 1519 in epoch 12, gen_loss = 0.896802517575653, disc_loss = 0.0031595422487618254
Trained batch 1520 in epoch 12, gen_loss = 0.8967954715876733, disc_loss = 0.003157672245241388
Trained batch 1521 in epoch 12, gen_loss = 0.8968361476717734, disc_loss = 0.003155732759130247
Trained batch 1522 in epoch 12, gen_loss = 0.8967890319899361, disc_loss = 0.003153847380832609
Trained batch 1523 in epoch 12, gen_loss = 0.8968279255734967, disc_loss = 0.00315186115726038
Trained batch 1524 in epoch 12, gen_loss = 0.8967763423137978, disc_loss = 0.0031499318706900356
Trained batch 1525 in epoch 12, gen_loss = 0.8967871403866015, disc_loss = 0.003147989241282926
Trained batch 1526 in epoch 12, gen_loss = 0.8968024829594076, disc_loss = 0.0031462092061325274
Trained batch 1527 in epoch 12, gen_loss = 0.89673887735418, disc_loss = 0.0031444855676740313
Trained batch 1528 in epoch 12, gen_loss = 0.8967024887832182, disc_loss = 0.0031427238834384197
Trained batch 1529 in epoch 12, gen_loss = 0.8966059712802663, disc_loss = 0.003140832358189239
Trained batch 1530 in epoch 12, gen_loss = 0.8965692101235019, disc_loss = 0.003138982910722542
Trained batch 1531 in epoch 12, gen_loss = 0.8966301441503879, disc_loss = 0.003137136784817164
Trained batch 1532 in epoch 12, gen_loss = 0.8966814737575006, disc_loss = 0.003135224687188157
Trained batch 1533 in epoch 12, gen_loss = 0.8966503100957833, disc_loss = 0.003133339784524549
Trained batch 1534 in epoch 12, gen_loss = 0.8966287516227375, disc_loss = 0.003131371823909081
Trained batch 1535 in epoch 12, gen_loss = 0.8966888820674891, disc_loss = 0.003129641980531043
Trained batch 1536 in epoch 12, gen_loss = 0.8966450747453941, disc_loss = 0.0031277461837209983
Trained batch 1537 in epoch 12, gen_loss = 0.8965751856216684, disc_loss = 0.0031258096928899835
Trained batch 1538 in epoch 12, gen_loss = 0.8965492630794963, disc_loss = 0.0031238559503216435
Trained batch 1539 in epoch 12, gen_loss = 0.8965524073932079, disc_loss = 0.003122008510541349
Trained batch 1540 in epoch 12, gen_loss = 0.8965937370684609, disc_loss = 0.0031201015084328905
Trained batch 1541 in epoch 12, gen_loss = 0.8965907919035812, disc_loss = 0.0031183531237421883
Trained batch 1542 in epoch 12, gen_loss = 0.8966202460861947, disc_loss = 0.003116460481928076
Trained batch 1543 in epoch 12, gen_loss = 0.8965912535400589, disc_loss = 0.0031146752714443955
Trained batch 1544 in epoch 12, gen_loss = 0.8966180613125798, disc_loss = 0.003112925341918697
Trained batch 1545 in epoch 12, gen_loss = 0.8966332438075373, disc_loss = 0.003111011360543491
Trained batch 1546 in epoch 12, gen_loss = 0.8965972455070338, disc_loss = 0.0031091389775496823
Trained batch 1547 in epoch 12, gen_loss = 0.8966593390826415, disc_loss = 0.003107305822593313
Trained batch 1548 in epoch 12, gen_loss = 0.8967836376079981, disc_loss = 0.0031067116010798533
Trained batch 1549 in epoch 12, gen_loss = 0.8967723456890352, disc_loss = 0.003104933943381653
Trained batch 1550 in epoch 12, gen_loss = 0.8967772263776557, disc_loss = 0.003103456449093565
Trained batch 1551 in epoch 12, gen_loss = 0.8967343122151095, disc_loss = 0.0031018854319460006
Trained batch 1552 in epoch 12, gen_loss = 0.8967961001918152, disc_loss = 0.0031000770533363546
Trained batch 1553 in epoch 12, gen_loss = 0.8967915287425926, disc_loss = 0.0030982073288119637
Trained batch 1554 in epoch 12, gen_loss = 0.8968200361230366, disc_loss = 0.003096819212293354
Trained batch 1555 in epoch 12, gen_loss = 0.8968493351210053, disc_loss = 0.0030951692879030595
Trained batch 1556 in epoch 12, gen_loss = 0.8967593875004837, disc_loss = 0.003095490390839511
Trained batch 1557 in epoch 12, gen_loss = 0.8968528346547113, disc_loss = 0.003094085180121432
Trained batch 1558 in epoch 12, gen_loss = 0.8968583125575679, disc_loss = 0.003093206222762603
Trained batch 1559 in epoch 12, gen_loss = 0.8968256891155855, disc_loss = 0.0030914603090376404
Trained batch 1560 in epoch 12, gen_loss = 0.8967437238207542, disc_loss = 0.0030899716512160463
Trained batch 1561 in epoch 12, gen_loss = 0.8967442343467024, disc_loss = 0.00308830738397048
Trained batch 1562 in epoch 12, gen_loss = 0.8967451240416909, disc_loss = 0.0030866654893509705
Trained batch 1563 in epoch 12, gen_loss = 0.8966956398142573, disc_loss = 0.003085007358927761
Trained batch 1564 in epoch 12, gen_loss = 0.8967072932484051, disc_loss = 0.00308324008121545
Trained batch 1565 in epoch 12, gen_loss = 0.8967176770189561, disc_loss = 0.0030814139058695698
Trained batch 1566 in epoch 12, gen_loss = 0.89666104278674, disc_loss = 0.003079594794244624
Trained batch 1567 in epoch 12, gen_loss = 0.8966380218614121, disc_loss = 0.003077746384071955
Trained batch 1568 in epoch 12, gen_loss = 0.8966580507784151, disc_loss = 0.003076086907912137
Trained batch 1569 in epoch 12, gen_loss = 0.8966516863008973, disc_loss = 0.003074731261622914
Trained batch 1570 in epoch 12, gen_loss = 0.8967556995164809, disc_loss = 0.0030729575174547052
Trained batch 1571 in epoch 12, gen_loss = 0.8967394444323679, disc_loss = 0.0030711463169486833
Trained batch 1572 in epoch 12, gen_loss = 0.8967486998114855, disc_loss = 0.003069317613342612
Trained batch 1573 in epoch 12, gen_loss = 0.8967064199862668, disc_loss = 0.0030676343659578917
Trained batch 1574 in epoch 12, gen_loss = 0.8966688302585056, disc_loss = 0.003065927199343042
Trained batch 1575 in epoch 12, gen_loss = 0.8966157547940458, disc_loss = 0.003064077438411083
Trained batch 1576 in epoch 12, gen_loss = 0.8965561224375636, disc_loss = 0.0030624540109667497
Trained batch 1577 in epoch 12, gen_loss = 0.8965817113490764, disc_loss = 0.0030606448941509073
Trained batch 1578 in epoch 12, gen_loss = 0.8966295414517543, disc_loss = 0.0030588400376006016
Trained batch 1579 in epoch 12, gen_loss = 0.8966284922406643, disc_loss = 0.0030569831732751894
Trained batch 1580 in epoch 12, gen_loss = 0.8966113109516238, disc_loss = 0.0030551341056053814
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.9109007716178894, disc_loss = 0.0001331326348008588
Trained batch 1 in epoch 13, gen_loss = 0.9205853641033173, disc_loss = 0.00013779778237221763
Trained batch 2 in epoch 13, gen_loss = 0.8730217019716898, disc_loss = 0.0001299887201942814
Trained batch 3 in epoch 13, gen_loss = 0.8782209604978561, disc_loss = 0.00017873700744530652
Trained batch 4 in epoch 13, gen_loss = 0.8578804850578308, disc_loss = 0.00022721853019902483
Trained batch 5 in epoch 13, gen_loss = 0.8671563367048899, disc_loss = 0.00022010527633635016
Trained batch 6 in epoch 13, gen_loss = 0.8862845131329128, disc_loss = 0.00022811005328549072
Trained batch 7 in epoch 13, gen_loss = 0.8810406774282455, disc_loss = 0.00022618410457653226
Trained batch 8 in epoch 13, gen_loss = 0.8901411824756198, disc_loss = 0.0002278471503005777
Trained batch 9 in epoch 13, gen_loss = 0.8928771853446961, disc_loss = 0.00022037324160919524
Trained batch 10 in epoch 13, gen_loss = 0.898904410275546, disc_loss = 0.0002256203528800556
Trained batch 11 in epoch 13, gen_loss = 0.8999443898598353, disc_loss = 0.00022142924899526406
Trained batch 12 in epoch 13, gen_loss = 0.8880488368181082, disc_loss = 0.0004061227949792877
Trained batch 13 in epoch 13, gen_loss = 0.88965705037117, disc_loss = 0.0004783233842837425
Trained batch 14 in epoch 13, gen_loss = 0.8956700921058655, disc_loss = 0.0004862965409605143
Trained batch 15 in epoch 13, gen_loss = 0.8923195712268353, disc_loss = 0.0004835402173739567
Trained batch 16 in epoch 13, gen_loss = 0.8901815379367155, disc_loss = 0.0004920175650862374
Trained batch 17 in epoch 13, gen_loss = 0.8839534587330289, disc_loss = 0.00048435641858506843
Trained batch 18 in epoch 13, gen_loss = 0.8808714088640714, disc_loss = 0.0004795232744072564
Trained batch 19 in epoch 13, gen_loss = 0.8828946560621261, disc_loss = 0.0004655592503695516
Trained batch 20 in epoch 13, gen_loss = 0.8774588562193371, disc_loss = 0.00045484319707611576
Trained batch 21 in epoch 13, gen_loss = 0.8758445273746144, disc_loss = 0.0004404453393362928
Trained batch 22 in epoch 13, gen_loss = 0.878802213979804, disc_loss = 0.0004279975290283682
Trained batch 23 in epoch 13, gen_loss = 0.8815119316180547, disc_loss = 0.00042006005818014575
Trained batch 24 in epoch 13, gen_loss = 0.882797327041626, disc_loss = 0.0004101357000763528
Trained batch 25 in epoch 13, gen_loss = 0.8822018779241122, disc_loss = 0.00039757308807635965
Trained batch 26 in epoch 13, gen_loss = 0.8853414345670629, disc_loss = 0.0003867168046848814
Trained batch 27 in epoch 13, gen_loss = 0.8859591739518302, disc_loss = 0.00037567885296344424
Trained batch 28 in epoch 13, gen_loss = 0.8880168528392397, disc_loss = 0.000367608310500208
Trained batch 29 in epoch 13, gen_loss = 0.886856758594513, disc_loss = 0.0003595385290585303
Trained batch 30 in epoch 13, gen_loss = 0.8882126846621113, disc_loss = 0.00035330362222720717
Trained batch 31 in epoch 13, gen_loss = 0.8909737803041935, disc_loss = 0.0003506023665522662
Trained batch 32 in epoch 13, gen_loss = 0.891711155573527, disc_loss = 0.00034844742758926287
Trained batch 33 in epoch 13, gen_loss = 0.8908117290805367, disc_loss = 0.00034298792867476177
Trained batch 34 in epoch 13, gen_loss = 0.8920531749725342, disc_loss = 0.00033911780358591515
Trained batch 35 in epoch 13, gen_loss = 0.8936436027288437, disc_loss = 0.0003315735656441474
Trained batch 36 in epoch 13, gen_loss = 0.889174806105124, disc_loss = 0.00032676427331721614
Trained batch 37 in epoch 13, gen_loss = 0.8905252453527952, disc_loss = 0.00032016830492035585
Trained batch 38 in epoch 13, gen_loss = 0.8897479528035873, disc_loss = 0.00031455277199618134
Trained batch 39 in epoch 13, gen_loss = 0.8901658922433853, disc_loss = 0.00030930177090340296
Trained batch 40 in epoch 13, gen_loss = 0.8917365481213826, disc_loss = 0.0003045790281470456
Trained batch 41 in epoch 13, gen_loss = 0.8914794992832911, disc_loss = 0.00030040247656870633
Trained batch 42 in epoch 13, gen_loss = 0.8876947330874067, disc_loss = 0.0003001643507199925
Trained batch 43 in epoch 13, gen_loss = 0.8860483535311439, disc_loss = 0.00030230971341635183
Trained batch 44 in epoch 13, gen_loss = 0.8838999695248074, disc_loss = 0.00029719316905053953
Trained batch 45 in epoch 13, gen_loss = 0.8842115635457246, disc_loss = 0.00029260849861083955
Trained batch 46 in epoch 13, gen_loss = 0.8843102581957554, disc_loss = 0.00028857553146774585
Trained batch 47 in epoch 13, gen_loss = 0.8801000018914541, disc_loss = 0.00029117442788143916
Trained batch 48 in epoch 13, gen_loss = 0.8789228590167298, disc_loss = 0.00028947904531972257
Trained batch 49 in epoch 13, gen_loss = 0.878799957036972, disc_loss = 0.00028623273145058194
Trained batch 50 in epoch 13, gen_loss = 0.8770600136588601, disc_loss = 0.0002830079923596178
Trained batch 51 in epoch 13, gen_loss = 0.8796139451173636, disc_loss = 0.00029561079127933434
Trained batch 52 in epoch 13, gen_loss = 0.8779096817070583, disc_loss = 0.0002956915481229102
Trained batch 53 in epoch 13, gen_loss = 0.8779323641900663, disc_loss = 0.00029259365328471176
Trained batch 54 in epoch 13, gen_loss = 0.878161947293715, disc_loss = 0.00029542177653638644
Trained batch 55 in epoch 13, gen_loss = 0.8765940070152283, disc_loss = 0.00029436162796108486
Trained batch 56 in epoch 13, gen_loss = 0.8772347381240443, disc_loss = 0.00029778997110010925
Trained batch 57 in epoch 13, gen_loss = 0.8783456847585481, disc_loss = 0.0003001498022560303
Trained batch 58 in epoch 13, gen_loss = 0.877917477640055, disc_loss = 0.0003027023084834613
Trained batch 59 in epoch 13, gen_loss = 0.8778026580810547, disc_loss = 0.0003094236789668988
Trained batch 60 in epoch 13, gen_loss = 0.8772934274595292, disc_loss = 0.00033763141075977447
Trained batch 61 in epoch 13, gen_loss = 0.877016733730993, disc_loss = 0.00037699644869257273
Trained batch 62 in epoch 13, gen_loss = 0.8782206139867268, disc_loss = 0.00038991717306161597
Trained batch 63 in epoch 13, gen_loss = 0.8813720596954226, disc_loss = 0.00039417493610471865
Trained batch 64 in epoch 13, gen_loss = 0.8808052319746751, disc_loss = 0.00039831841277191413
Trained batch 65 in epoch 13, gen_loss = 0.8806346745202036, disc_loss = 0.00039928293997284277
Trained batch 66 in epoch 13, gen_loss = 0.8820664793697756, disc_loss = 0.00040267185369287546
Trained batch 67 in epoch 13, gen_loss = 0.8815589310491786, disc_loss = 0.0004008680969170254
Trained batch 68 in epoch 13, gen_loss = 0.8821942434794661, disc_loss = 0.00039779238347588375
Trained batch 69 in epoch 13, gen_loss = 0.880451625585556, disc_loss = 0.0003973068308758749
Trained batch 70 in epoch 13, gen_loss = 0.8792069302478307, disc_loss = 0.00039569163519944864
Trained batch 71 in epoch 13, gen_loss = 0.8786252323124144, disc_loss = 0.00039211277756597457
Trained batch 72 in epoch 13, gen_loss = 0.8778886517433271, disc_loss = 0.00038935109199110854
Trained batch 73 in epoch 13, gen_loss = 0.8774796708210094, disc_loss = 0.00038651907350474693
Trained batch 74 in epoch 13, gen_loss = 0.8776666069030762, disc_loss = 0.0003839635529827016
Trained batch 75 in epoch 13, gen_loss = 0.8761310561707145, disc_loss = 0.0003838390884515033
Trained batch 76 in epoch 13, gen_loss = 0.8758924146751305, disc_loss = 0.0003811525502778868
Trained batch 77 in epoch 13, gen_loss = 0.8761284955036945, disc_loss = 0.00037775624374402326
Trained batch 78 in epoch 13, gen_loss = 0.8753799886643132, disc_loss = 0.00038154284671299704
Trained batch 79 in epoch 13, gen_loss = 0.8748841270804405, disc_loss = 0.00037898186265010735
Trained batch 80 in epoch 13, gen_loss = 0.8756142994503916, disc_loss = 0.00037709655005550933
Trained batch 81 in epoch 13, gen_loss = 0.8780432248987803, disc_loss = 0.00038426759233627263
Trained batch 82 in epoch 13, gen_loss = 0.876986652253622, disc_loss = 0.0003859553823958667
Trained batch 83 in epoch 13, gen_loss = 0.8772378443252473, disc_loss = 0.0003926587083004138
Trained batch 84 in epoch 13, gen_loss = 0.8776583636508268, disc_loss = 0.0003914573304320905
Trained batch 85 in epoch 13, gen_loss = 0.8773982642694961, disc_loss = 0.00039289552144107926
Trained batch 86 in epoch 13, gen_loss = 0.8775053037994209, disc_loss = 0.0003911086889860306
Trained batch 87 in epoch 13, gen_loss = 0.8785269233313474, disc_loss = 0.00039064350684467087
Trained batch 88 in epoch 13, gen_loss = 0.8781348774942119, disc_loss = 0.00038843031286254126
Trained batch 89 in epoch 13, gen_loss = 0.8773423870404561, disc_loss = 0.00038620188578432943
Trained batch 90 in epoch 13, gen_loss = 0.8770788567406791, disc_loss = 0.00038323598870032745
Trained batch 91 in epoch 13, gen_loss = 0.8767166785571886, disc_loss = 0.000381335631849968
Trained batch 92 in epoch 13, gen_loss = 0.8766543044838854, disc_loss = 0.00037968237294442453
Trained batch 93 in epoch 13, gen_loss = 0.8762574183179977, disc_loss = 0.0003765011604898857
Trained batch 94 in epoch 13, gen_loss = 0.877150098901046, disc_loss = 0.0003740328648219522
Trained batch 95 in epoch 13, gen_loss = 0.876668356359005, disc_loss = 0.00037118967035591294
Trained batch 96 in epoch 13, gen_loss = 0.8764898199396035, disc_loss = 0.0003684984844720433
Trained batch 97 in epoch 13, gen_loss = 0.8768618155498894, disc_loss = 0.00036603099891051116
Trained batch 98 in epoch 13, gen_loss = 0.8761592284597531, disc_loss = 0.00036328972459563776
Trained batch 99 in epoch 13, gen_loss = 0.8777325785160065, disc_loss = 0.00036227470380254087
Trained batch 100 in epoch 13, gen_loss = 0.8775919097484929, disc_loss = 0.0003643635761841099
Trained batch 101 in epoch 13, gen_loss = 0.8773473699887594, disc_loss = 0.0003623142684398986
Trained batch 102 in epoch 13, gen_loss = 0.8785237866697959, disc_loss = 0.00036079682651635946
Trained batch 103 in epoch 13, gen_loss = 0.8771658132855709, disc_loss = 0.00036085846099572687
Trained batch 104 in epoch 13, gen_loss = 0.8782438147635687, disc_loss = 0.00036185080673368207
Trained batch 105 in epoch 13, gen_loss = 0.8774149693408102, disc_loss = 0.0003596619306953694
Trained batch 106 in epoch 13, gen_loss = 0.8781828540507878, disc_loss = 0.00035747306660213724
Trained batch 107 in epoch 13, gen_loss = 0.8765516132116318, disc_loss = 0.00036697927633347853
Trained batch 108 in epoch 13, gen_loss = 0.8765291648173551, disc_loss = 0.00036505317871369115
Trained batch 109 in epoch 13, gen_loss = 0.8756814208897677, disc_loss = 0.0003632492309076373
Trained batch 110 in epoch 13, gen_loss = 0.8758668749182074, disc_loss = 0.0003616948263837142
Trained batch 111 in epoch 13, gen_loss = 0.8761060786034379, disc_loss = 0.0003645353956796628
Trained batch 112 in epoch 13, gen_loss = 0.8762677665305348, disc_loss = 0.00036249362783242773
Trained batch 113 in epoch 13, gen_loss = 0.8754428578050513, disc_loss = 0.0003645033396886694
Trained batch 114 in epoch 13, gen_loss = 0.8752698323001032, disc_loss = 0.0003624807424468758
Trained batch 115 in epoch 13, gen_loss = 0.8756990432739258, disc_loss = 0.00036018246063231974
Trained batch 116 in epoch 13, gen_loss = 0.8762758195909679, disc_loss = 0.0003579865487364049
Trained batch 117 in epoch 13, gen_loss = 0.8760559584124613, disc_loss = 0.0003564928142083572
Trained batch 118 in epoch 13, gen_loss = 0.8764590941557363, disc_loss = 0.00035636171396770866
Trained batch 119 in epoch 13, gen_loss = 0.8766069004933039, disc_loss = 0.00035428308310656573
Trained batch 120 in epoch 13, gen_loss = 0.8759808629012305, disc_loss = 0.00035223859348594143
Trained batch 121 in epoch 13, gen_loss = 0.8761368266871719, disc_loss = 0.00035110993002356245
Trained batch 122 in epoch 13, gen_loss = 0.8759373329519257, disc_loss = 0.0003523272577539745
Trained batch 123 in epoch 13, gen_loss = 0.8763205452311423, disc_loss = 0.000351058502224811
Trained batch 124 in epoch 13, gen_loss = 0.8764300694465638, disc_loss = 0.0003501011622720398
Trained batch 125 in epoch 13, gen_loss = 0.8771387783307878, disc_loss = 0.000348986245842839
Trained batch 126 in epoch 13, gen_loss = 0.8773834968176414, disc_loss = 0.0003479869888319018
Trained batch 127 in epoch 13, gen_loss = 0.8775084456428885, disc_loss = 0.00034857901647455947
Trained batch 128 in epoch 13, gen_loss = 0.8772701810496722, disc_loss = 0.0003472953977161665
Trained batch 129 in epoch 13, gen_loss = 0.8784123915892381, disc_loss = 0.0003458893466673684
Trained batch 130 in epoch 13, gen_loss = 0.8783937410543893, disc_loss = 0.00034474572221231326
Trained batch 131 in epoch 13, gen_loss = 0.8781479759649797, disc_loss = 0.00034319262775887074
Trained batch 132 in epoch 13, gen_loss = 0.8772773316928318, disc_loss = 0.00034207099536827704
Trained batch 133 in epoch 13, gen_loss = 0.8780020880165385, disc_loss = 0.00034120549981477114
Trained batch 134 in epoch 13, gen_loss = 0.8777603317190099, disc_loss = 0.0003404725687384295
Trained batch 135 in epoch 13, gen_loss = 0.8783746519509483, disc_loss = 0.00033951311680164724
Trained batch 136 in epoch 13, gen_loss = 0.8790969961751116, disc_loss = 0.00033881662977072513
Trained batch 137 in epoch 13, gen_loss = 0.8794968568760416, disc_loss = 0.00033713693588599227
Trained batch 138 in epoch 13, gen_loss = 0.8788025623602833, disc_loss = 0.000335677581068326
Trained batch 139 in epoch 13, gen_loss = 0.8791885984795434, disc_loss = 0.0003352081849568224
Trained batch 140 in epoch 13, gen_loss = 0.8789623219070705, disc_loss = 0.00033372493537352585
Trained batch 141 in epoch 13, gen_loss = 0.8777110929220495, disc_loss = 0.0008224975142991138
Trained batch 142 in epoch 13, gen_loss = 0.8744234882451437, disc_loss = 0.004939263525906986
Trained batch 143 in epoch 13, gen_loss = 0.8737456403258774, disc_loss = 0.006088863652975205
Trained batch 144 in epoch 13, gen_loss = 0.8740728051498019, disc_loss = 0.006717439775168494
Trained batch 145 in epoch 13, gen_loss = 0.8727788323000686, disc_loss = 0.007121734993047103
Trained batch 146 in epoch 13, gen_loss = 0.8723834236057437, disc_loss = 0.00725729853051618
Trained batch 147 in epoch 13, gen_loss = 0.871835232787841, disc_loss = 0.007308468457562708
Trained batch 148 in epoch 13, gen_loss = 0.8708929001484942, disc_loss = 0.007341452613822575
Trained batch 149 in epoch 13, gen_loss = 0.8709102449814479, disc_loss = 0.007319276328732182
Trained batch 150 in epoch 13, gen_loss = 0.8715582570887559, disc_loss = 0.007329849960097028
Trained batch 151 in epoch 13, gen_loss = 0.8718888251797149, disc_loss = 0.0073036701779098
Trained batch 152 in epoch 13, gen_loss = 0.8719251083782296, disc_loss = 0.00727587719530657
Trained batch 153 in epoch 13, gen_loss = 0.8727319118651476, disc_loss = 0.007257489775307099
Trained batch 154 in epoch 13, gen_loss = 0.8731431424617767, disc_loss = 0.00725490349666929
Trained batch 155 in epoch 13, gen_loss = 0.8732376432953737, disc_loss = 0.007234689406966656
Trained batch 156 in epoch 13, gen_loss = 0.8739112180889033, disc_loss = 0.007207181231053116
Trained batch 157 in epoch 13, gen_loss = 0.8737238854924335, disc_loss = 0.007186039988033671
Trained batch 158 in epoch 13, gen_loss = 0.8740083505897402, disc_loss = 0.007229806352090076
Trained batch 159 in epoch 13, gen_loss = 0.8746460841968655, disc_loss = 0.00720325477791448
Trained batch 160 in epoch 13, gen_loss = 0.8749737082431035, disc_loss = 0.007166503292068431
Trained batch 161 in epoch 13, gen_loss = 0.8751028273944501, disc_loss = 0.007126271145633511
Trained batch 162 in epoch 13, gen_loss = 0.8755166689676741, disc_loss = 0.007087068230281884
Trained batch 163 in epoch 13, gen_loss = 0.8761109911450525, disc_loss = 0.007049500860730626
Trained batch 164 in epoch 13, gen_loss = 0.8755848044698888, disc_loss = 0.007012754328906973
Trained batch 165 in epoch 13, gen_loss = 0.8756176507975681, disc_loss = 0.0069771781691307265
Trained batch 166 in epoch 13, gen_loss = 0.8759781402385164, disc_loss = 0.006957643983380599
Trained batch 167 in epoch 13, gen_loss = 0.8760962179374128, disc_loss = 0.006925520095050854
Trained batch 168 in epoch 13, gen_loss = 0.8765994784747355, disc_loss = 0.006893940245277681
Trained batch 169 in epoch 13, gen_loss = 0.8764602477059645, disc_loss = 0.006859943183842594
Trained batch 170 in epoch 13, gen_loss = 0.8763942385626118, disc_loss = 0.00683108628781108
Trained batch 171 in epoch 13, gen_loss = 0.8767512574098831, disc_loss = 0.006797719661673994
Trained batch 172 in epoch 13, gen_loss = 0.8768189416799931, disc_loss = 0.006785621216668373
Trained batch 173 in epoch 13, gen_loss = 0.8770733840506653, disc_loss = 0.00676017297289151
Trained batch 174 in epoch 13, gen_loss = 0.877740443944931, disc_loss = 0.00672611446198841
Trained batch 175 in epoch 13, gen_loss = 0.87687541493638, disc_loss = 0.006752136094085224
Trained batch 176 in epoch 13, gen_loss = 0.8781438959857165, disc_loss = 0.00673891961163319
Trained batch 177 in epoch 13, gen_loss = 0.878661751244845, disc_loss = 0.006712073161457391
Trained batch 178 in epoch 13, gen_loss = 0.8792696007470179, disc_loss = 0.006684384790147387
Trained batch 179 in epoch 13, gen_loss = 0.8794416538543172, disc_loss = 0.00665225287516983
Trained batch 180 in epoch 13, gen_loss = 0.8792855793929232, disc_loss = 0.006635825957346242
Trained batch 181 in epoch 13, gen_loss = 0.8799116868566681, disc_loss = 0.0066050682573084805
Trained batch 182 in epoch 13, gen_loss = 0.8802203654917211, disc_loss = 0.006577244161841615
Trained batch 183 in epoch 13, gen_loss = 0.8804300244411697, disc_loss = 0.006544708804935711
Trained batch 184 in epoch 13, gen_loss = 0.8811062534113188, disc_loss = 0.00651320003714834
Trained batch 185 in epoch 13, gen_loss = 0.8807692888282961, disc_loss = 0.006481360913351646
Trained batch 186 in epoch 13, gen_loss = 0.8806393906713169, disc_loss = 0.006453841363873898
Trained batch 187 in epoch 13, gen_loss = 0.8802307737951583, disc_loss = 0.006451687581849252
Trained batch 188 in epoch 13, gen_loss = 0.8801912279040726, disc_loss = 0.0064234025605074034
Trained batch 189 in epoch 13, gen_loss = 0.8800550305529644, disc_loss = 0.006458779858344075
Trained batch 190 in epoch 13, gen_loss = 0.8805096569173623, disc_loss = 0.006433948342490598
Trained batch 191 in epoch 13, gen_loss = 0.8808690931958457, disc_loss = 0.006675538291157561
Trained batch 192 in epoch 13, gen_loss = 0.8811359302058739, disc_loss = 0.006706954066397639
Trained batch 193 in epoch 13, gen_loss = 0.880882294982979, disc_loss = 0.006725410335046448
Trained batch 194 in epoch 13, gen_loss = 0.8811844078394083, disc_loss = 0.006713339724116779
Trained batch 195 in epoch 13, gen_loss = 0.8805134051612445, disc_loss = 0.00672516189182233
Trained batch 196 in epoch 13, gen_loss = 0.8783950330642274, disc_loss = 0.008745244240409253
Trained batch 197 in epoch 13, gen_loss = 0.8799091706974338, disc_loss = 0.00937865983477689
Trained batch 198 in epoch 13, gen_loss = 0.8805848854271012, disc_loss = 0.009731161276610677
Trained batch 199 in epoch 13, gen_loss = 0.880678557753563, disc_loss = 0.00977158646517637
Trained batch 200 in epoch 13, gen_loss = 0.8804176722592976, disc_loss = 0.009757998120959151
Trained batch 201 in epoch 13, gen_loss = 0.8806024196714458, disc_loss = 0.009754249124808207
Trained batch 202 in epoch 13, gen_loss = 0.8804167899592169, disc_loss = 0.009728920429919472
Trained batch 203 in epoch 13, gen_loss = 0.8805313519403046, disc_loss = 0.00970061426917656
Trained batch 204 in epoch 13, gen_loss = 0.8803273311475428, disc_loss = 0.00967713319309618
Trained batch 205 in epoch 13, gen_loss = 0.8804665682385269, disc_loss = 0.009635549799975142
Trained batch 206 in epoch 13, gen_loss = 0.880642863287442, disc_loss = 0.009599267956816225
Trained batch 207 in epoch 13, gen_loss = 0.8813476390563525, disc_loss = 0.009563212762714102
Trained batch 208 in epoch 13, gen_loss = 0.881501371780651, disc_loss = 0.009524043264644807
Trained batch 209 in epoch 13, gen_loss = 0.8806857631320045, disc_loss = 0.009554222472936436
Trained batch 210 in epoch 13, gen_loss = 0.8804514978734238, disc_loss = 0.009517712498813927
Trained batch 211 in epoch 13, gen_loss = 0.8801167567945877, disc_loss = 0.009494870477283257
Trained batch 212 in epoch 13, gen_loss = 0.8803110452884799, disc_loss = 0.009456314131317763
Trained batch 213 in epoch 13, gen_loss = 0.8804718228144066, disc_loss = 0.00943633809556644
Trained batch 214 in epoch 13, gen_loss = 0.8812381195467572, disc_loss = 0.009403222981335455
Trained batch 215 in epoch 13, gen_loss = 0.8824107084009383, disc_loss = 0.00936954165495586
Trained batch 216 in epoch 13, gen_loss = 0.8831266466923023, disc_loss = 0.009333643891781833
Trained batch 217 in epoch 13, gen_loss = 0.8831818174878392, disc_loss = 0.00929720488060111
Trained batch 218 in epoch 13, gen_loss = 0.8834061442989193, disc_loss = 0.00925736825606338
Trained batch 219 in epoch 13, gen_loss = 0.8833093599839644, disc_loss = 0.00921847702606597
Trained batch 220 in epoch 13, gen_loss = 0.8837162159147306, disc_loss = 0.009179090373938412
Trained batch 221 in epoch 13, gen_loss = 0.8839403095546069, disc_loss = 0.009139189036841754
Trained batch 222 in epoch 13, gen_loss = 0.8844145581861248, disc_loss = 0.0091031417288155
Trained batch 223 in epoch 13, gen_loss = 0.8842219313872712, disc_loss = 0.009066513080889698
Trained batch 224 in epoch 13, gen_loss = 0.8841510396533542, disc_loss = 0.009028506484755781
Trained batch 225 in epoch 13, gen_loss = 0.884382223660967, disc_loss = 0.008990829442549173
Trained batch 226 in epoch 13, gen_loss = 0.8845433469385827, disc_loss = 0.008953930518126048
Trained batch 227 in epoch 13, gen_loss = 0.8845194214791582, disc_loss = 0.008917074027442396
Trained batch 228 in epoch 13, gen_loss = 0.8846347646942305, disc_loss = 0.008880453427086073
Trained batch 229 in epoch 13, gen_loss = 0.8848251591558042, disc_loss = 0.008843224698711825
Trained batch 230 in epoch 13, gen_loss = 0.8852919247243312, disc_loss = 0.008806896406407035
Trained batch 231 in epoch 13, gen_loss = 0.8851771251908664, disc_loss = 0.008772433299217765
Trained batch 232 in epoch 13, gen_loss = 0.8849149464026029, disc_loss = 0.008739017306215204
Trained batch 233 in epoch 13, gen_loss = 0.8851971083726639, disc_loss = 0.008703323214435024
Trained batch 234 in epoch 13, gen_loss = 0.8855720852283722, disc_loss = 0.008669348677311915
Trained batch 235 in epoch 13, gen_loss = 0.88538136068037, disc_loss = 0.008634635330501192
Trained batch 236 in epoch 13, gen_loss = 0.8852258229054479, disc_loss = 0.00860039471365086
Trained batch 237 in epoch 13, gen_loss = 0.8856361215355015, disc_loss = 0.008566359789378525
Trained batch 238 in epoch 13, gen_loss = 0.8857025925584417, disc_loss = 0.008531797872207208
Trained batch 239 in epoch 13, gen_loss = 0.8858498439192772, disc_loss = 0.00849790021247827
Trained batch 240 in epoch 13, gen_loss = 0.885492853603917, disc_loss = 0.008465593222655981
Trained batch 241 in epoch 13, gen_loss = 0.8856280889392885, disc_loss = 0.008432636298050416
Trained batch 242 in epoch 13, gen_loss = 0.8855693102373507, disc_loss = 0.00839964568481657
Trained batch 243 in epoch 13, gen_loss = 0.8851036128939175, disc_loss = 0.008366657840702292
Trained batch 244 in epoch 13, gen_loss = 0.8846659134845345, disc_loss = 0.00833535791830307
Trained batch 245 in epoch 13, gen_loss = 0.8848696336513613, disc_loss = 0.008308419949327532
Trained batch 246 in epoch 13, gen_loss = 0.8848441687190098, disc_loss = 0.008276989354382256
Trained batch 247 in epoch 13, gen_loss = 0.8845478380399365, disc_loss = 0.00824595757110787
Trained batch 248 in epoch 13, gen_loss = 0.8846992706678, disc_loss = 0.008215280883073812
Trained batch 249 in epoch 13, gen_loss = 0.8849520621299743, disc_loss = 0.008183737514162204
Trained batch 250 in epoch 13, gen_loss = 0.8846150130864634, disc_loss = 0.008155789558001862
Trained batch 251 in epoch 13, gen_loss = 0.8844060098368024, disc_loss = 0.00812672512588578
Trained batch 252 in epoch 13, gen_loss = 0.8841995080940337, disc_loss = 0.008097833805258999
Trained batch 253 in epoch 13, gen_loss = 0.884548661746378, disc_loss = 0.008069566480432019
Trained batch 254 in epoch 13, gen_loss = 0.884747704337625, disc_loss = 0.008041645400768247
Trained batch 255 in epoch 13, gen_loss = 0.8845904925838113, disc_loss = 0.00801357036161221
Trained batch 256 in epoch 13, gen_loss = 0.8852737831234468, disc_loss = 0.007984109242678419
Trained batch 257 in epoch 13, gen_loss = 0.8853288997513379, disc_loss = 0.007954875314413063
Trained batch 258 in epoch 13, gen_loss = 0.8848579650219803, disc_loss = 0.007925421429988361
Trained batch 259 in epoch 13, gen_loss = 0.8844083916682464, disc_loss = 0.007897063095627415
Trained batch 260 in epoch 13, gen_loss = 0.8843830216433354, disc_loss = 0.007869605894571382
Trained batch 261 in epoch 13, gen_loss = 0.884692017358678, disc_loss = 0.00784047301725919
Trained batch 262 in epoch 13, gen_loss = 0.8850660337694698, disc_loss = 0.0078119752491116546
Trained batch 263 in epoch 13, gen_loss = 0.8848752162673257, disc_loss = 0.007782893572766625
Trained batch 264 in epoch 13, gen_loss = 0.88508618710176, disc_loss = 0.007754505734439316
Trained batch 265 in epoch 13, gen_loss = 0.8848600889507093, disc_loss = 0.00772618452631155
Trained batch 266 in epoch 13, gen_loss = 0.8847211809194043, disc_loss = 0.00769870986812421
Trained batch 267 in epoch 13, gen_loss = 0.8844366647414307, disc_loss = 0.00767134167947359
Trained batch 268 in epoch 13, gen_loss = 0.8844864496954312, disc_loss = 0.007645067920525114
Trained batch 269 in epoch 13, gen_loss = 0.8846975273556179, disc_loss = 0.00761940145190844
Trained batch 270 in epoch 13, gen_loss = 0.884480125349826, disc_loss = 0.0075936265527607955
Trained batch 271 in epoch 13, gen_loss = 0.8842793521197403, disc_loss = 0.007567318665812362
Trained batch 272 in epoch 13, gen_loss = 0.8840610908937978, disc_loss = 0.007540497057581868
Trained batch 273 in epoch 13, gen_loss = 0.8838262259960175, disc_loss = 0.007515698111278089
Trained batch 274 in epoch 13, gen_loss = 0.8839801079576666, disc_loss = 0.007489533813971899
Trained batch 275 in epoch 13, gen_loss = 0.8841070288765258, disc_loss = 0.007465227687503827
Trained batch 276 in epoch 13, gen_loss = 0.8840306870343453, disc_loss = 0.007440891207557462
Trained batch 277 in epoch 13, gen_loss = 0.8842588039182073, disc_loss = 0.007415550939866263
Trained batch 278 in epoch 13, gen_loss = 0.8843141428885921, disc_loss = 0.007390371978531824
Trained batch 279 in epoch 13, gen_loss = 0.8841226396816118, disc_loss = 0.007365664172773125
Trained batch 280 in epoch 13, gen_loss = 0.8842091740662517, disc_loss = 0.00734087156274897
Trained batch 281 in epoch 13, gen_loss = 0.8844716381942127, disc_loss = 0.0073161112358069115
Trained batch 282 in epoch 13, gen_loss = 0.8842880159300545, disc_loss = 0.007291607237685276
Trained batch 283 in epoch 13, gen_loss = 0.8843507269318674, disc_loss = 0.0072672257739585305
Trained batch 284 in epoch 13, gen_loss = 0.8843618365756253, disc_loss = 0.0072442664497525825
Trained batch 285 in epoch 13, gen_loss = 0.8845543373714794, disc_loss = 0.0072209251423252805
Trained batch 286 in epoch 13, gen_loss = 0.8847771093820446, disc_loss = 0.00719709064386471
Trained batch 287 in epoch 13, gen_loss = 0.8846101429727342, disc_loss = 0.007173543576275026
Trained batch 288 in epoch 13, gen_loss = 0.8845967394670401, disc_loss = 0.0071495472302527015
Trained batch 289 in epoch 13, gen_loss = 0.8848140996077966, disc_loss = 0.007126030007277913
Trained batch 290 in epoch 13, gen_loss = 0.885378063339548, disc_loss = 0.0071030950104576515
Trained batch 291 in epoch 13, gen_loss = 0.8854260005771297, disc_loss = 0.007079970842823968
Trained batch 292 in epoch 13, gen_loss = 0.8858308997577368, disc_loss = 0.007056774835682548
Trained batch 293 in epoch 13, gen_loss = 0.8856447896584362, disc_loss = 0.007034611171647015
Trained batch 294 in epoch 13, gen_loss = 0.8855642504611257, disc_loss = 0.007011739898722627
Trained batch 295 in epoch 13, gen_loss = 0.8857908788565043, disc_loss = 0.006989287785251469
Trained batch 296 in epoch 13, gen_loss = 0.8860274810180921, disc_loss = 0.006966774015608424
Trained batch 297 in epoch 13, gen_loss = 0.8859738285509532, disc_loss = 0.006944559413855528
Trained batch 298 in epoch 13, gen_loss = 0.8859672034065859, disc_loss = 0.006922327789165941
Trained batch 299 in epoch 13, gen_loss = 0.8859689531723658, disc_loss = 0.006900503856619859
Trained batch 300 in epoch 13, gen_loss = 0.8856991559168033, disc_loss = 0.006878092687357909
Trained batch 301 in epoch 13, gen_loss = 0.8854232414668759, disc_loss = 0.006856082235807005
Trained batch 302 in epoch 13, gen_loss = 0.8853365538930735, disc_loss = 0.0068351773017290875
Trained batch 303 in epoch 13, gen_loss = 0.884979250203622, disc_loss = 0.006813750833340524
Trained batch 304 in epoch 13, gen_loss = 0.8850394428753462, disc_loss = 0.006792991778543257
Trained batch 305 in epoch 13, gen_loss = 0.8849217285907346, disc_loss = 0.006771785440422736
Trained batch 306 in epoch 13, gen_loss = 0.8855460371567294, disc_loss = 0.006751214233626185
Trained batch 307 in epoch 13, gen_loss = 0.8855687857835324, disc_loss = 0.006730467515099717
Trained batch 308 in epoch 13, gen_loss = 0.8853935236683941, disc_loss = 0.006710268836360143
Trained batch 309 in epoch 13, gen_loss = 0.8854586184024811, disc_loss = 0.006689391378055124
Trained batch 310 in epoch 13, gen_loss = 0.8855802780945584, disc_loss = 0.006669285335119288
Trained batch 311 in epoch 13, gen_loss = 0.8856274638420496, disc_loss = 0.006648728528302737
Trained batch 312 in epoch 13, gen_loss = 0.8856809283978642, disc_loss = 0.006628608239425782
Trained batch 313 in epoch 13, gen_loss = 0.8858547077816763, disc_loss = 0.006608568597515447
Trained batch 314 in epoch 13, gen_loss = 0.8858004439444769, disc_loss = 0.006588237433272067
Trained batch 315 in epoch 13, gen_loss = 0.8862398038559323, disc_loss = 0.0065686367936364206
Trained batch 316 in epoch 13, gen_loss = 0.8858836443642336, disc_loss = 0.006549047927895659
Trained batch 317 in epoch 13, gen_loss = 0.8857159157219173, disc_loss = 0.006530388071853924
Trained batch 318 in epoch 13, gen_loss = 0.8854183945162543, disc_loss = 0.006510848291290356
Trained batch 319 in epoch 13, gen_loss = 0.8852468363940715, disc_loss = 0.006491169197192903
Trained batch 320 in epoch 13, gen_loss = 0.8856640519382798, disc_loss = 0.0064744757739469815
Trained batch 321 in epoch 13, gen_loss = 0.8855260058959818, disc_loss = 0.00645572110962738
Trained batch 322 in epoch 13, gen_loss = 0.8854231253127933, disc_loss = 0.006436906932814778
Trained batch 323 in epoch 13, gen_loss = 0.8855132295025719, disc_loss = 0.00641787297271223
Trained batch 324 in epoch 13, gen_loss = 0.8858267952845646, disc_loss = 0.006399370078870561
Trained batch 325 in epoch 13, gen_loss = 0.8856309272028917, disc_loss = 0.006380721380478993
Trained batch 326 in epoch 13, gen_loss = 0.8854474963033601, disc_loss = 0.006362019439592967
Trained batch 327 in epoch 13, gen_loss = 0.8854028311807934, disc_loss = 0.006343572925066926
Trained batch 328 in epoch 13, gen_loss = 0.8850716712989344, disc_loss = 0.0063250902153565375
Trained batch 329 in epoch 13, gen_loss = 0.8849485742323326, disc_loss = 0.006307140886091281
Trained batch 330 in epoch 13, gen_loss = 0.884911376183847, disc_loss = 0.006288820396688678
Trained batch 331 in epoch 13, gen_loss = 0.8843624731862402, disc_loss = 0.006271049225644499
Trained batch 332 in epoch 13, gen_loss = 0.884394121420634, disc_loss = 0.0062531473162238255
Trained batch 333 in epoch 13, gen_loss = 0.8845046944247035, disc_loss = 0.0062351157390301655
Trained batch 334 in epoch 13, gen_loss = 0.8844091173428208, disc_loss = 0.006217320697141443
Trained batch 335 in epoch 13, gen_loss = 0.8842060812527225, disc_loss = 0.0061998491341044085
Trained batch 336 in epoch 13, gen_loss = 0.8840233071621518, disc_loss = 0.006182271753397572
Trained batch 337 in epoch 13, gen_loss = 0.8842276400010262, disc_loss = 0.006164640224919849
Trained batch 338 in epoch 13, gen_loss = 0.8842325797826491, disc_loss = 0.0061474109663166845
Trained batch 339 in epoch 13, gen_loss = 0.8841970995945089, disc_loss = 0.006130382548080353
Trained batch 340 in epoch 13, gen_loss = 0.8841828924120346, disc_loss = 0.006112806807048353
Trained batch 341 in epoch 13, gen_loss = 0.8842651420517972, disc_loss = 0.006097028824492741
Trained batch 342 in epoch 13, gen_loss = 0.8844717129326423, disc_loss = 0.006079843289202042
Trained batch 343 in epoch 13, gen_loss = 0.884276207796363, disc_loss = 0.006063502120669846
Trained batch 344 in epoch 13, gen_loss = 0.8845219318417535, disc_loss = 0.006046692679650522
Trained batch 345 in epoch 13, gen_loss = 0.8846401758276659, disc_loss = 0.006030657695764655
Trained batch 346 in epoch 13, gen_loss = 0.8848051770619769, disc_loss = 0.00601421177365179
Trained batch 347 in epoch 13, gen_loss = 0.884750824207547, disc_loss = 0.005997975354388807
Trained batch 348 in epoch 13, gen_loss = 0.885110194498625, disc_loss = 0.00598201026056675
Trained batch 349 in epoch 13, gen_loss = 0.8851770939145769, disc_loss = 0.00596607596033469
Trained batch 350 in epoch 13, gen_loss = 0.8853819609707237, disc_loss = 0.005950205889584376
Trained batch 351 in epoch 13, gen_loss = 0.8852722235023975, disc_loss = 0.005934442753662303
Trained batch 352 in epoch 13, gen_loss = 0.8849351093721795, disc_loss = 0.005918391350437933
Trained batch 353 in epoch 13, gen_loss = 0.885025891375407, disc_loss = 0.005902626317233343
Trained batch 354 in epoch 13, gen_loss = 0.8850346835566238, disc_loss = 0.0058866862418141515
Trained batch 355 in epoch 13, gen_loss = 0.8853102123804306, disc_loss = 0.005871279769932055
Trained batch 356 in epoch 13, gen_loss = 0.8853310511893585, disc_loss = 0.005856751797880412
Trained batch 357 in epoch 13, gen_loss = 0.8856050217284837, disc_loss = 0.005841091013992011
Trained batch 358 in epoch 13, gen_loss = 0.8857153293814167, disc_loss = 0.005826461878516822
Trained batch 359 in epoch 13, gen_loss = 0.8860913410782814, disc_loss = 0.005811313891313653
Trained batch 360 in epoch 13, gen_loss = 0.8861254088766357, disc_loss = 0.005796229137442948
Trained batch 361 in epoch 13, gen_loss = 0.8862237192649209, disc_loss = 0.00578112298834896
Trained batch 362 in epoch 13, gen_loss = 0.8859309759350191, disc_loss = 0.00576615344940094
Trained batch 363 in epoch 13, gen_loss = 0.8858744423468035, disc_loss = 0.005751124312595054
Trained batch 364 in epoch 13, gen_loss = 0.8859199861957602, disc_loss = 0.005736483697287503
Trained batch 365 in epoch 13, gen_loss = 0.8856450487030009, disc_loss = 0.005722619545730461
Trained batch 366 in epoch 13, gen_loss = 0.8856601365905367, disc_loss = 0.0057079309098762255
Trained batch 367 in epoch 13, gen_loss = 0.8857192071559636, disc_loss = 0.005693475478457675
Trained batch 368 in epoch 13, gen_loss = 0.8858196665924093, disc_loss = 0.005678853349185828
Trained batch 369 in epoch 13, gen_loss = 0.8855544452731674, disc_loss = 0.005664536004277997
Trained batch 370 in epoch 13, gen_loss = 0.8857590707164569, disc_loss = 0.005649892740905369
Trained batch 371 in epoch 13, gen_loss = 0.8856833907224799, disc_loss = 0.005635525045383024
Trained batch 372 in epoch 13, gen_loss = 0.8859816971796767, disc_loss = 0.005622345402904058
Trained batch 373 in epoch 13, gen_loss = 0.8860635869005785, disc_loss = 0.005608631212871745
Trained batch 374 in epoch 13, gen_loss = 0.885879899819692, disc_loss = 0.005594764878876352
Trained batch 375 in epoch 13, gen_loss = 0.8858060354882098, disc_loss = 0.0055806480752428975
Trained batch 376 in epoch 13, gen_loss = 0.8857892992009535, disc_loss = 0.005566767584859049
Trained batch 377 in epoch 13, gen_loss = 0.885926251531278, disc_loss = 0.005553219215072064
Trained batch 378 in epoch 13, gen_loss = 0.8860769490453373, disc_loss = 0.005539757210700951
Trained batch 379 in epoch 13, gen_loss = 0.8863968571549967, disc_loss = 0.005527782707998229
Trained batch 380 in epoch 13, gen_loss = 0.8862286022328955, disc_loss = 0.005514598834163203
Trained batch 381 in epoch 13, gen_loss = 0.8864674884923466, disc_loss = 0.005501854803996905
Trained batch 382 in epoch 13, gen_loss = 0.8865124284442971, disc_loss = 0.005488846442286337
Trained batch 383 in epoch 13, gen_loss = 0.8868835787288845, disc_loss = 0.0054763288693682926
Trained batch 384 in epoch 13, gen_loss = 0.8869055303660306, disc_loss = 0.005463139772586761
Trained batch 385 in epoch 13, gen_loss = 0.8868087945515628, disc_loss = 0.005449885411734344
Trained batch 386 in epoch 13, gen_loss = 0.8873603074433576, disc_loss = 0.0054397524863886715
Trained batch 387 in epoch 13, gen_loss = 0.8875420880071896, disc_loss = 0.005426133343996871
Trained batch 388 in epoch 13, gen_loss = 0.8874036763198578, disc_loss = 0.005413452631038713
Trained batch 389 in epoch 13, gen_loss = 0.8875318748828692, disc_loss = 0.005399972543203218
Trained batch 390 in epoch 13, gen_loss = 0.887197514324237, disc_loss = 0.005395844201342223
Trained batch 391 in epoch 13, gen_loss = 0.8873483286220201, disc_loss = 0.005383241805377891
Trained batch 392 in epoch 13, gen_loss = 0.8877529585331148, disc_loss = 0.00538282012982746
Trained batch 393 in epoch 13, gen_loss = 0.8877551071534907, disc_loss = 0.005372941888865707
Trained batch 394 in epoch 13, gen_loss = 0.8877240678932093, disc_loss = 0.0053608542926944025
Trained batch 395 in epoch 13, gen_loss = 0.8874108111015474, disc_loss = 0.005348662131405265
Trained batch 396 in epoch 13, gen_loss = 0.8877810543069912, disc_loss = 0.005336458136582535
Trained batch 397 in epoch 13, gen_loss = 0.887763414101385, disc_loss = 0.0053249338365751655
Trained batch 398 in epoch 13, gen_loss = 0.8879052690396034, disc_loss = 0.005312788292466118
Trained batch 399 in epoch 13, gen_loss = 0.887755264788866, disc_loss = 0.005300339252771664
Trained batch 400 in epoch 13, gen_loss = 0.8879738615040768, disc_loss = 0.005288043920167152
Trained batch 401 in epoch 13, gen_loss = 0.8879945359716368, disc_loss = 0.0052754553837609875
Trained batch 402 in epoch 13, gen_loss = 0.8880854871669419, disc_loss = 0.005263344500549386
Trained batch 403 in epoch 13, gen_loss = 0.8881664487099884, disc_loss = 0.0052514587453038305
Trained batch 404 in epoch 13, gen_loss = 0.888373996593334, disc_loss = 0.0052390463600462634
Trained batch 405 in epoch 13, gen_loss = 0.8883760885652063, disc_loss = 0.005226719949340415
Trained batch 406 in epoch 13, gen_loss = 0.888174996914969, disc_loss = 0.005214127860188196
Trained batch 407 in epoch 13, gen_loss = 0.8879445363201347, disc_loss = 0.0052018277752258835
Trained batch 408 in epoch 13, gen_loss = 0.8879805992751366, disc_loss = 0.005189614697367472
Trained batch 409 in epoch 13, gen_loss = 0.8879550214220838, disc_loss = 0.005178013306945881
Trained batch 410 in epoch 13, gen_loss = 0.8879527757057598, disc_loss = 0.005167315872255804
Trained batch 411 in epoch 13, gen_loss = 0.8880666740311002, disc_loss = 0.005155184829826026
Trained batch 412 in epoch 13, gen_loss = 0.8871548399509587, disc_loss = 0.005402127302571123
Trained batch 413 in epoch 13, gen_loss = 0.8874746813002415, disc_loss = 0.006710831983925174
Trained batch 414 in epoch 13, gen_loss = 0.8876413427203534, disc_loss = 0.007695642822030764
Trained batch 415 in epoch 13, gen_loss = 0.8871080653312114, disc_loss = 0.008441696471016677
Trained batch 416 in epoch 13, gen_loss = 0.8864374087868835, disc_loss = 0.009078337874899202
Trained batch 417 in epoch 13, gen_loss = 0.8856579685610447, disc_loss = 0.009724745936069302
Trained batch 418 in epoch 13, gen_loss = 0.8847124849697287, disc_loss = 0.010423020443353671
Trained batch 419 in epoch 13, gen_loss = 0.8836944628329504, disc_loss = 0.011057446071347277
Trained batch 420 in epoch 13, gen_loss = 0.8827701312912332, disc_loss = 0.011678404335438323
Trained batch 421 in epoch 13, gen_loss = 0.8823589974952535, disc_loss = 0.012302974697239134
Trained batch 422 in epoch 13, gen_loss = 0.8816315782549251, disc_loss = 0.012922120599020284
Trained batch 423 in epoch 13, gen_loss = 0.8809709544732885, disc_loss = 0.013492956712825788
Trained batch 424 in epoch 13, gen_loss = 0.8801355938350454, disc_loss = 0.014085535537759665
Trained batch 425 in epoch 13, gen_loss = 0.8792548411888695, disc_loss = 0.014702024829483476
Trained batch 426 in epoch 13, gen_loss = 0.8785155835698862, disc_loss = 0.015249699937918254
Trained batch 427 in epoch 13, gen_loss = 0.8778134933977484, disc_loss = 0.015801031690040032
Trained batch 428 in epoch 13, gen_loss = 0.8774550783606399, disc_loss = 0.01637273223554126
Trained batch 429 in epoch 13, gen_loss = 0.8767039529112882, disc_loss = 0.017029693401398323
Trained batch 430 in epoch 13, gen_loss = 0.87615355289176, disc_loss = 0.017598752795942526
Trained batch 431 in epoch 13, gen_loss = 0.8756718246473206, disc_loss = 0.018084311606967444
Trained batch 432 in epoch 13, gen_loss = 0.874971664254715, disc_loss = 0.018632456375584146
Trained batch 433 in epoch 13, gen_loss = 0.87443051936989, disc_loss = 0.01915193337887179
Trained batch 434 in epoch 13, gen_loss = 0.8738305204216091, disc_loss = 0.019681172663026124
Trained batch 435 in epoch 13, gen_loss = 0.8730790839282745, disc_loss = 0.020239992963595778
Trained batch 436 in epoch 13, gen_loss = 0.8724247416315144, disc_loss = 0.02080544978474108
Trained batch 437 in epoch 13, gen_loss = 0.8718971977495167, disc_loss = 0.02133470208022757
Trained batch 438 in epoch 13, gen_loss = 0.8711790047365332, disc_loss = 0.0217873163445779
Trained batch 439 in epoch 13, gen_loss = 0.8705597652630372, disc_loss = 0.022262711949224467
Trained batch 440 in epoch 13, gen_loss = 0.8699645412211515, disc_loss = 0.02263960390024509
Trained batch 441 in epoch 13, gen_loss = 0.8693792809188635, disc_loss = 0.02300264412351927
Trained batch 442 in epoch 13, gen_loss = 0.8686725045165413, disc_loss = 0.023347945592996064
Trained batch 443 in epoch 13, gen_loss = 0.8681685837270977, disc_loss = 0.0235918466883582
Trained batch 444 in epoch 13, gen_loss = 0.8676767161722934, disc_loss = 0.023772166576530796
Trained batch 445 in epoch 13, gen_loss = 0.867383534865529, disc_loss = 0.02387682123727926
Trained batch 446 in epoch 13, gen_loss = 0.8671509358173516, disc_loss = 0.024031523314349705
Trained batch 447 in epoch 13, gen_loss = 0.8666489450260997, disc_loss = 0.024477820601565066
Trained batch 448 in epoch 13, gen_loss = 0.8665274799799335, disc_loss = 0.02482319514468475
Trained batch 449 in epoch 13, gen_loss = 0.8663726630475787, disc_loss = 0.025474601511410178
Trained batch 450 in epoch 13, gen_loss = 0.865851374396728, disc_loss = 0.02567386791498391
Trained batch 451 in epoch 13, gen_loss = 0.8654076033725148, disc_loss = 0.025897713550408957
Trained batch 452 in epoch 13, gen_loss = 0.8648840148191052, disc_loss = 0.026084673267443022
Trained batch 453 in epoch 13, gen_loss = 0.8646548637209485, disc_loss = 0.026271337806638217
Trained batch 454 in epoch 13, gen_loss = 0.8644569931449471, disc_loss = 0.02632296459450627
Trained batch 455 in epoch 13, gen_loss = 0.8642473971111733, disc_loss = 0.026312240063736936
Trained batch 456 in epoch 13, gen_loss = 0.864270372515956, disc_loss = 0.026311186730487962
Trained batch 457 in epoch 13, gen_loss = 0.8643516937197556, disc_loss = 0.026267146467269086
Trained batch 458 in epoch 13, gen_loss = 0.8643260074856495, disc_loss = 0.026234714666662752
Trained batch 459 in epoch 13, gen_loss = 0.8643557608127594, disc_loss = 0.026190439424681244
Trained batch 460 in epoch 13, gen_loss = 0.8642965899113719, disc_loss = 0.026149936708544156
Trained batch 461 in epoch 13, gen_loss = 0.8643117745717367, disc_loss = 0.026138503262976003
Trained batch 462 in epoch 13, gen_loss = 0.864072898937868, disc_loss = 0.026130423325217797
Trained batch 463 in epoch 13, gen_loss = 0.8641142866991717, disc_loss = 0.026083512744819393
Trained batch 464 in epoch 13, gen_loss = 0.8640512472839765, disc_loss = 0.026035758714042654
Trained batch 465 in epoch 13, gen_loss = 0.8640045906085313, disc_loss = 0.026010212879469308
Trained batch 466 in epoch 13, gen_loss = 0.8639061225047714, disc_loss = 0.025985557000917817
Trained batch 467 in epoch 13, gen_loss = 0.8640045816572304, disc_loss = 0.02594005440700223
Trained batch 468 in epoch 13, gen_loss = 0.8640620329740968, disc_loss = 0.025914931032680787
Trained batch 469 in epoch 13, gen_loss = 0.8641471676369931, disc_loss = 0.025867862026783033
Trained batch 470 in epoch 13, gen_loss = 0.8641757165297328, disc_loss = 0.025825427106865622
Trained batch 471 in epoch 13, gen_loss = 0.8638891118057703, disc_loss = 0.025806382611489872
Trained batch 472 in epoch 13, gen_loss = 0.8638260745094896, disc_loss = 0.025761698306978477
Trained batch 473 in epoch 13, gen_loss = 0.8635629226889792, disc_loss = 0.025730102691674882
Trained batch 474 in epoch 13, gen_loss = 0.8639297317203722, disc_loss = 0.025693374546030292
Trained batch 475 in epoch 13, gen_loss = 0.8643203936204189, disc_loss = 0.02564666621921268
Trained batch 476 in epoch 13, gen_loss = 0.8645299028300639, disc_loss = 0.025602577457994474
Trained batch 477 in epoch 13, gen_loss = 0.8644915230603397, disc_loss = 0.02555932721810997
Trained batch 478 in epoch 13, gen_loss = 0.8645711627036395, disc_loss = 0.025524787612373374
Trained batch 479 in epoch 13, gen_loss = 0.8646866622070472, disc_loss = 0.025483801906405763
Trained batch 480 in epoch 13, gen_loss = 0.8645619426596437, disc_loss = 0.025434375482374413
Trained batch 481 in epoch 13, gen_loss = 0.864519092304578, disc_loss = 0.025385097406363296
Trained batch 482 in epoch 13, gen_loss = 0.864535887789282, disc_loss = 0.025341488412316496
Trained batch 483 in epoch 13, gen_loss = 0.8649529162024664, disc_loss = 0.02529722845765944
Trained batch 484 in epoch 13, gen_loss = 0.8653767809425432, disc_loss = 0.025251098216262875
Trained batch 485 in epoch 13, gen_loss = 0.8651713481165254, disc_loss = 0.02520512910792724
Trained batch 486 in epoch 13, gen_loss = 0.8650955913982352, disc_loss = 0.02516285745234939
Trained batch 487 in epoch 13, gen_loss = 0.8651508524036798, disc_loss = 0.025114406580869997
Trained batch 488 in epoch 13, gen_loss = 0.8651109493827039, disc_loss = 0.02506557823226531
Trained batch 489 in epoch 13, gen_loss = 0.865186834213685, disc_loss = 0.025019052438467637
Trained batch 490 in epoch 13, gen_loss = 0.8650873407812565, disc_loss = 0.02497499775762794
Trained batch 491 in epoch 13, gen_loss = 0.8650486380831013, disc_loss = 0.02492689171513638
Trained batch 492 in epoch 13, gen_loss = 0.8650910699585147, disc_loss = 0.024881460750221678
Trained batch 493 in epoch 13, gen_loss = 0.8650175277520771, disc_loss = 0.02483412502374173
Trained batch 494 in epoch 13, gen_loss = 0.8649753363445551, disc_loss = 0.02478815004411224
Trained batch 495 in epoch 13, gen_loss = 0.865210649347113, disc_loss = 0.02474028045983892
Trained batch 496 in epoch 13, gen_loss = 0.8652054376045702, disc_loss = 0.024691928332228583
Trained batch 497 in epoch 13, gen_loss = 0.8653824044518681, disc_loss = 0.024645034193434615
Trained batch 498 in epoch 13, gen_loss = 0.8653629461605706, disc_loss = 0.024598256134287406
Trained batch 499 in epoch 13, gen_loss = 0.8653941179513931, disc_loss = 0.02455016805397463
Trained batch 500 in epoch 13, gen_loss = 0.8655408039064465, disc_loss = 0.024503921023636226
Trained batch 501 in epoch 13, gen_loss = 0.865799627099854, disc_loss = 0.024464067666072713
Trained batch 502 in epoch 13, gen_loss = 0.8660493931523848, disc_loss = 0.024417784421689202
Trained batch 503 in epoch 13, gen_loss = 0.8661652461640419, disc_loss = 0.02437188888654332
Trained batch 504 in epoch 13, gen_loss = 0.8659895938221771, disc_loss = 0.02432687401493186
Trained batch 505 in epoch 13, gen_loss = 0.8661823431729329, disc_loss = 0.024281918290955808
Trained batch 506 in epoch 13, gen_loss = 0.8664730811965536, disc_loss = 0.024237083344422032
Trained batch 507 in epoch 13, gen_loss = 0.8665824033847944, disc_loss = 0.024191912989422915
Trained batch 508 in epoch 13, gen_loss = 0.8667536162440107, disc_loss = 0.024147374855798362
Trained batch 509 in epoch 13, gen_loss = 0.8668001497493071, disc_loss = 0.02410318276656029
Trained batch 510 in epoch 13, gen_loss = 0.866911831200706, disc_loss = 0.02406381069933253
Trained batch 511 in epoch 13, gen_loss = 0.8671753031667322, disc_loss = 0.024018883929130652
Trained batch 512 in epoch 13, gen_loss = 0.8673625765023408, disc_loss = 0.02397747465696292
Trained batch 513 in epoch 13, gen_loss = 0.8672343553967977, disc_loss = 0.023963961754600537
Trained batch 514 in epoch 13, gen_loss = 0.8676574814666822, disc_loss = 0.0239250668105545
Trained batch 515 in epoch 13, gen_loss = 0.8675807493832685, disc_loss = 0.02390066656903224
Trained batch 516 in epoch 13, gen_loss = 0.8680262061797904, disc_loss = 0.02386676495770606
Trained batch 517 in epoch 13, gen_loss = 0.8678933400445002, disc_loss = 0.02382390804543959
Trained batch 518 in epoch 13, gen_loss = 0.86782054140848, disc_loss = 0.023781314666988823
Trained batch 519 in epoch 13, gen_loss = 0.8679848374082492, disc_loss = 0.023738330516033995
Trained batch 520 in epoch 13, gen_loss = 0.8682867944126166, disc_loss = 0.023695369455106457
Trained batch 521 in epoch 13, gen_loss = 0.8683922265681271, disc_loss = 0.02365214929502155
Trained batch 522 in epoch 13, gen_loss = 0.8682556690267121, disc_loss = 0.02361038050160322
Trained batch 523 in epoch 13, gen_loss = 0.8684754859627658, disc_loss = 0.02356745213657757
Trained batch 524 in epoch 13, gen_loss = 0.8685137879280816, disc_loss = 0.023524085218779786
Trained batch 525 in epoch 13, gen_loss = 0.8687519466242409, disc_loss = 0.02348242693175336
Trained batch 526 in epoch 13, gen_loss = 0.868685026661947, disc_loss = 0.023439462530848384
Trained batch 527 in epoch 13, gen_loss = 0.8689225239284111, disc_loss = 0.023401539846418018
Trained batch 528 in epoch 13, gen_loss = 0.8689153983146797, disc_loss = 0.0233598275335749
Trained batch 529 in epoch 13, gen_loss = 0.8687481587787844, disc_loss = 0.023317065408023925
Trained batch 530 in epoch 13, gen_loss = 0.8690808968804425, disc_loss = 0.02327496511491718
Trained batch 531 in epoch 13, gen_loss = 0.8690528678042548, disc_loss = 0.023235737791012918
Trained batch 532 in epoch 13, gen_loss = 0.8689670778573342, disc_loss = 0.023196448864902134
Trained batch 533 in epoch 13, gen_loss = 0.8690147982554489, disc_loss = 0.02315884942391278
Trained batch 534 in epoch 13, gen_loss = 0.8690650879779709, disc_loss = 0.023123798362076255
Trained batch 535 in epoch 13, gen_loss = 0.8690553850202418, disc_loss = 0.023085144957261022
Trained batch 536 in epoch 13, gen_loss = 0.8689731600342294, disc_loss = 0.023048527946582305
Trained batch 537 in epoch 13, gen_loss = 0.8691233430874835, disc_loss = 0.023009970425663828
Trained batch 538 in epoch 13, gen_loss = 0.8695744193108935, disc_loss = 0.022970615680346133
Trained batch 539 in epoch 13, gen_loss = 0.8697224405076769, disc_loss = 0.022931156565970955
Trained batch 540 in epoch 13, gen_loss = 0.8699311102824819, disc_loss = 0.022892760361447738
Trained batch 541 in epoch 13, gen_loss = 0.8698953553979247, disc_loss = 0.0228542726015944
Trained batch 542 in epoch 13, gen_loss = 0.8704434417009793, disc_loss = 0.02281555178377226
Trained batch 543 in epoch 13, gen_loss = 0.8706093273837777, disc_loss = 0.022775659874803428
Trained batch 544 in epoch 13, gen_loss = 0.8705773750576404, disc_loss = 0.02273674348239475
Trained batch 545 in epoch 13, gen_loss = 0.870834659634929, disc_loss = 0.02269829457202835
Trained batch 546 in epoch 13, gen_loss = 0.8708517785699973, disc_loss = 0.02265995097927297
Trained batch 547 in epoch 13, gen_loss = 0.8708941647171105, disc_loss = 0.022622183344504724
Trained batch 548 in epoch 13, gen_loss = 0.8710904310309822, disc_loss = 0.022583062238279834
Trained batch 549 in epoch 13, gen_loss = 0.871248298666694, disc_loss = 0.02254466263939817
Trained batch 550 in epoch 13, gen_loss = 0.871429565922102, disc_loss = 0.022506329345715673
Trained batch 551 in epoch 13, gen_loss = 0.8718095928214599, disc_loss = 0.0224677802861402
Trained batch 552 in epoch 13, gen_loss = 0.8722399045287161, disc_loss = 0.0224303614780415
Trained batch 553 in epoch 13, gen_loss = 0.8722610796401647, disc_loss = 0.0223931433374345
Trained batch 554 in epoch 13, gen_loss = 0.8722771352475828, disc_loss = 0.022354521190664764
Trained batch 555 in epoch 13, gen_loss = 0.8723719835066966, disc_loss = 0.022316020731392303
Trained batch 556 in epoch 13, gen_loss = 0.8725111084309686, disc_loss = 0.022278190404558144
Trained batch 557 in epoch 13, gen_loss = 0.8725664581449228, disc_loss = 0.022240116292370632
Trained batch 558 in epoch 13, gen_loss = 0.872700379231748, disc_loss = 0.022201902845884632
Trained batch 559 in epoch 13, gen_loss = 0.8727835993681635, disc_loss = 0.022164005086986956
Trained batch 560 in epoch 13, gen_loss = 0.8729303904183195, disc_loss = 0.022126829204255998
Trained batch 561 in epoch 13, gen_loss = 0.8728658059525745, disc_loss = 0.022090560058054133
Trained batch 562 in epoch 13, gen_loss = 0.8728408781715651, disc_loss = 0.022053226186248942
Trained batch 563 in epoch 13, gen_loss = 0.8727976565665387, disc_loss = 0.02201594225187635
Trained batch 564 in epoch 13, gen_loss = 0.8730337535385537, disc_loss = 0.02197849203369362
Trained batch 565 in epoch 13, gen_loss = 0.8731874688775295, disc_loss = 0.021941225598456196
Trained batch 566 in epoch 13, gen_loss = 0.8733002145033875, disc_loss = 0.021904198544838455
Trained batch 567 in epoch 13, gen_loss = 0.873553560653203, disc_loss = 0.021867381882080913
Trained batch 568 in epoch 13, gen_loss = 0.8737170136875763, disc_loss = 0.02183042387914355
Trained batch 569 in epoch 13, gen_loss = 0.873708106551254, disc_loss = 0.021793497603089476
Trained batch 570 in epoch 13, gen_loss = 0.8737105233447982, disc_loss = 0.021757046669162363
Trained batch 571 in epoch 13, gen_loss = 0.8737477596614744, disc_loss = 0.021720661878529033
Trained batch 572 in epoch 13, gen_loss = 0.8738662692056692, disc_loss = 0.021683768443947125
Trained batch 573 in epoch 13, gen_loss = 0.8739000700076698, disc_loss = 0.02164760460566104
Trained batch 574 in epoch 13, gen_loss = 0.8741688836139181, disc_loss = 0.02161119638529667
Trained batch 575 in epoch 13, gen_loss = 0.8744632748679982, disc_loss = 0.02157586716821748
Trained batch 576 in epoch 13, gen_loss = 0.8744440218191626, disc_loss = 0.021539905704332934
Trained batch 577 in epoch 13, gen_loss = 0.8746867702700275, disc_loss = 0.021503873077604096
Trained batch 578 in epoch 13, gen_loss = 0.8747974688730915, disc_loss = 0.021468643101306417
Trained batch 579 in epoch 13, gen_loss = 0.8748574853971087, disc_loss = 0.021432488972591115
Trained batch 580 in epoch 13, gen_loss = 0.8747790849762817, disc_loss = 0.02139650796161481
Trained batch 581 in epoch 13, gen_loss = 0.8750069248922092, disc_loss = 0.021360572585457004
Trained batch 582 in epoch 13, gen_loss = 0.8751880444752413, disc_loss = 0.021324906995729462
Trained batch 583 in epoch 13, gen_loss = 0.8751494920212929, disc_loss = 0.02128931987693885
Trained batch 584 in epoch 13, gen_loss = 0.8750313751717917, disc_loss = 0.021254528667922053
Trained batch 585 in epoch 13, gen_loss = 0.8751796677250911, disc_loss = 0.02121970700495896
Trained batch 586 in epoch 13, gen_loss = 0.8752553599047296, disc_loss = 0.02118499116057128
Trained batch 587 in epoch 13, gen_loss = 0.8753627585310514, disc_loss = 0.021150086084694552
Trained batch 588 in epoch 13, gen_loss = 0.8755665049083367, disc_loss = 0.021115401807105357
Trained batch 589 in epoch 13, gen_loss = 0.8758047238244848, disc_loss = 0.021080679371405463
Trained batch 590 in epoch 13, gen_loss = 0.8758567970012852, disc_loss = 0.02104591175885938
Trained batch 591 in epoch 13, gen_loss = 0.8759079596682174, disc_loss = 0.021011458276351168
Trained batch 592 in epoch 13, gen_loss = 0.8759145596980245, disc_loss = 0.020977288924247335
Trained batch 593 in epoch 13, gen_loss = 0.875953306152363, disc_loss = 0.020942891097079017
Trained batch 594 in epoch 13, gen_loss = 0.8760221806894831, disc_loss = 0.020908778271478398
Trained batch 595 in epoch 13, gen_loss = 0.8762440190419255, disc_loss = 0.020874866806956098
Trained batch 596 in epoch 13, gen_loss = 0.8763217204180195, disc_loss = 0.020840671315329608
Trained batch 597 in epoch 13, gen_loss = 0.8765475575541174, disc_loss = 0.020806624518837243
Trained batch 598 in epoch 13, gen_loss = 0.8765055559115338, disc_loss = 0.02077271394333542
Trained batch 599 in epoch 13, gen_loss = 0.8765636780858039, disc_loss = 0.02073891873313793
Trained batch 600 in epoch 13, gen_loss = 0.8767211061349129, disc_loss = 0.020705179691888252
Trained batch 601 in epoch 13, gen_loss = 0.8768188348442217, disc_loss = 0.02067151928610695
Trained batch 602 in epoch 13, gen_loss = 0.8766729377000091, disc_loss = 0.02064021300197912
Trained batch 603 in epoch 13, gen_loss = 0.8766465530490244, disc_loss = 0.020607399680623393
Trained batch 604 in epoch 13, gen_loss = 0.8768323569258383, disc_loss = 0.02057396165046683
Trained batch 605 in epoch 13, gen_loss = 0.8767362586145747, disc_loss = 0.02054117786274549
Trained batch 606 in epoch 13, gen_loss = 0.87681220449765, disc_loss = 0.02050821887412361
Trained batch 607 in epoch 13, gen_loss = 0.8766918339227375, disc_loss = 0.020475861321253768
Trained batch 608 in epoch 13, gen_loss = 0.8766711219190964, disc_loss = 0.020443689706309987
Trained batch 609 in epoch 13, gen_loss = 0.8766199930769498, disc_loss = 0.0204110281669571
Trained batch 610 in epoch 13, gen_loss = 0.8767949298828986, disc_loss = 0.020379282331753196
Trained batch 611 in epoch 13, gen_loss = 0.8769378581273011, disc_loss = 0.020346875732749955
Trained batch 612 in epoch 13, gen_loss = 0.8770424875310739, disc_loss = 0.02031527648760719
Trained batch 613 in epoch 13, gen_loss = 0.8771400756478698, disc_loss = 0.020283059338736233
Trained batch 614 in epoch 13, gen_loss = 0.8771365309149269, disc_loss = 0.020251717251830552
Trained batch 615 in epoch 13, gen_loss = 0.8770657303658399, disc_loss = 0.020234748890430497
Trained batch 616 in epoch 13, gen_loss = 0.877350641224334, disc_loss = 0.020218278515329802
Trained batch 617 in epoch 13, gen_loss = 0.8773991303536498, disc_loss = 0.02019129680093543
Trained batch 618 in epoch 13, gen_loss = 0.8775567416228077, disc_loss = 0.020164671035757874
Trained batch 619 in epoch 13, gen_loss = 0.8775963101656207, disc_loss = 0.02013788904481654
Trained batch 620 in epoch 13, gen_loss = 0.8778657002341537, disc_loss = 0.020109415758788645
Trained batch 621 in epoch 13, gen_loss = 0.8780264113685325, disc_loss = 0.02007874323485529
Trained batch 622 in epoch 13, gen_loss = 0.8782015186442992, disc_loss = 0.020049090072994546
Trained batch 623 in epoch 13, gen_loss = 0.8784298578707072, disc_loss = 0.020017911386742363
Trained batch 624 in epoch 13, gen_loss = 0.8785549348831176, disc_loss = 0.019987479780218562
Trained batch 625 in epoch 13, gen_loss = 0.8787491913801565, disc_loss = 0.0199565244263725
Trained batch 626 in epoch 13, gen_loss = 0.8786927953101041, disc_loss = 0.019925530701224912
Trained batch 627 in epoch 13, gen_loss = 0.8785820266433583, disc_loss = 0.019895431354887905
Trained batch 628 in epoch 13, gen_loss = 0.8786649029281446, disc_loss = 0.01986451013032136
Trained batch 629 in epoch 13, gen_loss = 0.8786302132265909, disc_loss = 0.01983429582293851
Trained batch 630 in epoch 13, gen_loss = 0.8786357627051001, disc_loss = 0.01980360382877747
Trained batch 631 in epoch 13, gen_loss = 0.878734755742399, disc_loss = 0.01977295511126532
Trained batch 632 in epoch 13, gen_loss = 0.878748615582784, disc_loss = 0.0197427128829453
Trained batch 633 in epoch 13, gen_loss = 0.8787689707256642, disc_loss = 0.019712193747199243
Trained batch 634 in epoch 13, gen_loss = 0.8789934366706788, disc_loss = 0.019681873357709035
Trained batch 635 in epoch 13, gen_loss = 0.8790126061477002, disc_loss = 0.019651577509030863
Trained batch 636 in epoch 13, gen_loss = 0.8789061573648378, disc_loss = 0.01962405989061967
Trained batch 637 in epoch 13, gen_loss = 0.8787177326537224, disc_loss = 0.019595482672190075
Trained batch 638 in epoch 13, gen_loss = 0.8787384525710988, disc_loss = 0.019569282936082944
Trained batch 639 in epoch 13, gen_loss = 0.8790142070502043, disc_loss = 0.019540803290851727
Trained batch 640 in epoch 13, gen_loss = 0.8788026057055885, disc_loss = 0.0195353374563442
Trained batch 641 in epoch 13, gen_loss = 0.8790263918887046, disc_loss = 0.019876349385880548
Trained batch 642 in epoch 13, gen_loss = 0.8792224264997717, disc_loss = 0.01986711534769162
Trained batch 643 in epoch 13, gen_loss = 0.8794522989795815, disc_loss = 0.019869586625634456
Trained batch 644 in epoch 13, gen_loss = 0.8795530631560687, disc_loss = 0.01984771447210634
Trained batch 645 in epoch 13, gen_loss = 0.8795366700588734, disc_loss = 0.019853353879504425
Trained batch 646 in epoch 13, gen_loss = 0.8798201769544316, disc_loss = 0.019841213978320855
Trained batch 647 in epoch 13, gen_loss = 0.8799838651845484, disc_loss = 0.019825573307784516
Trained batch 648 in epoch 13, gen_loss = 0.8799638577345156, disc_loss = 0.01982645735641757
Trained batch 649 in epoch 13, gen_loss = 0.8802232138927166, disc_loss = 0.019834769211973673
Trained batch 650 in epoch 13, gen_loss = 0.8805882463806786, disc_loss = 0.01982943439988413
Trained batch 651 in epoch 13, gen_loss = 0.8808269809725826, disc_loss = 0.019822977243277546
Trained batch 652 in epoch 13, gen_loss = 0.8809847099675153, disc_loss = 0.01980311859391147
Trained batch 653 in epoch 13, gen_loss = 0.8811226975662628, disc_loss = 0.01979997071979296
Trained batch 654 in epoch 13, gen_loss = 0.881575459924363, disc_loss = 0.020084162423265422
Trained batch 655 in epoch 13, gen_loss = 0.8817040852112014, disc_loss = 0.020096550258308636
Trained batch 656 in epoch 13, gen_loss = 0.8813239959276975, disc_loss = 0.02102265981572366
Trained batch 657 in epoch 13, gen_loss = 0.881110654413519, disc_loss = 0.021154834908668742
Trained batch 658 in epoch 13, gen_loss = 0.8806699464643128, disc_loss = 0.02150454655377889
Trained batch 659 in epoch 13, gen_loss = 0.8807318659442844, disc_loss = 0.021720479174749042
Trained batch 660 in epoch 13, gen_loss = 0.8804977282814107, disc_loss = 0.0218978211024215
Trained batch 661 in epoch 13, gen_loss = 0.880549062414832, disc_loss = 0.021949472868078412
Trained batch 662 in epoch 13, gen_loss = 0.8801170484153034, disc_loss = 0.022064440974980264
Trained batch 663 in epoch 13, gen_loss = 0.8798942936651678, disc_loss = 0.02215427265735957
Trained batch 664 in epoch 13, gen_loss = 0.8799773774648968, disc_loss = 0.02224868791441773
Trained batch 665 in epoch 13, gen_loss = 0.8802439349370675, disc_loss = 0.022570614812051557
Trained batch 666 in epoch 13, gen_loss = 0.880292051199494, disc_loss = 0.022589072171783506
Trained batch 667 in epoch 13, gen_loss = 0.8798114009603055, disc_loss = 0.02337511228451078
Trained batch 668 in epoch 13, gen_loss = 0.8802381406450486, disc_loss = 0.02349505752812906
Trained batch 669 in epoch 13, gen_loss = 0.8799307460215554, disc_loss = 0.023817002995668583
Trained batch 670 in epoch 13, gen_loss = 0.8794948349411192, disc_loss = 0.024096139430445092
Trained batch 671 in epoch 13, gen_loss = 0.8793880749671232, disc_loss = 0.02426266568222889
Trained batch 672 in epoch 13, gen_loss = 0.8790043218706196, disc_loss = 0.024371461264689986
Trained batch 673 in epoch 13, gen_loss = 0.8790499636964204, disc_loss = 0.02436339468568704
Trained batch 674 in epoch 13, gen_loss = 0.8792362244923909, disc_loss = 0.024340885067681988
Trained batch 675 in epoch 13, gen_loss = 0.8791876540205182, disc_loss = 0.024336349848669385
Trained batch 676 in epoch 13, gen_loss = 0.8792463681018159, disc_loss = 0.024328822263135944
Trained batch 677 in epoch 13, gen_loss = 0.8791925439440746, disc_loss = 0.024312247655396163
Trained batch 678 in epoch 13, gen_loss = 0.8792917758270287, disc_loss = 0.024288081300638812
Trained batch 679 in epoch 13, gen_loss = 0.8797845384653877, disc_loss = 0.024271119643419617
Trained batch 680 in epoch 13, gen_loss = 0.8799492027090859, disc_loss = 0.024242627945202593
Trained batch 681 in epoch 13, gen_loss = 0.8798981902361616, disc_loss = 0.024234488563415972
Trained batch 682 in epoch 13, gen_loss = 0.8799908050331853, disc_loss = 0.0242070709839032
Trained batch 683 in epoch 13, gen_loss = 0.8802315259014654, disc_loss = 0.02417447999232004
Trained batch 684 in epoch 13, gen_loss = 0.8802493176321043, disc_loss = 0.024145542943733743
Trained batch 685 in epoch 13, gen_loss = 0.8804606559846561, disc_loss = 0.024113502985377473
Trained batch 686 in epoch 13, gen_loss = 0.8805997990277831, disc_loss = 0.024084660827175964
Trained batch 687 in epoch 13, gen_loss = 0.8809054290312667, disc_loss = 0.02405846259435473
Trained batch 688 in epoch 13, gen_loss = 0.8808849207375669, disc_loss = 0.024209098884995846
Trained batch 689 in epoch 13, gen_loss = 0.8801543815412383, disc_loss = 0.024695249892534195
Trained batch 690 in epoch 13, gen_loss = 0.8803802655333203, disc_loss = 0.02466979390749416
Trained batch 691 in epoch 13, gen_loss = 0.8806491241806504, disc_loss = 0.024775438374048872
Trained batch 692 in epoch 13, gen_loss = 0.8808618967151229, disc_loss = 0.02480551942611032
Trained batch 693 in epoch 13, gen_loss = 0.8808324976853747, disc_loss = 0.024791831288852238
Trained batch 694 in epoch 13, gen_loss = 0.8808342474827664, disc_loss = 0.024772948194140228
Trained batch 695 in epoch 13, gen_loss = 0.8808512000859469, disc_loss = 0.024746319277715655
Trained batch 696 in epoch 13, gen_loss = 0.8804413121263129, disc_loss = 0.024752676533714674
Trained batch 697 in epoch 13, gen_loss = 0.8804153570302237, disc_loss = 0.02472343981626859
Trained batch 698 in epoch 13, gen_loss = 0.8807089017525592, disc_loss = 0.024694579534840673
Trained batch 699 in epoch 13, gen_loss = 0.8808763475928988, disc_loss = 0.024664421498289034
Trained batch 700 in epoch 13, gen_loss = 0.8810448044547001, disc_loss = 0.024631782416260094
Trained batch 701 in epoch 13, gen_loss = 0.8810852983398655, disc_loss = 0.0245991989152771
Trained batch 702 in epoch 13, gen_loss = 0.8808630146987069, disc_loss = 0.024582362577436224
Trained batch 703 in epoch 13, gen_loss = 0.8807901865379377, disc_loss = 0.024556928080755824
Trained batch 704 in epoch 13, gen_loss = 0.8807328217418481, disc_loss = 0.024548273670288126
Trained batch 705 in epoch 13, gen_loss = 0.8808867619834608, disc_loss = 0.024515974088670078
Trained batch 706 in epoch 13, gen_loss = 0.8809368887750229, disc_loss = 0.024484095330918346
Trained batch 707 in epoch 13, gen_loss = 0.8811395152308846, disc_loss = 0.02451488145461913
Trained batch 708 in epoch 13, gen_loss = 0.8812792555065182, disc_loss = 0.024494587405654866
Trained batch 709 in epoch 13, gen_loss = 0.880870646658078, disc_loss = 0.024539198004948075
Trained batch 710 in epoch 13, gen_loss = 0.8809584134406346, disc_loss = 0.024511221611561055
Trained batch 711 in epoch 13, gen_loss = 0.8812483815329798, disc_loss = 0.024483920717879238
Trained batch 712 in epoch 13, gen_loss = 0.8814024216329567, disc_loss = 0.024456938589559142
Trained batch 713 in epoch 13, gen_loss = 0.881446013681027, disc_loss = 0.024428013226594377
Trained batch 714 in epoch 13, gen_loss = 0.8815692276387782, disc_loss = 0.02439844841656513
Trained batch 715 in epoch 13, gen_loss = 0.8815859790953844, disc_loss = 0.02436790932501148
Trained batch 716 in epoch 13, gen_loss = 0.8818410066381159, disc_loss = 0.02433755745975456
Trained batch 717 in epoch 13, gen_loss = 0.881982194846055, disc_loss = 0.024307673851145312
Trained batch 718 in epoch 13, gen_loss = 0.8821616205950275, disc_loss = 0.024276165844579044
Trained batch 719 in epoch 13, gen_loss = 0.8822033171852429, disc_loss = 0.024244756908976543
Trained batch 720 in epoch 13, gen_loss = 0.8822679706486187, disc_loss = 0.024212584580047262
Trained batch 721 in epoch 13, gen_loss = 0.8824016372582919, disc_loss = 0.024180805450543172
Trained batch 722 in epoch 13, gen_loss = 0.882454719863327, disc_loss = 0.024148624671881867
Trained batch 723 in epoch 13, gen_loss = 0.8825812758826419, disc_loss = 0.024116814965944196
Trained batch 724 in epoch 13, gen_loss = 0.8827674129913593, disc_loss = 0.02408472269233557
Trained batch 725 in epoch 13, gen_loss = 0.8828328650023983, disc_loss = 0.024053321425291003
Trained batch 726 in epoch 13, gen_loss = 0.88277265294218, disc_loss = 0.024021720735703217
Trained batch 727 in epoch 13, gen_loss = 0.8829822754794425, disc_loss = 0.023990334311027973
Trained batch 728 in epoch 13, gen_loss = 0.8833215269368699, disc_loss = 0.02395993007342756
Trained batch 729 in epoch 13, gen_loss = 0.883355976784066, disc_loss = 0.023928221650896052
Trained batch 730 in epoch 13, gen_loss = 0.883423317636576, disc_loss = 0.023896642126809142
Trained batch 731 in epoch 13, gen_loss = 0.8835670733875264, disc_loss = 0.023865104445139083
Trained batch 732 in epoch 13, gen_loss = 0.8836992486274584, disc_loss = 0.02383355702369078
Trained batch 733 in epoch 13, gen_loss = 0.8839117949600116, disc_loss = 0.02380183971510697
Trained batch 734 in epoch 13, gen_loss = 0.8841449907847814, disc_loss = 0.023771281725450635
Trained batch 735 in epoch 13, gen_loss = 0.8842474261865668, disc_loss = 0.023740934209043822
Trained batch 736 in epoch 13, gen_loss = 0.8842088224282906, disc_loss = 0.023709538925101564
Trained batch 737 in epoch 13, gen_loss = 0.8843661276144064, disc_loss = 0.023678815628077454
Trained batch 738 in epoch 13, gen_loss = 0.8844298831664822, disc_loss = 0.023648110766927723
Trained batch 739 in epoch 13, gen_loss = 0.8845054147211281, disc_loss = 0.023617476288672078
Trained batch 740 in epoch 13, gen_loss = 0.8844868645333407, disc_loss = 0.023587056203030005
Trained batch 741 in epoch 13, gen_loss = 0.8845425832946345, disc_loss = 0.0235566159664122
Trained batch 742 in epoch 13, gen_loss = 0.8843839401191208, disc_loss = 0.02352764258467267
Trained batch 743 in epoch 13, gen_loss = 0.8844192973388139, disc_loss = 0.023497263773625952
Trained batch 744 in epoch 13, gen_loss = 0.8843794578673856, disc_loss = 0.02346672932107561
Trained batch 745 in epoch 13, gen_loss = 0.8845895297885261, disc_loss = 0.02343772668909171
Trained batch 746 in epoch 13, gen_loss = 0.8844997272434005, disc_loss = 0.02340805544330532
Trained batch 747 in epoch 13, gen_loss = 0.8845174269561462, disc_loss = 0.023378096283303746
Trained batch 748 in epoch 13, gen_loss = 0.8846032939383758, disc_loss = 0.023348880955884613
Trained batch 749 in epoch 13, gen_loss = 0.8845321470896403, disc_loss = 0.023319428680988494
Trained batch 750 in epoch 13, gen_loss = 0.8846756246848684, disc_loss = 0.02329183601393794
Trained batch 751 in epoch 13, gen_loss = 0.8845297245586172, disc_loss = 0.023265291317058772
Trained batch 752 in epoch 13, gen_loss = 0.884594739829085, disc_loss = 0.023242369306128895
Trained batch 753 in epoch 13, gen_loss = 0.8846027383121319, disc_loss = 0.02321361007658868
Trained batch 754 in epoch 13, gen_loss = 0.8847593752753655, disc_loss = 0.0231842869106913
Trained batch 755 in epoch 13, gen_loss = 0.8847583839817653, disc_loss = 0.02315720227933424
Trained batch 756 in epoch 13, gen_loss = 0.8848859367786341, disc_loss = 0.02312858527254598
Trained batch 757 in epoch 13, gen_loss = 0.8848797792180547, disc_loss = 0.0230989610325503
Trained batch 758 in epoch 13, gen_loss = 0.8851575794898474, disc_loss = 0.023070203518133447
Trained batch 759 in epoch 13, gen_loss = 0.8853335687988683, disc_loss = 0.02304211924460297
Trained batch 760 in epoch 13, gen_loss = 0.8855039692739619, disc_loss = 0.023013202015336683
Trained batch 761 in epoch 13, gen_loss = 0.8856112166965414, disc_loss = 0.022984303626746857
Trained batch 762 in epoch 13, gen_loss = 0.8856781997655666, disc_loss = 0.02295565437816549
Trained batch 763 in epoch 13, gen_loss = 0.885761572740465, disc_loss = 0.022926546236741965
Trained batch 764 in epoch 13, gen_loss = 0.8857405455283869, disc_loss = 0.02290048935978287
Trained batch 765 in epoch 13, gen_loss = 0.8857662585945727, disc_loss = 0.022872611602771188
Trained batch 766 in epoch 13, gen_loss = 0.8857788755188087, disc_loss = 0.022845631855371654
Trained batch 767 in epoch 13, gen_loss = 0.8856753182287017, disc_loss = 0.022819990616862167
Trained batch 768 in epoch 13, gen_loss = 0.8858525349972927, disc_loss = 0.022791521582534925
Trained batch 769 in epoch 13, gen_loss = 0.8859311552790853, disc_loss = 0.022767063180062552
Trained batch 770 in epoch 13, gen_loss = 0.8860419860300541, disc_loss = 0.022738662301018397
Trained batch 771 in epoch 13, gen_loss = 0.8858990137286754, disc_loss = 0.022717062417348246
Trained batch 772 in epoch 13, gen_loss = 0.885929974208057, disc_loss = 0.02269079771166879
Trained batch 773 in epoch 13, gen_loss = 0.8855173888132554, disc_loss = 0.02275881781307087
Trained batch 774 in epoch 13, gen_loss = 0.8856792966781124, disc_loss = 0.022732650163835064
Trained batch 775 in epoch 13, gen_loss = 0.8858112575313479, disc_loss = 0.023074824408280452
Trained batch 776 in epoch 13, gen_loss = 0.8857240464389707, disc_loss = 0.023051633458491504
Trained batch 777 in epoch 13, gen_loss = 0.8854742751176682, disc_loss = 0.02305189554684225
Trained batch 778 in epoch 13, gen_loss = 0.8855502324630727, disc_loss = 0.023027935368079896
Trained batch 779 in epoch 13, gen_loss = 0.8850498454310955, disc_loss = 0.023477608615287
Trained batch 780 in epoch 13, gen_loss = 0.8853429576880495, disc_loss = 0.023809596228665342
Trained batch 781 in epoch 13, gen_loss = 0.8854179144134302, disc_loss = 0.024112083837478523
Trained batch 782 in epoch 13, gen_loss = 0.8852633273997373, disc_loss = 0.0241338520635942
Trained batch 783 in epoch 13, gen_loss = 0.884848290826289, disc_loss = 0.02423283480591784
Trained batch 784 in epoch 13, gen_loss = 0.8846320101789608, disc_loss = 0.02421089648326583
Trained batch 785 in epoch 13, gen_loss = 0.8845250346809247, disc_loss = 0.024271573940375386
Trained batch 786 in epoch 13, gen_loss = 0.8844902419604673, disc_loss = 0.02426421536300068
Trained batch 787 in epoch 13, gen_loss = 0.884379973001589, disc_loss = 0.02426835997908794
Trained batch 788 in epoch 13, gen_loss = 0.8843649444093571, disc_loss = 0.024241563813572457
Trained batch 789 in epoch 13, gen_loss = 0.8844955688413185, disc_loss = 0.02421331992577334
Trained batch 790 in epoch 13, gen_loss = 0.8844120517165863, disc_loss = 0.024204674355523672
Trained batch 791 in epoch 13, gen_loss = 0.8844939042447191, disc_loss = 0.024178089592481623
Trained batch 792 in epoch 13, gen_loss = 0.8843935061748812, disc_loss = 0.024153375078249145
Trained batch 793 in epoch 13, gen_loss = 0.8843475808049329, disc_loss = 0.024131828718167003
Trained batch 794 in epoch 13, gen_loss = 0.884562122859295, disc_loss = 0.024116001089243364
Trained batch 795 in epoch 13, gen_loss = 0.8844911074593439, disc_loss = 0.024095846113938828
Trained batch 796 in epoch 13, gen_loss = 0.8846865245135246, disc_loss = 0.024069191547620595
Trained batch 797 in epoch 13, gen_loss = 0.8847443307924988, disc_loss = 0.02404988368587346
Trained batch 798 in epoch 13, gen_loss = 0.8849958019128281, disc_loss = 0.02403201225610524
Trained batch 799 in epoch 13, gen_loss = 0.8850998813286424, disc_loss = 0.024006720295565175
Trained batch 800 in epoch 13, gen_loss = 0.8853280522329233, disc_loss = 0.02398272829980734
Trained batch 801 in epoch 13, gen_loss = 0.8854057220672431, disc_loss = 0.023963518986202505
Trained batch 802 in epoch 13, gen_loss = 0.8854108715933257, disc_loss = 0.02394170669000755
Trained batch 803 in epoch 13, gen_loss = 0.8856305083751086, disc_loss = 0.023916561655746977
Trained batch 804 in epoch 13, gen_loss = 0.8859514530771267, disc_loss = 0.023890624542974415
Trained batch 805 in epoch 13, gen_loss = 0.8859845039344603, disc_loss = 0.023868949812294298
Trained batch 806 in epoch 13, gen_loss = 0.8861267032307172, disc_loss = 0.023845845708764756
Trained batch 807 in epoch 13, gen_loss = 0.8863480675707359, disc_loss = 0.023826074089126927
Trained batch 808 in epoch 13, gen_loss = 0.8865663540009663, disc_loss = 0.023800923896829567
Trained batch 809 in epoch 13, gen_loss = 0.8869129499167572, disc_loss = 0.023775664800012707
Trained batch 810 in epoch 13, gen_loss = 0.8869639830215938, disc_loss = 0.023750917433941785
Trained batch 811 in epoch 13, gen_loss = 0.8871198716054997, disc_loss = 0.023724380625953657
Trained batch 812 in epoch 13, gen_loss = 0.8870298712529233, disc_loss = 0.023704791280021002
Trained batch 813 in epoch 13, gen_loss = 0.8870876577547786, disc_loss = 0.023677151436219995
Trained batch 814 in epoch 13, gen_loss = 0.8868090665779231, disc_loss = 0.023703528301875346
Trained batch 815 in epoch 13, gen_loss = 0.8870280482532347, disc_loss = 0.023738426618561504
Trained batch 816 in epoch 13, gen_loss = 0.8873278674107579, disc_loss = 0.023712663871367664
Trained batch 817 in epoch 13, gen_loss = 0.8873651439738448, disc_loss = 0.023700625452361426
Trained batch 818 in epoch 13, gen_loss = 0.8875598706241347, disc_loss = 0.023674023885464537
Trained batch 819 in epoch 13, gen_loss = 0.8878338615705327, disc_loss = 0.023649526110594017
Trained batch 820 in epoch 13, gen_loss = 0.8881226959167532, disc_loss = 0.023622471835768676
Trained batch 821 in epoch 13, gen_loss = 0.8882223942346527, disc_loss = 0.02359572214745662
Trained batch 822 in epoch 13, gen_loss = 0.8883103556288259, disc_loss = 0.023569780929485265
Trained batch 823 in epoch 13, gen_loss = 0.8882771923197704, disc_loss = 0.02355119546345767
Trained batch 824 in epoch 13, gen_loss = 0.8880412037083597, disc_loss = 0.023599863216319742
Trained batch 825 in epoch 13, gen_loss = 0.8884734531941194, disc_loss = 0.023662697687585412
Trained batch 826 in epoch 13, gen_loss = 0.8889169980205388, disc_loss = 0.023647047678653253
Trained batch 827 in epoch 13, gen_loss = 0.8892541345262873, disc_loss = 0.02362625961497261
Trained batch 828 in epoch 13, gen_loss = 0.8895433074530704, disc_loss = 0.023603337134674288
Trained batch 829 in epoch 13, gen_loss = 0.8896473199129105, disc_loss = 0.02357839956703941
Trained batch 830 in epoch 13, gen_loss = 0.8898218932923571, disc_loss = 0.023552792479919978
Trained batch 831 in epoch 13, gen_loss = 0.890077762126636, disc_loss = 0.023527452846145443
Trained batch 832 in epoch 13, gen_loss = 0.8901778987976683, disc_loss = 0.02350300048321912
Trained batch 833 in epoch 13, gen_loss = 0.890280832954162, disc_loss = 0.02347594087030747
Trained batch 834 in epoch 13, gen_loss = 0.8903750121593476, disc_loss = 0.023448987324735358
Trained batch 835 in epoch 13, gen_loss = 0.8904029009373564, disc_loss = 0.02342217971334269
Trained batch 836 in epoch 13, gen_loss = 0.8903315160223233, disc_loss = 0.02341104767806792
Trained batch 837 in epoch 13, gen_loss = 0.8905848462783635, disc_loss = 0.0233857694117491
Trained batch 838 in epoch 13, gen_loss = 0.8907154551635056, disc_loss = 0.02336022590682967
Trained batch 839 in epoch 13, gen_loss = 0.8908173523843288, disc_loss = 0.023333946375887968
Trained batch 840 in epoch 13, gen_loss = 0.8909840365156407, disc_loss = 0.023307493449502024
Trained batch 841 in epoch 13, gen_loss = 0.8911563939195913, disc_loss = 0.023280634098467687
Trained batch 842 in epoch 13, gen_loss = 0.8912840619559531, disc_loss = 0.023254045170785286
Trained batch 843 in epoch 13, gen_loss = 0.8913688098579221, disc_loss = 0.02322715217570299
Trained batch 844 in epoch 13, gen_loss = 0.8915444665759272, disc_loss = 0.02320072664367793
Trained batch 845 in epoch 13, gen_loss = 0.8916387542835645, disc_loss = 0.02317384494126686
Trained batch 846 in epoch 13, gen_loss = 0.8916344336171359, disc_loss = 0.023147124690638
Trained batch 847 in epoch 13, gen_loss = 0.8917806067345839, disc_loss = 0.023120985855042957
Trained batch 848 in epoch 13, gen_loss = 0.8918261969960058, disc_loss = 0.02309443742506526
Trained batch 849 in epoch 13, gen_loss = 0.8918447746599422, disc_loss = 0.023067907353585777
Trained batch 850 in epoch 13, gen_loss = 0.8918423461087582, disc_loss = 0.023041278780948946
Trained batch 851 in epoch 13, gen_loss = 0.892228982992855, disc_loss = 0.02301513793910162
Trained batch 852 in epoch 13, gen_loss = 0.8923527977460993, disc_loss = 0.02298882430992736
Trained batch 853 in epoch 13, gen_loss = 0.8923915031014896, disc_loss = 0.0229625382609206
Trained batch 854 in epoch 13, gen_loss = 0.8923512363642977, disc_loss = 0.02293625569462229
Trained batch 855 in epoch 13, gen_loss = 0.8924940487143592, disc_loss = 0.022910201420340982
Trained batch 856 in epoch 13, gen_loss = 0.8925825596342565, disc_loss = 0.022884294935653575
Trained batch 857 in epoch 13, gen_loss = 0.8926508140105468, disc_loss = 0.02285843094323948
Trained batch 858 in epoch 13, gen_loss = 0.8926859786332834, disc_loss = 0.022832299770818663
Trained batch 859 in epoch 13, gen_loss = 0.8927721245690834, disc_loss = 0.02280624756749603
Trained batch 860 in epoch 13, gen_loss = 0.8929682633948797, disc_loss = 0.022780393982056932
Trained batch 861 in epoch 13, gen_loss = 0.8929727489945507, disc_loss = 0.022754447375200153
Trained batch 862 in epoch 13, gen_loss = 0.8928777613824931, disc_loss = 0.022728794709249045
Trained batch 863 in epoch 13, gen_loss = 0.8928225346392503, disc_loss = 0.022703321749742354
Trained batch 864 in epoch 13, gen_loss = 0.8929055437531774, disc_loss = 0.02267801781419484
Trained batch 865 in epoch 13, gen_loss = 0.8929889669801016, disc_loss = 0.022652508153523803
Trained batch 866 in epoch 13, gen_loss = 0.8930262126105879, disc_loss = 0.0226306347700268
Trained batch 867 in epoch 13, gen_loss = 0.8931035367505891, disc_loss = 0.022605314132884764
Trained batch 868 in epoch 13, gen_loss = 0.8932035031403716, disc_loss = 0.02257999053441743
Trained batch 869 in epoch 13, gen_loss = 0.8933131369023487, disc_loss = 0.0225548776279601
Trained batch 870 in epoch 13, gen_loss = 0.8934409580397688, disc_loss = 0.022529460395905927
Trained batch 871 in epoch 13, gen_loss = 0.8935052142435804, disc_loss = 0.02250414913650183
Trained batch 872 in epoch 13, gen_loss = 0.8933794584129547, disc_loss = 0.02247966108819348
Trained batch 873 in epoch 13, gen_loss = 0.8933698038146479, disc_loss = 0.022454933759508505
Trained batch 874 in epoch 13, gen_loss = 0.8935495250906264, disc_loss = 0.022430301113237093
Trained batch 875 in epoch 13, gen_loss = 0.893420307161329, disc_loss = 0.022405838935694325
Trained batch 876 in epoch 13, gen_loss = 0.8934524522471999, disc_loss = 0.02238104816820797
Trained batch 877 in epoch 13, gen_loss = 0.8936112418193752, disc_loss = 0.022356067518897887
Trained batch 878 in epoch 13, gen_loss = 0.8936707560180669, disc_loss = 0.02233112002643786
Trained batch 879 in epoch 13, gen_loss = 0.8937570306726478, disc_loss = 0.02230625196615702
Trained batch 880 in epoch 13, gen_loss = 0.8938879707276347, disc_loss = 0.022281391812970352
Trained batch 881 in epoch 13, gen_loss = 0.8940603081939442, disc_loss = 0.022257128331723518
Trained batch 882 in epoch 13, gen_loss = 0.8941846949935365, disc_loss = 0.02223235508260575
Trained batch 883 in epoch 13, gen_loss = 0.8942522261949146, disc_loss = 0.022207735954788203
Trained batch 884 in epoch 13, gen_loss = 0.8942267677541507, disc_loss = 0.022183002874575485
Trained batch 885 in epoch 13, gen_loss = 0.8941912255155313, disc_loss = 0.022158239037866057
Trained batch 886 in epoch 13, gen_loss = 0.8941983061484581, disc_loss = 0.02213351020846779
Trained batch 887 in epoch 13, gen_loss = 0.8942274060939346, disc_loss = 0.022108875381728704
Trained batch 888 in epoch 13, gen_loss = 0.8941846540526679, disc_loss = 0.02208461516376161
Trained batch 889 in epoch 13, gen_loss = 0.8941725914732793, disc_loss = 0.022060180539275085
Trained batch 890 in epoch 13, gen_loss = 0.8942951400472661, disc_loss = 0.02203593808442851
Trained batch 891 in epoch 13, gen_loss = 0.8941546064788986, disc_loss = 0.022013127676342722
Trained batch 892 in epoch 13, gen_loss = 0.89412878391991, disc_loss = 0.021988903995678804
Trained batch 893 in epoch 13, gen_loss = 0.8939976438513272, disc_loss = 0.0219648815153506
Trained batch 894 in epoch 13, gen_loss = 0.8938317864633806, disc_loss = 0.021940985397684815
Trained batch 895 in epoch 13, gen_loss = 0.8937074111974133, disc_loss = 0.02191683613294312
Trained batch 896 in epoch 13, gen_loss = 0.8936802560469778, disc_loss = 0.02189264075569131
Trained batch 897 in epoch 13, gen_loss = 0.8938511810151399, disc_loss = 0.021868618081433606
Trained batch 898 in epoch 13, gen_loss = 0.893719433909396, disc_loss = 0.021844754237837667
Trained batch 899 in epoch 13, gen_loss = 0.893884843952126, disc_loss = 0.021820804183225847
Trained batch 900 in epoch 13, gen_loss = 0.893846307921489, disc_loss = 0.021797280830958964
Trained batch 901 in epoch 13, gen_loss = 0.8937758439594257, disc_loss = 0.021773416445087335
Trained batch 902 in epoch 13, gen_loss = 0.8937264871293656, disc_loss = 0.02175084537462471
Trained batch 903 in epoch 13, gen_loss = 0.89346979720007, disc_loss = 0.021730291714472105
Trained batch 904 in epoch 13, gen_loss = 0.8934373077437364, disc_loss = 0.02170838886546807
Trained batch 905 in epoch 13, gen_loss = 0.8935296973974236, disc_loss = 0.02168548689270405
Trained batch 906 in epoch 13, gen_loss = 0.8934604638269481, disc_loss = 0.0216624457126155
Trained batch 907 in epoch 13, gen_loss = 0.8935721918677969, disc_loss = 0.02163943532610526
Trained batch 908 in epoch 13, gen_loss = 0.893716885082268, disc_loss = 0.021616275296206494
Trained batch 909 in epoch 13, gen_loss = 0.8937451357042396, disc_loss = 0.021593039027069168
Trained batch 910 in epoch 13, gen_loss = 0.893878712841237, disc_loss = 0.021569993460709234
Trained batch 911 in epoch 13, gen_loss = 0.8940160027133268, disc_loss = 0.021546701955916785
Trained batch 912 in epoch 13, gen_loss = 0.8940236701957498, disc_loss = 0.021523590429595098
Trained batch 913 in epoch 13, gen_loss = 0.8941257322447566, disc_loss = 0.021500895276873426
Trained batch 914 in epoch 13, gen_loss = 0.8940488332281998, disc_loss = 0.02147788973650806
Trained batch 915 in epoch 13, gen_loss = 0.8941195583434605, disc_loss = 0.021454805788157918
Trained batch 916 in epoch 13, gen_loss = 0.894137710072872, disc_loss = 0.02143184860571018
Trained batch 917 in epoch 13, gen_loss = 0.8939637141484841, disc_loss = 0.021409314549699895
Trained batch 918 in epoch 13, gen_loss = 0.8939973711643178, disc_loss = 0.021386459317863097
Trained batch 919 in epoch 13, gen_loss = 0.8940445435111938, disc_loss = 0.021363588621312848
Trained batch 920 in epoch 13, gen_loss = 0.8939315873753364, disc_loss = 0.021340769408310534
Trained batch 921 in epoch 13, gen_loss = 0.8940134518123242, disc_loss = 0.021317864700466486
Trained batch 922 in epoch 13, gen_loss = 0.8939791494498145, disc_loss = 0.021295540331358862
Trained batch 923 in epoch 13, gen_loss = 0.8940700793485621, disc_loss = 0.021272846209895755
Trained batch 924 in epoch 13, gen_loss = 0.89412762103854, disc_loss = 0.02125031147007453
Trained batch 925 in epoch 13, gen_loss = 0.8941694255073436, disc_loss = 0.021227615555158348
Trained batch 926 in epoch 13, gen_loss = 0.8941496592316427, disc_loss = 0.021205212256774842
Trained batch 927 in epoch 13, gen_loss = 0.8943159569632905, disc_loss = 0.02118273299576121
Trained batch 928 in epoch 13, gen_loss = 0.8944516438265021, disc_loss = 0.021160389637544855
Trained batch 929 in epoch 13, gen_loss = 0.8945019944060233, disc_loss = 0.0211380770673909
Trained batch 930 in epoch 13, gen_loss = 0.8945506557934266, disc_loss = 0.021115695184671768
Trained batch 931 in epoch 13, gen_loss = 0.8945534027505331, disc_loss = 0.02109338566935369
Trained batch 932 in epoch 13, gen_loss = 0.8945836099972679, disc_loss = 0.021070989672618515
Trained batch 933 in epoch 13, gen_loss = 0.894664088363821, disc_loss = 0.021048734239537525
Trained batch 934 in epoch 13, gen_loss = 0.8947431228058861, disc_loss = 0.0210267868886713
Trained batch 935 in epoch 13, gen_loss = 0.8946395739594586, disc_loss = 0.02100479560247814
Trained batch 936 in epoch 13, gen_loss = 0.8945607115199498, disc_loss = 0.02098271586184488
Trained batch 937 in epoch 13, gen_loss = 0.8946310883201262, disc_loss = 0.020960990987046794
Trained batch 938 in epoch 13, gen_loss = 0.8945574664269773, disc_loss = 0.020939334732882904
Trained batch 939 in epoch 13, gen_loss = 0.8946567497671919, disc_loss = 0.020917366792623106
Trained batch 940 in epoch 13, gen_loss = 0.8947118755418106, disc_loss = 0.020895455624050496
Trained batch 941 in epoch 13, gen_loss = 0.8947363639143622, disc_loss = 0.020873601703300618
Trained batch 942 in epoch 13, gen_loss = 0.894650802158475, disc_loss = 0.02085192748493886
Trained batch 943 in epoch 13, gen_loss = 0.8945771338007713, disc_loss = 0.020830138204180882
Trained batch 944 in epoch 13, gen_loss = 0.8944672082151686, disc_loss = 0.02080854498792043
Trained batch 945 in epoch 13, gen_loss = 0.8943990003041938, disc_loss = 0.020786794586779414
Trained batch 946 in epoch 13, gen_loss = 0.8942841814777793, disc_loss = 0.020765292561052338
Trained batch 947 in epoch 13, gen_loss = 0.8943277299089774, disc_loss = 0.02074374960066359
Trained batch 948 in epoch 13, gen_loss = 0.8943902312201871, disc_loss = 0.020722419249091482
Trained batch 949 in epoch 13, gen_loss = 0.894424120281872, disc_loss = 0.02070100399327011
Trained batch 950 in epoch 13, gen_loss = 0.8945214832054704, disc_loss = 0.02067966169619712
Trained batch 951 in epoch 13, gen_loss = 0.894474262919496, disc_loss = 0.020658239224139223
Trained batch 952 in epoch 13, gen_loss = 0.8945395774818793, disc_loss = 0.020636933445769844
Trained batch 953 in epoch 13, gen_loss = 0.8945389480898215, disc_loss = 0.02061568289966578
Trained batch 954 in epoch 13, gen_loss = 0.8944803105911036, disc_loss = 0.020594373970406487
Trained batch 955 in epoch 13, gen_loss = 0.8944391079839303, disc_loss = 0.02057314420689862
Trained batch 956 in epoch 13, gen_loss = 0.8943229050783279, disc_loss = 0.020552144341062888
Trained batch 957 in epoch 13, gen_loss = 0.8943568798781437, disc_loss = 0.020531277424252533
Trained batch 958 in epoch 13, gen_loss = 0.8942789837826778, disc_loss = 0.020510457845129063
Trained batch 959 in epoch 13, gen_loss = 0.8943294147960842, disc_loss = 0.020489812764465872
Trained batch 960 in epoch 13, gen_loss = 0.8942685514595456, disc_loss = 0.02046987801548503
Trained batch 961 in epoch 13, gen_loss = 0.8943516485346578, disc_loss = 0.02045001688254128
Trained batch 962 in epoch 13, gen_loss = 0.8942087633401805, disc_loss = 0.020430972496728095
Trained batch 963 in epoch 13, gen_loss = 0.8942236250799721, disc_loss = 0.020410443966582353
Trained batch 964 in epoch 13, gen_loss = 0.8943453251080192, disc_loss = 0.02039001132405322
Trained batch 965 in epoch 13, gen_loss = 0.8943560229263444, disc_loss = 0.020369827963077868
Trained batch 966 in epoch 13, gen_loss = 0.8943923543811214, disc_loss = 0.020351378893881923
Trained batch 967 in epoch 13, gen_loss = 0.8944764700987615, disc_loss = 0.020331455999086364
Trained batch 968 in epoch 13, gen_loss = 0.8943960093061745, disc_loss = 0.020311525306113326
Trained batch 969 in epoch 13, gen_loss = 0.8942743073726438, disc_loss = 0.020291083459109283
Trained batch 970 in epoch 13, gen_loss = 0.8942558641107149, disc_loss = 0.020270887072103737
Trained batch 971 in epoch 13, gen_loss = 0.8942582482479727, disc_loss = 0.020250601071564105
Trained batch 972 in epoch 13, gen_loss = 0.894276718839712, disc_loss = 0.020231143353097853
Trained batch 973 in epoch 13, gen_loss = 0.8943033704583895, disc_loss = 0.02021122582752396
Trained batch 974 in epoch 13, gen_loss = 0.8943754758895972, disc_loss = 0.020191227109843078
Trained batch 975 in epoch 13, gen_loss = 0.8945031466848049, disc_loss = 0.020171238014717957
Trained batch 976 in epoch 13, gen_loss = 0.8945930985430735, disc_loss = 0.020151030724516548
Trained batch 977 in epoch 13, gen_loss = 0.8947299080453279, disc_loss = 0.020131047449486187
Trained batch 978 in epoch 13, gen_loss = 0.8946794182884072, disc_loss = 0.02011132183902651
Trained batch 979 in epoch 13, gen_loss = 0.8948044183607005, disc_loss = 0.02009124283968977
Trained batch 980 in epoch 13, gen_loss = 0.8948675897447098, disc_loss = 0.020071190684596736
Trained batch 981 in epoch 13, gen_loss = 0.894862457260095, disc_loss = 0.02005112662077955
Trained batch 982 in epoch 13, gen_loss = 0.8949106800410658, disc_loss = 0.02003132273001719
Trained batch 983 in epoch 13, gen_loss = 0.8948179049402233, disc_loss = 0.020011871519088117
Trained batch 984 in epoch 13, gen_loss = 0.894905387961925, disc_loss = 0.01999229292459443
Trained batch 985 in epoch 13, gen_loss = 0.8948616018220329, disc_loss = 0.019972444398707778
Trained batch 986 in epoch 13, gen_loss = 0.8948874979335607, disc_loss = 0.019952734262930073
Trained batch 987 in epoch 13, gen_loss = 0.8950627478450416, disc_loss = 0.019933087815883967
Trained batch 988 in epoch 13, gen_loss = 0.8950834736243056, disc_loss = 0.019913367991653153
Trained batch 989 in epoch 13, gen_loss = 0.8950474712884787, disc_loss = 0.019893515862144103
Trained batch 990 in epoch 13, gen_loss = 0.8949905314250622, disc_loss = 0.01987379939110861
Trained batch 991 in epoch 13, gen_loss = 0.8949468282742365, disc_loss = 0.019854095321812974
Trained batch 992 in epoch 13, gen_loss = 0.8950402511870873, disc_loss = 0.019834658377858378
Trained batch 993 in epoch 13, gen_loss = 0.8949962776131793, disc_loss = 0.019815096104336866
Trained batch 994 in epoch 13, gen_loss = 0.8949201902252945, disc_loss = 0.019795746228791627
Trained batch 995 in epoch 13, gen_loss = 0.8949589244273293, disc_loss = 0.01977628072099066
Trained batch 996 in epoch 13, gen_loss = 0.8949321669525464, disc_loss = 0.01975690977522786
Trained batch 997 in epoch 13, gen_loss = 0.8949507340221462, disc_loss = 0.019737744425229922
Trained batch 998 in epoch 13, gen_loss = 0.8949014710055457, disc_loss = 0.019718621060109673
Trained batch 999 in epoch 13, gen_loss = 0.8948471697866917, disc_loss = 0.019700038943861728
Trained batch 1000 in epoch 13, gen_loss = 0.8947682861502949, disc_loss = 0.019680698251749573
Trained batch 1001 in epoch 13, gen_loss = 0.8948779051115889, disc_loss = 0.01966155945553043
Trained batch 1002 in epoch 13, gen_loss = 0.8948315134492971, disc_loss = 0.01964248689197077
Trained batch 1003 in epoch 13, gen_loss = 0.8948152989920867, disc_loss = 0.01962319972724698
Trained batch 1004 in epoch 13, gen_loss = 0.8947106802344915, disc_loss = 0.019604811089305063
Trained batch 1005 in epoch 13, gen_loss = 0.8946699606436147, disc_loss = 0.019585636935784564
Trained batch 1006 in epoch 13, gen_loss = 0.8948082171876238, disc_loss = 0.01956686566042718
Trained batch 1007 in epoch 13, gen_loss = 0.8948412559749115, disc_loss = 0.019547990144221532
Trained batch 1008 in epoch 13, gen_loss = 0.8948733808677662, disc_loss = 0.019529301158924508
Trained batch 1009 in epoch 13, gen_loss = 0.8948789480594125, disc_loss = 0.019510247451780562
Trained batch 1010 in epoch 13, gen_loss = 0.8949352806152151, disc_loss = 0.01949135940904537
Trained batch 1011 in epoch 13, gen_loss = 0.8950341886034596, disc_loss = 0.019472582669061423
Trained batch 1012 in epoch 13, gen_loss = 0.895021825146228, disc_loss = 0.019453697499948616
Trained batch 1013 in epoch 13, gen_loss = 0.8949584728455873, disc_loss = 0.01943511781141222
Trained batch 1014 in epoch 13, gen_loss = 0.8949016485014573, disc_loss = 0.0194163086615231
Trained batch 1015 in epoch 13, gen_loss = 0.8948414391126689, disc_loss = 0.019397843079514848
Trained batch 1016 in epoch 13, gen_loss = 0.8947656357124257, disc_loss = 0.019379260975188363
Trained batch 1017 in epoch 13, gen_loss = 0.8947501325712691, disc_loss = 0.019360710137137985
Trained batch 1018 in epoch 13, gen_loss = 0.8947992295289999, disc_loss = 0.01934224813808406
Trained batch 1019 in epoch 13, gen_loss = 0.8949428907504269, disc_loss = 0.019324635594039494
Trained batch 1020 in epoch 13, gen_loss = 0.8949909976425414, disc_loss = 0.01930608442845359
Trained batch 1021 in epoch 13, gen_loss = 0.8949115970654964, disc_loss = 0.01928787773934732
Trained batch 1022 in epoch 13, gen_loss = 0.8949819428888117, disc_loss = 0.019269364425488145
Trained batch 1023 in epoch 13, gen_loss = 0.8949758331582416, disc_loss = 0.019251102505606354
Trained batch 1024 in epoch 13, gen_loss = 0.8950516951084136, disc_loss = 0.019232697741784405
Trained batch 1025 in epoch 13, gen_loss = 0.8950301162738782, disc_loss = 0.019217291722329107
Trained batch 1026 in epoch 13, gen_loss = 0.8951201876217342, disc_loss = 0.019199254026088637
Trained batch 1027 in epoch 13, gen_loss = 0.8951175047903673, disc_loss = 0.019181284707572185
Trained batch 1028 in epoch 13, gen_loss = 0.8950287254547122, disc_loss = 0.019163034307942736
Trained batch 1029 in epoch 13, gen_loss = 0.8950064467284286, disc_loss = 0.01914476575752329
Trained batch 1030 in epoch 13, gen_loss = 0.8950130576710466, disc_loss = 0.019126880921467585
Trained batch 1031 in epoch 13, gen_loss = 0.895027294090783, disc_loss = 0.019108955845547105
Trained batch 1032 in epoch 13, gen_loss = 0.895023990087103, disc_loss = 0.019091711511710026
Trained batch 1033 in epoch 13, gen_loss = 0.8950728457889428, disc_loss = 0.019074179516445796
Trained batch 1034 in epoch 13, gen_loss = 0.8951190623396261, disc_loss = 0.019056506094043052
Trained batch 1035 in epoch 13, gen_loss = 0.8952228644122028, disc_loss = 0.019038755277372987
Trained batch 1036 in epoch 13, gen_loss = 0.8951917332359082, disc_loss = 0.019021217864661356
Trained batch 1037 in epoch 13, gen_loss = 0.8951701287302208, disc_loss = 0.019003320426683176
Trained batch 1038 in epoch 13, gen_loss = 0.8951414509446031, disc_loss = 0.018985649005202797
Trained batch 1039 in epoch 13, gen_loss = 0.8952687549189879, disc_loss = 0.018967817613394382
Trained batch 1040 in epoch 13, gen_loss = 0.8952963926778403, disc_loss = 0.018950339426984004
Trained batch 1041 in epoch 13, gen_loss = 0.8953254193410763, disc_loss = 0.018932680660908915
Trained batch 1042 in epoch 13, gen_loss = 0.8953238673943915, disc_loss = 0.018914893620891594
Trained batch 1043 in epoch 13, gen_loss = 0.8952738870206464, disc_loss = 0.018897034220251508
Trained batch 1044 in epoch 13, gen_loss = 0.895143857897754, disc_loss = 0.018888510191023826
Trained batch 1045 in epoch 13, gen_loss = 0.8950410247361911, disc_loss = 0.018873261743884363
Trained batch 1046 in epoch 13, gen_loss = 0.8949202734909404, disc_loss = 0.018864547448848648
Trained batch 1047 in epoch 13, gen_loss = 0.8950816410814078, disc_loss = 0.018847011139512284
Trained batch 1048 in epoch 13, gen_loss = 0.8950676827969383, disc_loss = 0.018830062121503455
Trained batch 1049 in epoch 13, gen_loss = 0.8950568787540708, disc_loss = 0.018812681095649687
Trained batch 1050 in epoch 13, gen_loss = 0.8950768503033468, disc_loss = 0.018795754026940475
Trained batch 1051 in epoch 13, gen_loss = 0.8950981596633508, disc_loss = 0.018778498777278108
Trained batch 1052 in epoch 13, gen_loss = 0.8951112215618575, disc_loss = 0.018761244525264304
Trained batch 1053 in epoch 13, gen_loss = 0.8950582523556316, disc_loss = 0.018743954234346424
Trained batch 1054 in epoch 13, gen_loss = 0.8950349194461136, disc_loss = 0.01872660998864402
Trained batch 1055 in epoch 13, gen_loss = 0.8949431094312759, disc_loss = 0.018709204139130717
Trained batch 1056 in epoch 13, gen_loss = 0.894826007007763, disc_loss = 0.018692155192530046
Trained batch 1057 in epoch 13, gen_loss = 0.894832218329938, disc_loss = 0.018674802383087642
Trained batch 1058 in epoch 13, gen_loss = 0.894760868395129, disc_loss = 0.018657365515681378
Trained batch 1059 in epoch 13, gen_loss = 0.8947328420461349, disc_loss = 0.018640125223244913
Trained batch 1060 in epoch 13, gen_loss = 0.8946579374815359, disc_loss = 0.018622845385255337
Trained batch 1061 in epoch 13, gen_loss = 0.8945433006055387, disc_loss = 0.018605563551308206
Trained batch 1062 in epoch 13, gen_loss = 0.8946013616876342, disc_loss = 0.01858841198661506
Trained batch 1063 in epoch 13, gen_loss = 0.8946591559937573, disc_loss = 0.018571502839229214
Trained batch 1064 in epoch 13, gen_loss = 0.8945664854396677, disc_loss = 0.01855460736402387
Trained batch 1065 in epoch 13, gen_loss = 0.8945527883844125, disc_loss = 0.01853755102690262
Trained batch 1066 in epoch 13, gen_loss = 0.8945932099778963, disc_loss = 0.018520471972252213
Trained batch 1067 in epoch 13, gen_loss = 0.894614192179303, disc_loss = 0.018503371876913966
Trained batch 1068 in epoch 13, gen_loss = 0.8945827614324354, disc_loss = 0.018486320999735975
Trained batch 1069 in epoch 13, gen_loss = 0.894535572200178, disc_loss = 0.01846930088392931
Trained batch 1070 in epoch 13, gen_loss = 0.8944743911480926, disc_loss = 0.01845236582281583
Trained batch 1071 in epoch 13, gen_loss = 0.8944526505726043, disc_loss = 0.018435357290943116
Trained batch 1072 in epoch 13, gen_loss = 0.8944833984968269, disc_loss = 0.018418503871594098
Trained batch 1073 in epoch 13, gen_loss = 0.8945177302624704, disc_loss = 0.01840177585076386
Trained batch 1074 in epoch 13, gen_loss = 0.8943641774321711, disc_loss = 0.01838571395907757
Trained batch 1075 in epoch 13, gen_loss = 0.8944375643222748, disc_loss = 0.01836945565923913
Trained batch 1076 in epoch 13, gen_loss = 0.8944554664021637, disc_loss = 0.018352879604964928
Trained batch 1077 in epoch 13, gen_loss = 0.894463750863783, disc_loss = 0.018336166426502595
Trained batch 1078 in epoch 13, gen_loss = 0.8945476247327432, disc_loss = 0.018319434702908987
Trained batch 1079 in epoch 13, gen_loss = 0.8946422333794611, disc_loss = 0.018302759422726078
Trained batch 1080 in epoch 13, gen_loss = 0.8945714662904325, disc_loss = 0.0182862374667324
Trained batch 1081 in epoch 13, gen_loss = 0.8945174769476029, disc_loss = 0.018269689133339248
Trained batch 1082 in epoch 13, gen_loss = 0.8944444779378886, disc_loss = 0.018253048705612698
Trained batch 1083 in epoch 13, gen_loss = 0.8943809795148698, disc_loss = 0.01823667807451536
Trained batch 1084 in epoch 13, gen_loss = 0.8944761207850848, disc_loss = 0.018220187155790046
Trained batch 1085 in epoch 13, gen_loss = 0.8944024987806931, disc_loss = 0.018203899845085685
Trained batch 1086 in epoch 13, gen_loss = 0.894302036061458, disc_loss = 0.018187769384146624
Trained batch 1087 in epoch 13, gen_loss = 0.8942883926005486, disc_loss = 0.01817136972018114
Trained batch 1088 in epoch 13, gen_loss = 0.8942490017830067, disc_loss = 0.018154972445571353
Trained batch 1089 in epoch 13, gen_loss = 0.8943769517021442, disc_loss = 0.018138661845589862
Trained batch 1090 in epoch 13, gen_loss = 0.8944523347888268, disc_loss = 0.01812234024118321
Trained batch 1091 in epoch 13, gen_loss = 0.8944903051296433, disc_loss = 0.018105922458814278
Trained batch 1092 in epoch 13, gen_loss = 0.8943893118997506, disc_loss = 0.018089658883607956
Trained batch 1093 in epoch 13, gen_loss = 0.8943215358246397, disc_loss = 0.01807366777214088
Trained batch 1094 in epoch 13, gen_loss = 0.8943749805835829, disc_loss = 0.018057425555636997
Trained batch 1095 in epoch 13, gen_loss = 0.8942751785753852, disc_loss = 0.018041428308400758
Trained batch 1096 in epoch 13, gen_loss = 0.8943310139553049, disc_loss = 0.01802529228182952
Trained batch 1097 in epoch 13, gen_loss = 0.8943744976283857, disc_loss = 0.018009148763070935
Trained batch 1098 in epoch 13, gen_loss = 0.8943726621886836, disc_loss = 0.01799316050475137
Trained batch 1099 in epoch 13, gen_loss = 0.8942745224183256, disc_loss = 0.017977105285178617
Trained batch 1100 in epoch 13, gen_loss = 0.8942093704907489, disc_loss = 0.01796129480030533
Trained batch 1101 in epoch 13, gen_loss = 0.8942384579491053, disc_loss = 0.017945198072689947
Trained batch 1102 in epoch 13, gen_loss = 0.8943119276304842, disc_loss = 0.017929151513341877
Trained batch 1103 in epoch 13, gen_loss = 0.8945057431262904, disc_loss = 0.017913810181304092
Trained batch 1104 in epoch 13, gen_loss = 0.8944862080645237, disc_loss = 0.017897986005296365
Trained batch 1105 in epoch 13, gen_loss = 0.8943766655962894, disc_loss = 0.017882423728109113
Trained batch 1106 in epoch 13, gen_loss = 0.8944373605427919, disc_loss = 0.017866563430946076
Trained batch 1107 in epoch 13, gen_loss = 0.894412374318937, disc_loss = 0.017850856436195862
Trained batch 1108 in epoch 13, gen_loss = 0.8943843187729016, disc_loss = 0.01783696246937856
Trained batch 1109 in epoch 13, gen_loss = 0.8945749974197096, disc_loss = 0.01782143200057567
Trained batch 1110 in epoch 13, gen_loss = 0.8946553125615382, disc_loss = 0.01780620739950558
Trained batch 1111 in epoch 13, gen_loss = 0.8947494817133859, disc_loss = 0.017790756761458644
Trained batch 1112 in epoch 13, gen_loss = 0.8948816772473361, disc_loss = 0.01777544265169682
Trained batch 1113 in epoch 13, gen_loss = 0.8948719435416603, disc_loss = 0.017759900739843057
Trained batch 1114 in epoch 13, gen_loss = 0.8949370731420047, disc_loss = 0.017744241721093897
Trained batch 1115 in epoch 13, gen_loss = 0.8948414866482058, disc_loss = 0.017728895185362775
Trained batch 1116 in epoch 13, gen_loss = 0.8948076106174353, disc_loss = 0.017713424222650768
Trained batch 1117 in epoch 13, gen_loss = 0.8948440625064061, disc_loss = 0.017698072433211982
Trained batch 1118 in epoch 13, gen_loss = 0.8948969534457636, disc_loss = 0.017682823670681164
Trained batch 1119 in epoch 13, gen_loss = 0.8949598811832922, disc_loss = 0.017667295572313637
Trained batch 1120 in epoch 13, gen_loss = 0.8950286146841551, disc_loss = 0.01765179231036043
Trained batch 1121 in epoch 13, gen_loss = 0.8951061978644016, disc_loss = 0.017636277724217015
Trained batch 1122 in epoch 13, gen_loss = 0.8950564372730595, disc_loss = 0.017620982402269683
Trained batch 1123 in epoch 13, gen_loss = 0.8951086665758883, disc_loss = 0.0176055316287764
Trained batch 1124 in epoch 13, gen_loss = 0.8951446417967478, disc_loss = 0.017590124970250247
Trained batch 1125 in epoch 13, gen_loss = 0.8951388650158583, disc_loss = 0.017574681706368722
Trained batch 1126 in epoch 13, gen_loss = 0.8951459044942628, disc_loss = 0.017559267757314312
Trained batch 1127 in epoch 13, gen_loss = 0.8951137786374447, disc_loss = 0.017543837351811507
Trained batch 1128 in epoch 13, gen_loss = 0.8950876769658419, disc_loss = 0.017528584007501367
Trained batch 1129 in epoch 13, gen_loss = 0.8950859807497632, disc_loss = 0.01751334796026318
Trained batch 1130 in epoch 13, gen_loss = 0.8950518763613426, disc_loss = 0.01749806298565679
Trained batch 1131 in epoch 13, gen_loss = 0.8950252838090536, disc_loss = 0.01748288932712035
Trained batch 1132 in epoch 13, gen_loss = 0.8950472577472546, disc_loss = 0.017467656795821476
Trained batch 1133 in epoch 13, gen_loss = 0.8951566958080523, disc_loss = 0.01745258600612381
Trained batch 1134 in epoch 13, gen_loss = 0.8951946842775471, disc_loss = 0.017437590390588936
Trained batch 1135 in epoch 13, gen_loss = 0.8951225433183808, disc_loss = 0.017422411859653538
Trained batch 1136 in epoch 13, gen_loss = 0.8951603561351461, disc_loss = 0.017407306973969753
Trained batch 1137 in epoch 13, gen_loss = 0.89504321919908, disc_loss = 0.017392394144765958
Trained batch 1138 in epoch 13, gen_loss = 0.8949953955291551, disc_loss = 0.017377259024192807
Trained batch 1139 in epoch 13, gen_loss = 0.8949338467236151, disc_loss = 0.01736224855328481
Trained batch 1140 in epoch 13, gen_loss = 0.8948620989017587, disc_loss = 0.017347414935557425
Trained batch 1141 in epoch 13, gen_loss = 0.8947904637889144, disc_loss = 0.017332715139063336
Trained batch 1142 in epoch 13, gen_loss = 0.8947466350863716, disc_loss = 0.017317669892612127
Trained batch 1143 in epoch 13, gen_loss = 0.8947558552287258, disc_loss = 0.01730278767621445
Trained batch 1144 in epoch 13, gen_loss = 0.8946781451264844, disc_loss = 0.017287968934333667
Trained batch 1145 in epoch 13, gen_loss = 0.8947425599341617, disc_loss = 0.017273177136408035
Trained batch 1146 in epoch 13, gen_loss = 0.8947735802183592, disc_loss = 0.017258331442416022
Trained batch 1147 in epoch 13, gen_loss = 0.8947908992291743, disc_loss = 0.01724349394934909
Trained batch 1148 in epoch 13, gen_loss = 0.8948436869394271, disc_loss = 0.017228649143362418
Trained batch 1149 in epoch 13, gen_loss = 0.894809045765711, disc_loss = 0.017213882452950042
Trained batch 1150 in epoch 13, gen_loss = 0.8947412519999736, disc_loss = 0.017199220553780464
Trained batch 1151 in epoch 13, gen_loss = 0.8947523423832737, disc_loss = 0.017184456646999833
Trained batch 1152 in epoch 13, gen_loss = 0.8947209466413529, disc_loss = 0.01716982013470104
Trained batch 1153 in epoch 13, gen_loss = 0.8947214805738971, disc_loss = 0.01715508973204464
Trained batch 1154 in epoch 13, gen_loss = 0.8947871067565241, disc_loss = 0.017140447026425046
Trained batch 1155 in epoch 13, gen_loss = 0.8946509417726507, disc_loss = 0.01712603359761129
Trained batch 1156 in epoch 13, gen_loss = 0.8947371898948271, disc_loss = 0.017111400215373482
Trained batch 1157 in epoch 13, gen_loss = 0.8946684534840016, disc_loss = 0.01709690652096281
Trained batch 1158 in epoch 13, gen_loss = 0.8945968081922342, disc_loss = 0.0170824136855821
Trained batch 1159 in epoch 13, gen_loss = 0.8946538744558548, disc_loss = 0.0170679730419767
Trained batch 1160 in epoch 13, gen_loss = 0.8946529898173228, disc_loss = 0.017053748730288414
Trained batch 1161 in epoch 13, gen_loss = 0.8945736636034183, disc_loss = 0.017039406131647936
Trained batch 1162 in epoch 13, gen_loss = 0.8945164379382687, disc_loss = 0.0170257106478908
Trained batch 1163 in epoch 13, gen_loss = 0.8945849951855915, disc_loss = 0.0170113187309856
Trained batch 1164 in epoch 13, gen_loss = 0.8946223386111689, disc_loss = 0.016997137967816378
Trained batch 1165 in epoch 13, gen_loss = 0.8945095107905042, disc_loss = 0.016986551759157018
Trained batch 1166 in epoch 13, gen_loss = 0.894580090285982, disc_loss = 0.016972806955090264
Trained batch 1167 in epoch 13, gen_loss = 0.8945221173998019, disc_loss = 0.01695900651142039
Trained batch 1168 in epoch 13, gen_loss = 0.8944600475099578, disc_loss = 0.016945314158910468
Trained batch 1169 in epoch 13, gen_loss = 0.8943379359622287, disc_loss = 0.016998068742644597
Trained batch 1170 in epoch 13, gen_loss = 0.894393078620163, disc_loss = 0.01699011378300372
Trained batch 1171 in epoch 13, gen_loss = 0.8943286094903539, disc_loss = 0.016983509463314804
Trained batch 1172 in epoch 13, gen_loss = 0.8943273962458687, disc_loss = 0.01697283544076616
Trained batch 1173 in epoch 13, gen_loss = 0.8943369988942268, disc_loss = 0.016959045272807092
Trained batch 1174 in epoch 13, gen_loss = 0.8943648211245842, disc_loss = 0.016945170892608115
Trained batch 1175 in epoch 13, gen_loss = 0.894383365782548, disc_loss = 0.016931359485380465
Trained batch 1176 in epoch 13, gen_loss = 0.8944059677972769, disc_loss = 0.016917581446836274
Trained batch 1177 in epoch 13, gen_loss = 0.8943947728451322, disc_loss = 0.016903605817683045
Trained batch 1178 in epoch 13, gen_loss = 0.8943156294897515, disc_loss = 0.01688946332703564
Trained batch 1179 in epoch 13, gen_loss = 0.8943741577914206, disc_loss = 0.01687638538750727
Trained batch 1180 in epoch 13, gen_loss = 0.8943625893207247, disc_loss = 0.016862370725230717
Trained batch 1181 in epoch 13, gen_loss = 0.894363827839519, disc_loss = 0.016848437532510425
Trained batch 1182 in epoch 13, gen_loss = 0.8943199677328285, disc_loss = 0.016835488790649836
Trained batch 1183 in epoch 13, gen_loss = 0.8943354515862223, disc_loss = 0.01682160797966119
Trained batch 1184 in epoch 13, gen_loss = 0.894294469693542, disc_loss = 0.01680775019331621
Trained batch 1185 in epoch 13, gen_loss = 0.8944026235032444, disc_loss = 0.016794061955625703
Trained batch 1186 in epoch 13, gen_loss = 0.8942431601889513, disc_loss = 0.01678039890671278
Trained batch 1187 in epoch 13, gen_loss = 0.8942216200007734, disc_loss = 0.016766546101941705
Trained batch 1188 in epoch 13, gen_loss = 0.8942788252567824, disc_loss = 0.016752736400102525
Trained batch 1189 in epoch 13, gen_loss = 0.8942984551692209, disc_loss = 0.016738919061038766
Trained batch 1190 in epoch 13, gen_loss = 0.8943266989452112, disc_loss = 0.016725108343556092
Trained batch 1191 in epoch 13, gen_loss = 0.8942672425018461, disc_loss = 0.016711404200498464
Trained batch 1192 in epoch 13, gen_loss = 0.8943652571846433, disc_loss = 0.016697618490858733
Trained batch 1193 in epoch 13, gen_loss = 0.8943651153064852, disc_loss = 0.0166842007524221
Trained batch 1194 in epoch 13, gen_loss = 0.8942954064662486, disc_loss = 0.016670750923735815
Trained batch 1195 in epoch 13, gen_loss = 0.8942635757319106, disc_loss = 0.016657047005206052
Trained batch 1196 in epoch 13, gen_loss = 0.8942702065782937, disc_loss = 0.016643434724988436
Trained batch 1197 in epoch 13, gen_loss = 0.8942688532633853, disc_loss = 0.016629874821140984
Trained batch 1198 in epoch 13, gen_loss = 0.8941578515327603, disc_loss = 0.016616492853003314
Trained batch 1199 in epoch 13, gen_loss = 0.894173813338081, disc_loss = 0.01660293259841031
Trained batch 1200 in epoch 13, gen_loss = 0.8942093520388814, disc_loss = 0.01658928607910905
Trained batch 1201 in epoch 13, gen_loss = 0.8942396529452773, disc_loss = 0.01657583280933078
Trained batch 1202 in epoch 13, gen_loss = 0.8942184496550192, disc_loss = 0.016562355953006553
Trained batch 1203 in epoch 13, gen_loss = 0.8942689232008402, disc_loss = 0.0165489532468732
Trained batch 1204 in epoch 13, gen_loss = 0.8942481693143172, disc_loss = 0.016535623203873678
Trained batch 1205 in epoch 13, gen_loss = 0.8942710898853653, disc_loss = 0.016522375117684965
Trained batch 1206 in epoch 13, gen_loss = 0.8942208123928076, disc_loss = 0.016509252430896883
Trained batch 1207 in epoch 13, gen_loss = 0.8942252320317637, disc_loss = 0.01649595081496786
Trained batch 1208 in epoch 13, gen_loss = 0.8941739712548316, disc_loss = 0.016482520566080315
Trained batch 1209 in epoch 13, gen_loss = 0.8942084331896679, disc_loss = 0.016469368442336447
Trained batch 1210 in epoch 13, gen_loss = 0.8941903181995468, disc_loss = 0.016456061703353196
Trained batch 1211 in epoch 13, gen_loss = 0.8941195100890135, disc_loss = 0.016442890957207936
Trained batch 1212 in epoch 13, gen_loss = 0.8941293940844854, disc_loss = 0.016430310106855743
Trained batch 1213 in epoch 13, gen_loss = 0.8936879502293306, disc_loss = 0.016828513353256278
Trained batch 1214 in epoch 13, gen_loss = 0.8933218881671812, disc_loss = 0.017055082352199102
Trained batch 1215 in epoch 13, gen_loss = 0.8930593320462656, disc_loss = 0.017252970199275585
Trained batch 1216 in epoch 13, gen_loss = 0.8928519996004018, disc_loss = 0.017430423031531517
Trained batch 1217 in epoch 13, gen_loss = 0.8929240079397834, disc_loss = 0.017539771118117494
Trained batch 1218 in epoch 13, gen_loss = 0.8930172629049316, disc_loss = 0.017571933650406605
Trained batch 1219 in epoch 13, gen_loss = 0.8931366328577526, disc_loss = 0.017568134968767808
Trained batch 1220 in epoch 13, gen_loss = 0.8932216026126899, disc_loss = 0.017559137318521583
Trained batch 1221 in epoch 13, gen_loss = 0.8932967981271775, disc_loss = 0.017549467113378413
Trained batch 1222 in epoch 13, gen_loss = 0.8933406624994801, disc_loss = 0.01753832467618021
Trained batch 1223 in epoch 13, gen_loss = 0.8934045579844441, disc_loss = 0.01752542760876322
Trained batch 1224 in epoch 13, gen_loss = 0.8935571599249937, disc_loss = 0.017512165975497977
Trained batch 1225 in epoch 13, gen_loss = 0.8935808389892781, disc_loss = 0.017498364392029432
Trained batch 1226 in epoch 13, gen_loss = 0.8936797065907799, disc_loss = 0.017485475539542054
Trained batch 1227 in epoch 13, gen_loss = 0.8937406163990304, disc_loss = 0.017471730970003145
Trained batch 1228 in epoch 13, gen_loss = 0.8938065666168855, disc_loss = 0.017458253709547372
Trained batch 1229 in epoch 13, gen_loss = 0.8938456333507367, disc_loss = 0.01744439671107339
Trained batch 1230 in epoch 13, gen_loss = 0.8938319602940356, disc_loss = 0.017430754061759476
Trained batch 1231 in epoch 13, gen_loss = 0.893851083570293, disc_loss = 0.01741702241349242
Trained batch 1232 in epoch 13, gen_loss = 0.8937733421602195, disc_loss = 0.017403351425531545
Trained batch 1233 in epoch 13, gen_loss = 0.8937507363298917, disc_loss = 0.017389631374459206
Trained batch 1234 in epoch 13, gen_loss = 0.8937712639208265, disc_loss = 0.01737627587701818
Trained batch 1235 in epoch 13, gen_loss = 0.8938842976893808, disc_loss = 0.017362839404451092
Trained batch 1236 in epoch 13, gen_loss = 0.8939035700855471, disc_loss = 0.017349204062736892
Trained batch 1237 in epoch 13, gen_loss = 0.893838547567366, disc_loss = 0.01733554961559333
Trained batch 1238 in epoch 13, gen_loss = 0.8938071317640016, disc_loss = 0.017322178639910226
Trained batch 1239 in epoch 13, gen_loss = 0.8937618162603148, disc_loss = 0.017308534907574686
Trained batch 1240 in epoch 13, gen_loss = 0.8937235770208234, disc_loss = 0.017294915571241184
Trained batch 1241 in epoch 13, gen_loss = 0.8937663316198785, disc_loss = 0.017281369636541186
Trained batch 1242 in epoch 13, gen_loss = 0.8938330449553525, disc_loss = 0.017267990780084234
Trained batch 1243 in epoch 13, gen_loss = 0.893798252513746, disc_loss = 0.01725434803795693
Trained batch 1244 in epoch 13, gen_loss = 0.893767858389391, disc_loss = 0.01724076138220935
Trained batch 1245 in epoch 13, gen_loss = 0.893728956340978, disc_loss = 0.017227129097585548
Trained batch 1246 in epoch 13, gen_loss = 0.89369895624082, disc_loss = 0.01721372746043223
Trained batch 1247 in epoch 13, gen_loss = 0.8935658118138329, disc_loss = 0.017200390662450306
Trained batch 1248 in epoch 13, gen_loss = 0.8935937970948277, disc_loss = 0.017186856522713526
Trained batch 1249 in epoch 13, gen_loss = 0.8935604630708694, disc_loss = 0.01717339076375356
Trained batch 1250 in epoch 13, gen_loss = 0.8934954730488605, disc_loss = 0.017159820100953554
Trained batch 1251 in epoch 13, gen_loss = 0.8935356477912242, disc_loss = 0.017146386109133414
Trained batch 1252 in epoch 13, gen_loss = 0.8935210016709942, disc_loss = 0.01713305156853699
Trained batch 1253 in epoch 13, gen_loss = 0.8935187649831438, disc_loss = 0.017119585782862948
Trained batch 1254 in epoch 13, gen_loss = 0.8934840693179354, disc_loss = 0.017106159340204815
Trained batch 1255 in epoch 13, gen_loss = 0.8935203839591734, disc_loss = 0.01709284969509064
Trained batch 1256 in epoch 13, gen_loss = 0.8935188638993266, disc_loss = 0.017079461851685053
Trained batch 1257 in epoch 13, gen_loss = 0.893512953090554, disc_loss = 0.017066087146266604
Trained batch 1258 in epoch 13, gen_loss = 0.8935854652980852, disc_loss = 0.017052777771544615
Trained batch 1259 in epoch 13, gen_loss = 0.8936228975653648, disc_loss = 0.01703940312546033
Trained batch 1260 in epoch 13, gen_loss = 0.8936531925418848, disc_loss = 0.017026110180883233
Trained batch 1261 in epoch 13, gen_loss = 0.893693056116958, disc_loss = 0.01701279162039669
Trained batch 1262 in epoch 13, gen_loss = 0.8936002404323572, disc_loss = 0.016999490464104636
Trained batch 1263 in epoch 13, gen_loss = 0.8935530468397126, disc_loss = 0.016986265525299096
Trained batch 1264 in epoch 13, gen_loss = 0.893662725960313, disc_loss = 0.01697327613649041
Trained batch 1265 in epoch 13, gen_loss = 0.89357609411269, disc_loss = 0.016960234873782197
Trained batch 1266 in epoch 13, gen_loss = 0.8935839471472655, disc_loss = 0.016947032772746097
Trained batch 1267 in epoch 13, gen_loss = 0.8935471619670323, disc_loss = 0.01693393596498408
Trained batch 1268 in epoch 13, gen_loss = 0.8935353781079758, disc_loss = 0.01692074604673574
Trained batch 1269 in epoch 13, gen_loss = 0.8935010605205701, disc_loss = 0.016907603261608714
Trained batch 1270 in epoch 13, gen_loss = 0.8934009969234467, disc_loss = 0.016894521448074913
Trained batch 1271 in epoch 13, gen_loss = 0.8935055627997192, disc_loss = 0.01688150163005597
Trained batch 1272 in epoch 13, gen_loss = 0.8935011107670633, disc_loss = 0.0168683550535175
Trained batch 1273 in epoch 13, gen_loss = 0.893532642319775, disc_loss = 0.01685525146070632
Trained batch 1274 in epoch 13, gen_loss = 0.89349133774346, disc_loss = 0.016842133373663505
Trained batch 1275 in epoch 13, gen_loss = 0.8935405005902333, disc_loss = 0.016829085966449362
Trained batch 1276 in epoch 13, gen_loss = 0.8935527812015664, disc_loss = 0.016816094733183285
Trained batch 1277 in epoch 13, gen_loss = 0.893583218000118, disc_loss = 0.016803079403659306
Trained batch 1278 in epoch 13, gen_loss = 0.8935133774034487, disc_loss = 0.016790021772483114
Trained batch 1279 in epoch 13, gen_loss = 0.8935166892362758, disc_loss = 0.016777013081355107
Trained batch 1280 in epoch 13, gen_loss = 0.8934806296594622, disc_loss = 0.016764037147291393
Trained batch 1281 in epoch 13, gen_loss = 0.8935081718631914, disc_loss = 0.016751174286748688
Trained batch 1282 in epoch 13, gen_loss = 0.8935406272381614, disc_loss = 0.01673834719574471
Trained batch 1283 in epoch 13, gen_loss = 0.893558671146724, disc_loss = 0.016725412925260686
Trained batch 1284 in epoch 13, gen_loss = 0.8934694516287703, disc_loss = 0.01671257523385172
Trained batch 1285 in epoch 13, gen_loss = 0.8934284240748982, disc_loss = 0.016699744941920464
Trained batch 1286 in epoch 13, gen_loss = 0.8933706641799272, disc_loss = 0.016686927735529263
Trained batch 1287 in epoch 13, gen_loss = 0.8933133576643764, disc_loss = 0.01667408476451382
Trained batch 1288 in epoch 13, gen_loss = 0.8933722582364656, disc_loss = 0.01666131689228073
Trained batch 1289 in epoch 13, gen_loss = 0.893363845140435, disc_loss = 0.016648530604587614
Trained batch 1290 in epoch 13, gen_loss = 0.8933867278669714, disc_loss = 0.01663578333983338
Trained batch 1291 in epoch 13, gen_loss = 0.8933977021290791, disc_loss = 0.016623188533149202
Trained batch 1292 in epoch 13, gen_loss = 0.8934998208713089, disc_loss = 0.016610535989316597
Trained batch 1293 in epoch 13, gen_loss = 0.8934763157524318, disc_loss = 0.01659804774898148
Trained batch 1294 in epoch 13, gen_loss = 0.8935192307220002, disc_loss = 0.016585564014825943
Trained batch 1295 in epoch 13, gen_loss = 0.8934848685921343, disc_loss = 0.016572869340018736
Trained batch 1296 in epoch 13, gen_loss = 0.8935359298447599, disc_loss = 0.01656025799105808
Trained batch 1297 in epoch 13, gen_loss = 0.8934980755089243, disc_loss = 0.016547649161300807
Trained batch 1298 in epoch 13, gen_loss = 0.8935305318114756, disc_loss = 0.016535053780866827
Trained batch 1299 in epoch 13, gen_loss = 0.8935282327807866, disc_loss = 0.01652245648684374
Trained batch 1300 in epoch 13, gen_loss = 0.8935156729613516, disc_loss = 0.016509988376837464
Trained batch 1301 in epoch 13, gen_loss = 0.8934772236418614, disc_loss = 0.016497550122845796
Trained batch 1302 in epoch 13, gen_loss = 0.893420581143358, disc_loss = 0.016485046506236636
Trained batch 1303 in epoch 13, gen_loss = 0.8934340538011373, disc_loss = 0.016472691239260973
Trained batch 1304 in epoch 13, gen_loss = 0.8934674719969432, disc_loss = 0.016460179676285273
Trained batch 1305 in epoch 13, gen_loss = 0.8934924986105053, disc_loss = 0.016447896280845718
Trained batch 1306 in epoch 13, gen_loss = 0.8934301863258453, disc_loss = 0.016435473058023578
Trained batch 1307 in epoch 13, gen_loss = 0.8933907454941615, disc_loss = 0.016423039832514665
Trained batch 1308 in epoch 13, gen_loss = 0.8934388353544123, disc_loss = 0.01641071899171945
Trained batch 1309 in epoch 13, gen_loss = 0.8933492038768667, disc_loss = 0.0163983128726294
Trained batch 1310 in epoch 13, gen_loss = 0.8933993404508092, disc_loss = 0.0163859156860846
Trained batch 1311 in epoch 13, gen_loss = 0.8934486445448384, disc_loss = 0.01637365673018283
Trained batch 1312 in epoch 13, gen_loss = 0.8935134154599038, disc_loss = 0.016361319090956814
Trained batch 1313 in epoch 13, gen_loss = 0.8934300339793506, disc_loss = 0.0163491165896777
Trained batch 1314 in epoch 13, gen_loss = 0.8934105938605029, disc_loss = 0.016336825966614586
Trained batch 1315 in epoch 13, gen_loss = 0.8934210629675163, disc_loss = 0.016324588276556355
Trained batch 1316 in epoch 13, gen_loss = 0.8934895494668522, disc_loss = 0.01631235466092737
Trained batch 1317 in epoch 13, gen_loss = 0.8935105223802225, disc_loss = 0.016300166521615957
Trained batch 1318 in epoch 13, gen_loss = 0.8934966124441698, disc_loss = 0.016287900521455907
Trained batch 1319 in epoch 13, gen_loss = 0.8934693406251344, disc_loss = 0.01627571205893522
Trained batch 1320 in epoch 13, gen_loss = 0.8934877857080831, disc_loss = 0.01626356086683856
Trained batch 1321 in epoch 13, gen_loss = 0.8934861879440732, disc_loss = 0.01625133546601323
Trained batch 1322 in epoch 13, gen_loss = 0.8935835289171223, disc_loss = 0.016239216361195817
Trained batch 1323 in epoch 13, gen_loss = 0.8936171938420423, disc_loss = 0.016227079496536144
Trained batch 1324 in epoch 13, gen_loss = 0.8936680110670485, disc_loss = 0.016214921256386728
Trained batch 1325 in epoch 13, gen_loss = 0.8936765885505921, disc_loss = 0.016202958571401686
Trained batch 1326 in epoch 13, gen_loss = 0.8937565029655621, disc_loss = 0.016190876561083575
Trained batch 1327 in epoch 13, gen_loss = 0.8936869105974953, disc_loss = 0.01617893026685628
Trained batch 1328 in epoch 13, gen_loss = 0.8937146573294545, disc_loss = 0.016166875544164443
Trained batch 1329 in epoch 13, gen_loss = 0.8937630814941306, disc_loss = 0.01615488970277155
Trained batch 1330 in epoch 13, gen_loss = 0.893840048408974, disc_loss = 0.01614296886509555
Trained batch 1331 in epoch 13, gen_loss = 0.8937980387885649, disc_loss = 0.016130984113610233
Trained batch 1332 in epoch 13, gen_loss = 0.8938411373843489, disc_loss = 0.016118995425779464
Trained batch 1333 in epoch 13, gen_loss = 0.8938432059500707, disc_loss = 0.016107058223123392
Trained batch 1334 in epoch 13, gen_loss = 0.8939144347714127, disc_loss = 0.016095225804314026
Trained batch 1335 in epoch 13, gen_loss = 0.8938901510736542, disc_loss = 0.01608334425315503
Trained batch 1336 in epoch 13, gen_loss = 0.8939280176260798, disc_loss = 0.01607144565372486
Trained batch 1337 in epoch 13, gen_loss = 0.8938892987766964, disc_loss = 0.01605952166250286
Trained batch 1338 in epoch 13, gen_loss = 0.8938715935777247, disc_loss = 0.01604759718515424
Trained batch 1339 in epoch 13, gen_loss = 0.8938270820388153, disc_loss = 0.016035795770455222
Trained batch 1340 in epoch 13, gen_loss = 0.8938367834605004, disc_loss = 0.016023983097783485
Trained batch 1341 in epoch 13, gen_loss = 0.8938942342197131, disc_loss = 0.016012160099696957
Trained batch 1342 in epoch 13, gen_loss = 0.8939039377205779, disc_loss = 0.01600032070474947
Trained batch 1343 in epoch 13, gen_loss = 0.8938756611952114, disc_loss = 0.015988485980848226
Trained batch 1344 in epoch 13, gen_loss = 0.8938593928033978, disc_loss = 0.015976687201757944
Trained batch 1345 in epoch 13, gen_loss = 0.8938147235014109, disc_loss = 0.015964892470228288
Trained batch 1346 in epoch 13, gen_loss = 0.8939009861275277, disc_loss = 0.01595316995305392
Trained batch 1347 in epoch 13, gen_loss = 0.8939065482876422, disc_loss = 0.01594143439838357
Trained batch 1348 in epoch 13, gen_loss = 0.8938636400020944, disc_loss = 0.01592976966243012
Trained batch 1349 in epoch 13, gen_loss = 0.8938592873016993, disc_loss = 0.01591810321934409
Trained batch 1350 in epoch 13, gen_loss = 0.893823292611, disc_loss = 0.015906436424370222
Trained batch 1351 in epoch 13, gen_loss = 0.8938267217982098, disc_loss = 0.015894744541750182
Trained batch 1352 in epoch 13, gen_loss = 0.8937827310162126, disc_loss = 0.015883095307788767
Trained batch 1353 in epoch 13, gen_loss = 0.8938166008081887, disc_loss = 0.01587147886396235
Trained batch 1354 in epoch 13, gen_loss = 0.8937755711624104, disc_loss = 0.01585990114541225
Trained batch 1355 in epoch 13, gen_loss = 0.8937821409563399, disc_loss = 0.015848309634045234
Trained batch 1356 in epoch 13, gen_loss = 0.893840788147778, disc_loss = 0.015836761921242764
Trained batch 1357 in epoch 13, gen_loss = 0.8939341507928887, disc_loss = 0.015825385171483075
Trained batch 1358 in epoch 13, gen_loss = 0.8939540717994755, disc_loss = 0.015813916665254543
Trained batch 1359 in epoch 13, gen_loss = 0.8938560101696673, disc_loss = 0.015802671830795804
Trained batch 1360 in epoch 13, gen_loss = 0.8938076841007866, disc_loss = 0.015791239126238872
Trained batch 1361 in epoch 13, gen_loss = 0.8937418729329424, disc_loss = 0.015779754594800265
Trained batch 1362 in epoch 13, gen_loss = 0.8936665904539435, disc_loss = 0.015768268476017627
Trained batch 1363 in epoch 13, gen_loss = 0.8937364206417215, disc_loss = 0.015756973512005785
Trained batch 1364 in epoch 13, gen_loss = 0.8937161979876158, disc_loss = 0.015745504884265283
Trained batch 1365 in epoch 13, gen_loss = 0.8936917183383492, disc_loss = 0.01573407610269618
Trained batch 1366 in epoch 13, gen_loss = 0.8936839165396296, disc_loss = 0.015722647190891996
Trained batch 1367 in epoch 13, gen_loss = 0.8935884501109694, disc_loss = 0.01571123415339427
Trained batch 1368 in epoch 13, gen_loss = 0.8935080106847038, disc_loss = 0.01569992007183186
Trained batch 1369 in epoch 13, gen_loss = 0.8934605143583604, disc_loss = 0.015688532024966537
Trained batch 1370 in epoch 13, gen_loss = 0.8934142731515966, disc_loss = 0.01567714795530356
Trained batch 1371 in epoch 13, gen_loss = 0.893414395565368, disc_loss = 0.01566584202086201
Trained batch 1372 in epoch 13, gen_loss = 0.8934565146344471, disc_loss = 0.015654658080613764
Trained batch 1373 in epoch 13, gen_loss = 0.8934822768146468, disc_loss = 0.01564342013271188
Trained batch 1374 in epoch 13, gen_loss = 0.8935291446555744, disc_loss = 0.01563222135439388
Trained batch 1375 in epoch 13, gen_loss = 0.8934832063915078, disc_loss = 0.015620966634456678
Trained batch 1376 in epoch 13, gen_loss = 0.8935135751205159, disc_loss = 0.015609737807522462
Trained batch 1377 in epoch 13, gen_loss = 0.89350298326057, disc_loss = 0.015598495827655103
Trained batch 1378 in epoch 13, gen_loss = 0.893430972613659, disc_loss = 0.015587295433551956
Trained batch 1379 in epoch 13, gen_loss = 0.8934927826126416, disc_loss = 0.01557614470182908
Trained batch 1380 in epoch 13, gen_loss = 0.893566278359063, disc_loss = 0.015565120827095248
Trained batch 1381 in epoch 13, gen_loss = 0.8935477952493083, disc_loss = 0.015553927647206641
Trained batch 1382 in epoch 13, gen_loss = 0.8935754259298094, disc_loss = 0.015542837188024254
Trained batch 1383 in epoch 13, gen_loss = 0.8935501918928817, disc_loss = 0.015531687135921726
Trained batch 1384 in epoch 13, gen_loss = 0.8936373895471277, disc_loss = 0.015520749367342334
Trained batch 1385 in epoch 13, gen_loss = 0.8936575785988853, disc_loss = 0.015509705751422728
Trained batch 1386 in epoch 13, gen_loss = 0.8937705008993926, disc_loss = 0.01549868014740651
Trained batch 1387 in epoch 13, gen_loss = 0.8937814743486193, disc_loss = 0.015487604221677248
Trained batch 1388 in epoch 13, gen_loss = 0.8938492924253918, disc_loss = 0.0154766429901904
Trained batch 1389 in epoch 13, gen_loss = 0.8938005008071447, disc_loss = 0.015465573941026822
Trained batch 1390 in epoch 13, gen_loss = 0.8938713935662481, disc_loss = 0.015454593235065872
Trained batch 1391 in epoch 13, gen_loss = 0.8939218491786856, disc_loss = 0.015443672067071564
Trained batch 1392 in epoch 13, gen_loss = 0.893979207761666, disc_loss = 0.015432676565417412
Trained batch 1393 in epoch 13, gen_loss = 0.89394818216434, disc_loss = 0.015421754755228188
Trained batch 1394 in epoch 13, gen_loss = 0.8938149726732657, disc_loss = 0.015410968106118821
Trained batch 1395 in epoch 13, gen_loss = 0.8937774553126455, disc_loss = 0.015400111954620654
Trained batch 1396 in epoch 13, gen_loss = 0.8937329455154148, disc_loss = 0.015389188440974628
Trained batch 1397 in epoch 13, gen_loss = 0.8936054175546412, disc_loss = 0.015378519592541098
Trained batch 1398 in epoch 13, gen_loss = 0.8936306541736335, disc_loss = 0.015367697413128994
Trained batch 1399 in epoch 13, gen_loss = 0.8936423103511334, disc_loss = 0.015356844766039492
Trained batch 1400 in epoch 13, gen_loss = 0.8935980317977222, disc_loss = 0.015346028406123674
Trained batch 1401 in epoch 13, gen_loss = 0.8935977535351537, disc_loss = 0.015335157399003973
Trained batch 1402 in epoch 13, gen_loss = 0.8935845115103215, disc_loss = 0.015324315620291172
Trained batch 1403 in epoch 13, gen_loss = 0.8935517052512223, disc_loss = 0.015313452128511434
Trained batch 1404 in epoch 13, gen_loss = 0.8935783554438594, disc_loss = 0.015302683152746221
Trained batch 1405 in epoch 13, gen_loss = 0.893522751810371, disc_loss = 0.015291856898720278
Trained batch 1406 in epoch 13, gen_loss = 0.8935312352327904, disc_loss = 0.01528104916100348
Trained batch 1407 in epoch 13, gen_loss = 0.8934809294825589, disc_loss = 0.01527024741859474
Trained batch 1408 in epoch 13, gen_loss = 0.8934527859567665, disc_loss = 0.015259460696041581
Trained batch 1409 in epoch 13, gen_loss = 0.8933598994997376, disc_loss = 0.015248725598093645
Trained batch 1410 in epoch 13, gen_loss = 0.8934074656959969, disc_loss = 0.015238011636432618
Trained batch 1411 in epoch 13, gen_loss = 0.8933926662245486, disc_loss = 0.015227276532025777
Trained batch 1412 in epoch 13, gen_loss = 0.8933643390545166, disc_loss = 0.015216572217092739
Trained batch 1413 in epoch 13, gen_loss = 0.8933166137552666, disc_loss = 0.015205923477136708
Trained batch 1414 in epoch 13, gen_loss = 0.8933431339137545, disc_loss = 0.015195276655130048
Trained batch 1415 in epoch 13, gen_loss = 0.8932514544050235, disc_loss = 0.01518462164323741
Trained batch 1416 in epoch 13, gen_loss = 0.8932066344213722, disc_loss = 0.015173998067570822
Trained batch 1417 in epoch 13, gen_loss = 0.893167286922128, disc_loss = 0.01516338648443848
Trained batch 1418 in epoch 13, gen_loss = 0.8932262472782108, disc_loss = 0.01515280480821855
Trained batch 1419 in epoch 13, gen_loss = 0.8932627532054002, disc_loss = 0.015142244687827565
Trained batch 1420 in epoch 13, gen_loss = 0.8933154297789413, disc_loss = 0.01513164143062279
Trained batch 1421 in epoch 13, gen_loss = 0.8933140028336213, disc_loss = 0.015121097579959993
Trained batch 1422 in epoch 13, gen_loss = 0.8932833802465477, disc_loss = 0.015110570668235795
Trained batch 1423 in epoch 13, gen_loss = 0.8932205882509437, disc_loss = 0.015100044053842078
Trained batch 1424 in epoch 13, gen_loss = 0.8930904774289382, disc_loss = 0.015089544246413362
Trained batch 1425 in epoch 13, gen_loss = 0.8931180558273201, disc_loss = 0.015079099744146104
Trained batch 1426 in epoch 13, gen_loss = 0.8931682406602912, disc_loss = 0.015068661985294095
Trained batch 1427 in epoch 13, gen_loss = 0.8931031575431677, disc_loss = 0.015058187967947013
Trained batch 1428 in epoch 13, gen_loss = 0.8931424951661793, disc_loss = 0.015047934013490747
Trained batch 1429 in epoch 13, gen_loss = 0.8931413300595917, disc_loss = 0.01503753146440889
Trained batch 1430 in epoch 13, gen_loss = 0.8931247575103112, disc_loss = 0.01502711344744917
Trained batch 1431 in epoch 13, gen_loss = 0.8931496180593967, disc_loss = 0.01501669192037694
Trained batch 1432 in epoch 13, gen_loss = 0.8932045781562483, disc_loss = 0.015006294969598438
Trained batch 1433 in epoch 13, gen_loss = 0.8932016506645636, disc_loss = 0.014995981170062173
Trained batch 1434 in epoch 13, gen_loss = 0.8932029977700436, disc_loss = 0.014985614740064624
Trained batch 1435 in epoch 13, gen_loss = 0.8932061836455526, disc_loss = 0.014975267343210042
Trained batch 1436 in epoch 13, gen_loss = 0.8932004030703171, disc_loss = 0.014964902278379941
Trained batch 1437 in epoch 13, gen_loss = 0.8931615448172135, disc_loss = 0.014954688104480536
Trained batch 1438 in epoch 13, gen_loss = 0.8931068575697031, disc_loss = 0.014944362364913812
Trained batch 1439 in epoch 13, gen_loss = 0.8931430871494942, disc_loss = 0.014934115967450149
Trained batch 1440 in epoch 13, gen_loss = 0.8931040886911066, disc_loss = 0.014923844408787355
Trained batch 1441 in epoch 13, gen_loss = 0.8931480956763732, disc_loss = 0.014913607344221296
Trained batch 1442 in epoch 13, gen_loss = 0.893115428509352, disc_loss = 0.014903353469968919
Trained batch 1443 in epoch 13, gen_loss = 0.8930455986771557, disc_loss = 0.014893152850574118
Trained batch 1444 in epoch 13, gen_loss = 0.8929268247322227, disc_loss = 0.014883028243923766
Trained batch 1445 in epoch 13, gen_loss = 0.8928166759582971, disc_loss = 0.014872794438834486
Trained batch 1446 in epoch 13, gen_loss = 0.8928295020284369, disc_loss = 0.014862659250857472
Trained batch 1447 in epoch 13, gen_loss = 0.892786391058844, disc_loss = 0.014852571020068083
Trained batch 1448 in epoch 13, gen_loss = 0.8927180323006779, disc_loss = 0.014845828160302246
Trained batch 1449 in epoch 13, gen_loss = 0.8927172335879556, disc_loss = 0.01483692296505163
Trained batch 1450 in epoch 13, gen_loss = 0.8926699971388653, disc_loss = 0.014826953391240084
Trained batch 1451 in epoch 13, gen_loss = 0.8928273668097071, disc_loss = 0.014817079922744416
Trained batch 1452 in epoch 13, gen_loss = 0.8928879127572998, disc_loss = 0.014807918536438452
Trained batch 1453 in epoch 13, gen_loss = 0.892954741600783, disc_loss = 0.014797917256994515
Trained batch 1454 in epoch 13, gen_loss = 0.8929753600322095, disc_loss = 0.014788552587090782
Trained batch 1455 in epoch 13, gen_loss = 0.8929682289874488, disc_loss = 0.014778661676041088
Trained batch 1456 in epoch 13, gen_loss = 0.8930402785723718, disc_loss = 0.014768817594557367
Trained batch 1457 in epoch 13, gen_loss = 0.8930122122393387, disc_loss = 0.014759209446192184
Trained batch 1458 in epoch 13, gen_loss = 0.8930135091704159, disc_loss = 0.014749951817278121
Trained batch 1459 in epoch 13, gen_loss = 0.892969828864483, disc_loss = 0.014740004658128721
Trained batch 1460 in epoch 13, gen_loss = 0.8928890310069783, disc_loss = 0.01473135849330022
Trained batch 1461 in epoch 13, gen_loss = 0.8929119171465144, disc_loss = 0.014721551763264501
Trained batch 1462 in epoch 13, gen_loss = 0.8929257109934389, disc_loss = 0.014711725466887815
Trained batch 1463 in epoch 13, gen_loss = 0.892860358428271, disc_loss = 0.01470573733758961
Trained batch 1464 in epoch 13, gen_loss = 0.8928804252945115, disc_loss = 0.014696532622457096
Trained batch 1465 in epoch 13, gen_loss = 0.8929579061383602, disc_loss = 0.014687062001531703
Trained batch 1466 in epoch 13, gen_loss = 0.8930165346130353, disc_loss = 0.014677504356505135
Trained batch 1467 in epoch 13, gen_loss = 0.8930345387769005, disc_loss = 0.014667782772285285
Trained batch 1468 in epoch 13, gen_loss = 0.8930576598871477, disc_loss = 0.014658069628714769
Trained batch 1469 in epoch 13, gen_loss = 0.8930993481355459, disc_loss = 0.014648476726731696
Trained batch 1470 in epoch 13, gen_loss = 0.8931417263623892, disc_loss = 0.01463873662679806
Trained batch 1471 in epoch 13, gen_loss = 0.8931278147248795, disc_loss = 0.014629108737030156
Trained batch 1472 in epoch 13, gen_loss = 0.893127424431268, disc_loss = 0.014619414527131804
Trained batch 1473 in epoch 13, gen_loss = 0.8931319444077633, disc_loss = 0.014609773036828724
Trained batch 1474 in epoch 13, gen_loss = 0.8930866954488269, disc_loss = 0.01460014088793117
Trained batch 1475 in epoch 13, gen_loss = 0.8931151445359395, disc_loss = 0.014590505464857267
Trained batch 1476 in epoch 13, gen_loss = 0.8931349276003195, disc_loss = 0.014580847283085131
Trained batch 1477 in epoch 13, gen_loss = 0.8930748569828247, disc_loss = 0.01457130600256241
Trained batch 1478 in epoch 13, gen_loss = 0.8931055458072394, disc_loss = 0.014561883473889535
Trained batch 1479 in epoch 13, gen_loss = 0.8931642351722395, disc_loss = 0.014552289114259553
Trained batch 1480 in epoch 13, gen_loss = 0.8931294416230244, disc_loss = 0.014542843052369813
Trained batch 1481 in epoch 13, gen_loss = 0.8932173015416554, disc_loss = 0.014533704096306983
Trained batch 1482 in epoch 13, gen_loss = 0.8932822997595761, disc_loss = 0.01452416679376716
Trained batch 1483 in epoch 13, gen_loss = 0.8932489407552542, disc_loss = 0.014514997831295014
Trained batch 1484 in epoch 13, gen_loss = 0.893222142971726, disc_loss = 0.014505545464429576
Trained batch 1485 in epoch 13, gen_loss = 0.8931942026395335, disc_loss = 0.014496017535494865
Trained batch 1486 in epoch 13, gen_loss = 0.893160544491167, disc_loss = 0.014486486628326056
Trained batch 1487 in epoch 13, gen_loss = 0.8930946181738569, disc_loss = 0.014476970946899563
Trained batch 1488 in epoch 13, gen_loss = 0.8930173173016394, disc_loss = 0.014467504861501092
Trained batch 1489 in epoch 13, gen_loss = 0.8929866788971345, disc_loss = 0.014457970078296814
Trained batch 1490 in epoch 13, gen_loss = 0.893083252477454, disc_loss = 0.014448801799362304
Trained batch 1491 in epoch 13, gen_loss = 0.8931332800846956, disc_loss = 0.01443940617264405
Trained batch 1492 in epoch 13, gen_loss = 0.8931024357806255, disc_loss = 0.014430143201975512
Trained batch 1493 in epoch 13, gen_loss = 0.8931066859638196, disc_loss = 0.014420825891387285
Trained batch 1494 in epoch 13, gen_loss = 0.8931093210560024, disc_loss = 0.014411461371791208
Trained batch 1495 in epoch 13, gen_loss = 0.8931642718772519, disc_loss = 0.01440210088961013
Trained batch 1496 in epoch 13, gen_loss = 0.8931414854669858, disc_loss = 0.014392671108281583
Trained batch 1497 in epoch 13, gen_loss = 0.8930407798139053, disc_loss = 0.014400730505929748
Trained batch 1498 in epoch 13, gen_loss = 0.893145505132637, disc_loss = 0.01439735112359726
Trained batch 1499 in epoch 13, gen_loss = 0.8931609442830086, disc_loss = 0.014389094977809387
Trained batch 1500 in epoch 13, gen_loss = 0.8931789026309617, disc_loss = 0.014380532488592617
Trained batch 1501 in epoch 13, gen_loss = 0.8931962326863475, disc_loss = 0.014390248545961038
Trained batch 1502 in epoch 13, gen_loss = 0.8932285383988124, disc_loss = 0.014384348673391206
Trained batch 1503 in epoch 13, gen_loss = 0.893349902486389, disc_loss = 0.01437791390206625
Trained batch 1504 in epoch 13, gen_loss = 0.8933728536696133, disc_loss = 0.014369504770628165
Trained batch 1505 in epoch 13, gen_loss = 0.8934005402909174, disc_loss = 0.014360628764568957
Trained batch 1506 in epoch 13, gen_loss = 0.8934517071471756, disc_loss = 0.014351372030397682
Trained batch 1507 in epoch 13, gen_loss = 0.893564378333819, disc_loss = 0.014342191745001174
Trained batch 1508 in epoch 13, gen_loss = 0.8934916211446442, disc_loss = 0.014333184050534603
Trained batch 1509 in epoch 13, gen_loss = 0.89348455037897, disc_loss = 0.01432401929537836
Trained batch 1510 in epoch 13, gen_loss = 0.8934748986357494, disc_loss = 0.014314732411018615
Trained batch 1511 in epoch 13, gen_loss = 0.8935458985152384, disc_loss = 0.014305486693484892
Trained batch 1512 in epoch 13, gen_loss = 0.8935986782688221, disc_loss = 0.01429647517258726
Trained batch 1513 in epoch 13, gen_loss = 0.8936677893409641, disc_loss = 0.014287454246711857
Trained batch 1514 in epoch 13, gen_loss = 0.8937120643582674, disc_loss = 0.01427822882993352
Trained batch 1515 in epoch 13, gen_loss = 0.8937337020888807, disc_loss = 0.014268988170538743
Trained batch 1516 in epoch 13, gen_loss = 0.8937193089868964, disc_loss = 0.014259904434686475
Trained batch 1517 in epoch 13, gen_loss = 0.8937875962814952, disc_loss = 0.01425064906615644
Trained batch 1518 in epoch 13, gen_loss = 0.8937379103141682, disc_loss = 0.014241547686531408
Trained batch 1519 in epoch 13, gen_loss = 0.8937418599858096, disc_loss = 0.014232319820875044
Trained batch 1520 in epoch 13, gen_loss = 0.8937227239466121, disc_loss = 0.014223167948306909
Trained batch 1521 in epoch 13, gen_loss = 0.8937480822303449, disc_loss = 0.014213977974415036
Trained batch 1522 in epoch 13, gen_loss = 0.8936933808356465, disc_loss = 0.014204781934136358
Trained batch 1523 in epoch 13, gen_loss = 0.8936524509484061, disc_loss = 0.014195647042477388
Trained batch 1524 in epoch 13, gen_loss = 0.8937165505182547, disc_loss = 0.014186543981266994
Trained batch 1525 in epoch 13, gen_loss = 0.8937019223974698, disc_loss = 0.014177540165903653
Trained batch 1526 in epoch 13, gen_loss = 0.8936732624314077, disc_loss = 0.014168563659605593
Trained batch 1527 in epoch 13, gen_loss = 0.893690084502179, disc_loss = 0.014159506488971345
Trained batch 1528 in epoch 13, gen_loss = 0.8936586420352043, disc_loss = 0.014150424535464725
Trained batch 1529 in epoch 13, gen_loss = 0.8936013339586507, disc_loss = 0.014141368238203831
Trained batch 1530 in epoch 13, gen_loss = 0.8936320202440938, disc_loss = 0.014132352676401701
Trained batch 1531 in epoch 13, gen_loss = 0.8936022539323989, disc_loss = 0.014123295191741726
Trained batch 1532 in epoch 13, gen_loss = 0.8935870695215227, disc_loss = 0.014114285172175335
Trained batch 1533 in epoch 13, gen_loss = 0.8935866607875215, disc_loss = 0.0141052937269587
Trained batch 1534 in epoch 13, gen_loss = 0.8936410020345197, disc_loss = 0.014096261976831495
Trained batch 1535 in epoch 13, gen_loss = 0.8937208105538351, disc_loss = 0.014087257295770428
Trained batch 1536 in epoch 13, gen_loss = 0.8937293285468839, disc_loss = 0.014078261672078367
Trained batch 1537 in epoch 13, gen_loss = 0.8937408200359779, disc_loss = 0.014069214355736168
Trained batch 1538 in epoch 13, gen_loss = 0.8937813515512877, disc_loss = 0.014060322953678907
Trained batch 1539 in epoch 13, gen_loss = 0.8938288165570853, disc_loss = 0.014051443798485093
Trained batch 1540 in epoch 13, gen_loss = 0.8939118950998218, disc_loss = 0.014042465074798179
Trained batch 1541 in epoch 13, gen_loss = 0.893876622333137, disc_loss = 0.014033643349331307
Trained batch 1542 in epoch 13, gen_loss = 0.893808892483226, disc_loss = 0.014024693030925755
Trained batch 1543 in epoch 13, gen_loss = 0.8938153343072518, disc_loss = 0.014016040588437933
Trained batch 1544 in epoch 13, gen_loss = 0.8938600120613875, disc_loss = 0.01400717113135118
Trained batch 1545 in epoch 13, gen_loss = 0.8938802138529959, disc_loss = 0.013998455384365059
Trained batch 1546 in epoch 13, gen_loss = 0.8939442925670491, disc_loss = 0.013989661944178125
Trained batch 1547 in epoch 13, gen_loss = 0.893927674095606, disc_loss = 0.013980950432977446
Trained batch 1548 in epoch 13, gen_loss = 0.8938699399486059, disc_loss = 0.013972175873720303
Trained batch 1549 in epoch 13, gen_loss = 0.8938056115758034, disc_loss = 0.0139634006704446
Trained batch 1550 in epoch 13, gen_loss = 0.8937171776205551, disc_loss = 0.013954573091858888
Trained batch 1551 in epoch 13, gen_loss = 0.8937309482086873, disc_loss = 0.01394652365868601
Trained batch 1552 in epoch 13, gen_loss = 0.8937272578190008, disc_loss = 0.013937771915317702
Trained batch 1553 in epoch 13, gen_loss = 0.8936485422815902, disc_loss = 0.013930969202084812
Trained batch 1554 in epoch 13, gen_loss = 0.8936532785463179, disc_loss = 0.013922365246924768
Trained batch 1555 in epoch 13, gen_loss = 0.8936042656743741, disc_loss = 0.013914778456298562
Trained batch 1556 in epoch 13, gen_loss = 0.8935494426166545, disc_loss = 0.013906140469173192
Trained batch 1557 in epoch 13, gen_loss = 0.8935355747044469, disc_loss = 0.013897486918614869
Trained batch 1558 in epoch 13, gen_loss = 0.8934516009227674, disc_loss = 0.01388929453491093
Trained batch 1559 in epoch 13, gen_loss = 0.8934053901105355, disc_loss = 0.013880803670536597
Trained batch 1560 in epoch 13, gen_loss = 0.893409759799003, disc_loss = 0.013872144473927856
Trained batch 1561 in epoch 13, gen_loss = 0.893320656330271, disc_loss = 0.013863556906102631
Trained batch 1562 in epoch 13, gen_loss = 0.8933529989008558, disc_loss = 0.01385508468351986
Trained batch 1563 in epoch 13, gen_loss = 0.8934351721268785, disc_loss = 0.01384667544405839
Trained batch 1564 in epoch 13, gen_loss = 0.893384478895809, disc_loss = 0.013838169066769707
Trained batch 1565 in epoch 13, gen_loss = 0.8933208914590217, disc_loss = 0.013829713731983238
Trained batch 1566 in epoch 13, gen_loss = 0.89325768160607, disc_loss = 0.013821404904471129
Trained batch 1567 in epoch 13, gen_loss = 0.8929644452065838, disc_loss = 0.013978490277423237
Trained batch 1568 in epoch 13, gen_loss = 0.8929674972615628, disc_loss = 0.014164695827787128
Trained batch 1569 in epoch 13, gen_loss = 0.8930074172794439, disc_loss = 0.014162961974267137
Trained batch 1570 in epoch 13, gen_loss = 0.8929572722700885, disc_loss = 0.01416619380432295
Trained batch 1571 in epoch 13, gen_loss = 0.8928934179492882, disc_loss = 0.01415972209809415
Trained batch 1572 in epoch 13, gen_loss = 0.8929100129457317, disc_loss = 0.014152084306956947
Trained batch 1573 in epoch 13, gen_loss = 0.8928700723748043, disc_loss = 0.01414416084439853
Trained batch 1574 in epoch 13, gen_loss = 0.8929408197175889, disc_loss = 0.01413586831304692
Trained batch 1575 in epoch 13, gen_loss = 0.8929190267690548, disc_loss = 0.014127848407587395
Trained batch 1576 in epoch 13, gen_loss = 0.8928929977048101, disc_loss = 0.014119458437007761
Trained batch 1577 in epoch 13, gen_loss = 0.8929354376212726, disc_loss = 0.014111005851148644
Trained batch 1578 in epoch 13, gen_loss = 0.8928834319945149, disc_loss = 0.014103018883875437
Trained batch 1579 in epoch 13, gen_loss = 0.8928388446569443, disc_loss = 0.014096396191151927
Trained batch 1580 in epoch 13, gen_loss = 0.8927704187829912, disc_loss = 0.014090526712850006
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.7946873903274536, disc_loss = 0.0017284764908254147
Trained batch 1 in epoch 14, gen_loss = 0.8804948031902313, disc_loss = 0.001068782526999712
Trained batch 2 in epoch 14, gen_loss = 0.919024666150411, disc_loss = 0.0008484612432463715
Trained batch 3 in epoch 14, gen_loss = 0.9145421981811523, disc_loss = 0.0007816266370355152
Trained batch 4 in epoch 14, gen_loss = 0.8943597197532653, disc_loss = 0.0007181147171650082
Trained batch 5 in epoch 14, gen_loss = 0.8891136546929678, disc_loss = 0.0006444345102257406
Trained batch 6 in epoch 14, gen_loss = 0.8832782677241734, disc_loss = 0.0006175656121091119
Trained batch 7 in epoch 14, gen_loss = 0.8834524601697922, disc_loss = 0.0005818752142658923
Trained batch 8 in epoch 14, gen_loss = 0.883208281464047, disc_loss = 0.0005740672770318472
Trained batch 9 in epoch 14, gen_loss = 0.8782622396945954, disc_loss = 0.0005785119807114825
Trained batch 10 in epoch 14, gen_loss = 0.8771073818206787, disc_loss = 0.0005721224720632149
Trained batch 11 in epoch 14, gen_loss = 0.8760230789581934, disc_loss = 0.0005831010469895167
Trained batch 12 in epoch 14, gen_loss = 0.8672360961253827, disc_loss = 0.0005912493462137019
Trained batch 13 in epoch 14, gen_loss = 0.8553421454770225, disc_loss = 0.000648132390259499
Trained batch 14 in epoch 14, gen_loss = 0.8649969538052876, disc_loss = 0.0006512354263880601
Trained batch 15 in epoch 14, gen_loss = 0.8652117997407913, disc_loss = 0.000630726093731937
Trained batch 16 in epoch 14, gen_loss = 0.8680544600767248, disc_loss = 0.0006220000864499632
Trained batch 17 in epoch 14, gen_loss = 0.869348386923472, disc_loss = 0.0006009417823709858
Trained batch 18 in epoch 14, gen_loss = 0.8670694388841328, disc_loss = 0.000624074973625523
Trained batch 19 in epoch 14, gen_loss = 0.8656510472297668, disc_loss = 0.0006938163242011797
Trained batch 20 in epoch 14, gen_loss = 0.8642971799487159, disc_loss = 0.0006991615844613296
Trained batch 21 in epoch 14, gen_loss = 0.8653572039170698, disc_loss = 0.0006943667851208539
Trained batch 22 in epoch 14, gen_loss = 0.8630521323369897, disc_loss = 0.0006813377403886989
Trained batch 23 in epoch 14, gen_loss = 0.8658100292086601, disc_loss = 0.0006735858302514922
Trained batch 24 in epoch 14, gen_loss = 0.8688482236862183, disc_loss = 0.0006643189809983596
Trained batch 25 in epoch 14, gen_loss = 0.8646341447646801, disc_loss = 0.0006541819955320813
Trained batch 26 in epoch 14, gen_loss = 0.8671598478599831, disc_loss = 0.0006431368512696483
Trained batch 27 in epoch 14, gen_loss = 0.8652456679514476, disc_loss = 0.0006318881896731909
Trained batch 28 in epoch 14, gen_loss = 0.8698081661914957, disc_loss = 0.0006266332001642099
Trained batch 29 in epoch 14, gen_loss = 0.8731136977672577, disc_loss = 0.000622884750191588
Trained batch 30 in epoch 14, gen_loss = 0.875043801722988, disc_loss = 0.0006442747427143097
Trained batch 31 in epoch 14, gen_loss = 0.8761295396834612, disc_loss = 0.0006376661963258812
Trained batch 32 in epoch 14, gen_loss = 0.8755919174714522, disc_loss = 0.0006301972223974934
Trained batch 33 in epoch 14, gen_loss = 0.8720859780031092, disc_loss = 0.0006229005439843819
Trained batch 34 in epoch 14, gen_loss = 0.8739718164716448, disc_loss = 0.000618736694117875
Trained batch 35 in epoch 14, gen_loss = 0.8758016990290748, disc_loss = 0.0006108584230888584
Trained batch 36 in epoch 14, gen_loss = 0.8749342464111947, disc_loss = 0.000602228069486021
Trained batch 37 in epoch 14, gen_loss = 0.8746315915333597, disc_loss = 0.0006050941420222731
Trained batch 38 in epoch 14, gen_loss = 0.8746924232213925, disc_loss = 0.0005975657964322286
Trained batch 39 in epoch 14, gen_loss = 0.87754225730896, disc_loss = 0.0005914689831115538
Trained batch 40 in epoch 14, gen_loss = 0.8782568428574539, disc_loss = 0.0005840670779523463
Trained batch 41 in epoch 14, gen_loss = 0.8792174870059604, disc_loss = 0.000579783617078127
Trained batch 42 in epoch 14, gen_loss = 0.8816908195961354, disc_loss = 0.0005742073953178776
Trained batch 43 in epoch 14, gen_loss = 0.8818631903691725, disc_loss = 0.0005686254937080031
Trained batch 44 in epoch 14, gen_loss = 0.8811045567194621, disc_loss = 0.0005630095796530239
Trained batch 45 in epoch 14, gen_loss = 0.8804861721785172, disc_loss = 0.0005569794862505818
Trained batch 46 in epoch 14, gen_loss = 0.8806771838918646, disc_loss = 0.0005521890165487383
Trained batch 47 in epoch 14, gen_loss = 0.8798167544106642, disc_loss = 0.0005473962867957501
Trained batch 48 in epoch 14, gen_loss = 0.8835138751535999, disc_loss = 0.0005603173010559677
Trained batch 49 in epoch 14, gen_loss = 0.8820891749858856, disc_loss = 0.0005592281473218463
Trained batch 50 in epoch 14, gen_loss = 0.8823284132807863, disc_loss = 0.0005534376430338906
Trained batch 51 in epoch 14, gen_loss = 0.8813165621115611, disc_loss = 0.0005496102611896975
Trained batch 52 in epoch 14, gen_loss = 0.8812874308172262, disc_loss = 0.000546116300337983
Trained batch 53 in epoch 14, gen_loss = 0.8800322865998303, disc_loss = 0.0005441628646049476
Trained batch 54 in epoch 14, gen_loss = 0.8790005976503545, disc_loss = 0.0005389791217484427
Trained batch 55 in epoch 14, gen_loss = 0.877746448985168, disc_loss = 0.0005334639809007058
Trained batch 56 in epoch 14, gen_loss = 0.8760621349016825, disc_loss = 0.0005471687669469567
Trained batch 57 in epoch 14, gen_loss = 0.8745649765277731, disc_loss = 0.0005437054388839269
Trained batch 58 in epoch 14, gen_loss = 0.8736669380786055, disc_loss = 0.0005395267056636671
Trained batch 59 in epoch 14, gen_loss = 0.8729973167181015, disc_loss = 0.0005398610628617462
Trained batch 60 in epoch 14, gen_loss = 0.8729997716966222, disc_loss = 0.0005425859701182296
Trained batch 61 in epoch 14, gen_loss = 0.8754558082549803, disc_loss = 0.0005388754129413546
Trained batch 62 in epoch 14, gen_loss = 0.8815574324320233, disc_loss = 0.0005749644573485952
Trained batch 63 in epoch 14, gen_loss = 0.8880566786974669, disc_loss = 0.0005809827382563526
Trained batch 64 in epoch 14, gen_loss = 0.8915854619099544, disc_loss = 0.0005790727336156684
Trained batch 65 in epoch 14, gen_loss = 0.8956170136278326, disc_loss = 0.0005784292586736917
Trained batch 66 in epoch 14, gen_loss = 0.8964620081346426, disc_loss = 0.0005762701792861404
Trained batch 67 in epoch 14, gen_loss = 0.8983190936200759, disc_loss = 0.0005740978789724656
Trained batch 68 in epoch 14, gen_loss = 0.8989938817162445, disc_loss = 0.0005734138761434461
Trained batch 69 in epoch 14, gen_loss = 0.8997471826417106, disc_loss = 0.0005697251860900516
Trained batch 70 in epoch 14, gen_loss = 0.8988976579316905, disc_loss = 0.0005668207359890466
Trained batch 71 in epoch 14, gen_loss = 0.8979291733768251, disc_loss = 0.0005643358484424729
Trained batch 72 in epoch 14, gen_loss = 0.8969302977601142, disc_loss = 0.000562247027418168
Trained batch 73 in epoch 14, gen_loss = 0.8980053824347418, disc_loss = 0.0005621478428381395
Trained batch 74 in epoch 14, gen_loss = 0.899253724416097, disc_loss = 0.0005587173445383087
Trained batch 75 in epoch 14, gen_loss = 0.8983331934401864, disc_loss = 0.0005582985910510424
Trained batch 76 in epoch 14, gen_loss = 0.8981810560474148, disc_loss = 0.0005546457535971271
Trained batch 77 in epoch 14, gen_loss = 0.8992559634722196, disc_loss = 0.0005511691924766637
Trained batch 78 in epoch 14, gen_loss = 0.8993246977842306, disc_loss = 0.0005508681007327889
Trained batch 79 in epoch 14, gen_loss = 0.8997776538133622, disc_loss = 0.0005468897505124914
Trained batch 80 in epoch 14, gen_loss = 0.9007287569987921, disc_loss = 0.000542944788905493
Trained batch 81 in epoch 14, gen_loss = 0.8998955982487377, disc_loss = 0.0005410987162954038
Trained batch 82 in epoch 14, gen_loss = 0.9014181875320803, disc_loss = 0.0005389365943706965
Trained batch 83 in epoch 14, gen_loss = 0.9014597024236407, disc_loss = 0.0005392805834985449
Trained batch 84 in epoch 14, gen_loss = 0.9004235246602227, disc_loss = 0.0005349298081401845
Trained batch 85 in epoch 14, gen_loss = 0.9005850401035574, disc_loss = 0.0005335876940503219
Trained batch 86 in epoch 14, gen_loss = 0.9007336558966801, disc_loss = 0.0005299928967758007
Trained batch 87 in epoch 14, gen_loss = 0.9016881625760685, disc_loss = 0.0005266585852620086
Trained batch 88 in epoch 14, gen_loss = 0.9029465672675143, disc_loss = 0.0005269980035510353
Trained batch 89 in epoch 14, gen_loss = 0.9025598314073351, disc_loss = 0.0005248454675893299
Trained batch 90 in epoch 14, gen_loss = 0.9024091389153029, disc_loss = 0.0005212732471441236
Trained batch 91 in epoch 14, gen_loss = 0.9021766444911128, disc_loss = 0.0005184969231777359
Trained batch 92 in epoch 14, gen_loss = 0.9030639644592039, disc_loss = 0.0005193769527156087
Trained batch 93 in epoch 14, gen_loss = 0.9029260252384429, disc_loss = 0.0005173739932905982
Trained batch 94 in epoch 14, gen_loss = 0.9030965039604588, disc_loss = 0.0005149497645968376
Trained batch 95 in epoch 14, gen_loss = 0.9032768085598946, disc_loss = 0.0005122135018306532
Trained batch 96 in epoch 14, gen_loss = 0.9030838147881105, disc_loss = 0.0005091345239221838
Trained batch 97 in epoch 14, gen_loss = 0.9031818490855548, disc_loss = 0.0005095461040452522
Trained batch 98 in epoch 14, gen_loss = 0.9025592316280712, disc_loss = 0.0005096417483979498
Trained batch 99 in epoch 14, gen_loss = 0.9025428169965743, disc_loss = 0.0005079852342896629
Trained batch 100 in epoch 14, gen_loss = 0.9015686329048459, disc_loss = 0.0005057019452128725
Trained batch 101 in epoch 14, gen_loss = 0.9019811287814495, disc_loss = 0.0005034026260403277
Trained batch 102 in epoch 14, gen_loss = 0.9025776519358737, disc_loss = 0.0005005023548734438
Trained batch 103 in epoch 14, gen_loss = 0.9027672266730895, disc_loss = 0.0004981281819289926
Trained batch 104 in epoch 14, gen_loss = 0.9035928924878438, disc_loss = 0.0004945909525434088
Trained batch 105 in epoch 14, gen_loss = 0.9038763248695517, disc_loss = 0.0004918307030544933
Trained batch 106 in epoch 14, gen_loss = 0.9031521923074098, disc_loss = 0.0004892817971233504
Trained batch 107 in epoch 14, gen_loss = 0.9036378656272535, disc_loss = 0.000486200263737744
Trained batch 108 in epoch 14, gen_loss = 0.9033186643495472, disc_loss = 0.00048417875176368265
Trained batch 109 in epoch 14, gen_loss = 0.903002510287545, disc_loss = 0.00048099082222589375
Trained batch 110 in epoch 14, gen_loss = 0.9031673589268246, disc_loss = 0.00047835160276500156
Trained batch 111 in epoch 14, gen_loss = 0.9023002231759685, disc_loss = 0.0004756978609553438
Trained batch 112 in epoch 14, gen_loss = 0.9023393904213357, disc_loss = 0.00047355947309828865
Trained batch 113 in epoch 14, gen_loss = 0.9020000277904042, disc_loss = 0.00047257241781233203
Trained batch 114 in epoch 14, gen_loss = 0.9026654559633006, disc_loss = 0.0004703560272110221
Trained batch 115 in epoch 14, gen_loss = 0.9023035682480911, disc_loss = 0.00046841358361516855
Trained batch 116 in epoch 14, gen_loss = 0.9021357715639293, disc_loss = 0.00046528916330620024
Trained batch 117 in epoch 14, gen_loss = 0.9015696579116886, disc_loss = 0.00046298202733712477
Trained batch 118 in epoch 14, gen_loss = 0.9014142556350773, disc_loss = 0.00046025055218262975
Trained batch 119 in epoch 14, gen_loss = 0.9027428622047107, disc_loss = 0.00045872874403964184
Trained batch 120 in epoch 14, gen_loss = 0.9029119926050675, disc_loss = 0.00045609159409770863
Trained batch 121 in epoch 14, gen_loss = 0.9036002862648885, disc_loss = 0.00045398652159225303
Trained batch 122 in epoch 14, gen_loss = 0.9036643039889452, disc_loss = 0.0004520162648868717
Trained batch 123 in epoch 14, gen_loss = 0.9042015690957347, disc_loss = 0.00044998295004094666
Trained batch 124 in epoch 14, gen_loss = 0.9033650188446045, disc_loss = 0.0004481649381923489
Trained batch 125 in epoch 14, gen_loss = 0.9037777275320084, disc_loss = 0.00044612038589779304
Trained batch 126 in epoch 14, gen_loss = 0.9032891852649179, disc_loss = 0.00044394181036403195
Trained batch 127 in epoch 14, gen_loss = 0.9038934763520956, disc_loss = 0.0004416848202595247
Trained batch 128 in epoch 14, gen_loss = 0.9037823616996292, disc_loss = 0.00043967035873170376
Trained batch 129 in epoch 14, gen_loss = 0.9030587806151463, disc_loss = 0.00043764947829633735
Trained batch 130 in epoch 14, gen_loss = 0.9025295718025615, disc_loss = 0.00043540755445661936
Trained batch 131 in epoch 14, gen_loss = 0.9020791347279693, disc_loss = 0.00043292456674945157
Trained batch 132 in epoch 14, gen_loss = 0.9020764473685645, disc_loss = 0.0004305892229089829
Trained batch 133 in epoch 14, gen_loss = 0.9025881570666584, disc_loss = 0.00042871203061337445
Trained batch 134 in epoch 14, gen_loss = 0.9023838144761545, disc_loss = 0.0004266732317908598
Trained batch 135 in epoch 14, gen_loss = 0.9027220532298088, disc_loss = 0.00042531260532996384
Trained batch 136 in epoch 14, gen_loss = 0.9030009686511798, disc_loss = 0.00042410358508503283
Trained batch 137 in epoch 14, gen_loss = 0.9036525250345037, disc_loss = 0.0004222350992980258
Trained batch 138 in epoch 14, gen_loss = 0.9044879782114098, disc_loss = 0.00042128486058585975
Trained batch 139 in epoch 14, gen_loss = 0.905223508817809, disc_loss = 0.00042054168064039135
Trained batch 140 in epoch 14, gen_loss = 0.905440925283635, disc_loss = 0.0004188355185064249
Trained batch 141 in epoch 14, gen_loss = 0.9043520231482008, disc_loss = 0.0004174992908714634
Trained batch 142 in epoch 14, gen_loss = 0.9044292794240938, disc_loss = 0.000416665110288113
Trained batch 143 in epoch 14, gen_loss = 0.9043243622614278, disc_loss = 0.0004180287378908866
Trained batch 144 in epoch 14, gen_loss = 0.9045181693701908, disc_loss = 0.00041777003152047057
Trained batch 145 in epoch 14, gen_loss = 0.9047347568485835, disc_loss = 0.00042414842042888594
Trained batch 146 in epoch 14, gen_loss = 0.9042450992428527, disc_loss = 0.0004277108851396542
Trained batch 147 in epoch 14, gen_loss = 0.904640780107395, disc_loss = 0.0004269430080819655
Trained batch 148 in epoch 14, gen_loss = 0.9049975347998959, disc_loss = 0.00042621967572782925
Trained batch 149 in epoch 14, gen_loss = 0.905758361419042, disc_loss = 0.00042579846073446487
Trained batch 150 in epoch 14, gen_loss = 0.9051727763074913, disc_loss = 0.000426185338587164
Trained batch 151 in epoch 14, gen_loss = 0.9045056312492019, disc_loss = 0.0004290724935727715
Trained batch 152 in epoch 14, gen_loss = 0.9040161332273795, disc_loss = 0.00042872406353792054
Trained batch 153 in epoch 14, gen_loss = 0.904096865808809, disc_loss = 0.0004289360502345469
Trained batch 154 in epoch 14, gen_loss = 0.9033006483508694, disc_loss = 0.0004354017695145411
Trained batch 155 in epoch 14, gen_loss = 0.9029729901215969, disc_loss = 0.0004441611771863581
Trained batch 156 in epoch 14, gen_loss = 0.9032062018752858, disc_loss = 0.00044249955407724937
Trained batch 157 in epoch 14, gen_loss = 0.9030448213408265, disc_loss = 0.0004420977105077834
Trained batch 158 in epoch 14, gen_loss = 0.9036375527861733, disc_loss = 0.00044189583596739766
Trained batch 159 in epoch 14, gen_loss = 0.9031966771930456, disc_loss = 0.00044167725304760096
Trained batch 160 in epoch 14, gen_loss = 0.9032139034004685, disc_loss = 0.00044288777881656245
Trained batch 161 in epoch 14, gen_loss = 0.9029361384886282, disc_loss = 0.0004426375158396291
Trained batch 162 in epoch 14, gen_loss = 0.9028252509474023, disc_loss = 0.0004422864555741912
Trained batch 163 in epoch 14, gen_loss = 0.9029771154973565, disc_loss = 0.00044107018894886475
Trained batch 164 in epoch 14, gen_loss = 0.9026112599806352, disc_loss = 0.00043976581933252007
Trained batch 165 in epoch 14, gen_loss = 0.9018081035240587, disc_loss = 0.0004381186530714243
Trained batch 166 in epoch 14, gen_loss = 0.9013858765899064, disc_loss = 0.0004364832763718357
Trained batch 167 in epoch 14, gen_loss = 0.9013477978961808, disc_loss = 0.0004358734376226147
Trained batch 168 in epoch 14, gen_loss = 0.9012813882009517, disc_loss = 0.0004346600417946686
Trained batch 169 in epoch 14, gen_loss = 0.9018229509101194, disc_loss = 0.00043311220176880905
Trained batch 170 in epoch 14, gen_loss = 0.9017713296483134, disc_loss = 0.00043255097066135313
Trained batch 171 in epoch 14, gen_loss = 0.9013891788416131, disc_loss = 0.0004307203752284485
Trained batch 172 in epoch 14, gen_loss = 0.9019614478756237, disc_loss = 0.00043152489335541316
Trained batch 173 in epoch 14, gen_loss = 0.9015683744145536, disc_loss = 0.0004301185033638057
Trained batch 174 in epoch 14, gen_loss = 0.9022445603779384, disc_loss = 0.00042948265281406097
Trained batch 175 in epoch 14, gen_loss = 0.9017964974045753, disc_loss = 0.00043037610012933413
Trained batch 176 in epoch 14, gen_loss = 0.9012851519773235, disc_loss = 0.0004325449810114079
Trained batch 177 in epoch 14, gen_loss = 0.901178954022654, disc_loss = 0.00043271231571156163
Trained batch 178 in epoch 14, gen_loss = 0.9012247067589999, disc_loss = 0.00043307185923718383
Trained batch 179 in epoch 14, gen_loss = 0.9009461439318127, disc_loss = 0.0004315593653801544
Trained batch 180 in epoch 14, gen_loss = 0.9010736790809842, disc_loss = 0.0004304984621192298
Trained batch 181 in epoch 14, gen_loss = 0.9015041887760162, disc_loss = 0.000429545517553189
Trained batch 182 in epoch 14, gen_loss = 0.9012554587562227, disc_loss = 0.0004282539499757552
Trained batch 183 in epoch 14, gen_loss = 0.9004671039140743, disc_loss = 0.00042785359963328
Trained batch 184 in epoch 14, gen_loss = 0.900592019429078, disc_loss = 0.0004270961175820589
Trained batch 185 in epoch 14, gen_loss = 0.9014959120622246, disc_loss = 0.0004263765749979078
Trained batch 186 in epoch 14, gen_loss = 0.9015411973637055, disc_loss = 0.0004252878586648973
Trained batch 187 in epoch 14, gen_loss = 0.900940902055578, disc_loss = 0.0004237020126078897
Trained batch 188 in epoch 14, gen_loss = 0.9003239725001906, disc_loss = 0.00042279612457918044
Trained batch 189 in epoch 14, gen_loss = 0.9007037426296033, disc_loss = 0.0004216181537470364
Trained batch 190 in epoch 14, gen_loss = 0.9006908061616707, disc_loss = 0.00042041059643918826
Trained batch 191 in epoch 14, gen_loss = 0.9009412145242095, disc_loss = 0.00041926638675704453
Trained batch 192 in epoch 14, gen_loss = 0.9011773423827374, disc_loss = 0.00041916636045729027
Trained batch 193 in epoch 14, gen_loss = 0.9011881938300181, disc_loss = 0.00041925413258758987
Trained batch 194 in epoch 14, gen_loss = 0.9012730992757357, disc_loss = 0.0004188553652896259
Trained batch 195 in epoch 14, gen_loss = 0.9014480372472685, disc_loss = 0.00041766128883957243
Trained batch 196 in epoch 14, gen_loss = 0.90088206287568, disc_loss = 0.00041727438242721894
Trained batch 197 in epoch 14, gen_loss = 0.9009829889042209, disc_loss = 0.00041625134705247196
Trained batch 198 in epoch 14, gen_loss = 0.9020677628229611, disc_loss = 0.0004265851222505751
Trained batch 199 in epoch 14, gen_loss = 0.9023950660228729, disc_loss = 0.0004283719622253557
Trained batch 200 in epoch 14, gen_loss = 0.9023984457129863, disc_loss = 0.0004400976730318884
Trained batch 201 in epoch 14, gen_loss = 0.9019473026884665, disc_loss = 0.00044065548873092696
Trained batch 202 in epoch 14, gen_loss = 0.9020108304587491, disc_loss = 0.0004415098327774614
Trained batch 203 in epoch 14, gen_loss = 0.9021433168182186, disc_loss = 0.00044273841754771887
Trained batch 204 in epoch 14, gen_loss = 0.9020577151600907, disc_loss = 0.00044230007961897815
Trained batch 205 in epoch 14, gen_loss = 0.9019388741659886, disc_loss = 0.0004417600799411269
Trained batch 206 in epoch 14, gen_loss = 0.9017044484327381, disc_loss = 0.0004409864612144715
Trained batch 207 in epoch 14, gen_loss = 0.9022864252328873, disc_loss = 0.00044178986022066406
Trained batch 208 in epoch 14, gen_loss = 0.9025728135017687, disc_loss = 0.00044147469957373615
Trained batch 209 in epoch 14, gen_loss = 0.9029544049785251, disc_loss = 0.00044080975615846306
Trained batch 210 in epoch 14, gen_loss = 0.902782381710848, disc_loss = 0.00044043547594814974
Trained batch 211 in epoch 14, gen_loss = 0.9022949129905341, disc_loss = 0.00043957140440157536
Trained batch 212 in epoch 14, gen_loss = 0.9022567260992919, disc_loss = 0.00043855935115582516
Trained batch 213 in epoch 14, gen_loss = 0.9021203690600172, disc_loss = 0.0004392846334939409
Trained batch 214 in epoch 14, gen_loss = 0.9021758096162663, disc_loss = 0.0004388675806017831
Trained batch 215 in epoch 14, gen_loss = 0.9015531026654773, disc_loss = 0.00043849264643035387
Trained batch 216 in epoch 14, gen_loss = 0.9010838176797612, disc_loss = 0.0004387571757580454
Trained batch 217 in epoch 14, gen_loss = 0.9015931492551751, disc_loss = 0.0004383803741035047
Trained batch 218 in epoch 14, gen_loss = 0.9016337704985109, disc_loss = 0.00043919824157999913
Trained batch 219 in epoch 14, gen_loss = 0.9012431908737529, disc_loss = 0.0004382888596327658
Trained batch 220 in epoch 14, gen_loss = 0.9017003440209643, disc_loss = 0.00043756578437487777
Trained batch 221 in epoch 14, gen_loss = 0.9015955291352831, disc_loss = 0.000436314943972566
Trained batch 222 in epoch 14, gen_loss = 0.9014577165312831, disc_loss = 0.0004359645626547897
Trained batch 223 in epoch 14, gen_loss = 0.9012746169630971, disc_loss = 0.0004350057964269841
Trained batch 224 in epoch 14, gen_loss = 0.9016906740930345, disc_loss = 0.0004342857381238395
Trained batch 225 in epoch 14, gen_loss = 0.9016045645802422, disc_loss = 0.0004342504320431818
Trained batch 226 in epoch 14, gen_loss = 0.9017084456225324, disc_loss = 0.0004333384074580995
Trained batch 227 in epoch 14, gen_loss = 0.9017096148771152, disc_loss = 0.0004320658710894988
Trained batch 228 in epoch 14, gen_loss = 0.901283980717305, disc_loss = 0.00043130773889164207
Trained batch 229 in epoch 14, gen_loss = 0.9013305262379024, disc_loss = 0.00043020321814844423
Trained batch 230 in epoch 14, gen_loss = 0.9011468224195175, disc_loss = 0.00042946773360849226
Trained batch 231 in epoch 14, gen_loss = 0.9011080855953282, disc_loss = 0.0004284037753489523
Trained batch 232 in epoch 14, gen_loss = 0.9011945008208312, disc_loss = 0.00042716159593077105
Trained batch 233 in epoch 14, gen_loss = 0.9012595517003638, disc_loss = 0.00042644283832145383
Trained batch 234 in epoch 14, gen_loss = 0.9009688179543678, disc_loss = 0.0004261921076636583
Trained batch 235 in epoch 14, gen_loss = 0.9006681548336805, disc_loss = 0.00042511675438633526
Trained batch 236 in epoch 14, gen_loss = 0.9009540981381251, disc_loss = 0.00042466345922368136
Trained batch 237 in epoch 14, gen_loss = 0.9003935143226335, disc_loss = 0.0004240700990896371
Trained batch 238 in epoch 14, gen_loss = 0.9007027096828157, disc_loss = 0.00042345778680884835
Trained batch 239 in epoch 14, gen_loss = 0.9005032569169998, disc_loss = 0.00042265280981155227
Trained batch 240 in epoch 14, gen_loss = 0.9005678869876624, disc_loss = 0.00042259947167244775
Trained batch 241 in epoch 14, gen_loss = 0.9004146350809366, disc_loss = 0.00042195910955793685
Trained batch 242 in epoch 14, gen_loss = 0.9009153546129235, disc_loss = 0.00042120815861856165
Trained batch 243 in epoch 14, gen_loss = 0.9010640536663962, disc_loss = 0.000420510662882064
Trained batch 244 in epoch 14, gen_loss = 0.901468296196996, disc_loss = 0.0004204747106996365
Trained batch 245 in epoch 14, gen_loss = 0.9015248405739544, disc_loss = 0.00041924509385101897
Trained batch 246 in epoch 14, gen_loss = 0.9016979117142526, disc_loss = 0.00041879737752170194
Trained batch 247 in epoch 14, gen_loss = 0.901568750700643, disc_loss = 0.00041841115768376415
Trained batch 248 in epoch 14, gen_loss = 0.9016613763977724, disc_loss = 0.0004174698178502581
Trained batch 249 in epoch 14, gen_loss = 0.9018021798133851, disc_loss = 0.00041636819861014376
Trained batch 250 in epoch 14, gen_loss = 0.9017392634395585, disc_loss = 0.0004153240526749463
Trained batch 251 in epoch 14, gen_loss = 0.9015582461678793, disc_loss = 0.0004144501971394574
Trained batch 252 in epoch 14, gen_loss = 0.9016921166845933, disc_loss = 0.000413389445075226
Trained batch 253 in epoch 14, gen_loss = 0.9018148345740762, disc_loss = 0.0004124332991473131
Trained batch 254 in epoch 14, gen_loss = 0.9019999672384823, disc_loss = 0.00041165930517451547
Trained batch 255 in epoch 14, gen_loss = 0.9020213549956679, disc_loss = 0.0004105268515388616
Trained batch 256 in epoch 14, gen_loss = 0.9022011429883163, disc_loss = 0.0004094110465536514
Trained batch 257 in epoch 14, gen_loss = 0.9018463476221691, disc_loss = 0.0004088225013988414
Trained batch 258 in epoch 14, gen_loss = 0.9017063929307415, disc_loss = 0.00040805340484643184
Trained batch 259 in epoch 14, gen_loss = 0.9014640251031288, disc_loss = 0.00040709060746079416
Trained batch 260 in epoch 14, gen_loss = 0.9014211333574463, disc_loss = 0.0004063903281237249
Trained batch 261 in epoch 14, gen_loss = 0.9015531351093118, disc_loss = 0.00040545140002398283
Trained batch 262 in epoch 14, gen_loss = 0.9011835668930083, disc_loss = 0.0004044893125951655
Trained batch 263 in epoch 14, gen_loss = 0.9007783620194956, disc_loss = 0.0004036741864073327
Trained batch 264 in epoch 14, gen_loss = 0.901097095237588, disc_loss = 0.00040277250801358056
Trained batch 265 in epoch 14, gen_loss = 0.9006863684582531, disc_loss = 0.0004025583280019788
Trained batch 266 in epoch 14, gen_loss = 0.9006379664167483, disc_loss = 0.00040212752080495445
Trained batch 267 in epoch 14, gen_loss = 0.9003416818024507, disc_loss = 0.00040156016287106307
Trained batch 268 in epoch 14, gen_loss = 0.9009399832846063, disc_loss = 0.00040112239634639804
Trained batch 269 in epoch 14, gen_loss = 0.9008736433806243, disc_loss = 0.00040014691053161017
Trained batch 270 in epoch 14, gen_loss = 0.9007258672555875, disc_loss = 0.00039905034664720196
Trained batch 271 in epoch 14, gen_loss = 0.9006091509671772, disc_loss = 0.00039803149149306323
Trained batch 272 in epoch 14, gen_loss = 0.9007379316584968, disc_loss = 0.0003972228135356693
Trained batch 273 in epoch 14, gen_loss = 0.9008036677854775, disc_loss = 0.00039643358080613893
Trained batch 274 in epoch 14, gen_loss = 0.9013702392578125, disc_loss = 0.000395610484781421
Trained batch 275 in epoch 14, gen_loss = 0.9010764369066211, disc_loss = 0.00039470198227217475
Trained batch 276 in epoch 14, gen_loss = 0.9008285074027437, disc_loss = 0.0003938919598037471
Trained batch 277 in epoch 14, gen_loss = 0.9005230157066593, disc_loss = 0.00039284902750099873
Trained batch 278 in epoch 14, gen_loss = 0.9003217327124756, disc_loss = 0.000392080057535686
Trained batch 279 in epoch 14, gen_loss = 0.9002467372587749, disc_loss = 0.000391556776152616
Trained batch 280 in epoch 14, gen_loss = 0.8998901383732562, disc_loss = 0.0003928790772671387
Trained batch 281 in epoch 14, gen_loss = 0.8995743472102686, disc_loss = 0.00039267639361932074
Trained batch 282 in epoch 14, gen_loss = 0.8995528655001637, disc_loss = 0.000392236702703392
Trained batch 283 in epoch 14, gen_loss = 0.8997112676291399, disc_loss = 0.00039148623743041216
Trained batch 284 in epoch 14, gen_loss = 0.8997986655486258, disc_loss = 0.000390788639988546
Trained batch 285 in epoch 14, gen_loss = 0.8998918256142756, disc_loss = 0.0003899092467958059
Trained batch 286 in epoch 14, gen_loss = 0.8994658857272477, disc_loss = 0.00038922918309520067
Trained batch 287 in epoch 14, gen_loss = 0.8997510818557607, disc_loss = 0.0003882913884657076
Trained batch 288 in epoch 14, gen_loss = 0.8999680138376758, disc_loss = 0.00038774563706053784
Trained batch 289 in epoch 14, gen_loss = 0.9000245305998572, disc_loss = 0.0003870116194242467
Trained batch 290 in epoch 14, gen_loss = 0.9005159403859955, disc_loss = 0.00038645316902576076
Trained batch 291 in epoch 14, gen_loss = 0.9000068606987391, disc_loss = 0.0003860441676358141
Trained batch 292 in epoch 14, gen_loss = 0.900189211751007, disc_loss = 0.0003851328890978473
Trained batch 293 in epoch 14, gen_loss = 0.9000639704619946, disc_loss = 0.00038476840962262246
Trained batch 294 in epoch 14, gen_loss = 0.9003125774658333, disc_loss = 0.0003840181621638032
Trained batch 295 in epoch 14, gen_loss = 0.9000196964354128, disc_loss = 0.0003832562729872439
Trained batch 296 in epoch 14, gen_loss = 0.8999486220404757, disc_loss = 0.0003824142655833963
Trained batch 297 in epoch 14, gen_loss = 0.8999078979828213, disc_loss = 0.0003815697007349633
Trained batch 298 in epoch 14, gen_loss = 0.9003066699640409, disc_loss = 0.0003808955652462116
Trained batch 299 in epoch 14, gen_loss = 0.9001314872503281, disc_loss = 0.0003805114096273125
Trained batch 300 in epoch 14, gen_loss = 0.8999510807452408, disc_loss = 0.00037970547365628806
Trained batch 301 in epoch 14, gen_loss = 0.900313866256878, disc_loss = 0.0003790642225288783
Trained batch 302 in epoch 14, gen_loss = 0.8998674573284564, disc_loss = 0.0003787300842839121
Trained batch 303 in epoch 14, gen_loss = 0.8996781202915468, disc_loss = 0.00037832940710072043
Trained batch 304 in epoch 14, gen_loss = 0.8998449067600438, disc_loss = 0.0003782102661865733
Trained batch 305 in epoch 14, gen_loss = 0.9002307384621864, disc_loss = 0.00037796749260974287
Trained batch 306 in epoch 14, gen_loss = 0.9000891093710734, disc_loss = 0.0003774045681547152
Trained batch 307 in epoch 14, gen_loss = 0.9002226449839481, disc_loss = 0.00037677571184191607
Trained batch 308 in epoch 14, gen_loss = 0.900079166426242, disc_loss = 0.00037596507763590294
Trained batch 309 in epoch 14, gen_loss = 0.9001649043252391, disc_loss = 0.0003751946305020547
Trained batch 310 in epoch 14, gen_loss = 0.8999225809643123, disc_loss = 0.00037460616580416503
Trained batch 311 in epoch 14, gen_loss = 0.8996400430034368, disc_loss = 0.00037385149416644336
Trained batch 312 in epoch 14, gen_loss = 0.8999252334570351, disc_loss = 0.0003732532686946286
Trained batch 313 in epoch 14, gen_loss = 0.8998757369199376, disc_loss = 0.00037268139282445377
Trained batch 314 in epoch 14, gen_loss = 0.8998711767650786, disc_loss = 0.0003718763506474225
Trained batch 315 in epoch 14, gen_loss = 0.8999299037305615, disc_loss = 0.0003711029739976386
Trained batch 316 in epoch 14, gen_loss = 0.9000029560143263, disc_loss = 0.00037026692397395964
Trained batch 317 in epoch 14, gen_loss = 0.9001734657857403, disc_loss = 0.0003695697016624511
Trained batch 318 in epoch 14, gen_loss = 0.8998833995627759, disc_loss = 0.0003688554001240743
Trained batch 319 in epoch 14, gen_loss = 0.8999172430485487, disc_loss = 0.00036840828515778413
Trained batch 320 in epoch 14, gen_loss = 0.8997106236460796, disc_loss = 0.0003678645621575386
Trained batch 321 in epoch 14, gen_loss = 0.8993047553560009, disc_loss = 0.00036719376549395146
Trained batch 322 in epoch 14, gen_loss = 0.8990021801954452, disc_loss = 0.00036677222906348033
Trained batch 323 in epoch 14, gen_loss = 0.8987509606429088, disc_loss = 0.0003664139851789065
Trained batch 324 in epoch 14, gen_loss = 0.8989124824450566, disc_loss = 0.00036584108499272797
Trained batch 325 in epoch 14, gen_loss = 0.8986869854795421, disc_loss = 0.00036576400341164676
Trained batch 326 in epoch 14, gen_loss = 0.8986309925350574, disc_loss = 0.00036529832472775517
Trained batch 327 in epoch 14, gen_loss = 0.8987541934702454, disc_loss = 0.0003648029080689345
Trained batch 328 in epoch 14, gen_loss = 0.8989729919332139, disc_loss = 0.00036475804885092127
Trained batch 329 in epoch 14, gen_loss = 0.8990539812680447, disc_loss = 0.0003644533944404402
Trained batch 330 in epoch 14, gen_loss = 0.899268028239109, disc_loss = 0.00036378807135543917
Trained batch 331 in epoch 14, gen_loss = 0.8996233893446175, disc_loss = 0.00036341436020574105
Trained batch 332 in epoch 14, gen_loss = 0.8995008604662554, disc_loss = 0.0003630934879110354
Trained batch 333 in epoch 14, gen_loss = 0.8997868087120399, disc_loss = 0.0003629178315464513
Trained batch 334 in epoch 14, gen_loss = 0.899803808553895, disc_loss = 0.0003622703204268534
Trained batch 335 in epoch 14, gen_loss = 0.8996474781916255, disc_loss = 0.00036178902133715817
Trained batch 336 in epoch 14, gen_loss = 0.8996919549183605, disc_loss = 0.00036122348199796084
Trained batch 337 in epoch 14, gen_loss = 0.899478494768312, disc_loss = 0.00036075722491444424
Trained batch 338 in epoch 14, gen_loss = 0.8993850331039204, disc_loss = 0.00035995461631691287
Trained batch 339 in epoch 14, gen_loss = 0.8994639147730434, disc_loss = 0.00035933960175230713
Trained batch 340 in epoch 14, gen_loss = 0.8997099226520907, disc_loss = 0.00035898474739322334
Trained batch 341 in epoch 14, gen_loss = 0.899735936470199, disc_loss = 0.0003582229964359873
Trained batch 342 in epoch 14, gen_loss = 0.8995261107172284, disc_loss = 0.0003575795156714566
Trained batch 343 in epoch 14, gen_loss = 0.8995055670655051, disc_loss = 0.0003569955980247171
Trained batch 344 in epoch 14, gen_loss = 0.89926961193914, disc_loss = 0.0003563420650712889
Trained batch 345 in epoch 14, gen_loss = 0.89931233339227, disc_loss = 0.0003563209282777022
Trained batch 346 in epoch 14, gen_loss = 0.899459822548913, disc_loss = 0.0003557799977858642
Trained batch 347 in epoch 14, gen_loss = 0.8991742594831291, disc_loss = 0.00035535586761105295
Trained batch 348 in epoch 14, gen_loss = 0.8989864352097826, disc_loss = 0.00035483174801642013
Trained batch 349 in epoch 14, gen_loss = 0.898907755783626, disc_loss = 0.00035461245539149136
Trained batch 350 in epoch 14, gen_loss = 0.8987373826850173, disc_loss = 0.0003544517881358029
Trained batch 351 in epoch 14, gen_loss = 0.8988231622021307, disc_loss = 0.00035442869253446673
Trained batch 352 in epoch 14, gen_loss = 0.8989268176616421, disc_loss = 0.00035391769422796654
Trained batch 353 in epoch 14, gen_loss = 0.8985929017686575, disc_loss = 0.00035348692630587995
Trained batch 354 in epoch 14, gen_loss = 0.8982797990382557, disc_loss = 0.0003530206497140478
Trained batch 355 in epoch 14, gen_loss = 0.8979789971300726, disc_loss = 0.0003527421465631132
Trained batch 356 in epoch 14, gen_loss = 0.8980506997482449, disc_loss = 0.0003521571212657858
Trained batch 357 in epoch 14, gen_loss = 0.8979191570308621, disc_loss = 0.00035226840809018185
Trained batch 358 in epoch 14, gen_loss = 0.8979332304266502, disc_loss = 0.0003519063258488808
Trained batch 359 in epoch 14, gen_loss = 0.8980154024230109, disc_loss = 0.00035196047228964745
Trained batch 360 in epoch 14, gen_loss = 0.8979214433157543, disc_loss = 0.00035226628874990333
Trained batch 361 in epoch 14, gen_loss = 0.8978261539290623, disc_loss = 0.0003521040452247709
Trained batch 362 in epoch 14, gen_loss = 0.8979688882827759, disc_loss = 0.0003518015434688083
Trained batch 363 in epoch 14, gen_loss = 0.898226553267175, disc_loss = 0.00035182977170644425
Trained batch 364 in epoch 14, gen_loss = 0.8983723970308696, disc_loss = 0.00035137547451559426
Trained batch 365 in epoch 14, gen_loss = 0.8983770327164176, disc_loss = 0.00035078255988067763
Trained batch 366 in epoch 14, gen_loss = 0.8985323758151291, disc_loss = 0.0003510488366160341
Trained batch 367 in epoch 14, gen_loss = 0.8987417653526949, disc_loss = 0.0003509834241610762
Trained batch 368 in epoch 14, gen_loss = 0.8991732957563426, disc_loss = 0.0003513199196023258
Trained batch 369 in epoch 14, gen_loss = 0.8995312985536215, disc_loss = 0.00035109204915430823
Trained batch 370 in epoch 14, gen_loss = 0.8997628320902185, disc_loss = 0.00035063854205397626
Trained batch 371 in epoch 14, gen_loss = 0.8998618566541261, disc_loss = 0.00035051411484140945
Trained batch 372 in epoch 14, gen_loss = 0.9004763507012068, disc_loss = 0.0003516474536355727
Trained batch 373 in epoch 14, gen_loss = 0.9005566030581367, disc_loss = 0.00035137717659478724
Trained batch 374 in epoch 14, gen_loss = 0.9003379146258036, disc_loss = 0.00035135732779356964
Trained batch 375 in epoch 14, gen_loss = 0.900230291676014, disc_loss = 0.00035075012661725345
Trained batch 376 in epoch 14, gen_loss = 0.9003462144803621, disc_loss = 0.0003501306112626548
Trained batch 377 in epoch 14, gen_loss = 0.9002239246847769, disc_loss = 0.00034955906706816574
Trained batch 378 in epoch 14, gen_loss = 0.9001192046344123, disc_loss = 0.0003490424093358479
Trained batch 379 in epoch 14, gen_loss = 0.8999422889006765, disc_loss = 0.0003485239272872844
Trained batch 380 in epoch 14, gen_loss = 0.8996972127223578, disc_loss = 0.0003481142767833355
Trained batch 381 in epoch 14, gen_loss = 0.8997377416226252, disc_loss = 0.0003475719185622838
Trained batch 382 in epoch 14, gen_loss = 0.8998561677360036, disc_loss = 0.0003470120103190855
Trained batch 383 in epoch 14, gen_loss = 0.8997785601144036, disc_loss = 0.00034645051440899505
Trained batch 384 in epoch 14, gen_loss = 0.8994466383735855, disc_loss = 0.0003460862190393102
Trained batch 385 in epoch 14, gen_loss = 0.899259647711571, disc_loss = 0.00034543900951363723
Trained batch 386 in epoch 14, gen_loss = 0.8989398376270166, disc_loss = 0.00034481189628817545
Trained batch 387 in epoch 14, gen_loss = 0.8989525515701353, disc_loss = 0.00034421546066725346
Trained batch 388 in epoch 14, gen_loss = 0.8989584298857074, disc_loss = 0.0003438830150060588
Trained batch 389 in epoch 14, gen_loss = 0.8989462024126298, disc_loss = 0.0003434653742610513
Trained batch 390 in epoch 14, gen_loss = 0.8989135548281852, disc_loss = 0.00034307167718923575
Trained batch 391 in epoch 14, gen_loss = 0.899004267034482, disc_loss = 0.0003424869715041607
Trained batch 392 in epoch 14, gen_loss = 0.8991053448681916, disc_loss = 0.0003422803951271231
Trained batch 393 in epoch 14, gen_loss = 0.8990627185342276, disc_loss = 0.0003426723576248044
Trained batch 394 in epoch 14, gen_loss = 0.8991140493863745, disc_loss = 0.00034237461125174583
Trained batch 395 in epoch 14, gen_loss = 0.8994443965981705, disc_loss = 0.0003422940560333452
Trained batch 396 in epoch 14, gen_loss = 0.8997187769082692, disc_loss = 0.00034195387732517327
Trained batch 397 in epoch 14, gen_loss = 0.8996188315614384, disc_loss = 0.00034157823500748205
Trained batch 398 in epoch 14, gen_loss = 0.8995785777431383, disc_loss = 0.00034110604838703297
Trained batch 399 in epoch 14, gen_loss = 0.8995018023252487, disc_loss = 0.0003412055453918583
Trained batch 400 in epoch 14, gen_loss = 0.8995201123920165, disc_loss = 0.00034109974990031587
Trained batch 401 in epoch 14, gen_loss = 0.8994319983086183, disc_loss = 0.00034101088503442253
Trained batch 402 in epoch 14, gen_loss = 0.8992830713096979, disc_loss = 0.00034082936482008886
Trained batch 403 in epoch 14, gen_loss = 0.899149754259846, disc_loss = 0.0003405660229306011
Trained batch 404 in epoch 14, gen_loss = 0.8991191546122234, disc_loss = 0.00034050641746337834
Trained batch 405 in epoch 14, gen_loss = 0.8989124016221521, disc_loss = 0.0003411024133438242
Trained batch 406 in epoch 14, gen_loss = 0.8990714523657534, disc_loss = 0.00034099826598880327
Trained batch 407 in epoch 14, gen_loss = 0.8991065307282934, disc_loss = 0.00034222412708842574
Trained batch 408 in epoch 14, gen_loss = 0.8993176079029559, disc_loss = 0.0003472632115806708
Trained batch 409 in epoch 14, gen_loss = 0.8994505355997784, disc_loss = 0.0003493423272519111
Trained batch 410 in epoch 14, gen_loss = 0.8996398828905574, disc_loss = 0.00035105873217028416
Trained batch 411 in epoch 14, gen_loss = 0.9003773490780765, disc_loss = 0.0003527355209512589
Trained batch 412 in epoch 14, gen_loss = 0.9007287651805554, disc_loss = 0.0003531998375279335
Trained batch 413 in epoch 14, gen_loss = 0.9008173284611264, disc_loss = 0.00035393342403804655
Trained batch 414 in epoch 14, gen_loss = 0.9007535486336214, disc_loss = 0.0003540127622826216
Trained batch 415 in epoch 14, gen_loss = 0.9008662482866874, disc_loss = 0.0003538034513195061
Trained batch 416 in epoch 14, gen_loss = 0.9008133235595209, disc_loss = 0.0003540346404219022
Trained batch 417 in epoch 14, gen_loss = 0.9006863263520327, disc_loss = 0.0003551570452663671
Trained batch 418 in epoch 14, gen_loss = 0.9008566512412843, disc_loss = 0.0003551889666008012
Trained batch 419 in epoch 14, gen_loss = 0.9008014213471186, disc_loss = 0.0003549614485867399
Trained batch 420 in epoch 14, gen_loss = 0.9009408249990957, disc_loss = 0.00035479816762913537
Trained batch 421 in epoch 14, gen_loss = 0.9007982391316743, disc_loss = 0.0003544894035598561
Trained batch 422 in epoch 14, gen_loss = 0.9006639021508237, disc_loss = 0.00035418072488281686
Trained batch 423 in epoch 14, gen_loss = 0.9008189129098406, disc_loss = 0.0003538866748094047
Trained batch 424 in epoch 14, gen_loss = 0.9007975487148061, disc_loss = 0.0003532880895620431
Trained batch 425 in epoch 14, gen_loss = 0.900918787633869, disc_loss = 0.0003527547636229497
Trained batch 426 in epoch 14, gen_loss = 0.9009525186842443, disc_loss = 0.0003523827441223729
Trained batch 427 in epoch 14, gen_loss = 0.9008927579238036, disc_loss = 0.00035183580284780456
Trained batch 428 in epoch 14, gen_loss = 0.9009761462956319, disc_loss = 0.0003513152549156728
Trained batch 429 in epoch 14, gen_loss = 0.9012538649315058, disc_loss = 0.0003507952702293974
Trained batch 430 in epoch 14, gen_loss = 0.9011551494388182, disc_loss = 0.00035055211199995284
Trained batch 431 in epoch 14, gen_loss = 0.9012307528820303, disc_loss = 0.00035010910573031717
Trained batch 432 in epoch 14, gen_loss = 0.9013060690624334, disc_loss = 0.00034976287276589465
Trained batch 433 in epoch 14, gen_loss = 0.9011809799803018, disc_loss = 0.00034928545253866346
Trained batch 434 in epoch 14, gen_loss = 0.9011225705859305, disc_loss = 0.00034874872637018776
Trained batch 435 in epoch 14, gen_loss = 0.9008853516174019, disc_loss = 0.00034916061038763366
Trained batch 436 in epoch 14, gen_loss = 0.9008986902182381, disc_loss = 0.0003487720548892415
Trained batch 437 in epoch 14, gen_loss = 0.9008042721171358, disc_loss = 0.00034896175441657485
Trained batch 438 in epoch 14, gen_loss = 0.9009942196496256, disc_loss = 0.0003488659472199441
Trained batch 439 in epoch 14, gen_loss = 0.9007956525141543, disc_loss = 0.00034854439452994317
Trained batch 440 in epoch 14, gen_loss = 0.9009367853335513, disc_loss = 0.00034816811168634983
Trained batch 441 in epoch 14, gen_loss = 0.9010147878487186, disc_loss = 0.00034770148798240753
Trained batch 442 in epoch 14, gen_loss = 0.9011432963084959, disc_loss = 0.0003472890675437908
Trained batch 443 in epoch 14, gen_loss = 0.9012124081989666, disc_loss = 0.00034700636011244195
Trained batch 444 in epoch 14, gen_loss = 0.901067097133465, disc_loss = 0.00034677010268925195
Trained batch 445 in epoch 14, gen_loss = 0.901013004004688, disc_loss = 0.0003466812171764471
Trained batch 446 in epoch 14, gen_loss = 0.9009701945637697, disc_loss = 0.00034635313946734987
Trained batch 447 in epoch 14, gen_loss = 0.9008190792852214, disc_loss = 0.00034618065709374993
Trained batch 448 in epoch 14, gen_loss = 0.9009133426012069, disc_loss = 0.0003459526080470159
Trained batch 449 in epoch 14, gen_loss = 0.9009081464343601, disc_loss = 0.0003470476627505074
Trained batch 450 in epoch 14, gen_loss = 0.9007717417243315, disc_loss = 0.0003470974172075215
Trained batch 451 in epoch 14, gen_loss = 0.9011494455348074, disc_loss = 0.0003472866520231005
Trained batch 452 in epoch 14, gen_loss = 0.9013054195881942, disc_loss = 0.0003471711608601804
Trained batch 453 in epoch 14, gen_loss = 0.9011200413042229, disc_loss = 0.0003467833582967795
Trained batch 454 in epoch 14, gen_loss = 0.901116025185847, disc_loss = 0.00034668187845554615
Trained batch 455 in epoch 14, gen_loss = 0.9009932408991613, disc_loss = 0.00034622804515381354
Trained batch 456 in epoch 14, gen_loss = 0.9008832320864404, disc_loss = 0.0003463316069601544
Trained batch 457 in epoch 14, gen_loss = 0.9008992289611867, disc_loss = 0.0003459313783340164
Trained batch 458 in epoch 14, gen_loss = 0.9008651105666732, disc_loss = 0.00034572780010552187
Trained batch 459 in epoch 14, gen_loss = 0.9012253420508426, disc_loss = 0.00034539230239359945
Trained batch 460 in epoch 14, gen_loss = 0.9012253908945527, disc_loss = 0.000345086473147102
Trained batch 461 in epoch 14, gen_loss = 0.9010758390932372, disc_loss = 0.0003450486530387044
Trained batch 462 in epoch 14, gen_loss = 0.9012435869058316, disc_loss = 0.00034628951204583635
Trained batch 463 in epoch 14, gen_loss = 0.9010720517614792, disc_loss = 0.00034652136099762646
Trained batch 464 in epoch 14, gen_loss = 0.9011278899767066, disc_loss = 0.0003462902450200511
Trained batch 465 in epoch 14, gen_loss = 0.9012252071896336, disc_loss = 0.0003460213637415144
Trained batch 466 in epoch 14, gen_loss = 0.9015378048384215, disc_loss = 0.0003457216653006642
Trained batch 467 in epoch 14, gen_loss = 0.9014836230084428, disc_loss = 0.0003454771795699126
Trained batch 468 in epoch 14, gen_loss = 0.9014114925602098, disc_loss = 0.0003453167431530104
Trained batch 469 in epoch 14, gen_loss = 0.9014064199112831, disc_loss = 0.00034513922508538485
Trained batch 470 in epoch 14, gen_loss = 0.9016284237748246, disc_loss = 0.00034513436508712983
Trained batch 471 in epoch 14, gen_loss = 0.9015578217173027, disc_loss = 0.0003448135653728722
Trained batch 472 in epoch 14, gen_loss = 0.9016153891797297, disc_loss = 0.00034891994480274016
Trained batch 473 in epoch 14, gen_loss = 0.9014583095468046, disc_loss = 0.00035387182045572746
Trained batch 474 in epoch 14, gen_loss = 0.9017749328362314, disc_loss = 0.00035474485160145715
Trained batch 475 in epoch 14, gen_loss = 0.9020941120987179, disc_loss = 0.0003551887242517731
Trained batch 476 in epoch 14, gen_loss = 0.9022797874684604, disc_loss = 0.000356246764804344
Trained batch 477 in epoch 14, gen_loss = 0.9023927727004973, disc_loss = 0.0003562434501561169
Trained batch 478 in epoch 14, gen_loss = 0.9026055438035714, disc_loss = 0.000356494612096943
Trained batch 479 in epoch 14, gen_loss = 0.9026306975632906, disc_loss = 0.00035632491132370583
Trained batch 480 in epoch 14, gen_loss = 0.9027349062868066, disc_loss = 0.0003558711768752409
Trained batch 481 in epoch 14, gen_loss = 0.9026476504644417, disc_loss = 0.0003557473987353486
Trained batch 482 in epoch 14, gen_loss = 0.9026119327693252, disc_loss = 0.00035535637729157215
Trained batch 483 in epoch 14, gen_loss = 0.9024327772954279, disc_loss = 0.0003551450562336259
Trained batch 484 in epoch 14, gen_loss = 0.9023372650146484, disc_loss = 0.0003552949128038797
Trained batch 485 in epoch 14, gen_loss = 0.9021995533640983, disc_loss = 0.0003549232678928646
Trained batch 486 in epoch 14, gen_loss = 0.9021282328227707, disc_loss = 0.0003562643354303477
Trained batch 487 in epoch 14, gen_loss = 0.9020569358692795, disc_loss = 0.00035683426707334146
Trained batch 488 in epoch 14, gen_loss = 0.9021924378194205, disc_loss = 0.00035666130098194296
Trained batch 489 in epoch 14, gen_loss = 0.9022852059529752, disc_loss = 0.0003565061611731594
Trained batch 490 in epoch 14, gen_loss = 0.9019842958741664, disc_loss = 0.00035705698794892055
Trained batch 491 in epoch 14, gen_loss = 0.9019311180686563, disc_loss = 0.00035694721512159527
Trained batch 492 in epoch 14, gen_loss = 0.9018936061714049, disc_loss = 0.0003577253301193443
Trained batch 493 in epoch 14, gen_loss = 0.9018473679478834, disc_loss = 0.0003583842695470115
Trained batch 494 in epoch 14, gen_loss = 0.9015691298427004, disc_loss = 0.00035840711636337064
Trained batch 495 in epoch 14, gen_loss = 0.9015669141325259, disc_loss = 0.00035859397001096965
Trained batch 496 in epoch 14, gen_loss = 0.9015986308965165, disc_loss = 0.00035872092402364003
Trained batch 497 in epoch 14, gen_loss = 0.9013415250672873, disc_loss = 0.0003595849647898279
Trained batch 498 in epoch 14, gen_loss = 0.9013341633016934, disc_loss = 0.00036142990656826043
Trained batch 499 in epoch 14, gen_loss = 0.9016229318380355, disc_loss = 0.0003611143709276803
Trained batch 500 in epoch 14, gen_loss = 0.9017062651183076, disc_loss = 0.0003608386058424471
Trained batch 501 in epoch 14, gen_loss = 0.9016222711578309, disc_loss = 0.0003604526374469589
Trained batch 502 in epoch 14, gen_loss = 0.9017837137635613, disc_loss = 0.00036021851713234046
Trained batch 503 in epoch 14, gen_loss = 0.9016533654833597, disc_loss = 0.00037283670145183036
Trained batch 504 in epoch 14, gen_loss = 0.901763119910023, disc_loss = 0.0003762538321224032
Trained batch 505 in epoch 14, gen_loss = 0.9019520232093193, disc_loss = 0.0003778758378728871
Trained batch 506 in epoch 14, gen_loss = 0.9021578710930352, disc_loss = 0.0003793836007339244
Trained batch 507 in epoch 14, gen_loss = 0.9024099272301817, disc_loss = 0.0003805537052694561
Trained batch 508 in epoch 14, gen_loss = 0.9026182476570189, disc_loss = 0.0003817805122448706
Trained batch 509 in epoch 14, gen_loss = 0.9026681167237899, disc_loss = 0.0003840327938543815
Trained batch 510 in epoch 14, gen_loss = 0.9027222664388892, disc_loss = 0.00038425794414403156
Trained batch 511 in epoch 14, gen_loss = 0.9027160805417225, disc_loss = 0.00038583358082178165
Trained batch 512 in epoch 14, gen_loss = 0.9028075873038457, disc_loss = 0.0003885882259863946
Trained batch 513 in epoch 14, gen_loss = 0.9028485459112472, disc_loss = 0.00038930391444342666
Trained batch 514 in epoch 14, gen_loss = 0.902762402840031, disc_loss = 0.00039005801624175413
Trained batch 515 in epoch 14, gen_loss = 0.9027754386035047, disc_loss = 0.0003902102322425953
Trained batch 516 in epoch 14, gen_loss = 0.9028435136178937, disc_loss = 0.0003901142543686168
Trained batch 517 in epoch 14, gen_loss = 0.9031430192895837, disc_loss = 0.00038990398044572085
Trained batch 518 in epoch 14, gen_loss = 0.9032113671532486, disc_loss = 0.0003896059653666122
Trained batch 519 in epoch 14, gen_loss = 0.9031972563037506, disc_loss = 0.000389269895374757
Trained batch 520 in epoch 14, gen_loss = 0.9032437815089601, disc_loss = 0.0003888474342682722
Trained batch 521 in epoch 14, gen_loss = 0.9035232012299286, disc_loss = 0.00038851098726384013
Trained batch 522 in epoch 14, gen_loss = 0.9035278704608604, disc_loss = 0.0003882088826937658
Trained batch 523 in epoch 14, gen_loss = 0.9037588559489214, disc_loss = 0.00038786456196054366
Trained batch 524 in epoch 14, gen_loss = 0.9034956455230713, disc_loss = 0.00038912393931587715
Trained batch 525 in epoch 14, gen_loss = 0.9035054932529029, disc_loss = 0.0003903923707426802
Trained batch 526 in epoch 14, gen_loss = 0.9036721933272577, disc_loss = 0.00039032075644812705
Trained batch 527 in epoch 14, gen_loss = 0.9035945301028815, disc_loss = 0.0003901431591381852
Trained batch 528 in epoch 14, gen_loss = 0.9037349757039479, disc_loss = 0.0003897174135137029
Trained batch 529 in epoch 14, gen_loss = 0.9039057501082151, disc_loss = 0.00038957817489303264
Trained batch 530 in epoch 14, gen_loss = 0.903902900533263, disc_loss = 0.00038915159834198925
Trained batch 531 in epoch 14, gen_loss = 0.9039328181205836, disc_loss = 0.000388587498197641
Trained batch 532 in epoch 14, gen_loss = 0.9037381233909564, disc_loss = 0.00038821534127795085
Trained batch 533 in epoch 14, gen_loss = 0.9038795804263055, disc_loss = 0.0003878102815202708
Trained batch 534 in epoch 14, gen_loss = 0.9037887225641268, disc_loss = 0.00038740554299242534
Trained batch 535 in epoch 14, gen_loss = 0.903701372333427, disc_loss = 0.0003869907160463557
Trained batch 536 in epoch 14, gen_loss = 0.9038846110942421, disc_loss = 0.000386494269938268
Trained batch 537 in epoch 14, gen_loss = 0.9036524091954568, disc_loss = 0.00038673929714277077
Trained batch 538 in epoch 14, gen_loss = 0.9037028981272498, disc_loss = 0.0003863565766390591
Trained batch 539 in epoch 14, gen_loss = 0.9036796946216512, disc_loss = 0.0003859093723332518
Trained batch 540 in epoch 14, gen_loss = 0.903725410455256, disc_loss = 0.00038587579490152545
Trained batch 541 in epoch 14, gen_loss = 0.903623917225982, disc_loss = 0.00038540672731933326
Trained batch 542 in epoch 14, gen_loss = 0.9034783497699717, disc_loss = 0.00038509323113157566
Trained batch 543 in epoch 14, gen_loss = 0.9034027616109919, disc_loss = 0.00038475638716055767
Trained batch 544 in epoch 14, gen_loss = 0.9033786514483461, disc_loss = 0.0003843347579235459
Trained batch 545 in epoch 14, gen_loss = 0.9032937530632857, disc_loss = 0.00038402105387948
Trained batch 546 in epoch 14, gen_loss = 0.9033065068874324, disc_loss = 0.00038380220190992653
Trained batch 547 in epoch 14, gen_loss = 0.9032009424519365, disc_loss = 0.00038341404509275597
Trained batch 548 in epoch 14, gen_loss = 0.9030773594079773, disc_loss = 0.00038316895668566626
Trained batch 549 in epoch 14, gen_loss = 0.9031127806143328, disc_loss = 0.0003826942700834479
Trained batch 550 in epoch 14, gen_loss = 0.9029319191152084, disc_loss = 0.00038233675036404856
Trained batch 551 in epoch 14, gen_loss = 0.903008807612502, disc_loss = 0.00038217548394575294
Trained batch 552 in epoch 14, gen_loss = 0.9030148408512095, disc_loss = 0.00038175510368522534
Trained batch 553 in epoch 14, gen_loss = 0.9027957942081273, disc_loss = 0.00038167418214033984
Trained batch 554 in epoch 14, gen_loss = 0.902796442014677, disc_loss = 0.00038134044345399063
Trained batch 555 in epoch 14, gen_loss = 0.9028847068548203, disc_loss = 0.00038111468457703546
Trained batch 556 in epoch 14, gen_loss = 0.9030282203128137, disc_loss = 0.00038073714379180656
Trained batch 557 in epoch 14, gen_loss = 0.9030829876340846, disc_loss = 0.00038042514558410433
Trained batch 558 in epoch 14, gen_loss = 0.9029898701072379, disc_loss = 0.0003801080809333628
Trained batch 559 in epoch 14, gen_loss = 0.902758371510676, disc_loss = 0.000379743825461836
Trained batch 560 in epoch 14, gen_loss = 0.902595814855341, disc_loss = 0.00037955432002062853
Trained batch 561 in epoch 14, gen_loss = 0.9025306762113265, disc_loss = 0.00037919179156757773
Trained batch 562 in epoch 14, gen_loss = 0.9024213167109244, disc_loss = 0.00037885090627190184
Trained batch 563 in epoch 14, gen_loss = 0.9022255465916708, disc_loss = 0.00037843072026047823
Trained batch 564 in epoch 14, gen_loss = 0.9024144389988047, disc_loss = 0.0003780759181914876
Trained batch 565 in epoch 14, gen_loss = 0.9023791687438008, disc_loss = 0.0003775623244826407
Trained batch 566 in epoch 14, gen_loss = 0.9022550874075982, disc_loss = 0.0003770747013557193
Trained batch 567 in epoch 14, gen_loss = 0.9022346459014315, disc_loss = 0.0003766099923691207
Trained batch 568 in epoch 14, gen_loss = 0.9020126899851646, disc_loss = 0.000376476525844227
Trained batch 569 in epoch 14, gen_loss = 0.9020433471913923, disc_loss = 0.0003760052370030041
Trained batch 570 in epoch 14, gen_loss = 0.9019251215270021, disc_loss = 0.00037558376253908745
Trained batch 571 in epoch 14, gen_loss = 0.9020297007335649, disc_loss = 0.0003756085552976929
Trained batch 572 in epoch 14, gen_loss = 0.9018061551124014, disc_loss = 0.0003753366368287609
Trained batch 573 in epoch 14, gen_loss = 0.9017918412070657, disc_loss = 0.0003751482513016463
Trained batch 574 in epoch 14, gen_loss = 0.9019700832988905, disc_loss = 0.0003747566672467181
Trained batch 575 in epoch 14, gen_loss = 0.9018612465717726, disc_loss = 0.0003744676970301144
Trained batch 576 in epoch 14, gen_loss = 0.9015603543774094, disc_loss = 0.00040254984301171126
Trained batch 577 in epoch 14, gen_loss = 0.9014296352244578, disc_loss = 0.00040799060233813873
Trained batch 578 in epoch 14, gen_loss = 0.9014424110323654, disc_loss = 0.0004104953359761026
Trained batch 579 in epoch 14, gen_loss = 0.9013534545898437, disc_loss = 0.00041286007637671867
Trained batch 580 in epoch 14, gen_loss = 0.9014992946806956, disc_loss = 0.0004131806784521038
Trained batch 581 in epoch 14, gen_loss = 0.901558976812461, disc_loss = 0.0004131931216392788
Trained batch 582 in epoch 14, gen_loss = 0.9014754905708863, disc_loss = 0.0004132807783053239
Trained batch 583 in epoch 14, gen_loss = 0.9014803933566564, disc_loss = 0.00041316133412119474
Trained batch 584 in epoch 14, gen_loss = 0.9014463232113765, disc_loss = 0.00041377160933991084
Trained batch 585 in epoch 14, gen_loss = 0.9014243604583545, disc_loss = 0.000413976334809777
Trained batch 586 in epoch 14, gen_loss = 0.9014740447169471, disc_loss = 0.0004141472628180674
Trained batch 587 in epoch 14, gen_loss = 0.9013705918578063, disc_loss = 0.000414924849179925
Trained batch 588 in epoch 14, gen_loss = 0.901052708941526, disc_loss = 0.00046213779620018255
Trained batch 589 in epoch 14, gen_loss = 0.9010666779542373, disc_loss = 0.0004663199650506505
Trained batch 590 in epoch 14, gen_loss = 0.9011744217420794, disc_loss = 0.0005994952808653498
Trained batch 591 in epoch 14, gen_loss = 0.9013127015047783, disc_loss = 0.0006120578058766409
Trained batch 592 in epoch 14, gen_loss = 0.901568087015747, disc_loss = 0.000620652637870442
Trained batch 593 in epoch 14, gen_loss = 0.9017488722648684, disc_loss = 0.0006253471195181167
Trained batch 594 in epoch 14, gen_loss = 0.9018019062130391, disc_loss = 0.0006266042909549721
Trained batch 595 in epoch 14, gen_loss = 0.9020289649699358, disc_loss = 0.0006271653897820459
Trained batch 596 in epoch 14, gen_loss = 0.9019456488802605, disc_loss = 0.0006274858589960384
Trained batch 597 in epoch 14, gen_loss = 0.9019584416545753, disc_loss = 0.0006274997157314917
Trained batch 598 in epoch 14, gen_loss = 0.9020532915906635, disc_loss = 0.0006272928282103108
Trained batch 599 in epoch 14, gen_loss = 0.902174492975076, disc_loss = 0.000627493307935462
Trained batch 600 in epoch 14, gen_loss = 0.9022867746043721, disc_loss = 0.0006275500623472872
Trained batch 601 in epoch 14, gen_loss = 0.9025126952071523, disc_loss = 0.0006274711985107777
Trained batch 602 in epoch 14, gen_loss = 0.9027392950224046, disc_loss = 0.0006273256631310918
Trained batch 603 in epoch 14, gen_loss = 0.9026726128052402, disc_loss = 0.0006269063802597125
Trained batch 604 in epoch 14, gen_loss = 0.9026647710603131, disc_loss = 0.0006263339757815404
Trained batch 605 in epoch 14, gen_loss = 0.9027216254484536, disc_loss = 0.0006257854880885722
Trained batch 606 in epoch 14, gen_loss = 0.9026508743719764, disc_loss = 0.0006254661986600498
Trained batch 607 in epoch 14, gen_loss = 0.9025664404034615, disc_loss = 0.0006249848361939689
Trained batch 608 in epoch 14, gen_loss = 0.9026189375002004, disc_loss = 0.0006252457409250674
Trained batch 609 in epoch 14, gen_loss = 0.902361267707387, disc_loss = 0.0006248321879433743
Trained batch 610 in epoch 14, gen_loss = 0.9022795406769223, disc_loss = 0.0006253128520170388
Trained batch 611 in epoch 14, gen_loss = 0.9023174594819935, disc_loss = 0.0006288276024480819
Trained batch 612 in epoch 14, gen_loss = 0.9020691807662877, disc_loss = 0.0006415010879057813
Trained batch 613 in epoch 14, gen_loss = 0.9015289107246586, disc_loss = 0.0007527358557896974
Trained batch 614 in epoch 14, gen_loss = 0.9015144217305067, disc_loss = 0.0007835309680861731
Trained batch 615 in epoch 14, gen_loss = 0.9015694167706874, disc_loss = 0.0008530473555234116
Trained batch 616 in epoch 14, gen_loss = 0.90199702852549, disc_loss = 0.0008578278605276764
Trained batch 617 in epoch 14, gen_loss = 0.9020279155001285, disc_loss = 0.0008698413601562585
Trained batch 618 in epoch 14, gen_loss = 0.9022076375457505, disc_loss = 0.0008745999730896259
Trained batch 619 in epoch 14, gen_loss = 0.9021357237331329, disc_loss = 0.0008759231883994934
Trained batch 620 in epoch 14, gen_loss = 0.9023329519611242, disc_loss = 0.0008763681163436968
Trained batch 621 in epoch 14, gen_loss = 0.9022696143752892, disc_loss = 0.0008761575457698387
Trained batch 622 in epoch 14, gen_loss = 0.9022181812871134, disc_loss = 0.0008765025553741996
Trained batch 623 in epoch 14, gen_loss = 0.9024293134227778, disc_loss = 0.0008760955861362163
Trained batch 624 in epoch 14, gen_loss = 0.9024062013626098, disc_loss = 0.0008755407429300249
Trained batch 625 in epoch 14, gen_loss = 0.9026507129684423, disc_loss = 0.0008748637588293747
Trained batch 626 in epoch 14, gen_loss = 0.9026135954370149, disc_loss = 0.0008742607617249453
Trained batch 627 in epoch 14, gen_loss = 0.902703108301588, disc_loss = 0.0008733333366056222
Trained batch 628 in epoch 14, gen_loss = 0.9027502992573906, disc_loss = 0.000872902398318606
Trained batch 629 in epoch 14, gen_loss = 0.9028743334232815, disc_loss = 0.0008720970039056348
Trained batch 630 in epoch 14, gen_loss = 0.9029653643843867, disc_loss = 0.0008711227777701096
Trained batch 631 in epoch 14, gen_loss = 0.9030109576975243, disc_loss = 0.000870735934319172
Trained batch 632 in epoch 14, gen_loss = 0.9030058363225976, disc_loss = 0.0008702577743440202
Trained batch 633 in epoch 14, gen_loss = 0.9030350308501006, disc_loss = 0.000869558585783076
Trained batch 634 in epoch 14, gen_loss = 0.9032342618844641, disc_loss = 0.0008686030199237931
Trained batch 635 in epoch 14, gen_loss = 0.9033014105176026, disc_loss = 0.0008676781786939586
Trained batch 636 in epoch 14, gen_loss = 0.9034500039727946, disc_loss = 0.000867181599945754
Trained batch 637 in epoch 14, gen_loss = 0.9033871902193769, disc_loss = 0.0008667297310051348
Trained batch 638 in epoch 14, gen_loss = 0.9035825706983396, disc_loss = 0.0008661711125937764
Trained batch 639 in epoch 14, gen_loss = 0.9035908598452806, disc_loss = 0.0008650048443428204
Trained batch 640 in epoch 14, gen_loss = 0.903548085559363, disc_loss = 0.0008638910949570722
Trained batch 641 in epoch 14, gen_loss = 0.9035778541431249, disc_loss = 0.0008629922776437122
Trained batch 642 in epoch 14, gen_loss = 0.9037687995385605, disc_loss = 0.0008625553243714428
Trained batch 643 in epoch 14, gen_loss = 0.90371617026951, disc_loss = 0.0008615594695764919
Trained batch 644 in epoch 14, gen_loss = 0.9038626606150191, disc_loss = 0.0008611808310902692
Trained batch 645 in epoch 14, gen_loss = 0.9036979912419806, disc_loss = 0.000860450288946989
Trained batch 646 in epoch 14, gen_loss = 0.903804653578969, disc_loss = 0.0008597234462952303
Trained batch 647 in epoch 14, gen_loss = 0.9035846002307939, disc_loss = 0.0008632130612893911
Trained batch 648 in epoch 14, gen_loss = 0.9034742118764916, disc_loss = 0.0008624552884459308
Trained batch 649 in epoch 14, gen_loss = 0.9034569813654973, disc_loss = 0.0008614562969104064
Trained batch 650 in epoch 14, gen_loss = 0.9034655058438876, disc_loss = 0.0008606084817205914
Trained batch 651 in epoch 14, gen_loss = 0.9034105481728454, disc_loss = 0.0008596000464818265
Trained batch 652 in epoch 14, gen_loss = 0.9034206047540054, disc_loss = 0.0008584928232441074
Trained batch 653 in epoch 14, gen_loss = 0.9032988573797617, disc_loss = 0.0008574671150427789
Trained batch 654 in epoch 14, gen_loss = 0.9033542707676195, disc_loss = 0.0008567642635920881
Trained batch 655 in epoch 14, gen_loss = 0.903323075756794, disc_loss = 0.0008556847222657447
Trained batch 656 in epoch 14, gen_loss = 0.9031650304249977, disc_loss = 0.0008545718899233617
Trained batch 657 in epoch 14, gen_loss = 0.9031995872777284, disc_loss = 0.0008539451216599631
Trained batch 658 in epoch 14, gen_loss = 0.9032344933887534, disc_loss = 0.0008529887971522503
Trained batch 659 in epoch 14, gen_loss = 0.9031769158262195, disc_loss = 0.0008520960571772638
Trained batch 660 in epoch 14, gen_loss = 0.9032182186706704, disc_loss = 0.0008510128345527001
Trained batch 661 in epoch 14, gen_loss = 0.903339051498027, disc_loss = 0.0008502919555182204
Trained batch 662 in epoch 14, gen_loss = 0.9033704752476147, disc_loss = 0.0008493654136920838
Trained batch 663 in epoch 14, gen_loss = 0.9033595908837146, disc_loss = 0.0008483688373537489
Trained batch 664 in epoch 14, gen_loss = 0.903277409793739, disc_loss = 0.0008475367604475644
Trained batch 665 in epoch 14, gen_loss = 0.9033648293834549, disc_loss = 0.0008466493271333382
Trained batch 666 in epoch 14, gen_loss = 0.903301431500036, disc_loss = 0.0008457701627519911
Trained batch 667 in epoch 14, gen_loss = 0.903278653582413, disc_loss = 0.000844832046894084
Trained batch 668 in epoch 14, gen_loss = 0.9033039614936874, disc_loss = 0.0008438509278571385
Trained batch 669 in epoch 14, gen_loss = 0.903328599413829, disc_loss = 0.0008431295249954303
Trained batch 670 in epoch 14, gen_loss = 0.9033785007572032, disc_loss = 0.0008421225931247156
Trained batch 671 in epoch 14, gen_loss = 0.9033168548097213, disc_loss = 0.0008411687831648166
Trained batch 672 in epoch 14, gen_loss = 0.9033032901042638, disc_loss = 0.0008401692766805364
Trained batch 673 in epoch 14, gen_loss = 0.9032769451686112, disc_loss = 0.0008392190612709731
Trained batch 674 in epoch 14, gen_loss = 0.9033009375466241, disc_loss = 0.000838378032602594
Trained batch 675 in epoch 14, gen_loss = 0.9032278045042027, disc_loss = 0.000837408997389793
Trained batch 676 in epoch 14, gen_loss = 0.9034097819772041, disc_loss = 0.0008369769385142803
Trained batch 677 in epoch 14, gen_loss = 0.9034930915959114, disc_loss = 0.0009593484265252276
Trained batch 678 in epoch 14, gen_loss = 0.9035217980573034, disc_loss = 0.0009893819713046594
Trained batch 679 in epoch 14, gen_loss = 0.9033523081856616, disc_loss = 0.0010180089388514342
Trained batch 680 in epoch 14, gen_loss = 0.9031812457611207, disc_loss = 0.0010256702195224421
Trained batch 681 in epoch 14, gen_loss = 0.9033931704385539, disc_loss = 0.001032521967197713
Trained batch 682 in epoch 14, gen_loss = 0.9029990552459594, disc_loss = 0.0012299474000113152
Trained batch 683 in epoch 14, gen_loss = 0.9033797643860878, disc_loss = 0.001269624222541682
Trained batch 684 in epoch 14, gen_loss = 0.9034240601706679, disc_loss = 0.001297539896635512
Trained batch 685 in epoch 14, gen_loss = 0.9034989358906148, disc_loss = 0.0013489635448077925
Trained batch 686 in epoch 14, gen_loss = 0.9036626865249534, disc_loss = 0.0013659926986753408
Trained batch 687 in epoch 14, gen_loss = 0.9035569577542848, disc_loss = 0.0014121308312242881
Trained batch 688 in epoch 14, gen_loss = 0.9037220639829538, disc_loss = 0.0014204452723968087
Trained batch 689 in epoch 14, gen_loss = 0.9039403750412706, disc_loss = 0.001424826733441939
Trained batch 690 in epoch 14, gen_loss = 0.9039749772262298, disc_loss = 0.0014265327640234117
Trained batch 691 in epoch 14, gen_loss = 0.904000973167447, disc_loss = 0.0014271307358432613
Trained batch 692 in epoch 14, gen_loss = 0.9040521956109381, disc_loss = 0.001427374047616179
Trained batch 693 in epoch 14, gen_loss = 0.9039663840783089, disc_loss = 0.0014261541333530463
Trained batch 694 in epoch 14, gen_loss = 0.9038345738280591, disc_loss = 0.0014253497693546137
Trained batch 695 in epoch 14, gen_loss = 0.9037982674165704, disc_loss = 0.0014237708972505898
Trained batch 696 in epoch 14, gen_loss = 0.9038003325633374, disc_loss = 0.0014226485061698253
Trained batch 697 in epoch 14, gen_loss = 0.9038664658465836, disc_loss = 0.0014210269216078308
Trained batch 698 in epoch 14, gen_loss = 0.9039072955456244, disc_loss = 0.001419766880751295
Trained batch 699 in epoch 14, gen_loss = 0.9038367977312632, disc_loss = 0.0014187292042749633
Trained batch 700 in epoch 14, gen_loss = 0.9039285775598208, disc_loss = 0.0014173552470118805
Trained batch 701 in epoch 14, gen_loss = 0.9040462738937802, disc_loss = 0.0014158635552450345
Trained batch 702 in epoch 14, gen_loss = 0.9040514194270116, disc_loss = 0.0014145850836163403
Trained batch 703 in epoch 14, gen_loss = 0.9040081854063001, disc_loss = 0.001413476541973647
Trained batch 704 in epoch 14, gen_loss = 0.904048492807023, disc_loss = 0.0014119256172533121
Trained batch 705 in epoch 14, gen_loss = 0.9039738256769208, disc_loss = 0.0014103748313217751
Trained batch 706 in epoch 14, gen_loss = 0.9038930980454408, disc_loss = 0.001409438368022528
Trained batch 707 in epoch 14, gen_loss = 0.9038000643084951, disc_loss = 0.0014079009540855726
Trained batch 708 in epoch 14, gen_loss = 0.9037389727506382, disc_loss = 0.0014063142099474723
Trained batch 709 in epoch 14, gen_loss = 0.9037322542197268, disc_loss = 0.0014052985997154855
Trained batch 710 in epoch 14, gen_loss = 0.9038746220317738, disc_loss = 0.0014039491934441626
Trained batch 711 in epoch 14, gen_loss = 0.903845864819007, disc_loss = 0.0014028099819237408
Trained batch 712 in epoch 14, gen_loss = 0.9037796579102815, disc_loss = 0.00140107203664826
Trained batch 713 in epoch 14, gen_loss = 0.9039290454708228, disc_loss = 0.0013996815288119658
Trained batch 714 in epoch 14, gen_loss = 0.904020582962703, disc_loss = 0.0013980029991293046
Trained batch 715 in epoch 14, gen_loss = 0.9039473684306917, disc_loss = 0.0013964047396272472
Trained batch 716 in epoch 14, gen_loss = 0.9040320889720358, disc_loss = 0.0013949086892689226
Trained batch 717 in epoch 14, gen_loss = 0.903922657531616, disc_loss = 0.001393874261242809
Trained batch 718 in epoch 14, gen_loss = 0.9039781329860608, disc_loss = 0.0013923689535337627
Trained batch 719 in epoch 14, gen_loss = 0.9040512177679274, disc_loss = 0.001391625149568022
Trained batch 720 in epoch 14, gen_loss = 0.90420511691481, disc_loss = 0.0013905656018116622
Trained batch 721 in epoch 14, gen_loss = 0.9042094121184046, disc_loss = 0.0013891729933090883
Trained batch 722 in epoch 14, gen_loss = 0.9041276057231475, disc_loss = 0.0013882526852422197
Trained batch 723 in epoch 14, gen_loss = 0.9039254817514788, disc_loss = 0.0013868136951041077
Trained batch 724 in epoch 14, gen_loss = 0.904039327769444, disc_loss = 0.001385294052135954
Trained batch 725 in epoch 14, gen_loss = 0.9040276945129899, disc_loss = 0.001383958290659065
Trained batch 726 in epoch 14, gen_loss = 0.903836078624122, disc_loss = 0.001382994786822996
Trained batch 727 in epoch 14, gen_loss = 0.9039446568259826, disc_loss = 0.0013815235533711728
Trained batch 728 in epoch 14, gen_loss = 0.9039609639078828, disc_loss = 0.0013798992343856799
Trained batch 729 in epoch 14, gen_loss = 0.9039951567780482, disc_loss = 0.001378800577836108
Trained batch 730 in epoch 14, gen_loss = 0.9039064992305844, disc_loss = 0.0013776067105578495
Trained batch 731 in epoch 14, gen_loss = 0.9039571527900592, disc_loss = 0.0013761810490000666
Trained batch 732 in epoch 14, gen_loss = 0.9039935916052346, disc_loss = 0.001374592494264726
Trained batch 733 in epoch 14, gen_loss = 0.904155815492209, disc_loss = 0.0013729311599354457
Trained batch 734 in epoch 14, gen_loss = 0.9041875566755022, disc_loss = 0.0013716908299374446
Trained batch 735 in epoch 14, gen_loss = 0.9044224017340204, disc_loss = 0.0013702032009682032
Trained batch 736 in epoch 14, gen_loss = 0.9042865917834693, disc_loss = 0.0013689100645689308
Trained batch 737 in epoch 14, gen_loss = 0.9042639590214262, disc_loss = 0.0013673993340381238
Trained batch 738 in epoch 14, gen_loss = 0.9042718762151282, disc_loss = 0.0013660367904297904
Trained batch 739 in epoch 14, gen_loss = 0.9041618666938833, disc_loss = 0.0013646228464003307
Trained batch 740 in epoch 14, gen_loss = 0.9040023722307563, disc_loss = 0.0013632114642735994
Trained batch 741 in epoch 14, gen_loss = 0.903855738614126, disc_loss = 0.001361820382321259
Trained batch 742 in epoch 14, gen_loss = 0.903968886283012, disc_loss = 0.001360771140973394
Trained batch 743 in epoch 14, gen_loss = 0.9038803215308856, disc_loss = 0.0013594999139655477
Trained batch 744 in epoch 14, gen_loss = 0.9039838483669613, disc_loss = 0.0013579934074339495
Trained batch 745 in epoch 14, gen_loss = 0.90400874502857, disc_loss = 0.0013564410329862384
Trained batch 746 in epoch 14, gen_loss = 0.904069845296612, disc_loss = 0.001354912757731951
Trained batch 747 in epoch 14, gen_loss = 0.904056996903955, disc_loss = 0.0013533533011969487
Trained batch 748 in epoch 14, gen_loss = 0.9041394861899963, disc_loss = 0.001351771697697546
Trained batch 749 in epoch 14, gen_loss = 0.9038778501351674, disc_loss = 0.001351601054649412
Trained batch 750 in epoch 14, gen_loss = 0.9039231267337317, disc_loss = 0.001350568750595036
Trained batch 751 in epoch 14, gen_loss = 0.9038046251269097, disc_loss = 0.0013494633396302115
Trained batch 752 in epoch 14, gen_loss = 0.9037020428880436, disc_loss = 0.0013480538250701434
Trained batch 753 in epoch 14, gen_loss = 0.9035335566542193, disc_loss = 0.0013468624583524386
Trained batch 754 in epoch 14, gen_loss = 0.9035311274970604, disc_loss = 0.0013453871516039787
Trained batch 755 in epoch 14, gen_loss = 0.9033156282529629, disc_loss = 0.0013444734017938904
Trained batch 756 in epoch 14, gen_loss = 0.903457196495807, disc_loss = 0.001343289079224027
Trained batch 757 in epoch 14, gen_loss = 0.9036126143856854, disc_loss = 0.001341971425902996
Trained batch 758 in epoch 14, gen_loss = 0.9036632342772051, disc_loss = 0.001340480987701552
Trained batch 759 in epoch 14, gen_loss = 0.9038062376411338, disc_loss = 0.0013389886840454175
Trained batch 760 in epoch 14, gen_loss = 0.903765549484283, disc_loss = 0.0013375260596543413
Trained batch 761 in epoch 14, gen_loss = 0.9037498771518547, disc_loss = 0.0013360268690037753
Trained batch 762 in epoch 14, gen_loss = 0.9035796455130821, disc_loss = 0.0013348756688334954
Trained batch 763 in epoch 14, gen_loss = 0.9035676998617761, disc_loss = 0.0013333932493350266
Trained batch 764 in epoch 14, gen_loss = 0.903587158598931, disc_loss = 0.0013320881167743993
Trained batch 765 in epoch 14, gen_loss = 0.903684512986838, disc_loss = 0.0013306342484433278
Trained batch 766 in epoch 14, gen_loss = 0.9035638581665119, disc_loss = 0.0013291247459611918
Trained batch 767 in epoch 14, gen_loss = 0.9036922689216832, disc_loss = 0.0013277003997605636
Trained batch 768 in epoch 14, gen_loss = 0.9038981033394644, disc_loss = 0.0013262740965572764
Trained batch 769 in epoch 14, gen_loss = 0.9039526336378866, disc_loss = 0.0013248522180361619
Trained batch 770 in epoch 14, gen_loss = 0.9038863635867177, disc_loss = 0.0013232882920419797
Trained batch 771 in epoch 14, gen_loss = 0.9037712340682281, disc_loss = 0.0013217526326313978
Trained batch 772 in epoch 14, gen_loss = 0.9037035109154774, disc_loss = 0.0013204626354048833
Trained batch 773 in epoch 14, gen_loss = 0.9038016899303565, disc_loss = 0.0013189415708145136
Trained batch 774 in epoch 14, gen_loss = 0.9037833968285591, disc_loss = 0.0013175838015928505
Trained batch 775 in epoch 14, gen_loss = 0.9039534467858138, disc_loss = 0.0013161573003822717
Trained batch 776 in epoch 14, gen_loss = 0.9038012223354177, disc_loss = 0.001314613716677955
Trained batch 777 in epoch 14, gen_loss = 0.9037872805693462, disc_loss = 0.0013131820616300504
Trained batch 778 in epoch 14, gen_loss = 0.9035714633657629, disc_loss = 0.0013118766258631066
Trained batch 779 in epoch 14, gen_loss = 0.9034623236228259, disc_loss = 0.001310594953928301
Trained batch 780 in epoch 14, gen_loss = 0.9034933966039543, disc_loss = 0.0013093885782171934
Trained batch 781 in epoch 14, gen_loss = 0.9036047556211272, disc_loss = 0.0013079378484392359
Trained batch 782 in epoch 14, gen_loss = 0.9036461334880133, disc_loss = 0.0013065746430377357
Trained batch 783 in epoch 14, gen_loss = 0.9037841709748823, disc_loss = 0.0013054044184451525
Trained batch 784 in epoch 14, gen_loss = 0.903791660563961, disc_loss = 0.0013040975940500528
Trained batch 785 in epoch 14, gen_loss = 0.9037520227238118, disc_loss = 0.0013026388322300742
Trained batch 786 in epoch 14, gen_loss = 0.9037237331706657, disc_loss = 0.0013012223294991592
Trained batch 787 in epoch 14, gen_loss = 0.9038144945341924, disc_loss = 0.0012999159334960062
Trained batch 788 in epoch 14, gen_loss = 0.9037322844691452, disc_loss = 0.0012985787520899098
Trained batch 789 in epoch 14, gen_loss = 0.9036668079563334, disc_loss = 0.0012974130165747727
Trained batch 790 in epoch 14, gen_loss = 0.9036424334823859, disc_loss = 0.001295950024018365
Trained batch 791 in epoch 14, gen_loss = 0.903742276959949, disc_loss = 0.0012944970148872916
Trained batch 792 in epoch 14, gen_loss = 0.9036044528775978, disc_loss = 0.0012931452754163125
Trained batch 793 in epoch 14, gen_loss = 0.9036055656164059, disc_loss = 0.0012916804381606776
Trained batch 794 in epoch 14, gen_loss = 0.9036406132410157, disc_loss = 0.0012903719685320835
Trained batch 795 in epoch 14, gen_loss = 0.903634934569124, disc_loss = 0.0012889374039382598
Trained batch 796 in epoch 14, gen_loss = 0.9036107600258764, disc_loss = 0.0012876634707438778
Trained batch 797 in epoch 14, gen_loss = 0.9035243954425468, disc_loss = 0.0012863447412481282
Trained batch 798 in epoch 14, gen_loss = 0.9037126927113205, disc_loss = 0.0012853526749084436
Trained batch 799 in epoch 14, gen_loss = 0.903556033745408, disc_loss = 0.001283927370359379
Trained batch 800 in epoch 14, gen_loss = 0.9037292151713043, disc_loss = 0.001282811385887014
Trained batch 801 in epoch 14, gen_loss = 0.903589366157156, disc_loss = 0.0012827054904896488
Trained batch 802 in epoch 14, gen_loss = 0.9036992342950101, disc_loss = 0.001282968748406757
Trained batch 803 in epoch 14, gen_loss = 0.9038667377844378, disc_loss = 0.00128185426842154
Trained batch 804 in epoch 14, gen_loss = 0.9039990596889709, disc_loss = 0.0012807785978874117
Trained batch 805 in epoch 14, gen_loss = 0.9040880076051054, disc_loss = 0.0012797422567573833
Trained batch 806 in epoch 14, gen_loss = 0.9041398644004169, disc_loss = 0.0012786185017070973
Trained batch 807 in epoch 14, gen_loss = 0.9042301701732202, disc_loss = 0.0012773418730551447
Trained batch 808 in epoch 14, gen_loss = 0.904270437356126, disc_loss = 0.0012759945967885243
Trained batch 809 in epoch 14, gen_loss = 0.9042139018023455, disc_loss = 0.0012746128254087878
Trained batch 810 in epoch 14, gen_loss = 0.904285658522981, disc_loss = 0.0012731825712859102
Trained batch 811 in epoch 14, gen_loss = 0.9043198912748562, disc_loss = 0.0012721837447405525
Trained batch 812 in epoch 14, gen_loss = 0.9041394861128644, disc_loss = 0.0012713210329382341
Trained batch 813 in epoch 14, gen_loss = 0.9040778788213941, disc_loss = 0.0012700848028655719
Trained batch 814 in epoch 14, gen_loss = 0.90419462641324, disc_loss = 0.0012687511076922872
Trained batch 815 in epoch 14, gen_loss = 0.9042926443119844, disc_loss = 0.001267409549128905
Trained batch 816 in epoch 14, gen_loss = 0.904384711454081, disc_loss = 0.0012663513647914338
Trained batch 817 in epoch 14, gen_loss = 0.9044654421817994, disc_loss = 0.0012649420831708407
Trained batch 818 in epoch 14, gen_loss = 0.9045238880592971, disc_loss = 0.0012636877072775897
Trained batch 819 in epoch 14, gen_loss = 0.9045932003637639, disc_loss = 0.001262405757405781
Trained batch 820 in epoch 14, gen_loss = 0.9046507779050541, disc_loss = 0.0012611533744352412
Trained batch 821 in epoch 14, gen_loss = 0.9045294277424359, disc_loss = 0.0012599201555617483
Trained batch 822 in epoch 14, gen_loss = 0.9044746976721475, disc_loss = 0.0012588119116536951
Trained batch 823 in epoch 14, gen_loss = 0.9043955777599973, disc_loss = 0.0012575749964773282
Trained batch 824 in epoch 14, gen_loss = 0.9043352064219388, disc_loss = 0.0012562162559708778
Trained batch 825 in epoch 14, gen_loss = 0.9044749203519151, disc_loss = 0.0012553537768550972
Trained batch 826 in epoch 14, gen_loss = 0.904356416868904, disc_loss = 0.001254126242063323
Trained batch 827 in epoch 14, gen_loss = 0.9043209345444388, disc_loss = 0.0012528276119757572
Trained batch 828 in epoch 14, gen_loss = 0.9041953227775951, disc_loss = 0.001251722380147971
Trained batch 829 in epoch 14, gen_loss = 0.9042279155857592, disc_loss = 0.0012505061360702327
Trained batch 830 in epoch 14, gen_loss = 0.9042548546578767, disc_loss = 0.0012493465882034665
Trained batch 831 in epoch 14, gen_loss = 0.9042983542268093, disc_loss = 0.0012480829790669863
Trained batch 832 in epoch 14, gen_loss = 0.9042170623055741, disc_loss = 0.00124673121228138
Trained batch 833 in epoch 14, gen_loss = 0.9043194918895511, disc_loss = 0.0012454873522641265
Trained batch 834 in epoch 14, gen_loss = 0.9042454905852586, disc_loss = 0.0012442920989866513
Trained batch 835 in epoch 14, gen_loss = 0.904113655811862, disc_loss = 0.0012430547472509655
Trained batch 836 in epoch 14, gen_loss = 0.904186462273592, disc_loss = 0.0012417439063670912
Trained batch 837 in epoch 14, gen_loss = 0.9042847107446849, disc_loss = 0.0012404931220639278
Trained batch 838 in epoch 14, gen_loss = 0.9043584762227691, disc_loss = 0.0012393897867933469
Trained batch 839 in epoch 14, gen_loss = 0.9043370324231329, disc_loss = 0.0012381128733891056
Trained batch 840 in epoch 14, gen_loss = 0.9041687248719859, disc_loss = 0.0012369296095125942
Trained batch 841 in epoch 14, gen_loss = 0.9042049448875237, disc_loss = 0.0012356723178924816
Trained batch 842 in epoch 14, gen_loss = 0.9040542788635653, disc_loss = 0.0012344091384922826
Trained batch 843 in epoch 14, gen_loss = 0.904087112130712, disc_loss = 0.0012332374028628003
Trained batch 844 in epoch 14, gen_loss = 0.9042362560181928, disc_loss = 0.001232043653011898
Trained batch 845 in epoch 14, gen_loss = 0.9042048319011715, disc_loss = 0.001230725500363943
Trained batch 846 in epoch 14, gen_loss = 0.9042369161051871, disc_loss = 0.0012294951431404985
Trained batch 847 in epoch 14, gen_loss = 0.9042503832364982, disc_loss = 0.001228159304883895
Trained batch 848 in epoch 14, gen_loss = 0.9042458665525394, disc_loss = 0.0012268995513454067
Trained batch 849 in epoch 14, gen_loss = 0.9043410475815044, disc_loss = 0.0012256477148398785
Trained batch 850 in epoch 14, gen_loss = 0.9042996392266871, disc_loss = 0.0012243032335249962
Trained batch 851 in epoch 14, gen_loss = 0.9044739375931556, disc_loss = 0.0012230441515440392
Trained batch 852 in epoch 14, gen_loss = 0.9045253303797276, disc_loss = 0.0012217799019597876
Trained batch 853 in epoch 14, gen_loss = 0.9044402041396157, disc_loss = 0.0012205471387181394
Trained batch 854 in epoch 14, gen_loss = 0.9044260970333167, disc_loss = 0.0012221723755706532
Trained batch 855 in epoch 14, gen_loss = 0.904447258423979, disc_loss = 0.0012210174670153125
Trained batch 856 in epoch 14, gen_loss = 0.9044235142136956, disc_loss = 0.0012200998752438376
Trained batch 857 in epoch 14, gen_loss = 0.9045153925746748, disc_loss = 0.0012189004446045656
Trained batch 858 in epoch 14, gen_loss = 0.9046506781794555, disc_loss = 0.0012179269803823047
Trained batch 859 in epoch 14, gen_loss = 0.9049277861450994, disc_loss = 0.0012173990360721757
Trained batch 860 in epoch 14, gen_loss = 0.9050308634872082, disc_loss = 0.0012169417843935037
Trained batch 861 in epoch 14, gen_loss = 0.9050455448798956, disc_loss = 0.0012157896822097623
Trained batch 862 in epoch 14, gen_loss = 0.9051088270831633, disc_loss = 0.001214652377295619
Trained batch 863 in epoch 14, gen_loss = 0.9051052498182764, disc_loss = 0.0012135392324850087
Trained batch 864 in epoch 14, gen_loss = 0.9051875454842011, disc_loss = 0.001212291446448145
Trained batch 865 in epoch 14, gen_loss = 0.9051763504812403, disc_loss = 0.0012110398994705895
Trained batch 866 in epoch 14, gen_loss = 0.9050563443215798, disc_loss = 0.0012098512708171455
Trained batch 867 in epoch 14, gen_loss = 0.9050291158636594, disc_loss = 0.0012086338466373331
Trained batch 868 in epoch 14, gen_loss = 0.9049647581453839, disc_loss = 0.0012075566943885326
Trained batch 869 in epoch 14, gen_loss = 0.9049209826294033, disc_loss = 0.001206320488814401
Trained batch 870 in epoch 14, gen_loss = 0.9048829296973762, disc_loss = 0.0012050522858558712
Trained batch 871 in epoch 14, gen_loss = 0.904844910248157, disc_loss = 0.0012038338604933741
Trained batch 872 in epoch 14, gen_loss = 0.9047017283865676, disc_loss = 0.0012026976759399886
Trained batch 873 in epoch 14, gen_loss = 0.9046704507937966, disc_loss = 0.0012015867770878061
Trained batch 874 in epoch 14, gen_loss = 0.9046368099621364, disc_loss = 0.0012004301874133359
Trained batch 875 in epoch 14, gen_loss = 0.9045655849861772, disc_loss = 0.001199293819044958
Trained batch 876 in epoch 14, gen_loss = 0.9047045476624196, disc_loss = 0.0011983972850770444
Trained batch 877 in epoch 14, gen_loss = 0.9046886164805341, disc_loss = 0.0011973557179823682
Trained batch 878 in epoch 14, gen_loss = 0.9045728775285888, disc_loss = 0.0011961948793161336
Trained batch 879 in epoch 14, gen_loss = 0.9046540441160852, disc_loss = 0.0011951141899275667
Trained batch 880 in epoch 14, gen_loss = 0.9046165221936315, disc_loss = 0.0011938988695198102
Trained batch 881 in epoch 14, gen_loss = 0.9045294150203264, disc_loss = 0.0011928820939810605
Trained batch 882 in epoch 14, gen_loss = 0.9045049176210725, disc_loss = 0.0011917321615056626
Trained batch 883 in epoch 14, gen_loss = 0.904500819169558, disc_loss = 0.0011906430061168576
Trained batch 884 in epoch 14, gen_loss = 0.9044964048822047, disc_loss = 0.0011895023949646869
Trained batch 885 in epoch 14, gen_loss = 0.9046253390425215, disc_loss = 0.0011882873718204628
Trained batch 886 in epoch 14, gen_loss = 0.9045766991182003, disc_loss = 0.0011871772762536955
Trained batch 887 in epoch 14, gen_loss = 0.9045235264274452, disc_loss = 0.0011859493508529489
Trained batch 888 in epoch 14, gen_loss = 0.9044391722727412, disc_loss = 0.0011847550853544347
Trained batch 889 in epoch 14, gen_loss = 0.9044273249218973, disc_loss = 0.0011837043776978043
Trained batch 890 in epoch 14, gen_loss = 0.9043831174354896, disc_loss = 0.0011826074879157762
Trained batch 891 in epoch 14, gen_loss = 0.9043468097934808, disc_loss = 0.0011815237112264613
Trained batch 892 in epoch 14, gen_loss = 0.904312220426049, disc_loss = 0.0011803595265058758
Trained batch 893 in epoch 14, gen_loss = 0.9043329538781637, disc_loss = 0.001179170674617781
Trained batch 894 in epoch 14, gen_loss = 0.9042991407090725, disc_loss = 0.0011780922090964439
Trained batch 895 in epoch 14, gen_loss = 0.9043317644058594, disc_loss = 0.0011768763641677132
Trained batch 896 in epoch 14, gen_loss = 0.904284368589969, disc_loss = 0.001175643805487571
Trained batch 897 in epoch 14, gen_loss = 0.9042761869446472, disc_loss = 0.0011746259935376912
Trained batch 898 in epoch 14, gen_loss = 0.9042752810792212, disc_loss = 0.001173442826248994
Trained batch 899 in epoch 14, gen_loss = 0.9042004000478321, disc_loss = 0.0011723063248387513
Trained batch 900 in epoch 14, gen_loss = 0.9043003449032495, disc_loss = 0.001171187346479243
Trained batch 901 in epoch 14, gen_loss = 0.9043429656462236, disc_loss = 0.0011699862400740447
Trained batch 902 in epoch 14, gen_loss = 0.9044111441668218, disc_loss = 0.0011687804862787505
Trained batch 903 in epoch 14, gen_loss = 0.9044564930738601, disc_loss = 0.0011676611714642
Trained batch 904 in epoch 14, gen_loss = 0.9044079353796184, disc_loss = 0.0011664624711597025
Trained batch 905 in epoch 14, gen_loss = 0.9043892276602865, disc_loss = 0.0011653397202499598
Trained batch 906 in epoch 14, gen_loss = 0.9045518937026784, disc_loss = 0.0011642780696027636
Trained batch 907 in epoch 14, gen_loss = 0.9045753325397222, disc_loss = 0.001163168826438489
Trained batch 908 in epoch 14, gen_loss = 0.9046627812915378, disc_loss = 0.0011620173660424954
Trained batch 909 in epoch 14, gen_loss = 0.904716820703758, disc_loss = 0.0011608801409778067
Trained batch 910 in epoch 14, gen_loss = 0.9047425991224798, disc_loss = 0.0011597629991698265
Trained batch 911 in epoch 14, gen_loss = 0.904750297074778, disc_loss = 0.0011586677782074012
Trained batch 912 in epoch 14, gen_loss = 0.9047966117012801, disc_loss = 0.0011575249970996668
Trained batch 913 in epoch 14, gen_loss = 0.9048142467729372, disc_loss = 0.0011564128028462729
Trained batch 914 in epoch 14, gen_loss = 0.9047171898878337, disc_loss = 0.0011554278170593246
Trained batch 915 in epoch 14, gen_loss = 0.9047626020736569, disc_loss = 0.001154282435049241
Trained batch 916 in epoch 14, gen_loss = 0.9046666501912581, disc_loss = 0.001153133587336377
Trained batch 917 in epoch 14, gen_loss = 0.9044958196564178, disc_loss = 0.0011520855672353643
Trained batch 918 in epoch 14, gen_loss = 0.9044008561783957, disc_loss = 0.001151069108034095
Trained batch 919 in epoch 14, gen_loss = 0.9044986645812574, disc_loss = 0.0011499355583984416
Trained batch 920 in epoch 14, gen_loss = 0.9044745820741312, disc_loss = 0.0011487860282772826
Trained batch 921 in epoch 14, gen_loss = 0.9044750736876838, disc_loss = 0.0011476653746834051
Trained batch 922 in epoch 14, gen_loss = 0.9043942910103473, disc_loss = 0.001146550150521938
Trained batch 923 in epoch 14, gen_loss = 0.9043419597855894, disc_loss = 0.0011454845159526237
Trained batch 924 in epoch 14, gen_loss = 0.9042818274369111, disc_loss = 0.001144424045955561
Trained batch 925 in epoch 14, gen_loss = 0.9041544157794433, disc_loss = 0.0011434686232783648
Trained batch 926 in epoch 14, gen_loss = 0.9040846933953327, disc_loss = 0.0011424639250265842
Trained batch 927 in epoch 14, gen_loss = 0.904059382348225, disc_loss = 0.0011413763702029396
Trained batch 928 in epoch 14, gen_loss = 0.9039058314457905, disc_loss = 0.0011403513993665404
Trained batch 929 in epoch 14, gen_loss = 0.9038150206688912, disc_loss = 0.00113934764875755
Trained batch 930 in epoch 14, gen_loss = 0.9038999031360885, disc_loss = 0.0011382968548144376
Trained batch 931 in epoch 14, gen_loss = 0.9038932090025603, disc_loss = 0.0011373105390027841
Trained batch 932 in epoch 14, gen_loss = 0.9037575277740422, disc_loss = 0.0011362483134484
Trained batch 933 in epoch 14, gen_loss = 0.9037457730708848, disc_loss = 0.0011352400537210066
Trained batch 934 in epoch 14, gen_loss = 0.9037482885753407, disc_loss = 0.0011341400659751436
Trained batch 935 in epoch 14, gen_loss = 0.9038295415986297, disc_loss = 0.0011330754128938967
Trained batch 936 in epoch 14, gen_loss = 0.9038487161363583, disc_loss = 0.0011320270221728112
Trained batch 937 in epoch 14, gen_loss = 0.9038195254197762, disc_loss = 0.0011309360977971425
Trained batch 938 in epoch 14, gen_loss = 0.9037860426912927, disc_loss = 0.001129898039994913
Trained batch 939 in epoch 14, gen_loss = 0.9038813060268442, disc_loss = 0.0011289830801499501
Trained batch 940 in epoch 14, gen_loss = 0.9039092696688507, disc_loss = 0.0011279670234661209
Trained batch 941 in epoch 14, gen_loss = 0.9038551731347532, disc_loss = 0.0011269775939566002
Trained batch 942 in epoch 14, gen_loss = 0.903769348673957, disc_loss = 0.0011259267834988734
Trained batch 943 in epoch 14, gen_loss = 0.9037283472085403, disc_loss = 0.0011248460504001572
Trained batch 944 in epoch 14, gen_loss = 0.9036365664194501, disc_loss = 0.0011238211824631974
Trained batch 945 in epoch 14, gen_loss = 0.9035676738550497, disc_loss = 0.0011228352886127838
Trained batch 946 in epoch 14, gen_loss = 0.9035636138135553, disc_loss = 0.0011218739562627216
Trained batch 947 in epoch 14, gen_loss = 0.9035356719408357, disc_loss = 0.0011208153983919718
Trained batch 948 in epoch 14, gen_loss = 0.9035551250294965, disc_loss = 0.0011197800617374321
Trained batch 949 in epoch 14, gen_loss = 0.903464081287384, disc_loss = 0.0011187584245559072
Trained batch 950 in epoch 14, gen_loss = 0.9034260799706797, disc_loss = 0.0011177486912808876
Trained batch 951 in epoch 14, gen_loss = 0.9034099337183127, disc_loss = 0.0011167528644807493
Trained batch 952 in epoch 14, gen_loss = 0.9032697640085771, disc_loss = 0.0011157610729036966
Trained batch 953 in epoch 14, gen_loss = 0.9032965218745937, disc_loss = 0.0011147087053613018
Trained batch 954 in epoch 14, gen_loss = 0.9033983947094822, disc_loss = 0.0011136744295567498
Trained batch 955 in epoch 14, gen_loss = 0.9032849559724081, disc_loss = 0.0011126707977078033
Trained batch 956 in epoch 14, gen_loss = 0.9032212123352656, disc_loss = 0.0011115955623177433
Trained batch 957 in epoch 14, gen_loss = 0.9032338355553176, disc_loss = 0.0011105366961268969
Trained batch 958 in epoch 14, gen_loss = 0.9032409463982886, disc_loss = 0.0011094923134308918
Trained batch 959 in epoch 14, gen_loss = 0.9033327696224054, disc_loss = 0.0011084553745073814
Trained batch 960 in epoch 14, gen_loss = 0.9034192199885659, disc_loss = 0.001107465096380313
Trained batch 961 in epoch 14, gen_loss = 0.9033385351641015, disc_loss = 0.0011064260303373318
Trained batch 962 in epoch 14, gen_loss = 0.9034294893932243, disc_loss = 0.0011054546085194402
Trained batch 963 in epoch 14, gen_loss = 0.903366301440599, disc_loss = 0.0011044447352007516
Trained batch 964 in epoch 14, gen_loss = 0.9033885160258397, disc_loss = 0.0011034251877150155
Trained batch 965 in epoch 14, gen_loss = 0.90344058134541, disc_loss = 0.00110240282646793
Trained batch 966 in epoch 14, gen_loss = 0.9034150826524184, disc_loss = 0.001101508963662426
Trained batch 967 in epoch 14, gen_loss = 0.9034461933842375, disc_loss = 0.0011005372145203084
Trained batch 968 in epoch 14, gen_loss = 0.9034761159043563, disc_loss = 0.001099614909004518
Trained batch 969 in epoch 14, gen_loss = 0.9035165605471306, disc_loss = 0.0010986551675422251
Trained batch 970 in epoch 14, gen_loss = 0.9034557502743635, disc_loss = 0.0010976411096080773
Trained batch 971 in epoch 14, gen_loss = 0.903377118179337, disc_loss = 0.0010966136592268799
Trained batch 972 in epoch 14, gen_loss = 0.9033254702314198, disc_loss = 0.0010956115666752367
Trained batch 973 in epoch 14, gen_loss = 0.90332905461656, disc_loss = 0.0010945831156755656
Trained batch 974 in epoch 14, gen_loss = 0.9032578520897108, disc_loss = 0.001093577958713584
Trained batch 975 in epoch 14, gen_loss = 0.9032105222100117, disc_loss = 0.0010925795777066163
Trained batch 976 in epoch 14, gen_loss = 0.9027001576511496, disc_loss = 0.0012619366468057992
Trained batch 977 in epoch 14, gen_loss = 0.9029272009136731, disc_loss = 0.001785839973821946
Trained batch 978 in epoch 14, gen_loss = 0.9030413946043605, disc_loss = 0.002013776983415736
Trained batch 979 in epoch 14, gen_loss = 0.9030190062766172, disc_loss = 0.0020568071838931003
Trained batch 980 in epoch 14, gen_loss = 0.9030100726327887, disc_loss = 0.0021106874778204945
Trained batch 981 in epoch 14, gen_loss = 0.9030656057681182, disc_loss = 0.002121251451364344
Trained batch 982 in epoch 14, gen_loss = 0.9033227476802023, disc_loss = 0.002125384057530627
Trained batch 983 in epoch 14, gen_loss = 0.9034251593113914, disc_loss = 0.0021292179943167306
Trained batch 984 in epoch 14, gen_loss = 0.9035105107399413, disc_loss = 0.0021318627883568477
Trained batch 985 in epoch 14, gen_loss = 0.9036413306638629, disc_loss = 0.0021326531182913064
Trained batch 986 in epoch 14, gen_loss = 0.9037906943604335, disc_loss = 0.002133625015581209
Trained batch 987 in epoch 14, gen_loss = 0.9038623020595867, disc_loss = 0.0021336811902950615
Trained batch 988 in epoch 14, gen_loss = 0.9038513112960137, disc_loss = 0.002133154745394196
Trained batch 989 in epoch 14, gen_loss = 0.9038493070939575, disc_loss = 0.0021320948000298225
Trained batch 990 in epoch 14, gen_loss = 0.9038978545624842, disc_loss = 0.0021307698830228096
Trained batch 991 in epoch 14, gen_loss = 0.9040036565594135, disc_loss = 0.0021295288335618206
Trained batch 992 in epoch 14, gen_loss = 0.904134430193829, disc_loss = 0.0021279309933049315
Trained batch 993 in epoch 14, gen_loss = 0.9040888067582243, disc_loss = 0.002126348323485441
Trained batch 994 in epoch 14, gen_loss = 0.9042692298865198, disc_loss = 0.002124501511227309
Trained batch 995 in epoch 14, gen_loss = 0.9042693185638712, disc_loss = 0.0021241992978674492
Trained batch 996 in epoch 14, gen_loss = 0.9042361201709108, disc_loss = 0.002122683287684307
Trained batch 997 in epoch 14, gen_loss = 0.9043235395977158, disc_loss = 0.0021217478821046517
Trained batch 998 in epoch 14, gen_loss = 0.9043466342581404, disc_loss = 0.0021202258419058912
Trained batch 999 in epoch 14, gen_loss = 0.9043476632237435, disc_loss = 0.002118891104233626
Trained batch 1000 in epoch 14, gen_loss = 0.90439792619004, disc_loss = 0.0021175539697104433
Trained batch 1001 in epoch 14, gen_loss = 0.9044388775340098, disc_loss = 0.0021161691124335245
Trained batch 1002 in epoch 14, gen_loss = 0.9045303701047052, disc_loss = 0.002114843986391943
Trained batch 1003 in epoch 14, gen_loss = 0.9046703717148161, disc_loss = 0.0021131711167097717
Trained batch 1004 in epoch 14, gen_loss = 0.9047145966273635, disc_loss = 0.0021113991393839166
Trained batch 1005 in epoch 14, gen_loss = 0.9047986555170586, disc_loss = 0.002109519850010958
Trained batch 1006 in epoch 14, gen_loss = 0.9049109688700133, disc_loss = 0.002107687189722401
Trained batch 1007 in epoch 14, gen_loss = 0.9050128498365955, disc_loss = 0.0021058582243342013
Trained batch 1008 in epoch 14, gen_loss = 0.9049802255937672, disc_loss = 0.0021045551741486154
Trained batch 1009 in epoch 14, gen_loss = 0.9050456918112122, disc_loss = 0.0021027852542595225
Trained batch 1010 in epoch 14, gen_loss = 0.9051222513502595, disc_loss = 0.0021011648784289906
Trained batch 1011 in epoch 14, gen_loss = 0.9052768235385653, disc_loss = 0.0020993583989132353
Trained batch 1012 in epoch 14, gen_loss = 0.9052799711811107, disc_loss = 0.0020975583756018107
Trained batch 1013 in epoch 14, gen_loss = 0.9053826310930873, disc_loss = 0.0020957444374637493
Trained batch 1014 in epoch 14, gen_loss = 0.9054010835187188, disc_loss = 0.0020940788537324086
Trained batch 1015 in epoch 14, gen_loss = 0.905492450601942, disc_loss = 0.002092211226370164
Trained batch 1016 in epoch 14, gen_loss = 0.9056426185305022, disc_loss = 0.0020903852678340997
Trained batch 1017 in epoch 14, gen_loss = 0.9056702656104194, disc_loss = 0.0020886224719551313
Trained batch 1018 in epoch 14, gen_loss = 0.9056826130330738, disc_loss = 0.0020873760015745896
Trained batch 1019 in epoch 14, gen_loss = 0.9056133364345513, disc_loss = 0.0020857165941432707
Trained batch 1020 in epoch 14, gen_loss = 0.9055953149580699, disc_loss = 0.0020839370015920703
Trained batch 1021 in epoch 14, gen_loss = 0.9055195467696031, disc_loss = 0.0020821442228034907
Trained batch 1022 in epoch 14, gen_loss = 0.9054777236511514, disc_loss = 0.0020803487865996358
Trained batch 1023 in epoch 14, gen_loss = 0.9054084428353235, disc_loss = 0.0020785151149951275
Trained batch 1024 in epoch 14, gen_loss = 0.905339412689209, disc_loss = 0.002076676124103492
Trained batch 1025 in epoch 14, gen_loss = 0.9053489213217536, disc_loss = 0.002074908323081464
Trained batch 1026 in epoch 14, gen_loss = 0.9052806747342734, disc_loss = 0.0020731794402955354
Trained batch 1027 in epoch 14, gen_loss = 0.9052706221082332, disc_loss = 0.002071673129560371
Trained batch 1028 in epoch 14, gen_loss = 0.9053261830924899, disc_loss = 0.0020699398372845796
Trained batch 1029 in epoch 14, gen_loss = 0.9053229182090574, disc_loss = 0.002068295090726873
Trained batch 1030 in epoch 14, gen_loss = 0.9054105106658085, disc_loss = 0.0020668587977188922
Trained batch 1031 in epoch 14, gen_loss = 0.9054878965135693, disc_loss = 0.0020651542361576516
Trained batch 1032 in epoch 14, gen_loss = 0.9055830132926653, disc_loss = 0.002063706723165066
Trained batch 1033 in epoch 14, gen_loss = 0.9056259726878523, disc_loss = 0.002062296006149138
Trained batch 1034 in epoch 14, gen_loss = 0.9056550905324411, disc_loss = 0.002060751752315735
Trained batch 1035 in epoch 14, gen_loss = 0.9056638233564995, disc_loss = 0.0020608091031820456
Trained batch 1036 in epoch 14, gen_loss = 0.9056865974700324, disc_loss = 0.002059399245558933
Trained batch 1037 in epoch 14, gen_loss = 0.9058571781726242, disc_loss = 0.0020578089781885097
Trained batch 1038 in epoch 14, gen_loss = 0.9059237187819715, disc_loss = 0.0020561892041374382
Trained batch 1039 in epoch 14, gen_loss = 0.9060644523455547, disc_loss = 0.002054440835707702
Trained batch 1040 in epoch 14, gen_loss = 0.9062569581122495, disc_loss = 0.0020526502552601833
Trained batch 1041 in epoch 14, gen_loss = 0.9063174500346413, disc_loss = 0.0020509153423055398
Trained batch 1042 in epoch 14, gen_loss = 0.9064758115395375, disc_loss = 0.0020500200164373424
Trained batch 1043 in epoch 14, gen_loss = 0.9067333706037295, disc_loss = 0.002048969035598811
Trained batch 1044 in epoch 14, gen_loss = 0.9069130596361662, disc_loss = 0.002047454194090848
Trained batch 1045 in epoch 14, gen_loss = 0.907093860223234, disc_loss = 0.002045905478398552
Trained batch 1046 in epoch 14, gen_loss = 0.9074973212955333, disc_loss = 0.002046812506280686
Trained batch 1047 in epoch 14, gen_loss = 0.9077516899991581, disc_loss = 0.002045467599274363
Trained batch 1048 in epoch 14, gen_loss = 0.9079263763727746, disc_loss = 0.00204395379503545
Trained batch 1049 in epoch 14, gen_loss = 0.9080539808954511, disc_loss = 0.002042326260201489
Trained batch 1050 in epoch 14, gen_loss = 0.9081213181638128, disc_loss = 0.0020413753663403597
Trained batch 1051 in epoch 14, gen_loss = 0.9082045432732586, disc_loss = 0.0020397660801746106
Trained batch 1052 in epoch 14, gen_loss = 0.9083996759860264, disc_loss = 0.0020383326880330796
Trained batch 1053 in epoch 14, gen_loss = 0.9083200770605221, disc_loss = 0.0020371132516230927
Trained batch 1054 in epoch 14, gen_loss = 0.9085238464070723, disc_loss = 0.0020359240298176524
Trained batch 1055 in epoch 14, gen_loss = 0.9086066818034108, disc_loss = 0.0020342765893598303
Trained batch 1056 in epoch 14, gen_loss = 0.9087344159353647, disc_loss = 0.002032633885729284
Trained batch 1057 in epoch 14, gen_loss = 0.9087818836782741, disc_loss = 0.0020310061152998358
Trained batch 1058 in epoch 14, gen_loss = 0.9088527009214739, disc_loss = 0.002029304942015281
Trained batch 1059 in epoch 14, gen_loss = 0.9088251748737299, disc_loss = 0.0020275150166474665
Trained batch 1060 in epoch 14, gen_loss = 0.9088766039485194, disc_loss = 0.002026872079690572
Trained batch 1061 in epoch 14, gen_loss = 0.9089160390380636, disc_loss = 0.0020254318835364504
Trained batch 1062 in epoch 14, gen_loss = 0.9089039502453378, disc_loss = 0.002023836664625442
Trained batch 1063 in epoch 14, gen_loss = 0.9090104267785424, disc_loss = 0.002022267582311146
Trained batch 1064 in epoch 14, gen_loss = 0.9089874087365021, disc_loss = 0.0020208619495822627
Trained batch 1065 in epoch 14, gen_loss = 0.90902270899481, disc_loss = 0.0020191316651083737
Trained batch 1066 in epoch 14, gen_loss = 0.909221018824269, disc_loss = 0.002017446015320202
Trained batch 1067 in epoch 14, gen_loss = 0.9092454726664762, disc_loss = 0.0020158168234061104
Trained batch 1068 in epoch 14, gen_loss = 0.9092239913146445, disc_loss = 0.0020150216969936825
Trained batch 1069 in epoch 14, gen_loss = 0.909186204738706, disc_loss = 0.0020136146612585604
Trained batch 1070 in epoch 14, gen_loss = 0.9092839094214524, disc_loss = 0.002012083700238316
Trained batch 1071 in epoch 14, gen_loss = 0.9092711975325399, disc_loss = 0.0020107384706561653
Trained batch 1072 in epoch 14, gen_loss = 0.909284348256768, disc_loss = 0.002009437314349082
Trained batch 1073 in epoch 14, gen_loss = 0.909245189896731, disc_loss = 0.002008140371452327
Trained batch 1074 in epoch 14, gen_loss = 0.909237649607104, disc_loss = 0.0020067105727706127
Trained batch 1075 in epoch 14, gen_loss = 0.909303234966271, disc_loss = 0.002004980605174768
Trained batch 1076 in epoch 14, gen_loss = 0.909318833630065, disc_loss = 0.002003328676810633
Trained batch 1077 in epoch 14, gen_loss = 0.9093371161945676, disc_loss = 0.00200163013365802
Trained batch 1078 in epoch 14, gen_loss = 0.9092823120042944, disc_loss = 0.001999894747267742
Trained batch 1079 in epoch 14, gen_loss = 0.9092554089647752, disc_loss = 0.0019981327118700765
Trained batch 1080 in epoch 14, gen_loss = 0.9093587459732712, disc_loss = 0.0019964319969010824
Trained batch 1081 in epoch 14, gen_loss = 0.9094310424354293, disc_loss = 0.0019946759145237467
Trained batch 1082 in epoch 14, gen_loss = 0.9093550283492767, disc_loss = 0.0019931202458408756
Trained batch 1083 in epoch 14, gen_loss = 0.9093814275581459, disc_loss = 0.0019915101332543266
Trained batch 1084 in epoch 14, gen_loss = 0.9094178225038239, disc_loss = 0.00198977838721945
Trained batch 1085 in epoch 14, gen_loss = 0.9093495962479277, disc_loss = 0.001991287895365913
Trained batch 1086 in epoch 14, gen_loss = 0.9093507149401562, disc_loss = 0.0019900318458765764
Trained batch 1087 in epoch 14, gen_loss = 0.9094698017682222, disc_loss = 0.0019884322839850616
Trained batch 1088 in epoch 14, gen_loss = 0.9096409357721593, disc_loss = 0.001986792361522998
Trained batch 1089 in epoch 14, gen_loss = 0.9095941487255447, disc_loss = 0.001989687701953957
Trained batch 1090 in epoch 14, gen_loss = 0.9096439883973377, disc_loss = 0.0019883752399139465
Trained batch 1091 in epoch 14, gen_loss = 0.9097127589659814, disc_loss = 0.0019868414292432135
Trained batch 1092 in epoch 14, gen_loss = 0.9098203577585212, disc_loss = 0.0019853365104926146
Trained batch 1093 in epoch 14, gen_loss = 0.909919212080225, disc_loss = 0.0019837249601550866
Trained batch 1094 in epoch 14, gen_loss = 0.9099230681924515, disc_loss = 0.001982194189183982
Trained batch 1095 in epoch 14, gen_loss = 0.9099742922469647, disc_loss = 0.0019805753470685168
Trained batch 1096 in epoch 14, gen_loss = 0.9099085113082893, disc_loss = 0.0019808906901027873
Trained batch 1097 in epoch 14, gen_loss = 0.9099464201536335, disc_loss = 0.0019795444424913324
Trained batch 1098 in epoch 14, gen_loss = 0.9100422783262411, disc_loss = 0.001978003073410774
Trained batch 1099 in epoch 14, gen_loss = 0.910072041424838, disc_loss = 0.0019765902952944584
Trained batch 1100 in epoch 14, gen_loss = 0.9101045140345242, disc_loss = 0.0019749226704746637
Trained batch 1101 in epoch 14, gen_loss = 0.9101243313341089, disc_loss = 0.0019733091488518283
Trained batch 1102 in epoch 14, gen_loss = 0.910181271089604, disc_loss = 0.001971670831408251
Trained batch 1103 in epoch 14, gen_loss = 0.9101521030500315, disc_loss = 0.001970028182590202
Trained batch 1104 in epoch 14, gen_loss = 0.9100185265907874, disc_loss = 0.0019686079788513214
Trained batch 1105 in epoch 14, gen_loss = 0.9099382864307969, disc_loss = 0.001967157004118207
Trained batch 1106 in epoch 14, gen_loss = 0.9100109408756797, disc_loss = 0.001965751084276379
Trained batch 1107 in epoch 14, gen_loss = 0.9099372406944041, disc_loss = 0.0019642833802615907
Trained batch 1108 in epoch 14, gen_loss = 0.909951497672161, disc_loss = 0.0019627753190188274
Trained batch 1109 in epoch 14, gen_loss = 0.9099595448455295, disc_loss = 0.0019611757431849982
Trained batch 1110 in epoch 14, gen_loss = 0.9099672224261973, disc_loss = 0.001959589229457147
Trained batch 1111 in epoch 14, gen_loss = 0.9098715654058422, disc_loss = 0.0019579691757734764
Trained batch 1112 in epoch 14, gen_loss = 0.9099795698905355, disc_loss = 0.0019564496945268777
Trained batch 1113 in epoch 14, gen_loss = 0.909942080933915, disc_loss = 0.001954868468196544
Trained batch 1114 in epoch 14, gen_loss = 0.9099767879520296, disc_loss = 0.001953249306734098
Trained batch 1115 in epoch 14, gen_loss = 0.9098085056069076, disc_loss = 0.001955303556503973
Trained batch 1116 in epoch 14, gen_loss = 0.9097663744710446, disc_loss = 0.0019540046033938376
Trained batch 1117 in epoch 14, gen_loss = 0.9096631157163644, disc_loss = 0.0019530986626669477
Trained batch 1118 in epoch 14, gen_loss = 0.9095591161802904, disc_loss = 0.0019516966732308228
Trained batch 1119 in epoch 14, gen_loss = 0.9094503586845738, disc_loss = 0.0019505537428618222
Trained batch 1120 in epoch 14, gen_loss = 0.9094534245162644, disc_loss = 0.0019493081233676345
Trained batch 1121 in epoch 14, gen_loss = 0.9093787133056213, disc_loss = 0.0019480186843556795
Trained batch 1122 in epoch 14, gen_loss = 0.9093159098022237, disc_loss = 0.0019480533250063829
Trained batch 1123 in epoch 14, gen_loss = 0.9094398356311262, disc_loss = 0.0019466509948025464
Trained batch 1124 in epoch 14, gen_loss = 0.9094682569503785, disc_loss = 0.0019451472689074258
Trained batch 1125 in epoch 14, gen_loss = 0.9095047343370123, disc_loss = 0.001943719739819491
Trained batch 1126 in epoch 14, gen_loss = 0.9095026578327778, disc_loss = 0.0019422953659289982
Trained batch 1127 in epoch 14, gen_loss = 0.9095070189829414, disc_loss = 0.0019407042054873202
Trained batch 1128 in epoch 14, gen_loss = 0.9095689310660079, disc_loss = 0.00193929810697722
Trained batch 1129 in epoch 14, gen_loss = 0.9095637495011355, disc_loss = 0.0019378045965380147
Trained batch 1130 in epoch 14, gen_loss = 0.9096802215361153, disc_loss = 0.001936226920954252
Trained batch 1131 in epoch 14, gen_loss = 0.909634521698362, disc_loss = 0.0019347712677185544
Trained batch 1132 in epoch 14, gen_loss = 0.9095634022647053, disc_loss = 0.0019331840648282865
Trained batch 1133 in epoch 14, gen_loss = 0.9095902741480967, disc_loss = 0.0019316462057823215
Trained batch 1134 in epoch 14, gen_loss = 0.9095200249802173, disc_loss = 0.0019300738162048765
Trained batch 1135 in epoch 14, gen_loss = 0.9095384318538955, disc_loss = 0.0019284865609439344
Trained batch 1136 in epoch 14, gen_loss = 0.9094830447891457, disc_loss = 0.0019269777190007483
Trained batch 1137 in epoch 14, gen_loss = 0.9094844515482864, disc_loss = 0.001925381419927576
Trained batch 1138 in epoch 14, gen_loss = 0.9095970907684373, disc_loss = 0.00192385427980473
Trained batch 1139 in epoch 14, gen_loss = 0.9096073975688532, disc_loss = 0.0019222937332399356
Trained batch 1140 in epoch 14, gen_loss = 0.9096609805363715, disc_loss = 0.0019207579280542293
Trained batch 1141 in epoch 14, gen_loss = 0.9097638820182212, disc_loss = 0.0019192062776990707
Trained batch 1142 in epoch 14, gen_loss = 0.9097828565724357, disc_loss = 0.0019176455154285843
Trained batch 1143 in epoch 14, gen_loss = 0.9098188541569077, disc_loss = 0.0019161122478130034
Trained batch 1144 in epoch 14, gen_loss = 0.909872356044153, disc_loss = 0.0019144987364593938
Trained batch 1145 in epoch 14, gen_loss = 0.9098814146472938, disc_loss = 0.001912969712996244
Trained batch 1146 in epoch 14, gen_loss = 0.9098390873973018, disc_loss = 0.0019113616078651333
Trained batch 1147 in epoch 14, gen_loss = 0.9097770972222816, disc_loss = 0.001909862563783913
Trained batch 1148 in epoch 14, gen_loss = 0.9097608218408855, disc_loss = 0.0019083155067165416
Trained batch 1149 in epoch 14, gen_loss = 0.9098116599476855, disc_loss = 0.001906896596293613
Trained batch 1150 in epoch 14, gen_loss = 0.9097735330812006, disc_loss = 0.0019054905138778332
Trained batch 1151 in epoch 14, gen_loss = 0.9098670280848941, disc_loss = 0.0019039353898556834
Trained batch 1152 in epoch 14, gen_loss = 0.9098714661412103, disc_loss = 0.0019023797662865798
Trained batch 1153 in epoch 14, gen_loss = 0.9098490014336551, disc_loss = 0.0019008273208012281
Trained batch 1154 in epoch 14, gen_loss = 0.909800466675779, disc_loss = 0.0018992737734270003
Trained batch 1155 in epoch 14, gen_loss = 0.9097673640841019, disc_loss = 0.0018977177121581236
Trained batch 1156 in epoch 14, gen_loss = 0.9097456942886346, disc_loss = 0.0018961422494625211
Trained batch 1157 in epoch 14, gen_loss = 0.9097514615260669, disc_loss = 0.0018947676949123897
Trained batch 1158 in epoch 14, gen_loss = 0.9096671549074602, disc_loss = 0.0018933097701339429
Trained batch 1159 in epoch 14, gen_loss = 0.9096679648448681, disc_loss = 0.001891759270745689
Trained batch 1160 in epoch 14, gen_loss = 0.9096219679797959, disc_loss = 0.0018903936985001256
Trained batch 1161 in epoch 14, gen_loss = 0.9096339385501284, disc_loss = 0.0018888875519961104
Trained batch 1162 in epoch 14, gen_loss = 0.9095591977558972, disc_loss = 0.0018875193469403435
Trained batch 1163 in epoch 14, gen_loss = 0.9094810119199589, disc_loss = 0.0018861350868048991
Trained batch 1164 in epoch 14, gen_loss = 0.9094972079403922, disc_loss = 0.001884722727486542
Trained batch 1165 in epoch 14, gen_loss = 0.9094806380480477, disc_loss = 0.0018832661774235407
Trained batch 1166 in epoch 14, gen_loss = 0.9095008977478962, disc_loss = 0.0018818266556540687
Trained batch 1167 in epoch 14, gen_loss = 0.9094616092537364, disc_loss = 0.0018803227719392255
Trained batch 1168 in epoch 14, gen_loss = 0.9094892312972539, disc_loss = 0.0018803655454954966
Trained batch 1169 in epoch 14, gen_loss = 0.9094857074766077, disc_loss = 0.001878942516561484
Trained batch 1170 in epoch 14, gen_loss = 0.9095388256923242, disc_loss = 0.0018774633360814394
Trained batch 1171 in epoch 14, gen_loss = 0.9094975614608758, disc_loss = 0.0018759534557600491
Trained batch 1172 in epoch 14, gen_loss = 0.909464938510511, disc_loss = 0.0018745094907127848
Trained batch 1173 in epoch 14, gen_loss = 0.9093918023056634, disc_loss = 0.001873030095086794
Trained batch 1174 in epoch 14, gen_loss = 0.9093297260872861, disc_loss = 0.001871649984114288
Trained batch 1175 in epoch 14, gen_loss = 0.9093101543634117, disc_loss = 0.0018701747936748212
Trained batch 1176 in epoch 14, gen_loss = 0.9093261303897621, disc_loss = 0.001868722246072695
Trained batch 1177 in epoch 14, gen_loss = 0.9092816728687448, disc_loss = 0.0018672259078617642
Trained batch 1178 in epoch 14, gen_loss = 0.9092695972391667, disc_loss = 0.0018657343811651753
Trained batch 1179 in epoch 14, gen_loss = 0.9093413871223643, disc_loss = 0.0018643075665626754
Trained batch 1180 in epoch 14, gen_loss = 0.9093533617071334, disc_loss = 0.001862945137591796
Trained batch 1181 in epoch 14, gen_loss = 0.9093350258777186, disc_loss = 0.0018615079548268212
Trained batch 1182 in epoch 14, gen_loss = 0.9094547249962491, disc_loss = 0.00186011625846916
Trained batch 1183 in epoch 14, gen_loss = 0.9094306587971546, disc_loss = 0.001858670377173808
Trained batch 1184 in epoch 14, gen_loss = 0.909468331417454, disc_loss = 0.001857176848915887
Trained batch 1185 in epoch 14, gen_loss = 0.9095260376270867, disc_loss = 0.0018557950038645746
Trained batch 1186 in epoch 14, gen_loss = 0.9095096821632321, disc_loss = 0.0018545385248665918
Trained batch 1187 in epoch 14, gen_loss = 0.9094703491990414, disc_loss = 0.0018532008071212385
Trained batch 1188 in epoch 14, gen_loss = 0.9094846479726298, disc_loss = 0.0018517656130783273
Trained batch 1189 in epoch 14, gen_loss = 0.9094653530782011, disc_loss = 0.0018504329744597776
Trained batch 1190 in epoch 14, gen_loss = 0.9095324604677413, disc_loss = 0.001849077594160123
Trained batch 1191 in epoch 14, gen_loss = 0.9096165900962465, disc_loss = 0.0018477146454124096
Trained batch 1192 in epoch 14, gen_loss = 0.9096280196986074, disc_loss = 0.001846677058341779
Trained batch 1193 in epoch 14, gen_loss = 0.9095214255391253, disc_loss = 0.0018454232630691857
Trained batch 1194 in epoch 14, gen_loss = 0.9095057925918612, disc_loss = 0.0018441151495558739
Trained batch 1195 in epoch 14, gen_loss = 0.9095342069565253, disc_loss = 0.0018427231119809665
Trained batch 1196 in epoch 14, gen_loss = 0.9094832180038331, disc_loss = 0.0018413160747025958
Trained batch 1197 in epoch 14, gen_loss = 0.9095146086359263, disc_loss = 0.0018398971976523342
Trained batch 1198 in epoch 14, gen_loss = 0.9094278097053285, disc_loss = 0.001838622950533748
Trained batch 1199 in epoch 14, gen_loss = 0.9093860624730588, disc_loss = 0.0018372493907554599
Trained batch 1200 in epoch 14, gen_loss = 0.9095122999295306, disc_loss = 0.0018362692335434315
Trained batch 1201 in epoch 14, gen_loss = 0.9095768033962282, disc_loss = 0.0018351332881731874
Trained batch 1202 in epoch 14, gen_loss = 0.9096294613748616, disc_loss = 0.0018338515520529262
Trained batch 1203 in epoch 14, gen_loss = 0.9096423213268039, disc_loss = 0.0018325471722638754
Trained batch 1204 in epoch 14, gen_loss = 0.9096549716233218, disc_loss = 0.001831210089316814
Trained batch 1205 in epoch 14, gen_loss = 0.9095909637499409, disc_loss = 0.0018301965281603124
Trained batch 1206 in epoch 14, gen_loss = 0.9095982013404518, disc_loss = 0.0018290120659209615
Trained batch 1207 in epoch 14, gen_loss = 0.909620515410079, disc_loss = 0.0018278903858870595
Trained batch 1208 in epoch 14, gen_loss = 0.9097297047168583, disc_loss = 0.0018265404533037806
Trained batch 1209 in epoch 14, gen_loss = 0.9097221345940897, disc_loss = 0.0018252073554983574
Trained batch 1210 in epoch 14, gen_loss = 0.9097006584769138, disc_loss = 0.0018238254730828767
Trained batch 1211 in epoch 14, gen_loss = 0.909706327289638, disc_loss = 0.0018225148947935504
Trained batch 1212 in epoch 14, gen_loss = 0.9097380151162929, disc_loss = 0.0018215675078412945
Trained batch 1213 in epoch 14, gen_loss = 0.9097340428554246, disc_loss = 0.0018202731889402444
Trained batch 1214 in epoch 14, gen_loss = 0.9097286633993863, disc_loss = 0.001819153232426898
Trained batch 1215 in epoch 14, gen_loss = 0.9096303702283063, disc_loss = 0.0018220323373486138
Trained batch 1216 in epoch 14, gen_loss = 0.909789053896165, disc_loss = 0.001821111737074506
Trained batch 1217 in epoch 14, gen_loss = 0.9098088682089337, disc_loss = 0.0018207624237538543
Trained batch 1218 in epoch 14, gen_loss = 0.9098466834736418, disc_loss = 0.0018198809969745377
Trained batch 1219 in epoch 14, gen_loss = 0.9099187494301405, disc_loss = 0.0018188391843575462
Trained batch 1220 in epoch 14, gen_loss = 0.9099606085175086, disc_loss = 0.0018176098464605173
Trained batch 1221 in epoch 14, gen_loss = 0.9100170500344809, disc_loss = 0.0018162386600772103
Trained batch 1222 in epoch 14, gen_loss = 0.9099559981805423, disc_loss = 0.0018150065796329747
Trained batch 1223 in epoch 14, gen_loss = 0.9099465073908076, disc_loss = 0.0018137510186968142
Trained batch 1224 in epoch 14, gen_loss = 0.9100620437154965, disc_loss = 0.0018124753341009858
Trained batch 1225 in epoch 14, gen_loss = 0.9101331620970908, disc_loss = 0.0018111237324809873
Trained batch 1226 in epoch 14, gen_loss = 0.9101057644772549, disc_loss = 0.0018097792891664532
Trained batch 1227 in epoch 14, gen_loss = 0.9101030649404961, disc_loss = 0.0018084353289788485
Trained batch 1228 in epoch 14, gen_loss = 0.9100667053456225, disc_loss = 0.0018070820961839503
Trained batch 1229 in epoch 14, gen_loss = 0.9100725598451568, disc_loss = 0.0018056784447519642
Trained batch 1230 in epoch 14, gen_loss = 0.9100423761735013, disc_loss = 0.001804331822244832
Trained batch 1231 in epoch 14, gen_loss = 0.9100668917518931, disc_loss = 0.001802981814047858
Trained batch 1232 in epoch 14, gen_loss = 0.9100701055290829, disc_loss = 0.0018016297179132164
Trained batch 1233 in epoch 14, gen_loss = 0.9101828402889413, disc_loss = 0.001800280789375304
Trained batch 1234 in epoch 14, gen_loss = 0.9101029628201535, disc_loss = 0.001800021823140489
Trained batch 1235 in epoch 14, gen_loss = 0.910037898033568, disc_loss = 0.0017989879014893245
Trained batch 1236 in epoch 14, gen_loss = 0.909934188679716, disc_loss = 0.0017978606692298576
Trained batch 1237 in epoch 14, gen_loss = 0.9099462428077549, disc_loss = 0.001796539797921229
Trained batch 1238 in epoch 14, gen_loss = 0.9100236238444207, disc_loss = 0.0017952764124347478
Trained batch 1239 in epoch 14, gen_loss = 0.90995989653372, disc_loss = 0.001793969771267345
Trained batch 1240 in epoch 14, gen_loss = 0.909936238257372, disc_loss = 0.0017926277680945693
Trained batch 1241 in epoch 14, gen_loss = 0.9099653541753834, disc_loss = 0.0017913105758846698
Trained batch 1242 in epoch 14, gen_loss = 0.909957930433683, disc_loss = 0.0017900767069640464
Trained batch 1243 in epoch 14, gen_loss = 0.9099310674851347, disc_loss = 0.0017887732870669505
Trained batch 1244 in epoch 14, gen_loss = 0.9100102686977769, disc_loss = 0.0017874784455375174
Trained batch 1245 in epoch 14, gen_loss = 0.9099355915002226, disc_loss = 0.001786222561034529
Trained batch 1246 in epoch 14, gen_loss = 0.9099784338101445, disc_loss = 0.0017849689997669997
Trained batch 1247 in epoch 14, gen_loss = 0.9099084964642922, disc_loss = 0.0017837257353221503
Trained batch 1248 in epoch 14, gen_loss = 0.9099082037675276, disc_loss = 0.0017824223908540096
Trained batch 1249 in epoch 14, gen_loss = 0.909938408613205, disc_loss = 0.0017811541743518319
Trained batch 1250 in epoch 14, gen_loss = 0.9099283964990331, disc_loss = 0.00177984906504956
Trained batch 1251 in epoch 14, gen_loss = 0.9098173566995719, disc_loss = 0.0017785944494153518
Trained batch 1252 in epoch 14, gen_loss = 0.9097403357814811, disc_loss = 0.0017772902515857609
Trained batch 1253 in epoch 14, gen_loss = 0.909682065296021, disc_loss = 0.0017760300735502146
Trained batch 1254 in epoch 14, gen_loss = 0.9096585483665011, disc_loss = 0.0017747138542286863
Trained batch 1255 in epoch 14, gen_loss = 0.909675416673065, disc_loss = 0.0017734921582374158
Trained batch 1256 in epoch 14, gen_loss = 0.9096926100783246, disc_loss = 0.001772304181518304
Trained batch 1257 in epoch 14, gen_loss = 0.9098597038152297, disc_loss = 0.0017712493905934468
Trained batch 1258 in epoch 14, gen_loss = 0.909735460334396, disc_loss = 0.0017702000043049327
Trained batch 1259 in epoch 14, gen_loss = 0.9098428983536978, disc_loss = 0.0017690899911868322
Trained batch 1260 in epoch 14, gen_loss = 0.9098689028140952, disc_loss = 0.0017678220788144594
Trained batch 1261 in epoch 14, gen_loss = 0.9098755010239863, disc_loss = 0.001766569016170557
Trained batch 1262 in epoch 14, gen_loss = 0.909843637796026, disc_loss = 0.0017653169007563092
Trained batch 1263 in epoch 14, gen_loss = 0.9098475729174251, disc_loss = 0.0017640506943153705
Trained batch 1264 in epoch 14, gen_loss = 0.9097794558219758, disc_loss = 0.0017628003481516463
Trained batch 1265 in epoch 14, gen_loss = 0.9097617306227179, disc_loss = 0.0017615355726291104
Trained batch 1266 in epoch 14, gen_loss = 0.9097200637740607, disc_loss = 0.0017602489701229744
Trained batch 1267 in epoch 14, gen_loss = 0.9096665488620662, disc_loss = 0.0017589783769419761
Trained batch 1268 in epoch 14, gen_loss = 0.9095400580747377, disc_loss = 0.0017580332693615337
Trained batch 1269 in epoch 14, gen_loss = 0.9095192294890486, disc_loss = 0.0017569836212185076
Trained batch 1270 in epoch 14, gen_loss = 0.9095206530332378, disc_loss = 0.0017557590384292123
Trained batch 1271 in epoch 14, gen_loss = 0.9095557556024887, disc_loss = 0.001754562221213294
Trained batch 1272 in epoch 14, gen_loss = 0.9094579920746263, disc_loss = 0.0017534407571672633
Trained batch 1273 in epoch 14, gen_loss = 0.9094059612818378, disc_loss = 0.0017522018435493852
Trained batch 1274 in epoch 14, gen_loss = 0.9093117180525088, disc_loss = 0.0017509915377641116
Trained batch 1275 in epoch 14, gen_loss = 0.9093347676215127, disc_loss = 0.0017497544251859963
Trained batch 1276 in epoch 14, gen_loss = 0.9092474700700705, disc_loss = 0.0017485566649232888
Trained batch 1277 in epoch 14, gen_loss = 0.9093420722861432, disc_loss = 0.0017473930082571674
Trained batch 1278 in epoch 14, gen_loss = 0.9093120901075725, disc_loss = 0.0017462332361418097
Trained batch 1279 in epoch 14, gen_loss = 0.9093613593839109, disc_loss = 0.0017449659636838532
Trained batch 1280 in epoch 14, gen_loss = 0.9094300598115497, disc_loss = 0.0017436989601648334
Trained batch 1281 in epoch 14, gen_loss = 0.9093252158667108, disc_loss = 0.0017426691312250168
Trained batch 1282 in epoch 14, gen_loss = 0.9093331946401232, disc_loss = 0.001741470968447539
Trained batch 1283 in epoch 14, gen_loss = 0.9093143539358151, disc_loss = 0.0017402105250055747
Trained batch 1284 in epoch 14, gen_loss = 0.9093406066356466, disc_loss = 0.0017392278442185114
Trained batch 1285 in epoch 14, gen_loss = 0.9093015068333775, disc_loss = 0.0017380201743308163
Trained batch 1286 in epoch 14, gen_loss = 0.9092417389918597, disc_loss = 0.0017368443512121956
Trained batch 1287 in epoch 14, gen_loss = 0.9091487245992844, disc_loss = 0.0017356409368702946
Trained batch 1288 in epoch 14, gen_loss = 0.9091968050846487, disc_loss = 0.001734506992446058
Trained batch 1289 in epoch 14, gen_loss = 0.9091618685759315, disc_loss = 0.0017332778200983203
Trained batch 1290 in epoch 14, gen_loss = 0.9090978837955099, disc_loss = 0.0017322090955352932
Trained batch 1291 in epoch 14, gen_loss = 0.9091282811696315, disc_loss = 0.0017310148891808604
Trained batch 1292 in epoch 14, gen_loss = 0.9090896219314758, disc_loss = 0.0017297955969955295
Trained batch 1293 in epoch 14, gen_loss = 0.9090455536495957, disc_loss = 0.0017285651255233361
Trained batch 1294 in epoch 14, gen_loss = 0.9089896536241627, disc_loss = 0.00172739653235358
Trained batch 1295 in epoch 14, gen_loss = 0.9090501155566286, disc_loss = 0.001726193629093797
Trained batch 1296 in epoch 14, gen_loss = 0.9090149451331534, disc_loss = 0.0017249700242902386
Trained batch 1297 in epoch 14, gen_loss = 0.9090516210888127, disc_loss = 0.0017239115270411538
Trained batch 1298 in epoch 14, gen_loss = 0.9089408487976286, disc_loss = 0.00172278241947168
Trained batch 1299 in epoch 14, gen_loss = 0.9089575149921271, disc_loss = 0.001721622974532343
Trained batch 1300 in epoch 14, gen_loss = 0.9089187664494526, disc_loss = 0.001720444839440802
Trained batch 1301 in epoch 14, gen_loss = 0.9089255784788439, disc_loss = 0.0017193188897040139
Trained batch 1302 in epoch 14, gen_loss = 0.9088681678724398, disc_loss = 0.0017181754440906978
Trained batch 1303 in epoch 14, gen_loss = 0.9088582206357476, disc_loss = 0.0017170041023216235
Trained batch 1304 in epoch 14, gen_loss = 0.9087983184390598, disc_loss = 0.0017158376697887544
Trained batch 1305 in epoch 14, gen_loss = 0.9087611711591163, disc_loss = 0.0017146656170885766
Trained batch 1306 in epoch 14, gen_loss = 0.9087102181508327, disc_loss = 0.0017135034841038632
Trained batch 1307 in epoch 14, gen_loss = 0.9087173165440194, disc_loss = 0.0017123731632784328
Trained batch 1308 in epoch 14, gen_loss = 0.9087473385383192, disc_loss = 0.001711163917601806
Trained batch 1309 in epoch 14, gen_loss = 0.9086863977308491, disc_loss = 0.0017099718117758983
Trained batch 1310 in epoch 14, gen_loss = 0.9086207002742339, disc_loss = 0.0017087461486371578
Trained batch 1311 in epoch 14, gen_loss = 0.908698882407895, disc_loss = 0.0017075797247077678
Trained batch 1312 in epoch 14, gen_loss = 0.9086258356024632, disc_loss = 0.0017064650669180229
Trained batch 1313 in epoch 14, gen_loss = 0.9086638807887537, disc_loss = 0.0017052339163335618
Trained batch 1314 in epoch 14, gen_loss = 0.9086617753532903, disc_loss = 0.0017041990041915158
Trained batch 1315 in epoch 14, gen_loss = 0.9085616223899065, disc_loss = 0.0017031448132082138
Trained batch 1316 in epoch 14, gen_loss = 0.9086381477574643, disc_loss = 0.0017019525469231633
Trained batch 1317 in epoch 14, gen_loss = 0.9086736291420839, disc_loss = 0.0017008169437074088
Trained batch 1318 in epoch 14, gen_loss = 0.9086519327463753, disc_loss = 0.0016996007977493764
Trained batch 1319 in epoch 14, gen_loss = 0.9087175191803412, disc_loss = 0.0016984181058267661
Trained batch 1320 in epoch 14, gen_loss = 0.908600811566664, disc_loss = 0.001697300506955669
Trained batch 1321 in epoch 14, gen_loss = 0.9086194764738184, disc_loss = 0.0016961055801274873
Trained batch 1322 in epoch 14, gen_loss = 0.9086046211213121, disc_loss = 0.0016949211520220992
Trained batch 1323 in epoch 14, gen_loss = 0.9086069277856285, disc_loss = 0.0016937090404868214
Trained batch 1324 in epoch 14, gen_loss = 0.9086473367349157, disc_loss = 0.0016926480882102624
Trained batch 1325 in epoch 14, gen_loss = 0.908636477513191, disc_loss = 0.0016915069589321817
Trained batch 1326 in epoch 14, gen_loss = 0.9086618695657955, disc_loss = 0.0016903195624056303
Trained batch 1327 in epoch 14, gen_loss = 0.9086590949221548, disc_loss = 0.0016891127690640527
Trained batch 1328 in epoch 14, gen_loss = 0.9086425415190473, disc_loss = 0.0016879130265679164
Trained batch 1329 in epoch 14, gen_loss = 0.9086396097240591, disc_loss = 0.001686746765072965
Trained batch 1330 in epoch 14, gen_loss = 0.9086858960222607, disc_loss = 0.001685596754292784
Trained batch 1331 in epoch 14, gen_loss = 0.9087407837311426, disc_loss = 0.0016844601717542621
Trained batch 1332 in epoch 14, gen_loss = 0.9087882081280055, disc_loss = 0.0016832709772270753
Trained batch 1333 in epoch 14, gen_loss = 0.9087909655771156, disc_loss = 0.0016821601361964307
Trained batch 1334 in epoch 14, gen_loss = 0.9088695042142261, disc_loss = 0.0016810329498205166
Trained batch 1335 in epoch 14, gen_loss = 0.9088401205971569, disc_loss = 0.001679929357810116
Trained batch 1336 in epoch 14, gen_loss = 0.9089010414920284, disc_loss = 0.0016787745313853529
Trained batch 1337 in epoch 14, gen_loss = 0.9088598662160438, disc_loss = 0.0016777113533700796
Trained batch 1338 in epoch 14, gen_loss = 0.908831011100524, disc_loss = 0.0016766420939591726
Trained batch 1339 in epoch 14, gen_loss = 0.9088753374654855, disc_loss = 0.0016754951504942676
Trained batch 1340 in epoch 14, gen_loss = 0.908780808905716, disc_loss = 0.0016744002974135516
Trained batch 1341 in epoch 14, gen_loss = 0.9087850122355846, disc_loss = 0.0016732317401667372
Trained batch 1342 in epoch 14, gen_loss = 0.9088287214157036, disc_loss = 0.0016720955672405856
Trained batch 1343 in epoch 14, gen_loss = 0.9087647085211107, disc_loss = 0.0016709759886994323
Trained batch 1344 in epoch 14, gen_loss = 0.9087660790376061, disc_loss = 0.0016698672736520604
Trained batch 1345 in epoch 14, gen_loss = 0.9086885607260298, disc_loss = 0.0016687735296565455
Trained batch 1346 in epoch 14, gen_loss = 0.9086383540451571, disc_loss = 0.0016676899502443636
Trained batch 1347 in epoch 14, gen_loss = 0.9086909306509204, disc_loss = 0.0016665425189661166
Trained batch 1348 in epoch 14, gen_loss = 0.9086283024281727, disc_loss = 0.001665451479824807
Trained batch 1349 in epoch 14, gen_loss = 0.9085237334834205, disc_loss = 0.001664495073820473
Trained batch 1350 in epoch 14, gen_loss = 0.9085250761136578, disc_loss = 0.0016634145259814006
Trained batch 1351 in epoch 14, gen_loss = 0.9084673135061941, disc_loss = 0.0016623212300119498
Trained batch 1352 in epoch 14, gen_loss = 0.9085110768686817, disc_loss = 0.0016612283172585702
Trained batch 1353 in epoch 14, gen_loss = 0.9085552962703226, disc_loss = 0.0016601260859142055
Trained batch 1354 in epoch 14, gen_loss = 0.9085718533209769, disc_loss = 0.0016589774567871422
Trained batch 1355 in epoch 14, gen_loss = 0.9085010579377852, disc_loss = 0.001657895418634124
Trained batch 1356 in epoch 14, gen_loss = 0.9085349721247955, disc_loss = 0.001656815517759515
Trained batch 1357 in epoch 14, gen_loss = 0.9084731243847045, disc_loss = 0.0016557797835490427
Trained batch 1358 in epoch 14, gen_loss = 0.9084663592426983, disc_loss = 0.0016546933027971594
Trained batch 1359 in epoch 14, gen_loss = 0.9085580808713155, disc_loss = 0.0016535492485779874
Trained batch 1360 in epoch 14, gen_loss = 0.9085820723683583, disc_loss = 0.0016524292064047914
Trained batch 1361 in epoch 14, gen_loss = 0.9085592334753616, disc_loss = 0.0016513433049096765
Trained batch 1362 in epoch 14, gen_loss = 0.9085291559785408, disc_loss = 0.0016502532965519605
Trained batch 1363 in epoch 14, gen_loss = 0.9085386132826903, disc_loss = 0.0016491744058532965
Trained batch 1364 in epoch 14, gen_loss = 0.9085312349455698, disc_loss = 0.0016481287757434964
Trained batch 1365 in epoch 14, gen_loss = 0.9085244010604842, disc_loss = 0.0016470268293734967
Trained batch 1366 in epoch 14, gen_loss = 0.9085136821606601, disc_loss = 0.0016458953876217286
Trained batch 1367 in epoch 14, gen_loss = 0.9084884456810896, disc_loss = 0.0016448272876728263
Trained batch 1368 in epoch 14, gen_loss = 0.9084952572908952, disc_loss = 0.0016437283973864342
Trained batch 1369 in epoch 14, gen_loss = 0.9084944043281304, disc_loss = 0.0016426529939903326
Trained batch 1370 in epoch 14, gen_loss = 0.9084988474237232, disc_loss = 0.001641545045255112
Trained batch 1371 in epoch 14, gen_loss = 0.9083704394519155, disc_loss = 0.0016406759391973235
Trained batch 1372 in epoch 14, gen_loss = 0.9083913389731738, disc_loss = 0.0016396416070801867
Trained batch 1373 in epoch 14, gen_loss = 0.9084057919409945, disc_loss = 0.0016386353605992148
Trained batch 1374 in epoch 14, gen_loss = 0.9084199630997397, disc_loss = 0.0016375439566644755
Trained batch 1375 in epoch 14, gen_loss = 0.9083864745618992, disc_loss = 0.0016366161664209782
Trained batch 1376 in epoch 14, gen_loss = 0.9083885112445945, disc_loss = 0.0016355532586805187
Trained batch 1377 in epoch 14, gen_loss = 0.9083405239575141, disc_loss = 0.001634498484266607
Trained batch 1378 in epoch 14, gen_loss = 0.9082428912825996, disc_loss = 0.001633449998676461
Trained batch 1379 in epoch 14, gen_loss = 0.9082771202360375, disc_loss = 0.00163257435247626
Trained batch 1380 in epoch 14, gen_loss = 0.9082547044684971, disc_loss = 0.001631466521895472
Trained batch 1381 in epoch 14, gen_loss = 0.9082566314254242, disc_loss = 0.0016304460802784256
Trained batch 1382 in epoch 14, gen_loss = 0.9081868378476483, disc_loss = 0.0016294707686268517
Trained batch 1383 in epoch 14, gen_loss = 0.9082071433177573, disc_loss = 0.0016284417627928822
Trained batch 1384 in epoch 14, gen_loss = 0.9082875277591527, disc_loss = 0.0016273985135914096
Trained batch 1385 in epoch 14, gen_loss = 0.908299388651552, disc_loss = 0.001626324673241176
Trained batch 1386 in epoch 14, gen_loss = 0.908349223203941, disc_loss = 0.001625225029066539
Trained batch 1387 in epoch 14, gen_loss = 0.9083478347282932, disc_loss = 0.0016241653421440385
Trained batch 1388 in epoch 14, gen_loss = 0.9082932938681479, disc_loss = 0.0016231029496157003
Trained batch 1389 in epoch 14, gen_loss = 0.9083826170122024, disc_loss = 0.0016220609489386556
Trained batch 1390 in epoch 14, gen_loss = 0.9083914680073023, disc_loss = 0.0016210039377411794
Trained batch 1391 in epoch 14, gen_loss = 0.9083249143742281, disc_loss = 0.0016199215263169343
Trained batch 1392 in epoch 14, gen_loss = 0.9083360772464913, disc_loss = 0.0016188237147616094
Trained batch 1393 in epoch 14, gen_loss = 0.9083225410672138, disc_loss = 0.0016177697251305745
Trained batch 1394 in epoch 14, gen_loss = 0.9083263142561827, disc_loss = 0.0016166726372876092
Trained batch 1395 in epoch 14, gen_loss = 0.9083229922462671, disc_loss = 0.0016169924359965184
Trained batch 1396 in epoch 14, gen_loss = 0.9084557197566705, disc_loss = 0.0016166417918587754
Trained batch 1397 in epoch 14, gen_loss = 0.908570760224169, disc_loss = 0.0016160186032161468
Trained batch 1398 in epoch 14, gen_loss = 0.908464789390564, disc_loss = 0.0016153091761417799
Trained batch 1399 in epoch 14, gen_loss = 0.9084353992768697, disc_loss = 0.0016148492055539723
Trained batch 1400 in epoch 14, gen_loss = 0.9084108075782454, disc_loss = 0.0016138750852418777
Trained batch 1401 in epoch 14, gen_loss = 0.9083644098119967, disc_loss = 0.0016129211856159976
Trained batch 1402 in epoch 14, gen_loss = 0.9083925283813341, disc_loss = 0.0016118790274103842
Trained batch 1403 in epoch 14, gen_loss = 0.9083861403400741, disc_loss = 0.0016108523452094544
Trained batch 1404 in epoch 14, gen_loss = 0.9083459127415966, disc_loss = 0.001609812643488967
Trained batch 1405 in epoch 14, gen_loss = 0.9083951925739625, disc_loss = 0.001608847772369019
Trained batch 1406 in epoch 14, gen_loss = 0.9083923600884135, disc_loss = 0.0016078306311923416
Trained batch 1407 in epoch 14, gen_loss = 0.9083959991959009, disc_loss = 0.0016068022511913941
Trained batch 1408 in epoch 14, gen_loss = 0.9084181834231716, disc_loss = 0.0016058191081423975
Trained batch 1409 in epoch 14, gen_loss = 0.908401933418098, disc_loss = 0.0016047550583091492
Trained batch 1410 in epoch 14, gen_loss = 0.9083701655596051, disc_loss = 0.0016036979124613513
Trained batch 1411 in epoch 14, gen_loss = 0.9083880581193875, disc_loss = 0.0016026296209803322
Trained batch 1412 in epoch 14, gen_loss = 0.9083560049660393, disc_loss = 0.0016015748575319317
Trained batch 1413 in epoch 14, gen_loss = 0.9084156649621912, disc_loss = 0.0016005651746313645
Trained batch 1414 in epoch 14, gen_loss = 0.9084572840916394, disc_loss = 0.0015995669270346892
Trained batch 1415 in epoch 14, gen_loss = 0.9083909452550829, disc_loss = 0.0015986046902703415
Trained batch 1416 in epoch 14, gen_loss = 0.9083704368783794, disc_loss = 0.0015976385348899984
Trained batch 1417 in epoch 14, gen_loss = 0.9082902616523049, disc_loss = 0.0015983169064672756
Trained batch 1418 in epoch 14, gen_loss = 0.9082198234995627, disc_loss = 0.0015976114298070227
Trained batch 1419 in epoch 14, gen_loss = 0.9081630102765392, disc_loss = 0.0015967486375968651
Trained batch 1420 in epoch 14, gen_loss = 0.9081185582152225, disc_loss = 0.0015957273817401203
Trained batch 1421 in epoch 14, gen_loss = 0.9080499385479633, disc_loss = 0.0015946951480324883
Trained batch 1422 in epoch 14, gen_loss = 0.9080723297905938, disc_loss = 0.0015937122930444955
Trained batch 1423 in epoch 14, gen_loss = 0.9080745581997914, disc_loss = 0.0015926610837514192
Trained batch 1424 in epoch 14, gen_loss = 0.9081272106839899, disc_loss = 0.0015916221385276386
Trained batch 1425 in epoch 14, gen_loss = 0.9081838640056519, disc_loss = 0.0015906128367852974
Trained batch 1426 in epoch 14, gen_loss = 0.9081287478431589, disc_loss = 0.0015895585435229784
Trained batch 1427 in epoch 14, gen_loss = 0.9080703921762168, disc_loss = 0.0015885552711704866
Trained batch 1428 in epoch 14, gen_loss = 0.9080575102688634, disc_loss = 0.0015875375065126879
Trained batch 1429 in epoch 14, gen_loss = 0.9080590895422689, disc_loss = 0.001586514292635924
Trained batch 1430 in epoch 14, gen_loss = 0.9080818735328611, disc_loss = 0.0015854797358508302
Trained batch 1431 in epoch 14, gen_loss = 0.9081134009461164, disc_loss = 0.00158446153330377
Trained batch 1432 in epoch 14, gen_loss = 0.9081318370545568, disc_loss = 0.001583424488018796
Trained batch 1433 in epoch 14, gen_loss = 0.908159943596256, disc_loss = 0.001582380981576084
Trained batch 1434 in epoch 14, gen_loss = 0.9081046110661602, disc_loss = 0.001581360813032938
Trained batch 1435 in epoch 14, gen_loss = 0.908102981517906, disc_loss = 0.0015803304835480705
Trained batch 1436 in epoch 14, gen_loss = 0.9081251278218911, disc_loss = 0.0015792931695075001
Trained batch 1437 in epoch 14, gen_loss = 0.9081357331202988, disc_loss = 0.0015783117250343448
Trained batch 1438 in epoch 14, gen_loss = 0.9081515797813209, disc_loss = 0.0015772650685720211
Trained batch 1439 in epoch 14, gen_loss = 0.908122156229284, disc_loss = 0.0015767161771792517
Trained batch 1440 in epoch 14, gen_loss = 0.9081323493858909, disc_loss = 0.0015757702814557606
Trained batch 1441 in epoch 14, gen_loss = 0.908147850082916, disc_loss = 0.00157492298178905
Trained batch 1442 in epoch 14, gen_loss = 0.9080493348551887, disc_loss = 0.0015741000058652533
Trained batch 1443 in epoch 14, gen_loss = 0.9080251818548609, disc_loss = 0.001573181146716472
Trained batch 1444 in epoch 14, gen_loss = 0.9080934992298535, disc_loss = 0.0015724854575225175
Trained batch 1445 in epoch 14, gen_loss = 0.908026472661505, disc_loss = 0.0015716986626597253
Trained batch 1446 in epoch 14, gen_loss = 0.9080237474784245, disc_loss = 0.0015706858221799845
Trained batch 1447 in epoch 14, gen_loss = 0.9079745025759902, disc_loss = 0.0015696901431792314
Trained batch 1448 in epoch 14, gen_loss = 0.9079365111614935, disc_loss = 0.0015686754324885836
Trained batch 1449 in epoch 14, gen_loss = 0.9078784577188821, disc_loss = 0.0015677360948506372
Trained batch 1450 in epoch 14, gen_loss = 0.9078443682579892, disc_loss = 0.0015667288901196404
Trained batch 1451 in epoch 14, gen_loss = 0.907715365660092, disc_loss = 0.0015798785604524347
Trained batch 1452 in epoch 14, gen_loss = 0.907735796361977, disc_loss = 0.0015840417081256206
Trained batch 1453 in epoch 14, gen_loss = 0.9076032244191701, disc_loss = 0.0015863764631492117
Trained batch 1454 in epoch 14, gen_loss = 0.907610063618401, disc_loss = 0.0015879693340679752
Trained batch 1455 in epoch 14, gen_loss = 0.9074610051709217, disc_loss = 0.001604361467808293
Trained batch 1456 in epoch 14, gen_loss = 0.9076277265502888, disc_loss = 0.0016075901886657285
Trained batch 1457 in epoch 14, gen_loss = 0.907737605365706, disc_loss = 0.001608956011980887
Trained batch 1458 in epoch 14, gen_loss = 0.9079237137860513, disc_loss = 0.0016093560661804608
Trained batch 1459 in epoch 14, gen_loss = 0.9081110210451361, disc_loss = 0.0016089877839700944
Trained batch 1460 in epoch 14, gen_loss = 0.9082790121160739, disc_loss = 0.001608668371735741
Trained batch 1461 in epoch 14, gen_loss = 0.9083882989374623, disc_loss = 0.0016083599165131028
Trained batch 1462 in epoch 14, gen_loss = 0.908564988261449, disc_loss = 0.0016080338194134302
Trained batch 1463 in epoch 14, gen_loss = 0.9087069444154781, disc_loss = 0.001607381952110655
Trained batch 1464 in epoch 14, gen_loss = 0.908799822501355, disc_loss = 0.0016067504781495411
Trained batch 1465 in epoch 14, gen_loss = 0.9088222935775455, disc_loss = 0.001606307806068203
Trained batch 1466 in epoch 14, gen_loss = 0.9088811397796273, disc_loss = 0.0016058546756968746
Trained batch 1467 in epoch 14, gen_loss = 0.9089605997872288, disc_loss = 0.0016053522462298085
Trained batch 1468 in epoch 14, gen_loss = 0.908990385704417, disc_loss = 0.0016047339781819557
Trained batch 1469 in epoch 14, gen_loss = 0.9090091742625853, disc_loss = 0.001605996051739876
Trained batch 1470 in epoch 14, gen_loss = 0.9090866841563232, disc_loss = 0.0016060604943047365
Trained batch 1471 in epoch 14, gen_loss = 0.9090106265376443, disc_loss = 0.0016527509910899782
Trained batch 1472 in epoch 14, gen_loss = 0.9090197228770311, disc_loss = 0.0016633985574861126
Trained batch 1473 in epoch 14, gen_loss = 0.9089780380315017, disc_loss = 0.00166994405643739
Trained batch 1474 in epoch 14, gen_loss = 0.908903037653131, disc_loss = 0.0016735393080418394
Trained batch 1475 in epoch 14, gen_loss = 0.9090485933834944, disc_loss = 0.0016751767427668097
Trained batch 1476 in epoch 14, gen_loss = 0.9089767959526284, disc_loss = 0.0016843718050972142
Trained batch 1477 in epoch 14, gen_loss = 0.9090668352595525, disc_loss = 0.0016875222620852948
Trained batch 1478 in epoch 14, gen_loss = 0.9092014771687815, disc_loss = 0.0016878840181047123
Trained batch 1479 in epoch 14, gen_loss = 0.9093152048620018, disc_loss = 0.0016877054396507052
Trained batch 1480 in epoch 14, gen_loss = 0.909348015926884, disc_loss = 0.0016874559012202044
Trained batch 1481 in epoch 14, gen_loss = 0.9093890809498013, disc_loss = 0.0016870990200106473
Trained batch 1482 in epoch 14, gen_loss = 0.9095244589321371, disc_loss = 0.0016864010023969883
Trained batch 1483 in epoch 14, gen_loss = 0.9096383971345392, disc_loss = 0.001685873538317194
Trained batch 1484 in epoch 14, gen_loss = 0.9096521433756408, disc_loss = 0.0016856243345503906
Trained batch 1485 in epoch 14, gen_loss = 0.9096280017098058, disc_loss = 0.0016943781335354302
Trained batch 1486 in epoch 14, gen_loss = 0.9097647491364008, disc_loss = 0.0016992706762408811
Trained batch 1487 in epoch 14, gen_loss = 0.9098953348334118, disc_loss = 0.0016991857249791713
Trained batch 1488 in epoch 14, gen_loss = 0.909980783773157, disc_loss = 0.0016989788856598767
Trained batch 1489 in epoch 14, gen_loss = 0.9101327704903264, disc_loss = 0.0016984787580929073
Trained batch 1490 in epoch 14, gen_loss = 0.9102666417997528, disc_loss = 0.0016978865133402937
Trained batch 1491 in epoch 14, gen_loss = 0.9102801027790152, disc_loss = 0.0017007561705225638
Trained batch 1492 in epoch 14, gen_loss = 0.9104193412291469, disc_loss = 0.0017007275653940022
Trained batch 1493 in epoch 14, gen_loss = 0.9106117654516994, disc_loss = 0.0017017627642112827
Trained batch 1494 in epoch 14, gen_loss = 0.9107392298338006, disc_loss = 0.001701131251050365
Trained batch 1495 in epoch 14, gen_loss = 0.9107525189292622, disc_loss = 0.0017012855945635005
Trained batch 1496 in epoch 14, gen_loss = 0.9108118009153173, disc_loss = 0.0017004452109817135
Trained batch 1497 in epoch 14, gen_loss = 0.9108917622445263, disc_loss = 0.001699708996745366
Trained batch 1498 in epoch 14, gen_loss = 0.91095501705358, disc_loss = 0.0016991424552050653
Trained batch 1499 in epoch 14, gen_loss = 0.9109312554995219, disc_loss = 0.0016983687666167196
Trained batch 1500 in epoch 14, gen_loss = 0.9109557578755887, disc_loss = 0.001697591087012443
Trained batch 1501 in epoch 14, gen_loss = 0.910923241060996, disc_loss = 0.0016968011510475958
Trained batch 1502 in epoch 14, gen_loss = 0.9109290642731998, disc_loss = 0.0016958392843105586
Trained batch 1503 in epoch 14, gen_loss = 0.9110050204190168, disc_loss = 0.0016955873338024793
Trained batch 1504 in epoch 14, gen_loss = 0.9110128475978129, disc_loss = 0.0016957312135259463
Trained batch 1505 in epoch 14, gen_loss = 0.911038323623409, disc_loss = 0.001694975319626286
Trained batch 1506 in epoch 14, gen_loss = 0.9110980608167439, disc_loss = 0.0016955980146666847
Trained batch 1507 in epoch 14, gen_loss = 0.9111419757655191, disc_loss = 0.0016953050360521758
Trained batch 1508 in epoch 14, gen_loss = 0.9111886654096064, disc_loss = 0.0016948952339551021
Trained batch 1509 in epoch 14, gen_loss = 0.9112781451237912, disc_loss = 0.0016943107908614758
Trained batch 1510 in epoch 14, gen_loss = 0.9113371937895042, disc_loss = 0.0016939221096200737
Trained batch 1511 in epoch 14, gen_loss = 0.9113015186376673, disc_loss = 0.001693316778963741
Trained batch 1512 in epoch 14, gen_loss = 0.9113004327765853, disc_loss = 0.0016925294980074674
Trained batch 1513 in epoch 14, gen_loss = 0.9113881202559805, disc_loss = 0.001691691530414745
Trained batch 1514 in epoch 14, gen_loss = 0.9114853965567283, disc_loss = 0.0016911806116839594
Trained batch 1515 in epoch 14, gen_loss = 0.9115345202052184, disc_loss = 0.0016905391108248344
Trained batch 1516 in epoch 14, gen_loss = 0.9115896405321874, disc_loss = 0.0016898783569588849
Trained batch 1517 in epoch 14, gen_loss = 0.9116187344583755, disc_loss = 0.0016889820885059223
Trained batch 1518 in epoch 14, gen_loss = 0.9116521345070117, disc_loss = 0.0016882471636629284
Trained batch 1519 in epoch 14, gen_loss = 0.9116349924159678, disc_loss = 0.0016877075480327844
Trained batch 1520 in epoch 14, gen_loss = 0.9116232303080788, disc_loss = 0.0016869979162846204
Trained batch 1521 in epoch 14, gen_loss = 0.9116307262835459, disc_loss = 0.00168609455553004
Trained batch 1522 in epoch 14, gen_loss = 0.9117574024106512, disc_loss = 0.0016852026086457157
Trained batch 1523 in epoch 14, gen_loss = 0.9117767037994905, disc_loss = 0.0016842775524135867
Trained batch 1524 in epoch 14, gen_loss = 0.9118203752548968, disc_loss = 0.0016836762089534189
Trained batch 1525 in epoch 14, gen_loss = 0.9118706546870315, disc_loss = 0.0016830719223828513
Trained batch 1526 in epoch 14, gen_loss = 0.9119735351558128, disc_loss = 0.0016824497242868934
Trained batch 1527 in epoch 14, gen_loss = 0.9119007127525295, disc_loss = 0.0016830455146601036
Trained batch 1528 in epoch 14, gen_loss = 0.9118598849263513, disc_loss = 0.0016822876132352544
Trained batch 1529 in epoch 14, gen_loss = 0.9119296100404527, disc_loss = 0.001681556798813688
Trained batch 1530 in epoch 14, gen_loss = 0.9119220175126422, disc_loss = 0.0016807418389105653
Trained batch 1531 in epoch 14, gen_loss = 0.9118848091706283, disc_loss = 0.0016798340155922092
Trained batch 1532 in epoch 14, gen_loss = 0.9118695133508457, disc_loss = 0.0016789466726971245
Trained batch 1533 in epoch 14, gen_loss = 0.9118101682703373, disc_loss = 0.0016785165976838912
Trained batch 1534 in epoch 14, gen_loss = 0.9118420058430601, disc_loss = 0.0016777409691475817
Trained batch 1535 in epoch 14, gen_loss = 0.9118992496514693, disc_loss = 0.0016768356632610448
Trained batch 1536 in epoch 14, gen_loss = 0.9119463262809276, disc_loss = 0.0016759446062869893
Trained batch 1537 in epoch 14, gen_loss = 0.9119494660080487, disc_loss = 0.0016749865897814288
Trained batch 1538 in epoch 14, gen_loss = 0.9119711043464432, disc_loss = 0.0016740347191083528
Trained batch 1539 in epoch 14, gen_loss = 0.9119261657649821, disc_loss = 0.0016731732073066116
Trained batch 1540 in epoch 14, gen_loss = 0.9118858809830074, disc_loss = 0.0016755089120152795
Trained batch 1541 in epoch 14, gen_loss = 0.9118683555401408, disc_loss = 0.0016748617912545117
Trained batch 1542 in epoch 14, gen_loss = 0.9119160816565938, disc_loss = 0.0016741971555671443
Trained batch 1543 in epoch 14, gen_loss = 0.9119972388979067, disc_loss = 0.0016734853429743028
Trained batch 1544 in epoch 14, gen_loss = 0.9120009963952221, disc_loss = 0.0016727078797764364
Trained batch 1545 in epoch 14, gen_loss = 0.9120043148738447, disc_loss = 0.0016718972681037825
Trained batch 1546 in epoch 14, gen_loss = 0.9120146062347915, disc_loss = 0.0016712844608087903
Trained batch 1547 in epoch 14, gen_loss = 0.9120389330910774, disc_loss = 0.0016706516155603074
Trained batch 1548 in epoch 14, gen_loss = 0.9120949890014816, disc_loss = 0.0016697012637136113
Trained batch 1549 in epoch 14, gen_loss = 0.912109830879396, disc_loss = 0.0016689551310921688
Trained batch 1550 in epoch 14, gen_loss = 0.9121200340475135, disc_loss = 0.001668187033050729
Trained batch 1551 in epoch 14, gen_loss = 0.9121516906109053, disc_loss = 0.0016672347595717322
Trained batch 1552 in epoch 14, gen_loss = 0.9120937614615933, disc_loss = 0.001667094665423353
Trained batch 1553 in epoch 14, gen_loss = 0.9121597637464335, disc_loss = 0.0016663755436235063
Trained batch 1554 in epoch 14, gen_loss = 0.9121570990016606, disc_loss = 0.001665605408679679
Trained batch 1555 in epoch 14, gen_loss = 0.9122499265447067, disc_loss = 0.0016647436874654535
Trained batch 1556 in epoch 14, gen_loss = 0.912266842087799, disc_loss = 0.001663799348253115
Trained batch 1557 in epoch 14, gen_loss = 0.9122618506823945, disc_loss = 0.0016629129194147766
Trained batch 1558 in epoch 14, gen_loss = 0.912228705219308, disc_loss = 0.0016625270335965672
Trained batch 1559 in epoch 14, gen_loss = 0.9122367304105025, disc_loss = 0.0016617636886505165
Trained batch 1560 in epoch 14, gen_loss = 0.9122926815819237, disc_loss = 0.0016608223671003045
Trained batch 1561 in epoch 14, gen_loss = 0.912370353097647, disc_loss = 0.0016599903991521175
Trained batch 1562 in epoch 14, gen_loss = 0.9123195532950086, disc_loss = 0.0016591544740959811
Trained batch 1563 in epoch 14, gen_loss = 0.9122937570523728, disc_loss = 0.0016582323204813961
Trained batch 1564 in epoch 14, gen_loss = 0.9121879559736282, disc_loss = 0.001659070766006876
Trained batch 1565 in epoch 14, gen_loss = 0.9122006501883535, disc_loss = 0.001658256663115309
Trained batch 1566 in epoch 14, gen_loss = 0.9122584277684321, disc_loss = 0.0016575609334091785
Trained batch 1567 in epoch 14, gen_loss = 0.9121793645377062, disc_loss = 0.0016568007743592958
Trained batch 1568 in epoch 14, gen_loss = 0.9122822602286014, disc_loss = 0.001656228625084632
Trained batch 1569 in epoch 14, gen_loss = 0.912323089541903, disc_loss = 0.0016554586195693184
Trained batch 1570 in epoch 14, gen_loss = 0.9123233003953245, disc_loss = 0.0016547310166005347
Trained batch 1571 in epoch 14, gen_loss = 0.9123509514877814, disc_loss = 0.0016540241366049834
Trained batch 1572 in epoch 14, gen_loss = 0.9123580809694449, disc_loss = 0.0016532004541201335
Trained batch 1573 in epoch 14, gen_loss = 0.9123021117310967, disc_loss = 0.0016522798166623467
Trained batch 1574 in epoch 14, gen_loss = 0.912260669072469, disc_loss = 0.0016514190587322301
Trained batch 1575 in epoch 14, gen_loss = 0.9122432005133121, disc_loss = 0.001650595543471382
Trained batch 1576 in epoch 14, gen_loss = 0.9122631085697578, disc_loss = 0.001649708252629521
Trained batch 1577 in epoch 14, gen_loss = 0.9122362160637352, disc_loss = 0.001648826347456325
Trained batch 1578 in epoch 14, gen_loss = 0.9121934046014493, disc_loss = 0.0016479358000501942
Trained batch 1579 in epoch 14, gen_loss = 0.9122611624153355, disc_loss = 0.0016470612564342998
Trained batch 1580 in epoch 14, gen_loss = 0.91232970532249, disc_loss = 0.0016463239364250747
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.8207575082778931, disc_loss = 0.0004299626452848315
Trained batch 1 in epoch 15, gen_loss = 0.8972591459751129, disc_loss = 0.0005034237983636558
Trained batch 2 in epoch 15, gen_loss = 0.9462257424990336, disc_loss = 0.0004060253850184381
Trained batch 3 in epoch 15, gen_loss = 0.8940283954143524, disc_loss = 0.0004831196565646678
Trained batch 4 in epoch 15, gen_loss = 0.88774573802948, disc_loss = 0.00042446976294741035
Trained batch 5 in epoch 15, gen_loss = 0.8983538150787354, disc_loss = 0.00040485825350818533
Trained batch 6 in epoch 15, gen_loss = 0.9081493275506156, disc_loss = 0.00038631484494544566
Trained batch 7 in epoch 15, gen_loss = 0.9028883427381516, disc_loss = 0.0003569854852685239
Trained batch 8 in epoch 15, gen_loss = 0.8954238759146796, disc_loss = 0.0003635137400124222
Trained batch 9 in epoch 15, gen_loss = 0.8986890912055969, disc_loss = 0.00033906518947333095
Trained batch 10 in epoch 15, gen_loss = 0.8996346647089178, disc_loss = 0.0003192570180875588
Trained batch 11 in epoch 15, gen_loss = 0.9023473958174387, disc_loss = 0.00031495545348055504
Trained batch 12 in epoch 15, gen_loss = 0.9004609401409442, disc_loss = 0.00030305531142333237
Trained batch 13 in epoch 15, gen_loss = 0.9000077205044883, disc_loss = 0.0003002994547257133
Trained batch 14 in epoch 15, gen_loss = 0.9005210876464844, disc_loss = 0.00032053173393554367
Trained batch 15 in epoch 15, gen_loss = 0.9014559723436832, disc_loss = 0.0007436028931806504
Trained batch 16 in epoch 15, gen_loss = 0.9103092481108273, disc_loss = 0.0007693028682671651
Trained batch 17 in epoch 15, gen_loss = 0.9167863296137916, disc_loss = 0.0007551240362065275
Trained batch 18 in epoch 15, gen_loss = 0.9156249981177481, disc_loss = 0.0007391309171859911
Trained batch 19 in epoch 15, gen_loss = 0.9220500737428665, disc_loss = 0.0007219158065709053
Trained batch 20 in epoch 15, gen_loss = 0.9215090416726612, disc_loss = 0.0006975584280250283
Trained batch 21 in epoch 15, gen_loss = 0.9233824041756716, disc_loss = 0.0006722402080909392
Trained batch 22 in epoch 15, gen_loss = 0.926184128160062, disc_loss = 0.0006535204450736511
Trained batch 23 in epoch 15, gen_loss = 0.9274728919068972, disc_loss = 0.0006371934405251523
Trained batch 24 in epoch 15, gen_loss = 0.9269330596923828, disc_loss = 0.0006228149586240761
Trained batch 25 in epoch 15, gen_loss = 0.9309102571927584, disc_loss = 0.0006198197121333438
Trained batch 26 in epoch 15, gen_loss = 0.9328163111651385, disc_loss = 0.0006132725369146405
Trained batch 27 in epoch 15, gen_loss = 0.9359713750226157, disc_loss = 0.000602016934083492
Trained batch 28 in epoch 15, gen_loss = 0.939022051876989, disc_loss = 0.000598159040362526
Trained batch 29 in epoch 15, gen_loss = 0.9408054153124491, disc_loss = 0.0005899043499084655
Trained batch 30 in epoch 15, gen_loss = 0.9386162988601192, disc_loss = 0.000582274848232872
Trained batch 31 in epoch 15, gen_loss = 0.9411044418811798, disc_loss = 0.000573986147855976
Trained batch 32 in epoch 15, gen_loss = 0.9385165554104429, disc_loss = 0.0005598847759150279
Trained batch 33 in epoch 15, gen_loss = 0.9351420192157521, disc_loss = 0.0005476385488102952
Trained batch 34 in epoch 15, gen_loss = 0.9361007520130702, disc_loss = 0.0005374970012261266
Trained batch 35 in epoch 15, gen_loss = 0.9362294409010146, disc_loss = 0.0005271214182963982
Trained batch 36 in epoch 15, gen_loss = 0.9382850414997822, disc_loss = 0.0005188936002259898
Trained batch 37 in epoch 15, gen_loss = 0.9392080636400926, disc_loss = 0.0005093207963861795
Trained batch 38 in epoch 15, gen_loss = 0.9383966265580593, disc_loss = 0.0005020361514209817
Trained batch 39 in epoch 15, gen_loss = 0.9386358991265297, disc_loss = 0.0004924592783936532
Trained batch 40 in epoch 15, gen_loss = 0.9367067973788191, disc_loss = 0.00048351673751490236
Trained batch 41 in epoch 15, gen_loss = 0.9374385688986097, disc_loss = 0.0004758204678572448
Trained batch 42 in epoch 15, gen_loss = 0.9357456204503082, disc_loss = 0.00046733707182114773
Trained batch 43 in epoch 15, gen_loss = 0.9345794157548384, disc_loss = 0.000459599383578858
Trained batch 44 in epoch 15, gen_loss = 0.9358877182006836, disc_loss = 0.00045211561260253397
Trained batch 45 in epoch 15, gen_loss = 0.9357895579027093, disc_loss = 0.00044733622322066526
Trained batch 46 in epoch 15, gen_loss = 0.9343796372413635, disc_loss = 0.0004398656051984909
Trained batch 47 in epoch 15, gen_loss = 0.9340633054574331, disc_loss = 0.000438121563547611
Trained batch 48 in epoch 15, gen_loss = 0.9348592818999777, disc_loss = 0.0004331048107907955
Trained batch 49 in epoch 15, gen_loss = 0.9339335572719574, disc_loss = 0.0004270986375922803
Trained batch 50 in epoch 15, gen_loss = 0.9343839848742765, disc_loss = 0.0004222166312769439
Trained batch 51 in epoch 15, gen_loss = 0.9331164119335321, disc_loss = 0.0004158620810742902
Trained batch 52 in epoch 15, gen_loss = 0.9315746494059293, disc_loss = 0.00041058158020396666
Trained batch 53 in epoch 15, gen_loss = 0.9297677885603022, disc_loss = 0.00040596932632507997
Trained batch 54 in epoch 15, gen_loss = 0.9280607873743231, disc_loss = 0.00040144015656551346
Trained batch 55 in epoch 15, gen_loss = 0.9265152258532388, disc_loss = 0.00042255994633576065
Trained batch 56 in epoch 15, gen_loss = 0.9287093438600239, disc_loss = 0.0004224299189987952
Trained batch 57 in epoch 15, gen_loss = 0.9274872551704275, disc_loss = 0.00041868076933214665
Trained batch 58 in epoch 15, gen_loss = 0.9270157217979431, disc_loss = 0.00041540159527666203
Trained batch 59 in epoch 15, gen_loss = 0.9266543745994568, disc_loss = 0.0004115389501142393
Trained batch 60 in epoch 15, gen_loss = 0.9260308957490765, disc_loss = 0.0004083319474345638
Trained batch 61 in epoch 15, gen_loss = 0.9265764817114799, disc_loss = 0.0004078616643270042
Trained batch 62 in epoch 15, gen_loss = 0.9237403547953046, disc_loss = 0.00040781311171096083
Trained batch 63 in epoch 15, gen_loss = 0.924507861956954, disc_loss = 0.0004031474675230129
Trained batch 64 in epoch 15, gen_loss = 0.924603535578801, disc_loss = 0.0003989775295709618
Trained batch 65 in epoch 15, gen_loss = 0.9252334182912653, disc_loss = 0.0003951888204689815
Trained batch 66 in epoch 15, gen_loss = 0.9246973333074086, disc_loss = 0.0003911749096656802
Trained batch 67 in epoch 15, gen_loss = 0.9230740648858687, disc_loss = 0.0003886525298773503
Trained batch 68 in epoch 15, gen_loss = 0.9218023168867913, disc_loss = 0.0003846060169145357
Trained batch 69 in epoch 15, gen_loss = 0.9197811501366752, disc_loss = 0.0003818525419254521
Trained batch 70 in epoch 15, gen_loss = 0.9204790457873278, disc_loss = 0.00037911191007161747
Trained batch 71 in epoch 15, gen_loss = 0.9208934812082185, disc_loss = 0.000376001994381012
Trained batch 72 in epoch 15, gen_loss = 0.9214266922375928, disc_loss = 0.0003731913560816431
Trained batch 73 in epoch 15, gen_loss = 0.9210398607962841, disc_loss = 0.0003714665457467876
Trained batch 74 in epoch 15, gen_loss = 0.9211776781082154, disc_loss = 0.00036855631022869297
Trained batch 75 in epoch 15, gen_loss = 0.9210099021070882, disc_loss = 0.00036563147315112136
Trained batch 76 in epoch 15, gen_loss = 0.9207836521136297, disc_loss = 0.0003619412823531825
Trained batch 77 in epoch 15, gen_loss = 0.9206048303689712, disc_loss = 0.00035930371217172925
Trained batch 78 in epoch 15, gen_loss = 0.9214701720430881, disc_loss = 0.0003565367037884278
Trained batch 79 in epoch 15, gen_loss = 0.9208989717066288, disc_loss = 0.00035315894629093234
Trained batch 80 in epoch 15, gen_loss = 0.9208203936800544, disc_loss = 0.0003519499997635671
Trained batch 81 in epoch 15, gen_loss = 0.9200530168486805, disc_loss = 0.00034934492373949757
Trained batch 82 in epoch 15, gen_loss = 0.9202726576701704, disc_loss = 0.00034647116131438166
Trained batch 83 in epoch 15, gen_loss = 0.9218041513647351, disc_loss = 0.00034368662844436973
Trained batch 84 in epoch 15, gen_loss = 0.9228377384297988, disc_loss = 0.00034183350448181634
Trained batch 85 in epoch 15, gen_loss = 0.9240699354992357, disc_loss = 0.00034089232661265904
Trained batch 86 in epoch 15, gen_loss = 0.9249082776321762, disc_loss = 0.0003393528344552568
Trained batch 87 in epoch 15, gen_loss = 0.9244025600227442, disc_loss = 0.00033719449154225663
Trained batch 88 in epoch 15, gen_loss = 0.9257523430867142, disc_loss = 0.0003361876957017792
Trained batch 89 in epoch 15, gen_loss = 0.9253481758965386, disc_loss = 0.0003349252796195085
Trained batch 90 in epoch 15, gen_loss = 0.9247764840230837, disc_loss = 0.0003954418858923888
Trained batch 91 in epoch 15, gen_loss = 0.9249283308568208, disc_loss = 0.0003994261611375765
Trained batch 92 in epoch 15, gen_loss = 0.9258950679532943, disc_loss = 0.00039923186102564076
Trained batch 93 in epoch 15, gen_loss = 0.9270582858552324, disc_loss = 0.00039768414709660067
Trained batch 94 in epoch 15, gen_loss = 0.9272556392770065, disc_loss = 0.00039768894517022235
Trained batch 95 in epoch 15, gen_loss = 0.9277868655820688, disc_loss = 0.0003962253750463181
Trained batch 96 in epoch 15, gen_loss = 0.9280528807148491, disc_loss = 0.0003937920107663436
Trained batch 97 in epoch 15, gen_loss = 0.9282847655062773, disc_loss = 0.0003910001737216478
Trained batch 98 in epoch 15, gen_loss = 0.9281219334313364, disc_loss = 0.00039060640898756587
Trained batch 99 in epoch 15, gen_loss = 0.9278024470806122, disc_loss = 0.00038835041814309077
Trained batch 100 in epoch 15, gen_loss = 0.9275362987329464, disc_loss = 0.00038531361893222825
Trained batch 101 in epoch 15, gen_loss = 0.9272643602361866, disc_loss = 0.0003830891486466177
Trained batch 102 in epoch 15, gen_loss = 0.9283054100656972, disc_loss = 0.0003852815749728374
Trained batch 103 in epoch 15, gen_loss = 0.9284510171184173, disc_loss = 0.0003841351719809329
Trained batch 104 in epoch 15, gen_loss = 0.9266501069068909, disc_loss = 0.00038408641613343555
Trained batch 105 in epoch 15, gen_loss = 0.9265970880130552, disc_loss = 0.000381687947975599
Trained batch 106 in epoch 15, gen_loss = 0.9260506852764949, disc_loss = 0.00037909540119004286
Trained batch 107 in epoch 15, gen_loss = 0.9255632349738369, disc_loss = 0.0003782510428007097
Trained batch 108 in epoch 15, gen_loss = 0.9247541865077588, disc_loss = 0.0003772762495519192
Trained batch 109 in epoch 15, gen_loss = 0.924238290569999, disc_loss = 0.0003775368631812109
Trained batch 110 in epoch 15, gen_loss = 0.9261388488717981, disc_loss = 0.0003816547358764109
Trained batch 111 in epoch 15, gen_loss = 0.9251028309975352, disc_loss = 0.0003847350564813366
Trained batch 112 in epoch 15, gen_loss = 0.9242609966117724, disc_loss = 0.0003830987863645444
Trained batch 113 in epoch 15, gen_loss = 0.9237972456112242, disc_loss = 0.00038057841754236604
Trained batch 114 in epoch 15, gen_loss = 0.9226698279380798, disc_loss = 0.00037887382799374833
Trained batch 115 in epoch 15, gen_loss = 0.9230545250506237, disc_loss = 0.0003775037263855258
Trained batch 116 in epoch 15, gen_loss = 0.9222570209421663, disc_loss = 0.0003756413295463078
Trained batch 117 in epoch 15, gen_loss = 0.9224240623288236, disc_loss = 0.00037370829054221544
Trained batch 118 in epoch 15, gen_loss = 0.921421549901241, disc_loss = 0.00037155747452766457
Trained batch 119 in epoch 15, gen_loss = 0.9217185060183207, disc_loss = 0.00036938360608473886
Trained batch 120 in epoch 15, gen_loss = 0.9208230844213943, disc_loss = 0.00036741091897672673
Trained batch 121 in epoch 15, gen_loss = 0.9212198164619383, disc_loss = 0.0003655393960738753
Trained batch 122 in epoch 15, gen_loss = 0.9209573661408773, disc_loss = 0.00036378704237172426
Trained batch 123 in epoch 15, gen_loss = 0.9199761205142544, disc_loss = 0.0003614797795073114
Trained batch 124 in epoch 15, gen_loss = 0.9197359642982483, disc_loss = 0.0003610450403066352
Trained batch 125 in epoch 15, gen_loss = 0.9196103120607043, disc_loss = 0.000360627382525265
Trained batch 126 in epoch 15, gen_loss = 0.9190783838587483, disc_loss = 0.00035897010580295566
Trained batch 127 in epoch 15, gen_loss = 0.9186807447113097, disc_loss = 0.0003571569478708625
Trained batch 128 in epoch 15, gen_loss = 0.9183744852857072, disc_loss = 0.00035567603582992803
Trained batch 129 in epoch 15, gen_loss = 0.9185777943867903, disc_loss = 0.0003537332157765587
Trained batch 130 in epoch 15, gen_loss = 0.9194020801828108, disc_loss = 0.00035215535044282644
Trained batch 131 in epoch 15, gen_loss = 0.9195182711789103, disc_loss = 0.00035251271247309916
Trained batch 132 in epoch 15, gen_loss = 0.9203558604520067, disc_loss = 0.0003518894960520845
Trained batch 133 in epoch 15, gen_loss = 0.9205413131571528, disc_loss = 0.0003499508376121208
Trained batch 134 in epoch 15, gen_loss = 0.9203751299116346, disc_loss = 0.0003485696314277852
Trained batch 135 in epoch 15, gen_loss = 0.9206947132068521, disc_loss = 0.00034691468836707133
Trained batch 136 in epoch 15, gen_loss = 0.9207385073613076, disc_loss = 0.000345627746740645
Trained batch 137 in epoch 15, gen_loss = 0.9212753453116486, disc_loss = 0.00034434621546466405
Trained batch 138 in epoch 15, gen_loss = 0.9213391666789706, disc_loss = 0.0003442699282799459
Trained batch 139 in epoch 15, gen_loss = 0.9209015109709331, disc_loss = 0.00034265767098986546
Trained batch 140 in epoch 15, gen_loss = 0.9203794864898033, disc_loss = 0.0003418264552869946
Trained batch 141 in epoch 15, gen_loss = 0.9200468692981022, disc_loss = 0.00034118302338215537
Trained batch 142 in epoch 15, gen_loss = 0.9201619433356332, disc_loss = 0.0003400856374202856
Trained batch 143 in epoch 15, gen_loss = 0.9202360096904967, disc_loss = 0.00033926910742189246
Trained batch 144 in epoch 15, gen_loss = 0.92027404554959, disc_loss = 0.0003378915705854587
Trained batch 145 in epoch 15, gen_loss = 0.920138710982179, disc_loss = 0.0003364787299276891
Trained batch 146 in epoch 15, gen_loss = 0.9208612052761779, disc_loss = 0.00033503743842858694
Trained batch 147 in epoch 15, gen_loss = 0.9209040636951858, disc_loss = 0.0003343249175216172
Trained batch 148 in epoch 15, gen_loss = 0.9207408452194009, disc_loss = 0.00033447920675264457
Trained batch 149 in epoch 15, gen_loss = 0.9200595418612162, disc_loss = 0.0003364416027519231
Trained batch 150 in epoch 15, gen_loss = 0.9193120914579227, disc_loss = 0.0003365629070456948
Trained batch 151 in epoch 15, gen_loss = 0.9192783554133616, disc_loss = 0.0003358639796236898
Trained batch 152 in epoch 15, gen_loss = 0.9190758829023323, disc_loss = 0.00033470232563178524
Trained batch 153 in epoch 15, gen_loss = 0.9200078461851392, disc_loss = 0.0003345332493213332
Trained batch 154 in epoch 15, gen_loss = 0.9203908416532701, disc_loss = 0.000333835473359232
Trained batch 155 in epoch 15, gen_loss = 0.9199882833621441, disc_loss = 0.00033248864304205665
Trained batch 156 in epoch 15, gen_loss = 0.9190485128171885, disc_loss = 0.0003314829641133013
Trained batch 157 in epoch 15, gen_loss = 0.9192630150650121, disc_loss = 0.00033006114553464167
Trained batch 158 in epoch 15, gen_loss = 0.9195601595272808, disc_loss = 0.0003293129230088718
Trained batch 159 in epoch 15, gen_loss = 0.9193751640617848, disc_loss = 0.0003280688859831571
Trained batch 160 in epoch 15, gen_loss = 0.9189849832783574, disc_loss = 0.00032700931655007317
Trained batch 161 in epoch 15, gen_loss = 0.9190114085321073, disc_loss = 0.00032615144475669323
Trained batch 162 in epoch 15, gen_loss = 0.9180925532352705, disc_loss = 0.0003250477169272547
Trained batch 163 in epoch 15, gen_loss = 0.9177307977182109, disc_loss = 0.0003237562489120159
Trained batch 164 in epoch 15, gen_loss = 0.9172725923133619, disc_loss = 0.00032265930067021116
Trained batch 165 in epoch 15, gen_loss = 0.9172361658280155, disc_loss = 0.0003219698116141904
Trained batch 166 in epoch 15, gen_loss = 0.9168104561503062, disc_loss = 0.0003210319501775161
Trained batch 167 in epoch 15, gen_loss = 0.9175390750169754, disc_loss = 0.0003208612129345143
Trained batch 168 in epoch 15, gen_loss = 0.9171685149683755, disc_loss = 0.0003199248761782483
Trained batch 169 in epoch 15, gen_loss = 0.917186884319081, disc_loss = 0.00031845439011436504
Trained batch 170 in epoch 15, gen_loss = 0.9169237645048844, disc_loss = 0.00031707649789267214
Trained batch 171 in epoch 15, gen_loss = 0.9164214290158693, disc_loss = 0.00031561056637783197
Trained batch 172 in epoch 15, gen_loss = 0.9162669867449413, disc_loss = 0.00031428212893627467
Trained batch 173 in epoch 15, gen_loss = 0.91679981556432, disc_loss = 0.000313257589013297
Trained batch 174 in epoch 15, gen_loss = 0.9160605233056205, disc_loss = 0.0003118702001354125
Trained batch 175 in epoch 15, gen_loss = 0.9163288880478252, disc_loss = 0.0003106396747253629
Trained batch 176 in epoch 15, gen_loss = 0.9168072972594008, disc_loss = 0.0003108102424181393
Trained batch 177 in epoch 15, gen_loss = 0.9166933418659682, disc_loss = 0.00031078911882339915
Trained batch 178 in epoch 15, gen_loss = 0.9165093262768325, disc_loss = 0.0003106974315450412
Trained batch 179 in epoch 15, gen_loss = 0.9162115173207389, disc_loss = 0.00030976679518062155
Trained batch 180 in epoch 15, gen_loss = 0.9159859356300607, disc_loss = 0.0003088063028437158
Trained batch 181 in epoch 15, gen_loss = 0.9157300666793362, disc_loss = 0.00030767969908013655
Trained batch 182 in epoch 15, gen_loss = 0.9162115324390391, disc_loss = 0.0003070614839486696
Trained batch 183 in epoch 15, gen_loss = 0.9163149433291476, disc_loss = 0.0003060519808929277
Trained batch 184 in epoch 15, gen_loss = 0.9161859879622588, disc_loss = 0.0003062887869640002
Trained batch 185 in epoch 15, gen_loss = 0.9156096769917396, disc_loss = 0.0003051784857547396
Trained batch 186 in epoch 15, gen_loss = 0.9147951405316113, disc_loss = 0.000304385368255612
Trained batch 187 in epoch 15, gen_loss = 0.9147073927711933, disc_loss = 0.0003034089281851614
Trained batch 188 in epoch 15, gen_loss = 0.9147031307220459, disc_loss = 0.00030227314167109037
Trained batch 189 in epoch 15, gen_loss = 0.9144762045458743, disc_loss = 0.0003017510935406838
Trained batch 190 in epoch 15, gen_loss = 0.9145238424470912, disc_loss = 0.0003011966613608934
Trained batch 191 in epoch 15, gen_loss = 0.9144682120531797, disc_loss = 0.0003009593016637761
Trained batch 192 in epoch 15, gen_loss = 0.9143666109272853, disc_loss = 0.0003002041054635014
Trained batch 193 in epoch 15, gen_loss = 0.9144722733300986, disc_loss = 0.0002999406578121275
Trained batch 194 in epoch 15, gen_loss = 0.914275355828114, disc_loss = 0.0002997590783380497
Trained batch 195 in epoch 15, gen_loss = 0.914386445466353, disc_loss = 0.0002992863395478225
Trained batch 196 in epoch 15, gen_loss = 0.9142431268837247, disc_loss = 0.0002984334264857089
Trained batch 197 in epoch 15, gen_loss = 0.9145434504807598, disc_loss = 0.0002983582450513201
Trained batch 198 in epoch 15, gen_loss = 0.9147815479705083, disc_loss = 0.0002980400629291292
Trained batch 199 in epoch 15, gen_loss = 0.914552690088749, disc_loss = 0.0002971408098528627
Trained batch 200 in epoch 15, gen_loss = 0.9141433351668552, disc_loss = 0.0002969320585768188
Trained batch 201 in epoch 15, gen_loss = 0.9136926927188835, disc_loss = 0.0002965970996607067
Trained batch 202 in epoch 15, gen_loss = 0.9133025980348071, disc_loss = 0.0002957115638636975
Trained batch 203 in epoch 15, gen_loss = 0.9136944053804174, disc_loss = 0.000295747843219764
Trained batch 204 in epoch 15, gen_loss = 0.9128676388321854, disc_loss = 0.00029655187735021704
Trained batch 205 in epoch 15, gen_loss = 0.9130047831720519, disc_loss = 0.0002971019222385824
Trained batch 206 in epoch 15, gen_loss = 0.9132631516111069, disc_loss = 0.0002966700741447
Trained batch 207 in epoch 15, gen_loss = 0.9133816725359514, disc_loss = 0.00029657443334284693
Trained batch 208 in epoch 15, gen_loss = 0.9134067177202143, disc_loss = 0.0002961782614283295
Trained batch 209 in epoch 15, gen_loss = 0.913351587454478, disc_loss = 0.00029628890122347954
Trained batch 210 in epoch 15, gen_loss = 0.9129720084475115, disc_loss = 0.00029601269902719925
Trained batch 211 in epoch 15, gen_loss = 0.912515160891245, disc_loss = 0.00029635304047090203
Trained batch 212 in epoch 15, gen_loss = 0.912536147334766, disc_loss = 0.0002957463813134023
Trained batch 213 in epoch 15, gen_loss = 0.9124270978375016, disc_loss = 0.0002949060200021067
Trained batch 214 in epoch 15, gen_loss = 0.9125800598499387, disc_loss = 0.00029401986546365025
Trained batch 215 in epoch 15, gen_loss = 0.9120867953256324, disc_loss = 0.00029362753785891173
Trained batch 216 in epoch 15, gen_loss = 0.9111999910547987, disc_loss = 0.00029402793543214785
Trained batch 217 in epoch 15, gen_loss = 0.910691270861057, disc_loss = 0.00029412902292337296
Trained batch 218 in epoch 15, gen_loss = 0.9105466753924818, disc_loss = 0.00029432599335886566
Trained batch 219 in epoch 15, gen_loss = 0.9105190461332148, disc_loss = 0.0002945212619207186
Trained batch 220 in epoch 15, gen_loss = 0.9101608473790717, disc_loss = 0.0002943815738718632
Trained batch 221 in epoch 15, gen_loss = 0.9103752755903983, disc_loss = 0.00029384457216643194
Trained batch 222 in epoch 15, gen_loss = 0.9105179868471462, disc_loss = 0.0002934284440819654
Trained batch 223 in epoch 15, gen_loss = 0.9099897750254188, disc_loss = 0.00029309952057181884
Trained batch 224 in epoch 15, gen_loss = 0.9102251590622796, disc_loss = 0.00029256742832431984
Trained batch 225 in epoch 15, gen_loss = 0.9104308362028241, disc_loss = 0.00029205697717014245
Trained batch 226 in epoch 15, gen_loss = 0.9099701971209522, disc_loss = 0.0002914342346474516
Trained batch 227 in epoch 15, gen_loss = 0.9101703404857401, disc_loss = 0.00029136076763710373
Trained batch 228 in epoch 15, gen_loss = 0.9105000748384467, disc_loss = 0.0002914023960599428
Trained batch 229 in epoch 15, gen_loss = 0.9104219739851744, disc_loss = 0.00029082614767147514
Trained batch 230 in epoch 15, gen_loss = 0.9100912979670933, disc_loss = 0.00029014637153893023
Trained batch 231 in epoch 15, gen_loss = 0.9102733782653151, disc_loss = 0.0002904652810998257
Trained batch 232 in epoch 15, gen_loss = 0.9102383427353887, disc_loss = 0.0002900071724359438
Trained batch 233 in epoch 15, gen_loss = 0.9101456602414449, disc_loss = 0.0002896801466766534
Trained batch 234 in epoch 15, gen_loss = 0.9105026549481331, disc_loss = 0.0002894968044277816
Trained batch 235 in epoch 15, gen_loss = 0.9104213186744916, disc_loss = 0.0002889070251743976
Trained batch 236 in epoch 15, gen_loss = 0.9108692047968192, disc_loss = 0.0002883432121647282
Trained batch 237 in epoch 15, gen_loss = 0.9107789241967081, disc_loss = 0.00028789591902261407
Trained batch 238 in epoch 15, gen_loss = 0.9110444607096237, disc_loss = 0.00028734064588998345
Trained batch 239 in epoch 15, gen_loss = 0.9117437355220318, disc_loss = 0.00028679362915985017
Trained batch 240 in epoch 15, gen_loss = 0.9120084786810816, disc_loss = 0.00028605154209844654
Trained batch 241 in epoch 15, gen_loss = 0.9118489933407996, disc_loss = 0.00028567823530525964
Trained batch 242 in epoch 15, gen_loss = 0.9113037340925554, disc_loss = 0.0002857732745915088
Trained batch 243 in epoch 15, gen_loss = 0.9117204112107636, disc_loss = 0.0002851670103199631
Trained batch 244 in epoch 15, gen_loss = 0.91185276605645, disc_loss = 0.00028511620692704443
Trained batch 245 in epoch 15, gen_loss = 0.9117492156300119, disc_loss = 0.00028493638284437215
Trained batch 246 in epoch 15, gen_loss = 0.9117550835435689, disc_loss = 0.0002846517539142465
Trained batch 247 in epoch 15, gen_loss = 0.9123788360626467, disc_loss = 0.00028444706435214856
Trained batch 248 in epoch 15, gen_loss = 0.9122841485054138, disc_loss = 0.00028396958688504985
Trained batch 249 in epoch 15, gen_loss = 0.9123758134841919, disc_loss = 0.00028358927063527515
Trained batch 250 in epoch 15, gen_loss = 0.9119852857285762, disc_loss = 0.0002831371168133365
Trained batch 251 in epoch 15, gen_loss = 0.9119142360157437, disc_loss = 0.00028300397750013323
Trained batch 252 in epoch 15, gen_loss = 0.9121650356077865, disc_loss = 0.00028225347896547356
Trained batch 253 in epoch 15, gen_loss = 0.9123772115219296, disc_loss = 0.00028161570235814596
Trained batch 254 in epoch 15, gen_loss = 0.9124347733516319, disc_loss = 0.0002811977703423312
Trained batch 255 in epoch 15, gen_loss = 0.9122556354850531, disc_loss = 0.00028072347143393017
Trained batch 256 in epoch 15, gen_loss = 0.912119908091623, disc_loss = 0.0002802086529806202
Trained batch 257 in epoch 15, gen_loss = 0.9121601181898931, disc_loss = 0.0002800615672971927
Trained batch 258 in epoch 15, gen_loss = 0.9124421104501113, disc_loss = 0.0002800023422181394
Trained batch 259 in epoch 15, gen_loss = 0.9121139932137269, disc_loss = 0.00027986877710365943
Trained batch 260 in epoch 15, gen_loss = 0.9119447841954871, disc_loss = 0.0002799253366672134
Trained batch 261 in epoch 15, gen_loss = 0.9121655783125462, disc_loss = 0.0002795293295850625
Trained batch 262 in epoch 15, gen_loss = 0.9123019843500376, disc_loss = 0.0002787947470086322
Trained batch 263 in epoch 15, gen_loss = 0.911889134708679, disc_loss = 0.00027820261865682284
Trained batch 264 in epoch 15, gen_loss = 0.9117952801146597, disc_loss = 0.0002775222235216478
Trained batch 265 in epoch 15, gen_loss = 0.9113862861816148, disc_loss = 0.0002770285287911783
Trained batch 266 in epoch 15, gen_loss = 0.911433291122708, disc_loss = 0.00027648293533016254
Trained batch 267 in epoch 15, gen_loss = 0.9115983581365045, disc_loss = 0.00027574701695146954
Trained batch 268 in epoch 15, gen_loss = 0.9113576381179923, disc_loss = 0.0002750076498690435
Trained batch 269 in epoch 15, gen_loss = 0.9110012367919639, disc_loss = 0.0002744633668044116
Trained batch 270 in epoch 15, gen_loss = 0.9108054708290804, disc_loss = 0.00027388315440032704
Trained batch 271 in epoch 15, gen_loss = 0.9110140690908712, disc_loss = 0.00027332426431231024
Trained batch 272 in epoch 15, gen_loss = 0.9107645717295971, disc_loss = 0.0002726904105803598
Trained batch 273 in epoch 15, gen_loss = 0.9108909707869927, disc_loss = 0.0002721851694471556
Trained batch 274 in epoch 15, gen_loss = 0.9108965858546171, disc_loss = 0.0002715941885782575
Trained batch 275 in epoch 15, gen_loss = 0.9110772998436637, disc_loss = 0.0002712122824458925
Trained batch 276 in epoch 15, gen_loss = 0.9107043416061126, disc_loss = 0.00027060862189845524
Trained batch 277 in epoch 15, gen_loss = 0.9105557670696176, disc_loss = 0.0002703909057796775
Trained batch 278 in epoch 15, gen_loss = 0.9102450607070786, disc_loss = 0.0002703108291688716
Trained batch 279 in epoch 15, gen_loss = 0.9101829867277826, disc_loss = 0.00026977990125617775
Trained batch 280 in epoch 15, gen_loss = 0.9099795485306464, disc_loss = 0.00026943491130393643
Trained batch 281 in epoch 15, gen_loss = 0.909652368396732, disc_loss = 0.0002689617110863378
Trained batch 282 in epoch 15, gen_loss = 0.9095385356842418, disc_loss = 0.000268620714254623
Trained batch 283 in epoch 15, gen_loss = 0.9095596975423921, disc_loss = 0.0002682733404174247
Trained batch 284 in epoch 15, gen_loss = 0.9095416541685137, disc_loss = 0.00026777159530371266
Trained batch 285 in epoch 15, gen_loss = 0.9096825218700862, disc_loss = 0.00026744691333167707
Trained batch 286 in epoch 15, gen_loss = 0.9094259356787812, disc_loss = 0.00026683036792854605
Trained batch 287 in epoch 15, gen_loss = 0.9092833170046409, disc_loss = 0.00026670112659606576
Trained batch 288 in epoch 15, gen_loss = 0.9093368311241836, disc_loss = 0.00026624299500018335
Trained batch 289 in epoch 15, gen_loss = 0.9092798732478043, disc_loss = 0.00026641628877580937
Trained batch 290 in epoch 15, gen_loss = 0.9094318552934837, disc_loss = 0.0002662517747756164
Trained batch 291 in epoch 15, gen_loss = 0.9091813543887988, disc_loss = 0.0002661030607482208
Trained batch 292 in epoch 15, gen_loss = 0.9092713439830741, disc_loss = 0.00026638580808207815
Trained batch 293 in epoch 15, gen_loss = 0.9092095656459834, disc_loss = 0.0002667914764091632
Trained batch 294 in epoch 15, gen_loss = 0.9092810121633239, disc_loss = 0.00026711246272020234
Trained batch 295 in epoch 15, gen_loss = 0.9091608222271945, disc_loss = 0.0002672267065291463
Trained batch 296 in epoch 15, gen_loss = 0.9092800177709021, disc_loss = 0.0002668907801500719
Trained batch 297 in epoch 15, gen_loss = 0.9092628573811294, disc_loss = 0.00026657878978516994
Trained batch 298 in epoch 15, gen_loss = 0.9093783148953747, disc_loss = 0.00026652564536616593
Trained batch 299 in epoch 15, gen_loss = 0.9090891098976135, disc_loss = 0.00026656395304598847
Trained batch 300 in epoch 15, gen_loss = 0.9086422823196234, disc_loss = 0.0002661698255235441
Trained batch 301 in epoch 15, gen_loss = 0.9084448070320862, disc_loss = 0.0002661576256636277
Trained batch 302 in epoch 15, gen_loss = 0.9083069639630837, disc_loss = 0.00026582602950169556
Trained batch 303 in epoch 15, gen_loss = 0.9083294713575589, disc_loss = 0.0002656093538940982
Trained batch 304 in epoch 15, gen_loss = 0.9083431875119444, disc_loss = 0.0002651745315591545
Trained batch 305 in epoch 15, gen_loss = 0.9088048995320314, disc_loss = 0.00026497818584579765
Trained batch 306 in epoch 15, gen_loss = 0.9084395214866737, disc_loss = 0.0002648314765517233
Trained batch 307 in epoch 15, gen_loss = 0.9085015437819741, disc_loss = 0.0002645477694599109
Trained batch 308 in epoch 15, gen_loss = 0.9085772621978834, disc_loss = 0.000264135397743497
Trained batch 309 in epoch 15, gen_loss = 0.9083927990928773, disc_loss = 0.0002638772033782105
Trained batch 310 in epoch 15, gen_loss = 0.9082164833400027, disc_loss = 0.00026356952538724294
Trained batch 311 in epoch 15, gen_loss = 0.9079063872878368, disc_loss = 0.0002633022175779423
Trained batch 312 in epoch 15, gen_loss = 0.90778271249308, disc_loss = 0.00026313533548811695
Trained batch 313 in epoch 15, gen_loss = 0.9076402238599813, disc_loss = 0.00026270480138571506
Trained batch 314 in epoch 15, gen_loss = 0.9074623861010113, disc_loss = 0.00026250535540009245
Trained batch 315 in epoch 15, gen_loss = 0.907242980561679, disc_loss = 0.00026204449236905055
Trained batch 316 in epoch 15, gen_loss = 0.9070986210359759, disc_loss = 0.000261944979285103
Trained batch 317 in epoch 15, gen_loss = 0.9069351244647548, disc_loss = 0.0002621740342142374
Trained batch 318 in epoch 15, gen_loss = 0.9068547279857169, disc_loss = 0.00026315715784614986
Trained batch 319 in epoch 15, gen_loss = 0.9065650451928378, disc_loss = 0.0002664888789468023
Trained batch 320 in epoch 15, gen_loss = 0.9067976172096632, disc_loss = 0.00026735687157196483
Trained batch 321 in epoch 15, gen_loss = 0.9069095526052557, disc_loss = 0.00026835071693318436
Trained batch 322 in epoch 15, gen_loss = 0.9072245682356158, disc_loss = 0.0002691959047460447
Trained batch 323 in epoch 15, gen_loss = 0.9071417147362674, disc_loss = 0.00027300582746928417
Trained batch 324 in epoch 15, gen_loss = 0.9073014937914334, disc_loss = 0.00027383843765934354
Trained batch 325 in epoch 15, gen_loss = 0.9073106679448321, disc_loss = 0.0002747823679889338
Trained batch 326 in epoch 15, gen_loss = 0.9072879498158026, disc_loss = 0.0002746827383438447
Trained batch 327 in epoch 15, gen_loss = 0.9074331216695832, disc_loss = 0.0002751997499661052
Trained batch 328 in epoch 15, gen_loss = 0.9073466470176326, disc_loss = 0.00027494754144298425
Trained batch 329 in epoch 15, gen_loss = 0.9075322911594853, disc_loss = 0.0002747813009729284
Trained batch 330 in epoch 15, gen_loss = 0.9073854112192944, disc_loss = 0.00027532046520537375
Trained batch 331 in epoch 15, gen_loss = 0.9074485991374556, disc_loss = 0.0002749498434273978
Trained batch 332 in epoch 15, gen_loss = 0.907758862048656, disc_loss = 0.00027673271308214663
Trained batch 333 in epoch 15, gen_loss = 0.9081953788945775, disc_loss = 0.0002778370168332281
Trained batch 334 in epoch 15, gen_loss = 0.9081106940312172, disc_loss = 0.00027864460719127294
Trained batch 335 in epoch 15, gen_loss = 0.9084058489118304, disc_loss = 0.0002791376106783684
Trained batch 336 in epoch 15, gen_loss = 0.9083050949283453, disc_loss = 0.0002790280088679713
Trained batch 337 in epoch 15, gen_loss = 0.9081482601588999, disc_loss = 0.0002785796400019417
Trained batch 338 in epoch 15, gen_loss = 0.9081132153494168, disc_loss = 0.00027830731949152887
Trained batch 339 in epoch 15, gen_loss = 0.908134092653499, disc_loss = 0.00027820801733469125
Trained batch 340 in epoch 15, gen_loss = 0.9079361486295101, disc_loss = 0.0002780037643321342
Trained batch 341 in epoch 15, gen_loss = 0.9077668557738701, disc_loss = 0.00027775796328494953
Trained batch 342 in epoch 15, gen_loss = 0.9078319057083686, disc_loss = 0.00027747207415665555
Trained batch 343 in epoch 15, gen_loss = 0.9076796458211056, disc_loss = 0.0002774422593236438
Trained batch 344 in epoch 15, gen_loss = 0.9074376470800759, disc_loss = 0.000277246742452785
Trained batch 345 in epoch 15, gen_loss = 0.907424402891556, disc_loss = 0.0002769832938195898
Trained batch 346 in epoch 15, gen_loss = 0.9074787215815497, disc_loss = 0.0002771908770574012
Trained batch 347 in epoch 15, gen_loss = 0.9072511567809116, disc_loss = 0.0002770129560575561
Trained batch 348 in epoch 15, gen_loss = 0.9076590792497454, disc_loss = 0.0002774716501301328
Trained batch 349 in epoch 15, gen_loss = 0.9078978468690599, disc_loss = 0.00027838569722786943
Trained batch 350 in epoch 15, gen_loss = 0.9075634970284595, disc_loss = 0.0002785721712139106
Trained batch 351 in epoch 15, gen_loss = 0.9077586170963265, disc_loss = 0.0002784296129696238
Trained batch 352 in epoch 15, gen_loss = 0.9079909491809164, disc_loss = 0.0002791041180136265
Trained batch 353 in epoch 15, gen_loss = 0.9076693989126022, disc_loss = 0.0002791549820157944
Trained batch 354 in epoch 15, gen_loss = 0.9079841763200894, disc_loss = 0.0002795936436266114
Trained batch 355 in epoch 15, gen_loss = 0.9080546309104126, disc_loss = 0.0002810591198835886
Trained batch 356 in epoch 15, gen_loss = 0.9082865292618588, disc_loss = 0.00028111616723713564
Trained batch 357 in epoch 15, gen_loss = 0.9081255708659828, disc_loss = 0.00028125137566994
Trained batch 358 in epoch 15, gen_loss = 0.9083161179733807, disc_loss = 0.0002810438168239987
Trained batch 359 in epoch 15, gen_loss = 0.9082724769910177, disc_loss = 0.0002816811881226992
Trained batch 360 in epoch 15, gen_loss = 0.908141060879356, disc_loss = 0.0002823045844374382
Trained batch 361 in epoch 15, gen_loss = 0.9081967466443942, disc_loss = 0.00028232992939874194
Trained batch 362 in epoch 15, gen_loss = 0.9082883047991877, disc_loss = 0.00028292606079219086
Trained batch 363 in epoch 15, gen_loss = 0.9086320544337179, disc_loss = 0.0002841111366721164
Trained batch 364 in epoch 15, gen_loss = 0.9088057168542523, disc_loss = 0.0002853155223619231
Trained batch 365 in epoch 15, gen_loss = 0.9085709879307148, disc_loss = 0.00028519756992839284
Trained batch 366 in epoch 15, gen_loss = 0.9084006687600866, disc_loss = 0.0002861367197771054
Trained batch 367 in epoch 15, gen_loss = 0.9083830108461173, disc_loss = 0.00028595136334684946
Trained batch 368 in epoch 15, gen_loss = 0.9088298495869004, disc_loss = 0.0002859514139803709
Trained batch 369 in epoch 15, gen_loss = 0.9089672964972418, disc_loss = 0.00028586853148079025
Trained batch 370 in epoch 15, gen_loss = 0.9092724776332269, disc_loss = 0.0002857481875772854
Trained batch 371 in epoch 15, gen_loss = 0.909098191607383, disc_loss = 0.0002862803547188417
Trained batch 372 in epoch 15, gen_loss = 0.9088342357576692, disc_loss = 0.00028621734413877007
Trained batch 373 in epoch 15, gen_loss = 0.9089984871486929, disc_loss = 0.0002864859356035361
Trained batch 374 in epoch 15, gen_loss = 0.9091393753687541, disc_loss = 0.0002872885818554399
Trained batch 375 in epoch 15, gen_loss = 0.9089995739941902, disc_loss = 0.0002874935857146332
Trained batch 376 in epoch 15, gen_loss = 0.9089002255103317, disc_loss = 0.0002874116183359569
Trained batch 377 in epoch 15, gen_loss = 0.908698853046175, disc_loss = 0.0002879757475822107
Trained batch 378 in epoch 15, gen_loss = 0.9087550629097427, disc_loss = 0.0002877899915900507
Trained batch 379 in epoch 15, gen_loss = 0.9087000188074614, disc_loss = 0.00028791535688996146
Trained batch 380 in epoch 15, gen_loss = 0.9086709075712469, disc_loss = 0.0002880746930028835
Trained batch 381 in epoch 15, gen_loss = 0.9089106287007557, disc_loss = 0.0002889871981163468
Trained batch 382 in epoch 15, gen_loss = 0.9093310447025548, disc_loss = 0.0002898047971680539
Trained batch 383 in epoch 15, gen_loss = 0.9096143888309598, disc_loss = 0.0002897313786623575
Trained batch 384 in epoch 15, gen_loss = 0.9095352375662172, disc_loss = 0.0002896776206091397
Trained batch 385 in epoch 15, gen_loss = 0.9096690084341277, disc_loss = 0.00028970322366686263
Trained batch 386 in epoch 15, gen_loss = 0.9099869581772068, disc_loss = 0.0002895983858811621
Trained batch 387 in epoch 15, gen_loss = 0.9101106409252304, disc_loss = 0.00028950234430799495
Trained batch 388 in epoch 15, gen_loss = 0.9100138312133847, disc_loss = 0.00028926206863461935
Trained batch 389 in epoch 15, gen_loss = 0.9097082752447861, disc_loss = 0.0002892828427250676
Trained batch 390 in epoch 15, gen_loss = 0.9097129172071472, disc_loss = 0.00028959024945631877
Trained batch 391 in epoch 15, gen_loss = 0.9095378122767623, disc_loss = 0.00028961716951907504
Trained batch 392 in epoch 15, gen_loss = 0.9095642489331369, disc_loss = 0.0002899938971895793
Trained batch 393 in epoch 15, gen_loss = 0.9094495396626178, disc_loss = 0.00029025516172632846
Trained batch 394 in epoch 15, gen_loss = 0.9093854706498641, disc_loss = 0.0002900528289558944
Trained batch 395 in epoch 15, gen_loss = 0.9092197662050073, disc_loss = 0.00028961566782858097
Trained batch 396 in epoch 15, gen_loss = 0.909111191703931, disc_loss = 0.000289304365335186
Trained batch 397 in epoch 15, gen_loss = 0.9092144486892163, disc_loss = 0.00028927309068792087
Trained batch 398 in epoch 15, gen_loss = 0.9094203332611791, disc_loss = 0.0002889462896320154
Trained batch 399 in epoch 15, gen_loss = 0.9093942494690418, disc_loss = 0.0002887371658835036
Trained batch 400 in epoch 15, gen_loss = 0.9093560499146097, disc_loss = 0.00028863689357265624
Trained batch 401 in epoch 15, gen_loss = 0.9091861431871481, disc_loss = 0.0002882962550182273
Trained batch 402 in epoch 15, gen_loss = 0.9091716161732638, disc_loss = 0.0002879222558914434
Trained batch 403 in epoch 15, gen_loss = 0.9088350363297037, disc_loss = 0.0002877232452399515
Trained batch 404 in epoch 15, gen_loss = 0.9089218798978829, disc_loss = 0.0002872680490125074
Trained batch 405 in epoch 15, gen_loss = 0.9090245051924231, disc_loss = 0.00028676334154916
Trained batch 406 in epoch 15, gen_loss = 0.9089948220100684, disc_loss = 0.0002863214937103363
Trained batch 407 in epoch 15, gen_loss = 0.9091799083878013, disc_loss = 0.00028614211481123905
Trained batch 408 in epoch 15, gen_loss = 0.9092037086090423, disc_loss = 0.000285934379696049
Trained batch 409 in epoch 15, gen_loss = 0.9093174679977137, disc_loss = 0.00028655281447998544
Trained batch 410 in epoch 15, gen_loss = 0.909192966283673, disc_loss = 0.00028627253098015667
Trained batch 411 in epoch 15, gen_loss = 0.9091278789112869, disc_loss = 0.00028640152302314073
Trained batch 412 in epoch 15, gen_loss = 0.9090120399835323, disc_loss = 0.0002863325664368244
Trained batch 413 in epoch 15, gen_loss = 0.9092840373804028, disc_loss = 0.0002865759744199222
Trained batch 414 in epoch 15, gen_loss = 0.9097792760435357, disc_loss = 0.0002869048668141757
Trained batch 415 in epoch 15, gen_loss = 0.909951674250456, disc_loss = 0.0002871635254170822
Trained batch 416 in epoch 15, gen_loss = 0.9099570629979781, disc_loss = 0.00028859380743889544
Trained batch 417 in epoch 15, gen_loss = 0.9101338677429126, disc_loss = 0.00028993270160662654
Trained batch 418 in epoch 15, gen_loss = 0.9102905677155834, disc_loss = 0.0002900655583163439
Trained batch 419 in epoch 15, gen_loss = 0.9103402038415273, disc_loss = 0.0002902814589365984
Trained batch 420 in epoch 15, gen_loss = 0.9103230189824048, disc_loss = 0.0002906930194534428
Trained batch 421 in epoch 15, gen_loss = 0.9105804932625938, disc_loss = 0.0002911589770829989
Trained batch 422 in epoch 15, gen_loss = 0.9104519580836555, disc_loss = 0.00029124540140457124
Trained batch 423 in epoch 15, gen_loss = 0.9105920213854538, disc_loss = 0.00029101459174098464
Trained batch 424 in epoch 15, gen_loss = 0.9105121395167183, disc_loss = 0.0002908273320987492
Trained batch 425 in epoch 15, gen_loss = 0.9106889388091127, disc_loss = 0.00029043685911991744
Trained batch 426 in epoch 15, gen_loss = 0.9104443473056552, disc_loss = 0.0002900365455599831
Trained batch 427 in epoch 15, gen_loss = 0.9103532163339241, disc_loss = 0.0002897061356668367
Trained batch 428 in epoch 15, gen_loss = 0.9102674389218951, disc_loss = 0.00028928520476040136
Trained batch 429 in epoch 15, gen_loss = 0.9102668913297876, disc_loss = 0.00028880910758743994
Trained batch 430 in epoch 15, gen_loss = 0.9104723025917177, disc_loss = 0.00028843979197330105
Trained batch 431 in epoch 15, gen_loss = 0.9103007093071938, disc_loss = 0.000288073930665565
Trained batch 432 in epoch 15, gen_loss = 0.910221674976393, disc_loss = 0.00028771177063898807
Trained batch 433 in epoch 15, gen_loss = 0.910393591438021, disc_loss = 0.00028728922787253863
Trained batch 434 in epoch 15, gen_loss = 0.910443937915495, disc_loss = 0.0002872122202942351
Trained batch 435 in epoch 15, gen_loss = 0.9105398463546683, disc_loss = 0.00028681324683012304
Trained batch 436 in epoch 15, gen_loss = 0.910488846509353, disc_loss = 0.0002863931175284311
Trained batch 437 in epoch 15, gen_loss = 0.9102707819579399, disc_loss = 0.000285986326207629
Trained batch 438 in epoch 15, gen_loss = 0.9101937145741491, disc_loss = 0.00028557621002192493
Trained batch 439 in epoch 15, gen_loss = 0.9103114762089469, disc_loss = 0.0002852421115180319
Trained batch 440 in epoch 15, gen_loss = 0.9106235277085077, disc_loss = 0.00028489467769012786
Trained batch 441 in epoch 15, gen_loss = 0.9107023170091447, disc_loss = 0.0002852491968095659
Trained batch 442 in epoch 15, gen_loss = 0.9106335695118183, disc_loss = 0.0002848423287895525
Trained batch 443 in epoch 15, gen_loss = 0.9106018345903706, disc_loss = 0.00028449346262294074
Trained batch 444 in epoch 15, gen_loss = 0.9106709402598692, disc_loss = 0.00028411253264534883
Trained batch 445 in epoch 15, gen_loss = 0.9104273513026302, disc_loss = 0.00028394472352912935
Trained batch 446 in epoch 15, gen_loss = 0.9102768632656243, disc_loss = 0.0002836256636456655
Trained batch 447 in epoch 15, gen_loss = 0.9102100607539926, disc_loss = 0.00028342762604032553
Trained batch 448 in epoch 15, gen_loss = 0.9100637313783302, disc_loss = 0.0002831707389043636
Trained batch 449 in epoch 15, gen_loss = 0.9100694036483765, disc_loss = 0.0002828202666973488
Trained batch 450 in epoch 15, gen_loss = 0.9100450780862187, disc_loss = 0.00028247880111056115
Trained batch 451 in epoch 15, gen_loss = 0.9103106137661807, disc_loss = 0.0002822249128346216
Trained batch 452 in epoch 15, gen_loss = 0.9102262499316639, disc_loss = 0.00028192975568491557
Trained batch 453 in epoch 15, gen_loss = 0.9102022433858611, disc_loss = 0.00028146666251297316
Trained batch 454 in epoch 15, gen_loss = 0.910043800663162, disc_loss = 0.00028113850960405644
Trained batch 455 in epoch 15, gen_loss = 0.9102146064764575, disc_loss = 0.00028093715107452386
Trained batch 456 in epoch 15, gen_loss = 0.9101001930706349, disc_loss = 0.00028056906696961257
Trained batch 457 in epoch 15, gen_loss = 0.9099558230050266, disc_loss = 0.0002803457292116056
Trained batch 458 in epoch 15, gen_loss = 0.9096556303288162, disc_loss = 0.0002814758580922675
Trained batch 459 in epoch 15, gen_loss = 0.9097177390171134, disc_loss = 0.0002819959364031725
Trained batch 460 in epoch 15, gen_loss = 0.9095895855390586, disc_loss = 0.00028190133348082085
Trained batch 461 in epoch 15, gen_loss = 0.9096823005707233, disc_loss = 0.0002818623374307476
Trained batch 462 in epoch 15, gen_loss = 0.9097989438419466, disc_loss = 0.00028169473411779865
Trained batch 463 in epoch 15, gen_loss = 0.9098182288480217, disc_loss = 0.0002812683330909028
Trained batch 464 in epoch 15, gen_loss = 0.9099217760947442, disc_loss = 0.00028091567673004404
Trained batch 465 in epoch 15, gen_loss = 0.9096471978103654, disc_loss = 0.0002815642653874026
Trained batch 466 in epoch 15, gen_loss = 0.9095631272430338, disc_loss = 0.0002814335390831677
Trained batch 467 in epoch 15, gen_loss = 0.9096641546895361, disc_loss = 0.00028118639617872774
Trained batch 468 in epoch 15, gen_loss = 0.9095632716028421, disc_loss = 0.0002809876549010004
Trained batch 469 in epoch 15, gen_loss = 0.9095814065730318, disc_loss = 0.0002805741409866506
Trained batch 470 in epoch 15, gen_loss = 0.9098191899099167, disc_loss = 0.0002804775047406402
Trained batch 471 in epoch 15, gen_loss = 0.9095625299013267, disc_loss = 0.00028041933717882415
Trained batch 472 in epoch 15, gen_loss = 0.9093769622403521, disc_loss = 0.0002803700540531535
Trained batch 473 in epoch 15, gen_loss = 0.9094008144447069, disc_loss = 0.00028010318428756895
Trained batch 474 in epoch 15, gen_loss = 0.9092028329246923, disc_loss = 0.00027988761214625186
Trained batch 475 in epoch 15, gen_loss = 0.9093305571239536, disc_loss = 0.00027969794235318927
Trained batch 476 in epoch 15, gen_loss = 0.9091858971293867, disc_loss = 0.00027938589681097574
Trained batch 477 in epoch 15, gen_loss = 0.9089964751668554, disc_loss = 0.0002790928175657058
Trained batch 478 in epoch 15, gen_loss = 0.9088988382532601, disc_loss = 0.00027877714009243425
Trained batch 479 in epoch 15, gen_loss = 0.9088805495450895, disc_loss = 0.00027852600765072567
Trained batch 480 in epoch 15, gen_loss = 0.9089020759548814, disc_loss = 0.00027824891593489746
Trained batch 481 in epoch 15, gen_loss = 0.9088153978848359, disc_loss = 0.00027797867781475394
Trained batch 482 in epoch 15, gen_loss = 0.9090517891366536, disc_loss = 0.000277766033440783
Trained batch 483 in epoch 15, gen_loss = 0.9091516650658994, disc_loss = 0.000277575087043373
Trained batch 484 in epoch 15, gen_loss = 0.9094034319071426, disc_loss = 0.0002774050891772633
Trained batch 485 in epoch 15, gen_loss = 0.9094976880913409, disc_loss = 0.0002769993935907384
Trained batch 486 in epoch 15, gen_loss = 0.9096943223256105, disc_loss = 0.00027662753283193915
Trained batch 487 in epoch 15, gen_loss = 0.9097827565474589, disc_loss = 0.0002763063152475506
Trained batch 488 in epoch 15, gen_loss = 0.9096610409594265, disc_loss = 0.0002760180106377258
Trained batch 489 in epoch 15, gen_loss = 0.9100358680802949, disc_loss = 0.00027578003380545035
Trained batch 490 in epoch 15, gen_loss = 0.9098909460842731, disc_loss = 0.0002756776453853896
Trained batch 491 in epoch 15, gen_loss = 0.9098323802880155, disc_loss = 0.00027562739639351336
Trained batch 492 in epoch 15, gen_loss = 0.9099641262155034, disc_loss = 0.00027532502399314984
Trained batch 493 in epoch 15, gen_loss = 0.9097532535854139, disc_loss = 0.00027510919518330935
Trained batch 494 in epoch 15, gen_loss = 0.9098765884987031, disc_loss = 0.000274928040303304
Trained batch 495 in epoch 15, gen_loss = 0.9097545095268758, disc_loss = 0.0002745094390276438
Trained batch 496 in epoch 15, gen_loss = 0.9095027043785847, disc_loss = 0.00027436349025688095
Trained batch 497 in epoch 15, gen_loss = 0.909600679414818, disc_loss = 0.00027411297358697316
Trained batch 498 in epoch 15, gen_loss = 0.9096123622749038, disc_loss = 0.00027372111813776486
Trained batch 499 in epoch 15, gen_loss = 0.9095462619066238, disc_loss = 0.000273374278069241
Trained batch 500 in epoch 15, gen_loss = 0.9096087831223082, disc_loss = 0.00027298025004152105
Trained batch 501 in epoch 15, gen_loss = 0.9095015307346663, disc_loss = 0.00027274738177327824
Trained batch 502 in epoch 15, gen_loss = 0.9098084067729548, disc_loss = 0.00027238767852504026
Trained batch 503 in epoch 15, gen_loss = 0.9099831384798837, disc_loss = 0.0002721861418404077
Trained batch 504 in epoch 15, gen_loss = 0.9100605356811297, disc_loss = 0.0002720107457837975
Trained batch 505 in epoch 15, gen_loss = 0.9100527686799468, disc_loss = 0.00027170763335493484
Trained batch 506 in epoch 15, gen_loss = 0.9097714648679398, disc_loss = 0.00027200702169227656
Trained batch 507 in epoch 15, gen_loss = 0.9097318883955948, disc_loss = 0.00027217313179890183
Trained batch 508 in epoch 15, gen_loss = 0.9097881805451773, disc_loss = 0.00027191939688020537
Trained batch 509 in epoch 15, gen_loss = 0.9098556229881212, disc_loss = 0.0002717353902898692
Trained batch 510 in epoch 15, gen_loss = 0.9097068756527164, disc_loss = 0.00027190577955287746
Trained batch 511 in epoch 15, gen_loss = 0.9097888509277254, disc_loss = 0.00027167020090246297
Trained batch 512 in epoch 15, gen_loss = 0.9096131891767416, disc_loss = 0.0002723252816605935
Trained batch 513 in epoch 15, gen_loss = 0.9095389155330361, disc_loss = 0.0002723664243738185
Trained batch 514 in epoch 15, gen_loss = 0.9096325206525118, disc_loss = 0.0002720320377599457
Trained batch 515 in epoch 15, gen_loss = 0.9096843994172045, disc_loss = 0.0002717217414256577
Trained batch 516 in epoch 15, gen_loss = 0.9096635499360253, disc_loss = 0.0002714607893637691
Trained batch 517 in epoch 15, gen_loss = 0.9097219562898732, disc_loss = 0.0002712731145660107
Trained batch 518 in epoch 15, gen_loss = 0.9093646734436124, disc_loss = 0.0002710419427990413
Trained batch 519 in epoch 15, gen_loss = 0.9094960079743312, disc_loss = 0.00027109504306001606
Trained batch 520 in epoch 15, gen_loss = 0.9094078128946491, disc_loss = 0.0002708431447847414
Trained batch 521 in epoch 15, gen_loss = 0.9092884016904794, disc_loss = 0.0002706066354841816
Trained batch 522 in epoch 15, gen_loss = 0.9093051359028935, disc_loss = 0.0002705417612266378
Trained batch 523 in epoch 15, gen_loss = 0.909324562390342, disc_loss = 0.00027029559071824926
Trained batch 524 in epoch 15, gen_loss = 0.9095134808903649, disc_loss = 0.0002701864636176088
Trained batch 525 in epoch 15, gen_loss = 0.9095973946975664, disc_loss = 0.0002700114471134296
Trained batch 526 in epoch 15, gen_loss = 0.9094399165157123, disc_loss = 0.00027019335330604
Trained batch 527 in epoch 15, gen_loss = 0.909362491446011, disc_loss = 0.000269881732341067
Trained batch 528 in epoch 15, gen_loss = 0.909462772042179, disc_loss = 0.00026964246286204725
Trained batch 529 in epoch 15, gen_loss = 0.9092844674047434, disc_loss = 0.0002699882475871215
Trained batch 530 in epoch 15, gen_loss = 0.9092054030316025, disc_loss = 0.0002697516283729173
Trained batch 531 in epoch 15, gen_loss = 0.9090804643648908, disc_loss = 0.00026994097765451527
Trained batch 532 in epoch 15, gen_loss = 0.9092553804784063, disc_loss = 0.00026982097931987713
Trained batch 533 in epoch 15, gen_loss = 0.9091151274098885, disc_loss = 0.0002709361160055635
Trained batch 534 in epoch 15, gen_loss = 0.9089930761640317, disc_loss = 0.0002709515281396953
Trained batch 535 in epoch 15, gen_loss = 0.9091044900132649, disc_loss = 0.0002714594334404987
Trained batch 536 in epoch 15, gen_loss = 0.9092425969281898, disc_loss = 0.0002713279195928303
Trained batch 537 in epoch 15, gen_loss = 0.9091696931970163, disc_loss = 0.0002711812691060007
Trained batch 538 in epoch 15, gen_loss = 0.9091289055590727, disc_loss = 0.0002709118957977512
Trained batch 539 in epoch 15, gen_loss = 0.9091927871659949, disc_loss = 0.00027072545774528946
Trained batch 540 in epoch 15, gen_loss = 0.9092401978929912, disc_loss = 0.0002706241810203929
Trained batch 541 in epoch 15, gen_loss = 0.9094623891409913, disc_loss = 0.0002705162653296359
Trained batch 542 in epoch 15, gen_loss = 0.9092937687044864, disc_loss = 0.00027014035490362064
Trained batch 543 in epoch 15, gen_loss = 0.9092602036235964, disc_loss = 0.00026983245881156644
Trained batch 544 in epoch 15, gen_loss = 0.9092369887806954, disc_loss = 0.00026953962158653117
Trained batch 545 in epoch 15, gen_loss = 0.9092129278968979, disc_loss = 0.0002692922178992529
Trained batch 546 in epoch 15, gen_loss = 0.9090665581021492, disc_loss = 0.00026900985361882646
Trained batch 547 in epoch 15, gen_loss = 0.9094703897942592, disc_loss = 0.0002699154494594771
Trained batch 548 in epoch 15, gen_loss = 0.9095200710609311, disc_loss = 0.00027016919986092534
Trained batch 549 in epoch 15, gen_loss = 0.9096376429904591, disc_loss = 0.0002700085197813513
Trained batch 550 in epoch 15, gen_loss = 0.9094700525546896, disc_loss = 0.000269793303235592
Trained batch 551 in epoch 15, gen_loss = 0.9091934702102689, disc_loss = 0.00027004005113522527
Trained batch 552 in epoch 15, gen_loss = 0.9091697685541771, disc_loss = 0.0002697742220367369
Trained batch 553 in epoch 15, gen_loss = 0.909137156465854, disc_loss = 0.0002694579548514927
Trained batch 554 in epoch 15, gen_loss = 0.9091668776563696, disc_loss = 0.00026930423204625563
Trained batch 555 in epoch 15, gen_loss = 0.9089878258302058, disc_loss = 0.0002691522621841332
Trained batch 556 in epoch 15, gen_loss = 0.9090453413059296, disc_loss = 0.00026885603850914747
Trained batch 557 in epoch 15, gen_loss = 0.9089939710700811, disc_loss = 0.00026864366049671336
Trained batch 558 in epoch 15, gen_loss = 0.9089084663203449, disc_loss = 0.00026835341000582105
Trained batch 559 in epoch 15, gen_loss = 0.908812945655414, disc_loss = 0.0002681170328027552
Trained batch 560 in epoch 15, gen_loss = 0.9086695902062822, disc_loss = 0.0002677584519211797
Trained batch 561 in epoch 15, gen_loss = 0.9083274109719911, disc_loss = 0.0002699452599693252
Trained batch 562 in epoch 15, gen_loss = 0.9082011026768659, disc_loss = 0.00027112520739149145
Trained batch 563 in epoch 15, gen_loss = 0.9082385686272425, disc_loss = 0.00027100843068724996
Trained batch 564 in epoch 15, gen_loss = 0.9082737456380794, disc_loss = 0.00027122256086945564
Trained batch 565 in epoch 15, gen_loss = 0.9083481736402208, disc_loss = 0.00027120686700265664
Trained batch 566 in epoch 15, gen_loss = 0.9083752764595879, disc_loss = 0.00027101980074681673
Trained batch 567 in epoch 15, gen_loss = 0.9084256646079076, disc_loss = 0.00027090695026268344
Trained batch 568 in epoch 15, gen_loss = 0.9083651170160733, disc_loss = 0.0002706138806906365
Trained batch 569 in epoch 15, gen_loss = 0.9082031319015904, disc_loss = 0.00027034973568413733
Trained batch 570 in epoch 15, gen_loss = 0.9080881335480618, disc_loss = 0.0002701551387993368
Trained batch 571 in epoch 15, gen_loss = 0.9081394824531529, disc_loss = 0.0002699236298925113
Trained batch 572 in epoch 15, gen_loss = 0.9081014704745893, disc_loss = 0.0002699591809933287
Trained batch 573 in epoch 15, gen_loss = 0.9079956753951747, disc_loss = 0.0002698297199642266
Trained batch 574 in epoch 15, gen_loss = 0.9078154728723609, disc_loss = 0.00026954203765616633
Trained batch 575 in epoch 15, gen_loss = 0.9078107426563898, disc_loss = 0.00026945323891898926
Trained batch 576 in epoch 15, gen_loss = 0.9079031537269182, disc_loss = 0.00026942838430872747
Trained batch 577 in epoch 15, gen_loss = 0.9078300793278176, disc_loss = 0.00026940651550956687
Trained batch 578 in epoch 15, gen_loss = 0.9077699569428729, disc_loss = 0.0002693081272768809
Trained batch 579 in epoch 15, gen_loss = 0.9077211743798749, disc_loss = 0.00026915675018620997
Trained batch 580 in epoch 15, gen_loss = 0.9079375901033464, disc_loss = 0.0002690567189676081
Trained batch 581 in epoch 15, gen_loss = 0.907828469456676, disc_loss = 0.0002687879273800149
Trained batch 582 in epoch 15, gen_loss = 0.9079970258382336, disc_loss = 0.00026863570397012463
Trained batch 583 in epoch 15, gen_loss = 0.9079632238574225, disc_loss = 0.0002685870635204618
Trained batch 584 in epoch 15, gen_loss = 0.9077470893533821, disc_loss = 0.0002684907033630551
Trained batch 585 in epoch 15, gen_loss = 0.9076781365448298, disc_loss = 0.0002682615089439429
Trained batch 586 in epoch 15, gen_loss = 0.9076445737323728, disc_loss = 0.00026805745887685506
Trained batch 587 in epoch 15, gen_loss = 0.9076167191980647, disc_loss = 0.0002678962795793033
Trained batch 588 in epoch 15, gen_loss = 0.9075830323789237, disc_loss = 0.0002677427169200585
Trained batch 589 in epoch 15, gen_loss = 0.9075748775975179, disc_loss = 0.00026742218118269484
Trained batch 590 in epoch 15, gen_loss = 0.9076653895442659, disc_loss = 0.0002670945089028529
Trained batch 591 in epoch 15, gen_loss = 0.9075130162810957, disc_loss = 0.00026683257381690154
Trained batch 592 in epoch 15, gen_loss = 0.9075029729590649, disc_loss = 0.0002665158249075606
Trained batch 593 in epoch 15, gen_loss = 0.9074029213049596, disc_loss = 0.00026618511528856597
Trained batch 594 in epoch 15, gen_loss = 0.9073708695523879, disc_loss = 0.00026600849691205147
Trained batch 595 in epoch 15, gen_loss = 0.9070740054117753, disc_loss = 0.0002658232241317563
Trained batch 596 in epoch 15, gen_loss = 0.9070758097734882, disc_loss = 0.0002656797150726558
Trained batch 597 in epoch 15, gen_loss = 0.9071331277340152, disc_loss = 0.000265446216087297
Trained batch 598 in epoch 15, gen_loss = 0.9072031708113937, disc_loss = 0.00026528627129661494
Trained batch 599 in epoch 15, gen_loss = 0.9072064368923505, disc_loss = 0.00026506574668019314
Trained batch 600 in epoch 15, gen_loss = 0.9069606899818445, disc_loss = 0.00026483139567828336
Trained batch 601 in epoch 15, gen_loss = 0.9069465757208409, disc_loss = 0.00026461290092077153
Trained batch 602 in epoch 15, gen_loss = 0.9071390318435618, disc_loss = 0.0002645938324557261
Trained batch 603 in epoch 15, gen_loss = 0.9070871827618175, disc_loss = 0.0002644732993583554
Trained batch 604 in epoch 15, gen_loss = 0.9068992547752444, disc_loss = 0.00026444976906194004
Trained batch 605 in epoch 15, gen_loss = 0.906974863199511, disc_loss = 0.00026418627016682394
Trained batch 606 in epoch 15, gen_loss = 0.9070453915800255, disc_loss = 0.0002639360089119504
Trained batch 607 in epoch 15, gen_loss = 0.9071011432495556, disc_loss = 0.00026368974454271665
Trained batch 608 in epoch 15, gen_loss = 0.9070731739105262, disc_loss = 0.0002636492066042328
Trained batch 609 in epoch 15, gen_loss = 0.9071599441473601, disc_loss = 0.0002633229757804179
Trained batch 610 in epoch 15, gen_loss = 0.9071863984320245, disc_loss = 0.0002630201171621194
Trained batch 611 in epoch 15, gen_loss = 0.9070889595287298, disc_loss = 0.00026279661420523873
Trained batch 612 in epoch 15, gen_loss = 0.9070733486147534, disc_loss = 0.00026256413250330907
Trained batch 613 in epoch 15, gen_loss = 0.9070650975944942, disc_loss = 0.0002622799414959137
Trained batch 614 in epoch 15, gen_loss = 0.9069927326062831, disc_loss = 0.0002619416450459805
Trained batch 615 in epoch 15, gen_loss = 0.9072257162301571, disc_loss = 0.0002617461184547517
Trained batch 616 in epoch 15, gen_loss = 0.9072779603483612, disc_loss = 0.00026154167288312434
Trained batch 617 in epoch 15, gen_loss = 0.9072722812879432, disc_loss = 0.0002613277836550369
Trained batch 618 in epoch 15, gen_loss = 0.9075540491953035, disc_loss = 0.0002610978804488654
Trained batch 619 in epoch 15, gen_loss = 0.9076481736475421, disc_loss = 0.00026086167062232794
Trained batch 620 in epoch 15, gen_loss = 0.90750045016192, disc_loss = 0.0002607092601069978
Trained batch 621 in epoch 15, gen_loss = 0.9076752022531638, disc_loss = 0.0002605052725072251
Trained batch 622 in epoch 15, gen_loss = 0.9074916550665376, disc_loss = 0.0002604098556454691
Trained batch 623 in epoch 15, gen_loss = 0.9073097428832299, disc_loss = 0.00026024206877431984
Trained batch 624 in epoch 15, gen_loss = 0.9072435455322265, disc_loss = 0.000260139579733368
Trained batch 625 in epoch 15, gen_loss = 0.9070098096379837, disc_loss = 0.0002602158382827135
Trained batch 626 in epoch 15, gen_loss = 0.9071424904812656, disc_loss = 0.0002603786339643753
Trained batch 627 in epoch 15, gen_loss = 0.9071177527023728, disc_loss = 0.00026036793053301074
Trained batch 628 in epoch 15, gen_loss = 0.9070842443285762, disc_loss = 0.00026035960517305104
Trained batch 629 in epoch 15, gen_loss = 0.9069090256615291, disc_loss = 0.00026024475007452855
Trained batch 630 in epoch 15, gen_loss = 0.9070226438638714, disc_loss = 0.00026031536650528435
Trained batch 631 in epoch 15, gen_loss = 0.9069650012858307, disc_loss = 0.0002602889680008358
Trained batch 632 in epoch 15, gen_loss = 0.906984730071931, disc_loss = 0.00026035200060600135
Trained batch 633 in epoch 15, gen_loss = 0.9068931620391761, disc_loss = 0.00026019935670177664
Trained batch 634 in epoch 15, gen_loss = 0.9069625515637435, disc_loss = 0.0002602566484481969
Trained batch 635 in epoch 15, gen_loss = 0.9070859964726106, disc_loss = 0.0002601260451303243
Trained batch 636 in epoch 15, gen_loss = 0.9070972429714173, disc_loss = 0.0002599452712401869
Trained batch 637 in epoch 15, gen_loss = 0.9072525233123744, disc_loss = 0.0002597727017876945
Trained batch 638 in epoch 15, gen_loss = 0.9070809089894959, disc_loss = 0.00025956640568157766
Trained batch 639 in epoch 15, gen_loss = 0.9068741059862078, disc_loss = 0.0002594574973386443
Trained batch 640 in epoch 15, gen_loss = 0.9067368028502383, disc_loss = 0.0002592946400798896
Trained batch 641 in epoch 15, gen_loss = 0.9067928374184998, disc_loss = 0.0002590437722242781
Trained batch 642 in epoch 15, gen_loss = 0.9066864990891417, disc_loss = 0.0002587927448297858
Trained batch 643 in epoch 15, gen_loss = 0.9067420110754345, disc_loss = 0.00025885995379913024
Trained batch 644 in epoch 15, gen_loss = 0.9066671340964562, disc_loss = 0.00025873865551845885
Trained batch 645 in epoch 15, gen_loss = 0.906687191488573, disc_loss = 0.0002586526475043394
Trained batch 646 in epoch 15, gen_loss = 0.9065391640574707, disc_loss = 0.0002585256633403102
Trained batch 647 in epoch 15, gen_loss = 0.9064509271655554, disc_loss = 0.00025830898481037795
Trained batch 648 in epoch 15, gen_loss = 0.9064564042723234, disc_loss = 0.0002581445260988857
Trained batch 649 in epoch 15, gen_loss = 0.9063928513343518, disc_loss = 0.00025804203906983064
Trained batch 650 in epoch 15, gen_loss = 0.9063609238776926, disc_loss = 0.000257862075201122
Trained batch 651 in epoch 15, gen_loss = 0.9064557054108637, disc_loss = 0.00025781787530134467
Trained batch 652 in epoch 15, gen_loss = 0.9064454648067538, disc_loss = 0.00025766483279810446
Trained batch 653 in epoch 15, gen_loss = 0.9064341280438485, disc_loss = 0.0002574089429429725
Trained batch 654 in epoch 15, gen_loss = 0.9064505598927273, disc_loss = 0.00025714797356373895
Trained batch 655 in epoch 15, gen_loss = 0.9064500092914919, disc_loss = 0.0002569755183685629
Trained batch 656 in epoch 15, gen_loss = 0.9064308759647236, disc_loss = 0.00025671208519876626
Trained batch 657 in epoch 15, gen_loss = 0.9062432523556393, disc_loss = 0.00025661509245604707
Trained batch 658 in epoch 15, gen_loss = 0.9061576308900199, disc_loss = 0.00025642249306898117
Trained batch 659 in epoch 15, gen_loss = 0.9061970223080028, disc_loss = 0.0002562393235579789
Trained batch 660 in epoch 15, gen_loss = 0.9063053722641291, disc_loss = 0.0002560085787423943
Trained batch 661 in epoch 15, gen_loss = 0.9064225303262382, disc_loss = 0.00025577279222291035
Trained batch 662 in epoch 15, gen_loss = 0.9063651230000802, disc_loss = 0.0002555115691696604
Trained batch 663 in epoch 15, gen_loss = 0.9062161374702511, disc_loss = 0.0002554160910441136
Trained batch 664 in epoch 15, gen_loss = 0.9061601394101193, disc_loss = 0.0002551175660936904
Trained batch 665 in epoch 15, gen_loss = 0.9062131138535233, disc_loss = 0.00025489058679157824
Trained batch 666 in epoch 15, gen_loss = 0.9061549210298186, disc_loss = 0.0002556243132999882
Trained batch 667 in epoch 15, gen_loss = 0.9063930366924423, disc_loss = 0.00025624297409821
Trained batch 668 in epoch 15, gen_loss = 0.9066325666658547, disc_loss = 0.0002562297098622247
Trained batch 669 in epoch 15, gen_loss = 0.9066978899400626, disc_loss = 0.0002563557043496116
Trained batch 670 in epoch 15, gen_loss = 0.9067649662761148, disc_loss = 0.0002564084148594843
Trained batch 671 in epoch 15, gen_loss = 0.9069116441089482, disc_loss = 0.00025651820897110156
Trained batch 672 in epoch 15, gen_loss = 0.906890205518629, disc_loss = 0.0002570114733800389
Trained batch 673 in epoch 15, gen_loss = 0.9069410443129101, disc_loss = 0.0002574839298079655
Trained batch 674 in epoch 15, gen_loss = 0.9069278706444635, disc_loss = 0.000257502884185804
Trained batch 675 in epoch 15, gen_loss = 0.9070658341667356, disc_loss = 0.0002575044171426916
Trained batch 676 in epoch 15, gen_loss = 0.9069688804392625, disc_loss = 0.00025752405068982237
Trained batch 677 in epoch 15, gen_loss = 0.9070340164643121, disc_loss = 0.0002573676376258762
Trained batch 678 in epoch 15, gen_loss = 0.9070688285954044, disc_loss = 0.0002572042832822458
Trained batch 679 in epoch 15, gen_loss = 0.9071618488606285, disc_loss = 0.0002570691192351446
Trained batch 680 in epoch 15, gen_loss = 0.907314116209089, disc_loss = 0.00025689645818907837
Trained batch 681 in epoch 15, gen_loss = 0.907350415096255, disc_loss = 0.0002567391079204236
Trained batch 682 in epoch 15, gen_loss = 0.9074151345786378, disc_loss = 0.0002566424892508966
Trained batch 683 in epoch 15, gen_loss = 0.9072902790809932, disc_loss = 0.00025712701182932274
Trained batch 684 in epoch 15, gen_loss = 0.9072512677986256, disc_loss = 0.0002570003938791512
Trained batch 685 in epoch 15, gen_loss = 0.9071273596919313, disc_loss = 0.0002570261620842097
Trained batch 686 in epoch 15, gen_loss = 0.9071647530906932, disc_loss = 0.0002569673080732734
Trained batch 687 in epoch 15, gen_loss = 0.9074085704809012, disc_loss = 0.0002567904012235082
Trained batch 688 in epoch 15, gen_loss = 0.9072566164768313, disc_loss = 0.00025684814732041916
Trained batch 689 in epoch 15, gen_loss = 0.907458275038263, disc_loss = 0.00025690529934987695
Trained batch 690 in epoch 15, gen_loss = 0.9074922379122456, disc_loss = 0.0002571504962628548
Trained batch 691 in epoch 15, gen_loss = 0.9074352586889542, disc_loss = 0.00025707139218740185
Trained batch 692 in epoch 15, gen_loss = 0.9074408959860754, disc_loss = 0.00025687817936278693
Trained batch 693 in epoch 15, gen_loss = 0.9074899852275848, disc_loss = 0.00025662580063088154
Trained batch 694 in epoch 15, gen_loss = 0.907418250351501, disc_loss = 0.00025638070893633055
Trained batch 695 in epoch 15, gen_loss = 0.9075254784233269, disc_loss = 0.0002565133628122149
Trained batch 696 in epoch 15, gen_loss = 0.9075169797607269, disc_loss = 0.0002568451015904534
Trained batch 697 in epoch 15, gen_loss = 0.9075163058872551, disc_loss = 0.0002567173718004641
Trained batch 698 in epoch 15, gen_loss = 0.9073459150453493, disc_loss = 0.0002567035654791729
Trained batch 699 in epoch 15, gen_loss = 0.9071410315377372, disc_loss = 0.00025660932335345673
Trained batch 700 in epoch 15, gen_loss = 0.9072266733765432, disc_loss = 0.0002565694833352874
Trained batch 701 in epoch 15, gen_loss = 0.9071483632438203, disc_loss = 0.0002566329411149225
Trained batch 702 in epoch 15, gen_loss = 0.9072824938707637, disc_loss = 0.0002566322393643015
Trained batch 703 in epoch 15, gen_loss = 0.9073045548390258, disc_loss = 0.0002565388503977705
Trained batch 704 in epoch 15, gen_loss = 0.9074354050852729, disc_loss = 0.0002563753006265644
Trained batch 705 in epoch 15, gen_loss = 0.9075083661687273, disc_loss = 0.0002562700748926249
Trained batch 706 in epoch 15, gen_loss = 0.9074725727886593, disc_loss = 0.0002560743033572935
Trained batch 707 in epoch 15, gen_loss = 0.9073528419275069, disc_loss = 0.0002566192618098161
Trained batch 708 in epoch 15, gen_loss = 0.9073827834156235, disc_loss = 0.00025674537733998164
Trained batch 709 in epoch 15, gen_loss = 0.9074747002460587, disc_loss = 0.0002568798808157149
Trained batch 710 in epoch 15, gen_loss = 0.9075114232410694, disc_loss = 0.0002566567088984727
Trained batch 711 in epoch 15, gen_loss = 0.9073074986593107, disc_loss = 0.00025646366810158297
Trained batch 712 in epoch 15, gen_loss = 0.9074508480905317, disc_loss = 0.00025622329974802065
Trained batch 713 in epoch 15, gen_loss = 0.9074306363652066, disc_loss = 0.000256139578155313
Trained batch 714 in epoch 15, gen_loss = 0.9073813990279511, disc_loss = 0.00025602531116870983
Trained batch 715 in epoch 15, gen_loss = 0.9074360746578132, disc_loss = 0.0002558768092718544
Trained batch 716 in epoch 15, gen_loss = 0.9074639978102893, disc_loss = 0.000255676970145041
Trained batch 717 in epoch 15, gen_loss = 0.9074482941029796, disc_loss = 0.00025543805598806654
Trained batch 718 in epoch 15, gen_loss = 0.9075821725980628, disc_loss = 0.0002552185830605438
Trained batch 719 in epoch 15, gen_loss = 0.9075637761917379, disc_loss = 0.00025512949555882693
Trained batch 720 in epoch 15, gen_loss = 0.9075272603273061, disc_loss = 0.00025505194889837503
Trained batch 721 in epoch 15, gen_loss = 0.9074934867940782, disc_loss = 0.00025480881663812635
Trained batch 722 in epoch 15, gen_loss = 0.9074868052826878, disc_loss = 0.00025458335629706223
Trained batch 723 in epoch 15, gen_loss = 0.9074111457358408, disc_loss = 0.0002543946433212937
Trained batch 724 in epoch 15, gen_loss = 0.9075110741319328, disc_loss = 0.0002541875175766422
Trained batch 725 in epoch 15, gen_loss = 0.9074710421982547, disc_loss = 0.00025397543629643266
Trained batch 726 in epoch 15, gen_loss = 0.9073244334906955, disc_loss = 0.0002537508181955549
Trained batch 727 in epoch 15, gen_loss = 0.9072005524412616, disc_loss = 0.0002535141156041281
Trained batch 728 in epoch 15, gen_loss = 0.9070920180554907, disc_loss = 0.00025345854742170803
Trained batch 729 in epoch 15, gen_loss = 0.9072461278471228, disc_loss = 0.0002532402840674191
Trained batch 730 in epoch 15, gen_loss = 0.9073991726589594, disc_loss = 0.0002531966936996553
Trained batch 731 in epoch 15, gen_loss = 0.9074963301908775, disc_loss = 0.0002530921383020074
Trained batch 732 in epoch 15, gen_loss = 0.9073754128622651, disc_loss = 0.00025282699987415374
Trained batch 733 in epoch 15, gen_loss = 0.907340658376912, disc_loss = 0.000252599170883635
Trained batch 734 in epoch 15, gen_loss = 0.9071129172026705, disc_loss = 0.00025290386837120737
Trained batch 735 in epoch 15, gen_loss = 0.907108577778158, disc_loss = 0.0002527679356588756
Trained batch 736 in epoch 15, gen_loss = 0.9070961446257427, disc_loss = 0.0002525496963257797
Trained batch 737 in epoch 15, gen_loss = 0.9069548100636904, disc_loss = 0.00025242098167824634
Trained batch 738 in epoch 15, gen_loss = 0.9068102782569493, disc_loss = 0.00025215503406990223
Trained batch 739 in epoch 15, gen_loss = 0.9067907751412005, disc_loss = 0.0002519419949159193
Trained batch 740 in epoch 15, gen_loss = 0.9068400911313159, disc_loss = 0.0002517924253419485
Trained batch 741 in epoch 15, gen_loss = 0.9066793847919474, disc_loss = 0.00025156266472652723
Trained batch 742 in epoch 15, gen_loss = 0.9065416330925389, disc_loss = 0.00025141257647485885
Trained batch 743 in epoch 15, gen_loss = 0.9063795813789932, disc_loss = 0.0002512302504299207
Trained batch 744 in epoch 15, gen_loss = 0.9063586014229179, disc_loss = 0.00025106776522213886
Trained batch 745 in epoch 15, gen_loss = 0.9062951808800327, disc_loss = 0.0002508517020627692
Trained batch 746 in epoch 15, gen_loss = 0.9064572065709585, disc_loss = 0.00025062367718027366
Trained batch 747 in epoch 15, gen_loss = 0.9064571870998903, disc_loss = 0.00025044572936789786
Trained batch 748 in epoch 15, gen_loss = 0.9063804007977128, disc_loss = 0.0002502604678088009
Trained batch 749 in epoch 15, gen_loss = 0.9063797908624013, disc_loss = 0.0002500753919254445
Trained batch 750 in epoch 15, gen_loss = 0.9062590187145136, disc_loss = 0.00024979712221773496
Trained batch 751 in epoch 15, gen_loss = 0.906206700792338, disc_loss = 0.00024953796042957927
Trained batch 752 in epoch 15, gen_loss = 0.9061472413549385, disc_loss = 0.00024936485339567104
Trained batch 753 in epoch 15, gen_loss = 0.9062472517041376, disc_loss = 0.00024912771873857915
Trained batch 754 in epoch 15, gen_loss = 0.9062810510199591, disc_loss = 0.00024888388390825533
Trained batch 755 in epoch 15, gen_loss = 0.9063355345574636, disc_loss = 0.0002487108723331913
Trained batch 756 in epoch 15, gen_loss = 0.9062751317433668, disc_loss = 0.0002496269707016824
Trained batch 757 in epoch 15, gen_loss = 0.9063242249249783, disc_loss = 0.0002499049857561661
Trained batch 758 in epoch 15, gen_loss = 0.9062575988461692, disc_loss = 0.00024997514359068924
Trained batch 759 in epoch 15, gen_loss = 0.9061730263264556, disc_loss = 0.0002499117135333731
Trained batch 760 in epoch 15, gen_loss = 0.9061610674419478, disc_loss = 0.00024982878509064485
Trained batch 761 in epoch 15, gen_loss = 0.9060430087129588, disc_loss = 0.0002498740328123226
Trained batch 762 in epoch 15, gen_loss = 0.9061100931342588, disc_loss = 0.00024974654680563486
Trained batch 763 in epoch 15, gen_loss = 0.9062049638538461, disc_loss = 0.00024955997409080205
Trained batch 764 in epoch 15, gen_loss = 0.9061484075060078, disc_loss = 0.0002493439203628881
Trained batch 765 in epoch 15, gen_loss = 0.9061902406632745, disc_loss = 0.0002491047376423026
Trained batch 766 in epoch 15, gen_loss = 0.9062990093169032, disc_loss = 0.0002489099747572195
Trained batch 767 in epoch 15, gen_loss = 0.9062511991554251, disc_loss = 0.0002486936917307503
Trained batch 768 in epoch 15, gen_loss = 0.9062570743504984, disc_loss = 0.0002484870155648327
Trained batch 769 in epoch 15, gen_loss = 0.9063403995006115, disc_loss = 0.0002482965236866859
Trained batch 770 in epoch 15, gen_loss = 0.9063580469862497, disc_loss = 0.0002481140945511103
Trained batch 771 in epoch 15, gen_loss = 0.9064140036470532, disc_loss = 0.0002479442236687924
Trained batch 772 in epoch 15, gen_loss = 0.9062749009391469, disc_loss = 0.00024776229614587405
Trained batch 773 in epoch 15, gen_loss = 0.9062313291915628, disc_loss = 0.0002477472535388223
Trained batch 774 in epoch 15, gen_loss = 0.9061572523270884, disc_loss = 0.0002476176192454483
Trained batch 775 in epoch 15, gen_loss = 0.9060902702286071, disc_loss = 0.0002474274884830781
Trained batch 776 in epoch 15, gen_loss = 0.9061849503136663, disc_loss = 0.00024721223122408514
Trained batch 777 in epoch 15, gen_loss = 0.9060559953852607, disc_loss = 0.0002469891417751527
Trained batch 778 in epoch 15, gen_loss = 0.9061921780620521, disc_loss = 0.00024677428340841805
Trained batch 779 in epoch 15, gen_loss = 0.906206449942711, disc_loss = 0.0002465196328324591
Trained batch 780 in epoch 15, gen_loss = 0.9060677099930035, disc_loss = 0.0002462934654442073
Trained batch 781 in epoch 15, gen_loss = 0.9061954199048259, disc_loss = 0.00024621655306280286
Trained batch 782 in epoch 15, gen_loss = 0.9061279926415756, disc_loss = 0.0002462941677620534
Trained batch 783 in epoch 15, gen_loss = 0.9061712456905112, disc_loss = 0.0002461425587384559
Trained batch 784 in epoch 15, gen_loss = 0.9061777735212047, disc_loss = 0.0002460508131610072
Trained batch 785 in epoch 15, gen_loss = 0.9062386081570584, disc_loss = 0.00024579901558842627
Trained batch 786 in epoch 15, gen_loss = 0.9061176751135568, disc_loss = 0.0002457622428481015
Trained batch 787 in epoch 15, gen_loss = 0.9062582174230953, disc_loss = 0.00024572262893879116
Trained batch 788 in epoch 15, gen_loss = 0.906157172526999, disc_loss = 0.0002455450397172054
Trained batch 789 in epoch 15, gen_loss = 0.9062179969835885, disc_loss = 0.00024534451197412844
Trained batch 790 in epoch 15, gen_loss = 0.9062314814170905, disc_loss = 0.00024519084237906527
Trained batch 791 in epoch 15, gen_loss = 0.9061021514312185, disc_loss = 0.0002450017318827149
Trained batch 792 in epoch 15, gen_loss = 0.9061491030913132, disc_loss = 0.00024481040534159946
Trained batch 793 in epoch 15, gen_loss = 0.9060474581622356, disc_loss = 0.00024471023620762543
Trained batch 794 in epoch 15, gen_loss = 0.9060731348751476, disc_loss = 0.0002445715684011731
Trained batch 795 in epoch 15, gen_loss = 0.9060566761535616, disc_loss = 0.00024442052851175424
Trained batch 796 in epoch 15, gen_loss = 0.9060057603579992, disc_loss = 0.000244246675313957
Trained batch 797 in epoch 15, gen_loss = 0.9058133072422859, disc_loss = 0.00024407000750042719
Trained batch 798 in epoch 15, gen_loss = 0.905771518156436, disc_loss = 0.000243979157085221
Trained batch 799 in epoch 15, gen_loss = 0.9059772757440805, disc_loss = 0.00024386870273701789
Trained batch 800 in epoch 15, gen_loss = 0.9060655867264661, disc_loss = 0.0002436827055223492
Trained batch 801 in epoch 15, gen_loss = 0.9060921100458302, disc_loss = 0.0002434734742020279
Trained batch 802 in epoch 15, gen_loss = 0.9060743491201294, disc_loss = 0.00024329558465417282
Trained batch 803 in epoch 15, gen_loss = 0.9059483572766556, disc_loss = 0.00024344466657738898
Trained batch 804 in epoch 15, gen_loss = 0.9058753058777093, disc_loss = 0.0002435160935216479
Trained batch 805 in epoch 15, gen_loss = 0.9059099887056327, disc_loss = 0.00024333483248194517
Trained batch 806 in epoch 15, gen_loss = 0.9058298531370388, disc_loss = 0.00024308435529041424
Trained batch 807 in epoch 15, gen_loss = 0.9058929730464916, disc_loss = 0.0002428931640211111
Trained batch 808 in epoch 15, gen_loss = 0.9059614111083399, disc_loss = 0.00024270330884117443
Trained batch 809 in epoch 15, gen_loss = 0.9058482894191036, disc_loss = 0.00024250037687899615
Trained batch 810 in epoch 15, gen_loss = 0.9057521038078938, disc_loss = 0.00024228291593757017
Trained batch 811 in epoch 15, gen_loss = 0.9057509065995663, disc_loss = 0.00024211073195608504
Trained batch 812 in epoch 15, gen_loss = 0.9056497736024094, disc_loss = 0.00024187925715872337
Trained batch 813 in epoch 15, gen_loss = 0.9057322393471251, disc_loss = 0.0002417382108793006
Trained batch 814 in epoch 15, gen_loss = 0.9056144350876837, disc_loss = 0.00024154905402644372
Trained batch 815 in epoch 15, gen_loss = 0.9057592547261247, disc_loss = 0.00024148141771244505
Trained batch 816 in epoch 15, gen_loss = 0.9057279103680661, disc_loss = 0.000241539145736058
Trained batch 817 in epoch 15, gen_loss = 0.905813054452607, disc_loss = 0.00024146465176541683
Trained batch 818 in epoch 15, gen_loss = 0.9059766109609778, disc_loss = 0.000241246991679604
Trained batch 819 in epoch 15, gen_loss = 0.9060145006674092, disc_loss = 0.00024118068848598872
Trained batch 820 in epoch 15, gen_loss = 0.9060781387550967, disc_loss = 0.00024102431696001043
Trained batch 821 in epoch 15, gen_loss = 0.9059550478655637, disc_loss = 0.0002408172971839646
Trained batch 822 in epoch 15, gen_loss = 0.9060419291656189, disc_loss = 0.0002406939449720792
Trained batch 823 in epoch 15, gen_loss = 0.905921311560765, disc_loss = 0.00024056412078528067
Trained batch 824 in epoch 15, gen_loss = 0.9057858326940825, disc_loss = 0.00024037258642210598
Trained batch 825 in epoch 15, gen_loss = 0.9058624977926942, disc_loss = 0.00024017289283498783
Trained batch 826 in epoch 15, gen_loss = 0.9058666958630157, disc_loss = 0.00024016996741575271
Trained batch 827 in epoch 15, gen_loss = 0.9057866183743961, disc_loss = 0.00023999854776142772
Trained batch 828 in epoch 15, gen_loss = 0.9057912009760324, disc_loss = 0.00023984087987303558
Trained batch 829 in epoch 15, gen_loss = 0.9056355202772531, disc_loss = 0.00023972898536201858
Trained batch 830 in epoch 15, gen_loss = 0.9056116810917998, disc_loss = 0.00023951235301062048
Trained batch 831 in epoch 15, gen_loss = 0.9055208006443886, disc_loss = 0.00023935455294139712
Trained batch 832 in epoch 15, gen_loss = 0.9055900901448684, disc_loss = 0.00023924611074786935
Trained batch 833 in epoch 15, gen_loss = 0.9054990889643022, disc_loss = 0.00023912510915542255
Trained batch 834 in epoch 15, gen_loss = 0.9054171126759695, disc_loss = 0.0002389929181741743
Trained batch 835 in epoch 15, gen_loss = 0.9053409382629622, disc_loss = 0.00023881274302166015
Trained batch 836 in epoch 15, gen_loss = 0.9054284604931675, disc_loss = 0.00023865097280961834
Trained batch 837 in epoch 15, gen_loss = 0.9052387823068441, disc_loss = 0.0002385825789821468
Trained batch 838 in epoch 15, gen_loss = 0.9052554238254606, disc_loss = 0.00023843992309720716
Trained batch 839 in epoch 15, gen_loss = 0.9052186758745284, disc_loss = 0.00023838844137052156
Trained batch 840 in epoch 15, gen_loss = 0.9051142232171421, disc_loss = 0.00023823744882157434
Trained batch 841 in epoch 15, gen_loss = 0.9052060521838218, disc_loss = 0.00023810432757577398
Trained batch 842 in epoch 15, gen_loss = 0.9052855286875371, disc_loss = 0.00023790990092440438
Trained batch 843 in epoch 15, gen_loss = 0.9054172437337903, disc_loss = 0.0002377381075236169
Trained batch 844 in epoch 15, gen_loss = 0.9053226371488627, disc_loss = 0.00023756672082914551
Trained batch 845 in epoch 15, gen_loss = 0.9053575598038116, disc_loss = 0.0002373672592365659
Trained batch 846 in epoch 15, gen_loss = 0.9053114034068345, disc_loss = 0.00023719021790678647
Trained batch 847 in epoch 15, gen_loss = 0.9052922031227147, disc_loss = 0.0002369750481716866
Trained batch 848 in epoch 15, gen_loss = 0.9051052416171286, disc_loss = 0.0002368796191573375
Trained batch 849 in epoch 15, gen_loss = 0.9050768849428962, disc_loss = 0.00023668494462018475
Trained batch 850 in epoch 15, gen_loss = 0.9051176253553003, disc_loss = 0.00023656029049393975
Trained batch 851 in epoch 15, gen_loss = 0.9051378352541319, disc_loss = 0.0002364193846509798
Trained batch 852 in epoch 15, gen_loss = 0.9049587110002882, disc_loss = 0.0002362343897027439
Trained batch 853 in epoch 15, gen_loss = 0.9049059001846671, disc_loss = 0.00023604858438854473
Trained batch 854 in epoch 15, gen_loss = 0.9048730348983006, disc_loss = 0.0002358509242142842
Trained batch 855 in epoch 15, gen_loss = 0.9046370908617973, disc_loss = 0.00023779491891992135
Trained batch 856 in epoch 15, gen_loss = 0.9045596954563813, disc_loss = 0.00023873368313685064
Trained batch 857 in epoch 15, gen_loss = 0.9045650080923155, disc_loss = 0.00023914256919773609
Trained batch 858 in epoch 15, gen_loss = 0.904696047514226, disc_loss = 0.00023946633253670602
Trained batch 859 in epoch 15, gen_loss = 0.9045735628105873, disc_loss = 0.00024002980081541165
Trained batch 860 in epoch 15, gen_loss = 0.9046217833800322, disc_loss = 0.00024005443941665632
Trained batch 861 in epoch 15, gen_loss = 0.9047685086450554, disc_loss = 0.00023995061674382317
Trained batch 862 in epoch 15, gen_loss = 0.9047975873063089, disc_loss = 0.0002402279219384883
Trained batch 863 in epoch 15, gen_loss = 0.9048872579027105, disc_loss = 0.00024026357775036795
Trained batch 864 in epoch 15, gen_loss = 0.9048142313268144, disc_loss = 0.00024019485113505043
Trained batch 865 in epoch 15, gen_loss = 0.9047257562294844, disc_loss = 0.0002401800566685548
Trained batch 866 in epoch 15, gen_loss = 0.9046947885274612, disc_loss = 0.0002400204675293121
Trained batch 867 in epoch 15, gen_loss = 0.9046198162615025, disc_loss = 0.00023981547002318614
Trained batch 868 in epoch 15, gen_loss = 0.9046173112850606, disc_loss = 0.00023972801605009225
Trained batch 869 in epoch 15, gen_loss = 0.9047033285957643, disc_loss = 0.0002395596329817594
Trained batch 870 in epoch 15, gen_loss = 0.9047502782944287, disc_loss = 0.00023936682681080054
Trained batch 871 in epoch 15, gen_loss = 0.9047051980544668, disc_loss = 0.00023915706709668909
Trained batch 872 in epoch 15, gen_loss = 0.9045941928681093, disc_loss = 0.00023903584745073826
Trained batch 873 in epoch 15, gen_loss = 0.9048213411114036, disc_loss = 0.00023909293447502088
Trained batch 874 in epoch 15, gen_loss = 0.904831313610077, disc_loss = 0.00023889446109699616
Trained batch 875 in epoch 15, gen_loss = 0.9047956225126301, disc_loss = 0.00023870502976534812
Trained batch 876 in epoch 15, gen_loss = 0.9048245318803168, disc_loss = 0.0002386273567069921
Trained batch 877 in epoch 15, gen_loss = 0.9048657682056036, disc_loss = 0.0002386577206357236
Trained batch 878 in epoch 15, gen_loss = 0.9047504205752558, disc_loss = 0.00023849371959618477
Trained batch 879 in epoch 15, gen_loss = 0.904672911492261, disc_loss = 0.00023834666335460498
Trained batch 880 in epoch 15, gen_loss = 0.9046155514024308, disc_loss = 0.00023817881288462257
Trained batch 881 in epoch 15, gen_loss = 0.9045501612211301, disc_loss = 0.00023798171746513655
Trained batch 882 in epoch 15, gen_loss = 0.9044844846358251, disc_loss = 0.0002377972315782908
Trained batch 883 in epoch 15, gen_loss = 0.9044781234199645, disc_loss = 0.00023762916077113536
Trained batch 884 in epoch 15, gen_loss = 0.9045286851414179, disc_loss = 0.00023743912009857753
Trained batch 885 in epoch 15, gen_loss = 0.9045808619354971, disc_loss = 0.00023723772791779676
Trained batch 886 in epoch 15, gen_loss = 0.9046144914197007, disc_loss = 0.0002370446250030654
Trained batch 887 in epoch 15, gen_loss = 0.9046484303769765, disc_loss = 0.00023685806130382484
Trained batch 888 in epoch 15, gen_loss = 0.9047409627917647, disc_loss = 0.00023678558209294342
Trained batch 889 in epoch 15, gen_loss = 0.9048160657454073, disc_loss = 0.00023673144242320122
Trained batch 890 in epoch 15, gen_loss = 0.9047813386092951, disc_loss = 0.00023654999327176254
Trained batch 891 in epoch 15, gen_loss = 0.9048717357385319, disc_loss = 0.0002363664440633121
Trained batch 892 in epoch 15, gen_loss = 0.9048692600056947, disc_loss = 0.0002361624264178841
Trained batch 893 in epoch 15, gen_loss = 0.904938167840309, disc_loss = 0.00023600117000624235
Trained batch 894 in epoch 15, gen_loss = 0.9049280846585108, disc_loss = 0.0002358736326326499
Trained batch 895 in epoch 15, gen_loss = 0.9048647295816669, disc_loss = 0.0002357139984375018
Trained batch 896 in epoch 15, gen_loss = 0.9049448917143321, disc_loss = 0.00023558231551013134
Trained batch 897 in epoch 15, gen_loss = 0.9048484264476793, disc_loss = 0.0002354332339590613
Trained batch 898 in epoch 15, gen_loss = 0.9047656511438305, disc_loss = 0.00023532397363680514
Trained batch 899 in epoch 15, gen_loss = 0.9045417065090603, disc_loss = 0.00023542819363986685
Trained batch 900 in epoch 15, gen_loss = 0.9045506524589827, disc_loss = 0.00023533174166777976
Trained batch 901 in epoch 15, gen_loss = 0.9045700427566029, disc_loss = 0.00023533336760801085
Trained batch 902 in epoch 15, gen_loss = 0.9043870183452551, disc_loss = 0.00023520006230876446
Trained batch 903 in epoch 15, gen_loss = 0.9043224497442752, disc_loss = 0.00023499464491860393
Trained batch 904 in epoch 15, gen_loss = 0.9041555465255653, disc_loss = 0.00023482534650520894
Trained batch 905 in epoch 15, gen_loss = 0.904203470705887, disc_loss = 0.00023476235028544557
Trained batch 906 in epoch 15, gen_loss = 0.9041609225225816, disc_loss = 0.000234629623199303
Trained batch 907 in epoch 15, gen_loss = 0.9041397826261982, disc_loss = 0.0002345015326029114
Trained batch 908 in epoch 15, gen_loss = 0.9041398277114852, disc_loss = 0.00023449197107227647
Trained batch 909 in epoch 15, gen_loss = 0.9040861610527877, disc_loss = 0.0002343120581876924
Trained batch 910 in epoch 15, gen_loss = 0.9040389036765868, disc_loss = 0.0002341485302331441
Trained batch 911 in epoch 15, gen_loss = 0.9040269649734622, disc_loss = 0.0002340080353772927
Trained batch 912 in epoch 15, gen_loss = 0.9040391052147906, disc_loss = 0.00023402533504248316
Trained batch 913 in epoch 15, gen_loss = 0.9039590901305952, disc_loss = 0.0002339410907801287
Trained batch 914 in epoch 15, gen_loss = 0.9039489245805584, disc_loss = 0.00023384740155255753
Trained batch 915 in epoch 15, gen_loss = 0.9038686400938243, disc_loss = 0.00023369838806490314
Trained batch 916 in epoch 15, gen_loss = 0.9039156417420282, disc_loss = 0.00023357366924184922
Trained batch 917 in epoch 15, gen_loss = 0.903833692175111, disc_loss = 0.0002334031282721784
Trained batch 918 in epoch 15, gen_loss = 0.9037942766364951, disc_loss = 0.0002332449940528117
Trained batch 919 in epoch 15, gen_loss = 0.9037739269111468, disc_loss = 0.00023310965686070394
Trained batch 920 in epoch 15, gen_loss = 0.9037722417120048, disc_loss = 0.00023292635299468765
Trained batch 921 in epoch 15, gen_loss = 0.9037480843687782, disc_loss = 0.00023274292546251072
Trained batch 922 in epoch 15, gen_loss = 0.9036905079079087, disc_loss = 0.00023255927152567813
Trained batch 923 in epoch 15, gen_loss = 0.9037346576715445, disc_loss = 0.00023245109640775843
Trained batch 924 in epoch 15, gen_loss = 0.9037883583275047, disc_loss = 0.00023243982470326906
Trained batch 925 in epoch 15, gen_loss = 0.9038005838126395, disc_loss = 0.00023230401061570947
Trained batch 926 in epoch 15, gen_loss = 0.9037520799307633, disc_loss = 0.00023214337356105883
Trained batch 927 in epoch 15, gen_loss = 0.9035557620227337, disc_loss = 0.00023208475908694678
Trained batch 928 in epoch 15, gen_loss = 0.9034816033103623, disc_loss = 0.00023277567526260045
Trained batch 929 in epoch 15, gen_loss = 0.9035190530361668, disc_loss = 0.00023335009965164992
Trained batch 930 in epoch 15, gen_loss = 0.9034731392573593, disc_loss = 0.000233469534288872
Trained batch 931 in epoch 15, gen_loss = 0.9035881217329287, disc_loss = 0.00023363747850102057
Trained batch 932 in epoch 15, gen_loss = 0.9036028612592724, disc_loss = 0.00023366195414757974
Trained batch 933 in epoch 15, gen_loss = 0.9036763378077962, disc_loss = 0.0002336420749970804
Trained batch 934 in epoch 15, gen_loss = 0.9039534044775733, disc_loss = 0.00023381661510180288
Trained batch 935 in epoch 15, gen_loss = 0.9039043007880194, disc_loss = 0.0002339462325019271
Trained batch 936 in epoch 15, gen_loss = 0.903947099804751, disc_loss = 0.00023385533888374153
Trained batch 937 in epoch 15, gen_loss = 0.9038727291738555, disc_loss = 0.000233702399123152
Trained batch 938 in epoch 15, gen_loss = 0.9037575305333406, disc_loss = 0.00023360308181232014
Trained batch 939 in epoch 15, gen_loss = 0.9037143537338744, disc_loss = 0.00023346198530371692
Trained batch 940 in epoch 15, gen_loss = 0.9037385309920681, disc_loss = 0.00023329232007857808
Trained batch 941 in epoch 15, gen_loss = 0.9038386878947037, disc_loss = 0.0002333129209845617
Trained batch 942 in epoch 15, gen_loss = 0.9037605115110775, disc_loss = 0.00023359905994096143
Trained batch 943 in epoch 15, gen_loss = 0.9038581613261821, disc_loss = 0.00023382904024108907
Trained batch 944 in epoch 15, gen_loss = 0.9039036444255284, disc_loss = 0.00023396553977305764
Trained batch 945 in epoch 15, gen_loss = 0.9039518327844067, disc_loss = 0.00023406381154135456
Trained batch 946 in epoch 15, gen_loss = 0.9040084508933135, disc_loss = 0.00023399084724493618
Trained batch 947 in epoch 15, gen_loss = 0.9039857110896694, disc_loss = 0.0002341117888481446
Trained batch 948 in epoch 15, gen_loss = 0.9042981413317681, disc_loss = 0.0002349308097751424
Trained batch 949 in epoch 15, gen_loss = 0.9041979564491072, disc_loss = 0.00023519175976903888
Trained batch 950 in epoch 15, gen_loss = 0.9042570744528504, disc_loss = 0.00023507622047459054
Trained batch 951 in epoch 15, gen_loss = 0.90430467175085, disc_loss = 0.00023514583074015603
Trained batch 952 in epoch 15, gen_loss = 0.9044549181854112, disc_loss = 0.0002351248246848919
Trained batch 953 in epoch 15, gen_loss = 0.9044463641988406, disc_loss = 0.00023501708370909086
Trained batch 954 in epoch 15, gen_loss = 0.9044015858185853, disc_loss = 0.00023488522601647287
Trained batch 955 in epoch 15, gen_loss = 0.9044230744928495, disc_loss = 0.0002347766790518264
Trained batch 956 in epoch 15, gen_loss = 0.9044849264086102, disc_loss = 0.00023468246843914362
Trained batch 957 in epoch 15, gen_loss = 0.9044644997488233, disc_loss = 0.0002345310010178861
Trained batch 958 in epoch 15, gen_loss = 0.904449060636964, disc_loss = 0.00023434652438300723
Trained batch 959 in epoch 15, gen_loss = 0.9043731870750586, disc_loss = 0.00023428332974238705
Trained batch 960 in epoch 15, gen_loss = 0.9043050289898336, disc_loss = 0.0002341704897878536
Trained batch 961 in epoch 15, gen_loss = 0.9044323977462467, disc_loss = 0.00023404861910843118
Trained batch 962 in epoch 15, gen_loss = 0.9045962793433406, disc_loss = 0.0002339614530359378
Trained batch 963 in epoch 15, gen_loss = 0.9045621157929116, disc_loss = 0.00023394542463525092
Trained batch 964 in epoch 15, gen_loss = 0.9046085622026513, disc_loss = 0.0002338834105979668
Trained batch 965 in epoch 15, gen_loss = 0.9046299034270687, disc_loss = 0.00023372701042289937
Trained batch 966 in epoch 15, gen_loss = 0.9047929933670265, disc_loss = 0.0002335959970041247
Trained batch 967 in epoch 15, gen_loss = 0.904807144822168, disc_loss = 0.00023343979742733136
Trained batch 968 in epoch 15, gen_loss = 0.9047856104509258, disc_loss = 0.00023326370006483514
Trained batch 969 in epoch 15, gen_loss = 0.9047334323838814, disc_loss = 0.00023312478990623482
Trained batch 970 in epoch 15, gen_loss = 0.9049079354956024, disc_loss = 0.00023324479153967868
Trained batch 971 in epoch 15, gen_loss = 0.9050390821548155, disc_loss = 0.00023355436221691767
Trained batch 972 in epoch 15, gen_loss = 0.9049179711420269, disc_loss = 0.00023359914880104383
Trained batch 973 in epoch 15, gen_loss = 0.9048730775071365, disc_loss = 0.00023344575849283908
Trained batch 974 in epoch 15, gen_loss = 0.9047536106598683, disc_loss = 0.0002332892619970386
Trained batch 975 in epoch 15, gen_loss = 0.9048006400221684, disc_loss = 0.00023315450801151126
Trained batch 976 in epoch 15, gen_loss = 0.9046681519052512, disc_loss = 0.0002330930392203832
Trained batch 977 in epoch 15, gen_loss = 0.9046973756120249, disc_loss = 0.0002331073665229905
Trained batch 978 in epoch 15, gen_loss = 0.9047330005419754, disc_loss = 0.00023295816229882866
Trained batch 979 in epoch 15, gen_loss = 0.9047447877879046, disc_loss = 0.00023279642519272024
Trained batch 980 in epoch 15, gen_loss = 0.9048132737234584, disc_loss = 0.00023262448304026744
Trained batch 981 in epoch 15, gen_loss = 0.9047171925090238, disc_loss = 0.00023246220630176187
Trained batch 982 in epoch 15, gen_loss = 0.9045971459192759, disc_loss = 0.00023230085532923632
Trained batch 983 in epoch 15, gen_loss = 0.9046102513869604, disc_loss = 0.00023212243400863608
Trained batch 984 in epoch 15, gen_loss = 0.9045894349287004, disc_loss = 0.0002319432913568308
Trained batch 985 in epoch 15, gen_loss = 0.9045725326992677, disc_loss = 0.00023177106633174218
Trained batch 986 in epoch 15, gen_loss = 0.9045777239939604, disc_loss = 0.0002316090621462216
Trained batch 987 in epoch 15, gen_loss = 0.9045673786145956, disc_loss = 0.0002314285263129586
Trained batch 988 in epoch 15, gen_loss = 0.9044964352078336, disc_loss = 0.00023127525956459985
Trained batch 989 in epoch 15, gen_loss = 0.9045369948401596, disc_loss = 0.00023113732683549359
Trained batch 990 in epoch 15, gen_loss = 0.9045140977824853, disc_loss = 0.00023106807971644679
Trained batch 991 in epoch 15, gen_loss = 0.9046126699015018, disc_loss = 0.0002309505186729204
Trained batch 992 in epoch 15, gen_loss = 0.9045389436883149, disc_loss = 0.0002307825312932542
Trained batch 993 in epoch 15, gen_loss = 0.9043975637952086, disc_loss = 0.00023069783021944552
Trained batch 994 in epoch 15, gen_loss = 0.9044696672477914, disc_loss = 0.0002305855824758039
Trained batch 995 in epoch 15, gen_loss = 0.9045283447906195, disc_loss = 0.00023040573925543021
Trained batch 996 in epoch 15, gen_loss = 0.9043985552032111, disc_loss = 0.00023033236766924943
Trained batch 997 in epoch 15, gen_loss = 0.9043685519743061, disc_loss = 0.00023019524281723766
Trained batch 998 in epoch 15, gen_loss = 0.9042787931941532, disc_loss = 0.00023004126205204966
Trained batch 999 in epoch 15, gen_loss = 0.904168937087059, disc_loss = 0.00022991343264948229
Trained batch 1000 in epoch 15, gen_loss = 0.904167744722757, disc_loss = 0.00022973830939143093
Trained batch 1001 in epoch 15, gen_loss = 0.9041347651781436, disc_loss = 0.00022961412419780192
Trained batch 1002 in epoch 15, gen_loss = 0.9041117847500627, disc_loss = 0.00022946463964911083
Trained batch 1003 in epoch 15, gen_loss = 0.9040180840696471, disc_loss = 0.00022939968671217427
Trained batch 1004 in epoch 15, gen_loss = 0.9040214344636718, disc_loss = 0.00022925244521497938
Trained batch 1005 in epoch 15, gen_loss = 0.9041113477222488, disc_loss = 0.00022908097775827164
Trained batch 1006 in epoch 15, gen_loss = 0.9040410389611359, disc_loss = 0.00022892029468775792
Trained batch 1007 in epoch 15, gen_loss = 0.9039383344352245, disc_loss = 0.00022877643358957096
Trained batch 1008 in epoch 15, gen_loss = 0.9037744588965348, disc_loss = 0.000228653544759475
Trained batch 1009 in epoch 15, gen_loss = 0.9037895903138831, disc_loss = 0.0002284938841791637
Trained batch 1010 in epoch 15, gen_loss = 0.9037720092915875, disc_loss = 0.0002283703050522664
Trained batch 1011 in epoch 15, gen_loss = 0.9037777218422871, disc_loss = 0.00022822957390622193
Trained batch 1012 in epoch 15, gen_loss = 0.9037634422607271, disc_loss = 0.00022811010991657444
Trained batch 1013 in epoch 15, gen_loss = 0.9037542495384254, disc_loss = 0.00022798388364195666
Trained batch 1014 in epoch 15, gen_loss = 0.9037561963931681, disc_loss = 0.00022782636808877778
Trained batch 1015 in epoch 15, gen_loss = 0.9038719897429774, disc_loss = 0.00022771591672758726
Trained batch 1016 in epoch 15, gen_loss = 0.903992776556587, disc_loss = 0.00022761661347589363
Trained batch 1017 in epoch 15, gen_loss = 0.904039506476614, disc_loss = 0.0002274799860645031
Trained batch 1018 in epoch 15, gen_loss = 0.9041661300181875, disc_loss = 0.0002273495290211621
Trained batch 1019 in epoch 15, gen_loss = 0.9040564493221395, disc_loss = 0.00022720776464577248
Trained batch 1020 in epoch 15, gen_loss = 0.9040479034798385, disc_loss = 0.00022721771683461713
Trained batch 1021 in epoch 15, gen_loss = 0.9040474075743831, disc_loss = 0.000227193851414479
Trained batch 1022 in epoch 15, gen_loss = 0.9040492841225566, disc_loss = 0.00022707285637752096
Trained batch 1023 in epoch 15, gen_loss = 0.9041029424406588, disc_loss = 0.00022697630997825513
Trained batch 1024 in epoch 15, gen_loss = 0.9040829779462116, disc_loss = 0.00022686971258868962
Trained batch 1025 in epoch 15, gen_loss = 0.9039963159644813, disc_loss = 0.0002269814653132557
Trained batch 1026 in epoch 15, gen_loss = 0.903949873124729, disc_loss = 0.0002268953474257275
Trained batch 1027 in epoch 15, gen_loss = 0.9039024199261275, disc_loss = 0.00022677003764845808
Trained batch 1028 in epoch 15, gen_loss = 0.9038259270587399, disc_loss = 0.0002266550704143501
Trained batch 1029 in epoch 15, gen_loss = 0.9038604780886937, disc_loss = 0.00022650967275871311
Trained batch 1030 in epoch 15, gen_loss = 0.9037734614658078, disc_loss = 0.0002263339043851609
Trained batch 1031 in epoch 15, gen_loss = 0.9037067135290582, disc_loss = 0.000226166594318276
Trained batch 1032 in epoch 15, gen_loss = 0.9036720759755529, disc_loss = 0.0002260579264189767
Trained batch 1033 in epoch 15, gen_loss = 0.9036385993431799, disc_loss = 0.0002259055404386308
Trained batch 1034 in epoch 15, gen_loss = 0.9035940983445172, disc_loss = 0.000225773632753745
Trained batch 1035 in epoch 15, gen_loss = 0.903465071642721, disc_loss = 0.00022567523888467463
Trained batch 1036 in epoch 15, gen_loss = 0.9034404560363166, disc_loss = 0.00022569968129846442
Trained batch 1037 in epoch 15, gen_loss = 0.903381599282024, disc_loss = 0.00022569381258678007
Trained batch 1038 in epoch 15, gen_loss = 0.9033282235680691, disc_loss = 0.00022554499913154136
Trained batch 1039 in epoch 15, gen_loss = 0.9032583712385251, disc_loss = 0.0002255339588408298
Trained batch 1040 in epoch 15, gen_loss = 0.903195304955346, disc_loss = 0.0002254132975659619
Trained batch 1041 in epoch 15, gen_loss = 0.903110129075865, disc_loss = 0.00022538634242133873
Trained batch 1042 in epoch 15, gen_loss = 0.9032025809827495, disc_loss = 0.00022532144652279197
Trained batch 1043 in epoch 15, gen_loss = 0.9032197493588787, disc_loss = 0.00022517086134002373
Trained batch 1044 in epoch 15, gen_loss = 0.9032195152278152, disc_loss = 0.0002250346745082799
Trained batch 1045 in epoch 15, gen_loss = 0.9031887540511829, disc_loss = 0.00022491261671499476
Trained batch 1046 in epoch 15, gen_loss = 0.9031449912156849, disc_loss = 0.000224822227454193
Trained batch 1047 in epoch 15, gen_loss = 0.903089088508646, disc_loss = 0.0002247491921993865
Trained batch 1048 in epoch 15, gen_loss = 0.9030366993382275, disc_loss = 0.0002246659673008017
Trained batch 1049 in epoch 15, gen_loss = 0.9030827404203869, disc_loss = 0.00022454752297476044
Trained batch 1050 in epoch 15, gen_loss = 0.9030522321883436, disc_loss = 0.00022441067146404856
Trained batch 1051 in epoch 15, gen_loss = 0.9030567983824037, disc_loss = 0.0002242717589377574
Trained batch 1052 in epoch 15, gen_loss = 0.9030169606888057, disc_loss = 0.00022415366502665448
Trained batch 1053 in epoch 15, gen_loss = 0.9030158321251227, disc_loss = 0.00022402861227928744
Trained batch 1054 in epoch 15, gen_loss = 0.9030046603125983, disc_loss = 0.00022391917252478905
Trained batch 1055 in epoch 15, gen_loss = 0.9029881551748875, disc_loss = 0.0002237610502823262
Trained batch 1056 in epoch 15, gen_loss = 0.9029459325683038, disc_loss = 0.00022368842238533224
Trained batch 1057 in epoch 15, gen_loss = 0.9030293146806764, disc_loss = 0.0002236128792074612
Trained batch 1058 in epoch 15, gen_loss = 0.9029744410424777, disc_loss = 0.0002234899480759546
Trained batch 1059 in epoch 15, gen_loss = 0.9029615813268805, disc_loss = 0.00022345382920252202
Trained batch 1060 in epoch 15, gen_loss = 0.9029290624995147, disc_loss = 0.0002233843512380075
Trained batch 1061 in epoch 15, gen_loss = 0.9029561303092934, disc_loss = 0.00022326925078547461
Trained batch 1062 in epoch 15, gen_loss = 0.9028652725865677, disc_loss = 0.00022333315397996713
Trained batch 1063 in epoch 15, gen_loss = 0.9027942007869706, disc_loss = 0.0002233507647176332
Trained batch 1064 in epoch 15, gen_loss = 0.9027531724580576, disc_loss = 0.00022321661084779963
Trained batch 1065 in epoch 15, gen_loss = 0.9028373550183331, disc_loss = 0.00022322243438918085
Trained batch 1066 in epoch 15, gen_loss = 0.9028444077885922, disc_loss = 0.00022316814804136109
Trained batch 1067 in epoch 15, gen_loss = 0.9028971982136201, disc_loss = 0.00022304935951256987
Trained batch 1068 in epoch 15, gen_loss = 0.9029682124185161, disc_loss = 0.00022293489639657325
Trained batch 1069 in epoch 15, gen_loss = 0.9029161798619778, disc_loss = 0.0002228588836047816
Trained batch 1070 in epoch 15, gen_loss = 0.9029242356284326, disc_loss = 0.0002227727045286812
Trained batch 1071 in epoch 15, gen_loss = 0.9029902694051835, disc_loss = 0.0002226437771296061
Trained batch 1072 in epoch 15, gen_loss = 0.9030076989700944, disc_loss = 0.00022255078395125557
Trained batch 1073 in epoch 15, gen_loss = 0.9030127540868976, disc_loss = 0.00022250551708336152
Trained batch 1074 in epoch 15, gen_loss = 0.9030230570948401, disc_loss = 0.0002224090840900317
Trained batch 1075 in epoch 15, gen_loss = 0.9030787307755211, disc_loss = 0.00022230100422452999
Trained batch 1076 in epoch 15, gen_loss = 0.9031042960250167, disc_loss = 0.00022216987685981824
Trained batch 1077 in epoch 15, gen_loss = 0.903112147812056, disc_loss = 0.0002220460298602471
Trained batch 1078 in epoch 15, gen_loss = 0.9031013738125756, disc_loss = 0.00022191656798465682
Trained batch 1079 in epoch 15, gen_loss = 0.9030906971957948, disc_loss = 0.0002217694833975488
Trained batch 1080 in epoch 15, gen_loss = 0.9030143256324182, disc_loss = 0.00022164446982077154
Trained batch 1081 in epoch 15, gen_loss = 0.9030134033914414, disc_loss = 0.00022156182211080725
Trained batch 1082 in epoch 15, gen_loss = 0.9030073866289409, disc_loss = 0.00022152791329329948
Trained batch 1083 in epoch 15, gen_loss = 0.9029282079081694, disc_loss = 0.00022154475726560746
Trained batch 1084 in epoch 15, gen_loss = 0.9029056695199782, disc_loss = 0.00022142234222543927
Trained batch 1085 in epoch 15, gen_loss = 0.9029948002835444, disc_loss = 0.0002213790890627046
Trained batch 1086 in epoch 15, gen_loss = 0.902900158481633, disc_loss = 0.0002213513110340753
Trained batch 1087 in epoch 15, gen_loss = 0.9030263485825237, disc_loss = 0.00022128285280252706
Trained batch 1088 in epoch 15, gen_loss = 0.9030825275144411, disc_loss = 0.0002212732344829132
Trained batch 1089 in epoch 15, gen_loss = 0.9030347844876281, disc_loss = 0.00022116530794888487
Trained batch 1090 in epoch 15, gen_loss = 0.9030900256115837, disc_loss = 0.00022106060219398725
Trained batch 1091 in epoch 15, gen_loss = 0.9030716512011084, disc_loss = 0.0002210904102344019
Trained batch 1092 in epoch 15, gen_loss = 0.9030251708035063, disc_loss = 0.0002210441104429629
Trained batch 1093 in epoch 15, gen_loss = 0.9029686093548316, disc_loss = 0.00022089722920873184
Trained batch 1094 in epoch 15, gen_loss = 0.9028455925858728, disc_loss = 0.0002208300104171259
Trained batch 1095 in epoch 15, gen_loss = 0.9029164516577756, disc_loss = 0.00022085721606225536
Trained batch 1096 in epoch 15, gen_loss = 0.9029918509172981, disc_loss = 0.0002208244894771712
Trained batch 1097 in epoch 15, gen_loss = 0.9029845424905718, disc_loss = 0.00022069020450459997
Trained batch 1098 in epoch 15, gen_loss = 0.902867621351525, disc_loss = 0.00022056125424542992
Trained batch 1099 in epoch 15, gen_loss = 0.9027561800046401, disc_loss = 0.00022048065993162294
Trained batch 1100 in epoch 15, gen_loss = 0.9026784389047163, disc_loss = 0.00022041912705127444
Trained batch 1101 in epoch 15, gen_loss = 0.9025784462095389, disc_loss = 0.00022028903821016326
Trained batch 1102 in epoch 15, gen_loss = 0.9025292444099433, disc_loss = 0.00022014829587990947
Trained batch 1103 in epoch 15, gen_loss = 0.9024536542162516, disc_loss = 0.00022000621894498497
Trained batch 1104 in epoch 15, gen_loss = 0.9024131069895369, disc_loss = 0.00021987221194789386
Trained batch 1105 in epoch 15, gen_loss = 0.9023826082942714, disc_loss = 0.0002197488726530486
Trained batch 1106 in epoch 15, gen_loss = 0.9023105507512941, disc_loss = 0.00021964029590318453
Trained batch 1107 in epoch 15, gen_loss = 0.9023051994049162, disc_loss = 0.00021954391084344333
Trained batch 1108 in epoch 15, gen_loss = 0.9022899085170413, disc_loss = 0.00021953561962830958
Trained batch 1109 in epoch 15, gen_loss = 0.9022793006789577, disc_loss = 0.00021950424749635973
Trained batch 1110 in epoch 15, gen_loss = 0.9023050298892518, disc_loss = 0.00021936878578660465
Trained batch 1111 in epoch 15, gen_loss = 0.9022855515317093, disc_loss = 0.0002192141989568142
Trained batch 1112 in epoch 15, gen_loss = 0.9022125498410933, disc_loss = 0.0002190571666077486
Trained batch 1113 in epoch 15, gen_loss = 0.9020975502859968, disc_loss = 0.00021889588893155018
Trained batch 1114 in epoch 15, gen_loss = 0.902220110829101, disc_loss = 0.00021877573197368207
Trained batch 1115 in epoch 15, gen_loss = 0.9021427239354793, disc_loss = 0.00021865040613570973
Trained batch 1116 in epoch 15, gen_loss = 0.9020674349798512, disc_loss = 0.0002185418415070393
Trained batch 1117 in epoch 15, gen_loss = 0.9021268240667626, disc_loss = 0.00021841841800635464
Trained batch 1118 in epoch 15, gen_loss = 0.9021420788828873, disc_loss = 0.00021828496964961303
Trained batch 1119 in epoch 15, gen_loss = 0.9020293259194919, disc_loss = 0.000218159010799874
Trained batch 1120 in epoch 15, gen_loss = 0.9020577250156522, disc_loss = 0.0002180292923525279
Trained batch 1121 in epoch 15, gen_loss = 0.9019063485922448, disc_loss = 0.00021791730493877986
Trained batch 1122 in epoch 15, gen_loss = 0.9018694302490112, disc_loss = 0.00021777891318412466
Trained batch 1123 in epoch 15, gen_loss = 0.9018798786019939, disc_loss = 0.00021765475984955054
Trained batch 1124 in epoch 15, gen_loss = 0.9017822091314528, disc_loss = 0.000217506944237458
Trained batch 1125 in epoch 15, gen_loss = 0.9016774743530721, disc_loss = 0.0002173833713067733
Trained batch 1126 in epoch 15, gen_loss = 0.9016076939869688, disc_loss = 0.00021725623663323239
Trained batch 1127 in epoch 15, gen_loss = 0.9015463502377483, disc_loss = 0.0002171046057842851
Trained batch 1128 in epoch 15, gen_loss = 0.9016078999868212, disc_loss = 0.0002169898961891566
Trained batch 1129 in epoch 15, gen_loss = 0.9014946423273171, disc_loss = 0.00021686048579940044
Trained batch 1130 in epoch 15, gen_loss = 0.9014782012299454, disc_loss = 0.0002167434764852637
Trained batch 1131 in epoch 15, gen_loss = 0.9014294740378646, disc_loss = 0.00021661098580550347
Trained batch 1132 in epoch 15, gen_loss = 0.9014371271061876, disc_loss = 0.0002165206321726807
Trained batch 1133 in epoch 15, gen_loss = 0.9014343213046879, disc_loss = 0.00021644896276410574
Trained batch 1134 in epoch 15, gen_loss = 0.9014225289159934, disc_loss = 0.00021630248992979764
Trained batch 1135 in epoch 15, gen_loss = 0.901399451399773, disc_loss = 0.00021624100784553685
Trained batch 1136 in epoch 15, gen_loss = 0.9013664125347725, disc_loss = 0.00021617895170976428
Trained batch 1137 in epoch 15, gen_loss = 0.901292275774877, disc_loss = 0.00021607032953388129
Trained batch 1138 in epoch 15, gen_loss = 0.9012561377671018, disc_loss = 0.00021598363490849838
Trained batch 1139 in epoch 15, gen_loss = 0.901313280379563, disc_loss = 0.00021589884809305147
Trained batch 1140 in epoch 15, gen_loss = 0.9012758427288948, disc_loss = 0.00021580287581610661
Trained batch 1141 in epoch 15, gen_loss = 0.9011424991796396, disc_loss = 0.00021573570202570205
Trained batch 1142 in epoch 15, gen_loss = 0.9011249645488468, disc_loss = 0.00021569955613062215
Trained batch 1143 in epoch 15, gen_loss = 0.9010476628383557, disc_loss = 0.00021566346279357462
Trained batch 1144 in epoch 15, gen_loss = 0.9011614022817154, disc_loss = 0.0002156121393156799
Trained batch 1145 in epoch 15, gen_loss = 0.9011753674785088, disc_loss = 0.00021568247490093384
Trained batch 1146 in epoch 15, gen_loss = 0.901165609372213, disc_loss = 0.00021568355104720964
Trained batch 1147 in epoch 15, gen_loss = 0.9010957847592722, disc_loss = 0.00021559353253494044
Trained batch 1148 in epoch 15, gen_loss = 0.9011011811004087, disc_loss = 0.00021548924719390166
Trained batch 1149 in epoch 15, gen_loss = 0.9009875488799551, disc_loss = 0.00021537451739119285
Trained batch 1150 in epoch 15, gen_loss = 0.9009584355727162, disc_loss = 0.00021527933475323148
Trained batch 1151 in epoch 15, gen_loss = 0.9010109909706645, disc_loss = 0.00021516612412142422
Trained batch 1152 in epoch 15, gen_loss = 0.900960806805676, disc_loss = 0.00021505732408994105
Trained batch 1153 in epoch 15, gen_loss = 0.9008782276144474, disc_loss = 0.0002149096629968715
Trained batch 1154 in epoch 15, gen_loss = 0.900832070261885, disc_loss = 0.00021484114283351106
Trained batch 1155 in epoch 15, gen_loss = 0.9008628811081388, disc_loss = 0.00021475992891666597
Trained batch 1156 in epoch 15, gen_loss = 0.9008506346387707, disc_loss = 0.00021463344617314716
Trained batch 1157 in epoch 15, gen_loss = 0.9008594269579556, disc_loss = 0.0002145504461188092
Trained batch 1158 in epoch 15, gen_loss = 0.9008303102076928, disc_loss = 0.00021447010893237877
Trained batch 1159 in epoch 15, gen_loss = 0.9008613461050494, disc_loss = 0.0002143521089112318
Trained batch 1160 in epoch 15, gen_loss = 0.9008224005333624, disc_loss = 0.00021422627128995185
Trained batch 1161 in epoch 15, gen_loss = 0.9007284840802933, disc_loss = 0.00021415484545236652
Trained batch 1162 in epoch 15, gen_loss = 0.9006770642687305, disc_loss = 0.00021411018134629304
Trained batch 1163 in epoch 15, gen_loss = 0.9006812295450788, disc_loss = 0.00021409199090686122
Trained batch 1164 in epoch 15, gen_loss = 0.9007575539048649, disc_loss = 0.0002142115286376543
Trained batch 1165 in epoch 15, gen_loss = 0.9007573700278333, disc_loss = 0.00021420744135712257
Trained batch 1166 in epoch 15, gen_loss = 0.9006995607260057, disc_loss = 0.00021410794629301994
Trained batch 1167 in epoch 15, gen_loss = 0.9007245854359783, disc_loss = 0.00021398926803581846
Trained batch 1168 in epoch 15, gen_loss = 0.9007389523006077, disc_loss = 0.00021384870271801243
Trained batch 1169 in epoch 15, gen_loss = 0.9007406087512644, disc_loss = 0.00021374931912627928
Trained batch 1170 in epoch 15, gen_loss = 0.9006828542553799, disc_loss = 0.0002137087974808448
Trained batch 1171 in epoch 15, gen_loss = 0.9006683940875245, disc_loss = 0.00021361491168701068
Trained batch 1172 in epoch 15, gen_loss = 0.9006124044826472, disc_loss = 0.00021351087427695
Trained batch 1173 in epoch 15, gen_loss = 0.900562717012896, disc_loss = 0.0002134320440848056
Trained batch 1174 in epoch 15, gen_loss = 0.9005525633629332, disc_loss = 0.000213429643620831
Trained batch 1175 in epoch 15, gen_loss = 0.9005038153861655, disc_loss = 0.0002133372912899764
Trained batch 1176 in epoch 15, gen_loss = 0.9003967292853706, disc_loss = 0.00021323199311179623
Trained batch 1177 in epoch 15, gen_loss = 0.9002572121968294, disc_loss = 0.0002131878095690103
Trained batch 1178 in epoch 15, gen_loss = 0.9002331168698091, disc_loss = 0.0002131147552058711
Trained batch 1179 in epoch 15, gen_loss = 0.9001867759025703, disc_loss = 0.00021304155542859038
Trained batch 1180 in epoch 15, gen_loss = 0.9001057410421864, disc_loss = 0.00021292734707275009
Trained batch 1181 in epoch 15, gen_loss = 0.9001132820665131, disc_loss = 0.0002128112328921765
Trained batch 1182 in epoch 15, gen_loss = 0.9001411612721086, disc_loss = 0.00021268905622886896
Trained batch 1183 in epoch 15, gen_loss = 0.9001444718120871, disc_loss = 0.00021259124371595504
Trained batch 1184 in epoch 15, gen_loss = 0.9001056936722768, disc_loss = 0.0002125108190501484
Trained batch 1185 in epoch 15, gen_loss = 0.9000580423396917, disc_loss = 0.00021242277609454023
Trained batch 1186 in epoch 15, gen_loss = 0.9000363351420987, disc_loss = 0.000212349947779662
Trained batch 1187 in epoch 15, gen_loss = 0.900088089734617, disc_loss = 0.00021225634313253462
Trained batch 1188 in epoch 15, gen_loss = 0.9000545532589103, disc_loss = 0.00021216529527679772
Trained batch 1189 in epoch 15, gen_loss = 0.9000450616624175, disc_loss = 0.00021204181904686876
Trained batch 1190 in epoch 15, gen_loss = 0.9000675267876946, disc_loss = 0.00021194753411092943
Trained batch 1191 in epoch 15, gen_loss = 0.9000686481095, disc_loss = 0.00021191003135156536
Trained batch 1192 in epoch 15, gen_loss = 0.9001431640515484, disc_loss = 0.0002119293266365315
Trained batch 1193 in epoch 15, gen_loss = 0.9000880351318187, disc_loss = 0.0002119142082394785
Trained batch 1194 in epoch 15, gen_loss = 0.9000929553139658, disc_loss = 0.0002118254433770588
Trained batch 1195 in epoch 15, gen_loss = 0.9000825705037867, disc_loss = 0.00021169951351629208
Trained batch 1196 in epoch 15, gen_loss = 0.9001548484951233, disc_loss = 0.00021160305686596624
Trained batch 1197 in epoch 15, gen_loss = 0.9001015437166758, disc_loss = 0.00021156054862815431
Trained batch 1198 in epoch 15, gen_loss = 0.9001040570033998, disc_loss = 0.00021152513591498172
Trained batch 1199 in epoch 15, gen_loss = 0.9001305501163006, disc_loss = 0.0002114449387257385
Trained batch 1200 in epoch 15, gen_loss = 0.9000406995304022, disc_loss = 0.0002113237186177949
Trained batch 1201 in epoch 15, gen_loss = 0.9000299734105286, disc_loss = 0.00021120667176021586
Trained batch 1202 in epoch 15, gen_loss = 0.9000500274120721, disc_loss = 0.0002111080873734908
Trained batch 1203 in epoch 15, gen_loss = 0.8999993667947097, disc_loss = 0.00021107156168797772
Trained batch 1204 in epoch 15, gen_loss = 0.9000087988821798, disc_loss = 0.00021097384329150524
Trained batch 1205 in epoch 15, gen_loss = 0.9000434312555525, disc_loss = 0.00021088526986050825
Trained batch 1206 in epoch 15, gen_loss = 0.8999483616468624, disc_loss = 0.0002107655450341424
Trained batch 1207 in epoch 15, gen_loss = 0.90001503723544, disc_loss = 0.00021066014853613824
Trained batch 1208 in epoch 15, gen_loss = 0.8999345356812647, disc_loss = 0.00021058898881396777
Trained batch 1209 in epoch 15, gen_loss = 0.8999976046814406, disc_loss = 0.00021057181138305227
Trained batch 1210 in epoch 15, gen_loss = 0.9000479198506212, disc_loss = 0.00021050292304061868
Trained batch 1211 in epoch 15, gen_loss = 0.9000489888804974, disc_loss = 0.00021039874627904313
Trained batch 1212 in epoch 15, gen_loss = 0.9000394551693066, disc_loss = 0.0002103271108383502
Trained batch 1213 in epoch 15, gen_loss = 0.9000689799742408, disc_loss = 0.00021023120996513985
Trained batch 1214 in epoch 15, gen_loss = 0.9001077431219595, disc_loss = 0.00021013105545950375
Trained batch 1215 in epoch 15, gen_loss = 0.9001125977129528, disc_loss = 0.00021002468272220205
Trained batch 1216 in epoch 15, gen_loss = 0.9001153188841012, disc_loss = 0.00020995256226691463
Trained batch 1217 in epoch 15, gen_loss = 0.9001248568443242, disc_loss = 0.00020988756182193218
Trained batch 1218 in epoch 15, gen_loss = 0.9000895629171664, disc_loss = 0.00020975732361706634
Trained batch 1219 in epoch 15, gen_loss = 0.900060965780352, disc_loss = 0.00020967881568229458
Trained batch 1220 in epoch 15, gen_loss = 0.900013153129284, disc_loss = 0.000209565429065764
Trained batch 1221 in epoch 15, gen_loss = 0.8999759539254558, disc_loss = 0.00020946167316440183
Trained batch 1222 in epoch 15, gen_loss = 0.899898596016579, disc_loss = 0.00020937003301872925
Trained batch 1223 in epoch 15, gen_loss = 0.8998536909717361, disc_loss = 0.00020938479901458633
Trained batch 1224 in epoch 15, gen_loss = 0.8998325217500025, disc_loss = 0.0002093281490165189
Trained batch 1225 in epoch 15, gen_loss = 0.8998190498565967, disc_loss = 0.0002092422823977906
Trained batch 1226 in epoch 15, gen_loss = 0.8997993573679998, disc_loss = 0.000209166756254014
Trained batch 1227 in epoch 15, gen_loss = 0.8997447101902885, disc_loss = 0.00020908671871711407
Trained batch 1228 in epoch 15, gen_loss = 0.8998423792949238, disc_loss = 0.00020901963860426437
Trained batch 1229 in epoch 15, gen_loss = 0.8997828259216092, disc_loss = 0.00020893138275047333
Trained batch 1230 in epoch 15, gen_loss = 0.8998105479487551, disc_loss = 0.00020883198314157044
Trained batch 1231 in epoch 15, gen_loss = 0.8998286592012102, disc_loss = 0.0002087247372790963
Trained batch 1232 in epoch 15, gen_loss = 0.8997733787801917, disc_loss = 0.0002086302288774883
Trained batch 1233 in epoch 15, gen_loss = 0.899751467536682, disc_loss = 0.00020853853129665367
Trained batch 1234 in epoch 15, gen_loss = 0.8995960763108876, disc_loss = 0.00020857155998779445
Trained batch 1235 in epoch 15, gen_loss = 0.8996947059064235, disc_loss = 0.00020860299930099095
Trained batch 1236 in epoch 15, gen_loss = 0.899694929897737, disc_loss = 0.00020854170836383858
Trained batch 1237 in epoch 15, gen_loss = 0.8995894146466293, disc_loss = 0.00020848870622066544
Trained batch 1238 in epoch 15, gen_loss = 0.8995022125259535, disc_loss = 0.0002084317713085832
Trained batch 1239 in epoch 15, gen_loss = 0.8994958890061224, disc_loss = 0.0002083256900204428
Trained batch 1240 in epoch 15, gen_loss = 0.8995991267089782, disc_loss = 0.00020826389884300782
Trained batch 1241 in epoch 15, gen_loss = 0.8995680778306847, disc_loss = 0.0002082164948174412
Trained batch 1242 in epoch 15, gen_loss = 0.8994791040666048, disc_loss = 0.00020823426603576377
Trained batch 1243 in epoch 15, gen_loss = 0.8994856476304616, disc_loss = 0.0002082753963012344
Trained batch 1244 in epoch 15, gen_loss = 0.8994199105055936, disc_loss = 0.00020827254914888087
Trained batch 1245 in epoch 15, gen_loss = 0.8993922615988871, disc_loss = 0.00020823744198073443
Trained batch 1246 in epoch 15, gen_loss = 0.8995174333489028, disc_loss = 0.00020816567413979033
Trained batch 1247 in epoch 15, gen_loss = 0.899607691866083, disc_loss = 0.0002081057800518092
Trained batch 1248 in epoch 15, gen_loss = 0.8995483157823714, disc_loss = 0.00020800809411313743
Trained batch 1249 in epoch 15, gen_loss = 0.8996035614490508, disc_loss = 0.00020789765558438375
Trained batch 1250 in epoch 15, gen_loss = 0.8996845111667776, disc_loss = 0.0002078149716822441
Trained batch 1251 in epoch 15, gen_loss = 0.8997396454929163, disc_loss = 0.00020776700343101318
Trained batch 1252 in epoch 15, gen_loss = 0.8997118388854877, disc_loss = 0.0002076862815153675
Trained batch 1253 in epoch 15, gen_loss = 0.8997228716454058, disc_loss = 0.0002075670615197037
Trained batch 1254 in epoch 15, gen_loss = 0.8996378694872457, disc_loss = 0.00020757348233656735
Trained batch 1255 in epoch 15, gen_loss = 0.8996721466730355, disc_loss = 0.00020755701807154614
Trained batch 1256 in epoch 15, gen_loss = 0.8996766437209591, disc_loss = 0.0002074584023737202
Trained batch 1257 in epoch 15, gen_loss = 0.8996390565305901, disc_loss = 0.00020736212551613955
Trained batch 1258 in epoch 15, gen_loss = 0.8995730053630493, disc_loss = 0.00020729087701295166
Trained batch 1259 in epoch 15, gen_loss = 0.8995270718184728, disc_loss = 0.00020723874347620746
Trained batch 1260 in epoch 15, gen_loss = 0.8995171053177019, disc_loss = 0.00020717844472456544
Trained batch 1261 in epoch 15, gen_loss = 0.8995188556363579, disc_loss = 0.0002071160360074509
Trained batch 1262 in epoch 15, gen_loss = 0.8994842484086067, disc_loss = 0.00020708854517420888
Trained batch 1263 in epoch 15, gen_loss = 0.8994926631544964, disc_loss = 0.00020700403294103114
Trained batch 1264 in epoch 15, gen_loss = 0.8993724960583472, disc_loss = 0.00020691611640258386
Trained batch 1265 in epoch 15, gen_loss = 0.8993253797339791, disc_loss = 0.0002068943450448808
Trained batch 1266 in epoch 15, gen_loss = 0.8993988146251266, disc_loss = 0.00020687383748980528
Trained batch 1267 in epoch 15, gen_loss = 0.8994061607009605, disc_loss = 0.00020687499576874742
Trained batch 1268 in epoch 15, gen_loss = 0.899485926303082, disc_loss = 0.00020681956496118687
Trained batch 1269 in epoch 15, gen_loss = 0.8994950025100408, disc_loss = 0.00020677109942615664
Trained batch 1270 in epoch 15, gen_loss = 0.8995004013520728, disc_loss = 0.00020676240576443977
Trained batch 1271 in epoch 15, gen_loss = 0.8995804319029335, disc_loss = 0.00020670254513027904
Trained batch 1272 in epoch 15, gen_loss = 0.8996147438005866, disc_loss = 0.00020663591240494653
Trained batch 1273 in epoch 15, gen_loss = 0.899657042565488, disc_loss = 0.00020657204469122004
Trained batch 1274 in epoch 15, gen_loss = 0.899606685965669, disc_loss = 0.00020652822176606267
Trained batch 1275 in epoch 15, gen_loss = 0.8995666087701403, disc_loss = 0.00020654478821683408
Trained batch 1276 in epoch 15, gen_loss = 0.8995634187173358, disc_loss = 0.00020645275139531555
Trained batch 1277 in epoch 15, gen_loss = 0.8995520280840251, disc_loss = 0.0002064145595516739
Trained batch 1278 in epoch 15, gen_loss = 0.8995319843944671, disc_loss = 0.00020634537931406787
Trained batch 1279 in epoch 15, gen_loss = 0.8995154193602503, disc_loss = 0.00020623372835189003
Trained batch 1280 in epoch 15, gen_loss = 0.8995721150337952, disc_loss = 0.00020613198261135488
Trained batch 1281 in epoch 15, gen_loss = 0.8996041330644009, disc_loss = 0.0002060427018215149
Trained batch 1282 in epoch 15, gen_loss = 0.8996045539273197, disc_loss = 0.0002059273160771294
Trained batch 1283 in epoch 15, gen_loss = 0.8995248532833712, disc_loss = 0.00020583943205282115
Trained batch 1284 in epoch 15, gen_loss = 0.8994347225831176, disc_loss = 0.00020578561053096755
Trained batch 1285 in epoch 15, gen_loss = 0.8993480548054026, disc_loss = 0.00020570878692541248
Trained batch 1286 in epoch 15, gen_loss = 0.8992859350680934, disc_loss = 0.00020570429767429157
Trained batch 1287 in epoch 15, gen_loss = 0.8993446826472046, disc_loss = 0.00020593968905170118
Trained batch 1288 in epoch 15, gen_loss = 0.8993326753863445, disc_loss = 0.00020641926946978267
Trained batch 1289 in epoch 15, gen_loss = 0.8993300188881482, disc_loss = 0.00020673847653498772
Trained batch 1290 in epoch 15, gen_loss = 0.8992714729076389, disc_loss = 0.0002067263078996493
Trained batch 1291 in epoch 15, gen_loss = 0.8991941120417863, disc_loss = 0.00020670328056710072
Trained batch 1292 in epoch 15, gen_loss = 0.8992164972578935, disc_loss = 0.00020663794605471972
Trained batch 1293 in epoch 15, gen_loss = 0.8992176869368811, disc_loss = 0.00020657101359255784
Trained batch 1294 in epoch 15, gen_loss = 0.8991764966585462, disc_loss = 0.0002064752599962045
Trained batch 1295 in epoch 15, gen_loss = 0.8991026593671169, disc_loss = 0.00020645210442024918
Trained batch 1296 in epoch 15, gen_loss = 0.8990437857169046, disc_loss = 0.0002063803096844796
Trained batch 1297 in epoch 15, gen_loss = 0.8990676055428427, disc_loss = 0.00020627887778039568
Trained batch 1298 in epoch 15, gen_loss = 0.899034205310798, disc_loss = 0.00020621863602675116
Trained batch 1299 in epoch 15, gen_loss = 0.8989561254244585, disc_loss = 0.00020620601507499278
Trained batch 1300 in epoch 15, gen_loss = 0.8989283135540205, disc_loss = 0.00020614694938287146
Trained batch 1301 in epoch 15, gen_loss = 0.8988988799158879, disc_loss = 0.00020610256815947392
Trained batch 1302 in epoch 15, gen_loss = 0.8989099915541783, disc_loss = 0.00020604773286149493
Trained batch 1303 in epoch 15, gen_loss = 0.8989832082683323, disc_loss = 0.00020610911069301983
Trained batch 1304 in epoch 15, gen_loss = 0.8989988364935835, disc_loss = 0.0002063183065258962
Trained batch 1305 in epoch 15, gen_loss = 0.8989771851901803, disc_loss = 0.00020635069041971259
Trained batch 1306 in epoch 15, gen_loss = 0.8990674264210275, disc_loss = 0.00020633402092280949
Trained batch 1307 in epoch 15, gen_loss = 0.8990860878509848, disc_loss = 0.00020643015982011235
Trained batch 1308 in epoch 15, gen_loss = 0.8990408606525593, disc_loss = 0.00020647587804058836
Trained batch 1309 in epoch 15, gen_loss = 0.898944187437305, disc_loss = 0.00020639401999278213
Trained batch 1310 in epoch 15, gen_loss = 0.8989214569807599, disc_loss = 0.00020640839425415194
Trained batch 1311 in epoch 15, gen_loss = 0.8988238341379456, disc_loss = 0.00020637902396562668
Trained batch 1312 in epoch 15, gen_loss = 0.8987650877632263, disc_loss = 0.00020634732394785458
Trained batch 1313 in epoch 15, gen_loss = 0.8987096912784663, disc_loss = 0.0002063164751486526
Trained batch 1314 in epoch 15, gen_loss = 0.8987356298776634, disc_loss = 0.00020637922296048224
Trained batch 1315 in epoch 15, gen_loss = 0.898736298084259, disc_loss = 0.00020648774999192256
Trained batch 1316 in epoch 15, gen_loss = 0.8986556513253359, disc_loss = 0.00020667973602675544
Trained batch 1317 in epoch 15, gen_loss = 0.8986230163816618, disc_loss = 0.0002067558558442512
Trained batch 1318 in epoch 15, gen_loss = 0.8985839256560649, disc_loss = 0.00020675491922356892
Trained batch 1319 in epoch 15, gen_loss = 0.8985661889115969, disc_loss = 0.00020673296285443057
Trained batch 1320 in epoch 15, gen_loss = 0.8985906310554348, disc_loss = 0.0002067234558928853
Trained batch 1321 in epoch 15, gen_loss = 0.8985978081799852, disc_loss = 0.00020667998128972697
Trained batch 1322 in epoch 15, gen_loss = 0.8985487135269384, disc_loss = 0.00020663144645992652
Trained batch 1323 in epoch 15, gen_loss = 0.8984747874322615, disc_loss = 0.00020656763241123203
Trained batch 1324 in epoch 15, gen_loss = 0.8984888545971996, disc_loss = 0.0002065532069756509
Trained batch 1325 in epoch 15, gen_loss = 0.8985184882381203, disc_loss = 0.00020647064292808498
Trained batch 1326 in epoch 15, gen_loss = 0.8986167233962266, disc_loss = 0.00020643062505655422
Trained batch 1327 in epoch 15, gen_loss = 0.8986292616969132, disc_loss = 0.00020644133675054344
Trained batch 1328 in epoch 15, gen_loss = 0.8986755177165621, disc_loss = 0.0002065296565545418
Trained batch 1329 in epoch 15, gen_loss = 0.8986570998690182, disc_loss = 0.00020666297943015317
Trained batch 1330 in epoch 15, gen_loss = 0.8986560019848492, disc_loss = 0.00020671329402939783
Trained batch 1331 in epoch 15, gen_loss = 0.8986106503296185, disc_loss = 0.00020662183310746882
Trained batch 1332 in epoch 15, gen_loss = 0.8986185282938299, disc_loss = 0.0002065747875160194
Trained batch 1333 in epoch 15, gen_loss = 0.8985625081423341, disc_loss = 0.0002065338095266709
Trained batch 1334 in epoch 15, gen_loss = 0.8985539851117224, disc_loss = 0.00020645160282733554
Trained batch 1335 in epoch 15, gen_loss = 0.8985835552483261, disc_loss = 0.00020637797496022244
Trained batch 1336 in epoch 15, gen_loss = 0.8985429591622563, disc_loss = 0.0002063246370487719
Trained batch 1337 in epoch 15, gen_loss = 0.8984667324699094, disc_loss = 0.00020627338793213995
Trained batch 1338 in epoch 15, gen_loss = 0.8984789046625133, disc_loss = 0.0002062023520430368
Trained batch 1339 in epoch 15, gen_loss = 0.8985276273382243, disc_loss = 0.00020616444708682153
Trained batch 1340 in epoch 15, gen_loss = 0.8985713397185363, disc_loss = 0.00020611760816203486
Trained batch 1341 in epoch 15, gen_loss = 0.8985877828964001, disc_loss = 0.0002060973147877968
Trained batch 1342 in epoch 15, gen_loss = 0.8985656601496801, disc_loss = 0.0002059899442329464
Trained batch 1343 in epoch 15, gen_loss = 0.8985912391383734, disc_loss = 0.00020590495974677955
Trained batch 1344 in epoch 15, gen_loss = 0.8984613001568167, disc_loss = 0.0002059593359902103
Trained batch 1345 in epoch 15, gen_loss = 0.8983872821568379, disc_loss = 0.0002059135940901947
Trained batch 1346 in epoch 15, gen_loss = 0.898441906407221, disc_loss = 0.0002059683942647133
Trained batch 1347 in epoch 15, gen_loss = 0.8984271867162043, disc_loss = 0.00020592491509293886
Trained batch 1348 in epoch 15, gen_loss = 0.8984304843256437, disc_loss = 0.00020584988480949363
Trained batch 1349 in epoch 15, gen_loss = 0.8983204831458904, disc_loss = 0.0002057507542485837
Trained batch 1350 in epoch 15, gen_loss = 0.898268300943424, disc_loss = 0.000205659857162393
Trained batch 1351 in epoch 15, gen_loss = 0.8982533748597789, disc_loss = 0.00020557997020703023
Trained batch 1352 in epoch 15, gen_loss = 0.8982075612719466, disc_loss = 0.0002054740898966351
Trained batch 1353 in epoch 15, gen_loss = 0.8981875722658335, disc_loss = 0.00020539157348766645
Trained batch 1354 in epoch 15, gen_loss = 0.8981503362145371, disc_loss = 0.0002052899217394153
Trained batch 1355 in epoch 15, gen_loss = 0.8981131988640731, disc_loss = 0.0002051862840722971
Trained batch 1356 in epoch 15, gen_loss = 0.8980719397501992, disc_loss = 0.0002051718384377928
Trained batch 1357 in epoch 15, gen_loss = 0.8981077477050635, disc_loss = 0.00020532336800921722
Trained batch 1358 in epoch 15, gen_loss = 0.8980597822081964, disc_loss = 0.00020539397505394506
Trained batch 1359 in epoch 15, gen_loss = 0.8980363085427705, disc_loss = 0.00020532363970393337
Trained batch 1360 in epoch 15, gen_loss = 0.8980212785757963, disc_loss = 0.00020521810442377067
Trained batch 1361 in epoch 15, gen_loss = 0.8980784652954331, disc_loss = 0.0002051108329906983
Trained batch 1362 in epoch 15, gen_loss = 0.8980559921404586, disc_loss = 0.00020511949790229302
Trained batch 1363 in epoch 15, gen_loss = 0.8980585213455636, disc_loss = 0.00020512761056767654
Trained batch 1364 in epoch 15, gen_loss = 0.8979890372290279, disc_loss = 0.00020506466304347765
Trained batch 1365 in epoch 15, gen_loss = 0.8978975314870585, disc_loss = 0.00020496257591618827
Trained batch 1366 in epoch 15, gen_loss = 0.8978748285779137, disc_loss = 0.00020485791764802034
Trained batch 1367 in epoch 15, gen_loss = 0.8978757860890606, disc_loss = 0.00020479653041590413
Trained batch 1368 in epoch 15, gen_loss = 0.8979522556697827, disc_loss = 0.0002047551457213263
Trained batch 1369 in epoch 15, gen_loss = 0.8978251666483218, disc_loss = 0.00020477087573121967
Trained batch 1370 in epoch 15, gen_loss = 0.8978792204203004, disc_loss = 0.00020476405847808999
Trained batch 1371 in epoch 15, gen_loss = 0.897925769883064, disc_loss = 0.00020470447431467968
Trained batch 1372 in epoch 15, gen_loss = 0.8979182151313776, disc_loss = 0.00020470058727491063
Trained batch 1373 in epoch 15, gen_loss = 0.8978420698139519, disc_loss = 0.00020461432911084357
Trained batch 1374 in epoch 15, gen_loss = 0.8978335249640725, disc_loss = 0.00020456874881214887
Trained batch 1375 in epoch 15, gen_loss = 0.8977608033131028, disc_loss = 0.00020445924614842772
Trained batch 1376 in epoch 15, gen_loss = 0.8977471517754709, disc_loss = 0.00020439409237955585
Trained batch 1377 in epoch 15, gen_loss = 0.8976527591315686, disc_loss = 0.0002043283115547787
Trained batch 1378 in epoch 15, gen_loss = 0.8977182031628703, disc_loss = 0.0002043125402053853
Trained batch 1379 in epoch 15, gen_loss = 0.8976930620877639, disc_loss = 0.000204336337027717
Trained batch 1380 in epoch 15, gen_loss = 0.8976827093348133, disc_loss = 0.0002042439718157354
Trained batch 1381 in epoch 15, gen_loss = 0.897726386914895, disc_loss = 0.00020418904896149297
Trained batch 1382 in epoch 15, gen_loss = 0.8977021232775304, disc_loss = 0.00020413664695077838
Trained batch 1383 in epoch 15, gen_loss = 0.8977443440628878, disc_loss = 0.00020421238233511285
Trained batch 1384 in epoch 15, gen_loss = 0.8976970959226147, disc_loss = 0.0002042565247760951
Trained batch 1385 in epoch 15, gen_loss = 0.897746003465391, disc_loss = 0.00020419512436615838
Trained batch 1386 in epoch 15, gen_loss = 0.8977243654059264, disc_loss = 0.00020413294567854298
Trained batch 1387 in epoch 15, gen_loss = 0.897686551257925, disc_loss = 0.00020409837750734268
Trained batch 1388 in epoch 15, gen_loss = 0.8977268850571651, disc_loss = 0.00020400267334076956
Trained batch 1389 in epoch 15, gen_loss = 0.8977419319341509, disc_loss = 0.0002039308326137537
Trained batch 1390 in epoch 15, gen_loss = 0.8976963664198162, disc_loss = 0.0002038217815799012
Trained batch 1391 in epoch 15, gen_loss = 0.8977180495001804, disc_loss = 0.00020372983989619078
Trained batch 1392 in epoch 15, gen_loss = 0.8975998333950138, disc_loss = 0.00020363815542378503
Trained batch 1393 in epoch 15, gen_loss = 0.8975479721253367, disc_loss = 0.00020356279844054893
Trained batch 1394 in epoch 15, gen_loss = 0.8975780640024438, disc_loss = 0.0002034850991516721
Trained batch 1395 in epoch 15, gen_loss = 0.8975977656834446, disc_loss = 0.00020348851240411324
Trained batch 1396 in epoch 15, gen_loss = 0.8975796162356798, disc_loss = 0.0002035357814612425
Trained batch 1397 in epoch 15, gen_loss = 0.8975523199049359, disc_loss = 0.00020347877134177107
Trained batch 1398 in epoch 15, gen_loss = 0.8975785580850483, disc_loss = 0.00020345141793619688
Trained batch 1399 in epoch 15, gen_loss = 0.8975239187904767, disc_loss = 0.00020350470924313413
Trained batch 1400 in epoch 15, gen_loss = 0.8975425862908618, disc_loss = 0.00020356953835647804
Trained batch 1401 in epoch 15, gen_loss = 0.8974887374974522, disc_loss = 0.00020352931515895428
Trained batch 1402 in epoch 15, gen_loss = 0.8974569832012641, disc_loss = 0.00020342432674112963
Trained batch 1403 in epoch 15, gen_loss = 0.8974112112213064, disc_loss = 0.000203408245928627
Trained batch 1404 in epoch 15, gen_loss = 0.8973189544423195, disc_loss = 0.00020336977035172608
Trained batch 1405 in epoch 15, gen_loss = 0.8972266084523832, disc_loss = 0.00020329166788152938
Trained batch 1406 in epoch 15, gen_loss = 0.8973435675665768, disc_loss = 0.0002032501904030202
Trained batch 1407 in epoch 15, gen_loss = 0.8973209092986177, disc_loss = 0.00020317323356845338
Trained batch 1408 in epoch 15, gen_loss = 0.8972282680828915, disc_loss = 0.0002030876789156845
Trained batch 1409 in epoch 15, gen_loss = 0.8972322061552224, disc_loss = 0.0002030421401828557
Trained batch 1410 in epoch 15, gen_loss = 0.897224097789221, disc_loss = 0.00020298432985699883
Trained batch 1411 in epoch 15, gen_loss = 0.8972225949885825, disc_loss = 0.00020292980155372324
Trained batch 1412 in epoch 15, gen_loss = 0.89718213894649, disc_loss = 0.00020289492279852055
Trained batch 1413 in epoch 15, gen_loss = 0.8971876087670954, disc_loss = 0.00020287439685973208
Trained batch 1414 in epoch 15, gen_loss = 0.8971630806636474, disc_loss = 0.0002028169561218217
Trained batch 1415 in epoch 15, gen_loss = 0.8972383080060873, disc_loss = 0.00020275893300511258
Trained batch 1416 in epoch 15, gen_loss = 0.8971497408083483, disc_loss = 0.00020269964176792738
Trained batch 1417 in epoch 15, gen_loss = 0.8970807019426725, disc_loss = 0.00020266814190698644
Trained batch 1418 in epoch 15, gen_loss = 0.8970777719603868, disc_loss = 0.0002026050396374682
Trained batch 1419 in epoch 15, gen_loss = 0.8970147619784717, disc_loss = 0.00020258380314310632
Trained batch 1420 in epoch 15, gen_loss = 0.8970527015547782, disc_loss = 0.00020251670350472363
Trained batch 1421 in epoch 15, gen_loss = 0.8970124795718535, disc_loss = 0.00020246201853404402
Trained batch 1422 in epoch 15, gen_loss = 0.8969994625488973, disc_loss = 0.00020239890156034315
Trained batch 1423 in epoch 15, gen_loss = 0.8969601890428013, disc_loss = 0.00020229862837858786
Trained batch 1424 in epoch 15, gen_loss = 0.8969240980399282, disc_loss = 0.0002021956485144696
Trained batch 1425 in epoch 15, gen_loss = 0.8968850962326537, disc_loss = 0.00020208508319099878
Trained batch 1426 in epoch 15, gen_loss = 0.8969689748382434, disc_loss = 0.0002020106764066517
Trained batch 1427 in epoch 15, gen_loss = 0.8970117861566758, disc_loss = 0.0002019379621322346
Trained batch 1428 in epoch 15, gen_loss = 0.8969829547563744, disc_loss = 0.0002018428813836003
Trained batch 1429 in epoch 15, gen_loss = 0.8969490768609347, disc_loss = 0.00020174795493409868
Trained batch 1430 in epoch 15, gen_loss = 0.8968876485304762, disc_loss = 0.0002016526749177182
Trained batch 1431 in epoch 15, gen_loss = 0.8968864459565232, disc_loss = 0.0002015502939852338
Trained batch 1432 in epoch 15, gen_loss = 0.8969135473261991, disc_loss = 0.00020147217321402552
Trained batch 1433 in epoch 15, gen_loss = 0.8970005533851506, disc_loss = 0.000201472663916783
Trained batch 1434 in epoch 15, gen_loss = 0.8970712120524682, disc_loss = 0.00020140001804797866
Trained batch 1435 in epoch 15, gen_loss = 0.8969587322563182, disc_loss = 0.0002013247779291115
Trained batch 1436 in epoch 15, gen_loss = 0.8969726224864781, disc_loss = 0.00020125858828048455
Trained batch 1437 in epoch 15, gen_loss = 0.8969971695927818, disc_loss = 0.00020118790635074795
Trained batch 1438 in epoch 15, gen_loss = 0.8970052904350382, disc_loss = 0.00020115967371736528
Trained batch 1439 in epoch 15, gen_loss = 0.8969510470827421, disc_loss = 0.00020109290646309495
Trained batch 1440 in epoch 15, gen_loss = 0.8970079735945199, disc_loss = 0.000201023037337536
Trained batch 1441 in epoch 15, gen_loss = 0.8970261521627106, disc_loss = 0.0002009704485531787
Trained batch 1442 in epoch 15, gen_loss = 0.8969629372231925, disc_loss = 0.0002009303844575207
Trained batch 1443 in epoch 15, gen_loss = 0.8969987608967065, disc_loss = 0.00020089253156133197
Trained batch 1444 in epoch 15, gen_loss = 0.8969609364093794, disc_loss = 0.00020089146956709975
Trained batch 1445 in epoch 15, gen_loss = 0.896913654988897, disc_loss = 0.0002008508379361375
Trained batch 1446 in epoch 15, gen_loss = 0.8969747101593282, disc_loss = 0.00020083552895440224
Trained batch 1447 in epoch 15, gen_loss = 0.8968639550370406, disc_loss = 0.00020082574143008607
Trained batch 1448 in epoch 15, gen_loss = 0.8969218113489855, disc_loss = 0.00020074519470767176
Trained batch 1449 in epoch 15, gen_loss = 0.8969592932586012, disc_loss = 0.00020070090214270247
Trained batch 1450 in epoch 15, gen_loss = 0.8968411110582885, disc_loss = 0.00020062180105074877
Trained batch 1451 in epoch 15, gen_loss = 0.8968106517286012, disc_loss = 0.00020053595919067025
Trained batch 1452 in epoch 15, gen_loss = 0.896725968336616, disc_loss = 0.00020046168489152766
Trained batch 1453 in epoch 15, gen_loss = 0.8966934758826496, disc_loss = 0.00020037144504147958
Trained batch 1454 in epoch 15, gen_loss = 0.8967038644548134, disc_loss = 0.00020030247432544198
Trained batch 1455 in epoch 15, gen_loss = 0.8967286573907176, disc_loss = 0.00020025486475418262
Trained batch 1456 in epoch 15, gen_loss = 0.8967232965572124, disc_loss = 0.00020022853661896088
Trained batch 1457 in epoch 15, gen_loss = 0.896691258511262, disc_loss = 0.00020013381553025657
Trained batch 1458 in epoch 15, gen_loss = 0.8966797720985595, disc_loss = 0.00020006930679449512
Trained batch 1459 in epoch 15, gen_loss = 0.8966719095429329, disc_loss = 0.00020002985812637124
Trained batch 1460 in epoch 15, gen_loss = 0.896663953799405, disc_loss = 0.00019995528239768218
Trained batch 1461 in epoch 15, gen_loss = 0.8966974132119713, disc_loss = 0.00019987294497014174
Trained batch 1462 in epoch 15, gen_loss = 0.8966780759582598, disc_loss = 0.0001998189015124241
Trained batch 1463 in epoch 15, gen_loss = 0.8967196229702789, disc_loss = 0.00019979372762990566
Trained batch 1464 in epoch 15, gen_loss = 0.896806422598126, disc_loss = 0.00019976059779190655
Trained batch 1465 in epoch 15, gen_loss = 0.8967905338106507, disc_loss = 0.000199723527782944
Trained batch 1466 in epoch 15, gen_loss = 0.8968242909035556, disc_loss = 0.00019966380179958654
Trained batch 1467 in epoch 15, gen_loss = 0.8967348509328567, disc_loss = 0.0001995990164749055
Trained batch 1468 in epoch 15, gen_loss = 0.8967250820890911, disc_loss = 0.0001995533107222767
Trained batch 1469 in epoch 15, gen_loss = 0.8966747954589169, disc_loss = 0.00019945726691767793
Trained batch 1470 in epoch 15, gen_loss = 0.896767567486118, disc_loss = 0.00019941023307976934
Trained batch 1471 in epoch 15, gen_loss = 0.8967210502242264, disc_loss = 0.00019935328902459767
Trained batch 1472 in epoch 15, gen_loss = 0.8967180853382066, disc_loss = 0.00019929131806149743
Trained batch 1473 in epoch 15, gen_loss = 0.8966776008036599, disc_loss = 0.00019922607077737487
Trained batch 1474 in epoch 15, gen_loss = 0.8966681508290566, disc_loss = 0.00019920439204108365
Trained batch 1475 in epoch 15, gen_loss = 0.8966749977209381, disc_loss = 0.00019918834469390375
Trained batch 1476 in epoch 15, gen_loss = 0.8966695964941723, disc_loss = 0.00019916887288333733
Trained batch 1477 in epoch 15, gen_loss = 0.8965683554844863, disc_loss = 0.00019913379275727169
Trained batch 1478 in epoch 15, gen_loss = 0.8966193040373198, disc_loss = 0.00019907941429127946
Trained batch 1479 in epoch 15, gen_loss = 0.8965332646627684, disc_loss = 0.00019913083144667719
Trained batch 1480 in epoch 15, gen_loss = 0.8964874633738191, disc_loss = 0.00019911480597032885
Trained batch 1481 in epoch 15, gen_loss = 0.8963873676362469, disc_loss = 0.00019909276306616535
Trained batch 1482 in epoch 15, gen_loss = 0.8964953279865006, disc_loss = 0.00019908150750317483
Trained batch 1483 in epoch 15, gen_loss = 0.8965280597823649, disc_loss = 0.00019905640588063452
Trained batch 1484 in epoch 15, gen_loss = 0.8964788000591676, disc_loss = 0.00019895902796419532
Trained batch 1485 in epoch 15, gen_loss = 0.8964537314338608, disc_loss = 0.00019888245768316746
Trained batch 1486 in epoch 15, gen_loss = 0.8964704163698197, disc_loss = 0.0001988314162149384
Trained batch 1487 in epoch 15, gen_loss = 0.8963987751994081, disc_loss = 0.00019877847579106943
Trained batch 1488 in epoch 15, gen_loss = 0.8963750215726383, disc_loss = 0.00019870785684326364
Trained batch 1489 in epoch 15, gen_loss = 0.8963952680562166, disc_loss = 0.0001987094886897088
Trained batch 1490 in epoch 15, gen_loss = 0.8963526026423868, disc_loss = 0.00019876498397429412
Trained batch 1491 in epoch 15, gen_loss = 0.8963312889791366, disc_loss = 0.00019887620631357886
Trained batch 1492 in epoch 15, gen_loss = 0.8963736882963519, disc_loss = 0.00019884006447482813
Trained batch 1493 in epoch 15, gen_loss = 0.8964269157633724, disc_loss = 0.00019878424109082696
Trained batch 1494 in epoch 15, gen_loss = 0.8964652741234438, disc_loss = 0.00019873107702609146
Trained batch 1495 in epoch 15, gen_loss = 0.8963970237157561, disc_loss = 0.00019866638958385184
Trained batch 1496 in epoch 15, gen_loss = 0.8963992002413284, disc_loss = 0.00019864703514449125
Trained batch 1497 in epoch 15, gen_loss = 0.8963502418294609, disc_loss = 0.00019860514913405385
Trained batch 1498 in epoch 15, gen_loss = 0.8963324664591789, disc_loss = 0.00019855097672772198
Trained batch 1499 in epoch 15, gen_loss = 0.896258690237999, disc_loss = 0.00019850612286245452
Trained batch 1500 in epoch 15, gen_loss = 0.8962640117042308, disc_loss = 0.00019848532773067878
Trained batch 1501 in epoch 15, gen_loss = 0.8962542704354907, disc_loss = 0.00019849072186153545
Trained batch 1502 in epoch 15, gen_loss = 0.8961978907277405, disc_loss = 0.00019859513238054425
Trained batch 1503 in epoch 15, gen_loss = 0.8961885007137947, disc_loss = 0.00019870426644666488
Trained batch 1504 in epoch 15, gen_loss = 0.8961987173834512, disc_loss = 0.00019877330004392296
Trained batch 1505 in epoch 15, gen_loss = 0.8962245037356221, disc_loss = 0.00019881110797620132
Trained batch 1506 in epoch 15, gen_loss = 0.8962248504438698, disc_loss = 0.00019876555762996534
Trained batch 1507 in epoch 15, gen_loss = 0.896219275239608, disc_loss = 0.00019873094193242734
Trained batch 1508 in epoch 15, gen_loss = 0.89613318885692, disc_loss = 0.00019867562301626807
Trained batch 1509 in epoch 15, gen_loss = 0.8961801847085258, disc_loss = 0.0001986941387686055
Trained batch 1510 in epoch 15, gen_loss = 0.8961505986538097, disc_loss = 0.00019867540653165544
Trained batch 1511 in epoch 15, gen_loss = 0.8961359253399587, disc_loss = 0.0001986458496479413
Trained batch 1512 in epoch 15, gen_loss = 0.8961868305830316, disc_loss = 0.00019865851741385234
Trained batch 1513 in epoch 15, gen_loss = 0.8962112114010587, disc_loss = 0.00019880729410592053
Trained batch 1514 in epoch 15, gen_loss = 0.8962172632563625, disc_loss = 0.00019914593124280378
Trained batch 1515 in epoch 15, gen_loss = 0.8962180532298806, disc_loss = 0.00019923100327323579
Trained batch 1516 in epoch 15, gen_loss = 0.8961991264227589, disc_loss = 0.00019922756334921302
Trained batch 1517 in epoch 15, gen_loss = 0.8961949417949194, disc_loss = 0.0001992655094342637
Trained batch 1518 in epoch 15, gen_loss = 0.8961522388882037, disc_loss = 0.00019929588144123795
Trained batch 1519 in epoch 15, gen_loss = 0.8961562715862926, disc_loss = 0.00019926790533932753
Trained batch 1520 in epoch 15, gen_loss = 0.8961934359115962, disc_loss = 0.000199266803391144
Trained batch 1521 in epoch 15, gen_loss = 0.8961750884172011, disc_loss = 0.00019935290293878038
Trained batch 1522 in epoch 15, gen_loss = 0.8962461763279891, disc_loss = 0.00019934017575369323
Trained batch 1523 in epoch 15, gen_loss = 0.8962656403072863, disc_loss = 0.00019931806535436374
Trained batch 1524 in epoch 15, gen_loss = 0.8962881271565547, disc_loss = 0.00019931185821197225
Trained batch 1525 in epoch 15, gen_loss = 0.8963155279700128, disc_loss = 0.0001992644340198943
Trained batch 1526 in epoch 15, gen_loss = 0.8963388444632584, disc_loss = 0.0001991991915263357
Trained batch 1527 in epoch 15, gen_loss = 0.8963423313192672, disc_loss = 0.0001991956303621376
Trained batch 1528 in epoch 15, gen_loss = 0.8963348196174991, disc_loss = 0.00019914988421825412
Trained batch 1529 in epoch 15, gen_loss = 0.8963438865795634, disc_loss = 0.00019906038283164996
Trained batch 1530 in epoch 15, gen_loss = 0.8963770850431989, disc_loss = 0.00019904294196349903
Trained batch 1531 in epoch 15, gen_loss = 0.8964294053944845, disc_loss = 0.0001990702368938194
Trained batch 1532 in epoch 15, gen_loss = 0.896490813351424, disc_loss = 0.00019913017568670563
Trained batch 1533 in epoch 15, gen_loss = 0.8964231822450283, disc_loss = 0.00019914462706209203
Trained batch 1534 in epoch 15, gen_loss = 0.8964034523171789, disc_loss = 0.00019921714779185223
Trained batch 1535 in epoch 15, gen_loss = 0.8963772399971882, disc_loss = 0.00019921546739472737
Trained batch 1536 in epoch 15, gen_loss = 0.8963641497168978, disc_loss = 0.00019919510132494693
Trained batch 1537 in epoch 15, gen_loss = 0.8963456143018328, disc_loss = 0.00019913880847910993
Trained batch 1538 in epoch 15, gen_loss = 0.8962655071316794, disc_loss = 0.00019907461554911882
Trained batch 1539 in epoch 15, gen_loss = 0.8962415740861521, disc_loss = 0.00019906001745129015
Trained batch 1540 in epoch 15, gen_loss = 0.8962318046304949, disc_loss = 0.0001990276152159418
Trained batch 1541 in epoch 15, gen_loss = 0.8962678743862147, disc_loss = 0.00019897714504924839
Trained batch 1542 in epoch 15, gen_loss = 0.896262280251867, disc_loss = 0.00019891510772326724
Trained batch 1543 in epoch 15, gen_loss = 0.8963234807157145, disc_loss = 0.00019886930134665996
Trained batch 1544 in epoch 15, gen_loss = 0.8963265162069821, disc_loss = 0.00019882833260668345
Trained batch 1545 in epoch 15, gen_loss = 0.8963401039235804, disc_loss = 0.00019877956819770718
Trained batch 1546 in epoch 15, gen_loss = 0.8963693242036072, disc_loss = 0.00019884184486466432
Trained batch 1547 in epoch 15, gen_loss = 0.8964211378217668, disc_loss = 0.00019896332702112296
Trained batch 1548 in epoch 15, gen_loss = 0.8964193155874816, disc_loss = 0.0001989945177622924
Trained batch 1549 in epoch 15, gen_loss = 0.8963186181745222, disc_loss = 0.0001990592158108484
Trained batch 1550 in epoch 15, gen_loss = 0.8963000151051927, disc_loss = 0.00019906159360740102
Trained batch 1551 in epoch 15, gen_loss = 0.8963064243728968, disc_loss = 0.0001990850139440433
Trained batch 1552 in epoch 15, gen_loss = 0.8962557515787909, disc_loss = 0.0001991177019310461
Trained batch 1553 in epoch 15, gen_loss = 0.8962179624512696, disc_loss = 0.0001990658450547556
Trained batch 1554 in epoch 15, gen_loss = 0.8961903610796791, disc_loss = 0.00019900210684526957
Trained batch 1555 in epoch 15, gen_loss = 0.8961864463544443, disc_loss = 0.00019896411480925107
Trained batch 1556 in epoch 15, gen_loss = 0.8962119831898002, disc_loss = 0.00019894557187604217
Trained batch 1557 in epoch 15, gen_loss = 0.8961736367434378, disc_loss = 0.0001989047266525352
Trained batch 1558 in epoch 15, gen_loss = 0.8962748461690294, disc_loss = 0.0001989296532550488
Trained batch 1559 in epoch 15, gen_loss = 0.896229048187916, disc_loss = 0.00019892926998298395
Trained batch 1560 in epoch 15, gen_loss = 0.8962558973759585, disc_loss = 0.00019887801831149486
Trained batch 1561 in epoch 15, gen_loss = 0.8962936421591555, disc_loss = 0.00019883179001309063
Trained batch 1562 in epoch 15, gen_loss = 0.896279103810865, disc_loss = 0.00019896525317296995
Trained batch 1563 in epoch 15, gen_loss = 0.8962723001494737, disc_loss = 0.0001990324764330785
Trained batch 1564 in epoch 15, gen_loss = 0.8963016081922732, disc_loss = 0.00019913493341244847
Trained batch 1565 in epoch 15, gen_loss = 0.8962520584749536, disc_loss = 0.00019915944222548333
Trained batch 1566 in epoch 15, gen_loss = 0.8962658281986624, disc_loss = 0.00019910959207534407
Trained batch 1567 in epoch 15, gen_loss = 0.8962265095692508, disc_loss = 0.00019908967513457558
Trained batch 1568 in epoch 15, gen_loss = 0.8962753247576507, disc_loss = 0.00019910752818007242
Trained batch 1569 in epoch 15, gen_loss = 0.8962868008643958, disc_loss = 0.0001991270239078247
Trained batch 1570 in epoch 15, gen_loss = 0.8962599284932691, disc_loss = 0.00019913653844383112
Trained batch 1571 in epoch 15, gen_loss = 0.8963167967687127, disc_loss = 0.00019912948816382705
Trained batch 1572 in epoch 15, gen_loss = 0.8964030430412414, disc_loss = 0.00019915443874789148
Trained batch 1573 in epoch 15, gen_loss = 0.8964543301313926, disc_loss = 0.00019993098451892178
Trained batch 1574 in epoch 15, gen_loss = 0.8965129613497901, disc_loss = 0.00020066108035814343
Trained batch 1575 in epoch 15, gen_loss = 0.8965962684623481, disc_loss = 0.0002009378614750715
Trained batch 1576 in epoch 15, gen_loss = 0.8966308376724084, disc_loss = 0.00020118582034611262
Trained batch 1577 in epoch 15, gen_loss = 0.8966361353379239, disc_loss = 0.00020140494968561682
Trained batch 1578 in epoch 15, gen_loss = 0.8966756193527623, disc_loss = 0.00020148766230402676
Trained batch 1579 in epoch 15, gen_loss = 0.8967128678967681, disc_loss = 0.0002014564794034747
Trained batch 1580 in epoch 15, gen_loss = 0.896677888020317, disc_loss = 0.00020144580994245367
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.9616425633430481, disc_loss = 0.00014864938566461205
Trained batch 1 in epoch 16, gen_loss = 0.9344381988048553, disc_loss = 0.00015591819828841835
Trained batch 2 in epoch 16, gen_loss = 0.8792099356651306, disc_loss = 0.00014112345767595494
Trained batch 3 in epoch 16, gen_loss = 0.9016535133123398, disc_loss = 0.0001272377066925401
Trained batch 4 in epoch 16, gen_loss = 0.8648199439048767, disc_loss = 0.00017962224810617045
Trained batch 5 in epoch 16, gen_loss = 0.8576897283395132, disc_loss = 0.00021226191529422067
Trained batch 6 in epoch 16, gen_loss = 0.8684718183108738, disc_loss = 0.0002453220045676322
Trained batch 7 in epoch 16, gen_loss = 0.8632501065731049, disc_loss = 0.00025402797928109067
Trained batch 8 in epoch 16, gen_loss = 0.8618126776483324, disc_loss = 0.00023306747445733182
Trained batch 9 in epoch 16, gen_loss = 0.8684849321842194, disc_loss = 0.00022105561001808382
Trained batch 10 in epoch 16, gen_loss = 0.8704939809712496, disc_loss = 0.00021802348320224237
Trained batch 11 in epoch 16, gen_loss = 0.8774985522031784, disc_loss = 0.00021143708787955498
Trained batch 12 in epoch 16, gen_loss = 0.8836477169623742, disc_loss = 0.0002135679829874649
Trained batch 13 in epoch 16, gen_loss = 0.8855705431529454, disc_loss = 0.0002214664278393944
Trained batch 14 in epoch 16, gen_loss = 0.8790177543958028, disc_loss = 0.00023974254969895507
Trained batch 15 in epoch 16, gen_loss = 0.8864510394632816, disc_loss = 0.00026168170234086574
Trained batch 16 in epoch 16, gen_loss = 0.8793098400620853, disc_loss = 0.0002720279996591511
Trained batch 17 in epoch 16, gen_loss = 0.8755412532223595, disc_loss = 0.0002801962275245589
Trained batch 18 in epoch 16, gen_loss = 0.8764779222638983, disc_loss = 0.0002810059449984692
Trained batch 19 in epoch 16, gen_loss = 0.8686381429433823, disc_loss = 0.00029751288857369216
Trained batch 20 in epoch 16, gen_loss = 0.8653205207415989, disc_loss = 0.0002982219742816163
Trained batch 21 in epoch 16, gen_loss = 0.8659678480841897, disc_loss = 0.00029682431704713963
Trained batch 22 in epoch 16, gen_loss = 0.8644875650820525, disc_loss = 0.0002916103862251317
Trained batch 23 in epoch 16, gen_loss = 0.8683923333883286, disc_loss = 0.0002867841167244478
Trained batch 24 in epoch 16, gen_loss = 0.8698250770568847, disc_loss = 0.00028002427716273816
Trained batch 25 in epoch 16, gen_loss = 0.8683230785223154, disc_loss = 0.00027428608210846927
Trained batch 26 in epoch 16, gen_loss = 0.8682087262471517, disc_loss = 0.0002683015972487973
Trained batch 27 in epoch 16, gen_loss = 0.8695883452892303, disc_loss = 0.0002649520148614621
Trained batch 28 in epoch 16, gen_loss = 0.8684418776939655, disc_loss = 0.0002594224775936615
Trained batch 29 in epoch 16, gen_loss = 0.8689079602559407, disc_loss = 0.00025371711793316837
Trained batch 30 in epoch 16, gen_loss = 0.8695541947118698, disc_loss = 0.00024958252094708564
Trained batch 31 in epoch 16, gen_loss = 0.8704472593963146, disc_loss = 0.00024666824242558505
Trained batch 32 in epoch 16, gen_loss = 0.8708151560841184, disc_loss = 0.00024365345796633682
Trained batch 33 in epoch 16, gen_loss = 0.8700944237849292, disc_loss = 0.00024005906294298577
Trained batch 34 in epoch 16, gen_loss = 0.8724829690796988, disc_loss = 0.00023440633335017731
Trained batch 35 in epoch 16, gen_loss = 0.876534072889222, disc_loss = 0.0002336904532664145
Trained batch 36 in epoch 16, gen_loss = 0.880600048078073, disc_loss = 0.00023955623524867602
Trained batch 37 in epoch 16, gen_loss = 0.878157272150642, disc_loss = 0.0002442462941153759
Trained batch 38 in epoch 16, gen_loss = 0.8807272865222051, disc_loss = 0.00024239228066737548
Trained batch 39 in epoch 16, gen_loss = 0.8800180301070213, disc_loss = 0.0002440198015392525
Trained batch 40 in epoch 16, gen_loss = 0.8805116778466759, disc_loss = 0.0002418053176725374
Trained batch 41 in epoch 16, gen_loss = 0.8796177847044808, disc_loss = 0.00024148148284958943
Trained batch 42 in epoch 16, gen_loss = 0.8817820964857589, disc_loss = 0.00023861934730734372
Trained batch 43 in epoch 16, gen_loss = 0.8829682144251737, disc_loss = 0.00023697573272908232
Trained batch 44 in epoch 16, gen_loss = 0.881400669945611, disc_loss = 0.00023878023671891749
Trained batch 45 in epoch 16, gen_loss = 0.8813715071781821, disc_loss = 0.0002406488769654812
Trained batch 46 in epoch 16, gen_loss = 0.8815715909004211, disc_loss = 0.00023823951979717636
Trained batch 47 in epoch 16, gen_loss = 0.8816308192908764, disc_loss = 0.00023776416295125577
Trained batch 48 in epoch 16, gen_loss = 0.8815428894393298, disc_loss = 0.00023935656392904076
Trained batch 49 in epoch 16, gen_loss = 0.8804108834266663, disc_loss = 0.0002388673026871402
Trained batch 50 in epoch 16, gen_loss = 0.8814650633755852, disc_loss = 0.00023665470650360243
Trained batch 51 in epoch 16, gen_loss = 0.8819267944647715, disc_loss = 0.00023472331262242873
Trained batch 52 in epoch 16, gen_loss = 0.8833711439708494, disc_loss = 0.0002329137042013243
Trained batch 53 in epoch 16, gen_loss = 0.8820805472356302, disc_loss = 0.00022988299948607433
Trained batch 54 in epoch 16, gen_loss = 0.882659020207145, disc_loss = 0.0002275185261334462
Trained batch 55 in epoch 16, gen_loss = 0.8816998090062823, disc_loss = 0.00022964389726049767
Trained batch 56 in epoch 16, gen_loss = 0.8845669658560502, disc_loss = 0.00022795630540809055
Trained batch 57 in epoch 16, gen_loss = 0.8853093591229669, disc_loss = 0.00022661657278839466
Trained batch 58 in epoch 16, gen_loss = 0.8830606715153839, disc_loss = 0.00022501685058252128
Trained batch 59 in epoch 16, gen_loss = 0.8825175831715266, disc_loss = 0.00022255735384533182
Trained batch 60 in epoch 16, gen_loss = 0.8816852510952559, disc_loss = 0.00022030656500795825
Trained batch 61 in epoch 16, gen_loss = 0.8823088186402475, disc_loss = 0.0002181192328627672
Trained batch 62 in epoch 16, gen_loss = 0.8840822265261695, disc_loss = 0.00021801493384705355
Trained batch 63 in epoch 16, gen_loss = 0.883504793047905, disc_loss = 0.00021952020119897497
Trained batch 64 in epoch 16, gen_loss = 0.8838125412280743, disc_loss = 0.00022152810326168457
Trained batch 65 in epoch 16, gen_loss = 0.8832332022262342, disc_loss = 0.00022002553349452546
Trained batch 66 in epoch 16, gen_loss = 0.8835186228823306, disc_loss = 0.00021774262750656832
Trained batch 67 in epoch 16, gen_loss = 0.8834457537707161, disc_loss = 0.0002156839672191863
Trained batch 68 in epoch 16, gen_loss = 0.8837828765744749, disc_loss = 0.00021368908473169026
Trained batch 69 in epoch 16, gen_loss = 0.8848475864955357, disc_loss = 0.00021177320585203624
Trained batch 70 in epoch 16, gen_loss = 0.8851206965849433, disc_loss = 0.00021034061183585642
Trained batch 71 in epoch 16, gen_loss = 0.8832409655054411, disc_loss = 0.0002091246378768119
Trained batch 72 in epoch 16, gen_loss = 0.8847989227673779, disc_loss = 0.00021009533121872515
Trained batch 73 in epoch 16, gen_loss = 0.8861365100821933, disc_loss = 0.0002141682720370276
Trained batch 74 in epoch 16, gen_loss = 0.886287693977356, disc_loss = 0.00021797871944727375
Trained batch 75 in epoch 16, gen_loss = 0.8862469070836118, disc_loss = 0.00022142939068496497
Trained batch 76 in epoch 16, gen_loss = 0.8865744293510139, disc_loss = 0.00022393258849034907
Trained batch 77 in epoch 16, gen_loss = 0.8864717422387539, disc_loss = 0.00022639267402924955
Trained batch 78 in epoch 16, gen_loss = 0.8874524620514882, disc_loss = 0.00022735552156058175
Trained batch 79 in epoch 16, gen_loss = 0.888099054992199, disc_loss = 0.0002268604951495945
Trained batch 80 in epoch 16, gen_loss = 0.8890917948734613, disc_loss = 0.00022874095570224188
Trained batch 81 in epoch 16, gen_loss = 0.888976258475606, disc_loss = 0.00023181742423131676
Trained batch 82 in epoch 16, gen_loss = 0.8889765825616308, disc_loss = 0.00023206753517060642
Trained batch 83 in epoch 16, gen_loss = 0.8879696130752563, disc_loss = 0.00023447589384366957
Trained batch 84 in epoch 16, gen_loss = 0.8884276277878705, disc_loss = 0.00023500077684944056
Trained batch 85 in epoch 16, gen_loss = 0.888785523730655, disc_loss = 0.00023378228670903914
Trained batch 86 in epoch 16, gen_loss = 0.8890275009747209, disc_loss = 0.00023661828397481498
Trained batch 87 in epoch 16, gen_loss = 0.8896184780380942, disc_loss = 0.00023624132989590925
Trained batch 88 in epoch 16, gen_loss = 0.8893920464462108, disc_loss = 0.00023471998437333937
Trained batch 89 in epoch 16, gen_loss = 0.8899172710047828, disc_loss = 0.0002330964545965091
Trained batch 90 in epoch 16, gen_loss = 0.8893868870787568, disc_loss = 0.00023148314413936951
Trained batch 91 in epoch 16, gen_loss = 0.8892963768347449, disc_loss = 0.00023163314519637345
Trained batch 92 in epoch 16, gen_loss = 0.8897873906679051, disc_loss = 0.00024046422929317762
Trained batch 93 in epoch 16, gen_loss = 0.8900105953216553, disc_loss = 0.00024900417988550194
Trained batch 94 in epoch 16, gen_loss = 0.8898855642268532, disc_loss = 0.0002506431855420631
Trained batch 95 in epoch 16, gen_loss = 0.8902503754943609, disc_loss = 0.0002542880448951716
Trained batch 96 in epoch 16, gen_loss = 0.8894933320812344, disc_loss = 0.00025492442064299295
Trained batch 97 in epoch 16, gen_loss = 0.8899055190232336, disc_loss = 0.00025460637490531165
Trained batch 98 in epoch 16, gen_loss = 0.8897933177273682, disc_loss = 0.00025507783801812265
Trained batch 99 in epoch 16, gen_loss = 0.889645391702652, disc_loss = 0.00025493189808912576
Trained batch 100 in epoch 16, gen_loss = 0.8891338546677391, disc_loss = 0.000253863003920985
Trained batch 101 in epoch 16, gen_loss = 0.8878764171226352, disc_loss = 0.00025576177879474036
Trained batch 102 in epoch 16, gen_loss = 0.8878264687593701, disc_loss = 0.0002562006018847878
Trained batch 103 in epoch 16, gen_loss = 0.8885373146488116, disc_loss = 0.0002562186068994029
Trained batch 104 in epoch 16, gen_loss = 0.8876678461120242, disc_loss = 0.0002556487452238798
Trained batch 105 in epoch 16, gen_loss = 0.8880997418232683, disc_loss = 0.00025506720689832637
Trained batch 106 in epoch 16, gen_loss = 0.8878627770414976, disc_loss = 0.0002544860078933623
Trained batch 107 in epoch 16, gen_loss = 0.8871314895373804, disc_loss = 0.0002546291621843853
Trained batch 108 in epoch 16, gen_loss = 0.8876648430430562, disc_loss = 0.0002534833775166798
Trained batch 109 in epoch 16, gen_loss = 0.8875721205364574, disc_loss = 0.00025301937950478697
Trained batch 110 in epoch 16, gen_loss = 0.8871698164725089, disc_loss = 0.00025172182234257945
Trained batch 111 in epoch 16, gen_loss = 0.8870227810527597, disc_loss = 0.0002513109252504364
Trained batch 112 in epoch 16, gen_loss = 0.8865310243800678, disc_loss = 0.0002521359560927747
Trained batch 113 in epoch 16, gen_loss = 0.8866224053658938, disc_loss = 0.00025264235496012447
Trained batch 114 in epoch 16, gen_loss = 0.8869026106336843, disc_loss = 0.00025138409299593745
Trained batch 115 in epoch 16, gen_loss = 0.8867033504206558, disc_loss = 0.00025043829473674875
Trained batch 116 in epoch 16, gen_loss = 0.886676072055458, disc_loss = 0.0002516813742386925
Trained batch 117 in epoch 16, gen_loss = 0.8862968521603083, disc_loss = 0.0002609763962366634
Trained batch 118 in epoch 16, gen_loss = 0.8855369171174634, disc_loss = 0.00026629058968964496
Trained batch 119 in epoch 16, gen_loss = 0.8856814116239548, disc_loss = 0.0002675715945467042
Trained batch 120 in epoch 16, gen_loss = 0.8866037046613772, disc_loss = 0.0002710274406246964
Trained batch 121 in epoch 16, gen_loss = 0.8868409400103522, disc_loss = 0.0002719919437248657
Trained batch 122 in epoch 16, gen_loss = 0.8870532914874999, disc_loss = 0.0002726294307087404
Trained batch 123 in epoch 16, gen_loss = 0.8866810851520107, disc_loss = 0.0002716603412409313
Trained batch 124 in epoch 16, gen_loss = 0.8869606251716614, disc_loss = 0.0002715322545263916
Trained batch 125 in epoch 16, gen_loss = 0.8876983613248856, disc_loss = 0.0002706400004431738
Trained batch 126 in epoch 16, gen_loss = 0.8877408654671016, disc_loss = 0.00026921806196997483
Trained batch 127 in epoch 16, gen_loss = 0.8886695774272084, disc_loss = 0.00026788228484520005
Trained batch 128 in epoch 16, gen_loss = 0.8878902483356091, disc_loss = 0.0002665898774262308
Trained batch 129 in epoch 16, gen_loss = 0.8882644295692443, disc_loss = 0.00026658539287522076
Trained batch 130 in epoch 16, gen_loss = 0.8880548122274967, disc_loss = 0.00026652592945024587
Trained batch 131 in epoch 16, gen_loss = 0.8883436502832355, disc_loss = 0.0002661127740738624
Trained batch 132 in epoch 16, gen_loss = 0.888145185054693, disc_loss = 0.00026514849211290635
Trained batch 133 in epoch 16, gen_loss = 0.887609060575713, disc_loss = 0.00026425511988684353
Trained batch 134 in epoch 16, gen_loss = 0.8873915641396134, disc_loss = 0.00026375052688376013
Trained batch 135 in epoch 16, gen_loss = 0.8877850591259844, disc_loss = 0.0002625415064518593
Trained batch 136 in epoch 16, gen_loss = 0.8872274930459739, disc_loss = 0.0002611594635888723
Trained batch 137 in epoch 16, gen_loss = 0.8869557354761206, disc_loss = 0.000259969867962038
Trained batch 138 in epoch 16, gen_loss = 0.8857329775103562, disc_loss = 0.0002594966311681942
Trained batch 139 in epoch 16, gen_loss = 0.8854103020259312, disc_loss = 0.00025959202783789286
Trained batch 140 in epoch 16, gen_loss = 0.8851332554580472, disc_loss = 0.0002602835275923853
Trained batch 141 in epoch 16, gen_loss = 0.8854433172185656, disc_loss = 0.0002605104694429057
Trained batch 142 in epoch 16, gen_loss = 0.8857346527226322, disc_loss = 0.00025999547786061437
Trained batch 143 in epoch 16, gen_loss = 0.8855021554562781, disc_loss = 0.0002598062097705325
Trained batch 144 in epoch 16, gen_loss = 0.885685660099161, disc_loss = 0.00025884118066610897
Trained batch 145 in epoch 16, gen_loss = 0.8865526359375209, disc_loss = 0.0002580766147181985
Trained batch 146 in epoch 16, gen_loss = 0.887468316928059, disc_loss = 0.00025741484806735107
Trained batch 147 in epoch 16, gen_loss = 0.8869607674108969, disc_loss = 0.000256722283321889
Trained batch 148 in epoch 16, gen_loss = 0.8875557296228089, disc_loss = 0.00025567265953860816
Trained batch 149 in epoch 16, gen_loss = 0.888961644967397, disc_loss = 0.0002547581228524602
Trained batch 150 in epoch 16, gen_loss = 0.8884451855097385, disc_loss = 0.0002541283523993079
Trained batch 151 in epoch 16, gen_loss = 0.8876180354701845, disc_loss = 0.0002534995670717571
Trained batch 152 in epoch 16, gen_loss = 0.8879624223397449, disc_loss = 0.00025262998312778674
Trained batch 153 in epoch 16, gen_loss = 0.8882795986417052, disc_loss = 0.00025161099081553594
Trained batch 154 in epoch 16, gen_loss = 0.8879578217383354, disc_loss = 0.00025072736757612157
Trained batch 155 in epoch 16, gen_loss = 0.8876580546299616, disc_loss = 0.0002497469090135732
Trained batch 156 in epoch 16, gen_loss = 0.8879359592298034, disc_loss = 0.00024891011749659695
Trained batch 157 in epoch 16, gen_loss = 0.8886488151701191, disc_loss = 0.0002481362303402835
Trained batch 158 in epoch 16, gen_loss = 0.8890115956090531, disc_loss = 0.0002474853628093183
Trained batch 159 in epoch 16, gen_loss = 0.8894264444708824, disc_loss = 0.0002470938367423514
Trained batch 160 in epoch 16, gen_loss = 0.8889481965799509, disc_loss = 0.00024700935436333156
Trained batch 161 in epoch 16, gen_loss = 0.8896298169353862, disc_loss = 0.00024655341055929765
Trained batch 162 in epoch 16, gen_loss = 0.8890185125766357, disc_loss = 0.00024570139209622736
Trained batch 163 in epoch 16, gen_loss = 0.8897118244956179, disc_loss = 0.0002446278417553957
Trained batch 164 in epoch 16, gen_loss = 0.8898473591515512, disc_loss = 0.0002441600244668679
Trained batch 165 in epoch 16, gen_loss = 0.8896295367235161, disc_loss = 0.0002440542372922604
Trained batch 166 in epoch 16, gen_loss = 0.8893851859126977, disc_loss = 0.000243190488716013
Trained batch 167 in epoch 16, gen_loss = 0.8891581073403358, disc_loss = 0.0002425692718610489
Trained batch 168 in epoch 16, gen_loss = 0.8890700812875871, disc_loss = 0.00024149128109817366
Trained batch 169 in epoch 16, gen_loss = 0.8885824960820815, disc_loss = 0.00024159338808043258
Trained batch 170 in epoch 16, gen_loss = 0.8890558383618182, disc_loss = 0.0002424456740794867
Trained batch 171 in epoch 16, gen_loss = 0.8897703574147335, disc_loss = 0.00024310502458531626
Trained batch 172 in epoch 16, gen_loss = 0.8894966644358773, disc_loss = 0.00024330410874190314
Trained batch 173 in epoch 16, gen_loss = 0.8892017308322863, disc_loss = 0.0002424742724751818
Trained batch 174 in epoch 16, gen_loss = 0.8890849958147321, disc_loss = 0.0002418080231707011
Trained batch 175 in epoch 16, gen_loss = 0.8888804472305558, disc_loss = 0.00024106842383017383
Trained batch 176 in epoch 16, gen_loss = 0.8888781926052719, disc_loss = 0.0002406140972562871
Trained batch 177 in epoch 16, gen_loss = 0.8883937202142865, disc_loss = 0.0002406192107944948
Trained batch 178 in epoch 16, gen_loss = 0.8879590174339337, disc_loss = 0.0002403550263619123
Trained batch 179 in epoch 16, gen_loss = 0.8881247083346049, disc_loss = 0.0002393000132239346
Trained batch 180 in epoch 16, gen_loss = 0.8881045886166188, disc_loss = 0.0002385761730873942
Trained batch 181 in epoch 16, gen_loss = 0.8872794305885231, disc_loss = 0.0002383133698338617
Trained batch 182 in epoch 16, gen_loss = 0.8865464788968446, disc_loss = 0.00023922485885779054
Trained batch 183 in epoch 16, gen_loss = 0.8871821864791538, disc_loss = 0.0002389911214777385
Trained batch 184 in epoch 16, gen_loss = 0.8878968006855733, disc_loss = 0.00023934630047045397
Trained batch 185 in epoch 16, gen_loss = 0.8870717392813775, disc_loss = 0.00023967043213610117
Trained batch 186 in epoch 16, gen_loss = 0.8868652827599469, disc_loss = 0.00023961311185522065
Trained batch 187 in epoch 16, gen_loss = 0.8865796165897492, disc_loss = 0.00023971029854982724
Trained batch 188 in epoch 16, gen_loss = 0.8865887333476354, disc_loss = 0.00024062922287075756
Trained batch 189 in epoch 16, gen_loss = 0.8862057927407716, disc_loss = 0.00024178444532720422
Trained batch 190 in epoch 16, gen_loss = 0.8859889282606035, disc_loss = 0.0002423497443730426
Trained batch 191 in epoch 16, gen_loss = 0.8863441273570061, disc_loss = 0.0002423314339997281
Trained batch 192 in epoch 16, gen_loss = 0.8865898223738596, disc_loss = 0.00024227094648790744
Trained batch 193 in epoch 16, gen_loss = 0.8859074097318748, disc_loss = 0.00024178940961083406
Trained batch 194 in epoch 16, gen_loss = 0.8861091956114158, disc_loss = 0.00024210620005107604
Trained batch 195 in epoch 16, gen_loss = 0.8864677280795817, disc_loss = 0.00024204521146109945
Trained batch 196 in epoch 16, gen_loss = 0.8856547653372517, disc_loss = 0.00024982613055915976
Trained batch 197 in epoch 16, gen_loss = 0.885188740311247, disc_loss = 0.00025941679393666836
Trained batch 198 in epoch 16, gen_loss = 0.8850119841757731, disc_loss = 0.000262515008838288
Trained batch 199 in epoch 16, gen_loss = 0.885393678843975, disc_loss = 0.0002647597589020734
Trained batch 200 in epoch 16, gen_loss = 0.8856713303286045, disc_loss = 0.00026474221189192436
Trained batch 201 in epoch 16, gen_loss = 0.885747488772515, disc_loss = 0.00026465262884146185
Trained batch 202 in epoch 16, gen_loss = 0.8858945319805239, disc_loss = 0.00026402365347614803
Trained batch 203 in epoch 16, gen_loss = 0.8855320501561258, disc_loss = 0.00026355023278572877
Trained batch 204 in epoch 16, gen_loss = 0.8856529357956677, disc_loss = 0.0002629504951140162
Trained batch 205 in epoch 16, gen_loss = 0.8860477261172915, disc_loss = 0.0002623523022989105
Trained batch 206 in epoch 16, gen_loss = 0.8861365347092854, disc_loss = 0.0002621381873209232
Trained batch 207 in epoch 16, gen_loss = 0.8861772160117443, disc_loss = 0.0002616983075453251
Trained batch 208 in epoch 16, gen_loss = 0.8861385292984082, disc_loss = 0.00026200817124088154
Trained batch 209 in epoch 16, gen_loss = 0.8863881917226882, disc_loss = 0.00026260420435435315
Trained batch 210 in epoch 16, gen_loss = 0.8864406488518014, disc_loss = 0.0002621832018250807
Trained batch 211 in epoch 16, gen_loss = 0.886139452738582, disc_loss = 0.00026141769324927944
Trained batch 212 in epoch 16, gen_loss = 0.8860670065096287, disc_loss = 0.00026080054098449456
Trained batch 213 in epoch 16, gen_loss = 0.8860103652299007, disc_loss = 0.0002602740248994876
Trained batch 214 in epoch 16, gen_loss = 0.8860559269439342, disc_loss = 0.0002604723637950672
Trained batch 215 in epoch 16, gen_loss = 0.8862320499287711, disc_loss = 0.00026037592828355693
Trained batch 216 in epoch 16, gen_loss = 0.8862129515766548, disc_loss = 0.0002601369866706465
Trained batch 217 in epoch 16, gen_loss = 0.8863462182359958, disc_loss = 0.0002600431365896563
Trained batch 218 in epoch 16, gen_loss = 0.8860252932326435, disc_loss = 0.00026049435332196354
Trained batch 219 in epoch 16, gen_loss = 0.8859663489190015, disc_loss = 0.00026060138704699716
Trained batch 220 in epoch 16, gen_loss = 0.8858484318353471, disc_loss = 0.0002601705772704255
Trained batch 221 in epoch 16, gen_loss = 0.8859532365390846, disc_loss = 0.00025937342942196264
Trained batch 222 in epoch 16, gen_loss = 0.8859517937818451, disc_loss = 0.0002608713888051093
Trained batch 223 in epoch 16, gen_loss = 0.885836581566504, disc_loss = 0.00026102661932522357
Trained batch 224 in epoch 16, gen_loss = 0.8855446656545003, disc_loss = 0.0002613735571180263
Trained batch 225 in epoch 16, gen_loss = 0.8858352060866567, disc_loss = 0.00026108666964568634
Trained batch 226 in epoch 16, gen_loss = 0.8852559433109435, disc_loss = 0.0002620198058042909
Trained batch 227 in epoch 16, gen_loss = 0.8848546646666109, disc_loss = 0.0002624253970440661
Trained batch 228 in epoch 16, gen_loss = 0.8852218717466795, disc_loss = 0.0002624445501625981
Trained batch 229 in epoch 16, gen_loss = 0.8855695252833159, disc_loss = 0.0002627060965333721
Trained batch 230 in epoch 16, gen_loss = 0.8859688776396054, disc_loss = 0.0002630365811436018
Trained batch 231 in epoch 16, gen_loss = 0.886065372362219, disc_loss = 0.0002630800130771541
Trained batch 232 in epoch 16, gen_loss = 0.8856987024581483, disc_loss = 0.00026306844893628093
Trained batch 233 in epoch 16, gen_loss = 0.8855521126180632, disc_loss = 0.00026264676327830076
Trained batch 234 in epoch 16, gen_loss = 0.8864561179850964, disc_loss = 0.00026225054235955544
Trained batch 235 in epoch 16, gen_loss = 0.8864093304185544, disc_loss = 0.0002622373210785662
Trained batch 236 in epoch 16, gen_loss = 0.8867554863293966, disc_loss = 0.0002617912803482331
Trained batch 237 in epoch 16, gen_loss = 0.8873060333127735, disc_loss = 0.00026130534134616393
Trained batch 238 in epoch 16, gen_loss = 0.8871011447208197, disc_loss = 0.0002608054513771722
Trained batch 239 in epoch 16, gen_loss = 0.8870867528021336, disc_loss = 0.0002603111384511673
Trained batch 240 in epoch 16, gen_loss = 0.8871583033399463, disc_loss = 0.0002598220670435875
Trained batch 241 in epoch 16, gen_loss = 0.8868904315735683, disc_loss = 0.00025918083052556913
Trained batch 242 in epoch 16, gen_loss = 0.8864370925436295, disc_loss = 0.0002585736385651063
Trained batch 243 in epoch 16, gen_loss = 0.8863309521655567, disc_loss = 0.00025793345868477756
Trained batch 244 in epoch 16, gen_loss = 0.8864231374798989, disc_loss = 0.00025727364691378245
Trained batch 245 in epoch 16, gen_loss = 0.8863729710985975, disc_loss = 0.0002564356495340911
Trained batch 246 in epoch 16, gen_loss = 0.8866627670010092, disc_loss = 0.00025566222987100974
Trained batch 247 in epoch 16, gen_loss = 0.8864169108771509, disc_loss = 0.00025525400489582794
Trained batch 248 in epoch 16, gen_loss = 0.8861838701259659, disc_loss = 0.00025505253651350487
Trained batch 249 in epoch 16, gen_loss = 0.8862972931861878, disc_loss = 0.00025447631982387974
Trained batch 250 in epoch 16, gen_loss = 0.8862490371403942, disc_loss = 0.0002537739737491788
Trained batch 251 in epoch 16, gen_loss = 0.8862774781291447, disc_loss = 0.0002529880344982736
Trained batch 252 in epoch 16, gen_loss = 0.8865595921697352, disc_loss = 0.00025238711305244243
Trained batch 253 in epoch 16, gen_loss = 0.8868548304546536, disc_loss = 0.0002519851199266002
Trained batch 254 in epoch 16, gen_loss = 0.8867940996207443, disc_loss = 0.00025182308671384246
Trained batch 255 in epoch 16, gen_loss = 0.8869943362660706, disc_loss = 0.0002513018312413351
Trained batch 256 in epoch 16, gen_loss = 0.8873549546713031, disc_loss = 0.00025087785256500193
Trained batch 257 in epoch 16, gen_loss = 0.8878207091213197, disc_loss = 0.0002507908523744676
Trained batch 258 in epoch 16, gen_loss = 0.8877376663178551, disc_loss = 0.00025085413735337434
Trained batch 259 in epoch 16, gen_loss = 0.8880664091843825, disc_loss = 0.0002502628062827101
Trained batch 260 in epoch 16, gen_loss = 0.8879412220812392, disc_loss = 0.00024962536177742454
Trained batch 261 in epoch 16, gen_loss = 0.887559876187157, disc_loss = 0.0002492207047158056
Trained batch 262 in epoch 16, gen_loss = 0.8872625043636946, disc_loss = 0.00024869719450716144
Trained batch 263 in epoch 16, gen_loss = 0.8872404536514571, disc_loss = 0.00024828434867562134
Trained batch 264 in epoch 16, gen_loss = 0.8869086409514805, disc_loss = 0.0002478981377416343
Trained batch 265 in epoch 16, gen_loss = 0.8868033729101482, disc_loss = 0.00024751980373893226
Trained batch 266 in epoch 16, gen_loss = 0.886930590488491, disc_loss = 0.0002472218227322468
Trained batch 267 in epoch 16, gen_loss = 0.8865568720137895, disc_loss = 0.0002466539114463028
Trained batch 268 in epoch 16, gen_loss = 0.8865372578450739, disc_loss = 0.00024600995231837856
Trained batch 269 in epoch 16, gen_loss = 0.8865208628001037, disc_loss = 0.00024535413925790364
Trained batch 270 in epoch 16, gen_loss = 0.8863259006250388, disc_loss = 0.00024475415852724154
Trained batch 271 in epoch 16, gen_loss = 0.88608944131171, disc_loss = 0.00024439299188409625
Trained batch 272 in epoch 16, gen_loss = 0.8863617044228774, disc_loss = 0.0002443983407779392
Trained batch 273 in epoch 16, gen_loss = 0.886338905478916, disc_loss = 0.0002443399565771518
Trained batch 274 in epoch 16, gen_loss = 0.8861963406476108, disc_loss = 0.0002443003172679296
Trained batch 275 in epoch 16, gen_loss = 0.8858507193516993, disc_loss = 0.00024371309684837522
Trained batch 276 in epoch 16, gen_loss = 0.8859730575919582, disc_loss = 0.00024317892729863692
Trained batch 277 in epoch 16, gen_loss = 0.8862153832003367, disc_loss = 0.00024257191516422974
Trained batch 278 in epoch 16, gen_loss = 0.8861347498859556, disc_loss = 0.00024237802059086722
Trained batch 279 in epoch 16, gen_loss = 0.8863392189145088, disc_loss = 0.00024189432905196944
Trained batch 280 in epoch 16, gen_loss = 0.8860294780697262, disc_loss = 0.00024161361469854053
Trained batch 281 in epoch 16, gen_loss = 0.8863705660857207, disc_loss = 0.00024148400062579557
Trained batch 282 in epoch 16, gen_loss = 0.886187156813726, disc_loss = 0.00024120128569982997
Trained batch 283 in epoch 16, gen_loss = 0.8864556863694124, disc_loss = 0.00024100299371229353
Trained batch 284 in epoch 16, gen_loss = 0.8866085619257208, disc_loss = 0.0002405269556778908
Trained batch 285 in epoch 16, gen_loss = 0.8865782339256126, disc_loss = 0.00024043446123519412
Trained batch 286 in epoch 16, gen_loss = 0.8862106019196194, disc_loss = 0.00024024279515250045
Trained batch 287 in epoch 16, gen_loss = 0.8865383795152108, disc_loss = 0.00024028265652810255
Trained batch 288 in epoch 16, gen_loss = 0.8864489436974575, disc_loss = 0.0002399764403531241
Trained batch 289 in epoch 16, gen_loss = 0.8863710294509756, disc_loss = 0.00023971703327521843
Trained batch 290 in epoch 16, gen_loss = 0.8864471379833943, disc_loss = 0.0002394253857358986
Trained batch 291 in epoch 16, gen_loss = 0.8863565203261702, disc_loss = 0.0002394067396879059
Trained batch 292 in epoch 16, gen_loss = 0.8863809503386045, disc_loss = 0.00023962390025916315
Trained batch 293 in epoch 16, gen_loss = 0.8864954120042373, disc_loss = 0.0002399689494800472
Trained batch 294 in epoch 16, gen_loss = 0.8864780605849573, disc_loss = 0.00023968091682961086
Trained batch 295 in epoch 16, gen_loss = 0.8861236074889028, disc_loss = 0.00023925819496562817
Trained batch 296 in epoch 16, gen_loss = 0.8864663443982802, disc_loss = 0.00023868639828199804
Trained batch 297 in epoch 16, gen_loss = 0.8865236467963097, disc_loss = 0.00023823802438216915
Trained batch 298 in epoch 16, gen_loss = 0.8865981891402432, disc_loss = 0.00023794178805687
Trained batch 299 in epoch 16, gen_loss = 0.8866300133864085, disc_loss = 0.0002375503817408268
Trained batch 300 in epoch 16, gen_loss = 0.8864588343423863, disc_loss = 0.0002370866671259874
Trained batch 301 in epoch 16, gen_loss = 0.8866902461509831, disc_loss = 0.0002369414957882821
Trained batch 302 in epoch 16, gen_loss = 0.8862969474037095, disc_loss = 0.0002368403002517928
Trained batch 303 in epoch 16, gen_loss = 0.8862082799406428, disc_loss = 0.00023658317808152978
Trained batch 304 in epoch 16, gen_loss = 0.8862081844298566, disc_loss = 0.00023639686012041341
Trained batch 305 in epoch 16, gen_loss = 0.8859879690058091, disc_loss = 0.0002359294053557058
Trained batch 306 in epoch 16, gen_loss = 0.8857283704832245, disc_loss = 0.00023537143736987462
Trained batch 307 in epoch 16, gen_loss = 0.8856500793587078, disc_loss = 0.00023496906425106163
Trained batch 308 in epoch 16, gen_loss = 0.8857859465682391, disc_loss = 0.00023485728335422901
Trained batch 309 in epoch 16, gen_loss = 0.8860407252465525, disc_loss = 0.00023477395638286496
Trained batch 310 in epoch 16, gen_loss = 0.8859558090136366, disc_loss = 0.00023432222032231516
Trained batch 311 in epoch 16, gen_loss = 0.8854959043554771, disc_loss = 0.00023436434847285572
Trained batch 312 in epoch 16, gen_loss = 0.8851609266223237, disc_loss = 0.00023472210905717733
Trained batch 313 in epoch 16, gen_loss = 0.8852700463905456, disc_loss = 0.000234923364987017
Trained batch 314 in epoch 16, gen_loss = 0.8853110481822302, disc_loss = 0.000235052774073593
Trained batch 315 in epoch 16, gen_loss = 0.8856255955333951, disc_loss = 0.00023490725871403202
Trained batch 316 in epoch 16, gen_loss = 0.8856895473853271, disc_loss = 0.00023475068139609343
Trained batch 317 in epoch 16, gen_loss = 0.8858111744406838, disc_loss = 0.0002345743271935535
Trained batch 318 in epoch 16, gen_loss = 0.8854166205773907, disc_loss = 0.00023436426974889212
Trained batch 319 in epoch 16, gen_loss = 0.8852450240403413, disc_loss = 0.00023387089895550163
Trained batch 320 in epoch 16, gen_loss = 0.8852212753994071, disc_loss = 0.00023353708174654117
Trained batch 321 in epoch 16, gen_loss = 0.8854791031490942, disc_loss = 0.00023356450943786777
Trained batch 322 in epoch 16, gen_loss = 0.8858542588104036, disc_loss = 0.00023366116087677552
Trained batch 323 in epoch 16, gen_loss = 0.8858106472977886, disc_loss = 0.0002334499455892113
Trained batch 324 in epoch 16, gen_loss = 0.8857020941147438, disc_loss = 0.00023302266860040477
Trained batch 325 in epoch 16, gen_loss = 0.8854035418823453, disc_loss = 0.00023266604258853833
Trained batch 326 in epoch 16, gen_loss = 0.8852766214525298, disc_loss = 0.0002321709489534589
Trained batch 327 in epoch 16, gen_loss = 0.8850175463935224, disc_loss = 0.00023181346167381513
Trained batch 328 in epoch 16, gen_loss = 0.8848102393483681, disc_loss = 0.00023149420009390946
Trained batch 329 in epoch 16, gen_loss = 0.8848792126684478, disc_loss = 0.00023143697582065324
Trained batch 330 in epoch 16, gen_loss = 0.8848037797158579, disc_loss = 0.00023112305316207453
Trained batch 331 in epoch 16, gen_loss = 0.8847779911684702, disc_loss = 0.0002308708607010173
Trained batch 332 in epoch 16, gen_loss = 0.8849168086911107, disc_loss = 0.00023050926858297053
Trained batch 333 in epoch 16, gen_loss = 0.8851303947186042, disc_loss = 0.00023010158171988103
Trained batch 334 in epoch 16, gen_loss = 0.8853883369645076, disc_loss = 0.00022974470656351255
Trained batch 335 in epoch 16, gen_loss = 0.8853663073054382, disc_loss = 0.0002293322401480206
Trained batch 336 in epoch 16, gen_loss = 0.8853454655285051, disc_loss = 0.00022899225375439574
Trained batch 337 in epoch 16, gen_loss = 0.8855895620478681, disc_loss = 0.00022858573410459572
Trained batch 338 in epoch 16, gen_loss = 0.8856097850124393, disc_loss = 0.00022828346017454847
Trained batch 339 in epoch 16, gen_loss = 0.8854610825286192, disc_loss = 0.00022823056148327475
Trained batch 340 in epoch 16, gen_loss = 0.8853359337775938, disc_loss = 0.00022796113781861093
Trained batch 341 in epoch 16, gen_loss = 0.8851977025556286, disc_loss = 0.000227599282720404
Trained batch 342 in epoch 16, gen_loss = 0.8852087987407651, disc_loss = 0.0002273746813496754
Trained batch 343 in epoch 16, gen_loss = 0.8853571881041971, disc_loss = 0.00022712016026733096
Trained batch 344 in epoch 16, gen_loss = 0.8855943748916405, disc_loss = 0.0002268280592693043
Trained batch 345 in epoch 16, gen_loss = 0.8854501157826771, disc_loss = 0.00022640648433222636
Trained batch 346 in epoch 16, gen_loss = 0.8856805696954645, disc_loss = 0.00022611524359529746
Trained batch 347 in epoch 16, gen_loss = 0.8853811676474823, disc_loss = 0.0002256399037697133
Trained batch 348 in epoch 16, gen_loss = 0.8856910303192357, disc_loss = 0.00022514786215888986
Trained batch 349 in epoch 16, gen_loss = 0.8860519473893301, disc_loss = 0.00022521059981954749
Trained batch 350 in epoch 16, gen_loss = 0.8861618072558672, disc_loss = 0.00022534014044757044
Trained batch 351 in epoch 16, gen_loss = 0.8861086951060728, disc_loss = 0.00022511814202888755
Trained batch 352 in epoch 16, gen_loss = 0.8860218055525177, disc_loss = 0.0002248241177404058
Trained batch 353 in epoch 16, gen_loss = 0.8859403116554864, disc_loss = 0.00022454540681011387
Trained batch 354 in epoch 16, gen_loss = 0.8858619006586747, disc_loss = 0.0002241980229421604
Trained batch 355 in epoch 16, gen_loss = 0.886028595185012, disc_loss = 0.00022402805596643345
Trained batch 356 in epoch 16, gen_loss = 0.8860549522715122, disc_loss = 0.00022390906272267894
Trained batch 357 in epoch 16, gen_loss = 0.8857714577094137, disc_loss = 0.0002238476299172672
Trained batch 358 in epoch 16, gen_loss = 0.8854540677787865, disc_loss = 0.00022394688014052276
Trained batch 359 in epoch 16, gen_loss = 0.8856856457061237, disc_loss = 0.00022393722820197582
Trained batch 360 in epoch 16, gen_loss = 0.8854817150372217, disc_loss = 0.00022393290349596742
Trained batch 361 in epoch 16, gen_loss = 0.8853835850460094, disc_loss = 0.00022398397939378404
Trained batch 362 in epoch 16, gen_loss = 0.8853734510004028, disc_loss = 0.00022392950312209768
Trained batch 363 in epoch 16, gen_loss = 0.8851828449047529, disc_loss = 0.000223621522139353
Trained batch 364 in epoch 16, gen_loss = 0.8852610165125703, disc_loss = 0.00022320834801600902
Trained batch 365 in epoch 16, gen_loss = 0.8851899136611021, disc_loss = 0.00022269768207300585
Trained batch 366 in epoch 16, gen_loss = 0.8849277892619453, disc_loss = 0.00022228596667111698
Trained batch 367 in epoch 16, gen_loss = 0.8852317271673161, disc_loss = 0.00022201335958055532
Trained batch 368 in epoch 16, gen_loss = 0.8848926113226873, disc_loss = 0.0002217018300537897
Trained batch 369 in epoch 16, gen_loss = 0.8847404943930136, disc_loss = 0.00022158876404196112
Trained batch 370 in epoch 16, gen_loss = 0.8846320543649062, disc_loss = 0.00022187159522654641
Trained batch 371 in epoch 16, gen_loss = 0.8846959029474566, disc_loss = 0.0002221105322791783
Trained batch 372 in epoch 16, gen_loss = 0.8845863813689183, disc_loss = 0.00022216084724048404
Trained batch 373 in epoch 16, gen_loss = 0.8844157325073997, disc_loss = 0.00022218805445159878
Trained batch 374 in epoch 16, gen_loss = 0.8844329713185628, disc_loss = 0.0002221821708662901
Trained batch 375 in epoch 16, gen_loss = 0.884627750262301, disc_loss = 0.0002219975200456789
Trained batch 376 in epoch 16, gen_loss = 0.8847942485101027, disc_loss = 0.00022172665232009705
Trained batch 377 in epoch 16, gen_loss = 0.8851212370332586, disc_loss = 0.00022138050906832894
Trained batch 378 in epoch 16, gen_loss = 0.8852614482034165, disc_loss = 0.00022104921883227374
Trained batch 379 in epoch 16, gen_loss = 0.8852015385502263, disc_loss = 0.00022067607252737568
Trained batch 380 in epoch 16, gen_loss = 0.8849741492684432, disc_loss = 0.00022026877256568333
Trained batch 381 in epoch 16, gen_loss = 0.8851914571217842, disc_loss = 0.0002200264083303076
Trained batch 382 in epoch 16, gen_loss = 0.8852601675389641, disc_loss = 0.00021973874144809013
Trained batch 383 in epoch 16, gen_loss = 0.8851302292508384, disc_loss = 0.00021938894209938553
Trained batch 384 in epoch 16, gen_loss = 0.8847786093687082, disc_loss = 0.00021926168925559764
Trained batch 385 in epoch 16, gen_loss = 0.8847567280030622, disc_loss = 0.0002193164117496317
Trained batch 386 in epoch 16, gen_loss = 0.8846857707937866, disc_loss = 0.00021948185766084802
Trained batch 387 in epoch 16, gen_loss = 0.8849160056753257, disc_loss = 0.00021942077954421264
Trained batch 388 in epoch 16, gen_loss = 0.8846560172679185, disc_loss = 0.0002191696609903856
Trained batch 389 in epoch 16, gen_loss = 0.8849274962376326, disc_loss = 0.0002189370173418399
Trained batch 390 in epoch 16, gen_loss = 0.8848410157291481, disc_loss = 0.00021883840309618258
Trained batch 391 in epoch 16, gen_loss = 0.8850605607945092, disc_loss = 0.00021867772914317487
Trained batch 392 in epoch 16, gen_loss = 0.8851075977769517, disc_loss = 0.00021854343362315203
Trained batch 393 in epoch 16, gen_loss = 0.8852231358816176, disc_loss = 0.00021877096166698614
Trained batch 394 in epoch 16, gen_loss = 0.8852066011368473, disc_loss = 0.00021876876753249466
Trained batch 395 in epoch 16, gen_loss = 0.8849245704183675, disc_loss = 0.0002186557975885925
Trained batch 396 in epoch 16, gen_loss = 0.8846337571552478, disc_loss = 0.00021861318012405368
Trained batch 397 in epoch 16, gen_loss = 0.8846813166261318, disc_loss = 0.00021843576561064336
Trained batch 398 in epoch 16, gen_loss = 0.8847456702911166, disc_loss = 0.00021843446339610417
Trained batch 399 in epoch 16, gen_loss = 0.8847328092157841, disc_loss = 0.00021873852719181741
Trained batch 400 in epoch 16, gen_loss = 0.8846645710474238, disc_loss = 0.00021856387197964668
Trained batch 401 in epoch 16, gen_loss = 0.8844789505301424, disc_loss = 0.00021829347868297373
Trained batch 402 in epoch 16, gen_loss = 0.8843777225567744, disc_loss = 0.0002181916546846235
Trained batch 403 in epoch 16, gen_loss = 0.8841677929210191, disc_loss = 0.00021791585402410204
Trained batch 404 in epoch 16, gen_loss = 0.8838059859511292, disc_loss = 0.00021773142684258255
Trained batch 405 in epoch 16, gen_loss = 0.8837559280430742, disc_loss = 0.00021761512049088734
Trained batch 406 in epoch 16, gen_loss = 0.8834578239654147, disc_loss = 0.0002175115766702363
Trained batch 407 in epoch 16, gen_loss = 0.8835281465275615, disc_loss = 0.00021752345446657273
Trained batch 408 in epoch 16, gen_loss = 0.8840174428699652, disc_loss = 0.00021741884021541903
Trained batch 409 in epoch 16, gen_loss = 0.883985505307593, disc_loss = 0.0002172360977277915
Trained batch 410 in epoch 16, gen_loss = 0.8843124996136574, disc_loss = 0.00021789116479764884
Trained batch 411 in epoch 16, gen_loss = 0.8841342805948073, disc_loss = 0.00021861493980430928
Trained batch 412 in epoch 16, gen_loss = 0.8840624473574087, disc_loss = 0.00021864575331673514
Trained batch 413 in epoch 16, gen_loss = 0.8839422365029653, disc_loss = 0.00021857828516289558
Trained batch 414 in epoch 16, gen_loss = 0.8840489377458411, disc_loss = 0.00021874330832141856
Trained batch 415 in epoch 16, gen_loss = 0.8842834237103279, disc_loss = 0.0002189201337614577
Trained batch 416 in epoch 16, gen_loss = 0.8844736379971035, disc_loss = 0.0002186453064286783
Trained batch 417 in epoch 16, gen_loss = 0.8843653835177991, disc_loss = 0.0002184517389045985
Trained batch 418 in epoch 16, gen_loss = 0.8842809114934151, disc_loss = 0.00021861496981493694
Trained batch 419 in epoch 16, gen_loss = 0.8843512817507698, disc_loss = 0.00021842754654027797
Trained batch 420 in epoch 16, gen_loss = 0.8843403209416714, disc_loss = 0.00021825254794865273
Trained batch 421 in epoch 16, gen_loss = 0.8844223275286327, disc_loss = 0.0002181176256634084
Trained batch 422 in epoch 16, gen_loss = 0.8842751590918142, disc_loss = 0.00021781167690566495
Trained batch 423 in epoch 16, gen_loss = 0.8842049626246938, disc_loss = 0.00021748288841167177
Trained batch 424 in epoch 16, gen_loss = 0.8844597406948314, disc_loss = 0.00021711303748923134
Trained batch 425 in epoch 16, gen_loss = 0.884754523425035, disc_loss = 0.00021686743547916663
Trained batch 426 in epoch 16, gen_loss = 0.8845322086046116, disc_loss = 0.00021672034357199762
Trained batch 427 in epoch 16, gen_loss = 0.8845301795507146, disc_loss = 0.00021676562217554614
Trained batch 428 in epoch 16, gen_loss = 0.884488025050619, disc_loss = 0.0002166264047783106
Trained batch 429 in epoch 16, gen_loss = 0.8842523218587387, disc_loss = 0.00021633324349538673
Trained batch 430 in epoch 16, gen_loss = 0.8843307809044203, disc_loss = 0.000216002790187445
Trained batch 431 in epoch 16, gen_loss = 0.8845070567395952, disc_loss = 0.00021584175139347886
Trained batch 432 in epoch 16, gen_loss = 0.8844712207278809, disc_loss = 0.0002156388534609509
Trained batch 433 in epoch 16, gen_loss = 0.8841652914126348, disc_loss = 0.00021536326192474702
Trained batch 434 in epoch 16, gen_loss = 0.8840268000789072, disc_loss = 0.00021523467445546686
Trained batch 435 in epoch 16, gen_loss = 0.8840552110464202, disc_loss = 0.00021538459869263718
Trained batch 436 in epoch 16, gen_loss = 0.8842359174307206, disc_loss = 0.00021552129922048678
Trained batch 437 in epoch 16, gen_loss = 0.8841051675685464, disc_loss = 0.0002156008054729159
Trained batch 438 in epoch 16, gen_loss = 0.8840174388505332, disc_loss = 0.00021576792707475557
Trained batch 439 in epoch 16, gen_loss = 0.8839886298233812, disc_loss = 0.00021583118752294632
Trained batch 440 in epoch 16, gen_loss = 0.8838367909530934, disc_loss = 0.0002157102137140253
Trained batch 441 in epoch 16, gen_loss = 0.8837758198852452, disc_loss = 0.00021537868345383612
Trained batch 442 in epoch 16, gen_loss = 0.8838161382126216, disc_loss = 0.00021521406550648617
Trained batch 443 in epoch 16, gen_loss = 0.8837593342806842, disc_loss = 0.00021502628156291016
Trained batch 444 in epoch 16, gen_loss = 0.8838787105646027, disc_loss = 0.0002149284779917569
Trained batch 445 in epoch 16, gen_loss = 0.884110088305623, disc_loss = 0.00021498089964988885
Trained batch 446 in epoch 16, gen_loss = 0.8840849426235395, disc_loss = 0.000215251801719551
Trained batch 447 in epoch 16, gen_loss = 0.8841919156589678, disc_loss = 0.00021516088017798602
Trained batch 448 in epoch 16, gen_loss = 0.8843180259776806, disc_loss = 0.00021491102040347327
Trained batch 449 in epoch 16, gen_loss = 0.8841274311807421, disc_loss = 0.00021462918418466061
Trained batch 450 in epoch 16, gen_loss = 0.8839272178726028, disc_loss = 0.0002143702473815509
Trained batch 451 in epoch 16, gen_loss = 0.8838396628873538, disc_loss = 0.0002144321197031794
Trained batch 452 in epoch 16, gen_loss = 0.8838173887850697, disc_loss = 0.00021498160840444642
Trained batch 453 in epoch 16, gen_loss = 0.8838462826964089, disc_loss = 0.000214990459057584
Trained batch 454 in epoch 16, gen_loss = 0.8840751049282787, disc_loss = 0.0002148536030010571
Trained batch 455 in epoch 16, gen_loss = 0.8842536303819272, disc_loss = 0.00021459483348320517
Trained batch 456 in epoch 16, gen_loss = 0.8843243725972832, disc_loss = 0.00021438281334669397
Trained batch 457 in epoch 16, gen_loss = 0.8843126524744076, disc_loss = 0.00021416060581548377
Trained batch 458 in epoch 16, gen_loss = 0.8842601013858853, disc_loss = 0.0002139616228071572
Trained batch 459 in epoch 16, gen_loss = 0.8845094780559125, disc_loss = 0.00021399324855535625
Trained batch 460 in epoch 16, gen_loss = 0.884563051180312, disc_loss = 0.00021397693696111864
Trained batch 461 in epoch 16, gen_loss = 0.8849602563556654, disc_loss = 0.00021383203024472245
Trained batch 462 in epoch 16, gen_loss = 0.8850278752668888, disc_loss = 0.00021409933524842165
Trained batch 463 in epoch 16, gen_loss = 0.8851252072330179, disc_loss = 0.00021420894986163305
Trained batch 464 in epoch 16, gen_loss = 0.8850552251262049, disc_loss = 0.00021411880331460677
Trained batch 465 in epoch 16, gen_loss = 0.8851255234730602, disc_loss = 0.0002138549319642437
Trained batch 466 in epoch 16, gen_loss = 0.8849978069166555, disc_loss = 0.0002136280866441635
Trained batch 467 in epoch 16, gen_loss = 0.8851086726555457, disc_loss = 0.00021335197761489434
Trained batch 468 in epoch 16, gen_loss = 0.8849954950784061, disc_loss = 0.00021302427042279142
Trained batch 469 in epoch 16, gen_loss = 0.8848009588870597, disc_loss = 0.00021282255001232384
Trained batch 470 in epoch 16, gen_loss = 0.8847335093593395, disc_loss = 0.00021248737163897337
Trained batch 471 in epoch 16, gen_loss = 0.884612085202993, disc_loss = 0.0002121651514398301
Trained batch 472 in epoch 16, gen_loss = 0.8847945851705039, disc_loss = 0.0002120249216721923
Trained batch 473 in epoch 16, gen_loss = 0.8848574548833984, disc_loss = 0.0002125195386406439
Trained batch 474 in epoch 16, gen_loss = 0.8847693165979887, disc_loss = 0.0002132358019374997
Trained batch 475 in epoch 16, gen_loss = 0.8848519183757926, disc_loss = 0.00021357629361964505
Trained batch 476 in epoch 16, gen_loss = 0.8846541315754505, disc_loss = 0.00021338158069164796
Trained batch 477 in epoch 16, gen_loss = 0.8846707347796053, disc_loss = 0.00021335455277500184
Trained batch 478 in epoch 16, gen_loss = 0.8847400136680842, disc_loss = 0.0002131742599156796
Trained batch 479 in epoch 16, gen_loss = 0.8847878735512495, disc_loss = 0.00021295942910910527
Trained batch 480 in epoch 16, gen_loss = 0.8847112743621557, disc_loss = 0.0002126861902160992
Trained batch 481 in epoch 16, gen_loss = 0.8848370628980186, disc_loss = 0.000212408280646413
Trained batch 482 in epoch 16, gen_loss = 0.8850400241759006, disc_loss = 0.00021219717178218487
Trained batch 483 in epoch 16, gen_loss = 0.8852521788236524, disc_loss = 0.00021194080742615302
Trained batch 484 in epoch 16, gen_loss = 0.8851775534374198, disc_loss = 0.00021164429740987468
Trained batch 485 in epoch 16, gen_loss = 0.8852361143861779, disc_loss = 0.00021144485296566544
Trained batch 486 in epoch 16, gen_loss = 0.8853204147526861, disc_loss = 0.00021133619430307605
Trained batch 487 in epoch 16, gen_loss = 0.8854780668606523, disc_loss = 0.00021130397237625477
Trained batch 488 in epoch 16, gen_loss = 0.8851946702032732, disc_loss = 0.00021155458842385142
Trained batch 489 in epoch 16, gen_loss = 0.8853250296748414, disc_loss = 0.00021197858548067434
Trained batch 490 in epoch 16, gen_loss = 0.8853003949594594, disc_loss = 0.00021258952735559046
Trained batch 491 in epoch 16, gen_loss = 0.8852491144969211, disc_loss = 0.00021330600554015625
Trained batch 492 in epoch 16, gen_loss = 0.8853481939066254, disc_loss = 0.00021364727424945054
Trained batch 493 in epoch 16, gen_loss = 0.8851872488313358, disc_loss = 0.00021378108674258763
Trained batch 494 in epoch 16, gen_loss = 0.8851036805095095, disc_loss = 0.00021379726522630362
Trained batch 495 in epoch 16, gen_loss = 0.8851906500997082, disc_loss = 0.00021373185277738112
Trained batch 496 in epoch 16, gen_loss = 0.885306041485347, disc_loss = 0.00021369977397080585
Trained batch 497 in epoch 16, gen_loss = 0.8853990928715013, disc_loss = 0.00021391544356286698
Trained batch 498 in epoch 16, gen_loss = 0.8854708757572518, disc_loss = 0.00021451440758658816
Trained batch 499 in epoch 16, gen_loss = 0.8856315789222717, disc_loss = 0.00021542977084754966
Trained batch 500 in epoch 16, gen_loss = 0.8856567510825669, disc_loss = 0.00021599048893027818
Trained batch 501 in epoch 16, gen_loss = 0.8855771802336097, disc_loss = 0.00021643687880378164
Trained batch 502 in epoch 16, gen_loss = 0.8856502142151592, disc_loss = 0.0002167877987585869
Trained batch 503 in epoch 16, gen_loss = 0.8855020659310477, disc_loss = 0.00021678398967658666
Trained batch 504 in epoch 16, gen_loss = 0.8856621430651976, disc_loss = 0.00021657824376828525
Trained batch 505 in epoch 16, gen_loss = 0.8856465110901316, disc_loss = 0.00021642910729791865
Trained batch 506 in epoch 16, gen_loss = 0.8856878861402854, disc_loss = 0.00021657661426467069
Trained batch 507 in epoch 16, gen_loss = 0.8855905252413487, disc_loss = 0.0002169049798472469
Trained batch 508 in epoch 16, gen_loss = 0.8854932978251594, disc_loss = 0.00021694857662146608
Trained batch 509 in epoch 16, gen_loss = 0.8854055492316976, disc_loss = 0.00021673548842812248
Trained batch 510 in epoch 16, gen_loss = 0.8854197989237985, disc_loss = 0.00021656181165149324
Trained batch 511 in epoch 16, gen_loss = 0.8851995968725532, disc_loss = 0.00021647468241781098
Trained batch 512 in epoch 16, gen_loss = 0.8851543218768828, disc_loss = 0.00021623943352093284
Trained batch 513 in epoch 16, gen_loss = 0.8851825959023798, disc_loss = 0.00021601448746106828
Trained batch 514 in epoch 16, gen_loss = 0.8852618592456707, disc_loss = 0.0002158718322798185
Trained batch 515 in epoch 16, gen_loss = 0.8852228633193082, disc_loss = 0.00021569777176367542
Trained batch 516 in epoch 16, gen_loss = 0.885186235955421, disc_loss = 0.0002154291829264748
Trained batch 517 in epoch 16, gen_loss = 0.8852189111893701, disc_loss = 0.0002154102124900577
Trained batch 518 in epoch 16, gen_loss = 0.8854679282690059, disc_loss = 0.00021578706399708544
Trained batch 519 in epoch 16, gen_loss = 0.8854675597869432, disc_loss = 0.00021706213868198505
Trained batch 520 in epoch 16, gen_loss = 0.8854047938637908, disc_loss = 0.00021736294267381382
Trained batch 521 in epoch 16, gen_loss = 0.885373190673375, disc_loss = 0.0002175625027417182
Trained batch 522 in epoch 16, gen_loss = 0.8855530518190811, disc_loss = 0.00021805729431041872
Trained batch 523 in epoch 16, gen_loss = 0.8855374475926844, disc_loss = 0.000218773844302743
Trained batch 524 in epoch 16, gen_loss = 0.8855717852002098, disc_loss = 0.00021948001055058003
Trained batch 525 in epoch 16, gen_loss = 0.8857044129997151, disc_loss = 0.0002201443578377977
Trained batch 526 in epoch 16, gen_loss = 0.8857843914339619, disc_loss = 0.00022121438393698462
Trained batch 527 in epoch 16, gen_loss = 0.8859960580188216, disc_loss = 0.00022208909402968746
Trained batch 528 in epoch 16, gen_loss = 0.8859978541309306, disc_loss = 0.00022348459435739978
Trained batch 529 in epoch 16, gen_loss = 0.8858828247718091, disc_loss = 0.0002248784923241781
Trained batch 530 in epoch 16, gen_loss = 0.8859248632765085, disc_loss = 0.0002251594979650334
Trained batch 531 in epoch 16, gen_loss = 0.8859372767514753, disc_loss = 0.0002262732236852031
Trained batch 532 in epoch 16, gen_loss = 0.8859412049486758, disc_loss = 0.00022791537424161993
Trained batch 533 in epoch 16, gen_loss = 0.8858316598760054, disc_loss = 0.00022953939149149673
Trained batch 534 in epoch 16, gen_loss = 0.8857668435462167, disc_loss = 0.00023022249530593942
Trained batch 535 in epoch 16, gen_loss = 0.885608991580223, disc_loss = 0.00023032319962506187
Trained batch 536 in epoch 16, gen_loss = 0.8856363090056947, disc_loss = 0.00023064265920864278
Trained batch 537 in epoch 16, gen_loss = 0.8856078036212567, disc_loss = 0.0002307081423172092
Trained batch 538 in epoch 16, gen_loss = 0.8855965176186005, disc_loss = 0.00023083231872837932
Trained batch 539 in epoch 16, gen_loss = 0.8859615081990206, disc_loss = 0.00023122040989552193
Trained batch 540 in epoch 16, gen_loss = 0.8860096225236128, disc_loss = 0.00023144558285392714
Trained batch 541 in epoch 16, gen_loss = 0.8859742095769552, disc_loss = 0.00023147637236142115
Trained batch 542 in epoch 16, gen_loss = 0.8862513329003617, disc_loss = 0.00023160219188699408
Trained batch 543 in epoch 16, gen_loss = 0.8861820057911032, disc_loss = 0.0002315197445488379
Trained batch 544 in epoch 16, gen_loss = 0.8860750688325375, disc_loss = 0.00023125978863590885
Trained batch 545 in epoch 16, gen_loss = 0.8861233644433074, disc_loss = 0.0002312655386502382
Trained batch 546 in epoch 16, gen_loss = 0.886043760850617, disc_loss = 0.00023153144697298192
Trained batch 547 in epoch 16, gen_loss = 0.885881063494369, disc_loss = 0.00023152202562002862
Trained batch 548 in epoch 16, gen_loss = 0.8858256806875622, disc_loss = 0.00023131079546683545
Trained batch 549 in epoch 16, gen_loss = 0.8857832593267614, disc_loss = 0.00023111578229211525
Trained batch 550 in epoch 16, gen_loss = 0.8857606530405865, disc_loss = 0.0002309357956840535
Trained batch 551 in epoch 16, gen_loss = 0.8855521537471509, disc_loss = 0.00023081409588063463
Trained batch 552 in epoch 16, gen_loss = 0.8856253974260948, disc_loss = 0.00023061296833705604
Trained batch 553 in epoch 16, gen_loss = 0.8854929573484276, disc_loss = 0.00023041418620653364
Trained batch 554 in epoch 16, gen_loss = 0.8853356755531586, disc_loss = 0.0002302031813038362
Trained batch 555 in epoch 16, gen_loss = 0.8854241835342037, disc_loss = 0.00023006419119384918
Trained batch 556 in epoch 16, gen_loss = 0.8853074045754848, disc_loss = 0.000229990984614365
Trained batch 557 in epoch 16, gen_loss = 0.8853504325540262, disc_loss = 0.00023015406244875878
Trained batch 558 in epoch 16, gen_loss = 0.8852975659592207, disc_loss = 0.0002302057183443857
Trained batch 559 in epoch 16, gen_loss = 0.8855081968009472, disc_loss = 0.00023010894476880952
Trained batch 560 in epoch 16, gen_loss = 0.885526575719184, disc_loss = 0.00023016350064405909
Trained batch 561 in epoch 16, gen_loss = 0.8856200919456754, disc_loss = 0.00023050539293827728
Trained batch 562 in epoch 16, gen_loss = 0.8857311904959738, disc_loss = 0.00023031390002133825
Trained batch 563 in epoch 16, gen_loss = 0.885698656452463, disc_loss = 0.00023007284080643118
Trained batch 564 in epoch 16, gen_loss = 0.8858407540658934, disc_loss = 0.00022993796543409816
Trained batch 565 in epoch 16, gen_loss = 0.885879600427176, disc_loss = 0.0002297467754258241
Trained batch 566 in epoch 16, gen_loss = 0.8857918105217936, disc_loss = 0.00022965460926182633
Trained batch 567 in epoch 16, gen_loss = 0.8857116265825822, disc_loss = 0.00022963635402306926
Trained batch 568 in epoch 16, gen_loss = 0.8856595678153483, disc_loss = 0.00022958863297127915
Trained batch 569 in epoch 16, gen_loss = 0.8858473973316059, disc_loss = 0.00022953203047029348
Trained batch 570 in epoch 16, gen_loss = 0.8857560779918932, disc_loss = 0.00022958030426938368
Trained batch 571 in epoch 16, gen_loss = 0.8859314567350841, disc_loss = 0.00022942021940354506
Trained batch 572 in epoch 16, gen_loss = 0.8858352178678462, disc_loss = 0.000229482760502149
Trained batch 573 in epoch 16, gen_loss = 0.8857926076297561, disc_loss = 0.00022954131448795558
Trained batch 574 in epoch 16, gen_loss = 0.8859196109357087, disc_loss = 0.00022949893829797436
Trained batch 575 in epoch 16, gen_loss = 0.8861324002759324, disc_loss = 0.0002295513018755931
Trained batch 576 in epoch 16, gen_loss = 0.885925938393049, disc_loss = 0.00022936646540671832
Trained batch 577 in epoch 16, gen_loss = 0.8858252725592947, disc_loss = 0.00022910790192950226
Trained batch 578 in epoch 16, gen_loss = 0.8859627587601723, disc_loss = 0.00022880949072023277
Trained batch 579 in epoch 16, gen_loss = 0.886033261130596, disc_loss = 0.0002285914973479772
Trained batch 580 in epoch 16, gen_loss = 0.8859453879412194, disc_loss = 0.0002283491642765277
Trained batch 581 in epoch 16, gen_loss = 0.8859478476940561, disc_loss = 0.0002280436938641956
Trained batch 582 in epoch 16, gen_loss = 0.8857830679028152, disc_loss = 0.00022777492551078724
Trained batch 583 in epoch 16, gen_loss = 0.885679412275961, disc_loss = 0.00022758105831300083
Trained batch 584 in epoch 16, gen_loss = 0.8856478008449588, disc_loss = 0.00022732681553993915
Trained batch 585 in epoch 16, gen_loss = 0.885292671035988, disc_loss = 0.00024733646333165176
Trained batch 586 in epoch 16, gen_loss = 0.8851264133364013, disc_loss = 0.0003030276311433746
Trained batch 587 in epoch 16, gen_loss = 0.8852954742048873, disc_loss = 0.0003361714384451249
Trained batch 588 in epoch 16, gen_loss = 0.8854187259447392, disc_loss = 0.0003536605943331941
Trained batch 589 in epoch 16, gen_loss = 0.8854548749277147, disc_loss = 0.00036005132325522414
Trained batch 590 in epoch 16, gen_loss = 0.8856028980006623, disc_loss = 0.0003619703982563535
Trained batch 591 in epoch 16, gen_loss = 0.8856215255485999, disc_loss = 0.00036311667384792155
Trained batch 592 in epoch 16, gen_loss = 0.8856941502773742, disc_loss = 0.0003643088873839367
Trained batch 593 in epoch 16, gen_loss = 0.8858225682769159, disc_loss = 0.000365534111900923
Trained batch 594 in epoch 16, gen_loss = 0.8858595735886517, disc_loss = 0.0003660259578091351
Trained batch 595 in epoch 16, gen_loss = 0.8858602251982529, disc_loss = 0.0003664575148691836
Trained batch 596 in epoch 16, gen_loss = 0.8859671798583052, disc_loss = 0.00036653987352558453
Trained batch 597 in epoch 16, gen_loss = 0.8859217048289385, disc_loss = 0.0003665454287968115
Trained batch 598 in epoch 16, gen_loss = 0.8860117162209321, disc_loss = 0.00036664274457036725
Trained batch 599 in epoch 16, gen_loss = 0.886102308134238, disc_loss = 0.00036649049861201395
Trained batch 600 in epoch 16, gen_loss = 0.8860223254625889, disc_loss = 0.00036687468139442325
Trained batch 601 in epoch 16, gen_loss = 0.8859871044705476, disc_loss = 0.00036728865882007414
Trained batch 602 in epoch 16, gen_loss = 0.8860911165501546, disc_loss = 0.00036709827530602456
Trained batch 603 in epoch 16, gen_loss = 0.8862579572477088, disc_loss = 0.0003668613109212609
Trained batch 604 in epoch 16, gen_loss = 0.8862243822783478, disc_loss = 0.00036690585793396226
Trained batch 605 in epoch 16, gen_loss = 0.8861118650475744, disc_loss = 0.00036717127577713676
Trained batch 606 in epoch 16, gen_loss = 0.8861097803422214, disc_loss = 0.0003671146769312869
Trained batch 607 in epoch 16, gen_loss = 0.8861398041052254, disc_loss = 0.0003670608773398654
Trained batch 608 in epoch 16, gen_loss = 0.886089558769721, disc_loss = 0.00036673519578961155
Trained batch 609 in epoch 16, gen_loss = 0.886146371188711, disc_loss = 0.0003665830357454442
Trained batch 610 in epoch 16, gen_loss = 0.8861515448838716, disc_loss = 0.0003663146178954115
Trained batch 611 in epoch 16, gen_loss = 0.8860950917005539, disc_loss = 0.0003662583805242891
Trained batch 612 in epoch 16, gen_loss = 0.885900984677755, disc_loss = 0.00036611672139785073
Trained batch 613 in epoch 16, gen_loss = 0.8857620508934854, disc_loss = 0.00036601814844191275
Trained batch 614 in epoch 16, gen_loss = 0.8858627597490947, disc_loss = 0.00036586975620593875
Trained batch 615 in epoch 16, gen_loss = 0.8857613234937965, disc_loss = 0.0003661056161472988
Trained batch 616 in epoch 16, gen_loss = 0.8860736034291297, disc_loss = 0.00036618824257357634
Trained batch 617 in epoch 16, gen_loss = 0.8860883130224777, disc_loss = 0.00036689484212491027
Trained batch 618 in epoch 16, gen_loss = 0.8862247035653603, disc_loss = 0.00036822014091170043
Trained batch 619 in epoch 16, gen_loss = 0.8860102871733327, disc_loss = 0.00036844924487072165
Trained batch 620 in epoch 16, gen_loss = 0.885775802600019, disc_loss = 0.00036933206445173827
Trained batch 621 in epoch 16, gen_loss = 0.8857928084215551, disc_loss = 0.00036983183294349764
Trained batch 622 in epoch 16, gen_loss = 0.8858425066138156, disc_loss = 0.00036963336000142
Trained batch 623 in epoch 16, gen_loss = 0.8857370496560366, disc_loss = 0.0003696628423896096
Trained batch 624 in epoch 16, gen_loss = 0.8859088127136231, disc_loss = 0.0003698608522536233
Trained batch 625 in epoch 16, gen_loss = 0.8858563074479088, disc_loss = 0.00036983793693354364
Trained batch 626 in epoch 16, gen_loss = 0.8860518100539273, disc_loss = 0.00036948966482068236
Trained batch 627 in epoch 16, gen_loss = 0.8859601262838218, disc_loss = 0.0003694805269495504
Trained batch 628 in epoch 16, gen_loss = 0.8860244262010001, disc_loss = 0.00036937153591594504
Trained batch 629 in epoch 16, gen_loss = 0.8860920275014544, disc_loss = 0.00036908346142837894
Trained batch 630 in epoch 16, gen_loss = 0.8861017972467062, disc_loss = 0.00036887700781823915
Trained batch 631 in epoch 16, gen_loss = 0.8861665301307847, disc_loss = 0.00036866470025738115
Trained batch 632 in epoch 16, gen_loss = 0.8861867609370565, disc_loss = 0.00036861607862366465
Trained batch 633 in epoch 16, gen_loss = 0.8862319009537201, disc_loss = 0.00036833760624127874
Trained batch 634 in epoch 16, gen_loss = 0.8861575490846408, disc_loss = 0.00036794031199295163
Trained batch 635 in epoch 16, gen_loss = 0.8862358610959923, disc_loss = 0.0003675821071337621
Trained batch 636 in epoch 16, gen_loss = 0.8862675421840542, disc_loss = 0.00036724345754262565
Trained batch 637 in epoch 16, gen_loss = 0.8863428193947365, disc_loss = 0.0003668764323701565
Trained batch 638 in epoch 16, gen_loss = 0.8863612562651179, disc_loss = 0.0003664636691060815
Trained batch 639 in epoch 16, gen_loss = 0.8862123031169176, disc_loss = 0.0003660885999579477
Trained batch 640 in epoch 16, gen_loss = 0.8862035869622193, disc_loss = 0.00036589377022140575
Trained batch 641 in epoch 16, gen_loss = 0.8863198276249419, disc_loss = 0.00036585572747059597
Trained batch 642 in epoch 16, gen_loss = 0.886364518112936, disc_loss = 0.0003654274228246213
Trained batch 643 in epoch 16, gen_loss = 0.8863362964265835, disc_loss = 0.00036504652847081095
Trained batch 644 in epoch 16, gen_loss = 0.8863557301750479, disc_loss = 0.00036477517806329264
Trained batch 645 in epoch 16, gen_loss = 0.8862075773370525, disc_loss = 0.00036487867039770335
Trained batch 646 in epoch 16, gen_loss = 0.8861236051761385, disc_loss = 0.00036461942959551655
Trained batch 647 in epoch 16, gen_loss = 0.8858826514563443, disc_loss = 0.0003643627909763449
Trained batch 648 in epoch 16, gen_loss = 0.885660575148872, disc_loss = 0.0003640459096287011
Trained batch 649 in epoch 16, gen_loss = 0.8857412159442901, disc_loss = 0.0003640159682254307
Trained batch 650 in epoch 16, gen_loss = 0.8858305126108149, disc_loss = 0.0003637772029964611
Trained batch 651 in epoch 16, gen_loss = 0.8859358336662222, disc_loss = 0.0003633969921391583
Trained batch 652 in epoch 16, gen_loss = 0.8860804558165406, disc_loss = 0.0003629715142242652
Trained batch 653 in epoch 16, gen_loss = 0.8861977955616942, disc_loss = 0.0003626052910126126
Trained batch 654 in epoch 16, gen_loss = 0.8862379001297114, disc_loss = 0.00036225624342283715
Trained batch 655 in epoch 16, gen_loss = 0.8863184462960173, disc_loss = 0.0003620622024732811
Trained batch 656 in epoch 16, gen_loss = 0.8861627259392354, disc_loss = 0.00036173356903879583
Trained batch 657 in epoch 16, gen_loss = 0.8859656435921561, disc_loss = 0.00036141777771451133
Trained batch 658 in epoch 16, gen_loss = 0.8858316291988529, disc_loss = 0.0003611253840819302
Trained batch 659 in epoch 16, gen_loss = 0.8859773202375932, disc_loss = 0.00036071611126923625
Trained batch 660 in epoch 16, gen_loss = 0.8859418727987293, disc_loss = 0.0003603028615353856
Trained batch 661 in epoch 16, gen_loss = 0.8857481545371951, disc_loss = 0.0003598656272361782
Trained batch 662 in epoch 16, gen_loss = 0.8857941435113392, disc_loss = 0.00035954901027301087
Trained batch 663 in epoch 16, gen_loss = 0.8857628979596747, disc_loss = 0.00035913599687598645
Trained batch 664 in epoch 16, gen_loss = 0.8857911970382346, disc_loss = 0.0003588506853784771
Trained batch 665 in epoch 16, gen_loss = 0.8856265423176167, disc_loss = 0.00035878073210803886
Trained batch 666 in epoch 16, gen_loss = 0.8857044466789337, disc_loss = 0.00035856120592544155
Trained batch 667 in epoch 16, gen_loss = 0.8856553919836433, disc_loss = 0.00035833526059347664
Trained batch 668 in epoch 16, gen_loss = 0.8854653260633015, disc_loss = 0.00035821679034971624
Trained batch 669 in epoch 16, gen_loss = 0.8855199151074709, disc_loss = 0.0003579762037439487
Trained batch 670 in epoch 16, gen_loss = 0.8856053490041799, disc_loss = 0.00035772715876635023
Trained batch 671 in epoch 16, gen_loss = 0.8856217200379997, disc_loss = 0.00035751780042335754
Trained batch 672 in epoch 16, gen_loss = 0.8854491716862434, disc_loss = 0.0003571507146278082
Trained batch 673 in epoch 16, gen_loss = 0.8855296616561334, disc_loss = 0.00035679008495758665
Trained batch 674 in epoch 16, gen_loss = 0.8855273585849338, disc_loss = 0.00035638332282865627
Trained batch 675 in epoch 16, gen_loss = 0.8855361207526111, disc_loss = 0.0003561341633116785
Trained batch 676 in epoch 16, gen_loss = 0.8855827493012568, disc_loss = 0.0003558161161290385
Trained batch 677 in epoch 16, gen_loss = 0.8855814798391675, disc_loss = 0.000356025340533156
Trained batch 678 in epoch 16, gen_loss = 0.8857202458803011, disc_loss = 0.00035667203426592884
Trained batch 679 in epoch 16, gen_loss = 0.8856554668615846, disc_loss = 0.0003570749358914327
Trained batch 680 in epoch 16, gen_loss = 0.8855990620436648, disc_loss = 0.000357064144850316
Trained batch 681 in epoch 16, gen_loss = 0.8854994883110796, disc_loss = 0.0003569782434182946
Trained batch 682 in epoch 16, gen_loss = 0.8857527160539809, disc_loss = 0.00035726430939747724
Trained batch 683 in epoch 16, gen_loss = 0.885949531406687, disc_loss = 0.0003575519436516946
Trained batch 684 in epoch 16, gen_loss = 0.8858750531273166, disc_loss = 0.00035726877246357937
Trained batch 685 in epoch 16, gen_loss = 0.8858888812211095, disc_loss = 0.00035685249443492465
Trained batch 686 in epoch 16, gen_loss = 0.8858879663191161, disc_loss = 0.00035656005476843405
Trained batch 687 in epoch 16, gen_loss = 0.8858942910162515, disc_loss = 0.00035639889297589284
Trained batch 688 in epoch 16, gen_loss = 0.8858803138677545, disc_loss = 0.00035627352961096424
Trained batch 689 in epoch 16, gen_loss = 0.8857635052307792, disc_loss = 0.00035590599609481547
Trained batch 690 in epoch 16, gen_loss = 0.8857523644539795, disc_loss = 0.00035562869593923623
Trained batch 691 in epoch 16, gen_loss = 0.8858628561558751, disc_loss = 0.0003553520698789063
Trained batch 692 in epoch 16, gen_loss = 0.8859755066566137, disc_loss = 0.0003550932242892532
Trained batch 693 in epoch 16, gen_loss = 0.8858778609837854, disc_loss = 0.0003547312355939479
Trained batch 694 in epoch 16, gen_loss = 0.8858074954087786, disc_loss = 0.0003543342569409099
Trained batch 695 in epoch 16, gen_loss = 0.8858135911239975, disc_loss = 0.00035392742269657737
Trained batch 696 in epoch 16, gen_loss = 0.8857946579733401, disc_loss = 0.0003543228180821814
Trained batch 697 in epoch 16, gen_loss = 0.8856099574135504, disc_loss = 0.0003669206728077331
Trained batch 698 in epoch 16, gen_loss = 0.8857374488028333, disc_loss = 0.0003818982556506922
Trained batch 699 in epoch 16, gen_loss = 0.8860381579399109, disc_loss = 0.00038796950609789097
Trained batch 700 in epoch 16, gen_loss = 0.8863645757996237, disc_loss = 0.00038935049494612863
Trained batch 701 in epoch 16, gen_loss = 0.8866910419912419, disc_loss = 0.0003923638028532474
Trained batch 702 in epoch 16, gen_loss = 0.8869599858524111, disc_loss = 0.00040264814179807976
Trained batch 703 in epoch 16, gen_loss = 0.8869774405929175, disc_loss = 0.00041973189957967736
Trained batch 704 in epoch 16, gen_loss = 0.8870642602020967, disc_loss = 0.0004226646063674294
Trained batch 705 in epoch 16, gen_loss = 0.887344872394297, disc_loss = 0.0004242646572474923
Trained batch 706 in epoch 16, gen_loss = 0.8873880417883143, disc_loss = 0.0004250951619048852
Trained batch 707 in epoch 16, gen_loss = 0.8876908888756219, disc_loss = 0.00042503495320992145
Trained batch 708 in epoch 16, gen_loss = 0.887614069687799, disc_loss = 0.0004251893645967521
Trained batch 709 in epoch 16, gen_loss = 0.887600513075439, disc_loss = 0.00042507035910269956
Trained batch 710 in epoch 16, gen_loss = 0.8875563099414487, disc_loss = 0.00042538325784992527
Trained batch 711 in epoch 16, gen_loss = 0.8877562982647607, disc_loss = 0.0004253567568320137
Trained batch 712 in epoch 16, gen_loss = 0.8879856178837437, disc_loss = 0.000425064143292713
Trained batch 713 in epoch 16, gen_loss = 0.8880822147641864, disc_loss = 0.0004249955905345073
Trained batch 714 in epoch 16, gen_loss = 0.8880985911909517, disc_loss = 0.0004246491707830488
Trained batch 715 in epoch 16, gen_loss = 0.8881043379699718, disc_loss = 0.00042458364072820955
Trained batch 716 in epoch 16, gen_loss = 0.8882808905598841, disc_loss = 0.00042450452998954013
Trained batch 717 in epoch 16, gen_loss = 0.8883431896691867, disc_loss = 0.00042472064374212543
Trained batch 718 in epoch 16, gen_loss = 0.8883836787499705, disc_loss = 0.00042516697554441715
Trained batch 719 in epoch 16, gen_loss = 0.8883760906755924, disc_loss = 0.0004250508310886087
Trained batch 720 in epoch 16, gen_loss = 0.8883326590143857, disc_loss = 0.0004250271302228406
Trained batch 721 in epoch 16, gen_loss = 0.8882221610097013, disc_loss = 0.000424925966437105
Trained batch 722 in epoch 16, gen_loss = 0.8881923525000344, disc_loss = 0.00042472946385348686
Trained batch 723 in epoch 16, gen_loss = 0.8881955933011039, disc_loss = 0.000424408155283762
Trained batch 724 in epoch 16, gen_loss = 0.8882382842590069, disc_loss = 0.0004240310578486593
Trained batch 725 in epoch 16, gen_loss = 0.888223959394723, disc_loss = 0.00042370757910749454
Trained batch 726 in epoch 16, gen_loss = 0.8882123363067228, disc_loss = 0.00042357335514129566
Trained batch 727 in epoch 16, gen_loss = 0.8881724183703517, disc_loss = 0.00042337490892780375
Trained batch 728 in epoch 16, gen_loss = 0.8882213611825176, disc_loss = 0.0004230249554237583
Trained batch 729 in epoch 16, gen_loss = 0.8881577891846225, disc_loss = 0.00042315037822995133
Trained batch 730 in epoch 16, gen_loss = 0.8881700132679189, disc_loss = 0.0004231331611728033
Trained batch 731 in epoch 16, gen_loss = 0.8882793203566244, disc_loss = 0.00042292150099287217
Trained batch 732 in epoch 16, gen_loss = 0.8883172808695294, disc_loss = 0.0004228026344327162
Trained batch 733 in epoch 16, gen_loss = 0.8884051193658272, disc_loss = 0.00042250860133208334
Trained batch 734 in epoch 16, gen_loss = 0.8885136556463177, disc_loss = 0.000422025720011142
Trained batch 735 in epoch 16, gen_loss = 0.8885343925946433, disc_loss = 0.00042172810727290357
Trained batch 736 in epoch 16, gen_loss = 0.8887771545142299, disc_loss = 0.0004218520687627189
Trained batch 737 in epoch 16, gen_loss = 0.8887677786311483, disc_loss = 0.00042162411688673337
Trained batch 738 in epoch 16, gen_loss = 0.8887492417482626, disc_loss = 0.0004212039256540407
Trained batch 739 in epoch 16, gen_loss = 0.8886542421740454, disc_loss = 0.00042096812647139664
Trained batch 740 in epoch 16, gen_loss = 0.8887176426798709, disc_loss = 0.000420913728793053
Trained batch 741 in epoch 16, gen_loss = 0.8889177473728869, disc_loss = 0.0004207013259163143
Trained batch 742 in epoch 16, gen_loss = 0.8890004409915827, disc_loss = 0.00042035246407871684
Trained batch 743 in epoch 16, gen_loss = 0.8891375883612581, disc_loss = 0.00041990064475553923
Trained batch 744 in epoch 16, gen_loss = 0.8891429904323296, disc_loss = 0.0004196868912901279
Trained batch 745 in epoch 16, gen_loss = 0.8891987799799155, disc_loss = 0.00041933014596660744
Trained batch 746 in epoch 16, gen_loss = 0.8891687349302861, disc_loss = 0.00041906521112503487
Trained batch 747 in epoch 16, gen_loss = 0.8892694043125061, disc_loss = 0.00041886997858328834
Trained batch 748 in epoch 16, gen_loss = 0.8892727587347197, disc_loss = 0.00041854410999279235
Trained batch 749 in epoch 16, gen_loss = 0.8893457329273224, disc_loss = 0.0004184222591963286
Trained batch 750 in epoch 16, gen_loss = 0.8893025421429569, disc_loss = 0.00041824027680613336
Trained batch 751 in epoch 16, gen_loss = 0.8891577878372466, disc_loss = 0.00041798601846784685
Trained batch 752 in epoch 16, gen_loss = 0.8892272523991457, disc_loss = 0.0004179415632273376
Trained batch 753 in epoch 16, gen_loss = 0.8890375628553587, disc_loss = 0.0004184114029305241
Trained batch 754 in epoch 16, gen_loss = 0.8890729987858147, disc_loss = 0.00041850146304412024
Trained batch 755 in epoch 16, gen_loss = 0.8890858276811227, disc_loss = 0.00041839384859832494
Trained batch 756 in epoch 16, gen_loss = 0.8890387342659611, disc_loss = 0.0004182720065012001
Trained batch 757 in epoch 16, gen_loss = 0.889078032923248, disc_loss = 0.00041814479497485576
Trained batch 758 in epoch 16, gen_loss = 0.8891421839967861, disc_loss = 0.0004178538099408324
Trained batch 759 in epoch 16, gen_loss = 0.888989225343654, disc_loss = 0.00041749671576039155
Trained batch 760 in epoch 16, gen_loss = 0.8891792184576568, disc_loss = 0.00041736509516249616
Trained batch 761 in epoch 16, gen_loss = 0.8890486713156612, disc_loss = 0.0004173990205476327
Trained batch 762 in epoch 16, gen_loss = 0.8890548538255504, disc_loss = 0.00041704087704374316
Trained batch 763 in epoch 16, gen_loss = 0.8890794325249357, disc_loss = 0.00041678244838413677
Trained batch 764 in epoch 16, gen_loss = 0.889189793705161, disc_loss = 0.00041652333186908925
Trained batch 765 in epoch 16, gen_loss = 0.8891616775690732, disc_loss = 0.0004162337774150657
Trained batch 766 in epoch 16, gen_loss = 0.8890714045453725, disc_loss = 0.000415886840795202
Trained batch 767 in epoch 16, gen_loss = 0.8890303683777651, disc_loss = 0.0004155704137929206
Trained batch 768 in epoch 16, gen_loss = 0.8890277931687116, disc_loss = 0.0004152286833261778
Trained batch 769 in epoch 16, gen_loss = 0.8888802217198657, disc_loss = 0.000415024334941265
Trained batch 770 in epoch 16, gen_loss = 0.8887892429621458, disc_loss = 0.0004146574152664954
Trained batch 771 in epoch 16, gen_loss = 0.8886689041871481, disc_loss = 0.00041425062737887884
Trained batch 772 in epoch 16, gen_loss = 0.8885702846275418, disc_loss = 0.0004138356357408365
Trained batch 773 in epoch 16, gen_loss = 0.8885375924350679, disc_loss = 0.00041350195794928824
Trained batch 774 in epoch 16, gen_loss = 0.8886478467141429, disc_loss = 0.0004132019593793478
Trained batch 775 in epoch 16, gen_loss = 0.8886956782224252, disc_loss = 0.0004127898929376916
Trained batch 776 in epoch 16, gen_loss = 0.88872726689281, disc_loss = 0.0004124452454252816
Trained batch 777 in epoch 16, gen_loss = 0.8886346317502097, disc_loss = 0.00041217261062773987
Trained batch 778 in epoch 16, gen_loss = 0.8885812861163441, disc_loss = 0.0004118472698699941
Trained batch 779 in epoch 16, gen_loss = 0.8885711452899835, disc_loss = 0.0004117246415355625
Trained batch 780 in epoch 16, gen_loss = 0.8885235583431131, disc_loss = 0.00041161507701831566
Trained batch 781 in epoch 16, gen_loss = 0.8885743875637688, disc_loss = 0.0004113061774713809
Trained batch 782 in epoch 16, gen_loss = 0.8885093857349868, disc_loss = 0.00041094491113525
Trained batch 783 in epoch 16, gen_loss = 0.8884301030514191, disc_loss = 0.00041053270134787975
Trained batch 784 in epoch 16, gen_loss = 0.8883221279283997, disc_loss = 0.0004101173947958252
Trained batch 785 in epoch 16, gen_loss = 0.8882265948612271, disc_loss = 0.00040972808996688235
Trained batch 786 in epoch 16, gen_loss = 0.8882464321928981, disc_loss = 0.00040930685778565616
Trained batch 787 in epoch 16, gen_loss = 0.8883155212184499, disc_loss = 0.0004089015785239514
Trained batch 788 in epoch 16, gen_loss = 0.8883301815152621, disc_loss = 0.0004084908037223789
Trained batch 789 in epoch 16, gen_loss = 0.8882666144944444, disc_loss = 0.00040807876522436183
Trained batch 790 in epoch 16, gen_loss = 0.8884334198744348, disc_loss = 0.0004077895140787086
Trained batch 791 in epoch 16, gen_loss = 0.8884108548965117, disc_loss = 0.0004075015018003401
Trained batch 792 in epoch 16, gen_loss = 0.8885058066132391, disc_loss = 0.00040715140231873564
Trained batch 793 in epoch 16, gen_loss = 0.888670486001584, disc_loss = 0.0004067017766084391
Trained batch 794 in epoch 16, gen_loss = 0.8887265276608977, disc_loss = 0.0004063009727629467
Trained batch 795 in epoch 16, gen_loss = 0.8887771506555117, disc_loss = 0.00040589066243205594
Trained batch 796 in epoch 16, gen_loss = 0.8887592755267432, disc_loss = 0.00040549482470430133
Trained batch 797 in epoch 16, gen_loss = 0.8886928966917789, disc_loss = 0.0004050749313025511
Trained batch 798 in epoch 16, gen_loss = 0.8885240583157211, disc_loss = 0.00040466085748688856
Trained batch 799 in epoch 16, gen_loss = 0.8884856667369604, disc_loss = 0.0004042305060011131
Trained batch 800 in epoch 16, gen_loss = 0.888613194636489, disc_loss = 0.00040386645808810435
Trained batch 801 in epoch 16, gen_loss = 0.8885926089233294, disc_loss = 0.0004034985050427968
Trained batch 802 in epoch 16, gen_loss = 0.88852132932929, disc_loss = 0.00040323199497663113
Trained batch 803 in epoch 16, gen_loss = 0.888537041286924, disc_loss = 0.0004029352816115846
Trained batch 804 in epoch 16, gen_loss = 0.8886496200324586, disc_loss = 0.00040278831092454203
Trained batch 805 in epoch 16, gen_loss = 0.8887405218025, disc_loss = 0.0004028532608170565
Trained batch 806 in epoch 16, gen_loss = 0.8888523282467063, disc_loss = 0.00040272344407777543
Trained batch 807 in epoch 16, gen_loss = 0.8889473397100326, disc_loss = 0.0004024005675451953
Trained batch 808 in epoch 16, gen_loss = 0.8889514823042418, disc_loss = 0.000402200084721928
Trained batch 809 in epoch 16, gen_loss = 0.8888750213163871, disc_loss = 0.00040190329802701144
Trained batch 810 in epoch 16, gen_loss = 0.8887495517583722, disc_loss = 0.0004015199161152891
Trained batch 811 in epoch 16, gen_loss = 0.8885679278027248, disc_loss = 0.0004013212309576648
Trained batch 812 in epoch 16, gen_loss = 0.8884414602323065, disc_loss = 0.00040158762291798636
Trained batch 813 in epoch 16, gen_loss = 0.8885426136873278, disc_loss = 0.0004017377300476123
Trained batch 814 in epoch 16, gen_loss = 0.8884144608228485, disc_loss = 0.0004021910594064211
Trained batch 815 in epoch 16, gen_loss = 0.888372324918415, disc_loss = 0.0004032496146696669
Trained batch 816 in epoch 16, gen_loss = 0.8882969827955473, disc_loss = 0.00040602280150133164
Trained batch 817 in epoch 16, gen_loss = 0.8883415297366005, disc_loss = 0.0004064656055641553
Trained batch 818 in epoch 16, gen_loss = 0.8882338853691669, disc_loss = 0.0004068667088746564
Trained batch 819 in epoch 16, gen_loss = 0.8882172122961137, disc_loss = 0.00040940041702614086
Trained batch 820 in epoch 16, gen_loss = 0.888436898316884, disc_loss = 0.00041027736062790586
Trained batch 821 in epoch 16, gen_loss = 0.8885762133882573, disc_loss = 0.0004106242051814743
Trained batch 822 in epoch 16, gen_loss = 0.8886089718935701, disc_loss = 0.0004110330670280863
Trained batch 823 in epoch 16, gen_loss = 0.8885890356111295, disc_loss = 0.00041121555635787816
Trained batch 824 in epoch 16, gen_loss = 0.8884604743755224, disc_loss = 0.00041213656922936385
Trained batch 825 in epoch 16, gen_loss = 0.8883580543804399, disc_loss = 0.00041215299250360425
Trained batch 826 in epoch 16, gen_loss = 0.8883898220731097, disc_loss = 0.0004120947273040304
Trained batch 827 in epoch 16, gen_loss = 0.8884229832801266, disc_loss = 0.0004119413787991023
Trained batch 828 in epoch 16, gen_loss = 0.8884363848136331, disc_loss = 0.00041194021190757907
Trained batch 829 in epoch 16, gen_loss = 0.8884188981659441, disc_loss = 0.00041173422792035785
Trained batch 830 in epoch 16, gen_loss = 0.8882566496783646, disc_loss = 0.00041178819425489527
Trained batch 831 in epoch 16, gen_loss = 0.8883456455973479, disc_loss = 0.0004116449145717874
Trained batch 832 in epoch 16, gen_loss = 0.8884063479708595, disc_loss = 0.0004116582350223605
Trained batch 833 in epoch 16, gen_loss = 0.8885904347582115, disc_loss = 0.0004120391833209137
Trained batch 834 in epoch 16, gen_loss = 0.8887739047318876, disc_loss = 0.0004125052573410989
Trained batch 835 in epoch 16, gen_loss = 0.8887771760875528, disc_loss = 0.0004124240260883864
Trained batch 836 in epoch 16, gen_loss = 0.8888751747645215, disc_loss = 0.00041217074240161453
Trained batch 837 in epoch 16, gen_loss = 0.8888917072433845, disc_loss = 0.000411847868782781
Trained batch 838 in epoch 16, gen_loss = 0.888862116615309, disc_loss = 0.0004115174042573115
Trained batch 839 in epoch 16, gen_loss = 0.8890053244573729, disc_loss = 0.00041123379971741956
Trained batch 840 in epoch 16, gen_loss = 0.8890525927583329, disc_loss = 0.00041096908003904366
Trained batch 841 in epoch 16, gen_loss = 0.8890248976665551, disc_loss = 0.0004110405965820325
Trained batch 842 in epoch 16, gen_loss = 0.8891503861083396, disc_loss = 0.00041147437107202147
Trained batch 843 in epoch 16, gen_loss = 0.8892388351579413, disc_loss = 0.0004113588272535294
Trained batch 844 in epoch 16, gen_loss = 0.8891964697273526, disc_loss = 0.000411434179527021
Trained batch 845 in epoch 16, gen_loss = 0.8891939291153675, disc_loss = 0.00041125283511563303
Trained batch 846 in epoch 16, gen_loss = 0.8891476014147401, disc_loss = 0.00041199827981240546
Trained batch 847 in epoch 16, gen_loss = 0.8891510737813869, disc_loss = 0.0004124220227599578
Trained batch 848 in epoch 16, gen_loss = 0.8893000452622367, disc_loss = 0.00041244400397470455
Trained batch 849 in epoch 16, gen_loss = 0.8892067716402166, disc_loss = 0.00041223700294401225
Trained batch 850 in epoch 16, gen_loss = 0.8891863626122615, disc_loss = 0.00041186825316909595
Trained batch 851 in epoch 16, gen_loss = 0.889090960294428, disc_loss = 0.00041161857747360506
Trained batch 852 in epoch 16, gen_loss = 0.8891644233975293, disc_loss = 0.0004179941988247829
Trained batch 853 in epoch 16, gen_loss = 0.8891811563482888, disc_loss = 0.0004255051345189415
Trained batch 854 in epoch 16, gen_loss = 0.8891552983668812, disc_loss = 0.0004279731644936347
Trained batch 855 in epoch 16, gen_loss = 0.8891882165987915, disc_loss = 0.0004308457613167724
Trained batch 856 in epoch 16, gen_loss = 0.8891782406608867, disc_loss = 0.000430849230526107
Trained batch 857 in epoch 16, gen_loss = 0.8891611354195432, disc_loss = 0.00043114549154910965
Trained batch 858 in epoch 16, gen_loss = 0.8891698351700176, disc_loss = 0.0004312434927084021
Trained batch 859 in epoch 16, gen_loss = 0.889192141488541, disc_loss = 0.0004310799921408626
Trained batch 860 in epoch 16, gen_loss = 0.8891751221386536, disc_loss = 0.0004308432589728427
Trained batch 861 in epoch 16, gen_loss = 0.8891043537868978, disc_loss = 0.00043058216516199963
Trained batch 862 in epoch 16, gen_loss = 0.8892554019168797, disc_loss = 0.00043097066060918614
Trained batch 863 in epoch 16, gen_loss = 0.8891944692780575, disc_loss = 0.0004310809390938596
Trained batch 864 in epoch 16, gen_loss = 0.8892633243103247, disc_loss = 0.0004309845384835492
Trained batch 865 in epoch 16, gen_loss = 0.8892860312797731, disc_loss = 0.0004312183724369614
Trained batch 866 in epoch 16, gen_loss = 0.8892224464724495, disc_loss = 0.00043101448494992827
Trained batch 867 in epoch 16, gen_loss = 0.8890878410520642, disc_loss = 0.00043095079762331363
Trained batch 868 in epoch 16, gen_loss = 0.8893030524528205, disc_loss = 0.0004307787456355857
Trained batch 869 in epoch 16, gen_loss = 0.8893367502196082, disc_loss = 0.0004304503323593921
Trained batch 870 in epoch 16, gen_loss = 0.8893767244917107, disc_loss = 0.00043042219637998196
Trained batch 871 in epoch 16, gen_loss = 0.8893748249756087, disc_loss = 0.00043026118681221666
Trained batch 872 in epoch 16, gen_loss = 0.8894944509826301, disc_loss = 0.00043016592111367306
Trained batch 873 in epoch 16, gen_loss = 0.889405272713515, disc_loss = 0.00042984130652894446
Trained batch 874 in epoch 16, gen_loss = 0.8894719033922468, disc_loss = 0.00042950622894568366
Trained batch 875 in epoch 16, gen_loss = 0.8893978975407065, disc_loss = 0.0004292116960998732
Trained batch 876 in epoch 16, gen_loss = 0.8894020105577249, disc_loss = 0.0004289372788839485
Trained batch 877 in epoch 16, gen_loss = 0.889356794077606, disc_loss = 0.0004288165873317138
Trained batch 878 in epoch 16, gen_loss = 0.8891923685258295, disc_loss = 0.0004288492972973286
Trained batch 879 in epoch 16, gen_loss = 0.8891778814521702, disc_loss = 0.0004288505840618613
Trained batch 880 in epoch 16, gen_loss = 0.8891313004304278, disc_loss = 0.00042867509573181375
Trained batch 881 in epoch 16, gen_loss = 0.888977422195227, disc_loss = 0.00042837568144270434
Trained batch 882 in epoch 16, gen_loss = 0.888904594956546, disc_loss = 0.00042804539288714
Trained batch 883 in epoch 16, gen_loss = 0.8888190866730332, disc_loss = 0.000427654083278657
Trained batch 884 in epoch 16, gen_loss = 0.8886915192765704, disc_loss = 0.00042726872539829126
Trained batch 885 in epoch 16, gen_loss = 0.8886709052472298, disc_loss = 0.0004270844007352142
Trained batch 886 in epoch 16, gen_loss = 0.8886186539656414, disc_loss = 0.00042681417246443653
Trained batch 887 in epoch 16, gen_loss = 0.888609808441755, disc_loss = 0.00042644625730784493
Trained batch 888 in epoch 16, gen_loss = 0.888486340088839, disc_loss = 0.0004260436740935795
Trained batch 889 in epoch 16, gen_loss = 0.8883944246876105, disc_loss = 0.0004257202183672755
Trained batch 890 in epoch 16, gen_loss = 0.8882350839348353, disc_loss = 0.00042557715467279503
Trained batch 891 in epoch 16, gen_loss = 0.8881398200855127, disc_loss = 0.0004254390020298666
Trained batch 892 in epoch 16, gen_loss = 0.8881453818329772, disc_loss = 0.00042510260570532835
Trained batch 893 in epoch 16, gen_loss = 0.8880691402310493, disc_loss = 0.0004247006684735988
Trained batch 894 in epoch 16, gen_loss = 0.8882351804045991, disc_loss = 0.00042449970288701644
Trained batch 895 in epoch 16, gen_loss = 0.8882048342243901, disc_loss = 0.00042425613543985364
Trained batch 896 in epoch 16, gen_loss = 0.888116611618395, disc_loss = 0.00042400556901877863
Trained batch 897 in epoch 16, gen_loss = 0.8881881764046599, disc_loss = 0.0004237365514755079
Trained batch 898 in epoch 16, gen_loss = 0.8882551037429836, disc_loss = 0.0004234189702170975
Trained batch 899 in epoch 16, gen_loss = 0.8883609858486388, disc_loss = 0.0004231455860361974
Trained batch 900 in epoch 16, gen_loss = 0.8883506234292846, disc_loss = 0.0004228933850611063
Trained batch 901 in epoch 16, gen_loss = 0.8883766944947634, disc_loss = 0.000422569762515534
Trained batch 902 in epoch 16, gen_loss = 0.8882919767106227, disc_loss = 0.0004222406954159042
Trained batch 903 in epoch 16, gen_loss = 0.8882152020799375, disc_loss = 0.00042190098513783915
Trained batch 904 in epoch 16, gen_loss = 0.8881675137340693, disc_loss = 0.00042164710925818674
Trained batch 905 in epoch 16, gen_loss = 0.888150760340638, disc_loss = 0.00042130129155824956
Trained batch 906 in epoch 16, gen_loss = 0.8881111401970094, disc_loss = 0.0004209822342660337
Trained batch 907 in epoch 16, gen_loss = 0.8881971885322999, disc_loss = 0.00042072221849954506
Trained batch 908 in epoch 16, gen_loss = 0.8881683542390074, disc_loss = 0.00042043399765217426
Trained batch 909 in epoch 16, gen_loss = 0.8880399593940148, disc_loss = 0.00042011390556421406
Trained batch 910 in epoch 16, gen_loss = 0.8879680227893113, disc_loss = 0.0004198328281532841
Trained batch 911 in epoch 16, gen_loss = 0.8878389685169646, disc_loss = 0.0004196964872024086
Trained batch 912 in epoch 16, gen_loss = 0.8878663829226875, disc_loss = 0.0004194017127535596
Trained batch 913 in epoch 16, gen_loss = 0.8877427847301934, disc_loss = 0.000419176788699721
Trained batch 914 in epoch 16, gen_loss = 0.8877508278752937, disc_loss = 0.0004189973496599759
Trained batch 915 in epoch 16, gen_loss = 0.8877451201843903, disc_loss = 0.00041875175229029975
Trained batch 916 in epoch 16, gen_loss = 0.8876793224002959, disc_loss = 0.0004187167514064918
Trained batch 917 in epoch 16, gen_loss = 0.8876117077658119, disc_loss = 0.00041849799993013494
Trained batch 918 in epoch 16, gen_loss = 0.8875684893170172, disc_loss = 0.000418266420837168
Trained batch 919 in epoch 16, gen_loss = 0.8874882858732472, disc_loss = 0.00041797380451063636
Trained batch 920 in epoch 16, gen_loss = 0.8875195879760187, disc_loss = 0.0004175929276405502
Trained batch 921 in epoch 16, gen_loss = 0.8875549683860481, disc_loss = 0.0004172528715097899
Trained batch 922 in epoch 16, gen_loss = 0.8875438926795968, disc_loss = 0.00041691448348822813
Trained batch 923 in epoch 16, gen_loss = 0.8875456371090629, disc_loss = 0.00041662569170409776
Trained batch 924 in epoch 16, gen_loss = 0.8874372326361166, disc_loss = 0.0004162590384618631
Trained batch 925 in epoch 16, gen_loss = 0.8874681487711665, disc_loss = 0.0004158858303587253
Trained batch 926 in epoch 16, gen_loss = 0.8873610427078692, disc_loss = 0.0004155399796259469
Trained batch 927 in epoch 16, gen_loss = 0.8872527733188251, disc_loss = 0.000415243800230671
Trained batch 928 in epoch 16, gen_loss = 0.887190268807057, disc_loss = 0.0004150104252503111
Trained batch 929 in epoch 16, gen_loss = 0.8871248473403275, disc_loss = 0.0004147677433627572
Trained batch 930 in epoch 16, gen_loss = 0.8871530864215691, disc_loss = 0.0004144619610406299
Trained batch 931 in epoch 16, gen_loss = 0.8873180046102008, disc_loss = 0.0004141296063498729
Trained batch 932 in epoch 16, gen_loss = 0.8873551085447575, disc_loss = 0.00041379687785552034
Trained batch 933 in epoch 16, gen_loss = 0.8872856355453712, disc_loss = 0.00041353902081681993
Trained batch 934 in epoch 16, gen_loss = 0.8873290432328209, disc_loss = 0.0004133624886676176
Trained batch 935 in epoch 16, gen_loss = 0.8873279403544899, disc_loss = 0.00041309878029135446
Trained batch 936 in epoch 16, gen_loss = 0.8873774904197156, disc_loss = 0.0004127624570940603
Trained batch 937 in epoch 16, gen_loss = 0.8872731688307293, disc_loss = 0.0004127071563710845
Trained batch 938 in epoch 16, gen_loss = 0.8871630566061749, disc_loss = 0.00041258636890647486
Trained batch 939 in epoch 16, gen_loss = 0.8872065713430973, disc_loss = 0.0004122615035080247
Trained batch 940 in epoch 16, gen_loss = 0.8872129946915427, disc_loss = 0.00041190537170616623
Trained batch 941 in epoch 16, gen_loss = 0.887112045870212, disc_loss = 0.0004115709922737526
Trained batch 942 in epoch 16, gen_loss = 0.8872799592710882, disc_loss = 0.00041129748732603893
Trained batch 943 in epoch 16, gen_loss = 0.8872207494736728, disc_loss = 0.0004109871990248532
Trained batch 944 in epoch 16, gen_loss = 0.8870782071951205, disc_loss = 0.0004106884896240897
Trained batch 945 in epoch 16, gen_loss = 0.8869528576385143, disc_loss = 0.0004104637517510735
Trained batch 946 in epoch 16, gen_loss = 0.8869437452606314, disc_loss = 0.00041032925637006425
Trained batch 947 in epoch 16, gen_loss = 0.8869424925700522, disc_loss = 0.00041011935907222266
Trained batch 948 in epoch 16, gen_loss = 0.886978403848642, disc_loss = 0.0004099009453934947
Trained batch 949 in epoch 16, gen_loss = 0.8868602068173258, disc_loss = 0.000409557098993039
Trained batch 950 in epoch 16, gen_loss = 0.8868455836073458, disc_loss = 0.0004092373059963128
Trained batch 951 in epoch 16, gen_loss = 0.8868435033980537, disc_loss = 0.0004089191309832444
Trained batch 952 in epoch 16, gen_loss = 0.8869628537239083, disc_loss = 0.000408591639547602
Trained batch 953 in epoch 16, gen_loss = 0.8869498546393413, disc_loss = 0.0004082398069613668
Trained batch 954 in epoch 16, gen_loss = 0.8869646338892233, disc_loss = 0.000407917374417098
Trained batch 955 in epoch 16, gen_loss = 0.8869103131558606, disc_loss = 0.00040759974229685324
Trained batch 956 in epoch 16, gen_loss = 0.8869020890915531, disc_loss = 0.000407240566116458
Trained batch 957 in epoch 16, gen_loss = 0.8869530686754772, disc_loss = 0.0004068723667544176
Trained batch 958 in epoch 16, gen_loss = 0.8868672646372361, disc_loss = 0.00040652878508564766
Trained batch 959 in epoch 16, gen_loss = 0.8869470159212748, disc_loss = 0.000406223377774495
Trained batch 960 in epoch 16, gen_loss = 0.8868901601815199, disc_loss = 0.0004058679841175876
Trained batch 961 in epoch 16, gen_loss = 0.8869380787355736, disc_loss = 0.0004055291044934163
Trained batch 962 in epoch 16, gen_loss = 0.8870461468632224, disc_loss = 0.00040521770092912684
Trained batch 963 in epoch 16, gen_loss = 0.8869086356825848, disc_loss = 0.0004049012336829671
Trained batch 964 in epoch 16, gen_loss = 0.8868430182106136, disc_loss = 0.00040460072545328064
Trained batch 965 in epoch 16, gen_loss = 0.8867267377628303, disc_loss = 0.00040432228475166646
Trained batch 966 in epoch 16, gen_loss = 0.8866625821454819, disc_loss = 0.00040402630143180696
Trained batch 967 in epoch 16, gen_loss = 0.8866214527448347, disc_loss = 0.00040369494933078056
Trained batch 968 in epoch 16, gen_loss = 0.8866106638967437, disc_loss = 0.0004033799949208127
Trained batch 969 in epoch 16, gen_loss = 0.8865706240393452, disc_loss = 0.00040301793155823857
Trained batch 970 in epoch 16, gen_loss = 0.8864796210759455, disc_loss = 0.00040276123506366993
Trained batch 971 in epoch 16, gen_loss = 0.8865859127093735, disc_loss = 0.0004024479768180934
Trained batch 972 in epoch 16, gen_loss = 0.8866508993926053, disc_loss = 0.00040215152399143646
Trained batch 973 in epoch 16, gen_loss = 0.8867481728476421, disc_loss = 0.00040182729807509147
Trained batch 974 in epoch 16, gen_loss = 0.8867798273991315, disc_loss = 0.00040149376207876066
Trained batch 975 in epoch 16, gen_loss = 0.886710163572284, disc_loss = 0.00040116109803197195
Trained batch 976 in epoch 16, gen_loss = 0.8867865026668248, disc_loss = 0.00040082539978423187
Trained batch 977 in epoch 16, gen_loss = 0.8867872495714628, disc_loss = 0.00040057243936709324
Trained batch 978 in epoch 16, gen_loss = 0.8866319057890295, disc_loss = 0.0004006296903409805
Trained batch 979 in epoch 16, gen_loss = 0.8865988084248134, disc_loss = 0.0004005603412187323
Trained batch 980 in epoch 16, gen_loss = 0.8865185762764117, disc_loss = 0.0004002218001961381
Trained batch 981 in epoch 16, gen_loss = 0.8864560215269233, disc_loss = 0.0003999430427198
Trained batch 982 in epoch 16, gen_loss = 0.8865164505622879, disc_loss = 0.0003996367174858762
Trained batch 983 in epoch 16, gen_loss = 0.8865317959732156, disc_loss = 0.00039933439681656794
Trained batch 984 in epoch 16, gen_loss = 0.8864936424996042, disc_loss = 0.00039901138036372967
Trained batch 985 in epoch 16, gen_loss = 0.8864694495230128, disc_loss = 0.0003987177782763151
Trained batch 986 in epoch 16, gen_loss = 0.8863685111748291, disc_loss = 0.00039841702041158283
Trained batch 987 in epoch 16, gen_loss = 0.8863954789001449, disc_loss = 0.00039811358765807017
Trained batch 988 in epoch 16, gen_loss = 0.8864141129507214, disc_loss = 0.00039777354531658597
Trained batch 989 in epoch 16, gen_loss = 0.8862798940653753, disc_loss = 0.0003974481071091217
Trained batch 990 in epoch 16, gen_loss = 0.8863746748201542, disc_loss = 0.00039712327975738304
Trained batch 991 in epoch 16, gen_loss = 0.8862877114405555, disc_loss = 0.0003967897575105986
Trained batch 992 in epoch 16, gen_loss = 0.8863693122777334, disc_loss = 0.00039661454664058967
Trained batch 993 in epoch 16, gen_loss = 0.8863731874546534, disc_loss = 0.00039634022628903126
Trained batch 994 in epoch 16, gen_loss = 0.8863818725748877, disc_loss = 0.00039607257611570465
Trained batch 995 in epoch 16, gen_loss = 0.8864001036288748, disc_loss = 0.00039572845868229
Trained batch 996 in epoch 16, gen_loss = 0.8864044009622862, disc_loss = 0.0003954596088284852
Trained batch 997 in epoch 16, gen_loss = 0.8863817849952377, disc_loss = 0.00039527473410328205
Trained batch 998 in epoch 16, gen_loss = 0.886350828964073, disc_loss = 0.0003950132667632096
Trained batch 999 in epoch 16, gen_loss = 0.8863193395137787, disc_loss = 0.00039468014632075213
Trained batch 1000 in epoch 16, gen_loss = 0.8863653615042641, disc_loss = 0.0003944861194546896
Trained batch 1001 in epoch 16, gen_loss = 0.8864686787723305, disc_loss = 0.0003942866890478664
Trained batch 1002 in epoch 16, gen_loss = 0.8864621810637348, disc_loss = 0.0003939806785061503
Trained batch 1003 in epoch 16, gen_loss = 0.8864590232353287, disc_loss = 0.00039369120558949795
Trained batch 1004 in epoch 16, gen_loss = 0.8864452882192622, disc_loss = 0.0003934512014214971
Trained batch 1005 in epoch 16, gen_loss = 0.886387589378338, disc_loss = 0.00039331203323010025
Trained batch 1006 in epoch 16, gen_loss = 0.8863275914703604, disc_loss = 0.00039314593974889444
Trained batch 1007 in epoch 16, gen_loss = 0.8864333792220033, disc_loss = 0.0003930271425433025
Trained batch 1008 in epoch 16, gen_loss = 0.8863970033004807, disc_loss = 0.00039280065697342884
Trained batch 1009 in epoch 16, gen_loss = 0.8865304277674987, disc_loss = 0.00039260791596858
Trained batch 1010 in epoch 16, gen_loss = 0.8864941212590913, disc_loss = 0.0003923437897752776
Trained batch 1011 in epoch 16, gen_loss = 0.8863642372397095, disc_loss = 0.00039232972917506925
Trained batch 1012 in epoch 16, gen_loss = 0.8864642286347731, disc_loss = 0.00039256699989540737
Trained batch 1013 in epoch 16, gen_loss = 0.8865182666618678, disc_loss = 0.0003923988918106164
Trained batch 1014 in epoch 16, gen_loss = 0.8865382974958185, disc_loss = 0.00039218383018065615
Trained batch 1015 in epoch 16, gen_loss = 0.8864568194418442, disc_loss = 0.00039201238834406054
Trained batch 1016 in epoch 16, gen_loss = 0.8864434499187338, disc_loss = 0.0003918118754121868
Trained batch 1017 in epoch 16, gen_loss = 0.886345243172936, disc_loss = 0.0003915408268140175
Trained batch 1018 in epoch 16, gen_loss = 0.8863086149432825, disc_loss = 0.00039120076972981745
Trained batch 1019 in epoch 16, gen_loss = 0.8864390453871559, disc_loss = 0.00039093128755256673
Trained batch 1020 in epoch 16, gen_loss = 0.886497426570104, disc_loss = 0.00039088582284389957
Trained batch 1021 in epoch 16, gen_loss = 0.8864959683670223, disc_loss = 0.00039058657724192386
Trained batch 1022 in epoch 16, gen_loss = 0.8864744545077998, disc_loss = 0.00039029758943865355
Trained batch 1023 in epoch 16, gen_loss = 0.8864483222714625, disc_loss = 0.000389998200798658
Trained batch 1024 in epoch 16, gen_loss = 0.886394857255424, disc_loss = 0.0003897615031178802
Trained batch 1025 in epoch 16, gen_loss = 0.8864682169801775, disc_loss = 0.0003894853474435632
Trained batch 1026 in epoch 16, gen_loss = 0.8863784955214155, disc_loss = 0.00038919955930178247
Trained batch 1027 in epoch 16, gen_loss = 0.8862891473194968, disc_loss = 0.00038890691322912866
Trained batch 1028 in epoch 16, gen_loss = 0.8862809077180394, disc_loss = 0.00038861087351931424
Trained batch 1029 in epoch 16, gen_loss = 0.8862291069864069, disc_loss = 0.00038829527683914935
Trained batch 1030 in epoch 16, gen_loss = 0.8861404661410763, disc_loss = 0.0003879570688119779
Trained batch 1031 in epoch 16, gen_loss = 0.8862107120050017, disc_loss = 0.000387655129293131
Trained batch 1032 in epoch 16, gen_loss = 0.8861461013468976, disc_loss = 0.00038737758107689396
Trained batch 1033 in epoch 16, gen_loss = 0.8860932870459972, disc_loss = 0.00038709416102826943
Trained batch 1034 in epoch 16, gen_loss = 0.8860598919472257, disc_loss = 0.0003867968741918527
Trained batch 1035 in epoch 16, gen_loss = 0.8860049663708477, disc_loss = 0.00038647184710042046
Trained batch 1036 in epoch 16, gen_loss = 0.8860630013098942, disc_loss = 0.00038615010460054414
Trained batch 1037 in epoch 16, gen_loss = 0.8860505202027874, disc_loss = 0.0003859182646489
Trained batch 1038 in epoch 16, gen_loss = 0.8860731109388753, disc_loss = 0.00038566609531930307
Trained batch 1039 in epoch 16, gen_loss = 0.8860578518074292, disc_loss = 0.0003854389843162118
Trained batch 1040 in epoch 16, gen_loss = 0.8859836654979145, disc_loss = 0.0003851805416333483
Trained batch 1041 in epoch 16, gen_loss = 0.8859297327139556, disc_loss = 0.00038489411323070535
Trained batch 1042 in epoch 16, gen_loss = 0.8859118619221169, disc_loss = 0.00038457356752335647
Trained batch 1043 in epoch 16, gen_loss = 0.8857510260010131, disc_loss = 0.00038428448890003003
Trained batch 1044 in epoch 16, gen_loss = 0.8857596639240758, disc_loss = 0.0003840202792027116
Trained batch 1045 in epoch 16, gen_loss = 0.8857781553131673, disc_loss = 0.0003837461694479881
Trained batch 1046 in epoch 16, gen_loss = 0.8858062733665693, disc_loss = 0.0003834879582771667
Trained batch 1047 in epoch 16, gen_loss = 0.8858198448446871, disc_loss = 0.0003832099129746498
Trained batch 1048 in epoch 16, gen_loss = 0.885712001696442, disc_loss = 0.00038295466037240397
Trained batch 1049 in epoch 16, gen_loss = 0.8857176610969362, disc_loss = 0.00038278006717432404
Trained batch 1050 in epoch 16, gen_loss = 0.8857156186303449, disc_loss = 0.0003826726753425332
Trained batch 1051 in epoch 16, gen_loss = 0.8857253689616352, disc_loss = 0.00038251909813620684
Trained batch 1052 in epoch 16, gen_loss = 0.8857564736522048, disc_loss = 0.0003824688022912748
Trained batch 1053 in epoch 16, gen_loss = 0.8857768323321948, disc_loss = 0.0003822750417871343
Trained batch 1054 in epoch 16, gen_loss = 0.8858120450476334, disc_loss = 0.00038203856473917173
Trained batch 1055 in epoch 16, gen_loss = 0.8857233384906342, disc_loss = 0.0003817683932642136
Trained batch 1056 in epoch 16, gen_loss = 0.8857909249830832, disc_loss = 0.00038153104044123316
Trained batch 1057 in epoch 16, gen_loss = 0.8857615257143299, disc_loss = 0.00038128028897701615
Trained batch 1058 in epoch 16, gen_loss = 0.8856941850484824, disc_loss = 0.00038101441211633167
Trained batch 1059 in epoch 16, gen_loss = 0.885698139948665, disc_loss = 0.0003807748603132907
Trained batch 1060 in epoch 16, gen_loss = 0.885608694948867, disc_loss = 0.00038049060893208286
Trained batch 1061 in epoch 16, gen_loss = 0.8855976575736496, disc_loss = 0.0003801917130790579
Trained batch 1062 in epoch 16, gen_loss = 0.8856596516643284, disc_loss = 0.0003798807214589409
Trained batch 1063 in epoch 16, gen_loss = 0.8855856316990423, disc_loss = 0.0003795624181149929
Trained batch 1064 in epoch 16, gen_loss = 0.8855361761061799, disc_loss = 0.00037926309595489547
Trained batch 1065 in epoch 16, gen_loss = 0.8854936253957408, disc_loss = 0.00037903791372827537
Trained batch 1066 in epoch 16, gen_loss = 0.8853968991893636, disc_loss = 0.00037885590625416567
Trained batch 1067 in epoch 16, gen_loss = 0.8853874196497242, disc_loss = 0.00037857398050557625
Trained batch 1068 in epoch 16, gen_loss = 0.8853667996775, disc_loss = 0.0003786267128096921
Trained batch 1069 in epoch 16, gen_loss = 0.8853987103867753, disc_loss = 0.0003788403981161537
Trained batch 1070 in epoch 16, gen_loss = 0.8853109039289722, disc_loss = 0.0003789741370117326
Trained batch 1071 in epoch 16, gen_loss = 0.8852743367984224, disc_loss = 0.0003789270989992515
Trained batch 1072 in epoch 16, gen_loss = 0.8852791823967527, disc_loss = 0.00037877869406568673
Trained batch 1073 in epoch 16, gen_loss = 0.8852473351431515, disc_loss = 0.00037876286925548003
Trained batch 1074 in epoch 16, gen_loss = 0.8852498808017997, disc_loss = 0.0003787282151461113
Trained batch 1075 in epoch 16, gen_loss = 0.8852598353057103, disc_loss = 0.00037862052303789417
Trained batch 1076 in epoch 16, gen_loss = 0.885125393710318, disc_loss = 0.00037845947655665724
Trained batch 1077 in epoch 16, gen_loss = 0.8850091487335141, disc_loss = 0.0003783405943585943
Trained batch 1078 in epoch 16, gen_loss = 0.8849719012081899, disc_loss = 0.0003782300696133144
Trained batch 1079 in epoch 16, gen_loss = 0.8849154233932495, disc_loss = 0.0003781436687151856
Trained batch 1080 in epoch 16, gen_loss = 0.8849951854246176, disc_loss = 0.00037786505700523144
Trained batch 1081 in epoch 16, gen_loss = 0.8850204709937964, disc_loss = 0.0003776833614017442
Trained batch 1082 in epoch 16, gen_loss = 0.8848800530394029, disc_loss = 0.0003775139100733697
Trained batch 1083 in epoch 16, gen_loss = 0.8848388348998178, disc_loss = 0.0003774151290367979
Trained batch 1084 in epoch 16, gen_loss = 0.8848557089880315, disc_loss = 0.0003772435025927613
Trained batch 1085 in epoch 16, gen_loss = 0.8847561349087218, disc_loss = 0.0003770069495517695
Trained batch 1086 in epoch 16, gen_loss = 0.8846905450263809, disc_loss = 0.0003767887321863871
Trained batch 1087 in epoch 16, gen_loss = 0.8846225705655182, disc_loss = 0.000376596818726097
Trained batch 1088 in epoch 16, gen_loss = 0.884546723302293, disc_loss = 0.0003763362295982863
Trained batch 1089 in epoch 16, gen_loss = 0.8845744630065533, disc_loss = 0.00037605500426728155
Trained batch 1090 in epoch 16, gen_loss = 0.8845802282762572, disc_loss = 0.0003758139489222594
Trained batch 1091 in epoch 16, gen_loss = 0.8845039155784544, disc_loss = 0.0003755472253499484
Trained batch 1092 in epoch 16, gen_loss = 0.8843828398267392, disc_loss = 0.00037530146041264174
Trained batch 1093 in epoch 16, gen_loss = 0.8844642913755595, disc_loss = 0.0003751047124136297
Trained batch 1094 in epoch 16, gen_loss = 0.8844135419418823, disc_loss = 0.0003749531101945471
Trained batch 1095 in epoch 16, gen_loss = 0.8844048381939421, disc_loss = 0.0003747791205582506
Trained batch 1096 in epoch 16, gen_loss = 0.8842671880313453, disc_loss = 0.00037454289404468746
Trained batch 1097 in epoch 16, gen_loss = 0.8842866247034681, disc_loss = 0.00037427976915375
Trained batch 1098 in epoch 16, gen_loss = 0.8842246399021235, disc_loss = 0.0003739868539680614
Trained batch 1099 in epoch 16, gen_loss = 0.8841758412664587, disc_loss = 0.0003736855977331288
Trained batch 1100 in epoch 16, gen_loss = 0.8841349202648928, disc_loss = 0.0003734200818127497
Trained batch 1101 in epoch 16, gen_loss = 0.884094155851596, disc_loss = 0.0003731521042448362
Trained batch 1102 in epoch 16, gen_loss = 0.8841587392611603, disc_loss = 0.0003728597168425429
Trained batch 1103 in epoch 16, gen_loss = 0.8841579758926578, disc_loss = 0.00037257349187870125
Trained batch 1104 in epoch 16, gen_loss = 0.8840717572971707, disc_loss = 0.0003722850649593381
Trained batch 1105 in epoch 16, gen_loss = 0.8841041586282672, disc_loss = 0.00037201923066588073
Trained batch 1106 in epoch 16, gen_loss = 0.8841616840328089, disc_loss = 0.00037177960425327164
Trained batch 1107 in epoch 16, gen_loss = 0.8841543490813527, disc_loss = 0.00037149383532637115
Trained batch 1108 in epoch 16, gen_loss = 0.8841465008592047, disc_loss = 0.0003712069099031612
Trained batch 1109 in epoch 16, gen_loss = 0.8841567191454741, disc_loss = 0.00037099669509090645
Trained batch 1110 in epoch 16, gen_loss = 0.8841513460225398, disc_loss = 0.00037072604059106647
Trained batch 1111 in epoch 16, gen_loss = 0.8840608268225794, disc_loss = 0.00037044204988214
Trained batch 1112 in epoch 16, gen_loss = 0.8840357806376262, disc_loss = 0.0003701722417389445
Trained batch 1113 in epoch 16, gen_loss = 0.8840211428688501, disc_loss = 0.00036988850644817536
Trained batch 1114 in epoch 16, gen_loss = 0.8841084605909784, disc_loss = 0.00036960574528455603
Trained batch 1115 in epoch 16, gen_loss = 0.8840215037907323, disc_loss = 0.0003693708506627745
Trained batch 1116 in epoch 16, gen_loss = 0.8839648837688894, disc_loss = 0.0003691773221811837
Trained batch 1117 in epoch 16, gen_loss = 0.8839294006764782, disc_loss = 0.0003689185926895674
Trained batch 1118 in epoch 16, gen_loss = 0.883984968585559, disc_loss = 0.00036866320968993943
Trained batch 1119 in epoch 16, gen_loss = 0.883847701177001, disc_loss = 0.00036844723875414535
Trained batch 1120 in epoch 16, gen_loss = 0.8838779827933775, disc_loss = 0.0003683052082261975
Trained batch 1121 in epoch 16, gen_loss = 0.8839287177232923, disc_loss = 0.00036812182874923575
Trained batch 1122 in epoch 16, gen_loss = 0.8839582124673566, disc_loss = 0.00036791430147017353
Trained batch 1123 in epoch 16, gen_loss = 0.8839593875980887, disc_loss = 0.0003677061075908167
Trained batch 1124 in epoch 16, gen_loss = 0.8839714763429429, disc_loss = 0.00036746244187816046
Trained batch 1125 in epoch 16, gen_loss = 0.8838430433459646, disc_loss = 0.0003674208323084731
Trained batch 1126 in epoch 16, gen_loss = 0.8837842198738295, disc_loss = 0.0003673306642601565
Trained batch 1127 in epoch 16, gen_loss = 0.8838276481057735, disc_loss = 0.0003671715415693794
Trained batch 1128 in epoch 16, gen_loss = 0.8837906673379025, disc_loss = 0.0003670766570472476
Trained batch 1129 in epoch 16, gen_loss = 0.88376606338847, disc_loss = 0.0003669522592556545
Trained batch 1130 in epoch 16, gen_loss = 0.8837375046403718, disc_loss = 0.0003668207612629907
Trained batch 1131 in epoch 16, gen_loss = 0.8837604119373295, disc_loss = 0.00036658667740287106
Trained batch 1132 in epoch 16, gen_loss = 0.8837533652624617, disc_loss = 0.0003663710329866019
Trained batch 1133 in epoch 16, gen_loss = 0.8837726100411996, disc_loss = 0.00036619932214907396
Trained batch 1134 in epoch 16, gen_loss = 0.8837824213347246, disc_loss = 0.0003660225192663652
Trained batch 1135 in epoch 16, gen_loss = 0.8837256927935171, disc_loss = 0.00036581488667303654
Trained batch 1136 in epoch 16, gen_loss = 0.8837520752229917, disc_loss = 0.0003655780620649819
Trained batch 1137 in epoch 16, gen_loss = 0.8837137688442358, disc_loss = 0.00036533802145714475
Trained batch 1138 in epoch 16, gen_loss = 0.8836863353338233, disc_loss = 0.0003651128898413218
Trained batch 1139 in epoch 16, gen_loss = 0.883646188859354, disc_loss = 0.00036488167722078895
Trained batch 1140 in epoch 16, gen_loss = 0.8836044997211928, disc_loss = 0.000364651544765847
Trained batch 1141 in epoch 16, gen_loss = 0.8836121757999194, disc_loss = 0.00036447393264709267
Trained batch 1142 in epoch 16, gen_loss = 0.8835813236778907, disc_loss = 0.0003642366903804559
Trained batch 1143 in epoch 16, gen_loss = 0.8835477880039415, disc_loss = 0.000364025254476836
Trained batch 1144 in epoch 16, gen_loss = 0.8835076696487494, disc_loss = 0.00036379441683545127
Trained batch 1145 in epoch 16, gen_loss = 0.8834399930989764, disc_loss = 0.00036351571566030404
Trained batch 1146 in epoch 16, gen_loss = 0.8832697580457254, disc_loss = 0.0003633321840157978
Trained batch 1147 in epoch 16, gen_loss = 0.8833499858188297, disc_loss = 0.00036316924146034303
Trained batch 1148 in epoch 16, gen_loss = 0.8833548695860581, disc_loss = 0.00036301063178709484
Trained batch 1149 in epoch 16, gen_loss = 0.883370229990586, disc_loss = 0.0003627448207818974
Trained batch 1150 in epoch 16, gen_loss = 0.8834121351548633, disc_loss = 0.00036250919968810287
Trained batch 1151 in epoch 16, gen_loss = 0.8834353614495032, disc_loss = 0.00036224923262769454
Trained batch 1152 in epoch 16, gen_loss = 0.8834026562888417, disc_loss = 0.00036199933348085946
Trained batch 1153 in epoch 16, gen_loss = 0.8834094748649894, disc_loss = 0.0003617187609632112
Trained batch 1154 in epoch 16, gen_loss = 0.8834951815151033, disc_loss = 0.0003614845366495131
Trained batch 1155 in epoch 16, gen_loss = 0.883517454085053, disc_loss = 0.00036133868540632664
Trained batch 1156 in epoch 16, gen_loss = 0.8835314528222937, disc_loss = 0.0003611532208645729
Trained batch 1157 in epoch 16, gen_loss = 0.8835947721012721, disc_loss = 0.0003609701529032796
Trained batch 1158 in epoch 16, gen_loss = 0.8835925042269248, disc_loss = 0.0003607884306195998
Trained batch 1159 in epoch 16, gen_loss = 0.8836371026676276, disc_loss = 0.00036061384700023435
Trained batch 1160 in epoch 16, gen_loss = 0.8836430668009446, disc_loss = 0.0003603978879815904
Trained batch 1161 in epoch 16, gen_loss = 0.8837172464433923, disc_loss = 0.0003603964508700226
Trained batch 1162 in epoch 16, gen_loss = 0.8836987464979407, disc_loss = 0.00036023575427634373
Trained batch 1163 in epoch 16, gen_loss = 0.8836027086293164, disc_loss = 0.0003599960299561957
Trained batch 1164 in epoch 16, gen_loss = 0.8834894262669936, disc_loss = 0.0003598063234348488
Trained batch 1165 in epoch 16, gen_loss = 0.8834710880270544, disc_loss = 0.000359568580068698
Trained batch 1166 in epoch 16, gen_loss = 0.883456825239595, disc_loss = 0.00035932147660640935
Trained batch 1167 in epoch 16, gen_loss = 0.8834094891503249, disc_loss = 0.00035914481503673975
Trained batch 1168 in epoch 16, gen_loss = 0.8833919896643013, disc_loss = 0.0003589505201082474
Trained batch 1169 in epoch 16, gen_loss = 0.8832793357535306, disc_loss = 0.00035871890782163194
Trained batch 1170 in epoch 16, gen_loss = 0.8832394337165468, disc_loss = 0.00035850132391123475
Trained batch 1171 in epoch 16, gen_loss = 0.8832630910259058, disc_loss = 0.0003583189170520684
Trained batch 1172 in epoch 16, gen_loss = 0.8832007026123574, disc_loss = 0.0003581405648279993
Trained batch 1173 in epoch 16, gen_loss = 0.8830622997661669, disc_loss = 0.00035790742043547276
Trained batch 1174 in epoch 16, gen_loss = 0.8831001586609698, disc_loss = 0.0003576817402233459
Trained batch 1175 in epoch 16, gen_loss = 0.8830853673268337, disc_loss = 0.00035753493916579793
Trained batch 1176 in epoch 16, gen_loss = 0.8831773764416638, disc_loss = 0.0003573501620132042
Trained batch 1177 in epoch 16, gen_loss = 0.8832222563301566, disc_loss = 0.00035710411762343054
Trained batch 1178 in epoch 16, gen_loss = 0.8831801670299333, disc_loss = 0.0003568637224387579
Trained batch 1179 in epoch 16, gen_loss = 0.8831114394179845, disc_loss = 0.0003566667996784741
Trained batch 1180 in epoch 16, gen_loss = 0.8832330130400242, disc_loss = 0.0003564879368043319
Trained batch 1181 in epoch 16, gen_loss = 0.8832682162876259, disc_loss = 0.00035627845569996633
Trained batch 1182 in epoch 16, gen_loss = 0.8833322540139709, disc_loss = 0.00035608165632357796
Trained batch 1183 in epoch 16, gen_loss = 0.8833261987546811, disc_loss = 0.00035591992901584955
Trained batch 1184 in epoch 16, gen_loss = 0.8833543039072415, disc_loss = 0.0003558483312439659
Trained batch 1185 in epoch 16, gen_loss = 0.8833025023466821, disc_loss = 0.0003557419146446801
Trained batch 1186 in epoch 16, gen_loss = 0.8833669283958474, disc_loss = 0.00035551954667204454
Trained batch 1187 in epoch 16, gen_loss = 0.8834345289051332, disc_loss = 0.00035526582053807635
Trained batch 1188 in epoch 16, gen_loss = 0.8833567561273118, disc_loss = 0.00035504252644997136
Trained batch 1189 in epoch 16, gen_loss = 0.8834332931442421, disc_loss = 0.0003548399566468771
Trained batch 1190 in epoch 16, gen_loss = 0.8834503585305362, disc_loss = 0.0003545950709309528
Trained batch 1191 in epoch 16, gen_loss = 0.8834558290823195, disc_loss = 0.0003544088046247825
Trained batch 1192 in epoch 16, gen_loss = 0.8835016563472284, disc_loss = 0.00035428081520475727
Trained batch 1193 in epoch 16, gen_loss = 0.8834448974935254, disc_loss = 0.0003540414061906363
Trained batch 1194 in epoch 16, gen_loss = 0.8834577313526903, disc_loss = 0.00035383569507247857
Trained batch 1195 in epoch 16, gen_loss = 0.8834085879616913, disc_loss = 0.0003536498927169427
Trained batch 1196 in epoch 16, gen_loss = 0.883425375821696, disc_loss = 0.0003534376474827568
Trained batch 1197 in epoch 16, gen_loss = 0.8834060104641572, disc_loss = 0.0003532795421482773
Trained batch 1198 in epoch 16, gen_loss = 0.8834229512349877, disc_loss = 0.0003531633421768581
Trained batch 1199 in epoch 16, gen_loss = 0.8833839443822702, disc_loss = 0.00035305587232869584
Trained batch 1200 in epoch 16, gen_loss = 0.8833550796421442, disc_loss = 0.0003529185831047002
Trained batch 1201 in epoch 16, gen_loss = 0.8834085246290819, disc_loss = 0.00035271102404872733
Trained batch 1202 in epoch 16, gen_loss = 0.88341914913799, disc_loss = 0.0003525141167491388
Trained batch 1203 in epoch 16, gen_loss = 0.8832491268945295, disc_loss = 0.0003524718097188901
Trained batch 1204 in epoch 16, gen_loss = 0.8831826293616869, disc_loss = 0.0003523330163491766
Trained batch 1205 in epoch 16, gen_loss = 0.8831910217678172, disc_loss = 0.0003521518879421411
Trained batch 1206 in epoch 16, gen_loss = 0.8831403597189359, disc_loss = 0.00035194346660548663
Trained batch 1207 in epoch 16, gen_loss = 0.8831116406136001, disc_loss = 0.000351738433566774
Trained batch 1208 in epoch 16, gen_loss = 0.8830737248740973, disc_loss = 0.0003515260960326401
Trained batch 1209 in epoch 16, gen_loss = 0.8831419393543369, disc_loss = 0.0003512907851066956
Trained batch 1210 in epoch 16, gen_loss = 0.8830679434572342, disc_loss = 0.0003510565774573046
Trained batch 1211 in epoch 16, gen_loss = 0.8830765217247576, disc_loss = 0.0003508212803563786
Trained batch 1212 in epoch 16, gen_loss = 0.8830863106673351, disc_loss = 0.0003505891745035062
Trained batch 1213 in epoch 16, gen_loss = 0.8831305443945984, disc_loss = 0.00035034328399994566
Trained batch 1214 in epoch 16, gen_loss = 0.8830910734678983, disc_loss = 0.0003501333302886267
Trained batch 1215 in epoch 16, gen_loss = 0.883114214300325, disc_loss = 0.00034990259115674186
Trained batch 1216 in epoch 16, gen_loss = 0.8830827588220062, disc_loss = 0.0003496802605512753
Trained batch 1217 in epoch 16, gen_loss = 0.8830532400283124, disc_loss = 0.0003494668607463355
Trained batch 1218 in epoch 16, gen_loss = 0.8830342594965058, disc_loss = 0.00034924683064528703
Trained batch 1219 in epoch 16, gen_loss = 0.882955837103187, disc_loss = 0.00034901620169503227
Trained batch 1220 in epoch 16, gen_loss = 0.8829907247709701, disc_loss = 0.0003487913492997616
Trained batch 1221 in epoch 16, gen_loss = 0.8829550802122357, disc_loss = 0.0003485933221929399
Trained batch 1222 in epoch 16, gen_loss = 0.8829712846292791, disc_loss = 0.000348509807541425
Trained batch 1223 in epoch 16, gen_loss = 0.8829525600558792, disc_loss = 0.00034848856243936064
Trained batch 1224 in epoch 16, gen_loss = 0.8828953707461454, disc_loss = 0.00035266318034181106
Trained batch 1225 in epoch 16, gen_loss = 0.8829568900155788, disc_loss = 0.0003534944849061251
Trained batch 1226 in epoch 16, gen_loss = 0.8830473311761577, disc_loss = 0.0004569989632386843
Trained batch 1227 in epoch 16, gen_loss = 0.8830110774851777, disc_loss = 0.0005476799896186944
Trained batch 1228 in epoch 16, gen_loss = 0.8827307944476265, disc_loss = 0.000986311174545985
Trained batch 1229 in epoch 16, gen_loss = 0.8826484606518009, disc_loss = 0.0013207494173216921
Trained batch 1230 in epoch 16, gen_loss = 0.8824947344201256, disc_loss = 0.0016332154132225865
Trained batch 1231 in epoch 16, gen_loss = 0.8822299836614689, disc_loss = 0.001873943729990131
Trained batch 1232 in epoch 16, gen_loss = 0.8820428381774451, disc_loss = 0.0020597170717633366
Trained batch 1233 in epoch 16, gen_loss = 0.8817312352757786, disc_loss = 0.0022724617800423067
Trained batch 1234 in epoch 16, gen_loss = 0.881785486342936, disc_loss = 0.0024131669498756642
Trained batch 1235 in epoch 16, gen_loss = 0.88207008841547, disc_loss = 0.0024729469377643763
Trained batch 1236 in epoch 16, gen_loss = 0.8822618421760411, disc_loss = 0.0024984920163511463
Trained batch 1237 in epoch 16, gen_loss = 0.882307606771805, disc_loss = 0.0025154021566598118
Trained batch 1238 in epoch 16, gen_loss = 0.8824426971971268, disc_loss = 0.0025346929963133724
Trained batch 1239 in epoch 16, gen_loss = 0.8826346906923479, disc_loss = 0.0025461424763512518
Trained batch 1240 in epoch 16, gen_loss = 0.8827598659767439, disc_loss = 0.002548718995888497
Trained batch 1241 in epoch 16, gen_loss = 0.8826522827148438, disc_loss = 0.0025904923150552647
Trained batch 1242 in epoch 16, gen_loss = 0.8822600565077505, disc_loss = 0.0028810468444158454
Trained batch 1243 in epoch 16, gen_loss = 0.8821980652078938, disc_loss = 0.0030877193167518
Trained batch 1244 in epoch 16, gen_loss = 0.8821763319902152, disc_loss = 0.0032252602381926277
Trained batch 1245 in epoch 16, gen_loss = 0.8821763169277537, disc_loss = 0.00331039134285517
Trained batch 1246 in epoch 16, gen_loss = 0.8821287674959316, disc_loss = 0.0033280564202722977
Trained batch 1247 in epoch 16, gen_loss = 0.8818309181250441, disc_loss = 0.0034899910154728366
Trained batch 1248 in epoch 16, gen_loss = 0.8819637432443895, disc_loss = 0.003597683481095389
Trained batch 1249 in epoch 16, gen_loss = 0.882128704571724, disc_loss = 0.0036126303149270826
Trained batch 1250 in epoch 16, gen_loss = 0.8823315208430865, disc_loss = 0.003627734665049714
Trained batch 1251 in epoch 16, gen_loss = 0.8825100686270207, disc_loss = 0.003639708793622694
Trained batch 1252 in epoch 16, gen_loss = 0.8827213872125981, disc_loss = 0.003642213370837104
Trained batch 1253 in epoch 16, gen_loss = 0.8829004129772171, disc_loss = 0.0036460135777719857
Trained batch 1254 in epoch 16, gen_loss = 0.8831045184239923, disc_loss = 0.003648516016099064
Trained batch 1255 in epoch 16, gen_loss = 0.8831154344140724, disc_loss = 0.00365517146207248
Trained batch 1256 in epoch 16, gen_loss = 0.8831324678095163, disc_loss = 0.0036616750969380167
Trained batch 1257 in epoch 16, gen_loss = 0.8829384123246128, disc_loss = 0.0037066295862434595
Trained batch 1258 in epoch 16, gen_loss = 0.8831127137064082, disc_loss = 0.0037764427313026123
Trained batch 1259 in epoch 16, gen_loss = 0.8832257008032193, disc_loss = 0.0037810690063379876
Trained batch 1260 in epoch 16, gen_loss = 0.8833912887287745, disc_loss = 0.0037814447540574
Trained batch 1261 in epoch 16, gen_loss = 0.883366788930825, disc_loss = 0.0037831754588499695
Trained batch 1262 in epoch 16, gen_loss = 0.8834184262597741, disc_loss = 0.0038020105784244045
Trained batch 1263 in epoch 16, gen_loss = 0.8833284685270318, disc_loss = 0.0038273873371531698
Trained batch 1264 in epoch 16, gen_loss = 0.8838410179370005, disc_loss = 0.0038591389950956567
Trained batch 1265 in epoch 16, gen_loss = 0.8842331824285724, disc_loss = 0.0038685978551634874
Trained batch 1266 in epoch 16, gen_loss = 0.8842886686089854, disc_loss = 0.003914654257658324
Trained batch 1267 in epoch 16, gen_loss = 0.8844651787391973, disc_loss = 0.00393751428416614
Trained batch 1268 in epoch 16, gen_loss = 0.8846574170416598, disc_loss = 0.003948472600038621
Trained batch 1269 in epoch 16, gen_loss = 0.8849992463673194, disc_loss = 0.003950707994822659
Trained batch 1270 in epoch 16, gen_loss = 0.8854687576637224, disc_loss = 0.003953039220960267
Trained batch 1271 in epoch 16, gen_loss = 0.8856996566572655, disc_loss = 0.003952023021699901
Trained batch 1272 in epoch 16, gen_loss = 0.8858945392897442, disc_loss = 0.0039528805463557816
Trained batch 1273 in epoch 16, gen_loss = 0.8860511198476121, disc_loss = 0.003952800886170683
Trained batch 1274 in epoch 16, gen_loss = 0.8862404899737414, disc_loss = 0.003953734894143874
Trained batch 1275 in epoch 16, gen_loss = 0.8863903872411827, disc_loss = 0.003955179521055191
Trained batch 1276 in epoch 16, gen_loss = 0.8864861809609921, disc_loss = 0.0039557397034351615
Trained batch 1277 in epoch 16, gen_loss = 0.886669688638014, disc_loss = 0.003955205551560233
Trained batch 1278 in epoch 16, gen_loss = 0.8868050072647986, disc_loss = 0.0039547620882822475
Trained batch 1279 in epoch 16, gen_loss = 0.8869116209214554, disc_loss = 0.003953256305601371
Trained batch 1280 in epoch 16, gen_loss = 0.8871488995285912, disc_loss = 0.003951882669046666
Trained batch 1281 in epoch 16, gen_loss = 0.8873853699046996, disc_loss = 0.003950754709039359
Trained batch 1282 in epoch 16, gen_loss = 0.8875920043870609, disc_loss = 0.003949447395232367
Trained batch 1283 in epoch 16, gen_loss = 0.8876614186019169, disc_loss = 0.003947527501144141
Trained batch 1284 in epoch 16, gen_loss = 0.8877031872012736, disc_loss = 0.003945772721536787
Trained batch 1285 in epoch 16, gen_loss = 0.887812839348802, disc_loss = 0.003945035509689379
Trained batch 1286 in epoch 16, gen_loss = 0.8878761495419408, disc_loss = 0.003943158139857042
Trained batch 1287 in epoch 16, gen_loss = 0.8880411523238102, disc_loss = 0.00394139615450767
Trained batch 1288 in epoch 16, gen_loss = 0.8880618104784872, disc_loss = 0.0039400087767460365
Trained batch 1289 in epoch 16, gen_loss = 0.8881723971098893, disc_loss = 0.003938003648295836
Trained batch 1290 in epoch 16, gen_loss = 0.8882092923318389, disc_loss = 0.003935675185653388
Trained batch 1291 in epoch 16, gen_loss = 0.888318954398942, disc_loss = 0.003934032036689951
Trained batch 1292 in epoch 16, gen_loss = 0.8884047515753711, disc_loss = 0.00393185232384359
Trained batch 1293 in epoch 16, gen_loss = 0.8885187976281094, disc_loss = 0.00392980232269248
Trained batch 1294 in epoch 16, gen_loss = 0.8886103711763405, disc_loss = 0.00392745268798809
Trained batch 1295 in epoch 16, gen_loss = 0.8886897930714451, disc_loss = 0.003925971108480026
Trained batch 1296 in epoch 16, gen_loss = 0.8887959346232639, disc_loss = 0.003923738330820128
Trained batch 1297 in epoch 16, gen_loss = 0.8888638682881562, disc_loss = 0.003921658891316942
Trained batch 1298 in epoch 16, gen_loss = 0.8889601784224139, disc_loss = 0.003919457456846133
Trained batch 1299 in epoch 16, gen_loss = 0.8890918399049685, disc_loss = 0.003917610105697979
Trained batch 1300 in epoch 16, gen_loss = 0.8891501328424707, disc_loss = 0.003917304644191392
Trained batch 1301 in epoch 16, gen_loss = 0.889136950335195, disc_loss = 0.0039159063757668155
Trained batch 1302 in epoch 16, gen_loss = 0.8892584615319121, disc_loss = 0.00391607597014048
Trained batch 1303 in epoch 16, gen_loss = 0.8893838777818197, disc_loss = 0.003913879563831178
Trained batch 1304 in epoch 16, gen_loss = 0.8894690355350231, disc_loss = 0.003911463856967826
Trained batch 1305 in epoch 16, gen_loss = 0.8896004279895727, disc_loss = 0.003909281787724511
Trained batch 1306 in epoch 16, gen_loss = 0.8895975309149765, disc_loss = 0.0039067447742363705
Trained batch 1307 in epoch 16, gen_loss = 0.8896047034804974, disc_loss = 0.0039044000463347864
Trained batch 1308 in epoch 16, gen_loss = 0.8896480374567558, disc_loss = 0.0039020694092778215
Trained batch 1309 in epoch 16, gen_loss = 0.8897691635002617, disc_loss = 0.003899934082387552
Trained batch 1310 in epoch 16, gen_loss = 0.8897407093319067, disc_loss = 0.0038976586033165855
Trained batch 1311 in epoch 16, gen_loss = 0.8898406506902198, disc_loss = 0.0038951980944636113
Trained batch 1312 in epoch 16, gen_loss = 0.8899591603037609, disc_loss = 0.003893494286108673
Trained batch 1313 in epoch 16, gen_loss = 0.88994259769423, disc_loss = 0.003891448351746206
Trained batch 1314 in epoch 16, gen_loss = 0.8900123142244245, disc_loss = 0.003889288862770115
Trained batch 1315 in epoch 16, gen_loss = 0.890080162706165, disc_loss = 0.00388749584929243
Trained batch 1316 in epoch 16, gen_loss = 0.890116897309107, disc_loss = 0.0038850102645564075
Trained batch 1317 in epoch 16, gen_loss = 0.8901245127995929, disc_loss = 0.0038830904963994945
Trained batch 1318 in epoch 16, gen_loss = 0.8901381315698761, disc_loss = 0.0038806434671306797
Trained batch 1319 in epoch 16, gen_loss = 0.8902046393490199, disc_loss = 0.003880181987485478
Trained batch 1320 in epoch 16, gen_loss = 0.8901525731568621, disc_loss = 0.003878434221832632
Trained batch 1321 in epoch 16, gen_loss = 0.8902562020090091, disc_loss = 0.003878418623387258
Trained batch 1322 in epoch 16, gen_loss = 0.8903073961547353, disc_loss = 0.00387716711148715
Trained batch 1323 in epoch 16, gen_loss = 0.8903129258589803, disc_loss = 0.0038749758417209366
Trained batch 1324 in epoch 16, gen_loss = 0.8904404205871078, disc_loss = 0.0038730812489542726
Trained batch 1325 in epoch 16, gen_loss = 0.890453670921189, disc_loss = 0.0038710609570384935
Trained batch 1326 in epoch 16, gen_loss = 0.8904588210151532, disc_loss = 0.003868672880859496
Trained batch 1327 in epoch 16, gen_loss = 0.8902787223503174, disc_loss = 0.003945618911957244
Trained batch 1328 in epoch 16, gen_loss = 0.8903627751957124, disc_loss = 0.003953933685588681
Trained batch 1329 in epoch 16, gen_loss = 0.8904786451642674, disc_loss = 0.004024347033309208
Trained batch 1330 in epoch 16, gen_loss = 0.8905632668066347, disc_loss = 0.00403082232554221
Trained batch 1331 in epoch 16, gen_loss = 0.8905738860860959, disc_loss = 0.0040359653946841325
Trained batch 1332 in epoch 16, gen_loss = 0.8906280323024629, disc_loss = 0.004037566520999862
Trained batch 1333 in epoch 16, gen_loss = 0.8906069618874582, disc_loss = 0.004036423995520768
Trained batch 1334 in epoch 16, gen_loss = 0.890287955468067, disc_loss = 0.004396693401066115
Trained batch 1335 in epoch 16, gen_loss = 0.8899914837124462, disc_loss = 0.004588388016246225
Trained batch 1336 in epoch 16, gen_loss = 0.8903181455477727, disc_loss = 0.004773141757299773
Trained batch 1337 in epoch 16, gen_loss = 0.8901282384301159, disc_loss = 0.004893276588030292
Trained batch 1338 in epoch 16, gen_loss = 0.8902003394079528, disc_loss = 0.0049289060074656395
Trained batch 1339 in epoch 16, gen_loss = 0.8901072719426297, disc_loss = 0.00496852079973471
Trained batch 1340 in epoch 16, gen_loss = 0.889999595997851, disc_loss = 0.005009628044333955
Trained batch 1341 in epoch 16, gen_loss = 0.8899797570465574, disc_loss = 0.005026622057271529
Trained batch 1342 in epoch 16, gen_loss = 0.8897936146426183, disc_loss = 0.00507567873372974
Trained batch 1343 in epoch 16, gen_loss = 0.8898202246720237, disc_loss = 0.005189803955144747
Trained batch 1344 in epoch 16, gen_loss = 0.8898290860387029, disc_loss = 0.00519043362402352
Trained batch 1345 in epoch 16, gen_loss = 0.8897633914563136, disc_loss = 0.005217235514528362
Trained batch 1346 in epoch 16, gen_loss = 0.8897954031504254, disc_loss = 0.0052310856488275255
Trained batch 1347 in epoch 16, gen_loss = 0.8898405952473069, disc_loss = 0.005232134191305097
Trained batch 1348 in epoch 16, gen_loss = 0.8899151545219549, disc_loss = 0.005232220564873871
Trained batch 1349 in epoch 16, gen_loss = 0.890004294956172, disc_loss = 0.005231724015029613
Trained batch 1350 in epoch 16, gen_loss = 0.8899799230405792, disc_loss = 0.005229892487403576
Trained batch 1351 in epoch 16, gen_loss = 0.8900040936320138, disc_loss = 0.0052273146064600534
Trained batch 1352 in epoch 16, gen_loss = 0.8900242302255638, disc_loss = 0.005224851231872936
Trained batch 1353 in epoch 16, gen_loss = 0.8899358973413309, disc_loss = 0.005239033822473286
Trained batch 1354 in epoch 16, gen_loss = 0.8897173659168046, disc_loss = 0.0052672431380569595
Trained batch 1355 in epoch 16, gen_loss = 0.8898498140121631, disc_loss = 0.005542856875908267
Trained batch 1356 in epoch 16, gen_loss = 0.8898666294822819, disc_loss = 0.005561282504020089
Trained batch 1357 in epoch 16, gen_loss = 0.8897258264282841, disc_loss = 0.005613847833101666
Trained batch 1358 in epoch 16, gen_loss = 0.8897835348922598, disc_loss = 0.0056167244862259155
Trained batch 1359 in epoch 16, gen_loss = 0.8897622517145732, disc_loss = 0.0056189454015860545
Trained batch 1360 in epoch 16, gen_loss = 0.8897765162541181, disc_loss = 0.0056195813202836176
Trained batch 1361 in epoch 16, gen_loss = 0.8898505019940294, disc_loss = 0.005617152876158675
Trained batch 1362 in epoch 16, gen_loss = 0.8899499394179965, disc_loss = 0.005614265537555897
Trained batch 1363 in epoch 16, gen_loss = 0.8901376745436897, disc_loss = 0.005611334013628628
Trained batch 1364 in epoch 16, gen_loss = 0.8900959029957488, disc_loss = 0.005608621439135347
Trained batch 1365 in epoch 16, gen_loss = 0.8901671525718178, disc_loss = 0.005605403437012159
Trained batch 1366 in epoch 16, gen_loss = 0.8902213593730982, disc_loss = 0.005602266768820229
Trained batch 1367 in epoch 16, gen_loss = 0.8903369052411868, disc_loss = 0.005599135906719014
Trained batch 1368 in epoch 16, gen_loss = 0.8903588774301782, disc_loss = 0.005595533852480333
Trained batch 1369 in epoch 16, gen_loss = 0.8903691946372498, disc_loss = 0.005592097311115392
Trained batch 1370 in epoch 16, gen_loss = 0.8904060612926511, disc_loss = 0.005588705609674412
Trained batch 1371 in epoch 16, gen_loss = 0.890401285760778, disc_loss = 0.005585681218130812
Trained batch 1372 in epoch 16, gen_loss = 0.8904065077138138, disc_loss = 0.00558432630824869
Trained batch 1373 in epoch 16, gen_loss = 0.8904183976558272, disc_loss = 0.005581420506177429
Trained batch 1374 in epoch 16, gen_loss = 0.890312907630747, disc_loss = 0.005580751181484878
Trained batch 1375 in epoch 16, gen_loss = 0.8904004528208874, disc_loss = 0.0055795438994675015
Trained batch 1376 in epoch 16, gen_loss = 0.8904162904838764, disc_loss = 0.005580216781959494
Trained batch 1377 in epoch 16, gen_loss = 0.8905092561495841, disc_loss = 0.005577734608499449
Trained batch 1378 in epoch 16, gen_loss = 0.8905598042969085, disc_loss = 0.00557580800689485
Trained batch 1379 in epoch 16, gen_loss = 0.890421944619089, disc_loss = 0.005596418227935868
Trained batch 1380 in epoch 16, gen_loss = 0.8904603337525113, disc_loss = 0.005600865679437913
Trained batch 1381 in epoch 16, gen_loss = 0.890268839583038, disc_loss = 0.005695330752682749
Trained batch 1382 in epoch 16, gen_loss = 0.8903694543516127, disc_loss = 0.0057556622338982765
Trained batch 1383 in epoch 16, gen_loss = 0.8904002854718983, disc_loss = 0.005753632846501279
Trained batch 1384 in epoch 16, gen_loss = 0.8904226792202959, disc_loss = 0.005751059478346766
Trained batch 1385 in epoch 16, gen_loss = 0.8904078320034311, disc_loss = 0.005750280676579186
Trained batch 1386 in epoch 16, gen_loss = 0.8902017925184411, disc_loss = 0.005779561769306138
Trained batch 1387 in epoch 16, gen_loss = 0.8902517413070978, disc_loss = 0.005783103458084396
Trained batch 1388 in epoch 16, gen_loss = 0.8901819871474377, disc_loss = 0.005853050275741543
Trained batch 1389 in epoch 16, gen_loss = 0.890237888222118, disc_loss = 0.005853089724033787
Trained batch 1390 in epoch 16, gen_loss = 0.8902329373368251, disc_loss = 0.005854080350473935
Trained batch 1391 in epoch 16, gen_loss = 0.8899541458907141, disc_loss = 0.006197459533085613
Trained batch 1392 in epoch 16, gen_loss = 0.8897933207949715, disc_loss = 0.0062863101994772375
Trained batch 1393 in epoch 16, gen_loss = 0.8900012936833257, disc_loss = 0.006449415465042118
Trained batch 1394 in epoch 16, gen_loss = 0.8900253145711824, disc_loss = 0.006479031130941468
Trained batch 1395 in epoch 16, gen_loss = 0.8900399155765345, disc_loss = 0.006484576528627985
Trained batch 1396 in epoch 16, gen_loss = 0.8900227840021839, disc_loss = 0.0064864761873298215
Trained batch 1397 in epoch 16, gen_loss = 0.8899667826034822, disc_loss = 0.006501965269699772
Trained batch 1398 in epoch 16, gen_loss = 0.8898797294895848, disc_loss = 0.006509219015671125
Trained batch 1399 in epoch 16, gen_loss = 0.88993950220091, disc_loss = 0.0065071710130827605
Trained batch 1400 in epoch 16, gen_loss = 0.8898734440342347, disc_loss = 0.0065207731157775105
Trained batch 1401 in epoch 16, gen_loss = 0.8900141350170345, disc_loss = 0.006518987092622852
Trained batch 1402 in epoch 16, gen_loss = 0.8901286192094948, disc_loss = 0.006517653502360851
Trained batch 1403 in epoch 16, gen_loss = 0.8900942220180122, disc_loss = 0.006588710853560915
Trained batch 1404 in epoch 16, gen_loss = 0.8901184344418956, disc_loss = 0.006591243957228598
Trained batch 1405 in epoch 16, gen_loss = 0.8901137968851187, disc_loss = 0.006593674837447591
Trained batch 1406 in epoch 16, gen_loss = 0.8902104736941879, disc_loss = 0.006592437954723035
Trained batch 1407 in epoch 16, gen_loss = 0.8902683196039024, disc_loss = 0.006589773716427771
Trained batch 1408 in epoch 16, gen_loss = 0.8902608638244626, disc_loss = 0.006593892190990341
Trained batch 1409 in epoch 16, gen_loss = 0.8902102411850125, disc_loss = 0.006591742197602759
Trained batch 1410 in epoch 16, gen_loss = 0.8903520324186261, disc_loss = 0.006589585942754401
Trained batch 1411 in epoch 16, gen_loss = 0.8904780359469122, disc_loss = 0.006586511690118373
Trained batch 1412 in epoch 16, gen_loss = 0.8904541302933731, disc_loss = 0.00658301781192618
Trained batch 1413 in epoch 16, gen_loss = 0.8905955090844817, disc_loss = 0.006579712509872742
Trained batch 1414 in epoch 16, gen_loss = 0.8905682368960903, disc_loss = 0.006576317854218643
Trained batch 1415 in epoch 16, gen_loss = 0.8906055019779057, disc_loss = 0.006572300035423533
Trained batch 1416 in epoch 16, gen_loss = 0.8906027899506904, disc_loss = 0.006568144657597752
Trained batch 1417 in epoch 16, gen_loss = 0.890587108827108, disc_loss = 0.006563966425658451
Trained batch 1418 in epoch 16, gen_loss = 0.8906256051824663, disc_loss = 0.006559982152513873
Trained batch 1419 in epoch 16, gen_loss = 0.8906545816802642, disc_loss = 0.006558664378488328
Trained batch 1420 in epoch 16, gen_loss = 0.8906748743857572, disc_loss = 0.006554836373663387
Trained batch 1421 in epoch 16, gen_loss = 0.8907810091846603, disc_loss = 0.006551767182950263
Trained batch 1422 in epoch 16, gen_loss = 0.8908829866834534, disc_loss = 0.006548569375010242
Trained batch 1423 in epoch 16, gen_loss = 0.8909823526366708, disc_loss = 0.006544388286753285
Trained batch 1424 in epoch 16, gen_loss = 0.8910412402529465, disc_loss = 0.006540507570291019
Trained batch 1425 in epoch 16, gen_loss = 0.8910706814216531, disc_loss = 0.006537403132028725
Trained batch 1426 in epoch 16, gen_loss = 0.8912261588513308, disc_loss = 0.006533626509401161
Trained batch 1427 in epoch 16, gen_loss = 0.8912297532546753, disc_loss = 0.006529496100927095
Trained batch 1428 in epoch 16, gen_loss = 0.8913178754445137, disc_loss = 0.006525580022826467
Trained batch 1429 in epoch 16, gen_loss = 0.891341501620266, disc_loss = 0.006521426321654923
Trained batch 1430 in epoch 16, gen_loss = 0.8913737719372217, disc_loss = 0.006517303291653155
Trained batch 1431 in epoch 16, gen_loss = 0.8913688639064408, disc_loss = 0.0065130615076470465
Trained batch 1432 in epoch 16, gen_loss = 0.8913640306075802, disc_loss = 0.006509022623852083
Trained batch 1433 in epoch 16, gen_loss = 0.8914490589661578, disc_loss = 0.006505105431249506
Trained batch 1434 in epoch 16, gen_loss = 0.8913398931043073, disc_loss = 0.006518605645903782
Trained batch 1435 in epoch 16, gen_loss = 0.8913669482205572, disc_loss = 0.0065159127300737
Trained batch 1436 in epoch 16, gen_loss = 0.8914834600027518, disc_loss = 0.006513582454366391
Trained batch 1437 in epoch 16, gen_loss = 0.8915934346937503, disc_loss = 0.006510439944735347
Trained batch 1438 in epoch 16, gen_loss = 0.8916714414902409, disc_loss = 0.006506707693359625
Trained batch 1439 in epoch 16, gen_loss = 0.8917281215182609, disc_loss = 0.0065039355737604235
Trained batch 1440 in epoch 16, gen_loss = 0.8917506070165151, disc_loss = 0.006500409393800189
Trained batch 1441 in epoch 16, gen_loss = 0.8917849269513449, disc_loss = 0.0064970530370165895
Trained batch 1442 in epoch 16, gen_loss = 0.8918120421350456, disc_loss = 0.006493142478015775
Trained batch 1443 in epoch 16, gen_loss = 0.8919036326274647, disc_loss = 0.006489461049190584
Trained batch 1444 in epoch 16, gen_loss = 0.8919034021329715, disc_loss = 0.00648702895861952
Trained batch 1445 in epoch 16, gen_loss = 0.8919302826311908, disc_loss = 0.006483589246662422
Trained batch 1446 in epoch 16, gen_loss = 0.8919794946064518, disc_loss = 0.006479979421251612
Trained batch 1447 in epoch 16, gen_loss = 0.8919765000226418, disc_loss = 0.00647681370287375
Trained batch 1448 in epoch 16, gen_loss = 0.8920703843554766, disc_loss = 0.006473084115566672
Trained batch 1449 in epoch 16, gen_loss = 0.892109572085841, disc_loss = 0.006469595603823485
Trained batch 1450 in epoch 16, gen_loss = 0.8921856440855338, disc_loss = 0.006466233091261433
Trained batch 1451 in epoch 16, gen_loss = 0.8922006372290537, disc_loss = 0.006462724483926725
Trained batch 1452 in epoch 16, gen_loss = 0.892210699428137, disc_loss = 0.006460006390421437
Trained batch 1453 in epoch 16, gen_loss = 0.8921604862608312, disc_loss = 0.006457541862016616
Trained batch 1454 in epoch 16, gen_loss = 0.8921228275061474, disc_loss = 0.00645377363989016
Trained batch 1455 in epoch 16, gen_loss = 0.8921937134198763, disc_loss = 0.006450243474029156
Trained batch 1456 in epoch 16, gen_loss = 0.8921988225793217, disc_loss = 0.006446471063207401
Trained batch 1457 in epoch 16, gen_loss = 0.8923085876657475, disc_loss = 0.006442752856135944
Trained batch 1458 in epoch 16, gen_loss = 0.8922928542082567, disc_loss = 0.006439000101266681
Trained batch 1459 in epoch 16, gen_loss = 0.892325552910158, disc_loss = 0.006434995742574133
Trained batch 1460 in epoch 16, gen_loss = 0.8923446995644109, disc_loss = 0.00643130751533415
Trained batch 1461 in epoch 16, gen_loss = 0.8923411515073802, disc_loss = 0.006427204012127466
Trained batch 1462 in epoch 16, gen_loss = 0.8924485660748211, disc_loss = 0.006423808104454181
Trained batch 1463 in epoch 16, gen_loss = 0.892527829896394, disc_loss = 0.006420062118751977
Trained batch 1464 in epoch 16, gen_loss = 0.8925053264297316, disc_loss = 0.006416268153888898
Trained batch 1465 in epoch 16, gen_loss = 0.8925962061665719, disc_loss = 0.006412684882042938
Trained batch 1466 in epoch 16, gen_loss = 0.8925823070560902, disc_loss = 0.006409251073990909
Trained batch 1467 in epoch 16, gen_loss = 0.8925620214125441, disc_loss = 0.00640535146233409
Trained batch 1468 in epoch 16, gen_loss = 0.8925802417763891, disc_loss = 0.006401642996141763
Trained batch 1469 in epoch 16, gen_loss = 0.892645534143156, disc_loss = 0.0063984052682090325
Trained batch 1470 in epoch 16, gen_loss = 0.8927874937298993, disc_loss = 0.006397508502802761
Trained batch 1471 in epoch 16, gen_loss = 0.8928753810772754, disc_loss = 0.00639383945086474
Trained batch 1472 in epoch 16, gen_loss = 0.8928908995641629, disc_loss = 0.006390718137902695
Trained batch 1473 in epoch 16, gen_loss = 0.8928589301039762, disc_loss = 0.006386891723616542
Trained batch 1474 in epoch 16, gen_loss = 0.8928963103738882, disc_loss = 0.006383780743068447
Trained batch 1475 in epoch 16, gen_loss = 0.8929693309797181, disc_loss = 0.006380304693791219
Trained batch 1476 in epoch 16, gen_loss = 0.8929581652845009, disc_loss = 0.006376394448197257
Trained batch 1477 in epoch 16, gen_loss = 0.8930214143210722, disc_loss = 0.0063725618056245485
Trained batch 1478 in epoch 16, gen_loss = 0.8930304077648488, disc_loss = 0.006368793708247799
Trained batch 1479 in epoch 16, gen_loss = 0.8931058127131011, disc_loss = 0.006364974522826693
Trained batch 1480 in epoch 16, gen_loss = 0.8931199837624423, disc_loss = 0.006360996257016422
Trained batch 1481 in epoch 16, gen_loss = 0.8931962891749525, disc_loss = 0.006357263369967186
Trained batch 1482 in epoch 16, gen_loss = 0.893319987619719, disc_loss = 0.006353434406327124
Trained batch 1483 in epoch 16, gen_loss = 0.8933609544708723, disc_loss = 0.006349912474377566
Trained batch 1484 in epoch 16, gen_loss = 0.8934226760759899, disc_loss = 0.006346015057729177
Trained batch 1485 in epoch 16, gen_loss = 0.8934549288786596, disc_loss = 0.006342202090455892
Trained batch 1486 in epoch 16, gen_loss = 0.8934567509157672, disc_loss = 0.006338277521072924
Trained batch 1487 in epoch 16, gen_loss = 0.8934807162731886, disc_loss = 0.0063346299432567475
Trained batch 1488 in epoch 16, gen_loss = 0.8935589971880211, disc_loss = 0.006331161092388627
Trained batch 1489 in epoch 16, gen_loss = 0.8935941460748646, disc_loss = 0.006327382601329185
Trained batch 1490 in epoch 16, gen_loss = 0.8935460369311907, disc_loss = 0.006323558326019583
Trained batch 1491 in epoch 16, gen_loss = 0.8935653982589136, disc_loss = 0.006319696738783925
Trained batch 1492 in epoch 16, gen_loss = 0.8935565516322711, disc_loss = 0.006316215563101157
Trained batch 1493 in epoch 16, gen_loss = 0.8935291612523307, disc_loss = 0.006312277379505809
Trained batch 1494 in epoch 16, gen_loss = 0.8934735631264971, disc_loss = 0.006308526491633785
Trained batch 1495 in epoch 16, gen_loss = 0.8935645800980336, disc_loss = 0.006304703478537295
Trained batch 1496 in epoch 16, gen_loss = 0.8936166684668941, disc_loss = 0.006301339450528309
Trained batch 1497 in epoch 16, gen_loss = 0.8936242590719294, disc_loss = 0.006298164910103648
Trained batch 1498 in epoch 16, gen_loss = 0.8935847172067514, disc_loss = 0.006294592097617131
Trained batch 1499 in epoch 16, gen_loss = 0.8935868457357089, disc_loss = 0.006290784722261984
Trained batch 1500 in epoch 16, gen_loss = 0.893606487331511, disc_loss = 0.00628710544624046
Trained batch 1501 in epoch 16, gen_loss = 0.8936650107171977, disc_loss = 0.006283411957743561
Trained batch 1502 in epoch 16, gen_loss = 0.8936529150623047, disc_loss = 0.0062796269004747945
Trained batch 1503 in epoch 16, gen_loss = 0.8936602519032486, disc_loss = 0.006275700818295786
Trained batch 1504 in epoch 16, gen_loss = 0.8937211183416487, disc_loss = 0.006272083219862852
Trained batch 1505 in epoch 16, gen_loss = 0.8936917715140706, disc_loss = 0.006268709545608676
Trained batch 1506 in epoch 16, gen_loss = 0.8938468211956505, disc_loss = 0.006265646554206377
Trained batch 1507 in epoch 16, gen_loss = 0.8938060274609521, disc_loss = 0.006262255718405294
Trained batch 1508 in epoch 16, gen_loss = 0.893783932552976, disc_loss = 0.006258411758596363
Trained batch 1509 in epoch 16, gen_loss = 0.8938405479619045, disc_loss = 0.006254900831797404
Trained batch 1510 in epoch 16, gen_loss = 0.8937501323333567, disc_loss = 0.00625125772705461
Trained batch 1511 in epoch 16, gen_loss = 0.8937281039617364, disc_loss = 0.006247440146585442
Trained batch 1512 in epoch 16, gen_loss = 0.8937010825153069, disc_loss = 0.006243626884680986
Trained batch 1513 in epoch 16, gen_loss = 0.8936504076187015, disc_loss = 0.006239876788379972
Trained batch 1514 in epoch 16, gen_loss = 0.8935522035206899, disc_loss = 0.00623614704763715
Trained batch 1515 in epoch 16, gen_loss = 0.8935232091901485, disc_loss = 0.006232527052060382
Trained batch 1516 in epoch 16, gen_loss = 0.8936298017094775, disc_loss = 0.0062290814804821385
Trained batch 1517 in epoch 16, gen_loss = 0.8936996820219578, disc_loss = 0.006225239577271337
Trained batch 1518 in epoch 16, gen_loss = 0.893774094492923, disc_loss = 0.006221531498293182
Trained batch 1519 in epoch 16, gen_loss = 0.8937742770306374, disc_loss = 0.006217968916969671
Trained batch 1520 in epoch 16, gen_loss = 0.8938489072931041, disc_loss = 0.006214402484961107
Trained batch 1521 in epoch 16, gen_loss = 0.8938895730832873, disc_loss = 0.006210978826847611
Trained batch 1522 in epoch 16, gen_loss = 0.8939382276758894, disc_loss = 0.006207346647566362
Trained batch 1523 in epoch 16, gen_loss = 0.8939860696828584, disc_loss = 0.006203616176504019
Trained batch 1524 in epoch 16, gen_loss = 0.8939075033586533, disc_loss = 0.006199881744343925
Trained batch 1525 in epoch 16, gen_loss = 0.8939261253469112, disc_loss = 0.006196097718898636
Trained batch 1526 in epoch 16, gen_loss = 0.8938639251601875, disc_loss = 0.006192530113905983
Trained batch 1527 in epoch 16, gen_loss = 0.893936571201885, disc_loss = 0.006189057348353263
Trained batch 1528 in epoch 16, gen_loss = 0.8939145432530547, disc_loss = 0.006185279891785022
Trained batch 1529 in epoch 16, gen_loss = 0.8938450385737263, disc_loss = 0.006182105675500626
Trained batch 1530 in epoch 16, gen_loss = 0.893898913959208, disc_loss = 0.006178478273805422
Trained batch 1531 in epoch 16, gen_loss = 0.8938946773932746, disc_loss = 0.006175276149612868
Trained batch 1532 in epoch 16, gen_loss = 0.893844269862458, disc_loss = 0.006173028458758143
Trained batch 1533 in epoch 16, gen_loss = 0.8938795086263522, disc_loss = 0.0061701573868523625
Trained batch 1534 in epoch 16, gen_loss = 0.8936240783537638, disc_loss = 0.006332516126592146
Trained batch 1535 in epoch 16, gen_loss = 0.8935638903834237, disc_loss = 0.006405262853746763
Trained batch 1536 in epoch 16, gen_loss = 0.8937364431387741, disc_loss = 0.006474002769174707
Trained batch 1537 in epoch 16, gen_loss = 0.8937000978946376, disc_loss = 0.006473369215168431
Trained batch 1538 in epoch 16, gen_loss = 0.8937519106135267, disc_loss = 0.006473883888732246
Trained batch 1539 in epoch 16, gen_loss = 0.8938299705262308, disc_loss = 0.0064713549375282325
Trained batch 1540 in epoch 16, gen_loss = 0.8938737856846672, disc_loss = 0.006468191062073262
Trained batch 1541 in epoch 16, gen_loss = 0.8938483863914368, disc_loss = 0.0064667743025434415
Trained batch 1542 in epoch 16, gen_loss = 0.8937258934209815, disc_loss = 0.006472904638306006
Trained batch 1543 in epoch 16, gen_loss = 0.8936851695372959, disc_loss = 0.006472630361737089
Trained batch 1544 in epoch 16, gen_loss = 0.8937887623665016, disc_loss = 0.006470441814912498
Trained batch 1545 in epoch 16, gen_loss = 0.8938371144514652, disc_loss = 0.006468242120450976
Trained batch 1546 in epoch 16, gen_loss = 0.8938938581758572, disc_loss = 0.006464810892340183
Trained batch 1547 in epoch 16, gen_loss = 0.8938506508019851, disc_loss = 0.006465527313530613
Trained batch 1548 in epoch 16, gen_loss = 0.8940032357127533, disc_loss = 0.006463561066656838
Trained batch 1549 in epoch 16, gen_loss = 0.8939380400219271, disc_loss = 0.006482049257094566
Trained batch 1550 in epoch 16, gen_loss = 0.8940170445148596, disc_loss = 0.006481773138029677
Trained batch 1551 in epoch 16, gen_loss = 0.8941497674269467, disc_loss = 0.006479627115086916
Trained batch 1552 in epoch 16, gen_loss = 0.8941674880534698, disc_loss = 0.00647699145112912
Trained batch 1553 in epoch 16, gen_loss = 0.894181206860751, disc_loss = 0.006473664296442985
Trained batch 1554 in epoch 16, gen_loss = 0.8943080179752644, disc_loss = 0.00647025730892667
Trained batch 1555 in epoch 16, gen_loss = 0.8942579251443512, disc_loss = 0.006482083391485204
Trained batch 1556 in epoch 16, gen_loss = 0.8942760906123013, disc_loss = 0.006480686715645156
Trained batch 1557 in epoch 16, gen_loss = 0.8941826151064639, disc_loss = 0.006480737325450479
Trained batch 1558 in epoch 16, gen_loss = 0.8941751807794271, disc_loss = 0.006477703000131724
Trained batch 1559 in epoch 16, gen_loss = 0.8942219082934734, disc_loss = 0.006474259548336611
Trained batch 1560 in epoch 16, gen_loss = 0.8941938427111645, disc_loss = 0.006470931485607552
Trained batch 1561 in epoch 16, gen_loss = 0.8942468022681992, disc_loss = 0.0064673770574724485
Trained batch 1562 in epoch 16, gen_loss = 0.8942794148653498, disc_loss = 0.006463615127413632
Trained batch 1563 in epoch 16, gen_loss = 0.8943043956937997, disc_loss = 0.00645988077673008
Trained batch 1564 in epoch 16, gen_loss = 0.8943612331589952, disc_loss = 0.006456578080644667
Trained batch 1565 in epoch 16, gen_loss = 0.8943579211964309, disc_loss = 0.006452945381532542
Trained batch 1566 in epoch 16, gen_loss = 0.894365560555808, disc_loss = 0.006449105656439758
Trained batch 1567 in epoch 16, gen_loss = 0.8943662673653084, disc_loss = 0.006445402098293295
Trained batch 1568 in epoch 16, gen_loss = 0.8943975142911409, disc_loss = 0.006441581100952209
Trained batch 1569 in epoch 16, gen_loss = 0.8944456951063909, disc_loss = 0.006437860071652785
Trained batch 1570 in epoch 16, gen_loss = 0.8945124674609783, disc_loss = 0.006434068296984343
Trained batch 1571 in epoch 16, gen_loss = 0.8945711701918801, disc_loss = 0.0064302263211108044
Trained batch 1572 in epoch 16, gen_loss = 0.8945136503550328, disc_loss = 0.006426388056920584
Trained batch 1573 in epoch 16, gen_loss = 0.8944759055915297, disc_loss = 0.006422699818381636
Trained batch 1574 in epoch 16, gen_loss = 0.8945233282777998, disc_loss = 0.0064190875368085615
Trained batch 1575 in epoch 16, gen_loss = 0.8945624527857086, disc_loss = 0.00641543379985941
Trained batch 1576 in epoch 16, gen_loss = 0.8945832405010204, disc_loss = 0.00641164076647604
Trained batch 1577 in epoch 16, gen_loss = 0.8945598682560999, disc_loss = 0.006407910991877719
Trained batch 1578 in epoch 16, gen_loss = 0.8946281527514093, disc_loss = 0.006404120830244012
Trained batch 1579 in epoch 16, gen_loss = 0.8945869977904272, disc_loss = 0.006400392449262354
Trained batch 1580 in epoch 16, gen_loss = 0.894640421637397, disc_loss = 0.006396685286287285
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.8743227124214172, disc_loss = 0.0003052114916499704
Trained batch 1 in epoch 17, gen_loss = 0.8982073366641998, disc_loss = 0.00036228720273356885
Trained batch 2 in epoch 17, gen_loss = 0.843814750512441, disc_loss = 0.0007366845675278455
Trained batch 3 in epoch 17, gen_loss = 0.8516037911176682, disc_loss = 0.0006656369296251796
Trained batch 4 in epoch 17, gen_loss = 0.8395075798034668, disc_loss = 0.0005903876270167529
Trained batch 5 in epoch 17, gen_loss = 0.8855387767155966, disc_loss = 0.0006775086803827435
Trained batch 6 in epoch 17, gen_loss = 0.8934123686381749, disc_loss = 0.000669647374057344
Trained batch 7 in epoch 17, gen_loss = 0.902280792593956, disc_loss = 0.0006384005901054479
Trained batch 8 in epoch 17, gen_loss = 0.8969996240403917, disc_loss = 0.0006403355768674777
Trained batch 9 in epoch 17, gen_loss = 0.8964202880859375, disc_loss = 0.0006222240335773677
Trained batch 10 in epoch 17, gen_loss = 0.9039871746843512, disc_loss = 0.0006139982565814121
Trained batch 11 in epoch 17, gen_loss = 0.9033186286687851, disc_loss = 0.0005938494578003883
Trained batch 12 in epoch 17, gen_loss = 0.9084184307318467, disc_loss = 0.000595056783193006
Trained batch 13 in epoch 17, gen_loss = 0.9095645930085864, disc_loss = 0.000603856090622555
Trained batch 14 in epoch 17, gen_loss = 0.9013006091117859, disc_loss = 0.0005943287862464786
Trained batch 15 in epoch 17, gen_loss = 0.9071619920432568, disc_loss = 0.0005912533379159868
Trained batch 16 in epoch 17, gen_loss = 0.9048280680880827, disc_loss = 0.0005825269926229821
Trained batch 17 in epoch 17, gen_loss = 0.8968965576754676, disc_loss = 0.0005792386299516591
Trained batch 18 in epoch 17, gen_loss = 0.8913169660066304, disc_loss = 0.0005938652106315681
Trained batch 19 in epoch 17, gen_loss = 0.8913733720779419, disc_loss = 0.0005950083490461111
Trained batch 20 in epoch 17, gen_loss = 0.8897762383733477, disc_loss = 0.0005990019722265147
Trained batch 21 in epoch 17, gen_loss = 0.8851506791331551, disc_loss = 0.0008960547804070467
Trained batch 22 in epoch 17, gen_loss = 0.8928584871084794, disc_loss = 0.0009441843367708118
Trained batch 23 in epoch 17, gen_loss = 0.8953424667318662, disc_loss = 0.0009678811232636993
Trained batch 24 in epoch 17, gen_loss = 0.9062854933738709, disc_loss = 0.0010283481189981103
Trained batch 25 in epoch 17, gen_loss = 0.9117131301989922, disc_loss = 0.0010315568338578136
Trained batch 26 in epoch 17, gen_loss = 0.9134537665932266, disc_loss = 0.0010247096932424163
Trained batch 27 in epoch 17, gen_loss = 0.9186407944985798, disc_loss = 0.0010200980655749195
Trained batch 28 in epoch 17, gen_loss = 0.9206260381073788, disc_loss = 0.0010205979382715605
Trained batch 29 in epoch 17, gen_loss = 0.9180857916673024, disc_loss = 0.0010032112535554917
Trained batch 30 in epoch 17, gen_loss = 0.9182386186815077, disc_loss = 0.000998503438407375
Trained batch 31 in epoch 17, gen_loss = 0.923155726864934, disc_loss = 0.0009998791792895645
Trained batch 32 in epoch 17, gen_loss = 0.9244123245730544, disc_loss = 0.000985902106163628
Trained batch 33 in epoch 17, gen_loss = 0.9288584923042971, disc_loss = 0.0009715370354516542
Trained batch 34 in epoch 17, gen_loss = 0.9230963315282549, disc_loss = 0.0013621739577502011
Trained batch 35 in epoch 17, gen_loss = 0.9257161898745431, disc_loss = 0.00135021707683336
Trained batch 36 in epoch 17, gen_loss = 0.9268572958740028, disc_loss = 0.0013418468391849987
Trained batch 37 in epoch 17, gen_loss = 0.9295671692020014, disc_loss = 0.0013311626741932215
Trained batch 38 in epoch 17, gen_loss = 0.9299073800062522, disc_loss = 0.0013221107133759712
Trained batch 39 in epoch 17, gen_loss = 0.9289249658584595, disc_loss = 0.0013078265750664287
Trained batch 40 in epoch 17, gen_loss = 0.9302791357040405, disc_loss = 0.001291156614415075
Trained batch 41 in epoch 17, gen_loss = 0.9338267161732628, disc_loss = 0.0012791746093647643
Trained batch 42 in epoch 17, gen_loss = 0.9341136799302212, disc_loss = 0.0012614223415703448
Trained batch 43 in epoch 17, gen_loss = 0.9355400556867773, disc_loss = 0.0012734451487300578
Trained batch 44 in epoch 17, gen_loss = 0.9348759810129802, disc_loss = 0.00127334092459124
Trained batch 45 in epoch 17, gen_loss = 0.9361126293306765, disc_loss = 0.0012702756654977313
Trained batch 46 in epoch 17, gen_loss = 0.9339902603879888, disc_loss = 0.001278329156388707
Trained batch 47 in epoch 17, gen_loss = 0.9338553895552953, disc_loss = 0.0012681964496247626
Trained batch 48 in epoch 17, gen_loss = 0.933892411845071, disc_loss = 0.0012908015526089892
Trained batch 49 in epoch 17, gen_loss = 0.9333496010303497, disc_loss = 0.00127330441493541
Trained batch 50 in epoch 17, gen_loss = 0.932290674424639, disc_loss = 0.0012762354545331762
Trained batch 51 in epoch 17, gen_loss = 0.9304040039961154, disc_loss = 0.0012629454476364816
Trained batch 52 in epoch 17, gen_loss = 0.9292472117352035, disc_loss = 0.001251915039248624
Trained batch 53 in epoch 17, gen_loss = 0.9295909051541928, disc_loss = 0.001242027476783497
Trained batch 54 in epoch 17, gen_loss = 0.9288678288459777, disc_loss = 0.0012246808047745039
Trained batch 55 in epoch 17, gen_loss = 0.9273741958396775, disc_loss = 0.001210102997512357
Trained batch 56 in epoch 17, gen_loss = 0.9270518443040681, disc_loss = 0.0011996814905535103
Trained batch 57 in epoch 17, gen_loss = 0.9262178879359673, disc_loss = 0.0011866579578932502
Trained batch 58 in epoch 17, gen_loss = 0.9259799840086598, disc_loss = 0.001171843532543882
Trained batch 59 in epoch 17, gen_loss = 0.92508438428243, disc_loss = 0.0011578892454660187
Trained batch 60 in epoch 17, gen_loss = 0.9233196934715646, disc_loss = 0.0012231742539519413
Trained batch 61 in epoch 17, gen_loss = 0.9237423269979416, disc_loss = 0.0012549602880983824
Trained batch 62 in epoch 17, gen_loss = 0.9226523931064303, disc_loss = 0.0012463722294861718
Trained batch 63 in epoch 17, gen_loss = 0.9232513522729278, disc_loss = 0.0012402778475006926
Trained batch 64 in epoch 17, gen_loss = 0.9211361646652222, disc_loss = 0.0015672126453584777
Trained batch 65 in epoch 17, gen_loss = 0.9213946786793795, disc_loss = 0.0016372371632535237
Trained batch 66 in epoch 17, gen_loss = 0.9188053874827143, disc_loss = 0.0029506907588107262
Trained batch 67 in epoch 17, gen_loss = 0.917574364472838, disc_loss = 0.0030031295601100497
Trained batch 68 in epoch 17, gen_loss = 0.9169120261634606, disc_loss = 0.0030950609133983758
Trained batch 69 in epoch 17, gen_loss = 0.9128040177481515, disc_loss = 0.004614097095327452
Trained batch 70 in epoch 17, gen_loss = 0.9141726896796428, disc_loss = 0.004656067179535634
Trained batch 71 in epoch 17, gen_loss = 0.915721572107739, disc_loss = 0.00482528217819183
Trained batch 72 in epoch 17, gen_loss = 0.9156437957123534, disc_loss = 0.00482196332360554
Trained batch 73 in epoch 17, gen_loss = 0.9166647010558361, disc_loss = 0.0048747479976972916
Trained batch 74 in epoch 17, gen_loss = 0.9161025420824687, disc_loss = 0.004846294499778499
Trained batch 75 in epoch 17, gen_loss = 0.9157866576784536, disc_loss = 0.004883895072883828
Trained batch 76 in epoch 17, gen_loss = 0.9160959759315888, disc_loss = 0.004869100537193431
Trained batch 77 in epoch 17, gen_loss = 0.9178545559063936, disc_loss = 0.004850023798495293
Trained batch 78 in epoch 17, gen_loss = 0.9152052010161967, disc_loss = 0.004812688692738125
Trained batch 79 in epoch 17, gen_loss = 0.9157141663134098, disc_loss = 0.004771179969975492
Trained batch 80 in epoch 17, gen_loss = 0.9161628985110625, disc_loss = 0.004748972600619136
Trained batch 81 in epoch 17, gen_loss = 0.9142287300854195, disc_loss = 0.005017332626909881
Trained batch 82 in epoch 17, gen_loss = 0.9145843106580068, disc_loss = 0.005005921463689666
Trained batch 83 in epoch 17, gen_loss = 0.9156519430024284, disc_loss = 0.004978850763152531
Trained batch 84 in epoch 17, gen_loss = 0.915235655448016, disc_loss = 0.004947447436450816
Trained batch 85 in epoch 17, gen_loss = 0.9134420128755791, disc_loss = 0.005014649764932475
Trained batch 86 in epoch 17, gen_loss = 0.9133789731168199, disc_loss = 0.004997171458236916
Trained batch 87 in epoch 17, gen_loss = 0.9137544774196364, disc_loss = 0.004985133055676918
Trained batch 88 in epoch 17, gen_loss = 0.9138666458344191, disc_loss = 0.004951592484421065
Trained batch 89 in epoch 17, gen_loss = 0.9140450225936042, disc_loss = 0.004950234564926682
Trained batch 90 in epoch 17, gen_loss = 0.9131026071506542, disc_loss = 0.004908517189195973
Trained batch 91 in epoch 17, gen_loss = 0.9134578043999879, disc_loss = 0.004893337641513664
Trained batch 92 in epoch 17, gen_loss = 0.9129349332983776, disc_loss = 0.004849848272379047
Trained batch 93 in epoch 17, gen_loss = 0.9095814044171191, disc_loss = 0.005853770682191912
Trained batch 94 in epoch 17, gen_loss = 0.9096990058296606, disc_loss = 0.00890350383461306
Trained batch 95 in epoch 17, gen_loss = 0.9097824593385061, disc_loss = 0.008859072089156447
Trained batch 96 in epoch 17, gen_loss = 0.9092024822825009, disc_loss = 0.008886907340901107
Trained batch 97 in epoch 17, gen_loss = 0.909865348922963, disc_loss = 0.008861410027673962
Trained batch 98 in epoch 17, gen_loss = 0.9110219719434025, disc_loss = 0.008794957096923631
Trained batch 99 in epoch 17, gen_loss = 0.9106063079833985, disc_loss = 0.008726560201030225
Trained batch 100 in epoch 17, gen_loss = 0.9119513483330755, disc_loss = 0.00867748393050146
Trained batch 101 in epoch 17, gen_loss = 0.911026093305326, disc_loss = 0.0086933453179275
Trained batch 102 in epoch 17, gen_loss = 0.9094566633400408, disc_loss = 0.008651222253796978
Trained batch 103 in epoch 17, gen_loss = 0.9098479403899267, disc_loss = 0.008620404260000214
Trained batch 104 in epoch 17, gen_loss = 0.909939600172497, disc_loss = 0.008637484630924605
Trained batch 105 in epoch 17, gen_loss = 0.9085431031461032, disc_loss = 0.008933731695232948
Trained batch 106 in epoch 17, gen_loss = 0.9113355574206771, disc_loss = 0.00898897638065723
Trained batch 107 in epoch 17, gen_loss = 0.9128018131962529, disc_loss = 0.008969468812682424
Trained batch 108 in epoch 17, gen_loss = 0.9129026433743468, disc_loss = 0.008925853611115333
Trained batch 109 in epoch 17, gen_loss = 0.9131597551432523, disc_loss = 0.008863288464701989
Trained batch 110 in epoch 17, gen_loss = 0.9132790178865999, disc_loss = 0.008825006248714688
Trained batch 111 in epoch 17, gen_loss = 0.9134061144930976, disc_loss = 0.008762482652465613
Trained batch 112 in epoch 17, gen_loss = 0.91356746443605, disc_loss = 0.008701298784555257
Trained batch 113 in epoch 17, gen_loss = 0.9138646821180979, disc_loss = 0.00864105403786852
Trained batch 114 in epoch 17, gen_loss = 0.9141791784245035, disc_loss = 0.008590143770181939
Trained batch 115 in epoch 17, gen_loss = 0.9155092367838169, disc_loss = 0.008547066362646955
Trained batch 116 in epoch 17, gen_loss = 0.9144553919123788, disc_loss = 0.00852570132826033
Trained batch 117 in epoch 17, gen_loss = 0.915131221888429, disc_loss = 0.008468924557900655
Trained batch 118 in epoch 17, gen_loss = 0.9159176755352181, disc_loss = 0.008411695280683642
Trained batch 119 in epoch 17, gen_loss = 0.9140986412763595, disc_loss = 0.008536652607532839
Trained batch 120 in epoch 17, gen_loss = 0.9126229512790018, disc_loss = 0.008969919532845335
Trained batch 121 in epoch 17, gen_loss = 0.912999482917004, disc_loss = 0.012947467300796607
Trained batch 122 in epoch 17, gen_loss = 0.9108434115968099, disc_loss = 0.013473438818340863
Trained batch 123 in epoch 17, gen_loss = 0.9112112430795547, disc_loss = 0.013730409742903805
Trained batch 124 in epoch 17, gen_loss = 0.9091432900428772, disc_loss = 0.01445844916254282
Trained batch 125 in epoch 17, gen_loss = 0.9060619705253177, disc_loss = 0.015048520114745886
Trained batch 126 in epoch 17, gen_loss = 0.9070022101477375, disc_loss = 0.014990061008202748
Trained batch 127 in epoch 17, gen_loss = 0.9075588234700263, disc_loss = 0.01502967304259073
Trained batch 128 in epoch 17, gen_loss = 0.9088114458461141, disc_loss = 0.01496796359762896
Trained batch 129 in epoch 17, gen_loss = 0.9091082614201765, disc_loss = 0.014933832462590474
Trained batch 130 in epoch 17, gen_loss = 0.9078579567770921, disc_loss = 0.014900107590751794
Trained batch 131 in epoch 17, gen_loss = 0.9077129404653203, disc_loss = 0.014825452584773302
Trained batch 132 in epoch 17, gen_loss = 0.9079343685530182, disc_loss = 0.014752593637212999
Trained batch 133 in epoch 17, gen_loss = 0.9081495817917496, disc_loss = 0.01466180991430058
Trained batch 134 in epoch 17, gen_loss = 0.9072948265958716, disc_loss = 0.014581613820391122
Trained batch 135 in epoch 17, gen_loss = 0.9074662393506836, disc_loss = 0.014488792072584415
Trained batch 136 in epoch 17, gen_loss = 0.9072991922824052, disc_loss = 0.014397778490517479
Trained batch 137 in epoch 17, gen_loss = 0.9077012551867444, disc_loss = 0.014299980654512816
Trained batch 138 in epoch 17, gen_loss = 0.906976024452731, disc_loss = 0.014219001531450198
Trained batch 139 in epoch 17, gen_loss = 0.9063374595982688, disc_loss = 0.014126133786963433
Trained batch 140 in epoch 17, gen_loss = 0.9061752447845243, disc_loss = 0.014039388311620642
Trained batch 141 in epoch 17, gen_loss = 0.9054305524053708, disc_loss = 0.01396105721187909
Trained batch 142 in epoch 17, gen_loss = 0.9056570900903715, disc_loss = 0.013881383252483174
Trained batch 143 in epoch 17, gen_loss = 0.905464355316427, disc_loss = 0.013799352967907907
Trained batch 144 in epoch 17, gen_loss = 0.9050529282668541, disc_loss = 0.013790100384583889
Trained batch 145 in epoch 17, gen_loss = 0.9041365711656335, disc_loss = 0.013987205242052393
Trained batch 146 in epoch 17, gen_loss = 0.9052515159658834, disc_loss = 0.014486030132595298
Trained batch 147 in epoch 17, gen_loss = 0.9062900535158209, disc_loss = 0.014445327450851659
Trained batch 148 in epoch 17, gen_loss = 0.9061179393089858, disc_loss = 0.014378282656008691
Trained batch 149 in epoch 17, gen_loss = 0.905669763882955, disc_loss = 0.014326441106774534
Trained batch 150 in epoch 17, gen_loss = 0.9039706197006023, disc_loss = 0.014533577615237912
Trained batch 151 in epoch 17, gen_loss = 0.9051880922756697, disc_loss = 0.01447561803759431
Trained batch 152 in epoch 17, gen_loss = 0.905901580854179, disc_loss = 0.014490606703451573
Trained batch 153 in epoch 17, gen_loss = 0.9066590519694538, disc_loss = 0.014450927303163576
Trained batch 154 in epoch 17, gen_loss = 0.9067793011665344, disc_loss = 0.014378283673431724
Trained batch 155 in epoch 17, gen_loss = 0.9058188669956647, disc_loss = 0.014622695310092054
Trained batch 156 in epoch 17, gen_loss = 0.9060612427201241, disc_loss = 0.01524053157676474
Trained batch 157 in epoch 17, gen_loss = 0.906759217192855, disc_loss = 0.015165458258338673
Trained batch 158 in epoch 17, gen_loss = 0.9062875145636264, disc_loss = 0.015238081944488434
Trained batch 159 in epoch 17, gen_loss = 0.9067684009671211, disc_loss = 0.015155544362278306
Trained batch 160 in epoch 17, gen_loss = 0.9044348260630732, disc_loss = 0.015953031892422587
Trained batch 161 in epoch 17, gen_loss = 0.9053984747992622, disc_loss = 0.01621341964921247
Trained batch 162 in epoch 17, gen_loss = 0.9063794217958041, disc_loss = 0.016658672180521
Trained batch 163 in epoch 17, gen_loss = 0.9046620635724649, disc_loss = 0.017397645154255216
Trained batch 164 in epoch 17, gen_loss = 0.9052464763323466, disc_loss = 0.017309860157371133
Trained batch 165 in epoch 17, gen_loss = 0.9059365301965231, disc_loss = 0.017225441862674745
Trained batch 166 in epoch 17, gen_loss = 0.9059889669903738, disc_loss = 0.017152310062191464
Trained batch 167 in epoch 17, gen_loss = 0.9055262218628611, disc_loss = 0.01710324827339112
Trained batch 168 in epoch 17, gen_loss = 0.9059391377945624, disc_loss = 0.01702493115792536
Trained batch 169 in epoch 17, gen_loss = 0.9061369503245634, disc_loss = 0.016945183954050983
Trained batch 170 in epoch 17, gen_loss = 0.9060236675697461, disc_loss = 0.016856368632826475
Trained batch 171 in epoch 17, gen_loss = 0.9059655098027961, disc_loss = 0.016771643846580045
Trained batch 172 in epoch 17, gen_loss = 0.9064165257305079, disc_loss = 0.01668135764654672
Trained batch 173 in epoch 17, gen_loss = 0.9059094632494038, disc_loss = 0.01659204018129646
Trained batch 174 in epoch 17, gen_loss = 0.905779914855957, disc_loss = 0.01650366557662242
Trained batch 175 in epoch 17, gen_loss = 0.9073429514061321, disc_loss = 0.01642247364328465
Trained batch 176 in epoch 17, gen_loss = 0.9076207647215848, disc_loss = 0.016334821889703137
Trained batch 177 in epoch 17, gen_loss = 0.9077579657013497, disc_loss = 0.016251629391120057
Trained batch 178 in epoch 17, gen_loss = 0.9078249834769265, disc_loss = 0.016166653275989287
Trained batch 179 in epoch 17, gen_loss = 0.9078441497352389, disc_loss = 0.016086515649739237
Trained batch 180 in epoch 17, gen_loss = 0.9075570649863607, disc_loss = 0.016008656249427912
Trained batch 181 in epoch 17, gen_loss = 0.9080405631563165, disc_loss = 0.015927554450412332
Trained batch 182 in epoch 17, gen_loss = 0.9084275664527559, disc_loss = 0.01584607059812896
Trained batch 183 in epoch 17, gen_loss = 0.9083064953270166, disc_loss = 0.01579808150089103
Trained batch 184 in epoch 17, gen_loss = 0.9085573450939075, disc_loss = 0.015721845818129746
Trained batch 185 in epoch 17, gen_loss = 0.9086239148852646, disc_loss = 0.015643245089293448
Trained batch 186 in epoch 17, gen_loss = 0.909188309136559, disc_loss = 0.015566859683793855
Trained batch 187 in epoch 17, gen_loss = 0.9096544768581999, disc_loss = 0.015488274462961969
Trained batch 188 in epoch 17, gen_loss = 0.9094497022174653, disc_loss = 0.015414636149120434
Trained batch 189 in epoch 17, gen_loss = 0.910727734314768, disc_loss = 0.015338465226140168
Trained batch 190 in epoch 17, gen_loss = 0.9109682122450224, disc_loss = 0.015262843537539322
Trained batch 191 in epoch 17, gen_loss = 0.9110446047658721, disc_loss = 0.015187363592910211
Trained batch 192 in epoch 17, gen_loss = 0.91154891684883, disc_loss = 0.015111998272782258
Trained batch 193 in epoch 17, gen_loss = 0.9117243077951608, disc_loss = 0.015036981492531342
Trained batch 194 in epoch 17, gen_loss = 0.9122622780310802, disc_loss = 0.014965529800452387
Trained batch 195 in epoch 17, gen_loss = 0.9121230001352272, disc_loss = 0.014907661839376432
Trained batch 196 in epoch 17, gen_loss = 0.9124123033533241, disc_loss = 0.014834939494792863
Trained batch 197 in epoch 17, gen_loss = 0.9127695572496665, disc_loss = 0.014763469460615512
Trained batch 198 in epoch 17, gen_loss = 0.9129968108843319, disc_loss = 0.014696473258386024
Trained batch 199 in epoch 17, gen_loss = 0.9128003430366516, disc_loss = 0.014630098184861709
Trained batch 200 in epoch 17, gen_loss = 0.914090983310149, disc_loss = 0.014565924272017637
Trained batch 201 in epoch 17, gen_loss = 0.9140942896356677, disc_loss = 0.014498324874883037
Trained batch 202 in epoch 17, gen_loss = 0.9143605299771126, disc_loss = 0.014430628909403687
Trained batch 203 in epoch 17, gen_loss = 0.9149683547370574, disc_loss = 0.01436457030193232
Trained batch 204 in epoch 17, gen_loss = 0.9151926886744616, disc_loss = 0.014298349252061509
Trained batch 205 in epoch 17, gen_loss = 0.9159646419066827, disc_loss = 0.014231713887109665
Trained batch 206 in epoch 17, gen_loss = 0.9159940605002325, disc_loss = 0.014165742084910364
Trained batch 207 in epoch 17, gen_loss = 0.9165743964795883, disc_loss = 0.014101069386435064
Trained batch 208 in epoch 17, gen_loss = 0.916557709280954, disc_loss = 0.014035845636033663
Trained batch 209 in epoch 17, gen_loss = 0.9167992191655295, disc_loss = 0.013972054931357326
Trained batch 210 in epoch 17, gen_loss = 0.916833895925097, disc_loss = 0.013907592361974993
Trained batch 211 in epoch 17, gen_loss = 0.9168091093031865, disc_loss = 0.013848696696546746
Trained batch 212 in epoch 17, gen_loss = 0.91732511078248, disc_loss = 0.013787234960776478
Trained batch 213 in epoch 17, gen_loss = 0.9172177685198383, disc_loss = 0.013730515832126046
Trained batch 214 in epoch 17, gen_loss = 0.9174622383228568, disc_loss = 0.013669980014268265
Trained batch 215 in epoch 17, gen_loss = 0.9175300490525033, disc_loss = 0.0136095710607791
Trained batch 216 in epoch 17, gen_loss = 0.9177175872886236, disc_loss = 0.013549596774161145
Trained batch 217 in epoch 17, gen_loss = 0.9172201495651805, disc_loss = 0.013489191100901686
Trained batch 218 in epoch 17, gen_loss = 0.9171816570573745, disc_loss = 0.013430277347967633
Trained batch 219 in epoch 17, gen_loss = 0.9180153914473274, disc_loss = 0.013373112640825142
Trained batch 220 in epoch 17, gen_loss = 0.9181525928402379, disc_loss = 0.01331821599239336
Trained batch 221 in epoch 17, gen_loss = 0.9181121740792249, disc_loss = 0.013260806614804702
Trained batch 222 in epoch 17, gen_loss = 0.917844078465962, disc_loss = 0.013204429199320845
Trained batch 223 in epoch 17, gen_loss = 0.9187790847250393, disc_loss = 0.013148040035048325
Trained batch 224 in epoch 17, gen_loss = 0.9186311451594035, disc_loss = 0.013092248632908901
Trained batch 225 in epoch 17, gen_loss = 0.9185881886334546, disc_loss = 0.01303630222930095
Trained batch 226 in epoch 17, gen_loss = 0.9186238888076749, disc_loss = 0.012981206225077436
Trained batch 227 in epoch 17, gen_loss = 0.919007967700038, disc_loss = 0.012926336882836103
Trained batch 228 in epoch 17, gen_loss = 0.9183995466044896, disc_loss = 0.012884261296537408
Trained batch 229 in epoch 17, gen_loss = 0.9187687275202377, disc_loss = 0.012831557227764278
Trained batch 230 in epoch 17, gen_loss = 0.9189037443239452, disc_loss = 0.012779506898053732
Trained batch 231 in epoch 17, gen_loss = 0.9182094579626774, disc_loss = 0.012817567807485768
Trained batch 232 in epoch 17, gen_loss = 0.9176980129127339, disc_loss = 0.012784655434738989
Trained batch 233 in epoch 17, gen_loss = 0.9179996066113822, disc_loss = 0.012734265918903148
Trained batch 234 in epoch 17, gen_loss = 0.9177133567789768, disc_loss = 0.012685690089029835
Trained batch 235 in epoch 17, gen_loss = 0.918033685977176, disc_loss = 0.012634111477813873
Trained batch 236 in epoch 17, gen_loss = 0.9180675699741025, disc_loss = 0.012585552378591025
Trained batch 237 in epoch 17, gen_loss = 0.9181614267725905, disc_loss = 0.012536126693481767
Trained batch 238 in epoch 17, gen_loss = 0.9181207238879663, disc_loss = 0.012487250190495151
Trained batch 239 in epoch 17, gen_loss = 0.9176896636684736, disc_loss = 0.012437090324237943
Trained batch 240 in epoch 17, gen_loss = 0.9175011874234528, disc_loss = 0.012389983061152313
Trained batch 241 in epoch 17, gen_loss = 0.9175957643296108, disc_loss = 0.012341434202418655
Trained batch 242 in epoch 17, gen_loss = 0.9176645283836397, disc_loss = 0.01229321828098592
Trained batch 243 in epoch 17, gen_loss = 0.9175007511846355, disc_loss = 0.0122465225705709
Trained batch 244 in epoch 17, gen_loss = 0.9174184422103726, disc_loss = 0.012198945208528668
Trained batch 245 in epoch 17, gen_loss = 0.9174234077213256, disc_loss = 0.012152058531660813
Trained batch 246 in epoch 17, gen_loss = 0.9169088833727818, disc_loss = 0.012105664626698986
Trained batch 247 in epoch 17, gen_loss = 0.9172842920787873, disc_loss = 0.012062285671896872
Trained batch 248 in epoch 17, gen_loss = 0.9170391882758543, disc_loss = 0.012017640828465423
Trained batch 249 in epoch 17, gen_loss = 0.916702241897583, disc_loss = 0.011971763725159689
Trained batch 250 in epoch 17, gen_loss = 0.9168192585151034, disc_loss = 0.011926967698655859
Trained batch 251 in epoch 17, gen_loss = 0.9168178264110808, disc_loss = 0.011882125813234968
Trained batch 252 in epoch 17, gen_loss = 0.9172554228145614, disc_loss = 0.011854101871756888
Trained batch 253 in epoch 17, gen_loss = 0.9169890763252739, disc_loss = 0.011812581805609474
Trained batch 254 in epoch 17, gen_loss = 0.917325187664406, disc_loss = 0.011769693909788175
Trained batch 255 in epoch 17, gen_loss = 0.9175032773055136, disc_loss = 0.011726174838486259
Trained batch 256 in epoch 17, gen_loss = 0.9177193256667616, disc_loss = 0.011682752185774756
Trained batch 257 in epoch 17, gen_loss = 0.9176491845485776, disc_loss = 0.011639542901363266
Trained batch 258 in epoch 17, gen_loss = 0.9174745596053517, disc_loss = 0.011597579168686176
Trained batch 259 in epoch 17, gen_loss = 0.9175065466990837, disc_loss = 0.011554481659102469
Trained batch 260 in epoch 17, gen_loss = 0.9175777981107719, disc_loss = 0.011511181999699095
Trained batch 261 in epoch 17, gen_loss = 0.9179985912246559, disc_loss = 0.011470153105564287
Trained batch 262 in epoch 17, gen_loss = 0.9175900769324357, disc_loss = 0.01142885484343161
Trained batch 263 in epoch 17, gen_loss = 0.9175728299852574, disc_loss = 0.011388855060707128
Trained batch 264 in epoch 17, gen_loss = 0.9175917668162652, disc_loss = 0.011347803909920226
Trained batch 265 in epoch 17, gen_loss = 0.9182343991627371, disc_loss = 0.011307481713759313
Trained batch 266 in epoch 17, gen_loss = 0.9184048240550895, disc_loss = 0.011266828291615199
Trained batch 267 in epoch 17, gen_loss = 0.9181088967554605, disc_loss = 0.0112264029897355
Trained batch 268 in epoch 17, gen_loss = 0.9179684411194244, disc_loss = 0.011185769582224394
Trained batch 269 in epoch 17, gen_loss = 0.9179069042205811, disc_loss = 0.011145908033897825
Trained batch 270 in epoch 17, gen_loss = 0.9178923964500427, disc_loss = 0.011107116107909676
Trained batch 271 in epoch 17, gen_loss = 0.9178556140293094, disc_loss = 0.011068015193493064
Trained batch 272 in epoch 17, gen_loss = 0.9175933955353258, disc_loss = 0.011029079370435171
Trained batch 273 in epoch 17, gen_loss = 0.9179264905243895, disc_loss = 0.010991319880271024
Trained batch 274 in epoch 17, gen_loss = 0.9183221520077098, disc_loss = 0.01095299306304448
Trained batch 275 in epoch 17, gen_loss = 0.9186925894540289, disc_loss = 0.010914631672874195
Trained batch 276 in epoch 17, gen_loss = 0.9187313862655998, disc_loss = 0.010876654403217789
Trained batch 277 in epoch 17, gen_loss = 0.9190330014383192, disc_loss = 0.01083866549360988
Trained batch 278 in epoch 17, gen_loss = 0.919463346295032, disc_loss = 0.01080201552324598
Trained batch 279 in epoch 17, gen_loss = 0.9195071065000125, disc_loss = 0.010765835409568223
Trained batch 280 in epoch 17, gen_loss = 0.9197512792947029, disc_loss = 0.010731326506449923
Trained batch 281 in epoch 17, gen_loss = 0.9197333939109288, disc_loss = 0.010695159378096607
Trained batch 282 in epoch 17, gen_loss = 0.9199846858691832, disc_loss = 0.010658978248860805
Trained batch 283 in epoch 17, gen_loss = 0.9204779059534342, disc_loss = 0.010622574334954319
Trained batch 284 in epoch 17, gen_loss = 0.920295210261094, disc_loss = 0.010587533489033057
Trained batch 285 in epoch 17, gen_loss = 0.9203777044386297, disc_loss = 0.01055137516578197
Trained batch 286 in epoch 17, gen_loss = 0.9199215537164269, disc_loss = 0.010515711035008318
Trained batch 287 in epoch 17, gen_loss = 0.9201502429528369, disc_loss = 0.01048037611376963
Trained batch 288 in epoch 17, gen_loss = 0.9201120721840116, disc_loss = 0.010445383528934689
Trained batch 289 in epoch 17, gen_loss = 0.9200814111479397, disc_loss = 0.010410163075671178
Trained batch 290 in epoch 17, gen_loss = 0.9198083660446901, disc_loss = 0.010375385634125853
Trained batch 291 in epoch 17, gen_loss = 0.9195504172207558, disc_loss = 0.01034099613982157
Trained batch 292 in epoch 17, gen_loss = 0.9191904002895941, disc_loss = 0.010306622155381005
Trained batch 293 in epoch 17, gen_loss = 0.9190178904809109, disc_loss = 0.010273570117626188
Trained batch 294 in epoch 17, gen_loss = 0.9189447483773959, disc_loss = 0.010239827123833662
Trained batch 295 in epoch 17, gen_loss = 0.9186573088974566, disc_loss = 0.010206380686164217
Trained batch 296 in epoch 17, gen_loss = 0.9186579940294979, disc_loss = 0.010174339371600097
Trained batch 297 in epoch 17, gen_loss = 0.9187749594249981, disc_loss = 0.01014139423341781
Trained batch 298 in epoch 17, gen_loss = 0.9190269224221093, disc_loss = 0.010109494503624084
Trained batch 299 in epoch 17, gen_loss = 0.919113400777181, disc_loss = 0.010078354617483758
Trained batch 300 in epoch 17, gen_loss = 0.9190504731133927, disc_loss = 0.010045922337625133
Trained batch 301 in epoch 17, gen_loss = 0.9189399093981611, disc_loss = 0.010014049030878174
Trained batch 302 in epoch 17, gen_loss = 0.918707278498722, disc_loss = 0.00998200704005513
Trained batch 303 in epoch 17, gen_loss = 0.918521328584144, disc_loss = 0.009950437699731801
Trained batch 304 in epoch 17, gen_loss = 0.9184492154199569, disc_loss = 0.009918918541239453
Trained batch 305 in epoch 17, gen_loss = 0.9182747064852247, disc_loss = 0.009887428582456493
Trained batch 306 in epoch 17, gen_loss = 0.91849687821702, disc_loss = 0.009856511750474651
Trained batch 307 in epoch 17, gen_loss = 0.9186069185470606, disc_loss = 0.009826116939774539
Trained batch 308 in epoch 17, gen_loss = 0.9183861464744247, disc_loss = 0.009795554047341165
Trained batch 309 in epoch 17, gen_loss = 0.9179292813424141, disc_loss = 0.009766641357864795
Trained batch 310 in epoch 17, gen_loss = 0.9180142283439636, disc_loss = 0.009736662194072165
Trained batch 311 in epoch 17, gen_loss = 0.9180658721388915, disc_loss = 0.009707322679530943
Trained batch 312 in epoch 17, gen_loss = 0.9178501438028135, disc_loss = 0.009677742511467687
Trained batch 313 in epoch 17, gen_loss = 0.9176515230707302, disc_loss = 0.00964858891006046
Trained batch 314 in epoch 17, gen_loss = 0.9173896729000031, disc_loss = 0.009620130232568564
Trained batch 315 in epoch 17, gen_loss = 0.9175090382370767, disc_loss = 0.009590539142111451
Trained batch 316 in epoch 17, gen_loss = 0.9174166246543547, disc_loss = 0.009561342766272692
Trained batch 317 in epoch 17, gen_loss = 0.9173900610620871, disc_loss = 0.009532939411759077
Trained batch 318 in epoch 17, gen_loss = 0.9174181540557957, disc_loss = 0.00950457549354333
Trained batch 319 in epoch 17, gen_loss = 0.9173076894134283, disc_loss = 0.00947685876953983
Trained batch 320 in epoch 17, gen_loss = 0.9170100052037343, disc_loss = 0.009449557913231555
Trained batch 321 in epoch 17, gen_loss = 0.9170124464153503, disc_loss = 0.009421042212475271
Trained batch 322 in epoch 17, gen_loss = 0.9168478994177591, disc_loss = 0.009393643094504241
Trained batch 323 in epoch 17, gen_loss = 0.9169737573391126, disc_loss = 0.009365338163111175
Trained batch 324 in epoch 17, gen_loss = 0.9167688030462998, disc_loss = 0.009337428115988866
Trained batch 325 in epoch 17, gen_loss = 0.9171183827830238, disc_loss = 0.009310236800889816
Trained batch 326 in epoch 17, gen_loss = 0.9170668923526729, disc_loss = 0.009282733056788967
Trained batch 327 in epoch 17, gen_loss = 0.9169815457085284, disc_loss = 0.0092642794175268
Trained batch 328 in epoch 17, gen_loss = 0.9166517538502585, disc_loss = 0.009237260643607232
Trained batch 329 in epoch 17, gen_loss = 0.9168644128423749, disc_loss = 0.0092113382227994
Trained batch 330 in epoch 17, gen_loss = 0.9171504552991009, disc_loss = 0.00918449281183426
Trained batch 331 in epoch 17, gen_loss = 0.9167854498667889, disc_loss = 0.009159378545496933
Trained batch 332 in epoch 17, gen_loss = 0.9167821278443208, disc_loss = 0.009133331359216562
Trained batch 333 in epoch 17, gen_loss = 0.9166947082131208, disc_loss = 0.009107364666899861
Trained batch 334 in epoch 17, gen_loss = 0.9163013815879821, disc_loss = 0.009082113887242445
Trained batch 335 in epoch 17, gen_loss = 0.9158664226886772, disc_loss = 0.0090592531754997
Trained batch 336 in epoch 17, gen_loss = 0.9159554181183834, disc_loss = 0.009034660070438839
Trained batch 337 in epoch 17, gen_loss = 0.9161930872491125, disc_loss = 0.009010444168527004
Trained batch 338 in epoch 17, gen_loss = 0.9160975040236053, disc_loss = 0.00898628238017484
Trained batch 339 in epoch 17, gen_loss = 0.9162503721082912, disc_loss = 0.008961118682825198
Trained batch 340 in epoch 17, gen_loss = 0.9167154679550104, disc_loss = 0.008936583513514852
Trained batch 341 in epoch 17, gen_loss = 0.9169397254784902, disc_loss = 0.008912034126387348
Trained batch 342 in epoch 17, gen_loss = 0.9166921698664785, disc_loss = 0.008887631041333813
Trained batch 343 in epoch 17, gen_loss = 0.91677783342988, disc_loss = 0.008862660080245235
Trained batch 344 in epoch 17, gen_loss = 0.9165480435758397, disc_loss = 0.00883862285771866
Trained batch 345 in epoch 17, gen_loss = 0.9164800013420898, disc_loss = 0.008814203769498171
Trained batch 346 in epoch 17, gen_loss = 0.9163809760503192, disc_loss = 0.00879081320334615
Trained batch 347 in epoch 17, gen_loss = 0.9164894788429655, disc_loss = 0.008766363475246933
Trained batch 348 in epoch 17, gen_loss = 0.9166513121230554, disc_loss = 0.008743027375576041
Trained batch 349 in epoch 17, gen_loss = 0.9170088240078518, disc_loss = 0.008719511193090251
Trained batch 350 in epoch 17, gen_loss = 0.91722612486266, disc_loss = 0.008696516003476939
Trained batch 351 in epoch 17, gen_loss = 0.917076791043986, disc_loss = 0.008673280902671237
Trained batch 352 in epoch 17, gen_loss = 0.9170263931366269, disc_loss = 0.008649642110792999
Trained batch 353 in epoch 17, gen_loss = 0.9170850089377602, disc_loss = 0.008627015993388443
Trained batch 354 in epoch 17, gen_loss = 0.9174647319484764, disc_loss = 0.008603891689645152
Trained batch 355 in epoch 17, gen_loss = 0.9176042945532317, disc_loss = 0.008582241958454565
Trained batch 356 in epoch 17, gen_loss = 0.9175759475438201, disc_loss = 0.008559595402662776
Trained batch 357 in epoch 17, gen_loss = 0.9175193179919067, disc_loss = 0.008537325244715604
Trained batch 358 in epoch 17, gen_loss = 0.9176347089677136, disc_loss = 0.008514869686418465
Trained batch 359 in epoch 17, gen_loss = 0.9174131052361594, disc_loss = 0.008499092733513357
Trained batch 360 in epoch 17, gen_loss = 0.9172117209830772, disc_loss = 0.008477078213155208
Trained batch 361 in epoch 17, gen_loss = 0.9172765498991171, disc_loss = 0.008457111600253895
Trained batch 362 in epoch 17, gen_loss = 0.9176553197143492, disc_loss = 0.008435792944550555
Trained batch 363 in epoch 17, gen_loss = 0.9174649494362401, disc_loss = 0.008415421726857568
Trained batch 364 in epoch 17, gen_loss = 0.9173996757154596, disc_loss = 0.008393810416750407
Trained batch 365 in epoch 17, gen_loss = 0.9172714916083331, disc_loss = 0.00837265498537947
Trained batch 366 in epoch 17, gen_loss = 0.917412772815299, disc_loss = 0.008351338141006531
Trained batch 367 in epoch 17, gen_loss = 0.9176021765755571, disc_loss = 0.008330493929268256
Trained batch 368 in epoch 17, gen_loss = 0.9175630074529467, disc_loss = 0.008309113176767954
Trained batch 369 in epoch 17, gen_loss = 0.9175188074240813, disc_loss = 0.008287981451596007
Trained batch 370 in epoch 17, gen_loss = 0.9175303419323945, disc_loss = 0.008267003065257551
Trained batch 371 in epoch 17, gen_loss = 0.9172146714502766, disc_loss = 0.008246185786594007
Trained batch 372 in epoch 17, gen_loss = 0.9170098838473772, disc_loss = 0.00822793028658211
Trained batch 373 in epoch 17, gen_loss = 0.9170385640572737, disc_loss = 0.008207944151136107
Trained batch 374 in epoch 17, gen_loss = 0.9170399293899536, disc_loss = 0.008197104070646067
Trained batch 375 in epoch 17, gen_loss = 0.9172816748948808, disc_loss = 0.008177120488711652
Trained batch 376 in epoch 17, gen_loss = 0.917247736959938, disc_loss = 0.008158261283728188
Trained batch 377 in epoch 17, gen_loss = 0.9170042222769803, disc_loss = 0.008138346275137294
Trained batch 378 in epoch 17, gen_loss = 0.9169530280347236, disc_loss = 0.008119106005065114
Trained batch 379 in epoch 17, gen_loss = 0.916659751534462, disc_loss = 0.008099342248322884
Trained batch 380 in epoch 17, gen_loss = 0.9164780431532171, disc_loss = 0.008084541570310898
Trained batch 381 in epoch 17, gen_loss = 0.9164284143148292, disc_loss = 0.0080666028428518
Trained batch 382 in epoch 17, gen_loss = 0.9161241714387899, disc_loss = 0.008055860400850356
Trained batch 383 in epoch 17, gen_loss = 0.9158326596952975, disc_loss = 0.008036907512026422
Trained batch 384 in epoch 17, gen_loss = 0.9157796290013698, disc_loss = 0.008018502360361012
Trained batch 385 in epoch 17, gen_loss = 0.9162014997684894, disc_loss = 0.007999943249160424
Trained batch 386 in epoch 17, gen_loss = 0.9161312105735759, disc_loss = 0.007981895398287203
Trained batch 387 in epoch 17, gen_loss = 0.916008182100414, disc_loss = 0.007964235660710046
Trained batch 388 in epoch 17, gen_loss = 0.9161839728796697, disc_loss = 0.007945964344511417
Trained batch 389 in epoch 17, gen_loss = 0.916070052752128, disc_loss = 0.007929004936252171
Trained batch 390 in epoch 17, gen_loss = 0.9165085387961639, disc_loss = 0.007915313458939552
Trained batch 391 in epoch 17, gen_loss = 0.9161375099603011, disc_loss = 0.007900613943074487
Trained batch 392 in epoch 17, gen_loss = 0.9160158578069458, disc_loss = 0.007883902602715289
Trained batch 393 in epoch 17, gen_loss = 0.9160879458570238, disc_loss = 0.007867066176646025
Trained batch 394 in epoch 17, gen_loss = 0.9159432295002515, disc_loss = 0.007853533839806914
Trained batch 395 in epoch 17, gen_loss = 0.9155151648352845, disc_loss = 0.007847704356089422
Trained batch 396 in epoch 17, gen_loss = 0.9150488508738559, disc_loss = 0.007850420842491447
Trained batch 397 in epoch 17, gen_loss = 0.9145873952750585, disc_loss = 0.007847828665940118
Trained batch 398 in epoch 17, gen_loss = 0.9146586578890196, disc_loss = 0.007836090794701437
Trained batch 399 in epoch 17, gen_loss = 0.9145853626728058, disc_loss = 0.007822348798508755
Trained batch 400 in epoch 17, gen_loss = 0.914571862565609, disc_loss = 0.007810402798589477
Trained batch 401 in epoch 17, gen_loss = 0.9145702359391682, disc_loss = 0.007799994045247634
Trained batch 402 in epoch 17, gen_loss = 0.9148895245036179, disc_loss = 0.007786961883611552
Trained batch 403 in epoch 17, gen_loss = 0.9151272509652789, disc_loss = 0.007772107832514137
Trained batch 404 in epoch 17, gen_loss = 0.9150813726731288, disc_loss = 0.007754659316111586
Trained batch 405 in epoch 17, gen_loss = 0.9147040496025179, disc_loss = 0.007740054282433183
Trained batch 406 in epoch 17, gen_loss = 0.9147256491225241, disc_loss = 0.007723533251512732
Trained batch 407 in epoch 17, gen_loss = 0.9148330903228592, disc_loss = 0.00770668171796441
Trained batch 408 in epoch 17, gen_loss = 0.9147920499221037, disc_loss = 0.007694511660255155
Trained batch 409 in epoch 17, gen_loss = 0.9144468090883116, disc_loss = 0.007733880353256742
Trained batch 410 in epoch 17, gen_loss = 0.9142763933706167, disc_loss = 0.007725106650388997
Trained batch 411 in epoch 17, gen_loss = 0.9139270360030017, disc_loss = 0.007732417661209537
Trained batch 412 in epoch 17, gen_loss = 0.9137286715588328, disc_loss = 0.0077234728237305095
Trained batch 413 in epoch 17, gen_loss = 0.9136792703527183, disc_loss = 0.007708756105635756
Trained batch 414 in epoch 17, gen_loss = 0.9136026333613568, disc_loss = 0.007692778609406922
Trained batch 415 in epoch 17, gen_loss = 0.9133715351613668, disc_loss = 0.007678785389753802
Trained batch 416 in epoch 17, gen_loss = 0.913166378899444, disc_loss = 0.0077664085569773625
Trained batch 417 in epoch 17, gen_loss = 0.9130400389290312, disc_loss = 0.008093415542687266
Trained batch 418 in epoch 17, gen_loss = 0.9117035926241863, disc_loss = 0.008786542169268517
Trained batch 419 in epoch 17, gen_loss = 0.9111789455726034, disc_loss = 0.008911490042754893
Trained batch 420 in epoch 17, gen_loss = 0.9114368190533192, disc_loss = 0.00900907690773415
Trained batch 421 in epoch 17, gen_loss = 0.9116050226004768, disc_loss = 0.009175287711216683
Trained batch 422 in epoch 17, gen_loss = 0.9115172557656083, disc_loss = 0.009177671022571174
Trained batch 423 in epoch 17, gen_loss = 0.9116511435581828, disc_loss = 0.009177558430891158
Trained batch 424 in epoch 17, gen_loss = 0.9112834095253664, disc_loss = 0.009174216807518593
Trained batch 425 in epoch 17, gen_loss = 0.9111988431830921, disc_loss = 0.009162367624749906
Trained batch 426 in epoch 17, gen_loss = 0.9109537073125326, disc_loss = 0.009148415553615815
Trained batch 427 in epoch 17, gen_loss = 0.9111684317761493, disc_loss = 0.009133113285817127
Trained batch 428 in epoch 17, gen_loss = 0.911232390812227, disc_loss = 0.009119275578385596
Trained batch 429 in epoch 17, gen_loss = 0.911581051834794, disc_loss = 0.009103540886534638
Trained batch 430 in epoch 17, gen_loss = 0.912034627940428, disc_loss = 0.00908735422555275
Trained batch 431 in epoch 17, gen_loss = 0.9120342343079823, disc_loss = 0.009070987174372594
Trained batch 432 in epoch 17, gen_loss = 0.912148249273212, disc_loss = 0.009053226526881467
Trained batch 433 in epoch 17, gen_loss = 0.912069941514648, disc_loss = 0.009034184278965357
Trained batch 434 in epoch 17, gen_loss = 0.9121914740951582, disc_loss = 0.0090159964873509
Trained batch 435 in epoch 17, gen_loss = 0.912059229516655, disc_loss = 0.008997290681031908
Trained batch 436 in epoch 17, gen_loss = 0.9120670008031946, disc_loss = 0.008979603752480006
Trained batch 437 in epoch 17, gen_loss = 0.912034733858827, disc_loss = 0.008962852701350204
Trained batch 438 in epoch 17, gen_loss = 0.9118861305550725, disc_loss = 0.008946963739321526
Trained batch 439 in epoch 17, gen_loss = 0.9120931961996989, disc_loss = 0.008929584464931395
Trained batch 440 in epoch 17, gen_loss = 0.9120604738491733, disc_loss = 0.00891223840023203
Trained batch 441 in epoch 17, gen_loss = 0.9120314608736815, disc_loss = 0.008894514029227172
Trained batch 442 in epoch 17, gen_loss = 0.9123082442827203, disc_loss = 0.008879301073707631
Trained batch 443 in epoch 17, gen_loss = 0.912276642480949, disc_loss = 0.008861762835819333
Trained batch 444 in epoch 17, gen_loss = 0.9123908039559139, disc_loss = 0.008844120062108078
Trained batch 445 in epoch 17, gen_loss = 0.9123454297738225, disc_loss = 0.008827090780579614
Trained batch 446 in epoch 17, gen_loss = 0.9121152120548607, disc_loss = 0.008809694962370808
Trained batch 447 in epoch 17, gen_loss = 0.9120192238395768, disc_loss = 0.008791169471935843
Trained batch 448 in epoch 17, gen_loss = 0.9119714318643966, disc_loss = 0.008773845586358447
Trained batch 449 in epoch 17, gen_loss = 0.911858727203475, disc_loss = 0.00875672793830745
Trained batch 450 in epoch 17, gen_loss = 0.9119438208523981, disc_loss = 0.008741321971566683
Trained batch 451 in epoch 17, gen_loss = 0.9117638478632522, disc_loss = 0.008726620323573799
Trained batch 452 in epoch 17, gen_loss = 0.9116568359449736, disc_loss = 0.00871257746716032
Trained batch 453 in epoch 17, gen_loss = 0.9117115275844079, disc_loss = 0.008695738891263734
Trained batch 454 in epoch 17, gen_loss = 0.9119371615268372, disc_loss = 0.008679073892794754
Trained batch 455 in epoch 17, gen_loss = 0.9119725101218935, disc_loss = 0.008661445375381797
Trained batch 456 in epoch 17, gen_loss = 0.9120821961297509, disc_loss = 0.008645495473324674
Trained batch 457 in epoch 17, gen_loss = 0.9118822660118211, disc_loss = 0.008629460831901758
Trained batch 458 in epoch 17, gen_loss = 0.9116971772610492, disc_loss = 0.008612211242780771
Trained batch 459 in epoch 17, gen_loss = 0.9117543539923171, disc_loss = 0.00859550067588039
Trained batch 460 in epoch 17, gen_loss = 0.9118620044109361, disc_loss = 0.008579204240793649
Trained batch 461 in epoch 17, gen_loss = 0.9120115197195119, disc_loss = 0.008562298793218692
Trained batch 462 in epoch 17, gen_loss = 0.9120359796041031, disc_loss = 0.008545268459253609
Trained batch 463 in epoch 17, gen_loss = 0.9120465084781935, disc_loss = 0.008527984845417889
Trained batch 464 in epoch 17, gen_loss = 0.9120699804957195, disc_loss = 0.008510748362819594
Trained batch 465 in epoch 17, gen_loss = 0.9120214779105821, disc_loss = 0.008493778794202473
Trained batch 466 in epoch 17, gen_loss = 0.9120138198839265, disc_loss = 0.008476682587769043
Trained batch 467 in epoch 17, gen_loss = 0.9119861897112976, disc_loss = 0.008459840418744044
Trained batch 468 in epoch 17, gen_loss = 0.9119857943007178, disc_loss = 0.008442840649935503
Trained batch 469 in epoch 17, gen_loss = 0.9117231269466116, disc_loss = 0.008425708136835849
Trained batch 470 in epoch 17, gen_loss = 0.9119660965070097, disc_loss = 0.008409495474046468
Trained batch 471 in epoch 17, gen_loss = 0.9119015580390469, disc_loss = 0.008392667517231747
Trained batch 472 in epoch 17, gen_loss = 0.911925039319105, disc_loss = 0.00837653837817471
Trained batch 473 in epoch 17, gen_loss = 0.91182055761291, disc_loss = 0.008359727390525068
Trained batch 474 in epoch 17, gen_loss = 0.9117045549969924, disc_loss = 0.008343133665805094
Trained batch 475 in epoch 17, gen_loss = 0.911379060011451, disc_loss = 0.00832727689416091
Trained batch 476 in epoch 17, gen_loss = 0.9112618632411557, disc_loss = 0.008311054563094653
Trained batch 477 in epoch 17, gen_loss = 0.911276899059946, disc_loss = 0.008295017931277661
Trained batch 478 in epoch 17, gen_loss = 0.9112809379439264, disc_loss = 0.008278687683185407
Trained batch 479 in epoch 17, gen_loss = 0.9114582832281788, disc_loss = 0.008264301433579627
Trained batch 480 in epoch 17, gen_loss = 0.9111864274975664, disc_loss = 0.00824891633891187
Trained batch 481 in epoch 17, gen_loss = 0.9111071129433842, disc_loss = 0.008232790431337667
Trained batch 482 in epoch 17, gen_loss = 0.9112239900212851, disc_loss = 0.008216662689555131
Trained batch 483 in epoch 17, gen_loss = 0.9111123511737044, disc_loss = 0.008200752909364051
Trained batch 484 in epoch 17, gen_loss = 0.9109466705740112, disc_loss = 0.008184854354236524
Trained batch 485 in epoch 17, gen_loss = 0.9109301833826818, disc_loss = 0.00816956134049515
Trained batch 486 in epoch 17, gen_loss = 0.9111613166772854, disc_loss = 0.008153949055815445
Trained batch 487 in epoch 17, gen_loss = 0.9110127449890629, disc_loss = 0.008138645868011288
Trained batch 488 in epoch 17, gen_loss = 0.9111547575528393, disc_loss = 0.008123750587654393
Trained batch 489 in epoch 17, gen_loss = 0.9113550945812342, disc_loss = 0.00810823595235647
Trained batch 490 in epoch 17, gen_loss = 0.9114402075527642, disc_loss = 0.008093521452701865
Trained batch 491 in epoch 17, gen_loss = 0.911193012524911, disc_loss = 0.008080521154033335
Trained batch 492 in epoch 17, gen_loss = 0.9110559141055565, disc_loss = 0.008068209171564833
Trained batch 493 in epoch 17, gen_loss = 0.911200223724369, disc_loss = 0.008061023855519194
Trained batch 494 in epoch 17, gen_loss = 0.9110849194454425, disc_loss = 0.008047513250259193
Trained batch 495 in epoch 17, gen_loss = 0.9114481580233381, disc_loss = 0.008035114915342532
Trained batch 496 in epoch 17, gen_loss = 0.9115631236756592, disc_loss = 0.008020736729706051
Trained batch 497 in epoch 17, gen_loss = 0.9114497552315394, disc_loss = 0.008006102572806295
Trained batch 498 in epoch 17, gen_loss = 0.9114744089289992, disc_loss = 0.007991265577466166
Trained batch 499 in epoch 17, gen_loss = 0.911267281472683, disc_loss = 0.00797746383730555
Trained batch 500 in epoch 17, gen_loss = 0.9114622543314974, disc_loss = 0.007963997385375845
Trained batch 501 in epoch 17, gen_loss = 0.9115379403430627, disc_loss = 0.007950240470929557
Trained batch 502 in epoch 17, gen_loss = 0.9115742528533367, disc_loss = 0.007936991614469644
Trained batch 503 in epoch 17, gen_loss = 0.9117067523064122, disc_loss = 0.007922116290819037
Trained batch 504 in epoch 17, gen_loss = 0.9118397250623986, disc_loss = 0.007908721272845172
Trained batch 505 in epoch 17, gen_loss = 0.9117411279042248, disc_loss = 0.007894511937898613
Trained batch 506 in epoch 17, gen_loss = 0.911560469419058, disc_loss = 0.007880994364955872
Trained batch 507 in epoch 17, gen_loss = 0.9115283693971596, disc_loss = 0.00786715627201754
Trained batch 508 in epoch 17, gen_loss = 0.9113303060498827, disc_loss = 0.007853863692958154
Trained batch 509 in epoch 17, gen_loss = 0.9113380383627088, disc_loss = 0.007841190626883569
Trained batch 510 in epoch 17, gen_loss = 0.9114635731959296, disc_loss = 0.007827303237284018
Trained batch 511 in epoch 17, gen_loss = 0.9115099561749958, disc_loss = 0.007812962626246645
Trained batch 512 in epoch 17, gen_loss = 0.9113116920226731, disc_loss = 0.007799895215844445
Trained batch 513 in epoch 17, gen_loss = 0.911141091573563, disc_loss = 0.007789917743811475
Trained batch 514 in epoch 17, gen_loss = 0.9113574389693806, disc_loss = 0.007776055597526121
Trained batch 515 in epoch 17, gen_loss = 0.9113720868562543, disc_loss = 0.00776673039883265
Trained batch 516 in epoch 17, gen_loss = 0.9115888259051155, disc_loss = 0.007753535702374694
Trained batch 517 in epoch 17, gen_loss = 0.9118099098154937, disc_loss = 0.007740019169502575
Trained batch 518 in epoch 17, gen_loss = 0.9115480407928915, disc_loss = 0.007726768683608503
Trained batch 519 in epoch 17, gen_loss = 0.911656007457238, disc_loss = 0.007712697516902923
Trained batch 520 in epoch 17, gen_loss = 0.9117658826417062, disc_loss = 0.007700648834265683
Trained batch 521 in epoch 17, gen_loss = 0.9119222428492659, disc_loss = 0.007687913705960587
Trained batch 522 in epoch 17, gen_loss = 0.9118471107450999, disc_loss = 0.007674468456176297
Trained batch 523 in epoch 17, gen_loss = 0.9120054468512535, disc_loss = 0.007660778047861745
Trained batch 524 in epoch 17, gen_loss = 0.9118256574017661, disc_loss = 0.0076513198488170195
Trained batch 525 in epoch 17, gen_loss = 0.9114450759647463, disc_loss = 0.007638730197488029
Trained batch 526 in epoch 17, gen_loss = 0.911521640798851, disc_loss = 0.007626536598939809
Trained batch 527 in epoch 17, gen_loss = 0.9116504058580507, disc_loss = 0.007613903529449034
Trained batch 528 in epoch 17, gen_loss = 0.9119367864835014, disc_loss = 0.007600946310623276
Trained batch 529 in epoch 17, gen_loss = 0.9122777758341916, disc_loss = 0.007588211222296967
Trained batch 530 in epoch 17, gen_loss = 0.9122873779856328, disc_loss = 0.007575419137193847
Trained batch 531 in epoch 17, gen_loss = 0.9125932667376404, disc_loss = 0.0075625987146644945
Trained batch 532 in epoch 17, gen_loss = 0.9123884418780093, disc_loss = 0.007550367698471777
Trained batch 533 in epoch 17, gen_loss = 0.912569640225239, disc_loss = 0.0075373731680870165
Trained batch 534 in epoch 17, gen_loss = 0.9130625434567995, disc_loss = 0.007525904132183815
Trained batch 535 in epoch 17, gen_loss = 0.9132790182397437, disc_loss = 0.007513399972079092
Trained batch 536 in epoch 17, gen_loss = 0.9132904683966433, disc_loss = 0.00750018681818576
Trained batch 537 in epoch 17, gen_loss = 0.9133651921851041, disc_loss = 0.007487457356648087
Trained batch 538 in epoch 17, gen_loss = 0.9132619738468213, disc_loss = 0.007474594124830855
Trained batch 539 in epoch 17, gen_loss = 0.9133814940298045, disc_loss = 0.007461553045895589
Trained batch 540 in epoch 17, gen_loss = 0.9135624452902077, disc_loss = 0.007449568149062604
Trained batch 541 in epoch 17, gen_loss = 0.9135788453131144, disc_loss = 0.007436662104173659
Trained batch 542 in epoch 17, gen_loss = 0.913438256109617, disc_loss = 0.007423847420424099
Trained batch 543 in epoch 17, gen_loss = 0.9133774113896138, disc_loss = 0.007411030856982346
Trained batch 544 in epoch 17, gen_loss = 0.9131742027374583, disc_loss = 0.007398656578072338
Trained batch 545 in epoch 17, gen_loss = 0.9133495167170689, disc_loss = 0.0073864808631890315
Trained batch 546 in epoch 17, gen_loss = 0.913411884955122, disc_loss = 0.007373823074892528
Trained batch 547 in epoch 17, gen_loss = 0.91343346047793, disc_loss = 0.007361319752923726
Trained batch 548 in epoch 17, gen_loss = 0.9130986336693303, disc_loss = 0.007349748028968571
Trained batch 549 in epoch 17, gen_loss = 0.9131144909967076, disc_loss = 0.00733699024707841
Trained batch 550 in epoch 17, gen_loss = 0.9130410803532644, disc_loss = 0.007324587923585321
Trained batch 551 in epoch 17, gen_loss = 0.9129098710482535, disc_loss = 0.007312027895882173
Trained batch 552 in epoch 17, gen_loss = 0.9128393250067885, disc_loss = 0.007299968603241407
Trained batch 553 in epoch 17, gen_loss = 0.9128991643551885, disc_loss = 0.00728759014408906
Trained batch 554 in epoch 17, gen_loss = 0.9130226019803468, disc_loss = 0.007275431633031264
Trained batch 555 in epoch 17, gen_loss = 0.9129111299947869, disc_loss = 0.007262966415994355
Trained batch 556 in epoch 17, gen_loss = 0.9128377858676431, disc_loss = 0.0072509015777505285
Trained batch 557 in epoch 17, gen_loss = 0.9127924544302793, disc_loss = 0.007238649919952055
Trained batch 558 in epoch 17, gen_loss = 0.9128702429518077, disc_loss = 0.007226493119998137
Trained batch 559 in epoch 17, gen_loss = 0.913151953741908, disc_loss = 0.0072144251444634785
Trained batch 560 in epoch 17, gen_loss = 0.9130933528596704, disc_loss = 0.00720217265188694
Trained batch 561 in epoch 17, gen_loss = 0.9131731796625246, disc_loss = 0.0071901500759914755
Trained batch 562 in epoch 17, gen_loss = 0.9134524188816653, disc_loss = 0.007230542735593661
Trained batch 563 in epoch 17, gen_loss = 0.9134908809412455, disc_loss = 0.007222981181231836
Trained batch 564 in epoch 17, gen_loss = 0.9133906284792234, disc_loss = 0.007216614618097984
Trained batch 565 in epoch 17, gen_loss = 0.9134217103146832, disc_loss = 0.007205821888220197
Trained batch 566 in epoch 17, gen_loss = 0.9133845217118608, disc_loss = 0.0071940577919126815
Trained batch 567 in epoch 17, gen_loss = 0.9133747500747862, disc_loss = 0.007182646098031833
Trained batch 568 in epoch 17, gen_loss = 0.9131832430253758, disc_loss = 0.007170746809246857
Trained batch 569 in epoch 17, gen_loss = 0.9130222416237781, disc_loss = 0.00715883485523559
Trained batch 570 in epoch 17, gen_loss = 0.9130222018149187, disc_loss = 0.007146976571656509
Trained batch 571 in epoch 17, gen_loss = 0.913137524017504, disc_loss = 0.007135087279830831
Trained batch 572 in epoch 17, gen_loss = 0.913104729450602, disc_loss = 0.007123548458460361
Trained batch 573 in epoch 17, gen_loss = 0.9133875342507811, disc_loss = 0.007112230182356016
Trained batch 574 in epoch 17, gen_loss = 0.9132638124279354, disc_loss = 0.007100367938957947
Trained batch 575 in epoch 17, gen_loss = 0.9133503715921607, disc_loss = 0.007088663234551657
Trained batch 576 in epoch 17, gen_loss = 0.913185439190377, disc_loss = 0.0070769311755288725
Trained batch 577 in epoch 17, gen_loss = 0.9131670680322449, disc_loss = 0.007065466312729031
Trained batch 578 in epoch 17, gen_loss = 0.913183105269862, disc_loss = 0.007053912540711543
Trained batch 579 in epoch 17, gen_loss = 0.9132447370681269, disc_loss = 0.007042458056169161
Trained batch 580 in epoch 17, gen_loss = 0.9132351810160685, disc_loss = 0.007030840837743323
Trained batch 581 in epoch 17, gen_loss = 0.9131983420795592, disc_loss = 0.007019625625385474
Trained batch 582 in epoch 17, gen_loss = 0.9133066053967124, disc_loss = 0.007008038343644843
Trained batch 583 in epoch 17, gen_loss = 0.9132626605258413, disc_loss = 0.006996574066350099
Trained batch 584 in epoch 17, gen_loss = 0.9131312414621695, disc_loss = 0.006985158052516337
Trained batch 585 in epoch 17, gen_loss = 0.9131915652202665, disc_loss = 0.0069737269692802355
Trained batch 586 in epoch 17, gen_loss = 0.9132259106818822, disc_loss = 0.006962421554502884
Trained batch 587 in epoch 17, gen_loss = 0.9133594010253342, disc_loss = 0.006951075990802726
Trained batch 588 in epoch 17, gen_loss = 0.9133215135244845, disc_loss = 0.006940031872976473
Trained batch 589 in epoch 17, gen_loss = 0.9132858804221881, disc_loss = 0.006928894039632169
Trained batch 590 in epoch 17, gen_loss = 0.9134830450749437, disc_loss = 0.006917703052208161
Trained batch 591 in epoch 17, gen_loss = 0.9132871657509256, disc_loss = 0.006907013658476628
Trained batch 592 in epoch 17, gen_loss = 0.9134501513803588, disc_loss = 0.00689601798229309
Trained batch 593 in epoch 17, gen_loss = 0.9135540002825284, disc_loss = 0.0068848187249680665
Trained batch 594 in epoch 17, gen_loss = 0.9137380831882733, disc_loss = 0.0068737861784488085
Trained batch 595 in epoch 17, gen_loss = 0.9136062465958147, disc_loss = 0.006863124986005722
Trained batch 596 in epoch 17, gen_loss = 0.913413836578628, disc_loss = 0.006852796520133794
Trained batch 597 in epoch 17, gen_loss = 0.9134692559174471, disc_loss = 0.006842057244242076
Trained batch 598 in epoch 17, gen_loss = 0.9134819515061896, disc_loss = 0.00683125971926482
Trained batch 599 in epoch 17, gen_loss = 0.9136221643785636, disc_loss = 0.006820721492210093
Trained batch 600 in epoch 17, gen_loss = 0.9138112370166525, disc_loss = 0.0068102399399232886
Trained batch 601 in epoch 17, gen_loss = 0.9138248334592363, disc_loss = 0.006799651819358246
Trained batch 602 in epoch 17, gen_loss = 0.9137867287320284, disc_loss = 0.00678892313733629
Trained batch 603 in epoch 17, gen_loss = 0.913721568685099, disc_loss = 0.006778189035516852
Trained batch 604 in epoch 17, gen_loss = 0.9135729779389279, disc_loss = 0.006767334207321887
Trained batch 605 in epoch 17, gen_loss = 0.9135237973023562, disc_loss = 0.006756430327051462
Trained batch 606 in epoch 17, gen_loss = 0.9134166890255112, disc_loss = 0.006746052533035824
Trained batch 607 in epoch 17, gen_loss = 0.913340133712872, disc_loss = 0.0067355355144603606
Trained batch 608 in epoch 17, gen_loss = 0.9134452505945572, disc_loss = 0.0067248894026675395
Trained batch 609 in epoch 17, gen_loss = 0.9133860436130743, disc_loss = 0.0067146708562609465
Trained batch 610 in epoch 17, gen_loss = 0.9135017552566996, disc_loss = 0.006704057262398366
Trained batch 611 in epoch 17, gen_loss = 0.9136900948056208, disc_loss = 0.006694142505771167
Trained batch 612 in epoch 17, gen_loss = 0.9136685005117202, disc_loss = 0.006683930798246089
Trained batch 613 in epoch 17, gen_loss = 0.9136980127919381, disc_loss = 0.006673515381597526
Trained batch 614 in epoch 17, gen_loss = 0.913820863884639, disc_loss = 0.006663019153359535
Trained batch 615 in epoch 17, gen_loss = 0.9138215081161493, disc_loss = 0.006653133223720376
Trained batch 616 in epoch 17, gen_loss = 0.9139399158993262, disc_loss = 0.006642917546781755
Trained batch 617 in epoch 17, gen_loss = 0.9139985498583433, disc_loss = 0.006632482773804446
Trained batch 618 in epoch 17, gen_loss = 0.9139624206719376, disc_loss = 0.006622189635588443
Trained batch 619 in epoch 17, gen_loss = 0.9139513396928387, disc_loss = 0.0066119078108327345
Trained batch 620 in epoch 17, gen_loss = 0.914023686002418, disc_loss = 0.006601695356562122
Trained batch 621 in epoch 17, gen_loss = 0.914136832597938, disc_loss = 0.0065915810360335165
Trained batch 622 in epoch 17, gen_loss = 0.9140778307834369, disc_loss = 0.006581420613020019
Trained batch 623 in epoch 17, gen_loss = 0.9142475648281666, disc_loss = 0.006571439214754859
Trained batch 624 in epoch 17, gen_loss = 0.9142192818164826, disc_loss = 0.006561420045699924
Trained batch 625 in epoch 17, gen_loss = 0.914136271554822, disc_loss = 0.0065522655428494345
Trained batch 626 in epoch 17, gen_loss = 0.9141246661710207, disc_loss = 0.006542120362652215
Trained batch 627 in epoch 17, gen_loss = 0.9141056063543459, disc_loss = 0.0065320389034368535
Trained batch 628 in epoch 17, gen_loss = 0.914144620465171, disc_loss = 0.006522302255975578
Trained batch 629 in epoch 17, gen_loss = 0.9142391977329103, disc_loss = 0.006512343524913636
Trained batch 630 in epoch 17, gen_loss = 0.9141335115663223, disc_loss = 0.006502498809873457
Trained batch 631 in epoch 17, gen_loss = 0.9142518191115011, disc_loss = 0.006492458137576181
Trained batch 632 in epoch 17, gen_loss = 0.9142487796279491, disc_loss = 0.006482584488885823
Trained batch 633 in epoch 17, gen_loss = 0.9142065961560241, disc_loss = 0.006472635477431866
Trained batch 634 in epoch 17, gen_loss = 0.9143550027543166, disc_loss = 0.006462852412667016
Trained batch 635 in epoch 17, gen_loss = 0.9144715621317707, disc_loss = 0.0064531514031818775
Trained batch 636 in epoch 17, gen_loss = 0.9145125409404, disc_loss = 0.006443665873536546
Trained batch 637 in epoch 17, gen_loss = 0.9144321662785492, disc_loss = 0.0064343057656001965
Trained batch 638 in epoch 17, gen_loss = 0.9144652260581093, disc_loss = 0.0064245756077301415
Trained batch 639 in epoch 17, gen_loss = 0.9143640034366399, disc_loss = 0.0064149160064744136
Trained batch 640 in epoch 17, gen_loss = 0.9143560336737104, disc_loss = 0.006405834564195427
Trained batch 641 in epoch 17, gen_loss = 0.9143022373550778, disc_loss = 0.006396184857725093
Trained batch 642 in epoch 17, gen_loss = 0.9143138186279018, disc_loss = 0.006386560412351199
Trained batch 643 in epoch 17, gen_loss = 0.9144112590399588, disc_loss = 0.006377186151948086
Trained batch 644 in epoch 17, gen_loss = 0.9144155656182489, disc_loss = 0.0063677475856285
Trained batch 645 in epoch 17, gen_loss = 0.9145032931868875, disc_loss = 0.006358287738342034
Trained batch 646 in epoch 17, gen_loss = 0.9143641524281716, disc_loss = 0.006349508658427906
Trained batch 647 in epoch 17, gen_loss = 0.9143326947994438, disc_loss = 0.00634004609795132
Trained batch 648 in epoch 17, gen_loss = 0.914254406705292, disc_loss = 0.006330539884361602
Trained batch 649 in epoch 17, gen_loss = 0.9141902284897291, disc_loss = 0.00632116038591798
Trained batch 650 in epoch 17, gen_loss = 0.9141450129254806, disc_loss = 0.0063121378559791936
Trained batch 651 in epoch 17, gen_loss = 0.9141857847571373, disc_loss = 0.006302981578027708
Trained batch 652 in epoch 17, gen_loss = 0.9142098870887143, disc_loss = 0.006293804775262972
Trained batch 653 in epoch 17, gen_loss = 0.9141449505856277, disc_loss = 0.006284929482533849
Trained batch 654 in epoch 17, gen_loss = 0.9141600853159227, disc_loss = 0.006275621329288474
Trained batch 655 in epoch 17, gen_loss = 0.9140565294045501, disc_loss = 0.006266359814395489
Trained batch 656 in epoch 17, gen_loss = 0.914109336050678, disc_loss = 0.006257193662852397
Trained batch 657 in epoch 17, gen_loss = 0.9139561564817255, disc_loss = 0.006248063596394012
Trained batch 658 in epoch 17, gen_loss = 0.9140059425635475, disc_loss = 0.006239093615373523
Trained batch 659 in epoch 17, gen_loss = 0.9140616841840021, disc_loss = 0.0062299245363895105
Trained batch 660 in epoch 17, gen_loss = 0.9139961473609964, disc_loss = 0.00622082686952316
Trained batch 661 in epoch 17, gen_loss = 0.9140291003752331, disc_loss = 0.006211716930991815
Trained batch 662 in epoch 17, gen_loss = 0.9140895539908748, disc_loss = 0.006202642811054215
Trained batch 663 in epoch 17, gen_loss = 0.9141780358391354, disc_loss = 0.006193642397061396
Trained batch 664 in epoch 17, gen_loss = 0.9139702283798303, disc_loss = 0.006184760212204139
Trained batch 665 in epoch 17, gen_loss = 0.9139572598107226, disc_loss = 0.006175748087269465
Trained batch 666 in epoch 17, gen_loss = 0.9140155129972426, disc_loss = 0.006166779757142234
Trained batch 667 in epoch 17, gen_loss = 0.9138354499807615, disc_loss = 0.006157955784081554
Trained batch 668 in epoch 17, gen_loss = 0.9138884665096465, disc_loss = 0.006149065387501383
Trained batch 669 in epoch 17, gen_loss = 0.91390604256694, disc_loss = 0.0061401619250997345
Trained batch 670 in epoch 17, gen_loss = 0.9138273078443041, disc_loss = 0.006131277682819028
Trained batch 671 in epoch 17, gen_loss = 0.9136724485793993, disc_loss = 0.006122406746141808
Trained batch 672 in epoch 17, gen_loss = 0.9136543071553399, disc_loss = 0.006113574936586213
Trained batch 673 in epoch 17, gen_loss = 0.9136015903259951, disc_loss = 0.006104797647371425
Trained batch 674 in epoch 17, gen_loss = 0.9136619818210602, disc_loss = 0.0060960202748430205
Trained batch 675 in epoch 17, gen_loss = 0.9137586282466995, disc_loss = 0.006087350507741091
Trained batch 676 in epoch 17, gen_loss = 0.9135206543800574, disc_loss = 0.006078952965073829
Trained batch 677 in epoch 17, gen_loss = 0.9136359440629813, disc_loss = 0.006070416066344006
Trained batch 678 in epoch 17, gen_loss = 0.9136672590108964, disc_loss = 0.006061943467971848
Trained batch 679 in epoch 17, gen_loss = 0.9135255818419596, disc_loss = 0.006053858143551385
Trained batch 680 in epoch 17, gen_loss = 0.9132450914855571, disc_loss = 0.006045628030748187
Trained batch 681 in epoch 17, gen_loss = 0.913233024415033, disc_loss = 0.006037218638009916
Trained batch 682 in epoch 17, gen_loss = 0.9131510229358561, disc_loss = 0.006028784331373016
Trained batch 683 in epoch 17, gen_loss = 0.9129994990445717, disc_loss = 0.006020378535560656
Trained batch 684 in epoch 17, gen_loss = 0.9130409470004757, disc_loss = 0.006011977142792019
Trained batch 685 in epoch 17, gen_loss = 0.9129311280330485, disc_loss = 0.006003550542534618
Trained batch 686 in epoch 17, gen_loss = 0.9128824523182415, disc_loss = 0.005995180353467567
Trained batch 687 in epoch 17, gen_loss = 0.9128157216189212, disc_loss = 0.0059867827253689285
Trained batch 688 in epoch 17, gen_loss = 0.9127924478192461, disc_loss = 0.005978353974952278
Trained batch 689 in epoch 17, gen_loss = 0.9128038623626681, disc_loss = 0.005970344473451774
Trained batch 690 in epoch 17, gen_loss = 0.9130491371523972, disc_loss = 0.005962029119870793
Trained batch 691 in epoch 17, gen_loss = 0.9128765475457115, disc_loss = 0.005953929323883562
Trained batch 692 in epoch 17, gen_loss = 0.9129506874652136, disc_loss = 0.005945727575193549
Trained batch 693 in epoch 17, gen_loss = 0.9130020105959016, disc_loss = 0.005937796788485902
Trained batch 694 in epoch 17, gen_loss = 0.9130308614789153, disc_loss = 0.005929473105218369
Trained batch 695 in epoch 17, gen_loss = 0.9131232899581564, disc_loss = 0.005921195020948352
Trained batch 696 in epoch 17, gen_loss = 0.9130584598870325, disc_loss = 0.005913103716653388
Trained batch 697 in epoch 17, gen_loss = 0.9129759616786908, disc_loss = 0.005905051989323075
Trained batch 698 in epoch 17, gen_loss = 0.9130088896284118, disc_loss = 0.005896983655883753
Trained batch 699 in epoch 17, gen_loss = 0.9128856638925417, disc_loss = 0.00588884703162226
Trained batch 700 in epoch 17, gen_loss = 0.9128099866583412, disc_loss = 0.005880709190690357
Trained batch 701 in epoch 17, gen_loss = 0.9127938230747511, disc_loss = 0.005872796646020331
Trained batch 702 in epoch 17, gen_loss = 0.9126934295952066, disc_loss = 0.005864752367081566
Trained batch 703 in epoch 17, gen_loss = 0.9127695061351088, disc_loss = 0.005856690796876633
Trained batch 704 in epoch 17, gen_loss = 0.9127778418097936, disc_loss = 0.005848693314478204
Trained batch 705 in epoch 17, gen_loss = 0.9126939858407542, disc_loss = 0.005841035542348578
Trained batch 706 in epoch 17, gen_loss = 0.9126858008548596, disc_loss = 0.005833392768904476
Trained batch 707 in epoch 17, gen_loss = 0.9125741425964792, disc_loss = 0.005825366458950445
Trained batch 708 in epoch 17, gen_loss = 0.9126582939718944, disc_loss = 0.0058174165425622145
Trained batch 709 in epoch 17, gen_loss = 0.9128054778760588, disc_loss = 0.005809459391498486
Trained batch 710 in epoch 17, gen_loss = 0.9127398500043464, disc_loss = 0.005801654796011428
Trained batch 711 in epoch 17, gen_loss = 0.9128034074236168, disc_loss = 0.0057938917929931544
Trained batch 712 in epoch 17, gen_loss = 0.9126791696979822, disc_loss = 0.0057859817355243245
Trained batch 713 in epoch 17, gen_loss = 0.9127960285636223, disc_loss = 0.005778313937362353
Trained batch 714 in epoch 17, gen_loss = 0.9128356432164466, disc_loss = 0.005770436287519744
Trained batch 715 in epoch 17, gen_loss = 0.9129575997507772, disc_loss = 0.005762733256146956
Trained batch 716 in epoch 17, gen_loss = 0.9128497112828152, disc_loss = 0.005754978356990415
Trained batch 717 in epoch 17, gen_loss = 0.9128245969087633, disc_loss = 0.005747286758527794
Trained batch 718 in epoch 17, gen_loss = 0.912806596684688, disc_loss = 0.005739717656554316
Trained batch 719 in epoch 17, gen_loss = 0.9128440964967013, disc_loss = 0.0057321427433028775
Trained batch 720 in epoch 17, gen_loss = 0.912882089490864, disc_loss = 0.005724509622494467
Trained batch 721 in epoch 17, gen_loss = 0.9129097847644642, disc_loss = 0.005716859242915778
Trained batch 722 in epoch 17, gen_loss = 0.9128408840500633, disc_loss = 0.00570914919644238
Trained batch 723 in epoch 17, gen_loss = 0.9128855970271385, disc_loss = 0.0057014833034890276
Trained batch 724 in epoch 17, gen_loss = 0.9129000526050042, disc_loss = 0.00569387227818691
Trained batch 725 in epoch 17, gen_loss = 0.9129411125396566, disc_loss = 0.005686314774775934
Trained batch 726 in epoch 17, gen_loss = 0.9130501298251802, disc_loss = 0.005679002925695946
Trained batch 727 in epoch 17, gen_loss = 0.9128711515484931, disc_loss = 0.005671525440797827
Trained batch 728 in epoch 17, gen_loss = 0.912842768659644, disc_loss = 0.0056639908424210355
Trained batch 729 in epoch 17, gen_loss = 0.9126748411214515, disc_loss = 0.005656483549523416
Trained batch 730 in epoch 17, gen_loss = 0.9125932417147463, disc_loss = 0.005649213244946306
Trained batch 731 in epoch 17, gen_loss = 0.9127706909358827, disc_loss = 0.005641820478807152
Trained batch 732 in epoch 17, gen_loss = 0.9127515578416328, disc_loss = 0.005635081537783852
Trained batch 733 in epoch 17, gen_loss = 0.9128955818245781, disc_loss = 0.005627994241812444
Trained batch 734 in epoch 17, gen_loss = 0.9128871498870201, disc_loss = 0.0056206370437585865
Trained batch 735 in epoch 17, gen_loss = 0.9129619856324532, disc_loss = 0.005613298543583211
Trained batch 736 in epoch 17, gen_loss = 0.9130539160166213, disc_loss = 0.0056060457730997834
Trained batch 737 in epoch 17, gen_loss = 0.912941732421154, disc_loss = 0.0055988584906356545
Trained batch 738 in epoch 17, gen_loss = 0.913256347139085, disc_loss = 0.0055921869362896325
Trained batch 739 in epoch 17, gen_loss = 0.9131144858292631, disc_loss = 0.005585183359535468
Trained batch 740 in epoch 17, gen_loss = 0.9130809207757314, disc_loss = 0.005577936672874068
Trained batch 741 in epoch 17, gen_loss = 0.9129941298392905, disc_loss = 0.005571152692814602
Trained batch 742 in epoch 17, gen_loss = 0.9129124495976706, disc_loss = 0.005563935494191555
Trained batch 743 in epoch 17, gen_loss = 0.9128169392145449, disc_loss = 0.005556720613571753
Trained batch 744 in epoch 17, gen_loss = 0.9128984838924152, disc_loss = 0.005549651132576205
Trained batch 745 in epoch 17, gen_loss = 0.9128156904001338, disc_loss = 0.005542607079200752
Trained batch 746 in epoch 17, gen_loss = 0.9127107297320921, disc_loss = 0.00553535817887159
Trained batch 747 in epoch 17, gen_loss = 0.9126873326731876, disc_loss = 0.005528312199772398
Trained batch 748 in epoch 17, gen_loss = 0.9126488104442729, disc_loss = 0.005521218787588257
Trained batch 749 in epoch 17, gen_loss = 0.9125862247546513, disc_loss = 0.005514143820619211
Trained batch 750 in epoch 17, gen_loss = 0.9124224765719808, disc_loss = 0.005507649293450884
Trained batch 751 in epoch 17, gen_loss = 0.9123837180990488, disc_loss = 0.005500624877157029
Trained batch 752 in epoch 17, gen_loss = 0.912161999608416, disc_loss = 0.005493605959466176
Trained batch 753 in epoch 17, gen_loss = 0.9120925996521739, disc_loss = 0.005486470877777075
Trained batch 754 in epoch 17, gen_loss = 0.9120115508701627, disc_loss = 0.005479553617898989
Trained batch 755 in epoch 17, gen_loss = 0.9121177692025427, disc_loss = 0.005472543554893856
Trained batch 756 in epoch 17, gen_loss = 0.9121515767813674, disc_loss = 0.005465565734852245
Trained batch 757 in epoch 17, gen_loss = 0.9119408679904912, disc_loss = 0.005458794810452808
Trained batch 758 in epoch 17, gen_loss = 0.9120695172012716, disc_loss = 0.005452006571244479
Trained batch 759 in epoch 17, gen_loss = 0.911988627636119, disc_loss = 0.00544514245797664
Trained batch 760 in epoch 17, gen_loss = 0.9119104340026319, disc_loss = 0.005438236265666841
Trained batch 761 in epoch 17, gen_loss = 0.9119909673616329, disc_loss = 0.00543132283656439
Trained batch 762 in epoch 17, gen_loss = 0.9119612019543254, disc_loss = 0.005424467109552714
Trained batch 763 in epoch 17, gen_loss = 0.9120630164343025, disc_loss = 0.005417563680904757
Trained batch 764 in epoch 17, gen_loss = 0.9121388305636013, disc_loss = 0.005410702585927865
Trained batch 765 in epoch 17, gen_loss = 0.9121701180857094, disc_loss = 0.005403842424775742
Trained batch 766 in epoch 17, gen_loss = 0.9121937175539979, disc_loss = 0.005396998276163516
Trained batch 767 in epoch 17, gen_loss = 0.9122046149568632, disc_loss = 0.00539019491713096
Trained batch 768 in epoch 17, gen_loss = 0.912249493932228, disc_loss = 0.00538336752485434
Trained batch 769 in epoch 17, gen_loss = 0.9120534190496841, disc_loss = 0.0053766365263852225
Trained batch 770 in epoch 17, gen_loss = 0.91190085178374, disc_loss = 0.005369849775553709
Trained batch 771 in epoch 17, gen_loss = 0.9119267501902086, disc_loss = 0.0053630192413443726
Trained batch 772 in epoch 17, gen_loss = 0.9117209789129926, disc_loss = 0.005357505133015059
Trained batch 773 in epoch 17, gen_loss = 0.9116593674402829, disc_loss = 0.005350989287259861
Trained batch 774 in epoch 17, gen_loss = 0.911660560138764, disc_loss = 0.005344372440660898
Trained batch 775 in epoch 17, gen_loss = 0.9117386906033325, disc_loss = 0.005337817795238546
Trained batch 776 in epoch 17, gen_loss = 0.9117652353862998, disc_loss = 0.0053311546468895864
Trained batch 777 in epoch 17, gen_loss = 0.911830520836737, disc_loss = 0.005324598257229014
Trained batch 778 in epoch 17, gen_loss = 0.9118408406576541, disc_loss = 0.005317989371998151
Trained batch 779 in epoch 17, gen_loss = 0.9117146716285974, disc_loss = 0.005311566952402175
Trained batch 780 in epoch 17, gen_loss = 0.9117044593933755, disc_loss = 0.00530497046690707
Trained batch 781 in epoch 17, gen_loss = 0.9117577253933757, disc_loss = 0.0052984638762230245
Trained batch 782 in epoch 17, gen_loss = 0.9116485179384093, disc_loss = 0.005291918225411048
Trained batch 783 in epoch 17, gen_loss = 0.911597178564692, disc_loss = 0.005285369628493253
Trained batch 784 in epoch 17, gen_loss = 0.9115549264060464, disc_loss = 0.005279063336151892
Trained batch 785 in epoch 17, gen_loss = 0.9115251277315101, disc_loss = 0.0052727191115260145
Trained batch 786 in epoch 17, gen_loss = 0.91132639532168, disc_loss = 0.005266373601812426
Trained batch 787 in epoch 17, gen_loss = 0.9112157419626483, disc_loss = 0.005260003077840657
Trained batch 788 in epoch 17, gen_loss = 0.9111819643862499, disc_loss = 0.00525414743025264
Trained batch 789 in epoch 17, gen_loss = 0.9112488191716278, disc_loss = 0.005249229166610682
Trained batch 790 in epoch 17, gen_loss = 0.9111382841084308, disc_loss = 0.005266256681002847
Trained batch 791 in epoch 17, gen_loss = 0.9110397459054836, disc_loss = 0.005263593753358755
Trained batch 792 in epoch 17, gen_loss = 0.9111836383877907, disc_loss = 0.0052595957810796
Trained batch 793 in epoch 17, gen_loss = 0.9114310043659859, disc_loss = 0.005254568859903064
Trained batch 794 in epoch 17, gen_loss = 0.9114588926798143, disc_loss = 0.00524876401755108
Trained batch 795 in epoch 17, gen_loss = 0.9115414833977594, disc_loss = 0.005243046117398286
Trained batch 796 in epoch 17, gen_loss = 0.9114889932920224, disc_loss = 0.005237556390221177
Trained batch 797 in epoch 17, gen_loss = 0.911645651349149, disc_loss = 0.005231512028034727
Trained batch 798 in epoch 17, gen_loss = 0.9117298339946995, disc_loss = 0.005225538050435534
Trained batch 799 in epoch 17, gen_loss = 0.9117784615233541, disc_loss = 0.005219388615287244
Trained batch 800 in epoch 17, gen_loss = 0.911806739857432, disc_loss = 0.005213208049103735
Trained batch 801 in epoch 17, gen_loss = 0.9118828938860548, disc_loss = 0.0052072875913385126
Trained batch 802 in epoch 17, gen_loss = 0.9120908275265177, disc_loss = 0.005201099240923852
Trained batch 803 in epoch 17, gen_loss = 0.9119510033459806, disc_loss = 0.005196162359570011
Trained batch 804 in epoch 17, gen_loss = 0.9119447143551725, disc_loss = 0.005190317317659414
Trained batch 805 in epoch 17, gen_loss = 0.9120406477756003, disc_loss = 0.005184583539050693
Trained batch 806 in epoch 17, gen_loss = 0.9119987273969615, disc_loss = 0.005178734548448696
Trained batch 807 in epoch 17, gen_loss = 0.9119979171543429, disc_loss = 0.005172650922786218
Trained batch 808 in epoch 17, gen_loss = 0.9119534833248525, disc_loss = 0.005166732192000852
Trained batch 809 in epoch 17, gen_loss = 0.9120120955470168, disc_loss = 0.005160575362134733
Trained batch 810 in epoch 17, gen_loss = 0.9121087729636896, disc_loss = 0.005154471421074487
Trained batch 811 in epoch 17, gen_loss = 0.9119305451001439, disc_loss = 0.005148558442598353
Trained batch 812 in epoch 17, gen_loss = 0.9119883503347892, disc_loss = 0.005142934903641576
Trained batch 813 in epoch 17, gen_loss = 0.9119165134444577, disc_loss = 0.005137318956517458
Trained batch 814 in epoch 17, gen_loss = 0.9120059003493537, disc_loss = 0.005131642503742103
Trained batch 815 in epoch 17, gen_loss = 0.9120003562420607, disc_loss = 0.005125597505304861
Trained batch 816 in epoch 17, gen_loss = 0.9118606741089862, disc_loss = 0.00511999864059361
Trained batch 817 in epoch 17, gen_loss = 0.9119920433660591, disc_loss = 0.005114114730335897
Trained batch 818 in epoch 17, gen_loss = 0.9120075129545652, disc_loss = 0.005108224200297665
Trained batch 819 in epoch 17, gen_loss = 0.9119555976696131, disc_loss = 0.005102279936146238
Trained batch 820 in epoch 17, gen_loss = 0.911803915534037, disc_loss = 0.005097237742834866
Trained batch 821 in epoch 17, gen_loss = 0.9116742229157121, disc_loss = 0.0050913545898772375
Trained batch 822 in epoch 17, gen_loss = 0.9116361241511557, disc_loss = 0.005085827271603056
Trained batch 823 in epoch 17, gen_loss = 0.9117036359475076, disc_loss = 0.005079939836585395
Trained batch 824 in epoch 17, gen_loss = 0.9116862759084412, disc_loss = 0.005074132810898873
Trained batch 825 in epoch 17, gen_loss = 0.9115691825422767, disc_loss = 0.0050681970295410736
Trained batch 826 in epoch 17, gen_loss = 0.9115699219372136, disc_loss = 0.00506241573848709
Trained batch 827 in epoch 17, gen_loss = 0.9117722938530111, disc_loss = 0.005056692218160325
Trained batch 828 in epoch 17, gen_loss = 0.9117888564870786, disc_loss = 0.00505092659794291
Trained batch 829 in epoch 17, gen_loss = 0.9116724294711308, disc_loss = 0.005045153453207297
Trained batch 830 in epoch 17, gen_loss = 0.9117290399493436, disc_loss = 0.005039274714258205
Trained batch 831 in epoch 17, gen_loss = 0.9118191329404138, disc_loss = 0.005033646858228517
Trained batch 832 in epoch 17, gen_loss = 0.9117889003951152, disc_loss = 0.005027826526997114
Trained batch 833 in epoch 17, gen_loss = 0.9115922171935189, disc_loss = 0.005025756845013917
Trained batch 834 in epoch 17, gen_loss = 0.9115918174832167, disc_loss = 0.005020659392262867
Trained batch 835 in epoch 17, gen_loss = 0.9115101578489445, disc_loss = 0.005015343224305509
Trained batch 836 in epoch 17, gen_loss = 0.9115141748028986, disc_loss = 0.005009679872174527
Trained batch 837 in epoch 17, gen_loss = 0.911656337841314, disc_loss = 0.005003946274687408
Trained batch 838 in epoch 17, gen_loss = 0.9117491060204103, disc_loss = 0.004998153062697644
Trained batch 839 in epoch 17, gen_loss = 0.9118788775588785, disc_loss = 0.004992405146021199
Trained batch 840 in epoch 17, gen_loss = 0.9117957329140549, disc_loss = 0.004986640480084317
Trained batch 841 in epoch 17, gen_loss = 0.9118444943300619, disc_loss = 0.0049808633049556374
Trained batch 842 in epoch 17, gen_loss = 0.9117574370416458, disc_loss = 0.004975308209779815
Trained batch 843 in epoch 17, gen_loss = 0.9118442785047807, disc_loss = 0.004969688302743725
Trained batch 844 in epoch 17, gen_loss = 0.9119940434334546, disc_loss = 0.004964139291211706
Trained batch 845 in epoch 17, gen_loss = 0.9120894946316456, disc_loss = 0.004958743872914623
Trained batch 846 in epoch 17, gen_loss = 0.9120127231128945, disc_loss = 0.00495315653957236
Trained batch 847 in epoch 17, gen_loss = 0.9119901375599065, disc_loss = 0.004947472936906569
Trained batch 848 in epoch 17, gen_loss = 0.9119878868683208, disc_loss = 0.004941826272099123
Trained batch 849 in epoch 17, gen_loss = 0.9121111401740243, disc_loss = 0.004936226673795746
Trained batch 850 in epoch 17, gen_loss = 0.912136180245358, disc_loss = 0.004930629281038279
Trained batch 851 in epoch 17, gen_loss = 0.9122228674555608, disc_loss = 0.00492498918959346
Trained batch 852 in epoch 17, gen_loss = 0.912229721843847, disc_loss = 0.004919389639993715
Trained batch 853 in epoch 17, gen_loss = 0.9122310451447824, disc_loss = 0.00491389585947731
Trained batch 854 in epoch 17, gen_loss = 0.9122280129563739, disc_loss = 0.004908315017259453
Trained batch 855 in epoch 17, gen_loss = 0.9121818196759602, disc_loss = 0.004902756109216757
Trained batch 856 in epoch 17, gen_loss = 0.9119986010891414, disc_loss = 0.004897297499180092
Trained batch 857 in epoch 17, gen_loss = 0.91204349328449, disc_loss = 0.004891801524941204
Trained batch 858 in epoch 17, gen_loss = 0.9118960992074262, disc_loss = 0.004886435574418727
Trained batch 859 in epoch 17, gen_loss = 0.911740214568238, disc_loss = 0.004880982150736896
Trained batch 860 in epoch 17, gen_loss = 0.9116858258826115, disc_loss = 0.00487563266538298
Trained batch 861 in epoch 17, gen_loss = 0.9116092070833436, disc_loss = 0.004870367911099005
Trained batch 862 in epoch 17, gen_loss = 0.9116858349269125, disc_loss = 0.004864960970781781
Trained batch 863 in epoch 17, gen_loss = 0.911690189641107, disc_loss = 0.004859655921664954
Trained batch 864 in epoch 17, gen_loss = 0.9116199225704105, disc_loss = 0.00485421530080581
Trained batch 865 in epoch 17, gen_loss = 0.9116606524786277, disc_loss = 0.004848782296248324
Trained batch 866 in epoch 17, gen_loss = 0.9115777214711925, disc_loss = 0.004843455248540458
Trained batch 867 in epoch 17, gen_loss = 0.9114772159314375, disc_loss = 0.0048380146875928835
Trained batch 868 in epoch 17, gen_loss = 0.9114226923507431, disc_loss = 0.004832660207871931
Trained batch 869 in epoch 17, gen_loss = 0.9113331716978686, disc_loss = 0.004827251412459829
Trained batch 870 in epoch 17, gen_loss = 0.9114826831765618, disc_loss = 0.00482185426611785
Trained batch 871 in epoch 17, gen_loss = 0.9113304574350152, disc_loss = 0.0048164834314767015
Trained batch 872 in epoch 17, gen_loss = 0.911237018385567, disc_loss = 0.0048113042694104555
Trained batch 873 in epoch 17, gen_loss = 0.9112029869782843, disc_loss = 0.004806004509788864
Trained batch 874 in epoch 17, gen_loss = 0.9111936158793313, disc_loss = 0.00480076893621091
Trained batch 875 in epoch 17, gen_loss = 0.911165038982755, disc_loss = 0.00479549597914071
Trained batch 876 in epoch 17, gen_loss = 0.9111163744293026, disc_loss = 0.004790226741448805
Trained batch 877 in epoch 17, gen_loss = 0.911110212462095, disc_loss = 0.004785003394439988
Trained batch 878 in epoch 17, gen_loss = 0.9109119990240863, disc_loss = 0.004779756843042281
Trained batch 879 in epoch 17, gen_loss = 0.9108955533328381, disc_loss = 0.0047745089989968455
Trained batch 880 in epoch 17, gen_loss = 0.9108559727736418, disc_loss = 0.004769701621541503
Trained batch 881 in epoch 17, gen_loss = 0.9108574391425062, disc_loss = 0.004764786873867352
Trained batch 882 in epoch 17, gen_loss = 0.9106669220419459, disc_loss = 0.004761280572576945
Trained batch 883 in epoch 17, gen_loss = 0.9106469621957697, disc_loss = 0.004756347426999589
Trained batch 884 in epoch 17, gen_loss = 0.9106936515051093, disc_loss = 0.0047514836965960785
Trained batch 885 in epoch 17, gen_loss = 0.9105687478796892, disc_loss = 0.004747267664187395
Trained batch 886 in epoch 17, gen_loss = 0.9106418076134051, disc_loss = 0.0047424216225566505
Trained batch 887 in epoch 17, gen_loss = 0.9107474831377601, disc_loss = 0.004737876011424781
Trained batch 888 in epoch 17, gen_loss = 0.9106955310692267, disc_loss = 0.004733422449587295
Trained batch 889 in epoch 17, gen_loss = 0.9105924800875481, disc_loss = 0.004728754476836707
Trained batch 890 in epoch 17, gen_loss = 0.9104899402486221, disc_loss = 0.004723970320276766
Trained batch 891 in epoch 17, gen_loss = 0.9105258879706999, disc_loss = 0.004718995236315894
Trained batch 892 in epoch 17, gen_loss = 0.9103912724159066, disc_loss = 0.004714381731147416
Trained batch 893 in epoch 17, gen_loss = 0.910414141929923, disc_loss = 0.004709465560455189
Trained batch 894 in epoch 17, gen_loss = 0.9103018328131244, disc_loss = 0.004704756212530348
Trained batch 895 in epoch 17, gen_loss = 0.9104312021351818, disc_loss = 0.004699853516488669
Trained batch 896 in epoch 17, gen_loss = 0.9103086974509185, disc_loss = 0.004694785471372459
Trained batch 897 in epoch 17, gen_loss = 0.9102866830499241, disc_loss = 0.004689859455895186
Trained batch 898 in epoch 17, gen_loss = 0.9102775869897263, disc_loss = 0.004685904979054131
Trained batch 899 in epoch 17, gen_loss = 0.9102021483911409, disc_loss = 0.004680992974050848
Trained batch 900 in epoch 17, gen_loss = 0.9102995219360314, disc_loss = 0.004676185290723691
Trained batch 901 in epoch 17, gen_loss = 0.9102839146577598, disc_loss = 0.004671437865731494
Trained batch 902 in epoch 17, gen_loss = 0.9102229313266897, disc_loss = 0.0046667756072029856
Trained batch 903 in epoch 17, gen_loss = 0.9102030535253276, disc_loss = 0.004661898064130309
Trained batch 904 in epoch 17, gen_loss = 0.9102883994579315, disc_loss = 0.004657064977953229
Trained batch 905 in epoch 17, gen_loss = 0.9103675398802915, disc_loss = 0.004652252903493842
Trained batch 906 in epoch 17, gen_loss = 0.9103420177985972, disc_loss = 0.004647531197975914
Trained batch 907 in epoch 17, gen_loss = 0.9103970783331846, disc_loss = 0.004642856565696361
Trained batch 908 in epoch 17, gen_loss = 0.9104383593410811, disc_loss = 0.004638053662791616
Trained batch 909 in epoch 17, gen_loss = 0.9104129050131683, disc_loss = 0.004633450313625732
Trained batch 910 in epoch 17, gen_loss = 0.9102751233509684, disc_loss = 0.004628997533997144
Trained batch 911 in epoch 17, gen_loss = 0.9102784722978086, disc_loss = 0.0046245711874976945
Trained batch 912 in epoch 17, gen_loss = 0.9100962228673181, disc_loss = 0.004620903481086112
Trained batch 913 in epoch 17, gen_loss = 0.9099900422850115, disc_loss = 0.0046172834100304
Trained batch 914 in epoch 17, gen_loss = 0.9100050736971892, disc_loss = 0.0046132565619372455
Trained batch 915 in epoch 17, gen_loss = 0.9100260690635469, disc_loss = 0.0046086244725206775
Trained batch 916 in epoch 17, gen_loss = 0.909979706794641, disc_loss = 0.004604063658250357
Trained batch 917 in epoch 17, gen_loss = 0.9099913908570421, disc_loss = 0.004599327485943921
Trained batch 918 in epoch 17, gen_loss = 0.9099585001110642, disc_loss = 0.004594809615651591
Trained batch 919 in epoch 17, gen_loss = 0.9099080027769442, disc_loss = 0.00459015778617512
Trained batch 920 in epoch 17, gen_loss = 0.9098516211771163, disc_loss = 0.004585459151270308
Trained batch 921 in epoch 17, gen_loss = 0.9098142886821204, disc_loss = 0.004580799173062136
Trained batch 922 in epoch 17, gen_loss = 0.909884657367725, disc_loss = 0.00457620425488292
Trained batch 923 in epoch 17, gen_loss = 0.9097725860290713, disc_loss = 0.004571609157178835
Trained batch 924 in epoch 17, gen_loss = 0.9098458996012404, disc_loss = 0.004566861034435459
Trained batch 925 in epoch 17, gen_loss = 0.9097780757473045, disc_loss = 0.00456243509502427
Trained batch 926 in epoch 17, gen_loss = 0.9097098939305628, disc_loss = 0.00455775399180575
Trained batch 927 in epoch 17, gen_loss = 0.9096693349359878, disc_loss = 0.004553495743611448
Trained batch 928 in epoch 17, gen_loss = 0.909622349093625, disc_loss = 0.004549014398315809
Trained batch 929 in epoch 17, gen_loss = 0.9096169863016375, disc_loss = 0.004544676845961799
Trained batch 930 in epoch 17, gen_loss = 0.9096301770043809, disc_loss = 0.004540500399418949
Trained batch 931 in epoch 17, gen_loss = 0.909582799628313, disc_loss = 0.004536108193290957
Trained batch 932 in epoch 17, gen_loss = 0.9095581203603285, disc_loss = 0.004531759773458103
Trained batch 933 in epoch 17, gen_loss = 0.9095446396244159, disc_loss = 0.0045272973366627025
Trained batch 934 in epoch 17, gen_loss = 0.9095067923400492, disc_loss = 0.004526992617876899
Trained batch 935 in epoch 17, gen_loss = 0.9094786602271419, disc_loss = 0.004522776944641087
Trained batch 936 in epoch 17, gen_loss = 0.9095358762377227, disc_loss = 0.0045183192365854385
Trained batch 937 in epoch 17, gen_loss = 0.9095101266591026, disc_loss = 0.00451397013522456
Trained batch 938 in epoch 17, gen_loss = 0.9094548018786092, disc_loss = 0.004511238224899555
Trained batch 939 in epoch 17, gen_loss = 0.9094593366726916, disc_loss = 0.004507439156232261
Trained batch 940 in epoch 17, gen_loss = 0.9094281868334151, disc_loss = 0.004503263249560262
Trained batch 941 in epoch 17, gen_loss = 0.9093962112746168, disc_loss = 0.004498958439895112
Trained batch 942 in epoch 17, gen_loss = 0.9093491916375853, disc_loss = 0.004494458770278873
Trained batch 943 in epoch 17, gen_loss = 0.9093547466889782, disc_loss = 0.004490027313719203
Trained batch 944 in epoch 17, gen_loss = 0.909404804561504, disc_loss = 0.004485751680465275
Trained batch 945 in epoch 17, gen_loss = 0.9093981754767214, disc_loss = 0.004481244636249463
Trained batch 946 in epoch 17, gen_loss = 0.9093587192398945, disc_loss = 0.004476997545087642
Trained batch 947 in epoch 17, gen_loss = 0.9092958964690377, disc_loss = 0.00447253742984739
Trained batch 948 in epoch 17, gen_loss = 0.9092358032003971, disc_loss = 0.004468610627082404
Trained batch 949 in epoch 17, gen_loss = 0.9091055327653885, disc_loss = 0.004473847964553371
Trained batch 950 in epoch 17, gen_loss = 0.9090803856290602, disc_loss = 0.004469730512730958
Trained batch 951 in epoch 17, gen_loss = 0.9091727870414738, disc_loss = 0.004466968673465594
Trained batch 952 in epoch 17, gen_loss = 0.9091655704870054, disc_loss = 0.004464736538455743
Trained batch 953 in epoch 17, gen_loss = 0.9091778460975963, disc_loss = 0.004461538493291895
Trained batch 954 in epoch 17, gen_loss = 0.9091046346731835, disc_loss = 0.00446803831984929
Trained batch 955 in epoch 17, gen_loss = 0.9089393644090976, disc_loss = 0.004497745854236786
Trained batch 956 in epoch 17, gen_loss = 0.9090308796462594, disc_loss = 0.004494878609004261
Trained batch 957 in epoch 17, gen_loss = 0.9091408928090197, disc_loss = 0.004491320181811349
Trained batch 958 in epoch 17, gen_loss = 0.9092297689198702, disc_loss = 0.004487838911429949
Trained batch 959 in epoch 17, gen_loss = 0.9093546812422574, disc_loss = 0.0044840347254118266
Trained batch 960 in epoch 17, gen_loss = 0.9094340211084805, disc_loss = 0.004480011953626607
Trained batch 961 in epoch 17, gen_loss = 0.9094405357964074, disc_loss = 0.004476006454897363
Trained batch 962 in epoch 17, gen_loss = 0.9096547396445448, disc_loss = 0.004473217616255986
Trained batch 963 in epoch 17, gen_loss = 0.9096873937738882, disc_loss = 0.004469764425307988
Trained batch 964 in epoch 17, gen_loss = 0.9096789850781001, disc_loss = 0.0044656163786729154
Trained batch 965 in epoch 17, gen_loss = 0.909646050437637, disc_loss = 0.004461397548557385
Trained batch 966 in epoch 17, gen_loss = 0.909747645089397, disc_loss = 0.004457307427793449
Trained batch 967 in epoch 17, gen_loss = 0.9098156982771128, disc_loss = 0.00445317574793095
Trained batch 968 in epoch 17, gen_loss = 0.9096800950351023, disc_loss = 0.004449140269740163
Trained batch 969 in epoch 17, gen_loss = 0.9096105715355922, disc_loss = 0.0044451227853360906
Trained batch 970 in epoch 17, gen_loss = 0.9095552241704, disc_loss = 0.004441249873278431
Trained batch 971 in epoch 17, gen_loss = 0.9095776358565676, disc_loss = 0.004437099414772017
Trained batch 972 in epoch 17, gen_loss = 0.9095858961251877, disc_loss = 0.004432896299310469
Trained batch 973 in epoch 17, gen_loss = 0.9093851327467748, disc_loss = 0.004432064197100597
Trained batch 974 in epoch 17, gen_loss = 0.9094609616658627, disc_loss = 0.004428475873122433
Trained batch 975 in epoch 17, gen_loss = 0.9093699214949471, disc_loss = 0.004425662188377381
Trained batch 976 in epoch 17, gen_loss = 0.909453659212577, disc_loss = 0.004421592867719508
Trained batch 977 in epoch 17, gen_loss = 0.9094459059474902, disc_loss = 0.004417757495720492
Trained batch 978 in epoch 17, gen_loss = 0.9095224590479293, disc_loss = 0.004413555229441641
Trained batch 979 in epoch 17, gen_loss = 0.9095332281626001, disc_loss = 0.004409377973020963
Trained batch 980 in epoch 17, gen_loss = 0.9095112362099957, disc_loss = 0.0044052308414048455
Trained batch 981 in epoch 17, gen_loss = 0.9094218860272235, disc_loss = 0.004401232320932985
Trained batch 982 in epoch 17, gen_loss = 0.9095125527311559, disc_loss = 0.004397143275416416
Trained batch 983 in epoch 17, gen_loss = 0.9093960496649994, disc_loss = 0.004392951732096833
Trained batch 984 in epoch 17, gen_loss = 0.9093869380236882, disc_loss = 0.004388746988953997
Trained batch 985 in epoch 17, gen_loss = 0.909294290698566, disc_loss = 0.0043845087550431145
Trained batch 986 in epoch 17, gen_loss = 0.9093966502488686, disc_loss = 0.0043804700910726494
Trained batch 987 in epoch 17, gen_loss = 0.9094860117867408, disc_loss = 0.0043763525390156585
Trained batch 988 in epoch 17, gen_loss = 0.9094614477261252, disc_loss = 0.004372254990177976
Trained batch 989 in epoch 17, gen_loss = 0.9093594955976563, disc_loss = 0.00436866016195813
Trained batch 990 in epoch 17, gen_loss = 0.9092978753006663, disc_loss = 0.00436461548692368
Trained batch 991 in epoch 17, gen_loss = 0.9092455649027421, disc_loss = 0.004360573289820804
Trained batch 992 in epoch 17, gen_loss = 0.9092559153279749, disc_loss = 0.004357059541714252
Trained batch 993 in epoch 17, gen_loss = 0.9093783845903888, disc_loss = 0.00435414298227631
Trained batch 994 in epoch 17, gen_loss = 0.9093731429409142, disc_loss = 0.004350440199690199
Trained batch 995 in epoch 17, gen_loss = 0.9093470664088985, disc_loss = 0.004346750413871968
Trained batch 996 in epoch 17, gen_loss = 0.9094594188236306, disc_loss = 0.0043432025584191295
Trained batch 997 in epoch 17, gen_loss = 0.9095169988149153, disc_loss = 0.004340462271585295
Trained batch 998 in epoch 17, gen_loss = 0.909568211606315, disc_loss = 0.00433680031856202
Trained batch 999 in epoch 17, gen_loss = 0.9095959459841252, disc_loss = 0.00433291737644322
Trained batch 1000 in epoch 17, gen_loss = 0.909527245845709, disc_loss = 0.004329007891100446
Trained batch 1001 in epoch 17, gen_loss = 0.9094874202431795, disc_loss = 0.00432515039721762
Trained batch 1002 in epoch 17, gen_loss = 0.9094129814761704, disc_loss = 0.004322142067448858
Trained batch 1003 in epoch 17, gen_loss = 0.9094593314476223, disc_loss = 0.0043183297522150265
Trained batch 1004 in epoch 17, gen_loss = 0.9093949065576146, disc_loss = 0.004315113454942177
Trained batch 1005 in epoch 17, gen_loss = 0.9092885432672311, disc_loss = 0.004311271881725799
Trained batch 1006 in epoch 17, gen_loss = 0.9093129295400735, disc_loss = 0.004307688564366336
Trained batch 1007 in epoch 17, gen_loss = 0.9093020163062546, disc_loss = 0.004303955821984663
Trained batch 1008 in epoch 17, gen_loss = 0.9093128255798275, disc_loss = 0.004300092934141094
Trained batch 1009 in epoch 17, gen_loss = 0.9092515026283736, disc_loss = 0.004296321930998583
Trained batch 1010 in epoch 17, gen_loss = 0.9092185037720922, disc_loss = 0.004293298147641282
Trained batch 1011 in epoch 17, gen_loss = 0.9091286461049389, disc_loss = 0.004290413186587649
Trained batch 1012 in epoch 17, gen_loss = 0.9090185740563618, disc_loss = 0.004286890104572486
Trained batch 1013 in epoch 17, gen_loss = 0.9088887079403951, disc_loss = 0.00428345100675048
Trained batch 1014 in epoch 17, gen_loss = 0.9086812350843928, disc_loss = 0.004280537441268212
Trained batch 1015 in epoch 17, gen_loss = 0.9086322819330092, disc_loss = 0.004276869978087871
Trained batch 1016 in epoch 17, gen_loss = 0.9084433347367724, disc_loss = 0.004291266778042078
Trained batch 1017 in epoch 17, gen_loss = 0.908435086926449, disc_loss = 0.004290418586420563
Trained batch 1018 in epoch 17, gen_loss = 0.9085565851937333, disc_loss = 0.004289604913349589
Trained batch 1019 in epoch 17, gen_loss = 0.9085787149328811, disc_loss = 0.004287259347813019
Trained batch 1020 in epoch 17, gen_loss = 0.9084675542346177, disc_loss = 0.004287260830383618
Trained batch 1021 in epoch 17, gen_loss = 0.9084258184799243, disc_loss = 0.004292337898707595
Trained batch 1022 in epoch 17, gen_loss = 0.9083906334341446, disc_loss = 0.004290208893959587
Trained batch 1023 in epoch 17, gen_loss = 0.9083478332904633, disc_loss = 0.004287377016474636
Trained batch 1024 in epoch 17, gen_loss = 0.9083700021011073, disc_loss = 0.0042839155001097315
Trained batch 1025 in epoch 17, gen_loss = 0.9084275740454768, disc_loss = 0.00428122691719217
Trained batch 1026 in epoch 17, gen_loss = 0.9083941889656554, disc_loss = 0.004277658650850568
Trained batch 1027 in epoch 17, gen_loss = 0.9084472733075053, disc_loss = 0.004273939051085044
Trained batch 1028 in epoch 17, gen_loss = 0.9086130270399552, disc_loss = 0.004270420046315894
Trained batch 1029 in epoch 17, gen_loss = 0.9086489034798538, disc_loss = 0.004266777458775605
Trained batch 1030 in epoch 17, gen_loss = 0.9086879010517313, disc_loss = 0.004263178215355752
Trained batch 1031 in epoch 17, gen_loss = 0.9088846265749876, disc_loss = 0.004259444335194396
Trained batch 1032 in epoch 17, gen_loss = 0.9089211502183673, disc_loss = 0.004255841269123962
Trained batch 1033 in epoch 17, gen_loss = 0.908844455039017, disc_loss = 0.004252023773484427
Trained batch 1034 in epoch 17, gen_loss = 0.9088786094948865, disc_loss = 0.004248475225928862
Trained batch 1035 in epoch 17, gen_loss = 0.9089683378007422, disc_loss = 0.0042451016476335035
Trained batch 1036 in epoch 17, gen_loss = 0.9090596625694544, disc_loss = 0.004241395328374813
Trained batch 1037 in epoch 17, gen_loss = 0.9090911234102727, disc_loss = 0.004237550733854529
Trained batch 1038 in epoch 17, gen_loss = 0.909108221215394, disc_loss = 0.0042336970207602865
Trained batch 1039 in epoch 17, gen_loss = 0.909097918208975, disc_loss = 0.0042298799112079274
Trained batch 1040 in epoch 17, gen_loss = 0.909087626809231, disc_loss = 0.004226035335349506
Trained batch 1041 in epoch 17, gen_loss = 0.9090945781592902, disc_loss = 0.004222351529057267
Trained batch 1042 in epoch 17, gen_loss = 0.9089706193509289, disc_loss = 0.004218497150620856
Trained batch 1043 in epoch 17, gen_loss = 0.9090075888795871, disc_loss = 0.00421475260726316
Trained batch 1044 in epoch 17, gen_loss = 0.9091126388054716, disc_loss = 0.004211583121730689
Trained batch 1045 in epoch 17, gen_loss = 0.9091782553644983, disc_loss = 0.0042080166594885594
Trained batch 1046 in epoch 17, gen_loss = 0.9090484098069648, disc_loss = 0.004204435828721999
Trained batch 1047 in epoch 17, gen_loss = 0.9091063215475501, disc_loss = 0.004200695724822108
Trained batch 1048 in epoch 17, gen_loss = 0.909095369002385, disc_loss = 0.00419699235811262
Trained batch 1049 in epoch 17, gen_loss = 0.9090314684311549, disc_loss = 0.004193138787058637
Trained batch 1050 in epoch 17, gen_loss = 0.9090497727115079, disc_loss = 0.00418946595516391
Trained batch 1051 in epoch 17, gen_loss = 0.909028267707435, disc_loss = 0.004185729802410686
Trained batch 1052 in epoch 17, gen_loss = 0.9090145010950446, disc_loss = 0.004181975014360455
Trained batch 1053 in epoch 17, gen_loss = 0.9090264010644276, disc_loss = 0.00417831900094359
Trained batch 1054 in epoch 17, gen_loss = 0.909076577425003, disc_loss = 0.004174587612780488
Trained batch 1055 in epoch 17, gen_loss = 0.9090559759995702, disc_loss = 0.004170958344227047
Trained batch 1056 in epoch 17, gen_loss = 0.9089987744051212, disc_loss = 0.0041671572161625075
Trained batch 1057 in epoch 17, gen_loss = 0.9090612741690728, disc_loss = 0.00416368354048063
Trained batch 1058 in epoch 17, gen_loss = 0.9090817150527064, disc_loss = 0.004159990587723065
Trained batch 1059 in epoch 17, gen_loss = 0.9090083124783804, disc_loss = 0.004156305831312015
Trained batch 1060 in epoch 17, gen_loss = 0.9090228952348064, disc_loss = 0.004152673804802189
Trained batch 1061 in epoch 17, gen_loss = 0.9089542997478316, disc_loss = 0.004149158119072244
Trained batch 1062 in epoch 17, gen_loss = 0.909008404245269, disc_loss = 0.0041454875950800866
Trained batch 1063 in epoch 17, gen_loss = 0.9089906940278702, disc_loss = 0.004141993454482818
Trained batch 1064 in epoch 17, gen_loss = 0.9089698410649815, disc_loss = 0.004138408490901259
Trained batch 1065 in epoch 17, gen_loss = 0.9089240091547063, disc_loss = 0.0041347916161114115
Trained batch 1066 in epoch 17, gen_loss = 0.9088796829384068, disc_loss = 0.004131181470545664
Trained batch 1067 in epoch 17, gen_loss = 0.9088768371649449, disc_loss = 0.004127652721426069
Trained batch 1068 in epoch 17, gen_loss = 0.9087683136101857, disc_loss = 0.004124284049221787
Trained batch 1069 in epoch 17, gen_loss = 0.9088266673210625, disc_loss = 0.004120734205493153
Trained batch 1070 in epoch 17, gen_loss = 0.9087664300487155, disc_loss = 0.004117286682989956
Trained batch 1071 in epoch 17, gen_loss = 0.9087105413704221, disc_loss = 0.004114129753381702
Trained batch 1072 in epoch 17, gen_loss = 0.9087372738572891, disc_loss = 0.004110526316944336
Trained batch 1073 in epoch 17, gen_loss = 0.9087760977072423, disc_loss = 0.004106919734929378
Trained batch 1074 in epoch 17, gen_loss = 0.9088639526866203, disc_loss = 0.004103320255140546
Trained batch 1075 in epoch 17, gen_loss = 0.9088665390712621, disc_loss = 0.004099747732270703
Trained batch 1076 in epoch 17, gen_loss = 0.9089128440081686, disc_loss = 0.004096124240538218
Trained batch 1077 in epoch 17, gen_loss = 0.9089782320115031, disc_loss = 0.004092633601000581
Trained batch 1078 in epoch 17, gen_loss = 0.9089102464709932, disc_loss = 0.004089187496228532
Trained batch 1079 in epoch 17, gen_loss = 0.9088418917799438, disc_loss = 0.004085525627986634
Trained batch 1080 in epoch 17, gen_loss = 0.9087003888243552, disc_loss = 0.0040819470706216715
Trained batch 1081 in epoch 17, gen_loss = 0.9086782874715086, disc_loss = 0.004078329821021088
Trained batch 1082 in epoch 17, gen_loss = 0.9085492545933165, disc_loss = 0.004074802395529129
Trained batch 1083 in epoch 17, gen_loss = 0.9085900618306385, disc_loss = 0.004071262631538967
Trained batch 1084 in epoch 17, gen_loss = 0.9086509043445236, disc_loss = 0.004067815231940707
Trained batch 1085 in epoch 17, gen_loss = 0.9086661054778494, disc_loss = 0.0040643230057838715
Trained batch 1086 in epoch 17, gen_loss = 0.9086052121486594, disc_loss = 0.004060908632131309
Trained batch 1087 in epoch 17, gen_loss = 0.9085965641116833, disc_loss = 0.004057374591525331
Trained batch 1088 in epoch 17, gen_loss = 0.9085469923783487, disc_loss = 0.004054023091972554
Trained batch 1089 in epoch 17, gen_loss = 0.9085110515902896, disc_loss = 0.004050528132838652
Trained batch 1090 in epoch 17, gen_loss = 0.9085103176964411, disc_loss = 0.004047145776338434
Trained batch 1091 in epoch 17, gen_loss = 0.9085066200339751, disc_loss = 0.004043701764673172
Trained batch 1092 in epoch 17, gen_loss = 0.9085370987953664, disc_loss = 0.004040657204536907
Trained batch 1093 in epoch 17, gen_loss = 0.9086449063183839, disc_loss = 0.004037651613168089
Trained batch 1094 in epoch 17, gen_loss = 0.9086478228710558, disc_loss = 0.004034300347170569
Trained batch 1095 in epoch 17, gen_loss = 0.9086318684157229, disc_loss = 0.004030888544574915
Trained batch 1096 in epoch 17, gen_loss = 0.9086335080530606, disc_loss = 0.004027427731056851
Trained batch 1097 in epoch 17, gen_loss = 0.9087104366613867, disc_loss = 0.004024086478441152
Trained batch 1098 in epoch 17, gen_loss = 0.9087427678001914, disc_loss = 0.004020736281392942
Trained batch 1099 in epoch 17, gen_loss = 0.9087367589636283, disc_loss = 0.00401722739545221
Trained batch 1100 in epoch 17, gen_loss = 0.9087679996531622, disc_loss = 0.004013940978882364
Trained batch 1101 in epoch 17, gen_loss = 0.9087503578128486, disc_loss = 0.004010526392022948
Trained batch 1102 in epoch 17, gen_loss = 0.9087638261906148, disc_loss = 0.004007016873986497
Trained batch 1103 in epoch 17, gen_loss = 0.9088420991286419, disc_loss = 0.0040036676863881284
Trained batch 1104 in epoch 17, gen_loss = 0.9088079621619228, disc_loss = 0.004000226401480819
Trained batch 1105 in epoch 17, gen_loss = 0.9088356764094524, disc_loss = 0.003996943004361607
Trained batch 1106 in epoch 17, gen_loss = 0.9088645624005267, disc_loss = 0.003993602374371349
Trained batch 1107 in epoch 17, gen_loss = 0.9088431354410381, disc_loss = 0.003990182564477489
Trained batch 1108 in epoch 17, gen_loss = 0.908888696092437, disc_loss = 0.003986845313977062
Trained batch 1109 in epoch 17, gen_loss = 0.908776902642336, disc_loss = 0.003983904011601316
Trained batch 1110 in epoch 17, gen_loss = 0.9087240662958899, disc_loss = 0.003980861341468472
Trained batch 1111 in epoch 17, gen_loss = 0.9087788735201462, disc_loss = 0.003978039450394528
Trained batch 1112 in epoch 17, gen_loss = 0.9088099338348556, disc_loss = 0.003974912692718712
Trained batch 1113 in epoch 17, gen_loss = 0.908864737921386, disc_loss = 0.00397184474393438
Trained batch 1114 in epoch 17, gen_loss = 0.9088087818815035, disc_loss = 0.003968546563878733
Trained batch 1115 in epoch 17, gen_loss = 0.9087219371003062, disc_loss = 0.0039695670160047785
Trained batch 1116 in epoch 17, gen_loss = 0.9087577781030506, disc_loss = 0.003966540598772283
Trained batch 1117 in epoch 17, gen_loss = 0.9087070318635333, disc_loss = 0.003964194453791067
Trained batch 1118 in epoch 17, gen_loss = 0.9087449417410417, disc_loss = 0.003961497013088263
Trained batch 1119 in epoch 17, gen_loss = 0.9087055973442537, disc_loss = 0.0039584993900397035
Trained batch 1120 in epoch 17, gen_loss = 0.9087392460491698, disc_loss = 0.0039556074073814115
Trained batch 1121 in epoch 17, gen_loss = 0.9087579091230603, disc_loss = 0.003952617879928998
Trained batch 1122 in epoch 17, gen_loss = 0.9086861726384236, disc_loss = 0.0039497123982943205
Trained batch 1123 in epoch 17, gen_loss = 0.9086886336529807, disc_loss = 0.003946799556062123
Trained batch 1124 in epoch 17, gen_loss = 0.9086667001247406, disc_loss = 0.003943798265478108
Trained batch 1125 in epoch 17, gen_loss = 0.9086522091821921, disc_loss = 0.003940899670089161
Trained batch 1126 in epoch 17, gen_loss = 0.9086737860433803, disc_loss = 0.003938110037994215
Trained batch 1127 in epoch 17, gen_loss = 0.908731174410869, disc_loss = 0.003935081313753756
Trained batch 1128 in epoch 17, gen_loss = 0.9087690139524276, disc_loss = 0.003931938173084433
Trained batch 1129 in epoch 17, gen_loss = 0.908791765728883, disc_loss = 0.003928721313699884
Trained batch 1130 in epoch 17, gen_loss = 0.9088379895918987, disc_loss = 0.003925510407191037
Trained batch 1131 in epoch 17, gen_loss = 0.90886582152477, disc_loss = 0.003922492617216175
Trained batch 1132 in epoch 17, gen_loss = 0.9088893090584377, disc_loss = 0.003919316083260897
Trained batch 1133 in epoch 17, gen_loss = 0.9089847450165942, disc_loss = 0.003916182091040629
Trained batch 1134 in epoch 17, gen_loss = 0.9090216447865911, disc_loss = 0.003912974662709795
Trained batch 1135 in epoch 17, gen_loss = 0.9089183196372969, disc_loss = 0.003910004345816816
Trained batch 1136 in epoch 17, gen_loss = 0.9089681870232786, disc_loss = 0.003906916465232504
Trained batch 1137 in epoch 17, gen_loss = 0.9090144065698128, disc_loss = 0.0039038677594151537
Trained batch 1138 in epoch 17, gen_loss = 0.9090953669964587, disc_loss = 0.0039009282504917403
Trained batch 1139 in epoch 17, gen_loss = 0.9091100778234632, disc_loss = 0.003897969714186426
Trained batch 1140 in epoch 17, gen_loss = 0.9091067097617491, disc_loss = 0.0038948803577208576
Trained batch 1141 in epoch 17, gen_loss = 0.9091107352341536, disc_loss = 0.0038916880469892076
Trained batch 1142 in epoch 17, gen_loss = 0.9091117623231959, disc_loss = 0.003888569096241471
Trained batch 1143 in epoch 17, gen_loss = 0.9091356160392711, disc_loss = 0.0038854676097932364
Trained batch 1144 in epoch 17, gen_loss = 0.9091889450904064, disc_loss = 0.0038822946407413824
Trained batch 1145 in epoch 17, gen_loss = 0.9091927425035423, disc_loss = 0.0038791843230119825
Trained batch 1146 in epoch 17, gen_loss = 0.909235077129828, disc_loss = 0.003876157868196045
Trained batch 1147 in epoch 17, gen_loss = 0.9090885545162789, disc_loss = 0.0038734456705682824
Trained batch 1148 in epoch 17, gen_loss = 0.9091142408997209, disc_loss = 0.0038704698484381753
Trained batch 1149 in epoch 17, gen_loss = 0.9091066900802696, disc_loss = 0.003867574798723976
Trained batch 1150 in epoch 17, gen_loss = 0.909053778694983, disc_loss = 0.003864550544850443
Trained batch 1151 in epoch 17, gen_loss = 0.9090590702318069, disc_loss = 0.0038614808720025292
Trained batch 1152 in epoch 17, gen_loss = 0.9090984272677693, disc_loss = 0.003858341620145323
Trained batch 1153 in epoch 17, gen_loss = 0.9090641499133829, disc_loss = 0.0038555285407228137
Trained batch 1154 in epoch 17, gen_loss = 0.9089961849507832, disc_loss = 0.003852425335579626
Trained batch 1155 in epoch 17, gen_loss = 0.9089025529971585, disc_loss = 0.003849445003425776
Trained batch 1156 in epoch 17, gen_loss = 0.9089325112882316, disc_loss = 0.003846267331085945
Trained batch 1157 in epoch 17, gen_loss = 0.9089973789474095, disc_loss = 0.003843152476410554
Trained batch 1158 in epoch 17, gen_loss = 0.9089723096467792, disc_loss = 0.003840132884302197
Trained batch 1159 in epoch 17, gen_loss = 0.9089766099792103, disc_loss = 0.00383748827700464
Trained batch 1160 in epoch 17, gen_loss = 0.9089003225578305, disc_loss = 0.0038343588742563396
Trained batch 1161 in epoch 17, gen_loss = 0.9089815902063646, disc_loss = 0.003831583009973413
Trained batch 1162 in epoch 17, gen_loss = 0.9089924451972735, disc_loss = 0.0038285322543547442
Trained batch 1163 in epoch 17, gen_loss = 0.9089932773275065, disc_loss = 0.003825465002223156
Trained batch 1164 in epoch 17, gen_loss = 0.9089881198856452, disc_loss = 0.0038223331016895576
Trained batch 1165 in epoch 17, gen_loss = 0.9089751290365108, disc_loss = 0.0038192383898749105
Trained batch 1166 in epoch 17, gen_loss = 0.9087957273258954, disc_loss = 0.003818337703587305
Trained batch 1167 in epoch 17, gen_loss = 0.9086881653750187, disc_loss = 0.0038159702352434217
Trained batch 1168 in epoch 17, gen_loss = 0.9085848260323547, disc_loss = 0.0038129327947104457
Trained batch 1169 in epoch 17, gen_loss = 0.9085359382069009, disc_loss = 0.0038098634672826294
Trained batch 1170 in epoch 17, gen_loss = 0.9085406068295724, disc_loss = 0.003806936174987175
Trained batch 1171 in epoch 17, gen_loss = 0.9084907383896385, disc_loss = 0.003803916331144944
Trained batch 1172 in epoch 17, gen_loss = 0.9084882967663136, disc_loss = 0.003800814264170452
Trained batch 1173 in epoch 17, gen_loss = 0.9084619863222161, disc_loss = 0.0037979701324819697
Trained batch 1174 in epoch 17, gen_loss = 0.9084611228425452, disc_loss = 0.0037950099275900705
Trained batch 1175 in epoch 17, gen_loss = 0.9084251176591228, disc_loss = 0.003792066074787553
Trained batch 1176 in epoch 17, gen_loss = 0.9084014380342796, disc_loss = 0.0037891306710724137
Trained batch 1177 in epoch 17, gen_loss = 0.9082970882565137, disc_loss = 0.0037860506585991765
Trained batch 1178 in epoch 17, gen_loss = 0.9083219877080052, disc_loss = 0.0037830240474668753
Trained batch 1179 in epoch 17, gen_loss = 0.9082835333074554, disc_loss = 0.0037800181672306065
Trained batch 1180 in epoch 17, gen_loss = 0.9082568164955853, disc_loss = 0.0037769419496286455
Trained batch 1181 in epoch 17, gen_loss = 0.9082097801208092, disc_loss = 0.003773862084951427
Trained batch 1182 in epoch 17, gen_loss = 0.9082153822190663, disc_loss = 0.0037708145359002894
Trained batch 1183 in epoch 17, gen_loss = 0.9081748746385848, disc_loss = 0.003767817056719601
Trained batch 1184 in epoch 17, gen_loss = 0.9082212552994112, disc_loss = 0.0037647838329192434
Trained batch 1185 in epoch 17, gen_loss = 0.9081834915767834, disc_loss = 0.003761747698295415
Trained batch 1186 in epoch 17, gen_loss = 0.9081908176451444, disc_loss = 0.0037588857485174334
Trained batch 1187 in epoch 17, gen_loss = 0.9080784626631223, disc_loss = 0.0037559735177490785
Trained batch 1188 in epoch 17, gen_loss = 0.9080749401984042, disc_loss = 0.0037529357396032604
Trained batch 1189 in epoch 17, gen_loss = 0.9080882381240861, disc_loss = 0.003750003720180008
Trained batch 1190 in epoch 17, gen_loss = 0.9081463972176953, disc_loss = 0.0037472635225110295
Trained batch 1191 in epoch 17, gen_loss = 0.9081408811745627, disc_loss = 0.003744534311097339
Trained batch 1192 in epoch 17, gen_loss = 0.9081058560402975, disc_loss = 0.0037414926668064147
Trained batch 1193 in epoch 17, gen_loss = 0.9080218178293413, disc_loss = 0.00373850929659125
Trained batch 1194 in epoch 17, gen_loss = 0.9079173291826846, disc_loss = 0.0037355508374074128
Trained batch 1195 in epoch 17, gen_loss = 0.9079045903772415, disc_loss = 0.003732562298764271
Trained batch 1196 in epoch 17, gen_loss = 0.9078100760628406, disc_loss = 0.0037296293578057632
Trained batch 1197 in epoch 17, gen_loss = 0.9076991394933357, disc_loss = 0.0037267362380701834
Trained batch 1198 in epoch 17, gen_loss = 0.9077840345764876, disc_loss = 0.0037238064240279266
Trained batch 1199 in epoch 17, gen_loss = 0.9078002672642469, disc_loss = 0.0037208654057940293
Trained batch 1200 in epoch 17, gen_loss = 0.907790891559396, disc_loss = 0.003717891327116852
Trained batch 1201 in epoch 17, gen_loss = 0.9078120539916336, disc_loss = 0.0037150263651680436
Trained batch 1202 in epoch 17, gen_loss = 0.9077273134826523, disc_loss = 0.00371207165476437
Trained batch 1203 in epoch 17, gen_loss = 0.9075972236123592, disc_loss = 0.0037092253528211937
Trained batch 1204 in epoch 17, gen_loss = 0.9074756904509058, disc_loss = 0.0037062739670994937
Trained batch 1205 in epoch 17, gen_loss = 0.9073768900352134, disc_loss = 0.0037033174626193194
Trained batch 1206 in epoch 17, gen_loss = 0.9072951874213467, disc_loss = 0.003700715151959334
Trained batch 1207 in epoch 17, gen_loss = 0.9072337843082994, disc_loss = 0.003697799556740567
Trained batch 1208 in epoch 17, gen_loss = 0.9072694801860254, disc_loss = 0.0036950317854658244
Trained batch 1209 in epoch 17, gen_loss = 0.9072444869220749, disc_loss = 0.0036921988260316036
Trained batch 1210 in epoch 17, gen_loss = 0.907169811864415, disc_loss = 0.0036892906761061364
Trained batch 1211 in epoch 17, gen_loss = 0.9071214701918879, disc_loss = 0.0036863943611750694
Trained batch 1212 in epoch 17, gen_loss = 0.907121672747259, disc_loss = 0.0036834652906325292
Trained batch 1213 in epoch 17, gen_loss = 0.9071399462232873, disc_loss = 0.003680662055791801
Trained batch 1214 in epoch 17, gen_loss = 0.9070965777454062, disc_loss = 0.0036778019848191026
Trained batch 1215 in epoch 17, gen_loss = 0.9070472403821584, disc_loss = 0.003674901324368301
Trained batch 1216 in epoch 17, gen_loss = 0.906932101816845, disc_loss = 0.003671975557376631
Trained batch 1217 in epoch 17, gen_loss = 0.9068756002951138, disc_loss = 0.0036690755853674025
Trained batch 1218 in epoch 17, gen_loss = 0.9068100775383455, disc_loss = 0.0036662973425657355
Trained batch 1219 in epoch 17, gen_loss = 0.90684035901652, disc_loss = 0.003663493434059554
Trained batch 1220 in epoch 17, gen_loss = 0.9066986429652262, disc_loss = 0.00366086657171306
Trained batch 1221 in epoch 17, gen_loss = 0.9066062710825629, disc_loss = 0.0036582737687220947
Trained batch 1222 in epoch 17, gen_loss = 0.906596931710364, disc_loss = 0.003655431144401301
Trained batch 1223 in epoch 17, gen_loss = 0.906620187477933, disc_loss = 0.0036526694501208706
Trained batch 1224 in epoch 17, gen_loss = 0.9065947608315215, disc_loss = 0.003649821464995122
Trained batch 1225 in epoch 17, gen_loss = 0.9064597756059485, disc_loss = 0.0036470569075791404
Trained batch 1226 in epoch 17, gen_loss = 0.906477473305801, disc_loss = 0.0036442396985809544
Trained batch 1227 in epoch 17, gen_loss = 0.9064040500245965, disc_loss = 0.003641419688982031
Trained batch 1228 in epoch 17, gen_loss = 0.9063979420989776, disc_loss = 0.003638741219849574
Trained batch 1229 in epoch 17, gen_loss = 0.9063796639200149, disc_loss = 0.0036360806863903108
Trained batch 1230 in epoch 17, gen_loss = 0.9063659400643613, disc_loss = 0.0036332478429454947
Trained batch 1231 in epoch 17, gen_loss = 0.906381169092152, disc_loss = 0.003630419169617021
Trained batch 1232 in epoch 17, gen_loss = 0.9063126166613239, disc_loss = 0.003627576498761186
Trained batch 1233 in epoch 17, gen_loss = 0.9062550793638878, disc_loss = 0.003624820083035075
Trained batch 1234 in epoch 17, gen_loss = 0.9062671111421546, disc_loss = 0.0036220707675700854
Trained batch 1235 in epoch 17, gen_loss = 0.9063087410766716, disc_loss = 0.003619254378407742
Trained batch 1236 in epoch 17, gen_loss = 0.9062310732605964, disc_loss = 0.0036164675950237494
Trained batch 1237 in epoch 17, gen_loss = 0.9062587520369421, disc_loss = 0.003613675757183538
Trained batch 1238 in epoch 17, gen_loss = 0.906298399717217, disc_loss = 0.003610892967595856
Trained batch 1239 in epoch 17, gen_loss = 0.9063312907613092, disc_loss = 0.0036081033906978726
Trained batch 1240 in epoch 17, gen_loss = 0.9063080918827333, disc_loss = 0.0036052940650982386
Trained batch 1241 in epoch 17, gen_loss = 0.9063149437956188, disc_loss = 0.003602537207176128
Trained batch 1242 in epoch 17, gen_loss = 0.9062774597351722, disc_loss = 0.003599735778899594
Trained batch 1243 in epoch 17, gen_loss = 0.9062588506908279, disc_loss = 0.003597018523104543
Trained batch 1244 in epoch 17, gen_loss = 0.9062259044752542, disc_loss = 0.0035942681094299138
Trained batch 1245 in epoch 17, gen_loss = 0.9062174829156594, disc_loss = 0.0035914754469903356
Trained batch 1246 in epoch 17, gen_loss = 0.9061249855669766, disc_loss = 0.0035887228775465223
Trained batch 1247 in epoch 17, gen_loss = 0.9061247837992433, disc_loss = 0.0035859464894190006
Trained batch 1248 in epoch 17, gen_loss = 0.906115348359124, disc_loss = 0.0035833423809600706
Trained batch 1249 in epoch 17, gen_loss = 0.9061140111684799, disc_loss = 0.0035807163627410775
Trained batch 1250 in epoch 17, gen_loss = 0.9060245076481768, disc_loss = 0.0035779527980651575
Trained batch 1251 in epoch 17, gen_loss = 0.9060786561891675, disc_loss = 0.0035752926927578085
Trained batch 1252 in epoch 17, gen_loss = 0.9060511263912426, disc_loss = 0.0035725683282843103
Trained batch 1253 in epoch 17, gen_loss = 0.9059685248364672, disc_loss = 0.0035698201486941013
Trained batch 1254 in epoch 17, gen_loss = 0.9059428751943596, disc_loss = 0.003567174907844
Trained batch 1255 in epoch 17, gen_loss = 0.9058240126035396, disc_loss = 0.0035644807095097093
Trained batch 1256 in epoch 17, gen_loss = 0.905880925360424, disc_loss = 0.0035619601106248273
Trained batch 1257 in epoch 17, gen_loss = 0.9060162866579898, disc_loss = 0.003559446073733783
Trained batch 1258 in epoch 17, gen_loss = 0.9059746906670244, disc_loss = 0.003556850244660484
Trained batch 1259 in epoch 17, gen_loss = 0.9060199388199383, disc_loss = 0.003554174309453903
Trained batch 1260 in epoch 17, gen_loss = 0.905984378092635, disc_loss = 0.0035515029074716592
Trained batch 1261 in epoch 17, gen_loss = 0.9059569126972117, disc_loss = 0.0035488884175650976
Trained batch 1262 in epoch 17, gen_loss = 0.9059633360858579, disc_loss = 0.003546202148150504
Trained batch 1263 in epoch 17, gen_loss = 0.905894502596576, disc_loss = 0.0035434889742830392
Trained batch 1264 in epoch 17, gen_loss = 0.9059110114461348, disc_loss = 0.003540895745937442
Trained batch 1265 in epoch 17, gen_loss = 0.9058583075354262, disc_loss = 0.0035382101628916043
Trained batch 1266 in epoch 17, gen_loss = 0.905877824810987, disc_loss = 0.0035355177980758257
Trained batch 1267 in epoch 17, gen_loss = 0.9057853839797928, disc_loss = 0.00353282493043632
Trained batch 1268 in epoch 17, gen_loss = 0.9057360154564124, disc_loss = 0.003530176123896593
Trained batch 1269 in epoch 17, gen_loss = 0.9057002870351311, disc_loss = 0.003527531097900887
Trained batch 1270 in epoch 17, gen_loss = 0.9057929138092429, disc_loss = 0.003525133357313196
Trained batch 1271 in epoch 17, gen_loss = 0.9058480711899838, disc_loss = 0.0035225812031149536
Trained batch 1272 in epoch 17, gen_loss = 0.9058324690653597, disc_loss = 0.003519974814390499
Trained batch 1273 in epoch 17, gen_loss = 0.9057410548629716, disc_loss = 0.003517397856038951
Trained batch 1274 in epoch 17, gen_loss = 0.9057521019963657, disc_loss = 0.0035147693251458218
Trained batch 1275 in epoch 17, gen_loss = 0.9057334750470323, disc_loss = 0.0035121714517685016
Trained batch 1276 in epoch 17, gen_loss = 0.9057050876862012, disc_loss = 0.003509595170801025
Trained batch 1277 in epoch 17, gen_loss = 0.9056714465593881, disc_loss = 0.003507021342677963
Trained batch 1278 in epoch 17, gen_loss = 0.9056781354921697, disc_loss = 0.0035043829532279275
Trained batch 1279 in epoch 17, gen_loss = 0.9056379973655566, disc_loss = 0.0035017510338377633
Trained batch 1280 in epoch 17, gen_loss = 0.9056049353391468, disc_loss = 0.003499134465187392
Trained batch 1281 in epoch 17, gen_loss = 0.905540468795995, disc_loss = 0.0034965543361838275
Trained batch 1282 in epoch 17, gen_loss = 0.9055539800938646, disc_loss = 0.0034939321111688527
Trained batch 1283 in epoch 17, gen_loss = 0.9054965566483985, disc_loss = 0.0034913888232544666
Trained batch 1284 in epoch 17, gen_loss = 0.9054161290946173, disc_loss = 0.00348874962418014
Trained batch 1285 in epoch 17, gen_loss = 0.9054058216639662, disc_loss = 0.0034862080198366117
Trained batch 1286 in epoch 17, gen_loss = 0.9053770902319851, disc_loss = 0.003483652419054435
Trained batch 1287 in epoch 17, gen_loss = 0.9053409288619986, disc_loss = 0.0034810800244028444
Trained batch 1288 in epoch 17, gen_loss = 0.905301874163911, disc_loss = 0.0034785713670635126
Trained batch 1289 in epoch 17, gen_loss = 0.9052496020877084, disc_loss = 0.003475986924063046
Trained batch 1290 in epoch 17, gen_loss = 0.9052245202081135, disc_loss = 0.0034733781250468566
Trained batch 1291 in epoch 17, gen_loss = 0.9052758077303692, disc_loss = 0.003470923208824219
Trained batch 1292 in epoch 17, gen_loss = 0.9052592722694724, disc_loss = 0.003468327492846049
Trained batch 1293 in epoch 17, gen_loss = 0.9052289759127029, disc_loss = 0.0034657978307436614
Trained batch 1294 in epoch 17, gen_loss = 0.9052529226168703, disc_loss = 0.003463315158338748
Trained batch 1295 in epoch 17, gen_loss = 0.9052142099143914, disc_loss = 0.003460812724723736
Trained batch 1296 in epoch 17, gen_loss = 0.9051425193444342, disc_loss = 0.0034582413619608293
Trained batch 1297 in epoch 17, gen_loss = 0.9051673672921118, disc_loss = 0.00345581937683209
Trained batch 1298 in epoch 17, gen_loss = 0.9051268626351463, disc_loss = 0.003453296192219218
Trained batch 1299 in epoch 17, gen_loss = 0.9051021325358978, disc_loss = 0.0034507754157227914
Trained batch 1300 in epoch 17, gen_loss = 0.9051321231109376, disc_loss = 0.003448232933158797
Trained batch 1301 in epoch 17, gen_loss = 0.9051583566103479, disc_loss = 0.0034456778341976618
Trained batch 1302 in epoch 17, gen_loss = 0.9051756557142927, disc_loss = 0.0034432100127897397
Trained batch 1303 in epoch 17, gen_loss = 0.9052256783870466, disc_loss = 0.003440740015857006
Trained batch 1304 in epoch 17, gen_loss = 0.9052468028790193, disc_loss = 0.0034382941522307685
Trained batch 1305 in epoch 17, gen_loss = 0.9051568307564416, disc_loss = 0.0034357525785180406
Trained batch 1306 in epoch 17, gen_loss = 0.9052282385955627, disc_loss = 0.0034332659418395664
Trained batch 1307 in epoch 17, gen_loss = 0.9051346785477178, disc_loss = 0.0034307366832771707
Trained batch 1308 in epoch 17, gen_loss = 0.905186385052909, disc_loss = 0.0034282490395532365
Trained batch 1309 in epoch 17, gen_loss = 0.9051582804390492, disc_loss = 0.0034257806303636756
Trained batch 1310 in epoch 17, gen_loss = 0.9050873855567906, disc_loss = 0.003423271011188866
Trained batch 1311 in epoch 17, gen_loss = 0.9050843941229509, disc_loss = 0.003420838109250104
Trained batch 1312 in epoch 17, gen_loss = 0.9050838277935528, disc_loss = 0.0034183072334055516
Trained batch 1313 in epoch 17, gen_loss = 0.905042525091672, disc_loss = 0.0034157919049582126
Trained batch 1314 in epoch 17, gen_loss = 0.9050660726462026, disc_loss = 0.003413275410494229
Trained batch 1315 in epoch 17, gen_loss = 0.9050712991494538, disc_loss = 0.0034107865091083473
Trained batch 1316 in epoch 17, gen_loss = 0.9050254180246714, disc_loss = 0.0034082759340866853
Trained batch 1317 in epoch 17, gen_loss = 0.9050165124248843, disc_loss = 0.003405831884920907
Trained batch 1318 in epoch 17, gen_loss = 0.9049647719549174, disc_loss = 0.00340332321771695
Trained batch 1319 in epoch 17, gen_loss = 0.9049864081496543, disc_loss = 0.0034008308896084074
Trained batch 1320 in epoch 17, gen_loss = 0.9050815116041633, disc_loss = 0.0033984459379614233
Trained batch 1321 in epoch 17, gen_loss = 0.9049620488362666, disc_loss = 0.003395994675760305
Trained batch 1322 in epoch 17, gen_loss = 0.9049216314012681, disc_loss = 0.0033935073974965305
Trained batch 1323 in epoch 17, gen_loss = 0.9048415629300106, disc_loss = 0.0033910562875281
Trained batch 1324 in epoch 17, gen_loss = 0.9047350649338848, disc_loss = 0.0033886080502833343
Trained batch 1325 in epoch 17, gen_loss = 0.9047960212192924, disc_loss = 0.003386240984720951
Trained batch 1326 in epoch 17, gen_loss = 0.9048629007621555, disc_loss = 0.0033838400714806586
Trained batch 1327 in epoch 17, gen_loss = 0.9047814071941448, disc_loss = 0.0033814534650851587
Trained batch 1328 in epoch 17, gen_loss = 0.9048762786334578, disc_loss = 0.0033790101055817504
Trained batch 1329 in epoch 17, gen_loss = 0.9047865576537928, disc_loss = 0.0033771469521183517
Trained batch 1330 in epoch 17, gen_loss = 0.9048142905391131, disc_loss = 0.0033747245682013618
Trained batch 1331 in epoch 17, gen_loss = 0.9048307552128225, disc_loss = 0.0033723103384469062
Trained batch 1332 in epoch 17, gen_loss = 0.9048141032479708, disc_loss = 0.003369919081016233
Trained batch 1333 in epoch 17, gen_loss = 0.9047303800952846, disc_loss = 0.0033674822720811412
Trained batch 1334 in epoch 17, gen_loss = 0.9046312774835008, disc_loss = 0.0033650655914965687
Trained batch 1335 in epoch 17, gen_loss = 0.9046407782076719, disc_loss = 0.003362630838855258
Trained batch 1336 in epoch 17, gen_loss = 0.904799704352866, disc_loss = 0.0033882800662338826
Trained batch 1337 in epoch 17, gen_loss = 0.9047723621219085, disc_loss = 0.003391947301990787
Trained batch 1338 in epoch 17, gen_loss = 0.9046315827015357, disc_loss = 0.003393834748779779
Trained batch 1339 in epoch 17, gen_loss = 0.9046125371731929, disc_loss = 0.003392760956221401
Trained batch 1340 in epoch 17, gen_loss = 0.9045846766051208, disc_loss = 0.0033911233337549267
Trained batch 1341 in epoch 17, gen_loss = 0.9045112414393801, disc_loss = 0.0033894056248459595
Trained batch 1342 in epoch 17, gen_loss = 0.9045583213210017, disc_loss = 0.003387381252235681
Trained batch 1343 in epoch 17, gen_loss = 0.9045715921647137, disc_loss = 0.003385226270638885
Trained batch 1344 in epoch 17, gen_loss = 0.9045769379706188, disc_loss = 0.003382996628395252
Trained batch 1345 in epoch 17, gen_loss = 0.9045591878899848, disc_loss = 0.003380756312242841
Trained batch 1346 in epoch 17, gen_loss = 0.9045095608556545, disc_loss = 0.003379090852904645
Trained batch 1347 in epoch 17, gen_loss = 0.9044779743170173, disc_loss = 0.003376824005216283
Trained batch 1348 in epoch 17, gen_loss = 0.904445946327044, disc_loss = 0.0033763638601224237
Trained batch 1349 in epoch 17, gen_loss = 0.9044191796470571, disc_loss = 0.0033745297014818923
Trained batch 1350 in epoch 17, gen_loss = 0.9043966439324428, disc_loss = 0.0033726746828361557
Trained batch 1351 in epoch 17, gen_loss = 0.9044084624117296, disc_loss = 0.0033706686291714925
Trained batch 1352 in epoch 17, gen_loss = 0.9043769047203896, disc_loss = 0.0033686857084908968
Trained batch 1353 in epoch 17, gen_loss = 0.9044849228339498, disc_loss = 0.003366669625720909
Trained batch 1354 in epoch 17, gen_loss = 0.9044216415319055, disc_loss = 0.003365156775203188
Trained batch 1355 in epoch 17, gen_loss = 0.9044785023746589, disc_loss = 0.0033631569072455226
Trained batch 1356 in epoch 17, gen_loss = 0.9044822818361492, disc_loss = 0.0033611290931309865
Trained batch 1357 in epoch 17, gen_loss = 0.9044543516785126, disc_loss = 0.003358905248051663
Trained batch 1358 in epoch 17, gen_loss = 0.9044321864689862, disc_loss = 0.003356644989229162
Trained batch 1359 in epoch 17, gen_loss = 0.9044435693718055, disc_loss = 0.0033543111691976854
Trained batch 1360 in epoch 17, gen_loss = 0.9044236590063458, disc_loss = 0.003352083281792786
Trained batch 1361 in epoch 17, gen_loss = 0.9044207589435508, disc_loss = 0.003349817792094843
Trained batch 1362 in epoch 17, gen_loss = 0.9044324174271904, disc_loss = 0.0033475401741339347
Trained batch 1363 in epoch 17, gen_loss = 0.9044134057293539, disc_loss = 0.0033451851448427824
Trained batch 1364 in epoch 17, gen_loss = 0.9044936731839791, disc_loss = 0.003343020640107873
Trained batch 1365 in epoch 17, gen_loss = 0.9045061496785933, disc_loss = 0.0033407317939261535
Trained batch 1366 in epoch 17, gen_loss = 0.9045416729547896, disc_loss = 0.00333844578099939
Trained batch 1367 in epoch 17, gen_loss = 0.9044980873184943, disc_loss = 0.0033362616794986757
Trained batch 1368 in epoch 17, gen_loss = 0.9044508973423628, disc_loss = 0.0033339657005205547
Trained batch 1369 in epoch 17, gen_loss = 0.9044687815173699, disc_loss = 0.0033317024583588814
Trained batch 1370 in epoch 17, gen_loss = 0.9044318407187055, disc_loss = 0.003329389441223996
Trained batch 1371 in epoch 17, gen_loss = 0.904360503153794, disc_loss = 0.003327090576130589
Trained batch 1372 in epoch 17, gen_loss = 0.9043992533140259, disc_loss = 0.0033247853061130444
Trained batch 1373 in epoch 17, gen_loss = 0.9044173758753522, disc_loss = 0.0033225496781080725
Trained batch 1374 in epoch 17, gen_loss = 0.9043382299813357, disc_loss = 0.0033203781857631507
Trained batch 1375 in epoch 17, gen_loss = 0.9043282908279189, disc_loss = 0.0033180865508246255
Trained batch 1376 in epoch 17, gen_loss = 0.9043156301836736, disc_loss = 0.0033157792305585233
Trained batch 1377 in epoch 17, gen_loss = 0.9043662171102573, disc_loss = 0.003313570299948637
Trained batch 1378 in epoch 17, gen_loss = 0.9043761507551942, disc_loss = 0.0033112778051619476
Trained batch 1379 in epoch 17, gen_loss = 0.9044123337536618, disc_loss = 0.0033090393722807715
Trained batch 1380 in epoch 17, gen_loss = 0.9044261104511576, disc_loss = 0.003306816041146165
Trained batch 1381 in epoch 17, gen_loss = 0.9044315259251339, disc_loss = 0.0033045516012333094
Trained batch 1382 in epoch 17, gen_loss = 0.9043864236090033, disc_loss = 0.0033023584330264147
Trained batch 1383 in epoch 17, gen_loss = 0.9043784945815629, disc_loss = 0.0033001408745136265
Trained batch 1384 in epoch 17, gen_loss = 0.9043705136121826, disc_loss = 0.0032978834858635314
Trained batch 1385 in epoch 17, gen_loss = 0.9042964033879243, disc_loss = 0.003295640391972738
Trained batch 1386 in epoch 17, gen_loss = 0.9042984591642557, disc_loss = 0.00329341344229855
Trained batch 1387 in epoch 17, gen_loss = 0.9043378608156349, disc_loss = 0.0032912619958512346
Trained batch 1388 in epoch 17, gen_loss = 0.9043723515377704, disc_loss = 0.003289060876682752
Trained batch 1389 in epoch 17, gen_loss = 0.9042655449762619, disc_loss = 0.003287119990906288
Trained batch 1390 in epoch 17, gen_loss = 0.904267498672994, disc_loss = 0.003285023584860582
Trained batch 1391 in epoch 17, gen_loss = 0.904239807342147, disc_loss = 0.003282876820572585
Trained batch 1392 in epoch 17, gen_loss = 0.9042349274819135, disc_loss = 0.0032807331948290974
Trained batch 1393 in epoch 17, gen_loss = 0.9041544559653555, disc_loss = 0.003278712098567686
Trained batch 1394 in epoch 17, gen_loss = 0.9041376200414473, disc_loss = 0.0032765266705042763
Trained batch 1395 in epoch 17, gen_loss = 0.9042495124703833, disc_loss = 0.0032743116198903576
Trained batch 1396 in epoch 17, gen_loss = 0.9042244288822371, disc_loss = 0.003272262059679662
Trained batch 1397 in epoch 17, gen_loss = 0.9041923170480264, disc_loss = 0.0032701999149707035
Trained batch 1398 in epoch 17, gen_loss = 0.9042139994280095, disc_loss = 0.00326798477730208
Trained batch 1399 in epoch 17, gen_loss = 0.9041181639475482, disc_loss = 0.003265807315240506
Trained batch 1400 in epoch 17, gen_loss = 0.9040660861770567, disc_loss = 0.003263692670619721
Trained batch 1401 in epoch 17, gen_loss = 0.9040431819654225, disc_loss = 0.003261543549195996
Trained batch 1402 in epoch 17, gen_loss = 0.904053285452441, disc_loss = 0.0032593664329678483
Trained batch 1403 in epoch 17, gen_loss = 0.9040106224835428, disc_loss = 0.0032571264589808606
Trained batch 1404 in epoch 17, gen_loss = 0.9039701299098887, disc_loss = 0.0032549716002302446
Trained batch 1405 in epoch 17, gen_loss = 0.9039199800147102, disc_loss = 0.00325274724467401
Trained batch 1406 in epoch 17, gen_loss = 0.9038652499559168, disc_loss = 0.0032505573494709923
Trained batch 1407 in epoch 17, gen_loss = 0.903817382154309, disc_loss = 0.0032483886323885517
Trained batch 1408 in epoch 17, gen_loss = 0.9038496694512363, disc_loss = 0.003246173015476931
Trained batch 1409 in epoch 17, gen_loss = 0.903717781952087, disc_loss = 0.0032441304884580583
Trained batch 1410 in epoch 17, gen_loss = 0.9036968564792865, disc_loss = 0.0032419767781318937
Trained batch 1411 in epoch 17, gen_loss = 0.9036307177234641, disc_loss = 0.0032398108774921034
Trained batch 1412 in epoch 17, gen_loss = 0.9036997803246308, disc_loss = 0.0032376540468367437
Trained batch 1413 in epoch 17, gen_loss = 0.9037110696966948, disc_loss = 0.0032355162169232445
Trained batch 1414 in epoch 17, gen_loss = 0.9036430147216514, disc_loss = 0.0032334083031878196
Trained batch 1415 in epoch 17, gen_loss = 0.9036143941352259, disc_loss = 0.0032312271693272277
Trained batch 1416 in epoch 17, gen_loss = 0.903657346164667, disc_loss = 0.0032290412815475108
Trained batch 1417 in epoch 17, gen_loss = 0.9036524967725253, disc_loss = 0.0032268522309339444
Trained batch 1418 in epoch 17, gen_loss = 0.9036505700123822, disc_loss = 0.0032246609731294133
Trained batch 1419 in epoch 17, gen_loss = 0.903594759295524, disc_loss = 0.0032224984354221487
Trained batch 1420 in epoch 17, gen_loss = 0.9035912327452665, disc_loss = 0.003220359490464889
Trained batch 1421 in epoch 17, gen_loss = 0.903616132720278, disc_loss = 0.0032181592272454494
Trained batch 1422 in epoch 17, gen_loss = 0.9036158318471004, disc_loss = 0.003215978692203457
Trained batch 1423 in epoch 17, gen_loss = 0.9036911881915973, disc_loss = 0.003213823421518693
Trained batch 1424 in epoch 17, gen_loss = 0.9037215223019583, disc_loss = 0.003211695834715532
Trained batch 1425 in epoch 17, gen_loss = 0.9037752584730593, disc_loss = 0.0032095380277306525
Trained batch 1426 in epoch 17, gen_loss = 0.9038788665193065, disc_loss = 0.0032074171363516155
Trained batch 1427 in epoch 17, gen_loss = 0.903790387807607, disc_loss = 0.003205300551953183
Trained batch 1428 in epoch 17, gen_loss = 0.903728463188429, disc_loss = 0.0032032152725955288
Trained batch 1429 in epoch 17, gen_loss = 0.9037239558421648, disc_loss = 0.0032011868586485728
Trained batch 1430 in epoch 17, gen_loss = 0.9036343516918598, disc_loss = 0.0031990496211179308
Trained batch 1431 in epoch 17, gen_loss = 0.9035849521904351, disc_loss = 0.0031970269938994037
Trained batch 1432 in epoch 17, gen_loss = 0.9035362999545721, disc_loss = 0.0031948805400754086
Trained batch 1433 in epoch 17, gen_loss = 0.9035003518833775, disc_loss = 0.003192761432733804
Trained batch 1434 in epoch 17, gen_loss = 0.9034274738632428, disc_loss = 0.0031905933947891374
Trained batch 1435 in epoch 17, gen_loss = 0.9033913467297315, disc_loss = 0.003188476760424693
Trained batch 1436 in epoch 17, gen_loss = 0.9033836862363994, disc_loss = 0.003186450846892313
Trained batch 1437 in epoch 17, gen_loss = 0.9034719770782017, disc_loss = 0.0031844303744549764
Trained batch 1438 in epoch 17, gen_loss = 0.9034579512019221, disc_loss = 0.0031823207913535337
Trained batch 1439 in epoch 17, gen_loss = 0.9034770917354359, disc_loss = 0.003180187332635695
Trained batch 1440 in epoch 17, gen_loss = 0.9034426715910062, disc_loss = 0.003178081231133062
Trained batch 1441 in epoch 17, gen_loss = 0.9034313891656521, disc_loss = 0.0031760150700500065
Trained batch 1442 in epoch 17, gen_loss = 0.9033732915494646, disc_loss = 0.0031739314960626667
Trained batch 1443 in epoch 17, gen_loss = 0.9033060992482296, disc_loss = 0.0031718266246946536
Trained batch 1444 in epoch 17, gen_loss = 0.9032797122702879, disc_loss = 0.003169730056562037
Trained batch 1445 in epoch 17, gen_loss = 0.9032656292161836, disc_loss = 0.0031676773930584446
Trained batch 1446 in epoch 17, gen_loss = 0.9032566206942942, disc_loss = 0.0031655517599556925
Trained batch 1447 in epoch 17, gen_loss = 0.9032270198904019, disc_loss = 0.0031635249381338952
Trained batch 1448 in epoch 17, gen_loss = 0.9032752263167548, disc_loss = 0.003161489672297356
Trained batch 1449 in epoch 17, gen_loss = 0.903235540410568, disc_loss = 0.0031593945148202253
Trained batch 1450 in epoch 17, gen_loss = 0.9032655067274605, disc_loss = 0.003157332007079663
Trained batch 1451 in epoch 17, gen_loss = 0.9031764154550787, disc_loss = 0.0031553190744461695
Trained batch 1452 in epoch 17, gen_loss = 0.903172442872854, disc_loss = 0.003153248548310233
Trained batch 1453 in epoch 17, gen_loss = 0.9031909947505188, disc_loss = 0.0031511958297347265
Trained batch 1454 in epoch 17, gen_loss = 0.9031958543762718, disc_loss = 0.003149147908395529
Trained batch 1455 in epoch 17, gen_loss = 0.903223729252324, disc_loss = 0.00314707991774812
Trained batch 1456 in epoch 17, gen_loss = 0.9032337317216372, disc_loss = 0.003145047080977019
Trained batch 1457 in epoch 17, gen_loss = 0.9031659886138756, disc_loss = 0.0031430553023444937
Trained batch 1458 in epoch 17, gen_loss = 0.9031125882907303, disc_loss = 0.003141018738771281
Trained batch 1459 in epoch 17, gen_loss = 0.9029505535143696, disc_loss = 0.0031392741534683123
Trained batch 1460 in epoch 17, gen_loss = 0.9030074168157284, disc_loss = 0.0031373191307576373
Trained batch 1461 in epoch 17, gen_loss = 0.9030170742977823, disc_loss = 0.003135299250273018
Trained batch 1462 in epoch 17, gen_loss = 0.9030424401072387, disc_loss = 0.0031333020373879136
Trained batch 1463 in epoch 17, gen_loss = 0.9030958267712528, disc_loss = 0.0031312662009450767
Trained batch 1464 in epoch 17, gen_loss = 0.9031101149707117, disc_loss = 0.0031292472987619717
Trained batch 1465 in epoch 17, gen_loss = 0.903140714292962, disc_loss = 0.0031272749362918338
Trained batch 1466 in epoch 17, gen_loss = 0.9030912931914548, disc_loss = 0.003125232056841842
Trained batch 1467 in epoch 17, gen_loss = 0.9030507040649084, disc_loss = 0.0031231876252061984
Trained batch 1468 in epoch 17, gen_loss = 0.903027250155695, disc_loss = 0.003121180200077068
Trained batch 1469 in epoch 17, gen_loss = 0.9030362826829054, disc_loss = 0.003119219039727381
Trained batch 1470 in epoch 17, gen_loss = 0.902972792399975, disc_loss = 0.0031172635751301318
Trained batch 1471 in epoch 17, gen_loss = 0.9029120390060479, disc_loss = 0.003115255269068731
Trained batch 1472 in epoch 17, gen_loss = 0.9029323693974359, disc_loss = 0.0031134710675943594
Trained batch 1473 in epoch 17, gen_loss = 0.9028813847248396, disc_loss = 0.0031115154916675444
Trained batch 1474 in epoch 17, gen_loss = 0.9029464362233373, disc_loss = 0.003109567728602935
Trained batch 1475 in epoch 17, gen_loss = 0.9029209227944778, disc_loss = 0.0031077511825686405
Trained batch 1476 in epoch 17, gen_loss = 0.9029138473416796, disc_loss = 0.003105798938773948
Trained batch 1477 in epoch 17, gen_loss = 0.9029236021520965, disc_loss = 0.0031038233257095027
Trained batch 1478 in epoch 17, gen_loss = 0.9028762509042625, disc_loss = 0.0031019056909011964
Trained batch 1479 in epoch 17, gen_loss = 0.9028580411261803, disc_loss = 0.0030999227443710363
Trained batch 1480 in epoch 17, gen_loss = 0.902773752174693, disc_loss = 0.0030980078714556132
Trained batch 1481 in epoch 17, gen_loss = 0.9027476207568095, disc_loss = 0.003096057008326425
Trained batch 1482 in epoch 17, gen_loss = 0.9026942484417398, disc_loss = 0.0030941833651521237
Trained batch 1483 in epoch 17, gen_loss = 0.9026632535288919, disc_loss = 0.003092198837026626
Trained batch 1484 in epoch 17, gen_loss = 0.9027200401632072, disc_loss = 0.003090240978215459
Trained batch 1485 in epoch 17, gen_loss = 0.9027056261435813, disc_loss = 0.0030883962396482706
Trained batch 1486 in epoch 17, gen_loss = 0.9026848810305913, disc_loss = 0.0030864391915223256
Trained batch 1487 in epoch 17, gen_loss = 0.9027118957851843, disc_loss = 0.0030844695988498545
Trained batch 1488 in epoch 17, gen_loss = 0.9026769581579217, disc_loss = 0.003082572174243636
Trained batch 1489 in epoch 17, gen_loss = 0.9026919650351442, disc_loss = 0.0030806122427552724
Trained batch 1490 in epoch 17, gen_loss = 0.9027312074748564, disc_loss = 0.0030787103767165964
Trained batch 1491 in epoch 17, gen_loss = 0.9026862495346619, disc_loss = 0.0030767222336646285
Trained batch 1492 in epoch 17, gen_loss = 0.9026656890785782, disc_loss = 0.003074815563133917
Trained batch 1493 in epoch 17, gen_loss = 0.9026851235743029, disc_loss = 0.0030728391028382444
Trained batch 1494 in epoch 17, gen_loss = 0.902673674327474, disc_loss = 0.0030708733782558438
Trained batch 1495 in epoch 17, gen_loss = 0.9027099108751764, disc_loss = 0.003068889768427346
Trained batch 1496 in epoch 17, gen_loss = 0.9027363681243751, disc_loss = 0.00306694509523968
Trained batch 1497 in epoch 17, gen_loss = 0.90269988606148, disc_loss = 0.003065015447845288
Trained batch 1498 in epoch 17, gen_loss = 0.9026837844583017, disc_loss = 0.0030630468539604725
Trained batch 1499 in epoch 17, gen_loss = 0.9026702496409417, disc_loss = 0.0030611356183265644
Trained batch 1500 in epoch 17, gen_loss = 0.9026493784151897, disc_loss = 0.0030591931758848063
Trained batch 1501 in epoch 17, gen_loss = 0.902612631651914, disc_loss = 0.003057230978455229
Trained batch 1502 in epoch 17, gen_loss = 0.9026354570549009, disc_loss = 0.0030553579328875865
Trained batch 1503 in epoch 17, gen_loss = 0.9026862720740919, disc_loss = 0.0030534069395740672
Trained batch 1504 in epoch 17, gen_loss = 0.902705238843677, disc_loss = 0.003051461488988167
Trained batch 1505 in epoch 17, gen_loss = 0.902761667076335, disc_loss = 0.0030495705664258205
Trained batch 1506 in epoch 17, gen_loss = 0.9027934819361035, disc_loss = 0.0030476324054151903
Trained batch 1507 in epoch 17, gen_loss = 0.9028020265761674, disc_loss = 0.003045812539980714
Trained batch 1508 in epoch 17, gen_loss = 0.9027689671856114, disc_loss = 0.0030438803323951744
Trained batch 1509 in epoch 17, gen_loss = 0.9027225793394822, disc_loss = 0.00304238921279413
Trained batch 1510 in epoch 17, gen_loss = 0.9026979792402092, disc_loss = 0.003041580952745172
Trained batch 1511 in epoch 17, gen_loss = 0.9027273708353283, disc_loss = 0.003040008885171446
Trained batch 1512 in epoch 17, gen_loss = 0.9027074680411886, disc_loss = 0.003039096570342532
Trained batch 1513 in epoch 17, gen_loss = 0.9027847505348047, disc_loss = 0.0030380464583303
Trained batch 1514 in epoch 17, gen_loss = 0.9028559337158014, disc_loss = 0.003036819800199317
Trained batch 1515 in epoch 17, gen_loss = 0.9028795862221466, disc_loss = 0.003035616407227026
Trained batch 1516 in epoch 17, gen_loss = 0.9029312305687758, disc_loss = 0.003034016286848612
Trained batch 1517 in epoch 17, gen_loss = 0.9029787732325053, disc_loss = 0.003032307678441948
Trained batch 1518 in epoch 17, gen_loss = 0.9030136338302067, disc_loss = 0.003030703833165831
Trained batch 1519 in epoch 17, gen_loss = 0.9031337878225665, disc_loss = 0.003028950500954938
Trained batch 1520 in epoch 17, gen_loss = 0.9032215635334482, disc_loss = 0.003027135153094176
Trained batch 1521 in epoch 17, gen_loss = 0.9032439489441382, disc_loss = 0.003025329710034768
Trained batch 1522 in epoch 17, gen_loss = 0.9032331143682596, disc_loss = 0.0030234220235775
Trained batch 1523 in epoch 17, gen_loss = 0.9032489192180746, disc_loss = 0.003021680185951496
Trained batch 1524 in epoch 17, gen_loss = 0.9032301482020831, disc_loss = 0.0030197671206847413
Trained batch 1525 in epoch 17, gen_loss = 0.9031625744516852, disc_loss = 0.0030178665045308114
Trained batch 1526 in epoch 17, gen_loss = 0.903196746313892, disc_loss = 0.003016031317072603
Trained batch 1527 in epoch 17, gen_loss = 0.9031934125534214, disc_loss = 0.003014138928342642
Trained batch 1528 in epoch 17, gen_loss = 0.903194207452028, disc_loss = 0.0030122842283395925
Trained batch 1529 in epoch 17, gen_loss = 0.9031287290496763, disc_loss = 0.0030105726126112725
Trained batch 1530 in epoch 17, gen_loss = 0.9030765700114466, disc_loss = 0.003008847531871986
Trained batch 1531 in epoch 17, gen_loss = 0.9030036659955044, disc_loss = 0.0030070896099039473
Trained batch 1532 in epoch 17, gen_loss = 0.9029822725722468, disc_loss = 0.0030053145159066297
Trained batch 1533 in epoch 17, gen_loss = 0.9029241085169057, disc_loss = 0.0030034767929806084
Trained batch 1534 in epoch 17, gen_loss = 0.9029485086858855, disc_loss = 0.003001636524168253
Trained batch 1535 in epoch 17, gen_loss = 0.9028766431729309, disc_loss = 0.002999908265811276
Trained batch 1536 in epoch 17, gen_loss = 0.9029253009045054, disc_loss = 0.0029980766151026777
Trained batch 1537 in epoch 17, gen_loss = 0.9029537530613504, disc_loss = 0.0029962709415133288
Trained batch 1538 in epoch 17, gen_loss = 0.9030566825697839, disc_loss = 0.0029944089455340183
Trained batch 1539 in epoch 17, gen_loss = 0.9030073292263142, disc_loss = 0.002992531862462358
Trained batch 1540 in epoch 17, gen_loss = 0.9030113038616007, disc_loss = 0.0029906664763432312
Trained batch 1541 in epoch 17, gen_loss = 0.9028797739326722, disc_loss = 0.002988863024758059
Trained batch 1542 in epoch 17, gen_loss = 0.9028292203096314, disc_loss = 0.0029870494691783224
Trained batch 1543 in epoch 17, gen_loss = 0.9027661504561728, disc_loss = 0.002985233326158551
Trained batch 1544 in epoch 17, gen_loss = 0.9027311529735146, disc_loss = 0.0029834233844661436
Trained batch 1545 in epoch 17, gen_loss = 0.902735928148224, disc_loss = 0.002981569687197696
Trained batch 1546 in epoch 17, gen_loss = 0.9027535410449824, disc_loss = 0.0029797268910700747
Trained batch 1547 in epoch 17, gen_loss = 0.9027460418275777, disc_loss = 0.00297794211774301
Trained batch 1548 in epoch 17, gen_loss = 0.9027076389152362, disc_loss = 0.0029760738918583694
Trained batch 1549 in epoch 17, gen_loss = 0.9026900468141802, disc_loss = 0.002974236257981712
Trained batch 1550 in epoch 17, gen_loss = 0.9026967475946145, disc_loss = 0.0029723904098207772
Trained batch 1551 in epoch 17, gen_loss = 0.9026024473504615, disc_loss = 0.002970542804703036
Trained batch 1552 in epoch 17, gen_loss = 0.9025782213737638, disc_loss = 0.0029686929477903906
Trained batch 1553 in epoch 17, gen_loss = 0.902643994302363, disc_loss = 0.002966993255456451
Trained batch 1554 in epoch 17, gen_loss = 0.9026458749242151, disc_loss = 0.0029651683834295305
Trained batch 1555 in epoch 17, gen_loss = 0.9026512132627186, disc_loss = 0.0029633249903636733
Trained batch 1556 in epoch 17, gen_loss = 0.9026856872808803, disc_loss = 0.0029615352418633028
Trained batch 1557 in epoch 17, gen_loss = 0.9027103934920033, disc_loss = 0.0029597082524681815
Trained batch 1558 in epoch 17, gen_loss = 0.9027590076268828, disc_loss = 0.0029579211287869894
Trained batch 1559 in epoch 17, gen_loss = 0.9027488755683104, disc_loss = 0.0029561037188334293
Trained batch 1560 in epoch 17, gen_loss = 0.9027498473844644, disc_loss = 0.002954308262256427
Trained batch 1561 in epoch 17, gen_loss = 0.9027408813430466, disc_loss = 0.0029525296604275336
Trained batch 1562 in epoch 17, gen_loss = 0.9027475223317027, disc_loss = 0.0029507383208051763
Trained batch 1563 in epoch 17, gen_loss = 0.9027914664591364, disc_loss = 0.002948997120549621
Trained batch 1564 in epoch 17, gen_loss = 0.9028102332220291, disc_loss = 0.002947192318500771
Trained batch 1565 in epoch 17, gen_loss = 0.9027632375748526, disc_loss = 0.002945394942919686
Trained batch 1566 in epoch 17, gen_loss = 0.9027618411132007, disc_loss = 0.00294358356130517
Trained batch 1567 in epoch 17, gen_loss = 0.9027881516827917, disc_loss = 0.0029418270375006204
Trained batch 1568 in epoch 17, gen_loss = 0.902709161555258, disc_loss = 0.002940020201592672
Trained batch 1569 in epoch 17, gen_loss = 0.9027049942570887, disc_loss = 0.002938218067822256
Trained batch 1570 in epoch 17, gen_loss = 0.9026878198986976, disc_loss = 0.00293646849064533
Trained batch 1571 in epoch 17, gen_loss = 0.9026277399131359, disc_loss = 0.00293470427162249
Trained batch 1572 in epoch 17, gen_loss = 0.9026751064109862, disc_loss = 0.0029329168600422412
Trained batch 1573 in epoch 17, gen_loss = 0.9026578084448544, disc_loss = 0.0029311353727739012
Trained batch 1574 in epoch 17, gen_loss = 0.9025946490915995, disc_loss = 0.0029294313188034317
Trained batch 1575 in epoch 17, gen_loss = 0.9026341955106573, disc_loss = 0.0029276642968157868
Trained batch 1576 in epoch 17, gen_loss = 0.9026115668409598, disc_loss = 0.002925925909284614
Trained batch 1577 in epoch 17, gen_loss = 0.9026089629632892, disc_loss = 0.0029241501374881883
Trained batch 1578 in epoch 17, gen_loss = 0.9025720665355209, disc_loss = 0.002922382380361523
Trained batch 1579 in epoch 17, gen_loss = 0.9025690397318406, disc_loss = 0.0029206278792347044
Trained batch 1580 in epoch 17, gen_loss = 0.9025118934776419, disc_loss = 0.002918838538114928
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.8560971617698669, disc_loss = 0.00014969341282267123
Trained batch 1 in epoch 18, gen_loss = 0.8303481638431549, disc_loss = 0.00017062614642782137
Trained batch 2 in epoch 18, gen_loss = 0.8419724305470785, disc_loss = 0.00014777344767935574
Trained batch 3 in epoch 18, gen_loss = 0.8384011685848236, disc_loss = 0.00013659518663189374
Trained batch 4 in epoch 18, gen_loss = 0.8369325041770935, disc_loss = 0.0001471712428610772
Trained batch 5 in epoch 18, gen_loss = 0.8498943746089935, disc_loss = 0.00013783025254573053
Trained batch 6 in epoch 18, gen_loss = 0.8507459248815264, disc_loss = 0.00013821428832930645
Trained batch 7 in epoch 18, gen_loss = 0.8355780243873596, disc_loss = 0.00014374124111782294
Trained batch 8 in epoch 18, gen_loss = 0.8365214864412943, disc_loss = 0.00013858016043539264
Trained batch 9 in epoch 18, gen_loss = 0.830610853433609, disc_loss = 0.00013911807327531277
Trained batch 10 in epoch 18, gen_loss = 0.833305835723877, disc_loss = 0.0001341927365336398
Trained batch 11 in epoch 18, gen_loss = 0.8402979026238123, disc_loss = 0.00013941273815968694
Trained batch 12 in epoch 18, gen_loss = 0.8484696837571951, disc_loss = 0.00014299384425752438
Trained batch 13 in epoch 18, gen_loss = 0.8473593762942723, disc_loss = 0.0001474760179657356
Trained batch 14 in epoch 18, gen_loss = 0.8503451307614645, disc_loss = 0.0001542768489647036
Trained batch 15 in epoch 18, gen_loss = 0.8482630886137486, disc_loss = 0.0001554279551783111
Trained batch 16 in epoch 18, gen_loss = 0.8517380321727079, disc_loss = 0.00015192321349305157
Trained batch 17 in epoch 18, gen_loss = 0.8486856884426541, disc_loss = 0.0001560859612557882
Trained batch 18 in epoch 18, gen_loss = 0.849191028820841, disc_loss = 0.00015783298639641878
Trained batch 19 in epoch 18, gen_loss = 0.8459784418344498, disc_loss = 0.00016123683635669295
Trained batch 20 in epoch 18, gen_loss = 0.8442866887365069, disc_loss = 0.00016018614579003216
Trained batch 21 in epoch 18, gen_loss = 0.8497428108345378, disc_loss = 0.00016054430803209968
Trained batch 22 in epoch 18, gen_loss = 0.8497997962910196, disc_loss = 0.000160883653734345
Trained batch 23 in epoch 18, gen_loss = 0.8460020273923874, disc_loss = 0.0001627043175176368
Trained batch 24 in epoch 18, gen_loss = 0.8498355078697205, disc_loss = 0.0001594737861887552
Trained batch 25 in epoch 18, gen_loss = 0.8500947516698104, disc_loss = 0.00015869381408825016
Trained batch 26 in epoch 18, gen_loss = 0.8491683447802508, disc_loss = 0.0001565897597444106
Trained batch 27 in epoch 18, gen_loss = 0.8495676815509796, disc_loss = 0.00015621605806310463
Trained batch 28 in epoch 18, gen_loss = 0.8527821487393873, disc_loss = 0.00015583964328658926
Trained batch 29 in epoch 18, gen_loss = 0.8532219549020131, disc_loss = 0.00015477706450231683
Trained batch 30 in epoch 18, gen_loss = 0.850829210973555, disc_loss = 0.00015396470811420812
Trained batch 31 in epoch 18, gen_loss = 0.8502422776073217, disc_loss = 0.0001606715702564543
Trained batch 32 in epoch 18, gen_loss = 0.8513142972281484, disc_loss = 0.00016049867046989897
Trained batch 33 in epoch 18, gen_loss = 0.8509918503901538, disc_loss = 0.00016562993829104337
Trained batch 34 in epoch 18, gen_loss = 0.8512253471783229, disc_loss = 0.00016506206073764977
Trained batch 35 in epoch 18, gen_loss = 0.8521086308691237, disc_loss = 0.0001672416019573575
Trained batch 36 in epoch 18, gen_loss = 0.8551175884298376, disc_loss = 0.00016780088186056378
Trained batch 37 in epoch 18, gen_loss = 0.8591152774660211, disc_loss = 0.00016738523673235536
Trained batch 38 in epoch 18, gen_loss = 0.859143853187561, disc_loss = 0.0001664448102998834
Trained batch 39 in epoch 18, gen_loss = 0.8582683652639389, disc_loss = 0.00016688755949871846
Trained batch 40 in epoch 18, gen_loss = 0.8603378577930171, disc_loss = 0.00016538692686547774
Trained batch 41 in epoch 18, gen_loss = 0.8628946840763092, disc_loss = 0.00016543526068008284
Trained batch 42 in epoch 18, gen_loss = 0.8609571637109269, disc_loss = 0.0001656335411690782
Trained batch 43 in epoch 18, gen_loss = 0.8623323697935451, disc_loss = 0.0001670068969278046
Trained batch 44 in epoch 18, gen_loss = 0.8617364976141187, disc_loss = 0.0001663554398368837
Trained batch 45 in epoch 18, gen_loss = 0.8594631202842878, disc_loss = 0.0001690169342707478
Trained batch 46 in epoch 18, gen_loss = 0.8594648546360909, disc_loss = 0.0001678424107128794
Trained batch 47 in epoch 18, gen_loss = 0.8628666289150715, disc_loss = 0.00017120711102810068
Trained batch 48 in epoch 18, gen_loss = 0.8629476719973038, disc_loss = 0.00016941490009360547
Trained batch 49 in epoch 18, gen_loss = 0.865367339849472, disc_loss = 0.00016809268418001012
Trained batch 50 in epoch 18, gen_loss = 0.86509022175097, disc_loss = 0.00016661675423771763
Trained batch 51 in epoch 18, gen_loss = 0.8646547794342041, disc_loss = 0.00016875824034146857
Trained batch 52 in epoch 18, gen_loss = 0.8628947869786676, disc_loss = 0.0001682252602548479
Trained batch 53 in epoch 18, gen_loss = 0.8622760993463022, disc_loss = 0.0001673601765543464
Trained batch 54 in epoch 18, gen_loss = 0.8626604849641973, disc_loss = 0.00016767371985638006
Trained batch 55 in epoch 18, gen_loss = 0.8607378016625132, disc_loss = 0.00016811960735399874
Trained batch 56 in epoch 18, gen_loss = 0.8618247979565671, disc_loss = 0.00016707141657478357
Trained batch 57 in epoch 18, gen_loss = 0.8649611031186992, disc_loss = 0.00016861683239955614
Trained batch 58 in epoch 18, gen_loss = 0.864531542285014, disc_loss = 0.00016844743811939765
Trained batch 59 in epoch 18, gen_loss = 0.8646571318308512, disc_loss = 0.00016745189823268446
Trained batch 60 in epoch 18, gen_loss = 0.8643002822750905, disc_loss = 0.00016623522337720745
Trained batch 61 in epoch 18, gen_loss = 0.867082865007462, disc_loss = 0.00016530649982967355
Trained batch 62 in epoch 18, gen_loss = 0.8659721404787094, disc_loss = 0.00016449998067747358
Trained batch 63 in epoch 18, gen_loss = 0.8671120647341013, disc_loss = 0.00016356782464299613
Trained batch 64 in epoch 18, gen_loss = 0.8668941360253554, disc_loss = 0.00016286188082841152
Trained batch 65 in epoch 18, gen_loss = 0.8678736307404258, disc_loss = 0.00016266580055481896
Trained batch 66 in epoch 18, gen_loss = 0.865972825840338, disc_loss = 0.00016494332760600235
Trained batch 67 in epoch 18, gen_loss = 0.8634757268078187, disc_loss = 0.00017466376833480727
Trained batch 68 in epoch 18, gen_loss = 0.8626782678175664, disc_loss = 0.0001762279944555105
Trained batch 69 in epoch 18, gen_loss = 0.8627276718616486, disc_loss = 0.00017631078621239534
Trained batch 70 in epoch 18, gen_loss = 0.8622525191642869, disc_loss = 0.00017541361432424156
Trained batch 71 in epoch 18, gen_loss = 0.8631217728058497, disc_loss = 0.00017443160181250682
Trained batch 72 in epoch 18, gen_loss = 0.8630714049078014, disc_loss = 0.00017346482142273413
Trained batch 73 in epoch 18, gen_loss = 0.8630247389948046, disc_loss = 0.00017297520242061945
Trained batch 74 in epoch 18, gen_loss = 0.8640579684575399, disc_loss = 0.0001721210188892049
Trained batch 75 in epoch 18, gen_loss = 0.8636330726899599, disc_loss = 0.00017121181630691833
Trained batch 76 in epoch 18, gen_loss = 0.8639794193304978, disc_loss = 0.00017073318105593154
Trained batch 77 in epoch 18, gen_loss = 0.864476773983393, disc_loss = 0.0001706338969084661
Trained batch 78 in epoch 18, gen_loss = 0.8658286363263673, disc_loss = 0.0001695823994401807
Trained batch 79 in epoch 18, gen_loss = 0.8653179168701172, disc_loss = 0.00016963593088803464
Trained batch 80 in epoch 18, gen_loss = 0.8667020871315474, disc_loss = 0.0001686299928459684
Trained batch 81 in epoch 18, gen_loss = 0.8660806097635408, disc_loss = 0.00016824597013310712
Trained batch 82 in epoch 18, gen_loss = 0.8663191465010126, disc_loss = 0.00016726189072409375
Trained batch 83 in epoch 18, gen_loss = 0.8656020519279298, disc_loss = 0.00016645829635395093
Trained batch 84 in epoch 18, gen_loss = 0.8667368496165556, disc_loss = 0.00016592650893418228
Trained batch 85 in epoch 18, gen_loss = 0.8676566488521044, disc_loss = 0.00016544963677175516
Trained batch 86 in epoch 18, gen_loss = 0.8668818336793747, disc_loss = 0.0001646685102906335
Trained batch 87 in epoch 18, gen_loss = 0.8681565374135971, disc_loss = 0.00016395307300792246
Trained batch 88 in epoch 18, gen_loss = 0.8678059557850442, disc_loss = 0.00016410814959875027
Trained batch 89 in epoch 18, gen_loss = 0.8678014854590098, disc_loss = 0.00016461414294705417
Trained batch 90 in epoch 18, gen_loss = 0.869582644530705, disc_loss = 0.00016707408028925964
Trained batch 91 in epoch 18, gen_loss = 0.8687402573616608, disc_loss = 0.00016650471677522822
Trained batch 92 in epoch 18, gen_loss = 0.8690689001032101, disc_loss = 0.00016577498407118144
Trained batch 93 in epoch 18, gen_loss = 0.8696162706993996, disc_loss = 0.00016471620240716877
Trained batch 94 in epoch 18, gen_loss = 0.8704453963982431, disc_loss = 0.0001649616433975385
Trained batch 95 in epoch 18, gen_loss = 0.8713503467539946, disc_loss = 0.00016491911181522786
Trained batch 96 in epoch 18, gen_loss = 0.872489075070804, disc_loss = 0.00016450938132901187
Trained batch 97 in epoch 18, gen_loss = 0.8718839099212569, disc_loss = 0.0001642667010280408
Trained batch 98 in epoch 18, gen_loss = 0.87150700525804, disc_loss = 0.00016346530526678896
Trained batch 99 in epoch 18, gen_loss = 0.8714456677436828, disc_loss = 0.0001630104286596179
Trained batch 100 in epoch 18, gen_loss = 0.8712169651937957, disc_loss = 0.0001620357674039384
Trained batch 101 in epoch 18, gen_loss = 0.8698664623148301, disc_loss = 0.000161847698430339
Trained batch 102 in epoch 18, gen_loss = 0.8697046290323572, disc_loss = 0.00016185298018966737
Trained batch 103 in epoch 18, gen_loss = 0.8706312838655251, disc_loss = 0.00016116972458873462
Trained batch 104 in epoch 18, gen_loss = 0.8705481813067482, disc_loss = 0.00016081482248236646
Trained batch 105 in epoch 18, gen_loss = 0.8711704578039781, disc_loss = 0.00016017107774595783
Trained batch 106 in epoch 18, gen_loss = 0.8712744957932802, disc_loss = 0.00015963320466678887
Trained batch 107 in epoch 18, gen_loss = 0.8720830469219772, disc_loss = 0.0001589915384640874
Trained batch 108 in epoch 18, gen_loss = 0.8719329571505205, disc_loss = 0.0001582620553154319
Trained batch 109 in epoch 18, gen_loss = 0.8726124595512044, disc_loss = 0.0001577248058641668
Trained batch 110 in epoch 18, gen_loss = 0.8728591155361485, disc_loss = 0.00015703904828442646
Trained batch 111 in epoch 18, gen_loss = 0.8725527636706829, disc_loss = 0.0001562989028960666
Trained batch 112 in epoch 18, gen_loss = 0.8733065956461746, disc_loss = 0.00015583809566131868
Trained batch 113 in epoch 18, gen_loss = 0.8734564828245264, disc_loss = 0.00015517306721385307
Trained batch 114 in epoch 18, gen_loss = 0.8725264248640641, disc_loss = 0.0001551263554416516
Trained batch 115 in epoch 18, gen_loss = 0.8729246279288982, disc_loss = 0.00015462998817383777
Trained batch 116 in epoch 18, gen_loss = 0.8715017132270031, disc_loss = 0.0001564698736456971
Trained batch 117 in epoch 18, gen_loss = 0.8709593612258717, disc_loss = 0.00015621331402730055
Trained batch 118 in epoch 18, gen_loss = 0.8712174336449439, disc_loss = 0.00015616514997609634
Trained batch 119 in epoch 18, gen_loss = 0.8704227338234584, disc_loss = 0.00015696862095258742
Trained batch 120 in epoch 18, gen_loss = 0.8704848013633539, disc_loss = 0.00015633555557549938
Trained batch 121 in epoch 18, gen_loss = 0.8705528896363055, disc_loss = 0.00015704476909824555
Trained batch 122 in epoch 18, gen_loss = 0.8702752677405753, disc_loss = 0.00015632835437110208
Trained batch 123 in epoch 18, gen_loss = 0.8705729563390056, disc_loss = 0.0001562019969564825
Trained batch 124 in epoch 18, gen_loss = 0.8716191844940185, disc_loss = 0.00015614932152675464
Trained batch 125 in epoch 18, gen_loss = 0.8709641146281409, disc_loss = 0.00015581091504409127
Trained batch 126 in epoch 18, gen_loss = 0.8708304579802385, disc_loss = 0.00015581717218985546
Trained batch 127 in epoch 18, gen_loss = 0.8715988006442785, disc_loss = 0.00015524452959425616
Trained batch 128 in epoch 18, gen_loss = 0.8709093748137008, disc_loss = 0.00015476456097220684
Trained batch 129 in epoch 18, gen_loss = 0.8705298873094413, disc_loss = 0.00015423037900920742
Trained batch 130 in epoch 18, gen_loss = 0.8711566911398909, disc_loss = 0.0001538999872224384
Trained batch 131 in epoch 18, gen_loss = 0.8710749916958086, disc_loss = 0.00015419186572464903
Trained batch 132 in epoch 18, gen_loss = 0.8719748151033444, disc_loss = 0.0001540388219925939
Trained batch 133 in epoch 18, gen_loss = 0.8720926704691417, disc_loss = 0.0001533343089086789
Trained batch 134 in epoch 18, gen_loss = 0.8721090184317695, disc_loss = 0.0001528130277249686
Trained batch 135 in epoch 18, gen_loss = 0.872608589775422, disc_loss = 0.00015286400326551623
Trained batch 136 in epoch 18, gen_loss = 0.872546592333021, disc_loss = 0.00015237051390288193
Trained batch 137 in epoch 18, gen_loss = 0.8725917430027671, disc_loss = 0.00015184461833838293
Trained batch 138 in epoch 18, gen_loss = 0.8723299970729745, disc_loss = 0.00015145319854428576
Trained batch 139 in epoch 18, gen_loss = 0.8727970093488693, disc_loss = 0.00015120851977761568
Trained batch 140 in epoch 18, gen_loss = 0.8719614448276818, disc_loss = 0.00015136091544702384
Trained batch 141 in epoch 18, gen_loss = 0.8714360670304634, disc_loss = 0.00015201729219767567
Trained batch 142 in epoch 18, gen_loss = 0.8715236307857753, disc_loss = 0.0001514659404031724
Trained batch 143 in epoch 18, gen_loss = 0.8710473643408881, disc_loss = 0.00015088347208802588
Trained batch 144 in epoch 18, gen_loss = 0.8714708348800396, disc_loss = 0.00015046874142516853
Trained batch 145 in epoch 18, gen_loss = 0.8714729220899817, disc_loss = 0.000150022359713609
Trained batch 146 in epoch 18, gen_loss = 0.8725146071440508, disc_loss = 0.00015004699055674062
Trained batch 147 in epoch 18, gen_loss = 0.8727229825548224, disc_loss = 0.00014980161344086614
Trained batch 148 in epoch 18, gen_loss = 0.8724576762858653, disc_loss = 0.00014964826404071732
Trained batch 149 in epoch 18, gen_loss = 0.872438119649887, disc_loss = 0.00014926350107998586
Trained batch 150 in epoch 18, gen_loss = 0.872009562735526, disc_loss = 0.00014894065405326952
Trained batch 151 in epoch 18, gen_loss = 0.8725461826512688, disc_loss = 0.00014835899231145863
Trained batch 152 in epoch 18, gen_loss = 0.8727303178481807, disc_loss = 0.00014820117790162948
Trained batch 153 in epoch 18, gen_loss = 0.872102083710881, disc_loss = 0.00014781100458980315
Trained batch 154 in epoch 18, gen_loss = 0.8720255970954895, disc_loss = 0.00014738493419211028
Trained batch 155 in epoch 18, gen_loss = 0.871480540969433, disc_loss = 0.00014719627910007825
Trained batch 156 in epoch 18, gen_loss = 0.8715059320638134, disc_loss = 0.00014687882834851925
Trained batch 157 in epoch 18, gen_loss = 0.8715967079506645, disc_loss = 0.00014661626066092277
Trained batch 158 in epoch 18, gen_loss = 0.8712876244161114, disc_loss = 0.00014685571968241348
Trained batch 159 in epoch 18, gen_loss = 0.8715248260647058, disc_loss = 0.000146853965156879
Trained batch 160 in epoch 18, gen_loss = 0.8716353944369725, disc_loss = 0.00014667787702746186
Trained batch 161 in epoch 18, gen_loss = 0.870954234658936, disc_loss = 0.00014622196777278908
Trained batch 162 in epoch 18, gen_loss = 0.871316296556976, disc_loss = 0.00014640927331988483
Trained batch 163 in epoch 18, gen_loss = 0.8712332495828954, disc_loss = 0.0001460787160373534
Trained batch 164 in epoch 18, gen_loss = 0.8711890975634257, disc_loss = 0.00014559390170192768
Trained batch 165 in epoch 18, gen_loss = 0.870889944843499, disc_loss = 0.00014573039544598306
Trained batch 166 in epoch 18, gen_loss = 0.871124945714802, disc_loss = 0.0001456169084993311
Trained batch 167 in epoch 18, gen_loss = 0.8716948124624434, disc_loss = 0.00014569821700033137
Trained batch 168 in epoch 18, gen_loss = 0.8720804396465686, disc_loss = 0.00014529934704641967
Trained batch 169 in epoch 18, gen_loss = 0.871855494555305, disc_loss = 0.00014481947447861517
Trained batch 170 in epoch 18, gen_loss = 0.87259504669591, disc_loss = 0.00014481348398210324
Trained batch 171 in epoch 18, gen_loss = 0.8726603042247684, disc_loss = 0.000145216676871716
Trained batch 172 in epoch 18, gen_loss = 0.8731991614220459, disc_loss = 0.00014531620767797246
Trained batch 173 in epoch 18, gen_loss = 0.8732334159571549, disc_loss = 0.00014495740605912293
Trained batch 174 in epoch 18, gen_loss = 0.8735635450908116, disc_loss = 0.0001446242905928687
Trained batch 175 in epoch 18, gen_loss = 0.8734914511442184, disc_loss = 0.0001443419859531952
Trained batch 176 in epoch 18, gen_loss = 0.873581182148497, disc_loss = 0.00014416862621270042
Trained batch 177 in epoch 18, gen_loss = 0.8734911114312289, disc_loss = 0.00014385230644436663
Trained batch 178 in epoch 18, gen_loss = 0.8742293635560148, disc_loss = 0.00014340616112679645
Trained batch 179 in epoch 18, gen_loss = 0.8744605223337809, disc_loss = 0.0001433021912210582
Trained batch 180 in epoch 18, gen_loss = 0.8739548006110428, disc_loss = 0.00014287065372507098
Trained batch 181 in epoch 18, gen_loss = 0.8738256846810435, disc_loss = 0.0001424725205552122
Trained batch 182 in epoch 18, gen_loss = 0.8738723833704255, disc_loss = 0.00014201892272119483
Trained batch 183 in epoch 18, gen_loss = 0.8736380303035611, disc_loss = 0.00014176109599524668
Trained batch 184 in epoch 18, gen_loss = 0.8732927712234291, disc_loss = 0.00014150026932789793
Trained batch 185 in epoch 18, gen_loss = 0.873366690451099, disc_loss = 0.0001411831015756952
Trained batch 186 in epoch 18, gen_loss = 0.8734017846418575, disc_loss = 0.00014087387677272757
Trained batch 187 in epoch 18, gen_loss = 0.8731764634238913, disc_loss = 0.00014061439951353562
Trained batch 188 in epoch 18, gen_loss = 0.8724050039336795, disc_loss = 0.00014034174443897053
Trained batch 189 in epoch 18, gen_loss = 0.8725979020721034, disc_loss = 0.0001399768139028885
Trained batch 190 in epoch 18, gen_loss = 0.8729568295453856, disc_loss = 0.00014017363423947854
Trained batch 191 in epoch 18, gen_loss = 0.8728819101427993, disc_loss = 0.00014031232181347755
Trained batch 192 in epoch 18, gen_loss = 0.8723977912275285, disc_loss = 0.00014032796992262262
Trained batch 193 in epoch 18, gen_loss = 0.8722357476494976, disc_loss = 0.00014028998397332113
Trained batch 194 in epoch 18, gen_loss = 0.8723495553701351, disc_loss = 0.0001398898873258776
Trained batch 195 in epoch 18, gen_loss = 0.8725000312741922, disc_loss = 0.00013966370758624887
Trained batch 196 in epoch 18, gen_loss = 0.872732530087989, disc_loss = 0.00013920831800066761
Trained batch 197 in epoch 18, gen_loss = 0.8724487086739203, disc_loss = 0.0001391159262908846
Trained batch 198 in epoch 18, gen_loss = 0.8721608456654765, disc_loss = 0.0001388316378695013
Trained batch 199 in epoch 18, gen_loss = 0.8722209200263024, disc_loss = 0.00013878060797651415
Trained batch 200 in epoch 18, gen_loss = 0.8722653697379192, disc_loss = 0.00013877804982502
Trained batch 201 in epoch 18, gen_loss = 0.8721938915181868, disc_loss = 0.00013864572011329127
Trained batch 202 in epoch 18, gen_loss = 0.8722707593969523, disc_loss = 0.00013902702421053734
Trained batch 203 in epoch 18, gen_loss = 0.8723467199825773, disc_loss = 0.00013894827621055918
Trained batch 204 in epoch 18, gen_loss = 0.8729398166261069, disc_loss = 0.0001388089216872198
Trained batch 205 in epoch 18, gen_loss = 0.8733883381468578, disc_loss = 0.0001384292180888418
Trained batch 206 in epoch 18, gen_loss = 0.8735964050615467, disc_loss = 0.00013823590500354496
Trained batch 207 in epoch 18, gen_loss = 0.8737229739244168, disc_loss = 0.0001379626636872462
Trained batch 208 in epoch 18, gen_loss = 0.8735422882737155, disc_loss = 0.00013764275949638844
Trained batch 209 in epoch 18, gen_loss = 0.8733215769131978, disc_loss = 0.000137422630567536
Trained batch 210 in epoch 18, gen_loss = 0.8732907664719352, disc_loss = 0.00013790784326577293
Trained batch 211 in epoch 18, gen_loss = 0.873310811114761, disc_loss = 0.00013761518064986272
Trained batch 212 in epoch 18, gen_loss = 0.8733024613958009, disc_loss = 0.0001374867287280799
Trained batch 213 in epoch 18, gen_loss = 0.8730862087735506, disc_loss = 0.00013746968958750977
Trained batch 214 in epoch 18, gen_loss = 0.8731571250183637, disc_loss = 0.0001373223724861651
Trained batch 215 in epoch 18, gen_loss = 0.8727838626062429, disc_loss = 0.00013784666063859023
Trained batch 216 in epoch 18, gen_loss = 0.872666755030232, disc_loss = 0.00013783065524930777
Trained batch 217 in epoch 18, gen_loss = 0.8729001978121766, disc_loss = 0.0001374732283034272
Trained batch 218 in epoch 18, gen_loss = 0.8726219382460259, disc_loss = 0.00013729778328271515
Trained batch 219 in epoch 18, gen_loss = 0.873100253126838, disc_loss = 0.0001370545948289377
Trained batch 220 in epoch 18, gen_loss = 0.8728805548465091, disc_loss = 0.00013669492224888767
Trained batch 221 in epoch 18, gen_loss = 0.8728870819280813, disc_loss = 0.0001367248214837919
Trained batch 222 in epoch 18, gen_loss = 0.8728446444588391, disc_loss = 0.00013680174185125985
Trained batch 223 in epoch 18, gen_loss = 0.872422568500042, disc_loss = 0.0001368192889848225
Trained batch 224 in epoch 18, gen_loss = 0.8728000900480483, disc_loss = 0.00013668386718361741
Trained batch 225 in epoch 18, gen_loss = 0.8729084323992772, disc_loss = 0.0001364634783095804
Trained batch 226 in epoch 18, gen_loss = 0.8722968970626461, disc_loss = 0.00013625258023415728
Trained batch 227 in epoch 18, gen_loss = 0.8721774233537808, disc_loss = 0.00013601534744354962
Trained batch 228 in epoch 18, gen_loss = 0.872454901449545, disc_loss = 0.00013584087036095567
Trained batch 229 in epoch 18, gen_loss = 0.8726583657057388, disc_loss = 0.00013583126821448905
Trained batch 230 in epoch 18, gen_loss = 0.8728166029050752, disc_loss = 0.00013573267189075252
Trained batch 231 in epoch 18, gen_loss = 0.87228597315221, disc_loss = 0.00013608652038940285
Trained batch 232 in epoch 18, gen_loss = 0.8721249784011186, disc_loss = 0.00013604255271610873
Trained batch 233 in epoch 18, gen_loss = 0.8722100780050979, disc_loss = 0.00013573278752469027
Trained batch 234 in epoch 18, gen_loss = 0.8722183453275802, disc_loss = 0.00013578874322194408
Trained batch 235 in epoch 18, gen_loss = 0.8722274778252941, disc_loss = 0.0001356135384474143
Trained batch 236 in epoch 18, gen_loss = 0.8722724009163773, disc_loss = 0.00013543712699742603
Trained batch 237 in epoch 18, gen_loss = 0.8722838321152855, disc_loss = 0.00013526560296133326
Trained batch 238 in epoch 18, gen_loss = 0.8720721772026317, disc_loss = 0.00013509473656732823
Trained batch 239 in epoch 18, gen_loss = 0.8717598972221215, disc_loss = 0.00013483901423872642
Trained batch 240 in epoch 18, gen_loss = 0.8720255071196813, disc_loss = 0.00013461563083719022
Trained batch 241 in epoch 18, gen_loss = 0.87181184828774, disc_loss = 0.0001344200594878413
Trained batch 242 in epoch 18, gen_loss = 0.8717905182406736, disc_loss = 0.0001342649065095111
Trained batch 243 in epoch 18, gen_loss = 0.871846472386454, disc_loss = 0.00013402323974496839
Trained batch 244 in epoch 18, gen_loss = 0.8721198147656967, disc_loss = 0.00013391279546562962
Trained batch 245 in epoch 18, gen_loss = 0.8725701076228444, disc_loss = 0.00013376953924070984
Trained batch 246 in epoch 18, gen_loss = 0.8723499543271084, disc_loss = 0.00013379593218840763
Trained batch 247 in epoch 18, gen_loss = 0.8720332598013263, disc_loss = 0.0001338793899776647
Trained batch 248 in epoch 18, gen_loss = 0.871972287515081, disc_loss = 0.00013357238665147848
Trained batch 249 in epoch 18, gen_loss = 0.8722502784729004, disc_loss = 0.0001333772106881952
Trained batch 250 in epoch 18, gen_loss = 0.8719018507763684, disc_loss = 0.00013333932798718977
Trained batch 251 in epoch 18, gen_loss = 0.8720074693361918, disc_loss = 0.00013308035986050353
Trained batch 252 in epoch 18, gen_loss = 0.8721664248719045, disc_loss = 0.000132806982278291
Trained batch 253 in epoch 18, gen_loss = 0.8722277025538167, disc_loss = 0.00013269151011942502
Trained batch 254 in epoch 18, gen_loss = 0.8725177619971481, disc_loss = 0.00013247611271913676
Trained batch 255 in epoch 18, gen_loss = 0.8728868281468749, disc_loss = 0.00013217781985019883
Trained batch 256 in epoch 18, gen_loss = 0.8730198815175068, disc_loss = 0.00013206950693759535
Trained batch 257 in epoch 18, gen_loss = 0.8733049476331518, disc_loss = 0.00013197491563012365
Trained batch 258 in epoch 18, gen_loss = 0.8727744539271911, disc_loss = 0.00013173903868379498
Trained batch 259 in epoch 18, gen_loss = 0.8733970488493259, disc_loss = 0.00013169203690407673
Trained batch 260 in epoch 18, gen_loss = 0.8735174998012996, disc_loss = 0.00013159039953352893
Trained batch 261 in epoch 18, gen_loss = 0.8731773352349987, disc_loss = 0.00013152999634410606
Trained batch 262 in epoch 18, gen_loss = 0.8728719217695664, disc_loss = 0.0001312212657864859
Trained batch 263 in epoch 18, gen_loss = 0.8728173607678125, disc_loss = 0.00013116356933206782
Trained batch 264 in epoch 18, gen_loss = 0.872578863377841, disc_loss = 0.00013099933543653263
Trained batch 265 in epoch 18, gen_loss = 0.8721770229644346, disc_loss = 0.00013086959869608274
Trained batch 266 in epoch 18, gen_loss = 0.8723740624577812, disc_loss = 0.00013081891958879513
Trained batch 267 in epoch 18, gen_loss = 0.8727720368709138, disc_loss = 0.00013070532062176506
Trained batch 268 in epoch 18, gen_loss = 0.8724678384770248, disc_loss = 0.00013052950626237883
Trained batch 269 in epoch 18, gen_loss = 0.872364788585239, disc_loss = 0.000130285948438945
Trained batch 270 in epoch 18, gen_loss = 0.8721095838230034, disc_loss = 0.00013009645693196152
Trained batch 271 in epoch 18, gen_loss = 0.8723150960662786, disc_loss = 0.00012992766704990252
Trained batch 272 in epoch 18, gen_loss = 0.8723813114148793, disc_loss = 0.00012979620391272278
Trained batch 273 in epoch 18, gen_loss = 0.8725540287738299, disc_loss = 0.00012962161607683013
Trained batch 274 in epoch 18, gen_loss = 0.873051225272092, disc_loss = 0.00012952672252801925
Trained batch 275 in epoch 18, gen_loss = 0.8731571934793306, disc_loss = 0.00012936951074864382
Trained batch 276 in epoch 18, gen_loss = 0.8728790885704949, disc_loss = 0.00013003776657963693
Trained batch 277 in epoch 18, gen_loss = 0.8728319846040054, disc_loss = 0.00013011631078939807
Trained batch 278 in epoch 18, gen_loss = 0.8730190648400228, disc_loss = 0.00013012271645943313
Trained batch 279 in epoch 18, gen_loss = 0.8735000569905553, disc_loss = 0.0001301204154385362
Trained batch 280 in epoch 18, gen_loss = 0.8734693236622522, disc_loss = 0.00013014713871747246
Trained batch 281 in epoch 18, gen_loss = 0.8732556512592532, disc_loss = 0.00012999948382541514
Trained batch 282 in epoch 18, gen_loss = 0.8730938927444889, disc_loss = 0.00012994254362066408
Trained batch 283 in epoch 18, gen_loss = 0.8727383195934161, disc_loss = 0.00012991754206716867
Trained batch 284 in epoch 18, gen_loss = 0.8724794804004201, disc_loss = 0.00012970206065036013
Trained batch 285 in epoch 18, gen_loss = 0.872323287950529, disc_loss = 0.0001295106486376445
Trained batch 286 in epoch 18, gen_loss = 0.8730186817953396, disc_loss = 0.0001295666975444402
Trained batch 287 in epoch 18, gen_loss = 0.8726605230735408, disc_loss = 0.00012934962406537429
Trained batch 288 in epoch 18, gen_loss = 0.8727395540702714, disc_loss = 0.00012916753673150564
Trained batch 289 in epoch 18, gen_loss = 0.8725320415250186, disc_loss = 0.0001291472277004906
Trained batch 290 in epoch 18, gen_loss = 0.8726082362260196, disc_loss = 0.00012902821644152917
Trained batch 291 in epoch 18, gen_loss = 0.8721641326603824, disc_loss = 0.00012931411923975796
Trained batch 292 in epoch 18, gen_loss = 0.8721591366435888, disc_loss = 0.0001292197299993449
Trained batch 293 in epoch 18, gen_loss = 0.8720083828686046, disc_loss = 0.0001292411023957796
Trained batch 294 in epoch 18, gen_loss = 0.8719142445063187, disc_loss = 0.00012900932300816118
Trained batch 295 in epoch 18, gen_loss = 0.8717060948948603, disc_loss = 0.00012890852969969666
Trained batch 296 in epoch 18, gen_loss = 0.8717438331758133, disc_loss = 0.00012879342906218594
Trained batch 297 in epoch 18, gen_loss = 0.8716342739210833, disc_loss = 0.00012860014383159985
Trained batch 298 in epoch 18, gen_loss = 0.8714348299048816, disc_loss = 0.00012838614645221716
Trained batch 299 in epoch 18, gen_loss = 0.8714444214105606, disc_loss = 0.00012818705188692549
Trained batch 300 in epoch 18, gen_loss = 0.871362145754982, disc_loss = 0.0001279463354525995
Trained batch 301 in epoch 18, gen_loss = 0.8711163741073861, disc_loss = 0.00012779793580542997
Trained batch 302 in epoch 18, gen_loss = 0.8714816499464583, disc_loss = 0.00012767055327293276
Trained batch 303 in epoch 18, gen_loss = 0.8713911654133546, disc_loss = 0.0001275048706654496
Trained batch 304 in epoch 18, gen_loss = 0.871407172328136, disc_loss = 0.00012739196831940627
Trained batch 305 in epoch 18, gen_loss = 0.8713146346846438, disc_loss = 0.00012750220319539236
Trained batch 306 in epoch 18, gen_loss = 0.8715026332035127, disc_loss = 0.00012728290920134813
Trained batch 307 in epoch 18, gen_loss = 0.8717038314063827, disc_loss = 0.00012708835579183138
Trained batch 308 in epoch 18, gen_loss = 0.8716510794695141, disc_loss = 0.0001269987047711895
Trained batch 309 in epoch 18, gen_loss = 0.8715113614836046, disc_loss = 0.00012713722639854231
Trained batch 310 in epoch 18, gen_loss = 0.8713700508764702, disc_loss = 0.00012689751045669092
Trained batch 311 in epoch 18, gen_loss = 0.8717883991507384, disc_loss = 0.0001267084429015925
Trained batch 312 in epoch 18, gen_loss = 0.8714501541643478, disc_loss = 0.0001264896930540174
Trained batch 313 in epoch 18, gen_loss = 0.8711243338265996, disc_loss = 0.000126338986351613
Trained batch 314 in epoch 18, gen_loss = 0.8712457838512603, disc_loss = 0.0001263919662700833
Trained batch 315 in epoch 18, gen_loss = 0.8707855502261391, disc_loss = 0.0001268161149134438
Trained batch 316 in epoch 18, gen_loss = 0.8709199693676801, disc_loss = 0.0001270239961809884
Trained batch 317 in epoch 18, gen_loss = 0.870671678639058, disc_loss = 0.00012708948407583553
Trained batch 318 in epoch 18, gen_loss = 0.8708264534376258, disc_loss = 0.00012702240874033953
Trained batch 319 in epoch 18, gen_loss = 0.8714281911030411, disc_loss = 0.0001272663829013254
Trained batch 320 in epoch 18, gen_loss = 0.8715304399947883, disc_loss = 0.00012789860063952733
Trained batch 321 in epoch 18, gen_loss = 0.8717320864985448, disc_loss = 0.00012787316041591474
Trained batch 322 in epoch 18, gen_loss = 0.8715649933637849, disc_loss = 0.00012770209514342059
Trained batch 323 in epoch 18, gen_loss = 0.871769811268206, disc_loss = 0.0001276296404318634
Trained batch 324 in epoch 18, gen_loss = 0.8717408558038565, disc_loss = 0.00012741964243244953
Trained batch 325 in epoch 18, gen_loss = 0.8717393015791302, disc_loss = 0.00012720447214917735
Trained batch 326 in epoch 18, gen_loss = 0.8716867431223575, disc_loss = 0.00012703090051941314
Trained batch 327 in epoch 18, gen_loss = 0.8714827620765058, disc_loss = 0.000126979374804583
Trained batch 328 in epoch 18, gen_loss = 0.8713480080152355, disc_loss = 0.0001268030939565152
Trained batch 329 in epoch 18, gen_loss = 0.8713423564578547, disc_loss = 0.00012677826965624593
Trained batch 330 in epoch 18, gen_loss = 0.87136984519728, disc_loss = 0.00012686986018654896
Trained batch 331 in epoch 18, gen_loss = 0.8711557325469442, disc_loss = 0.00012670201899216255
Trained batch 332 in epoch 18, gen_loss = 0.8711122147313826, disc_loss = 0.00012667763107706228
Trained batch 333 in epoch 18, gen_loss = 0.8710050575747461, disc_loss = 0.0001265663099049104
Trained batch 334 in epoch 18, gen_loss = 0.8709801435470581, disc_loss = 0.00012661605206128808
Trained batch 335 in epoch 18, gen_loss = 0.8710814918435755, disc_loss = 0.00012644356436231603
Trained batch 336 in epoch 18, gen_loss = 0.870863904761985, disc_loss = 0.0001264303258079752
Trained batch 337 in epoch 18, gen_loss = 0.8707650354980717, disc_loss = 0.000126325935692359
Trained batch 338 in epoch 18, gen_loss = 0.870546429382313, disc_loss = 0.00012635170502231353
Trained batch 339 in epoch 18, gen_loss = 0.8701975354376961, disc_loss = 0.00012622944969360318
Trained batch 340 in epoch 18, gen_loss = 0.8699108026594011, disc_loss = 0.00012629242954067982
Trained batch 341 in epoch 18, gen_loss = 0.8699120433009856, disc_loss = 0.00012612334212888378
Trained batch 342 in epoch 18, gen_loss = 0.8701315190284662, disc_loss = 0.00012601796568311282
Trained batch 343 in epoch 18, gen_loss = 0.8704426162118135, disc_loss = 0.00012598937702171307
Trained batch 344 in epoch 18, gen_loss = 0.870395629129548, disc_loss = 0.00012617535952207012
Trained batch 345 in epoch 18, gen_loss = 0.8704806028762994, disc_loss = 0.00012633050229819963
Trained batch 346 in epoch 18, gen_loss = 0.8704884069453742, disc_loss = 0.00012627323728210094
Trained batch 347 in epoch 18, gen_loss = 0.8705708617451547, disc_loss = 0.0001260840371883362
Trained batch 348 in epoch 18, gen_loss = 0.8706944808577398, disc_loss = 0.00012588617091672895
Trained batch 349 in epoch 18, gen_loss = 0.8704332865987505, disc_loss = 0.00012578719229038273
Trained batch 350 in epoch 18, gen_loss = 0.8705058471429722, disc_loss = 0.0001256217142935853
Trained batch 351 in epoch 18, gen_loss = 0.8706130280413411, disc_loss = 0.00012543849611161434
Trained batch 352 in epoch 18, gen_loss = 0.8706114185768213, disc_loss = 0.0001252212772690348
Trained batch 353 in epoch 18, gen_loss = 0.8705020720339091, disc_loss = 0.00012507432456194728
Trained batch 354 in epoch 18, gen_loss = 0.8705314302108658, disc_loss = 0.0001248969544589349
Trained batch 355 in epoch 18, gen_loss = 0.8704552652125948, disc_loss = 0.0001248487987641567
Trained batch 356 in epoch 18, gen_loss = 0.8708082544369524, disc_loss = 0.00012473128095653342
Trained batch 357 in epoch 18, gen_loss = 0.8711624250398667, disc_loss = 0.00012458468173671508
Trained batch 358 in epoch 18, gen_loss = 0.8709691605196026, disc_loss = 0.0001244492386248868
Trained batch 359 in epoch 18, gen_loss = 0.8709707193904452, disc_loss = 0.00012431854320311687
Trained batch 360 in epoch 18, gen_loss = 0.8708357713559328, disc_loss = 0.000124226931550758
Trained batch 361 in epoch 18, gen_loss = 0.8709548677199453, disc_loss = 0.0001241353652629749
Trained batch 362 in epoch 18, gen_loss = 0.8710827750279555, disc_loss = 0.00012414980050851141
Trained batch 363 in epoch 18, gen_loss = 0.8709842208977584, disc_loss = 0.00012410679918612805
Trained batch 364 in epoch 18, gen_loss = 0.8708765240564739, disc_loss = 0.00012392372869502127
Trained batch 365 in epoch 18, gen_loss = 0.8710686570959665, disc_loss = 0.0001238020191482323
Trained batch 366 in epoch 18, gen_loss = 0.8710901209379087, disc_loss = 0.00012375647121840868
Trained batch 367 in epoch 18, gen_loss = 0.8713748552229094, disc_loss = 0.00012375108910774819
Trained batch 368 in epoch 18, gen_loss = 0.8716277308903413, disc_loss = 0.00012384711739001102
Trained batch 369 in epoch 18, gen_loss = 0.8716310847449947, disc_loss = 0.00012370836560188076
Trained batch 370 in epoch 18, gen_loss = 0.871866903054425, disc_loss = 0.00012361496508899998
Trained batch 371 in epoch 18, gen_loss = 0.8723120642926103, disc_loss = 0.00012350491827526892
Trained batch 372 in epoch 18, gen_loss = 0.872784293528856, disc_loss = 0.00012346698290079485
Trained batch 373 in epoch 18, gen_loss = 0.8731505199868411, disc_loss = 0.00012350889115370523
Trained batch 374 in epoch 18, gen_loss = 0.8732385452588399, disc_loss = 0.00012342715827010883
Trained batch 375 in epoch 18, gen_loss = 0.8731565031599491, disc_loss = 0.0001234039410093751
Trained batch 376 in epoch 18, gen_loss = 0.8730979656667228, disc_loss = 0.00012325368062489597
Trained batch 377 in epoch 18, gen_loss = 0.8734644662450861, disc_loss = 0.00012338747391940733
Trained batch 378 in epoch 18, gen_loss = 0.8736181974725548, disc_loss = 0.00012327638777987455
Trained batch 379 in epoch 18, gen_loss = 0.8735683645072736, disc_loss = 0.00012316896252167155
Trained batch 380 in epoch 18, gen_loss = 0.8735217358183673, disc_loss = 0.00012308239645675726
Trained batch 381 in epoch 18, gen_loss = 0.8737811773859393, disc_loss = 0.00012298009884005828
Trained batch 382 in epoch 18, gen_loss = 0.8737891433133158, disc_loss = 0.0001228560157971762
Trained batch 383 in epoch 18, gen_loss = 0.8737664480383197, disc_loss = 0.00012276399349768022
Trained batch 384 in epoch 18, gen_loss = 0.8739701481608602, disc_loss = 0.00012271026834088087
Trained batch 385 in epoch 18, gen_loss = 0.8739946405813483, disc_loss = 0.0001227199287606021
Trained batch 386 in epoch 18, gen_loss = 0.8741294151744793, disc_loss = 0.0001226936650056499
Trained batch 387 in epoch 18, gen_loss = 0.87389288089939, disc_loss = 0.00012275708047230547
Trained batch 388 in epoch 18, gen_loss = 0.8740355721782596, disc_loss = 0.00012258610666901888
Trained batch 389 in epoch 18, gen_loss = 0.8736113297633635, disc_loss = 0.00012269801201257043
Trained batch 390 in epoch 18, gen_loss = 0.8732268014527342, disc_loss = 0.00012262595287548578
Trained batch 391 in epoch 18, gen_loss = 0.8731874321796456, disc_loss = 0.00012256494156478155
Trained batch 392 in epoch 18, gen_loss = 0.8731979350097306, disc_loss = 0.00012247800452971794
Trained batch 393 in epoch 18, gen_loss = 0.8732971411368569, disc_loss = 0.0001224651096535251
Trained batch 394 in epoch 18, gen_loss = 0.8732233420203004, disc_loss = 0.00012253438552865123
Trained batch 395 in epoch 18, gen_loss = 0.8729058454434077, disc_loss = 0.00012241850731008913
Trained batch 396 in epoch 18, gen_loss = 0.8729755662250278, disc_loss = 0.00012221889683728396
Trained batch 397 in epoch 18, gen_loss = 0.872574194591848, disc_loss = 0.00012225196384756074
Trained batch 398 in epoch 18, gen_loss = 0.8724715173393861, disc_loss = 0.00012232558377430527
Trained batch 399 in epoch 18, gen_loss = 0.8724135053157807, disc_loss = 0.00012228733269694202
Trained batch 400 in epoch 18, gen_loss = 0.8723763325565176, disc_loss = 0.00012217676229105782
Trained batch 401 in epoch 18, gen_loss = 0.872338892808601, disc_loss = 0.00012200353851210876
Trained batch 402 in epoch 18, gen_loss = 0.8724998283031264, disc_loss = 0.00012191062876439038
Trained batch 403 in epoch 18, gen_loss = 0.8725596825675209, disc_loss = 0.00012195663426195601
Trained batch 404 in epoch 18, gen_loss = 0.8724261417800998, disc_loss = 0.00012200176114910627
Trained batch 405 in epoch 18, gen_loss = 0.8724207455301519, disc_loss = 0.00012189046612341734
Trained batch 406 in epoch 18, gen_loss = 0.872338406723313, disc_loss = 0.00012195709540847065
Trained batch 407 in epoch 18, gen_loss = 0.8721915727444723, disc_loss = 0.00012209283536054392
Trained batch 408 in epoch 18, gen_loss = 0.8721170266566475, disc_loss = 0.0001220983495131849
Trained batch 409 in epoch 18, gen_loss = 0.8722050313542529, disc_loss = 0.00012201709839090898
Trained batch 410 in epoch 18, gen_loss = 0.8726037991597995, disc_loss = 0.00012216959700449777
Trained batch 411 in epoch 18, gen_loss = 0.8727550929032483, disc_loss = 0.00012218623059312645
Trained batch 412 in epoch 18, gen_loss = 0.8727764557983916, disc_loss = 0.0001220777122105543
Trained batch 413 in epoch 18, gen_loss = 0.8727456535694104, disc_loss = 0.00012212545867872386
Trained batch 414 in epoch 18, gen_loss = 0.8727473250354629, disc_loss = 0.0001221301170582855
Trained batch 415 in epoch 18, gen_loss = 0.8727614502780713, disc_loss = 0.00012211020504519882
Trained batch 416 in epoch 18, gen_loss = 0.8724768915050607, disc_loss = 0.00012247136077985705
Trained batch 417 in epoch 18, gen_loss = 0.8726133888132834, disc_loss = 0.00012233523959462458
Trained batch 418 in epoch 18, gen_loss = 0.8726517804198163, disc_loss = 0.0001222340193843699
Trained batch 419 in epoch 18, gen_loss = 0.8725299393846875, disc_loss = 0.00012220674806095693
Trained batch 420 in epoch 18, gen_loss = 0.8726201847443388, disc_loss = 0.00012208190692856636
Trained batch 421 in epoch 18, gen_loss = 0.8726719349481483, disc_loss = 0.0001220819441096386
Trained batch 422 in epoch 18, gen_loss = 0.8724566428937529, disc_loss = 0.00012207469989384092
Trained batch 423 in epoch 18, gen_loss = 0.8721690102005905, disc_loss = 0.00012199329622266957
Trained batch 424 in epoch 18, gen_loss = 0.8722735550824333, disc_loss = 0.00012199164553963141
Trained batch 425 in epoch 18, gen_loss = 0.8724260754148725, disc_loss = 0.0001219571317085464
Trained batch 426 in epoch 18, gen_loss = 0.8724887079321528, disc_loss = 0.00012184508665486901
Trained batch 427 in epoch 18, gen_loss = 0.8727199918477335, disc_loss = 0.00012178307385179791
Trained batch 428 in epoch 18, gen_loss = 0.8727167973985205, disc_loss = 0.0001217051659128493
Trained batch 429 in epoch 18, gen_loss = 0.872674034501231, disc_loss = 0.00012170094784334312
Trained batch 430 in epoch 18, gen_loss = 0.8725334578766347, disc_loss = 0.00012166298961294156
Trained batch 431 in epoch 18, gen_loss = 0.872574392568182, disc_loss = 0.00012150193019469616
Trained batch 432 in epoch 18, gen_loss = 0.8725085401645158, disc_loss = 0.00012152338153033358
Trained batch 433 in epoch 18, gen_loss = 0.8728149612927767, disc_loss = 0.00012143471418974614
Trained batch 434 in epoch 18, gen_loss = 0.8727367994429052, disc_loss = 0.00012141523459403048
Trained batch 435 in epoch 18, gen_loss = 0.8727307993611064, disc_loss = 0.00012140076437014755
Trained batch 436 in epoch 18, gen_loss = 0.8728078175463992, disc_loss = 0.0001213725700509469
Trained batch 437 in epoch 18, gen_loss = 0.8730130191535166, disc_loss = 0.00012125667795007591
Trained batch 438 in epoch 18, gen_loss = 0.8728155269709698, disc_loss = 0.00012120186015750082
Trained batch 439 in epoch 18, gen_loss = 0.8728791253133253, disc_loss = 0.00012101379204316551
Trained batch 440 in epoch 18, gen_loss = 0.872845569570589, disc_loss = 0.00012084010056557362
Trained batch 441 in epoch 18, gen_loss = 0.8729174543020413, disc_loss = 0.00012064916369307952
Trained batch 442 in epoch 18, gen_loss = 0.8727932615420081, disc_loss = 0.0001205658166493635
Trained batch 443 in epoch 18, gen_loss = 0.8727680930683205, disc_loss = 0.00012043392422407403
Trained batch 444 in epoch 18, gen_loss = 0.8727058136061336, disc_loss = 0.0001204220505560136
Trained batch 445 in epoch 18, gen_loss = 0.8727701729990441, disc_loss = 0.00012030569974544736
Trained batch 446 in epoch 18, gen_loss = 0.87320233951479, disc_loss = 0.0001202313912616625
Trained batch 447 in epoch 18, gen_loss = 0.8730194317176938, disc_loss = 0.00012008226463779335
Trained batch 448 in epoch 18, gen_loss = 0.8730849814839777, disc_loss = 0.00012001092457371963
Trained batch 449 in epoch 18, gen_loss = 0.8730086365011003, disc_loss = 0.0001199081076952603
Trained batch 450 in epoch 18, gen_loss = 0.8727935775949263, disc_loss = 0.00011981300157480646
Trained batch 451 in epoch 18, gen_loss = 0.8724731024915138, disc_loss = 0.00011975611869274871
Trained batch 452 in epoch 18, gen_loss = 0.8723178153269602, disc_loss = 0.00011968802701082814
Trained batch 453 in epoch 18, gen_loss = 0.8722159550053432, disc_loss = 0.00011967259031069918
Trained batch 454 in epoch 18, gen_loss = 0.8722497416066599, disc_loss = 0.00011961158996820194
Trained batch 455 in epoch 18, gen_loss = 0.8721267288191277, disc_loss = 0.00011955023938482332
Trained batch 456 in epoch 18, gen_loss = 0.8720817845029435, disc_loss = 0.00011945751238724113
Trained batch 457 in epoch 18, gen_loss = 0.8720578447179502, disc_loss = 0.0001194322863961626
Trained batch 458 in epoch 18, gen_loss = 0.8722152078852934, disc_loss = 0.00011931299755530085
Trained batch 459 in epoch 18, gen_loss = 0.8719782339489979, disc_loss = 0.00011922786797304465
Trained batch 460 in epoch 18, gen_loss = 0.8718235289714341, disc_loss = 0.00011915357586244119
Trained batch 461 in epoch 18, gen_loss = 0.8717791876751623, disc_loss = 0.00011906611811536216
Trained batch 462 in epoch 18, gen_loss = 0.8717297101896216, disc_loss = 0.00011914129798195212
Trained batch 463 in epoch 18, gen_loss = 0.871627444208696, disc_loss = 0.00011906973233227949
Trained batch 464 in epoch 18, gen_loss = 0.8713781532420907, disc_loss = 0.0001189420974384042
Trained batch 465 in epoch 18, gen_loss = 0.871376218202288, disc_loss = 0.00011882855840886207
Trained batch 466 in epoch 18, gen_loss = 0.8713955237217071, disc_loss = 0.00011872537416339666
Trained batch 467 in epoch 18, gen_loss = 0.8712381492567878, disc_loss = 0.00011873120190732431
Trained batch 468 in epoch 18, gen_loss = 0.8711345679978572, disc_loss = 0.00011874596660731852
Trained batch 469 in epoch 18, gen_loss = 0.8711220906135884, disc_loss = 0.00011866267917905638
Trained batch 470 in epoch 18, gen_loss = 0.8712826191493154, disc_loss = 0.00011853006013830721
Trained batch 471 in epoch 18, gen_loss = 0.8712214351458064, disc_loss = 0.00011857730361829824
Trained batch 472 in epoch 18, gen_loss = 0.8711184618588986, disc_loss = 0.00011851805648739384
Trained batch 473 in epoch 18, gen_loss = 0.8711168071891688, disc_loss = 0.00011840230085774529
Trained batch 474 in epoch 18, gen_loss = 0.8709731539927031, disc_loss = 0.00011833268311181057
Trained batch 475 in epoch 18, gen_loss = 0.8709102696230432, disc_loss = 0.00011831555192878747
Trained batch 476 in epoch 18, gen_loss = 0.8706533135358142, disc_loss = 0.00011822426895988301
Trained batch 477 in epoch 18, gen_loss = 0.8704124570641059, disc_loss = 0.00011847707594607988
Trained batch 478 in epoch 18, gen_loss = 0.8704925137173408, disc_loss = 0.0001186079720135084
Trained batch 479 in epoch 18, gen_loss = 0.8703480546673139, disc_loss = 0.00011854216633461571
Trained batch 480 in epoch 18, gen_loss = 0.8704834188839997, disc_loss = 0.0001184839918272107
Trained batch 481 in epoch 18, gen_loss = 0.870535948959129, disc_loss = 0.00011843333920911708
Trained batch 482 in epoch 18, gen_loss = 0.8706011700580826, disc_loss = 0.00011841773052963063
Trained batch 483 in epoch 18, gen_loss = 0.8705900035613825, disc_loss = 0.0001185957641181563
Trained batch 484 in epoch 18, gen_loss = 0.870453072085823, disc_loss = 0.00011865737624154378
Trained batch 485 in epoch 18, gen_loss = 0.8704276706701444, disc_loss = 0.00011879022933476616
Trained batch 486 in epoch 18, gen_loss = 0.8705282273723359, disc_loss = 0.00011890533646626983
Trained batch 487 in epoch 18, gen_loss = 0.870366738101498, disc_loss = 0.00011885501680808375
Trained batch 488 in epoch 18, gen_loss = 0.8706280906020011, disc_loss = 0.00011877010212539827
Trained batch 489 in epoch 18, gen_loss = 0.8707033598909573, disc_loss = 0.0001187487397721864
Trained batch 490 in epoch 18, gen_loss = 0.8707529788347466, disc_loss = 0.00011871718842635318
Trained batch 491 in epoch 18, gen_loss = 0.8709195431897311, disc_loss = 0.0001186531397370419
Trained batch 492 in epoch 18, gen_loss = 0.8710388173679793, disc_loss = 0.00011859151226755054
Trained batch 493 in epoch 18, gen_loss = 0.8709486227045175, disc_loss = 0.0001184801120344721
Trained batch 494 in epoch 18, gen_loss = 0.8710158154217884, disc_loss = 0.00011834836471767042
Trained batch 495 in epoch 18, gen_loss = 0.8709348881196591, disc_loss = 0.00011842457228516239
Trained batch 496 in epoch 18, gen_loss = 0.8707866564363062, disc_loss = 0.00011835578914019195
Trained batch 497 in epoch 18, gen_loss = 0.8708527204262684, disc_loss = 0.0001182812343632763
Trained batch 498 in epoch 18, gen_loss = 0.8711456646900139, disc_loss = 0.00011823228718738588
Trained batch 499 in epoch 18, gen_loss = 0.8714163273572921, disc_loss = 0.00011819304528762586
Trained batch 500 in epoch 18, gen_loss = 0.8715285917004187, disc_loss = 0.00011826794843273999
Trained batch 501 in epoch 18, gen_loss = 0.8715763961176474, disc_loss = 0.00011814192974458975
Trained batch 502 in epoch 18, gen_loss = 0.871805912102193, disc_loss = 0.00011833839976378285
Trained batch 503 in epoch 18, gen_loss = 0.8720094115724639, disc_loss = 0.00011828801848062698
Trained batch 504 in epoch 18, gen_loss = 0.8721725139287438, disc_loss = 0.00011818190384771454
Trained batch 505 in epoch 18, gen_loss = 0.8722466581423763, disc_loss = 0.00011806944166892208
Trained batch 506 in epoch 18, gen_loss = 0.8721243967201112, disc_loss = 0.00011804067803612456
Trained batch 507 in epoch 18, gen_loss = 0.8721657124325985, disc_loss = 0.00011794082148678466
Trained batch 508 in epoch 18, gen_loss = 0.8722926731896541, disc_loss = 0.00011782781796616572
Trained batch 509 in epoch 18, gen_loss = 0.8721790832631728, disc_loss = 0.00011777699209250939
Trained batch 510 in epoch 18, gen_loss = 0.8721037806830061, disc_loss = 0.00011776461498327727
Trained batch 511 in epoch 18, gen_loss = 0.8719900483265519, disc_loss = 0.00011776395935925166
Trained batch 512 in epoch 18, gen_loss = 0.8720135325112073, disc_loss = 0.00011771671698726196
Trained batch 513 in epoch 18, gen_loss = 0.8719371208189063, disc_loss = 0.00011766930335967535
Trained batch 514 in epoch 18, gen_loss = 0.8720783320445459, disc_loss = 0.00011759279512668038
Trained batch 515 in epoch 18, gen_loss = 0.8721610728160355, disc_loss = 0.00011750504678599636
Trained batch 516 in epoch 18, gen_loss = 0.8721585249531891, disc_loss = 0.00011742139994737609
Trained batch 517 in epoch 18, gen_loss = 0.8721905919115516, disc_loss = 0.00011727211157761875
Trained batch 518 in epoch 18, gen_loss = 0.8721038413185604, disc_loss = 0.0001171988859296142
Trained batch 519 in epoch 18, gen_loss = 0.8720051576311771, disc_loss = 0.00011709811017751165
Trained batch 520 in epoch 18, gen_loss = 0.8720123274770213, disc_loss = 0.00011695434158828132
Trained batch 521 in epoch 18, gen_loss = 0.8718526177251019, disc_loss = 0.00011689979113711774
Trained batch 522 in epoch 18, gen_loss = 0.8717665099049161, disc_loss = 0.00011684192184363955
Trained batch 523 in epoch 18, gen_loss = 0.8717454431848671, disc_loss = 0.0001167303302462163
Trained batch 524 in epoch 18, gen_loss = 0.872036767800649, disc_loss = 0.00011668574290871176
Trained batch 525 in epoch 18, gen_loss = 0.8721329677467564, disc_loss = 0.00011667647723410856
Trained batch 526 in epoch 18, gen_loss = 0.8720847439494486, disc_loss = 0.00011672864658296359
Trained batch 527 in epoch 18, gen_loss = 0.8719527436928316, disc_loss = 0.00011672116703597236
Trained batch 528 in epoch 18, gen_loss = 0.8719826237015103, disc_loss = 0.0001167446631931177
Trained batch 529 in epoch 18, gen_loss = 0.8719715796551615, disc_loss = 0.00011665126835138818
Trained batch 530 in epoch 18, gen_loss = 0.8719041942427612, disc_loss = 0.00011666018075211913
Trained batch 531 in epoch 18, gen_loss = 0.8718805586485038, disc_loss = 0.00011662836711769713
Trained batch 532 in epoch 18, gen_loss = 0.8717383202200312, disc_loss = 0.00011658660686515031
Trained batch 533 in epoch 18, gen_loss = 0.8718601726414112, disc_loss = 0.00011662346074540319
Trained batch 534 in epoch 18, gen_loss = 0.8721159709948245, disc_loss = 0.0001165584301620626
Trained batch 535 in epoch 18, gen_loss = 0.8720250731306289, disc_loss = 0.00011646501820566178
Trained batch 536 in epoch 18, gen_loss = 0.8719243296253837, disc_loss = 0.00011641726391144995
Trained batch 537 in epoch 18, gen_loss = 0.8720062322997693, disc_loss = 0.00011633382620593727
Trained batch 538 in epoch 18, gen_loss = 0.8721209076649625, disc_loss = 0.00011622093920617542
Trained batch 539 in epoch 18, gen_loss = 0.8722652998235491, disc_loss = 0.00011611639926101175
Trained batch 540 in epoch 18, gen_loss = 0.8724593805517595, disc_loss = 0.0001161089760843426
Trained batch 541 in epoch 18, gen_loss = 0.8725144114221594, disc_loss = 0.00011598614149975437
Trained batch 542 in epoch 18, gen_loss = 0.8723719087094892, disc_loss = 0.0001159605418146364
Trained batch 543 in epoch 18, gen_loss = 0.8722931683501777, disc_loss = 0.00011589216889847997
Trained batch 544 in epoch 18, gen_loss = 0.8723110360836764, disc_loss = 0.00011577508639258016
Trained batch 545 in epoch 18, gen_loss = 0.8723828660481142, disc_loss = 0.00011570584885016998
Trained batch 546 in epoch 18, gen_loss = 0.8724698197689091, disc_loss = 0.00011558229505870631
Trained batch 547 in epoch 18, gen_loss = 0.8726172665827465, disc_loss = 0.00011551943333850525
Trained batch 548 in epoch 18, gen_loss = 0.8728181604696319, disc_loss = 0.00011549194803058961
Trained batch 549 in epoch 18, gen_loss = 0.8728861259330403, disc_loss = 0.00011541789695250124
Trained batch 550 in epoch 18, gen_loss = 0.87318289485471, disc_loss = 0.00011536608145184758
Trained batch 551 in epoch 18, gen_loss = 0.8732517982522646, disc_loss = 0.0001153292844627277
Trained batch 552 in epoch 18, gen_loss = 0.8732369905354532, disc_loss = 0.00011522076237521717
Trained batch 553 in epoch 18, gen_loss = 0.873232674835391, disc_loss = 0.00011511077656366926
Trained batch 554 in epoch 18, gen_loss = 0.8732431904689686, disc_loss = 0.0001150140876258799
Trained batch 555 in epoch 18, gen_loss = 0.8731273853307148, disc_loss = 0.00011496074043763735
Trained batch 556 in epoch 18, gen_loss = 0.8730418422063763, disc_loss = 0.00011483943648406436
Trained batch 557 in epoch 18, gen_loss = 0.8729320128972385, disc_loss = 0.00011474525226437817
Trained batch 558 in epoch 18, gen_loss = 0.8729495041485549, disc_loss = 0.00011476805973119121
Trained batch 559 in epoch 18, gen_loss = 0.8727933507944856, disc_loss = 0.0001147179484697907
Trained batch 560 in epoch 18, gen_loss = 0.872792681164495, disc_loss = 0.0001147945663165849
Trained batch 561 in epoch 18, gen_loss = 0.8728000870590956, disc_loss = 0.00011468747879755086
Trained batch 562 in epoch 18, gen_loss = 0.8728399556229424, disc_loss = 0.00011467608918328761
Trained batch 563 in epoch 18, gen_loss = 0.8728150797228441, disc_loss = 0.00011464848869357584
Trained batch 564 in epoch 18, gen_loss = 0.8729609843903938, disc_loss = 0.00011495353160292091
Trained batch 565 in epoch 18, gen_loss = 0.8736551083861307, disc_loss = 0.00011532188499049784
Trained batch 566 in epoch 18, gen_loss = 0.8740165141103969, disc_loss = 0.00011545027683132182
Trained batch 567 in epoch 18, gen_loss = 0.8742078437771595, disc_loss = 0.00011541222843782596
Trained batch 568 in epoch 18, gen_loss = 0.8742947516625711, disc_loss = 0.00011535359198268034
Trained batch 569 in epoch 18, gen_loss = 0.8743690472945832, disc_loss = 0.00011539033420328787
Trained batch 570 in epoch 18, gen_loss = 0.8746607110504511, disc_loss = 0.00011542045920644846
Trained batch 571 in epoch 18, gen_loss = 0.8748604502086039, disc_loss = 0.00011539420626507632
Trained batch 572 in epoch 18, gen_loss = 0.8750194443249993, disc_loss = 0.00011529792944862496
Trained batch 573 in epoch 18, gen_loss = 0.8752579025482882, disc_loss = 0.00011529869892853897
Trained batch 574 in epoch 18, gen_loss = 0.8753346627691517, disc_loss = 0.00011533551812728705
Trained batch 575 in epoch 18, gen_loss = 0.8753233386410607, disc_loss = 0.00011531451411883609
Trained batch 576 in epoch 18, gen_loss = 0.8754102513323211, disc_loss = 0.00011549075145447511
Trained batch 577 in epoch 18, gen_loss = 0.8755259074554311, disc_loss = 0.00011565980472922999
Trained batch 578 in epoch 18, gen_loss = 0.8755604926374498, disc_loss = 0.00011572445169405285
Trained batch 579 in epoch 18, gen_loss = 0.8757873950333431, disc_loss = 0.00011584874372256936
Trained batch 580 in epoch 18, gen_loss = 0.8758800304695169, disc_loss = 0.00011587922136780602
Trained batch 581 in epoch 18, gen_loss = 0.8758848336144411, disc_loss = 0.0001158288240484146
Trained batch 582 in epoch 18, gen_loss = 0.8761577158399553, disc_loss = 0.00011584975663702344
Trained batch 583 in epoch 18, gen_loss = 0.8761384997465839, disc_loss = 0.00011601527735552263
Trained batch 584 in epoch 18, gen_loss = 0.8761986650972284, disc_loss = 0.00011629080070276211
Trained batch 585 in epoch 18, gen_loss = 0.8762542312462582, disc_loss = 0.00011629822597957738
Trained batch 586 in epoch 18, gen_loss = 0.8763878454138514, disc_loss = 0.00011657106379882768
Trained batch 587 in epoch 18, gen_loss = 0.8761963134720212, disc_loss = 0.0001167648813886636
Trained batch 588 in epoch 18, gen_loss = 0.876297575508597, disc_loss = 0.00011697771613071444
Trained batch 589 in epoch 18, gen_loss = 0.8762954517946405, disc_loss = 0.00011709362108870094
Trained batch 590 in epoch 18, gen_loss = 0.876378240218219, disc_loss = 0.00011763534865032033
Trained batch 591 in epoch 18, gen_loss = 0.8761903396933466, disc_loss = 0.0001179131753987521
Trained batch 592 in epoch 18, gen_loss = 0.876501400092802, disc_loss = 0.00011832940827870213
Trained batch 593 in epoch 18, gen_loss = 0.8765386903928185, disc_loss = 0.00011886259841410089
Trained batch 594 in epoch 18, gen_loss = 0.8765516841111063, disc_loss = 0.00011942003074174497
Trained batch 595 in epoch 18, gen_loss = 0.8763298017266613, disc_loss = 0.0001199740476441615
Trained batch 596 in epoch 18, gen_loss = 0.8763986197947657, disc_loss = 0.00012020742419728435
Trained batch 597 in epoch 18, gen_loss = 0.8763548525480124, disc_loss = 0.00012046423991863696
Trained batch 598 in epoch 18, gen_loss = 0.8764409743286732, disc_loss = 0.00012061512009044393
Trained batch 599 in epoch 18, gen_loss = 0.8763642476995787, disc_loss = 0.00012108323216428592
Trained batch 600 in epoch 18, gen_loss = 0.8763753796575867, disc_loss = 0.00012110966630289703
Trained batch 601 in epoch 18, gen_loss = 0.8761879513628062, disc_loss = 0.00012133154566595068
Trained batch 602 in epoch 18, gen_loss = 0.8762565454835718, disc_loss = 0.00012174457631193203
Trained batch 603 in epoch 18, gen_loss = 0.8763351291418076, disc_loss = 0.00012191216634489697
Trained batch 604 in epoch 18, gen_loss = 0.8762981873898467, disc_loss = 0.00012209483361966554
Trained batch 605 in epoch 18, gen_loss = 0.8761893300333432, disc_loss = 0.00012229334484206025
Trained batch 606 in epoch 18, gen_loss = 0.8762984953366552, disc_loss = 0.00012229804933802616
Trained batch 607 in epoch 18, gen_loss = 0.8762344793465576, disc_loss = 0.000122275232618114
Trained batch 608 in epoch 18, gen_loss = 0.8762800967556307, disc_loss = 0.00012228324157162912
Trained batch 609 in epoch 18, gen_loss = 0.8762610853695478, disc_loss = 0.0001223092981743947
Trained batch 610 in epoch 18, gen_loss = 0.876373554212567, disc_loss = 0.00012224618358931577
Trained batch 611 in epoch 18, gen_loss = 0.876317216290368, disc_loss = 0.00012215144184082852
Trained batch 612 in epoch 18, gen_loss = 0.8762552493159184, disc_loss = 0.00012202698266499054
Trained batch 613 in epoch 18, gen_loss = 0.8763222566256694, disc_loss = 0.00012202102400181233
Trained batch 614 in epoch 18, gen_loss = 0.8762866213069699, disc_loss = 0.00012192726707865855
Trained batch 615 in epoch 18, gen_loss = 0.8761641543793988, disc_loss = 0.0001218528995632841
Trained batch 616 in epoch 18, gen_loss = 0.8761397718030784, disc_loss = 0.00012175653137976448
Trained batch 617 in epoch 18, gen_loss = 0.8761650100109261, disc_loss = 0.0001216567893121482
Trained batch 618 in epoch 18, gen_loss = 0.8763219826826179, disc_loss = 0.00012155500442705152
Trained batch 619 in epoch 18, gen_loss = 0.8764099323941815, disc_loss = 0.00012143416472920967
Trained batch 620 in epoch 18, gen_loss = 0.8763485652621049, disc_loss = 0.00012139962990001525
Trained batch 621 in epoch 18, gen_loss = 0.876427525396899, disc_loss = 0.00012132684180392866
Trained batch 622 in epoch 18, gen_loss = 0.8765785092335452, disc_loss = 0.00012122070819076322
Trained batch 623 in epoch 18, gen_loss = 0.8765779277070974, disc_loss = 0.00012112759068025835
Trained batch 624 in epoch 18, gen_loss = 0.8766228834152222, disc_loss = 0.00012103211510693654
Trained batch 625 in epoch 18, gen_loss = 0.8767091026321386, disc_loss = 0.0001209722858229347
Trained batch 626 in epoch 18, gen_loss = 0.8767268684302031, disc_loss = 0.00012092080726977096
Trained batch 627 in epoch 18, gen_loss = 0.8768277637138489, disc_loss = 0.00012092888720675036
Trained batch 628 in epoch 18, gen_loss = 0.8769367434830658, disc_loss = 0.00012094675872035529
Trained batch 629 in epoch 18, gen_loss = 0.8769584595210969, disc_loss = 0.00012086952663680893
Trained batch 630 in epoch 18, gen_loss = 0.8770115059075756, disc_loss = 0.00012095679782505152
Trained batch 631 in epoch 18, gen_loss = 0.8769664136292059, disc_loss = 0.00012083641869841952
Trained batch 632 in epoch 18, gen_loss = 0.876865393836728, disc_loss = 0.00012084259803327445
Trained batch 633 in epoch 18, gen_loss = 0.8768866343265076, disc_loss = 0.00012079210342442373
Trained batch 634 in epoch 18, gen_loss = 0.8769205566466324, disc_loss = 0.00012075509334039896
Trained batch 635 in epoch 18, gen_loss = 0.877072792945418, disc_loss = 0.00012087501846914657
Trained batch 636 in epoch 18, gen_loss = 0.8772308305256782, disc_loss = 0.0001207931156523688
Trained batch 637 in epoch 18, gen_loss = 0.8771670984810797, disc_loss = 0.00012070482934915992
Trained batch 638 in epoch 18, gen_loss = 0.8774127903305495, disc_loss = 0.00012065384746082811
Trained batch 639 in epoch 18, gen_loss = 0.8774699862115085, disc_loss = 0.00012055315306724879
Trained batch 640 in epoch 18, gen_loss = 0.8773407343769222, disc_loss = 0.00012047721078525284
Trained batch 641 in epoch 18, gen_loss = 0.8773687980442404, disc_loss = 0.00012050045550047606
Trained batch 642 in epoch 18, gen_loss = 0.8775025631183785, disc_loss = 0.00012044342720669638
Trained batch 643 in epoch 18, gen_loss = 0.8773281185523324, disc_loss = 0.00012034953946319281
Trained batch 644 in epoch 18, gen_loss = 0.877483492211778, disc_loss = 0.00012029608565629929
Trained batch 645 in epoch 18, gen_loss = 0.87751341465826, disc_loss = 0.00012025192124549597
Trained batch 646 in epoch 18, gen_loss = 0.8775191803619703, disc_loss = 0.00012025491711588208
Trained batch 647 in epoch 18, gen_loss = 0.877352482282821, disc_loss = 0.00012029018473836958
Trained batch 648 in epoch 18, gen_loss = 0.8771096711349782, disc_loss = 0.0001203569128583989
Trained batch 649 in epoch 18, gen_loss = 0.8770178939745976, disc_loss = 0.00012038956498145126
Trained batch 650 in epoch 18, gen_loss = 0.87713872608135, disc_loss = 0.00012033924803711094
Trained batch 651 in epoch 18, gen_loss = 0.8771825466602127, disc_loss = 0.00012029149938323692
Trained batch 652 in epoch 18, gen_loss = 0.877229673939131, disc_loss = 0.00012040978878464445
Trained batch 653 in epoch 18, gen_loss = 0.8771164615948995, disc_loss = 0.00012044282548871128
Trained batch 654 in epoch 18, gen_loss = 0.8771887644556643, disc_loss = 0.00012041000017935396
Trained batch 655 in epoch 18, gen_loss = 0.8772019870215799, disc_loss = 0.0001203290481143773
Trained batch 656 in epoch 18, gen_loss = 0.8770807242103181, disc_loss = 0.00012026448081859886
Trained batch 657 in epoch 18, gen_loss = 0.8768793445952395, disc_loss = 0.00012030789904093999
Trained batch 658 in epoch 18, gen_loss = 0.8769053027192089, disc_loss = 0.00012028143114155252
Trained batch 659 in epoch 18, gen_loss = 0.8768895732633996, disc_loss = 0.00012019351011214453
Trained batch 660 in epoch 18, gen_loss = 0.8768751045939782, disc_loss = 0.00012012684538616318
Trained batch 661 in epoch 18, gen_loss = 0.876938806469707, disc_loss = 0.0001200069378309421
Trained batch 662 in epoch 18, gen_loss = 0.8768670736035251, disc_loss = 0.00011994456979343394
Trained batch 663 in epoch 18, gen_loss = 0.8768133504024471, disc_loss = 0.00011994512449592844
Trained batch 664 in epoch 18, gen_loss = 0.8769704803488308, disc_loss = 0.00012003173722856664
Trained batch 665 in epoch 18, gen_loss = 0.8770421496382704, disc_loss = 0.00012004162024757468
Trained batch 666 in epoch 18, gen_loss = 0.8770007057704668, disc_loss = 0.0001199670364605762
Trained batch 667 in epoch 18, gen_loss = 0.8768115002595022, disc_loss = 0.0001199051890133871
Trained batch 668 in epoch 18, gen_loss = 0.8769986522571923, disc_loss = 0.00011986343565661292
Trained batch 669 in epoch 18, gen_loss = 0.876985797508439, disc_loss = 0.00011977633744684125
Trained batch 670 in epoch 18, gen_loss = 0.877030149213248, disc_loss = 0.00011970850192143127
Trained batch 671 in epoch 18, gen_loss = 0.876979148724959, disc_loss = 0.00011965174813949055
Trained batch 672 in epoch 18, gen_loss = 0.8768170646005718, disc_loss = 0.00011966241202248851
Trained batch 673 in epoch 18, gen_loss = 0.8768142185862057, disc_loss = 0.00011964924606191132
Trained batch 674 in epoch 18, gen_loss = 0.8770273381692392, disc_loss = 0.00011965692292842842
Trained batch 675 in epoch 18, gen_loss = 0.8769685067015992, disc_loss = 0.00011957979534239303
Trained batch 676 in epoch 18, gen_loss = 0.8770346771843148, disc_loss = 0.00011951634274855664
Trained batch 677 in epoch 18, gen_loss = 0.8772902137058675, disc_loss = 0.00011943889637107673
Trained batch 678 in epoch 18, gen_loss = 0.8770544887115748, disc_loss = 0.00011961805124754952
Trained batch 679 in epoch 18, gen_loss = 0.8770932194064646, disc_loss = 0.00011970502939541749
Trained batch 680 in epoch 18, gen_loss = 0.8770218450417427, disc_loss = 0.00011971015002457637
Trained batch 681 in epoch 18, gen_loss = 0.8772703844431209, disc_loss = 0.00011984081788329426
Trained batch 682 in epoch 18, gen_loss = 0.8773254545331874, disc_loss = 0.00011989672586655396
Trained batch 683 in epoch 18, gen_loss = 0.8773307860420462, disc_loss = 0.00011982817227761731
Trained batch 684 in epoch 18, gen_loss = 0.8773956308399674, disc_loss = 0.00011976998179652185
Trained batch 685 in epoch 18, gen_loss = 0.8773223661299002, disc_loss = 0.00011968129151695918
Trained batch 686 in epoch 18, gen_loss = 0.8774336068911324, disc_loss = 0.00011963169342725371
Trained batch 687 in epoch 18, gen_loss = 0.8775068725091081, disc_loss = 0.00011957901792917509
Trained batch 688 in epoch 18, gen_loss = 0.8775774104674773, disc_loss = 0.00011950144311497651
Trained batch 689 in epoch 18, gen_loss = 0.8773211428220721, disc_loss = 0.00011982231818905532
Trained batch 690 in epoch 18, gen_loss = 0.8772993744195974, disc_loss = 0.00011980991709307537
Trained batch 691 in epoch 18, gen_loss = 0.8773133090638012, disc_loss = 0.00011972712031636263
Trained batch 692 in epoch 18, gen_loss = 0.8773041070797742, disc_loss = 0.00011964062096445733
Trained batch 693 in epoch 18, gen_loss = 0.87728064324739, disc_loss = 0.00011956155781171342
Trained batch 694 in epoch 18, gen_loss = 0.8773003534447374, disc_loss = 0.00011951216801070514
Trained batch 695 in epoch 18, gen_loss = 0.8773910875978141, disc_loss = 0.00011947822693024324
Trained batch 696 in epoch 18, gen_loss = 0.8776510681962352, disc_loss = 0.00011941183773713712
Trained batch 697 in epoch 18, gen_loss = 0.8774520187801481, disc_loss = 0.0001193394016178527
Trained batch 698 in epoch 18, gen_loss = 0.8774994067709163, disc_loss = 0.00011930332860178434
Trained batch 699 in epoch 18, gen_loss = 0.8773992991447449, disc_loss = 0.00011921766123642946
Trained batch 700 in epoch 18, gen_loss = 0.877524524034345, disc_loss = 0.00011914937105378569
Trained batch 701 in epoch 18, gen_loss = 0.8774818502090596, disc_loss = 0.00011914516395553907
Trained batch 702 in epoch 18, gen_loss = 0.877663441521684, disc_loss = 0.00011918931348677552
Trained batch 703 in epoch 18, gen_loss = 0.8776493579657241, disc_loss = 0.00011916540146020535
Trained batch 704 in epoch 18, gen_loss = 0.8775211314783029, disc_loss = 0.00011909951290556606
Trained batch 705 in epoch 18, gen_loss = 0.8774412493023589, disc_loss = 0.00011915051577708067
Trained batch 706 in epoch 18, gen_loss = 0.8776600317874083, disc_loss = 0.00011911881532310278
Trained batch 707 in epoch 18, gen_loss = 0.8778183257344079, disc_loss = 0.00011906350467189302
Trained batch 708 in epoch 18, gen_loss = 0.8778589996699722, disc_loss = 0.00011907465439984359
Trained batch 709 in epoch 18, gen_loss = 0.8778950428459006, disc_loss = 0.00011906985077280616
Trained batch 710 in epoch 18, gen_loss = 0.877902247315553, disc_loss = 0.00011901633666043003
Trained batch 711 in epoch 18, gen_loss = 0.8779017446416147, disc_loss = 0.00011901203302595912
Trained batch 712 in epoch 18, gen_loss = 0.8778319305323619, disc_loss = 0.00011901818084002173
Trained batch 713 in epoch 18, gen_loss = 0.8777708925452887, disc_loss = 0.00011895141656920106
Trained batch 714 in epoch 18, gen_loss = 0.8776505817066539, disc_loss = 0.00011910174668431152
Trained batch 715 in epoch 18, gen_loss = 0.8775931997172659, disc_loss = 0.00011912296397199167
Trained batch 716 in epoch 18, gen_loss = 0.8775371441947533, disc_loss = 0.00011909676897701596
Trained batch 717 in epoch 18, gen_loss = 0.8775165336709833, disc_loss = 0.0001190998679442684
Trained batch 718 in epoch 18, gen_loss = 0.877710748116728, disc_loss = 0.00011906609143909606
Trained batch 719 in epoch 18, gen_loss = 0.8777547609474924, disc_loss = 0.00011898619850398972
Trained batch 720 in epoch 18, gen_loss = 0.8778480091306604, disc_loss = 0.00011899921228985164
Trained batch 721 in epoch 18, gen_loss = 0.8779418428023436, disc_loss = 0.00011897282444536906
Trained batch 722 in epoch 18, gen_loss = 0.8779298831318424, disc_loss = 0.0001188968327793294
Trained batch 723 in epoch 18, gen_loss = 0.8780410502167696, disc_loss = 0.00011883614905910485
Trained batch 724 in epoch 18, gen_loss = 0.8780572134872963, disc_loss = 0.00011872727344121687
Trained batch 725 in epoch 18, gen_loss = 0.8779192261459413, disc_loss = 0.00011863885815189599
Trained batch 726 in epoch 18, gen_loss = 0.8778800956976627, disc_loss = 0.00011854327547295401
Trained batch 727 in epoch 18, gen_loss = 0.8780037348905763, disc_loss = 0.00011849085064198704
Trained batch 728 in epoch 18, gen_loss = 0.8780064794588809, disc_loss = 0.00011843978792645513
Trained batch 729 in epoch 18, gen_loss = 0.8779976344271881, disc_loss = 0.00011839775122584112
Trained batch 730 in epoch 18, gen_loss = 0.8780661016580344, disc_loss = 0.00011834628861630017
Trained batch 731 in epoch 18, gen_loss = 0.8778896342372634, disc_loss = 0.00011835076971106166
Trained batch 732 in epoch 18, gen_loss = 0.8779176040203152, disc_loss = 0.00011828540116848708
Trained batch 733 in epoch 18, gen_loss = 0.8780098464086206, disc_loss = 0.00011821614305527782
Trained batch 734 in epoch 18, gen_loss = 0.8780158942248546, disc_loss = 0.00011819902048002752
Trained batch 735 in epoch 18, gen_loss = 0.8780327603706847, disc_loss = 0.00011815660056289862
Trained batch 736 in epoch 18, gen_loss = 0.8780493934410074, disc_loss = 0.00011817497282454509
Trained batch 737 in epoch 18, gen_loss = 0.8782408868232716, disc_loss = 0.00011814488943534977
Trained batch 738 in epoch 18, gen_loss = 0.8781940018372543, disc_loss = 0.0001180670127347118
Trained batch 739 in epoch 18, gen_loss = 0.8783704049683906, disc_loss = 0.00011805795393475156
Trained batch 740 in epoch 18, gen_loss = 0.8782891344766707, disc_loss = 0.0001181075480829751
Trained batch 741 in epoch 18, gen_loss = 0.8782924914135123, disc_loss = 0.00011805383359255255
Trained batch 742 in epoch 18, gen_loss = 0.8782692550008422, disc_loss = 0.00011797463408060099
Trained batch 743 in epoch 18, gen_loss = 0.8783583630637456, disc_loss = 0.00011803122727845523
Trained batch 744 in epoch 18, gen_loss = 0.8783055264677777, disc_loss = 0.00011812243633571506
Trained batch 745 in epoch 18, gen_loss = 0.8783325981198943, disc_loss = 0.0001180939611828004
Trained batch 746 in epoch 18, gen_loss = 0.878323593133265, disc_loss = 0.00011799958902778176
Trained batch 747 in epoch 18, gen_loss = 0.8783945199002556, disc_loss = 0.00011790649787728136
Trained batch 748 in epoch 18, gen_loss = 0.8783257779514837, disc_loss = 0.00011782179533957643
Trained batch 749 in epoch 18, gen_loss = 0.8784415361086527, disc_loss = 0.00011776671285527603
Trained batch 750 in epoch 18, gen_loss = 0.8786353487149376, disc_loss = 0.00011789517546000211
Trained batch 751 in epoch 18, gen_loss = 0.8785919157114435, disc_loss = 0.00011803719019824596
Trained batch 752 in epoch 18, gen_loss = 0.8784597109988391, disc_loss = 0.00011798549168929489
Trained batch 753 in epoch 18, gen_loss = 0.8782910240581877, disc_loss = 0.00011795057959405153
Trained batch 754 in epoch 18, gen_loss = 0.8782854865718361, disc_loss = 0.00011791369503549768
Trained batch 755 in epoch 18, gen_loss = 0.8783110630102259, disc_loss = 0.00011781894589042712
Trained batch 756 in epoch 18, gen_loss = 0.8784277057238268, disc_loss = 0.0001178440196609787
Trained batch 757 in epoch 18, gen_loss = 0.8783804209691554, disc_loss = 0.00011791361361256853
Trained batch 758 in epoch 18, gen_loss = 0.8783569546399224, disc_loss = 0.00011788280608016066
Trained batch 759 in epoch 18, gen_loss = 0.878410299828178, disc_loss = 0.00011793693145495797
Trained batch 760 in epoch 18, gen_loss = 0.8782332743984328, disc_loss = 0.00011797320568489992
Trained batch 761 in epoch 18, gen_loss = 0.8783617132292019, disc_loss = 0.00011802270868491398
Trained batch 762 in epoch 18, gen_loss = 0.8783306382586727, disc_loss = 0.00011809817015341858
Trained batch 763 in epoch 18, gen_loss = 0.8782587798009992, disc_loss = 0.00011807907892715494
Trained batch 764 in epoch 18, gen_loss = 0.8783689616552366, disc_loss = 0.0001181374018522226
Trained batch 765 in epoch 18, gen_loss = 0.8783297555098023, disc_loss = 0.00011809823344533505
Trained batch 766 in epoch 18, gen_loss = 0.878211031914379, disc_loss = 0.00011807020065470142
Trained batch 767 in epoch 18, gen_loss = 0.8782432655182978, disc_loss = 0.00011800380144203852
Trained batch 768 in epoch 18, gen_loss = 0.8782559995998487, disc_loss = 0.00011801745466792124
Trained batch 769 in epoch 18, gen_loss = 0.8783073045990684, disc_loss = 0.00011804708991295737
Trained batch 770 in epoch 18, gen_loss = 0.8781727521490649, disc_loss = 0.00011803488784422705
Trained batch 771 in epoch 18, gen_loss = 0.8780417216874157, disc_loss = 0.00011795264099937365
Trained batch 772 in epoch 18, gen_loss = 0.8780525820992434, disc_loss = 0.00011785978228649707
Trained batch 773 in epoch 18, gen_loss = 0.8780710048761786, disc_loss = 0.00011783958950996109
Trained batch 774 in epoch 18, gen_loss = 0.878094958489941, disc_loss = 0.00011777649490414337
Trained batch 775 in epoch 18, gen_loss = 0.8780837983814711, disc_loss = 0.00011775379858384618
Trained batch 776 in epoch 18, gen_loss = 0.8780898978811433, disc_loss = 0.00011779385217011635
Trained batch 777 in epoch 18, gen_loss = 0.8780646402302622, disc_loss = 0.00011777223440441261
Trained batch 778 in epoch 18, gen_loss = 0.8780848294381765, disc_loss = 0.00011766335372762983
Trained batch 779 in epoch 18, gen_loss = 0.8780046657874034, disc_loss = 0.00011757667325582589
Trained batch 780 in epoch 18, gen_loss = 0.8780100807337694, disc_loss = 0.00011749782604222762
Trained batch 781 in epoch 18, gen_loss = 0.8779649973068091, disc_loss = 0.00011739649549023161
Trained batch 782 in epoch 18, gen_loss = 0.8779429968441735, disc_loss = 0.00011733828814078621
Trained batch 783 in epoch 18, gen_loss = 0.8780122569629124, disc_loss = 0.00011726756887193395
Trained batch 784 in epoch 18, gen_loss = 0.8780769004183969, disc_loss = 0.00011723208768833814
Trained batch 785 in epoch 18, gen_loss = 0.877979749865811, disc_loss = 0.0001171638108755485
Trained batch 786 in epoch 18, gen_loss = 0.8778393519273101, disc_loss = 0.0001171067730855215
Trained batch 787 in epoch 18, gen_loss = 0.8778992743056437, disc_loss = 0.00011705289969467032
Trained batch 788 in epoch 18, gen_loss = 0.8779303618105948, disc_loss = 0.00011706283730607454
Trained batch 789 in epoch 18, gen_loss = 0.8780047734326955, disc_loss = 0.000117076027439723
Trained batch 790 in epoch 18, gen_loss = 0.8779252028344705, disc_loss = 0.00011706331388866052
Trained batch 791 in epoch 18, gen_loss = 0.877784485543015, disc_loss = 0.00011713107951804014
Trained batch 792 in epoch 18, gen_loss = 0.8778611738023361, disc_loss = 0.0001170515346160707
Trained batch 793 in epoch 18, gen_loss = 0.877932212665039, disc_loss = 0.00011712251801164856
Trained batch 794 in epoch 18, gen_loss = 0.8777805866685303, disc_loss = 0.00011726868085002339
Trained batch 795 in epoch 18, gen_loss = 0.8777784157038933, disc_loss = 0.00011738731803750706
Trained batch 796 in epoch 18, gen_loss = 0.8777642395146369, disc_loss = 0.00011739958915326317
Trained batch 797 in epoch 18, gen_loss = 0.8778338912585026, disc_loss = 0.00011751558034811204
Trained batch 798 in epoch 18, gen_loss = 0.8778610175034878, disc_loss = 0.00011748052637447697
Trained batch 799 in epoch 18, gen_loss = 0.8779997263103724, disc_loss = 0.00011755668012483511
Trained batch 800 in epoch 18, gen_loss = 0.8778759610935692, disc_loss = 0.00011767638202587471
Trained batch 801 in epoch 18, gen_loss = 0.8779403389689334, disc_loss = 0.00011766709920316192
Trained batch 802 in epoch 18, gen_loss = 0.8781106636058053, disc_loss = 0.00011768385196443309
Trained batch 803 in epoch 18, gen_loss = 0.8782591983601822, disc_loss = 0.00011764043300904609
Trained batch 804 in epoch 18, gen_loss = 0.8781822964271403, disc_loss = 0.00011774042695551034
Trained batch 805 in epoch 18, gen_loss = 0.8782689309593465, disc_loss = 0.0001177562042551835
Trained batch 806 in epoch 18, gen_loss = 0.8782702357204726, disc_loss = 0.0001177983313692587
Trained batch 807 in epoch 18, gen_loss = 0.8783642330234593, disc_loss = 0.00011774909216010111
Trained batch 808 in epoch 18, gen_loss = 0.8782921901297362, disc_loss = 0.00011771876857696879
Trained batch 809 in epoch 18, gen_loss = 0.8783078321704159, disc_loss = 0.00011776092586741369
Trained batch 810 in epoch 18, gen_loss = 0.8782367238869061, disc_loss = 0.00011771021642253945
Trained batch 811 in epoch 18, gen_loss = 0.8781793974890497, disc_loss = 0.00011766448599884798
Trained batch 812 in epoch 18, gen_loss = 0.87813185230539, disc_loss = 0.00011767892486541526
Trained batch 813 in epoch 18, gen_loss = 0.8779827913576028, disc_loss = 0.00011772572632508034
Trained batch 814 in epoch 18, gen_loss = 0.8780101213718484, disc_loss = 0.00011771627791273048
Trained batch 815 in epoch 18, gen_loss = 0.8780137555418062, disc_loss = 0.00011777242169795071
Trained batch 816 in epoch 18, gen_loss = 0.8778581988417533, disc_loss = 0.0001179460976628337
Trained batch 817 in epoch 18, gen_loss = 0.8778541904935627, disc_loss = 0.00011810576042078132
Trained batch 818 in epoch 18, gen_loss = 0.8777287518002902, disc_loss = 0.00011811257856953446
Trained batch 819 in epoch 18, gen_loss = 0.8776423577128387, disc_loss = 0.00011806671542971588
Trained batch 820 in epoch 18, gen_loss = 0.8776600039252119, disc_loss = 0.00011805806445960641
Trained batch 821 in epoch 18, gen_loss = 0.8776928678771295, disc_loss = 0.00011809873395730286
Trained batch 822 in epoch 18, gen_loss = 0.877805954703149, disc_loss = 0.00011803621206549138
Trained batch 823 in epoch 18, gen_loss = 0.8777661706926754, disc_loss = 0.00011798487313410202
Trained batch 824 in epoch 18, gen_loss = 0.8777490325407549, disc_loss = 0.0001179238696667281
Trained batch 825 in epoch 18, gen_loss = 0.877629877147028, disc_loss = 0.0001178721062735864
Trained batch 826 in epoch 18, gen_loss = 0.8775303623984774, disc_loss = 0.00011779338804069691
Trained batch 827 in epoch 18, gen_loss = 0.8773736331053978, disc_loss = 0.00011777151628382783
Trained batch 828 in epoch 18, gen_loss = 0.8774221740815837, disc_loss = 0.00011774846490959
Trained batch 829 in epoch 18, gen_loss = 0.8774456894541361, disc_loss = 0.00011770916690331805
Trained batch 830 in epoch 18, gen_loss = 0.8775305024266387, disc_loss = 0.00011763772750009977
Trained batch 831 in epoch 18, gen_loss = 0.8774931816957318, disc_loss = 0.00011759098487555793
Trained batch 832 in epoch 18, gen_loss = 0.8775267606021977, disc_loss = 0.0001175111223584922
Trained batch 833 in epoch 18, gen_loss = 0.8775274255435815, disc_loss = 0.00011749140407123192
Trained batch 834 in epoch 18, gen_loss = 0.8774627866859208, disc_loss = 0.00011745982642723303
Trained batch 835 in epoch 18, gen_loss = 0.8774697464048578, disc_loss = 0.00011741273687673681
Trained batch 836 in epoch 18, gen_loss = 0.8774249713195837, disc_loss = 0.0001173516235992634
Trained batch 837 in epoch 18, gen_loss = 0.8774031238510387, disc_loss = 0.00011731955593320994
Trained batch 838 in epoch 18, gen_loss = 0.8772447131245582, disc_loss = 0.00011730902920964399
Trained batch 839 in epoch 18, gen_loss = 0.8772281213175683, disc_loss = 0.00011725074665654184
Trained batch 840 in epoch 18, gen_loss = 0.8772540113021587, disc_loss = 0.000117221973904527
Trained batch 841 in epoch 18, gen_loss = 0.8773558527018849, disc_loss = 0.00011717067144351023
Trained batch 842 in epoch 18, gen_loss = 0.8774062267119067, disc_loss = 0.00011711411618915953
Trained batch 843 in epoch 18, gen_loss = 0.8774292351086558, disc_loss = 0.0001170469541040578
Trained batch 844 in epoch 18, gen_loss = 0.8775831570286723, disc_loss = 0.0001170351856440504
Trained batch 845 in epoch 18, gen_loss = 0.8775785046829964, disc_loss = 0.00011702598261178514
Trained batch 846 in epoch 18, gen_loss = 0.8776005816150021, disc_loss = 0.0001169691879248385
Trained batch 847 in epoch 18, gen_loss = 0.8775096816133778, disc_loss = 0.00011700400588075731
Trained batch 848 in epoch 18, gen_loss = 0.8775187970190643, disc_loss = 0.00011700128614562438
Trained batch 849 in epoch 18, gen_loss = 0.8774949556939742, disc_loss = 0.00011726304101209868
Trained batch 850 in epoch 18, gen_loss = 0.8775283643837961, disc_loss = 0.00011733650446970116
Trained batch 851 in epoch 18, gen_loss = 0.8775549275634434, disc_loss = 0.00011730027895944385
Trained batch 852 in epoch 18, gen_loss = 0.8775477080244531, disc_loss = 0.00011728167204486025
Trained batch 853 in epoch 18, gen_loss = 0.8775184677272546, disc_loss = 0.00011727784618389611
Trained batch 854 in epoch 18, gen_loss = 0.8775296322086401, disc_loss = 0.00011720591473559256
Trained batch 855 in epoch 18, gen_loss = 0.8774158772185584, disc_loss = 0.00011719800725493038
Trained batch 856 in epoch 18, gen_loss = 0.8776404594735198, disc_loss = 0.00011721802536307702
Trained batch 857 in epoch 18, gen_loss = 0.8776740558914371, disc_loss = 0.00011719915198920933
Trained batch 858 in epoch 18, gen_loss = 0.8777111650068352, disc_loss = 0.0001172616623855132
Trained batch 859 in epoch 18, gen_loss = 0.8778705521378406, disc_loss = 0.00011742715884560481
Trained batch 860 in epoch 18, gen_loss = 0.8779859363548155, disc_loss = 0.0001174949369528228
Trained batch 861 in epoch 18, gen_loss = 0.8779786734597589, disc_loss = 0.00011743453318360392
Trained batch 862 in epoch 18, gen_loss = 0.87784722271275, disc_loss = 0.00011748593004787586
Trained batch 863 in epoch 18, gen_loss = 0.8778946765319064, disc_loss = 0.00011755498988990169
Trained batch 864 in epoch 18, gen_loss = 0.8780749597990444, disc_loss = 0.00011756814328376258
Trained batch 865 in epoch 18, gen_loss = 0.8780644771408539, disc_loss = 0.00011762983004064363
Trained batch 866 in epoch 18, gen_loss = 0.8781455111063613, disc_loss = 0.0001176330922230554
Trained batch 867 in epoch 18, gen_loss = 0.8781311319720361, disc_loss = 0.0001177429597103788
Trained batch 868 in epoch 18, gen_loss = 0.8782401025912567, disc_loss = 0.00011782018174133312
Trained batch 869 in epoch 18, gen_loss = 0.8782396855025456, disc_loss = 0.00011780560429772662
Trained batch 870 in epoch 18, gen_loss = 0.8782903998234789, disc_loss = 0.00011774992450190137
Trained batch 871 in epoch 18, gen_loss = 0.878382231869282, disc_loss = 0.00011773265428728169
Trained batch 872 in epoch 18, gen_loss = 0.8783722447502381, disc_loss = 0.00011775652747269228
Trained batch 873 in epoch 18, gen_loss = 0.8784183321064615, disc_loss = 0.00011771827530017542
Trained batch 874 in epoch 18, gen_loss = 0.8785588144574846, disc_loss = 0.00011770554022431107
Trained batch 875 in epoch 18, gen_loss = 0.8785555865530554, disc_loss = 0.00011772120015935698
Trained batch 876 in epoch 18, gen_loss = 0.8785468494198885, disc_loss = 0.0001176940334381131
Trained batch 877 in epoch 18, gen_loss = 0.878549379612699, disc_loss = 0.00011772774277748975
Trained batch 878 in epoch 18, gen_loss = 0.8784336408386187, disc_loss = 0.00011789664139633943
Trained batch 879 in epoch 18, gen_loss = 0.8782889792187647, disc_loss = 0.00011809869491282205
Trained batch 880 in epoch 18, gen_loss = 0.8782350472370152, disc_loss = 0.00011811977489786667
Trained batch 881 in epoch 18, gen_loss = 0.8781641239211673, disc_loss = 0.00011806520450428125
Trained batch 882 in epoch 18, gen_loss = 0.8781301460881735, disc_loss = 0.00011800649708356036
Trained batch 883 in epoch 18, gen_loss = 0.8782373664066263, disc_loss = 0.0001179386495898464
Trained batch 884 in epoch 18, gen_loss = 0.8781846251191392, disc_loss = 0.00011793242028018587
Trained batch 885 in epoch 18, gen_loss = 0.8780535754177963, disc_loss = 0.00011794524672240151
Trained batch 886 in epoch 18, gen_loss = 0.8780030538963223, disc_loss = 0.00011797773928478362
Trained batch 887 in epoch 18, gen_loss = 0.8778484349583721, disc_loss = 0.00011796563234515038
Trained batch 888 in epoch 18, gen_loss = 0.8777967822833324, disc_loss = 0.00011794649753375168
Trained batch 889 in epoch 18, gen_loss = 0.8777479493216183, disc_loss = 0.00011800893791199118
Trained batch 890 in epoch 18, gen_loss = 0.8779578381515913, disc_loss = 0.00011808638768859875
Trained batch 891 in epoch 18, gen_loss = 0.8779853686623509, disc_loss = 0.0001181798222283034
Trained batch 892 in epoch 18, gen_loss = 0.8780688933135414, disc_loss = 0.00011819795827301269
Trained batch 893 in epoch 18, gen_loss = 0.8780703279262688, disc_loss = 0.00011877314290882118
Trained batch 894 in epoch 18, gen_loss = 0.8781121201355364, disc_loss = 0.00011922322528588965
Trained batch 895 in epoch 18, gen_loss = 0.8781330033338496, disc_loss = 0.00011934826806379663
Trained batch 896 in epoch 18, gen_loss = 0.8782296344189341, disc_loss = 0.00011947084805174651
Trained batch 897 in epoch 18, gen_loss = 0.8782066391544512, disc_loss = 0.00011955334681050203
Trained batch 898 in epoch 18, gen_loss = 0.8781672569615424, disc_loss = 0.00011949885232513667
Trained batch 899 in epoch 18, gen_loss = 0.8782251714335547, disc_loss = 0.0001194612819542979
Trained batch 900 in epoch 18, gen_loss = 0.8780714276098914, disc_loss = 0.0001194953593938016
Trained batch 901 in epoch 18, gen_loss = 0.8781903122454684, disc_loss = 0.00011949968546572939
Trained batch 902 in epoch 18, gen_loss = 0.8783126333491219, disc_loss = 0.00011951356880094265
Trained batch 903 in epoch 18, gen_loss = 0.8782703034513819, disc_loss = 0.00011947614583193245
Trained batch 904 in epoch 18, gen_loss = 0.8783609066878894, disc_loss = 0.00011943801453636795
Trained batch 905 in epoch 18, gen_loss = 0.8783177832104513, disc_loss = 0.0001194016444116469
Trained batch 906 in epoch 18, gen_loss = 0.8783081186382878, disc_loss = 0.00011937056663835035
Trained batch 907 in epoch 18, gen_loss = 0.878241377123652, disc_loss = 0.00011945107839672082
Trained batch 908 in epoch 18, gen_loss = 0.8782802978889122, disc_loss = 0.00011953807871718814
Trained batch 909 in epoch 18, gen_loss = 0.8782113013686714, disc_loss = 0.00011962541065768564
Trained batch 910 in epoch 18, gen_loss = 0.8782653222361458, disc_loss = 0.00011965534743554144
Trained batch 911 in epoch 18, gen_loss = 0.8782434493564722, disc_loss = 0.00011961160248973644
Trained batch 912 in epoch 18, gen_loss = 0.8782052408826312, disc_loss = 0.0001195752710236725
Trained batch 913 in epoch 18, gen_loss = 0.8781727868044663, disc_loss = 0.0001196273469619725
Trained batch 914 in epoch 18, gen_loss = 0.878190093222863, disc_loss = 0.00011976454514326895
Trained batch 915 in epoch 18, gen_loss = 0.87818161752807, disc_loss = 0.0001200120471855478
Trained batch 916 in epoch 18, gen_loss = 0.8781459304212614, disc_loss = 0.00012001250199106498
Trained batch 917 in epoch 18, gen_loss = 0.8781584975896058, disc_loss = 0.00012001104007302865
Trained batch 918 in epoch 18, gen_loss = 0.8781684938011542, disc_loss = 0.00012001272238881182
Trained batch 919 in epoch 18, gen_loss = 0.8781169405449991, disc_loss = 0.00011998808593331056
Trained batch 920 in epoch 18, gen_loss = 0.8781728686261254, disc_loss = 0.00011992040317073686
Trained batch 921 in epoch 18, gen_loss = 0.8781197667768358, disc_loss = 0.00011982613050783787
Trained batch 922 in epoch 18, gen_loss = 0.8781968906667096, disc_loss = 0.00011977103433195518
Trained batch 923 in epoch 18, gen_loss = 0.8782325583747971, disc_loss = 0.0001197263267094653
Trained batch 924 in epoch 18, gen_loss = 0.8782644485138558, disc_loss = 0.00011972757904692804
Trained batch 925 in epoch 18, gen_loss = 0.8782319469663031, disc_loss = 0.00011966999996930374
Trained batch 926 in epoch 18, gen_loss = 0.8781351155833519, disc_loss = 0.00011965819414680047
Trained batch 927 in epoch 18, gen_loss = 0.8781069079092865, disc_loss = 0.00011966403275013802
Trained batch 928 in epoch 18, gen_loss = 0.8781762264259921, disc_loss = 0.0001196415057476067
Trained batch 929 in epoch 18, gen_loss = 0.8780458789999767, disc_loss = 0.0001196455853430727
Trained batch 930 in epoch 18, gen_loss = 0.8780369759246178, disc_loss = 0.00011962107909694149
Trained batch 931 in epoch 18, gen_loss = 0.877970442687493, disc_loss = 0.0001195684781006316
Trained batch 932 in epoch 18, gen_loss = 0.8781879333437831, disc_loss = 0.00011956202713758305
Trained batch 933 in epoch 18, gen_loss = 0.878186578413659, disc_loss = 0.00011952006280365748
Trained batch 934 in epoch 18, gen_loss = 0.8780837650605064, disc_loss = 0.00011953390022490129
Trained batch 935 in epoch 18, gen_loss = 0.8780287077538987, disc_loss = 0.00011958073794156582
Trained batch 936 in epoch 18, gen_loss = 0.8778835533141072, disc_loss = 0.00011963887162006007
Trained batch 937 in epoch 18, gen_loss = 0.8778274475511457, disc_loss = 0.00011963470489081956
Trained batch 938 in epoch 18, gen_loss = 0.8778697497928485, disc_loss = 0.00011957137853065749
Trained batch 939 in epoch 18, gen_loss = 0.8779168874025345, disc_loss = 0.00011952373063630806
Trained batch 940 in epoch 18, gen_loss = 0.8778852774156901, disc_loss = 0.00011947248750150388
Trained batch 941 in epoch 18, gen_loss = 0.8778339612382738, disc_loss = 0.0001194483623288425
Trained batch 942 in epoch 18, gen_loss = 0.8779105777325837, disc_loss = 0.00011943165558890424
Trained batch 943 in epoch 18, gen_loss = 0.8779232923762273, disc_loss = 0.00011938478564458156
Trained batch 944 in epoch 18, gen_loss = 0.8780532737257619, disc_loss = 0.00011936678080625522
Trained batch 945 in epoch 18, gen_loss = 0.87808940186309, disc_loss = 0.00011938018932371636
Trained batch 946 in epoch 18, gen_loss = 0.8780545039690535, disc_loss = 0.00011934129710763681
Trained batch 947 in epoch 18, gen_loss = 0.8781071883716663, disc_loss = 0.00011937197810950721
Trained batch 948 in epoch 18, gen_loss = 0.8780427940653046, disc_loss = 0.00011940850616345997
Trained batch 949 in epoch 18, gen_loss = 0.8779962411052302, disc_loss = 0.00011933502975520433
Trained batch 950 in epoch 18, gen_loss = 0.877803771152356, disc_loss = 0.00012672108760679906
Trained batch 951 in epoch 18, gen_loss = 0.8776807369304305, disc_loss = 0.00013159087774044923
Trained batch 952 in epoch 18, gen_loss = 0.8775267192599405, disc_loss = 0.00013315699815787748
Trained batch 953 in epoch 18, gen_loss = 0.877642059788514, disc_loss = 0.00013343984832188144
Trained batch 954 in epoch 18, gen_loss = 0.877650198948945, disc_loss = 0.00013429906756522045
Trained batch 955 in epoch 18, gen_loss = 0.8774667160905056, disc_loss = 0.00013511966538328626
Trained batch 956 in epoch 18, gen_loss = 0.8773135125574771, disc_loss = 0.00013528833207550247
Trained batch 957 in epoch 18, gen_loss = 0.8773122623967229, disc_loss = 0.00013558455913447695
Trained batch 958 in epoch 18, gen_loss = 0.8773262724513431, disc_loss = 0.00013598549672039722
Trained batch 959 in epoch 18, gen_loss = 0.8772331334650516, disc_loss = 0.00013690172089203163
Trained batch 960 in epoch 18, gen_loss = 0.8772572535133759, disc_loss = 0.00013765324202172835
Trained batch 961 in epoch 18, gen_loss = 0.8771391115044853, disc_loss = 0.00014344511238464566
Trained batch 962 in epoch 18, gen_loss = 0.8773639862534909, disc_loss = 0.000144136905159897
Trained batch 963 in epoch 18, gen_loss = 0.8777085082041277, disc_loss = 0.0001446149755974302
Trained batch 964 in epoch 18, gen_loss = 0.8778203142121666, disc_loss = 0.00014472100179500086
Trained batch 965 in epoch 18, gen_loss = 0.8779647576759567, disc_loss = 0.00014492041474089168
Trained batch 966 in epoch 18, gen_loss = 0.8782102296739478, disc_loss = 0.0001449722703167063
Trained batch 967 in epoch 18, gen_loss = 0.8782001960376078, disc_loss = 0.00014503352426537043
Trained batch 968 in epoch 18, gen_loss = 0.8783291190770388, disc_loss = 0.0001452381874485589
Trained batch 969 in epoch 18, gen_loss = 0.8784316773881617, disc_loss = 0.00014585269688263767
Trained batch 970 in epoch 18, gen_loss = 0.8784478122615912, disc_loss = 0.00014629951445865384
Trained batch 971 in epoch 18, gen_loss = 0.8783653474148408, disc_loss = 0.0001465221439989345
Trained batch 972 in epoch 18, gen_loss = 0.8783805590861871, disc_loss = 0.00014671219067977317
Trained batch 973 in epoch 18, gen_loss = 0.8784650032402799, disc_loss = 0.0001468614404863301
Trained batch 974 in epoch 18, gen_loss = 0.878526638899094, disc_loss = 0.00014678034075470164
Trained batch 975 in epoch 18, gen_loss = 0.8787216221089246, disc_loss = 0.00014688501163409904
Trained batch 976 in epoch 18, gen_loss = 0.8786764622588729, disc_loss = 0.0001468493069366346
Trained batch 977 in epoch 18, gen_loss = 0.8786776563750698, disc_loss = 0.00014677870694310063
Trained batch 978 in epoch 18, gen_loss = 0.8786801673905721, disc_loss = 0.00014678889046052367
Trained batch 979 in epoch 18, gen_loss = 0.8785324536415995, disc_loss = 0.00014682633473985706
Trained batch 980 in epoch 18, gen_loss = 0.8786935816603455, disc_loss = 0.00014699666434548895
Trained batch 981 in epoch 18, gen_loss = 0.8786594013696776, disc_loss = 0.00014712021926584153
Trained batch 982 in epoch 18, gen_loss = 0.8786202989905193, disc_loss = 0.0001471245667580605
Trained batch 983 in epoch 18, gen_loss = 0.8787492605123094, disc_loss = 0.00014744037545040748
Trained batch 984 in epoch 18, gen_loss = 0.8787958039245024, disc_loss = 0.00014801697389944812
Trained batch 985 in epoch 18, gen_loss = 0.8787421022539932, disc_loss = 0.00014809684680899252
Trained batch 986 in epoch 18, gen_loss = 0.8787646550900305, disc_loss = 0.00014813710084443784
Trained batch 987 in epoch 18, gen_loss = 0.8788518930977656, disc_loss = 0.0001482050513063566
Trained batch 988 in epoch 18, gen_loss = 0.8789026602816413, disc_loss = 0.00014820773422081706
Trained batch 989 in epoch 18, gen_loss = 0.8789598231363778, disc_loss = 0.00014828111326840537
Trained batch 990 in epoch 18, gen_loss = 0.8789936584372573, disc_loss = 0.00014824663501604782
Trained batch 991 in epoch 18, gen_loss = 0.8789077661931515, disc_loss = 0.0001482722479977383
Trained batch 992 in epoch 18, gen_loss = 0.8788660402744558, disc_loss = 0.0001483838919136689
Trained batch 993 in epoch 18, gen_loss = 0.8788041034095004, disc_loss = 0.00014844020704371747
Trained batch 994 in epoch 18, gen_loss = 0.8788622101946691, disc_loss = 0.00014846367357402863
Trained batch 995 in epoch 18, gen_loss = 0.8787676689016771, disc_loss = 0.00014842169092658134
Trained batch 996 in epoch 18, gen_loss = 0.8788276300387253, disc_loss = 0.0001484033230096877
Trained batch 997 in epoch 18, gen_loss = 0.8787503563808295, disc_loss = 0.0001483359761670967
Trained batch 998 in epoch 18, gen_loss = 0.8788631061414579, disc_loss = 0.0001483319884665344
Trained batch 999 in epoch 18, gen_loss = 0.8788741180300712, disc_loss = 0.00014835610556474422
Trained batch 1000 in epoch 18, gen_loss = 0.8789010371242489, disc_loss = 0.00014842041319742757
Trained batch 1001 in epoch 18, gen_loss = 0.8788817898480002, disc_loss = 0.0001483824345702166
Trained batch 1002 in epoch 18, gen_loss = 0.8789319778130513, disc_loss = 0.00014831155661241906
Trained batch 1003 in epoch 18, gen_loss = 0.8788067577963331, disc_loss = 0.00014829634576553544
Trained batch 1004 in epoch 18, gen_loss = 0.8788819764383989, disc_loss = 0.00014825990833764878
Trained batch 1005 in epoch 18, gen_loss = 0.8788785812987485, disc_loss = 0.00014821306683168706
Trained batch 1006 in epoch 18, gen_loss = 0.8788579491067904, disc_loss = 0.0001481343656464465
Trained batch 1007 in epoch 18, gen_loss = 0.8788289397600151, disc_loss = 0.00014810833533648827
Trained batch 1008 in epoch 18, gen_loss = 0.8787958855317062, disc_loss = 0.00014813297113327068
Trained batch 1009 in epoch 18, gen_loss = 0.8789216175527856, disc_loss = 0.0001480817481429353
Trained batch 1010 in epoch 18, gen_loss = 0.8789082211981187, disc_loss = 0.00014798377300525691
Trained batch 1011 in epoch 18, gen_loss = 0.8789123590638044, disc_loss = 0.00014790464963434607
Trained batch 1012 in epoch 18, gen_loss = 0.8788709578132817, disc_loss = 0.00014780488122403547
Trained batch 1013 in epoch 18, gen_loss = 0.8789884801917293, disc_loss = 0.00014771429174733524
Trained batch 1014 in epoch 18, gen_loss = 0.8789983686555195, disc_loss = 0.0001476507476649105
Trained batch 1015 in epoch 18, gen_loss = 0.8789786589075261, disc_loss = 0.00014760267411503716
Trained batch 1016 in epoch 18, gen_loss = 0.8789268717418847, disc_loss = 0.00014766427160625557
Trained batch 1017 in epoch 18, gen_loss = 0.8789473205863375, disc_loss = 0.00014765937553750934
Trained batch 1018 in epoch 18, gen_loss = 0.878911330784151, disc_loss = 0.00014762506738348047
Trained batch 1019 in epoch 18, gen_loss = 0.8788700499955345, disc_loss = 0.00014758293895569046
Trained batch 1020 in epoch 18, gen_loss = 0.8788065564153711, disc_loss = 0.00014755302666956478
Trained batch 1021 in epoch 18, gen_loss = 0.8788665950648239, disc_loss = 0.0001474847266747372
Trained batch 1022 in epoch 18, gen_loss = 0.8788275308506464, disc_loss = 0.0001474101576505307
Trained batch 1023 in epoch 18, gen_loss = 0.8788055545301177, disc_loss = 0.00014733788145804283
Trained batch 1024 in epoch 18, gen_loss = 0.8787574513947092, disc_loss = 0.00014726312918355688
Trained batch 1025 in epoch 18, gen_loss = 0.8787210599372262, disc_loss = 0.000147175424646091
Trained batch 1026 in epoch 18, gen_loss = 0.8786797590822184, disc_loss = 0.00014714775212940434
Trained batch 1027 in epoch 18, gen_loss = 0.8787168459205776, disc_loss = 0.00014730420321648974
Trained batch 1028 in epoch 18, gen_loss = 0.8787257832966463, disc_loss = 0.00014729156819767516
Trained batch 1029 in epoch 18, gen_loss = 0.8786887249321613, disc_loss = 0.00014724273232345297
Trained batch 1030 in epoch 18, gen_loss = 0.8787710039391319, disc_loss = 0.00014718769364175047
Trained batch 1031 in epoch 18, gen_loss = 0.878798401864, disc_loss = 0.0001471049786902253
Trained batch 1032 in epoch 18, gen_loss = 0.8788263326923706, disc_loss = 0.00014702425040978584
Trained batch 1033 in epoch 18, gen_loss = 0.8788121229675337, disc_loss = 0.00014692920490189538
Trained batch 1034 in epoch 18, gen_loss = 0.878821887774168, disc_loss = 0.0001468289109815254
Trained batch 1035 in epoch 18, gen_loss = 0.8787466778373166, disc_loss = 0.00014675507483850853
Trained batch 1036 in epoch 18, gen_loss = 0.878740517876992, disc_loss = 0.00014673745559914427
Trained batch 1037 in epoch 18, gen_loss = 0.8787516232055965, disc_loss = 0.00014666831762506806
Trained batch 1038 in epoch 18, gen_loss = 0.878810262886576, disc_loss = 0.00014661843045879087
Trained batch 1039 in epoch 18, gen_loss = 0.8787866250826762, disc_loss = 0.00014660252216764584
Trained batch 1040 in epoch 18, gen_loss = 0.8788128259889674, disc_loss = 0.00014653672570933917
Trained batch 1041 in epoch 18, gen_loss = 0.8787201692755987, disc_loss = 0.0001464843593839236
Trained batch 1042 in epoch 18, gen_loss = 0.8786370735954804, disc_loss = 0.0001464375203331595
Trained batch 1043 in epoch 18, gen_loss = 0.8786678319347316, disc_loss = 0.00014636009010416946
Trained batch 1044 in epoch 18, gen_loss = 0.8786346201120951, disc_loss = 0.00014629567764854308
Trained batch 1045 in epoch 18, gen_loss = 0.8786727082319059, disc_loss = 0.00014622958381761562
Trained batch 1046 in epoch 18, gen_loss = 0.8786976483740346, disc_loss = 0.00014614765040579572
Trained batch 1047 in epoch 18, gen_loss = 0.8786452540573273, disc_loss = 0.00014607229401313704
Trained batch 1048 in epoch 18, gen_loss = 0.8785176492510124, disc_loss = 0.00014603203676931303
Trained batch 1049 in epoch 18, gen_loss = 0.8784454914501735, disc_loss = 0.00014639048413040914
Trained batch 1050 in epoch 18, gen_loss = 0.8783477204510646, disc_loss = 0.00014639491003840102
Trained batch 1051 in epoch 18, gen_loss = 0.8784462572163956, disc_loss = 0.00014645675178265338
Trained batch 1052 in epoch 18, gen_loss = 0.8784131245848573, disc_loss = 0.00014659609545938977
Trained batch 1053 in epoch 18, gen_loss = 0.8783038005770044, disc_loss = 0.00014666409167218988
Trained batch 1054 in epoch 18, gen_loss = 0.8783432060508366, disc_loss = 0.0001466370252321333
Trained batch 1055 in epoch 18, gen_loss = 0.8782558150476578, disc_loss = 0.0001467326322295831
Trained batch 1056 in epoch 18, gen_loss = 0.8782846727456929, disc_loss = 0.00014673909430275121
Trained batch 1057 in epoch 18, gen_loss = 0.8782619779299248, disc_loss = 0.00014669606056510442
Trained batch 1058 in epoch 18, gen_loss = 0.8784098254272238, disc_loss = 0.00014662710371741856
Trained batch 1059 in epoch 18, gen_loss = 0.878442220249266, disc_loss = 0.00014658310885935416
Trained batch 1060 in epoch 18, gen_loss = 0.8784930280196454, disc_loss = 0.00014655919838883245
Trained batch 1061 in epoch 18, gen_loss = 0.8784506428713179, disc_loss = 0.00014649038758965713
Trained batch 1062 in epoch 18, gen_loss = 0.8784251686322274, disc_loss = 0.00014647737752333212
Trained batch 1063 in epoch 18, gen_loss = 0.878362084801932, disc_loss = 0.00014641766928181647
Trained batch 1064 in epoch 18, gen_loss = 0.8783245151591413, disc_loss = 0.00014634441692702377
Trained batch 1065 in epoch 18, gen_loss = 0.8783542641331957, disc_loss = 0.0001462691612229888
Trained batch 1066 in epoch 18, gen_loss = 0.8783638613628469, disc_loss = 0.00014620006487367897
Trained batch 1067 in epoch 18, gen_loss = 0.878328269508001, disc_loss = 0.00014611668463116524
Trained batch 1068 in epoch 18, gen_loss = 0.8783950502343887, disc_loss = 0.0001460291031213134
Trained batch 1069 in epoch 18, gen_loss = 0.8783952621656044, disc_loss = 0.00014595063264529596
Trained batch 1070 in epoch 18, gen_loss = 0.8784621876049665, disc_loss = 0.0001459031819801688
Trained batch 1071 in epoch 18, gen_loss = 0.8784565500803848, disc_loss = 0.0001458225621528113
Trained batch 1072 in epoch 18, gen_loss = 0.8784231875171643, disc_loss = 0.00014578279437010548
Trained batch 1073 in epoch 18, gen_loss = 0.8782931529609851, disc_loss = 0.00014574732655156153
Trained batch 1074 in epoch 18, gen_loss = 0.8783243768159733, disc_loss = 0.00014568626330380306
Trained batch 1075 in epoch 18, gen_loss = 0.8783164016597776, disc_loss = 0.00014567380416250075
Trained batch 1076 in epoch 18, gen_loss = 0.8784360794857241, disc_loss = 0.00014559569852622294
Trained batch 1077 in epoch 18, gen_loss = 0.87851841739467, disc_loss = 0.0001455213156661493
Trained batch 1078 in epoch 18, gen_loss = 0.8784514610363003, disc_loss = 0.0001454381949622814
Trained batch 1079 in epoch 18, gen_loss = 0.8785020092019329, disc_loss = 0.00014540661071536036
Trained batch 1080 in epoch 18, gen_loss = 0.8785083245392975, disc_loss = 0.00014540429745619224
Trained batch 1081 in epoch 18, gen_loss = 0.8785128835278827, disc_loss = 0.00014535478964520493
Trained batch 1082 in epoch 18, gen_loss = 0.8785106858388209, disc_loss = 0.00014532616567744858
Trained batch 1083 in epoch 18, gen_loss = 0.8784685596768707, disc_loss = 0.00014541767115346663
Trained batch 1084 in epoch 18, gen_loss = 0.8784772029120801, disc_loss = 0.00014546668269775577
Trained batch 1085 in epoch 18, gen_loss = 0.8783954504884189, disc_loss = 0.00014545195828581916
Trained batch 1086 in epoch 18, gen_loss = 0.8783386197787638, disc_loss = 0.00014539321365034965
Trained batch 1087 in epoch 18, gen_loss = 0.8782769741819185, disc_loss = 0.00014535248399571334
Trained batch 1088 in epoch 18, gen_loss = 0.8782711126478141, disc_loss = 0.0001452634242014028
Trained batch 1089 in epoch 18, gen_loss = 0.8781882321069, disc_loss = 0.00014519466821760058
Trained batch 1090 in epoch 18, gen_loss = 0.8782016566649803, disc_loss = 0.00014510978945533298
Trained batch 1091 in epoch 18, gen_loss = 0.8780513696181469, disc_loss = 0.0001451117030481681
Trained batch 1092 in epoch 18, gen_loss = 0.878098373061893, disc_loss = 0.00014514043233254055
Trained batch 1093 in epoch 18, gen_loss = 0.8780633515697075, disc_loss = 0.0001450605328497062
Trained batch 1094 in epoch 18, gen_loss = 0.8780780293081449, disc_loss = 0.00014507312400515837
Trained batch 1095 in epoch 18, gen_loss = 0.8781483333802571, disc_loss = 0.00014509829946683254
Trained batch 1096 in epoch 18, gen_loss = 0.8781863801459779, disc_loss = 0.00014506572557878238
Trained batch 1097 in epoch 18, gen_loss = 0.8782105262379395, disc_loss = 0.00014499547210281214
Trained batch 1098 in epoch 18, gen_loss = 0.8782474607419056, disc_loss = 0.00014492987981534842
Trained batch 1099 in epoch 18, gen_loss = 0.8782799980857156, disc_loss = 0.00014490696240086848
Trained batch 1100 in epoch 18, gen_loss = 0.8783251737920291, disc_loss = 0.000144886191727554
Trained batch 1101 in epoch 18, gen_loss = 0.8783803715788084, disc_loss = 0.00014490257971574102
Trained batch 1102 in epoch 18, gen_loss = 0.87839884927677, disc_loss = 0.00014484787064322974
Trained batch 1103 in epoch 18, gen_loss = 0.8784217930034451, disc_loss = 0.00014478952471438168
Trained batch 1104 in epoch 18, gen_loss = 0.8784953672422003, disc_loss = 0.00014478620620114136
Trained batch 1105 in epoch 18, gen_loss = 0.8784593036549863, disc_loss = 0.00014480507828095346
Trained batch 1106 in epoch 18, gen_loss = 0.8784092470882384, disc_loss = 0.00014483366947900945
Trained batch 1107 in epoch 18, gen_loss = 0.8785264807272474, disc_loss = 0.00014487260436300977
Trained batch 1108 in epoch 18, gen_loss = 0.8785935227026049, disc_loss = 0.0001451031633127513
Trained batch 1109 in epoch 18, gen_loss = 0.8785268802900572, disc_loss = 0.00014524468184914965
Trained batch 1110 in epoch 18, gen_loss = 0.8785537392249738, disc_loss = 0.00014519127911622853
Trained batch 1111 in epoch 18, gen_loss = 0.8786201516715743, disc_loss = 0.00014514976612399746
Trained batch 1112 in epoch 18, gen_loss = 0.8786939843110104, disc_loss = 0.00014508465958081092
Trained batch 1113 in epoch 18, gen_loss = 0.8787254461052174, disc_loss = 0.00014503263214848543
Trained batch 1114 in epoch 18, gen_loss = 0.8788080491827208, disc_loss = 0.00014499047388504845
Trained batch 1115 in epoch 18, gen_loss = 0.8787717067746705, disc_loss = 0.00014499841709886732
Trained batch 1116 in epoch 18, gen_loss = 0.8787317406202707, disc_loss = 0.00014503732918920193
Trained batch 1117 in epoch 18, gen_loss = 0.8787370945238683, disc_loss = 0.0001450169857891332
Trained batch 1118 in epoch 18, gen_loss = 0.8787977282653652, disc_loss = 0.00014504310730429116
Trained batch 1119 in epoch 18, gen_loss = 0.8787386705300637, disc_loss = 0.00014504831805360092
Trained batch 1120 in epoch 18, gen_loss = 0.8788342075513794, disc_loss = 0.00014510114958643665
Trained batch 1121 in epoch 18, gen_loss = 0.8787793393334815, disc_loss = 0.00014509783851895534
Trained batch 1122 in epoch 18, gen_loss = 0.8787378074330935, disc_loss = 0.00014505975349341936
Trained batch 1123 in epoch 18, gen_loss = 0.8787494691559429, disc_loss = 0.000145042210921971
Trained batch 1124 in epoch 18, gen_loss = 0.878712528069814, disc_loss = 0.00014509863774098144
Trained batch 1125 in epoch 18, gen_loss = 0.8787524199930432, disc_loss = 0.00014514238138668768
Trained batch 1126 in epoch 18, gen_loss = 0.8786612506344346, disc_loss = 0.0001450735775169145
Trained batch 1127 in epoch 18, gen_loss = 0.878748967715189, disc_loss = 0.00014504637602253396
Trained batch 1128 in epoch 18, gen_loss = 0.8787105477310262, disc_loss = 0.00014508084281940285
Trained batch 1129 in epoch 18, gen_loss = 0.8786917087251106, disc_loss = 0.0001450222266411184
Trained batch 1130 in epoch 18, gen_loss = 0.8787745332738975, disc_loss = 0.000144990585019307
Trained batch 1131 in epoch 18, gen_loss = 0.8787886346081542, disc_loss = 0.00014502420305268155
Trained batch 1132 in epoch 18, gen_loss = 0.8788018832665466, disc_loss = 0.00014498244241655875
Trained batch 1133 in epoch 18, gen_loss = 0.878884676745329, disc_loss = 0.00014500696375935584
Trained batch 1134 in epoch 18, gen_loss = 0.8788657078658957, disc_loss = 0.0001452002001331149
Trained batch 1135 in epoch 18, gen_loss = 0.8789718749237733, disc_loss = 0.0001452879294056786
Trained batch 1136 in epoch 18, gen_loss = 0.8789049443070471, disc_loss = 0.00014523630028571822
Trained batch 1137 in epoch 18, gen_loss = 0.8790212268883817, disc_loss = 0.00014517165693724615
Trained batch 1138 in epoch 18, gen_loss = 0.8790091751854706, disc_loss = 0.00014513585277002805
Trained batch 1139 in epoch 18, gen_loss = 0.8789342219369454, disc_loss = 0.0001451228780544561
Trained batch 1140 in epoch 18, gen_loss = 0.878986756703396, disc_loss = 0.00014509946569049136
Trained batch 1141 in epoch 18, gen_loss = 0.8789930245504697, disc_loss = 0.00014505484086170734
Trained batch 1142 in epoch 18, gen_loss = 0.8790095633617745, disc_loss = 0.00014505728568834592
Trained batch 1143 in epoch 18, gen_loss = 0.8789076352348695, disc_loss = 0.00014501301230965212
Trained batch 1144 in epoch 18, gen_loss = 0.8789186560951466, disc_loss = 0.00014509783576252284
Trained batch 1145 in epoch 18, gen_loss = 0.8788878593145241, disc_loss = 0.00014537048583846099
Trained batch 1146 in epoch 18, gen_loss = 0.8788407812351337, disc_loss = 0.00014537314507448432
Trained batch 1147 in epoch 18, gen_loss = 0.8787928387678459, disc_loss = 0.00014533793286895295
Trained batch 1148 in epoch 18, gen_loss = 0.8787247566060464, disc_loss = 0.0001453181662679793
Trained batch 1149 in epoch 18, gen_loss = 0.8787341972019361, disc_loss = 0.0001453196138122028
Trained batch 1150 in epoch 18, gen_loss = 0.8787223575013705, disc_loss = 0.0001452528421807665
Trained batch 1151 in epoch 18, gen_loss = 0.8787050461396575, disc_loss = 0.00014526272966008946
Trained batch 1152 in epoch 18, gen_loss = 0.8787168538373962, disc_loss = 0.00014546133206907563
Trained batch 1153 in epoch 18, gen_loss = 0.8787702678910988, disc_loss = 0.0001454635162355749
Trained batch 1154 in epoch 18, gen_loss = 0.8786919482858666, disc_loss = 0.0001454666683603294
Trained batch 1155 in epoch 18, gen_loss = 0.8786736150307639, disc_loss = 0.00014552842201416804
Trained batch 1156 in epoch 18, gen_loss = 0.8787439121392233, disc_loss = 0.00014557339326794381
Trained batch 1157 in epoch 18, gen_loss = 0.8787780429312191, disc_loss = 0.00014561890929111297
Trained batch 1158 in epoch 18, gen_loss = 0.8787867603783365, disc_loss = 0.00014591380744098043
Trained batch 1159 in epoch 18, gen_loss = 0.8788160235203546, disc_loss = 0.0001460285248993324
Trained batch 1160 in epoch 18, gen_loss = 0.8788114873937858, disc_loss = 0.00014604800012706968
Trained batch 1161 in epoch 18, gen_loss = 0.8789374116878707, disc_loss = 0.00014608393823386834
Trained batch 1162 in epoch 18, gen_loss = 0.8788919960335217, disc_loss = 0.00014606773313354627
Trained batch 1163 in epoch 18, gen_loss = 0.8789165774776354, disc_loss = 0.00014602409756315463
Trained batch 1164 in epoch 18, gen_loss = 0.8789981276180611, disc_loss = 0.00014597167566160336
Trained batch 1165 in epoch 18, gen_loss = 0.8790646775611269, disc_loss = 0.00014594549022436338
Trained batch 1166 in epoch 18, gen_loss = 0.8790681640511409, disc_loss = 0.00014591027322758868
Trained batch 1167 in epoch 18, gen_loss = 0.8789434181398725, disc_loss = 0.00014586915821606977
Trained batch 1168 in epoch 18, gen_loss = 0.8789223290285154, disc_loss = 0.00014582722890482067
Trained batch 1169 in epoch 18, gen_loss = 0.8789742478957543, disc_loss = 0.0001457802405607992
Trained batch 1170 in epoch 18, gen_loss = 0.8790129590095566, disc_loss = 0.00014578077226056938
Trained batch 1171 in epoch 18, gen_loss = 0.8791407416908408, disc_loss = 0.0001457518601269132
Trained batch 1172 in epoch 18, gen_loss = 0.8790648682749587, disc_loss = 0.00014568709458199366
Trained batch 1173 in epoch 18, gen_loss = 0.8790486100077426, disc_loss = 0.0001456270076055982
Trained batch 1174 in epoch 18, gen_loss = 0.8790731174895104, disc_loss = 0.00014557219199908084
Trained batch 1175 in epoch 18, gen_loss = 0.8792285729123621, disc_loss = 0.00014560867200652
Trained batch 1176 in epoch 18, gen_loss = 0.8793490571598938, disc_loss = 0.00014563650863655896
Trained batch 1177 in epoch 18, gen_loss = 0.8792777371629187, disc_loss = 0.0001456527364473517
Trained batch 1178 in epoch 18, gen_loss = 0.879198345468649, disc_loss = 0.00014570356601775834
Trained batch 1179 in epoch 18, gen_loss = 0.879218622233908, disc_loss = 0.00014576260369506336
Trained batch 1180 in epoch 18, gen_loss = 0.8792238175414762, disc_loss = 0.00014570824473413282
Trained batch 1181 in epoch 18, gen_loss = 0.8792140438976224, disc_loss = 0.00014563796785588683
Trained batch 1182 in epoch 18, gen_loss = 0.879204367089856, disc_loss = 0.00014560715807545227
Trained batch 1183 in epoch 18, gen_loss = 0.8792279224238686, disc_loss = 0.00014566845905429127
Trained batch 1184 in epoch 18, gen_loss = 0.879222398166415, disc_loss = 0.0001456591565333128
Trained batch 1185 in epoch 18, gen_loss = 0.8791765002737962, disc_loss = 0.00014562378814606398
Trained batch 1186 in epoch 18, gen_loss = 0.8791168006207628, disc_loss = 0.00014555559130612563
Trained batch 1187 in epoch 18, gen_loss = 0.8791018367215038, disc_loss = 0.00014555237716935894
Trained batch 1188 in epoch 18, gen_loss = 0.8789624791369908, disc_loss = 0.00014550107506294642
Trained batch 1189 in epoch 18, gen_loss = 0.878869836520748, disc_loss = 0.00014870935095537223
Trained batch 1190 in epoch 18, gen_loss = 0.8789891056109636, disc_loss = 0.000148926665948898
Trained batch 1191 in epoch 18, gen_loss = 0.8789977979840048, disc_loss = 0.00014901331795826137
Trained batch 1192 in epoch 18, gen_loss = 0.8790275827237567, disc_loss = 0.00014921635846219108
Trained batch 1193 in epoch 18, gen_loss = 0.8790814220106582, disc_loss = 0.0001495333450244651
Trained batch 1194 in epoch 18, gen_loss = 0.879073911680836, disc_loss = 0.00015013289214883908
Trained batch 1195 in epoch 18, gen_loss = 0.8790714071945204, disc_loss = 0.00015053821401955287
Trained batch 1196 in epoch 18, gen_loss = 0.8791166523046661, disc_loss = 0.0001506267637330714
Trained batch 1197 in epoch 18, gen_loss = 0.8792509576912118, disc_loss = 0.00015083874062723335
Trained batch 1198 in epoch 18, gen_loss = 0.8792247056364516, disc_loss = 0.00015099252787278557
Trained batch 1199 in epoch 18, gen_loss = 0.8791660703221957, disc_loss = 0.0001512957932845893
Trained batch 1200 in epoch 18, gen_loss = 0.8791529525328834, disc_loss = 0.00015131813586937386
Trained batch 1201 in epoch 18, gen_loss = 0.87924626707634, disc_loss = 0.00015148427395821537
Trained batch 1202 in epoch 18, gen_loss = 0.8793310608748882, disc_loss = 0.00015203254802821878
Trained batch 1203 in epoch 18, gen_loss = 0.8792915343248171, disc_loss = 0.0001522819227352632
Trained batch 1204 in epoch 18, gen_loss = 0.8792952541493776, disc_loss = 0.00015254615600082224
Trained batch 1205 in epoch 18, gen_loss = 0.8792297427432849, disc_loss = 0.00015284561660619251
Trained batch 1206 in epoch 18, gen_loss = 0.8791528098229643, disc_loss = 0.00015306825019364121
Trained batch 1207 in epoch 18, gen_loss = 0.8792677170886899, disc_loss = 0.00015328812462078514
Trained batch 1208 in epoch 18, gen_loss = 0.8792685186498119, disc_loss = 0.00015343417602274324
Trained batch 1209 in epoch 18, gen_loss = 0.8791931987793977, disc_loss = 0.00015364863435280305
Trained batch 1210 in epoch 18, gen_loss = 0.8791858399829817, disc_loss = 0.0001537372497996728
Trained batch 1211 in epoch 18, gen_loss = 0.8792391232531457, disc_loss = 0.00015384648868168352
Trained batch 1212 in epoch 18, gen_loss = 0.8791961669921875, disc_loss = 0.00015387230221733858
Trained batch 1213 in epoch 18, gen_loss = 0.8792181593385914, disc_loss = 0.00015382373676941897
Trained batch 1214 in epoch 18, gen_loss = 0.8792127910955453, disc_loss = 0.00015383527052520253
Trained batch 1215 in epoch 18, gen_loss = 0.8792227860049981, disc_loss = 0.00015379383306947747
Trained batch 1216 in epoch 18, gen_loss = 0.8792763740289574, disc_loss = 0.0001537654231066979
Trained batch 1217 in epoch 18, gen_loss = 0.8793071092447428, disc_loss = 0.00015373229717208117
Trained batch 1218 in epoch 18, gen_loss = 0.8792568618298751, disc_loss = 0.00015374368284579227
Trained batch 1219 in epoch 18, gen_loss = 0.8793296204727205, disc_loss = 0.0001536816845846708
Trained batch 1220 in epoch 18, gen_loss = 0.8793165175569145, disc_loss = 0.00015387271570458335
Trained batch 1221 in epoch 18, gen_loss = 0.8792182728526245, disc_loss = 0.00015443540034446894
Trained batch 1222 in epoch 18, gen_loss = 0.8791774198936811, disc_loss = 0.00015444897963846378
Trained batch 1223 in epoch 18, gen_loss = 0.8792633490722164, disc_loss = 0.00015447948659855126
Trained batch 1224 in epoch 18, gen_loss = 0.8792423332953939, disc_loss = 0.00015449401256402632
Trained batch 1225 in epoch 18, gen_loss = 0.8791745620100572, disc_loss = 0.00015452199643466876
Trained batch 1226 in epoch 18, gen_loss = 0.879070894982432, disc_loss = 0.00015450055564349247
Trained batch 1227 in epoch 18, gen_loss = 0.8790709195288462, disc_loss = 0.00015444179160480333
Trained batch 1228 in epoch 18, gen_loss = 0.8790596049912486, disc_loss = 0.0001543948805210246
Trained batch 1229 in epoch 18, gen_loss = 0.878944283578454, disc_loss = 0.00015454351050129473
Trained batch 1230 in epoch 18, gen_loss = 0.8789285270302011, disc_loss = 0.00015456657573407396
Trained batch 1231 in epoch 18, gen_loss = 0.8789718561358266, disc_loss = 0.00015470200216216877
Trained batch 1232 in epoch 18, gen_loss = 0.8789763683626928, disc_loss = 0.00015472948570663145
Trained batch 1233 in epoch 18, gen_loss = 0.8789832080009498, disc_loss = 0.00015467683124886444
Trained batch 1234 in epoch 18, gen_loss = 0.8790346643220075, disc_loss = 0.00015466898006162236
Trained batch 1235 in epoch 18, gen_loss = 0.8791177184064797, disc_loss = 0.00015470963163296357
Trained batch 1236 in epoch 18, gen_loss = 0.8790556611606163, disc_loss = 0.00015477274665457954
Trained batch 1237 in epoch 18, gen_loss = 0.8790078327806008, disc_loss = 0.00015482598950101198
Trained batch 1238 in epoch 18, gen_loss = 0.8789536873595767, disc_loss = 0.00015490341859785003
Trained batch 1239 in epoch 18, gen_loss = 0.8789476421090865, disc_loss = 0.00015490964261780684
Trained batch 1240 in epoch 18, gen_loss = 0.8789248071208681, disc_loss = 0.00015488397520182126
Trained batch 1241 in epoch 18, gen_loss = 0.878908567910417, disc_loss = 0.00015481666392682254
Trained batch 1242 in epoch 18, gen_loss = 0.8789642330915431, disc_loss = 0.00015479671564941707
Trained batch 1243 in epoch 18, gen_loss = 0.8789408321932581, disc_loss = 0.00015473569610812218
Trained batch 1244 in epoch 18, gen_loss = 0.8788729647555983, disc_loss = 0.0001546996052010615
Trained batch 1245 in epoch 18, gen_loss = 0.8788979278330245, disc_loss = 0.0001546430949063646
Trained batch 1246 in epoch 18, gen_loss = 0.8788513661195683, disc_loss = 0.00015457495969359175
Trained batch 1247 in epoch 18, gen_loss = 0.8789040279120971, disc_loss = 0.00015454081628481968
Trained batch 1248 in epoch 18, gen_loss = 0.8789532099178641, disc_loss = 0.00015454777770401598
Trained batch 1249 in epoch 18, gen_loss = 0.8789318118572235, disc_loss = 0.00015452303194615525
Trained batch 1250 in epoch 18, gen_loss = 0.8788923179026511, disc_loss = 0.00015452810187647166
Trained batch 1251 in epoch 18, gen_loss = 0.8788700378455293, disc_loss = 0.00015474332353689602
Trained batch 1252 in epoch 18, gen_loss = 0.8788835390129759, disc_loss = 0.00015473115843514382
Trained batch 1253 in epoch 18, gen_loss = 0.8788883695096681, disc_loss = 0.00015472547459813706
Trained batch 1254 in epoch 18, gen_loss = 0.8789633460253833, disc_loss = 0.00015470404488364314
Trained batch 1255 in epoch 18, gen_loss = 0.8788713589310646, disc_loss = 0.00015481392476176322
Trained batch 1256 in epoch 18, gen_loss = 0.87887510825645, disc_loss = 0.00015491211177920053
Trained batch 1257 in epoch 18, gen_loss = 0.8787850307356951, disc_loss = 0.00015503721457982598
Trained batch 1258 in epoch 18, gen_loss = 0.8788007767641706, disc_loss = 0.00015501111732923716
Trained batch 1259 in epoch 18, gen_loss = 0.8787377497979573, disc_loss = 0.000155066514404704
Trained batch 1260 in epoch 18, gen_loss = 0.8786550520621624, disc_loss = 0.000155072532426805
Trained batch 1261 in epoch 18, gen_loss = 0.8786527624504313, disc_loss = 0.00015505893272474587
Trained batch 1262 in epoch 18, gen_loss = 0.8786804411303686, disc_loss = 0.0001551631481181128
Trained batch 1263 in epoch 18, gen_loss = 0.8785829216807703, disc_loss = 0.000155389745035031
Trained batch 1264 in epoch 18, gen_loss = 0.878661637343908, disc_loss = 0.00015565305162281473
Trained batch 1265 in epoch 18, gen_loss = 0.8786884350422622, disc_loss = 0.0001556643756535881
Trained batch 1266 in epoch 18, gen_loss = 0.8786745963834267, disc_loss = 0.00015563783870929364
Trained batch 1267 in epoch 18, gen_loss = 0.8786870581024453, disc_loss = 0.00015558312564449916
Trained batch 1268 in epoch 18, gen_loss = 0.878682268520713, disc_loss = 0.00015552463212292777
Trained batch 1269 in epoch 18, gen_loss = 0.8786540800661553, disc_loss = 0.00015545925574927632
Trained batch 1270 in epoch 18, gen_loss = 0.878650583496814, disc_loss = 0.00015540341102047075
Trained batch 1271 in epoch 18, gen_loss = 0.8786386321738081, disc_loss = 0.0001553204763426404
Trained batch 1272 in epoch 18, gen_loss = 0.8786199493662916, disc_loss = 0.00015533686217800998
Trained batch 1273 in epoch 18, gen_loss = 0.8786885744922763, disc_loss = 0.00015535369050979897
Trained batch 1274 in epoch 18, gen_loss = 0.8786651329900704, disc_loss = 0.00015529417862268803
Trained batch 1275 in epoch 18, gen_loss = 0.8786497453350258, disc_loss = 0.00015527918633303207
Trained batch 1276 in epoch 18, gen_loss = 0.8786750222522016, disc_loss = 0.0001551971274542297
Trained batch 1277 in epoch 18, gen_loss = 0.8785921865972182, disc_loss = 0.00015520314999561098
Trained batch 1278 in epoch 18, gen_loss = 0.8785834857688647, disc_loss = 0.00015522547921827906
Trained batch 1279 in epoch 18, gen_loss = 0.8785995075013489, disc_loss = 0.00015517785491852009
Trained batch 1280 in epoch 18, gen_loss = 0.8786375707336741, disc_loss = 0.00015511209250198405
Trained batch 1281 in epoch 18, gen_loss = 0.8786243408127992, disc_loss = 0.00015506857304336023
Trained batch 1282 in epoch 18, gen_loss = 0.8786571192629896, disc_loss = 0.00015501765942279778
Trained batch 1283 in epoch 18, gen_loss = 0.8786769258641751, disc_loss = 0.0001549802754229193
Trained batch 1284 in epoch 18, gen_loss = 0.8786224335084165, disc_loss = 0.00015495918169780725
Trained batch 1285 in epoch 18, gen_loss = 0.878661908962493, disc_loss = 0.00015500694644853943
Trained batch 1286 in epoch 18, gen_loss = 0.8787049646977778, disc_loss = 0.00015497558818776928
Trained batch 1287 in epoch 18, gen_loss = 0.8786418007119842, disc_loss = 0.00015490218406993792
Trained batch 1288 in epoch 18, gen_loss = 0.8786065658457618, disc_loss = 0.00015483633000373839
Trained batch 1289 in epoch 18, gen_loss = 0.8785664158736088, disc_loss = 0.0001548204838527031
Trained batch 1290 in epoch 18, gen_loss = 0.8785909312257094, disc_loss = 0.00015478764388690062
Trained batch 1291 in epoch 18, gen_loss = 0.8786528722697368, disc_loss = 0.00015477204854874411
Trained batch 1292 in epoch 18, gen_loss = 0.8787305592937426, disc_loss = 0.00015476240582633778
Trained batch 1293 in epoch 18, gen_loss = 0.8786889298069054, disc_loss = 0.000154706803705562
Trained batch 1294 in epoch 18, gen_loss = 0.8786809614726475, disc_loss = 0.00015463837360964124
Trained batch 1295 in epoch 18, gen_loss = 0.8785902373032806, disc_loss = 0.00015468301529117414
Trained batch 1296 in epoch 18, gen_loss = 0.8785740055758492, disc_loss = 0.0001546997956592039
Trained batch 1297 in epoch 18, gen_loss = 0.878588628419926, disc_loss = 0.00015470589763142824
Trained batch 1298 in epoch 18, gen_loss = 0.878547359742597, disc_loss = 0.0001546575329427355
Trained batch 1299 in epoch 18, gen_loss = 0.8785416479294117, disc_loss = 0.0001546271261927009
Trained batch 1300 in epoch 18, gen_loss = 0.8785726275927832, disc_loss = 0.00015457683806545635
Trained batch 1301 in epoch 18, gen_loss = 0.8785570090359074, disc_loss = 0.00015456794355455902
Trained batch 1302 in epoch 18, gen_loss = 0.8784575605520539, disc_loss = 0.0001545616653669234
Trained batch 1303 in epoch 18, gen_loss = 0.8783705936162018, disc_loss = 0.00015451804724789941
Trained batch 1304 in epoch 18, gen_loss = 0.8783452968944535, disc_loss = 0.00015445985049977222
Trained batch 1305 in epoch 18, gen_loss = 0.878322428391867, disc_loss = 0.00015439955152915812
Trained batch 1306 in epoch 18, gen_loss = 0.8783243663363905, disc_loss = 0.00015434270939470305
Trained batch 1307 in epoch 18, gen_loss = 0.8782075386072882, disc_loss = 0.0001543917564889441
Trained batch 1308 in epoch 18, gen_loss = 0.8781844711740842, disc_loss = 0.00015439255575796539
Trained batch 1309 in epoch 18, gen_loss = 0.8781816640428004, disc_loss = 0.0001543669472848428
Trained batch 1310 in epoch 18, gen_loss = 0.8781201638036971, disc_loss = 0.00015445260187979678
Trained batch 1311 in epoch 18, gen_loss = 0.878141800441393, disc_loss = 0.00015443104591279888
Trained batch 1312 in epoch 18, gen_loss = 0.878040974229143, disc_loss = 0.0001545001808687816
Trained batch 1313 in epoch 18, gen_loss = 0.8780136538422816, disc_loss = 0.00015456655331048478
Trained batch 1314 in epoch 18, gen_loss = 0.8780437702008527, disc_loss = 0.00015455206614669356
Trained batch 1315 in epoch 18, gen_loss = 0.8780366259324152, disc_loss = 0.00015477951624054577
Trained batch 1316 in epoch 18, gen_loss = 0.878037586842148, disc_loss = 0.00015512631183404237
Trained batch 1317 in epoch 18, gen_loss = 0.878056374639951, disc_loss = 0.0001551828731193415
Trained batch 1318 in epoch 18, gen_loss = 0.8780959471777771, disc_loss = 0.00015522346359798
Trained batch 1319 in epoch 18, gen_loss = 0.8780493943980245, disc_loss = 0.00015531098755618036
Trained batch 1320 in epoch 18, gen_loss = 0.8780589295462349, disc_loss = 0.00015538094153412372
Trained batch 1321 in epoch 18, gen_loss = 0.8780235637785266, disc_loss = 0.00015540589508574116
Trained batch 1322 in epoch 18, gen_loss = 0.8780285369151484, disc_loss = 0.00015538570225430274
Trained batch 1323 in epoch 18, gen_loss = 0.8779475890617716, disc_loss = 0.00015548960712588508
Trained batch 1324 in epoch 18, gen_loss = 0.8779069987782893, disc_loss = 0.00015551922537544567
Trained batch 1325 in epoch 18, gen_loss = 0.8778935707262738, disc_loss = 0.00015552525822209128
Trained batch 1326 in epoch 18, gen_loss = 0.8778213485345503, disc_loss = 0.00015557403275074638
Trained batch 1327 in epoch 18, gen_loss = 0.8778633786342949, disc_loss = 0.0001556302694366587
Trained batch 1328 in epoch 18, gen_loss = 0.8778169687481372, disc_loss = 0.00015569656578698837
Trained batch 1329 in epoch 18, gen_loss = 0.8778151602225196, disc_loss = 0.00015569713448753748
Trained batch 1330 in epoch 18, gen_loss = 0.8778332531407397, disc_loss = 0.00015566974321730467
Trained batch 1331 in epoch 18, gen_loss = 0.877831659562237, disc_loss = 0.00015563478006367073
Trained batch 1332 in epoch 18, gen_loss = 0.8777651476931589, disc_loss = 0.0001555742234894999
Trained batch 1333 in epoch 18, gen_loss = 0.8777578074088518, disc_loss = 0.00015558578064204425
Trained batch 1334 in epoch 18, gen_loss = 0.8777844654933343, disc_loss = 0.00015564829243865032
Trained batch 1335 in epoch 18, gen_loss = 0.8776819613165484, disc_loss = 0.00015578506230406287
Trained batch 1336 in epoch 18, gen_loss = 0.8776776959134646, disc_loss = 0.00015588230009581865
Trained batch 1337 in epoch 18, gen_loss = 0.8776236358244858, disc_loss = 0.00015589608863263735
Trained batch 1338 in epoch 18, gen_loss = 0.8776244887493724, disc_loss = 0.00015594225348457847
Trained batch 1339 in epoch 18, gen_loss = 0.8776329520033367, disc_loss = 0.00015595038917737514
Trained batch 1340 in epoch 18, gen_loss = 0.8776653147206033, disc_loss = 0.00015594626233515752
Trained batch 1341 in epoch 18, gen_loss = 0.8777325001896404, disc_loss = 0.00015588094416012343
Trained batch 1342 in epoch 18, gen_loss = 0.877716271937648, disc_loss = 0.00015586105546363084
Trained batch 1343 in epoch 18, gen_loss = 0.8777627696150115, disc_loss = 0.00015586967023886072
Trained batch 1344 in epoch 18, gen_loss = 0.8778058652984165, disc_loss = 0.00015588189465717367
Trained batch 1345 in epoch 18, gen_loss = 0.8778466844452437, disc_loss = 0.00015587397410989605
Trained batch 1346 in epoch 18, gen_loss = 0.8778307650296353, disc_loss = 0.00015580715606953262
Trained batch 1347 in epoch 18, gen_loss = 0.8778496093672178, disc_loss = 0.00015575622605852152
Trained batch 1348 in epoch 18, gen_loss = 0.8778582409278298, disc_loss = 0.0001557570026027283
Trained batch 1349 in epoch 18, gen_loss = 0.8779886029384755, disc_loss = 0.0001557995496895509
Trained batch 1350 in epoch 18, gen_loss = 0.8779463654178589, disc_loss = 0.0001559416780244493
Trained batch 1351 in epoch 18, gen_loss = 0.8779573118721945, disc_loss = 0.0001559769715474038
Trained batch 1352 in epoch 18, gen_loss = 0.8779829394262276, disc_loss = 0.00015592484017832347
Trained batch 1353 in epoch 18, gen_loss = 0.8779842066447879, disc_loss = 0.00015589301702128813
Trained batch 1354 in epoch 18, gen_loss = 0.8780540776868588, disc_loss = 0.00015589738166628996
Trained batch 1355 in epoch 18, gen_loss = 0.8780791613556291, disc_loss = 0.0001558779375871886
Trained batch 1356 in epoch 18, gen_loss = 0.8780616654046072, disc_loss = 0.00015582110636045554
Trained batch 1357 in epoch 18, gen_loss = 0.8781065244298971, disc_loss = 0.00015575270316059824
Trained batch 1358 in epoch 18, gen_loss = 0.8780901048269405, disc_loss = 0.00015568372889459057
Trained batch 1359 in epoch 18, gen_loss = 0.8780452714246862, disc_loss = 0.00015566456914337538
Trained batch 1360 in epoch 18, gen_loss = 0.8780298859297047, disc_loss = 0.0001556580764045039
Trained batch 1361 in epoch 18, gen_loss = 0.8780209427363022, disc_loss = 0.00015564575766806597
Trained batch 1362 in epoch 18, gen_loss = 0.8780265131245093, disc_loss = 0.0001555885504003647
Trained batch 1363 in epoch 18, gen_loss = 0.8780395288096845, disc_loss = 0.00015551656843931636
Trained batch 1364 in epoch 18, gen_loss = 0.8780855460481329, disc_loss = 0.00015545444882693598
Trained batch 1365 in epoch 18, gen_loss = 0.8781342220603111, disc_loss = 0.00015543118978090435
Trained batch 1366 in epoch 18, gen_loss = 0.8780710847602766, disc_loss = 0.00015536224568042043
Trained batch 1367 in epoch 18, gen_loss = 0.8780561180142631, disc_loss = 0.00015529907501087104
Trained batch 1368 in epoch 18, gen_loss = 0.8780918148331959, disc_loss = 0.0001552259808079395
Trained batch 1369 in epoch 18, gen_loss = 0.878047651095982, disc_loss = 0.00015515486359412282
Trained batch 1370 in epoch 18, gen_loss = 0.8780540983925589, disc_loss = 0.00015508134494837745
Trained batch 1371 in epoch 18, gen_loss = 0.8780655228796228, disc_loss = 0.00015499931237769466
Trained batch 1372 in epoch 18, gen_loss = 0.87805312455178, disc_loss = 0.00015494549700899426
Trained batch 1373 in epoch 18, gen_loss = 0.8780731770929812, disc_loss = 0.0001549295028075142
Trained batch 1374 in epoch 18, gen_loss = 0.8780837332552129, disc_loss = 0.0001548597060715441
Trained batch 1375 in epoch 18, gen_loss = 0.8780288559406303, disc_loss = 0.000154809458424922
Trained batch 1376 in epoch 18, gen_loss = 0.8780541703505367, disc_loss = 0.00015477466680374627
Trained batch 1377 in epoch 18, gen_loss = 0.8780518364058524, disc_loss = 0.0001547035135392384
Trained batch 1378 in epoch 18, gen_loss = 0.8780954503511673, disc_loss = 0.00015463043797601733
Trained batch 1379 in epoch 18, gen_loss = 0.8780824264322502, disc_loss = 0.00015458572440326426
Trained batch 1380 in epoch 18, gen_loss = 0.8780493669368321, disc_loss = 0.00015455195325314052
Trained batch 1381 in epoch 18, gen_loss = 0.8780367303256879, disc_loss = 0.0001544673557060054
Trained batch 1382 in epoch 18, gen_loss = 0.877981751402995, disc_loss = 0.00015440654086001842
Trained batch 1383 in epoch 18, gen_loss = 0.8780781773559619, disc_loss = 0.0001543578560324411
Trained batch 1384 in epoch 18, gen_loss = 0.8780452798419911, disc_loss = 0.00015434083964165876
Trained batch 1385 in epoch 18, gen_loss = 0.8780791975375034, disc_loss = 0.00015431977300680848
Trained batch 1386 in epoch 18, gen_loss = 0.8780644200393083, disc_loss = 0.00015425055620248198
Trained batch 1387 in epoch 18, gen_loss = 0.8780700100601921, disc_loss = 0.00015423208197462793
Trained batch 1388 in epoch 18, gen_loss = 0.8779690338176648, disc_loss = 0.0001542214038026044
Trained batch 1389 in epoch 18, gen_loss = 0.8778734384252013, disc_loss = 0.00015418286577004037
Trained batch 1390 in epoch 18, gen_loss = 0.8779146256933616, disc_loss = 0.00015418916300561738
Trained batch 1391 in epoch 18, gen_loss = 0.8779997886854342, disc_loss = 0.00015419816966265177
Trained batch 1392 in epoch 18, gen_loss = 0.8779392876132135, disc_loss = 0.00015416399857395946
Trained batch 1393 in epoch 18, gen_loss = 0.8779780594485049, disc_loss = 0.00015412040738999115
Trained batch 1394 in epoch 18, gen_loss = 0.8779096040247162, disc_loss = 0.0001542286227362716
Trained batch 1395 in epoch 18, gen_loss = 0.8777795479256649, disc_loss = 0.00015549784180141413
Trained batch 1396 in epoch 18, gen_loss = 0.877774163024632, disc_loss = 0.00015604958152848046
Trained batch 1397 in epoch 18, gen_loss = 0.8777618249172134, disc_loss = 0.0001565008469788284
Trained batch 1398 in epoch 18, gen_loss = 0.8777644402900707, disc_loss = 0.00015654414072286207
Trained batch 1399 in epoch 18, gen_loss = 0.8777845727971622, disc_loss = 0.00015661844224658646
Trained batch 1400 in epoch 18, gen_loss = 0.8777238028037556, disc_loss = 0.00015665831950700145
Trained batch 1401 in epoch 18, gen_loss = 0.8776773104654059, disc_loss = 0.00015670158316323732
Trained batch 1402 in epoch 18, gen_loss = 0.8776761650274417, disc_loss = 0.00015679583154327577
Trained batch 1403 in epoch 18, gen_loss = 0.8777202573257294, disc_loss = 0.0001568256027563009
Trained batch 1404 in epoch 18, gen_loss = 0.8776572167237034, disc_loss = 0.00015682532054898693
Trained batch 1405 in epoch 18, gen_loss = 0.8776959437733863, disc_loss = 0.00015678646889179305
Trained batch 1406 in epoch 18, gen_loss = 0.8777593469145286, disc_loss = 0.00015677032156020596
Trained batch 1407 in epoch 18, gen_loss = 0.8776736118915406, disc_loss = 0.00015674279560006323
Trained batch 1408 in epoch 18, gen_loss = 0.8777360947441767, disc_loss = 0.00015674787587200746
Trained batch 1409 in epoch 18, gen_loss = 0.8776897968975365, disc_loss = 0.00015679601286440933
Trained batch 1410 in epoch 18, gen_loss = 0.8776768650423965, disc_loss = 0.00015688353536413664
Trained batch 1411 in epoch 18, gen_loss = 0.8777690711338865, disc_loss = 0.00015692046457503294
Trained batch 1412 in epoch 18, gen_loss = 0.8778272706485352, disc_loss = 0.00015686469345658135
Trained batch 1413 in epoch 18, gen_loss = 0.877798080064957, disc_loss = 0.00015686531900726685
Trained batch 1414 in epoch 18, gen_loss = 0.8778695223188232, disc_loss = 0.00015678955633345457
Trained batch 1415 in epoch 18, gen_loss = 0.8778216582907121, disc_loss = 0.00015673418520390888
Trained batch 1416 in epoch 18, gen_loss = 0.8778704034668001, disc_loss = 0.000156754999349527
Trained batch 1417 in epoch 18, gen_loss = 0.877823245289968, disc_loss = 0.0001567406872686308
Trained batch 1418 in epoch 18, gen_loss = 0.8778194895590419, disc_loss = 0.0001567338342906614
Trained batch 1419 in epoch 18, gen_loss = 0.877808254957199, disc_loss = 0.00015668127203420046
Trained batch 1420 in epoch 18, gen_loss = 0.877747950043836, disc_loss = 0.00015661080041617635
Trained batch 1421 in epoch 18, gen_loss = 0.8777561407384322, disc_loss = 0.00015655432281879453
Trained batch 1422 in epoch 18, gen_loss = 0.8778464249633017, disc_loss = 0.00015652040903177048
Trained batch 1423 in epoch 18, gen_loss = 0.8778585652203372, disc_loss = 0.00015652918307423942
Trained batch 1424 in epoch 18, gen_loss = 0.8778277103942738, disc_loss = 0.00015668699186981508
Trained batch 1425 in epoch 18, gen_loss = 0.8778229925943457, disc_loss = 0.00015670847658795823
Trained batch 1426 in epoch 18, gen_loss = 0.8778179734423183, disc_loss = 0.0001567645216781317
Trained batch 1427 in epoch 18, gen_loss = 0.8778429289324945, disc_loss = 0.0001567683372055852
Trained batch 1428 in epoch 18, gen_loss = 0.8778319357991469, disc_loss = 0.00015675921383598315
Trained batch 1429 in epoch 18, gen_loss = 0.8778994952465271, disc_loss = 0.00015669681862590126
Trained batch 1430 in epoch 18, gen_loss = 0.8778616602315843, disc_loss = 0.00015668519879059195
Trained batch 1431 in epoch 18, gen_loss = 0.877819510811534, disc_loss = 0.0001566949204569627
Trained batch 1432 in epoch 18, gen_loss = 0.8777349117911952, disc_loss = 0.00015668250692241247
Trained batch 1433 in epoch 18, gen_loss = 0.8777949053123905, disc_loss = 0.00015662858076791398
Trained batch 1434 in epoch 18, gen_loss = 0.8777912701048503, disc_loss = 0.00015659203835217874
Trained batch 1435 in epoch 18, gen_loss = 0.8777858553905673, disc_loss = 0.0001565226865063892
Trained batch 1436 in epoch 18, gen_loss = 0.8777445571324688, disc_loss = 0.00015648878859339437
Trained batch 1437 in epoch 18, gen_loss = 0.8777290011480222, disc_loss = 0.00015644518868064347
Trained batch 1438 in epoch 18, gen_loss = 0.8777328982711087, disc_loss = 0.00015639661069144495
Trained batch 1439 in epoch 18, gen_loss = 0.8777410954650905, disc_loss = 0.00015634448564267385
Trained batch 1440 in epoch 18, gen_loss = 0.8777832356200791, disc_loss = 0.00015640589925669353
Trained batch 1441 in epoch 18, gen_loss = 0.8777515941949228, disc_loss = 0.00015647397733885803
Trained batch 1442 in epoch 18, gen_loss = 0.8777904812032286, disc_loss = 0.00015646749172424325
Trained batch 1443 in epoch 18, gen_loss = 0.8777297831803478, disc_loss = 0.00015644663813278622
Trained batch 1444 in epoch 18, gen_loss = 0.8777060375906605, disc_loss = 0.00015640855604143422
Trained batch 1445 in epoch 18, gen_loss = 0.8776579932882907, disc_loss = 0.000156397855250033
Trained batch 1446 in epoch 18, gen_loss = 0.8777096416510296, disc_loss = 0.00015640032520608538
Trained batch 1447 in epoch 18, gen_loss = 0.877738093597125, disc_loss = 0.00015639762389115446
Trained batch 1448 in epoch 18, gen_loss = 0.8777133813391397, disc_loss = 0.00015640100081044467
Trained batch 1449 in epoch 18, gen_loss = 0.877716379206756, disc_loss = 0.00015659179858881417
Trained batch 1450 in epoch 18, gen_loss = 0.8776908692288283, disc_loss = 0.000156718848337363
Trained batch 1451 in epoch 18, gen_loss = 0.8776844015791396, disc_loss = 0.00015674484042061852
Trained batch 1452 in epoch 18, gen_loss = 0.8776987443196717, disc_loss = 0.00015667719499225097
Trained batch 1453 in epoch 18, gen_loss = 0.8776808292534525, disc_loss = 0.00015663538752138525
Trained batch 1454 in epoch 18, gen_loss = 0.8776946699906051, disc_loss = 0.00015656094312981088
Trained batch 1455 in epoch 18, gen_loss = 0.8778245942360097, disc_loss = 0.00015667183114161603
Trained batch 1456 in epoch 18, gen_loss = 0.8777639564783833, disc_loss = 0.00015667304781700775
Trained batch 1457 in epoch 18, gen_loss = 0.8777143325252952, disc_loss = 0.0001566796247051594
Trained batch 1458 in epoch 18, gen_loss = 0.8777344259519623, disc_loss = 0.0001567121525062687
Trained batch 1459 in epoch 18, gen_loss = 0.8777925984091954, disc_loss = 0.00015674709816204546
Trained batch 1460 in epoch 18, gen_loss = 0.8777596672702375, disc_loss = 0.00015674073636983386
Trained batch 1461 in epoch 18, gen_loss = 0.8777563601691485, disc_loss = 0.00015675835139964973
Trained batch 1462 in epoch 18, gen_loss = 0.8776865689948415, disc_loss = 0.0001567602035821193
Trained batch 1463 in epoch 18, gen_loss = 0.8776862688891874, disc_loss = 0.000156726192335306
Trained batch 1464 in epoch 18, gen_loss = 0.8777654334546763, disc_loss = 0.00015672669413373583
Trained batch 1465 in epoch 18, gen_loss = 0.8778390167192093, disc_loss = 0.00015665884498116642
Trained batch 1466 in epoch 18, gen_loss = 0.877703642877658, disc_loss = 0.0001567203257630756
Trained batch 1467 in epoch 18, gen_loss = 0.8776980697783852, disc_loss = 0.0001567841402652262
Trained batch 1468 in epoch 18, gen_loss = 0.8776767670175021, disc_loss = 0.00015676795140238384
Trained batch 1469 in epoch 18, gen_loss = 0.8776668256237393, disc_loss = 0.00015675548374125033
Trained batch 1470 in epoch 18, gen_loss = 0.877656085283719, disc_loss = 0.00015680460154170626
Trained batch 1471 in epoch 18, gen_loss = 0.8776331715609716, disc_loss = 0.00015683257626248988
Trained batch 1472 in epoch 18, gen_loss = 0.8776283782109547, disc_loss = 0.0001568690413607843
Trained batch 1473 in epoch 18, gen_loss = 0.8775585032544595, disc_loss = 0.00015712536323386807
Trained batch 1474 in epoch 18, gen_loss = 0.8774604272034209, disc_loss = 0.00015723442788762672
Trained batch 1475 in epoch 18, gen_loss = 0.877455739955592, disc_loss = 0.00015723893230078288
Trained batch 1476 in epoch 18, gen_loss = 0.8774814062531767, disc_loss = 0.0001572905350163396
Trained batch 1477 in epoch 18, gen_loss = 0.877350322287202, disc_loss = 0.0001575222601155309
Trained batch 1478 in epoch 18, gen_loss = 0.8773876107005029, disc_loss = 0.00015826324152072184
Trained batch 1479 in epoch 18, gen_loss = 0.8773816052320841, disc_loss = 0.00015899807336805876
Trained batch 1480 in epoch 18, gen_loss = 0.8773644133084212, disc_loss = 0.0001591772436778664
Trained batch 1481 in epoch 18, gen_loss = 0.8773027333492531, disc_loss = 0.00015923805125255257
Trained batch 1482 in epoch 18, gen_loss = 0.8772436281916103, disc_loss = 0.00015930589234455398
Trained batch 1483 in epoch 18, gen_loss = 0.8772731986489257, disc_loss = 0.0001592877105544558
Trained batch 1484 in epoch 18, gen_loss = 0.877235151220251, disc_loss = 0.00015931329629899422
Trained batch 1485 in epoch 18, gen_loss = 0.8772216557172875, disc_loss = 0.00015939897936290555
Trained batch 1486 in epoch 18, gen_loss = 0.8772114678044887, disc_loss = 0.000159428229256092
Trained batch 1487 in epoch 18, gen_loss = 0.8772812262177467, disc_loss = 0.00015946005450503983
Trained batch 1488 in epoch 18, gen_loss = 0.8772996729696414, disc_loss = 0.00015963578132721046
Trained batch 1489 in epoch 18, gen_loss = 0.8772729671241453, disc_loss = 0.00015977764418518604
Trained batch 1490 in epoch 18, gen_loss = 0.8772071512012495, disc_loss = 0.00015985808119854837
Trained batch 1491 in epoch 18, gen_loss = 0.877247038699347, disc_loss = 0.00015989016403923428
Trained batch 1492 in epoch 18, gen_loss = 0.8772777790042752, disc_loss = 0.00016000449195161025
Trained batch 1493 in epoch 18, gen_loss = 0.8772177922438427, disc_loss = 0.00016009296211281184
Trained batch 1494 in epoch 18, gen_loss = 0.8771623292096881, disc_loss = 0.0001601193953934476
Trained batch 1495 in epoch 18, gen_loss = 0.8771921097435416, disc_loss = 0.00016010461973214635
Trained batch 1496 in epoch 18, gen_loss = 0.8772781460621234, disc_loss = 0.0001601225818241531
Trained batch 1497 in epoch 18, gen_loss = 0.8772605709701736, disc_loss = 0.00016007180309046456
Trained batch 1498 in epoch 18, gen_loss = 0.8773110786066444, disc_loss = 0.00016004959659068378
Trained batch 1499 in epoch 18, gen_loss = 0.8773243187268575, disc_loss = 0.00015999842153541978
Trained batch 1500 in epoch 18, gen_loss = 0.8773189346683891, disc_loss = 0.0001600194588950365
Trained batch 1501 in epoch 18, gen_loss = 0.8773607381094947, disc_loss = 0.00016006098395275414
Trained batch 1502 in epoch 18, gen_loss = 0.8774020182079104, disc_loss = 0.00016009238503914168
Trained batch 1503 in epoch 18, gen_loss = 0.8773947597897434, disc_loss = 0.00016018604342062123
Trained batch 1504 in epoch 18, gen_loss = 0.8773919406127296, disc_loss = 0.00016029490726453445
Trained batch 1505 in epoch 18, gen_loss = 0.8773631154699313, disc_loss = 0.0001603083357047455
Trained batch 1506 in epoch 18, gen_loss = 0.8773827955828808, disc_loss = 0.000160337640993326
Trained batch 1507 in epoch 18, gen_loss = 0.8773772489249865, disc_loss = 0.00016031415307514454
Trained batch 1508 in epoch 18, gen_loss = 0.8773681097586792, disc_loss = 0.00016034291000575654
Trained batch 1509 in epoch 18, gen_loss = 0.8773298588414855, disc_loss = 0.00016048226264544027
Trained batch 1510 in epoch 18, gen_loss = 0.8774022269848559, disc_loss = 0.00016046103985573276
Trained batch 1511 in epoch 18, gen_loss = 0.8772606119986565, disc_loss = 0.00016071484563485322
Trained batch 1512 in epoch 18, gen_loss = 0.8772485544960466, disc_loss = 0.0001607786334782489
Trained batch 1513 in epoch 18, gen_loss = 0.877252979039201, disc_loss = 0.0001607719633035733
Trained batch 1514 in epoch 18, gen_loss = 0.8773170166283157, disc_loss = 0.00016073385645105602
Trained batch 1515 in epoch 18, gen_loss = 0.8772730960616336, disc_loss = 0.0001616056206618507
Trained batch 1516 in epoch 18, gen_loss = 0.8772212136082533, disc_loss = 0.0001618258909816108
Trained batch 1517 in epoch 18, gen_loss = 0.8772774283358231, disc_loss = 0.00016209291729787185
Trained batch 1518 in epoch 18, gen_loss = 0.8772738544151452, disc_loss = 0.00016224965776384342
Trained batch 1519 in epoch 18, gen_loss = 0.8772497236336533, disc_loss = 0.00016228624574403895
Trained batch 1520 in epoch 18, gen_loss = 0.8772943897673677, disc_loss = 0.0001622397124227591
Trained batch 1521 in epoch 18, gen_loss = 0.8772993050956225, disc_loss = 0.00016220909302138876
Trained batch 1522 in epoch 18, gen_loss = 0.8772873067965417, disc_loss = 0.00016217272365762724
Trained batch 1523 in epoch 18, gen_loss = 0.8773348848885438, disc_loss = 0.00016222940376169355
Trained batch 1524 in epoch 18, gen_loss = 0.8773549391793423, disc_loss = 0.00016233192440208246
Trained batch 1525 in epoch 18, gen_loss = 0.8773522961342788, disc_loss = 0.00016243281888664223
Trained batch 1526 in epoch 18, gen_loss = 0.8774495313740589, disc_loss = 0.00016255130408433986
Trained batch 1527 in epoch 18, gen_loss = 0.8774215764712289, disc_loss = 0.00016267679453896695
Trained batch 1528 in epoch 18, gen_loss = 0.8774400499227236, disc_loss = 0.00016281328097581904
Trained batch 1529 in epoch 18, gen_loss = 0.877354732525894, disc_loss = 0.00016284796773439678
Trained batch 1530 in epoch 18, gen_loss = 0.8773659674814525, disc_loss = 0.00016306209734081445
Trained batch 1531 in epoch 18, gen_loss = 0.8773631083903051, disc_loss = 0.00016355365923244227
Trained batch 1532 in epoch 18, gen_loss = 0.8773716999204503, disc_loss = 0.00016401846238504381
Trained batch 1533 in epoch 18, gen_loss = 0.8774116251428249, disc_loss = 0.00016432650318046963
Trained batch 1534 in epoch 18, gen_loss = 0.8773381746553054, disc_loss = 0.00016464502282612442
Trained batch 1535 in epoch 18, gen_loss = 0.8773279049200937, disc_loss = 0.0001647702392920299
Trained batch 1536 in epoch 18, gen_loss = 0.8773547046046484, disc_loss = 0.00016490914325323214
Trained batch 1537 in epoch 18, gen_loss = 0.8773669372221894, disc_loss = 0.0001649168464294049
Trained batch 1538 in epoch 18, gen_loss = 0.8773172872650538, disc_loss = 0.00016502087551470234
Trained batch 1539 in epoch 18, gen_loss = 0.8773631050602182, disc_loss = 0.00016497552461059258
Trained batch 1540 in epoch 18, gen_loss = 0.8773418216253549, disc_loss = 0.00016498227180084888
Trained batch 1541 in epoch 18, gen_loss = 0.8772895700272882, disc_loss = 0.0001650335870783943
Trained batch 1542 in epoch 18, gen_loss = 0.8772478596158253, disc_loss = 0.00016517089751936638
Trained batch 1543 in epoch 18, gen_loss = 0.8772494656665956, disc_loss = 0.0001652214507630749
Trained batch 1544 in epoch 18, gen_loss = 0.8772517363616178, disc_loss = 0.0001652697050680435
Trained batch 1545 in epoch 18, gen_loss = 0.8772818249147891, disc_loss = 0.00016532791310873193
Trained batch 1546 in epoch 18, gen_loss = 0.8773223614800569, disc_loss = 0.0001655241186448104
Trained batch 1547 in epoch 18, gen_loss = 0.8773306188888328, disc_loss = 0.0001656688678727399
Trained batch 1548 in epoch 18, gen_loss = 0.8772740402938937, disc_loss = 0.00016566355901736398
Trained batch 1549 in epoch 18, gen_loss = 0.8772570898840504, disc_loss = 0.00016574857345521226
Trained batch 1550 in epoch 18, gen_loss = 0.8772883967074327, disc_loss = 0.00016588671476548152
Trained batch 1551 in epoch 18, gen_loss = 0.8772531762795964, disc_loss = 0.0001659082406276116
Trained batch 1552 in epoch 18, gen_loss = 0.8772806923618182, disc_loss = 0.00016590281611324423
Trained batch 1553 in epoch 18, gen_loss = 0.8771922102382591, disc_loss = 0.00016583831286012658
Trained batch 1554 in epoch 18, gen_loss = 0.877133298993494, disc_loss = 0.00016580207885246367
Trained batch 1555 in epoch 18, gen_loss = 0.8770640957095016, disc_loss = 0.00016578382568097278
Trained batch 1556 in epoch 18, gen_loss = 0.8770579208375249, disc_loss = 0.0001657986211958968
Trained batch 1557 in epoch 18, gen_loss = 0.8771351103758169, disc_loss = 0.00016578208410715883
Trained batch 1558 in epoch 18, gen_loss = 0.8772006330389178, disc_loss = 0.00016577151616775185
Trained batch 1559 in epoch 18, gen_loss = 0.8771654096933511, disc_loss = 0.00016574210370750873
Trained batch 1560 in epoch 18, gen_loss = 0.8771580191165648, disc_loss = 0.00016570642970000545
Trained batch 1561 in epoch 18, gen_loss = 0.8771683563038268, disc_loss = 0.0001656534659536548
Trained batch 1562 in epoch 18, gen_loss = 0.8772185240048136, disc_loss = 0.00016562568828867172
Trained batch 1563 in epoch 18, gen_loss = 0.8772329189969451, disc_loss = 0.00016561047319471918
Trained batch 1564 in epoch 18, gen_loss = 0.8771991423143747, disc_loss = 0.00016557460408068273
Trained batch 1565 in epoch 18, gen_loss = 0.8771917012307227, disc_loss = 0.0001655638322888451
Trained batch 1566 in epoch 18, gen_loss = 0.8771896095281965, disc_loss = 0.0001655351817508143
Trained batch 1567 in epoch 18, gen_loss = 0.8771998558801656, disc_loss = 0.00016555708688364184
Trained batch 1568 in epoch 18, gen_loss = 0.877138112934628, disc_loss = 0.00016556289735134946
Trained batch 1569 in epoch 18, gen_loss = 0.8770956169268128, disc_loss = 0.00016557344526842542
Trained batch 1570 in epoch 18, gen_loss = 0.8770811481129812, disc_loss = 0.00016562534782326428
Trained batch 1571 in epoch 18, gen_loss = 0.8770943324984485, disc_loss = 0.0001658130171234622
Trained batch 1572 in epoch 18, gen_loss = 0.8771309141360948, disc_loss = 0.0001660420042873949
Trained batch 1573 in epoch 18, gen_loss = 0.8770939177979054, disc_loss = 0.00016651956656687906
Trained batch 1574 in epoch 18, gen_loss = 0.8771016179190742, disc_loss = 0.00016691724158821643
Trained batch 1575 in epoch 18, gen_loss = 0.8771311989819943, disc_loss = 0.00016708203436903047
Trained batch 1576 in epoch 18, gen_loss = 0.8770798497284675, disc_loss = 0.00016720773464349805
Trained batch 1577 in epoch 18, gen_loss = 0.8770280289634854, disc_loss = 0.00016729936595084792
Trained batch 1578 in epoch 18, gen_loss = 0.8771372753808285, disc_loss = 0.0001674306941299
Trained batch 1579 in epoch 18, gen_loss = 0.8771697272605534, disc_loss = 0.00016751101416566253
Trained batch 1580 in epoch 18, gen_loss = 0.8771654982343646, disc_loss = 0.0001675163733365259
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 1.0416347980499268, disc_loss = 0.0002684978535398841
Trained batch 1 in epoch 19, gen_loss = 0.8934004008769989, disc_loss = 0.00020931215840391815
Trained batch 2 in epoch 19, gen_loss = 0.9300608436266581, disc_loss = 0.00018339246647277227
Trained batch 3 in epoch 19, gen_loss = 0.953328087925911, disc_loss = 0.00018166844893130474
Trained batch 4 in epoch 19, gen_loss = 0.9150130748748779, disc_loss = 0.0001803252031095326
Trained batch 5 in epoch 19, gen_loss = 0.92182856798172, disc_loss = 0.00016612337640253827
Trained batch 6 in epoch 19, gen_loss = 0.9073687706674848, disc_loss = 0.00016091537171243026
Trained batch 7 in epoch 19, gen_loss = 0.9035118371248245, disc_loss = 0.00016370856610592455
Trained batch 8 in epoch 19, gen_loss = 0.8890676034821404, disc_loss = 0.00015681188880181353
Trained batch 9 in epoch 19, gen_loss = 0.885306465625763, disc_loss = 0.00015249873249558731
Trained batch 10 in epoch 19, gen_loss = 0.8828692815520547, disc_loss = 0.00014907566219335422
Trained batch 11 in epoch 19, gen_loss = 0.8813021381696066, disc_loss = 0.0001440476280549774
Trained batch 12 in epoch 19, gen_loss = 0.8811660638222327, disc_loss = 0.0001507101109242425
Trained batch 13 in epoch 19, gen_loss = 0.8756150092397418, disc_loss = 0.00015890858724430603
Trained batch 14 in epoch 19, gen_loss = 0.8765445351600647, disc_loss = 0.00015585935664906477
Trained batch 15 in epoch 19, gen_loss = 0.8751913905143738, disc_loss = 0.00015577874683003756
Trained batch 16 in epoch 19, gen_loss = 0.8678135451148538, disc_loss = 0.00016158204722588007
Trained batch 17 in epoch 19, gen_loss = 0.8721853130393558, disc_loss = 0.0001619194546138816
Trained batch 18 in epoch 19, gen_loss = 0.8695614149695948, disc_loss = 0.0001591194335273222
Trained batch 19 in epoch 19, gen_loss = 0.8732934087514878, disc_loss = 0.00015771516336826608
Trained batch 20 in epoch 19, gen_loss = 0.8755188641094026, disc_loss = 0.0001552042896426948
Trained batch 21 in epoch 19, gen_loss = 0.8729313882914457, disc_loss = 0.00015180790036207657
Trained batch 22 in epoch 19, gen_loss = 0.8686980060909105, disc_loss = 0.0001497634220868349
Trained batch 23 in epoch 19, gen_loss = 0.8655583709478378, disc_loss = 0.0001471803519355793
Trained batch 24 in epoch 19, gen_loss = 0.8657823610305786, disc_loss = 0.00014434979966608806
Trained batch 25 in epoch 19, gen_loss = 0.8666241123126104, disc_loss = 0.00014360039355009436
Trained batch 26 in epoch 19, gen_loss = 0.8670114080111185, disc_loss = 0.0001439552528339576
Trained batch 27 in epoch 19, gen_loss = 0.8722474553755352, disc_loss = 0.00014821796113600221
Trained batch 28 in epoch 19, gen_loss = 0.8702230864557726, disc_loss = 0.000152779317808193
Trained batch 29 in epoch 19, gen_loss = 0.8680767794450124, disc_loss = 0.00015247985502355731
Trained batch 30 in epoch 19, gen_loss = 0.8667577178247513, disc_loss = 0.00015185633744676448
Trained batch 31 in epoch 19, gen_loss = 0.8665274623781443, disc_loss = 0.00015146422288125905
Trained batch 32 in epoch 19, gen_loss = 0.8690908298347936, disc_loss = 0.00015237260055128542
Trained batch 33 in epoch 19, gen_loss = 0.868761947926353, disc_loss = 0.0001511746109720073
Trained batch 34 in epoch 19, gen_loss = 0.8682975155966622, disc_loss = 0.00015088844291832564
Trained batch 35 in epoch 19, gen_loss = 0.867241190539466, disc_loss = 0.00015289737489688883
Trained batch 36 in epoch 19, gen_loss = 0.8677300456407908, disc_loss = 0.00015238834866731604
Trained batch 37 in epoch 19, gen_loss = 0.8682193740418083, disc_loss = 0.00015043103772577045
Trained batch 38 in epoch 19, gen_loss = 0.8688801481173589, disc_loss = 0.0001494880002260638
Trained batch 39 in epoch 19, gen_loss = 0.8708550825715065, disc_loss = 0.00014789649085287238
Trained batch 40 in epoch 19, gen_loss = 0.8709619437775961, disc_loss = 0.00014623804351530698
Trained batch 41 in epoch 19, gen_loss = 0.8692262924852825, disc_loss = 0.00014579792228427583
Trained batch 42 in epoch 19, gen_loss = 0.8696300650751868, disc_loss = 0.00014458740905717794
Trained batch 43 in epoch 19, gen_loss = 0.8695289587432687, disc_loss = 0.00014336377683899957
Trained batch 44 in epoch 19, gen_loss = 0.8693920969963074, disc_loss = 0.0001426011823544589
Trained batch 45 in epoch 19, gen_loss = 0.8698584489200426, disc_loss = 0.00014244885049107404
Trained batch 46 in epoch 19, gen_loss = 0.8665631730505761, disc_loss = 0.00026524083319174604
Trained batch 47 in epoch 19, gen_loss = 0.8687778549889723, disc_loss = 0.00028088717999708024
Trained batch 48 in epoch 19, gen_loss = 0.8700945584141478, disc_loss = 0.00029184822422542554
Trained batch 49 in epoch 19, gen_loss = 0.8700356090068817, disc_loss = 0.0009446181466046255
Trained batch 50 in epoch 19, gen_loss = 0.8707413100728801, disc_loss = 0.0014898274931314803
Trained batch 51 in epoch 19, gen_loss = 0.8727732128821887, disc_loss = 0.0016664577609704933
Trained batch 52 in epoch 19, gen_loss = 0.8723766218941167, disc_loss = 0.0018751005622072866
Trained batch 53 in epoch 19, gen_loss = 0.8733615886282038, disc_loss = 0.002047152113340821
Trained batch 54 in epoch 19, gen_loss = 0.8721813982183283, disc_loss = 0.002115660128368869
Trained batch 55 in epoch 19, gen_loss = 0.8710426624332156, disc_loss = 0.002127048901846657
Trained batch 56 in epoch 19, gen_loss = 0.8715303121951589, disc_loss = 0.0021233545883564816
Trained batch 57 in epoch 19, gen_loss = 0.8728013459978432, disc_loss = 0.0021438065785583478
Trained batch 58 in epoch 19, gen_loss = 0.8736169580685891, disc_loss = 0.002172208510874968
Trained batch 59 in epoch 19, gen_loss = 0.8735758244991303, disc_loss = 0.002162642105031409
Trained batch 60 in epoch 19, gen_loss = 0.8748939936278296, disc_loss = 0.0021410137199039084
Trained batch 61 in epoch 19, gen_loss = 0.8756466854003168, disc_loss = 0.002117394502889628
Trained batch 62 in epoch 19, gen_loss = 0.8747616892769223, disc_loss = 0.002097363257018428
Trained batch 63 in epoch 19, gen_loss = 0.8748279279097915, disc_loss = 0.0020695983492942105
Trained batch 64 in epoch 19, gen_loss = 0.8740431813093332, disc_loss = 0.002044075686157717
Trained batch 65 in epoch 19, gen_loss = 0.8734616646260926, disc_loss = 0.0020222255066486964
Trained batch 66 in epoch 19, gen_loss = 0.8739203668352383, disc_loss = 0.002003279113998713
Trained batch 67 in epoch 19, gen_loss = 0.8750244580647525, disc_loss = 0.0019826777774784097
Trained batch 68 in epoch 19, gen_loss = 0.8742066863654316, disc_loss = 0.001968806472744462
Trained batch 69 in epoch 19, gen_loss = 0.8737698589052473, disc_loss = 0.0019501241430199506
Trained batch 70 in epoch 19, gen_loss = 0.8739208184497457, disc_loss = 0.001932648837654097
Trained batch 71 in epoch 19, gen_loss = 0.8737104021840625, disc_loss = 0.0019139693458782858
Trained batch 72 in epoch 19, gen_loss = 0.8732864374983801, disc_loss = 0.0019038567782582218
Trained batch 73 in epoch 19, gen_loss = 0.8732868851842107, disc_loss = 0.0018873988119594287
Trained batch 74 in epoch 19, gen_loss = 0.8749632660547892, disc_loss = 0.0018706119672666924
Trained batch 75 in epoch 19, gen_loss = 0.8744855460367704, disc_loss = 0.0018546435878402246
Trained batch 76 in epoch 19, gen_loss = 0.8731926803465013, disc_loss = 0.0018361207424147455
Trained batch 77 in epoch 19, gen_loss = 0.8734386288202726, disc_loss = 0.001817225049028191
Trained batch 78 in epoch 19, gen_loss = 0.8721456535254852, disc_loss = 0.0017988100577745576
Trained batch 79 in epoch 19, gen_loss = 0.8710863642394543, disc_loss = 0.0017794890422919707
Trained batch 80 in epoch 19, gen_loss = 0.872744044403971, disc_loss = 0.001762321411346712
Trained batch 81 in epoch 19, gen_loss = 0.8730137369981626, disc_loss = 0.0017441316530294433
Trained batch 82 in epoch 19, gen_loss = 0.8745671805128994, disc_loss = 0.001727131084123127
Trained batch 83 in epoch 19, gen_loss = 0.8751424423285893, disc_loss = 0.0017098546414629147
Trained batch 84 in epoch 19, gen_loss = 0.8756893957362456, disc_loss = 0.0017029020205133266
Trained batch 85 in epoch 19, gen_loss = 0.8748086940410525, disc_loss = 0.0016947331750152232
Trained batch 86 in epoch 19, gen_loss = 0.875823877323633, disc_loss = 0.0016822426819246552
Trained batch 87 in epoch 19, gen_loss = 0.8753096691586755, disc_loss = 0.0016711238762251344
Trained batch 88 in epoch 19, gen_loss = 0.8749947963135966, disc_loss = 0.0016800979556341844
Trained batch 89 in epoch 19, gen_loss = 0.8746262861622704, disc_loss = 0.0016790585717697266
Trained batch 90 in epoch 19, gen_loss = 0.8736323950054882, disc_loss = 0.001674726272400361
Trained batch 91 in epoch 19, gen_loss = 0.8738242569177047, disc_loss = 0.0016640050695929424
Trained batch 92 in epoch 19, gen_loss = 0.8748262627150423, disc_loss = 0.0016493826871581366
Trained batch 93 in epoch 19, gen_loss = 0.8738720645295813, disc_loss = 0.0017197458992279978
Trained batch 94 in epoch 19, gen_loss = 0.8726490321912264, disc_loss = 0.0017389002429952503
Trained batch 95 in epoch 19, gen_loss = 0.8735320580502351, disc_loss = 0.0017334209917407861
Trained batch 96 in epoch 19, gen_loss = 0.8739810788754335, disc_loss = 0.0017297280205686135
Trained batch 97 in epoch 19, gen_loss = 0.8735811637372387, disc_loss = 0.0017220124875388953
Trained batch 98 in epoch 19, gen_loss = 0.87338805499703, disc_loss = 0.0017152533567636368
Trained batch 99 in epoch 19, gen_loss = 0.873300730586052, disc_loss = 0.001703254210515297
Trained batch 100 in epoch 19, gen_loss = 0.875014316327501, disc_loss = 0.0018902349098911739
Trained batch 101 in epoch 19, gen_loss = 0.8747798157673256, disc_loss = 0.0019180369314448862
Trained batch 102 in epoch 19, gen_loss = 0.8760291280098331, disc_loss = 0.001945567961759047
Trained batch 103 in epoch 19, gen_loss = 0.8763523938564154, disc_loss = 0.0019518867396842465
Trained batch 104 in epoch 19, gen_loss = 0.8770148578144256, disc_loss = 0.001948828580775409
Trained batch 105 in epoch 19, gen_loss = 0.8759894039271012, disc_loss = 0.0019402708750485029
Trained batch 106 in epoch 19, gen_loss = 0.8752945577986887, disc_loss = 0.0019291939518374182
Trained batch 107 in epoch 19, gen_loss = 0.8748675446819376, disc_loss = 0.0023156857471433425
Trained batch 108 in epoch 19, gen_loss = 0.8759008296039126, disc_loss = 0.002340592438803127
Trained batch 109 in epoch 19, gen_loss = 0.8754862714897502, disc_loss = 0.0023331913792141927
Trained batch 110 in epoch 19, gen_loss = 0.8748720717859698, disc_loss = 0.0023260141382919967
Trained batch 111 in epoch 19, gen_loss = 0.874803784170321, disc_loss = 0.0023149088303528386
Trained batch 112 in epoch 19, gen_loss = 0.8743692346378765, disc_loss = 0.0023015128343393905
Trained batch 113 in epoch 19, gen_loss = 0.874579271726441, disc_loss = 0.0022885935564740897
Trained batch 114 in epoch 19, gen_loss = 0.8747236837511477, disc_loss = 0.0025582418384146877
Trained batch 115 in epoch 19, gen_loss = 0.8752217339030628, disc_loss = 0.0025494364162396183
Trained batch 116 in epoch 19, gen_loss = 0.874875145080762, disc_loss = 0.0025374380391937857
Trained batch 117 in epoch 19, gen_loss = 0.8748114856622987, disc_loss = 0.002523979805673816
Trained batch 118 in epoch 19, gen_loss = 0.8746618322965478, disc_loss = 0.002508122038314835
Trained batch 119 in epoch 19, gen_loss = 0.8746402472257614, disc_loss = 0.0024900207343913888
Trained batch 120 in epoch 19, gen_loss = 0.87542269348113, disc_loss = 0.002487590069791652
Trained batch 121 in epoch 19, gen_loss = 0.8752254325835431, disc_loss = 0.00246910807600514
Trained batch 122 in epoch 19, gen_loss = 0.8747171338011579, disc_loss = 0.002450722657705797
Trained batch 123 in epoch 19, gen_loss = 0.8754918104217898, disc_loss = 0.0024341349717067187
Trained batch 124 in epoch 19, gen_loss = 0.8745767817497253, disc_loss = 0.0024176045497297308
Trained batch 125 in epoch 19, gen_loss = 0.8744188532942817, disc_loss = 0.002401133257254038
Trained batch 126 in epoch 19, gen_loss = 0.8744509853715972, disc_loss = 0.002384669794992078
Trained batch 127 in epoch 19, gen_loss = 0.8739019138738513, disc_loss = 0.002367617850438819
Trained batch 128 in epoch 19, gen_loss = 0.8739352337149686, disc_loss = 0.002350510041129707
Trained batch 129 in epoch 19, gen_loss = 0.8734876806919392, disc_loss = 0.002333190305944299
Trained batch 130 in epoch 19, gen_loss = 0.8737578624077426, disc_loss = 0.002316711011432904
Trained batch 131 in epoch 19, gen_loss = 0.8745386410843242, disc_loss = 0.0023008772710785374
Trained batch 132 in epoch 19, gen_loss = 0.8759229622389141, disc_loss = 0.0022855660568155117
Trained batch 133 in epoch 19, gen_loss = 0.8762167153963402, disc_loss = 0.002269761622355601
Trained batch 134 in epoch 19, gen_loss = 0.875915676134604, disc_loss = 0.002254052667962646
Trained batch 135 in epoch 19, gen_loss = 0.8755472937927526, disc_loss = 0.0022386994659802225
Trained batch 136 in epoch 19, gen_loss = 0.8753239973618167, disc_loss = 0.0022237780232540754
Trained batch 137 in epoch 19, gen_loss = 0.8751888659553252, disc_loss = 0.0022089016398451245
Trained batch 138 in epoch 19, gen_loss = 0.8746988648990933, disc_loss = 0.0021940343706008457
Trained batch 139 in epoch 19, gen_loss = 0.8746930812086378, disc_loss = 0.0021790271733542407
Trained batch 140 in epoch 19, gen_loss = 0.8748831837735278, disc_loss = 0.002165567877932356
Trained batch 141 in epoch 19, gen_loss = 0.8747365873464397, disc_loss = 0.002151629502151709
Trained batch 142 in epoch 19, gen_loss = 0.8747614463726123, disc_loss = 0.0021377970856615225
Trained batch 143 in epoch 19, gen_loss = 0.8752530266841253, disc_loss = 0.0021245140330595153
Trained batch 144 in epoch 19, gen_loss = 0.8757020810554768, disc_loss = 0.002124780938400614
Trained batch 145 in epoch 19, gen_loss = 0.8733504243092994, disc_loss = 0.005608018444683993
Trained batch 146 in epoch 19, gen_loss = 0.8717706219679644, disc_loss = 0.00782115231146347
Trained batch 147 in epoch 19, gen_loss = 0.8721014019605275, disc_loss = 0.010501658098783574
Trained batch 148 in epoch 19, gen_loss = 0.8757215050242891, disc_loss = 0.011249446436724134
Trained batch 149 in epoch 19, gen_loss = 0.8757064954439799, disc_loss = 0.011926090327760904
Trained batch 150 in epoch 19, gen_loss = 0.8769082320446999, disc_loss = 0.012411001608724357
Trained batch 151 in epoch 19, gen_loss = 0.8776596886546988, disc_loss = 0.012455888847733533
Trained batch 152 in epoch 19, gen_loss = 0.8792786403419146, disc_loss = 0.012442790137748827
Trained batch 153 in epoch 19, gen_loss = 0.8804923319197321, disc_loss = 0.01241593036424352
Trained batch 154 in epoch 19, gen_loss = 0.8806685663038685, disc_loss = 0.012423879786952204
Trained batch 155 in epoch 19, gen_loss = 0.881647099287082, disc_loss = 0.012367200800443429
Trained batch 156 in epoch 19, gen_loss = 0.8826586790145583, disc_loss = 0.01230027214598962
Trained batch 157 in epoch 19, gen_loss = 0.8826558484306818, disc_loss = 0.012229517889196198
Trained batch 158 in epoch 19, gen_loss = 0.8832013434584036, disc_loss = 0.012166053355488789
Trained batch 159 in epoch 19, gen_loss = 0.8831083744764328, disc_loss = 0.012127356499013331
Trained batch 160 in epoch 19, gen_loss = 0.8833421128136771, disc_loss = 0.012062458577466425
Trained batch 161 in epoch 19, gen_loss = 0.8815228975849387, disc_loss = 0.012614741152553765
Trained batch 162 in epoch 19, gen_loss = 0.883605950449142, disc_loss = 0.014166124909303789
Trained batch 163 in epoch 19, gen_loss = 0.8843007854572157, disc_loss = 0.014118610076343983
Trained batch 164 in epoch 19, gen_loss = 0.8846002878564777, disc_loss = 0.014079205196564241
Trained batch 165 in epoch 19, gen_loss = 0.884973114154425, disc_loss = 0.014030738101182688
Trained batch 166 in epoch 19, gen_loss = 0.8852827306279165, disc_loss = 0.013971970942260733
Trained batch 167 in epoch 19, gen_loss = 0.8854530425298781, disc_loss = 0.013895871261194685
Trained batch 168 in epoch 19, gen_loss = 0.8857845029181982, disc_loss = 0.013819733103532303
Trained batch 169 in epoch 19, gen_loss = 0.8862214460092432, disc_loss = 0.013744034948253743
Trained batch 170 in epoch 19, gen_loss = 0.8872082986329731, disc_loss = 0.013667247657113019
Trained batch 171 in epoch 19, gen_loss = 0.8885263807551805, disc_loss = 0.013590528916739819
Trained batch 172 in epoch 19, gen_loss = 0.8878162272403695, disc_loss = 0.013517069798933593
Trained batch 173 in epoch 19, gen_loss = 0.8886066716292809, disc_loss = 0.013441862471426112
Trained batch 174 in epoch 19, gen_loss = 0.8889393632752555, disc_loss = 0.013366938856571713
Trained batch 175 in epoch 19, gen_loss = 0.8895152722570029, disc_loss = 0.013293328905547241
Trained batch 176 in epoch 19, gen_loss = 0.8892159859339396, disc_loss = 0.013221518221940374
Trained batch 177 in epoch 19, gen_loss = 0.8884204984380958, disc_loss = 0.01315096454987377
Trained batch 178 in epoch 19, gen_loss = 0.8887173979642005, disc_loss = 0.013080669057631264
Trained batch 179 in epoch 19, gen_loss = 0.8894025070799721, disc_loss = 0.013010200852659182
Trained batch 180 in epoch 19, gen_loss = 0.889109241040372, disc_loss = 0.012943862675335734
Trained batch 181 in epoch 19, gen_loss = 0.8888485454596006, disc_loss = 0.012874509648979286
Trained batch 182 in epoch 19, gen_loss = 0.8887873409224338, disc_loss = 0.012805539114813287
Trained batch 183 in epoch 19, gen_loss = 0.8890750330427418, disc_loss = 0.012737568531322366
Trained batch 184 in epoch 19, gen_loss = 0.8893236005628431, disc_loss = 0.012670331520407549
Trained batch 185 in epoch 19, gen_loss = 0.8899555571617619, disc_loss = 0.012603770248989026
Trained batch 186 in epoch 19, gen_loss = 0.8900127787003542, disc_loss = 0.01253730433965494
Trained batch 187 in epoch 19, gen_loss = 0.8905978786184433, disc_loss = 0.012472881346610015
Trained batch 188 in epoch 19, gen_loss = 0.8907047062323837, disc_loss = 0.012410056265710087
Trained batch 189 in epoch 19, gen_loss = 0.8908880754521019, disc_loss = 0.012345992830944995
Trained batch 190 in epoch 19, gen_loss = 0.8912359744466413, disc_loss = 0.012282384467515083
Trained batch 191 in epoch 19, gen_loss = 0.890204394236207, disc_loss = 0.012292264607253856
Trained batch 192 in epoch 19, gen_loss = 0.8903859239168118, disc_loss = 0.012233796147088256
Trained batch 193 in epoch 19, gen_loss = 0.891349915683884, disc_loss = 0.012176896686722422
Trained batch 194 in epoch 19, gen_loss = 0.8921228528022767, disc_loss = 0.012118064618754523
Trained batch 195 in epoch 19, gen_loss = 0.8928541617125881, disc_loss = 0.01205849842654989
Trained batch 196 in epoch 19, gen_loss = 0.8930544420547292, disc_loss = 0.011998972582826119
Trained batch 197 in epoch 19, gen_loss = 0.8935285117289032, disc_loss = 0.011940371034841225
Trained batch 198 in epoch 19, gen_loss = 0.8938674162979701, disc_loss = 0.011884015178883826
Trained batch 199 in epoch 19, gen_loss = 0.89361637622118, disc_loss = 0.011826432960988313
Trained batch 200 in epoch 19, gen_loss = 0.8936490784237041, disc_loss = 0.011770218111401186
Trained batch 201 in epoch 19, gen_loss = 0.8936047736961062, disc_loss = 0.011713139556665584
Trained batch 202 in epoch 19, gen_loss = 0.8941966941203977, disc_loss = 0.011657045438624471
Trained batch 203 in epoch 19, gen_loss = 0.8938446836728676, disc_loss = 0.011601147201266334
Trained batch 204 in epoch 19, gen_loss = 0.8939086568064806, disc_loss = 0.01154615809227391
Trained batch 205 in epoch 19, gen_loss = 0.8938238279333393, disc_loss = 0.011491252206998042
Trained batch 206 in epoch 19, gen_loss = 0.8941908576638227, disc_loss = 0.011436709687292322
Trained batch 207 in epoch 19, gen_loss = 0.8942802385068856, disc_loss = 0.011382390295378943
Trained batch 208 in epoch 19, gen_loss = 0.8943655547913182, disc_loss = 0.01132914204100725
Trained batch 209 in epoch 19, gen_loss = 0.8941827495892842, disc_loss = 0.011276395933618049
Trained batch 210 in epoch 19, gen_loss = 0.8941201734316857, disc_loss = 0.011223893831626091
Trained batch 211 in epoch 19, gen_loss = 0.8943083994793442, disc_loss = 0.011171673651297856
Trained batch 212 in epoch 19, gen_loss = 0.8942337276790063, disc_loss = 0.01111986494672724
Trained batch 213 in epoch 19, gen_loss = 0.8947458406475103, disc_loss = 0.011068942339088013
Trained batch 214 in epoch 19, gen_loss = 0.8944036888521771, disc_loss = 0.011018418426304612
Trained batch 215 in epoch 19, gen_loss = 0.8946498033625109, disc_loss = 0.010968091493682382
Trained batch 216 in epoch 19, gen_loss = 0.8953856880763709, disc_loss = 0.010918578074879951
Trained batch 217 in epoch 19, gen_loss = 0.895245950976643, disc_loss = 0.01086967329543651
Trained batch 218 in epoch 19, gen_loss = 0.894981566357286, disc_loss = 0.010821484290131158
Trained batch 219 in epoch 19, gen_loss = 0.8949027383869345, disc_loss = 0.010773059718584674
Trained batch 220 in epoch 19, gen_loss = 0.8949157975917488, disc_loss = 0.01072522648350084
Trained batch 221 in epoch 19, gen_loss = 0.8948056818665685, disc_loss = 0.010678642162003581
Trained batch 222 in epoch 19, gen_loss = 0.8942324513811701, disc_loss = 0.010632355663291912
Trained batch 223 in epoch 19, gen_loss = 0.8939809485205582, disc_loss = 0.010587475397479855
Trained batch 224 in epoch 19, gen_loss = 0.8939015158017476, disc_loss = 0.010541496516315318
Trained batch 225 in epoch 19, gen_loss = 0.8941747696526283, disc_loss = 0.010496698855660676
Trained batch 226 in epoch 19, gen_loss = 0.8945734713571187, disc_loss = 0.010451085044468275
Trained batch 227 in epoch 19, gen_loss = 0.8946088659658766, disc_loss = 0.010406401491165621
Trained batch 228 in epoch 19, gen_loss = 0.8945437651534268, disc_loss = 0.010361404812375722
Trained batch 229 in epoch 19, gen_loss = 0.8947097977866297, disc_loss = 0.010316811353297217
Trained batch 230 in epoch 19, gen_loss = 0.8943967537962513, disc_loss = 0.0102729022089524
Trained batch 231 in epoch 19, gen_loss = 0.8941565978116003, disc_loss = 0.010229857408595652
Trained batch 232 in epoch 19, gen_loss = 0.8944145625241324, disc_loss = 0.01018685245333847
Trained batch 233 in epoch 19, gen_loss = 0.8942801549903348, disc_loss = 0.01014402172132445
Trained batch 234 in epoch 19, gen_loss = 0.8939477504567898, disc_loss = 0.01010176310113859
Trained batch 235 in epoch 19, gen_loss = 0.8942377365241616, disc_loss = 0.010059612773132404
Trained batch 236 in epoch 19, gen_loss = 0.8946065480196024, disc_loss = 0.010017667691660986
Trained batch 237 in epoch 19, gen_loss = 0.8947977989661593, disc_loss = 0.009976115044533615
Trained batch 238 in epoch 19, gen_loss = 0.8947189086151921, disc_loss = 0.009934825770409337
Trained batch 239 in epoch 19, gen_loss = 0.894825679063797, disc_loss = 0.009894074459407421
Trained batch 240 in epoch 19, gen_loss = 0.8949624206020624, disc_loss = 0.009853586267776058
Trained batch 241 in epoch 19, gen_loss = 0.8950821804113624, disc_loss = 0.009813156694878318
Trained batch 242 in epoch 19, gen_loss = 0.8949095165288007, disc_loss = 0.00977386097372112
Trained batch 243 in epoch 19, gen_loss = 0.8949947647872518, disc_loss = 0.009735041820916746
Trained batch 244 in epoch 19, gen_loss = 0.8956955235831592, disc_loss = 0.009698213631440458
Trained batch 245 in epoch 19, gen_loss = 0.8957069290847313, disc_loss = 0.009659461831496281
Trained batch 246 in epoch 19, gen_loss = 0.895891865255379, disc_loss = 0.009621896247172338
Trained batch 247 in epoch 19, gen_loss = 0.8962519188081065, disc_loss = 0.009584064379146918
Trained batch 248 in epoch 19, gen_loss = 0.8957718902802372, disc_loss = 0.009547203701288939
Trained batch 249 in epoch 19, gen_loss = 0.8954110307693481, disc_loss = 0.009509713110484881
Trained batch 250 in epoch 19, gen_loss = 0.8952053424371667, disc_loss = 0.009472747513739369
Trained batch 251 in epoch 19, gen_loss = 0.8953282603668788, disc_loss = 0.009435750533128388
Trained batch 252 in epoch 19, gen_loss = 0.8954509277588765, disc_loss = 0.009399106742414091
Trained batch 253 in epoch 19, gen_loss = 0.895599699395848, disc_loss = 0.00936298767716269
Trained batch 254 in epoch 19, gen_loss = 0.8953094297764348, disc_loss = 0.009327568726382428
Trained batch 255 in epoch 19, gen_loss = 0.8952295056078583, disc_loss = 0.009293075896181335
Trained batch 256 in epoch 19, gen_loss = 0.8954348585021171, disc_loss = 0.00925749828482381
Trained batch 257 in epoch 19, gen_loss = 0.8957852714283522, disc_loss = 0.009222087932202574
Trained batch 258 in epoch 19, gen_loss = 0.8954443998318381, disc_loss = 0.009187411312475705
Trained batch 259 in epoch 19, gen_loss = 0.8954937822543658, disc_loss = 0.009153083294418489
Trained batch 260 in epoch 19, gen_loss = 0.8955520695196715, disc_loss = 0.009118473500929286
Trained batch 261 in epoch 19, gen_loss = 0.8956811703343428, disc_loss = 0.00908437580882082
Trained batch 262 in epoch 19, gen_loss = 0.8952861527979601, disc_loss = 0.009050545547999214
Trained batch 263 in epoch 19, gen_loss = 0.8953533183896181, disc_loss = 0.009016778694537854
Trained batch 264 in epoch 19, gen_loss = 0.8954308350131197, disc_loss = 0.008983135916691335
Trained batch 265 in epoch 19, gen_loss = 0.8955232216451401, disc_loss = 0.008949893931861524
Trained batch 266 in epoch 19, gen_loss = 0.8952925620454081, disc_loss = 0.008916810584632368
Trained batch 267 in epoch 19, gen_loss = 0.8950369358062744, disc_loss = 0.008884032327678957
Trained batch 268 in epoch 19, gen_loss = 0.8954395521085945, disc_loss = 0.00885144583471933
Trained batch 269 in epoch 19, gen_loss = 0.8953106182592886, disc_loss = 0.008819212041001905
Trained batch 270 in epoch 19, gen_loss = 0.8952917986690339, disc_loss = 0.00878691933336569
Trained batch 271 in epoch 19, gen_loss = 0.8950154110789299, disc_loss = 0.008755418458857842
Trained batch 272 in epoch 19, gen_loss = 0.8953634011439788, disc_loss = 0.008724180150058781
Trained batch 273 in epoch 19, gen_loss = 0.8950704388374829, disc_loss = 0.008693097866335535
Trained batch 274 in epoch 19, gen_loss = 0.8950127796693281, disc_loss = 0.008662087836022361
Trained batch 275 in epoch 19, gen_loss = 0.8948246149913125, disc_loss = 0.008631213026013069
Trained batch 276 in epoch 19, gen_loss = 0.8947106246913814, disc_loss = 0.008601298577244442
Trained batch 277 in epoch 19, gen_loss = 0.8945516888186228, disc_loss = 0.008571154081463443
Trained batch 278 in epoch 19, gen_loss = 0.894361027893627, disc_loss = 0.008540854641685127
Trained batch 279 in epoch 19, gen_loss = 0.8943385601043701, disc_loss = 0.008510605069048844
Trained batch 280 in epoch 19, gen_loss = 0.8943219356689589, disc_loss = 0.008480628529394517
Trained batch 281 in epoch 19, gen_loss = 0.8942021991766936, disc_loss = 0.008450813904475439
Trained batch 282 in epoch 19, gen_loss = 0.8946641972123944, disc_loss = 0.008421326109496943
Trained batch 283 in epoch 19, gen_loss = 0.8945480650159675, disc_loss = 0.008392069018132326
Trained batch 284 in epoch 19, gen_loss = 0.8947895158801162, disc_loss = 0.008363680194873413
Trained batch 285 in epoch 19, gen_loss = 0.8946254876526919, disc_loss = 0.008334717030577537
Trained batch 286 in epoch 19, gen_loss = 0.8945323750117099, disc_loss = 0.008305994702886607
Trained batch 287 in epoch 19, gen_loss = 0.8942381791356537, disc_loss = 0.008277480525925461
Trained batch 288 in epoch 19, gen_loss = 0.8943397043898031, disc_loss = 0.008251892035244159
Trained batch 289 in epoch 19, gen_loss = 0.8942668707206332, disc_loss = 0.008224482560211166
Trained batch 290 in epoch 19, gen_loss = 0.8942122146026376, disc_loss = 0.008196731779335909
Trained batch 291 in epoch 19, gen_loss = 0.8943105152208511, disc_loss = 0.008169495640063423
Trained batch 292 in epoch 19, gen_loss = 0.8938665957581061, disc_loss = 0.00814233252048769
Trained batch 293 in epoch 19, gen_loss = 0.8941431765248176, disc_loss = 0.008115389937698067
Trained batch 294 in epoch 19, gen_loss = 0.8940358911530446, disc_loss = 0.00809153530419157
Trained batch 295 in epoch 19, gen_loss = 0.8937752526756879, disc_loss = 0.00806465614216388
Trained batch 296 in epoch 19, gen_loss = 0.8935332444781807, disc_loss = 0.00803784586201396
Trained batch 297 in epoch 19, gen_loss = 0.8935303041998972, disc_loss = 0.008011370918364069
Trained batch 298 in epoch 19, gen_loss = 0.8935609344255964, disc_loss = 0.007984860951882392
Trained batch 299 in epoch 19, gen_loss = 0.8936571091413498, disc_loss = 0.007958500650347559
Trained batch 300 in epoch 19, gen_loss = 0.8936853466239878, disc_loss = 0.007932345319875404
Trained batch 301 in epoch 19, gen_loss = 0.8939338312638516, disc_loss = 0.007906710168946956
Trained batch 302 in epoch 19, gen_loss = 0.8946134601489152, disc_loss = 0.007882726981610801
Trained batch 303 in epoch 19, gen_loss = 0.8948134707384988, disc_loss = 0.007857849679997966
Trained batch 304 in epoch 19, gen_loss = 0.8948072994341616, disc_loss = 0.007833697177234991
Trained batch 305 in epoch 19, gen_loss = 0.8945596857008591, disc_loss = 0.007808909962097186
Trained batch 306 in epoch 19, gen_loss = 0.8944809495043677, disc_loss = 0.007784016264713648
Trained batch 307 in epoch 19, gen_loss = 0.894475273497693, disc_loss = 0.007760086734792408
Trained batch 308 in epoch 19, gen_loss = 0.8948592198319419, disc_loss = 0.007735268930702253
Trained batch 309 in epoch 19, gen_loss = 0.8946943198480913, disc_loss = 0.007710699069139082
Trained batch 310 in epoch 19, gen_loss = 0.894579152777264, disc_loss = 0.0076865959636754
Trained batch 311 in epoch 19, gen_loss = 0.8943269354028579, disc_loss = 0.007662489620624677
Trained batch 312 in epoch 19, gen_loss = 0.8937217402762879, disc_loss = 0.007646166042483504
Trained batch 313 in epoch 19, gen_loss = 0.8935541755454556, disc_loss = 0.0076235222282995925
Trained batch 314 in epoch 19, gen_loss = 0.8933971861052135, disc_loss = 0.007600287534388905
Trained batch 315 in epoch 19, gen_loss = 0.8936558699683298, disc_loss = 0.007576886402303795
Trained batch 316 in epoch 19, gen_loss = 0.8934510316382447, disc_loss = 0.007553558645157396
Trained batch 317 in epoch 19, gen_loss = 0.8940451626882613, disc_loss = 0.00753041751323628
Trained batch 318 in epoch 19, gen_loss = 0.8936989178478157, disc_loss = 0.007507172936948052
Trained batch 319 in epoch 19, gen_loss = 0.8938280737027526, disc_loss = 0.007484393424510927
Trained batch 320 in epoch 19, gen_loss = 0.8936059445235588, disc_loss = 0.007461488356306421
Trained batch 321 in epoch 19, gen_loss = 0.8939655123290068, disc_loss = 0.007438714695945802
Trained batch 322 in epoch 19, gen_loss = 0.8937084296539471, disc_loss = 0.007416375694447197
Trained batch 323 in epoch 19, gen_loss = 0.8939308470781938, disc_loss = 0.007393844650042736
Trained batch 324 in epoch 19, gen_loss = 0.8941131597298843, disc_loss = 0.007371479885343713
Trained batch 325 in epoch 19, gen_loss = 0.8940354400982886, disc_loss = 0.007349280583056402
Trained batch 326 in epoch 19, gen_loss = 0.8935441803130171, disc_loss = 0.00732754013162097
Trained batch 327 in epoch 19, gen_loss = 0.8933658828822578, disc_loss = 0.007305892150725413
Trained batch 328 in epoch 19, gen_loss = 0.8934327719059396, disc_loss = 0.007284054323833784
Trained batch 329 in epoch 19, gen_loss = 0.8934239792101311, disc_loss = 0.007262211616255103
Trained batch 330 in epoch 19, gen_loss = 0.8935029899245662, disc_loss = 0.007240580182212681
Trained batch 331 in epoch 19, gen_loss = 0.893460237118135, disc_loss = 0.007219114552458176
Trained batch 332 in epoch 19, gen_loss = 0.893079252572389, disc_loss = 0.00719768536271784
Trained batch 333 in epoch 19, gen_loss = 0.893145255164472, disc_loss = 0.007176350677206598
Trained batch 334 in epoch 19, gen_loss = 0.8932585440464874, disc_loss = 0.007155298268002868
Trained batch 335 in epoch 19, gen_loss = 0.8932581077374163, disc_loss = 0.0071342040971666435
Trained batch 336 in epoch 19, gen_loss = 0.8933372108448153, disc_loss = 0.007113243645639677
Trained batch 337 in epoch 19, gen_loss = 0.8935553738351404, disc_loss = 0.007092459282362331
Trained batch 338 in epoch 19, gen_loss = 0.893785132067745, disc_loss = 0.007071802702420398
Trained batch 339 in epoch 19, gen_loss = 0.8938955398166881, disc_loss = 0.007051574246018872
Trained batch 340 in epoch 19, gen_loss = 0.8934240945972656, disc_loss = 0.007031238056150711
Trained batch 341 in epoch 19, gen_loss = 0.8935199188210113, disc_loss = 0.007010863837943452
Trained batch 342 in epoch 19, gen_loss = 0.8934627223987969, disc_loss = 0.006990732775715827
Trained batch 343 in epoch 19, gen_loss = 0.8933339498417322, disc_loss = 0.006970689153519722
Trained batch 344 in epoch 19, gen_loss = 0.8934714498727218, disc_loss = 0.006951132990154978
Trained batch 345 in epoch 19, gen_loss = 0.8933314636263544, disc_loss = 0.006931462673939067
Trained batch 346 in epoch 19, gen_loss = 0.8934139933984631, disc_loss = 0.006911719877366614
Trained batch 347 in epoch 19, gen_loss = 0.8935343157285931, disc_loss = 0.006892195981253145
Trained batch 348 in epoch 19, gen_loss = 0.8935026950002741, disc_loss = 0.006872644999599381
Trained batch 349 in epoch 19, gen_loss = 0.8932910111972264, disc_loss = 0.006853240831447433
Trained batch 350 in epoch 19, gen_loss = 0.8935787468893915, disc_loss = 0.0068340083637504975
Trained batch 351 in epoch 19, gen_loss = 0.8934238310903311, disc_loss = 0.006814733726431851
Trained batch 352 in epoch 19, gen_loss = 0.8932359534350063, disc_loss = 0.006795679182893427
Trained batch 353 in epoch 19, gen_loss = 0.8932201422877231, disc_loss = 0.006776618113541333
Trained batch 354 in epoch 19, gen_loss = 0.8932158473511816, disc_loss = 0.006757748418739295
Trained batch 355 in epoch 19, gen_loss = 0.8930688681227438, disc_loss = 0.006739123635270516
Trained batch 356 in epoch 19, gen_loss = 0.8929705476226593, disc_loss = 0.0067205846860800365
Trained batch 357 in epoch 19, gen_loss = 0.892890759686518, disc_loss = 0.006701990578963562
Trained batch 358 in epoch 19, gen_loss = 0.8929553510086782, disc_loss = 0.00668359997300924
Trained batch 359 in epoch 19, gen_loss = 0.8927492686443859, disc_loss = 0.006665203140073572
Trained batch 360 in epoch 19, gen_loss = 0.8924511570349294, disc_loss = 0.006647053723737219
Trained batch 361 in epoch 19, gen_loss = 0.8924549016175349, disc_loss = 0.006629084717937056
Trained batch 362 in epoch 19, gen_loss = 0.8924939361485568, disc_loss = 0.0066110243830682655
Trained batch 363 in epoch 19, gen_loss = 0.8924754646780727, disc_loss = 0.006592984379424776
Trained batch 364 in epoch 19, gen_loss = 0.8923036565519359, disc_loss = 0.006575252099201077
Trained batch 365 in epoch 19, gen_loss = 0.892317197036222, disc_loss = 0.0065575903194695345
Trained batch 366 in epoch 19, gen_loss = 0.8924818201350906, disc_loss = 0.00654002159725423
Trained batch 367 in epoch 19, gen_loss = 0.8927075218247331, disc_loss = 0.006522430960024433
Trained batch 368 in epoch 19, gen_loss = 0.8926920582285418, disc_loss = 0.006504955268502053
Trained batch 369 in epoch 19, gen_loss = 0.8926328816929379, disc_loss = 0.006487520257320973
Trained batch 370 in epoch 19, gen_loss = 0.8924942517858953, disc_loss = 0.006470234743091171
Trained batch 371 in epoch 19, gen_loss = 0.8927630692399958, disc_loss = 0.006453208439916614
Trained batch 372 in epoch 19, gen_loss = 0.8928964106071411, disc_loss = 0.006436234213083785
Trained batch 373 in epoch 19, gen_loss = 0.8929555127646196, disc_loss = 0.006419325354367427
Trained batch 374 in epoch 19, gen_loss = 0.8932173428535461, disc_loss = 0.006402452037242862
Trained batch 375 in epoch 19, gen_loss = 0.8929192758304008, disc_loss = 0.006385868346424491
Trained batch 376 in epoch 19, gen_loss = 0.8930024281737027, disc_loss = 0.006369186598320914
Trained batch 377 in epoch 19, gen_loss = 0.8929592495557492, disc_loss = 0.006352504138424703
Trained batch 378 in epoch 19, gen_loss = 0.8931420656181577, disc_loss = 0.006336049812256591
Trained batch 379 in epoch 19, gen_loss = 0.8931750214413593, disc_loss = 0.006319526869495013
Trained batch 380 in epoch 19, gen_loss = 0.8932992107286228, disc_loss = 0.006303056678054866
Trained batch 381 in epoch 19, gen_loss = 0.8935894975487474, disc_loss = 0.0062869601559271205
Trained batch 382 in epoch 19, gen_loss = 0.8935587315895539, disc_loss = 0.006270793410555786
Trained batch 383 in epoch 19, gen_loss = 0.8936207879645129, disc_loss = 0.006254670939256357
Trained batch 384 in epoch 19, gen_loss = 0.8932876566787818, disc_loss = 0.006238630828001634
Trained batch 385 in epoch 19, gen_loss = 0.8929014105562101, disc_loss = 0.006222709986227269
Trained batch 386 in epoch 19, gen_loss = 0.8931631344233373, disc_loss = 0.006206874148970565
Trained batch 387 in epoch 19, gen_loss = 0.893168701492634, disc_loss = 0.006191072004757067
Trained batch 388 in epoch 19, gen_loss = 0.893222286492816, disc_loss = 0.006175324939006394
Trained batch 389 in epoch 19, gen_loss = 0.8934373750136448, disc_loss = 0.006159595047537527
Trained batch 390 in epoch 19, gen_loss = 0.8934261428425684, disc_loss = 0.006143936287312348
Trained batch 391 in epoch 19, gen_loss = 0.8935060110323283, disc_loss = 0.0061285047060516025
Trained batch 392 in epoch 19, gen_loss = 0.8934113950523105, disc_loss = 0.006113067948858967
Trained batch 393 in epoch 19, gen_loss = 0.8936609728687306, disc_loss = 0.006097799778457519
Trained batch 394 in epoch 19, gen_loss = 0.8935532461238813, disc_loss = 0.0060827439969377535
Trained batch 395 in epoch 19, gen_loss = 0.8931608025473777, disc_loss = 0.006067726333970892
Trained batch 396 in epoch 19, gen_loss = 0.8932351129181139, disc_loss = 0.006052642667672529
Trained batch 397 in epoch 19, gen_loss = 0.8929753417345747, disc_loss = 0.006037624554546116
Trained batch 398 in epoch 19, gen_loss = 0.8930470375787645, disc_loss = 0.0060226810545871215
Trained batch 399 in epoch 19, gen_loss = 0.8934105405211449, disc_loss = 0.0060079353516266564
Trained batch 400 in epoch 19, gen_loss = 0.8934439331516066, disc_loss = 0.005993228422425149
Trained batch 401 in epoch 19, gen_loss = 0.8936010572447706, disc_loss = 0.005978476909339365
Trained batch 402 in epoch 19, gen_loss = 0.8935076770356511, disc_loss = 0.00596394693995589
Trained batch 403 in epoch 19, gen_loss = 0.8934648318751024, disc_loss = 0.0059493083815348406
Trained batch 404 in epoch 19, gen_loss = 0.8935196657239655, disc_loss = 0.005934940655361847
Trained batch 405 in epoch 19, gen_loss = 0.8931278482152911, disc_loss = 0.005920566297413307
Trained batch 406 in epoch 19, gen_loss = 0.8929862174999509, disc_loss = 0.005906304023579333
Trained batch 407 in epoch 19, gen_loss = 0.8930738327257773, disc_loss = 0.005892034154982742
Trained batch 408 in epoch 19, gen_loss = 0.8932027235299276, disc_loss = 0.005877834093446509
Trained batch 409 in epoch 19, gen_loss = 0.893519101055657, disc_loss = 0.005863729241102148
Trained batch 410 in epoch 19, gen_loss = 0.8936986280763817, disc_loss = 0.005849706433399242
Trained batch 411 in epoch 19, gen_loss = 0.893981606780904, disc_loss = 0.005836024070826506
Trained batch 412 in epoch 19, gen_loss = 0.8941439610993891, disc_loss = 0.005822404155651935
Trained batch 413 in epoch 19, gen_loss = 0.8943311749161154, disc_loss = 0.005808906425910837
Trained batch 414 in epoch 19, gen_loss = 0.8943664368376675, disc_loss = 0.005795072239684432
Trained batch 415 in epoch 19, gen_loss = 0.8940996205290923, disc_loss = 0.005782208926741707
Trained batch 416 in epoch 19, gen_loss = 0.8942288536247875, disc_loss = 0.0057687346465874895
Trained batch 417 in epoch 19, gen_loss = 0.8941719638959073, disc_loss = 0.005755088675677574
Trained batch 418 in epoch 19, gen_loss = 0.8940203707656315, disc_loss = 0.005741529906076406
Trained batch 419 in epoch 19, gen_loss = 0.8939238446099418, disc_loss = 0.005728281141368609
Trained batch 420 in epoch 19, gen_loss = 0.8939903998601465, disc_loss = 0.005714870774975716
Trained batch 421 in epoch 19, gen_loss = 0.8940660076401244, disc_loss = 0.005701630106991335
Trained batch 422 in epoch 19, gen_loss = 0.8938912302607904, disc_loss = 0.005688427582451065
Trained batch 423 in epoch 19, gen_loss = 0.8939851667239981, disc_loss = 0.005675244725824875
Trained batch 424 in epoch 19, gen_loss = 0.8941708775127635, disc_loss = 0.005662078038705444
Trained batch 425 in epoch 19, gen_loss = 0.8939260147826772, disc_loss = 0.005648999572203108
Trained batch 426 in epoch 19, gen_loss = 0.8939934788878126, disc_loss = 0.0056359684439074055
Trained batch 427 in epoch 19, gen_loss = 0.893673316201317, disc_loss = 0.005623132503974248
Trained batch 428 in epoch 19, gen_loss = 0.8939416587769569, disc_loss = 0.005610223967068227
Trained batch 429 in epoch 19, gen_loss = 0.8938632531221523, disc_loss = 0.00559734730522905
Trained batch 430 in epoch 19, gen_loss = 0.8938392772752005, disc_loss = 0.005584597835938699
Trained batch 431 in epoch 19, gen_loss = 0.8941529607055364, disc_loss = 0.005571850717968927
Trained batch 432 in epoch 19, gen_loss = 0.8939676082437088, disc_loss = 0.005559168217881348
Trained batch 433 in epoch 19, gen_loss = 0.893783572494709, disc_loss = 0.005546503200982405
Trained batch 434 in epoch 19, gen_loss = 0.8938647677158488, disc_loss = 0.005533874704261329
Trained batch 435 in epoch 19, gen_loss = 0.8937988717348204, disc_loss = 0.005521358278877523
Trained batch 436 in epoch 19, gen_loss = 0.8939531004947164, disc_loss = 0.005508886074563193
Trained batch 437 in epoch 19, gen_loss = 0.8937506421243764, disc_loss = 0.005496439974846812
Trained batch 438 in epoch 19, gen_loss = 0.8939073034190914, disc_loss = 0.0054841888456326005
Trained batch 439 in epoch 19, gen_loss = 0.8937031052329324, disc_loss = 0.0054724839857706025
Trained batch 440 in epoch 19, gen_loss = 0.8934389581215355, disc_loss = 0.005460419654952114
Trained batch 441 in epoch 19, gen_loss = 0.8931731925560877, disc_loss = 0.0054482590429504206
Trained batch 442 in epoch 19, gen_loss = 0.892900583571828, disc_loss = 0.005436164757881524
Trained batch 443 in epoch 19, gen_loss = 0.8929087431044191, disc_loss = 0.0054240293168789375
Trained batch 444 in epoch 19, gen_loss = 0.8929672364438518, disc_loss = 0.0054119631403542435
Trained batch 445 in epoch 19, gen_loss = 0.8931254127100444, disc_loss = 0.005399948742690014
Trained batch 446 in epoch 19, gen_loss = 0.8929144629429384, disc_loss = 0.005388057218402675
Trained batch 447 in epoch 19, gen_loss = 0.8926617625568595, disc_loss = 0.0053857670028816884
Trained batch 448 in epoch 19, gen_loss = 0.8926892615108023, disc_loss = 0.005374707277716559
Trained batch 449 in epoch 19, gen_loss = 0.8927720562616984, disc_loss = 0.005363992357694467
Trained batch 450 in epoch 19, gen_loss = 0.8924155814156035, disc_loss = 0.005443392486943003
Trained batch 451 in epoch 19, gen_loss = 0.8924751948993818, disc_loss = 0.005446691485601544
Trained batch 452 in epoch 19, gen_loss = 0.8927146741096547, disc_loss = 0.005440937924917986
Trained batch 453 in epoch 19, gen_loss = 0.8929658891871112, disc_loss = 0.005433349492452605
Trained batch 454 in epoch 19, gen_loss = 0.893062125981509, disc_loss = 0.00542305074864039
Trained batch 455 in epoch 19, gen_loss = 0.8930118342763499, disc_loss = 0.005427108777615088
Trained batch 456 in epoch 19, gen_loss = 0.8931276597392377, disc_loss = 0.005422404413208945
Trained batch 457 in epoch 19, gen_loss = 0.8934609671347006, disc_loss = 0.005415948802025355
Trained batch 458 in epoch 19, gen_loss = 0.893388005643109, disc_loss = 0.0054075472008327605
Trained batch 459 in epoch 19, gen_loss = 0.8934927252323731, disc_loss = 0.005397482399728134
Trained batch 460 in epoch 19, gen_loss = 0.8936146188713207, disc_loss = 0.005387407692327692
Trained batch 461 in epoch 19, gen_loss = 0.8937935234406293, disc_loss = 0.005377264528221464
Trained batch 462 in epoch 19, gen_loss = 0.8941248000054328, disc_loss = 0.005366830574288853
Trained batch 463 in epoch 19, gen_loss = 0.8941077796806549, disc_loss = 0.0053571384226666725
Trained batch 464 in epoch 19, gen_loss = 0.8940458779693932, disc_loss = 0.005346537126001015
Trained batch 465 in epoch 19, gen_loss = 0.8939452749465157, disc_loss = 0.0053363076490411275
Trained batch 466 in epoch 19, gen_loss = 0.8938548414303863, disc_loss = 0.005327733714516525
Trained batch 467 in epoch 19, gen_loss = 0.8940074848823059, disc_loss = 0.005317522360449861
Trained batch 468 in epoch 19, gen_loss = 0.8941470215569681, disc_loss = 0.00530691619951346
Trained batch 469 in epoch 19, gen_loss = 0.8940420507116521, disc_loss = 0.005296433222448538
Trained batch 470 in epoch 19, gen_loss = 0.8940922911506296, disc_loss = 0.005286140793704229
Trained batch 471 in epoch 19, gen_loss = 0.8941415371531147, disc_loss = 0.0052766124809919745
Trained batch 472 in epoch 19, gen_loss = 0.8943102461843108, disc_loss = 0.0052662525114133985
Trained batch 473 in epoch 19, gen_loss = 0.8942417724977566, disc_loss = 0.005255634965732294
Trained batch 474 in epoch 19, gen_loss = 0.8942167854309082, disc_loss = 0.005245289308107826
Trained batch 475 in epoch 19, gen_loss = 0.8940585210543721, disc_loss = 0.005234656364902411
Trained batch 476 in epoch 19, gen_loss = 0.8944433175292905, disc_loss = 0.005224727284339812
Trained batch 477 in epoch 19, gen_loss = 0.8944972157478333, disc_loss = 0.005214586616081558
Trained batch 478 in epoch 19, gen_loss = 0.8943992599316082, disc_loss = 0.005203973072639201
Trained batch 479 in epoch 19, gen_loss = 0.8943144934872787, disc_loss = 0.005193927813813086
Trained batch 480 in epoch 19, gen_loss = 0.8941969772386452, disc_loss = 0.005183656595021331
Trained batch 481 in epoch 19, gen_loss = 0.8942476524604307, disc_loss = 0.0051740655276620775
Trained batch 482 in epoch 19, gen_loss = 0.8941440576105137, disc_loss = 0.005166164521613244
Trained batch 483 in epoch 19, gen_loss = 0.8940373422685733, disc_loss = 0.005156374650509823
Trained batch 484 in epoch 19, gen_loss = 0.8944029631073942, disc_loss = 0.005147441783868924
Trained batch 485 in epoch 19, gen_loss = 0.8935753942271809, disc_loss = 0.005518649210393455
Trained batch 486 in epoch 19, gen_loss = 0.8941386496261894, disc_loss = 0.006562638936085159
Trained batch 487 in epoch 19, gen_loss = 0.8942415099896368, disc_loss = 0.0068578435734483805
Trained batch 488 in epoch 19, gen_loss = 0.8943075559621939, disc_loss = 0.006959624748515962
Trained batch 489 in epoch 19, gen_loss = 0.893838867727591, disc_loss = 0.006993612601485327
Trained batch 490 in epoch 19, gen_loss = 0.8935792847951901, disc_loss = 0.007052084176927163
Trained batch 491 in epoch 19, gen_loss = 0.8937061323625285, disc_loss = 0.007062019818181213
Trained batch 492 in epoch 19, gen_loss = 0.893777267686252, disc_loss = 0.00705693931177787
Trained batch 493 in epoch 19, gen_loss = 0.8939308957291036, disc_loss = 0.0070569861024637704
Trained batch 494 in epoch 19, gen_loss = 0.8938563092790469, disc_loss = 0.007059953982675463
Trained batch 495 in epoch 19, gen_loss = 0.8937980069989159, disc_loss = 0.007067200040578868
Trained batch 496 in epoch 19, gen_loss = 0.8939829860894493, disc_loss = 0.007063403871831305
Trained batch 497 in epoch 19, gen_loss = 0.8937834723886237, disc_loss = 0.007090815608564415
Trained batch 498 in epoch 19, gen_loss = 0.8939397387609692, disc_loss = 0.007091366592651762
Trained batch 499 in epoch 19, gen_loss = 0.8941281435489654, disc_loss = 0.007089831933422829
Trained batch 500 in epoch 19, gen_loss = 0.8940396304140071, disc_loss = 0.007089738938592057
Trained batch 501 in epoch 19, gen_loss = 0.8943707591508964, disc_loss = 0.0070857061982678715
Trained batch 502 in epoch 19, gen_loss = 0.8943421685434952, disc_loss = 0.007077687121897072
Trained batch 503 in epoch 19, gen_loss = 0.8945992630389001, disc_loss = 0.007067298653416243
Trained batch 504 in epoch 19, gen_loss = 0.8947036319439954, disc_loss = 0.007054911237852625
Trained batch 505 in epoch 19, gen_loss = 0.8947030510827015, disc_loss = 0.007046695488774592
Trained batch 506 in epoch 19, gen_loss = 0.8947585491974208, disc_loss = 0.007035657576616753
Trained batch 507 in epoch 19, gen_loss = 0.8949772844633718, disc_loss = 0.007025322826497516
Trained batch 508 in epoch 19, gen_loss = 0.8948919007258237, disc_loss = 0.007013706934602528
Trained batch 509 in epoch 19, gen_loss = 0.8949306467000175, disc_loss = 0.007002393676777822
Trained batch 510 in epoch 19, gen_loss = 0.8947195851639526, disc_loss = 0.0069902095114401045
Trained batch 511 in epoch 19, gen_loss = 0.8949580685002729, disc_loss = 0.006978440331337765
Trained batch 512 in epoch 19, gen_loss = 0.8947406570349056, disc_loss = 0.006966220087243664
Trained batch 513 in epoch 19, gen_loss = 0.8947027251414288, disc_loss = 0.006954724897069613
Trained batch 514 in epoch 19, gen_loss = 0.8945828410028254, disc_loss = 0.00694573633942145
Trained batch 515 in epoch 19, gen_loss = 0.8945516012897787, disc_loss = 0.006933942301621974
Trained batch 516 in epoch 19, gen_loss = 0.894851931059153, disc_loss = 0.006921592399581427
Trained batch 517 in epoch 19, gen_loss = 0.8946809585720416, disc_loss = 0.006909879146574284
Trained batch 518 in epoch 19, gen_loss = 0.894505651470324, disc_loss = 0.006898739583372979
Trained batch 519 in epoch 19, gen_loss = 0.8947231581577888, disc_loss = 0.006888382838713789
Trained batch 520 in epoch 19, gen_loss = 0.8943417907447595, disc_loss = 0.006905059589181098
Trained batch 521 in epoch 19, gen_loss = 0.8945122846470025, disc_loss = 0.006900242779408274
Trained batch 522 in epoch 19, gen_loss = 0.8947090280899355, disc_loss = 0.006889496349912011
Trained batch 523 in epoch 19, gen_loss = 0.8946410362957088, disc_loss = 0.006881146696224548
Trained batch 524 in epoch 19, gen_loss = 0.8950042122886295, disc_loss = 0.006870416445433096
Trained batch 525 in epoch 19, gen_loss = 0.8951270251672984, disc_loss = 0.006859248994976108
Trained batch 526 in epoch 19, gen_loss = 0.8951901479056935, disc_loss = 0.006847656569909194
Trained batch 527 in epoch 19, gen_loss = 0.8951362534002825, disc_loss = 0.0068378490308063965
Trained batch 528 in epoch 19, gen_loss = 0.8953315700159632, disc_loss = 0.0068261337398509815
Trained batch 529 in epoch 19, gen_loss = 0.8952638449533931, disc_loss = 0.006815792612864895
Trained batch 530 in epoch 19, gen_loss = 0.8954818061291611, disc_loss = 0.006804947021722389
Trained batch 531 in epoch 19, gen_loss = 0.8956829606366337, disc_loss = 0.0067939151981966945
Trained batch 532 in epoch 19, gen_loss = 0.8954625714563295, disc_loss = 0.006793949850390977
Trained batch 533 in epoch 19, gen_loss = 0.8955670435553633, disc_loss = 0.006782603946342529
Trained batch 534 in epoch 19, gen_loss = 0.8954962060830304, disc_loss = 0.0067781799072894776
Trained batch 535 in epoch 19, gen_loss = 0.8954288549165228, disc_loss = 0.006769266466080943
Trained batch 536 in epoch 19, gen_loss = 0.8955909345625055, disc_loss = 0.006759424114231176
Trained batch 537 in epoch 19, gen_loss = 0.8958690799080307, disc_loss = 0.0067484877862486956
Trained batch 538 in epoch 19, gen_loss = 0.8957329345987989, disc_loss = 0.006739520560299389
Trained batch 539 in epoch 19, gen_loss = 0.8959749426002855, disc_loss = 0.006728040896228372
Trained batch 540 in epoch 19, gen_loss = 0.8958712596990265, disc_loss = 0.006716814787768223
Trained batch 541 in epoch 19, gen_loss = 0.8960810595112974, disc_loss = 0.0067051015275965895
Trained batch 542 in epoch 19, gen_loss = 0.8960277703805084, disc_loss = 0.006695119799931064
Trained batch 543 in epoch 19, gen_loss = 0.8959174032377846, disc_loss = 0.006683841332861608
Trained batch 544 in epoch 19, gen_loss = 0.8959907655322223, disc_loss = 0.006672198420383545
Trained batch 545 in epoch 19, gen_loss = 0.8959216057380914, disc_loss = 0.006660320954237943
Trained batch 546 in epoch 19, gen_loss = 0.8958142279924814, disc_loss = 0.006648702931435974
Trained batch 547 in epoch 19, gen_loss = 0.8960589354273176, disc_loss = 0.0066374607057078875
Trained batch 548 in epoch 19, gen_loss = 0.8960453359807123, disc_loss = 0.006625797177535267
Trained batch 549 in epoch 19, gen_loss = 0.8960908784649589, disc_loss = 0.006614202856025341
Trained batch 550 in epoch 19, gen_loss = 0.8962971842873119, disc_loss = 0.006602750441396779
Trained batch 551 in epoch 19, gen_loss = 0.8962689492365589, disc_loss = 0.006591517692776098
Trained batch 552 in epoch 19, gen_loss = 0.8963301777839661, disc_loss = 0.00657994551023889
Trained batch 553 in epoch 19, gen_loss = 0.8963480472349518, disc_loss = 0.00656837319457155
Trained batch 554 in epoch 19, gen_loss = 0.8962629806887996, disc_loss = 0.006558378522380293
Trained batch 555 in epoch 19, gen_loss = 0.8963321475245112, disc_loss = 0.006548145140814674
Trained batch 556 in epoch 19, gen_loss = 0.8964434617083633, disc_loss = 0.0065382236079224035
Trained batch 557 in epoch 19, gen_loss = 0.8967756397194333, disc_loss = 0.006529746762810981
Trained batch 558 in epoch 19, gen_loss = 0.8967543480008148, disc_loss = 0.006519508273065342
Trained batch 559 in epoch 19, gen_loss = 0.8968700179031917, disc_loss = 0.006508955729168519
Trained batch 560 in epoch 19, gen_loss = 0.8968098709715029, disc_loss = 0.0064984548789296095
Trained batch 561 in epoch 19, gen_loss = 0.8970081135895753, disc_loss = 0.006487600095865786
Trained batch 562 in epoch 19, gen_loss = 0.897170664997338, disc_loss = 0.006476812949122387
Trained batch 563 in epoch 19, gen_loss = 0.897198756218802, disc_loss = 0.006466181013523745
Trained batch 564 in epoch 19, gen_loss = 0.897259288762523, disc_loss = 0.006455196423929461
Trained batch 565 in epoch 19, gen_loss = 0.8973462924940426, disc_loss = 0.006444116955603594
Trained batch 566 in epoch 19, gen_loss = 0.8972571257771218, disc_loss = 0.006433228276964302
Trained batch 567 in epoch 19, gen_loss = 0.8974497181848741, disc_loss = 0.006422344458884946
Trained batch 568 in epoch 19, gen_loss = 0.8974397704136183, disc_loss = 0.0064115049044215135
Trained batch 569 in epoch 19, gen_loss = 0.8975440428968061, disc_loss = 0.006400616709773506
Trained batch 570 in epoch 19, gen_loss = 0.8974453681613435, disc_loss = 0.00638981126847988
Trained batch 571 in epoch 19, gen_loss = 0.8975268960832716, disc_loss = 0.006378865808341021
Trained batch 572 in epoch 19, gen_loss = 0.8973913307173298, disc_loss = 0.006368239936134904
Trained batch 573 in epoch 19, gen_loss = 0.8973574418224108, disc_loss = 0.006357545363798414
Trained batch 574 in epoch 19, gen_loss = 0.89716871396355, disc_loss = 0.006347494716667469
Trained batch 575 in epoch 19, gen_loss = 0.8972851561589373, disc_loss = 0.006336739757456498
Trained batch 576 in epoch 19, gen_loss = 0.8972301345764041, disc_loss = 0.006326187735178207
Trained batch 577 in epoch 19, gen_loss = 0.8973849008446334, disc_loss = 0.0063154927780192105
Trained batch 578 in epoch 19, gen_loss = 0.8971823310810874, disc_loss = 0.006313940469601931
Trained batch 579 in epoch 19, gen_loss = 0.8971042465547036, disc_loss = 0.006308679652446981
Trained batch 580 in epoch 19, gen_loss = 0.8969662898378815, disc_loss = 0.006299585858646964
Trained batch 581 in epoch 19, gen_loss = 0.8970572717001348, disc_loss = 0.006289710856867011
Trained batch 582 in epoch 19, gen_loss = 0.8970565304134559, disc_loss = 0.006279368372736391
Trained batch 583 in epoch 19, gen_loss = 0.8971339372331149, disc_loss = 0.006269230077795988
Trained batch 584 in epoch 19, gen_loss = 0.8971296497899243, disc_loss = 0.006258957885252013
Trained batch 585 in epoch 19, gen_loss = 0.8971247799160538, disc_loss = 0.006248853594826478
Trained batch 586 in epoch 19, gen_loss = 0.8969719492190944, disc_loss = 0.006238974688705664
Trained batch 587 in epoch 19, gen_loss = 0.8969765709979194, disc_loss = 0.006229072808093319
Trained batch 588 in epoch 19, gen_loss = 0.8968607201438605, disc_loss = 0.006219286241405861
Trained batch 589 in epoch 19, gen_loss = 0.8968854683940694, disc_loss = 0.006209017624903443
Trained batch 590 in epoch 19, gen_loss = 0.8968951292651155, disc_loss = 0.0061987285561619886
Trained batch 591 in epoch 19, gen_loss = 0.8968274170482481, disc_loss = 0.006188522253253452
Trained batch 592 in epoch 19, gen_loss = 0.8967498680592387, disc_loss = 0.006178354464076647
Trained batch 593 in epoch 19, gen_loss = 0.8967156410217285, disc_loss = 0.006168407912966102
Trained batch 594 in epoch 19, gen_loss = 0.8966356930612516, disc_loss = 0.006158303654155432
Trained batch 595 in epoch 19, gen_loss = 0.8966769192042767, disc_loss = 0.006148298586442447
Trained batch 596 in epoch 19, gen_loss = 0.896701265220067, disc_loss = 0.0061382125056345035
Trained batch 597 in epoch 19, gen_loss = 0.8965785845266936, disc_loss = 0.006128173012671004
Trained batch 598 in epoch 19, gen_loss = 0.8965274103495832, disc_loss = 0.0061183262109071
Trained batch 599 in epoch 19, gen_loss = 0.8966985953847567, disc_loss = 0.006108507370966739
Trained batch 600 in epoch 19, gen_loss = 0.8968499810644077, disc_loss = 0.006100036985027901
Trained batch 601 in epoch 19, gen_loss = 0.8967203014712793, disc_loss = 0.0060905240182990115
Trained batch 602 in epoch 19, gen_loss = 0.8967728322220482, disc_loss = 0.006081033788954358
Trained batch 603 in epoch 19, gen_loss = 0.896817080627214, disc_loss = 0.00607122929257409
Trained batch 604 in epoch 19, gen_loss = 0.8966616560604946, disc_loss = 0.006061804682665316
Trained batch 605 in epoch 19, gen_loss = 0.8966174053870412, disc_loss = 0.006051977194471361
Trained batch 606 in epoch 19, gen_loss = 0.8967439833740033, disc_loss = 0.006042300683900862
Trained batch 607 in epoch 19, gen_loss = 0.8966399891988227, disc_loss = 0.006032778231165618
Trained batch 608 in epoch 19, gen_loss = 0.8966009170551018, disc_loss = 0.006023648011373232
Trained batch 609 in epoch 19, gen_loss = 0.8961925328754988, disc_loss = 0.006100480708775023
Trained batch 610 in epoch 19, gen_loss = 0.8963142824641226, disc_loss = 0.00610655979222152
Trained batch 611 in epoch 19, gen_loss = 0.8966646122387032, disc_loss = 0.006106373601284634
Trained batch 612 in epoch 19, gen_loss = 0.8968623812396997, disc_loss = 0.0063873904484418546
Trained batch 613 in epoch 19, gen_loss = 0.8963826225906708, disc_loss = 0.0065529229094321555
Trained batch 614 in epoch 19, gen_loss = 0.8964627867791711, disc_loss = 0.006553120945111329
Trained batch 615 in epoch 19, gen_loss = 0.8965792739159101, disc_loss = 0.006557756494315415
Trained batch 616 in epoch 19, gen_loss = 0.8967296145916758, disc_loss = 0.006560697892637462
Trained batch 617 in epoch 19, gen_loss = 0.8967866012193624, disc_loss = 0.0065575727648076315
Trained batch 618 in epoch 19, gen_loss = 0.8969442940682703, disc_loss = 0.00655017413118501
Trained batch 619 in epoch 19, gen_loss = 0.896831014944661, disc_loss = 0.006551031736695046
Trained batch 620 in epoch 19, gen_loss = 0.8967214338061507, disc_loss = 0.006546242401332744
Trained batch 621 in epoch 19, gen_loss = 0.8965807682639916, disc_loss = 0.0065542124050009245
Trained batch 622 in epoch 19, gen_loss = 0.8967143225440244, disc_loss = 0.006546945649642145
Trained batch 623 in epoch 19, gen_loss = 0.8968486732397324, disc_loss = 0.006567368503930573
Trained batch 624 in epoch 19, gen_loss = 0.8972690620422363, disc_loss = 0.006578022859164048
Trained batch 625 in epoch 19, gen_loss = 0.897584316829523, disc_loss = 0.006618673354454697
Trained batch 626 in epoch 19, gen_loss = 0.8978801408642977, disc_loss = 0.006622429608035127
Trained batch 627 in epoch 19, gen_loss = 0.8980528651529057, disc_loss = 0.006620425561800837
Trained batch 628 in epoch 19, gen_loss = 0.8975416675849636, disc_loss = 0.006800599203664615
Trained batch 629 in epoch 19, gen_loss = 0.8981764810425895, disc_loss = 0.006814588993588658
Trained batch 630 in epoch 19, gen_loss = 0.8987203970575106, disc_loss = 0.006885801623428256
Trained batch 631 in epoch 19, gen_loss = 0.8989894386333755, disc_loss = 0.006883446137410978
Trained batch 632 in epoch 19, gen_loss = 0.8993262348205181, disc_loss = 0.0068773701731017186
Trained batch 633 in epoch 19, gen_loss = 0.8994309478189667, disc_loss = 0.006875273663167675
Trained batch 634 in epoch 19, gen_loss = 0.8996882649857229, disc_loss = 0.006866652320249567
Trained batch 635 in epoch 19, gen_loss = 0.8999047996300571, disc_loss = 0.006857064989357092
Trained batch 636 in epoch 19, gen_loss = 0.8999209769853804, disc_loss = 0.006847617774281166
Trained batch 637 in epoch 19, gen_loss = 0.9001128937943976, disc_loss = 0.006838937372591534
Trained batch 638 in epoch 19, gen_loss = 0.9004104843535147, disc_loss = 0.006830713080333095
Trained batch 639 in epoch 19, gen_loss = 0.9003658751957119, disc_loss = 0.006821016460992269
Trained batch 640 in epoch 19, gen_loss = 0.9004238082354601, disc_loss = 0.006811567062872819
Trained batch 641 in epoch 19, gen_loss = 0.9004776361761063, disc_loss = 0.006801740508109953
Trained batch 642 in epoch 19, gen_loss = 0.9003824587928748, disc_loss = 0.006793707462899336
Trained batch 643 in epoch 19, gen_loss = 0.9005783823151026, disc_loss = 0.0067856722380948776
Trained batch 644 in epoch 19, gen_loss = 0.9005953921828159, disc_loss = 0.006775957380627668
Trained batch 645 in epoch 19, gen_loss = 0.9006326095238558, disc_loss = 0.006767652679250331
Trained batch 646 in epoch 19, gen_loss = 0.9006417479360306, disc_loss = 0.006758001048044194
Trained batch 647 in epoch 19, gen_loss = 0.9007181236405432, disc_loss = 0.00674838584940135
Trained batch 648 in epoch 19, gen_loss = 0.90083919853569, disc_loss = 0.006738453169692059
Trained batch 649 in epoch 19, gen_loss = 0.900779153567094, disc_loss = 0.006728741942889218
Trained batch 650 in epoch 19, gen_loss = 0.9009700086992091, disc_loss = 0.006719547953582623
Trained batch 651 in epoch 19, gen_loss = 0.9009573410259434, disc_loss = 0.006710114061496841
Trained batch 652 in epoch 19, gen_loss = 0.9010928668435463, disc_loss = 0.006701008904981409
Trained batch 653 in epoch 19, gen_loss = 0.9011360354926607, disc_loss = 0.006691756322861109
Trained batch 654 in epoch 19, gen_loss = 0.9012042645279688, disc_loss = 0.006682930922969724
Trained batch 655 in epoch 19, gen_loss = 0.9011298439851622, disc_loss = 0.006674254331711581
Trained batch 656 in epoch 19, gen_loss = 0.9011246096597959, disc_loss = 0.006664662220807412
Trained batch 657 in epoch 19, gen_loss = 0.9009979403489992, disc_loss = 0.006655268571835374
Trained batch 658 in epoch 19, gen_loss = 0.9009670505755226, disc_loss = 0.006645931120621756
Trained batch 659 in epoch 19, gen_loss = 0.9008696462168838, disc_loss = 0.006636470686620062
Trained batch 660 in epoch 19, gen_loss = 0.9009001634665589, disc_loss = 0.006627164019693803
Trained batch 661 in epoch 19, gen_loss = 0.9010122460721123, disc_loss = 0.006618018442657344
Trained batch 662 in epoch 19, gen_loss = 0.9011776169500739, disc_loss = 0.006608564998553929
Trained batch 663 in epoch 19, gen_loss = 0.9012822314019663, disc_loss = 0.006599434256878088
Trained batch 664 in epoch 19, gen_loss = 0.9012575747375201, disc_loss = 0.0065900144263637194
Trained batch 665 in epoch 19, gen_loss = 0.9012589188846382, disc_loss = 0.006580751351956659
Trained batch 666 in epoch 19, gen_loss = 0.9013330087490168, disc_loss = 0.006571293035512068
Trained batch 667 in epoch 19, gen_loss = 0.9011886204609614, disc_loss = 0.006563052664031041
Trained batch 668 in epoch 19, gen_loss = 0.9010393535787927, disc_loss = 0.0065805649472668
Trained batch 669 in epoch 19, gen_loss = 0.9014513597559574, disc_loss = 0.006573350571016451
Trained batch 670 in epoch 19, gen_loss = 0.9017654261183987, disc_loss = 0.006566329533210383
Trained batch 671 in epoch 19, gen_loss = 0.9020014158671811, disc_loss = 0.006557435697437714
Trained batch 672 in epoch 19, gen_loss = 0.9024316869554335, disc_loss = 0.006548546233888107
Trained batch 673 in epoch 19, gen_loss = 0.9026998109916551, disc_loss = 0.006540525827957307
Trained batch 674 in epoch 19, gen_loss = 0.9030245380048398, disc_loss = 0.006532084478800513
Trained batch 675 in epoch 19, gen_loss = 0.9031762729382374, disc_loss = 0.006523675303200563
Trained batch 676 in epoch 19, gen_loss = 0.9034369180262353, disc_loss = 0.006514558595347
Trained batch 677 in epoch 19, gen_loss = 0.9037650406888101, disc_loss = 0.006506522835238241
Trained batch 678 in epoch 19, gen_loss = 0.9041303366378761, disc_loss = 0.006497770031038085
Trained batch 679 in epoch 19, gen_loss = 0.9046087217681548, disc_loss = 0.006488812965075982
Trained batch 680 in epoch 19, gen_loss = 0.9050009490459852, disc_loss = 0.006480166246971712
Trained batch 681 in epoch 19, gen_loss = 0.9053262987794065, disc_loss = 0.006471205212360967
Trained batch 682 in epoch 19, gen_loss = 0.9055582054537527, disc_loss = 0.006462291932389454
Trained batch 683 in epoch 19, gen_loss = 0.9057438713416719, disc_loss = 0.006453338028744019
Trained batch 684 in epoch 19, gen_loss = 0.9059392464421961, disc_loss = 0.006444404632489139
Trained batch 685 in epoch 19, gen_loss = 0.906166030436146, disc_loss = 0.006435561504577909
Trained batch 686 in epoch 19, gen_loss = 0.9062867129039903, disc_loss = 0.006426733543665004
Trained batch 687 in epoch 19, gen_loss = 0.906422864039277, disc_loss = 0.006417660177407396
Trained batch 688 in epoch 19, gen_loss = 0.9064852714711592, disc_loss = 0.006409231389501265
Trained batch 689 in epoch 19, gen_loss = 0.9064423957596655, disc_loss = 0.006402168418540184
Trained batch 690 in epoch 19, gen_loss = 0.9067059549167429, disc_loss = 0.0063934439897409025
Trained batch 691 in epoch 19, gen_loss = 0.9066629700922553, disc_loss = 0.0063885156662506016
Trained batch 692 in epoch 19, gen_loss = 0.9067331776130423, disc_loss = 0.006380142713752041
Trained batch 693 in epoch 19, gen_loss = 0.906914475843611, disc_loss = 0.006371766303303858
Trained batch 694 in epoch 19, gen_loss = 0.9068731147608311, disc_loss = 0.006364234438550863
Trained batch 695 in epoch 19, gen_loss = 0.9071609246833571, disc_loss = 0.006355785662294536
Trained batch 696 in epoch 19, gen_loss = 0.9071167137906746, disc_loss = 0.006347467358613843
Trained batch 697 in epoch 19, gen_loss = 0.90712871874301, disc_loss = 0.006338813704315337
Trained batch 698 in epoch 19, gen_loss = 0.907326820497008, disc_loss = 0.00633057981163211
Trained batch 699 in epoch 19, gen_loss = 0.9074898565667017, disc_loss = 0.006321925972328505
Trained batch 700 in epoch 19, gen_loss = 0.9075026954291721, disc_loss = 0.006313109017277755
Trained batch 701 in epoch 19, gen_loss = 0.907618664693289, disc_loss = 0.006304366118645682
Trained batch 702 in epoch 19, gen_loss = 0.9077688726049399, disc_loss = 0.006295742381607619
Trained batch 703 in epoch 19, gen_loss = 0.9076519311321053, disc_loss = 0.006287837142084837
Trained batch 704 in epoch 19, gen_loss = 0.9076813232814167, disc_loss = 0.006279174782674684
Trained batch 705 in epoch 19, gen_loss = 0.90783461717303, disc_loss = 0.006270849760437517
Trained batch 706 in epoch 19, gen_loss = 0.9080220545198152, disc_loss = 0.006262750423551966
Trained batch 707 in epoch 19, gen_loss = 0.9081908526730402, disc_loss = 0.006254143276401729
Trained batch 708 in epoch 19, gen_loss = 0.9080575908020622, disc_loss = 0.006246928454454176
Trained batch 709 in epoch 19, gen_loss = 0.9082159361369173, disc_loss = 0.006238940047396554
Trained batch 710 in epoch 19, gen_loss = 0.9083145385720727, disc_loss = 0.00623078272068988
Trained batch 711 in epoch 19, gen_loss = 0.9083572241027703, disc_loss = 0.0062227434098204365
Trained batch 712 in epoch 19, gen_loss = 0.9084304568643824, disc_loss = 0.006214465227904733
Trained batch 713 in epoch 19, gen_loss = 0.9083724058642775, disc_loss = 0.006206193968148805
Trained batch 714 in epoch 19, gen_loss = 0.9083352992584656, disc_loss = 0.006198194790686484
Trained batch 715 in epoch 19, gen_loss = 0.9086395268999664, disc_loss = 0.006190162971420276
Trained batch 716 in epoch 19, gen_loss = 0.9086793875594518, disc_loss = 0.006181881039210084
Trained batch 717 in epoch 19, gen_loss = 0.9088365619893194, disc_loss = 0.006173687594725727
Trained batch 718 in epoch 19, gen_loss = 0.9086913349565445, disc_loss = 0.006166567010824036
Trained batch 719 in epoch 19, gen_loss = 0.9087347490092118, disc_loss = 0.006158446355513863
Trained batch 720 in epoch 19, gen_loss = 0.9087849556986403, disc_loss = 0.006150172704260557
Trained batch 721 in epoch 19, gen_loss = 0.9088372121722414, disc_loss = 0.006142143535562304
Trained batch 722 in epoch 19, gen_loss = 0.9088234571665319, disc_loss = 0.0061341873272796315
Trained batch 723 in epoch 19, gen_loss = 0.9089298045766946, disc_loss = 0.006125942963879837
Trained batch 724 in epoch 19, gen_loss = 0.9088585465529869, disc_loss = 0.006118210682390531
Trained batch 725 in epoch 19, gen_loss = 0.9089717482403947, disc_loss = 0.006110035248072937
Trained batch 726 in epoch 19, gen_loss = 0.908902837452895, disc_loss = 0.006101943149393987
Trained batch 727 in epoch 19, gen_loss = 0.9090579543467406, disc_loss = 0.006094188739472963
Trained batch 728 in epoch 19, gen_loss = 0.9091129405998889, disc_loss = 0.006086283766414088
Trained batch 729 in epoch 19, gen_loss = 0.9092730582576909, disc_loss = 0.006078392861852317
Trained batch 730 in epoch 19, gen_loss = 0.9092308083898228, disc_loss = 0.00607023786558289
Trained batch 731 in epoch 19, gen_loss = 0.9091732354600572, disc_loss = 0.006062331824038859
Trained batch 732 in epoch 19, gen_loss = 0.9091975224619836, disc_loss = 0.0060542949807897975
Trained batch 733 in epoch 19, gen_loss = 0.9091871489620988, disc_loss = 0.006046256520837334
Trained batch 734 in epoch 19, gen_loss = 0.9091096545563263, disc_loss = 0.006038307777768695
Trained batch 735 in epoch 19, gen_loss = 0.9090590754766827, disc_loss = 0.006030451538396412
Trained batch 736 in epoch 19, gen_loss = 0.9091049347027348, disc_loss = 0.0060224433721189595
Trained batch 737 in epoch 19, gen_loss = 0.9091862002362404, disc_loss = 0.006014487247354951
Trained batch 738 in epoch 19, gen_loss = 0.90910732520288, disc_loss = 0.006006892345658159
Trained batch 739 in epoch 19, gen_loss = 0.9092559864392151, disc_loss = 0.005999091884734446
Trained batch 740 in epoch 19, gen_loss = 0.9091081102849984, disc_loss = 0.005992221161251427
Trained batch 741 in epoch 19, gen_loss = 0.9092133170510881, disc_loss = 0.005984415182274829
Trained batch 742 in epoch 19, gen_loss = 0.9089920654752534, disc_loss = 0.005977055049882647
Trained batch 743 in epoch 19, gen_loss = 0.9090283096477549, disc_loss = 0.0059692253508308235
Trained batch 744 in epoch 19, gen_loss = 0.9089528207010871, disc_loss = 0.005961469564641179
Trained batch 745 in epoch 19, gen_loss = 0.9089960786676279, disc_loss = 0.0059538711335998615
Trained batch 746 in epoch 19, gen_loss = 0.9089194624778257, disc_loss = 0.0059463185546189574
Trained batch 747 in epoch 19, gen_loss = 0.9089261573106847, disc_loss = 0.005938598587886069
Trained batch 748 in epoch 19, gen_loss = 0.9089360358081608, disc_loss = 0.005930897485081604
Trained batch 749 in epoch 19, gen_loss = 0.9089255782763164, disc_loss = 0.005923164369645141
Trained batch 750 in epoch 19, gen_loss = 0.9088622199869981, disc_loss = 0.005915725659301176
Trained batch 751 in epoch 19, gen_loss = 0.908955048690451, disc_loss = 0.005908141981492124
Trained batch 752 in epoch 19, gen_loss = 0.908992923984173, disc_loss = 0.005900596131951808
Trained batch 753 in epoch 19, gen_loss = 0.909109685481069, disc_loss = 0.00589293092875428
Trained batch 754 in epoch 19, gen_loss = 0.9091268069696742, disc_loss = 0.0058853050396759955
Trained batch 755 in epoch 19, gen_loss = 0.9091840516480189, disc_loss = 0.0058780241333566165
Trained batch 756 in epoch 19, gen_loss = 0.9092577220269207, disc_loss = 0.005870791259279018
Trained batch 757 in epoch 19, gen_loss = 0.9093039334606684, disc_loss = 0.005863455621469818
Trained batch 758 in epoch 19, gen_loss = 0.9094119290275222, disc_loss = 0.005856124193101832
Trained batch 759 in epoch 19, gen_loss = 0.9092299197849475, disc_loss = 0.005854380850407899
Trained batch 760 in epoch 19, gen_loss = 0.9093436100636456, disc_loss = 0.0058475224284181195
Trained batch 761 in epoch 19, gen_loss = 0.9093506213404688, disc_loss = 0.005840285121349956
Trained batch 762 in epoch 19, gen_loss = 0.9092962100496454, disc_loss = 0.0058338769351875715
Trained batch 763 in epoch 19, gen_loss = 0.9094857716279504, disc_loss = 0.005826919843590619
Trained batch 764 in epoch 19, gen_loss = 0.9093549441667943, disc_loss = 0.00582053802164273
Trained batch 765 in epoch 19, gen_loss = 0.9094978332830783, disc_loss = 0.005813542825885147
Trained batch 766 in epoch 19, gen_loss = 0.9096502003489448, disc_loss = 0.005806441167640033
Trained batch 767 in epoch 19, gen_loss = 0.9095814395695925, disc_loss = 0.005799790430510636
Trained batch 768 in epoch 19, gen_loss = 0.9097030917751774, disc_loss = 0.005792952712176938
Trained batch 769 in epoch 19, gen_loss = 0.9097879201560826, disc_loss = 0.005785815547722733
Trained batch 770 in epoch 19, gen_loss = 0.9098890145465094, disc_loss = 0.005778598509625554
Trained batch 771 in epoch 19, gen_loss = 0.9100523005032168, disc_loss = 0.005771336343120635
Trained batch 772 in epoch 19, gen_loss = 0.9101456763827631, disc_loss = 0.005764133606422231
Trained batch 773 in epoch 19, gen_loss = 0.9102197972533007, disc_loss = 0.005756904515690091
Trained batch 774 in epoch 19, gen_loss = 0.9103986125607645, disc_loss = 0.005749895342000415
Trained batch 775 in epoch 19, gen_loss = 0.9103582596655974, disc_loss = 0.005742879487096963
Trained batch 776 in epoch 19, gen_loss = 0.9103192534379211, disc_loss = 0.0057357022852349655
Trained batch 777 in epoch 19, gen_loss = 0.9102810061223097, disc_loss = 0.005728732477401842
Trained batch 778 in epoch 19, gen_loss = 0.910136141351619, disc_loss = 0.005721762875296084
Trained batch 779 in epoch 19, gen_loss = 0.9102581659188638, disc_loss = 0.005714962527800265
Trained batch 780 in epoch 19, gen_loss = 0.9103334409479296, disc_loss = 0.005708132928395546
Trained batch 781 in epoch 19, gen_loss = 0.9103174675303651, disc_loss = 0.0057012153614163985
Trained batch 782 in epoch 19, gen_loss = 0.9103610953304199, disc_loss = 0.005694158887525941
Trained batch 783 in epoch 19, gen_loss = 0.9102393692093236, disc_loss = 0.005687350299133553
Trained batch 784 in epoch 19, gen_loss = 0.9101203917697737, disc_loss = 0.005683080208104824
Trained batch 785 in epoch 19, gen_loss = 0.9102768281488928, disc_loss = 0.0056762514298430876
Trained batch 786 in epoch 19, gen_loss = 0.9103286615472282, disc_loss = 0.005669824223721851
Trained batch 787 in epoch 19, gen_loss = 0.9102921459426735, disc_loss = 0.005663188158402318
Trained batch 788 in epoch 19, gen_loss = 0.9104120476768648, disc_loss = 0.005656466242682507
Trained batch 789 in epoch 19, gen_loss = 0.9104378148724761, disc_loss = 0.00564955517654624
Trained batch 790 in epoch 19, gen_loss = 0.9105288812845908, disc_loss = 0.005642789997346685
Trained batch 791 in epoch 19, gen_loss = 0.910452554246994, disc_loss = 0.005636009647796619
Trained batch 792 in epoch 19, gen_loss = 0.910403166337392, disc_loss = 0.005629177482952913
Trained batch 793 in epoch 19, gen_loss = 0.9103372126292222, disc_loss = 0.00562230180301834
Trained batch 794 in epoch 19, gen_loss = 0.9102316371299936, disc_loss = 0.00561537655457926
Trained batch 795 in epoch 19, gen_loss = 0.9101819354834868, disc_loss = 0.005608513199912701
Trained batch 796 in epoch 19, gen_loss = 0.9099915901869723, disc_loss = 0.0056019136345559824
Trained batch 797 in epoch 19, gen_loss = 0.9098508786736873, disc_loss = 0.005595256542840714
Trained batch 798 in epoch 19, gen_loss = 0.9098785007104409, disc_loss = 0.00558885457897706
Trained batch 799 in epoch 19, gen_loss = 0.909903398156166, disc_loss = 0.0055821680812459815
Trained batch 800 in epoch 19, gen_loss = 0.9098733091324605, disc_loss = 0.0055753676611532636
Trained batch 801 in epoch 19, gen_loss = 0.9097302379899489, disc_loss = 0.0055686378207456455
Trained batch 802 in epoch 19, gen_loss = 0.9097136150706898, disc_loss = 0.005561919683869392
Trained batch 803 in epoch 19, gen_loss = 0.9097809533574688, disc_loss = 0.005555209182019288
Trained batch 804 in epoch 19, gen_loss = 0.9097534330735295, disc_loss = 0.005548538439966787
Trained batch 805 in epoch 19, gen_loss = 0.9098849018513416, disc_loss = 0.005541884751708282
Trained batch 806 in epoch 19, gen_loss = 0.9097939471182179, disc_loss = 0.00553536746974827
Trained batch 807 in epoch 19, gen_loss = 0.9096013848291765, disc_loss = 0.005528740119324097
Trained batch 808 in epoch 19, gen_loss = 0.9096718402521866, disc_loss = 0.005522214866092424
Trained batch 809 in epoch 19, gen_loss = 0.9097813768151366, disc_loss = 0.005515643703472085
Trained batch 810 in epoch 19, gen_loss = 0.9096951669888197, disc_loss = 0.00550914851246646
Trained batch 811 in epoch 19, gen_loss = 0.909664025667853, disc_loss = 0.00550250942919752
Trained batch 812 in epoch 19, gen_loss = 0.9094910673696324, disc_loss = 0.005496298136799006
Trained batch 813 in epoch 19, gen_loss = 0.9093971804553227, disc_loss = 0.005489767824041632
Trained batch 814 in epoch 19, gen_loss = 0.9093506517585801, disc_loss = 0.005483227198696381
Trained batch 815 in epoch 19, gen_loss = 0.909322201402164, disc_loss = 0.00547699094550255
Trained batch 816 in epoch 19, gen_loss = 0.9093556367636019, disc_loss = 0.005470461436789431
Trained batch 817 in epoch 19, gen_loss = 0.9092349093088602, disc_loss = 0.00546420310792376
Trained batch 818 in epoch 19, gen_loss = 0.909056985116267, disc_loss = 0.0054580745520816445
Trained batch 819 in epoch 19, gen_loss = 0.9088817530288928, disc_loss = 0.005451525364182222
Trained batch 820 in epoch 19, gen_loss = 0.9087751536073115, disc_loss = 0.005445073904500024
Trained batch 821 in epoch 19, gen_loss = 0.9087230368832312, disc_loss = 0.0054387864190536305
Trained batch 822 in epoch 19, gen_loss = 0.9086803413683125, disc_loss = 0.005432315182920988
Trained batch 823 in epoch 19, gen_loss = 0.9087079798856985, disc_loss = 0.005426039806082469
Trained batch 824 in epoch 19, gen_loss = 0.9086779307596611, disc_loss = 0.005419624056905212
Trained batch 825 in epoch 19, gen_loss = 0.9087006116317491, disc_loss = 0.005413203251516189
Trained batch 826 in epoch 19, gen_loss = 0.9086488347676241, disc_loss = 0.005406797577528395
Trained batch 827 in epoch 19, gen_loss = 0.9085747826358547, disc_loss = 0.005400455213706321
Trained batch 828 in epoch 19, gen_loss = 0.9084829138041406, disc_loss = 0.005394113026242335
Trained batch 829 in epoch 19, gen_loss = 0.9084536209163896, disc_loss = 0.005387749190719978
Trained batch 830 in epoch 19, gen_loss = 0.9083897903220892, disc_loss = 0.005381525572906719
Trained batch 831 in epoch 19, gen_loss = 0.9083955379632803, disc_loss = 0.005375237816434282
Trained batch 832 in epoch 19, gen_loss = 0.9084717410237563, disc_loss = 0.005368959809075437
Trained batch 833 in epoch 19, gen_loss = 0.9083560802381959, disc_loss = 0.005362834062536718
Trained batch 834 in epoch 19, gen_loss = 0.9083220006463056, disc_loss = 0.005356515715817829
Trained batch 835 in epoch 19, gen_loss = 0.9082032159755105, disc_loss = 0.005350268309693697
Trained batch 836 in epoch 19, gen_loss = 0.9081019347571415, disc_loss = 0.005344308377905977
Trained batch 837 in epoch 19, gen_loss = 0.9080176761725068, disc_loss = 0.005338138121779053
Trained batch 838 in epoch 19, gen_loss = 0.9080606846758237, disc_loss = 0.005331933853291467
Trained batch 839 in epoch 19, gen_loss = 0.9079383614517393, disc_loss = 0.005325792781072128
Trained batch 840 in epoch 19, gen_loss = 0.9078795625678707, disc_loss = 0.005320185995943455
Trained batch 841 in epoch 19, gen_loss = 0.9078273881501087, disc_loss = 0.005314040836003831
Trained batch 842 in epoch 19, gen_loss = 0.9079144182719936, disc_loss = 0.00530787107201825
Trained batch 843 in epoch 19, gen_loss = 0.9079859121857097, disc_loss = 0.005301761378293997
Trained batch 844 in epoch 19, gen_loss = 0.9079154287569622, disc_loss = 0.005295706981381115
Trained batch 845 in epoch 19, gen_loss = 0.907985073384382, disc_loss = 0.0052899057072412275
Trained batch 846 in epoch 19, gen_loss = 0.9078686282372953, disc_loss = 0.005283945304095039
Trained batch 847 in epoch 19, gen_loss = 0.9078467968359308, disc_loss = 0.0052780069959655245
Trained batch 848 in epoch 19, gen_loss = 0.9078822535395763, disc_loss = 0.005272228391298057
Trained batch 849 in epoch 19, gen_loss = 0.9079135039974662, disc_loss = 0.005266211708675495
Trained batch 850 in epoch 19, gen_loss = 0.9079026303196065, disc_loss = 0.005260290920328252
Trained batch 851 in epoch 19, gen_loss = 0.9079102783555716, disc_loss = 0.005254355581311816
Trained batch 852 in epoch 19, gen_loss = 0.9079408858054409, disc_loss = 0.005248366763815557
Trained batch 853 in epoch 19, gen_loss = 0.9079523462741101, disc_loss = 0.005244866196363041
Trained batch 854 in epoch 19, gen_loss = 0.9079992136062934, disc_loss = 0.005239352914511515
Trained batch 855 in epoch 19, gen_loss = 0.9080383320835149, disc_loss = 0.005233814635796301
Trained batch 856 in epoch 19, gen_loss = 0.90805377133947, disc_loss = 0.005228292832077429
Trained batch 857 in epoch 19, gen_loss = 0.9080930062524089, disc_loss = 0.005222754117522317
Trained batch 858 in epoch 19, gen_loss = 0.9081918713793904, disc_loss = 0.005217017155553717
Trained batch 859 in epoch 19, gen_loss = 0.9081997774368109, disc_loss = 0.0052112836452663965
Trained batch 860 in epoch 19, gen_loss = 0.9082657066925616, disc_loss = 0.0052055645087162195
Trained batch 861 in epoch 19, gen_loss = 0.908402543610044, disc_loss = 0.0051997720092955575
Trained batch 862 in epoch 19, gen_loss = 0.9083992433437467, disc_loss = 0.005194077361000757
Trained batch 863 in epoch 19, gen_loss = 0.9082750357273552, disc_loss = 0.005188306334528331
Trained batch 864 in epoch 19, gen_loss = 0.9082756675736753, disc_loss = 0.0051824753073271565
Trained batch 865 in epoch 19, gen_loss = 0.9082967165435984, disc_loss = 0.0051766547131648945
Trained batch 866 in epoch 19, gen_loss = 0.9082421229372387, disc_loss = 0.005170866343528575
Trained batch 867 in epoch 19, gen_loss = 0.9081913552800631, disc_loss = 0.005165218671808349
Trained batch 868 in epoch 19, gen_loss = 0.9081299925700979, disc_loss = 0.005159471741961492
Trained batch 869 in epoch 19, gen_loss = 0.9081429719239816, disc_loss = 0.005153914591837433
Trained batch 870 in epoch 19, gen_loss = 0.9081644808657544, disc_loss = 0.0051482949950995595
Trained batch 871 in epoch 19, gen_loss = 0.9083212490338798, disc_loss = 0.005142592850678313
Trained batch 872 in epoch 19, gen_loss = 0.9082455760698002, disc_loss = 0.0051369139658310374
Trained batch 873 in epoch 19, gen_loss = 0.9081962747622955, disc_loss = 0.0051313129433037
Trained batch 874 in epoch 19, gen_loss = 0.9080776322228568, disc_loss = 0.005126438578224874
Trained batch 875 in epoch 19, gen_loss = 0.9082698061313803, disc_loss = 0.00512229903861184
Trained batch 876 in epoch 19, gen_loss = 0.9081301217476074, disc_loss = 0.005117905059275287
Trained batch 877 in epoch 19, gen_loss = 0.9079883785617107, disc_loss = 0.00511258864536768
Trained batch 878 in epoch 19, gen_loss = 0.9079651549136408, disc_loss = 0.005107017907925083
Trained batch 879 in epoch 19, gen_loss = 0.9081315613605759, disc_loss = 0.005101646218860299
Trained batch 880 in epoch 19, gen_loss = 0.9082242414169225, disc_loss = 0.005096181441133072
Trained batch 881 in epoch 19, gen_loss = 0.9081084766760975, disc_loss = 0.0050907576592747845
Trained batch 882 in epoch 19, gen_loss = 0.9081663886931043, disc_loss = 0.0050852587676137985
Trained batch 883 in epoch 19, gen_loss = 0.9081575626431547, disc_loss = 0.005079608751414554
Trained batch 884 in epoch 19, gen_loss = 0.9080936652792375, disc_loss = 0.005074178325643731
Trained batch 885 in epoch 19, gen_loss = 0.908022915671157, disc_loss = 0.005068691967419295
Trained batch 886 in epoch 19, gen_loss = 0.9081299155782552, disc_loss = 0.00506331674855876
Trained batch 887 in epoch 19, gen_loss = 0.9080044711763794, disc_loss = 0.00505775965693583
Trained batch 888 in epoch 19, gen_loss = 0.907998547980434, disc_loss = 0.00505217438571496
Trained batch 889 in epoch 19, gen_loss = 0.9080043727762244, disc_loss = 0.0050466384611640575
Trained batch 890 in epoch 19, gen_loss = 0.9079360981314003, disc_loss = 0.005041225278027791
Trained batch 891 in epoch 19, gen_loss = 0.9079153374706148, disc_loss = 0.005035751252946096
Trained batch 892 in epoch 19, gen_loss = 0.9079428464007404, disc_loss = 0.005030200767714683
Trained batch 893 in epoch 19, gen_loss = 0.9079710039783111, disc_loss = 0.005024681956849024
Trained batch 894 in epoch 19, gen_loss = 0.9078020631268038, disc_loss = 0.005019202044888272
Trained batch 895 in epoch 19, gen_loss = 0.9077731324359775, disc_loss = 0.0050136787463900745
Trained batch 896 in epoch 19, gen_loss = 0.9077284872997033, disc_loss = 0.005008206166635364
Trained batch 897 in epoch 19, gen_loss = 0.9076141813948319, disc_loss = 0.005002982381342097
Trained batch 898 in epoch 19, gen_loss = 0.9076940146118435, disc_loss = 0.004997605992907408
Trained batch 899 in epoch 19, gen_loss = 0.9077632735172908, disc_loss = 0.004992247688723081
Trained batch 900 in epoch 19, gen_loss = 0.9077212330900736, disc_loss = 0.0049868517539436285
Trained batch 901 in epoch 19, gen_loss = 0.907687873242964, disc_loss = 0.0049815320084207046
Trained batch 902 in epoch 19, gen_loss = 0.9075900308977594, disc_loss = 0.004976133671279141
Trained batch 903 in epoch 19, gen_loss = 0.9075629859503391, disc_loss = 0.004970743420395528
Trained batch 904 in epoch 19, gen_loss = 0.907481479315468, disc_loss = 0.004965470406646166
Trained batch 905 in epoch 19, gen_loss = 0.9074588555505471, disc_loss = 0.00496012959490524
Trained batch 906 in epoch 19, gen_loss = 0.9074105717644276, disc_loss = 0.004954756019440161
Trained batch 907 in epoch 19, gen_loss = 0.9074072691443733, disc_loss = 0.004949470632461155
Trained batch 908 in epoch 19, gen_loss = 0.9073546772087105, disc_loss = 0.004944290483140987
Trained batch 909 in epoch 19, gen_loss = 0.9074577419312446, disc_loss = 0.004939073644705427
Trained batch 910 in epoch 19, gen_loss = 0.9074099253613653, disc_loss = 0.004933942427419949
Trained batch 911 in epoch 19, gen_loss = 0.9073291535963092, disc_loss = 0.004928673926762011
Trained batch 912 in epoch 19, gen_loss = 0.9071560608465857, disc_loss = 0.004923570788429929
Trained batch 913 in epoch 19, gen_loss = 0.9071022587740708, disc_loss = 0.004918397607908651
Trained batch 914 in epoch 19, gen_loss = 0.9072120437205163, disc_loss = 0.004913138738530243
Trained batch 915 in epoch 19, gen_loss = 0.907069268250049, disc_loss = 0.004907906885267051
Trained batch 916 in epoch 19, gen_loss = 0.9070354386140372, disc_loss = 0.0049027405248492405
Trained batch 917 in epoch 19, gen_loss = 0.907105435927709, disc_loss = 0.004897516935405348
Trained batch 918 in epoch 19, gen_loss = 0.907185935416341, disc_loss = 0.004892325530256073
Trained batch 919 in epoch 19, gen_loss = 0.9072350472859715, disc_loss = 0.0048871013610867365
Trained batch 920 in epoch 19, gen_loss = 0.9072378869294861, disc_loss = 0.0048818778190534914
Trained batch 921 in epoch 19, gen_loss = 0.9071547030885411, disc_loss = 0.004876678207962874
Trained batch 922 in epoch 19, gen_loss = 0.9071794444793999, disc_loss = 0.004871519392135617
Trained batch 923 in epoch 19, gen_loss = 0.907288936567513, disc_loss = 0.004866335324313932
Trained batch 924 in epoch 19, gen_loss = 0.907267444907008, disc_loss = 0.004861289009639075
Trained batch 925 in epoch 19, gen_loss = 0.9072779783291127, disc_loss = 0.0048561297316082426
Trained batch 926 in epoch 19, gen_loss = 0.9072572041097968, disc_loss = 0.004851008631771432
Trained batch 927 in epoch 19, gen_loss = 0.9073143055469826, disc_loss = 0.004845861730912255
Trained batch 928 in epoch 19, gen_loss = 0.9072251040147632, disc_loss = 0.004840854194617203
Trained batch 929 in epoch 19, gen_loss = 0.9072350526368747, disc_loss = 0.004835740515370153
Trained batch 930 in epoch 19, gen_loss = 0.9072074809468779, disc_loss = 0.004830646743209158
Trained batch 931 in epoch 19, gen_loss = 0.9071835881266983, disc_loss = 0.004825558610254366
Trained batch 932 in epoch 19, gen_loss = 0.9071539996904575, disc_loss = 0.0048204877250884
Trained batch 933 in epoch 19, gen_loss = 0.9073026323216375, disc_loss = 0.004815414322061727
Trained batch 934 in epoch 19, gen_loss = 0.9071886520972227, disc_loss = 0.004810326394281365
Trained batch 935 in epoch 19, gen_loss = 0.9070969716223896, disc_loss = 0.00480527330487387
Trained batch 936 in epoch 19, gen_loss = 0.9072326581404329, disc_loss = 0.004800248287661086
Trained batch 937 in epoch 19, gen_loss = 0.9071934718185904, disc_loss = 0.004795210264970488
Trained batch 938 in epoch 19, gen_loss = 0.9071480671183878, disc_loss = 0.004790227895569296
Trained batch 939 in epoch 19, gen_loss = 0.9071444721298015, disc_loss = 0.004785300333644548
Trained batch 940 in epoch 19, gen_loss = 0.9069809919336017, disc_loss = 0.004781275381045315
Trained batch 941 in epoch 19, gen_loss = 0.9069259311616295, disc_loss = 0.004776752941614605
Trained batch 942 in epoch 19, gen_loss = 0.9068157811306441, disc_loss = 0.004771909701792177
Trained batch 943 in epoch 19, gen_loss = 0.9067461258274013, disc_loss = 0.004767052371350427
Trained batch 944 in epoch 19, gen_loss = 0.9067199630081338, disc_loss = 0.004762211896544729
Trained batch 945 in epoch 19, gen_loss = 0.906771939224219, disc_loss = 0.004757547308950811
Trained batch 946 in epoch 19, gen_loss = 0.906822353632926, disc_loss = 0.004752665370955182
Trained batch 947 in epoch 19, gen_loss = 0.9068454872455275, disc_loss = 0.00474784692730132
Trained batch 948 in epoch 19, gen_loss = 0.9067683096178214, disc_loss = 0.0047429320195281795
Trained batch 949 in epoch 19, gen_loss = 0.9067221251914376, disc_loss = 0.004738048239761204
Trained batch 950 in epoch 19, gen_loss = 0.9066696893404209, disc_loss = 0.004733382818774716
Trained batch 951 in epoch 19, gen_loss = 0.9066362212560758, disc_loss = 0.004728498984241779
Trained batch 952 in epoch 19, gen_loss = 0.9066513035630129, disc_loss = 0.0047236101589608935
Trained batch 953 in epoch 19, gen_loss = 0.9065187706512475, disc_loss = 0.004718953844258258
Trained batch 954 in epoch 19, gen_loss = 0.9065211878397078, disc_loss = 0.004714172586247981
Trained batch 955 in epoch 19, gen_loss = 0.9065922775527923, disc_loss = 0.004709344320499402
Trained batch 956 in epoch 19, gen_loss = 0.9065225521723429, disc_loss = 0.004704578405051444
Trained batch 957 in epoch 19, gen_loss = 0.9064990996318969, disc_loss = 0.004699742932138794
Trained batch 958 in epoch 19, gen_loss = 0.9064168331521146, disc_loss = 0.004694963701571798
Trained batch 959 in epoch 19, gen_loss = 0.906359882839024, disc_loss = 0.004690158749190232
Trained batch 960 in epoch 19, gen_loss = 0.9062437236495122, disc_loss = 0.004685442040086376
Trained batch 961 in epoch 19, gen_loss = 0.9062262943281701, disc_loss = 0.004680655473606817
Trained batch 962 in epoch 19, gen_loss = 0.906239500050728, disc_loss = 0.004675939309386634
Trained batch 963 in epoch 19, gen_loss = 0.9061463424526309, disc_loss = 0.004671193465066186
Trained batch 964 in epoch 19, gen_loss = 0.9059436399701963, disc_loss = 0.004666676352693581
Trained batch 965 in epoch 19, gen_loss = 0.9058929807034092, disc_loss = 0.004662164636388025
Trained batch 966 in epoch 19, gen_loss = 0.9058778519590983, disc_loss = 0.004657511974920193
Trained batch 967 in epoch 19, gen_loss = 0.9057846770675715, disc_loss = 0.004653001815230792
Trained batch 968 in epoch 19, gen_loss = 0.9057623000336874, disc_loss = 0.004648455113288886
Trained batch 969 in epoch 19, gen_loss = 0.9056582895750852, disc_loss = 0.0046437685888188
Trained batch 970 in epoch 19, gen_loss = 0.9056244726406927, disc_loss = 0.004639136565497721
Trained batch 971 in epoch 19, gen_loss = 0.9056019724151234, disc_loss = 0.004634457955873414
Trained batch 972 in epoch 19, gen_loss = 0.9055260228718662, disc_loss = 0.004629779336366524
Trained batch 973 in epoch 19, gen_loss = 0.9054629430633796, disc_loss = 0.004625120395868316
Trained batch 974 in epoch 19, gen_loss = 0.9054036645400219, disc_loss = 0.004620453469800011
Trained batch 975 in epoch 19, gen_loss = 0.9054989095960484, disc_loss = 0.004615832700176829
Trained batch 976 in epoch 19, gen_loss = 0.9054915049058998, disc_loss = 0.004611234466998136
Trained batch 977 in epoch 19, gen_loss = 0.9053918871655299, disc_loss = 0.004606616434374308
Trained batch 978 in epoch 19, gen_loss = 0.9053448455691703, disc_loss = 0.004601967656486593
Trained batch 979 in epoch 19, gen_loss = 0.9052957728201029, disc_loss = 0.004597407340061553
Trained batch 980 in epoch 19, gen_loss = 0.9051649468389855, disc_loss = 0.004592839526865332
Trained batch 981 in epoch 19, gen_loss = 0.905130134823366, disc_loss = 0.004588342684048235
Trained batch 982 in epoch 19, gen_loss = 0.9050590597843469, disc_loss = 0.004583898801015036
Trained batch 983 in epoch 19, gen_loss = 0.9049681749770312, disc_loss = 0.004579317804300223
Trained batch 984 in epoch 19, gen_loss = 0.9050326478057706, disc_loss = 0.004574795145229561
Trained batch 985 in epoch 19, gen_loss = 0.905049129504461, disc_loss = 0.004570273436505661
Trained batch 986 in epoch 19, gen_loss = 0.9050607299611441, disc_loss = 0.004565767215404525
Trained batch 987 in epoch 19, gen_loss = 0.9050384183161655, disc_loss = 0.004561321648620115
Trained batch 988 in epoch 19, gen_loss = 0.904969494432, disc_loss = 0.004556832541755622
Trained batch 989 in epoch 19, gen_loss = 0.9049098967301725, disc_loss = 0.004552382563538185
Trained batch 990 in epoch 19, gen_loss = 0.90473101773007, disc_loss = 0.00454863246274307
Trained batch 991 in epoch 19, gen_loss = 0.9046164333459831, disc_loss = 0.0045444237395324836
Trained batch 992 in epoch 19, gen_loss = 0.9046764302349762, disc_loss = 0.004540005882768975
Trained batch 993 in epoch 19, gen_loss = 0.9047895701718283, disc_loss = 0.004535595381143801
Trained batch 994 in epoch 19, gen_loss = 0.9047245033422308, disc_loss = 0.004531131150099611
Trained batch 995 in epoch 19, gen_loss = 0.9046747680289678, disc_loss = 0.004526736424280438
Trained batch 996 in epoch 19, gen_loss = 0.9047047029526806, disc_loss = 0.004522270493911503
Trained batch 997 in epoch 19, gen_loss = 0.904762422094842, disc_loss = 0.004518066340064186
Trained batch 998 in epoch 19, gen_loss = 0.9048358272981118, disc_loss = 0.004513649646529362
Trained batch 999 in epoch 19, gen_loss = 0.9046967088580131, disc_loss = 0.004509225966688973
Trained batch 1000 in epoch 19, gen_loss = 0.9046781519790749, disc_loss = 0.004504812227048581
Trained batch 1001 in epoch 19, gen_loss = 0.9046495423583452, disc_loss = 0.004500374409569001
Trained batch 1002 in epoch 19, gen_loss = 0.9045347524426157, disc_loss = 0.004495979718010319
Trained batch 1003 in epoch 19, gen_loss = 0.9044051775894317, disc_loss = 0.004491675515743711
Trained batch 1004 in epoch 19, gen_loss = 0.9043155373625494, disc_loss = 0.00448735025578508
Trained batch 1005 in epoch 19, gen_loss = 0.9043043150342482, disc_loss = 0.004483042260346001
Trained batch 1006 in epoch 19, gen_loss = 0.9043614383724027, disc_loss = 0.0044786851108116095
Trained batch 1007 in epoch 19, gen_loss = 0.9042899398103593, disc_loss = 0.004474357090798332
Trained batch 1008 in epoch 19, gen_loss = 0.9043104383943102, disc_loss = 0.00447000139594173
Trained batch 1009 in epoch 19, gen_loss = 0.9042879843475795, disc_loss = 0.0044656445051646865
Trained batch 1010 in epoch 19, gen_loss = 0.9043299774505736, disc_loss = 0.004461334010002886
Trained batch 1011 in epoch 19, gen_loss = 0.9042883389316528, disc_loss = 0.004457029797715955
Trained batch 1012 in epoch 19, gen_loss = 0.9041857712949016, disc_loss = 0.004452753887531298
Trained batch 1013 in epoch 19, gen_loss = 0.9040714820931414, disc_loss = 0.004448462242594925
Trained batch 1014 in epoch 19, gen_loss = 0.9040922593600644, disc_loss = 0.0044441519431023474
Trained batch 1015 in epoch 19, gen_loss = 0.9039813203253145, disc_loss = 0.004439858907467061
Trained batch 1016 in epoch 19, gen_loss = 0.9040005798419551, disc_loss = 0.0044355960730558565
Trained batch 1017 in epoch 19, gen_loss = 0.9039715594650486, disc_loss = 0.004431363953527939
Trained batch 1018 in epoch 19, gen_loss = 0.9038875401897449, disc_loss = 0.004427103474046319
Trained batch 1019 in epoch 19, gen_loss = 0.9037278361764609, disc_loss = 0.004422966207854259
Trained batch 1020 in epoch 19, gen_loss = 0.903732160104477, disc_loss = 0.004418697995597905
Trained batch 1021 in epoch 19, gen_loss = 0.9037296363168966, disc_loss = 0.0044144808154434655
Trained batch 1022 in epoch 19, gen_loss = 0.9036822425072261, disc_loss = 0.004410241400820693
Trained batch 1023 in epoch 19, gen_loss = 0.9037785331020132, disc_loss = 0.004406103985285625
Trained batch 1024 in epoch 19, gen_loss = 0.9038153043025877, disc_loss = 0.004401892026074986
Trained batch 1025 in epoch 19, gen_loss = 0.9036993633004424, disc_loss = 0.004397759187453751
Trained batch 1026 in epoch 19, gen_loss = 0.903675135642203, disc_loss = 0.004393550499688029
Trained batch 1027 in epoch 19, gen_loss = 0.903684806846923, disc_loss = 0.004389367900755065
Trained batch 1028 in epoch 19, gen_loss = 0.9035025532669646, disc_loss = 0.004385341992871719
Trained batch 1029 in epoch 19, gen_loss = 0.9035075564407608, disc_loss = 0.004381177886036701
Trained batch 1030 in epoch 19, gen_loss = 0.9034222797440974, disc_loss = 0.0043771229412827685
Trained batch 1031 in epoch 19, gen_loss = 0.9033570742422297, disc_loss = 0.004372982163859824
Trained batch 1032 in epoch 19, gen_loss = 0.9033993405271015, disc_loss = 0.004368811717781026
Trained batch 1033 in epoch 19, gen_loss = 0.9033301009200297, disc_loss = 0.0043647057033713126
Trained batch 1034 in epoch 19, gen_loss = 0.9033178676153727, disc_loss = 0.004360594179266574
Trained batch 1035 in epoch 19, gen_loss = 0.9031672410983377, disc_loss = 0.004356512933301936
Trained batch 1036 in epoch 19, gen_loss = 0.9031613626038671, disc_loss = 0.004352368654024481
Trained batch 1037 in epoch 19, gen_loss = 0.9032897334797074, disc_loss = 0.004348244520901524
Trained batch 1038 in epoch 19, gen_loss = 0.9033088583115549, disc_loss = 0.004344182753485257
Trained batch 1039 in epoch 19, gen_loss = 0.9031139786999959, disc_loss = 0.004340506940178994
Trained batch 1040 in epoch 19, gen_loss = 0.9031543885138491, disc_loss = 0.004336579414384259
Trained batch 1041 in epoch 19, gen_loss = 0.9032741931486954, disc_loss = 0.004332637558905712
Trained batch 1042 in epoch 19, gen_loss = 0.903259526048845, disc_loss = 0.0043286735392347505
Trained batch 1043 in epoch 19, gen_loss = 0.9031927067201256, disc_loss = 0.004324603654042005
Trained batch 1044 in epoch 19, gen_loss = 0.903170659895719, disc_loss = 0.004320639002448255
Trained batch 1045 in epoch 19, gen_loss = 0.9030258423625626, disc_loss = 0.00431674629412616
Trained batch 1046 in epoch 19, gen_loss = 0.9029753926034871, disc_loss = 0.004312792857781425
Trained batch 1047 in epoch 19, gen_loss = 0.9029615829122886, disc_loss = 0.00430884551808035
Trained batch 1048 in epoch 19, gen_loss = 0.9028568157022402, disc_loss = 0.004304964031902736
Trained batch 1049 in epoch 19, gen_loss = 0.9027817338988895, disc_loss = 0.004301062904276131
Trained batch 1050 in epoch 19, gen_loss = 0.9027716452229261, disc_loss = 0.004297091198723907
Trained batch 1051 in epoch 19, gen_loss = 0.9027823274353158, disc_loss = 0.004293194335996339
Trained batch 1052 in epoch 19, gen_loss = 0.9027835798059773, disc_loss = 0.004289229919308427
Trained batch 1053 in epoch 19, gen_loss = 0.9028096123822953, disc_loss = 0.0042852688512078525
Trained batch 1054 in epoch 19, gen_loss = 0.9026698575200628, disc_loss = 0.004281609367220045
Trained batch 1055 in epoch 19, gen_loss = 0.902653590014035, disc_loss = 0.00427769880471632
Trained batch 1056 in epoch 19, gen_loss = 0.9026251113290705, disc_loss = 0.004273782005176621
Trained batch 1057 in epoch 19, gen_loss = 0.902499675469047, disc_loss = 0.004270466119464155
Trained batch 1058 in epoch 19, gen_loss = 0.9024529114323365, disc_loss = 0.004266633630508264
Trained batch 1059 in epoch 19, gen_loss = 0.9024429524282239, disc_loss = 0.004262712341129235
Trained batch 1060 in epoch 19, gen_loss = 0.9024124551673299, disc_loss = 0.00425922550625518
Trained batch 1061 in epoch 19, gen_loss = 0.9024227712226228, disc_loss = 0.004255313828050728
Trained batch 1062 in epoch 19, gen_loss = 0.9024567554160771, disc_loss = 0.004251428754675629
Trained batch 1063 in epoch 19, gen_loss = 0.9024543734757524, disc_loss = 0.004247569943793206
Trained batch 1064 in epoch 19, gen_loss = 0.9024358557983183, disc_loss = 0.004243716489954878
Trained batch 1065 in epoch 19, gen_loss = 0.9024882573235997, disc_loss = 0.004239826512476965
Trained batch 1066 in epoch 19, gen_loss = 0.9025026734118833, disc_loss = 0.004235942991568372
Trained batch 1067 in epoch 19, gen_loss = 0.9026577047417673, disc_loss = 0.0042322904383660116
Trained batch 1068 in epoch 19, gen_loss = 0.9026152744708048, disc_loss = 0.00422846197928583
Trained batch 1069 in epoch 19, gen_loss = 0.9027679704617118, disc_loss = 0.00422462922944981
Trained batch 1070 in epoch 19, gen_loss = 0.9026577205551105, disc_loss = 0.0042207960013452795
Trained batch 1071 in epoch 19, gen_loss = 0.9026451060242617, disc_loss = 0.004217008277729333
Trained batch 1072 in epoch 19, gen_loss = 0.9025856102612789, disc_loss = 0.004213162217163789
Trained batch 1073 in epoch 19, gen_loss = 0.902578004412145, disc_loss = 0.004209358720822101
Trained batch 1074 in epoch 19, gen_loss = 0.9025247297176094, disc_loss = 0.00420560700410089
Trained batch 1075 in epoch 19, gen_loss = 0.9025072807162224, disc_loss = 0.004201855054387016
Trained batch 1076 in epoch 19, gen_loss = 0.9024897700896835, disc_loss = 0.004198159814338583
Trained batch 1077 in epoch 19, gen_loss = 0.9024758630316421, disc_loss = 0.004194606113344118
Trained batch 1078 in epoch 19, gen_loss = 0.902569761035396, disc_loss = 0.004190936942389097
Trained batch 1079 in epoch 19, gen_loss = 0.9025688767985062, disc_loss = 0.0041872183339162605
Trained batch 1080 in epoch 19, gen_loss = 0.9026089166183365, disc_loss = 0.004183450648667197
Trained batch 1081 in epoch 19, gen_loss = 0.9025383375709026, disc_loss = 0.004179719630649805
Trained batch 1082 in epoch 19, gen_loss = 0.9024534363055383, disc_loss = 0.004176106432102692
Trained batch 1083 in epoch 19, gen_loss = 0.9023853007057936, disc_loss = 0.004173612385247538
Trained batch 1084 in epoch 19, gen_loss = 0.9024830177632345, disc_loss = 0.0041702163471032385
Trained batch 1085 in epoch 19, gen_loss = 0.9023790046106166, disc_loss = 0.004166594732752259
Trained batch 1086 in epoch 19, gen_loss = 0.9024113956239098, disc_loss = 0.004162966213080896
Trained batch 1087 in epoch 19, gen_loss = 0.9023094923399827, disc_loss = 0.004159301097749502
Trained batch 1088 in epoch 19, gen_loss = 0.9023309905557484, disc_loss = 0.004155556587918473
Trained batch 1089 in epoch 19, gen_loss = 0.9022371025260435, disc_loss = 0.004151894459416801
Trained batch 1090 in epoch 19, gen_loss = 0.9022149821140698, disc_loss = 0.004148205361789398
Trained batch 1091 in epoch 19, gen_loss = 0.9022040981185305, disc_loss = 0.0041444618697687305
Trained batch 1092 in epoch 19, gen_loss = 0.9021930562064719, disc_loss = 0.004140755150216513
Trained batch 1093 in epoch 19, gen_loss = 0.902206843306857, disc_loss = 0.004137166801032688
Trained batch 1094 in epoch 19, gen_loss = 0.9021824346285432, disc_loss = 0.004133580150382384
Trained batch 1095 in epoch 19, gen_loss = 0.9022044102749686, disc_loss = 0.004129867837604331
Trained batch 1096 in epoch 19, gen_loss = 0.9022029865407466, disc_loss = 0.004127455790177999
Trained batch 1097 in epoch 19, gen_loss = 0.9022004068549213, disc_loss = 0.004123793367491093
Trained batch 1098 in epoch 19, gen_loss = 0.9022147201537218, disc_loss = 0.004120229643355144
Trained batch 1099 in epoch 19, gen_loss = 0.9021156546744433, disc_loss = 0.00411662663000739
Trained batch 1100 in epoch 19, gen_loss = 0.9021053494484613, disc_loss = 0.004112998742894937
Trained batch 1101 in epoch 19, gen_loss = 0.9021764286200494, disc_loss = 0.004109337063634044
Trained batch 1102 in epoch 19, gen_loss = 0.9022244771069434, disc_loss = 0.004105677875578787
Trained batch 1103 in epoch 19, gen_loss = 0.9022113357441149, disc_loss = 0.00410209589553022
Trained batch 1104 in epoch 19, gen_loss = 0.9021340133917278, disc_loss = 0.004098639029314045
Trained batch 1105 in epoch 19, gen_loss = 0.9020763395276682, disc_loss = 0.004095625996250177
Trained batch 1106 in epoch 19, gen_loss = 0.9020729160244226, disc_loss = 0.004092127723567049
Trained batch 1107 in epoch 19, gen_loss = 0.9021112883349188, disc_loss = 0.004088497172331975
Trained batch 1108 in epoch 19, gen_loss = 0.9021346436845386, disc_loss = 0.004084922183578664
Trained batch 1109 in epoch 19, gen_loss = 0.9021706737913527, disc_loss = 0.004081314822290117
Trained batch 1110 in epoch 19, gen_loss = 0.9020625681194714, disc_loss = 0.004077749812123656
Trained batch 1111 in epoch 19, gen_loss = 0.902102226404835, disc_loss = 0.00407416577491276
Trained batch 1112 in epoch 19, gen_loss = 0.9019412300336072, disc_loss = 0.004070704750124961
Trained batch 1113 in epoch 19, gen_loss = 0.9019433498596588, disc_loss = 0.004067147138497149
Trained batch 1114 in epoch 19, gen_loss = 0.9019187118975036, disc_loss = 0.004063580238661387
Trained batch 1115 in epoch 19, gen_loss = 0.9018935737430408, disc_loss = 0.004060033741568915
Trained batch 1116 in epoch 19, gen_loss = 0.9018764540673156, disc_loss = 0.004056436536830934
Trained batch 1117 in epoch 19, gen_loss = 0.9019027811363473, disc_loss = 0.004052881054780763
Trained batch 1118 in epoch 19, gen_loss = 0.9018486994947036, disc_loss = 0.004049318289695103
Trained batch 1119 in epoch 19, gen_loss = 0.9017920226923057, disc_loss = 0.004045782048979163
Trained batch 1120 in epoch 19, gen_loss = 0.9017484636311016, disc_loss = 0.004042230728340944
Trained batch 1121 in epoch 19, gen_loss = 0.90170304331125, disc_loss = 0.004038817751370354
Trained batch 1122 in epoch 19, gen_loss = 0.9016819114888871, disc_loss = 0.004035362736391441
Trained batch 1123 in epoch 19, gen_loss = 0.9015986880161584, disc_loss = 0.004031854617145092
Trained batch 1124 in epoch 19, gen_loss = 0.901588779396481, disc_loss = 0.004028418287026903
Trained batch 1125 in epoch 19, gen_loss = 0.901640376019859, disc_loss = 0.004024981936988554
Trained batch 1126 in epoch 19, gen_loss = 0.9015356081189999, disc_loss = 0.004021667837891575
Trained batch 1127 in epoch 19, gen_loss = 0.9014436267052136, disc_loss = 0.0040182775927415275
Trained batch 1128 in epoch 19, gen_loss = 0.9014537083141776, disc_loss = 0.004014879542696179
Trained batch 1129 in epoch 19, gen_loss = 0.9014105118481459, disc_loss = 0.0040113724658410715
Trained batch 1130 in epoch 19, gen_loss = 0.9013233555828334, disc_loss = 0.004008114500034753
Trained batch 1131 in epoch 19, gen_loss = 0.9012750464067021, disc_loss = 0.004004690720507391
Trained batch 1132 in epoch 19, gen_loss = 0.9011990067081334, disc_loss = 0.004001253358066625
Trained batch 1133 in epoch 19, gen_loss = 0.9011141573205407, disc_loss = 0.0039977960805470504
Trained batch 1134 in epoch 19, gen_loss = 0.9010222899231092, disc_loss = 0.00399437852718035
Trained batch 1135 in epoch 19, gen_loss = 0.9010015128993653, disc_loss = 0.003990954709521042
Trained batch 1136 in epoch 19, gen_loss = 0.9010735990294471, disc_loss = 0.003987610446144533
Trained batch 1137 in epoch 19, gen_loss = 0.9010971886202405, disc_loss = 0.0039842476001008984
Trained batch 1138 in epoch 19, gen_loss = 0.9010343322950669, disc_loss = 0.003980814344469031
Trained batch 1139 in epoch 19, gen_loss = 0.9009698997986945, disc_loss = 0.0039773968229941635
Trained batch 1140 in epoch 19, gen_loss = 0.901000780823145, disc_loss = 0.003973961487406153
Trained batch 1141 in epoch 19, gen_loss = 0.9009362571920071, disc_loss = 0.003970613982513794
Trained batch 1142 in epoch 19, gen_loss = 0.9009296850791023, disc_loss = 0.003967227916619281
Trained batch 1143 in epoch 19, gen_loss = 0.9008413462580501, disc_loss = 0.0039639136278857585
Trained batch 1144 in epoch 19, gen_loss = 0.900870821986136, disc_loss = 0.003960687309132068
Trained batch 1145 in epoch 19, gen_loss = 0.900907085776121, disc_loss = 0.003957402981084108
Trained batch 1146 in epoch 19, gen_loss = 0.9008225374566854, disc_loss = 0.003954050013366144
Trained batch 1147 in epoch 19, gen_loss = 0.9008070784474914, disc_loss = 0.003950688870474411
Trained batch 1148 in epoch 19, gen_loss = 0.9006477725619955, disc_loss = 0.003947462127880744
Trained batch 1149 in epoch 19, gen_loss = 0.9006681876078896, disc_loss = 0.003944098796741657
Trained batch 1150 in epoch 19, gen_loss = 0.9006446181018906, disc_loss = 0.003940726389616179
Trained batch 1151 in epoch 19, gen_loss = 0.900548862448583, disc_loss = 0.0039374104923663505
Trained batch 1152 in epoch 19, gen_loss = 0.9005098493845692, disc_loss = 0.003934096528255135
Trained batch 1153 in epoch 19, gen_loss = 0.9003677691496018, disc_loss = 0.003930766528321212
Trained batch 1154 in epoch 19, gen_loss = 0.9004369053489718, disc_loss = 0.003927480408058676
Trained batch 1155 in epoch 19, gen_loss = 0.9005551176293911, disc_loss = 0.003924153405007655
Trained batch 1156 in epoch 19, gen_loss = 0.9004597802974071, disc_loss = 0.003920947584669737
Trained batch 1157 in epoch 19, gen_loss = 0.9004686032140399, disc_loss = 0.003917759336857613
Trained batch 1158 in epoch 19, gen_loss = 0.9004907082955934, disc_loss = 0.00391446343843314
Trained batch 1159 in epoch 19, gen_loss = 0.9004736221042172, disc_loss = 0.003911151161876127
Trained batch 1160 in epoch 19, gen_loss = 0.9004151081854059, disc_loss = 0.003907852882918219
Trained batch 1161 in epoch 19, gen_loss = 0.9003117964210281, disc_loss = 0.0039045794297970435
Trained batch 1162 in epoch 19, gen_loss = 0.9002904238007956, disc_loss = 0.003901346496702427
Trained batch 1163 in epoch 19, gen_loss = 0.9004423899953717, disc_loss = 0.0038983953859236943
Trained batch 1164 in epoch 19, gen_loss = 0.9005050200761132, disc_loss = 0.003895256851417939
Trained batch 1165 in epoch 19, gen_loss = 0.9005358705798717, disc_loss = 0.003892009613604945
Trained batch 1166 in epoch 19, gen_loss = 0.9005853386137765, disc_loss = 0.0038887646685848154
Trained batch 1167 in epoch 19, gen_loss = 0.9006296882074173, disc_loss = 0.003885542226043981
Trained batch 1168 in epoch 19, gen_loss = 0.9006819314585475, disc_loss = 0.00388233405613277
Trained batch 1169 in epoch 19, gen_loss = 0.9006958354232658, disc_loss = 0.0038790999019861026
Trained batch 1170 in epoch 19, gen_loss = 0.9007637534357359, disc_loss = 0.0038760807825130184
Trained batch 1171 in epoch 19, gen_loss = 0.9007147374108383, disc_loss = 0.0038729272081684603
Trained batch 1172 in epoch 19, gen_loss = 0.9006813508978484, disc_loss = 0.0038696889209715924
Trained batch 1173 in epoch 19, gen_loss = 0.9007297082593129, disc_loss = 0.003866474222166574
Trained batch 1174 in epoch 19, gen_loss = 0.9008141871716113, disc_loss = 0.0038632495283734973
Trained batch 1175 in epoch 19, gen_loss = 0.9007423383240797, disc_loss = 0.0038600501720886353
Trained batch 1176 in epoch 19, gen_loss = 0.9006566182981636, disc_loss = 0.00385689617065778
Trained batch 1177 in epoch 19, gen_loss = 0.9006971390016617, disc_loss = 0.003853717181941269
Trained batch 1178 in epoch 19, gen_loss = 0.9006411007544669, disc_loss = 0.003850660016031894
Trained batch 1179 in epoch 19, gen_loss = 0.9005726954189398, disc_loss = 0.0038474757714616085
Trained batch 1180 in epoch 19, gen_loss = 0.9005867688460031, disc_loss = 0.003844476247279743
Trained batch 1181 in epoch 19, gen_loss = 0.9006249909170994, disc_loss = 0.0038413383299207844
Trained batch 1182 in epoch 19, gen_loss = 0.900639443657505, disc_loss = 0.003838152509810503
Trained batch 1183 in epoch 19, gen_loss = 0.9004824235028511, disc_loss = 0.0038361983680181002
Trained batch 1184 in epoch 19, gen_loss = 0.9004127637746465, disc_loss = 0.003833269251063874
Trained batch 1185 in epoch 19, gen_loss = 0.9005217493384524, disc_loss = 0.0038303569920098124
Trained batch 1186 in epoch 19, gen_loss = 0.9005254028018221, disc_loss = 0.0038275623438864302
Trained batch 1187 in epoch 19, gen_loss = 0.9004716528987242, disc_loss = 0.003824477517730391
Trained batch 1188 in epoch 19, gen_loss = 0.9005643131353958, disc_loss = 0.003821576314852756
Trained batch 1189 in epoch 19, gen_loss = 0.9003831548851078, disc_loss = 0.0038185175762460674
Trained batch 1190 in epoch 19, gen_loss = 0.9003121026116795, disc_loss = 0.003815475956749891
Trained batch 1191 in epoch 19, gen_loss = 0.9001910157451694, disc_loss = 0.003812386505596683
Trained batch 1192 in epoch 19, gen_loss = 0.900147582239597, disc_loss = 0.0038092872849478958
Trained batch 1193 in epoch 19, gen_loss = 0.90010770301723, disc_loss = 0.0038067505460309668
Trained batch 1194 in epoch 19, gen_loss = 0.900096843432183, disc_loss = 0.003803848601615511
Trained batch 1195 in epoch 19, gen_loss = 0.9001355450288907, disc_loss = 0.0038008026217129097
Trained batch 1196 in epoch 19, gen_loss = 0.9001778258118116, disc_loss = 0.003797803988117302
Trained batch 1197 in epoch 19, gen_loss = 0.9000641921028271, disc_loss = 0.0037948773583707596
Trained batch 1198 in epoch 19, gen_loss = 0.9000346361347991, disc_loss = 0.0037918018406359515
Trained batch 1199 in epoch 19, gen_loss = 0.9000412860016028, disc_loss = 0.0037887665753775462
Trained batch 1200 in epoch 19, gen_loss = 0.9000239135522231, disc_loss = 0.0037856944751345676
Trained batch 1201 in epoch 19, gen_loss = 0.8999876694849842, disc_loss = 0.0037826005393825305
Trained batch 1202 in epoch 19, gen_loss = 0.8997448196732195, disc_loss = 0.003910965557888487
Trained batch 1203 in epoch 19, gen_loss = 0.8997861340493459, disc_loss = 0.004400412508702087
Trained batch 1204 in epoch 19, gen_loss = 0.8997917275705772, disc_loss = 0.004762991882543175
Trained batch 1205 in epoch 19, gen_loss = 0.8997824034880643, disc_loss = 0.00496516556198653
Trained batch 1206 in epoch 19, gen_loss = 0.8997128001894947, disc_loss = 0.005155215137031842
Trained batch 1207 in epoch 19, gen_loss = 0.8994399729548701, disc_loss = 0.005449117663961893
Trained batch 1208 in epoch 19, gen_loss = 0.8992683497512508, disc_loss = 0.005715289747039898
Trained batch 1209 in epoch 19, gen_loss = 0.899056361874273, disc_loss = 0.005889550962808041
Trained batch 1210 in epoch 19, gen_loss = 0.8987572216771045, disc_loss = 0.0060411158035111835
Trained batch 1211 in epoch 19, gen_loss = 0.898543570350499, disc_loss = 0.006256215953576415
Trained batch 1212 in epoch 19, gen_loss = 0.898341315350843, disc_loss = 0.006412316543630723
Trained batch 1213 in epoch 19, gen_loss = 0.8981701449369873, disc_loss = 0.00670877984326727
Trained batch 1214 in epoch 19, gen_loss = 0.8981268032588096, disc_loss = 0.006885307625571717
Trained batch 1215 in epoch 19, gen_loss = 0.8979848009093028, disc_loss = 0.007019716563081003
Trained batch 1216 in epoch 19, gen_loss = 0.897738902365074, disc_loss = 0.007159543559589762
Trained batch 1217 in epoch 19, gen_loss = 0.8976261531093046, disc_loss = 0.007259809303445502
Trained batch 1218 in epoch 19, gen_loss = 0.8974822840307265, disc_loss = 0.007388160356921116
Trained batch 1219 in epoch 19, gen_loss = 0.8971776159571819, disc_loss = 0.007512326566005659
Trained batch 1220 in epoch 19, gen_loss = 0.8968238713895562, disc_loss = 0.007681788847629334
Trained batch 1221 in epoch 19, gen_loss = 0.8966995271840384, disc_loss = 0.0077756025085719705
Trained batch 1222 in epoch 19, gen_loss = 0.8963901857226381, disc_loss = 0.00789348878882437
Trained batch 1223 in epoch 19, gen_loss = 0.896121039304858, disc_loss = 0.008017626210545916
Trained batch 1224 in epoch 19, gen_loss = 0.8958271079160729, disc_loss = 0.008116694776948936
Trained batch 1225 in epoch 19, gen_loss = 0.8955547795988024, disc_loss = 0.008184613678170775
Trained batch 1226 in epoch 19, gen_loss = 0.8953215379295256, disc_loss = 0.008345880503890884
Trained batch 1227 in epoch 19, gen_loss = 0.8950040592821102, disc_loss = 0.008438666460311498
Trained batch 1228 in epoch 19, gen_loss = 0.8948470714908969, disc_loss = 0.008492446384006373
Trained batch 1229 in epoch 19, gen_loss = 0.8946146446514905, disc_loss = 0.008551788423929105
Trained batch 1230 in epoch 19, gen_loss = 0.8945398553419075, disc_loss = 0.008622398807240663
Trained batch 1231 in epoch 19, gen_loss = 0.894407185641202, disc_loss = 0.008663249368341836
Trained batch 1232 in epoch 19, gen_loss = 0.8941966402559675, disc_loss = 0.008693883632062152
Trained batch 1233 in epoch 19, gen_loss = 0.8940539201615888, disc_loss = 0.008724889025126253
Trained batch 1234 in epoch 19, gen_loss = 0.8938686325482511, disc_loss = 0.008791712813252212
Trained batch 1235 in epoch 19, gen_loss = 0.8937240860222998, disc_loss = 0.008836509515176628
Trained batch 1236 in epoch 19, gen_loss = 0.8935288917950882, disc_loss = 0.00888318429932861
Trained batch 1237 in epoch 19, gen_loss = 0.8933574670447286, disc_loss = 0.008963095418384586
Trained batch 1238 in epoch 19, gen_loss = 0.8930501874845965, disc_loss = 0.00902162194609
Trained batch 1239 in epoch 19, gen_loss = 0.8927242267756693, disc_loss = 0.009125468333123506
Trained batch 1240 in epoch 19, gen_loss = 0.8925548478012407, disc_loss = 0.009160494739504352
Trained batch 1241 in epoch 19, gen_loss = 0.8922806647808655, disc_loss = 0.009246992310186062
Trained batch 1242 in epoch 19, gen_loss = 0.8920476908225353, disc_loss = 0.009299726139233489
Trained batch 1243 in epoch 19, gen_loss = 0.8918265074826897, disc_loss = 0.009393441505764006
Trained batch 1244 in epoch 19, gen_loss = 0.891452455760006, disc_loss = 0.009539914687675958
Trained batch 1245 in epoch 19, gen_loss = 0.8912704189458972, disc_loss = 0.009682043986192606
Trained batch 1246 in epoch 19, gen_loss = 0.8911064959279804, disc_loss = 0.009750813998560695
Trained batch 1247 in epoch 19, gen_loss = 0.8909167006898385, disc_loss = 0.009829132292286257
Trained batch 1248 in epoch 19, gen_loss = 0.8907302142239457, disc_loss = 0.009878309907352311
Trained batch 1249 in epoch 19, gen_loss = 0.8906085896015167, disc_loss = 0.00991184253092797
Trained batch 1250 in epoch 19, gen_loss = 0.8903873884420601, disc_loss = 0.009943592944982172
Trained batch 1251 in epoch 19, gen_loss = 0.8901418623642419, disc_loss = 0.009980465243785647
Trained batch 1252 in epoch 19, gen_loss = 0.889976528960043, disc_loss = 0.010015703205513676
Trained batch 1253 in epoch 19, gen_loss = 0.889763963469668, disc_loss = 0.010070051275975897
Trained batch 1254 in epoch 19, gen_loss = 0.8896312635733312, disc_loss = 0.01015483739065965
Trained batch 1255 in epoch 19, gen_loss = 0.8894189243578607, disc_loss = 0.010227174773940735
Trained batch 1256 in epoch 19, gen_loss = 0.8891781482226145, disc_loss = 0.010369418199264659
Trained batch 1257 in epoch 19, gen_loss = 0.8889409572786292, disc_loss = 0.01046783413988923
Trained batch 1258 in epoch 19, gen_loss = 0.8888003445978293, disc_loss = 0.010540785639256998
Trained batch 1259 in epoch 19, gen_loss = 0.8886867688288764, disc_loss = 0.010678641518747358
Trained batch 1260 in epoch 19, gen_loss = 0.8885138412017278, disc_loss = 0.010761196539654728
Trained batch 1261 in epoch 19, gen_loss = 0.8883126586817335, disc_loss = 0.010827595385701575
Trained batch 1262 in epoch 19, gen_loss = 0.8881178854102666, disc_loss = 0.010960720051765184
Trained batch 1263 in epoch 19, gen_loss = 0.8878991870751863, disc_loss = 0.011112234086538915
Trained batch 1264 in epoch 19, gen_loss = 0.8877494771018801, disc_loss = 0.011209381136107659
Trained batch 1265 in epoch 19, gen_loss = 0.8875387279437428, disc_loss = 0.011312528847315985
Trained batch 1266 in epoch 19, gen_loss = 0.8873589588792284, disc_loss = 0.011462922268983905
Trained batch 1267 in epoch 19, gen_loss = 0.8871320342697931, disc_loss = 0.011551769300435364
Trained batch 1268 in epoch 19, gen_loss = 0.8869677193527432, disc_loss = 0.011650350391005537
Trained batch 1269 in epoch 19, gen_loss = 0.8867527575004758, disc_loss = 0.011732066988790436
Trained batch 1270 in epoch 19, gen_loss = 0.8865394844584912, disc_loss = 0.011871177878964452
Trained batch 1271 in epoch 19, gen_loss = 0.8863343762807876, disc_loss = 0.01198962617532949
Trained batch 1272 in epoch 19, gen_loss = 0.8861864682547426, disc_loss = 0.01215528982679704
Trained batch 1273 in epoch 19, gen_loss = 0.8860750075786417, disc_loss = 0.012302163020441004
Trained batch 1274 in epoch 19, gen_loss = 0.8859969913258272, disc_loss = 0.012369345528785226
Trained batch 1275 in epoch 19, gen_loss = 0.885869707153135, disc_loss = 0.012449580320590087
Trained batch 1276 in epoch 19, gen_loss = 0.8858854075195085, disc_loss = 0.0125546922809136
Trained batch 1277 in epoch 19, gen_loss = 0.8856845050350601, disc_loss = 0.012656268096712019
Trained batch 1278 in epoch 19, gen_loss = 0.8856900572497179, disc_loss = 0.012715632309976388
Trained batch 1279 in epoch 19, gen_loss = 0.8856063520535826, disc_loss = 0.012743531609848447
Trained batch 1280 in epoch 19, gen_loss = 0.8854845003352139, disc_loss = 0.01277061583794841
Trained batch 1281 in epoch 19, gen_loss = 0.885333875691091, disc_loss = 0.01280761078321834
Trained batch 1282 in epoch 19, gen_loss = 0.8852993490541715, disc_loss = 0.012855292731221846
Trained batch 1283 in epoch 19, gen_loss = 0.8851918561436306, disc_loss = 0.012871983719262311
Trained batch 1284 in epoch 19, gen_loss = 0.8851092136323684, disc_loss = 0.012879143843702145
Trained batch 1285 in epoch 19, gen_loss = 0.8851468622406385, disc_loss = 0.012878120986890484
Trained batch 1286 in epoch 19, gen_loss = 0.8852075727391632, disc_loss = 0.012875879759390989
Trained batch 1287 in epoch 19, gen_loss = 0.8853488047115551, disc_loss = 0.012876064356044237
Trained batch 1288 in epoch 19, gen_loss = 0.8854167358740251, disc_loss = 0.012876422588782986
Trained batch 1289 in epoch 19, gen_loss = 0.885460644821788, disc_loss = 0.012873989015838737
Trained batch 1290 in epoch 19, gen_loss = 0.8855991578674612, disc_loss = 0.012868734481285818
Trained batch 1291 in epoch 19, gen_loss = 0.8856008746675662, disc_loss = 0.012862749393753455
Trained batch 1292 in epoch 19, gen_loss = 0.8857228241497845, disc_loss = 0.012857620796254415
Trained batch 1293 in epoch 19, gen_loss = 0.8858033423261628, disc_loss = 0.012852737702712303
Trained batch 1294 in epoch 19, gen_loss = 0.8858222798951344, disc_loss = 0.012852825623141708
Trained batch 1295 in epoch 19, gen_loss = 0.8859640091749621, disc_loss = 0.012854004786442691
Trained batch 1296 in epoch 19, gen_loss = 0.8859646875488822, disc_loss = 0.01285012867965851
Trained batch 1297 in epoch 19, gen_loss = 0.8860252083082596, disc_loss = 0.0128506396122584
Trained batch 1298 in epoch 19, gen_loss = 0.8861344912769796, disc_loss = 0.012849616918825572
Trained batch 1299 in epoch 19, gen_loss = 0.8862244543203941, disc_loss = 0.012845692812572031
Trained batch 1300 in epoch 19, gen_loss = 0.8862770769707887, disc_loss = 0.012848023819463837
Trained batch 1301 in epoch 19, gen_loss = 0.8863897624378381, disc_loss = 0.012846291309455209
Trained batch 1302 in epoch 19, gen_loss = 0.8863993877186194, disc_loss = 0.012842462988103756
Trained batch 1303 in epoch 19, gen_loss = 0.886418213827844, disc_loss = 0.012842639669685416
Trained batch 1304 in epoch 19, gen_loss = 0.8864185728332549, disc_loss = 0.012837289002869734
Trained batch 1305 in epoch 19, gen_loss = 0.8863818753185535, disc_loss = 0.012832281001412236
Trained batch 1306 in epoch 19, gen_loss = 0.8864891711499915, disc_loss = 0.0128262322295919
Trained batch 1307 in epoch 19, gen_loss = 0.8865869224800611, disc_loss = 0.012821457126577446
Trained batch 1308 in epoch 19, gen_loss = 0.8865758341810374, disc_loss = 0.012818797111526328
Trained batch 1309 in epoch 19, gen_loss = 0.8865879045187972, disc_loss = 0.012821220361257398
Trained batch 1310 in epoch 19, gen_loss = 0.8865604898931414, disc_loss = 0.012815365840557445
Trained batch 1311 in epoch 19, gen_loss = 0.8866807772982411, disc_loss = 0.012811461563268406
Trained batch 1312 in epoch 19, gen_loss = 0.8868832332163663, disc_loss = 0.012812472020522886
Trained batch 1313 in epoch 19, gen_loss = 0.8869275788193969, disc_loss = 0.012805732732171792
Trained batch 1314 in epoch 19, gen_loss = 0.8869516335512748, disc_loss = 0.012804034162106806
Trained batch 1315 in epoch 19, gen_loss = 0.8870377894774034, disc_loss = 0.012809115774415186
Trained batch 1316 in epoch 19, gen_loss = 0.8871314343667519, disc_loss = 0.01280202309794714
Trained batch 1317 in epoch 19, gen_loss = 0.88722461489155, disc_loss = 0.01279713120767212
Trained batch 1318 in epoch 19, gen_loss = 0.8871486045086899, disc_loss = 0.012793321736824343
Trained batch 1319 in epoch 19, gen_loss = 0.887177786366506, disc_loss = 0.012786542272483943
Trained batch 1320 in epoch 19, gen_loss = 0.887203974537918, disc_loss = 0.012778673268801896
Trained batch 1321 in epoch 19, gen_loss = 0.8872883928525466, disc_loss = 0.012770426209132045
Trained batch 1322 in epoch 19, gen_loss = 0.8873045792294918, disc_loss = 0.012762306083467656
Trained batch 1323 in epoch 19, gen_loss = 0.8873211831484676, disc_loss = 0.01275390618054417
Trained batch 1324 in epoch 19, gen_loss = 0.8874973644400542, disc_loss = 0.01274696302350626
Trained batch 1325 in epoch 19, gen_loss = 0.8875339166970634, disc_loss = 0.012739179068178423
Trained batch 1326 in epoch 19, gen_loss = 0.8875820312449693, disc_loss = 0.012731162712543083
Trained batch 1327 in epoch 19, gen_loss = 0.8877007210829172, disc_loss = 0.01272387669280717
Trained batch 1328 in epoch 19, gen_loss = 0.8877966021845626, disc_loss = 0.012715885901270886
Trained batch 1329 in epoch 19, gen_loss = 0.8878574795292732, disc_loss = 0.012707866890726525
Trained batch 1330 in epoch 19, gen_loss = 0.8878537940853615, disc_loss = 0.012700649624680071
Trained batch 1331 in epoch 19, gen_loss = 0.8878099434637092, disc_loss = 0.012714726048907105
Trained batch 1332 in epoch 19, gen_loss = 0.8877779063387912, disc_loss = 0.012713106390820454
Trained batch 1333 in epoch 19, gen_loss = 0.887819917618424, disc_loss = 0.01270963962558418
Trained batch 1334 in epoch 19, gen_loss = 0.8879327161035288, disc_loss = 0.012703130232162702
Trained batch 1335 in epoch 19, gen_loss = 0.8879643324874118, disc_loss = 0.012695736655704188
Trained batch 1336 in epoch 19, gen_loss = 0.8879256048305942, disc_loss = 0.012689582186749827
Trained batch 1337 in epoch 19, gen_loss = 0.887955003388794, disc_loss = 0.012683177454172408
Trained batch 1338 in epoch 19, gen_loss = 0.8879481700928555, disc_loss = 0.012675401720386833
Trained batch 1339 in epoch 19, gen_loss = 0.8880466016370858, disc_loss = 0.012667723383837351
Trained batch 1340 in epoch 19, gen_loss = 0.8880986225062747, disc_loss = 0.012664488230752901
Trained batch 1341 in epoch 19, gen_loss = 0.8881911023363094, disc_loss = 0.012662912242324973
Trained batch 1342 in epoch 19, gen_loss = 0.8882631750046452, disc_loss = 0.012658342106540493
Trained batch 1343 in epoch 19, gen_loss = 0.8883038340579896, disc_loss = 0.012656077185930653
Trained batch 1344 in epoch 19, gen_loss = 0.8883818214267603, disc_loss = 0.01265424194908387
Trained batch 1345 in epoch 19, gen_loss = 0.8883903751933026, disc_loss = 0.01265086522055971
Trained batch 1346 in epoch 19, gen_loss = 0.8885421148475755, disc_loss = 0.012648673527392986
Trained batch 1347 in epoch 19, gen_loss = 0.8886138542115866, disc_loss = 0.012641978405694592
Trained batch 1348 in epoch 19, gen_loss = 0.8887126338844215, disc_loss = 0.012638637171733207
Trained batch 1349 in epoch 19, gen_loss = 0.8888337226267214, disc_loss = 0.01263337731720067
Trained batch 1350 in epoch 19, gen_loss = 0.8889173649576838, disc_loss = 0.012627765012533588
Trained batch 1351 in epoch 19, gen_loss = 0.8889481602512168, disc_loss = 0.012622333251038502
Trained batch 1352 in epoch 19, gen_loss = 0.8890382099926957, disc_loss = 0.012615853668956123
Trained batch 1353 in epoch 19, gen_loss = 0.8891873890575314, disc_loss = 0.012609194936622305
Trained batch 1354 in epoch 19, gen_loss = 0.8892445022329634, disc_loss = 0.01260351932834354
Trained batch 1355 in epoch 19, gen_loss = 0.8893315661973307, disc_loss = 0.01259806241072897
Trained batch 1356 in epoch 19, gen_loss = 0.8894021931868225, disc_loss = 0.012590281496286493
Trained batch 1357 in epoch 19, gen_loss = 0.8893855403730199, disc_loss = 0.012584364852100755
Trained batch 1358 in epoch 19, gen_loss = 0.8895467291692323, disc_loss = 0.012577356337661634
Trained batch 1359 in epoch 19, gen_loss = 0.8895215460482766, disc_loss = 0.012571018762160106
Trained batch 1360 in epoch 19, gen_loss = 0.8895750368105674, disc_loss = 0.012563597591877992
Trained batch 1361 in epoch 19, gen_loss = 0.8896205747355098, disc_loss = 0.012556768580244952
Trained batch 1362 in epoch 19, gen_loss = 0.8896694788579458, disc_loss = 0.012549044158970587
Trained batch 1363 in epoch 19, gen_loss = 0.8897307726207716, disc_loss = 0.01254139268849964
Trained batch 1364 in epoch 19, gen_loss = 0.8898736069490621, disc_loss = 0.012533873401295147
Trained batch 1365 in epoch 19, gen_loss = 0.8899977721633883, disc_loss = 0.012527238411895158
Trained batch 1366 in epoch 19, gen_loss = 0.8900690487290963, disc_loss = 0.012519674891014082
Trained batch 1367 in epoch 19, gen_loss = 0.8901070942829924, disc_loss = 0.012511395629867923
Trained batch 1368 in epoch 19, gen_loss = 0.8901764252831937, disc_loss = 0.01250642673394721
Trained batch 1369 in epoch 19, gen_loss = 0.8902327687635909, disc_loss = 0.012502781134642075
Trained batch 1370 in epoch 19, gen_loss = 0.8902312287181768, disc_loss = 0.01250666533600157
Trained batch 1371 in epoch 19, gen_loss = 0.8904121089346555, disc_loss = 0.012511304442691508
Trained batch 1372 in epoch 19, gen_loss = 0.8905220178036645, disc_loss = 0.012511158136966483
Trained batch 1373 in epoch 19, gen_loss = 0.8907048717423124, disc_loss = 0.012516681769295586
Trained batch 1374 in epoch 19, gen_loss = 0.890706645488739, disc_loss = 0.012518552898818267
Trained batch 1375 in epoch 19, gen_loss = 0.8907877054758543, disc_loss = 0.012512912379975205
Trained batch 1376 in epoch 19, gen_loss = 0.8909909547284278, disc_loss = 0.012506434466309193
Trained batch 1377 in epoch 19, gen_loss = 0.8911144072068274, disc_loss = 0.012506290619715206
Trained batch 1378 in epoch 19, gen_loss = 0.891353127012398, disc_loss = 0.012508618178323702
Trained batch 1379 in epoch 19, gen_loss = 0.8916481548029443, disc_loss = 0.012509156782753184
Trained batch 1380 in epoch 19, gen_loss = 0.8917590216136686, disc_loss = 0.012503824824571979
Trained batch 1381 in epoch 19, gen_loss = 0.8917550128465451, disc_loss = 0.012498233580857518
Trained batch 1382 in epoch 19, gen_loss = 0.8917872202801514, disc_loss = 0.012492984498931957
Trained batch 1383 in epoch 19, gen_loss = 0.8919370162779885, disc_loss = 0.012485523151961367
Trained batch 1384 in epoch 19, gen_loss = 0.8920472179078883, disc_loss = 0.012477599495705297
Trained batch 1385 in epoch 19, gen_loss = 0.8921421085515235, disc_loss = 0.012472288586093935
Trained batch 1386 in epoch 19, gen_loss = 0.8921977783074547, disc_loss = 0.01251557573827808
Trained batch 1387 in epoch 19, gen_loss = 0.891851912614935, disc_loss = 0.012740104909924003
Trained batch 1388 in epoch 19, gen_loss = 0.8920400329336492, disc_loss = 0.013006530634862571
Trained batch 1389 in epoch 19, gen_loss = 0.8920686037849179, disc_loss = 0.013026726119715545
Trained batch 1390 in epoch 19, gen_loss = 0.8919262194016441, disc_loss = 0.013052957230009349
Trained batch 1391 in epoch 19, gen_loss = 0.8918288797568316, disc_loss = 0.013072315892324549
Trained batch 1392 in epoch 19, gen_loss = 0.891846935824362, disc_loss = 0.013074468731497242
Trained batch 1393 in epoch 19, gen_loss = 0.8918420610417594, disc_loss = 0.013079065297511946
Trained batch 1394 in epoch 19, gen_loss = 0.8919334087320553, disc_loss = 0.013073745270903405
Trained batch 1395 in epoch 19, gen_loss = 0.8920676638625754, disc_loss = 0.013066086952606052
Trained batch 1396 in epoch 19, gen_loss = 0.8921717701849121, disc_loss = 0.013059076320902111
Trained batch 1397 in epoch 19, gen_loss = 0.8922951535690837, disc_loss = 0.013051743139459022
Trained batch 1398 in epoch 19, gen_loss = 0.8923685867246174, disc_loss = 0.01304366639771948
Trained batch 1399 in epoch 19, gen_loss = 0.8924602966223444, disc_loss = 0.013035436947047856
Trained batch 1400 in epoch 19, gen_loss = 0.892491655337819, disc_loss = 0.013026916947239207
Trained batch 1401 in epoch 19, gen_loss = 0.892556742620196, disc_loss = 0.013018509900640608
Trained batch 1402 in epoch 19, gen_loss = 0.8925778087937484, disc_loss = 0.01300983525466896
Trained batch 1403 in epoch 19, gen_loss = 0.8926836950571788, disc_loss = 0.0130011231077719
Trained batch 1404 in epoch 19, gen_loss = 0.8927777092227732, disc_loss = 0.012992692751953609
Trained batch 1405 in epoch 19, gen_loss = 0.8928889328266784, disc_loss = 0.012984144118492098
Trained batch 1406 in epoch 19, gen_loss = 0.8929908123521324, disc_loss = 0.012975453348368466
Trained batch 1407 in epoch 19, gen_loss = 0.8930066890421916, disc_loss = 0.012967133553716663
Trained batch 1408 in epoch 19, gen_loss = 0.8930648149032809, disc_loss = 0.012958541012588686
Trained batch 1409 in epoch 19, gen_loss = 0.8931587084810785, disc_loss = 0.012950302419674906
Trained batch 1410 in epoch 19, gen_loss = 0.8932163797736083, disc_loss = 0.012942720807508745
Trained batch 1411 in epoch 19, gen_loss = 0.8932521693176319, disc_loss = 0.012934499387707963
Trained batch 1412 in epoch 19, gen_loss = 0.8933252487212989, disc_loss = 0.012926216948146154
Trained batch 1413 in epoch 19, gen_loss = 0.893470842270062, disc_loss = 0.01291863768250476
Trained batch 1414 in epoch 19, gen_loss = 0.8935687011627763, disc_loss = 0.012910828410693367
Trained batch 1415 in epoch 19, gen_loss = 0.8936864366218195, disc_loss = 0.012902807477926242
Trained batch 1416 in epoch 19, gen_loss = 0.8936857907134375, disc_loss = 0.012894308552644625
Trained batch 1417 in epoch 19, gen_loss = 0.8936560538154731, disc_loss = 0.012886108468525578
Trained batch 1418 in epoch 19, gen_loss = 0.8937069001207896, disc_loss = 0.01287751307229705
Trained batch 1419 in epoch 19, gen_loss = 0.8937065780162812, disc_loss = 0.012869029940838387
Trained batch 1420 in epoch 19, gen_loss = 0.8937968404925599, disc_loss = 0.012860624220414738
Trained batch 1421 in epoch 19, gen_loss = 0.8938482669503042, disc_loss = 0.012852697848034354
Trained batch 1422 in epoch 19, gen_loss = 0.8939320228506961, disc_loss = 0.012844634381112887
Trained batch 1423 in epoch 19, gen_loss = 0.8940522838174627, disc_loss = 0.012836685607588948
Trained batch 1424 in epoch 19, gen_loss = 0.8940078399474161, disc_loss = 0.012829024753328555
Trained batch 1425 in epoch 19, gen_loss = 0.894046703068772, disc_loss = 0.012820515940107384
Trained batch 1426 in epoch 19, gen_loss = 0.8940571914541195, disc_loss = 0.012812208347898198
Trained batch 1427 in epoch 19, gen_loss = 0.8941448024925398, disc_loss = 0.012803644222694041
Trained batch 1428 in epoch 19, gen_loss = 0.8940777233466141, disc_loss = 0.012798282754199006
Trained batch 1429 in epoch 19, gen_loss = 0.8940828619720219, disc_loss = 0.012790113117616974
Trained batch 1430 in epoch 19, gen_loss = 0.8940773448854122, disc_loss = 0.01278225196376366
Trained batch 1431 in epoch 19, gen_loss = 0.8941058860727529, disc_loss = 0.012774104866369082
Trained batch 1432 in epoch 19, gen_loss = 0.8941774395322434, disc_loss = 0.01276567644497754
Trained batch 1433 in epoch 19, gen_loss = 0.8941648620358738, disc_loss = 0.01275798794371772
Trained batch 1434 in epoch 19, gen_loss = 0.8941440816124973, disc_loss = 0.012749532300853458
Trained batch 1435 in epoch 19, gen_loss = 0.8941490124278082, disc_loss = 0.012741370773706713
Trained batch 1436 in epoch 19, gen_loss = 0.8942179677796679, disc_loss = 0.012732903420590537
Trained batch 1437 in epoch 19, gen_loss = 0.8942862443615565, disc_loss = 0.012724504519927992
Trained batch 1438 in epoch 19, gen_loss = 0.8942979402721053, disc_loss = 0.012716140252743978
Trained batch 1439 in epoch 19, gen_loss = 0.8942769715355502, disc_loss = 0.012707780945136922
Trained batch 1440 in epoch 19, gen_loss = 0.8943462005760172, disc_loss = 0.012699355835389904
Trained batch 1441 in epoch 19, gen_loss = 0.8943074385683348, disc_loss = 0.012691329970235862
Trained batch 1442 in epoch 19, gen_loss = 0.894307092214242, disc_loss = 0.012683063698431835
Trained batch 1443 in epoch 19, gen_loss = 0.8942953177683901, disc_loss = 0.012675215002136586
Trained batch 1444 in epoch 19, gen_loss = 0.8944076014637534, disc_loss = 0.012666891261001796
Trained batch 1445 in epoch 19, gen_loss = 0.8944735681202731, disc_loss = 0.012658493588230409
Trained batch 1446 in epoch 19, gen_loss = 0.8945992550688442, disc_loss = 0.012650178706175746
Trained batch 1447 in epoch 19, gen_loss = 0.8946158470616815, disc_loss = 0.012641808624492677
Trained batch 1448 in epoch 19, gen_loss = 0.8946118045050658, disc_loss = 0.012633812784479032
Trained batch 1449 in epoch 19, gen_loss = 0.8946563338000199, disc_loss = 0.012625714527683409
Trained batch 1450 in epoch 19, gen_loss = 0.8946535493241434, disc_loss = 0.012618129130203333
Trained batch 1451 in epoch 19, gen_loss = 0.8947408306450884, disc_loss = 0.012610074824565833
Trained batch 1452 in epoch 19, gen_loss = 0.8947367273112125, disc_loss = 0.012602334024341813
Trained batch 1453 in epoch 19, gen_loss = 0.894773398870615, disc_loss = 0.012594758318253053
Trained batch 1454 in epoch 19, gen_loss = 0.8949075033984233, disc_loss = 0.012586638353343655
Trained batch 1455 in epoch 19, gen_loss = 0.8949649472731155, disc_loss = 0.012578300401938268
Trained batch 1456 in epoch 19, gen_loss = 0.8949058873651775, disc_loss = 0.012570835340079814
Trained batch 1457 in epoch 19, gen_loss = 0.8949796000217051, disc_loss = 0.01256285239678032
Trained batch 1458 in epoch 19, gen_loss = 0.8950434035843083, disc_loss = 0.012554891633904712
Trained batch 1459 in epoch 19, gen_loss = 0.8950489210755858, disc_loss = 0.012546681290083666
Trained batch 1460 in epoch 19, gen_loss = 0.8950702120880816, disc_loss = 0.01253919170576198
Trained batch 1461 in epoch 19, gen_loss = 0.8950290757393218, disc_loss = 0.01253129988763796
Trained batch 1462 in epoch 19, gen_loss = 0.8950070579493608, disc_loss = 0.01252336874941565
Trained batch 1463 in epoch 19, gen_loss = 0.8949981531728812, disc_loss = 0.012515225455315816
Trained batch 1464 in epoch 19, gen_loss = 0.8951120269583354, disc_loss = 0.012507451072687569
Trained batch 1465 in epoch 19, gen_loss = 0.8951922226976731, disc_loss = 0.012499332349846345
Trained batch 1466 in epoch 19, gen_loss = 0.8952137557275456, disc_loss = 0.012491469015089088
Trained batch 1467 in epoch 19, gen_loss = 0.895323073628488, disc_loss = 0.012483844583133839
Trained batch 1468 in epoch 19, gen_loss = 0.8953588105854816, disc_loss = 0.012476247575010233
Trained batch 1469 in epoch 19, gen_loss = 0.89543036761738, disc_loss = 0.012469034626862477
Trained batch 1470 in epoch 19, gen_loss = 0.8954459219704997, disc_loss = 0.012461059710558359
Trained batch 1471 in epoch 19, gen_loss = 0.8955264096350773, disc_loss = 0.012453117655050628
Trained batch 1472 in epoch 19, gen_loss = 0.8955813652386247, disc_loss = 0.01244511258676447
Trained batch 1473 in epoch 19, gen_loss = 0.8955981392954228, disc_loss = 0.012437498244393901
Trained batch 1474 in epoch 19, gen_loss = 0.8956771636817414, disc_loss = 0.01242956457182842
Trained batch 1475 in epoch 19, gen_loss = 0.8956455601263176, disc_loss = 0.012422290835437581
Trained batch 1476 in epoch 19, gen_loss = 0.8957127869815219, disc_loss = 0.012414616280923418
Trained batch 1477 in epoch 19, gen_loss = 0.8958009114042832, disc_loss = 0.012406843576623272
Trained batch 1478 in epoch 19, gen_loss = 0.8959103825529174, disc_loss = 0.01239887217120763
Trained batch 1479 in epoch 19, gen_loss = 0.8958961222220112, disc_loss = 0.012391854097525022
Trained batch 1480 in epoch 19, gen_loss = 0.8958968810339701, disc_loss = 0.012384613340086165
Trained batch 1481 in epoch 19, gen_loss = 0.8959410732332994, disc_loss = 0.012377172483268422
Trained batch 1482 in epoch 19, gen_loss = 0.8960099834810619, disc_loss = 0.012369321899385086
Trained batch 1483 in epoch 19, gen_loss = 0.8961007299850572, disc_loss = 0.012361799797728027
Trained batch 1484 in epoch 19, gen_loss = 0.8962021637043166, disc_loss = 0.012354037613475751
Trained batch 1485 in epoch 19, gen_loss = 0.8962331818138446, disc_loss = 0.012346974502001873
Trained batch 1486 in epoch 19, gen_loss = 0.8962695587779663, disc_loss = 0.012339106810052604
Trained batch 1487 in epoch 19, gen_loss = 0.8963147403011399, disc_loss = 0.01233210240945081
Trained batch 1488 in epoch 19, gen_loss = 0.8964658061716683, disc_loss = 0.012324348058897571
Trained batch 1489 in epoch 19, gen_loss = 0.8965381228283748, disc_loss = 0.012316974293371337
Trained batch 1490 in epoch 19, gen_loss = 0.8966005093135104, disc_loss = 0.012311789621570422
Trained batch 1491 in epoch 19, gen_loss = 0.8966280063739092, disc_loss = 0.01230878893865833
Trained batch 1492 in epoch 19, gen_loss = 0.8968213632133929, disc_loss = 0.012307592747764946
Trained batch 1493 in epoch 19, gen_loss = 0.8968401015044216, disc_loss = 0.01230202207851039
Trained batch 1494 in epoch 19, gen_loss = 0.8969340154558519, disc_loss = 0.012295032342097991
Trained batch 1495 in epoch 19, gen_loss = 0.8970387612275261, disc_loss = 0.012288219110515568
Trained batch 1496 in epoch 19, gen_loss = 0.8971440224306696, disc_loss = 0.012281527142360341
Trained batch 1497 in epoch 19, gen_loss = 0.8971226040288826, disc_loss = 0.012275391621035952
Trained batch 1498 in epoch 19, gen_loss = 0.897126088148757, disc_loss = 0.012268519384836947
Trained batch 1499 in epoch 19, gen_loss = 0.8970723941723505, disc_loss = 0.012267597967572026
Trained batch 1500 in epoch 19, gen_loss = 0.8970311197100441, disc_loss = 0.012263029575940583
Trained batch 1501 in epoch 19, gen_loss = 0.8970270934657314, disc_loss = 0.012256842503849473
Trained batch 1502 in epoch 19, gen_loss = 0.8971526911476019, disc_loss = 0.012249334195240382
Trained batch 1503 in epoch 19, gen_loss = 0.8971316748635566, disc_loss = 0.012242124289424824
Trained batch 1504 in epoch 19, gen_loss = 0.8971385405309177, disc_loss = 0.012234432221222743
Trained batch 1505 in epoch 19, gen_loss = 0.8971105471233606, disc_loss = 0.01222695575247484
Trained batch 1506 in epoch 19, gen_loss = 0.8971942789758683, disc_loss = 0.012219168420654363
Trained batch 1507 in epoch 19, gen_loss = 0.8972275099798602, disc_loss = 0.012211542533443318
Trained batch 1508 in epoch 19, gen_loss = 0.8972791089294287, disc_loss = 0.01220370420599413
Trained batch 1509 in epoch 19, gen_loss = 0.8973258658355435, disc_loss = 0.012196211640642388
Trained batch 1510 in epoch 19, gen_loss = 0.8974084710932819, disc_loss = 0.012188534693128467
Trained batch 1511 in epoch 19, gen_loss = 0.8974926864738186, disc_loss = 0.012180873165790512
Trained batch 1512 in epoch 19, gen_loss = 0.8975714082286126, disc_loss = 0.012173126373484635
Trained batch 1513 in epoch 19, gen_loss = 0.8976095648312663, disc_loss = 0.012165434562284333
Trained batch 1514 in epoch 19, gen_loss = 0.8975859589702618, disc_loss = 0.012157836848920923
Trained batch 1515 in epoch 19, gen_loss = 0.8976345952000656, disc_loss = 0.012150302568524885
Trained batch 1516 in epoch 19, gen_loss = 0.8975641774203955, disc_loss = 0.012142934956572484
Trained batch 1517 in epoch 19, gen_loss = 0.8975669875917699, disc_loss = 0.012135408404469103
Trained batch 1518 in epoch 19, gen_loss = 0.8976148763246015, disc_loss = 0.012127838774073797
Trained batch 1519 in epoch 19, gen_loss = 0.8976819989320479, disc_loss = 0.012120159747148232
Trained batch 1520 in epoch 19, gen_loss = 0.8977228349404144, disc_loss = 0.01211261678609706
Trained batch 1521 in epoch 19, gen_loss = 0.8978369896656268, disc_loss = 0.01210497616644171
Trained batch 1522 in epoch 19, gen_loss = 0.8978804735392234, disc_loss = 0.012097333563739343
Trained batch 1523 in epoch 19, gen_loss = 0.8979479485531179, disc_loss = 0.012089686943021318
Trained batch 1524 in epoch 19, gen_loss = 0.8980128584924292, disc_loss = 0.012082135662745177
Trained batch 1525 in epoch 19, gen_loss = 0.8980562598255327, disc_loss = 0.012074626471910443
Trained batch 1526 in epoch 19, gen_loss = 0.8980779446022293, disc_loss = 0.0120672170883389
Trained batch 1527 in epoch 19, gen_loss = 0.8980948513090923, disc_loss = 0.012059649421546664
Trained batch 1528 in epoch 19, gen_loss = 0.8981002748909146, disc_loss = 0.012052159563475924
Trained batch 1529 in epoch 19, gen_loss = 0.8980830741474052, disc_loss = 0.012044621575109679
Trained batch 1530 in epoch 19, gen_loss = 0.8981630724680182, disc_loss = 0.012037081383114235
Trained batch 1531 in epoch 19, gen_loss = 0.8981684635809134, disc_loss = 0.012029531078317515
Trained batch 1532 in epoch 19, gen_loss = 0.8981779451783933, disc_loss = 0.012021907755598226
Trained batch 1533 in epoch 19, gen_loss = 0.8982846868628784, disc_loss = 0.012014386947644975
Trained batch 1534 in epoch 19, gen_loss = 0.8983040996405511, disc_loss = 0.012007058974979154
Trained batch 1535 in epoch 19, gen_loss = 0.8982869035486752, disc_loss = 0.011999985611763483
Trained batch 1536 in epoch 19, gen_loss = 0.8983729798140739, disc_loss = 0.011992640367149802
Trained batch 1537 in epoch 19, gen_loss = 0.8983272228423889, disc_loss = 0.011985245855643197
Trained batch 1538 in epoch 19, gen_loss = 0.8983829725168214, disc_loss = 0.01197788344766541
Trained batch 1539 in epoch 19, gen_loss = 0.898416085870235, disc_loss = 0.01197036000369251
Trained batch 1540 in epoch 19, gen_loss = 0.8984216122484919, disc_loss = 0.011962979430520264
Trained batch 1541 in epoch 19, gen_loss = 0.8984472166007594, disc_loss = 0.011956136672223788
Trained batch 1542 in epoch 19, gen_loss = 0.8984341482720588, disc_loss = 0.011948971310222553
Trained batch 1543 in epoch 19, gen_loss = 0.8985139778935848, disc_loss = 0.011941547190662668
Trained batch 1544 in epoch 19, gen_loss = 0.8985153088291872, disc_loss = 0.011934165137188044
Trained batch 1545 in epoch 19, gen_loss = 0.898596279486956, disc_loss = 0.011926689042702068
Trained batch 1546 in epoch 19, gen_loss = 0.8985254532996501, disc_loss = 0.011919315250593886
Trained batch 1547 in epoch 19, gen_loss = 0.898501192761022, disc_loss = 0.011911893670017437
Trained batch 1548 in epoch 19, gen_loss = 0.8986308531964341, disc_loss = 0.01190459725754036
Trained batch 1549 in epoch 19, gen_loss = 0.8986760845107417, disc_loss = 0.011897226468058615
Trained batch 1550 in epoch 19, gen_loss = 0.8987143664956477, disc_loss = 0.011889949572727883
Trained batch 1551 in epoch 19, gen_loss = 0.8988287135881862, disc_loss = 0.011882557120759078
Trained batch 1552 in epoch 19, gen_loss = 0.8988879347569084, disc_loss = 0.011875355096435376
Trained batch 1553 in epoch 19, gen_loss = 0.8989296256728767, disc_loss = 0.011867975853407046
Trained batch 1554 in epoch 19, gen_loss = 0.8989522406525934, disc_loss = 0.011860690785540022
Trained batch 1555 in epoch 19, gen_loss = 0.8990233384245159, disc_loss = 0.011853332516565035
Trained batch 1556 in epoch 19, gen_loss = 0.8991148797992566, disc_loss = 0.011845946068790237
Trained batch 1557 in epoch 19, gen_loss = 0.8991637210025714, disc_loss = 0.011838661683998584
Trained batch 1558 in epoch 19, gen_loss = 0.8992334256346521, disc_loss = 0.011831246719133172
Trained batch 1559 in epoch 19, gen_loss = 0.8993026012793566, disc_loss = 0.011823883658011115
Trained batch 1560 in epoch 19, gen_loss = 0.8992536539148628, disc_loss = 0.011816887665803667
Trained batch 1561 in epoch 19, gen_loss = 0.8992919180060471, disc_loss = 0.01180967680174735
Trained batch 1562 in epoch 19, gen_loss = 0.8993024931301768, disc_loss = 0.011802427926315875
Trained batch 1563 in epoch 19, gen_loss = 0.8993471923386654, disc_loss = 0.01179508953354834
Trained batch 1564 in epoch 19, gen_loss = 0.8993444900924025, disc_loss = 0.01178782236178734
Trained batch 1565 in epoch 19, gen_loss = 0.8994008956208235, disc_loss = 0.011780606666195044
Trained batch 1566 in epoch 19, gen_loss = 0.8994501564026488, disc_loss = 0.011773326530391374
Trained batch 1567 in epoch 19, gen_loss = 0.8994664010420745, disc_loss = 0.011766097486457159
Trained batch 1568 in epoch 19, gen_loss = 0.8995372797365474, disc_loss = 0.011758820936633873
Trained batch 1569 in epoch 19, gen_loss = 0.8995432654383836, disc_loss = 0.011751569596579975
Trained batch 1570 in epoch 19, gen_loss = 0.8996054287703458, disc_loss = 0.011744355263765575
Trained batch 1571 in epoch 19, gen_loss = 0.8996817099532401, disc_loss = 0.011737045433696011
Trained batch 1572 in epoch 19, gen_loss = 0.8996637604150208, disc_loss = 0.01172986722699849
Trained batch 1573 in epoch 19, gen_loss = 0.8997134179293428, disc_loss = 0.011722732782913702
Trained batch 1574 in epoch 19, gen_loss = 0.8998227901307363, disc_loss = 0.011715517443341908
Trained batch 1575 in epoch 19, gen_loss = 0.8999341134038673, disc_loss = 0.011708660188719593
Trained batch 1576 in epoch 19, gen_loss = 0.8999056820636621, disc_loss = 0.011701705056142821
Trained batch 1577 in epoch 19, gen_loss = 0.89985272197669, disc_loss = 0.011694791909974139
Trained batch 1578 in epoch 19, gen_loss = 0.8998224586908994, disc_loss = 0.011687573081164639
Trained batch 1579 in epoch 19, gen_loss = 0.8998402123587042, disc_loss = 0.011680576122830355
Trained batch 1580 in epoch 19, gen_loss = 0.8998321088562277, disc_loss = 0.01167339621572506
Testing Epoch 19
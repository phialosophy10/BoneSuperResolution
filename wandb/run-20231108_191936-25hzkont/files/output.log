/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 1
Epoch 1, batch no. 10, gen. loss: 48344236.0, disc. loss: 0.6308553218841553
Epoch 1, batch no. 20, gen. loss: 57974368.0, disc. loss: 0.37252846360206604
Epoch 1, batch no. 30, gen. loss: 66685408.0, disc. loss: 0.341248095035553
Epoch 1, batch no. 40, gen. loss: 55992992.0, disc. loss: 0.45411550998687744
Epoch 1, batch no. 50, gen. loss: 63338700.0, disc. loss: 0.4022778570652008
Epoch 1, batch no. 60, gen. loss: 28466802.0, disc. loss: 0.34031981229782104
Epoch 1, batch no. 70, gen. loss: 35724384.0, disc. loss: 0.3334408700466156
Epoch 1, batch no. 80, gen. loss: 36300424.0, disc. loss: 0.34582436084747314
Epoch 1, batch no. 90, gen. loss: 35659264.0, disc. loss: 0.5177127122879028
Epoch 1, batch no. 100, gen. loss: 38181592.0, disc. loss: 0.3475731909275055
Epoch 1, batch no. 110, gen. loss: 44040760.0, disc. loss: 0.32853496074676514
Epoch 1, batch no. 120, gen. loss: 34833516.0, disc. loss: 0.3293423056602478
Epoch 1, batch no. 130, gen. loss: 25033532.0, disc. loss: 0.36937421560287476
Epoch 1, batch no. 140, gen. loss: 40422480.0, disc. loss: 0.33840543031692505
Epoch 1, batch no. 150, gen. loss: 42919096.0, disc. loss: 0.33478400111198425
Epoch 1, batch no. 160, gen. loss: 49394684.0, disc. loss: 0.3780927360057831
Epoch 1, batch no. 170, gen. loss: 43945500.0, disc. loss: 0.3318019509315491
Epoch 1, batch no. 180, gen. loss: 38495232.0, disc. loss: 0.42569252848625183
Epoch 1, batch no. 190, gen. loss: 36981736.0, disc. loss: 0.3401539623737335
Epoch 1, batch no. 200, gen. loss: 35231976.0, disc. loss: 0.41911396384239197
Epoch 1, batch no. 210, gen. loss: 37061064.0, disc. loss: 0.4521735608577728
Epoch 1, batch no. 220, gen. loss: 52895816.0, disc. loss: 0.32862263917922974
Epoch 1, batch no. 230, gen. loss: 52226432.0, disc. loss: 0.32640233635902405
Epoch 1, batch no. 240, gen. loss: 29039320.0, disc. loss: 0.32810115814208984
Epoch 1, batch no. 250, gen. loss: 31733718.0, disc. loss: 0.3271051049232483
Epoch 1, batch no. 260, gen. loss: 34852440.0, disc. loss: 0.3261079490184784
Epoch 1, batch no. 270, gen. loss: 29961500.0, disc. loss: 0.32572445273399353
Epoch 1, batch no. 280, gen. loss: 39782080.0, disc. loss: 0.326781690120697
Epoch 1, batch no. 290, gen. loss: 31141774.0, disc. loss: 0.3257136046886444
Epoch 1, batch no. 300, gen. loss: 35538528.0, disc. loss: 0.32553619146347046
Epoch 1, batch no. 310, gen. loss: 34748932.0, disc. loss: 0.3287665843963623
Epoch 1, batch no. 320, gen. loss: 33370316.0, disc. loss: 0.34118568897247314
Epoch 1, batch no. 330, gen. loss: 31908064.0, disc. loss: 0.3283727169036865
Epoch 1, batch no. 340, gen. loss: 37374856.0, disc. loss: 0.3302496075630188
Epoch 1, batch no. 350, gen. loss: 36068656.0, disc. loss: 0.33058416843414307
Epoch 1, batch no. 360, gen. loss: 35325676.0, disc. loss: 0.35623976588249207
Epoch 1, batch no. 370, gen. loss: 24363942.0, disc. loss: 0.3333345651626587
Epoch 1, batch no. 380, gen. loss: 41489972.0, disc. loss: 0.329595148563385
Epoch 1, batch no. 390, gen. loss: 30389660.0, disc. loss: 0.3271271884441376
Epoch 1, batch no. 400, gen. loss: 25795964.0, disc. loss: 0.3254581093788147
Epoch 1, batch no. 410, gen. loss: 27029556.0, disc. loss: 0.3251570165157318
Epoch 1, batch no. 420, gen. loss: 23482732.0, disc. loss: 0.3254561424255371
Epoch 1, batch no. 430, gen. loss: 31616266.0, disc. loss: 0.32524919509887695
Epoch 1, batch no. 440, gen. loss: 42980728.0, disc. loss: 0.3259759545326233
Epoch 1, batch no. 450, gen. loss: 22713362.0, disc. loss: 0.32616370916366577
Epoch 1, batch no. 460, gen. loss: 23265786.0, disc. loss: 0.32625246047973633
Epoch 1, batch no. 470, gen. loss: 42165824.0, disc. loss: 0.3265947103500366
Epoch 1, batch no. 480, gen. loss: 22888344.0, disc. loss: 0.3257334530353546
Epoch 1, batch no. 490, gen. loss: 30208752.0, disc. loss: 0.3263953924179077
Epoch 1, batch no. 500, gen. loss: 20068326.0, disc. loss: 0.32572680711746216
Epoch 1, batch no. 510, gen. loss: 38423864.0, disc. loss: 0.32614320516586304
Epoch 1, batch no. 520, gen. loss: 45043740.0, disc. loss: 0.3267049491405487
Epoch 1, batch no. 530, gen. loss: 30655246.0, disc. loss: 0.3252824544906616
Epoch 1, batch no. 540, gen. loss: 14957080.0, disc. loss: 0.325747013092041
Epoch 1, batch no. 550, gen. loss: 24556304.0, disc. loss: 0.3252963721752167
Epoch 1, batch no. 560, gen. loss: 16489554.0, disc. loss: 0.3253111243247986
Epoch 1, batch no. 570, gen. loss: 21783674.0, disc. loss: 0.325212687253952
Epoch 1, batch no. 580, gen. loss: 40213356.0, disc. loss: 0.3253328800201416
Epoch 1, batch no. 590, gen. loss: 21101974.0, disc. loss: 0.32588836550712585
Epoch 1, batch no. 600, gen. loss: 31503936.0, disc. loss: 0.32526010274887085
Epoch 1, batch no. 610, gen. loss: 23342138.0, disc. loss: 0.32513049244880676
Epoch 1, batch no. 620, gen. loss: 16897290.0, disc. loss: 0.32518112659454346
Epoch 1, batch no. 630, gen. loss: 15232124.0, disc. loss: 0.3251098394393921
Epoch 1, batch no. 640, gen. loss: 27590624.0, disc. loss: 0.3256039023399353
Epoch 1, batch no. 650, gen. loss: 11410803.0, disc. loss: 0.3252255618572235
Epoch 1, batch no. 660, gen. loss: 24120086.0, disc. loss: 0.3252348005771637
Epoch 1, batch no. 670, gen. loss: 14398232.0, disc. loss: 0.32533931732177734
Epoch 1, batch no. 680, gen. loss: 16370074.0, disc. loss: 0.3252476453781128
Epoch 1, batch no. 690, gen. loss: 49119844.0, disc. loss: 0.32540789246559143
Epoch 1, batch no. 700, gen. loss: 21516170.0, disc. loss: 0.32515257596969604
Epoch 1, batch no. 710, gen. loss: 13830986.0, disc. loss: 0.3251636028289795
Epoch 1, batch no. 720, gen. loss: 16026255.0, disc. loss: 0.32516294717788696
Epoch 1, batch no. 730, gen. loss: 17061544.0, disc. loss: 0.32753944396972656
Epoch 1, batch no. 740, gen. loss: 18489934.0, disc. loss: 0.32862988114356995
Epoch 1, batch no. 750, gen. loss: 41074088.0, disc. loss: 0.3270336985588074
Epoch 1, batch no. 760, gen. loss: 12198047.0, disc. loss: 0.32759571075439453
Testing Epoch 1
Discriminator training/validation loss in epoch 1/1 was 0.3494/0.3374
Generator GAN training/validation loss in epoch 1/1 was 31314971.8868/52915371.2329
Average PSNR of validation set in epoch 1/1 was 11.7710
Average SSIM of validation set in epoch 1/1 was -0.0041
Average discriminator guess on reals in epoch 1/1 was 0.9093
Average discriminator guess on fakes in epoch 1/1 was 0.0000
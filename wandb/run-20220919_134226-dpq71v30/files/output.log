/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.8993349075317383, disc_loss = 0.455181747674942
Trained batch 1 in epoch 0, gen_loss = 1.0614776611328125, disc_loss = 0.8148660212755203
Trained batch 2 in epoch 0, gen_loss = 0.9616798957188925, disc_loss = 0.6698210835456848
Trained batch 3 in epoch 0, gen_loss = 0.910574421286583, disc_loss = 0.5759078785777092
Trained batch 4 in epoch 0, gen_loss = 0.8814382433891297, disc_loss = 0.5091621696949005
Trained batch 5 in epoch 0, gen_loss = 0.877601553996404, disc_loss = 0.4691328704357147
Trained batch 6 in epoch 0, gen_loss = 0.8661909358842033, disc_loss = 0.43673532775470186
Trained batch 7 in epoch 0, gen_loss = 0.858802042901516, disc_loss = 0.42097434401512146
Trained batch 8 in epoch 0, gen_loss = 0.8483443458875021, disc_loss = 0.4054278896914588
Trained batch 9 in epoch 0, gen_loss = 0.860273689031601, disc_loss = 0.3844820946455002
Trained batch 10 in epoch 0, gen_loss = 0.8687705993652344, disc_loss = 0.36407040330496704
Trained batch 11 in epoch 0, gen_loss = 0.8653930077950159, disc_loss = 0.3459603289763133
Trained batch 12 in epoch 0, gen_loss = 0.8598175461475666, disc_loss = 0.33045271039009094
Trained batch 13 in epoch 0, gen_loss = 0.8546140193939209, disc_loss = 0.31570410089833395
Trained batch 14 in epoch 0, gen_loss = 0.8564762989679973, disc_loss = 0.30372301638126376
Trained batch 15 in epoch 0, gen_loss = 0.851404957473278, disc_loss = 0.2925466005690396
Trained batch 16 in epoch 0, gen_loss = 0.8443211422247046, disc_loss = 0.2854893658967579
Trained batch 17 in epoch 0, gen_loss = 0.8554733097553253, disc_loss = 0.28383755145801437
Trained batch 18 in epoch 0, gen_loss = 0.8550297084607577, disc_loss = 0.28847347866547735
Trained batch 19 in epoch 0, gen_loss = 0.8545800417661666, disc_loss = 0.2863436218351126
Trained batch 20 in epoch 0, gen_loss = 0.8592968242509025, disc_loss = 0.2805267043766521
Trained batch 21 in epoch 0, gen_loss = 0.8603494411165064, disc_loss = 0.2741395150395957
Trained batch 22 in epoch 0, gen_loss = 0.8611004171164139, disc_loss = 0.26739184947117517
Trained batch 23 in epoch 0, gen_loss = 0.863113097846508, disc_loss = 0.2602061831081907
Trained batch 24 in epoch 0, gen_loss = 0.8638928818702698, disc_loss = 0.2530611297488213
Trained batch 25 in epoch 0, gen_loss = 0.864037465590697, disc_loss = 0.24666598439216614
Trained batch 26 in epoch 0, gen_loss = 0.8684706334714536, disc_loss = 0.24048809707164764
Trained batch 27 in epoch 0, gen_loss = 0.8711743184498378, disc_loss = 0.23464558752519743
Trained batch 28 in epoch 0, gen_loss = 0.8745400206796055, disc_loss = 0.22961486516327695
Trained batch 29 in epoch 0, gen_loss = 0.8761240998903911, disc_loss = 0.22453628728787103
Trained batch 30 in epoch 0, gen_loss = 0.8793618813637765, disc_loss = 0.21975193244795646
Trained batch 31 in epoch 0, gen_loss = 0.8818837460130453, disc_loss = 0.2154314408544451
Trained batch 32 in epoch 0, gen_loss = 0.8879119898333694, disc_loss = 0.2110997878692367
Trained batch 33 in epoch 0, gen_loss = 0.8965249534915475, disc_loss = 0.20726832133882186
Trained batch 34 in epoch 0, gen_loss = 0.9044843111719404, disc_loss = 0.20372224301099778
Trained batch 35 in epoch 0, gen_loss = 0.9104501720931795, disc_loss = 0.19985367274946636
Trained batch 36 in epoch 0, gen_loss = 0.9167260398735871, disc_loss = 0.19568947712714607
Trained batch 37 in epoch 0, gen_loss = 0.9218861099920774, disc_loss = 0.19155542650505117
Trained batch 38 in epoch 0, gen_loss = 0.926738862807934, disc_loss = 0.1875556822006519
Trained batch 39 in epoch 0, gen_loss = 0.9320827558636665, disc_loss = 0.18376891138032078
Trained batch 40 in epoch 0, gen_loss = 0.9361858527834822, disc_loss = 0.1800496818997511
Trained batch 41 in epoch 0, gen_loss = 0.940512261220387, disc_loss = 0.17645872326656467
Trained batch 42 in epoch 0, gen_loss = 0.9449645239253377, disc_loss = 0.173070119390654
Trained batch 43 in epoch 0, gen_loss = 0.9501869529485703, disc_loss = 0.16977731443264268
Trained batch 44 in epoch 0, gen_loss = 0.9544873515764872, disc_loss = 0.16667681295010778
Trained batch 45 in epoch 0, gen_loss = 0.957693083130795, disc_loss = 0.16365765375287636
Trained batch 46 in epoch 0, gen_loss = 0.9601000965909755, disc_loss = 0.1606781223115135
Trained batch 47 in epoch 0, gen_loss = 0.9646568261086941, disc_loss = 0.15790049945159504
Trained batch 48 in epoch 0, gen_loss = 0.9680997023777086, disc_loss = 0.1552085987843421
Trained batch 49 in epoch 0, gen_loss = 0.9709389889240265, disc_loss = 0.1525921068713069
Trained batch 50 in epoch 0, gen_loss = 0.9745165752429589, disc_loss = 0.15011099441086545
Trained batch 51 in epoch 0, gen_loss = 0.9770047469780996, disc_loss = 0.14766144917274898
Trained batch 52 in epoch 0, gen_loss = 0.9799249925703373, disc_loss = 0.14530485411578753
Trained batch 53 in epoch 0, gen_loss = 0.982305117227413, disc_loss = 0.14304018889864287
Trained batch 54 in epoch 0, gen_loss = 0.9842841917818242, disc_loss = 0.1408368128944527
Trained batch 55 in epoch 0, gen_loss = 0.986616316650595, disc_loss = 0.13867276161909103
Trained batch 56 in epoch 0, gen_loss = 0.989336115226411, disc_loss = 0.13657373895770625
Trained batch 57 in epoch 0, gen_loss = 0.9902897734066536, disc_loss = 0.13454497958822498
Trained batch 58 in epoch 0, gen_loss = 0.9917926697407738, disc_loss = 0.1325915552423162
Trained batch 59 in epoch 0, gen_loss = 0.9940583974123001, disc_loss = 0.1307847364495198
Trained batch 60 in epoch 0, gen_loss = 0.9959563671565447, disc_loss = 0.12901115747260267
Trained batch 61 in epoch 0, gen_loss = 0.9975787987632136, disc_loss = 0.12732355278586188
Trained batch 62 in epoch 0, gen_loss = 0.999654888160645, disc_loss = 0.12568543150666214
Trained batch 63 in epoch 0, gen_loss = 1.002390836365521, disc_loss = 0.12405949135427363
Trained batch 64 in epoch 0, gen_loss = 1.0031660437583922, disc_loss = 0.12242205618665769
Trained batch 65 in epoch 0, gen_loss = 1.005492068601377, disc_loss = 0.12082990162977666
Trained batch 66 in epoch 0, gen_loss = 1.0063230075053315, disc_loss = 0.11927406403667001
Trained batch 67 in epoch 0, gen_loss = 1.0071931770619225, disc_loss = 0.11774354726623963
Trained batch 68 in epoch 0, gen_loss = 1.0079170456831006, disc_loss = 0.11626396206733973
Trained batch 69 in epoch 0, gen_loss = 1.0087204839502062, disc_loss = 0.11482804292546851
Trained batch 70 in epoch 0, gen_loss = 1.0097381841968482, disc_loss = 0.1134526173151295
Trained batch 71 in epoch 0, gen_loss = 1.0113646528787084, disc_loss = 0.11211535901141663
Trained batch 72 in epoch 0, gen_loss = 1.012221193476899, disc_loss = 0.11081142593430329
Trained batch 73 in epoch 0, gen_loss = 1.0116121213178377, disc_loss = 0.109522503624494
Trained batch 74 in epoch 0, gen_loss = 1.0123808979988098, disc_loss = 0.10827266089618207
Trained batch 75 in epoch 0, gen_loss = 1.012963733390758, disc_loss = 0.10706734282307719
Trained batch 76 in epoch 0, gen_loss = 1.0136863372542642, disc_loss = 0.10588366260098947
Trained batch 77 in epoch 0, gen_loss = 1.0149063506187537, disc_loss = 0.10474735025603038
Trained batch 78 in epoch 0, gen_loss = 1.0156935038445871, disc_loss = 0.10371953399875496
Trained batch 79 in epoch 0, gen_loss = 1.016824121028185, disc_loss = 0.10290374062024057
Trained batch 80 in epoch 0, gen_loss = 1.0192991546642634, disc_loss = 0.10196994631378739
Trained batch 81 in epoch 0, gen_loss = 1.0211978285777858, disc_loss = 0.10100839823120977
Trained batch 82 in epoch 0, gen_loss = 1.022364120167422, disc_loss = 0.1000654978834721
Trained batch 83 in epoch 0, gen_loss = 1.0234780872151965, disc_loss = 0.09923385003847736
Trained batch 84 in epoch 0, gen_loss = 1.024852021301494, disc_loss = 0.09840794372207978
Trained batch 85 in epoch 0, gen_loss = 1.0258193466552468, disc_loss = 0.09758094754503217
Trained batch 86 in epoch 0, gen_loss = 1.0273469761870373, disc_loss = 0.09671351758913062
Trained batch 87 in epoch 0, gen_loss = 1.0282977988774127, disc_loss = 0.09580316925844685
Trained batch 88 in epoch 0, gen_loss = 1.0287637703874137, disc_loss = 0.09486832042758385
Trained batch 89 in epoch 0, gen_loss = 1.0303284453021155, disc_loss = 0.09397283630031679
Trained batch 90 in epoch 0, gen_loss = 1.0304879415166246, disc_loss = 0.09308561869989057
Trained batch 91 in epoch 0, gen_loss = 1.0306727814933527, disc_loss = 0.09222716420038563
Trained batch 92 in epoch 0, gen_loss = 1.0313507414633227, disc_loss = 0.09139334281245547
Trained batch 93 in epoch 0, gen_loss = 1.0318993095387803, disc_loss = 0.09054908825163828
Trained batch 94 in epoch 0, gen_loss = 1.0320096135139465, disc_loss = 0.08971414910139222
Trained batch 95 in epoch 0, gen_loss = 1.0321693091342847, disc_loss = 0.08892249424631397
Trained batch 96 in epoch 0, gen_loss = 1.0323617525936402, disc_loss = 0.08812754887357815
Trained batch 97 in epoch 0, gen_loss = 1.0326301096653452, disc_loss = 0.08736118982184907
Trained batch 98 in epoch 0, gen_loss = 1.0322193407049083, disc_loss = 0.08659213254548083
Trained batch 99 in epoch 0, gen_loss = 1.0322850745916368, disc_loss = 0.0858425161615014
Trained batch 100 in epoch 0, gen_loss = 1.0321845483071734, disc_loss = 0.08510328068554697
Trained batch 101 in epoch 0, gen_loss = 1.0325599692615808, disc_loss = 0.08439410673271791
Trained batch 102 in epoch 0, gen_loss = 1.0320804443174196, disc_loss = 0.08367646955749364
Trained batch 103 in epoch 0, gen_loss = 1.032050208403514, disc_loss = 0.08297522617683101
Trained batch 104 in epoch 0, gen_loss = 1.0324922800064087, disc_loss = 0.0822972145907226
Trained batch 105 in epoch 0, gen_loss = 1.032785768778819, disc_loss = 0.08163145760003969
Trained batch 106 in epoch 0, gen_loss = 1.0325308648225302, disc_loss = 0.0809671400445644
Trained batch 107 in epoch 0, gen_loss = 1.0327383346027799, disc_loss = 0.08031790247359485
Trained batch 108 in epoch 0, gen_loss = 1.0330618324629757, disc_loss = 0.0796784203619175
Trained batch 109 in epoch 0, gen_loss = 1.0330136635086753, disc_loss = 0.0790459198961881
Trained batch 110 in epoch 0, gen_loss = 1.0331654011666238, disc_loss = 0.07841031544481043
Trained batch 111 in epoch 0, gen_loss = 1.0327004098466463, disc_loss = 0.07778893433611042
Trained batch 112 in epoch 0, gen_loss = 1.0323399600729477, disc_loss = 0.07718226449580583
Trained batch 113 in epoch 0, gen_loss = 1.032461939150827, disc_loss = 0.07659609948301263
Trained batch 114 in epoch 0, gen_loss = 1.0326857546101447, disc_loss = 0.07602520090244387
Trained batch 115 in epoch 0, gen_loss = 1.032312060738432, disc_loss = 0.07547380391444111
Trained batch 116 in epoch 0, gen_loss = 1.0319508584136636, disc_loss = 0.07493926899141481
Trained batch 117 in epoch 0, gen_loss = 1.0316804905058974, disc_loss = 0.07441705431378746
Trained batch 118 in epoch 0, gen_loss = 1.0316197666801323, disc_loss = 0.07389313017777285
Trained batch 119 in epoch 0, gen_loss = 1.0318746124704679, disc_loss = 0.07336849697555105
Trained batch 120 in epoch 0, gen_loss = 1.0319327810579095, disc_loss = 0.07287250694718735
Trained batch 121 in epoch 0, gen_loss = 1.0318213188257375, disc_loss = 0.07238977071142098
Trained batch 122 in epoch 0, gen_loss = 1.0319166808593563, disc_loss = 0.07190252692113078
Trained batch 123 in epoch 0, gen_loss = 1.032026281760585, disc_loss = 0.07140712123063783
Trained batch 124 in epoch 0, gen_loss = 1.0322536234855653, disc_loss = 0.07092398172616958
Trained batch 125 in epoch 0, gen_loss = 1.032249886365164, disc_loss = 0.07043653191436851
Trained batch 126 in epoch 0, gen_loss = 1.0320259159005534, disc_loss = 0.0699633023019616
Trained batch 127 in epoch 0, gen_loss = 1.0320023433305323, disc_loss = 0.06949127711413894
Trained batch 128 in epoch 0, gen_loss = 1.0320253349089807, disc_loss = 0.06904554930190708
Trained batch 129 in epoch 0, gen_loss = 1.0319175458871401, disc_loss = 0.06862717922776937
Trained batch 130 in epoch 0, gen_loss = 1.0315910500424508, disc_loss = 0.0682367454958326
Trained batch 131 in epoch 0, gen_loss = 1.0313305886405888, disc_loss = 0.06783208097895664
Trained batch 132 in epoch 0, gen_loss = 1.0311017551816495, disc_loss = 0.06742557190722764
Trained batch 133 in epoch 0, gen_loss = 1.0308695666825594, disc_loss = 0.06702789006782557
Trained batch 134 in epoch 0, gen_loss = 1.0308933920330472, disc_loss = 0.06664873614079422
Trained batch 135 in epoch 0, gen_loss = 1.0308664292097092, disc_loss = 0.0662795100498068
Trained batch 136 in epoch 0, gen_loss = 1.0311436209365399, disc_loss = 0.06592468487737822
Trained batch 137 in epoch 0, gen_loss = 1.0310092283331829, disc_loss = 0.06555305595469216
Trained batch 138 in epoch 0, gen_loss = 1.0311323086992443, disc_loss = 0.0651436465919661
Trained batch 139 in epoch 0, gen_loss = 1.031151420729501, disc_loss = 0.06473131452554039
Trained batch 140 in epoch 0, gen_loss = 1.0311083810549255, disc_loss = 0.06433384866182897
Trained batch 141 in epoch 0, gen_loss = 1.031202712529142, disc_loss = 0.06393069275786024
Trained batch 142 in epoch 0, gen_loss = 1.0313676737405204, disc_loss = 0.06353670496076762
Trained batch 143 in epoch 0, gen_loss = 1.0315365261501737, disc_loss = 0.06314848496630374
Trained batch 144 in epoch 0, gen_loss = 1.0316743151894932, disc_loss = 0.06276484684825971
Trained batch 145 in epoch 0, gen_loss = 1.0316188719174633, disc_loss = 0.062382284054303
Trained batch 146 in epoch 0, gen_loss = 1.0314060725322387, disc_loss = 0.06200269633764718
Trained batch 147 in epoch 0, gen_loss = 1.031490930028864, disc_loss = 0.06162504989943291
Trained batch 148 in epoch 0, gen_loss = 1.0314929653334137, disc_loss = 0.061255833121554165
Trained batch 149 in epoch 0, gen_loss = 1.0316161934534709, disc_loss = 0.06089568520585696
Trained batch 150 in epoch 0, gen_loss = 1.0313061633646883, disc_loss = 0.060542534790094325
Trained batch 151 in epoch 0, gen_loss = 1.0313312027015185, disc_loss = 0.06018729464726915
Trained batch 152 in epoch 0, gen_loss = 1.0314836237165663, disc_loss = 0.05983765774522147
Trained batch 153 in epoch 0, gen_loss = 1.0311580997008782, disc_loss = 0.05949446598563779
Trained batch 154 in epoch 0, gen_loss = 1.0312943643139254, disc_loss = 0.059172432265815235
Trained batch 155 in epoch 0, gen_loss = 1.0314959333493159, disc_loss = 0.058853842404623255
Trained batch 156 in epoch 0, gen_loss = 1.0316033834105085, disc_loss = 0.05852574228670946
Trained batch 157 in epoch 0, gen_loss = 1.0319713354110718, disc_loss = 0.05821452109449649
Trained batch 158 in epoch 0, gen_loss = 1.0319795728479542, disc_loss = 0.05792647686277358
Trained batch 159 in epoch 0, gen_loss = 1.0319836139678955, disc_loss = 0.057676704454934224
Trained batch 160 in epoch 0, gen_loss = 1.0319531837605542, disc_loss = 0.05742034806019586
Trained batch 161 in epoch 0, gen_loss = 1.0322010885050268, disc_loss = 0.0571431009972721
Trained batch 162 in epoch 0, gen_loss = 1.0318749894393733, disc_loss = 0.056854399001122984
Trained batch 163 in epoch 0, gen_loss = 1.031818266321973, disc_loss = 0.05657005754140455
Trained batch 164 in epoch 0, gen_loss = 1.0315545761223994, disc_loss = 0.05629063170741905
Trained batch 165 in epoch 0, gen_loss = 1.031385591949325, disc_loss = 0.05601632917097893
Trained batch 166 in epoch 0, gen_loss = 1.031538972597636, disc_loss = 0.05573183366147701
Trained batch 167 in epoch 0, gen_loss = 1.0315251981928235, disc_loss = 0.055434608868035
Trained batch 168 in epoch 0, gen_loss = 1.0314651960451928, disc_loss = 0.05514539747372182
Trained batch 169 in epoch 0, gen_loss = 1.0317688759635477, disc_loss = 0.05487266003209002
Trained batch 170 in epoch 0, gen_loss = 1.0318333217275073, disc_loss = 0.054599209067722164
Trained batch 171 in epoch 0, gen_loss = 1.0317041007585304, disc_loss = 0.05432557068808481
Trained batch 172 in epoch 0, gen_loss = 1.0315993982932472, disc_loss = 0.05406060868152821
Trained batch 173 in epoch 0, gen_loss = 1.0316035891401356, disc_loss = 0.05379317057233347
Trained batch 174 in epoch 0, gen_loss = 1.0318368646076748, disc_loss = 0.05351982313873512
Trained batch 175 in epoch 0, gen_loss = 1.0316695862195708, disc_loss = 0.053248335697307164
Trained batch 176 in epoch 0, gen_loss = 1.0318309540128978, disc_loss = 0.05297627551533745
Trained batch 177 in epoch 0, gen_loss = 1.0317657147900443, disc_loss = 0.052708434914186426
Trained batch 178 in epoch 0, gen_loss = 1.0318164825439453, disc_loss = 0.052444132294651516
Trained batch 179 in epoch 0, gen_loss = 1.0315336863199869, disc_loss = 0.05218594743508018
Trained batch 180 in epoch 0, gen_loss = 1.031603227004162, disc_loss = 0.051926477534377444
Trained batch 181 in epoch 0, gen_loss = 1.0313627274481805, disc_loss = 0.05166822056807987
Trained batch 182 in epoch 0, gen_loss = 1.0313090711343484, disc_loss = 0.051414074600150024
Trained batch 183 in epoch 0, gen_loss = 1.0311616225087123, disc_loss = 0.05116125570519058
Trained batch 184 in epoch 0, gen_loss = 1.0311018782692987, disc_loss = 0.05091752747728213
Trained batch 185 in epoch 0, gen_loss = 1.0310793288292424, disc_loss = 0.05068124428902182
Trained batch 186 in epoch 0, gen_loss = 1.0311101764281165, disc_loss = 0.0504451570111043
Trained batch 187 in epoch 0, gen_loss = 1.0308809486475397, disc_loss = 0.05020359169166694
Trained batch 188 in epoch 0, gen_loss = 1.0306152379702007, disc_loss = 0.04996960115663353
Trained batch 189 in epoch 0, gen_loss = 1.0306546113992991, disc_loss = 0.049738233894305796
Trained batch 190 in epoch 0, gen_loss = 1.0305291149004592, disc_loss = 0.04950857817814612
Trained batch 191 in epoch 0, gen_loss = 1.0303465534622471, disc_loss = 0.04928158934975121
Trained batch 192 in epoch 0, gen_loss = 1.0301912062526366, disc_loss = 0.0490618751099613
Trained batch 193 in epoch 0, gen_loss = 1.03032767373262, disc_loss = 0.0488458658621368
Trained batch 194 in epoch 0, gen_loss = 1.0303548406331966, disc_loss = 0.04863439470481796
Trained batch 195 in epoch 0, gen_loss = 1.030230913539322, disc_loss = 0.048423642050284814
Trained batch 196 in epoch 0, gen_loss = 1.0300201906770619, disc_loss = 0.04821122618779767
Trained batch 197 in epoch 0, gen_loss = 1.0299116803540125, disc_loss = 0.04799555990412229
Trained batch 198 in epoch 0, gen_loss = 1.029754526950606, disc_loss = 0.04778091126968663
Trained batch 199 in epoch 0, gen_loss = 1.0297121998667718, disc_loss = 0.04756786556914449
Trained batch 200 in epoch 0, gen_loss = 1.0294256509833075, disc_loss = 0.04735588541356337
Trained batch 201 in epoch 0, gen_loss = 1.0297392208387357, disc_loss = 0.04715155156808767
Trained batch 202 in epoch 0, gen_loss = 1.029236824935293, disc_loss = 0.04694464134988306
Trained batch 203 in epoch 0, gen_loss = 1.0292042584395875, disc_loss = 0.04673997022887217
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0558143854141235, disc_loss = 0.004877760540693998
Trained batch 1 in epoch 1, gen_loss = 1.063492774963379, disc_loss = 0.004747930681332946
Trained batch 2 in epoch 1, gen_loss = 1.041653037071228, disc_loss = 0.004919679990659158
Trained batch 3 in epoch 1, gen_loss = 1.0366244614124298, disc_loss = 0.0048204612685367465
Trained batch 4 in epoch 1, gen_loss = 1.0343366861343384, disc_loss = 0.004776258859783411
Trained batch 5 in epoch 1, gen_loss = 1.0403599937756856, disc_loss = 0.004872396665935715
Trained batch 6 in epoch 1, gen_loss = 1.0385104417800903, disc_loss = 0.004891805151211364
Trained batch 7 in epoch 1, gen_loss = 1.0390124469995499, disc_loss = 0.00493918388383463
Trained batch 8 in epoch 1, gen_loss = 1.0365187989340887, disc_loss = 0.0049440512537128395
Trained batch 9 in epoch 1, gen_loss = 1.0366390705108643, disc_loss = 0.004898726427927613
Trained batch 10 in epoch 1, gen_loss = 1.0343150225552646, disc_loss = 0.0048554989678615875
Trained batch 11 in epoch 1, gen_loss = 1.0302846332391102, disc_loss = 0.0047437148362708586
Trained batch 12 in epoch 1, gen_loss = 1.0275587026889508, disc_loss = 0.004633070811486015
Trained batch 13 in epoch 1, gen_loss = 1.0278865354401725, disc_loss = 0.004558216331393591
Trained batch 14 in epoch 1, gen_loss = 1.0282603899637859, disc_loss = 0.004480212818210324
Trained batch 15 in epoch 1, gen_loss = 1.0250165797770023, disc_loss = 0.007283687955350615
Trained batch 16 in epoch 1, gen_loss = 1.04656784324085, disc_loss = 0.011321246089852032
Trained batch 17 in epoch 1, gen_loss = 1.0544111165735457, disc_loss = 0.015691132918517623
Trained batch 18 in epoch 1, gen_loss = 1.0658494516422874, disc_loss = 0.023598468531609365
Trained batch 19 in epoch 1, gen_loss = 1.0817653745412827, disc_loss = 0.034267841943074015
Trained batch 20 in epoch 1, gen_loss = 1.0872306114151364, disc_loss = 0.03656896444347998
Trained batch 21 in epoch 1, gen_loss = 1.0897813954136588, disc_loss = 0.036719937142069364
Trained batch 22 in epoch 1, gen_loss = 1.093856358009836, disc_loss = 0.03601955105145664
Trained batch 23 in epoch 1, gen_loss = 1.0968489224712055, disc_loss = 0.03512632320052944
Trained batch 24 in epoch 1, gen_loss = 1.1004327130317688, disc_loss = 0.034205584162846206
Trained batch 25 in epoch 1, gen_loss = 1.102683587716176, disc_loss = 0.03334626774840917
Trained batch 26 in epoch 1, gen_loss = 1.1066190247182492, disc_loss = 0.03245883925679933
Trained batch 27 in epoch 1, gen_loss = 1.1105933508702688, disc_loss = 0.03160488938946011
Trained batch 28 in epoch 1, gen_loss = 1.1113725756776744, disc_loss = 0.03073492762632668
Trained batch 29 in epoch 1, gen_loss = 1.1094158033529917, disc_loss = 0.02993384029250592
Trained batch 30 in epoch 1, gen_loss = 1.1101848790722508, disc_loss = 0.02920128258636161
Trained batch 31 in epoch 1, gen_loss = 1.112139182165265, disc_loss = 0.028500212378276046
Trained batch 32 in epoch 1, gen_loss = 1.1116001985289834, disc_loss = 0.027850804758737937
Trained batch 33 in epoch 1, gen_loss = 1.112780923352522, disc_loss = 0.027220342657528818
Trained batch 34 in epoch 1, gen_loss = 1.1127990330968585, disc_loss = 0.026632840099877545
Trained batch 35 in epoch 1, gen_loss = 1.1140483568112056, disc_loss = 0.02611567113005246
Trained batch 36 in epoch 1, gen_loss = 1.1154507350277256, disc_loss = 0.02562749926378397
Trained batch 37 in epoch 1, gen_loss = 1.1171189342674457, disc_loss = 0.025198244630653215
Trained batch 38 in epoch 1, gen_loss = 1.1181328128545711, disc_loss = 0.02475484108958298
Trained batch 39 in epoch 1, gen_loss = 1.1220344707369805, disc_loss = 0.024300111568300052
Trained batch 40 in epoch 1, gen_loss = 1.1253895861346548, disc_loss = 0.023832907542450037
Trained batch 41 in epoch 1, gen_loss = 1.12582275839079, disc_loss = 0.023380533975016857
Trained batch 42 in epoch 1, gen_loss = 1.1261611968971963, disc_loss = 0.022950322437641578
Trained batch 43 in epoch 1, gen_loss = 1.1272495998577639, disc_loss = 0.022529797940726647
Trained batch 44 in epoch 1, gen_loss = 1.128447057141198, disc_loss = 0.022115075381265746
Trained batch 45 in epoch 1, gen_loss = 1.128785103559494, disc_loss = 0.021723230794558058
Trained batch 46 in epoch 1, gen_loss = 1.1288209582896942, disc_loss = 0.021338816771798944
Trained batch 47 in epoch 1, gen_loss = 1.1291493910054367, disc_loss = 0.020972303881232317
Trained batch 48 in epoch 1, gen_loss = 1.1296039199342534, disc_loss = 0.020624030143858826
Trained batch 49 in epoch 1, gen_loss = 1.1304500830173492, disc_loss = 0.020317460969090463
Trained batch 50 in epoch 1, gen_loss = 1.1298117322080277, disc_loss = 0.020021988416784535
Trained batch 51 in epoch 1, gen_loss = 1.129726135959992, disc_loss = 0.019717545767959494
Trained batch 52 in epoch 1, gen_loss = 1.130081852651992, disc_loss = 0.019424195436514774
Trained batch 53 in epoch 1, gen_loss = 1.1314164720199726, disc_loss = 0.019136484457973252
Trained batch 54 in epoch 1, gen_loss = 1.1317984635179692, disc_loss = 0.018870674806054342
Trained batch 55 in epoch 1, gen_loss = 1.132483391889504, disc_loss = 0.018613881901338964
Trained batch 56 in epoch 1, gen_loss = 1.1319302498248585, disc_loss = 0.018348487498434752
Trained batch 57 in epoch 1, gen_loss = 1.1313237969217629, disc_loss = 0.018107003094789027
Trained batch 58 in epoch 1, gen_loss = 1.130328044042749, disc_loss = 0.01785975073116942
Trained batch 59 in epoch 1, gen_loss = 1.1291569262742995, disc_loss = 0.017621475943208984
Trained batch 60 in epoch 1, gen_loss = 1.1282148507774854, disc_loss = 0.017422852407927153
Trained batch 61 in epoch 1, gen_loss = 1.128138679650522, disc_loss = 0.01725714171170107
Trained batch 62 in epoch 1, gen_loss = 1.127898599420275, disc_loss = 0.01707692860832645
Trained batch 63 in epoch 1, gen_loss = 1.1280779177322984, disc_loss = 0.01688381417261553
Trained batch 64 in epoch 1, gen_loss = 1.1276825400499197, disc_loss = 0.016690342934229052
Trained batch 65 in epoch 1, gen_loss = 1.127752451282559, disc_loss = 0.016511367058917654
Trained batch 66 in epoch 1, gen_loss = 1.127538363435375, disc_loss = 0.01634624409628337
Trained batch 67 in epoch 1, gen_loss = 1.1277893772896599, disc_loss = 0.016167882785392815
Trained batch 68 in epoch 1, gen_loss = 1.1279065600339917, disc_loss = 0.01599208790930393
Trained batch 69 in epoch 1, gen_loss = 1.1279404205935342, disc_loss = 0.015813016508972006
Trained batch 70 in epoch 1, gen_loss = 1.1280390116530405, disc_loss = 0.015642034463768065
Trained batch 71 in epoch 1, gen_loss = 1.1278575468394492, disc_loss = 0.015480831229878176
Trained batch 72 in epoch 1, gen_loss = 1.127810926470038, disc_loss = 0.015335437679050924
Trained batch 73 in epoch 1, gen_loss = 1.1281049791220072, disc_loss = 0.015178050087588662
Trained batch 74 in epoch 1, gen_loss = 1.1280650432904562, disc_loss = 0.01501715309607486
Trained batch 75 in epoch 1, gen_loss = 1.1281142964174873, disc_loss = 0.014861488815911702
Trained batch 76 in epoch 1, gen_loss = 1.127832887234626, disc_loss = 0.014705961685047134
Trained batch 77 in epoch 1, gen_loss = 1.1271938735093825, disc_loss = 0.014548024210410241
Trained batch 78 in epoch 1, gen_loss = 1.126407426369341, disc_loss = 0.014397415456279546
Trained batch 79 in epoch 1, gen_loss = 1.1258692853152752, disc_loss = 0.014248837489867583
Trained batch 80 in epoch 1, gen_loss = 1.1257666400921198, disc_loss = 0.014119774879266819
Trained batch 81 in epoch 1, gen_loss = 1.1258792564636324, disc_loss = 0.013993397167679377
Trained batch 82 in epoch 1, gen_loss = 1.1256761960236423, disc_loss = 0.013869005401270935
Trained batch 83 in epoch 1, gen_loss = 1.1252078307526452, disc_loss = 0.013750592224477302
Trained batch 84 in epoch 1, gen_loss = 1.1242980795748094, disc_loss = 0.013625744533012895
Trained batch 85 in epoch 1, gen_loss = 1.1237160667430524, disc_loss = 0.01350055445732852
Trained batch 86 in epoch 1, gen_loss = 1.123599809476699, disc_loss = 0.013380889499816915
Trained batch 87 in epoch 1, gen_loss = 1.1230091879313642, disc_loss = 0.01326370195866647
Trained batch 88 in epoch 1, gen_loss = 1.1233516563190502, disc_loss = 0.013149699190987294
Trained batch 89 in epoch 1, gen_loss = 1.1227586938275231, disc_loss = 0.013035055017098784
Trained batch 90 in epoch 1, gen_loss = 1.1225594799597185, disc_loss = 0.012924601623256291
Trained batch 91 in epoch 1, gen_loss = 1.1220791087202404, disc_loss = 0.012824541102062263
Trained batch 92 in epoch 1, gen_loss = 1.1224643472702271, disc_loss = 0.012735139375792877
Trained batch 93 in epoch 1, gen_loss = 1.122741975048755, disc_loss = 0.01264813250832339
Trained batch 94 in epoch 1, gen_loss = 1.1228950343633952, disc_loss = 0.012553749853549035
Trained batch 95 in epoch 1, gen_loss = 1.122526924436291, disc_loss = 0.012457252623183498
Trained batch 96 in epoch 1, gen_loss = 1.1226417471453087, disc_loss = 0.01237560272187993
Trained batch 97 in epoch 1, gen_loss = 1.1225944325631978, disc_loss = 0.012302649955797409
Trained batch 98 in epoch 1, gen_loss = 1.1226990060372786, disc_loss = 0.012219454996720558
Trained batch 99 in epoch 1, gen_loss = 1.122711792588234, disc_loss = 0.012135281066875905
Trained batch 100 in epoch 1, gen_loss = 1.122483752151527, disc_loss = 0.012049120903881912
Trained batch 101 in epoch 1, gen_loss = 1.1222320871025908, disc_loss = 0.011969868684936241
Trained batch 102 in epoch 1, gen_loss = 1.1219742512239994, disc_loss = 0.0118916024729718
Trained batch 103 in epoch 1, gen_loss = 1.1218336528310409, disc_loss = 0.011817432624341633
Trained batch 104 in epoch 1, gen_loss = 1.1217941562334697, disc_loss = 0.011747106162476397
Trained batch 105 in epoch 1, gen_loss = 1.121510291436933, disc_loss = 0.01167755503479813
Trained batch 106 in epoch 1, gen_loss = 1.1214834412681722, disc_loss = 0.011602913862895047
Trained batch 107 in epoch 1, gen_loss = 1.1212388117004324, disc_loss = 0.011528833691651622
Trained batch 108 in epoch 1, gen_loss = 1.1213651660385482, disc_loss = 0.011456532863079818
Trained batch 109 in epoch 1, gen_loss = 1.1209767433730038, disc_loss = 0.011378255050460046
Trained batch 110 in epoch 1, gen_loss = 1.1207340649656348, disc_loss = 0.011298869616930952
Trained batch 111 in epoch 1, gen_loss = 1.1204733758100442, disc_loss = 0.011217301744701607
Trained batch 112 in epoch 1, gen_loss = 1.120197306164598, disc_loss = 0.011138441585070264
Trained batch 113 in epoch 1, gen_loss = 1.1198881252815849, disc_loss = 0.01106149391189479
Trained batch 114 in epoch 1, gen_loss = 1.119786364617555, disc_loss = 0.01098380583419424
Trained batch 115 in epoch 1, gen_loss = 1.1197812901488666, disc_loss = 0.010909541263164759
Trained batch 116 in epoch 1, gen_loss = 1.119755575290093, disc_loss = 0.01084541499367955
Trained batch 117 in epoch 1, gen_loss = 1.119821888410439, disc_loss = 0.01077891951545252
Trained batch 118 in epoch 1, gen_loss = 1.1200976006123198, disc_loss = 0.010716207253065806
Trained batch 119 in epoch 1, gen_loss = 1.1205434218049048, disc_loss = 0.010654018646649395
Trained batch 120 in epoch 1, gen_loss = 1.1204854422364354, disc_loss = 0.010588829444090196
Trained batch 121 in epoch 1, gen_loss = 1.1208430494441362, disc_loss = 0.010529164423341633
Trained batch 122 in epoch 1, gen_loss = 1.121029551920852, disc_loss = 0.01046482246270691
Trained batch 123 in epoch 1, gen_loss = 1.120993364722498, disc_loss = 0.010398578927702
Trained batch 124 in epoch 1, gen_loss = 1.1204665341377258, disc_loss = 0.010334120651707053
Trained batch 125 in epoch 1, gen_loss = 1.1201353938806624, disc_loss = 0.010268727725829988
Trained batch 126 in epoch 1, gen_loss = 1.1201183659823861, disc_loss = 0.010208001059634009
Trained batch 127 in epoch 1, gen_loss = 1.1202735076658428, disc_loss = 0.010149183857720345
Trained batch 128 in epoch 1, gen_loss = 1.1203784429749777, disc_loss = 0.010090058091883512
Trained batch 129 in epoch 1, gen_loss = 1.119844957956901, disc_loss = 0.010033833968023268
Trained batch 130 in epoch 1, gen_loss = 1.1199416773009847, disc_loss = 0.009987026179308882
Trained batch 131 in epoch 1, gen_loss = 1.119685764114062, disc_loss = 0.009943221688665675
Trained batch 132 in epoch 1, gen_loss = 1.1196648155836235, disc_loss = 0.009902741024760823
Trained batch 133 in epoch 1, gen_loss = 1.1196523455541525, disc_loss = 0.009861999761257598
Trained batch 134 in epoch 1, gen_loss = 1.1193134948059364, disc_loss = 0.009825512166652414
Trained batch 135 in epoch 1, gen_loss = 1.1190653149695957, disc_loss = 0.009795510230640717
Trained batch 136 in epoch 1, gen_loss = 1.1189275697199967, disc_loss = 0.009771369526801753
Trained batch 137 in epoch 1, gen_loss = 1.119046458731527, disc_loss = 0.009748513499895731
Trained batch 138 in epoch 1, gen_loss = 1.119032162127735, disc_loss = 0.009719207293266873
Trained batch 139 in epoch 1, gen_loss = 1.1189975410699844, disc_loss = 0.009681358667356628
Trained batch 140 in epoch 1, gen_loss = 1.1185964519250478, disc_loss = 0.009637121345636481
Trained batch 141 in epoch 1, gen_loss = 1.1184528020905777, disc_loss = 0.009592360600461843
Trained batch 142 in epoch 1, gen_loss = 1.1185041069984436, disc_loss = 0.009546262348865296
Trained batch 143 in epoch 1, gen_loss = 1.1182107176217768, disc_loss = 0.009495626278092258
Trained batch 144 in epoch 1, gen_loss = 1.1179020795328865, disc_loss = 0.00944301980098003
Trained batch 145 in epoch 1, gen_loss = 1.1175792776558497, disc_loss = 0.009391053776696886
Trained batch 146 in epoch 1, gen_loss = 1.117629593326932, disc_loss = 0.009342676759570786
Trained batch 147 in epoch 1, gen_loss = 1.1175150142328159, disc_loss = 0.00929615496283372
Trained batch 148 in epoch 1, gen_loss = 1.1174074239378808, disc_loss = 0.009252797281713344
Trained batch 149 in epoch 1, gen_loss = 1.1172538880507152, disc_loss = 0.009212713175608466
Trained batch 150 in epoch 1, gen_loss = 1.1171275902268112, disc_loss = 0.00917136009754798
Trained batch 151 in epoch 1, gen_loss = 1.117043661051675, disc_loss = 0.009129480341614812
Trained batch 152 in epoch 1, gen_loss = 1.1171038583213209, disc_loss = 0.00908912955615913
Trained batch 153 in epoch 1, gen_loss = 1.1169547767608197, disc_loss = 0.009046106672597832
Trained batch 154 in epoch 1, gen_loss = 1.1168709866462214, disc_loss = 0.009002865099107787
Trained batch 155 in epoch 1, gen_loss = 1.116210943995378, disc_loss = 0.008957840635841235
Trained batch 156 in epoch 1, gen_loss = 1.1159716764832759, disc_loss = 0.008913539186161556
Trained batch 157 in epoch 1, gen_loss = 1.116280424821226, disc_loss = 0.008872637444889009
Trained batch 158 in epoch 1, gen_loss = 1.1160645601134631, disc_loss = 0.008828199576182326
Trained batch 159 in epoch 1, gen_loss = 1.1160437908023595, disc_loss = 0.008784655621275306
Trained batch 160 in epoch 1, gen_loss = 1.1158878370101408, disc_loss = 0.008743757315512215
Trained batch 161 in epoch 1, gen_loss = 1.1157254859989072, disc_loss = 0.008701483616289212
Trained batch 162 in epoch 1, gen_loss = 1.1155072264144756, disc_loss = 0.008659116655982391
Trained batch 163 in epoch 1, gen_loss = 1.1156010580498998, disc_loss = 0.008622038569272973
Trained batch 164 in epoch 1, gen_loss = 1.1155551538322912, disc_loss = 0.008590833130857033
Trained batch 165 in epoch 1, gen_loss = 1.1152512169027904, disc_loss = 0.008562539455183524
Trained batch 166 in epoch 1, gen_loss = 1.1151763175775904, disc_loss = 0.008535755355563572
Trained batch 167 in epoch 1, gen_loss = 1.1155279779008456, disc_loss = 0.008511344082459496
Trained batch 168 in epoch 1, gen_loss = 1.1152404529103161, disc_loss = 0.00848452240495926
Trained batch 169 in epoch 1, gen_loss = 1.1151368789813099, disc_loss = 0.008461298512103145
Trained batch 170 in epoch 1, gen_loss = 1.115028266669714, disc_loss = 0.008436790207940104
Trained batch 171 in epoch 1, gen_loss = 1.114761386846387, disc_loss = 0.008407931625274508
Trained batch 172 in epoch 1, gen_loss = 1.1145848094383417, disc_loss = 0.008373722047114347
Trained batch 173 in epoch 1, gen_loss = 1.1145913117918476, disc_loss = 0.008337544104025495
Trained batch 174 in epoch 1, gen_loss = 1.1144353522573198, disc_loss = 0.008302939614680196
Trained batch 175 in epoch 1, gen_loss = 1.114466035569256, disc_loss = 0.00827044591013956
Trained batch 176 in epoch 1, gen_loss = 1.114489781317738, disc_loss = 0.008234081812871167
Trained batch 177 in epoch 1, gen_loss = 1.1145820667904414, disc_loss = 0.008198713324571635
Trained batch 178 in epoch 1, gen_loss = 1.1143595756099212, disc_loss = 0.008163498372474279
Trained batch 179 in epoch 1, gen_loss = 1.114164091149966, disc_loss = 0.00812758174401501
Trained batch 180 in epoch 1, gen_loss = 1.114147778044748, disc_loss = 0.008096275536616163
Trained batch 181 in epoch 1, gen_loss = 1.1138459932018112, disc_loss = 0.008061232122689855
Trained batch 182 in epoch 1, gen_loss = 1.113772384781655, disc_loss = 0.008028444977187108
Trained batch 183 in epoch 1, gen_loss = 1.1136891443444334, disc_loss = 0.007996727305631477
Trained batch 184 in epoch 1, gen_loss = 1.1136614248559282, disc_loss = 0.007962344909665754
Trained batch 185 in epoch 1, gen_loss = 1.1136926076104563, disc_loss = 0.007928237616289807
Trained batch 186 in epoch 1, gen_loss = 1.1137358552631846, disc_loss = 0.00789408030033231
Trained batch 187 in epoch 1, gen_loss = 1.113475813193524, disc_loss = 0.00786614649621968
Trained batch 188 in epoch 1, gen_loss = 1.1131472988103432, disc_loss = 0.007834582408476207
Trained batch 189 in epoch 1, gen_loss = 1.1129859695309088, disc_loss = 0.007802437387382318
Trained batch 190 in epoch 1, gen_loss = 1.113006779348663, disc_loss = 0.007771270631822265
Trained batch 191 in epoch 1, gen_loss = 1.1127762679631512, disc_loss = 0.00773814381621681
Trained batch 192 in epoch 1, gen_loss = 1.112505612286879, disc_loss = 0.007706817926554289
Trained batch 193 in epoch 1, gen_loss = 1.1124832811429328, disc_loss = 0.007674642718521897
Trained batch 194 in epoch 1, gen_loss = 1.1123737552227118, disc_loss = 0.007642317286286599
Trained batch 195 in epoch 1, gen_loss = 1.112166409285701, disc_loss = 0.007610257543333597
Trained batch 196 in epoch 1, gen_loss = 1.1118596855759015, disc_loss = 0.007579353592490901
Trained batch 197 in epoch 1, gen_loss = 1.111654679281543, disc_loss = 0.007548318194540575
Trained batch 198 in epoch 1, gen_loss = 1.1115825352956301, disc_loss = 0.007517670605907301
Trained batch 199 in epoch 1, gen_loss = 1.1113890883326532, disc_loss = 0.007486237207776867
Trained batch 200 in epoch 1, gen_loss = 1.1116520121916016, disc_loss = 0.007458528141787655
Trained batch 201 in epoch 1, gen_loss = 1.1117512356526782, disc_loss = 0.00743306384567116
Trained batch 202 in epoch 1, gen_loss = 1.111699816335011, disc_loss = 0.007406475239782021
Trained batch 203 in epoch 1, gen_loss = 1.1114929052544575, disc_loss = 0.007376245312579889
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.110757827758789, disc_loss = 0.0015380389522761106
Trained batch 1 in epoch 2, gen_loss = 1.1016009449958801, disc_loss = 0.0014491453766822815
Trained batch 2 in epoch 2, gen_loss = 1.0924295981725056, disc_loss = 0.0014434991559634607
Trained batch 3 in epoch 2, gen_loss = 1.0866678357124329, disc_loss = 0.0014399235078599304
Trained batch 4 in epoch 2, gen_loss = 1.1023752212524414, disc_loss = 0.0017005486181005836
Trained batch 5 in epoch 2, gen_loss = 1.1009889841079712, disc_loss = 0.0018140710308216512
Trained batch 6 in epoch 2, gen_loss = 1.1048061677387782, disc_loss = 0.0017963553047073738
Trained batch 7 in epoch 2, gen_loss = 1.106070727109909, disc_loss = 0.0017855340847745538
Trained batch 8 in epoch 2, gen_loss = 1.1026369995541043, disc_loss = 0.0017189351298535864
Trained batch 9 in epoch 2, gen_loss = 1.1030559420585633, disc_loss = 0.0017183913965709507
Trained batch 10 in epoch 2, gen_loss = 1.097962737083435, disc_loss = 0.0017436171395026824
Trained batch 11 in epoch 2, gen_loss = 1.097314049800237, disc_loss = 0.0017789022434347619
Trained batch 12 in epoch 2, gen_loss = 1.0948682840053852, disc_loss = 0.0017847918027725357
Trained batch 13 in epoch 2, gen_loss = 1.0917786359786987, disc_loss = 0.0017690044894282306
Trained batch 14 in epoch 2, gen_loss = 1.091244061787923, disc_loss = 0.0017374326552574834
Trained batch 15 in epoch 2, gen_loss = 1.0908594653010368, disc_loss = 0.001708190429781098
Trained batch 16 in epoch 2, gen_loss = 1.0901670946794397, disc_loss = 0.0016805425847825758
Trained batch 17 in epoch 2, gen_loss = 1.0894291864501104, disc_loss = 0.0016479320086849232
Trained batch 18 in epoch 2, gen_loss = 1.0889405263097662, disc_loss = 0.0016279392324289993
Trained batch 19 in epoch 2, gen_loss = 1.090990924835205, disc_loss = 0.0016614668245892971
Trained batch 20 in epoch 2, gen_loss = 1.091636305763608, disc_loss = 0.0017130888410888257
Trained batch 21 in epoch 2, gen_loss = 1.0916064002297141, disc_loss = 0.0017501640461639247
Trained batch 22 in epoch 2, gen_loss = 1.0921375077703726, disc_loss = 0.0018015727248933652
Trained batch 23 in epoch 2, gen_loss = 1.0926540344953537, disc_loss = 0.0018468879328186933
Trained batch 24 in epoch 2, gen_loss = 1.0928126335144044, disc_loss = 0.0018851664336398243
Trained batch 25 in epoch 2, gen_loss = 1.0932403298524709, disc_loss = 0.0019309258742186313
Trained batch 26 in epoch 2, gen_loss = 1.0930926005045574, disc_loss = 0.001989416954866438
Trained batch 27 in epoch 2, gen_loss = 1.0928467810153961, disc_loss = 0.002068691042950377
Trained batch 28 in epoch 2, gen_loss = 1.0918911942120255, disc_loss = 0.002168965385423909
Trained batch 29 in epoch 2, gen_loss = 1.0928177913029988, disc_loss = 0.002296223867839823
Trained batch 30 in epoch 2, gen_loss = 1.0918828518159929, disc_loss = 0.0024415994431042382
Trained batch 31 in epoch 2, gen_loss = 1.0928646624088287, disc_loss = 0.0025910686126735527
Trained batch 32 in epoch 2, gen_loss = 1.0926563089544123, disc_loss = 0.0027113881025632672
Trained batch 33 in epoch 2, gen_loss = 1.0923268654767204, disc_loss = 0.0027907697983798295
Trained batch 34 in epoch 2, gen_loss = 1.0927405595779418, disc_loss = 0.002856767061166465
Trained batch 35 in epoch 2, gen_loss = 1.0939405825403001, disc_loss = 0.0029183024210700146
Trained batch 36 in epoch 2, gen_loss = 1.0934510069924432, disc_loss = 0.002934713033027947
Trained batch 37 in epoch 2, gen_loss = 1.091518355043311, disc_loss = 0.0029624079164166594
Trained batch 38 in epoch 2, gen_loss = 1.092031384125734, disc_loss = 0.002983863504293064
Trained batch 39 in epoch 2, gen_loss = 1.0919084757566453, disc_loss = 0.0029906557785579933
Trained batch 40 in epoch 2, gen_loss = 1.091348697499531, disc_loss = 0.002980607456709372
Trained batch 41 in epoch 2, gen_loss = 1.0916827150753565, disc_loss = 0.002960261686461135
Trained batch 42 in epoch 2, gen_loss = 1.0922172152718832, disc_loss = 0.002924114706666144
Trained batch 43 in epoch 2, gen_loss = 1.0916639864444733, disc_loss = 0.002884142553243278
Trained batch 44 in epoch 2, gen_loss = 1.0928455538219877, disc_loss = 0.0028487664388699664
Trained batch 45 in epoch 2, gen_loss = 1.092378336450328, disc_loss = 0.002810260217697562
Trained batch 46 in epoch 2, gen_loss = 1.0917157695648518, disc_loss = 0.0027755185530738947
Trained batch 47 in epoch 2, gen_loss = 1.091131255030632, disc_loss = 0.002754535344138276
Trained batch 48 in epoch 2, gen_loss = 1.0921891660106426, disc_loss = 0.0027525079156253108
Trained batch 49 in epoch 2, gen_loss = 1.0917416858673095, disc_loss = 0.0027474138024263083
Trained batch 50 in epoch 2, gen_loss = 1.0911723211699842, disc_loss = 0.0027590086569498273
Trained batch 51 in epoch 2, gen_loss = 1.0904146983073308, disc_loss = 0.002781590901297302
Trained batch 52 in epoch 2, gen_loss = 1.0908611697970696, disc_loss = 0.0027996690324419795
Trained batch 53 in epoch 2, gen_loss = 1.090596784044195, disc_loss = 0.002785593661462405
Trained batch 54 in epoch 2, gen_loss = 1.090410676869479, disc_loss = 0.002758938503790308
Trained batch 55 in epoch 2, gen_loss = 1.0900326775653022, disc_loss = 0.002736947763228922
Trained batch 56 in epoch 2, gen_loss = 1.0903025028998392, disc_loss = 0.002729234397983211
Trained batch 57 in epoch 2, gen_loss = 1.0896100648518265, disc_loss = 0.0027143806700819523
Trained batch 58 in epoch 2, gen_loss = 1.089189901190289, disc_loss = 0.0026890095264129974
Trained batch 59 in epoch 2, gen_loss = 1.0882161657015483, disc_loss = 0.002666421323859443
Trained batch 60 in epoch 2, gen_loss = 1.0884463591653792, disc_loss = 0.00265199355170375
Trained batch 61 in epoch 2, gen_loss = 1.08875346760596, disc_loss = 0.002633485139437741
Trained batch 62 in epoch 2, gen_loss = 1.0881810850567288, disc_loss = 0.002617077281077703
Trained batch 63 in epoch 2, gen_loss = 1.0881672967225313, disc_loss = 0.0025948125548893586
Trained batch 64 in epoch 2, gen_loss = 1.0883236573292658, disc_loss = 0.0025785005651414394
Trained batch 65 in epoch 2, gen_loss = 1.0887828649896565, disc_loss = 0.002557048096081637
Trained batch 66 in epoch 2, gen_loss = 1.0893554207104355, disc_loss = 0.0025391818611507316
Trained batch 67 in epoch 2, gen_loss = 1.0894352180116318, disc_loss = 0.00251915685572278
Trained batch 68 in epoch 2, gen_loss = 1.089352364125459, disc_loss = 0.0024990851187781577
Trained batch 69 in epoch 2, gen_loss = 1.0892606207302638, disc_loss = 0.00248046024103782
Trained batch 70 in epoch 2, gen_loss = 1.0892834109319767, disc_loss = 0.0024664328256490784
Trained batch 71 in epoch 2, gen_loss = 1.0895804249578052, disc_loss = 0.0024549587429242414
Trained batch 72 in epoch 2, gen_loss = 1.0896725083050662, disc_loss = 0.002447845167097674
Trained batch 73 in epoch 2, gen_loss = 1.0896267327102456, disc_loss = 0.002439263356987991
Trained batch 74 in epoch 2, gen_loss = 1.0894210243225098, disc_loss = 0.002431594738736749
Trained batch 75 in epoch 2, gen_loss = 1.08973785450584, disc_loss = 0.0024209762586427756
Trained batch 76 in epoch 2, gen_loss = 1.0901602661454832, disc_loss = 0.0024082074425630755
Trained batch 77 in epoch 2, gen_loss = 1.0894170265931349, disc_loss = 0.0023971725798522434
Trained batch 78 in epoch 2, gen_loss = 1.0892853103106535, disc_loss = 0.002385409165739636
Trained batch 79 in epoch 2, gen_loss = 1.0890096679329873, disc_loss = 0.002370918306405656
Trained batch 80 in epoch 2, gen_loss = 1.0890130275561485, disc_loss = 0.0023577340079448473
Trained batch 81 in epoch 2, gen_loss = 1.0888355432487116, disc_loss = 0.002346289662144533
Trained batch 82 in epoch 2, gen_loss = 1.0882481652570057, disc_loss = 0.0023347063534275955
Trained batch 83 in epoch 2, gen_loss = 1.0880609495299203, disc_loss = 0.002327477388981996
Trained batch 84 in epoch 2, gen_loss = 1.0877295858719769, disc_loss = 0.0023176867487456868
Trained batch 85 in epoch 2, gen_loss = 1.0883083953413852, disc_loss = 0.0023097546600606726
Trained batch 86 in epoch 2, gen_loss = 1.088201056951764, disc_loss = 0.002306044603505268
Trained batch 87 in epoch 2, gen_loss = 1.0884292301806537, disc_loss = 0.002301702996853485
Trained batch 88 in epoch 2, gen_loss = 1.0883337955796317, disc_loss = 0.0022958924096559037
Trained batch 89 in epoch 2, gen_loss = 1.0879663626352947, disc_loss = 0.0022942568317780064
Trained batch 90 in epoch 2, gen_loss = 1.0884099687848772, disc_loss = 0.002289201711191908
Trained batch 91 in epoch 2, gen_loss = 1.088835050230441, disc_loss = 0.0022825043415650725
Trained batch 92 in epoch 2, gen_loss = 1.0882767451706754, disc_loss = 0.00227711589441144
Trained batch 93 in epoch 2, gen_loss = 1.0883179116756359, disc_loss = 0.0022759953293295457
Trained batch 94 in epoch 2, gen_loss = 1.0884330460899754, disc_loss = 0.002280579405640693
Trained batch 95 in epoch 2, gen_loss = 1.0889740797380607, disc_loss = 0.002283434908652756
Trained batch 96 in epoch 2, gen_loss = 1.0892652113413073, disc_loss = 0.002282260399859053
Trained batch 97 in epoch 2, gen_loss = 1.0895167078290666, disc_loss = 0.00227981948944721
Trained batch 98 in epoch 2, gen_loss = 1.0894211663140192, disc_loss = 0.0022821954388002105
Trained batch 99 in epoch 2, gen_loss = 1.0895543467998505, disc_loss = 0.002290341070620343
Trained batch 100 in epoch 2, gen_loss = 1.0896846492691796, disc_loss = 0.002291771983220657
Trained batch 101 in epoch 2, gen_loss = 1.0893049777722825, disc_loss = 0.0022910537355689004
Trained batch 102 in epoch 2, gen_loss = 1.089554358454584, disc_loss = 0.0022942754993830056
Trained batch 103 in epoch 2, gen_loss = 1.0890933527396276, disc_loss = 0.002296633211349567
Trained batch 104 in epoch 2, gen_loss = 1.0890443949472337, disc_loss = 0.002294020708428607
Trained batch 105 in epoch 2, gen_loss = 1.089239094617232, disc_loss = 0.002290034590877663
Trained batch 106 in epoch 2, gen_loss = 1.089376858461683, disc_loss = 0.0022829210801293778
Trained batch 107 in epoch 2, gen_loss = 1.089264498816596, disc_loss = 0.0022740964325041408
Trained batch 108 in epoch 2, gen_loss = 1.0891408012547623, disc_loss = 0.0022648148230114662
Trained batch 109 in epoch 2, gen_loss = 1.0897797020998867, disc_loss = 0.0022615607976066796
Trained batch 110 in epoch 2, gen_loss = 1.0899217085795359, disc_loss = 0.002261014170692982
Trained batch 111 in epoch 2, gen_loss = 1.0895898810454778, disc_loss = 0.0022590740679463905
Trained batch 112 in epoch 2, gen_loss = 1.0897062605461187, disc_loss = 0.002254703961955631
Trained batch 113 in epoch 2, gen_loss = 1.0896189861130297, disc_loss = 0.0022511763208169946
Trained batch 114 in epoch 2, gen_loss = 1.0898675566134246, disc_loss = 0.0022473659204400105
Trained batch 115 in epoch 2, gen_loss = 1.0899815826580441, disc_loss = 0.002243841705233629
Trained batch 116 in epoch 2, gen_loss = 1.089994981757596, disc_loss = 0.0022422103529684562
Trained batch 117 in epoch 2, gen_loss = 1.0900881603612738, disc_loss = 0.0022445899114738833
Trained batch 118 in epoch 2, gen_loss = 1.0901435232963883, disc_loss = 0.0022486684542587575
Trained batch 119 in epoch 2, gen_loss = 1.0899886578321456, disc_loss = 0.0022509605643184234
Trained batch 120 in epoch 2, gen_loss = 1.0903237939866122, disc_loss = 0.0022544191903934993
Trained batch 121 in epoch 2, gen_loss = 1.090149690870379, disc_loss = 0.0022549889790901886
Trained batch 122 in epoch 2, gen_loss = 1.0901006615258815, disc_loss = 0.0022529353296793088
Trained batch 123 in epoch 2, gen_loss = 1.0902511842789189, disc_loss = 0.002248959370791131
Trained batch 124 in epoch 2, gen_loss = 1.0903632431030272, disc_loss = 0.002244294255040586
Trained batch 125 in epoch 2, gen_loss = 1.0905695075080508, disc_loss = 0.0022387573336591087
Trained batch 126 in epoch 2, gen_loss = 1.0901642042820847, disc_loss = 0.0022314044291256215
Trained batch 127 in epoch 2, gen_loss = 1.0902949031442404, disc_loss = 0.002224828422185965
Trained batch 128 in epoch 2, gen_loss = 1.0902657324029494, disc_loss = 0.0022156594227277495
Trained batch 129 in epoch 2, gen_loss = 1.0903931782795833, disc_loss = 0.002206591141517632
Trained batch 130 in epoch 2, gen_loss = 1.0902923309166013, disc_loss = 0.002197658876845798
Trained batch 131 in epoch 2, gen_loss = 1.0905287690234906, disc_loss = 0.0021915590826238535
Trained batch 132 in epoch 2, gen_loss = 1.0904290711969362, disc_loss = 0.0021852560173299977
Trained batch 133 in epoch 2, gen_loss = 1.0906458808414972, disc_loss = 0.002180139846932977
Trained batch 134 in epoch 2, gen_loss = 1.0907593532844826, disc_loss = 0.002174355357850867
Trained batch 135 in epoch 2, gen_loss = 1.0907226616845411, disc_loss = 0.0021733897387200747
Trained batch 136 in epoch 2, gen_loss = 1.0903876497797722, disc_loss = 0.0021740084872615053
Trained batch 137 in epoch 2, gen_loss = 1.09023439279501, disc_loss = 0.002175623200921531
Trained batch 138 in epoch 2, gen_loss = 1.0904390648972215, disc_loss = 0.0021795811133271605
Trained batch 139 in epoch 2, gen_loss = 1.09031691466059, disc_loss = 0.0021805989131930153
Trained batch 140 in epoch 2, gen_loss = 1.0900864406680384, disc_loss = 0.0021815196510259036
Trained batch 141 in epoch 2, gen_loss = 1.0902126213194618, disc_loss = 0.002179984981358104
Trained batch 142 in epoch 2, gen_loss = 1.0904183504464744, disc_loss = 0.0021801278788036297
Trained batch 143 in epoch 2, gen_loss = 1.0901545708378155, disc_loss = 0.002179630331132406
Trained batch 144 in epoch 2, gen_loss = 1.0900434222714654, disc_loss = 0.0021819297938832434
Trained batch 145 in epoch 2, gen_loss = 1.0904299649473739, disc_loss = 0.002185847646116649
Trained batch 146 in epoch 2, gen_loss = 1.0903741210496345, disc_loss = 0.002188606508437316
Trained batch 147 in epoch 2, gen_loss = 1.0904370642997123, disc_loss = 0.0021888549302742388
Trained batch 148 in epoch 2, gen_loss = 1.0902841939222092, disc_loss = 0.0021848006083336254
Trained batch 149 in epoch 2, gen_loss = 1.0900887195269267, disc_loss = 0.0021785270888358354
Trained batch 150 in epoch 2, gen_loss = 1.089931954611216, disc_loss = 0.0021712202501686794
Trained batch 151 in epoch 2, gen_loss = 1.0898725523760444, disc_loss = 0.0021629399611571756
Trained batch 152 in epoch 2, gen_loss = 1.0897263280706468, disc_loss = 0.0021554550693942587
Trained batch 153 in epoch 2, gen_loss = 1.0898278703937283, disc_loss = 0.002150127515665485
Trained batch 154 in epoch 2, gen_loss = 1.0894893723149452, disc_loss = 0.002144826838611475
Trained batch 155 in epoch 2, gen_loss = 1.089381327231725, disc_loss = 0.002140714683590863
Trained batch 156 in epoch 2, gen_loss = 1.0894784175666274, disc_loss = 0.0021366138410885004
Trained batch 157 in epoch 2, gen_loss = 1.0894178695316556, disc_loss = 0.002132531674357744
Trained batch 158 in epoch 2, gen_loss = 1.0896459577968285, disc_loss = 0.00212846667639056
Trained batch 159 in epoch 2, gen_loss = 1.0894139885902405, disc_loss = 0.0021229700312687784
Trained batch 160 in epoch 2, gen_loss = 1.0895252331443455, disc_loss = 0.002117534936333411
Trained batch 161 in epoch 2, gen_loss = 1.0894226211088676, disc_loss = 0.0021103155593686727
Trained batch 162 in epoch 2, gen_loss = 1.0895996978677855, disc_loss = 0.0021067914785817266
Trained batch 163 in epoch 2, gen_loss = 1.0896541788810636, disc_loss = 0.0021043367202609503
Trained batch 164 in epoch 2, gen_loss = 1.0896870468602036, disc_loss = 0.0021028221373192288
Trained batch 165 in epoch 2, gen_loss = 1.0896252451172794, disc_loss = 0.00210062751871904
Trained batch 166 in epoch 2, gen_loss = 1.0895784572212996, disc_loss = 0.002095612371061555
Trained batch 167 in epoch 2, gen_loss = 1.0895142895834786, disc_loss = 0.002090161694684953
Trained batch 168 in epoch 2, gen_loss = 1.0895886816216644, disc_loss = 0.0020840031944887615
Trained batch 169 in epoch 2, gen_loss = 1.089348554611206, disc_loss = 0.0020776340922833802
Trained batch 170 in epoch 2, gen_loss = 1.089196803276999, disc_loss = 0.0020759358698480396
Trained batch 171 in epoch 2, gen_loss = 1.0889548770217008, disc_loss = 0.0020733772205773653
Trained batch 172 in epoch 2, gen_loss = 1.088743058243239, disc_loss = 0.0020678721986054256
Trained batch 173 in epoch 2, gen_loss = 1.088380344982805, disc_loss = 0.0020621299185661665
Trained batch 174 in epoch 2, gen_loss = 1.088193919999259, disc_loss = 0.002055802710487374
Trained batch 175 in epoch 2, gen_loss = 1.0881853117184206, disc_loss = 0.0020498101214550184
Trained batch 176 in epoch 2, gen_loss = 1.088435690281755, disc_loss = 0.0020450472135865
Trained batch 177 in epoch 2, gen_loss = 1.0885596482941273, disc_loss = 0.0020397585127345714
Trained batch 178 in epoch 2, gen_loss = 1.0887221510849852, disc_loss = 0.002034419635700988
Trained batch 179 in epoch 2, gen_loss = 1.0884952286879221, disc_loss = 0.0020283350779209284
Trained batch 180 in epoch 2, gen_loss = 1.0883928194889048, disc_loss = 0.0020236158209662493
Trained batch 181 in epoch 2, gen_loss = 1.0882952953432943, disc_loss = 0.002019440201315824
Trained batch 182 in epoch 2, gen_loss = 1.0881885420429251, disc_loss = 0.002017698307328252
Trained batch 183 in epoch 2, gen_loss = 1.0881429670945457, disc_loss = 0.0020154469688271133
Trained batch 184 in epoch 2, gen_loss = 1.088195320722219, disc_loss = 0.0020144776560718546
Trained batch 185 in epoch 2, gen_loss = 1.0881636431140285, disc_loss = 0.002011248052635941
Trained batch 186 in epoch 2, gen_loss = 1.0880787837951578, disc_loss = 0.002007173412892828
Trained batch 187 in epoch 2, gen_loss = 1.0883726458600227, disc_loss = 0.0020040410553461853
Trained batch 188 in epoch 2, gen_loss = 1.0884292775360995, disc_loss = 0.002001969897676082
Trained batch 189 in epoch 2, gen_loss = 1.0883741008607966, disc_loss = 0.001999252670640616
Trained batch 190 in epoch 2, gen_loss = 1.0882162367486206, disc_loss = 0.0019981427500950885
Trained batch 191 in epoch 2, gen_loss = 1.0882610709716876, disc_loss = 0.001999500838185971
Trained batch 192 in epoch 2, gen_loss = 1.087812255083588, disc_loss = 0.001999198428326204
Trained batch 193 in epoch 2, gen_loss = 1.0878312704489403, disc_loss = 0.0019969953369282033
Trained batch 194 in epoch 2, gen_loss = 1.0878675032884646, disc_loss = 0.001993613040003066
Trained batch 195 in epoch 2, gen_loss = 1.0879970594328277, disc_loss = 0.0019915287628798385
Trained batch 196 in epoch 2, gen_loss = 1.0880605133656922, disc_loss = 0.0019879907973555065
Trained batch 197 in epoch 2, gen_loss = 1.087962755049118, disc_loss = 0.0019846155121216943
Trained batch 198 in epoch 2, gen_loss = 1.0879914317298773, disc_loss = 0.0019807710894968493
Trained batch 199 in epoch 2, gen_loss = 1.0878315722942353, disc_loss = 0.00197644155996386
Trained batch 200 in epoch 2, gen_loss = 1.0879310654170478, disc_loss = 0.001973333971839009
Trained batch 201 in epoch 2, gen_loss = 1.0877782873588033, disc_loss = 0.0019688703970393477
Trained batch 202 in epoch 2, gen_loss = 1.0874541839355318, disc_loss = 0.0019647908142396233
Trained batch 203 in epoch 2, gen_loss = 1.087400353422352, disc_loss = 0.001960332208089348
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.097069501876831, disc_loss = 0.0009537891601212323
Trained batch 1 in epoch 3, gen_loss = 1.061892807483673, disc_loss = 0.0008164515311364084
Trained batch 2 in epoch 3, gen_loss = 1.054456114768982, disc_loss = 0.0007920204855812093
Trained batch 3 in epoch 3, gen_loss = 1.059414952993393, disc_loss = 0.0007811206305632368
Trained batch 4 in epoch 3, gen_loss = 1.0534234762191772, disc_loss = 0.0007616146351210773
Trained batch 5 in epoch 3, gen_loss = 1.0649492939313252, disc_loss = 0.0007989089062903076
Trained batch 6 in epoch 3, gen_loss = 1.0730756691523962, disc_loss = 0.0009687611350922712
Trained batch 7 in epoch 3, gen_loss = 1.0731585919857025, disc_loss = 0.0011114476874354295
Trained batch 8 in epoch 3, gen_loss = 1.0759394036398993, disc_loss = 0.0011862552168572114
Trained batch 9 in epoch 3, gen_loss = 1.0813110709190368, disc_loss = 0.0011993334686849267
Trained batch 10 in epoch 3, gen_loss = 1.08056809685447, disc_loss = 0.0011923738956366751
Trained batch 11 in epoch 3, gen_loss = 1.0804120699564617, disc_loss = 0.0012047244963468984
Trained batch 12 in epoch 3, gen_loss = 1.079244540287898, disc_loss = 0.0012234150602195698
Trained batch 13 in epoch 3, gen_loss = 1.08034428528377, disc_loss = 0.0012667544776507253
Trained batch 14 in epoch 3, gen_loss = 1.0768473784128825, disc_loss = 0.0012834153564957281
Trained batch 15 in epoch 3, gen_loss = 1.0728126019239426, disc_loss = 0.0012839980445278343
Trained batch 16 in epoch 3, gen_loss = 1.0736802816390991, disc_loss = 0.0012817489332519472
Trained batch 17 in epoch 3, gen_loss = 1.07511219713423, disc_loss = 0.0012752958670413743
Trained batch 18 in epoch 3, gen_loss = 1.0750434649618048, disc_loss = 0.0012705121893974904
Trained batch 19 in epoch 3, gen_loss = 1.0766543567180633, disc_loss = 0.0012643416732316837
Trained batch 20 in epoch 3, gen_loss = 1.07486439318884, disc_loss = 0.0012487410567700863
Trained batch 21 in epoch 3, gen_loss = 1.0745906667275862, disc_loss = 0.001234131701163609
Trained batch 22 in epoch 3, gen_loss = 1.0743913909663325, disc_loss = 0.0012232413434464
Trained batch 23 in epoch 3, gen_loss = 1.073323090871175, disc_loss = 0.00121124343907771
Trained batch 24 in epoch 3, gen_loss = 1.0721647500991822, disc_loss = 0.001204791320487857
Trained batch 25 in epoch 3, gen_loss = 1.0713884784625127, disc_loss = 0.0012028087691690486
Trained batch 26 in epoch 3, gen_loss = 1.0709766061217696, disc_loss = 0.001218327204696834
Trained batch 27 in epoch 3, gen_loss = 1.0716345012187958, disc_loss = 0.0012586368622058736
Trained batch 28 in epoch 3, gen_loss = 1.0709797390576066, disc_loss = 0.0013114886462752674
Trained batch 29 in epoch 3, gen_loss = 1.0697090387344361, disc_loss = 0.0013533814849021534
Trained batch 30 in epoch 3, gen_loss = 1.0713631183870378, disc_loss = 0.001392879857561521
Trained batch 31 in epoch 3, gen_loss = 1.0714243650436401, disc_loss = 0.0014162113111524377
Trained batch 32 in epoch 3, gen_loss = 1.0721224438060413, disc_loss = 0.0014225347355629008
Trained batch 33 in epoch 3, gen_loss = 1.0725707306581385, disc_loss = 0.0014203814344535418
Trained batch 34 in epoch 3, gen_loss = 1.0742795535496303, disc_loss = 0.001422683518779065
Trained batch 35 in epoch 3, gen_loss = 1.0743202832010057, disc_loss = 0.0014328147646867568
Trained batch 36 in epoch 3, gen_loss = 1.0743781650388562, disc_loss = 0.0014544876002882783
Trained batch 37 in epoch 3, gen_loss = 1.0749219059944153, disc_loss = 0.00148273909488987
Trained batch 38 in epoch 3, gen_loss = 1.0754768878985674, disc_loss = 0.0015353693519360744
Trained batch 39 in epoch 3, gen_loss = 1.0759840101003646, disc_loss = 0.0016278616909403353
Trained batch 40 in epoch 3, gen_loss = 1.0763656511539366, disc_loss = 0.001743461635736067
Trained batch 41 in epoch 3, gen_loss = 1.0776459461166745, disc_loss = 0.0019006988953887707
Trained batch 42 in epoch 3, gen_loss = 1.078739651413851, disc_loss = 0.002081401878967881
Trained batch 43 in epoch 3, gen_loss = 1.078645253723318, disc_loss = 0.002274485405492173
Trained batch 44 in epoch 3, gen_loss = 1.0784849802652994, disc_loss = 0.00241387450757126
Trained batch 45 in epoch 3, gen_loss = 1.0778829377630483, disc_loss = 0.0024742192497638903
Trained batch 46 in epoch 3, gen_loss = 1.0783733459229166, disc_loss = 0.0024853697284422023
Trained batch 47 in epoch 3, gen_loss = 1.0779651949803035, disc_loss = 0.0024636269445181824
Trained batch 48 in epoch 3, gen_loss = 1.078292384439585, disc_loss = 0.0024305901713479235
Trained batch 49 in epoch 3, gen_loss = 1.0789108848571778, disc_loss = 0.002397420093184337
Trained batch 50 in epoch 3, gen_loss = 1.078715770852332, disc_loss = 0.002365634364632926
Trained batch 51 in epoch 3, gen_loss = 1.0787931887003093, disc_loss = 0.00233867351758258
Trained batch 52 in epoch 3, gen_loss = 1.0785180217814896, disc_loss = 0.0023173901157998392
Trained batch 53 in epoch 3, gen_loss = 1.079897869516302, disc_loss = 0.0023051836749935456
Trained batch 54 in epoch 3, gen_loss = 1.0795115189118818, disc_loss = 0.0023013920300978827
Trained batch 55 in epoch 3, gen_loss = 1.0796510470764977, disc_loss = 0.002304686544188631
Trained batch 56 in epoch 3, gen_loss = 1.0796745973720885, disc_loss = 0.0023219706276186593
Trained batch 57 in epoch 3, gen_loss = 1.0790617527632878, disc_loss = 0.0023493976603213952
Trained batch 58 in epoch 3, gen_loss = 1.0792713145078239, disc_loss = 0.0023830796747815685
Trained batch 59 in epoch 3, gen_loss = 1.0790419538815816, disc_loss = 0.002407035723445006
Trained batch 60 in epoch 3, gen_loss = 1.0791784778970186, disc_loss = 0.0024052802730947123
Trained batch 61 in epoch 3, gen_loss = 1.078865074342297, disc_loss = 0.002382154031018276
Trained batch 62 in epoch 3, gen_loss = 1.0779877617245628, disc_loss = 0.0023546956353894775
Trained batch 63 in epoch 3, gen_loss = 1.0778424106538296, disc_loss = 0.0023286384084713063
Trained batch 64 in epoch 3, gen_loss = 1.0770643087533804, disc_loss = 0.0023065429467421313
Trained batch 65 in epoch 3, gen_loss = 1.077862712469968, disc_loss = 0.002291538488035175
Trained batch 66 in epoch 3, gen_loss = 1.078531587301795, disc_loss = 0.002279561935618186
Trained batch 67 in epoch 3, gen_loss = 1.0785107191871195, disc_loss = 0.002267006262520547
Trained batch 68 in epoch 3, gen_loss = 1.0776994280193164, disc_loss = 0.002249925884931092
Trained batch 69 in epoch 3, gen_loss = 1.0781580465180534, disc_loss = 0.0022414688619651966
Trained batch 70 in epoch 3, gen_loss = 1.0781263549562912, disc_loss = 0.0022343743713834968
Trained batch 71 in epoch 3, gen_loss = 1.0785889973243077, disc_loss = 0.0022260639024251658
Trained batch 72 in epoch 3, gen_loss = 1.078430763662678, disc_loss = 0.002212133861389266
Trained batch 73 in epoch 3, gen_loss = 1.078238980190174, disc_loss = 0.0021950799344120095
Trained batch 74 in epoch 3, gen_loss = 1.0785071531931558, disc_loss = 0.002177764595641444
Trained batch 75 in epoch 3, gen_loss = 1.0787285346733897, disc_loss = 0.002159581096891902
Trained batch 76 in epoch 3, gen_loss = 1.0779838267858926, disc_loss = 0.002144604204706364
Trained batch 77 in epoch 3, gen_loss = 1.077018222747705, disc_loss = 0.0021310700939442865
Trained batch 78 in epoch 3, gen_loss = 1.0769216727606858, disc_loss = 0.002119497612672799
Trained batch 79 in epoch 3, gen_loss = 1.0772157534956932, disc_loss = 0.0021134309863555245
Trained batch 80 in epoch 3, gen_loss = 1.077109897578204, disc_loss = 0.0021075966141336127
Trained batch 81 in epoch 3, gen_loss = 1.076865643989749, disc_loss = 0.0020971639726379116
Trained batch 82 in epoch 3, gen_loss = 1.0762404332678002, disc_loss = 0.002086257675651416
Trained batch 83 in epoch 3, gen_loss = 1.076190588020143, disc_loss = 0.0020760581385166873
Trained batch 84 in epoch 3, gen_loss = 1.0760729523266064, disc_loss = 0.0020634143531103343
Trained batch 85 in epoch 3, gen_loss = 1.0756766976312149, disc_loss = 0.0020502109573287673
Trained batch 86 in epoch 3, gen_loss = 1.0758654098401124, disc_loss = 0.0020374900918325475
Trained batch 87 in epoch 3, gen_loss = 1.0758297592401505, disc_loss = 0.0020223235214044425
Trained batch 88 in epoch 3, gen_loss = 1.075479617279567, disc_loss = 0.0020059593907410926
Trained batch 89 in epoch 3, gen_loss = 1.0755964544084338, disc_loss = 0.001991807040758431
Trained batch 90 in epoch 3, gen_loss = 1.0754704580202208, disc_loss = 0.00197903651636667
Trained batch 91 in epoch 3, gen_loss = 1.0754996045776035, disc_loss = 0.0019680551802435807
Trained batch 92 in epoch 3, gen_loss = 1.0753486630737141, disc_loss = 0.001958960528305221
Trained batch 93 in epoch 3, gen_loss = 1.0754308802016237, disc_loss = 0.0019504878251377414
Trained batch 94 in epoch 3, gen_loss = 1.075665885523746, disc_loss = 0.0019403219529378572
Trained batch 95 in epoch 3, gen_loss = 1.076002520819505, disc_loss = 0.0019288900530227693
Trained batch 96 in epoch 3, gen_loss = 1.075852709947173, disc_loss = 0.0019166041027572122
Trained batch 97 in epoch 3, gen_loss = 1.075466698529769, disc_loss = 0.0019068578667986225
Trained batch 98 in epoch 3, gen_loss = 1.0753659190553608, disc_loss = 0.0019048823853907637
Trained batch 99 in epoch 3, gen_loss = 1.075041069984436, disc_loss = 0.0019112010352546349
Trained batch 100 in epoch 3, gen_loss = 1.0746749899174908, disc_loss = 0.0019173154908250832
Trained batch 101 in epoch 3, gen_loss = 1.0743928294555813, disc_loss = 0.0019186801355852582
Trained batch 102 in epoch 3, gen_loss = 1.0740985349544043, disc_loss = 0.0019157130674694132
Trained batch 103 in epoch 3, gen_loss = 1.0743209478946834, disc_loss = 0.0019107922702320279
Trained batch 104 in epoch 3, gen_loss = 1.0744726669220697, disc_loss = 0.0019039565392415083
Trained batch 105 in epoch 3, gen_loss = 1.0740079373683569, disc_loss = 0.0018952845080694148
Trained batch 106 in epoch 3, gen_loss = 1.0734120518247658, disc_loss = 0.001886100845550683
Trained batch 107 in epoch 3, gen_loss = 1.0728133883741167, disc_loss = 0.0018752016896744156
Trained batch 108 in epoch 3, gen_loss = 1.0728386017160678, disc_loss = 0.0018664932908028912
Trained batch 109 in epoch 3, gen_loss = 1.0724306149916216, disc_loss = 0.0018597885585305365
Trained batch 110 in epoch 3, gen_loss = 1.0722696867075052, disc_loss = 0.0018538253566434792
Trained batch 111 in epoch 3, gen_loss = 1.0722891156162535, disc_loss = 0.0018473796725239871
Trained batch 112 in epoch 3, gen_loss = 1.0722227117656606, disc_loss = 0.0018401119159534574
Trained batch 113 in epoch 3, gen_loss = 1.0725516457306712, disc_loss = 0.0018342889777972903
Trained batch 114 in epoch 3, gen_loss = 1.0727144759634266, disc_loss = 0.0018282208703053386
Trained batch 115 in epoch 3, gen_loss = 1.0726427374214962, disc_loss = 0.0018205082596978173
Trained batch 116 in epoch 3, gen_loss = 1.0722686826673329, disc_loss = 0.0018127749457111598
Trained batch 117 in epoch 3, gen_loss = 1.0719734066623752, disc_loss = 0.0018063943736428805
Trained batch 118 in epoch 3, gen_loss = 1.072103932124226, disc_loss = 0.0018014270820099266
Trained batch 119 in epoch 3, gen_loss = 1.0720386842886607, disc_loss = 0.001796808659370678
Trained batch 120 in epoch 3, gen_loss = 1.072385344623534, disc_loss = 0.0017934592800553548
Trained batch 121 in epoch 3, gen_loss = 1.0722866556683526, disc_loss = 0.0017891106401860225
Trained batch 122 in epoch 3, gen_loss = 1.0722708295031291, disc_loss = 0.0017833864672215489
Trained batch 123 in epoch 3, gen_loss = 1.0718579926798422, disc_loss = 0.0017769669526211556
Trained batch 124 in epoch 3, gen_loss = 1.071466423034668, disc_loss = 0.0017701105950400234
Trained batch 125 in epoch 3, gen_loss = 1.0714657136372157, disc_loss = 0.0017624092861152595
Trained batch 126 in epoch 3, gen_loss = 1.0710011748817023, disc_loss = 0.001755899443074797
Trained batch 127 in epoch 3, gen_loss = 1.070700683631003, disc_loss = 0.001750558424191695
Trained batch 128 in epoch 3, gen_loss = 1.0705727967180947, disc_loss = 0.0017484359866434117
Trained batch 129 in epoch 3, gen_loss = 1.0703714517446665, disc_loss = 0.0017489271144418477
Trained batch 130 in epoch 3, gen_loss = 1.0701973256264024, disc_loss = 0.0017496636061829635
Trained batch 131 in epoch 3, gen_loss = 1.0702256533232601, disc_loss = 0.001749948605940903
Trained batch 132 in epoch 3, gen_loss = 1.070289248810675, disc_loss = 0.001746372361334839
Trained batch 133 in epoch 3, gen_loss = 1.0704666989952771, disc_loss = 0.0017399521368215167
Trained batch 134 in epoch 3, gen_loss = 1.0703964471817016, disc_loss = 0.0017327968492517592
Trained batch 135 in epoch 3, gen_loss = 1.070527254658587, disc_loss = 0.0017260795596966466
Trained batch 136 in epoch 3, gen_loss = 1.0704933961812597, disc_loss = 0.0017191539046925621
Trained batch 137 in epoch 3, gen_loss = 1.0702303224715635, disc_loss = 0.0017131908144633137
Trained batch 138 in epoch 3, gen_loss = 1.0700225572791888, disc_loss = 0.00170862914704577
Trained batch 139 in epoch 3, gen_loss = 1.069692245551518, disc_loss = 0.0017053254426822864
Trained batch 140 in epoch 3, gen_loss = 1.0695028812327283, disc_loss = 0.0017020147965051869
Trained batch 141 in epoch 3, gen_loss = 1.0696907060247072, disc_loss = 0.0016970574486062822
Trained batch 142 in epoch 3, gen_loss = 1.0695589063884494, disc_loss = 0.0016895910298412706
Trained batch 143 in epoch 3, gen_loss = 1.06947187665436, disc_loss = 0.0016831150549276369
Trained batch 144 in epoch 3, gen_loss = 1.0694682935188558, disc_loss = 0.0016792118946764747
Trained batch 145 in epoch 3, gen_loss = 1.0692248564876923, disc_loss = 0.0016786773256121893
Trained batch 146 in epoch 3, gen_loss = 1.0691148423824182, disc_loss = 0.0016790260738997283
Trained batch 147 in epoch 3, gen_loss = 1.0690992329571698, disc_loss = 0.0016781267481132385
Trained batch 148 in epoch 3, gen_loss = 1.0687352722923227, disc_loss = 0.0016780801585425417
Trained batch 149 in epoch 3, gen_loss = 1.0685261527697245, disc_loss = 0.0016790152244114628
Trained batch 150 in epoch 3, gen_loss = 1.0683501264117412, disc_loss = 0.0016803457089453098
Trained batch 151 in epoch 3, gen_loss = 1.0687474741747505, disc_loss = 0.0016824775708588085
Trained batch 152 in epoch 3, gen_loss = 1.068478362233031, disc_loss = 0.0016836298190611202
Trained batch 153 in epoch 3, gen_loss = 1.0684933523079017, disc_loss = 0.0016861582645850087
Trained batch 154 in epoch 3, gen_loss = 1.0685224371571695, disc_loss = 0.0016904470341790828
Trained batch 155 in epoch 3, gen_loss = 1.0680507601071627, disc_loss = 0.001696124075514933
Trained batch 156 in epoch 3, gen_loss = 1.0679803718427183, disc_loss = 0.0016997905287173855
Trained batch 157 in epoch 3, gen_loss = 1.0677431131465525, disc_loss = 0.0017013574248221054
Trained batch 158 in epoch 3, gen_loss = 1.0676528788962454, disc_loss = 0.0017021339750590986
Trained batch 159 in epoch 3, gen_loss = 1.067871716246009, disc_loss = 0.0017004839257424465
Trained batch 160 in epoch 3, gen_loss = 1.0675576232975315, disc_loss = 0.0016952434616880664
Trained batch 161 in epoch 3, gen_loss = 1.067400562542456, disc_loss = 0.0016902359051595409
Trained batch 162 in epoch 3, gen_loss = 1.0671965004476303, disc_loss = 0.001685597920973151
Trained batch 163 in epoch 3, gen_loss = 1.0666965813171574, disc_loss = 0.0016803725263410498
Trained batch 164 in epoch 3, gen_loss = 1.0666755242781205, disc_loss = 0.0016763730334456671
Trained batch 165 in epoch 3, gen_loss = 1.0666424280189606, disc_loss = 0.0016729918460036259
Trained batch 166 in epoch 3, gen_loss = 1.0667574341425639, disc_loss = 0.0016712243668735027
Trained batch 167 in epoch 3, gen_loss = 1.0665597397656668, disc_loss = 0.0016699283192532935
Trained batch 168 in epoch 3, gen_loss = 1.0666784584169557, disc_loss = 0.0016695780916547282
Trained batch 169 in epoch 3, gen_loss = 1.0663901602520662, disc_loss = 0.0016728557701058248
Trained batch 170 in epoch 3, gen_loss = 1.0662158643990232, disc_loss = 0.0016773924509292108
Trained batch 171 in epoch 3, gen_loss = 1.0658018900904545, disc_loss = 0.0016808533840704449
Trained batch 172 in epoch 3, gen_loss = 1.065976217992044, disc_loss = 0.0016851467497625275
Trained batch 173 in epoch 3, gen_loss = 1.066397566219856, disc_loss = 0.0016986532123416834
Trained batch 174 in epoch 3, gen_loss = 1.0667802272524152, disc_loss = 0.001705279021656939
Trained batch 175 in epoch 3, gen_loss = 1.0671739679845897, disc_loss = 0.0017109019787643444
Trained batch 176 in epoch 3, gen_loss = 1.0674978427294284, disc_loss = 0.0017202366485476158
Trained batch 177 in epoch 3, gen_loss = 1.0677315773588887, disc_loss = 0.0017252331782718388
Trained batch 178 in epoch 3, gen_loss = 1.0681818264156746, disc_loss = 0.0017268873592474442
Trained batch 179 in epoch 3, gen_loss = 1.0684530231687757, disc_loss = 0.0017247546503009895
Trained batch 180 in epoch 3, gen_loss = 1.0684127484895907, disc_loss = 0.0017211648490207878
Trained batch 181 in epoch 3, gen_loss = 1.0684766880758516, disc_loss = 0.0017164580128667365
Trained batch 182 in epoch 3, gen_loss = 1.0688694324649748, disc_loss = 0.0017137962738255578
Trained batch 183 in epoch 3, gen_loss = 1.0690141870923664, disc_loss = 0.0017117489845512191
Trained batch 184 in epoch 3, gen_loss = 1.0690620467469498, disc_loss = 0.0017106800050650899
Trained batch 185 in epoch 3, gen_loss = 1.069471424625766, disc_loss = 0.001709272187473553
Trained batch 186 in epoch 3, gen_loss = 1.0694282615886015, disc_loss = 0.0017051606185056946
Trained batch 187 in epoch 3, gen_loss = 1.0695206916078608, disc_loss = 0.0017003312117439952
Trained batch 188 in epoch 3, gen_loss = 1.0694221226626603, disc_loss = 0.0016953450619617587
Trained batch 189 in epoch 3, gen_loss = 1.0694463516536512, disc_loss = 0.0016914515639655293
Trained batch 190 in epoch 3, gen_loss = 1.0695325167391312, disc_loss = 0.0016882832543631888
Trained batch 191 in epoch 3, gen_loss = 1.0695304665714502, disc_loss = 0.001683666652146106
Trained batch 192 in epoch 3, gen_loss = 1.0693027732285811, disc_loss = 0.0016787476210922505
Trained batch 193 in epoch 3, gen_loss = 1.069264365840204, disc_loss = 0.0016746491478208797
Trained batch 194 in epoch 3, gen_loss = 1.0692338680609679, disc_loss = 0.0016713742936889714
Trained batch 195 in epoch 3, gen_loss = 1.0690389196483456, disc_loss = 0.001668506044756659
Trained batch 196 in epoch 3, gen_loss = 1.0687757143514411, disc_loss = 0.001665021236725908
Trained batch 197 in epoch 3, gen_loss = 1.0690332651138306, disc_loss = 0.0016637685687535188
Trained batch 198 in epoch 3, gen_loss = 1.0688436354824047, disc_loss = 0.001659659514362788
Trained batch 199 in epoch 3, gen_loss = 1.0687435287237168, disc_loss = 0.0016557334034587256
Trained batch 200 in epoch 3, gen_loss = 1.0687689632918704, disc_loss = 0.001651544359614563
Trained batch 201 in epoch 3, gen_loss = 1.0689424884201277, disc_loss = 0.0016479415998858686
Trained batch 202 in epoch 3, gen_loss = 1.0688643866571887, disc_loss = 0.0016440449553780405
Trained batch 203 in epoch 3, gen_loss = 1.0687505176254348, disc_loss = 0.0016417369179715239
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.0593082904815674, disc_loss = 0.0018556201830506325
Trained batch 1 in epoch 4, gen_loss = 1.0361058712005615, disc_loss = 0.0022793191019445658
Trained batch 2 in epoch 4, gen_loss = 1.0284563700358074, disc_loss = 0.0023455471576501927
Trained batch 3 in epoch 4, gen_loss = 1.0166022181510925, disc_loss = 0.002294967242050916
Trained batch 4 in epoch 4, gen_loss = 1.020724844932556, disc_loss = 0.002221201919019222
Trained batch 5 in epoch 4, gen_loss = 1.0237086415290833, disc_loss = 0.0022013277436296144
Trained batch 6 in epoch 4, gen_loss = 1.0213605335780553, disc_loss = 0.0022055685985833406
Trained batch 7 in epoch 4, gen_loss = 1.0203320384025574, disc_loss = 0.0022333240776788443
Trained batch 8 in epoch 4, gen_loss = 1.0183353688981798, disc_loss = 0.0022659290633681747
Trained batch 9 in epoch 4, gen_loss = 1.0182110786437988, disc_loss = 0.0023167786886915563
Trained batch 10 in epoch 4, gen_loss = 1.017064387148077, disc_loss = 0.002331622452898459
Trained batch 11 in epoch 4, gen_loss = 1.014062116543452, disc_loss = 0.0022956000466365367
Trained batch 12 in epoch 4, gen_loss = 1.0178952033703144, disc_loss = 0.0022911702623017705
Trained batch 13 in epoch 4, gen_loss = 1.0190521478652954, disc_loss = 0.0022806491885733393
Trained batch 14 in epoch 4, gen_loss = 1.0220406691233317, disc_loss = 0.0022866125917062165
Trained batch 15 in epoch 4, gen_loss = 1.0220325142145157, disc_loss = 0.0022864430575282313
Trained batch 16 in epoch 4, gen_loss = 1.0224677113925709, disc_loss = 0.0022824290824834913
Trained batch 17 in epoch 4, gen_loss = 1.0220713218053181, disc_loss = 0.0022656151365178325
Trained batch 18 in epoch 4, gen_loss = 1.0225889557286312, disc_loss = 0.0022351037294260764
Trained batch 19 in epoch 4, gen_loss = 1.0225358128547668, disc_loss = 0.0022067347192205487
Trained batch 20 in epoch 4, gen_loss = 1.02493793623788, disc_loss = 0.002172079031533074
Trained batch 21 in epoch 4, gen_loss = 1.0262570001862266, disc_loss = 0.002131560288200324
Trained batch 22 in epoch 4, gen_loss = 1.0266256384227588, disc_loss = 0.0020828556836299276
Trained batch 23 in epoch 4, gen_loss = 1.026461347937584, disc_loss = 0.0020252463000360876
Trained batch 24 in epoch 4, gen_loss = 1.0290571451187134, disc_loss = 0.00197891722433269
Trained batch 25 in epoch 4, gen_loss = 1.029940352990077, disc_loss = 0.0019366301108115853
Trained batch 26 in epoch 4, gen_loss = 1.0293306244744196, disc_loss = 0.001901390235784843
Trained batch 27 in epoch 4, gen_loss = 1.0287951869624001, disc_loss = 0.0018838138348655775
Trained batch 28 in epoch 4, gen_loss = 1.0283438542793537, disc_loss = 0.0018646240631792822
Trained batch 29 in epoch 4, gen_loss = 1.0285406510035198, disc_loss = 0.0018380346843817582
Trained batch 30 in epoch 4, gen_loss = 1.0281437327784877, disc_loss = 0.0018037596976594819
Trained batch 31 in epoch 4, gen_loss = 1.0282342955470085, disc_loss = 0.0017719247989589348
Trained batch 32 in epoch 4, gen_loss = 1.0281917037385884, disc_loss = 0.0017390674294085438
Trained batch 33 in epoch 4, gen_loss = 1.0278502842959236, disc_loss = 0.001705260801827535
Trained batch 34 in epoch 4, gen_loss = 1.0267414961542403, disc_loss = 0.0016719887149520218
Trained batch 35 in epoch 4, gen_loss = 1.0261281314823363, disc_loss = 0.001638749413864894
Trained batch 36 in epoch 4, gen_loss = 1.0253181650831893, disc_loss = 0.0016110326758132793
Trained batch 37 in epoch 4, gen_loss = 1.024378505192305, disc_loss = 0.0015890906996853453
Trained batch 38 in epoch 4, gen_loss = 1.0246538183627985, disc_loss = 0.0015707586739713757
Trained batch 39 in epoch 4, gen_loss = 1.0237972214818, disc_loss = 0.0015549337360425853
Trained batch 40 in epoch 4, gen_loss = 1.023158156290287, disc_loss = 0.0015382697768850115
Trained batch 41 in epoch 4, gen_loss = 1.02351323337782, disc_loss = 0.0015162236855498382
Trained batch 42 in epoch 4, gen_loss = 1.0234996620998826, disc_loss = 0.0014959823470129523
Trained batch 43 in epoch 4, gen_loss = 1.0233593081886119, disc_loss = 0.0014782777791631154
Trained batch 44 in epoch 4, gen_loss = 1.024007374710507, disc_loss = 0.0014607698928254347
Trained batch 45 in epoch 4, gen_loss = 1.0235549846421117, disc_loss = 0.0014419445120122123
Trained batch 46 in epoch 4, gen_loss = 1.023684984826027, disc_loss = 0.0014320140372605084
Trained batch 47 in epoch 4, gen_loss = 1.0241963304579258, disc_loss = 0.0014310107095904339
Trained batch 48 in epoch 4, gen_loss = 1.0241240761717971, disc_loss = 0.0014324333585266555
Trained batch 49 in epoch 4, gen_loss = 1.0239603126049042, disc_loss = 0.0014330570213496685
Trained batch 50 in epoch 4, gen_loss = 1.0236928194176917, disc_loss = 0.0014333912358601012
Trained batch 51 in epoch 4, gen_loss = 1.0228457760352354, disc_loss = 0.0014355818655950804
Trained batch 52 in epoch 4, gen_loss = 1.0221478230548355, disc_loss = 0.0014398757978957499
Trained batch 53 in epoch 4, gen_loss = 1.023759224900493, disc_loss = 0.001451508126963206
Trained batch 54 in epoch 4, gen_loss = 1.023127316344868, disc_loss = 0.0014532659223980525
Trained batch 55 in epoch 4, gen_loss = 1.0222801917365618, disc_loss = 0.001459440983515898
Trained batch 56 in epoch 4, gen_loss = 1.0224143967293857, disc_loss = 0.0014677276107760374
Trained batch 57 in epoch 4, gen_loss = 1.0227775974520321, disc_loss = 0.0014769329954388327
Trained batch 58 in epoch 4, gen_loss = 1.0225506808798193, disc_loss = 0.001473341693596567
Trained batch 59 in epoch 4, gen_loss = 1.022623293598493, disc_loss = 0.0014661952872605374
Trained batch 60 in epoch 4, gen_loss = 1.0226935959253154, disc_loss = 0.0014567442331844787
Trained batch 61 in epoch 4, gen_loss = 1.022898075080687, disc_loss = 0.0014510755511676712
Trained batch 62 in epoch 4, gen_loss = 1.0228394828145466, disc_loss = 0.0014518961940507686
Trained batch 63 in epoch 4, gen_loss = 1.0226213848218322, disc_loss = 0.0014579678836526
Trained batch 64 in epoch 4, gen_loss = 1.0223832708138687, disc_loss = 0.0014611586095550312
Trained batch 65 in epoch 4, gen_loss = 1.022320717573166, disc_loss = 0.0014587880427963241
Trained batch 66 in epoch 4, gen_loss = 1.022436728228384, disc_loss = 0.0014564415862186075
Trained batch 67 in epoch 4, gen_loss = 1.0226268338806488, disc_loss = 0.0014586118315278059
Trained batch 68 in epoch 4, gen_loss = 1.0219388673270957, disc_loss = 0.001468337636164295
Trained batch 69 in epoch 4, gen_loss = 1.0214421272277832, disc_loss = 0.0014938666510196136
Trained batch 70 in epoch 4, gen_loss = 1.021502263109449, disc_loss = 0.001520864274451168
Trained batch 71 in epoch 4, gen_loss = 1.02141558792856, disc_loss = 0.0015343849170474438
Trained batch 72 in epoch 4, gen_loss = 1.0212506219132307, disc_loss = 0.00154273524124507
Trained batch 73 in epoch 4, gen_loss = 1.020567797325753, disc_loss = 0.0015482857242868457
Trained batch 74 in epoch 4, gen_loss = 1.0202716477711995, disc_loss = 0.001553267640216897
Trained batch 75 in epoch 4, gen_loss = 1.0199951780469794, disc_loss = 0.0015584703551691124
Trained batch 76 in epoch 4, gen_loss = 1.0193423806846915, disc_loss = 0.0015584975080383191
Trained batch 77 in epoch 4, gen_loss = 1.0188142619071863, disc_loss = 0.0015550023011970692
Trained batch 78 in epoch 4, gen_loss = 1.0185706464550164, disc_loss = 0.0015489992905184154
Trained batch 79 in epoch 4, gen_loss = 1.0184458404779435, disc_loss = 0.0015399197429360357
Trained batch 80 in epoch 4, gen_loss = 1.0186315495290874, disc_loss = 0.0015375522952699274
Trained batch 81 in epoch 4, gen_loss = 1.0180362092285622, disc_loss = 0.0015511216855573853
Trained batch 82 in epoch 4, gen_loss = 1.0178411215184682, disc_loss = 0.0015845047835967537
Trained batch 83 in epoch 4, gen_loss = 1.0174922339972996, disc_loss = 0.0016318088296213232
Trained batch 84 in epoch 4, gen_loss = 1.0173597497098585, disc_loss = 0.0016709501108647707
Trained batch 85 in epoch 4, gen_loss = 1.0170904654403066, disc_loss = 0.0016920721357374256
Trained batch 86 in epoch 4, gen_loss = 1.0169645075140328, disc_loss = 0.0017026376090247997
Trained batch 87 in epoch 4, gen_loss = 1.0168356956406073, disc_loss = 0.0017095653106066907
Trained batch 88 in epoch 4, gen_loss = 1.016520997781432, disc_loss = 0.001711864490716017
Trained batch 89 in epoch 4, gen_loss = 1.0164923210938772, disc_loss = 0.0017090275670246533
Trained batch 90 in epoch 4, gen_loss = 1.016440756373353, disc_loss = 0.0017009129182302526
Trained batch 91 in epoch 4, gen_loss = 1.0160279682149058, disc_loss = 0.0016899634723338986
Trained batch 92 in epoch 4, gen_loss = 1.0161235710626007, disc_loss = 0.0016796526283786822
Trained batch 93 in epoch 4, gen_loss = 1.015688991292994, disc_loss = 0.0016734940396185886
Trained batch 94 in epoch 4, gen_loss = 1.0153818808103863, disc_loss = 0.0016719790028506204
Trained batch 95 in epoch 4, gen_loss = 1.0150924660265446, disc_loss = 0.0016740574465075042
Trained batch 96 in epoch 4, gen_loss = 1.0147466057354642, disc_loss = 0.0016764384915226513
Trained batch 97 in epoch 4, gen_loss = 1.0147366487250036, disc_loss = 0.0016766162268456299
Trained batch 98 in epoch 4, gen_loss = 1.014430825758462, disc_loss = 0.0016731522528153628
Trained batch 99 in epoch 4, gen_loss = 1.0143703001737594, disc_loss = 0.0016656836599577218
Trained batch 100 in epoch 4, gen_loss = 1.0139524753731075, disc_loss = 0.0016569303496196718
Trained batch 101 in epoch 4, gen_loss = 1.013875182352814, disc_loss = 0.0016521258261419979
Trained batch 102 in epoch 4, gen_loss = 1.0136142755017696, disc_loss = 0.0016522322299899262
Trained batch 103 in epoch 4, gen_loss = 1.0137418709122217, disc_loss = 0.0016572553174158272
Trained batch 104 in epoch 4, gen_loss = 1.01380326009932, disc_loss = 0.0016626003830294523
Trained batch 105 in epoch 4, gen_loss = 1.0140156380410463, disc_loss = 0.0016640772623501999
Trained batch 106 in epoch 4, gen_loss = 1.013806873392836, disc_loss = 0.0016636387619111583
Trained batch 107 in epoch 4, gen_loss = 1.0136202264715124, disc_loss = 0.0016618515774435192
Trained batch 108 in epoch 4, gen_loss = 1.0135503077725752, disc_loss = 0.001656864641593137
Trained batch 109 in epoch 4, gen_loss = 1.0128635926680132, disc_loss = 0.0016502883544572714
Trained batch 110 in epoch 4, gen_loss = 1.0125074032190684, disc_loss = 0.0016437230987247785
Trained batch 111 in epoch 4, gen_loss = 1.0131230631044932, disc_loss = 0.0016386628459648428
Trained batch 112 in epoch 4, gen_loss = 1.0132747751421634, disc_loss = 0.0016341642296329075
Trained batch 113 in epoch 4, gen_loss = 1.0132734817371034, disc_loss = 0.0016305340487681526
Trained batch 114 in epoch 4, gen_loss = 1.0132096757059512, disc_loss = 0.001627517606475917
Trained batch 115 in epoch 4, gen_loss = 1.013201824549971, disc_loss = 0.0016233677948736746
Trained batch 116 in epoch 4, gen_loss = 1.0131530191144373, disc_loss = 0.0016207821556749062
Trained batch 117 in epoch 4, gen_loss = 1.0132889767824593, disc_loss = 0.001619575129352289
Trained batch 118 in epoch 4, gen_loss = 1.013389889933482, disc_loss = 0.0016188832413710403
Trained batch 119 in epoch 4, gen_loss = 1.0133854309717814, disc_loss = 0.0016157431882068826
Trained batch 120 in epoch 4, gen_loss = 1.013246209168237, disc_loss = 0.001611147728683196
Trained batch 121 in epoch 4, gen_loss = 1.013521993746523, disc_loss = 0.00161045460177387
Trained batch 122 in epoch 4, gen_loss = 1.0135471413775188, disc_loss = 0.001610238473707189
Trained batch 123 in epoch 4, gen_loss = 1.013713054118618, disc_loss = 0.0016093477855564184
Trained batch 124 in epoch 4, gen_loss = 1.0135798234939575, disc_loss = 0.0016091873836703598
Trained batch 125 in epoch 4, gen_loss = 1.0136876418477012, disc_loss = 0.0016096982516400102
Trained batch 126 in epoch 4, gen_loss = 1.0133311307336401, disc_loss = 0.001609603202018124
Trained batch 127 in epoch 4, gen_loss = 1.0130712459795177, disc_loss = 0.0016084524327197869
Trained batch 128 in epoch 4, gen_loss = 1.0126704605974892, disc_loss = 0.001606073866277038
Trained batch 129 in epoch 4, gen_loss = 1.012514591217041, disc_loss = 0.0016016303592970452
Trained batch 130 in epoch 4, gen_loss = 1.0125818361762826, disc_loss = 0.0015965086507490117
Trained batch 131 in epoch 4, gen_loss = 1.0122425565213868, disc_loss = 0.0015886339833466054
Trained batch 132 in epoch 4, gen_loss = 1.0121001650516253, disc_loss = 0.0015811665006388062
Trained batch 133 in epoch 4, gen_loss = 1.0122474974660731, disc_loss = 0.0015763802086385384
Trained batch 134 in epoch 4, gen_loss = 1.0121746495917991, disc_loss = 0.0015728842074706874
Trained batch 135 in epoch 4, gen_loss = 1.011999803430894, disc_loss = 0.001568417869052877
Trained batch 136 in epoch 4, gen_loss = 1.0118431009515358, disc_loss = 0.0015635031392716252
Trained batch 137 in epoch 4, gen_loss = 1.0116087440131367, disc_loss = 0.0015581713903330915
Trained batch 138 in epoch 4, gen_loss = 1.011713767223221, disc_loss = 0.001553666405212268
Trained batch 139 in epoch 4, gen_loss = 1.0114268354007176, disc_loss = 0.0015504951455763407
Trained batch 140 in epoch 4, gen_loss = 1.0113525120079094, disc_loss = 0.0015475984971560803
Trained batch 141 in epoch 4, gen_loss = 1.0114816049454918, disc_loss = 0.0015434342687359263
Trained batch 142 in epoch 4, gen_loss = 1.011608754004632, disc_loss = 0.0015382410981203919
Trained batch 143 in epoch 4, gen_loss = 1.0114844408300188, disc_loss = 0.0015332995159648515
Trained batch 144 in epoch 4, gen_loss = 1.0115106993708116, disc_loss = 0.0015283329873988084
Trained batch 145 in epoch 4, gen_loss = 1.0118073984368208, disc_loss = 0.0015232439239809214
Trained batch 146 in epoch 4, gen_loss = 1.0118309705435824, disc_loss = 0.0015181029380970717
Trained batch 147 in epoch 4, gen_loss = 1.0116803122533333, disc_loss = 0.0015132365928415361
Trained batch 148 in epoch 4, gen_loss = 1.0115300156926148, disc_loss = 0.0015085386264687966
Trained batch 149 in epoch 4, gen_loss = 1.0114857542514801, disc_loss = 0.0015047191572375596
Trained batch 150 in epoch 4, gen_loss = 1.011378275637595, disc_loss = 0.0015003026369804925
Trained batch 151 in epoch 4, gen_loss = 1.0110349204195173, disc_loss = 0.001494490845959119
Trained batch 152 in epoch 4, gen_loss = 1.0108641117226844, disc_loss = 0.001487346290720298
Trained batch 153 in epoch 4, gen_loss = 1.0107689426316844, disc_loss = 0.001480556275338757
Trained batch 154 in epoch 4, gen_loss = 1.01084654062025, disc_loss = 0.0014741597821064775
Trained batch 155 in epoch 4, gen_loss = 1.0108410131472807, disc_loss = 0.0014679110967195951
Trained batch 156 in epoch 4, gen_loss = 1.0108959352134899, disc_loss = 0.0014620024657505714
Trained batch 157 in epoch 4, gen_loss = 1.010888153616386, disc_loss = 0.0014571017011723044
Trained batch 158 in epoch 4, gen_loss = 1.010735920765115, disc_loss = 0.0014517586769788005
Trained batch 159 in epoch 4, gen_loss = 1.010757913812995, disc_loss = 0.0014463991436059586
Trained batch 160 in epoch 4, gen_loss = 1.0104208399790415, disc_loss = 0.0014406366965021961
Trained batch 161 in epoch 4, gen_loss = 1.0103030510154771, disc_loss = 0.001435661904030928
Trained batch 162 in epoch 4, gen_loss = 1.0102369664636857, disc_loss = 0.001431461575403924
Trained batch 163 in epoch 4, gen_loss = 1.010064481235132, disc_loss = 0.00142813755572694
Trained batch 164 in epoch 4, gen_loss = 1.0099732290614736, disc_loss = 0.0014265455788876297
Trained batch 165 in epoch 4, gen_loss = 1.0102433648454137, disc_loss = 0.0014263032784780868
Trained batch 166 in epoch 4, gen_loss = 1.010139710175063, disc_loss = 0.0014271216169362163
Trained batch 167 in epoch 4, gen_loss = 1.0102027654647827, disc_loss = 0.0014293258105421305
Trained batch 168 in epoch 4, gen_loss = 1.0101169305440236, disc_loss = 0.001432509217673042
Trained batch 169 in epoch 4, gen_loss = 1.0098213290466982, disc_loss = 0.0014334604270783637
Trained batch 170 in epoch 4, gen_loss = 1.009685246219412, disc_loss = 0.0014321246883581386
Trained batch 171 in epoch 4, gen_loss = 1.0100345365529837, disc_loss = 0.0014313425165519854
Trained batch 172 in epoch 4, gen_loss = 1.0098513588739957, disc_loss = 0.0014303392865910394
Trained batch 173 in epoch 4, gen_loss = 1.0098092470360898, disc_loss = 0.0014291810057120633
Trained batch 174 in epoch 4, gen_loss = 1.009634348324367, disc_loss = 0.0014292777672276966
Trained batch 175 in epoch 4, gen_loss = 1.0095530281012708, disc_loss = 0.0014318048154316123
Trained batch 176 in epoch 4, gen_loss = 1.0093759483536757, disc_loss = 0.0014337490264742009
Trained batch 177 in epoch 4, gen_loss = 1.0092301921228344, disc_loss = 0.0014343006883648466
Trained batch 178 in epoch 4, gen_loss = 1.0091391538774501, disc_loss = 0.0014338718454728122
Trained batch 179 in epoch 4, gen_loss = 1.0090796291828155, disc_loss = 0.0014326849282952025
Trained batch 180 in epoch 4, gen_loss = 1.0090422465656343, disc_loss = 0.0014320306935944487
Trained batch 181 in epoch 4, gen_loss = 1.0088279709056183, disc_loss = 0.0014315423108560575
Trained batch 182 in epoch 4, gen_loss = 1.008994734678112, disc_loss = 0.0014298571642014945
Trained batch 183 in epoch 4, gen_loss = 1.0088849854858026, disc_loss = 0.001426280984204546
Trained batch 184 in epoch 4, gen_loss = 1.0086778991931193, disc_loss = 0.0014217911709754451
Trained batch 185 in epoch 4, gen_loss = 1.0086129125087493, disc_loss = 0.0014169796880695127
Trained batch 186 in epoch 4, gen_loss = 1.008545437598611, disc_loss = 0.0014119430457274205
Trained batch 187 in epoch 4, gen_loss = 1.0084209334343037, disc_loss = 0.0014077256369575402
Trained batch 188 in epoch 4, gen_loss = 1.0084011939467576, disc_loss = 0.0014037024918093627
Trained batch 189 in epoch 4, gen_loss = 1.008133685275128, disc_loss = 0.0013988308107639711
Trained batch 190 in epoch 4, gen_loss = 1.0079528480300104, disc_loss = 0.001394457232081502
Trained batch 191 in epoch 4, gen_loss = 1.0078644507254164, disc_loss = 0.0013923843806272391
Trained batch 192 in epoch 4, gen_loss = 1.0078274243236205, disc_loss = 0.0013920540815530527
Trained batch 193 in epoch 4, gen_loss = 1.0078691081287934, disc_loss = 0.001393230329057653
Trained batch 194 in epoch 4, gen_loss = 1.0078496954379939, disc_loss = 0.0013956045703544544
Trained batch 195 in epoch 4, gen_loss = 1.0076905811319545, disc_loss = 0.0013989418650304955
Trained batch 196 in epoch 4, gen_loss = 1.0076598316279766, disc_loss = 0.0014024631524763452
Trained batch 197 in epoch 4, gen_loss = 1.0073167467960205, disc_loss = 0.0014068319521329338
Trained batch 198 in epoch 4, gen_loss = 1.007128211721104, disc_loss = 0.0014126990699787254
Trained batch 199 in epoch 4, gen_loss = 1.006977894306183, disc_loss = 0.0014191672632296105
Trained batch 200 in epoch 4, gen_loss = 1.0069603190493228, disc_loss = 0.0014237184304829724
Trained batch 201 in epoch 4, gen_loss = 1.0067975438467347, disc_loss = 0.0014248052227257815
Trained batch 202 in epoch 4, gen_loss = 1.006710600383176, disc_loss = 0.0014229270325930045
Trained batch 203 in epoch 4, gen_loss = 1.0067776798033248, disc_loss = 0.0014196841627434717
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0069382190704346, disc_loss = 0.0006460984004661441
Trained batch 1 in epoch 5, gen_loss = 0.9954575896263123, disc_loss = 0.0006033460958860815
Trained batch 2 in epoch 5, gen_loss = 1.0010019540786743, disc_loss = 0.0006553624601413807
Trained batch 3 in epoch 5, gen_loss = 1.002661019563675, disc_loss = 0.0006776961090508848
Trained batch 4 in epoch 5, gen_loss = 1.007599139213562, disc_loss = 0.0006651960546150803
Trained batch 5 in epoch 5, gen_loss = 0.9992250700791677, disc_loss = 0.0006601501469655583
Trained batch 6 in epoch 5, gen_loss = 0.9992974485669818, disc_loss = 0.0006813133368268609
Trained batch 7 in epoch 5, gen_loss = 0.9933804571628571, disc_loss = 0.0007470496784662828
Trained batch 8 in epoch 5, gen_loss = 0.9941323200861613, disc_loss = 0.0008325087967225247
Trained batch 9 in epoch 5, gen_loss = 0.9909790933132172, disc_loss = 0.00086410854710266
Trained batch 10 in epoch 5, gen_loss = 0.9919812191616405, disc_loss = 0.0008561406549150971
Trained batch 11 in epoch 5, gen_loss = 0.9870510449012121, disc_loss = 0.0008299596326348061
Trained batch 12 in epoch 5, gen_loss = 0.9872801487262433, disc_loss = 0.0008164513094995457
Trained batch 13 in epoch 5, gen_loss = 0.9846960987363543, disc_loss = 0.0008233697403089277
Trained batch 14 in epoch 5, gen_loss = 0.9853843887646992, disc_loss = 0.0008419225690886378
Trained batch 15 in epoch 5, gen_loss = 0.9852561838924885, disc_loss = 0.0008570285790483467
Trained batch 16 in epoch 5, gen_loss = 0.9851183926357943, disc_loss = 0.0008758553577696576
Trained batch 17 in epoch 5, gen_loss = 0.9855818847815195, disc_loss = 0.000892929086047742
Trained batch 18 in epoch 5, gen_loss = 0.9842024131825096, disc_loss = 0.0009103517942620735
Trained batch 19 in epoch 5, gen_loss = 0.9856812745332718, disc_loss = 0.0009404318348970264
Trained batch 20 in epoch 5, gen_loss = 0.9856132779802594, disc_loss = 0.0009611275856427493
Trained batch 21 in epoch 5, gen_loss = 0.9868054173209451, disc_loss = 0.0009685479453764856
Trained batch 22 in epoch 5, gen_loss = 0.9883054132046907, disc_loss = 0.0009634269391308012
Trained batch 23 in epoch 5, gen_loss = 0.9905395110448202, disc_loss = 0.0009520732104040993
Trained batch 24 in epoch 5, gen_loss = 0.9912037706375122, disc_loss = 0.0009378600609488785
Trained batch 25 in epoch 5, gen_loss = 0.9919545008586004, disc_loss = 0.0009422022603058184
Trained batch 26 in epoch 5, gen_loss = 0.9916874280682316, disc_loss = 0.0009648086464342972
Trained batch 27 in epoch 5, gen_loss = 0.9913596319300788, disc_loss = 0.0009800453824157427
Trained batch 28 in epoch 5, gen_loss = 0.991072469744189, disc_loss = 0.0009786021727105152
Trained batch 29 in epoch 5, gen_loss = 0.9921466747919718, disc_loss = 0.0009741383410679798
Trained batch 30 in epoch 5, gen_loss = 0.9918300240270553, disc_loss = 0.000967742909016388
Trained batch 31 in epoch 5, gen_loss = 0.9921520184725523, disc_loss = 0.0009599261829862371
Trained batch 32 in epoch 5, gen_loss = 0.9919434117548394, disc_loss = 0.0009486006985587829
Trained batch 33 in epoch 5, gen_loss = 0.9925176063004661, disc_loss = 0.0009390120634206516
Trained batch 34 in epoch 5, gen_loss = 0.9914375764983041, disc_loss = 0.0009321074134537152
Trained batch 35 in epoch 5, gen_loss = 0.9915881322489845, disc_loss = 0.0009256015166303971
Trained batch 36 in epoch 5, gen_loss = 0.9929207692275176, disc_loss = 0.0009180293182490041
Trained batch 37 in epoch 5, gen_loss = 0.9925659377323953, disc_loss = 0.0009102692603942399
Trained batch 38 in epoch 5, gen_loss = 0.9925248821576437, disc_loss = 0.0009018184291795852
Trained batch 39 in epoch 5, gen_loss = 0.9920065209269524, disc_loss = 0.0008905222544854041
Trained batch 40 in epoch 5, gen_loss = 0.9914202486596456, disc_loss = 0.0008869593723097862
Trained batch 41 in epoch 5, gen_loss = 0.9907774669783456, disc_loss = 0.0008940743247789907
Trained batch 42 in epoch 5, gen_loss = 0.9913240116696025, disc_loss = 0.000902650089322611
Trained batch 43 in epoch 5, gen_loss = 0.9906476112929258, disc_loss = 0.0009084844463028606
Trained batch 44 in epoch 5, gen_loss = 0.9912625551223755, disc_loss = 0.0009146049689863705
Trained batch 45 in epoch 5, gen_loss = 0.9915785245273424, disc_loss = 0.0009190775827332602
Trained batch 46 in epoch 5, gen_loss = 0.9913604005854181, disc_loss = 0.0009237738998676154
Trained batch 47 in epoch 5, gen_loss = 0.9915350849429766, disc_loss = 0.0009251255827014878
Trained batch 48 in epoch 5, gen_loss = 0.992665130264905, disc_loss = 0.0009242099316610137
Trained batch 49 in epoch 5, gen_loss = 0.9929282975196838, disc_loss = 0.0009188353613717482
Trained batch 50 in epoch 5, gen_loss = 0.9925342552802142, disc_loss = 0.0009117122076442648
Trained batch 51 in epoch 5, gen_loss = 0.9927386377866452, disc_loss = 0.0009053696608484293
Trained batch 52 in epoch 5, gen_loss = 0.9936678375837937, disc_loss = 0.0008976540878582043
Trained batch 53 in epoch 5, gen_loss = 0.9942563650784669, disc_loss = 0.0008894926873768714
Trained batch 54 in epoch 5, gen_loss = 0.9936091238802129, disc_loss = 0.0008812279768542132
Trained batch 55 in epoch 5, gen_loss = 0.9941632907305445, disc_loss = 0.0008772848783077539
Trained batch 56 in epoch 5, gen_loss = 0.9942247417935154, disc_loss = 0.0008712034598973236
Trained batch 57 in epoch 5, gen_loss = 0.9938145372374304, disc_loss = 0.0008636726606396381
Trained batch 58 in epoch 5, gen_loss = 0.9928223046205812, disc_loss = 0.0008572207090949987
Trained batch 59 in epoch 5, gen_loss = 0.9932534207900365, disc_loss = 0.0008524312016864618
Trained batch 60 in epoch 5, gen_loss = 0.9939862597184103, disc_loss = 0.0008531385960179518
Trained batch 61 in epoch 5, gen_loss = 0.9938556090477975, disc_loss = 0.0008620299800719706
Trained batch 62 in epoch 5, gen_loss = 0.9939597428791107, disc_loss = 0.0008841001794540457
Trained batch 63 in epoch 5, gen_loss = 0.9948310721665621, disc_loss = 0.0009174846545647597
Trained batch 64 in epoch 5, gen_loss = 0.9946462622055641, disc_loss = 0.0009481420292733954
Trained batch 65 in epoch 5, gen_loss = 0.9941596018545555, disc_loss = 0.0009671181606157033
Trained batch 66 in epoch 5, gen_loss = 0.9943846793317083, disc_loss = 0.0009809834847866155
Trained batch 67 in epoch 5, gen_loss = 0.994266680058311, disc_loss = 0.0009915011024157353
Trained batch 68 in epoch 5, gen_loss = 0.9940194807190826, disc_loss = 0.0010041034142689211
Trained batch 69 in epoch 5, gen_loss = 0.9942010692187718, disc_loss = 0.001025306451733091
Trained batch 70 in epoch 5, gen_loss = 0.9943486485682743, disc_loss = 0.0010510512912960748
Trained batch 71 in epoch 5, gen_loss = 0.9944567763143115, disc_loss = 0.0010767999483505264
Trained batch 72 in epoch 5, gen_loss = 0.9947109728643339, disc_loss = 0.001099546872117646
Trained batch 73 in epoch 5, gen_loss = 0.9940964160738764, disc_loss = 0.0011177329437782031
Trained batch 74 in epoch 5, gen_loss = 0.9944021145502726, disc_loss = 0.001133161822023491
Trained batch 75 in epoch 5, gen_loss = 0.9946742606790442, disc_loss = 0.0011424111404554232
Trained batch 76 in epoch 5, gen_loss = 0.9952061919422893, disc_loss = 0.0011546364048036276
Trained batch 77 in epoch 5, gen_loss = 0.9960370063781738, disc_loss = 0.0011678624163883238
Trained batch 78 in epoch 5, gen_loss = 0.9963403200801415, disc_loss = 0.0011755550498307884
Trained batch 79 in epoch 5, gen_loss = 0.9965137898921966, disc_loss = 0.001185608419473283
Trained batch 80 in epoch 5, gen_loss = 0.996766002089889, disc_loss = 0.001200832550149457
Trained batch 81 in epoch 5, gen_loss = 0.9961031522692704, disc_loss = 0.0012138037652731305
Trained batch 82 in epoch 5, gen_loss = 0.9962167201271976, disc_loss = 0.0012179200357970703
Trained batch 83 in epoch 5, gen_loss = 0.9966899461689449, disc_loss = 0.0012218471951893576
Trained batch 84 in epoch 5, gen_loss = 0.996186034118428, disc_loss = 0.0012287128004519379
Trained batch 85 in epoch 5, gen_loss = 0.9962465201699456, disc_loss = 0.001229522890562928
Trained batch 86 in epoch 5, gen_loss = 0.9969167318837396, disc_loss = 0.0012303530104758069
Trained batch 87 in epoch 5, gen_loss = 0.997246079146862, disc_loss = 0.0012307341147044842
Trained batch 88 in epoch 5, gen_loss = 0.9975178596678744, disc_loss = 0.0012358008606589577
Trained batch 89 in epoch 5, gen_loss = 0.9975807236300575, disc_loss = 0.001240978239931994
Trained batch 90 in epoch 5, gen_loss = 0.9974910413825905, disc_loss = 0.001243614039005159
Trained batch 91 in epoch 5, gen_loss = 0.9969945925733318, disc_loss = 0.0012424235882581738
Trained batch 92 in epoch 5, gen_loss = 0.996690389930561, disc_loss = 0.0012393829566727003
Trained batch 93 in epoch 5, gen_loss = 0.9961932555158087, disc_loss = 0.0012366408661770773
Trained batch 94 in epoch 5, gen_loss = 0.9969715181149934, disc_loss = 0.0012363665044846895
Trained batch 95 in epoch 5, gen_loss = 0.9967916905879974, disc_loss = 0.0012335454678880826
Trained batch 96 in epoch 5, gen_loss = 0.9970660467737729, disc_loss = 0.0012287162832397315
Trained batch 97 in epoch 5, gen_loss = 0.997009881905147, disc_loss = 0.0012257388443686068
Trained batch 98 in epoch 5, gen_loss = 0.9973585713993419, disc_loss = 0.001226704684086144
Trained batch 99 in epoch 5, gen_loss = 0.9975719225406646, disc_loss = 0.00122706908849068
Trained batch 100 in epoch 5, gen_loss = 0.9974664113309124, disc_loss = 0.0012223368872528767
Trained batch 101 in epoch 5, gen_loss = 0.9970716477609148, disc_loss = 0.0012147346238706115
Trained batch 102 in epoch 5, gen_loss = 0.9970956473674589, disc_loss = 0.0012071658139460658
Trained batch 103 in epoch 5, gen_loss = 0.9974888288057767, disc_loss = 0.0012006198169099381
Trained batch 104 in epoch 5, gen_loss = 0.9976069427671886, disc_loss = 0.0011951784664277164
Trained batch 105 in epoch 5, gen_loss = 0.9971963695760043, disc_loss = 0.001190153255351415
Trained batch 106 in epoch 5, gen_loss = 0.9971743888944109, disc_loss = 0.0011854214353321521
Trained batch 107 in epoch 5, gen_loss = 0.9972550350206869, disc_loss = 0.0011796253249351004
Trained batch 108 in epoch 5, gen_loss = 0.9971775046182335, disc_loss = 0.001174154764024216
Trained batch 109 in epoch 5, gen_loss = 0.9971566530791196, disc_loss = 0.0011711979782293466
Trained batch 110 in epoch 5, gen_loss = 0.9973361690839132, disc_loss = 0.0011696793214493507
Trained batch 111 in epoch 5, gen_loss = 0.9974307806364128, disc_loss = 0.0011663266808942094
Trained batch 112 in epoch 5, gen_loss = 0.99757434045319, disc_loss = 0.0011605009430426015
Trained batch 113 in epoch 5, gen_loss = 0.9972085466510371, disc_loss = 0.0011535036888712887
Trained batch 114 in epoch 5, gen_loss = 0.9968279283979665, disc_loss = 0.0011479411529802272
Trained batch 115 in epoch 5, gen_loss = 0.9973588056605438, disc_loss = 0.0011446051706523828
Trained batch 116 in epoch 5, gen_loss = 0.9972127334684389, disc_loss = 0.0011422841903717758
Trained batch 117 in epoch 5, gen_loss = 0.9974421692096581, disc_loss = 0.0011410272132183063
Trained batch 118 in epoch 5, gen_loss = 0.997407408321605, disc_loss = 0.0011414855304311084
Trained batch 119 in epoch 5, gen_loss = 0.9973200539747874, disc_loss = 0.0011441310637261874
Trained batch 120 in epoch 5, gen_loss = 0.9968885666082713, disc_loss = 0.0011475937047007317
Trained batch 121 in epoch 5, gen_loss = 0.9969957246155036, disc_loss = 0.0011511746945229862
Trained batch 122 in epoch 5, gen_loss = 0.996829004791694, disc_loss = 0.0011530310917376896
Trained batch 123 in epoch 5, gen_loss = 0.9967650338526695, disc_loss = 0.0011535104330828144
Trained batch 124 in epoch 5, gen_loss = 0.9968267946243287, disc_loss = 0.0011519709748681634
Trained batch 125 in epoch 5, gen_loss = 0.9966356754302979, disc_loss = 0.0011496108862855989
Trained batch 126 in epoch 5, gen_loss = 0.9967420232577586, disc_loss = 0.0011475595444400508
Trained batch 127 in epoch 5, gen_loss = 0.9963652812875807, disc_loss = 0.0011450095018972206
Trained batch 128 in epoch 5, gen_loss = 0.9964169980019562, disc_loss = 0.0011404289531452914
Trained batch 129 in epoch 5, gen_loss = 0.9959442051557394, disc_loss = 0.0011341962611857944
Trained batch 130 in epoch 5, gen_loss = 0.9959045043428436, disc_loss = 0.0011285155963149092
Trained batch 131 in epoch 5, gen_loss = 0.9960728644421606, disc_loss = 0.001123296024161391
Trained batch 132 in epoch 5, gen_loss = 0.9959477078645749, disc_loss = 0.0011173976045644569
Trained batch 133 in epoch 5, gen_loss = 0.9959869749510466, disc_loss = 0.001111337255665671
Trained batch 134 in epoch 5, gen_loss = 0.9960086451636421, disc_loss = 0.0011056290124543012
Trained batch 135 in epoch 5, gen_loss = 0.9961351392900243, disc_loss = 0.0011007290090406861
Trained batch 136 in epoch 5, gen_loss = 0.9962457984033293, disc_loss = 0.001097999374640521
Trained batch 137 in epoch 5, gen_loss = 0.9963643792746724, disc_loss = 0.0010961600510990652
Trained batch 138 in epoch 5, gen_loss = 0.9962943938138674, disc_loss = 0.0010924359834618973
Trained batch 139 in epoch 5, gen_loss = 0.9960692486592702, disc_loss = 0.0010874854872651798
Trained batch 140 in epoch 5, gen_loss = 0.9962212392624389, disc_loss = 0.0010826083435594427
Trained batch 141 in epoch 5, gen_loss = 0.9961299623402071, disc_loss = 0.0010772352063828344
Trained batch 142 in epoch 5, gen_loss = 0.9963131255203194, disc_loss = 0.0010732402644442539
Trained batch 143 in epoch 5, gen_loss = 0.9960060893661447, disc_loss = 0.0010701634530252907
Trained batch 144 in epoch 5, gen_loss = 0.9958400890744966, disc_loss = 0.001069283071335341
Trained batch 145 in epoch 5, gen_loss = 0.9960621203461738, disc_loss = 0.0010707492588091106
Trained batch 146 in epoch 5, gen_loss = 0.9959535619028571, disc_loss = 0.0010718705117160796
Trained batch 147 in epoch 5, gen_loss = 0.9961508387649382, disc_loss = 0.0010714862730457902
Trained batch 148 in epoch 5, gen_loss = 0.9960846768929654, disc_loss = 0.0010709600101596983
Trained batch 149 in epoch 5, gen_loss = 0.9960283573468526, disc_loss = 0.0010712961117193725
Trained batch 150 in epoch 5, gen_loss = 0.995821137696702, disc_loss = 0.001073733497363213
Trained batch 151 in epoch 5, gen_loss = 0.9958562847030791, disc_loss = 0.0010763712828185433
Trained batch 152 in epoch 5, gen_loss = 0.99593794384813, disc_loss = 0.001077347074588152
Trained batch 153 in epoch 5, gen_loss = 0.9959783503761539, disc_loss = 0.0010767776986611282
Trained batch 154 in epoch 5, gen_loss = 0.9958888549958506, disc_loss = 0.0010759727043595404
Trained batch 155 in epoch 5, gen_loss = 0.995871942394819, disc_loss = 0.0010751977281940456
Trained batch 156 in epoch 5, gen_loss = 0.9957696184231217, disc_loss = 0.0010733169428989362
Trained batch 157 in epoch 5, gen_loss = 0.9960590208633037, disc_loss = 0.0010717404548364656
Trained batch 158 in epoch 5, gen_loss = 0.995857022093527, disc_loss = 0.0010694773362893845
Trained batch 159 in epoch 5, gen_loss = 0.9956549376249313, disc_loss = 0.0010668743268979596
Trained batch 160 in epoch 5, gen_loss = 0.995826074055263, disc_loss = 0.0010644417794447346
Trained batch 161 in epoch 5, gen_loss = 0.9957270188096129, disc_loss = 0.0010611807683520134
Trained batch 162 in epoch 5, gen_loss = 0.9956395428604875, disc_loss = 0.0010576879691712535
Trained batch 163 in epoch 5, gen_loss = 0.9955024195880424, disc_loss = 0.0010533058767777685
Trained batch 164 in epoch 5, gen_loss = 0.9953535090793263, disc_loss = 0.001048702470231519
Trained batch 165 in epoch 5, gen_loss = 0.9953253667756735, disc_loss = 0.0010441084550511293
Trained batch 166 in epoch 5, gen_loss = 0.9952688456295493, disc_loss = 0.001040038777150013
Trained batch 167 in epoch 5, gen_loss = 0.9951486520114399, disc_loss = 0.0010363667871778099
Trained batch 168 in epoch 5, gen_loss = 0.9951977712162853, disc_loss = 0.0010337932612237207
Trained batch 169 in epoch 5, gen_loss = 0.9954930147703956, disc_loss = 0.0010335414846742745
Trained batch 170 in epoch 5, gen_loss = 0.9954471612534328, disc_loss = 0.001036199801485735
Trained batch 171 in epoch 5, gen_loss = 0.9955270612655684, disc_loss = 0.0010404402238173346
Trained batch 172 in epoch 5, gen_loss = 0.9955084537495078, disc_loss = 0.0010436167609083839
Trained batch 173 in epoch 5, gen_loss = 0.995668907960256, disc_loss = 0.0010466083117169275
Trained batch 174 in epoch 5, gen_loss = 0.9954671059335981, disc_loss = 0.0010495997823974383
Trained batch 175 in epoch 5, gen_loss = 0.9952783628620885, disc_loss = 0.001053008673393792
Trained batch 176 in epoch 5, gen_loss = 0.9953246658804726, disc_loss = 0.0010566234390980086
Trained batch 177 in epoch 5, gen_loss = 0.9951321844304546, disc_loss = 0.001059506672370415
Trained batch 178 in epoch 5, gen_loss = 0.9953099462573088, disc_loss = 0.001062214869957719
Trained batch 179 in epoch 5, gen_loss = 0.9955901841322581, disc_loss = 0.001064623430364817
Trained batch 180 in epoch 5, gen_loss = 0.9954540634023551, disc_loss = 0.0010672699097603127
Trained batch 181 in epoch 5, gen_loss = 0.9953875174889197, disc_loss = 0.0010692597791273658
Trained batch 182 in epoch 5, gen_loss = 0.9954186352224298, disc_loss = 0.0010696965817787018
Trained batch 183 in epoch 5, gen_loss = 0.995336983838807, disc_loss = 0.0010697264880708763
Trained batch 184 in epoch 5, gen_loss = 0.9953145993722452, disc_loss = 0.0010699328675400465
Trained batch 185 in epoch 5, gen_loss = 0.9953097473549587, disc_loss = 0.0010697248368962138
Trained batch 186 in epoch 5, gen_loss = 0.9952411160749548, disc_loss = 0.0010692625458135624
Trained batch 187 in epoch 5, gen_loss = 0.9951849535424658, disc_loss = 0.0010687098050418192
Trained batch 188 in epoch 5, gen_loss = 0.9951391992745576, disc_loss = 0.0010677688010098541
Trained batch 189 in epoch 5, gen_loss = 0.9953879039538535, disc_loss = 0.001066942520801125
Trained batch 190 in epoch 5, gen_loss = 0.9952545702769494, disc_loss = 0.00106690151550495
Trained batch 191 in epoch 5, gen_loss = 0.9953447207808495, disc_loss = 0.0010689911267339387
Trained batch 192 in epoch 5, gen_loss = 0.9952115397996854, disc_loss = 0.001072817526539363
Trained batch 193 in epoch 5, gen_loss = 0.9950168793348922, disc_loss = 0.0010782254668679951
Trained batch 194 in epoch 5, gen_loss = 0.9949571487231132, disc_loss = 0.0010857155174912455
Trained batch 195 in epoch 5, gen_loss = 0.9949137133603193, disc_loss = 0.0010947788486729984
Trained batch 196 in epoch 5, gen_loss = 0.9950842678849467, disc_loss = 0.0011030152251856487
Trained batch 197 in epoch 5, gen_loss = 0.9949611025025146, disc_loss = 0.0011081899164392698
Trained batch 198 in epoch 5, gen_loss = 0.9949440396011774, disc_loss = 0.0011103474837786346
Trained batch 199 in epoch 5, gen_loss = 0.9948873373866082, disc_loss = 0.0011105934919032733
Trained batch 200 in epoch 5, gen_loss = 0.9950420723032596, disc_loss = 0.0011103995981572928
Trained batch 201 in epoch 5, gen_loss = 0.9948006747382703, disc_loss = 0.0011089203259988347
Trained batch 202 in epoch 5, gen_loss = 0.9947397024760692, disc_loss = 0.0011065168229672654
Trained batch 203 in epoch 5, gen_loss = 0.9949760001664069, disc_loss = 0.001104080620565333
Testing Epoch 5

Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9871982336044312, disc_loss = 0.0005288072279654443
Trained batch 1 in epoch 6, gen_loss = 0.9828948080539703, disc_loss = 0.0005360736104194075
Trained batch 2 in epoch 6, gen_loss = 0.9716009497642517, disc_loss = 0.0005485758689853052
Trained batch 3 in epoch 6, gen_loss = 0.974394828081131, disc_loss = 0.0005524461303139105
Trained batch 4 in epoch 6, gen_loss = 0.9771791934967041, disc_loss = 0.0005520156119018793
Trained batch 5 in epoch 6, gen_loss = 0.973659743865331, disc_loss = 0.0005373415964034697
Trained batch 6 in epoch 6, gen_loss = 0.9807018637657166, disc_loss = 0.0005362206138670444
Trained batch 7 in epoch 6, gen_loss = 0.9737826213240623, disc_loss = 0.0005452586119645275
Trained batch 8 in epoch 6, gen_loss = 0.9742549790276421, disc_loss = 0.0005569891331510411
Trained batch 9 in epoch 6, gen_loss = 0.9881441116333007, disc_loss = 0.0006049489369615912
Trained batch 10 in epoch 6, gen_loss = 0.9869486039335077, disc_loss = 0.0006467563057826324
Trained batch 11 in epoch 6, gen_loss = 0.9857998937368393, disc_loss = 0.0006707879074383527
Trained batch 12 in epoch 6, gen_loss = 0.9850037143780634, disc_loss = 0.0006891542490428457
Trained batch 13 in epoch 6, gen_loss = 0.9909562000206539, disc_loss = 0.0007269785356973964
Trained batch 14 in epoch 6, gen_loss = 0.9928290486335755, disc_loss = 0.0007653972832486033
Trained batch 15 in epoch 6, gen_loss = 0.9922386258840561, disc_loss = 0.000800312016508542
Trained batch 16 in epoch 6, gen_loss = 0.9936585847069236, disc_loss = 0.0008231767809347195
Trained batch 17 in epoch 6, gen_loss = 0.9933933781252967, disc_loss = 0.0008296570061550786
Trained batch 18 in epoch 6, gen_loss = 0.9954219962421217, disc_loss = 0.0008279703018304549
Trained batch 19 in epoch 6, gen_loss = 0.9966941922903061, disc_loss = 0.0008174232294550166
Trained batch 20 in epoch 6, gen_loss = 0.995636693068913, disc_loss = 0.000804190984040144
Trained batch 21 in epoch 6, gen_loss = 0.9940036237239838, disc_loss = 0.0007917387199334123
Trained batch 22 in epoch 6, gen_loss = 0.9924367122028185, disc_loss = 0.0007770885814629171
Trained batch 23 in epoch 6, gen_loss = 0.9951946164170901, disc_loss = 0.0007631334422815902
Trained batch 24 in epoch 6, gen_loss = 0.9955161738395691, disc_loss = 0.000752721184398979
Trained batch 25 in epoch 6, gen_loss = 0.9955303485576923, disc_loss = 0.000753440305393619
Trained batch 26 in epoch 6, gen_loss = 0.9939117210882681, disc_loss = 0.0007659698409649233
Trained batch 27 in epoch 6, gen_loss = 0.9937635021550315, disc_loss = 0.0007877337567541483
Trained batch 28 in epoch 6, gen_loss = 0.9938357472419739, disc_loss = 0.0008034325176689388
Trained batch 29 in epoch 6, gen_loss = 0.9947394033273061, disc_loss = 0.0008040667104069144
Trained batch 30 in epoch 6, gen_loss = 0.9944893102492055, disc_loss = 0.0007925566488636598
Trained batch 31 in epoch 6, gen_loss = 0.9931625984609127, disc_loss = 0.0007764056745145353
Trained batch 32 in epoch 6, gen_loss = 0.9942573634060946, disc_loss = 0.0007679245115441242
Trained batch 33 in epoch 6, gen_loss = 0.9934049055856817, disc_loss = 0.0007640469369053951
Trained batch 34 in epoch 6, gen_loss = 0.9932899287768773, disc_loss = 0.0007636940115064915
Trained batch 35 in epoch 6, gen_loss = 0.9931428366237216, disc_loss = 0.0007678609828063701
Trained batch 36 in epoch 6, gen_loss = 0.9937465319762359, disc_loss = 0.0007698702967310375
Trained batch 37 in epoch 6, gen_loss = 0.9937564322822973, disc_loss = 0.0007728468021684277
Trained batch 38 in epoch 6, gen_loss = 0.9936582721196688, disc_loss = 0.0007723083694238598
Trained batch 39 in epoch 6, gen_loss = 0.9945200100541115, disc_loss = 0.0007697064655076246
Trained batch 40 in epoch 6, gen_loss = 0.9947644602961656, disc_loss = 0.0007629406818745249
Trained batch 41 in epoch 6, gen_loss = 0.9945590311572665, disc_loss = 0.0007555479110340544
Trained batch 42 in epoch 6, gen_loss = 0.9941120771474616, disc_loss = 0.0007548242378276014
Trained batch 43 in epoch 6, gen_loss = 0.9947282631288875, disc_loss = 0.0007571322752152231
Trained batch 44 in epoch 6, gen_loss = 0.9949112084176805, disc_loss = 0.0007605341424803352
Trained batch 45 in epoch 6, gen_loss = 0.9941960456578628, disc_loss = 0.0007694319033559979
Trained batch 46 in epoch 6, gen_loss = 0.9944074597764523, disc_loss = 0.0007823859273327238
Trained batch 47 in epoch 6, gen_loss = 0.9941089153289795, disc_loss = 0.0007915448131825542
Trained batch 48 in epoch 6, gen_loss = 0.9937335058134429, disc_loss = 0.0007924202464910566
Trained batch 49 in epoch 6, gen_loss = 0.9937370848655701, disc_loss = 0.0007884705910691991
Trained batch 50 in epoch 6, gen_loss = 0.9930509457401201, disc_loss = 0.0007857625771030857
Trained batch 51 in epoch 6, gen_loss = 0.9938991058331269, disc_loss = 0.0007879071664109898
Trained batch 52 in epoch 6, gen_loss = 0.9929991735602325, disc_loss = 0.0007948567678949814
Trained batch 53 in epoch 6, gen_loss = 0.9927553744227798, disc_loss = 0.0008048110461526516
Trained batch 54 in epoch 6, gen_loss = 0.992961195382205, disc_loss = 0.0008118190067100592
Trained batch 55 in epoch 6, gen_loss = 0.9928538586412158, disc_loss = 0.0008214052800862451
Trained batch 56 in epoch 6, gen_loss = 0.9931747955188417, disc_loss = 0.0008367727609686227
Trained batch 57 in epoch 6, gen_loss = 0.9935794102734533, disc_loss = 0.0008534739975183239
Trained batch 58 in epoch 6, gen_loss = 0.9935374835790214, disc_loss = 0.0008637696308265361
Trained batch 59 in epoch 6, gen_loss = 0.9936867048343022, disc_loss = 0.0008651773818807366
Trained batch 60 in epoch 6, gen_loss = 0.9931330456108344, disc_loss = 0.0008613259543962472
Trained batch 61 in epoch 6, gen_loss = 0.9934074503760184, disc_loss = 0.0008557088266599983
Trained batch 62 in epoch 6, gen_loss = 0.9930902672192407, disc_loss = 0.000848409607045589
Trained batch 63 in epoch 6, gen_loss = 0.9934639995917678, disc_loss = 0.0008424116026617412
Trained batch 64 in epoch 6, gen_loss = 0.9925644480265103, disc_loss = 0.000837406331153873
Trained batch 65 in epoch 6, gen_loss = 0.9922618197672295, disc_loss = 0.0008334744422675365
Trained batch 66 in epoch 6, gen_loss = 0.9927957734065269, disc_loss = 0.0008366592319633589
Trained batch 67 in epoch 6, gen_loss = 0.9929989997078391, disc_loss = 0.0008530586496550206
Trained batch 68 in epoch 6, gen_loss = 0.9929271150326383, disc_loss = 0.0008771092216720454
Trained batch 69 in epoch 6, gen_loss = 0.992897720847811, disc_loss = 0.0009065321584265413
Trained batch 70 in epoch 6, gen_loss = 0.9926489641968633, disc_loss = 0.0009301908377354676
Trained batch 71 in epoch 6, gen_loss = 0.9930803494320976, disc_loss = 0.0009501350032223854
Trained batch 72 in epoch 6, gen_loss = 0.992640734535374, disc_loss = 0.0009678588029513875
Trained batch 73 in epoch 6, gen_loss = 0.9925967011902783, disc_loss = 0.0009834046913719911
Trained batch 74 in epoch 6, gen_loss = 0.9925451985994975, disc_loss = 0.00099382822906288
Trained batch 75 in epoch 6, gen_loss = 0.9929059438015285, disc_loss = 0.000998786185319707
Trained batch 76 in epoch 6, gen_loss = 0.9925310681392621, disc_loss = 0.0009974789259163059
Trained batch 77 in epoch 6, gen_loss = 0.993013715896851, disc_loss = 0.000992520923878496
Trained batch 78 in epoch 6, gen_loss = 0.9931197868117804, disc_loss = 0.0009857154855817038
Trained batch 79 in epoch 6, gen_loss = 0.9926732003688812, disc_loss = 0.0009786610164155718
Trained batch 80 in epoch 6, gen_loss = 0.9927763055872034, disc_loss = 0.0009703751054109523
Trained batch 81 in epoch 6, gen_loss = 0.9927366404998593, disc_loss = 0.0009637748064450556
Trained batch 82 in epoch 6, gen_loss = 0.9924013944993536, disc_loss = 0.0009579943350645298
Trained batch 83 in epoch 6, gen_loss = 0.9921004360630399, disc_loss = 0.0009517950193618336
Trained batch 84 in epoch 6, gen_loss = 0.9925124126322129, disc_loss = 0.0009504907541935715
Trained batch 85 in epoch 6, gen_loss = 0.9923956671426463, disc_loss = 0.0009547111650706853
Trained batch 86 in epoch 6, gen_loss = 0.9922954768970095, disc_loss = 0.0009568143530946825
Trained batch 87 in epoch 6, gen_loss = 0.9926064535975456, disc_loss = 0.0009581870435795281
Trained batch 88 in epoch 6, gen_loss = 0.9925888167338425, disc_loss = 0.0009599543798563144
Trained batch 89 in epoch 6, gen_loss = 0.9925375229782528, disc_loss = 0.0009654084644151024
Trained batch 90 in epoch 6, gen_loss = 0.9925069926859258, disc_loss = 0.0009689662783984914
Trained batch 91 in epoch 6, gen_loss = 0.9921867406886556, disc_loss = 0.0009706929391224706
Trained batch 92 in epoch 6, gen_loss = 0.9921267699169857, disc_loss = 0.0009710859298901332
Trained batch 93 in epoch 6, gen_loss = 0.9924051444581214, disc_loss = 0.0009709415964143192
Trained batch 94 in epoch 6, gen_loss = 0.9922868753734387, disc_loss = 0.0009699967031146547
Trained batch 95 in epoch 6, gen_loss = 0.9926065454880396, disc_loss = 0.0009694718449585101
Trained batch 96 in epoch 6, gen_loss = 0.9925485609732952, disc_loss = 0.0009691124219692207
Trained batch 97 in epoch 6, gen_loss = 0.9925416628925168, disc_loss = 0.0009687380079412833
Trained batch 98 in epoch 6, gen_loss = 0.9922568322432161, disc_loss = 0.000969365901475998
Trained batch 99 in epoch 6, gen_loss = 0.9925259917974472, disc_loss = 0.0009721093837288208
Trained batch 100 in epoch 6, gen_loss = 0.9924553314057907, disc_loss = 0.0009767230047434015
Trained batch 101 in epoch 6, gen_loss = 0.9923793883884654, disc_loss = 0.0009836091881951171
Trained batch 102 in epoch 6, gen_loss = 0.9926683081006541, disc_loss = 0.000990781361447394
Trained batch 103 in epoch 6, gen_loss = 0.9924658158650765, disc_loss = 0.000997685742521963
Trained batch 104 in epoch 6, gen_loss = 0.9925037032081967, disc_loss = 0.00100358684929753
Trained batch 105 in epoch 6, gen_loss = 0.992423008635359, disc_loss = 0.0010063114099946961
Trained batch 106 in epoch 6, gen_loss = 0.992290178191996, disc_loss = 0.0010075656564962816
Trained batch 107 in epoch 6, gen_loss = 0.9917414519521925, disc_loss = 0.0010075954889072346
Trained batch 108 in epoch 6, gen_loss = 0.9914839869245476, disc_loss = 0.0010065986289441962
Trained batch 109 in epoch 6, gen_loss = 0.9915550817142833, disc_loss = 0.0010049066540721635
Trained batch 110 in epoch 6, gen_loss = 0.9919000359268876, disc_loss = 0.0010041303553530393
Trained batch 111 in epoch 6, gen_loss = 0.9916206832442965, disc_loss = 0.0010064614806261879
Trained batch 112 in epoch 6, gen_loss = 0.9912926032479885, disc_loss = 0.0010101203500206656
Trained batch 113 in epoch 6, gen_loss = 0.9916547139485677, disc_loss = 0.0010110657489062042
Trained batch 114 in epoch 6, gen_loss = 0.9916706587957299, disc_loss = 0.0010086270917267742
Trained batch 115 in epoch 6, gen_loss = 0.9917321616205675, disc_loss = 0.0010074215907511174
Trained batch 116 in epoch 6, gen_loss = 0.9916228947476444, disc_loss = 0.0010065820725320273
Trained batch 117 in epoch 6, gen_loss = 0.9914205533973242, disc_loss = 0.001004705154504706
Trained batch 118 in epoch 6, gen_loss = 0.9916486695033162, disc_loss = 0.001000607923551721
Trained batch 119 in epoch 6, gen_loss = 0.9917296037077904, disc_loss = 0.0009955134145760288
Trained batch 120 in epoch 6, gen_loss = 0.991355120150511, disc_loss = 0.0009914931017628386
Trained batch 121 in epoch 6, gen_loss = 0.9914673083141202, disc_loss = 0.0009930721316181246
Trained batch 122 in epoch 6, gen_loss = 0.9913946172086204, disc_loss = 0.0009966837564044126
Trained batch 123 in epoch 6, gen_loss = 0.99191265000451, disc_loss = 0.0010040263746744923
Trained batch 124 in epoch 6, gen_loss = 0.9918240690231324, disc_loss = 0.0010221050046384334
Trained batch 125 in epoch 6, gen_loss = 0.992183350381397, disc_loss = 0.0010523798779421855
Trained batch 126 in epoch 6, gen_loss = 0.9921981598448566, disc_loss = 0.0010837008149957093
Trained batch 127 in epoch 6, gen_loss = 0.9923424194566905, disc_loss = 0.0011078763636760414
Trained batch 128 in epoch 6, gen_loss = 0.9919501889583676, disc_loss = 0.001123536439511434
Trained batch 129 in epoch 6, gen_loss = 0.9920745817514566, disc_loss = 0.0011333175522920032
Trained batch 130 in epoch 6, gen_loss = 0.9918474068168466, disc_loss = 0.001138815403923051
Trained batch 131 in epoch 6, gen_loss = 0.9915883640448252, disc_loss = 0.0011418503647402042
Trained batch 132 in epoch 6, gen_loss = 0.9913216690371808, disc_loss = 0.0011477307285203185
Trained batch 133 in epoch 6, gen_loss = 0.9914399888088454, disc_loss = 0.001159006178052401
Trained batch 134 in epoch 6, gen_loss = 0.9915180740533052, disc_loss = 0.0011706030625780975
Trained batch 135 in epoch 6, gen_loss = 0.9914162702420178, disc_loss = 0.0011744308285415173
Trained batch 136 in epoch 6, gen_loss = 0.9915698897229493, disc_loss = 0.0011724494074736415
Trained batch 137 in epoch 6, gen_loss = 0.9917089559029841, disc_loss = 0.0011680343089645485
Trained batch 138 in epoch 6, gen_loss = 0.9914753424177924, disc_loss = 0.0011645698381366758
Trained batch 139 in epoch 6, gen_loss = 0.9918810048273632, disc_loss = 0.0011622391894759079
Trained batch 140 in epoch 6, gen_loss = 0.9918471338055658, disc_loss = 0.001158631718403772
Trained batch 141 in epoch 6, gen_loss = 0.9918923210090315, disc_loss = 0.0011537378085334457
Trained batch 142 in epoch 6, gen_loss = 0.9919390711751017, disc_loss = 0.0011493158907307168
Trained batch 143 in epoch 6, gen_loss = 0.9920515409774251, disc_loss = 0.0011454373086760622
Trained batch 144 in epoch 6, gen_loss = 0.9918551650540582, disc_loss = 0.001141835474770452
Trained batch 145 in epoch 6, gen_loss = 0.9914368129756352, disc_loss = 0.001138299271226733
Trained batch 146 in epoch 6, gen_loss = 0.9915362118052787, disc_loss = 0.001134999679856091
Trained batch 147 in epoch 6, gen_loss = 0.9913108312600368, disc_loss = 0.0011320870062509376
Trained batch 148 in epoch 6, gen_loss = 0.9912501049521786, disc_loss = 0.0011283233322300042
Trained batch 149 in epoch 6, gen_loss = 0.9915533967812856, disc_loss = 0.0011254872775559002
Trained batch 150 in epoch 6, gen_loss = 0.9915342757243983, disc_loss = 0.0011221805002635948
Trained batch 151 in epoch 6, gen_loss = 0.9913922842395934, disc_loss = 0.0011172843614507368
Trained batch 152 in epoch 6, gen_loss = 0.991615475782382, disc_loss = 0.0011131561116248466
Trained batch 153 in epoch 6, gen_loss = 0.9918276114123208, disc_loss = 0.00110974394816107
Trained batch 154 in epoch 6, gen_loss = 0.9917549202519078, disc_loss = 0.001106707787051076
Trained batch 155 in epoch 6, gen_loss = 0.9915062265518384, disc_loss = 0.0011026388599883574
Trained batch 156 in epoch 6, gen_loss = 0.9916594977591447, disc_loss = 0.001098313557568368
Trained batch 157 in epoch 6, gen_loss = 0.9915473329115517, disc_loss = 0.0010937931879255566
Trained batch 158 in epoch 6, gen_loss = 0.9917603922340105, disc_loss = 0.0010896272308986822
Trained batch 159 in epoch 6, gen_loss = 0.9915855247527361, disc_loss = 0.001085994978529925
Trained batch 160 in epoch 6, gen_loss = 0.9914872042881036, disc_loss = 0.0010836930095539168
Trained batch 161 in epoch 6, gen_loss = 0.9912861548824075, disc_loss = 0.0010819481191711132
Trained batch 162 in epoch 6, gen_loss = 0.9911851678157877, disc_loss = 0.0010803513158544145
Trained batch 163 in epoch 6, gen_loss = 0.9909688714073925, disc_loss = 0.001077626728014055
Trained batch 164 in epoch 6, gen_loss = 0.9910885507410223, disc_loss = 0.0010768749311947348
Trained batch 165 in epoch 6, gen_loss = 0.9912969965532602, disc_loss = 0.0010798002047259472
Trained batch 166 in epoch 6, gen_loss = 0.9912276207329984, disc_loss = 0.0010833549130259048
Trained batch 167 in epoch 6, gen_loss = 0.9914538501983597, disc_loss = 0.0010855084489906272
Trained batch 168 in epoch 6, gen_loss = 0.991209970776146, disc_loss = 0.0010844733097284658
Trained batch 169 in epoch 6, gen_loss = 0.9913964232977699, disc_loss = 0.0010823893790503087
Trained batch 170 in epoch 6, gen_loss = 0.9911881897881715, disc_loss = 0.0010806479345263685
Trained batch 171 in epoch 6, gen_loss = 0.9911512950825137, disc_loss = 0.0010778280335470363
Trained batch 172 in epoch 6, gen_loss = 0.9908979900310494, disc_loss = 0.0010740721865417167
Trained batch 173 in epoch 6, gen_loss = 0.9908365836773796, disc_loss = 0.0010697332277075098
Trained batch 174 in epoch 6, gen_loss = 0.9906792960848128, disc_loss = 0.001065242095085393
Trained batch 175 in epoch 6, gen_loss = 0.9905840111049738, disc_loss = 0.0010614118390631947
Trained batch 176 in epoch 6, gen_loss = 0.9902592584238215, disc_loss = 0.0010587713749563626
Trained batch 177 in epoch 6, gen_loss = 0.990264121401176, disc_loss = 0.0010607723163681502
Trained batch 178 in epoch 6, gen_loss = 0.9901908093324586, disc_loss = 0.0010646771140105232
Trained batch 179 in epoch 6, gen_loss = 0.9904416094223658, disc_loss = 0.001067262891188471
Trained batch 180 in epoch 6, gen_loss = 0.9905047479255423, disc_loss = 0.0010677172541258167
Trained batch 181 in epoch 6, gen_loss = 0.9903992787822262, disc_loss = 0.0010679358396433539
Trained batch 182 in epoch 6, gen_loss = 0.9904864726822233, disc_loss = 0.001067853742660802
Trained batch 183 in epoch 6, gen_loss = 0.9901842811833257, disc_loss = 0.0010668805223995942
Trained batch 184 in epoch 6, gen_loss = 0.9902437106983082, disc_loss = 0.0010652899886859028
Trained batch 185 in epoch 6, gen_loss = 0.990080964180731, disc_loss = 0.00106316466718131
Trained batch 186 in epoch 6, gen_loss = 0.9901204309998987, disc_loss = 0.0010622913238248803
Trained batch 187 in epoch 6, gen_loss = 0.9901782772008408, disc_loss = 0.001062864096503348
Trained batch 188 in epoch 6, gen_loss = 0.990202699704145, disc_loss = 0.001062654519315671
Trained batch 189 in epoch 6, gen_loss = 0.9901936647139098, disc_loss = 0.0010614047997238997
Trained batch 190 in epoch 6, gen_loss = 0.9901684953280144, disc_loss = 0.0010591172192645556
Trained batch 191 in epoch 6, gen_loss = 0.9902471179763476, disc_loss = 0.0010569897440291243
Trained batch 192 in epoch 6, gen_loss = 0.9903550401252786, disc_loss = 0.001054937955489083
Trained batch 193 in epoch 6, gen_loss = 0.9903739319019711, disc_loss = 0.00105203714488151
Trained batch 194 in epoch 6, gen_loss = 0.9903101254732181, disc_loss = 0.0010488490568091853
Trained batch 195 in epoch 6, gen_loss = 0.9904114914183714, disc_loss = 0.0010457625342366686
Trained batch 196 in epoch 6, gen_loss = 0.9902411469348191, disc_loss = 0.001043515172633366
Trained batch 197 in epoch 6, gen_loss = 0.9902441044046422, disc_loss = 0.0010437132697199668
Trained batch 198 in epoch 6, gen_loss = 0.990131554292075, disc_loss = 0.0010456825918330806
Trained batch 199 in epoch 6, gen_loss = 0.9902966046333312, disc_loss = 0.0010461231498629785
Trained batch 200 in epoch 6, gen_loss = 0.9903262657905693, disc_loss = 0.0010445568208415894
Trained batch 201 in epoch 6, gen_loss = 0.9901959137751324, disc_loss = 0.001042093789449312
Trained batch 202 in epoch 6, gen_loss = 0.9902355709099417, disc_loss = 0.0010386021673596771
Trained batch 203 in epoch 6, gen_loss = 0.9901964094708947, disc_loss = 0.001034492195507411
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.9787375926971436, disc_loss = 0.00019857019651681185
Trained batch 1 in epoch 7, gen_loss = 0.9844231009483337, disc_loss = 0.00022241448459681123
Trained batch 2 in epoch 7, gen_loss = 0.9900901317596436, disc_loss = 0.00027686716445411247
Trained batch 3 in epoch 7, gen_loss = 0.9864591509103775, disc_loss = 0.0003781541745411232
Trained batch 4 in epoch 7, gen_loss = 0.9863633394241333, disc_loss = 0.00045932556968182326
Trained batch 5 in epoch 7, gen_loss = 0.9872591296831766, disc_loss = 0.00047131852867702645
Trained batch 6 in epoch 7, gen_loss = 0.9794893264770508, disc_loss = 0.0004448762795488749
Trained batch 7 in epoch 7, gen_loss = 0.9821317791938782, disc_loss = 0.0004293839665479027
Trained batch 8 in epoch 7, gen_loss = 0.9829254945119222, disc_loss = 0.0004319211713866227
Trained batch 9 in epoch 7, gen_loss = 0.9823296904563904, disc_loss = 0.000436102322419174
Trained batch 10 in epoch 7, gen_loss = 0.9818366007371382, disc_loss = 0.0004427959343460812
Trained batch 11 in epoch 7, gen_loss = 0.9769941320021948, disc_loss = 0.00045811155723640695
Trained batch 12 in epoch 7, gen_loss = 0.9778897441350497, disc_loss = 0.0005124561967722212
Trained batch 13 in epoch 7, gen_loss = 0.9812010228633881, disc_loss = 0.0005777069912125755
Trained batch 14 in epoch 7, gen_loss = 0.9835690061251322, disc_loss = 0.000621723630077516
Trained batch 15 in epoch 7, gen_loss = 0.9832437038421631, disc_loss = 0.0006483101878984598
Trained batch 16 in epoch 7, gen_loss = 0.982456203769235, disc_loss = 0.0006545637580155231
Trained batch 17 in epoch 7, gen_loss = 0.9810074468453726, disc_loss = 0.0006569856308892162
Trained batch 18 in epoch 7, gen_loss = 0.9775217426450629, disc_loss = 0.0006688793333810999
Trained batch 19 in epoch 7, gen_loss = 0.9790421932935714, disc_loss = 0.0006898557403474115
Trained batch 20 in epoch 7, gen_loss = 0.9804834496407282, disc_loss = 0.0007104537923753794
Trained batch 21 in epoch 7, gen_loss = 0.9797138598832217, disc_loss = 0.0007307930645765737
Trained batch 22 in epoch 7, gen_loss = 0.9797152902769006, disc_loss = 0.0007531949832691284
Trained batch 23 in epoch 7, gen_loss = 0.9790113394459089, disc_loss = 0.0007706381523651847
Trained batch 24 in epoch 7, gen_loss = 0.979793746471405, disc_loss = 0.0007900291995611042
Trained batch 25 in epoch 7, gen_loss = 0.9790806426451757, disc_loss = 0.000803924979453978
Trained batch 26 in epoch 7, gen_loss = 0.9789551010838261, disc_loss = 0.0008097524804287348
Trained batch 27 in epoch 7, gen_loss = 0.9785589533192771, disc_loss = 0.0008152323664814633
Trained batch 28 in epoch 7, gen_loss = 0.9789244018751999, disc_loss = 0.000823057905955497
Trained batch 29 in epoch 7, gen_loss = 0.9795795122782389, disc_loss = 0.000827305043155017
Trained batch 30 in epoch 7, gen_loss = 0.9802203409133419, disc_loss = 0.0008299225807986072
Trained batch 31 in epoch 7, gen_loss = 0.9803349897265434, disc_loss = 0.0008335673292094725
Trained batch 32 in epoch 7, gen_loss = 0.9812190207568082, disc_loss = 0.0008410068191799589
Trained batch 33 in epoch 7, gen_loss = 0.9808972986305461, disc_loss = 0.0008492377194617054
Trained batch 34 in epoch 7, gen_loss = 0.9815176606178284, disc_loss = 0.0008496967435348779
Trained batch 35 in epoch 7, gen_loss = 0.9801485455698438, disc_loss = 0.0008430622813951535
Trained batch 36 in epoch 7, gen_loss = 0.9801092631108052, disc_loss = 0.0008364045462331962
Trained batch 37 in epoch 7, gen_loss = 0.9795501890935396, disc_loss = 0.000831610870112567
Trained batch 38 in epoch 7, gen_loss = 0.9793753822644552, disc_loss = 0.0008230283938479634
Trained batch 39 in epoch 7, gen_loss = 0.9797269105911255, disc_loss = 0.0008136261603794992
Trained batch 40 in epoch 7, gen_loss = 0.9800890262533979, disc_loss = 0.0008078496335301457
Trained batch 41 in epoch 7, gen_loss = 0.9793557538872674, disc_loss = 0.0008085591599367382
Trained batch 42 in epoch 7, gen_loss = 0.9792191136715024, disc_loss = 0.0008076661547949148
Trained batch 43 in epoch 7, gen_loss = 0.9793845347382806, disc_loss = 0.0008055635566548021
Trained batch 44 in epoch 7, gen_loss = 0.9794150922033522, disc_loss = 0.0008003070575392081
Trained batch 45 in epoch 7, gen_loss = 0.9796977950179059, disc_loss = 0.0007966950209305177
Trained batch 46 in epoch 7, gen_loss = 0.980253627959718, disc_loss = 0.0007953011106323213
Trained batch 47 in epoch 7, gen_loss = 0.9802065218488375, disc_loss = 0.0007924761363634995
Trained batch 48 in epoch 7, gen_loss = 0.9804006316223923, disc_loss = 0.0007886343210346388
Trained batch 49 in epoch 7, gen_loss = 0.9802699673175812, disc_loss = 0.0007866257044952362
Trained batch 50 in epoch 7, gen_loss = 0.9802708532295975, disc_loss = 0.000784798919031506
Trained batch 51 in epoch 7, gen_loss = 0.9805412063231835, disc_loss = 0.0007855176540593115
Trained batch 52 in epoch 7, gen_loss = 0.9810162197868779, disc_loss = 0.0007871246483739255
Trained batch 53 in epoch 7, gen_loss = 0.9815003430401837, disc_loss = 0.0007853918618315624
Trained batch 54 in epoch 7, gen_loss = 0.9811554236845537, disc_loss = 0.000780651865484701
Trained batch 55 in epoch 7, gen_loss = 0.9817319491079876, disc_loss = 0.000776070132685293
Trained batch 56 in epoch 7, gen_loss = 0.9820083369288528, disc_loss = 0.0007728304236048931
Trained batch 57 in epoch 7, gen_loss = 0.9817292649170448, disc_loss = 0.0007721171925117358
Trained batch 58 in epoch 7, gen_loss = 0.9820178423897695, disc_loss = 0.0007730814356009586
Trained batch 59 in epoch 7, gen_loss = 0.9821194291114808, disc_loss = 0.0007704772831251224
Trained batch 60 in epoch 7, gen_loss = 0.9821216688781488, disc_loss = 0.0007654943510118994
Trained batch 61 in epoch 7, gen_loss = 0.9827444495693329, disc_loss = 0.0007613133221316422
Trained batch 62 in epoch 7, gen_loss = 0.9827182330782451, disc_loss = 0.0007578044762975345
Trained batch 63 in epoch 7, gen_loss = 0.9827720616012812, disc_loss = 0.000753861844259518
Trained batch 64 in epoch 7, gen_loss = 0.9827148602559016, disc_loss = 0.0007505770078681123
Trained batch 65 in epoch 7, gen_loss = 0.9831759116866372, disc_loss = 0.0007513761295492507
Trained batch 66 in epoch 7, gen_loss = 0.9835700259279849, disc_loss = 0.000755789801356758
Trained batch 67 in epoch 7, gen_loss = 0.9830690455787322, disc_loss = 0.000756652644400567
Trained batch 68 in epoch 7, gen_loss = 0.9824613030406012, disc_loss = 0.0007546055995339555
Trained batch 69 in epoch 7, gen_loss = 0.9831889927387237, disc_loss = 0.0007534323256030412
Trained batch 70 in epoch 7, gen_loss = 0.9837312169477973, disc_loss = 0.0007568928277821766
Trained batch 71 in epoch 7, gen_loss = 0.9835833683609962, disc_loss = 0.0007633880704815965
Trained batch 72 in epoch 7, gen_loss = 0.9834353899302548, disc_loss = 0.0007631629223023121
Trained batch 73 in epoch 7, gen_loss = 0.9828999179440576, disc_loss = 0.0007599429239210597
Trained batch 74 in epoch 7, gen_loss = 0.9829654232660929, disc_loss = 0.0007584929446845005
Trained batch 75 in epoch 7, gen_loss = 0.9836794483034235, disc_loss = 0.0007596955620101653
Trained batch 76 in epoch 7, gen_loss = 0.9835533499717712, disc_loss = 0.0007602818360908997
Trained batch 77 in epoch 7, gen_loss = 0.9833925267060598, disc_loss = 0.0007595425797775626
Trained batch 78 in epoch 7, gen_loss = 0.982742207714274, disc_loss = 0.0007585047407494269
Trained batch 79 in epoch 7, gen_loss = 0.9819585330784321, disc_loss = 0.0007571222635306185
Trained batch 80 in epoch 7, gen_loss = 0.9815291512159654, disc_loss = 0.0007552381451845307
Trained batch 81 in epoch 7, gen_loss = 0.9816446464236189, disc_loss = 0.0007529214309193421
Trained batch 82 in epoch 7, gen_loss = 0.9813165363058987, disc_loss = 0.0007522553447437618
Trained batch 83 in epoch 7, gen_loss = 0.9814050829126721, disc_loss = 0.0007560857716487677
Trained batch 84 in epoch 7, gen_loss = 0.9813374077572542, disc_loss = 0.0007641155550064629
Trained batch 85 in epoch 7, gen_loss = 0.9819381257822347, disc_loss = 0.0007736607631370642
Trained batch 86 in epoch 7, gen_loss = 0.9814356599731007, disc_loss = 0.000780329671915856
Trained batch 87 in epoch 7, gen_loss = 0.981740533628247, disc_loss = 0.0007876647515248889
Trained batch 88 in epoch 7, gen_loss = 0.9822257603152414, disc_loss = 0.0007954774600364728
Trained batch 89 in epoch 7, gen_loss = 0.9825932443141937, disc_loss = 0.0008029837229211504
Trained batch 90 in epoch 7, gen_loss = 0.9825259610846803, disc_loss = 0.000812383669564132
Trained batch 91 in epoch 7, gen_loss = 0.9821121491815733, disc_loss = 0.0008266766080455652
Trained batch 92 in epoch 7, gen_loss = 0.9822468706356582, disc_loss = 0.0008505873287582309
Trained batch 93 in epoch 7, gen_loss = 0.9825914464098342, disc_loss = 0.0008784981975158518
Trained batch 94 in epoch 7, gen_loss = 0.9827745826620805, disc_loss = 0.0009023460305271376
Trained batch 95 in epoch 7, gen_loss = 0.9829439229021469, disc_loss = 0.0009173036053956215
Trained batch 96 in epoch 7, gen_loss = 0.9827410922837012, disc_loss = 0.0009227315838251877
Trained batch 97 in epoch 7, gen_loss = 0.9829383972956209, disc_loss = 0.0009249035754283814
Trained batch 98 in epoch 7, gen_loss = 0.9829373197122053, disc_loss = 0.000925820357591911
Trained batch 99 in epoch 7, gen_loss = 0.9827323549985886, disc_loss = 0.0009265875109122135
Trained batch 100 in epoch 7, gen_loss = 0.982888386391177, disc_loss = 0.0009279609095918402
Trained batch 101 in epoch 7, gen_loss = 0.9828426872982698, disc_loss = 0.0009295445248854402
Trained batch 102 in epoch 7, gen_loss = 0.982964530153182, disc_loss = 0.0009305800463285442
Trained batch 103 in epoch 7, gen_loss = 0.9832250068967159, disc_loss = 0.0009323955480515276
Trained batch 104 in epoch 7, gen_loss = 0.9834464635167803, disc_loss = 0.0009356595545319752
Trained batch 105 in epoch 7, gen_loss = 0.9838018906566331, disc_loss = 0.0009404469156782758
Trained batch 106 in epoch 7, gen_loss = 0.9838135832938079, disc_loss = 0.0009488925725661183
Trained batch 107 in epoch 7, gen_loss = 0.9835575140184827, disc_loss = 0.0009577109058564356
Trained batch 108 in epoch 7, gen_loss = 0.9831800455347114, disc_loss = 0.0009633251596690763
Trained batch 109 in epoch 7, gen_loss = 0.9834582355889407, disc_loss = 0.0009654978398678147
Trained batch 110 in epoch 7, gen_loss = 0.9837151696016123, disc_loss = 0.0009633160339404099
Trained batch 111 in epoch 7, gen_loss = 0.9835315894867692, disc_loss = 0.0009592810246041543
Trained batch 112 in epoch 7, gen_loss = 0.9838646718886046, disc_loss = 0.0009553959035310498
Trained batch 113 in epoch 7, gen_loss = 0.9835193371563627, disc_loss = 0.0009508026177124856
Trained batch 114 in epoch 7, gen_loss = 0.9835083355074343, disc_loss = 0.0009459410811794678
Trained batch 115 in epoch 7, gen_loss = 0.983284169743801, disc_loss = 0.0009414123555400473
Trained batch 116 in epoch 7, gen_loss = 0.9833152986999251, disc_loss = 0.0009370726686464543
Trained batch 117 in epoch 7, gen_loss = 0.9831462416608455, disc_loss = 0.0009336903187154271
Trained batch 118 in epoch 7, gen_loss = 0.9828969966463682, disc_loss = 0.0009329626155711961
Trained batch 119 in epoch 7, gen_loss = 0.9826810181140899, disc_loss = 0.0009345494448401345
Trained batch 120 in epoch 7, gen_loss = 0.9826827187183474, disc_loss = 0.0009392273101439961
Trained batch 121 in epoch 7, gen_loss = 0.9829780625515296, disc_loss = 0.0009443851719327942
Trained batch 122 in epoch 7, gen_loss = 0.9829151858159197, disc_loss = 0.0009443033888852754
Trained batch 123 in epoch 7, gen_loss = 0.9833328488372988, disc_loss = 0.0009408590760299816
Trained batch 124 in epoch 7, gen_loss = 0.9833651342391968, disc_loss = 0.0009353189915418625
Trained batch 125 in epoch 7, gen_loss = 0.9835208029974074, disc_loss = 0.0009295977566609277
Trained batch 126 in epoch 7, gen_loss = 0.9834044603850898, disc_loss = 0.0009245037733243529
Trained batch 127 in epoch 7, gen_loss = 0.9831063053570688, disc_loss = 0.0009193186358515959
Trained batch 128 in epoch 7, gen_loss = 0.9828025338261627, disc_loss = 0.0009138568149033082
Trained batch 129 in epoch 7, gen_loss = 0.9830282674385951, disc_loss = 0.000908735159072631
Trained batch 130 in epoch 7, gen_loss = 0.9833675199792585, disc_loss = 0.0009039322605031322
Trained batch 131 in epoch 7, gen_loss = 0.983546516660488, disc_loss = 0.0009007642280873066
Trained batch 132 in epoch 7, gen_loss = 0.9835155077446672, disc_loss = 0.000899962143761568
Trained batch 133 in epoch 7, gen_loss = 0.9832159356394811, disc_loss = 0.0008996175058010562
Trained batch 134 in epoch 7, gen_loss = 0.9829257157113817, disc_loss = 0.0008993428229587153
Trained batch 135 in epoch 7, gen_loss = 0.9829335103140158, disc_loss = 0.0009000452224855133
Trained batch 136 in epoch 7, gen_loss = 0.9829196272975337, disc_loss = 0.000900268311128802
Trained batch 137 in epoch 7, gen_loss = 0.9827580495157103, disc_loss = 0.0008980216637913448
Trained batch 138 in epoch 7, gen_loss = 0.9825380131495085, disc_loss = 0.0008942443556478917
Trained batch 139 in epoch 7, gen_loss = 0.9823504677840642, disc_loss = 0.0008911136366285584
Trained batch 140 in epoch 7, gen_loss = 0.9823752789632648, disc_loss = 0.0008892746532215334
Trained batch 141 in epoch 7, gen_loss = 0.9821620642299383, disc_loss = 0.0008867736683435358
Trained batch 142 in epoch 7, gen_loss = 0.9823271994824176, disc_loss = 0.0008833534484183729
Trained batch 143 in epoch 7, gen_loss = 0.9825901521576775, disc_loss = 0.0008800242274244536
Trained batch 144 in epoch 7, gen_loss = 0.982699455474985, disc_loss = 0.000876983046503577
Trained batch 145 in epoch 7, gen_loss = 0.9828373287638573, disc_loss = 0.0008749445173323269
Trained batch 146 in epoch 7, gen_loss = 0.9829860297190088, disc_loss = 0.0008740893555813006
Trained batch 147 in epoch 7, gen_loss = 0.9831192594122242, disc_loss = 0.0008723624189253707
Trained batch 148 in epoch 7, gen_loss = 0.983153101181824, disc_loss = 0.0008714840160065562
Trained batch 149 in epoch 7, gen_loss = 0.9833566709359487, disc_loss = 0.0008741167479699167
Trained batch 150 in epoch 7, gen_loss = 0.9833551846592632, disc_loss = 0.0008802608135256558
Trained batch 151 in epoch 7, gen_loss = 0.9831944233492801, disc_loss = 0.0008880568574999128
Trained batch 152 in epoch 7, gen_loss = 0.9831690546733881, disc_loss = 0.0008919816354808574
Trained batch 153 in epoch 7, gen_loss = 0.9832870255817067, disc_loss = 0.0008907742022919203
Trained batch 154 in epoch 7, gen_loss = 0.9834214848856773, disc_loss = 0.0008878872745798059
Trained batch 155 in epoch 7, gen_loss = 0.9832660326590905, disc_loss = 0.0008872275447617703
Trained batch 156 in epoch 7, gen_loss = 0.9833144537962166, disc_loss = 0.0008897773068209896
Trained batch 157 in epoch 7, gen_loss = 0.9832731202433381, disc_loss = 0.0008913018797631847
Trained batch 158 in epoch 7, gen_loss = 0.9836351635321131, disc_loss = 0.0008906973427953784
Trained batch 159 in epoch 7, gen_loss = 0.9839952509850264, disc_loss = 0.0008890403762961796
Trained batch 160 in epoch 7, gen_loss = 0.9841388852699943, disc_loss = 0.0008879902741693897
Trained batch 161 in epoch 7, gen_loss = 0.9841704482649579, disc_loss = 0.0008883703440567191
Trained batch 162 in epoch 7, gen_loss = 0.9840328828688779, disc_loss = 0.0008908294290739849
Trained batch 163 in epoch 7, gen_loss = 0.9843317128536178, disc_loss = 0.0008966634959506337
Trained batch 164 in epoch 7, gen_loss = 0.98444387587634, disc_loss = 0.0009044797301722803
Trained batch 165 in epoch 7, gen_loss = 0.9846468607345259, disc_loss = 0.0009123510639891533
Trained batch 166 in epoch 7, gen_loss = 0.9845248514306759, disc_loss = 0.0009170378145133006
Trained batch 167 in epoch 7, gen_loss = 0.9845024975282806, disc_loss = 0.000920129609464008
Trained batch 168 in epoch 7, gen_loss = 0.9847167444652354, disc_loss = 0.0009243529016660394
Trained batch 169 in epoch 7, gen_loss = 0.9847522837274215, disc_loss = 0.0009255770690609044
Trained batch 170 in epoch 7, gen_loss = 0.9849554171339113, disc_loss = 0.0009229962166149594
Trained batch 171 in epoch 7, gen_loss = 0.9850235117036242, disc_loss = 0.0009199780636896152
Trained batch 172 in epoch 7, gen_loss = 0.9850012363726004, disc_loss = 0.0009186397912418146
Trained batch 173 in epoch 7, gen_loss = 0.9852723599165335, disc_loss = 0.0009188048894304365
Trained batch 174 in epoch 7, gen_loss = 0.9850958572115217, disc_loss = 0.0009184264705150521
Trained batch 175 in epoch 7, gen_loss = 0.9850993627174334, disc_loss = 0.0009175787934674935
Trained batch 176 in epoch 7, gen_loss = 0.9850203475709689, disc_loss = 0.0009172082929457617
Trained batch 177 in epoch 7, gen_loss = 0.9850375752770499, disc_loss = 0.0009189102625548892
Trained batch 178 in epoch 7, gen_loss = 0.9850950021317552, disc_loss = 0.0009258553437275979
Trained batch 179 in epoch 7, gen_loss = 0.9851730999019411, disc_loss = 0.0009368607535887147
Trained batch 180 in epoch 7, gen_loss = 0.9850843713428434, disc_loss = 0.0009470331574724575
Trained batch 181 in epoch 7, gen_loss = 0.9851612556766678, disc_loss = 0.000954319776120918
Trained batch 182 in epoch 7, gen_loss = 0.9849305755453683, disc_loss = 0.0009592391368125113
Trained batch 183 in epoch 7, gen_loss = 0.9851710514529891, disc_loss = 0.000961913400201213
Trained batch 184 in epoch 7, gen_loss = 0.9848484812556086, disc_loss = 0.0009628389893584205
Trained batch 185 in epoch 7, gen_loss = 0.9848975689821345, disc_loss = 0.0009623042788007297
Trained batch 186 in epoch 7, gen_loss = 0.9847134861716612, disc_loss = 0.0009603485920905997
Trained batch 187 in epoch 7, gen_loss = 0.9847120886787455, disc_loss = 0.000957656951210625
Trained batch 188 in epoch 7, gen_loss = 0.9848029730181215, disc_loss = 0.0009548452063913275
Trained batch 189 in epoch 7, gen_loss = 0.9848041393254933, disc_loss = 0.0009519834870221339
Trained batch 190 in epoch 7, gen_loss = 0.9849005853318419, disc_loss = 0.0009508422341688989
Trained batch 191 in epoch 7, gen_loss = 0.9849214612816771, disc_loss = 0.000952210948753418
Trained batch 192 in epoch 7, gen_loss = 0.9848357664488758, disc_loss = 0.000953491248411773
Trained batch 193 in epoch 7, gen_loss = 0.9849425502044639, disc_loss = 0.0009529891857588136
Trained batch 194 in epoch 7, gen_loss = 0.9849079569180806, disc_loss = 0.0009510171801920455
Trained batch 195 in epoch 7, gen_loss = 0.984928655077, disc_loss = 0.0009493601634802668
Trained batch 196 in epoch 7, gen_loss = 0.9849346960861671, disc_loss = 0.0009475720042172527
Trained batch 197 in epoch 7, gen_loss = 0.9847326670030151, disc_loss = 0.0009449414221418203
Trained batch 198 in epoch 7, gen_loss = 0.984851090153258, disc_loss = 0.0009432120678505285
Trained batch 199 in epoch 7, gen_loss = 0.9845950746536255, disc_loss = 0.0009420444320858224
Trained batch 200 in epoch 7, gen_loss = 0.9845701438277515, disc_loss = 0.000940610861347233
Trained batch 201 in epoch 7, gen_loss = 0.984438550059158, disc_loss = 0.0009387759024266955
Trained batch 202 in epoch 7, gen_loss = 0.9844946670414779, disc_loss = 0.0009367650547816093
Trained batch 203 in epoch 7, gen_loss = 0.9844721485586727, disc_loss = 0.0009349423568945734
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.0058739185333252, disc_loss = 0.0007583627011626959
Trained batch 1 in epoch 8, gen_loss = 0.9783515334129333, disc_loss = 0.0008376174955628812
Trained batch 2 in epoch 8, gen_loss = 0.9832473794619242, disc_loss = 0.0008991102998455366
Trained batch 3 in epoch 8, gen_loss = 0.9854348748922348, disc_loss = 0.0008819764043437317
Trained batch 4 in epoch 8, gen_loss = 0.9869320511817932, disc_loss = 0.0007976993336342275
Trained batch 5 in epoch 8, gen_loss = 0.9850909312566122, disc_loss = 0.0007063691252066443
Trained batch 6 in epoch 8, gen_loss = 0.982457527092525, disc_loss = 0.0006423407217620739
Trained batch 7 in epoch 8, gen_loss = 0.9852404221892357, disc_loss = 0.0006296441570157185
Trained batch 8 in epoch 8, gen_loss = 0.9910224344995286, disc_loss = 0.0006631446045099033
Trained batch 9 in epoch 8, gen_loss = 0.9892071664333344, disc_loss = 0.0006703344988636672
Trained batch 10 in epoch 8, gen_loss = 0.9899655038660223, disc_loss = 0.0006403545108200474
Trained batch 11 in epoch 8, gen_loss = 0.9899658958117167, disc_loss = 0.0006141365447547287
Trained batch 12 in epoch 8, gen_loss = 0.9888143860376798, disc_loss = 0.0005954198288516357
Trained batch 13 in epoch 8, gen_loss = 0.9913109498364585, disc_loss = 0.0005809373604798955
Trained batch 14 in epoch 8, gen_loss = 0.9899559458096822, disc_loss = 0.0005594210738005738
Trained batch 15 in epoch 8, gen_loss = 0.9889697507023811, disc_loss = 0.0005410603625932708
Trained batch 16 in epoch 8, gen_loss = 0.9898520567837883, disc_loss = 0.0005268122904988773
Trained batch 17 in epoch 8, gen_loss = 0.9853574302461412, disc_loss = 0.0005127144411542556
Trained batch 18 in epoch 8, gen_loss = 0.984158522204349, disc_loss = 0.0005027230761602129
Trained batch 19 in epoch 8, gen_loss = 0.9818417012691498, disc_loss = 0.0005035518173826858
Trained batch 20 in epoch 8, gen_loss = 0.9801237185796102, disc_loss = 0.0005212006785552061
Trained batch 21 in epoch 8, gen_loss = 0.9803790016607805, disc_loss = 0.0005465769182509658
Trained batch 22 in epoch 8, gen_loss = 0.9821610709895259, disc_loss = 0.0005725478606662997
Trained batch 23 in epoch 8, gen_loss = 0.9827622522910436, disc_loss = 0.000595435779056667
Trained batch 24 in epoch 8, gen_loss = 0.9823737454414367, disc_loss = 0.0006134382425807416
Trained batch 25 in epoch 8, gen_loss = 0.9820215220634754, disc_loss = 0.0006270244663867813
Trained batch 26 in epoch 8, gen_loss = 0.9811107781198289, disc_loss = 0.0006394950388413337
Trained batch 27 in epoch 8, gen_loss = 0.9800518133810588, disc_loss = 0.0006611402038418289
Trained batch 28 in epoch 8, gen_loss = 0.9793222299937544, disc_loss = 0.0006714557550430041
Trained batch 29 in epoch 8, gen_loss = 0.9809943616390229, disc_loss = 0.0006727331279156108
Trained batch 30 in epoch 8, gen_loss = 0.9815550196555353, disc_loss = 0.0006735087954439223
Trained batch 31 in epoch 8, gen_loss = 0.9837054833769798, disc_loss = 0.0006736573996022344
Trained batch 32 in epoch 8, gen_loss = 0.9842340476585157, disc_loss = 0.0006715086620357451
Trained batch 33 in epoch 8, gen_loss = 0.9826115632758421, disc_loss = 0.0006677348728236906
Trained batch 34 in epoch 8, gen_loss = 0.9822988901819502, disc_loss = 0.0006620986886056406
Trained batch 35 in epoch 8, gen_loss = 0.9825058546331193, disc_loss = 0.000657579247167127
Trained batch 36 in epoch 8, gen_loss = 0.9823554722038476, disc_loss = 0.0006550543884922927
Trained batch 37 in epoch 8, gen_loss = 0.983523572746076, disc_loss = 0.0006589083105178648
Trained batch 38 in epoch 8, gen_loss = 0.9833418344840025, disc_loss = 0.0006715062563904586
Trained batch 39 in epoch 8, gen_loss = 0.9838982373476028, disc_loss = 0.0006888811360113323
Trained batch 40 in epoch 8, gen_loss = 0.9844592518922759, disc_loss = 0.000708590945933105
Trained batch 41 in epoch 8, gen_loss = 0.9844569847697303, disc_loss = 0.0007249049709311553
Trained batch 42 in epoch 8, gen_loss = 0.9835644433664721, disc_loss = 0.0007350053800659818
Trained batch 43 in epoch 8, gen_loss = 0.9836711571975187, disc_loss = 0.00074202021245252
Trained batch 44 in epoch 8, gen_loss = 0.9826443142361111, disc_loss = 0.0007518123835325241
Trained batch 45 in epoch 8, gen_loss = 0.9814892488977184, disc_loss = 0.0007676830889819109
Trained batch 46 in epoch 8, gen_loss = 0.9816870283573231, disc_loss = 0.0007876483500598275
Trained batch 47 in epoch 8, gen_loss = 0.982456569870313, disc_loss = 0.0008094721585318135
Trained batch 48 in epoch 8, gen_loss = 0.9823970186467074, disc_loss = 0.0008235488072683921
Trained batch 49 in epoch 8, gen_loss = 0.9831999039649963, disc_loss = 0.0008352268836461007
Trained batch 50 in epoch 8, gen_loss = 0.9846356522803213, disc_loss = 0.0008507609120844042
Trained batch 51 in epoch 8, gen_loss = 0.9841421475777259, disc_loss = 0.0008636407281021372
Trained batch 52 in epoch 8, gen_loss = 0.9844737390302262, disc_loss = 0.0008664416557810498
Trained batch 53 in epoch 8, gen_loss = 0.9846559343514619, disc_loss = 0.0008636152876230577
Trained batch 54 in epoch 8, gen_loss = 0.9851007960059426, disc_loss = 0.0008582309057766741
Trained batch 55 in epoch 8, gen_loss = 0.9848248192242214, disc_loss = 0.0008500604609642844
Trained batch 56 in epoch 8, gen_loss = 0.9847747850836369, disc_loss = 0.0008428510969806986
Trained batch 57 in epoch 8, gen_loss = 0.984558020172448, disc_loss = 0.0008358854985121509
Trained batch 58 in epoch 8, gen_loss = 0.9836998258606863, disc_loss = 0.0008278173134046591
Trained batch 59 in epoch 8, gen_loss = 0.9845342506965001, disc_loss = 0.0008217596516866858
Trained batch 60 in epoch 8, gen_loss = 0.9847119372399127, disc_loss = 0.0008196716939221273
Trained batch 61 in epoch 8, gen_loss = 0.9851758585822198, disc_loss = 0.0008175252709582808
Trained batch 62 in epoch 8, gen_loss = 0.9853908703440711, disc_loss = 0.0008187487154149465
Trained batch 63 in epoch 8, gen_loss = 0.9855693634599447, disc_loss = 0.0008224069943025825
Trained batch 64 in epoch 8, gen_loss = 0.985278608248784, disc_loss = 0.0008286419709642919
Trained batch 65 in epoch 8, gen_loss = 0.9853562676545345, disc_loss = 0.0008321373968625046
Trained batch 66 in epoch 8, gen_loss = 0.9859816298555972, disc_loss = 0.0008269923942427693
Trained batch 67 in epoch 8, gen_loss = 0.98626388872371, disc_loss = 0.0008183242209591245
Trained batch 68 in epoch 8, gen_loss = 0.9859421374141306, disc_loss = 0.0008103007347781913
Trained batch 69 in epoch 8, gen_loss = 0.9864107881273542, disc_loss = 0.0008037228395031499
Trained batch 70 in epoch 8, gen_loss = 0.9868948644315693, disc_loss = 0.0008014895843381298
Trained batch 71 in epoch 8, gen_loss = 0.9867898970842361, disc_loss = 0.0008005013910911253
Trained batch 72 in epoch 8, gen_loss = 0.9866826517941201, disc_loss = 0.0007980430621513459
Trained batch 73 in epoch 8, gen_loss = 0.9862637068774249, disc_loss = 0.0007940347367784361
Trained batch 74 in epoch 8, gen_loss = 0.9861122075716654, disc_loss = 0.0007889400116012742
Trained batch 75 in epoch 8, gen_loss = 0.9864666297247535, disc_loss = 0.0007830486256831424
Trained batch 76 in epoch 8, gen_loss = 0.9857350131133934, disc_loss = 0.0007769870288313258
Trained batch 77 in epoch 8, gen_loss = 0.9857454460400802, disc_loss = 0.0007711462583243608
Trained batch 78 in epoch 8, gen_loss = 0.985564562338817, disc_loss = 0.0007679223328315995
Trained batch 79 in epoch 8, gen_loss = 0.985121338814497, disc_loss = 0.0007657449485122924
Trained batch 80 in epoch 8, gen_loss = 0.9847926129529505, disc_loss = 0.0007629320754836325
Trained batch 81 in epoch 8, gen_loss = 0.9842861207520089, disc_loss = 0.0007581569676048962
Trained batch 82 in epoch 8, gen_loss = 0.9844918452113508, disc_loss = 0.0007527904439134052
Trained batch 83 in epoch 8, gen_loss = 0.9840353315784818, disc_loss = 0.000748116603409428
Trained batch 84 in epoch 8, gen_loss = 0.9841339938780841, disc_loss = 0.0007440263788928003
Trained batch 85 in epoch 8, gen_loss = 0.9844187789185103, disc_loss = 0.0007401718832498286
Trained batch 86 in epoch 8, gen_loss = 0.9848893291648777, disc_loss = 0.0007373466090855842
Trained batch 87 in epoch 8, gen_loss = 0.9846633659167723, disc_loss = 0.0007361517570891672
Trained batch 88 in epoch 8, gen_loss = 0.9843321261780985, disc_loss = 0.0007358624644347288
Trained batch 89 in epoch 8, gen_loss = 0.9843845870759752, disc_loss = 0.0007369267767191761
Trained batch 90 in epoch 8, gen_loss = 0.984261447256738, disc_loss = 0.0007380942460968272
Trained batch 91 in epoch 8, gen_loss = 0.9839201129001119, disc_loss = 0.0007379986472306368
Trained batch 92 in epoch 8, gen_loss = 0.9840040629909884, disc_loss = 0.00073922568586685
Trained batch 93 in epoch 8, gen_loss = 0.9845000682993138, disc_loss = 0.0007431132327567072
Trained batch 94 in epoch 8, gen_loss = 0.9846775996057611, disc_loss = 0.0007466388351627086
Trained batch 95 in epoch 8, gen_loss = 0.9843065192302068, disc_loss = 0.0007495993825917443
Trained batch 96 in epoch 8, gen_loss = 0.9840591125881549, disc_loss = 0.0007515509508444553
Trained batch 97 in epoch 8, gen_loss = 0.9843108459394805, disc_loss = 0.0007528905847052834
Trained batch 98 in epoch 8, gen_loss = 0.9843516614702013, disc_loss = 0.0007532226754296007
Trained batch 99 in epoch 8, gen_loss = 0.9842629462480545, disc_loss = 0.0007526088284794242
Trained batch 100 in epoch 8, gen_loss = 0.9844632272673125, disc_loss = 0.0007512569369858887
Trained batch 101 in epoch 8, gen_loss = 0.9840680430917179, disc_loss = 0.0007515587312096328
Trained batch 102 in epoch 8, gen_loss = 0.9838059585071305, disc_loss = 0.0007544800478657617
Trained batch 103 in epoch 8, gen_loss = 0.9835568746695151, disc_loss = 0.0007554886990244716
Trained batch 104 in epoch 8, gen_loss = 0.98344950959796, disc_loss = 0.0007556452432514302
Trained batch 105 in epoch 8, gen_loss = 0.9830282448597674, disc_loss = 0.0007581762164470933
Trained batch 106 in epoch 8, gen_loss = 0.983342938891081, disc_loss = 0.000763252605444743
Trained batch 107 in epoch 8, gen_loss = 0.9837026369792444, disc_loss = 0.0007688631955749804
Trained batch 108 in epoch 8, gen_loss = 0.9840532032721633, disc_loss = 0.0007723117628510734
Trained batch 109 in epoch 8, gen_loss = 0.9836245693943717, disc_loss = 0.0007738256705289876
Trained batch 110 in epoch 8, gen_loss = 0.9840038429509412, disc_loss = 0.0007756698844106952
Trained batch 111 in epoch 8, gen_loss = 0.9839109081242766, disc_loss = 0.0007802264699421357
Trained batch 112 in epoch 8, gen_loss = 0.9839414068027935, disc_loss = 0.0007860541618758796
Trained batch 113 in epoch 8, gen_loss = 0.9838027865217444, disc_loss = 0.0007947178168442884
Trained batch 114 in epoch 8, gen_loss = 0.9839317751967389, disc_loss = 0.0008062291318429229
Trained batch 115 in epoch 8, gen_loss = 0.9838428266089538, disc_loss = 0.0008141148934775064
Trained batch 116 in epoch 8, gen_loss = 0.9834218081246074, disc_loss = 0.0008162432623844052
Trained batch 117 in epoch 8, gen_loss = 0.9833562005374391, disc_loss = 0.0008159583588367549
Trained batch 118 in epoch 8, gen_loss = 0.983801395452323, disc_loss = 0.0008165152350190182
Trained batch 119 in epoch 8, gen_loss = 0.9838419283429781, disc_loss = 0.0008199294088020299
Trained batch 120 in epoch 8, gen_loss = 0.9840188839218833, disc_loss = 0.0008263137135731657
Trained batch 121 in epoch 8, gen_loss = 0.9838862296987753, disc_loss = 0.0008310979932592418
Trained batch 122 in epoch 8, gen_loss = 0.9840527545145856, disc_loss = 0.0008312755352363172
Trained batch 123 in epoch 8, gen_loss = 0.9839521987784293, disc_loss = 0.0008294037853052179
Trained batch 124 in epoch 8, gen_loss = 0.9841265120506286, disc_loss = 0.0008283559838309884
Trained batch 125 in epoch 8, gen_loss = 0.983878053843029, disc_loss = 0.0008276273392044776
Trained batch 126 in epoch 8, gen_loss = 0.983778969978723, disc_loss = 0.0008261446079319915
Trained batch 127 in epoch 8, gen_loss = 0.9836612469516695, disc_loss = 0.0008228927770232985
Trained batch 128 in epoch 8, gen_loss = 0.9834268892458243, disc_loss = 0.0008193675436299698
Trained batch 129 in epoch 8, gen_loss = 0.9836321853674375, disc_loss = 0.0008155123467216841
Trained batch 130 in epoch 8, gen_loss = 0.9836744984597651, disc_loss = 0.0008105941267660997
Trained batch 131 in epoch 8, gen_loss = 0.9840775443748995, disc_loss = 0.000807496696462763
Trained batch 132 in epoch 8, gen_loss = 0.9841964921556917, disc_loss = 0.0008086157909942847
Trained batch 133 in epoch 8, gen_loss = 0.9839699566364288, disc_loss = 0.0008143807022698543
Trained batch 134 in epoch 8, gen_loss = 0.9842513812912835, disc_loss = 0.0008251044842095494
Trained batch 135 in epoch 8, gen_loss = 0.9840382736395387, disc_loss = 0.0008382580515043467
Trained batch 136 in epoch 8, gen_loss = 0.984183723474071, disc_loss = 0.0008480319744579317
Trained batch 137 in epoch 8, gen_loss = 0.9844453399596007, disc_loss = 0.0008528481200261487
Trained batch 138 in epoch 8, gen_loss = 0.984508110893716, disc_loss = 0.0008570445359562249
Trained batch 139 in epoch 8, gen_loss = 0.9844457026038851, disc_loss = 0.0008617331925571697
Trained batch 140 in epoch 8, gen_loss = 0.9841880016293086, disc_loss = 0.0008640077450363864
Trained batch 141 in epoch 8, gen_loss = 0.9846111548618531, disc_loss = 0.0008641000222013017
Trained batch 142 in epoch 8, gen_loss = 0.984748278047655, disc_loss = 0.0008631640074610176
Trained batch 143 in epoch 8, gen_loss = 0.9845021780994203, disc_loss = 0.0008617524325826606
Trained batch 144 in epoch 8, gen_loss = 0.9843037555957662, disc_loss = 0.0008610484221396197
Trained batch 145 in epoch 8, gen_loss = 0.9844752639940341, disc_loss = 0.0008596529001457783
Trained batch 146 in epoch 8, gen_loss = 0.984584471806377, disc_loss = 0.0008574507149137544
Trained batch 147 in epoch 8, gen_loss = 0.98446847015136, disc_loss = 0.0008546288251661306
Trained batch 148 in epoch 8, gen_loss = 0.9846850469608435, disc_loss = 0.0008515387955363902
Trained batch 149 in epoch 8, gen_loss = 0.9850564261277517, disc_loss = 0.0008487724189762957
Trained batch 150 in epoch 8, gen_loss = 0.9850635903560563, disc_loss = 0.0008452860652954805
Trained batch 151 in epoch 8, gen_loss = 0.9849710476241613, disc_loss = 0.0008421652090826109
Trained batch 152 in epoch 8, gen_loss = 0.985077861477347, disc_loss = 0.000839318533133551
Trained batch 153 in epoch 8, gen_loss = 0.9850861519188076, disc_loss = 0.000836472517138728
Trained batch 154 in epoch 8, gen_loss = 0.9848440358715672, disc_loss = 0.0008334048675380707
Trained batch 155 in epoch 8, gen_loss = 0.9849561395553442, disc_loss = 0.0008311603026716815
Trained batch 156 in epoch 8, gen_loss = 0.9847641218999389, disc_loss = 0.0008294547732458242
Trained batch 157 in epoch 8, gen_loss = 0.9848132054262524, disc_loss = 0.0008285868073160807
Trained batch 158 in epoch 8, gen_loss = 0.9849554274067189, disc_loss = 0.0008305455562578069
Trained batch 159 in epoch 8, gen_loss = 0.9848282564431429, disc_loss = 0.0008333385446348985
Trained batch 160 in epoch 8, gen_loss = 0.9846241729600089, disc_loss = 0.0008380659751959943
Trained batch 161 in epoch 8, gen_loss = 0.9844891826311747, disc_loss = 0.0008433887266653108
Trained batch 162 in epoch 8, gen_loss = 0.985051920077552, disc_loss = 0.0008472755242980434
Trained batch 163 in epoch 8, gen_loss = 0.9850279518016954, disc_loss = 0.0008522075301543071
Trained batch 164 in epoch 8, gen_loss = 0.9847232027487322, disc_loss = 0.0008591532768067819
Trained batch 165 in epoch 8, gen_loss = 0.984786053378898, disc_loss = 0.0008654901811310247
Trained batch 166 in epoch 8, gen_loss = 0.9845068768826787, disc_loss = 0.0008688496874853088
Trained batch 167 in epoch 8, gen_loss = 0.9846592715808323, disc_loss = 0.0008693133679896294
Trained batch 168 in epoch 8, gen_loss = 0.9848251378042459, disc_loss = 0.0008687398210615636
Trained batch 169 in epoch 8, gen_loss = 0.9847230308196124, disc_loss = 0.0008683764544377267
Trained batch 170 in epoch 8, gen_loss = 0.9847511624732213, disc_loss = 0.0008670980658290952
Trained batch 171 in epoch 8, gen_loss = 0.9846484473971433, disc_loss = 0.0008641196099931623
Trained batch 172 in epoch 8, gen_loss = 0.9846168914971324, disc_loss = 0.0008605541435112057
Trained batch 173 in epoch 8, gen_loss = 0.9846362444176071, disc_loss = 0.0008574976757584922
Trained batch 174 in epoch 8, gen_loss = 0.9845651538031441, disc_loss = 0.0008543543629847201
Trained batch 175 in epoch 8, gen_loss = 0.9847416870973327, disc_loss = 0.0008516256559067352
Trained batch 176 in epoch 8, gen_loss = 0.9845118334064376, disc_loss = 0.0008504238514207293
Trained batch 177 in epoch 8, gen_loss = 0.984626597902748, disc_loss = 0.0008530790669538782
Trained batch 178 in epoch 8, gen_loss = 0.98447599024746, disc_loss = 0.0008580127220266556
Trained batch 179 in epoch 8, gen_loss = 0.9844850735531913, disc_loss = 0.0008619813254174207
Trained batch 180 in epoch 8, gen_loss = 0.9843583531801213, disc_loss = 0.0008654411732140692
Trained batch 181 in epoch 8, gen_loss = 0.9844724178969205, disc_loss = 0.0008701982646176315
Trained batch 182 in epoch 8, gen_loss = 0.9842565102003963, disc_loss = 0.0008752481773199229
Trained batch 183 in epoch 8, gen_loss = 0.9843108722049257, disc_loss = 0.0008778406113972027
Trained batch 184 in epoch 8, gen_loss = 0.9843677646404988, disc_loss = 0.0008790911652770749
Trained batch 185 in epoch 8, gen_loss = 0.9843196993873965, disc_loss = 0.0008796292621741241
Trained batch 186 in epoch 8, gen_loss = 0.9844725409293558, disc_loss = 0.0008783163234341222
Trained batch 187 in epoch 8, gen_loss = 0.9847247838339908, disc_loss = 0.0008756324559533126
Trained batch 188 in epoch 8, gen_loss = 0.984638995909817, disc_loss = 0.000872513623252171
Trained batch 189 in epoch 8, gen_loss = 0.984591250356875, disc_loss = 0.0008691106487132952
Trained batch 190 in epoch 8, gen_loss = 0.9845464644631791, disc_loss = 0.0008660534984786892
Trained batch 191 in epoch 8, gen_loss = 0.9846590288604299, disc_loss = 0.0008630646517152248
Trained batch 192 in epoch 8, gen_loss = 0.9847520327320989, disc_loss = 0.0008612480081667293
Trained batch 193 in epoch 8, gen_loss = 0.9845350676590634, disc_loss = 0.000862338058797513
Trained batch 194 in epoch 8, gen_loss = 0.984465225537618, disc_loss = 0.0008662889097393371
Trained batch 195 in epoch 8, gen_loss = 0.984589616863095, disc_loss = 0.0008704122441745962
Trained batch 196 in epoch 8, gen_loss = 0.9845594663910454, disc_loss = 0.0008732171098821026
Trained batch 197 in epoch 8, gen_loss = 0.9843343574591358, disc_loss = 0.000875103051113929
Trained batch 198 in epoch 8, gen_loss = 0.9841622012344438, disc_loss = 0.0008756328841709957
Trained batch 199 in epoch 8, gen_loss = 0.9840348833799362, disc_loss = 0.0008742958139191614
Trained batch 200 in epoch 8, gen_loss = 0.9840449379451239, disc_loss = 0.0008715637751758812
Trained batch 201 in epoch 8, gen_loss = 0.9839016742045337, disc_loss = 0.000868697832917707
Trained batch 202 in epoch 8, gen_loss = 0.9839814090963654, disc_loss = 0.0008669304670771731
Trained batch 203 in epoch 8, gen_loss = 0.9839703691940681, disc_loss = 0.0008675499466691833
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9760591983795166, disc_loss = 0.0016359114088118076
Trained batch 1 in epoch 9, gen_loss = 0.9574465155601501, disc_loss = 0.0017680594464764
Trained batch 2 in epoch 9, gen_loss = 0.9684308767318726, disc_loss = 0.001854391535744071
Trained batch 3 in epoch 9, gen_loss = 0.9717550724744797, disc_loss = 0.0018720460939221084
Trained batch 4 in epoch 9, gen_loss = 0.9772284984588623, disc_loss = 0.0019606913439929484
Trained batch 5 in epoch 9, gen_loss = 0.9655013084411621, disc_loss = 0.0020675367365280786
Trained batch 6 in epoch 9, gen_loss = 0.9668599878038678, disc_loss = 0.00210399559832045
Trained batch 7 in epoch 9, gen_loss = 0.9673144221305847, disc_loss = 0.0020875938644167036
Trained batch 8 in epoch 9, gen_loss = 0.962526281674703, disc_loss = 0.0020268963805089393
Trained batch 9 in epoch 9, gen_loss = 0.961442357301712, disc_loss = 0.001937572006136179
Trained batch 10 in epoch 9, gen_loss = 0.965304044159976, disc_loss = 0.0018547031372277574
Trained batch 11 in epoch 9, gen_loss = 0.9674513638019562, disc_loss = 0.0017570917019232486
Trained batch 12 in epoch 9, gen_loss = 0.9706411636792697, disc_loss = 0.0016604105073313874
Trained batch 13 in epoch 9, gen_loss = 0.9703402263777596, disc_loss = 0.0015862238568453385
Trained batch 14 in epoch 9, gen_loss = 0.9737874587376912, disc_loss = 0.0015140071200827757
Trained batch 15 in epoch 9, gen_loss = 0.9735785201191902, disc_loss = 0.0014417335114558227
Trained batch 16 in epoch 9, gen_loss = 0.9751895105137545, disc_loss = 0.0013816844113855896
Trained batch 17 in epoch 9, gen_loss = 0.9751268327236176, disc_loss = 0.0013428662674010007
Trained batch 18 in epoch 9, gen_loss = 0.9748199738954243, disc_loss = 0.001316493868791057
Trained batch 19 in epoch 9, gen_loss = 0.9758475452661515, disc_loss = 0.0013048258741036988
Trained batch 20 in epoch 9, gen_loss = 0.9763479630152384, disc_loss = 0.001320413647807159
Trained batch 21 in epoch 9, gen_loss = 0.9751867110078986, disc_loss = 0.0013715287006396632
Trained batch 22 in epoch 9, gen_loss = 0.977620534274889, disc_loss = 0.0014679076000744396
Trained batch 23 in epoch 9, gen_loss = 0.9770622352759043, disc_loss = 0.001541854688791015
Trained batch 24 in epoch 9, gen_loss = 0.9794451904296875, disc_loss = 0.0015754456364084036
Trained batch 25 in epoch 9, gen_loss = 0.9799219369888306, disc_loss = 0.0015842054820565793
Trained batch 26 in epoch 9, gen_loss = 0.9802328679296706, disc_loss = 0.0015830987540539354
Trained batch 27 in epoch 9, gen_loss = 0.9803368725946972, disc_loss = 0.0015662185001669318
Trained batch 28 in epoch 9, gen_loss = 0.9809725716196257, disc_loss = 0.0015348509538131926
Trained batch 29 in epoch 9, gen_loss = 0.9824251592159271, disc_loss = 0.0014996463636634872
Trained batch 30 in epoch 9, gen_loss = 0.9836997428248005, disc_loss = 0.0014616988586156718
Trained batch 31 in epoch 9, gen_loss = 0.983443958684802, disc_loss = 0.0014271136224124348
Trained batch 32 in epoch 9, gen_loss = 0.9838824434713884, disc_loss = 0.0013933306185980186
Trained batch 33 in epoch 9, gen_loss = 0.9831099405008203, disc_loss = 0.0013581072108696818
Trained batch 34 in epoch 9, gen_loss = 0.9832487821578979, disc_loss = 0.0013258117184575115
Trained batch 35 in epoch 9, gen_loss = 0.9813963340388404, disc_loss = 0.0012990134443195227
Trained batch 36 in epoch 9, gen_loss = 0.9815396006042892, disc_loss = 0.001280134093060435
Trained batch 37 in epoch 9, gen_loss = 0.9819714474050623, disc_loss = 0.0012583323213651678
Trained batch 38 in epoch 9, gen_loss = 0.9809918495324942, disc_loss = 0.0012303409532297594
Trained batch 39 in epoch 9, gen_loss = 0.9813019841909408, disc_loss = 0.0012105001129384617
Trained batch 40 in epoch 9, gen_loss = 0.9818714217441838, disc_loss = 0.001202720057690607
Trained batch 41 in epoch 9, gen_loss = 0.98268742504574, disc_loss = 0.0011961746599159337
Trained batch 42 in epoch 9, gen_loss = 0.982736723367558, disc_loss = 0.001186684351333222
Trained batch 43 in epoch 9, gen_loss = 0.9821413403207605, disc_loss = 0.00117366274604468
Trained batch 44 in epoch 9, gen_loss = 0.981980570157369, disc_loss = 0.0011562192521523684
Trained batch 45 in epoch 9, gen_loss = 0.9817611536254054, disc_loss = 0.001137810687752157
Trained batch 46 in epoch 9, gen_loss = 0.9818531946933016, disc_loss = 0.0011186954773407668
Trained batch 47 in epoch 9, gen_loss = 0.9818705742557844, disc_loss = 0.0011017944307241123
Trained batch 48 in epoch 9, gen_loss = 0.9827145824627, disc_loss = 0.001090726336435776
Trained batch 49 in epoch 9, gen_loss = 0.9827276635169983, disc_loss = 0.0010852064413484186
Trained batch 50 in epoch 9, gen_loss = 0.983552984162873, disc_loss = 0.0010864789992589138
Trained batch 51 in epoch 9, gen_loss = 0.9842530076320355, disc_loss = 0.001084334211415038
Trained batch 52 in epoch 9, gen_loss = 0.9845347831834037, disc_loss = 0.0010723122532857266
Trained batch 53 in epoch 9, gen_loss = 0.9845164793509024, disc_loss = 0.0010579264974997689
Trained batch 54 in epoch 9, gen_loss = 0.983810363032601, disc_loss = 0.001043424192308025
Trained batch 55 in epoch 9, gen_loss = 0.9836591535380909, disc_loss = 0.0010291136976385523
Trained batch 56 in epoch 9, gen_loss = 0.9829421095680773, disc_loss = 0.0010149878316473117
Trained batch 57 in epoch 9, gen_loss = 0.9835906450090737, disc_loss = 0.0010019223672911878
Trained batch 58 in epoch 9, gen_loss = 0.9827980267799507, disc_loss = 0.000988575018956168
Trained batch 59 in epoch 9, gen_loss = 0.9829337477684021, disc_loss = 0.0009750002677416584
Trained batch 60 in epoch 9, gen_loss = 0.982800874553743, disc_loss = 0.0009620405218781537
Trained batch 61 in epoch 9, gen_loss = 0.9829624199098156, disc_loss = 0.0009513894650397913
Trained batch 62 in epoch 9, gen_loss = 0.9827924777591039, disc_loss = 0.0009404859555948023
Trained batch 63 in epoch 9, gen_loss = 0.9829840296879411, disc_loss = 0.0009296961554809968
Trained batch 64 in epoch 9, gen_loss = 0.9823291457616365, disc_loss = 0.0009188824671302708
Trained batch 65 in epoch 9, gen_loss = 0.9814244617115367, disc_loss = 0.0009099822233441624
Trained batch 66 in epoch 9, gen_loss = 0.981296259075848, disc_loss = 0.0009011117523838419
Trained batch 67 in epoch 9, gen_loss = 0.9814077300183913, disc_loss = 0.0008935887973861742
Trained batch 68 in epoch 9, gen_loss = 0.9809338269026383, disc_loss = 0.000886159417332501
Trained batch 69 in epoch 9, gen_loss = 0.9809302568435669, disc_loss = 0.0008804471791206327
Trained batch 70 in epoch 9, gen_loss = 0.9800969597319482, disc_loss = 0.0008759581310507304
Trained batch 71 in epoch 9, gen_loss = 0.9798833065562778, disc_loss = 0.0008707104508276745
Trained batch 72 in epoch 9, gen_loss = 0.9793744144374377, disc_loss = 0.0008623862779804518
Trained batch 73 in epoch 9, gen_loss = 0.9798831174502501, disc_loss = 0.0008539299608831218
Trained batch 74 in epoch 9, gen_loss = 0.9797051286697388, disc_loss = 0.0008472679256616781
Trained batch 75 in epoch 9, gen_loss = 0.9791829021353471, disc_loss = 0.0008412267837373197
Trained batch 76 in epoch 9, gen_loss = 0.9790465560826388, disc_loss = 0.0008343625001083189
Trained batch 77 in epoch 9, gen_loss = 0.9790003223296924, disc_loss = 0.0008281381623162768
Trained batch 78 in epoch 9, gen_loss = 0.9790441869180414, disc_loss = 0.0008218740415169939
Trained batch 79 in epoch 9, gen_loss = 0.979116179049015, disc_loss = 0.0008148779350449331
Trained batch 80 in epoch 9, gen_loss = 0.9790532279897619, disc_loss = 0.0008080993163870809
Trained batch 81 in epoch 9, gen_loss = 0.9786940391470746, disc_loss = 0.0008021162996045882
Trained batch 82 in epoch 9, gen_loss = 0.9783428124634617, disc_loss = 0.0007962756551779717
Trained batch 83 in epoch 9, gen_loss = 0.9783946864661717, disc_loss = 0.0007906662590574429
Trained batch 84 in epoch 9, gen_loss = 0.9786949781810537, disc_loss = 0.0007845712089500226
Trained batch 85 in epoch 9, gen_loss = 0.978921897882639, disc_loss = 0.0007784123401168387
Trained batch 86 in epoch 9, gen_loss = 0.9789060628277132, disc_loss = 0.0007720811096161882
Trained batch 87 in epoch 9, gen_loss = 0.9787012094801123, disc_loss = 0.0007651522952404445
Trained batch 88 in epoch 9, gen_loss = 0.9791798698768187, disc_loss = 0.0007585793337261493
Trained batch 89 in epoch 9, gen_loss = 0.9788668036460877, disc_loss = 0.0007517739422231291
Trained batch 90 in epoch 9, gen_loss = 0.9785693733246772, disc_loss = 0.0007452665899168946
Trained batch 91 in epoch 9, gen_loss = 0.9784308088862378, disc_loss = 0.0007392868841555395
Trained batch 92 in epoch 9, gen_loss = 0.9784890938830632, disc_loss = 0.0007344018879173804
Trained batch 93 in epoch 9, gen_loss = 0.9782029263516689, disc_loss = 0.0007314142708213345
Trained batch 94 in epoch 9, gen_loss = 0.9776965078554656, disc_loss = 0.0007291869519241644
Trained batch 95 in epoch 9, gen_loss = 0.9777869855364164, disc_loss = 0.0007252441096170514
Trained batch 96 in epoch 9, gen_loss = 0.9783365296334335, disc_loss = 0.0007206139026615365
Trained batch 97 in epoch 9, gen_loss = 0.9786396196910313, disc_loss = 0.0007159699344644038
Trained batch 98 in epoch 9, gen_loss = 0.9785967023685725, disc_loss = 0.0007114389491199299
Trained batch 99 in epoch 9, gen_loss = 0.9785755085945129, disc_loss = 0.0007072364112536888
Trained batch 100 in epoch 9, gen_loss = 0.9785617052918614, disc_loss = 0.0007037081002744173
Trained batch 101 in epoch 9, gen_loss = 0.978299540047552, disc_loss = 0.0007005703203806964
Trained batch 102 in epoch 9, gen_loss = 0.978139232663275, disc_loss = 0.0006981621471231405
Trained batch 103 in epoch 9, gen_loss = 0.9785160319163249, disc_loss = 0.0006955962373747473
Trained batch 104 in epoch 9, gen_loss = 0.9783908509072803, disc_loss = 0.0006934389642473044
Trained batch 105 in epoch 9, gen_loss = 0.9783204883899329, disc_loss = 0.0006909975917946178
Trained batch 106 in epoch 9, gen_loss = 0.9788979225069563, disc_loss = 0.0006881024606610761
Trained batch 107 in epoch 9, gen_loss = 0.9784443516422201, disc_loss = 0.00069276686998718
Trained batch 108 in epoch 9, gen_loss = 0.9780989322093648, disc_loss = 0.0007139307332231553
Trained batch 109 in epoch 9, gen_loss = 0.9784806701270017, disc_loss = 0.0007469263127528724
Trained batch 110 in epoch 9, gen_loss = 0.9788919649682604, disc_loss = 0.0007767950189625006
Trained batch 111 in epoch 9, gen_loss = 0.9788821163986411, disc_loss = 0.0007998652278859351
Trained batch 112 in epoch 9, gen_loss = 0.9788225725688765, disc_loss = 0.0008184983861473991
Trained batch 113 in epoch 9, gen_loss = 0.9788840062785567, disc_loss = 0.0008325409377759666
Trained batch 114 in epoch 9, gen_loss = 0.9783345663029215, disc_loss = 0.0008439036682197501
Trained batch 115 in epoch 9, gen_loss = 0.9785797744989395, disc_loss = 0.0008570213353307516
Trained batch 116 in epoch 9, gen_loss = 0.9791972825669835, disc_loss = 0.0008793579916714523
Trained batch 117 in epoch 9, gen_loss = 0.978940757654481, disc_loss = 0.0009039047052560895
Trained batch 118 in epoch 9, gen_loss = 0.979221649530555, disc_loss = 0.0009234901819673579
Trained batch 119 in epoch 9, gen_loss = 0.9791013767321904, disc_loss = 0.0009337292352332346
Trained batch 120 in epoch 9, gen_loss = 0.9789201779799028, disc_loss = 0.0009369170012997371
Trained batch 121 in epoch 9, gen_loss = 0.9793020545459185, disc_loss = 0.000939486600667597
Trained batch 122 in epoch 9, gen_loss = 0.9794702306995547, disc_loss = 0.0009411670923246283
Trained batch 123 in epoch 9, gen_loss = 0.9792749506811942, disc_loss = 0.000940805963769127
Trained batch 124 in epoch 9, gen_loss = 0.9793072805404663, disc_loss = 0.000938410122296773
Trained batch 125 in epoch 9, gen_loss = 0.9794545277716622, disc_loss = 0.0009352522545322288
Trained batch 126 in epoch 9, gen_loss = 0.9791701037114061, disc_loss = 0.0009311426644750658
Trained batch 127 in epoch 9, gen_loss = 0.9796029813587666, disc_loss = 0.0009271275627042996
Trained batch 128 in epoch 9, gen_loss = 0.9793270456698514, disc_loss = 0.0009241825942709941
Trained batch 129 in epoch 9, gen_loss = 0.9793915134209853, disc_loss = 0.0009223981506343429
Trained batch 130 in epoch 9, gen_loss = 0.9795592177005215, disc_loss = 0.0009198503859584639
Trained batch 131 in epoch 9, gen_loss = 0.9794460765340112, disc_loss = 0.0009173198333442225
Trained batch 132 in epoch 9, gen_loss = 0.9795463309252173, disc_loss = 0.0009170678244856417
Trained batch 133 in epoch 9, gen_loss = 0.9797446558724588, disc_loss = 0.0009203679620074594
Trained batch 134 in epoch 9, gen_loss = 0.9795553286870321, disc_loss = 0.000926209511601849
Trained batch 135 in epoch 9, gen_loss = 0.979603895369698, disc_loss = 0.0009334209151026752
Trained batch 136 in epoch 9, gen_loss = 0.9792184281523211, disc_loss = 0.0009409459364085533
Trained batch 137 in epoch 9, gen_loss = 0.9794376371563345, disc_loss = 0.0009488108390950651
Trained batch 138 in epoch 9, gen_loss = 0.9790752825977134, disc_loss = 0.0009563103668507282
Trained batch 139 in epoch 9, gen_loss = 0.979310131072998, disc_loss = 0.0009616887958795165
Trained batch 140 in epoch 9, gen_loss = 0.9792038650377423, disc_loss = 0.0009647059979467118
Trained batch 141 in epoch 9, gen_loss = 0.9792255507388585, disc_loss = 0.0009655458111730798
Trained batch 142 in epoch 9, gen_loss = 0.979670014414754, disc_loss = 0.0009646470520288807
Trained batch 143 in epoch 9, gen_loss = 0.9794741877251201, disc_loss = 0.0009622076137626815
Trained batch 144 in epoch 9, gen_loss = 0.9793736116639499, disc_loss = 0.0009585382148888412
Trained batch 145 in epoch 9, gen_loss = 0.9793827688857301, disc_loss = 0.0009543165170439289
Trained batch 146 in epoch 9, gen_loss = 0.9792030113083976, disc_loss = 0.0009497182951966098
Trained batch 147 in epoch 9, gen_loss = 0.9789759838903273, disc_loss = 0.000946423317391482
Trained batch 148 in epoch 9, gen_loss = 0.9791214914129884, disc_loss = 0.0009481261419671456
Trained batch 149 in epoch 9, gen_loss = 0.9788959169387818, disc_loss = 0.0009567420107972187
Trained batch 150 in epoch 9, gen_loss = 0.9791023810178239, disc_loss = 0.0009666225405152431
Trained batch 151 in epoch 9, gen_loss = 0.979010032195794, disc_loss = 0.0009702774865505298
Trained batch 152 in epoch 9, gen_loss = 0.9791740077772951, disc_loss = 0.0009687829587123132
Trained batch 153 in epoch 9, gen_loss = 0.9792625989232745, disc_loss = 0.0009656283043834454
Trained batch 154 in epoch 9, gen_loss = 0.9793501900088403, disc_loss = 0.0009618133033302823
Trained batch 155 in epoch 9, gen_loss = 0.9794344848547226, disc_loss = 0.0009571197507074641
Trained batch 156 in epoch 9, gen_loss = 0.9794439487396531, disc_loss = 0.0009523242367038528
Trained batch 157 in epoch 9, gen_loss = 0.9796691514268706, disc_loss = 0.0009477953740603385
Trained batch 158 in epoch 9, gen_loss = 0.9800459716305043, disc_loss = 0.0009431888732097094
Trained batch 159 in epoch 9, gen_loss = 0.9802278928458691, disc_loss = 0.0009387060028529959
Trained batch 160 in epoch 9, gen_loss = 0.980361016640752, disc_loss = 0.0009351688743025204
Trained batch 161 in epoch 9, gen_loss = 0.9802711598667098, disc_loss = 0.0009318628415959761
Trained batch 162 in epoch 9, gen_loss = 0.9801371316968298, disc_loss = 0.0009284148366259057
Trained batch 163 in epoch 9, gen_loss = 0.9799913538665306, disc_loss = 0.0009247135962274425
Trained batch 164 in epoch 9, gen_loss = 0.9801677638834173, disc_loss = 0.0009210868742119408
Trained batch 165 in epoch 9, gen_loss = 0.9801536712301783, disc_loss = 0.0009182641796027142
Trained batch 166 in epoch 9, gen_loss = 0.9798872067542848, disc_loss = 0.0009165902267918437
Trained batch 167 in epoch 9, gen_loss = 0.979933387821629, disc_loss = 0.0009154709464166358
Trained batch 168 in epoch 9, gen_loss = 0.9798767034118697, disc_loss = 0.0009139581185974975
Trained batch 169 in epoch 9, gen_loss = 0.9799334603197435, disc_loss = 0.0009118889848811223
Trained batch 170 in epoch 9, gen_loss = 0.9801983226809585, disc_loss = 0.0009096045542660861
Trained batch 171 in epoch 9, gen_loss = 0.9802797367406446, disc_loss = 0.0009073124427570377
Trained batch 172 in epoch 9, gen_loss = 0.9804367371377228, disc_loss = 0.0009052826975192337
Trained batch 173 in epoch 9, gen_loss = 0.9803111087316754, disc_loss = 0.0009040256895943834
Trained batch 174 in epoch 9, gen_loss = 0.9804126364844186, disc_loss = 0.0009031202281559153
Trained batch 175 in epoch 9, gen_loss = 0.9803910536522215, disc_loss = 0.0009015408104460221
Trained batch 176 in epoch 9, gen_loss = 0.9803430438041687, disc_loss = 0.0008992618051789028
Trained batch 177 in epoch 9, gen_loss = 0.9804649818479345, disc_loss = 0.0008965367467660625
Trained batch 178 in epoch 9, gen_loss = 0.980557800338255, disc_loss = 0.0008934197479770544
Trained batch 179 in epoch 9, gen_loss = 0.9805377016464869, disc_loss = 0.0008901516444489567
Trained batch 180 in epoch 9, gen_loss = 0.9803150032765299, disc_loss = 0.0008867585909995379
Trained batch 181 in epoch 9, gen_loss = 0.9803887605667114, disc_loss = 0.0008834798816798746
Trained batch 182 in epoch 9, gen_loss = 0.9804115914256195, disc_loss = 0.0008802274498093588
Trained batch 183 in epoch 9, gen_loss = 0.9804934162808501, disc_loss = 0.0008770098855007825
Trained batch 184 in epoch 9, gen_loss = 0.9805918732204952, disc_loss = 0.0008741369310489578
Trained batch 185 in epoch 9, gen_loss = 0.9805161235153034, disc_loss = 0.0008728620023541753
Trained batch 186 in epoch 9, gen_loss = 0.9803242664286159, disc_loss = 0.0008737921455182773
Trained batch 187 in epoch 9, gen_loss = 0.980153463622357, disc_loss = 0.0008759697427988013
Trained batch 188 in epoch 9, gen_loss = 0.9805619508501083, disc_loss = 0.0008776113560309919
Trained batch 189 in epoch 9, gen_loss = 0.9805814705396954, disc_loss = 0.0008782615839185095
Trained batch 190 in epoch 9, gen_loss = 0.9804794189193486, disc_loss = 0.0008792209293308097
Trained batch 191 in epoch 9, gen_loss = 0.9805945778886477, disc_loss = 0.000880132843121828
Trained batch 192 in epoch 9, gen_loss = 0.9808778911056913, disc_loss = 0.0008817164524738228
Trained batch 193 in epoch 9, gen_loss = 0.9806171047318842, disc_loss = 0.0008832537884147089
Trained batch 194 in epoch 9, gen_loss = 0.9805304411130074, disc_loss = 0.0008850632190632705
Trained batch 195 in epoch 9, gen_loss = 0.9807667166602855, disc_loss = 0.0008869185626188445
Trained batch 196 in epoch 9, gen_loss = 0.9806756325784673, disc_loss = 0.0008901043911464512
Trained batch 197 in epoch 9, gen_loss = 0.9806232882870568, disc_loss = 0.0008944242347779712
Trained batch 198 in epoch 9, gen_loss = 0.9805233319800104, disc_loss = 0.0008995635771361091
Trained batch 199 in epoch 9, gen_loss = 0.9802170500159264, disc_loss = 0.0009050175370066426
Trained batch 200 in epoch 9, gen_loss = 0.980318301649236, disc_loss = 0.0009104168811113347
Trained batch 201 in epoch 9, gen_loss = 0.9804115044598533, disc_loss = 0.0009146165036444211
Trained batch 202 in epoch 9, gen_loss = 0.9805312864298891, disc_loss = 0.0009165114755834007
Trained batch 203 in epoch 9, gen_loss = 0.9805261457667631, disc_loss = 0.0009166121790436663
Testing Epoch 9
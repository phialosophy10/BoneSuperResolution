/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.1082649230957031, disc_loss = 0.7307771444320679
Trained batch 1 in epoch 0, gen_loss = 1.3420305252075195, disc_loss = 1.218059480190277
Trained batch 2 in epoch 0, gen_loss = 1.2277504205703735, disc_loss = 0.9688456952571869
Trained batch 3 in epoch 0, gen_loss = 1.133903905749321, disc_loss = 0.8255888223648071
Trained batch 4 in epoch 0, gen_loss = 1.0563207864761353, disc_loss = 0.72455233335495
Trained batch 5 in epoch 0, gen_loss = 0.99699733654658, disc_loss = 0.653297538558642
Trained batch 6 in epoch 0, gen_loss = 0.9519133993557521, disc_loss = 0.5978923738002777
Trained batch 7 in epoch 0, gen_loss = 0.9274883791804314, disc_loss = 0.5496074203401804
Trained batch 8 in epoch 0, gen_loss = 0.9053086241086324, disc_loss = 0.508224681019783
Trained batch 9 in epoch 0, gen_loss = 0.8896805822849274, disc_loss = 0.4728337302803993
Trained batch 10 in epoch 0, gen_loss = 0.8796190131794323, disc_loss = 0.44654710455374286
Trained batch 11 in epoch 0, gen_loss = 0.8667801221211752, disc_loss = 0.4231518432497978
Trained batch 12 in epoch 0, gen_loss = 0.8518638152342576, disc_loss = 0.4027458635660318
Trained batch 13 in epoch 0, gen_loss = 0.8430299162864685, disc_loss = 0.387310871056148
Trained batch 14 in epoch 0, gen_loss = 0.8456487894058228, disc_loss = 0.37553539176781975
Trained batch 15 in epoch 0, gen_loss = 0.847086064517498, disc_loss = 0.3635962586849928
Trained batch 16 in epoch 0, gen_loss = 0.8504549054538503, disc_loss = 0.3518844781553044
Trained batch 17 in epoch 0, gen_loss = 0.8579980466100905, disc_loss = 0.33953572975264656
Trained batch 18 in epoch 0, gen_loss = 0.8676645065608778, disc_loss = 0.326806156258834
Trained batch 19 in epoch 0, gen_loss = 0.878515750169754, disc_loss = 0.3142630115151405
Trained batch 20 in epoch 0, gen_loss = 0.8862043165025257, disc_loss = 0.3036274388432503
Trained batch 21 in epoch 0, gen_loss = 0.896128616549752, disc_loss = 0.29604652016000316
Trained batch 22 in epoch 0, gen_loss = 0.9022735771925553, disc_loss = 0.28781546166409616
Trained batch 23 in epoch 0, gen_loss = 0.9024388045072556, disc_loss = 0.2797597339376807
Trained batch 24 in epoch 0, gen_loss = 0.8934582662582398, disc_loss = 0.27561546593904496
Trained batch 25 in epoch 0, gen_loss = 0.9042567106393667, disc_loss = 0.2710011718937984
Trained batch 26 in epoch 0, gen_loss = 0.8992564589888962, disc_loss = 0.2654861319396231
Trained batch 27 in epoch 0, gen_loss = 0.8974740377494267, disc_loss = 0.2610957949821438
Trained batch 28 in epoch 0, gen_loss = 0.8987981800375313, disc_loss = 0.25937640744036644
Trained batch 29 in epoch 0, gen_loss = 0.9053366760412852, disc_loss = 0.26090193962057434
Trained batch 30 in epoch 0, gen_loss = 0.906125545501709, disc_loss = 0.2580178271858923
Trained batch 31 in epoch 0, gen_loss = 0.9033179357647896, disc_loss = 0.2550602799747139
Trained batch 32 in epoch 0, gen_loss = 0.9025591322869966, disc_loss = 0.25024890380375314
Trained batch 33 in epoch 0, gen_loss = 0.9040168103049783, disc_loss = 0.2457537147052148
Trained batch 34 in epoch 0, gen_loss = 0.9049690416881017, disc_loss = 0.2411288870232446
Trained batch 35 in epoch 0, gen_loss = 0.9041748609807756, disc_loss = 0.23620684175855583
Trained batch 36 in epoch 0, gen_loss = 0.9030788653605694, disc_loss = 0.23152711524351224
Trained batch 37 in epoch 0, gen_loss = 0.905165107626664, disc_loss = 0.22687660392962003
Trained batch 38 in epoch 0, gen_loss = 0.9060078523097894, disc_loss = 0.2223798013650454
Trained batch 39 in epoch 0, gen_loss = 0.9063019663095474, disc_loss = 0.21830136515200138
Trained batch 40 in epoch 0, gen_loss = 0.9048737781803783, disc_loss = 0.2144452582408742
Trained batch 41 in epoch 0, gen_loss = 0.9072286600158328, disc_loss = 0.21055046646367936
Trained batch 42 in epoch 0, gen_loss = 0.9093345265055812, disc_loss = 0.20725322705368662
Trained batch 43 in epoch 0, gen_loss = 0.9091756452213634, disc_loss = 0.20390213230116802
Trained batch 44 in epoch 0, gen_loss = 0.9112866772545709, disc_loss = 0.20085505098104478
Trained batch 45 in epoch 0, gen_loss = 0.9140872437021007, disc_loss = 0.19773556972327438
Trained batch 46 in epoch 0, gen_loss = 0.9185298199349261, disc_loss = 0.19465846370192283
Trained batch 47 in epoch 0, gen_loss = 0.9219667663176855, disc_loss = 0.1915462234367927
Trained batch 48 in epoch 0, gen_loss = 0.9267393350601196, disc_loss = 0.18852481093941903
Trained batch 49 in epoch 0, gen_loss = 0.9295208334922791, disc_loss = 0.1856254780292511
Trained batch 50 in epoch 0, gen_loss = 0.9323676824569702, disc_loss = 0.18274106077995955
Trained batch 51 in epoch 0, gen_loss = 0.9355733692646027, disc_loss = 0.18032060427447924
Trained batch 52 in epoch 0, gen_loss = 0.9417765522902867, disc_loss = 0.17798541366772833
Trained batch 53 in epoch 0, gen_loss = 0.9433883472725197, disc_loss = 0.17619046010077
Trained batch 54 in epoch 0, gen_loss = 0.9442131454294378, disc_loss = 0.17420967891812325
Trained batch 55 in epoch 0, gen_loss = 0.9480755392994199, disc_loss = 0.17267314816958138
Trained batch 56 in epoch 0, gen_loss = 0.9457544517098811, disc_loss = 0.1714703413870251
Trained batch 57 in epoch 0, gen_loss = 0.9484903946005064, disc_loss = 0.17007041356429972
Trained batch 58 in epoch 0, gen_loss = 0.9479275911541308, disc_loss = 0.167986070895094
Trained batch 59 in epoch 0, gen_loss = 0.9473654299974441, disc_loss = 0.16598887337992588
Trained batch 60 in epoch 0, gen_loss = 0.9492632727153966, disc_loss = 0.16406054080265467
Trained batch 61 in epoch 0, gen_loss = 0.9521373212337494, disc_loss = 0.16196792554711142
Trained batch 62 in epoch 0, gen_loss = 0.9510930615758139, disc_loss = 0.16022898859920956
Trained batch 63 in epoch 0, gen_loss = 0.9487466299906373, disc_loss = 0.1585140364477411
Trained batch 64 in epoch 0, gen_loss = 0.952690616937784, disc_loss = 0.1570650578691409
Trained batch 65 in epoch 0, gen_loss = 0.9542935156460964, disc_loss = 0.1554255781864578
Trained batch 66 in epoch 0, gen_loss = 0.9531781157450889, disc_loss = 0.15391163700329724
Trained batch 67 in epoch 0, gen_loss = 0.9552149194128373, disc_loss = 0.15222491280120962
Trained batch 68 in epoch 0, gen_loss = 0.9559165291164232, disc_loss = 0.15049737475920413
Trained batch 69 in epoch 0, gen_loss = 0.9553651119981493, disc_loss = 0.14884805099240372
Trained batch 70 in epoch 0, gen_loss = 0.9559972109928937, disc_loss = 0.14716974965913196
Trained batch 71 in epoch 0, gen_loss = 0.9567783797780672, disc_loss = 0.1456200139493578
Trained batch 72 in epoch 0, gen_loss = 0.9559903512262318, disc_loss = 0.14404347931889638
Trained batch 73 in epoch 0, gen_loss = 0.9555958501390509, disc_loss = 0.1426447885161316
Trained batch 74 in epoch 0, gen_loss = 0.9578875168164571, disc_loss = 0.14136671031514803
Trained batch 75 in epoch 0, gen_loss = 0.9556483963602468, disc_loss = 0.14050123718028007
Trained batch 76 in epoch 0, gen_loss = 0.958807283407682, disc_loss = 0.14047511981485725
Trained batch 77 in epoch 0, gen_loss = 0.9591902158199213, disc_loss = 0.13937131821727142
Trained batch 78 in epoch 0, gen_loss = 0.9558257747300064, disc_loss = 0.14003015441607825
Trained batch 79 in epoch 0, gen_loss = 0.9576054148375988, disc_loss = 0.13980251615867018
Trained batch 80 in epoch 0, gen_loss = 0.9573415753282146, disc_loss = 0.13884016420738196
Trained batch 81 in epoch 0, gen_loss = 0.9563483152447677, disc_loss = 0.13793972289053405
Trained batch 82 in epoch 0, gen_loss = 0.9552617231047297, disc_loss = 0.1369722510676786
Trained batch 83 in epoch 0, gen_loss = 0.9553909358524141, disc_loss = 0.1360843319534546
Trained batch 84 in epoch 0, gen_loss = 0.9548700711306404, disc_loss = 0.13533649422666605
Trained batch 85 in epoch 0, gen_loss = 0.955802041430806, disc_loss = 0.13442419213784296
Trained batch 86 in epoch 0, gen_loss = 0.9556342808679602, disc_loss = 0.13335844347703046
Trained batch 87 in epoch 0, gen_loss = 0.9566600356589664, disc_loss = 0.13226119128309868
Trained batch 88 in epoch 0, gen_loss = 0.9548501024085484, disc_loss = 0.13171957939695778
Trained batch 89 in epoch 0, gen_loss = 0.95795885125796, disc_loss = 0.13156238401101694
Trained batch 90 in epoch 0, gen_loss = 0.9563750853905311, disc_loss = 0.1310208094725897
Trained batch 91 in epoch 0, gen_loss = 0.9569898014483245, disc_loss = 0.130212370103792
Trained batch 92 in epoch 0, gen_loss = 0.954179847112266, disc_loss = 0.13021577137612528
Trained batch 93 in epoch 0, gen_loss = 0.956252229974625, disc_loss = 0.1298825917963652
Trained batch 94 in epoch 0, gen_loss = 0.9540584840272602, disc_loss = 0.12937027949251625
Trained batch 95 in epoch 0, gen_loss = 0.9541929550468922, disc_loss = 0.12849978532176465
Trained batch 96 in epoch 0, gen_loss = 0.9550889165131087, disc_loss = 0.12767836985360717
Trained batch 97 in epoch 0, gen_loss = 0.9594382643699646, disc_loss = 0.1270570094716184
Trained batch 98 in epoch 0, gen_loss = 0.9590373767746819, disc_loss = 0.12650478973683685
Trained batch 99 in epoch 0, gen_loss = 0.9601617509126663, disc_loss = 0.12557057216763495
Trained batch 100 in epoch 0, gen_loss = 0.9591670018611568, disc_loss = 0.12567838392045239
Trained batch 101 in epoch 0, gen_loss = 0.9560912362500733, disc_loss = 0.1264825285065408
Trained batch 102 in epoch 0, gen_loss = 0.9582448057757998, disc_loss = 0.1280799988404061
Trained batch 103 in epoch 0, gen_loss = 0.956212074137651, disc_loss = 0.12826703417186552
Trained batch 104 in epoch 0, gen_loss = 0.9547364740144639, disc_loss = 0.12787586216415678
Trained batch 105 in epoch 0, gen_loss = 0.9563371488508189, disc_loss = 0.12754934836389883
Trained batch 106 in epoch 0, gen_loss = 0.9566735992921847, disc_loss = 0.12684294671934343
Trained batch 107 in epoch 0, gen_loss = 0.9557639001696198, disc_loss = 0.12641555381317934
Trained batch 108 in epoch 0, gen_loss = 0.954768828842618, disc_loss = 0.1258768930074272
Trained batch 109 in epoch 0, gen_loss = 0.9548279242082076, disc_loss = 0.12540737973018126
Trained batch 110 in epoch 0, gen_loss = 0.9535296994286615, disc_loss = 0.1252393523180807
Trained batch 111 in epoch 0, gen_loss = 0.9546977260283062, disc_loss = 0.12522612532068575
Trained batch 112 in epoch 0, gen_loss = 0.9535323492193644, disc_loss = 0.12513244013606975
Trained batch 113 in epoch 0, gen_loss = 0.9544801759092432, disc_loss = 0.12466323081600039
Trained batch 114 in epoch 0, gen_loss = 0.9538581055143606, disc_loss = 0.12417069751283397
Trained batch 115 in epoch 0, gen_loss = 0.9526284239415465, disc_loss = 0.12387922399773679
Trained batch 116 in epoch 0, gen_loss = 0.9543567422108773, disc_loss = 0.12402668372433409
Trained batch 117 in epoch 0, gen_loss = 0.9519514461695138, disc_loss = 0.1252551430489047
Trained batch 118 in epoch 0, gen_loss = 0.9530263918788493, disc_loss = 0.1255272209268658
Trained batch 119 in epoch 0, gen_loss = 0.9520340442657471, disc_loss = 0.12576949391514064
Trained batch 120 in epoch 0, gen_loss = 0.9530405318441469, disc_loss = 0.12594187179626512
Trained batch 121 in epoch 0, gen_loss = 0.9546908560346384, disc_loss = 0.12551485563887924
Trained batch 122 in epoch 0, gen_loss = 0.9538286139325398, disc_loss = 0.12509882328956107
Trained batch 123 in epoch 0, gen_loss = 0.9566557493902021, disc_loss = 0.12442631659007841
Trained batch 124 in epoch 0, gen_loss = 0.9562567958831787, disc_loss = 0.1238612889945507
Trained batch 125 in epoch 0, gen_loss = 0.9552171892589993, disc_loss = 0.12341214003898794
Trained batch 126 in epoch 0, gen_loss = 0.9559264849490068, disc_loss = 0.12316723898287833
Trained batch 127 in epoch 0, gen_loss = 0.9532333142124116, disc_loss = 0.12354708267957903
Trained batch 128 in epoch 0, gen_loss = 0.955225082792977, disc_loss = 0.12450816075122634
Trained batch 129 in epoch 0, gen_loss = 0.9537643767320193, disc_loss = 0.12419214618320648
Trained batch 130 in epoch 0, gen_loss = 0.9525555677086343, disc_loss = 0.12374167078892694
Trained batch 131 in epoch 0, gen_loss = 0.9528672189423533, disc_loss = 0.1237966599168651
Trained batch 132 in epoch 0, gen_loss = 0.9512257163685963, disc_loss = 0.12371421165596273
Trained batch 133 in epoch 0, gen_loss = 0.950894706284822, disc_loss = 0.12316535616210147
Trained batch 134 in epoch 0, gen_loss = 0.9514898123564544, disc_loss = 0.12274268686219499
Trained batch 135 in epoch 0, gen_loss = 0.9502899366266587, disc_loss = 0.122465376769576
Trained batch 136 in epoch 0, gen_loss = 0.9513760709414517, disc_loss = 0.12218600449009534
Trained batch 137 in epoch 0, gen_loss = 0.9517390650251637, disc_loss = 0.12153665170721385
Trained batch 138 in epoch 0, gen_loss = 0.9511196759107302, disc_loss = 0.12103060774987551
Trained batch 139 in epoch 0, gen_loss = 0.950761912550245, disc_loss = 0.12050645223685673
Trained batch 140 in epoch 0, gen_loss = 0.9516858538837297, disc_loss = 0.12000059901822543
Trained batch 141 in epoch 0, gen_loss = 0.9514024958644115, disc_loss = 0.11951772952583474
Trained batch 142 in epoch 0, gen_loss = 0.9508417006972787, disc_loss = 0.11911823030014138
Trained batch 143 in epoch 0, gen_loss = 0.9514093411465486, disc_loss = 0.11857244393063916
Trained batch 144 in epoch 0, gen_loss = 0.9529043209963831, disc_loss = 0.11803576748432784
Trained batch 145 in epoch 0, gen_loss = 0.9514067920103465, disc_loss = 0.1185007961594487
Trained batch 146 in epoch 0, gen_loss = 0.9547580200798658, disc_loss = 0.12015963013784416
Trained batch 147 in epoch 0, gen_loss = 0.9529296546368986, disc_loss = 0.12105115973768202
Trained batch 148 in epoch 0, gen_loss = 0.9523112729891835, disc_loss = 0.12080436162400565
Trained batch 149 in epoch 0, gen_loss = 0.9514634184042613, disc_loss = 0.12120121804376444
Trained batch 150 in epoch 0, gen_loss = 0.9498294659008254, disc_loss = 0.12163142778522132
Trained batch 151 in epoch 0, gen_loss = 0.9487011342456466, disc_loss = 0.12168433387322646
Trained batch 152 in epoch 0, gen_loss = 0.9483585587513992, disc_loss = 0.1219184304910158
Trained batch 153 in epoch 0, gen_loss = 0.9472589872100137, disc_loss = 0.12213492100792271
Trained batch 154 in epoch 0, gen_loss = 0.947744067253605, disc_loss = 0.1222640042103106
Trained batch 155 in epoch 0, gen_loss = 0.9469629499392632, disc_loss = 0.12201972246074523
Trained batch 156 in epoch 0, gen_loss = 0.945189017778749, disc_loss = 0.12206379573341387
Trained batch 157 in epoch 0, gen_loss = 0.9459806337386747, disc_loss = 0.12240014024833336
Trained batch 158 in epoch 0, gen_loss = 0.9444915082469676, disc_loss = 0.12254176281814305
Trained batch 159 in epoch 0, gen_loss = 0.9451842423528433, disc_loss = 0.12276296352501959
Trained batch 160 in epoch 0, gen_loss = 0.9436608097568062, disc_loss = 0.12308207401855392
Trained batch 161 in epoch 0, gen_loss = 0.9432608275501816, disc_loss = 0.12314720467928751
Trained batch 162 in epoch 0, gen_loss = 0.9423193324562962, disc_loss = 0.12317524601253996
Trained batch 163 in epoch 0, gen_loss = 0.943370479636076, disc_loss = 0.12395463209235813
Trained batch 164 in epoch 0, gen_loss = 0.9418112657286904, disc_loss = 0.12436473249937549
Trained batch 165 in epoch 0, gen_loss = 0.9418998780738876, disc_loss = 0.12460779836289136
Trained batch 166 in epoch 0, gen_loss = 0.9399194881587685, disc_loss = 0.12488892386684161
Trained batch 167 in epoch 0, gen_loss = 0.9401942736336163, disc_loss = 0.12481741773496781
Trained batch 168 in epoch 0, gen_loss = 0.9404762337899067, disc_loss = 0.12448189392156855
Trained batch 169 in epoch 0, gen_loss = 0.9399117932600134, disc_loss = 0.12419774630928741
Trained batch 170 in epoch 0, gen_loss = 0.9390807287734851, disc_loss = 0.12403804427611897
Trained batch 171 in epoch 0, gen_loss = 0.9386527572953424, disc_loss = 0.12374004156350396
Trained batch 172 in epoch 0, gen_loss = 0.9408938443729643, disc_loss = 0.12385160598710093
Trained batch 173 in epoch 0, gen_loss = 0.9394488923851101, disc_loss = 0.12391588243859253
Trained batch 174 in epoch 0, gen_loss = 0.9391937562397548, disc_loss = 0.12357018234474318
Trained batch 175 in epoch 0, gen_loss = 0.9402423358776353, disc_loss = 0.12450700881890953
Trained batch 176 in epoch 0, gen_loss = 0.9389300972728406, disc_loss = 0.12486534353114118
Trained batch 177 in epoch 0, gen_loss = 0.9389235223277231, disc_loss = 0.12450673360000836
Trained batch 178 in epoch 0, gen_loss = 0.9393431008195078, disc_loss = 0.1242746418165095
Trained batch 179 in epoch 0, gen_loss = 0.937907252046797, disc_loss = 0.12470507369273238
Trained batch 180 in epoch 0, gen_loss = 0.9381945251759903, disc_loss = 0.1250391029932881
Trained batch 181 in epoch 0, gen_loss = 0.9367345427418803, disc_loss = 0.12529460655955169
Trained batch 182 in epoch 0, gen_loss = 0.936422494916968, disc_loss = 0.12529644919712035
Trained batch 183 in epoch 0, gen_loss = 0.9365505164732104, disc_loss = 0.12532955970939086
Trained batch 184 in epoch 0, gen_loss = 0.9353580139778755, disc_loss = 0.1252406162587372
Trained batch 185 in epoch 0, gen_loss = 0.9349565480345039, disc_loss = 0.12498179450631142
Trained batch 186 in epoch 0, gen_loss = 0.93606849787707, disc_loss = 0.1250846509866536
Trained batch 187 in epoch 0, gen_loss = 0.9342127391632568, disc_loss = 0.12619062525002248
Trained batch 188 in epoch 0, gen_loss = 0.9353613916528288, disc_loss = 0.12691566076070543
Trained batch 189 in epoch 0, gen_loss = 0.934146986823333, disc_loss = 0.1270111674933057
Trained batch 190 in epoch 0, gen_loss = 0.932906727204148, disc_loss = 0.12712208033388198
Trained batch 191 in epoch 0, gen_loss = 0.9325607862944404, disc_loss = 0.12694180566662303
Trained batch 192 in epoch 0, gen_loss = 0.9318058648257675, disc_loss = 0.1270308662495465
Trained batch 193 in epoch 0, gen_loss = 0.9305928659807775, disc_loss = 0.12725858670688167
Trained batch 194 in epoch 0, gen_loss = 0.9309019837623987, disc_loss = 0.12788587315724445
Trained batch 195 in epoch 0, gen_loss = 0.9295557317685108, disc_loss = 0.12796994789066363
Trained batch 196 in epoch 0, gen_loss = 0.9293631635946671, disc_loss = 0.1279292847148053
Trained batch 197 in epoch 0, gen_loss = 0.9288222377348427, disc_loss = 0.1276261041110212
Trained batch 198 in epoch 0, gen_loss = 0.9283547044998437, disc_loss = 0.12737069088010933
Trained batch 199 in epoch 0, gen_loss = 0.9291416206955909, disc_loss = 0.1271355862542987
Trained batch 200 in epoch 0, gen_loss = 0.9279733833981983, disc_loss = 0.12732995138387776
Trained batch 201 in epoch 0, gen_loss = 0.9297189750883839, disc_loss = 0.1274804779429837
Trained batch 202 in epoch 0, gen_loss = 0.92845984838279, disc_loss = 0.12759126594354367
Trained batch 203 in epoch 0, gen_loss = 0.9280893159847633, disc_loss = 0.12767879383675024
Trained batch 204 in epoch 0, gen_loss = 0.9291722262777933, disc_loss = 0.12813167633806788
Trained batch 205 in epoch 0, gen_loss = 0.9281509431820472, disc_loss = 0.12824007431135595
Trained batch 206 in epoch 0, gen_loss = 0.9272154644491591, disc_loss = 0.12827833029239075
Trained batch 207 in epoch 0, gen_loss = 0.9270352274179459, disc_loss = 0.1283549265577816
Trained batch 208 in epoch 0, gen_loss = 0.9263895336520729, disc_loss = 0.1282792630021652
Trained batch 209 in epoch 0, gen_loss = 0.9254177962030683, disc_loss = 0.1282581562442439
Trained batch 210 in epoch 0, gen_loss = 0.9253611872546481, disc_loss = 0.12844433889711074
Trained batch 211 in epoch 0, gen_loss = 0.9240522570205185, disc_loss = 0.12864259416061752
Trained batch 212 in epoch 0, gen_loss = 0.9244009726484057, disc_loss = 0.12887450097732142
Trained batch 213 in epoch 0, gen_loss = 0.9234543353597694, disc_loss = 0.12945298526749432
Trained batch 214 in epoch 0, gen_loss = 0.9241955651793369, disc_loss = 0.1295814017570296
Trained batch 215 in epoch 0, gen_loss = 0.9243700046230245, disc_loss = 0.12958184805595213
Trained batch 216 in epoch 0, gen_loss = 0.9230514745558461, disc_loss = 0.1299129415835653
Trained batch 217 in epoch 0, gen_loss = 0.9228297146635318, disc_loss = 0.1299293395644481
Trained batch 218 in epoch 0, gen_loss = 0.9222113068245318, disc_loss = 0.130108413596948
Trained batch 219 in epoch 0, gen_loss = 0.9225745824250308, disc_loss = 0.13001498823816127
Trained batch 220 in epoch 0, gen_loss = 0.9220730934747204, disc_loss = 0.1297036852030193
Trained batch 221 in epoch 0, gen_loss = 0.921553978511879, disc_loss = 0.1296840019792587
Trained batch 222 in epoch 0, gen_loss = 0.9232449242886941, disc_loss = 0.1306259526198755
Trained batch 223 in epoch 0, gen_loss = 0.9216537861419576, disc_loss = 0.1317168179832931
Trained batch 224 in epoch 0, gen_loss = 0.9212507523430719, disc_loss = 0.13188312315278583
Trained batch 225 in epoch 0, gen_loss = 0.9215273163487426, disc_loss = 0.13205582111150818
Trained batch 226 in epoch 0, gen_loss = 0.921159623215377, disc_loss = 0.13201633594634773
Trained batch 227 in epoch 0, gen_loss = 0.9206826307794505, disc_loss = 0.131958714964097
Trained batch 228 in epoch 0, gen_loss = 0.9205991763735443, disc_loss = 0.13200558624413336
Trained batch 229 in epoch 0, gen_loss = 0.9202699899673462, disc_loss = 0.1320183272594991
Trained batch 230 in epoch 0, gen_loss = 0.9198907058992427, disc_loss = 0.13198428984844324
Trained batch 231 in epoch 0, gen_loss = 0.91970352802811, disc_loss = 0.13187527785013461
Trained batch 232 in epoch 0, gen_loss = 0.9194247932393151, disc_loss = 0.13176194050792972
Trained batch 233 in epoch 0, gen_loss = 0.9188232039793943, disc_loss = 0.13174245124443984
Trained batch 234 in epoch 0, gen_loss = 0.920287274299784, disc_loss = 0.13184650432556233
Trained batch 235 in epoch 0, gen_loss = 0.9196901366872302, disc_loss = 0.1319348203428721
Trained batch 236 in epoch 0, gen_loss = 0.9197357623888973, disc_loss = 0.13204530988061478
Trained batch 237 in epoch 0, gen_loss = 0.9187462074416024, disc_loss = 0.13206276285047291
Trained batch 238 in epoch 0, gen_loss = 0.9194163981840701, disc_loss = 0.13199791031651917
Trained batch 239 in epoch 0, gen_loss = 0.9188134717444579, disc_loss = 0.13181013443196812
Trained batch 240 in epoch 0, gen_loss = 0.9180926848743961, disc_loss = 0.13170404775508707
Trained batch 241 in epoch 0, gen_loss = 0.9184971345850259, disc_loss = 0.13155316897044497
Trained batch 242 in epoch 0, gen_loss = 0.9176636671823729, disc_loss = 0.1315138091337043
Trained batch 243 in epoch 0, gen_loss = 0.9183538324031674, disc_loss = 0.13188957487095576
Trained batch 244 in epoch 0, gen_loss = 0.9175574767346285, disc_loss = 0.1317931717451738
Trained batch 245 in epoch 0, gen_loss = 0.9166835146706279, disc_loss = 0.13166989528430187
Trained batch 246 in epoch 0, gen_loss = 0.917080483697204, disc_loss = 0.13168346975375766
Trained batch 247 in epoch 0, gen_loss = 0.9161910878554467, disc_loss = 0.1316648389122659
Testing Epoch 0

  0%|          | 0/25 [00:00<?, ?it/s]
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.9851702451705933, disc_loss = 0.10437895357608795
Trained batch 1 in epoch 1, gen_loss = 0.8840855956077576, disc_loss = 0.08732680231332779
Trained batch 2 in epoch 1, gen_loss = 0.9378501176834106, disc_loss = 0.07947458078463872
Trained batch 3 in epoch 1, gen_loss = 0.8832216560840607, disc_loss = 0.08509168215095997
Trained batch 4 in epoch 1, gen_loss = 0.9067845106124878, disc_loss = 0.08253035247325897
Trained batch 5 in epoch 1, gen_loss = 0.891512930393219, disc_loss = 0.07983750229080518
Trained batch 6 in epoch 1, gen_loss = 0.873633861541748, disc_loss = 0.08040956833532878
Trained batch 7 in epoch 1, gen_loss = 0.8972345888614655, disc_loss = 0.07668200600892305
Trained batch 8 in epoch 1, gen_loss = 0.9197770489586724, disc_loss = 0.07088703289628029
Trained batch 9 in epoch 1, gen_loss = 0.9019638657569885, disc_loss = 0.07364863343536854
Trained batch 10 in epoch 1, gen_loss = 0.9140868403694846, disc_loss = 0.07497731359167532
Trained batch 11 in epoch 1, gen_loss = 0.9091203908125559, disc_loss = 0.07285192639877398
Trained batch 12 in epoch 1, gen_loss = 0.8978131551008958, disc_loss = 0.07458761993509072
Trained batch 13 in epoch 1, gen_loss = 0.9098960331508091, disc_loss = 0.0765897102121796
Trained batch 14 in epoch 1, gen_loss = 0.9049778779347738, disc_loss = 0.07873043393095334
Trained batch 15 in epoch 1, gen_loss = 0.9181124866008759, disc_loss = 0.0793425131123513
Trained batch 16 in epoch 1, gen_loss = 0.9055383415783153, disc_loss = 0.08004884882008328
Trained batch 17 in epoch 1, gen_loss = 0.9166867136955261, disc_loss = 0.08161237525443236
Trained batch 18 in epoch 1, gen_loss = 0.9035359872014899, disc_loss = 0.08333234939920275
Trained batch 19 in epoch 1, gen_loss = 0.9019147396087647, disc_loss = 0.08361732754856348
Trained batch 20 in epoch 1, gen_loss = 0.9145459731419882, disc_loss = 0.08858064544342813
Trained batch 21 in epoch 1, gen_loss = 0.8986039486798373, disc_loss = 0.09852878088978204
Trained batch 22 in epoch 1, gen_loss = 0.906218585760697, disc_loss = 0.105712889491216
Trained batch 23 in epoch 1, gen_loss = 0.9055940210819244, disc_loss = 0.1044829545232157
Trained batch 24 in epoch 1, gen_loss = 0.8965772771835328, disc_loss = 0.1062791569530964
Trained batch 25 in epoch 1, gen_loss = 0.892839484489881, disc_loss = 0.1056792760411134
Trained batch 26 in epoch 1, gen_loss = 0.901370417188715, disc_loss = 0.10700714546773168
Trained batch 27 in epoch 1, gen_loss = 0.8917225130966732, disc_loss = 0.1106878759871636
Trained batch 28 in epoch 1, gen_loss = 0.8950102945853924, disc_loss = 0.11101846563918837
Trained batch 29 in epoch 1, gen_loss = 0.8916198472181956, disc_loss = 0.1101018588989973
Trained batch 30 in epoch 1, gen_loss = 0.8863259880773483, disc_loss = 0.10958805067404624
Trained batch 31 in epoch 1, gen_loss = 0.8846336342394352, disc_loss = 0.10912253626156598
Trained batch 32 in epoch 1, gen_loss = 0.8834517417532025, disc_loss = 0.10870161121993353
Trained batch 33 in epoch 1, gen_loss = 0.8801271722597235, disc_loss = 0.10825639886452872
Trained batch 34 in epoch 1, gen_loss = 0.8759663803236825, disc_loss = 0.10686389984829085
Trained batch 35 in epoch 1, gen_loss = 0.8827624734905031, disc_loss = 0.10504973555604617
Trained batch 36 in epoch 1, gen_loss = 0.8767408793037003, disc_loss = 0.10880601849104907
Trained batch 37 in epoch 1, gen_loss = 0.8872251620418147, disc_loss = 0.11435931724937339
Trained batch 38 in epoch 1, gen_loss = 0.8838832546503116, disc_loss = 0.1133856733257954
Trained batch 39 in epoch 1, gen_loss = 0.8801912546157837, disc_loss = 0.11299561876803636
Trained batch 40 in epoch 1, gen_loss = 0.882743800558695, disc_loss = 0.11408875464666181
Trained batch 41 in epoch 1, gen_loss = 0.8796009165900094, disc_loss = 0.11409418125237737
Trained batch 42 in epoch 1, gen_loss = 0.8793080684750579, disc_loss = 0.11389823309903921
Trained batch 43 in epoch 1, gen_loss = 0.8777294077656486, disc_loss = 0.11289047873155637
Trained batch 44 in epoch 1, gen_loss = 0.8741139968236288, disc_loss = 0.11210056361224917
Trained batch 45 in epoch 1, gen_loss = 0.8758608128713525, disc_loss = 0.11182797295243843
Trained batch 46 in epoch 1, gen_loss = 0.8788026723455875, disc_loss = 0.11032626223056874
Trained batch 47 in epoch 1, gen_loss = 0.8733060831824938, disc_loss = 0.1109260581433773
Trained batch 48 in epoch 1, gen_loss = 0.8761511505866537, disc_loss = 0.10990555964562358
Trained batch 49 in epoch 1, gen_loss = 0.8781418097019196, disc_loss = 0.10904435351490975
Trained batch 50 in epoch 1, gen_loss = 0.8744766922558055, disc_loss = 0.11039660914855845
Trained batch 51 in epoch 1, gen_loss = 0.8769266926325284, disc_loss = 0.11065624382060307
Trained batch 52 in epoch 1, gen_loss = 0.8787179274379082, disc_loss = 0.10925692629139379
Trained batch 53 in epoch 1, gen_loss = 0.8744605658230958, disc_loss = 0.10945786894471557
Trained batch 54 in epoch 1, gen_loss = 0.8777992085977034, disc_loss = 0.10882003253156489
Trained batch 55 in epoch 1, gen_loss = 0.8788605034351349, disc_loss = 0.10778299852141313
Trained batch 56 in epoch 1, gen_loss = 0.8765480351029781, disc_loss = 0.10847253600756328
Trained batch 57 in epoch 1, gen_loss = 0.8776051381538654, disc_loss = 0.10814859461167763
Trained batch 58 in epoch 1, gen_loss = 0.8818455550630214, disc_loss = 0.1072518886777304
Trained batch 59 in epoch 1, gen_loss = 0.8795902947584788, disc_loss = 0.10716454070061446
Trained batch 60 in epoch 1, gen_loss = 0.8833254907951981, disc_loss = 0.1062885097182188
Trained batch 61 in epoch 1, gen_loss = 0.8831903117318307, disc_loss = 0.1054383585409772
Trained batch 62 in epoch 1, gen_loss = 0.8819327931555491, disc_loss = 0.10497002084813421
Trained batch 63 in epoch 1, gen_loss = 0.8869069395586848, disc_loss = 0.10440149524947628
Trained batch 64 in epoch 1, gen_loss = 0.8858919959801894, disc_loss = 0.10349470067482729
Trained batch 65 in epoch 1, gen_loss = 0.8906251399806051, disc_loss = 0.10256150285854485
Trained batch 66 in epoch 1, gen_loss = 0.893740211849782, disc_loss = 0.10132563069685181
Trained batch 67 in epoch 1, gen_loss = 0.8919153380043366, disc_loss = 0.10084721665172015
Trained batch 68 in epoch 1, gen_loss = 0.8959356693254001, disc_loss = 0.10134856165319249
Trained batch 69 in epoch 1, gen_loss = 0.8918959813458579, disc_loss = 0.1039678794997079
Trained batch 70 in epoch 1, gen_loss = 0.8957032141551166, disc_loss = 0.10507147265991694
Trained batch 71 in epoch 1, gen_loss = 0.894251373079088, disc_loss = 0.10443707928061485
Trained batch 72 in epoch 1, gen_loss = 0.8904984585226399, disc_loss = 0.10500729655566281
Trained batch 73 in epoch 1, gen_loss = 0.8914395296895826, disc_loss = 0.10537576453911292
Trained batch 74 in epoch 1, gen_loss = 0.8914778502782186, disc_loss = 0.1052534407377243
Trained batch 75 in epoch 1, gen_loss = 0.8896422213629672, disc_loss = 0.10539197892342743
Trained batch 76 in epoch 1, gen_loss = 0.8900191721978126, disc_loss = 0.10519415411082181
Trained batch 77 in epoch 1, gen_loss = 0.8862822758845794, disc_loss = 0.1059735459394944
Trained batch 78 in epoch 1, gen_loss = 0.8868853940239435, disc_loss = 0.10654374579840069
Trained batch 79 in epoch 1, gen_loss = 0.8854270160198212, disc_loss = 0.10654602637514472
Trained batch 80 in epoch 1, gen_loss = 0.8830176106205693, disc_loss = 0.1065917040830777
Trained batch 81 in epoch 1, gen_loss = 0.8829084525747997, disc_loss = 0.1071594204844498
Trained batch 82 in epoch 1, gen_loss = 0.8802753220121544, disc_loss = 0.1081229441137199
Trained batch 83 in epoch 1, gen_loss = 0.8799219088894981, disc_loss = 0.10887063418825467
Trained batch 84 in epoch 1, gen_loss = 0.8832317590713501, disc_loss = 0.10865903295138303
Trained batch 85 in epoch 1, gen_loss = 0.8824576742427294, disc_loss = 0.10812752771862717
Trained batch 86 in epoch 1, gen_loss = 0.882443080688345, disc_loss = 0.10736483215600595
Trained batch 87 in epoch 1, gen_loss = 0.8838549425656145, disc_loss = 0.10690031048249114
Trained batch 88 in epoch 1, gen_loss = 0.8823324086960782, disc_loss = 0.10652220408233364
Trained batch 89 in epoch 1, gen_loss = 0.8840116110112932, disc_loss = 0.10622883546683523
Trained batch 90 in epoch 1, gen_loss = 0.8837039929169875, disc_loss = 0.10564337924614058
Trained batch 91 in epoch 1, gen_loss = 0.8821455007014067, disc_loss = 0.10520503702371017
Trained batch 92 in epoch 1, gen_loss = 0.8843302521654355, disc_loss = 0.10531582915654747
Trained batch 93 in epoch 1, gen_loss = 0.8817281900568211, disc_loss = 0.10573159998401682
Trained batch 94 in epoch 1, gen_loss = 0.8825216889381409, disc_loss = 0.10525660475617961
Trained batch 95 in epoch 1, gen_loss = 0.8819843151917061, disc_loss = 0.10505973710678518
Trained batch 96 in epoch 1, gen_loss = 0.8833958801534987, disc_loss = 0.1047051119589314
Trained batch 97 in epoch 1, gen_loss = 0.8827973817076001, disc_loss = 0.10426987205841104
Trained batch 98 in epoch 1, gen_loss = 0.8866630967217263, disc_loss = 0.10362800617109645
Trained batch 99 in epoch 1, gen_loss = 0.8872037839889526, disc_loss = 0.10288556853309273
Trained batch 100 in epoch 1, gen_loss = 0.8904951256100494, disc_loss = 0.10224934875743814
Trained batch 101 in epoch 1, gen_loss = 0.8918141944735658, disc_loss = 0.10146424159699795
Trained batch 102 in epoch 1, gen_loss = 0.8920588342888841, disc_loss = 0.100806778640423
Trained batch 103 in epoch 1, gen_loss = 0.8931770336169463, disc_loss = 0.1002074467161527
Trained batch 104 in epoch 1, gen_loss = 0.8932608269509815, disc_loss = 0.09954964426301774
Trained batch 105 in epoch 1, gen_loss = 0.8963183822496882, disc_loss = 0.09889977154726128
Trained batch 106 in epoch 1, gen_loss = 0.8946130570964278, disc_loss = 0.09879672342789507
Trained batch 107 in epoch 1, gen_loss = 0.8953864944201929, disc_loss = 0.09872170437679247
Trained batch 108 in epoch 1, gen_loss = 0.8973503457296879, disc_loss = 0.09800204258719715
Trained batch 109 in epoch 1, gen_loss = 0.8954180777072906, disc_loss = 0.09846434491601858
Trained batch 110 in epoch 1, gen_loss = 0.8998367877693864, disc_loss = 0.10141864908976597
Trained batch 111 in epoch 1, gen_loss = 0.8992873675056866, disc_loss = 0.10093818834450628
Trained batch 112 in epoch 1, gen_loss = 0.8965416756351438, disc_loss = 0.10153221520306789
Trained batch 113 in epoch 1, gen_loss = 0.897193659815872, disc_loss = 0.10243140804793752
Trained batch 114 in epoch 1, gen_loss = 0.8965785544851552, disc_loss = 0.1028431172280208
Trained batch 115 in epoch 1, gen_loss = 0.8942878688203877, disc_loss = 0.10343788079275139
Trained batch 116 in epoch 1, gen_loss = 0.8937041188916589, disc_loss = 0.10353731074266964
Trained batch 117 in epoch 1, gen_loss = 0.892953830250239, disc_loss = 0.10393556330542443
Trained batch 118 in epoch 1, gen_loss = 0.8918384999788108, disc_loss = 0.10412168800204742
Trained batch 119 in epoch 1, gen_loss = 0.8907027125358582, disc_loss = 0.10442895637825131
Trained batch 120 in epoch 1, gen_loss = 0.8894184418946258, disc_loss = 0.10456342641110263
Trained batch 121 in epoch 1, gen_loss = 0.8892320238175939, disc_loss = 0.10427244267136347
Trained batch 122 in epoch 1, gen_loss = 0.8871695578582888, disc_loss = 0.10464334612091382
Trained batch 123 in epoch 1, gen_loss = 0.8869154587868722, disc_loss = 0.10478844370452627
Trained batch 124 in epoch 1, gen_loss = 0.8856517786979675, disc_loss = 0.10475106498599053
Trained batch 125 in epoch 1, gen_loss = 0.8839579815902407, disc_loss = 0.10471905989661104
Trained batch 126 in epoch 1, gen_loss = 0.8845005875497353, disc_loss = 0.10466143145687937
Trained batch 127 in epoch 1, gen_loss = 0.8840388390235603, disc_loss = 0.10411422641482204
Trained batch 128 in epoch 1, gen_loss = 0.8820559604223385, disc_loss = 0.10428743457147317
Trained batch 129 in epoch 1, gen_loss = 0.8828460422845987, disc_loss = 0.10481060112898166
Trained batch 130 in epoch 1, gen_loss = 0.8829155145710661, disc_loss = 0.10428082399809634
Trained batch 131 in epoch 1, gen_loss = 0.8805335701415034, disc_loss = 0.10520987407389013
Trained batch 132 in epoch 1, gen_loss = 0.8817006855979002, disc_loss = 0.10625275244054042
Trained batch 133 in epoch 1, gen_loss = 0.8809393026045899, disc_loss = 0.10614940838248872
Trained batch 134 in epoch 1, gen_loss = 0.8802445698667456, disc_loss = 0.10602808602982097
Trained batch 135 in epoch 1, gen_loss = 0.8792039134046611, disc_loss = 0.10594765685827416
Trained batch 136 in epoch 1, gen_loss = 0.8791380228787443, disc_loss = 0.10614875206438294
Trained batch 137 in epoch 1, gen_loss = 0.8786053592744081, disc_loss = 0.1058468944190637
Trained batch 138 in epoch 1, gen_loss = 0.8768758808108542, disc_loss = 0.10609550755336988
Trained batch 139 in epoch 1, gen_loss = 0.8779804774693081, disc_loss = 0.10694704324539218
Trained batch 140 in epoch 1, gen_loss = 0.8769409221114842, disc_loss = 0.10662775167019654
Trained batch 141 in epoch 1, gen_loss = 0.8763960704837047, disc_loss = 0.10623569812783053
Trained batch 142 in epoch 1, gen_loss = 0.8757914304733276, disc_loss = 0.10592638383378515
Trained batch 143 in epoch 1, gen_loss = 0.8754532345467143, disc_loss = 0.10600094579988056
Trained batch 144 in epoch 1, gen_loss = 0.8742652995833036, disc_loss = 0.10610303503685985
Trained batch 145 in epoch 1, gen_loss = 0.8743374163973822, disc_loss = 0.1060016043484211
Trained batch 146 in epoch 1, gen_loss = 0.8757193473731579, disc_loss = 0.10555548856959862
Trained batch 147 in epoch 1, gen_loss = 0.8747747854606526, disc_loss = 0.1053917194792145
Trained batch 148 in epoch 1, gen_loss = 0.8746641106253502, disc_loss = 0.10503785062156268
Trained batch 149 in epoch 1, gen_loss = 0.8746892905235291, disc_loss = 0.10461886405944824
Trained batch 150 in epoch 1, gen_loss = 0.8751623891047294, disc_loss = 0.10410435660588031
Trained batch 151 in epoch 1, gen_loss = 0.8758572732147417, disc_loss = 0.10355312737489217
Trained batch 152 in epoch 1, gen_loss = 0.8738626031314626, disc_loss = 0.10382367259049727
Trained batch 153 in epoch 1, gen_loss = 0.8750938966676787, disc_loss = 0.10400089415927212
Trained batch 154 in epoch 1, gen_loss = 0.8743539567916624, disc_loss = 0.10364698782082526
Trained batch 155 in epoch 1, gen_loss = 0.873248658883266, disc_loss = 0.10337511841685344
Trained batch 156 in epoch 1, gen_loss = 0.8727593585184426, disc_loss = 0.10304475338405865
Trained batch 157 in epoch 1, gen_loss = 0.8720743893822537, disc_loss = 0.10294974439694912
Trained batch 158 in epoch 1, gen_loss = 0.8727889402107623, disc_loss = 0.10244551393549023
Trained batch 159 in epoch 1, gen_loss = 0.8730100896209478, disc_loss = 0.10197015168378129
Trained batch 160 in epoch 1, gen_loss = 0.8729389691204759, disc_loss = 0.10145841926475119
Trained batch 161 in epoch 1, gen_loss = 0.8734789700419815, disc_loss = 0.10092109411862897
Trained batch 162 in epoch 1, gen_loss = 0.8740704421616771, disc_loss = 0.10054295126097335
Trained batch 163 in epoch 1, gen_loss = 0.8738048509126757, disc_loss = 0.10037536982719492
Trained batch 164 in epoch 1, gen_loss = 0.8765013402158564, disc_loss = 0.10030502898223473
Trained batch 165 in epoch 1, gen_loss = 0.8745206644736141, disc_loss = 0.10060752035084977
Trained batch 166 in epoch 1, gen_loss = 0.875928451201159, disc_loss = 0.10154585660753136
Trained batch 167 in epoch 1, gen_loss = 0.8763934224843979, disc_loss = 0.1010866794912588
Trained batch 168 in epoch 1, gen_loss = 0.8759826665093913, disc_loss = 0.10090978708140244
Trained batch 169 in epoch 1, gen_loss = 0.8749201974448035, disc_loss = 0.10101645676528706
Trained batch 170 in epoch 1, gen_loss = 0.8769748005253529, disc_loss = 0.10270756291367157
Trained batch 171 in epoch 1, gen_loss = 0.8758080133865046, disc_loss = 0.10319070795247721
Trained batch 172 in epoch 1, gen_loss = 0.8743295473170418, disc_loss = 0.1037611323974036
Trained batch 173 in epoch 1, gen_loss = 0.8751221425916956, disc_loss = 0.10452140156907597
Trained batch 174 in epoch 1, gen_loss = 0.8748147514888218, disc_loss = 0.10482527588094984
Trained batch 175 in epoch 1, gen_loss = 0.8734351186589762, disc_loss = 0.10512713198973374
Trained batch 176 in epoch 1, gen_loss = 0.8732133857947958, disc_loss = 0.10496517039288235
Trained batch 177 in epoch 1, gen_loss = 0.8733418131812235, disc_loss = 0.10497846877139606
Trained batch 178 in epoch 1, gen_loss = 0.8717507683365039, disc_loss = 0.10515716251547776
Trained batch 179 in epoch 1, gen_loss = 0.8710278113683064, disc_loss = 0.10521835680637094
Trained batch 180 in epoch 1, gen_loss = 0.8704831020608133, disc_loss = 0.10523904724180369
Trained batch 181 in epoch 1, gen_loss = 0.869882542025912, disc_loss = 0.10528268337577254
Trained batch 182 in epoch 1, gen_loss = 0.8691780625796709, disc_loss = 0.1051089808426268
Trained batch 183 in epoch 1, gen_loss = 0.8684963350710662, disc_loss = 0.10506776582611643
Trained batch 184 in epoch 1, gen_loss = 0.8682467315648054, disc_loss = 0.10511258723768029
Trained batch 185 in epoch 1, gen_loss = 0.867473421237802, disc_loss = 0.10507906208275467
Trained batch 186 in epoch 1, gen_loss = 0.8669570493188133, disc_loss = 0.1049022873375505
Trained batch 187 in epoch 1, gen_loss = 0.8673999379289911, disc_loss = 0.10469211891610572
Trained batch 188 in epoch 1, gen_loss = 0.8673372637657892, disc_loss = 0.10430848273256468
Trained batch 189 in epoch 1, gen_loss = 0.8686941815050024, disc_loss = 0.10386017900156347
Trained batch 190 in epoch 1, gen_loss = 0.8695493384181517, disc_loss = 0.1034130132440185
Trained batch 191 in epoch 1, gen_loss = 0.8696295022964478, disc_loss = 0.10303204728794906
Trained batch 192 in epoch 1, gen_loss = 0.8698423739541997, disc_loss = 0.10263449819324238
Trained batch 193 in epoch 1, gen_loss = 0.869924703516911, disc_loss = 0.1022531978363536
Trained batch 194 in epoch 1, gen_loss = 0.8706245773877853, disc_loss = 0.10194872256654959
Trained batch 195 in epoch 1, gen_loss = 0.8716029436612616, disc_loss = 0.10150585440462645
Trained batch 196 in epoch 1, gen_loss = 0.8709338594814242, disc_loss = 0.10129152477581792
Trained batch 197 in epoch 1, gen_loss = 0.8705382332055256, disc_loss = 0.10105056849054316
Trained batch 198 in epoch 1, gen_loss = 0.8709286789798257, disc_loss = 0.10113036040048204
Trained batch 199 in epoch 1, gen_loss = 0.8713444030284881, disc_loss = 0.10080855998210608
Trained batch 200 in epoch 1, gen_loss = 0.8710289303936175, disc_loss = 0.1005786963789469
Trained batch 201 in epoch 1, gen_loss = 0.8719251256177921, disc_loss = 0.10044293831296192
Trained batch 202 in epoch 1, gen_loss = 0.8716633173045266, disc_loss = 0.10011167863723386
Trained batch 203 in epoch 1, gen_loss = 0.8716128307814691, disc_loss = 0.09982236776975732
Trained batch 204 in epoch 1, gen_loss = 0.8725509925586421, disc_loss = 0.09960356877162689
Trained batch 205 in epoch 1, gen_loss = 0.8719934884784291, disc_loss = 0.0992790740616258
Trained batch 206 in epoch 1, gen_loss = 0.8724862927399971, disc_loss = 0.09896450123529216
Trained batch 207 in epoch 1, gen_loss = 0.8713743615035827, disc_loss = 0.09902234705917251
Trained batch 208 in epoch 1, gen_loss = 0.872328094032963, disc_loss = 0.09925284996878302
Trained batch 209 in epoch 1, gen_loss = 0.8719366646948314, disc_loss = 0.09895515955452408
Trained batch 210 in epoch 1, gen_loss = 0.8711203415811909, disc_loss = 0.09897829852645149
Trained batch 211 in epoch 1, gen_loss = 0.8713161880677601, disc_loss = 0.09897512182558202
Trained batch 212 in epoch 1, gen_loss = 0.871048026521441, disc_loss = 0.09880225301803278
Trained batch 213 in epoch 1, gen_loss = 0.8703559695560241, disc_loss = 0.09873096778048812
Trained batch 214 in epoch 1, gen_loss = 0.8713968911836314, disc_loss = 0.09850760735571384
Trained batch 215 in epoch 1, gen_loss = 0.8702489802682841, disc_loss = 0.09883336249428491
Trained batch 216 in epoch 1, gen_loss = 0.8711276430688146, disc_loss = 0.0988752349163942
Trained batch 217 in epoch 1, gen_loss = 0.8707775651314936, disc_loss = 0.09855077248237548
Trained batch 218 in epoch 1, gen_loss = 0.8704977672394008, disc_loss = 0.09829829847567702
Trained batch 219 in epoch 1, gen_loss = 0.8708474012938413, disc_loss = 0.09793504081158476
Trained batch 220 in epoch 1, gen_loss = 0.8708035757099342, disc_loss = 0.09760473522766414
Trained batch 221 in epoch 1, gen_loss = 0.8713317534945033, disc_loss = 0.09728076288828978
Trained batch 222 in epoch 1, gen_loss = 0.8704262362467334, disc_loss = 0.0971582651205127
Trained batch 223 in epoch 1, gen_loss = 0.8716994816703456, disc_loss = 0.09716376133396157
Trained batch 224 in epoch 1, gen_loss = 0.8725652625825671, disc_loss = 0.09684778696960873
Trained batch 225 in epoch 1, gen_loss = 0.8713266171712791, disc_loss = 0.09739794687623471
Trained batch 226 in epoch 1, gen_loss = 0.872602137962627, disc_loss = 0.09816244631874403
Trained batch 227 in epoch 1, gen_loss = 0.8715272242562813, disc_loss = 0.09827852389660843
Trained batch 228 in epoch 1, gen_loss = 0.8706089966161803, disc_loss = 0.09853755227212822
Trained batch 229 in epoch 1, gen_loss = 0.87067856270334, disc_loss = 0.09879848526223846
Trained batch 230 in epoch 1, gen_loss = 0.8700605300597815, disc_loss = 0.09878866345464409
Trained batch 231 in epoch 1, gen_loss = 0.8697249622180544, disc_loss = 0.09866901805046303
Trained batch 232 in epoch 1, gen_loss = 0.8689347101383454, disc_loss = 0.09858652757472747
Trained batch 233 in epoch 1, gen_loss = 0.8687128205584664, disc_loss = 0.09850248446067174
Trained batch 234 in epoch 1, gen_loss = 0.8692240580599359, disc_loss = 0.09837096232049009
Trained batch 235 in epoch 1, gen_loss = 0.8679525185439546, disc_loss = 0.09862903354026503
Trained batch 236 in epoch 1, gen_loss = 0.8682058637152241, disc_loss = 0.09873718828088623
Trained batch 237 in epoch 1, gen_loss = 0.8676630398806404, disc_loss = 0.09869724537144188
Trained batch 238 in epoch 1, gen_loss = 0.866623286921609, disc_loss = 0.09869668274245003
Trained batch 239 in epoch 1, gen_loss = 0.8663848305741946, disc_loss = 0.09891220896194379
Trained batch 240 in epoch 1, gen_loss = 0.8658787899986837, disc_loss = 0.09889812860251462
Trained batch 241 in epoch 1, gen_loss = 0.8649533206273702, disc_loss = 0.09893303407617837
Trained batch 242 in epoch 1, gen_loss = 0.8646415783544626, disc_loss = 0.098834250689534
Trained batch 243 in epoch 1, gen_loss = 0.8652304364520995, disc_loss = 0.09879185082238229
Trained batch 244 in epoch 1, gen_loss = 0.8647872547714077, disc_loss = 0.09855776879252219
Trained batch 245 in epoch 1, gen_loss = 0.8636926240552731, disc_loss = 0.09857243517550027
Trained batch 246 in epoch 1, gen_loss = 0.8641228936461784, disc_loss = 0.09851970101295696
Trained batch 247 in epoch 1, gen_loss = 0.863505923699948, disc_loss = 0.0984374435858861
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.8890355229377747, disc_loss = 0.0681430771946907
Trained batch 1 in epoch 2, gen_loss = 0.891946941614151, disc_loss = 0.06494846567511559
Trained batch 2 in epoch 2, gen_loss = 0.7859933773676554, disc_loss = 0.08103978633880615
Trained batch 3 in epoch 2, gen_loss = 0.820091962814331, disc_loss = 0.10589643940329552
Trained batch 4 in epoch 2, gen_loss = 0.7757568597793579, disc_loss = 0.11159913241863251
Trained batch 5 in epoch 2, gen_loss = 0.8339910904566447, disc_loss = 0.10772986710071564
Trained batch 6 in epoch 2, gen_loss = 0.8148222139903477, disc_loss = 0.11401566650186266
Trained batch 7 in epoch 2, gen_loss = 0.8199655637145042, disc_loss = 0.11313738860189915
Trained batch 8 in epoch 2, gen_loss = 0.818291876051161, disc_loss = 0.10619988996121618
Trained batch 9 in epoch 2, gen_loss = 0.8122047305107116, disc_loss = 0.10268275700509548
Trained batch 10 in epoch 2, gen_loss = 0.8133689761161804, disc_loss = 0.10030362856659022
Trained batch 11 in epoch 2, gen_loss = 0.8072299907604853, disc_loss = 0.09744223859161139
Trained batch 12 in epoch 2, gen_loss = 0.8012434106606704, disc_loss = 0.09418738375489528
Trained batch 13 in epoch 2, gen_loss = 0.8123742895466941, disc_loss = 0.09906273042517048
Trained batch 14 in epoch 2, gen_loss = 0.8035101691881815, disc_loss = 0.10001710231105486
Trained batch 15 in epoch 2, gen_loss = 0.8142702020704746, disc_loss = 0.0962938831653446
Trained batch 16 in epoch 2, gen_loss = 0.8046089691274306, disc_loss = 0.09633110704667427
Trained batch 17 in epoch 2, gen_loss = 0.8106965455744002, disc_loss = 0.09563273336324427
Trained batch 18 in epoch 2, gen_loss = 0.8053321995233235, disc_loss = 0.09289624012614552
Trained batch 19 in epoch 2, gen_loss = 0.8118258595466614, disc_loss = 0.08960417974740267
Trained batch 20 in epoch 2, gen_loss = 0.8173899224826268, disc_loss = 0.0864602415157216
Trained batch 21 in epoch 2, gen_loss = 0.819844660433856, disc_loss = 0.08409985197200016
Trained batch 22 in epoch 2, gen_loss = 0.8305783038553984, disc_loss = 0.08195147201742815
Trained batch 23 in epoch 2, gen_loss = 0.8410312011837959, disc_loss = 0.07949661238429447
Trained batch 24 in epoch 2, gen_loss = 0.8374487900733948, disc_loss = 0.07851506493985654
Trained batch 25 in epoch 2, gen_loss = 0.8433093268137711, disc_loss = 0.0771302141679021
Trained batch 26 in epoch 2, gen_loss = 0.8464102899586713, disc_loss = 0.07531697130589574
Trained batch 27 in epoch 2, gen_loss = 0.8400007890803474, disc_loss = 0.07599591856290187
Trained batch 28 in epoch 2, gen_loss = 0.8490086444492998, disc_loss = 0.07501665355059607
Trained batch 29 in epoch 2, gen_loss = 0.849381031592687, disc_loss = 0.07422845307737588
Trained batch 30 in epoch 2, gen_loss = 0.845584217579134, disc_loss = 0.07306830194448272
Trained batch 31 in epoch 2, gen_loss = 0.8449722453951836, disc_loss = 0.07212051429087296
Trained batch 32 in epoch 2, gen_loss = 0.8502526572256377, disc_loss = 0.07285045476799662
Trained batch 33 in epoch 2, gen_loss = 0.8440967359963585, disc_loss = 0.07456040935700431
Trained batch 34 in epoch 2, gen_loss = 0.8486289756638663, disc_loss = 0.07503330755446638
Trained batch 35 in epoch 2, gen_loss = 0.8432159440384971, disc_loss = 0.07641500819267498
Trained batch 36 in epoch 2, gen_loss = 0.845924166408745, disc_loss = 0.07765069407587116
Trained batch 37 in epoch 2, gen_loss = 0.844887270739204, disc_loss = 0.07752552966734297
Trained batch 38 in epoch 2, gen_loss = 0.8396575420330732, disc_loss = 0.07890413266917069
Trained batch 39 in epoch 2, gen_loss = 0.843308174610138, disc_loss = 0.08291595266200602
Trained batch 40 in epoch 2, gen_loss = 0.8366092370777596, disc_loss = 0.08667738503980928
Trained batch 41 in epoch 2, gen_loss = 0.834969372976394, disc_loss = 0.08780212899936098
Trained batch 42 in epoch 2, gen_loss = 0.8343371984570526, disc_loss = 0.08831072966893051
Trained batch 43 in epoch 2, gen_loss = 0.8322561274875294, disc_loss = 0.08921885291453112
Trained batch 44 in epoch 2, gen_loss = 0.8291044566366408, disc_loss = 0.0897364601906803
Trained batch 45 in epoch 2, gen_loss = 0.8320395441158958, disc_loss = 0.0902672185279105
Trained batch 46 in epoch 2, gen_loss = 0.8287702037933025, disc_loss = 0.08990106735616288
Trained batch 47 in epoch 2, gen_loss = 0.8248422642548879, disc_loss = 0.08976071580157925
Trained batch 48 in epoch 2, gen_loss = 0.830785084743889, disc_loss = 0.09010106450592985
Trained batch 49 in epoch 2, gen_loss = 0.8268977069854736, disc_loss = 0.09097741339355707
Trained batch 50 in epoch 2, gen_loss = 0.8310621556113748, disc_loss = 0.09035249854273655
Trained batch 51 in epoch 2, gen_loss = 0.8305958326046283, disc_loss = 0.0899817024787458
Trained batch 52 in epoch 2, gen_loss = 0.8287384858671224, disc_loss = 0.08973008770284788
Trained batch 53 in epoch 2, gen_loss = 0.8293007402508347, disc_loss = 0.08854024981458981
Trained batch 54 in epoch 2, gen_loss = 0.832008852741935, disc_loss = 0.0888034072789279
Trained batch 55 in epoch 2, gen_loss = 0.8286215343645641, disc_loss = 0.08932678161987237
Trained batch 56 in epoch 2, gen_loss = 0.8276054754591825, disc_loss = 0.08848836377524492
Trained batch 57 in epoch 2, gen_loss = 0.8311710686519228, disc_loss = 0.09011994623418512
Trained batch 58 in epoch 2, gen_loss = 0.8272646786802906, disc_loss = 0.09062639522855565
Trained batch 59 in epoch 2, gen_loss = 0.824703723192215, disc_loss = 0.0909706683208545
Trained batch 60 in epoch 2, gen_loss = 0.8270526782411044, disc_loss = 0.09342348245812244
Trained batch 61 in epoch 2, gen_loss = 0.8241747329311986, disc_loss = 0.09322653831012788
Trained batch 62 in epoch 2, gen_loss = 0.821375638719589, disc_loss = 0.09380034061651381
Trained batch 63 in epoch 2, gen_loss = 0.822077483870089, disc_loss = 0.09412873804103583
Trained batch 64 in epoch 2, gen_loss = 0.8202544569969177, disc_loss = 0.09396769255399703
Trained batch 65 in epoch 2, gen_loss = 0.8195355525522521, disc_loss = 0.09376323144092705
Trained batch 66 in epoch 2, gen_loss = 0.8186642652127281, disc_loss = 0.0933985881396194
Trained batch 67 in epoch 2, gen_loss = 0.817647479912814, disc_loss = 0.09302599202184116
Trained batch 68 in epoch 2, gen_loss = 0.8175870819368224, disc_loss = 0.0921477140939754
Trained batch 69 in epoch 2, gen_loss = 0.8158163411276681, disc_loss = 0.09224333401237216
Trained batch 70 in epoch 2, gen_loss = 0.8183991841866937, disc_loss = 0.09218984265142763
Trained batch 71 in epoch 2, gen_loss = 0.8179765293995539, disc_loss = 0.09159742947667837
Trained batch 72 in epoch 2, gen_loss = 0.8179645815940753, disc_loss = 0.09094274227749811
Trained batch 73 in epoch 2, gen_loss = 0.819695318067396, disc_loss = 0.09029876773019095
Trained batch 74 in epoch 2, gen_loss = 0.8216256364186605, disc_loss = 0.08929344793160757
Trained batch 75 in epoch 2, gen_loss = 0.8236482817875711, disc_loss = 0.08830334214297564
Trained batch 76 in epoch 2, gen_loss = 0.8235907144360728, disc_loss = 0.08758126908018217
Trained batch 77 in epoch 2, gen_loss = 0.8242581891707885, disc_loss = 0.08673155794923122
Trained batch 78 in epoch 2, gen_loss = 0.828973343855218, disc_loss = 0.08735974104721335
Trained batch 79 in epoch 2, gen_loss = 0.8289285905659198, disc_loss = 0.08681620331481099
Trained batch 80 in epoch 2, gen_loss = 0.8264284891846739, disc_loss = 0.08738825433416131
Trained batch 81 in epoch 2, gen_loss = 0.8300211727619171, disc_loss = 0.08918948516976542
Trained batch 82 in epoch 2, gen_loss = 0.8269552681819502, disc_loss = 0.08970290790480304
Trained batch 83 in epoch 2, gen_loss = 0.8268336213770366, disc_loss = 0.08979068794065997
Trained batch 84 in epoch 2, gen_loss = 0.826356828212738, disc_loss = 0.09107117083142785
Trained batch 85 in epoch 2, gen_loss = 0.8269543529942979, disc_loss = 0.09194831662746362
Trained batch 86 in epoch 2, gen_loss = 0.8255823556034044, disc_loss = 0.09222782985574898
Trained batch 87 in epoch 2, gen_loss = 0.8237211230126295, disc_loss = 0.0927803898230195
Trained batch 88 in epoch 2, gen_loss = 0.8255919345309225, disc_loss = 0.09327921195981208
Trained batch 89 in epoch 2, gen_loss = 0.8237954742378659, disc_loss = 0.09303133115172386
Trained batch 90 in epoch 2, gen_loss = 0.8223656992335896, disc_loss = 0.09294424238768252
Trained batch 91 in epoch 2, gen_loss = 0.8247393343759619, disc_loss = 0.09349016189251257
Trained batch 92 in epoch 2, gen_loss = 0.8242568803089921, disc_loss = 0.09301647776237099
Trained batch 93 in epoch 2, gen_loss = 0.8243001699447632, disc_loss = 0.09241005215556064
Trained batch 94 in epoch 2, gen_loss = 0.822159535006473, disc_loss = 0.09227958752920754
Trained batch 95 in epoch 2, gen_loss = 0.8235420708854994, disc_loss = 0.09271206373038392
Trained batch 96 in epoch 2, gen_loss = 0.8212663082732368, disc_loss = 0.09278424038100488
Trained batch 97 in epoch 2, gen_loss = 0.8204976478401496, disc_loss = 0.09265392669001404
Trained batch 98 in epoch 2, gen_loss = 0.8223781405073224, disc_loss = 0.09295840154994618
Trained batch 99 in epoch 2, gen_loss = 0.8202496206760407, disc_loss = 0.09325840801000596
Trained batch 100 in epoch 2, gen_loss = 0.8197331050835034, disc_loss = 0.09298779321188974
Trained batch 101 in epoch 2, gen_loss = 0.8193225416482663, disc_loss = 0.09282180710750468
Trained batch 102 in epoch 2, gen_loss = 0.8188154818942246, disc_loss = 0.09269717523773897
Trained batch 103 in epoch 2, gen_loss = 0.8169274393182534, disc_loss = 0.09267903685283202
Trained batch 104 in epoch 2, gen_loss = 0.8175466208230882, disc_loss = 0.09280424259957813
Trained batch 105 in epoch 2, gen_loss = 0.8165770161826655, disc_loss = 0.09235170321925631
Trained batch 106 in epoch 2, gen_loss = 0.8156004397668571, disc_loss = 0.09229364260056308
Trained batch 107 in epoch 2, gen_loss = 0.8154561232637476, disc_loss = 0.09249992820399779
Trained batch 108 in epoch 2, gen_loss = 0.8140373645572487, disc_loss = 0.09227880329713908
Trained batch 109 in epoch 2, gen_loss = 0.8159162792292508, disc_loss = 0.09173246615312317
Trained batch 110 in epoch 2, gen_loss = 0.8149369401974721, disc_loss = 0.09131233578732421
Trained batch 111 in epoch 2, gen_loss = 0.8156465680471489, disc_loss = 0.091025534252237
Trained batch 112 in epoch 2, gen_loss = 0.8153794687406152, disc_loss = 0.09055585737249493
Trained batch 113 in epoch 2, gen_loss = 0.8156148320750186, disc_loss = 0.0903393826855902
Trained batch 114 in epoch 2, gen_loss = 0.8155721135761427, disc_loss = 0.09042400380839473
Trained batch 115 in epoch 2, gen_loss = 0.8138522218013632, disc_loss = 0.09150297528710859
Trained batch 116 in epoch 2, gen_loss = 0.8147689012380747, disc_loss = 0.09151734558180866
Trained batch 117 in epoch 2, gen_loss = 0.8160023386195555, disc_loss = 0.09114895249574871
Trained batch 118 in epoch 2, gen_loss = 0.815585732460022, disc_loss = 0.09089707288922382
Trained batch 119 in epoch 2, gen_loss = 0.815174114704132, disc_loss = 0.09049259011323253
Trained batch 120 in epoch 2, gen_loss = 0.8170272476416974, disc_loss = 0.09017498437161288
Trained batch 121 in epoch 2, gen_loss = 0.8179675575162544, disc_loss = 0.08960509031522469
Trained batch 122 in epoch 2, gen_loss = 0.8203741670624027, disc_loss = 0.08907243560969345
Trained batch 123 in epoch 2, gen_loss = 0.818771154649796, disc_loss = 0.08922405252533575
Trained batch 124 in epoch 2, gen_loss = 0.8183098764419555, disc_loss = 0.08894163367152214
Trained batch 125 in epoch 2, gen_loss = 0.8204452007535904, disc_loss = 0.08901262652897646
Trained batch 126 in epoch 2, gen_loss = 0.8191882761444632, disc_loss = 0.08953544922818349
Trained batch 127 in epoch 2, gen_loss = 0.8196099773049355, disc_loss = 0.08947932251612656
Trained batch 128 in epoch 2, gen_loss = 0.8194020298100257, disc_loss = 0.08915240502403687
Trained batch 129 in epoch 2, gen_loss = 0.8208599837926718, disc_loss = 0.08877917619851919
Trained batch 130 in epoch 2, gen_loss = 0.8199685743746866, disc_loss = 0.08884774728585745
Trained batch 131 in epoch 2, gen_loss = 0.8211450545173703, disc_loss = 0.08859654493404157
Trained batch 132 in epoch 2, gen_loss = 0.8207064069303355, disc_loss = 0.08825658284183732
Trained batch 133 in epoch 2, gen_loss = 0.8212898738348662, disc_loss = 0.08780678435326067
Trained batch 134 in epoch 2, gen_loss = 0.8212467281906694, disc_loss = 0.08751087438453127
Trained batch 135 in epoch 2, gen_loss = 0.8224760039764292, disc_loss = 0.08700482751352384
Trained batch 136 in epoch 2, gen_loss = 0.8216052899395463, disc_loss = 0.0867903975865049
Trained batch 137 in epoch 2, gen_loss = 0.8226307984711467, disc_loss = 0.08682284950940074
Trained batch 138 in epoch 2, gen_loss = 0.8211248276902617, disc_loss = 0.08686453842377062
Trained batch 139 in epoch 2, gen_loss = 0.8209149973733084, disc_loss = 0.08654299510110702
Trained batch 140 in epoch 2, gen_loss = 0.8215195684568256, disc_loss = 0.0861707009137311
Trained batch 141 in epoch 2, gen_loss = 0.8210376131702477, disc_loss = 0.08580827727441637
Trained batch 142 in epoch 2, gen_loss = 0.8229742967165433, disc_loss = 0.08535721281973216
Trained batch 143 in epoch 2, gen_loss = 0.8251390117737982, disc_loss = 0.0850046540532882
Trained batch 144 in epoch 2, gen_loss = 0.826020336973256, disc_loss = 0.08469548858702183
Trained batch 145 in epoch 2, gen_loss = 0.8252637410817081, disc_loss = 0.08446060392801484
Trained batch 146 in epoch 2, gen_loss = 0.8257211661663185, disc_loss = 0.08402444908813554
Trained batch 147 in epoch 2, gen_loss = 0.8260485062728057, disc_loss = 0.08367090254417948
Trained batch 148 in epoch 2, gen_loss = 0.8267352389009207, disc_loss = 0.0834563658041442
Trained batch 149 in epoch 2, gen_loss = 0.8271157709757487, disc_loss = 0.08300969167302052
Trained batch 150 in epoch 2, gen_loss = 0.8268869412655862, disc_loss = 0.08276992438003322
Trained batch 151 in epoch 2, gen_loss = 0.8274189700421534, disc_loss = 0.08282262159168328
Trained batch 152 in epoch 2, gen_loss = 0.8270298608767441, disc_loss = 0.08274582338829835
Trained batch 153 in epoch 2, gen_loss = 0.8270749890959108, disc_loss = 0.08296787456984257
Trained batch 154 in epoch 2, gen_loss = 0.8253543080822114, disc_loss = 0.08391193717477784
Trained batch 155 in epoch 2, gen_loss = 0.8275342320020382, disc_loss = 0.0843865738536876
Trained batch 156 in epoch 2, gen_loss = 0.8270744601632379, disc_loss = 0.0842626066225919
Trained batch 157 in epoch 2, gen_loss = 0.8276558103440683, disc_loss = 0.0841110593321014
Trained batch 158 in epoch 2, gen_loss = 0.8267163435618082, disc_loss = 0.0842035590266844
Trained batch 159 in epoch 2, gen_loss = 0.8270914617925882, disc_loss = 0.0841957761789672
Trained batch 160 in epoch 2, gen_loss = 0.8268858190649044, disc_loss = 0.08411394382439415
Trained batch 161 in epoch 2, gen_loss = 0.8263891276753978, disc_loss = 0.08391127175433033
Trained batch 162 in epoch 2, gen_loss = 0.8256120809748129, disc_loss = 0.08391009761374786
Trained batch 163 in epoch 2, gen_loss = 0.826752013913015, disc_loss = 0.08446571490977232
Trained batch 164 in epoch 2, gen_loss = 0.8256203033707359, disc_loss = 0.0846759254846609
Trained batch 165 in epoch 2, gen_loss = 0.8252869165805449, disc_loss = 0.08434020318315331
Trained batch 166 in epoch 2, gen_loss = 0.824506542282904, disc_loss = 0.08438459291920333
Trained batch 167 in epoch 2, gen_loss = 0.8252672354380289, disc_loss = 0.0843899070307435
Trained batch 168 in epoch 2, gen_loss = 0.8245944260845522, disc_loss = 0.08429992444725079
Trained batch 169 in epoch 2, gen_loss = 0.8238010143532473, disc_loss = 0.08432923116009025
Trained batch 170 in epoch 2, gen_loss = 0.8249949262156124, disc_loss = 0.08435766781239133
Trained batch 171 in epoch 2, gen_loss = 0.823627763362818, disc_loss = 0.0847423606725453
Trained batch 172 in epoch 2, gen_loss = 0.8245847352667351, disc_loss = 0.08478212730173086
Trained batch 173 in epoch 2, gen_loss = 0.8239619755881956, disc_loss = 0.08473683228908942
Trained batch 174 in epoch 2, gen_loss = 0.8240035431725639, disc_loss = 0.0845652156748942
Trained batch 175 in epoch 2, gen_loss = 0.8240058869123459, disc_loss = 0.08422025103672323
Trained batch 176 in epoch 2, gen_loss = 0.8245210997802389, disc_loss = 0.084096560128412
Trained batch 177 in epoch 2, gen_loss = 0.8242763595634632, disc_loss = 0.08402409698563011
Trained batch 178 in epoch 2, gen_loss = 0.8251763828639878, disc_loss = 0.08422904200435684
Trained batch 179 in epoch 2, gen_loss = 0.8247205734252929, disc_loss = 0.08416036534019643
Trained batch 180 in epoch 2, gen_loss = 0.8246862137515242, disc_loss = 0.08429702615252187
Trained batch 181 in epoch 2, gen_loss = 0.8245940309959453, disc_loss = 0.08428108504881243
Trained batch 182 in epoch 2, gen_loss = 0.8233169431243438, disc_loss = 0.08430870383204332
Trained batch 183 in epoch 2, gen_loss = 0.8244310121821321, disc_loss = 0.0841514602323751
Trained batch 184 in epoch 2, gen_loss = 0.8232273968490395, disc_loss = 0.08415643811427258
Trained batch 185 in epoch 2, gen_loss = 0.8239402120472282, disc_loss = 0.08419367455707122
Trained batch 186 in epoch 2, gen_loss = 0.8233915379340636, disc_loss = 0.0840321896687389
Trained batch 187 in epoch 2, gen_loss = 0.8232025897249262, disc_loss = 0.08374271740978385
Trained batch 188 in epoch 2, gen_loss = 0.8231985121176987, disc_loss = 0.0835800342478607
Trained batch 189 in epoch 2, gen_loss = 0.8238896583255969, disc_loss = 0.08328371803815428
Trained batch 190 in epoch 2, gen_loss = 0.8229163697876856, disc_loss = 0.08324289816329304
Trained batch 191 in epoch 2, gen_loss = 0.8240948002785444, disc_loss = 0.08294688135113877
Trained batch 192 in epoch 2, gen_loss = 0.8240183425073179, disc_loss = 0.08270852251335438
Trained batch 193 in epoch 2, gen_loss = 0.8234804198913968, disc_loss = 0.08251199029270828
Trained batch 194 in epoch 2, gen_loss = 0.8237947613765032, disc_loss = 0.08247451880612434
Trained batch 195 in epoch 2, gen_loss = 0.8228441035869171, disc_loss = 0.08250271151678598
Trained batch 196 in epoch 2, gen_loss = 0.8247143384163755, disc_loss = 0.08269457998425525
Trained batch 197 in epoch 2, gen_loss = 0.8236388097507785, disc_loss = 0.08311289965617236
Trained batch 198 in epoch 2, gen_loss = 0.8230461627993751, disc_loss = 0.08309519477188587
Trained batch 199 in epoch 2, gen_loss = 0.8245271977782249, disc_loss = 0.08335250756703318
Trained batch 200 in epoch 2, gen_loss = 0.8245412143901806, disc_loss = 0.08324243509168945
Trained batch 201 in epoch 2, gen_loss = 0.8237858653658687, disc_loss = 0.08331471499940842
Trained batch 202 in epoch 2, gen_loss = 0.8240331220509384, disc_loss = 0.08326829286301371
Trained batch 203 in epoch 2, gen_loss = 0.8236494739266003, disc_loss = 0.08310106324543264
Trained batch 204 in epoch 2, gen_loss = 0.8233774083416636, disc_loss = 0.08307983607235478
Trained batch 205 in epoch 2, gen_loss = 0.8236314000435245, disc_loss = 0.08285406417240507
Trained batch 206 in epoch 2, gen_loss = 0.8237439019668505, disc_loss = 0.08254153348937415
Trained batch 207 in epoch 2, gen_loss = 0.8236121962276789, disc_loss = 0.08223861871430507
Trained batch 208 in epoch 2, gen_loss = 0.8243389024118487, disc_loss = 0.08220990547580583
Trained batch 209 in epoch 2, gen_loss = 0.8236261276971726, disc_loss = 0.08221400415613538
Trained batch 210 in epoch 2, gen_loss = 0.8235194440136588, disc_loss = 0.0822095859672221
Trained batch 211 in epoch 2, gen_loss = 0.8243055200239398, disc_loss = 0.08254601469017425
Trained batch 212 in epoch 2, gen_loss = 0.8233475867011737, disc_loss = 0.08284664119073483
Trained batch 213 in epoch 2, gen_loss = 0.8234335086613058, disc_loss = 0.08288162737806266
Trained batch 214 in epoch 2, gen_loss = 0.8235783039137374, disc_loss = 0.08294114498204963
Trained batch 215 in epoch 2, gen_loss = 0.8224634481249032, disc_loss = 0.08325984204808871
Trained batch 216 in epoch 2, gen_loss = 0.8221261663370968, disc_loss = 0.08306497376635327
Trained batch 217 in epoch 2, gen_loss = 0.8231526785487429, disc_loss = 0.08303752900400294
Trained batch 218 in epoch 2, gen_loss = 0.8230462223971815, disc_loss = 0.08279645266053884
Trained batch 219 in epoch 2, gen_loss = 0.823488954522393, disc_loss = 0.08249219903214411
Trained batch 220 in epoch 2, gen_loss = 0.8232978701052083, disc_loss = 0.0822484813698007
Trained batch 221 in epoch 2, gen_loss = 0.824480131402746, disc_loss = 0.08235051961162605
Trained batch 222 in epoch 2, gen_loss = 0.8233166994535335, disc_loss = 0.0830773473487574
Trained batch 223 in epoch 2, gen_loss = 0.8231345343270472, disc_loss = 0.08292626775801182
Trained batch 224 in epoch 2, gen_loss = 0.8238185180558099, disc_loss = 0.08318688842985365
Trained batch 225 in epoch 2, gen_loss = 0.8230938043742053, disc_loss = 0.08320928529827995
Trained batch 226 in epoch 2, gen_loss = 0.8226297366461565, disc_loss = 0.08315409280129991
Trained batch 227 in epoch 2, gen_loss = 0.8220574531638831, disc_loss = 0.08311496230593898
Trained batch 228 in epoch 2, gen_loss = 0.8222572215259335, disc_loss = 0.08309898893125192
Trained batch 229 in epoch 2, gen_loss = 0.8225558410520138, disc_loss = 0.08298729718055414
Trained batch 230 in epoch 2, gen_loss = 0.8220445451798377, disc_loss = 0.08292984912470305
Trained batch 231 in epoch 2, gen_loss = 0.8223845858512253, disc_loss = 0.08262732111977349
Trained batch 232 in epoch 2, gen_loss = 0.8231367867903648, disc_loss = 0.08243633382214241
Trained batch 233 in epoch 2, gen_loss = 0.8231295543348688, disc_loss = 0.08218595871908797
Trained batch 234 in epoch 2, gen_loss = 0.8230326797099824, disc_loss = 0.08194316696137824
Trained batch 235 in epoch 2, gen_loss = 0.8240461533857604, disc_loss = 0.08228815278290945
Trained batch 236 in epoch 2, gen_loss = 0.8234670069147263, disc_loss = 0.08228029603853759
Trained batch 237 in epoch 2, gen_loss = 0.8231484702154368, disc_loss = 0.08212632057452653
Trained batch 238 in epoch 2, gen_loss = 0.8230509658238878, disc_loss = 0.08245159271777175
Trained batch 239 in epoch 2, gen_loss = 0.8224793794254462, disc_loss = 0.08244431848482539
Trained batch 240 in epoch 2, gen_loss = 0.8225246791523028, disc_loss = 0.08236454032299677
Trained batch 241 in epoch 2, gen_loss = 0.8217433055570303, disc_loss = 0.08245521596794532
Trained batch 242 in epoch 2, gen_loss = 0.8212232724629311, disc_loss = 0.08239394387253272
Trained batch 243 in epoch 2, gen_loss = 0.8227657409476452, disc_loss = 0.08292742938444507
Trained batch 244 in epoch 2, gen_loss = 0.8220661355524647, disc_loss = 0.08307677000304874
Trained batch 245 in epoch 2, gen_loss = 0.8213118011873912, disc_loss = 0.0831172227692919
Trained batch 246 in epoch 2, gen_loss = 0.8216578123057902, disc_loss = 0.08313337675020521
Trained batch 247 in epoch 2, gen_loss = 0.8220538482550652, disc_loss = 0.0828490030365966
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.6857235431671143, disc_loss = 0.09509501606225967
Trained batch 1 in epoch 3, gen_loss = 0.642976850271225, disc_loss = 0.09826815128326416
Trained batch 2 in epoch 3, gen_loss = 0.7532853484153748, disc_loss = 0.09599096576372783
Trained batch 3 in epoch 3, gen_loss = 0.7590532600879669, disc_loss = 0.08225059043616056
Trained batch 4 in epoch 3, gen_loss = 0.7659605145454407, disc_loss = 0.07054205015301704
Trained batch 5 in epoch 3, gen_loss = 0.7740725179513296, disc_loss = 0.06379260619481404
Trained batch 6 in epoch 3, gen_loss = 0.8190904259681702, disc_loss = 0.06452609066452299
Trained batch 7 in epoch 3, gen_loss = 0.7831254675984383, disc_loss = 0.07370742876082659
Trained batch 8 in epoch 3, gen_loss = 0.7993934088283114, disc_loss = 0.06890290478865306
Trained batch 9 in epoch 3, gen_loss = 0.8014941036701202, disc_loss = 0.07009773999452591
Trained batch 10 in epoch 3, gen_loss = 0.8206927071918141, disc_loss = 0.06685603613203223
Trained batch 11 in epoch 3, gen_loss = 0.8062564382950465, disc_loss = 0.06801134223739307
Trained batch 12 in epoch 3, gen_loss = 0.812017913048084, disc_loss = 0.064937179764876
Trained batch 13 in epoch 3, gen_loss = 0.8030393506799426, disc_loss = 0.06715334712394647
Trained batch 14 in epoch 3, gen_loss = 0.8072553714116414, disc_loss = 0.06397167692581812
Trained batch 15 in epoch 3, gen_loss = 0.8291873708367348, disc_loss = 0.06293204496614635
Trained batch 16 in epoch 3, gen_loss = 0.8221066208446727, disc_loss = 0.06201155812424772
Trained batch 17 in epoch 3, gen_loss = 0.8155246244536506, disc_loss = 0.06085639840198888
Trained batch 18 in epoch 3, gen_loss = 0.8281041885677137, disc_loss = 0.05994440968099393
Trained batch 19 in epoch 3, gen_loss = 0.8312382698059082, disc_loss = 0.05796691216528416
Trained batch 20 in epoch 3, gen_loss = 0.8291132478486924, disc_loss = 0.05774955699841181
Trained batch 21 in epoch 3, gen_loss = 0.8420799510045485, disc_loss = 0.05649723544378172
Trained batch 22 in epoch 3, gen_loss = 0.855165333851524, disc_loss = 0.05790238171491934
Trained batch 23 in epoch 3, gen_loss = 0.8457178448637327, disc_loss = 0.06069650431163609
Trained batch 24 in epoch 3, gen_loss = 0.8497207856178284, disc_loss = 0.05918032594025135
Trained batch 25 in epoch 3, gen_loss = 0.858113543345378, disc_loss = 0.06050836559958183
Trained batch 26 in epoch 3, gen_loss = 0.8641360313804062, disc_loss = 0.0590094699765797
Trained batch 27 in epoch 3, gen_loss = 0.855235925742558, disc_loss = 0.06183916829260332
Trained batch 28 in epoch 3, gen_loss = 0.8604273220588421, disc_loss = 0.06045173455415101
Trained batch 29 in epoch 3, gen_loss = 0.8652921875317892, disc_loss = 0.05945859805991252
Trained batch 30 in epoch 3, gen_loss = 0.8625576246169305, disc_loss = 0.05825523695638103
Trained batch 31 in epoch 3, gen_loss = 0.8640664611011744, disc_loss = 0.057032397482544184
Trained batch 32 in epoch 3, gen_loss = 0.8645364280902978, disc_loss = 0.056106998387611275
Trained batch 33 in epoch 3, gen_loss = 0.8660551362177905, disc_loss = 0.05479708207113778
Trained batch 34 in epoch 3, gen_loss = 0.8638581514358521, disc_loss = 0.05432032306811639
Trained batch 35 in epoch 3, gen_loss = 0.8652017182774014, disc_loss = 0.05348930313872794
Trained batch 36 in epoch 3, gen_loss = 0.8693232439659737, disc_loss = 0.05355520770457145
Trained batch 37 in epoch 3, gen_loss = 0.8631126504195364, disc_loss = 0.05572991173616365
Trained batch 38 in epoch 3, gen_loss = 0.8623666518773788, disc_loss = 0.055788032161310695
Trained batch 39 in epoch 3, gen_loss = 0.864226333796978, disc_loss = 0.05555014603305608
Trained batch 40 in epoch 3, gen_loss = 0.8596512413606411, disc_loss = 0.05539229114698928
Trained batch 41 in epoch 3, gen_loss = 0.8593076737154097, disc_loss = 0.05456533622262733
Trained batch 42 in epoch 3, gen_loss = 0.8692375047262325, disc_loss = 0.055492358520453755
Trained batch 43 in epoch 3, gen_loss = 0.8731220188465986, disc_loss = 0.05505304684100503
Trained batch 44 in epoch 3, gen_loss = 0.8734240704112582, disc_loss = 0.05524577434278197
Trained batch 45 in epoch 3, gen_loss = 0.8733989829602449, disc_loss = 0.0545960049468862
Trained batch 46 in epoch 3, gen_loss = 0.8740068648723845, disc_loss = 0.05419143687616637
Trained batch 47 in epoch 3, gen_loss = 0.8719704858958721, disc_loss = 0.05388231569668278
Trained batch 48 in epoch 3, gen_loss = 0.8737866805524243, disc_loss = 0.05369567226770581
Trained batch 49 in epoch 3, gen_loss = 0.8747714400291443, disc_loss = 0.05292747320607304
Trained batch 50 in epoch 3, gen_loss = 0.8786049333273196, disc_loss = 0.052291812685628734
Trained batch 51 in epoch 3, gen_loss = 0.8835035402041215, disc_loss = 0.05185373842071455
Trained batch 52 in epoch 3, gen_loss = 0.8841153248301092, disc_loss = 0.051356968083331046
Trained batch 53 in epoch 3, gen_loss = 0.8848365434893856, disc_loss = 0.05081713832569895
Trained batch 54 in epoch 3, gen_loss = 0.8864048871127042, disc_loss = 0.05002469320527532
Trained batch 55 in epoch 3, gen_loss = 0.8888609664780753, disc_loss = 0.04940757601122771
Trained batch 56 in epoch 3, gen_loss = 0.8896146583975407, disc_loss = 0.04887931604395833
Trained batch 57 in epoch 3, gen_loss = 0.886410646397492, disc_loss = 0.048983296186759555
Trained batch 58 in epoch 3, gen_loss = 0.892851990158275, disc_loss = 0.04947035305075726
Trained batch 59 in epoch 3, gen_loss = 0.8916929523150127, disc_loss = 0.049019541063656406
Trained batch 60 in epoch 3, gen_loss = 0.8905715053198767, disc_loss = 0.04850273832800935
Trained batch 61 in epoch 3, gen_loss = 0.8913275003433228, disc_loss = 0.04786411129058369
Trained batch 62 in epoch 3, gen_loss = 0.8930809138313173, disc_loss = 0.047266971674703416
Trained batch 63 in epoch 3, gen_loss = 0.8944885432720184, disc_loss = 0.04669643079978414
Trained batch 64 in epoch 3, gen_loss = 0.8988712567549485, disc_loss = 0.04644048188168269
Trained batch 65 in epoch 3, gen_loss = 0.9006805997906309, disc_loss = 0.04598829119155804
Trained batch 66 in epoch 3, gen_loss = 0.9008706968222091, disc_loss = 0.0454564699347117
Trained batch 67 in epoch 3, gen_loss = 0.9005896598100662, disc_loss = 0.044941826025024056
Trained batch 68 in epoch 3, gen_loss = 0.9002747060596079, disc_loss = 0.04449770986979854
Trained batch 69 in epoch 3, gen_loss = 0.8998237677982875, disc_loss = 0.04397117063802268
Trained batch 70 in epoch 3, gen_loss = 0.8993226491229634, disc_loss = 0.043508709874004126
Trained batch 71 in epoch 3, gen_loss = 0.8995943615833918, disc_loss = 0.043040201747013875
Trained batch 72 in epoch 3, gen_loss = 0.9008580103312454, disc_loss = 0.04278108623669776
Trained batch 73 in epoch 3, gen_loss = 0.9023376735481056, disc_loss = 0.04237822675448213
Trained batch 74 in epoch 3, gen_loss = 0.9026170587539672, disc_loss = 0.041898093912750484
Trained batch 75 in epoch 3, gen_loss = 0.9016321426943729, disc_loss = 0.0418581342949581
Trained batch 76 in epoch 3, gen_loss = 0.9005709576916385, disc_loss = 0.04161793842016683
Trained batch 77 in epoch 3, gen_loss = 0.9000988220557188, disc_loss = 0.0414102603502285
Trained batch 78 in epoch 3, gen_loss = 0.9008575059190581, disc_loss = 0.04107723154622731
Trained batch 79 in epoch 3, gen_loss = 0.8988634213805199, disc_loss = 0.04088436093297787
Trained batch 80 in epoch 3, gen_loss = 0.8975401734128411, disc_loss = 0.04065780700931763
Trained batch 81 in epoch 3, gen_loss = 0.8994955187890588, disc_loss = 0.04079812733888081
Trained batch 82 in epoch 3, gen_loss = 0.8993200350956745, disc_loss = 0.040561527176479616
Trained batch 83 in epoch 3, gen_loss = 0.8988195331323714, disc_loss = 0.04023947375493923
Trained batch 84 in epoch 3, gen_loss = 0.8983083535643185, disc_loss = 0.03991892622126376
Trained batch 85 in epoch 3, gen_loss = 0.8961952106897221, disc_loss = 0.04006265350184295
Trained batch 86 in epoch 3, gen_loss = 0.8999529131527605, disc_loss = 0.04076991319634962
Trained batch 87 in epoch 3, gen_loss = 0.8992052606560967, disc_loss = 0.040510646570262245
Trained batch 88 in epoch 3, gen_loss = 0.8970645733093947, disc_loss = 0.04067897637050306
Trained batch 89 in epoch 3, gen_loss = 0.8966143449147542, disc_loss = 0.04040624136622581
Trained batch 90 in epoch 3, gen_loss = 0.8960797184116238, disc_loss = 0.04011812232496156
Trained batch 91 in epoch 3, gen_loss = 0.895791452863942, disc_loss = 0.03987820018791472
Trained batch 92 in epoch 3, gen_loss = 0.8965149662827933, disc_loss = 0.03953383864474393
Trained batch 93 in epoch 3, gen_loss = 0.8941931274343045, disc_loss = 0.03976711267704501
Trained batch 94 in epoch 3, gen_loss = 0.8949035638257077, disc_loss = 0.03955816341760127
Trained batch 95 in epoch 3, gen_loss = 0.8975591380149126, disc_loss = 0.039930073209689
Trained batch 96 in epoch 3, gen_loss = 0.8955416513472488, disc_loss = 0.04025781981781432
Trained batch 97 in epoch 3, gen_loss = 0.8928003232089841, disc_loss = 0.04094179512039587
Trained batch 98 in epoch 3, gen_loss = 0.8932428582750186, disc_loss = 0.041260671185687034
Trained batch 99 in epoch 3, gen_loss = 0.8927900904417038, disc_loss = 0.04119232145603746
Trained batch 100 in epoch 3, gen_loss = 0.8919817333174224, disc_loss = 0.041318097599035146
Trained batch 101 in epoch 3, gen_loss = 0.8910986968115264, disc_loss = 0.04162184511968756
Trained batch 102 in epoch 3, gen_loss = 0.8900681710937648, disc_loss = 0.04170943526731967
Trained batch 103 in epoch 3, gen_loss = 0.8898993570071, disc_loss = 0.04157778156401876
Trained batch 104 in epoch 3, gen_loss = 0.8909221308571952, disc_loss = 0.04180778833993134
Trained batch 105 in epoch 3, gen_loss = 0.8886925628725088, disc_loss = 0.04233629496785689
Trained batch 106 in epoch 3, gen_loss = 0.8897364568487506, disc_loss = 0.04225881903858803
Trained batch 107 in epoch 3, gen_loss = 0.8884125804459607, disc_loss = 0.04210894797600944
Trained batch 108 in epoch 3, gen_loss = 0.8880732863321217, disc_loss = 0.041967328701920194
Trained batch 109 in epoch 3, gen_loss = 0.8882638747041876, disc_loss = 0.04173938435163688
Trained batch 110 in epoch 3, gen_loss = 0.8869521295702135, disc_loss = 0.04170648149122392
Trained batch 111 in epoch 3, gen_loss = 0.8876350655087403, disc_loss = 0.0415131861435449
Trained batch 112 in epoch 3, gen_loss = 0.8865171254208658, disc_loss = 0.04151581583412743
Trained batch 113 in epoch 3, gen_loss = 0.8859244893517411, disc_loss = 0.041309563144878075
Trained batch 114 in epoch 3, gen_loss = 0.8876368123552073, disc_loss = 0.04107446786745087
Trained batch 115 in epoch 3, gen_loss = 0.888243374639544, disc_loss = 0.04077480477682347
Trained batch 116 in epoch 3, gen_loss = 0.8878246632396666, disc_loss = 0.040641089292386405
Trained batch 117 in epoch 3, gen_loss = 0.8875277976868516, disc_loss = 0.040386794383590253
Trained batch 118 in epoch 3, gen_loss = 0.8879687951392486, disc_loss = 0.0401209865915863
Trained batch 119 in epoch 3, gen_loss = 0.8867678289612134, disc_loss = 0.04030887510549898
Trained batch 120 in epoch 3, gen_loss = 0.8867853224770097, disc_loss = 0.040237455771204605
Trained batch 121 in epoch 3, gen_loss = 0.8871452002251734, disc_loss = 0.040051428337779936
Trained batch 122 in epoch 3, gen_loss = 0.8868395453546105, disc_loss = 0.039907182631181266
Trained batch 123 in epoch 3, gen_loss = 0.8870189338922501, disc_loss = 0.03969678428820184
Trained batch 124 in epoch 3, gen_loss = 0.887545859336853, disc_loss = 0.03946838525310159
Trained batch 125 in epoch 3, gen_loss = 0.8863806681973594, disc_loss = 0.03953304097780751
Trained batch 126 in epoch 3, gen_loss = 0.8862961774735939, disc_loss = 0.03947035660673901
Trained batch 127 in epoch 3, gen_loss = 0.886456391774118, disc_loss = 0.03924625827130512
Trained batch 128 in epoch 3, gen_loss = 0.8853698650071787, disc_loss = 0.03925298914212243
Trained batch 129 in epoch 3, gen_loss = 0.8863766968250275, disc_loss = 0.039105284160289626
Trained batch 130 in epoch 3, gen_loss = 0.8866084463723743, disc_loss = 0.039439313003494764
Trained batch 131 in epoch 3, gen_loss = 0.8848561278798364, disc_loss = 0.03968989426114907
Trained batch 132 in epoch 3, gen_loss = 0.8837905073524418, disc_loss = 0.03992719450069213
Trained batch 133 in epoch 3, gen_loss = 0.8841301042642167, disc_loss = 0.039767594511078586
Trained batch 134 in epoch 3, gen_loss = 0.8821689031742237, disc_loss = 0.03985429326486256
Trained batch 135 in epoch 3, gen_loss = 0.8827970273354474, disc_loss = 0.04017020797918496
Trained batch 136 in epoch 3, gen_loss = 0.8818422329686854, disc_loss = 0.04069764142937578
Trained batch 137 in epoch 3, gen_loss = 0.8787684332633364, disc_loss = 0.04228283316774321
Trained batch 138 in epoch 3, gen_loss = 0.8804988410833071, disc_loss = 0.04269543357474877
Trained batch 139 in epoch 3, gen_loss = 0.8790768074137824, disc_loss = 0.0428833332744294
Trained batch 140 in epoch 3, gen_loss = 0.8778708902656609, disc_loss = 0.04310098013358442
Trained batch 141 in epoch 3, gen_loss = 0.8778698146343231, disc_loss = 0.04377547638740023
Trained batch 142 in epoch 3, gen_loss = 0.8773449284213406, disc_loss = 0.0436397851900673
Trained batch 143 in epoch 3, gen_loss = 0.8767455894913938, disc_loss = 0.04374731813570381
Trained batch 144 in epoch 3, gen_loss = 0.8779016753722881, disc_loss = 0.04441735616339178
Trained batch 145 in epoch 3, gen_loss = 0.8760815017843899, disc_loss = 0.04496253991486785
Trained batch 146 in epoch 3, gen_loss = 0.8755617530978456, disc_loss = 0.04506310613090996
Trained batch 147 in epoch 3, gen_loss = 0.876086105366011, disc_loss = 0.04568115164009804
Trained batch 148 in epoch 3, gen_loss = 0.8760860922352579, disc_loss = 0.04565340625872248
Trained batch 149 in epoch 3, gen_loss = 0.87545108238856, disc_loss = 0.04559729881895085
Trained batch 150 in epoch 3, gen_loss = 0.8754435848716079, disc_loss = 0.045446391880438225
Trained batch 151 in epoch 3, gen_loss = 0.8743780482756464, disc_loss = 0.04552465395720087
Trained batch 152 in epoch 3, gen_loss = 0.8753009933272219, disc_loss = 0.04569180867652975
Trained batch 153 in epoch 3, gen_loss = 0.8740679788125025, disc_loss = 0.04570322210731154
Trained batch 154 in epoch 3, gen_loss = 0.8739071830626457, disc_loss = 0.045668374822144545
Trained batch 155 in epoch 3, gen_loss = 0.873309633288628, disc_loss = 0.04550271757388822
Trained batch 156 in epoch 3, gen_loss = 0.8727990195250056, disc_loss = 0.04538424903004887
Trained batch 157 in epoch 3, gen_loss = 0.87332377214975, disc_loss = 0.04557977523949422
Trained batch 158 in epoch 3, gen_loss = 0.8725029601241058, disc_loss = 0.04549783141697821
Trained batch 159 in epoch 3, gen_loss = 0.871837479993701, disc_loss = 0.045434087529429235
Trained batch 160 in epoch 3, gen_loss = 0.8721818424159695, disc_loss = 0.04526420134576674
Trained batch 161 in epoch 3, gen_loss = 0.8717253487787129, disc_loss = 0.04607332518818662
Trained batch 162 in epoch 3, gen_loss = 0.8708747650948039, disc_loss = 0.04614430405713755
Trained batch 163 in epoch 3, gen_loss = 0.8692932161616116, disc_loss = 0.046535322990654625
Trained batch 164 in epoch 3, gen_loss = 0.8688066804047787, disc_loss = 0.04643946213534836
Trained batch 165 in epoch 3, gen_loss = 0.8701397945363838, disc_loss = 0.047617633526875494
Trained batch 166 in epoch 3, gen_loss = 0.8685390984940672, disc_loss = 0.04820814483637314
Trained batch 167 in epoch 3, gen_loss = 0.8678245505406743, disc_loss = 0.04853572754377854
Trained batch 168 in epoch 3, gen_loss = 0.8671235301085478, disc_loss = 0.0486566073911474
Trained batch 169 in epoch 3, gen_loss = 0.8657657661858726, disc_loss = 0.049082513550734695
Trained batch 170 in epoch 3, gen_loss = 0.8669765731047469, disc_loss = 0.04920035038873205
Trained batch 171 in epoch 3, gen_loss = 0.865763216864231, disc_loss = 0.04924228293875362
Trained batch 172 in epoch 3, gen_loss = 0.8646781978579615, disc_loss = 0.049329260097698155
Trained batch 173 in epoch 3, gen_loss = 0.8657806998696821, disc_loss = 0.04926728560246699
Trained batch 174 in epoch 3, gen_loss = 0.8644555967194694, disc_loss = 0.0493934996239841
Trained batch 175 in epoch 3, gen_loss = 0.8652525479820642, disc_loss = 0.049504295840795916
Trained batch 176 in epoch 3, gen_loss = 0.8650495975704516, disc_loss = 0.04968373768168401
Trained batch 177 in epoch 3, gen_loss = 0.8634845316410065, disc_loss = 0.05033898944024708
Trained batch 178 in epoch 3, gen_loss = 0.8629564200033689, disc_loss = 0.05084795197055743
Trained batch 179 in epoch 3, gen_loss = 0.8630369673172633, disc_loss = 0.05082758243143973
Trained batch 180 in epoch 3, gen_loss = 0.8633111777885184, disc_loss = 0.0508175534916558
Trained batch 181 in epoch 3, gen_loss = 0.8627490486417498, disc_loss = 0.05085873579514305
Trained batch 182 in epoch 3, gen_loss = 0.8627531984464718, disc_loss = 0.05104770829208969
Trained batch 183 in epoch 3, gen_loss = 0.8614761405017065, disc_loss = 0.0512010834164634
Trained batch 184 in epoch 3, gen_loss = 0.8611248103347985, disc_loss = 0.0511370366716103
Trained batch 185 in epoch 3, gen_loss = 0.8612906090033952, disc_loss = 0.0511979209784899
Trained batch 186 in epoch 3, gen_loss = 0.860743514994249, disc_loss = 0.05134265553355615
Trained batch 187 in epoch 3, gen_loss = 0.8596813513877544, disc_loss = 0.05172989444381141
Trained batch 188 in epoch 3, gen_loss = 0.8604337033771333, disc_loss = 0.051869405741512616
Trained batch 189 in epoch 3, gen_loss = 0.859669890529231, disc_loss = 0.051823330457371315
Trained batch 190 in epoch 3, gen_loss = 0.8597340059530049, disc_loss = 0.0516795917726195
Trained batch 191 in epoch 3, gen_loss = 0.8599562014763554, disc_loss = 0.05148315368811988
Trained batch 192 in epoch 3, gen_loss = 0.8593530318279958, disc_loss = 0.05149317682609734
Trained batch 193 in epoch 3, gen_loss = 0.8590740942463433, disc_loss = 0.05129695445366357
Trained batch 194 in epoch 3, gen_loss = 0.8600800612033942, disc_loss = 0.051406662584019776
Trained batch 195 in epoch 3, gen_loss = 0.8594004055675195, disc_loss = 0.05142045820996698
Trained batch 196 in epoch 3, gen_loss = 0.8584855365269075, disc_loss = 0.05156365310924534
Trained batch 197 in epoch 3, gen_loss = 0.8587923411167029, disc_loss = 0.051897379426247996
Trained batch 198 in epoch 3, gen_loss = 0.8579568108122553, disc_loss = 0.05194749317866699
Trained batch 199 in epoch 3, gen_loss = 0.8578574243187904, disc_loss = 0.05180977284675464
Trained batch 200 in epoch 3, gen_loss = 0.8574344646278306, disc_loss = 0.05170284374501204
Trained batch 201 in epoch 3, gen_loss = 0.8578377351312354, disc_loss = 0.05178963348481546
Trained batch 202 in epoch 3, gen_loss = 0.8572884475069092, disc_loss = 0.05181050381113963
Trained batch 203 in epoch 3, gen_loss = 0.8565101664440304, disc_loss = 0.05172859510069019
Trained batch 204 in epoch 3, gen_loss = 0.8572981979788803, disc_loss = 0.051700748301043015
Trained batch 205 in epoch 3, gen_loss = 0.8577225894025229, disc_loss = 0.05157258812546079
Trained batch 206 in epoch 3, gen_loss = 0.857531874364125, disc_loss = 0.051463549594498344
Trained batch 207 in epoch 3, gen_loss = 0.8576721282532582, disc_loss = 0.051270878446163036
Trained batch 208 in epoch 3, gen_loss = 0.8579779464091981, disc_loss = 0.05108823142188231
Trained batch 209 in epoch 3, gen_loss = 0.8579971671104432, disc_loss = 0.05088626600225412
Trained batch 210 in epoch 3, gen_loss = 0.8573208985170482, disc_loss = 0.050862700274540776
Trained batch 211 in epoch 3, gen_loss = 0.8572670957952175, disc_loss = 0.05067571620500805
Trained batch 212 in epoch 3, gen_loss = 0.8581527992033623, disc_loss = 0.05088950905887664
Trained batch 213 in epoch 3, gen_loss = 0.8571666000045348, disc_loss = 0.05109974270834474
Trained batch 214 in epoch 3, gen_loss = 0.8569277727326682, disc_loss = 0.05106241114567532
Trained batch 215 in epoch 3, gen_loss = 0.8569287149994461, disc_loss = 0.05089481401955709
Trained batch 216 in epoch 3, gen_loss = 0.857182930691451, disc_loss = 0.0508630953767779
Trained batch 217 in epoch 3, gen_loss = 0.8568471760377971, disc_loss = 0.05069038586118558
Trained batch 218 in epoch 3, gen_loss = 0.8562736946698193, disc_loss = 0.05077823853443406
Trained batch 219 in epoch 3, gen_loss = 0.8578095089305531, disc_loss = 0.051026782052676106
Trained batch 220 in epoch 3, gen_loss = 0.8571635881160719, disc_loss = 0.05096869005261166
Trained batch 221 in epoch 3, gen_loss = 0.856616870777027, disc_loss = 0.05092029358881215
Trained batch 222 in epoch 3, gen_loss = 0.8565905922731476, disc_loss = 0.050775042645249
Trained batch 223 in epoch 3, gen_loss = 0.8577155039778778, disc_loss = 0.05080426618847663
Trained batch 224 in epoch 3, gen_loss = 0.857182149887085, disc_loss = 0.050741032128118806
Trained batch 225 in epoch 3, gen_loss = 0.8565124890445608, disc_loss = 0.05076783336492964
Trained batch 226 in epoch 3, gen_loss = 0.8567142276511843, disc_loss = 0.050609542095894196
Trained batch 227 in epoch 3, gen_loss = 0.8567333791339606, disc_loss = 0.05062337301205844
Trained batch 228 in epoch 3, gen_loss = 0.8575696877517034, disc_loss = 0.05046784448921355
Trained batch 229 in epoch 3, gen_loss = 0.8574882193751957, disc_loss = 0.05031188836361727
Trained batch 230 in epoch 3, gen_loss = 0.8575295331158164, disc_loss = 0.0501298858558364
Trained batch 231 in epoch 3, gen_loss = 0.857269626496167, disc_loss = 0.05003654866294678
Trained batch 232 in epoch 3, gen_loss = 0.8581641572227805, disc_loss = 0.0499033166811094
Trained batch 233 in epoch 3, gen_loss = 0.8583197364440331, disc_loss = 0.04999051229733751
Trained batch 234 in epoch 3, gen_loss = 0.857092809677124, disc_loss = 0.05029913471773901
Trained batch 235 in epoch 3, gen_loss = 0.8571874443757332, disc_loss = 0.05012742552503754
Trained batch 236 in epoch 3, gen_loss = 0.8586916767595186, disc_loss = 0.050438304170416
Trained batch 237 in epoch 3, gen_loss = 0.8587839994109979, disc_loss = 0.050310020869159526
Trained batch 238 in epoch 3, gen_loss = 0.8591363070898974, disc_loss = 0.05021225616811272
Trained batch 239 in epoch 3, gen_loss = 0.8581252718965212, disc_loss = 0.0504265646081573
Trained batch 240 in epoch 3, gen_loss = 0.8582399044788724, disc_loss = 0.05035008387485542
Trained batch 241 in epoch 3, gen_loss = 0.8596800777537763, disc_loss = 0.0504657169515344
Trained batch 242 in epoch 3, gen_loss = 0.8591355718212363, disc_loss = 0.050382413922467964
Trained batch 243 in epoch 3, gen_loss = 0.8586917954390166, disc_loss = 0.050427524955011904
Trained batch 244 in epoch 3, gen_loss = 0.8591926190317893, disc_loss = 0.05026839090587229
Trained batch 245 in epoch 3, gen_loss = 0.8590489058959775, disc_loss = 0.05014569950062872
Trained batch 246 in epoch 3, gen_loss = 0.8596347454588423, disc_loss = 0.05011558762152004
Trained batch 247 in epoch 3, gen_loss = 0.8597421446634878, disc_loss = 0.04996404434261363
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.7481895089149475, disc_loss = 0.02892681211233139
Trained batch 1 in epoch 4, gen_loss = 0.7401174008846283, disc_loss = 0.02783500123769045
Trained batch 2 in epoch 4, gen_loss = 0.881979763507843, disc_loss = 0.037739853685100876
Trained batch 3 in epoch 4, gen_loss = 0.9217439740896225, disc_loss = 0.0321234364528209
Trained batch 4 in epoch 4, gen_loss = 0.9253951430320739, disc_loss = 0.029500377736985682
Trained batch 5 in epoch 4, gen_loss = 0.9209625522295634, disc_loss = 0.027387971834590037
Trained batch 6 in epoch 4, gen_loss = 0.9286757792745318, disc_loss = 0.028191335632332733
Trained batch 7 in epoch 4, gen_loss = 0.9269209578633308, disc_loss = 0.02574804099276662
Trained batch 8 in epoch 4, gen_loss = 0.9234198530515035, disc_loss = 0.0266196404894193
Trained batch 9 in epoch 4, gen_loss = 0.9268277168273926, disc_loss = 0.025050461851060392
Trained batch 10 in epoch 4, gen_loss = 0.9240175919099287, disc_loss = 0.02356417307799513
Trained batch 11 in epoch 4, gen_loss = 0.9111311833063761, disc_loss = 0.02514292113482952
Trained batch 12 in epoch 4, gen_loss = 0.9037606624456552, disc_loss = 0.02419700022213734
Trained batch 13 in epoch 4, gen_loss = 0.90408969776971, disc_loss = 0.023146547177540406
Trained batch 14 in epoch 4, gen_loss = 0.9101977109909057, disc_loss = 0.022731337510049344
Trained batch 15 in epoch 4, gen_loss = 0.9041962325572968, disc_loss = 0.022286004445049912
Trained batch 16 in epoch 4, gen_loss = 0.904047990546507, disc_loss = 0.025964189156451645
Trained batch 17 in epoch 4, gen_loss = 0.8919416699144576, disc_loss = 0.02787189542626341
Trained batch 18 in epoch 4, gen_loss = 0.8819471378075449, disc_loss = 0.028307408927694747
Trained batch 19 in epoch 4, gen_loss = 0.8904305666685104, disc_loss = 0.032373883621767165
Trained batch 20 in epoch 4, gen_loss = 0.8816318370047069, disc_loss = 0.0324939415302305
Trained batch 21 in epoch 4, gen_loss = 0.8837591328404166, disc_loss = 0.03212925787507133
Trained batch 22 in epoch 4, gen_loss = 0.8808295623115872, disc_loss = 0.031322894617915154
Trained batch 23 in epoch 4, gen_loss = 0.8779866173863411, disc_loss = 0.03102280936824779
Trained batch 24 in epoch 4, gen_loss = 0.8718971228599548, disc_loss = 0.03160091079771519
Trained batch 25 in epoch 4, gen_loss = 0.8733601386730487, disc_loss = 0.031250447393036805
Trained batch 26 in epoch 4, gen_loss = 0.8690119981765747, disc_loss = 0.030967573807747277
Trained batch 27 in epoch 4, gen_loss = 0.8729167027132851, disc_loss = 0.03043763279648764
Trained batch 28 in epoch 4, gen_loss = 0.8678558859331854, disc_loss = 0.03132223819607291
Trained batch 29 in epoch 4, gen_loss = 0.8730241060256958, disc_loss = 0.03125921580940485
Trained batch 30 in epoch 4, gen_loss = 0.8685434864413354, disc_loss = 0.03124608676279745
Trained batch 31 in epoch 4, gen_loss = 0.8666349314153194, disc_loss = 0.031109290081076324
Trained batch 32 in epoch 4, gen_loss = 0.8694058909560695, disc_loss = 0.030838809230110863
Trained batch 33 in epoch 4, gen_loss = 0.8675855415708879, disc_loss = 0.030420146005995134
Trained batch 34 in epoch 4, gen_loss = 0.8694681610379901, disc_loss = 0.0303265922835895
Trained batch 35 in epoch 4, gen_loss = 0.8679480420218574, disc_loss = 0.030751325086587004
Trained batch 36 in epoch 4, gen_loss = 0.8720560524914716, disc_loss = 0.03087068077277493
Trained batch 37 in epoch 4, gen_loss = 0.8696642110222265, disc_loss = 0.03091746519662832
Trained batch 38 in epoch 4, gen_loss = 0.8709169962467291, disc_loss = 0.030493490159129485
Trained batch 39 in epoch 4, gen_loss = 0.876547759771347, disc_loss = 0.030432555731385945
Trained batch 40 in epoch 4, gen_loss = 0.8739829644924257, disc_loss = 0.03025464967983525
Trained batch 41 in epoch 4, gen_loss = 0.8688776067325047, disc_loss = 0.031133801631984256
Trained batch 42 in epoch 4, gen_loss = 0.8765374311181002, disc_loss = 0.037349173669205156
Trained batch 43 in epoch 4, gen_loss = 0.8744748356667432, disc_loss = 0.037094948389990764
Trained batch 44 in epoch 4, gen_loss = 0.8673005249765184, disc_loss = 0.03906988807850414
Trained batch 45 in epoch 4, gen_loss = 0.8686011187408281, disc_loss = 0.041428997221848236
Trained batch 46 in epoch 4, gen_loss = 0.8664664981213022, disc_loss = 0.04528058470880732
Trained batch 47 in epoch 4, gen_loss = 0.8646538915733496, disc_loss = 0.05347763941002389
Trained batch 48 in epoch 4, gen_loss = 0.8742331935434925, disc_loss = 0.06360498929814416
Trained batch 49 in epoch 4, gen_loss = 0.871140171289444, disc_loss = 0.06874236650764942
Trained batch 50 in epoch 4, gen_loss = 0.8699595495766285, disc_loss = 0.07481487540929925
Trained batch 51 in epoch 4, gen_loss = 0.8704861711997253, disc_loss = 0.07811377376604539
Trained batch 52 in epoch 4, gen_loss = 0.8676636072824586, disc_loss = 0.07913976802297358
Trained batch 53 in epoch 4, gen_loss = 0.8641934803238621, disc_loss = 0.07967209036427515
Trained batch 54 in epoch 4, gen_loss = 0.861821769584309, disc_loss = 0.07964657484130426
Trained batch 55 in epoch 4, gen_loss = 0.8591840820653098, disc_loss = 0.07947764618854437
Trained batch 56 in epoch 4, gen_loss = 0.8568495532922578, disc_loss = 0.07916862399954545
Trained batch 57 in epoch 4, gen_loss = 0.8531513851264427, disc_loss = 0.07976739185637441
Trained batch 58 in epoch 4, gen_loss = 0.8512107234890178, disc_loss = 0.07895710009892108
Trained batch 59 in epoch 4, gen_loss = 0.8497553487618764, disc_loss = 0.08014314031849305
Trained batch 60 in epoch 4, gen_loss = 0.8440333370302544, disc_loss = 0.08079108675239516
Trained batch 61 in epoch 4, gen_loss = 0.8438681489036929, disc_loss = 0.08157106398815109
Trained batch 62 in epoch 4, gen_loss = 0.8411146317209516, disc_loss = 0.08106622892239737
Trained batch 63 in epoch 4, gen_loss = 0.8396496502682567, disc_loss = 0.08032084931619465
Trained batch 64 in epoch 4, gen_loss = 0.8413014338566707, disc_loss = 0.07972074850247457
Trained batch 65 in epoch 4, gen_loss = 0.8407902293133013, disc_loss = 0.07880940102040768
Trained batch 66 in epoch 4, gen_loss = 0.8372396719989492, disc_loss = 0.07865526354802188
Trained batch 67 in epoch 4, gen_loss = 0.8369924610151964, disc_loss = 0.07787907435832654
Trained batch 68 in epoch 4, gen_loss = 0.83595026144083, disc_loss = 0.0775715414488661
Trained batch 69 in epoch 4, gen_loss = 0.8353807611124856, disc_loss = 0.07686597353645734
Trained batch 70 in epoch 4, gen_loss = 0.8334037401306797, disc_loss = 0.07640764972483607
Trained batch 71 in epoch 4, gen_loss = 0.8357222841845618, disc_loss = 0.0760921238300701
Trained batch 72 in epoch 4, gen_loss = 0.8356679579983018, disc_loss = 0.07526381992518086
Trained batch 73 in epoch 4, gen_loss = 0.8363791365881224, disc_loss = 0.07439841002829976
Trained batch 74 in epoch 4, gen_loss = 0.8348690128326416, disc_loss = 0.07384132131934167
Trained batch 75 in epoch 4, gen_loss = 0.8340309168163099, disc_loss = 0.0738415644062977
Trained batch 76 in epoch 4, gen_loss = 0.8376998220171247, disc_loss = 0.07353647295143698
Trained batch 77 in epoch 4, gen_loss = 0.8387385591482505, disc_loss = 0.07268765655298455
Trained batch 78 in epoch 4, gen_loss = 0.8359968918788282, disc_loss = 0.07265665014922808
Trained batch 79 in epoch 4, gen_loss = 0.8348639018833637, disc_loss = 0.07206825952162035
Trained batch 80 in epoch 4, gen_loss = 0.8360551367571325, disc_loss = 0.07169680235861445
Trained batch 81 in epoch 4, gen_loss = 0.8354544232531291, disc_loss = 0.07105941487271793
Trained batch 82 in epoch 4, gen_loss = 0.8350977280053747, disc_loss = 0.07049305647813592
Trained batch 83 in epoch 4, gen_loss = 0.8350586465426854, disc_loss = 0.06981359891748677
Trained batch 84 in epoch 4, gen_loss = 0.8359741105752833, disc_loss = 0.06947515268864878
Trained batch 85 in epoch 4, gen_loss = 0.8368098777393962, disc_loss = 0.06876855530386228
Trained batch 86 in epoch 4, gen_loss = 0.8352092682630167, disc_loss = 0.0684509305229903
Trained batch 87 in epoch 4, gen_loss = 0.8372329229658301, disc_loss = 0.06790995505236258
Trained batch 88 in epoch 4, gen_loss = 0.8409017203898912, disc_loss = 0.06783959412361297
Trained batch 89 in epoch 4, gen_loss = 0.8402353829807705, disc_loss = 0.06750875095215937
Trained batch 90 in epoch 4, gen_loss = 0.8393717899427309, disc_loss = 0.06702587346720336
Trained batch 91 in epoch 4, gen_loss = 0.8401286096676536, disc_loss = 0.06642328286239796
Trained batch 92 in epoch 4, gen_loss = 0.8422965170234762, disc_loss = 0.06591661685516917
Trained batch 93 in epoch 4, gen_loss = 0.8429159357192668, disc_loss = 0.06536292333770147
Trained batch 94 in epoch 4, gen_loss = 0.8427120064434253, disc_loss = 0.0648864548996483
Trained batch 95 in epoch 4, gen_loss = 0.8430460734913746, disc_loss = 0.06429818336134001
Trained batch 96 in epoch 4, gen_loss = 0.844575481316478, disc_loss = 0.06372762301015024
Trained batch 97 in epoch 4, gen_loss = 0.842639896334434, disc_loss = 0.0634329505882473
Trained batch 98 in epoch 4, gen_loss = 0.8448220298747824, disc_loss = 0.0629604728845409
Trained batch 99 in epoch 4, gen_loss = 0.8446960616111755, disc_loss = 0.06251915125641971
Trained batch 100 in epoch 4, gen_loss = 0.8441933204631994, disc_loss = 0.062197285589052013
Trained batch 101 in epoch 4, gen_loss = 0.8433788985598321, disc_loss = 0.06195931266719366
Trained batch 102 in epoch 4, gen_loss = 0.8459683141662079, disc_loss = 0.06180565896923247
Trained batch 103 in epoch 4, gen_loss = 0.8449677555606916, disc_loss = 0.061454159749421075
Trained batch 104 in epoch 4, gen_loss = 0.8456984122594198, disc_loss = 0.06100669861105936
Trained batch 105 in epoch 4, gen_loss = 0.8454324535603793, disc_loss = 0.06059221107565429
Trained batch 106 in epoch 4, gen_loss = 0.845967746226587, disc_loss = 0.06021821557622507
Trained batch 107 in epoch 4, gen_loss = 0.8450050287776523, disc_loss = 0.06001747602648619
Trained batch 108 in epoch 4, gen_loss = 0.8457157240001434, disc_loss = 0.05993835046596893
Trained batch 109 in epoch 4, gen_loss = 0.845324018868533, disc_loss = 0.05959472743878988
Trained batch 110 in epoch 4, gen_loss = 0.8445986466364818, disc_loss = 0.0591805732288809
Trained batch 111 in epoch 4, gen_loss = 0.8461399866001946, disc_loss = 0.05930754608458041
Trained batch 112 in epoch 4, gen_loss = 0.8439705741089002, disc_loss = 0.05956148810734132
Trained batch 113 in epoch 4, gen_loss = 0.8443572991772702, disc_loss = 0.05919585763803569
Trained batch 114 in epoch 4, gen_loss = 0.8463748258093129, disc_loss = 0.0592566857640834
Trained batch 115 in epoch 4, gen_loss = 0.845163615099315, disc_loss = 0.059272348443206786
Trained batch 116 in epoch 4, gen_loss = 0.8444707857237922, disc_loss = 0.059119998688339934
Trained batch 117 in epoch 4, gen_loss = 0.8459949740919016, disc_loss = 0.059402564489203745
Trained batch 118 in epoch 4, gen_loss = 0.8463742101893705, disc_loss = 0.059035480253304504
Trained batch 119 in epoch 4, gen_loss = 0.844689454138279, disc_loss = 0.059030828108855835
Trained batch 120 in epoch 4, gen_loss = 0.844095565563391, disc_loss = 0.05869189558612291
Trained batch 121 in epoch 4, gen_loss = 0.8437247095537967, disc_loss = 0.058862386618695056
Trained batch 122 in epoch 4, gen_loss = 0.8440198961312209, disc_loss = 0.05853788225676834
Trained batch 123 in epoch 4, gen_loss = 0.8438854385768214, disc_loss = 0.0581715741277402
Trained batch 124 in epoch 4, gen_loss = 0.8440885171890259, disc_loss = 0.05786797193810344
Trained batch 125 in epoch 4, gen_loss = 0.8428681294123331, disc_loss = 0.057688333164338794
Trained batch 126 in epoch 4, gen_loss = 0.8435571888300377, disc_loss = 0.05744482846343963
Trained batch 127 in epoch 4, gen_loss = 0.8435648176819086, disc_loss = 0.05719314841189771
Trained batch 128 in epoch 4, gen_loss = 0.8426493928413983, disc_loss = 0.0571384367518589
Trained batch 129 in epoch 4, gen_loss = 0.8420802836234753, disc_loss = 0.05681201798053315
Trained batch 130 in epoch 4, gen_loss = 0.843627180306966, disc_loss = 0.05665083709777198
Trained batch 131 in epoch 4, gen_loss = 0.8430601155216043, disc_loss = 0.05655584836759689
Trained batch 132 in epoch 4, gen_loss = 0.8413451345343339, disc_loss = 0.056862862679155024
Trained batch 133 in epoch 4, gen_loss = 0.8418871698094837, disc_loss = 0.056596563055193914
Trained batch 134 in epoch 4, gen_loss = 0.8428590063695555, disc_loss = 0.0564579650035335
Trained batch 135 in epoch 4, gen_loss = 0.8417262632180663, disc_loss = 0.056410423791556454
Trained batch 136 in epoch 4, gen_loss = 0.8408651108289287, disc_loss = 0.05635491232081813
Trained batch 137 in epoch 4, gen_loss = 0.8432872519976851, disc_loss = 0.05670529043477406
Trained batch 138 in epoch 4, gen_loss = 0.8436748908578063, disc_loss = 0.05637947461574519
Trained batch 139 in epoch 4, gen_loss = 0.8423983910254069, disc_loss = 0.056399052613414824
Trained batch 140 in epoch 4, gen_loss = 0.8442471741784549, disc_loss = 0.056231542282361296
Trained batch 141 in epoch 4, gen_loss = 0.84328931528078, disc_loss = 0.056181946713608544
Trained batch 142 in epoch 4, gen_loss = 0.8441744888579095, disc_loss = 0.05615310326309784
Trained batch 143 in epoch 4, gen_loss = 0.8438769835564826, disc_loss = 0.055903131785776675
Trained batch 144 in epoch 4, gen_loss = 0.8426110366295124, disc_loss = 0.05590418846635469
Trained batch 145 in epoch 4, gen_loss = 0.8432489339619467, disc_loss = 0.055733694474863475
Trained batch 146 in epoch 4, gen_loss = 0.8440229475092725, disc_loss = 0.05547137554342143
Trained batch 147 in epoch 4, gen_loss = 0.8443084620946163, disc_loss = 0.05513812890087531
Trained batch 148 in epoch 4, gen_loss = 0.8441116677834684, disc_loss = 0.05484880893584966
Trained batch 149 in epoch 4, gen_loss = 0.8438714452584585, disc_loss = 0.05456619736738503
Trained batch 150 in epoch 4, gen_loss = 0.8449550886817326, disc_loss = 0.05471513679078379
Trained batch 151 in epoch 4, gen_loss = 0.8434078744367549, disc_loss = 0.05524273998238832
Trained batch 152 in epoch 4, gen_loss = 0.8425648450072295, disc_loss = 0.05507725323519968
Trained batch 153 in epoch 4, gen_loss = 0.843872601722742, disc_loss = 0.05600426299799863
Trained batch 154 in epoch 4, gen_loss = 0.8427335335362343, disc_loss = 0.056060110245861355
Trained batch 155 in epoch 4, gen_loss = 0.8415064020798757, disc_loss = 0.05641280771054041
Trained batch 156 in epoch 4, gen_loss = 0.8405490418907943, disc_loss = 0.056696718733662825
Trained batch 157 in epoch 4, gen_loss = 0.8416085126279276, disc_loss = 0.056583617044659924
Trained batch 158 in epoch 4, gen_loss = 0.8420956434693726, disc_loss = 0.0562933353654478
Trained batch 159 in epoch 4, gen_loss = 0.8416801027953624, disc_loss = 0.056176603297353724
Trained batch 160 in epoch 4, gen_loss = 0.8413258276370742, disc_loss = 0.05597890698588135
Trained batch 161 in epoch 4, gen_loss = 0.8417051254231253, disc_loss = 0.05571785679857396
Trained batch 162 in epoch 4, gen_loss = 0.8417015510834068, disc_loss = 0.05554002354584314
Trained batch 163 in epoch 4, gen_loss = 0.84122731191356, disc_loss = 0.0553853768974588
Trained batch 164 in epoch 4, gen_loss = 0.8425371170043945, disc_loss = 0.05546903199600903
Trained batch 165 in epoch 4, gen_loss = 0.8433059999741703, disc_loss = 0.05522059391993266
Trained batch 166 in epoch 4, gen_loss = 0.8435397886944388, disc_loss = 0.054994280575523656
Trained batch 167 in epoch 4, gen_loss = 0.8430518163811593, disc_loss = 0.05488277707592629
Trained batch 168 in epoch 4, gen_loss = 0.8430894214726059, disc_loss = 0.05462767397323568
Trained batch 169 in epoch 4, gen_loss = 0.8444520252592423, disc_loss = 0.0544124055407284
Trained batch 170 in epoch 4, gen_loss = 0.8451261739981802, disc_loss = 0.05420959551072522
Trained batch 171 in epoch 4, gen_loss = 0.8447341527356658, disc_loss = 0.05399260265741844
Trained batch 172 in epoch 4, gen_loss = 0.8445245923334463, disc_loss = 0.05378686541669889
Trained batch 173 in epoch 4, gen_loss = 0.8445970659283386, disc_loss = 0.05357909548074949
Trained batch 174 in epoch 4, gen_loss = 0.8449131952013288, disc_loss = 0.05338888818398118
Trained batch 175 in epoch 4, gen_loss = 0.8449628993191503, disc_loss = 0.05313053343773142
Trained batch 176 in epoch 4, gen_loss = 0.8439818263727393, disc_loss = 0.05313123743402335
Trained batch 177 in epoch 4, gen_loss = 0.8447817121998648, disc_loss = 0.05325888099117477
Trained batch 178 in epoch 4, gen_loss = 0.8451053333682055, disc_loss = 0.05302251102506865
Trained batch 179 in epoch 4, gen_loss = 0.8443437914053599, disc_loss = 0.052872362714778215
Trained batch 180 in epoch 4, gen_loss = 0.8442995607523628, disc_loss = 0.05264993537556977
Trained batch 181 in epoch 4, gen_loss = 0.8446976722596766, disc_loss = 0.052446497816612925
Trained batch 182 in epoch 4, gen_loss = 0.8442508962636437, disc_loss = 0.05240576786289368
Trained batch 183 in epoch 4, gen_loss = 0.8450761311080145, disc_loss = 0.05220492230475192
Trained batch 184 in epoch 4, gen_loss = 0.84562230754543, disc_loss = 0.05198193248613058
Trained batch 185 in epoch 4, gen_loss = 0.8462342905100956, disc_loss = 0.05176757819079343
Trained batch 186 in epoch 4, gen_loss = 0.8463583543976361, disc_loss = 0.05167240424599638
Trained batch 187 in epoch 4, gen_loss = 0.8464489087779471, disc_loss = 0.051486090105522346
Trained batch 188 in epoch 4, gen_loss = 0.8462353878551059, disc_loss = 0.05128436418565572
Trained batch 189 in epoch 4, gen_loss = 0.8463577107379311, disc_loss = 0.05114221352544662
Trained batch 190 in epoch 4, gen_loss = 0.8460806121376796, disc_loss = 0.0510414214585347
Trained batch 191 in epoch 4, gen_loss = 0.8462470524633924, disc_loss = 0.050815634611353744
Trained batch 192 in epoch 4, gen_loss = 0.8468101793620253, disc_loss = 0.05061911570796154
Trained batch 193 in epoch 4, gen_loss = 0.8470402264717928, disc_loss = 0.05039523158116823
Trained batch 194 in epoch 4, gen_loss = 0.8467275350521772, disc_loss = 0.05031692175767743
Trained batch 195 in epoch 4, gen_loss = 0.8458281682462109, disc_loss = 0.050260753335184136
Trained batch 196 in epoch 4, gen_loss = 0.8459174009749126, disc_loss = 0.05005864511825485
Trained batch 197 in epoch 4, gen_loss = 0.8466868951465144, disc_loss = 0.04995736820538613
Trained batch 198 in epoch 4, gen_loss = 0.8469818701696157, disc_loss = 0.04983307611449954
Trained batch 199 in epoch 4, gen_loss = 0.8451525002717972, disc_loss = 0.05100134077714756
Trained batch 200 in epoch 4, gen_loss = 0.8466999512999805, disc_loss = 0.05121333336698549
Trained batch 201 in epoch 4, gen_loss = 0.8466154378239471, disc_loss = 0.05106084883480453
Trained batch 202 in epoch 4, gen_loss = 0.8465000755093955, disc_loss = 0.05093120032315845
Trained batch 203 in epoch 4, gen_loss = 0.8456816319741455, disc_loss = 0.050893311948040684
Trained batch 204 in epoch 4, gen_loss = 0.8455728234314337, disc_loss = 0.050802237733562544
Trained batch 205 in epoch 4, gen_loss = 0.8457919903171872, disc_loss = 0.05062154418499507
Trained batch 206 in epoch 4, gen_loss = 0.8455240205290236, disc_loss = 0.05049873634066055
Trained batch 207 in epoch 4, gen_loss = 0.8458907297597482, disc_loss = 0.05045355261133339
Trained batch 208 in epoch 4, gen_loss = 0.8462969290012378, disc_loss = 0.05024250847862312
Trained batch 209 in epoch 4, gen_loss = 0.8458407192003159, disc_loss = 0.05022101245953568
Trained batch 210 in epoch 4, gen_loss = 0.8459081782548914, disc_loss = 0.05003545361116387
Trained batch 211 in epoch 4, gen_loss = 0.8473118068474643, disc_loss = 0.05004069650378781
Trained batch 212 in epoch 4, gen_loss = 0.8478298481081573, disc_loss = 0.049882961448037146
Trained batch 213 in epoch 4, gen_loss = 0.8474139448638275, disc_loss = 0.04988020846715945
Trained batch 214 in epoch 4, gen_loss = 0.8465117033137831, disc_loss = 0.04988147228479732
Trained batch 215 in epoch 4, gen_loss = 0.8474602528192379, disc_loss = 0.04988474778494694
Trained batch 216 in epoch 4, gen_loss = 0.8476617630176281, disc_loss = 0.04969555686103515
Trained batch 217 in epoch 4, gen_loss = 0.8488987287796965, disc_loss = 0.04978974967331993
Trained batch 218 in epoch 4, gen_loss = 0.8479239703857735, disc_loss = 0.05005729148062329
Trained batch 219 in epoch 4, gen_loss = 0.8474757584658537, disc_loss = 0.05012544499159875
Trained batch 220 in epoch 4, gen_loss = 0.846599601512581, disc_loss = 0.05003563101230636
Trained batch 221 in epoch 4, gen_loss = 0.8466961896634316, disc_loss = 0.04990292826105278
Trained batch 222 in epoch 4, gen_loss = 0.8474843232086421, disc_loss = 0.04972558864287932
Trained batch 223 in epoch 4, gen_loss = 0.8473285966153655, disc_loss = 0.04955531012092251
Trained batch 224 in epoch 4, gen_loss = 0.8478073218133715, disc_loss = 0.04945786509041985
Trained batch 225 in epoch 4, gen_loss = 0.8475770082621448, disc_loss = 0.049295098057214534
Trained batch 226 in epoch 4, gen_loss = 0.848165345874652, disc_loss = 0.04913481466250601
Trained batch 227 in epoch 4, gen_loss = 0.8482338425360227, disc_loss = 0.04897837437027575
Trained batch 228 in epoch 4, gen_loss = 0.8477620573543565, disc_loss = 0.04889602485564273
Trained batch 229 in epoch 4, gen_loss = 0.8481048775755841, disc_loss = 0.04903452773578465
Trained batch 230 in epoch 4, gen_loss = 0.8476010852561885, disc_loss = 0.04894317303344736
Trained batch 231 in epoch 4, gen_loss = 0.8470187171779829, disc_loss = 0.04883135393350225
Trained batch 232 in epoch 4, gen_loss = 0.8470470836234195, disc_loss = 0.04876109264399297
Trained batch 233 in epoch 4, gen_loss = 0.8482429769813505, disc_loss = 0.04929029773403373
Trained batch 234 in epoch 4, gen_loss = 0.8470371761220566, disc_loss = 0.04977610210115288
Trained batch 235 in epoch 4, gen_loss = 0.8466063252950119, disc_loss = 0.04972343414161607
Trained batch 236 in epoch 4, gen_loss = 0.8458377686230946, disc_loss = 0.049840396205316995
Trained batch 237 in epoch 4, gen_loss = 0.8470600097119307, disc_loss = 0.04978315564099418
Trained batch 238 in epoch 4, gen_loss = 0.8472319996007815, disc_loss = 0.04961282642028259
Trained batch 239 in epoch 4, gen_loss = 0.8473337878783543, disc_loss = 0.04944549901993014
Trained batch 240 in epoch 4, gen_loss = 0.8471470539500604, disc_loss = 0.04930672700868541
Trained batch 241 in epoch 4, gen_loss = 0.8473242912903305, disc_loss = 0.04918825755488466
Trained batch 242 in epoch 4, gen_loss = 0.8480140228330353, disc_loss = 0.04904568680358951
Trained batch 243 in epoch 4, gen_loss = 0.8478380795873579, disc_loss = 0.04894888842073804
Trained batch 244 in epoch 4, gen_loss = 0.8473107882908413, disc_loss = 0.04888134010098114
Trained batch 245 in epoch 4, gen_loss = 0.8469231252263232, disc_loss = 0.04884412246983408
Trained batch 246 in epoch 4, gen_loss = 0.8474786612186355, disc_loss = 0.04880445460913333
Trained batch 247 in epoch 4, gen_loss = 0.8471709992135724, disc_loss = 0.04868249593475353
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.6917746067047119, disc_loss = 0.040239982306957245
Trained batch 1 in epoch 5, gen_loss = 0.7819415330886841, disc_loss = 0.04024112410843372
Trained batch 2 in epoch 5, gen_loss = 0.8041525880495707, disc_loss = 0.030169565230607986
Trained batch 3 in epoch 5, gen_loss = 0.8531336635351181, disc_loss = 0.025371937779709697
Trained batch 4 in epoch 5, gen_loss = 0.8749393105506897, disc_loss = 0.021794614009559156
Trained batch 5 in epoch 5, gen_loss = 0.8740367790063223, disc_loss = 0.022365098353475332
Trained batch 6 in epoch 5, gen_loss = 0.8737738728523254, disc_loss = 0.020322824828326702
Trained batch 7 in epoch 5, gen_loss = 0.8499814495444298, disc_loss = 0.023808373254723847
Trained batch 8 in epoch 5, gen_loss = 0.867931412325965, disc_loss = 0.039302857489221625
Trained batch 9 in epoch 5, gen_loss = 0.859749311208725, disc_loss = 0.037585533875972035
Trained batch 10 in epoch 5, gen_loss = 0.8505912531505931, disc_loss = 0.0384525569494475
Trained batch 11 in epoch 5, gen_loss = 0.82851309577624, disc_loss = 0.0468738570343703
Trained batch 12 in epoch 5, gen_loss = 0.8264875641235938, disc_loss = 0.04455190889823895
Trained batch 13 in epoch 5, gen_loss = 0.8505754513399941, disc_loss = 0.049537846485951116
Trained batch 14 in epoch 5, gen_loss = 0.8481724619865417, disc_loss = 0.047212011304994424
Trained batch 15 in epoch 5, gen_loss = 0.8408714719116688, disc_loss = 0.04719804710475728
Trained batch 16 in epoch 5, gen_loss = 0.8427979350090027, disc_loss = 0.045264610418063754
Trained batch 17 in epoch 5, gen_loss = 0.8363218473063575, disc_loss = 0.045824816398736506
Trained batch 18 in epoch 5, gen_loss = 0.8476903846389369, disc_loss = 0.060612423394463565
Trained batch 19 in epoch 5, gen_loss = 0.8423387259244919, disc_loss = 0.06129177561961115
Trained batch 20 in epoch 5, gen_loss = 0.8426478022620791, disc_loss = 0.0662897305030908
Trained batch 21 in epoch 5, gen_loss = 0.8289886713027954, disc_loss = 0.07669086800888181
Trained batch 22 in epoch 5, gen_loss = 0.8367161025171694, disc_loss = 0.07577038665666529
Trained batch 23 in epoch 5, gen_loss = 0.8379518538713455, disc_loss = 0.07376016882093002
Trained batch 24 in epoch 5, gen_loss = 0.8314866471290588, disc_loss = 0.07359395015984774
Trained batch 25 in epoch 5, gen_loss = 0.8281641625441037, disc_loss = 0.07401328064644566
Trained batch 26 in epoch 5, gen_loss = 0.822609837408419, disc_loss = 0.07282503256229339
Trained batch 27 in epoch 5, gen_loss = 0.8178823696715491, disc_loss = 0.07235735964163073
Trained batch 28 in epoch 5, gen_loss = 0.8214834764085966, disc_loss = 0.07143303613852837
Trained batch 29 in epoch 5, gen_loss = 0.8197196364402771, disc_loss = 0.07035183648889264
Trained batch 30 in epoch 5, gen_loss = 0.8129645720604928, disc_loss = 0.07090625830835873
Trained batch 31 in epoch 5, gen_loss = 0.81829515658319, disc_loss = 0.06906834919936955
Trained batch 32 in epoch 5, gen_loss = 0.8240066134568417, disc_loss = 0.06808876957405698
Trained batch 33 in epoch 5, gen_loss = 0.8239143631037544, disc_loss = 0.06642256507321316
Trained batch 34 in epoch 5, gen_loss = 0.8237539410591126, disc_loss = 0.06476871137108121
Trained batch 35 in epoch 5, gen_loss = 0.8197241971890131, disc_loss = 0.06425465477837457
Trained batch 36 in epoch 5, gen_loss = 0.8213810791840425, disc_loss = 0.06301625203844663
Trained batch 37 in epoch 5, gen_loss = 0.8242348808991281, disc_loss = 0.061563969246650994
Trained batch 38 in epoch 5, gen_loss = 0.8235733631329659, disc_loss = 0.060567138716578484
Trained batch 39 in epoch 5, gen_loss = 0.8233928471803665, disc_loss = 0.05975569738075137
Trained batch 40 in epoch 5, gen_loss = 0.8213044230530901, disc_loss = 0.05903017039342624
Trained batch 41 in epoch 5, gen_loss = 0.8221231273242405, disc_loss = 0.058262537100485394
Trained batch 42 in epoch 5, gen_loss = 0.8237507176953692, disc_loss = 0.05717135575968166
Trained batch 43 in epoch 5, gen_loss = 0.8296686031601646, disc_loss = 0.05654971208423376
Trained batch 44 in epoch 5, gen_loss = 0.8280225329928927, disc_loss = 0.05569211021065712
Trained batch 45 in epoch 5, gen_loss = 0.8236951335616733, disc_loss = 0.056362031027674675
Trained batch 46 in epoch 5, gen_loss = 0.8276705107790359, disc_loss = 0.05597353885148434
Trained batch 47 in epoch 5, gen_loss = 0.8298542288442453, disc_loss = 0.055482623322556414
Trained batch 48 in epoch 5, gen_loss = 0.8317264196824055, disc_loss = 0.05464232253024773
Trained batch 49 in epoch 5, gen_loss = 0.8304773306846619, disc_loss = 0.05396836571395397
Trained batch 50 in epoch 5, gen_loss = 0.831927052899903, disc_loss = 0.05308582147985112
Trained batch 51 in epoch 5, gen_loss = 0.8320153859945444, disc_loss = 0.052402140465206824
Trained batch 52 in epoch 5, gen_loss = 0.8346627635775872, disc_loss = 0.052380740677691856
Trained batch 53 in epoch 5, gen_loss = 0.8276127919002816, disc_loss = 0.054591003977866086
Trained batch 54 in epoch 5, gen_loss = 0.8286612694913691, disc_loss = 0.054598837582902474
Trained batch 55 in epoch 5, gen_loss = 0.8311098973665919, disc_loss = 0.05387844526142414
Trained batch 56 in epoch 5, gen_loss = 0.828879177570343, disc_loss = 0.05417663298481912
Trained batch 57 in epoch 5, gen_loss = 0.8315378571378773, disc_loss = 0.053573124961734844
Trained batch 58 in epoch 5, gen_loss = 0.8330708378452366, disc_loss = 0.05297060182981067
Trained batch 59 in epoch 5, gen_loss = 0.8310454706350963, disc_loss = 0.05268503003753722
Trained batch 60 in epoch 5, gen_loss = 0.8295680675350252, disc_loss = 0.05219555171359269
Trained batch 61 in epoch 5, gen_loss = 0.8331971956837562, disc_loss = 0.052901494421906045
Trained batch 62 in epoch 5, gen_loss = 0.8314228455225626, disc_loss = 0.052514518581567304
Trained batch 63 in epoch 5, gen_loss = 0.8302327487617731, disc_loss = 0.05190732446499169
Trained batch 64 in epoch 5, gen_loss = 0.8312549939522377, disc_loss = 0.051251787978869215
Trained batch 65 in epoch 5, gen_loss = 0.8324756929368684, disc_loss = 0.050904803768251884
Trained batch 66 in epoch 5, gen_loss = 0.8304339540538503, disc_loss = 0.05073539462329736
Trained batch 67 in epoch 5, gen_loss = 0.8316396895576926, disc_loss = 0.05021882865249234
Trained batch 68 in epoch 5, gen_loss = 0.8312626083691915, disc_loss = 0.05045084728170996
Trained batch 69 in epoch 5, gen_loss = 0.8292288592883519, disc_loss = 0.050197318914745534
Trained batch 70 in epoch 5, gen_loss = 0.8273185575512093, disc_loss = 0.05003529396170462
Trained batch 71 in epoch 5, gen_loss = 0.8307008147239685, disc_loss = 0.050208609007919826
Trained batch 72 in epoch 5, gen_loss = 0.830708190186383, disc_loss = 0.049639656297760466
Trained batch 73 in epoch 5, gen_loss = 0.8285347787109582, disc_loss = 0.04955024430779992
Trained batch 74 in epoch 5, gen_loss = 0.8276253453890483, disc_loss = 0.04916614678998788
Trained batch 75 in epoch 5, gen_loss = 0.8300060951396039, disc_loss = 0.05057841389881153
Trained batch 76 in epoch 5, gen_loss = 0.8285148530811458, disc_loss = 0.05057120175620952
Trained batch 77 in epoch 5, gen_loss = 0.8287379390154129, disc_loss = 0.05065811117394613
Trained batch 78 in epoch 5, gen_loss = 0.8262400204622293, disc_loss = 0.05169537491341935
Trained batch 79 in epoch 5, gen_loss = 0.8270788826048374, disc_loss = 0.05129740841221064
Trained batch 80 in epoch 5, gen_loss = 0.8271340286290204, disc_loss = 0.050844018531526314
Trained batch 81 in epoch 5, gen_loss = 0.8287431270610995, disc_loss = 0.05065542846781815
Trained batch 82 in epoch 5, gen_loss = 0.825694607682975, disc_loss = 0.051342729131231106
Trained batch 83 in epoch 5, gen_loss = 0.8243544988688969, disc_loss = 0.05129438670839937
Trained batch 84 in epoch 5, gen_loss = 0.8257997589952806, disc_loss = 0.05145050178775016
Trained batch 85 in epoch 5, gen_loss = 0.8278605833996174, disc_loss = 0.051312438721313726
Trained batch 86 in epoch 5, gen_loss = 0.8256009721207893, disc_loss = 0.05153625065610669
Trained batch 87 in epoch 5, gen_loss = 0.8251759084788236, disc_loss = 0.051127945951355454
Trained batch 88 in epoch 5, gen_loss = 0.8265384616476766, disc_loss = 0.0506906851581978
Trained batch 89 in epoch 5, gen_loss = 0.825487384531233, disc_loss = 0.050518490518960686
Trained batch 90 in epoch 5, gen_loss = 0.827720894918337, disc_loss = 0.05029096929254113
Trained batch 91 in epoch 5, gen_loss = 0.8266306785137757, disc_loss = 0.050114201503279415
Trained batch 92 in epoch 5, gen_loss = 0.8277503078983676, disc_loss = 0.049661466571432285
Trained batch 93 in epoch 5, gen_loss = 0.828215924349237, disc_loss = 0.04937595301406815
Trained batch 94 in epoch 5, gen_loss = 0.8310309077564039, disc_loss = 0.04915899914738379
Trained batch 95 in epoch 5, gen_loss = 0.8313299448539814, disc_loss = 0.048776173973844074
Trained batch 96 in epoch 5, gen_loss = 0.8310537792972683, disc_loss = 0.04857941166757001
Trained batch 97 in epoch 5, gen_loss = 0.8316667311045588, disc_loss = 0.04815729984975591
Trained batch 98 in epoch 5, gen_loss = 0.8347710346934771, disc_loss = 0.048139805256417305
Trained batch 99 in epoch 5, gen_loss = 0.8324939268827438, disc_loss = 0.048525576777756214
Trained batch 100 in epoch 5, gen_loss = 0.8344472463768308, disc_loss = 0.04844705564993443
Trained batch 101 in epoch 5, gen_loss = 0.8356137643842136, disc_loss = 0.04814996975747978
Trained batch 102 in epoch 5, gen_loss = 0.8344643422700826, disc_loss = 0.048230181945469776
Trained batch 103 in epoch 5, gen_loss = 0.8343347041652753, disc_loss = 0.047950523278604336
Trained batch 104 in epoch 5, gen_loss = 0.8352071972120376, disc_loss = 0.048476535312476615
Trained batch 105 in epoch 5, gen_loss = 0.8328244680503629, disc_loss = 0.04929477097642309
Trained batch 106 in epoch 5, gen_loss = 0.8324197647727538, disc_loss = 0.04914281268334277
Trained batch 107 in epoch 5, gen_loss = 0.832584728245382, disc_loss = 0.04946059831935498
Trained batch 108 in epoch 5, gen_loss = 0.8313363085099317, disc_loss = 0.04949609615728943
Trained batch 109 in epoch 5, gen_loss = 0.8305227686058391, disc_loss = 0.04939750217917291
Trained batch 110 in epoch 5, gen_loss = 0.8303450668180311, disc_loss = 0.04974321606527041
Trained batch 111 in epoch 5, gen_loss = 0.830873616039753, disc_loss = 0.04942921071778983
Trained batch 112 in epoch 5, gen_loss = 0.8310017675425099, disc_loss = 0.04919281273882473
Trained batch 113 in epoch 5, gen_loss = 0.831130314814417, disc_loss = 0.048866826534401955
Trained batch 114 in epoch 5, gen_loss = 0.8344425206599029, disc_loss = 0.04942803229002849
Trained batch 115 in epoch 5, gen_loss = 0.8366999836831257, disc_loss = 0.049279064598396934
Trained batch 116 in epoch 5, gen_loss = 0.8356478275396885, disc_loss = 0.049734846473886415
Trained batch 117 in epoch 5, gen_loss = 0.835449279364893, disc_loss = 0.04989915727874485
Trained batch 118 in epoch 5, gen_loss = 0.8348709064371446, disc_loss = 0.050258289756519456
Trained batch 119 in epoch 5, gen_loss = 0.8337867647409439, disc_loss = 0.05014029513113201
Trained batch 120 in epoch 5, gen_loss = 0.8335971753459331, disc_loss = 0.04989026382196048
Trained batch 121 in epoch 5, gen_loss = 0.8329014543627129, disc_loss = 0.049778208716726696
Trained batch 122 in epoch 5, gen_loss = 0.834258786061915, disc_loss = 0.04953065506992786
Trained batch 123 in epoch 5, gen_loss = 0.8345948481752027, disc_loss = 0.04947145846522143
Trained batch 124 in epoch 5, gen_loss = 0.8335883460044861, disc_loss = 0.04934342776238918
Trained batch 125 in epoch 5, gen_loss = 0.833557234870063, disc_loss = 0.049568415028117006
Trained batch 126 in epoch 5, gen_loss = 0.8327694995196786, disc_loss = 0.049396874647088876
Trained batch 127 in epoch 5, gen_loss = 0.8326693051494658, disc_loss = 0.049222897316212766
Trained batch 128 in epoch 5, gen_loss = 0.8323972331461056, disc_loss = 0.048931897740608965
Trained batch 129 in epoch 5, gen_loss = 0.8318483632344466, disc_loss = 0.04890489493711637
Trained batch 130 in epoch 5, gen_loss = 0.8326583045129557, disc_loss = 0.048575302856114076
Trained batch 131 in epoch 5, gen_loss = 0.8338078310092291, disc_loss = 0.048525966591004166
Trained batch 132 in epoch 5, gen_loss = 0.8319402673190698, disc_loss = 0.0487882520135184
Trained batch 133 in epoch 5, gen_loss = 0.8314600982772771, disc_loss = 0.048615992666958874
Trained batch 134 in epoch 5, gen_loss = 0.8323593492861148, disc_loss = 0.04879547317546827
Trained batch 135 in epoch 5, gen_loss = 0.8336418937234318, disc_loss = 0.04852748255464522
Trained batch 136 in epoch 5, gen_loss = 0.8333705302572598, disc_loss = 0.048386901426706874
Trained batch 137 in epoch 5, gen_loss = 0.8314410275307255, disc_loss = 0.049081074829766716
Trained batch 138 in epoch 5, gen_loss = 0.8339354202901716, disc_loss = 0.0498915019063212
Trained batch 139 in epoch 5, gen_loss = 0.8348049053124019, disc_loss = 0.04966116772432413
Trained batch 140 in epoch 5, gen_loss = 0.8327288293669409, disc_loss = 0.05036067668057925
Trained batch 141 in epoch 5, gen_loss = 0.8338442692454432, disc_loss = 0.05078410720583838
Trained batch 142 in epoch 5, gen_loss = 0.8318548431763282, disc_loss = 0.05143072196914183
Trained batch 143 in epoch 5, gen_loss = 0.8321709719796976, disc_loss = 0.05146753659937531
Trained batch 144 in epoch 5, gen_loss = 0.8322542437191667, disc_loss = 0.05137513461041039
Trained batch 145 in epoch 5, gen_loss = 0.8331910028849563, disc_loss = 0.05117767698399416
Trained batch 146 in epoch 5, gen_loss = 0.8331045439454163, disc_loss = 0.051025407933661726
Trained batch 147 in epoch 5, gen_loss = 0.831554805104797, disc_loss = 0.051283771902121404
Trained batch 148 in epoch 5, gen_loss = 0.8320888080852944, disc_loss = 0.05138405874971575
Trained batch 149 in epoch 5, gen_loss = 0.8312231135368348, disc_loss = 0.05130112106601397
Trained batch 150 in epoch 5, gen_loss = 0.8316788373403992, disc_loss = 0.05101461702377986
Trained batch 151 in epoch 5, gen_loss = 0.83204545904147, disc_loss = 0.05077655805814031
Trained batch 152 in epoch 5, gen_loss = 0.831830812825097, disc_loss = 0.050543210371793094
Trained batch 153 in epoch 5, gen_loss = 0.8333283906633203, disc_loss = 0.05094992784880005
Trained batch 154 in epoch 5, gen_loss = 0.8321712220868757, disc_loss = 0.05112410600507452
Trained batch 155 in epoch 5, gen_loss = 0.8305834336922719, disc_loss = 0.051496239277558066
Trained batch 156 in epoch 5, gen_loss = 0.8316670333503917, disc_loss = 0.05152244041940779
Trained batch 157 in epoch 5, gen_loss = 0.8315667747696743, disc_loss = 0.05189489523137483
Trained batch 158 in epoch 5, gen_loss = 0.8298020763967022, disc_loss = 0.052241918958910984
Trained batch 159 in epoch 5, gen_loss = 0.8298254676163197, disc_loss = 0.05213867267011665
Trained batch 160 in epoch 5, gen_loss = 0.8323935129627678, disc_loss = 0.05242982691281146
Trained batch 161 in epoch 5, gen_loss = 0.8317981686121152, disc_loss = 0.05228649740348811
Trained batch 162 in epoch 5, gen_loss = 0.8309372392900151, disc_loss = 0.052174407834518544
Trained batch 163 in epoch 5, gen_loss = 0.8318811382462339, disc_loss = 0.052025556592725036
Trained batch 164 in epoch 5, gen_loss = 0.8324207201148525, disc_loss = 0.05177747518614386
Trained batch 165 in epoch 5, gen_loss = 0.8324413611946335, disc_loss = 0.051515583504350426
Trained batch 166 in epoch 5, gen_loss = 0.8323029550963533, disc_loss = 0.05129055354833424
Trained batch 167 in epoch 5, gen_loss = 0.8339461528119587, disc_loss = 0.05109664410286184
Trained batch 168 in epoch 5, gen_loss = 0.8331503864576125, disc_loss = 0.051071406253916624
Trained batch 169 in epoch 5, gen_loss = 0.8339211502495933, disc_loss = 0.05102049119441825
Trained batch 170 in epoch 5, gen_loss = 0.8339505317615487, disc_loss = 0.05078467466917477
Trained batch 171 in epoch 5, gen_loss = 0.8347009933272074, disc_loss = 0.05062952688028819
Trained batch 172 in epoch 5, gen_loss = 0.8331965359649217, disc_loss = 0.0508366147745293
Trained batch 173 in epoch 5, gen_loss = 0.8325885373285447, disc_loss = 0.05077533717748934
Trained batch 174 in epoch 5, gen_loss = 0.8336132230077471, disc_loss = 0.050989257634750436
Trained batch 175 in epoch 5, gen_loss = 0.8329482874409719, disc_loss = 0.05104781897336414
Trained batch 176 in epoch 5, gen_loss = 0.8319169380570536, disc_loss = 0.0512203816061387
Trained batch 177 in epoch 5, gen_loss = 0.8309871859095069, disc_loss = 0.05122235838554046
Trained batch 178 in epoch 5, gen_loss = 0.8315837493155922, disc_loss = 0.0509899152369972
Trained batch 179 in epoch 5, gen_loss = 0.8314331024885178, disc_loss = 0.050781457747022314
Trained batch 180 in epoch 5, gen_loss = 0.8315178982460696, disc_loss = 0.050728294689681645
Trained batch 181 in epoch 5, gen_loss = 0.8315714463427827, disc_loss = 0.05052220514862911
Trained batch 182 in epoch 5, gen_loss = 0.8308574896041161, disc_loss = 0.050470168865158586
Trained batch 183 in epoch 5, gen_loss = 0.8309997741294943, disc_loss = 0.05024604211844828
Trained batch 184 in epoch 5, gen_loss = 0.8323520357544357, disc_loss = 0.05075938649274207
Trained batch 185 in epoch 5, gen_loss = 0.8314749361366354, disc_loss = 0.05068072574513574
Trained batch 186 in epoch 5, gen_loss = 0.8314701841476767, disc_loss = 0.050502184320261136
Trained batch 187 in epoch 5, gen_loss = 0.8307820117854058, disc_loss = 0.05065255897476318
Trained batch 188 in epoch 5, gen_loss = 0.8310187935198425, disc_loss = 0.050649884220941986
Trained batch 189 in epoch 5, gen_loss = 0.8305466849552957, disc_loss = 0.05052625076159051
Trained batch 190 in epoch 5, gen_loss = 0.8302023732225309, disc_loss = 0.050406555815829035
Trained batch 191 in epoch 5, gen_loss = 0.8300071333845457, disc_loss = 0.050224240922640696
Trained batch 192 in epoch 5, gen_loss = 0.8300706713310795, disc_loss = 0.05015166174774806
Trained batch 193 in epoch 5, gen_loss = 0.8293900179494288, disc_loss = 0.050088491919690496
Trained batch 194 in epoch 5, gen_loss = 0.8303129345942766, disc_loss = 0.04994006913919479
Trained batch 195 in epoch 5, gen_loss = 0.8299684764779344, disc_loss = 0.04979554080518381
Trained batch 196 in epoch 5, gen_loss = 0.8311687323647707, disc_loss = 0.051247082116451056
Trained batch 197 in epoch 5, gen_loss = 0.8298042395500221, disc_loss = 0.05189109341043866
Trained batch 198 in epoch 5, gen_loss = 0.8296513722170538, disc_loss = 0.05191641562529395
Trained batch 199 in epoch 5, gen_loss = 0.8289247465133667, disc_loss = 0.051900662290863694
Trained batch 200 in epoch 5, gen_loss = 0.8288378798546483, disc_loss = 0.05182190882088385
Trained batch 201 in epoch 5, gen_loss = 0.8288283300871896, disc_loss = 0.05184187704586599
Trained batch 202 in epoch 5, gen_loss = 0.8286014947985193, disc_loss = 0.05252897388444011
Trained batch 203 in epoch 5, gen_loss = 0.8288756661555347, disc_loss = 0.053321161631531284
Trained batch 204 in epoch 5, gen_loss = 0.8291125948836163, disc_loss = 0.05382484787757077
Trained batch 205 in epoch 5, gen_loss = 0.8288252078792424, disc_loss = 0.053975377281567136
Trained batch 206 in epoch 5, gen_loss = 0.8280107995162264, disc_loss = 0.054103081798459886
Trained batch 207 in epoch 5, gen_loss = 0.8275620539027911, disc_loss = 0.053959416068839625
Trained batch 208 in epoch 5, gen_loss = 0.826671248417722, disc_loss = 0.05419895030183798
Trained batch 209 in epoch 5, gen_loss = 0.8272220577512469, disc_loss = 0.05414852945666228
Trained batch 210 in epoch 5, gen_loss = 0.8265250486220229, disc_loss = 0.054241134467318444
Trained batch 211 in epoch 5, gen_loss = 0.8266199950901967, disc_loss = 0.0541376601245676
Trained batch 212 in epoch 5, gen_loss = 0.8264903210698159, disc_loss = 0.05415005546867707
Trained batch 213 in epoch 5, gen_loss = 0.8262551958872894, disc_loss = 0.053975717595421545
Trained batch 214 in epoch 5, gen_loss = 0.8264268362244894, disc_loss = 0.053777287974087304
Trained batch 215 in epoch 5, gen_loss = 0.826911962694592, disc_loss = 0.05361758686032974
Trained batch 216 in epoch 5, gen_loss = 0.8271271745730105, disc_loss = 0.05363336409343415
Trained batch 217 in epoch 5, gen_loss = 0.8265486488101679, disc_loss = 0.053624425079126695
Trained batch 218 in epoch 5, gen_loss = 0.8261384302622652, disc_loss = 0.05350629475444011
Trained batch 219 in epoch 5, gen_loss = 0.8266069219871001, disc_loss = 0.05374449745921249
Trained batch 220 in epoch 5, gen_loss = 0.8261591673436748, disc_loss = 0.053647795468737366
Trained batch 221 in epoch 5, gen_loss = 0.8254672216402518, disc_loss = 0.053658773019272195
Trained batch 222 in epoch 5, gen_loss = 0.8254418207390961, disc_loss = 0.05362606934384514
Trained batch 223 in epoch 5, gen_loss = 0.8249224666506052, disc_loss = 0.053540358889482116
Trained batch 224 in epoch 5, gen_loss = 0.8258574393060473, disc_loss = 0.05341832034703758
Trained batch 225 in epoch 5, gen_loss = 0.8255887094852143, disc_loss = 0.05326970447003182
Trained batch 226 in epoch 5, gen_loss = 0.8251654014713439, disc_loss = 0.053127676154187335
Trained batch 227 in epoch 5, gen_loss = 0.8265684074477145, disc_loss = 0.053073579318854106
Trained batch 228 in epoch 5, gen_loss = 0.8266005695647027, disc_loss = 0.05292609171722263
Trained batch 229 in epoch 5, gen_loss = 0.8272760383460833, disc_loss = 0.05290407086925014
Trained batch 230 in epoch 5, gen_loss = 0.8271572798877568, disc_loss = 0.052849649661321406
Trained batch 231 in epoch 5, gen_loss = 0.8271739613907091, disc_loss = 0.05271761574188311
Trained batch 232 in epoch 5, gen_loss = 0.8271768612411401, disc_loss = 0.05257881982371915
Trained batch 233 in epoch 5, gen_loss = 0.8274455521351252, disc_loss = 0.05256157032110625
Trained batch 234 in epoch 5, gen_loss = 0.8277585760075995, disc_loss = 0.05238714922378038
Trained batch 235 in epoch 5, gen_loss = 0.8270973361144631, disc_loss = 0.052457174542754635
Trained batch 236 in epoch 5, gen_loss = 0.8276474782686193, disc_loss = 0.052400332183934716
Trained batch 237 in epoch 5, gen_loss = 0.8281382207109147, disc_loss = 0.05225407344312603
Trained batch 238 in epoch 5, gen_loss = 0.8279563093783965, disc_loss = 0.05211706529274022
Trained batch 239 in epoch 5, gen_loss = 0.8279494062066078, disc_loss = 0.051979735668282956
Trained batch 240 in epoch 5, gen_loss = 0.82791733939618, disc_loss = 0.05183462425679958
Trained batch 241 in epoch 5, gen_loss = 0.8284184188882181, disc_loss = 0.05165945274816934
Trained batch 242 in epoch 5, gen_loss = 0.829344538013631, disc_loss = 0.051533413395561556
Trained batch 243 in epoch 5, gen_loss = 0.8292892570378351, disc_loss = 0.05141604948620938
Trained batch 244 in epoch 5, gen_loss = 0.8292588413978109, disc_loss = 0.05126870504523418
Trained batch 245 in epoch 5, gen_loss = 0.8298745261944407, disc_loss = 0.05110010842800262
Trained batch 246 in epoch 5, gen_loss = 0.8298742372980003, disc_loss = 0.0509735707698865
Trained batch 247 in epoch 5, gen_loss = 0.8298444743117979, disc_loss = 0.05094881588968659
Testing Epoch 5

Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.8511950969696045, disc_loss = 0.025734636932611465
Trained batch 1 in epoch 6, gen_loss = 0.8843443095684052, disc_loss = 0.0337070319801569
Trained batch 2 in epoch 6, gen_loss = 0.8263971209526062, disc_loss = 0.047500974188248314
Trained batch 3 in epoch 6, gen_loss = 0.8282573223114014, disc_loss = 0.03826465387828648
Trained batch 4 in epoch 6, gen_loss = 0.8144000768661499, disc_loss = 0.03472747039049864
Trained batch 5 in epoch 6, gen_loss = 0.8320801357428232, disc_loss = 0.03023865493014455
Trained batch 6 in epoch 6, gen_loss = 0.8656733461788723, disc_loss = 0.03886833294693913
Trained batch 7 in epoch 6, gen_loss = 0.8409598916769028, disc_loss = 0.043707694276236
Trained batch 8 in epoch 6, gen_loss = 0.8287558290693495, disc_loss = 0.043111453764140606
Trained batch 9 in epoch 6, gen_loss = 0.8510879516601563, disc_loss = 0.04266465408727527
Trained batch 10 in epoch 6, gen_loss = 0.8610796603289518, disc_loss = 0.04212438780814409
Trained batch 11 in epoch 6, gen_loss = 0.8546910136938095, disc_loss = 0.04035024756255249
Trained batch 12 in epoch 6, gen_loss = 0.839325854411492, disc_loss = 0.0407243431903995
Trained batch 13 in epoch 6, gen_loss = 0.8435653320380619, disc_loss = 0.03913871245458722
Trained batch 14 in epoch 6, gen_loss = 0.8536913752555847, disc_loss = 0.03858530862877766
Trained batch 15 in epoch 6, gen_loss = 0.8519572727382183, disc_loss = 0.03718181553995237
Trained batch 16 in epoch 6, gen_loss = 0.8388969161931206, disc_loss = 0.03781227893469965
Trained batch 17 in epoch 6, gen_loss = 0.831437862581677, disc_loss = 0.037823740341183215
Trained batch 18 in epoch 6, gen_loss = 0.8330449618791279, disc_loss = 0.03849070435880046
Trained batch 19 in epoch 6, gen_loss = 0.8331195652484894, disc_loss = 0.03690708768554032
Trained batch 20 in epoch 6, gen_loss = 0.8318690089952379, disc_loss = 0.03772100775192181
Trained batch 21 in epoch 6, gen_loss = 0.8397720862518657, disc_loss = 0.0390541984022341
Trained batch 22 in epoch 6, gen_loss = 0.8291785328284554, disc_loss = 0.042276492949737156
Trained batch 23 in epoch 6, gen_loss = 0.8269421483079592, disc_loss = 0.04121409934790184
Trained batch 24 in epoch 6, gen_loss = 0.8300283193588257, disc_loss = 0.0431887261942029
Trained batch 25 in epoch 6, gen_loss = 0.8283693125614753, disc_loss = 0.04211103855274045
Trained batch 26 in epoch 6, gen_loss = 0.8304437774199026, disc_loss = 0.040905678265348626
Trained batch 27 in epoch 6, gen_loss = 0.8385670419250216, disc_loss = 0.04028373081902308
Trained batch 28 in epoch 6, gen_loss = 0.8397746723273705, disc_loss = 0.039147546514868736
Trained batch 29 in epoch 6, gen_loss = 0.8366848051548004, disc_loss = 0.03883599905918042
Trained batch 30 in epoch 6, gen_loss = 0.8468465708917187, disc_loss = 0.03928880075052861
Trained batch 31 in epoch 6, gen_loss = 0.8411124441772699, disc_loss = 0.03934871481033042
Trained batch 32 in epoch 6, gen_loss = 0.840168996290727, disc_loss = 0.03880792466754263
Trained batch 33 in epoch 6, gen_loss = 0.8432714483317207, disc_loss = 0.038380568792276526
Trained batch 34 in epoch 6, gen_loss = 0.8440365706171308, disc_loss = 0.03771094094429697
Trained batch 35 in epoch 6, gen_loss = 0.844017893075943, disc_loss = 0.037088599883847766
Trained batch 36 in epoch 6, gen_loss = 0.8454802584003758, disc_loss = 0.03789064811693656
Trained batch 37 in epoch 6, gen_loss = 0.8458908451230902, disc_loss = 0.037218160241058
Trained batch 38 in epoch 6, gen_loss = 0.8426320736224835, disc_loss = 0.03749291073435392
Trained batch 39 in epoch 6, gen_loss = 0.8373864978551865, disc_loss = 0.03790207775309682
Trained batch 40 in epoch 6, gen_loss = 0.8361489482042266, disc_loss = 0.03750418485483018
Trained batch 41 in epoch 6, gen_loss = 0.8426556275004432, disc_loss = 0.037399575247296264
Trained batch 42 in epoch 6, gen_loss = 0.8447621339975402, disc_loss = 0.03675944691653862
Trained batch 43 in epoch 6, gen_loss = 0.8435369012030688, disc_loss = 0.03623461418531158
Trained batch 44 in epoch 6, gen_loss = 0.844061569372813, disc_loss = 0.035590704934050636
Trained batch 45 in epoch 6, gen_loss = 0.8460583816403928, disc_loss = 0.034998534115679235
Trained batch 46 in epoch 6, gen_loss = 0.8439505962615318, disc_loss = 0.03488437763038785
Trained batch 47 in epoch 6, gen_loss = 0.8450362409154574, disc_loss = 0.03453460268792696
Trained batch 48 in epoch 6, gen_loss = 0.8480533945317171, disc_loss = 0.035073224483628054
Trained batch 49 in epoch 6, gen_loss = 0.8460156464576721, disc_loss = 0.0351630527805537
Trained batch 50 in epoch 6, gen_loss = 0.8430377829308603, disc_loss = 0.03550088751659382
Trained batch 51 in epoch 6, gen_loss = 0.8416501329495356, disc_loss = 0.03559630760887208
Trained batch 52 in epoch 6, gen_loss = 0.8463119538325183, disc_loss = 0.036448128055781126
Trained batch 53 in epoch 6, gen_loss = 0.8426158163282607, disc_loss = 0.036882037943643003
Trained batch 54 in epoch 6, gen_loss = 0.8433761845935475, disc_loss = 0.036750917229801415
Trained batch 55 in epoch 6, gen_loss = 0.8427181531276021, disc_loss = 0.03678164194570854
Trained batch 56 in epoch 6, gen_loss = 0.8427938965328953, disc_loss = 0.03688260712742544
Trained batch 57 in epoch 6, gen_loss = 0.8418796422152683, disc_loss = 0.036845666091439536
Trained batch 58 in epoch 6, gen_loss = 0.8392891944464991, disc_loss = 0.03701958820318519
Trained batch 59 in epoch 6, gen_loss = 0.8392356554667155, disc_loss = 0.03725333048496395
Trained batch 60 in epoch 6, gen_loss = 0.8426868681047783, disc_loss = 0.0385714389124244
Trained batch 61 in epoch 6, gen_loss = 0.8387178384488628, disc_loss = 0.039392068944571
Trained batch 62 in epoch 6, gen_loss = 0.8400808052411155, disc_loss = 0.03976681280792469
Trained batch 63 in epoch 6, gen_loss = 0.8390028448775411, disc_loss = 0.04013663107616594
Trained batch 64 in epoch 6, gen_loss = 0.8382666239371667, disc_loss = 0.04013453643912306
Trained batch 65 in epoch 6, gen_loss = 0.8362836774551508, disc_loss = 0.040410416052592074
Trained batch 66 in epoch 6, gen_loss = 0.8357375424299667, disc_loss = 0.040741908370948106
Trained batch 67 in epoch 6, gen_loss = 0.8390920170966316, disc_loss = 0.040944552069584673
Trained batch 68 in epoch 6, gen_loss = 0.840536369793657, disc_loss = 0.04150280995510411
Trained batch 69 in epoch 6, gen_loss = 0.8367275868143355, disc_loss = 0.04277270108328334
Trained batch 70 in epoch 6, gen_loss = 0.8377232392069319, disc_loss = 0.042452247701847634
Trained batch 71 in epoch 6, gen_loss = 0.8387217869361242, disc_loss = 0.04226878908229992
Trained batch 72 in epoch 6, gen_loss = 0.8349974669822274, disc_loss = 0.04287622462677425
Trained batch 73 in epoch 6, gen_loss = 0.8381568861974252, disc_loss = 0.04300102371898656
Trained batch 74 in epoch 6, gen_loss = 0.8373402015368143, disc_loss = 0.04291218565776944
Trained batch 75 in epoch 6, gen_loss = 0.8361594104453137, disc_loss = 0.042656959788138535
Trained batch 76 in epoch 6, gen_loss = 0.8376832256069431, disc_loss = 0.042993419084020636
Trained batch 77 in epoch 6, gen_loss = 0.838714449833601, disc_loss = 0.042569576732766554
Trained batch 78 in epoch 6, gen_loss = 0.8411179962037485, disc_loss = 0.04228157761707148
Trained batch 79 in epoch 6, gen_loss = 0.842721325904131, disc_loss = 0.041959892836166544
Trained batch 80 in epoch 6, gen_loss = 0.8420452225355455, disc_loss = 0.04173931448984845
Trained batch 81 in epoch 6, gen_loss = 0.8425685857854238, disc_loss = 0.041325102997489455
Trained batch 82 in epoch 6, gen_loss = 0.8440823562173958, disc_loss = 0.04108837249700025
Trained batch 83 in epoch 6, gen_loss = 0.840711983186858, disc_loss = 0.042243027998622326
Trained batch 84 in epoch 6, gen_loss = 0.843917398593005, disc_loss = 0.042205055041567366
Trained batch 85 in epoch 6, gen_loss = 0.8455238598723744, disc_loss = 0.04217657189664626
Trained batch 86 in epoch 6, gen_loss = 0.8458670521604603, disc_loss = 0.04194722727647629
Trained batch 87 in epoch 6, gen_loss = 0.8463086262345314, disc_loss = 0.04175987090936608
Trained batch 88 in epoch 6, gen_loss = 0.8460455148407583, disc_loss = 0.04144439392649893
Trained batch 89 in epoch 6, gen_loss = 0.8499558415677813, disc_loss = 0.04224752368301981
Trained batch 90 in epoch 6, gen_loss = 0.8499194363971333, disc_loss = 0.041938665901198165
Trained batch 91 in epoch 6, gen_loss = 0.8498918504818626, disc_loss = 0.041630954638568925
Trained batch 92 in epoch 6, gen_loss = 0.850193896601277, disc_loss = 0.04127020204079247
Trained batch 93 in epoch 6, gen_loss = 0.846781222110099, disc_loss = 0.04192430612710404
Trained batch 94 in epoch 6, gen_loss = 0.8467989350620069, disc_loss = 0.04216731590169825
Trained batch 95 in epoch 6, gen_loss = 0.8462104853242636, disc_loss = 0.0423405119945528
Trained batch 96 in epoch 6, gen_loss = 0.8501933561157935, disc_loss = 0.042427486322397734
Trained batch 97 in epoch 6, gen_loss = 0.8505473532238785, disc_loss = 0.042123303097691765
Trained batch 98 in epoch 6, gen_loss = 0.8516483216574697, disc_loss = 0.041777460003328146
Trained batch 99 in epoch 6, gen_loss = 0.8525538510084152, disc_loss = 0.04154262200463563
Trained batch 100 in epoch 6, gen_loss = 0.851531179234533, disc_loss = 0.041383877917570935
Trained batch 101 in epoch 6, gen_loss = 0.8508754857614929, disc_loss = 0.041090309679252555
Trained batch 102 in epoch 6, gen_loss = 0.8523507228175413, disc_loss = 0.04084780590283205
Trained batch 103 in epoch 6, gen_loss = 0.8542932541324542, disc_loss = 0.04088132322067395
Trained batch 104 in epoch 6, gen_loss = 0.8537598411242168, disc_loss = 0.040669703080008425
Trained batch 105 in epoch 6, gen_loss = 0.8518412759843862, disc_loss = 0.04101564877947687
Trained batch 106 in epoch 6, gen_loss = 0.8526565555100128, disc_loss = 0.04076263195808942
Trained batch 107 in epoch 6, gen_loss = 0.8561143847527327, disc_loss = 0.04089929852031033
Trained batch 108 in epoch 6, gen_loss = 0.8585751269935468, disc_loss = 0.04079864844423505
Trained batch 109 in epoch 6, gen_loss = 0.8569121198220686, disc_loss = 0.0412804716732353
Trained batch 110 in epoch 6, gen_loss = 0.8570207915864549, disc_loss = 0.04160692677455577
Trained batch 111 in epoch 6, gen_loss = 0.8588468549507005, disc_loss = 0.042894016223726794
Trained batch 112 in epoch 6, gen_loss = 0.860360166667837, disc_loss = 0.044605895683202335
Trained batch 113 in epoch 6, gen_loss = 0.8610815625441702, disc_loss = 0.04483535173839252
Trained batch 114 in epoch 6, gen_loss = 0.8612416085989579, disc_loss = 0.044687338679543005
Trained batch 115 in epoch 6, gen_loss = 0.8610509171568114, disc_loss = 0.0444962261124225
Trained batch 116 in epoch 6, gen_loss = 0.8599410016312559, disc_loss = 0.04467180258650173
Trained batch 117 in epoch 6, gen_loss = 0.8599691633450783, disc_loss = 0.04442487559596992
Trained batch 118 in epoch 6, gen_loss = 0.8598535105961711, disc_loss = 0.0443146114253259
Trained batch 119 in epoch 6, gen_loss = 0.8581749255458514, disc_loss = 0.044548795562392725
Trained batch 120 in epoch 6, gen_loss = 0.8588430226341752, disc_loss = 0.04506759783099136
Trained batch 121 in epoch 6, gen_loss = 0.8591532848897527, disc_loss = 0.04500210984823767
Trained batch 122 in epoch 6, gen_loss = 0.8589191209009992, disc_loss = 0.044843835775111994
Trained batch 123 in epoch 6, gen_loss = 0.8590313253864166, disc_loss = 0.044673528556051036
Trained batch 124 in epoch 6, gen_loss = 0.859292818069458, disc_loss = 0.04440752652660012
Trained batch 125 in epoch 6, gen_loss = 0.8571870502025362, disc_loss = 0.044764757840081104
Trained batch 126 in epoch 6, gen_loss = 0.858248292461155, disc_loss = 0.044927301343647745
Trained batch 127 in epoch 6, gen_loss = 0.8582643731497228, disc_loss = 0.044763364352547796
Trained batch 128 in epoch 6, gen_loss = 0.8576591338298117, disc_loss = 0.04461335912419036
Trained batch 129 in epoch 6, gen_loss = 0.8576340400255643, disc_loss = 0.04433161509223282
Trained batch 130 in epoch 6, gen_loss = 0.8570854827647901, disc_loss = 0.0441156011963448
Trained batch 131 in epoch 6, gen_loss = 0.8576960378524029, disc_loss = 0.04383483726291381
Trained batch 132 in epoch 6, gen_loss = 0.857107010550965, disc_loss = 0.04361189824451966
Trained batch 133 in epoch 6, gen_loss = 0.8565619369940971, disc_loss = 0.04400039148350149
Trained batch 134 in epoch 6, gen_loss = 0.8561128819430316, disc_loss = 0.04378321930697119
Trained batch 135 in epoch 6, gen_loss = 0.8559921752004063, disc_loss = 0.04366283508716151
Trained batch 136 in epoch 6, gen_loss = 0.8552192971654182, disc_loss = 0.04349158184575665
Trained batch 137 in epoch 6, gen_loss = 0.8561869648055754, disc_loss = 0.04362897004972657
Trained batch 138 in epoch 6, gen_loss = 0.855870564635709, disc_loss = 0.04337902175155368
Trained batch 139 in epoch 6, gen_loss = 0.8543929291622979, disc_loss = 0.04344071132197444
Trained batch 140 in epoch 6, gen_loss = 0.854724332373193, disc_loss = 0.0432682323850797
Trained batch 141 in epoch 6, gen_loss = 0.8570570194385421, disc_loss = 0.0434331881426747
Trained batch 142 in epoch 6, gen_loss = 0.8557552178422888, disc_loss = 0.04349155915197688
Trained batch 143 in epoch 6, gen_loss = 0.8550719887846046, disc_loss = 0.0434449920786493
Trained batch 144 in epoch 6, gen_loss = 0.8542979022552227, disc_loss = 0.043268522488531365
Trained batch 145 in epoch 6, gen_loss = 0.8546385434392381, disc_loss = 0.043056798036758825
Trained batch 146 in epoch 6, gen_loss = 0.855279067746636, disc_loss = 0.04281427677353324
Trained batch 147 in epoch 6, gen_loss = 0.8541028342536978, disc_loss = 0.04280192474519985
Trained batch 148 in epoch 6, gen_loss = 0.8549326526238614, disc_loss = 0.04270000496079158
Trained batch 149 in epoch 6, gen_loss = 0.8544750515619913, disc_loss = 0.042881043953821064
Trained batch 150 in epoch 6, gen_loss = 0.8525518522357309, disc_loss = 0.04373233662054732
Trained batch 151 in epoch 6, gen_loss = 0.8516346863225887, disc_loss = 0.04373277363820786
Trained batch 152 in epoch 6, gen_loss = 0.852854510927512, disc_loss = 0.04391306203187389
Trained batch 153 in epoch 6, gen_loss = 0.8528424683329346, disc_loss = 0.043837873582643544
Trained batch 154 in epoch 6, gen_loss = 0.8519299957060045, disc_loss = 0.043689675776348
Trained batch 155 in epoch 6, gen_loss = 0.8510418247718078, disc_loss = 0.043571083761680014
Trained batch 156 in epoch 6, gen_loss = 0.8515688192312885, disc_loss = 0.04387495365693785
Trained batch 157 in epoch 6, gen_loss = 0.8500686948057972, disc_loss = 0.04408821395504041
Trained batch 158 in epoch 6, gen_loss = 0.8499073573628312, disc_loss = 0.04388424822381176
Trained batch 159 in epoch 6, gen_loss = 0.8496399734169244, disc_loss = 0.043726849512313495
Trained batch 160 in epoch 6, gen_loss = 0.8500850078482065, disc_loss = 0.04350701541067188
Trained batch 161 in epoch 6, gen_loss = 0.8497820478162648, disc_loss = 0.043301910952446454
Trained batch 162 in epoch 6, gen_loss = 0.8520528067109043, disc_loss = 0.043310669127943145
Trained batch 163 in epoch 6, gen_loss = 0.8520052204044853, disc_loss = 0.04311819721251817
Trained batch 164 in epoch 6, gen_loss = 0.8517305659525323, disc_loss = 0.04295257478105751
Trained batch 165 in epoch 6, gen_loss = 0.8513825424464352, disc_loss = 0.04281389136821121
Trained batch 166 in epoch 6, gen_loss = 0.8509382784009694, disc_loss = 0.04295251079316357
Trained batch 167 in epoch 6, gen_loss = 0.8513904167782693, disc_loss = 0.042726401663717946
Trained batch 168 in epoch 6, gen_loss = 0.851616248929289, disc_loss = 0.042526557272818136
Trained batch 169 in epoch 6, gen_loss = 0.8509030636619119, disc_loss = 0.04244945588631227
Trained batch 170 in epoch 6, gen_loss = 0.8501791999354, disc_loss = 0.04242430791008281
Trained batch 171 in epoch 6, gen_loss = 0.8508739357077798, disc_loss = 0.04235916823246191
Trained batch 172 in epoch 6, gen_loss = 0.8517873586946829, disc_loss = 0.042275250509833495
Trained batch 173 in epoch 6, gen_loss = 0.8506744144291714, disc_loss = 0.04228914095806065
Trained batch 174 in epoch 6, gen_loss = 0.8493059386525835, disc_loss = 0.04238156600988337
Trained batch 175 in epoch 6, gen_loss = 0.8499656888571653, disc_loss = 0.04248773365080441
Trained batch 176 in epoch 6, gen_loss = 0.8513850263283078, disc_loss = 0.042438707395988165
Trained batch 177 in epoch 6, gen_loss = 0.8511671926198381, disc_loss = 0.04227696423251391
Trained batch 178 in epoch 6, gen_loss = 0.850539659654628, disc_loss = 0.04215708462646304
Trained batch 179 in epoch 6, gen_loss = 0.8503448317448298, disc_loss = 0.04197517772360394
Trained batch 180 in epoch 6, gen_loss = 0.8506861365302492, disc_loss = 0.041787595279741185
Trained batch 181 in epoch 6, gen_loss = 0.8498659163385958, disc_loss = 0.04168428671239251
Trained batch 182 in epoch 6, gen_loss = 0.8499031063637447, disc_loss = 0.04155706545297321
Trained batch 183 in epoch 6, gen_loss = 0.8490608609888864, disc_loss = 0.04163053970146195
Trained batch 184 in epoch 6, gen_loss = 0.8494143843650818, disc_loss = 0.04178844225416715
Trained batch 185 in epoch 6, gen_loss = 0.8488411759176562, disc_loss = 0.041744335426858833
Trained batch 186 in epoch 6, gen_loss = 0.8495399540758388, disc_loss = 0.04158122571842635
Trained batch 187 in epoch 6, gen_loss = 0.8491798515649552, disc_loss = 0.04147977471361531
Trained batch 188 in epoch 6, gen_loss = 0.8486996551670095, disc_loss = 0.04135834041578823
Trained batch 189 in epoch 6, gen_loss = 0.8496520516119506, disc_loss = 0.041226311442197155
Trained batch 190 in epoch 6, gen_loss = 0.8502875875428085, disc_loss = 0.041070926068984555
Trained batch 191 in epoch 6, gen_loss = 0.8498378545045853, disc_loss = 0.04093649827458042
Trained batch 192 in epoch 6, gen_loss = 0.8505698417752517, disc_loss = 0.04075128502101478
Trained batch 193 in epoch 6, gen_loss = 0.8506437819643119, disc_loss = 0.0406345328335295
Trained batch 194 in epoch 6, gen_loss = 0.8507392684618632, disc_loss = 0.04047406282371435
Trained batch 195 in epoch 6, gen_loss = 0.8503906504840267, disc_loss = 0.0403628074183908
Trained batch 196 in epoch 6, gen_loss = 0.8507031277956696, disc_loss = 0.04020679003658331
Trained batch 197 in epoch 6, gen_loss = 0.8508345331206466, disc_loss = 0.04009093955685996
Trained batch 198 in epoch 6, gen_loss = 0.8497883045493658, disc_loss = 0.040361232961991324
Trained batch 199 in epoch 6, gen_loss = 0.8508818870782853, disc_loss = 0.04031033933162689
Trained batch 200 in epoch 6, gen_loss = 0.8508616341880305, disc_loss = 0.04019825725783756
Trained batch 201 in epoch 6, gen_loss = 0.8494935059311366, disc_loss = 0.04056556071016458
Trained batch 202 in epoch 6, gen_loss = 0.8503205235955751, disc_loss = 0.04081053292296203
Trained batch 203 in epoch 6, gen_loss = 0.8507622383973178, disc_loss = 0.040673817539879795
Trained batch 204 in epoch 6, gen_loss = 0.8490241949151202, disc_loss = 0.04161470959008467
Trained batch 205 in epoch 6, gen_loss = 0.8504413062507666, disc_loss = 0.04309897939900605
Trained batch 206 in epoch 6, gen_loss = 0.8500504441883253, disc_loss = 0.042988777291119676
Trained batch 207 in epoch 6, gen_loss = 0.8488739723196397, disc_loss = 0.04320817220902357
Trained batch 208 in epoch 6, gen_loss = 0.8483340395124335, disc_loss = 0.04345330366481577
Trained batch 209 in epoch 6, gen_loss = 0.8478129358518691, disc_loss = 0.04333851347633061
Trained batch 210 in epoch 6, gen_loss = 0.8470729403021211, disc_loss = 0.04328994350110609
Trained batch 211 in epoch 6, gen_loss = 0.8467764618261805, disc_loss = 0.04322441043068637
Trained batch 212 in epoch 6, gen_loss = 0.8472135279659934, disc_loss = 0.04320407873500541
Trained batch 213 in epoch 6, gen_loss = 0.846154443014448, disc_loss = 0.04334042863224015
Trained batch 214 in epoch 6, gen_loss = 0.8456899479378102, disc_loss = 0.04333305406968954
Trained batch 215 in epoch 6, gen_loss = 0.84646200278291, disc_loss = 0.043685473945785175
Trained batch 216 in epoch 6, gen_loss = 0.8456891503202201, disc_loss = 0.043732393477197894
Trained batch 217 in epoch 6, gen_loss = 0.8452776424381712, disc_loss = 0.043624697317189855
Trained batch 218 in epoch 6, gen_loss = 0.8453832168012994, disc_loss = 0.04346383561605596
Trained batch 219 in epoch 6, gen_loss = 0.8450119896368546, disc_loss = 0.04344073233871975
Trained batch 220 in epoch 6, gen_loss = 0.8443255144007066, disc_loss = 0.04350189055101229
Trained batch 221 in epoch 6, gen_loss = 0.8434650173058381, disc_loss = 0.04352583916992083
Trained batch 222 in epoch 6, gen_loss = 0.8435182325508562, disc_loss = 0.04360353425061623
Trained batch 223 in epoch 6, gen_loss = 0.8429162438426699, disc_loss = 0.04369884017173068
Trained batch 224 in epoch 6, gen_loss = 0.8421690188513862, disc_loss = 0.043710045479238034
Trained batch 225 in epoch 6, gen_loss = 0.8427334380360831, disc_loss = 0.04363078097771622
Trained batch 226 in epoch 6, gen_loss = 0.8423665544009944, disc_loss = 0.04363794790145978
Trained batch 227 in epoch 6, gen_loss = 0.8418090670255193, disc_loss = 0.04360445923368005
Trained batch 228 in epoch 6, gen_loss = 0.842342695034227, disc_loss = 0.04344502940172061
Trained batch 229 in epoch 6, gen_loss = 0.8437652823717697, disc_loss = 0.04359907491294586
Trained batch 230 in epoch 6, gen_loss = 0.8441697294577891, disc_loss = 0.043503166289266315
Trained batch 231 in epoch 6, gen_loss = 0.8443690212122326, disc_loss = 0.043392760289736605
Trained batch 232 in epoch 6, gen_loss = 0.8444763102244921, disc_loss = 0.043295175392708295
Trained batch 233 in epoch 6, gen_loss = 0.8454537404398633, disc_loss = 0.04322021910283937
Trained batch 234 in epoch 6, gen_loss = 0.8459569309620147, disc_loss = 0.04320616513252892
Trained batch 235 in epoch 6, gen_loss = 0.8460244943024748, disc_loss = 0.043112090966364335
Trained batch 236 in epoch 6, gen_loss = 0.8457982193065595, disc_loss = 0.043051140284645156
Trained batch 237 in epoch 6, gen_loss = 0.8458468232836042, disc_loss = 0.042943435028477125
Trained batch 238 in epoch 6, gen_loss = 0.8463647250849832, disc_loss = 0.04281571582661139
Trained batch 239 in epoch 6, gen_loss = 0.8466793561975161, disc_loss = 0.04273180221595491
Trained batch 240 in epoch 6, gen_loss = 0.8468663544081059, disc_loss = 0.042589073927292435
Trained batch 241 in epoch 6, gen_loss = 0.8474045871210493, disc_loss = 0.04245734795127526
Trained batch 242 in epoch 6, gen_loss = 0.847167943976053, disc_loss = 0.04234143882346006
Trained batch 243 in epoch 6, gen_loss = 0.8462388429973946, disc_loss = 0.042362954032408896
Trained batch 244 in epoch 6, gen_loss = 0.8454756111514812, disc_loss = 0.04243871854732231
Trained batch 245 in epoch 6, gen_loss = 0.8467324082928944, disc_loss = 0.04263773202381241
Trained batch 246 in epoch 6, gen_loss = 0.8471031553349514, disc_loss = 0.042508258563485224
Trained batch 247 in epoch 6, gen_loss = 0.8461030923551128, disc_loss = 0.04260787186813691
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.7843548655509949, disc_loss = 0.02687908336520195
Trained batch 1 in epoch 7, gen_loss = 0.8435678780078888, disc_loss = 0.02067511435598135
Trained batch 2 in epoch 7, gen_loss = 0.8884211778640747, disc_loss = 0.019054705897967022
Trained batch 3 in epoch 7, gen_loss = 0.8835508674383163, disc_loss = 0.015752226347103715
Trained batch 4 in epoch 7, gen_loss = 0.8865645051002502, disc_loss = 0.014481522142887115
Trained batch 5 in epoch 7, gen_loss = 0.8573180735111237, disc_loss = 0.021148808300495148
Trained batch 6 in epoch 7, gen_loss = 0.8778300711086818, disc_loss = 0.019997030230505124
Trained batch 7 in epoch 7, gen_loss = 0.9124936237931252, disc_loss = 0.022323456360027194
Trained batch 8 in epoch 7, gen_loss = 0.90624424484041, disc_loss = 0.021427197174893484
Trained batch 9 in epoch 7, gen_loss = 0.8849747598171234, disc_loss = 0.02375197485089302
Trained batch 10 in epoch 7, gen_loss = 0.8954953442920338, disc_loss = 0.02368333376944065
Trained batch 11 in epoch 7, gen_loss = 0.9053687999645869, disc_loss = 0.02299631154164672
Trained batch 12 in epoch 7, gen_loss = 0.9015307884949905, disc_loss = 0.021862870798661158
Trained batch 13 in epoch 7, gen_loss = 0.9021686656134469, disc_loss = 0.02089685308081763
Trained batch 14 in epoch 7, gen_loss = 0.8934831142425537, disc_loss = 0.021041493117809295
Trained batch 15 in epoch 7, gen_loss = 0.8917181268334389, disc_loss = 0.022259781137108803
Trained batch 16 in epoch 7, gen_loss = 0.8814292795517865, disc_loss = 0.02276476680794183
Trained batch 17 in epoch 7, gen_loss = 0.8800242013401456, disc_loss = 0.022463264254232247
Trained batch 18 in epoch 7, gen_loss = 0.8761819695171557, disc_loss = 0.022403509012962643
Trained batch 19 in epoch 7, gen_loss = 0.8748452872037887, disc_loss = 0.028137901239097117
Trained batch 20 in epoch 7, gen_loss = 0.8616395592689514, disc_loss = 0.0326049251570588
Trained batch 21 in epoch 7, gen_loss = 0.8724609477953478, disc_loss = 0.03545425104146654
Trained batch 22 in epoch 7, gen_loss = 0.86698986136395, disc_loss = 0.03748705869783526
Trained batch 23 in epoch 7, gen_loss = 0.8635405749082565, disc_loss = 0.040153014628837504
Trained batch 24 in epoch 7, gen_loss = 0.8600660228729248, disc_loss = 0.04572937294840813
Trained batch 25 in epoch 7, gen_loss = 0.8466474597270672, disc_loss = 0.053273909796889014
Trained batch 26 in epoch 7, gen_loss = 0.8532827827665541, disc_loss = 0.05468463111254904
Trained batch 27 in epoch 7, gen_loss = 0.8538368940353394, disc_loss = 0.053954298341912885
Trained batch 28 in epoch 7, gen_loss = 0.8473848885503309, disc_loss = 0.053499536653017175
Trained batch 29 in epoch 7, gen_loss = 0.8458279550075531, disc_loss = 0.052808513616522154
Trained batch 30 in epoch 7, gen_loss = 0.8470464502611468, disc_loss = 0.05149422640040997
Trained batch 31 in epoch 7, gen_loss = 0.8449410554021597, disc_loss = 0.05032241059234366
Trained batch 32 in epoch 7, gen_loss = 0.8390342195828756, disc_loss = 0.050681893516219025
Trained batch 33 in epoch 7, gen_loss = 0.8406440002076766, disc_loss = 0.05241034021053244
Trained batch 34 in epoch 7, gen_loss = 0.8367577978542873, disc_loss = 0.051748778830681526
Trained batch 35 in epoch 7, gen_loss = 0.8297082649336921, disc_loss = 0.05439080365209116
Trained batch 36 in epoch 7, gen_loss = 0.827546868775342, disc_loss = 0.05376835917500225
Trained batch 37 in epoch 7, gen_loss = 0.8275510856979772, disc_loss = 0.052567202573348036
Trained batch 38 in epoch 7, gen_loss = 0.8266711754676623, disc_loss = 0.05213177039359625
Trained batch 39 in epoch 7, gen_loss = 0.8276695370674133, disc_loss = 0.051187216443940996
Trained batch 40 in epoch 7, gen_loss = 0.829836352569301, disc_loss = 0.05050543800178098
Trained batch 41 in epoch 7, gen_loss = 0.8277040592261723, disc_loss = 0.05000232723319814
Trained batch 42 in epoch 7, gen_loss = 0.8317764872728393, disc_loss = 0.049143905751407146
Trained batch 43 in epoch 7, gen_loss = 0.8299477276476946, disc_loss = 0.04851128222336146
Trained batch 44 in epoch 7, gen_loss = 0.8305350608295865, disc_loss = 0.04817672796133492
Trained batch 45 in epoch 7, gen_loss = 0.827919857657474, disc_loss = 0.048193447231112616
Trained batch 46 in epoch 7, gen_loss = 0.8294143740167009, disc_loss = 0.047416126434790325
Trained batch 47 in epoch 7, gen_loss = 0.8284145010014375, disc_loss = 0.04680495650973171
Trained batch 48 in epoch 7, gen_loss = 0.8337479622996583, disc_loss = 0.04757695268763571
Trained batch 49 in epoch 7, gen_loss = 0.8319860696792603, disc_loss = 0.047225598208606244
Trained batch 50 in epoch 7, gen_loss = 0.8297442291297165, disc_loss = 0.04715652234267955
Trained batch 51 in epoch 7, gen_loss = 0.8325557238780535, disc_loss = 0.04644727635268982
Trained batch 52 in epoch 7, gen_loss = 0.8340453550500689, disc_loss = 0.047224184392758134
Trained batch 53 in epoch 7, gen_loss = 0.8315817636472208, disc_loss = 0.04683240237473338
Trained batch 54 in epoch 7, gen_loss = 0.8320785663344643, disc_loss = 0.0467354585162618
Trained batch 55 in epoch 7, gen_loss = 0.835455388895103, disc_loss = 0.04608916963583657
Trained batch 56 in epoch 7, gen_loss = 0.8365555876179745, disc_loss = 0.04540536456267562
Trained batch 57 in epoch 7, gen_loss = 0.8383364163596054, disc_loss = 0.04479808830816684
Trained batch 58 in epoch 7, gen_loss = 0.8399534791202868, disc_loss = 0.044631226351326804
Trained batch 59 in epoch 7, gen_loss = 0.8360689441363017, disc_loss = 0.04525115789535145
Trained batch 60 in epoch 7, gen_loss = 0.8377642035484314, disc_loss = 0.045287980056810576
Trained batch 61 in epoch 7, gen_loss = 0.8372975539776587, disc_loss = 0.044778443317139344
Trained batch 62 in epoch 7, gen_loss = 0.8336982736511837, disc_loss = 0.04551172722131014
Trained batch 63 in epoch 7, gen_loss = 0.8339189710095525, disc_loss = 0.045802186519722454
Trained batch 64 in epoch 7, gen_loss = 0.8353925053889935, disc_loss = 0.045647962377048455
Trained batch 65 in epoch 7, gen_loss = 0.834689531362418, disc_loss = 0.04531358186663552
Trained batch 66 in epoch 7, gen_loss = 0.8317962208790566, disc_loss = 0.04577960489567981
Trained batch 67 in epoch 7, gen_loss = 0.8312662375323913, disc_loss = 0.04623968476046096
Trained batch 68 in epoch 7, gen_loss = 0.8335925297460695, disc_loss = 0.046032817075973835
Trained batch 69 in epoch 7, gen_loss = 0.8317043670586177, disc_loss = 0.046013079410684964
Trained batch 70 in epoch 7, gen_loss = 0.8331675554665041, disc_loss = 0.045629436320717066
Trained batch 71 in epoch 7, gen_loss = 0.8311922260456615, disc_loss = 0.04561134385100255
Trained batch 72 in epoch 7, gen_loss = 0.8308340613156149, disc_loss = 0.045238848073943835
Trained batch 73 in epoch 7, gen_loss = 0.8334391076822538, disc_loss = 0.04516996182753025
Trained batch 74 in epoch 7, gen_loss = 0.833429102897644, disc_loss = 0.04477905299514532
Trained batch 75 in epoch 7, gen_loss = 0.8329978820524717, disc_loss = 0.04449095144426744
Trained batch 76 in epoch 7, gen_loss = 0.8315844876425607, disc_loss = 0.044289400353543944
Trained batch 77 in epoch 7, gen_loss = 0.8329976522005521, disc_loss = 0.04410294277402453
Trained batch 78 in epoch 7, gen_loss = 0.8370162988010841, disc_loss = 0.043993474385123466
Trained batch 79 in epoch 7, gen_loss = 0.8355391852557659, disc_loss = 0.04397201753454283
Trained batch 80 in epoch 7, gen_loss = 0.8361336036964699, disc_loss = 0.04400116353537197
Trained batch 81 in epoch 7, gen_loss = 0.8345448694578032, disc_loss = 0.04421969849570859
Trained batch 82 in epoch 7, gen_loss = 0.833901188459741, disc_loss = 0.04393040060054466
Trained batch 83 in epoch 7, gen_loss = 0.8333231196517036, disc_loss = 0.04364616054642413
Trained batch 84 in epoch 7, gen_loss = 0.8335552334785461, disc_loss = 0.04335224079516004
Trained batch 85 in epoch 7, gen_loss = 0.8328009220056756, disc_loss = 0.0433756310037922
Trained batch 86 in epoch 7, gen_loss = 0.8326024755664255, disc_loss = 0.04303085980615739
Trained batch 87 in epoch 7, gen_loss = 0.8340768685395067, disc_loss = 0.042641377954913136
Trained batch 88 in epoch 7, gen_loss = 0.8362456044454253, disc_loss = 0.042651825437971046
Trained batch 89 in epoch 7, gen_loss = 0.8372559209664663, disc_loss = 0.042417054219792284
Trained batch 90 in epoch 7, gen_loss = 0.8360436702822591, disc_loss = 0.042336180611708005
Trained batch 91 in epoch 7, gen_loss = 0.8377064764499664, disc_loss = 0.04204584999293413
Trained batch 92 in epoch 7, gen_loss = 0.8398963738513249, disc_loss = 0.042130273566531234
Trained batch 93 in epoch 7, gen_loss = 0.8386937582746465, disc_loss = 0.042206369429588955
Trained batch 94 in epoch 7, gen_loss = 0.8399433631646006, disc_loss = 0.04194445638476234
Trained batch 95 in epoch 7, gen_loss = 0.8436045789470276, disc_loss = 0.04181379783161295
Trained batch 96 in epoch 7, gen_loss = 0.8442956092431373, disc_loss = 0.0414967529149246
Trained batch 97 in epoch 7, gen_loss = 0.8435085239459057, disc_loss = 0.041267306097231955
Trained batch 98 in epoch 7, gen_loss = 0.8450445881997696, disc_loss = 0.04120097944343632
Trained batch 99 in epoch 7, gen_loss = 0.8452448761463165, disc_loss = 0.040992544004693626
Trained batch 100 in epoch 7, gen_loss = 0.8460643297374839, disc_loss = 0.04073247170573709
Trained batch 101 in epoch 7, gen_loss = 0.8472067929950415, disc_loss = 0.04046875590860259
Trained batch 102 in epoch 7, gen_loss = 0.8509502648149879, disc_loss = 0.040438610933793404
Trained batch 103 in epoch 7, gen_loss = 0.851110445192227, disc_loss = 0.04021202778228773
Trained batch 104 in epoch 7, gen_loss = 0.8503807181403751, disc_loss = 0.04015562422573567
Trained batch 105 in epoch 7, gen_loss = 0.8541411251392005, disc_loss = 0.04031917929016757
Trained batch 106 in epoch 7, gen_loss = 0.8565357199339109, disc_loss = 0.04049917503703977
Trained batch 107 in epoch 7, gen_loss = 0.8542280660735236, disc_loss = 0.04123464066328274
Trained batch 108 in epoch 7, gen_loss = 0.8536330352135755, disc_loss = 0.041041300879842646
Trained batch 109 in epoch 7, gen_loss = 0.8547939706932415, disc_loss = 0.04088386437770995
Trained batch 110 in epoch 7, gen_loss = 0.8569630389814978, disc_loss = 0.04080462742697548
Trained batch 111 in epoch 7, gen_loss = 0.8579319449407714, disc_loss = 0.04054003613003131
Trained batch 112 in epoch 7, gen_loss = 0.8564531971923018, disc_loss = 0.040672151075132126
Trained batch 113 in epoch 7, gen_loss = 0.8577412638747901, disc_loss = 0.040540064390944805
Trained batch 114 in epoch 7, gen_loss = 0.8581498498501985, disc_loss = 0.040386403465400574
Trained batch 115 in epoch 7, gen_loss = 0.8595694920112347, disc_loss = 0.04021388761185367
Trained batch 116 in epoch 7, gen_loss = 0.8592878870474987, disc_loss = 0.04002933694511397
Trained batch 117 in epoch 7, gen_loss = 0.8599765012829991, disc_loss = 0.03982870550668341
Trained batch 118 in epoch 7, gen_loss = 0.8605800726834465, disc_loss = 0.03958391953854501
Trained batch 119 in epoch 7, gen_loss = 0.8611223181088765, disc_loss = 0.03931471919252848
Trained batch 120 in epoch 7, gen_loss = 0.8631469001454756, disc_loss = 0.0391190539514415
Trained batch 121 in epoch 7, gen_loss = 0.864802957558241, disc_loss = 0.038917051517542024
Trained batch 122 in epoch 7, gen_loss = 0.8633742642596485, disc_loss = 0.03892937318868632
Trained batch 123 in epoch 7, gen_loss = 0.8630020892427813, disc_loss = 0.038760942553410366
Trained batch 124 in epoch 7, gen_loss = 0.8640884923934936, disc_loss = 0.038905502256006
Trained batch 125 in epoch 7, gen_loss = 0.8636806493713742, disc_loss = 0.038711030912097724
Trained batch 126 in epoch 7, gen_loss = 0.8639839437064223, disc_loss = 0.03845820533419688
Trained batch 127 in epoch 7, gen_loss = 0.8639204618521035, disc_loss = 0.03822739548195386
Trained batch 128 in epoch 7, gen_loss = 0.8644838887591695, disc_loss = 0.037995586965897284
Trained batch 129 in epoch 7, gen_loss = 0.8658298950928908, disc_loss = 0.03782659789117483
Trained batch 130 in epoch 7, gen_loss = 0.8656743455479163, disc_loss = 0.03764326035805786
Trained batch 131 in epoch 7, gen_loss = 0.8670596489400575, disc_loss = 0.03750465710111188
Trained batch 132 in epoch 7, gen_loss = 0.8670045522818888, disc_loss = 0.03733179006809579
Trained batch 133 in epoch 7, gen_loss = 0.8671321935618101, disc_loss = 0.03717788338049579
Trained batch 134 in epoch 7, gen_loss = 0.8700443598959181, disc_loss = 0.03723273739494659
Trained batch 135 in epoch 7, gen_loss = 0.8704732156851712, disc_loss = 0.03702080933897592
Trained batch 136 in epoch 7, gen_loss = 0.872169556408903, disc_loss = 0.03688931881864793
Trained batch 137 in epoch 7, gen_loss = 0.8715504952099012, disc_loss = 0.03674203832971229
Trained batch 138 in epoch 7, gen_loss = 0.8713350501849497, disc_loss = 0.03656009598735639
Trained batch 139 in epoch 7, gen_loss = 0.8709782004356384, disc_loss = 0.036361626449174116
Trained batch 140 in epoch 7, gen_loss = 0.8711833822811749, disc_loss = 0.03615607095367097
Trained batch 141 in epoch 7, gen_loss = 0.8723461875613306, disc_loss = 0.036028055972616435
Trained batch 142 in epoch 7, gen_loss = 0.872920787834621, disc_loss = 0.035824262074657255
Trained batch 143 in epoch 7, gen_loss = 0.8732012949056096, disc_loss = 0.035647832879072264
Trained batch 144 in epoch 7, gen_loss = 0.8731157138429839, disc_loss = 0.03545346347743581
Trained batch 145 in epoch 7, gen_loss = 0.873301479506166, disc_loss = 0.03525185191442501
Trained batch 146 in epoch 7, gen_loss = 0.8727924243933489, disc_loss = 0.03508734964721259
Trained batch 147 in epoch 7, gen_loss = 0.873287250464027, disc_loss = 0.034897467606021346
Trained batch 148 in epoch 7, gen_loss = 0.8732345864276758, disc_loss = 0.03470959234045156
Trained batch 149 in epoch 7, gen_loss = 0.8728176963329315, disc_loss = 0.03464415172425409
Trained batch 150 in epoch 7, gen_loss = 0.8735980371765742, disc_loss = 0.034484475736956524
Trained batch 151 in epoch 7, gen_loss = 0.8735614999344474, disc_loss = 0.03431967250990534
Trained batch 152 in epoch 7, gen_loss = 0.8728364706039429, disc_loss = 0.03420724671979258
Trained batch 153 in epoch 7, gen_loss = 0.8734802228289765, disc_loss = 0.034016099453044985
Trained batch 154 in epoch 7, gen_loss = 0.8751950360113575, disc_loss = 0.034122670246588604
Trained batch 155 in epoch 7, gen_loss = 0.8759032182204418, disc_loss = 0.03396110451266838
Trained batch 156 in epoch 7, gen_loss = 0.8756707443553171, disc_loss = 0.03382845860342406
Trained batch 157 in epoch 7, gen_loss = 0.8751246419888509, disc_loss = 0.03368510738239164
Trained batch 158 in epoch 7, gen_loss = 0.8753826768143372, disc_loss = 0.03352443013726821
Trained batch 159 in epoch 7, gen_loss = 0.8756896648555994, disc_loss = 0.03334897835447918
Trained batch 160 in epoch 7, gen_loss = 0.8752285934383084, disc_loss = 0.03318524801154962
Trained batch 161 in epoch 7, gen_loss = 0.8754007569801661, disc_loss = 0.03302772874644969
Trained batch 162 in epoch 7, gen_loss = 0.8748658687059133, disc_loss = 0.0329859613532349
Trained batch 163 in epoch 7, gen_loss = 0.8746928976076406, disc_loss = 0.03286580653668086
Trained batch 164 in epoch 7, gen_loss = 0.8739691907709295, disc_loss = 0.032754253977063025
Trained batch 165 in epoch 7, gen_loss = 0.8742852372577391, disc_loss = 0.03280619657261813
Trained batch 166 in epoch 7, gen_loss = 0.876799991387807, disc_loss = 0.03290438225693599
Trained batch 167 in epoch 7, gen_loss = 0.8765162552396456, disc_loss = 0.032781713911043925
Trained batch 168 in epoch 7, gen_loss = 0.8764633610403749, disc_loss = 0.03263314246591291
Trained batch 169 in epoch 7, gen_loss = 0.8752466068548315, disc_loss = 0.03265712105340379
Trained batch 170 in epoch 7, gen_loss = 0.8752329370431733, disc_loss = 0.03251130713901499
Trained batch 171 in epoch 7, gen_loss = 0.8759157657623291, disc_loss = 0.03248614196795537
Trained batch 172 in epoch 7, gen_loss = 0.8759206092426542, disc_loss = 0.03234676982819862
Trained batch 173 in epoch 7, gen_loss = 0.8758536762204664, disc_loss = 0.0322065433947605
Trained batch 174 in epoch 7, gen_loss = 0.8752974094663347, disc_loss = 0.032078185086803775
Trained batch 175 in epoch 7, gen_loss = 0.8751311278478666, disc_loss = 0.03192699287319556
Trained batch 176 in epoch 7, gen_loss = 0.8748051433239953, disc_loss = 0.031795036537036046
Trained batch 177 in epoch 7, gen_loss = 0.8749989411804113, disc_loss = 0.0316449471597633
Trained batch 178 in epoch 7, gen_loss = 0.874804050562768, disc_loss = 0.03155774871074704
Trained batch 179 in epoch 7, gen_loss = 0.87438728345765, disc_loss = 0.03144259222317487
Trained batch 180 in epoch 7, gen_loss = 0.8741223301676756, disc_loss = 0.0313553959877328
Trained batch 181 in epoch 7, gen_loss = 0.8726122379302979, disc_loss = 0.03146374576909283
Trained batch 182 in epoch 7, gen_loss = 0.8744010260847749, disc_loss = 0.03191532144994765
Trained batch 183 in epoch 7, gen_loss = 0.8743898440962252, disc_loss = 0.03183207250169843
Trained batch 184 in epoch 7, gen_loss = 0.8728953271298795, disc_loss = 0.03201257721646815
Trained batch 185 in epoch 7, gen_loss = 0.8725627471682846, disc_loss = 0.03216356738290239
Trained batch 186 in epoch 7, gen_loss = 0.8739227384806955, disc_loss = 0.03229198706670002
Trained batch 187 in epoch 7, gen_loss = 0.8752099919192334, disc_loss = 0.03228441001896925
Trained batch 188 in epoch 7, gen_loss = 0.8752926332609994, disc_loss = 0.03227536563845302
Trained batch 189 in epoch 7, gen_loss = 0.8758873465814089, disc_loss = 0.03213893966014056
Trained batch 190 in epoch 7, gen_loss = 0.8755622755794625, disc_loss = 0.03206094633056465
Trained batch 191 in epoch 7, gen_loss = 0.8752088143179814, disc_loss = 0.031992277205669474
Trained batch 192 in epoch 7, gen_loss = 0.8752171072935193, disc_loss = 0.03193071916689758
Trained batch 193 in epoch 7, gen_loss = 0.8752882253263414, disc_loss = 0.031786824494945944
Trained batch 194 in epoch 7, gen_loss = 0.8753796024200243, disc_loss = 0.03165499815383019
Trained batch 195 in epoch 7, gen_loss = 0.8750435998853372, disc_loss = 0.031545445075904836
Trained batch 196 in epoch 7, gen_loss = 0.8748226907047524, disc_loss = 0.03141282261987477
Trained batch 197 in epoch 7, gen_loss = 0.8751157639604626, disc_loss = 0.031304262667856735
Trained batch 198 in epoch 7, gen_loss = 0.8756415565409253, disc_loss = 0.03123420661773963
Trained batch 199 in epoch 7, gen_loss = 0.875045635998249, disc_loss = 0.031219453890807925
Trained batch 200 in epoch 7, gen_loss = 0.8746766753457672, disc_loss = 0.0311088969198922
Trained batch 201 in epoch 7, gen_loss = 0.8748584124121336, disc_loss = 0.030972703196348088
Trained batch 202 in epoch 7, gen_loss = 0.8748568892478943, disc_loss = 0.03086465512507875
Trained batch 203 in epoch 7, gen_loss = 0.8747632947622561, disc_loss = 0.03074923656679982
Trained batch 204 in epoch 7, gen_loss = 0.8758995079412693, disc_loss = 0.030716086692381198
Trained batch 205 in epoch 7, gen_loss = 0.8751691643474171, disc_loss = 0.030620100446841093
Trained batch 206 in epoch 7, gen_loss = 0.8750603420722888, disc_loss = 0.030485511368257556
Trained batch 207 in epoch 7, gen_loss = 0.8753135453623074, disc_loss = 0.030408243422593493
Trained batch 208 in epoch 7, gen_loss = 0.8746257395835585, disc_loss = 0.030363458112933846
Trained batch 209 in epoch 7, gen_loss = 0.8755926015831176, disc_loss = 0.030322538455948234
Trained batch 210 in epoch 7, gen_loss = 0.875740173021199, disc_loss = 0.030366246608390487
Trained batch 211 in epoch 7, gen_loss = 0.8751187844658798, disc_loss = 0.0303333254403628
Trained batch 212 in epoch 7, gen_loss = 0.875050447356533, disc_loss = 0.030269871642944257
Trained batch 213 in epoch 7, gen_loss = 0.874810028298993, disc_loss = 0.030157900117250665
Trained batch 214 in epoch 7, gen_loss = 0.8747364870337553, disc_loss = 0.03006253228414544
Trained batch 215 in epoch 7, gen_loss = 0.8743125316169527, disc_loss = 0.030021032980315526
Trained batch 216 in epoch 7, gen_loss = 0.8734318479414909, disc_loss = 0.03006321151230124
Trained batch 217 in epoch 7, gen_loss = 0.8733714876371786, disc_loss = 0.029961909656626505
Trained batch 218 in epoch 7, gen_loss = 0.874489719737066, disc_loss = 0.03006546119585225
Trained batch 219 in epoch 7, gen_loss = 0.8746699151667682, disc_loss = 0.02996641035742042
Trained batch 220 in epoch 7, gen_loss = 0.8736737926081835, disc_loss = 0.030015685091983543
Trained batch 221 in epoch 7, gen_loss = 0.8740504641790647, disc_loss = 0.029995025192211207
Trained batch 222 in epoch 7, gen_loss = 0.8731007340777616, disc_loss = 0.03010662676632872
Trained batch 223 in epoch 7, gen_loss = 0.8732658502246652, disc_loss = 0.029996395441620343
Trained batch 224 in epoch 7, gen_loss = 0.8735678593317667, disc_loss = 0.029966878913756875
Trained batch 225 in epoch 7, gen_loss = 0.8741204683232097, disc_loss = 0.02988781536665572
Trained batch 226 in epoch 7, gen_loss = 0.8736946375359522, disc_loss = 0.02981037538835065
Trained batch 227 in epoch 7, gen_loss = 0.8737838733614537, disc_loss = 0.029711245113918393
Trained batch 228 in epoch 7, gen_loss = 0.872776253254653, disc_loss = 0.029806593144271833
Trained batch 229 in epoch 7, gen_loss = 0.8726364835448887, disc_loss = 0.02971344103064874
Trained batch 230 in epoch 7, gen_loss = 0.8733993149422979, disc_loss = 0.029781868693406707
Trained batch 231 in epoch 7, gen_loss = 0.8734514759532337, disc_loss = 0.029732567109649295
Trained batch 232 in epoch 7, gen_loss = 0.872390430628486, disc_loss = 0.030065594197055043
Trained batch 233 in epoch 7, gen_loss = 0.8726478583282895, disc_loss = 0.02999204012334474
Trained batch 234 in epoch 7, gen_loss = 0.8727619513552239, disc_loss = 0.029894090899603164
Trained batch 235 in epoch 7, gen_loss = 0.8726537086195865, disc_loss = 0.029819608362139028
Trained batch 236 in epoch 7, gen_loss = 0.8726605425907087, disc_loss = 0.029887751636845903
Trained batch 237 in epoch 7, gen_loss = 0.8721603300391125, disc_loss = 0.029816360369387295
Trained batch 238 in epoch 7, gen_loss = 0.8725681848605806, disc_loss = 0.029758014330430013
Trained batch 239 in epoch 7, gen_loss = 0.8725046060979367, disc_loss = 0.02965928042734352
Trained batch 240 in epoch 7, gen_loss = 0.8724560158875968, disc_loss = 0.029616194910512796
Trained batch 241 in epoch 7, gen_loss = 0.8718682419170033, disc_loss = 0.029662467545083115
Trained batch 242 in epoch 7, gen_loss = 0.8718298403814496, disc_loss = 0.02958159905440584
Trained batch 243 in epoch 7, gen_loss = 0.8724449413721679, disc_loss = 0.02966606460671994
Trained batch 244 in epoch 7, gen_loss = 0.8724810021264212, disc_loss = 0.029565721520279743
Trained batch 245 in epoch 7, gen_loss = 0.8726105505858011, disc_loss = 0.029475959379422833
Trained batch 246 in epoch 7, gen_loss = 0.8714524444780851, disc_loss = 0.029733928031691535
Trained batch 247 in epoch 7, gen_loss = 0.8715201810963692, disc_loss = 0.029733154012055528
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.8369989395141602, disc_loss = 0.016436610370874405
Trained batch 1 in epoch 8, gen_loss = 1.0106582641601562, disc_loss = 0.04585364647209644
Trained batch 2 in epoch 8, gen_loss = 0.9514669974644979, disc_loss = 0.03651843095819155
Trained batch 3 in epoch 8, gen_loss = 0.9079844951629639, disc_loss = 0.031437234953045845
Trained batch 4 in epoch 8, gen_loss = 0.9183066844940185, disc_loss = 0.026653346326202153
Trained batch 5 in epoch 8, gen_loss = 0.9250759681065878, disc_loss = 0.02397214116839071
Trained batch 6 in epoch 8, gen_loss = 0.9254105176244464, disc_loss = 0.02116960014349648
Trained batch 7 in epoch 8, gen_loss = 0.9277686104178429, disc_loss = 0.019435390655416995
Trained batch 8 in epoch 8, gen_loss = 0.9152408573362563, disc_loss = 0.019437513676368527
Trained batch 9 in epoch 8, gen_loss = 0.901503574848175, disc_loss = 0.019973380723968148
Trained batch 10 in epoch 8, gen_loss = 0.8927774591879412, disc_loss = 0.019565165085210043
Trained batch 11 in epoch 8, gen_loss = 0.8897896409034729, disc_loss = 0.019211793201975524
Trained batch 12 in epoch 8, gen_loss = 0.9045692957364596, disc_loss = 0.020550960424141243
Trained batch 13 in epoch 8, gen_loss = 0.9011402811322894, disc_loss = 0.019952851913071105
Trained batch 14 in epoch 8, gen_loss = 0.883712375164032, disc_loss = 0.02261246656998992
Trained batch 15 in epoch 8, gen_loss = 0.8867692537605762, disc_loss = 0.024950517487013713
Trained batch 16 in epoch 8, gen_loss = 0.88148533596712, disc_loss = 0.024513903046574664
Trained batch 17 in epoch 8, gen_loss = 0.8772730231285095, disc_loss = 0.02385715692717996
Trained batch 18 in epoch 8, gen_loss = 0.8760465320787931, disc_loss = 0.022942386322507734
Trained batch 19 in epoch 8, gen_loss = 0.878849595785141, disc_loss = 0.02205650492105633
Trained batch 20 in epoch 8, gen_loss = 0.878621708779108, disc_loss = 0.022677838292327664
Trained batch 21 in epoch 8, gen_loss = 0.8762702400034125, disc_loss = 0.022313309685242446
Trained batch 22 in epoch 8, gen_loss = 0.8763728400935298, disc_loss = 0.02163156771870411
Trained batch 23 in epoch 8, gen_loss = 0.8848783324162165, disc_loss = 0.02158015207775558
Trained batch 24 in epoch 8, gen_loss = 0.8859120678901672, disc_loss = 0.020982056204229594
Trained batch 25 in epoch 8, gen_loss = 0.889133441906709, disc_loss = 0.0207080790379013
Trained batch 26 in epoch 8, gen_loss = 0.8885212452323349, disc_loss = 0.02031465235200745
Trained batch 27 in epoch 8, gen_loss = 0.8849197498389653, disc_loss = 0.020082686478937312
Trained batch 28 in epoch 8, gen_loss = 0.8872656370031422, disc_loss = 0.0196050062839841
Trained batch 29 in epoch 8, gen_loss = 0.8885053118069967, disc_loss = 0.0195882821145157
Trained batch 30 in epoch 8, gen_loss = 0.8881433913784642, disc_loss = 0.019217166779262405
Trained batch 31 in epoch 8, gen_loss = 0.8903574254363775, disc_loss = 0.019019819563254714
Trained batch 32 in epoch 8, gen_loss = 0.8899693182020476, disc_loss = 0.019251050483999832
Trained batch 33 in epoch 8, gen_loss = 0.8883742795271032, disc_loss = 0.0191249519257861
Trained batch 34 in epoch 8, gen_loss = 0.8858177678925651, disc_loss = 0.018997551021831375
Trained batch 35 in epoch 8, gen_loss = 0.8870502428876029, disc_loss = 0.018612125991947122
Trained batch 36 in epoch 8, gen_loss = 0.892176446076986, disc_loss = 0.018558967657185888
Trained batch 37 in epoch 8, gen_loss = 0.8926763126724645, disc_loss = 0.01820775246443717
Trained batch 38 in epoch 8, gen_loss = 0.8890935442386529, disc_loss = 0.01844553040483823
Trained batch 39 in epoch 8, gen_loss = 0.8899770304560661, disc_loss = 0.01808063256321475
Trained batch 40 in epoch 8, gen_loss = 0.8905889202908772, disc_loss = 0.017745400903882776
Trained batch 41 in epoch 8, gen_loss = 0.8900214036305746, disc_loss = 0.017426171639401997
Trained batch 42 in epoch 8, gen_loss = 0.8893463500710421, disc_loss = 0.017323442139164653
Trained batch 43 in epoch 8, gen_loss = 0.8884416141293265, disc_loss = 0.017142737718214365
Trained batch 44 in epoch 8, gen_loss = 0.8932724343405829, disc_loss = 0.017162747691488928
Trained batch 45 in epoch 8, gen_loss = 0.8961078265438909, disc_loss = 0.016940658982924146
Trained batch 46 in epoch 8, gen_loss = 0.8918093747281014, disc_loss = 0.017321562503484336
Trained batch 47 in epoch 8, gen_loss = 0.89732147504886, disc_loss = 0.017599468575402472
Trained batch 48 in epoch 8, gen_loss = 0.8979842334377522, disc_loss = 0.017791302751141543
Trained batch 49 in epoch 8, gen_loss = 0.8972229707241058, disc_loss = 0.017793420841917394
Trained batch 50 in epoch 8, gen_loss = 0.8949016169005749, disc_loss = 0.018012007981465728
Trained batch 51 in epoch 8, gen_loss = 0.8938526110007212, disc_loss = 0.017808433917637628
Trained batch 52 in epoch 8, gen_loss = 0.8947691591280811, disc_loss = 0.017702966269527404
Trained batch 53 in epoch 8, gen_loss = 0.8933723226741508, disc_loss = 0.01761377398442063
Trained batch 54 in epoch 8, gen_loss = 0.8917293602770026, disc_loss = 0.0174424213018607
Trained batch 55 in epoch 8, gen_loss = 0.8922480759876115, disc_loss = 0.017780914994156256
Trained batch 56 in epoch 8, gen_loss = 0.8895335322932193, disc_loss = 0.01790871418064885
Trained batch 57 in epoch 8, gen_loss = 0.8909852977456718, disc_loss = 0.01779115610306376
Trained batch 58 in epoch 8, gen_loss = 0.891370854135287, disc_loss = 0.017576666904013542
Trained batch 59 in epoch 8, gen_loss = 0.8928132514158885, disc_loss = 0.01779737448475013
Trained batch 60 in epoch 8, gen_loss = 0.8918776248322159, disc_loss = 0.017662909698718397
Trained batch 61 in epoch 8, gen_loss = 0.8894003620070796, disc_loss = 0.01779456303695277
Trained batch 62 in epoch 8, gen_loss = 0.8912319711276463, disc_loss = 0.01774071706163268
Trained batch 63 in epoch 8, gen_loss = 0.8915989371016622, disc_loss = 0.017536976221890654
Trained batch 64 in epoch 8, gen_loss = 0.8906453288518466, disc_loss = 0.01744509536343125
Trained batch 65 in epoch 8, gen_loss = 0.8884046718929753, disc_loss = 0.017650295267671798
Trained batch 66 in epoch 8, gen_loss = 0.8914049765956935, disc_loss = 0.01797896044662417
Trained batch 67 in epoch 8, gen_loss = 0.8940541174481896, disc_loss = 0.018105016987058607
Trained batch 68 in epoch 8, gen_loss = 0.8972816216772881, disc_loss = 0.01823161927767206
Trained batch 69 in epoch 8, gen_loss = 0.8975596283163343, disc_loss = 0.018177911539429
Trained batch 70 in epoch 8, gen_loss = 0.8956005766358174, disc_loss = 0.018106355417100057
Trained batch 71 in epoch 8, gen_loss = 0.8976407191819615, disc_loss = 0.018105859447839774
Trained batch 72 in epoch 8, gen_loss = 0.8961850527214678, disc_loss = 0.018087108141091997
Trained batch 73 in epoch 8, gen_loss = 0.8969925988364864, disc_loss = 0.017989230663138064
Trained batch 74 in epoch 8, gen_loss = 0.8970709586143494, disc_loss = 0.01780738997583588
Trained batch 75 in epoch 8, gen_loss = 0.8951397357802642, disc_loss = 0.017857888523538253
Trained batch 76 in epoch 8, gen_loss = 0.8950041803446683, disc_loss = 0.017844434301429367
Trained batch 77 in epoch 8, gen_loss = 0.8937000502378513, disc_loss = 0.01777346513998241
Trained batch 78 in epoch 8, gen_loss = 0.8958517260189298, disc_loss = 0.017736198810884094
Trained batch 79 in epoch 8, gen_loss = 0.895418181270361, disc_loss = 0.01757113998173736
Trained batch 80 in epoch 8, gen_loss = 0.8950213054080068, disc_loss = 0.01741694462382131
Trained batch 81 in epoch 8, gen_loss = 0.895196927029912, disc_loss = 0.0172605759055331
Trained batch 82 in epoch 8, gen_loss = 0.8947738918913416, disc_loss = 0.017101443372666836
Trained batch 83 in epoch 8, gen_loss = 0.8949971220323018, disc_loss = 0.016947953490584734
Trained batch 84 in epoch 8, gen_loss = 0.8954921589178197, disc_loss = 0.01679182324339362
Trained batch 85 in epoch 8, gen_loss = 0.8945258412250253, disc_loss = 0.016719580606319184
Trained batch 86 in epoch 8, gen_loss = 0.894177086736964, disc_loss = 0.01692447430272212
Trained batch 87 in epoch 8, gen_loss = 0.8924712498079647, disc_loss = 0.01704123654318127
Trained batch 88 in epoch 8, gen_loss = 0.8936973770013016, disc_loss = 0.017044341505578396
Trained batch 89 in epoch 8, gen_loss = 0.8931889428032769, disc_loss = 0.016919929699765312
Trained batch 90 in epoch 8, gen_loss = 0.8933731121021312, disc_loss = 0.01676398284917513
Trained batch 91 in epoch 8, gen_loss = 0.8925956798636395, disc_loss = 0.016646886922662026
Trained batch 92 in epoch 8, gen_loss = 0.8930036771682001, disc_loss = 0.016526650737530443
Trained batch 93 in epoch 8, gen_loss = 0.8921661395975884, disc_loss = 0.016427429407795378
Trained batch 94 in epoch 8, gen_loss = 0.8938525294002734, disc_loss = 0.016359809310616633
Trained batch 95 in epoch 8, gen_loss = 0.8944422056277593, disc_loss = 0.01626844784671751
Trained batch 96 in epoch 8, gen_loss = 0.895284437641655, disc_loss = 0.016187774199877204
Trained batch 97 in epoch 8, gen_loss = 0.8932703891578986, disc_loss = 0.016197598149657856
Trained batch 98 in epoch 8, gen_loss = 0.892077027547239, disc_loss = 0.0162096486492741
Trained batch 99 in epoch 8, gen_loss = 0.8912274497747421, disc_loss = 0.01637603887356818
Trained batch 100 in epoch 8, gen_loss = 0.8890095046251127, disc_loss = 0.016596149256692665
Trained batch 101 in epoch 8, gen_loss = 0.8895673804423389, disc_loss = 0.016510105317495034
Trained batch 102 in epoch 8, gen_loss = 0.8881775308581232, disc_loss = 0.016844501203486642
Trained batch 103 in epoch 8, gen_loss = 0.8901562845477691, disc_loss = 0.016888712183572352
Trained batch 104 in epoch 8, gen_loss = 0.8922787456285386, disc_loss = 0.016914949539516652
Trained batch 105 in epoch 8, gen_loss = 0.8914851023341125, disc_loss = 0.016894529389112064
Trained batch 106 in epoch 8, gen_loss = 0.8922952157314693, disc_loss = 0.016797588089324324
Trained batch 107 in epoch 8, gen_loss = 0.8908661388688617, disc_loss = 0.01698502354513578
Trained batch 108 in epoch 8, gen_loss = 0.8908241407586894, disc_loss = 0.01696608741468656
Trained batch 109 in epoch 8, gen_loss = 0.8915232961828058, disc_loss = 0.017104453216730195
Trained batch 110 in epoch 8, gen_loss = 0.8914945055772593, disc_loss = 0.017014202775081266
Trained batch 111 in epoch 8, gen_loss = 0.8906038941017219, disc_loss = 0.017172760267775238
Trained batch 112 in epoch 8, gen_loss = 0.8903022397935918, disc_loss = 0.017098724887401395
Trained batch 113 in epoch 8, gen_loss = 0.8900310872939595, disc_loss = 0.01703223136351689
Trained batch 114 in epoch 8, gen_loss = 0.8902093109877213, disc_loss = 0.017042021773269644
Trained batch 115 in epoch 8, gen_loss = 0.8886457393909323, disc_loss = 0.017158404663044573
Trained batch 116 in epoch 8, gen_loss = 0.8893869865653862, disc_loss = 0.017158652309519358
Trained batch 117 in epoch 8, gen_loss = 0.8901870200189493, disc_loss = 0.01731730394175876
Trained batch 118 in epoch 8, gen_loss = 0.8874213910904252, disc_loss = 0.01823114136922635
Trained batch 119 in epoch 8, gen_loss = 0.8875489180286725, disc_loss = 0.018186659610364586
Trained batch 120 in epoch 8, gen_loss = 0.8884022812212794, disc_loss = 0.018173577906640846
Trained batch 121 in epoch 8, gen_loss = 0.8898645654076436, disc_loss = 0.018127848451468545
Trained batch 122 in epoch 8, gen_loss = 0.8892094425069608, disc_loss = 0.01814901351368403
Trained batch 123 in epoch 8, gen_loss = 0.8886707737561195, disc_loss = 0.018059324987623238
Trained batch 124 in epoch 8, gen_loss = 0.8873141508102417, disc_loss = 0.018169872377067804
Trained batch 125 in epoch 8, gen_loss = 0.8886438428409515, disc_loss = 0.01846414447082059
Trained batch 126 in epoch 8, gen_loss = 0.8878889881719755, disc_loss = 0.018406519361984307
Trained batch 127 in epoch 8, gen_loss = 0.8892943412065506, disc_loss = 0.018362783248448977
Trained batch 128 in epoch 8, gen_loss = 0.8878801109254822, disc_loss = 0.018465026696898448
Trained batch 129 in epoch 8, gen_loss = 0.8873106342095595, disc_loss = 0.01836537397108399
Trained batch 130 in epoch 8, gen_loss = 0.8881819257299408, disc_loss = 0.01836672704666853
Trained batch 131 in epoch 8, gen_loss = 0.8885255862366069, disc_loss = 0.0182829154337841
Trained batch 132 in epoch 8, gen_loss = 0.8901445820815581, disc_loss = 0.018326228200913147
Trained batch 133 in epoch 8, gen_loss = 0.8903629143736256, disc_loss = 0.01830805961473553
Trained batch 134 in epoch 8, gen_loss = 0.889234416573136, disc_loss = 0.018355728116714293
Trained batch 135 in epoch 8, gen_loss = 0.8900587725288728, disc_loss = 0.01837968232918202
Trained batch 136 in epoch 8, gen_loss = 0.8901885434658858, disc_loss = 0.018349791234563085
Trained batch 137 in epoch 8, gen_loss = 0.8892220038434734, disc_loss = 0.018381221412235627
Trained batch 138 in epoch 8, gen_loss = 0.8882576420152788, disc_loss = 0.018445745542672254
Trained batch 139 in epoch 8, gen_loss = 0.887991526722908, disc_loss = 0.018346583344308394
Trained batch 140 in epoch 8, gen_loss = 0.8884232690993775, disc_loss = 0.018249715404281167
Trained batch 141 in epoch 8, gen_loss = 0.8884600736725499, disc_loss = 0.01817461416374525
Trained batch 142 in epoch 8, gen_loss = 0.8890439213572682, disc_loss = 0.018202879313066914
Trained batch 143 in epoch 8, gen_loss = 0.888568347113, disc_loss = 0.01817893346499962
Trained batch 144 in epoch 8, gen_loss = 0.8883021062818067, disc_loss = 0.018118022057902198
Trained batch 145 in epoch 8, gen_loss = 0.8885908824940251, disc_loss = 0.01803498973508608
Trained batch 146 in epoch 8, gen_loss = 0.8887591876951205, disc_loss = 0.017974146591106646
Trained batch 147 in epoch 8, gen_loss = 0.8894607473064113, disc_loss = 0.01793241564410965
Trained batch 148 in epoch 8, gen_loss = 0.8888393624516941, disc_loss = 0.01787907935228924
Trained batch 149 in epoch 8, gen_loss = 0.8889974125226339, disc_loss = 0.017786116016407807
Trained batch 150 in epoch 8, gen_loss = 0.8888576717566181, disc_loss = 0.017695679187478608
Trained batch 151 in epoch 8, gen_loss = 0.8894203003299864, disc_loss = 0.017636153056580377
Trained batch 152 in epoch 8, gen_loss = 0.8896537158224318, disc_loss = 0.01755365319671779
Trained batch 153 in epoch 8, gen_loss = 0.8894755457128797, disc_loss = 0.017477787214682086
Trained batch 154 in epoch 8, gen_loss = 0.8886309243017627, disc_loss = 0.017445517553677483
Trained batch 155 in epoch 8, gen_loss = 0.8887082506448795, disc_loss = 0.017386381699440952
Trained batch 156 in epoch 8, gen_loss = 0.8891008959454336, disc_loss = 0.017311510042684854
Trained batch 157 in epoch 8, gen_loss = 0.8902099958703488, disc_loss = 0.01728220762614208
Trained batch 158 in epoch 8, gen_loss = 0.8896722160045456, disc_loss = 0.017281318774575706
Trained batch 159 in epoch 8, gen_loss = 0.8889387521892786, disc_loss = 0.017285830434411766
Trained batch 160 in epoch 8, gen_loss = 0.8887434409271856, disc_loss = 0.017242003914824923
Trained batch 161 in epoch 8, gen_loss = 0.8880927371390072, disc_loss = 0.017295253991988706
Trained batch 162 in epoch 8, gen_loss = 0.8888101921491096, disc_loss = 0.01724526196421107
Trained batch 163 in epoch 8, gen_loss = 0.8893896708401238, disc_loss = 0.017164143648498307
Trained batch 164 in epoch 8, gen_loss = 0.8910187760988871, disc_loss = 0.017209904544958562
Trained batch 165 in epoch 8, gen_loss = 0.8913062085588295, disc_loss = 0.017155873089894115
Trained batch 166 in epoch 8, gen_loss = 0.8911011008445374, disc_loss = 0.017096041874614304
Trained batch 167 in epoch 8, gen_loss = 0.8907427454278583, disc_loss = 0.017030461153592028
Trained batch 168 in epoch 8, gen_loss = 0.8908278335481, disc_loss = 0.016956267919744084
Trained batch 169 in epoch 8, gen_loss = 0.8908448892481187, disc_loss = 0.01706592704388587
Trained batch 170 in epoch 8, gen_loss = 0.8902010119449325, disc_loss = 0.01710040724362459
Trained batch 171 in epoch 8, gen_loss = 0.8892957855795705, disc_loss = 0.01712306191180941
Trained batch 172 in epoch 8, gen_loss = 0.8901431226316904, disc_loss = 0.017139599682773985
Trained batch 173 in epoch 8, gen_loss = 0.8901993392527788, disc_loss = 0.017073803161131752
Trained batch 174 in epoch 8, gen_loss = 0.8900126484462193, disc_loss = 0.01700620986787336
Trained batch 175 in epoch 8, gen_loss = 0.8904297622767362, disc_loss = 0.01692974133369386
Trained batch 176 in epoch 8, gen_loss = 0.8908263646950156, disc_loss = 0.0168587754041188
Trained batch 177 in epoch 8, gen_loss = 0.8892134863339113, disc_loss = 0.017116317592215925
Trained batch 178 in epoch 8, gen_loss = 0.8907810263127588, disc_loss = 0.01739878744776647
Trained batch 179 in epoch 8, gen_loss = 0.8894566218058269, disc_loss = 0.017537697967297088
Trained batch 180 in epoch 8, gen_loss = 0.8899142531400227, disc_loss = 0.01764316330355134
Trained batch 181 in epoch 8, gen_loss = 0.8901748185629373, disc_loss = 0.017666287642166757
Trained batch 182 in epoch 8, gen_loss = 0.8897693274451084, disc_loss = 0.01764959864740774
Trained batch 183 in epoch 8, gen_loss = 0.8898753961143286, disc_loss = 0.0175863589785244
Trained batch 184 in epoch 8, gen_loss = 0.8899029300019548, disc_loss = 0.017513633122969722
Trained batch 185 in epoch 8, gen_loss = 0.8894262522138575, disc_loss = 0.017457443854010473
Trained batch 186 in epoch 8, gen_loss = 0.8888484249140489, disc_loss = 0.017465379222341003
Trained batch 187 in epoch 8, gen_loss = 0.8887192014049976, disc_loss = 0.017397357335442953
Trained batch 188 in epoch 8, gen_loss = 0.8887002136972215, disc_loss = 0.017351287595740464
Trained batch 189 in epoch 8, gen_loss = 0.8889496947589673, disc_loss = 0.01735715892190408
Trained batch 190 in epoch 8, gen_loss = 0.8887363831410233, disc_loss = 0.017331458731793373
Trained batch 191 in epoch 8, gen_loss = 0.8876523217186332, disc_loss = 0.01741122146510558
Trained batch 192 in epoch 8, gen_loss = 0.8878831690457201, disc_loss = 0.017404270060408688
Trained batch 193 in epoch 8, gen_loss = 0.8886699418431705, disc_loss = 0.01751222756820894
Trained batch 194 in epoch 8, gen_loss = 0.8876813139670935, disc_loss = 0.017588969335580865
Trained batch 195 in epoch 8, gen_loss = 0.8860663580042976, disc_loss = 0.018068197616898665
Trained batch 196 in epoch 8, gen_loss = 0.8865029004019529, disc_loss = 0.018420032472562443
Trained batch 197 in epoch 8, gen_loss = 0.8861650285696743, disc_loss = 0.018473684934739287
Trained batch 198 in epoch 8, gen_loss = 0.8863362948499133, disc_loss = 0.01842952672808651
Trained batch 199 in epoch 8, gen_loss = 0.8857981997728348, disc_loss = 0.018435653425985948
Trained batch 200 in epoch 8, gen_loss = 0.8854512085962059, disc_loss = 0.018457277512307562
Trained batch 201 in epoch 8, gen_loss = 0.8855289031963537, disc_loss = 0.01840812415645301
Trained batch 202 in epoch 8, gen_loss = 0.8852343893990728, disc_loss = 0.018377751292055242
Trained batch 203 in epoch 8, gen_loss = 0.8850642997844547, disc_loss = 0.01832815516835955
Trained batch 204 in epoch 8, gen_loss = 0.8849599553317559, disc_loss = 0.01899538855749841
Trained batch 205 in epoch 8, gen_loss = 0.8837761369723718, disc_loss = 0.019325961744259067
Trained batch 206 in epoch 8, gen_loss = 0.8844135141603037, disc_loss = 0.019356718877384414
Trained batch 207 in epoch 8, gen_loss = 0.8849624873927007, disc_loss = 0.019327244592624575
Trained batch 208 in epoch 8, gen_loss = 0.8846382635632201, disc_loss = 0.019276648578256297
Trained batch 209 in epoch 8, gen_loss = 0.8833240330219269, disc_loss = 0.019503228824275236
Trained batch 210 in epoch 8, gen_loss = 0.8829133129232868, disc_loss = 0.01975937155560895
Trained batch 211 in epoch 8, gen_loss = 0.8829947991191216, disc_loss = 0.019734485414239385
Trained batch 212 in epoch 8, gen_loss = 0.8819217922542016, disc_loss = 0.019875140909866338
Trained batch 213 in epoch 8, gen_loss = 0.8818939163863102, disc_loss = 0.019919825009522944
Trained batch 214 in epoch 8, gen_loss = 0.8824545874152072, disc_loss = 0.020333801146033545
Trained batch 215 in epoch 8, gen_loss = 0.8813733259836832, disc_loss = 0.020762858917738346
Trained batch 216 in epoch 8, gen_loss = 0.8802685960097247, disc_loss = 0.02104409290198666
Trained batch 217 in epoch 8, gen_loss = 0.8800315285494568, disc_loss = 0.021275351769205423
Trained batch 218 in epoch 8, gen_loss = 0.879942290586968, disc_loss = 0.021323985744429303
Trained batch 219 in epoch 8, gen_loss = 0.8801372758366844, disc_loss = 0.021278209282635626
Trained batch 220 in epoch 8, gen_loss = 0.8794548417108631, disc_loss = 0.02130858786509486
Trained batch 221 in epoch 8, gen_loss = 0.8783997098604838, disc_loss = 0.02139547934675975
Trained batch 222 in epoch 8, gen_loss = 0.8793106586943827, disc_loss = 0.021574910806341625
Trained batch 223 in epoch 8, gen_loss = 0.8787291496992111, disc_loss = 0.02164665921528857
Trained batch 224 in epoch 8, gen_loss = 0.878232143190172, disc_loss = 0.021692651502995028
Trained batch 225 in epoch 8, gen_loss = 0.8780002878830496, disc_loss = 0.021672221379708992
Trained batch 226 in epoch 8, gen_loss = 0.8792901312202084, disc_loss = 0.02229338152526923
Trained batch 227 in epoch 8, gen_loss = 0.8787957942276671, disc_loss = 0.0223261782452219
Trained batch 228 in epoch 8, gen_loss = 0.8772611342142763, disc_loss = 0.023039081456204754
Trained batch 229 in epoch 8, gen_loss = 0.8778605880944625, disc_loss = 0.023048467011919812
Trained batch 230 in epoch 8, gen_loss = 0.8779349342569128, disc_loss = 0.023006496883453034
Trained batch 231 in epoch 8, gen_loss = 0.8779982325845751, disc_loss = 0.022981286086021634
Trained batch 232 in epoch 8, gen_loss = 0.877800104699933, disc_loss = 0.02295011658992922
Trained batch 233 in epoch 8, gen_loss = 0.8779562991908473, disc_loss = 0.022882675452547897
Trained batch 234 in epoch 8, gen_loss = 0.8770150144049462, disc_loss = 0.023068464883266294
Trained batch 235 in epoch 8, gen_loss = 0.8765104771670649, disc_loss = 0.023057675812890657
Trained batch 236 in epoch 8, gen_loss = 0.8773102463549199, disc_loss = 0.023146263613534564
Trained batch 237 in epoch 8, gen_loss = 0.8767472220068219, disc_loss = 0.023124444003983894
Trained batch 238 in epoch 8, gen_loss = 0.8762565127975273, disc_loss = 0.02316442736284223
Trained batch 239 in epoch 8, gen_loss = 0.8771771639585495, disc_loss = 0.023215649210033006
Trained batch 240 in epoch 8, gen_loss = 0.8771684377519916, disc_loss = 0.023190572350653065
Trained batch 241 in epoch 8, gen_loss = 0.87691894001212, disc_loss = 0.023126180644516547
Trained batch 242 in epoch 8, gen_loss = 0.8769009510676066, disc_loss = 0.023087691763845185
Trained batch 243 in epoch 8, gen_loss = 0.877558739947491, disc_loss = 0.023108660918087928
Trained batch 244 in epoch 8, gen_loss = 0.8776334040018977, disc_loss = 0.023057599782905714
Trained batch 245 in epoch 8, gen_loss = 0.8778929703119325, disc_loss = 0.023014974930868824
Trained batch 246 in epoch 8, gen_loss = 0.8777286711974666, disc_loss = 0.022967148722085332
Trained batch 247 in epoch 8, gen_loss = 0.8778808974931317, disc_loss = 0.022895778074011868
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8869656324386597, disc_loss = 0.004403957165777683
Trained batch 1 in epoch 9, gen_loss = 0.9151526093482971, disc_loss = 0.004599046893417835
Trained batch 2 in epoch 9, gen_loss = 0.9274507959683737, disc_loss = 0.005153991126765807
Trained batch 3 in epoch 9, gen_loss = 0.9001847058534622, disc_loss = 0.005923893651925027
Trained batch 4 in epoch 9, gen_loss = 0.9029063701629638, disc_loss = 0.008156514819711446
Trained batch 5 in epoch 9, gen_loss = 0.8950689236323038, disc_loss = 0.00879877689294517
Trained batch 6 in epoch 9, gen_loss = 0.9004720790045602, disc_loss = 0.00842275656759739
Trained batch 7 in epoch 9, gen_loss = 0.8976597264409065, disc_loss = 0.008236368303187191
Trained batch 8 in epoch 9, gen_loss = 0.8884535564316643, disc_loss = 0.009232026731802357
Trained batch 9 in epoch 9, gen_loss = 0.8768639504909516, disc_loss = 0.009113828092813492
Trained batch 10 in epoch 9, gen_loss = 0.9048091010613875, disc_loss = 0.011168854480439966
Trained batch 11 in epoch 9, gen_loss = 0.9152188946803411, disc_loss = 0.010916299497087797
Trained batch 12 in epoch 9, gen_loss = 0.9134728862689092, disc_loss = 0.010435920029592056
Trained batch 13 in epoch 9, gen_loss = 0.9028938838413784, disc_loss = 0.010581885830366186
Trained batch 14 in epoch 9, gen_loss = 0.8985836585362752, disc_loss = 0.010332956972221533
Trained batch 15 in epoch 9, gen_loss = 0.9000536650419235, disc_loss = 0.010116063116583973
Trained batch 16 in epoch 9, gen_loss = 0.9012804381987628, disc_loss = 0.010123369722243617
Trained batch 17 in epoch 9, gen_loss = 0.8989743590354919, disc_loss = 0.009734199886831144
Trained batch 18 in epoch 9, gen_loss = 0.8945987663770977, disc_loss = 0.010149086078040694
Trained batch 19 in epoch 9, gen_loss = 0.891220211982727, disc_loss = 0.00987231385661289
Trained batch 20 in epoch 9, gen_loss = 0.8954274938220069, disc_loss = 0.010136385703281988
Trained batch 21 in epoch 9, gen_loss = 0.8882791914723136, disc_loss = 0.010813537424176255
Trained batch 22 in epoch 9, gen_loss = 0.8836082867954088, disc_loss = 0.010854425546510713
Trained batch 23 in epoch 9, gen_loss = 0.8910297726591428, disc_loss = 0.011967916419962421
Trained batch 24 in epoch 9, gen_loss = 0.8787143707275391, disc_loss = 0.014459510510787367
Trained batch 25 in epoch 9, gen_loss = 0.8804855461304004, disc_loss = 0.01516266259400604
Trained batch 26 in epoch 9, gen_loss = 0.8813772488523413, disc_loss = 0.015626376762089354
Trained batch 27 in epoch 9, gen_loss = 0.8806175014802388, disc_loss = 0.015520523293941681
Trained batch 28 in epoch 9, gen_loss = 0.87049879082318, disc_loss = 0.01759151098768002
Trained batch 29 in epoch 9, gen_loss = 0.86932066877683, disc_loss = 0.01841737440942476
Trained batch 30 in epoch 9, gen_loss = 0.8735040714663844, disc_loss = 0.018293496934817202
Trained batch 31 in epoch 9, gen_loss = 0.8713334295898676, disc_loss = 0.018530573513999116
Trained batch 32 in epoch 9, gen_loss = 0.8639296654498938, disc_loss = 0.01962214476203151
Trained batch 33 in epoch 9, gen_loss = 0.8627202212810516, disc_loss = 0.019971633925760054
Trained batch 34 in epoch 9, gen_loss = 0.8534214547702245, disc_loss = 0.022051575400733523
Trained batch 35 in epoch 9, gen_loss = 0.8591525736782286, disc_loss = 0.02457656922827785
Trained batch 36 in epoch 9, gen_loss = 0.8572809035713608, disc_loss = 0.024861312037132478
Trained batch 37 in epoch 9, gen_loss = 0.8493890040799191, disc_loss = 0.02709436871871156
Trained batch 38 in epoch 9, gen_loss = 0.8473462661107382, disc_loss = 0.027591151633084968
Trained batch 39 in epoch 9, gen_loss = 0.8469708174467087, disc_loss = 0.027253149583702906
Trained batch 40 in epoch 9, gen_loss = 0.8481377901100531, disc_loss = 0.027007432830542688
Trained batch 41 in epoch 9, gen_loss = 0.8477018248467219, disc_loss = 0.02650016261863389
Trained batch 42 in epoch 9, gen_loss = 0.8472601369369862, disc_loss = 0.026156227033975167
Trained batch 43 in epoch 9, gen_loss = 0.8501190787011926, disc_loss = 0.026653328016188672
Trained batch 44 in epoch 9, gen_loss = 0.8478254053327773, disc_loss = 0.026723763879595533
Trained batch 45 in epoch 9, gen_loss = 0.8482728172903475, disc_loss = 0.026417598771133824
Trained batch 46 in epoch 9, gen_loss = 0.8499738738891927, disc_loss = 0.02597428192979002
Trained batch 47 in epoch 9, gen_loss = 0.8509624811510245, disc_loss = 0.025601360815926455
Trained batch 48 in epoch 9, gen_loss = 0.8481834311874545, disc_loss = 0.025871769681915034
Trained batch 49 in epoch 9, gen_loss = 0.84484020113945, disc_loss = 0.02616068782750517
Trained batch 50 in epoch 9, gen_loss = 0.8483164392265619, disc_loss = 0.026540142013782672
Trained batch 51 in epoch 9, gen_loss = 0.8475982535343903, disc_loss = 0.027184227145670984
Trained batch 52 in epoch 9, gen_loss = 0.8424712959325539, disc_loss = 0.028181494639764697
Trained batch 53 in epoch 9, gen_loss = 0.8433563400197912, disc_loss = 0.02775983762047771
Trained batch 54 in epoch 9, gen_loss = 0.8429957129738548, disc_loss = 0.027842597134242003
Trained batch 55 in epoch 9, gen_loss = 0.8473713163818631, disc_loss = 0.02791873154014216
Trained batch 56 in epoch 9, gen_loss = 0.8468097521547686, disc_loss = 0.02761270976298603
Trained batch 57 in epoch 9, gen_loss = 0.8441439353186508, disc_loss = 0.027757684551661128
Trained batch 58 in epoch 9, gen_loss = 0.8474857261625387, disc_loss = 0.027678786078467965
Trained batch 59 in epoch 9, gen_loss = 0.8474615891774495, disc_loss = 0.027603715856093912
Trained batch 60 in epoch 9, gen_loss = 0.8475021807873835, disc_loss = 0.028267492963856118
Trained batch 61 in epoch 9, gen_loss = 0.8454796575730846, disc_loss = 0.028567930454418303
Trained batch 62 in epoch 9, gen_loss = 0.8453854445427184, disc_loss = 0.028432288085154835
Trained batch 63 in epoch 9, gen_loss = 0.8436085348948836, disc_loss = 0.028199600503285183
Trained batch 64 in epoch 9, gen_loss = 0.8443867820959825, disc_loss = 0.028023488314535754
Trained batch 65 in epoch 9, gen_loss = 0.8423853010842295, disc_loss = 0.028178053213085866
Trained batch 66 in epoch 9, gen_loss = 0.8467200709812677, disc_loss = 0.029509476160130173
Trained batch 67 in epoch 9, gen_loss = 0.8459461532971438, disc_loss = 0.029471714991172227
Trained batch 68 in epoch 9, gen_loss = 0.8427855026894722, disc_loss = 0.0298417161549509
Trained batch 69 in epoch 9, gen_loss = 0.8469328701496124, disc_loss = 0.031048782020142034
Trained batch 70 in epoch 9, gen_loss = 0.8425432334483509, disc_loss = 0.032331991950574686
Trained batch 71 in epoch 9, gen_loss = 0.8452138991819488, disc_loss = 0.03272336039420528
Trained batch 72 in epoch 9, gen_loss = 0.843748880575781, disc_loss = 0.033015073886243244
Trained batch 73 in epoch 9, gen_loss = 0.8437306292959161, disc_loss = 0.03307504424309308
Trained batch 74 in epoch 9, gen_loss = 0.8423506053288777, disc_loss = 0.03300398539441327
Trained batch 75 in epoch 9, gen_loss = 0.8408713372130143, disc_loss = 0.03293592123449535
Trained batch 76 in epoch 9, gen_loss = 0.840296517718922, disc_loss = 0.033387078416787765
Trained batch 77 in epoch 9, gen_loss = 0.8406876302682437, disc_loss = 0.033106165493313126
Trained batch 78 in epoch 9, gen_loss = 0.8397832867465441, disc_loss = 0.03309717166968444
Trained batch 79 in epoch 9, gen_loss = 0.8387833341956139, disc_loss = 0.03288133729656693
Trained batch 80 in epoch 9, gen_loss = 0.8398840942500551, disc_loss = 0.03260216743248388
Trained batch 81 in epoch 9, gen_loss = 0.8407538969342302, disc_loss = 0.032537349281128405
Trained batch 82 in epoch 9, gen_loss = 0.8410016456282282, disc_loss = 0.03238998760514141
Trained batch 83 in epoch 9, gen_loss = 0.8408907637709663, disc_loss = 0.03219911922600919
Trained batch 84 in epoch 9, gen_loss = 0.8435712267370785, disc_loss = 0.03204582479015431
Trained batch 85 in epoch 9, gen_loss = 0.8445593867191049, disc_loss = 0.031952427123499993
Trained batch 86 in epoch 9, gen_loss = 0.8449815052679215, disc_loss = 0.03174741990896392
Trained batch 87 in epoch 9, gen_loss = 0.8456879007545385, disc_loss = 0.03150368021240204
Trained batch 88 in epoch 9, gen_loss = 0.842421787508418, disc_loss = 0.032085183346016184
Trained batch 89 in epoch 9, gen_loss = 0.8456618852085538, disc_loss = 0.03244507499815275
Trained batch 90 in epoch 9, gen_loss = 0.8470854471018027, disc_loss = 0.03216860185704798
Trained batch 91 in epoch 9, gen_loss = 0.846168410518895, disc_loss = 0.03192151435296577
Trained batch 92 in epoch 9, gen_loss = 0.8446715544628841, disc_loss = 0.03173618162080886
Trained batch 93 in epoch 9, gen_loss = 0.8450615659673163, disc_loss = 0.0314680926942643
Trained batch 94 in epoch 9, gen_loss = 0.8448697416405929, disc_loss = 0.03164992953258518
Trained batch 95 in epoch 9, gen_loss = 0.8428451747943958, disc_loss = 0.03161264340208921
Trained batch 96 in epoch 9, gen_loss = 0.8425216723963157, disc_loss = 0.03143742395632122
Trained batch 97 in epoch 9, gen_loss = 0.8417735939123192, disc_loss = 0.0314078847331242
Trained batch 98 in epoch 9, gen_loss = 0.8415173412573458, disc_loss = 0.03137943559947113
Trained batch 99 in epoch 9, gen_loss = 0.8450660848617554, disc_loss = 0.031527058121282606
Trained batch 100 in epoch 9, gen_loss = 0.8452127428338079, disc_loss = 0.03154349940515464
Trained batch 101 in epoch 9, gen_loss = 0.8444666108664345, disc_loss = 0.031392166731130405
Trained batch 102 in epoch 9, gen_loss = 0.8440914998934107, disc_loss = 0.03121194555604993
Trained batch 103 in epoch 9, gen_loss = 0.8454833426154577, disc_loss = 0.03097991478101064
Trained batch 104 in epoch 9, gen_loss = 0.8470751904305958, disc_loss = 0.030969756462478213
Trained batch 105 in epoch 9, gen_loss = 0.8466394571763165, disc_loss = 0.030777992946447206
Trained batch 106 in epoch 9, gen_loss = 0.8450284360725189, disc_loss = 0.03085595580192161
Trained batch 107 in epoch 9, gen_loss = 0.8458974328305986, disc_loss = 0.030615699746973674
Trained batch 108 in epoch 9, gen_loss = 0.8476865586884524, disc_loss = 0.03144503496971767
Trained batch 109 in epoch 9, gen_loss = 0.8450254109772769, disc_loss = 0.03228669778909534
Trained batch 110 in epoch 9, gen_loss = 0.8435033704783466, disc_loss = 0.03295256092783634
Trained batch 111 in epoch 9, gen_loss = 0.8415800636368138, disc_loss = 0.03386837885357506
Trained batch 112 in epoch 9, gen_loss = 0.8413938426338465, disc_loss = 0.03466892482473853
Trained batch 113 in epoch 9, gen_loss = 0.8412904159018868, disc_loss = 0.035338256077171025
Trained batch 114 in epoch 9, gen_loss = 0.8400864243507385, disc_loss = 0.0357361646713284
Trained batch 115 in epoch 9, gen_loss = 0.8388612008300321, disc_loss = 0.035957684381142385
Trained batch 116 in epoch 9, gen_loss = 0.8403774861596588, disc_loss = 0.03636779434955082
Trained batch 117 in epoch 9, gen_loss = 0.838049828501071, disc_loss = 0.03696780256587633
Trained batch 118 in epoch 9, gen_loss = 0.8371581505326664, disc_loss = 0.03715551944504328
Trained batch 119 in epoch 9, gen_loss = 0.8362795541683833, disc_loss = 0.03717396286665462
Trained batch 120 in epoch 9, gen_loss = 0.8371180571800421, disc_loss = 0.03710455128207248
Trained batch 121 in epoch 9, gen_loss = 0.839972758879427, disc_loss = 0.03706857498895499
Trained batch 122 in epoch 9, gen_loss = 0.8396921758729268, disc_loss = 0.03694520937089574
Trained batch 123 in epoch 9, gen_loss = 0.8394952377965373, disc_loss = 0.03680562152294442
Trained batch 124 in epoch 9, gen_loss = 0.8393557434082031, disc_loss = 0.0365585532579571
Trained batch 125 in epoch 9, gen_loss = 0.8399590916103787, disc_loss = 0.03634561803228858
Trained batch 126 in epoch 9, gen_loss = 0.8405003970063577, disc_loss = 0.03627448958183426
Trained batch 127 in epoch 9, gen_loss = 0.8408714141696692, disc_loss = 0.036115749602686265
Trained batch 128 in epoch 9, gen_loss = 0.8409823142280874, disc_loss = 0.03593081246173486
Trained batch 129 in epoch 9, gen_loss = 0.8415853812144353, disc_loss = 0.03569030454919602
Trained batch 130 in epoch 9, gen_loss = 0.8419908257841154, disc_loss = 0.03546257587754033
Trained batch 131 in epoch 9, gen_loss = 0.8429235955982497, disc_loss = 0.03523263955933296
Trained batch 132 in epoch 9, gen_loss = 0.8435848682446587, disc_loss = 0.03502091655290609
Trained batch 133 in epoch 9, gen_loss = 0.8441663749182402, disc_loss = 0.03480377293073697
Trained batch 134 in epoch 9, gen_loss = 0.8448522620730929, disc_loss = 0.034605145449232724
Trained batch 135 in epoch 9, gen_loss = 0.8447041748201146, disc_loss = 0.0343947728345965
Trained batch 136 in epoch 9, gen_loss = 0.8448289302143738, disc_loss = 0.03426450005746073
Trained batch 137 in epoch 9, gen_loss = 0.8449491733226223, disc_loss = 0.034070953212179025
Trained batch 138 in epoch 9, gen_loss = 0.8452531939787831, disc_loss = 0.033916850324733544
Trained batch 139 in epoch 9, gen_loss = 0.8455355290855681, disc_loss = 0.033712320896198175
Trained batch 140 in epoch 9, gen_loss = 0.8458170320125337, disc_loss = 0.03356192747282908
Trained batch 141 in epoch 9, gen_loss = 0.8463459560568903, disc_loss = 0.03335524895589169
Trained batch 142 in epoch 9, gen_loss = 0.8468005619682633, disc_loss = 0.03316967075827395
Trained batch 143 in epoch 9, gen_loss = 0.8469208913544813, disc_loss = 0.032988823211376764
Trained batch 144 in epoch 9, gen_loss = 0.8472350264417714, disc_loss = 0.03280018892556686
Trained batch 145 in epoch 9, gen_loss = 0.8477853810134, disc_loss = 0.032617585074909236
Trained batch 146 in epoch 9, gen_loss = 0.8480738628478277, disc_loss = 0.0324414450260272
Trained batch 147 in epoch 9, gen_loss = 0.8483272718416678, disc_loss = 0.03224776844286385
Trained batch 148 in epoch 9, gen_loss = 0.848632181250809, disc_loss = 0.03206853469014918
Trained batch 149 in epoch 9, gen_loss = 0.8489821926752726, disc_loss = 0.0319165909026439
Trained batch 150 in epoch 9, gen_loss = 0.8492346899398905, disc_loss = 0.031728370016477755
Trained batch 151 in epoch 9, gen_loss = 0.8499725704130373, disc_loss = 0.031549932664921995
Trained batch 152 in epoch 9, gen_loss = 0.8502076279883292, disc_loss = 0.03140317449906196
Trained batch 153 in epoch 9, gen_loss = 0.850313050793363, disc_loss = 0.031282336677896316
Trained batch 154 in epoch 9, gen_loss = 0.8503339148336841, disc_loss = 0.031119051494545514
Trained batch 155 in epoch 9, gen_loss = 0.8508722430620438, disc_loss = 0.030939627964145098
Trained batch 156 in epoch 9, gen_loss = 0.8517388989970942, disc_loss = 0.0307727113372059
Trained batch 157 in epoch 9, gen_loss = 0.8523093926001198, disc_loss = 0.030604048375676894
Trained batch 158 in epoch 9, gen_loss = 0.8525982690307329, disc_loss = 0.030434640300161433
Trained batch 159 in epoch 9, gen_loss = 0.8528489835560322, disc_loss = 0.0302677691943245
Trained batch 160 in epoch 9, gen_loss = 0.8533140076613575, disc_loss = 0.030119488140140076
Trained batch 161 in epoch 9, gen_loss = 0.8536678828574993, disc_loss = 0.029988214583423586
Trained batch 162 in epoch 9, gen_loss = 0.8539248247819444, disc_loss = 0.029828400059711713
Trained batch 163 in epoch 9, gen_loss = 0.854113039810483, disc_loss = 0.02972972611669542
Trained batch 164 in epoch 9, gen_loss = 0.8547567183321173, disc_loss = 0.029567180033490965
Trained batch 165 in epoch 9, gen_loss = 0.8551531617181847, disc_loss = 0.029416874635975854
Trained batch 166 in epoch 9, gen_loss = 0.8544199641593202, disc_loss = 0.029436202531591238
Trained batch 167 in epoch 9, gen_loss = 0.8565224611333438, disc_loss = 0.029402255314856858
Trained batch 168 in epoch 9, gen_loss = 0.8578553386693876, disc_loss = 0.029305464859511812
Trained batch 169 in epoch 9, gen_loss = 0.8584184376632467, disc_loss = 0.029261617396739038
Trained batch 170 in epoch 9, gen_loss = 0.8596757402894093, disc_loss = 0.029431599656621007
Trained batch 171 in epoch 9, gen_loss = 0.8608848268902579, disc_loss = 0.029679941090614382
Trained batch 172 in epoch 9, gen_loss = 0.8620410285933169, disc_loss = 0.0296521685449568
Trained batch 173 in epoch 9, gen_loss = 0.8620205624350186, disc_loss = 0.029607642603898955
Trained batch 174 in epoch 9, gen_loss = 0.8617748611313956, disc_loss = 0.029547879601429617
Trained batch 175 in epoch 9, gen_loss = 0.8625263758003712, disc_loss = 0.029493378148551776
Trained batch 176 in epoch 9, gen_loss = 0.8631290328704705, disc_loss = 0.029388903141663657
Trained batch 177 in epoch 9, gen_loss = 0.8626005612732319, disc_loss = 0.02941922301536405
Trained batch 178 in epoch 9, gen_loss = 0.8627889326164843, disc_loss = 0.02930370178828068
Trained batch 179 in epoch 9, gen_loss = 0.8635263297292921, disc_loss = 0.02919017095765513
Trained batch 180 in epoch 9, gen_loss = 0.8631844533741145, disc_loss = 0.02908237957272123
Trained batch 181 in epoch 9, gen_loss = 0.8639832040765784, disc_loss = 0.028975922528623636
Trained batch 182 in epoch 9, gen_loss = 0.8644320515335583, disc_loss = 0.029198442933103832
Trained batch 183 in epoch 9, gen_loss = 0.8633747505752937, disc_loss = 0.029197628788255235
Trained batch 184 in epoch 9, gen_loss = 0.8623334913640409, disc_loss = 0.02923364820135002
Trained batch 185 in epoch 9, gen_loss = 0.8609425201210924, disc_loss = 0.029413632844494636
Trained batch 186 in epoch 9, gen_loss = 0.8620493239897458, disc_loss = 0.029935054636664966
Trained batch 187 in epoch 9, gen_loss = 0.8625260807098226, disc_loss = 0.029886953637964946
Trained batch 188 in epoch 9, gen_loss = 0.8613584063671254, disc_loss = 0.030104796038743442
Trained batch 189 in epoch 9, gen_loss = 0.860601470344945, disc_loss = 0.03012252242770046
Trained batch 190 in epoch 9, gen_loss = 0.8610571847536177, disc_loss = 0.03012097241352093
Trained batch 191 in epoch 9, gen_loss = 0.8603964392095804, disc_loss = 0.030163166352091746
Trained batch 192 in epoch 9, gen_loss = 0.8594756799658345, disc_loss = 0.03013272917047722
Trained batch 193 in epoch 9, gen_loss = 0.8599737765862769, disc_loss = 0.030040225188113442
Trained batch 194 in epoch 9, gen_loss = 0.8592837847196139, disc_loss = 0.029988879864462293
Trained batch 195 in epoch 9, gen_loss = 0.8585319479509276, disc_loss = 0.030013288068347514
Trained batch 196 in epoch 9, gen_loss = 0.857924870428095, disc_loss = 0.0305198633554037
Trained batch 197 in epoch 9, gen_loss = 0.8565504021114774, disc_loss = 0.030761870340387704
Trained batch 198 in epoch 9, gen_loss = 0.8573527443948104, disc_loss = 0.03170356141454798
Trained batch 199 in epoch 9, gen_loss = 0.8564019030332566, disc_loss = 0.03180621547740884
Trained batch 200 in epoch 9, gen_loss = 0.8559838835872821, disc_loss = 0.03237476728193981
Trained batch 201 in epoch 9, gen_loss = 0.854662839138862, disc_loss = 0.03387832647249434
Trained batch 202 in epoch 9, gen_loss = 0.8534713954173873, disc_loss = 0.03635476850858646
Trained batch 203 in epoch 9, gen_loss = 0.853266162907376, disc_loss = 0.03766575738828739
Trained batch 204 in epoch 9, gen_loss = 0.852851572560101, disc_loss = 0.039821313849718466
Trained batch 205 in epoch 9, gen_loss = 0.8529969879145761, disc_loss = 0.0445329363749462
Trained batch 206 in epoch 9, gen_loss = 0.8538284678965951, disc_loss = 0.04682081957698624
Trained batch 207 in epoch 9, gen_loss = 0.8526926461893779, disc_loss = 0.04786305392917711
Trained batch 208 in epoch 9, gen_loss = 0.8517703408259524, disc_loss = 0.04844818779481263
Trained batch 209 in epoch 9, gen_loss = 0.8502322205475399, disc_loss = 0.049029046564274245
Trained batch 210 in epoch 9, gen_loss = 0.8491082835536432, disc_loss = 0.04967179836294839
Trained batch 211 in epoch 9, gen_loss = 0.8480556326092414, disc_loss = 0.05008171497128096
Trained batch 212 in epoch 9, gen_loss = 0.8465131280567725, disc_loss = 0.0503569370050403
Trained batch 213 in epoch 9, gen_loss = 0.8453857792872135, disc_loss = 0.05080290892592274
Trained batch 214 in epoch 9, gen_loss = 0.844730331731397, disc_loss = 0.05112183931023749
Trained batch 215 in epoch 9, gen_loss = 0.8438406390724359, disc_loss = 0.0513618369597545
Trained batch 216 in epoch 9, gen_loss = 0.842553622436963, disc_loss = 0.05161941482488083
Trained batch 217 in epoch 9, gen_loss = 0.841887007339285, disc_loss = 0.05205854525845156
Trained batch 218 in epoch 9, gen_loss = 0.8405458140590963, disc_loss = 0.05227233165105354
Trained batch 219 in epoch 9, gen_loss = 0.8398072689771652, disc_loss = 0.05233958808980374
Trained batch 220 in epoch 9, gen_loss = 0.8395755204679739, disc_loss = 0.053716960385214216
Trained batch 221 in epoch 9, gen_loss = 0.8379840713900488, disc_loss = 0.05434828484955302
Trained batch 222 in epoch 9, gen_loss = 0.8368653828787697, disc_loss = 0.054395739591551
Trained batch 223 in epoch 9, gen_loss = 0.8363420159689018, disc_loss = 0.0545280121909205
Trained batch 224 in epoch 9, gen_loss = 0.835882092581855, disc_loss = 0.054799582777130935
Trained batch 225 in epoch 9, gen_loss = 0.8350653719585553, disc_loss = 0.05495316942482033
Trained batch 226 in epoch 9, gen_loss = 0.834238142956721, disc_loss = 0.05519693586175301
Trained batch 227 in epoch 9, gen_loss = 0.8335314463627966, disc_loss = 0.055330221084755306
Trained batch 228 in epoch 9, gen_loss = 0.8329893829520613, disc_loss = 0.05526484601203694
Trained batch 229 in epoch 9, gen_loss = 0.8327693135842033, disc_loss = 0.055104192914238764
Trained batch 230 in epoch 9, gen_loss = 0.8320038715998331, disc_loss = 0.05503700126982516
Trained batch 231 in epoch 9, gen_loss = 0.8316960350192827, disc_loss = 0.05504043853203445
Trained batch 232 in epoch 9, gen_loss = 0.8312414083869673, disc_loss = 0.05498337002307208
Trained batch 233 in epoch 9, gen_loss = 0.8311500139216073, disc_loss = 0.055046694449738115
Trained batch 234 in epoch 9, gen_loss = 0.8304887259260137, disc_loss = 0.05496679963048627
Trained batch 235 in epoch 9, gen_loss = 0.8301247055247679, disc_loss = 0.05488137155869913
Trained batch 236 in epoch 9, gen_loss = 0.8301025241739136, disc_loss = 0.05490744855934715
Trained batch 237 in epoch 9, gen_loss = 0.829677333350943, disc_loss = 0.05483191552818479
Trained batch 238 in epoch 9, gen_loss = 0.8285516056555584, disc_loss = 0.05506194839702148
Trained batch 239 in epoch 9, gen_loss = 0.8285245284438133, disc_loss = 0.05503685594012495
Trained batch 240 in epoch 9, gen_loss = 0.8279238776052641, disc_loss = 0.05514356668717788
Trained batch 241 in epoch 9, gen_loss = 0.8281692123610126, disc_loss = 0.05515473902568006
Trained batch 242 in epoch 9, gen_loss = 0.8270367045461395, disc_loss = 0.05537394400582545
Trained batch 243 in epoch 9, gen_loss = 0.8271789975830766, disc_loss = 0.05525613222824654
Trained batch 244 in epoch 9, gen_loss = 0.826279920947795, disc_loss = 0.05536005117702393
Trained batch 245 in epoch 9, gen_loss = 0.825804643756975, disc_loss = 0.05530234174216091
Trained batch 246 in epoch 9, gen_loss = 0.8257551178758443, disc_loss = 0.055438018212592616
Trained batch 247 in epoch 9, gen_loss = 0.8255596470928961, disc_loss = 0.05568911143552301
Testing Epoch 9
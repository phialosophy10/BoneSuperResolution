/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 2.9989774227142334, disc_loss = 0.8759356141090393
Trained batch 1 in epoch 0, gen_loss = 2.889104962348938, disc_loss = 1.4157238900661469
Trained batch 2 in epoch 0, gen_loss = 2.8514602184295654, disc_loss = 1.1377342740694683
Trained batch 3 in epoch 0, gen_loss = 2.8356472849845886, disc_loss = 1.0145526677370071
Trained batch 4 in epoch 0, gen_loss = 2.8392269611358643, disc_loss = 0.9004810392856598
Trained batch 5 in epoch 0, gen_loss = 2.793908715248108, disc_loss = 0.8197812885046005
Trained batch 6 in epoch 0, gen_loss = 2.785585199083601, disc_loss = 0.7512875241892678
Trained batch 7 in epoch 0, gen_loss = 2.6881041526794434, disc_loss = 0.6958197541534901
Trained batch 8 in epoch 0, gen_loss = 2.6495238145192466, disc_loss = 0.646492772632175
Trained batch 9 in epoch 0, gen_loss = 2.616768217086792, disc_loss = 0.6048744842410088
Trained batch 10 in epoch 0, gen_loss = 2.6233175017616968, disc_loss = 0.5688514357263391
Trained batch 11 in epoch 0, gen_loss = 2.597647031148275, disc_loss = 0.5366228508452574
Trained batch 12 in epoch 0, gen_loss = 2.5538960053370547, disc_loss = 0.5068957347136277
Trained batch 13 in epoch 0, gen_loss = 2.5492489678519115, disc_loss = 0.482449010014534
Trained batch 14 in epoch 0, gen_loss = 2.535866864522298, disc_loss = 0.4594965875148773
Trained batch 15 in epoch 0, gen_loss = 2.513094574213028, disc_loss = 0.4403672628104687
Trained batch 16 in epoch 0, gen_loss = 2.4786726236343384, disc_loss = 0.42471811175346375
Trained batch 17 in epoch 0, gen_loss = 2.4663187861442566, disc_loss = 0.4088735307256381
Trained batch 18 in epoch 0, gen_loss = 2.456542309961821, disc_loss = 0.39213735571033076
Trained batch 19 in epoch 0, gen_loss = 2.4431640684604643, disc_loss = 0.37761099860072134
Trained batch 20 in epoch 0, gen_loss = 2.4472429014387584, disc_loss = 0.363182008266449
Trained batch 21 in epoch 0, gen_loss = 2.4389230717312205, disc_loss = 0.3497938049787825
Trained batch 22 in epoch 0, gen_loss = 2.4448997611584873, disc_loss = 0.33736082231220993
Trained batch 23 in epoch 0, gen_loss = 2.434812511006991, disc_loss = 0.3259510671099027
Trained batch 24 in epoch 0, gen_loss = 2.4195772790908814, disc_loss = 0.3154086439311504
Trained batch 25 in epoch 0, gen_loss = 2.4169035462232737, disc_loss = 0.305759563898811
Trained batch 26 in epoch 0, gen_loss = 2.408444294223079, disc_loss = 0.2965566406923312
Trained batch 27 in epoch 0, gen_loss = 2.399366340466908, disc_loss = 0.2877850452704089
Trained batch 28 in epoch 0, gen_loss = 2.390020185503466, disc_loss = 0.27963626718726653
Trained batch 29 in epoch 0, gen_loss = 2.3803513805071512, disc_loss = 0.2718123123049736
Trained batch 30 in epoch 0, gen_loss = 2.3724230912423905, disc_loss = 0.2643574490662544
Trained batch 31 in epoch 0, gen_loss = 2.365513753145933, disc_loss = 0.25737584836315364
Trained batch 32 in epoch 0, gen_loss = 2.355481252525792, disc_loss = 0.25127593100522505
Trained batch 33 in epoch 0, gen_loss = 2.3527816148365246, disc_loss = 0.24569991482969591
Trained batch 34 in epoch 0, gen_loss = 2.3561307191848755, disc_loss = 0.24124320287789616
Trained batch 35 in epoch 0, gen_loss = 2.3517069584793515, disc_loss = 0.23756404065837464
Trained batch 36 in epoch 0, gen_loss = 2.3445716194204382, disc_loss = 0.2332248004103029
Trained batch 37 in epoch 0, gen_loss = 2.3433773486237777, disc_loss = 0.22825413795286104
Trained batch 38 in epoch 0, gen_loss = 2.3393122935906434, disc_loss = 0.22335726242416945
Trained batch 39 in epoch 0, gen_loss = 2.338298645615578, disc_loss = 0.2187071499414742
Trained batch 40 in epoch 0, gen_loss = 2.3386903477878107, disc_loss = 0.21432688614217246
Trained batch 41 in epoch 0, gen_loss = 2.3357449117160978, disc_loss = 0.210016390131343
Trained batch 42 in epoch 0, gen_loss = 2.3280745966489924, disc_loss = 0.20574069854825042
Trained batch 43 in epoch 0, gen_loss = 2.319234772162004, disc_loss = 0.20180466991256585
Trained batch 44 in epoch 0, gen_loss = 2.3177881876627606, disc_loss = 0.19789315416581102
Trained batch 45 in epoch 0, gen_loss = 2.31089098557182, disc_loss = 0.19418970932779106
Trained batch 46 in epoch 0, gen_loss = 2.3144484885195467, disc_loss = 0.19056306858646108
Trained batch 47 in epoch 0, gen_loss = 2.31463556488355, disc_loss = 0.18735506121690074
Trained batch 48 in epoch 0, gen_loss = 2.307230754774444, disc_loss = 0.18409320050660444
Trained batch 49 in epoch 0, gen_loss = 2.305982370376587, disc_loss = 0.1808803543448448
Trained batch 50 in epoch 0, gen_loss = 2.305920381172031, disc_loss = 0.17777658100513852
Trained batch 51 in epoch 0, gen_loss = 2.3017946023207445, disc_loss = 0.17479085166437122
Trained batch 52 in epoch 0, gen_loss = 2.2968212928412095, disc_loss = 0.17197947320089024
Trained batch 53 in epoch 0, gen_loss = 2.2933926494033248, disc_loss = 0.16924912082376303
Trained batch 54 in epoch 0, gen_loss = 2.289811949296431, disc_loss = 0.16661935506219214
Trained batch 55 in epoch 0, gen_loss = 2.286076788391386, disc_loss = 0.1641118320569928
Trained batch 56 in epoch 0, gen_loss = 2.2853480723866246, disc_loss = 0.16164508831213442
Trained batch 57 in epoch 0, gen_loss = 2.2786208987236023, disc_loss = 0.1593291070954553
Trained batch 58 in epoch 0, gen_loss = 2.2819689673892523, disc_loss = 0.15734376341609632
Trained batch 59 in epoch 0, gen_loss = 2.2790998121102652, disc_loss = 0.1551824093175431
Trained batch 60 in epoch 0, gen_loss = 2.273557715728635, disc_loss = 0.15294129697636502
Trained batch 61 in epoch 0, gen_loss = 2.2701921943695313, disc_loss = 0.15081957045702205
Trained batch 62 in epoch 0, gen_loss = 2.2656662028933328, disc_loss = 0.14871632943432483
Trained batch 63 in epoch 0, gen_loss = 2.2655651811510324, disc_loss = 0.14674850340816192
Trained batch 64 in epoch 0, gen_loss = 2.2614506483078003, disc_loss = 0.14485089030976478
Trained batch 65 in epoch 0, gen_loss = 2.2570446422605803, disc_loss = 0.14301005409409603
Trained batch 66 in epoch 0, gen_loss = 2.252701371463377, disc_loss = 0.14118842758349517
Trained batch 67 in epoch 0, gen_loss = 2.2510646967326893, disc_loss = 0.13943230870234616
Trained batch 68 in epoch 0, gen_loss = 2.250164837077044, disc_loss = 0.13767597953910413
Trained batch 69 in epoch 0, gen_loss = 2.2487473011016847, disc_loss = 0.13594821436064583
Trained batch 70 in epoch 0, gen_loss = 2.2499113485846722, disc_loss = 0.13426692217168673
Trained batch 71 in epoch 0, gen_loss = 2.2433444129096136, disc_loss = 0.13264678703207108
Trained batch 72 in epoch 0, gen_loss = 2.238740034299354, disc_loss = 0.13113690963754915
Trained batch 73 in epoch 0, gen_loss = 2.2315751394710026, disc_loss = 0.12963080635243976
Trained batch 74 in epoch 0, gen_loss = 2.2332182614008587, disc_loss = 0.12816361350317795
Trained batch 75 in epoch 0, gen_loss = 2.2271666275827506, disc_loss = 0.12688044421864966
Trained batch 76 in epoch 0, gen_loss = 2.224347548051314, disc_loss = 0.12556048886632765
Trained batch 77 in epoch 0, gen_loss = 2.2195636737040982, disc_loss = 0.12423321530700494
Trained batch 78 in epoch 0, gen_loss = 2.2148704377910757, disc_loss = 0.12290048259723035
Trained batch 79 in epoch 0, gen_loss = 2.2171772480010987, disc_loss = 0.12159904167056083
Trained batch 80 in epoch 0, gen_loss = 2.213925020194348, disc_loss = 0.12031439595200398
Trained batch 81 in epoch 0, gen_loss = 2.208355766970937, disc_loss = 0.11903802911955409
Trained batch 82 in epoch 0, gen_loss = 2.2085650627871596, disc_loss = 0.11778284111116306
Trained batch 83 in epoch 0, gen_loss = 2.2126500549770536, disc_loss = 0.11659150045099002
Trained batch 84 in epoch 0, gen_loss = 2.2080384562997257, disc_loss = 0.11547535988776123
Trained batch 85 in epoch 0, gen_loss = 2.2053760969361593, disc_loss = 0.11441390974403814
Trained batch 86 in epoch 0, gen_loss = 2.209520141283671, disc_loss = 0.11333949243028958
Trained batch 87 in epoch 0, gen_loss = 2.2078434269536626, disc_loss = 0.1122384255074642
Trained batch 88 in epoch 0, gen_loss = 2.206910836562682, disc_loss = 0.11116775043643592
Trained batch 89 in epoch 0, gen_loss = 2.2069396085209316, disc_loss = 0.11017896166692177
Trained batch 90 in epoch 0, gen_loss = 2.2089893359404345, disc_loss = 0.10919790045655035
Trained batch 91 in epoch 0, gen_loss = 2.2090409359206324, disc_loss = 0.10822132956641524
Trained batch 92 in epoch 0, gen_loss = 2.2070180716053134, disc_loss = 0.10734982077553067
Trained batch 93 in epoch 0, gen_loss = 2.2055959333764745, disc_loss = 0.10646627805730764
Trained batch 94 in epoch 0, gen_loss = 2.204387944623044, disc_loss = 0.10554986825506939
Trained batch 95 in epoch 0, gen_loss = 2.201749302446842, disc_loss = 0.1046334962787417
Trained batch 96 in epoch 0, gen_loss = 2.205050200531163, disc_loss = 0.10372793689831016
Trained batch 97 in epoch 0, gen_loss = 2.2053370621739603, disc_loss = 0.10287773050367832
Trained batch 98 in epoch 0, gen_loss = 2.2051654295487837, disc_loss = 0.1020169851153788
Trained batch 99 in epoch 0, gen_loss = 2.205473389625549, disc_loss = 0.10112958419136703
Trained batch 100 in epoch 0, gen_loss = 2.2019216707437343, disc_loss = 0.10027157992936007
Trained batch 101 in epoch 0, gen_loss = 2.201048832313687, disc_loss = 0.09945665097192806
Trained batch 102 in epoch 0, gen_loss = 2.2007038107196104, disc_loss = 0.09864716049175239
Trained batch 103 in epoch 0, gen_loss = 2.201063355574241, disc_loss = 0.09782354028608936
Trained batch 104 in epoch 0, gen_loss = 2.2031801541646323, disc_loss = 0.09703049168345473
Trained batch 105 in epoch 0, gen_loss = 2.2036543882118083, disc_loss = 0.09625470269260542
Trained batch 106 in epoch 0, gen_loss = 2.20359455313638, disc_loss = 0.09550252805733792
Trained batch 107 in epoch 0, gen_loss = 2.201120217641195, disc_loss = 0.09478121062878657
Trained batch 108 in epoch 0, gen_loss = 2.2011061108440435, disc_loss = 0.09405272447187966
Trained batch 109 in epoch 0, gen_loss = 2.2053501627661967, disc_loss = 0.09335204994475299
Trained batch 110 in epoch 0, gen_loss = 2.2047787700687445, disc_loss = 0.09265462787368813
Trained batch 111 in epoch 0, gen_loss = 2.205443407808031, disc_loss = 0.09198306971562228
Trained batch 112 in epoch 0, gen_loss = 2.204299487898835, disc_loss = 0.09129487634924925
Trained batch 113 in epoch 0, gen_loss = 2.2031870745775994, disc_loss = 0.09060207459454735
Trained batch 114 in epoch 0, gen_loss = 2.2040346187093984, disc_loss = 0.08992857533790495
Trained batch 115 in epoch 0, gen_loss = 2.204879261296371, disc_loss = 0.0892727956223976
Trained batch 116 in epoch 0, gen_loss = 2.201260398595761, disc_loss = 0.08864614234552678
Trained batch 117 in epoch 0, gen_loss = 2.1981167490199462, disc_loss = 0.08801761664986862
Trained batch 118 in epoch 0, gen_loss = 2.197605738118917, disc_loss = 0.0873890979090283
Trained batch 119 in epoch 0, gen_loss = 2.1960758169492087, disc_loss = 0.08678877286147327
Trained batch 120 in epoch 0, gen_loss = 2.1958093682596505, disc_loss = 0.08617957179580839
Trained batch 121 in epoch 0, gen_loss = 2.196620919665352, disc_loss = 0.08556139001958683
Trained batch 122 in epoch 0, gen_loss = 2.1971626068518413, disc_loss = 0.08496345487249092
Trained batch 123 in epoch 0, gen_loss = 2.1996106313120936, disc_loss = 0.08437621839825184
Trained batch 124 in epoch 0, gen_loss = 2.203736394882202, disc_loss = 0.083788908213377
Trained batch 125 in epoch 0, gen_loss = 2.2049651259467717, disc_loss = 0.08323850609096033
Trained batch 126 in epoch 0, gen_loss = 2.205593126026664, disc_loss = 0.08270922193934363
Trained batch 127 in epoch 0, gen_loss = 2.2057195976376534, disc_loss = 0.08217550730478251
Trained batch 128 in epoch 0, gen_loss = 2.2067893808202226, disc_loss = 0.08164502415344004
Trained batch 129 in epoch 0, gen_loss = 2.20564248745258, disc_loss = 0.08115415513658752
Trained batch 130 in epoch 0, gen_loss = 2.20372964316652, disc_loss = 0.08068048132882091
Trained batch 131 in epoch 0, gen_loss = 2.203330931338397, disc_loss = 0.08024136883658216
Trained batch 132 in epoch 0, gen_loss = 2.2019030303883373, disc_loss = 0.0797769056521076
Trained batch 133 in epoch 0, gen_loss = 2.2005120827190914, disc_loss = 0.07927591696298167
Trained batch 134 in epoch 0, gen_loss = 2.1976282676060994, disc_loss = 0.07879328234466138
Trained batch 135 in epoch 0, gen_loss = 2.19652752227643, disc_loss = 0.07833769537426312
Trained batch 136 in epoch 0, gen_loss = 2.197434168662468, disc_loss = 0.07786204670657859
Trained batch 137 in epoch 0, gen_loss = 2.1974998099216516, disc_loss = 0.07736915095533797
Trained batch 138 in epoch 0, gen_loss = 2.1964219671359166, disc_loss = 0.07688842519528145
Trained batch 139 in epoch 0, gen_loss = 2.197287151643208, disc_loss = 0.0764205131081066
Trained batch 140 in epoch 0, gen_loss = 2.1957000806822, disc_loss = 0.07596625943159592
Trained batch 141 in epoch 0, gen_loss = 2.192307805511313, disc_loss = 0.07551987000255728
Trained batch 142 in epoch 0, gen_loss = 2.1943989742052303, disc_loss = 0.07507006056163903
Trained batch 143 in epoch 0, gen_loss = 2.192460155321492, disc_loss = 0.0746316800165611
Trained batch 144 in epoch 0, gen_loss = 2.194521661462455, disc_loss = 0.07421552291589564
Trained batch 145 in epoch 0, gen_loss = 2.193899253459826, disc_loss = 0.07379826341360195
Trained batch 146 in epoch 0, gen_loss = 2.1948463827574334, disc_loss = 0.07337211552677916
Trained batch 147 in epoch 0, gen_loss = 2.193385713003777, disc_loss = 0.0729526801575982
Trained batch 148 in epoch 0, gen_loss = 2.192168079766651, disc_loss = 0.07254071421171195
Trained batch 149 in epoch 0, gen_loss = 2.190800731976827, disc_loss = 0.07215024168292682
Trained batch 150 in epoch 0, gen_loss = 2.18960907917149, disc_loss = 0.0717535459541327
Trained batch 151 in epoch 0, gen_loss = 2.1895983830878607, disc_loss = 0.07134294966971011
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.097083330154419, disc_loss = 0.007713135797530413
Trained batch 1 in epoch 1, gen_loss = 2.1068822145462036, disc_loss = 0.007635185262188315
Trained batch 2 in epoch 1, gen_loss = 2.1883676846822104, disc_loss = 0.007618688978254795
Trained batch 3 in epoch 1, gen_loss = 2.116401880979538, disc_loss = 0.007894975831732154
Trained batch 4 in epoch 1, gen_loss = 2.161148476600647, disc_loss = 0.008384975977241993
Trained batch 5 in epoch 1, gen_loss = 2.1355239351590476, disc_loss = 0.008794349463035664
Trained batch 6 in epoch 1, gen_loss = 2.144543698855809, disc_loss = 0.008690668403037958
Trained batch 7 in epoch 1, gen_loss = 2.160327360033989, disc_loss = 0.008466711966320872
Trained batch 8 in epoch 1, gen_loss = 2.171744015481737, disc_loss = 0.008298262850277953
Trained batch 9 in epoch 1, gen_loss = 2.1591133952140806, disc_loss = 0.008178368955850602
Trained batch 10 in epoch 1, gen_loss = 2.1381215073845605, disc_loss = 0.008106344125487587
Trained batch 11 in epoch 1, gen_loss = 2.1418195267518363, disc_loss = 0.00802281863677005
Trained batch 12 in epoch 1, gen_loss = 2.148295466716473, disc_loss = 0.007948526038000217
Trained batch 13 in epoch 1, gen_loss = 2.169729769229889, disc_loss = 0.007862946184884225
Trained batch 14 in epoch 1, gen_loss = 2.1758013010025024, disc_loss = 0.007914518099278211
Trained batch 15 in epoch 1, gen_loss = 2.157926805317402, disc_loss = 0.007891939050750807
Trained batch 16 in epoch 1, gen_loss = 2.155033399077023, disc_loss = 0.00788955157622695
Trained batch 17 in epoch 1, gen_loss = 2.1427853571044073, disc_loss = 0.007919089325393239
Trained batch 18 in epoch 1, gen_loss = 2.132503729117544, disc_loss = 0.00790028227493167
Trained batch 19 in epoch 1, gen_loss = 2.1422465264797212, disc_loss = 0.007804445433430373
Trained batch 20 in epoch 1, gen_loss = 2.1528266895385015, disc_loss = 0.00769202018688832
Trained batch 21 in epoch 1, gen_loss = 2.1468060395934363, disc_loss = 0.007575001821599223
Trained batch 22 in epoch 1, gen_loss = 2.13861172095589, disc_loss = 0.0074620031873169155
Trained batch 23 in epoch 1, gen_loss = 2.13944011926651, disc_loss = 0.0073603924829512835
Trained batch 24 in epoch 1, gen_loss = 2.1462134456634523, disc_loss = 0.00732867693528533
Trained batch 25 in epoch 1, gen_loss = 2.1385284066200256, disc_loss = 0.00729705087052515
Trained batch 26 in epoch 1, gen_loss = 2.136316763030158, disc_loss = 0.007394705088464198
Trained batch 27 in epoch 1, gen_loss = 2.141174848590578, disc_loss = 0.007530045745495174
Trained batch 28 in epoch 1, gen_loss = 2.13587053890886, disc_loss = 0.007569048666106215
Trained batch 29 in epoch 1, gen_loss = 2.1388156096140545, disc_loss = 0.007504243589937687
Trained batch 30 in epoch 1, gen_loss = 2.131437243953828, disc_loss = 0.007455121815925644
Trained batch 31 in epoch 1, gen_loss = 2.1366310007870197, disc_loss = 0.007467449264368042
Trained batch 32 in epoch 1, gen_loss = 2.130565556612882, disc_loss = 0.007528627883981575
Trained batch 33 in epoch 1, gen_loss = 2.1323560336056877, disc_loss = 0.007513788569828167
Trained batch 34 in epoch 1, gen_loss = 2.1186093432562694, disc_loss = 0.007514966132917574
Trained batch 35 in epoch 1, gen_loss = 2.1122452451123133, disc_loss = 0.007572582366669344
Trained batch 36 in epoch 1, gen_loss = 2.1042191080144934, disc_loss = 0.007598739633387005
Trained batch 37 in epoch 1, gen_loss = 2.1097777705443534, disc_loss = 0.007562699323323996
Trained batch 38 in epoch 1, gen_loss = 2.119073659945757, disc_loss = 0.007548465978545256
Trained batch 39 in epoch 1, gen_loss = 2.1226128697395326, disc_loss = 0.007506323512643576
Trained batch 40 in epoch 1, gen_loss = 2.1244976985745314, disc_loss = 0.0074808393241610465
Trained batch 41 in epoch 1, gen_loss = 2.1295437131609236, disc_loss = 0.007454712542572192
Trained batch 42 in epoch 1, gen_loss = 2.1222706035126087, disc_loss = 0.007424802876749011
Trained batch 43 in epoch 1, gen_loss = 2.117544721473347, disc_loss = 0.00741051853930747
Trained batch 44 in epoch 1, gen_loss = 2.119791020287408, disc_loss = 0.007356579156799449
Trained batch 45 in epoch 1, gen_loss = 2.1186776679495107, disc_loss = 0.007331336180315069
Trained batch 46 in epoch 1, gen_loss = 2.1166911531001964, disc_loss = 0.007299264258843787
Trained batch 47 in epoch 1, gen_loss = 2.112811103463173, disc_loss = 0.0072738163483639555
Trained batch 48 in epoch 1, gen_loss = 2.1103849556981302, disc_loss = 0.00726172614994706
Trained batch 49 in epoch 1, gen_loss = 2.11428795337677, disc_loss = 0.0072216917760670185
Trained batch 50 in epoch 1, gen_loss = 2.1110057223076915, disc_loss = 0.007231699576710954
Trained batch 51 in epoch 1, gen_loss = 2.108561469958379, disc_loss = 0.007289021078927012
Trained batch 52 in epoch 1, gen_loss = 2.1108173739235356, disc_loss = 0.007311676277445172
Trained batch 53 in epoch 1, gen_loss = 2.1151952566923917, disc_loss = 0.007297239145608964
Trained batch 54 in epoch 1, gen_loss = 2.1139287905259567, disc_loss = 0.0072488798505880615
Trained batch 55 in epoch 1, gen_loss = 2.114067933389119, disc_loss = 0.0072109123741808745
Trained batch 56 in epoch 1, gen_loss = 2.112984113525926, disc_loss = 0.007163155039674358
Trained batch 57 in epoch 1, gen_loss = 2.110734861472557, disc_loss = 0.007147011788690399
Trained batch 58 in epoch 1, gen_loss = 2.1074026115870073, disc_loss = 0.007143957635103646
Trained batch 59 in epoch 1, gen_loss = 2.1102793415387473, disc_loss = 0.007138178249200185
Trained batch 60 in epoch 1, gen_loss = 2.1151445576402006, disc_loss = 0.007088310268448025
Trained batch 61 in epoch 1, gen_loss = 2.112942397594452, disc_loss = 0.0070583939687499115
Trained batch 62 in epoch 1, gen_loss = 2.113848150722564, disc_loss = 0.007072660428959699
Trained batch 63 in epoch 1, gen_loss = 2.1127207074314356, disc_loss = 0.007078885326336604
Trained batch 64 in epoch 1, gen_loss = 2.1098816651564376, disc_loss = 0.00707708984756699
Trained batch 65 in epoch 1, gen_loss = 2.109458504301129, disc_loss = 0.007073921532454816
Trained batch 66 in epoch 1, gen_loss = 2.1054997337398245, disc_loss = 0.007049570714971467
Trained batch 67 in epoch 1, gen_loss = 2.107772104880389, disc_loss = 0.007030393941985334
Trained batch 68 in epoch 1, gen_loss = 2.1074556786081065, disc_loss = 0.006994868223757848
Trained batch 69 in epoch 1, gen_loss = 2.1040472269058226, disc_loss = 0.006965602435437697
Trained batch 70 in epoch 1, gen_loss = 2.1040718018169136, disc_loss = 0.006939240383692611
Trained batch 71 in epoch 1, gen_loss = 2.1018334511253567, disc_loss = 0.006909622196366804
Trained batch 72 in epoch 1, gen_loss = 2.103796601295471, disc_loss = 0.006880732374393368
Trained batch 73 in epoch 1, gen_loss = 2.1018709894773124, disc_loss = 0.006835199423713257
Trained batch 74 in epoch 1, gen_loss = 2.1006665245691933, disc_loss = 0.006798031333213051
Trained batch 75 in epoch 1, gen_loss = 2.1013940055119362, disc_loss = 0.006768185378812058
Trained batch 76 in epoch 1, gen_loss = 2.101670598054861, disc_loss = 0.0067559298545170525
Trained batch 77 in epoch 1, gen_loss = 2.100899037642357, disc_loss = 0.006774304067501082
Trained batch 78 in epoch 1, gen_loss = 2.1018876078762587, disc_loss = 0.006814205326446438
Trained batch 79 in epoch 1, gen_loss = 2.105717344582081, disc_loss = 0.006838183270883746
Trained batch 80 in epoch 1, gen_loss = 2.1050534851757097, disc_loss = 0.006837176161898691
Trained batch 81 in epoch 1, gen_loss = 2.1050128224419384, disc_loss = 0.006828112905368027
Trained batch 82 in epoch 1, gen_loss = 2.1037012195012657, disc_loss = 0.00680700981574335
Trained batch 83 in epoch 1, gen_loss = 2.10418634613355, disc_loss = 0.006770548100272815
Trained batch 84 in epoch 1, gen_loss = 2.099211159874411, disc_loss = 0.006741985388319282
Trained batch 85 in epoch 1, gen_loss = 2.101304475651231, disc_loss = 0.006704336405883349
Trained batch 86 in epoch 1, gen_loss = 2.101866387772834, disc_loss = 0.006669341688226351
Trained batch 87 in epoch 1, gen_loss = 2.099909324537624, disc_loss = 0.006642016529274935
Trained batch 88 in epoch 1, gen_loss = 2.1015283338139565, disc_loss = 0.006622173849576979
Trained batch 89 in epoch 1, gen_loss = 2.102452050315009, disc_loss = 0.006603815665261613
Trained batch 90 in epoch 1, gen_loss = 2.1016129739991913, disc_loss = 0.006591367084983286
Trained batch 91 in epoch 1, gen_loss = 2.0997324598872145, disc_loss = 0.006561338228335523
Trained batch 92 in epoch 1, gen_loss = 2.099588110882749, disc_loss = 0.00652731052269378
Trained batch 93 in epoch 1, gen_loss = 2.100280618413966, disc_loss = 0.006510106985397795
Trained batch 94 in epoch 1, gen_loss = 2.103054454452113, disc_loss = 0.006480410891143899
Trained batch 95 in epoch 1, gen_loss = 2.1005744511882463, disc_loss = 0.006457847426645458
Trained batch 96 in epoch 1, gen_loss = 2.1060090384532497, disc_loss = 0.006456327586213953
Trained batch 97 in epoch 1, gen_loss = 2.1048142204479294, disc_loss = 0.006439111670669244
Trained batch 98 in epoch 1, gen_loss = 2.0982017324428366, disc_loss = 0.006437761408060488
Trained batch 99 in epoch 1, gen_loss = 2.0967654514312746, disc_loss = 0.006422988213598728
Trained batch 100 in epoch 1, gen_loss = 2.09432055336414, disc_loss = 0.006397703196853399
Trained batch 101 in epoch 1, gen_loss = 2.092450677179823, disc_loss = 0.006367576710295444
Trained batch 102 in epoch 1, gen_loss = 2.0891721179184404, disc_loss = 0.006342011639504757
Trained batch 103 in epoch 1, gen_loss = 2.0913061705919413, disc_loss = 0.006315932206164759
Trained batch 104 in epoch 1, gen_loss = 2.0901872634887697, disc_loss = 0.006290219910442829
Trained batch 105 in epoch 1, gen_loss = 2.0906392650784187, disc_loss = 0.006282726706901811
Trained batch 106 in epoch 1, gen_loss = 2.0920447367374027, disc_loss = 0.0062950974782911414
Trained batch 107 in epoch 1, gen_loss = 2.0945443753842956, disc_loss = 0.006283474469522911
Trained batch 108 in epoch 1, gen_loss = 2.0931065782494502, disc_loss = 0.006287556957590197
Trained batch 109 in epoch 1, gen_loss = 2.091883035139604, disc_loss = 0.006281177839264273
Trained batch 110 in epoch 1, gen_loss = 2.0897439213486404, disc_loss = 0.006290943676454795
Trained batch 111 in epoch 1, gen_loss = 2.085067654294627, disc_loss = 0.006289667645303
Trained batch 112 in epoch 1, gen_loss = 2.085095493139419, disc_loss = 0.006280213334820176
Trained batch 113 in epoch 1, gen_loss = 2.0840775998015153, disc_loss = 0.006253486856605792
Trained batch 114 in epoch 1, gen_loss = 2.0829076549281247, disc_loss = 0.006225050550521068
Trained batch 115 in epoch 1, gen_loss = 2.0822710980629098, disc_loss = 0.006198827677069168
Trained batch 116 in epoch 1, gen_loss = 2.0805224628529997, disc_loss = 0.00618165702972975
Trained batch 117 in epoch 1, gen_loss = 2.0842330708342085, disc_loss = 0.006174108587694749
Trained batch 118 in epoch 1, gen_loss = 2.079897923629825, disc_loss = 0.006150601324116608
Trained batch 119 in epoch 1, gen_loss = 2.0798310309648516, disc_loss = 0.006132030384227012
Trained batch 120 in epoch 1, gen_loss = 2.0794615893324546, disc_loss = 0.006118283401174117
Trained batch 121 in epoch 1, gen_loss = 2.0781074088127887, disc_loss = 0.006098487496482911
Trained batch 122 in epoch 1, gen_loss = 2.0802196826392074, disc_loss = 0.006077221083659224
Trained batch 123 in epoch 1, gen_loss = 2.0822996852859372, disc_loss = 0.006057631847779116
Trained batch 124 in epoch 1, gen_loss = 2.080541971206665, disc_loss = 0.006034165797755123
Trained batch 125 in epoch 1, gen_loss = 2.078484094332135, disc_loss = 0.006016708498391959
Trained batch 126 in epoch 1, gen_loss = 2.075925233795887, disc_loss = 0.006002889617940221
Trained batch 127 in epoch 1, gen_loss = 2.07771317102015, disc_loss = 0.005985874495308963
Trained batch 128 in epoch 1, gen_loss = 2.0773356589236003, disc_loss = 0.005970994582717386
Trained batch 129 in epoch 1, gen_loss = 2.0764799631558932, disc_loss = 0.0059678563221286125
Trained batch 130 in epoch 1, gen_loss = 2.0795228499492615, disc_loss = 0.005951085781948712
Trained batch 131 in epoch 1, gen_loss = 2.0776087054700563, disc_loss = 0.005932324664723693
Trained batch 132 in epoch 1, gen_loss = 2.076282102362554, disc_loss = 0.005929532411851381
Trained batch 133 in epoch 1, gen_loss = 2.0763783623923118, disc_loss = 0.0059214766874019775
Trained batch 134 in epoch 1, gen_loss = 2.076683831214905, disc_loss = 0.0058999313714189665
Trained batch 135 in epoch 1, gen_loss = 2.076064509503982, disc_loss = 0.005885197181829854
Trained batch 136 in epoch 1, gen_loss = 2.0745899790394917, disc_loss = 0.005870185027673949
Trained batch 137 in epoch 1, gen_loss = 2.073234787021858, disc_loss = 0.00585267905726273
Trained batch 138 in epoch 1, gen_loss = 2.0726806491398984, disc_loss = 0.005840672652418021
Trained batch 139 in epoch 1, gen_loss = 2.073507066283907, disc_loss = 0.0058223695860111285
Trained batch 140 in epoch 1, gen_loss = 2.071529652209992, disc_loss = 0.005804808952363459
Trained batch 141 in epoch 1, gen_loss = 2.0739190914261507, disc_loss = 0.00578606327910396
Trained batch 142 in epoch 1, gen_loss = 2.0747452765911607, disc_loss = 0.005766927236951627
Trained batch 143 in epoch 1, gen_loss = 2.0753921071688333, disc_loss = 0.005755054038470714
Trained batch 144 in epoch 1, gen_loss = 2.0765448586694126, disc_loss = 0.005742883687068163
Trained batch 145 in epoch 1, gen_loss = 2.0745494431012297, disc_loss = 0.005734440827525336
Trained batch 146 in epoch 1, gen_loss = 2.076552322932652, disc_loss = 0.0057193096838004534
Trained batch 147 in epoch 1, gen_loss = 2.075533371519398, disc_loss = 0.005709182645659894
Trained batch 148 in epoch 1, gen_loss = 2.073385054633121, disc_loss = 0.00569625446985432
Trained batch 149 in epoch 1, gen_loss = 2.074305985768636, disc_loss = 0.005678402598326405
Trained batch 150 in epoch 1, gen_loss = 2.076281926489824, disc_loss = 0.005661003223762212
Trained batch 151 in epoch 1, gen_loss = 2.0764217047314895, disc_loss = 0.005641543474906173
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.31007719039917, disc_loss = 0.00216380855999887
Trained batch 1 in epoch 2, gen_loss = 2.2019731998443604, disc_loss = 0.002347528119571507
Trained batch 2 in epoch 2, gen_loss = 2.071387688318888, disc_loss = 0.0026220968769242368
Trained batch 3 in epoch 2, gen_loss = 2.074510157108307, disc_loss = 0.0028240264509804547
Trained batch 4 in epoch 2, gen_loss = 2.05050151348114, disc_loss = 0.0029714623000472785
Trained batch 5 in epoch 2, gen_loss = 2.0390692949295044, disc_loss = 0.00295390619430691
Trained batch 6 in epoch 2, gen_loss = 2.014725923538208, disc_loss = 0.003003547866163509
Trained batch 7 in epoch 2, gen_loss = 1.9866600185632706, disc_loss = 0.0030845134460832924
Trained batch 8 in epoch 2, gen_loss = 1.9809639586342707, disc_loss = 0.0031859017649872434
Trained batch 9 in epoch 2, gen_loss = 1.9787798643112182, disc_loss = 0.0032318410463631152
Trained batch 10 in epoch 2, gen_loss = 2.010469740087336, disc_loss = 0.003355922262099656
Trained batch 11 in epoch 2, gen_loss = 2.019830803076426, disc_loss = 0.0035309236651907363
Trained batch 12 in epoch 2, gen_loss = 2.0276158589583178, disc_loss = 0.0036660568215526068
Trained batch 13 in epoch 2, gen_loss = 2.024950844900949, disc_loss = 0.003713189491203853
Trained batch 14 in epoch 2, gen_loss = 2.0376654624938966, disc_loss = 0.003766504426797231
Trained batch 15 in epoch 2, gen_loss = 2.050047606229782, disc_loss = 0.0037400612782221287
Trained batch 16 in epoch 2, gen_loss = 2.062631873523488, disc_loss = 0.003713442642679986
Trained batch 17 in epoch 2, gen_loss = 2.0620796150631375, disc_loss = 0.0037069465421761074
Trained batch 18 in epoch 2, gen_loss = 2.073603956322921, disc_loss = 0.0036435723917460756
Trained batch 19 in epoch 2, gen_loss = 2.0557608366012574, disc_loss = 0.0036706966697238387
Trained batch 20 in epoch 2, gen_loss = 2.060708897454398, disc_loss = 0.0037432816655685506
Trained batch 21 in epoch 2, gen_loss = 2.0511959574439307, disc_loss = 0.0037534129911695013
Trained batch 22 in epoch 2, gen_loss = 2.059551778046981, disc_loss = 0.003733010648790261
Trained batch 23 in epoch 2, gen_loss = 2.0553590953350067, disc_loss = 0.0037466507540860525
Trained batch 24 in epoch 2, gen_loss = 2.056760768890381, disc_loss = 0.003753559337928891
Trained batch 25 in epoch 2, gen_loss = 2.0472022753495436, disc_loss = 0.0037274728529155254
Trained batch 26 in epoch 2, gen_loss = 2.0405895047717624, disc_loss = 0.003782977677743744
Trained batch 27 in epoch 2, gen_loss = 2.035525198493685, disc_loss = 0.0038726076516988023
Trained batch 28 in epoch 2, gen_loss = 2.0413601357361366, disc_loss = 0.0038354779786333956
Trained batch 29 in epoch 2, gen_loss = 2.048938564459483, disc_loss = 0.0038597072940319776
Trained batch 30 in epoch 2, gen_loss = 2.0505495571321055, disc_loss = 0.0038711230510905864
Trained batch 31 in epoch 2, gen_loss = 2.066468831151724, disc_loss = 0.003906191443093121
Trained batch 32 in epoch 2, gen_loss = 2.0687900492639253, disc_loss = 0.003978461351697192
Trained batch 33 in epoch 2, gen_loss = 2.071760153069216, disc_loss = 0.0039689435335971855
Trained batch 34 in epoch 2, gen_loss = 2.06764361177172, disc_loss = 0.003971411108172365
Trained batch 35 in epoch 2, gen_loss = 2.0617535842789545, disc_loss = 0.003994138607393122
Trained batch 36 in epoch 2, gen_loss = 2.0613515377044678, disc_loss = 0.00405518984346575
Trained batch 37 in epoch 2, gen_loss = 2.076016426086426, disc_loss = 0.004073362386981516
Trained batch 38 in epoch 2, gen_loss = 2.0732515225043664, disc_loss = 0.004055701655884966
Trained batch 39 in epoch 2, gen_loss = 2.0740526020526886, disc_loss = 0.004042723000748083
Trained batch 40 in epoch 2, gen_loss = 2.065965969388078, disc_loss = 0.004016077776280482
Trained batch 41 in epoch 2, gen_loss = 2.0667084597405934, disc_loss = 0.004089391452171618
Trained batch 42 in epoch 2, gen_loss = 2.065064785092376, disc_loss = 0.004198193306449887
Trained batch 43 in epoch 2, gen_loss = 2.0634337717836555, disc_loss = 0.004190759585154327
Trained batch 44 in epoch 2, gen_loss = 2.059410540262858, disc_loss = 0.004209361370238993
Trained batch 45 in epoch 2, gen_loss = 2.0586947980134385, disc_loss = 0.004275952536693733
Trained batch 46 in epoch 2, gen_loss = 2.06736037071715, disc_loss = 0.00428365771361488
Trained batch 47 in epoch 2, gen_loss = 2.070041169722875, disc_loss = 0.004263843933586031
Trained batch 48 in epoch 2, gen_loss = 2.0658775640993703, disc_loss = 0.0042517031162825165
Trained batch 49 in epoch 2, gen_loss = 2.0675791358947753, disc_loss = 0.0042269400181248785
Trained batch 50 in epoch 2, gen_loss = 2.0713064810808968, disc_loss = 0.0042179222994794445
Trained batch 51 in epoch 2, gen_loss = 2.066473364830017, disc_loss = 0.004221545017431849
Trained batch 52 in epoch 2, gen_loss = 2.0675235469386264, disc_loss = 0.004261465308274019
Trained batch 53 in epoch 2, gen_loss = 2.070276211809229, disc_loss = 0.0042905568240072444
Trained batch 54 in epoch 2, gen_loss = 2.0671680905602194, disc_loss = 0.004267023461447521
Trained batch 55 in epoch 2, gen_loss = 2.0637222485882893, disc_loss = 0.004242855776932889
Trained batch 56 in epoch 2, gen_loss = 2.066978036311635, disc_loss = 0.0042318242904321665
Trained batch 57 in epoch 2, gen_loss = 2.073650392992743, disc_loss = 0.0042184551912841615
Trained batch 58 in epoch 2, gen_loss = 2.0678612559528675, disc_loss = 0.004233219791045886
Trained batch 59 in epoch 2, gen_loss = 2.0638437350591023, disc_loss = 0.004253572136318932
Trained batch 60 in epoch 2, gen_loss = 2.0638205418821243, disc_loss = 0.004227464572053219
Trained batch 61 in epoch 2, gen_loss = 2.0597528353814156, disc_loss = 0.0042189619721724626
Trained batch 62 in epoch 2, gen_loss = 2.0612590861698936, disc_loss = 0.00422151869769016
Trained batch 63 in epoch 2, gen_loss = 2.060839554294944, disc_loss = 0.004213200616504764
Trained batch 64 in epoch 2, gen_loss = 2.0599581846824058, disc_loss = 0.0042422768122588215
Trained batch 65 in epoch 2, gen_loss = 2.057057850288622, disc_loss = 0.004245489239551578
Trained batch 66 in epoch 2, gen_loss = 2.0556137846476994, disc_loss = 0.004246359075933917
Trained batch 67 in epoch 2, gen_loss = 2.049642100053675, disc_loss = 0.0042563587091589234
Trained batch 68 in epoch 2, gen_loss = 2.046919693117556, disc_loss = 0.004258361742899254
Trained batch 69 in epoch 2, gen_loss = 2.0442467893872944, disc_loss = 0.0042430927245212455
Trained batch 70 in epoch 2, gen_loss = 2.045744321715664, disc_loss = 0.00424256573864062
Trained batch 71 in epoch 2, gen_loss = 2.0454359319474964, disc_loss = 0.004246728772866643
Trained batch 72 in epoch 2, gen_loss = 2.0454314146956354, disc_loss = 0.004254445267764673
Trained batch 73 in epoch 2, gen_loss = 2.046170650301753, disc_loss = 0.004248137944503813
Trained batch 74 in epoch 2, gen_loss = 2.041371494928996, disc_loss = 0.004244330953806639
Trained batch 75 in epoch 2, gen_loss = 2.041177809238434, disc_loss = 0.004231788291546859
Trained batch 76 in epoch 2, gen_loss = 2.042830498187573, disc_loss = 0.0042186029733146556
Trained batch 77 in epoch 2, gen_loss = 2.0407918172004895, disc_loss = 0.004221930219314228
Trained batch 78 in epoch 2, gen_loss = 2.0394901188114023, disc_loss = 0.004211705169180715
Trained batch 79 in epoch 2, gen_loss = 2.0413899794220924, disc_loss = 0.004202091382467188
Trained batch 80 in epoch 2, gen_loss = 2.0377125592879306, disc_loss = 0.004213054621316216
Trained batch 81 in epoch 2, gen_loss = 2.036029790959707, disc_loss = 0.0042138147343904146
Trained batch 82 in epoch 2, gen_loss = 2.034274236265435, disc_loss = 0.004211679322600186
Trained batch 83 in epoch 2, gen_loss = 2.0337852239608765, disc_loss = 0.004191203505754294
Trained batch 84 in epoch 2, gen_loss = 2.035939303566428, disc_loss = 0.004176421307356042
Trained batch 85 in epoch 2, gen_loss = 2.035934004672738, disc_loss = 0.004165416965152808
Trained batch 86 in epoch 2, gen_loss = 2.0379064466761445, disc_loss = 0.004152971587475689
Trained batch 87 in epoch 2, gen_loss = 2.0354928103360264, disc_loss = 0.004140649355990304
Trained batch 88 in epoch 2, gen_loss = 2.0356246701787026, disc_loss = 0.004147888323438637
Trained batch 89 in epoch 2, gen_loss = 2.029629486136966, disc_loss = 0.004158563430731495
Trained batch 90 in epoch 2, gen_loss = 2.030541256233886, disc_loss = 0.004171021958137606
Trained batch 91 in epoch 2, gen_loss = 2.0307550754236137, disc_loss = 0.004176345137555314
Trained batch 92 in epoch 2, gen_loss = 2.0332384506861367, disc_loss = 0.004171385219500911
Trained batch 93 in epoch 2, gen_loss = 2.032490263593958, disc_loss = 0.004164814037528444
Trained batch 94 in epoch 2, gen_loss = 2.0358231142947547, disc_loss = 0.004155741835405168
Trained batch 95 in epoch 2, gen_loss = 2.0363017519315085, disc_loss = 0.004154421488541023
Trained batch 96 in epoch 2, gen_loss = 2.034105727353047, disc_loss = 0.004150769814906507
Trained batch 97 in epoch 2, gen_loss = 2.0375398141997203, disc_loss = 0.004140497244685432
Trained batch 98 in epoch 2, gen_loss = 2.03988911286749, disc_loss = 0.004129133521193507
Trained batch 99 in epoch 2, gen_loss = 2.039938946962357, disc_loss = 0.004114256470929831
Trained batch 100 in epoch 2, gen_loss = 2.0431395887148263, disc_loss = 0.004106130925846277
Trained batch 101 in epoch 2, gen_loss = 2.0443779475548687, disc_loss = 0.004112536242852609
Trained batch 102 in epoch 2, gen_loss = 2.0475426889160304, disc_loss = 0.004103370598580652
Trained batch 103 in epoch 2, gen_loss = 2.047375570123012, disc_loss = 0.004091871065051796
Trained batch 104 in epoch 2, gen_loss = 2.0498849108105612, disc_loss = 0.0040912810225217115
Trained batch 105 in epoch 2, gen_loss = 2.0523759722709656, disc_loss = 0.00407835226813507
Trained batch 106 in epoch 2, gen_loss = 2.052277666386043, disc_loss = 0.004064360498581256
Trained batch 107 in epoch 2, gen_loss = 2.0549746829050557, disc_loss = 0.004058482082284711
Trained batch 108 in epoch 2, gen_loss = 2.0556070181207917, disc_loss = 0.004061021807885498
Trained batch 109 in epoch 2, gen_loss = 2.058137186007066, disc_loss = 0.004061775967817415
Trained batch 110 in epoch 2, gen_loss = 2.0586827391976708, disc_loss = 0.0040492386880188105
Trained batch 111 in epoch 2, gen_loss = 2.058562841798578, disc_loss = 0.004042867013985025
Trained batch 112 in epoch 2, gen_loss = 2.059798349321416, disc_loss = 0.004034195198323083
Trained batch 113 in epoch 2, gen_loss = 2.061990096903684, disc_loss = 0.004027128623994558
Trained batch 114 in epoch 2, gen_loss = 2.0605920926384305, disc_loss = 0.004007831460836789
Trained batch 115 in epoch 2, gen_loss = 2.0621253961119157, disc_loss = 0.003997610851817219
Trained batch 116 in epoch 2, gen_loss = 2.06145031329913, disc_loss = 0.003995008697000961
Trained batch 117 in epoch 2, gen_loss = 2.0600142489045354, disc_loss = 0.003988721802578134
Trained batch 118 in epoch 2, gen_loss = 2.0583994258351686, disc_loss = 0.003975917213447705
Trained batch 119 in epoch 2, gen_loss = 2.0572479516267776, disc_loss = 0.0039655065241580205
Trained batch 120 in epoch 2, gen_loss = 2.0570551176701697, disc_loss = 0.003959025587301609
Trained batch 121 in epoch 2, gen_loss = 2.058510341605202, disc_loss = 0.003948288956336433
Trained batch 122 in epoch 2, gen_loss = 2.058193994731438, disc_loss = 0.003937752656184319
Trained batch 123 in epoch 2, gen_loss = 2.0606582251287278, disc_loss = 0.003927553093226086
Trained batch 124 in epoch 2, gen_loss = 2.0617745447158815, disc_loss = 0.003914370452985167
Trained batch 125 in epoch 2, gen_loss = 2.061256129590292, disc_loss = 0.003905832124430509
Trained batch 126 in epoch 2, gen_loss = 2.0570079632631435, disc_loss = 0.0039047846152615827
Trained batch 127 in epoch 2, gen_loss = 2.058431421406567, disc_loss = 0.003896757938491646
Trained batch 128 in epoch 2, gen_loss = 2.0609794263691867, disc_loss = 0.0038897813795957456
Trained batch 129 in epoch 2, gen_loss = 2.0601757590587324, disc_loss = 0.0038767265943953624
Trained batch 130 in epoch 2, gen_loss = 2.060651539846231, disc_loss = 0.0038682562423486065
Trained batch 131 in epoch 2, gen_loss = 2.062680566852743, disc_loss = 0.0038611673428959243
Trained batch 132 in epoch 2, gen_loss = 2.0628884116509805, disc_loss = 0.0038545500028430296
Trained batch 133 in epoch 2, gen_loss = 2.0605350492605523, disc_loss = 0.0038459685095933393
Trained batch 134 in epoch 2, gen_loss = 2.05912620668058, disc_loss = 0.0038464987581526794
Trained batch 135 in epoch 2, gen_loss = 2.059153626070303, disc_loss = 0.0038481740732951198
Trained batch 136 in epoch 2, gen_loss = 2.059859045230559, disc_loss = 0.003842698987981264
Trained batch 137 in epoch 2, gen_loss = 2.061360007610874, disc_loss = 0.003834812820929548
Trained batch 138 in epoch 2, gen_loss = 2.061056448401307, disc_loss = 0.0038287394643231904
Trained batch 139 in epoch 2, gen_loss = 2.0608507113797323, disc_loss = 0.0038255455471309166
Trained batch 140 in epoch 2, gen_loss = 2.058758464265377, disc_loss = 0.0038164644436052084
Trained batch 141 in epoch 2, gen_loss = 2.059764392778907, disc_loss = 0.0038168339360452872
Trained batch 142 in epoch 2, gen_loss = 2.0597454109391964, disc_loss = 0.0038200562780762054
Trained batch 143 in epoch 2, gen_loss = 2.0583109160264335, disc_loss = 0.003814538997378097
Trained batch 144 in epoch 2, gen_loss = 2.057241108499724, disc_loss = 0.0038103266490687585
Trained batch 145 in epoch 2, gen_loss = 2.05821479265004, disc_loss = 0.0038024628174503985
Trained batch 146 in epoch 2, gen_loss = 2.057823444710297, disc_loss = 0.0037946489585728264
Trained batch 147 in epoch 2, gen_loss = 2.058194206373112, disc_loss = 0.003785629177818427
Trained batch 148 in epoch 2, gen_loss = 2.057718990633152, disc_loss = 0.0037790046592286767
Trained batch 149 in epoch 2, gen_loss = 2.056954963207245, disc_loss = 0.0037712026325364906
Trained batch 150 in epoch 2, gen_loss = 2.0562493611645225, disc_loss = 0.003765288470559661
Trained batch 151 in epoch 2, gen_loss = 2.0533646313767684, disc_loss = 0.003762253943070965
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.06174898147583, disc_loss = 0.00450912257656455
Trained batch 1 in epoch 3, gen_loss = 2.1192835569381714, disc_loss = 0.005766209214925766
Trained batch 2 in epoch 3, gen_loss = 2.1373849709828696, disc_loss = 0.005241161988427241
Trained batch 3 in epoch 3, gen_loss = 2.073666989803314, disc_loss = 0.004853739403188229
Trained batch 4 in epoch 3, gen_loss = 2.1502535343170166, disc_loss = 0.004709985852241516
Trained batch 5 in epoch 3, gen_loss = 2.172759771347046, disc_loss = 0.004391516015554468
Trained batch 6 in epoch 3, gen_loss = 2.159053700310843, disc_loss = 0.004290595584149871
Trained batch 7 in epoch 3, gen_loss = 2.218686729669571, disc_loss = 0.004221021663397551
Trained batch 8 in epoch 3, gen_loss = 2.2221307489607067, disc_loss = 0.004121686616498563
Trained batch 9 in epoch 3, gen_loss = 2.193771147727966, disc_loss = 0.003994131903164088
Trained batch 10 in epoch 3, gen_loss = 2.1994673989035864, disc_loss = 0.0038152280983261085
Trained batch 11 in epoch 3, gen_loss = 2.194620986779531, disc_loss = 0.0037131222779862583
Trained batch 12 in epoch 3, gen_loss = 2.182467717390794, disc_loss = 0.003610015452767794
Trained batch 13 in epoch 3, gen_loss = 2.157593778201512, disc_loss = 0.00349583852637027
Trained batch 14 in epoch 3, gen_loss = 2.1336926301320394, disc_loss = 0.0035522361285984516
Trained batch 15 in epoch 3, gen_loss = 2.137088418006897, disc_loss = 0.003487186157144606
Trained batch 16 in epoch 3, gen_loss = 2.146522409775678, disc_loss = 0.003418504383743686
Trained batch 17 in epoch 3, gen_loss = 2.14657986164093, disc_loss = 0.003388541039182908
Trained batch 18 in epoch 3, gen_loss = 2.136431091710141, disc_loss = 0.0033157250574348787
Trained batch 19 in epoch 3, gen_loss = 2.128579705953598, disc_loss = 0.0032482869224622845
Trained batch 20 in epoch 3, gen_loss = 2.12736637819381, disc_loss = 0.0032121759861530293
Trained batch 21 in epoch 3, gen_loss = 2.1260967417196794, disc_loss = 0.0031700887907804413
Trained batch 22 in epoch 3, gen_loss = 2.1148613328519077, disc_loss = 0.0031378340158287597
Trained batch 23 in epoch 3, gen_loss = 2.1063580314318338, disc_loss = 0.0031827006702466556
Trained batch 24 in epoch 3, gen_loss = 2.096886758804321, disc_loss = 0.0032079338002949953
Trained batch 25 in epoch 3, gen_loss = 2.0972109849636373, disc_loss = 0.003199105652479025
Trained batch 26 in epoch 3, gen_loss = 2.0888256320246943, disc_loss = 0.0031812987980191355
Trained batch 27 in epoch 3, gen_loss = 2.081593326159886, disc_loss = 0.0031541434416015235
Trained batch 28 in epoch 3, gen_loss = 2.0724324768987197, disc_loss = 0.0031486868392676115
Trained batch 29 in epoch 3, gen_loss = 2.065882841746012, disc_loss = 0.0031253979386140903
Trained batch 30 in epoch 3, gen_loss = 2.076852167806318, disc_loss = 0.003123807165050699
Trained batch 31 in epoch 3, gen_loss = 2.0737894512712955, disc_loss = 0.0031252179760485888
Trained batch 32 in epoch 3, gen_loss = 2.0651786544106225, disc_loss = 0.003125059898152496
Trained batch 33 in epoch 3, gen_loss = 2.0680802639792946, disc_loss = 0.00311338556382586
Trained batch 34 in epoch 3, gen_loss = 2.0687489100864958, disc_loss = 0.003081633456583534
Trained batch 35 in epoch 3, gen_loss = 2.0665741198592715, disc_loss = 0.0030860639138457677
Trained batch 36 in epoch 3, gen_loss = 2.061903612033741, disc_loss = 0.0030627952120896125
Trained batch 37 in epoch 3, gen_loss = 2.059616578252692, disc_loss = 0.003047399032910011
Trained batch 38 in epoch 3, gen_loss = 2.061822805649195, disc_loss = 0.003029996057590231
Trained batch 39 in epoch 3, gen_loss = 2.05178981423378, disc_loss = 0.003037362772738561
Trained batch 40 in epoch 3, gen_loss = 2.0540030409650103, disc_loss = 0.0030352362806386336
Trained batch 41 in epoch 3, gen_loss = 2.049242524873643, disc_loss = 0.003003422597733637
Trained batch 42 in epoch 3, gen_loss = 2.0459604180136393, disc_loss = 0.0029806264968545632
Trained batch 43 in epoch 3, gen_loss = 2.042490455237302, disc_loss = 0.0029747045641257005
Trained batch 44 in epoch 3, gen_loss = 2.0336510552300346, disc_loss = 0.0029704279938919677
Trained batch 45 in epoch 3, gen_loss = 2.0329277256260747, disc_loss = 0.0030360534918777967
Trained batch 46 in epoch 3, gen_loss = 2.0355030983052353, disc_loss = 0.0030905568744353158
Trained batch 47 in epoch 3, gen_loss = 2.0299165919423103, disc_loss = 0.0030935780669096857
Trained batch 48 in epoch 3, gen_loss = 2.031526344163077, disc_loss = 0.003089188146690021
Trained batch 49 in epoch 3, gen_loss = 2.027978074550629, disc_loss = 0.0030971119832247495
Trained batch 50 in epoch 3, gen_loss = 2.027189210349438, disc_loss = 0.0031114250750226132
Trained batch 51 in epoch 3, gen_loss = 2.025150159230599, disc_loss = 0.003116790894777156
Trained batch 52 in epoch 3, gen_loss = 2.0256586412213884, disc_loss = 0.0031265549203556664
Trained batch 53 in epoch 3, gen_loss = 2.0353534155421786, disc_loss = 0.003131555764142562
Trained batch 54 in epoch 3, gen_loss = 2.0371571735902267, disc_loss = 0.0031228437130762774
Trained batch 55 in epoch 3, gen_loss = 2.0399822699172154, disc_loss = 0.0031160789533584777
Trained batch 56 in epoch 3, gen_loss = 2.0440029282318917, disc_loss = 0.0031069855025985787
Trained batch 57 in epoch 3, gen_loss = 2.0429745686465295, disc_loss = 0.0030945499291129665
Trained batch 58 in epoch 3, gen_loss = 2.037912605172497, disc_loss = 0.003097492716101519
Trained batch 59 in epoch 3, gen_loss = 2.036827222506205, disc_loss = 0.0030897204880602656
Trained batch 60 in epoch 3, gen_loss = 2.0446128571619755, disc_loss = 0.003091930278164686
Trained batch 61 in epoch 3, gen_loss = 2.04588415545802, disc_loss = 0.003081849682325077
Trained batch 62 in epoch 3, gen_loss = 2.0456123503427657, disc_loss = 0.0030739609455128036
Trained batch 63 in epoch 3, gen_loss = 2.0483929701149464, disc_loss = 0.003064494510908844
Trained batch 64 in epoch 3, gen_loss = 2.045255870085496, disc_loss = 0.0030635241884738205
Trained batch 65 in epoch 3, gen_loss = 2.04399091908426, disc_loss = 0.003053049338191296
Trained batch 66 in epoch 3, gen_loss = 2.0457866263033737, disc_loss = 0.0030429841839333077
Trained batch 67 in epoch 3, gen_loss = 2.0450252101701847, disc_loss = 0.003025926911504939
Trained batch 68 in epoch 3, gen_loss = 2.045774516852006, disc_loss = 0.0030112652043960447
Trained batch 69 in epoch 3, gen_loss = 2.0444196564810615, disc_loss = 0.0030176191740403217
Trained batch 70 in epoch 3, gen_loss = 2.046370805149347, disc_loss = 0.003009940433630746
Trained batch 71 in epoch 3, gen_loss = 2.0428952160808773, disc_loss = 0.002989289569086395
Trained batch 72 in epoch 3, gen_loss = 2.037230263017628, disc_loss = 0.002987787489498621
Trained batch 73 in epoch 3, gen_loss = 2.0382434323027327, disc_loss = 0.0029925105297258377
Trained batch 74 in epoch 3, gen_loss = 2.038952916463216, disc_loss = 0.0029886864110206563
Trained batch 75 in epoch 3, gen_loss = 2.0394583971876847, disc_loss = 0.002982681318443563
Trained batch 76 in epoch 3, gen_loss = 2.0409065933970663, disc_loss = 0.002992935552769764
Trained batch 77 in epoch 3, gen_loss = 2.041792502770057, disc_loss = 0.003003545462165792
Trained batch 78 in epoch 3, gen_loss = 2.0448993248275564, disc_loss = 0.003013756384047432
Trained batch 79 in epoch 3, gen_loss = 2.0427040323615073, disc_loss = 0.0030300367725430988
Trained batch 80 in epoch 3, gen_loss = 2.0422171766375317, disc_loss = 0.0030658278933346824
Trained batch 81 in epoch 3, gen_loss = 2.0444941040946216, disc_loss = 0.003091031093457032
Trained batch 82 in epoch 3, gen_loss = 2.0450487381004425, disc_loss = 0.003090438462445984
Trained batch 83 in epoch 3, gen_loss = 2.045961767435074, disc_loss = 0.0030838717066217214
Trained batch 84 in epoch 3, gen_loss = 2.047042191729826, disc_loss = 0.0030867944540017666
Trained batch 85 in epoch 3, gen_loss = 2.051664032215296, disc_loss = 0.0030869349450154534
Trained batch 86 in epoch 3, gen_loss = 2.049364876473087, disc_loss = 0.0030803249776898615
Trained batch 87 in epoch 3, gen_loss = 2.049870962446386, disc_loss = 0.003079887621094134
Trained batch 88 in epoch 3, gen_loss = 2.0465119769064226, disc_loss = 0.0030722821594393822
Trained batch 89 in epoch 3, gen_loss = 2.045943621794383, disc_loss = 0.003073336304320643
Trained batch 90 in epoch 3, gen_loss = 2.0468811792331736, disc_loss = 0.003071762765962426
Trained batch 91 in epoch 3, gen_loss = 2.047148135693177, disc_loss = 0.0030611026817021648
Trained batch 92 in epoch 3, gen_loss = 2.044902334931076, disc_loss = 0.003053348910774515
Trained batch 93 in epoch 3, gen_loss = 2.043785196669558, disc_loss = 0.0030525559249849235
Trained batch 94 in epoch 3, gen_loss = 2.0424525712665758, disc_loss = 0.003044152787984594
Trained batch 95 in epoch 3, gen_loss = 2.040081621458133, disc_loss = 0.0030401535659621004
Trained batch 96 in epoch 3, gen_loss = 2.042019203766105, disc_loss = 0.0030415423644092124
Trained batch 97 in epoch 3, gen_loss = 2.043741010889715, disc_loss = 0.003045327199993617
Trained batch 98 in epoch 3, gen_loss = 2.0435350049625742, disc_loss = 0.003040015011922353
Trained batch 99 in epoch 3, gen_loss = 2.0415805804729463, disc_loss = 0.0030344709393102676
Trained batch 100 in epoch 3, gen_loss = 2.0428921668836386, disc_loss = 0.00303515779559897
Trained batch 101 in epoch 3, gen_loss = 2.039210373280095, disc_loss = 0.0030425272701655095
Trained batch 102 in epoch 3, gen_loss = 2.039300867654745, disc_loss = 0.0030485491112362847
Trained batch 103 in epoch 3, gen_loss = 2.0394448523338022, disc_loss = 0.0030394980399600733
Trained batch 104 in epoch 3, gen_loss = 2.045635847818284, disc_loss = 0.0030463833639043426
Trained batch 105 in epoch 3, gen_loss = 2.0459925993433536, disc_loss = 0.0030503279017723814
Trained batch 106 in epoch 3, gen_loss = 2.045184684691028, disc_loss = 0.003048435844715998
Trained batch 107 in epoch 3, gen_loss = 2.043865148667936, disc_loss = 0.003046854104872586
Trained batch 108 in epoch 3, gen_loss = 2.0409155012270728, disc_loss = 0.0030473128821991314
Trained batch 109 in epoch 3, gen_loss = 2.038999890197407, disc_loss = 0.0030420711189931768
Trained batch 110 in epoch 3, gen_loss = 2.041023730157732, disc_loss = 0.0030314016569120525
Trained batch 111 in epoch 3, gen_loss = 2.040191571627344, disc_loss = 0.003029869126164288
Trained batch 112 in epoch 3, gen_loss = 2.0419185245986533, disc_loss = 0.0030388638873757646
Trained batch 113 in epoch 3, gen_loss = 2.03997352248744, disc_loss = 0.0030580741453409325
Trained batch 114 in epoch 3, gen_loss = 2.037703974350639, disc_loss = 0.0030628007158394095
Trained batch 115 in epoch 3, gen_loss = 2.037548722891972, disc_loss = 0.003061750691970168
Trained batch 116 in epoch 3, gen_loss = 2.038804944763836, disc_loss = 0.003061114912892445
Trained batch 117 in epoch 3, gen_loss = 2.040247636326289, disc_loss = 0.003060544895252876
Trained batch 118 in epoch 3, gen_loss = 2.040027273803198, disc_loss = 0.0030619790650387646
Trained batch 119 in epoch 3, gen_loss = 2.0390208929777147, disc_loss = 0.003059030362055637
Trained batch 120 in epoch 3, gen_loss = 2.0400006820347683, disc_loss = 0.0030485997159295708
Trained batch 121 in epoch 3, gen_loss = 2.037864654767709, disc_loss = 0.003040433459586968
Trained batch 122 in epoch 3, gen_loss = 2.0379633738742613, disc_loss = 0.003036293294848647
Trained batch 123 in epoch 3, gen_loss = 2.0379722685583177, disc_loss = 0.003032722103882641
Trained batch 124 in epoch 3, gen_loss = 2.0393451528549194, disc_loss = 0.003035367633216083
Trained batch 125 in epoch 3, gen_loss = 2.038624730375078, disc_loss = 0.0030406530187021765
Trained batch 126 in epoch 3, gen_loss = 2.0370473063836885, disc_loss = 0.003053576649738637
Trained batch 127 in epoch 3, gen_loss = 2.036346268840134, disc_loss = 0.0030686883264934295
Trained batch 128 in epoch 3, gen_loss = 2.0388895014459774, disc_loss = 0.0030597840045946973
Trained batch 129 in epoch 3, gen_loss = 2.03961413365144, disc_loss = 0.003053272209273508
Trained batch 130 in epoch 3, gen_loss = 2.0400496066071603, disc_loss = 0.003049148070689945
Trained batch 131 in epoch 3, gen_loss = 2.0393346602266487, disc_loss = 0.003048926385500553
Trained batch 132 in epoch 3, gen_loss = 2.039778913770403, disc_loss = 0.0030485960581388915
Trained batch 133 in epoch 3, gen_loss = 2.0403617816184885, disc_loss = 0.003038078965271698
Trained batch 134 in epoch 3, gen_loss = 2.040199398111414, disc_loss = 0.003029399717019664
Trained batch 135 in epoch 3, gen_loss = 2.039908773758832, disc_loss = 0.003020314985941
Trained batch 136 in epoch 3, gen_loss = 2.03992009336931, disc_loss = 0.0030151966374612205
Trained batch 137 in epoch 3, gen_loss = 2.0394949653874272, disc_loss = 0.0030104245592340612
Trained batch 138 in epoch 3, gen_loss = 2.0407633867195183, disc_loss = 0.0030088270495129787
Trained batch 139 in epoch 3, gen_loss = 2.0396674513816833, disc_loss = 0.0030103899289055593
Trained batch 140 in epoch 3, gen_loss = 2.0395251301163477, disc_loss = 0.003012082622062864
Trained batch 141 in epoch 3, gen_loss = 2.0416876849993852, disc_loss = 0.0030092572773688696
Trained batch 142 in epoch 3, gen_loss = 2.041887685135528, disc_loss = 0.00300400230180394
Trained batch 143 in epoch 3, gen_loss = 2.0443156974183188, disc_loss = 0.0030033276739737224
Trained batch 144 in epoch 3, gen_loss = 2.043914613230475, disc_loss = 0.003007052906242938
Trained batch 145 in epoch 3, gen_loss = 2.0462886952374078, disc_loss = 0.0030193110156089883
Trained batch 146 in epoch 3, gen_loss = 2.046999594792217, disc_loss = 0.0030171638227948524
Trained batch 147 in epoch 3, gen_loss = 2.048107950268565, disc_loss = 0.0030156429573843205
Trained batch 148 in epoch 3, gen_loss = 2.046176522370153, disc_loss = 0.00301358743802013
Trained batch 149 in epoch 3, gen_loss = 2.047005027929942, disc_loss = 0.003011141068612536
Trained batch 150 in epoch 3, gen_loss = 2.0464753512515137, disc_loss = 0.003005844641119143
Trained batch 151 in epoch 3, gen_loss = 2.04776557260438, disc_loss = 0.003005182607969465
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.960046410560608, disc_loss = 0.0023838006891310215
Trained batch 1 in epoch 4, gen_loss = 2.066155970096588, disc_loss = 0.0022939075715839863
Trained batch 2 in epoch 4, gen_loss = 2.13400669892629, disc_loss = 0.002083200728520751
Trained batch 3 in epoch 4, gen_loss = 2.0676061511039734, disc_loss = 0.0022092271829023957
Trained batch 4 in epoch 4, gen_loss = 2.0790649890899657, disc_loss = 0.002286832919344306
Trained batch 5 in epoch 4, gen_loss = 2.073063333829244, disc_loss = 0.0025584334895635643
Trained batch 6 in epoch 4, gen_loss = 2.1354874542781284, disc_loss = 0.0027043415300015894
Trained batch 7 in epoch 4, gen_loss = 2.117150664329529, disc_loss = 0.0026133897190447897
Trained batch 8 in epoch 4, gen_loss = 2.118149916330973, disc_loss = 0.002489717172769209
Trained batch 9 in epoch 4, gen_loss = 2.084602105617523, disc_loss = 0.002364858170039952
Trained batch 10 in epoch 4, gen_loss = 2.076574531468478, disc_loss = 0.002241231469352814
Trained batch 11 in epoch 4, gen_loss = 2.0463637312253318, disc_loss = 0.002175385016016662
Trained batch 12 in epoch 4, gen_loss = 2.0671179661383996, disc_loss = 0.002156718043037332
Trained batch 13 in epoch 4, gen_loss = 2.07324172769274, disc_loss = 0.0021668431415621725
Trained batch 14 in epoch 4, gen_loss = 2.070034313201904, disc_loss = 0.002133190631866455
Trained batch 15 in epoch 4, gen_loss = 2.0663002133369446, disc_loss = 0.0020907836296828464
Trained batch 16 in epoch 4, gen_loss = 2.069139228147619, disc_loss = 0.00204645176007248
Trained batch 17 in epoch 4, gen_loss = 2.070946627193027, disc_loss = 0.002008081252117538
Trained batch 18 in epoch 4, gen_loss = 2.056504908360933, disc_loss = 0.0019843823668595994
Trained batch 19 in epoch 4, gen_loss = 2.0452463150024416, disc_loss = 0.0019602478831075134
Trained batch 20 in epoch 4, gen_loss = 2.054452759878976, disc_loss = 0.001945955767517998
Trained batch 21 in epoch 4, gen_loss = 2.0652232386849145, disc_loss = 0.001924764280292121
Trained batch 22 in epoch 4, gen_loss = 2.0680711476699165, disc_loss = 0.001900729703028565
Trained batch 23 in epoch 4, gen_loss = 2.049055109421412, disc_loss = 0.0018906918703578413
Trained batch 24 in epoch 4, gen_loss = 2.0457674741744993, disc_loss = 0.0018829032219946384
Trained batch 25 in epoch 4, gen_loss = 2.0430236825576196, disc_loss = 0.001881545284189857
Trained batch 26 in epoch 4, gen_loss = 2.041914564591867, disc_loss = 0.0018899247429713054
Trained batch 27 in epoch 4, gen_loss = 2.0567249613148824, disc_loss = 0.0019324609893374145
Trained batch 28 in epoch 4, gen_loss = 2.0584969479462196, disc_loss = 0.0019215237036154702
Trained batch 29 in epoch 4, gen_loss = 2.064335278669993, disc_loss = 0.0019268746216160556
Trained batch 30 in epoch 4, gen_loss = 2.0571809007275488, disc_loss = 0.001944750611249718
Trained batch 31 in epoch 4, gen_loss = 2.055142004042864, disc_loss = 0.001940755722898757
Trained batch 32 in epoch 4, gen_loss = 2.060175227396416, disc_loss = 0.0019304542943383708
Trained batch 33 in epoch 4, gen_loss = 2.0566094517707825, disc_loss = 0.0019531345323604695
Trained batch 34 in epoch 4, gen_loss = 2.0572474309376307, disc_loss = 0.00195869873277843
Trained batch 35 in epoch 4, gen_loss = 2.0533276432090335, disc_loss = 0.001965279930219468
Trained batch 36 in epoch 4, gen_loss = 2.0430239567885526, disc_loss = 0.0019567469260781197
Trained batch 37 in epoch 4, gen_loss = 2.047415234540638, disc_loss = 0.0019506702481425907
Trained batch 38 in epoch 4, gen_loss = 2.0528097244409413, disc_loss = 0.001954178570602567
Trained batch 39 in epoch 4, gen_loss = 2.052895340323448, disc_loss = 0.001939641241915524
Trained batch 40 in epoch 4, gen_loss = 2.0532272065558086, disc_loss = 0.0019237417614132893
Trained batch 41 in epoch 4, gen_loss = 2.0511524365061806, disc_loss = 0.0019140922287035557
Trained batch 42 in epoch 4, gen_loss = 2.053296679674193, disc_loss = 0.0019117119954898953
Trained batch 43 in epoch 4, gen_loss = 2.050871588967063, disc_loss = 0.0019130614104638385
Trained batch 44 in epoch 4, gen_loss = 2.0528249899546305, disc_loss = 0.0019191657011914584
Trained batch 45 in epoch 4, gen_loss = 2.0449772243914395, disc_loss = 0.0019169710500611236
Trained batch 46 in epoch 4, gen_loss = 2.044269805258893, disc_loss = 0.0019034436641340244
Trained batch 47 in epoch 4, gen_loss = 2.0473380386829376, disc_loss = 0.001909075409154563
Trained batch 48 in epoch 4, gen_loss = 2.048639117454996, disc_loss = 0.0019061859953692372
Trained batch 49 in epoch 4, gen_loss = 2.048460659980774, disc_loss = 0.0019034072221256792
Trained batch 50 in epoch 4, gen_loss = 2.046812501608157, disc_loss = 0.0019052534195247526
Trained batch 51 in epoch 4, gen_loss = 2.043351634190633, disc_loss = 0.00190532218458919
Trained batch 52 in epoch 4, gen_loss = 2.039398577978026, disc_loss = 0.001904783996683106
Trained batch 53 in epoch 4, gen_loss = 2.0449057707080134, disc_loss = 0.0019004723376215057
Trained batch 54 in epoch 4, gen_loss = 2.0431706580248745, disc_loss = 0.0018928834596987475
Trained batch 55 in epoch 4, gen_loss = 2.04130289384297, disc_loss = 0.0018897321777850656
Trained batch 56 in epoch 4, gen_loss = 2.044443205783242, disc_loss = 0.0019050050596298095
Trained batch 57 in epoch 4, gen_loss = 2.042932461047995, disc_loss = 0.0019018388341245209
Trained batch 58 in epoch 4, gen_loss = 2.035353214053784, disc_loss = 0.0019031281571172305
Trained batch 59 in epoch 4, gen_loss = 2.035049961010615, disc_loss = 0.0019068139236575613
Trained batch 60 in epoch 4, gen_loss = 2.03333004771686, disc_loss = 0.0019011778573765129
Trained batch 61 in epoch 4, gen_loss = 2.0354580821529513, disc_loss = 0.0018952746777945468
Trained batch 62 in epoch 4, gen_loss = 2.037617832895309, disc_loss = 0.001886393067367848
Trained batch 63 in epoch 4, gen_loss = 2.0352566242218018, disc_loss = 0.0018843425750674214
Trained batch 64 in epoch 4, gen_loss = 2.0347014097067024, disc_loss = 0.0018744712211908056
Trained batch 65 in epoch 4, gen_loss = 2.0310405167666348, disc_loss = 0.0018691053000194106
Trained batch 66 in epoch 4, gen_loss = 2.031912230733615, disc_loss = 0.0018729144505767235
Trained batch 67 in epoch 4, gen_loss = 2.027057996567558, disc_loss = 0.001866251411710811
Trained batch 68 in epoch 4, gen_loss = 2.0292562591856806, disc_loss = 0.0018649584566499443
Trained batch 69 in epoch 4, gen_loss = 2.029835590294429, disc_loss = 0.0018672139117760318
Trained batch 70 in epoch 4, gen_loss = 2.030358937424673, disc_loss = 0.0018637127843095173
Trained batch 71 in epoch 4, gen_loss = 2.0334281673034034, disc_loss = 0.0018525470691707192
Trained batch 72 in epoch 4, gen_loss = 2.031726758774013, disc_loss = 0.0018422861666456886
Trained batch 73 in epoch 4, gen_loss = 2.033001754734967, disc_loss = 0.0018340554434453716
Trained batch 74 in epoch 4, gen_loss = 2.030081130663554, disc_loss = 0.0018265405762940645
Trained batch 75 in epoch 4, gen_loss = 2.029112845659256, disc_loss = 0.0018199795219851168
Trained batch 76 in epoch 4, gen_loss = 2.032471673829215, disc_loss = 0.001812263721503414
Trained batch 77 in epoch 4, gen_loss = 2.030951122442881, disc_loss = 0.0018070913725890792
Trained batch 78 in epoch 4, gen_loss = 2.0302469730377197, disc_loss = 0.001803793514123823
Trained batch 79 in epoch 4, gen_loss = 2.0277162075042723, disc_loss = 0.0017986742226639763
Trained batch 80 in epoch 4, gen_loss = 2.0311095537962736, disc_loss = 0.0017977177142453047
Trained batch 81 in epoch 4, gen_loss = 2.0287930558367475, disc_loss = 0.0018072281140697802
Trained batch 82 in epoch 4, gen_loss = 2.025906715048365, disc_loss = 0.0018198040835783783
Trained batch 83 in epoch 4, gen_loss = 2.0282232818149386, disc_loss = 0.0018181456890445026
Trained batch 84 in epoch 4, gen_loss = 2.028471924276913, disc_loss = 0.0018187178463182029
Trained batch 85 in epoch 4, gen_loss = 2.026336230510889, disc_loss = 0.0018214094831586578
Trained batch 86 in epoch 4, gen_loss = 2.0263601404496994, disc_loss = 0.0018263614319007971
Trained batch 87 in epoch 4, gen_loss = 2.0271705267104236, disc_loss = 0.0018310621751218357
Trained batch 88 in epoch 4, gen_loss = 2.0276517318875604, disc_loss = 0.0018309619581180342
Trained batch 89 in epoch 4, gen_loss = 2.028299309147729, disc_loss = 0.0018262770725414156
Trained batch 90 in epoch 4, gen_loss = 2.03001352587899, disc_loss = 0.0018207210571515363
Trained batch 91 in epoch 4, gen_loss = 2.032514944024708, disc_loss = 0.0018148263144489054
Trained batch 92 in epoch 4, gen_loss = 2.032690208445313, disc_loss = 0.0018092124617748683
Trained batch 93 in epoch 4, gen_loss = 2.0348970725181257, disc_loss = 0.0018033087166878295
Trained batch 94 in epoch 4, gen_loss = 2.0351787052656474, disc_loss = 0.0017972468043138323
Trained batch 95 in epoch 4, gen_loss = 2.0380061281224093, disc_loss = 0.0017938455566763878
Trained batch 96 in epoch 4, gen_loss = 2.041341502641894, disc_loss = 0.0017876510361939208
Trained batch 97 in epoch 4, gen_loss = 2.0412100030451406, disc_loss = 0.001782521915536526
Trained batch 98 in epoch 4, gen_loss = 2.044071494930922, disc_loss = 0.001779941111718389
Trained batch 99 in epoch 4, gen_loss = 2.042256063222885, disc_loss = 0.0017749377654399723
Trained batch 100 in epoch 4, gen_loss = 2.042402511776084, disc_loss = 0.001771746183708679
Trained batch 101 in epoch 4, gen_loss = 2.0383667022574183, disc_loss = 0.0017789649907225633
Trained batch 102 in epoch 4, gen_loss = 2.0364067103098895, disc_loss = 0.0017748727289127928
Trained batch 103 in epoch 4, gen_loss = 2.0383443247813444, disc_loss = 0.0017670275824807154
Trained batch 104 in epoch 4, gen_loss = 2.036560042699178, disc_loss = 0.001762361974189324
Trained batch 105 in epoch 4, gen_loss = 2.0375090365139945, disc_loss = 0.0017562890117812269
Trained batch 106 in epoch 4, gen_loss = 2.039963974016849, disc_loss = 0.0017482601051767156
Trained batch 107 in epoch 4, gen_loss = 2.038985055905801, disc_loss = 0.0017422942500733942
Trained batch 108 in epoch 4, gen_loss = 2.038887800426658, disc_loss = 0.0017373358335243453
Trained batch 109 in epoch 4, gen_loss = 2.037083357030695, disc_loss = 0.0017341385151005604
Trained batch 110 in epoch 4, gen_loss = 2.0369096103015245, disc_loss = 0.0017288189972876698
Trained batch 111 in epoch 4, gen_loss = 2.0371690903391158, disc_loss = 0.0017232090342856412
Trained batch 112 in epoch 4, gen_loss = 2.035497031380645, disc_loss = 0.0017199497216636628
Trained batch 113 in epoch 4, gen_loss = 2.0324080774658606, disc_loss = 0.0017404395702964905
Trained batch 114 in epoch 4, gen_loss = 2.0331317082695337, disc_loss = 0.0017745829389795014
Trained batch 115 in epoch 4, gen_loss = 2.031882395004404, disc_loss = 0.0018095491967838385
Trained batch 116 in epoch 4, gen_loss = 2.032543777400612, disc_loss = 0.0018220582626696327
Trained batch 117 in epoch 4, gen_loss = 2.0352136846316062, disc_loss = 0.0018222588272291725
Trained batch 118 in epoch 4, gen_loss = 2.0355723946034407, disc_loss = 0.0018263236236046342
Trained batch 119 in epoch 4, gen_loss = 2.0391457875569663, disc_loss = 0.001827412537143876
Trained batch 120 in epoch 4, gen_loss = 2.0362310261765786, disc_loss = 0.0018289831336125854
Trained batch 121 in epoch 4, gen_loss = 2.0346597579659007, disc_loss = 0.0018323730108648782
Trained batch 122 in epoch 4, gen_loss = 2.035932629089045, disc_loss = 0.0018322825823660668
Trained batch 123 in epoch 4, gen_loss = 2.0349493536256973, disc_loss = 0.0018323311692990001
Trained batch 124 in epoch 4, gen_loss = 2.0340026235580444, disc_loss = 0.0018281178157776594
Trained batch 125 in epoch 4, gen_loss = 2.0347238864217485, disc_loss = 0.0018243122409792646
Trained batch 126 in epoch 4, gen_loss = 2.0346604510555117, disc_loss = 0.0018264871314314641
Trained batch 127 in epoch 4, gen_loss = 2.0339393112808466, disc_loss = 0.001824376171498443
Trained batch 128 in epoch 4, gen_loss = 2.0352744113567263, disc_loss = 0.0018211950695994057
Trained batch 129 in epoch 4, gen_loss = 2.0345070921457733, disc_loss = 0.0018198783554208393
Trained batch 130 in epoch 4, gen_loss = 2.0349271342954562, disc_loss = 0.0018160108517755874
Trained batch 131 in epoch 4, gen_loss = 2.031728730057225, disc_loss = 0.0018140934434169058
Trained batch 132 in epoch 4, gen_loss = 2.0301483735106047, disc_loss = 0.0018127352494704432
Trained batch 133 in epoch 4, gen_loss = 2.030115026146618, disc_loss = 0.0018076029877220072
Trained batch 134 in epoch 4, gen_loss = 2.0308260034631798, disc_loss = 0.0018054816371726769
Trained batch 135 in epoch 4, gen_loss = 2.0311662414494682, disc_loss = 0.0018045865478651488
Trained batch 136 in epoch 4, gen_loss = 2.0291210282458008, disc_loss = 0.0018002863269788723
Trained batch 137 in epoch 4, gen_loss = 2.0282761117686396, disc_loss = 0.0017924195567172937
Trained batch 138 in epoch 4, gen_loss = 2.029276400161304, disc_loss = 0.001786774746309832
Trained batch 139 in epoch 4, gen_loss = 2.0279347607067653, disc_loss = 0.0017811852025001176
Trained batch 140 in epoch 4, gen_loss = 2.027591883713472, disc_loss = 0.00177727489738811
Trained batch 141 in epoch 4, gen_loss = 2.02856565948943, disc_loss = 0.0017756616194981715
Trained batch 142 in epoch 4, gen_loss = 2.029936304459205, disc_loss = 0.0017751094045026319
Trained batch 143 in epoch 4, gen_loss = 2.0314862951636314, disc_loss = 0.0017746157601423976
Trained batch 144 in epoch 4, gen_loss = 2.0322196689145318, disc_loss = 0.0017731182245088034
Trained batch 145 in epoch 4, gen_loss = 2.0332508503574216, disc_loss = 0.0017716410475757535
Trained batch 146 in epoch 4, gen_loss = 2.0327131383273067, disc_loss = 0.0017666937395309408
Trained batch 147 in epoch 4, gen_loss = 2.0335194492662274, disc_loss = 0.0017621001768290895
Trained batch 148 in epoch 4, gen_loss = 2.0336768379147423, disc_loss = 0.001759462356223606
Trained batch 149 in epoch 4, gen_loss = 2.0338861838976543, disc_loss = 0.001758074639365077
Trained batch 150 in epoch 4, gen_loss = 2.0331038291880628, disc_loss = 0.0017548916932343449
Trained batch 151 in epoch 4, gen_loss = 2.0320761141024137, disc_loss = 0.001751263492654911
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.8177056312561035, disc_loss = 0.0011567935580387712
Trained batch 1 in epoch 5, gen_loss = 2.022788882255554, disc_loss = 0.0011488161399029195
Trained batch 2 in epoch 5, gen_loss = 2.0309747060139975, disc_loss = 0.0010508277725117903
Trained batch 3 in epoch 5, gen_loss = 2.023984730243683, disc_loss = 0.0010880281188292429
Trained batch 4 in epoch 5, gen_loss = 2.0108306407928467, disc_loss = 0.0012143863015808166
Trained batch 5 in epoch 5, gen_loss = 1.9788083632787068, disc_loss = 0.001204043170825268
Trained batch 6 in epoch 5, gen_loss = 1.9806108134133475, disc_loss = 0.0011906155601276883
Trained batch 7 in epoch 5, gen_loss = 2.0059404969215393, disc_loss = 0.0012187906031613238
Trained batch 8 in epoch 5, gen_loss = 2.0097716649373374, disc_loss = 0.0012814851361326873
Trained batch 9 in epoch 5, gen_loss = 2.0057586073875426, disc_loss = 0.0013717489724513142
Trained batch 10 in epoch 5, gen_loss = 2.0319164341146294, disc_loss = 0.0014738341613503342
Trained batch 11 in epoch 5, gen_loss = 2.036324590444565, disc_loss = 0.0014510446004957582
Trained batch 12 in epoch 5, gen_loss = 2.0574581164580126, disc_loss = 0.001428995196385166
Trained batch 13 in epoch 5, gen_loss = 2.043149547917502, disc_loss = 0.0014219691469666681
Trained batch 14 in epoch 5, gen_loss = 2.056413737932841, disc_loss = 0.0014679559933332106
Trained batch 15 in epoch 5, gen_loss = 2.076204337179661, disc_loss = 0.0014968663781473879
Trained batch 16 in epoch 5, gen_loss = 2.0757160397136913, disc_loss = 0.0015193040736074396
Trained batch 17 in epoch 5, gen_loss = 2.062344577577379, disc_loss = 0.0015748458972666413
Trained batch 18 in epoch 5, gen_loss = 2.071422401227449, disc_loss = 0.001596783070310362
Trained batch 19 in epoch 5, gen_loss = 2.0548540592193603, disc_loss = 0.0015843999542994424
Trained batch 20 in epoch 5, gen_loss = 2.037482182184855, disc_loss = 0.0015768003400548228
Trained batch 21 in epoch 5, gen_loss = 2.030196341601285, disc_loss = 0.0015655638284938918
Trained batch 22 in epoch 5, gen_loss = 2.02098634450332, disc_loss = 0.001548567961435765
Trained batch 23 in epoch 5, gen_loss = 2.018902435898781, disc_loss = 0.0015417780402155283
Trained batch 24 in epoch 5, gen_loss = 2.011595816612244, disc_loss = 0.0015425214101560413
Trained batch 25 in epoch 5, gen_loss = 2.013968123839452, disc_loss = 0.001527361229259091
Trained batch 26 in epoch 5, gen_loss = 2.013383008815624, disc_loss = 0.00152045314381313
Trained batch 27 in epoch 5, gen_loss = 2.0123432108334134, disc_loss = 0.0015036970164926191
Trained batch 28 in epoch 5, gen_loss = 2.008210807011045, disc_loss = 0.0015121278340992485
Trained batch 29 in epoch 5, gen_loss = 2.0007837692896526, disc_loss = 0.0015357500039196263
Trained batch 30 in epoch 5, gen_loss = 1.9959205350568217, disc_loss = 0.0015517709975791795
Trained batch 31 in epoch 5, gen_loss = 1.9988184198737144, disc_loss = 0.0015487356595258461
Trained batch 32 in epoch 5, gen_loss = 2.000253915786743, disc_loss = 0.0015410251799039543
Trained batch 33 in epoch 5, gen_loss = 1.998433463713702, disc_loss = 0.00154230507220799
Trained batch 34 in epoch 5, gen_loss = 1.9995456763676234, disc_loss = 0.0015485714272862035
Trained batch 35 in epoch 5, gen_loss = 2.005282680193583, disc_loss = 0.0015578726807790291
Trained batch 36 in epoch 5, gen_loss = 1.9987703432907928, disc_loss = 0.0015654324324222634
Trained batch 37 in epoch 5, gen_loss = 1.9982572856702303, disc_loss = 0.0015819847850300568
Trained batch 38 in epoch 5, gen_loss = 1.9946038386760614, disc_loss = 0.0016006925008976115
Trained batch 39 in epoch 5, gen_loss = 1.9936410695314408, disc_loss = 0.0016079868059023284
Trained batch 40 in epoch 5, gen_loss = 2.001514303974989, disc_loss = 0.0015958997423806023
Trained batch 41 in epoch 5, gen_loss = 2.001708056245531, disc_loss = 0.0015853214468474367
Trained batch 42 in epoch 5, gen_loss = 2.007626308951267, disc_loss = 0.0015715807392045337
Trained batch 43 in epoch 5, gen_loss = 1.9988117922436108, disc_loss = 0.0015608897440622306
Trained batch 44 in epoch 5, gen_loss = 1.9985565741856892, disc_loss = 0.001549224836182677
Trained batch 45 in epoch 5, gen_loss = 1.9974990305693254, disc_loss = 0.0015438641181073922
Trained batch 46 in epoch 5, gen_loss = 1.9954319152426212, disc_loss = 0.0015401331561696815
Trained batch 47 in epoch 5, gen_loss = 1.9904239724079769, disc_loss = 0.0015262971198050461
Trained batch 48 in epoch 5, gen_loss = 1.9863773900635389, disc_loss = 0.0015182862098670888
Trained batch 49 in epoch 5, gen_loss = 1.9910503101348878, disc_loss = 0.0015080862084869296
Trained batch 50 in epoch 5, gen_loss = 1.9939625403460335, disc_loss = 0.0015015399149692088
Trained batch 51 in epoch 5, gen_loss = 1.9969805524899409, disc_loss = 0.0015090420727994149
Trained batch 52 in epoch 5, gen_loss = 1.9951680426327687, disc_loss = 0.0015230179283293491
Trained batch 53 in epoch 5, gen_loss = 1.9997652460027624, disc_loss = 0.0015285026499811836
Trained batch 54 in epoch 5, gen_loss = 1.99982797015797, disc_loss = 0.0015281224760904232
Trained batch 55 in epoch 5, gen_loss = 2.001476947750364, disc_loss = 0.0015261014892270655
Trained batch 56 in epoch 5, gen_loss = 2.0013743241628013, disc_loss = 0.0015210277909461997
Trained batch 57 in epoch 5, gen_loss = 2.00018226072706, disc_loss = 0.0015122769109439105
Trained batch 58 in epoch 5, gen_loss = 1.995949252177093, disc_loss = 0.0015006621804293562
Trained batch 59 in epoch 5, gen_loss = 1.9961654623349507, disc_loss = 0.0014940986225459103
Trained batch 60 in epoch 5, gen_loss = 2.0000275353916357, disc_loss = 0.0014844694734001379
Trained batch 61 in epoch 5, gen_loss = 2.001058916891775, disc_loss = 0.0014758324316297207
Trained batch 62 in epoch 5, gen_loss = 1.9997787551274375, disc_loss = 0.0014702238406734689
Trained batch 63 in epoch 5, gen_loss = 1.9966465253382921, disc_loss = 0.001461606663724524
Trained batch 64 in epoch 5, gen_loss = 1.9932184787896963, disc_loss = 0.0014565605007541868
Trained batch 65 in epoch 5, gen_loss = 1.9892293883092476, disc_loss = 0.0014547277647635024
Trained batch 66 in epoch 5, gen_loss = 1.9888748179620772, disc_loss = 0.0014510513787199535
Trained batch 67 in epoch 5, gen_loss = 1.993464941487593, disc_loss = 0.001443300213021062
Trained batch 68 in epoch 5, gen_loss = 1.9932637836622156, disc_loss = 0.001438991178461499
Trained batch 69 in epoch 5, gen_loss = 1.9944910866873604, disc_loss = 0.0014366774437283832
Trained batch 70 in epoch 5, gen_loss = 1.9910596894546293, disc_loss = 0.0014314495607502234
Trained batch 71 in epoch 5, gen_loss = 1.988897078567081, disc_loss = 0.0014231309501661195
Trained batch 72 in epoch 5, gen_loss = 1.9928622801009923, disc_loss = 0.0014180846110445587
Trained batch 73 in epoch 5, gen_loss = 1.988419295968236, disc_loss = 0.0014200564174963212
Trained batch 74 in epoch 5, gen_loss = 1.9846571811040243, disc_loss = 0.001417756479543944
Trained batch 75 in epoch 5, gen_loss = 1.9839933091088344, disc_loss = 0.0014132740585697128
Trained batch 76 in epoch 5, gen_loss = 1.9805072066071745, disc_loss = 0.0014101249171880545
Trained batch 77 in epoch 5, gen_loss = 1.9825187554726234, disc_loss = 0.001405620629576823
Trained batch 78 in epoch 5, gen_loss = 1.9833412140230589, disc_loss = 0.001408650161097227
Trained batch 79 in epoch 5, gen_loss = 1.9824817776679993, disc_loss = 0.0014162665189360268
Trained batch 80 in epoch 5, gen_loss = 1.9814409871160248, disc_loss = 0.001419379074057495
Trained batch 81 in epoch 5, gen_loss = 1.9846298040413275, disc_loss = 0.0014173878220523277
Trained batch 82 in epoch 5, gen_loss = 1.9816253558698906, disc_loss = 0.0014185176079486866
Trained batch 83 in epoch 5, gen_loss = 1.9809842521236056, disc_loss = 0.0014143989371534968
Trained batch 84 in epoch 5, gen_loss = 1.9789536251741298, disc_loss = 0.001407314816435032
Trained batch 85 in epoch 5, gen_loss = 1.980886043504227, disc_loss = 0.0014039077620065317
Trained batch 86 in epoch 5, gen_loss = 1.9817588712977268, disc_loss = 0.0013975701763176884
Trained batch 87 in epoch 5, gen_loss = 1.9811349456960505, disc_loss = 0.001390440841946243
Trained batch 88 in epoch 5, gen_loss = 1.979701865924878, disc_loss = 0.0013876832875140597
Trained batch 89 in epoch 5, gen_loss = 1.9794271601570976, disc_loss = 0.0013832355021602578
Trained batch 90 in epoch 5, gen_loss = 1.981114536851317, disc_loss = 0.0013777518332782355
Trained batch 91 in epoch 5, gen_loss = 1.9822466969490051, disc_loss = 0.001372914882781713
Trained batch 92 in epoch 5, gen_loss = 1.9795582063736454, disc_loss = 0.0013663215338633025
Trained batch 93 in epoch 5, gen_loss = 1.9797573939282844, disc_loss = 0.0013615714913689867
Trained batch 94 in epoch 5, gen_loss = 1.981625119008516, disc_loss = 0.0013560466603130886
Trained batch 95 in epoch 5, gen_loss = 1.983505727102359, disc_loss = 0.0013507160656445194
Trained batch 96 in epoch 5, gen_loss = 1.9831134216072632, disc_loss = 0.001345765013631779
Trained batch 97 in epoch 5, gen_loss = 1.9854813449236812, disc_loss = 0.0013404329110184039
Trained batch 98 in epoch 5, gen_loss = 1.9853760329159824, disc_loss = 0.001334155238271136
Trained batch 99 in epoch 5, gen_loss = 1.98615980386734, disc_loss = 0.0013290157180745154
Trained batch 100 in epoch 5, gen_loss = 1.9868264387149621, disc_loss = 0.0013239074367015521
Trained batch 101 in epoch 5, gen_loss = 1.9864448495939666, disc_loss = 0.00131941137963212
Trained batch 102 in epoch 5, gen_loss = 1.9850693304561875, disc_loss = 0.0013155253757767885
Trained batch 103 in epoch 5, gen_loss = 1.9870752210800464, disc_loss = 0.001311879187526826
Trained batch 104 in epoch 5, gen_loss = 1.9862285125823247, disc_loss = 0.0013069796326038029
Trained batch 105 in epoch 5, gen_loss = 1.9872460736418671, disc_loss = 0.001300820067661094
Trained batch 106 in epoch 5, gen_loss = 1.986796716663325, disc_loss = 0.0012967692047279225
Trained batch 107 in epoch 5, gen_loss = 1.9865157935354445, disc_loss = 0.001295549653285114
Trained batch 108 in epoch 5, gen_loss = 1.9882359876545197, disc_loss = 0.0012916943646856336
Trained batch 109 in epoch 5, gen_loss = 1.9857635205442254, disc_loss = 0.0012886923594950615
Trained batch 110 in epoch 5, gen_loss = 1.9853032268919386, disc_loss = 0.0012862057375788755
Trained batch 111 in epoch 5, gen_loss = 1.9847103655338287, disc_loss = 0.001283899068636986
Trained batch 112 in epoch 5, gen_loss = 1.9861296573571399, disc_loss = 0.0012806813656022788
Trained batch 113 in epoch 5, gen_loss = 1.9875231500257526, disc_loss = 0.0012789527551687666
Trained batch 114 in epoch 5, gen_loss = 1.985763948896657, disc_loss = 0.001277371707028183
Trained batch 115 in epoch 5, gen_loss = 1.990711868836962, disc_loss = 0.0012744590384155062
Trained batch 116 in epoch 5, gen_loss = 1.9911581175959008, disc_loss = 0.0012703692604206565
Trained batch 117 in epoch 5, gen_loss = 1.9928623023679701, disc_loss = 0.001266042102558412
Trained batch 118 in epoch 5, gen_loss = 1.9931164739512597, disc_loss = 0.0012614957869890296
Trained batch 119 in epoch 5, gen_loss = 1.993564286828041, disc_loss = 0.0012572970808832906
Trained batch 120 in epoch 5, gen_loss = 1.9935326999869227, disc_loss = 0.0012533780757899681
Trained batch 121 in epoch 5, gen_loss = 1.9957500745038517, disc_loss = 0.001251663257402261
Trained batch 122 in epoch 5, gen_loss = 1.9962357844763654, disc_loss = 0.0012506172141416104
Trained batch 123 in epoch 5, gen_loss = 1.9963331328284355, disc_loss = 0.001247256943081025
Trained batch 124 in epoch 5, gen_loss = 1.9988443784713745, disc_loss = 0.0012433076035231352
Trained batch 125 in epoch 5, gen_loss = 2.000434829129113, disc_loss = 0.0012411715893355746
Trained batch 126 in epoch 5, gen_loss = 2.0026890433679414, disc_loss = 0.0012370947199345631
Trained batch 127 in epoch 5, gen_loss = 2.0036154137924314, disc_loss = 0.0012327300878496317
Trained batch 128 in epoch 5, gen_loss = 2.005760530168696, disc_loss = 0.0012294557789347834
Trained batch 129 in epoch 5, gen_loss = 2.0039550772080053, disc_loss = 0.0012279759622358072
Trained batch 130 in epoch 5, gen_loss = 2.0036187235635654, disc_loss = 0.001228589124227554
Trained batch 131 in epoch 5, gen_loss = 2.006022058653109, disc_loss = 0.001227971974665045
Trained batch 132 in epoch 5, gen_loss = 2.00514641112851, disc_loss = 0.0012271107735525452
Trained batch 133 in epoch 5, gen_loss = 2.005893174392074, disc_loss = 0.001223723739020721
Trained batch 134 in epoch 5, gen_loss = 2.0080113508083204, disc_loss = 0.0012223890245271227
Trained batch 135 in epoch 5, gen_loss = 2.0100928571294334, disc_loss = 0.0012224789375870708
Trained batch 136 in epoch 5, gen_loss = 2.0106975362248662, disc_loss = 0.001220306729554559
Trained batch 137 in epoch 5, gen_loss = 2.0110491764718206, disc_loss = 0.0012244935737133187
Trained batch 138 in epoch 5, gen_loss = 2.0139249889113064, disc_loss = 0.0012307679242950281
Trained batch 139 in epoch 5, gen_loss = 2.01383107985769, disc_loss = 0.001233319122028271
Trained batch 140 in epoch 5, gen_loss = 2.014251633738795, disc_loss = 0.0012361655331296015
Trained batch 141 in epoch 5, gen_loss = 2.015338082548598, disc_loss = 0.0012337669675258106
Trained batch 142 in epoch 5, gen_loss = 2.0142428683234264, disc_loss = 0.00123302883125021
Trained batch 143 in epoch 5, gen_loss = 2.0136977492107286, disc_loss = 0.0012336219333519693
Trained batch 144 in epoch 5, gen_loss = 2.0135859777187477, disc_loss = 0.0012334986264688958
Trained batch 145 in epoch 5, gen_loss = 2.013484718864911, disc_loss = 0.0012318714396638974
Trained batch 146 in epoch 5, gen_loss = 2.0149237420283206, disc_loss = 0.0012274834982334908
Trained batch 147 in epoch 5, gen_loss = 2.016859999379596, disc_loss = 0.0012260239529643662
Trained batch 148 in epoch 5, gen_loss = 2.016285562675271, disc_loss = 0.0012247734917984062
Trained batch 149 in epoch 5, gen_loss = 2.0168850779533387, disc_loss = 0.0012226609711069613
Trained batch 150 in epoch 5, gen_loss = 2.017136896682891, disc_loss = 0.0012210608974241016
Trained batch 151 in epoch 5, gen_loss = 2.0191952060712013, disc_loss = 0.0012188464671979953
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 2.1471290588378906, disc_loss = 0.0015695749316364527
Trained batch 1 in epoch 6, gen_loss = 2.279076099395752, disc_loss = 0.0016694992082193494
Trained batch 2 in epoch 6, gen_loss = 2.207858085632324, disc_loss = 0.0017234038872023423
Trained batch 3 in epoch 6, gen_loss = 2.2203714847564697, disc_loss = 0.0017265134665649384
Trained batch 4 in epoch 6, gen_loss = 2.105124068260193, disc_loss = 0.0017109362641349434
Trained batch 5 in epoch 6, gen_loss = 2.156830370426178, disc_loss = 0.0016515051829628646
Trained batch 6 in epoch 6, gen_loss = 2.1008197920663014, disc_loss = 0.0015685869314308678
Trained batch 7 in epoch 6, gen_loss = 2.0664054602384567, disc_loss = 0.0014803614612901583
Trained batch 8 in epoch 6, gen_loss = 2.055375403828091, disc_loss = 0.0013942466790063514
Trained batch 9 in epoch 6, gen_loss = 2.0843067288398744, disc_loss = 0.0013294339878484607
Trained batch 10 in epoch 6, gen_loss = 2.0592997724359687, disc_loss = 0.0012823165584863586
Trained batch 11 in epoch 6, gen_loss = 2.0461090306440988, disc_loss = 0.0012923352090486635
Trained batch 12 in epoch 6, gen_loss = 2.0615306542469907, disc_loss = 0.0014057448760677988
Trained batch 13 in epoch 6, gen_loss = 2.0517600178718567, disc_loss = 0.001565572664341224
Trained batch 14 in epoch 6, gen_loss = 2.0440913518269856, disc_loss = 0.0016866252835219106
Trained batch 15 in epoch 6, gen_loss = 2.0249502658843994, disc_loss = 0.0017153928856714629
Trained batch 16 in epoch 6, gen_loss = 2.019702469601351, disc_loss = 0.0016975439605577027
Trained batch 17 in epoch 6, gen_loss = 2.022554430696699, disc_loss = 0.0017519879297146366
Trained batch 18 in epoch 6, gen_loss = 2.047150078572725, disc_loss = 0.0018629943523065823
Trained batch 19 in epoch 6, gen_loss = 2.0278652608394623, disc_loss = 0.0019278806692454963
Trained batch 20 in epoch 6, gen_loss = 2.021706297284081, disc_loss = 0.0019222246427532462
Trained batch 21 in epoch 6, gen_loss = 2.010284423828125, disc_loss = 0.001880371588578617
Trained batch 22 in epoch 6, gen_loss = 2.0141546207925547, disc_loss = 0.0018761722047043884
Trained batch 23 in epoch 6, gen_loss = 2.01473867893219, disc_loss = 0.0018795744981616735
Trained batch 24 in epoch 6, gen_loss = 2.013712930679321, disc_loss = 0.0018471065722405911
Trained batch 25 in epoch 6, gen_loss = 2.010401734938988, disc_loss = 0.0018757629978398865
Trained batch 26 in epoch 6, gen_loss = 2.012483181776824, disc_loss = 0.001990243025055086
Trained batch 27 in epoch 6, gen_loss = 2.020335384777614, disc_loss = 0.002053653630095401
Trained batch 28 in epoch 6, gen_loss = 2.0096474433767386, disc_loss = 0.0020388477754875504
Trained batch 29 in epoch 6, gen_loss = 2.006568209330241, disc_loss = 0.0020045417011715473
Trained batch 30 in epoch 6, gen_loss = 2.0105678343003794, disc_loss = 0.0019901724449629264
Trained batch 31 in epoch 6, gen_loss = 2.003846175968647, disc_loss = 0.0019744720157177653
Trained batch 32 in epoch 6, gen_loss = 1.9984142924800063, disc_loss = 0.0019892538777750097
Trained batch 33 in epoch 6, gen_loss = 2.0026936951805565, disc_loss = 0.0020380273687324543
Trained batch 34 in epoch 6, gen_loss = 2.01325318472726, disc_loss = 0.0020582271773102027
Trained batch 35 in epoch 6, gen_loss = 2.014826946788364, disc_loss = 0.0020349249340749034
Trained batch 36 in epoch 6, gen_loss = 2.006094136753598, disc_loss = 0.002010300324449467
Trained batch 37 in epoch 6, gen_loss = 2.0058442762023523, disc_loss = 0.0020100444916782804
Trained batch 38 in epoch 6, gen_loss = 2.0071745255054574, disc_loss = 0.0020113832956084455
Trained batch 39 in epoch 6, gen_loss = 1.9996053636074067, disc_loss = 0.0019875900383340196
Trained batch 40 in epoch 6, gen_loss = 2.0046828490931814, disc_loss = 0.001962375812936665
Trained batch 41 in epoch 6, gen_loss = 2.0013038714726767, disc_loss = 0.0019477675142254504
Trained batch 42 in epoch 6, gen_loss = 2.002124403798303, disc_loss = 0.0019401530112508078
Trained batch 43 in epoch 6, gen_loss = 2.0019612935456363, disc_loss = 0.0019171053982890126
Trained batch 44 in epoch 6, gen_loss = 2.002517406145732, disc_loss = 0.0018907073264320692
Trained batch 45 in epoch 6, gen_loss = 1.9992279306701992, disc_loss = 0.0018812921277814262
Trained batch 46 in epoch 6, gen_loss = 1.9983095082830875, disc_loss = 0.001863164993181349
Trained batch 47 in epoch 6, gen_loss = 1.9948649083574612, disc_loss = 0.0018399275165090028
Trained batch 48 in epoch 6, gen_loss = 1.99160242567257, disc_loss = 0.0018187794900898422
Trained batch 49 in epoch 6, gen_loss = 1.99017418384552, disc_loss = 0.0017990171629935503
Trained batch 50 in epoch 6, gen_loss = 1.9943967005785774, disc_loss = 0.0017799228343053483
Trained batch 51 in epoch 6, gen_loss = 1.9900917823498065, disc_loss = 0.0017619143103589662
Trained batch 52 in epoch 6, gen_loss = 1.9896135397677153, disc_loss = 0.001750272809624461
Trained batch 53 in epoch 6, gen_loss = 1.9903720065399453, disc_loss = 0.0017334217112942565
Trained batch 54 in epoch 6, gen_loss = 1.9936127250844782, disc_loss = 0.0017168140451593156
Trained batch 55 in epoch 6, gen_loss = 1.9896549774067742, disc_loss = 0.0017052007803743305
Trained batch 56 in epoch 6, gen_loss = 1.992605399667171, disc_loss = 0.001696929330488242
Trained batch 57 in epoch 6, gen_loss = 1.987378745243467, disc_loss = 0.0016878831194280166
Trained batch 58 in epoch 6, gen_loss = 1.987581277297715, disc_loss = 0.0016868365741082294
Trained batch 59 in epoch 6, gen_loss = 1.987132696310679, disc_loss = 0.0016870309375614549
Trained batch 60 in epoch 6, gen_loss = 1.991224281123427, disc_loss = 0.001722891625116167
Trained batch 61 in epoch 6, gen_loss = 1.987237363092361, disc_loss = 0.001756992680208397
Trained batch 62 in epoch 6, gen_loss = 1.9948001608016, disc_loss = 0.001754370635367989
Trained batch 63 in epoch 6, gen_loss = 1.991517687216401, disc_loss = 0.00174753465125832
Trained batch 64 in epoch 6, gen_loss = 1.9890646072534415, disc_loss = 0.0017354630059204423
Trained batch 65 in epoch 6, gen_loss = 1.9888837229121814, disc_loss = 0.001723875347207385
Trained batch 66 in epoch 6, gen_loss = 1.990126090263253, disc_loss = 0.0017086646142554706
Trained batch 67 in epoch 6, gen_loss = 1.9930099739747889, disc_loss = 0.0016919573245104402
Trained batch 68 in epoch 6, gen_loss = 1.9937954156295112, disc_loss = 0.0016784439760975647
Trained batch 69 in epoch 6, gen_loss = 1.9898048639297485, disc_loss = 0.0016624752598415529
Trained batch 70 in epoch 6, gen_loss = 1.9948507899969397, disc_loss = 0.0016481396242071101
Trained batch 71 in epoch 6, gen_loss = 1.9959503312905629, disc_loss = 0.001640639207228863
Trained batch 72 in epoch 6, gen_loss = 1.9928589765339682, disc_loss = 0.0016324561964784277
Trained batch 73 in epoch 6, gen_loss = 1.9935578381693042, disc_loss = 0.0016198346691797614
Trained batch 74 in epoch 6, gen_loss = 1.994812798500061, disc_loss = 0.001605934260878712
Trained batch 75 in epoch 6, gen_loss = 1.998245667470129, disc_loss = 0.001593075169550598
Trained batch 76 in epoch 6, gen_loss = 1.9983992437263587, disc_loss = 0.0015815550018428498
Trained batch 77 in epoch 6, gen_loss = 2.0049558648696313, disc_loss = 0.00157066852448341
Trained batch 78 in epoch 6, gen_loss = 2.0084403481664537, disc_loss = 0.0015607936097061426
Trained batch 79 in epoch 6, gen_loss = 2.010835687816143, disc_loss = 0.0015488943921809551
Trained batch 80 in epoch 6, gen_loss = 2.012878746162226, disc_loss = 0.0015384117859979104
Trained batch 81 in epoch 6, gen_loss = 2.01205230340725, disc_loss = 0.0015321859661148998
Trained batch 82 in epoch 6, gen_loss = 2.0072929356471603, disc_loss = 0.00152764446522861
Trained batch 83 in epoch 6, gen_loss = 2.009630959658396, disc_loss = 0.0015199758012646011
Trained batch 84 in epoch 6, gen_loss = 2.0077515223447016, disc_loss = 0.0015148011214264176
Trained batch 85 in epoch 6, gen_loss = 2.004096340301425, disc_loss = 0.0015150843090702627
Trained batch 86 in epoch 6, gen_loss = 2.00370903535821, disc_loss = 0.0015097708138904866
Trained batch 87 in epoch 6, gen_loss = 2.00665799731558, disc_loss = 0.0015001503726869653
Trained batch 88 in epoch 6, gen_loss = 2.0044500988520935, disc_loss = 0.001493719657569119
Trained batch 89 in epoch 6, gen_loss = 2.0035180224312676, disc_loss = 0.0014891606859034961
Trained batch 90 in epoch 6, gen_loss = 2.0040379539950863, disc_loss = 0.0014844338299583766
Trained batch 91 in epoch 6, gen_loss = 2.0003167740676715, disc_loss = 0.0014880121895618251
Trained batch 92 in epoch 6, gen_loss = 2.0004818759938723, disc_loss = 0.0015000636346377833
Trained batch 93 in epoch 6, gen_loss = 2.003257765414867, disc_loss = 0.001499381121941545
Trained batch 94 in epoch 6, gen_loss = 2.00231229004107, disc_loss = 0.0014978661937148946
Trained batch 95 in epoch 6, gen_loss = 2.0040270077685514, disc_loss = 0.0014958829948833834
Trained batch 96 in epoch 6, gen_loss = 2.002675722554787, disc_loss = 0.0014872131509149505
Trained batch 97 in epoch 6, gen_loss = 2.0006895624861425, disc_loss = 0.0014830411231259303
Trained batch 98 in epoch 6, gen_loss = 1.9996197849813133, disc_loss = 0.0014784914450814025
Trained batch 99 in epoch 6, gen_loss = 1.9999363946914672, disc_loss = 0.0014685012877453118
Trained batch 100 in epoch 6, gen_loss = 1.997158411705848, disc_loss = 0.0014623990351573962
Trained batch 101 in epoch 6, gen_loss = 1.99675333850524, disc_loss = 0.001459065302019464
Trained batch 102 in epoch 6, gen_loss = 1.9982501476713754, disc_loss = 0.0014535112247702855
Trained batch 103 in epoch 6, gen_loss = 1.9986243603321223, disc_loss = 0.0014456191106896417
Trained batch 104 in epoch 6, gen_loss = 1.999927544593811, disc_loss = 0.0014369956627931623
Trained batch 105 in epoch 6, gen_loss = 2.000373308388692, disc_loss = 0.0014294684916198745
Trained batch 106 in epoch 6, gen_loss = 1.9983861023020522, disc_loss = 0.0014212527818255405
Trained batch 107 in epoch 6, gen_loss = 1.9970003841099915, disc_loss = 0.0014128453244834586
Trained batch 108 in epoch 6, gen_loss = 1.9959155288311319, disc_loss = 0.001407018194077622
Trained batch 109 in epoch 6, gen_loss = 1.995945756001906, disc_loss = 0.0014027459562798454
Trained batch 110 in epoch 6, gen_loss = 1.9977622923550304, disc_loss = 0.001397642844486646
Trained batch 111 in epoch 6, gen_loss = 1.998674855700561, disc_loss = 0.001391638833281052
Trained batch 112 in epoch 6, gen_loss = 1.9976185011652718, disc_loss = 0.001384467305821589
Trained batch 113 in epoch 6, gen_loss = 1.9979079470299839, disc_loss = 0.0013759441095763784
Trained batch 114 in epoch 6, gen_loss = 1.9966489926628443, disc_loss = 0.00136846065490871
Trained batch 115 in epoch 6, gen_loss = 1.993860910678732, disc_loss = 0.001365963694266172
Trained batch 116 in epoch 6, gen_loss = 1.9917930344231107, disc_loss = 0.0013673061452224914
Trained batch 117 in epoch 6, gen_loss = 1.9904087165654716, disc_loss = 0.001367403429605351
Trained batch 118 in epoch 6, gen_loss = 1.9888984916590844, disc_loss = 0.0013626719117673318
Trained batch 119 in epoch 6, gen_loss = 1.9903059820334117, disc_loss = 0.0013556642744030492
Trained batch 120 in epoch 6, gen_loss = 1.995606355430666, disc_loss = 0.001349252483168663
Trained batch 121 in epoch 6, gen_loss = 1.9933854663958315, disc_loss = 0.001344979704895866
Trained batch 122 in epoch 6, gen_loss = 1.9917901541159404, disc_loss = 0.0013432880627877283
Trained batch 123 in epoch 6, gen_loss = 1.9933722048036513, disc_loss = 0.0013385892426970626
Trained batch 124 in epoch 6, gen_loss = 1.991798758506775, disc_loss = 0.0013350418442860245
Trained batch 125 in epoch 6, gen_loss = 1.9911470365902735, disc_loss = 0.001335789526199242
Trained batch 126 in epoch 6, gen_loss = 1.9925960414991604, disc_loss = 0.0013345344593440453
Trained batch 127 in epoch 6, gen_loss = 1.9889689786359668, disc_loss = 0.0013298836074682185
Trained batch 128 in epoch 6, gen_loss = 1.9886953054472458, disc_loss = 0.0013248687434053526
Trained batch 129 in epoch 6, gen_loss = 1.9908387330862192, disc_loss = 0.0013229425033876815
Trained batch 130 in epoch 6, gen_loss = 1.98944953925737, disc_loss = 0.001318289375355652
Trained batch 131 in epoch 6, gen_loss = 1.9894206027189891, disc_loss = 0.0013124766538208914
Trained batch 132 in epoch 6, gen_loss = 1.9870116235618305, disc_loss = 0.0013094936148263514
Trained batch 133 in epoch 6, gen_loss = 1.9871827586373287, disc_loss = 0.0013050333259682825
Trained batch 134 in epoch 6, gen_loss = 1.9852731139571578, disc_loss = 0.0012994716426840535
Trained batch 135 in epoch 6, gen_loss = 1.9863663420957678, disc_loss = 0.0012951042967067812
Trained batch 136 in epoch 6, gen_loss = 1.9863598738273565, disc_loss = 0.0012897872128082018
Trained batch 137 in epoch 6, gen_loss = 1.9853707888851995, disc_loss = 0.0012842001818606386
Trained batch 138 in epoch 6, gen_loss = 1.9885624286939771, disc_loss = 0.0012782490680332585
Trained batch 139 in epoch 6, gen_loss = 1.9881117301327842, disc_loss = 0.0012721062066183158
Trained batch 140 in epoch 6, gen_loss = 1.9873372062723687, disc_loss = 0.0012670337465667688
Trained batch 141 in epoch 6, gen_loss = 1.9870456826518959, disc_loss = 0.0012623460389080156
Trained batch 142 in epoch 6, gen_loss = 1.987517878725812, disc_loss = 0.0012576846433135882
Trained batch 143 in epoch 6, gen_loss = 1.9858837905857298, disc_loss = 0.0012525983278869211
Trained batch 144 in epoch 6, gen_loss = 1.9848946217832895, disc_loss = 0.001247810948728423
Trained batch 145 in epoch 6, gen_loss = 1.9854563923731243, disc_loss = 0.0012433222973039883
Trained batch 146 in epoch 6, gen_loss = 1.986041369892302, disc_loss = 0.0012395007123609967
Trained batch 147 in epoch 6, gen_loss = 1.9870123033587996, disc_loss = 0.001236014771928092
Trained batch 148 in epoch 6, gen_loss = 1.988049885570603, disc_loss = 0.0012324109793431283
Trained batch 149 in epoch 6, gen_loss = 1.9871749671300252, disc_loss = 0.0012278213012420261
Trained batch 150 in epoch 6, gen_loss = 1.9874576780180269, disc_loss = 0.0012251497814909783
Trained batch 151 in epoch 6, gen_loss = 1.9873874132570468, disc_loss = 0.0012236120679804834
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.6707730293273926, disc_loss = 0.0007670770864933729
Trained batch 1 in epoch 7, gen_loss = 1.8304046392440796, disc_loss = 0.0007255644304677844
Trained batch 2 in epoch 7, gen_loss = 1.8729972044626872, disc_loss = 0.0006553782538200418
Trained batch 3 in epoch 7, gen_loss = 1.880556583404541, disc_loss = 0.000631343646091409
Trained batch 4 in epoch 7, gen_loss = 1.9643303871154785, disc_loss = 0.0006354074692353606
Trained batch 5 in epoch 7, gen_loss = 1.942595640818278, disc_loss = 0.0006719878292642534
Trained batch 6 in epoch 7, gen_loss = 1.8985562494822912, disc_loss = 0.0007146870318268027
Trained batch 7 in epoch 7, gen_loss = 1.906417965888977, disc_loss = 0.0007242478313855827
Trained batch 8 in epoch 7, gen_loss = 1.9199481805165608, disc_loss = 0.0007415254884916875
Trained batch 9 in epoch 7, gen_loss = 1.9022397160530091, disc_loss = 0.000732966372743249
Trained batch 10 in epoch 7, gen_loss = 1.9283127242868596, disc_loss = 0.000712004363198172
Trained batch 11 in epoch 7, gen_loss = 1.9185640116532643, disc_loss = 0.0007224052775806437
Trained batch 12 in epoch 7, gen_loss = 1.9240992894539466, disc_loss = 0.0007264904516677444
Trained batch 13 in epoch 7, gen_loss = 1.9349213072231837, disc_loss = 0.0007249245370206024
Trained batch 14 in epoch 7, gen_loss = 1.9315709511439005, disc_loss = 0.000709297131591787
Trained batch 15 in epoch 7, gen_loss = 1.9091030582785606, disc_loss = 0.0007079495117068291
Trained batch 16 in epoch 7, gen_loss = 1.906638264656067, disc_loss = 0.0007419049027649796
Trained batch 17 in epoch 7, gen_loss = 1.896465692255232, disc_loss = 0.0008075505417461196
Trained batch 18 in epoch 7, gen_loss = 1.8920910860362805, disc_loss = 0.0008612089349251045
Trained batch 19 in epoch 7, gen_loss = 1.8970887541770936, disc_loss = 0.0008709885238204152
Trained batch 20 in epoch 7, gen_loss = 1.8897043296269007, disc_loss = 0.0008625208228338687
Trained batch 21 in epoch 7, gen_loss = 1.8914346803318371, disc_loss = 0.0008697544081686912
Trained batch 22 in epoch 7, gen_loss = 1.9023198148478633, disc_loss = 0.0008902684608271912
Trained batch 23 in epoch 7, gen_loss = 1.900127425789833, disc_loss = 0.0009113434231646048
Trained batch 24 in epoch 7, gen_loss = 1.8976922225952149, disc_loss = 0.0009294990473426878
Trained batch 25 in epoch 7, gen_loss = 1.8948780252383306, disc_loss = 0.0009298038203269243
Trained batch 26 in epoch 7, gen_loss = 1.8963772146790117, disc_loss = 0.0009166611061017546
Trained batch 27 in epoch 7, gen_loss = 1.9066254368850164, disc_loss = 0.0009052276020936136
Trained batch 28 in epoch 7, gen_loss = 1.8992696794970283, disc_loss = 0.0008905112095064772
Trained batch 29 in epoch 7, gen_loss = 1.904038413365682, disc_loss = 0.0008809449529508129
Trained batch 30 in epoch 7, gen_loss = 1.904845295413848, disc_loss = 0.0008802552221177687
Trained batch 31 in epoch 7, gen_loss = 1.9030727110803127, disc_loss = 0.0008892383420970873
Trained batch 32 in epoch 7, gen_loss = 1.8933813066193552, disc_loss = 0.0009003934550988065
Trained batch 33 in epoch 7, gen_loss = 1.8971689027898453, disc_loss = 0.0009007221096373327
Trained batch 34 in epoch 7, gen_loss = 1.900360597882952, disc_loss = 0.0008950719684695027
Trained batch 35 in epoch 7, gen_loss = 1.8975265589025285, disc_loss = 0.0008872307185407004
Trained batch 36 in epoch 7, gen_loss = 1.8937565281584456, disc_loss = 0.0008799955885970612
Trained batch 37 in epoch 7, gen_loss = 1.8937370494792336, disc_loss = 0.0008720167488239607
Trained batch 38 in epoch 7, gen_loss = 1.8910933641286998, disc_loss = 0.0008683553352080381
Trained batch 39 in epoch 7, gen_loss = 1.8886060804128646, disc_loss = 0.0008598123815318104
Trained batch 40 in epoch 7, gen_loss = 1.8815929715226336, disc_loss = 0.0008551677775557903
Trained batch 41 in epoch 7, gen_loss = 1.8940668389910744, disc_loss = 0.0008677593078963193
Trained batch 42 in epoch 7, gen_loss = 1.900810019914494, disc_loss = 0.0008955668789323766
Trained batch 43 in epoch 7, gen_loss = 1.9046032428741455, disc_loss = 0.0009140474437365563
Trained batch 44 in epoch 7, gen_loss = 1.9095887925889756, disc_loss = 0.0009283051806657264
Trained batch 45 in epoch 7, gen_loss = 1.9094762646633645, disc_loss = 0.0009327029041267689
Trained batch 46 in epoch 7, gen_loss = 1.9029446891013613, disc_loss = 0.0009345447185122349
Trained batch 47 in epoch 7, gen_loss = 1.9059986149271329, disc_loss = 0.0009270966432571489
Trained batch 48 in epoch 7, gen_loss = 1.9054591266476377, disc_loss = 0.0009163967102091303
Trained batch 49 in epoch 7, gen_loss = 1.9079598331451415, disc_loss = 0.0009056940238224342
Trained batch 50 in epoch 7, gen_loss = 1.907620953578575, disc_loss = 0.0008948403279360968
Trained batch 51 in epoch 7, gen_loss = 1.9060504734516144, disc_loss = 0.0008886284346002727
Trained batch 52 in epoch 7, gen_loss = 1.900027353808565, disc_loss = 0.0008880310183399761
Trained batch 53 in epoch 7, gen_loss = 1.8992190338947155, disc_loss = 0.0008840639671284913
Trained batch 54 in epoch 7, gen_loss = 1.8958196444944901, disc_loss = 0.0008743920495775952
Trained batch 55 in epoch 7, gen_loss = 1.900627857872418, disc_loss = 0.0008688837411422615
Trained batch 56 in epoch 7, gen_loss = 1.9013462171219944, disc_loss = 0.0008637884273316319
Trained batch 57 in epoch 7, gen_loss = 1.8960533368176427, disc_loss = 0.0008633601572565285
Trained batch 58 in epoch 7, gen_loss = 1.9017473418833846, disc_loss = 0.0008773061065042738
Trained batch 59 in epoch 7, gen_loss = 1.9011151572068532, disc_loss = 0.0008983272637124173
Trained batch 60 in epoch 7, gen_loss = 1.899047878922009, disc_loss = 0.0009127481097210443
Trained batch 61 in epoch 7, gen_loss = 1.9103229661141672, disc_loss = 0.0009185591334244236
Trained batch 62 in epoch 7, gen_loss = 1.9098492330975003, disc_loss = 0.0009163419853725899
Trained batch 63 in epoch 7, gen_loss = 1.9103355687111616, disc_loss = 0.0009107379632951051
Trained batch 64 in epoch 7, gen_loss = 1.913854457781865, disc_loss = 0.0009033988059784931
Trained batch 65 in epoch 7, gen_loss = 1.9131986751700893, disc_loss = 0.0008954581518826836
Trained batch 66 in epoch 7, gen_loss = 1.914389033815754, disc_loss = 0.0008883025061075033
Trained batch 67 in epoch 7, gen_loss = 1.9165411591529846, disc_loss = 0.0008810528670437634
Trained batch 68 in epoch 7, gen_loss = 1.9149036614791206, disc_loss = 0.0008749585924332664
Trained batch 69 in epoch 7, gen_loss = 1.9174607345036099, disc_loss = 0.0008697241286946726
Trained batch 70 in epoch 7, gen_loss = 1.9212081801723426, disc_loss = 0.0008672100113062056
Trained batch 71 in epoch 7, gen_loss = 1.920485748185052, disc_loss = 0.000862334409450543
Trained batch 72 in epoch 7, gen_loss = 1.9245928934175673, disc_loss = 0.0008560036929413574
Trained batch 73 in epoch 7, gen_loss = 1.922936471732887, disc_loss = 0.0008516141789260547
Trained batch 74 in epoch 7, gen_loss = 1.9215771516164144, disc_loss = 0.0008517269634952147
Trained batch 75 in epoch 7, gen_loss = 1.9214966736341779, disc_loss = 0.0008472674173964677
Trained batch 76 in epoch 7, gen_loss = 1.9212037975137883, disc_loss = 0.0008417431699027392
Trained batch 77 in epoch 7, gen_loss = 1.9242778206482911, disc_loss = 0.0008359727922092694
Trained batch 78 in epoch 7, gen_loss = 1.9267423349090769, disc_loss = 0.0008300813625985167
Trained batch 79 in epoch 7, gen_loss = 1.9310710325837135, disc_loss = 0.000824709470543894
Trained batch 80 in epoch 7, gen_loss = 1.9291626700648554, disc_loss = 0.0008220297904587408
Trained batch 81 in epoch 7, gen_loss = 1.9292516940977515, disc_loss = 0.0008208496902825129
Trained batch 82 in epoch 7, gen_loss = 1.9335641975862434, disc_loss = 0.0008251355594186763
Trained batch 83 in epoch 7, gen_loss = 1.93243727513722, disc_loss = 0.0008298714019474573
Trained batch 84 in epoch 7, gen_loss = 1.93095025174758, disc_loss = 0.0008291953301522881
Trained batch 85 in epoch 7, gen_loss = 1.9315996377967124, disc_loss = 0.0008254507492258495
Trained batch 86 in epoch 7, gen_loss = 1.9314167198093457, disc_loss = 0.0008209322511630625
Trained batch 87 in epoch 7, gen_loss = 1.929558122699911, disc_loss = 0.000816669060771925
Trained batch 88 in epoch 7, gen_loss = 1.928225169021092, disc_loss = 0.0008130657962089132
Trained batch 89 in epoch 7, gen_loss = 1.9322821378707886, disc_loss = 0.0008087637617589078
Trained batch 90 in epoch 7, gen_loss = 1.9322594836518006, disc_loss = 0.000805637005724238
Trained batch 91 in epoch 7, gen_loss = 1.9312449201293613, disc_loss = 0.0008034880507772829
Trained batch 92 in epoch 7, gen_loss = 1.9294008337041384, disc_loss = 0.0007984805570524786
Trained batch 93 in epoch 7, gen_loss = 1.9249388169735036, disc_loss = 0.0008006967223952822
Trained batch 94 in epoch 7, gen_loss = 1.9283397611818816, disc_loss = 0.0008003112081879456
Trained batch 95 in epoch 7, gen_loss = 1.9300128184258938, disc_loss = 0.0007975378363577571
Trained batch 96 in epoch 7, gen_loss = 1.932131348196993, disc_loss = 0.0007955472317485849
Trained batch 97 in epoch 7, gen_loss = 1.9321171264259183, disc_loss = 0.0007931436703074723
Trained batch 98 in epoch 7, gen_loss = 1.9330403202711934, disc_loss = 0.000789586733027145
Trained batch 99 in epoch 7, gen_loss = 1.9313748121261596, disc_loss = 0.0007863892271416262
Trained batch 100 in epoch 7, gen_loss = 1.9315052103288104, disc_loss = 0.0007845747819410102
Trained batch 101 in epoch 7, gen_loss = 1.9303998783522962, disc_loss = 0.0007865435818173722
Trained batch 102 in epoch 7, gen_loss = 1.9297323597287668, disc_loss = 0.0007914457113020918
Trained batch 103 in epoch 7, gen_loss = 1.931617402113401, disc_loss = 0.0007937136307681123
Trained batch 104 in epoch 7, gen_loss = 1.9293843382880802, disc_loss = 0.0007947035932115146
Trained batch 105 in epoch 7, gen_loss = 1.9314392467714705, disc_loss = 0.0007955049052570929
Trained batch 106 in epoch 7, gen_loss = 1.9349775113792063, disc_loss = 0.0007966836385655208
Trained batch 107 in epoch 7, gen_loss = 1.9323386483722262, disc_loss = 0.0007946794147654953
Trained batch 108 in epoch 7, gen_loss = 1.931598769415409, disc_loss = 0.0007933573706562571
Trained batch 109 in epoch 7, gen_loss = 1.9291871786117554, disc_loss = 0.0007988497694234618
Trained batch 110 in epoch 7, gen_loss = 1.9297312949154828, disc_loss = 0.000807255193452678
Trained batch 111 in epoch 7, gen_loss = 1.9304409612502371, disc_loss = 0.0008102349763378568
Trained batch 112 in epoch 7, gen_loss = 1.9303706082622563, disc_loss = 0.0008091027353914965
Trained batch 113 in epoch 7, gen_loss = 1.929702691864549, disc_loss = 0.0008070431333116925
Trained batch 114 in epoch 7, gen_loss = 1.9277295941891877, disc_loss = 0.0008039266458186119
Trained batch 115 in epoch 7, gen_loss = 1.925017319876572, disc_loss = 0.0008006913548311347
Trained batch 116 in epoch 7, gen_loss = 1.9267530094864023, disc_loss = 0.0008005188438746856
Trained batch 117 in epoch 7, gen_loss = 1.926046250230175, disc_loss = 0.000802114121004213
Trained batch 118 in epoch 7, gen_loss = 1.9270905927449715, disc_loss = 0.000800293214822642
Trained batch 119 in epoch 7, gen_loss = 1.9290946344534556, disc_loss = 0.0007974578154971823
Trained batch 120 in epoch 7, gen_loss = 1.9281753094728329, disc_loss = 0.0007947086604804663
Trained batch 121 in epoch 7, gen_loss = 1.929276665703195, disc_loss = 0.0007916684298237907
Trained batch 122 in epoch 7, gen_loss = 1.9288073274178235, disc_loss = 0.0007890975313370941
Trained batch 123 in epoch 7, gen_loss = 1.9279957346377834, disc_loss = 0.0007866268924478772
Trained batch 124 in epoch 7, gen_loss = 1.9298446855545044, disc_loss = 0.0007830046331509948
Trained batch 125 in epoch 7, gen_loss = 1.9275622169176738, disc_loss = 0.000783676644214355
Trained batch 126 in epoch 7, gen_loss = 1.9270310552101435, disc_loss = 0.0007973118711768935
Trained batch 127 in epoch 7, gen_loss = 1.92763102799654, disc_loss = 0.0008139427013702516
Trained batch 128 in epoch 7, gen_loss = 1.9267410585122515, disc_loss = 0.0008286960687408902
Trained batch 129 in epoch 7, gen_loss = 1.926010643518888, disc_loss = 0.000839194811683578
Trained batch 130 in epoch 7, gen_loss = 1.9251614181139998, disc_loss = 0.0008509076962012883
Trained batch 131 in epoch 7, gen_loss = 1.9264809760180386, disc_loss = 0.000862767943269291
Trained batch 132 in epoch 7, gen_loss = 1.9259463943036876, disc_loss = 0.0008711026201577843
Trained batch 133 in epoch 7, gen_loss = 1.926759491215891, disc_loss = 0.0008727448419911036
Trained batch 134 in epoch 7, gen_loss = 1.9261454926596748, disc_loss = 0.0008788731445006474
Trained batch 135 in epoch 7, gen_loss = 1.9272075777544695, disc_loss = 0.0008929504217710072
Trained batch 136 in epoch 7, gen_loss = 1.927264794816066, disc_loss = 0.0009019738517830788
Trained batch 137 in epoch 7, gen_loss = 1.9267051807348279, disc_loss = 0.0009038624690298963
Trained batch 138 in epoch 7, gen_loss = 1.9248765689863576, disc_loss = 0.0009016144259417389
Trained batch 139 in epoch 7, gen_loss = 1.924284474338804, disc_loss = 0.00089830213172328
Trained batch 140 in epoch 7, gen_loss = 1.9260305741154555, disc_loss = 0.0008958770985573081
Trained batch 141 in epoch 7, gen_loss = 1.928401872305803, disc_loss = 0.0008948732052296794
Trained batch 142 in epoch 7, gen_loss = 1.9276581377416224, disc_loss = 0.0008920766810082238
Trained batch 143 in epoch 7, gen_loss = 1.9263868042164378, disc_loss = 0.0008885360024982623
Trained batch 144 in epoch 7, gen_loss = 1.924775010141833, disc_loss = 0.0008860139093955914
Trained batch 145 in epoch 7, gen_loss = 1.9243362766422638, disc_loss = 0.0008846302403133898
Trained batch 146 in epoch 7, gen_loss = 1.9264643046320702, disc_loss = 0.0008846668561771639
Trained batch 147 in epoch 7, gen_loss = 1.9253814429850191, disc_loss = 0.000887373043263545
Trained batch 148 in epoch 7, gen_loss = 1.9242909162636572, disc_loss = 0.0008913654696911999
Trained batch 149 in epoch 7, gen_loss = 1.9242496013641357, disc_loss = 0.0008955327656197672
Trained batch 150 in epoch 7, gen_loss = 1.9215176200235127, disc_loss = 0.0008974136556853349
Trained batch 151 in epoch 7, gen_loss = 1.920474297906223, disc_loss = 0.0008999999334168694
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.7647024393081665, disc_loss = 0.0010976631892845035
Trained batch 1 in epoch 8, gen_loss = 1.8163158893585205, disc_loss = 0.0009767484734766185
Trained batch 2 in epoch 8, gen_loss = 1.789743979771932, disc_loss = 0.0008612237482642134
Trained batch 3 in epoch 8, gen_loss = 1.7827148735523224, disc_loss = 0.0007878023025114089
Trained batch 4 in epoch 8, gen_loss = 1.8810888051986694, disc_loss = 0.0007432994549162686
Trained batch 5 in epoch 8, gen_loss = 1.8285404046376545, disc_loss = 0.0008634451563314846
Trained batch 6 in epoch 8, gen_loss = 1.821779761995588, disc_loss = 0.0010706460785253771
Trained batch 7 in epoch 8, gen_loss = 1.8501516282558441, disc_loss = 0.001131019693275448
Trained batch 8 in epoch 8, gen_loss = 1.8473163445790608, disc_loss = 0.001130956787771235
Trained batch 9 in epoch 8, gen_loss = 1.8919792890548706, disc_loss = 0.0010835570166818798
Trained batch 10 in epoch 8, gen_loss = 1.8757559277794578, disc_loss = 0.0010592351371253078
Trained batch 11 in epoch 8, gen_loss = 1.874996930360794, disc_loss = 0.0010746568344378222
Trained batch 12 in epoch 8, gen_loss = 1.868667144041795, disc_loss = 0.0010756788363393683
Trained batch 13 in epoch 8, gen_loss = 1.8603142499923706, disc_loss = 0.0010483112169562706
Trained batch 14 in epoch 8, gen_loss = 1.8663079738616943, disc_loss = 0.0010338385783446333
Trained batch 15 in epoch 8, gen_loss = 1.8706426620483398, disc_loss = 0.0010036337771452963
Trained batch 16 in epoch 8, gen_loss = 1.8859676192788517, disc_loss = 0.0009678601824870223
Trained batch 17 in epoch 8, gen_loss = 1.8920885456932917, disc_loss = 0.0009379519728503914
Trained batch 18 in epoch 8, gen_loss = 1.899981323041414, disc_loss = 0.0009152417601159725
Trained batch 19 in epoch 8, gen_loss = 1.8988799512386323, disc_loss = 0.0009036819174070843
Trained batch 20 in epoch 8, gen_loss = 1.901354233423869, disc_loss = 0.0008815365422162271
Trained batch 21 in epoch 8, gen_loss = 1.9083765745162964, disc_loss = 0.0008639924926683307
Trained batch 22 in epoch 8, gen_loss = 1.9101674297581548, disc_loss = 0.0008418297334371701
Trained batch 23 in epoch 8, gen_loss = 1.9098063757022221, disc_loss = 0.0008273318332309524
Trained batch 24 in epoch 8, gen_loss = 1.8987090349197389, disc_loss = 0.0008084721094928682
Trained batch 25 in epoch 8, gen_loss = 1.896228084197411, disc_loss = 0.0007923262231857874
Trained batch 26 in epoch 8, gen_loss = 1.9120157294803195, disc_loss = 0.0007820360532841059
Trained batch 27 in epoch 8, gen_loss = 1.9138177675860268, disc_loss = 0.0007761462547932751
Trained batch 28 in epoch 8, gen_loss = 1.90692073312299, disc_loss = 0.0007712047713696314
Trained batch 29 in epoch 8, gen_loss = 1.906556538740794, disc_loss = 0.0007657961153502887
Trained batch 30 in epoch 8, gen_loss = 1.9117940279745287, disc_loss = 0.0007583632053161461
Trained batch 31 in epoch 8, gen_loss = 1.9160884954035282, disc_loss = 0.0007465826556654065
Trained batch 32 in epoch 8, gen_loss = 1.9126288276730161, disc_loss = 0.000738159509086417
Trained batch 33 in epoch 8, gen_loss = 1.9177101605078752, disc_loss = 0.0007372210512745797
Trained batch 34 in epoch 8, gen_loss = 1.9217458418437412, disc_loss = 0.0007279826827081186
Trained batch 35 in epoch 8, gen_loss = 1.920126693116294, disc_loss = 0.0007163508174320062
Trained batch 36 in epoch 8, gen_loss = 1.9256080904522457, disc_loss = 0.0007098534575512482
Trained batch 37 in epoch 8, gen_loss = 1.9261283341207003, disc_loss = 0.0007005890166558521
Trained batch 38 in epoch 8, gen_loss = 1.9134742877422235, disc_loss = 0.0006970211830682671
Trained batch 39 in epoch 8, gen_loss = 1.9162018924951554, disc_loss = 0.0007234180884552188
Trained batch 40 in epoch 8, gen_loss = 1.9127067443801136, disc_loss = 0.0007586190434422617
Trained batch 41 in epoch 8, gen_loss = 1.9112642010052998, disc_loss = 0.000770653433088834
Trained batch 42 in epoch 8, gen_loss = 1.9060496646304463, disc_loss = 0.000774939835537225
Trained batch 43 in epoch 8, gen_loss = 1.907215803861618, disc_loss = 0.0007875766062749211
Trained batch 44 in epoch 8, gen_loss = 1.9027883450190226, disc_loss = 0.0008140783795776466
Trained batch 45 in epoch 8, gen_loss = 1.901329675446386, disc_loss = 0.0008414613181704898
Trained batch 46 in epoch 8, gen_loss = 1.8956796285953927, disc_loss = 0.0008516666675085559
Trained batch 47 in epoch 8, gen_loss = 1.8923644473155339, disc_loss = 0.0008490737248697163
Trained batch 48 in epoch 8, gen_loss = 1.8966956284581398, disc_loss = 0.0008433017682531203
Trained batch 49 in epoch 8, gen_loss = 1.8965068173408508, disc_loss = 0.0008443634887225926
Trained batch 50 in epoch 8, gen_loss = 1.903980668853311, disc_loss = 0.0008860933160701511
Trained batch 51 in epoch 8, gen_loss = 1.9042734114023356, disc_loss = 0.0009765212106196067
Trained batch 52 in epoch 8, gen_loss = 1.9054242642420642, disc_loss = 0.0010647903183334559
Trained batch 53 in epoch 8, gen_loss = 1.9037716962673046, disc_loss = 0.0011376770734959454
Trained batch 54 in epoch 8, gen_loss = 1.9069008523767645, disc_loss = 0.001185505471022969
Trained batch 55 in epoch 8, gen_loss = 1.9131113971982683, disc_loss = 0.0012089457658086239
Trained batch 56 in epoch 8, gen_loss = 1.9106045773154812, disc_loss = 0.001215823576785624
Trained batch 57 in epoch 8, gen_loss = 1.906228731418478, disc_loss = 0.0012185049668789424
Trained batch 58 in epoch 8, gen_loss = 1.906160481905533, disc_loss = 0.001208336055042001
Trained batch 59 in epoch 8, gen_loss = 1.9003823121388754, disc_loss = 0.0011958012968534605
Trained batch 60 in epoch 8, gen_loss = 1.8981905999730846, disc_loss = 0.0011879476579287867
Trained batch 61 in epoch 8, gen_loss = 1.8993740600924338, disc_loss = 0.0011780203813912286
Trained batch 62 in epoch 8, gen_loss = 1.892701750709897, disc_loss = 0.001171522314608511
Trained batch 63 in epoch 8, gen_loss = 1.8919302131980658, disc_loss = 0.0011641071878329967
Trained batch 64 in epoch 8, gen_loss = 1.8946812758078941, disc_loss = 0.0011603110308687275
Trained batch 65 in epoch 8, gen_loss = 1.8993489290728713, disc_loss = 0.0011503266110649388
Trained batch 66 in epoch 8, gen_loss = 1.9042317315713684, disc_loss = 0.0011412114540893417
Trained batch 67 in epoch 8, gen_loss = 1.9048433724571676, disc_loss = 0.0011297049504184328
Trained batch 68 in epoch 8, gen_loss = 1.9048704548158508, disc_loss = 0.0011195703451791644
Trained batch 69 in epoch 8, gen_loss = 1.8995760321617126, disc_loss = 0.0011095843677009856
Trained batch 70 in epoch 8, gen_loss = 1.895413209015215, disc_loss = 0.0011085549985963693
Trained batch 71 in epoch 8, gen_loss = 1.8979009836912155, disc_loss = 0.001113432312397183
Trained batch 72 in epoch 8, gen_loss = 1.896993836311445, disc_loss = 0.001117751640203881
Trained batch 73 in epoch 8, gen_loss = 1.9019383030968744, disc_loss = 0.0011161340658578116
Trained batch 74 in epoch 8, gen_loss = 1.8982814613978067, disc_loss = 0.001115574319846928
Trained batch 75 in epoch 8, gen_loss = 1.8986278678241528, disc_loss = 0.0011197128088066453
Trained batch 76 in epoch 8, gen_loss = 1.8966664091333167, disc_loss = 0.0011239904598877221
Trained batch 77 in epoch 8, gen_loss = 1.8942173627706675, disc_loss = 0.001123546958506967
Trained batch 78 in epoch 8, gen_loss = 1.8937770233878606, disc_loss = 0.0011176922840443499
Trained batch 79 in epoch 8, gen_loss = 1.8951378047466279, disc_loss = 0.0011095883022790077
Trained batch 80 in epoch 8, gen_loss = 1.8960188568374257, disc_loss = 0.0011021069845293912
Trained batch 81 in epoch 8, gen_loss = 1.895368656007255, disc_loss = 0.0010938069221660177
Trained batch 82 in epoch 8, gen_loss = 1.8941995695412877, disc_loss = 0.0010863242075492415
Trained batch 83 in epoch 8, gen_loss = 1.8937938752628507, disc_loss = 0.0010783944384283608
Trained batch 84 in epoch 8, gen_loss = 1.8956512731664321, disc_loss = 0.0010701158850946848
Trained batch 85 in epoch 8, gen_loss = 1.8938354835953823, disc_loss = 0.0010618976277412934
Trained batch 86 in epoch 8, gen_loss = 1.8931152409520642, disc_loss = 0.0010530502383527614
Trained batch 87 in epoch 8, gen_loss = 1.8933267810127952, disc_loss = 0.0010450621904800012
Trained batch 88 in epoch 8, gen_loss = 1.8933883664313327, disc_loss = 0.0010405132501893624
Trained batch 89 in epoch 8, gen_loss = 1.8941905776659647, disc_loss = 0.001035646274491834
Trained batch 90 in epoch 8, gen_loss = 1.8988618025412927, disc_loss = 0.0010288334342876224
Trained batch 91 in epoch 8, gen_loss = 1.9012677112351293, disc_loss = 0.0010219158278272041
Trained batch 92 in epoch 8, gen_loss = 1.9009669480785247, disc_loss = 0.0010149431695300405
Trained batch 93 in epoch 8, gen_loss = 1.8986276438895693, disc_loss = 0.0010080971504918279
Trained batch 94 in epoch 8, gen_loss = 1.8967637262846295, disc_loss = 0.0010001075129318787
Trained batch 95 in epoch 8, gen_loss = 1.8944989119966824, disc_loss = 0.0009921566988850827
Trained batch 96 in epoch 8, gen_loss = 1.8956663116966326, disc_loss = 0.0009853164962440077
Trained batch 97 in epoch 8, gen_loss = 1.8983556640391448, disc_loss = 0.0009785622880409224
Trained batch 98 in epoch 8, gen_loss = 1.8952170851254704, disc_loss = 0.0009712311915460635
Trained batch 99 in epoch 8, gen_loss = 1.8958384048938752, disc_loss = 0.0009654152567964047
Trained batch 100 in epoch 8, gen_loss = 1.8966199065198992, disc_loss = 0.0009599707301447887
Trained batch 101 in epoch 8, gen_loss = 1.8943059900227714, disc_loss = 0.0009597953541350423
Trained batch 102 in epoch 8, gen_loss = 1.894624866328193, disc_loss = 0.0009667981705329951
Trained batch 103 in epoch 8, gen_loss = 1.8926143795251846, disc_loss = 0.0009731438845987073
Trained batch 104 in epoch 8, gen_loss = 1.8929596628461565, disc_loss = 0.0009757063462443294
Trained batch 105 in epoch 8, gen_loss = 1.894044835612459, disc_loss = 0.0009715741040088447
Trained batch 106 in epoch 8, gen_loss = 1.8936595504529008, disc_loss = 0.0009667591325651471
Trained batch 107 in epoch 8, gen_loss = 1.8921779096126556, disc_loss = 0.0009618926797648546
Trained batch 108 in epoch 8, gen_loss = 1.8947388874281437, disc_loss = 0.0009558852065093986
Trained batch 109 in epoch 8, gen_loss = 1.8925707394426519, disc_loss = 0.0009509672910842875
Trained batch 110 in epoch 8, gen_loss = 1.8937159733729318, disc_loss = 0.0009465871490475193
Trained batch 111 in epoch 8, gen_loss = 1.8966406232544355, disc_loss = 0.0009413563467595461
Trained batch 112 in epoch 8, gen_loss = 1.8980807973220286, disc_loss = 0.000936639716177025
Trained batch 113 in epoch 8, gen_loss = 1.8952369606285764, disc_loss = 0.0009350140314557377
Trained batch 114 in epoch 8, gen_loss = 1.8967804120934528, disc_loss = 0.000932451548135799
Trained batch 115 in epoch 8, gen_loss = 1.8959342261840557, disc_loss = 0.0009271021109929405
Trained batch 116 in epoch 8, gen_loss = 1.8953581060099804, disc_loss = 0.0009219555620056314
Trained batch 117 in epoch 8, gen_loss = 1.8954748945721125, disc_loss = 0.0009164732493168154
Trained batch 118 in epoch 8, gen_loss = 1.893581180011525, disc_loss = 0.0009122945139861564
Trained batch 119 in epoch 8, gen_loss = 1.8942200362682342, disc_loss = 0.0009108714102088318
Trained batch 120 in epoch 8, gen_loss = 1.8954985279682255, disc_loss = 0.0009092605051734631
Trained batch 121 in epoch 8, gen_loss = 1.8936789465732262, disc_loss = 0.0009053856357225965
Trained batch 122 in epoch 8, gen_loss = 1.8917570773178969, disc_loss = 0.0009009553882865068
Trained batch 123 in epoch 8, gen_loss = 1.8915997532106215, disc_loss = 0.0008954995364840743
Trained batch 124 in epoch 8, gen_loss = 1.8937057418823242, disc_loss = 0.0008908381746150553
Trained batch 125 in epoch 8, gen_loss = 1.8921913939809043, disc_loss = 0.000887412822940239
Trained batch 126 in epoch 8, gen_loss = 1.892364475670762, disc_loss = 0.0008864794744592982
Trained batch 127 in epoch 8, gen_loss = 1.8926051473245025, disc_loss = 0.0008855113676418114
Trained batch 128 in epoch 8, gen_loss = 1.895983565685361, disc_loss = 0.0008840176541730039
Trained batch 129 in epoch 8, gen_loss = 1.8968447712751535, disc_loss = 0.0008812594292416739
Trained batch 130 in epoch 8, gen_loss = 1.895158652130884, disc_loss = 0.0008773692512088491
Trained batch 131 in epoch 8, gen_loss = 1.8938679704160402, disc_loss = 0.0008749604929824162
Trained batch 132 in epoch 8, gen_loss = 1.8948737831044018, disc_loss = 0.0008759008588346379
Trained batch 133 in epoch 8, gen_loss = 1.8941605197849558, disc_loss = 0.0008787559210705056
Trained batch 134 in epoch 8, gen_loss = 1.8941931512620713, disc_loss = 0.000881136008279605
Trained batch 135 in epoch 8, gen_loss = 1.8922185494619257, disc_loss = 0.0008801046556875328
Trained batch 136 in epoch 8, gen_loss = 1.892688065549753, disc_loss = 0.0008787877554325455
Trained batch 137 in epoch 8, gen_loss = 1.8903285515481147, disc_loss = 0.0008820723653669753
Trained batch 138 in epoch 8, gen_loss = 1.8907671429270463, disc_loss = 0.0008900526977184383
Trained batch 139 in epoch 8, gen_loss = 1.891477392401014, disc_loss = 0.0008998024871938729
Trained batch 140 in epoch 8, gen_loss = 1.8898413155941254, disc_loss = 0.0009080259346548494
Trained batch 141 in epoch 8, gen_loss = 1.8887706264643602, disc_loss = 0.0009124440860009791
Trained batch 142 in epoch 8, gen_loss = 1.8875826063689651, disc_loss = 0.0009157454022662258
Trained batch 143 in epoch 8, gen_loss = 1.8883267202311091, disc_loss = 0.0009171153938546518
Trained batch 144 in epoch 8, gen_loss = 1.8865109312123265, disc_loss = 0.0009183265080129536
Trained batch 145 in epoch 8, gen_loss = 1.887199584751913, disc_loss = 0.0009187255066672774
Trained batch 146 in epoch 8, gen_loss = 1.886619827374309, disc_loss = 0.0009180189195076371
Trained batch 147 in epoch 8, gen_loss = 1.8848678936829437, disc_loss = 0.0009154856120034851
Trained batch 148 in epoch 8, gen_loss = 1.8831924000042397, disc_loss = 0.000911864789980995
Trained batch 149 in epoch 8, gen_loss = 1.8840742349624633, disc_loss = 0.0009096925922979911
Trained batch 150 in epoch 8, gen_loss = 1.8823008355715416, disc_loss = 0.0009090303010091383
Trained batch 151 in epoch 8, gen_loss = 1.8819745253575475, disc_loss = 0.0009091149075079317
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.0591773986816406, disc_loss = 0.0009739550296217203
Trained batch 1 in epoch 9, gen_loss = 1.8715424537658691, disc_loss = 0.0014817062765359879
Trained batch 2 in epoch 9, gen_loss = 1.8199406862258911, disc_loss = 0.0022964910604059696
Trained batch 3 in epoch 9, gen_loss = 1.876998633146286, disc_loss = 0.002637065073940903
Trained batch 4 in epoch 9, gen_loss = 1.9345471143722535, disc_loss = 0.0026817778591066597
Trained batch 5 in epoch 9, gen_loss = 1.9256500204404194, disc_loss = 0.00263113621622324
Trained batch 6 in epoch 9, gen_loss = 1.9242620638438634, disc_loss = 0.002503279679720955
Trained batch 7 in epoch 9, gen_loss = 1.9299854189157486, disc_loss = 0.0022974309322307818
Trained batch 8 in epoch 9, gen_loss = 1.9416863520940144, disc_loss = 0.0020936242459962764
Trained batch 9 in epoch 9, gen_loss = 1.9178617238998412, disc_loss = 0.0019345959764905274
Trained batch 10 in epoch 9, gen_loss = 1.9097356579520486, disc_loss = 0.0018169037754308772
Trained batch 11 in epoch 9, gen_loss = 1.8821668823560078, disc_loss = 0.0017029589240943703
Trained batch 12 in epoch 9, gen_loss = 1.9098255267510047, disc_loss = 0.0016134844828719417
Trained batch 13 in epoch 9, gen_loss = 1.9072875125067574, disc_loss = 0.0015502480361776958
Trained batch 14 in epoch 9, gen_loss = 1.899329121907552, disc_loss = 0.0015134541259612887
Trained batch 15 in epoch 9, gen_loss = 1.911319687962532, disc_loss = 0.0014775561194255715
Trained batch 16 in epoch 9, gen_loss = 1.9258542762083166, disc_loss = 0.0014288590087637525
Trained batch 17 in epoch 9, gen_loss = 1.925783680544959, disc_loss = 0.0013768045221998666
Trained batch 18 in epoch 9, gen_loss = 1.9086761788318032, disc_loss = 0.0013481289635436905
Trained batch 19 in epoch 9, gen_loss = 1.9099350929260255, disc_loss = 0.0013224650858319365
Trained batch 20 in epoch 9, gen_loss = 1.9214054289318265, disc_loss = 0.0012783226598652878
Trained batch 21 in epoch 9, gen_loss = 1.9096122600815513, disc_loss = 0.0012340735913973979
Trained batch 22 in epoch 9, gen_loss = 1.9069947056148364, disc_loss = 0.001202285955356353
Trained batch 23 in epoch 9, gen_loss = 1.9009821166594822, disc_loss = 0.0011730526869844955
Trained batch 24 in epoch 9, gen_loss = 1.8937513303756714, disc_loss = 0.0011454050196334719
Trained batch 25 in epoch 9, gen_loss = 1.8912099462289076, disc_loss = 0.0011178485617095318
Trained batch 26 in epoch 9, gen_loss = 1.8960156131673742, disc_loss = 0.0010948795512646299
Trained batch 27 in epoch 9, gen_loss = 1.8926251147474562, disc_loss = 0.0010729373773626452
Trained batch 28 in epoch 9, gen_loss = 1.8844839909981037, disc_loss = 0.001049594061473256
Trained batch 29 in epoch 9, gen_loss = 1.878230102856954, disc_loss = 0.0010295672119051838
Trained batch 30 in epoch 9, gen_loss = 1.8851419802634948, disc_loss = 0.0010094352398863843
Trained batch 31 in epoch 9, gen_loss = 1.8902333080768585, disc_loss = 0.000995631859950663
Trained batch 32 in epoch 9, gen_loss = 1.889234275528879, disc_loss = 0.0009886062480015398
Trained batch 33 in epoch 9, gen_loss = 1.8811194756451775, disc_loss = 0.0009807605982881367
Trained batch 34 in epoch 9, gen_loss = 1.8768515654972622, disc_loss = 0.000970640907429957
Trained batch 35 in epoch 9, gen_loss = 1.8746161030398474, disc_loss = 0.000958998363380993
Trained batch 36 in epoch 9, gen_loss = 1.8688586918083396, disc_loss = 0.0009401752495496357
Trained batch 37 in epoch 9, gen_loss = 1.875704482982033, disc_loss = 0.0009221039401477595
Trained batch 38 in epoch 9, gen_loss = 1.8811935706016345, disc_loss = 0.0009058974869847775
Trained batch 39 in epoch 9, gen_loss = 1.8822473853826522, disc_loss = 0.0008893957128748298
Trained batch 40 in epoch 9, gen_loss = 1.881033016414177, disc_loss = 0.0008739395828054445
Trained batch 41 in epoch 9, gen_loss = 1.8752071999368214, disc_loss = 0.0008606197412258812
Trained batch 42 in epoch 9, gen_loss = 1.8742144218710965, disc_loss = 0.0008493910481351926
Trained batch 43 in epoch 9, gen_loss = 1.8699907606298274, disc_loss = 0.000835523979317672
Trained batch 44 in epoch 9, gen_loss = 1.8674210495418972, disc_loss = 0.0008321207045810297
Trained batch 45 in epoch 9, gen_loss = 1.8718274624451348, disc_loss = 0.0008318470186761418
Trained batch 46 in epoch 9, gen_loss = 1.8766845743706886, disc_loss = 0.0008347248426326451
Trained batch 47 in epoch 9, gen_loss = 1.8830127169688542, disc_loss = 0.0008370518580704811
Trained batch 48 in epoch 9, gen_loss = 1.8816728883860063, disc_loss = 0.0008314705720499195
Trained batch 49 in epoch 9, gen_loss = 1.873527615070343, disc_loss = 0.0008251007754006423
Trained batch 50 in epoch 9, gen_loss = 1.8732606055689793, disc_loss = 0.0008267297928207828
Trained batch 51 in epoch 9, gen_loss = 1.8698764901894789, disc_loss = 0.0008357754091915782
Trained batch 52 in epoch 9, gen_loss = 1.8702317678703453, disc_loss = 0.0008482165870208399
Trained batch 53 in epoch 9, gen_loss = 1.867816635855922, disc_loss = 0.0008645408522204014
Trained batch 54 in epoch 9, gen_loss = 1.8618254206397318, disc_loss = 0.0008842869325731457
Trained batch 55 in epoch 9, gen_loss = 1.8609324374369212, disc_loss = 0.0008989689400290704
Trained batch 56 in epoch 9, gen_loss = 1.8574772801315576, disc_loss = 0.0009024745966981802
Trained batch 57 in epoch 9, gen_loss = 1.858130054227237, disc_loss = 0.0008960004109620309
Trained batch 58 in epoch 9, gen_loss = 1.8598128112695984, disc_loss = 0.0008860518911683742
Trained batch 59 in epoch 9, gen_loss = 1.8616028308868409, disc_loss = 0.000876246030141677
Trained batch 60 in epoch 9, gen_loss = 1.8651351029755638, disc_loss = 0.000865785975904265
Trained batch 61 in epoch 9, gen_loss = 1.8649000160155758, disc_loss = 0.0008611140508418753
Trained batch 62 in epoch 9, gen_loss = 1.8619320771050831, disc_loss = 0.0008559245904926063
Trained batch 63 in epoch 9, gen_loss = 1.863148469477892, disc_loss = 0.000846171318926281
Trained batch 64 in epoch 9, gen_loss = 1.8639602661132812, disc_loss = 0.0008358615161761498
Trained batch 65 in epoch 9, gen_loss = 1.8695855249058118, disc_loss = 0.0008265751841298135
Trained batch 66 in epoch 9, gen_loss = 1.869446188656252, disc_loss = 0.0008190706445672202
Trained batch 67 in epoch 9, gen_loss = 1.8684110851848827, disc_loss = 0.0008109874669411083
Trained batch 68 in epoch 9, gen_loss = 1.864275612692902, disc_loss = 0.0008053977560822218
Trained batch 69 in epoch 9, gen_loss = 1.8634698850767952, disc_loss = 0.0008030587892530353
Trained batch 70 in epoch 9, gen_loss = 1.8660068830973666, disc_loss = 0.0007993253818991869
Trained batch 71 in epoch 9, gen_loss = 1.8636947969595592, disc_loss = 0.0007949942234214783
Trained batch 72 in epoch 9, gen_loss = 1.862136716712011, disc_loss = 0.0007896190945757553
Trained batch 73 in epoch 9, gen_loss = 1.8637375042245194, disc_loss = 0.000783794186891346
Trained batch 74 in epoch 9, gen_loss = 1.861396803855896, disc_loss = 0.0007841795700369403
Trained batch 75 in epoch 9, gen_loss = 1.861651404907829, disc_loss = 0.0007868122884246986
Trained batch 76 in epoch 9, gen_loss = 1.8563568266955288, disc_loss = 0.0007937246173478107
Trained batch 77 in epoch 9, gen_loss = 1.8566554494393177, disc_loss = 0.0008110504521680876
Trained batch 78 in epoch 9, gen_loss = 1.8582275155224377, disc_loss = 0.0008240939131598991
Trained batch 79 in epoch 9, gen_loss = 1.855142679810524, disc_loss = 0.000827349382052489
Trained batch 80 in epoch 9, gen_loss = 1.853413615697696, disc_loss = 0.0008246226498158649
Trained batch 81 in epoch 9, gen_loss = 1.8526382431751345, disc_loss = 0.0008200478284668019
Trained batch 82 in epoch 9, gen_loss = 1.8578110358801232, disc_loss = 0.0008139467630914064
Trained batch 83 in epoch 9, gen_loss = 1.8580199749696822, disc_loss = 0.0008141756765585992
Trained batch 84 in epoch 9, gen_loss = 1.8606998990563786, disc_loss = 0.0008173632899449919
Trained batch 85 in epoch 9, gen_loss = 1.8558488280274148, disc_loss = 0.0008229428405134375
Trained batch 86 in epoch 9, gen_loss = 1.8535777837380596, disc_loss = 0.0008260343669065349
Trained batch 87 in epoch 9, gen_loss = 1.8510095382278615, disc_loss = 0.0008245760134079981
Trained batch 88 in epoch 9, gen_loss = 1.8521852225400088, disc_loss = 0.0008203068042103347
Trained batch 89 in epoch 9, gen_loss = 1.8578674422370063, disc_loss = 0.0008175821517296653
Trained batch 90 in epoch 9, gen_loss = 1.8567482036548657, disc_loss = 0.00082363681384787
Trained batch 91 in epoch 9, gen_loss = 1.8571804943292036, disc_loss = 0.0008367696334418091
Trained batch 92 in epoch 9, gen_loss = 1.8554420317372968, disc_loss = 0.0008507262978274675
Trained batch 93 in epoch 9, gen_loss = 1.853978972485725, disc_loss = 0.0008620767492833151
Trained batch 94 in epoch 9, gen_loss = 1.8556489580555966, disc_loss = 0.0008640259009553119
Trained batch 95 in epoch 9, gen_loss = 1.8594874429206054, disc_loss = 0.0008590895339087486
Trained batch 96 in epoch 9, gen_loss = 1.861217853949242, disc_loss = 0.0008578949315970303
Trained batch 97 in epoch 9, gen_loss = 1.8607839844664749, disc_loss = 0.0008571484286221676
Trained batch 98 in epoch 9, gen_loss = 1.8623088237011072, disc_loss = 0.0008567990057553738
Trained batch 99 in epoch 9, gen_loss = 1.8605891919136048, disc_loss = 0.0008569995684956666
Trained batch 100 in epoch 9, gen_loss = 1.8607540708957333, disc_loss = 0.000856858871659347
Trained batch 101 in epoch 9, gen_loss = 1.8592018847372018, disc_loss = 0.0008551255597529805
Trained batch 102 in epoch 9, gen_loss = 1.8591836876082188, disc_loss = 0.0008520742744666262
Trained batch 103 in epoch 9, gen_loss = 1.8586172610521317, disc_loss = 0.000847289840609077
Trained batch 104 in epoch 9, gen_loss = 1.8569254636764527, disc_loss = 0.0008437513017616723
Trained batch 105 in epoch 9, gen_loss = 1.8562437442113768, disc_loss = 0.0008403225619299777
Trained batch 106 in epoch 9, gen_loss = 1.8544973547213546, disc_loss = 0.0008351826939947259
Trained batch 107 in epoch 9, gen_loss = 1.8554599340315219, disc_loss = 0.0008299567536461702
Trained batch 108 in epoch 9, gen_loss = 1.8564228694373315, disc_loss = 0.0008246516292207712
Trained batch 109 in epoch 9, gen_loss = 1.8588573575019836, disc_loss = 0.0008208251951145939
Trained batch 110 in epoch 9, gen_loss = 1.8591337934270635, disc_loss = 0.0008178498227042272
Trained batch 111 in epoch 9, gen_loss = 1.857116379908153, disc_loss = 0.0008151331906317084
Trained batch 112 in epoch 9, gen_loss = 1.8558530026832514, disc_loss = 0.0008127285314124259
Trained batch 113 in epoch 9, gen_loss = 1.8563202546353925, disc_loss = 0.000812334252195637
Trained batch 114 in epoch 9, gen_loss = 1.8542315877002218, disc_loss = 0.0008142052923136836
Trained batch 115 in epoch 9, gen_loss = 1.8564662316749836, disc_loss = 0.0008177148738468532
Trained batch 116 in epoch 9, gen_loss = 1.854463075980162, disc_loss = 0.0008197848126142978
Trained batch 117 in epoch 9, gen_loss = 1.8560520430742684, disc_loss = 0.0008230995456145492
Trained batch 118 in epoch 9, gen_loss = 1.8553392145814014, disc_loss = 0.0008254538857849597
Trained batch 119 in epoch 9, gen_loss = 1.855484868089358, disc_loss = 0.0008241148157442997
Trained batch 120 in epoch 9, gen_loss = 1.8562020299848445, disc_loss = 0.0008231397620296444
Trained batch 121 in epoch 9, gen_loss = 1.857919129191852, disc_loss = 0.0008203039265697685
Trained batch 122 in epoch 9, gen_loss = 1.858536419829702, disc_loss = 0.0008160519214655553
Trained batch 123 in epoch 9, gen_loss = 1.8607070253741356, disc_loss = 0.0008131350324190628
Trained batch 124 in epoch 9, gen_loss = 1.861462887763977, disc_loss = 0.0008096689941594378
Trained batch 125 in epoch 9, gen_loss = 1.863773589096372, disc_loss = 0.0008055208721392167
Trained batch 126 in epoch 9, gen_loss = 1.8623718379989385, disc_loss = 0.0008024350043586052
Trained batch 127 in epoch 9, gen_loss = 1.8650102289393544, disc_loss = 0.0008010374764353401
Trained batch 128 in epoch 9, gen_loss = 1.8661438078843346, disc_loss = 0.0008024853802432284
Trained batch 129 in epoch 9, gen_loss = 1.8675958239115202, disc_loss = 0.0008065874344678238
Trained batch 130 in epoch 9, gen_loss = 1.8655353893760507, disc_loss = 0.0008105251371357518
Trained batch 131 in epoch 9, gen_loss = 1.8642875814076625, disc_loss = 0.0008128047150173436
Trained batch 132 in epoch 9, gen_loss = 1.8622590832244186, disc_loss = 0.0008129693758787756
Trained batch 133 in epoch 9, gen_loss = 1.8601295725623173, disc_loss = 0.000810094965155299
Trained batch 134 in epoch 9, gen_loss = 1.857395064389264, disc_loss = 0.0008076626590789399
Trained batch 135 in epoch 9, gen_loss = 1.856005021754433, disc_loss = 0.0008045728516342077
Trained batch 136 in epoch 9, gen_loss = 1.8554092236678965, disc_loss = 0.0008011753344780894
Trained batch 137 in epoch 9, gen_loss = 1.85386163773744, disc_loss = 0.0007993514904544851
Trained batch 138 in epoch 9, gen_loss = 1.8547795367755477, disc_loss = 0.000798374045202207
Trained batch 139 in epoch 9, gen_loss = 1.853976583480835, disc_loss = 0.0007970712165323285
Trained batch 140 in epoch 9, gen_loss = 1.8538020976046299, disc_loss = 0.0007942793768019818
Trained batch 141 in epoch 9, gen_loss = 1.853104485592372, disc_loss = 0.0007908226809223366
Trained batch 142 in epoch 9, gen_loss = 1.8529652340428813, disc_loss = 0.0007890643267216604
Trained batch 143 in epoch 9, gen_loss = 1.85428456382619, disc_loss = 0.0007898622462663399
Trained batch 144 in epoch 9, gen_loss = 1.8536901021825856, disc_loss = 0.0007914200558624199
Trained batch 145 in epoch 9, gen_loss = 1.8548291129608676, disc_loss = 0.0007940764625258552
Trained batch 146 in epoch 9, gen_loss = 1.8542167483543863, disc_loss = 0.0007960574285065451
Trained batch 147 in epoch 9, gen_loss = 1.8541926620779812, disc_loss = 0.0007971497493476695
Trained batch 148 in epoch 9, gen_loss = 1.8529689327982448, disc_loss = 0.0007959467288764544
Trained batch 149 in epoch 9, gen_loss = 1.854490434328715, disc_loss = 0.0007971801830960127
Trained batch 150 in epoch 9, gen_loss = 1.855347245734259, disc_loss = 0.0007981276198402849
Trained batch 151 in epoch 9, gen_loss = 1.8537101620122005, disc_loss = 0.0007990616015472609
Testing Epoch 9
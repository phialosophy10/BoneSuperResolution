/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5501489043235779, disc_loss = 0.5714585781097412
Trained batch 1 in epoch 0, gen_loss = 0.528908759355545, disc_loss = 0.7481993734836578
Trained batch 2 in epoch 0, gen_loss = 0.5344441930452982, disc_loss = 0.6513209541638693
Trained batch 3 in epoch 0, gen_loss = 0.5410044640302658, disc_loss = 0.6077501624822617
Trained batch 4 in epoch 0, gen_loss = 0.5275487244129181, disc_loss = 0.5534690320491791
Trained batch 5 in epoch 0, gen_loss = 0.5202698856592178, disc_loss = 0.5001798123121262
Trained batch 6 in epoch 0, gen_loss = 0.5092909123216357, disc_loss = 0.4624491206237248
Trained batch 7 in epoch 0, gen_loss = 0.5050993002951145, disc_loss = 0.4265221320092678
Trained batch 8 in epoch 0, gen_loss = 0.4944065709908803, disc_loss = 0.3941076348225276
Trained batch 9 in epoch 0, gen_loss = 0.4875753909349442, disc_loss = 0.3650015026330948
Trained batch 10 in epoch 0, gen_loss = 0.4901531690900976, disc_loss = 0.342951429838484
Trained batch 11 in epoch 0, gen_loss = 0.48951225976149243, disc_loss = 0.3223805862168471
Trained batch 12 in epoch 0, gen_loss = 0.49029821157455444, disc_loss = 0.31041750655724454
Trained batch 13 in epoch 0, gen_loss = 0.48531778369631084, disc_loss = 0.29686425785933224
Trained batch 14 in epoch 0, gen_loss = 0.4851349631945292, disc_loss = 0.2831960886716843
Trained batch 15 in epoch 0, gen_loss = 0.48221250623464584, disc_loss = 0.274063597433269
Trained batch 16 in epoch 0, gen_loss = 0.48596538866267486, disc_loss = 0.26418086009867053
Trained batch 17 in epoch 0, gen_loss = 0.48881348967552185, disc_loss = 0.2549473461177614
Trained batch 18 in epoch 0, gen_loss = 0.4894291978133352, disc_loss = 0.24630706992588544
Trained batch 19 in epoch 0, gen_loss = 0.4939211517572403, disc_loss = 0.2406031008809805
Trained batch 20 in epoch 0, gen_loss = 0.4968282949356806, disc_loss = 0.23304374586968196
Trained batch 21 in epoch 0, gen_loss = 0.4999456893314015, disc_loss = 0.22564764016053893
Trained batch 22 in epoch 0, gen_loss = 0.49615870480952057, disc_loss = 0.2188942147337872
Trained batch 23 in epoch 0, gen_loss = 0.49753569935758907, disc_loss = 0.21588569631179175
Trained batch 24 in epoch 0, gen_loss = 0.49943605303764343, disc_loss = 0.21145798981189728
Trained batch 25 in epoch 0, gen_loss = 0.498873124902065, disc_loss = 0.20758130086156037
Trained batch 26 in epoch 0, gen_loss = 0.49626327333626924, disc_loss = 0.20344292869170508
Trained batch 27 in epoch 0, gen_loss = 0.4956053931798254, disc_loss = 0.20087585890931742
Trained batch 28 in epoch 0, gen_loss = 0.4939903627181875, disc_loss = 0.19697485581554217
Trained batch 29 in epoch 0, gen_loss = 0.49410377244154613, disc_loss = 0.19200901538133622
Trained batch 30 in epoch 0, gen_loss = 0.49145238726369794, disc_loss = 0.18824973726464855
Trained batch 31 in epoch 0, gen_loss = 0.49306573811918497, disc_loss = 0.18440782045945525
Trained batch 32 in epoch 0, gen_loss = 0.4940291327057463, disc_loss = 0.18090064191456998
Trained batch 33 in epoch 0, gen_loss = 0.4949891137726167, disc_loss = 0.1772283096523846
Trained batch 34 in epoch 0, gen_loss = 0.496092974288123, disc_loss = 0.1735605265413012
Trained batch 35 in epoch 0, gen_loss = 0.4967212966746754, disc_loss = 0.1706982230146726
Trained batch 36 in epoch 0, gen_loss = 0.49737442425779393, disc_loss = 0.1703986626219105
Trained batch 37 in epoch 0, gen_loss = 0.49982324791582006, disc_loss = 0.1698588407353351
Trained batch 38 in epoch 0, gen_loss = 0.5030934115250906, disc_loss = 0.16738825157666817
Trained batch 39 in epoch 0, gen_loss = 0.5026433624327182, disc_loss = 0.16438893247395753
Trained batch 40 in epoch 0, gen_loss = 0.5028268266014937, disc_loss = 0.16158067489542613
Trained batch 41 in epoch 0, gen_loss = 0.503734094046411, disc_loss = 0.1587821011032377
Trained batch 42 in epoch 0, gen_loss = 0.5034146759399148, disc_loss = 0.1558329495926236
Trained batch 43 in epoch 0, gen_loss = 0.5029808303171938, disc_loss = 0.15302222010425545
Trained batch 44 in epoch 0, gen_loss = 0.5035413073168861, disc_loss = 0.15166058796975349
Trained batch 45 in epoch 0, gen_loss = 0.5031829800294794, disc_loss = 0.15031588733520196
Trained batch 46 in epoch 0, gen_loss = 0.5021167162885057, disc_loss = 0.15057671965753777
Trained batch 47 in epoch 0, gen_loss = 0.5049994122236967, disc_loss = 0.15080812425973514
Trained batch 48 in epoch 0, gen_loss = 0.5045527870557747, disc_loss = 0.14979888977749006
Trained batch 49 in epoch 0, gen_loss = 0.5049815040826797, disc_loss = 0.14936303786933422
Trained batch 50 in epoch 0, gen_loss = 0.5068065097518996, disc_loss = 0.14746697305464276
Trained batch 51 in epoch 0, gen_loss = 0.5056482209609106, disc_loss = 0.1466106755229143
Trained batch 52 in epoch 0, gen_loss = 0.5080322330852725, disc_loss = 0.144900936000752
Trained batch 53 in epoch 0, gen_loss = 0.507824249289654, disc_loss = 0.14363504753068643
Trained batch 54 in epoch 0, gen_loss = 0.5080658462914553, disc_loss = 0.1416137261146849
Trained batch 55 in epoch 0, gen_loss = 0.5067095314817769, disc_loss = 0.139670894946903
Trained batch 56 in epoch 0, gen_loss = 0.5048600733280182, disc_loss = 0.13767111334100104
Trained batch 57 in epoch 0, gen_loss = 0.505478603572681, disc_loss = 0.1356457618932272
Trained batch 58 in epoch 0, gen_loss = 0.5042244458602647, disc_loss = 0.1336518652042595
Trained batch 59 in epoch 0, gen_loss = 0.5051364133755366, disc_loss = 0.1317577133886516
Trained batch 60 in epoch 0, gen_loss = 0.5054389717148953, disc_loss = 0.12991450598738233
Trained batch 61 in epoch 0, gen_loss = 0.5066455391145521, disc_loss = 0.12814789956375475
Trained batch 62 in epoch 0, gen_loss = 0.50605175372154, disc_loss = 0.12636527147084947
Trained batch 63 in epoch 0, gen_loss = 0.5062380614690483, disc_loss = 0.12463649825076573
Trained batch 64 in epoch 0, gen_loss = 0.5058646390071282, disc_loss = 0.12307571553840087
Trained batch 65 in epoch 0, gen_loss = 0.5046648879845937, disc_loss = 0.12153811600397933
Trained batch 66 in epoch 0, gen_loss = 0.5044470447212902, disc_loss = 0.12009498299057804
Trained batch 67 in epoch 0, gen_loss = 0.5041309472392587, disc_loss = 0.11858946019235779
Trained batch 68 in epoch 0, gen_loss = 0.5024828932423523, disc_loss = 0.11714236980871014
Trained batch 69 in epoch 0, gen_loss = 0.5011279821395874, disc_loss = 0.11572529058903455
Trained batch 70 in epoch 0, gen_loss = 0.50134780037571, disc_loss = 0.11435196034505334
Trained batch 71 in epoch 0, gen_loss = 0.5016632253925005, disc_loss = 0.1129989598153366
Trained batch 72 in epoch 0, gen_loss = 0.5017707102919278, disc_loss = 0.11169819658851787
Trained batch 73 in epoch 0, gen_loss = 0.501964957327456, disc_loss = 0.11040978574168843
Trained batch 74 in epoch 0, gen_loss = 0.5025991559028625, disc_loss = 0.1091358778377374
Trained batch 75 in epoch 0, gen_loss = 0.5006114848350224, disc_loss = 0.10834456053807547
Trained batch 76 in epoch 0, gen_loss = 0.5000001223056347, disc_loss = 0.10742964348816253
Trained batch 77 in epoch 0, gen_loss = 0.5002548358379266, disc_loss = 0.10650437029126363
Trained batch 78 in epoch 0, gen_loss = 0.5004001320162906, disc_loss = 0.10545535140399691
Trained batch 79 in epoch 0, gen_loss = 0.49977274872362615, disc_loss = 0.1043423302937299
Trained batch 80 in epoch 0, gen_loss = 0.4985668957233429, disc_loss = 0.10323695511913594
Trained batch 81 in epoch 0, gen_loss = 0.4979188722081301, disc_loss = 0.10219291988305929
Trained batch 82 in epoch 0, gen_loss = 0.49840987482702875, disc_loss = 0.10114998076425259
Trained batch 83 in epoch 0, gen_loss = 0.49926737057311193, disc_loss = 0.1001322843311798
Trained batch 84 in epoch 0, gen_loss = 0.49946470506051005, disc_loss = 0.09911806732416154
Trained batch 85 in epoch 0, gen_loss = 0.49841583294923913, disc_loss = 0.09812471027984175
Trained batch 86 in epoch 0, gen_loss = 0.4982561760250179, disc_loss = 0.09714560700987263
Trained batch 87 in epoch 0, gen_loss = 0.4979895827445117, disc_loss = 0.09621062950993126
Trained batch 88 in epoch 0, gen_loss = 0.49807553612784056, disc_loss = 0.09530479986262455
Trained batch 89 in epoch 0, gen_loss = 0.4969924016131295, disc_loss = 0.09440384643773238
Trained batch 90 in epoch 0, gen_loss = 0.4970595270067781, disc_loss = 0.09354318318131206
Trained batch 91 in epoch 0, gen_loss = 0.49684132894744043, disc_loss = 0.092702343614529
Trained batch 92 in epoch 0, gen_loss = 0.4962436386974909, disc_loss = 0.09187765794015058
Trained batch 93 in epoch 0, gen_loss = 0.4971591522718998, disc_loss = 0.09107534779592398
Trained batch 94 in epoch 0, gen_loss = 0.4968930344832571, disc_loss = 0.0902618259387581
Trained batch 95 in epoch 0, gen_loss = 0.496798325330019, disc_loss = 0.08945394480057682
Trained batch 96 in epoch 0, gen_loss = 0.4961098195965757, disc_loss = 0.0886718909611407
Trained batch 97 in epoch 0, gen_loss = 0.4965281982202919, disc_loss = 0.08791583796430912
Trained batch 98 in epoch 0, gen_loss = 0.4963466389612718, disc_loss = 0.08714929032092443
Trained batch 99 in epoch 0, gen_loss = 0.496565588414669, disc_loss = 0.08642986349761486
Trained batch 100 in epoch 0, gen_loss = 0.4963279753038199, disc_loss = 0.08573514466533566
Trained batch 101 in epoch 0, gen_loss = 0.49753474458759905, disc_loss = 0.08507021447168846
Trained batch 102 in epoch 0, gen_loss = 0.4975979336835806, disc_loss = 0.08439900254089276
Trained batch 103 in epoch 0, gen_loss = 0.49756603143536127, disc_loss = 0.08373460769116019
Trained batch 104 in epoch 0, gen_loss = 0.49687112115678334, disc_loss = 0.08307290361041114
Trained batch 105 in epoch 0, gen_loss = 0.4967817557307909, disc_loss = 0.08239090165017911
Trained batch 106 in epoch 0, gen_loss = 0.49633956289737025, disc_loss = 0.08171635884443455
Trained batch 107 in epoch 0, gen_loss = 0.4966868857542674, disc_loss = 0.08108532368377955
Trained batch 108 in epoch 0, gen_loss = 0.49663344080295035, disc_loss = 0.08049468403904263
Trained batch 109 in epoch 0, gen_loss = 0.4966421130028638, disc_loss = 0.07999009005725384
Trained batch 110 in epoch 0, gen_loss = 0.49681173600592055, disc_loss = 0.07947074007746335
Trained batch 111 in epoch 0, gen_loss = 0.4960885425763471, disc_loss = 0.07889273335292403
Trained batch 112 in epoch 0, gen_loss = 0.49559130367979537, disc_loss = 0.07830481458686095
Trained batch 113 in epoch 0, gen_loss = 0.4952170757348077, disc_loss = 0.07772772033747874
Trained batch 114 in epoch 0, gen_loss = 0.49497055152188174, disc_loss = 0.07715323742317116
Trained batch 115 in epoch 0, gen_loss = 0.4951184779919427, disc_loss = 0.07657651993413937
Trained batch 116 in epoch 0, gen_loss = 0.49494774142901105, disc_loss = 0.07600284926593304
Trained batch 117 in epoch 0, gen_loss = 0.49479210023152626, disc_loss = 0.07543258046163089
Trained batch 118 in epoch 0, gen_loss = 0.4940880491953938, disc_loss = 0.0748973333300287
Trained batch 119 in epoch 0, gen_loss = 0.4939163533349832, disc_loss = 0.0743549394266059
Trained batch 120 in epoch 0, gen_loss = 0.49354333916971505, disc_loss = 0.07381838396930497
Trained batch 121 in epoch 0, gen_loss = 0.49256756730744095, disc_loss = 0.07339335327632114
Trained batch 122 in epoch 0, gen_loss = 0.49211217475131275, disc_loss = 0.07293555585712921
Trained batch 123 in epoch 0, gen_loss = 0.4919771948649037, disc_loss = 0.07247618540760971
Trained batch 124 in epoch 0, gen_loss = 0.49160646796226504, disc_loss = 0.07197888950258494
Trained batch 125 in epoch 0, gen_loss = 0.4921535544452213, disc_loss = 0.07148830028664735
Trained batch 126 in epoch 0, gen_loss = 0.4921216920135528, disc_loss = 0.07099211342838102
Trained batch 127 in epoch 0, gen_loss = 0.49225006881169975, disc_loss = 0.0705084196451935
Trained batch 128 in epoch 0, gen_loss = 0.4916747357956199, disc_loss = 0.07003464414774216
Trained batch 129 in epoch 0, gen_loss = 0.4910528309070147, disc_loss = 0.06955879005388571
Trained batch 130 in epoch 0, gen_loss = 0.49125055297640446, disc_loss = 0.06915605012753992
Trained batch 131 in epoch 0, gen_loss = 0.49125956202095206, disc_loss = 0.06874043253165754
Trained batch 132 in epoch 0, gen_loss = 0.49116583022856175, disc_loss = 0.06832497856138568
Trained batch 133 in epoch 0, gen_loss = 0.4908033458154593, disc_loss = 0.06790215856353961
Trained batch 134 in epoch 0, gen_loss = 0.4906381125803347, disc_loss = 0.06748021687208502
Trained batch 135 in epoch 0, gen_loss = 0.4900466996957274, disc_loss = 0.06706277995288153
Trained batch 136 in epoch 0, gen_loss = 0.4893086063165734, disc_loss = 0.06664867656319028
Trained batch 137 in epoch 0, gen_loss = 0.48944274044555164, disc_loss = 0.06624311539411977
Trained batch 138 in epoch 0, gen_loss = 0.48953050910997736, disc_loss = 0.06582120213014402
Trained batch 139 in epoch 0, gen_loss = 0.4896096883075578, disc_loss = 0.06541667332473611
Trained batch 140 in epoch 0, gen_loss = 0.4887008453514559, disc_loss = 0.0651115095507063
Trained batch 141 in epoch 0, gen_loss = 0.4884040359879883, disc_loss = 0.06501454956383562
Trained batch 142 in epoch 0, gen_loss = 0.48818989150174014, disc_loss = 0.06486559494470175
Trained batch 143 in epoch 0, gen_loss = 0.48843604947129887, disc_loss = 0.06471287541272533
Trained batch 144 in epoch 0, gen_loss = 0.48904943548399826, disc_loss = 0.06450205449785652
Trained batch 145 in epoch 0, gen_loss = 0.48901437018832117, disc_loss = 0.06419728514547013
Trained batch 146 in epoch 0, gen_loss = 0.48920503785821046, disc_loss = 0.06384059289457644
Trained batch 147 in epoch 0, gen_loss = 0.4883094971647134, disc_loss = 0.06406344331775767
Trained batch 148 in epoch 0, gen_loss = 0.4881806099574838, disc_loss = 0.06743149048705029
Trained batch 149 in epoch 0, gen_loss = 0.48797789911429085, disc_loss = 0.0677270820674797
Trained batch 150 in epoch 0, gen_loss = 0.488038883106598, disc_loss = 0.06850014803992795
Trained batch 151 in epoch 0, gen_loss = 0.48781129443331767, disc_loss = 0.06881003267450356
Trained batch 152 in epoch 0, gen_loss = 0.4870256308247061, disc_loss = 0.0692904665518333
Trained batch 153 in epoch 0, gen_loss = 0.487261324153318, disc_loss = 0.06937455225663332
Trained batch 154 in epoch 0, gen_loss = 0.4874403586310725, disc_loss = 0.06920640751599304
Trained batch 155 in epoch 0, gen_loss = 0.4878349990034715, disc_loss = 0.06883478821971668
Trained batch 156 in epoch 0, gen_loss = 0.48766826767071036, disc_loss = 0.06847792334712235
Trained batch 157 in epoch 0, gen_loss = 0.48719524035725414, disc_loss = 0.06814135292167717
Trained batch 158 in epoch 0, gen_loss = 0.486675241458341, disc_loss = 0.06779422324572532
Trained batch 159 in epoch 0, gen_loss = 0.48663637824356554, disc_loss = 0.06749586684745737
Trained batch 160 in epoch 0, gen_loss = 0.4860270176985249, disc_loss = 0.06714784567423673
Trained batch 161 in epoch 0, gen_loss = 0.4860639612615844, disc_loss = 0.066788241284451
Trained batch 162 in epoch 0, gen_loss = 0.48619481061865216, disc_loss = 0.06642823335514661
Trained batch 163 in epoch 0, gen_loss = 0.4860011909793063, disc_loss = 0.06606905713461612
Trained batch 164 in epoch 0, gen_loss = 0.48626965934580024, disc_loss = 0.0657167707344122
Trained batch 165 in epoch 0, gen_loss = 0.4860377695905157, disc_loss = 0.06537378558339214
Trained batch 166 in epoch 0, gen_loss = 0.4860303997993469, disc_loss = 0.06502279656253264
Trained batch 167 in epoch 0, gen_loss = 0.4863907833184515, disc_loss = 0.06468534426641695
Trained batch 168 in epoch 0, gen_loss = 0.4864526285222296, disc_loss = 0.06434600768588791
Trained batch 169 in epoch 0, gen_loss = 0.48649042564279893, disc_loss = 0.06400663761476821
Trained batch 170 in epoch 0, gen_loss = 0.48663012604964406, disc_loss = 0.06367351990519908
Trained batch 171 in epoch 0, gen_loss = 0.4868283874766771, disc_loss = 0.06335044866644365
Trained batch 172 in epoch 0, gen_loss = 0.486205459502391, disc_loss = 0.06302681540790407
Trained batch 173 in epoch 0, gen_loss = 0.48626561034684895, disc_loss = 0.06270247441984114
Trained batch 174 in epoch 0, gen_loss = 0.4860781676428659, disc_loss = 0.06239061666386468
Trained batch 175 in epoch 0, gen_loss = 0.4861731217666106, disc_loss = 0.06208609802309762
Trained batch 176 in epoch 0, gen_loss = 0.48545708865095666, disc_loss = 0.061928877217621456
Trained batch 177 in epoch 0, gen_loss = 0.48560563198636086, disc_loss = 0.06168087170030294
Trained batch 178 in epoch 0, gen_loss = 0.48516218089524593, disc_loss = 0.06182003795434643
Trained batch 179 in epoch 0, gen_loss = 0.485935867495007, disc_loss = 0.061796089282466306
Trained batch 180 in epoch 0, gen_loss = 0.4859799426563537, disc_loss = 0.061852986003318546
Trained batch 181 in epoch 0, gen_loss = 0.4859372031885189, disc_loss = 0.061629941973548666
Trained batch 182 in epoch 0, gen_loss = 0.4853815750671866, disc_loss = 0.061465662298469594
Trained batch 183 in epoch 0, gen_loss = 0.4857690510866435, disc_loss = 0.06120042942221398
Trained batch 184 in epoch 0, gen_loss = 0.48600630550771146, disc_loss = 0.06095115674307217
Trained batch 185 in epoch 0, gen_loss = 0.4859712505212394, disc_loss = 0.060665527578964026
Trained batch 186 in epoch 0, gen_loss = 0.48639511137722646, disc_loss = 0.06039468223916337
Trained batch 187 in epoch 0, gen_loss = 0.48620114729125447, disc_loss = 0.060111397327458925
Trained batch 188 in epoch 0, gen_loss = 0.48594086794626146, disc_loss = 0.059829221538233536
Trained batch 189 in epoch 0, gen_loss = 0.48601733289266885, disc_loss = 0.059553811299663625
Trained batch 190 in epoch 0, gen_loss = 0.4860218724343165, disc_loss = 0.059278011690162086
Trained batch 191 in epoch 0, gen_loss = 0.48557517196362215, disc_loss = 0.05899614327063318
Trained batch 192 in epoch 0, gen_loss = 0.48592990497851, disc_loss = 0.05872313254826504
Trained batch 193 in epoch 0, gen_loss = 0.4857535932174663, disc_loss = 0.058450854889875684
Trained batch 194 in epoch 0, gen_loss = 0.486038135106747, disc_loss = 0.05818372462900021
Trained batch 195 in epoch 0, gen_loss = 0.48563813919923743, disc_loss = 0.05791301573911796
Trained batch 196 in epoch 0, gen_loss = 0.48570127112006173, disc_loss = 0.057652123378788306
Trained batch 197 in epoch 0, gen_loss = 0.4856482804423631, disc_loss = 0.0573914659684618
Trained batch 198 in epoch 0, gen_loss = 0.4853748157994831, disc_loss = 0.057130441778624926
Trained batch 199 in epoch 0, gen_loss = 0.4853305974602699, disc_loss = 0.0568740349705331
Trained batch 200 in epoch 0, gen_loss = 0.48458940294844594, disc_loss = 0.05686033197182847
Trained batch 201 in epoch 0, gen_loss = 0.48459262585285867, disc_loss = 0.05737892356424565
Trained batch 202 in epoch 0, gen_loss = 0.48494864787374226, disc_loss = 0.057211757575625126
Trained batch 203 in epoch 0, gen_loss = 0.484773905107788, disc_loss = 0.05742194202920312
Trained batch 204 in epoch 0, gen_loss = 0.4849312356332453, disc_loss = 0.05724548391043777
Trained batch 205 in epoch 0, gen_loss = 0.4852802902460098, disc_loss = 0.05711354674925141
Trained batch 206 in epoch 0, gen_loss = 0.48470644415288733, disc_loss = 0.05721194266256143
Trained batch 207 in epoch 0, gen_loss = 0.4852429095369119, disc_loss = 0.05715633855120709
Trained batch 208 in epoch 0, gen_loss = 0.48520447049985094, disc_loss = 0.057073533764492236
Trained batch 209 in epoch 0, gen_loss = 0.4848390416020439, disc_loss = 0.05688594948456046
Trained batch 210 in epoch 0, gen_loss = 0.4848110552930154, disc_loss = 0.05676090591741611
Trained batch 211 in epoch 0, gen_loss = 0.4849794092324545, disc_loss = 0.05654061452775561
Trained batch 212 in epoch 0, gen_loss = 0.48531514056411706, disc_loss = 0.05633232462495356
Trained batch 213 in epoch 0, gen_loss = 0.48537948142702336, disc_loss = 0.05614671394638021
Trained batch 214 in epoch 0, gen_loss = 0.4853131593659867, disc_loss = 0.055947810279335396
Trained batch 215 in epoch 0, gen_loss = 0.4857245617442661, disc_loss = 0.05573266438268884
Trained batch 216 in epoch 0, gen_loss = 0.48527030090582535, disc_loss = 0.05556678991498692
Trained batch 217 in epoch 0, gen_loss = 0.48504549223895466, disc_loss = 0.05540821713036558
Trained batch 218 in epoch 0, gen_loss = 0.4856091679231217, disc_loss = 0.055215940523688514
Trained batch 219 in epoch 0, gen_loss = 0.4856329013000835, disc_loss = 0.055059889193878254
Trained batch 220 in epoch 0, gen_loss = 0.48596983986202946, disc_loss = 0.054865432096164825
Trained batch 221 in epoch 0, gen_loss = 0.4864872395992279, disc_loss = 0.05466965155734739
Trained batch 222 in epoch 0, gen_loss = 0.48642905677915155, disc_loss = 0.05447603830015245
Trained batch 223 in epoch 0, gen_loss = 0.486109717349921, disc_loss = 0.05433338474124737
Trained batch 224 in epoch 0, gen_loss = 0.4864331891801622, disc_loss = 0.054137930081536376
Trained batch 225 in epoch 0, gen_loss = 0.48660683315412134, disc_loss = 0.054284841718514804
Trained batch 226 in epoch 0, gen_loss = 0.48759996759733965, disc_loss = 0.05459791878730649
Trained batch 227 in epoch 0, gen_loss = 0.48759912856315313, disc_loss = 0.05443641318522982
Trained batch 228 in epoch 0, gen_loss = 0.48762491449518497, disc_loss = 0.05430534220703239
Trained batch 229 in epoch 0, gen_loss = 0.48762272868467416, disc_loss = 0.05415471476988624
Trained batch 230 in epoch 0, gen_loss = 0.48771214652887157, disc_loss = 0.05402164872195491
Trained batch 231 in epoch 0, gen_loss = 0.487854413302808, disc_loss = 0.053924995408281044
Trained batch 232 in epoch 0, gen_loss = 0.48809108879944796, disc_loss = 0.053778453156463964
Trained batch 233 in epoch 0, gen_loss = 0.48803994670892376, disc_loss = 0.05359351957957141
Trained batch 234 in epoch 0, gen_loss = 0.48812275922044795, disc_loss = 0.05339428566673652
Trained batch 235 in epoch 0, gen_loss = 0.48849147633980894, disc_loss = 0.05323162609987529
Trained batch 236 in epoch 0, gen_loss = 0.48864979683598386, disc_loss = 0.053061438561318924
Trained batch 237 in epoch 0, gen_loss = 0.4888016083160368, disc_loss = 0.05287963776661381
Trained batch 238 in epoch 0, gen_loss = 0.48871321433757636, disc_loss = 0.052755225350433435
Trained batch 239 in epoch 0, gen_loss = 0.489014849315087, disc_loss = 0.05270916978867414
Trained batch 240 in epoch 0, gen_loss = 0.48917079862222634, disc_loss = 0.05263140143177383
Trained batch 241 in epoch 0, gen_loss = 0.489538160237399, disc_loss = 0.05267896892094969
Trained batch 242 in epoch 0, gen_loss = 0.48965906091187716, disc_loss = 0.052506011744018324
Trained batch 243 in epoch 0, gen_loss = 0.48951658582101104, disc_loss = 0.05236256130032058
Trained batch 244 in epoch 0, gen_loss = 0.4900373872445554, disc_loss = 0.05228805561568968
Trained batch 245 in epoch 0, gen_loss = 0.4899689947686544, disc_loss = 0.05255714254037333
Trained batch 246 in epoch 0, gen_loss = 0.4897420815369378, disc_loss = 0.05427396238445934
Trained batch 247 in epoch 0, gen_loss = 0.4895177168711539, disc_loss = 0.05438349451381533
Trained batch 248 in epoch 0, gen_loss = 0.48941863516727124, disc_loss = 0.05473192175102222
Trained batch 249 in epoch 0, gen_loss = 0.4893413655757904, disc_loss = 0.05525914259068668
Trained batch 250 in epoch 0, gen_loss = 0.4897578771845753, disc_loss = 0.05589624314542964
Trained batch 251 in epoch 0, gen_loss = 0.48958564088458106, disc_loss = 0.056061271236218985
Trained batch 252 in epoch 0, gen_loss = 0.4895121038195644, disc_loss = 0.056618851059201086
Trained batch 253 in epoch 0, gen_loss = 0.48896267036284047, disc_loss = 0.05729822956546261
Trained batch 254 in epoch 0, gen_loss = 0.48895283925767036, disc_loss = 0.05759847486829933
Trained batch 255 in epoch 0, gen_loss = 0.4892691426211968, disc_loss = 0.05794703717219818
Trained batch 256 in epoch 0, gen_loss = 0.4895127528140517, disc_loss = 0.05800239215441889
Trained batch 257 in epoch 0, gen_loss = 0.4893557303404623, disc_loss = 0.05818436945817441
Trained batch 258 in epoch 0, gen_loss = 0.4894212384251554, disc_loss = 0.05904886688727842
Trained batch 259 in epoch 0, gen_loss = 0.4892684816167905, disc_loss = 0.060158768394747035
Trained batch 260 in epoch 0, gen_loss = 0.4893483892939557, disc_loss = 0.060239523347695556
Trained batch 261 in epoch 0, gen_loss = 0.48967990791069643, disc_loss = 0.06031666418629919
Trained batch 262 in epoch 0, gen_loss = 0.4897049485277314, disc_loss = 0.060698275796063385
Trained batch 263 in epoch 0, gen_loss = 0.4899393632782228, disc_loss = 0.06127069609514861
Trained batch 264 in epoch 0, gen_loss = 0.4901286461443271, disc_loss = 0.06124624567598386
Trained batch 265 in epoch 0, gen_loss = 0.49009899727832107, disc_loss = 0.061366653222156536
Trained batch 266 in epoch 0, gen_loss = 0.4902164542049951, disc_loss = 0.06199284146055021
Trained batch 267 in epoch 0, gen_loss = 0.4904972587281199, disc_loss = 0.0620820299051563
Trained batch 268 in epoch 0, gen_loss = 0.4904132814433938, disc_loss = 0.06204793163052445
Trained batch 269 in epoch 0, gen_loss = 0.4901762893906346, disc_loss = 0.06252073729583235
Trained batch 270 in epoch 0, gen_loss = 0.4905325442662538, disc_loss = 0.06368570272876053
Trained batch 271 in epoch 0, gen_loss = 0.4902505027678083, disc_loss = 0.06421745246488546
Trained batch 272 in epoch 0, gen_loss = 0.49002692321717956, disc_loss = 0.0645391703753872
Trained batch 273 in epoch 0, gen_loss = 0.49032079923326954, disc_loss = 0.0646332421452215
Trained batch 274 in epoch 0, gen_loss = 0.4901503656127236, disc_loss = 0.06506914275444367
Trained batch 275 in epoch 0, gen_loss = 0.48994762785192847, disc_loss = 0.06559531829164673
Trained batch 276 in epoch 0, gen_loss = 0.48984459634292, disc_loss = 0.06552348599100102
Trained batch 277 in epoch 0, gen_loss = 0.48986513859076464, disc_loss = 0.06554791911357759
Trained batch 278 in epoch 0, gen_loss = 0.4898887838514048, disc_loss = 0.0656946765969918
Trained batch 279 in epoch 0, gen_loss = 0.48991991451808387, disc_loss = 0.06626699815470992
Trained batch 280 in epoch 0, gen_loss = 0.4899421243056708, disc_loss = 0.06715842703476654
Trained batch 281 in epoch 0, gen_loss = 0.48995112601324176, disc_loss = 0.0671988820363206
Trained batch 282 in epoch 0, gen_loss = 0.49015466179106343, disc_loss = 0.06719045631765214
Trained batch 283 in epoch 0, gen_loss = 0.4897133059484858, disc_loss = 0.0672611771135027
Trained batch 284 in epoch 0, gen_loss = 0.4896178390896111, disc_loss = 0.06762178672085467
Trained batch 285 in epoch 0, gen_loss = 0.48958637987400266, disc_loss = 0.06820830172481393
Trained batch 286 in epoch 0, gen_loss = 0.4894342335259042, disc_loss = 0.06886582228254513
Trained batch 287 in epoch 0, gen_loss = 0.48912370215273565, disc_loss = 0.06902810787465165
Trained batch 288 in epoch 0, gen_loss = 0.4890735918675327, disc_loss = 0.06915214236110294
Trained batch 289 in epoch 0, gen_loss = 0.4891803883273026, disc_loss = 0.06934924620075215
Trained batch 290 in epoch 0, gen_loss = 0.4892980259718354, disc_loss = 0.06943362747571875
Trained batch 291 in epoch 0, gen_loss = 0.4893317355276787, disc_loss = 0.07040466154982936
Trained batch 292 in epoch 0, gen_loss = 0.4890328022196838, disc_loss = 0.07147508331831964
Trained batch 293 in epoch 0, gen_loss = 0.4891075198950411, disc_loss = 0.072014832132667
Trained batch 294 in epoch 0, gen_loss = 0.48921404723393713, disc_loss = 0.07235234396027054
Trained batch 295 in epoch 0, gen_loss = 0.4889046757205113, disc_loss = 0.07277477674683355
Trained batch 296 in epoch 0, gen_loss = 0.4889895564779288, disc_loss = 0.07304541070346629
Trained batch 297 in epoch 0, gen_loss = 0.4892652038759833, disc_loss = 0.0733472878010256
Trained batch 298 in epoch 0, gen_loss = 0.48914189831070276, disc_loss = 0.07345687955412328
Trained batch 299 in epoch 0, gen_loss = 0.4888412686189016, disc_loss = 0.07377017826928446
Trained batch 300 in epoch 0, gen_loss = 0.4891457848770674, disc_loss = 0.07386551496489252
Trained batch 301 in epoch 0, gen_loss = 0.4890606003683924, disc_loss = 0.07456002864117013
Trained batch 302 in epoch 0, gen_loss = 0.4890198144975669, disc_loss = 0.0757931801459749
Trained batch 303 in epoch 0, gen_loss = 0.4889913431711887, disc_loss = 0.07588617066013333
Trained batch 304 in epoch 0, gen_loss = 0.48891046799597193, disc_loss = 0.07611389857426774
Trained batch 305 in epoch 0, gen_loss = 0.488757693202667, disc_loss = 0.07622821554632894
Trained batch 306 in epoch 0, gen_loss = 0.48855211360058487, disc_loss = 0.07648875812942266
Trained batch 307 in epoch 0, gen_loss = 0.4881451610814441, disc_loss = 0.0771471710812131
Trained batch 308 in epoch 0, gen_loss = 0.48804562493049597, disc_loss = 0.07723564383178998
Trained batch 309 in epoch 0, gen_loss = 0.4881280710620265, disc_loss = 0.0775038800517758
Trained batch 310 in epoch 0, gen_loss = 0.48794880701031335, disc_loss = 0.07783002577500472
Trained batch 311 in epoch 0, gen_loss = 0.4879179064853069, disc_loss = 0.07809670509334701
Trained batch 312 in epoch 0, gen_loss = 0.48778890735044267, disc_loss = 0.0782822768632382
Trained batch 313 in epoch 0, gen_loss = 0.4879390368605875, disc_loss = 0.07848927237324796
Trained batch 314 in epoch 0, gen_loss = 0.48797035274051487, disc_loss = 0.07962916910737043
Trained batch 315 in epoch 0, gen_loss = 0.48764298507307147, disc_loss = 0.08008049089974383
Trained batch 316 in epoch 0, gen_loss = 0.4875123538429429, disc_loss = 0.08066730733449667
Trained batch 317 in epoch 0, gen_loss = 0.4876036971994916, disc_loss = 0.0810589111459869
Trained batch 318 in epoch 0, gen_loss = 0.4874077226300972, disc_loss = 0.08146225043125802
Trained batch 319 in epoch 0, gen_loss = 0.48720014495775105, disc_loss = 0.08178067324770381
Trained batch 320 in epoch 0, gen_loss = 0.48696981709322823, disc_loss = 0.08201759878250066
Trained batch 321 in epoch 0, gen_loss = 0.4868087000358179, disc_loss = 0.08221755344391748
Trained batch 322 in epoch 0, gen_loss = 0.4867617005349682, disc_loss = 0.08238298809098155
Trained batch 323 in epoch 0, gen_loss = 0.4869407408951241, disc_loss = 0.08302614700917246
Trained batch 324 in epoch 0, gen_loss = 0.4867094363616063, disc_loss = 0.08335264990965907
Trained batch 325 in epoch 0, gen_loss = 0.4863655669557536, disc_loss = 0.08393343438485786
Trained batch 326 in epoch 0, gen_loss = 0.4862171529994463, disc_loss = 0.08417344618366536
Trained batch 327 in epoch 0, gen_loss = 0.4861334210670576, disc_loss = 0.08446188767230502
Trained batch 328 in epoch 0, gen_loss = 0.48611503169167003, disc_loss = 0.08471354720887578
Trained batch 329 in epoch 0, gen_loss = 0.4857557685989322, disc_loss = 0.08510721584245788
Trained batch 330 in epoch 0, gen_loss = 0.4856195448028357, disc_loss = 0.0857975265599247
Trained batch 331 in epoch 0, gen_loss = 0.4853828287268259, disc_loss = 0.0861989933063265
Trained batch 332 in epoch 0, gen_loss = 0.4851441972248547, disc_loss = 0.08659941674973648
Trained batch 333 in epoch 0, gen_loss = 0.48501983811398464, disc_loss = 0.08683006582408027
Trained batch 334 in epoch 0, gen_loss = 0.48490199384404653, disc_loss = 0.0870193316073004
Trained batch 335 in epoch 0, gen_loss = 0.48482369702486766, disc_loss = 0.08722072184346394
Trained batch 336 in epoch 0, gen_loss = 0.4848268185065125, disc_loss = 0.08731046757724369
Trained batch 337 in epoch 0, gen_loss = 0.4847512930278947, disc_loss = 0.08756882107552119
Trained batch 338 in epoch 0, gen_loss = 0.4846774793304173, disc_loss = 0.08835134583670964
Trained batch 339 in epoch 0, gen_loss = 0.4845223999198745, disc_loss = 0.08946843126323074
Trained batch 340 in epoch 0, gen_loss = 0.4845315900541121, disc_loss = 0.08978330229116806
Trained batch 341 in epoch 0, gen_loss = 0.4844914069998334, disc_loss = 0.0899836672510821
Trained batch 342 in epoch 0, gen_loss = 0.4842860740405825, disc_loss = 0.09020656222238616
Trained batch 343 in epoch 0, gen_loss = 0.48395967448866645, disc_loss = 0.09043776197223599
Trained batch 344 in epoch 0, gen_loss = 0.4838497625744861, disc_loss = 0.09063351125037973
Trained batch 345 in epoch 0, gen_loss = 0.48352569591447797, disc_loss = 0.09083167412802792
Trained batch 346 in epoch 0, gen_loss = 0.483523476278404, disc_loss = 0.09093797753191947
Trained batch 347 in epoch 0, gen_loss = 0.48360373585046024, disc_loss = 0.09144988190248908
Trained batch 348 in epoch 0, gen_loss = 0.4835289160809066, disc_loss = 0.09176527771613105
Trained batch 349 in epoch 0, gen_loss = 0.4833959210770471, disc_loss = 0.09195867335024689
Trained batch 350 in epoch 0, gen_loss = 0.4830411727781649, disc_loss = 0.09218139446438675
Trained batch 351 in epoch 0, gen_loss = 0.4827035806057128, disc_loss = 0.09267911277790765
Trained batch 352 in epoch 0, gen_loss = 0.48255246911440625, disc_loss = 0.09314681024873687
Trained batch 353 in epoch 0, gen_loss = 0.48235227740080344, disc_loss = 0.0933463558815104
Trained batch 354 in epoch 0, gen_loss = 0.4821308475984654, disc_loss = 0.0935605558383108
Trained batch 355 in epoch 0, gen_loss = 0.4817737252189872, disc_loss = 0.09392679341299606
Trained batch 356 in epoch 0, gen_loss = 0.4816163776635456, disc_loss = 0.09438569030753162
Trained batch 357 in epoch 0, gen_loss = 0.48140769098058095, disc_loss = 0.0952014701750504
Trained batch 358 in epoch 0, gen_loss = 0.48100486655089186, disc_loss = 0.09547759178366959
Trained batch 359 in epoch 0, gen_loss = 0.48108512759208677, disc_loss = 0.09594616745986666
Trained batch 360 in epoch 0, gen_loss = 0.48068109947228366, disc_loss = 0.09630203037458238
Trained batch 361 in epoch 0, gen_loss = 0.48064292745036974, disc_loss = 0.09657854949978299
Trained batch 362 in epoch 0, gen_loss = 0.48016157122354536, disc_loss = 0.09695639825469658
Trained batch 363 in epoch 0, gen_loss = 0.48004565756399553, disc_loss = 0.09714271301009621
Trained batch 364 in epoch 0, gen_loss = 0.47966240660785, disc_loss = 0.09740583950602641
Trained batch 365 in epoch 0, gen_loss = 0.47939558384197006, disc_loss = 0.09753021342257455
Trained batch 366 in epoch 0, gen_loss = 0.4791798233498669, disc_loss = 0.0976157044771074
Trained batch 367 in epoch 0, gen_loss = 0.47892536838417465, disc_loss = 0.09769851966310576
Trained batch 368 in epoch 0, gen_loss = 0.47861747003506194, disc_loss = 0.09780010804003937
Trained batch 369 in epoch 0, gen_loss = 0.47824269106259215, disc_loss = 0.09814399622657613
Trained batch 370 in epoch 0, gen_loss = 0.47797683363333543, disc_loss = 0.0983836203499765
Trained batch 371 in epoch 0, gen_loss = 0.47773945475778273, disc_loss = 0.09848706825681391
Trained batch 372 in epoch 0, gen_loss = 0.4775343171393264, disc_loss = 0.0986306721746582
Trained batch 373 in epoch 0, gen_loss = 0.4773561442121465, disc_loss = 0.09887921890707059
Trained batch 374 in epoch 0, gen_loss = 0.47734899473190306, disc_loss = 0.0992909502275288
Trained batch 375 in epoch 0, gen_loss = 0.4771761660404662, disc_loss = 0.09968176568199465
Trained batch 376 in epoch 0, gen_loss = 0.4770004696333756, disc_loss = 0.09977487999259121
Trained batch 377 in epoch 0, gen_loss = 0.47676781521587774, disc_loss = 0.09988832640185676
Trained batch 378 in epoch 0, gen_loss = 0.47654240261910774, disc_loss = 0.1005295196678342
Trained batch 379 in epoch 0, gen_loss = 0.4763356021360347, disc_loss = 0.10072802345292937
Trained batch 380 in epoch 0, gen_loss = 0.47635332289643173, disc_loss = 0.10090079677616322
Trained batch 381 in epoch 0, gen_loss = 0.47622401637868733, disc_loss = 0.10110460870158103
Trained batch 382 in epoch 0, gen_loss = 0.47606517051592195, disc_loss = 0.10120860875192689
Trained batch 383 in epoch 0, gen_loss = 0.47606260624403757, disc_loss = 0.10132782670431577
Trained batch 384 in epoch 0, gen_loss = 0.47584046427305643, disc_loss = 0.10158168747900174
Trained batch 385 in epoch 0, gen_loss = 0.47570987315993235, disc_loss = 0.10173016571237131
Trained batch 386 in epoch 0, gen_loss = 0.4754583099399734, disc_loss = 0.10181555768850353
Trained batch 387 in epoch 0, gen_loss = 0.4755578895205075, disc_loss = 0.1018240550213695
Trained batch 388 in epoch 0, gen_loss = 0.475589311980956, disc_loss = 0.10177048444053623
Trained batch 389 in epoch 0, gen_loss = 0.4756028826420124, disc_loss = 0.10164521442463574
Trained batch 390 in epoch 0, gen_loss = 0.47532724465250664, disc_loss = 0.10176311878134947
Trained batch 391 in epoch 0, gen_loss = 0.47513533870176394, disc_loss = 0.101630618024798
Trained batch 392 in epoch 0, gen_loss = 0.474943310098187, disc_loss = 0.10170200223378059
Trained batch 393 in epoch 0, gen_loss = 0.4749983992370857, disc_loss = 0.10179830681849365
Trained batch 394 in epoch 0, gen_loss = 0.4747082532206668, disc_loss = 0.1019009109055977
Trained batch 395 in epoch 0, gen_loss = 0.47452039407058194, disc_loss = 0.10233807671848083
Trained batch 396 in epoch 0, gen_loss = 0.4745196784173211, disc_loss = 0.10309784773910789
Trained batch 397 in epoch 0, gen_loss = 0.47445872935218425, disc_loss = 0.10320235709144954
Trained batch 398 in epoch 0, gen_loss = 0.4741238389995164, disc_loss = 0.10327007794136503
Trained batch 399 in epoch 0, gen_loss = 0.4740108881890774, disc_loss = 0.10380517448182218
Trained batch 400 in epoch 0, gen_loss = 0.47392152573105106, disc_loss = 0.10387360323986916
Trained batch 401 in epoch 0, gen_loss = 0.47392695408258867, disc_loss = 0.10393866654647635
Trained batch 402 in epoch 0, gen_loss = 0.4738477776127477, disc_loss = 0.1039458244343383
Trained batch 403 in epoch 0, gen_loss = 0.47366032697776755, disc_loss = 0.10402412564000392
Trained batch 404 in epoch 0, gen_loss = 0.4735355429443312, disc_loss = 0.10438872206795179
Trained batch 405 in epoch 0, gen_loss = 0.47347893121794526, disc_loss = 0.10500394247284187
Trained batch 406 in epoch 0, gen_loss = 0.4735248104946033, disc_loss = 0.10508017526500164
Trained batch 407 in epoch 0, gen_loss = 0.4732561790767838, disc_loss = 0.10520992795913937
Trained batch 408 in epoch 0, gen_loss = 0.47316287279420494, disc_loss = 0.10519904957419321
Trained batch 409 in epoch 0, gen_loss = 0.4729772258095625, disc_loss = 0.10534325837066806
Trained batch 410 in epoch 0, gen_loss = 0.4729673262785241, disc_loss = 0.10559221568184286
Trained batch 411 in epoch 0, gen_loss = 0.47297303921100003, disc_loss = 0.10600231973865766
Trained batch 412 in epoch 0, gen_loss = 0.4727662771435107, disc_loss = 0.10599766529929659
Trained batch 413 in epoch 0, gen_loss = 0.47240163256292755, disc_loss = 0.10648076782331482
Trained batch 414 in epoch 0, gen_loss = 0.4724547636796193, disc_loss = 0.10650722713781947
Trained batch 415 in epoch 0, gen_loss = 0.4724702706130651, disc_loss = 0.10662042452447797
Trained batch 416 in epoch 0, gen_loss = 0.4723052413915273, disc_loss = 0.10683987054603099
Trained batch 417 in epoch 0, gen_loss = 0.4720734128256164, disc_loss = 0.10718598793278578
Trained batch 418 in epoch 0, gen_loss = 0.47179955493009745, disc_loss = 0.10745539406741256
Trained batch 419 in epoch 0, gen_loss = 0.4717526342897188, disc_loss = 0.10778143915813417
Trained batch 420 in epoch 0, gen_loss = 0.47172409933140047, disc_loss = 0.10797823359304928
Trained batch 421 in epoch 0, gen_loss = 0.47155077345845825, disc_loss = 0.10828195889127304
Trained batch 422 in epoch 0, gen_loss = 0.47142108387135445, disc_loss = 0.10849784391141776
Trained batch 423 in epoch 0, gen_loss = 0.47114822050591687, disc_loss = 0.10873807772427341
Trained batch 424 in epoch 0, gen_loss = 0.4710521317229551, disc_loss = 0.10888407856992939
Trained batch 425 in epoch 0, gen_loss = 0.4710329585651836, disc_loss = 0.10909075572312822
Trained batch 426 in epoch 0, gen_loss = 0.470862872148286, disc_loss = 0.10935436833793825
Trained batch 427 in epoch 0, gen_loss = 0.4706573613057627, disc_loss = 0.10947975459634805
Trained batch 428 in epoch 0, gen_loss = 0.47034716522777, disc_loss = 0.1096311249696413
Trained batch 429 in epoch 0, gen_loss = 0.4701266288757324, disc_loss = 0.10984615734561758
Trained batch 430 in epoch 0, gen_loss = 0.47005129171634774, disc_loss = 0.11000763342160463
Trained batch 431 in epoch 0, gen_loss = 0.469700663867924, disc_loss = 0.1102149508865464
Trained batch 432 in epoch 0, gen_loss = 0.4694979300262196, disc_loss = 0.11051118930405991
Trained batch 433 in epoch 0, gen_loss = 0.46931054467155087, disc_loss = 0.11075272907992216
Trained batch 434 in epoch 0, gen_loss = 0.4689790733929338, disc_loss = 0.11092816785555976
Trained batch 435 in epoch 0, gen_loss = 0.4688671959239408, disc_loss = 0.11122983047170479
Trained batch 436 in epoch 0, gen_loss = 0.4689407688938507, disc_loss = 0.11147123673137968
Trained batch 437 in epoch 0, gen_loss = 0.46890283406597294, disc_loss = 0.11161220378931357
Trained batch 438 in epoch 0, gen_loss = 0.4687227014800139, disc_loss = 0.11169186963303045
Trained batch 439 in epoch 0, gen_loss = 0.4684360506859693, disc_loss = 0.1118852862485007
Trained batch 440 in epoch 0, gen_loss = 0.4684541707947141, disc_loss = 0.11191874052252189
Trained batch 441 in epoch 0, gen_loss = 0.46808776724662177, disc_loss = 0.11201504714749079
Trained batch 442 in epoch 0, gen_loss = 0.4679312348096688, disc_loss = 0.1123028771844577
Trained batch 443 in epoch 0, gen_loss = 0.4677969991221084, disc_loss = 0.11251690862008144
Trained batch 444 in epoch 0, gen_loss = 0.46778772406363756, disc_loss = 0.11250229145431619
Trained batch 445 in epoch 0, gen_loss = 0.4678970072167871, disc_loss = 0.11255253496320893
Trained batch 446 in epoch 0, gen_loss = 0.4680093902202794, disc_loss = 0.11259166012003484
Trained batch 447 in epoch 0, gen_loss = 0.4680547533290727, disc_loss = 0.11276392840643114
Trained batch 448 in epoch 0, gen_loss = 0.4681849499587758, disc_loss = 0.11307580688478786
Trained batch 449 in epoch 0, gen_loss = 0.4679938361379835, disc_loss = 0.11323382532327539
Trained batch 450 in epoch 0, gen_loss = 0.4678362349581031, disc_loss = 0.11380926973006777
Trained batch 451 in epoch 0, gen_loss = 0.4677593203640617, disc_loss = 0.11397035719015002
Trained batch 452 in epoch 0, gen_loss = 0.46765125232027066, disc_loss = 0.11416332393156871
Trained batch 453 in epoch 0, gen_loss = 0.4675095635363709, disc_loss = 0.1145079725940962
Trained batch 454 in epoch 0, gen_loss = 0.4673104093624995, disc_loss = 0.11487256084558564
Trained batch 455 in epoch 0, gen_loss = 0.46707913959235475, disc_loss = 0.11506929620181357
Trained batch 456 in epoch 0, gen_loss = 0.4669829505277671, disc_loss = 0.11524528697748511
Trained batch 457 in epoch 0, gen_loss = 0.46667386988364973, disc_loss = 0.11537313076472276
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.38363131880760193, disc_loss = 0.2405591905117035
Trained batch 1 in epoch 1, gen_loss = 0.3968627154827118, disc_loss = 0.23735060542821884
Trained batch 2 in epoch 1, gen_loss = 0.42565898100535077, disc_loss = 0.20766803622245789
Trained batch 3 in epoch 1, gen_loss = 0.4283425584435463, disc_loss = 0.20519956573843956
Trained batch 4 in epoch 1, gen_loss = 0.4188100278377533, disc_loss = 0.19172048270702363
Trained batch 5 in epoch 1, gen_loss = 0.43036437034606934, disc_loss = 0.18535014986991882
Trained batch 6 in epoch 1, gen_loss = 0.42660580362592426, disc_loss = 0.2045667724949973
Trained batch 7 in epoch 1, gen_loss = 0.41438691690564156, disc_loss = 0.20976170897483826
Trained batch 8 in epoch 1, gen_loss = 0.40439066621992326, disc_loss = 0.220580432150099
Trained batch 9 in epoch 1, gen_loss = 0.3961524575948715, disc_loss = 0.22447549402713776
Trained batch 10 in epoch 1, gen_loss = 0.3868043910373341, disc_loss = 0.22493679144165732
Trained batch 11 in epoch 1, gen_loss = 0.38433752457300824, disc_loss = 0.2270898794134458
Trained batch 12 in epoch 1, gen_loss = 0.38433758799846357, disc_loss = 0.22419197857379913
Trained batch 13 in epoch 1, gen_loss = 0.38637138477393557, disc_loss = 0.22162067890167236
Trained batch 14 in epoch 1, gen_loss = 0.38135915199915565, disc_loss = 0.22064432501792908
Trained batch 15 in epoch 1, gen_loss = 0.38018147833645344, disc_loss = 0.2224237760528922
Trained batch 16 in epoch 1, gen_loss = 0.3835546251605539, disc_loss = 0.21916773915290833
Trained batch 17 in epoch 1, gen_loss = 0.3859699285692639, disc_loss = 0.21599823815955055
Trained batch 18 in epoch 1, gen_loss = 0.3853515465008585, disc_loss = 0.21630099102070457
Trained batch 19 in epoch 1, gen_loss = 0.3855313017964363, disc_loss = 0.21868450492620467
Trained batch 20 in epoch 1, gen_loss = 0.386334783974148, disc_loss = 0.2194986165989013
Trained batch 21 in epoch 1, gen_loss = 0.388938460837711, disc_loss = 0.21657886085185138
Trained batch 22 in epoch 1, gen_loss = 0.38536935267241107, disc_loss = 0.2177647352218628
Trained batch 23 in epoch 1, gen_loss = 0.3837856749693553, disc_loss = 0.22243566438555717
Trained batch 24 in epoch 1, gen_loss = 0.3815309679508209, disc_loss = 0.22305180072784425
Trained batch 25 in epoch 1, gen_loss = 0.38235590205742764, disc_loss = 0.22104821927272356
Trained batch 26 in epoch 1, gen_loss = 0.38157764739460415, disc_loss = 0.22026596521889721
Trained batch 27 in epoch 1, gen_loss = 0.38043090807540075, disc_loss = 0.22008852713874408
Trained batch 28 in epoch 1, gen_loss = 0.3820415539988156, disc_loss = 0.21952437275442585
Trained batch 29 in epoch 1, gen_loss = 0.3823656539122264, disc_loss = 0.2181411052743594
Trained batch 30 in epoch 1, gen_loss = 0.3810006380081177, disc_loss = 0.21643657501666777
Trained batch 31 in epoch 1, gen_loss = 0.38042865600436926, disc_loss = 0.2153816861100495
Trained batch 32 in epoch 1, gen_loss = 0.38098792054436426, disc_loss = 0.21505472199483353
Trained batch 33 in epoch 1, gen_loss = 0.3826243158648996, disc_loss = 0.2126185135806308
Trained batch 34 in epoch 1, gen_loss = 0.38345681599208287, disc_loss = 0.21285224769796643
Trained batch 35 in epoch 1, gen_loss = 0.3832355696294043, disc_loss = 0.21407002748714554
Trained batch 36 in epoch 1, gen_loss = 0.38352844843993317, disc_loss = 0.2122407124654667
Trained batch 37 in epoch 1, gen_loss = 0.38576529841674, disc_loss = 0.21097955852746964
Trained batch 38 in epoch 1, gen_loss = 0.3873383433390886, disc_loss = 0.20879291685727927
Trained batch 39 in epoch 1, gen_loss = 0.3868003562092781, disc_loss = 0.20780433788895608
Trained batch 40 in epoch 1, gen_loss = 0.3862365200752165, disc_loss = 0.2066593406403937
Trained batch 41 in epoch 1, gen_loss = 0.38544307507219766, disc_loss = 0.20678360582817168
Trained batch 42 in epoch 1, gen_loss = 0.38683703957602034, disc_loss = 0.20711783129115438
Trained batch 43 in epoch 1, gen_loss = 0.38491617278619245, disc_loss = 0.2069633328779177
Trained batch 44 in epoch 1, gen_loss = 0.3838660392496321, disc_loss = 0.20856513877709706
Trained batch 45 in epoch 1, gen_loss = 0.38434617739656696, disc_loss = 0.20950197298889575
Trained batch 46 in epoch 1, gen_loss = 0.3857918254872586, disc_loss = 0.2104133903346163
Trained batch 47 in epoch 1, gen_loss = 0.3874195919682582, disc_loss = 0.21111799714465937
Trained batch 48 in epoch 1, gen_loss = 0.38911294389744194, disc_loss = 0.21099681209544746
Trained batch 49 in epoch 1, gen_loss = 0.389601902961731, disc_loss = 0.20993498116731643
Trained batch 50 in epoch 1, gen_loss = 0.39078467967463476, disc_loss = 0.20880067611441894
Trained batch 51 in epoch 1, gen_loss = 0.3918154898744363, disc_loss = 0.20737299609642762
Trained batch 52 in epoch 1, gen_loss = 0.3922339053648823, disc_loss = 0.20622803664432382
Trained batch 53 in epoch 1, gen_loss = 0.39229851464430493, disc_loss = 0.20544828860848038
Trained batch 54 in epoch 1, gen_loss = 0.3933162293650887, disc_loss = 0.2049664085561579
Trained batch 55 in epoch 1, gen_loss = 0.39422007703355383, disc_loss = 0.20362981036305428
Trained batch 56 in epoch 1, gen_loss = 0.39463040389512716, disc_loss = 0.20334813966040025
Trained batch 57 in epoch 1, gen_loss = 0.3957925921884076, disc_loss = 0.21133827212555656
Trained batch 58 in epoch 1, gen_loss = 0.39637627338959, disc_loss = 0.21102866555674601
Trained batch 59 in epoch 1, gen_loss = 0.39580710927645363, disc_loss = 0.21274147406220437
Trained batch 60 in epoch 1, gen_loss = 0.3969120256236342, disc_loss = 0.21299746217297727
Trained batch 61 in epoch 1, gen_loss = 0.3967165942153623, disc_loss = 0.21329587818153442
Trained batch 62 in epoch 1, gen_loss = 0.3965583490946936, disc_loss = 0.21321103095062197
Trained batch 63 in epoch 1, gen_loss = 0.39585949620231986, disc_loss = 0.21303507196716964
Trained batch 64 in epoch 1, gen_loss = 0.3957583597073188, disc_loss = 0.2140010831447748
Trained batch 65 in epoch 1, gen_loss = 0.395426511312976, disc_loss = 0.21391376153086172
Trained batch 66 in epoch 1, gen_loss = 0.39583883045324636, disc_loss = 0.2137586031831912
Trained batch 67 in epoch 1, gen_loss = 0.396475934806992, disc_loss = 0.21392069143407486
Trained batch 68 in epoch 1, gen_loss = 0.39538343920223956, disc_loss = 0.21383488631766776
Trained batch 69 in epoch 1, gen_loss = 0.3946696907281876, disc_loss = 0.21342132432120187
Trained batch 70 in epoch 1, gen_loss = 0.39507252103845836, disc_loss = 0.21267776380122547
Trained batch 71 in epoch 1, gen_loss = 0.3944080029096868, disc_loss = 0.21290555265214708
Trained batch 72 in epoch 1, gen_loss = 0.3944027913759833, disc_loss = 0.21329935691128038
Trained batch 73 in epoch 1, gen_loss = 0.39549714447678747, disc_loss = 0.21243439050945076
Trained batch 74 in epoch 1, gen_loss = 0.39603161414464316, disc_loss = 0.2123915954430898
Trained batch 75 in epoch 1, gen_loss = 0.3960710834515722, disc_loss = 0.2118126289232781
Trained batch 76 in epoch 1, gen_loss = 0.39608035575259815, disc_loss = 0.21105753175624006
Trained batch 77 in epoch 1, gen_loss = 0.39620293638645077, disc_loss = 0.21032418597203034
Trained batch 78 in epoch 1, gen_loss = 0.3964107278027112, disc_loss = 0.20911592075341864
Trained batch 79 in epoch 1, gen_loss = 0.39692749418318274, disc_loss = 0.2077865457162261
Trained batch 80 in epoch 1, gen_loss = 0.3971366120709313, disc_loss = 0.20675892070119764
Trained batch 81 in epoch 1, gen_loss = 0.3973762200372975, disc_loss = 0.206115064733639
Trained batch 82 in epoch 1, gen_loss = 0.39784379285502147, disc_loss = 0.20571922654488
Trained batch 83 in epoch 1, gen_loss = 0.39865013850586756, disc_loss = 0.2038792438272919
Trained batch 84 in epoch 1, gen_loss = 0.39891295853783104, disc_loss = 0.20368924798334345
Trained batch 85 in epoch 1, gen_loss = 0.3991210013628006, disc_loss = 0.2025578112969565
Trained batch 86 in epoch 1, gen_loss = 0.3994505888429181, disc_loss = 0.20243448866852398
Trained batch 87 in epoch 1, gen_loss = 0.4001182026483796, disc_loss = 0.20194999255578627
Trained batch 88 in epoch 1, gen_loss = 0.39943397145592763, disc_loss = 0.20138211590185595
Trained batch 89 in epoch 1, gen_loss = 0.3987604273690118, disc_loss = 0.20167666946848234
Trained batch 90 in epoch 1, gen_loss = 0.3996893331244752, disc_loss = 0.2011830414553265
Trained batch 91 in epoch 1, gen_loss = 0.39961978598781256, disc_loss = 0.20155279929547207
Trained batch 92 in epoch 1, gen_loss = 0.4003932200452333, disc_loss = 0.2029604694695883
Trained batch 93 in epoch 1, gen_loss = 0.4009264583917374, disc_loss = 0.20350350605997633
Trained batch 94 in epoch 1, gen_loss = 0.40156599345960114, disc_loss = 0.204396658900537
Trained batch 95 in epoch 1, gen_loss = 0.4012518481661876, disc_loss = 0.20531262278867266
Trained batch 96 in epoch 1, gen_loss = 0.40081540518200276, disc_loss = 0.20470318405591337
Trained batch 97 in epoch 1, gen_loss = 0.40123255003471764, disc_loss = 0.20350529534780248
Trained batch 98 in epoch 1, gen_loss = 0.4002027725330507, disc_loss = 0.2031087228896642
Trained batch 99 in epoch 1, gen_loss = 0.4002738791704178, disc_loss = 0.20267874725162982
Trained batch 100 in epoch 1, gen_loss = 0.4007959690424475, disc_loss = 0.20131205560842363
Trained batch 101 in epoch 1, gen_loss = 0.4011218688067268, disc_loss = 0.20006322692714484
Trained batch 102 in epoch 1, gen_loss = 0.40189638126243665, disc_loss = 0.19862580765942925
Trained batch 103 in epoch 1, gen_loss = 0.4024645264905233, disc_loss = 0.19763859486780488
Trained batch 104 in epoch 1, gen_loss = 0.40189649292400903, disc_loss = 0.19747843313075247
Trained batch 105 in epoch 1, gen_loss = 0.40230137728295234, disc_loss = 0.19657529563695755
Trained batch 106 in epoch 1, gen_loss = 0.4030635384755714, disc_loss = 0.19552055673203736
Trained batch 107 in epoch 1, gen_loss = 0.4027653502093421, disc_loss = 0.1942123826938095
Trained batch 108 in epoch 1, gen_loss = 0.4030726675046693, disc_loss = 0.19434318612885038
Trained batch 109 in epoch 1, gen_loss = 0.4039724818684838, disc_loss = 0.19509074481373484
Trained batch 110 in epoch 1, gen_loss = 0.4036244642627132, disc_loss = 0.19525452545500016
Trained batch 111 in epoch 1, gen_loss = 0.40398744121193886, disc_loss = 0.1953249284664967
Trained batch 112 in epoch 1, gen_loss = 0.40338414590970606, disc_loss = 0.1956343253563463
Trained batch 113 in epoch 1, gen_loss = 0.40321350045371473, disc_loss = 0.19535089110988274
Trained batch 114 in epoch 1, gen_loss = 0.40264663281648055, disc_loss = 0.19596962536806645
Trained batch 115 in epoch 1, gen_loss = 0.40250273922394064, disc_loss = 0.19696518698514537
Trained batch 116 in epoch 1, gen_loss = 0.40250216437201214, disc_loss = 0.19667599251509732
Trained batch 117 in epoch 1, gen_loss = 0.40236913753768144, disc_loss = 0.1968909872979936
Trained batch 118 in epoch 1, gen_loss = 0.40250865526559976, disc_loss = 0.19567883549993778
Trained batch 119 in epoch 1, gen_loss = 0.40251316328843434, disc_loss = 0.19500199193134904
Trained batch 120 in epoch 1, gen_loss = 0.40219798955050384, disc_loss = 0.19508887257827215
Trained batch 121 in epoch 1, gen_loss = 0.4023173214470754, disc_loss = 0.1946521254531184
Trained batch 122 in epoch 1, gen_loss = 0.40205459914556363, disc_loss = 0.1942897826372608
Trained batch 123 in epoch 1, gen_loss = 0.40202198850531734, disc_loss = 0.19294569779547951
Trained batch 124 in epoch 1, gen_loss = 0.4019030902385712, disc_loss = 0.1920420368909836
Trained batch 125 in epoch 1, gen_loss = 0.4019885103380869, disc_loss = 0.1911399265130361
Trained batch 126 in epoch 1, gen_loss = 0.4012600397031138, disc_loss = 0.191283515940501
Trained batch 127 in epoch 1, gen_loss = 0.4013960927259177, disc_loss = 0.1923335933825001
Trained batch 128 in epoch 1, gen_loss = 0.40104341368342555, disc_loss = 0.19219955744207368
Trained batch 129 in epoch 1, gen_loss = 0.4007819459988521, disc_loss = 0.19187192378135828
Trained batch 130 in epoch 1, gen_loss = 0.4005678848910878, disc_loss = 0.19162556881668003
Trained batch 131 in epoch 1, gen_loss = 0.40068716194593545, disc_loss = 0.19148485825368852
Trained batch 132 in epoch 1, gen_loss = 0.4007450348900673, disc_loss = 0.1927353713969539
Trained batch 133 in epoch 1, gen_loss = 0.4001919940781237, disc_loss = 0.19301043461952636
Trained batch 134 in epoch 1, gen_loss = 0.3996883315068704, disc_loss = 0.19299603866206275
Trained batch 135 in epoch 1, gen_loss = 0.39964645509334173, disc_loss = 0.1931997755651965
Trained batch 136 in epoch 1, gen_loss = 0.3997763917393928, disc_loss = 0.19301880352253462
Trained batch 137 in epoch 1, gen_loss = 0.3998579663642939, disc_loss = 0.19280230037976
Trained batch 138 in epoch 1, gen_loss = 0.4000496186798425, disc_loss = 0.1928722424258431
Trained batch 139 in epoch 1, gen_loss = 0.4000357006277357, disc_loss = 0.19336446513022695
Trained batch 140 in epoch 1, gen_loss = 0.39953634121739273, disc_loss = 0.19420791084462025
Trained batch 141 in epoch 1, gen_loss = 0.39929868952489234, disc_loss = 0.19421486755911732
Trained batch 142 in epoch 1, gen_loss = 0.39947597359443876, disc_loss = 0.19404200188346676
Trained batch 143 in epoch 1, gen_loss = 0.39985832903120255, disc_loss = 0.19365598778757784
Trained batch 144 in epoch 1, gen_loss = 0.3998019271883471, disc_loss = 0.1931988448932253
Trained batch 145 in epoch 1, gen_loss = 0.4006415454492177, disc_loss = 0.19262562457421054
Trained batch 146 in epoch 1, gen_loss = 0.4005770622467508, disc_loss = 0.19204246678522655
Trained batch 147 in epoch 1, gen_loss = 0.400539349865269, disc_loss = 0.1917227041983121
Trained batch 148 in epoch 1, gen_loss = 0.3999701190314837, disc_loss = 0.19186855327563
Trained batch 149 in epoch 1, gen_loss = 0.4003897440433502, disc_loss = 0.19238890811800957
Trained batch 150 in epoch 1, gen_loss = 0.40137116640608833, disc_loss = 0.1920312260653799
Trained batch 151 in epoch 1, gen_loss = 0.4015972137843308, disc_loss = 0.19175635851723583
Trained batch 152 in epoch 1, gen_loss = 0.40143473397672563, disc_loss = 0.19117942345298194
Trained batch 153 in epoch 1, gen_loss = 0.40142128548838873, disc_loss = 0.19079826143267867
Trained batch 154 in epoch 1, gen_loss = 0.40152610828799584, disc_loss = 0.19042575705435968
Trained batch 155 in epoch 1, gen_loss = 0.40209155548841524, disc_loss = 0.18989820023759818
Trained batch 156 in epoch 1, gen_loss = 0.4018617050283274, disc_loss = 0.1891733006971657
Trained batch 157 in epoch 1, gen_loss = 0.40098572720455217, disc_loss = 0.18932207131498976
Trained batch 158 in epoch 1, gen_loss = 0.4007789228322371, disc_loss = 0.18996901027623964
Trained batch 159 in epoch 1, gen_loss = 0.4009408442303538, disc_loss = 0.19015427087433637
Trained batch 160 in epoch 1, gen_loss = 0.4006747434968534, disc_loss = 0.19015069153182995
Trained batch 161 in epoch 1, gen_loss = 0.4006269579684293, disc_loss = 0.1902789179649618
Trained batch 162 in epoch 1, gen_loss = 0.4003786607388338, disc_loss = 0.19031786630672912
Trained batch 163 in epoch 1, gen_loss = 0.4007968437380907, disc_loss = 0.19012990780174732
Trained batch 164 in epoch 1, gen_loss = 0.4007934573924903, disc_loss = 0.18963303010572086
Trained batch 165 in epoch 1, gen_loss = 0.4009903107421944, disc_loss = 0.18931644136108547
Trained batch 166 in epoch 1, gen_loss = 0.400938991479531, disc_loss = 0.18968722888987935
Trained batch 167 in epoch 1, gen_loss = 0.40058635565496625, disc_loss = 0.1891871355917482
Trained batch 168 in epoch 1, gen_loss = 0.40055566320757896, disc_loss = 0.19035055990931551
Trained batch 169 in epoch 1, gen_loss = 0.40066215325804316, disc_loss = 0.1908131457865238
Trained batch 170 in epoch 1, gen_loss = 0.40049031185127837, disc_loss = 0.1904852957143421
Trained batch 171 in epoch 1, gen_loss = 0.400717482490595, disc_loss = 0.19027558389271415
Trained batch 172 in epoch 1, gen_loss = 0.40060072155357096, disc_loss = 0.19000570428681512
Trained batch 173 in epoch 1, gen_loss = 0.4007173857127113, disc_loss = 0.18991055926200986
Trained batch 174 in epoch 1, gen_loss = 0.401007879120963, disc_loss = 0.18971872521298272
Trained batch 175 in epoch 1, gen_loss = 0.4015052887526425, disc_loss = 0.18876696926202963
Trained batch 176 in epoch 1, gen_loss = 0.4013372814587954, disc_loss = 0.18789276823738202
Trained batch 177 in epoch 1, gen_loss = 0.4013847303524446, disc_loss = 0.186942944585691
Trained batch 178 in epoch 1, gen_loss = 0.4012809968527469, disc_loss = 0.18607570833458914
Trained batch 179 in epoch 1, gen_loss = 0.40160916397968927, disc_loss = 0.18510537966568436
Trained batch 180 in epoch 1, gen_loss = 0.40144468045366405, disc_loss = 0.18479268614573208
Trained batch 181 in epoch 1, gen_loss = 0.40184466802811886, disc_loss = 0.18404806169404925
Trained batch 182 in epoch 1, gen_loss = 0.40189487784286665, disc_loss = 0.18410311152273026
Trained batch 183 in epoch 1, gen_loss = 0.40250087820965313, disc_loss = 0.1850716092006263
Trained batch 184 in epoch 1, gen_loss = 0.4020567346263576, disc_loss = 0.185311875567847
Trained batch 185 in epoch 1, gen_loss = 0.40173068850912075, disc_loss = 0.18569446933425723
Trained batch 186 in epoch 1, gen_loss = 0.40159480966986183, disc_loss = 0.1855477071690926
Trained batch 187 in epoch 1, gen_loss = 0.401940810870617, disc_loss = 0.18511017124128945
Trained batch 188 in epoch 1, gen_loss = 0.4025159582259163, disc_loss = 0.18474107394832626
Trained batch 189 in epoch 1, gen_loss = 0.4032398973640643, disc_loss = 0.18397940963408665
Trained batch 190 in epoch 1, gen_loss = 0.4035177851846705, disc_loss = 0.1832998172765237
Trained batch 191 in epoch 1, gen_loss = 0.40329183591529727, disc_loss = 0.1825022689833228
Trained batch 192 in epoch 1, gen_loss = 0.4030693747836691, disc_loss = 0.18200585649015835
Trained batch 193 in epoch 1, gen_loss = 0.40316090602235694, disc_loss = 0.18176045600497692
Trained batch 194 in epoch 1, gen_loss = 0.4031983549778278, disc_loss = 0.18138475702263607
Trained batch 195 in epoch 1, gen_loss = 0.4037519118615559, disc_loss = 0.18064647511465057
Trained batch 196 in epoch 1, gen_loss = 0.4035817823434239, disc_loss = 0.17994644721204103
Trained batch 197 in epoch 1, gen_loss = 0.4039455144995391, disc_loss = 0.17908790063658597
Trained batch 198 in epoch 1, gen_loss = 0.4043385909130825, disc_loss = 0.17822506791214698
Trained batch 199 in epoch 1, gen_loss = 0.4044291366636753, disc_loss = 0.1775134629709646
Trained batch 200 in epoch 1, gen_loss = 0.40432552481765177, disc_loss = 0.1770713018642655
Trained batch 201 in epoch 1, gen_loss = 0.4047057751086679, disc_loss = 0.17652935530566197
Trained batch 202 in epoch 1, gen_loss = 0.405091416806423, disc_loss = 0.1764033375436376
Trained batch 203 in epoch 1, gen_loss = 0.4052726607404503, disc_loss = 0.17684061010368168
Trained batch 204 in epoch 1, gen_loss = 0.40482399623568466, disc_loss = 0.17672294236083583
Trained batch 205 in epoch 1, gen_loss = 0.4051254206490748, disc_loss = 0.17614521830821933
Trained batch 206 in epoch 1, gen_loss = 0.40520504980847455, disc_loss = 0.17606154602056973
Trained batch 207 in epoch 1, gen_loss = 0.405089687412748, disc_loss = 0.17676483710350183
Trained batch 208 in epoch 1, gen_loss = 0.40506729569161337, disc_loss = 0.17725726747751663
Trained batch 209 in epoch 1, gen_loss = 0.40535003117152624, disc_loss = 0.1776553727287267
Trained batch 210 in epoch 1, gen_loss = 0.4054091013438329, disc_loss = 0.17810316037351345
Trained batch 211 in epoch 1, gen_loss = 0.40536424306766045, disc_loss = 0.1782745211429121
Trained batch 212 in epoch 1, gen_loss = 0.4057311351310479, disc_loss = 0.17811607390624676
Trained batch 213 in epoch 1, gen_loss = 0.40529187803513533, disc_loss = 0.17783685982070654
Trained batch 214 in epoch 1, gen_loss = 0.40528006401172906, disc_loss = 0.17782118756670592
Trained batch 215 in epoch 1, gen_loss = 0.4056477550831106, disc_loss = 0.1782922114857852
Trained batch 216 in epoch 1, gen_loss = 0.4052702307975787, disc_loss = 0.17842304973953194
Trained batch 217 in epoch 1, gen_loss = 0.4051619723029093, disc_loss = 0.17920504598835602
Trained batch 218 in epoch 1, gen_loss = 0.40556386888843693, disc_loss = 0.1787933863690931
Trained batch 219 in epoch 1, gen_loss = 0.40557785318656403, disc_loss = 0.1792362162970345
Trained batch 220 in epoch 1, gen_loss = 0.40572187061762915, disc_loss = 0.17925501078350375
Trained batch 221 in epoch 1, gen_loss = 0.4053631885363175, disc_loss = 0.17926273199201032
Trained batch 222 in epoch 1, gen_loss = 0.40536674322568783, disc_loss = 0.17913465776100687
Trained batch 223 in epoch 1, gen_loss = 0.4052156993587102, disc_loss = 0.17913658989709802
Trained batch 224 in epoch 1, gen_loss = 0.40525683840115867, disc_loss = 0.1792143749487069
Trained batch 225 in epoch 1, gen_loss = 0.4053056961403484, disc_loss = 0.1791354026769049
Trained batch 226 in epoch 1, gen_loss = 0.405018103017681, disc_loss = 0.1791920426223706
Trained batch 227 in epoch 1, gen_loss = 0.4049589295397725, disc_loss = 0.17915943793936126
Trained batch 228 in epoch 1, gen_loss = 0.4051183771878871, disc_loss = 0.17901723977894113
Trained batch 229 in epoch 1, gen_loss = 0.4050485329783481, disc_loss = 0.17875519802631892
Trained batch 230 in epoch 1, gen_loss = 0.40481129430589224, disc_loss = 0.17848273253398927
Trained batch 231 in epoch 1, gen_loss = 0.40504255428396424, disc_loss = 0.17829862795368737
Trained batch 232 in epoch 1, gen_loss = 0.4051048194134184, disc_loss = 0.1786382438119325
Trained batch 233 in epoch 1, gen_loss = 0.405046528730637, disc_loss = 0.17862986855638716
Trained batch 234 in epoch 1, gen_loss = 0.40468497961125477, disc_loss = 0.1788417292362515
Trained batch 235 in epoch 1, gen_loss = 0.4047678770907855, disc_loss = 0.17864286602411608
Trained batch 236 in epoch 1, gen_loss = 0.4046127699346985, disc_loss = 0.17885511553598732
Trained batch 237 in epoch 1, gen_loss = 0.40445834072698067, disc_loss = 0.17901078573655055
Trained batch 238 in epoch 1, gen_loss = 0.4043488768104729, disc_loss = 0.17910615856287743
Trained batch 239 in epoch 1, gen_loss = 0.40446077610055603, disc_loss = 0.17908222308615224
Trained batch 240 in epoch 1, gen_loss = 0.40447004887572957, disc_loss = 0.17881591803166258
Trained batch 241 in epoch 1, gen_loss = 0.4045249022974456, disc_loss = 0.1789514536292038
Trained batch 242 in epoch 1, gen_loss = 0.4043180009219872, disc_loss = 0.17905996022017773
Trained batch 243 in epoch 1, gen_loss = 0.4044696816899737, disc_loss = 0.17895784643936719
Trained batch 244 in epoch 1, gen_loss = 0.40440187490716273, disc_loss = 0.17926080530623392
Trained batch 245 in epoch 1, gen_loss = 0.4041109195327371, disc_loss = 0.17922593089486888
Trained batch 246 in epoch 1, gen_loss = 0.40384559918511737, disc_loss = 0.1793550427829628
Trained batch 247 in epoch 1, gen_loss = 0.40381110579736773, disc_loss = 0.17994897055154246
Trained batch 248 in epoch 1, gen_loss = 0.40370245535210914, disc_loss = 0.17993799342313804
Trained batch 249 in epoch 1, gen_loss = 0.40345879209041596, disc_loss = 0.18018000167235732
Trained batch 250 in epoch 1, gen_loss = 0.4035146501197283, disc_loss = 0.18004395530384731
Trained batch 251 in epoch 1, gen_loss = 0.40324793389392277, disc_loss = 0.18014999035198892
Trained batch 252 in epoch 1, gen_loss = 0.40328609366190765, disc_loss = 0.18008207697274067
Trained batch 253 in epoch 1, gen_loss = 0.40330087047392926, disc_loss = 0.1802262091811189
Trained batch 254 in epoch 1, gen_loss = 0.4031826136158962, disc_loss = 0.18025649306455663
Trained batch 255 in epoch 1, gen_loss = 0.40329574747011065, disc_loss = 0.18005655746310367
Trained batch 256 in epoch 1, gen_loss = 0.4034301536556348, disc_loss = 0.1799647801660784
Trained batch 257 in epoch 1, gen_loss = 0.4031669149796168, disc_loss = 0.17993971456723043
Trained batch 258 in epoch 1, gen_loss = 0.4031811194300191, disc_loss = 0.18031577777088725
Trained batch 259 in epoch 1, gen_loss = 0.40307010538302934, disc_loss = 0.18022049430113
Trained batch 260 in epoch 1, gen_loss = 0.40291716986232334, disc_loss = 0.18024038708629622
Trained batch 261 in epoch 1, gen_loss = 0.4027632259913073, disc_loss = 0.18026884502681498
Trained batch 262 in epoch 1, gen_loss = 0.4027396348719361, disc_loss = 0.18019805479964715
Trained batch 263 in epoch 1, gen_loss = 0.4026437405158173, disc_loss = 0.18027563020234194
Trained batch 264 in epoch 1, gen_loss = 0.40240244932894437, disc_loss = 0.18030156211681522
Trained batch 265 in epoch 1, gen_loss = 0.4026565798243186, disc_loss = 0.18021642242705352
Trained batch 266 in epoch 1, gen_loss = 0.4026599624630217, disc_loss = 0.18009044424969048
Trained batch 267 in epoch 1, gen_loss = 0.4024305530448458, disc_loss = 0.1801068550358012
Trained batch 268 in epoch 1, gen_loss = 0.40221786399313064, disc_loss = 0.18027112640952864
Trained batch 269 in epoch 1, gen_loss = 0.40254604231428215, disc_loss = 0.1803864851559478
Trained batch 270 in epoch 1, gen_loss = 0.40288794095665764, disc_loss = 0.18029987443293483
Trained batch 271 in epoch 1, gen_loss = 0.40280930193908077, disc_loss = 0.18021640745470957
Trained batch 272 in epoch 1, gen_loss = 0.4030131310115367, disc_loss = 0.1797919500407664
Trained batch 273 in epoch 1, gen_loss = 0.4028947251121493, disc_loss = 0.17972973391182556
Trained batch 274 in epoch 1, gen_loss = 0.40280821258371524, disc_loss = 0.1805399377745661
Trained batch 275 in epoch 1, gen_loss = 0.40290107675220654, disc_loss = 0.18064636078096277
Trained batch 276 in epoch 1, gen_loss = 0.40263289880236136, disc_loss = 0.18094073122683307
Trained batch 277 in epoch 1, gen_loss = 0.40261178586980423, disc_loss = 0.18118476111562454
Trained batch 278 in epoch 1, gen_loss = 0.40245193104162863, disc_loss = 0.18117660903255037
Trained batch 279 in epoch 1, gen_loss = 0.40235433418835914, disc_loss = 0.18119543300875063
Trained batch 280 in epoch 1, gen_loss = 0.40242532425927946, disc_loss = 0.18105494296940514
Trained batch 281 in epoch 1, gen_loss = 0.40224929196192016, disc_loss = 0.18086332484009734
Trained batch 282 in epoch 1, gen_loss = 0.40225493865805045, disc_loss = 0.18074180490860564
Trained batch 283 in epoch 1, gen_loss = 0.40219656545931187, disc_loss = 0.18062748722928826
Trained batch 284 in epoch 1, gen_loss = 0.4020040145045833, disc_loss = 0.18057778493027415
Trained batch 285 in epoch 1, gen_loss = 0.4018193706349059, disc_loss = 0.18076148800799377
Trained batch 286 in epoch 1, gen_loss = 0.40207541092762966, disc_loss = 0.18065153368349587
Trained batch 287 in epoch 1, gen_loss = 0.4020455123649703, disc_loss = 0.1805350524341015
Trained batch 288 in epoch 1, gen_loss = 0.4020151817674868, disc_loss = 0.1804147201290541
Trained batch 289 in epoch 1, gen_loss = 0.40210374110731584, disc_loss = 0.1801651150983726
Trained batch 290 in epoch 1, gen_loss = 0.4020129014126624, disc_loss = 0.18018406782862553
Trained batch 291 in epoch 1, gen_loss = 0.4019755249562329, disc_loss = 0.18028491153381765
Trained batch 292 in epoch 1, gen_loss = 0.4023946725060915, disc_loss = 0.18046037165874
Trained batch 293 in epoch 1, gen_loss = 0.4023950124273495, disc_loss = 0.18030637923032553
Trained batch 294 in epoch 1, gen_loss = 0.4021507515745648, disc_loss = 0.18029170450201984
Trained batch 295 in epoch 1, gen_loss = 0.40210300059737386, disc_loss = 0.18024787175582369
Trained batch 296 in epoch 1, gen_loss = 0.4020352033452956, disc_loss = 0.18010254831112896
Trained batch 297 in epoch 1, gen_loss = 0.40204246852221903, disc_loss = 0.18022161106822776
Trained batch 298 in epoch 1, gen_loss = 0.4021452652371448, disc_loss = 0.1801074884775839
Trained batch 299 in epoch 1, gen_loss = 0.40204967439174655, disc_loss = 0.18000323623108366
Trained batch 300 in epoch 1, gen_loss = 0.40205591134850766, disc_loss = 0.17993101982269868
Trained batch 301 in epoch 1, gen_loss = 0.4020958002039928, disc_loss = 0.17987257962281636
Trained batch 302 in epoch 1, gen_loss = 0.4022868901196093, disc_loss = 0.17965564898617886
Trained batch 303 in epoch 1, gen_loss = 0.40242487437238816, disc_loss = 0.17963590972603447
Trained batch 304 in epoch 1, gen_loss = 0.40264630356773, disc_loss = 0.17947127896925955
Trained batch 305 in epoch 1, gen_loss = 0.40255213923314037, disc_loss = 0.1794162385768312
Trained batch 306 in epoch 1, gen_loss = 0.40241958555258833, disc_loss = 0.17924936494034646
Trained batch 307 in epoch 1, gen_loss = 0.4021572608065295, disc_loss = 0.1792174875222195
Trained batch 308 in epoch 1, gen_loss = 0.4022929963556308, disc_loss = 0.17917709910645357
Trained batch 309 in epoch 1, gen_loss = 0.4026159240353492, disc_loss = 0.17905700576581782
Trained batch 310 in epoch 1, gen_loss = 0.4025967370275516, disc_loss = 0.17895949370500264
Trained batch 311 in epoch 1, gen_loss = 0.4027856159477662, disc_loss = 0.17870502001665628
Trained batch 312 in epoch 1, gen_loss = 0.40289343460299337, disc_loss = 0.17878000680714273
Trained batch 313 in epoch 1, gen_loss = 0.40291977963250153, disc_loss = 0.17886220312315473
Trained batch 314 in epoch 1, gen_loss = 0.4031907156346336, disc_loss = 0.17883113806860315
Trained batch 315 in epoch 1, gen_loss = 0.403112028973012, disc_loss = 0.1789685099627351
Trained batch 316 in epoch 1, gen_loss = 0.40292815718365016, disc_loss = 0.17914548407864025
Trained batch 317 in epoch 1, gen_loss = 0.4029538320295466, disc_loss = 0.1790648028225222
Trained batch 318 in epoch 1, gen_loss = 0.4029559435141871, disc_loss = 0.17921241781262676
Trained batch 319 in epoch 1, gen_loss = 0.4028594045899808, disc_loss = 0.17924816505692434
Trained batch 320 in epoch 1, gen_loss = 0.4028964117865696, disc_loss = 0.17921651198566424
Trained batch 321 in epoch 1, gen_loss = 0.40291591506937274, disc_loss = 0.1791518222257171
Trained batch 322 in epoch 1, gen_loss = 0.4030216193236065, disc_loss = 0.17903346814872587
Trained batch 323 in epoch 1, gen_loss = 0.4030513629133319, disc_loss = 0.17900445390159242
Trained batch 324 in epoch 1, gen_loss = 0.40294526567825906, disc_loss = 0.17912538321832053
Trained batch 325 in epoch 1, gen_loss = 0.40320607946694265, disc_loss = 0.1790432360886019
Trained batch 326 in epoch 1, gen_loss = 0.403420407837684, disc_loss = 0.1787413107117336
Trained batch 327 in epoch 1, gen_loss = 0.40328833633443206, disc_loss = 0.17880649196563242
Trained batch 328 in epoch 1, gen_loss = 0.40312442545832833, disc_loss = 0.17899625347276135
Trained batch 329 in epoch 1, gen_loss = 0.40307646800171243, disc_loss = 0.1789461249175171
Trained batch 330 in epoch 1, gen_loss = 0.40325015837332273, disc_loss = 0.17883490376860983
Trained batch 331 in epoch 1, gen_loss = 0.40320154746253806, disc_loss = 0.178924718846466
Trained batch 332 in epoch 1, gen_loss = 0.40344787503147983, disc_loss = 0.1791130135160264
Trained batch 333 in epoch 1, gen_loss = 0.40348822030121695, disc_loss = 0.17963980191560117
Trained batch 334 in epoch 1, gen_loss = 0.4035008236543456, disc_loss = 0.1797785543655949
Trained batch 335 in epoch 1, gen_loss = 0.40336609152810915, disc_loss = 0.18012458919492064
Trained batch 336 in epoch 1, gen_loss = 0.40347361997963765, disc_loss = 0.18009694092782652
Trained batch 337 in epoch 1, gen_loss = 0.40353132149524235, disc_loss = 0.1802198605573345
Trained batch 338 in epoch 1, gen_loss = 0.4034797075399607, disc_loss = 0.1802224036839112
Trained batch 339 in epoch 1, gen_loss = 0.40325484372237147, disc_loss = 0.1803344385999748
Trained batch 340 in epoch 1, gen_loss = 0.4032339533228329, disc_loss = 0.18034918230201755
Trained batch 341 in epoch 1, gen_loss = 0.40299293416285376, disc_loss = 0.180353634797407
Trained batch 342 in epoch 1, gen_loss = 0.4029700364211558, disc_loss = 0.1801865782681038
Trained batch 343 in epoch 1, gen_loss = 0.40297008288461106, disc_loss = 0.18020042687990204
Trained batch 344 in epoch 1, gen_loss = 0.4033544683801955, disc_loss = 0.18026461218740197
Trained batch 345 in epoch 1, gen_loss = 0.4032206988403563, disc_loss = 0.18031295003218717
Trained batch 346 in epoch 1, gen_loss = 0.4030272378358099, disc_loss = 0.18081413426031212
Trained batch 347 in epoch 1, gen_loss = 0.4030126698058227, disc_loss = 0.18090910385041659
Trained batch 348 in epoch 1, gen_loss = 0.4029837380507614, disc_loss = 0.18124877908840817
Trained batch 349 in epoch 1, gen_loss = 0.4030116791384561, disc_loss = 0.18140174918674998
Trained batch 350 in epoch 1, gen_loss = 0.4029665377914396, disc_loss = 0.1813997539885321
Trained batch 351 in epoch 1, gen_loss = 0.4028905774890022, disc_loss = 0.18132201440113765
Trained batch 352 in epoch 1, gen_loss = 0.40288151661329835, disc_loss = 0.18119749893030684
Trained batch 353 in epoch 1, gen_loss = 0.40261143673274474, disc_loss = 0.18123306512653745
Trained batch 354 in epoch 1, gen_loss = 0.40247123728335743, disc_loss = 0.1811625920734565
Trained batch 355 in epoch 1, gen_loss = 0.40236314285672115, disc_loss = 0.18118839390481706
Trained batch 356 in epoch 1, gen_loss = 0.40244349353119774, disc_loss = 0.18108269436342292
Trained batch 357 in epoch 1, gen_loss = 0.40248550607838446, disc_loss = 0.1810754996453875
Trained batch 358 in epoch 1, gen_loss = 0.4022398616776161, disc_loss = 0.180965521352101
Trained batch 359 in epoch 1, gen_loss = 0.4020860489871767, disc_loss = 0.18093284581425703
Trained batch 360 in epoch 1, gen_loss = 0.40232366554624815, disc_loss = 0.18082672483197457
Trained batch 361 in epoch 1, gen_loss = 0.4021684104237109, disc_loss = 0.1808029086977367
Trained batch 362 in epoch 1, gen_loss = 0.40207042345987537, disc_loss = 0.18108701383433312
Trained batch 363 in epoch 1, gen_loss = 0.40210650402766007, disc_loss = 0.18103123805997381
Trained batch 364 in epoch 1, gen_loss = 0.4022309947503756, disc_loss = 0.18090253229163689
Trained batch 365 in epoch 1, gen_loss = 0.4021514693244559, disc_loss = 0.18081346025710793
Trained batch 366 in epoch 1, gen_loss = 0.4024448346052248, disc_loss = 0.18069619063937614
Trained batch 367 in epoch 1, gen_loss = 0.40234919443078665, disc_loss = 0.18056574651880353
Trained batch 368 in epoch 1, gen_loss = 0.4024723605088748, disc_loss = 0.1804688068682222
Trained batch 369 in epoch 1, gen_loss = 0.40247799133932266, disc_loss = 0.18071424507762532
Trained batch 370 in epoch 1, gen_loss = 0.40257603773530926, disc_loss = 0.1808575133685113
Trained batch 371 in epoch 1, gen_loss = 0.4024374778232267, disc_loss = 0.18084930746455588
Trained batch 372 in epoch 1, gen_loss = 0.40238119513994886, disc_loss = 0.1809789065156761
Trained batch 373 in epoch 1, gen_loss = 0.40211871609012073, disc_loss = 0.18098886404435505
Trained batch 374 in epoch 1, gen_loss = 0.4019998416900635, disc_loss = 0.1810075329716007
Trained batch 375 in epoch 1, gen_loss = 0.4017711717714655, disc_loss = 0.18101830164000313
Trained batch 376 in epoch 1, gen_loss = 0.40188767589055574, disc_loss = 0.18086976237565436
Trained batch 377 in epoch 1, gen_loss = 0.4019933246746265, disc_loss = 0.18087777650851028
Trained batch 378 in epoch 1, gen_loss = 0.40182668238013275, disc_loss = 0.18085719792216545
Trained batch 379 in epoch 1, gen_loss = 0.40203425884246824, disc_loss = 0.18069901593568685
Trained batch 380 in epoch 1, gen_loss = 0.4021235743532656, disc_loss = 0.1808746516328119
Trained batch 381 in epoch 1, gen_loss = 0.40197675655649595, disc_loss = 0.18083969747199047
Trained batch 382 in epoch 1, gen_loss = 0.40207793896254296, disc_loss = 0.18067567569614623
Trained batch 383 in epoch 1, gen_loss = 0.4021878216881305, disc_loss = 0.18082361060805852
Trained batch 384 in epoch 1, gen_loss = 0.4020158360530804, disc_loss = 0.18059006809172304
Trained batch 385 in epoch 1, gen_loss = 0.40216816753303447, disc_loss = 0.18091500766449872
Trained batch 386 in epoch 1, gen_loss = 0.4022334543001436, disc_loss = 0.1808933533646301
Trained batch 387 in epoch 1, gen_loss = 0.4020827698338892, disc_loss = 0.1808941152652476
Trained batch 388 in epoch 1, gen_loss = 0.4020681289290401, disc_loss = 0.18086976015696105
Trained batch 389 in epoch 1, gen_loss = 0.4020281532636056, disc_loss = 0.1806695653627125
Trained batch 390 in epoch 1, gen_loss = 0.4019137420465269, disc_loss = 0.18046949908394566
Trained batch 391 in epoch 1, gen_loss = 0.4019609015358954, disc_loss = 0.18030473891864246
Trained batch 392 in epoch 1, gen_loss = 0.4019206631122958, disc_loss = 0.18021269735783035
Trained batch 393 in epoch 1, gen_loss = 0.4018486558180775, disc_loss = 0.17999724217165772
Trained batch 394 in epoch 1, gen_loss = 0.40182831943789615, disc_loss = 0.1796893078668774
Trained batch 395 in epoch 1, gen_loss = 0.4019299393350428, disc_loss = 0.18045024712795787
Trained batch 396 in epoch 1, gen_loss = 0.40186281295807597, disc_loss = 0.18069909820544255
Trained batch 397 in epoch 1, gen_loss = 0.4017380384644072, disc_loss = 0.18066429780871052
Trained batch 398 in epoch 1, gen_loss = 0.40150506417255355, disc_loss = 0.18071758567605326
Trained batch 399 in epoch 1, gen_loss = 0.40144226923584936, disc_loss = 0.18075432888930665
Trained batch 400 in epoch 1, gen_loss = 0.4012632844156755, disc_loss = 0.1808324631586894
Trained batch 401 in epoch 1, gen_loss = 0.4013343496405663, disc_loss = 0.18076868614515484
Trained batch 402 in epoch 1, gen_loss = 0.4011824346209874, disc_loss = 0.18068472415939085
Trained batch 403 in epoch 1, gen_loss = 0.4012295288762244, disc_loss = 0.18079482712137449
Trained batch 404 in epoch 1, gen_loss = 0.40120018624965054, disc_loss = 0.18074350798341596
Trained batch 405 in epoch 1, gen_loss = 0.4012759419644407, disc_loss = 0.18061991112783846
Trained batch 406 in epoch 1, gen_loss = 0.4013454178188005, disc_loss = 0.18052527546214456
Trained batch 407 in epoch 1, gen_loss = 0.4012199214422235, disc_loss = 0.18029600765108697
Trained batch 408 in epoch 1, gen_loss = 0.4012070696044959, disc_loss = 0.18031846088628242
Trained batch 409 in epoch 1, gen_loss = 0.40128016210183864, disc_loss = 0.18027523810316512
Trained batch 410 in epoch 1, gen_loss = 0.4013936260755915, disc_loss = 0.18037695018687894
Trained batch 411 in epoch 1, gen_loss = 0.40153011527744314, disc_loss = 0.18086200395318708
Trained batch 412 in epoch 1, gen_loss = 0.40181341666286274, disc_loss = 0.18058489897845373
Trained batch 413 in epoch 1, gen_loss = 0.40200984737147455, disc_loss = 0.18040555452586013
Trained batch 414 in epoch 1, gen_loss = 0.4021520537066172, disc_loss = 0.18031567054834352
Trained batch 415 in epoch 1, gen_loss = 0.4022360395353574, disc_loss = 0.18021099917510022
Trained batch 416 in epoch 1, gen_loss = 0.4022809637250374, disc_loss = 0.180341728047269
Trained batch 417 in epoch 1, gen_loss = 0.40210192511526593, disc_loss = 0.18049271778831855
Trained batch 418 in epoch 1, gen_loss = 0.40221799536650393, disc_loss = 0.18036789722465033
Trained batch 419 in epoch 1, gen_loss = 0.40201826074293684, disc_loss = 0.180394138287132
Trained batch 420 in epoch 1, gen_loss = 0.4020518363230019, disc_loss = 0.1805579958554366
Trained batch 421 in epoch 1, gen_loss = 0.4020253509565552, disc_loss = 0.18050010378529888
Trained batch 422 in epoch 1, gen_loss = 0.402159097699127, disc_loss = 0.18028525939215653
Trained batch 423 in epoch 1, gen_loss = 0.40227713534292187, disc_loss = 0.1801582315282123
Trained batch 424 in epoch 1, gen_loss = 0.4021147525310516, disc_loss = 0.18030617470031277
Trained batch 425 in epoch 1, gen_loss = 0.4022100672055858, disc_loss = 0.18035738084229155
Trained batch 426 in epoch 1, gen_loss = 0.40198552803915055, disc_loss = 0.18073905566249227
Trained batch 427 in epoch 1, gen_loss = 0.4019614153097723, disc_loss = 0.18072445699118217
Trained batch 428 in epoch 1, gen_loss = 0.4019264134910557, disc_loss = 0.18083331261333815
Trained batch 429 in epoch 1, gen_loss = 0.40193508572356645, disc_loss = 0.18077835920375102
Trained batch 430 in epoch 1, gen_loss = 0.40185647808758673, disc_loss = 0.18065788250917833
Trained batch 431 in epoch 1, gen_loss = 0.40176394809451366, disc_loss = 0.18070826994867442
Trained batch 432 in epoch 1, gen_loss = 0.40160056012607337, disc_loss = 0.18073219926188985
Trained batch 433 in epoch 1, gen_loss = 0.401489049539588, disc_loss = 0.18070485413477924
Trained batch 434 in epoch 1, gen_loss = 0.40133241908303624, disc_loss = 0.18071793990702123
Trained batch 435 in epoch 1, gen_loss = 0.4012070639964637, disc_loss = 0.1807609076906474
Trained batch 436 in epoch 1, gen_loss = 0.40134456501399896, disc_loss = 0.18066356832148758
Trained batch 437 in epoch 1, gen_loss = 0.401211111376819, disc_loss = 0.1806761819558839
Trained batch 438 in epoch 1, gen_loss = 0.40098323820663745, disc_loss = 0.18169773641362752
Trained batch 439 in epoch 1, gen_loss = 0.4008625107732686, disc_loss = 0.18184338257521052
Trained batch 440 in epoch 1, gen_loss = 0.4011388083163843, disc_loss = 0.18187329106987402
Trained batch 441 in epoch 1, gen_loss = 0.401144371987468, disc_loss = 0.181882489875077
Trained batch 442 in epoch 1, gen_loss = 0.40090386101946607, disc_loss = 0.18187447240193527
Trained batch 443 in epoch 1, gen_loss = 0.40076280304708994, disc_loss = 0.18200769531960087
Trained batch 444 in epoch 1, gen_loss = 0.4006772687595882, disc_loss = 0.1819649504623219
Trained batch 445 in epoch 1, gen_loss = 0.4006034282825453, disc_loss = 0.1819652594738711
Trained batch 446 in epoch 1, gen_loss = 0.4005363902922978, disc_loss = 0.1819025805278346
Trained batch 447 in epoch 1, gen_loss = 0.4005269656356956, disc_loss = 0.18190081548735698
Trained batch 448 in epoch 1, gen_loss = 0.4004337542704856, disc_loss = 0.18191558585392273
Trained batch 449 in epoch 1, gen_loss = 0.4004530702034632, disc_loss = 0.18193972231406305
Trained batch 450 in epoch 1, gen_loss = 0.40037229161569127, disc_loss = 0.18184552771016593
Trained batch 451 in epoch 1, gen_loss = 0.40027452398717933, disc_loss = 0.18184925195250035
Trained batch 452 in epoch 1, gen_loss = 0.40038745371711176, disc_loss = 0.18185938083696246
Trained batch 453 in epoch 1, gen_loss = 0.40018857812041225, disc_loss = 0.18184566154608314
Trained batch 454 in epoch 1, gen_loss = 0.40040612391063146, disc_loss = 0.1816452483042747
Trained batch 455 in epoch 1, gen_loss = 0.4002883763689744, disc_loss = 0.18145955992625667
Trained batch 456 in epoch 1, gen_loss = 0.4002598179769203, disc_loss = 0.18123498599552418
Trained batch 457 in epoch 1, gen_loss = 0.40022329576150817, disc_loss = 0.1812497595524391
Testing Epoch 1

Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4032520651817322, disc_loss = 0.18081150949001312
Trained batch 1 in epoch 2, gen_loss = 0.37288787961006165, disc_loss = 0.13919277489185333
Trained batch 2 in epoch 2, gen_loss = 0.4006146391232808, disc_loss = 0.11156712099909782
Trained batch 3 in epoch 2, gen_loss = 0.39245566725730896, disc_loss = 0.15258740726858377
Trained batch 4 in epoch 2, gen_loss = 0.4078329622745514, disc_loss = 0.15214952304959298
Trained batch 5 in epoch 2, gen_loss = 0.4111162672440211, disc_loss = 0.1425399985164404
Trained batch 6 in epoch 2, gen_loss = 0.4058293955666678, disc_loss = 0.1458801802779947
Trained batch 7 in epoch 2, gen_loss = 0.40846411883831024, disc_loss = 0.14880672143772244
Trained batch 8 in epoch 2, gen_loss = 0.42138177818722194, disc_loss = 0.14792979632814726
Trained batch 9 in epoch 2, gen_loss = 0.42980443239212035, disc_loss = 0.1378129582852125
Trained batch 10 in epoch 2, gen_loss = 0.4265610927885229, disc_loss = 0.1340137581256303
Trained batch 11 in epoch 2, gen_loss = 0.4168668215473493, disc_loss = 0.13995934991786876
Trained batch 12 in epoch 2, gen_loss = 0.4165437083977919, disc_loss = 0.15496168199640054
Trained batch 13 in epoch 2, gen_loss = 0.4168665749686105, disc_loss = 0.15703860537282058
Trained batch 14 in epoch 2, gen_loss = 0.4126112838586172, disc_loss = 0.15895936066905658
Trained batch 15 in epoch 2, gen_loss = 0.41156984120607376, disc_loss = 0.15718634403310716
Trained batch 16 in epoch 2, gen_loss = 0.4105694311506608, disc_loss = 0.15956955074387438
Trained batch 17 in epoch 2, gen_loss = 0.4138045658667882, disc_loss = 0.15886230828861395
Trained batch 18 in epoch 2, gen_loss = 0.4110618845412606, disc_loss = 0.1590321469855936
Trained batch 19 in epoch 2, gen_loss = 0.41079741567373274, disc_loss = 0.16038680654019116
Trained batch 20 in epoch 2, gen_loss = 0.4050604544934772, disc_loss = 0.1601417176425457
Trained batch 21 in epoch 2, gen_loss = 0.40258614447983826, disc_loss = 0.1617916305972771
Trained batch 22 in epoch 2, gen_loss = 0.40473670156105707, disc_loss = 0.16102701798081398
Trained batch 23 in epoch 2, gen_loss = 0.40761850277582806, disc_loss = 0.1619288659033676
Trained batch 24 in epoch 2, gen_loss = 0.40814252495765685, disc_loss = 0.16120065197348596
Trained batch 25 in epoch 2, gen_loss = 0.40450428884762984, disc_loss = 0.16057493351399899
Trained batch 26 in epoch 2, gen_loss = 0.40923541011633696, disc_loss = 0.158991783167477
Trained batch 27 in epoch 2, gen_loss = 0.4135962054133415, disc_loss = 0.15771683717944793
Trained batch 28 in epoch 2, gen_loss = 0.4147636366301569, disc_loss = 0.15529191994975353
Trained batch 29 in epoch 2, gen_loss = 0.41375353932380676, disc_loss = 0.15340265395740668
Trained batch 30 in epoch 2, gen_loss = 0.4118787867407645, disc_loss = 0.15908591653550824
Trained batch 31 in epoch 2, gen_loss = 0.41344326362013817, disc_loss = 0.15855720464605838
Trained batch 32 in epoch 2, gen_loss = 0.4146049383914832, disc_loss = 0.15729971105853716
Trained batch 33 in epoch 2, gen_loss = 0.41254378679920645, disc_loss = 0.16097716384512537
Trained batch 34 in epoch 2, gen_loss = 0.41098781909261434, disc_loss = 0.16058855748602321
Trained batch 35 in epoch 2, gen_loss = 0.40916061649719876, disc_loss = 0.15920511829770273
Trained batch 36 in epoch 2, gen_loss = 0.40794316256368485, disc_loss = 0.15798741488440618
Trained batch 37 in epoch 2, gen_loss = 0.407366123638655, disc_loss = 0.160677487814897
Trained batch 38 in epoch 2, gen_loss = 0.4055013809448633, disc_loss = 0.1636794208525083
Trained batch 39 in epoch 2, gen_loss = 0.4057035520672798, disc_loss = 0.16073507433757186
Trained batch 40 in epoch 2, gen_loss = 0.4055040965719921, disc_loss = 0.16378535357553783
Trained batch 41 in epoch 2, gen_loss = 0.4067527751127879, disc_loss = 0.16448255619477659
Trained batch 42 in epoch 2, gen_loss = 0.4063110802062722, disc_loss = 0.16315019104716388
Trained batch 43 in epoch 2, gen_loss = 0.40614754977551376, disc_loss = 0.16065677483989435
Trained batch 44 in epoch 2, gen_loss = 0.4048133499092526, disc_loss = 0.16283967453572484
Trained batch 45 in epoch 2, gen_loss = 0.4045131932134214, disc_loss = 0.16183968285179656
Trained batch 46 in epoch 2, gen_loss = 0.4067591187801767, disc_loss = 0.16283649689656624
Trained batch 47 in epoch 2, gen_loss = 0.4062443785369396, disc_loss = 0.16257955793601772
Trained batch 48 in epoch 2, gen_loss = 0.40590942149259607, disc_loss = 0.16387176855790372
Trained batch 49 in epoch 2, gen_loss = 0.407667818069458, disc_loss = 0.16356282152235507
Trained batch 50 in epoch 2, gen_loss = 0.4082644686979406, disc_loss = 0.16379919801564777
Trained batch 51 in epoch 2, gen_loss = 0.4066518069459842, disc_loss = 0.16200077469245747
Trained batch 52 in epoch 2, gen_loss = 0.40660177255576513, disc_loss = 0.16328839528954253
Trained batch 53 in epoch 2, gen_loss = 0.4057210154003567, disc_loss = 0.16374110423580365
Trained batch 54 in epoch 2, gen_loss = 0.40539024634794757, disc_loss = 0.16386205195025963
Trained batch 55 in epoch 2, gen_loss = 0.40621355708156315, disc_loss = 0.16345254192128778
Trained batch 56 in epoch 2, gen_loss = 0.4060394622777638, disc_loss = 0.1641091120739778
Trained batch 57 in epoch 2, gen_loss = 0.4046276679326748, disc_loss = 0.163522701003942
Trained batch 58 in epoch 2, gen_loss = 0.40598161190243093, disc_loss = 0.1635620555508945
Trained batch 59 in epoch 2, gen_loss = 0.4072595397631327, disc_loss = 0.16474318994830053
Trained batch 60 in epoch 2, gen_loss = 0.4070814735576755, disc_loss = 0.16483080771858574
Trained batch 61 in epoch 2, gen_loss = 0.405222132321327, disc_loss = 0.16569084211462928
Trained batch 62 in epoch 2, gen_loss = 0.4034656641029176, disc_loss = 0.16547650707856057
Trained batch 63 in epoch 2, gen_loss = 0.4053211729042232, disc_loss = 0.16447547363350168
Trained batch 64 in epoch 2, gen_loss = 0.40680831808310286, disc_loss = 0.16403270782186435
Trained batch 65 in epoch 2, gen_loss = 0.4064329605210911, disc_loss = 0.16366184621372007
Trained batch 66 in epoch 2, gen_loss = 0.4066106401272674, disc_loss = 0.1630934317276549
Trained batch 67 in epoch 2, gen_loss = 0.405723375870901, disc_loss = 0.16267108068089275
Trained batch 68 in epoch 2, gen_loss = 0.40468265915262525, disc_loss = 0.1647710357995137
Trained batch 69 in epoch 2, gen_loss = 0.4046610087156296, disc_loss = 0.16505091919430664
Trained batch 70 in epoch 2, gen_loss = 0.4034126321194877, disc_loss = 0.16385234498851736
Trained batch 71 in epoch 2, gen_loss = 0.40404458302590585, disc_loss = 0.16429295789243448
Trained batch 72 in epoch 2, gen_loss = 0.4040694383725728, disc_loss = 0.16406638945822846
Trained batch 73 in epoch 2, gen_loss = 0.4036306742880795, disc_loss = 0.16307862269113194
Trained batch 74 in epoch 2, gen_loss = 0.4046119956175486, disc_loss = 0.16261009578903515
Trained batch 75 in epoch 2, gen_loss = 0.40387884252949763, disc_loss = 0.1622335762275677
Trained batch 76 in epoch 2, gen_loss = 0.40258354335636287, disc_loss = 0.16221512936345941
Trained batch 77 in epoch 2, gen_loss = 0.4021126131216685, disc_loss = 0.16204145154318747
Trained batch 78 in epoch 2, gen_loss = 0.4029660447488857, disc_loss = 0.16163595629077923
Trained batch 79 in epoch 2, gen_loss = 0.4029070671647787, disc_loss = 0.16159468689002096
Trained batch 80 in epoch 2, gen_loss = 0.4020550927998107, disc_loss = 0.16176658303097444
Trained batch 81 in epoch 2, gen_loss = 0.40271569788455963, disc_loss = 0.16148600695518459
Trained batch 82 in epoch 2, gen_loss = 0.4034976434994893, disc_loss = 0.1624285609697003
Trained batch 83 in epoch 2, gen_loss = 0.40382828208662214, disc_loss = 0.16300076552267587
Trained batch 84 in epoch 2, gen_loss = 0.40345122884301576, disc_loss = 0.162933101592695
Trained batch 85 in epoch 2, gen_loss = 0.40276958845382516, disc_loss = 0.16294899916406289
Trained batch 86 in epoch 2, gen_loss = 0.40218716106195557, disc_loss = 0.16404615620943322
Trained batch 87 in epoch 2, gen_loss = 0.4030926230956208, disc_loss = 0.1640479783527553
Trained batch 88 in epoch 2, gen_loss = 0.4028629824686586, disc_loss = 0.16375596289721767
Trained batch 89 in epoch 2, gen_loss = 0.40280413097805445, disc_loss = 0.16356736309826375
Trained batch 90 in epoch 2, gen_loss = 0.4027732771176558, disc_loss = 0.16346937503952247
Trained batch 91 in epoch 2, gen_loss = 0.4023578390479088, disc_loss = 0.16378680734044831
Trained batch 92 in epoch 2, gen_loss = 0.4022994759262249, disc_loss = 0.16266678534047577
Trained batch 93 in epoch 2, gen_loss = 0.4030147743351916, disc_loss = 0.16310142808930672
Trained batch 94 in epoch 2, gen_loss = 0.40366149795682804, disc_loss = 0.1625018752327091
Trained batch 95 in epoch 2, gen_loss = 0.403721553273499, disc_loss = 0.1619576421023036
Trained batch 96 in epoch 2, gen_loss = 0.40391772063737064, disc_loss = 0.16180492465182678
Trained batch 97 in epoch 2, gen_loss = 0.4047029599243281, disc_loss = 0.1617570302392147
Trained batch 98 in epoch 2, gen_loss = 0.40480605399969855, disc_loss = 0.16199350586593753
Trained batch 99 in epoch 2, gen_loss = 0.4045680570602417, disc_loss = 0.16223349306732415
Trained batch 100 in epoch 2, gen_loss = 0.4043003775105618, disc_loss = 0.16204360647514315
Trained batch 101 in epoch 2, gen_loss = 0.40398942050980585, disc_loss = 0.16163166564907513
Trained batch 102 in epoch 2, gen_loss = 0.4033048427799373, disc_loss = 0.16154851174904306
Trained batch 103 in epoch 2, gen_loss = 0.40337969391391826, disc_loss = 0.16179649012449843
Trained batch 104 in epoch 2, gen_loss = 0.4028439124425252, disc_loss = 0.16208537955369268
Trained batch 105 in epoch 2, gen_loss = 0.40221967337266457, disc_loss = 0.1619896565054385
Trained batch 106 in epoch 2, gen_loss = 0.4022682331432806, disc_loss = 0.16264702348369303
Trained batch 107 in epoch 2, gen_loss = 0.40199441076428805, disc_loss = 0.16298863357277932
Trained batch 108 in epoch 2, gen_loss = 0.40233664966504507, disc_loss = 0.16332308397790707
Trained batch 109 in epoch 2, gen_loss = 0.4024106868288734, disc_loss = 0.16343047927049073
Trained batch 110 in epoch 2, gen_loss = 0.402421288930618, disc_loss = 0.16317960415203292
Trained batch 111 in epoch 2, gen_loss = 0.40235379870448795, disc_loss = 0.16317573691984372
Trained batch 112 in epoch 2, gen_loss = 0.4016957217085678, disc_loss = 0.16402371923348544
Trained batch 113 in epoch 2, gen_loss = 0.40140182250424433, disc_loss = 0.16484494007339603
Trained batch 114 in epoch 2, gen_loss = 0.40062367890192113, disc_loss = 0.16523179343861083
Trained batch 115 in epoch 2, gen_loss = 0.39987174318782215, disc_loss = 0.1654686856822207
Trained batch 116 in epoch 2, gen_loss = 0.40002974689516246, disc_loss = 0.16503924153681493
Trained batch 117 in epoch 2, gen_loss = 0.40059649590718543, disc_loss = 0.1645852582750179
Trained batch 118 in epoch 2, gen_loss = 0.40083070687887046, disc_loss = 0.16431207394524783
Trained batch 119 in epoch 2, gen_loss = 0.40112694079677264, disc_loss = 0.16470744886125127
Trained batch 120 in epoch 2, gen_loss = 0.4015053993414256, disc_loss = 0.1646880300884897
Trained batch 121 in epoch 2, gen_loss = 0.4013651321168806, disc_loss = 0.1658447084673604
Trained batch 122 in epoch 2, gen_loss = 0.40094453920193807, disc_loss = 0.16580446576321028
Trained batch 123 in epoch 2, gen_loss = 0.40107160758587623, disc_loss = 0.16546169647406186
Trained batch 124 in epoch 2, gen_loss = 0.40135603070259096, disc_loss = 0.16632019475102425
Trained batch 125 in epoch 2, gen_loss = 0.401162666224298, disc_loss = 0.16660987505955355
Trained batch 126 in epoch 2, gen_loss = 0.40056480432119895, disc_loss = 0.1668502756753775
Trained batch 127 in epoch 2, gen_loss = 0.4003176607657224, disc_loss = 0.16648792239720933
Trained batch 128 in epoch 2, gen_loss = 0.4003987802091495, disc_loss = 0.16655447983811067
Trained batch 129 in epoch 2, gen_loss = 0.4007601075447523, disc_loss = 0.16648308929915612
Trained batch 130 in epoch 2, gen_loss = 0.4005014716668893, disc_loss = 0.16624090004399533
Trained batch 131 in epoch 2, gen_loss = 0.4000684153853041, disc_loss = 0.1660741422833367
Trained batch 132 in epoch 2, gen_loss = 0.40015487249632525, disc_loss = 0.16584562244159834
Trained batch 133 in epoch 2, gen_loss = 0.39960218387753216, disc_loss = 0.1654228726818935
Trained batch 134 in epoch 2, gen_loss = 0.3995084009788655, disc_loss = 0.16474382024672296
Trained batch 135 in epoch 2, gen_loss = 0.3995976792100598, disc_loss = 0.16420464395709775
Trained batch 136 in epoch 2, gen_loss = 0.40017672024504114, disc_loss = 0.16403753797176981
Trained batch 137 in epoch 2, gen_loss = 0.4003186135188393, disc_loss = 0.16395501158051734
Trained batch 138 in epoch 2, gen_loss = 0.4000248113553301, disc_loss = 0.1636293369928281
Trained batch 139 in epoch 2, gen_loss = 0.4003932448370116, disc_loss = 0.1641213239569749
Trained batch 140 in epoch 2, gen_loss = 0.40056090152010004, disc_loss = 0.16488096659593549
Trained batch 141 in epoch 2, gen_loss = 0.4007220918863592, disc_loss = 0.16421464151165016
Trained batch 142 in epoch 2, gen_loss = 0.40089678993591893, disc_loss = 0.1634303801595331
Trained batch 143 in epoch 2, gen_loss = 0.40089483331474995, disc_loss = 0.1630797632711215
Trained batch 144 in epoch 2, gen_loss = 0.40096804931246, disc_loss = 0.16283435988528974
Trained batch 145 in epoch 2, gen_loss = 0.40093705139748037, disc_loss = 0.1624999020044526
Trained batch 146 in epoch 2, gen_loss = 0.40090686589682184, disc_loss = 0.16183396629026148
Trained batch 147 in epoch 2, gen_loss = 0.40054131138163646, disc_loss = 0.1619873967374096
Trained batch 148 in epoch 2, gen_loss = 0.4002881844171742, disc_loss = 0.16224393821102662
Trained batch 149 in epoch 2, gen_loss = 0.40068385859330496, disc_loss = 0.16279076946278412
Trained batch 150 in epoch 2, gen_loss = 0.40078184580960813, disc_loss = 0.16250574828082362
Trained batch 151 in epoch 2, gen_loss = 0.4009938110646449, disc_loss = 0.16289930959771337
Trained batch 152 in epoch 2, gen_loss = 0.4016250800463109, disc_loss = 0.16299457451194718
Trained batch 153 in epoch 2, gen_loss = 0.40121841933820157, disc_loss = 0.1628889221117481
Trained batch 154 in epoch 2, gen_loss = 0.400484009135154, disc_loss = 0.16350444865322883
Trained batch 155 in epoch 2, gen_loss = 0.40072390131461316, disc_loss = 0.16366044587145248
Trained batch 156 in epoch 2, gen_loss = 0.4007161844308209, disc_loss = 0.16397744523966387
Trained batch 157 in epoch 2, gen_loss = 0.4006841697647602, disc_loss = 0.1643661784267501
Trained batch 158 in epoch 2, gen_loss = 0.3998800176869398, disc_loss = 0.16477511647456097
Trained batch 159 in epoch 2, gen_loss = 0.39973918776959183, disc_loss = 0.16462104360107332
Trained batch 160 in epoch 2, gen_loss = 0.4005841348112, disc_loss = 0.16423221008840555
Trained batch 161 in epoch 2, gen_loss = 0.400487212487209, disc_loss = 0.1644291875217064
Trained batch 162 in epoch 2, gen_loss = 0.4006934736403951, disc_loss = 0.16418539744121896
Trained batch 163 in epoch 2, gen_loss = 0.40069150143280263, disc_loss = 0.16399602626064202
Trained batch 164 in epoch 2, gen_loss = 0.4011124795133417, disc_loss = 0.16353511528083772
Trained batch 165 in epoch 2, gen_loss = 0.40153676002140504, disc_loss = 0.1633556931986507
Trained batch 166 in epoch 2, gen_loss = 0.4011498263139211, disc_loss = 0.16356568134384242
Trained batch 167 in epoch 2, gen_loss = 0.40127920057801975, disc_loss = 0.16393276142133845
Trained batch 168 in epoch 2, gen_loss = 0.4022855922667938, disc_loss = 0.16384455189108849
Trained batch 169 in epoch 2, gen_loss = 0.4019255899331149, disc_loss = 0.16393366821986788
Trained batch 170 in epoch 2, gen_loss = 0.4014496118353124, disc_loss = 0.16447880949106133
Trained batch 171 in epoch 2, gen_loss = 0.4015485417357711, disc_loss = 0.16467531517061385
Trained batch 172 in epoch 2, gen_loss = 0.4013495891424962, disc_loss = 0.16562932288284934
Trained batch 173 in epoch 2, gen_loss = 0.4010661032008029, disc_loss = 0.16605448412398496
Trained batch 174 in epoch 2, gen_loss = 0.40105859756469725, disc_loss = 0.1661800575043474
Trained batch 175 in epoch 2, gen_loss = 0.4007157517427748, disc_loss = 0.16647860558110883
Trained batch 176 in epoch 2, gen_loss = 0.401090572782829, disc_loss = 0.16642114517968254
Trained batch 177 in epoch 2, gen_loss = 0.4010848178622428, disc_loss = 0.16646692171441704
Trained batch 178 in epoch 2, gen_loss = 0.40107028727424876, disc_loss = 0.16657621964978772
Trained batch 179 in epoch 2, gen_loss = 0.40093676646550497, disc_loss = 0.1678051805951529
Trained batch 180 in epoch 2, gen_loss = 0.4006470239294168, disc_loss = 0.16800725392132834
Trained batch 181 in epoch 2, gen_loss = 0.4010511890544996, disc_loss = 0.16756474126416904
Trained batch 182 in epoch 2, gen_loss = 0.40090839198378264, disc_loss = 0.1674482713102317
Trained batch 183 in epoch 2, gen_loss = 0.4006548778194448, disc_loss = 0.16715888531230713
Trained batch 184 in epoch 2, gen_loss = 0.40035731953543585, disc_loss = 0.16714571116341126
Trained batch 185 in epoch 2, gen_loss = 0.40038993794430966, disc_loss = 0.16759635121511515
Trained batch 186 in epoch 2, gen_loss = 0.4006241139243631, disc_loss = 0.16748500912186295
Trained batch 187 in epoch 2, gen_loss = 0.4008641301634464, disc_loss = 0.16722089739793794
Trained batch 188 in epoch 2, gen_loss = 0.40039523032607227, disc_loss = 0.16722590919761432
Trained batch 189 in epoch 2, gen_loss = 0.40017893047709213, disc_loss = 0.16783942570419688
Trained batch 190 in epoch 2, gen_loss = 0.4007369864985581, disc_loss = 0.16867750139994772
Trained batch 191 in epoch 2, gen_loss = 0.4012010994677742, disc_loss = 0.16818862507352605
Trained batch 192 in epoch 2, gen_loss = 0.40098864241585214, disc_loss = 0.16794840750221762
Trained batch 193 in epoch 2, gen_loss = 0.4008630678518531, disc_loss = 0.16812966116848066
Trained batch 194 in epoch 2, gen_loss = 0.4009684088902596, disc_loss = 0.167757504624434
Trained batch 195 in epoch 2, gen_loss = 0.4006190137291441, disc_loss = 0.16768231697152464
Trained batch 196 in epoch 2, gen_loss = 0.4002488665471827, disc_loss = 0.1679268001110723
Trained batch 197 in epoch 2, gen_loss = 0.4001742578817136, disc_loss = 0.16799843106230702
Trained batch 198 in epoch 2, gen_loss = 0.40009238896657473, disc_loss = 0.1677221725671435
Trained batch 199 in epoch 2, gen_loss = 0.40039540246129035, disc_loss = 0.16769312838092446
Trained batch 200 in epoch 2, gen_loss = 0.39992252614960744, disc_loss = 0.16785652989252883
Trained batch 201 in epoch 2, gen_loss = 0.3996266322855902, disc_loss = 0.16795608882635538
Trained batch 202 in epoch 2, gen_loss = 0.3998596264517366, disc_loss = 0.16826019228752612
Trained batch 203 in epoch 2, gen_loss = 0.4003636911511421, disc_loss = 0.16946355715467065
Trained batch 204 in epoch 2, gen_loss = 0.4003347488438211, disc_loss = 0.16943870457570728
Trained batch 205 in epoch 2, gen_loss = 0.40000034680644286, disc_loss = 0.1696520372682694
Trained batch 206 in epoch 2, gen_loss = 0.3999125318250794, disc_loss = 0.16969134663974028
Trained batch 207 in epoch 2, gen_loss = 0.3995483252578057, disc_loss = 0.16972021294686085
Trained batch 208 in epoch 2, gen_loss = 0.3995432574212836, disc_loss = 0.169584834992743
Trained batch 209 in epoch 2, gen_loss = 0.39949656753312973, disc_loss = 0.1697811201392185
Trained batch 210 in epoch 2, gen_loss = 0.3986565181853082, disc_loss = 0.17000586636611636
Trained batch 211 in epoch 2, gen_loss = 0.39915728730694305, disc_loss = 0.1696823557909086
Trained batch 212 in epoch 2, gen_loss = 0.3988211684523614, disc_loss = 0.16977594374840807
Trained batch 213 in epoch 2, gen_loss = 0.3988890489824464, disc_loss = 0.1694731622690631
Trained batch 214 in epoch 2, gen_loss = 0.39887569789276567, disc_loss = 0.16927465423941612
Trained batch 215 in epoch 2, gen_loss = 0.3987965449276898, disc_loss = 0.16938556649687667
Trained batch 216 in epoch 2, gen_loss = 0.39910030852539746, disc_loss = 0.16957764095768402
Trained batch 217 in epoch 2, gen_loss = 0.39924132297618675, disc_loss = 0.16895533201002746
Trained batch 218 in epoch 2, gen_loss = 0.3989363165070477, disc_loss = 0.16953303421673166
Trained batch 219 in epoch 2, gen_loss = 0.3987248699096116, disc_loss = 0.16998258387161927
Trained batch 220 in epoch 2, gen_loss = 0.3986811513140191, disc_loss = 0.17000495812674454
Trained batch 221 in epoch 2, gen_loss = 0.3986668284009169, disc_loss = 0.16980238512225515
Trained batch 222 in epoch 2, gen_loss = 0.3985415295501461, disc_loss = 0.16960491779606973
Trained batch 223 in epoch 2, gen_loss = 0.39896119592179147, disc_loss = 0.16930877771561167
Trained batch 224 in epoch 2, gen_loss = 0.3988501622279485, disc_loss = 0.16890145965748363
Trained batch 225 in epoch 2, gen_loss = 0.3991303310061978, disc_loss = 0.16838402978548433
Trained batch 226 in epoch 2, gen_loss = 0.39927924447385227, disc_loss = 0.16804988729861864
Trained batch 227 in epoch 2, gen_loss = 0.39975142276339365, disc_loss = 0.1683622452414088
Trained batch 228 in epoch 2, gen_loss = 0.399593307006307, disc_loss = 0.1678648641471259
Trained batch 229 in epoch 2, gen_loss = 0.39936538565417995, disc_loss = 0.16830249529169952
Trained batch 230 in epoch 2, gen_loss = 0.39917081433199186, disc_loss = 0.16818738625550167
Trained batch 231 in epoch 2, gen_loss = 0.39962745554231366, disc_loss = 0.16885654766369482
Trained batch 232 in epoch 2, gen_loss = 0.39963563285416287, disc_loss = 0.16834141896006374
Trained batch 233 in epoch 2, gen_loss = 0.3992932252267487, disc_loss = 0.1680337009457951
Trained batch 234 in epoch 2, gen_loss = 0.39882714463041186, disc_loss = 0.16763290258798194
Trained batch 235 in epoch 2, gen_loss = 0.3989250096097841, disc_loss = 0.16788262005705953
Trained batch 236 in epoch 2, gen_loss = 0.3991507274817817, disc_loss = 0.16787761251760436
Trained batch 237 in epoch 2, gen_loss = 0.3989988414555037, disc_loss = 0.16793320756875166
Trained batch 238 in epoch 2, gen_loss = 0.3990732279906213, disc_loss = 0.1677735319758559
Trained batch 239 in epoch 2, gen_loss = 0.3986647753044963, disc_loss = 0.16809077284609278
Trained batch 240 in epoch 2, gen_loss = 0.3986690592840005, disc_loss = 0.1679412388393493
Trained batch 241 in epoch 2, gen_loss = 0.3985651723486333, disc_loss = 0.168065132958091
Trained batch 242 in epoch 2, gen_loss = 0.3985515383413299, disc_loss = 0.16776180485025846
Trained batch 243 in epoch 2, gen_loss = 0.39858066516577223, disc_loss = 0.16748507259810558
Trained batch 244 in epoch 2, gen_loss = 0.39859921244942415, disc_loss = 0.16720614901610784
Trained batch 245 in epoch 2, gen_loss = 0.39865322332314357, disc_loss = 0.16703784435502883
Trained batch 246 in epoch 2, gen_loss = 0.39865291028128946, disc_loss = 0.1670618054837833
Trained batch 247 in epoch 2, gen_loss = 0.3983728502907099, disc_loss = 0.16690455076675262
Trained batch 248 in epoch 2, gen_loss = 0.3978989650327039, disc_loss = 0.16690923351360612
Trained batch 249 in epoch 2, gen_loss = 0.3978970895409584, disc_loss = 0.166668338984251
Trained batch 250 in epoch 2, gen_loss = 0.39806036864856326, disc_loss = 0.16681146304089708
Trained batch 251 in epoch 2, gen_loss = 0.3977668632472318, disc_loss = 0.1669061157024569
Trained batch 252 in epoch 2, gen_loss = 0.3978707928784751, disc_loss = 0.1666136800418258
Trained batch 253 in epoch 2, gen_loss = 0.39793322164946654, disc_loss = 0.16796914675808328
Trained batch 254 in epoch 2, gen_loss = 0.39780788743028456, disc_loss = 0.167960797922284
Trained batch 255 in epoch 2, gen_loss = 0.3976659088511951, disc_loss = 0.16771211472223513
Trained batch 256 in epoch 2, gen_loss = 0.39754424896453605, disc_loss = 0.1678014062200075
Trained batch 257 in epoch 2, gen_loss = 0.3973236409153125, disc_loss = 0.16798938935001692
Trained batch 258 in epoch 2, gen_loss = 0.397444428681867, disc_loss = 0.16805741003926655
Trained batch 259 in epoch 2, gen_loss = 0.39740135984925123, disc_loss = 0.16796534637419078
Trained batch 260 in epoch 2, gen_loss = 0.3975532584149262, disc_loss = 0.1677633976685133
Trained batch 261 in epoch 2, gen_loss = 0.39748451142138197, disc_loss = 0.1677645751424418
Trained batch 262 in epoch 2, gen_loss = 0.39745312719517334, disc_loss = 0.1677578659905227
Trained batch 263 in epoch 2, gen_loss = 0.3974432559740363, disc_loss = 0.1675592181696133
Trained batch 264 in epoch 2, gen_loss = 0.3975133497197673, disc_loss = 0.1675971802113191
Trained batch 265 in epoch 2, gen_loss = 0.3975709216823255, disc_loss = 0.16760812806231634
Trained batch 266 in epoch 2, gen_loss = 0.3973997220229567, disc_loss = 0.16749316928315253
Trained batch 267 in epoch 2, gen_loss = 0.3973846103606829, disc_loss = 0.16751043492955947
Trained batch 268 in epoch 2, gen_loss = 0.39745038398801175, disc_loss = 0.16764709635959682
Trained batch 269 in epoch 2, gen_loss = 0.3976988661620352, disc_loss = 0.16724924530695987
Trained batch 270 in epoch 2, gen_loss = 0.39754304944149244, disc_loss = 0.16741789121359477
Trained batch 271 in epoch 2, gen_loss = 0.3977564418250147, disc_loss = 0.1680626379161635
Trained batch 272 in epoch 2, gen_loss = 0.39753410607685535, disc_loss = 0.16816224045915046
Trained batch 273 in epoch 2, gen_loss = 0.39768722767594955, disc_loss = 0.16795027563280432
Trained batch 274 in epoch 2, gen_loss = 0.3979449409246445, disc_loss = 0.1680767746676098
Trained batch 275 in epoch 2, gen_loss = 0.39782441823162895, disc_loss = 0.1677226611831482
Trained batch 276 in epoch 2, gen_loss = 0.39806790230291417, disc_loss = 0.1684590825266356
Trained batch 277 in epoch 2, gen_loss = 0.3984673187779866, disc_loss = 0.16925369661381776
Trained batch 278 in epoch 2, gen_loss = 0.39853189458342864, disc_loss = 0.16917603665889377
Trained batch 279 in epoch 2, gen_loss = 0.3984121038977589, disc_loss = 0.1696428405653153
Trained batch 280 in epoch 2, gen_loss = 0.39848490303309364, disc_loss = 0.16954988641564955
Trained batch 281 in epoch 2, gen_loss = 0.39864119078884735, disc_loss = 0.1697991746907116
Trained batch 282 in epoch 2, gen_loss = 0.39850112916934616, disc_loss = 0.16966761230053412
Trained batch 283 in epoch 2, gen_loss = 0.3982667226711629, disc_loss = 0.16973570164975146
Trained batch 284 in epoch 2, gen_loss = 0.39841363518907313, disc_loss = 0.16975612627309666
Trained batch 285 in epoch 2, gen_loss = 0.3986178918422519, disc_loss = 0.16979485820536014
Trained batch 286 in epoch 2, gen_loss = 0.3986599269332786, disc_loss = 0.16962416249389017
Trained batch 287 in epoch 2, gen_loss = 0.3988777570322984, disc_loss = 0.1696707014667077
Trained batch 288 in epoch 2, gen_loss = 0.3986526269298111, disc_loss = 0.1697744545381787
Trained batch 289 in epoch 2, gen_loss = 0.398955619900391, disc_loss = 0.16961273317193162
Trained batch 290 in epoch 2, gen_loss = 0.3987442379452519, disc_loss = 0.16961927094922444
Trained batch 291 in epoch 2, gen_loss = 0.39875006323603734, disc_loss = 0.1694833835051076
Trained batch 292 in epoch 2, gen_loss = 0.39888960016262004, disc_loss = 0.16919881489394875
Trained batch 293 in epoch 2, gen_loss = 0.39869902870890234, disc_loss = 0.1692888625979829
Trained batch 294 in epoch 2, gen_loss = 0.398412838679249, disc_loss = 0.16952859024375172
Trained batch 295 in epoch 2, gen_loss = 0.39857177874325095, disc_loss = 0.16931225774759376
Trained batch 296 in epoch 2, gen_loss = 0.39846104699553864, disc_loss = 0.16936443061238587
Trained batch 297 in epoch 2, gen_loss = 0.3981592295653868, disc_loss = 0.1694102120529485
Trained batch 298 in epoch 2, gen_loss = 0.3978183709558436, disc_loss = 0.1694022685438893
Trained batch 299 in epoch 2, gen_loss = 0.3980563597381115, disc_loss = 0.16935408435761928
Trained batch 300 in epoch 2, gen_loss = 0.39813013444113177, disc_loss = 0.16943525636810006
Trained batch 301 in epoch 2, gen_loss = 0.39775296882880445, disc_loss = 0.16971456276758617
Trained batch 302 in epoch 2, gen_loss = 0.3976922683884995, disc_loss = 0.16975494503679842
Trained batch 303 in epoch 2, gen_loss = 0.3978962586016247, disc_loss = 0.1700448162706667
Trained batch 304 in epoch 2, gen_loss = 0.3977515864079116, disc_loss = 0.17045458254755522
Trained batch 305 in epoch 2, gen_loss = 0.3977309976235714, disc_loss = 0.170320436772373
Trained batch 306 in epoch 2, gen_loss = 0.39764318991367514, disc_loss = 0.170336672823864
Trained batch 307 in epoch 2, gen_loss = 0.39771429947637893, disc_loss = 0.17012271152010985
Trained batch 308 in epoch 2, gen_loss = 0.39750829054506853, disc_loss = 0.17013968611708738
Trained batch 309 in epoch 2, gen_loss = 0.39741620685785045, disc_loss = 0.17017999803346973
Trained batch 310 in epoch 2, gen_loss = 0.39749104306820504, disc_loss = 0.16992788273134415
Trained batch 311 in epoch 2, gen_loss = 0.3974786380258126, disc_loss = 0.16979688346290436
Trained batch 312 in epoch 2, gen_loss = 0.3973950167147877, disc_loss = 0.1695933506464044
Trained batch 313 in epoch 2, gen_loss = 0.3971885122406255, disc_loss = 0.169325744982358
Trained batch 314 in epoch 2, gen_loss = 0.3973880106967593, disc_loss = 0.16917196805514986
Trained batch 315 in epoch 2, gen_loss = 0.39755028236327294, disc_loss = 0.16916018498094776
Trained batch 316 in epoch 2, gen_loss = 0.3976262247054735, disc_loss = 0.16920228974676282
Trained batch 317 in epoch 2, gen_loss = 0.3975241432118716, disc_loss = 0.16920546878058956
Trained batch 318 in epoch 2, gen_loss = 0.3970777011683742, disc_loss = 0.16939031591983425
Trained batch 319 in epoch 2, gen_loss = 0.3969671574886888, disc_loss = 0.16926610870286823
Trained batch 320 in epoch 2, gen_loss = 0.39673835489423104, disc_loss = 0.16922146963924634
Trained batch 321 in epoch 2, gen_loss = 0.3964877747323202, disc_loss = 0.16944014443003613
Trained batch 322 in epoch 2, gen_loss = 0.39662094792529895, disc_loss = 0.16937569235869607
Trained batch 323 in epoch 2, gen_loss = 0.3965313358715287, disc_loss = 0.16934265605645415
Trained batch 324 in epoch 2, gen_loss = 0.3966993748683196, disc_loss = 0.16942391225924858
Trained batch 325 in epoch 2, gen_loss = 0.39642372274874177, disc_loss = 0.16947682508113193
Trained batch 326 in epoch 2, gen_loss = 0.396356475417038, disc_loss = 0.16953996634993715
Trained batch 327 in epoch 2, gen_loss = 0.3962571541438015, disc_loss = 0.16941121266019055
Trained batch 328 in epoch 2, gen_loss = 0.39620975162664085, disc_loss = 0.16942738132455065
Trained batch 329 in epoch 2, gen_loss = 0.3961706234198628, disc_loss = 0.16960293248747335
Trained batch 330 in epoch 2, gen_loss = 0.3961144651981279, disc_loss = 0.16978189344672637
Trained batch 331 in epoch 2, gen_loss = 0.3961189535996282, disc_loss = 0.17031987410891486
Trained batch 332 in epoch 2, gen_loss = 0.3963940496648754, disc_loss = 0.1709316878078936
Trained batch 333 in epoch 2, gen_loss = 0.396386010962689, disc_loss = 0.170829051670557
Trained batch 334 in epoch 2, gen_loss = 0.396552569519228, disc_loss = 0.1705911951500978
Trained batch 335 in epoch 2, gen_loss = 0.39635567823868423, disc_loss = 0.17049445808377295
Trained batch 336 in epoch 2, gen_loss = 0.39623985362159037, disc_loss = 0.17078476315170793
Trained batch 337 in epoch 2, gen_loss = 0.39629904498186336, disc_loss = 0.17057277733933995
Trained batch 338 in epoch 2, gen_loss = 0.3961949281196679, disc_loss = 0.17028025961906862
Trained batch 339 in epoch 2, gen_loss = 0.3960314850158551, disc_loss = 0.16997966365340877
Trained batch 340 in epoch 2, gen_loss = 0.39619569733869997, disc_loss = 0.17014089595974366
Trained batch 341 in epoch 2, gen_loss = 0.3961323609913302, disc_loss = 0.17000542202016763
Trained batch 342 in epoch 2, gen_loss = 0.3965699071873729, disc_loss = 0.16970452970387984
Trained batch 343 in epoch 2, gen_loss = 0.39646241159806417, disc_loss = 0.1695316379110134
Trained batch 344 in epoch 2, gen_loss = 0.3966819454362427, disc_loss = 0.1693083482807961
Trained batch 345 in epoch 2, gen_loss = 0.3967580596749493, disc_loss = 0.16927569928024547
Trained batch 346 in epoch 2, gen_loss = 0.3967363362439428, disc_loss = 0.16989932086866252
Trained batch 347 in epoch 2, gen_loss = 0.3966153424618573, disc_loss = 0.16968101468579522
Trained batch 348 in epoch 2, gen_loss = 0.39665479334685044, disc_loss = 0.1695456697384061
Trained batch 349 in epoch 2, gen_loss = 0.3967497112495559, disc_loss = 0.1693874648000513
Trained batch 350 in epoch 2, gen_loss = 0.3968080749623796, disc_loss = 0.16997667486935938
Trained batch 351 in epoch 2, gen_loss = 0.3968548355200751, disc_loss = 0.16989863572896205
Trained batch 352 in epoch 2, gen_loss = 0.3969526184939122, disc_loss = 0.1701787356656604
Trained batch 353 in epoch 2, gen_loss = 0.397077650463177, disc_loss = 0.1698822659666592
Trained batch 354 in epoch 2, gen_loss = 0.3971203255401531, disc_loss = 0.16999917573912043
Trained batch 355 in epoch 2, gen_loss = 0.3970371787383985, disc_loss = 0.16986472944446493
Trained batch 356 in epoch 2, gen_loss = 0.39713058973393855, disc_loss = 0.1697824051191493
Trained batch 357 in epoch 2, gen_loss = 0.3971273413333813, disc_loss = 0.16957771318168613
Trained batch 358 in epoch 2, gen_loss = 0.3972749194976015, disc_loss = 0.16942537268805305
Trained batch 359 in epoch 2, gen_loss = 0.3971724685281515, disc_loss = 0.1692548369574878
Trained batch 360 in epoch 2, gen_loss = 0.3970024809034908, disc_loss = 0.16917501478726843
Trained batch 361 in epoch 2, gen_loss = 0.3972844381441069, disc_loss = 0.1691002352420467
Trained batch 362 in epoch 2, gen_loss = 0.3974139506905532, disc_loss = 0.1690619428829385
Trained batch 363 in epoch 2, gen_loss = 0.397392021635404, disc_loss = 0.16893189736119993
Trained batch 364 in epoch 2, gen_loss = 0.3972939116089311, disc_loss = 0.1690840767670984
Trained batch 365 in epoch 2, gen_loss = 0.3973830599195319, disc_loss = 0.1692642419716048
Trained batch 366 in epoch 2, gen_loss = 0.3974589319336317, disc_loss = 0.1692267850406813
Trained batch 367 in epoch 2, gen_loss = 0.3973035686446921, disc_loss = 0.1691809242348308
Trained batch 368 in epoch 2, gen_loss = 0.39761580526828766, disc_loss = 0.1691094071561405
Trained batch 369 in epoch 2, gen_loss = 0.3976796260959393, disc_loss = 0.16908148531172726
Trained batch 370 in epoch 2, gen_loss = 0.39778700659699195, disc_loss = 0.16905402426289098
Trained batch 371 in epoch 2, gen_loss = 0.3977905889592504, disc_loss = 0.16899941168645377
Trained batch 372 in epoch 2, gen_loss = 0.39760111512032015, disc_loss = 0.16894911109761962
Trained batch 373 in epoch 2, gen_loss = 0.39741324641328446, disc_loss = 0.16891189321955258
Trained batch 374 in epoch 2, gen_loss = 0.3973669719298681, disc_loss = 0.16868298335870108
Trained batch 375 in epoch 2, gen_loss = 0.39742751788110176, disc_loss = 0.1687744970017291
Trained batch 376 in epoch 2, gen_loss = 0.3975446940812255, disc_loss = 0.1686685233122474
Trained batch 377 in epoch 2, gen_loss = 0.3974902927481308, disc_loss = 0.16852991862429512
Trained batch 378 in epoch 2, gen_loss = 0.3978243153689719, disc_loss = 0.16828325335771868
Trained batch 379 in epoch 2, gen_loss = 0.3979670658315483, disc_loss = 0.16806478649377823
Trained batch 380 in epoch 2, gen_loss = 0.3981717312977383, disc_loss = 0.16784330394871905
Trained batch 381 in epoch 2, gen_loss = 0.39802136818307854, disc_loss = 0.16783222710196885
Trained batch 382 in epoch 2, gen_loss = 0.3980052103495162, disc_loss = 0.16771940591285497
Trained batch 383 in epoch 2, gen_loss = 0.39814608338444185, disc_loss = 0.16773633049645773
Trained batch 384 in epoch 2, gen_loss = 0.39855284160607823, disc_loss = 0.1675712312777321
Trained batch 385 in epoch 2, gen_loss = 0.3986266146129277, disc_loss = 0.1675538759427676
Trained batch 386 in epoch 2, gen_loss = 0.39886488382360424, disc_loss = 0.1675667352108068
Trained batch 387 in epoch 2, gen_loss = 0.39891424878817244, disc_loss = 0.16782281722527803
Trained batch 388 in epoch 2, gen_loss = 0.3990244048343526, disc_loss = 0.16764842109769046
Trained batch 389 in epoch 2, gen_loss = 0.39911942722705696, disc_loss = 0.16777059208506193
Trained batch 390 in epoch 2, gen_loss = 0.39887797790567586, disc_loss = 0.16767978609141793
Trained batch 391 in epoch 2, gen_loss = 0.39885755829817177, disc_loss = 0.16810858548067661
Trained batch 392 in epoch 2, gen_loss = 0.39901228506904823, disc_loss = 0.1682028088140427
Trained batch 393 in epoch 2, gen_loss = 0.3990936403725353, disc_loss = 0.16833978541535774
Trained batch 394 in epoch 2, gen_loss = 0.39902368063413646, disc_loss = 0.16871485504545744
Trained batch 395 in epoch 2, gen_loss = 0.39894714458572744, disc_loss = 0.16858404936889806
Trained batch 396 in epoch 2, gen_loss = 0.39897504227437663, disc_loss = 0.1687863074449508
Trained batch 397 in epoch 2, gen_loss = 0.3991125495215157, disc_loss = 0.168794729695398
Trained batch 398 in epoch 2, gen_loss = 0.39899826382186476, disc_loss = 0.16886996683246808
Trained batch 399 in epoch 2, gen_loss = 0.39908192958682775, disc_loss = 0.16884808273985982
Trained batch 400 in epoch 2, gen_loss = 0.3992161239100216, disc_loss = 0.16868670098948063
Trained batch 401 in epoch 2, gen_loss = 0.3991559589309479, disc_loss = 0.16869060298548408
Trained batch 402 in epoch 2, gen_loss = 0.3993215763909054, disc_loss = 0.1685863193817825
Trained batch 403 in epoch 2, gen_loss = 0.3994011655081027, disc_loss = 0.1683568989138792
Trained batch 404 in epoch 2, gen_loss = 0.3994606206078588, disc_loss = 0.168475243964313
Trained batch 405 in epoch 2, gen_loss = 0.3996367140723567, disc_loss = 0.16854569297559155
Trained batch 406 in epoch 2, gen_loss = 0.3996712285338807, disc_loss = 0.1684546880698614
Trained batch 407 in epoch 2, gen_loss = 0.39971897579437377, disc_loss = 0.16821683431957282
Trained batch 408 in epoch 2, gen_loss = 0.39982908465022854, disc_loss = 0.1678877904792578
Trained batch 409 in epoch 2, gen_loss = 0.3997602916708807, disc_loss = 0.16787486394367568
Trained batch 410 in epoch 2, gen_loss = 0.399844273272222, disc_loss = 0.16782407000334593
Trained batch 411 in epoch 2, gen_loss = 0.39980065457305863, disc_loss = 0.16765625702524647
Trained batch 412 in epoch 2, gen_loss = 0.39966065359029007, disc_loss = 0.1674716534323034
Trained batch 413 in epoch 2, gen_loss = 0.39975644824441503, disc_loss = 0.16727627401694584
Trained batch 414 in epoch 2, gen_loss = 0.39977047554699774, disc_loss = 0.16701766155570386
Trained batch 415 in epoch 2, gen_loss = 0.39987219508307487, disc_loss = 0.1667055886847755
Trained batch 416 in epoch 2, gen_loss = 0.3996818950779432, disc_loss = 0.16677710533642368
Trained batch 417 in epoch 2, gen_loss = 0.399703751732573, disc_loss = 0.16704783191164715
Trained batch 418 in epoch 2, gen_loss = 0.399489573440859, disc_loss = 0.16699722798670105
Trained batch 419 in epoch 2, gen_loss = 0.3995036057418301, disc_loss = 0.16700521283561276
Trained batch 420 in epoch 2, gen_loss = 0.3994648357822323, disc_loss = 0.16683012139131792
Trained batch 421 in epoch 2, gen_loss = 0.3994228160141204, disc_loss = 0.16667882554339006
Trained batch 422 in epoch 2, gen_loss = 0.39938423153779185, disc_loss = 0.16653473844342198
Trained batch 423 in epoch 2, gen_loss = 0.399289324985079, disc_loss = 0.16670111594897397
Trained batch 424 in epoch 2, gen_loss = 0.3992137246622759, disc_loss = 0.16768616017173318
Trained batch 425 in epoch 2, gen_loss = 0.39925730812577576, disc_loss = 0.16748414884710536
Trained batch 426 in epoch 2, gen_loss = 0.39892811312468884, disc_loss = 0.1679459122081551
Trained batch 427 in epoch 2, gen_loss = 0.39907023188806023, disc_loss = 0.16771629407444846
Trained batch 428 in epoch 2, gen_loss = 0.39894356250346125, disc_loss = 0.16762320183234894
Trained batch 429 in epoch 2, gen_loss = 0.3987522896985675, disc_loss = 0.16770799024853594
Trained batch 430 in epoch 2, gen_loss = 0.39866197555220045, disc_loss = 0.1676771253209103
Trained batch 431 in epoch 2, gen_loss = 0.3985034887920375, disc_loss = 0.16771468164882175
Trained batch 432 in epoch 2, gen_loss = 0.39855477878045265, disc_loss = 0.16768952044411015
Trained batch 433 in epoch 2, gen_loss = 0.39863953121384166, disc_loss = 0.16742871794420452
Trained batch 434 in epoch 2, gen_loss = 0.3986107236009905, disc_loss = 0.16775906966335472
Trained batch 435 in epoch 2, gen_loss = 0.3985789794509017, disc_loss = 0.16768320584926036
Trained batch 436 in epoch 2, gen_loss = 0.39873350911200456, disc_loss = 0.16757587114992623
Trained batch 437 in epoch 2, gen_loss = 0.39881064531873894, disc_loss = 0.16734729021719602
Trained batch 438 in epoch 2, gen_loss = 0.39881246803425985, disc_loss = 0.16739424572650827
Trained batch 439 in epoch 2, gen_loss = 0.3989893818782134, disc_loss = 0.16737049128860235
Trained batch 440 in epoch 2, gen_loss = 0.39889800714121926, disc_loss = 0.16723607171352217
Trained batch 441 in epoch 2, gen_loss = 0.3990066161724777, disc_loss = 0.16715266125706527
Trained batch 442 in epoch 2, gen_loss = 0.398724382638124, disc_loss = 0.16734884499359884
Trained batch 443 in epoch 2, gen_loss = 0.3987480539257999, disc_loss = 0.1675690912415047
Trained batch 444 in epoch 2, gen_loss = 0.3987349252017696, disc_loss = 0.1676818551139885
Trained batch 445 in epoch 2, gen_loss = 0.39897106998838117, disc_loss = 0.16756659032852125
Trained batch 446 in epoch 2, gen_loss = 0.39894133709554436, disc_loss = 0.16750503308087655
Trained batch 447 in epoch 2, gen_loss = 0.39884972841744976, disc_loss = 0.16752424398769758
Trained batch 448 in epoch 2, gen_loss = 0.39899712233474366, disc_loss = 0.16749148639976846
Trained batch 449 in epoch 2, gen_loss = 0.3988701198829545, disc_loss = 0.1674407443238629
Trained batch 450 in epoch 2, gen_loss = 0.39884529816205644, disc_loss = 0.16748174778836264
Trained batch 451 in epoch 2, gen_loss = 0.39911578671462766, disc_loss = 0.16744999819954412
Trained batch 452 in epoch 2, gen_loss = 0.39913688429012467, disc_loss = 0.16722272042078162
Trained batch 453 in epoch 2, gen_loss = 0.3991364733303696, disc_loss = 0.16699957540710067
Trained batch 454 in epoch 2, gen_loss = 0.39921326024846715, disc_loss = 0.16695085195722162
Trained batch 455 in epoch 2, gen_loss = 0.39904368966164294, disc_loss = 0.1668754273110576
Trained batch 456 in epoch 2, gen_loss = 0.3989592091846779, disc_loss = 0.16686870178912871
Trained batch 457 in epoch 2, gen_loss = 0.39900705071906334, disc_loss = 0.16672902694175337
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.34797853231430054, disc_loss = 0.22643280029296875
Trained batch 1 in epoch 3, gen_loss = 0.36592230200767517, disc_loss = 0.19512857496738434
Trained batch 2 in epoch 3, gen_loss = 0.3818644980589549, disc_loss = 0.17017185439666113
Trained batch 3 in epoch 3, gen_loss = 0.3778073191642761, disc_loss = 0.16780666075646877
Trained batch 4 in epoch 3, gen_loss = 0.4194740653038025, disc_loss = 0.2006888911128044
Trained batch 5 in epoch 3, gen_loss = 0.41573162376880646, disc_loss = 0.1904573750992616
Trained batch 6 in epoch 3, gen_loss = 0.4212564698287419, disc_loss = 0.1858334488102368
Trained batch 7 in epoch 3, gen_loss = 0.41219237446784973, disc_loss = 0.18746042158454657
Trained batch 8 in epoch 3, gen_loss = 0.4108092486858368, disc_loss = 0.18785331563817131
Trained batch 9 in epoch 3, gen_loss = 0.4064644783735275, disc_loss = 0.18861123993992807
Trained batch 10 in epoch 3, gen_loss = 0.4034226645122875, disc_loss = 0.1867332925850695
Trained batch 11 in epoch 3, gen_loss = 0.407968873778979, disc_loss = 0.18352828485270342
Trained batch 12 in epoch 3, gen_loss = 0.41004830598831177, disc_loss = 0.18446231862673393
Trained batch 13 in epoch 3, gen_loss = 0.41005186310836245, disc_loss = 0.18521919048258237
Trained batch 14 in epoch 3, gen_loss = 0.40914053718249005, disc_loss = 0.17992550979057947
Trained batch 15 in epoch 3, gen_loss = 0.4103410765528679, disc_loss = 0.1741188676096499
Trained batch 16 in epoch 3, gen_loss = 0.41084803903804107, disc_loss = 0.17059457214439616
Trained batch 17 in epoch 3, gen_loss = 0.41066021886136794, disc_loss = 0.16999572432703441
Trained batch 18 in epoch 3, gen_loss = 0.4062397385898389, disc_loss = 0.1693628563692695
Trained batch 19 in epoch 3, gen_loss = 0.40586787164211274, disc_loss = 0.1663507901132107
Trained batch 20 in epoch 3, gen_loss = 0.40551580701555523, disc_loss = 0.16424150339194707
Trained batch 21 in epoch 3, gen_loss = 0.4043025550517169, disc_loss = 0.16347692771391434
Trained batch 22 in epoch 3, gen_loss = 0.4019701118054597, disc_loss = 0.16258190507474152
Trained batch 23 in epoch 3, gen_loss = 0.40040159970521927, disc_loss = 0.16519029438495636
Trained batch 24 in epoch 3, gen_loss = 0.4001019847393036, disc_loss = 0.17181560277938843
Trained batch 25 in epoch 3, gen_loss = 0.4002995456640537, disc_loss = 0.17231682802622134
Trained batch 26 in epoch 3, gen_loss = 0.3966257936424679, disc_loss = 0.17110184883629834
Trained batch 27 in epoch 3, gen_loss = 0.39487147331237793, disc_loss = 0.1729617714881897
Trained batch 28 in epoch 3, gen_loss = 0.39468988467907085, disc_loss = 0.1716044925410172
Trained batch 29 in epoch 3, gen_loss = 0.39559793174266816, disc_loss = 0.17163372784852982
Trained batch 30 in epoch 3, gen_loss = 0.39461617700515256, disc_loss = 0.16960263396463088
Trained batch 31 in epoch 3, gen_loss = 0.3931324314326048, disc_loss = 0.1711062234826386
Trained batch 32 in epoch 3, gen_loss = 0.39167374553102435, disc_loss = 0.17469563312602765
Trained batch 33 in epoch 3, gen_loss = 0.39028530962326946, disc_loss = 0.17347056243349523
Trained batch 34 in epoch 3, gen_loss = 0.3907736957073212, disc_loss = 0.17270563627992358
Trained batch 35 in epoch 3, gen_loss = 0.39235272589657044, disc_loss = 0.16990127683513695
Trained batch 36 in epoch 3, gen_loss = 0.39386794051608526, disc_loss = 0.16873554381969813
Trained batch 37 in epoch 3, gen_loss = 0.39307968945879684, disc_loss = 0.1693488157501346
Trained batch 38 in epoch 3, gen_loss = 0.393965809009014, disc_loss = 0.16629880265547678
Trained batch 39 in epoch 3, gen_loss = 0.3961300477385521, disc_loss = 0.16394936945289373
Trained batch 40 in epoch 3, gen_loss = 0.39906535206771476, disc_loss = 0.1617273368486544
Trained batch 41 in epoch 3, gen_loss = 0.3998213403281711, disc_loss = 0.1595035812684468
Trained batch 42 in epoch 3, gen_loss = 0.40083995114925297, disc_loss = 0.15830626789220545
Trained batch 43 in epoch 3, gen_loss = 0.40155778147957544, disc_loss = 0.15585687671872703
Trained batch 44 in epoch 3, gen_loss = 0.4020132005214691, disc_loss = 0.15663376930687162
Trained batch 45 in epoch 3, gen_loss = 0.40184583288172016, disc_loss = 0.15824063300438548
Trained batch 46 in epoch 3, gen_loss = 0.4020356599320757, disc_loss = 0.15642847960933726
Trained batch 47 in epoch 3, gen_loss = 0.4020720260838668, disc_loss = 0.15579676674678922
Trained batch 48 in epoch 3, gen_loss = 0.40202260686426744, disc_loss = 0.15985170843041674
Trained batch 49 in epoch 3, gen_loss = 0.4017201405763626, disc_loss = 0.1602983532845974
Trained batch 50 in epoch 3, gen_loss = 0.401216529748019, disc_loss = 0.16051282587589003
Trained batch 51 in epoch 3, gen_loss = 0.3999828581626599, disc_loss = 0.15913616980497652
Trained batch 52 in epoch 3, gen_loss = 0.39990047182676924, disc_loss = 0.15931966957056298
Trained batch 53 in epoch 3, gen_loss = 0.4001410956735964, disc_loss = 0.15934443004705287
Trained batch 54 in epoch 3, gen_loss = 0.39804166501218624, disc_loss = 0.1590696082873778
Trained batch 55 in epoch 3, gen_loss = 0.39815999727164, disc_loss = 0.15848303346761636
Trained batch 56 in epoch 3, gen_loss = 0.39830042761668827, disc_loss = 0.15795378230120005
Trained batch 57 in epoch 3, gen_loss = 0.3976429531286503, disc_loss = 0.15738603087334796
Trained batch 58 in epoch 3, gen_loss = 0.39729874265395987, disc_loss = 0.15793916936648095
Trained batch 59 in epoch 3, gen_loss = 0.3975284124414126, disc_loss = 0.15817699482043585
Trained batch 60 in epoch 3, gen_loss = 0.3969944739928011, disc_loss = 0.15929599961296456
Trained batch 61 in epoch 3, gen_loss = 0.3980772288576249, disc_loss = 0.15828317932544217
Trained batch 62 in epoch 3, gen_loss = 0.3983036606084733, disc_loss = 0.1576698694437269
Trained batch 63 in epoch 3, gen_loss = 0.39906145771965384, disc_loss = 0.15802612085826695
Trained batch 64 in epoch 3, gen_loss = 0.399224270765598, disc_loss = 0.15687802881002427
Trained batch 65 in epoch 3, gen_loss = 0.39909687186732434, disc_loss = 0.1559992115380186
Trained batch 66 in epoch 3, gen_loss = 0.40026498152248896, disc_loss = 0.15454682496501437
Trained batch 67 in epoch 3, gen_loss = 0.40046223253011703, disc_loss = 0.1556455827153781
Trained batch 68 in epoch 3, gen_loss = 0.4004942532898723, disc_loss = 0.15691161533628684
Trained batch 69 in epoch 3, gen_loss = 0.4004009532076972, disc_loss = 0.15713856571487017
Trained batch 70 in epoch 3, gen_loss = 0.40076044663577015, disc_loss = 0.15652026603339422
Trained batch 71 in epoch 3, gen_loss = 0.40023285605841213, disc_loss = 0.15635000531458193
Trained batch 72 in epoch 3, gen_loss = 0.40049239829795, disc_loss = 0.15682158455865025
Trained batch 73 in epoch 3, gen_loss = 0.3997723661564492, disc_loss = 0.15728860036344142
Trained batch 74 in epoch 3, gen_loss = 0.39814781745274863, disc_loss = 0.15715617269277574
Trained batch 75 in epoch 3, gen_loss = 0.3974461931931345, disc_loss = 0.1589590488491874
Trained batch 76 in epoch 3, gen_loss = 0.3976841267053183, disc_loss = 0.15924603279147828
Trained batch 77 in epoch 3, gen_loss = 0.39721378149130404, disc_loss = 0.1593218985467385
Trained batch 78 in epoch 3, gen_loss = 0.39697779809372336, disc_loss = 0.16053201663720457
Trained batch 79 in epoch 3, gen_loss = 0.39832198843359945, disc_loss = 0.1610025000758469
Trained batch 80 in epoch 3, gen_loss = 0.39948226750632865, disc_loss = 0.1606489575387519
Trained batch 81 in epoch 3, gen_loss = 0.4002385750049498, disc_loss = 0.16066313198790316
Trained batch 82 in epoch 3, gen_loss = 0.40007811246148073, disc_loss = 0.16104470184409475
Trained batch 83 in epoch 3, gen_loss = 0.39989463630176725, disc_loss = 0.16074160956555889
Trained batch 84 in epoch 3, gen_loss = 0.39951535077656014, disc_loss = 0.16053347946966395
Trained batch 85 in epoch 3, gen_loss = 0.3995856774407764, disc_loss = 0.16029716724919718
Trained batch 86 in epoch 3, gen_loss = 0.3990823273686157, disc_loss = 0.16015856507523307
Trained batch 87 in epoch 3, gen_loss = 0.3988565071062608, disc_loss = 0.1603840905326334
Trained batch 88 in epoch 3, gen_loss = 0.39891917451044145, disc_loss = 0.16099675393171525
Trained batch 89 in epoch 3, gen_loss = 0.3992252396212684, disc_loss = 0.16081336629059578
Trained batch 90 in epoch 3, gen_loss = 0.39965057176548047, disc_loss = 0.16326714798316852
Trained batch 91 in epoch 3, gen_loss = 0.40057260057200555, disc_loss = 0.1630724795648585
Trained batch 92 in epoch 3, gen_loss = 0.4006405677846683, disc_loss = 0.1629921158635488
Trained batch 93 in epoch 3, gen_loss = 0.40014895479729834, disc_loss = 0.16298774796280455
Trained batch 94 in epoch 3, gen_loss = 0.3996214088640715, disc_loss = 0.16271139563698517
Trained batch 95 in epoch 3, gen_loss = 0.39954372371236485, disc_loss = 0.1622741026027749
Trained batch 96 in epoch 3, gen_loss = 0.3997006791154134, disc_loss = 0.1619511591558604
Trained batch 97 in epoch 3, gen_loss = 0.39930487530572073, disc_loss = 0.16126305898841548
Trained batch 98 in epoch 3, gen_loss = 0.3995460229690629, disc_loss = 0.16114797947382686
Trained batch 99 in epoch 3, gen_loss = 0.3996689003705978, disc_loss = 0.161294504404068
Trained batch 100 in epoch 3, gen_loss = 0.3993108089607541, disc_loss = 0.16067292356845175
Trained batch 101 in epoch 3, gen_loss = 0.39976750401889577, disc_loss = 0.1601113580605563
Trained batch 102 in epoch 3, gen_loss = 0.40034722732108774, disc_loss = 0.15952346495632985
Trained batch 103 in epoch 3, gen_loss = 0.400823022883672, disc_loss = 0.15911185648292303
Trained batch 104 in epoch 3, gen_loss = 0.4015682895978292, disc_loss = 0.1584691685580072
Trained batch 105 in epoch 3, gen_loss = 0.4020958478158375, disc_loss = 0.15799448182279208
Trained batch 106 in epoch 3, gen_loss = 0.4025755081778375, disc_loss = 0.1575975324088168
Trained batch 107 in epoch 3, gen_loss = 0.40229377178130327, disc_loss = 0.1574725117534399
Trained batch 108 in epoch 3, gen_loss = 0.40177730600768274, disc_loss = 0.15850140284234232
Trained batch 109 in epoch 3, gen_loss = 0.40191492384130306, disc_loss = 0.15798115249384534
Trained batch 110 in epoch 3, gen_loss = 0.40160638308739877, disc_loss = 0.157724171809785
Trained batch 111 in epoch 3, gen_loss = 0.40197426533060415, disc_loss = 0.15826534047456725
Trained batch 112 in epoch 3, gen_loss = 0.40258794732853376, disc_loss = 0.15868389283397558
Trained batch 113 in epoch 3, gen_loss = 0.4019754793037448, disc_loss = 0.15873229823875845
Trained batch 114 in epoch 3, gen_loss = 0.4020777191804803, disc_loss = 0.15843993198612463
Trained batch 115 in epoch 3, gen_loss = 0.4017304618810785, disc_loss = 0.1579000724415327
Trained batch 116 in epoch 3, gen_loss = 0.4014240274062523, disc_loss = 0.15850410686853605
Trained batch 117 in epoch 3, gen_loss = 0.402113601312799, disc_loss = 0.15930932135147563
Trained batch 118 in epoch 3, gen_loss = 0.40217698572062643, disc_loss = 0.15961020289599395
Trained batch 119 in epoch 3, gen_loss = 0.40246772517760593, disc_loss = 0.1593108480796218
Trained batch 120 in epoch 3, gen_loss = 0.40287682660355056, disc_loss = 0.15906257170044685
Trained batch 121 in epoch 3, gen_loss = 0.4025345588805246, disc_loss = 0.15870027335696532
Trained batch 122 in epoch 3, gen_loss = 0.4028259995507031, disc_loss = 0.15821209725567964
Trained batch 123 in epoch 3, gen_loss = 0.40242158645583737, disc_loss = 0.15809242529494147
Trained batch 124 in epoch 3, gen_loss = 0.4017177515029907, disc_loss = 0.1579424017071724
Trained batch 125 in epoch 3, gen_loss = 0.40229452436878566, disc_loss = 0.15759409969997784
Trained batch 126 in epoch 3, gen_loss = 0.40223234234832406, disc_loss = 0.15747900019715153
Trained batch 127 in epoch 3, gen_loss = 0.40301811788231134, disc_loss = 0.1579140610410832
Trained batch 128 in epoch 3, gen_loss = 0.40240993125494134, disc_loss = 0.15831223020488902
Trained batch 129 in epoch 3, gen_loss = 0.4016205010505823, disc_loss = 0.15838541600566644
Trained batch 130 in epoch 3, gen_loss = 0.4014686323304213, disc_loss = 0.1580590035851675
Trained batch 131 in epoch 3, gen_loss = 0.4016189814516992, disc_loss = 0.15737177663002955
Trained batch 132 in epoch 3, gen_loss = 0.4013969320103638, disc_loss = 0.15709532606870608
Trained batch 133 in epoch 3, gen_loss = 0.4010984739705698, disc_loss = 0.15714639158391241
Trained batch 134 in epoch 3, gen_loss = 0.4014086518022749, disc_loss = 0.15731222850305063
Trained batch 135 in epoch 3, gen_loss = 0.4008634283262141, disc_loss = 0.15726466893273242
Trained batch 136 in epoch 3, gen_loss = 0.400612451734334, disc_loss = 0.1569324849839628
Trained batch 137 in epoch 3, gen_loss = 0.4002137551273125, disc_loss = 0.15641655119648878
Trained batch 138 in epoch 3, gen_loss = 0.40073998218817675, disc_loss = 0.15558404194043696
Trained batch 139 in epoch 3, gen_loss = 0.40009165299790245, disc_loss = 0.15627249173287835
Trained batch 140 in epoch 3, gen_loss = 0.4010208530206207, disc_loss = 0.15597061038757046
Trained batch 141 in epoch 3, gen_loss = 0.4019052350605038, disc_loss = 0.15751961563569558
Trained batch 142 in epoch 3, gen_loss = 0.40171300260337084, disc_loss = 0.15809336989805414
Trained batch 143 in epoch 3, gen_loss = 0.4015468129267295, disc_loss = 0.15808966039266023
Trained batch 144 in epoch 3, gen_loss = 0.40214954491319327, disc_loss = 0.15799380014168804
Trained batch 145 in epoch 3, gen_loss = 0.40246361963552973, disc_loss = 0.15866907499730587
Trained batch 146 in epoch 3, gen_loss = 0.40238613113254107, disc_loss = 0.1598773017576357
Trained batch 147 in epoch 3, gen_loss = 0.4023294060214146, disc_loss = 0.15944316764236302
Trained batch 148 in epoch 3, gen_loss = 0.4022651342737595, disc_loss = 0.15962836058847857
Trained batch 149 in epoch 3, gen_loss = 0.40262153526147204, disc_loss = 0.15973783396184443
Trained batch 150 in epoch 3, gen_loss = 0.4022066222121384, disc_loss = 0.15958050547155322
Trained batch 151 in epoch 3, gen_loss = 0.4021549422882105, disc_loss = 0.1597539568074832
Trained batch 152 in epoch 3, gen_loss = 0.40228269107980663, disc_loss = 0.15973296208806287
Trained batch 153 in epoch 3, gen_loss = 0.40238339870007006, disc_loss = 0.1598649544810707
Trained batch 154 in epoch 3, gen_loss = 0.4020015345465752, disc_loss = 0.15983861014246942
Trained batch 155 in epoch 3, gen_loss = 0.4022075455540266, disc_loss = 0.15983302091272214
Trained batch 156 in epoch 3, gen_loss = 0.4020817984061636, disc_loss = 0.15988902322900522
Trained batch 157 in epoch 3, gen_loss = 0.40232297042502635, disc_loss = 0.1597661363031668
Trained batch 158 in epoch 3, gen_loss = 0.4025172600581211, disc_loss = 0.1598774089050368
Trained batch 159 in epoch 3, gen_loss = 0.40248955581337215, disc_loss = 0.15942530871834606
Trained batch 160 in epoch 3, gen_loss = 0.40257575052865546, disc_loss = 0.15982350501121942
Trained batch 161 in epoch 3, gen_loss = 0.4025656008793984, disc_loss = 0.1599804666813141
Trained batch 162 in epoch 3, gen_loss = 0.4020167612956345, disc_loss = 0.1604332204199642
Trained batch 163 in epoch 3, gen_loss = 0.40223024222182063, disc_loss = 0.16035168243163242
Trained batch 164 in epoch 3, gen_loss = 0.40204150315487025, disc_loss = 0.16048919709794449
Trained batch 165 in epoch 3, gen_loss = 0.40211173963834, disc_loss = 0.161017594814121
Trained batch 166 in epoch 3, gen_loss = 0.4019054563459522, disc_loss = 0.16107252577018594
Trained batch 167 in epoch 3, gen_loss = 0.402165557124785, disc_loss = 0.16099616013733403
Trained batch 168 in epoch 3, gen_loss = 0.40242514190589185, disc_loss = 0.16177687293590878
Trained batch 169 in epoch 3, gen_loss = 0.4026301522465313, disc_loss = 0.16219535450286726
Trained batch 170 in epoch 3, gen_loss = 0.4024826579275187, disc_loss = 0.16274296328948254
Trained batch 171 in epoch 3, gen_loss = 0.4026379515958387, disc_loss = 0.16258004522167666
Trained batch 172 in epoch 3, gen_loss = 0.4024080096641717, disc_loss = 0.16321260363638745
Trained batch 173 in epoch 3, gen_loss = 0.4022473095134757, disc_loss = 0.16345235797437443
Trained batch 174 in epoch 3, gen_loss = 0.40209859473364695, disc_loss = 0.16346850324954304
Trained batch 175 in epoch 3, gen_loss = 0.40182408250190993, disc_loss = 0.1629573484163054
Trained batch 176 in epoch 3, gen_loss = 0.4019957494601018, disc_loss = 0.16302133395762766
Trained batch 177 in epoch 3, gen_loss = 0.4018615790632334, disc_loss = 0.16312063357719545
Trained batch 178 in epoch 3, gen_loss = 0.40183250347995225, disc_loss = 0.16356094787157446
Trained batch 179 in epoch 3, gen_loss = 0.4016166349252065, disc_loss = 0.1639465861643354
Trained batch 180 in epoch 3, gen_loss = 0.4015091725146573, disc_loss = 0.16362388685180995
Trained batch 181 in epoch 3, gen_loss = 0.40130438254429746, disc_loss = 0.16345769901770157
Trained batch 182 in epoch 3, gen_loss = 0.40163897718888164, disc_loss = 0.16339705035579008
Trained batch 183 in epoch 3, gen_loss = 0.4017716678588287, disc_loss = 0.16297787049299348
Trained batch 184 in epoch 3, gen_loss = 0.4012721366173512, disc_loss = 0.1629286541527993
Trained batch 185 in epoch 3, gen_loss = 0.40148950985042, disc_loss = 0.16261237841700354
Trained batch 186 in epoch 3, gen_loss = 0.4016836857731967, disc_loss = 0.1625270427349098
Trained batch 187 in epoch 3, gen_loss = 0.40134544892514007, disc_loss = 0.16238046039212892
Trained batch 188 in epoch 3, gen_loss = 0.40166390210232406, disc_loss = 0.16216322217905332
Trained batch 189 in epoch 3, gen_loss = 0.401797857723738, disc_loss = 0.1630687765973179
Trained batch 190 in epoch 3, gen_loss = 0.4014425989220904, disc_loss = 0.1632721371636653
Trained batch 191 in epoch 3, gen_loss = 0.40160363757361967, disc_loss = 0.16346353275002912
Trained batch 192 in epoch 3, gen_loss = 0.4021552229792343, disc_loss = 0.16297081072327388
Trained batch 193 in epoch 3, gen_loss = 0.40203254554689544, disc_loss = 0.16252731460809094
Trained batch 194 in epoch 3, gen_loss = 0.40188942704445274, disc_loss = 0.16236149330551808
Trained batch 195 in epoch 3, gen_loss = 0.4019921902491122, disc_loss = 0.1624483072902171
Trained batch 196 in epoch 3, gen_loss = 0.40275398638042703, disc_loss = 0.1617411779816532
Trained batch 197 in epoch 3, gen_loss = 0.40311673810385695, disc_loss = 0.1617307790244619
Trained batch 198 in epoch 3, gen_loss = 0.4032515681269181, disc_loss = 0.1613045459959525
Trained batch 199 in epoch 3, gen_loss = 0.4031928141415119, disc_loss = 0.16084680897183717
Trained batch 200 in epoch 3, gen_loss = 0.40339072026423556, disc_loss = 0.16053044874758565
Trained batch 201 in epoch 3, gen_loss = 0.40362593561115834, disc_loss = 0.16014523996907
Trained batch 202 in epoch 3, gen_loss = 0.40330159899049206, disc_loss = 0.1600157976095459
Trained batch 203 in epoch 3, gen_loss = 0.40279591960065503, disc_loss = 0.16020660249370278
Trained batch 204 in epoch 3, gen_loss = 0.4032528571966218, disc_loss = 0.16029006796093975
Trained batch 205 in epoch 3, gen_loss = 0.4029341049275352, disc_loss = 0.16035497753691036
Trained batch 206 in epoch 3, gen_loss = 0.40274044223453687, disc_loss = 0.15983867095468413
Trained batch 207 in epoch 3, gen_loss = 0.403035536265144, disc_loss = 0.15918892743782356
Trained batch 208 in epoch 3, gen_loss = 0.4029558755849537, disc_loss = 0.15950206920290677
Trained batch 209 in epoch 3, gen_loss = 0.40315576366015843, disc_loss = 0.1594446586711066
Trained batch 210 in epoch 3, gen_loss = 0.4030347854887705, disc_loss = 0.15932958767312397
Trained batch 211 in epoch 3, gen_loss = 0.4026895649028274, disc_loss = 0.1594800315094444
Trained batch 212 in epoch 3, gen_loss = 0.40273241761704565, disc_loss = 0.15971546637620165
Trained batch 213 in epoch 3, gen_loss = 0.40300976074187556, disc_loss = 0.159826691950036
Trained batch 214 in epoch 3, gen_loss = 0.4033036352590073, disc_loss = 0.15935495797284813
Trained batch 215 in epoch 3, gen_loss = 0.4030211613410049, disc_loss = 0.1592947938307016
Trained batch 216 in epoch 3, gen_loss = 0.402969734597316, disc_loss = 0.15914939628905414
Trained batch 217 in epoch 3, gen_loss = 0.4029840792811245, disc_loss = 0.159196521745089
Trained batch 218 in epoch 3, gen_loss = 0.4029933685037099, disc_loss = 0.1588461596739891
Trained batch 219 in epoch 3, gen_loss = 0.40299430218609894, disc_loss = 0.15862934762103992
Trained batch 220 in epoch 3, gen_loss = 0.40257745603630446, disc_loss = 0.15859003125677282
Trained batch 221 in epoch 3, gen_loss = 0.402952114069784, disc_loss = 0.15856192532826113
Trained batch 222 in epoch 3, gen_loss = 0.40279822539320975, disc_loss = 0.15844575362488827
Trained batch 223 in epoch 3, gen_loss = 0.4028836905157992, disc_loss = 0.15795621984372182
Trained batch 224 in epoch 3, gen_loss = 0.4027684043513404, disc_loss = 0.15745173143015967
Trained batch 225 in epoch 3, gen_loss = 0.4027431331640851, disc_loss = 0.15722149514914613
Trained batch 226 in epoch 3, gen_loss = 0.40272517311940637, disc_loss = 0.15690877419867705
Trained batch 227 in epoch 3, gen_loss = 0.40279709743826014, disc_loss = 0.15675671160090388
Trained batch 228 in epoch 3, gen_loss = 0.40299381582497507, disc_loss = 0.15666064304425728
Trained batch 229 in epoch 3, gen_loss = 0.403177976867427, disc_loss = 0.15658826397165007
Trained batch 230 in epoch 3, gen_loss = 0.403176100094081, disc_loss = 0.15667693803965788
Trained batch 231 in epoch 3, gen_loss = 0.40295209581482, disc_loss = 0.15762247739295507
Trained batch 232 in epoch 3, gen_loss = 0.40291763221757093, disc_loss = 0.15783639018755613
Trained batch 233 in epoch 3, gen_loss = 0.4030840300087236, disc_loss = 0.15743113299592948
Trained batch 234 in epoch 3, gen_loss = 0.40294292290159994, disc_loss = 0.15756652852956285
Trained batch 235 in epoch 3, gen_loss = 0.4030621155338772, disc_loss = 0.15754192155170238
Trained batch 236 in epoch 3, gen_loss = 0.40281434489201895, disc_loss = 0.15719978646512775
Trained batch 237 in epoch 3, gen_loss = 0.4030233934646895, disc_loss = 0.15710385128104387
Trained batch 238 in epoch 3, gen_loss = 0.4033017964043877, disc_loss = 0.1569694419348589
Trained batch 239 in epoch 3, gen_loss = 0.40329879919687905, disc_loss = 0.15659844372421503
Trained batch 240 in epoch 3, gen_loss = 0.4034134696133404, disc_loss = 0.15672591464648108
Trained batch 241 in epoch 3, gen_loss = 0.40337351752706796, disc_loss = 0.15685107158727882
Trained batch 242 in epoch 3, gen_loss = 0.40342625448242625, disc_loss = 0.15672951985779124
Trained batch 243 in epoch 3, gen_loss = 0.4036406217539897, disc_loss = 0.15670559207191231
Trained batch 244 in epoch 3, gen_loss = 0.4034233638218471, disc_loss = 0.15656680276199264
Trained batch 245 in epoch 3, gen_loss = 0.4032178250997047, disc_loss = 0.15683479704023376
Trained batch 246 in epoch 3, gen_loss = 0.40324317130000004, disc_loss = 0.15679860724370007
Trained batch 247 in epoch 3, gen_loss = 0.40296744795576217, disc_loss = 0.15653490311195772
Trained batch 248 in epoch 3, gen_loss = 0.4028733900512557, disc_loss = 0.156565073862612
Trained batch 249 in epoch 3, gen_loss = 0.4029574579000473, disc_loss = 0.1563718571662903
Trained batch 250 in epoch 3, gen_loss = 0.40300555105703284, disc_loss = 0.15611785807576312
Trained batch 251 in epoch 3, gen_loss = 0.4027630009111904, disc_loss = 0.15580916401767542
Trained batch 252 in epoch 3, gen_loss = 0.4027514167925115, disc_loss = 0.15567152570241052
Trained batch 253 in epoch 3, gen_loss = 0.4024711475362928, disc_loss = 0.15563760119981654
Trained batch 254 in epoch 3, gen_loss = 0.4025523689447665, disc_loss = 0.15555089101487515
Trained batch 255 in epoch 3, gen_loss = 0.40245142905041575, disc_loss = 0.15591452937223949
Trained batch 256 in epoch 3, gen_loss = 0.4022401308039283, disc_loss = 0.1563191880337923
Trained batch 257 in epoch 3, gen_loss = 0.40197810634624126, disc_loss = 0.15611506914792134
Trained batch 258 in epoch 3, gen_loss = 0.4020960594466294, disc_loss = 0.15584733860718236
Trained batch 259 in epoch 3, gen_loss = 0.4019854927292237, disc_loss = 0.15564948649933705
Trained batch 260 in epoch 3, gen_loss = 0.40212977857425297, disc_loss = 0.15544629296808865
Trained batch 261 in epoch 3, gen_loss = 0.40236253490429796, disc_loss = 0.1552482107440934
Trained batch 262 in epoch 3, gen_loss = 0.4028545972738882, disc_loss = 0.1557348520130259
Trained batch 263 in epoch 3, gen_loss = 0.4023311718395262, disc_loss = 0.1562883681194349
Trained batch 264 in epoch 3, gen_loss = 0.4022700787715192, disc_loss = 0.15616020307226
Trained batch 265 in epoch 3, gen_loss = 0.40221853072481945, disc_loss = 0.1563320510593572
Trained batch 266 in epoch 3, gen_loss = 0.40201251973373614, disc_loss = 0.15655431307656933
Trained batch 267 in epoch 3, gen_loss = 0.4022404420286862, disc_loss = 0.15647829724336737
Trained batch 268 in epoch 3, gen_loss = 0.4021894182857528, disc_loss = 0.1566051302346155
Trained batch 269 in epoch 3, gen_loss = 0.40195975380915183, disc_loss = 0.15661853662243597
Trained batch 270 in epoch 3, gen_loss = 0.4018571639632827, disc_loss = 0.15686229107784608
Trained batch 271 in epoch 3, gen_loss = 0.4017402154996115, disc_loss = 0.15690068073351593
Trained batch 272 in epoch 3, gen_loss = 0.40181061505398036, disc_loss = 0.15672572451087582
Trained batch 273 in epoch 3, gen_loss = 0.40195297835952176, disc_loss = 0.15644174281263004
Trained batch 274 in epoch 3, gen_loss = 0.4018498024073514, disc_loss = 0.15619243638081984
Trained batch 275 in epoch 3, gen_loss = 0.401995815768622, disc_loss = 0.1560427543801674
Trained batch 276 in epoch 3, gen_loss = 0.4021892486281343, disc_loss = 0.15612748362097068
Trained batch 277 in epoch 3, gen_loss = 0.4024794011664905, disc_loss = 0.1557952905033561
Trained batch 278 in epoch 3, gen_loss = 0.40257670321772177, disc_loss = 0.15541341882132287
Trained batch 279 in epoch 3, gen_loss = 0.40242348707148007, disc_loss = 0.15582473557442428
Trained batch 280 in epoch 3, gen_loss = 0.40273050555554996, disc_loss = 0.15597437722509017
Trained batch 281 in epoch 3, gen_loss = 0.40281649800479835, disc_loss = 0.15562768320136883
Trained batch 282 in epoch 3, gen_loss = 0.4029255668392451, disc_loss = 0.15520640249387113
Trained batch 283 in epoch 3, gen_loss = 0.40309062851986416, disc_loss = 0.15485711837790803
Trained batch 284 in epoch 3, gen_loss = 0.4030265312445791, disc_loss = 0.15457632412251673
Trained batch 285 in epoch 3, gen_loss = 0.4028218663655795, disc_loss = 0.15468803763233283
Trained batch 286 in epoch 3, gen_loss = 0.40315639266569026, disc_loss = 0.15454635554957058
Trained batch 287 in epoch 3, gen_loss = 0.40329151124589974, disc_loss = 0.15424116922076792
Trained batch 288 in epoch 3, gen_loss = 0.40324258371207955, disc_loss = 0.15410681070186275
Trained batch 289 in epoch 3, gen_loss = 0.40339015927808036, disc_loss = 0.15393903847655346
Trained batch 290 in epoch 3, gen_loss = 0.40331016680628984, disc_loss = 0.1545241168504933
Trained batch 291 in epoch 3, gen_loss = 0.4034852905020322, disc_loss = 0.1545527983227209
Trained batch 292 in epoch 3, gen_loss = 0.4037950972648204, disc_loss = 0.15450119347956806
Trained batch 293 in epoch 3, gen_loss = 0.4037006644367361, disc_loss = 0.1543948702438145
Trained batch 294 in epoch 3, gen_loss = 0.4038166735131862, disc_loss = 0.15420079424472177
Trained batch 295 in epoch 3, gen_loss = 0.40384259809916084, disc_loss = 0.15399989874630765
Trained batch 296 in epoch 3, gen_loss = 0.4038684176475512, disc_loss = 0.15359319409085845
Trained batch 297 in epoch 3, gen_loss = 0.40386427118874235, disc_loss = 0.15335165225469427
Trained batch 298 in epoch 3, gen_loss = 0.4040014226500406, disc_loss = 0.15314866959998838
Trained batch 299 in epoch 3, gen_loss = 0.4041198971867561, disc_loss = 0.15314462039619683
Trained batch 300 in epoch 3, gen_loss = 0.40405189882085174, disc_loss = 0.15315142554846714
Trained batch 301 in epoch 3, gen_loss = 0.4039563597827558, disc_loss = 0.1531759947908438
Trained batch 302 in epoch 3, gen_loss = 0.4038810590312819, disc_loss = 0.15322555059401116
Trained batch 303 in epoch 3, gen_loss = 0.4038826201699282, disc_loss = 0.1536867076800646
Trained batch 304 in epoch 3, gen_loss = 0.4037182040878984, disc_loss = 0.15379836533646116
Trained batch 305 in epoch 3, gen_loss = 0.40381187668033675, disc_loss = 0.15386714298107657
Trained batch 306 in epoch 3, gen_loss = 0.40387621221014264, disc_loss = 0.15386350563323847
Trained batch 307 in epoch 3, gen_loss = 0.4037186032185307, disc_loss = 0.15376451813507003
Trained batch 308 in epoch 3, gen_loss = 0.40377896127191565, disc_loss = 0.15373478172811103
Trained batch 309 in epoch 3, gen_loss = 0.40368259203049445, disc_loss = 0.15364576533677116
Trained batch 310 in epoch 3, gen_loss = 0.4036643059499011, disc_loss = 0.15334553834518053
Trained batch 311 in epoch 3, gen_loss = 0.4036196507513523, disc_loss = 0.15322363037520495
Trained batch 312 in epoch 3, gen_loss = 0.4035544109801515, disc_loss = 0.15294307282271857
Trained batch 313 in epoch 3, gen_loss = 0.4033654854176151, disc_loss = 0.15309584247553423
Trained batch 314 in epoch 3, gen_loss = 0.40317720572153726, disc_loss = 0.1534681056463529
Trained batch 315 in epoch 3, gen_loss = 0.40308250901819787, disc_loss = 0.15349449219677266
Trained batch 316 in epoch 3, gen_loss = 0.40306964178190624, disc_loss = 0.15341018443509982
Trained batch 317 in epoch 3, gen_loss = 0.403104489704348, disc_loss = 0.15372641588438232
Trained batch 318 in epoch 3, gen_loss = 0.4033057244967517, disc_loss = 0.15362427171121196
Trained batch 319 in epoch 3, gen_loss = 0.40310420664027335, disc_loss = 0.15354506531730294
Trained batch 320 in epoch 3, gen_loss = 0.40291639438299376, disc_loss = 0.15335913234596313
Trained batch 321 in epoch 3, gen_loss = 0.40329768911281727, disc_loss = 0.1536541327556468
Trained batch 322 in epoch 3, gen_loss = 0.40300761333929125, disc_loss = 0.1535982277371197
Trained batch 323 in epoch 3, gen_loss = 0.4027188152626709, disc_loss = 0.15379965314526617
Trained batch 324 in epoch 3, gen_loss = 0.4025688991179833, disc_loss = 0.15380931349901053
Trained batch 325 in epoch 3, gen_loss = 0.4025516202844725, disc_loss = 0.15363801988355952
Trained batch 326 in epoch 3, gen_loss = 0.40246321201689017, disc_loss = 0.1539232200894516
Trained batch 327 in epoch 3, gen_loss = 0.40239664348887233, disc_loss = 0.15396066750513343
Trained batch 328 in epoch 3, gen_loss = 0.40249836979303677, disc_loss = 0.1540625649292056
Trained batch 329 in epoch 3, gen_loss = 0.4027409633000692, disc_loss = 0.1540831220420924
Trained batch 330 in epoch 3, gen_loss = 0.40278874747342575, disc_loss = 0.1538755439019275
Trained batch 331 in epoch 3, gen_loss = 0.4029428507369685, disc_loss = 0.153600104848843
Trained batch 332 in epoch 3, gen_loss = 0.4033451176083482, disc_loss = 0.15331964251828623
Trained batch 333 in epoch 3, gen_loss = 0.4035063041541391, disc_loss = 0.15330570314949502
Trained batch 334 in epoch 3, gen_loss = 0.40332686660894707, disc_loss = 0.15338541730793553
Trained batch 335 in epoch 3, gen_loss = 0.4036335438667309, disc_loss = 0.15332989411295525
Trained batch 336 in epoch 3, gen_loss = 0.4040438353307877, disc_loss = 0.1532106762226859
Trained batch 337 in epoch 3, gen_loss = 0.4042696590430638, disc_loss = 0.15308439020706704
Trained batch 338 in epoch 3, gen_loss = 0.4041962235023138, disc_loss = 0.15289578161540285
Trained batch 339 in epoch 3, gen_loss = 0.4040446786319508, disc_loss = 0.15286521954352364
Trained batch 340 in epoch 3, gen_loss = 0.40386332803108127, disc_loss = 0.15285461480098386
Trained batch 341 in epoch 3, gen_loss = 0.4039106346361818, disc_loss = 0.1531742269510937
Trained batch 342 in epoch 3, gen_loss = 0.40405497093937487, disc_loss = 0.15334049695912672
Trained batch 343 in epoch 3, gen_loss = 0.4041112482027952, disc_loss = 0.15375950260001214
Trained batch 344 in epoch 3, gen_loss = 0.4038165844005087, disc_loss = 0.1540609053403571
Trained batch 345 in epoch 3, gen_loss = 0.4035812096099633, disc_loss = 0.1540461354323722
Trained batch 346 in epoch 3, gen_loss = 0.40352930321817093, disc_loss = 0.15414643806193334
Trained batch 347 in epoch 3, gen_loss = 0.4034970772677454, disc_loss = 0.1540627546672677
Trained batch 348 in epoch 3, gen_loss = 0.40350168473741044, disc_loss = 0.1542362498498407
Trained batch 349 in epoch 3, gen_loss = 0.40349333482129235, disc_loss = 0.1541633450878518
Trained batch 350 in epoch 3, gen_loss = 0.4034292179974396, disc_loss = 0.15400459179044448
Trained batch 351 in epoch 3, gen_loss = 0.4033077128062194, disc_loss = 0.1543383645422926
Trained batch 352 in epoch 3, gen_loss = 0.4031389364102069, disc_loss = 0.15445031940134996
Trained batch 353 in epoch 3, gen_loss = 0.4028316458403054, disc_loss = 0.15432770105110385
Trained batch 354 in epoch 3, gen_loss = 0.40290855387566793, disc_loss = 0.1542159510015602
Trained batch 355 in epoch 3, gen_loss = 0.4029656668727318, disc_loss = 0.1545543230002683
Trained batch 356 in epoch 3, gen_loss = 0.40275483739142326, disc_loss = 0.15463275478041472
Trained batch 357 in epoch 3, gen_loss = 0.40279223898935584, disc_loss = 0.15450574167322514
Trained batch 358 in epoch 3, gen_loss = 0.4027396068599563, disc_loss = 0.15441583459133226
Trained batch 359 in epoch 3, gen_loss = 0.4024906856318315, disc_loss = 0.15439890764860642
Trained batch 360 in epoch 3, gen_loss = 0.4024436342584129, disc_loss = 0.15430016862099522
Trained batch 361 in epoch 3, gen_loss = 0.4025143079500831, disc_loss = 0.1543037597583967
Trained batch 362 in epoch 3, gen_loss = 0.40255740851410166, disc_loss = 0.15445700863545592
Trained batch 363 in epoch 3, gen_loss = 0.4025599521758792, disc_loss = 0.15432864522745648
Trained batch 364 in epoch 3, gen_loss = 0.4021516281447998, disc_loss = 0.15440243299897402
Trained batch 365 in epoch 3, gen_loss = 0.40214843917739845, disc_loss = 0.15421606157524664
Trained batch 366 in epoch 3, gen_loss = 0.40198118160466084, disc_loss = 0.15418812117922534
Trained batch 367 in epoch 3, gen_loss = 0.4020130145970894, disc_loss = 0.15399361186174917
Trained batch 368 in epoch 3, gen_loss = 0.4020612838307047, disc_loss = 0.15396192305415948
Trained batch 369 in epoch 3, gen_loss = 0.40214290465857533, disc_loss = 0.15396478610062922
Trained batch 370 in epoch 3, gen_loss = 0.4022391721244771, disc_loss = 0.15369925409997248
Trained batch 371 in epoch 3, gen_loss = 0.4020889970243618, disc_loss = 0.15413518867866005
Trained batch 372 in epoch 3, gen_loss = 0.40205361887852564, disc_loss = 0.15395998400473723
Trained batch 373 in epoch 3, gen_loss = 0.4016463460928616, disc_loss = 0.15416625529567507
Trained batch 374 in epoch 3, gen_loss = 0.4014542644818624, disc_loss = 0.15448108153541884
Trained batch 375 in epoch 3, gen_loss = 0.4015871378335547, disc_loss = 0.1544462171422833
Trained batch 376 in epoch 3, gen_loss = 0.4016601573725278, disc_loss = 0.15439590381888244
Trained batch 377 in epoch 3, gen_loss = 0.4017463015816199, disc_loss = 0.15423008031827748
Trained batch 378 in epoch 3, gen_loss = 0.4016393625170071, disc_loss = 0.15446973968503658
Trained batch 379 in epoch 3, gen_loss = 0.40149599219623366, disc_loss = 0.1543011992091411
Trained batch 380 in epoch 3, gen_loss = 0.40151081200972627, disc_loss = 0.1541266766843677
Trained batch 381 in epoch 3, gen_loss = 0.40137776396973596, disc_loss = 0.1541502345938489
Trained batch 382 in epoch 3, gen_loss = 0.40154407712249157, disc_loss = 0.15415103501073685
Trained batch 383 in epoch 3, gen_loss = 0.401532635713617, disc_loss = 0.15386255825675713
Trained batch 384 in epoch 3, gen_loss = 0.4018612864729646, disc_loss = 0.15353544642785927
Trained batch 385 in epoch 3, gen_loss = 0.4019340332307964, disc_loss = 0.1532122639871632
Trained batch 386 in epoch 3, gen_loss = 0.40182897132804535, disc_loss = 0.15286380141126402
Trained batch 387 in epoch 3, gen_loss = 0.40175338972782354, disc_loss = 0.15276710804283006
Trained batch 388 in epoch 3, gen_loss = 0.40192994207220395, disc_loss = 0.1524859141070003
Trained batch 389 in epoch 3, gen_loss = 0.4021200949564958, disc_loss = 0.15226626495520273
Trained batch 390 in epoch 3, gen_loss = 0.40212880330317463, disc_loss = 0.15218954681969055
Trained batch 391 in epoch 3, gen_loss = 0.4019635803237253, disc_loss = 0.1522554520859706
Trained batch 392 in epoch 3, gen_loss = 0.40204906873120605, disc_loss = 0.15224427991468487
Trained batch 393 in epoch 3, gen_loss = 0.40210506819226416, disc_loss = 0.1521396808477525
Trained batch 394 in epoch 3, gen_loss = 0.40233466127250767, disc_loss = 0.15211830363620685
Trained batch 395 in epoch 3, gen_loss = 0.40239255325962797, disc_loss = 0.15186887337929672
Trained batch 396 in epoch 3, gen_loss = 0.402320785546483, disc_loss = 0.15192984511855268
Trained batch 397 in epoch 3, gen_loss = 0.4023507784059898, disc_loss = 0.1521654922196913
Trained batch 398 in epoch 3, gen_loss = 0.40250706261859504, disc_loss = 0.15215150901772326
Trained batch 399 in epoch 3, gen_loss = 0.40243254482746127, disc_loss = 0.1520150516740978
Trained batch 400 in epoch 3, gen_loss = 0.40263905883429946, disc_loss = 0.15235333666762807
Trained batch 401 in epoch 3, gen_loss = 0.4026307617105655, disc_loss = 0.15231966610942313
Trained batch 402 in epoch 3, gen_loss = 0.40252009278195666, disc_loss = 0.15224538715764252
Trained batch 403 in epoch 3, gen_loss = 0.40256541635435406, disc_loss = 0.15232515657818554
Trained batch 404 in epoch 3, gen_loss = 0.4025230356940517, disc_loss = 0.15227257607527722
Trained batch 405 in epoch 3, gen_loss = 0.4024161193611587, disc_loss = 0.15250706535034578
Trained batch 406 in epoch 3, gen_loss = 0.40232590734226403, disc_loss = 0.1526150131730834
Trained batch 407 in epoch 3, gen_loss = 0.40228208680363264, disc_loss = 0.15243972620616356
Trained batch 408 in epoch 3, gen_loss = 0.4022978920225409, disc_loss = 0.15235709539252562
Trained batch 409 in epoch 3, gen_loss = 0.40224385923001826, disc_loss = 0.15231905601373533
Trained batch 410 in epoch 3, gen_loss = 0.4021984048713443, disc_loss = 0.15243882426670288
Trained batch 411 in epoch 3, gen_loss = 0.4022315246532264, disc_loss = 0.15257756292675306
Trained batch 412 in epoch 3, gen_loss = 0.40215274034920384, disc_loss = 0.15278079485200508
Trained batch 413 in epoch 3, gen_loss = 0.4020056725268203, disc_loss = 0.153164178420956
Trained batch 414 in epoch 3, gen_loss = 0.40204069772398615, disc_loss = 0.15304139531161412
Trained batch 415 in epoch 3, gen_loss = 0.40202313761871594, disc_loss = 0.1532516405881884
Trained batch 416 in epoch 3, gen_loss = 0.40173660479575324, disc_loss = 0.15352771324005057
Trained batch 417 in epoch 3, gen_loss = 0.40160457747119466, disc_loss = 0.15344454626147255
Trained batch 418 in epoch 3, gen_loss = 0.40166949500332016, disc_loss = 0.15332983946316567
Trained batch 419 in epoch 3, gen_loss = 0.401646193365256, disc_loss = 0.15328252947046644
Trained batch 420 in epoch 3, gen_loss = 0.40158011957188966, disc_loss = 0.15313994905727776
Trained batch 421 in epoch 3, gen_loss = 0.401539243157441, disc_loss = 0.15300829263660015
Trained batch 422 in epoch 3, gen_loss = 0.4015653670256865, disc_loss = 0.15285005344707633
Trained batch 423 in epoch 3, gen_loss = 0.40149997568355417, disc_loss = 0.15273748178316174
Trained batch 424 in epoch 3, gen_loss = 0.40158877456889436, disc_loss = 0.15259048929985833
Trained batch 425 in epoch 3, gen_loss = 0.40159693395307927, disc_loss = 0.1526533330095486
Trained batch 426 in epoch 3, gen_loss = 0.40150747073059617, disc_loss = 0.15250176765391085
Trained batch 427 in epoch 3, gen_loss = 0.40132190878981744, disc_loss = 0.1523572755716393
Trained batch 428 in epoch 3, gen_loss = 0.4012170404126316, disc_loss = 0.15236987161400156
Trained batch 429 in epoch 3, gen_loss = 0.4013654150242029, disc_loss = 0.15231108247887257
Trained batch 430 in epoch 3, gen_loss = 0.40135142255548534, disc_loss = 0.15220106481261153
Trained batch 431 in epoch 3, gen_loss = 0.40132699513600933, disc_loss = 0.1522512685990444
Trained batch 432 in epoch 3, gen_loss = 0.4012988100976922, disc_loss = 0.15211573910768258
Trained batch 433 in epoch 3, gen_loss = 0.40141621534176136, disc_loss = 0.152199405850628
Trained batch 434 in epoch 3, gen_loss = 0.4013455903393099, disc_loss = 0.1521796991085184
Trained batch 435 in epoch 3, gen_loss = 0.40128207507483454, disc_loss = 0.15216095455059217
Trained batch 436 in epoch 3, gen_loss = 0.40138017169670875, disc_loss = 0.15200782874151553
Trained batch 437 in epoch 3, gen_loss = 0.4013352977902922, disc_loss = 0.15208549778823438
Trained batch 438 in epoch 3, gen_loss = 0.40131253764406694, disc_loss = 0.15256363372392698
Trained batch 439 in epoch 3, gen_loss = 0.40143888355656104, disc_loss = 0.15259674856947228
Trained batch 440 in epoch 3, gen_loss = 0.4013791428942259, disc_loss = 0.15255508517800004
Trained batch 441 in epoch 3, gen_loss = 0.40135668386701007, disc_loss = 0.1523949074563128
Trained batch 442 in epoch 3, gen_loss = 0.4013331570151697, disc_loss = 0.15230202187130198
Trained batch 443 in epoch 3, gen_loss = 0.40128145769641205, disc_loss = 0.1523481289948429
Trained batch 444 in epoch 3, gen_loss = 0.4013554668828343, disc_loss = 0.15225098136435733
Trained batch 445 in epoch 3, gen_loss = 0.4012135554589498, disc_loss = 0.15223184956296143
Trained batch 446 in epoch 3, gen_loss = 0.4009756971925697, disc_loss = 0.15264575500082916
Trained batch 447 in epoch 3, gen_loss = 0.40107476531660985, disc_loss = 0.15267148367794497
Trained batch 448 in epoch 3, gen_loss = 0.40102022806626386, disc_loss = 0.15248483806052027
Trained batch 449 in epoch 3, gen_loss = 0.4008082061343723, disc_loss = 0.1525241765214337
Trained batch 450 in epoch 3, gen_loss = 0.40078189354513805, disc_loss = 0.1526778132351169
Trained batch 451 in epoch 3, gen_loss = 0.40080329999987, disc_loss = 0.15259714469115818
Trained batch 452 in epoch 3, gen_loss = 0.4006017953749524, disc_loss = 0.15267294531823783
Trained batch 453 in epoch 3, gen_loss = 0.4006550396722844, disc_loss = 0.15280023422338365
Trained batch 454 in epoch 3, gen_loss = 0.400824595611174, disc_loss = 0.15254046266059298
Trained batch 455 in epoch 3, gen_loss = 0.4006541785048811, disc_loss = 0.15251628209003493
Trained batch 456 in epoch 3, gen_loss = 0.40070638490975297, disc_loss = 0.1523278506810999
Trained batch 457 in epoch 3, gen_loss = 0.400575039493465, disc_loss = 0.15215577242904094
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.29440438747406006, disc_loss = 0.10919472575187683
Trained batch 1 in epoch 4, gen_loss = 0.3581436276435852, disc_loss = 0.08791972696781158
Trained batch 2 in epoch 4, gen_loss = 0.384344349304835, disc_loss = 0.09692419071992238
Trained batch 3 in epoch 4, gen_loss = 0.3711656257510185, disc_loss = 0.09181738644838333
Trained batch 4 in epoch 4, gen_loss = 0.37896500825881957, disc_loss = 0.12050849497318268
Trained batch 5 in epoch 4, gen_loss = 0.39796706040700275, disc_loss = 0.13754235953092575
Trained batch 6 in epoch 4, gen_loss = 0.40189605951309204, disc_loss = 0.13870180930410111
Trained batch 7 in epoch 4, gen_loss = 0.3998427279293537, disc_loss = 0.13842689618468285
Trained batch 8 in epoch 4, gen_loss = 0.39896470970577663, disc_loss = 0.13884395526515114
Trained batch 9 in epoch 4, gen_loss = 0.3999121725559235, disc_loss = 0.14031495451927184
Trained batch 10 in epoch 4, gen_loss = 0.39104206453670154, disc_loss = 0.15185097401792352
Trained batch 11 in epoch 4, gen_loss = 0.39321256428956985, disc_loss = 0.14877505972981453
Trained batch 12 in epoch 4, gen_loss = 0.40312655843221223, disc_loss = 0.15162645051112542
Trained batch 13 in epoch 4, gen_loss = 0.40097727732998983, disc_loss = 0.15232682015214646
Trained batch 14 in epoch 4, gen_loss = 0.4001720905303955, disc_loss = 0.14879894107580185
Trained batch 15 in epoch 4, gen_loss = 0.39652983099222183, disc_loss = 0.14507754938676953
Trained batch 16 in epoch 4, gen_loss = 0.3967035815996282, disc_loss = 0.14231922039214304
Trained batch 17 in epoch 4, gen_loss = 0.4039569679233763, disc_loss = 0.13775667630963856
Trained batch 18 in epoch 4, gen_loss = 0.4057539607349195, disc_loss = 0.1349891761415883
Trained batch 19 in epoch 4, gen_loss = 0.40767294615507127, disc_loss = 0.13560879081487656
Trained batch 20 in epoch 4, gen_loss = 0.40868191917737323, disc_loss = 0.13312825986317225
Trained batch 21 in epoch 4, gen_loss = 0.40613084760579193, disc_loss = 0.13195671208880164
Trained batch 22 in epoch 4, gen_loss = 0.4079384311385777, disc_loss = 0.13091274836789007
Trained batch 23 in epoch 4, gen_loss = 0.41104093566536903, disc_loss = 0.13253874455889067
Trained batch 24 in epoch 4, gen_loss = 0.4105664336681366, disc_loss = 0.12988843113183976
Trained batch 25 in epoch 4, gen_loss = 0.4075552901396385, disc_loss = 0.12993317412642333
Trained batch 26 in epoch 4, gen_loss = 0.4049923132967066, disc_loss = 0.13726909541421467
Trained batch 27 in epoch 4, gen_loss = 0.40832287605319706, disc_loss = 0.13443423661270312
Trained batch 28 in epoch 4, gen_loss = 0.4100008627464031, disc_loss = 0.14105435447960063
Trained batch 29 in epoch 4, gen_loss = 0.40839248994986216, disc_loss = 0.13886510270337263
Trained batch 30 in epoch 4, gen_loss = 0.4081466918991458, disc_loss = 0.13857251537903661
Trained batch 31 in epoch 4, gen_loss = 0.40839878004044294, disc_loss = 0.13710687158163637
Trained batch 32 in epoch 4, gen_loss = 0.4074387216206753, disc_loss = 0.14090209601051878
Trained batch 33 in epoch 4, gen_loss = 0.40609925459412965, disc_loss = 0.14263707782854051
Trained batch 34 in epoch 4, gen_loss = 0.40621606366974966, disc_loss = 0.14287143466728075
Trained batch 35 in epoch 4, gen_loss = 0.4056985643174913, disc_loss = 0.14285391558789545
Trained batch 36 in epoch 4, gen_loss = 0.4038254159527856, disc_loss = 0.14421742902816953
Trained batch 37 in epoch 4, gen_loss = 0.4024730246318014, disc_loss = 0.14494808753462216
Trained batch 38 in epoch 4, gen_loss = 0.40226960258606154, disc_loss = 0.1453050622382225
Trained batch 39 in epoch 4, gen_loss = 0.40171645358204844, disc_loss = 0.14445643154904247
Trained batch 40 in epoch 4, gen_loss = 0.4024842672231721, disc_loss = 0.14354575198234582
Trained batch 41 in epoch 4, gen_loss = 0.4017543409551893, disc_loss = 0.14243403760095438
Trained batch 42 in epoch 4, gen_loss = 0.40172723143599753, disc_loss = 0.1422946582180123
Trained batch 43 in epoch 4, gen_loss = 0.40069071271202783, disc_loss = 0.14290150500495324
Trained batch 44 in epoch 4, gen_loss = 0.3988719767994351, disc_loss = 0.1434054776198334
Trained batch 45 in epoch 4, gen_loss = 0.3998074505640113, disc_loss = 0.14314911133893157
Trained batch 46 in epoch 4, gen_loss = 0.39931391464903, disc_loss = 0.14318978572462468
Trained batch 47 in epoch 4, gen_loss = 0.39767180879910785, disc_loss = 0.1439671088786175
Trained batch 48 in epoch 4, gen_loss = 0.3958072273098693, disc_loss = 0.14615843924028532
Trained batch 49 in epoch 4, gen_loss = 0.3980503141880035, disc_loss = 0.14608614332973957
Trained batch 50 in epoch 4, gen_loss = 0.398891793162215, disc_loss = 0.1446429043277806
Trained batch 51 in epoch 4, gen_loss = 0.39719636337115216, disc_loss = 0.14384116225231153
Trained batch 52 in epoch 4, gen_loss = 0.39796466703684824, disc_loss = 0.14471739523534505
Trained batch 53 in epoch 4, gen_loss = 0.3977696868004622, disc_loss = 0.14576440242429575
Trained batch 54 in epoch 4, gen_loss = 0.39887745597145774, disc_loss = 0.1465507495809685
Trained batch 55 in epoch 4, gen_loss = 0.3978540317288467, disc_loss = 0.14810034785685794
Trained batch 56 in epoch 4, gen_loss = 0.3979286420763585, disc_loss = 0.14753620947400728
Trained batch 57 in epoch 4, gen_loss = 0.39827060493929634, disc_loss = 0.14687458111037469
Trained batch 58 in epoch 4, gen_loss = 0.39704354132636116, disc_loss = 0.1468352581358562
Trained batch 59 in epoch 4, gen_loss = 0.39827921936909355, disc_loss = 0.14620649411032596
Trained batch 60 in epoch 4, gen_loss = 0.3988828654171991, disc_loss = 0.14432634901805003
Trained batch 61 in epoch 4, gen_loss = 0.398827810441294, disc_loss = 0.14369993813095555
Trained batch 62 in epoch 4, gen_loss = 0.3993135879910181, disc_loss = 0.14486326998661433
Trained batch 63 in epoch 4, gen_loss = 0.40090178698301315, disc_loss = 0.14565236901398748
Trained batch 64 in epoch 4, gen_loss = 0.4000770004896017, disc_loss = 0.14480138421058655
Trained batch 65 in epoch 4, gen_loss = 0.4006412151184949, disc_loss = 0.14427584443580022
Trained batch 66 in epoch 4, gen_loss = 0.4011723114483392, disc_loss = 0.14358423383378272
Trained batch 67 in epoch 4, gen_loss = 0.4022132259081392, disc_loss = 0.14415055579122374
Trained batch 68 in epoch 4, gen_loss = 0.401858603608781, disc_loss = 0.14343818914199222
Trained batch 69 in epoch 4, gen_loss = 0.40156942563397546, disc_loss = 0.14324914195707866
Trained batch 70 in epoch 4, gen_loss = 0.4010320864093136, disc_loss = 0.14359630938147155
Trained batch 71 in epoch 4, gen_loss = 0.40201499313116074, disc_loss = 0.14312952167044082
Trained batch 72 in epoch 4, gen_loss = 0.40251253484046623, disc_loss = 0.1429517325269033
Trained batch 73 in epoch 4, gen_loss = 0.4038532545437684, disc_loss = 0.1428304593506697
Trained batch 74 in epoch 4, gen_loss = 0.40448254108428955, disc_loss = 0.14212073226769764
Trained batch 75 in epoch 4, gen_loss = 0.4047277914850335, disc_loss = 0.14197060720700966
Trained batch 76 in epoch 4, gen_loss = 0.4044092750394499, disc_loss = 0.14572742794241225
Trained batch 77 in epoch 4, gen_loss = 0.404542041130555, disc_loss = 0.14515069318123353
Trained batch 78 in epoch 4, gen_loss = 0.4043361378621452, disc_loss = 0.14722513435762138
Trained batch 79 in epoch 4, gen_loss = 0.4041724193841219, disc_loss = 0.1483891412615776
Trained batch 80 in epoch 4, gen_loss = 0.4029743358676816, disc_loss = 0.1493975051023342
Trained batch 81 in epoch 4, gen_loss = 0.4016237175319253, disc_loss = 0.1505817629215194
Trained batch 82 in epoch 4, gen_loss = 0.40235520953155424, disc_loss = 0.15111801028251648
Trained batch 83 in epoch 4, gen_loss = 0.40113366004966555, disc_loss = 0.15183071756646746
Trained batch 84 in epoch 4, gen_loss = 0.40139875832725974, disc_loss = 0.15156121429275063
Trained batch 85 in epoch 4, gen_loss = 0.4014524165974107, disc_loss = 0.15337899223316548
Trained batch 86 in epoch 4, gen_loss = 0.40185190822886324, disc_loss = 0.15381654000830378
Trained batch 87 in epoch 4, gen_loss = 0.4012906084006483, disc_loss = 0.1540651512755589
Trained batch 88 in epoch 4, gen_loss = 0.4002738343865684, disc_loss = 0.1540042624044954
Trained batch 89 in epoch 4, gen_loss = 0.400327092077997, disc_loss = 0.15354616824123596
Trained batch 90 in epoch 4, gen_loss = 0.4005517664846483, disc_loss = 0.15368405000849084
Trained batch 91 in epoch 4, gen_loss = 0.4009429138639699, disc_loss = 0.15417450682624526
Trained batch 92 in epoch 4, gen_loss = 0.4001634133759365, disc_loss = 0.15536524323366022
Trained batch 93 in epoch 4, gen_loss = 0.4003225526911147, disc_loss = 0.1550537978715085
Trained batch 94 in epoch 4, gen_loss = 0.4005290050255625, disc_loss = 0.15662058278133995
Trained batch 95 in epoch 4, gen_loss = 0.4010528825844328, disc_loss = 0.15721152226130167
Trained batch 96 in epoch 4, gen_loss = 0.40164367501268683, disc_loss = 0.15696956678149626
Trained batch 97 in epoch 4, gen_loss = 0.39988040969688066, disc_loss = 0.1574792068223564
Trained batch 98 in epoch 4, gen_loss = 0.39922422185690715, disc_loss = 0.15688415037261116
Trained batch 99 in epoch 4, gen_loss = 0.39854127779603005, disc_loss = 0.15693945735692977
Trained batch 100 in epoch 4, gen_loss = 0.3987728671567275, disc_loss = 0.15754135572674252
Trained batch 101 in epoch 4, gen_loss = 0.3990495621281512, disc_loss = 0.15671246586477056
Trained batch 102 in epoch 4, gen_loss = 0.39984481673217515, disc_loss = 0.15679580132359439
Trained batch 103 in epoch 4, gen_loss = 0.3997531932993577, disc_loss = 0.1566222466241855
Trained batch 104 in epoch 4, gen_loss = 0.39939816012268975, disc_loss = 0.15678284764289857
Trained batch 105 in epoch 4, gen_loss = 0.3997052119306798, disc_loss = 0.1563999795548196
Trained batch 106 in epoch 4, gen_loss = 0.4002380896115971, disc_loss = 0.15537645096812291
Trained batch 107 in epoch 4, gen_loss = 0.39994267415669227, disc_loss = 0.15521398069405998
Trained batch 108 in epoch 4, gen_loss = 0.40010868778469366, disc_loss = 0.15535851513300467
Trained batch 109 in epoch 4, gen_loss = 0.39992365390062334, disc_loss = 0.15466391708363186
Trained batch 110 in epoch 4, gen_loss = 0.4003802799695247, disc_loss = 0.1537662126325272
Trained batch 111 in epoch 4, gen_loss = 0.4000935002363154, disc_loss = 0.1533499177146171
Trained batch 112 in epoch 4, gen_loss = 0.40006269171702125, disc_loss = 0.15306280250042942
Trained batch 113 in epoch 4, gen_loss = 0.4000727101637606, disc_loss = 0.15283223999696866
Trained batch 114 in epoch 4, gen_loss = 0.3995545041301976, disc_loss = 0.15336297322874484
Trained batch 115 in epoch 4, gen_loss = 0.3992357314403715, disc_loss = 0.15305056281644722
Trained batch 116 in epoch 4, gen_loss = 0.39908814519389063, disc_loss = 0.15318649981775853
Trained batch 117 in epoch 4, gen_loss = 0.39911865291454024, disc_loss = 0.15312919980388576
Trained batch 118 in epoch 4, gen_loss = 0.3995070844387808, disc_loss = 0.15358090363129848
Trained batch 119 in epoch 4, gen_loss = 0.4004105529437462, disc_loss = 0.1531575679158171
Trained batch 120 in epoch 4, gen_loss = 0.399896004598988, disc_loss = 0.1526073780803641
Trained batch 121 in epoch 4, gen_loss = 0.3995835244899891, disc_loss = 0.15195635504654195
Trained batch 122 in epoch 4, gen_loss = 0.3989529123878091, disc_loss = 0.1517200788589028
Trained batch 123 in epoch 4, gen_loss = 0.3988059397426344, disc_loss = 0.1513221746370677
Trained batch 124 in epoch 4, gen_loss = 0.39875138008594513, disc_loss = 0.1520374466776848
Trained batch 125 in epoch 4, gen_loss = 0.3991969456038778, disc_loss = 0.1517186239361763
Trained batch 126 in epoch 4, gen_loss = 0.3995278422522733, disc_loss = 0.15193929681627769
Trained batch 127 in epoch 4, gen_loss = 0.39890596957411617, disc_loss = 0.15241298591718078
Trained batch 128 in epoch 4, gen_loss = 0.39827826422776363, disc_loss = 0.15347521780997284
Trained batch 129 in epoch 4, gen_loss = 0.39786013192855396, disc_loss = 0.15394239184948114
Trained batch 130 in epoch 4, gen_loss = 0.3979771252124364, disc_loss = 0.1544222541665303
Trained batch 131 in epoch 4, gen_loss = 0.3978504575788975, disc_loss = 0.15462931629383203
Trained batch 132 in epoch 4, gen_loss = 0.39774943103915766, disc_loss = 0.15426846235094213
Trained batch 133 in epoch 4, gen_loss = 0.3975259113445211, disc_loss = 0.15411897854351286
Trained batch 134 in epoch 4, gen_loss = 0.39740499114548716, disc_loss = 0.15414633690207094
Trained batch 135 in epoch 4, gen_loss = 0.3970627678448663, disc_loss = 0.15458828742232392
Trained batch 136 in epoch 4, gen_loss = 0.39736154381811184, disc_loss = 0.15519209396447578
Trained batch 137 in epoch 4, gen_loss = 0.39778276100970694, disc_loss = 0.1549098214161569
Trained batch 138 in epoch 4, gen_loss = 0.39774611560132006, disc_loss = 0.1543827105661948
Trained batch 139 in epoch 4, gen_loss = 0.3974666668900422, disc_loss = 0.1543968167155981
Trained batch 140 in epoch 4, gen_loss = 0.39702164038275994, disc_loss = 0.15422405276104068
Trained batch 141 in epoch 4, gen_loss = 0.39714902272106894, disc_loss = 0.15396835439851586
Trained batch 142 in epoch 4, gen_loss = 0.39794836563247066, disc_loss = 0.15390863936472607
Trained batch 143 in epoch 4, gen_loss = 0.39752274968971807, disc_loss = 0.15314938027101258
Trained batch 144 in epoch 4, gen_loss = 0.3974389991883574, disc_loss = 0.15385384315560605
Trained batch 145 in epoch 4, gen_loss = 0.3981672920388718, disc_loss = 0.15513646258168842
Trained batch 146 in epoch 4, gen_loss = 0.39872908359076703, disc_loss = 0.15471334950554938
Trained batch 147 in epoch 4, gen_loss = 0.3985789074889711, disc_loss = 0.1561460593916677
Trained batch 148 in epoch 4, gen_loss = 0.3989934200208459, disc_loss = 0.15597112119297854
Trained batch 149 in epoch 4, gen_loss = 0.3990322362383207, disc_loss = 0.15571382460494837
Trained batch 150 in epoch 4, gen_loss = 0.3985447424729139, disc_loss = 0.155576000125795
Trained batch 151 in epoch 4, gen_loss = 0.3976242329533163, disc_loss = 0.15603289348808558
Trained batch 152 in epoch 4, gen_loss = 0.3983188722453086, disc_loss = 0.15554853774655877
Trained batch 153 in epoch 4, gen_loss = 0.39837502417239273, disc_loss = 0.15583330506531448
Trained batch 154 in epoch 4, gen_loss = 0.3986548657378843, disc_loss = 0.1551785247220147
Trained batch 155 in epoch 4, gen_loss = 0.3989757942274595, disc_loss = 0.15495532973167989
Trained batch 156 in epoch 4, gen_loss = 0.399697353221049, disc_loss = 0.1544893824608083
Trained batch 157 in epoch 4, gen_loss = 0.3996360333094114, disc_loss = 0.15467103063777277
Trained batch 158 in epoch 4, gen_loss = 0.3997428403148111, disc_loss = 0.15528793785275904
Trained batch 159 in epoch 4, gen_loss = 0.40005366830155253, disc_loss = 0.15532921312842518
Trained batch 160 in epoch 4, gen_loss = 0.40047181124642767, disc_loss = 0.15491629380339422
Trained batch 161 in epoch 4, gen_loss = 0.4010976610912217, disc_loss = 0.15473270317378604
Trained batch 162 in epoch 4, gen_loss = 0.40096039466697014, disc_loss = 0.15475234327597853
Trained batch 163 in epoch 4, gen_loss = 0.4003321095029028, disc_loss = 0.15526767368087682
Trained batch 164 in epoch 4, gen_loss = 0.4000423370888739, disc_loss = 0.15528952517744266
Trained batch 165 in epoch 4, gen_loss = 0.40002637643771, disc_loss = 0.1551214069891048
Trained batch 166 in epoch 4, gen_loss = 0.40042421230655945, disc_loss = 0.15511798289810827
Trained batch 167 in epoch 4, gen_loss = 0.4000375284148114, disc_loss = 0.15510566197779208
Trained batch 168 in epoch 4, gen_loss = 0.40019713765418036, disc_loss = 0.15497551622563566
Trained batch 169 in epoch 4, gen_loss = 0.40015018433332444, disc_loss = 0.1547318400486427
Trained batch 170 in epoch 4, gen_loss = 0.4003145990141651, disc_loss = 0.15463627619962944
Trained batch 171 in epoch 4, gen_loss = 0.4002423107104246, disc_loss = 0.15432627250028905
Trained batch 172 in epoch 4, gen_loss = 0.40019880252421935, disc_loss = 0.15427609737639483
Trained batch 173 in epoch 4, gen_loss = 0.4005453530913112, disc_loss = 0.15380875383043427
Trained batch 174 in epoch 4, gen_loss = 0.40034131126744404, disc_loss = 0.15330707126430101
Trained batch 175 in epoch 4, gen_loss = 0.40004237851297314, disc_loss = 0.15316182664934208
Trained batch 176 in epoch 4, gen_loss = 0.4000961629852737, disc_loss = 0.1530960183906353
Trained batch 177 in epoch 4, gen_loss = 0.40047883476768986, disc_loss = 0.1528434274362379
Trained batch 178 in epoch 4, gen_loss = 0.4003628951044722, disc_loss = 0.15264845720632783
Trained batch 179 in epoch 4, gen_loss = 0.40076052670677503, disc_loss = 0.15227830912917853
Trained batch 180 in epoch 4, gen_loss = 0.40011485810108605, disc_loss = 0.15250230245086369
Trained batch 181 in epoch 4, gen_loss = 0.3996373060476649, disc_loss = 0.1523463264885512
Trained batch 182 in epoch 4, gen_loss = 0.3997180588095566, disc_loss = 0.15237439865541588
Trained batch 183 in epoch 4, gen_loss = 0.39946924158088537, disc_loss = 0.15197589246394194
Trained batch 184 in epoch 4, gen_loss = 0.39966374563204277, disc_loss = 0.15138841436521427
Trained batch 185 in epoch 4, gen_loss = 0.39979850468776557, disc_loss = 0.1508684019528089
Trained batch 186 in epoch 4, gen_loss = 0.3996404035684259, disc_loss = 0.1504855425878961
Trained batch 187 in epoch 4, gen_loss = 0.3994128719130729, disc_loss = 0.15029037892422142
Trained batch 188 in epoch 4, gen_loss = 0.39917780663916674, disc_loss = 0.15000151277140336
Trained batch 189 in epoch 4, gen_loss = 0.3993873887156185, disc_loss = 0.14964969383650703
Trained batch 190 in epoch 4, gen_loss = 0.3990523102863921, disc_loss = 0.14979994123440762
Trained batch 191 in epoch 4, gen_loss = 0.39912715593042475, disc_loss = 0.1496394084339651
Trained batch 192 in epoch 4, gen_loss = 0.39946570583266916, disc_loss = 0.1492553640716743
Trained batch 193 in epoch 4, gen_loss = 0.3996208999113938, disc_loss = 0.14890968405939253
Trained batch 194 in epoch 4, gen_loss = 0.3993975615654236, disc_loss = 0.1486414940120318
Trained batch 195 in epoch 4, gen_loss = 0.399508606490432, disc_loss = 0.14837431149291141
Trained batch 196 in epoch 4, gen_loss = 0.3991956151832784, disc_loss = 0.14816256553917972
Trained batch 197 in epoch 4, gen_loss = 0.39910366747415427, disc_loss = 0.14785240404307842
Trained batch 198 in epoch 4, gen_loss = 0.3990447779546431, disc_loss = 0.1478316166330522
Trained batch 199 in epoch 4, gen_loss = 0.3990838309377432, disc_loss = 0.14782783763483168
Trained batch 200 in epoch 4, gen_loss = 0.3996202476433854, disc_loss = 0.1476461029801499
Trained batch 201 in epoch 4, gen_loss = 0.39969220809122125, disc_loss = 0.14742966378015457
Trained batch 202 in epoch 4, gen_loss = 0.39933297617975716, disc_loss = 0.14713339608511314
Trained batch 203 in epoch 4, gen_loss = 0.39930637714033035, disc_loss = 0.14725834421594353
Trained batch 204 in epoch 4, gen_loss = 0.3995893176735901, disc_loss = 0.14685245543354894
Trained batch 205 in epoch 4, gen_loss = 0.4001741201698201, disc_loss = 0.14672148547777272
Trained batch 206 in epoch 4, gen_loss = 0.40049045536541134, disc_loss = 0.14683612002338764
Trained batch 207 in epoch 4, gen_loss = 0.4003933992666694, disc_loss = 0.1471983223186376
Trained batch 208 in epoch 4, gen_loss = 0.40037042209121027, disc_loss = 0.14680615104913142
Trained batch 209 in epoch 4, gen_loss = 0.40020973618541444, disc_loss = 0.14653691360283466
Trained batch 210 in epoch 4, gen_loss = 0.40022922176602893, disc_loss = 0.1463760285333717
Trained batch 211 in epoch 4, gen_loss = 0.40098250186387097, disc_loss = 0.14671298413414438
Trained batch 212 in epoch 4, gen_loss = 0.40051952291262544, disc_loss = 0.14707302531236213
Trained batch 213 in epoch 4, gen_loss = 0.40027467565280256, disc_loss = 0.14692724978324967
Trained batch 214 in epoch 4, gen_loss = 0.40025444703046664, disc_loss = 0.14706408362402473
Trained batch 215 in epoch 4, gen_loss = 0.4005052221732007, disc_loss = 0.14707984694245238
Trained batch 216 in epoch 4, gen_loss = 0.4003335349433433, disc_loss = 0.14692629676329375
Trained batch 217 in epoch 4, gen_loss = 0.4004133714858545, disc_loss = 0.14670574550576712
Trained batch 218 in epoch 4, gen_loss = 0.4002384606697788, disc_loss = 0.14682500787317482
Trained batch 219 in epoch 4, gen_loss = 0.4004633791744709, disc_loss = 0.14698175647380676
Trained batch 220 in epoch 4, gen_loss = 0.40052191656908837, disc_loss = 0.14676952761560005
Trained batch 221 in epoch 4, gen_loss = 0.40053605341965015, disc_loss = 0.14694294549927517
Trained batch 222 in epoch 4, gen_loss = 0.4008562967782598, disc_loss = 0.14691279863629642
Trained batch 223 in epoch 4, gen_loss = 0.4005723062769643, disc_loss = 0.14668203373106994
Trained batch 224 in epoch 4, gen_loss = 0.40034643974569106, disc_loss = 0.14649559542536736
Trained batch 225 in epoch 4, gen_loss = 0.40031684888938884, disc_loss = 0.14621168782159819
Trained batch 226 in epoch 4, gen_loss = 0.4004760251302551, disc_loss = 0.1459840902902744
Trained batch 227 in epoch 4, gen_loss = 0.4004692804525819, disc_loss = 0.14580489539851746
Trained batch 228 in epoch 4, gen_loss = 0.40069890497293015, disc_loss = 0.1459474040593903
Trained batch 229 in epoch 4, gen_loss = 0.40066057670375577, disc_loss = 0.14706099242295909
Trained batch 230 in epoch 4, gen_loss = 0.400629958484596, disc_loss = 0.1469627728613166
Trained batch 231 in epoch 4, gen_loss = 0.40085961149427396, disc_loss = 0.146992616178789
Trained batch 232 in epoch 4, gen_loss = 0.4010195762174836, disc_loss = 0.14751043309789358
Trained batch 233 in epoch 4, gen_loss = 0.4009408000060636, disc_loss = 0.14744790237492475
Trained batch 234 in epoch 4, gen_loss = 0.40103650378419997, disc_loss = 0.14759783321555625
Trained batch 235 in epoch 4, gen_loss = 0.4008915046135248, disc_loss = 0.14800087383048513
Trained batch 236 in epoch 4, gen_loss = 0.40124492938256967, disc_loss = 0.14761358928642695
Trained batch 237 in epoch 4, gen_loss = 0.4014061757621645, disc_loss = 0.1477300666366555
Trained batch 238 in epoch 4, gen_loss = 0.40133282972429585, disc_loss = 0.1477775865674767
Trained batch 239 in epoch 4, gen_loss = 0.40106623178968825, disc_loss = 0.14789938884787263
Trained batch 240 in epoch 4, gen_loss = 0.4011199727221643, disc_loss = 0.14783854512072697
Trained batch 241 in epoch 4, gen_loss = 0.40129734495700886, disc_loss = 0.14751339412856201
Trained batch 242 in epoch 4, gen_loss = 0.40125823149710527, disc_loss = 0.1472942687019154
Trained batch 243 in epoch 4, gen_loss = 0.4010881475615697, disc_loss = 0.14719785537692856
Trained batch 244 in epoch 4, gen_loss = 0.40107029937967964, disc_loss = 0.14712744733812858
Trained batch 245 in epoch 4, gen_loss = 0.40101151913404465, disc_loss = 0.1469198946757772
Trained batch 246 in epoch 4, gen_loss = 0.4012575424031207, disc_loss = 0.14680855059129025
Trained batch 247 in epoch 4, gen_loss = 0.4014002892879709, disc_loss = 0.14647533184277914
Trained batch 248 in epoch 4, gen_loss = 0.40129751786888845, disc_loss = 0.1460914550326675
Trained batch 249 in epoch 4, gen_loss = 0.4014040114283562, disc_loss = 0.14608436669409275
Trained batch 250 in epoch 4, gen_loss = 0.40146792273359944, disc_loss = 0.1458944600090325
Trained batch 251 in epoch 4, gen_loss = 0.40148277764046003, disc_loss = 0.1457726765453579
Trained batch 252 in epoch 4, gen_loss = 0.4007347557148915, disc_loss = 0.14617229319313768
Trained batch 253 in epoch 4, gen_loss = 0.4004409725037147, disc_loss = 0.14586922202229968
Trained batch 254 in epoch 4, gen_loss = 0.40041469990038403, disc_loss = 0.1459644485776331
Trained batch 255 in epoch 4, gen_loss = 0.4002273518126458, disc_loss = 0.14615951727319043
Trained batch 256 in epoch 4, gen_loss = 0.4000024943964027, disc_loss = 0.1461031076712135
Trained batch 257 in epoch 4, gen_loss = 0.400048856587373, disc_loss = 0.14610568802197313
Trained batch 258 in epoch 4, gen_loss = 0.40035582313666473, disc_loss = 0.14598648582358617
Trained batch 259 in epoch 4, gen_loss = 0.40063432982334723, disc_loss = 0.14580914078710172
Trained batch 260 in epoch 4, gen_loss = 0.40096156567449315, disc_loss = 0.1455649076550628
Trained batch 261 in epoch 4, gen_loss = 0.40101085079990273, disc_loss = 0.14552220100721786
Trained batch 262 in epoch 4, gen_loss = 0.400602899916725, disc_loss = 0.1453363985644774
Trained batch 263 in epoch 4, gen_loss = 0.40074131581367867, disc_loss = 0.14555476759701516
Trained batch 264 in epoch 4, gen_loss = 0.4013125589433706, disc_loss = 0.14569278253980403
Trained batch 265 in epoch 4, gen_loss = 0.4013040163239142, disc_loss = 0.14546347391280465
Trained batch 266 in epoch 4, gen_loss = 0.4014966060383043, disc_loss = 0.14636273351445628
Trained batch 267 in epoch 4, gen_loss = 0.40187192129999844, disc_loss = 0.1461405813443794
Trained batch 268 in epoch 4, gen_loss = 0.4018252229380342, disc_loss = 0.14609603172507427
Trained batch 269 in epoch 4, gen_loss = 0.4017127964231703, disc_loss = 0.14597188674465375
Trained batch 270 in epoch 4, gen_loss = 0.4019490948902285, disc_loss = 0.14622678675059902
Trained batch 271 in epoch 4, gen_loss = 0.4016795537489302, disc_loss = 0.1461382188478156
Trained batch 272 in epoch 4, gen_loss = 0.4014832588124188, disc_loss = 0.14617654977318567
Trained batch 273 in epoch 4, gen_loss = 0.4014387125298925, disc_loss = 0.1464386787537458
Trained batch 274 in epoch 4, gen_loss = 0.4014303505420685, disc_loss = 0.14624890491366385
Trained batch 275 in epoch 4, gen_loss = 0.4013950541831445, disc_loss = 0.14639540757659986
Trained batch 276 in epoch 4, gen_loss = 0.4012221968346124, disc_loss = 0.14630979166403144
Trained batch 277 in epoch 4, gen_loss = 0.40113605526711443, disc_loss = 0.1461587990868649
Trained batch 278 in epoch 4, gen_loss = 0.40086302193262247, disc_loss = 0.14587277741468507
Trained batch 279 in epoch 4, gen_loss = 0.4005695346210684, disc_loss = 0.14617313988772887
Trained batch 280 in epoch 4, gen_loss = 0.40095210913237306, disc_loss = 0.14621233511914986
Trained batch 281 in epoch 4, gen_loss = 0.40081642631520614, disc_loss = 0.14623332838692987
Trained batch 282 in epoch 4, gen_loss = 0.40073941737518715, disc_loss = 0.14623091131606708
Trained batch 283 in epoch 4, gen_loss = 0.4008186454294433, disc_loss = 0.14593128284150866
Trained batch 284 in epoch 4, gen_loss = 0.4006915315201408, disc_loss = 0.1462681700393819
Trained batch 285 in epoch 4, gen_loss = 0.4008008263536266, disc_loss = 0.14640397663143548
Trained batch 286 in epoch 4, gen_loss = 0.4008265596648957, disc_loss = 0.1462577605938039
Trained batch 287 in epoch 4, gen_loss = 0.400916844399439, disc_loss = 0.1462169078618495
Trained batch 288 in epoch 4, gen_loss = 0.4008562986619745, disc_loss = 0.14621419355170123
Trained batch 289 in epoch 4, gen_loss = 0.4013732146600197, disc_loss = 0.14610145458116613
Trained batch 290 in epoch 4, gen_loss = 0.4014051785993412, disc_loss = 0.14589394225748545
Trained batch 291 in epoch 4, gen_loss = 0.4014419812249811, disc_loss = 0.14611558040782605
Trained batch 292 in epoch 4, gen_loss = 0.4017519089345639, disc_loss = 0.1465234172247579
Trained batch 293 in epoch 4, gen_loss = 0.4016001485034722, disc_loss = 0.14635819471662953
Trained batch 294 in epoch 4, gen_loss = 0.4017420418181662, disc_loss = 0.14649323893047997
Trained batch 295 in epoch 4, gen_loss = 0.40193000969451825, disc_loss = 0.14636012824957031
Trained batch 296 in epoch 4, gen_loss = 0.40198475905139036, disc_loss = 0.14637244137800504
Trained batch 297 in epoch 4, gen_loss = 0.4019207693386398, disc_loss = 0.14642582372480992
Trained batch 298 in epoch 4, gen_loss = 0.40205182498912745, disc_loss = 0.1462325523903338
Trained batch 299 in epoch 4, gen_loss = 0.40189723889033, disc_loss = 0.1459433835496505
Trained batch 300 in epoch 4, gen_loss = 0.4019315452670734, disc_loss = 0.14621286225378316
Trained batch 301 in epoch 4, gen_loss = 0.40194219745547566, disc_loss = 0.14615306339615228
Trained batch 302 in epoch 4, gen_loss = 0.4019339900008916, disc_loss = 0.1460281085751631
Trained batch 303 in epoch 4, gen_loss = 0.40190506108889457, disc_loss = 0.14628258048507728
Trained batch 304 in epoch 4, gen_loss = 0.4018828996869384, disc_loss = 0.14647940118781855
Trained batch 305 in epoch 4, gen_loss = 0.40172646111912197, disc_loss = 0.146589489690229
Trained batch 306 in epoch 4, gen_loss = 0.40163502048591837, disc_loss = 0.1465623375841383
Trained batch 307 in epoch 4, gen_loss = 0.4014662548706129, disc_loss = 0.1465699818323959
Trained batch 308 in epoch 4, gen_loss = 0.401329901804816, disc_loss = 0.14645621954526716
Trained batch 309 in epoch 4, gen_loss = 0.4012075258839515, disc_loss = 0.14651754121145893
Trained batch 310 in epoch 4, gen_loss = 0.4008910777676144, disc_loss = 0.14643293911429464
Trained batch 311 in epoch 4, gen_loss = 0.40042740154342776, disc_loss = 0.14636701999757534
Trained batch 312 in epoch 4, gen_loss = 0.4002217771336674, disc_loss = 0.146219830472058
Trained batch 313 in epoch 4, gen_loss = 0.4004485300581926, disc_loss = 0.14605317682407465
Trained batch 314 in epoch 4, gen_loss = 0.40054191644229586, disc_loss = 0.14632325768470764
Trained batch 315 in epoch 4, gen_loss = 0.40047758204650274, disc_loss = 0.14621097278557246
Trained batch 316 in epoch 4, gen_loss = 0.4004327572106563, disc_loss = 0.14612672170065932
Trained batch 317 in epoch 4, gen_loss = 0.40038544333206033, disc_loss = 0.14597545123700076
Trained batch 318 in epoch 4, gen_loss = 0.4003363435731786, disc_loss = 0.14601865621009216
Trained batch 319 in epoch 4, gen_loss = 0.4002105830237269, disc_loss = 0.14648564183153212
Trained batch 320 in epoch 4, gen_loss = 0.40040305386822544, disc_loss = 0.1466806163761846
Trained batch 321 in epoch 4, gen_loss = 0.40021587806458797, disc_loss = 0.1467608621124155
Trained batch 322 in epoch 4, gen_loss = 0.4000875846520297, disc_loss = 0.14739076876234344
Trained batch 323 in epoch 4, gen_loss = 0.4004276932021718, disc_loss = 0.14753198407498408
Trained batch 324 in epoch 4, gen_loss = 0.4001269280910492, disc_loss = 0.1473310911655426
Trained batch 325 in epoch 4, gen_loss = 0.4002683158118301, disc_loss = 0.14750766708441307
Trained batch 326 in epoch 4, gen_loss = 0.4003637124092207, disc_loss = 0.14783129405902432
Trained batch 327 in epoch 4, gen_loss = 0.400421561355271, disc_loss = 0.1478114813202765
Trained batch 328 in epoch 4, gen_loss = 0.40034003270433305, disc_loss = 0.14786047834936972
Trained batch 329 in epoch 4, gen_loss = 0.40021400316195055, disc_loss = 0.1479528581102689
Trained batch 330 in epoch 4, gen_loss = 0.40006727358365707, disc_loss = 0.14797184429500038
Trained batch 331 in epoch 4, gen_loss = 0.3998625418507909, disc_loss = 0.14794148859309864
Trained batch 332 in epoch 4, gen_loss = 0.3999554695667805, disc_loss = 0.14785637610309474
Trained batch 333 in epoch 4, gen_loss = 0.39985629719888377, disc_loss = 0.14780824885753815
Trained batch 334 in epoch 4, gen_loss = 0.4000351134520858, disc_loss = 0.14790687222978963
Trained batch 335 in epoch 4, gen_loss = 0.40011676622643355, disc_loss = 0.14830069944617294
Trained batch 336 in epoch 4, gen_loss = 0.3999139157176371, disc_loss = 0.14864542585098425
Trained batch 337 in epoch 4, gen_loss = 0.40010825443197284, disc_loss = 0.148444154316328
Trained batch 338 in epoch 4, gen_loss = 0.399946486176291, disc_loss = 0.14845092082533512
Trained batch 339 in epoch 4, gen_loss = 0.40005437232115687, disc_loss = 0.1483599951162058
Trained batch 340 in epoch 4, gen_loss = 0.3998569923062478, disc_loss = 0.1483339322102734
Trained batch 341 in epoch 4, gen_loss = 0.399806148824636, disc_loss = 0.14859513842571548
Trained batch 342 in epoch 4, gen_loss = 0.39975983721174235, disc_loss = 0.1486810817662898
Trained batch 343 in epoch 4, gen_loss = 0.3996486007127651, disc_loss = 0.14863087864982527
Trained batch 344 in epoch 4, gen_loss = 0.39972705029059147, disc_loss = 0.14862249713876974
Trained batch 345 in epoch 4, gen_loss = 0.3996631259346284, disc_loss = 0.1485804732393667
Trained batch 346 in epoch 4, gen_loss = 0.39972024949895546, disc_loss = 0.1484182279245654
Trained batch 347 in epoch 4, gen_loss = 0.3997081011191182, disc_loss = 0.14833901966012072
Trained batch 348 in epoch 4, gen_loss = 0.3996681099634799, disc_loss = 0.14841306621587722
Trained batch 349 in epoch 4, gen_loss = 0.399729072536741, disc_loss = 0.14831083197678838
Trained batch 350 in epoch 4, gen_loss = 0.3998672917188063, disc_loss = 0.14819290996277096
Trained batch 351 in epoch 4, gen_loss = 0.3996398062021895, disc_loss = 0.1487544940953905
Trained batch 352 in epoch 4, gen_loss = 0.3997282614620144, disc_loss = 0.14900479248326493
Trained batch 353 in epoch 4, gen_loss = 0.3998499800593166, disc_loss = 0.14896834405970438
Trained batch 354 in epoch 4, gen_loss = 0.3998812048368051, disc_loss = 0.14934445640570682
Trained batch 355 in epoch 4, gen_loss = 0.40004286973663933, disc_loss = 0.1492504955928647
Trained batch 356 in epoch 4, gen_loss = 0.39990657693197745, disc_loss = 0.14940573763446646
Trained batch 357 in epoch 4, gen_loss = 0.39967951511537564, disc_loss = 0.1497587696467032
Trained batch 358 in epoch 4, gen_loss = 0.3994816431262035, disc_loss = 0.149690618920127
Trained batch 359 in epoch 4, gen_loss = 0.39948398917913436, disc_loss = 0.14955027179999483
Trained batch 360 in epoch 4, gen_loss = 0.3994700703099164, disc_loss = 0.1496015692392875
Trained batch 361 in epoch 4, gen_loss = 0.39940653617869426, disc_loss = 0.14968207867517655
Trained batch 362 in epoch 4, gen_loss = 0.399153685274203, disc_loss = 0.14968755186507196
Trained batch 363 in epoch 4, gen_loss = 0.39913904871586914, disc_loss = 0.14957104686770464
Trained batch 364 in epoch 4, gen_loss = 0.39920270075536757, disc_loss = 0.1494874741933117
Trained batch 365 in epoch 4, gen_loss = 0.3993074287319444, disc_loss = 0.14938033881083213
Trained batch 366 in epoch 4, gen_loss = 0.39928731078672797, disc_loss = 0.14938853104530303
Trained batch 367 in epoch 4, gen_loss = 0.3993861166679341, disc_loss = 0.14948609378188848
Trained batch 368 in epoch 4, gen_loss = 0.3993192391020819, disc_loss = 0.1492873134046066
Trained batch 369 in epoch 4, gen_loss = 0.39905675746299124, disc_loss = 0.14936347932026192
Trained batch 370 in epoch 4, gen_loss = 0.39906027840796826, disc_loss = 0.14958693490757774
Trained batch 371 in epoch 4, gen_loss = 0.39913366102082753, disc_loss = 0.14952465813727148
Trained batch 372 in epoch 4, gen_loss = 0.3996173709870663, disc_loss = 0.14934872532258406
Trained batch 373 in epoch 4, gen_loss = 0.39954438813548676, disc_loss = 0.1490904737044783
Trained batch 374 in epoch 4, gen_loss = 0.39936161986986796, disc_loss = 0.14928322207927705
Trained batch 375 in epoch 4, gen_loss = 0.39948958863920353, disc_loss = 0.14930362896399296
Trained batch 376 in epoch 4, gen_loss = 0.3995389894876303, disc_loss = 0.14909557780789442
Trained batch 377 in epoch 4, gen_loss = 0.3995456440896584, disc_loss = 0.14897861315932853
Trained batch 378 in epoch 4, gen_loss = 0.39941746334601835, disc_loss = 0.14893765841908066
Trained batch 379 in epoch 4, gen_loss = 0.3994360220275427, disc_loss = 0.14911616824959453
Trained batch 380 in epoch 4, gen_loss = 0.39979386916310766, disc_loss = 0.14886410792512217
Trained batch 381 in epoch 4, gen_loss = 0.4000387800301557, disc_loss = 0.1487255292062048
Trained batch 382 in epoch 4, gen_loss = 0.3999599768505395, disc_loss = 0.1488571637176347
Trained batch 383 in epoch 4, gen_loss = 0.3999935609754175, disc_loss = 0.14866248931502923
Trained batch 384 in epoch 4, gen_loss = 0.39999701094317747, disc_loss = 0.14860080215451005
Trained batch 385 in epoch 4, gen_loss = 0.40007375860152466, disc_loss = 0.1485016035601265
Trained batch 386 in epoch 4, gen_loss = 0.40030993132320175, disc_loss = 0.14831995998704156
Trained batch 387 in epoch 4, gen_loss = 0.40034344523530646, disc_loss = 0.14824018062850863
Trained batch 388 in epoch 4, gen_loss = 0.4004540663298727, disc_loss = 0.14799777471046216
Trained batch 389 in epoch 4, gen_loss = 0.4005930490218676, disc_loss = 0.14819374081607048
Trained batch 390 in epoch 4, gen_loss = 0.4009144335908963, disc_loss = 0.14822963818602855
Trained batch 391 in epoch 4, gen_loss = 0.4010741623992823, disc_loss = 0.14811000586202255
Trained batch 392 in epoch 4, gen_loss = 0.4009670941277618, disc_loss = 0.1481965299951666
Trained batch 393 in epoch 4, gen_loss = 0.40094561988327104, disc_loss = 0.14867802823747173
Trained batch 394 in epoch 4, gen_loss = 0.40098658739765985, disc_loss = 0.1492368002198165
Trained batch 395 in epoch 4, gen_loss = 0.40079615212450126, disc_loss = 0.14936782699078321
Trained batch 396 in epoch 4, gen_loss = 0.4008247106141347, disc_loss = 0.14949553320067055
Trained batch 397 in epoch 4, gen_loss = 0.4007739754178416, disc_loss = 0.14974314192469096
Trained batch 398 in epoch 4, gen_loss = 0.400697919733841, disc_loss = 0.1495942995232299
Trained batch 399 in epoch 4, gen_loss = 0.4008491580188274, disc_loss = 0.1496048077289015
Trained batch 400 in epoch 4, gen_loss = 0.4008772988569112, disc_loss = 0.1495183001822813
Trained batch 401 in epoch 4, gen_loss = 0.4007848730282997, disc_loss = 0.1495737764910234
Trained batch 402 in epoch 4, gen_loss = 0.40102108839723666, disc_loss = 0.1494678928616177
Trained batch 403 in epoch 4, gen_loss = 0.40097530023886424, disc_loss = 0.14934200231944866
Trained batch 404 in epoch 4, gen_loss = 0.40100074734216856, disc_loss = 0.14924107695251335
Trained batch 405 in epoch 4, gen_loss = 0.40097056145738497, disc_loss = 0.14918849886087654
Trained batch 406 in epoch 4, gen_loss = 0.400896881150965, disc_loss = 0.14908392547059995
Trained batch 407 in epoch 4, gen_loss = 0.4009445248281254, disc_loss = 0.14891645483051738
Trained batch 408 in epoch 4, gen_loss = 0.40089614335948504, disc_loss = 0.14877416385670164
Trained batch 409 in epoch 4, gen_loss = 0.4009222226898845, disc_loss = 0.14879289446625768
Trained batch 410 in epoch 4, gen_loss = 0.4008311358101467, disc_loss = 0.1488871606941496
Trained batch 411 in epoch 4, gen_loss = 0.40094356354579186, disc_loss = 0.149101641164749
Trained batch 412 in epoch 4, gen_loss = 0.4009709880657981, disc_loss = 0.148928069777913
Trained batch 413 in epoch 4, gen_loss = 0.40073871468576255, disc_loss = 0.1488460134534876
Trained batch 414 in epoch 4, gen_loss = 0.4006014865565013, disc_loss = 0.14887545190482254
Trained batch 415 in epoch 4, gen_loss = 0.400690826229178, disc_loss = 0.14912892056879803
Trained batch 416 in epoch 4, gen_loss = 0.4005866546710904, disc_loss = 0.14922909158989967
Trained batch 417 in epoch 4, gen_loss = 0.40061628961106804, disc_loss = 0.149248208039614
Trained batch 418 in epoch 4, gen_loss = 0.400542165612833, disc_loss = 0.14907115378677133
Trained batch 419 in epoch 4, gen_loss = 0.4004504657927014, disc_loss = 0.1491061847568268
Trained batch 420 in epoch 4, gen_loss = 0.4005552278278559, disc_loss = 0.14898767832870155
Trained batch 421 in epoch 4, gen_loss = 0.4005740370371895, disc_loss = 0.14893693260636656
Trained batch 422 in epoch 4, gen_loss = 0.4003632971862811, disc_loss = 0.1488575124342532
Trained batch 423 in epoch 4, gen_loss = 0.4004054458917312, disc_loss = 0.1487346141915417
Trained batch 424 in epoch 4, gen_loss = 0.40052423042409563, disc_loss = 0.14883882839013549
Trained batch 425 in epoch 4, gen_loss = 0.40034389894613076, disc_loss = 0.14882230294317428
Trained batch 426 in epoch 4, gen_loss = 0.4002775956791514, disc_loss = 0.14868909182502457
Trained batch 427 in epoch 4, gen_loss = 0.4003512371923322, disc_loss = 0.14862801443576534
Trained batch 428 in epoch 4, gen_loss = 0.4003583244232587, disc_loss = 0.14856371261822038
Trained batch 429 in epoch 4, gen_loss = 0.40010864180187844, disc_loss = 0.14866603508071843
Trained batch 430 in epoch 4, gen_loss = 0.40013023312019913, disc_loss = 0.14851548689527744
Trained batch 431 in epoch 4, gen_loss = 0.40002552785531237, disc_loss = 0.14837483383059777
Trained batch 432 in epoch 4, gen_loss = 0.39994664307829964, disc_loss = 0.1483805587485123
Trained batch 433 in epoch 4, gen_loss = 0.400078696657985, disc_loss = 0.14841262368734257
Trained batch 434 in epoch 4, gen_loss = 0.40008929015576156, disc_loss = 0.14845910785698344
Trained batch 435 in epoch 4, gen_loss = 0.399848590818567, disc_loss = 0.14852068529660822
Trained batch 436 in epoch 4, gen_loss = 0.3998319803304476, disc_loss = 0.14941051095144428
Trained batch 437 in epoch 4, gen_loss = 0.39993732480425814, disc_loss = 0.14941495334618984
Trained batch 438 in epoch 4, gen_loss = 0.39975798374428023, disc_loss = 0.14955412412321106
Trained batch 439 in epoch 4, gen_loss = 0.39979925629767504, disc_loss = 0.14958248464390636
Trained batch 440 in epoch 4, gen_loss = 0.3995490493147281, disc_loss = 0.14953196333412952
Trained batch 441 in epoch 4, gen_loss = 0.3996317102089187, disc_loss = 0.14952717385174732
Trained batch 442 in epoch 4, gen_loss = 0.3996952719666888, disc_loss = 0.14947484935682193
Trained batch 443 in epoch 4, gen_loss = 0.3996087922840505, disc_loss = 0.14962402419900303
Trained batch 444 in epoch 4, gen_loss = 0.39949897480814645, disc_loss = 0.14960306501957807
Trained batch 445 in epoch 4, gen_loss = 0.39943161987670334, disc_loss = 0.14950776772548532
Trained batch 446 in epoch 4, gen_loss = 0.3994463392152082, disc_loss = 0.14942996071389059
Trained batch 447 in epoch 4, gen_loss = 0.39927624152707203, disc_loss = 0.14940295638682852
Trained batch 448 in epoch 4, gen_loss = 0.3991422097640473, disc_loss = 0.1494008026983929
Trained batch 449 in epoch 4, gen_loss = 0.39924765831894343, disc_loss = 0.1492570487740967
Trained batch 450 in epoch 4, gen_loss = 0.3993715818996176, disc_loss = 0.14910027583825614
Trained batch 451 in epoch 4, gen_loss = 0.39940666710644696, disc_loss = 0.14893823942021195
Trained batch 452 in epoch 4, gen_loss = 0.399400443101824, disc_loss = 0.14876730296818363
Trained batch 453 in epoch 4, gen_loss = 0.39960595433669993, disc_loss = 0.14856559253966492
Trained batch 454 in epoch 4, gen_loss = 0.3995102970154731, disc_loss = 0.14861980053585963
Trained batch 455 in epoch 4, gen_loss = 0.39936658093019534, disc_loss = 0.14864664873631114
Trained batch 456 in epoch 4, gen_loss = 0.39933276469910955, disc_loss = 0.1489498717893787
Trained batch 457 in epoch 4, gen_loss = 0.3995479805370606, disc_loss = 0.14959860820014143
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.5101722478866577, disc_loss = 0.032256729900836945
Trained batch 1 in epoch 5, gen_loss = 0.4251548647880554, disc_loss = 0.13288867846131325
Trained batch 2 in epoch 5, gen_loss = 0.4252191384633382, disc_loss = 0.12230506539344788
Trained batch 3 in epoch 5, gen_loss = 0.41684064269065857, disc_loss = 0.12286213226616383
Trained batch 4 in epoch 5, gen_loss = 0.4270147979259491, disc_loss = 0.11541847586631775
Trained batch 5 in epoch 5, gen_loss = 0.41459624965985614, disc_loss = 0.12297531962394714
Trained batch 6 in epoch 5, gen_loss = 0.4161318966320583, disc_loss = 0.1194911641733987
Trained batch 7 in epoch 5, gen_loss = 0.41768762469291687, disc_loss = 0.11693692021071911
Trained batch 8 in epoch 5, gen_loss = 0.40540310740470886, disc_loss = 0.11701895710494783
Trained batch 9 in epoch 5, gen_loss = 0.39933807849884034, disc_loss = 0.11688726916909217
Trained batch 10 in epoch 5, gen_loss = 0.39949103648012335, disc_loss = 0.1119529049504887
Trained batch 11 in epoch 5, gen_loss = 0.39744368692239124, disc_loss = 0.11424236744642258
Trained batch 12 in epoch 5, gen_loss = 0.38984980491491467, disc_loss = 0.11079441584073581
Trained batch 13 in epoch 5, gen_loss = 0.39055147979940685, disc_loss = 0.11184672159808022
Trained batch 14 in epoch 5, gen_loss = 0.396973047653834, disc_loss = 0.1096475640932719
Trained batch 15 in epoch 5, gen_loss = 0.4001323226839304, disc_loss = 0.10919524310156703
Trained batch 16 in epoch 5, gen_loss = 0.39793291162042055, disc_loss = 0.11508136680897545
Trained batch 17 in epoch 5, gen_loss = 0.40285200874010724, disc_loss = 0.12231788742873403
Trained batch 18 in epoch 5, gen_loss = 0.4005243495890969, disc_loss = 0.11947309461079146
Trained batch 19 in epoch 5, gen_loss = 0.4024365246295929, disc_loss = 0.12459160499274731
Trained batch 20 in epoch 5, gen_loss = 0.4100043915566944, disc_loss = 0.12367360116470427
Trained batch 21 in epoch 5, gen_loss = 0.4097230922092091, disc_loss = 0.12131118706681511
Trained batch 22 in epoch 5, gen_loss = 0.4058949571588765, disc_loss = 0.12250335773696071
Trained batch 23 in epoch 5, gen_loss = 0.4036305323243141, disc_loss = 0.1207210108016928
Trained batch 24 in epoch 5, gen_loss = 0.40348638892173766, disc_loss = 0.11894763618707657
Trained batch 25 in epoch 5, gen_loss = 0.40757023715055907, disc_loss = 0.12083941841354737
Trained batch 26 in epoch 5, gen_loss = 0.4084546654312699, disc_loss = 0.12578953664611886
Trained batch 27 in epoch 5, gen_loss = 0.4063870055334909, disc_loss = 0.1229412385395595
Trained batch 28 in epoch 5, gen_loss = 0.4082600474357605, disc_loss = 0.12081416054018612
Trained batch 29 in epoch 5, gen_loss = 0.40652209719022114, disc_loss = 0.11934413636724155
Trained batch 30 in epoch 5, gen_loss = 0.4076840233418249, disc_loss = 0.12027174546833962
Trained batch 31 in epoch 5, gen_loss = 0.40613563638180494, disc_loss = 0.12033000960946083
Trained batch 32 in epoch 5, gen_loss = 0.4038312082940882, disc_loss = 0.1197287126472502
Trained batch 33 in epoch 5, gen_loss = 0.40378569329486175, disc_loss = 0.11985566357479376
Trained batch 34 in epoch 5, gen_loss = 0.4037038777555738, disc_loss = 0.120577857536929
Trained batch 35 in epoch 5, gen_loss = 0.4064913367231687, disc_loss = 0.1195340837455458
Trained batch 36 in epoch 5, gen_loss = 0.40604645335996475, disc_loss = 0.11880911363137735
Trained batch 37 in epoch 5, gen_loss = 0.40628816501090403, disc_loss = 0.118022371083498
Trained batch 38 in epoch 5, gen_loss = 0.40662109087675047, disc_loss = 0.11726161990410243
Trained batch 39 in epoch 5, gen_loss = 0.40449546203017234, disc_loss = 0.11739465855062008
Trained batch 40 in epoch 5, gen_loss = 0.40544617466810273, disc_loss = 0.11634005896928834
Trained batch 41 in epoch 5, gen_loss = 0.40737529737608774, disc_loss = 0.11731525191238948
Trained batch 42 in epoch 5, gen_loss = 0.4069191536238027, disc_loss = 0.11561710630045381
Trained batch 43 in epoch 5, gen_loss = 0.40611167319796304, disc_loss = 0.11655031940476461
Trained batch 44 in epoch 5, gen_loss = 0.4060267647107442, disc_loss = 0.11769052594900131
Trained batch 45 in epoch 5, gen_loss = 0.40533391613027325, disc_loss = 0.12354302584477093
Trained batch 46 in epoch 5, gen_loss = 0.4028426871654835, disc_loss = 0.12514807680185805
Trained batch 47 in epoch 5, gen_loss = 0.40285919420421124, disc_loss = 0.12506423595671853
Trained batch 48 in epoch 5, gen_loss = 0.4025581381758865, disc_loss = 0.12616455995914888
Trained batch 49 in epoch 5, gen_loss = 0.40303739726543425, disc_loss = 0.12565283790230752
Trained batch 50 in epoch 5, gen_loss = 0.4018653426684585, disc_loss = 0.12527645671484516
Trained batch 51 in epoch 5, gen_loss = 0.4024643754729858, disc_loss = 0.12474584851700526
Trained batch 52 in epoch 5, gen_loss = 0.40234230543082616, disc_loss = 0.12562969425376855
Trained batch 53 in epoch 5, gen_loss = 0.40162446598211926, disc_loss = 0.12618743642060845
Trained batch 54 in epoch 5, gen_loss = 0.4007197054949674, disc_loss = 0.12588437592441384
Trained batch 55 in epoch 5, gen_loss = 0.4018407091498375, disc_loss = 0.12567532328622683
Trained batch 56 in epoch 5, gen_loss = 0.4014305514201783, disc_loss = 0.1255914429039286
Trained batch 57 in epoch 5, gen_loss = 0.4007600910704711, disc_loss = 0.12489510494573362
Trained batch 58 in epoch 5, gen_loss = 0.40132147578869837, disc_loss = 0.12375763753208063
Trained batch 59 in epoch 5, gen_loss = 0.4013354326287905, disc_loss = 0.12472512436409791
Trained batch 60 in epoch 5, gen_loss = 0.4021330363437778, disc_loss = 0.12548141291395562
Trained batch 61 in epoch 5, gen_loss = 0.40218271747712164, disc_loss = 0.1247152334019061
Trained batch 62 in epoch 5, gen_loss = 0.40233702602840604, disc_loss = 0.12343678475608902
Trained batch 63 in epoch 5, gen_loss = 0.40111619839444757, disc_loss = 0.12393010809319094
Trained batch 64 in epoch 5, gen_loss = 0.4003523812844203, disc_loss = 0.12448840949397821
Trained batch 65 in epoch 5, gen_loss = 0.39927515839085437, disc_loss = 0.12469615205896623
Trained batch 66 in epoch 5, gen_loss = 0.39918514196552446, disc_loss = 0.12532647004100814
Trained batch 67 in epoch 5, gen_loss = 0.39906009637257633, disc_loss = 0.12595635942895622
Trained batch 68 in epoch 5, gen_loss = 0.39873572147410846, disc_loss = 0.12686653699779857
Trained batch 69 in epoch 5, gen_loss = 0.39854227517332347, disc_loss = 0.1265674441520657
Trained batch 70 in epoch 5, gen_loss = 0.40088571754979413, disc_loss = 0.12678369412749585
Trained batch 71 in epoch 5, gen_loss = 0.400564076171981, disc_loss = 0.12787532387301326
Trained batch 72 in epoch 5, gen_loss = 0.4009321295235255, disc_loss = 0.12924348445583697
Trained batch 73 in epoch 5, gen_loss = 0.40008799973371867, disc_loss = 0.13024229591561332
Trained batch 74 in epoch 5, gen_loss = 0.4007217562198639, disc_loss = 0.13065417264898618
Trained batch 75 in epoch 5, gen_loss = 0.4020210669228905, disc_loss = 0.1300809057429433
Trained batch 76 in epoch 5, gen_loss = 0.4018430779506634, disc_loss = 0.12941939988500112
Trained batch 77 in epoch 5, gen_loss = 0.4023399635767325, disc_loss = 0.12906495400537282
Trained batch 78 in epoch 5, gen_loss = 0.402523104148575, disc_loss = 0.12855232719190512
Trained batch 79 in epoch 5, gen_loss = 0.40258209891617297, disc_loss = 0.1282077632378787
Trained batch 80 in epoch 5, gen_loss = 0.4029951066146662, disc_loss = 0.12842325567279333
Trained batch 81 in epoch 5, gen_loss = 0.40372768989423424, disc_loss = 0.1305554608655412
Trained batch 82 in epoch 5, gen_loss = 0.4038449281669525, disc_loss = 0.1321965647659388
Trained batch 83 in epoch 5, gen_loss = 0.4042592602116721, disc_loss = 0.1320484477937931
Trained batch 84 in epoch 5, gen_loss = 0.40341156650992, disc_loss = 0.13256280970047501
Trained batch 85 in epoch 5, gen_loss = 0.40245868369590404, disc_loss = 0.13320965930646242
Trained batch 86 in epoch 5, gen_loss = 0.4030344897303088, disc_loss = 0.13250248275440316
Trained batch 87 in epoch 5, gen_loss = 0.40329286185177887, disc_loss = 0.13291890669444745
Trained batch 88 in epoch 5, gen_loss = 0.40292650561654164, disc_loss = 0.1324062447450804
Trained batch 89 in epoch 5, gen_loss = 0.40216459665033555, disc_loss = 0.132688252420889
Trained batch 90 in epoch 5, gen_loss = 0.4016199780034495, disc_loss = 0.1321260694537189
Trained batch 91 in epoch 5, gen_loss = 0.4031368105307869, disc_loss = 0.13245757389813662
Trained batch 92 in epoch 5, gen_loss = 0.4021053974346448, disc_loss = 0.13206583617996143
Trained batch 93 in epoch 5, gen_loss = 0.4018486754057255, disc_loss = 0.13248487106187545
Trained batch 94 in epoch 5, gen_loss = 0.402982318087628, disc_loss = 0.13254349784631478
Trained batch 95 in epoch 5, gen_loss = 0.4026190722361207, disc_loss = 0.13215155717140684
Trained batch 96 in epoch 5, gen_loss = 0.40190243751732346, disc_loss = 0.1322581955836606
Trained batch 97 in epoch 5, gen_loss = 0.40199270236248874, disc_loss = 0.13206699425924798
Trained batch 98 in epoch 5, gen_loss = 0.40191810931822264, disc_loss = 0.1319843770352879
Trained batch 99 in epoch 5, gen_loss = 0.4016838952898979, disc_loss = 0.13241463024169206
Trained batch 100 in epoch 5, gen_loss = 0.4016904683396368, disc_loss = 0.13293549141818933
Trained batch 101 in epoch 5, gen_loss = 0.40194177627563477, disc_loss = 0.13311364505366952
Trained batch 102 in epoch 5, gen_loss = 0.4016051764048419, disc_loss = 0.13252195451878807
Trained batch 103 in epoch 5, gen_loss = 0.40220411952871543, disc_loss = 0.13235308340965554
Trained batch 104 in epoch 5, gen_loss = 0.4036991269815536, disc_loss = 0.1322705697800432
Trained batch 105 in epoch 5, gen_loss = 0.40351034251024137, disc_loss = 0.13241024136121543
Trained batch 106 in epoch 5, gen_loss = 0.4022737125927043, disc_loss = 0.13275668655182712
Trained batch 107 in epoch 5, gen_loss = 0.401305267656291, disc_loss = 0.13348121378846742
Trained batch 108 in epoch 5, gen_loss = 0.4014961489843666, disc_loss = 0.13453303431288913
Trained batch 109 in epoch 5, gen_loss = 0.4015184865756468, disc_loss = 0.13577011854133822
Trained batch 110 in epoch 5, gen_loss = 0.4014654938165132, disc_loss = 0.13564183224026147
Trained batch 111 in epoch 5, gen_loss = 0.40228758858782904, disc_loss = 0.1348257389119161
Trained batch 112 in epoch 5, gen_loss = 0.4028792623924998, disc_loss = 0.13456793000872155
Trained batch 113 in epoch 5, gen_loss = 0.40229213159335286, disc_loss = 0.1340996464551018
Trained batch 114 in epoch 5, gen_loss = 0.4026075852953869, disc_loss = 0.1339818565417891
Trained batch 115 in epoch 5, gen_loss = 0.40231527516554144, disc_loss = 0.13416570344747142
Trained batch 116 in epoch 5, gen_loss = 0.4024698670603271, disc_loss = 0.13362850614974642
Trained batch 117 in epoch 5, gen_loss = 0.40217757427086265, disc_loss = 0.13461853257554063
Trained batch 118 in epoch 5, gen_loss = 0.40121345960793375, disc_loss = 0.13453035667037763
Trained batch 119 in epoch 5, gen_loss = 0.40109376708666483, disc_loss = 0.13527581055338184
Trained batch 120 in epoch 5, gen_loss = 0.4009279155534161, disc_loss = 0.1359291570184152
Trained batch 121 in epoch 5, gen_loss = 0.40066166441948686, disc_loss = 0.13576933689659737
Trained batch 122 in epoch 5, gen_loss = 0.399986163629749, disc_loss = 0.13564131666368584
Trained batch 123 in epoch 5, gen_loss = 0.40055710029217506, disc_loss = 0.13607403416667255
Trained batch 124 in epoch 5, gen_loss = 0.4007631125450134, disc_loss = 0.1358192728459835
Trained batch 125 in epoch 5, gen_loss = 0.4008854469136586, disc_loss = 0.13502708071517566
Trained batch 126 in epoch 5, gen_loss = 0.40107943762944437, disc_loss = 0.13467700362909496
Trained batch 127 in epoch 5, gen_loss = 0.40084269479848444, disc_loss = 0.1352998589281924
Trained batch 128 in epoch 5, gen_loss = 0.4010001159915628, disc_loss = 0.1346779234649599
Trained batch 129 in epoch 5, gen_loss = 0.400891264126851, disc_loss = 0.13450955083737007
Trained batch 130 in epoch 5, gen_loss = 0.40140982870837205, disc_loss = 0.13416706793408356
Trained batch 131 in epoch 5, gen_loss = 0.40116558088497684, disc_loss = 0.1338514251578035
Trained batch 132 in epoch 5, gen_loss = 0.4014049952191518, disc_loss = 0.13369696195188321
Trained batch 133 in epoch 5, gen_loss = 0.4008588319394126, disc_loss = 0.13425110764245488
Trained batch 134 in epoch 5, gen_loss = 0.40096023656703805, disc_loss = 0.13395737834550717
Trained batch 135 in epoch 5, gen_loss = 0.4013248313875759, disc_loss = 0.13364921592395096
Trained batch 136 in epoch 5, gen_loss = 0.40161756812220945, disc_loss = 0.13295403767349948
Trained batch 137 in epoch 5, gen_loss = 0.40185239198415174, disc_loss = 0.13277547895584418
Trained batch 138 in epoch 5, gen_loss = 0.4020284785212373, disc_loss = 0.13265110855158285
Trained batch 139 in epoch 5, gen_loss = 0.40208316019603185, disc_loss = 0.1327881728165916
Trained batch 140 in epoch 5, gen_loss = 0.40222714619433625, disc_loss = 0.13323142662221657
Trained batch 141 in epoch 5, gen_loss = 0.40266213051869837, disc_loss = 0.13290056804011405
Trained batch 142 in epoch 5, gen_loss = 0.4025993019967646, disc_loss = 0.13302280235436412
Trained batch 143 in epoch 5, gen_loss = 0.4025398761861854, disc_loss = 0.13265820807363424
Trained batch 144 in epoch 5, gen_loss = 0.40275636171472484, disc_loss = 0.13255956437567185
Trained batch 145 in epoch 5, gen_loss = 0.402654595775147, disc_loss = 0.13239443115890026
Trained batch 146 in epoch 5, gen_loss = 0.40290055733148744, disc_loss = 0.13195668954123446
Trained batch 147 in epoch 5, gen_loss = 0.40277840579683716, disc_loss = 0.13152823529231386
Trained batch 148 in epoch 5, gen_loss = 0.4030259379604519, disc_loss = 0.13118657492251204
Trained batch 149 in epoch 5, gen_loss = 0.4034318103392919, disc_loss = 0.13167152764896553
Trained batch 150 in epoch 5, gen_loss = 0.40272447052380894, disc_loss = 0.1319262460614277
Trained batch 151 in epoch 5, gen_loss = 0.4029895484839615, disc_loss = 0.13202149541068234
Trained batch 152 in epoch 5, gen_loss = 0.4026410603055767, disc_loss = 0.13234593629155283
Trained batch 153 in epoch 5, gen_loss = 0.40258505940437317, disc_loss = 0.1320312498500208
Trained batch 154 in epoch 5, gen_loss = 0.402589810855927, disc_loss = 0.1327594747706767
Trained batch 155 in epoch 5, gen_loss = 0.40370556463797885, disc_loss = 0.1333278866771322
Trained batch 156 in epoch 5, gen_loss = 0.40347191197856974, disc_loss = 0.1331124397552317
Trained batch 157 in epoch 5, gen_loss = 0.40375463683393936, disc_loss = 0.13270073985280115
Trained batch 158 in epoch 5, gen_loss = 0.4041859190793907, disc_loss = 0.13223051504706437
Trained batch 159 in epoch 5, gen_loss = 0.4044171582907438, disc_loss = 0.13274970469065012
Trained batch 160 in epoch 5, gen_loss = 0.40407610180215064, disc_loss = 0.1325470061498399
Trained batch 161 in epoch 5, gen_loss = 0.40438945959379646, disc_loss = 0.1319606742925114
Trained batch 162 in epoch 5, gen_loss = 0.4046518925143166, disc_loss = 0.13187081874148246
Trained batch 163 in epoch 5, gen_loss = 0.4043369763871519, disc_loss = 0.13159190445411495
Trained batch 164 in epoch 5, gen_loss = 0.40405940016110736, disc_loss = 0.13166245258215703
Trained batch 165 in epoch 5, gen_loss = 0.40350757216114597, disc_loss = 0.1329484215701919
Trained batch 166 in epoch 5, gen_loss = 0.40356009841679097, disc_loss = 0.1326308233473829
Trained batch 167 in epoch 5, gen_loss = 0.4035199288101423, disc_loss = 0.13244368033927112
Trained batch 168 in epoch 5, gen_loss = 0.40376618098930495, disc_loss = 0.13207989230134784
Trained batch 169 in epoch 5, gen_loss = 0.40347230925279504, disc_loss = 0.13183398058309276
Trained batch 170 in epoch 5, gen_loss = 0.40297922457170765, disc_loss = 0.13158786214060253
Trained batch 171 in epoch 5, gen_loss = 0.40284343826216323, disc_loss = 0.13141354407335437
Trained batch 172 in epoch 5, gen_loss = 0.4030083302473057, disc_loss = 0.13105461242571043
Trained batch 173 in epoch 5, gen_loss = 0.40340651640261727, disc_loss = 0.1306999001609183
Trained batch 174 in epoch 5, gen_loss = 0.40309176870754787, disc_loss = 0.13054644852876662
Trained batch 175 in epoch 5, gen_loss = 0.4024767315184528, disc_loss = 0.1303913084451448
Trained batch 176 in epoch 5, gen_loss = 0.4024286175851768, disc_loss = 0.12998485253692346
Trained batch 177 in epoch 5, gen_loss = 0.40284121170472564, disc_loss = 0.12969996834571443
Trained batch 178 in epoch 5, gen_loss = 0.40288064516456434, disc_loss = 0.12948425684394782
Trained batch 179 in epoch 5, gen_loss = 0.4028401881456375, disc_loss = 0.12937894517348872
Trained batch 180 in epoch 5, gen_loss = 0.40316468444318404, disc_loss = 0.12924024339209603
Trained batch 181 in epoch 5, gen_loss = 0.4030916965924777, disc_loss = 0.12968732130069
Trained batch 182 in epoch 5, gen_loss = 0.40321716259086066, disc_loss = 0.13082576343596308
Trained batch 183 in epoch 5, gen_loss = 0.40312053036430606, disc_loss = 0.13083151776505553
Trained batch 184 in epoch 5, gen_loss = 0.4028097711704873, disc_loss = 0.13041488369171683
Trained batch 185 in epoch 5, gen_loss = 0.40284941129146085, disc_loss = 0.13009576020782354
Trained batch 186 in epoch 5, gen_loss = 0.4029931285802056, disc_loss = 0.12978976193994762
Trained batch 187 in epoch 5, gen_loss = 0.40350345934325077, disc_loss = 0.12954127941122082
Trained batch 188 in epoch 5, gen_loss = 0.4037278299293821, disc_loss = 0.1293510556733482
Trained batch 189 in epoch 5, gen_loss = 0.40348650766046423, disc_loss = 0.12923038886173777
Trained batch 190 in epoch 5, gen_loss = 0.4031835721113295, disc_loss = 0.129151982962305
Trained batch 191 in epoch 5, gen_loss = 0.40334170203035075, disc_loss = 0.12896198362189656
Trained batch 192 in epoch 5, gen_loss = 0.4032625078846136, disc_loss = 0.12918954386998335
Trained batch 193 in epoch 5, gen_loss = 0.40276212805939704, disc_loss = 0.1294631445108308
Trained batch 194 in epoch 5, gen_loss = 0.4032429799055442, disc_loss = 0.1293351321839369
Trained batch 195 in epoch 5, gen_loss = 0.4029711790534915, disc_loss = 0.12916749105693734
Trained batch 196 in epoch 5, gen_loss = 0.4030805628009254, disc_loss = 0.1295236898066126
Trained batch 197 in epoch 5, gen_loss = 0.4032980548311966, disc_loss = 0.13057406666227664
Trained batch 198 in epoch 5, gen_loss = 0.40322713546417466, disc_loss = 0.1302431645667433
Trained batch 199 in epoch 5, gen_loss = 0.40292941421270373, disc_loss = 0.13033951295539736
Trained batch 200 in epoch 5, gen_loss = 0.40294832554622667, disc_loss = 0.12998402860034164
Trained batch 201 in epoch 5, gen_loss = 0.4034988537873372, disc_loss = 0.1297200300758428
Trained batch 202 in epoch 5, gen_loss = 0.40329377345850903, disc_loss = 0.12955882660861084
Trained batch 203 in epoch 5, gen_loss = 0.40329962428293975, disc_loss = 0.12966317471628094
Trained batch 204 in epoch 5, gen_loss = 0.40355985935141403, disc_loss = 0.12965983581252213
Trained batch 205 in epoch 5, gen_loss = 0.40320499762169365, disc_loss = 0.12958809212573524
Trained batch 206 in epoch 5, gen_loss = 0.4031254492232189, disc_loss = 0.12943472065355466
Trained batch 207 in epoch 5, gen_loss = 0.4029356067856917, disc_loss = 0.12948250415949866
Trained batch 208 in epoch 5, gen_loss = 0.4032085111551878, disc_loss = 0.1294657416534766
Trained batch 209 in epoch 5, gen_loss = 0.4029943694670995, disc_loss = 0.12972674877161072
Trained batch 210 in epoch 5, gen_loss = 0.40291289794501534, disc_loss = 0.13019253084021157
Trained batch 211 in epoch 5, gen_loss = 0.4033202070672557, disc_loss = 0.13083805133289886
Trained batch 212 in epoch 5, gen_loss = 0.4035288408888338, disc_loss = 0.13098057548344974
Trained batch 213 in epoch 5, gen_loss = 0.4038167168325353, disc_loss = 0.1308381417156937
Trained batch 214 in epoch 5, gen_loss = 0.403679523911587, disc_loss = 0.1309602323313092
Trained batch 215 in epoch 5, gen_loss = 0.4038170287730517, disc_loss = 0.13113859064739058
Trained batch 216 in epoch 5, gen_loss = 0.4037902875704699, disc_loss = 0.13126111912974564
Trained batch 217 in epoch 5, gen_loss = 0.40389994702754767, disc_loss = 0.13092885894376202
Trained batch 218 in epoch 5, gen_loss = 0.4036185916972487, disc_loss = 0.13074612654915682
Trained batch 219 in epoch 5, gen_loss = 0.4035017797892744, disc_loss = 0.13103554672138257
Trained batch 220 in epoch 5, gen_loss = 0.40314776649302486, disc_loss = 0.13072254869463218
Trained batch 221 in epoch 5, gen_loss = 0.4028366527578852, disc_loss = 0.13098422995021752
Trained batch 222 in epoch 5, gen_loss = 0.40279595386821593, disc_loss = 0.13144948737770987
Trained batch 223 in epoch 5, gen_loss = 0.40291111663516077, disc_loss = 0.1311689049803785
Trained batch 224 in epoch 5, gen_loss = 0.40300897942648994, disc_loss = 0.13162647406260172
Trained batch 225 in epoch 5, gen_loss = 0.4027740733813396, disc_loss = 0.13198051166481675
Trained batch 226 in epoch 5, gen_loss = 0.4028774478887146, disc_loss = 0.1322228227155324
Trained batch 227 in epoch 5, gen_loss = 0.402798061046684, disc_loss = 0.1328247077109521
Trained batch 228 in epoch 5, gen_loss = 0.4025998824808795, disc_loss = 0.13246737523045082
Trained batch 229 in epoch 5, gen_loss = 0.4030965552381847, disc_loss = 0.1329082327530436
Trained batch 230 in epoch 5, gen_loss = 0.40281283997354056, disc_loss = 0.13364678987370424
Trained batch 231 in epoch 5, gen_loss = 0.40279385537422935, disc_loss = 0.13388347836082864
Trained batch 232 in epoch 5, gen_loss = 0.4026386122590994, disc_loss = 0.1337239166218068
Trained batch 233 in epoch 5, gen_loss = 0.4025969599556719, disc_loss = 0.13349172735634524
Trained batch 234 in epoch 5, gen_loss = 0.40263612980538227, disc_loss = 0.13316456409210856
Trained batch 235 in epoch 5, gen_loss = 0.40251161372762617, disc_loss = 0.1333289277755608
Trained batch 236 in epoch 5, gen_loss = 0.4025383107521363, disc_loss = 0.13319085091981203
Trained batch 237 in epoch 5, gen_loss = 0.40238606228547935, disc_loss = 0.133309797454281
Trained batch 238 in epoch 5, gen_loss = 0.4026212738398229, disc_loss = 0.13336271540141006
Trained batch 239 in epoch 5, gen_loss = 0.4027524347106616, disc_loss = 0.13324936653176944
Trained batch 240 in epoch 5, gen_loss = 0.402937660449768, disc_loss = 0.13302228649251194
Trained batch 241 in epoch 5, gen_loss = 0.4031816530079881, disc_loss = 0.1328773068433458
Trained batch 242 in epoch 5, gen_loss = 0.4030168469795965, disc_loss = 0.13286102716446904
Trained batch 243 in epoch 5, gen_loss = 0.40294241367793476, disc_loss = 0.13320928784545327
Trained batch 244 in epoch 5, gen_loss = 0.4030651267693967, disc_loss = 0.13405400535890033
Trained batch 245 in epoch 5, gen_loss = 0.4029020061337851, disc_loss = 0.13391588261820436
Trained batch 246 in epoch 5, gen_loss = 0.4028927858783166, disc_loss = 0.1341291565583785
Trained batch 247 in epoch 5, gen_loss = 0.4028609601720687, disc_loss = 0.13415951110542781
Trained batch 248 in epoch 5, gen_loss = 0.4032974635740839, disc_loss = 0.13430564683005514
Trained batch 249 in epoch 5, gen_loss = 0.40337590885162355, disc_loss = 0.13460163220763208
Trained batch 250 in epoch 5, gen_loss = 0.40300777495144846, disc_loss = 0.13454735436406268
Trained batch 251 in epoch 5, gen_loss = 0.4029220278773989, disc_loss = 0.13447132393244712
Trained batch 252 in epoch 5, gen_loss = 0.40283847986002685, disc_loss = 0.13421982220510248
Trained batch 253 in epoch 5, gen_loss = 0.40269060984371213, disc_loss = 0.13426130311930273
Trained batch 254 in epoch 5, gen_loss = 0.40265951074805917, disc_loss = 0.13418292701244355
Trained batch 255 in epoch 5, gen_loss = 0.40249124413821846, disc_loss = 0.13425309595186263
Trained batch 256 in epoch 5, gen_loss = 0.4027368523731306, disc_loss = 0.13428376348334065
Trained batch 257 in epoch 5, gen_loss = 0.4025197021027868, disc_loss = 0.13441350738438526
Trained batch 258 in epoch 5, gen_loss = 0.40270795911895724, disc_loss = 0.13421879982050783
Trained batch 259 in epoch 5, gen_loss = 0.40249355194660336, disc_loss = 0.13399409342270632
Trained batch 260 in epoch 5, gen_loss = 0.402310723888463, disc_loss = 0.13398536514505116
Trained batch 261 in epoch 5, gen_loss = 0.4022648079704692, disc_loss = 0.13415019691900443
Trained batch 262 in epoch 5, gen_loss = 0.40242494172469745, disc_loss = 0.13418048427585413
Trained batch 263 in epoch 5, gen_loss = 0.40275015715848317, disc_loss = 0.13405220645169416
Trained batch 264 in epoch 5, gen_loss = 0.4028595178757074, disc_loss = 0.13388296019918514
Trained batch 265 in epoch 5, gen_loss = 0.4028822697867128, disc_loss = 0.13359136037752592
Trained batch 266 in epoch 5, gen_loss = 0.40283249290694906, disc_loss = 0.1336419482886345
Trained batch 267 in epoch 5, gen_loss = 0.4027131863716823, disc_loss = 0.13354890288979704
Trained batch 268 in epoch 5, gen_loss = 0.4026074347442854, disc_loss = 0.13372557664283147
Trained batch 269 in epoch 5, gen_loss = 0.402733936574724, disc_loss = 0.13458376964209257
Trained batch 270 in epoch 5, gen_loss = 0.40268352693737214, disc_loss = 0.13454279084982027
Trained batch 271 in epoch 5, gen_loss = 0.40271806366303387, disc_loss = 0.13450509809669764
Trained batch 272 in epoch 5, gen_loss = 0.402972107732689, disc_loss = 0.13453110568088927
Trained batch 273 in epoch 5, gen_loss = 0.4027428237626152, disc_loss = 0.13453461606408992
Trained batch 274 in epoch 5, gen_loss = 0.40331092726100576, disc_loss = 0.13441908704963598
Trained batch 275 in epoch 5, gen_loss = 0.4030254251067189, disc_loss = 0.1346833085425306
Trained batch 276 in epoch 5, gen_loss = 0.40294368785641255, disc_loss = 0.13485427506079742
Trained batch 277 in epoch 5, gen_loss = 0.40281728220929347, disc_loss = 0.13491095242043621
Trained batch 278 in epoch 5, gen_loss = 0.40292475257723137, disc_loss = 0.13471264874155375
Trained batch 279 in epoch 5, gen_loss = 0.40291654361145834, disc_loss = 0.134418318473867
Trained batch 280 in epoch 5, gen_loss = 0.40281493914084926, disc_loss = 0.1342588503748921
Trained batch 281 in epoch 5, gen_loss = 0.40282919643618537, disc_loss = 0.1344223920493684
Trained batch 282 in epoch 5, gen_loss = 0.4026980350590426, disc_loss = 0.1342474664215907
Trained batch 283 in epoch 5, gen_loss = 0.40241841037928217, disc_loss = 0.1342910076688293
Trained batch 284 in epoch 5, gen_loss = 0.40277579196712426, disc_loss = 0.13432718601666
Trained batch 285 in epoch 5, gen_loss = 0.402570663423805, disc_loss = 0.1345500055361878
Trained batch 286 in epoch 5, gen_loss = 0.40237581376830045, disc_loss = 0.1346138071151976
Trained batch 287 in epoch 5, gen_loss = 0.4025402119797137, disc_loss = 0.13446445646695793
Trained batch 288 in epoch 5, gen_loss = 0.40251048440339243, disc_loss = 0.13427464790307114
Trained batch 289 in epoch 5, gen_loss = 0.40244619240020885, disc_loss = 0.13416578957232936
Trained batch 290 in epoch 5, gen_loss = 0.4028669025275306, disc_loss = 0.13398103515819176
Trained batch 291 in epoch 5, gen_loss = 0.4026602854671544, disc_loss = 0.13463804495763287
Trained batch 292 in epoch 5, gen_loss = 0.40290754128234785, disc_loss = 0.13590275450472947
Trained batch 293 in epoch 5, gen_loss = 0.40291829832962583, disc_loss = 0.13656966431307144
Trained batch 294 in epoch 5, gen_loss = 0.40265899563239793, disc_loss = 0.13678581929307873
Trained batch 295 in epoch 5, gen_loss = 0.40259633324033506, disc_loss = 0.13695758090329332
Trained batch 296 in epoch 5, gen_loss = 0.4024781145230688, disc_loss = 0.1370412155183076
Trained batch 297 in epoch 5, gen_loss = 0.4025870520596536, disc_loss = 0.13702740737755828
Trained batch 298 in epoch 5, gen_loss = 0.4024952596246598, disc_loss = 0.13707600925180027
Trained batch 299 in epoch 5, gen_loss = 0.402427725593249, disc_loss = 0.13712391110757988
Trained batch 300 in epoch 5, gen_loss = 0.4023282942779832, disc_loss = 0.13699723465795136
Trained batch 301 in epoch 5, gen_loss = 0.4024983121464584, disc_loss = 0.13685530498130433
Trained batch 302 in epoch 5, gen_loss = 0.4025263740087893, disc_loss = 0.13681612303941557
Trained batch 303 in epoch 5, gen_loss = 0.40256141910427495, disc_loss = 0.13684526703467495
Trained batch 304 in epoch 5, gen_loss = 0.4025115177279613, disc_loss = 0.13669886857759758
Trained batch 305 in epoch 5, gen_loss = 0.402499825054524, disc_loss = 0.1366631981788897
Trained batch 306 in epoch 5, gen_loss = 0.40243737210279956, disc_loss = 0.1367427796028336
Trained batch 307 in epoch 5, gen_loss = 0.40238309748374024, disc_loss = 0.13685675241149864
Trained batch 308 in epoch 5, gen_loss = 0.4022525033904511, disc_loss = 0.13696854211944592
Trained batch 309 in epoch 5, gen_loss = 0.4022819748809261, disc_loss = 0.1368299235259333
Trained batch 310 in epoch 5, gen_loss = 0.4021498754476811, disc_loss = 0.13678038364629652
Trained batch 311 in epoch 5, gen_loss = 0.4021949900839573, disc_loss = 0.13674696654272386
Trained batch 312 in epoch 5, gen_loss = 0.4019624184305295, disc_loss = 0.13673716345534156
Trained batch 313 in epoch 5, gen_loss = 0.40201935504272485, disc_loss = 0.13683897954453328
Trained batch 314 in epoch 5, gen_loss = 0.40202564786350914, disc_loss = 0.13674310672850837
Trained batch 315 in epoch 5, gen_loss = 0.4021082943941973, disc_loss = 0.1365167462986104
Trained batch 316 in epoch 5, gen_loss = 0.40213667669506853, disc_loss = 0.13619178797967427
Trained batch 317 in epoch 5, gen_loss = 0.4023021038785671, disc_loss = 0.1361556989521538
Trained batch 318 in epoch 5, gen_loss = 0.4020240686156533, disc_loss = 0.13595775973787502
Trained batch 319 in epoch 5, gen_loss = 0.40186792369931934, disc_loss = 0.1358637321391143
Trained batch 320 in epoch 5, gen_loss = 0.40200578637212236, disc_loss = 0.13573436969397967
Trained batch 321 in epoch 5, gen_loss = 0.4017434499648787, disc_loss = 0.1356083548147671
Trained batch 322 in epoch 5, gen_loss = 0.4016897524288933, disc_loss = 0.13606321489893985
Trained batch 323 in epoch 5, gen_loss = 0.40199871903952256, disc_loss = 0.1366032832129686
Trained batch 324 in epoch 5, gen_loss = 0.4020566917382754, disc_loss = 0.13642664534541277
Trained batch 325 in epoch 5, gen_loss = 0.40192722305198386, disc_loss = 0.13668649096293317
Trained batch 326 in epoch 5, gen_loss = 0.40206997420080576, disc_loss = 0.13691327592147234
Trained batch 327 in epoch 5, gen_loss = 0.40209755783037443, disc_loss = 0.13688310359536512
Trained batch 328 in epoch 5, gen_loss = 0.40213692206379853, disc_loss = 0.13674584983375296
Trained batch 329 in epoch 5, gen_loss = 0.4021333988868829, disc_loss = 0.13656224169288622
Trained batch 330 in epoch 5, gen_loss = 0.4018149783784169, disc_loss = 0.1364170662113367
Trained batch 331 in epoch 5, gen_loss = 0.40196644927722863, disc_loss = 0.13626596317009396
Trained batch 332 in epoch 5, gen_loss = 0.4019953178929853, disc_loss = 0.13612742439001888
Trained batch 333 in epoch 5, gen_loss = 0.40224998984151256, disc_loss = 0.13612507719791936
Trained batch 334 in epoch 5, gen_loss = 0.4022245915078405, disc_loss = 0.13615035640437212
Trained batch 335 in epoch 5, gen_loss = 0.4022570586807671, disc_loss = 0.13618181006140298
Trained batch 336 in epoch 5, gen_loss = 0.402143144819786, disc_loss = 0.1359947018811717
Trained batch 337 in epoch 5, gen_loss = 0.4021462164157946, disc_loss = 0.13583245014871012
Trained batch 338 in epoch 5, gen_loss = 0.40200870218178514, disc_loss = 0.1359251383856862
Trained batch 339 in epoch 5, gen_loss = 0.40199388318202073, disc_loss = 0.1358129059895873
Trained batch 340 in epoch 5, gen_loss = 0.4018937485658528, disc_loss = 0.13568722405348005
Trained batch 341 in epoch 5, gen_loss = 0.40172543503039065, disc_loss = 0.13556114084234364
Trained batch 342 in epoch 5, gen_loss = 0.4019860152600458, disc_loss = 0.1353387426226549
Trained batch 343 in epoch 5, gen_loss = 0.4018189695685409, disc_loss = 0.13534320286626733
Trained batch 344 in epoch 5, gen_loss = 0.40198391831439473, disc_loss = 0.13514895413232886
Trained batch 345 in epoch 5, gen_loss = 0.4020280098984007, disc_loss = 0.13518088082702173
Trained batch 346 in epoch 5, gen_loss = 0.4019759688150642, disc_loss = 0.13521057109667864
Trained batch 347 in epoch 5, gen_loss = 0.4021050142145705, disc_loss = 0.13491431092736364
Trained batch 348 in epoch 5, gen_loss = 0.402091858209375, disc_loss = 0.1348216827841406
Trained batch 349 in epoch 5, gen_loss = 0.402029117005212, disc_loss = 0.13480571078402656
Trained batch 350 in epoch 5, gen_loss = 0.40207710514041434, disc_loss = 0.13471394399462264
Trained batch 351 in epoch 5, gen_loss = 0.4021567753939466, disc_loss = 0.13478521452370015
Trained batch 352 in epoch 5, gen_loss = 0.40218928338110277, disc_loss = 0.13487390152286877
Trained batch 353 in epoch 5, gen_loss = 0.4021618911775492, disc_loss = 0.13497170094547972
Trained batch 354 in epoch 5, gen_loss = 0.4020919760348092, disc_loss = 0.13503326626730636
Trained batch 355 in epoch 5, gen_loss = 0.4019834770915214, disc_loss = 0.13492602126651934
Trained batch 356 in epoch 5, gen_loss = 0.40215183539884763, disc_loss = 0.13496601418787693
Trained batch 357 in epoch 5, gen_loss = 0.40211707653280077, disc_loss = 0.13523314002505893
Trained batch 358 in epoch 5, gen_loss = 0.40190586962407676, disc_loss = 0.13543249533867105
Trained batch 359 in epoch 5, gen_loss = 0.40168023655811946, disc_loss = 0.1354389993680848
Trained batch 360 in epoch 5, gen_loss = 0.4018075509084559, disc_loss = 0.1353773369023014
Trained batch 361 in epoch 5, gen_loss = 0.4016243876343933, disc_loss = 0.1352664618984441
Trained batch 362 in epoch 5, gen_loss = 0.4015306588211007, disc_loss = 0.1353976186929327
Trained batch 363 in epoch 5, gen_loss = 0.4015176203715932, disc_loss = 0.1352733006230095
Trained batch 364 in epoch 5, gen_loss = 0.4016350447315059, disc_loss = 0.13511613291012098
Trained batch 365 in epoch 5, gen_loss = 0.40157192505773953, disc_loss = 0.13527209558040718
Trained batch 366 in epoch 5, gen_loss = 0.4014742775574042, disc_loss = 0.13549015281229643
Trained batch 367 in epoch 5, gen_loss = 0.4014441532933194, disc_loss = 0.1354624573748721
Trained batch 368 in epoch 5, gen_loss = 0.40141954428458276, disc_loss = 0.13547569939356832
Trained batch 369 in epoch 5, gen_loss = 0.4012560406246701, disc_loss = 0.13538941666483878
Trained batch 370 in epoch 5, gen_loss = 0.40140281854614096, disc_loss = 0.13534508968861597
Trained batch 371 in epoch 5, gen_loss = 0.4015870533322775, disc_loss = 0.13520378180809559
Trained batch 372 in epoch 5, gen_loss = 0.4017989428529151, disc_loss = 0.13519957495838325
Trained batch 373 in epoch 5, gen_loss = 0.401681283419145, disc_loss = 0.1350603175354514
Trained batch 374 in epoch 5, gen_loss = 0.4017401343981425, disc_loss = 0.13496172094345094
Trained batch 375 in epoch 5, gen_loss = 0.4015822041224926, disc_loss = 0.13494096910382838
Trained batch 376 in epoch 5, gen_loss = 0.401707498322115, disc_loss = 0.13484621289079954
Trained batch 377 in epoch 5, gen_loss = 0.40174418648399374, disc_loss = 0.1346621282556385
Trained batch 378 in epoch 5, gen_loss = 0.4016900340925735, disc_loss = 0.13445600191018198
Trained batch 379 in epoch 5, gen_loss = 0.40187723071951614, disc_loss = 0.1343065505553233
Trained batch 380 in epoch 5, gen_loss = 0.4017674419980037, disc_loss = 0.1341108411863407
Trained batch 381 in epoch 5, gen_loss = 0.40172015153924834, disc_loss = 0.13392143840877174
Trained batch 382 in epoch 5, gen_loss = 0.40167950938015634, disc_loss = 0.13453057276050975
Trained batch 383 in epoch 5, gen_loss = 0.4019572602119297, disc_loss = 0.1360849520812432
Trained batch 384 in epoch 5, gen_loss = 0.4019146399838584, disc_loss = 0.1360574026386459
Trained batch 385 in epoch 5, gen_loss = 0.4018710518130367, disc_loss = 0.13601976501818147
Trained batch 386 in epoch 5, gen_loss = 0.4018447231260689, disc_loss = 0.1359062239874241
Trained batch 387 in epoch 5, gen_loss = 0.4016947353009096, disc_loss = 0.1358901538415668
Trained batch 388 in epoch 5, gen_loss = 0.4017331242408115, disc_loss = 0.13579780679282308
Trained batch 389 in epoch 5, gen_loss = 0.40181844868721106, disc_loss = 0.13571547955656663
Trained batch 390 in epoch 5, gen_loss = 0.40163621969540103, disc_loss = 0.13575524741502673
Trained batch 391 in epoch 5, gen_loss = 0.4017903677054814, disc_loss = 0.13563168294043565
Trained batch 392 in epoch 5, gen_loss = 0.40159692010503384, disc_loss = 0.1355565879067392
Trained batch 393 in epoch 5, gen_loss = 0.40173075003974934, disc_loss = 0.13552228505084962
Trained batch 394 in epoch 5, gen_loss = 0.4015766155870655, disc_loss = 0.13545028216476682
Trained batch 395 in epoch 5, gen_loss = 0.40191012485460803, disc_loss = 0.13533271764489738
Trained batch 396 in epoch 5, gen_loss = 0.40207743779838234, disc_loss = 0.1352029440722778
Trained batch 397 in epoch 5, gen_loss = 0.40222651702375267, disc_loss = 0.13515131987968282
Trained batch 398 in epoch 5, gen_loss = 0.4021929637680675, disc_loss = 0.13521915491212877
Trained batch 399 in epoch 5, gen_loss = 0.4022032031416893, disc_loss = 0.135044647436589
Trained batch 400 in epoch 5, gen_loss = 0.4020089516021367, disc_loss = 0.13508669944698376
Trained batch 401 in epoch 5, gen_loss = 0.4021850526332855, disc_loss = 0.13493311138295416
Trained batch 402 in epoch 5, gen_loss = 0.40231206436311046, disc_loss = 0.13483825653199819
Trained batch 403 in epoch 5, gen_loss = 0.4021774062720856, disc_loss = 0.1346327569243489
Trained batch 404 in epoch 5, gen_loss = 0.4022506810264823, disc_loss = 0.1345245050519337
Trained batch 405 in epoch 5, gen_loss = 0.4023786546855137, disc_loss = 0.13444737747788724
Trained batch 406 in epoch 5, gen_loss = 0.4024801139310185, disc_loss = 0.13428148976012297
Trained batch 407 in epoch 5, gen_loss = 0.4026583141702063, disc_loss = 0.1340914478653348
Trained batch 408 in epoch 5, gen_loss = 0.4029506575361732, disc_loss = 0.1339774871823403
Trained batch 409 in epoch 5, gen_loss = 0.40327729531904544, disc_loss = 0.13411919115701826
Trained batch 410 in epoch 5, gen_loss = 0.40343386964496325, disc_loss = 0.13435076540585272
Trained batch 411 in epoch 5, gen_loss = 0.40359184189328867, disc_loss = 0.134249433847958
Trained batch 412 in epoch 5, gen_loss = 0.40374905924531507, disc_loss = 0.13407232098227262
Trained batch 413 in epoch 5, gen_loss = 0.4037403282911881, disc_loss = 0.13394881021861293
Trained batch 414 in epoch 5, gen_loss = 0.4037190983094365, disc_loss = 0.13401664244123251
Trained batch 415 in epoch 5, gen_loss = 0.4036494947683353, disc_loss = 0.13383144256658852
Trained batch 416 in epoch 5, gen_loss = 0.4036274985443774, disc_loss = 0.13430722270437853
Trained batch 417 in epoch 5, gen_loss = 0.4039723319870433, disc_loss = 0.1346913711769444
Trained batch 418 in epoch 5, gen_loss = 0.4038855795501809, disc_loss = 0.1344876894038304
Trained batch 419 in epoch 5, gen_loss = 0.40385938201631816, disc_loss = 0.1346836856522021
Trained batch 420 in epoch 5, gen_loss = 0.4039337097041114, disc_loss = 0.13471295750941065
Trained batch 421 in epoch 5, gen_loss = 0.4040553293663179, disc_loss = 0.1347667196438917
Trained batch 422 in epoch 5, gen_loss = 0.403910017605369, disc_loss = 0.1347134151445354
Trained batch 423 in epoch 5, gen_loss = 0.40359092602189983, disc_loss = 0.13489489644800998
Trained batch 424 in epoch 5, gen_loss = 0.40361626029014586, disc_loss = 0.13472839954144814
Trained batch 425 in epoch 5, gen_loss = 0.4035319392809845, disc_loss = 0.13475292339536227
Trained batch 426 in epoch 5, gen_loss = 0.4033317967237298, disc_loss = 0.13453918012334534
Trained batch 427 in epoch 5, gen_loss = 0.4030956597389462, disc_loss = 0.13458087226532608
Trained batch 428 in epoch 5, gen_loss = 0.4031201239788171, disc_loss = 0.13440213917748078
Trained batch 429 in epoch 5, gen_loss = 0.40315752999727117, disc_loss = 0.13417458011833736
Trained batch 430 in epoch 5, gen_loss = 0.40335760543905114, disc_loss = 0.13418688136747153
Trained batch 431 in epoch 5, gen_loss = 0.40331304618329916, disc_loss = 0.13413007290930384
Trained batch 432 in epoch 5, gen_loss = 0.403179629295032, disc_loss = 0.1340971799270523
Trained batch 433 in epoch 5, gen_loss = 0.4030492548156993, disc_loss = 0.13408100133770348
Trained batch 434 in epoch 5, gen_loss = 0.40288935803818976, disc_loss = 0.133915326744318
Trained batch 435 in epoch 5, gen_loss = 0.4028400114370049, disc_loss = 0.13399026025975241
Trained batch 436 in epoch 5, gen_loss = 0.4026447243357687, disc_loss = 0.13402565859377522
Trained batch 437 in epoch 5, gen_loss = 0.40268334773577513, disc_loss = 0.13398085564340903
Trained batch 438 in epoch 5, gen_loss = 0.4025234290163175, disc_loss = 0.13386969386275374
Trained batch 439 in epoch 5, gen_loss = 0.40256293185732583, disc_loss = 0.13392299771816893
Trained batch 440 in epoch 5, gen_loss = 0.40281960672261763, disc_loss = 0.13399720204626622
Trained batch 441 in epoch 5, gen_loss = 0.40298182102619795, disc_loss = 0.1338449624784257
Trained batch 442 in epoch 5, gen_loss = 0.4030025175543456, disc_loss = 0.13370193076019363
Trained batch 443 in epoch 5, gen_loss = 0.4030014110041094, disc_loss = 0.13363838705091594
Trained batch 444 in epoch 5, gen_loss = 0.403215583120839, disc_loss = 0.13349046513773083
Trained batch 445 in epoch 5, gen_loss = 0.4032134308809657, disc_loss = 0.13349975332317063
Trained batch 446 in epoch 5, gen_loss = 0.4031658319285519, disc_loss = 0.13332474220052395
Trained batch 447 in epoch 5, gen_loss = 0.40295784268528223, disc_loss = 0.13338157443130122
Trained batch 448 in epoch 5, gen_loss = 0.40307705817881034, disc_loss = 0.13325239834116404
Trained batch 449 in epoch 5, gen_loss = 0.40294434686501823, disc_loss = 0.13327721973260243
Trained batch 450 in epoch 5, gen_loss = 0.40307115761773815, disc_loss = 0.133780132045767
Trained batch 451 in epoch 5, gen_loss = 0.40316056915089094, disc_loss = 0.13376659929620482
Trained batch 452 in epoch 5, gen_loss = 0.40335458615757774, disc_loss = 0.13372551014947048
Trained batch 453 in epoch 5, gen_loss = 0.4033170895823298, disc_loss = 0.13369866058492977
Trained batch 454 in epoch 5, gen_loss = 0.40307902340050583, disc_loss = 0.13370527842870125
Trained batch 455 in epoch 5, gen_loss = 0.40330116836386815, disc_loss = 0.13413419667631388
Trained batch 456 in epoch 5, gen_loss = 0.4032821755049265, disc_loss = 0.13403815026160665
Trained batch 457 in epoch 5, gen_loss = 0.40312179083647165, disc_loss = 0.13415457283890925
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.47006845474243164, disc_loss = 0.08305154740810394
Trained batch 1 in epoch 6, gen_loss = 0.5067190229892731, disc_loss = 0.08288885653018951
Trained batch 2 in epoch 6, gen_loss = 0.46034420530001324, disc_loss = 0.08980390926202138
Trained batch 3 in epoch 6, gen_loss = 0.4255431294441223, disc_loss = 0.15422150120139122
Trained batch 4 in epoch 6, gen_loss = 0.4173925995826721, disc_loss = 0.14666132926940917
Trained batch 5 in epoch 6, gen_loss = 0.42471344272295636, disc_loss = 0.1399752820531527
Trained batch 6 in epoch 6, gen_loss = 0.4187806418963841, disc_loss = 0.1421378914799009
Trained batch 7 in epoch 6, gen_loss = 0.4105854853987694, disc_loss = 0.14414305798709393
Trained batch 8 in epoch 6, gen_loss = 0.41065391567018295, disc_loss = 0.14093433568874994
Trained batch 9 in epoch 6, gen_loss = 0.41358636021614076, disc_loss = 0.13505661264061927
Trained batch 10 in epoch 6, gen_loss = 0.4088910032402385, disc_loss = 0.13527860357002777
Trained batch 11 in epoch 6, gen_loss = 0.4089186241229375, disc_loss = 0.13024472010632357
Trained batch 12 in epoch 6, gen_loss = 0.40519691430605376, disc_loss = 0.12513300146047884
Trained batch 13 in epoch 6, gen_loss = 0.4000842443534306, disc_loss = 0.1271094355200018
Trained batch 14 in epoch 6, gen_loss = 0.39542778929074607, disc_loss = 0.12611890335877737
Trained batch 15 in epoch 6, gen_loss = 0.3938683643937111, disc_loss = 0.12702993024140596
Trained batch 16 in epoch 6, gen_loss = 0.400273834957796, disc_loss = 0.12273829496082138
Trained batch 17 in epoch 6, gen_loss = 0.40372917387220597, disc_loss = 0.12291817553341389
Trained batch 18 in epoch 6, gen_loss = 0.4031563322795065, disc_loss = 0.13042100656189418
Trained batch 19 in epoch 6, gen_loss = 0.4058338925242424, disc_loss = 0.1398876326158643
Trained batch 20 in epoch 6, gen_loss = 0.4026899224235898, disc_loss = 0.13575727226478712
Trained batch 21 in epoch 6, gen_loss = 0.3965493372895501, disc_loss = 0.13347764567218043
Trained batch 22 in epoch 6, gen_loss = 0.394890062187029, disc_loss = 0.13193112109666286
Trained batch 23 in epoch 6, gen_loss = 0.3926450548072656, disc_loss = 0.1356279441776375
Trained batch 24 in epoch 6, gen_loss = 0.39121787309646605, disc_loss = 0.13470171347260476
Trained batch 25 in epoch 6, gen_loss = 0.3933893533853384, disc_loss = 0.13497740503114003
Trained batch 26 in epoch 6, gen_loss = 0.393537571032842, disc_loss = 0.1348735978481946
Trained batch 27 in epoch 6, gen_loss = 0.39506674451487406, disc_loss = 0.13253546013895953
Trained batch 28 in epoch 6, gen_loss = 0.3937654896029111, disc_loss = 0.13408264350788346
Trained batch 29 in epoch 6, gen_loss = 0.39417502482732136, disc_loss = 0.1338518081853787
Trained batch 30 in epoch 6, gen_loss = 0.39551827023106234, disc_loss = 0.13370030769898045
Trained batch 31 in epoch 6, gen_loss = 0.39437325950711966, disc_loss = 0.13714936038013548
Trained batch 32 in epoch 6, gen_loss = 0.39551712075869244, disc_loss = 0.13638025081970476
Trained batch 33 in epoch 6, gen_loss = 0.3948323104311438, disc_loss = 0.13573550400050247
Trained batch 34 in epoch 6, gen_loss = 0.3956012649195535, disc_loss = 0.13461019662874085
Trained batch 35 in epoch 6, gen_loss = 0.3949886312087377, disc_loss = 0.1349617252126336
Trained batch 36 in epoch 6, gen_loss = 0.3937115000711905, disc_loss = 0.13409456963071953
Trained batch 37 in epoch 6, gen_loss = 0.3941831526003386, disc_loss = 0.13334186835900733
Trained batch 38 in epoch 6, gen_loss = 0.39527345162171584, disc_loss = 0.1340774854597373
Trained batch 39 in epoch 6, gen_loss = 0.396326195448637, disc_loss = 0.13414362957701087
Trained batch 40 in epoch 6, gen_loss = 0.39772918020806663, disc_loss = 0.13181343429335735
Trained batch 41 in epoch 6, gen_loss = 0.3962500031505312, disc_loss = 0.13240705758687996
Trained batch 42 in epoch 6, gen_loss = 0.39562598979750346, disc_loss = 0.13454225286841393
Trained batch 43 in epoch 6, gen_loss = 0.39591472257267346, disc_loss = 0.134623860178346
Trained batch 44 in epoch 6, gen_loss = 0.3973004082838694, disc_loss = 0.13392498087551857
Trained batch 45 in epoch 6, gen_loss = 0.3954558093910632, disc_loss = 0.13515259738525617
Trained batch 46 in epoch 6, gen_loss = 0.39813427531972845, disc_loss = 0.1335612840633443
Trained batch 47 in epoch 6, gen_loss = 0.39827988917628926, disc_loss = 0.13339941087178886
Trained batch 48 in epoch 6, gen_loss = 0.39653256778814355, disc_loss = 0.13364889799636237
Trained batch 49 in epoch 6, gen_loss = 0.39592351257801056, disc_loss = 0.13261925764381885
Trained batch 50 in epoch 6, gen_loss = 0.39596234291207555, disc_loss = 0.13248922551671663
Trained batch 51 in epoch 6, gen_loss = 0.39499609115032047, disc_loss = 0.13390904328284356
Trained batch 52 in epoch 6, gen_loss = 0.39500222397300433, disc_loss = 0.13344827217032323
Trained batch 53 in epoch 6, gen_loss = 0.39396450972115554, disc_loss = 0.13233693889169781
Trained batch 54 in epoch 6, gen_loss = 0.39414910457350993, disc_loss = 0.13114509250630033
Trained batch 55 in epoch 6, gen_loss = 0.3928589363183294, disc_loss = 0.13023003955770815
Trained batch 56 in epoch 6, gen_loss = 0.39182421878764506, disc_loss = 0.13114326296929726
Trained batch 57 in epoch 6, gen_loss = 0.39088899976220626, disc_loss = 0.13431842670101543
Trained batch 58 in epoch 6, gen_loss = 0.3917613731602491, disc_loss = 0.13688531006544324
Trained batch 59 in epoch 6, gen_loss = 0.39292337000370026, disc_loss = 0.13621603567153215
Trained batch 60 in epoch 6, gen_loss = 0.3933141524674463, disc_loss = 0.13724738890763188
Trained batch 61 in epoch 6, gen_loss = 0.392643331520019, disc_loss = 0.1370181340964571
Trained batch 62 in epoch 6, gen_loss = 0.3927755932959299, disc_loss = 0.13718784712846316
Trained batch 63 in epoch 6, gen_loss = 0.3941484438255429, disc_loss = 0.1362141557619907
Trained batch 64 in epoch 6, gen_loss = 0.3937392037648421, disc_loss = 0.13646436545711296
Trained batch 65 in epoch 6, gen_loss = 0.394719406059294, disc_loss = 0.13577649883474363
Trained batch 66 in epoch 6, gen_loss = 0.39537275059899285, disc_loss = 0.13486883550215123
Trained batch 67 in epoch 6, gen_loss = 0.39527992860359307, disc_loss = 0.13413207819137504
Trained batch 68 in epoch 6, gen_loss = 0.39402802050977515, disc_loss = 0.13478146423248277
Trained batch 69 in epoch 6, gen_loss = 0.393019277708871, disc_loss = 0.1345444770263774
Trained batch 70 in epoch 6, gen_loss = 0.39257099384992894, disc_loss = 0.134747399987889
Trained batch 71 in epoch 6, gen_loss = 0.39254630025890136, disc_loss = 0.13459667071907055
Trained batch 72 in epoch 6, gen_loss = 0.3942735872856558, disc_loss = 0.13386635405764188
Trained batch 73 in epoch 6, gen_loss = 0.39649142123557424, disc_loss = 0.1326648562743857
Trained batch 74 in epoch 6, gen_loss = 0.3971021413803101, disc_loss = 0.13131491323312125
Trained batch 75 in epoch 6, gen_loss = 0.3969639226009971, disc_loss = 0.13034804096739544
Trained batch 76 in epoch 6, gen_loss = 0.39673010405007897, disc_loss = 0.13021846163969536
Trained batch 77 in epoch 6, gen_loss = 0.39722483051128876, disc_loss = 0.1299023073262129
Trained batch 78 in epoch 6, gen_loss = 0.39778269921677023, disc_loss = 0.1299670948823796
Trained batch 79 in epoch 6, gen_loss = 0.3974610812962055, disc_loss = 0.13101648231968283
Trained batch 80 in epoch 6, gen_loss = 0.398404277033276, disc_loss = 0.13042145112046488
Trained batch 81 in epoch 6, gen_loss = 0.398698454223028, disc_loss = 0.1316290493236809
Trained batch 82 in epoch 6, gen_loss = 0.3982254658118788, disc_loss = 0.13277888971279903
Trained batch 83 in epoch 6, gen_loss = 0.3976787846712839, disc_loss = 0.13381197294663816
Trained batch 84 in epoch 6, gen_loss = 0.3971071639481713, disc_loss = 0.133870585613391
Trained batch 85 in epoch 6, gen_loss = 0.3981217339981434, disc_loss = 0.13399457247104757
Trained batch 86 in epoch 6, gen_loss = 0.39853789648790466, disc_loss = 0.13459358484238043
Trained batch 87 in epoch 6, gen_loss = 0.39953175898302684, disc_loss = 0.13468376572497867
Trained batch 88 in epoch 6, gen_loss = 0.399919916404767, disc_loss = 0.13499682162250026
Trained batch 89 in epoch 6, gen_loss = 0.4000898907581965, disc_loss = 0.13403988629579544
Trained batch 90 in epoch 6, gen_loss = 0.40055060877904786, disc_loss = 0.13339159465753114
Trained batch 91 in epoch 6, gen_loss = 0.40032492804786435, disc_loss = 0.13306685537099838
Trained batch 92 in epoch 6, gen_loss = 0.4005678177520793, disc_loss = 0.13318605720996857
Trained batch 93 in epoch 6, gen_loss = 0.4008043332302824, disc_loss = 0.1324158249066231
Trained batch 94 in epoch 6, gen_loss = 0.4001597950333043, disc_loss = 0.13293579957987134
Trained batch 95 in epoch 6, gen_loss = 0.3997023915871978, disc_loss = 0.13289428874850273
Trained batch 96 in epoch 6, gen_loss = 0.39963190426531525, disc_loss = 0.13301266883451915
Trained batch 97 in epoch 6, gen_loss = 0.3989624298956929, disc_loss = 0.13276950969379775
Trained batch 98 in epoch 6, gen_loss = 0.39957866072654724, disc_loss = 0.13260112650165654
Trained batch 99 in epoch 6, gen_loss = 0.4000922966003418, disc_loss = 0.13230187468230725
Trained batch 100 in epoch 6, gen_loss = 0.39952872088640046, disc_loss = 0.13203767060053231
Trained batch 101 in epoch 6, gen_loss = 0.39937682508253586, disc_loss = 0.13224112198633306
Trained batch 102 in epoch 6, gen_loss = 0.3992900579299742, disc_loss = 0.13348316914826922
Trained batch 103 in epoch 6, gen_loss = 0.399820507145845, disc_loss = 0.13297938670103365
Trained batch 104 in epoch 6, gen_loss = 0.40001269153186253, disc_loss = 0.13273821260247912
Trained batch 105 in epoch 6, gen_loss = 0.4003830389031824, disc_loss = 0.1323115642200101
Trained batch 106 in epoch 6, gen_loss = 0.4005196902239434, disc_loss = 0.13205932310529958
Trained batch 107 in epoch 6, gen_loss = 0.40048564115056284, disc_loss = 0.13151546919511425
Trained batch 108 in epoch 6, gen_loss = 0.40003994845469065, disc_loss = 0.13142122130054945
Trained batch 109 in epoch 6, gen_loss = 0.4001626109535044, disc_loss = 0.13191049417311496
Trained batch 110 in epoch 6, gen_loss = 0.3997445098451666, disc_loss = 0.1327253003512417
Trained batch 111 in epoch 6, gen_loss = 0.399649392547352, disc_loss = 0.13227205676957965
Trained batch 112 in epoch 6, gen_loss = 0.39938085374578963, disc_loss = 0.13166340176774338
Trained batch 113 in epoch 6, gen_loss = 0.39940501409664486, disc_loss = 0.13125052492608102
Trained batch 114 in epoch 6, gen_loss = 0.39917478379995924, disc_loss = 0.13094519085210302
Trained batch 115 in epoch 6, gen_loss = 0.40026206471796694, disc_loss = 0.13049288973982992
Trained batch 116 in epoch 6, gen_loss = 0.3996928943018628, disc_loss = 0.13050936678281197
Trained batch 117 in epoch 6, gen_loss = 0.39952661198074535, disc_loss = 0.13016717255873195
Trained batch 118 in epoch 6, gen_loss = 0.39900030433630745, disc_loss = 0.12998512806762166
Trained batch 119 in epoch 6, gen_loss = 0.3986678558091323, disc_loss = 0.12990585130949814
Trained batch 120 in epoch 6, gen_loss = 0.3988283266705915, disc_loss = 0.12940482764450972
Trained batch 121 in epoch 6, gen_loss = 0.39885467681728426, disc_loss = 0.12957409970828745
Trained batch 122 in epoch 6, gen_loss = 0.398268508232706, disc_loss = 0.12916124836216128
Trained batch 123 in epoch 6, gen_loss = 0.398377887904644, disc_loss = 0.1290962399253922
Trained batch 124 in epoch 6, gen_loss = 0.3983238093852997, disc_loss = 0.12887404781579972
Trained batch 125 in epoch 6, gen_loss = 0.3985567544660871, disc_loss = 0.12832339495302192
Trained batch 126 in epoch 6, gen_loss = 0.39881519069821814, disc_loss = 0.12808398711751764
Trained batch 127 in epoch 6, gen_loss = 0.39886273397132754, disc_loss = 0.12822803246672265
Trained batch 128 in epoch 6, gen_loss = 0.39912308740985486, disc_loss = 0.12776699803711833
Trained batch 129 in epoch 6, gen_loss = 0.3994550835627776, disc_loss = 0.1272961888462305
Trained batch 130 in epoch 6, gen_loss = 0.3997527299491504, disc_loss = 0.1274525243646771
Trained batch 131 in epoch 6, gen_loss = 0.3996933522549542, disc_loss = 0.12764309123722892
Trained batch 132 in epoch 6, gen_loss = 0.39898115799839334, disc_loss = 0.127824644201008
Trained batch 133 in epoch 6, gen_loss = 0.3998542218955595, disc_loss = 0.12745231042490968
Trained batch 134 in epoch 6, gen_loss = 0.3990251399852611, disc_loss = 0.1270184762775898
Trained batch 135 in epoch 6, gen_loss = 0.3989993517889696, disc_loss = 0.1271554344224141
Trained batch 136 in epoch 6, gen_loss = 0.3994002342224121, disc_loss = 0.12707967156150046
Trained batch 137 in epoch 6, gen_loss = 0.39871445967667346, disc_loss = 0.12753209409614405
Trained batch 138 in epoch 6, gen_loss = 0.3990608258641881, disc_loss = 0.1274936702772439
Trained batch 139 in epoch 6, gen_loss = 0.4000919731599944, disc_loss = 0.1272920555035983
Trained batch 140 in epoch 6, gen_loss = 0.4001187633538077, disc_loss = 0.1275808168377014
Trained batch 141 in epoch 6, gen_loss = 0.39977304175705974, disc_loss = 0.12818318057123204
Trained batch 142 in epoch 6, gen_loss = 0.3994472501994847, disc_loss = 0.12857418634987378
Trained batch 143 in epoch 6, gen_loss = 0.3997256923466921, disc_loss = 0.12817701161839068
Trained batch 144 in epoch 6, gen_loss = 0.39998182531060844, disc_loss = 0.12802818677034872
Trained batch 145 in epoch 6, gen_loss = 0.39948163497937866, disc_loss = 0.12787456802819688
Trained batch 146 in epoch 6, gen_loss = 0.39947937013340645, disc_loss = 0.12805889366942197
Trained batch 147 in epoch 6, gen_loss = 0.39964961180010355, disc_loss = 0.12839930738649658
Trained batch 148 in epoch 6, gen_loss = 0.39990292679543465, disc_loss = 0.12782417957814748
Trained batch 149 in epoch 6, gen_loss = 0.4001192267735799, disc_loss = 0.1275299267967542
Trained batch 150 in epoch 6, gen_loss = 0.39965745471171193, disc_loss = 0.12808987893016133
Trained batch 151 in epoch 6, gen_loss = 0.4000260267210634, disc_loss = 0.12840592272971807
Trained batch 152 in epoch 6, gen_loss = 0.399637392143798, disc_loss = 0.12853297971042932
Trained batch 153 in epoch 6, gen_loss = 0.3997834711879879, disc_loss = 0.12808670536554478
Trained batch 154 in epoch 6, gen_loss = 0.3999759201080568, disc_loss = 0.12798141128113194
Trained batch 155 in epoch 6, gen_loss = 0.399918505587639, disc_loss = 0.12805531491549352
Trained batch 156 in epoch 6, gen_loss = 0.39987829137759606, disc_loss = 0.12763360016949618
Trained batch 157 in epoch 6, gen_loss = 0.4003610905212692, disc_loss = 0.12787453460070905
Trained batch 158 in epoch 6, gen_loss = 0.40068265683246107, disc_loss = 0.12758933773861741
Trained batch 159 in epoch 6, gen_loss = 0.4001377424225211, disc_loss = 0.1283521154662594
Trained batch 160 in epoch 6, gen_loss = 0.4002545768429774, disc_loss = 0.12968272505247075
Trained batch 161 in epoch 6, gen_loss = 0.40074182697284366, disc_loss = 0.12956136987073186
Trained batch 162 in epoch 6, gen_loss = 0.40094454796767676, disc_loss = 0.1298740570850533
Trained batch 163 in epoch 6, gen_loss = 0.4006848139006917, disc_loss = 0.12997118990141443
Trained batch 164 in epoch 6, gen_loss = 0.4006117661794027, disc_loss = 0.13000552263675313
Trained batch 165 in epoch 6, gen_loss = 0.4007762753101717, disc_loss = 0.13038255550326353
Trained batch 166 in epoch 6, gen_loss = 0.40090056754157927, disc_loss = 0.13035526450076504
Trained batch 167 in epoch 6, gen_loss = 0.4007937810605481, disc_loss = 0.13034750554444535
Trained batch 168 in epoch 6, gen_loss = 0.4007608313884961, disc_loss = 0.13020021620498606
Trained batch 169 in epoch 6, gen_loss = 0.40065344835028927, disc_loss = 0.13001511699574836
Trained batch 170 in epoch 6, gen_loss = 0.4012680982637127, disc_loss = 0.12963939521309228
Trained batch 171 in epoch 6, gen_loss = 0.40119105802718985, disc_loss = 0.12975750228953223
Trained batch 172 in epoch 6, gen_loss = 0.4007632105336713, disc_loss = 0.12981055468062444
Trained batch 173 in epoch 6, gen_loss = 0.40102228231128606, disc_loss = 0.12996831696865888
Trained batch 174 in epoch 6, gen_loss = 0.40103411504200526, disc_loss = 0.12995764415178981
Trained batch 175 in epoch 6, gen_loss = 0.40122179754755716, disc_loss = 0.13054945885034447
Trained batch 176 in epoch 6, gen_loss = 0.4012036010370416, disc_loss = 0.13146077447944443
Trained batch 177 in epoch 6, gen_loss = 0.40132171468118605, disc_loss = 0.13166029255293057
Trained batch 178 in epoch 6, gen_loss = 0.4020036560530103, disc_loss = 0.13157480411939115
Trained batch 179 in epoch 6, gen_loss = 0.40243432223796843, disc_loss = 0.13213975982119638
Trained batch 180 in epoch 6, gen_loss = 0.4018494570782171, disc_loss = 0.1322219448977083
Trained batch 181 in epoch 6, gen_loss = 0.4021909541481144, disc_loss = 0.13222431495867587
Trained batch 182 in epoch 6, gen_loss = 0.40254654600972034, disc_loss = 0.13256934063275003
Trained batch 183 in epoch 6, gen_loss = 0.4021889641880989, disc_loss = 0.13242438457825262
Trained batch 184 in epoch 6, gen_loss = 0.401766769628267, disc_loss = 0.13229716273175704
Trained batch 185 in epoch 6, gen_loss = 0.4013367929766255, disc_loss = 0.13208159061288963
Trained batch 186 in epoch 6, gen_loss = 0.4012108634818684, disc_loss = 0.13192084477467333
Trained batch 187 in epoch 6, gen_loss = 0.40113586171510374, disc_loss = 0.13184261379486067
Trained batch 188 in epoch 6, gen_loss = 0.4013154880395011, disc_loss = 0.1316597769776034
Trained batch 189 in epoch 6, gen_loss = 0.4014598160982132, disc_loss = 0.13133815250506525
Trained batch 190 in epoch 6, gen_loss = 0.4016676813520062, disc_loss = 0.13125844352454416
Trained batch 191 in epoch 6, gen_loss = 0.40119637673099834, disc_loss = 0.13143272447632626
Trained batch 192 in epoch 6, gen_loss = 0.40227441960665844, disc_loss = 0.13136078318860864
Trained batch 193 in epoch 6, gen_loss = 0.40223320980661925, disc_loss = 0.13091862084555259
Trained batch 194 in epoch 6, gen_loss = 0.4019631440822895, disc_loss = 0.13057012605743532
Trained batch 195 in epoch 6, gen_loss = 0.4019121737504492, disc_loss = 0.13058574872129425
Trained batch 196 in epoch 6, gen_loss = 0.4023524049272392, disc_loss = 0.13037396923917804
Trained batch 197 in epoch 6, gen_loss = 0.4026310458929852, disc_loss = 0.13030119020153175
Trained batch 198 in epoch 6, gen_loss = 0.402383249758476, disc_loss = 0.13034748677257915
Trained batch 199 in epoch 6, gen_loss = 0.40252761349081995, disc_loss = 0.13008817279711365
Trained batch 200 in epoch 6, gen_loss = 0.40240841140201433, disc_loss = 0.1304280886343166
Trained batch 201 in epoch 6, gen_loss = 0.40237084016351415, disc_loss = 0.13024158585853507
Trained batch 202 in epoch 6, gen_loss = 0.40242625839017293, disc_loss = 0.13034732546198544
Trained batch 203 in epoch 6, gen_loss = 0.4022674788446987, disc_loss = 0.13025336385722838
Trained batch 204 in epoch 6, gen_loss = 0.4022999093299959, disc_loss = 0.13001030634452657
Trained batch 205 in epoch 6, gen_loss = 0.4023565790317591, disc_loss = 0.12969220619540192
Trained batch 206 in epoch 6, gen_loss = 0.4024066851622816, disc_loss = 0.1297025927634919
Trained batch 207 in epoch 6, gen_loss = 0.402853536634491, disc_loss = 0.12947378531456566
Trained batch 208 in epoch 6, gen_loss = 0.4029735777366675, disc_loss = 0.1292816123359226
Trained batch 209 in epoch 6, gen_loss = 0.4031891859713055, disc_loss = 0.1295085712735142
Trained batch 210 in epoch 6, gen_loss = 0.4033067264545585, disc_loss = 0.12988742453297733
Trained batch 211 in epoch 6, gen_loss = 0.4028303288626221, disc_loss = 0.13010021300880975
Trained batch 212 in epoch 6, gen_loss = 0.40277512658369935, disc_loss = 0.13007045780339152
Trained batch 213 in epoch 6, gen_loss = 0.4027813301186695, disc_loss = 0.1300870969230048
Trained batch 214 in epoch 6, gen_loss = 0.4025474836659986, disc_loss = 0.12994909319420195
Trained batch 215 in epoch 6, gen_loss = 0.402163992739386, disc_loss = 0.1297969321237394
Trained batch 216 in epoch 6, gen_loss = 0.4022209004323054, disc_loss = 0.12990282886245283
Trained batch 217 in epoch 6, gen_loss = 0.40280699429162053, disc_loss = 0.13014414105051703
Trained batch 218 in epoch 6, gen_loss = 0.4029412397510929, disc_loss = 0.12989604995335075
Trained batch 219 in epoch 6, gen_loss = 0.40284394310279326, disc_loss = 0.1300310022959655
Trained batch 220 in epoch 6, gen_loss = 0.40320274638374465, disc_loss = 0.13013437145907955
Trained batch 221 in epoch 6, gen_loss = 0.40337822593010225, disc_loss = 0.1297155000638586
Trained batch 222 in epoch 6, gen_loss = 0.40377712704141044, disc_loss = 0.12955273291923006
Trained batch 223 in epoch 6, gen_loss = 0.4037648145375507, disc_loss = 0.12977144266811333
Trained batch 224 in epoch 6, gen_loss = 0.40395807610617745, disc_loss = 0.12994836944672797
Trained batch 225 in epoch 6, gen_loss = 0.40435418328352735, disc_loss = 0.12977830780488728
Trained batch 226 in epoch 6, gen_loss = 0.40434501507208737, disc_loss = 0.12949554124920903
Trained batch 227 in epoch 6, gen_loss = 0.40478396833988656, disc_loss = 0.12928826497508245
Trained batch 228 in epoch 6, gen_loss = 0.40487889743788275, disc_loss = 0.12939665520230234
Trained batch 229 in epoch 6, gen_loss = 0.40499991100767385, disc_loss = 0.1290945908135694
Trained batch 230 in epoch 6, gen_loss = 0.40568933910105653, disc_loss = 0.1292343745854768
Trained batch 231 in epoch 6, gen_loss = 0.4055094038104189, disc_loss = 0.1291187204067306
Trained batch 232 in epoch 6, gen_loss = 0.4052113552973506, disc_loss = 0.12902138825074286
Trained batch 233 in epoch 6, gen_loss = 0.40495872892375684, disc_loss = 0.12896847147016954
Trained batch 234 in epoch 6, gen_loss = 0.40494844368163574, disc_loss = 0.129023087357587
Trained batch 235 in epoch 6, gen_loss = 0.40487774688813644, disc_loss = 0.12886639035669928
Trained batch 236 in epoch 6, gen_loss = 0.40482427751967676, disc_loss = 0.1286607575033033
Trained batch 237 in epoch 6, gen_loss = 0.4047545234696204, disc_loss = 0.12848680690243966
Trained batch 238 in epoch 6, gen_loss = 0.40515433295501324, disc_loss = 0.128203317024219
Trained batch 239 in epoch 6, gen_loss = 0.40549528362850346, disc_loss = 0.1278993599737684
Trained batch 240 in epoch 6, gen_loss = 0.40581026871174697, disc_loss = 0.12772650333484672
Trained batch 241 in epoch 6, gen_loss = 0.4058332987560714, disc_loss = 0.12740968917458018
Trained batch 242 in epoch 6, gen_loss = 0.4058943817644943, disc_loss = 0.12699061296420333
Trained batch 243 in epoch 6, gen_loss = 0.40586440448389677, disc_loss = 0.12697238690357227
Trained batch 244 in epoch 6, gen_loss = 0.40568061179044296, disc_loss = 0.12708924274359432
Trained batch 245 in epoch 6, gen_loss = 0.40590965759948017, disc_loss = 0.1270394196991271
Trained batch 246 in epoch 6, gen_loss = 0.40609871834395866, disc_loss = 0.12713622698477406
Trained batch 247 in epoch 6, gen_loss = 0.4061256645908279, disc_loss = 0.12714825902554777
Trained batch 248 in epoch 6, gen_loss = 0.40588887508614474, disc_loss = 0.12723814311575699
Trained batch 249 in epoch 6, gen_loss = 0.4059627619981766, disc_loss = 0.126944268360734
Trained batch 250 in epoch 6, gen_loss = 0.4059855135313543, disc_loss = 0.1266255553707896
Trained batch 251 in epoch 6, gen_loss = 0.40598818849003504, disc_loss = 0.1268461923602791
Trained batch 252 in epoch 6, gen_loss = 0.40577755709410657, disc_loss = 0.12773164257171596
Trained batch 253 in epoch 6, gen_loss = 0.40564270211955694, disc_loss = 0.12751893935299766
Trained batch 254 in epoch 6, gen_loss = 0.40606966696533503, disc_loss = 0.12763402048571437
Trained batch 255 in epoch 6, gen_loss = 0.40578233264386654, disc_loss = 0.12887068786949385
Trained batch 256 in epoch 6, gen_loss = 0.4061865859922268, disc_loss = 0.12911621514519364
Trained batch 257 in epoch 6, gen_loss = 0.40622325449488883, disc_loss = 0.12912116466855356
Trained batch 258 in epoch 6, gen_loss = 0.4059130486144062, disc_loss = 0.12890024683132595
Trained batch 259 in epoch 6, gen_loss = 0.40590441616681905, disc_loss = 0.12872772278407446
Trained batch 260 in epoch 6, gen_loss = 0.40604790714051986, disc_loss = 0.1287696978569716
Trained batch 261 in epoch 6, gen_loss = 0.40593693843324674, disc_loss = 0.12867523108445506
Trained batch 262 in epoch 6, gen_loss = 0.40612033904731953, disc_loss = 0.12849496912650282
Trained batch 263 in epoch 6, gen_loss = 0.40631749966379366, disc_loss = 0.12828985309566965
Trained batch 264 in epoch 6, gen_loss = 0.4067315719037686, disc_loss = 0.1282750869556418
Trained batch 265 in epoch 6, gen_loss = 0.4064198721172218, disc_loss = 0.12829508244487128
Trained batch 266 in epoch 6, gen_loss = 0.4063310320680954, disc_loss = 0.12807630754532887
Trained batch 267 in epoch 6, gen_loss = 0.4061296008416076, disc_loss = 0.12819694186936118
Trained batch 268 in epoch 6, gen_loss = 0.4062283610765819, disc_loss = 0.12833242886959398
Trained batch 269 in epoch 6, gen_loss = 0.4061544956984343, disc_loss = 0.12809267202737154
Trained batch 270 in epoch 6, gen_loss = 0.40596388208910106, disc_loss = 0.1284185616485087
Trained batch 271 in epoch 6, gen_loss = 0.405858981587431, disc_loss = 0.12865467116181903
Trained batch 272 in epoch 6, gen_loss = 0.4058848636927622, disc_loss = 0.1283457082570036
Trained batch 273 in epoch 6, gen_loss = 0.4059877213987991, disc_loss = 0.12811998969936458
Trained batch 274 in epoch 6, gen_loss = 0.4060053034262224, disc_loss = 0.12790466984564608
Trained batch 275 in epoch 6, gen_loss = 0.40634147423333017, disc_loss = 0.12791072446313026
Trained batch 276 in epoch 6, gen_loss = 0.40647577873636237, disc_loss = 0.12754709581551998
Trained batch 277 in epoch 6, gen_loss = 0.40632202631706815, disc_loss = 0.12731536602427204
Trained batch 278 in epoch 6, gen_loss = 0.4062496153470863, disc_loss = 0.1271350444778533
Trained batch 279 in epoch 6, gen_loss = 0.4067891375294754, disc_loss = 0.1269072820166392
Trained batch 280 in epoch 6, gen_loss = 0.40669695561042457, disc_loss = 0.1266564959096739
Trained batch 281 in epoch 6, gen_loss = 0.4063495142874143, disc_loss = 0.12734773480300363
Trained batch 282 in epoch 6, gen_loss = 0.40649510967436614, disc_loss = 0.12723549376422863
Trained batch 283 in epoch 6, gen_loss = 0.40683778511806273, disc_loss = 0.1270895116818203
Trained batch 284 in epoch 6, gen_loss = 0.4070127174519656, disc_loss = 0.12698459748113364
Trained batch 285 in epoch 6, gen_loss = 0.40711933322302946, disc_loss = 0.12710553425904755
Trained batch 286 in epoch 6, gen_loss = 0.40717179216574295, disc_loss = 0.1269820608224603
Trained batch 287 in epoch 6, gen_loss = 0.40717845544632936, disc_loss = 0.12698117716030943
Trained batch 288 in epoch 6, gen_loss = 0.4070507235386792, disc_loss = 0.1266822824995823
Trained batch 289 in epoch 6, gen_loss = 0.4073661058113493, disc_loss = 0.1263751390165296
Trained batch 290 in epoch 6, gen_loss = 0.4074791539780463, disc_loss = 0.12621915430035377
Trained batch 291 in epoch 6, gen_loss = 0.4073327144939605, disc_loss = 0.126088393418348
Trained batch 292 in epoch 6, gen_loss = 0.4073133572376629, disc_loss = 0.12592388508974894
Trained batch 293 in epoch 6, gen_loss = 0.40771651937037096, disc_loss = 0.12563964274718242
Trained batch 294 in epoch 6, gen_loss = 0.40771951160188447, disc_loss = 0.12544992789626122
Trained batch 295 in epoch 6, gen_loss = 0.40774112043751254, disc_loss = 0.12587328709510937
Trained batch 296 in epoch 6, gen_loss = 0.40795785539880747, disc_loss = 0.1258376580521916
Trained batch 297 in epoch 6, gen_loss = 0.40808587216290854, disc_loss = 0.12550145151381126
Trained batch 298 in epoch 6, gen_loss = 0.40812121057590117, disc_loss = 0.12637310526193585
Trained batch 299 in epoch 6, gen_loss = 0.40818827430407206, disc_loss = 0.12701504562050103
Trained batch 300 in epoch 6, gen_loss = 0.40810210384007706, disc_loss = 0.12716011785936118
Trained batch 301 in epoch 6, gen_loss = 0.40820814590185683, disc_loss = 0.12707045803845718
Trained batch 302 in epoch 6, gen_loss = 0.4084959506201665, disc_loss = 0.12686783838832733
Trained batch 303 in epoch 6, gen_loss = 0.4085160319350268, disc_loss = 0.12672749584491708
Trained batch 304 in epoch 6, gen_loss = 0.4083377353480605, disc_loss = 0.12659361300165536
Trained batch 305 in epoch 6, gen_loss = 0.4085787544453066, disc_loss = 0.1263321396572138
Trained batch 306 in epoch 6, gen_loss = 0.40844868904992887, disc_loss = 0.12629764837725543
Trained batch 307 in epoch 6, gen_loss = 0.4087183669983567, disc_loss = 0.12635749503486343
Trained batch 308 in epoch 6, gen_loss = 0.4086540273863907, disc_loss = 0.12641765980176556
Trained batch 309 in epoch 6, gen_loss = 0.4083680164429449, disc_loss = 0.12683497693750165
Trained batch 310 in epoch 6, gen_loss = 0.4083785864126261, disc_loss = 0.12695801064036666
Trained batch 311 in epoch 6, gen_loss = 0.408489621984653, disc_loss = 0.12671720726081195
Trained batch 312 in epoch 6, gen_loss = 0.40830368908068626, disc_loss = 0.12680251613116492
Trained batch 313 in epoch 6, gen_loss = 0.40859248493887057, disc_loss = 0.12709850967404948
Trained batch 314 in epoch 6, gen_loss = 0.4081249346808782, disc_loss = 0.12770093246584846
Trained batch 315 in epoch 6, gen_loss = 0.4081642103346088, disc_loss = 0.12748040183435513
Trained batch 316 in epoch 6, gen_loss = 0.4080356230683131, disc_loss = 0.12742177060913965
Trained batch 317 in epoch 6, gen_loss = 0.40806972680601683, disc_loss = 0.12719387304529828
Trained batch 318 in epoch 6, gen_loss = 0.40796864677372396, disc_loss = 0.12714270692680696
Trained batch 319 in epoch 6, gen_loss = 0.40784319238737227, disc_loss = 0.12697133825859055
Trained batch 320 in epoch 6, gen_loss = 0.40766649853403325, disc_loss = 0.1267672381088184
Trained batch 321 in epoch 6, gen_loss = 0.40754026017203837, disc_loss = 0.12676066441334183
Trained batch 322 in epoch 6, gen_loss = 0.4073685484220369, disc_loss = 0.12658751600251847
Trained batch 323 in epoch 6, gen_loss = 0.4071157585691523, disc_loss = 0.12668428288335787
Trained batch 324 in epoch 6, gen_loss = 0.40726701222933254, disc_loss = 0.1264870785176754
Trained batch 325 in epoch 6, gen_loss = 0.40754239517121227, disc_loss = 0.12631174619166763
Trained batch 326 in epoch 6, gen_loss = 0.4076288813662456, disc_loss = 0.12614686863457025
Trained batch 327 in epoch 6, gen_loss = 0.4075939333656939, disc_loss = 0.1260234996926312
Trained batch 328 in epoch 6, gen_loss = 0.40742082454513273, disc_loss = 0.12579738098482593
Trained batch 329 in epoch 6, gen_loss = 0.4074590799483386, disc_loss = 0.12571410878815434
Trained batch 330 in epoch 6, gen_loss = 0.40734700493942216, disc_loss = 0.1259369280110493
Trained batch 331 in epoch 6, gen_loss = 0.4073849219873727, disc_loss = 0.12591373241585063
Trained batch 332 in epoch 6, gen_loss = 0.4075305254251749, disc_loss = 0.1257899735715833
Trained batch 333 in epoch 6, gen_loss = 0.4072860029643167, disc_loss = 0.1256928180573051
Trained batch 334 in epoch 6, gen_loss = 0.4074828556224481, disc_loss = 0.12553366030107682
Trained batch 335 in epoch 6, gen_loss = 0.40735506630014806, disc_loss = 0.12546246448930884
Trained batch 336 in epoch 6, gen_loss = 0.4073195316848132, disc_loss = 0.12539028204999622
Trained batch 337 in epoch 6, gen_loss = 0.40722338202789693, disc_loss = 0.1253377515161355
Trained batch 338 in epoch 6, gen_loss = 0.4072991839024873, disc_loss = 0.1250849204758803
Trained batch 339 in epoch 6, gen_loss = 0.40720158228102854, disc_loss = 0.12487228672732326
Trained batch 340 in epoch 6, gen_loss = 0.4072563455076861, disc_loss = 0.12469318065562905
Trained batch 341 in epoch 6, gen_loss = 0.40761238397562016, disc_loss = 0.12472125118848873
Trained batch 342 in epoch 6, gen_loss = 0.4076478975681105, disc_loss = 0.12447316099620769
Trained batch 343 in epoch 6, gen_loss = 0.4077457277927288, disc_loss = 0.12426441999932014
Trained batch 344 in epoch 6, gen_loss = 0.4075450653615205, disc_loss = 0.12405740601429041
Trained batch 345 in epoch 6, gen_loss = 0.4075911052826512, disc_loss = 0.12413917042616475
Trained batch 346 in epoch 6, gen_loss = 0.4080249436135251, disc_loss = 0.12426297310793434
Trained batch 347 in epoch 6, gen_loss = 0.40787725022126886, disc_loss = 0.12450877778317737
Trained batch 348 in epoch 6, gen_loss = 0.4079766004509092, disc_loss = 0.12458502738216204
Trained batch 349 in epoch 6, gen_loss = 0.4080508497783116, disc_loss = 0.12511954192604338
Trained batch 350 in epoch 6, gen_loss = 0.40794266178737, disc_loss = 0.1253165847215897
Trained batch 351 in epoch 6, gen_loss = 0.4076630805873058, disc_loss = 0.12540028769184242
Trained batch 352 in epoch 6, gen_loss = 0.40755408377552843, disc_loss = 0.12536781806783703
Trained batch 353 in epoch 6, gen_loss = 0.40752524314290384, disc_loss = 0.12533551904946397
Trained batch 354 in epoch 6, gen_loss = 0.40770429314022333, disc_loss = 0.12534891761524578
Trained batch 355 in epoch 6, gen_loss = 0.4078993985659621, disc_loss = 0.12528926684531602
Trained batch 356 in epoch 6, gen_loss = 0.40784711330210793, disc_loss = 0.12547790188164937
Trained batch 357 in epoch 6, gen_loss = 0.4080590496682588, disc_loss = 0.12528258362295908
Trained batch 358 in epoch 6, gen_loss = 0.4079892045110049, disc_loss = 0.12521804234111542
Trained batch 359 in epoch 6, gen_loss = 0.40797237844930756, disc_loss = 0.12513890353341897
Trained batch 360 in epoch 6, gen_loss = 0.40815234597039685, disc_loss = 0.12505767413949043
Trained batch 361 in epoch 6, gen_loss = 0.40798945889617855, disc_loss = 0.1251605746248809
Trained batch 362 in epoch 6, gen_loss = 0.40793661736259773, disc_loss = 0.12517600364921508
Trained batch 363 in epoch 6, gen_loss = 0.40823300854190364, disc_loss = 0.12532053322909953
Trained batch 364 in epoch 6, gen_loss = 0.40812096456958824, disc_loss = 0.1251583993026655
Trained batch 365 in epoch 6, gen_loss = 0.4082150205236966, disc_loss = 0.12510768069677014
Trained batch 366 in epoch 6, gen_loss = 0.408477434670243, disc_loss = 0.12497608146404375
Trained batch 367 in epoch 6, gen_loss = 0.4084093260538319, disc_loss = 0.12506715117184364
Trained batch 368 in epoch 6, gen_loss = 0.40855468038297926, disc_loss = 0.12494308515615903
Trained batch 369 in epoch 6, gen_loss = 0.40856524681722795, disc_loss = 0.12510850248304572
Trained batch 370 in epoch 6, gen_loss = 0.4085872559695231, disc_loss = 0.12521254783370744
Trained batch 371 in epoch 6, gen_loss = 0.4084697258408352, disc_loss = 0.12523739604699996
Trained batch 372 in epoch 6, gen_loss = 0.40843433629092196, disc_loss = 0.12516001615942962
Trained batch 373 in epoch 6, gen_loss = 0.4083265908421042, disc_loss = 0.12499671475214755
Trained batch 374 in epoch 6, gen_loss = 0.40833753895759584, disc_loss = 0.12487180777390798
Trained batch 375 in epoch 6, gen_loss = 0.4083233987714382, disc_loss = 0.12484863503499234
Trained batch 376 in epoch 6, gen_loss = 0.4081885252612339, disc_loss = 0.12469339884560683
Trained batch 377 in epoch 6, gen_loss = 0.4085891679638908, disc_loss = 0.1245090767209019
Trained batch 378 in epoch 6, gen_loss = 0.40863463730799493, disc_loss = 0.12433468285053575
Trained batch 379 in epoch 6, gen_loss = 0.4083690309995099, disc_loss = 0.1242776351931848
Trained batch 380 in epoch 6, gen_loss = 0.4084708092250223, disc_loss = 0.12430756979101286
Trained batch 381 in epoch 6, gen_loss = 0.4084613437896, disc_loss = 0.1242952022447948
Trained batch 382 in epoch 6, gen_loss = 0.4082766590790711, disc_loss = 0.12433893653727075
Trained batch 383 in epoch 6, gen_loss = 0.4081450918844591, disc_loss = 0.12417085250490345
Trained batch 384 in epoch 6, gen_loss = 0.4082784068274808, disc_loss = 0.1240783939404147
Trained batch 385 in epoch 6, gen_loss = 0.40830896177131276, disc_loss = 0.12413301904700272
Trained batch 386 in epoch 6, gen_loss = 0.4081637332605761, disc_loss = 0.12408137106810738
Trained batch 387 in epoch 6, gen_loss = 0.40807470633197074, disc_loss = 0.12389886765212742
Trained batch 388 in epoch 6, gen_loss = 0.4082817845142286, disc_loss = 0.12381090700702986
Trained batch 389 in epoch 6, gen_loss = 0.40826570475712803, disc_loss = 0.12357755935727022
Trained batch 390 in epoch 6, gen_loss = 0.40819829252674755, disc_loss = 0.12349385080282646
Trained batch 391 in epoch 6, gen_loss = 0.4081390876399011, disc_loss = 0.12340994783658155
Trained batch 392 in epoch 6, gen_loss = 0.4082007402833788, disc_loss = 0.1233610150430342
Trained batch 393 in epoch 6, gen_loss = 0.40827726916915874, disc_loss = 0.12325370695612152
Trained batch 394 in epoch 6, gen_loss = 0.4083808855165409, disc_loss = 0.12311718111174016
Trained batch 395 in epoch 6, gen_loss = 0.4085548170136683, disc_loss = 0.12291334059578601
Trained batch 396 in epoch 6, gen_loss = 0.4086207423912788, disc_loss = 0.122863878737619
Trained batch 397 in epoch 6, gen_loss = 0.40892615742120314, disc_loss = 0.12284408807380115
Trained batch 398 in epoch 6, gen_loss = 0.4086976506955044, disc_loss = 0.12268393235584549
Trained batch 399 in epoch 6, gen_loss = 0.4086706855893135, disc_loss = 0.12256953814066947
Trained batch 400 in epoch 6, gen_loss = 0.40860182017162255, disc_loss = 0.12273255801594762
Trained batch 401 in epoch 6, gen_loss = 0.4085874268368109, disc_loss = 0.1225794047135767
Trained batch 402 in epoch 6, gen_loss = 0.40876008337248054, disc_loss = 0.12236639336860801
Trained batch 403 in epoch 6, gen_loss = 0.4087667102270787, disc_loss = 0.12224996489205278
Trained batch 404 in epoch 6, gen_loss = 0.40860350117271327, disc_loss = 0.12239880430293672
Trained batch 405 in epoch 6, gen_loss = 0.40842165449276346, disc_loss = 0.12250104639220413
Trained batch 406 in epoch 6, gen_loss = 0.40843064874337404, disc_loss = 0.12251234114060237
Trained batch 407 in epoch 6, gen_loss = 0.40846025206002534, disc_loss = 0.12237391130560461
Trained batch 408 in epoch 6, gen_loss = 0.4082875835429194, disc_loss = 0.12236250462443146
Trained batch 409 in epoch 6, gen_loss = 0.4084058611858182, disc_loss = 0.12220499968928535
Trained batch 410 in epoch 6, gen_loss = 0.40840482233214553, disc_loss = 0.1222638266201872
Trained batch 411 in epoch 6, gen_loss = 0.4084266830705902, disc_loss = 0.12213767666225005
Trained batch 412 in epoch 6, gen_loss = 0.4083860625510643, disc_loss = 0.12204862740477118
Trained batch 413 in epoch 6, gen_loss = 0.40853161605947835, disc_loss = 0.12194686779833358
Trained batch 414 in epoch 6, gen_loss = 0.40847731074654914, disc_loss = 0.1220602534711361
Trained batch 415 in epoch 6, gen_loss = 0.40854786329257947, disc_loss = 0.12195265473117335
Trained batch 416 in epoch 6, gen_loss = 0.40862382837622574, disc_loss = 0.12192587298061922
Trained batch 417 in epoch 6, gen_loss = 0.40861588067700416, disc_loss = 0.12185148097146926
Trained batch 418 in epoch 6, gen_loss = 0.4085307934972722, disc_loss = 0.1218260436414392
Trained batch 419 in epoch 6, gen_loss = 0.408486118770781, disc_loss = 0.12196182829460928
Trained batch 420 in epoch 6, gen_loss = 0.4086617353126725, disc_loss = 0.12181246164752582
Trained batch 421 in epoch 6, gen_loss = 0.4087564181801267, disc_loss = 0.12191838796705148
Trained batch 422 in epoch 6, gen_loss = 0.40896170718450076, disc_loss = 0.1223198585564504
Trained batch 423 in epoch 6, gen_loss = 0.40902683307539744, disc_loss = 0.12234496754892873
Trained batch 424 in epoch 6, gen_loss = 0.40889369705144096, disc_loss = 0.12290176048874855
Trained batch 425 in epoch 6, gen_loss = 0.4091775122802582, disc_loss = 0.12283042439657478
Trained batch 426 in epoch 6, gen_loss = 0.4090355541164479, disc_loss = 0.12283538015825408
Trained batch 427 in epoch 6, gen_loss = 0.4090353806859979, disc_loss = 0.12274079803795179
Trained batch 428 in epoch 6, gen_loss = 0.4089348034842031, disc_loss = 0.12266383380010411
Trained batch 429 in epoch 6, gen_loss = 0.40911120356515396, disc_loss = 0.12254448313872482
Trained batch 430 in epoch 6, gen_loss = 0.4090292198613735, disc_loss = 0.12258781357009284
Trained batch 431 in epoch 6, gen_loss = 0.40912822144175015, disc_loss = 0.1224868950623743
Trained batch 432 in epoch 6, gen_loss = 0.40911121064190503, disc_loss = 0.12240723560953526
Trained batch 433 in epoch 6, gen_loss = 0.40915485941869323, disc_loss = 0.12239843722827698
Trained batch 434 in epoch 6, gen_loss = 0.40926152885645284, disc_loss = 0.12235973137377322
Trained batch 435 in epoch 6, gen_loss = 0.40937699069943995, disc_loss = 0.12235912471291942
Trained batch 436 in epoch 6, gen_loss = 0.4095283917895171, disc_loss = 0.12233421689824327
Trained batch 437 in epoch 6, gen_loss = 0.4094444424186123, disc_loss = 0.12229659011136723
Trained batch 438 in epoch 6, gen_loss = 0.409334765955093, disc_loss = 0.12216245653722987
Trained batch 439 in epoch 6, gen_loss = 0.4092609899287874, disc_loss = 0.1220911124297841
Trained batch 440 in epoch 6, gen_loss = 0.4094930718950674, disc_loss = 0.12198213911076793
Trained batch 441 in epoch 6, gen_loss = 0.4095714771235151, disc_loss = 0.12192001246859854
Trained batch 442 in epoch 6, gen_loss = 0.4096881493623316, disc_loss = 0.12174824916213145
Trained batch 443 in epoch 6, gen_loss = 0.40966352216295293, disc_loss = 0.1219341087381582
Trained batch 444 in epoch 6, gen_loss = 0.40963412154926343, disc_loss = 0.12190945772977357
Trained batch 445 in epoch 6, gen_loss = 0.409606193814577, disc_loss = 0.12195744858261182
Trained batch 446 in epoch 6, gen_loss = 0.4096801637003086, disc_loss = 0.12180210024918486
Trained batch 447 in epoch 6, gen_loss = 0.4096160645463637, disc_loss = 0.12187666830141097
Trained batch 448 in epoch 6, gen_loss = 0.4095417358030986, disc_loss = 0.12180763478069369
Trained batch 449 in epoch 6, gen_loss = 0.4096094697713852, disc_loss = 0.12186799441774686
Trained batch 450 in epoch 6, gen_loss = 0.40974146874410877, disc_loss = 0.12210433533675391
Trained batch 451 in epoch 6, gen_loss = 0.40984149231056194, disc_loss = 0.12209529833521991
Trained batch 452 in epoch 6, gen_loss = 0.4097652708984105, disc_loss = 0.1219610030172808
Trained batch 453 in epoch 6, gen_loss = 0.40968181061587144, disc_loss = 0.12193525315873686
Trained batch 454 in epoch 6, gen_loss = 0.40959474057941647, disc_loss = 0.12195245108597881
Trained batch 455 in epoch 6, gen_loss = 0.4095698759090482, disc_loss = 0.1219383994395142
Trained batch 456 in epoch 6, gen_loss = 0.4097280259074998, disc_loss = 0.12196735189147538
Trained batch 457 in epoch 6, gen_loss = 0.40950607114743975, disc_loss = 0.12193812682866789
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.38034120202064514, disc_loss = 0.10420577973127365
Trained batch 1 in epoch 7, gen_loss = 0.3852965384721756, disc_loss = 0.06621912773698568
Trained batch 2 in epoch 7, gen_loss = 0.4227248728275299, disc_loss = 0.09111752050618331
Trained batch 3 in epoch 7, gen_loss = 0.42813362926244736, disc_loss = 0.10265184147283435
Trained batch 4 in epoch 7, gen_loss = 0.41480287313461306, disc_loss = 0.13685043416917325
Trained batch 5 in epoch 7, gen_loss = 0.407518337170283, disc_loss = 0.14047255087643862
Trained batch 6 in epoch 7, gen_loss = 0.41908216902187895, disc_loss = 0.13026280887424946
Trained batch 7 in epoch 7, gen_loss = 0.41999733448028564, disc_loss = 0.12399594369344413
Trained batch 8 in epoch 7, gen_loss = 0.41627644499142963, disc_loss = 0.11529446579515934
Trained batch 9 in epoch 7, gen_loss = 0.4088028848171234, disc_loss = 0.11361587587743997
Trained batch 10 in epoch 7, gen_loss = 0.40819426016374066, disc_loss = 0.11047321710396897
Trained batch 11 in epoch 7, gen_loss = 0.4030516967177391, disc_loss = 0.10662061860784888
Trained batch 12 in epoch 7, gen_loss = 0.40996453166007996, disc_loss = 0.10559043703744045
Trained batch 13 in epoch 7, gen_loss = 0.4155022714819227, disc_loss = 0.10537975294781583
Trained batch 14 in epoch 7, gen_loss = 0.4182889997959137, disc_loss = 0.10259102396667004
Trained batch 15 in epoch 7, gen_loss = 0.41615804843604565, disc_loss = 0.12106234219390899
Trained batch 16 in epoch 7, gen_loss = 0.41628364955677705, disc_loss = 0.12692582968841581
Trained batch 17 in epoch 7, gen_loss = 0.4126688407527076, disc_loss = 0.12873407711999285
Trained batch 18 in epoch 7, gen_loss = 0.4131952288903688, disc_loss = 0.12564729830544247
Trained batch 19 in epoch 7, gen_loss = 0.41385002583265307, disc_loss = 0.12609761776402592
Trained batch 20 in epoch 7, gen_loss = 0.4170115391413371, disc_loss = 0.12370350646475951
Trained batch 21 in epoch 7, gen_loss = 0.41747566244818946, disc_loss = 0.12155144399201329
Trained batch 22 in epoch 7, gen_loss = 0.4167726946913678, disc_loss = 0.11958003797284934
Trained batch 23 in epoch 7, gen_loss = 0.4188835422197978, disc_loss = 0.11872177361510694
Trained batch 24 in epoch 7, gen_loss = 0.41827123284339907, disc_loss = 0.11734426029026508
Trained batch 25 in epoch 7, gen_loss = 0.41844355716155124, disc_loss = 0.11525824959748067
Trained batch 26 in epoch 7, gen_loss = 0.42209990708916273, disc_loss = 0.11628976415980745
Trained batch 27 in epoch 7, gen_loss = 0.42126450687646866, disc_loss = 0.11680239818191954
Trained batch 28 in epoch 7, gen_loss = 0.4209488496698182, disc_loss = 0.11715292063509596
Trained batch 29 in epoch 7, gen_loss = 0.4230054606993993, disc_loss = 0.11513580524673064
Trained batch 30 in epoch 7, gen_loss = 0.4241576012103788, disc_loss = 0.11325590799172078
Trained batch 31 in epoch 7, gen_loss = 0.4239054471254349, disc_loss = 0.11406723834807053
Trained batch 32 in epoch 7, gen_loss = 0.42548746954311023, disc_loss = 0.11415596989293893
Trained batch 33 in epoch 7, gen_loss = 0.427957122816759, disc_loss = 0.11210205783957944
Trained batch 34 in epoch 7, gen_loss = 0.42536790370941163, disc_loss = 0.11155068198485034
Trained batch 35 in epoch 7, gen_loss = 0.42577307091818917, disc_loss = 0.11192691041570571
Trained batch 36 in epoch 7, gen_loss = 0.4260364569522239, disc_loss = 0.11054085280645538
Trained batch 37 in epoch 7, gen_loss = 0.4234449400713569, disc_loss = 0.11155056683836799
Trained batch 38 in epoch 7, gen_loss = 0.42268358896940184, disc_loss = 0.11261117577743836
Trained batch 39 in epoch 7, gen_loss = 0.421737752109766, disc_loss = 0.11286622215993702
Trained batch 40 in epoch 7, gen_loss = 0.4210768923526857, disc_loss = 0.1121903062321064
Trained batch 41 in epoch 7, gen_loss = 0.4208429895696186, disc_loss = 0.11110341713009846
Trained batch 42 in epoch 7, gen_loss = 0.4199545833953591, disc_loss = 0.11031821686341318
Trained batch 43 in epoch 7, gen_loss = 0.4202687300064347, disc_loss = 0.10879311223768375
Trained batch 44 in epoch 7, gen_loss = 0.42036305401060314, disc_loss = 0.10835993790792095
Trained batch 45 in epoch 7, gen_loss = 0.4204854148885478, disc_loss = 0.1096081491154821
Trained batch 46 in epoch 7, gen_loss = 0.42084729608069077, disc_loss = 0.10906680883403788
Trained batch 47 in epoch 7, gen_loss = 0.4193041529506445, disc_loss = 0.10798102310703446
Trained batch 48 in epoch 7, gen_loss = 0.4187733768200388, disc_loss = 0.10690112894743073
Trained batch 49 in epoch 7, gen_loss = 0.41721739292144777, disc_loss = 0.10698047917336226
Trained batch 50 in epoch 7, gen_loss = 0.4187978658021665, disc_loss = 0.10623311247749656
Trained batch 51 in epoch 7, gen_loss = 0.4192510505135243, disc_loss = 0.10512548925068516
Trained batch 52 in epoch 7, gen_loss = 0.4198446526842297, disc_loss = 0.10515546809249329
Trained batch 53 in epoch 7, gen_loss = 0.4210138315403903, disc_loss = 0.10625037230137321
Trained batch 54 in epoch 7, gen_loss = 0.42077150669964875, disc_loss = 0.10551144788888368
Trained batch 55 in epoch 7, gen_loss = 0.4202358504491193, disc_loss = 0.10557528701610863
Trained batch 56 in epoch 7, gen_loss = 0.4194411593571044, disc_loss = 0.10571272328103844
Trained batch 57 in epoch 7, gen_loss = 0.4189133135409191, disc_loss = 0.10683116904492009
Trained batch 58 in epoch 7, gen_loss = 0.4183914363384247, disc_loss = 0.11033117187098931
Trained batch 59 in epoch 7, gen_loss = 0.41728608558575314, disc_loss = 0.11167208226397633
Trained batch 60 in epoch 7, gen_loss = 0.41671620724631137, disc_loss = 0.11114288716897612
Trained batch 61 in epoch 7, gen_loss = 0.41499970132304775, disc_loss = 0.11075888210607152
Trained batch 62 in epoch 7, gen_loss = 0.4138763655745794, disc_loss = 0.11083977571910336
Trained batch 63 in epoch 7, gen_loss = 0.4129653386771679, disc_loss = 0.11010889065801166
Trained batch 64 in epoch 7, gen_loss = 0.4129092399890606, disc_loss = 0.10961960539794885
Trained batch 65 in epoch 7, gen_loss = 0.41433293620745343, disc_loss = 0.1095760248770768
Trained batch 66 in epoch 7, gen_loss = 0.41401533582317296, disc_loss = 0.11431219248073314
Trained batch 67 in epoch 7, gen_loss = 0.4142061493852559, disc_loss = 0.11312557940426118
Trained batch 68 in epoch 7, gen_loss = 0.4148659550625345, disc_loss = 0.1148908519172582
Trained batch 69 in epoch 7, gen_loss = 0.41447836288384027, disc_loss = 0.11390850488096475
Trained batch 70 in epoch 7, gen_loss = 0.4134309879491027, disc_loss = 0.11396125963771007
Trained batch 71 in epoch 7, gen_loss = 0.4131704519192378, disc_loss = 0.1146601394801918
Trained batch 72 in epoch 7, gen_loss = 0.41296157240867615, disc_loss = 0.11391953580489714
Trained batch 73 in epoch 7, gen_loss = 0.4121123209998414, disc_loss = 0.11555662335878289
Trained batch 74 in epoch 7, gen_loss = 0.41204392313957217, disc_loss = 0.11634808011353016
Trained batch 75 in epoch 7, gen_loss = 0.4135940447449684, disc_loss = 0.11555866149597262
Trained batch 76 in epoch 7, gen_loss = 0.4128229343271875, disc_loss = 0.11555555799080953
Trained batch 77 in epoch 7, gen_loss = 0.41278407741815615, disc_loss = 0.11532531322863622
Trained batch 78 in epoch 7, gen_loss = 0.41336530107486097, disc_loss = 0.11531761625805233
Trained batch 79 in epoch 7, gen_loss = 0.41412106044590474, disc_loss = 0.11556515374686568
Trained batch 80 in epoch 7, gen_loss = 0.4147220353285472, disc_loss = 0.11530212577386403
Trained batch 81 in epoch 7, gen_loss = 0.41474081248771855, disc_loss = 0.114988440488715
Trained batch 82 in epoch 7, gen_loss = 0.4149685340473451, disc_loss = 0.1150100918554039
Trained batch 83 in epoch 7, gen_loss = 0.41562563996939433, disc_loss = 0.11516792644258766
Trained batch 84 in epoch 7, gen_loss = 0.41552816944963794, disc_loss = 0.11490636132657528
Trained batch 85 in epoch 7, gen_loss = 0.4154509652492612, disc_loss = 0.11448833673412717
Trained batch 86 in epoch 7, gen_loss = 0.4148155450820923, disc_loss = 0.11469100242287948
Trained batch 87 in epoch 7, gen_loss = 0.4152943627400832, disc_loss = 0.11392278840172697
Trained batch 88 in epoch 7, gen_loss = 0.4149414120095499, disc_loss = 0.11302112371482875
Trained batch 89 in epoch 7, gen_loss = 0.4149981763627794, disc_loss = 0.11217666411151489
Trained batch 90 in epoch 7, gen_loss = 0.4144806429580018, disc_loss = 0.11224006224873957
Trained batch 91 in epoch 7, gen_loss = 0.41435067452814267, disc_loss = 0.11205381958785912
Trained batch 92 in epoch 7, gen_loss = 0.41488402376892747, disc_loss = 0.11157858477885364
Trained batch 93 in epoch 7, gen_loss = 0.41452355492622295, disc_loss = 0.11282045530908286
Trained batch 94 in epoch 7, gen_loss = 0.41468432420178464, disc_loss = 0.11348523726980937
Trained batch 95 in epoch 7, gen_loss = 0.4147113353634874, disc_loss = 0.11311600002227351
Trained batch 96 in epoch 7, gen_loss = 0.4142700873084904, disc_loss = 0.1129866460741488
Trained batch 97 in epoch 7, gen_loss = 0.4133983719713834, disc_loss = 0.11244518650049458
Trained batch 98 in epoch 7, gen_loss = 0.4129415437428638, disc_loss = 0.1128562292027654
Trained batch 99 in epoch 7, gen_loss = 0.41270710915327075, disc_loss = 0.11329843183979392
Trained batch 100 in epoch 7, gen_loss = 0.4124445820798968, disc_loss = 0.11336787662810029
Trained batch 101 in epoch 7, gen_loss = 0.4123225179957409, disc_loss = 0.11454696688508871
Trained batch 102 in epoch 7, gen_loss = 0.41179241167688835, disc_loss = 0.11383331167394097
Trained batch 103 in epoch 7, gen_loss = 0.4128325842320919, disc_loss = 0.11345205790936373
Trained batch 104 in epoch 7, gen_loss = 0.41259437316939945, disc_loss = 0.11372688261880762
Trained batch 105 in epoch 7, gen_loss = 0.41251016703416715, disc_loss = 0.11361899021310064
Trained batch 106 in epoch 7, gen_loss = 0.411943572703923, disc_loss = 0.1133994607550797
Trained batch 107 in epoch 7, gen_loss = 0.41247954688690325, disc_loss = 0.11280350847583678
Trained batch 108 in epoch 7, gen_loss = 0.41229533547655156, disc_loss = 0.11256016105618499
Trained batch 109 in epoch 7, gen_loss = 0.4119206466458061, disc_loss = 0.11239885428751056
Trained batch 110 in epoch 7, gen_loss = 0.41099928977253203, disc_loss = 0.11206649074347706
Trained batch 111 in epoch 7, gen_loss = 0.4103487424020256, disc_loss = 0.11200792999339423
Trained batch 112 in epoch 7, gen_loss = 0.41034768139366556, disc_loss = 0.11245653657984417
Trained batch 113 in epoch 7, gen_loss = 0.40974409407690954, disc_loss = 0.11311748811746375
Trained batch 114 in epoch 7, gen_loss = 0.4096760957137398, disc_loss = 0.11297407479065916
Trained batch 115 in epoch 7, gen_loss = 0.4105073095395647, disc_loss = 0.11296168738847663
Trained batch 116 in epoch 7, gen_loss = 0.4106066970743685, disc_loss = 0.11308873717028362
Trained batch 117 in epoch 7, gen_loss = 0.40981007228463384, disc_loss = 0.11395958039151916
Trained batch 118 in epoch 7, gen_loss = 0.408716537371403, disc_loss = 0.11404864632469766
Trained batch 119 in epoch 7, gen_loss = 0.4084042487045129, disc_loss = 0.11401072571364541
Trained batch 120 in epoch 7, gen_loss = 0.4093065377601907, disc_loss = 0.11335973710991627
Trained batch 121 in epoch 7, gen_loss = 0.40914289091454176, disc_loss = 0.11341655710864751
Trained batch 122 in epoch 7, gen_loss = 0.40873609931488347, disc_loss = 0.11373743673831951
Trained batch 123 in epoch 7, gen_loss = 0.40890008259204125, disc_loss = 0.11438097845342371
Trained batch 124 in epoch 7, gen_loss = 0.4090332839488983, disc_loss = 0.11411810229718686
Trained batch 125 in epoch 7, gen_loss = 0.40881791356064023, disc_loss = 0.11421001535500326
Trained batch 126 in epoch 7, gen_loss = 0.4089016789995779, disc_loss = 0.11446489838105957
Trained batch 127 in epoch 7, gen_loss = 0.40860133757814765, disc_loss = 0.11450332861568313
Trained batch 128 in epoch 7, gen_loss = 0.408839717853901, disc_loss = 0.1143349188906971
Trained batch 129 in epoch 7, gen_loss = 0.40935367483359114, disc_loss = 0.11518849711865187
Trained batch 130 in epoch 7, gen_loss = 0.4083718188846384, disc_loss = 0.11610490747706126
Trained batch 131 in epoch 7, gen_loss = 0.4081145308234475, disc_loss = 0.11618290913545272
Trained batch 132 in epoch 7, gen_loss = 0.4079115117402901, disc_loss = 0.11603614580082267
Trained batch 133 in epoch 7, gen_loss = 0.40766789308234824, disc_loss = 0.115924483457052
Trained batch 134 in epoch 7, gen_loss = 0.4073499098972038, disc_loss = 0.11606005616486073
Trained batch 135 in epoch 7, gen_loss = 0.4079340564854005, disc_loss = 0.11574797144652728
Trained batch 136 in epoch 7, gen_loss = 0.4082486840495228, disc_loss = 0.11526171679533746
Trained batch 137 in epoch 7, gen_loss = 0.4078359260507252, disc_loss = 0.11523335649753394
Trained batch 138 in epoch 7, gen_loss = 0.40786681286722637, disc_loss = 0.1156142784563972
Trained batch 139 in epoch 7, gen_loss = 0.40820345687014714, disc_loss = 0.11568574092483946
Trained batch 140 in epoch 7, gen_loss = 0.4081455540995226, disc_loss = 0.11570088423999912
Trained batch 141 in epoch 7, gen_loss = 0.4085891842842102, disc_loss = 0.11541010813236656
Trained batch 142 in epoch 7, gen_loss = 0.4093614349832068, disc_loss = 0.1148044214798854
Trained batch 143 in epoch 7, gen_loss = 0.4093082398176193, disc_loss = 0.11481852105094327
Trained batch 144 in epoch 7, gen_loss = 0.4091233590553547, disc_loss = 0.11485001573274875
Trained batch 145 in epoch 7, gen_loss = 0.40851563888869874, disc_loss = 0.11471934642081391
Trained batch 146 in epoch 7, gen_loss = 0.4087771690216194, disc_loss = 0.11413757178653665
Trained batch 147 in epoch 7, gen_loss = 0.40919145438316706, disc_loss = 0.11402618562853015
Trained batch 148 in epoch 7, gen_loss = 0.4090112055708098, disc_loss = 0.11399711948513185
Trained batch 149 in epoch 7, gen_loss = 0.4085992932319641, disc_loss = 0.11369034081697464
Trained batch 150 in epoch 7, gen_loss = 0.40875453960816593, disc_loss = 0.1132206642469823
Trained batch 151 in epoch 7, gen_loss = 0.4094284033696902, disc_loss = 0.11258518290215809
Trained batch 152 in epoch 7, gen_loss = 0.4096726027189517, disc_loss = 0.11337973806836636
Trained batch 153 in epoch 7, gen_loss = 0.4097252822928614, disc_loss = 0.11341115567446142
Trained batch 154 in epoch 7, gen_loss = 0.4101266470647627, disc_loss = 0.11341329919955423
Trained batch 155 in epoch 7, gen_loss = 0.41064103463521373, disc_loss = 0.11518562500341198
Trained batch 156 in epoch 7, gen_loss = 0.4101673112173749, disc_loss = 0.1155012449380129
Trained batch 157 in epoch 7, gen_loss = 0.41029500923579254, disc_loss = 0.11586558555924817
Trained batch 158 in epoch 7, gen_loss = 0.4104678379664631, disc_loss = 0.11596551266903023
Trained batch 159 in epoch 7, gen_loss = 0.4105169469490647, disc_loss = 0.11620647945674137
Trained batch 160 in epoch 7, gen_loss = 0.41035894725633704, disc_loss = 0.11705630537562119
Trained batch 161 in epoch 7, gen_loss = 0.4105191468088715, disc_loss = 0.11705957409454348
Trained batch 162 in epoch 7, gen_loss = 0.4102173604848195, disc_loss = 0.11742658804576456
Trained batch 163 in epoch 7, gen_loss = 0.4099026514989574, disc_loss = 0.11774035953212439
Trained batch 164 in epoch 7, gen_loss = 0.4098420708468466, disc_loss = 0.11797736333400914
Trained batch 165 in epoch 7, gen_loss = 0.40960913878607463, disc_loss = 0.11782832714134311
Trained batch 166 in epoch 7, gen_loss = 0.4099914933036187, disc_loss = 0.11763424534506783
Trained batch 167 in epoch 7, gen_loss = 0.40959737290229115, disc_loss = 0.11768380770947606
Trained batch 168 in epoch 7, gen_loss = 0.4091864468077936, disc_loss = 0.1173923117543995
Trained batch 169 in epoch 7, gen_loss = 0.40943565333590787, disc_loss = 0.11718871261486236
Trained batch 170 in epoch 7, gen_loss = 0.4091819191885273, disc_loss = 0.11710684050462748
Trained batch 171 in epoch 7, gen_loss = 0.4088735110884489, disc_loss = 0.11717060932802946
Trained batch 172 in epoch 7, gen_loss = 0.4090160388133429, disc_loss = 0.11726041987667539
Trained batch 173 in epoch 7, gen_loss = 0.40890294073641986, disc_loss = 0.11708046055944829
Trained batch 174 in epoch 7, gen_loss = 0.40829331857817514, disc_loss = 0.1167663650321109
Trained batch 175 in epoch 7, gen_loss = 0.4084915220737457, disc_loss = 0.11668786443558267
Trained batch 176 in epoch 7, gen_loss = 0.40828731100438004, disc_loss = 0.1169256644039336
Trained batch 177 in epoch 7, gen_loss = 0.4088603994819555, disc_loss = 0.11741589783073476
Trained batch 178 in epoch 7, gen_loss = 0.4092057225757471, disc_loss = 0.11702524592798183
Trained batch 179 in epoch 7, gen_loss = 0.4095602110028267, disc_loss = 0.1171494185200168
Trained batch 180 in epoch 7, gen_loss = 0.4098237586614177, disc_loss = 0.11672293856863489
Trained batch 181 in epoch 7, gen_loss = 0.4103185789925711, disc_loss = 0.1172593215193886
Trained batch 182 in epoch 7, gen_loss = 0.40972089474318457, disc_loss = 0.11709965819421687
Trained batch 183 in epoch 7, gen_loss = 0.4092268074012321, disc_loss = 0.11705175699139743
Trained batch 184 in epoch 7, gen_loss = 0.40905317358068516, disc_loss = 0.11713521852082498
Trained batch 185 in epoch 7, gen_loss = 0.40902576074805314, disc_loss = 0.11730188869380502
Trained batch 186 in epoch 7, gen_loss = 0.40896171841391904, disc_loss = 0.11767517493410225
Trained batch 187 in epoch 7, gen_loss = 0.4093059616837096, disc_loss = 0.11769255422095352
Trained batch 188 in epoch 7, gen_loss = 0.4098139577126377, disc_loss = 0.11715573186754549
Trained batch 189 in epoch 7, gen_loss = 0.4096308581138912, disc_loss = 0.11686780027260905
Trained batch 190 in epoch 7, gen_loss = 0.409659837084915, disc_loss = 0.11661404712584006
Trained batch 191 in epoch 7, gen_loss = 0.4094339427538216, disc_loss = 0.1164518916242135
Trained batch 192 in epoch 7, gen_loss = 0.4091952348928995, disc_loss = 0.11628673841375761
Trained batch 193 in epoch 7, gen_loss = 0.4091306993949045, disc_loss = 0.11632292043686528
Trained batch 194 in epoch 7, gen_loss = 0.40971469833300667, disc_loss = 0.11631658453589831
Trained batch 195 in epoch 7, gen_loss = 0.4098844509951922, disc_loss = 0.11624947100953788
Trained batch 196 in epoch 7, gen_loss = 0.4094790551565625, disc_loss = 0.11623053076833033
Trained batch 197 in epoch 7, gen_loss = 0.4095910153906755, disc_loss = 0.11590438902453341
Trained batch 198 in epoch 7, gen_loss = 0.40934081338158806, disc_loss = 0.1156052262826481
Trained batch 199 in epoch 7, gen_loss = 0.4090517847239971, disc_loss = 0.11568679625168443
Trained batch 200 in epoch 7, gen_loss = 0.40925909482424533, disc_loss = 0.11551890783567927
Trained batch 201 in epoch 7, gen_loss = 0.4089836703963799, disc_loss = 0.1155751694067575
Trained batch 202 in epoch 7, gen_loss = 0.40854173047201975, disc_loss = 0.11543689189212662
Trained batch 203 in epoch 7, gen_loss = 0.40911610804352105, disc_loss = 0.11512856389961991
Trained batch 204 in epoch 7, gen_loss = 0.40943900564821756, disc_loss = 0.11495129836768639
Trained batch 205 in epoch 7, gen_loss = 0.40930205149557986, disc_loss = 0.11473200379789454
Trained batch 206 in epoch 7, gen_loss = 0.4095414017421612, disc_loss = 0.11444741928419053
Trained batch 207 in epoch 7, gen_loss = 0.4094182884750458, disc_loss = 0.11439213667136545
Trained batch 208 in epoch 7, gen_loss = 0.409052138693595, disc_loss = 0.11423399875109846
Trained batch 209 in epoch 7, gen_loss = 0.4089294740131923, disc_loss = 0.11471189361597811
Trained batch 210 in epoch 7, gen_loss = 0.40889816148586183, disc_loss = 0.11466367237305189
Trained batch 211 in epoch 7, gen_loss = 0.4093327263616166, disc_loss = 0.11477268619005973
Trained batch 212 in epoch 7, gen_loss = 0.40898109293879475, disc_loss = 0.1147939697992354
Trained batch 213 in epoch 7, gen_loss = 0.4084392203905872, disc_loss = 0.11529074722430974
Trained batch 214 in epoch 7, gen_loss = 0.4084186828413675, disc_loss = 0.11512265141273653
Trained batch 215 in epoch 7, gen_loss = 0.408501954542266, disc_loss = 0.11500279075914512
Trained batch 216 in epoch 7, gen_loss = 0.4083511444830125, disc_loss = 0.11505991895146633
Trained batch 217 in epoch 7, gen_loss = 0.40875984865044235, disc_loss = 0.1148452216229581
Trained batch 218 in epoch 7, gen_loss = 0.40874213442954843, disc_loss = 0.1147375083507196
Trained batch 219 in epoch 7, gen_loss = 0.40827056643637744, disc_loss = 0.11473342374983159
Trained batch 220 in epoch 7, gen_loss = 0.40814608982785255, disc_loss = 0.11461791161835463
Trained batch 221 in epoch 7, gen_loss = 0.40862944507384086, disc_loss = 0.11439849793709614
Trained batch 222 in epoch 7, gen_loss = 0.4083585501251734, disc_loss = 0.11419371824561213
Trained batch 223 in epoch 7, gen_loss = 0.4084221027525408, disc_loss = 0.11402701069268265
Trained batch 224 in epoch 7, gen_loss = 0.4085704298814138, disc_loss = 0.11397976843847168
Trained batch 225 in epoch 7, gen_loss = 0.40833847343394186, disc_loss = 0.11367982243542123
Trained batch 226 in epoch 7, gen_loss = 0.4085086064191642, disc_loss = 0.11366247520310238
Trained batch 227 in epoch 7, gen_loss = 0.40885709827406364, disc_loss = 0.11437698159562915
Trained batch 228 in epoch 7, gen_loss = 0.4087493605749055, disc_loss = 0.11403812331403708
Trained batch 229 in epoch 7, gen_loss = 0.4083295623893323, disc_loss = 0.11461278154798175
Trained batch 230 in epoch 7, gen_loss = 0.40798783882871853, disc_loss = 0.11621847264952474
Trained batch 231 in epoch 7, gen_loss = 0.4081008903168399, disc_loss = 0.11614548453483088
Trained batch 232 in epoch 7, gen_loss = 0.4080626628173779, disc_loss = 0.11652419373968641
Trained batch 233 in epoch 7, gen_loss = 0.40820192284563667, disc_loss = 0.1171395374286888
Trained batch 234 in epoch 7, gen_loss = 0.40828591838796086, disc_loss = 0.1173119676239947
Trained batch 235 in epoch 7, gen_loss = 0.40777573873430994, disc_loss = 0.11712646503317153
Trained batch 236 in epoch 7, gen_loss = 0.40736946853404304, disc_loss = 0.11703166302749377
Trained batch 237 in epoch 7, gen_loss = 0.40691343150218995, disc_loss = 0.11720771899744242
Trained batch 238 in epoch 7, gen_loss = 0.40734290902085885, disc_loss = 0.11717984407641399
Trained batch 239 in epoch 7, gen_loss = 0.40732770214478176, disc_loss = 0.11710858764126897
Trained batch 240 in epoch 7, gen_loss = 0.40714435866759524, disc_loss = 0.11717481382531249
Trained batch 241 in epoch 7, gen_loss = 0.40697725141836594, disc_loss = 0.11727708864433706
Trained batch 242 in epoch 7, gen_loss = 0.40702202351986133, disc_loss = 0.11693116590196703
Trained batch 243 in epoch 7, gen_loss = 0.40697815562369394, disc_loss = 0.1167207487599283
Trained batch 244 in epoch 7, gen_loss = 0.4068513573432455, disc_loss = 0.11661199419474115
Trained batch 245 in epoch 7, gen_loss = 0.40706229682375744, disc_loss = 0.1168461520436818
Trained batch 246 in epoch 7, gen_loss = 0.4070694218521659, disc_loss = 0.11662706358712695
Trained batch 247 in epoch 7, gen_loss = 0.40650025106245474, disc_loss = 0.11679733538579556
Trained batch 248 in epoch 7, gen_loss = 0.40639004733667794, disc_loss = 0.11700909186797927
Trained batch 249 in epoch 7, gen_loss = 0.4065988824367523, disc_loss = 0.11702110067009926
Trained batch 250 in epoch 7, gen_loss = 0.4066582252067399, disc_loss = 0.11680884697878978
Trained batch 251 in epoch 7, gen_loss = 0.406702699760596, disc_loss = 0.116817148875386
Trained batch 252 in epoch 7, gen_loss = 0.40664391519995075, disc_loss = 0.11674379357118381
Trained batch 253 in epoch 7, gen_loss = 0.4064311606912162, disc_loss = 0.11672598760076396
Trained batch 254 in epoch 7, gen_loss = 0.40656518106367073, disc_loss = 0.11651492501590766
Trained batch 255 in epoch 7, gen_loss = 0.4066193640464917, disc_loss = 0.11631596073857509
Trained batch 256 in epoch 7, gen_loss = 0.4066468335775086, disc_loss = 0.11649891406529608
Trained batch 257 in epoch 7, gen_loss = 0.4065887062817581, disc_loss = 0.1167212790239227
Trained batch 258 in epoch 7, gen_loss = 0.4069224016086475, disc_loss = 0.11650611678835968
Trained batch 259 in epoch 7, gen_loss = 0.40725289583206176, disc_loss = 0.11625565313375913
Trained batch 260 in epoch 7, gen_loss = 0.4071903459413755, disc_loss = 0.11625482495945533
Trained batch 261 in epoch 7, gen_loss = 0.40705294474845627, disc_loss = 0.11604349935100279
Trained batch 262 in epoch 7, gen_loss = 0.40720397619240184, disc_loss = 0.11592839437292556
Trained batch 263 in epoch 7, gen_loss = 0.4076049966794072, disc_loss = 0.11605294500336502
Trained batch 264 in epoch 7, gen_loss = 0.40724403160922934, disc_loss = 0.11611426225248372
Trained batch 265 in epoch 7, gen_loss = 0.4069811263702866, disc_loss = 0.11610366838206922
Trained batch 266 in epoch 7, gen_loss = 0.406541620189331, disc_loss = 0.1163002826580394
Trained batch 267 in epoch 7, gen_loss = 0.40684230547787537, disc_loss = 0.1162181791585328
Trained batch 268 in epoch 7, gen_loss = 0.4067946215987649, disc_loss = 0.11636723436719866
Trained batch 269 in epoch 7, gen_loss = 0.40689167590052994, disc_loss = 0.11617989300025834
Trained batch 270 in epoch 7, gen_loss = 0.40673804052201584, disc_loss = 0.11634406626114546
Trained batch 271 in epoch 7, gen_loss = 0.4069195551907315, disc_loss = 0.11639072195462444
Trained batch 272 in epoch 7, gen_loss = 0.40654112480498933, disc_loss = 0.11667743759168374
Trained batch 273 in epoch 7, gen_loss = 0.4066004580172309, disc_loss = 0.1175994807514396
Trained batch 274 in epoch 7, gen_loss = 0.4066409666971727, disc_loss = 0.117356168681925
Trained batch 275 in epoch 7, gen_loss = 0.4067628437626189, disc_loss = 0.1173381272001543
Trained batch 276 in epoch 7, gen_loss = 0.40651467001395103, disc_loss = 0.11722600261011709
Trained batch 277 in epoch 7, gen_loss = 0.4069991549141973, disc_loss = 0.11774933418567232
Trained batch 278 in epoch 7, gen_loss = 0.40699309869051836, disc_loss = 0.11775880565993675
Trained batch 279 in epoch 7, gen_loss = 0.4067943444209439, disc_loss = 0.11779469368713243
Trained batch 280 in epoch 7, gen_loss = 0.40690053050204106, disc_loss = 0.11769320844967594
Trained batch 281 in epoch 7, gen_loss = 0.4067757782783914, disc_loss = 0.11779904291562154
Trained batch 282 in epoch 7, gen_loss = 0.40687230987599377, disc_loss = 0.11769299427633151
Trained batch 283 in epoch 7, gen_loss = 0.40702951636532664, disc_loss = 0.11740017036946726
Trained batch 284 in epoch 7, gen_loss = 0.4067997290377031, disc_loss = 0.11755641573353817
Trained batch 285 in epoch 7, gen_loss = 0.4070573007310187, disc_loss = 0.1172984980203055
Trained batch 286 in epoch 7, gen_loss = 0.4070358318941934, disc_loss = 0.11736272114494536
Trained batch 287 in epoch 7, gen_loss = 0.4070204950662123, disc_loss = 0.11710682472524543
Trained batch 288 in epoch 7, gen_loss = 0.4072358845426962, disc_loss = 0.1169411702448934
Trained batch 289 in epoch 7, gen_loss = 0.4070464548365823, disc_loss = 0.11727360389355955
Trained batch 290 in epoch 7, gen_loss = 0.4069898023023638, disc_loss = 0.11752047397426724
Trained batch 291 in epoch 7, gen_loss = 0.40670460452363916, disc_loss = 0.11735875577959295
Trained batch 292 in epoch 7, gen_loss = 0.40686957034641563, disc_loss = 0.11721942881471875
Trained batch 293 in epoch 7, gen_loss = 0.40718809439211473, disc_loss = 0.11705026408137918
Trained batch 294 in epoch 7, gen_loss = 0.407376047918352, disc_loss = 0.11700058379920862
Trained batch 295 in epoch 7, gen_loss = 0.4073546057617342, disc_loss = 0.11701410845224117
Trained batch 296 in epoch 7, gen_loss = 0.4074427074053472, disc_loss = 0.1169688990872717
Trained batch 297 in epoch 7, gen_loss = 0.40721520341482736, disc_loss = 0.11690183971452232
Trained batch 298 in epoch 7, gen_loss = 0.4073104422826033, disc_loss = 0.11680524380111375
Trained batch 299 in epoch 7, gen_loss = 0.4073046326637268, disc_loss = 0.11682949423789978
Trained batch 300 in epoch 7, gen_loss = 0.4077815407534374, disc_loss = 0.11675051176468795
Trained batch 301 in epoch 7, gen_loss = 0.40752558587797433, disc_loss = 0.11662962934039287
Trained batch 302 in epoch 7, gen_loss = 0.4074613349665903, disc_loss = 0.11665906675971381
Trained batch 303 in epoch 7, gen_loss = 0.40720244938213573, disc_loss = 0.11652356974388424
Trained batch 304 in epoch 7, gen_loss = 0.4074307520858577, disc_loss = 0.11640231115896194
Trained batch 305 in epoch 7, gen_loss = 0.40750521226646075, disc_loss = 0.11617401273908957
Trained batch 306 in epoch 7, gen_loss = 0.40745489634209425, disc_loss = 0.11634143339985745
Trained batch 307 in epoch 7, gen_loss = 0.40780379661878985, disc_loss = 0.1165659274518877
Trained batch 308 in epoch 7, gen_loss = 0.4081268886339317, disc_loss = 0.1164365213569314
Trained batch 309 in epoch 7, gen_loss = 0.40800512683007023, disc_loss = 0.11624117577748914
Trained batch 310 in epoch 7, gen_loss = 0.4078293079540277, disc_loss = 0.11629454664574558
Trained batch 311 in epoch 7, gen_loss = 0.4079603181244471, disc_loss = 0.1165086522173041
Trained batch 312 in epoch 7, gen_loss = 0.40801497103688056, disc_loss = 0.11639259489009175
Trained batch 313 in epoch 7, gen_loss = 0.4078528083813418, disc_loss = 0.11634781987519022
Trained batch 314 in epoch 7, gen_loss = 0.4077316947399624, disc_loss = 0.11626485903111715
Trained batch 315 in epoch 7, gen_loss = 0.4079730633316161, disc_loss = 0.11605931066353864
Trained batch 316 in epoch 7, gen_loss = 0.4078562989219882, disc_loss = 0.11592531871720443
Trained batch 317 in epoch 7, gen_loss = 0.4078628880985128, disc_loss = 0.11593535294135411
Trained batch 318 in epoch 7, gen_loss = 0.4075646654565506, disc_loss = 0.11609897129587993
Trained batch 319 in epoch 7, gen_loss = 0.4073288396000862, disc_loss = 0.11596940103918314
Trained batch 320 in epoch 7, gen_loss = 0.4074286525123216, disc_loss = 0.1157982911786929
Trained batch 321 in epoch 7, gen_loss = 0.4072287660207808, disc_loss = 0.11593514141736563
Trained batch 322 in epoch 7, gen_loss = 0.40709233911413895, disc_loss = 0.11586850011957688
Trained batch 323 in epoch 7, gen_loss = 0.40739324192206067, disc_loss = 0.11579435698136135
Trained batch 324 in epoch 7, gen_loss = 0.40729716594402604, disc_loss = 0.11565763157147628
Trained batch 325 in epoch 7, gen_loss = 0.4074558537979067, disc_loss = 0.11563584110213936
Trained batch 326 in epoch 7, gen_loss = 0.40744430747236315, disc_loss = 0.11562695019288895
Trained batch 327 in epoch 7, gen_loss = 0.4075610920241693, disc_loss = 0.11582945464406072
Trained batch 328 in epoch 7, gen_loss = 0.4078055650992234, disc_loss = 0.11605228008107936
Trained batch 329 in epoch 7, gen_loss = 0.4080255069515922, disc_loss = 0.11611352409377243
Trained batch 330 in epoch 7, gen_loss = 0.40802368764790886, disc_loss = 0.1160911394570169
Trained batch 331 in epoch 7, gen_loss = 0.4080541815204793, disc_loss = 0.11594871629074395
Trained batch 332 in epoch 7, gen_loss = 0.40797180966572005, disc_loss = 0.11585312218100459
Trained batch 333 in epoch 7, gen_loss = 0.40814118515588566, disc_loss = 0.11572615791134491
Trained batch 334 in epoch 7, gen_loss = 0.40805670636803354, disc_loss = 0.11575545688618474
Trained batch 335 in epoch 7, gen_loss = 0.4080304296775943, disc_loss = 0.11586233966850809
Trained batch 336 in epoch 7, gen_loss = 0.40828035174915983, disc_loss = 0.11582237311835106
Trained batch 337 in epoch 7, gen_loss = 0.40816230040330154, disc_loss = 0.11589527608463045
Trained batch 338 in epoch 7, gen_loss = 0.4080351730011909, disc_loss = 0.11569503635431813
Trained batch 339 in epoch 7, gen_loss = 0.40802646726369857, disc_loss = 0.11588137373328208
Trained batch 340 in epoch 7, gen_loss = 0.4079789007164516, disc_loss = 0.11576429658359097
Trained batch 341 in epoch 7, gen_loss = 0.4080070956060064, disc_loss = 0.11557138384434215
Trained batch 342 in epoch 7, gen_loss = 0.4079626720431247, disc_loss = 0.11548563981369007
Trained batch 343 in epoch 7, gen_loss = 0.40794715891743816, disc_loss = 0.11557455781067527
Trained batch 344 in epoch 7, gen_loss = 0.4080639286317687, disc_loss = 0.11532101742383363
Trained batch 345 in epoch 7, gen_loss = 0.40797534576385697, disc_loss = 0.11524280420143825
Trained batch 346 in epoch 7, gen_loss = 0.40810387785565266, disc_loss = 0.11520161203803865
Trained batch 347 in epoch 7, gen_loss = 0.4081937900219841, disc_loss = 0.11509205868746016
Trained batch 348 in epoch 7, gen_loss = 0.4080008825121773, disc_loss = 0.11505372797734074
Trained batch 349 in epoch 7, gen_loss = 0.40799624562263487, disc_loss = 0.11476832509040832
Trained batch 350 in epoch 7, gen_loss = 0.4080605513689525, disc_loss = 0.11504717812239275
Trained batch 351 in epoch 7, gen_loss = 0.4085697526620193, disc_loss = 0.11588336518880996
Trained batch 352 in epoch 7, gen_loss = 0.4085530256245697, disc_loss = 0.11582708175138441
Trained batch 353 in epoch 7, gen_loss = 0.4085804059007074, disc_loss = 0.11594159625428545
Trained batch 354 in epoch 7, gen_loss = 0.40868609782675624, disc_loss = 0.11580279060232808
Trained batch 355 in epoch 7, gen_loss = 0.4087341164939859, disc_loss = 0.11603570672986882
Trained batch 356 in epoch 7, gen_loss = 0.4087080523914316, disc_loss = 0.11600687822290495
Trained batch 357 in epoch 7, gen_loss = 0.40860717914290934, disc_loss = 0.11635097501247955
Trained batch 358 in epoch 7, gen_loss = 0.40874081111219934, disc_loss = 0.11654372278777338
Trained batch 359 in epoch 7, gen_loss = 0.4089403975341055, disc_loss = 0.11641119472268555
Trained batch 360 in epoch 7, gen_loss = 0.4088384963964161, disc_loss = 0.11652620873540392
Trained batch 361 in epoch 7, gen_loss = 0.4089111163800593, disc_loss = 0.1163756595461408
Trained batch 362 in epoch 7, gen_loss = 0.40907207320215944, disc_loss = 0.11621955518428616
Trained batch 363 in epoch 7, gen_loss = 0.4089637861310781, disc_loss = 0.11616670930819524
Trained batch 364 in epoch 7, gen_loss = 0.40912453319928416, disc_loss = 0.11620808759168402
Trained batch 365 in epoch 7, gen_loss = 0.4090924206001511, disc_loss = 0.11613909011615105
Trained batch 366 in epoch 7, gen_loss = 0.4091288876143723, disc_loss = 0.11618994609820746
Trained batch 367 in epoch 7, gen_loss = 0.40924880653619766, disc_loss = 0.11607625512608691
Trained batch 368 in epoch 7, gen_loss = 0.40918694400205846, disc_loss = 0.11603371866632929
Trained batch 369 in epoch 7, gen_loss = 0.4091757022045754, disc_loss = 0.11588968998072921
Trained batch 370 in epoch 7, gen_loss = 0.40912367214732415, disc_loss = 0.11626817925639872
Trained batch 371 in epoch 7, gen_loss = 0.40890732159217197, disc_loss = 0.11644083506838289
Trained batch 372 in epoch 7, gen_loss = 0.4091234447649273, disc_loss = 0.11637908141390887
Trained batch 373 in epoch 7, gen_loss = 0.4091988831439758, disc_loss = 0.11635689251124859
Trained batch 374 in epoch 7, gen_loss = 0.4093170104821523, disc_loss = 0.11633198192715645
Trained batch 375 in epoch 7, gen_loss = 0.4094927357707886, disc_loss = 0.11628810590767164
Trained batch 376 in epoch 7, gen_loss = 0.4096143385617739, disc_loss = 0.1163172228286532
Trained batch 377 in epoch 7, gen_loss = 0.4094838981748258, disc_loss = 0.1161246663501496
Trained batch 378 in epoch 7, gen_loss = 0.40937969206505526, disc_loss = 0.11600513417165638
Trained batch 379 in epoch 7, gen_loss = 0.40950014889240266, disc_loss = 0.11593807240653979
Trained batch 380 in epoch 7, gen_loss = 0.4096259779817476, disc_loss = 0.11586539530417737
Trained batch 381 in epoch 7, gen_loss = 0.4096429044507561, disc_loss = 0.11568428588670274
Trained batch 382 in epoch 7, gen_loss = 0.4093684891807815, disc_loss = 0.11582390801596891
Trained batch 383 in epoch 7, gen_loss = 0.40944525925442576, disc_loss = 0.11610314666177146
Trained batch 384 in epoch 7, gen_loss = 0.4094239008891118, disc_loss = 0.1162081831171141
Trained batch 385 in epoch 7, gen_loss = 0.4094185217674532, disc_loss = 0.11635883782695922
Trained batch 386 in epoch 7, gen_loss = 0.4094159037105797, disc_loss = 0.11634541149864826
Trained batch 387 in epoch 7, gen_loss = 0.4093976818870023, disc_loss = 0.11629877952839603
Trained batch 388 in epoch 7, gen_loss = 0.40934540764225175, disc_loss = 0.11623697615872619
Trained batch 389 in epoch 7, gen_loss = 0.40952719503488294, disc_loss = 0.11612739071058921
Trained batch 390 in epoch 7, gen_loss = 0.40932566872643084, disc_loss = 0.11603791774500666
Trained batch 391 in epoch 7, gen_loss = 0.4093989602917311, disc_loss = 0.11615278346616091
Trained batch 392 in epoch 7, gen_loss = 0.4091760784615087, disc_loss = 0.11612239922693061
Trained batch 393 in epoch 7, gen_loss = 0.40896956289782743, disc_loss = 0.11618189062677362
Trained batch 394 in epoch 7, gen_loss = 0.4091692605350591, disc_loss = 0.1161078169847591
Trained batch 395 in epoch 7, gen_loss = 0.409176542752921, disc_loss = 0.1160206924653565
Trained batch 396 in epoch 7, gen_loss = 0.4090824693966873, disc_loss = 0.11586455675193885
Trained batch 397 in epoch 7, gen_loss = 0.40919983035056434, disc_loss = 0.11583678331694111
Trained batch 398 in epoch 7, gen_loss = 0.40910870665894417, disc_loss = 0.1157574735880645
Trained batch 399 in epoch 7, gen_loss = 0.40910020120441914, disc_loss = 0.1156084562651813
Trained batch 400 in epoch 7, gen_loss = 0.4089082631089741, disc_loss = 0.11558618896322655
Trained batch 401 in epoch 7, gen_loss = 0.4087449341864135, disc_loss = 0.11556650116224194
Trained batch 402 in epoch 7, gen_loss = 0.4085909159988091, disc_loss = 0.11585972988723821
Trained batch 403 in epoch 7, gen_loss = 0.40846918324137677, disc_loss = 0.11584742855981435
Trained batch 404 in epoch 7, gen_loss = 0.4085462154429636, disc_loss = 0.1157336453044856
Trained batch 405 in epoch 7, gen_loss = 0.40869874474156664, disc_loss = 0.11595556978595081
Trained batch 406 in epoch 7, gen_loss = 0.40865649484299327, disc_loss = 0.11602050159355347
Trained batch 407 in epoch 7, gen_loss = 0.40860308955113095, disc_loss = 0.11584053783878392
Trained batch 408 in epoch 7, gen_loss = 0.40858888363779905, disc_loss = 0.11585453105293451
Trained batch 409 in epoch 7, gen_loss = 0.4088249351920151, disc_loss = 0.11570218685196668
Trained batch 410 in epoch 7, gen_loss = 0.40905239967824186, disc_loss = 0.11560488349039769
Trained batch 411 in epoch 7, gen_loss = 0.4090460984452257, disc_loss = 0.11574031376433604
Trained batch 412 in epoch 7, gen_loss = 0.40905100265946287, disc_loss = 0.11557334822943077
Trained batch 413 in epoch 7, gen_loss = 0.4090230319523005, disc_loss = 0.11563567283612806
Trained batch 414 in epoch 7, gen_loss = 0.40896508873227133, disc_loss = 0.11541157936654896
Trained batch 415 in epoch 7, gen_loss = 0.4088307718674724, disc_loss = 0.11532525670750496
Trained batch 416 in epoch 7, gen_loss = 0.40879771599380804, disc_loss = 0.11526062120672324
Trained batch 417 in epoch 7, gen_loss = 0.4088332454838821, disc_loss = 0.11519673841885117
Trained batch 418 in epoch 7, gen_loss = 0.4088076803308683, disc_loss = 0.11510860024637994
Trained batch 419 in epoch 7, gen_loss = 0.4088319698969523, disc_loss = 0.1149867406824515
Trained batch 420 in epoch 7, gen_loss = 0.40889489615331637, disc_loss = 0.11487421923429836
Trained batch 421 in epoch 7, gen_loss = 0.40885804777179285, disc_loss = 0.1147478816421676
Trained batch 422 in epoch 7, gen_loss = 0.4087748168208075, disc_loss = 0.11473546055614525
Trained batch 423 in epoch 7, gen_loss = 0.40878233334647035, disc_loss = 0.11479690646366128
Trained batch 424 in epoch 7, gen_loss = 0.4089240525049322, disc_loss = 0.11463976726812475
Trained batch 425 in epoch 7, gen_loss = 0.40888097854287414, disc_loss = 0.11454145930392641
Trained batch 426 in epoch 7, gen_loss = 0.4090186399374969, disc_loss = 0.11453443118294732
Trained batch 427 in epoch 7, gen_loss = 0.4089573901668887, disc_loss = 0.1144594555877358
Trained batch 428 in epoch 7, gen_loss = 0.40912352894847487, disc_loss = 0.11431282590249757
Trained batch 429 in epoch 7, gen_loss = 0.4089858131353245, disc_loss = 0.11464931914626166
Trained batch 430 in epoch 7, gen_loss = 0.4092165484782438, disc_loss = 0.11509288676307815
Trained batch 431 in epoch 7, gen_loss = 0.40908683912345656, disc_loss = 0.11498213336906499
Trained batch 432 in epoch 7, gen_loss = 0.4089238971265304, disc_loss = 0.11516510072329854
Trained batch 433 in epoch 7, gen_loss = 0.40925743448020124, disc_loss = 0.1156457730736326
Trained batch 434 in epoch 7, gen_loss = 0.4091001160528468, disc_loss = 0.11572418940820914
Trained batch 435 in epoch 7, gen_loss = 0.409076823212138, disc_loss = 0.11637160593831758
Trained batch 436 in epoch 7, gen_loss = 0.40932871595672937, disc_loss = 0.11705340484255239
Trained batch 437 in epoch 7, gen_loss = 0.40944481066100674, disc_loss = 0.11782329895248696
Trained batch 438 in epoch 7, gen_loss = 0.4094075747258571, disc_loss = 0.11826952594355733
Trained batch 439 in epoch 7, gen_loss = 0.40948365052992647, disc_loss = 0.11847937115552751
Trained batch 440 in epoch 7, gen_loss = 0.4093733704955129, disc_loss = 0.11891762153699555
Trained batch 441 in epoch 7, gen_loss = 0.4093503269000291, disc_loss = 0.11925842995624736
Trained batch 442 in epoch 7, gen_loss = 0.4094192772498249, disc_loss = 0.11967462114569295
Trained batch 443 in epoch 7, gen_loss = 0.40944226294218955, disc_loss = 0.11983425661854379
Trained batch 444 in epoch 7, gen_loss = 0.40926965361230827, disc_loss = 0.12010263601380787
Trained batch 445 in epoch 7, gen_loss = 0.4092093929982506, disc_loss = 0.12031749226654057
Trained batch 446 in epoch 7, gen_loss = 0.4091470750919658, disc_loss = 0.12046655287478594
Trained batch 447 in epoch 7, gen_loss = 0.40913380875385236, disc_loss = 0.12042015195558113
Trained batch 448 in epoch 7, gen_loss = 0.40918669622300197, disc_loss = 0.1203721956347835
Trained batch 449 in epoch 7, gen_loss = 0.4090626355012258, disc_loss = 0.12057859660850631
Trained batch 450 in epoch 7, gen_loss = 0.40886346807501006, disc_loss = 0.12091764716840372
Trained batch 451 in epoch 7, gen_loss = 0.40892401667295303, disc_loss = 0.12104416607293934
Trained batch 452 in epoch 7, gen_loss = 0.40876169887599567, disc_loss = 0.12113228409035053
Trained batch 453 in epoch 7, gen_loss = 0.40866261162684353, disc_loss = 0.12120444995519349
Trained batch 454 in epoch 7, gen_loss = 0.4088557479145763, disc_loss = 0.12104855248561272
Trained batch 455 in epoch 7, gen_loss = 0.4087956604596816, disc_loss = 0.12114856535928291
Trained batch 456 in epoch 7, gen_loss = 0.4087570844385243, disc_loss = 0.12114098772439184
Trained batch 457 in epoch 7, gen_loss = 0.4088407188133381, disc_loss = 0.12134801228754385
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.3834688365459442, disc_loss = 0.10325784236192703
Trained batch 1 in epoch 8, gen_loss = 0.4205281734466553, disc_loss = 0.08565586060285568
Trained batch 2 in epoch 8, gen_loss = 0.4378091295560201, disc_loss = 0.08727527409791946
Trained batch 3 in epoch 8, gen_loss = 0.41334863007068634, disc_loss = 0.11113386042416096
Trained batch 4 in epoch 8, gen_loss = 0.3881997108459473, disc_loss = 0.13545898646116256
Trained batch 5 in epoch 8, gen_loss = 0.3862497905890147, disc_loss = 0.13247229531407356
Trained batch 6 in epoch 8, gen_loss = 0.3851990188871111, disc_loss = 0.13160432981593267
Trained batch 7 in epoch 8, gen_loss = 0.38537877798080444, disc_loss = 0.13620775286108255
Trained batch 8 in epoch 8, gen_loss = 0.3802797496318817, disc_loss = 0.13838398539357716
Trained batch 9 in epoch 8, gen_loss = 0.36856925785541533, disc_loss = 0.1384090505540371
Trained batch 10 in epoch 8, gen_loss = 0.36581585894931445, disc_loss = 0.13307024470784448
Trained batch 11 in epoch 8, gen_loss = 0.3639676372210185, disc_loss = 0.13432777983446917
Trained batch 12 in epoch 8, gen_loss = 0.36365559009405285, disc_loss = 0.13344783393236306
Trained batch 13 in epoch 8, gen_loss = 0.37095193352018085, disc_loss = 0.13170208569083894
Trained batch 14 in epoch 8, gen_loss = 0.3693889280160268, disc_loss = 0.1317286362250646
Trained batch 15 in epoch 8, gen_loss = 0.3752435930073261, disc_loss = 0.12726669805124402
Trained batch 16 in epoch 8, gen_loss = 0.3756178950562197, disc_loss = 0.12682904785170274
Trained batch 17 in epoch 8, gen_loss = 0.3744014451901118, disc_loss = 0.12639112066891459
Trained batch 18 in epoch 8, gen_loss = 0.3772835041347303, disc_loss = 0.12729387965641523
Trained batch 19 in epoch 8, gen_loss = 0.3817319869995117, disc_loss = 0.12712619155645372
Trained batch 20 in epoch 8, gen_loss = 0.38575758110909236, disc_loss = 0.12667607551529295
Trained batch 21 in epoch 8, gen_loss = 0.3814577934416858, disc_loss = 0.12550155208869415
Trained batch 22 in epoch 8, gen_loss = 0.3818782282912213, disc_loss = 0.12503724026939142
Trained batch 23 in epoch 8, gen_loss = 0.38253254691759747, disc_loss = 0.12482356528441112
Trained batch 24 in epoch 8, gen_loss = 0.38619049072265627, disc_loss = 0.12619832038879394
Trained batch 25 in epoch 8, gen_loss = 0.3866258573073607, disc_loss = 0.12519283191515848
Trained batch 26 in epoch 8, gen_loss = 0.38907307938293173, disc_loss = 0.12362553675969441
Trained batch 27 in epoch 8, gen_loss = 0.3878159373998642, disc_loss = 0.12332684200789247
Trained batch 28 in epoch 8, gen_loss = 0.39041051987943975, disc_loss = 0.12134922321500449
Trained batch 29 in epoch 8, gen_loss = 0.38846538265546166, disc_loss = 0.1209606039027373
Trained batch 30 in epoch 8, gen_loss = 0.38788762592500253, disc_loss = 0.12241806402321785
Trained batch 31 in epoch 8, gen_loss = 0.389434901997447, disc_loss = 0.12377390149049461
Trained batch 32 in epoch 8, gen_loss = 0.3888667289054755, disc_loss = 0.12463925575668161
Trained batch 33 in epoch 8, gen_loss = 0.38855545485720916, disc_loss = 0.1239333310547997
Trained batch 34 in epoch 8, gen_loss = 0.3889239694390978, disc_loss = 0.12238102427550725
Trained batch 35 in epoch 8, gen_loss = 0.3880545157525275, disc_loss = 0.12177575793531206
Trained batch 36 in epoch 8, gen_loss = 0.3896267454366426, disc_loss = 0.1205978862739898
Trained batch 37 in epoch 8, gen_loss = 0.39111637677017014, disc_loss = 0.12033730764922343
Trained batch 38 in epoch 8, gen_loss = 0.3906500576398311, disc_loss = 0.12245383915992883
Trained batch 39 in epoch 8, gen_loss = 0.38917350545525553, disc_loss = 0.12422489654272795
Trained batch 40 in epoch 8, gen_loss = 0.3869190085224989, disc_loss = 0.12533573897146597
Trained batch 41 in epoch 8, gen_loss = 0.38775453964869183, disc_loss = 0.1251105900321688
Trained batch 42 in epoch 8, gen_loss = 0.3881601767484532, disc_loss = 0.12797039920507475
Trained batch 43 in epoch 8, gen_loss = 0.3867629265243357, disc_loss = 0.1296155212277716
Trained batch 44 in epoch 8, gen_loss = 0.3847316225369771, disc_loss = 0.12919314271873897
Trained batch 45 in epoch 8, gen_loss = 0.38499623601851257, disc_loss = 0.12929288557042246
Trained batch 46 in epoch 8, gen_loss = 0.38572671882649684, disc_loss = 0.12875948354918906
Trained batch 47 in epoch 8, gen_loss = 0.3861241756627957, disc_loss = 0.1283325202142199
Trained batch 48 in epoch 8, gen_loss = 0.3863199736390795, disc_loss = 0.12702636983321638
Trained batch 49 in epoch 8, gen_loss = 0.38546003758907316, disc_loss = 0.12623769864439965
Trained batch 50 in epoch 8, gen_loss = 0.3852471159953697, disc_loss = 0.12544932245623833
Trained batch 51 in epoch 8, gen_loss = 0.3858962059020996, disc_loss = 0.12479493466134255
Trained batch 52 in epoch 8, gen_loss = 0.3848864666695865, disc_loss = 0.1247409885784365
Trained batch 53 in epoch 8, gen_loss = 0.3861075981899544, disc_loss = 0.1244178034917072
Trained batch 54 in epoch 8, gen_loss = 0.3848172198642384, disc_loss = 0.12431302043524656
Trained batch 55 in epoch 8, gen_loss = 0.3833005992429597, disc_loss = 0.12566693100546086
Trained batch 56 in epoch 8, gen_loss = 0.38349637075474385, disc_loss = 0.1242342268427213
Trained batch 57 in epoch 8, gen_loss = 0.38483320587667924, disc_loss = 0.12578584986000224
Trained batch 58 in epoch 8, gen_loss = 0.3843581363306207, disc_loss = 0.12605415979179285
Trained batch 59 in epoch 8, gen_loss = 0.38405685871839523, disc_loss = 0.124774338491261
Trained batch 60 in epoch 8, gen_loss = 0.3848841395534453, disc_loss = 0.1246368593734796
Trained batch 61 in epoch 8, gen_loss = 0.3850678883252605, disc_loss = 0.1242287679905853
Trained batch 62 in epoch 8, gen_loss = 0.38573424116013544, disc_loss = 0.1255816589627001
Trained batch 63 in epoch 8, gen_loss = 0.38556555286049843, disc_loss = 0.12439534463919699
Trained batch 64 in epoch 8, gen_loss = 0.38609303602805506, disc_loss = 0.12498692480417398
Trained batch 65 in epoch 8, gen_loss = 0.38740023338433466, disc_loss = 0.12461182757308989
Trained batch 66 in epoch 8, gen_loss = 0.38731674916708647, disc_loss = 0.12411163791791717
Trained batch 67 in epoch 8, gen_loss = 0.38751281929366727, disc_loss = 0.12346767612239894
Trained batch 68 in epoch 8, gen_loss = 0.38744705699492193, disc_loss = 0.12278129527534264
Trained batch 69 in epoch 8, gen_loss = 0.38806721014635903, disc_loss = 0.12198691985436848
Trained batch 70 in epoch 8, gen_loss = 0.38914061977829734, disc_loss = 0.12089018345298902
Trained batch 71 in epoch 8, gen_loss = 0.3889946709904406, disc_loss = 0.12002317969583803
Trained batch 72 in epoch 8, gen_loss = 0.3894580129074724, disc_loss = 0.11967172279749831
Trained batch 73 in epoch 8, gen_loss = 0.3892827601851644, disc_loss = 0.11953624055997746
Trained batch 74 in epoch 8, gen_loss = 0.3887069137891134, disc_loss = 0.11977270980676015
Trained batch 75 in epoch 8, gen_loss = 0.3889667889789531, disc_loss = 0.11925269810384825
Trained batch 76 in epoch 8, gen_loss = 0.390322700336382, disc_loss = 0.11834941209330187
Trained batch 77 in epoch 8, gen_loss = 0.3906210286495013, disc_loss = 0.11811797488003205
Trained batch 78 in epoch 8, gen_loss = 0.3907305156882805, disc_loss = 0.11807230883572675
Trained batch 79 in epoch 8, gen_loss = 0.3913175817579031, disc_loss = 0.11732562719844282
Trained batch 80 in epoch 8, gen_loss = 0.3907637658678455, disc_loss = 0.1165093581341667
Trained batch 81 in epoch 8, gen_loss = 0.3905805469286151, disc_loss = 0.11583725172208577
Trained batch 82 in epoch 8, gen_loss = 0.39228624572236853, disc_loss = 0.11623152094074042
Trained batch 83 in epoch 8, gen_loss = 0.39223395607301165, disc_loss = 0.11606923677027225
Trained batch 84 in epoch 8, gen_loss = 0.39239538627512316, disc_loss = 0.11551910594982259
Trained batch 85 in epoch 8, gen_loss = 0.3927988066922787, disc_loss = 0.11506138646671939
Trained batch 86 in epoch 8, gen_loss = 0.3932328936697423, disc_loss = 0.11443963805320619
Trained batch 87 in epoch 8, gen_loss = 0.3934766206551682, disc_loss = 0.1143524890172888
Trained batch 88 in epoch 8, gen_loss = 0.39425136433558516, disc_loss = 0.11432872097311395
Trained batch 89 in epoch 8, gen_loss = 0.3943079342444738, disc_loss = 0.1138932079490688
Trained batch 90 in epoch 8, gen_loss = 0.39519064799769893, disc_loss = 0.11336119575323639
Trained batch 91 in epoch 8, gen_loss = 0.3958309098430302, disc_loss = 0.11238537129500638
Trained batch 92 in epoch 8, gen_loss = 0.39664746196039263, disc_loss = 0.11220089874921306
Trained batch 93 in epoch 8, gen_loss = 0.3952509754515709, disc_loss = 0.11234696201504545
Trained batch 94 in epoch 8, gen_loss = 0.39470241258018895, disc_loss = 0.11342226698210364
Trained batch 95 in epoch 8, gen_loss = 0.39545420308907825, disc_loss = 0.11309175309725106
Trained batch 96 in epoch 8, gen_loss = 0.39520611437325626, disc_loss = 0.11269926410360434
Trained batch 97 in epoch 8, gen_loss = 0.39513978757420365, disc_loss = 0.11239461418317288
Trained batch 98 in epoch 8, gen_loss = 0.39533148751114355, disc_loss = 0.11226254987596261
Trained batch 99 in epoch 8, gen_loss = 0.396640767455101, disc_loss = 0.11191789984703064
Trained batch 100 in epoch 8, gen_loss = 0.3968914965591808, disc_loss = 0.11141388926028024
Trained batch 101 in epoch 8, gen_loss = 0.39706208425409656, disc_loss = 0.11224365888126925
Trained batch 102 in epoch 8, gen_loss = 0.3976809952444243, disc_loss = 0.11239045290547667
Trained batch 103 in epoch 8, gen_loss = 0.39746651970423186, disc_loss = 0.11273704508606058
Trained batch 104 in epoch 8, gen_loss = 0.3982061017127264, disc_loss = 0.11304126506050428
Trained batch 105 in epoch 8, gen_loss = 0.39850763639189163, disc_loss = 0.11305103320979847
Trained batch 106 in epoch 8, gen_loss = 0.39789724377828223, disc_loss = 0.11364880562803456
Trained batch 107 in epoch 8, gen_loss = 0.39734661606726823, disc_loss = 0.11464108274904666
Trained batch 108 in epoch 8, gen_loss = 0.3974515046548406, disc_loss = 0.11421885467860676
Trained batch 109 in epoch 8, gen_loss = 0.3969624297185378, disc_loss = 0.11386478038674051
Trained batch 110 in epoch 8, gen_loss = 0.3969866719331827, disc_loss = 0.11433721525040833
Trained batch 111 in epoch 8, gen_loss = 0.3964148334094456, disc_loss = 0.11456707728627537
Trained batch 112 in epoch 8, gen_loss = 0.39673009593929864, disc_loss = 0.11448190193128797
Trained batch 113 in epoch 8, gen_loss = 0.3971570986404754, disc_loss = 0.11445497868484572
Trained batch 114 in epoch 8, gen_loss = 0.39664375833843063, disc_loss = 0.11440140660042349
Trained batch 115 in epoch 8, gen_loss = 0.39697393723602953, disc_loss = 0.11391698071283513
Trained batch 116 in epoch 8, gen_loss = 0.39716117300538933, disc_loss = 0.11362686094183189
Trained batch 117 in epoch 8, gen_loss = 0.39691434093451095, disc_loss = 0.11333828492058536
Trained batch 118 in epoch 8, gen_loss = 0.39673363085554425, disc_loss = 0.11321845290665868
Trained batch 119 in epoch 8, gen_loss = 0.3968542064229647, disc_loss = 0.11313890401894848
Trained batch 120 in epoch 8, gen_loss = 0.39651926686941097, disc_loss = 0.11345468322969665
Trained batch 121 in epoch 8, gen_loss = 0.39710291194134073, disc_loss = 0.11301885102493842
Trained batch 122 in epoch 8, gen_loss = 0.39763950162786776, disc_loss = 0.11343336332498527
Trained batch 123 in epoch 8, gen_loss = 0.39786920504223916, disc_loss = 0.11269873580444724
Trained batch 124 in epoch 8, gen_loss = 0.3974675431251526, disc_loss = 0.1130729491263628
Trained batch 125 in epoch 8, gen_loss = 0.398326731863476, disc_loss = 0.11239528854096693
Trained batch 126 in epoch 8, gen_loss = 0.3983781891544973, disc_loss = 0.11311820029156415
Trained batch 127 in epoch 8, gen_loss = 0.39818412717431784, disc_loss = 0.11364045829395764
Trained batch 128 in epoch 8, gen_loss = 0.3988713026046753, disc_loss = 0.113531710536674
Trained batch 129 in epoch 8, gen_loss = 0.40040919689031745, disc_loss = 0.11565381950483872
Trained batch 130 in epoch 8, gen_loss = 0.4009687839118579, disc_loss = 0.11647904621622035
Trained batch 131 in epoch 8, gen_loss = 0.4011252226703095, disc_loss = 0.1161511235334205
Trained batch 132 in epoch 8, gen_loss = 0.40125542856696855, disc_loss = 0.11599827022816901
Trained batch 133 in epoch 8, gen_loss = 0.4010273491713538, disc_loss = 0.11640393898002248
Trained batch 134 in epoch 8, gen_loss = 0.401312165790134, disc_loss = 0.11729783666906533
Trained batch 135 in epoch 8, gen_loss = 0.4017765653484008, disc_loss = 0.11776931635925875
Trained batch 136 in epoch 8, gen_loss = 0.40147374015654963, disc_loss = 0.11765650727779325
Trained batch 137 in epoch 8, gen_loss = 0.40114924786747364, disc_loss = 0.11756678457385387
Trained batch 138 in epoch 8, gen_loss = 0.4012037196176515, disc_loss = 0.11758700905622338
Trained batch 139 in epoch 8, gen_loss = 0.40132958931582313, disc_loss = 0.11709974804627044
Trained batch 140 in epoch 8, gen_loss = 0.40133555983820707, disc_loss = 0.11689094937545189
Trained batch 141 in epoch 8, gen_loss = 0.40111838973743813, disc_loss = 0.11667532261303613
Trained batch 142 in epoch 8, gen_loss = 0.4008118739494911, disc_loss = 0.11671130351357527
Trained batch 143 in epoch 8, gen_loss = 0.4009448362307416, disc_loss = 0.11633766615866786
Trained batch 144 in epoch 8, gen_loss = 0.40083672692035804, disc_loss = 0.11615539755800675
Trained batch 145 in epoch 8, gen_loss = 0.40077757488374843, disc_loss = 0.11596234563789139
Trained batch 146 in epoch 8, gen_loss = 0.40122167086925636, disc_loss = 0.11571675480729869
Trained batch 147 in epoch 8, gen_loss = 0.40078714993354436, disc_loss = 0.11559991913570745
Trained batch 148 in epoch 8, gen_loss = 0.4005383017079142, disc_loss = 0.11605037101263167
Trained batch 149 in epoch 8, gen_loss = 0.4007551352183024, disc_loss = 0.11598317337532839
Trained batch 150 in epoch 8, gen_loss = 0.4002530302432989, disc_loss = 0.11626694102259662
Trained batch 151 in epoch 8, gen_loss = 0.4002991228511459, disc_loss = 0.11708578871759145
Trained batch 152 in epoch 8, gen_loss = 0.39994778002009673, disc_loss = 0.11760550194413834
Trained batch 153 in epoch 8, gen_loss = 0.4000917216400047, disc_loss = 0.11774329301695545
Trained batch 154 in epoch 8, gen_loss = 0.39984405925196986, disc_loss = 0.1180955077611631
Trained batch 155 in epoch 8, gen_loss = 0.4003076159801239, disc_loss = 0.11921680835672678
Trained batch 156 in epoch 8, gen_loss = 0.40049922181542513, disc_loss = 0.11978187257791781
Trained batch 157 in epoch 8, gen_loss = 0.4009264162446879, disc_loss = 0.11991754138865802
Trained batch 158 in epoch 8, gen_loss = 0.401128629281086, disc_loss = 0.11965179694055011
Trained batch 159 in epoch 8, gen_loss = 0.40123795084655284, disc_loss = 0.11932742909993976
Trained batch 160 in epoch 8, gen_loss = 0.4006394560662856, disc_loss = 0.11973856498273264
Trained batch 161 in epoch 8, gen_loss = 0.40070825152926975, disc_loss = 0.11970725317520124
Trained batch 162 in epoch 8, gen_loss = 0.4007531002255305, disc_loss = 0.11993106077510886
Trained batch 163 in epoch 8, gen_loss = 0.40088219177432177, disc_loss = 0.11981907743597175
Trained batch 164 in epoch 8, gen_loss = 0.40100689313628457, disc_loss = 0.12083563463705958
Trained batch 165 in epoch 8, gen_loss = 0.40112576409276707, disc_loss = 0.12069159133516881
Trained batch 166 in epoch 8, gen_loss = 0.40118524271570993, disc_loss = 0.1203930374614136
Trained batch 167 in epoch 8, gen_loss = 0.40120662855250494, disc_loss = 0.1201794277654872
Trained batch 168 in epoch 8, gen_loss = 0.4013009284727672, disc_loss = 0.12018852074735263
Trained batch 169 in epoch 8, gen_loss = 0.40110616964452406, disc_loss = 0.12034339613335975
Trained batch 170 in epoch 8, gen_loss = 0.40105277561304864, disc_loss = 0.12020265304467134
Trained batch 171 in epoch 8, gen_loss = 0.4007363123602645, disc_loss = 0.12003638294287199
Trained batch 172 in epoch 8, gen_loss = 0.40080705715741727, disc_loss = 0.11984872075088451
Trained batch 173 in epoch 8, gen_loss = 0.4013354791992012, disc_loss = 0.11988005647971027
Trained batch 174 in epoch 8, gen_loss = 0.4012549235139574, disc_loss = 0.12003534459642001
Trained batch 175 in epoch 8, gen_loss = 0.40135842036794533, disc_loss = 0.12018889711577106
Trained batch 176 in epoch 8, gen_loss = 0.4011799347939464, disc_loss = 0.11979231082618573
Trained batch 177 in epoch 8, gen_loss = 0.40098397216100373, disc_loss = 0.11941636257459608
Trained batch 178 in epoch 8, gen_loss = 0.40089447321838506, disc_loss = 0.11955851004276861
Trained batch 179 in epoch 8, gen_loss = 0.4005354565050867, disc_loss = 0.11987463182045353
Trained batch 180 in epoch 8, gen_loss = 0.4007754972955799, disc_loss = 0.11951714313655927
Trained batch 181 in epoch 8, gen_loss = 0.40107234379092416, disc_loss = 0.11959283532840866
Trained batch 182 in epoch 8, gen_loss = 0.401181186483206, disc_loss = 0.11910388931184193
Trained batch 183 in epoch 8, gen_loss = 0.4010164906149325, disc_loss = 0.1190702851517531
Trained batch 184 in epoch 8, gen_loss = 0.40091126786695946, disc_loss = 0.11893933877550267
Trained batch 185 in epoch 8, gen_loss = 0.4014114264839439, disc_loss = 0.11848989805026401
Trained batch 186 in epoch 8, gen_loss = 0.4016675869411326, disc_loss = 0.1179977851536344
Trained batch 187 in epoch 8, gen_loss = 0.40181077303404505, disc_loss = 0.11764786278511932
Trained batch 188 in epoch 8, gen_loss = 0.40225723701179344, disc_loss = 0.11732407916514646
Trained batch 189 in epoch 8, gen_loss = 0.4021325313731244, disc_loss = 0.11721758012120662
Trained batch 190 in epoch 8, gen_loss = 0.4022584543490285, disc_loss = 0.11752049267018964
Trained batch 191 in epoch 8, gen_loss = 0.4020610630201797, disc_loss = 0.11740864325353566
Trained batch 192 in epoch 8, gen_loss = 0.40170045158406, disc_loss = 0.1180912934996458
Trained batch 193 in epoch 8, gen_loss = 0.40253354347858233, disc_loss = 0.11988217830081883
Trained batch 194 in epoch 8, gen_loss = 0.40271505851012007, disc_loss = 0.11955504823380556
Trained batch 195 in epoch 8, gen_loss = 0.4022709128199791, disc_loss = 0.11928887305097008
Trained batch 196 in epoch 8, gen_loss = 0.40231485475743484, disc_loss = 0.1195137663106174
Trained batch 197 in epoch 8, gen_loss = 0.4027256426787136, disc_loss = 0.11918484123254364
Trained batch 198 in epoch 8, gen_loss = 0.40283111546506833, disc_loss = 0.11905307529597127
Trained batch 199 in epoch 8, gen_loss = 0.4030111636221409, disc_loss = 0.11914085009135306
Trained batch 200 in epoch 8, gen_loss = 0.40252905950617435, disc_loss = 0.11903063901954919
Trained batch 201 in epoch 8, gen_loss = 0.4026148090563198, disc_loss = 0.11866124200238155
Trained batch 202 in epoch 8, gen_loss = 0.40281213474978367, disc_loss = 0.11831477043113392
Trained batch 203 in epoch 8, gen_loss = 0.40235577918150844, disc_loss = 0.11820054592053388
Trained batch 204 in epoch 8, gen_loss = 0.40275487042054897, disc_loss = 0.11786258123451616
Trained batch 205 in epoch 8, gen_loss = 0.4025941776129806, disc_loss = 0.11756974513850456
Trained batch 206 in epoch 8, gen_loss = 0.4024442274501358, disc_loss = 0.11766719253922718
Trained batch 207 in epoch 8, gen_loss = 0.4025428777990433, disc_loss = 0.11829797297608681
Trained batch 208 in epoch 8, gen_loss = 0.4023636282916274, disc_loss = 0.1181907515937204
Trained batch 209 in epoch 8, gen_loss = 0.40242270245438533, disc_loss = 0.11809092047846033
Trained batch 210 in epoch 8, gen_loss = 0.4024835382875108, disc_loss = 0.11797776801502817
Trained batch 211 in epoch 8, gen_loss = 0.40232090286488803, disc_loss = 0.1183688262178791
Trained batch 212 in epoch 8, gen_loss = 0.4020964928635969, disc_loss = 0.11840609797744404
Trained batch 213 in epoch 8, gen_loss = 0.4019016553865415, disc_loss = 0.11820722058868018
Trained batch 214 in epoch 8, gen_loss = 0.40231649238009787, disc_loss = 0.11800199404878672
Trained batch 215 in epoch 8, gen_loss = 0.4026603442099359, disc_loss = 0.11767868486371029
Trained batch 216 in epoch 8, gen_loss = 0.40264193088777606, disc_loss = 0.11778203088120656
Trained batch 217 in epoch 8, gen_loss = 0.402625109897841, disc_loss = 0.11782590944935149
Trained batch 218 in epoch 8, gen_loss = 0.40275230200867673, disc_loss = 0.11755378101208167
Trained batch 219 in epoch 8, gen_loss = 0.40303981290622193, disc_loss = 0.11742618144066497
Trained batch 220 in epoch 8, gen_loss = 0.40278670609806455, disc_loss = 0.1171910031466867
Trained batch 221 in epoch 8, gen_loss = 0.40283476984178695, disc_loss = 0.11705017159483186
Trained batch 222 in epoch 8, gen_loss = 0.40259017043584133, disc_loss = 0.11719410985942111
Trained batch 223 in epoch 8, gen_loss = 0.40299546119890045, disc_loss = 0.11729142404926408
Trained batch 224 in epoch 8, gen_loss = 0.4031348737080892, disc_loss = 0.11729989014565945
Trained batch 225 in epoch 8, gen_loss = 0.4028446309070672, disc_loss = 0.11703488341969463
Trained batch 226 in epoch 8, gen_loss = 0.4028074080986073, disc_loss = 0.11678610308021964
Trained batch 227 in epoch 8, gen_loss = 0.4030334150843453, disc_loss = 0.11656135225080345
Trained batch 228 in epoch 8, gen_loss = 0.4033390696132027, disc_loss = 0.11656882105533473
Trained batch 229 in epoch 8, gen_loss = 0.40324826460817587, disc_loss = 0.1169654309992557
Trained batch 230 in epoch 8, gen_loss = 0.40303215165158884, disc_loss = 0.11691767179701494
Trained batch 231 in epoch 8, gen_loss = 0.40336753851894674, disc_loss = 0.11704172189989738
Trained batch 232 in epoch 8, gen_loss = 0.40320471031471383, disc_loss = 0.11671921825875796
Trained batch 233 in epoch 8, gen_loss = 0.4030525220765008, disc_loss = 0.11791426692412704
Trained batch 234 in epoch 8, gen_loss = 0.40319805462309655, disc_loss = 0.11841614269354242
Trained batch 235 in epoch 8, gen_loss = 0.4032644201385773, disc_loss = 0.11815232140312003
Trained batch 236 in epoch 8, gen_loss = 0.4032871183715289, disc_loss = 0.1181105189889921
Trained batch 237 in epoch 8, gen_loss = 0.40358807810214387, disc_loss = 0.1181478988801857
Trained batch 238 in epoch 8, gen_loss = 0.40349929390093275, disc_loss = 0.11853062571123804
Trained batch 239 in epoch 8, gen_loss = 0.4032311202337345, disc_loss = 0.11911121148150414
Trained batch 240 in epoch 8, gen_loss = 0.403307072107228, disc_loss = 0.1196380394947603
Trained batch 241 in epoch 8, gen_loss = 0.40314893744701197, disc_loss = 0.11980253261752612
Trained batch 242 in epoch 8, gen_loss = 0.40320326639301, disc_loss = 0.11959258734474702
Trained batch 243 in epoch 8, gen_loss = 0.40313826818935206, disc_loss = 0.11957308748492697
Trained batch 244 in epoch 8, gen_loss = 0.40306239553860257, disc_loss = 0.11954447551801496
Trained batch 245 in epoch 8, gen_loss = 0.4029561213361538, disc_loss = 0.11950897280793123
Trained batch 246 in epoch 8, gen_loss = 0.4031753695686819, disc_loss = 0.11925215108946026
Trained batch 247 in epoch 8, gen_loss = 0.40277366352177435, disc_loss = 0.11939096343403141
Trained batch 248 in epoch 8, gen_loss = 0.40246565466425027, disc_loss = 0.11966608986108897
Trained batch 249 in epoch 8, gen_loss = 0.4028040201663971, disc_loss = 0.11986443115025759
Trained batch 250 in epoch 8, gen_loss = 0.40307770390434566, disc_loss = 0.11959394129119309
Trained batch 251 in epoch 8, gen_loss = 0.40288898679945206, disc_loss = 0.119498373874064
Trained batch 252 in epoch 8, gen_loss = 0.4025048926884949, disc_loss = 0.11932056570212125
Trained batch 253 in epoch 8, gen_loss = 0.40243426727967, disc_loss = 0.11909614168254175
Trained batch 254 in epoch 8, gen_loss = 0.4026188862090017, disc_loss = 0.11926337783681411
Trained batch 255 in epoch 8, gen_loss = 0.4025457422249019, disc_loss = 0.11901508388837101
Trained batch 256 in epoch 8, gen_loss = 0.40276357218449216, disc_loss = 0.11924058396789583
Trained batch 257 in epoch 8, gen_loss = 0.40270387017449666, disc_loss = 0.11935621870378423
Trained batch 258 in epoch 8, gen_loss = 0.4026146228479142, disc_loss = 0.11923702504902962
Trained batch 259 in epoch 8, gen_loss = 0.4026013148518709, disc_loss = 0.11933463078995164
Trained batch 260 in epoch 8, gen_loss = 0.40261679282590346, disc_loss = 0.1193267580949598
Trained batch 261 in epoch 8, gen_loss = 0.4029742861522063, disc_loss = 0.11938612288902052
Trained batch 262 in epoch 8, gen_loss = 0.4030884209694518, disc_loss = 0.11953493539853015
Trained batch 263 in epoch 8, gen_loss = 0.40308645356333617, disc_loss = 0.11969172915754218
Trained batch 264 in epoch 8, gen_loss = 0.4032432408827656, disc_loss = 0.11945676748060956
Trained batch 265 in epoch 8, gen_loss = 0.4029944401262398, disc_loss = 0.11980621254113608
Trained batch 266 in epoch 8, gen_loss = 0.402719759539272, disc_loss = 0.11982916586435913
Trained batch 267 in epoch 8, gen_loss = 0.4028771020360847, disc_loss = 0.11979670445226244
Trained batch 268 in epoch 8, gen_loss = 0.4026549366548602, disc_loss = 0.1196054251289833
Trained batch 269 in epoch 8, gen_loss = 0.4026540560854806, disc_loss = 0.11937810566828207
Trained batch 270 in epoch 8, gen_loss = 0.40291342216224246, disc_loss = 0.11931592776574113
Trained batch 271 in epoch 8, gen_loss = 0.40287094705683346, disc_loss = 0.11943494803135228
Trained batch 272 in epoch 8, gen_loss = 0.40261868231899134, disc_loss = 0.11977744889155631
Trained batch 273 in epoch 8, gen_loss = 0.40260690874861976, disc_loss = 0.11953085599072875
Trained batch 274 in epoch 8, gen_loss = 0.40274082736535505, disc_loss = 0.11959610953249715
Trained batch 275 in epoch 8, gen_loss = 0.40301438701757486, disc_loss = 0.11954461397819113
Trained batch 276 in epoch 8, gen_loss = 0.40344115768959377, disc_loss = 0.1193976717318546
Trained batch 277 in epoch 8, gen_loss = 0.40324715755397467, disc_loss = 0.11967572299830562
Trained batch 278 in epoch 8, gen_loss = 0.403489155047256, disc_loss = 0.11950400013035985
Trained batch 279 in epoch 8, gen_loss = 0.40371632863368306, disc_loss = 0.11925880360150976
Trained batch 280 in epoch 8, gen_loss = 0.4035248856103293, disc_loss = 0.11923463286639745
Trained batch 281 in epoch 8, gen_loss = 0.4031704872423875, disc_loss = 0.11910008337243018
Trained batch 282 in epoch 8, gen_loss = 0.4032269629909798, disc_loss = 0.1189765095539628
Trained batch 283 in epoch 8, gen_loss = 0.4034089506931708, disc_loss = 0.11889734519907916
Trained batch 284 in epoch 8, gen_loss = 0.4035501550164139, disc_loss = 0.11875161146254916
Trained batch 285 in epoch 8, gen_loss = 0.4033528204772856, disc_loss = 0.11884635957153318
Trained batch 286 in epoch 8, gen_loss = 0.4029497895714298, disc_loss = 0.11907357023542144
Trained batch 287 in epoch 8, gen_loss = 0.40312289477636415, disc_loss = 0.118898871632862
Trained batch 288 in epoch 8, gen_loss = 0.40297032866923455, disc_loss = 0.11864160794674525
Trained batch 289 in epoch 8, gen_loss = 0.4031099816848492, disc_loss = 0.11841019284750881
Trained batch 290 in epoch 8, gen_loss = 0.4031928144779402, disc_loss = 0.1182814972519977
Trained batch 291 in epoch 8, gen_loss = 0.4032071387931092, disc_loss = 0.11832213297818009
Trained batch 292 in epoch 8, gen_loss = 0.40320660351893195, disc_loss = 0.11813290293229928
Trained batch 293 in epoch 8, gen_loss = 0.4031785646466171, disc_loss = 0.1180305545135927
Trained batch 294 in epoch 8, gen_loss = 0.4033697235382209, disc_loss = 0.11793496455302684
Trained batch 295 in epoch 8, gen_loss = 0.4033552106167819, disc_loss = 0.1179294814544453
Trained batch 296 in epoch 8, gen_loss = 0.40345453894900957, disc_loss = 0.11790470004407846
Trained batch 297 in epoch 8, gen_loss = 0.40320893162048904, disc_loss = 0.11794119606407097
Trained batch 298 in epoch 8, gen_loss = 0.4028774665350898, disc_loss = 0.11819577040804868
Trained batch 299 in epoch 8, gen_loss = 0.40314011404911676, disc_loss = 0.11831284938380122
Trained batch 300 in epoch 8, gen_loss = 0.402860491774803, disc_loss = 0.1181015521968619
Trained batch 301 in epoch 8, gen_loss = 0.40295671410118505, disc_loss = 0.11814502781466735
Trained batch 302 in epoch 8, gen_loss = 0.40278825773657745, disc_loss = 0.1183765137832452
Trained batch 303 in epoch 8, gen_loss = 0.40299821076424497, disc_loss = 0.11823947170724798
Trained batch 304 in epoch 8, gen_loss = 0.4030928430987186, disc_loss = 0.11813094842507214
Trained batch 305 in epoch 8, gen_loss = 0.4032471832496668, disc_loss = 0.11796797794332496
Trained batch 306 in epoch 8, gen_loss = 0.4032682925948103, disc_loss = 0.11781276453662579
Trained batch 307 in epoch 8, gen_loss = 0.40354730343663847, disc_loss = 0.11765171898915977
Trained batch 308 in epoch 8, gen_loss = 0.40341074846709046, disc_loss = 0.11746294595735166
Trained batch 309 in epoch 8, gen_loss = 0.4032743218445009, disc_loss = 0.11740418669557379
Trained batch 310 in epoch 8, gen_loss = 0.40310892002758875, disc_loss = 0.1174379908374939
Trained batch 311 in epoch 8, gen_loss = 0.40338585420678824, disc_loss = 0.1171753809799273
Trained batch 312 in epoch 8, gen_loss = 0.40312756450412374, disc_loss = 0.11714006935993132
Trained batch 313 in epoch 8, gen_loss = 0.40329447540507957, disc_loss = 0.11707303952425718
Trained batch 314 in epoch 8, gen_loss = 0.4033513108889262, disc_loss = 0.11686513344092028
Trained batch 315 in epoch 8, gen_loss = 0.4031622479610805, disc_loss = 0.11745076829897641
Trained batch 316 in epoch 8, gen_loss = 0.4031970229246639, disc_loss = 0.11815954585580232
Trained batch 317 in epoch 8, gen_loss = 0.40322641672203374, disc_loss = 0.1179381858545748
Trained batch 318 in epoch 8, gen_loss = 0.40340489420023834, disc_loss = 0.11783182649613361
Trained batch 319 in epoch 8, gen_loss = 0.40351688880473374, disc_loss = 0.11775298421853223
Trained batch 320 in epoch 8, gen_loss = 0.4035934402006809, disc_loss = 0.11778620299172364
Trained batch 321 in epoch 8, gen_loss = 0.4034517074223631, disc_loss = 0.11760446223898889
Trained batch 322 in epoch 8, gen_loss = 0.40374786787357864, disc_loss = 0.1175731738665986
Trained batch 323 in epoch 8, gen_loss = 0.4036018497965954, disc_loss = 0.11744831047699224
Trained batch 324 in epoch 8, gen_loss = 0.40371790702526383, disc_loss = 0.11717901423000372
Trained batch 325 in epoch 8, gen_loss = 0.40365206610205717, disc_loss = 0.11699105932325857
Trained batch 326 in epoch 8, gen_loss = 0.4038250472749774, disc_loss = 0.11682034418875471
Trained batch 327 in epoch 8, gen_loss = 0.4041527686867772, disc_loss = 0.11663152187176776
Trained batch 328 in epoch 8, gen_loss = 0.40411783849939387, disc_loss = 0.11672383094472545
Trained batch 329 in epoch 8, gen_loss = 0.40393953612356476, disc_loss = 0.11669687017459761
Trained batch 330 in epoch 8, gen_loss = 0.40403005993978497, disc_loss = 0.11652519941622577
Trained batch 331 in epoch 8, gen_loss = 0.4039191780499665, disc_loss = 0.11629338343122816
Trained batch 332 in epoch 8, gen_loss = 0.40389897345422626, disc_loss = 0.11640989011315792
Trained batch 333 in epoch 8, gen_loss = 0.4038088686630398, disc_loss = 0.11627495340712948
Trained batch 334 in epoch 8, gen_loss = 0.4038095428872464, disc_loss = 0.11634420372768124
Trained batch 335 in epoch 8, gen_loss = 0.40382797670151505, disc_loss = 0.11621668121577906
Trained batch 336 in epoch 8, gen_loss = 0.40388899900085495, disc_loss = 0.11598800872770368
Trained batch 337 in epoch 8, gen_loss = 0.4041746616716216, disc_loss = 0.11616229744815439
Trained batch 338 in epoch 8, gen_loss = 0.4039651131735439, disc_loss = 0.11600334173656318
Trained batch 339 in epoch 8, gen_loss = 0.40384392738342284, disc_loss = 0.11588924672345029
Trained batch 340 in epoch 8, gen_loss = 0.4040165099580267, disc_loss = 0.1156868810363966
Trained batch 341 in epoch 8, gen_loss = 0.4039642286230946, disc_loss = 0.11595002242108012
Trained batch 342 in epoch 8, gen_loss = 0.40409156775683075, disc_loss = 0.11612572478070725
Trained batch 343 in epoch 8, gen_loss = 0.40424992646588837, disc_loss = 0.11605779684235364
Trained batch 344 in epoch 8, gen_loss = 0.404130032269851, disc_loss = 0.11635587708349678
Trained batch 345 in epoch 8, gen_loss = 0.40407883965900177, disc_loss = 0.11625807896536382
Trained batch 346 in epoch 8, gen_loss = 0.4041216966913482, disc_loss = 0.11612858437001705
Trained batch 347 in epoch 8, gen_loss = 0.40414762411309385, disc_loss = 0.1159815101927125
Trained batch 348 in epoch 8, gen_loss = 0.4043306506807278, disc_loss = 0.11583080036528302
Trained batch 349 in epoch 8, gen_loss = 0.4042772659233638, disc_loss = 0.11580067053969417
Trained batch 350 in epoch 8, gen_loss = 0.4040899719947424, disc_loss = 0.11565566914649601
Trained batch 351 in epoch 8, gen_loss = 0.40411056722091004, disc_loss = 0.11568169965175912
Trained batch 352 in epoch 8, gen_loss = 0.40408867133237825, disc_loss = 0.11551063514654934
Trained batch 353 in epoch 8, gen_loss = 0.4041692165836776, disc_loss = 0.1154292638197878
Trained batch 354 in epoch 8, gen_loss = 0.40440941570510325, disc_loss = 0.11571241095137429
Trained batch 355 in epoch 8, gen_loss = 0.40427267819308166, disc_loss = 0.11605958479948425
Trained batch 356 in epoch 8, gen_loss = 0.4046660194209978, disc_loss = 0.1160328470076583
Trained batch 357 in epoch 8, gen_loss = 0.40463356582146115, disc_loss = 0.116042215465542
Trained batch 358 in epoch 8, gen_loss = 0.4045180462529068, disc_loss = 0.11604113111526687
Trained batch 359 in epoch 8, gen_loss = 0.4043845074872176, disc_loss = 0.1158735183843722
Trained batch 360 in epoch 8, gen_loss = 0.4042493970935695, disc_loss = 0.11608762403955254
Trained batch 361 in epoch 8, gen_loss = 0.40414617930986607, disc_loss = 0.11601725711039582
Trained batch 362 in epoch 8, gen_loss = 0.40425630139582086, disc_loss = 0.11592115244774287
Trained batch 363 in epoch 8, gen_loss = 0.4043041623228199, disc_loss = 0.11578554955341823
Trained batch 364 in epoch 8, gen_loss = 0.4045130855416598, disc_loss = 0.1157416990817818
Trained batch 365 in epoch 8, gen_loss = 0.4048675292176627, disc_loss = 0.11561010888385806
Trained batch 366 in epoch 8, gen_loss = 0.40487176699599386, disc_loss = 0.11543390990744982
Trained batch 367 in epoch 8, gen_loss = 0.4050944160832011, disc_loss = 0.1153791596778952
Trained batch 368 in epoch 8, gen_loss = 0.4051845370915524, disc_loss = 0.11531256011568596
Trained batch 369 in epoch 8, gen_loss = 0.4050552058058816, disc_loss = 0.11528782918545845
Trained batch 370 in epoch 8, gen_loss = 0.4050605511568949, disc_loss = 0.1150424844783673
Trained batch 371 in epoch 8, gen_loss = 0.40514161750193567, disc_loss = 0.11525862095677243
Trained batch 372 in epoch 8, gen_loss = 0.40525124204062907, disc_loss = 0.1152955902935113
Trained batch 373 in epoch 8, gen_loss = 0.4052074224872385, disc_loss = 0.11503261619093105
Trained batch 374 in epoch 8, gen_loss = 0.40525834957758583, disc_loss = 0.11503323629001776
Trained batch 375 in epoch 8, gen_loss = 0.4052836503437225, disc_loss = 0.1151775896321348
Trained batch 376 in epoch 8, gen_loss = 0.40542179433040976, disc_loss = 0.11528533885369092
Trained batch 377 in epoch 8, gen_loss = 0.4054498629910605, disc_loss = 0.115317852551699
Trained batch 378 in epoch 8, gen_loss = 0.405462468598323, disc_loss = 0.11526089594613437
Trained batch 379 in epoch 8, gen_loss = 0.4055905165640931, disc_loss = 0.11517954112373685
Trained batch 380 in epoch 8, gen_loss = 0.405898648531731, disc_loss = 0.11509319416826636
Trained batch 381 in epoch 8, gen_loss = 0.4057467792046632, disc_loss = 0.1152962073732499
Trained batch 382 in epoch 8, gen_loss = 0.40591295238574554, disc_loss = 0.11520577926801484
Trained batch 383 in epoch 8, gen_loss = 0.40584657511984307, disc_loss = 0.11536556639960811
Trained batch 384 in epoch 8, gen_loss = 0.4057011554767559, disc_loss = 0.11517713910283206
Trained batch 385 in epoch 8, gen_loss = 0.40566977843101776, disc_loss = 0.11545027924190068
Trained batch 386 in epoch 8, gen_loss = 0.4054959680528912, disc_loss = 0.11538492771255415
Trained batch 387 in epoch 8, gen_loss = 0.40578198886102007, disc_loss = 0.11529728012236277
Trained batch 388 in epoch 8, gen_loss = 0.40577433386621253, disc_loss = 0.11520410509622035
Trained batch 389 in epoch 8, gen_loss = 0.40587466473762807, disc_loss = 0.11518500293008029
Trained batch 390 in epoch 8, gen_loss = 0.40587888677101913, disc_loss = 0.11514156828622532
Trained batch 391 in epoch 8, gen_loss = 0.40578875082487964, disc_loss = 0.11518711483163037
Trained batch 392 in epoch 8, gen_loss = 0.4061256636493382, disc_loss = 0.11542649245311437
Trained batch 393 in epoch 8, gen_loss = 0.40596377539453166, disc_loss = 0.1156087638432075
Trained batch 394 in epoch 8, gen_loss = 0.405840264845498, disc_loss = 0.1155511795012634
Trained batch 395 in epoch 8, gen_loss = 0.40600600379585017, disc_loss = 0.11563691572577815
Trained batch 396 in epoch 8, gen_loss = 0.40590472463096117, disc_loss = 0.11587003147891096
Trained batch 397 in epoch 8, gen_loss = 0.40591113958226976, disc_loss = 0.11571877274250415
Trained batch 398 in epoch 8, gen_loss = 0.40571028778427526, disc_loss = 0.11569903389945216
Trained batch 399 in epoch 8, gen_loss = 0.40566533379256725, disc_loss = 0.11562388692516834
Trained batch 400 in epoch 8, gen_loss = 0.4054676602754807, disc_loss = 0.11571945993698891
Trained batch 401 in epoch 8, gen_loss = 0.40582451409664916, disc_loss = 0.11559991450025815
Trained batch 402 in epoch 8, gen_loss = 0.40585179645429476, disc_loss = 0.11555123512653943
Trained batch 403 in epoch 8, gen_loss = 0.4057755271839623, disc_loss = 0.11545454185585131
Trained batch 404 in epoch 8, gen_loss = 0.4059251919204806, disc_loss = 0.1154294409547691
Trained batch 405 in epoch 8, gen_loss = 0.4062983083901147, disc_loss = 0.11549246506169071
Trained batch 406 in epoch 8, gen_loss = 0.4061661030209328, disc_loss = 0.11550410095995856
Trained batch 407 in epoch 8, gen_loss = 0.4060630647867334, disc_loss = 0.11559296852689893
Trained batch 408 in epoch 8, gen_loss = 0.40590439099262865, disc_loss = 0.11555969613560983
Trained batch 409 in epoch 8, gen_loss = 0.4061124059485226, disc_loss = 0.11559297617343141
Trained batch 410 in epoch 8, gen_loss = 0.40609995524088544, disc_loss = 0.11548640307519413
Trained batch 411 in epoch 8, gen_loss = 0.4060397163322828, disc_loss = 0.11560306812464757
Trained batch 412 in epoch 8, gen_loss = 0.4064375359123036, disc_loss = 0.11559567862521794
Trained batch 413 in epoch 8, gen_loss = 0.40659469618025607, disc_loss = 0.1154154812341223
Trained batch 414 in epoch 8, gen_loss = 0.40652588684874846, disc_loss = 0.11542492247220264
Trained batch 415 in epoch 8, gen_loss = 0.40652441433989084, disc_loss = 0.11547335259204444
Trained batch 416 in epoch 8, gen_loss = 0.4066113035598819, disc_loss = 0.11537311514236516
Trained batch 417 in epoch 8, gen_loss = 0.4066589406232514, disc_loss = 0.11536856575392222
Trained batch 418 in epoch 8, gen_loss = 0.40656176522409715, disc_loss = 0.11565716499307133
Trained batch 419 in epoch 8, gen_loss = 0.40658344200679236, disc_loss = 0.11565438026917123
Trained batch 420 in epoch 8, gen_loss = 0.4066108799320502, disc_loss = 0.11562076652081874
Trained batch 421 in epoch 8, gen_loss = 0.4067229754975622, disc_loss = 0.11561192673194041
Trained batch 422 in epoch 8, gen_loss = 0.40657014239482564, disc_loss = 0.11555948834558046
Trained batch 423 in epoch 8, gen_loss = 0.4067444587653538, disc_loss = 0.11547060921032615
Trained batch 424 in epoch 8, gen_loss = 0.4067836583361906, disc_loss = 0.11537053629317705
Trained batch 425 in epoch 8, gen_loss = 0.40667101034256214, disc_loss = 0.11535557886331993
Trained batch 426 in epoch 8, gen_loss = 0.40657131865934687, disc_loss = 0.1154328285818985
Trained batch 427 in epoch 8, gen_loss = 0.4065152353772493, disc_loss = 0.11557186835784918
Trained batch 428 in epoch 8, gen_loss = 0.40659525587564305, disc_loss = 0.11539596336131747
Trained batch 429 in epoch 8, gen_loss = 0.4069300679966461, disc_loss = 0.11548101444143889
Trained batch 430 in epoch 8, gen_loss = 0.406904055873092, disc_loss = 0.11538909359677346
Trained batch 431 in epoch 8, gen_loss = 0.40666428615373595, disc_loss = 0.11555862559126345
Trained batch 432 in epoch 8, gen_loss = 0.4069551414622996, disc_loss = 0.11544387517002246
Trained batch 433 in epoch 8, gen_loss = 0.4070588054332865, disc_loss = 0.11561190295312125
Trained batch 434 in epoch 8, gen_loss = 0.4070174501545128, disc_loss = 0.115638485957665
Trained batch 435 in epoch 8, gen_loss = 0.4068941994817979, disc_loss = 0.1158528946160655
Trained batch 436 in epoch 8, gen_loss = 0.4069448743586682, disc_loss = 0.11568505236414395
Trained batch 437 in epoch 8, gen_loss = 0.4071028910271109, disc_loss = 0.115920897790116
Trained batch 438 in epoch 8, gen_loss = 0.4071633989555689, disc_loss = 0.1160450072275954
Trained batch 439 in epoch 8, gen_loss = 0.4072103161026131, disc_loss = 0.11586335057985377
Trained batch 440 in epoch 8, gen_loss = 0.40709074534256173, disc_loss = 0.11588893402072173
Trained batch 441 in epoch 8, gen_loss = 0.40702358009588663, disc_loss = 0.11577929775925917
Trained batch 442 in epoch 8, gen_loss = 0.4071004412916928, disc_loss = 0.11579378640897252
Trained batch 443 in epoch 8, gen_loss = 0.4068703003026344, disc_loss = 0.1159231043420732
Trained batch 444 in epoch 8, gen_loss = 0.40688526108023826, disc_loss = 0.11586245370798566
Trained batch 445 in epoch 8, gen_loss = 0.40702481100110194, disc_loss = 0.11605046096888492
Trained batch 446 in epoch 8, gen_loss = 0.4071459979552284, disc_loss = 0.11599348072520972
Trained batch 447 in epoch 8, gen_loss = 0.4072207440622151, disc_loss = 0.11586576128528188
Trained batch 448 in epoch 8, gen_loss = 0.40705163992592913, disc_loss = 0.11585944181179549
Trained batch 449 in epoch 8, gen_loss = 0.4069652400414149, disc_loss = 0.11572201926261187
Trained batch 450 in epoch 8, gen_loss = 0.40686415284541655, disc_loss = 0.11570370979111501
Trained batch 451 in epoch 8, gen_loss = 0.4068392109026951, disc_loss = 0.11559969080051621
Trained batch 452 in epoch 8, gen_loss = 0.4067795378614472, disc_loss = 0.11548552060577912
Trained batch 453 in epoch 8, gen_loss = 0.4067748549357385, disc_loss = 0.11552130446116961
Trained batch 454 in epoch 8, gen_loss = 0.4066513370026599, disc_loss = 0.11569858683416477
Trained batch 455 in epoch 8, gen_loss = 0.4067408154277425, disc_loss = 0.11561150283944842
Trained batch 456 in epoch 8, gen_loss = 0.406888933293929, disc_loss = 0.11556760890560155
Trained batch 457 in epoch 8, gen_loss = 0.4067433186233304, disc_loss = 0.11545392436963632
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.3888323903083801, disc_loss = 0.16094738245010376
Trained batch 1 in epoch 9, gen_loss = 0.4059780538082123, disc_loss = 0.12752779945731163
Trained batch 2 in epoch 9, gen_loss = 0.40521688262621564, disc_loss = 0.10839308549960454
Trained batch 3 in epoch 9, gen_loss = 0.41712426394224167, disc_loss = 0.12451526708900928
Trained batch 4 in epoch 9, gen_loss = 0.40584676861763, disc_loss = 0.12172382324934006
Trained batch 5 in epoch 9, gen_loss = 0.4129544347524643, disc_loss = 0.12957027678688368
Trained batch 6 in epoch 9, gen_loss = 0.3910910316876003, disc_loss = 0.13135005853005818
Trained batch 7 in epoch 9, gen_loss = 0.3905998542904854, disc_loss = 0.12438628356903791
Trained batch 8 in epoch 9, gen_loss = 0.406466007232666, disc_loss = 0.12107575353648928
Trained batch 9 in epoch 9, gen_loss = 0.41128588020801543, disc_loss = 0.11632017567753791
Trained batch 10 in epoch 9, gen_loss = 0.41620954871177673, disc_loss = 0.12992923164909537
Trained batch 11 in epoch 9, gen_loss = 0.42139510065317154, disc_loss = 0.13442407362163067
Trained batch 12 in epoch 9, gen_loss = 0.41518781506098235, disc_loss = 0.12859867226618987
Trained batch 13 in epoch 9, gen_loss = 0.4134985144649233, disc_loss = 0.14786637308342115
Trained batch 14 in epoch 9, gen_loss = 0.4136111080646515, disc_loss = 0.14563508729139965
Trained batch 15 in epoch 9, gen_loss = 0.41612696647644043, disc_loss = 0.1424574595876038
Trained batch 16 in epoch 9, gen_loss = 0.4118894426261677, disc_loss = 0.13971398376366673
Trained batch 17 in epoch 9, gen_loss = 0.4090203510390388, disc_loss = 0.13718776611818206
Trained batch 18 in epoch 9, gen_loss = 0.40930456864206416, disc_loss = 0.13412193208932877
Trained batch 19 in epoch 9, gen_loss = 0.41099837720394133, disc_loss = 0.13113666661083698
Trained batch 20 in epoch 9, gen_loss = 0.415974185580299, disc_loss = 0.13031998808894837
Trained batch 21 in epoch 9, gen_loss = 0.4160010652108626, disc_loss = 0.1304078647358851
Trained batch 22 in epoch 9, gen_loss = 0.4142769225265669, disc_loss = 0.12849224294009415
Trained batch 23 in epoch 9, gen_loss = 0.4143908979992072, disc_loss = 0.13127426647891602
Trained batch 24 in epoch 9, gen_loss = 0.41353690505027774, disc_loss = 0.13264564245939256
Trained batch 25 in epoch 9, gen_loss = 0.4174499041759051, disc_loss = 0.13014968398671883
Trained batch 26 in epoch 9, gen_loss = 0.4167363268357736, disc_loss = 0.13309117241038215
Trained batch 27 in epoch 9, gen_loss = 0.41790356167725157, disc_loss = 0.13154106800045287
Trained batch 28 in epoch 9, gen_loss = 0.41727193265125667, disc_loss = 0.13135760611501232
Trained batch 29 in epoch 9, gen_loss = 0.4154652088880539, disc_loss = 0.1307140161593755
Trained batch 30 in epoch 9, gen_loss = 0.41508836034805546, disc_loss = 0.1296003381571462
Trained batch 31 in epoch 9, gen_loss = 0.4190921140834689, disc_loss = 0.12748108233790845
Trained batch 32 in epoch 9, gen_loss = 0.41540753751090076, disc_loss = 0.12719527981949574
Trained batch 33 in epoch 9, gen_loss = 0.41587351350223317, disc_loss = 0.12510423745740862
Trained batch 34 in epoch 9, gen_loss = 0.41754073330334257, disc_loss = 0.1255488420171397
Trained batch 35 in epoch 9, gen_loss = 0.414981169005235, disc_loss = 0.12601757494525778
Trained batch 36 in epoch 9, gen_loss = 0.4137483134463027, disc_loss = 0.12559846194612012
Trained batch 37 in epoch 9, gen_loss = 0.41414529555722285, disc_loss = 0.12340186163783073
Trained batch 38 in epoch 9, gen_loss = 0.4145839030926044, disc_loss = 0.12162872566244541
Trained batch 39 in epoch 9, gen_loss = 0.4142635874450207, disc_loss = 0.1197796874679625
Trained batch 40 in epoch 9, gen_loss = 0.41464657172924135, disc_loss = 0.11741445545197987
Trained batch 41 in epoch 9, gen_loss = 0.41602893031778787, disc_loss = 0.11654029915197975
Trained batch 42 in epoch 9, gen_loss = 0.41520000335782076, disc_loss = 0.11565140656433827
Trained batch 43 in epoch 9, gen_loss = 0.41555040600624954, disc_loss = 0.11450700669295409
Trained batch 44 in epoch 9, gen_loss = 0.4171991719139947, disc_loss = 0.11409687072866492
Trained batch 45 in epoch 9, gen_loss = 0.415909657659738, disc_loss = 0.11332205492679191
Trained batch 46 in epoch 9, gen_loss = 0.4146417740811693, disc_loss = 0.11220682352939819
Trained batch 47 in epoch 9, gen_loss = 0.41557268612086773, disc_loss = 0.11072742353038241
Trained batch 48 in epoch 9, gen_loss = 0.4162947480775872, disc_loss = 0.10880118555256299
Trained batch 49 in epoch 9, gen_loss = 0.4155771607160568, disc_loss = 0.10790072195231915
Trained batch 50 in epoch 9, gen_loss = 0.4157842292505152, disc_loss = 0.10721608302464672
Trained batch 51 in epoch 9, gen_loss = 0.41574815144905675, disc_loss = 0.10757729418289202
Trained batch 52 in epoch 9, gen_loss = 0.4161742740082291, disc_loss = 0.10732622943677993
Trained batch 53 in epoch 9, gen_loss = 0.4150932287728345, disc_loss = 0.10732052523504805
Trained batch 54 in epoch 9, gen_loss = 0.41599963199008594, disc_loss = 0.1065930617803877
Trained batch 55 in epoch 9, gen_loss = 0.4169902742973396, disc_loss = 0.10533480592338103
Trained batch 56 in epoch 9, gen_loss = 0.4186334698869471, disc_loss = 0.10439233501490794
Trained batch 57 in epoch 9, gen_loss = 0.4186204908222988, disc_loss = 0.10339063964784145
Trained batch 58 in epoch 9, gen_loss = 0.4182352191310818, disc_loss = 0.10247647225604219
Trained batch 59 in epoch 9, gen_loss = 0.41648593842983245, disc_loss = 0.1014099607244134
Trained batch 60 in epoch 9, gen_loss = 0.4172066704171603, disc_loss = 0.1001267642943097
Trained batch 61 in epoch 9, gen_loss = 0.4184847055904327, disc_loss = 0.09885237963810083
Trained batch 62 in epoch 9, gen_loss = 0.4183788649619572, disc_loss = 0.09853865936516769
Trained batch 63 in epoch 9, gen_loss = 0.4183655781671405, disc_loss = 0.09855811888701282
Trained batch 64 in epoch 9, gen_loss = 0.41800025976621186, disc_loss = 0.09995408364786551
Trained batch 65 in epoch 9, gen_loss = 0.4186069938269528, disc_loss = 0.10130989221348004
Trained batch 66 in epoch 9, gen_loss = 0.4185718831731312, disc_loss = 0.10077523081493911
Trained batch 67 in epoch 9, gen_loss = 0.4186964981696185, disc_loss = 0.10010214848443866
Trained batch 68 in epoch 9, gen_loss = 0.4186309636503026, disc_loss = 0.10076911895927312
Trained batch 69 in epoch 9, gen_loss = 0.41944543038095744, disc_loss = 0.09980571059776204
Trained batch 70 in epoch 9, gen_loss = 0.41856859435497873, disc_loss = 0.09920647207804968
Trained batch 71 in epoch 9, gen_loss = 0.41835910288823974, disc_loss = 0.09866014658473432
Trained batch 72 in epoch 9, gen_loss = 0.4177318901231844, disc_loss = 0.0983325070255015
Trained batch 73 in epoch 9, gen_loss = 0.41737411231608, disc_loss = 0.09789063768914423
Trained batch 74 in epoch 9, gen_loss = 0.4169870762030284, disc_loss = 0.09712025679647923
Trained batch 75 in epoch 9, gen_loss = 0.41629076984367874, disc_loss = 0.09773216845075551
Trained batch 76 in epoch 9, gen_loss = 0.4163250427741509, disc_loss = 0.09791383086764194
Trained batch 77 in epoch 9, gen_loss = 0.4149132455006624, disc_loss = 0.09743590354441832
Trained batch 78 in epoch 9, gen_loss = 0.4151700191859958, disc_loss = 0.09671580619355545
Trained batch 79 in epoch 9, gen_loss = 0.4156601633876562, disc_loss = 0.0961721345083788
Trained batch 80 in epoch 9, gen_loss = 0.41625485633626397, disc_loss = 0.09627927124592257
Trained batch 81 in epoch 9, gen_loss = 0.4152577784730167, disc_loss = 0.09632933196588987
Trained batch 82 in epoch 9, gen_loss = 0.41474950241755293, disc_loss = 0.09694898795022304
Trained batch 83 in epoch 9, gen_loss = 0.41587592093717485, disc_loss = 0.0966876429683041
Trained batch 84 in epoch 9, gen_loss = 0.4159368634223938, disc_loss = 0.09632958070758511
Trained batch 85 in epoch 9, gen_loss = 0.41570826602536576, disc_loss = 0.09595835574924252
Trained batch 86 in epoch 9, gen_loss = 0.4147956254838527, disc_loss = 0.09609507163451321
Trained batch 87 in epoch 9, gen_loss = 0.4144013754346154, disc_loss = 0.09609906225126576
Trained batch 88 in epoch 9, gen_loss = 0.4133473386925258, disc_loss = 0.09699469304570321
Trained batch 89 in epoch 9, gen_loss = 0.41514881187015107, disc_loss = 0.09615744933899906
Trained batch 90 in epoch 9, gen_loss = 0.4148328219141279, disc_loss = 0.09621890677282444
Trained batch 91 in epoch 9, gen_loss = 0.4150364522052848, disc_loss = 0.09619006338407812
Trained batch 92 in epoch 9, gen_loss = 0.41410663563718075, disc_loss = 0.0967423478642138
Trained batch 93 in epoch 9, gen_loss = 0.41392100523126885, disc_loss = 0.09663016676030894
Trained batch 94 in epoch 9, gen_loss = 0.4134225519079911, disc_loss = 0.09671749811815589
Trained batch 95 in epoch 9, gen_loss = 0.413543068493406, disc_loss = 0.09681494497150804
Trained batch 96 in epoch 9, gen_loss = 0.41369350116277476, disc_loss = 0.0970723148358544
Trained batch 97 in epoch 9, gen_loss = 0.41342925751695825, disc_loss = 0.09640761375503272
Trained batch 98 in epoch 9, gen_loss = 0.4126533152479114, disc_loss = 0.09659323083105112
Trained batch 99 in epoch 9, gen_loss = 0.4130378451943397, disc_loss = 0.09634958641603589
Trained batch 100 in epoch 9, gen_loss = 0.41344131544084833, disc_loss = 0.09686076687187842
Trained batch 101 in epoch 9, gen_loss = 0.41328588858538984, disc_loss = 0.09632917864284679
Trained batch 102 in epoch 9, gen_loss = 0.4127714981153173, disc_loss = 0.09699037589711472
Trained batch 103 in epoch 9, gen_loss = 0.41335208628040093, disc_loss = 0.09722288459754334
Trained batch 104 in epoch 9, gen_loss = 0.41383003081594194, disc_loss = 0.09978009510253157
Trained batch 105 in epoch 9, gen_loss = 0.4140102691807837, disc_loss = 0.10050833061829491
Trained batch 106 in epoch 9, gen_loss = 0.413934870301006, disc_loss = 0.10031807748165643
Trained batch 107 in epoch 9, gen_loss = 0.41452745017078185, disc_loss = 0.10111488420861187
Trained batch 108 in epoch 9, gen_loss = 0.41345725803200256, disc_loss = 0.10219323052383891
Trained batch 109 in epoch 9, gen_loss = 0.41376587748527527, disc_loss = 0.10204812957143242
Trained batch 110 in epoch 9, gen_loss = 0.41365998795440606, disc_loss = 0.10179298986924125
Trained batch 111 in epoch 9, gen_loss = 0.4136389360896179, disc_loss = 0.10137852532456496
Trained batch 112 in epoch 9, gen_loss = 0.41411229968070984, disc_loss = 0.1009366868838536
Trained batch 113 in epoch 9, gen_loss = 0.41392344184089125, disc_loss = 0.10091457520856668
Trained batch 114 in epoch 9, gen_loss = 0.4135511914025182, disc_loss = 0.10079581405481566
Trained batch 115 in epoch 9, gen_loss = 0.41339663929980375, disc_loss = 0.10074418094330306
Trained batch 116 in epoch 9, gen_loss = 0.41292526986863876, disc_loss = 0.10122934332451759
Trained batch 117 in epoch 9, gen_loss = 0.41302062848866994, disc_loss = 0.10252530309292725
Trained batch 118 in epoch 9, gen_loss = 0.4135662014243983, disc_loss = 0.10465766944992944
Trained batch 119 in epoch 9, gen_loss = 0.4128402585784594, disc_loss = 0.1043033287084351
Trained batch 120 in epoch 9, gen_loss = 0.41234795860022555, disc_loss = 0.1047606948639982
Trained batch 121 in epoch 9, gen_loss = 0.4121748941843627, disc_loss = 0.10510934499993188
Trained batch 122 in epoch 9, gen_loss = 0.411201077505825, disc_loss = 0.10537197727073984
Trained batch 123 in epoch 9, gen_loss = 0.4111481917000586, disc_loss = 0.10530906682834029
Trained batch 124 in epoch 9, gen_loss = 0.4118372044563293, disc_loss = 0.10486221365630627
Trained batch 125 in epoch 9, gen_loss = 0.4117101556251919, disc_loss = 0.1048781101163181
Trained batch 126 in epoch 9, gen_loss = 0.41263128476818717, disc_loss = 0.10529869787512332
Trained batch 127 in epoch 9, gen_loss = 0.41185393393971026, disc_loss = 0.10602225262846332
Trained batch 128 in epoch 9, gen_loss = 0.4112253963023193, disc_loss = 0.10615983823415383
Trained batch 129 in epoch 9, gen_loss = 0.4115924216233767, disc_loss = 0.1059743302802627
Trained batch 130 in epoch 9, gen_loss = 0.4119999431471788, disc_loss = 0.1058101266594106
Trained batch 131 in epoch 9, gen_loss = 0.41225886886770075, disc_loss = 0.10648738676117676
Trained batch 132 in epoch 9, gen_loss = 0.4120554720100604, disc_loss = 0.1062415808971439
Trained batch 133 in epoch 9, gen_loss = 0.4114284557637884, disc_loss = 0.10599887019384709
Trained batch 134 in epoch 9, gen_loss = 0.41156815489133197, disc_loss = 0.10570775870647696
Trained batch 135 in epoch 9, gen_loss = 0.4121525189017548, disc_loss = 0.10516066237024087
Trained batch 136 in epoch 9, gen_loss = 0.41200512560614705, disc_loss = 0.10491892000673896
Trained batch 137 in epoch 9, gen_loss = 0.4121423024630201, disc_loss = 0.10501489476503237
Trained batch 138 in epoch 9, gen_loss = 0.4119583550545809, disc_loss = 0.10524279405798415
Trained batch 139 in epoch 9, gen_loss = 0.4116589507886342, disc_loss = 0.10639855213729399
Trained batch 140 in epoch 9, gen_loss = 0.411706952761251, disc_loss = 0.10715832821496413
Trained batch 141 in epoch 9, gen_loss = 0.41162286572892903, disc_loss = 0.10700066719519001
Trained batch 142 in epoch 9, gen_loss = 0.41186667572368274, disc_loss = 0.10675278166634636
Trained batch 143 in epoch 9, gen_loss = 0.4121672639416324, disc_loss = 0.10633632904177324
Trained batch 144 in epoch 9, gen_loss = 0.41220571501501674, disc_loss = 0.10621461926092361
Trained batch 145 in epoch 9, gen_loss = 0.4126459443814134, disc_loss = 0.10607980978866555
Trained batch 146 in epoch 9, gen_loss = 0.4125312945875181, disc_loss = 0.10611728341857186
Trained batch 147 in epoch 9, gen_loss = 0.41248902396575826, disc_loss = 0.10633780768241834
Trained batch 148 in epoch 9, gen_loss = 0.4117315327561142, disc_loss = 0.1062262791440191
Trained batch 149 in epoch 9, gen_loss = 0.41126853187878926, disc_loss = 0.10635652215530475
Trained batch 150 in epoch 9, gen_loss = 0.4110178671135808, disc_loss = 0.1063247396185106
Trained batch 151 in epoch 9, gen_loss = 0.4113607261525957, disc_loss = 0.10626781046831686
Trained batch 152 in epoch 9, gen_loss = 0.4114035812078738, disc_loss = 0.105915966486327
Trained batch 153 in epoch 9, gen_loss = 0.4106103061855613, disc_loss = 0.1061962100906999
Trained batch 154 in epoch 9, gen_loss = 0.4106455212639224, disc_loss = 0.10622480435957832
Trained batch 155 in epoch 9, gen_loss = 0.410635466950062, disc_loss = 0.10571987221304041
Trained batch 156 in epoch 9, gen_loss = 0.4107685649091271, disc_loss = 0.105829883497327
Trained batch 157 in epoch 9, gen_loss = 0.4114940243808529, disc_loss = 0.10662494058708978
Trained batch 158 in epoch 9, gen_loss = 0.41151278836172334, disc_loss = 0.10650490745667766
Trained batch 159 in epoch 9, gen_loss = 0.4115076422691345, disc_loss = 0.10661896608071401
Trained batch 160 in epoch 9, gen_loss = 0.41158170266921473, disc_loss = 0.10658644353797347
Trained batch 161 in epoch 9, gen_loss = 0.41130029088185155, disc_loss = 0.10669149818289796
Trained batch 162 in epoch 9, gen_loss = 0.41089305482759064, disc_loss = 0.10648944892811994
Trained batch 163 in epoch 9, gen_loss = 0.41062386733729667, disc_loss = 0.10619733722244458
Trained batch 164 in epoch 9, gen_loss = 0.4098358710606893, disc_loss = 0.10620732703669504
Trained batch 165 in epoch 9, gen_loss = 0.4101070370300707, disc_loss = 0.10603265642715864
Trained batch 166 in epoch 9, gen_loss = 0.4104263002644042, disc_loss = 0.10589727022110702
Trained batch 167 in epoch 9, gen_loss = 0.41027117733444485, disc_loss = 0.10582407762385196
Trained batch 168 in epoch 9, gen_loss = 0.41026929796800105, disc_loss = 0.10562467715047168
Trained batch 169 in epoch 9, gen_loss = 0.41034482244183035, disc_loss = 0.10531378540703479
Trained batch 170 in epoch 9, gen_loss = 0.41067602202209114, disc_loss = 0.10517584418126366
Trained batch 171 in epoch 9, gen_loss = 0.4105105536968209, disc_loss = 0.1051414628339888
Trained batch 172 in epoch 9, gen_loss = 0.4110153848036176, disc_loss = 0.10503558038244012
Trained batch 173 in epoch 9, gen_loss = 0.4113631006972543, disc_loss = 0.10483725963096166
Trained batch 174 in epoch 9, gen_loss = 0.41128939628601074, disc_loss = 0.10491497443190642
Trained batch 175 in epoch 9, gen_loss = 0.41155637038702314, disc_loss = 0.1046741166554222
Trained batch 176 in epoch 9, gen_loss = 0.41185964820748666, disc_loss = 0.10488209990247832
Trained batch 177 in epoch 9, gen_loss = 0.41156305590372405, disc_loss = 0.10541619840758236
Trained batch 178 in epoch 9, gen_loss = 0.41127504416684196, disc_loss = 0.1054920003380023
Trained batch 179 in epoch 9, gen_loss = 0.4112104265226258, disc_loss = 0.10536274888242285
Trained batch 180 in epoch 9, gen_loss = 0.4109464295990559, disc_loss = 0.10566359061686044
Trained batch 181 in epoch 9, gen_loss = 0.41089502910336295, disc_loss = 0.10602722426487522
Trained batch 182 in epoch 9, gen_loss = 0.4105286028215794, disc_loss = 0.10585181133139654
Trained batch 183 in epoch 9, gen_loss = 0.41006828002307727, disc_loss = 0.10609577404861541
Trained batch 184 in epoch 9, gen_loss = 0.41082966939823046, disc_loss = 0.10604577587061637
Trained batch 185 in epoch 9, gen_loss = 0.4110607538492449, disc_loss = 0.10586666883600335
Trained batch 186 in epoch 9, gen_loss = 0.4108530094916808, disc_loss = 0.10569405769879486
Trained batch 187 in epoch 9, gen_loss = 0.4105169990278305, disc_loss = 0.10564246503239934
Trained batch 188 in epoch 9, gen_loss = 0.4107090248948052, disc_loss = 0.10544898836976951
Trained batch 189 in epoch 9, gen_loss = 0.41072289959380504, disc_loss = 0.10617341594280381
Trained batch 190 in epoch 9, gen_loss = 0.410607992510521, disc_loss = 0.10634204393242978
Trained batch 191 in epoch 9, gen_loss = 0.4105298575013876, disc_loss = 0.1060964549833443
Trained batch 192 in epoch 9, gen_loss = 0.41060661682810806, disc_loss = 0.10615059603102157
Trained batch 193 in epoch 9, gen_loss = 0.41028165571468395, disc_loss = 0.10617518157112538
Trained batch 194 in epoch 9, gen_loss = 0.41120018194883295, disc_loss = 0.10612310175903332
Trained batch 195 in epoch 9, gen_loss = 0.41172671591749, disc_loss = 0.10608100242038467
Trained batch 196 in epoch 9, gen_loss = 0.4114228565680799, disc_loss = 0.10587604114133392
Trained batch 197 in epoch 9, gen_loss = 0.41188477205507684, disc_loss = 0.10553612602366642
Trained batch 198 in epoch 9, gen_loss = 0.4119526979012705, disc_loss = 0.10552369512093426
Trained batch 199 in epoch 9, gen_loss = 0.41177540555596354, disc_loss = 0.10571752903051675
Trained batch 200 in epoch 9, gen_loss = 0.41205750309412753, disc_loss = 0.1057562895990278
Trained batch 201 in epoch 9, gen_loss = 0.41172341471261314, disc_loss = 0.10559122143589919
Trained batch 202 in epoch 9, gen_loss = 0.41141865743792116, disc_loss = 0.10548873991691714
Trained batch 203 in epoch 9, gen_loss = 0.41218212904299006, disc_loss = 0.10570080130014058
Trained batch 204 in epoch 9, gen_loss = 0.4122262912552531, disc_loss = 0.10559505984732291
Trained batch 205 in epoch 9, gen_loss = 0.41250325377705027, disc_loss = 0.1055880757591244
Trained batch 206 in epoch 9, gen_loss = 0.41269456865130993, disc_loss = 0.10529075133735719
Trained batch 207 in epoch 9, gen_loss = 0.4126525793511134, disc_loss = 0.10566276371873055
Trained batch 208 in epoch 9, gen_loss = 0.41255674279477605, disc_loss = 0.10571770379809957
Trained batch 209 in epoch 9, gen_loss = 0.4123668941713515, disc_loss = 0.105712505740424
Trained batch 210 in epoch 9, gen_loss = 0.4121489305914296, disc_loss = 0.105601708073681
Trained batch 211 in epoch 9, gen_loss = 0.4120359351893641, disc_loss = 0.10539260149037219
Trained batch 212 in epoch 9, gen_loss = 0.41196430233162895, disc_loss = 0.10518991633235289
Trained batch 213 in epoch 9, gen_loss = 0.4116446250509993, disc_loss = 0.10574795292672988
Trained batch 214 in epoch 9, gen_loss = 0.41161838575851084, disc_loss = 0.1055796947676775
Trained batch 215 in epoch 9, gen_loss = 0.4117553552819623, disc_loss = 0.10564928509605427
Trained batch 216 in epoch 9, gen_loss = 0.41196019487446905, disc_loss = 0.10652697066591907
Trained batch 217 in epoch 9, gen_loss = 0.41236364923485924, disc_loss = 0.10637937558797794
Trained batch 218 in epoch 9, gen_loss = 0.4120419757551254, disc_loss = 0.10693239509957293
Trained batch 219 in epoch 9, gen_loss = 0.41224762445146385, disc_loss = 0.1076976098543541
Trained batch 220 in epoch 9, gen_loss = 0.4118312219688795, disc_loss = 0.10818153886942032
Trained batch 221 in epoch 9, gen_loss = 0.4117801345146454, disc_loss = 0.10832973875877289
Trained batch 222 in epoch 9, gen_loss = 0.4120828769934017, disc_loss = 0.10813721808116265
Trained batch 223 in epoch 9, gen_loss = 0.4122680859374149, disc_loss = 0.10792857665468805
Trained batch 224 in epoch 9, gen_loss = 0.41286400768491954, disc_loss = 0.10783676260875331
Trained batch 225 in epoch 9, gen_loss = 0.4126901390541971, disc_loss = 0.10773903738905106
Trained batch 226 in epoch 9, gen_loss = 0.4129611706681188, disc_loss = 0.10765562853919515
Trained batch 227 in epoch 9, gen_loss = 0.41282779370483597, disc_loss = 0.10779993713980443
Trained batch 228 in epoch 9, gen_loss = 0.41291224201693805, disc_loss = 0.1076948986384676
Trained batch 229 in epoch 9, gen_loss = 0.4124782181304434, disc_loss = 0.10746152092419241
Trained batch 230 in epoch 9, gen_loss = 0.4122410389510068, disc_loss = 0.10748357234675905
Trained batch 231 in epoch 9, gen_loss = 0.41208416005146914, disc_loss = 0.10744712642265548
Trained batch 232 in epoch 9, gen_loss = 0.4120489879483317, disc_loss = 0.1071649807956981
Trained batch 233 in epoch 9, gen_loss = 0.41209370814836943, disc_loss = 0.1069555623202115
Trained batch 234 in epoch 9, gen_loss = 0.4116956941624905, disc_loss = 0.10665806139561725
Trained batch 235 in epoch 9, gen_loss = 0.4117293530854128, disc_loss = 0.10660496279123728
Trained batch 236 in epoch 9, gen_loss = 0.41165108041924264, disc_loss = 0.1064104660480963
Trained batch 237 in epoch 9, gen_loss = 0.4120926413716388, disc_loss = 0.10652656159011506
Trained batch 238 in epoch 9, gen_loss = 0.4118075026627864, disc_loss = 0.10645845392913748
Trained batch 239 in epoch 9, gen_loss = 0.41161599569022655, disc_loss = 0.10687277159498383
Trained batch 240 in epoch 9, gen_loss = 0.41205543959783814, disc_loss = 0.10732958720092704
Trained batch 241 in epoch 9, gen_loss = 0.41200552240383526, disc_loss = 0.10732039345105078
Trained batch 242 in epoch 9, gen_loss = 0.4116389975871569, disc_loss = 0.10850580169248238
Trained batch 243 in epoch 9, gen_loss = 0.41198865421971337, disc_loss = 0.10825987931982171
Trained batch 244 in epoch 9, gen_loss = 0.41200853598361115, disc_loss = 0.10834450109728745
Trained batch 245 in epoch 9, gen_loss = 0.4119701211045428, disc_loss = 0.1080609522684197
Trained batch 246 in epoch 9, gen_loss = 0.4118332610680507, disc_loss = 0.10784957608441834
Trained batch 247 in epoch 9, gen_loss = 0.41205442816980425, disc_loss = 0.10766818580938683
Trained batch 248 in epoch 9, gen_loss = 0.41196658608903847, disc_loss = 0.10757579294643009
Trained batch 249 in epoch 9, gen_loss = 0.41200169110298157, disc_loss = 0.107381124176085
Trained batch 250 in epoch 9, gen_loss = 0.4116274433069495, disc_loss = 0.10752586471992898
Trained batch 251 in epoch 9, gen_loss = 0.41173225818645387, disc_loss = 0.10738976995298077
Trained batch 252 in epoch 9, gen_loss = 0.4113339733464916, disc_loss = 0.10755415694427349
Trained batch 253 in epoch 9, gen_loss = 0.4113050985524035, disc_loss = 0.10735586193925518
Trained batch 254 in epoch 9, gen_loss = 0.41103560912842846, disc_loss = 0.10720697146858654
Trained batch 255 in epoch 9, gen_loss = 0.4109456749865785, disc_loss = 0.10736383354378631
Trained batch 256 in epoch 9, gen_loss = 0.410825084967372, disc_loss = 0.10739032117512208
Trained batch 257 in epoch 9, gen_loss = 0.4107441965692727, disc_loss = 0.10727229320927877
Trained batch 258 in epoch 9, gen_loss = 0.41071539610969515, disc_loss = 0.10712010012831698
Trained batch 259 in epoch 9, gen_loss = 0.41029396458314016, disc_loss = 0.10717302299319552
Trained batch 260 in epoch 9, gen_loss = 0.41016092234187657, disc_loss = 0.10701176651906921
Trained batch 261 in epoch 9, gen_loss = 0.41018776663842094, disc_loss = 0.10672271095984082
Trained batch 262 in epoch 9, gen_loss = 0.4102162372023434, disc_loss = 0.10658416368010606
Trained batch 263 in epoch 9, gen_loss = 0.4103279546128981, disc_loss = 0.10632778662539115
Trained batch 264 in epoch 9, gen_loss = 0.41021029769249684, disc_loss = 0.106163723801948
Trained batch 265 in epoch 9, gen_loss = 0.4102518867729302, disc_loss = 0.10616638030352674
Trained batch 266 in epoch 9, gen_loss = 0.4103361743219783, disc_loss = 0.10618730604453257
Trained batch 267 in epoch 9, gen_loss = 0.41026212686478203, disc_loss = 0.10608700199275096
Trained batch 268 in epoch 9, gen_loss = 0.4104827189312548, disc_loss = 0.1057875506496784
Trained batch 269 in epoch 9, gen_loss = 0.410508793702832, disc_loss = 0.1055223008548772
Trained batch 270 in epoch 9, gen_loss = 0.41074944169318983, disc_loss = 0.10543914034797697
Trained batch 271 in epoch 9, gen_loss = 0.41098337258924456, disc_loss = 0.10519339886548765
Trained batch 272 in epoch 9, gen_loss = 0.41071599110578877, disc_loss = 0.1050469213789636
Trained batch 273 in epoch 9, gen_loss = 0.41048985393377985, disc_loss = 0.10505946024055898
Trained batch 274 in epoch 9, gen_loss = 0.4103663801063191, disc_loss = 0.10505447764288295
Trained batch 275 in epoch 9, gen_loss = 0.41038608907357504, disc_loss = 0.10495396841155447
Trained batch 276 in epoch 9, gen_loss = 0.41040139163874545, disc_loss = 0.10465776147690706
Trained batch 277 in epoch 9, gen_loss = 0.4107792596165225, disc_loss = 0.10468569576820667
Trained batch 278 in epoch 9, gen_loss = 0.4107959052567841, disc_loss = 0.1044572051481
Trained batch 279 in epoch 9, gen_loss = 0.41084720300776617, disc_loss = 0.10441070182381997
Trained batch 280 in epoch 9, gen_loss = 0.41030185131415775, disc_loss = 0.10431463379426147
Trained batch 281 in epoch 9, gen_loss = 0.41039880740304363, disc_loss = 0.10413206180438717
Trained batch 282 in epoch 9, gen_loss = 0.4100793723293412, disc_loss = 0.10401028954808998
Trained batch 283 in epoch 9, gen_loss = 0.4102162484761695, disc_loss = 0.104579368232369
Trained batch 284 in epoch 9, gen_loss = 0.4101891130731817, disc_loss = 0.10490821345725604
Trained batch 285 in epoch 9, gen_loss = 0.410348240103755, disc_loss = 0.10477097657463559
Trained batch 286 in epoch 9, gen_loss = 0.4104253616482539, disc_loss = 0.10520262696264306
Trained batch 287 in epoch 9, gen_loss = 0.4108230293624931, disc_loss = 0.10525232951234405
Trained batch 288 in epoch 9, gen_loss = 0.41087886783903443, disc_loss = 0.10567737197355209
Trained batch 289 in epoch 9, gen_loss = 0.4106958284460265, disc_loss = 0.10545449635206626
Trained batch 290 in epoch 9, gen_loss = 0.41094291128243776, disc_loss = 0.10542031572779634
Trained batch 291 in epoch 9, gen_loss = 0.41082426762744173, disc_loss = 0.10529502305801805
Trained batch 292 in epoch 9, gen_loss = 0.410636023856674, disc_loss = 0.10529793608844687
Trained batch 293 in epoch 9, gen_loss = 0.4105872219922591, disc_loss = 0.10508331309902627
Trained batch 294 in epoch 9, gen_loss = 0.41040584505614586, disc_loss = 0.10492861226074776
Trained batch 295 in epoch 9, gen_loss = 0.41028850726984645, disc_loss = 0.10479707334417145
Trained batch 296 in epoch 9, gen_loss = 0.41057246552171933, disc_loss = 0.10469963517579366
Trained batch 297 in epoch 9, gen_loss = 0.41056526697322027, disc_loss = 0.10480799424093241
Trained batch 298 in epoch 9, gen_loss = 0.410586783519158, disc_loss = 0.10489835202021144
Trained batch 299 in epoch 9, gen_loss = 0.4103977306683858, disc_loss = 0.10476888679588835
Trained batch 300 in epoch 9, gen_loss = 0.410452436173081, disc_loss = 0.10452716638553776
Trained batch 301 in epoch 9, gen_loss = 0.4104066024355541, disc_loss = 0.10460399828283795
Trained batch 302 in epoch 9, gen_loss = 0.4104380526951831, disc_loss = 0.10467938441328287
Trained batch 303 in epoch 9, gen_loss = 0.41051796411997393, disc_loss = 0.10502255361796797
Trained batch 304 in epoch 9, gen_loss = 0.4106361264088115, disc_loss = 0.10489543900504464
Trained batch 305 in epoch 9, gen_loss = 0.41070783781070336, disc_loss = 0.10530668793526156
Trained batch 306 in epoch 9, gen_loss = 0.41068057060630003, disc_loss = 0.10518750457960736
Trained batch 307 in epoch 9, gen_loss = 0.41070873609610964, disc_loss = 0.10507695964090043
Trained batch 308 in epoch 9, gen_loss = 0.4104879603609684, disc_loss = 0.10512399115873965
Trained batch 309 in epoch 9, gen_loss = 0.4103277471757704, disc_loss = 0.1050299465355854
Trained batch 310 in epoch 9, gen_loss = 0.4103284104460689, disc_loss = 0.10498607383256364
Trained batch 311 in epoch 9, gen_loss = 0.4103908749918143, disc_loss = 0.1050884349641796
Trained batch 312 in epoch 9, gen_loss = 0.4102752535297467, disc_loss = 0.10495663862139844
Trained batch 313 in epoch 9, gen_loss = 0.4101889347005042, disc_loss = 0.10482903756794466
Trained batch 314 in epoch 9, gen_loss = 0.4104936581755441, disc_loss = 0.1047102100260201
Trained batch 315 in epoch 9, gen_loss = 0.41062498998038377, disc_loss = 0.10450520042825161
Trained batch 316 in epoch 9, gen_loss = 0.41056304502562396, disc_loss = 0.10478791145002617
Trained batch 317 in epoch 9, gen_loss = 0.4105092189596884, disc_loss = 0.10522980853891785
Trained batch 318 in epoch 9, gen_loss = 0.4104123808747175, disc_loss = 0.10516163577737292
Trained batch 319 in epoch 9, gen_loss = 0.4101384900510311, disc_loss = 0.10518823924358003
Trained batch 320 in epoch 9, gen_loss = 0.41033121432842123, disc_loss = 0.10586169841945914
Trained batch 321 in epoch 9, gen_loss = 0.4099445742849978, disc_loss = 0.10661138359873747
Trained batch 322 in epoch 9, gen_loss = 0.41000546427334056, disc_loss = 0.10640342884780638
Trained batch 323 in epoch 9, gen_loss = 0.4099413472929119, disc_loss = 0.10627814263312353
Trained batch 324 in epoch 9, gen_loss = 0.4102111603663518, disc_loss = 0.10622828140281713
Trained batch 325 in epoch 9, gen_loss = 0.41002928067935757, disc_loss = 0.10634902097353358
Trained batch 326 in epoch 9, gen_loss = 0.410053489587358, disc_loss = 0.10638607758743865
Trained batch 327 in epoch 9, gen_loss = 0.41019149760647516, disc_loss = 0.10667642208792996
Trained batch 328 in epoch 9, gen_loss = 0.4099699129268391, disc_loss = 0.10700098140374686
Trained batch 329 in epoch 9, gen_loss = 0.4094813979484818, disc_loss = 0.1071176530567534
Trained batch 330 in epoch 9, gen_loss = 0.4095190781931142, disc_loss = 0.10725564285099866
Trained batch 331 in epoch 9, gen_loss = 0.4094782791672701, disc_loss = 0.10715711480904236
Trained batch 332 in epoch 9, gen_loss = 0.4091874715891686, disc_loss = 0.10725858221921297
Trained batch 333 in epoch 9, gen_loss = 0.40926062574465116, disc_loss = 0.10734690543442607
Trained batch 334 in epoch 9, gen_loss = 0.409602798410316, disc_loss = 0.10713828687013975
Trained batch 335 in epoch 9, gen_loss = 0.4095823737748322, disc_loss = 0.10706244054849126
Trained batch 336 in epoch 9, gen_loss = 0.40959126168436394, disc_loss = 0.10704784215226194
Trained batch 337 in epoch 9, gen_loss = 0.4095261550602123, disc_loss = 0.10709997707944827
Trained batch 338 in epoch 9, gen_loss = 0.4092147138881824, disc_loss = 0.10716988274327598
Trained batch 339 in epoch 9, gen_loss = 0.40927064361817694, disc_loss = 0.10738570515395088
Trained batch 340 in epoch 9, gen_loss = 0.4089612831905091, disc_loss = 0.10784723734772625
Trained batch 341 in epoch 9, gen_loss = 0.40894471496692175, disc_loss = 0.10772147897238794
Trained batch 342 in epoch 9, gen_loss = 0.40887601777867744, disc_loss = 0.10769640843848272
Trained batch 343 in epoch 9, gen_loss = 0.4089344363486351, disc_loss = 0.10776190689851552
Trained batch 344 in epoch 9, gen_loss = 0.4086262317239374, disc_loss = 0.10800993352372577
Trained batch 345 in epoch 9, gen_loss = 0.4085347011168568, disc_loss = 0.10803996931460035
Trained batch 346 in epoch 9, gen_loss = 0.40852237877138065, disc_loss = 0.10794078896321378
Trained batch 347 in epoch 9, gen_loss = 0.40858248599815644, disc_loss = 0.1077730667284936
Trained batch 348 in epoch 9, gen_loss = 0.4085225224238754, disc_loss = 0.1077523753954295
Trained batch 349 in epoch 9, gen_loss = 0.40870038121938707, disc_loss = 0.10763975935855082
Trained batch 350 in epoch 9, gen_loss = 0.4089631076976445, disc_loss = 0.1075152667594856
Trained batch 351 in epoch 9, gen_loss = 0.40891667891463096, disc_loss = 0.10744042151120746
Trained batch 352 in epoch 9, gen_loss = 0.4093056774933007, disc_loss = 0.107199268885189
Trained batch 353 in epoch 9, gen_loss = 0.4093126282095909, disc_loss = 0.10721031192290244
Trained batch 354 in epoch 9, gen_loss = 0.40931853421137365, disc_loss = 0.10700004921412803
Trained batch 355 in epoch 9, gen_loss = 0.40915576766213674, disc_loss = 0.10706948830086864
Trained batch 356 in epoch 9, gen_loss = 0.4090003152103985, disc_loss = 0.10713178468268125
Trained batch 357 in epoch 9, gen_loss = 0.40906997029175307, disc_loss = 0.1071478244354272
Trained batch 358 in epoch 9, gen_loss = 0.4093206262107015, disc_loss = 0.10736876740678107
Trained batch 359 in epoch 9, gen_loss = 0.40927908656497797, disc_loss = 0.10733232405036688
Trained batch 360 in epoch 9, gen_loss = 0.4089305389703476, disc_loss = 0.10816828702212701
Trained batch 361 in epoch 9, gen_loss = 0.40909091498476363, disc_loss = 0.10805242224622168
Trained batch 362 in epoch 9, gen_loss = 0.4091273016262974, disc_loss = 0.10815035750879072
Trained batch 363 in epoch 9, gen_loss = 0.40915339583387744, disc_loss = 0.10816306968802934
Trained batch 364 in epoch 9, gen_loss = 0.40908467626734957, disc_loss = 0.10865643877689153
Trained batch 365 in epoch 9, gen_loss = 0.4092175258231945, disc_loss = 0.10882868670700678
Trained batch 366 in epoch 9, gen_loss = 0.4094861193232705, disc_loss = 0.10877909817877518
Trained batch 367 in epoch 9, gen_loss = 0.4093495977880514, disc_loss = 0.10866482685441556
Trained batch 368 in epoch 9, gen_loss = 0.4093457147438675, disc_loss = 0.10853766248155093
Trained batch 369 in epoch 9, gen_loss = 0.40922833902610317, disc_loss = 0.10852280122202795
Trained batch 370 in epoch 9, gen_loss = 0.409434887236662, disc_loss = 0.10846748556489894
Trained batch 371 in epoch 9, gen_loss = 0.4095678739249706, disc_loss = 0.10835418655907594
Trained batch 372 in epoch 9, gen_loss = 0.40954120377273406, disc_loss = 0.10811797701741192
Trained batch 373 in epoch 9, gen_loss = 0.4096177458205325, disc_loss = 0.10805525677029622
Trained batch 374 in epoch 9, gen_loss = 0.4096060026884079, disc_loss = 0.10816615619758765
Trained batch 375 in epoch 9, gen_loss = 0.4095775633654062, disc_loss = 0.1080665093440404
Trained batch 376 in epoch 9, gen_loss = 0.4094884812594725, disc_loss = 0.10795226863607646
Trained batch 377 in epoch 9, gen_loss = 0.4094841541357772, disc_loss = 0.10773437197699591
Trained batch 378 in epoch 9, gen_loss = 0.4094693669779005, disc_loss = 0.10766157588004908
Trained batch 379 in epoch 9, gen_loss = 0.40930734453232664, disc_loss = 0.10750582250031201
Trained batch 380 in epoch 9, gen_loss = 0.4092549599140022, disc_loss = 0.10764504120907602
Trained batch 381 in epoch 9, gen_loss = 0.4090802378913495, disc_loss = 0.10757092451335404
Trained batch 382 in epoch 9, gen_loss = 0.40880108467125703, disc_loss = 0.10750927122956623
Trained batch 383 in epoch 9, gen_loss = 0.4089001019407685, disc_loss = 0.10742082464760945
Trained batch 384 in epoch 9, gen_loss = 0.4090924812214715, disc_loss = 0.10735282081771981
Trained batch 385 in epoch 9, gen_loss = 0.40902963462116804, disc_loss = 0.1072591010317052
Trained batch 386 in epoch 9, gen_loss = 0.40881524741341596, disc_loss = 0.10717432289949837
Trained batch 387 in epoch 9, gen_loss = 0.40880556101190674, disc_loss = 0.10711635353965397
Trained batch 388 in epoch 9, gen_loss = 0.4088575773726392, disc_loss = 0.1071556505524484
Trained batch 389 in epoch 9, gen_loss = 0.40901943303835697, disc_loss = 0.10705051764559287
Trained batch 390 in epoch 9, gen_loss = 0.40908355020043796, disc_loss = 0.10685165317448052
Trained batch 391 in epoch 9, gen_loss = 0.4089483743799584, disc_loss = 0.10691026510309656
Trained batch 392 in epoch 9, gen_loss = 0.4089009383783389, disc_loss = 0.10698063655948366
Trained batch 393 in epoch 9, gen_loss = 0.4091167737006536, disc_loss = 0.107193493823223
Trained batch 394 in epoch 9, gen_loss = 0.4088806920790974, disc_loss = 0.10724028744557991
Trained batch 395 in epoch 9, gen_loss = 0.4089146844591155, disc_loss = 0.10725502654289205
Trained batch 396 in epoch 9, gen_loss = 0.40909447143750466, disc_loss = 0.10711807085280906
Trained batch 397 in epoch 9, gen_loss = 0.4093430254552233, disc_loss = 0.10693290847910558
Trained batch 398 in epoch 9, gen_loss = 0.40938871378139746, disc_loss = 0.10690245257788583
Trained batch 399 in epoch 9, gen_loss = 0.4094803847000003, disc_loss = 0.10688576025422662
Trained batch 400 in epoch 9, gen_loss = 0.4093139012927129, disc_loss = 0.10673392823713825
Trained batch 401 in epoch 9, gen_loss = 0.40928168628198, disc_loss = 0.10664803523162555
Trained batch 402 in epoch 9, gen_loss = 0.4095779371542611, disc_loss = 0.10664456671857213
Trained batch 403 in epoch 9, gen_loss = 0.4095574507840199, disc_loss = 0.1065467572955433
Trained batch 404 in epoch 9, gen_loss = 0.40955771483756875, disc_loss = 0.10682919350579197
Trained batch 405 in epoch 9, gen_loss = 0.4095187129572107, disc_loss = 0.10675708829824414
Trained batch 406 in epoch 9, gen_loss = 0.40939012605523006, disc_loss = 0.10664418644983441
Trained batch 407 in epoch 9, gen_loss = 0.4094038712700792, disc_loss = 0.10653277213100855
Trained batch 408 in epoch 9, gen_loss = 0.4095067275838339, disc_loss = 0.10642770466948051
Trained batch 409 in epoch 9, gen_loss = 0.4095004699942542, disc_loss = 0.10626868819590748
Trained batch 410 in epoch 9, gen_loss = 0.409833231002745, disc_loss = 0.1064426896735627
Trained batch 411 in epoch 9, gen_loss = 0.409708432021361, disc_loss = 0.10659987207737218
Trained batch 412 in epoch 9, gen_loss = 0.40981131947213745, disc_loss = 0.10650086541351192
Trained batch 413 in epoch 9, gen_loss = 0.4098559826396514, disc_loss = 0.10644082272884206
Trained batch 414 in epoch 9, gen_loss = 0.40978840585932674, disc_loss = 0.10637112706450813
Trained batch 415 in epoch 9, gen_loss = 0.4099604656131795, disc_loss = 0.10649706825810987
Trained batch 416 in epoch 9, gen_loss = 0.41014014770515816, disc_loss = 0.10637983497080328
Trained batch 417 in epoch 9, gen_loss = 0.4102136191497579, disc_loss = 0.10626235427379466
Trained batch 418 in epoch 9, gen_loss = 0.41024509516849156, disc_loss = 0.10614645982112264
Trained batch 419 in epoch 9, gen_loss = 0.4101174980047203, disc_loss = 0.10607260594676649
Trained batch 420 in epoch 9, gen_loss = 0.4104105001603056, disc_loss = 0.10630446925069119
Trained batch 421 in epoch 9, gen_loss = 0.4103146798167184, disc_loss = 0.10643727813904744
Trained batch 422 in epoch 9, gen_loss = 0.4103643014569091, disc_loss = 0.10634802985962824
Trained batch 423 in epoch 9, gen_loss = 0.4105496742182745, disc_loss = 0.10618086982043987
Trained batch 424 in epoch 9, gen_loss = 0.41048771980930776, disc_loss = 0.10627240998341757
Trained batch 425 in epoch 9, gen_loss = 0.41055378999928355, disc_loss = 0.10615566581435187
Trained batch 426 in epoch 9, gen_loss = 0.41046695278595424, disc_loss = 0.10607180277221516
Trained batch 427 in epoch 9, gen_loss = 0.4104441051658626, disc_loss = 0.10589888823766992
Trained batch 428 in epoch 9, gen_loss = 0.41033973418054603, disc_loss = 0.10600839912596144
Trained batch 429 in epoch 9, gen_loss = 0.410377116085485, disc_loss = 0.10586336155876863
Trained batch 430 in epoch 9, gen_loss = 0.4104182660372241, disc_loss = 0.10606509946252105
Trained batch 431 in epoch 9, gen_loss = 0.41028929760472643, disc_loss = 0.10598937568203029
Trained batch 432 in epoch 9, gen_loss = 0.41033329413752084, disc_loss = 0.10596002832347609
Trained batch 433 in epoch 9, gen_loss = 0.4105160386400289, disc_loss = 0.10592819035722775
Trained batch 434 in epoch 9, gen_loss = 0.41050391337652314, disc_loss = 0.10580365020225103
Trained batch 435 in epoch 9, gen_loss = 0.41067232611939447, disc_loss = 0.1056394925161581
Trained batch 436 in epoch 9, gen_loss = 0.41076256532554495, disc_loss = 0.10556658951126602
Trained batch 437 in epoch 9, gen_loss = 0.411061626012739, disc_loss = 0.10545640027567268
Trained batch 438 in epoch 9, gen_loss = 0.4111656175591136, disc_loss = 0.10556313158320539
Trained batch 439 in epoch 9, gen_loss = 0.4111234622584148, disc_loss = 0.10550508530048484
Trained batch 440 in epoch 9, gen_loss = 0.41110471853999053, disc_loss = 0.10563008632941716
Trained batch 441 in epoch 9, gen_loss = 0.41100225482995695, disc_loss = 0.10568336529311687
Trained batch 442 in epoch 9, gen_loss = 0.4113909912634111, disc_loss = 0.10559212413467214
Trained batch 443 in epoch 9, gen_loss = 0.41125237924961355, disc_loss = 0.10561646056688719
Trained batch 444 in epoch 9, gen_loss = 0.4112894548793857, disc_loss = 0.10550875701010227
Trained batch 445 in epoch 9, gen_loss = 0.41123693904133657, disc_loss = 0.10544065256172899
Trained batch 446 in epoch 9, gen_loss = 0.4112609145825341, disc_loss = 0.10550611744941081
Trained batch 447 in epoch 9, gen_loss = 0.41136818282705334, disc_loss = 0.10561270526626945
Trained batch 448 in epoch 9, gen_loss = 0.4112611400722661, disc_loss = 0.1054864643485947
Trained batch 449 in epoch 9, gen_loss = 0.411564138299889, disc_loss = 0.10552729068944852
Trained batch 450 in epoch 9, gen_loss = 0.4114342913064618, disc_loss = 0.10546642867745026
Trained batch 451 in epoch 9, gen_loss = 0.4114816775298224, disc_loss = 0.10559197016208705
Trained batch 452 in epoch 9, gen_loss = 0.4115139316709889, disc_loss = 0.10566972471181525
Trained batch 453 in epoch 9, gen_loss = 0.411498570396249, disc_loss = 0.10574853681602273
Trained batch 454 in epoch 9, gen_loss = 0.41145704902790403, disc_loss = 0.10579616570292594
Trained batch 455 in epoch 9, gen_loss = 0.4115738257308278, disc_loss = 0.10568053368887488
Trained batch 456 in epoch 9, gen_loss = 0.411521434816542, disc_loss = 0.10553410871431264
Trained batch 457 in epoch 9, gen_loss = 0.41137316988935635, disc_loss = 0.10545794703635716
Testing Epoch 9

wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.8801459074020386, disc_loss = 0.5669503211975098
Trained batch 1 in epoch 0, gen_loss = 0.9506948590278625, disc_loss = 0.6214798092842102
Trained batch 2 in epoch 0, gen_loss = 0.9243876536687216, disc_loss = 0.5917877356211344
Trained batch 3 in epoch 0, gen_loss = 0.8618588894605637, disc_loss = 0.527338519692421
Trained batch 4 in epoch 0, gen_loss = 0.8533747315406799, disc_loss = 0.4950055956840515
Trained batch 5 in epoch 0, gen_loss = 0.8529545168081919, disc_loss = 0.4664345135291417
Trained batch 6 in epoch 0, gen_loss = 0.8467619163649422, disc_loss = 0.43535782183919636
Trained batch 7 in epoch 0, gen_loss = 0.8538198918104172, disc_loss = 0.4105488732457161
Trained batch 8 in epoch 0, gen_loss = 0.8492307530509101, disc_loss = 0.38936379220750594
Trained batch 9 in epoch 0, gen_loss = 0.8472797274589539, disc_loss = 0.37354577630758284
Trained batch 10 in epoch 0, gen_loss = 0.8374537229537964, disc_loss = 0.3590647998181256
Trained batch 11 in epoch 0, gen_loss = 0.8425906946261724, disc_loss = 0.34464967126647633
Trained batch 12 in epoch 0, gen_loss = 0.8383540556981013, disc_loss = 0.332163094328
Trained batch 13 in epoch 0, gen_loss = 0.8422984778881073, disc_loss = 0.3208025342651776
Trained batch 14 in epoch 0, gen_loss = 0.8356239597002665, disc_loss = 0.3127147575219472
Trained batch 15 in epoch 0, gen_loss = 0.8357326649129391, disc_loss = 0.3079108214005828
Trained batch 16 in epoch 0, gen_loss = 0.8251145306755515, disc_loss = 0.308033304179416
Trained batch 17 in epoch 0, gen_loss = 0.8219108151064979, disc_loss = 0.30382929576767814
Trained batch 18 in epoch 0, gen_loss = 0.8171313342295194, disc_loss = 0.2999642593295951
Trained batch 19 in epoch 0, gen_loss = 0.8129043966531754, disc_loss = 0.2961852513253689
Trained batch 20 in epoch 0, gen_loss = 0.8068662342571077, disc_loss = 0.29327414078371866
Trained batch 21 in epoch 0, gen_loss = 0.8075393275781111, disc_loss = 0.2889464389194142
Trained batch 22 in epoch 0, gen_loss = 0.8079621688179348, disc_loss = 0.28665752255398297
Trained batch 23 in epoch 0, gen_loss = 0.8044663419326147, disc_loss = 0.2908107067147891
Trained batch 24 in epoch 0, gen_loss = 0.8098727536201477, disc_loss = 0.2919479250907898
Trained batch 25 in epoch 0, gen_loss = 0.8213991912511679, disc_loss = 0.2914071839589339
Trained batch 26 in epoch 0, gen_loss = 0.8219586566642478, disc_loss = 0.2885403136412303
Trained batch 27 in epoch 0, gen_loss = 0.8203315990311759, disc_loss = 0.28636413120797705
Trained batch 28 in epoch 0, gen_loss = 0.8208252828696678, disc_loss = 0.2830240587735998
Trained batch 29 in epoch 0, gen_loss = 0.8267915308475494, disc_loss = 0.2794562682509422
Trained batch 30 in epoch 0, gen_loss = 0.8286383632690676, disc_loss = 0.2763411229656589
Trained batch 31 in epoch 0, gen_loss = 0.8291069027036428, disc_loss = 0.27293406147509813
Trained batch 32 in epoch 0, gen_loss = 0.8235252680200519, disc_loss = 0.27158085866407916
Trained batch 33 in epoch 0, gen_loss = 0.8274209779851577, disc_loss = 0.2701230987029917
Trained batch 34 in epoch 0, gen_loss = 0.8263245803969247, disc_loss = 0.2709201727594648
Trained batch 35 in epoch 0, gen_loss = 0.8282616403367784, disc_loss = 0.26836686126059955
Trained batch 36 in epoch 0, gen_loss = 0.8304107801334278, disc_loss = 0.26618563444227783
Trained batch 37 in epoch 0, gen_loss = 0.82794420656405, disc_loss = 0.26514910279135956
Trained batch 38 in epoch 0, gen_loss = 0.8294855172817523, disc_loss = 0.2641077125683809
Trained batch 39 in epoch 0, gen_loss = 0.827886575460434, disc_loss = 0.263440266251564
Trained batch 40 in epoch 0, gen_loss = 0.8242022336983099, disc_loss = 0.2630916012496483
Trained batch 41 in epoch 0, gen_loss = 0.8260286123979659, disc_loss = 0.26156976641643614
Trained batch 42 in epoch 0, gen_loss = 0.8234251723733059, disc_loss = 0.25974743761295493
Trained batch 43 in epoch 0, gen_loss = 0.819995634935119, disc_loss = 0.25928741320967674
Trained batch 44 in epoch 0, gen_loss = 0.8132037242253621, disc_loss = 0.2601502647002538
Trained batch 45 in epoch 0, gen_loss = 0.8158643323442211, disc_loss = 0.2604111462183621
Trained batch 46 in epoch 0, gen_loss = 0.8143160038806022, disc_loss = 0.2610080575055264
Trained batch 47 in epoch 0, gen_loss = 0.8140839412808418, disc_loss = 0.2616030185793837
Trained batch 48 in epoch 0, gen_loss = 0.8140287326306713, disc_loss = 0.26077692910116546
Trained batch 49 in epoch 0, gen_loss = 0.8124381959438324, disc_loss = 0.25994978308677674
Trained batch 50 in epoch 0, gen_loss = 0.8086543246811512, disc_loss = 0.2598842709672217
Trained batch 51 in epoch 0, gen_loss = 0.8084952567632382, disc_loss = 0.2589208879149877
Trained batch 52 in epoch 0, gen_loss = 0.8087838314614206, disc_loss = 0.25913333499206687
Trained batch 53 in epoch 0, gen_loss = 0.805496213612733, disc_loss = 0.2610719292252152
Trained batch 54 in epoch 0, gen_loss = 0.8061536832289262, disc_loss = 0.2603592818433588
Trained batch 55 in epoch 0, gen_loss = 0.8076347421322551, disc_loss = 0.26101565999644144
Trained batch 56 in epoch 0, gen_loss = 0.806029058339303, disc_loss = 0.26116987226302163
Trained batch 57 in epoch 0, gen_loss = 0.8032786681734282, disc_loss = 0.26141826191852835
Trained batch 58 in epoch 0, gen_loss = 0.8037076440908141, disc_loss = 0.2611871715319359
Trained batch 59 in epoch 0, gen_loss = 0.8038397312164307, disc_loss = 0.2606544248759747
Trained batch 60 in epoch 0, gen_loss = 0.802850209298681, disc_loss = 0.26048452028485597
Trained batch 61 in epoch 0, gen_loss = 0.799461777171781, disc_loss = 0.26033694873894414
Trained batch 62 in epoch 0, gen_loss = 0.7971266347264486, disc_loss = 0.2598316047399763
Trained batch 63 in epoch 0, gen_loss = 0.796481198631227, disc_loss = 0.25917241419665515
Trained batch 64 in epoch 0, gen_loss = 0.7951300501823425, disc_loss = 0.2587775292304846
Trained batch 65 in epoch 0, gen_loss = 0.7961614935687094, disc_loss = 0.25850313043955603
Trained batch 66 in epoch 0, gen_loss = 0.7926506862711551, disc_loss = 0.2576738186736605
Trained batch 67 in epoch 0, gen_loss = 0.7932954702307197, disc_loss = 0.2568299167734735
Trained batch 68 in epoch 0, gen_loss = 0.792404642139656, disc_loss = 0.25600690491821454
Trained batch 69 in epoch 0, gen_loss = 0.7914041348866054, disc_loss = 0.2554449236818722
Trained batch 70 in epoch 0, gen_loss = 0.7906557145253034, disc_loss = 0.2548867726409939
Trained batch 71 in epoch 0, gen_loss = 0.7902280978030629, disc_loss = 0.25456941769354874
Trained batch 72 in epoch 0, gen_loss = 0.7914671930548263, disc_loss = 0.2541893347077174
Trained batch 73 in epoch 0, gen_loss = 0.7884834102682166, disc_loss = 0.2561041936278343
Trained batch 74 in epoch 0, gen_loss = 0.788126060962677, disc_loss = 0.25599519491195677
Trained batch 75 in epoch 0, gen_loss = 0.7904667940578962, disc_loss = 0.2560788585167182
Trained batch 76 in epoch 0, gen_loss = 0.7886710298525823, disc_loss = 0.2559409307969081
Trained batch 77 in epoch 0, gen_loss = 0.7883116793938172, disc_loss = 0.25598761706780165
Trained batch 78 in epoch 0, gen_loss = 0.7890871257721623, disc_loss = 0.25562445762791214
Trained batch 79 in epoch 0, gen_loss = 0.788333785533905, disc_loss = 0.2553466772660613
Trained batch 80 in epoch 0, gen_loss = 0.7873448177620217, disc_loss = 0.2553016504755727
Trained batch 81 in epoch 0, gen_loss = 0.7867474992100786, disc_loss = 0.2551105267754415
Trained batch 82 in epoch 0, gen_loss = 0.7855437390775566, disc_loss = 0.2550585918038724
Trained batch 83 in epoch 0, gen_loss = 0.7838772095385051, disc_loss = 0.25460498638096307
Trained batch 84 in epoch 0, gen_loss = 0.7822113261503332, disc_loss = 0.25440069156534534
Trained batch 85 in epoch 0, gen_loss = 0.7826186487841051, disc_loss = 0.2545064355051795
Trained batch 86 in epoch 0, gen_loss = 0.7813538840447349, disc_loss = 0.2551907153650262
Trained batch 87 in epoch 0, gen_loss = 0.7803404168649153, disc_loss = 0.2549826363948258
Trained batch 88 in epoch 0, gen_loss = 0.7804906220918291, disc_loss = 0.25471722995967006
Trained batch 89 in epoch 0, gen_loss = 0.7785851803090837, disc_loss = 0.2544645032948918
Trained batch 90 in epoch 0, gen_loss = 0.7776584042297615, disc_loss = 0.2539400545122859
Trained batch 91 in epoch 0, gen_loss = 0.7788468864948853, disc_loss = 0.2535125838349695
Trained batch 92 in epoch 0, gen_loss = 0.7784783231314792, disc_loss = 0.25316704200801027
Trained batch 93 in epoch 0, gen_loss = 0.7774142420038264, disc_loss = 0.25310766681077634
Trained batch 94 in epoch 0, gen_loss = 0.7743503843483172, disc_loss = 0.25359470263907785
Trained batch 95 in epoch 0, gen_loss = 0.7720772304261724, disc_loss = 0.25363307089234394
Trained batch 96 in epoch 0, gen_loss = 0.7717468207029953, disc_loss = 0.25367951900074165
Trained batch 97 in epoch 0, gen_loss = 0.7714555157082421, disc_loss = 0.2535185815424335
Trained batch 98 in epoch 0, gen_loss = 0.7698290284835931, disc_loss = 0.2532453562575157
Trained batch 99 in epoch 0, gen_loss = 0.7705715784430504, disc_loss = 0.2533921630680561
Trained batch 100 in epoch 0, gen_loss = 0.7706687299921962, disc_loss = 0.2536391410792228
Trained batch 101 in epoch 0, gen_loss = 0.7701174906071495, disc_loss = 0.2534460847576459
Trained batch 102 in epoch 0, gen_loss = 0.7710164788278561, disc_loss = 0.25319714323409553
Trained batch 103 in epoch 0, gen_loss = 0.7696320726894416, disc_loss = 0.25311511654693347
Trained batch 104 in epoch 0, gen_loss = 0.7687984054996854, disc_loss = 0.2528330611331122
Trained batch 105 in epoch 0, gen_loss = 0.7689679869503345, disc_loss = 0.2525224001058992
Trained batch 106 in epoch 0, gen_loss = 0.7691406693971046, disc_loss = 0.25200410173318094
Trained batch 107 in epoch 0, gen_loss = 0.7676627440033136, disc_loss = 0.2517771988555237
Trained batch 108 in epoch 0, gen_loss = 0.7666876351614611, disc_loss = 0.2514119729262973
Trained batch 109 in epoch 0, gen_loss = 0.7670056589625098, disc_loss = 0.25108632811091164
Trained batch 110 in epoch 0, gen_loss = 0.7650271141314292, disc_loss = 0.2511548981204763
Trained batch 111 in epoch 0, gen_loss = 0.7634550335683993, disc_loss = 0.25103024007486446
Trained batch 112 in epoch 0, gen_loss = 0.7626586385005343, disc_loss = 0.25129596414291755
Trained batch 113 in epoch 0, gen_loss = 0.7604648358466333, disc_loss = 0.2520582766125077
Trained batch 114 in epoch 0, gen_loss = 0.7595183012278184, disc_loss = 0.2517589453769767
Trained batch 115 in epoch 0, gen_loss = 0.7599174675756487, disc_loss = 0.2514933131892106
Trained batch 116 in epoch 0, gen_loss = 0.7590810394185221, disc_loss = 0.2514072362429056
Trained batch 117 in epoch 0, gen_loss = 0.7607474415484121, disc_loss = 0.25123980237265764
Trained batch 118 in epoch 0, gen_loss = 0.7600042827489997, disc_loss = 0.2512761204182601
Trained batch 119 in epoch 0, gen_loss = 0.7587835945188999, disc_loss = 0.25115455960234007
Trained batch 120 in epoch 0, gen_loss = 0.7580255415321382, disc_loss = 0.2509530093059067
Trained batch 121 in epoch 0, gen_loss = 0.7570323306517522, disc_loss = 0.2509433624685788
Trained batch 122 in epoch 0, gen_loss = 0.7567382854659382, disc_loss = 0.2507802479393114
Trained batch 123 in epoch 0, gen_loss = 0.7561343905906523, disc_loss = 0.2505280514878611
Trained batch 124 in epoch 0, gen_loss = 0.7548181445598602, disc_loss = 0.25046745359897615
Trained batch 125 in epoch 0, gen_loss = 0.7561454557710223, disc_loss = 0.2506178424708427
Trained batch 126 in epoch 0, gen_loss = 0.7548455612396631, disc_loss = 0.25126531168701144
Trained batch 127 in epoch 0, gen_loss = 0.7540629741270095, disc_loss = 0.25095060386229306
Trained batch 128 in epoch 0, gen_loss = 0.7536047440628673, disc_loss = 0.2506146288888399
Trained batch 129 in epoch 0, gen_loss = 0.7537131788638922, disc_loss = 0.25027045894127625
Trained batch 130 in epoch 0, gen_loss = 0.753742725112056, disc_loss = 0.25006795395876613
Trained batch 131 in epoch 0, gen_loss = 0.7528543086214499, disc_loss = 0.24992182275111025
Trained batch 132 in epoch 0, gen_loss = 0.7526946038679969, disc_loss = 0.24977732108051615
Trained batch 133 in epoch 0, gen_loss = 0.7521561319703487, disc_loss = 0.24948636698189067
Trained batch 134 in epoch 0, gen_loss = 0.7518757897394674, disc_loss = 0.24891435669528114
Trained batch 135 in epoch 0, gen_loss = 0.7512757328941542, disc_loss = 0.24844467190696912
Trained batch 136 in epoch 0, gen_loss = 0.7502479333512104, disc_loss = 0.2484234936916045
Trained batch 137 in epoch 0, gen_loss = 0.7512194520753362, disc_loss = 0.24831103436324908
Trained batch 138 in epoch 0, gen_loss = 0.7502589751061776, disc_loss = 0.24853073821650992
Trained batch 139 in epoch 0, gen_loss = 0.7493351453116962, disc_loss = 0.24836063395653452
Trained batch 140 in epoch 0, gen_loss = 0.748851865952742, disc_loss = 0.24826839967822353
Trained batch 141 in epoch 0, gen_loss = 0.7491666462639688, disc_loss = 0.24791781058613682
Trained batch 142 in epoch 0, gen_loss = 0.7485304714499653, disc_loss = 0.24742204461481188
Trained batch 143 in epoch 0, gen_loss = 0.7474103195385801, disc_loss = 0.24703333413021433
Trained batch 144 in epoch 0, gen_loss = 0.7469488199414878, disc_loss = 0.24663689516741655
Trained batch 145 in epoch 0, gen_loss = 0.7466491560821664, disc_loss = 0.2463958692060758
Trained batch 146 in epoch 0, gen_loss = 0.7458691858515447, disc_loss = 0.2461379912434792
Trained batch 147 in epoch 0, gen_loss = 0.745718749189699, disc_loss = 0.24597345695302292
Trained batch 148 in epoch 0, gen_loss = 0.7452974633482479, disc_loss = 0.2457059728819252
Trained batch 149 in epoch 0, gen_loss = 0.7453485053777694, disc_loss = 0.2451404897371928
Trained batch 150 in epoch 0, gen_loss = 0.7451188921533674, disc_loss = 0.2446089775751758
Trained batch 151 in epoch 0, gen_loss = 0.7461475967184493, disc_loss = 0.24474307639818443
Trained batch 152 in epoch 0, gen_loss = 0.745337661769655, disc_loss = 0.24631383839775534
Trained batch 153 in epoch 0, gen_loss = 0.7449071947243306, disc_loss = 0.24574824335513176
Trained batch 154 in epoch 0, gen_loss = 0.7447622251126074, disc_loss = 0.24569157679234782
Trained batch 155 in epoch 0, gen_loss = 0.7465076436981176, disc_loss = 0.24600615992377967
Trained batch 156 in epoch 0, gen_loss = 0.745481525826606, disc_loss = 0.24630494738460346
Trained batch 157 in epoch 0, gen_loss = 0.7448569262706781, disc_loss = 0.24626240407741523
Trained batch 158 in epoch 0, gen_loss = 0.7449337572046796, disc_loss = 0.24621499400093871
Trained batch 159 in epoch 0, gen_loss = 0.744152813591063, disc_loss = 0.24608389334753156
Trained batch 160 in epoch 0, gen_loss = 0.7435613317149026, disc_loss = 0.24601921994493614
Trained batch 161 in epoch 0, gen_loss = 0.7428718122803135, disc_loss = 0.24581130502032644
Trained batch 162 in epoch 0, gen_loss = 0.7428034187460238, disc_loss = 0.24564508481259725
Trained batch 163 in epoch 0, gen_loss = 0.7416453486899051, disc_loss = 0.2455211456229047
Trained batch 164 in epoch 0, gen_loss = 0.7407452097444823, disc_loss = 0.24549601619893854
Trained batch 165 in epoch 0, gen_loss = 0.7409133758530559, disc_loss = 0.24567754063979688
Trained batch 166 in epoch 0, gen_loss = 0.7399565118872476, disc_loss = 0.24569887217290387
Trained batch 167 in epoch 0, gen_loss = 0.7393293474756536, disc_loss = 0.24561232115541184
Trained batch 168 in epoch 0, gen_loss = 0.7395687126196347, disc_loss = 0.24548373428674844
Trained batch 169 in epoch 0, gen_loss = 0.7399132982772939, disc_loss = 0.245239698360948
Trained batch 170 in epoch 0, gen_loss = 0.7390638365034472, disc_loss = 0.24496108005967057
Trained batch 171 in epoch 0, gen_loss = 0.7390315108174501, disc_loss = 0.24456614749722702
Trained batch 172 in epoch 0, gen_loss = 0.7383541397621177, disc_loss = 0.24441994614683824
Trained batch 173 in epoch 0, gen_loss = 0.7371976356739285, disc_loss = 0.244423633591197
Trained batch 174 in epoch 0, gen_loss = 0.7377847506318773, disc_loss = 0.2442241985457284
Trained batch 175 in epoch 0, gen_loss = 0.7371927948499267, disc_loss = 0.24409385973756964
Trained batch 176 in epoch 0, gen_loss = 0.736892685209964, disc_loss = 0.2438654525805328
Trained batch 177 in epoch 0, gen_loss = 0.7362181860744283, disc_loss = 0.2435221690475271
Trained batch 178 in epoch 0, gen_loss = 0.7363923210338508, disc_loss = 0.24315733982864038
Trained batch 179 in epoch 0, gen_loss = 0.7360143527388573, disc_loss = 0.2429855482445823
Trained batch 180 in epoch 0, gen_loss = 0.7357799820807758, disc_loss = 0.2424851112602824
Trained batch 181 in epoch 0, gen_loss = 0.7352009682537435, disc_loss = 0.24230346362014393
Trained batch 182 in epoch 0, gen_loss = 0.7355759930415232, disc_loss = 0.24198582980150735
Trained batch 183 in epoch 0, gen_loss = 0.7351028577465079, disc_loss = 0.24212473873858867
Trained batch 184 in epoch 0, gen_loss = 0.7359519476826126, disc_loss = 0.2427846130487081
Trained batch 185 in epoch 0, gen_loss = 0.7351966261543254, disc_loss = 0.2435258952199772
Trained batch 186 in epoch 0, gen_loss = 0.7344090283554505, disc_loss = 0.24355847360616062
Trained batch 187 in epoch 0, gen_loss = 0.7339093103370768, disc_loss = 0.24349832106777963
Trained batch 188 in epoch 0, gen_loss = 0.7334558886510355, disc_loss = 0.24337766291918578
Trained batch 189 in epoch 0, gen_loss = 0.7322486863324517, disc_loss = 0.24329209759047157
Trained batch 190 in epoch 0, gen_loss = 0.7315607793356111, disc_loss = 0.2432532227788296
Trained batch 191 in epoch 0, gen_loss = 0.7315558575404187, disc_loss = 0.24313863444452485
Trained batch 192 in epoch 0, gen_loss = 0.7310208139333083, disc_loss = 0.2430431149475315
Trained batch 193 in epoch 0, gen_loss = 0.730503768804147, disc_loss = 0.242956142910977
Trained batch 194 in epoch 0, gen_loss = 0.7302445816688049, disc_loss = 0.24277025293081234
Trained batch 195 in epoch 0, gen_loss = 0.7298320162357116, disc_loss = 0.24252101672547205
Trained batch 196 in epoch 0, gen_loss = 0.729219660389847, disc_loss = 0.2422135481374518
Trained batch 197 in epoch 0, gen_loss = 0.7292793650518764, disc_loss = 0.24193331915320773
Trained batch 198 in epoch 0, gen_loss = 0.7286333757728788, disc_loss = 0.24164493831258324
Trained batch 199 in epoch 0, gen_loss = 0.7280303703248501, disc_loss = 0.24149323284626006
Trained batch 200 in epoch 0, gen_loss = 0.7277936844979945, disc_loss = 0.24125368329719524
Trained batch 201 in epoch 0, gen_loss = 0.7273642779281824, disc_loss = 0.24099142052749595
Trained batch 202 in epoch 0, gen_loss = 0.7268075639097561, disc_loss = 0.24080058734111598
Trained batch 203 in epoch 0, gen_loss = 0.7271650768086022, disc_loss = 0.2408564719645416
Trained batch 204 in epoch 0, gen_loss = 0.7259334200766029, disc_loss = 0.24174513518810273
Trained batch 205 in epoch 0, gen_loss = 0.7264049385936515, disc_loss = 0.24164171777303936
Trained batch 206 in epoch 0, gen_loss = 0.7265819662435044, disc_loss = 0.24161691394980978
Trained batch 207 in epoch 0, gen_loss = 0.7259531376453546, disc_loss = 0.24159081158443138
Trained batch 208 in epoch 0, gen_loss = 0.7251703659313147, disc_loss = 0.24155016999210469
Trained batch 209 in epoch 0, gen_loss = 0.7251679582255227, disc_loss = 0.2416472205803508
Trained batch 210 in epoch 0, gen_loss = 0.7251108305714141, disc_loss = 0.2416796933559445
Trained batch 211 in epoch 0, gen_loss = 0.7252279812434934, disc_loss = 0.24158638750888267
Trained batch 212 in epoch 0, gen_loss = 0.7249936704904261, disc_loss = 0.24143496078784477
Trained batch 213 in epoch 0, gen_loss = 0.724696698032807, disc_loss = 0.241261799898103
Trained batch 214 in epoch 0, gen_loss = 0.7243121391118958, disc_loss = 0.24114123291747513
Trained batch 215 in epoch 0, gen_loss = 0.7234279896925997, disc_loss = 0.24114026874303818
Trained batch 216 in epoch 0, gen_loss = 0.7226673729958073, disc_loss = 0.24107385574397952
Trained batch 217 in epoch 0, gen_loss = 0.7221476028271772, disc_loss = 0.24095884232072656
Trained batch 218 in epoch 0, gen_loss = 0.7217725958998344, disc_loss = 0.24090673138289692
Trained batch 219 in epoch 0, gen_loss = 0.7220661147074265, disc_loss = 0.24068916297771714
Trained batch 220 in epoch 0, gen_loss = 0.7222203329138087, disc_loss = 0.24051605030152592
Trained batch 221 in epoch 0, gen_loss = 0.7218717776977264, disc_loss = 0.2404307530404211
Trained batch 222 in epoch 0, gen_loss = 0.7218211140867841, disc_loss = 0.24057588362105758
Trained batch 223 in epoch 0, gen_loss = 0.7209654421146426, disc_loss = 0.24079652270302176
Trained batch 224 in epoch 0, gen_loss = 0.7201274704933166, disc_loss = 0.24078512609004973
Trained batch 225 in epoch 0, gen_loss = 0.7202791935574692, disc_loss = 0.24075367156646948
Trained batch 226 in epoch 0, gen_loss = 0.719972545354902, disc_loss = 0.24074304372991234
Trained batch 227 in epoch 0, gen_loss = 0.7197645643824025, disc_loss = 0.240704716624398
Trained batch 228 in epoch 0, gen_loss = 0.7191659334445104, disc_loss = 0.24058621204315836
Trained batch 229 in epoch 0, gen_loss = 0.7192399281522502, disc_loss = 0.24044571149608363
Trained batch 230 in epoch 0, gen_loss = 0.7189968047720013, disc_loss = 0.24026405843563411
Trained batch 231 in epoch 0, gen_loss = 0.7188766919847193, disc_loss = 0.2400710285352222
Trained batch 232 in epoch 0, gen_loss = 0.7186684828459449, disc_loss = 0.2398429575012477
Trained batch 233 in epoch 0, gen_loss = 0.7182901906661499, disc_loss = 0.23972625323595145
Trained batch 234 in epoch 0, gen_loss = 0.7181354454223146, disc_loss = 0.2394959775057245
Trained batch 235 in epoch 0, gen_loss = 0.71815162038399, disc_loss = 0.23941305342872263
Trained batch 236 in epoch 0, gen_loss = 0.7177336009745859, disc_loss = 0.23950930650224161
Trained batch 237 in epoch 0, gen_loss = 0.7179681563577732, disc_loss = 0.23930070060892267
Trained batch 238 in epoch 0, gen_loss = 0.7171280404015066, disc_loss = 0.23920991499304273
Trained batch 239 in epoch 0, gen_loss = 0.7169209259251753, disc_loss = 0.23902716115117073
Trained batch 240 in epoch 0, gen_loss = 0.7170411204896032, disc_loss = 0.23879368510483706
Trained batch 241 in epoch 0, gen_loss = 0.7171973260966215, disc_loss = 0.23855692973314238
Trained batch 242 in epoch 0, gen_loss = 0.716784487535924, disc_loss = 0.23841368121865356
Trained batch 243 in epoch 0, gen_loss = 0.7159416856335812, disc_loss = 0.2388546458277546
Trained batch 244 in epoch 0, gen_loss = 0.7164663144520351, disc_loss = 0.2388076711065915
Trained batch 245 in epoch 0, gen_loss = 0.7164619550472353, disc_loss = 0.2383866941904634
Trained batch 246 in epoch 0, gen_loss = 0.7161750798283318, disc_loss = 0.23805054618038146
Trained batch 247 in epoch 0, gen_loss = 0.7157547272020771, disc_loss = 0.23787798546254635
Trained batch 248 in epoch 0, gen_loss = 0.7159893278137268, disc_loss = 0.23775774605542302
Trained batch 249 in epoch 0, gen_loss = 0.7153811285495758, disc_loss = 0.2375348774790764
Trained batch 250 in epoch 0, gen_loss = 0.7150806411803956, disc_loss = 0.23737005070148712
Trained batch 251 in epoch 0, gen_loss = 0.7153895667621067, disc_loss = 0.23724351675500946
Trained batch 252 in epoch 0, gen_loss = 0.7145863081155558, disc_loss = 0.23707752925133987
Trained batch 253 in epoch 0, gen_loss = 0.7146079012258785, disc_loss = 0.23693537049171493
Trained batch 254 in epoch 0, gen_loss = 0.7141997442525976, disc_loss = 0.23685914096879024
Trained batch 255 in epoch 0, gen_loss = 0.714439291274175, disc_loss = 0.23686122539220378
Trained batch 256 in epoch 0, gen_loss = 0.7144200804168612, disc_loss = 0.2365832743941578
Trained batch 257 in epoch 0, gen_loss = 0.7146652925384137, disc_loss = 0.2363015883421713
Trained batch 258 in epoch 0, gen_loss = 0.7156737649302685, disc_loss = 0.23618780433211087
Trained batch 259 in epoch 0, gen_loss = 0.7150771095202519, disc_loss = 0.23750100611494138
Trained batch 260 in epoch 0, gen_loss = 0.7143804689020032, disc_loss = 0.2372346407951523
Trained batch 261 in epoch 0, gen_loss = 0.7146085154919224, disc_loss = 0.23704935633044205
Trained batch 262 in epoch 0, gen_loss = 0.7143754455979786, disc_loss = 0.236896700732155
Trained batch 263 in epoch 0, gen_loss = 0.714186198332093, disc_loss = 0.23681802229222024
Trained batch 264 in epoch 0, gen_loss = 0.7140624975258449, disc_loss = 0.23668702317858642
Trained batch 265 in epoch 0, gen_loss = 0.7136201542571075, disc_loss = 0.23659764112610565
Trained batch 266 in epoch 0, gen_loss = 0.7138349016507467, disc_loss = 0.23640146818053856
Trained batch 267 in epoch 0, gen_loss = 0.7136350093937632, disc_loss = 0.2363618751292798
Trained batch 268 in epoch 0, gen_loss = 0.7135878404720122, disc_loss = 0.2362479243469061
Trained batch 269 in epoch 0, gen_loss = 0.7137126465638478, disc_loss = 0.23625218277728116
Trained batch 270 in epoch 0, gen_loss = 0.7127839680967296, disc_loss = 0.2367263799773811
Trained batch 271 in epoch 0, gen_loss = 0.712848270421519, disc_loss = 0.23671948159223094
Trained batch 272 in epoch 0, gen_loss = 0.7124102796827044, disc_loss = 0.23668041339505724
Trained batch 273 in epoch 0, gen_loss = 0.7122029157450599, disc_loss = 0.23660126029357423
Trained batch 274 in epoch 0, gen_loss = 0.7122988323731856, disc_loss = 0.23658031257716092
Trained batch 275 in epoch 0, gen_loss = 0.7117364587991134, disc_loss = 0.2365755888538948
Trained batch 276 in epoch 0, gen_loss = 0.7113095216372384, disc_loss = 0.2365155991987201
Trained batch 277 in epoch 0, gen_loss = 0.7110989942825098, disc_loss = 0.23644721277540537
Trained batch 278 in epoch 0, gen_loss = 0.7108217315434555, disc_loss = 0.23627632712164232
Trained batch 279 in epoch 0, gen_loss = 0.7104843320591109, disc_loss = 0.236192091394748
Trained batch 280 in epoch 0, gen_loss = 0.7102746333515941, disc_loss = 0.23606405356812732
Trained batch 281 in epoch 0, gen_loss = 0.7095885496612981, disc_loss = 0.23584210486910867
Trained batch 282 in epoch 0, gen_loss = 0.7092370578341265, disc_loss = 0.23572059786572475
Trained batch 283 in epoch 0, gen_loss = 0.7091621636924609, disc_loss = 0.23548206004878164
Trained batch 284 in epoch 0, gen_loss = 0.7093232976762872, disc_loss = 0.235370412521195
Trained batch 285 in epoch 0, gen_loss = 0.7089093237906903, disc_loss = 0.2356559241359884
Trained batch 286 in epoch 0, gen_loss = 0.7096073625395107, disc_loss = 0.23561676277516194
Trained batch 287 in epoch 0, gen_loss = 0.70928722123305, disc_loss = 0.23549111854905883
Trained batch 288 in epoch 0, gen_loss = 0.7086313191582175, disc_loss = 0.23549407962903018
Trained batch 289 in epoch 0, gen_loss = 0.708291041234444, disc_loss = 0.23545968681573867
Trained batch 290 in epoch 0, gen_loss = 0.707955914469519, disc_loss = 0.2353121902012743
Trained batch 291 in epoch 0, gen_loss = 0.7077993997564055, disc_loss = 0.23509320540175047
Trained batch 292 in epoch 0, gen_loss = 0.7078978679692786, disc_loss = 0.23474134387823503
Trained batch 293 in epoch 0, gen_loss = 0.707315524013675, disc_loss = 0.23448734471992572
Trained batch 294 in epoch 0, gen_loss = 0.7076009936251882, disc_loss = 0.23464357580168774
Trained batch 295 in epoch 0, gen_loss = 0.7071832799025484, disc_loss = 0.23426145972130266
Trained batch 296 in epoch 0, gen_loss = 0.7068853787701539, disc_loss = 0.23442704551649415
Trained batch 297 in epoch 0, gen_loss = 0.7075960672141721, disc_loss = 0.23495409165152767
Trained batch 298 in epoch 0, gen_loss = 0.7073029638532811, disc_loss = 0.23501848708526746
Trained batch 299 in epoch 0, gen_loss = 0.70715884745121, disc_loss = 0.2348211701462666
Trained batch 300 in epoch 0, gen_loss = 0.7068708495444238, disc_loss = 0.23471223661966895
Trained batch 301 in epoch 0, gen_loss = 0.7069003183320658, disc_loss = 0.23467760634244672
Trained batch 302 in epoch 0, gen_loss = 0.7067091557452387, disc_loss = 0.23444111259168524
Trained batch 303 in epoch 0, gen_loss = 0.7062006757447594, disc_loss = 0.2343898599134072
Trained batch 304 in epoch 0, gen_loss = 0.7062467315157906, disc_loss = 0.23440322976131908
Trained batch 305 in epoch 0, gen_loss = 0.7057041518049303, disc_loss = 0.23448468659535732
Trained batch 306 in epoch 0, gen_loss = 0.7056856877640715, disc_loss = 0.23434536379886373
Trained batch 307 in epoch 0, gen_loss = 0.7056399678642099, disc_loss = 0.23429408352580164
Trained batch 308 in epoch 0, gen_loss = 0.7051062155695795, disc_loss = 0.23428716525001433
Trained batch 309 in epoch 0, gen_loss = 0.7050767648604608, disc_loss = 0.23418823800260022
Trained batch 310 in epoch 0, gen_loss = 0.704894663244965, disc_loss = 0.23407293829791415
Trained batch 311 in epoch 0, gen_loss = 0.7046304792165756, disc_loss = 0.2339887569586818
Trained batch 312 in epoch 0, gen_loss = 0.7046674097688815, disc_loss = 0.23386731208227693
Trained batch 313 in epoch 0, gen_loss = 0.704327558635906, disc_loss = 0.23362899507591678
Trained batch 314 in epoch 0, gen_loss = 0.7038709791879806, disc_loss = 0.2334481973733221
Trained batch 315 in epoch 0, gen_loss = 0.703729088170619, disc_loss = 0.23320407139821142
Trained batch 316 in epoch 0, gen_loss = 0.7039249672874667, disc_loss = 0.23311651996351568
Trained batch 317 in epoch 0, gen_loss = 0.7036431690431991, disc_loss = 0.23302248375689458
Trained batch 318 in epoch 0, gen_loss = 0.7037715568064149, disc_loss = 0.23309790072115985
Trained batch 319 in epoch 0, gen_loss = 0.7035306299105286, disc_loss = 0.23283649815712124
Trained batch 320 in epoch 0, gen_loss = 0.7033382583630048, disc_loss = 0.2326244424297431
Trained batch 321 in epoch 0, gen_loss = 0.7033583792100041, disc_loss = 0.23258083241974345
Trained batch 322 in epoch 0, gen_loss = 0.7027282661328744, disc_loss = 0.23253593870637587
Trained batch 323 in epoch 0, gen_loss = 0.7032127994814037, disc_loss = 0.23246240388188097
Trained batch 324 in epoch 0, gen_loss = 0.702905334692735, disc_loss = 0.2323221145914151
Trained batch 325 in epoch 0, gen_loss = 0.7026806215932764, disc_loss = 0.23212934008862343
Trained batch 326 in epoch 0, gen_loss = 0.7026620911895682, disc_loss = 0.23203729573830917
Trained batch 327 in epoch 0, gen_loss = 0.7030574096048751, disc_loss = 0.23165741946729945
Trained batch 328 in epoch 0, gen_loss = 0.7028900886741453, disc_loss = 0.2313502422989683
Trained batch 329 in epoch 0, gen_loss = 0.7025907702518231, disc_loss = 0.23104039125821807
Trained batch 330 in epoch 0, gen_loss = 0.7030634107546504, disc_loss = 0.23114876113719451
Trained batch 331 in epoch 0, gen_loss = 0.7025580860405083, disc_loss = 0.23123273282614817
Trained batch 332 in epoch 0, gen_loss = 0.7025530841257479, disc_loss = 0.23094687449771004
Trained batch 333 in epoch 0, gen_loss = 0.7028286598042813, disc_loss = 0.23093581777400599
Trained batch 334 in epoch 0, gen_loss = 0.7035680977266227, disc_loss = 0.2303917128648331
Trained batch 335 in epoch 0, gen_loss = 0.7026399546968085, disc_loss = 0.2308377366335619
Trained batch 336 in epoch 0, gen_loss = 0.7027651985073655, disc_loss = 0.23079921751772262
Trained batch 337 in epoch 0, gen_loss = 0.7034293131891792, disc_loss = 0.23100701300702856
Trained batch 338 in epoch 0, gen_loss = 0.7032068158145499, disc_loss = 0.23110187853683764
Trained batch 339 in epoch 0, gen_loss = 0.703006282185807, disc_loss = 0.23104424296933063
Trained batch 340 in epoch 0, gen_loss = 0.7032197038274357, disc_loss = 0.23094289686498054
Trained batch 341 in epoch 0, gen_loss = 0.7030204925795047, disc_loss = 0.23086192180015888
Trained batch 342 in epoch 0, gen_loss = 0.7028013824895242, disc_loss = 0.2307289695861388
Trained batch 343 in epoch 0, gen_loss = 0.7029027236235696, disc_loss = 0.23064186021165792
Trained batch 344 in epoch 0, gen_loss = 0.7029146399187005, disc_loss = 0.23052045474017877
Trained batch 345 in epoch 0, gen_loss = 0.7027469123202252, disc_loss = 0.2303574787657385
Trained batch 346 in epoch 0, gen_loss = 0.7023463610785152, disc_loss = 0.2304190792766016
Trained batch 347 in epoch 0, gen_loss = 0.7029221074163229, disc_loss = 0.2309406615108594
Trained batch 348 in epoch 0, gen_loss = 0.7024052213973507, disc_loss = 0.23089097295073863
Trained batch 349 in epoch 0, gen_loss = 0.7019820978811809, disc_loss = 0.2307823641385351
Trained batch 350 in epoch 0, gen_loss = 0.701985044442011, disc_loss = 0.23074041417351476
Trained batch 351 in epoch 0, gen_loss = 0.702088816176084, disc_loss = 0.2306873597289351
Trained batch 352 in epoch 0, gen_loss = 0.7018802222550422, disc_loss = 0.23064679679890868
Trained batch 353 in epoch 0, gen_loss = 0.7017589331851841, disc_loss = 0.23056050440517523
Trained batch 354 in epoch 0, gen_loss = 0.7014907795778462, disc_loss = 0.23049183546657293
Trained batch 355 in epoch 0, gen_loss = 0.7016023252619786, disc_loss = 0.23037645053327754
Trained batch 356 in epoch 0, gen_loss = 0.7012469345281104, disc_loss = 0.23034388357016886
Trained batch 357 in epoch 0, gen_loss = 0.7012511166280875, disc_loss = 0.23010200694952598
Trained batch 358 in epoch 0, gen_loss = 0.7010320963799788, disc_loss = 0.22996273753038687
Trained batch 359 in epoch 0, gen_loss = 0.7007372371852398, disc_loss = 0.2298017224503888
Trained batch 360 in epoch 0, gen_loss = 0.7008843285720434, disc_loss = 0.22967727502957605
Trained batch 361 in epoch 0, gen_loss = 0.7009569036861809, disc_loss = 0.229435531556277
Trained batch 362 in epoch 0, gen_loss = 0.7007798290613926, disc_loss = 0.22954863539740403
Trained batch 363 in epoch 0, gen_loss = 0.7008412089812887, disc_loss = 0.22941926269085852
Trained batch 364 in epoch 0, gen_loss = 0.7006885108065932, disc_loss = 0.2292813007962214
Trained batch 365 in epoch 0, gen_loss = 0.7007543147424531, disc_loss = 0.22914401462169293
Trained batch 366 in epoch 0, gen_loss = 0.7005197154890939, disc_loss = 0.22903006598962425
Trained batch 367 in epoch 0, gen_loss = 0.7000761905928021, disc_loss = 0.22892060827301897
Trained batch 368 in epoch 0, gen_loss = 0.6999593146932803, disc_loss = 0.22860527115301066
Trained batch 369 in epoch 0, gen_loss = 0.6997827508159586, disc_loss = 0.22834731578021436
Trained batch 370 in epoch 0, gen_loss = 0.6998876343679556, disc_loss = 0.22802686058687713
Trained batch 371 in epoch 0, gen_loss = 0.6993747958412735, disc_loss = 0.2279272132543146
Trained batch 372 in epoch 0, gen_loss = 0.6997385995797114, disc_loss = 0.22774100960819077
Trained batch 373 in epoch 0, gen_loss = 0.6997141591845987, disc_loss = 0.2274097539484501
Trained batch 374 in epoch 0, gen_loss = 0.6993327888647716, disc_loss = 0.22728351201613745
Trained batch 375 in epoch 0, gen_loss = 0.6998110498361131, disc_loss = 0.22765668741169762
Trained batch 376 in epoch 0, gen_loss = 0.6997855113577147, disc_loss = 0.22724157518433008
Trained batch 377 in epoch 0, gen_loss = 0.6992331501195039, disc_loss = 0.22715169500815804
Trained batch 378 in epoch 0, gen_loss = 0.6992583728560042, disc_loss = 0.22708759625936248
Trained batch 379 in epoch 0, gen_loss = 0.6993103865730135, disc_loss = 0.22726666325409162
Trained batch 380 in epoch 0, gen_loss = 0.6986551744731393, disc_loss = 0.22729886174593072
Trained batch 381 in epoch 0, gen_loss = 0.698355226772618, disc_loss = 0.22719567789847314
Trained batch 382 in epoch 0, gen_loss = 0.6981743348485184, disc_loss = 0.22709964377217132
Trained batch 383 in epoch 0, gen_loss = 0.6981245695302883, disc_loss = 0.2270363845746033
Trained batch 384 in epoch 0, gen_loss = 0.6978542818651571, disc_loss = 0.22687935161513167
Trained batch 385 in epoch 0, gen_loss = 0.6979445016754724, disc_loss = 0.22658095603393766
Trained batch 386 in epoch 0, gen_loss = 0.6977299755241828, disc_loss = 0.22634280034044915
Trained batch 387 in epoch 0, gen_loss = 0.69777120926331, disc_loss = 0.2260877848554825
Trained batch 388 in epoch 0, gen_loss = 0.6979639648165372, disc_loss = 0.225958496734385
Trained batch 389 in epoch 0, gen_loss = 0.6978952577480904, disc_loss = 0.22586922876727886
Trained batch 390 in epoch 0, gen_loss = 0.6989900741125922, disc_loss = 0.22587541631801658
Trained batch 391 in epoch 0, gen_loss = 0.6990032492547619, disc_loss = 0.22572726393308568
Trained batch 392 in epoch 0, gen_loss = 0.698581590452267, disc_loss = 0.2259714336681912
Trained batch 393 in epoch 0, gen_loss = 0.6989790332801451, disc_loss = 0.226346138562194
Trained batch 394 in epoch 0, gen_loss = 0.6986678194396103, disc_loss = 0.22642373218189313
Trained batch 395 in epoch 0, gen_loss = 0.6982219046113467, disc_loss = 0.22651492204103205
Trained batch 396 in epoch 0, gen_loss = 0.6981999985216847, disc_loss = 0.22659218598448058
Trained batch 397 in epoch 0, gen_loss = 0.6982092366146682, disc_loss = 0.22657781002584415
Trained batch 398 in epoch 0, gen_loss = 0.6980356999805996, disc_loss = 0.22648481189980543
Trained batch 399 in epoch 0, gen_loss = 0.6976857946813106, disc_loss = 0.22649082450196148
Trained batch 400 in epoch 0, gen_loss = 0.6976872446233792, disc_loss = 0.22635345616171187
Trained batch 401 in epoch 0, gen_loss = 0.6973132270189067, disc_loss = 0.22638848473999038
Trained batch 402 in epoch 0, gen_loss = 0.6973058108064732, disc_loss = 0.22624485344434198
Trained batch 403 in epoch 0, gen_loss = 0.6972616874050386, disc_loss = 0.22610191187572362
Trained batch 404 in epoch 0, gen_loss = 0.6971958959544147, disc_loss = 0.2259448167902452
Trained batch 405 in epoch 0, gen_loss = 0.696958477127141, disc_loss = 0.22582772904502346
Trained batch 406 in epoch 0, gen_loss = 0.6965739347717979, disc_loss = 0.2257541582647354
Trained batch 407 in epoch 0, gen_loss = 0.6966514305449, disc_loss = 0.22579525233995096
Trained batch 408 in epoch 0, gen_loss = 0.6966033496308734, disc_loss = 0.22561650530123187
Trained batch 409 in epoch 0, gen_loss = 0.6965233461159032, disc_loss = 0.22560642497932037
Trained batch 410 in epoch 0, gen_loss = 0.6958486447949189, disc_loss = 0.22586312177625015
Trained batch 411 in epoch 0, gen_loss = 0.6956987072831219, disc_loss = 0.22569880238508136
Trained batch 412 in epoch 0, gen_loss = 0.6954966455914495, disc_loss = 0.22558381700703364
Trained batch 413 in epoch 0, gen_loss = 0.6953461364559506, disc_loss = 0.22538879054827968
Trained batch 414 in epoch 0, gen_loss = 0.6955537806074303, disc_loss = 0.22518447563949837
Trained batch 415 in epoch 0, gen_loss = 0.6956111278671485, disc_loss = 0.22494105668738484
Trained batch 416 in epoch 0, gen_loss = 0.6960593580627898, disc_loss = 0.22486823343401618
Trained batch 417 in epoch 0, gen_loss = 0.6954224372024171, disc_loss = 0.22505153455374913
Trained batch 418 in epoch 0, gen_loss = 0.6956261669536764, disc_loss = 0.2247320149707339
Trained batch 419 in epoch 0, gen_loss = 0.6962337794758025, disc_loss = 0.22453115490220843
Trained batch 420 in epoch 0, gen_loss = 0.6958031713820976, disc_loss = 0.22427177569008214
Trained batch 421 in epoch 0, gen_loss = 0.6965500249116907, disc_loss = 0.22384391147731605
Trained batch 422 in epoch 0, gen_loss = 0.6963386079098316, disc_loss = 0.22371043428672965
Trained batch 423 in epoch 0, gen_loss = 0.6968687263862142, disc_loss = 0.2235221576543068
Trained batch 424 in epoch 0, gen_loss = 0.6969755606090321, disc_loss = 0.22323429179542206
Trained batch 425 in epoch 0, gen_loss = 0.6968736753497325, disc_loss = 0.22308117104038386
Trained batch 426 in epoch 0, gen_loss = 0.6969896478172767, disc_loss = 0.2231403878373061
Trained batch 427 in epoch 0, gen_loss = 0.6964838994301368, disc_loss = 0.22318793546025442
Trained batch 428 in epoch 0, gen_loss = 0.696514506509532, disc_loss = 0.22311495854095978
Trained batch 429 in epoch 0, gen_loss = 0.6962102070104245, disc_loss = 0.22305062158509742
Trained batch 430 in epoch 0, gen_loss = 0.696146465993536, disc_loss = 0.2229853772543146
Trained batch 431 in epoch 0, gen_loss = 0.6962410136367436, disc_loss = 0.2229646922227133
Trained batch 432 in epoch 0, gen_loss = 0.6957068446739717, disc_loss = 0.2230845595996044
Trained batch 433 in epoch 0, gen_loss = 0.6954136414599309, disc_loss = 0.22298268913742034
Trained batch 434 in epoch 0, gen_loss = 0.6958556676047972, disc_loss = 0.2230409194854484
Trained batch 435 in epoch 0, gen_loss = 0.6958152845228484, disc_loss = 0.2228319860755577
Trained batch 436 in epoch 0, gen_loss = 0.6954315595959635, disc_loss = 0.22290206997222703
Trained batch 437 in epoch 0, gen_loss = 0.6962657636839505, disc_loss = 0.22301832955653808
Trained batch 438 in epoch 0, gen_loss = 0.6960687373249297, disc_loss = 0.22302396804230087
Trained batch 439 in epoch 0, gen_loss = 0.6957658775150776, disc_loss = 0.22289618539877915
Trained batch 440 in epoch 0, gen_loss = 0.6958235169078758, disc_loss = 0.22272630412629943
Trained batch 441 in epoch 0, gen_loss = 0.6959914577897318, disc_loss = 0.22259730338308606
Trained batch 442 in epoch 0, gen_loss = 0.6960271694455674, disc_loss = 0.22237013934630034
Trained batch 443 in epoch 0, gen_loss = 0.6957950034254307, disc_loss = 0.2223007970128779
Trained batch 444 in epoch 0, gen_loss = 0.6962764783521717, disc_loss = 0.22221974521205667
Trained batch 445 in epoch 0, gen_loss = 0.6959369757918499, disc_loss = 0.22206843980157856
Trained batch 446 in epoch 0, gen_loss = 0.6956932849398662, disc_loss = 0.22205510673840306
Trained batch 447 in epoch 0, gen_loss = 0.6957086152397096, disc_loss = 0.222020733885334
Trained batch 448 in epoch 0, gen_loss = 0.6958286639444016, disc_loss = 0.22171142149741507
Trained batch 449 in epoch 0, gen_loss = 0.6956212257676654, disc_loss = 0.22156688534551197
Trained batch 450 in epoch 0, gen_loss = 0.6957407602317581, disc_loss = 0.2215206236175846
Trained batch 451 in epoch 0, gen_loss = 0.6956334180668392, disc_loss = 0.22144038329082252
Trained batch 452 in epoch 0, gen_loss = 0.6955454554120962, disc_loss = 0.22139193745901517
Trained batch 453 in epoch 0, gen_loss = 0.6956095035774592, disc_loss = 0.221192788185002
Trained batch 454 in epoch 0, gen_loss = 0.6954144310820234, disc_loss = 0.22111727241631393
Trained batch 455 in epoch 0, gen_loss = 0.6955764618489826, disc_loss = 0.22098765620275548
Trained batch 456 in epoch 0, gen_loss = 0.6952569054957292, disc_loss = 0.22096044992461508
Trained batch 457 in epoch 0, gen_loss = 0.6952910024396197, disc_loss = 0.22068145513274265
Trained batch 458 in epoch 0, gen_loss = 0.6954081574686213, disc_loss = 0.22064194248782265
Trained batch 459 in epoch 0, gen_loss = 0.6956444889954899, disc_loss = 0.2204379943077979
Trained batch 460 in epoch 0, gen_loss = 0.6955796664423125, disc_loss = 0.22025683169897622
Trained batch 461 in epoch 0, gen_loss = 0.6964307554485478, disc_loss = 0.2199567672010366
Trained batch 462 in epoch 0, gen_loss = 0.6961893842879433, disc_loss = 0.2198697586843571
Trained batch 463 in epoch 0, gen_loss = 0.6967092267526634, disc_loss = 0.21948131831394957
Trained batch 464 in epoch 0, gen_loss = 0.6966208932861205, disc_loss = 0.2192896377896109
Trained batch 465 in epoch 0, gen_loss = 0.6968159585423735, disc_loss = 0.2193403079897933
Trained batch 466 in epoch 0, gen_loss = 0.6966418804525053, disc_loss = 0.21923944991424968
Trained batch 467 in epoch 0, gen_loss = 0.6965974094903368, disc_loss = 0.21914212382597548
Trained batch 468 in epoch 0, gen_loss = 0.697097451892743, disc_loss = 0.21955732428538266
Trained batch 469 in epoch 0, gen_loss = 0.6970255173901294, disc_loss = 0.2194060089661086
Trained batch 470 in epoch 0, gen_loss = 0.6968760620130349, disc_loss = 0.21937050456042756
Trained batch 471 in epoch 0, gen_loss = 0.6969383213100797, disc_loss = 0.2192416682886749
Trained batch 472 in epoch 0, gen_loss = 0.6969430874442449, disc_loss = 0.2191391488887669
Trained batch 473 in epoch 0, gen_loss = 0.6969055408289664, disc_loss = 0.2190603423580716
Trained batch 474 in epoch 0, gen_loss = 0.6970664228263654, disc_loss = 0.21898954908314505
Trained batch 475 in epoch 0, gen_loss = 0.6969932941954677, disc_loss = 0.21902728421190956
Trained batch 476 in epoch 0, gen_loss = 0.697045414765176, disc_loss = 0.21881812653920185
Trained batch 477 in epoch 0, gen_loss = 0.6970232295566025, disc_loss = 0.21865232406519197
Trained batch 478 in epoch 0, gen_loss = 0.6970332255567538, disc_loss = 0.21840653559951295
Trained batch 479 in epoch 0, gen_loss = 0.6971435585990549, disc_loss = 0.21817156578569363
Trained batch 480 in epoch 0, gen_loss = 0.6975383568330515, disc_loss = 0.2181583004083926
Trained batch 481 in epoch 0, gen_loss = 0.6971297204123493, disc_loss = 0.21815567997697724
Trained batch 482 in epoch 0, gen_loss = 0.6973513332089529, disc_loss = 0.2182267675905124
Trained batch 483 in epoch 0, gen_loss = 0.6976012317232849, disc_loss = 0.21799519012320387
Trained batch 484 in epoch 0, gen_loss = 0.6974386771315152, disc_loss = 0.2177911099161684
Trained batch 485 in epoch 0, gen_loss = 0.6976506807553915, disc_loss = 0.21758792102490188
Trained batch 486 in epoch 0, gen_loss = 0.69762098073225, disc_loss = 0.21731959909843224
Trained batch 487 in epoch 0, gen_loss = 0.6976481966185765, disc_loss = 0.21715753112507405
Trained batch 488 in epoch 0, gen_loss = 0.6980071861929201, disc_loss = 0.21713125637917188
Trained batch 489 in epoch 0, gen_loss = 0.6982346074313533, disc_loss = 0.21677991189062595
Trained batch 490 in epoch 0, gen_loss = 0.697853692862264, disc_loss = 0.21687073475262056
Trained batch 491 in epoch 0, gen_loss = 0.6984864121408967, disc_loss = 0.21684760670745518
Trained batch 492 in epoch 0, gen_loss = 0.6982021927229047, disc_loss = 0.21677680909784763
Trained batch 493 in epoch 0, gen_loss = 0.6981711810537679, disc_loss = 0.21669249590260056
Trained batch 494 in epoch 0, gen_loss = 0.6982133113374613, disc_loss = 0.21654187757710014
Trained batch 495 in epoch 0, gen_loss = 0.6979766458633446, disc_loss = 0.21650938645395781
Trained batch 496 in epoch 0, gen_loss = 0.6980418982040474, disc_loss = 0.21627815648673526
Trained batch 497 in epoch 0, gen_loss = 0.6979162014990925, disc_loss = 0.21617985180912008
Trained batch 498 in epoch 0, gen_loss = 0.6980052125119494, disc_loss = 0.216132245368076
Trained batch 499 in epoch 0, gen_loss = 0.6978559219241143, disc_loss = 0.21603628673404454
Trained batch 500 in epoch 0, gen_loss = 0.6979819833042616, disc_loss = 0.21593446395324614
Trained batch 501 in epoch 0, gen_loss = 0.6979426615147951, disc_loss = 0.2156999186052388
Trained batch 502 in epoch 0, gen_loss = 0.6987472395181182, disc_loss = 0.21570996096576184
Trained batch 503 in epoch 0, gen_loss = 0.6983381368456378, disc_loss = 0.2157872809496309
Trained batch 504 in epoch 0, gen_loss = 0.6982772474831874, disc_loss = 0.2156494176697613
Trained batch 505 in epoch 0, gen_loss = 0.6986167304247264, disc_loss = 0.21569712602132157
Trained batch 506 in epoch 0, gen_loss = 0.6983886971864004, disc_loss = 0.2155708975178838
Trained batch 507 in epoch 0, gen_loss = 0.6981598564137624, disc_loss = 0.21549601305100158
Trained batch 508 in epoch 0, gen_loss = 0.6980420359811053, disc_loss = 0.21542203061150897
Trained batch 509 in epoch 0, gen_loss = 0.6979220233127182, disc_loss = 0.21532990240729322
Trained batch 510 in epoch 0, gen_loss = 0.6976982465345566, disc_loss = 0.21525660767393104
Trained batch 511 in epoch 0, gen_loss = 0.6978250494576059, disc_loss = 0.2151377213667729
Trained batch 512 in epoch 0, gen_loss = 0.6978186958598347, disc_loss = 0.21504168006905572
Trained batch 513 in epoch 0, gen_loss = 0.6979898552370443, disc_loss = 0.21483716470867048
Trained batch 514 in epoch 0, gen_loss = 0.6978622530849234, disc_loss = 0.2148872876413239
Trained batch 515 in epoch 0, gen_loss = 0.6980699327911517, disc_loss = 0.2150161087642922
Trained batch 516 in epoch 0, gen_loss = 0.697810746657318, disc_loss = 0.21505911550997997
Trained batch 517 in epoch 0, gen_loss = 0.6978005409585923, disc_loss = 0.2149006634965021
Trained batch 518 in epoch 0, gen_loss = 0.6977610125821909, disc_loss = 0.21491534158817147
Trained batch 519 in epoch 0, gen_loss = 0.6975579909980297, disc_loss = 0.214882684019036
Trained batch 520 in epoch 0, gen_loss = 0.6978948028783194, disc_loss = 0.21475881913716185
Trained batch 521 in epoch 0, gen_loss = 0.6975158112145018, disc_loss = 0.2147785328771077
Trained batch 522 in epoch 0, gen_loss = 0.6976793723512106, disc_loss = 0.21464356336293894
Trained batch 523 in epoch 0, gen_loss = 0.6976353660908364, disc_loss = 0.21445621828058067
Trained batch 524 in epoch 0, gen_loss = 0.6975885182902927, disc_loss = 0.2142593405431225
Trained batch 525 in epoch 0, gen_loss = 0.6977568033643549, disc_loss = 0.21408802535059107
Trained batch 526 in epoch 0, gen_loss = 0.6976003084169167, disc_loss = 0.21388974089521837
Trained batch 527 in epoch 0, gen_loss = 0.6980787525235703, disc_loss = 0.2137959921153996
Trained batch 528 in epoch 0, gen_loss = 0.697882765238587, disc_loss = 0.21379279061475864
Trained batch 529 in epoch 0, gen_loss = 0.6980422062131594, disc_loss = 0.21357350750773582
Trained batch 530 in epoch 0, gen_loss = 0.6984770611742347, disc_loss = 0.2136169725260829
Trained batch 531 in epoch 0, gen_loss = 0.6982236110738346, disc_loss = 0.21376797959516594
Trained batch 532 in epoch 0, gen_loss = 0.6984398016674658, disc_loss = 0.21376654611267917
Trained batch 533 in epoch 0, gen_loss = 0.6986194273617383, disc_loss = 0.21380593671641324
Trained batch 534 in epoch 0, gen_loss = 0.6981874514405972, disc_loss = 0.21403826577501878
Trained batch 535 in epoch 0, gen_loss = 0.6980660374818454, disc_loss = 0.21391497448837357
Trained batch 536 in epoch 0, gen_loss = 0.698145799075203, disc_loss = 0.21383591966783314
Trained batch 537 in epoch 0, gen_loss = 0.6984353891424974, disc_loss = 0.21364025124192904
Trained batch 538 in epoch 0, gen_loss = 0.6982978146129283, disc_loss = 0.213453035843118
Trained batch 539 in epoch 0, gen_loss = 0.6983564468997496, disc_loss = 0.21323998544917064
Trained batch 540 in epoch 0, gen_loss = 0.6982793613524622, disc_loss = 0.21303442258959338
Trained batch 541 in epoch 0, gen_loss = 0.6989341452442852, disc_loss = 0.21282737717939698
Trained batch 542 in epoch 0, gen_loss = 0.6994890882933776, disc_loss = 0.21249343334091741
Trained batch 543 in epoch 0, gen_loss = 0.6994749229291782, disc_loss = 0.21226166889948003
Trained batch 544 in epoch 0, gen_loss = 0.6993518425237149, disc_loss = 0.2121616512263587
Trained batch 545 in epoch 0, gen_loss = 0.6997021443787075, disc_loss = 0.21220626755730138
Trained batch 546 in epoch 0, gen_loss = 0.6995067910803737, disc_loss = 0.2120704730151994
Trained batch 547 in epoch 0, gen_loss = 0.6991609477975073, disc_loss = 0.21208343034895666
Trained batch 548 in epoch 0, gen_loss = 0.6995721153765645, disc_loss = 0.21215584521302325
Trained batch 549 in epoch 0, gen_loss = 0.6995195243033496, disc_loss = 0.2120094575665214
Trained batch 550 in epoch 0, gen_loss = 0.6992854307762292, disc_loss = 0.21206452931444789
Trained batch 551 in epoch 0, gen_loss = 0.6992512782090816, disc_loss = 0.2120034500848556
Trained batch 552 in epoch 0, gen_loss = 0.7000085766988033, disc_loss = 0.21199914826514707
Trained batch 553 in epoch 0, gen_loss = 0.6996778880753672, disc_loss = 0.21198853099927145
Trained batch 554 in epoch 0, gen_loss = 0.6995892553179114, disc_loss = 0.2118708001869219
Trained batch 555 in epoch 0, gen_loss = 0.7000766244830845, disc_loss = 0.211898150123495
Trained batch 556 in epoch 0, gen_loss = 0.7000247693254447, disc_loss = 0.21184461096993898
Trained batch 557 in epoch 0, gen_loss = 0.6997115835814494, disc_loss = 0.21174033330653302
Trained batch 558 in epoch 0, gen_loss = 0.6997434305483625, disc_loss = 0.21161128543250676
Trained batch 559 in epoch 0, gen_loss = 0.6996672267892531, disc_loss = 0.21143916031079632
Trained batch 560 in epoch 0, gen_loss = 0.6999040855337166, disc_loss = 0.21128014071368068
Trained batch 561 in epoch 0, gen_loss = 0.7002558933564352, disc_loss = 0.2112495134123916
Trained batch 562 in epoch 0, gen_loss = 0.6999353036469719, disc_loss = 0.21123950854340837
Trained batch 563 in epoch 0, gen_loss = 0.7001530323573883, disc_loss = 0.21112206738098716
Trained batch 564 in epoch 0, gen_loss = 0.7006206943398028, disc_loss = 0.2107970048467406
Trained batch 565 in epoch 0, gen_loss = 0.700729173032218, disc_loss = 0.21052979539369
Trained batch 566 in epoch 0, gen_loss = 0.7008001747059864, disc_loss = 0.21032083264143064
Trained batch 567 in epoch 0, gen_loss = 0.7006917146205063, disc_loss = 0.21011215591029278
Trained batch 568 in epoch 0, gen_loss = 0.7013643529063159, disc_loss = 0.2099041011420149
Trained batch 569 in epoch 0, gen_loss = 0.7012645097678167, disc_loss = 0.20979195129649159
Trained batch 570 in epoch 0, gen_loss = 0.7013400241393342, disc_loss = 0.20954500879576973
Trained batch 571 in epoch 0, gen_loss = 0.7016910315080956, disc_loss = 0.20936861349973124
Trained batch 572 in epoch 0, gen_loss = 0.7014872074439263, disc_loss = 0.20920626804505654
Trained batch 573 in epoch 0, gen_loss = 0.701403906588355, disc_loss = 0.20903009300538783
Trained batch 574 in epoch 0, gen_loss = 0.7016586572709291, disc_loss = 0.2090658716760252
Trained batch 575 in epoch 0, gen_loss = 0.7014274095805982, disc_loss = 0.20891407157695438
Trained batch 576 in epoch 0, gen_loss = 0.7013621027072959, disc_loss = 0.208810511088738
Trained batch 577 in epoch 0, gen_loss = 0.7013957467974263, disc_loss = 0.2086683936565341
Trained batch 578 in epoch 0, gen_loss = 0.7017863293488821, disc_loss = 0.20860086018235674
Trained batch 579 in epoch 0, gen_loss = 0.7014095468253925, disc_loss = 0.20871105019067382
Trained batch 580 in epoch 0, gen_loss = 0.701734939202179, disc_loss = 0.20853460392563664
Trained batch 581 in epoch 0, gen_loss = 0.7016099337552422, disc_loss = 0.20843337167412862
Trained batch 582 in epoch 0, gen_loss = 0.7017971367717403, disc_loss = 0.20816292734832645
Trained batch 583 in epoch 0, gen_loss = 0.7018409063656853, disc_loss = 0.2079023300855076
Trained batch 584 in epoch 0, gen_loss = 0.7016642982633705, disc_loss = 0.207826546799296
Trained batch 585 in epoch 0, gen_loss = 0.7024215006685908, disc_loss = 0.20828846551846625
Trained batch 586 in epoch 0, gen_loss = 0.7020337164808172, disc_loss = 0.20840540545749806
Trained batch 587 in epoch 0, gen_loss = 0.7019821064305954, disc_loss = 0.20825455437547394
Trained batch 588 in epoch 0, gen_loss = 0.7018521321346076, disc_loss = 0.2081687245328226
Trained batch 589 in epoch 0, gen_loss = 0.70179024040699, disc_loss = 0.20817673977590717
Trained batch 590 in epoch 0, gen_loss = 0.7015283500583442, disc_loss = 0.2081991810881093
Trained batch 591 in epoch 0, gen_loss = 0.7013469890666169, disc_loss = 0.20807615426885015
Trained batch 592 in epoch 0, gen_loss = 0.7012130627644203, disc_loss = 0.20796613825852614
Trained batch 593 in epoch 0, gen_loss = 0.7011139696394956, disc_loss = 0.20795031191360971
Trained batch 594 in epoch 0, gen_loss = 0.7009716074506775, disc_loss = 0.2079533065911852
Trained batch 595 in epoch 0, gen_loss = 0.7009265093295366, disc_loss = 0.20783347814912664
Trained batch 596 in epoch 0, gen_loss = 0.7007962399890874, disc_loss = 0.20777699135094133
Trained batch 597 in epoch 0, gen_loss = 0.7011309027372794, disc_loss = 0.20778900266229408
Trained batch 598 in epoch 0, gen_loss = 0.7009760562784485, disc_loss = 0.20783722182682937
Trained batch 599 in epoch 0, gen_loss = 0.7008892485002677, disc_loss = 0.20774750504332284
Trained batch 600 in epoch 0, gen_loss = 0.7008721721846728, disc_loss = 0.2075993240642022
Trained batch 601 in epoch 0, gen_loss = 0.7009964135299094, disc_loss = 0.20758012451689406
Trained batch 602 in epoch 0, gen_loss = 0.7007139419540639, disc_loss = 0.20755074942672924
Trained batch 603 in epoch 0, gen_loss = 0.7006610517963668, disc_loss = 0.20743437513203317
Trained batch 604 in epoch 0, gen_loss = 0.7011227895898268, disc_loss = 0.20745503862719397
Trained batch 605 in epoch 0, gen_loss = 0.7011305003768147, disc_loss = 0.20738333094520833
Trained batch 606 in epoch 0, gen_loss = 0.7011701880510792, disc_loss = 0.2072024743181624
Trained batch 607 in epoch 0, gen_loss = 0.700934679149405, disc_loss = 0.20720254081779307
Trained batch 608 in epoch 0, gen_loss = 0.7010174349121664, disc_loss = 0.20708813305106166
Trained batch 609 in epoch 0, gen_loss = 0.7012040700580253, disc_loss = 0.20692297160075826
Trained batch 610 in epoch 0, gen_loss = 0.7010953295152823, disc_loss = 0.20689813418042544
Trained batch 611 in epoch 0, gen_loss = 0.7009238905084678, disc_loss = 0.20679483682927646
Trained batch 612 in epoch 0, gen_loss = 0.7008348222560634, disc_loss = 0.206686181826046
Trained batch 613 in epoch 0, gen_loss = 0.7010361492536744, disc_loss = 0.20658192340381662
Trained batch 614 in epoch 0, gen_loss = 0.7010370712454727, disc_loss = 0.20635149477398007
Trained batch 615 in epoch 0, gen_loss = 0.700855326294512, disc_loss = 0.20624448967093675
Trained batch 616 in epoch 0, gen_loss = 0.7014362875317832, disc_loss = 0.20622989956464624
Trained batch 617 in epoch 0, gen_loss = 0.7011758122339989, disc_loss = 0.20628775683650596
Trained batch 618 in epoch 0, gen_loss = 0.7016311771746406, disc_loss = 0.20616338081561594
Trained batch 619 in epoch 0, gen_loss = 0.701556393552211, disc_loss = 0.20610629585421375
Trained batch 620 in epoch 0, gen_loss = 0.7013271826764812, disc_loss = 0.20608760503791093
Trained batch 621 in epoch 0, gen_loss = 0.7015116366638632, disc_loss = 0.2059607354001744
Trained batch 622 in epoch 0, gen_loss = 0.7015287214546295, disc_loss = 0.20586553539775826
Trained batch 623 in epoch 0, gen_loss = 0.701591580389784, disc_loss = 0.2057615684864756
Trained batch 624 in epoch 0, gen_loss = 0.7014748288631439, disc_loss = 0.20564410282075404
Trained batch 625 in epoch 0, gen_loss = 0.7015669720527082, disc_loss = 0.2055287971086919
Trained batch 626 in epoch 0, gen_loss = 0.701425528079509, disc_loss = 0.2054400887589848
Trained batch 627 in epoch 0, gen_loss = 0.7016852580153259, disc_loss = 0.20537425692424557
Trained batch 628 in epoch 0, gen_loss = 0.7014531423537644, disc_loss = 0.20537967658609105
Trained batch 629 in epoch 0, gen_loss = 0.701453356941541, disc_loss = 0.20523831140368232
Trained batch 630 in epoch 0, gen_loss = 0.7017565121646917, disc_loss = 0.20504767791015316
Trained batch 631 in epoch 0, gen_loss = 0.7016967874067493, disc_loss = 0.20511723142058316
Trained batch 632 in epoch 0, gen_loss = 0.7018224484453457, disc_loss = 0.2053140273044036
Trained batch 633 in epoch 0, gen_loss = 0.7015645222426965, disc_loss = 0.20539505283527476
Trained batch 634 in epoch 0, gen_loss = 0.701602766692169, disc_loss = 0.20529670417015478
Trained batch 635 in epoch 0, gen_loss = 0.7017774680781664, disc_loss = 0.20536032189913797
Trained batch 636 in epoch 0, gen_loss = 0.701613883348986, disc_loss = 0.2052047499301997
Trained batch 637 in epoch 0, gen_loss = 0.7012611748095964, disc_loss = 0.2052406746759824
Trained batch 638 in epoch 0, gen_loss = 0.7017737398498308, disc_loss = 0.20511254603815657
Trained batch 639 in epoch 0, gen_loss = 0.7018138534389436, disc_loss = 0.20499007691105361
Trained batch 640 in epoch 0, gen_loss = 0.7017093513759548, disc_loss = 0.20495409018384778
Trained batch 641 in epoch 0, gen_loss = 0.7016627667848938, disc_loss = 0.20481181757182254
Trained batch 642 in epoch 0, gen_loss = 0.7018392711738777, disc_loss = 0.20469074254539762
Trained batch 643 in epoch 0, gen_loss = 0.7019377127752541, disc_loss = 0.2044791738178743
Trained batch 644 in epoch 0, gen_loss = 0.7018622135007104, disc_loss = 0.20433882466524608
Trained batch 645 in epoch 0, gen_loss = 0.7019444827693904, disc_loss = 0.2041670875393154
Trained batch 646 in epoch 0, gen_loss = 0.7018532934476271, disc_loss = 0.20407791539070871
Trained batch 647 in epoch 0, gen_loss = 0.7019599505964621, disc_loss = 0.20399488398034907
Trained batch 648 in epoch 0, gen_loss = 0.7020518946904798, disc_loss = 0.20377888556609994
Trained batch 649 in epoch 0, gen_loss = 0.7017741227149963, disc_loss = 0.20365777038324337
Trained batch 650 in epoch 0, gen_loss = 0.7020491910969606, disc_loss = 0.203615643733543
Trained batch 651 in epoch 0, gen_loss = 0.7019272620326902, disc_loss = 0.20362452499602743
Trained batch 652 in epoch 0, gen_loss = 0.7020647456415945, disc_loss = 0.20347013423478896
Trained batch 653 in epoch 0, gen_loss = 0.7021319049578558, disc_loss = 0.20329019787012165
Trained batch 654 in epoch 0, gen_loss = 0.7019015031916495, disc_loss = 0.20317453532444157
Trained batch 655 in epoch 0, gen_loss = 0.701899360683633, disc_loss = 0.20302082903444676
Trained batch 656 in epoch 0, gen_loss = 0.7020561206104912, disc_loss = 0.2029438243875538
Trained batch 657 in epoch 0, gen_loss = 0.7018629241859297, disc_loss = 0.20284880884274795
Trained batch 658 in epoch 0, gen_loss = 0.7017742171092171, disc_loss = 0.20271225024596964
Trained batch 659 in epoch 0, gen_loss = 0.7021322506846803, disc_loss = 0.20287159362694981
Trained batch 660 in epoch 0, gen_loss = 0.7016634262996795, disc_loss = 0.2031913050471519
Trained batch 661 in epoch 0, gen_loss = 0.7018408995020425, disc_loss = 0.20310385365129147
Trained batch 662 in epoch 0, gen_loss = 0.7021928079887033, disc_loss = 0.20336113209087475
Trained batch 663 in epoch 0, gen_loss = 0.7021515511245613, disc_loss = 0.20341314031764954
Trained batch 664 in epoch 0, gen_loss = 0.7021530353933348, disc_loss = 0.20333638453113853
Trained batch 665 in epoch 0, gen_loss = 0.7023089366990167, disc_loss = 0.2033431206664837
Trained batch 666 in epoch 0, gen_loss = 0.7023159888373322, disc_loss = 0.20316718147601234
Trained batch 667 in epoch 0, gen_loss = 0.7020853306362015, disc_loss = 0.20318822232270223
Trained batch 668 in epoch 0, gen_loss = 0.7024002158053787, disc_loss = 0.2033010256547698
Trained batch 669 in epoch 0, gen_loss = 0.702443941760419, disc_loss = 0.20318142520124788
Trained batch 670 in epoch 0, gen_loss = 0.7023749752122848, disc_loss = 0.20308141552200526
Trained batch 671 in epoch 0, gen_loss = 0.7025555451178834, disc_loss = 0.20303148314789204
Trained batch 672 in epoch 0, gen_loss = 0.7024548505425985, disc_loss = 0.20289385380475253
Trained batch 673 in epoch 0, gen_loss = 0.7023188790157217, disc_loss = 0.20276358359678473
Trained batch 674 in epoch 0, gen_loss = 0.702402411390234, disc_loss = 0.20269735140656983
Trained batch 675 in epoch 0, gen_loss = 0.7024463024541471, disc_loss = 0.20272187605092423
Trained batch 676 in epoch 0, gen_loss = 0.702331566740174, disc_loss = 0.2026504564182929
Trained batch 677 in epoch 0, gen_loss = 0.7022087047409519, disc_loss = 0.20255857621179482
Trained batch 678 in epoch 0, gen_loss = 0.7024373045199398, disc_loss = 0.20242243562722154
Trained batch 679 in epoch 0, gen_loss = 0.7022968752419247, disc_loss = 0.20231859226820662
Trained batch 680 in epoch 0, gen_loss = 0.7021629706178293, disc_loss = 0.20226292991285894
Trained batch 681 in epoch 0, gen_loss = 0.7025917307897047, disc_loss = 0.2022504349515017
Trained batch 682 in epoch 0, gen_loss = 0.702551417521816, disc_loss = 0.20213716208531166
Trained batch 683 in epoch 0, gen_loss = 0.7024591050127096, disc_loss = 0.2020747329881796
Trained batch 684 in epoch 0, gen_loss = 0.7027026384416288, disc_loss = 0.20214128177477061
Trained batch 685 in epoch 0, gen_loss = 0.702578141025482, disc_loss = 0.20214974020849424
Trained batch 686 in epoch 0, gen_loss = 0.702339380762636, disc_loss = 0.20206441868806943
Trained batch 687 in epoch 0, gen_loss = 0.7024964814962342, disc_loss = 0.202055269383912
Trained batch 688 in epoch 0, gen_loss = 0.7024358151093969, disc_loss = 0.20193623235322136
Trained batch 689 in epoch 0, gen_loss = 0.7022964011067929, disc_loss = 0.2019266569501032
Trained batch 690 in epoch 0, gen_loss = 0.7021218500330548, disc_loss = 0.20191903946875406
Trained batch 691 in epoch 0, gen_loss = 0.7024229162001197, disc_loss = 0.20195616260332439
Trained batch 692 in epoch 0, gen_loss = 0.7023963419045893, disc_loss = 0.20188803065294053
Trained batch 693 in epoch 0, gen_loss = 0.7022281341490897, disc_loss = 0.20181929077201602
Trained batch 694 in epoch 0, gen_loss = 0.7022101427153717, disc_loss = 0.20171643160819577
Trained batch 695 in epoch 0, gen_loss = 0.7024397311368208, disc_loss = 0.20168095522817095
Trained batch 696 in epoch 0, gen_loss = 0.7024165911004054, disc_loss = 0.20162754378400455
Trained batch 697 in epoch 0, gen_loss = 0.7022088369872304, disc_loss = 0.2015779314263801
Trained batch 698 in epoch 0, gen_loss = 0.7023014106463976, disc_loss = 0.20149768332288587
Trained batch 699 in epoch 0, gen_loss = 0.7024256840773991, disc_loss = 0.20148093402119618
Trained batch 700 in epoch 0, gen_loss = 0.7022676700872293, disc_loss = 0.20141212563276206
Trained batch 701 in epoch 0, gen_loss = 0.7020910519819993, disc_loss = 0.20127789623918613
Trained batch 702 in epoch 0, gen_loss = 0.7023925370037302, disc_loss = 0.20113345694226104
Trained batch 703 in epoch 0, gen_loss = 0.7023476644165136, disc_loss = 0.2011785349909174
Trained batch 704 in epoch 0, gen_loss = 0.7025689185933864, disc_loss = 0.20101712034050878
Trained batch 705 in epoch 0, gen_loss = 0.7024858358392635, disc_loss = 0.20090850171166083
Trained batch 706 in epoch 0, gen_loss = 0.7026511077496422, disc_loss = 0.2007413504268484
Trained batch 707 in epoch 0, gen_loss = 0.7027716914475974, disc_loss = 0.20056762378715443
Trained batch 708 in epoch 0, gen_loss = 0.7024467990579996, disc_loss = 0.20073198646632756
Trained batch 709 in epoch 0, gen_loss = 0.7027309246046443, disc_loss = 0.20072159136212628
Trained batch 710 in epoch 0, gen_loss = 0.7026219972829778, disc_loss = 0.20067054868195044
Trained batch 711 in epoch 0, gen_loss = 0.7024713938407013, disc_loss = 0.200549054574326
Trained batch 712 in epoch 0, gen_loss = 0.7023042774384353, disc_loss = 0.20052090890935478
Trained batch 713 in epoch 0, gen_loss = 0.7022720366215506, disc_loss = 0.2004318052579333
Trained batch 714 in epoch 0, gen_loss = 0.7021586249341498, disc_loss = 0.20034797601922827
Trained batch 715 in epoch 0, gen_loss = 0.702098538214601, disc_loss = 0.20018554282993828
Trained batch 716 in epoch 0, gen_loss = 0.7021389607355685, disc_loss = 0.200151487351025
Trained batch 717 in epoch 0, gen_loss = 0.7020558234625872, disc_loss = 0.20005151755786124
Trained batch 718 in epoch 0, gen_loss = 0.7022589210923424, disc_loss = 0.19991868488511305
Trained batch 719 in epoch 0, gen_loss = 0.7020050736351146, disc_loss = 0.19993427764986538
Trained batch 720 in epoch 0, gen_loss = 0.7026623224997157, disc_loss = 0.1998065074830834
Trained batch 721 in epoch 0, gen_loss = 0.7027911696159939, disc_loss = 0.1996168647957269
Trained batch 722 in epoch 0, gen_loss = 0.7026883057456459, disc_loss = 0.19947010781332583
Trained batch 723 in epoch 0, gen_loss = 0.7027410081489969, disc_loss = 0.19940680322798165
Trained batch 724 in epoch 0, gen_loss = 0.7026695117868226, disc_loss = 0.19924280522969262
Trained batch 725 in epoch 0, gen_loss = 0.7026939319431289, disc_loss = 0.19915055316044197
Trained batch 726 in epoch 0, gen_loss = 0.7027424542333269, disc_loss = 0.19913270967811386
Trained batch 727 in epoch 0, gen_loss = 0.702504325985581, disc_loss = 0.1990241968139474
Trained batch 728 in epoch 0, gen_loss = 0.7027660471339938, disc_loss = 0.1988531201643504
Trained batch 729 in epoch 0, gen_loss = 0.7027720069640303, disc_loss = 0.1987726174575621
Trained batch 730 in epoch 0, gen_loss = 0.7029945193579683, disc_loss = 0.1986708680980631
Trained batch 731 in epoch 0, gen_loss = 0.7028272039984744, disc_loss = 0.19866368833858053
Trained batch 732 in epoch 0, gen_loss = 0.703042475986936, disc_loss = 0.19848083922992707
Trained batch 733 in epoch 0, gen_loss = 0.7035772027777716, disc_loss = 0.1983810013352972
Trained batch 734 in epoch 0, gen_loss = 0.7035322942295853, disc_loss = 0.19832016424003507
Trained batch 735 in epoch 0, gen_loss = 0.7033882627425634, disc_loss = 0.19824362390057143
Trained batch 736 in epoch 0, gen_loss = 0.7038904592253298, disc_loss = 0.19839836292858445
Trained batch 737 in epoch 0, gen_loss = 0.7037565247395497, disc_loss = 0.1983401584123491
Trained batch 738 in epoch 0, gen_loss = 0.7039031330319638, disc_loss = 0.19820314007326054
Trained batch 739 in epoch 0, gen_loss = 0.7038887695283503, disc_loss = 0.19812767361416608
Trained batch 740 in epoch 0, gen_loss = 0.7037921680210412, disc_loss = 0.19808313020036208
Trained batch 741 in epoch 0, gen_loss = 0.7038039649834209, disc_loss = 0.19798184345624437
Trained batch 742 in epoch 0, gen_loss = 0.703964756082237, disc_loss = 0.19786070521625101
Trained batch 743 in epoch 0, gen_loss = 0.703753972205744, disc_loss = 0.19787019587081847
Trained batch 744 in epoch 0, gen_loss = 0.7038518021170725, disc_loss = 0.1977822214139988
Trained batch 745 in epoch 0, gen_loss = 0.7039482630689406, disc_loss = 0.19779703468234147
Trained batch 746 in epoch 0, gen_loss = 0.7041973810358698, disc_loss = 0.1975891506261974
Trained batch 747 in epoch 0, gen_loss = 0.7040575095278057, disc_loss = 0.19764221839377666
Trained batch 748 in epoch 0, gen_loss = 0.7042693836746292, disc_loss = 0.19748011363971138
Trained batch 749 in epoch 0, gen_loss = 0.7044013035694758, disc_loss = 0.19734131965289514
Trained batch 750 in epoch 0, gen_loss = 0.7042989563767348, disc_loss = 0.19720256728642235
Trained batch 751 in epoch 0, gen_loss = 0.7042226504058914, disc_loss = 0.19711709394307925
Trained batch 752 in epoch 0, gen_loss = 0.70422453847856, disc_loss = 0.19697730279073694
Trained batch 753 in epoch 0, gen_loss = 0.7041271742759396, disc_loss = 0.19687910255696872
Trained batch 754 in epoch 0, gen_loss = 0.7040363340583069, disc_loss = 0.19681760382820043
Trained batch 755 in epoch 0, gen_loss = 0.7039290178941671, disc_loss = 0.19677317428535648
Trained batch 756 in epoch 0, gen_loss = 0.7042203785327498, disc_loss = 0.19662555981589827
Trained batch 757 in epoch 0, gen_loss = 0.7043869434450422, disc_loss = 0.1964464572658836
Trained batch 758 in epoch 0, gen_loss = 0.7042438694532367, disc_loss = 0.19635436646836626
Trained batch 759 in epoch 0, gen_loss = 0.7046132504547897, disc_loss = 0.1965174301404898
Trained batch 760 in epoch 0, gen_loss = 0.7046068364389623, disc_loss = 0.19637232400359447
Trained batch 761 in epoch 0, gen_loss = 0.7046230689981791, disc_loss = 0.19629300812264205
Trained batch 762 in epoch 0, gen_loss = 0.7047564576759563, disc_loss = 0.19615963048900956
Trained batch 763 in epoch 0, gen_loss = 0.7049021236793533, disc_loss = 0.19604898100055715
Trained batch 764 in epoch 0, gen_loss = 0.7046855062051536, disc_loss = 0.19598283230333158
Trained batch 765 in epoch 0, gen_loss = 0.7048914497499367, disc_loss = 0.19583630888885759
Trained batch 766 in epoch 0, gen_loss = 0.7050094298697823, disc_loss = 0.1957071362745692
Trained batch 767 in epoch 0, gen_loss = 0.705162577990753, disc_loss = 0.19565393591619795
Trained batch 768 in epoch 0, gen_loss = 0.7052122418452611, disc_loss = 0.19554271195592512
Trained batch 769 in epoch 0, gen_loss = 0.7050986625544436, disc_loss = 0.1954813665020969
Trained batch 770 in epoch 0, gen_loss = 0.7051673862024967, disc_loss = 0.19536896626164246
Trained batch 771 in epoch 0, gen_loss = 0.7053652541239027, disc_loss = 0.195419527959426
Trained batch 772 in epoch 0, gen_loss = 0.7052085045315469, disc_loss = 0.19527495897496733
Trained batch 773 in epoch 0, gen_loss = 0.7051422625626088, disc_loss = 0.19518659713627526
Trained batch 774 in epoch 0, gen_loss = 0.7054610798820372, disc_loss = 0.19503159894337577
Trained batch 775 in epoch 0, gen_loss = 0.7054840889711356, disc_loss = 0.19491033980229236
Trained batch 776 in epoch 0, gen_loss = 0.7055139308040207, disc_loss = 0.19487494391603744
Trained batch 777 in epoch 0, gen_loss = 0.7059452472048737, disc_loss = 0.19489924242159778
Trained batch 778 in epoch 0, gen_loss = 0.7056071054338644, disc_loss = 0.19487169442581198
Trained batch 779 in epoch 0, gen_loss = 0.7062334629205557, disc_loss = 0.19470297551164642
Trained batch 780 in epoch 0, gen_loss = 0.7062744711944297, disc_loss = 0.19454251099306322
Trained batch 781 in epoch 0, gen_loss = 0.7061491681029425, disc_loss = 0.19444036116237606
Trained batch 782 in epoch 0, gen_loss = 0.7060561046137511, disc_loss = 0.1942867430600208
Trained batch 783 in epoch 0, gen_loss = 0.7058181278407574, disc_loss = 0.19429413636205528
Trained batch 784 in epoch 0, gen_loss = 0.7065379134408988, disc_loss = 0.1943675906438926
Trained batch 785 in epoch 0, gen_loss = 0.7069344706359407, disc_loss = 0.19414830586515158
Trained batch 786 in epoch 0, gen_loss = 0.7067759517187387, disc_loss = 0.19440292913982646
Trained batch 787 in epoch 0, gen_loss = 0.7073440917857408, disc_loss = 0.19424760414920936
Trained batch 788 in epoch 0, gen_loss = 0.7074585671056208, disc_loss = 0.1940847363356024
Trained batch 789 in epoch 0, gen_loss = 0.7075243537939048, disc_loss = 0.19396006020281134
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.7773317098617554, disc_loss = 0.13933423161506653
Trained batch 1 in epoch 1, gen_loss = 0.6686508059501648, disc_loss = 0.1374311000108719
Trained batch 2 in epoch 1, gen_loss = 0.7147474487622579, disc_loss = 0.12180991719166438
Trained batch 3 in epoch 1, gen_loss = 0.722386971116066, disc_loss = 0.11898743733763695
Trained batch 4 in epoch 1, gen_loss = 0.6844757676124573, disc_loss = 0.11916889101266862
Trained batch 5 in epoch 1, gen_loss = 0.7141970296700796, disc_loss = 0.11606355756521225
Trained batch 6 in epoch 1, gen_loss = 0.7343190823282514, disc_loss = 0.10620073495166642
Trained batch 7 in epoch 1, gen_loss = 0.7473241835832596, disc_loss = 0.10643624840304255
Trained batch 8 in epoch 1, gen_loss = 0.7384892106056213, disc_loss = 0.1097876922123962
Trained batch 9 in epoch 1, gen_loss = 0.7237327635288239, disc_loss = 0.11038071475923061
Trained batch 10 in epoch 1, gen_loss = 0.7305466045032848, disc_loss = 0.11319936642592604
Trained batch 11 in epoch 1, gen_loss = 0.7210590442021688, disc_loss = 0.11042475855598848
Trained batch 12 in epoch 1, gen_loss = 0.7294045503322895, disc_loss = 0.10896957063904175
Trained batch 13 in epoch 1, gen_loss = 0.7284933073180062, disc_loss = 0.10762085685772556
Trained batch 14 in epoch 1, gen_loss = 0.7331871430079142, disc_loss = 0.10540114268660546
Trained batch 15 in epoch 1, gen_loss = 0.7239579483866692, disc_loss = 0.10893573542125523
Trained batch 16 in epoch 1, gen_loss = 0.7487575516981237, disc_loss = 0.1137943673221504
Trained batch 17 in epoch 1, gen_loss = 0.7707328928841485, disc_loss = 0.11078086247046788
Trained batch 18 in epoch 1, gen_loss = 0.7535327249451688, disc_loss = 0.1324994069965262
Trained batch 19 in epoch 1, gen_loss = 0.7519801542162895, disc_loss = 0.1298648603260517
Trained batch 20 in epoch 1, gen_loss = 0.7689407822631654, disc_loss = 0.13332346152691615
Trained batch 21 in epoch 1, gen_loss = 0.7607783797112379, disc_loss = 0.13474314253438602
Trained batch 22 in epoch 1, gen_loss = 0.7624163485091665, disc_loss = 0.1331017211727474
Trained batch 23 in epoch 1, gen_loss = 0.7542476070423921, disc_loss = 0.1324064942697684
Trained batch 24 in epoch 1, gen_loss = 0.7545897853374481, disc_loss = 0.13209880888462067
Trained batch 25 in epoch 1, gen_loss = 0.7573199283618194, disc_loss = 0.13207920067585432
Trained batch 26 in epoch 1, gen_loss = 0.7512676506130783, disc_loss = 0.13108515077167088
Trained batch 27 in epoch 1, gen_loss = 0.7456945319260869, disc_loss = 0.1310098740671362
Trained batch 28 in epoch 1, gen_loss = 0.7386758337760794, disc_loss = 0.13247337269371953
Trained batch 29 in epoch 1, gen_loss = 0.7363734612862269, disc_loss = 0.1323872352639834
Trained batch 30 in epoch 1, gen_loss = 0.7347153434830327, disc_loss = 0.13170322247089877
Trained batch 31 in epoch 1, gen_loss = 0.7336957072839141, disc_loss = 0.13166258437559009
Trained batch 32 in epoch 1, gen_loss = 0.7356201184518409, disc_loss = 0.13004691989132852
Trained batch 33 in epoch 1, gen_loss = 0.7312780820271548, disc_loss = 0.12980164171141736
Trained batch 34 in epoch 1, gen_loss = 0.7283313878944941, disc_loss = 0.12963513455220632
Trained batch 35 in epoch 1, gen_loss = 0.732880932589372, disc_loss = 0.1351404237664408
Trained batch 36 in epoch 1, gen_loss = 0.7270766456384916, disc_loss = 0.13979069183807116
Trained batch 37 in epoch 1, gen_loss = 0.7293338077633005, disc_loss = 0.14070478689513707
Trained batch 38 in epoch 1, gen_loss = 0.726281749132352, disc_loss = 0.14145203335927084
Trained batch 39 in epoch 1, gen_loss = 0.7265216998755932, disc_loss = 0.14119205977767707
Trained batch 40 in epoch 1, gen_loss = 0.722666315189222, disc_loss = 0.14335911066793813
Trained batch 41 in epoch 1, gen_loss = 0.7212320246866771, disc_loss = 0.14398185962012836
Trained batch 42 in epoch 1, gen_loss = 0.7211502104304558, disc_loss = 0.14441208489412485
Trained batch 43 in epoch 1, gen_loss = 0.7207960845394568, disc_loss = 0.1429118908603083
Trained batch 44 in epoch 1, gen_loss = 0.7151751140753428, disc_loss = 0.14436834868457582
Trained batch 45 in epoch 1, gen_loss = 0.7157971126877744, disc_loss = 0.1442038522142431
Trained batch 46 in epoch 1, gen_loss = 0.7148082579704041, disc_loss = 0.1435578467046961
Trained batch 47 in epoch 1, gen_loss = 0.7166834889600674, disc_loss = 0.14209643860037127
Trained batch 48 in epoch 1, gen_loss = 0.7136834355033174, disc_loss = 0.1415622372712408
Trained batch 49 in epoch 1, gen_loss = 0.7171813279390336, disc_loss = 0.1405599234998226
Trained batch 50 in epoch 1, gen_loss = 0.7176057783996358, disc_loss = 0.14111153094791898
Trained batch 51 in epoch 1, gen_loss = 0.7147712541314272, disc_loss = 0.14218892200061908
Trained batch 52 in epoch 1, gen_loss = 0.7135086515039768, disc_loss = 0.14374405468972223
Trained batch 53 in epoch 1, gen_loss = 0.7179058387323662, disc_loss = 0.14717742400588812
Trained batch 54 in epoch 1, gen_loss = 0.7155797161839225, disc_loss = 0.1484518450769511
Trained batch 55 in epoch 1, gen_loss = 0.7144256963261536, disc_loss = 0.14969886426946946
Trained batch 56 in epoch 1, gen_loss = 0.7125962977869469, disc_loss = 0.15053279161976094
Trained batch 57 in epoch 1, gen_loss = 0.7089529063167244, disc_loss = 0.15101620259469953
Trained batch 58 in epoch 1, gen_loss = 0.7103143652616921, disc_loss = 0.15164680968401795
Trained batch 59 in epoch 1, gen_loss = 0.7098936940232913, disc_loss = 0.15105521890024345
Trained batch 60 in epoch 1, gen_loss = 0.7093708051032708, disc_loss = 0.15060734345776136
Trained batch 61 in epoch 1, gen_loss = 0.7098340137350944, disc_loss = 0.150383374263202
Trained batch 62 in epoch 1, gen_loss = 0.7068029694140904, disc_loss = 0.1507490583591991
Trained batch 63 in epoch 1, gen_loss = 0.708318944554776, disc_loss = 0.1504423258593306
Trained batch 64 in epoch 1, gen_loss = 0.7098907759556403, disc_loss = 0.14997973854725177
Trained batch 65 in epoch 1, gen_loss = 0.7102120586416938, disc_loss = 0.1487446395736752
Trained batch 66 in epoch 1, gen_loss = 0.7074761635331965, disc_loss = 0.1484139323679369
Trained batch 67 in epoch 1, gen_loss = 0.709893743343213, disc_loss = 0.14718950463130193
Trained batch 68 in epoch 1, gen_loss = 0.715441172969514, disc_loss = 0.145943116882573
Trained batch 69 in epoch 1, gen_loss = 0.7142522347824914, disc_loss = 0.14583115300961902
Trained batch 70 in epoch 1, gen_loss = 0.7173618451810219, disc_loss = 0.14470824494328297
Trained batch 71 in epoch 1, gen_loss = 0.7211712164183458, disc_loss = 0.14327597142093712
Trained batch 72 in epoch 1, gen_loss = 0.7229332405410401, disc_loss = 0.1418304668407734
Trained batch 73 in epoch 1, gen_loss = 0.7227949697423626, disc_loss = 0.14088786368233128
Trained batch 74 in epoch 1, gen_loss = 0.7239501623312632, disc_loss = 0.1403219043711821
Trained batch 75 in epoch 1, gen_loss = 0.7230477846766773, disc_loss = 0.13993410300463438
Trained batch 76 in epoch 1, gen_loss = 0.7281185864628136, disc_loss = 0.13993455106755356
Trained batch 77 in epoch 1, gen_loss = 0.728279214256849, disc_loss = 0.13883282454350057
Trained batch 78 in epoch 1, gen_loss = 0.7265166251719752, disc_loss = 0.1397419155021257
Trained batch 79 in epoch 1, gen_loss = 0.7299022797495127, disc_loss = 0.13869449361227454
Trained batch 80 in epoch 1, gen_loss = 0.7384669828562089, disc_loss = 0.13818858467318393
Trained batch 81 in epoch 1, gen_loss = 0.7359978196824469, disc_loss = 0.14256506317817583
Trained batch 82 in epoch 1, gen_loss = 0.7352724193808544, disc_loss = 0.14213838423770594
Trained batch 83 in epoch 1, gen_loss = 0.7382461382519632, disc_loss = 0.14228211773470753
Trained batch 84 in epoch 1, gen_loss = 0.7380096950951744, disc_loss = 0.1415216842556701
Trained batch 85 in epoch 1, gen_loss = 0.7376815035592678, disc_loss = 0.14181797280041283
Trained batch 86 in epoch 1, gen_loss = 0.7377903553946265, disc_loss = 0.14186955358961534
Trained batch 87 in epoch 1, gen_loss = 0.7390904335135763, disc_loss = 0.1421811620027504
Trained batch 88 in epoch 1, gen_loss = 0.7390652617041984, disc_loss = 0.14142825483773533
Trained batch 89 in epoch 1, gen_loss = 0.7369671175877254, disc_loss = 0.14268920111159483
Trained batch 90 in epoch 1, gen_loss = 0.7390212714672089, disc_loss = 0.14332234110314768
Trained batch 91 in epoch 1, gen_loss = 0.7396770058118779, disc_loss = 0.14297749980798233
Trained batch 92 in epoch 1, gen_loss = 0.7394089330268162, disc_loss = 0.14226233658771362
Trained batch 93 in epoch 1, gen_loss = 0.7388663276078853, disc_loss = 0.14124987706383493
Trained batch 94 in epoch 1, gen_loss = 0.7387213013674083, disc_loss = 0.1405409642348164
Trained batch 95 in epoch 1, gen_loss = 0.7409272768224279, disc_loss = 0.1398169630750393
Trained batch 96 in epoch 1, gen_loss = 0.7425040464425824, disc_loss = 0.13880190349270388
Trained batch 97 in epoch 1, gen_loss = 0.7414121053048542, disc_loss = 0.13851222095592897
Trained batch 98 in epoch 1, gen_loss = 0.7426859305964576, disc_loss = 0.13762194821328827
Trained batch 99 in epoch 1, gen_loss = 0.7439506867527962, disc_loss = 0.1375608342885971
Trained batch 100 in epoch 1, gen_loss = 0.7416373984058304, disc_loss = 0.1384059707126995
Trained batch 101 in epoch 1, gen_loss = 0.7427975205229778, disc_loss = 0.1383251934951427
Trained batch 102 in epoch 1, gen_loss = 0.7433671809515907, disc_loss = 0.13733723014593124
Trained batch 103 in epoch 1, gen_loss = 0.742620952713948, disc_loss = 0.13658989285333797
Trained batch 104 in epoch 1, gen_loss = 0.7433144787947337, disc_loss = 0.13653101743686766
Trained batch 105 in epoch 1, gen_loss = 0.7413716290919286, disc_loss = 0.13655813200012692
Trained batch 106 in epoch 1, gen_loss = 0.7408909449510486, disc_loss = 0.13686940540498663
Trained batch 107 in epoch 1, gen_loss = 0.7388621952246737, disc_loss = 0.13750780615265723
Trained batch 108 in epoch 1, gen_loss = 0.7399229289741691, disc_loss = 0.13667306153599276
Trained batch 109 in epoch 1, gen_loss = 0.7400864479216662, disc_loss = 0.13580372370779514
Trained batch 110 in epoch 1, gen_loss = 0.7397123551046526, disc_loss = 0.1351752130499294
Trained batch 111 in epoch 1, gen_loss = 0.7381821399820703, disc_loss = 0.13543762502792692
Trained batch 112 in epoch 1, gen_loss = 0.7401945899545619, disc_loss = 0.1349327898196942
Trained batch 113 in epoch 1, gen_loss = 0.7401590621785114, disc_loss = 0.1342669829987643
Trained batch 114 in epoch 1, gen_loss = 0.7420865185882735, disc_loss = 0.1334182133493216
Trained batch 115 in epoch 1, gen_loss = 0.7411341515594515, disc_loss = 0.13390316550844703
Trained batch 116 in epoch 1, gen_loss = 0.7435310653641692, disc_loss = 0.13425003100409466
Trained batch 117 in epoch 1, gen_loss = 0.7433584814859648, disc_loss = 0.13366868290103087
Trained batch 118 in epoch 1, gen_loss = 0.7434143887347534, disc_loss = 0.13364190420433253
Trained batch 119 in epoch 1, gen_loss = 0.7436081719895203, disc_loss = 0.13350929624090593
Trained batch 120 in epoch 1, gen_loss = 0.7435874729609686, disc_loss = 0.13421545645668487
Trained batch 121 in epoch 1, gen_loss = 0.7410425262861564, disc_loss = 0.13619164982047238
Trained batch 122 in epoch 1, gen_loss = 0.7429527187250494, disc_loss = 0.13706163607719468
Trained batch 123 in epoch 1, gen_loss = 0.7426557230853266, disc_loss = 0.13683496481708943
Trained batch 124 in epoch 1, gen_loss = 0.7424678857326508, disc_loss = 0.13650891184806824
Trained batch 125 in epoch 1, gen_loss = 0.742786159354543, disc_loss = 0.13722036542400481
Trained batch 126 in epoch 1, gen_loss = 0.741795763490707, disc_loss = 0.1380565074954446
Trained batch 127 in epoch 1, gen_loss = 0.741495854454115, disc_loss = 0.13880811992567033
Trained batch 128 in epoch 1, gen_loss = 0.7405654360619627, disc_loss = 0.13929652278275453
Trained batch 129 in epoch 1, gen_loss = 0.7409427012388523, disc_loss = 0.1400144406236135
Trained batch 130 in epoch 1, gen_loss = 0.7401923221031218, disc_loss = 0.14010505116622868
Trained batch 131 in epoch 1, gen_loss = 0.7400432443528464, disc_loss = 0.14004252354303995
Trained batch 132 in epoch 1, gen_loss = 0.7400957236164495, disc_loss = 0.1403591957755555
Trained batch 133 in epoch 1, gen_loss = 0.7395375181934727, disc_loss = 0.13998266882193622
Trained batch 134 in epoch 1, gen_loss = 0.7382292577513943, disc_loss = 0.13995319444824147
Trained batch 135 in epoch 1, gen_loss = 0.7383723300607765, disc_loss = 0.1400763238506282
Trained batch 136 in epoch 1, gen_loss = 0.7385872748211353, disc_loss = 0.1400098125756222
Trained batch 137 in epoch 1, gen_loss = 0.7384149948323983, disc_loss = 0.1404119567486687
Trained batch 138 in epoch 1, gen_loss = 0.7400763114150479, disc_loss = 0.14146346941911916
Trained batch 139 in epoch 1, gen_loss = 0.7390418489064489, disc_loss = 0.1415760842284986
Trained batch 140 in epoch 1, gen_loss = 0.7376618053473479, disc_loss = 0.14141623966448696
Trained batch 141 in epoch 1, gen_loss = 0.7381701685593162, disc_loss = 0.14133579614506642
Trained batch 142 in epoch 1, gen_loss = 0.7371882781698987, disc_loss = 0.14171470498496835
Trained batch 143 in epoch 1, gen_loss = 0.737369204353955, disc_loss = 0.1419348770028187
Trained batch 144 in epoch 1, gen_loss = 0.7374019028811619, disc_loss = 0.14219893694951616
Trained batch 145 in epoch 1, gen_loss = 0.7369046396996877, disc_loss = 0.14204555071175914
Trained batch 146 in epoch 1, gen_loss = 0.7363793393787073, disc_loss = 0.14211953147536233
Trained batch 147 in epoch 1, gen_loss = 0.7364459502938632, disc_loss = 0.14166523199025038
Trained batch 148 in epoch 1, gen_loss = 0.7380305290622199, disc_loss = 0.14145392379504723
Trained batch 149 in epoch 1, gen_loss = 0.7369833972056706, disc_loss = 0.14239425381024678
Trained batch 150 in epoch 1, gen_loss = 0.7382880459163362, disc_loss = 0.14243983215843606
Trained batch 151 in epoch 1, gen_loss = 0.7380655637305034, disc_loss = 0.1424530576914549
Trained batch 152 in epoch 1, gen_loss = 0.7371056054542268, disc_loss = 0.1427861723829718
Trained batch 153 in epoch 1, gen_loss = 0.7379101284525611, disc_loss = 0.14299789100111304
Trained batch 154 in epoch 1, gen_loss = 0.7369773028358336, disc_loss = 0.1426875581183741
Trained batch 155 in epoch 1, gen_loss = 0.7382311498125395, disc_loss = 0.1421022138868769
Trained batch 156 in epoch 1, gen_loss = 0.7372908172713724, disc_loss = 0.14208613400151776
Trained batch 157 in epoch 1, gen_loss = 0.7383445076927354, disc_loss = 0.1417722532030525
Trained batch 158 in epoch 1, gen_loss = 0.7375177289329985, disc_loss = 0.14161174376524469
Trained batch 159 in epoch 1, gen_loss = 0.7379595952108502, disc_loss = 0.14125324490014463
Trained batch 160 in epoch 1, gen_loss = 0.7382546953903222, disc_loss = 0.14097306819528527
Trained batch 161 in epoch 1, gen_loss = 0.738661034055698, disc_loss = 0.14098888444771737
Trained batch 162 in epoch 1, gen_loss = 0.7381221321097181, disc_loss = 0.14076784177700435
Trained batch 163 in epoch 1, gen_loss = 0.7387744408191704, disc_loss = 0.1404797649011016
Trained batch 164 in epoch 1, gen_loss = 0.7387559263995199, disc_loss = 0.14013365861592872
Trained batch 165 in epoch 1, gen_loss = 0.7391388385769833, disc_loss = 0.13987831051001348
Trained batch 166 in epoch 1, gen_loss = 0.7392434197628569, disc_loss = 0.1400810877853882
Trained batch 167 in epoch 1, gen_loss = 0.7378220893442631, disc_loss = 0.1423686967852215
Trained batch 168 in epoch 1, gen_loss = 0.7386986558606639, disc_loss = 0.14261714891480975
Trained batch 169 in epoch 1, gen_loss = 0.7394576148075216, disc_loss = 0.14292113673599327
Trained batch 170 in epoch 1, gen_loss = 0.7387573281575365, disc_loss = 0.1431698108756403
Trained batch 171 in epoch 1, gen_loss = 0.7377473789938661, disc_loss = 0.14377148776466764
Trained batch 172 in epoch 1, gen_loss = 0.7387367557583516, disc_loss = 0.14504636107066463
Trained batch 173 in epoch 1, gen_loss = 0.7381671244043043, disc_loss = 0.14603761727011752
Trained batch 174 in epoch 1, gen_loss = 0.73802169748715, disc_loss = 0.1462703106871673
Trained batch 175 in epoch 1, gen_loss = 0.7373123580420559, disc_loss = 0.1466217352373695
Trained batch 176 in epoch 1, gen_loss = 0.7376274070834036, disc_loss = 0.14693069253853486
Trained batch 177 in epoch 1, gen_loss = 0.7367787506808056, disc_loss = 0.1471385940532671
Trained batch 178 in epoch 1, gen_loss = 0.7367732479918603, disc_loss = 0.14709891285226998
Trained batch 179 in epoch 1, gen_loss = 0.7364134641157256, disc_loss = 0.14688852410763503
Trained batch 180 in epoch 1, gen_loss = 0.7361232844176213, disc_loss = 0.14686244691192116
Trained batch 181 in epoch 1, gen_loss = 0.7368231243812121, disc_loss = 0.1474225594570021
Trained batch 182 in epoch 1, gen_loss = 0.7364358463899685, disc_loss = 0.1474166022908818
Trained batch 183 in epoch 1, gen_loss = 0.7355490927786931, disc_loss = 0.14731168777317458
Trained batch 184 in epoch 1, gen_loss = 0.7356362760066986, disc_loss = 0.14766334695993244
Trained batch 185 in epoch 1, gen_loss = 0.7357082243568154, disc_loss = 0.1474087089901009
Trained batch 186 in epoch 1, gen_loss = 0.7352187552235343, disc_loss = 0.14729663424871184
Trained batch 187 in epoch 1, gen_loss = 0.7353744895217267, disc_loss = 0.14713103072519632
Trained batch 188 in epoch 1, gen_loss = 0.7358053413333085, disc_loss = 0.14677913851602367
Trained batch 189 in epoch 1, gen_loss = 0.735510914106118, disc_loss = 0.14631906263530253
Trained batch 190 in epoch 1, gen_loss = 0.7354244188800532, disc_loss = 0.14591772341369336
Trained batch 191 in epoch 1, gen_loss = 0.7358196242712438, disc_loss = 0.145535942458082
Trained batch 192 in epoch 1, gen_loss = 0.735676491044346, disc_loss = 0.14529760751313497
Trained batch 193 in epoch 1, gen_loss = 0.7357298816295014, disc_loss = 0.14510832932422457
Trained batch 194 in epoch 1, gen_loss = 0.7363389087028992, disc_loss = 0.14498047417937182
Trained batch 195 in epoch 1, gen_loss = 0.7361443558213662, disc_loss = 0.14473024578955102
Trained batch 196 in epoch 1, gen_loss = 0.7355734014571621, disc_loss = 0.1447908143668913
Trained batch 197 in epoch 1, gen_loss = 0.7367249478896459, disc_loss = 0.1446294736944967
Trained batch 198 in epoch 1, gen_loss = 0.7369613298519173, disc_loss = 0.1442720212192092
Trained batch 199 in epoch 1, gen_loss = 0.736600937396288, disc_loss = 0.14402095722034575
Trained batch 200 in epoch 1, gen_loss = 0.7356928609200378, disc_loss = 0.14423866764600599
Trained batch 201 in epoch 1, gen_loss = 0.7361680468415269, disc_loss = 0.14392104016450963
Trained batch 202 in epoch 1, gen_loss = 0.7371489947358963, disc_loss = 0.14338355986722584
Trained batch 203 in epoch 1, gen_loss = 0.7368194772040143, disc_loss = 0.1430991741773837
Trained batch 204 in epoch 1, gen_loss = 0.7380766509509669, disc_loss = 0.14337941806127386
Trained batch 205 in epoch 1, gen_loss = 0.7374775807545023, disc_loss = 0.14343783033342616
Trained batch 206 in epoch 1, gen_loss = 0.7373223971341543, disc_loss = 0.14334534650335565
Trained batch 207 in epoch 1, gen_loss = 0.7366591819490378, disc_loss = 0.143455476159803
Trained batch 208 in epoch 1, gen_loss = 0.7366000711917877, disc_loss = 0.14307836812149965
Trained batch 209 in epoch 1, gen_loss = 0.7359991469553538, disc_loss = 0.142989169398234
Trained batch 210 in epoch 1, gen_loss = 0.737979706288514, disc_loss = 0.14323657036039503
Trained batch 211 in epoch 1, gen_loss = 0.7374387123393562, disc_loss = 0.1429982278320306
Trained batch 212 in epoch 1, gen_loss = 0.7365203126215599, disc_loss = 0.14271495384579533
Trained batch 213 in epoch 1, gen_loss = 0.7364466556600321, disc_loss = 0.14247534248246768
Trained batch 214 in epoch 1, gen_loss = 0.7372994282910991, disc_loss = 0.14202387802476107
Trained batch 215 in epoch 1, gen_loss = 0.7377790161580952, disc_loss = 0.14153297474883772
Trained batch 216 in epoch 1, gen_loss = 0.7379249676306676, disc_loss = 0.14169076594957558
Trained batch 217 in epoch 1, gen_loss = 0.7375102085531304, disc_loss = 0.14159337214168605
Trained batch 218 in epoch 1, gen_loss = 0.7382927794162542, disc_loss = 0.14175958096232588
Trained batch 219 in epoch 1, gen_loss = 0.7377144240520217, disc_loss = 0.14201116130094638
Trained batch 220 in epoch 1, gen_loss = 0.7378365590291864, disc_loss = 0.14195935982721963
Trained batch 221 in epoch 1, gen_loss = 0.7378044433153428, disc_loss = 0.14180665679678722
Trained batch 222 in epoch 1, gen_loss = 0.7379484744617223, disc_loss = 0.14161498388567847
Trained batch 223 in epoch 1, gen_loss = 0.7373807559322033, disc_loss = 0.14146710657847247
Trained batch 224 in epoch 1, gen_loss = 0.7382546190420787, disc_loss = 0.1413239486184385
Trained batch 225 in epoch 1, gen_loss = 0.7380042702487085, disc_loss = 0.14096964102864792
Trained batch 226 in epoch 1, gen_loss = 0.7384354951360678, disc_loss = 0.14073355829072418
Trained batch 227 in epoch 1, gen_loss = 0.7388458776108006, disc_loss = 0.14046285842267567
Trained batch 228 in epoch 1, gen_loss = 0.7389261906063713, disc_loss = 0.140229538652444
Trained batch 229 in epoch 1, gen_loss = 0.7397865887569345, disc_loss = 0.14018170015643472
Trained batch 230 in epoch 1, gen_loss = 0.7400775720804801, disc_loss = 0.13968971653869658
Trained batch 231 in epoch 1, gen_loss = 0.7397152181586315, disc_loss = 0.13958352246996145
Trained batch 232 in epoch 1, gen_loss = 0.7401013140258871, disc_loss = 0.139534817185141
Trained batch 233 in epoch 1, gen_loss = 0.7395951433314217, disc_loss = 0.13959021766025287
Trained batch 234 in epoch 1, gen_loss = 0.740246268155727, disc_loss = 0.13946929474143271
Trained batch 235 in epoch 1, gen_loss = 0.7397377196762521, disc_loss = 0.13937564189466883
Trained batch 236 in epoch 1, gen_loss = 0.7410813543615462, disc_loss = 0.13941056713587624
Trained batch 237 in epoch 1, gen_loss = 0.7399264872074127, disc_loss = 0.14082945878578335
Trained batch 238 in epoch 1, gen_loss = 0.7412321380491536, disc_loss = 0.14115415814344354
Trained batch 239 in epoch 1, gen_loss = 0.7409590793152651, disc_loss = 0.14116444185686608
Trained batch 240 in epoch 1, gen_loss = 0.7400450169792808, disc_loss = 0.14113541814610672
Trained batch 241 in epoch 1, gen_loss = 0.7399783104904427, disc_loss = 0.14118830762680404
Trained batch 242 in epoch 1, gen_loss = 0.7398827961442892, disc_loss = 0.14121625681288938
Trained batch 243 in epoch 1, gen_loss = 0.7403455454795087, disc_loss = 0.14130463739704402
Trained batch 244 in epoch 1, gen_loss = 0.7399544723179876, disc_loss = 0.14131037649147365
Trained batch 245 in epoch 1, gen_loss = 0.7402778362355581, disc_loss = 0.14125871181306315
Trained batch 246 in epoch 1, gen_loss = 0.7405728615729915, disc_loss = 0.14083967896306562
Trained batch 247 in epoch 1, gen_loss = 0.7399013919695732, disc_loss = 0.1409813962846754
Trained batch 248 in epoch 1, gen_loss = 0.7403983243976731, disc_loss = 0.1410772887069777
Trained batch 249 in epoch 1, gen_loss = 0.741448662519455, disc_loss = 0.1407777273505926
Trained batch 250 in epoch 1, gen_loss = 0.7405007270227866, disc_loss = 0.14161310239557726
Trained batch 251 in epoch 1, gen_loss = 0.7408960447424934, disc_loss = 0.14170289345617806
Trained batch 252 in epoch 1, gen_loss = 0.7414013882399547, disc_loss = 0.1419633671553003
Trained batch 253 in epoch 1, gen_loss = 0.7409629049732929, disc_loss = 0.14181396272766777
Trained batch 254 in epoch 1, gen_loss = 0.7403933864013822, disc_loss = 0.14171983232977345
Trained batch 255 in epoch 1, gen_loss = 0.740888906409964, disc_loss = 0.14179944615170825
Trained batch 256 in epoch 1, gen_loss = 0.7416261599221582, disc_loss = 0.14131033303875637
Trained batch 257 in epoch 1, gen_loss = 0.7412062023961267, disc_loss = 0.14120039906237244
Trained batch 258 in epoch 1, gen_loss = 0.7409629122170702, disc_loss = 0.14094490246509264
Trained batch 259 in epoch 1, gen_loss = 0.7406880729473554, disc_loss = 0.1407793044972305
Trained batch 260 in epoch 1, gen_loss = 0.7414994522986285, disc_loss = 0.14076539953292785
Trained batch 261 in epoch 1, gen_loss = 0.7407595224052895, disc_loss = 0.1406124103885457
Trained batch 262 in epoch 1, gen_loss = 0.7406158671632919, disc_loss = 0.14046218834760751
Trained batch 263 in epoch 1, gen_loss = 0.7414314649773367, disc_loss = 0.14044938136992807
Trained batch 264 in epoch 1, gen_loss = 0.7416667697564611, disc_loss = 0.14021834142787276
Trained batch 265 in epoch 1, gen_loss = 0.7412850168862737, disc_loss = 0.14024653102978504
Trained batch 266 in epoch 1, gen_loss = 0.7418716293149227, disc_loss = 0.13993379851098586
Trained batch 267 in epoch 1, gen_loss = 0.7431965247908635, disc_loss = 0.14021828245899792
Trained batch 268 in epoch 1, gen_loss = 0.7421076139331307, disc_loss = 0.1407215749034762
Trained batch 269 in epoch 1, gen_loss = 0.7419102316653287, disc_loss = 0.1405510748771054
Trained batch 270 in epoch 1, gen_loss = 0.7425654938520101, disc_loss = 0.14044246545604455
Trained batch 271 in epoch 1, gen_loss = 0.7422391243059846, disc_loss = 0.1402128143578439
Trained batch 272 in epoch 1, gen_loss = 0.7415299462529766, disc_loss = 0.14024594260359202
Trained batch 273 in epoch 1, gen_loss = 0.7419530865702316, disc_loss = 0.14006066494315428
Trained batch 274 in epoch 1, gen_loss = 0.7419022314115004, disc_loss = 0.13981451566246422
Trained batch 275 in epoch 1, gen_loss = 0.7421228253970975, disc_loss = 0.13986959260469978
Trained batch 276 in epoch 1, gen_loss = 0.7418817702398404, disc_loss = 0.13980005932333023
Trained batch 277 in epoch 1, gen_loss = 0.7415727088562876, disc_loss = 0.13963990878956994
Trained batch 278 in epoch 1, gen_loss = 0.7411542424805275, disc_loss = 0.13955994498478683
Trained batch 279 in epoch 1, gen_loss = 0.7412502081266471, disc_loss = 0.13964192865283362
Trained batch 280 in epoch 1, gen_loss = 0.742130956934016, disc_loss = 0.13959506040710784
Trained batch 281 in epoch 1, gen_loss = 0.7417950261357829, disc_loss = 0.13950405719670209
Trained batch 282 in epoch 1, gen_loss = 0.7413716138251679, disc_loss = 0.13963251137717664
Trained batch 283 in epoch 1, gen_loss = 0.7418965255500565, disc_loss = 0.13976469421496904
Trained batch 284 in epoch 1, gen_loss = 0.7420643769858176, disc_loss = 0.13947590561420248
Trained batch 285 in epoch 1, gen_loss = 0.741846165352768, disc_loss = 0.13949200691381744
Trained batch 286 in epoch 1, gen_loss = 0.7416643007084053, disc_loss = 0.13935419260962292
Trained batch 287 in epoch 1, gen_loss = 0.7419471257469721, disc_loss = 0.1390867924848054
Trained batch 288 in epoch 1, gen_loss = 0.7425871539899634, disc_loss = 0.13891161898969573
Trained batch 289 in epoch 1, gen_loss = 0.7422718974023029, disc_loss = 0.13889338187231073
Trained batch 290 in epoch 1, gen_loss = 0.7423892427760711, disc_loss = 0.13858886296729656
Trained batch 291 in epoch 1, gen_loss = 0.7434145094801302, disc_loss = 0.13828861610708784
Trained batch 292 in epoch 1, gen_loss = 0.7440352725697865, disc_loss = 0.1379547935970916
Trained batch 293 in epoch 1, gen_loss = 0.7434767400529109, disc_loss = 0.13800801154935644
Trained batch 294 in epoch 1, gen_loss = 0.7440088402416747, disc_loss = 0.137950802436572
Trained batch 295 in epoch 1, gen_loss = 0.7441075972809985, disc_loss = 0.13770223477528104
Trained batch 296 in epoch 1, gen_loss = 0.7437489675953733, disc_loss = 0.13758581468477996
Trained batch 297 in epoch 1, gen_loss = 0.7445457460696265, disc_loss = 0.13771565641657818
Trained batch 298 in epoch 1, gen_loss = 0.7440549229897783, disc_loss = 0.13763608076425898
Trained batch 299 in epoch 1, gen_loss = 0.7443415442109108, disc_loss = 0.1375323970677952
Trained batch 300 in epoch 1, gen_loss = 0.7449103418576757, disc_loss = 0.13717810234729436
Trained batch 301 in epoch 1, gen_loss = 0.7452927639350196, disc_loss = 0.13691633615938836
Trained batch 302 in epoch 1, gen_loss = 0.7455232878132622, disc_loss = 0.13681854501292848
Trained batch 303 in epoch 1, gen_loss = 0.7451027032772177, disc_loss = 0.1367369693838746
Trained batch 304 in epoch 1, gen_loss = 0.7459467310397352, disc_loss = 0.13676139738593923
Trained batch 305 in epoch 1, gen_loss = 0.7456214214656868, disc_loss = 0.13661475169770662
Trained batch 306 in epoch 1, gen_loss = 0.7451620252396463, disc_loss = 0.13675368047571143
Trained batch 307 in epoch 1, gen_loss = 0.7470480469720704, disc_loss = 0.13704215833772118
Trained batch 308 in epoch 1, gen_loss = 0.7471127970126069, disc_loss = 0.13678767203585424
Trained batch 309 in epoch 1, gen_loss = 0.7470403683762397, disc_loss = 0.13704152594530775
Trained batch 310 in epoch 1, gen_loss = 0.7472119355316714, disc_loss = 0.13690950895788392
Trained batch 311 in epoch 1, gen_loss = 0.7470953656503787, disc_loss = 0.1369434933667668
Trained batch 312 in epoch 1, gen_loss = 0.7469491555858344, disc_loss = 0.13674929228048927
Trained batch 313 in epoch 1, gen_loss = 0.7468006087906042, disc_loss = 0.13668950276366273
Trained batch 314 in epoch 1, gen_loss = 0.7472227106964777, disc_loss = 0.13659331769578986
Trained batch 315 in epoch 1, gen_loss = 0.7467756530717958, disc_loss = 0.13646611903169298
Trained batch 316 in epoch 1, gen_loss = 0.7480662733034381, disc_loss = 0.13641053167309858
Trained batch 317 in epoch 1, gen_loss = 0.7472539316370802, disc_loss = 0.13666548094354897
Trained batch 318 in epoch 1, gen_loss = 0.7479828611997228, disc_loss = 0.1364103273129482
Trained batch 319 in epoch 1, gen_loss = 0.7483213677071034, disc_loss = 0.1361928648839239
Trained batch 320 in epoch 1, gen_loss = 0.7484080669850204, disc_loss = 0.13616691586036364
Trained batch 321 in epoch 1, gen_loss = 0.74846636665904, disc_loss = 0.13587767101523485
Trained batch 322 in epoch 1, gen_loss = 0.7486432979904092, disc_loss = 0.13578318302222633
Trained batch 323 in epoch 1, gen_loss = 0.748275490546668, disc_loss = 0.13577503773648245
Trained batch 324 in epoch 1, gen_loss = 0.7485108820291666, disc_loss = 0.13589901606050822
Trained batch 325 in epoch 1, gen_loss = 0.7484051851224314, disc_loss = 0.13585631684771526
Trained batch 326 in epoch 1, gen_loss = 0.7474647939934278, disc_loss = 0.13661808976818116
Trained batch 327 in epoch 1, gen_loss = 0.7483257590452346, disc_loss = 0.13693052964716604
Trained batch 328 in epoch 1, gen_loss = 0.7485484668367902, disc_loss = 0.13690919746675934
Trained batch 329 in epoch 1, gen_loss = 0.7483674104466583, disc_loss = 0.13677467117368272
Trained batch 330 in epoch 1, gen_loss = 0.7478795747562478, disc_loss = 0.13688760888382928
Trained batch 331 in epoch 1, gen_loss = 0.7477288268596293, disc_loss = 0.13700444054374672
Trained batch 332 in epoch 1, gen_loss = 0.747262683090147, disc_loss = 0.13715468965157554
Trained batch 333 in epoch 1, gen_loss = 0.7471138145216925, disc_loss = 0.13713276016520348
Trained batch 334 in epoch 1, gen_loss = 0.746982480251967, disc_loss = 0.13698606011249237
Trained batch 335 in epoch 1, gen_loss = 0.7469637689313718, disc_loss = 0.13679839578080213
Trained batch 336 in epoch 1, gen_loss = 0.7475256471499491, disc_loss = 0.13669509167067198
Trained batch 337 in epoch 1, gen_loss = 0.7472170098469808, disc_loss = 0.13655646703586247
Trained batch 338 in epoch 1, gen_loss = 0.7467850802746494, disc_loss = 0.13649383480152374
Trained batch 339 in epoch 1, gen_loss = 0.7470307479009909, disc_loss = 0.13648305669536484
Trained batch 340 in epoch 1, gen_loss = 0.7472795844952033, disc_loss = 0.1362816786934291
Trained batch 341 in epoch 1, gen_loss = 0.7465276907236256, disc_loss = 0.13658589811461885
Trained batch 342 in epoch 1, gen_loss = 0.7476812525497581, disc_loss = 0.13676049096004783
Trained batch 343 in epoch 1, gen_loss = 0.7473712914385074, disc_loss = 0.13670543003502453
Trained batch 344 in epoch 1, gen_loss = 0.7475256316039873, disc_loss = 0.13654671145630057
Trained batch 345 in epoch 1, gen_loss = 0.7479226321326515, disc_loss = 0.13651123072822832
Trained batch 346 in epoch 1, gen_loss = 0.7482790686726913, disc_loss = 0.13632686997116986
Trained batch 347 in epoch 1, gen_loss = 0.7478016811026924, disc_loss = 0.1363591292562584
Trained batch 348 in epoch 1, gen_loss = 0.7494236033591295, disc_loss = 0.13641013946373517
Trained batch 349 in epoch 1, gen_loss = 0.7492441653353827, disc_loss = 0.13623035669858966
Trained batch 350 in epoch 1, gen_loss = 0.7488881858155938, disc_loss = 0.13637360323889133
Trained batch 351 in epoch 1, gen_loss = 0.7494238617575981, disc_loss = 0.13627155354267664
Trained batch 352 in epoch 1, gen_loss = 0.7501416171745268, disc_loss = 0.13601011976536373
Trained batch 353 in epoch 1, gen_loss = 0.7497911859871977, disc_loss = 0.135965250763979
Trained batch 354 in epoch 1, gen_loss = 0.7497423370959053, disc_loss = 0.13583636253967252
Trained batch 355 in epoch 1, gen_loss = 0.7509641437215752, disc_loss = 0.13651819421983
Trained batch 356 in epoch 1, gen_loss = 0.7503689727028545, disc_loss = 0.13664833015399655
Trained batch 357 in epoch 1, gen_loss = 0.7504044102723372, disc_loss = 0.1364972113095765
Trained batch 358 in epoch 1, gen_loss = 0.7504457574866941, disc_loss = 0.1367983905582956
Trained batch 359 in epoch 1, gen_loss = 0.7503060659600629, disc_loss = 0.13668628228931792
Trained batch 360 in epoch 1, gen_loss = 0.7500900344670314, disc_loss = 0.13660582032704782
Trained batch 361 in epoch 1, gen_loss = 0.7501181325365825, disc_loss = 0.13681113188417413
Trained batch 362 in epoch 1, gen_loss = 0.7498156013731786, disc_loss = 0.13682696986276421
Trained batch 363 in epoch 1, gen_loss = 0.7495361452738007, disc_loss = 0.13669657821326955
Trained batch 364 in epoch 1, gen_loss = 0.75011658644023, disc_loss = 0.13691563083190625
Trained batch 365 in epoch 1, gen_loss = 0.7503957871368022, disc_loss = 0.13670825798960168
Trained batch 366 in epoch 1, gen_loss = 0.749750040938484, disc_loss = 0.13702924078081707
Trained batch 367 in epoch 1, gen_loss = 0.7496786110265099, disc_loss = 0.1370374136351292
Trained batch 368 in epoch 1, gen_loss = 0.7495256632485687, disc_loss = 0.13722119558612667
Trained batch 369 in epoch 1, gen_loss = 0.7492422215841912, disc_loss = 0.1373028952880083
Trained batch 370 in epoch 1, gen_loss = 0.7496531616163382, disc_loss = 0.13731800718107473
Trained batch 371 in epoch 1, gen_loss = 0.7492827310837725, disc_loss = 0.13722624637246614
Trained batch 372 in epoch 1, gen_loss = 0.7492668568768386, disc_loss = 0.13709020971672625
Trained batch 373 in epoch 1, gen_loss = 0.7485590233681674, disc_loss = 0.13730014519477113
Trained batch 374 in epoch 1, gen_loss = 0.7488488964239757, disc_loss = 0.13718694122135638
Trained batch 375 in epoch 1, gen_loss = 0.7486168061323623, disc_loss = 0.1370921996075343
Trained batch 376 in epoch 1, gen_loss = 0.748899054859298, disc_loss = 0.13686495049503342
Trained batch 377 in epoch 1, gen_loss = 0.7486971117674358, disc_loss = 0.13671837418423916
Trained batch 378 in epoch 1, gen_loss = 0.7482092738308819, disc_loss = 0.13685893216772413
Trained batch 379 in epoch 1, gen_loss = 0.7479150394860067, disc_loss = 0.13703654191309683
Trained batch 380 in epoch 1, gen_loss = 0.747459946889577, disc_loss = 0.13716951304474684
Trained batch 381 in epoch 1, gen_loss = 0.747237630461523, disc_loss = 0.13719432815148724
Trained batch 382 in epoch 1, gen_loss = 0.7482150088869249, disc_loss = 0.13766147327115735
Trained batch 383 in epoch 1, gen_loss = 0.7477461260277778, disc_loss = 0.1380270248676728
Trained batch 384 in epoch 1, gen_loss = 0.7477919822389429, disc_loss = 0.1379391712656656
Trained batch 385 in epoch 1, gen_loss = 0.7476964013100905, disc_loss = 0.13783836139394984
Trained batch 386 in epoch 1, gen_loss = 0.7477142438870068, disc_loss = 0.1377926940767417
Trained batch 387 in epoch 1, gen_loss = 0.7477117295271343, disc_loss = 0.13776355911257496
Trained batch 388 in epoch 1, gen_loss = 0.7473570029502663, disc_loss = 0.13779605743606937
Trained batch 389 in epoch 1, gen_loss = 0.7478464352014738, disc_loss = 0.1376840429667097
Trained batch 390 in epoch 1, gen_loss = 0.7478776513920415, disc_loss = 0.13756152185732903
Trained batch 391 in epoch 1, gen_loss = 0.7478205877147159, disc_loss = 0.13750096872848058
Trained batch 392 in epoch 1, gen_loss = 0.7472372354593593, disc_loss = 0.137468307570533
Trained batch 393 in epoch 1, gen_loss = 0.747078726058684, disc_loss = 0.13732676363554855
Trained batch 394 in epoch 1, gen_loss = 0.7470122648945338, disc_loss = 0.13740274065374575
Trained batch 395 in epoch 1, gen_loss = 0.7467884264058537, disc_loss = 0.1373383643133848
Trained batch 396 in epoch 1, gen_loss = 0.7468847711230405, disc_loss = 0.13720300047182166
Trained batch 397 in epoch 1, gen_loss = 0.7471687086113733, disc_loss = 0.13766113729052357
Trained batch 398 in epoch 1, gen_loss = 0.7469745217857504, disc_loss = 0.13785717466888123
Trained batch 399 in epoch 1, gen_loss = 0.7465896066278219, disc_loss = 0.13789753579068928
Trained batch 400 in epoch 1, gen_loss = 0.746624369499392, disc_loss = 0.13793833531959546
Trained batch 401 in epoch 1, gen_loss = 0.7464397993698642, disc_loss = 0.13801157927205462
Trained batch 402 in epoch 1, gen_loss = 0.7462420878428088, disc_loss = 0.13825593656275614
Trained batch 403 in epoch 1, gen_loss = 0.746455598364372, disc_loss = 0.13815134889584516
Trained batch 404 in epoch 1, gen_loss = 0.7462128461878976, disc_loss = 0.13812813663648235
Trained batch 405 in epoch 1, gen_loss = 0.7463083979971891, disc_loss = 0.13797253515718166
Trained batch 406 in epoch 1, gen_loss = 0.7460961604733432, disc_loss = 0.13786286251569116
Trained batch 407 in epoch 1, gen_loss = 0.7460540447603253, disc_loss = 0.13778370630233458
Trained batch 408 in epoch 1, gen_loss = 0.7458445287712628, disc_loss = 0.13767906945553998
Trained batch 409 in epoch 1, gen_loss = 0.7462346928148735, disc_loss = 0.13779302997650897
Trained batch 410 in epoch 1, gen_loss = 0.7462168180014386, disc_loss = 0.13782366662945625
Trained batch 411 in epoch 1, gen_loss = 0.7460837129105642, disc_loss = 0.1377686462003412
Trained batch 412 in epoch 1, gen_loss = 0.746690210433041, disc_loss = 0.13788924925931284
Trained batch 413 in epoch 1, gen_loss = 0.7466318010564011, disc_loss = 0.13787619437086554
Trained batch 414 in epoch 1, gen_loss = 0.7461285540138383, disc_loss = 0.13814640898392144
Trained batch 415 in epoch 1, gen_loss = 0.7460212047713307, disc_loss = 0.13824796900959113
Trained batch 416 in epoch 1, gen_loss = 0.7463534961072661, disc_loss = 0.13815525437233975
Trained batch 417 in epoch 1, gen_loss = 0.7462157362528394, disc_loss = 0.13807189145958737
Trained batch 418 in epoch 1, gen_loss = 0.7461884543121857, disc_loss = 0.13797199401142063
Trained batch 419 in epoch 1, gen_loss = 0.7464023116798628, disc_loss = 0.13784868950024248
Trained batch 420 in epoch 1, gen_loss = 0.7466541149978683, disc_loss = 0.1378473711206695
Trained batch 421 in epoch 1, gen_loss = 0.7461982957700982, disc_loss = 0.13813879064138607
Trained batch 422 in epoch 1, gen_loss = 0.7467740130903591, disc_loss = 0.13809086957034913
Trained batch 423 in epoch 1, gen_loss = 0.7467978054763011, disc_loss = 0.1379903133229335
Trained batch 424 in epoch 1, gen_loss = 0.7470727524336647, disc_loss = 0.1380467142471496
Trained batch 425 in epoch 1, gen_loss = 0.7466731476531902, disc_loss = 0.1379269195738043
Trained batch 426 in epoch 1, gen_loss = 0.7468298745518267, disc_loss = 0.13781518452916408
Trained batch 427 in epoch 1, gen_loss = 0.7469812037649556, disc_loss = 0.13761463390976608
Trained batch 428 in epoch 1, gen_loss = 0.7465720264922767, disc_loss = 0.1377215985174015
Trained batch 429 in epoch 1, gen_loss = 0.7472416505564091, disc_loss = 0.1377353242533498
Trained batch 430 in epoch 1, gen_loss = 0.7473926092660067, disc_loss = 0.13757151479804738
Trained batch 431 in epoch 1, gen_loss = 0.7469038449365784, disc_loss = 0.13770220915493728
Trained batch 432 in epoch 1, gen_loss = 0.7469930108507566, disc_loss = 0.13771194657074248
Trained batch 433 in epoch 1, gen_loss = 0.7464717547602367, disc_loss = 0.13785840533587926
Trained batch 434 in epoch 1, gen_loss = 0.7464336689176231, disc_loss = 0.1377021407986852
Trained batch 435 in epoch 1, gen_loss = 0.7468048906244269, disc_loss = 0.137648848205839
Trained batch 436 in epoch 1, gen_loss = 0.7465957035598275, disc_loss = 0.137478191605865
Trained batch 437 in epoch 1, gen_loss = 0.746967947714405, disc_loss = 0.13734441337741266
Trained batch 438 in epoch 1, gen_loss = 0.7471071973884296, disc_loss = 0.1372361739202146
Trained batch 439 in epoch 1, gen_loss = 0.7473370479589159, disc_loss = 0.1369870420757004
Trained batch 440 in epoch 1, gen_loss = 0.7473228173055887, disc_loss = 0.1369302097302513
Trained batch 441 in epoch 1, gen_loss = 0.7478596348972881, disc_loss = 0.13685797940838526
Trained batch 442 in epoch 1, gen_loss = 0.7477802360434564, disc_loss = 0.1367312420546403
Trained batch 443 in epoch 1, gen_loss = 0.7476541079782151, disc_loss = 0.13677953093455317
Trained batch 444 in epoch 1, gen_loss = 0.7480108271154126, disc_loss = 0.136765374130245
Trained batch 445 in epoch 1, gen_loss = 0.7479387435544232, disc_loss = 0.13661252587382167
Trained batch 446 in epoch 1, gen_loss = 0.7475642034538107, disc_loss = 0.1367060806835591
Trained batch 447 in epoch 1, gen_loss = 0.7480458044447005, disc_loss = 0.1366670909545584
Trained batch 448 in epoch 1, gen_loss = 0.7477509815469882, disc_loss = 0.13669837794301903
Trained batch 449 in epoch 1, gen_loss = 0.7479417295588388, disc_loss = 0.1366784713541468
Trained batch 450 in epoch 1, gen_loss = 0.7478107030930911, disc_loss = 0.13658949715021312
Trained batch 451 in epoch 1, gen_loss = 0.7479980020264608, disc_loss = 0.13663894342324506
Trained batch 452 in epoch 1, gen_loss = 0.7481862698038156, disc_loss = 0.13644346453775766
Trained batch 453 in epoch 1, gen_loss = 0.7482496155384879, disc_loss = 0.13639131448096248
Trained batch 454 in epoch 1, gen_loss = 0.7475389421641172, disc_loss = 0.13653759265748355
Trained batch 455 in epoch 1, gen_loss = 0.7482807723837986, disc_loss = 0.13636473712119224
Trained batch 456 in epoch 1, gen_loss = 0.7484144860597356, disc_loss = 0.13615122119971515
Trained batch 457 in epoch 1, gen_loss = 0.7480807318697851, disc_loss = 0.13620878803629152
Trained batch 458 in epoch 1, gen_loss = 0.7491726209135616, disc_loss = 0.1364022987024262
Trained batch 459 in epoch 1, gen_loss = 0.7487459717885308, disc_loss = 0.13667025555168158
Trained batch 460 in epoch 1, gen_loss = 0.7491140400510031, disc_loss = 0.1367294625005404
Trained batch 461 in epoch 1, gen_loss = 0.7489745797532977, disc_loss = 0.13670215731914037
Trained batch 462 in epoch 1, gen_loss = 0.7490043969700197, disc_loss = 0.13659849362628892
Trained batch 463 in epoch 1, gen_loss = 0.7492757759474474, disc_loss = 0.13643536005763274
Trained batch 464 in epoch 1, gen_loss = 0.7493834112280159, disc_loss = 0.13632889339119517
Trained batch 465 in epoch 1, gen_loss = 0.7499304939493089, disc_loss = 0.13630410074755997
Trained batch 466 in epoch 1, gen_loss = 0.7502379320418299, disc_loss = 0.136054623134163
Trained batch 467 in epoch 1, gen_loss = 0.7496339377557111, disc_loss = 0.13657868337124968
Trained batch 468 in epoch 1, gen_loss = 0.751021062832143, disc_loss = 0.137046016693147
Trained batch 469 in epoch 1, gen_loss = 0.7507867523330323, disc_loss = 0.13705580743782697
Trained batch 470 in epoch 1, gen_loss = 0.7507016511353212, disc_loss = 0.13710699487089983
Trained batch 471 in epoch 1, gen_loss = 0.7506442506308273, disc_loss = 0.13709015795818957
Trained batch 472 in epoch 1, gen_loss = 0.7503168127375476, disc_loss = 0.1371768460221132
Trained batch 473 in epoch 1, gen_loss = 0.7500688778825954, disc_loss = 0.13712199710168038
Trained batch 474 in epoch 1, gen_loss = 0.750035197923058, disc_loss = 0.1370054840923924
Trained batch 475 in epoch 1, gen_loss = 0.750026585111598, disc_loss = 0.13693213258173412
Trained batch 476 in epoch 1, gen_loss = 0.7499591653826851, disc_loss = 0.13683791740151197
Trained batch 477 in epoch 1, gen_loss = 0.7499678882470191, disc_loss = 0.1367740337795356
Trained batch 478 in epoch 1, gen_loss = 0.7499563641115121, disc_loss = 0.13680031482278057
Trained batch 479 in epoch 1, gen_loss = 0.7498125599697232, disc_loss = 0.1367144013949049
Trained batch 480 in epoch 1, gen_loss = 0.7498552757712263, disc_loss = 0.13679092765055798
Trained batch 481 in epoch 1, gen_loss = 0.749870855964071, disc_loss = 0.13660804307884325
Trained batch 482 in epoch 1, gen_loss = 0.7503573708776115, disc_loss = 0.13647117200799241
Trained batch 483 in epoch 1, gen_loss = 0.7504927040008474, disc_loss = 0.13628599572203254
Trained batch 484 in epoch 1, gen_loss = 0.7503423675433877, disc_loss = 0.13626970944868536
Trained batch 485 in epoch 1, gen_loss = 0.7509736768870687, disc_loss = 0.13615630861034486
Trained batch 486 in epoch 1, gen_loss = 0.7510864535763523, disc_loss = 0.1359676324955553
Trained batch 487 in epoch 1, gen_loss = 0.7511341600510918, disc_loss = 0.1358403844766502
Trained batch 488 in epoch 1, gen_loss = 0.7508795508212107, disc_loss = 0.13577060273835143
Trained batch 489 in epoch 1, gen_loss = 0.7519630294065086, disc_loss = 0.13602404561349932
Trained batch 490 in epoch 1, gen_loss = 0.7519047863007563, disc_loss = 0.13582993284732772
Trained batch 491 in epoch 1, gen_loss = 0.7516897430386, disc_loss = 0.1359241021744059
Trained batch 492 in epoch 1, gen_loss = 0.7521276574952124, disc_loss = 0.13597205794712955
Trained batch 493 in epoch 1, gen_loss = 0.7519338068812482, disc_loss = 0.13597183918527625
Trained batch 494 in epoch 1, gen_loss = 0.7522835765824173, disc_loss = 0.13577267409048296
Trained batch 495 in epoch 1, gen_loss = 0.7526662357512021, disc_loss = 0.13559866842678597
Trained batch 496 in epoch 1, gen_loss = 0.7526516916166609, disc_loss = 0.13548237165170057
Trained batch 497 in epoch 1, gen_loss = 0.7526764931329283, disc_loss = 0.13533051628769044
Trained batch 498 in epoch 1, gen_loss = 0.7530297902757992, disc_loss = 0.13520168128959043
Trained batch 499 in epoch 1, gen_loss = 0.7535273541808128, disc_loss = 0.13512384667620062
Trained batch 500 in epoch 1, gen_loss = 0.7529873836659148, disc_loss = 0.1353811575527379
Trained batch 501 in epoch 1, gen_loss = 0.7536073313410063, disc_loss = 0.13541632252133107
Trained batch 502 in epoch 1, gen_loss = 0.7532689968942411, disc_loss = 0.13540524075078086
Trained batch 503 in epoch 1, gen_loss = 0.7530908618299734, disc_loss = 0.13537956234289422
Trained batch 504 in epoch 1, gen_loss = 0.7530852984083761, disc_loss = 0.13535614784917618
Trained batch 505 in epoch 1, gen_loss = 0.7532214711423919, disc_loss = 0.1352407867751515
Trained batch 506 in epoch 1, gen_loss = 0.7532390286113618, disc_loss = 0.13516587929715654
Trained batch 507 in epoch 1, gen_loss = 0.7536408554498605, disc_loss = 0.13496270713095707
Trained batch 508 in epoch 1, gen_loss = 0.7535433407968061, disc_loss = 0.13489629397413938
Trained batch 509 in epoch 1, gen_loss = 0.7533728152513504, disc_loss = 0.13478582085420687
Trained batch 510 in epoch 1, gen_loss = 0.7531647429657542, disc_loss = 0.13469938773829526
Trained batch 511 in epoch 1, gen_loss = 0.7538957455544733, disc_loss = 0.13478898842367926
Trained batch 512 in epoch 1, gen_loss = 0.7534993104418816, disc_loss = 0.13505847276084954
Trained batch 513 in epoch 1, gen_loss = 0.7539372387911095, disc_loss = 0.13509219186561697
Trained batch 514 in epoch 1, gen_loss = 0.7536859821926043, disc_loss = 0.13501010780557265
Trained batch 515 in epoch 1, gen_loss = 0.7535480543277985, disc_loss = 0.13491400513552534
Trained batch 516 in epoch 1, gen_loss = 0.7540245190464551, disc_loss = 0.1348402468195794
Trained batch 517 in epoch 1, gen_loss = 0.7545438858187797, disc_loss = 0.13465027961678602
Trained batch 518 in epoch 1, gen_loss = 0.754020595194517, disc_loss = 0.1347553857668574
Trained batch 519 in epoch 1, gen_loss = 0.754289486259222, disc_loss = 0.13487425594447325
Trained batch 520 in epoch 1, gen_loss = 0.754082174024289, disc_loss = 0.13484644499784354
Trained batch 521 in epoch 1, gen_loss = 0.7540482138194343, disc_loss = 0.13480799584167785
Trained batch 522 in epoch 1, gen_loss = 0.7539251029035557, disc_loss = 0.13475779247742653
Trained batch 523 in epoch 1, gen_loss = 0.7536455717591839, disc_loss = 0.13465579536935415
Trained batch 524 in epoch 1, gen_loss = 0.7537481084891728, disc_loss = 0.13456688554868812
Trained batch 525 in epoch 1, gen_loss = 0.7535393402943593, disc_loss = 0.13453195866254006
Trained batch 526 in epoch 1, gen_loss = 0.7539422987647482, disc_loss = 0.1344954170307862
Trained batch 527 in epoch 1, gen_loss = 0.7539143167774786, disc_loss = 0.134419633798781
Trained batch 528 in epoch 1, gen_loss = 0.753549211248333, disc_loss = 0.13462400097322486
Trained batch 529 in epoch 1, gen_loss = 0.7538203173650886, disc_loss = 0.13470559909166593
Trained batch 530 in epoch 1, gen_loss = 0.7537565706701153, disc_loss = 0.1346330240319734
Trained batch 531 in epoch 1, gen_loss = 0.7535166377971944, disc_loss = 0.13466343687343083
Trained batch 532 in epoch 1, gen_loss = 0.7535368193493104, disc_loss = 0.13457288810071197
Trained batch 533 in epoch 1, gen_loss = 0.7532717134064056, disc_loss = 0.1345023973722862
Trained batch 534 in epoch 1, gen_loss = 0.7535461106590021, disc_loss = 0.13458946387971116
Trained batch 535 in epoch 1, gen_loss = 0.7537920863659524, disc_loss = 0.13443819637438142
Trained batch 536 in epoch 1, gen_loss = 0.7533225542007211, disc_loss = 0.1345553371319946
Trained batch 537 in epoch 1, gen_loss = 0.754226486866802, disc_loss = 0.13450959799499648
Trained batch 538 in epoch 1, gen_loss = 0.7541297377261691, disc_loss = 0.1344870325965817
Trained batch 539 in epoch 1, gen_loss = 0.7539024899955149, disc_loss = 0.1343952421064454
Trained batch 540 in epoch 1, gen_loss = 0.7537155142002318, disc_loss = 0.1343642556506197
Trained batch 541 in epoch 1, gen_loss = 0.7541789572507253, disc_loss = 0.1344082038059171
Trained batch 542 in epoch 1, gen_loss = 0.7542245003290159, disc_loss = 0.13421109380478358
Trained batch 543 in epoch 1, gen_loss = 0.7541456117897349, disc_loss = 0.13421449006315977
Trained batch 544 in epoch 1, gen_loss = 0.7540942277930198, disc_loss = 0.13410091303083874
Trained batch 545 in epoch 1, gen_loss = 0.7542571729465282, disc_loss = 0.13393231939128686
Trained batch 546 in epoch 1, gen_loss = 0.7541006891230561, disc_loss = 0.13383184679165835
Trained batch 547 in epoch 1, gen_loss = 0.7541397237320886, disc_loss = 0.13372688523636464
Trained batch 548 in epoch 1, gen_loss = 0.7542720907698564, disc_loss = 0.13354686716188063
Trained batch 549 in epoch 1, gen_loss = 0.7543590043349699, disc_loss = 0.13353068836033344
Trained batch 550 in epoch 1, gen_loss = 0.7542422690214133, disc_loss = 0.13347087964794163
Trained batch 551 in epoch 1, gen_loss = 0.7543223979140538, disc_loss = 0.13332038309317137
Trained batch 552 in epoch 1, gen_loss = 0.7548028402582861, disc_loss = 0.13315499354335758
Trained batch 553 in epoch 1, gen_loss = 0.7547797682806042, disc_loss = 0.1330553776843453
Trained batch 554 in epoch 1, gen_loss = 0.7548540667907612, disc_loss = 0.1329161421672718
Trained batch 555 in epoch 1, gen_loss = 0.7552331257745516, disc_loss = 0.13278730196891714
Trained batch 556 in epoch 1, gen_loss = 0.7552052507815712, disc_loss = 0.1327531460465285
Trained batch 557 in epoch 1, gen_loss = 0.7552781086348291, disc_loss = 0.132669046167351
Trained batch 558 in epoch 1, gen_loss = 0.7560444341469322, disc_loss = 0.1325712389977439
Trained batch 559 in epoch 1, gen_loss = 0.7559166197798082, disc_loss = 0.13256742730071502
Trained batch 560 in epoch 1, gen_loss = 0.7557457613753763, disc_loss = 0.13264047479964194
Trained batch 561 in epoch 1, gen_loss = 0.7568075313792958, disc_loss = 0.13317396427468262
Trained batch 562 in epoch 1, gen_loss = 0.7565409744929251, disc_loss = 0.13316111064798877
Trained batch 563 in epoch 1, gen_loss = 0.7560855178756917, disc_loss = 0.13341380552065077
Trained batch 564 in epoch 1, gen_loss = 0.7566811682903661, disc_loss = 0.13368523613409658
Trained batch 565 in epoch 1, gen_loss = 0.7568758706111369, disc_loss = 0.13372573413797276
Trained batch 566 in epoch 1, gen_loss = 0.7568933207942485, disc_loss = 0.1337919479837178
Trained batch 567 in epoch 1, gen_loss = 0.7571648035041043, disc_loss = 0.13387928836860916
Trained batch 568 in epoch 1, gen_loss = 0.7572247304271101, disc_loss = 0.1339569565478339
Trained batch 569 in epoch 1, gen_loss = 0.7570305510571128, disc_loss = 0.13396088932559155
Trained batch 570 in epoch 1, gen_loss = 0.7574026250588706, disc_loss = 0.1340899823621672
Trained batch 571 in epoch 1, gen_loss = 0.757146495413947, disc_loss = 0.13406347246983877
Trained batch 572 in epoch 1, gen_loss = 0.7569941964657103, disc_loss = 0.13403605650882863
Trained batch 573 in epoch 1, gen_loss = 0.7570706863436549, disc_loss = 0.13399776443190067
Trained batch 574 in epoch 1, gen_loss = 0.757142070894656, disc_loss = 0.13396430172997972
Trained batch 575 in epoch 1, gen_loss = 0.7571634979297718, disc_loss = 0.13382734929392529
Trained batch 576 in epoch 1, gen_loss = 0.7575439958473219, disc_loss = 0.13397660073493342
Trained batch 577 in epoch 1, gen_loss = 0.7575551365279821, disc_loss = 0.133858290761967
Trained batch 578 in epoch 1, gen_loss = 0.7572772518340788, disc_loss = 0.13386353141980467
Trained batch 579 in epoch 1, gen_loss = 0.7577664139969595, disc_loss = 0.13372382206906533
Trained batch 580 in epoch 1, gen_loss = 0.7579936760633209, disc_loss = 0.13362988803965295
Trained batch 581 in epoch 1, gen_loss = 0.7579520266899948, disc_loss = 0.1336024243038954
Trained batch 582 in epoch 1, gen_loss = 0.7576790160625713, disc_loss = 0.13364632846867444
Trained batch 583 in epoch 1, gen_loss = 0.7578387857504087, disc_loss = 0.13358524390687682
Trained batch 584 in epoch 1, gen_loss = 0.7577941791624085, disc_loss = 0.13348499303444838
Trained batch 585 in epoch 1, gen_loss = 0.7574222907678259, disc_loss = 0.13371512264572719
Trained batch 586 in epoch 1, gen_loss = 0.7580774661020282, disc_loss = 0.13369862492842
Trained batch 587 in epoch 1, gen_loss = 0.7582897458757673, disc_loss = 0.13362278055627735
Trained batch 588 in epoch 1, gen_loss = 0.7580208342225119, disc_loss = 0.13359327270239846
Trained batch 589 in epoch 1, gen_loss = 0.7581529167749114, disc_loss = 0.1335111243366185
Trained batch 590 in epoch 1, gen_loss = 0.7580277602079556, disc_loss = 0.13355312140913783
Trained batch 591 in epoch 1, gen_loss = 0.7579673084656935, disc_loss = 0.13349453228953723
Trained batch 592 in epoch 1, gen_loss = 0.7577831846666577, disc_loss = 0.13345581659981212
Trained batch 593 in epoch 1, gen_loss = 0.7578120997257104, disc_loss = 0.1335403507305717
Trained batch 594 in epoch 1, gen_loss = 0.7574347252605342, disc_loss = 0.13371273088855903
Trained batch 595 in epoch 1, gen_loss = 0.7573999037478594, disc_loss = 0.13368471185582997
Trained batch 596 in epoch 1, gen_loss = 0.7581214137013433, disc_loss = 0.13361167319905218
Trained batch 597 in epoch 1, gen_loss = 0.757790556221104, disc_loss = 0.133782467926326
Trained batch 598 in epoch 1, gen_loss = 0.7579964467002474, disc_loss = 0.13383058948638243
Trained batch 599 in epoch 1, gen_loss = 0.7576529328028361, disc_loss = 0.13384178724139928
Trained batch 600 in epoch 1, gen_loss = 0.7573865863328766, disc_loss = 0.13387099403063588
Trained batch 601 in epoch 1, gen_loss = 0.7576435093467814, disc_loss = 0.13388745767680119
Trained batch 602 in epoch 1, gen_loss = 0.7573200901151692, disc_loss = 0.13386666397896177
Trained batch 603 in epoch 1, gen_loss = 0.7572158750714055, disc_loss = 0.1338217022477199
Trained batch 604 in epoch 1, gen_loss = 0.7571418419357173, disc_loss = 0.1337161082743613
Trained batch 605 in epoch 1, gen_loss = 0.7574206700812866, disc_loss = 0.13390744741846233
Trained batch 606 in epoch 1, gen_loss = 0.757268829047189, disc_loss = 0.1339204815481797
Trained batch 607 in epoch 1, gen_loss = 0.757093118111554, disc_loss = 0.13407661632242562
Trained batch 608 in epoch 1, gen_loss = 0.7572875941915466, disc_loss = 0.13405153823309932
Trained batch 609 in epoch 1, gen_loss = 0.7572071838574331, disc_loss = 0.13399430565902445
Trained batch 610 in epoch 1, gen_loss = 0.7568956206746266, disc_loss = 0.1340541505359979
Trained batch 611 in epoch 1, gen_loss = 0.7573173265246784, disc_loss = 0.13396852092172196
Trained batch 612 in epoch 1, gen_loss = 0.7569830960200622, disc_loss = 0.13389362518783496
Trained batch 613 in epoch 1, gen_loss = 0.7572415211884129, disc_loss = 0.13386280774002354
Trained batch 614 in epoch 1, gen_loss = 0.7568474746331936, disc_loss = 0.1339821856438629
Trained batch 615 in epoch 1, gen_loss = 0.7570017297546585, disc_loss = 0.1339201612228697
Trained batch 616 in epoch 1, gen_loss = 0.7574712005194814, disc_loss = 0.13380396680686038
Trained batch 617 in epoch 1, gen_loss = 0.7572310969088841, disc_loss = 0.1337438537332329
Trained batch 618 in epoch 1, gen_loss = 0.7570119422163832, disc_loss = 0.13373876465950912
Trained batch 619 in epoch 1, gen_loss = 0.757409111338277, disc_loss = 0.13377901193715871
Trained batch 620 in epoch 1, gen_loss = 0.7572675298377511, disc_loss = 0.13369523562886865
Trained batch 621 in epoch 1, gen_loss = 0.7570335475003221, disc_loss = 0.13359845050541727
Trained batch 622 in epoch 1, gen_loss = 0.7573537453411097, disc_loss = 0.13353249925169286
Trained batch 623 in epoch 1, gen_loss = 0.7574678193300198, disc_loss = 0.13345957522949156
Trained batch 624 in epoch 1, gen_loss = 0.7572942170143128, disc_loss = 0.13340810893177987
Trained batch 625 in epoch 1, gen_loss = 0.7571084463177398, disc_loss = 0.13335343844855366
Trained batch 626 in epoch 1, gen_loss = 0.7574781453210201, disc_loss = 0.13318699751304763
Trained batch 627 in epoch 1, gen_loss = 0.7572439837797432, disc_loss = 0.1331210778818531
Trained batch 628 in epoch 1, gen_loss = 0.7573445457343266, disc_loss = 0.1329907293154581
Trained batch 629 in epoch 1, gen_loss = 0.7571073653205993, disc_loss = 0.1329522431458509
Trained batch 630 in epoch 1, gen_loss = 0.757956221439948, disc_loss = 0.13319885259325928
Trained batch 631 in epoch 1, gen_loss = 0.757983638327333, disc_loss = 0.13313222888420936
Trained batch 632 in epoch 1, gen_loss = 0.7576552423255704, disc_loss = 0.13336594673212013
Trained batch 633 in epoch 1, gen_loss = 0.758185681014407, disc_loss = 0.1333301353476918
Trained batch 634 in epoch 1, gen_loss = 0.7584164471138181, disc_loss = 0.1332801364274241
Trained batch 635 in epoch 1, gen_loss = 0.7582950093461283, disc_loss = 0.13342292297268346
Trained batch 636 in epoch 1, gen_loss = 0.7579864125049657, disc_loss = 0.1335511167315851
Trained batch 637 in epoch 1, gen_loss = 0.7578186447904401, disc_loss = 0.13353800799020313
Trained batch 638 in epoch 1, gen_loss = 0.7582734878260952, disc_loss = 0.133804449193611
Trained batch 639 in epoch 1, gen_loss = 0.7583103916607797, disc_loss = 0.13367192027799318
Trained batch 640 in epoch 1, gen_loss = 0.758011018523188, disc_loss = 0.133765144157405
Trained batch 641 in epoch 1, gen_loss = 0.7581519884669521, disc_loss = 0.1337558185171069
Trained batch 642 in epoch 1, gen_loss = 0.7583430338981177, disc_loss = 0.13369788626617352
Trained batch 643 in epoch 1, gen_loss = 0.7581527652392476, disc_loss = 0.13367353269529547
Trained batch 644 in epoch 1, gen_loss = 0.7582084628038628, disc_loss = 0.13360954906300518
Trained batch 645 in epoch 1, gen_loss = 0.758148391457165, disc_loss = 0.13354027964140147
Trained batch 646 in epoch 1, gen_loss = 0.7580847449059465, disc_loss = 0.13352387630808207
Trained batch 647 in epoch 1, gen_loss = 0.7580339974827237, disc_loss = 0.13356354162039488
Trained batch 648 in epoch 1, gen_loss = 0.7576954606317776, disc_loss = 0.1336010983658636
Trained batch 649 in epoch 1, gen_loss = 0.7576273482579451, disc_loss = 0.1336036716372921
Trained batch 650 in epoch 1, gen_loss = 0.7576903169788707, disc_loss = 0.1335486436488762
Trained batch 651 in epoch 1, gen_loss = 0.7572855990540031, disc_loss = 0.1335658980104958
Trained batch 652 in epoch 1, gen_loss = 0.7573261995775594, disc_loss = 0.13352514052361386
Trained batch 653 in epoch 1, gen_loss = 0.757210807424802, disc_loss = 0.13354546236962261
Trained batch 654 in epoch 1, gen_loss = 0.7573585846041905, disc_loss = 0.133478564999372
Trained batch 655 in epoch 1, gen_loss = 0.7571533101542693, disc_loss = 0.13355359041824846
Trained batch 656 in epoch 1, gen_loss = 0.7568239800099006, disc_loss = 0.13362423662532863
Trained batch 657 in epoch 1, gen_loss = 0.7573608497899355, disc_loss = 0.1337836309333295
Trained batch 658 in epoch 1, gen_loss = 0.7573020554999842, disc_loss = 0.13369854476037174
Trained batch 659 in epoch 1, gen_loss = 0.7569056329853607, disc_loss = 0.13371501972221517
Trained batch 660 in epoch 1, gen_loss = 0.7575590263787269, disc_loss = 0.13379879479272552
Trained batch 661 in epoch 1, gen_loss = 0.7573415754514878, disc_loss = 0.13377702074952627
Trained batch 662 in epoch 1, gen_loss = 0.7573838754027498, disc_loss = 0.133667576442814
Trained batch 663 in epoch 1, gen_loss = 0.7572049881410168, disc_loss = 0.1335973746552839
Trained batch 664 in epoch 1, gen_loss = 0.7570734778293093, disc_loss = 0.1335383746156791
Trained batch 665 in epoch 1, gen_loss = 0.7573915125281961, disc_loss = 0.13354332044485723
Trained batch 666 in epoch 1, gen_loss = 0.7572975503183019, disc_loss = 0.13356628977991025
Trained batch 667 in epoch 1, gen_loss = 0.7572542102840132, disc_loss = 0.1334807732990179
Trained batch 668 in epoch 1, gen_loss = 0.757295423068986, disc_loss = 0.13350485070080945
Trained batch 669 in epoch 1, gen_loss = 0.7570532066163732, disc_loss = 0.13354791423667278
Trained batch 670 in epoch 1, gen_loss = 0.7576339119148681, disc_loss = 0.13352715856660763
Trained batch 671 in epoch 1, gen_loss = 0.7577016618368881, disc_loss = 0.13338848461474603
Trained batch 672 in epoch 1, gen_loss = 0.7577452157882844, disc_loss = 0.13330463536725798
Trained batch 673 in epoch 1, gen_loss = 0.7579668974752596, disc_loss = 0.13334556490746644
Trained batch 674 in epoch 1, gen_loss = 0.7578857764049812, disc_loss = 0.13331736396584246
Trained batch 675 in epoch 1, gen_loss = 0.7581706026337556, disc_loss = 0.13321917327451546
Trained batch 676 in epoch 1, gen_loss = 0.758449466973323, disc_loss = 0.13318710395326203
Trained batch 677 in epoch 1, gen_loss = 0.7584030493258727, disc_loss = 0.1330959670833562
Trained batch 678 in epoch 1, gen_loss = 0.7583520714857441, disc_loss = 0.13321374579221668
Trained batch 679 in epoch 1, gen_loss = 0.7585363658473773, disc_loss = 0.13328755264280034
Trained batch 680 in epoch 1, gen_loss = 0.7583245016667286, disc_loss = 0.1333017649974198
Trained batch 681 in epoch 1, gen_loss = 0.7583743164703644, disc_loss = 0.1331984229205597
Trained batch 682 in epoch 1, gen_loss = 0.7584077191824096, disc_loss = 0.13315528764022652
Trained batch 683 in epoch 1, gen_loss = 0.7590018753506984, disc_loss = 0.13325096660004984
Trained batch 684 in epoch 1, gen_loss = 0.7585336505931659, disc_loss = 0.13338851062648924
Trained batch 685 in epoch 1, gen_loss = 0.7585014788645698, disc_loss = 0.13342524476012665
Trained batch 686 in epoch 1, gen_loss = 0.7587023832912528, disc_loss = 0.13340474201808242
Trained batch 687 in epoch 1, gen_loss = 0.7587347794757333, disc_loss = 0.13338921507982926
Trained batch 688 in epoch 1, gen_loss = 0.7586024513438409, disc_loss = 0.13328636954274942
Trained batch 689 in epoch 1, gen_loss = 0.7590369504431019, disc_loss = 0.13325292361981195
Trained batch 690 in epoch 1, gen_loss = 0.7588440914747512, disc_loss = 0.13340460216591482
Trained batch 691 in epoch 1, gen_loss = 0.7591617018673461, disc_loss = 0.1333842433186926
Trained batch 692 in epoch 1, gen_loss = 0.759270451371632, disc_loss = 0.1332670379225783
Trained batch 693 in epoch 1, gen_loss = 0.7592057843373213, disc_loss = 0.1332210646942258
Trained batch 694 in epoch 1, gen_loss = 0.7594281407568952, disc_loss = 0.13314765887669952
Trained batch 695 in epoch 1, gen_loss = 0.759623142151997, disc_loss = 0.13310659099530814
Trained batch 696 in epoch 1, gen_loss = 0.7597515759201269, disc_loss = 0.13300049710361397
Trained batch 697 in epoch 1, gen_loss = 0.7596968864984703, disc_loss = 0.1329029879764918
Trained batch 698 in epoch 1, gen_loss = 0.7596714198162968, disc_loss = 0.1328220147884668
Trained batch 699 in epoch 1, gen_loss = 0.7596398254803248, disc_loss = 0.13275353803432413
Trained batch 700 in epoch 1, gen_loss = 0.7598554882275395, disc_loss = 0.1327051226921199
Trained batch 701 in epoch 1, gen_loss = 0.7597534260009429, disc_loss = 0.1326572932966287
Trained batch 702 in epoch 1, gen_loss = 0.7600759974923277, disc_loss = 0.13265528769668186
Trained batch 703 in epoch 1, gen_loss = 0.7600603602318601, disc_loss = 0.13262165436489423
Trained batch 704 in epoch 1, gen_loss = 0.7597309045757807, disc_loss = 0.1328069447334988
Trained batch 705 in epoch 1, gen_loss = 0.7602428796439941, disc_loss = 0.13275477099403865
Trained batch 706 in epoch 1, gen_loss = 0.7607282768550317, disc_loss = 0.13265249030625045
Trained batch 707 in epoch 1, gen_loss = 0.7606342172218581, disc_loss = 0.1326400655174449
Trained batch 708 in epoch 1, gen_loss = 0.7605036088542643, disc_loss = 0.13257796828843896
Trained batch 709 in epoch 1, gen_loss = 0.7605819339483557, disc_loss = 0.13246181375596305
Trained batch 710 in epoch 1, gen_loss = 0.7607938340444605, disc_loss = 0.13239684527276185
Trained batch 711 in epoch 1, gen_loss = 0.7607488630527861, disc_loss = 0.13233279198502307
Trained batch 712 in epoch 1, gen_loss = 0.7607011353651906, disc_loss = 0.13227598229357856
Trained batch 713 in epoch 1, gen_loss = 0.7611531286346478, disc_loss = 0.13228397643459694
Trained batch 714 in epoch 1, gen_loss = 0.7609423485669222, disc_loss = 0.13223584431086804
Trained batch 715 in epoch 1, gen_loss = 0.7608127078697002, disc_loss = 0.13230864448972338
Trained batch 716 in epoch 1, gen_loss = 0.7609822578011197, disc_loss = 0.13242848237490637
Trained batch 717 in epoch 1, gen_loss = 0.7608526751689592, disc_loss = 0.13243203980894888
Trained batch 718 in epoch 1, gen_loss = 0.7607579413640814, disc_loss = 0.13248714913713833
Trained batch 719 in epoch 1, gen_loss = 0.7609319052762455, disc_loss = 0.13256860641607393
Trained batch 720 in epoch 1, gen_loss = 0.7610137680863209, disc_loss = 0.13251988977534843
Trained batch 721 in epoch 1, gen_loss = 0.7611653482814905, disc_loss = 0.13239153703917178
Trained batch 722 in epoch 1, gen_loss = 0.7613702225981906, disc_loss = 0.13227094448896776
Trained batch 723 in epoch 1, gen_loss = 0.7612261792737476, disc_loss = 0.13226970141877045
Trained batch 724 in epoch 1, gen_loss = 0.7612481004616309, disc_loss = 0.13227610011296026
Trained batch 725 in epoch 1, gen_loss = 0.7610451949365211, disc_loss = 0.1322624651745947
Trained batch 726 in epoch 1, gen_loss = 0.7612661440565957, disc_loss = 0.1322354068326286
Trained batch 727 in epoch 1, gen_loss = 0.7610986949159548, disc_loss = 0.1322009989270265
Trained batch 728 in epoch 1, gen_loss = 0.7611590219950316, disc_loss = 0.13209453995489043
Trained batch 729 in epoch 1, gen_loss = 0.7615913619733836, disc_loss = 0.1320671207054633
Trained batch 730 in epoch 1, gen_loss = 0.7612138227871765, disc_loss = 0.1323024597701842
Trained batch 731 in epoch 1, gen_loss = 0.7619028535615551, disc_loss = 0.13232004733837613
Trained batch 732 in epoch 1, gen_loss = 0.7618117400357375, disc_loss = 0.13222127375008708
Trained batch 733 in epoch 1, gen_loss = 0.7617142710844892, disc_loss = 0.13213685988029847
Trained batch 734 in epoch 1, gen_loss = 0.7616195543688171, disc_loss = 0.13213188446247254
Trained batch 735 in epoch 1, gen_loss = 0.7617647830477875, disc_loss = 0.13208945777581033
Trained batch 736 in epoch 1, gen_loss = 0.7614359940974651, disc_loss = 0.13209581205032492
Trained batch 737 in epoch 1, gen_loss = 0.7614627902504552, disc_loss = 0.13197397270812816
Trained batch 738 in epoch 1, gen_loss = 0.7616334431306919, disc_loss = 0.13197206575499093
Trained batch 739 in epoch 1, gen_loss = 0.761620170079373, disc_loss = 0.13187903463588777
Trained batch 740 in epoch 1, gen_loss = 0.7615191118035078, disc_loss = 0.13180542693758704
Trained batch 741 in epoch 1, gen_loss = 0.7614540245253442, disc_loss = 0.13179969845585665
Trained batch 742 in epoch 1, gen_loss = 0.7612820816794122, disc_loss = 0.13181484722022171
Trained batch 743 in epoch 1, gen_loss = 0.7611209576729164, disc_loss = 0.131758767077499
Trained batch 744 in epoch 1, gen_loss = 0.761248212172681, disc_loss = 0.13169643511658147
Trained batch 745 in epoch 1, gen_loss = 0.7611075014515153, disc_loss = 0.13163232052044557
Trained batch 746 in epoch 1, gen_loss = 0.7609760950767053, disc_loss = 0.13176260768639117
Trained batch 747 in epoch 1, gen_loss = 0.7612628742733741, disc_loss = 0.13161653398043094
Trained batch 748 in epoch 1, gen_loss = 0.7611839675378099, disc_loss = 0.13157609218758878
Trained batch 749 in epoch 1, gen_loss = 0.7609405230283737, disc_loss = 0.13159474577754737
Trained batch 750 in epoch 1, gen_loss = 0.7613935758286564, disc_loss = 0.131656575181612
Trained batch 751 in epoch 1, gen_loss = 0.761443477084345, disc_loss = 0.13154682149724203
Trained batch 752 in epoch 1, gen_loss = 0.7615294345267424, disc_loss = 0.13142397824877683
Trained batch 753 in epoch 1, gen_loss = 0.7614481587862146, disc_loss = 0.13130528658420954
Trained batch 754 in epoch 1, gen_loss = 0.7614852479356804, disc_loss = 0.13125864145722216
Trained batch 755 in epoch 1, gen_loss = 0.7618157406726842, disc_loss = 0.13117268649742952
Trained batch 756 in epoch 1, gen_loss = 0.7615750341859487, disc_loss = 0.13125107195991112
Trained batch 757 in epoch 1, gen_loss = 0.7616406869841125, disc_loss = 0.1311815130575941
Trained batch 758 in epoch 1, gen_loss = 0.7615521108444501, disc_loss = 0.13112039351406382
Trained batch 759 in epoch 1, gen_loss = 0.7614543960674813, disc_loss = 0.13106359973500825
Trained batch 760 in epoch 1, gen_loss = 0.7612465036134682, disc_loss = 0.13101041974663813
Trained batch 761 in epoch 1, gen_loss = 0.7618196395829594, disc_loss = 0.13124288739563209
Trained batch 762 in epoch 1, gen_loss = 0.7615431316323862, disc_loss = 0.13129358706192687
Trained batch 763 in epoch 1, gen_loss = 0.7615733594872565, disc_loss = 0.13114900516190064
Trained batch 764 in epoch 1, gen_loss = 0.7617704963761996, disc_loss = 0.1310605131211429
Trained batch 765 in epoch 1, gen_loss = 0.7618732952340154, disc_loss = 0.1309467381518091
Trained batch 766 in epoch 1, gen_loss = 0.7619461119952071, disc_loss = 0.13083665874073916
Trained batch 767 in epoch 1, gen_loss = 0.7620011612695331, disc_loss = 0.1307108666539231
Trained batch 768 in epoch 1, gen_loss = 0.7621016108245626, disc_loss = 0.1306173452121655
Trained batch 769 in epoch 1, gen_loss = 0.7626107943135423, disc_loss = 0.13052356785719657
Trained batch 770 in epoch 1, gen_loss = 0.7626033043815004, disc_loss = 0.13044072526003367
Trained batch 771 in epoch 1, gen_loss = 0.7624922215243696, disc_loss = 0.13040459927875991
Trained batch 772 in epoch 1, gen_loss = 0.7626078773824857, disc_loss = 0.13041147857393592
Trained batch 773 in epoch 1, gen_loss = 0.7626923809756913, disc_loss = 0.13032311545468347
Trained batch 774 in epoch 1, gen_loss = 0.7623269140335821, disc_loss = 0.13036169547948145
Trained batch 775 in epoch 1, gen_loss = 0.7627786240473236, disc_loss = 0.13049074050912768
Trained batch 776 in epoch 1, gen_loss = 0.7627019218649796, disc_loss = 0.1304431091898158
Trained batch 777 in epoch 1, gen_loss = 0.7626337189141154, disc_loss = 0.1304420738871231
Trained batch 778 in epoch 1, gen_loss = 0.7628485959821856, disc_loss = 0.13043652167627456
Trained batch 779 in epoch 1, gen_loss = 0.7632686079312594, disc_loss = 0.13039688520276776
Trained batch 780 in epoch 1, gen_loss = 0.7631228934024269, disc_loss = 0.13035775123643434
Trained batch 781 in epoch 1, gen_loss = 0.7630387437160667, disc_loss = 0.13028965749160942
Trained batch 782 in epoch 1, gen_loss = 0.763371979368144, disc_loss = 0.13035488784988797
Trained batch 783 in epoch 1, gen_loss = 0.763078934075881, disc_loss = 0.1303864114000747
Trained batch 784 in epoch 1, gen_loss = 0.763055700860965, disc_loss = 0.13028844992398836
Trained batch 785 in epoch 1, gen_loss = 0.7629883111888216, disc_loss = 0.13028017663498795
Trained batch 786 in epoch 1, gen_loss = 0.7628720976800446, disc_loss = 0.13025096574563916
Trained batch 787 in epoch 1, gen_loss = 0.7629852687495614, disc_loss = 0.13021713569713048
Trained batch 788 in epoch 1, gen_loss = 0.7628303511665498, disc_loss = 0.1301656864625986
Trained batch 789 in epoch 1, gen_loss = 0.7628344848940644, disc_loss = 0.13007252448108755
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6974794864654541, disc_loss = 0.13279977440834045
Trained batch 1 in epoch 2, gen_loss = 0.7631660103797913, disc_loss = 0.09859305247664452
Trained batch 2 in epoch 2, gen_loss = 0.7884608308474222, disc_loss = 0.08330559233824412
Trained batch 3 in epoch 2, gen_loss = 0.7513767629861832, disc_loss = 0.07607028353959322
Trained batch 4 in epoch 2, gen_loss = 0.8168282151222229, disc_loss = 0.09112902358174324
Trained batch 5 in epoch 2, gen_loss = 0.7644067605336508, disc_loss = 0.12283471288780372
Trained batch 6 in epoch 2, gen_loss = 0.7877623013087681, disc_loss = 0.12181976810097694
Trained batch 7 in epoch 2, gen_loss = 0.7847873121500015, disc_loss = 0.11569814709946513
Trained batch 8 in epoch 2, gen_loss = 0.7908610237969292, disc_loss = 0.11004376370045874
Trained batch 9 in epoch 2, gen_loss = 0.7639887511730195, disc_loss = 0.11797252856194973
Trained batch 10 in epoch 2, gen_loss = 0.7813927260312167, disc_loss = 0.11259227178313515
Trained batch 11 in epoch 2, gen_loss = 0.7876635193824768, disc_loss = 0.10648022188494603
Trained batch 12 in epoch 2, gen_loss = 0.7651013044210581, disc_loss = 0.11218462741145721
Trained batch 13 in epoch 2, gen_loss = 0.7980573347636631, disc_loss = 0.1204531913889306
Trained batch 14 in epoch 2, gen_loss = 0.7956640799840291, disc_loss = 0.11622212305665017
Trained batch 15 in epoch 2, gen_loss = 0.7859779000282288, disc_loss = 0.11224804702214897
Trained batch 16 in epoch 2, gen_loss = 0.8008243055904612, disc_loss = 0.10867712033145568
Trained batch 17 in epoch 2, gen_loss = 0.8005468216207292, disc_loss = 0.10351369933535655
Trained batch 18 in epoch 2, gen_loss = 0.7940014067449068, disc_loss = 0.10004391903547864
Trained batch 19 in epoch 2, gen_loss = 0.7963850647211075, disc_loss = 0.09800230218097568
Trained batch 20 in epoch 2, gen_loss = 0.800653528599512, disc_loss = 0.09565521182403677
Trained batch 21 in epoch 2, gen_loss = 0.8050867075269873, disc_loss = 0.09292973281646316
Trained batch 22 in epoch 2, gen_loss = 0.8130863516227059, disc_loss = 0.09327333784945634
Trained batch 23 in epoch 2, gen_loss = 0.8100539768735567, disc_loss = 0.09117819919871788
Trained batch 24 in epoch 2, gen_loss = 0.8095020246505737, disc_loss = 0.08880380116403103
Trained batch 25 in epoch 2, gen_loss = 0.813529385970189, disc_loss = 0.08661537395360377
Trained batch 26 in epoch 2, gen_loss = 0.8098338533330847, disc_loss = 0.0872493141365272
Trained batch 27 in epoch 2, gen_loss = 0.8066799214908055, disc_loss = 0.08603775201897536
Trained batch 28 in epoch 2, gen_loss = 0.799116810847973, disc_loss = 0.08674678456937444
Trained batch 29 in epoch 2, gen_loss = 0.816071742773056, disc_loss = 0.08904340509325266
Trained batch 30 in epoch 2, gen_loss = 0.8136298137326394, disc_loss = 0.08818898392060111
Trained batch 31 in epoch 2, gen_loss = 0.8020876012742519, disc_loss = 0.09500040876446292
Trained batch 32 in epoch 2, gen_loss = 0.8154332890655055, disc_loss = 0.0993826702575792
Trained batch 33 in epoch 2, gen_loss = 0.8082663802539601, disc_loss = 0.10142707622007412
Trained batch 34 in epoch 2, gen_loss = 0.8075911555971418, disc_loss = 0.10103571856660502
Trained batch 35 in epoch 2, gen_loss = 0.821175217628479, disc_loss = 0.10586722624591655
Trained batch 36 in epoch 2, gen_loss = 0.8163568361385448, disc_loss = 0.10769376979284995
Trained batch 37 in epoch 2, gen_loss = 0.8239749136723971, disc_loss = 0.10674988395093303
Trained batch 38 in epoch 2, gen_loss = 0.8232512749158419, disc_loss = 0.10899731970559327
Trained batch 39 in epoch 2, gen_loss = 0.817082716524601, disc_loss = 0.1110513552557677
Trained batch 40 in epoch 2, gen_loss = 0.8153625116115664, disc_loss = 0.1098783406451708
Trained batch 41 in epoch 2, gen_loss = 0.8102072236083803, disc_loss = 0.11040045121418578
Trained batch 42 in epoch 2, gen_loss = 0.8159566992937133, disc_loss = 0.11237236108024452
Trained batch 43 in epoch 2, gen_loss = 0.8196112527088686, disc_loss = 0.11056057410314679
Trained batch 44 in epoch 2, gen_loss = 0.8146799551116095, disc_loss = 0.11410982720553875
Trained batch 45 in epoch 2, gen_loss = 0.8146325919939124, disc_loss = 0.11432883673873932
Trained batch 46 in epoch 2, gen_loss = 0.8180363152889495, disc_loss = 0.1143296305090189
Trained batch 47 in epoch 2, gen_loss = 0.8140277129908403, disc_loss = 0.114399784981894
Trained batch 48 in epoch 2, gen_loss = 0.8093793598973021, disc_loss = 0.11580709820347172
Trained batch 49 in epoch 2, gen_loss = 0.8116997468471527, disc_loss = 0.11576451133936644
Trained batch 50 in epoch 2, gen_loss = 0.8107946760514203, disc_loss = 0.11458968564721883
Trained batch 51 in epoch 2, gen_loss = 0.8075518069358972, disc_loss = 0.1142098128867264
Trained batch 52 in epoch 2, gen_loss = 0.8081600418630636, disc_loss = 0.11454987009319495
Trained batch 53 in epoch 2, gen_loss = 0.8039415732577995, disc_loss = 0.11433119040534452
Trained batch 54 in epoch 2, gen_loss = 0.8033137928355824, disc_loss = 0.11326555836607109
Trained batch 55 in epoch 2, gen_loss = 0.8031753450632095, disc_loss = 0.11372303653375379
Trained batch 56 in epoch 2, gen_loss = 0.7991034273515668, disc_loss = 0.11463794697141438
Trained batch 57 in epoch 2, gen_loss = 0.7968565780540993, disc_loss = 0.11423190538610878
Trained batch 58 in epoch 2, gen_loss = 0.7963945855528621, disc_loss = 0.11321377359583217
Trained batch 59 in epoch 2, gen_loss = 0.8008677889903386, disc_loss = 0.11252060492212573
Trained batch 60 in epoch 2, gen_loss = 0.7987662192250862, disc_loss = 0.11231227838968644
Trained batch 61 in epoch 2, gen_loss = 0.7954573044853825, disc_loss = 0.11374069350741563
Trained batch 62 in epoch 2, gen_loss = 0.8016322311900911, disc_loss = 0.11783835277079589
Trained batch 63 in epoch 2, gen_loss = 0.8022629683837295, disc_loss = 0.11729204244329594
Trained batch 64 in epoch 2, gen_loss = 0.7994880557060242, disc_loss = 0.11728870407319986
Trained batch 65 in epoch 2, gen_loss = 0.798458401000861, disc_loss = 0.11679746975388491
Trained batch 66 in epoch 2, gen_loss = 0.8026111979982746, disc_loss = 0.1173662745407713
Trained batch 67 in epoch 2, gen_loss = 0.8000742521356133, disc_loss = 0.11708867130801082
Trained batch 68 in epoch 2, gen_loss = 0.8024522817653158, disc_loss = 0.11573507356038992
Trained batch 69 in epoch 2, gen_loss = 0.8035061384950365, disc_loss = 0.11532091487731252
Trained batch 70 in epoch 2, gen_loss = 0.8024776670294749, disc_loss = 0.11460119905606123
Trained batch 71 in epoch 2, gen_loss = 0.8005153843098216, disc_loss = 0.11465239028135936
Trained batch 72 in epoch 2, gen_loss = 0.8041020362344506, disc_loss = 0.1151383641647966
Trained batch 73 in epoch 2, gen_loss = 0.8013393677569725, disc_loss = 0.11439574444414796
Trained batch 74 in epoch 2, gen_loss = 0.798076688448588, disc_loss = 0.11621885215242704
Trained batch 75 in epoch 2, gen_loss = 0.8015875518321991, disc_loss = 0.11859501501251209
Trained batch 76 in epoch 2, gen_loss = 0.7998677406992231, disc_loss = 0.11825104730276319
Trained batch 77 in epoch 2, gen_loss = 0.7980801463127136, disc_loss = 0.12015809610677071
Trained batch 78 in epoch 2, gen_loss = 0.7936299665819241, disc_loss = 0.12390118493120882
Trained batch 79 in epoch 2, gen_loss = 0.7956069823354482, disc_loss = 0.1235630167182535
Trained batch 80 in epoch 2, gen_loss = 0.7973443067368166, disc_loss = 0.12333717063805204
Trained batch 81 in epoch 2, gen_loss = 0.7950708288245085, disc_loss = 0.12342258492802702
Trained batch 82 in epoch 2, gen_loss = 0.7922920724713659, disc_loss = 0.12397180699619902
Trained batch 83 in epoch 2, gen_loss = 0.7917079347230139, disc_loss = 0.12387256231158972
Trained batch 84 in epoch 2, gen_loss = 0.7909546785494861, disc_loss = 0.12331242609549971
Trained batch 85 in epoch 2, gen_loss = 0.7898013581370198, disc_loss = 0.12376749233970809
Trained batch 86 in epoch 2, gen_loss = 0.787612329611833, disc_loss = 0.12336676169572205
Trained batch 87 in epoch 2, gen_loss = 0.7900747775354169, disc_loss = 0.12283162218095227
Trained batch 88 in epoch 2, gen_loss = 0.7888298647457295, disc_loss = 0.12243747681881605
Trained batch 89 in epoch 2, gen_loss = 0.7898517651690378, disc_loss = 0.12250732055140866
Trained batch 90 in epoch 2, gen_loss = 0.78872319990462, disc_loss = 0.1218308686882585
Trained batch 91 in epoch 2, gen_loss = 0.7872017009750657, disc_loss = 0.12185728485169618
Trained batch 92 in epoch 2, gen_loss = 0.7884250100581877, disc_loss = 0.12205966441862044
Trained batch 93 in epoch 2, gen_loss = 0.7895598617639947, disc_loss = 0.12127883660983532
Trained batch 94 in epoch 2, gen_loss = 0.7863281974666997, disc_loss = 0.12223507612943649
Trained batch 95 in epoch 2, gen_loss = 0.7898897351697087, disc_loss = 0.12172553028600912
Trained batch 96 in epoch 2, gen_loss = 0.7914074097097534, disc_loss = 0.12193841686875549
Trained batch 97 in epoch 2, gen_loss = 0.78865241973984, disc_loss = 0.12386246109191253
Trained batch 98 in epoch 2, gen_loss = 0.7896711913624195, disc_loss = 0.12352787357087087
Trained batch 99 in epoch 2, gen_loss = 0.7898828253149986, disc_loss = 0.1237514378875494
Trained batch 100 in epoch 2, gen_loss = 0.789434155910322, disc_loss = 0.12337016107717363
Trained batch 101 in epoch 2, gen_loss = 0.7888154518954894, disc_loss = 0.12311417120052319
Trained batch 102 in epoch 2, gen_loss = 0.787085122564464, disc_loss = 0.1226832018170542
Trained batch 103 in epoch 2, gen_loss = 0.7893481314755403, disc_loss = 0.12189380666957451
Trained batch 104 in epoch 2, gen_loss = 0.789656928323564, disc_loss = 0.12149386547860645
Trained batch 105 in epoch 2, gen_loss = 0.788452851041308, disc_loss = 0.12100884472986437
Trained batch 106 in epoch 2, gen_loss = 0.78860950832055, disc_loss = 0.12046942066087901
Trained batch 107 in epoch 2, gen_loss = 0.7904717428264795, disc_loss = 0.12028109544405231
Trained batch 108 in epoch 2, gen_loss = 0.7900381036307833, disc_loss = 0.1196667648031624
Trained batch 109 in epoch 2, gen_loss = 0.7867893468249928, disc_loss = 0.120416653461077
Trained batch 110 in epoch 2, gen_loss = 0.7899043055268021, disc_loss = 0.1216520952010477
Trained batch 111 in epoch 2, gen_loss = 0.7883072351770741, disc_loss = 0.12225852790288627
Trained batch 112 in epoch 2, gen_loss = 0.7880715384947515, disc_loss = 0.12190512999628497
Trained batch 113 in epoch 2, gen_loss = 0.7908894085047538, disc_loss = 0.12130649456460225
Trained batch 114 in epoch 2, gen_loss = 0.790238342596137, disc_loss = 0.12083903722788976
Trained batch 115 in epoch 2, gen_loss = 0.7885230337751323, disc_loss = 0.1210620298275146
Trained batch 116 in epoch 2, gen_loss = 0.7893838449421092, disc_loss = 0.1204799079360106
Trained batch 117 in epoch 2, gen_loss = 0.7921290867409464, disc_loss = 0.12048559010786525
Trained batch 118 in epoch 2, gen_loss = 0.7918060131433631, disc_loss = 0.12012710491148364
Trained batch 119 in epoch 2, gen_loss = 0.7923314491907756, disc_loss = 0.11975123224159082
Trained batch 120 in epoch 2, gen_loss = 0.7912082992309382, disc_loss = 0.1196352423222597
Trained batch 121 in epoch 2, gen_loss = 0.7946325174120606, disc_loss = 0.11903289558946109
Trained batch 122 in epoch 2, gen_loss = 0.7951605208520967, disc_loss = 0.11853150272272467
Trained batch 123 in epoch 2, gen_loss = 0.7956770793084176, disc_loss = 0.11784712387429129
Trained batch 124 in epoch 2, gen_loss = 0.7949618844985962, disc_loss = 0.11757566207647324
Trained batch 125 in epoch 2, gen_loss = 0.7970093308933197, disc_loss = 0.11843511562735315
Trained batch 126 in epoch 2, gen_loss = 0.7993383435752448, disc_loss = 0.11766332421657139
Trained batch 127 in epoch 2, gen_loss = 0.7985533149912953, disc_loss = 0.11748086717852857
Trained batch 128 in epoch 2, gen_loss = 0.7971335912859717, disc_loss = 0.11710659268694792
Trained batch 129 in epoch 2, gen_loss = 0.7986725183633657, disc_loss = 0.11700467712317522
Trained batch 130 in epoch 2, gen_loss = 0.7973575655740636, disc_loss = 0.11685092495541081
Trained batch 131 in epoch 2, gen_loss = 0.7979233517791285, disc_loss = 0.11650191505693576
Trained batch 132 in epoch 2, gen_loss = 0.7996545026176854, disc_loss = 0.11627600329430927
Trained batch 133 in epoch 2, gen_loss = 0.7989671314830211, disc_loss = 0.11597573544496476
Trained batch 134 in epoch 2, gen_loss = 0.7984933742770443, disc_loss = 0.11555524582940119
Trained batch 135 in epoch 2, gen_loss = 0.7992634637390866, disc_loss = 0.11535845438073225
Trained batch 136 in epoch 2, gen_loss = 0.7988969326889428, disc_loss = 0.11503137005017186
Trained batch 137 in epoch 2, gen_loss = 0.798572148533835, disc_loss = 0.11476096450148718
Trained batch 138 in epoch 2, gen_loss = 0.7988217756044951, disc_loss = 0.11442606064001862
Trained batch 139 in epoch 2, gen_loss = 0.7987152069807053, disc_loss = 0.11416303077712656
Trained batch 140 in epoch 2, gen_loss = 0.7977786846194707, disc_loss = 0.11376576554954898
Trained batch 141 in epoch 2, gen_loss = 0.7971832907535661, disc_loss = 0.11393858341526397
Trained batch 142 in epoch 2, gen_loss = 0.7974489618848254, disc_loss = 0.11346906088813619
Trained batch 143 in epoch 2, gen_loss = 0.7975608805815378, disc_loss = 0.11307227110955864
Trained batch 144 in epoch 2, gen_loss = 0.7967705660852893, disc_loss = 0.11304186743138166
Trained batch 145 in epoch 2, gen_loss = 0.7966040176888035, disc_loss = 0.11276090008602159
Trained batch 146 in epoch 2, gen_loss = 0.7969113847836345, disc_loss = 0.11265137645916469
Trained batch 147 in epoch 2, gen_loss = 0.7961998400655953, disc_loss = 0.1126487948428336
Trained batch 148 in epoch 2, gen_loss = 0.7958266039022663, disc_loss = 0.11239091228168682
Trained batch 149 in epoch 2, gen_loss = 0.7986961555480957, disc_loss = 0.11344699011494716
Trained batch 150 in epoch 2, gen_loss = 0.7977133448550243, disc_loss = 0.1137792971972006
Trained batch 151 in epoch 2, gen_loss = 0.7968803561831775, disc_loss = 0.11340746044573423
Trained batch 152 in epoch 2, gen_loss = 0.7968216452723235, disc_loss = 0.11332356614468533
Trained batch 153 in epoch 2, gen_loss = 0.7962214532610657, disc_loss = 0.11344736907631159
Trained batch 154 in epoch 2, gen_loss = 0.7950557470321655, disc_loss = 0.1131351112958885
Trained batch 155 in epoch 2, gen_loss = 0.7963371513745724, disc_loss = 0.11271560582547234
Trained batch 156 in epoch 2, gen_loss = 0.7971342437586207, disc_loss = 0.11283159444618757
Trained batch 157 in epoch 2, gen_loss = 0.795894452288181, disc_loss = 0.1139062986225833
Trained batch 158 in epoch 2, gen_loss = 0.7984803015331052, disc_loss = 0.1151746143967663
Trained batch 159 in epoch 2, gen_loss = 0.7974119149148464, disc_loss = 0.1151296909316443
Trained batch 160 in epoch 2, gen_loss = 0.7966772458568123, disc_loss = 0.11525627826080188
Trained batch 161 in epoch 2, gen_loss = 0.7973949578073289, disc_loss = 0.1150522954463039
Trained batch 162 in epoch 2, gen_loss = 0.7981953924418959, disc_loss = 0.11626251941215407
Trained batch 163 in epoch 2, gen_loss = 0.7964635843910822, disc_loss = 0.11774618518198045
Trained batch 164 in epoch 2, gen_loss = 0.7967862862529177, disc_loss = 0.117530834076531
Trained batch 165 in epoch 2, gen_loss = 0.7971604599292019, disc_loss = 0.11769073872815773
Trained batch 166 in epoch 2, gen_loss = 0.7980798122411716, disc_loss = 0.11837643691656476
Trained batch 167 in epoch 2, gen_loss = 0.797009717850458, disc_loss = 0.1190034943477561
Trained batch 168 in epoch 2, gen_loss = 0.797750358398144, disc_loss = 0.11917231371901797
Trained batch 169 in epoch 2, gen_loss = 0.7969231587999007, disc_loss = 0.1190452491864562
Trained batch 170 in epoch 2, gen_loss = 0.7962436142720675, disc_loss = 0.11927858956855292
Trained batch 171 in epoch 2, gen_loss = 0.7957366341075232, disc_loss = 0.11917479880977162
Trained batch 172 in epoch 2, gen_loss = 0.7953987255950884, disc_loss = 0.11915128694233522
Trained batch 173 in epoch 2, gen_loss = 0.7945771453709438, disc_loss = 0.11935294105874739
Trained batch 174 in epoch 2, gen_loss = 0.7938672695841108, disc_loss = 0.11901785008609295
Trained batch 175 in epoch 2, gen_loss = 0.7940623550252481, disc_loss = 0.11892678378022868
Trained batch 176 in epoch 2, gen_loss = 0.7936636664099612, disc_loss = 0.11843774950731609
Trained batch 177 in epoch 2, gen_loss = 0.7930778844302959, disc_loss = 0.11847194781254851
Trained batch 178 in epoch 2, gen_loss = 0.7934308201907068, disc_loss = 0.11856320736586382
Trained batch 179 in epoch 2, gen_loss = 0.7942423284053802, disc_loss = 0.11819882938224409
Trained batch 180 in epoch 2, gen_loss = 0.7930850620427843, disc_loss = 0.11861418277148714
Trained batch 181 in epoch 2, gen_loss = 0.7934521459616147, disc_loss = 0.11828815133648586
Trained batch 182 in epoch 2, gen_loss = 0.7941094532690413, disc_loss = 0.11799150333826333
Trained batch 183 in epoch 2, gen_loss = 0.7934385447398477, disc_loss = 0.11806665444949074
Trained batch 184 in epoch 2, gen_loss = 0.7935268379546501, disc_loss = 0.11779539410931034
Trained batch 185 in epoch 2, gen_loss = 0.793524065004882, disc_loss = 0.11784637257737178
Trained batch 186 in epoch 2, gen_loss = 0.7927251400794575, disc_loss = 0.11784237355272718
Trained batch 187 in epoch 2, gen_loss = 0.7928548819841222, disc_loss = 0.11756956287005797
Trained batch 188 in epoch 2, gen_loss = 0.7936969922963905, disc_loss = 0.11804174693922202
Trained batch 189 in epoch 2, gen_loss = 0.7934411673169387, disc_loss = 0.11775374027263177
Trained batch 190 in epoch 2, gen_loss = 0.7928373401701763, disc_loss = 0.11770235816338612
Trained batch 191 in epoch 2, gen_loss = 0.7942764783898989, disc_loss = 0.11766758486434507
Trained batch 192 in epoch 2, gen_loss = 0.7933278293807272, disc_loss = 0.11772584562899226
Trained batch 193 in epoch 2, gen_loss = 0.7936736253119007, disc_loss = 0.11757139595628706
Trained batch 194 in epoch 2, gen_loss = 0.7930451585696294, disc_loss = 0.11733505029517871
Trained batch 195 in epoch 2, gen_loss = 0.7937565284724138, disc_loss = 0.11701793876495592
Trained batch 196 in epoch 2, gen_loss = 0.7930093074813107, disc_loss = 0.11683905509484903
Trained batch 197 in epoch 2, gen_loss = 0.7934172048111154, disc_loss = 0.11639150072152567
Trained batch 198 in epoch 2, gen_loss = 0.7947937217190038, disc_loss = 0.11646207910611402
Trained batch 199 in epoch 2, gen_loss = 0.7942214831709862, disc_loss = 0.11630792835727334
Trained batch 200 in epoch 2, gen_loss = 0.7935509915968672, disc_loss = 0.11622361762829088
Trained batch 201 in epoch 2, gen_loss = 0.794071508811252, disc_loss = 0.11674641439746512
Trained batch 202 in epoch 2, gen_loss = 0.7934325281622374, disc_loss = 0.1167236568929233
Trained batch 203 in epoch 2, gen_loss = 0.7924375329531875, disc_loss = 0.11687443589828178
Trained batch 204 in epoch 2, gen_loss = 0.7921174828599139, disc_loss = 0.11706690157695514
Trained batch 205 in epoch 2, gen_loss = 0.7922044558432496, disc_loss = 0.11665174929262365
Trained batch 206 in epoch 2, gen_loss = 0.7914913198798175, disc_loss = 0.1165242582415613
Trained batch 207 in epoch 2, gen_loss = 0.7918334216452562, disc_loss = 0.11659791492498837
Trained batch 208 in epoch 2, gen_loss = 0.7919264971924741, disc_loss = 0.11644451694482821
Trained batch 209 in epoch 2, gen_loss = 0.7914905681496575, disc_loss = 0.116800231415601
Trained batch 210 in epoch 2, gen_loss = 0.7903714795813176, disc_loss = 0.11665940281197923
Trained batch 211 in epoch 2, gen_loss = 0.7904807396654813, disc_loss = 0.11662321917290958
Trained batch 212 in epoch 2, gen_loss = 0.7898822787781836, disc_loss = 0.11647973769287548
Trained batch 213 in epoch 2, gen_loss = 0.790543666231298, disc_loss = 0.11685234019271681
Trained batch 214 in epoch 2, gen_loss = 0.7894686629605848, disc_loss = 0.11705212658920953
Trained batch 215 in epoch 2, gen_loss = 0.7888821426917005, disc_loss = 0.11718603440870841
Trained batch 216 in epoch 2, gen_loss = 0.7899406414976867, disc_loss = 0.11765954547351407
Trained batch 217 in epoch 2, gen_loss = 0.789815177337839, disc_loss = 0.11754185822578746
Trained batch 218 in epoch 2, gen_loss = 0.7900747166921015, disc_loss = 0.11734305257530517
Trained batch 219 in epoch 2, gen_loss = 0.7901272760196165, disc_loss = 0.11719352376054634
Trained batch 220 in epoch 2, gen_loss = 0.7897930811433231, disc_loss = 0.1168909938289569
Trained batch 221 in epoch 2, gen_loss = 0.7899596320616232, disc_loss = 0.11678002247804994
Trained batch 222 in epoch 2, gen_loss = 0.7893680478425303, disc_loss = 0.11669424570462095
Trained batch 223 in epoch 2, gen_loss = 0.7904016556484359, disc_loss = 0.11665472102218441
Trained batch 224 in epoch 2, gen_loss = 0.7898133529557122, disc_loss = 0.11644152780373891
Trained batch 225 in epoch 2, gen_loss = 0.7899522259172085, disc_loss = 0.1163831013625702
Trained batch 226 in epoch 2, gen_loss = 0.7892921338522487, disc_loss = 0.11619747928979639
Trained batch 227 in epoch 2, gen_loss = 0.789898896949333, disc_loss = 0.11586520827391691
Trained batch 228 in epoch 2, gen_loss = 0.790043307704176, disc_loss = 0.1157639604468533
Trained batch 229 in epoch 2, gen_loss = 0.7895554309305938, disc_loss = 0.11556457452799963
Trained batch 230 in epoch 2, gen_loss = 0.7894185216395886, disc_loss = 0.11546376844247182
Trained batch 231 in epoch 2, gen_loss = 0.7911035765347809, disc_loss = 0.11566050678234675
Trained batch 232 in epoch 2, gen_loss = 0.7907108106838275, disc_loss = 0.11563479017802063
Trained batch 233 in epoch 2, gen_loss = 0.7918832029542352, disc_loss = 0.11526551863385572
Trained batch 234 in epoch 2, gen_loss = 0.7907437943397684, disc_loss = 0.11579771836070304
Trained batch 235 in epoch 2, gen_loss = 0.7911634427511086, disc_loss = 0.11599395874003737
Trained batch 236 in epoch 2, gen_loss = 0.7915146476608791, disc_loss = 0.11633337010877041
Trained batch 237 in epoch 2, gen_loss = 0.7924361794936556, disc_loss = 0.11668502146519032
Trained batch 238 in epoch 2, gen_loss = 0.7919979399717004, disc_loss = 0.11704174521141471
Trained batch 239 in epoch 2, gen_loss = 0.7921851431330045, disc_loss = 0.11688699779721598
Trained batch 240 in epoch 2, gen_loss = 0.7922290130769564, disc_loss = 0.11679177470041509
Trained batch 241 in epoch 2, gen_loss = 0.7918427111196124, disc_loss = 0.11669312865465634
Trained batch 242 in epoch 2, gen_loss = 0.7917734740202319, disc_loss = 0.11663593850079387
Trained batch 243 in epoch 2, gen_loss = 0.7912613751946903, disc_loss = 0.11650455017864216
Trained batch 244 in epoch 2, gen_loss = 0.7909401436241306, disc_loss = 0.11658028225813594
Trained batch 245 in epoch 2, gen_loss = 0.7923315831316196, disc_loss = 0.11653475280154527
Trained batch 246 in epoch 2, gen_loss = 0.7923983996696318, disc_loss = 0.11630837866651868
Trained batch 247 in epoch 2, gen_loss = 0.7918143406991036, disc_loss = 0.11607268431614484
Trained batch 248 in epoch 2, gen_loss = 0.7908922359646564, disc_loss = 0.11609420979238418
Trained batch 249 in epoch 2, gen_loss = 0.7924289729595184, disc_loss = 0.11660209676623344
Trained batch 250 in epoch 2, gen_loss = 0.7925725363165259, disc_loss = 0.1164918772846579
Trained batch 251 in epoch 2, gen_loss = 0.7919787000569086, disc_loss = 0.1163395427108284
Trained batch 252 in epoch 2, gen_loss = 0.7927683019355352, disc_loss = 0.11618370368428853
Trained batch 253 in epoch 2, gen_loss = 0.7928893831301862, disc_loss = 0.11597881175753638
Trained batch 254 in epoch 2, gen_loss = 0.7926068810855641, disc_loss = 0.11598924664305706
Trained batch 255 in epoch 2, gen_loss = 0.7940149432979524, disc_loss = 0.115952163701877
Trained batch 256 in epoch 2, gen_loss = 0.7938894719929083, disc_loss = 0.11566974651720738
Trained batch 257 in epoch 2, gen_loss = 0.793581942024157, disc_loss = 0.11550533996765004
Trained batch 258 in epoch 2, gen_loss = 0.7941640926143838, disc_loss = 0.11533024012467115
Trained batch 259 in epoch 2, gen_loss = 0.7951594162445802, disc_loss = 0.11501854765587129
Trained batch 260 in epoch 2, gen_loss = 0.7948991226967267, disc_loss = 0.11498428951106766
Trained batch 261 in epoch 2, gen_loss = 0.7946668153500739, disc_loss = 0.1147556170138694
Trained batch 262 in epoch 2, gen_loss = 0.7955745843880077, disc_loss = 0.11499095812949844
Trained batch 263 in epoch 2, gen_loss = 0.794438115800872, disc_loss = 0.11517763137817383
Trained batch 264 in epoch 2, gen_loss = 0.7951663176968412, disc_loss = 0.1152768020359975
Trained batch 265 in epoch 2, gen_loss = 0.7946932748296207, disc_loss = 0.11534190049072854
Trained batch 266 in epoch 2, gen_loss = 0.7946344209967481, disc_loss = 0.11503247978089008
Trained batch 267 in epoch 2, gen_loss = 0.7942768995886418, disc_loss = 0.11480933753078554
Trained batch 268 in epoch 2, gen_loss = 0.7955673859908236, disc_loss = 0.11468900729067706
Trained batch 269 in epoch 2, gen_loss = 0.7949097772439321, disc_loss = 0.11458374485373497
Trained batch 270 in epoch 2, gen_loss = 0.7944588812954751, disc_loss = 0.11453851779778505
Trained batch 271 in epoch 2, gen_loss = 0.7938253283500671, disc_loss = 0.11447983243338325
Trained batch 272 in epoch 2, gen_loss = 0.7944159167153495, disc_loss = 0.11443280641521726
Trained batch 273 in epoch 2, gen_loss = 0.7935956520755796, disc_loss = 0.11459731585244193
Trained batch 274 in epoch 2, gen_loss = 0.7945936922593551, disc_loss = 0.11466897842558947
Trained batch 275 in epoch 2, gen_loss = 0.7939048551994822, disc_loss = 0.11480725872451844
Trained batch 276 in epoch 2, gen_loss = 0.7940124854284073, disc_loss = 0.1149013928719376
Trained batch 277 in epoch 2, gen_loss = 0.7933295459198437, disc_loss = 0.11489316510210792
Trained batch 278 in epoch 2, gen_loss = 0.7932409755217986, disc_loss = 0.1151809204757
Trained batch 279 in epoch 2, gen_loss = 0.7926253478441919, disc_loss = 0.11527996510267258
Trained batch 280 in epoch 2, gen_loss = 0.7932090829275681, disc_loss = 0.11521011004986711
Trained batch 281 in epoch 2, gen_loss = 0.793193370526564, disc_loss = 0.11500051151300576
Trained batch 282 in epoch 2, gen_loss = 0.7928520346277594, disc_loss = 0.11481407475608398
Trained batch 283 in epoch 2, gen_loss = 0.7934980952823666, disc_loss = 0.11449299108000918
Trained batch 284 in epoch 2, gen_loss = 0.7941113921633938, disc_loss = 0.11438519388045135
Trained batch 285 in epoch 2, gen_loss = 0.7933558994656676, disc_loss = 0.114551247553444
Trained batch 286 in epoch 2, gen_loss = 0.7936475239564318, disc_loss = 0.11445123783413334
Trained batch 287 in epoch 2, gen_loss = 0.7943300037748284, disc_loss = 0.11417910734113927
Trained batch 288 in epoch 2, gen_loss = 0.7938073234162116, disc_loss = 0.11412805236979133
Trained batch 289 in epoch 2, gen_loss = 0.7928846786762106, disc_loss = 0.11400839841185972
Trained batch 290 in epoch 2, gen_loss = 0.7934015378919254, disc_loss = 0.11381214498014179
Trained batch 291 in epoch 2, gen_loss = 0.7939605055606529, disc_loss = 0.11347291159622167
Trained batch 292 in epoch 2, gen_loss = 0.7950358118213484, disc_loss = 0.11314020673633131
Trained batch 293 in epoch 2, gen_loss = 0.7946052433682137, disc_loss = 0.11297257020626039
Trained batch 294 in epoch 2, gen_loss = 0.7942798464985217, disc_loss = 0.11285684996805453
Trained batch 295 in epoch 2, gen_loss = 0.7950004508366456, disc_loss = 0.11280673582773856
Trained batch 296 in epoch 2, gen_loss = 0.7953855872956992, disc_loss = 0.11255249062785094
Trained batch 297 in epoch 2, gen_loss = 0.7946332523086727, disc_loss = 0.11271506870765514
Trained batch 298 in epoch 2, gen_loss = 0.7959234836109506, disc_loss = 0.1127345502457541
Trained batch 299 in epoch 2, gen_loss = 0.7966524082422256, disc_loss = 0.11267466021391252
Trained batch 300 in epoch 2, gen_loss = 0.7965055329855099, disc_loss = 0.11258675826657749
Trained batch 301 in epoch 2, gen_loss = 0.7959562553869968, disc_loss = 0.11267767545908985
Trained batch 302 in epoch 2, gen_loss = 0.796408720339092, disc_loss = 0.11259483671731779
Trained batch 303 in epoch 2, gen_loss = 0.7963645197451115, disc_loss = 0.11246120376132526
Trained batch 304 in epoch 2, gen_loss = 0.7970460467651242, disc_loss = 0.11214983298702806
Trained batch 305 in epoch 2, gen_loss = 0.796656377175275, disc_loss = 0.11195132264477853
Trained batch 306 in epoch 2, gen_loss = 0.7971513739237956, disc_loss = 0.11190051681601748
Trained batch 307 in epoch 2, gen_loss = 0.796735061647056, disc_loss = 0.1117533112410456
Trained batch 308 in epoch 2, gen_loss = 0.7967110744957785, disc_loss = 0.11153164712416798
Trained batch 309 in epoch 2, gen_loss = 0.7968452868923064, disc_loss = 0.11159094350051976
Trained batch 310 in epoch 2, gen_loss = 0.7968381896279633, disc_loss = 0.11137288291654115
Trained batch 311 in epoch 2, gen_loss = 0.7969655480522376, disc_loss = 0.11116485584539194
Trained batch 312 in epoch 2, gen_loss = 0.7964680813752805, disc_loss = 0.11121159730354152
Trained batch 313 in epoch 2, gen_loss = 0.7963791609190072, disc_loss = 0.11093780380276264
Trained batch 314 in epoch 2, gen_loss = 0.7983412623405457, disc_loss = 0.11149502719146391
Trained batch 315 in epoch 2, gen_loss = 0.7975117549111571, disc_loss = 0.11219468902313162
Trained batch 316 in epoch 2, gen_loss = 0.7975983442944307, disc_loss = 0.1120618980242768
Trained batch 317 in epoch 2, gen_loss = 0.7979276564511113, disc_loss = 0.11217135704948374
Trained batch 318 in epoch 2, gen_loss = 0.7978403590689632, disc_loss = 0.11211487588685788
Trained batch 319 in epoch 2, gen_loss = 0.797800013050437, disc_loss = 0.11198868461360689
Trained batch 320 in epoch 2, gen_loss = 0.7979411792903675, disc_loss = 0.11182916823287155
Trained batch 321 in epoch 2, gen_loss = 0.7977751336112526, disc_loss = 0.11169557791399937
Trained batch 322 in epoch 2, gen_loss = 0.7980079169243851, disc_loss = 0.11195973318139374
Trained batch 323 in epoch 2, gen_loss = 0.7974099862722703, disc_loss = 0.1118848074980678
Trained batch 324 in epoch 2, gen_loss = 0.7971627503175002, disc_loss = 0.11183123909223538
Trained batch 325 in epoch 2, gen_loss = 0.7973734884539996, disc_loss = 0.1119768923931281
Trained batch 326 in epoch 2, gen_loss = 0.7965834762342844, disc_loss = 0.11215704542496427
Trained batch 327 in epoch 2, gen_loss = 0.7972011495290733, disc_loss = 0.1125458884592418
Trained batch 328 in epoch 2, gen_loss = 0.7970784792059461, disc_loss = 0.1123943039864347
Trained batch 329 in epoch 2, gen_loss = 0.797033583576029, disc_loss = 0.11221712326179399
Trained batch 330 in epoch 2, gen_loss = 0.7971035326715683, disc_loss = 0.11212275881500312
Trained batch 331 in epoch 2, gen_loss = 0.797176110457225, disc_loss = 0.11233636090273869
Trained batch 332 in epoch 2, gen_loss = 0.7967487312293984, disc_loss = 0.11230706817025805
Trained batch 333 in epoch 2, gen_loss = 0.7967335007147874, disc_loss = 0.11209749092186193
Trained batch 334 in epoch 2, gen_loss = 0.7971910412631817, disc_loss = 0.11226225100290864
Trained batch 335 in epoch 2, gen_loss = 0.7967132416864237, disc_loss = 0.11243027720012747
Trained batch 336 in epoch 2, gen_loss = 0.7966314235851389, disc_loss = 0.11220693458645474
Trained batch 337 in epoch 2, gen_loss = 0.7974879336074965, disc_loss = 0.11238255703094355
Trained batch 338 in epoch 2, gen_loss = 0.7967230041118498, disc_loss = 0.1127186227551384
Trained batch 339 in epoch 2, gen_loss = 0.7965959005496082, disc_loss = 0.11259499548057861
Trained batch 340 in epoch 2, gen_loss = 0.796720861165055, disc_loss = 0.11263293164162255
Trained batch 341 in epoch 2, gen_loss = 0.7963034951547433, disc_loss = 0.11258368310382405
Trained batch 342 in epoch 2, gen_loss = 0.796418445798468, disc_loss = 0.1125905237760688
Trained batch 343 in epoch 2, gen_loss = 0.7959026730684347, disc_loss = 0.11254427364085216
Trained batch 344 in epoch 2, gen_loss = 0.796761459371318, disc_loss = 0.11253257783372765
Trained batch 345 in epoch 2, gen_loss = 0.796541968694312, disc_loss = 0.11236299290940854
Trained batch 346 in epoch 2, gen_loss = 0.7964390260341875, disc_loss = 0.11221114260222366
Trained batch 347 in epoch 2, gen_loss = 0.7966028727676676, disc_loss = 0.11216806495915456
Trained batch 348 in epoch 2, gen_loss = 0.7967025340457359, disc_loss = 0.11207988781101981
Trained batch 349 in epoch 2, gen_loss = 0.7961326774529048, disc_loss = 0.11213375721392888
Trained batch 350 in epoch 2, gen_loss = 0.7961141772759266, disc_loss = 0.11215842714496063
Trained batch 351 in epoch 2, gen_loss = 0.796408320015127, disc_loss = 0.11204619682129388
Trained batch 352 in epoch 2, gen_loss = 0.7963265418668645, disc_loss = 0.11185441546870274
Trained batch 353 in epoch 2, gen_loss = 0.7955519422299444, disc_loss = 0.11205531562820582
Trained batch 354 in epoch 2, gen_loss = 0.7963499354644561, disc_loss = 0.1120928022512038
Trained batch 355 in epoch 2, gen_loss = 0.7962439763412047, disc_loss = 0.11202683166621692
Trained batch 356 in epoch 2, gen_loss = 0.7953739965162357, disc_loss = 0.11217295502362047
Trained batch 357 in epoch 2, gen_loss = 0.7949264689697234, disc_loss = 0.11227360788951289
Trained batch 358 in epoch 2, gen_loss = 0.794945827350643, disc_loss = 0.11221558943878558
Trained batch 359 in epoch 2, gen_loss = 0.7951948948204517, disc_loss = 0.11209349937271326
Trained batch 360 in epoch 2, gen_loss = 0.7957019455049837, disc_loss = 0.11198667039284663
Trained batch 361 in epoch 2, gen_loss = 0.796024742623719, disc_loss = 0.11220765530353011
Trained batch 362 in epoch 2, gen_loss = 0.7969788413895064, disc_loss = 0.11225788579283913
Trained batch 363 in epoch 2, gen_loss = 0.7963608667909444, disc_loss = 0.11241156887007202
Trained batch 364 in epoch 2, gen_loss = 0.7968682410782331, disc_loss = 0.11314557856841854
Trained batch 365 in epoch 2, gen_loss = 0.7960406325228228, disc_loss = 0.1140836508298303
Trained batch 366 in epoch 2, gen_loss = 0.7960507224950868, disc_loss = 0.11405210146979919
Trained batch 367 in epoch 2, gen_loss = 0.7963152624990629, disc_loss = 0.11391971566785208
Trained batch 368 in epoch 2, gen_loss = 0.7961968188363362, disc_loss = 0.11403894722007396
Trained batch 369 in epoch 2, gen_loss = 0.7961438170961431, disc_loss = 0.11389202639410222
Trained batch 370 in epoch 2, gen_loss = 0.7952972014316652, disc_loss = 0.11404678159998353
Trained batch 371 in epoch 2, gen_loss = 0.7955484295724541, disc_loss = 0.11399975726230731
Trained batch 372 in epoch 2, gen_loss = 0.7964421285381266, disc_loss = 0.11422145457304116
Trained batch 373 in epoch 2, gen_loss = 0.795843204871856, disc_loss = 0.11428467326493745
Trained batch 374 in epoch 2, gen_loss = 0.7955255886713664, disc_loss = 0.11431352900216976
Trained batch 375 in epoch 2, gen_loss = 0.7961927011926123, disc_loss = 0.11424547200774814
Trained batch 376 in epoch 2, gen_loss = 0.7959599153432669, disc_loss = 0.11421661103386382
Trained batch 377 in epoch 2, gen_loss = 0.795782139692357, disc_loss = 0.11409576470525097
Trained batch 378 in epoch 2, gen_loss = 0.7955662578265711, disc_loss = 0.1139676470707581
Trained batch 379 in epoch 2, gen_loss = 0.7967803572353563, disc_loss = 0.11380475962191428
Trained batch 380 in epoch 2, gen_loss = 0.796594631171289, disc_loss = 0.11368641694103247
Trained batch 381 in epoch 2, gen_loss = 0.7962033369466273, disc_loss = 0.11364313330823136
Trained batch 382 in epoch 2, gen_loss = 0.7958738427249321, disc_loss = 0.11358955174480266
Trained batch 383 in epoch 2, gen_loss = 0.7959378128871322, disc_loss = 0.11345589419700748
Trained batch 384 in epoch 2, gen_loss = 0.7965604048270684, disc_loss = 0.11366035801588328
Trained batch 385 in epoch 2, gen_loss = 0.7961388296722748, disc_loss = 0.11388924878833748
Trained batch 386 in epoch 2, gen_loss = 0.7955986475451664, disc_loss = 0.11391992222768006
Trained batch 387 in epoch 2, gen_loss = 0.7965187309021803, disc_loss = 0.11408466913679749
Trained batch 388 in epoch 2, gen_loss = 0.7960569973470006, disc_loss = 0.11420068013359694
Trained batch 389 in epoch 2, gen_loss = 0.795926280816396, disc_loss = 0.11411158223517048
Trained batch 390 in epoch 2, gen_loss = 0.7957777292527202, disc_loss = 0.11398029629179203
Trained batch 391 in epoch 2, gen_loss = 0.7959124579721567, disc_loss = 0.11397359456287279
Trained batch 392 in epoch 2, gen_loss = 0.7957022124877716, disc_loss = 0.11392609444008453
Trained batch 393 in epoch 2, gen_loss = 0.7956845353400042, disc_loss = 0.11380557623942415
Trained batch 394 in epoch 2, gen_loss = 0.7951594121848481, disc_loss = 0.11390356978613742
Trained batch 395 in epoch 2, gen_loss = 0.7958180409188222, disc_loss = 0.11413144541085896
Trained batch 396 in epoch 2, gen_loss = 0.795259083548481, disc_loss = 0.11421016551863862
Trained batch 397 in epoch 2, gen_loss = 0.7953627864320074, disc_loss = 0.11420230010299752
Trained batch 398 in epoch 2, gen_loss = 0.7951172605194244, disc_loss = 0.11411337523410718
Trained batch 399 in epoch 2, gen_loss = 0.7946989724040031, disc_loss = 0.11420834353892133
Trained batch 400 in epoch 2, gen_loss = 0.7940681159050388, disc_loss = 0.11430198101656618
Trained batch 401 in epoch 2, gen_loss = 0.7944691861743358, disc_loss = 0.11422178833814922
Trained batch 402 in epoch 2, gen_loss = 0.7947064095336214, disc_loss = 0.11420633932968449
Trained batch 403 in epoch 2, gen_loss = 0.7942252645988276, disc_loss = 0.11422414375736498
Trained batch 404 in epoch 2, gen_loss = 0.7942382509325757, disc_loss = 0.11414288914084067
Trained batch 405 in epoch 2, gen_loss = 0.7941000253108922, disc_loss = 0.11420702764287298
Trained batch 406 in epoch 2, gen_loss = 0.7941300429641761, disc_loss = 0.11406292616909128
Trained batch 407 in epoch 2, gen_loss = 0.7940227514972874, disc_loss = 0.11388107696685064
Trained batch 408 in epoch 2, gen_loss = 0.7943716990627112, disc_loss = 0.11384529316875273
Trained batch 409 in epoch 2, gen_loss = 0.7939918192421518, disc_loss = 0.11397902729989189
Trained batch 410 in epoch 2, gen_loss = 0.794406802404826, disc_loss = 0.11392283558147595
Trained batch 411 in epoch 2, gen_loss = 0.7945393535118659, disc_loss = 0.11374003467041528
Trained batch 412 in epoch 2, gen_loss = 0.7944528268555463, disc_loss = 0.11357417750255752
Trained batch 413 in epoch 2, gen_loss = 0.7952582075975944, disc_loss = 0.11348880790308982
Trained batch 414 in epoch 2, gen_loss = 0.7951226648077907, disc_loss = 0.11332875762852919
Trained batch 415 in epoch 2, gen_loss = 0.7947620975856597, disc_loss = 0.11325501852731507
Trained batch 416 in epoch 2, gen_loss = 0.7948951925591028, disc_loss = 0.11322147239946562
Trained batch 417 in epoch 2, gen_loss = 0.7946622498582995, disc_loss = 0.1131159406863866
Trained batch 418 in epoch 2, gen_loss = 0.7949379775006333, disc_loss = 0.11309325677033753
Trained batch 419 in epoch 2, gen_loss = 0.7944912318672452, disc_loss = 0.11300438773552222
Trained batch 420 in epoch 2, gen_loss = 0.7950197117062476, disc_loss = 0.1128335670145525
Trained batch 421 in epoch 2, gen_loss = 0.7956498746905847, disc_loss = 0.1126344704016231
Trained batch 422 in epoch 2, gen_loss = 0.7954922896186792, disc_loss = 0.11256300947512225
Trained batch 423 in epoch 2, gen_loss = 0.7953931118519801, disc_loss = 0.11261877975259679
Trained batch 424 in epoch 2, gen_loss = 0.7958829582438749, disc_loss = 0.11245282816317152
Trained batch 425 in epoch 2, gen_loss = 0.7959547619304747, disc_loss = 0.11224720610672949
Trained batch 426 in epoch 2, gen_loss = 0.7956816447981627, disc_loss = 0.11220777103899862
Trained batch 427 in epoch 2, gen_loss = 0.795433420165677, disc_loss = 0.11215213643796046
Trained batch 428 in epoch 2, gen_loss = 0.7951698067027094, disc_loss = 0.11215638894900366
Trained batch 429 in epoch 2, gen_loss = 0.7947415428106175, disc_loss = 0.11208683366042584
Trained batch 430 in epoch 2, gen_loss = 0.7949936880866225, disc_loss = 0.11191943040000936
Trained batch 431 in epoch 2, gen_loss = 0.7948990722221357, disc_loss = 0.11185369058727736
Trained batch 432 in epoch 2, gen_loss = 0.7948799476061903, disc_loss = 0.1116744670393182
Trained batch 433 in epoch 2, gen_loss = 0.794597450077259, disc_loss = 0.11193388164223682
Trained batch 434 in epoch 2, gen_loss = 0.7945621786446407, disc_loss = 0.11191333875959289
Trained batch 435 in epoch 2, gen_loss = 0.7942028767472014, disc_loss = 0.1118977000069625
Trained batch 436 in epoch 2, gen_loss = 0.7944781530639945, disc_loss = 0.11194445236502919
Trained batch 437 in epoch 2, gen_loss = 0.7947879062123495, disc_loss = 0.11183582055148537
Trained batch 438 in epoch 2, gen_loss = 0.793865331281019, disc_loss = 0.11211835916508371
Trained batch 439 in epoch 2, gen_loss = 0.7941451917317781, disc_loss = 0.11212355148428205
Trained batch 440 in epoch 2, gen_loss = 0.7938760002048648, disc_loss = 0.11207950976202075
Trained batch 441 in epoch 2, gen_loss = 0.793690621111188, disc_loss = 0.11199932907206508
Trained batch 442 in epoch 2, gen_loss = 0.7938749344165923, disc_loss = 0.1119060351641567
Trained batch 443 in epoch 2, gen_loss = 0.7943925536027899, disc_loss = 0.11180093653944766
Trained batch 444 in epoch 2, gen_loss = 0.7941497768578905, disc_loss = 0.11178777689386285
Trained batch 445 in epoch 2, gen_loss = 0.7947073357655863, disc_loss = 0.1116051597608412
Trained batch 446 in epoch 2, gen_loss = 0.7944229280521939, disc_loss = 0.1115193560748659
Trained batch 447 in epoch 2, gen_loss = 0.7951170575272825, disc_loss = 0.1116051081563845
Trained batch 448 in epoch 2, gen_loss = 0.7949018694111923, disc_loss = 0.11154476849192169
Trained batch 449 in epoch 2, gen_loss = 0.794904306795862, disc_loss = 0.11147581743490365
Trained batch 450 in epoch 2, gen_loss = 0.7949783410174883, disc_loss = 0.11151100523943316
Trained batch 451 in epoch 2, gen_loss = 0.7947061739004819, disc_loss = 0.1114583927210816
Trained batch 452 in epoch 2, gen_loss = 0.7952064601396094, disc_loss = 0.11130614201055128
Trained batch 453 in epoch 2, gen_loss = 0.7953418642282486, disc_loss = 0.11120526087860114
Trained batch 454 in epoch 2, gen_loss = 0.7948699709478315, disc_loss = 0.11126693964291078
Trained batch 455 in epoch 2, gen_loss = 0.7955208788707591, disc_loss = 0.11113179916017607
Trained batch 456 in epoch 2, gen_loss = 0.7964551351654712, disc_loss = 0.11094133251629916
Trained batch 457 in epoch 2, gen_loss = 0.7965648250418459, disc_loss = 0.1108210712211719
Trained batch 458 in epoch 2, gen_loss = 0.7964304449901082, disc_loss = 0.11070289450427741
Trained batch 459 in epoch 2, gen_loss = 0.7966072731043982, disc_loss = 0.1107107421848923
Trained batch 460 in epoch 2, gen_loss = 0.7961384583579744, disc_loss = 0.11098655501336117
Trained batch 461 in epoch 2, gen_loss = 0.7964066723079393, disc_loss = 0.1110303497961944
Trained batch 462 in epoch 2, gen_loss = 0.7960534460729966, disc_loss = 0.11107902372654198
Trained batch 463 in epoch 2, gen_loss = 0.7963821576458627, disc_loss = 0.11108804497956137
Trained batch 464 in epoch 2, gen_loss = 0.7959925813700564, disc_loss = 0.11105634692495549
Trained batch 465 in epoch 2, gen_loss = 0.7955830732256558, disc_loss = 0.11101417135359327
Trained batch 466 in epoch 2, gen_loss = 0.7971194692163447, disc_loss = 0.1117221893088561
Trained batch 467 in epoch 2, gen_loss = 0.7967746123416811, disc_loss = 0.11191794840404047
Trained batch 468 in epoch 2, gen_loss = 0.796834382230539, disc_loss = 0.11173089107732846
Trained batch 469 in epoch 2, gen_loss = 0.7969396908866598, disc_loss = 0.11183507412553151
Trained batch 470 in epoch 2, gen_loss = 0.7968743287200887, disc_loss = 0.11175685469456602
Trained batch 471 in epoch 2, gen_loss = 0.7970329578018794, disc_loss = 0.11159681174627868
Trained batch 472 in epoch 2, gen_loss = 0.7971770650614644, disc_loss = 0.11143224097465423
Trained batch 473 in epoch 2, gen_loss = 0.7972924624440036, disc_loss = 0.11130587398447882
Trained batch 474 in epoch 2, gen_loss = 0.7972906810986369, disc_loss = 0.1112376423121283
Trained batch 475 in epoch 2, gen_loss = 0.7974574488877249, disc_loss = 0.11116678280435002
Trained batch 476 in epoch 2, gen_loss = 0.7972431983213005, disc_loss = 0.1111789978044869
Trained batch 477 in epoch 2, gen_loss = 0.796674405244105, disc_loss = 0.1113594317181371
Trained batch 478 in epoch 2, gen_loss = 0.7969895405286538, disc_loss = 0.11126399395058013
Trained batch 479 in epoch 2, gen_loss = 0.797577734850347, disc_loss = 0.11114538340868117
Trained batch 480 in epoch 2, gen_loss = 0.7976356029138744, disc_loss = 0.11096943960004252
Trained batch 481 in epoch 2, gen_loss = 0.7972627070063872, disc_loss = 0.11100668180540699
Trained batch 482 in epoch 2, gen_loss = 0.7980721994586613, disc_loss = 0.11094403114385795
Trained batch 483 in epoch 2, gen_loss = 0.7986621448446897, disc_loss = 0.11081944828014051
Trained batch 484 in epoch 2, gen_loss = 0.798327901744351, disc_loss = 0.11093695019515827
Trained batch 485 in epoch 2, gen_loss = 0.7988807277546989, disc_loss = 0.11093413146258688
Trained batch 486 in epoch 2, gen_loss = 0.7991200356880008, disc_loss = 0.11085467120284478
Trained batch 487 in epoch 2, gen_loss = 0.7991593049564323, disc_loss = 0.1107393765047223
Trained batch 488 in epoch 2, gen_loss = 0.7990137160068154, disc_loss = 0.1106834982546591
Trained batch 489 in epoch 2, gen_loss = 0.8002745995107963, disc_loss = 0.1106361878332587
Trained batch 490 in epoch 2, gen_loss = 0.800174789795322, disc_loss = 0.11057268203162188
Trained batch 491 in epoch 2, gen_loss = 0.8000957186265689, disc_loss = 0.11044377708103417
Trained batch 492 in epoch 2, gen_loss = 0.7996917704902362, disc_loss = 0.11052218450017984
Trained batch 493 in epoch 2, gen_loss = 0.7998738772111383, disc_loss = 0.11055917710797326
Trained batch 494 in epoch 2, gen_loss = 0.8000210716868892, disc_loss = 0.11051778343477936
Trained batch 495 in epoch 2, gen_loss = 0.8008524747264962, disc_loss = 0.11049866877804179
Trained batch 496 in epoch 2, gen_loss = 0.8008169642756403, disc_loss = 0.11050300301807807
Trained batch 497 in epoch 2, gen_loss = 0.8010263444788485, disc_loss = 0.1103577049894176
Trained batch 498 in epoch 2, gen_loss = 0.8011929985874879, disc_loss = 0.11023910904493564
Trained batch 499 in epoch 2, gen_loss = 0.8011091749072075, disc_loss = 0.11013435419090092
Trained batch 500 in epoch 2, gen_loss = 0.801940041090438, disc_loss = 0.11014218365368313
Trained batch 501 in epoch 2, gen_loss = 0.801906443627707, disc_loss = 0.11000436010299272
Trained batch 502 in epoch 2, gen_loss = 0.8017043370020318, disc_loss = 0.1099710522856467
Trained batch 503 in epoch 2, gen_loss = 0.8015651560373722, disc_loss = 0.10987734524274452
Trained batch 504 in epoch 2, gen_loss = 0.8018430110841694, disc_loss = 0.10995536321349958
Trained batch 505 in epoch 2, gen_loss = 0.8014818350434775, disc_loss = 0.11007578316302934
Trained batch 506 in epoch 2, gen_loss = 0.8014843345746486, disc_loss = 0.11004691089170983
Trained batch 507 in epoch 2, gen_loss = 0.8014820170566792, disc_loss = 0.11017832364043675
Trained batch 508 in epoch 2, gen_loss = 0.8011714286209324, disc_loss = 0.11031696257640723
Trained batch 509 in epoch 2, gen_loss = 0.8008292320312238, disc_loss = 0.11037108777090907
Trained batch 510 in epoch 2, gen_loss = 0.8013411254682187, disc_loss = 0.1103009919557582
Trained batch 511 in epoch 2, gen_loss = 0.8010569448233582, disc_loss = 0.1103582976229518
Trained batch 512 in epoch 2, gen_loss = 0.8008169523108075, disc_loss = 0.11034755907103158
Trained batch 513 in epoch 2, gen_loss = 0.8006291250890331, disc_loss = 0.11033190769625371
Trained batch 514 in epoch 2, gen_loss = 0.8006560159539713, disc_loss = 0.11028071396161342
Trained batch 515 in epoch 2, gen_loss = 0.8007490040604458, disc_loss = 0.1101854943305745
Trained batch 516 in epoch 2, gen_loss = 0.8005568670465592, disc_loss = 0.11008582020095573
Trained batch 517 in epoch 2, gen_loss = 0.8005123647598686, disc_loss = 0.1099678101000092
Trained batch 518 in epoch 2, gen_loss = 0.8004132597088125, disc_loss = 0.10990480416291079
Trained batch 519 in epoch 2, gen_loss = 0.8003819172772078, disc_loss = 0.10987031652699583
Trained batch 520 in epoch 2, gen_loss = 0.8002652847949923, disc_loss = 0.10978790259099568
Trained batch 521 in epoch 2, gen_loss = 0.8008080908736049, disc_loss = 0.11000887977701551
Trained batch 522 in epoch 2, gen_loss = 0.8001300929039432, disc_loss = 0.11056402909175901
Trained batch 523 in epoch 2, gen_loss = 0.8004253263805658, disc_loss = 0.11047514187676818
Trained batch 524 in epoch 2, gen_loss = 0.8003117941107069, disc_loss = 0.11051567657540241
Trained batch 525 in epoch 2, gen_loss = 0.7999305889973622, disc_loss = 0.11071339219334064
Trained batch 526 in epoch 2, gen_loss = 0.7997357309769408, disc_loss = 0.11068100484522798
Trained batch 527 in epoch 2, gen_loss = 0.7996786899977562, disc_loss = 0.11078742494503262
Trained batch 528 in epoch 2, gen_loss = 0.7995847999373545, disc_loss = 0.11084775745847557
Trained batch 529 in epoch 2, gen_loss = 0.7990057698398266, disc_loss = 0.11096915409566378
Trained batch 530 in epoch 2, gen_loss = 0.7987397110507088, disc_loss = 0.11084563706224528
Trained batch 531 in epoch 2, gen_loss = 0.798481709694952, disc_loss = 0.11080008190776452
Trained batch 532 in epoch 2, gen_loss = 0.7986143630060872, disc_loss = 0.11086591122249109
Trained batch 533 in epoch 2, gen_loss = 0.7982634328835913, disc_loss = 0.1108862244112466
Trained batch 534 in epoch 2, gen_loss = 0.7984086623258679, disc_loss = 0.11077608822836219
Trained batch 535 in epoch 2, gen_loss = 0.7981606693521365, disc_loss = 0.1106515439911815
Trained batch 536 in epoch 2, gen_loss = 0.7982897257338689, disc_loss = 0.11072518912558504
Trained batch 537 in epoch 2, gen_loss = 0.7981386130959571, disc_loss = 0.11070079662660517
Trained batch 538 in epoch 2, gen_loss = 0.7976775803570403, disc_loss = 0.11071708285749124
Trained batch 539 in epoch 2, gen_loss = 0.7978300410840247, disc_loss = 0.11061911379608015
Trained batch 540 in epoch 2, gen_loss = 0.7980080356549424, disc_loss = 0.11076112792012928
Trained batch 541 in epoch 2, gen_loss = 0.7979420872741959, disc_loss = 0.11068396343990501
Trained batch 542 in epoch 2, gen_loss = 0.7980397658124154, disc_loss = 0.1106351909500377
Trained batch 543 in epoch 2, gen_loss = 0.7979026059346164, disc_loss = 0.11059099917389069
Trained batch 544 in epoch 2, gen_loss = 0.7975985997860585, disc_loss = 0.11070774607189478
Trained batch 545 in epoch 2, gen_loss = 0.798213731947836, disc_loss = 0.11080408194051175
Trained batch 546 in epoch 2, gen_loss = 0.7978509766419147, disc_loss = 0.11084217573575662
Trained batch 547 in epoch 2, gen_loss = 0.7975479102809063, disc_loss = 0.1108236786770043
Trained batch 548 in epoch 2, gen_loss = 0.7978492310246917, disc_loss = 0.11075978764996122
Trained batch 549 in epoch 2, gen_loss = 0.7983480333740061, disc_loss = 0.11091040426526558
Trained batch 550 in epoch 2, gen_loss = 0.7978406121748113, disc_loss = 0.11134979615119808
Trained batch 551 in epoch 2, gen_loss = 0.7978831880010556, disc_loss = 0.1113965215947668
Trained batch 552 in epoch 2, gen_loss = 0.7978530609693923, disc_loss = 0.11146433688666517
Trained batch 553 in epoch 2, gen_loss = 0.7976131906685846, disc_loss = 0.11153738700451887
Trained batch 554 in epoch 2, gen_loss = 0.7971362216515584, disc_loss = 0.11176713731408387
Trained batch 555 in epoch 2, gen_loss = 0.7970903871192349, disc_loss = 0.11192541740493005
Trained batch 556 in epoch 2, gen_loss = 0.7975612910367428, disc_loss = 0.11195083946504596
Trained batch 557 in epoch 2, gen_loss = 0.7974997584217338, disc_loss = 0.11193957737409994
Trained batch 558 in epoch 2, gen_loss = 0.7971215699674405, disc_loss = 0.11200305176582287
Trained batch 559 in epoch 2, gen_loss = 0.797022112299289, disc_loss = 0.11201029609655962
Trained batch 560 in epoch 2, gen_loss = 0.7975489510465645, disc_loss = 0.11211538464395386
Trained batch 561 in epoch 2, gen_loss = 0.7973097425444695, disc_loss = 0.11204234091233581
Trained batch 562 in epoch 2, gen_loss = 0.7970432445909795, disc_loss = 0.11195204293332187
Trained batch 563 in epoch 2, gen_loss = 0.7970617365435506, disc_loss = 0.11194897209399822
Trained batch 564 in epoch 2, gen_loss = 0.7968607861911301, disc_loss = 0.1119026399176337
Trained batch 565 in epoch 2, gen_loss = 0.7970900391837312, disc_loss = 0.11189043636568707
Trained batch 566 in epoch 2, gen_loss = 0.7969517017693326, disc_loss = 0.11185617364016633
Trained batch 567 in epoch 2, gen_loss = 0.7968925431265798, disc_loss = 0.11176908756179971
Trained batch 568 in epoch 2, gen_loss = 0.7965685909054191, disc_loss = 0.11172857920038522
Trained batch 569 in epoch 2, gen_loss = 0.7967744921905953, disc_loss = 0.11178472554637936
Trained batch 570 in epoch 2, gen_loss = 0.7963106104559322, disc_loss = 0.1118527115086149
Trained batch 571 in epoch 2, gen_loss = 0.7960647300302566, disc_loss = 0.11186261068853726
Trained batch 572 in epoch 2, gen_loss = 0.7966216465045436, disc_loss = 0.11192416565014898
Trained batch 573 in epoch 2, gen_loss = 0.7965427862954056, disc_loss = 0.11190851375570955
Trained batch 574 in epoch 2, gen_loss = 0.7961513369498046, disc_loss = 0.1119998488235085
Trained batch 575 in epoch 2, gen_loss = 0.7966107100558778, disc_loss = 0.11210972836609774
Trained batch 576 in epoch 2, gen_loss = 0.7966195323748233, disc_loss = 0.11202462353425639
Trained batch 577 in epoch 2, gen_loss = 0.79664665991666, disc_loss = 0.11196911768265919
Trained batch 578 in epoch 2, gen_loss = 0.7966317406281288, disc_loss = 0.1119535749404979
Trained batch 579 in epoch 2, gen_loss = 0.796929815462951, disc_loss = 0.11198812170949732
Trained batch 580 in epoch 2, gen_loss = 0.7970430608357907, disc_loss = 0.11189906812223274
Trained batch 581 in epoch 2, gen_loss = 0.7974992420562764, disc_loss = 0.11184068064003722
Trained batch 582 in epoch 2, gen_loss = 0.7977831426554234, disc_loss = 0.11168437470134035
Trained batch 583 in epoch 2, gen_loss = 0.7975333320257598, disc_loss = 0.11158461250485979
Trained batch 584 in epoch 2, gen_loss = 0.7982870792221819, disc_loss = 0.1114965296183259
Trained batch 585 in epoch 2, gen_loss = 0.7979035709599993, disc_loss = 0.111647772299183
Trained batch 586 in epoch 2, gen_loss = 0.798749387822728, disc_loss = 0.1118449506030959
Trained batch 587 in epoch 2, gen_loss = 0.7988288304736825, disc_loss = 0.11171777650150058
Trained batch 588 in epoch 2, gen_loss = 0.798610305391467, disc_loss = 0.11175990258841594
Trained batch 589 in epoch 2, gen_loss = 0.7987126952005645, disc_loss = 0.11170359081983314
Trained batch 590 in epoch 2, gen_loss = 0.7990695723724849, disc_loss = 0.1117643651405945
Trained batch 591 in epoch 2, gen_loss = 0.7987182881884478, disc_loss = 0.11189156868715293
Trained batch 592 in epoch 2, gen_loss = 0.7986969582447515, disc_loss = 0.11179027615765244
Trained batch 593 in epoch 2, gen_loss = 0.7984509976323606, disc_loss = 0.11168567960931346
Trained batch 594 in epoch 2, gen_loss = 0.7992462906016021, disc_loss = 0.11168841980554226
Trained batch 595 in epoch 2, gen_loss = 0.7991131302594339, disc_loss = 0.11163100560708283
Trained batch 596 in epoch 2, gen_loss = 0.7989615957241761, disc_loss = 0.11164312936222084
Trained batch 597 in epoch 2, gen_loss = 0.7991505746159665, disc_loss = 0.11159867596934023
Trained batch 598 in epoch 2, gen_loss = 0.7990486909929221, disc_loss = 0.11157821552153173
Trained batch 599 in epoch 2, gen_loss = 0.7987956231335799, disc_loss = 0.11163338227042308
Trained batch 600 in epoch 2, gen_loss = 0.7988396626641469, disc_loss = 0.11168114442266709
Trained batch 601 in epoch 2, gen_loss = 0.7987643325348629, disc_loss = 0.1117061557808266
Trained batch 602 in epoch 2, gen_loss = 0.7987091413283625, disc_loss = 0.11163140611435791
Trained batch 603 in epoch 2, gen_loss = 0.7985318052946337, disc_loss = 0.11154585829257521
Trained batch 604 in epoch 2, gen_loss = 0.7990312533437713, disc_loss = 0.11151042997313679
Trained batch 605 in epoch 2, gen_loss = 0.7992236545868833, disc_loss = 0.11136225294536932
Trained batch 606 in epoch 2, gen_loss = 0.799190275407898, disc_loss = 0.11130229474077556
Trained batch 607 in epoch 2, gen_loss = 0.7994446006946658, disc_loss = 0.11125075767631643
Trained batch 608 in epoch 2, gen_loss = 0.7993938550475391, disc_loss = 0.11113619934216949
Trained batch 609 in epoch 2, gen_loss = 0.7993648108400282, disc_loss = 0.1110600718235994
Trained batch 610 in epoch 2, gen_loss = 0.7993520203179111, disc_loss = 0.11099636269529059
Trained batch 611 in epoch 2, gen_loss = 0.7991333207955548, disc_loss = 0.11096120896152666
Trained batch 612 in epoch 2, gen_loss = 0.7994181120473448, disc_loss = 0.11092813591492555
Trained batch 613 in epoch 2, gen_loss = 0.7999895926115955, disc_loss = 0.1107877983396163
Trained batch 614 in epoch 2, gen_loss = 0.8001760092692647, disc_loss = 0.11065531003675083
Trained batch 615 in epoch 2, gen_loss = 0.8000484920264065, disc_loss = 0.11054086796002002
Trained batch 616 in epoch 2, gen_loss = 0.8002965183176909, disc_loss = 0.11038888708463412
Trained batch 617 in epoch 2, gen_loss = 0.8009378103280145, disc_loss = 0.11031560884475178
Trained batch 618 in epoch 2, gen_loss = 0.8016238127367177, disc_loss = 0.11019178646163766
Trained batch 619 in epoch 2, gen_loss = 0.8014524380526235, disc_loss = 0.11020476897547563
Trained batch 620 in epoch 2, gen_loss = 0.8014423138373524, disc_loss = 0.11013412209386651
Trained batch 621 in epoch 2, gen_loss = 0.801279957990171, disc_loss = 0.1103319389419181
Trained batch 622 in epoch 2, gen_loss = 0.8015217480173463, disc_loss = 0.11019149647030028
Trained batch 623 in epoch 2, gen_loss = 0.801591682080657, disc_loss = 0.11006832918755184
Trained batch 624 in epoch 2, gen_loss = 0.8014264726161957, disc_loss = 0.11000725115090608
Trained batch 625 in epoch 2, gen_loss = 0.8019087483612494, disc_loss = 0.10988506664798711
Trained batch 626 in epoch 2, gen_loss = 0.8017768960154988, disc_loss = 0.10978832273659381
Trained batch 627 in epoch 2, gen_loss = 0.8016839822291568, disc_loss = 0.10973017661132298
Trained batch 628 in epoch 2, gen_loss = 0.8016799840430576, disc_loss = 0.10975936517883418
Trained batch 629 in epoch 2, gen_loss = 0.8025220597074145, disc_loss = 0.10964370819459122
Trained batch 630 in epoch 2, gen_loss = 0.8022495853447499, disc_loss = 0.10972348585423737
Trained batch 631 in epoch 2, gen_loss = 0.8023574510235575, disc_loss = 0.10957296584184648
Trained batch 632 in epoch 2, gen_loss = 0.8027908070863329, disc_loss = 0.10956980456490699
Trained batch 633 in epoch 2, gen_loss = 0.8026870504632734, disc_loss = 0.10949692702543708
Trained batch 634 in epoch 2, gen_loss = 0.8025460013723749, disc_loss = 0.10940307004626576
Trained batch 635 in epoch 2, gen_loss = 0.8025468431834905, disc_loss = 0.10933609200354502
Trained batch 636 in epoch 2, gen_loss = 0.8026856811398427, disc_loss = 0.10921543809838206
Trained batch 637 in epoch 2, gen_loss = 0.8029441488293645, disc_loss = 0.10906293157190318
Trained batch 638 in epoch 2, gen_loss = 0.8025912675592635, disc_loss = 0.10903113263517805
Trained batch 639 in epoch 2, gen_loss = 0.8025702621322125, disc_loss = 0.10909763715899316
Trained batch 640 in epoch 2, gen_loss = 0.8025782567197559, disc_loss = 0.1089873453544078
Trained batch 641 in epoch 2, gen_loss = 0.8026739792938916, disc_loss = 0.10886288800268112
Trained batch 642 in epoch 2, gen_loss = 0.8029266929088817, disc_loss = 0.10873996151950135
Trained batch 643 in epoch 2, gen_loss = 0.8028830652188811, disc_loss = 0.10868320150896675
Trained batch 644 in epoch 2, gen_loss = 0.80286258861076, disc_loss = 0.10860848463349795
Trained batch 645 in epoch 2, gen_loss = 0.8030562148466937, disc_loss = 0.10855301115056355
Trained batch 646 in epoch 2, gen_loss = 0.8034119877325143, disc_loss = 0.10842508851612416
Trained batch 647 in epoch 2, gen_loss = 0.803130801031251, disc_loss = 0.10848544926790774
Trained batch 648 in epoch 2, gen_loss = 0.8036088803424306, disc_loss = 0.1084731897850089
Trained batch 649 in epoch 2, gen_loss = 0.8034073736575934, disc_loss = 0.1084751442547601
Trained batch 650 in epoch 2, gen_loss = 0.803292274063084, disc_loss = 0.10863009933096152
Trained batch 651 in epoch 2, gen_loss = 0.8030952349122317, disc_loss = 0.10871974081858032
Trained batch 652 in epoch 2, gen_loss = 0.8031324641536608, disc_loss = 0.10868598525462299
Trained batch 653 in epoch 2, gen_loss = 0.8030599846478996, disc_loss = 0.10874862738939099
Trained batch 654 in epoch 2, gen_loss = 0.8030816633737724, disc_loss = 0.10872448254092276
Trained batch 655 in epoch 2, gen_loss = 0.8026394528314108, disc_loss = 0.10882351837240205
Trained batch 656 in epoch 2, gen_loss = 0.8029152366759389, disc_loss = 0.10881298892852061
Trained batch 657 in epoch 2, gen_loss = 0.8027260303044391, disc_loss = 0.10874901148193378
Trained batch 658 in epoch 2, gen_loss = 0.8028245758666616, disc_loss = 0.10862256516879128
Trained batch 659 in epoch 2, gen_loss = 0.8028520648678144, disc_loss = 0.10859192208330513
Trained batch 660 in epoch 2, gen_loss = 0.8027481181087724, disc_loss = 0.10861050109160604
Trained batch 661 in epoch 2, gen_loss = 0.8026669541784643, disc_loss = 0.10857591225858497
Trained batch 662 in epoch 2, gen_loss = 0.8028453296755593, disc_loss = 0.10845190122987665
Trained batch 663 in epoch 2, gen_loss = 0.8024824167859842, disc_loss = 0.10862466372431716
Trained batch 664 in epoch 2, gen_loss = 0.8025975119350548, disc_loss = 0.10865218397790104
Trained batch 665 in epoch 2, gen_loss = 0.8027085164735267, disc_loss = 0.10864407504704576
Trained batch 666 in epoch 2, gen_loss = 0.8024329128919513, disc_loss = 0.1086723635621045
Trained batch 667 in epoch 2, gen_loss = 0.8025204560267711, disc_loss = 0.10871371560350819
Trained batch 668 in epoch 2, gen_loss = 0.8022552963418633, disc_loss = 0.10868084794174886
Trained batch 669 in epoch 2, gen_loss = 0.8021763060964755, disc_loss = 0.10862373316438118
Trained batch 670 in epoch 2, gen_loss = 0.8022061995440197, disc_loss = 0.10855119316609668
Trained batch 671 in epoch 2, gen_loss = 0.8020207632244343, disc_loss = 0.10847153298839528
Trained batch 672 in epoch 2, gen_loss = 0.8021943744100398, disc_loss = 0.10844275899325535
Trained batch 673 in epoch 2, gen_loss = 0.8020844987043642, disc_loss = 0.10834613977309637
Trained batch 674 in epoch 2, gen_loss = 0.8022249607245128, disc_loss = 0.1082587240015467
Trained batch 675 in epoch 2, gen_loss = 0.8022829025719292, disc_loss = 0.10813254513502253
Trained batch 676 in epoch 2, gen_loss = 0.8021221079449534, disc_loss = 0.10806796584069245
Trained batch 677 in epoch 2, gen_loss = 0.8020367057537963, disc_loss = 0.1079702326041649
Trained batch 678 in epoch 2, gen_loss = 0.8022466117134852, disc_loss = 0.10790456498291381
Trained batch 679 in epoch 2, gen_loss = 0.8020087752710371, disc_loss = 0.10786605177529375
Trained batch 680 in epoch 2, gen_loss = 0.8026014258770515, disc_loss = 0.10806145076332245
Trained batch 681 in epoch 2, gen_loss = 0.8023449369102629, disc_loss = 0.10821707946961183
Trained batch 682 in epoch 2, gen_loss = 0.8024250506743854, disc_loss = 0.10813381226588788
Trained batch 683 in epoch 2, gen_loss = 0.8020511381545959, disc_loss = 0.10812828976699092
Trained batch 684 in epoch 2, gen_loss = 0.8022808895058876, disc_loss = 0.10813551146373915
Trained batch 685 in epoch 2, gen_loss = 0.8022757814246781, disc_loss = 0.10809987354833557
Trained batch 686 in epoch 2, gen_loss = 0.8020742151674746, disc_loss = 0.10809620044003017
Trained batch 687 in epoch 2, gen_loss = 0.8019514508805302, disc_loss = 0.10807378508210139
Trained batch 688 in epoch 2, gen_loss = 0.80221173383501, disc_loss = 0.1081328900092983
Trained batch 689 in epoch 2, gen_loss = 0.802092163156772, disc_loss = 0.10815624569178275
Trained batch 690 in epoch 2, gen_loss = 0.8018568499302209, disc_loss = 0.10816866733462653
Trained batch 691 in epoch 2, gen_loss = 0.802187303113455, disc_loss = 0.10824916749045985
Trained batch 692 in epoch 2, gen_loss = 0.8018897878917265, disc_loss = 0.10830771325701716
Trained batch 693 in epoch 2, gen_loss = 0.8016995755413424, disc_loss = 0.10830262075084388
Trained batch 694 in epoch 2, gen_loss = 0.8016653985857106, disc_loss = 0.10833599459540716
Trained batch 695 in epoch 2, gen_loss = 0.8015422363305229, disc_loss = 0.10838819063273954
Trained batch 696 in epoch 2, gen_loss = 0.8012729256789346, disc_loss = 0.10843635539001809
Trained batch 697 in epoch 2, gen_loss = 0.8014773632103529, disc_loss = 0.10852212248967806
Trained batch 698 in epoch 2, gen_loss = 0.8012521845503086, disc_loss = 0.10858103035361598
Trained batch 699 in epoch 2, gen_loss = 0.8011196977325848, disc_loss = 0.10852565830706486
Trained batch 700 in epoch 2, gen_loss = 0.8012148897334954, disc_loss = 0.10859905771470062
Trained batch 701 in epoch 2, gen_loss = 0.801291823769227, disc_loss = 0.10867807659004786
Trained batch 702 in epoch 2, gen_loss = 0.8007279859582865, disc_loss = 0.10897349288944118
Trained batch 703 in epoch 2, gen_loss = 0.8004214554940435, disc_loss = 0.10898958929068282
Trained batch 704 in epoch 2, gen_loss = 0.8006452815329775, disc_loss = 0.10901056379476126
Trained batch 705 in epoch 2, gen_loss = 0.800551751644348, disc_loss = 0.10896888955050378
Trained batch 706 in epoch 2, gen_loss = 0.8004081947715819, disc_loss = 0.10891216314006517
Trained batch 707 in epoch 2, gen_loss = 0.8005686015479982, disc_loss = 0.10883506636745638
Trained batch 708 in epoch 2, gen_loss = 0.8001591992395048, disc_loss = 0.10893640002926709
Trained batch 709 in epoch 2, gen_loss = 0.8002676123884362, disc_loss = 0.10882699821065639
Trained batch 710 in epoch 2, gen_loss = 0.8003328505866806, disc_loss = 0.10880663756113473
Trained batch 711 in epoch 2, gen_loss = 0.8003374410562971, disc_loss = 0.10880190374596525
Trained batch 712 in epoch 2, gen_loss = 0.8002902906790355, disc_loss = 0.10881544437343033
Trained batch 713 in epoch 2, gen_loss = 0.80006405723696, disc_loss = 0.10877688013992849
Trained batch 714 in epoch 2, gen_loss = 0.8002429904220821, disc_loss = 0.10877048481464177
Trained batch 715 in epoch 2, gen_loss = 0.8002278628712259, disc_loss = 0.1087635158022668
Trained batch 716 in epoch 2, gen_loss = 0.7999839936922118, disc_loss = 0.1088626120782443
Trained batch 717 in epoch 2, gen_loss = 0.8002168426191575, disc_loss = 0.10886228392627038
Trained batch 718 in epoch 2, gen_loss = 0.8006270785242194, disc_loss = 0.10881323218008863
Trained batch 719 in epoch 2, gen_loss = 0.8002995038612022, disc_loss = 0.10904538468845809
Trained batch 720 in epoch 2, gen_loss = 0.8006461983993546, disc_loss = 0.10906024412452224
Trained batch 721 in epoch 2, gen_loss = 0.8005340788255438, disc_loss = 0.10903080960302265
Trained batch 722 in epoch 2, gen_loss = 0.8002228593018375, disc_loss = 0.10907344255122366
Trained batch 723 in epoch 2, gen_loss = 0.8001198223200292, disc_loss = 0.10899605549413978
Trained batch 724 in epoch 2, gen_loss = 0.800341166175645, disc_loss = 0.10899837583174993
Trained batch 725 in epoch 2, gen_loss = 0.8002098919028421, disc_loss = 0.10896839421965983
Trained batch 726 in epoch 2, gen_loss = 0.8000178066949569, disc_loss = 0.1089670016344488
Trained batch 727 in epoch 2, gen_loss = 0.8003478497676142, disc_loss = 0.10901344858063897
Trained batch 728 in epoch 2, gen_loss = 0.8001514516658417, disc_loss = 0.10905093774173935
Trained batch 729 in epoch 2, gen_loss = 0.7998029013610866, disc_loss = 0.10905837920711262
Trained batch 730 in epoch 2, gen_loss = 0.8000460486813218, disc_loss = 0.10903491135737597
Trained batch 731 in epoch 2, gen_loss = 0.7998689589360373, disc_loss = 0.10900590630741841
Trained batch 732 in epoch 2, gen_loss = 0.7996627895357176, disc_loss = 0.10908623642350405
Trained batch 733 in epoch 2, gen_loss = 0.7998106152793693, disc_loss = 0.10924553640608038
Trained batch 734 in epoch 2, gen_loss = 0.799608472293737, disc_loss = 0.10921306314998541
Trained batch 735 in epoch 2, gen_loss = 0.7993162316067711, disc_loss = 0.10917542830145027
Trained batch 736 in epoch 2, gen_loss = 0.7996585274891096, disc_loss = 0.109259618912524
Trained batch 737 in epoch 2, gen_loss = 0.7995729794912545, disc_loss = 0.10925277992754892
Trained batch 738 in epoch 2, gen_loss = 0.7993258841547495, disc_loss = 0.1092407440852389
Trained batch 739 in epoch 2, gen_loss = 0.7992895205681388, disc_loss = 0.10931640084002267
Trained batch 740 in epoch 2, gen_loss = 0.7991878402780103, disc_loss = 0.10923661981230444
Trained batch 741 in epoch 2, gen_loss = 0.799225213272231, disc_loss = 0.10918259895670246
Trained batch 742 in epoch 2, gen_loss = 0.7991162999401503, disc_loss = 0.10914777631308598
Trained batch 743 in epoch 2, gen_loss = 0.7992059471866777, disc_loss = 0.10907151791272104
Trained batch 744 in epoch 2, gen_loss = 0.799339513130636, disc_loss = 0.10903476749565577
Trained batch 745 in epoch 2, gen_loss = 0.7991706156458995, disc_loss = 0.10903169227584238
Trained batch 746 in epoch 2, gen_loss = 0.7989470587277827, disc_loss = 0.10907131831325002
Trained batch 747 in epoch 2, gen_loss = 0.799160970763408, disc_loss = 0.10903509512897282
Trained batch 748 in epoch 2, gen_loss = 0.7993485444139575, disc_loss = 0.10901857034063267
Trained batch 749 in epoch 2, gen_loss = 0.7988752543528874, disc_loss = 0.1093353184349835
Trained batch 750 in epoch 2, gen_loss = 0.7992404336221367, disc_loss = 0.10960580044352858
Trained batch 751 in epoch 2, gen_loss = 0.7990100266847838, disc_loss = 0.109679461386243
Trained batch 752 in epoch 2, gen_loss = 0.7989993440914914, disc_loss = 0.10971393004668305
Trained batch 753 in epoch 2, gen_loss = 0.7990131434695474, disc_loss = 0.1097203368699025
Trained batch 754 in epoch 2, gen_loss = 0.7986156782172373, disc_loss = 0.10985700019222024
Trained batch 755 in epoch 2, gen_loss = 0.7986883030287804, disc_loss = 0.10985807062215394
Trained batch 756 in epoch 2, gen_loss = 0.7987888772311267, disc_loss = 0.10981202260265065
Trained batch 757 in epoch 2, gen_loss = 0.7985710139560825, disc_loss = 0.10980905438982205
Trained batch 758 in epoch 2, gen_loss = 0.79837805256542, disc_loss = 0.10985512159671512
Trained batch 759 in epoch 2, gen_loss = 0.7982090307301597, disc_loss = 0.10980977185536175
Trained batch 760 in epoch 2, gen_loss = 0.7982715489281618, disc_loss = 0.10978207995554581
Trained batch 761 in epoch 2, gen_loss = 0.798050665519056, disc_loss = 0.10971523146572819
Trained batch 762 in epoch 2, gen_loss = 0.7978855123448029, disc_loss = 0.10971285840118034
Trained batch 763 in epoch 2, gen_loss = 0.797863875657164, disc_loss = 0.109681300232577
Trained batch 764 in epoch 2, gen_loss = 0.7976605360414467, disc_loss = 0.1096713701092632
Trained batch 765 in epoch 2, gen_loss = 0.7976947343925271, disc_loss = 0.10960403112840521
Trained batch 766 in epoch 2, gen_loss = 0.7976981472549414, disc_loss = 0.10956731579367271
Trained batch 767 in epoch 2, gen_loss = 0.797570299784032, disc_loss = 0.10953843641012402
Trained batch 768 in epoch 2, gen_loss = 0.7977440970694291, disc_loss = 0.10954427761625213
Trained batch 769 in epoch 2, gen_loss = 0.7976943740984062, disc_loss = 0.10952859377585254
Trained batch 770 in epoch 2, gen_loss = 0.7977406545294553, disc_loss = 0.10953052757348956
Trained batch 771 in epoch 2, gen_loss = 0.7978122280283295, disc_loss = 0.1095565393979666
Trained batch 772 in epoch 2, gen_loss = 0.7979333152052348, disc_loss = 0.1095117458345954
Trained batch 773 in epoch 2, gen_loss = 0.7978090750539641, disc_loss = 0.1095052459854777
Trained batch 774 in epoch 2, gen_loss = 0.7978400090817482, disc_loss = 0.10946545250833996
Trained batch 775 in epoch 2, gen_loss = 0.7977318863202002, disc_loss = 0.10954530974826056
Trained batch 776 in epoch 2, gen_loss = 0.7979756989917853, disc_loss = 0.10959969884674023
Trained batch 777 in epoch 2, gen_loss = 0.7975565352522622, disc_loss = 0.10967651105205742
Trained batch 778 in epoch 2, gen_loss = 0.7979986677962488, disc_loss = 0.10985187969896201
Trained batch 779 in epoch 2, gen_loss = 0.7976717724631994, disc_loss = 0.1100094946137128
Trained batch 780 in epoch 2, gen_loss = 0.797810846612945, disc_loss = 0.10993834704079603
Trained batch 781 in epoch 2, gen_loss = 0.7979012683148274, disc_loss = 0.10998741516252727
Trained batch 782 in epoch 2, gen_loss = 0.7975996207079515, disc_loss = 0.11000712192944449
Trained batch 783 in epoch 2, gen_loss = 0.7979495258887812, disc_loss = 0.11006959666360208
Trained batch 784 in epoch 2, gen_loss = 0.7978053159394841, disc_loss = 0.1100839311707836
Trained batch 785 in epoch 2, gen_loss = 0.7978312316665819, disc_loss = 0.11008836850215878
Trained batch 786 in epoch 2, gen_loss = 0.7979047443466841, disc_loss = 0.11009190245643921
Trained batch 787 in epoch 2, gen_loss = 0.7977116850351319, disc_loss = 0.11014012039194668
Trained batch 788 in epoch 2, gen_loss = 0.7978336102835579, disc_loss = 0.11008326200171077
Trained batch 789 in epoch 2, gen_loss = 0.7977861799394028, disc_loss = 0.11017287115955465
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.8876974582672119, disc_loss = 0.08088512718677521
Trained batch 1 in epoch 3, gen_loss = 0.673894852399826, disc_loss = 0.15882641822099686
Trained batch 2 in epoch 3, gen_loss = 0.7716897328694662, disc_loss = 0.1340248833100001
Trained batch 3 in epoch 3, gen_loss = 0.7504967451095581, disc_loss = 0.11328646168112755
Trained batch 4 in epoch 3, gen_loss = 0.7445077180862427, disc_loss = 0.1089166447520256
Trained batch 5 in epoch 3, gen_loss = 0.7473921179771423, disc_loss = 0.09766651690006256
Trained batch 6 in epoch 3, gen_loss = 0.7511087145124163, disc_loss = 0.09006277099251747
Trained batch 7 in epoch 3, gen_loss = 0.7678159326314926, disc_loss = 0.08130403864197433
Trained batch 8 in epoch 3, gen_loss = 0.7846454315715365, disc_loss = 0.07915172705219851
Trained batch 9 in epoch 3, gen_loss = 0.7733287990093232, disc_loss = 0.08148309644311666
Trained batch 10 in epoch 3, gen_loss = 0.8016108437017961, disc_loss = 0.08399156260896813
Trained batch 11 in epoch 3, gen_loss = 0.7883787999550501, disc_loss = 0.08405001259719332
Trained batch 12 in epoch 3, gen_loss = 0.7932985470845149, disc_loss = 0.08084448842475048
Trained batch 13 in epoch 3, gen_loss = 0.8007943247045789, disc_loss = 0.07750133837440185
Trained batch 14 in epoch 3, gen_loss = 0.7990936199824016, disc_loss = 0.07392934150993824
Trained batch 15 in epoch 3, gen_loss = 0.785276148468256, disc_loss = 0.07538938138168305
Trained batch 16 in epoch 3, gen_loss = 0.8077180070035598, disc_loss = 0.07980640221606283
Trained batch 17 in epoch 3, gen_loss = 0.801472481754091, disc_loss = 0.07907864772197273
Trained batch 18 in epoch 3, gen_loss = 0.795642121842033, disc_loss = 0.07844043552483383
Trained batch 19 in epoch 3, gen_loss = 0.8040268212556839, disc_loss = 0.07618992114439607
Trained batch 20 in epoch 3, gen_loss = 0.7967885931332906, disc_loss = 0.07690278449583621
Trained batch 21 in epoch 3, gen_loss = 0.7864565632560037, disc_loss = 0.07881034411151301
Trained batch 22 in epoch 3, gen_loss = 0.7995400636092477, disc_loss = 0.07951591204365958
Trained batch 23 in epoch 3, gen_loss = 0.7960093667109808, disc_loss = 0.07840817895097037
Trained batch 24 in epoch 3, gen_loss = 0.7915774297714233, disc_loss = 0.0794143757969141
Trained batch 25 in epoch 3, gen_loss = 0.7893096323196704, disc_loss = 0.07809469340225825
Trained batch 26 in epoch 3, gen_loss = 0.7892302583765101, disc_loss = 0.07788446110983689
Trained batch 27 in epoch 3, gen_loss = 0.7939578656639371, disc_loss = 0.07568766715537224
Trained batch 28 in epoch 3, gen_loss = 0.7938113664758617, disc_loss = 0.0766488779336214
Trained batch 29 in epoch 3, gen_loss = 0.7888379017512004, disc_loss = 0.07873331339408954
Trained batch 30 in epoch 3, gen_loss = 0.7843792323143252, disc_loss = 0.07934939386623521
Trained batch 31 in epoch 3, gen_loss = 0.7985969297587872, disc_loss = 0.08138389844680205
Trained batch 32 in epoch 3, gen_loss = 0.7997692444107749, disc_loss = 0.07991229770987322
Trained batch 33 in epoch 3, gen_loss = 0.7938740849494934, disc_loss = 0.08152097162297543
Trained batch 34 in epoch 3, gen_loss = 0.7958113380840847, disc_loss = 0.08027552839900766
Trained batch 35 in epoch 3, gen_loss = 0.7987814363506105, disc_loss = 0.08123881499179536
Trained batch 36 in epoch 3, gen_loss = 0.7965293623305656, disc_loss = 0.08076952201490467
Trained batch 37 in epoch 3, gen_loss = 0.7951574733382777, disc_loss = 0.08129309730506257
Trained batch 38 in epoch 3, gen_loss = 0.7998895477025937, disc_loss = 0.08070976597567399
Trained batch 39 in epoch 3, gen_loss = 0.7988346800208092, disc_loss = 0.07935770801268519
Trained batch 40 in epoch 3, gen_loss = 0.8017822198751496, disc_loss = 0.07895508385831262
Trained batch 41 in epoch 3, gen_loss = 0.7977634228411175, disc_loss = 0.07865340417871873
Trained batch 42 in epoch 3, gen_loss = 0.8065364818240321, disc_loss = 0.0772766700924136
Trained batch 43 in epoch 3, gen_loss = 0.8096514818343249, disc_loss = 0.07693169668147509
Trained batch 44 in epoch 3, gen_loss = 0.8123428477181329, disc_loss = 0.07935700246857272
Trained batch 45 in epoch 3, gen_loss = 0.8079071874203889, disc_loss = 0.081675516805895
Trained batch 46 in epoch 3, gen_loss = 0.8128361904874761, disc_loss = 0.08156832953558323
Trained batch 47 in epoch 3, gen_loss = 0.8176794846852621, disc_loss = 0.08026933379005641
Trained batch 48 in epoch 3, gen_loss = 0.8143740186885912, disc_loss = 0.08100965759735934
Trained batch 49 in epoch 3, gen_loss = 0.815370203256607, disc_loss = 0.08026849847286939
Trained batch 50 in epoch 3, gen_loss = 0.8186888542829776, disc_loss = 0.08098576988513563
Trained batch 51 in epoch 3, gen_loss = 0.8174556092574046, disc_loss = 0.08096231731514518
Trained batch 52 in epoch 3, gen_loss = 0.8205242460628726, disc_loss = 0.080040172129026
Trained batch 53 in epoch 3, gen_loss = 0.8180880844593048, disc_loss = 0.0801704053732532
Trained batch 54 in epoch 3, gen_loss = 0.8206651676784862, disc_loss = 0.07992895987223494
Trained batch 55 in epoch 3, gen_loss = 0.8237462373716491, disc_loss = 0.0800654873185392
Trained batch 56 in epoch 3, gen_loss = 0.821775682139815, disc_loss = 0.07976881189173773
Trained batch 57 in epoch 3, gen_loss = 0.8204411555980814, disc_loss = 0.0794032658932024
Trained batch 58 in epoch 3, gen_loss = 0.8199736728506574, disc_loss = 0.07956157836242247
Trained batch 59 in epoch 3, gen_loss = 0.8173472742239635, disc_loss = 0.08002113870655497
Trained batch 60 in epoch 3, gen_loss = 0.8238012184862231, disc_loss = 0.08087455417166968
Trained batch 61 in epoch 3, gen_loss = 0.8235287320229315, disc_loss = 0.08028215954020139
Trained batch 62 in epoch 3, gen_loss = 0.8211814108349028, disc_loss = 0.0803241960645195
Trained batch 63 in epoch 3, gen_loss = 0.8218046436086297, disc_loss = 0.081501195585588
Trained batch 64 in epoch 3, gen_loss = 0.8202906223443839, disc_loss = 0.08115620088691895
Trained batch 65 in epoch 3, gen_loss = 0.8191287779446804, disc_loss = 0.08092148999937555
Trained batch 66 in epoch 3, gen_loss = 0.8178721639647413, disc_loss = 0.08055110434209233
Trained batch 67 in epoch 3, gen_loss = 0.8168599184821633, disc_loss = 0.0813234001672005
Trained batch 68 in epoch 3, gen_loss = 0.8161180226699166, disc_loss = 0.08103618239039097
Trained batch 69 in epoch 3, gen_loss = 0.817055926152638, disc_loss = 0.08018598122788327
Trained batch 70 in epoch 3, gen_loss = 0.8181136183335748, disc_loss = 0.07993230593561286
Trained batch 71 in epoch 3, gen_loss = 0.8156640041205618, disc_loss = 0.08004799208396839
Trained batch 72 in epoch 3, gen_loss = 0.8209340711162515, disc_loss = 0.08165644571083049
Trained batch 73 in epoch 3, gen_loss = 0.8197719696405772, disc_loss = 0.0818266330186177
Trained batch 74 in epoch 3, gen_loss = 0.8190634576479594, disc_loss = 0.08189562124510606
Trained batch 75 in epoch 3, gen_loss = 0.8158940633660868, disc_loss = 0.08238198198868256
Trained batch 76 in epoch 3, gen_loss = 0.8133231238885359, disc_loss = 0.08275572822562285
Trained batch 77 in epoch 3, gen_loss = 0.815419940612255, disc_loss = 0.08258557140540618
Trained batch 78 in epoch 3, gen_loss = 0.8160749998273729, disc_loss = 0.08218910608770727
Trained batch 79 in epoch 3, gen_loss = 0.8143921367824077, disc_loss = 0.0825514144031331
Trained batch 80 in epoch 3, gen_loss = 0.8172710140546163, disc_loss = 0.08282718446427657
Trained batch 81 in epoch 3, gen_loss = 0.8162208468448825, disc_loss = 0.0834597672403949
Trained batch 82 in epoch 3, gen_loss = 0.8122497384088585, disc_loss = 0.08649121563746986
Trained batch 83 in epoch 3, gen_loss = 0.8098025729968434, disc_loss = 0.08732112317479082
Trained batch 84 in epoch 3, gen_loss = 0.8138515651226044, disc_loss = 0.08800124436178629
Trained batch 85 in epoch 3, gen_loss = 0.8109541462604389, disc_loss = 0.08898536546892205
Trained batch 86 in epoch 3, gen_loss = 0.8120509869065778, disc_loss = 0.08901328385818279
Trained batch 87 in epoch 3, gen_loss = 0.8108085302466695, disc_loss = 0.08972370851022954
Trained batch 88 in epoch 3, gen_loss = 0.8103089041254493, disc_loss = 0.08984335442858465
Trained batch 89 in epoch 3, gen_loss = 0.8090950982438193, disc_loss = 0.08961126959572235
Trained batch 90 in epoch 3, gen_loss = 0.8089097446792728, disc_loss = 0.08970736153423786
Trained batch 91 in epoch 3, gen_loss = 0.8093725556264753, disc_loss = 0.08943525772622746
Trained batch 92 in epoch 3, gen_loss = 0.808624279434963, disc_loss = 0.08968973301991981
Trained batch 93 in epoch 3, gen_loss = 0.8071972737286953, disc_loss = 0.08978052387767016
Trained batch 94 in epoch 3, gen_loss = 0.8064098298549652, disc_loss = 0.09002658393430082
Trained batch 95 in epoch 3, gen_loss = 0.8082372251277169, disc_loss = 0.09122215907943125
Trained batch 96 in epoch 3, gen_loss = 0.8055268590597763, disc_loss = 0.09219749423569625
Trained batch 97 in epoch 3, gen_loss = 0.8089161822382285, disc_loss = 0.09186972531356982
Trained batch 98 in epoch 3, gen_loss = 0.8063230409164621, disc_loss = 0.09243177048711464
Trained batch 99 in epoch 3, gen_loss = 0.8071039924025536, disc_loss = 0.0936934675835073
Trained batch 100 in epoch 3, gen_loss = 0.8038467369457283, disc_loss = 0.09679419324170835
Trained batch 101 in epoch 3, gen_loss = 0.8030666159648522, disc_loss = 0.0969769306590452
Trained batch 102 in epoch 3, gen_loss = 0.8039961706087427, disc_loss = 0.09752252327224005
Trained batch 103 in epoch 3, gen_loss = 0.8030376887092223, disc_loss = 0.09742789699409443
Trained batch 104 in epoch 3, gen_loss = 0.8001184948853084, disc_loss = 0.0983663252244393
Trained batch 105 in epoch 3, gen_loss = 0.8049737493384559, disc_loss = 0.1003186429833185
Trained batch 106 in epoch 3, gen_loss = 0.8044913820574217, disc_loss = 0.10006684362540179
Trained batch 107 in epoch 3, gen_loss = 0.8027775036516013, disc_loss = 0.10022084151084225
Trained batch 108 in epoch 3, gen_loss = 0.8029979770883507, disc_loss = 0.09991934114571559
Trained batch 109 in epoch 3, gen_loss = 0.8051132123578678, disc_loss = 0.0997898153114048
Trained batch 110 in epoch 3, gen_loss = 0.8034710059831808, disc_loss = 0.09967254234796709
Trained batch 111 in epoch 3, gen_loss = 0.8043519484677485, disc_loss = 0.099268259730057
Trained batch 112 in epoch 3, gen_loss = 0.803929832920564, disc_loss = 0.09873578115572444
Trained batch 113 in epoch 3, gen_loss = 0.8052619138830587, disc_loss = 0.09863960636746988
Trained batch 114 in epoch 3, gen_loss = 0.8032736340294714, disc_loss = 0.09870214376436627
Trained batch 115 in epoch 3, gen_loss = 0.8015413065922672, disc_loss = 0.09900291435870118
Trained batch 116 in epoch 3, gen_loss = 0.8024343203785073, disc_loss = 0.09869630957961592
Trained batch 117 in epoch 3, gen_loss = 0.8042699646646694, disc_loss = 0.09818601423590365
Trained batch 118 in epoch 3, gen_loss = 0.8026531947260144, disc_loss = 0.09841274255651887
Trained batch 119 in epoch 3, gen_loss = 0.8030505441129208, disc_loss = 0.09836641480214894
Trained batch 120 in epoch 3, gen_loss = 0.803263079282666, disc_loss = 0.09776460054553737
Trained batch 121 in epoch 3, gen_loss = 0.8028553995441218, disc_loss = 0.09725768114516481
Trained batch 122 in epoch 3, gen_loss = 0.803553366806449, disc_loss = 0.09679010966262681
Trained batch 123 in epoch 3, gen_loss = 0.8048340733493528, disc_loss = 0.09680906973118263
Trained batch 124 in epoch 3, gen_loss = 0.8048169190883636, disc_loss = 0.09753639258444309
Trained batch 125 in epoch 3, gen_loss = 0.8023173071089245, disc_loss = 0.0995406001244509
Trained batch 126 in epoch 3, gen_loss = 0.802990266657251, disc_loss = 0.0994247927469766
Trained batch 127 in epoch 3, gen_loss = 0.8023867569863796, disc_loss = 0.09922743945207912
Trained batch 128 in epoch 3, gen_loss = 0.8026850366777227, disc_loss = 0.09882048056857992
Trained batch 129 in epoch 3, gen_loss = 0.8025458464255699, disc_loss = 0.09847047932159442
Trained batch 130 in epoch 3, gen_loss = 0.8056357143489459, disc_loss = 0.09830622632369285
Trained batch 131 in epoch 3, gen_loss = 0.8048555440071857, disc_loss = 0.09832550575392264
Trained batch 132 in epoch 3, gen_loss = 0.8029098067068516, disc_loss = 0.09879292896423574
Trained batch 133 in epoch 3, gen_loss = 0.8058525826503982, disc_loss = 0.09937855380295373
Trained batch 134 in epoch 3, gen_loss = 0.8052800960010953, disc_loss = 0.09917368117581915
Trained batch 135 in epoch 3, gen_loss = 0.8044148438117084, disc_loss = 0.09954702548737474
Trained batch 136 in epoch 3, gen_loss = 0.8029011814263616, disc_loss = 0.09955496516377821
Trained batch 137 in epoch 3, gen_loss = 0.801927795012792, disc_loss = 0.09928957223082366
Trained batch 138 in epoch 3, gen_loss = 0.8049413922021715, disc_loss = 0.09968180451944149
Trained batch 139 in epoch 3, gen_loss = 0.8041931633438383, disc_loss = 0.09946953974930303
Trained batch 140 in epoch 3, gen_loss = 0.8022011865115335, disc_loss = 0.0998789879579282
Trained batch 141 in epoch 3, gen_loss = 0.8023726037690337, disc_loss = 0.10042978866471791
Trained batch 142 in epoch 3, gen_loss = 0.8025889634252428, disc_loss = 0.09991943673393526
Trained batch 143 in epoch 3, gen_loss = 0.8022163692447875, disc_loss = 0.0998695529350597
Trained batch 144 in epoch 3, gen_loss = 0.8031623375826868, disc_loss = 0.09933989655611844
Trained batch 145 in epoch 3, gen_loss = 0.8042113180846384, disc_loss = 0.0989414945576493
Trained batch 146 in epoch 3, gen_loss = 0.8037566688595986, disc_loss = 0.09883914286029988
Trained batch 147 in epoch 3, gen_loss = 0.8056728296183251, disc_loss = 0.09972072831933966
Trained batch 148 in epoch 3, gen_loss = 0.8052263055871797, disc_loss = 0.0998045488216933
Trained batch 149 in epoch 3, gen_loss = 0.8055076130231221, disc_loss = 0.09942238212873539
Trained batch 150 in epoch 3, gen_loss = 0.8052421768769523, disc_loss = 0.10008273743685113
Trained batch 151 in epoch 3, gen_loss = 0.8051286806401453, disc_loss = 0.10044845008585405
Trained batch 152 in epoch 3, gen_loss = 0.8041683828908633, disc_loss = 0.10049549452473525
Trained batch 153 in epoch 3, gen_loss = 0.806226438129103, disc_loss = 0.10019172932468838
Trained batch 154 in epoch 3, gen_loss = 0.8055859654180465, disc_loss = 0.10005283779915303
Trained batch 155 in epoch 3, gen_loss = 0.8058586181738437, disc_loss = 0.10012191688068785
Trained batch 156 in epoch 3, gen_loss = 0.8051173967920291, disc_loss = 0.09982501128154575
Trained batch 157 in epoch 3, gen_loss = 0.8064605970925922, disc_loss = 0.09925851809403187
Trained batch 158 in epoch 3, gen_loss = 0.8066569349300936, disc_loss = 0.09877267474039171
Trained batch 159 in epoch 3, gen_loss = 0.8059919320046902, disc_loss = 0.09833928804146126
Trained batch 160 in epoch 3, gen_loss = 0.8075760440056369, disc_loss = 0.09830505721363592
Trained batch 161 in epoch 3, gen_loss = 0.8063103898807809, disc_loss = 0.0988107521523848
Trained batch 162 in epoch 3, gen_loss = 0.804794184635022, disc_loss = 0.09944940482957597
Trained batch 163 in epoch 3, gen_loss = 0.8047255172235209, disc_loss = 0.09905738107542075
Trained batch 164 in epoch 3, gen_loss = 0.8069746324510285, disc_loss = 0.10051837361445932
Trained batch 165 in epoch 3, gen_loss = 0.8061504256294434, disc_loss = 0.10037359784929509
Trained batch 166 in epoch 3, gen_loss = 0.8054619442203088, disc_loss = 0.10037494898065479
Trained batch 167 in epoch 3, gen_loss = 0.8038608151532355, disc_loss = 0.10133629093789273
Trained batch 168 in epoch 3, gen_loss = 0.8031095650774487, disc_loss = 0.10128126223984907
Trained batch 169 in epoch 3, gen_loss = 0.8027801159550162, disc_loss = 0.10112550706766985
Trained batch 170 in epoch 3, gen_loss = 0.8036764891524064, disc_loss = 0.10121632656028047
Trained batch 171 in epoch 3, gen_loss = 0.8021624375914418, disc_loss = 0.10191967161805478
Trained batch 172 in epoch 3, gen_loss = 0.8022931473103562, disc_loss = 0.10163668964079695
Trained batch 173 in epoch 3, gen_loss = 0.8016127906311518, disc_loss = 0.10162115879570958
Trained batch 174 in epoch 3, gen_loss = 0.8009991254125323, disc_loss = 0.10175050759954112
Trained batch 175 in epoch 3, gen_loss = 0.8001880500126969, disc_loss = 0.10175715508574451
Trained batch 176 in epoch 3, gen_loss = 0.8010333385844689, disc_loss = 0.10156261919876614
Trained batch 177 in epoch 3, gen_loss = 0.8009789083780867, disc_loss = 0.10141346242613672
Trained batch 178 in epoch 3, gen_loss = 0.800170605076092, disc_loss = 0.10132328865206774
Trained batch 179 in epoch 3, gen_loss = 0.7998248759243224, disc_loss = 0.1010474464442167
Trained batch 180 in epoch 3, gen_loss = 0.8013892170474015, disc_loss = 0.10136740875960384
Trained batch 181 in epoch 3, gen_loss = 0.8021069162494534, disc_loss = 0.10090846798618089
Trained batch 182 in epoch 3, gen_loss = 0.8004404246155682, disc_loss = 0.10175210523515776
Trained batch 183 in epoch 3, gen_loss = 0.80051633634645, disc_loss = 0.10169808636419475
Trained batch 184 in epoch 3, gen_loss = 0.8006599244233724, disc_loss = 0.10178122501316908
Trained batch 185 in epoch 3, gen_loss = 0.7995694354977659, disc_loss = 0.10166485452403624
Trained batch 186 in epoch 3, gen_loss = 0.7987068829370693, disc_loss = 0.10150988452774
Trained batch 187 in epoch 3, gen_loss = 0.7989190948453355, disc_loss = 0.10122076480431443
Trained batch 188 in epoch 3, gen_loss = 0.7980483759332586, disc_loss = 0.10105332825825643
Trained batch 189 in epoch 3, gen_loss = 0.7982416869778383, disc_loss = 0.10085037337910188
Trained batch 190 in epoch 3, gen_loss = 0.7972020873536614, disc_loss = 0.10093480706487963
Trained batch 191 in epoch 3, gen_loss = 0.7989658423078557, disc_loss = 0.10092158490442671
Trained batch 192 in epoch 3, gen_loss = 0.7984257975081706, disc_loss = 0.10105632746428096
Trained batch 193 in epoch 3, gen_loss = 0.798735013481268, disc_loss = 0.10080812446120166
Trained batch 194 in epoch 3, gen_loss = 0.7989481979455704, disc_loss = 0.10057910735217425
Trained batch 195 in epoch 3, gen_loss = 0.7993951188970585, disc_loss = 0.10032989081869624
Trained batch 196 in epoch 3, gen_loss = 0.7976879625756124, disc_loss = 0.10082206301164204
Trained batch 197 in epoch 3, gen_loss = 0.7990023547952826, disc_loss = 0.10071741974903177
Trained batch 198 in epoch 3, gen_loss = 0.7998210605065427, disc_loss = 0.10069189625956006
Trained batch 199 in epoch 3, gen_loss = 0.7984838181734085, disc_loss = 0.10078147106803953
Trained batch 200 in epoch 3, gen_loss = 0.7982230423694819, disc_loss = 0.10045840228856796
Trained batch 201 in epoch 3, gen_loss = 0.7973996306409931, disc_loss = 0.10071021116495428
Trained batch 202 in epoch 3, gen_loss = 0.7973449412237834, disc_loss = 0.10069799075462842
Trained batch 203 in epoch 3, gen_loss = 0.7973056742373634, disc_loss = 0.10055319816056713
Trained batch 204 in epoch 3, gen_loss = 0.7965085544237276, disc_loss = 0.10060553965953792
Trained batch 205 in epoch 3, gen_loss = 0.7952821141886479, disc_loss = 0.10110555004183817
Trained batch 206 in epoch 3, gen_loss = 0.7953340644421785, disc_loss = 0.10133799601904148
Trained batch 207 in epoch 3, gen_loss = 0.794847258581565, disc_loss = 0.10115863097151025
Trained batch 208 in epoch 3, gen_loss = 0.7950891484484148, disc_loss = 0.10088175844454594
Trained batch 209 in epoch 3, gen_loss = 0.7950227990036919, disc_loss = 0.10075019203303825
Trained batch 210 in epoch 3, gen_loss = 0.7945254275584108, disc_loss = 0.10043855164182412
Trained batch 211 in epoch 3, gen_loss = 0.7942810474701647, disc_loss = 0.10090806979229147
Trained batch 212 in epoch 3, gen_loss = 0.7934473084172172, disc_loss = 0.10088031921763095
Trained batch 213 in epoch 3, gen_loss = 0.7942101830076949, disc_loss = 0.10080988103715337
Trained batch 214 in epoch 3, gen_loss = 0.7944372800893562, disc_loss = 0.10069957781842975
Trained batch 215 in epoch 3, gen_loss = 0.7938128375896701, disc_loss = 0.10081210074497869
Trained batch 216 in epoch 3, gen_loss = 0.7943911428825097, disc_loss = 0.10083186002405282
Trained batch 217 in epoch 3, gen_loss = 0.7942742981495113, disc_loss = 0.10083429813555894
Trained batch 218 in epoch 3, gen_loss = 0.7956580677533258, disc_loss = 0.10128136493741921
Trained batch 219 in epoch 3, gen_loss = 0.7950881513682279, disc_loss = 0.10115017326210032
Trained batch 220 in epoch 3, gen_loss = 0.7944983052452226, disc_loss = 0.10095347060371039
Trained batch 221 in epoch 3, gen_loss = 0.7955457989696983, disc_loss = 0.10076628139594922
Trained batch 222 in epoch 3, gen_loss = 0.7954033525000773, disc_loss = 0.10046072722717518
Trained batch 223 in epoch 3, gen_loss = 0.7954766867416245, disc_loss = 0.1002219572879507
Trained batch 224 in epoch 3, gen_loss = 0.7959656998846266, disc_loss = 0.1000110635575321
Trained batch 225 in epoch 3, gen_loss = 0.7963783772645798, disc_loss = 0.10002194873296318
Trained batch 226 in epoch 3, gen_loss = 0.7957501161991237, disc_loss = 0.09990550046745639
Trained batch 227 in epoch 3, gen_loss = 0.7950382993409508, disc_loss = 0.09983761540793798
Trained batch 228 in epoch 3, gen_loss = 0.7954658459888275, disc_loss = 0.09975755527843294
Trained batch 229 in epoch 3, gen_loss = 0.7953473383965699, disc_loss = 0.09948346453678349
Trained batch 230 in epoch 3, gen_loss = 0.7953327840024774, disc_loss = 0.09927615501567141
Trained batch 231 in epoch 3, gen_loss = 0.7953864893522756, disc_loss = 0.09931162668488405
Trained batch 232 in epoch 3, gen_loss = 0.7956342832724935, disc_loss = 0.09899473537255254
Trained batch 233 in epoch 3, gen_loss = 0.7960951305352725, disc_loss = 0.09878231109016472
Trained batch 234 in epoch 3, gen_loss = 0.7958997008648324, disc_loss = 0.09860315039119821
Trained batch 235 in epoch 3, gen_loss = 0.7969595085261232, disc_loss = 0.09828713365783126
Trained batch 236 in epoch 3, gen_loss = 0.7966064896261642, disc_loss = 0.09817922027302191
Trained batch 237 in epoch 3, gen_loss = 0.7970065281671637, disc_loss = 0.09789822903313056
Trained batch 238 in epoch 3, gen_loss = 0.7988065299129885, disc_loss = 0.0986680572532959
Trained batch 239 in epoch 3, gen_loss = 0.7976537716885408, disc_loss = 0.0990051835309714
Trained batch 240 in epoch 3, gen_loss = 0.7977011626686793, disc_loss = 0.09886625274644847
Trained batch 241 in epoch 3, gen_loss = 0.797994244936084, disc_loss = 0.09854929412384171
Trained batch 242 in epoch 3, gen_loss = 0.798445964301074, disc_loss = 0.09844042494157214
Trained batch 243 in epoch 3, gen_loss = 0.7974789841253249, disc_loss = 0.09850840134637766
Trained batch 244 in epoch 3, gen_loss = 0.7975014725509955, disc_loss = 0.09823977503241325
Trained batch 245 in epoch 3, gen_loss = 0.7979607538479131, disc_loss = 0.09792226992123496
Trained batch 246 in epoch 3, gen_loss = 0.798179477573889, disc_loss = 0.0979064151886021
Trained batch 247 in epoch 3, gen_loss = 0.7979066201275394, disc_loss = 0.0977348537454682
Trained batch 248 in epoch 3, gen_loss = 0.7974062490176006, disc_loss = 0.09760134508571472
Trained batch 249 in epoch 3, gen_loss = 0.7976901731491088, disc_loss = 0.09747401916980744
Trained batch 250 in epoch 3, gen_loss = 0.798917739989748, disc_loss = 0.09729433123512098
Trained batch 251 in epoch 3, gen_loss = 0.7988701325560373, disc_loss = 0.09711715926431001
Trained batch 252 in epoch 3, gen_loss = 0.798060946784943, disc_loss = 0.09710923395314706
Trained batch 253 in epoch 3, gen_loss = 0.7984527133581206, disc_loss = 0.0972166598635161
Trained batch 254 in epoch 3, gen_loss = 0.7987878621793261, disc_loss = 0.09720622948279568
Trained batch 255 in epoch 3, gen_loss = 0.7973364042118192, disc_loss = 0.09790954149502795
Trained batch 256 in epoch 3, gen_loss = 0.7975783162543746, disc_loss = 0.09777303748847446
Trained batch 257 in epoch 3, gen_loss = 0.7989215351814447, disc_loss = 0.09776397602444933
Trained batch 258 in epoch 3, gen_loss = 0.798399454608387, disc_loss = 0.09766394623400622
Trained batch 259 in epoch 3, gen_loss = 0.7983601632026526, disc_loss = 0.09750973279946125
Trained batch 260 in epoch 3, gen_loss = 0.7989491418403684, disc_loss = 0.09758601698781795
Trained batch 261 in epoch 3, gen_loss = 0.7990154799159247, disc_loss = 0.09738776009558266
Trained batch 262 in epoch 3, gen_loss = 0.7992306895582395, disc_loss = 0.09718439854086579
Trained batch 263 in epoch 3, gen_loss = 0.7994493383801344, disc_loss = 0.09696516063007893
Trained batch 264 in epoch 3, gen_loss = 0.8004860511365927, disc_loss = 0.09709604203982174
Trained batch 265 in epoch 3, gen_loss = 0.7995392588296331, disc_loss = 0.09718823019779266
Trained batch 266 in epoch 3, gen_loss = 0.7990900691082415, disc_loss = 0.09705924436673243
Trained batch 267 in epoch 3, gen_loss = 0.8005872219800949, disc_loss = 0.09741240563288109
Trained batch 268 in epoch 3, gen_loss = 0.7998041705571143, disc_loss = 0.09769406018702514
Trained batch 269 in epoch 3, gen_loss = 0.8005335951292957, disc_loss = 0.09805251471698284
Trained batch 270 in epoch 3, gen_loss = 0.7996256006159905, disc_loss = 0.09833158229604859
Trained batch 271 in epoch 3, gen_loss = 0.8000330510823166, disc_loss = 0.09804844741216477
Trained batch 272 in epoch 3, gen_loss = 0.8014028043974013, disc_loss = 0.09813066170765804
Trained batch 273 in epoch 3, gen_loss = 0.8011927861366829, disc_loss = 0.09792688176253417
Trained batch 274 in epoch 3, gen_loss = 0.8010220696709373, disc_loss = 0.09789441124959425
Trained batch 275 in epoch 3, gen_loss = 0.8011199194883954, disc_loss = 0.09765947094538073
Trained batch 276 in epoch 3, gen_loss = 0.802681738934362, disc_loss = 0.0974168153916778
Trained batch 277 in epoch 3, gen_loss = 0.8020467357240992, disc_loss = 0.09734510037404813
Trained batch 278 in epoch 3, gen_loss = 0.8030918193547102, disc_loss = 0.0973038919016345
Trained batch 279 in epoch 3, gen_loss = 0.8028289384075573, disc_loss = 0.09718320919866008
Trained batch 280 in epoch 3, gen_loss = 0.8031489282740393, disc_loss = 0.09691179851964911
Trained batch 281 in epoch 3, gen_loss = 0.8032895079318513, disc_loss = 0.09668578103792372
Trained batch 282 in epoch 3, gen_loss = 0.8032566188923461, disc_loss = 0.09655737747230926
Trained batch 283 in epoch 3, gen_loss = 0.8039694951033928, disc_loss = 0.09652130921620508
Trained batch 284 in epoch 3, gen_loss = 0.803271920848311, disc_loss = 0.09654210371275743
Trained batch 285 in epoch 3, gen_loss = 0.8035971591105828, disc_loss = 0.09625219642608003
Trained batch 286 in epoch 3, gen_loss = 0.8036770561015565, disc_loss = 0.09612829443586517
Trained batch 287 in epoch 3, gen_loss = 0.8041108147137694, disc_loss = 0.0958977058406971
Trained batch 288 in epoch 3, gen_loss = 0.804347083642821, disc_loss = 0.09591165582317485
Trained batch 289 in epoch 3, gen_loss = 0.8035546853624541, disc_loss = 0.09622083753668542
Trained batch 290 in epoch 3, gen_loss = 0.8037093814296001, disc_loss = 0.09601044970087681
Trained batch 291 in epoch 3, gen_loss = 0.8036410398270986, disc_loss = 0.09586292064161844
Trained batch 292 in epoch 3, gen_loss = 0.8034612365550149, disc_loss = 0.09574597283447664
Trained batch 293 in epoch 3, gen_loss = 0.8041333059469858, disc_loss = 0.09636555493296105
Trained batch 294 in epoch 3, gen_loss = 0.8031863774283458, disc_loss = 0.09720629698959952
Trained batch 295 in epoch 3, gen_loss = 0.8040543283159668, disc_loss = 0.09749448362649796
Trained batch 296 in epoch 3, gen_loss = 0.8031755938674464, disc_loss = 0.09775496219356955
Trained batch 297 in epoch 3, gen_loss = 0.8025132751704862, disc_loss = 0.09772882573369066
Trained batch 298 in epoch 3, gen_loss = 0.8042365258752702, disc_loss = 0.09791819474980684
Trained batch 299 in epoch 3, gen_loss = 0.8036454790830612, disc_loss = 0.09802374922049542
Trained batch 300 in epoch 3, gen_loss = 0.8038193779530319, disc_loss = 0.09813046220541495
Trained batch 301 in epoch 3, gen_loss = 0.8035650578950415, disc_loss = 0.09803044944323155
Trained batch 302 in epoch 3, gen_loss = 0.8029828618461936, disc_loss = 0.09819578210033304
Trained batch 303 in epoch 3, gen_loss = 0.8031277833016295, disc_loss = 0.09831697229406257
Trained batch 304 in epoch 3, gen_loss = 0.802848922229204, disc_loss = 0.09834028326402433
Trained batch 305 in epoch 3, gen_loss = 0.8031635775285608, disc_loss = 0.09819950117406989
Trained batch 306 in epoch 3, gen_loss = 0.8039872696811291, disc_loss = 0.098276741927071
Trained batch 307 in epoch 3, gen_loss = 0.8034264619474287, disc_loss = 0.09840640503393075
Trained batch 308 in epoch 3, gen_loss = 0.8028307454871514, disc_loss = 0.09852985661886753
Trained batch 309 in epoch 3, gen_loss = 0.8034888775117935, disc_loss = 0.0985642071723217
Trained batch 310 in epoch 3, gen_loss = 0.803702598216066, disc_loss = 0.09838234239416586
Trained batch 311 in epoch 3, gen_loss = 0.8030421705200121, disc_loss = 0.09843790960104133
Trained batch 312 in epoch 3, gen_loss = 0.8031623458709961, disc_loss = 0.09830968654729402
Trained batch 313 in epoch 3, gen_loss = 0.8034299167857808, disc_loss = 0.098148384911548
Trained batch 314 in epoch 3, gen_loss = 0.8028961416274782, disc_loss = 0.09801203080172104
Trained batch 315 in epoch 3, gen_loss = 0.8024385850640792, disc_loss = 0.09800691097750788
Trained batch 316 in epoch 3, gen_loss = 0.8030571578428949, disc_loss = 0.09779157013887957
Trained batch 317 in epoch 3, gen_loss = 0.8029275261006266, disc_loss = 0.09759024302504442
Trained batch 318 in epoch 3, gen_loss = 0.8024909509386762, disc_loss = 0.09758487097673749
Trained batch 319 in epoch 3, gen_loss = 0.8029568517580629, disc_loss = 0.09737361083098221
Trained batch 320 in epoch 3, gen_loss = 0.8021282464544349, disc_loss = 0.09776011197842263
Trained batch 321 in epoch 3, gen_loss = 0.8032910125966398, disc_loss = 0.09780263662720041
Trained batch 322 in epoch 3, gen_loss = 0.8031935682606771, disc_loss = 0.09763625239082627
Trained batch 323 in epoch 3, gen_loss = 0.8032599932249681, disc_loss = 0.09747440563687296
Trained batch 324 in epoch 3, gen_loss = 0.8032345373813923, disc_loss = 0.0972610939380068
Trained batch 325 in epoch 3, gen_loss = 0.8028950285326484, disc_loss = 0.09718411940612767
Trained batch 326 in epoch 3, gen_loss = 0.8022790241314366, disc_loss = 0.0971266138267672
Trained batch 327 in epoch 3, gen_loss = 0.8026356762502251, disc_loss = 0.09718798338605954
Trained batch 328 in epoch 3, gen_loss = 0.8021292838644474, disc_loss = 0.0972946785463977
Trained batch 329 in epoch 3, gen_loss = 0.8018050022197493, disc_loss = 0.09723101377092076
Trained batch 330 in epoch 3, gen_loss = 0.8023490615841845, disc_loss = 0.09751304202175663
Trained batch 331 in epoch 3, gen_loss = 0.8013362143054066, disc_loss = 0.09763427528956659
Trained batch 332 in epoch 3, gen_loss = 0.8009180431967383, disc_loss = 0.097693810337321
Trained batch 333 in epoch 3, gen_loss = 0.801955784509282, disc_loss = 0.09813430603359363
Trained batch 334 in epoch 3, gen_loss = 0.8013385379492347, disc_loss = 0.09822169347985912
Trained batch 335 in epoch 3, gen_loss = 0.8008626974409535, disc_loss = 0.09851518292478952
Trained batch 336 in epoch 3, gen_loss = 0.8013520631662816, disc_loss = 0.09842197443648774
Trained batch 337 in epoch 3, gen_loss = 0.8011084754438795, disc_loss = 0.0983582372369366
Trained batch 338 in epoch 3, gen_loss = 0.8010444716717993, disc_loss = 0.09831337682672042
Trained batch 339 in epoch 3, gen_loss = 0.8009162113947027, disc_loss = 0.09825898977818297
Trained batch 340 in epoch 3, gen_loss = 0.8005901942155228, disc_loss = 0.09818359878722611
Trained batch 341 in epoch 3, gen_loss = 0.8015714932603446, disc_loss = 0.09831705189729381
Trained batch 342 in epoch 3, gen_loss = 0.8010134761257005, disc_loss = 0.09837242579983639
Trained batch 343 in epoch 3, gen_loss = 0.8015336531192757, disc_loss = 0.09827359910068903
Trained batch 344 in epoch 3, gen_loss = 0.801250333889671, disc_loss = 0.0982179787846795
Trained batch 345 in epoch 3, gen_loss = 0.800887728185323, disc_loss = 0.0982408097977454
Trained batch 346 in epoch 3, gen_loss = 0.8019859373397717, disc_loss = 0.09859034040357692
Trained batch 347 in epoch 3, gen_loss = 0.8025239070599106, disc_loss = 0.09836478367843933
Trained batch 348 in epoch 3, gen_loss = 0.801934870573716, disc_loss = 0.098694460431813
Trained batch 349 in epoch 3, gen_loss = 0.8028911769390106, disc_loss = 0.09849053574725986
Trained batch 350 in epoch 3, gen_loss = 0.8026916343941648, disc_loss = 0.09840835550497486
Trained batch 351 in epoch 3, gen_loss = 0.8033446136184714, disc_loss = 0.09853711838844571
Trained batch 352 in epoch 3, gen_loss = 0.8027056653168654, disc_loss = 0.09869223757364678
Trained batch 353 in epoch 3, gen_loss = 0.8030021283249397, disc_loss = 0.0984772828744335
Trained batch 354 in epoch 3, gen_loss = 0.8027453434299415, disc_loss = 0.09866085676082843
Trained batch 355 in epoch 3, gen_loss = 0.8018341999542847, disc_loss = 0.09888876420236455
Trained batch 356 in epoch 3, gen_loss = 0.8024899275863872, disc_loss = 0.09903790589150678
Trained batch 357 in epoch 3, gen_loss = 0.8021392483451513, disc_loss = 0.0991442204588327
Trained batch 358 in epoch 3, gen_loss = 0.8016232741078294, disc_loss = 0.09924667146222921
Trained batch 359 in epoch 3, gen_loss = 0.8015613644487328, disc_loss = 0.09920023537189182
Trained batch 360 in epoch 3, gen_loss = 0.8018786335090521, disc_loss = 0.09907852279646658
Trained batch 361 in epoch 3, gen_loss = 0.8014740177445648, disc_loss = 0.0990324912320061
Trained batch 362 in epoch 3, gen_loss = 0.8016389234827898, disc_loss = 0.09893371656629418
Trained batch 363 in epoch 3, gen_loss = 0.8013335165905429, disc_loss = 0.09890490433886893
Trained batch 364 in epoch 3, gen_loss = 0.8015279635174634, disc_loss = 0.09891456148446831
Trained batch 365 in epoch 3, gen_loss = 0.8016124070504975, disc_loss = 0.09893300868010993
Trained batch 366 in epoch 3, gen_loss = 0.8008685817673031, disc_loss = 0.09925339035233051
Trained batch 367 in epoch 3, gen_loss = 0.800990274661909, disc_loss = 0.09950811637859062
Trained batch 368 in epoch 3, gen_loss = 0.8010368092757899, disc_loss = 0.09935261211471587
Trained batch 369 in epoch 3, gen_loss = 0.8011221817216357, disc_loss = 0.09918553549544634
Trained batch 370 in epoch 3, gen_loss = 0.8009095541389805, disc_loss = 0.09913960366567592
Trained batch 371 in epoch 3, gen_loss = 0.8003887773681713, disc_loss = 0.09919494857400736
Trained batch 372 in epoch 3, gen_loss = 0.801096563604498, disc_loss = 0.09938679745635542
Trained batch 373 in epoch 3, gen_loss = 0.801301619665508, disc_loss = 0.09929596626991655
Trained batch 374 in epoch 3, gen_loss = 0.8010258799393972, disc_loss = 0.09927830666551987
Trained batch 375 in epoch 3, gen_loss = 0.8012301459749962, disc_loss = 0.09933685438281441
Trained batch 376 in epoch 3, gen_loss = 0.801407860903272, disc_loss = 0.0992408426063486
Trained batch 377 in epoch 3, gen_loss = 0.8006767393262298, disc_loss = 0.09943321591893596
Trained batch 378 in epoch 3, gen_loss = 0.8016145885934302, disc_loss = 0.09932023437452898
Trained batch 379 in epoch 3, gen_loss = 0.8018183553689404, disc_loss = 0.09917766354046761
Trained batch 380 in epoch 3, gen_loss = 0.8021854962420276, disc_loss = 0.09901357533317304
Trained batch 381 in epoch 3, gen_loss = 0.8020565872573103, disc_loss = 0.09886764999508312
Trained batch 382 in epoch 3, gen_loss = 0.8029203913697375, disc_loss = 0.09871339556024296
Trained batch 383 in epoch 3, gen_loss = 0.8025885038853934, disc_loss = 0.0987367030781267
Trained batch 384 in epoch 3, gen_loss = 0.8024955518059916, disc_loss = 0.09861218020948884
Trained batch 385 in epoch 3, gen_loss = 0.80278417830949, disc_loss = 0.09849636243424653
Trained batch 386 in epoch 3, gen_loss = 0.802352559119848, disc_loss = 0.09849611104006376
Trained batch 387 in epoch 3, gen_loss = 0.8028498934869913, disc_loss = 0.09833248597377739
Trained batch 388 in epoch 3, gen_loss = 0.8031787471630273, disc_loss = 0.09832390752360033
Trained batch 389 in epoch 3, gen_loss = 0.8028424211801627, disc_loss = 0.09832830746443226
Trained batch 390 in epoch 3, gen_loss = 0.8031450187611153, disc_loss = 0.09824216175500465
Trained batch 391 in epoch 3, gen_loss = 0.803441366750975, disc_loss = 0.09811850859812099
Trained batch 392 in epoch 3, gen_loss = 0.8030814782505423, disc_loss = 0.09834359508747136
Trained batch 393 in epoch 3, gen_loss = 0.8037368710422274, disc_loss = 0.09841493780247224
Trained batch 394 in epoch 3, gen_loss = 0.8043293235422689, disc_loss = 0.09831274570779333
Trained batch 395 in epoch 3, gen_loss = 0.8039165168549075, disc_loss = 0.09835785539171686
Trained batch 396 in epoch 3, gen_loss = 0.8038435197747325, disc_loss = 0.09819091451342596
Trained batch 397 in epoch 3, gen_loss = 0.8043134148845721, disc_loss = 0.09823629187288971
Trained batch 398 in epoch 3, gen_loss = 0.8041509535527767, disc_loss = 0.09819709330582455
Trained batch 399 in epoch 3, gen_loss = 0.8043417582660913, disc_loss = 0.09806215246440843
Trained batch 400 in epoch 3, gen_loss = 0.804245513647869, disc_loss = 0.09793926196920678
Trained batch 401 in epoch 3, gen_loss = 0.8037925226919687, disc_loss = 0.09801267507481412
Trained batch 402 in epoch 3, gen_loss = 0.803812909141072, disc_loss = 0.09809520069010574
Trained batch 403 in epoch 3, gen_loss = 0.8036816231537574, disc_loss = 0.09802071979997845
Trained batch 404 in epoch 3, gen_loss = 0.8038063185450471, disc_loss = 0.09786466039303277
Trained batch 405 in epoch 3, gen_loss = 0.8038955438753654, disc_loss = 0.09779816687226368
Trained batch 406 in epoch 3, gen_loss = 0.8038223811244496, disc_loss = 0.09764316353342824
Trained batch 407 in epoch 3, gen_loss = 0.8045139490243267, disc_loss = 0.09750070544553227
Trained batch 408 in epoch 3, gen_loss = 0.8041344669016766, disc_loss = 0.09747283114461926
Trained batch 409 in epoch 3, gen_loss = 0.8046485994647189, disc_loss = 0.0976775570000272
Trained batch 410 in epoch 3, gen_loss = 0.8047753025000403, disc_loss = 0.09749840886769431
Trained batch 411 in epoch 3, gen_loss = 0.8040531901913939, disc_loss = 0.09754711792587294
Trained batch 412 in epoch 3, gen_loss = 0.8045975982276926, disc_loss = 0.09738137197092211
Trained batch 413 in epoch 3, gen_loss = 0.804799933148467, disc_loss = 0.09738932506086817
Trained batch 414 in epoch 3, gen_loss = 0.8044057704598071, disc_loss = 0.0977089258853391
Trained batch 415 in epoch 3, gen_loss = 0.8049220507964492, disc_loss = 0.09756949758201909
Trained batch 416 in epoch 3, gen_loss = 0.8056066184163951, disc_loss = 0.09762634665033014
Trained batch 417 in epoch 3, gen_loss = 0.8048014045474632, disc_loss = 0.09789160096518802
Trained batch 418 in epoch 3, gen_loss = 0.8046331478900728, disc_loss = 0.09777113896859076
Trained batch 419 in epoch 3, gen_loss = 0.8048538616015798, disc_loss = 0.0978423562987397
Trained batch 420 in epoch 3, gen_loss = 0.8051734002497304, disc_loss = 0.09802825637648409
Trained batch 421 in epoch 3, gen_loss = 0.8046160696948309, disc_loss = 0.0982773353972459
Trained batch 422 in epoch 3, gen_loss = 0.8042066808147069, disc_loss = 0.09833244250395971
Trained batch 423 in epoch 3, gen_loss = 0.8047735950435108, disc_loss = 0.09865158592693438
Trained batch 424 in epoch 3, gen_loss = 0.8044874201802646, disc_loss = 0.0986137447308968
Trained batch 425 in epoch 3, gen_loss = 0.8042255043283875, disc_loss = 0.09857866434083089
Trained batch 426 in epoch 3, gen_loss = 0.8050170921190561, disc_loss = 0.09858584730499871
Trained batch 427 in epoch 3, gen_loss = 0.804557292469751, disc_loss = 0.09861039786564761
Trained batch 428 in epoch 3, gen_loss = 0.8044754759276108, disc_loss = 0.09861312763405082
Trained batch 429 in epoch 3, gen_loss = 0.8043518652056538, disc_loss = 0.09857863442712399
Trained batch 430 in epoch 3, gen_loss = 0.8052138071463999, disc_loss = 0.09877649065660282
Trained batch 431 in epoch 3, gen_loss = 0.8046350979280693, disc_loss = 0.0991628315424788
Trained batch 432 in epoch 3, gen_loss = 0.8045965689847431, disc_loss = 0.09915369152205439
Trained batch 433 in epoch 3, gen_loss = 0.8045364936238609, disc_loss = 0.09926876808787065
Trained batch 434 in epoch 3, gen_loss = 0.8046256244182587, disc_loss = 0.09915380450714936
Trained batch 435 in epoch 3, gen_loss = 0.804100037646403, disc_loss = 0.09916337841156221
Trained batch 436 in epoch 3, gen_loss = 0.8034257294793423, disc_loss = 0.0993361756295068
Trained batch 437 in epoch 3, gen_loss = 0.8039423540983026, disc_loss = 0.09936365818808952
Trained batch 438 in epoch 3, gen_loss = 0.8037223835605152, disc_loss = 0.09940499099764913
Trained batch 439 in epoch 3, gen_loss = 0.8032157366248694, disc_loss = 0.09948591920335523
Trained batch 440 in epoch 3, gen_loss = 0.803853285218042, disc_loss = 0.09963042704840433
Trained batch 441 in epoch 3, gen_loss = 0.8037988076247781, disc_loss = 0.09947108088600622
Trained batch 442 in epoch 3, gen_loss = 0.8033216203443084, disc_loss = 0.09946728044275707
Trained batch 443 in epoch 3, gen_loss = 0.8033181283253807, disc_loss = 0.09935394524143555
Trained batch 444 in epoch 3, gen_loss = 0.8035594663593206, disc_loss = 0.09950478030682615
Trained batch 445 in epoch 3, gen_loss = 0.8035793227598806, disc_loss = 0.09936260115229963
Trained batch 446 in epoch 3, gen_loss = 0.803141525994478, disc_loss = 0.09948619394052682
Trained batch 447 in epoch 3, gen_loss = 0.803264785092324, disc_loss = 0.09943363889345035
Trained batch 448 in epoch 3, gen_loss = 0.8039477262438538, disc_loss = 0.09931243475493384
Trained batch 449 in epoch 3, gen_loss = 0.8036402741405699, disc_loss = 0.09928726831037138
Trained batch 450 in epoch 3, gen_loss = 0.8033196766862848, disc_loss = 0.09934351775596979
Trained batch 451 in epoch 3, gen_loss = 0.8039350651402389, disc_loss = 0.09926199339190087
Trained batch 452 in epoch 3, gen_loss = 0.803503887740192, disc_loss = 0.09922471818273627
Trained batch 453 in epoch 3, gen_loss = 0.8030028896578608, disc_loss = 0.09937650541106181
Trained batch 454 in epoch 3, gen_loss = 0.8037011033231085, disc_loss = 0.09940276967750473
Trained batch 455 in epoch 3, gen_loss = 0.8034200173590267, disc_loss = 0.09929418236858685
Trained batch 456 in epoch 3, gen_loss = 0.8030966245762889, disc_loss = 0.0993925739931558
Trained batch 457 in epoch 3, gen_loss = 0.8045461744590617, disc_loss = 0.09997078593958608
Trained batch 458 in epoch 3, gen_loss = 0.804149744362613, disc_loss = 0.10003726800988896
Trained batch 459 in epoch 3, gen_loss = 0.8040909829994907, disc_loss = 0.09998552324452802
Trained batch 460 in epoch 3, gen_loss = 0.8037554582261729, disc_loss = 0.10014971759202618
Trained batch 461 in epoch 3, gen_loss = 0.803611799300491, disc_loss = 0.10025144431103038
Trained batch 462 in epoch 3, gen_loss = 0.8036031633551126, disc_loss = 0.100192557447077
Trained batch 463 in epoch 3, gen_loss = 0.8033123276485451, disc_loss = 0.10023253332173195
Trained batch 464 in epoch 3, gen_loss = 0.8040128290653229, disc_loss = 0.10032093856403584
Trained batch 465 in epoch 3, gen_loss = 0.8033029987704601, disc_loss = 0.10060448348002564
Trained batch 466 in epoch 3, gen_loss = 0.803354616913091, disc_loss = 0.10057463428121244
Trained batch 467 in epoch 3, gen_loss = 0.8034689663949176, disc_loss = 0.10059091918226172
Trained batch 468 in epoch 3, gen_loss = 0.80336605390506, disc_loss = 0.10062069852334032
Trained batch 469 in epoch 3, gen_loss = 0.8034410855237474, disc_loss = 0.10050161341997854
Trained batch 470 in epoch 3, gen_loss = 0.8031486146895496, disc_loss = 0.10041188793316198
Trained batch 471 in epoch 3, gen_loss = 0.8033400412206932, disc_loss = 0.10042268478003788
Trained batch 472 in epoch 3, gen_loss = 0.8032776164580098, disc_loss = 0.10038669791513656
Trained batch 473 in epoch 3, gen_loss = 0.8032268845959555, disc_loss = 0.10029109614362886
Trained batch 474 in epoch 3, gen_loss = 0.8032586380682494, disc_loss = 0.10018753162144046
Trained batch 475 in epoch 3, gen_loss = 0.8037796771200765, disc_loss = 0.10011008153904323
Trained batch 476 in epoch 3, gen_loss = 0.8039081149756033, disc_loss = 0.10003363961779534
Trained batch 477 in epoch 3, gen_loss = 0.8034371430030927, disc_loss = 0.1000945490831704
Trained batch 478 in epoch 3, gen_loss = 0.8036286475638507, disc_loss = 0.0999777023126381
Trained batch 479 in epoch 3, gen_loss = 0.803529319477578, disc_loss = 0.09998641180767057
Trained batch 480 in epoch 3, gen_loss = 0.803538214949709, disc_loss = 0.099945290968705
Trained batch 481 in epoch 3, gen_loss = 0.8042729769628573, disc_loss = 0.0997775512384212
Trained batch 482 in epoch 3, gen_loss = 0.8039396360177185, disc_loss = 0.09976609822702025
Trained batch 483 in epoch 3, gen_loss = 0.8042873692783442, disc_loss = 0.09961417317582864
Trained batch 484 in epoch 3, gen_loss = 0.8046497220231086, disc_loss = 0.09957211211362144
Trained batch 485 in epoch 3, gen_loss = 0.8047674220407941, disc_loss = 0.0994942717871211
Trained batch 486 in epoch 3, gen_loss = 0.8043527934218334, disc_loss = 0.09993140736988744
Trained batch 487 in epoch 3, gen_loss = 0.8047156532401921, disc_loss = 0.09995175451689141
Trained batch 488 in epoch 3, gen_loss = 0.8046786537077774, disc_loss = 0.09991504895883652
Trained batch 489 in epoch 3, gen_loss = 0.8049633926883035, disc_loss = 0.09982462674569414
Trained batch 490 in epoch 3, gen_loss = 0.8047130397405255, disc_loss = 0.09985099881773629
Trained batch 491 in epoch 3, gen_loss = 0.8043613153381076, disc_loss = 0.09984366523245788
Trained batch 492 in epoch 3, gen_loss = 0.8043999156289362, disc_loss = 0.09967970330661076
Trained batch 493 in epoch 3, gen_loss = 0.8048139073950077, disc_loss = 0.09957509077821484
Trained batch 494 in epoch 3, gen_loss = 0.8045338315795166, disc_loss = 0.0995746180433968
Trained batch 495 in epoch 3, gen_loss = 0.804121678935424, disc_loss = 0.09984349593287334
Trained batch 496 in epoch 3, gen_loss = 0.8037839165515823, disc_loss = 0.09993720104284509
Trained batch 497 in epoch 3, gen_loss = 0.8034009621684332, disc_loss = 0.10009576699109261
Trained batch 498 in epoch 3, gen_loss = 0.8037459559454947, disc_loss = 0.10006439768128798
Trained batch 499 in epoch 3, gen_loss = 0.8034200673699379, disc_loss = 0.10001434473879635
Trained batch 500 in epoch 3, gen_loss = 0.803376373833049, disc_loss = 0.0999148620121523
Trained batch 501 in epoch 3, gen_loss = 0.8035748029253872, disc_loss = 0.09978464403304743
Trained batch 502 in epoch 3, gen_loss = 0.803800133362442, disc_loss = 0.09973678347019564
Trained batch 503 in epoch 3, gen_loss = 0.8033433864632297, disc_loss = 0.09989363211022305
Trained batch 504 in epoch 3, gen_loss = 0.8039161477348592, disc_loss = 0.09985641745832002
Trained batch 505 in epoch 3, gen_loss = 0.8038424857166916, disc_loss = 0.09971536488526246
Trained batch 506 in epoch 3, gen_loss = 0.8036047766312104, disc_loss = 0.09965690664939685
Trained batch 507 in epoch 3, gen_loss = 0.8036695969269032, disc_loss = 0.09956428037743693
Trained batch 508 in epoch 3, gen_loss = 0.8040154309895746, disc_loss = 0.09957269702311641
Trained batch 509 in epoch 3, gen_loss = 0.8036878491733589, disc_loss = 0.0996698838987333
Trained batch 510 in epoch 3, gen_loss = 0.8034483653341954, disc_loss = 0.09958443318451746
Trained batch 511 in epoch 3, gen_loss = 0.8032918505487032, disc_loss = 0.09950318855590012
Trained batch 512 in epoch 3, gen_loss = 0.8038416397385663, disc_loss = 0.09948486766685345
Trained batch 513 in epoch 3, gen_loss = 0.8038284197043816, disc_loss = 0.09939497263000459
Trained batch 514 in epoch 3, gen_loss = 0.803697819212108, disc_loss = 0.09934781834808658
Trained batch 515 in epoch 3, gen_loss = 0.8040275581238806, disc_loss = 0.09922745785777017
Trained batch 516 in epoch 3, gen_loss = 0.8043857895313425, disc_loss = 0.09914069485308412
Trained batch 517 in epoch 3, gen_loss = 0.8043071490111958, disc_loss = 0.09910221647607831
Trained batch 518 in epoch 3, gen_loss = 0.8042229863605058, disc_loss = 0.09900848080291053
Trained batch 519 in epoch 3, gen_loss = 0.803655835814201, disc_loss = 0.09905135216943634
Trained batch 520 in epoch 3, gen_loss = 0.8042293506139986, disc_loss = 0.09898274840390213
Trained batch 521 in epoch 3, gen_loss = 0.8041930539512087, disc_loss = 0.09883570049307755
Trained batch 522 in epoch 3, gen_loss = 0.8043965669366643, disc_loss = 0.09872656500583112
Trained batch 523 in epoch 3, gen_loss = 0.8044727361042991, disc_loss = 0.0985774217823961
Trained batch 524 in epoch 3, gen_loss = 0.8049881295363108, disc_loss = 0.09852934062303531
Trained batch 525 in epoch 3, gen_loss = 0.8047760057018737, disc_loss = 0.09851808537031478
Trained batch 526 in epoch 3, gen_loss = 0.8047655249116995, disc_loss = 0.09842943025318167
Trained batch 527 in epoch 3, gen_loss = 0.8045753232118759, disc_loss = 0.09844933461334388
Trained batch 528 in epoch 3, gen_loss = 0.8049127456709207, disc_loss = 0.09829309421973496
Trained batch 529 in epoch 3, gen_loss = 0.805057233065929, disc_loss = 0.09818052592388583
Trained batch 530 in epoch 3, gen_loss = 0.8051807436453645, disc_loss = 0.098061963696587
Trained batch 531 in epoch 3, gen_loss = 0.8053585782198978, disc_loss = 0.09791930826709963
Trained batch 532 in epoch 3, gen_loss = 0.8054022463021091, disc_loss = 0.09783195071865929
Trained batch 533 in epoch 3, gen_loss = 0.8049758991387006, disc_loss = 0.09780672218559888
Trained batch 534 in epoch 3, gen_loss = 0.8051784851283671, disc_loss = 0.09764720471836974
Trained batch 535 in epoch 3, gen_loss = 0.8058969878327491, disc_loss = 0.09766483746309167
Trained batch 536 in epoch 3, gen_loss = 0.8061659719579934, disc_loss = 0.0975217558877123
Trained batch 537 in epoch 3, gen_loss = 0.8055291054527999, disc_loss = 0.09789471632409771
Trained batch 538 in epoch 3, gen_loss = 0.8062216442126733, disc_loss = 0.09785826592179143
Trained batch 539 in epoch 3, gen_loss = 0.8061693298044028, disc_loss = 0.09778800967701332
Trained batch 540 in epoch 3, gen_loss = 0.8061195960657433, disc_loss = 0.09773296051161182
Trained batch 541 in epoch 3, gen_loss = 0.805800897223923, disc_loss = 0.09769350841015963
Trained batch 542 in epoch 3, gen_loss = 0.8057418895360514, disc_loss = 0.09768370309292337
Trained batch 543 in epoch 3, gen_loss = 0.8055637817939415, disc_loss = 0.09774946166127098
Trained batch 544 in epoch 3, gen_loss = 0.806074406849135, disc_loss = 0.09779429303977741
Trained batch 545 in epoch 3, gen_loss = 0.8068409788630384, disc_loss = 0.09781293172027657
Trained batch 546 in epoch 3, gen_loss = 0.8063908721127937, disc_loss = 0.09783124470984532
Trained batch 547 in epoch 3, gen_loss = 0.8066373040532544, disc_loss = 0.0977320635749068
Trained batch 548 in epoch 3, gen_loss = 0.8067045150450236, disc_loss = 0.09763008660258546
Trained batch 549 in epoch 3, gen_loss = 0.8066190694137053, disc_loss = 0.09756754184480418
Trained batch 550 in epoch 3, gen_loss = 0.8064806351536199, disc_loss = 0.09751138874175815
Trained batch 551 in epoch 3, gen_loss = 0.80677157289524, disc_loss = 0.09742505905940535
Trained batch 552 in epoch 3, gen_loss = 0.8072644810025559, disc_loss = 0.09728951478178258
Trained batch 553 in epoch 3, gen_loss = 0.8070333246612377, disc_loss = 0.09725598916445022
Trained batch 554 in epoch 3, gen_loss = 0.8069425732702822, disc_loss = 0.09712425042950623
Trained batch 555 in epoch 3, gen_loss = 0.8074904214456785, disc_loss = 0.09730293922856612
Trained batch 556 in epoch 3, gen_loss = 0.8070507714628531, disc_loss = 0.09738445003254463
Trained batch 557 in epoch 3, gen_loss = 0.8080878641763468, disc_loss = 0.09736534520002302
Trained batch 558 in epoch 3, gen_loss = 0.8077453927725073, disc_loss = 0.09739896965134816
Trained batch 559 in epoch 3, gen_loss = 0.8075415105159793, disc_loss = 0.09736385364916973
Trained batch 560 in epoch 3, gen_loss = 0.8079339591470844, disc_loss = 0.09727246230119531
Trained batch 561 in epoch 3, gen_loss = 0.8077767670048513, disc_loss = 0.09720603407284384
Trained batch 562 in epoch 3, gen_loss = 0.8081804832069742, disc_loss = 0.0972019924036166
Trained batch 563 in epoch 3, gen_loss = 0.8084521564714452, disc_loss = 0.09707701872499223
Trained batch 564 in epoch 3, gen_loss = 0.8078550306041684, disc_loss = 0.09714693213953117
Trained batch 565 in epoch 3, gen_loss = 0.8078041819085502, disc_loss = 0.09703558335712595
Trained batch 566 in epoch 3, gen_loss = 0.8078558382954337, disc_loss = 0.09698056909083216
Trained batch 567 in epoch 3, gen_loss = 0.808031510404298, disc_loss = 0.09690506743680372
Trained batch 568 in epoch 3, gen_loss = 0.8081933492516382, disc_loss = 0.0968159937163936
Trained batch 569 in epoch 3, gen_loss = 0.8076679219279372, disc_loss = 0.09713484810077046
Trained batch 570 in epoch 3, gen_loss = 0.8078590838170093, disc_loss = 0.09703808184386918
Trained batch 571 in epoch 3, gen_loss = 0.8092224743816402, disc_loss = 0.09726586647924375
Trained batch 572 in epoch 3, gen_loss = 0.8087125223968665, disc_loss = 0.09752052920150456
Trained batch 573 in epoch 3, gen_loss = 0.8086748187550269, disc_loss = 0.09745826005435936
Trained batch 574 in epoch 3, gen_loss = 0.8084009116628895, disc_loss = 0.09760137974406066
Trained batch 575 in epoch 3, gen_loss = 0.8086342822967304, disc_loss = 0.09749252748022424
Trained batch 576 in epoch 3, gen_loss = 0.8083072498931422, disc_loss = 0.09750320132744322
Trained batch 577 in epoch 3, gen_loss = 0.8085167200713834, disc_loss = 0.09744365208308538
Trained batch 578 in epoch 3, gen_loss = 0.8086249033610026, disc_loss = 0.09758491980616447
Trained batch 579 in epoch 3, gen_loss = 0.8083867839698133, disc_loss = 0.09752255225200848
Trained batch 580 in epoch 3, gen_loss = 0.8080439010503575, disc_loss = 0.09748395471296653
Trained batch 581 in epoch 3, gen_loss = 0.8082885767790869, disc_loss = 0.09735362613381646
Trained batch 582 in epoch 3, gen_loss = 0.8085246821210479, disc_loss = 0.09727553457922684
Trained batch 583 in epoch 3, gen_loss = 0.8086056698062648, disc_loss = 0.09716435958956662
Trained batch 584 in epoch 3, gen_loss = 0.8089098183517782, disc_loss = 0.09712427228721034
Trained batch 585 in epoch 3, gen_loss = 0.8084694630253437, disc_loss = 0.09730987368571117
Trained batch 586 in epoch 3, gen_loss = 0.8086275850284648, disc_loss = 0.09719541699512904
Trained batch 587 in epoch 3, gen_loss = 0.8086857311174173, disc_loss = 0.09706925381082712
Trained batch 588 in epoch 3, gen_loss = 0.808648142628435, disc_loss = 0.0969961270490734
Trained batch 589 in epoch 3, gen_loss = 0.8090934088674643, disc_loss = 0.0968731547074424
Trained batch 590 in epoch 3, gen_loss = 0.8087326510101809, disc_loss = 0.09685924412389546
Trained batch 591 in epoch 3, gen_loss = 0.8089542729226319, disc_loss = 0.09673490625258686
Trained batch 592 in epoch 3, gen_loss = 0.8086776142377676, disc_loss = 0.09676250092477913
Trained batch 593 in epoch 3, gen_loss = 0.8088682066109847, disc_loss = 0.09668257036826476
Trained batch 594 in epoch 3, gen_loss = 0.8085420381121274, disc_loss = 0.09663510529966164
Trained batch 595 in epoch 3, gen_loss = 0.8083169271281901, disc_loss = 0.0965847662359401
Trained batch 596 in epoch 3, gen_loss = 0.8085860338442689, disc_loss = 0.0965509489007057
Trained batch 597 in epoch 3, gen_loss = 0.8085961850191837, disc_loss = 0.09644489187940357
Trained batch 598 in epoch 3, gen_loss = 0.808474950081916, disc_loss = 0.09644446429487112
Trained batch 599 in epoch 3, gen_loss = 0.8086416618029276, disc_loss = 0.09647752082130562
Trained batch 600 in epoch 3, gen_loss = 0.8084752803634289, disc_loss = 0.09656126807891638
Trained batch 601 in epoch 3, gen_loss = 0.8083659913452756, disc_loss = 0.09653756221248908
Trained batch 602 in epoch 3, gen_loss = 0.8087735717767112, disc_loss = 0.09648799366946294
Trained batch 603 in epoch 3, gen_loss = 0.8086184057968342, disc_loss = 0.09640549365831971
Trained batch 604 in epoch 3, gen_loss = 0.8088807303058214, disc_loss = 0.09634943700064559
Trained batch 605 in epoch 3, gen_loss = 0.8090762605171392, disc_loss = 0.09623982909323014
Trained batch 606 in epoch 3, gen_loss = 0.8086149884016549, disc_loss = 0.09648814008922563
Trained batch 607 in epoch 3, gen_loss = 0.8090213163706818, disc_loss = 0.0963957627306962
Trained batch 608 in epoch 3, gen_loss = 0.8092569570823256, disc_loss = 0.09630806598665533
Trained batch 609 in epoch 3, gen_loss = 0.809206708923715, disc_loss = 0.09633673022913396
Trained batch 610 in epoch 3, gen_loss = 0.808923933880614, disc_loss = 0.09630230785105164
Trained batch 611 in epoch 3, gen_loss = 0.8087000587796853, disc_loss = 0.09621328869195399
Trained batch 612 in epoch 3, gen_loss = 0.8089889379348879, disc_loss = 0.09611253881125087
Trained batch 613 in epoch 3, gen_loss = 0.8090677622475143, disc_loss = 0.09600690749385894
Trained batch 614 in epoch 3, gen_loss = 0.8093569910623194, disc_loss = 0.09590415313264461
Trained batch 615 in epoch 3, gen_loss = 0.809333583364239, disc_loss = 0.09582599278618037
Trained batch 616 in epoch 3, gen_loss = 0.8093143960451964, disc_loss = 0.09573138160615967
Trained batch 617 in epoch 3, gen_loss = 0.8094155215522618, disc_loss = 0.09562778237357157
Trained batch 618 in epoch 3, gen_loss = 0.8094904066480226, disc_loss = 0.09560406138979032
Trained batch 619 in epoch 3, gen_loss = 0.8092850129450521, disc_loss = 0.09553102568062323
Trained batch 620 in epoch 3, gen_loss = 0.8097924520044127, disc_loss = 0.09548047105309324
Trained batch 621 in epoch 3, gen_loss = 0.8097855780285654, disc_loss = 0.09535820871873062
Trained batch 622 in epoch 3, gen_loss = 0.8097171358656539, disc_loss = 0.09528275519268614
Trained batch 623 in epoch 3, gen_loss = 0.8096218124414102, disc_loss = 0.09519743841613093
Trained batch 624 in epoch 3, gen_loss = 0.8096681064605713, disc_loss = 0.09511884427517653
Trained batch 625 in epoch 3, gen_loss = 0.8097835456410917, disc_loss = 0.09501803497792766
Trained batch 626 in epoch 3, gen_loss = 0.8102135221923937, disc_loss = 0.09491111321948124
Trained batch 627 in epoch 3, gen_loss = 0.8100447875868743, disc_loss = 0.09486412011816575
Trained batch 628 in epoch 3, gen_loss = 0.8099671859051352, disc_loss = 0.0947891422880544
Trained batch 629 in epoch 3, gen_loss = 0.8100693521045503, disc_loss = 0.09470168982322018
Trained batch 630 in epoch 3, gen_loss = 0.809979198473947, disc_loss = 0.09461582126022093
Trained batch 631 in epoch 3, gen_loss = 0.810386150320874, disc_loss = 0.09465782965468597
Trained batch 632 in epoch 3, gen_loss = 0.810440908581913, disc_loss = 0.09455746724925006
Trained batch 633 in epoch 3, gen_loss = 0.8102710725569199, disc_loss = 0.09451981752153121
Trained batch 634 in epoch 3, gen_loss = 0.8103945665472135, disc_loss = 0.09440675831480523
Trained batch 635 in epoch 3, gen_loss = 0.8103929341026822, disc_loss = 0.09461850582317408
Trained batch 636 in epoch 3, gen_loss = 0.8101408572361645, disc_loss = 0.09468044809195882
Trained batch 637 in epoch 3, gen_loss = 0.8103071046660313, disc_loss = 0.09466200353005509
Trained batch 638 in epoch 3, gen_loss = 0.8099783544249378, disc_loss = 0.09467633739725945
Trained batch 639 in epoch 3, gen_loss = 0.8096642621792853, disc_loss = 0.09472890810138779
Trained batch 640 in epoch 3, gen_loss = 0.8099917185473926, disc_loss = 0.09484407082112875
Trained batch 641 in epoch 3, gen_loss = 0.81004893751902, disc_loss = 0.09476148591426163
Trained batch 642 in epoch 3, gen_loss = 0.8098461253461349, disc_loss = 0.09483246038440458
Trained batch 643 in epoch 3, gen_loss = 0.8098393662005478, disc_loss = 0.09475323379832257
Trained batch 644 in epoch 3, gen_loss = 0.8106725387795027, disc_loss = 0.09496532616371563
Trained batch 645 in epoch 3, gen_loss = 0.8101367333632874, disc_loss = 0.09563576347185962
Trained batch 646 in epoch 3, gen_loss = 0.8103219629531666, disc_loss = 0.09567287660000912
Trained batch 647 in epoch 3, gen_loss = 0.8102997392875912, disc_loss = 0.09558488468978737
Trained batch 648 in epoch 3, gen_loss = 0.8102679379823946, disc_loss = 0.09554234213799881
Trained batch 649 in epoch 3, gen_loss = 0.8106454132611935, disc_loss = 0.09548925064074305
Trained batch 650 in epoch 3, gen_loss = 0.8108272373493183, disc_loss = 0.09540271803811078
Trained batch 651 in epoch 3, gen_loss = 0.8107164871016163, disc_loss = 0.09530032595956664
Trained batch 652 in epoch 3, gen_loss = 0.8109851465382218, disc_loss = 0.09519833920360934
Trained batch 653 in epoch 3, gen_loss = 0.8112241224320292, disc_loss = 0.09507821982908732
Trained batch 654 in epoch 3, gen_loss = 0.8111128482654805, disc_loss = 0.09505303788304556
Trained batch 655 in epoch 3, gen_loss = 0.8115015569165712, disc_loss = 0.09504506251598685
Trained batch 656 in epoch 3, gen_loss = 0.8115145414840866, disc_loss = 0.09499224285131584
Trained batch 657 in epoch 3, gen_loss = 0.8114025117687904, disc_loss = 0.09498670987790524
Trained batch 658 in epoch 3, gen_loss = 0.8112971261256743, disc_loss = 0.09489573222445112
Trained batch 659 in epoch 3, gen_loss = 0.8116440234310699, disc_loss = 0.094781169533786
Trained batch 660 in epoch 3, gen_loss = 0.8118146157030258, disc_loss = 0.09465947425142268
Trained batch 661 in epoch 3, gen_loss = 0.8120023878769572, disc_loss = 0.09462529409879374
Trained batch 662 in epoch 3, gen_loss = 0.8118541627717774, disc_loss = 0.09460139447938352
Trained batch 663 in epoch 3, gen_loss = 0.8120712202087225, disc_loss = 0.0945328044037458
Trained batch 664 in epoch 3, gen_loss = 0.8122503021157774, disc_loss = 0.09444669324596573
Trained batch 665 in epoch 3, gen_loss = 0.8123268479252005, disc_loss = 0.0943377384938322
Trained batch 666 in epoch 3, gen_loss = 0.8124967822874861, disc_loss = 0.09425784504205838
Trained batch 667 in epoch 3, gen_loss = 0.8125616500745276, disc_loss = 0.09417591902321416
Trained batch 668 in epoch 3, gen_loss = 0.8131519519962003, disc_loss = 0.09434998784108457
Trained batch 669 in epoch 3, gen_loss = 0.8129599284325073, disc_loss = 0.09444198001509727
Trained batch 670 in epoch 3, gen_loss = 0.8129474062766829, disc_loss = 0.09447425145561489
Trained batch 671 in epoch 3, gen_loss = 0.8129161471678388, disc_loss = 0.09456684869725168
Trained batch 672 in epoch 3, gen_loss = 0.8135959782802332, disc_loss = 0.09468856220580582
Trained batch 673 in epoch 3, gen_loss = 0.813701985188337, disc_loss = 0.09461951809893818
Trained batch 674 in epoch 3, gen_loss = 0.813244929181205, disc_loss = 0.09473120452353248
Trained batch 675 in epoch 3, gen_loss = 0.8134531825340006, disc_loss = 0.09472772608285207
Trained batch 676 in epoch 3, gen_loss = 0.8134582164632693, disc_loss = 0.0946818807546154
Trained batch 677 in epoch 3, gen_loss = 0.8132061478750544, disc_loss = 0.0946906384294935
Trained batch 678 in epoch 3, gen_loss = 0.8129632196914465, disc_loss = 0.09465296426307909
Trained batch 679 in epoch 3, gen_loss = 0.8127416095751173, disc_loss = 0.09466055581510505
Trained batch 680 in epoch 3, gen_loss = 0.8131357545632097, disc_loss = 0.09472944796708975
Trained batch 681 in epoch 3, gen_loss = 0.8128895067836532, disc_loss = 0.09474245677606538
Trained batch 682 in epoch 3, gen_loss = 0.8128495707257076, disc_loss = 0.094906958949099
Trained batch 683 in epoch 3, gen_loss = 0.8128148371800344, disc_loss = 0.09489564364776015
Trained batch 684 in epoch 3, gen_loss = 0.8126584415453194, disc_loss = 0.09479171494769789
Trained batch 685 in epoch 3, gen_loss = 0.8125311819613849, disc_loss = 0.09474002742330725
Trained batch 686 in epoch 3, gen_loss = 0.8129562535573995, disc_loss = 0.09466965725642712
Trained batch 687 in epoch 3, gen_loss = 0.8133410248732151, disc_loss = 0.0945577806993496
Trained batch 688 in epoch 3, gen_loss = 0.8130267345074819, disc_loss = 0.0946265676116952
Trained batch 689 in epoch 3, gen_loss = 0.8133762042159619, disc_loss = 0.09456049828803625
Trained batch 690 in epoch 3, gen_loss = 0.8134154169759599, disc_loss = 0.09446869638792944
Trained batch 691 in epoch 3, gen_loss = 0.8136928810635743, disc_loss = 0.09439277729945462
Trained batch 692 in epoch 3, gen_loss = 0.8133416987342752, disc_loss = 0.09439710574157396
Trained batch 693 in epoch 3, gen_loss = 0.8133518307198708, disc_loss = 0.09429485144453278
Trained batch 694 in epoch 3, gen_loss = 0.8135903102459667, disc_loss = 0.09423411371950194
Trained batch 695 in epoch 3, gen_loss = 0.8136157774976616, disc_loss = 0.0941135819503588
Trained batch 696 in epoch 3, gen_loss = 0.8135636252600972, disc_loss = 0.09403108804616302
Trained batch 697 in epoch 3, gen_loss = 0.8136106060449578, disc_loss = 0.09405859192849315
Trained batch 698 in epoch 3, gen_loss = 0.8133287706514967, disc_loss = 0.09409130856298838
Trained batch 699 in epoch 3, gen_loss = 0.8136252287881715, disc_loss = 0.09404486499992865
Trained batch 700 in epoch 3, gen_loss = 0.8135109722784344, disc_loss = 0.09396535811013144
Trained batch 701 in epoch 3, gen_loss = 0.813296326332622, disc_loss = 0.09392939648322994
Trained batch 702 in epoch 3, gen_loss = 0.8135471822611807, disc_loss = 0.09383913178585078
Trained batch 703 in epoch 3, gen_loss = 0.8139641266739504, disc_loss = 0.09380600472584112
Trained batch 704 in epoch 3, gen_loss = 0.8139444950201833, disc_loss = 0.09375933012693909
Trained batch 705 in epoch 3, gen_loss = 0.8140170367767048, disc_loss = 0.09367314083158716
Trained batch 706 in epoch 3, gen_loss = 0.8138745931705625, disc_loss = 0.09358047696865852
Trained batch 707 in epoch 3, gen_loss = 0.8142080687112727, disc_loss = 0.09360936641598404
Trained batch 708 in epoch 3, gen_loss = 0.8145557713861694, disc_loss = 0.0935331396259399
Trained batch 709 in epoch 3, gen_loss = 0.8141593784093857, disc_loss = 0.09370962241533357
Trained batch 710 in epoch 3, gen_loss = 0.8140063618222034, disc_loss = 0.09367100121885664
Trained batch 711 in epoch 3, gen_loss = 0.8144675590767619, disc_loss = 0.09396349354856386
Trained batch 712 in epoch 3, gen_loss = 0.8142257628317133, disc_loss = 0.09392632947134855
Trained batch 713 in epoch 3, gen_loss = 0.8140333102447312, disc_loss = 0.0938720621914715
Trained batch 714 in epoch 3, gen_loss = 0.8142454977218921, disc_loss = 0.09379828536583411
Trained batch 715 in epoch 3, gen_loss = 0.8142101001722852, disc_loss = 0.09375430074098973
Trained batch 716 in epoch 3, gen_loss = 0.8140114435674091, disc_loss = 0.093803702130124
Trained batch 717 in epoch 3, gen_loss = 0.8138624299784557, disc_loss = 0.0937428699785579
Trained batch 718 in epoch 3, gen_loss = 0.8139338869295797, disc_loss = 0.09372685550969814
Trained batch 719 in epoch 3, gen_loss = 0.814131203500761, disc_loss = 0.09376529592555016
Trained batch 720 in epoch 3, gen_loss = 0.8139419875181333, disc_loss = 0.09385409290629766
Trained batch 721 in epoch 3, gen_loss = 0.8139775503127529, disc_loss = 0.09381615347551424
Trained batch 722 in epoch 3, gen_loss = 0.8144000782264219, disc_loss = 0.0940330822000159
Trained batch 723 in epoch 3, gen_loss = 0.8140937696257349, disc_loss = 0.0941659700079147
Trained batch 724 in epoch 3, gen_loss = 0.8143798407603955, disc_loss = 0.09413579707258735
Trained batch 725 in epoch 3, gen_loss = 0.814382687621537, disc_loss = 0.09406475276114117
Trained batch 726 in epoch 3, gen_loss = 0.8141896369286712, disc_loss = 0.09417071242392719
Trained batch 727 in epoch 3, gen_loss = 0.8142218930790057, disc_loss = 0.09410747739097493
Trained batch 728 in epoch 3, gen_loss = 0.8144970127012177, disc_loss = 0.09407328218170563
Trained batch 729 in epoch 3, gen_loss = 0.814320510911615, disc_loss = 0.09404607760936838
Trained batch 730 in epoch 3, gen_loss = 0.8143059512251216, disc_loss = 0.09400582567071376
Trained batch 731 in epoch 3, gen_loss = 0.8142647739560878, disc_loss = 0.09392722537028578
Trained batch 732 in epoch 3, gen_loss = 0.8140282271097009, disc_loss = 0.09397018732093936
Trained batch 733 in epoch 3, gen_loss = 0.8143418784930856, disc_loss = 0.09408346065941803
Trained batch 734 in epoch 3, gen_loss = 0.8142324434251201, disc_loss = 0.09409073475418853
Trained batch 735 in epoch 3, gen_loss = 0.8141389474191744, disc_loss = 0.0940321808169677
Trained batch 736 in epoch 3, gen_loss = 0.813870837075416, disc_loss = 0.09424195190691964
Trained batch 737 in epoch 3, gen_loss = 0.8138685927077683, disc_loss = 0.09415535055111013
Trained batch 738 in epoch 3, gen_loss = 0.8136364084054717, disc_loss = 0.09413018291097774
Trained batch 739 in epoch 3, gen_loss = 0.8136084922664875, disc_loss = 0.09406530821091823
Trained batch 740 in epoch 3, gen_loss = 0.813619308022835, disc_loss = 0.09399982533504364
Trained batch 741 in epoch 3, gen_loss = 0.8134675672192457, disc_loss = 0.09398757116843989
Trained batch 742 in epoch 3, gen_loss = 0.8137181285332542, disc_loss = 0.09410826258942946
Trained batch 743 in epoch 3, gen_loss = 0.8135244438164336, disc_loss = 0.09408970576490686
Trained batch 744 in epoch 3, gen_loss = 0.8134916342744891, disc_loss = 0.09406801394918221
Trained batch 745 in epoch 3, gen_loss = 0.8135335890041919, disc_loss = 0.09399031182306622
Trained batch 746 in epoch 3, gen_loss = 0.8132728774305009, disc_loss = 0.09413318206098584
Trained batch 747 in epoch 3, gen_loss = 0.8135600597224134, disc_loss = 0.09407076948536511
Trained batch 748 in epoch 3, gen_loss = 0.8135923635418488, disc_loss = 0.093986125613186
Trained batch 749 in epoch 3, gen_loss = 0.8137115228573482, disc_loss = 0.0939711836402615
Trained batch 750 in epoch 3, gen_loss = 0.813542731711455, disc_loss = 0.09395969338893652
Trained batch 751 in epoch 3, gen_loss = 0.8132604992690873, disc_loss = 0.09394551255056595
Trained batch 752 in epoch 3, gen_loss = 0.8135090470709807, disc_loss = 0.09412150205933002
Trained batch 753 in epoch 3, gen_loss = 0.8134014971297363, disc_loss = 0.0941456510297539
Trained batch 754 in epoch 3, gen_loss = 0.813020321509696, disc_loss = 0.09424554005215895
Trained batch 755 in epoch 3, gen_loss = 0.8136923107757139, disc_loss = 0.09452687556949005
Trained batch 756 in epoch 3, gen_loss = 0.8130695034837155, disc_loss = 0.09495076716507206
Trained batch 757 in epoch 3, gen_loss = 0.8134182892091042, disc_loss = 0.09493107875774671
Trained batch 758 in epoch 3, gen_loss = 0.8134131076621758, disc_loss = 0.09485974947385716
Trained batch 759 in epoch 3, gen_loss = 0.8132572898739263, disc_loss = 0.09481114129731921
Trained batch 760 in epoch 3, gen_loss = 0.8129014124538206, disc_loss = 0.09487063820754103
Trained batch 761 in epoch 3, gen_loss = 0.812977701816659, disc_loss = 0.09499605938919338
Trained batch 762 in epoch 3, gen_loss = 0.8129521476331888, disc_loss = 0.09494833260784377
Trained batch 763 in epoch 3, gen_loss = 0.8127784088488025, disc_loss = 0.09495565314967361
Trained batch 764 in epoch 3, gen_loss = 0.8126922679882423, disc_loss = 0.09493371112138228
Trained batch 765 in epoch 3, gen_loss = 0.8127622774002135, disc_loss = 0.09489857844337238
Trained batch 766 in epoch 3, gen_loss = 0.8127771979671413, disc_loss = 0.09481320915576144
Trained batch 767 in epoch 3, gen_loss = 0.8127710622890542, disc_loss = 0.09476335260114865
Trained batch 768 in epoch 3, gen_loss = 0.8125575212725428, disc_loss = 0.0947521378023378
Trained batch 769 in epoch 3, gen_loss = 0.8125208487758389, disc_loss = 0.09473850574924961
Trained batch 770 in epoch 3, gen_loss = 0.8127031593780418, disc_loss = 0.09468490778481836
Trained batch 771 in epoch 3, gen_loss = 0.8125884773817704, disc_loss = 0.09471416442746712
Trained batch 772 in epoch 3, gen_loss = 0.8121378447229156, disc_loss = 0.09479342534280301
Trained batch 773 in epoch 3, gen_loss = 0.8121112407177917, disc_loss = 0.09470736392525816
Trained batch 774 in epoch 3, gen_loss = 0.8120757934354966, disc_loss = 0.09473823842742751
Trained batch 775 in epoch 3, gen_loss = 0.811913496517029, disc_loss = 0.09470723342083241
Trained batch 776 in epoch 3, gen_loss = 0.8121183167860161, disc_loss = 0.094632798638027
Trained batch 777 in epoch 3, gen_loss = 0.8119071491426552, disc_loss = 0.09457342452812548
Trained batch 778 in epoch 3, gen_loss = 0.8118317605442199, disc_loss = 0.09455108964655534
Trained batch 779 in epoch 3, gen_loss = 0.8119048036825962, disc_loss = 0.09450582712172316
Trained batch 780 in epoch 3, gen_loss = 0.8116500044143765, disc_loss = 0.0945169311064497
Trained batch 781 in epoch 3, gen_loss = 0.8114255961707181, disc_loss = 0.09450439650736883
Trained batch 782 in epoch 3, gen_loss = 0.8115628192707953, disc_loss = 0.09443365356445997
Trained batch 783 in epoch 3, gen_loss = 0.8115062416360086, disc_loss = 0.09437632456431355
Trained batch 784 in epoch 3, gen_loss = 0.8117231535304125, disc_loss = 0.09467593839831033
Trained batch 785 in epoch 3, gen_loss = 0.8113916076473304, disc_loss = 0.09502203984579437
Trained batch 786 in epoch 3, gen_loss = 0.8115293490386827, disc_loss = 0.09503069062027346
Trained batch 787 in epoch 3, gen_loss = 0.8113414673938364, disc_loss = 0.09502808566484128
Trained batch 788 in epoch 3, gen_loss = 0.8115637956614428, disc_loss = 0.09499848206469692
Trained batch 789 in epoch 3, gen_loss = 0.8115816588643231, disc_loss = 0.09494394757843848
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.8771374225616455, disc_loss = 0.12959831953048706
Trained batch 1 in epoch 4, gen_loss = 0.728710263967514, disc_loss = 0.1293325126171112
Trained batch 2 in epoch 4, gen_loss = 0.861845870812734, disc_loss = 0.13955413301785788
Trained batch 3 in epoch 4, gen_loss = 0.8172506541013718, disc_loss = 0.12975171767175198
Trained batch 4 in epoch 4, gen_loss = 0.7704142928123474, disc_loss = 0.11924790292978286
Trained batch 5 in epoch 4, gen_loss = 0.8391574521859487, disc_loss = 0.1144478830198447
Trained batch 6 in epoch 4, gen_loss = 0.8232205169541496, disc_loss = 0.11200889838593346
Trained batch 7 in epoch 4, gen_loss = 0.804174467921257, disc_loss = 0.10704648308455944
Trained batch 8 in epoch 4, gen_loss = 0.7967483335071139, disc_loss = 0.10165769441260232
Trained batch 9 in epoch 4, gen_loss = 0.8137907266616822, disc_loss = 0.09376651272177697
Trained batch 10 in epoch 4, gen_loss = 0.7987754399126227, disc_loss = 0.09284009852192619
Trained batch 11 in epoch 4, gen_loss = 0.8093286255995432, disc_loss = 0.09064735534290473
Trained batch 12 in epoch 4, gen_loss = 0.808972546687493, disc_loss = 0.08857898700695771
Trained batch 13 in epoch 4, gen_loss = 0.811308673449925, disc_loss = 0.08412100880273751
Trained batch 14 in epoch 4, gen_loss = 0.796869687239329, disc_loss = 0.08830533002813658
Trained batch 15 in epoch 4, gen_loss = 0.8047660477459431, disc_loss = 0.0911093836184591
Trained batch 16 in epoch 4, gen_loss = 0.8087822304052465, disc_loss = 0.08708983133820926
Trained batch 17 in epoch 4, gen_loss = 0.8033973409069909, disc_loss = 0.08412236347794533
Trained batch 18 in epoch 4, gen_loss = 0.7975051371674788, disc_loss = 0.08244845702459938
Trained batch 19 in epoch 4, gen_loss = 0.7937130182981491, disc_loss = 0.08246293179690838
Trained batch 20 in epoch 4, gen_loss = 0.8027181795665196, disc_loss = 0.08072090024749438
Trained batch 21 in epoch 4, gen_loss = 0.794234804131768, disc_loss = 0.08123853955079209
Trained batch 22 in epoch 4, gen_loss = 0.8116612615792648, disc_loss = 0.08181483606281488
Trained batch 23 in epoch 4, gen_loss = 0.8218563869595528, disc_loss = 0.07906418992206454
Trained batch 24 in epoch 4, gen_loss = 0.8162710595130921, disc_loss = 0.07971592739224434
Trained batch 25 in epoch 4, gen_loss = 0.8128389097177066, disc_loss = 0.07818115316331387
Trained batch 26 in epoch 4, gen_loss = 0.8212096006781967, disc_loss = 0.07732663510574235
Trained batch 27 in epoch 4, gen_loss = 0.8279440764869962, disc_loss = 0.07635648269206285
Trained batch 28 in epoch 4, gen_loss = 0.8222300595250623, disc_loss = 0.07693128146488092
Trained batch 29 in epoch 4, gen_loss = 0.8253465414047241, disc_loss = 0.07560636786123116
Trained batch 30 in epoch 4, gen_loss = 0.8324247867830338, disc_loss = 0.07456410219592433
Trained batch 31 in epoch 4, gen_loss = 0.8300496861338615, disc_loss = 0.07445587497204542
Trained batch 32 in epoch 4, gen_loss = 0.8298250834147135, disc_loss = 0.07430960147669821
Trained batch 33 in epoch 4, gen_loss = 0.8340901311706094, disc_loss = 0.07414861943791895
Trained batch 34 in epoch 4, gen_loss = 0.8295932480267116, disc_loss = 0.0744316354393959
Trained batch 35 in epoch 4, gen_loss = 0.8360587507486343, disc_loss = 0.07496794602937168
Trained batch 36 in epoch 4, gen_loss = 0.8307818705971176, disc_loss = 0.07534014071161682
Trained batch 37 in epoch 4, gen_loss = 0.8343492950263777, disc_loss = 0.07541298317281823
Trained batch 38 in epoch 4, gen_loss = 0.833081352405059, disc_loss = 0.07437589592658557
Trained batch 39 in epoch 4, gen_loss = 0.8394764453172684, disc_loss = 0.07339408118277788
Trained batch 40 in epoch 4, gen_loss = 0.8362301326379543, disc_loss = 0.07284304208871795
Trained batch 41 in epoch 4, gen_loss = 0.8407108102525983, disc_loss = 0.07428677380084991
Trained batch 42 in epoch 4, gen_loss = 0.8382567791051643, disc_loss = 0.07380217365747274
Trained batch 43 in epoch 4, gen_loss = 0.830871959978884, disc_loss = 0.0758657782253894
Trained batch 44 in epoch 4, gen_loss = 0.8388863311873542, disc_loss = 0.07952880379226472
Trained batch 45 in epoch 4, gen_loss = 0.83554716732191, disc_loss = 0.07891190116820128
Trained batch 46 in epoch 4, gen_loss = 0.833441972732544, disc_loss = 0.07832032822548075
Trained batch 47 in epoch 4, gen_loss = 0.8322991927464803, disc_loss = 0.07830374982828896
Trained batch 48 in epoch 4, gen_loss = 0.8388446545114323, disc_loss = 0.08480027059511262
Trained batch 49 in epoch 4, gen_loss = 0.8307607728242874, disc_loss = 0.08799051269888877
Trained batch 50 in epoch 4, gen_loss = 0.8307797680882847, disc_loss = 0.08667422867580957
Trained batch 51 in epoch 4, gen_loss = 0.8331743988853234, disc_loss = 0.08910179202659772
Trained batch 52 in epoch 4, gen_loss = 0.8296927309261178, disc_loss = 0.08909370251140504
Trained batch 53 in epoch 4, gen_loss = 0.8334570974111557, disc_loss = 0.08782228399757985
Trained batch 54 in epoch 4, gen_loss = 0.8297097991813313, disc_loss = 0.08714597861875187
Trained batch 55 in epoch 4, gen_loss = 0.8293439176465783, disc_loss = 0.08876025530376605
Trained batch 56 in epoch 4, gen_loss = 0.8263444602489471, disc_loss = 0.0884061603431116
Trained batch 57 in epoch 4, gen_loss = 0.8236729620859541, disc_loss = 0.0886195797858567
Trained batch 58 in epoch 4, gen_loss = 0.8230919822797937, disc_loss = 0.08783038983405647
Trained batch 59 in epoch 4, gen_loss = 0.8259824439883232, disc_loss = 0.08847228301068147
Trained batch 60 in epoch 4, gen_loss = 0.8226557124833591, disc_loss = 0.08886658021661102
Trained batch 61 in epoch 4, gen_loss = 0.8191893355500314, disc_loss = 0.0888101619578177
Trained batch 62 in epoch 4, gen_loss = 0.8192770003326355, disc_loss = 0.08916298418291031
Trained batch 63 in epoch 4, gen_loss = 0.8172905049286783, disc_loss = 0.0887721263570711
Trained batch 64 in epoch 4, gen_loss = 0.8197438675623674, disc_loss = 0.08832209144647304
Trained batch 65 in epoch 4, gen_loss = 0.8171907983946077, disc_loss = 0.08820238878781145
Trained batch 66 in epoch 4, gen_loss = 0.8142148082825675, disc_loss = 0.0882515926192056
Trained batch 67 in epoch 4, gen_loss = 0.8211634163470829, disc_loss = 0.08777741611223011
Trained batch 68 in epoch 4, gen_loss = 0.8206603643686875, disc_loss = 0.08722910922074663
Trained batch 69 in epoch 4, gen_loss = 0.8184193947485515, disc_loss = 0.08729938023856708
Trained batch 70 in epoch 4, gen_loss = 0.8179044652153069, disc_loss = 0.08661027147736348
Trained batch 71 in epoch 4, gen_loss = 0.8182478791309727, disc_loss = 0.08608537933064832
Trained batch 72 in epoch 4, gen_loss = 0.8178224347225608, disc_loss = 0.08535711161077839
Trained batch 73 in epoch 4, gen_loss = 0.8172284457329158, disc_loss = 0.08475657864599614
Trained batch 74 in epoch 4, gen_loss = 0.8163730831940968, disc_loss = 0.08449692159891128
Trained batch 75 in epoch 4, gen_loss = 0.8189492904041943, disc_loss = 0.08635901042113178
Trained batch 76 in epoch 4, gen_loss = 0.8153693912091193, disc_loss = 0.08763121387788228
Trained batch 77 in epoch 4, gen_loss = 0.8140608251858981, disc_loss = 0.08766117271704552
Trained batch 78 in epoch 4, gen_loss = 0.8155800869947747, disc_loss = 0.0892218992679934
Trained batch 79 in epoch 4, gen_loss = 0.8144035201519728, disc_loss = 0.08857789589092135
Trained batch 80 in epoch 4, gen_loss = 0.8114557527465585, disc_loss = 0.08978152137111735
Trained batch 81 in epoch 4, gen_loss = 0.8104697287809558, disc_loss = 0.08914808274769201
Trained batch 82 in epoch 4, gen_loss = 0.8108687928642135, disc_loss = 0.0888191802225199
Trained batch 83 in epoch 4, gen_loss = 0.8123461274164063, disc_loss = 0.08828410954170283
Trained batch 84 in epoch 4, gen_loss = 0.8115187999080209, disc_loss = 0.08859135758350878
Trained batch 85 in epoch 4, gen_loss = 0.8117189729629561, disc_loss = 0.09000524709564309
Trained batch 86 in epoch 4, gen_loss = 0.8087682453380234, disc_loss = 0.09017769928122389
Trained batch 87 in epoch 4, gen_loss = 0.8099608180875127, disc_loss = 0.08963292176750573
Trained batch 88 in epoch 4, gen_loss = 0.8083264777499638, disc_loss = 0.08966758361693179
Trained batch 89 in epoch 4, gen_loss = 0.8075293544265959, disc_loss = 0.08967980866630872
Trained batch 90 in epoch 4, gen_loss = 0.807140092600833, disc_loss = 0.08913586145410171
Trained batch 91 in epoch 4, gen_loss = 0.806549009097659, disc_loss = 0.08867425046375264
Trained batch 92 in epoch 4, gen_loss = 0.8091316431440333, disc_loss = 0.08938001476789034
Trained batch 93 in epoch 4, gen_loss = 0.8071824448539856, disc_loss = 0.08933517895638943
Trained batch 94 in epoch 4, gen_loss = 0.8056045610653727, disc_loss = 0.08976344407389039
Trained batch 95 in epoch 4, gen_loss = 0.8058274161691467, disc_loss = 0.09064687668190648
Trained batch 96 in epoch 4, gen_loss = 0.8054975950226342, disc_loss = 0.09077995996346179
Trained batch 97 in epoch 4, gen_loss = 0.8029189477769696, disc_loss = 0.09091600809930539
Trained batch 98 in epoch 4, gen_loss = 0.8034423815481591, disc_loss = 0.0912427617368674
Trained batch 99 in epoch 4, gen_loss = 0.8044241574406624, disc_loss = 0.09070950355380773
Trained batch 100 in epoch 4, gen_loss = 0.8038554212244431, disc_loss = 0.09036755432734395
Trained batch 101 in epoch 4, gen_loss = 0.8027087353608188, disc_loss = 0.09003692492842674
Trained batch 102 in epoch 4, gen_loss = 0.8005658987077694, disc_loss = 0.0903070393985915
Trained batch 103 in epoch 4, gen_loss = 0.8060570356364434, disc_loss = 0.09321301330167514
Trained batch 104 in epoch 4, gen_loss = 0.8054102633680617, disc_loss = 0.09282244642575582
Trained batch 105 in epoch 4, gen_loss = 0.8019359966494003, disc_loss = 0.09324748181509522
Trained batch 106 in epoch 4, gen_loss = 0.7994463126236033, disc_loss = 0.09430575036556921
Trained batch 107 in epoch 4, gen_loss = 0.8025170824042073, disc_loss = 0.09567380530966653
Trained batch 108 in epoch 4, gen_loss = 0.8003398316715835, disc_loss = 0.09630420585291101
Trained batch 109 in epoch 4, gen_loss = 0.8001710490746932, disc_loss = 0.09571862247857181
Trained batch 110 in epoch 4, gen_loss = 0.8008017346665666, disc_loss = 0.09512874202148335
Trained batch 111 in epoch 4, gen_loss = 0.8009372843163354, disc_loss = 0.09526502061635256
Trained batch 112 in epoch 4, gen_loss = 0.8007579255948024, disc_loss = 0.09487751604313344
Trained batch 113 in epoch 4, gen_loss = 0.798924433034763, disc_loss = 0.09521880043311078
Trained batch 114 in epoch 4, gen_loss = 0.7984863410825315, disc_loss = 0.09534057576371276
Trained batch 115 in epoch 4, gen_loss = 0.8004079938962542, disc_loss = 0.09575986467173388
Trained batch 116 in epoch 4, gen_loss = 0.798845051190792, disc_loss = 0.09564423984569362
Trained batch 117 in epoch 4, gen_loss = 0.7972385964151156, disc_loss = 0.09599417388060336
Trained batch 118 in epoch 4, gen_loss = 0.7965978859853344, disc_loss = 0.09614417335691572
Trained batch 119 in epoch 4, gen_loss = 0.7999123498797417, disc_loss = 0.09687534660721818
Trained batch 120 in epoch 4, gen_loss = 0.7972179429590209, disc_loss = 0.0976540386245763
Trained batch 121 in epoch 4, gen_loss = 0.7973076725592378, disc_loss = 0.09780513131838353
Trained batch 122 in epoch 4, gen_loss = 0.7965564306189374, disc_loss = 0.09761514705492229
Trained batch 123 in epoch 4, gen_loss = 0.7967515433988264, disc_loss = 0.09741894519256969
Trained batch 124 in epoch 4, gen_loss = 0.7964000949859619, disc_loss = 0.09714360120892525
Trained batch 125 in epoch 4, gen_loss = 0.7957366335959661, disc_loss = 0.09714643695643024
Trained batch 126 in epoch 4, gen_loss = 0.7950751523333272, disc_loss = 0.09738582422531496
Trained batch 127 in epoch 4, gen_loss = 0.7951757893897593, disc_loss = 0.0969674842490349
Trained batch 128 in epoch 4, gen_loss = 0.7943526945372884, disc_loss = 0.09701048366205636
Trained batch 129 in epoch 4, gen_loss = 0.7947272305305187, disc_loss = 0.09672397011174605
Trained batch 130 in epoch 4, gen_loss = 0.7961162979366215, disc_loss = 0.09659085681533995
Trained batch 131 in epoch 4, gen_loss = 0.7968160803570892, disc_loss = 0.09611717394242685
Trained batch 132 in epoch 4, gen_loss = 0.7960045140488703, disc_loss = 0.09615645706093401
Trained batch 133 in epoch 4, gen_loss = 0.7954601658813989, disc_loss = 0.09645525685775636
Trained batch 134 in epoch 4, gen_loss = 0.7981652935345968, disc_loss = 0.09638039963664832
Trained batch 135 in epoch 4, gen_loss = 0.7976523348513771, disc_loss = 0.09598138279226773
Trained batch 136 in epoch 4, gen_loss = 0.7972374527993864, disc_loss = 0.0959152685084047
Trained batch 137 in epoch 4, gen_loss = 0.7949390864890554, disc_loss = 0.09634130461600379
Trained batch 138 in epoch 4, gen_loss = 0.7954373857100233, disc_loss = 0.09591853902708712
Trained batch 139 in epoch 4, gen_loss = 0.797156229189464, disc_loss = 0.09660403414496353
Trained batch 140 in epoch 4, gen_loss = 0.7969552802701368, disc_loss = 0.09626715445349403
Trained batch 141 in epoch 4, gen_loss = 0.7952609385403109, disc_loss = 0.09714342674738924
Trained batch 142 in epoch 4, gen_loss = 0.7964895951164352, disc_loss = 0.09783975769589831
Trained batch 143 in epoch 4, gen_loss = 0.7980870236125257, disc_loss = 0.09741405521829923
Trained batch 144 in epoch 4, gen_loss = 0.7957808876859731, disc_loss = 0.09775443971157075
Trained batch 145 in epoch 4, gen_loss = 0.7960795511121619, disc_loss = 0.09737093389442522
Trained batch 146 in epoch 4, gen_loss = 0.7991503546027099, disc_loss = 0.09768314598774423
Trained batch 147 in epoch 4, gen_loss = 0.7975403751070435, disc_loss = 0.09858681140719233
Trained batch 148 in epoch 4, gen_loss = 0.7976385294991052, disc_loss = 0.0981921107326978
Trained batch 149 in epoch 4, gen_loss = 0.7969535434246063, disc_loss = 0.09859851298232873
Trained batch 150 in epoch 4, gen_loss = 0.7972180294674753, disc_loss = 0.09836365615591308
Trained batch 151 in epoch 4, gen_loss = 0.7970569937636978, disc_loss = 0.09819119734885662
Trained batch 152 in epoch 4, gen_loss = 0.7974588477533627, disc_loss = 0.09774097661469497
Trained batch 153 in epoch 4, gen_loss = 0.7975270039849467, disc_loss = 0.0977879623072101
Trained batch 154 in epoch 4, gen_loss = 0.7969181468409877, disc_loss = 0.09795246126670991
Trained batch 155 in epoch 4, gen_loss = 0.7961962880232395, disc_loss = 0.09784783960248415
Trained batch 156 in epoch 4, gen_loss = 0.7977300464727317, disc_loss = 0.09757403087369196
Trained batch 157 in epoch 4, gen_loss = 0.7970653176307678, disc_loss = 0.09744079960392246
Trained batch 158 in epoch 4, gen_loss = 0.7977275061157515, disc_loss = 0.09771509939488375
Trained batch 159 in epoch 4, gen_loss = 0.7969216205179691, disc_loss = 0.09762276315595955
Trained batch 160 in epoch 4, gen_loss = 0.7966769382079936, disc_loss = 0.0974190995235991
Trained batch 161 in epoch 4, gen_loss = 0.798653957652457, disc_loss = 0.0979759134122251
Trained batch 162 in epoch 4, gen_loss = 0.7993504309946774, disc_loss = 0.09784445383705975
Trained batch 163 in epoch 4, gen_loss = 0.7972835907485427, disc_loss = 0.09927217314792115
Trained batch 164 in epoch 4, gen_loss = 0.7971632240396558, disc_loss = 0.09984241252144178
Trained batch 165 in epoch 4, gen_loss = 0.7971586109284895, disc_loss = 0.09955724712506116
Trained batch 166 in epoch 4, gen_loss = 0.7962462147195896, disc_loss = 0.09965268355197535
Trained batch 167 in epoch 4, gen_loss = 0.7959333294559092, disc_loss = 0.09954859087953255
Trained batch 168 in epoch 4, gen_loss = 0.798366376457835, disc_loss = 0.09966911263102611
Trained batch 169 in epoch 4, gen_loss = 0.79737909664126, disc_loss = 0.09954489252584822
Trained batch 170 in epoch 4, gen_loss = 0.7965826714596553, disc_loss = 0.09971408112442981
Trained batch 171 in epoch 4, gen_loss = 0.7970782190907834, disc_loss = 0.09930618901108933
Trained batch 172 in epoch 4, gen_loss = 0.7970065717407734, disc_loss = 0.09902362995969423
Trained batch 173 in epoch 4, gen_loss = 0.7985495080550512, disc_loss = 0.09862680308221058
Trained batch 174 in epoch 4, gen_loss = 0.7984402300630297, disc_loss = 0.0983001296115773
Trained batch 175 in epoch 4, gen_loss = 0.7983246640386906, disc_loss = 0.09826409826266834
Trained batch 176 in epoch 4, gen_loss = 0.7968547457018814, disc_loss = 0.09881766663474889
Trained batch 177 in epoch 4, gen_loss = 0.7964534851607312, disc_loss = 0.09874072613382942
Trained batch 178 in epoch 4, gen_loss = 0.7958355227995185, disc_loss = 0.09870549125919462
Trained batch 179 in epoch 4, gen_loss = 0.7973045638865894, disc_loss = 0.09965634731989768
Trained batch 180 in epoch 4, gen_loss = 0.7969351870249648, disc_loss = 0.09955747784707099
Trained batch 181 in epoch 4, gen_loss = 0.7963110301848296, disc_loss = 0.09978426359389182
Trained batch 182 in epoch 4, gen_loss = 0.7977977452056656, disc_loss = 0.09959873851246195
Trained batch 183 in epoch 4, gen_loss = 0.7972046559595544, disc_loss = 0.09956985777851356
Trained batch 184 in epoch 4, gen_loss = 0.797374057930869, disc_loss = 0.09955038046716033
Trained batch 185 in epoch 4, gen_loss = 0.7979281232241662, disc_loss = 0.09971700429475756
Trained batch 186 in epoch 4, gen_loss = 0.7972210978760439, disc_loss = 0.09997456601477243
Trained batch 187 in epoch 4, gen_loss = 0.7959562956969789, disc_loss = 0.10010631145671645
Trained batch 188 in epoch 4, gen_loss = 0.7968897250278917, disc_loss = 0.10008185677151515
Trained batch 189 in epoch 4, gen_loss = 0.7964000098015133, disc_loss = 0.10048134876905303
Trained batch 190 in epoch 4, gen_loss = 0.7957244754149652, disc_loss = 0.1004621067927926
Trained batch 191 in epoch 4, gen_loss = 0.7964493612137934, disc_loss = 0.10023723931711477
Trained batch 192 in epoch 4, gen_loss = 0.7968313448478521, disc_loss = 0.10003628974558466
Trained batch 193 in epoch 4, gen_loss = 0.7961133271455765, disc_loss = 0.09996747877448797
Trained batch 194 in epoch 4, gen_loss = 0.7958698035814823, disc_loss = 0.09975696277733033
Trained batch 195 in epoch 4, gen_loss = 0.7968277175511632, disc_loss = 0.09955498138062503
Trained batch 196 in epoch 4, gen_loss = 0.7956386918041307, disc_loss = 0.09972268724010377
Trained batch 197 in epoch 4, gen_loss = 0.7953757690359847, disc_loss = 0.09967462661102264
Trained batch 198 in epoch 4, gen_loss = 0.796118235318505, disc_loss = 0.09933476939086039
Trained batch 199 in epoch 4, gen_loss = 0.7965888465940952, disc_loss = 0.09896250397898257
Trained batch 200 in epoch 4, gen_loss = 0.7963060723311866, disc_loss = 0.0987661231531581
Trained batch 201 in epoch 4, gen_loss = 0.7966442817803656, disc_loss = 0.09840174816032447
Trained batch 202 in epoch 4, gen_loss = 0.7968638391036705, disc_loss = 0.09806791743437938
Trained batch 203 in epoch 4, gen_loss = 0.7962648834960133, disc_loss = 0.09794435251102436
Trained batch 204 in epoch 4, gen_loss = 0.7970382383683833, disc_loss = 0.09813209527694597
Trained batch 205 in epoch 4, gen_loss = 0.7956988286335491, disc_loss = 0.098310041729614
Trained batch 206 in epoch 4, gen_loss = 0.7951656673553485, disc_loss = 0.09846701371317036
Trained batch 207 in epoch 4, gen_loss = 0.7950641651852772, disc_loss = 0.09851127596966062
Trained batch 208 in epoch 4, gen_loss = 0.795742162249305, disc_loss = 0.09824434121509203
Trained batch 209 in epoch 4, gen_loss = 0.794895732828549, disc_loss = 0.09835581455734514
Trained batch 210 in epoch 4, gen_loss = 0.7964520034914333, disc_loss = 0.09815618875149584
Trained batch 211 in epoch 4, gen_loss = 0.7970922964642633, disc_loss = 0.09808898779546034
Trained batch 212 in epoch 4, gen_loss = 0.7964172725666296, disc_loss = 0.09798304158582094
Trained batch 213 in epoch 4, gen_loss = 0.7966071599833319, disc_loss = 0.09770054470260288
Trained batch 214 in epoch 4, gen_loss = 0.7973614048126132, disc_loss = 0.09803814772776392
Trained batch 215 in epoch 4, gen_loss = 0.7967089647772135, disc_loss = 0.09799703440835907
Trained batch 216 in epoch 4, gen_loss = 0.7970970837476616, disc_loss = 0.09781307140837342
Trained batch 217 in epoch 4, gen_loss = 0.7962292456025377, disc_loss = 0.09763889377851279
Trained batch 218 in epoch 4, gen_loss = 0.7977359742606611, disc_loss = 0.09760511684397312
Trained batch 219 in epoch 4, gen_loss = 0.7982864413749088, disc_loss = 0.09725791378454729
Trained batch 220 in epoch 4, gen_loss = 0.79755359712769, disc_loss = 0.09721461646427396
Trained batch 221 in epoch 4, gen_loss = 0.7985498079577008, disc_loss = 0.09700640114779407
Trained batch 222 in epoch 4, gen_loss = 0.7996441346380209, disc_loss = 0.09667326410555786
Trained batch 223 in epoch 4, gen_loss = 0.7994479141863329, disc_loss = 0.09657545258856512
Trained batch 224 in epoch 4, gen_loss = 0.8002206334802839, disc_loss = 0.09621305815047689
Trained batch 225 in epoch 4, gen_loss = 0.8002056836818172, disc_loss = 0.09631959014300225
Trained batch 226 in epoch 4, gen_loss = 0.800379447868742, disc_loss = 0.0960354824357621
Trained batch 227 in epoch 4, gen_loss = 0.7997287920953935, disc_loss = 0.09606367287536462
Trained batch 228 in epoch 4, gen_loss = 0.7989585338461347, disc_loss = 0.09612879885856762
Trained batch 229 in epoch 4, gen_loss = 0.8003691311763681, disc_loss = 0.0962905197687771
Trained batch 230 in epoch 4, gen_loss = 0.800125182578058, disc_loss = 0.09621939256593778
Trained batch 231 in epoch 4, gen_loss = 0.7999836731830547, disc_loss = 0.09613717305634556
Trained batch 232 in epoch 4, gen_loss = 0.800471219254154, disc_loss = 0.09596413258830877
Trained batch 233 in epoch 4, gen_loss = 0.8020786769115008, disc_loss = 0.09601657509676412
Trained batch 234 in epoch 4, gen_loss = 0.8010541879116221, disc_loss = 0.09613319676607213
Trained batch 235 in epoch 4, gen_loss = 0.8014939082628589, disc_loss = 0.09583296783868286
Trained batch 236 in epoch 4, gen_loss = 0.8010458620540201, disc_loss = 0.09568975170296204
Trained batch 237 in epoch 4, gen_loss = 0.8013201742863455, disc_loss = 0.09557371354121871
Trained batch 238 in epoch 4, gen_loss = 0.8007555056565975, disc_loss = 0.09543821193028444
Trained batch 239 in epoch 4, gen_loss = 0.800648495927453, disc_loss = 0.09518776462258151
Trained batch 240 in epoch 4, gen_loss = 0.8015160485174646, disc_loss = 0.0949677435209766
Trained batch 241 in epoch 4, gen_loss = 0.8025368426210624, disc_loss = 0.09466706729717245
Trained batch 242 in epoch 4, gen_loss = 0.8024914121186292, disc_loss = 0.0944536374230321
Trained batch 243 in epoch 4, gen_loss = 0.8024895666319816, disc_loss = 0.09425133864441124
Trained batch 244 in epoch 4, gen_loss = 0.8028815122283235, disc_loss = 0.093915463436623
Trained batch 245 in epoch 4, gen_loss = 0.8039157621986498, disc_loss = 0.09412525185361141
Trained batch 246 in epoch 4, gen_loss = 0.8045898013510685, disc_loss = 0.09380832281310549
Trained batch 247 in epoch 4, gen_loss = 0.8035785763734772, disc_loss = 0.09428695820632481
Trained batch 248 in epoch 4, gen_loss = 0.80459355170947, disc_loss = 0.09411136880816226
Trained batch 249 in epoch 4, gen_loss = 0.804989394068718, disc_loss = 0.09437001314759254
Trained batch 250 in epoch 4, gen_loss = 0.8041186094046588, disc_loss = 0.09429341343888249
Trained batch 251 in epoch 4, gen_loss = 0.804983102494762, disc_loss = 0.0940048417283429
Trained batch 252 in epoch 4, gen_loss = 0.8053853600157108, disc_loss = 0.09408324918610306
Trained batch 253 in epoch 4, gen_loss = 0.8045009340592256, disc_loss = 0.093972607860415
Trained batch 254 in epoch 4, gen_loss = 0.8042564603627896, disc_loss = 0.09382369116533036
Trained batch 255 in epoch 4, gen_loss = 0.804899359238334, disc_loss = 0.09376561820681673
Trained batch 256 in epoch 4, gen_loss = 0.8046409342771375, disc_loss = 0.09366129792443974
Trained batch 257 in epoch 4, gen_loss = 0.8048306212637776, disc_loss = 0.09352296678883623
Trained batch 258 in epoch 4, gen_loss = 0.8050772829635723, disc_loss = 0.09322495096898907
Trained batch 259 in epoch 4, gen_loss = 0.8049928521880737, disc_loss = 0.09299233180399125
Trained batch 260 in epoch 4, gen_loss = 0.8053821872248961, disc_loss = 0.09272701026322284
Trained batch 261 in epoch 4, gen_loss = 0.8062434509282804, disc_loss = 0.0924835346056191
Trained batch 262 in epoch 4, gen_loss = 0.8053749374790337, disc_loss = 0.0924605751488032
Trained batch 263 in epoch 4, gen_loss = 0.8069111457602545, disc_loss = 0.09237114610291566
Trained batch 264 in epoch 4, gen_loss = 0.8075206042460675, disc_loss = 0.09207565606975893
Trained batch 265 in epoch 4, gen_loss = 0.8074456091438021, disc_loss = 0.0918038561625084
Trained batch 266 in epoch 4, gen_loss = 0.8071932182106633, disc_loss = 0.09158596845364637
Trained batch 267 in epoch 4, gen_loss = 0.8072227950193989, disc_loss = 0.09135100156166104
Trained batch 268 in epoch 4, gen_loss = 0.8086338901829986, disc_loss = 0.09135047002560476
Trained batch 269 in epoch 4, gen_loss = 0.8084577316487277, disc_loss = 0.09110511119511944
Trained batch 270 in epoch 4, gen_loss = 0.8074931747579047, disc_loss = 0.09114694040323645
Trained batch 271 in epoch 4, gen_loss = 0.808175462681581, disc_loss = 0.09116013827802175
Trained batch 272 in epoch 4, gen_loss = 0.8084609981203253, disc_loss = 0.0909597377971688
Trained batch 273 in epoch 4, gen_loss = 0.8084454411355249, disc_loss = 0.09080823683893702
Trained batch 274 in epoch 4, gen_loss = 0.8086358160322362, disc_loss = 0.09126315359703518
Trained batch 275 in epoch 4, gen_loss = 0.8085473550186641, disc_loss = 0.09106302541086747
Trained batch 276 in epoch 4, gen_loss = 0.8083239252601719, disc_loss = 0.09096480582232187
Trained batch 277 in epoch 4, gen_loss = 0.8089621123864497, disc_loss = 0.09095448227733266
Trained batch 278 in epoch 4, gen_loss = 0.808526269744374, disc_loss = 0.09096680719432117
Trained batch 279 in epoch 4, gen_loss = 0.8089468209871225, disc_loss = 0.09098857249066766
Trained batch 280 in epoch 4, gen_loss = 0.8087608081378123, disc_loss = 0.09093051193301895
Trained batch 281 in epoch 4, gen_loss = 0.8097052376532385, disc_loss = 0.09075441736239173
Trained batch 282 in epoch 4, gen_loss = 0.8092378250491071, disc_loss = 0.09081200172288784
Trained batch 283 in epoch 4, gen_loss = 0.8097515142929386, disc_loss = 0.09063093023518966
Trained batch 284 in epoch 4, gen_loss = 0.8094876384525969, disc_loss = 0.09053380257008892
Trained batch 285 in epoch 4, gen_loss = 0.8092624573232411, disc_loss = 0.09043544341022006
Trained batch 286 in epoch 4, gen_loss = 0.8097957641613193, disc_loss = 0.09023412273229726
Trained batch 287 in epoch 4, gen_loss = 0.809956879975895, disc_loss = 0.090002911388486
Trained batch 288 in epoch 4, gen_loss = 0.8100702080965867, disc_loss = 0.0899267769918155
Trained batch 289 in epoch 4, gen_loss = 0.8095100574452302, disc_loss = 0.0900216628668894
Trained batch 290 in epoch 4, gen_loss = 0.8106891374612591, disc_loss = 0.09017523461664767
Trained batch 291 in epoch 4, gen_loss = 0.8104232932402663, disc_loss = 0.09008495700035295
Trained batch 292 in epoch 4, gen_loss = 0.8097064907030034, disc_loss = 0.09010242484192088
Trained batch 293 in epoch 4, gen_loss = 0.8103561215862936, disc_loss = 0.09026718757045614
Trained batch 294 in epoch 4, gen_loss = 0.8103464792340489, disc_loss = 0.0901474013829888
Trained batch 295 in epoch 4, gen_loss = 0.8105976163736872, disc_loss = 0.0899426389542232
Trained batch 296 in epoch 4, gen_loss = 0.8096507744556324, disc_loss = 0.09026205049583105
Trained batch 297 in epoch 4, gen_loss = 0.8104351247917085, disc_loss = 0.09058253213625726
Trained batch 298 in epoch 4, gen_loss = 0.8100856824662773, disc_loss = 0.09046162511954041
Trained batch 299 in epoch 4, gen_loss = 0.8095579366882643, disc_loss = 0.09049286881151299
Trained batch 300 in epoch 4, gen_loss = 0.8099356649127909, disc_loss = 0.09048716099221148
Trained batch 301 in epoch 4, gen_loss = 0.8117582017420143, disc_loss = 0.09076910415688987
Trained batch 302 in epoch 4, gen_loss = 0.8109069467574457, disc_loss = 0.09148410950224883
Trained batch 303 in epoch 4, gen_loss = 0.8109465785520641, disc_loss = 0.09126542736224733
Trained batch 304 in epoch 4, gen_loss = 0.8107209509513417, disc_loss = 0.09116338698773599
Trained batch 305 in epoch 4, gen_loss = 0.8115192487154131, disc_loss = 0.09102002467680113
Trained batch 306 in epoch 4, gen_loss = 0.8118750345240975, disc_loss = 0.09088296984119117
Trained batch 307 in epoch 4, gen_loss = 0.8108499512656943, disc_loss = 0.09146825422218384
Trained batch 308 in epoch 4, gen_loss = 0.8111061677577812, disc_loss = 0.0914927907137375
Trained batch 309 in epoch 4, gen_loss = 0.81021750723162, disc_loss = 0.09168355748237621
Trained batch 310 in epoch 4, gen_loss = 0.8105602580634728, disc_loss = 0.09155595469980282
Trained batch 311 in epoch 4, gen_loss = 0.811100328197846, disc_loss = 0.0915256798094234
Trained batch 312 in epoch 4, gen_loss = 0.8108881350142506, disc_loss = 0.09154460824038178
Trained batch 313 in epoch 4, gen_loss = 0.8103440164760419, disc_loss = 0.09173178587073258
Trained batch 314 in epoch 4, gen_loss = 0.8106531843306526, disc_loss = 0.09168836157177648
Trained batch 315 in epoch 4, gen_loss = 0.8110038243894335, disc_loss = 0.09173091097522669
Trained batch 316 in epoch 4, gen_loss = 0.8112179527899445, disc_loss = 0.09151112424850182
Trained batch 317 in epoch 4, gen_loss = 0.8110357517341398, disc_loss = 0.09137225842525093
Trained batch 318 in epoch 4, gen_loss = 0.8103437268621869, disc_loss = 0.09133503168272468
Trained batch 319 in epoch 4, gen_loss = 0.8104434667155147, disc_loss = 0.0914276748924749
Trained batch 320 in epoch 4, gen_loss = 0.8105637353157329, disc_loss = 0.09128325981758187
Trained batch 321 in epoch 4, gen_loss = 0.8111205180609449, disc_loss = 0.09114878850566767
Trained batch 322 in epoch 4, gen_loss = 0.8108811286211752, disc_loss = 0.09101269454421367
Trained batch 323 in epoch 4, gen_loss = 0.8102261361516552, disc_loss = 0.09099147540379178
Trained batch 324 in epoch 4, gen_loss = 0.8103684704120343, disc_loss = 0.090894792610063
Trained batch 325 in epoch 4, gen_loss = 0.8112615558998716, disc_loss = 0.09105279907138526
Trained batch 326 in epoch 4, gen_loss = 0.81055431300347, disc_loss = 0.09107102825383254
Trained batch 327 in epoch 4, gen_loss = 0.8102264535136339, disc_loss = 0.09123549558415373
Trained batch 328 in epoch 4, gen_loss = 0.8104660373328305, disc_loss = 0.09115424521527844
Trained batch 329 in epoch 4, gen_loss = 0.8097443262736003, disc_loss = 0.09104322007941928
Trained batch 330 in epoch 4, gen_loss = 0.8092532654903446, disc_loss = 0.09094105086083949
Trained batch 331 in epoch 4, gen_loss = 0.8098500004733902, disc_loss = 0.09090462680737746
Trained batch 332 in epoch 4, gen_loss = 0.8108558339757604, disc_loss = 0.0911340764430058
Trained batch 333 in epoch 4, gen_loss = 0.8102421321554812, disc_loss = 0.09135727440759897
Trained batch 334 in epoch 4, gen_loss = 0.809632749343986, disc_loss = 0.09139457909084522
Trained batch 335 in epoch 4, gen_loss = 0.8099916868266606, disc_loss = 0.09129448149940886
Trained batch 336 in epoch 4, gen_loss = 0.811170038908101, disc_loss = 0.0914395830403317
Trained batch 337 in epoch 4, gen_loss = 0.810335168119013, disc_loss = 0.09173269674854254
Trained batch 338 in epoch 4, gen_loss = 0.8100882640278797, disc_loss = 0.09154751994386096
Trained batch 339 in epoch 4, gen_loss = 0.8102607409743702, disc_loss = 0.0914027750136002
Trained batch 340 in epoch 4, gen_loss = 0.810810543749689, disc_loss = 0.09127460398009359
Trained batch 341 in epoch 4, gen_loss = 0.810554709176571, disc_loss = 0.09127816838642572
Trained batch 342 in epoch 4, gen_loss = 0.8111428677514413, disc_loss = 0.091143208865413
Trained batch 343 in epoch 4, gen_loss = 0.8120236038122066, disc_loss = 0.09097543841520281
Trained batch 344 in epoch 4, gen_loss = 0.8114693810974343, disc_loss = 0.09101494388465864
Trained batch 345 in epoch 4, gen_loss = 0.8115601615409631, disc_loss = 0.09091335173017975
Trained batch 346 in epoch 4, gen_loss = 0.8113879903249164, disc_loss = 0.09075589849202965
Trained batch 347 in epoch 4, gen_loss = 0.8118034976309744, disc_loss = 0.09087781695616913
Trained batch 348 in epoch 4, gen_loss = 0.8113306482405239, disc_loss = 0.09081222492411604
Trained batch 349 in epoch 4, gen_loss = 0.8110143986770085, disc_loss = 0.09081727117033941
Trained batch 350 in epoch 4, gen_loss = 0.8115191170972297, disc_loss = 0.09068292151987978
Trained batch 351 in epoch 4, gen_loss = 0.8113220069896091, disc_loss = 0.09089440371661278
Trained batch 352 in epoch 4, gen_loss = 0.8113195403101762, disc_loss = 0.09081835126393493
Trained batch 353 in epoch 4, gen_loss = 0.8113758112751158, disc_loss = 0.09100701388150538
Trained batch 354 in epoch 4, gen_loss = 0.8118809025052568, disc_loss = 0.0912198411930405
Trained batch 355 in epoch 4, gen_loss = 0.8116646735520845, disc_loss = 0.091327316951781
Trained batch 356 in epoch 4, gen_loss = 0.811459289211519, disc_loss = 0.09134894667626345
Trained batch 357 in epoch 4, gen_loss = 0.8114988893769973, disc_loss = 0.0915866120375027
Trained batch 358 in epoch 4, gen_loss = 0.8117387630149182, disc_loss = 0.09161314446852649
Trained batch 359 in epoch 4, gen_loss = 0.8112738693753878, disc_loss = 0.09159798866086122
Trained batch 360 in epoch 4, gen_loss = 0.8107062857236889, disc_loss = 0.09157320122051354
Trained batch 361 in epoch 4, gen_loss = 0.8113708333086572, disc_loss = 0.09151204642248005
Trained batch 362 in epoch 4, gen_loss = 0.8113513762957465, disc_loss = 0.09135487682594001
Trained batch 363 in epoch 4, gen_loss = 0.8114682740562564, disc_loss = 0.0912114505702118
Trained batch 364 in epoch 4, gen_loss = 0.8112753675408559, disc_loss = 0.09109615925189159
Trained batch 365 in epoch 4, gen_loss = 0.811133812034065, disc_loss = 0.09113497568721898
Trained batch 366 in epoch 4, gen_loss = 0.8110976881811989, disc_loss = 0.0911055381513868
Trained batch 367 in epoch 4, gen_loss = 0.8107124017956464, disc_loss = 0.09097636029195122
Trained batch 368 in epoch 4, gen_loss = 0.8103240374627152, disc_loss = 0.0908677153930391
Trained batch 369 in epoch 4, gen_loss = 0.8100017304356034, disc_loss = 0.09083202692453524
Trained batch 370 in epoch 4, gen_loss = 0.8097083425586115, disc_loss = 0.09076010943654012
Trained batch 371 in epoch 4, gen_loss = 0.8102799408858822, disc_loss = 0.09063742944460002
Trained batch 372 in epoch 4, gen_loss = 0.8105035847697117, disc_loss = 0.09044259252031671
Trained batch 373 in epoch 4, gen_loss = 0.8105566850639282, disc_loss = 0.09027280619387879
Trained batch 374 in epoch 4, gen_loss = 0.8105262053807577, disc_loss = 0.0901855738038818
Trained batch 375 in epoch 4, gen_loss = 0.8109939217250398, disc_loss = 0.09006649730083077
Trained batch 376 in epoch 4, gen_loss = 0.8110393186146764, disc_loss = 0.08989618820155568
Trained batch 377 in epoch 4, gen_loss = 0.8115313792670215, disc_loss = 0.08978315851547652
Trained batch 378 in epoch 4, gen_loss = 0.8121623211297008, disc_loss = 0.08963193186856118
Trained batch 379 in epoch 4, gen_loss = 0.811517827918655, disc_loss = 0.08977225754949215
Trained batch 380 in epoch 4, gen_loss = 0.8118104623371535, disc_loss = 0.0896190155145964
Trained batch 381 in epoch 4, gen_loss = 0.8119853610143611, disc_loss = 0.0895114265533447
Trained batch 382 in epoch 4, gen_loss = 0.8122362234573762, disc_loss = 0.08938657100173808
Trained batch 383 in epoch 4, gen_loss = 0.8118907863584658, disc_loss = 0.08937263297411846
Trained batch 384 in epoch 4, gen_loss = 0.8121317567763391, disc_loss = 0.08918332207173883
Trained batch 385 in epoch 4, gen_loss = 0.8120837063369356, disc_loss = 0.08903100171941936
Trained batch 386 in epoch 4, gen_loss = 0.8117416909190728, disc_loss = 0.08895112943982354
Trained batch 387 in epoch 4, gen_loss = 0.8125582626185466, disc_loss = 0.08926377407294343
Trained batch 388 in epoch 4, gen_loss = 0.8122085741982056, disc_loss = 0.08919881774797307
Trained batch 389 in epoch 4, gen_loss = 0.8118142205935258, disc_loss = 0.08928120415418958
Trained batch 390 in epoch 4, gen_loss = 0.8113726022298379, disc_loss = 0.08922772117368781
Trained batch 391 in epoch 4, gen_loss = 0.812436650146027, disc_loss = 0.08977787801283127
Trained batch 392 in epoch 4, gen_loss = 0.8121548149421924, disc_loss = 0.0898249280157928
Trained batch 393 in epoch 4, gen_loss = 0.8119951134103204, disc_loss = 0.08973849391054153
Trained batch 394 in epoch 4, gen_loss = 0.8115897068494483, disc_loss = 0.08970685850451642
Trained batch 395 in epoch 4, gen_loss = 0.8117077812702969, disc_loss = 0.09006229126026308
Trained batch 396 in epoch 4, gen_loss = 0.8118761967051239, disc_loss = 0.08995385146383149
Trained batch 397 in epoch 4, gen_loss = 0.8112381558921469, disc_loss = 0.09009178478186529
Trained batch 398 in epoch 4, gen_loss = 0.8113506986085036, disc_loss = 0.089993139847945
Trained batch 399 in epoch 4, gen_loss = 0.8115294520556927, disc_loss = 0.0900208614510484
Trained batch 400 in epoch 4, gen_loss = 0.8111613134196274, disc_loss = 0.08993971148306072
Trained batch 401 in epoch 4, gen_loss = 0.8108129662957357, disc_loss = 0.08987290554202686
Trained batch 402 in epoch 4, gen_loss = 0.8105231604860084, disc_loss = 0.0898844221579119
Trained batch 403 in epoch 4, gen_loss = 0.8102259987061566, disc_loss = 0.08983505529462185
Trained batch 404 in epoch 4, gen_loss = 0.810787057582243, disc_loss = 0.08974654723510699
Trained batch 405 in epoch 4, gen_loss = 0.8108816093999177, disc_loss = 0.08970730228055948
Trained batch 406 in epoch 4, gen_loss = 0.8105016236516123, disc_loss = 0.08979479475427392
Trained batch 407 in epoch 4, gen_loss = 0.811056374773091, disc_loss = 0.09002588683164076
Trained batch 408 in epoch 4, gen_loss = 0.8109783664309308, disc_loss = 0.08996417760748808
Trained batch 409 in epoch 4, gen_loss = 0.8108912985499312, disc_loss = 0.08993314598437126
Trained batch 410 in epoch 4, gen_loss = 0.811013426368834, disc_loss = 0.08983495009614385
Trained batch 411 in epoch 4, gen_loss = 0.8123329751989217, disc_loss = 0.08981059981030819
Trained batch 412 in epoch 4, gen_loss = 0.8119503131212968, disc_loss = 0.08976113128072197
Trained batch 413 in epoch 4, gen_loss = 0.8119109470199272, disc_loss = 0.0896066521735331
Trained batch 414 in epoch 4, gen_loss = 0.812299901462463, disc_loss = 0.08944344611456954
Trained batch 415 in epoch 4, gen_loss = 0.8126264723161092, disc_loss = 0.08933893089908032
Trained batch 416 in epoch 4, gen_loss = 0.8128398419570008, disc_loss = 0.08924713248623718
Trained batch 417 in epoch 4, gen_loss = 0.8125156542045648, disc_loss = 0.08935971996795974
Trained batch 418 in epoch 4, gen_loss = 0.8129645448026908, disc_loss = 0.0892031697805322
Trained batch 419 in epoch 4, gen_loss = 0.8130531636022386, disc_loss = 0.08909556298250598
Trained batch 420 in epoch 4, gen_loss = 0.8132331490233505, disc_loss = 0.0889657932198706
Trained batch 421 in epoch 4, gen_loss = 0.8129623230034706, disc_loss = 0.08893476101079893
Trained batch 422 in epoch 4, gen_loss = 0.8130717359254265, disc_loss = 0.08876927553436083
Trained batch 423 in epoch 4, gen_loss = 0.8132537424845515, disc_loss = 0.0886383747203135
Trained batch 424 in epoch 4, gen_loss = 0.8130595013674567, disc_loss = 0.08849941042197101
Trained batch 425 in epoch 4, gen_loss = 0.8135638849836, disc_loss = 0.08840308339934044
Trained batch 426 in epoch 4, gen_loss = 0.8135066737335794, disc_loss = 0.08828578589034793
Trained batch 427 in epoch 4, gen_loss = 0.8130409955699868, disc_loss = 0.08834946177960765
Trained batch 428 in epoch 4, gen_loss = 0.8135673851122112, disc_loss = 0.08823836561605021
Trained batch 429 in epoch 4, gen_loss = 0.8141399942165197, disc_loss = 0.08817708630677919
Trained batch 430 in epoch 4, gen_loss = 0.8138523559559249, disc_loss = 0.08811471733781066
Trained batch 431 in epoch 4, gen_loss = 0.8138319820993476, disc_loss = 0.08804074832436594
Trained batch 432 in epoch 4, gen_loss = 0.8140321552891103, disc_loss = 0.08790196575370658
Trained batch 433 in epoch 4, gen_loss = 0.8145030908595582, disc_loss = 0.08806488478195763
Trained batch 434 in epoch 4, gen_loss = 0.8144137926485346, disc_loss = 0.08795666498314032
Trained batch 435 in epoch 4, gen_loss = 0.8136401951586435, disc_loss = 0.08839636277877341
Trained batch 436 in epoch 4, gen_loss = 0.8138612946601972, disc_loss = 0.08848405916465434
Trained batch 437 in epoch 4, gen_loss = 0.8146922646864364, disc_loss = 0.08897705344466246
Trained batch 438 in epoch 4, gen_loss = 0.8143792756597653, disc_loss = 0.08917907388469284
Trained batch 439 in epoch 4, gen_loss = 0.8143671561371196, disc_loss = 0.08926048179538074
Trained batch 440 in epoch 4, gen_loss = 0.814671794573466, disc_loss = 0.08935243187603159
Trained batch 441 in epoch 4, gen_loss = 0.8149105439898116, disc_loss = 0.0895427116740714
Trained batch 442 in epoch 4, gen_loss = 0.8147467931829242, disc_loss = 0.08953541923213422
Trained batch 443 in epoch 4, gen_loss = 0.8146100064387193, disc_loss = 0.08943646765934925
Trained batch 444 in epoch 4, gen_loss = 0.8153014058477424, disc_loss = 0.08949707415624616
Trained batch 445 in epoch 4, gen_loss = 0.8151821915076987, disc_loss = 0.08940683979115077
Trained batch 446 in epoch 4, gen_loss = 0.8149209042523531, disc_loss = 0.08934660343207436
Trained batch 447 in epoch 4, gen_loss = 0.8152474807575345, disc_loss = 0.08921229212137405
Trained batch 448 in epoch 4, gen_loss = 0.8159036958934469, disc_loss = 0.08965369778372065
Trained batch 449 in epoch 4, gen_loss = 0.8151770471202002, disc_loss = 0.09018508882779214
Trained batch 450 in epoch 4, gen_loss = 0.8148133762659889, disc_loss = 0.09015083003855268
Trained batch 451 in epoch 4, gen_loss = 0.8153538880622493, disc_loss = 0.09050472438195309
Trained batch 452 in epoch 4, gen_loss = 0.8150226018549854, disc_loss = 0.09060200468059341
Trained batch 453 in epoch 4, gen_loss = 0.8140538538342531, disc_loss = 0.09088600270802952
Trained batch 454 in epoch 4, gen_loss = 0.8142845427596962, disc_loss = 0.09076218586824425
Trained batch 455 in epoch 4, gen_loss = 0.8144714140839744, disc_loss = 0.09081858296658059
Trained batch 456 in epoch 4, gen_loss = 0.8143243916185993, disc_loss = 0.09071761488515061
Trained batch 457 in epoch 4, gen_loss = 0.8141210228855433, disc_loss = 0.09065374810712241
Trained batch 458 in epoch 4, gen_loss = 0.8138441871973424, disc_loss = 0.09066500101433275
Trained batch 459 in epoch 4, gen_loss = 0.8140210625918015, disc_loss = 0.09049058088263416
Trained batch 460 in epoch 4, gen_loss = 0.8139343974130014, disc_loss = 0.09038504073901381
Trained batch 461 in epoch 4, gen_loss = 0.8136712873910928, disc_loss = 0.09032036152615885
Trained batch 462 in epoch 4, gen_loss = 0.8134692342183503, disc_loss = 0.09027739528759703
Trained batch 463 in epoch 4, gen_loss = 0.813898419383271, disc_loss = 0.09015576346127059
Trained batch 464 in epoch 4, gen_loss = 0.8144354121659392, disc_loss = 0.09003252755369871
Trained batch 465 in epoch 4, gen_loss = 0.81400465248992, disc_loss = 0.09005002333490826
Trained batch 466 in epoch 4, gen_loss = 0.8142048652728568, disc_loss = 0.0899060789029048
Trained batch 467 in epoch 4, gen_loss = 0.8148538313615017, disc_loss = 0.09016708656548499
Trained batch 468 in epoch 4, gen_loss = 0.8146091923276498, disc_loss = 0.09014272230115336
Trained batch 469 in epoch 4, gen_loss = 0.8138462612603573, disc_loss = 0.09044887896904603
Trained batch 470 in epoch 4, gen_loss = 0.8135295912085572, disc_loss = 0.0904326965763469
Trained batch 471 in epoch 4, gen_loss = 0.8137195992394018, disc_loss = 0.09064202447287675
Trained batch 472 in epoch 4, gen_loss = 0.8134781630674326, disc_loss = 0.09052147084047692
Trained batch 473 in epoch 4, gen_loss = 0.8128434065650787, disc_loss = 0.090665622753826
Trained batch 474 in epoch 4, gen_loss = 0.8124305473503314, disc_loss = 0.09065628316253424
Trained batch 475 in epoch 4, gen_loss = 0.8128356136569456, disc_loss = 0.09056930369384461
Trained batch 476 in epoch 4, gen_loss = 0.8125637875288038, disc_loss = 0.09053977568139883
Trained batch 477 in epoch 4, gen_loss = 0.8121118447645937, disc_loss = 0.0906471213867506
Trained batch 478 in epoch 4, gen_loss = 0.8121319042989257, disc_loss = 0.09077450686128564
Trained batch 479 in epoch 4, gen_loss = 0.8116278209413091, disc_loss = 0.09075727188222421
Trained batch 480 in epoch 4, gen_loss = 0.8115355531663756, disc_loss = 0.09074639287542963
Trained batch 481 in epoch 4, gen_loss = 0.8113624705194933, disc_loss = 0.09067510185314968
Trained batch 482 in epoch 4, gen_loss = 0.8121254120184027, disc_loss = 0.09072696086883113
Trained batch 483 in epoch 4, gen_loss = 0.8123906829263553, disc_loss = 0.09058405643075028
Trained batch 484 in epoch 4, gen_loss = 0.8117978392802563, disc_loss = 0.09068620763527056
Trained batch 485 in epoch 4, gen_loss = 0.8116702694338536, disc_loss = 0.09074153102083522
Trained batch 486 in epoch 4, gen_loss = 0.8115139118332637, disc_loss = 0.0906657682754696
Trained batch 487 in epoch 4, gen_loss = 0.8110407849193596, disc_loss = 0.09078376288487591
Trained batch 488 in epoch 4, gen_loss = 0.811293470774204, disc_loss = 0.09078631871751298
Trained batch 489 in epoch 4, gen_loss = 0.811019747050441, disc_loss = 0.09071365881673231
Trained batch 490 in epoch 4, gen_loss = 0.810293283275577, disc_loss = 0.09087850133150573
Trained batch 491 in epoch 4, gen_loss = 0.8104155019410257, disc_loss = 0.09078909677256475
Trained batch 492 in epoch 4, gen_loss = 0.8104272028374624, disc_loss = 0.0908507680044364
Trained batch 493 in epoch 4, gen_loss = 0.8100865193103489, disc_loss = 0.09079204933521778
Trained batch 494 in epoch 4, gen_loss = 0.8097685102862541, disc_loss = 0.09077493328074313
Trained batch 495 in epoch 4, gen_loss = 0.8099968609430136, disc_loss = 0.09067136374670232
Trained batch 496 in epoch 4, gen_loss = 0.8095519482130016, disc_loss = 0.09064281776255105
Trained batch 497 in epoch 4, gen_loss = 0.8095673573424059, disc_loss = 0.09070821978099435
Trained batch 498 in epoch 4, gen_loss = 0.8095545821892236, disc_loss = 0.09060864252241735
Trained batch 499 in epoch 4, gen_loss = 0.8091919532418251, disc_loss = 0.09054471816308797
Trained batch 500 in epoch 4, gen_loss = 0.8093876532332864, disc_loss = 0.09042210243976936
Trained batch 501 in epoch 4, gen_loss = 0.8096948102769623, disc_loss = 0.0902810591547583
Trained batch 502 in epoch 4, gen_loss = 0.8106847622878035, disc_loss = 0.0902760165982378
Trained batch 503 in epoch 4, gen_loss = 0.8101144366202846, disc_loss = 0.090285155861195
Trained batch 504 in epoch 4, gen_loss = 0.8100793909908521, disc_loss = 0.09014050603687468
Trained batch 505 in epoch 4, gen_loss = 0.8103594932513746, disc_loss = 0.09002161897873513
Trained batch 506 in epoch 4, gen_loss = 0.8101779045555484, disc_loss = 0.09001713969305716
Trained batch 507 in epoch 4, gen_loss = 0.8101575483135351, disc_loss = 0.08991803017840903
Trained batch 508 in epoch 4, gen_loss = 0.8099391328679555, disc_loss = 0.0899876743163511
Trained batch 509 in epoch 4, gen_loss = 0.8096941493889864, disc_loss = 0.09001600310096845
Trained batch 510 in epoch 4, gen_loss = 0.8099672446162267, disc_loss = 0.08999501880433286
Trained batch 511 in epoch 4, gen_loss = 0.81024338217685, disc_loss = 0.08991960084131279
Trained batch 512 in epoch 4, gen_loss = 0.809880310389963, disc_loss = 0.08994891552788298
Trained batch 513 in epoch 4, gen_loss = 0.8099299364864594, disc_loss = 0.08993775215079639
Trained batch 514 in epoch 4, gen_loss = 0.8097440633380297, disc_loss = 0.0899392180379878
Trained batch 515 in epoch 4, gen_loss = 0.8097523149940394, disc_loss = 0.08988943997979915
Trained batch 516 in epoch 4, gen_loss = 0.8093546290577496, disc_loss = 0.08997528282547193
Trained batch 517 in epoch 4, gen_loss = 0.8092769983307275, disc_loss = 0.08988903283274599
Trained batch 518 in epoch 4, gen_loss = 0.8101843207902302, disc_loss = 0.09054533834524295
Trained batch 519 in epoch 4, gen_loss = 0.8099904005917219, disc_loss = 0.09053211283977501
Trained batch 520 in epoch 4, gen_loss = 0.810004516492192, disc_loss = 0.0904818315098273
Trained batch 521 in epoch 4, gen_loss = 0.8098672901876128, disc_loss = 0.09078037793216406
Trained batch 522 in epoch 4, gen_loss = 0.809601264006777, disc_loss = 0.09083333935047255
Trained batch 523 in epoch 4, gen_loss = 0.8091678448192036, disc_loss = 0.09096402542857553
Trained batch 524 in epoch 4, gen_loss = 0.8091779594761984, disc_loss = 0.09140514934524184
Trained batch 525 in epoch 4, gen_loss = 0.8087068070363636, disc_loss = 0.09154926627314873
Trained batch 526 in epoch 4, gen_loss = 0.8084020213678168, disc_loss = 0.09153254032028976
Trained batch 527 in epoch 4, gen_loss = 0.8090330129207084, disc_loss = 0.09172558300655731
Trained batch 528 in epoch 4, gen_loss = 0.8089862232059521, disc_loss = 0.09178981147107927
Trained batch 529 in epoch 4, gen_loss = 0.8085544452914651, disc_loss = 0.091999893946538
Trained batch 530 in epoch 4, gen_loss = 0.808820088199303, disc_loss = 0.0920010748461394
Trained batch 531 in epoch 4, gen_loss = 0.8086593214394455, disc_loss = 0.09199916627573171
Trained batch 532 in epoch 4, gen_loss = 0.8087037064232925, disc_loss = 0.09194007871137831
Trained batch 533 in epoch 4, gen_loss = 0.8086014747731248, disc_loss = 0.0918870346449762
Trained batch 534 in epoch 4, gen_loss = 0.8083391691479728, disc_loss = 0.09181924383112482
Trained batch 535 in epoch 4, gen_loss = 0.8083839923032184, disc_loss = 0.09173488023572726
Trained batch 536 in epoch 4, gen_loss = 0.8083563631806294, disc_loss = 0.09162371556553817
Trained batch 537 in epoch 4, gen_loss = 0.808513832745942, disc_loss = 0.09164322370690983
Trained batch 538 in epoch 4, gen_loss = 0.8080918850283897, disc_loss = 0.0916600156392287
Trained batch 539 in epoch 4, gen_loss = 0.8079419310998034, disc_loss = 0.09168844119024773
Trained batch 540 in epoch 4, gen_loss = 0.8079413533100579, disc_loss = 0.09161282817070508
Trained batch 541 in epoch 4, gen_loss = 0.8076737901931319, disc_loss = 0.09155623238994241
Trained batch 542 in epoch 4, gen_loss = 0.807921463887775, disc_loss = 0.09140811009335968
Trained batch 543 in epoch 4, gen_loss = 0.8078006591976565, disc_loss = 0.091391149601858
Trained batch 544 in epoch 4, gen_loss = 0.8077600241254229, disc_loss = 0.0913613399593245
Trained batch 545 in epoch 4, gen_loss = 0.807933951526771, disc_loss = 0.09163531962093034
Trained batch 546 in epoch 4, gen_loss = 0.8074411811405824, disc_loss = 0.09174858189785556
Trained batch 547 in epoch 4, gen_loss = 0.8072500812420009, disc_loss = 0.09171190554187734
Trained batch 548 in epoch 4, gen_loss = 0.8076271012506849, disc_loss = 0.09175903402533525
Trained batch 549 in epoch 4, gen_loss = 0.8074633365869522, disc_loss = 0.09170195730741729
Trained batch 550 in epoch 4, gen_loss = 0.8074197509003205, disc_loss = 0.09160467585592705
Trained batch 551 in epoch 4, gen_loss = 0.8075786587660727, disc_loss = 0.09171853323325353
Trained batch 552 in epoch 4, gen_loss = 0.8074142180019434, disc_loss = 0.09166724599433042
Trained batch 553 in epoch 4, gen_loss = 0.8075031480526665, disc_loss = 0.0916218953930003
Trained batch 554 in epoch 4, gen_loss = 0.8072492972687558, disc_loss = 0.09168200478930999
Trained batch 555 in epoch 4, gen_loss = 0.8070592469127058, disc_loss = 0.09165997812088927
Trained batch 556 in epoch 4, gen_loss = 0.8078042526112424, disc_loss = 0.0917358685843312
Trained batch 557 in epoch 4, gen_loss = 0.8078604103950616, disc_loss = 0.09161646150579963
Trained batch 558 in epoch 4, gen_loss = 0.8077735334154958, disc_loss = 0.091561165964814
Trained batch 559 in epoch 4, gen_loss = 0.8080412477787052, disc_loss = 0.09146783312483292
Trained batch 560 in epoch 4, gen_loss = 0.8075867660224119, disc_loss = 0.09147165479792578
Trained batch 561 in epoch 4, gen_loss = 0.8077009901987701, disc_loss = 0.09135627422607719
Trained batch 562 in epoch 4, gen_loss = 0.8079995013786675, disc_loss = 0.0914661773095043
Trained batch 563 in epoch 4, gen_loss = 0.8077116947330482, disc_loss = 0.0915257076267153
Trained batch 564 in epoch 4, gen_loss = 0.807312486076777, disc_loss = 0.09147028091108113
Trained batch 565 in epoch 4, gen_loss = 0.8078327154207566, disc_loss = 0.09184224362725346
Trained batch 566 in epoch 4, gen_loss = 0.8075323114845068, disc_loss = 0.09186609960744253
Trained batch 567 in epoch 4, gen_loss = 0.807818028236359, disc_loss = 0.09186160316671127
Trained batch 568 in epoch 4, gen_loss = 0.8079743374315842, disc_loss = 0.09180856940806278
Trained batch 569 in epoch 4, gen_loss = 0.8075472293715728, disc_loss = 0.09199837598655569
Trained batch 570 in epoch 4, gen_loss = 0.8075799231667026, disc_loss = 0.09190315590933253
Trained batch 571 in epoch 4, gen_loss = 0.8078840625557032, disc_loss = 0.0919650016577224
Trained batch 572 in epoch 4, gen_loss = 0.8079662308955068, disc_loss = 0.09188199019381357
Trained batch 573 in epoch 4, gen_loss = 0.807750738923558, disc_loss = 0.09181211458661882
Trained batch 574 in epoch 4, gen_loss = 0.8077773664826933, disc_loss = 0.09179414530973072
Trained batch 575 in epoch 4, gen_loss = 0.8074912421094874, disc_loss = 0.09174786854257239
Trained batch 576 in epoch 4, gen_loss = 0.8077735322910123, disc_loss = 0.09168943802969759
Trained batch 577 in epoch 4, gen_loss = 0.8073118091351433, disc_loss = 0.09175943185101589
Trained batch 578 in epoch 4, gen_loss = 0.8076546761964887, disc_loss = 0.09186178954263477
Trained batch 579 in epoch 4, gen_loss = 0.8078667121200725, disc_loss = 0.09175049281871782
Trained batch 580 in epoch 4, gen_loss = 0.8078031130070941, disc_loss = 0.09165412365345095
Trained batch 581 in epoch 4, gen_loss = 0.8076923653944251, disc_loss = 0.09165339225173458
Trained batch 582 in epoch 4, gen_loss = 0.8084454404040021, disc_loss = 0.0916316572075157
Trained batch 583 in epoch 4, gen_loss = 0.8082180084941322, disc_loss = 0.09164261557193702
Trained batch 584 in epoch 4, gen_loss = 0.808280216373949, disc_loss = 0.0916868805582834
Trained batch 585 in epoch 4, gen_loss = 0.8078143267603051, disc_loss = 0.09178758300236925
Trained batch 586 in epoch 4, gen_loss = 0.8075298728386425, disc_loss = 0.0917541143996879
Trained batch 587 in epoch 4, gen_loss = 0.8074304802583999, disc_loss = 0.0917773150417599
Trained batch 588 in epoch 4, gen_loss = 0.8074280750670538, disc_loss = 0.09171901932476383
Trained batch 589 in epoch 4, gen_loss = 0.807697128289837, disc_loss = 0.0916961032407895
Trained batch 590 in epoch 4, gen_loss = 0.8076675878664362, disc_loss = 0.09157670152022199
Trained batch 591 in epoch 4, gen_loss = 0.8073430279320156, disc_loss = 0.09163259634452343
Trained batch 592 in epoch 4, gen_loss = 0.8071523435903842, disc_loss = 0.09159542134103897
Trained batch 593 in epoch 4, gen_loss = 0.8073565669433035, disc_loss = 0.0916005111368442
Trained batch 594 in epoch 4, gen_loss = 0.8076966135942636, disc_loss = 0.09148873749243862
Trained batch 595 in epoch 4, gen_loss = 0.8076843952872609, disc_loss = 0.09138605540037005
Trained batch 596 in epoch 4, gen_loss = 0.8073640689877809, disc_loss = 0.0914549995198147
Trained batch 597 in epoch 4, gen_loss = 0.807521335207499, disc_loss = 0.0913631425295212
Trained batch 598 in epoch 4, gen_loss = 0.8079925257594438, disc_loss = 0.09142631005172389
Trained batch 599 in epoch 4, gen_loss = 0.8080164952576161, disc_loss = 0.09135372482395421
Trained batch 600 in epoch 4, gen_loss = 0.8079107886245366, disc_loss = 0.09128873910717727
Trained batch 601 in epoch 4, gen_loss = 0.8081538862861272, disc_loss = 0.09152871281360322
Trained batch 602 in epoch 4, gen_loss = 0.8077993062301655, disc_loss = 0.09159345549390734
Trained batch 603 in epoch 4, gen_loss = 0.8076779032681162, disc_loss = 0.09155038100457596
Trained batch 604 in epoch 4, gen_loss = 0.8076833758965012, disc_loss = 0.09166769052986518
Trained batch 605 in epoch 4, gen_loss = 0.8072319731558903, disc_loss = 0.09171832099759786
Trained batch 606 in epoch 4, gen_loss = 0.8074688423897525, disc_loss = 0.09187444264017033
Trained batch 607 in epoch 4, gen_loss = 0.8074458117449754, disc_loss = 0.09181776095187831
Trained batch 608 in epoch 4, gen_loss = 0.8071445370053227, disc_loss = 0.09182380620781669
Trained batch 609 in epoch 4, gen_loss = 0.8069873875770412, disc_loss = 0.09179150671163788
Trained batch 610 in epoch 4, gen_loss = 0.8069073392502024, disc_loss = 0.09183480085899562
Trained batch 611 in epoch 4, gen_loss = 0.807098336615204, disc_loss = 0.09182919973501437
Trained batch 612 in epoch 4, gen_loss = 0.8071457287129531, disc_loss = 0.09179617781921322
Trained batch 613 in epoch 4, gen_loss = 0.8067927030961755, disc_loss = 0.09192459691916546
Trained batch 614 in epoch 4, gen_loss = 0.8069703077397695, disc_loss = 0.09188847598899913
Trained batch 615 in epoch 4, gen_loss = 0.8072388766744694, disc_loss = 0.09178131373822931
Trained batch 616 in epoch 4, gen_loss = 0.80721220267843, disc_loss = 0.09166607142213243
Trained batch 617 in epoch 4, gen_loss = 0.8072738028749293, disc_loss = 0.09159504331521762
Trained batch 618 in epoch 4, gen_loss = 0.8075091379043167, disc_loss = 0.09146936324625148
Trained batch 619 in epoch 4, gen_loss = 0.8074776261564224, disc_loss = 0.09140212643561103
Trained batch 620 in epoch 4, gen_loss = 0.8071643498496733, disc_loss = 0.09135268051057287
Trained batch 621 in epoch 4, gen_loss = 0.8076422291649116, disc_loss = 0.09147957384951676
Trained batch 622 in epoch 4, gen_loss = 0.8073752045535735, disc_loss = 0.09145932586753014
Trained batch 623 in epoch 4, gen_loss = 0.8071016052690072, disc_loss = 0.09143530048029976
Trained batch 624 in epoch 4, gen_loss = 0.8076705328464509, disc_loss = 0.0914522516682744
Trained batch 625 in epoch 4, gen_loss = 0.8075919320312933, disc_loss = 0.09143881903985104
Trained batch 626 in epoch 4, gen_loss = 0.8071894605289045, disc_loss = 0.09148647887647104
Trained batch 627 in epoch 4, gen_loss = 0.8071756373829903, disc_loss = 0.09142415133708269
Trained batch 628 in epoch 4, gen_loss = 0.8078322125826807, disc_loss = 0.09161534188359692
Trained batch 629 in epoch 4, gen_loss = 0.8077717004787355, disc_loss = 0.09159270991674728
Trained batch 630 in epoch 4, gen_loss = 0.807478922057643, disc_loss = 0.09157992505782805
Trained batch 631 in epoch 4, gen_loss = 0.8071566576350339, disc_loss = 0.09163159762267495
Trained batch 632 in epoch 4, gen_loss = 0.8074212092641405, disc_loss = 0.09171321776976565
Trained batch 633 in epoch 4, gen_loss = 0.8076300497404785, disc_loss = 0.09166756149657564
Trained batch 634 in epoch 4, gen_loss = 0.8073108238967385, disc_loss = 0.09177654870881105
Trained batch 635 in epoch 4, gen_loss = 0.8073186452190081, disc_loss = 0.09165796271009874
Trained batch 636 in epoch 4, gen_loss = 0.8071723696856147, disc_loss = 0.09165629063947843
Trained batch 637 in epoch 4, gen_loss = 0.8074660355861658, disc_loss = 0.09180146012145757
Trained batch 638 in epoch 4, gen_loss = 0.8074352850843111, disc_loss = 0.09171726173504091
Trained batch 639 in epoch 4, gen_loss = 0.8070083085913211, disc_loss = 0.09182088414818282
Trained batch 640 in epoch 4, gen_loss = 0.8074745392185664, disc_loss = 0.09192103749742607
Trained batch 641 in epoch 4, gen_loss = 0.8072859977728852, disc_loss = 0.09191808615291834
Trained batch 642 in epoch 4, gen_loss = 0.8069187596926979, disc_loss = 0.09206454386474046
Trained batch 643 in epoch 4, gen_loss = 0.8069578422615247, disc_loss = 0.09209459448690231
Trained batch 644 in epoch 4, gen_loss = 0.8074904233448266, disc_loss = 0.0923355307704372
Trained batch 645 in epoch 4, gen_loss = 0.8075042243804725, disc_loss = 0.09231637968557768
Trained batch 646 in epoch 4, gen_loss = 0.8072881173037304, disc_loss = 0.09234139173675956
Trained batch 647 in epoch 4, gen_loss = 0.8075337683621012, disc_loss = 0.09228233061874584
Trained batch 648 in epoch 4, gen_loss = 0.8078562156720595, disc_loss = 0.09246230823560424
Trained batch 649 in epoch 4, gen_loss = 0.8074991568693748, disc_loss = 0.09257456376145666
Trained batch 650 in epoch 4, gen_loss = 0.8070731466541642, disc_loss = 0.09258228854151777
Trained batch 651 in epoch 4, gen_loss = 0.8072582911585737, disc_loss = 0.09277370777923866
Trained batch 652 in epoch 4, gen_loss = 0.8071558472299649, disc_loss = 0.09272349907219364
Trained batch 653 in epoch 4, gen_loss = 0.8072795792730576, disc_loss = 0.09262834680024591
Trained batch 654 in epoch 4, gen_loss = 0.8074395903649221, disc_loss = 0.09254494940591905
Trained batch 655 in epoch 4, gen_loss = 0.8074671816444252, disc_loss = 0.09251194087101328
Trained batch 656 in epoch 4, gen_loss = 0.8075911450331614, disc_loss = 0.09259322084787003
Trained batch 657 in epoch 4, gen_loss = 0.807684505375323, disc_loss = 0.09251185027474826
Trained batch 658 in epoch 4, gen_loss = 0.8074735456876942, disc_loss = 0.09255431473611293
Trained batch 659 in epoch 4, gen_loss = 0.8074138694188812, disc_loss = 0.09247364269033301
Trained batch 660 in epoch 4, gen_loss = 0.8075570588122698, disc_loss = 0.09241416859165759
Trained batch 661 in epoch 4, gen_loss = 0.8077154420203673, disc_loss = 0.09231873535131895
Trained batch 662 in epoch 4, gen_loss = 0.8077031443651266, disc_loss = 0.09226516320554155
Trained batch 663 in epoch 4, gen_loss = 0.8077366164919123, disc_loss = 0.0922074498067307
Trained batch 664 in epoch 4, gen_loss = 0.8082453578486478, disc_loss = 0.0922265809099365
Trained batch 665 in epoch 4, gen_loss = 0.8079887393627081, disc_loss = 0.09226158013365962
Trained batch 666 in epoch 4, gen_loss = 0.8079126976329883, disc_loss = 0.09217333636557994
Trained batch 667 in epoch 4, gen_loss = 0.8083046540439486, disc_loss = 0.09215325948469966
Trained batch 668 in epoch 4, gen_loss = 0.808177859482031, disc_loss = 0.09217226180499935
Trained batch 669 in epoch 4, gen_loss = 0.8078556712438811, disc_loss = 0.09216690547625297
Trained batch 670 in epoch 4, gen_loss = 0.8081180281415249, disc_loss = 0.09213824215277075
Trained batch 671 in epoch 4, gen_loss = 0.8079878071855221, disc_loss = 0.09212280958863198
Trained batch 672 in epoch 4, gen_loss = 0.8079906782193489, disc_loss = 0.0920337165898213
Trained batch 673 in epoch 4, gen_loss = 0.8075177771666637, disc_loss = 0.09210134448914703
Trained batch 674 in epoch 4, gen_loss = 0.8077639838942775, disc_loss = 0.09203607561273708
Trained batch 675 in epoch 4, gen_loss = 0.8081122590504455, disc_loss = 0.09208372105105873
Trained batch 676 in epoch 4, gen_loss = 0.8079326682376017, disc_loss = 0.09203493306096891
Trained batch 677 in epoch 4, gen_loss = 0.808399306769568, disc_loss = 0.09199616808999209
Trained batch 678 in epoch 4, gen_loss = 0.8079524336489732, disc_loss = 0.09219272188233302
Trained batch 679 in epoch 4, gen_loss = 0.8078663434614154, disc_loss = 0.0921103833393906
Trained batch 680 in epoch 4, gen_loss = 0.8080627709495863, disc_loss = 0.09223845187935667
Trained batch 681 in epoch 4, gen_loss = 0.8075651411524266, disc_loss = 0.09240899172057111
Trained batch 682 in epoch 4, gen_loss = 0.8078332390216224, disc_loss = 0.09238643884675177
Trained batch 683 in epoch 4, gen_loss = 0.8080195327512703, disc_loss = 0.09228111857858796
Trained batch 684 in epoch 4, gen_loss = 0.8078864126744931, disc_loss = 0.09225483129793492
Trained batch 685 in epoch 4, gen_loss = 0.807679816819836, disc_loss = 0.09235546101324543
Trained batch 686 in epoch 4, gen_loss = 0.8080701905653813, disc_loss = 0.09234713089382587
Trained batch 687 in epoch 4, gen_loss = 0.8079791454988163, disc_loss = 0.0922618203858715
Trained batch 688 in epoch 4, gen_loss = 0.8076324875970711, disc_loss = 0.09249877436992175
Trained batch 689 in epoch 4, gen_loss = 0.8080594381992368, disc_loss = 0.09244216666894331
Trained batch 690 in epoch 4, gen_loss = 0.8081550342387988, disc_loss = 0.09248303917847175
Trained batch 691 in epoch 4, gen_loss = 0.8080142129621753, disc_loss = 0.09244479460108788
Trained batch 692 in epoch 4, gen_loss = 0.8077382795824462, disc_loss = 0.09244733097765481
Trained batch 693 in epoch 4, gen_loss = 0.8076722902334389, disc_loss = 0.09244519214867815
Trained batch 694 in epoch 4, gen_loss = 0.808166283026016, disc_loss = 0.09269589040321198
Trained batch 695 in epoch 4, gen_loss = 0.8077540830548467, disc_loss = 0.09304317053080932
Trained batch 696 in epoch 4, gen_loss = 0.8077984238885225, disc_loss = 0.09318041263102758
Trained batch 697 in epoch 4, gen_loss = 0.8078468445805902, disc_loss = 0.09325404205148703
Trained batch 698 in epoch 4, gen_loss = 0.8076960117434909, disc_loss = 0.09354270425876962
Trained batch 699 in epoch 4, gen_loss = 0.8077268242410252, disc_loss = 0.09397573067008384
Trained batch 700 in epoch 4, gen_loss = 0.8074492806629856, disc_loss = 0.09400845116426831
Trained batch 701 in epoch 4, gen_loss = 0.8073980109049723, disc_loss = 0.09412528801990667
Trained batch 702 in epoch 4, gen_loss = 0.80716815141492, disc_loss = 0.09419366166626195
Trained batch 703 in epoch 4, gen_loss = 0.8068014156835323, disc_loss = 0.09429417153031946
Trained batch 704 in epoch 4, gen_loss = 0.8069424838461774, disc_loss = 0.0943705819851012
Trained batch 705 in epoch 4, gen_loss = 0.8067484152300162, disc_loss = 0.09437293380303652
Trained batch 706 in epoch 4, gen_loss = 0.8066956550515187, disc_loss = 0.09436849877106544
Trained batch 707 in epoch 4, gen_loss = 0.8064917809629845, disc_loss = 0.09433329613000617
Trained batch 708 in epoch 4, gen_loss = 0.8066629561870156, disc_loss = 0.09428610003649221
Trained batch 709 in epoch 4, gen_loss = 0.8068111463751592, disc_loss = 0.0941830248257119
Trained batch 710 in epoch 4, gen_loss = 0.807016729176799, disc_loss = 0.0940707853724119
Trained batch 711 in epoch 4, gen_loss = 0.8069038282703148, disc_loss = 0.09408462327627695
Trained batch 712 in epoch 4, gen_loss = 0.807055132628156, disc_loss = 0.09398553799054106
Trained batch 713 in epoch 4, gen_loss = 0.8070892410702398, disc_loss = 0.09390564738311061
Trained batch 714 in epoch 4, gen_loss = 0.8068093770450645, disc_loss = 0.09394981548111964
Trained batch 715 in epoch 4, gen_loss = 0.8067476228711992, disc_loss = 0.09390141742756622
Trained batch 716 in epoch 4, gen_loss = 0.8069884135716463, disc_loss = 0.093827170600421
Trained batch 717 in epoch 4, gen_loss = 0.8070892682065539, disc_loss = 0.09372258807524707
Trained batch 718 in epoch 4, gen_loss = 0.8068402211838538, disc_loss = 0.09368207265903994
Trained batch 719 in epoch 4, gen_loss = 0.806982592948609, disc_loss = 0.0935791138934696
Trained batch 720 in epoch 4, gen_loss = 0.8069919498634736, disc_loss = 0.09354682934913532
Trained batch 721 in epoch 4, gen_loss = 0.8069153577914859, disc_loss = 0.09351044318089236
Trained batch 722 in epoch 4, gen_loss = 0.8066418134242832, disc_loss = 0.09352476876950404
Trained batch 723 in epoch 4, gen_loss = 0.8069416415872495, disc_loss = 0.09349135757753245
Trained batch 724 in epoch 4, gen_loss = 0.806686223745346, disc_loss = 0.0934829452081487
Trained batch 725 in epoch 4, gen_loss = 0.8064909739517312, disc_loss = 0.09345466673974533
Trained batch 726 in epoch 4, gen_loss = 0.8065945868888944, disc_loss = 0.09335858246601063
Trained batch 727 in epoch 4, gen_loss = 0.8066428284478057, disc_loss = 0.09328342639395946
Trained batch 728 in epoch 4, gen_loss = 0.8069000476754088, disc_loss = 0.0932111047164873
Trained batch 729 in epoch 4, gen_loss = 0.806668978235493, disc_loss = 0.09323423509804965
Trained batch 730 in epoch 4, gen_loss = 0.8070141493295677, disc_loss = 0.09318186090838688
Trained batch 731 in epoch 4, gen_loss = 0.807196571079434, disc_loss = 0.09315773400813952
Trained batch 732 in epoch 4, gen_loss = 0.8067727126333594, disc_loss = 0.09330726840684513
Trained batch 733 in epoch 4, gen_loss = 0.8068858202374274, disc_loss = 0.09330416961930875
Trained batch 734 in epoch 4, gen_loss = 0.8071105189063922, disc_loss = 0.09319805549901156
Trained batch 735 in epoch 4, gen_loss = 0.807102995560221, disc_loss = 0.0931393288761762
Trained batch 736 in epoch 4, gen_loss = 0.8071141044029225, disc_loss = 0.09304441586566464
Trained batch 737 in epoch 4, gen_loss = 0.8073254600773013, disc_loss = 0.09295385650316187
Trained batch 738 in epoch 4, gen_loss = 0.8072851159091893, disc_loss = 0.09291048521233952
Trained batch 739 in epoch 4, gen_loss = 0.8071092415500332, disc_loss = 0.09286801830009633
Trained batch 740 in epoch 4, gen_loss = 0.8071848492712466, disc_loss = 0.09278674463285247
Trained batch 741 in epoch 4, gen_loss = 0.8074760792872334, disc_loss = 0.09272189839364021
Trained batch 742 in epoch 4, gen_loss = 0.807294621121033, disc_loss = 0.0927065817995215
Trained batch 743 in epoch 4, gen_loss = 0.8069528787527033, disc_loss = 0.09271172615724506
Trained batch 744 in epoch 4, gen_loss = 0.8072158652664031, disc_loss = 0.09261498715128474
Trained batch 745 in epoch 4, gen_loss = 0.8071025534066054, disc_loss = 0.09263476111049747
Trained batch 746 in epoch 4, gen_loss = 0.8071449493149039, disc_loss = 0.09254989657461284
Trained batch 747 in epoch 4, gen_loss = 0.8070708514056741, disc_loss = 0.09250870172337773
Trained batch 748 in epoch 4, gen_loss = 0.8072148205759687, disc_loss = 0.09241500158032007
Trained batch 749 in epoch 4, gen_loss = 0.8074312108357747, disc_loss = 0.09238186093543967
Trained batch 750 in epoch 4, gen_loss = 0.807377493175146, disc_loss = 0.09231282271985486
Trained batch 751 in epoch 4, gen_loss = 0.807516040637138, disc_loss = 0.09221716871252283
Trained batch 752 in epoch 4, gen_loss = 0.8075300011818469, disc_loss = 0.09224838222368345
Trained batch 753 in epoch 4, gen_loss = 0.807507362384695, disc_loss = 0.09218402240123966
Trained batch 754 in epoch 4, gen_loss = 0.8071753322683423, disc_loss = 0.09216791825208641
Trained batch 755 in epoch 4, gen_loss = 0.8073613460732516, disc_loss = 0.09212676160377524
Trained batch 756 in epoch 4, gen_loss = 0.8075689421462257, disc_loss = 0.09215135671213132
Trained batch 757 in epoch 4, gen_loss = 0.8073301401018782, disc_loss = 0.09213540891411476
Trained batch 758 in epoch 4, gen_loss = 0.8072795400663484, disc_loss = 0.09205987072416014
Trained batch 759 in epoch 4, gen_loss = 0.8073077184589286, disc_loss = 0.092030461844498
Trained batch 760 in epoch 4, gen_loss = 0.8073120873798365, disc_loss = 0.09196735633250801
Trained batch 761 in epoch 4, gen_loss = 0.8071689741817984, disc_loss = 0.09194334374075838
Trained batch 762 in epoch 4, gen_loss = 0.8070319231653276, disc_loss = 0.09195113243220245
Trained batch 763 in epoch 4, gen_loss = 0.8070303496577977, disc_loss = 0.09189899596970783
Trained batch 764 in epoch 4, gen_loss = 0.8069896692544027, disc_loss = 0.0918199042540068
Trained batch 765 in epoch 4, gen_loss = 0.8073344969095823, disc_loss = 0.09184508989188168
Trained batch 766 in epoch 4, gen_loss = 0.8074005999963006, disc_loss = 0.09194443242398553
Trained batch 767 in epoch 4, gen_loss = 0.8070377889865389, disc_loss = 0.09213962131010096
Trained batch 768 in epoch 4, gen_loss = 0.8067292784218361, disc_loss = 0.09218560343896498
Trained batch 769 in epoch 4, gen_loss = 0.8069637880696878, disc_loss = 0.09226438537264219
Trained batch 770 in epoch 4, gen_loss = 0.8069965693273433, disc_loss = 0.09222768221639976
Trained batch 771 in epoch 4, gen_loss = 0.8069027981146629, disc_loss = 0.09221041465655858
Trained batch 772 in epoch 4, gen_loss = 0.8069877181139523, disc_loss = 0.09219938734086064
Trained batch 773 in epoch 4, gen_loss = 0.8070882536490143, disc_loss = 0.0921892015569066
Trained batch 774 in epoch 4, gen_loss = 0.8070970066901176, disc_loss = 0.09211090488419417
Trained batch 775 in epoch 4, gen_loss = 0.8070437742262772, disc_loss = 0.09203091668104273
Trained batch 776 in epoch 4, gen_loss = 0.8075481886415715, disc_loss = 0.09201726640671722
Trained batch 777 in epoch 4, gen_loss = 0.807597014545475, disc_loss = 0.09193719971020033
Trained batch 778 in epoch 4, gen_loss = 0.8073682195874019, disc_loss = 0.09202530687084286
Trained batch 779 in epoch 4, gen_loss = 0.807199192352784, disc_loss = 0.09202833810510734
Trained batch 780 in epoch 4, gen_loss = 0.8076809815652239, disc_loss = 0.0920453390187647
Trained batch 781 in epoch 4, gen_loss = 0.8077594243047183, disc_loss = 0.09196504633373502
Trained batch 782 in epoch 4, gen_loss = 0.8077665093910344, disc_loss = 0.09193828052188131
Trained batch 783 in epoch 4, gen_loss = 0.8074003287724086, disc_loss = 0.09198554100739599
Trained batch 784 in epoch 4, gen_loss = 0.8072788340270899, disc_loss = 0.0920586863817398
Trained batch 785 in epoch 4, gen_loss = 0.8072194197705684, disc_loss = 0.09200731174944504
Trained batch 786 in epoch 4, gen_loss = 0.8069762321712102, disc_loss = 0.09203120908111788
Trained batch 787 in epoch 4, gen_loss = 0.8072403853919905, disc_loss = 0.0919629760419827
Trained batch 788 in epoch 4, gen_loss = 0.8070800447192029, disc_loss = 0.09197046929859427
Trained batch 789 in epoch 4, gen_loss = 0.8075729043423375, disc_loss = 0.09199035138575526
Testing Epoch 4
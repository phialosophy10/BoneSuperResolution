/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.7066061496734619, disc_loss = 0.6106678247451782
Trained batch 1 in epoch 0, gen_loss = 0.6818712651729584, disc_loss = 0.6495093107223511
Trained batch 2 in epoch 0, gen_loss = 0.6278145909309387, disc_loss = 0.6168660720189413
Trained batch 3 in epoch 0, gen_loss = 0.6506867408752441, disc_loss = 0.5953246355056763
Trained batch 4 in epoch 0, gen_loss = 0.649539566040039, disc_loss = 0.5547073125839234
Trained batch 5 in epoch 0, gen_loss = 0.6436578333377838, disc_loss = 0.4986800402402878
Trained batch 6 in epoch 0, gen_loss = 0.6315207055636815, disc_loss = 0.4508303829601833
Trained batch 7 in epoch 0, gen_loss = 0.6273048594594002, disc_loss = 0.4123959317803383
Trained batch 8 in epoch 0, gen_loss = 0.6202719344033135, disc_loss = 0.37797236608134377
Trained batch 9 in epoch 0, gen_loss = 0.6173336863517761, disc_loss = 0.349378776550293
Trained batch 10 in epoch 0, gen_loss = 0.6153729557991028, disc_loss = 0.3248214789412238
Trained batch 11 in epoch 0, gen_loss = 0.614407812555631, disc_loss = 0.3048202358186245
Trained batch 12 in epoch 0, gen_loss = 0.6129035353660583, disc_loss = 0.2875129053225884
Trained batch 13 in epoch 0, gen_loss = 0.6133869418076107, disc_loss = 0.2718147986701557
Trained batch 14 in epoch 0, gen_loss = 0.6146367867787679, disc_loss = 0.25903193056583407
Trained batch 15 in epoch 0, gen_loss = 0.6149627789855003, disc_loss = 0.24808479752391577
Trained batch 16 in epoch 0, gen_loss = 0.6133141096900491, disc_loss = 0.24057304596199708
Trained batch 17 in epoch 0, gen_loss = 0.614763425456153, disc_loss = 0.23594529181718826
Trained batch 18 in epoch 0, gen_loss = 0.6176949959052237, disc_loss = 0.23432736334047818
Trained batch 19 in epoch 0, gen_loss = 0.6095987066626549, disc_loss = 0.23872273564338684
Trained batch 20 in epoch 0, gen_loss = 0.6219007500580379, disc_loss = 0.25260589520136517
Trained batch 21 in epoch 0, gen_loss = 0.6221956272016872, disc_loss = 0.25209746780720627
Trained batch 22 in epoch 0, gen_loss = 0.61638819264329, disc_loss = 0.25639228652352875
Trained batch 23 in epoch 0, gen_loss = 0.6139416955411434, disc_loss = 0.25506688468158245
Trained batch 24 in epoch 0, gen_loss = 0.6160036623477936, disc_loss = 0.25058202505111693
Trained batch 25 in epoch 0, gen_loss = 0.6200303676036688, disc_loss = 0.2451810659124301
Trained batch 26 in epoch 0, gen_loss = 0.619002718616415, disc_loss = 0.23970872770856927
Trained batch 27 in epoch 0, gen_loss = 0.6168448850512505, disc_loss = 0.23435539486152784
Trained batch 28 in epoch 0, gen_loss = 0.617421325938455, disc_loss = 0.22867530944018527
Trained batch 29 in epoch 0, gen_loss = 0.618212432662646, disc_loss = 0.22327695737282435
Trained batch 30 in epoch 0, gen_loss = 0.618680618463024, disc_loss = 0.21835441719139775
Trained batch 31 in epoch 0, gen_loss = 0.6175212739035487, disc_loss = 0.21420932607725263
Trained batch 32 in epoch 0, gen_loss = 0.6182988764661731, disc_loss = 0.21073348504124265
Trained batch 33 in epoch 0, gen_loss = 0.6201567833914476, disc_loss = 0.20707413115922144
Trained batch 34 in epoch 0, gen_loss = 0.6217790339674268, disc_loss = 0.2030093178153038
Trained batch 35 in epoch 0, gen_loss = 0.6236880545814832, disc_loss = 0.1990597169432375
Trained batch 36 in epoch 0, gen_loss = 0.6270855496058593, disc_loss = 0.19535980685739904
Trained batch 37 in epoch 0, gen_loss = 0.6281516512757853, disc_loss = 0.19147378745439805
Trained batch 38 in epoch 0, gen_loss = 0.6276288941884652, disc_loss = 0.18805892440753105
Trained batch 39 in epoch 0, gen_loss = 0.6314348198473454, disc_loss = 0.1851457968354225
Trained batch 40 in epoch 0, gen_loss = 0.6332314065316829, disc_loss = 0.1821466563496648
Trained batch 41 in epoch 0, gen_loss = 0.6372745171898887, disc_loss = 0.17955895362510568
Trained batch 42 in epoch 0, gen_loss = 0.6385637057382006, disc_loss = 0.1774336800499018
Trained batch 43 in epoch 0, gen_loss = 0.6426245888525789, disc_loss = 0.17499801152470437
Trained batch 44 in epoch 0, gen_loss = 0.6452787246969011, disc_loss = 0.17226320033272108
Trained batch 45 in epoch 0, gen_loss = 0.6463678731866505, disc_loss = 0.1693233513151822
Trained batch 46 in epoch 0, gen_loss = 0.6474504033301739, disc_loss = 0.16664075938628076
Trained batch 47 in epoch 0, gen_loss = 0.6482653338462114, disc_loss = 0.16391100571490824
Trained batch 48 in epoch 0, gen_loss = 0.6487997131688255, disc_loss = 0.16145266060318267
Trained batch 49 in epoch 0, gen_loss = 0.6492984980344773, disc_loss = 0.1593240200728178
Trained batch 50 in epoch 0, gen_loss = 0.6514210438027102, disc_loss = 0.15727598534203044
Trained batch 51 in epoch 0, gen_loss = 0.6548882602499082, disc_loss = 0.156560063147201
Trained batch 52 in epoch 0, gen_loss = 0.6541595385884339, disc_loss = 0.15706244258666938
Trained batch 53 in epoch 0, gen_loss = 0.6564821584357156, disc_loss = 0.15735787325711162
Trained batch 54 in epoch 0, gen_loss = 0.6611512319608168, disc_loss = 0.1606324651701884
Trained batch 55 in epoch 0, gen_loss = 0.6637236098093646, disc_loss = 0.16127350693568587
Trained batch 56 in epoch 0, gen_loss = 0.666454428643511, disc_loss = 0.163085466740947
Trained batch 57 in epoch 0, gen_loss = 0.6697527010893, disc_loss = 0.16226945541285234
Trained batch 58 in epoch 0, gen_loss = 0.6729380998571041, disc_loss = 0.16121954451930726
Trained batch 59 in epoch 0, gen_loss = 0.674847457309564, disc_loss = 0.15932137655715148
Trained batch 60 in epoch 0, gen_loss = 0.6760527623481438, disc_loss = 0.15749722829119103
Trained batch 61 in epoch 0, gen_loss = 0.6777329584283214, disc_loss = 0.1556994689087714
Trained batch 62 in epoch 0, gen_loss = 0.6782976535577623, disc_loss = 0.1540103554134331
Trained batch 63 in epoch 0, gen_loss = 0.677637645509094, disc_loss = 0.1526731026242487
Trained batch 64 in epoch 0, gen_loss = 0.6798890384343954, disc_loss = 0.15113454833626747
Trained batch 65 in epoch 0, gen_loss = 0.6796455153010108, disc_loss = 0.1494532942659024
Trained batch 66 in epoch 0, gen_loss = 0.6802760536101327, disc_loss = 0.1476221553314088
Trained batch 67 in epoch 0, gen_loss = 0.6812614951940144, disc_loss = 0.1460766627398484
Trained batch 68 in epoch 0, gen_loss = 0.68149844157523, disc_loss = 0.14453905172969983
Trained batch 69 in epoch 0, gen_loss = 0.6823068537882396, disc_loss = 0.14289049234773432
Trained batch 70 in epoch 0, gen_loss = 0.6835348643887211, disc_loss = 0.14124970998562558
Trained batch 71 in epoch 0, gen_loss = 0.683147000355853, disc_loss = 0.13993682536400026
Trained batch 72 in epoch 0, gen_loss = 0.6823843231756394, disc_loss = 0.1394417958512698
Trained batch 73 in epoch 0, gen_loss = 0.6833466150470682, disc_loss = 0.1386678538008316
Trained batch 74 in epoch 0, gen_loss = 0.6824764923254649, disc_loss = 0.13741283868749937
Trained batch 75 in epoch 0, gen_loss = 0.6826192654277149, disc_loss = 0.13618907249091486
Trained batch 76 in epoch 0, gen_loss = 0.6842700215903196, disc_loss = 0.13480695332219075
Trained batch 77 in epoch 0, gen_loss = 0.6853048744109961, disc_loss = 0.13352529174433306
Trained batch 78 in epoch 0, gen_loss = 0.6855661374858663, disc_loss = 0.13233196839124342
Trained batch 79 in epoch 0, gen_loss = 0.6859433922916651, disc_loss = 0.13111023656092585
Trained batch 80 in epoch 0, gen_loss = 0.6861201381241834, disc_loss = 0.12981280482109683
Trained batch 81 in epoch 0, gen_loss = 0.6863259836667921, disc_loss = 0.12866238168463473
Trained batch 82 in epoch 0, gen_loss = 0.6872908340161106, disc_loss = 0.12758198524095926
Trained batch 83 in epoch 0, gen_loss = 0.6877791459361712, disc_loss = 0.12685046912658782
Trained batch 84 in epoch 0, gen_loss = 0.6898631604278789, disc_loss = 0.12630637726363014
Trained batch 85 in epoch 0, gen_loss = 0.6893574155347292, disc_loss = 0.12575448443030202
Trained batch 86 in epoch 0, gen_loss = 0.6908276015999674, disc_loss = 0.12468960221814013
Trained batch 87 in epoch 0, gen_loss = 0.6916995851153677, disc_loss = 0.12368510858240453
Trained batch 88 in epoch 0, gen_loss = 0.6921851236498757, disc_loss = 0.12263110650473097
Trained batch 89 in epoch 0, gen_loss = 0.6925417181518343, disc_loss = 0.1216098882464899
Trained batch 90 in epoch 0, gen_loss = 0.6930054462218023, disc_loss = 0.12059032393025827
Trained batch 91 in epoch 0, gen_loss = 0.6934865709880124, disc_loss = 0.11969154012268005
Trained batch 92 in epoch 0, gen_loss = 0.6941951516494956, disc_loss = 0.11878877133131027
Trained batch 93 in epoch 0, gen_loss = 0.6942960508960359, disc_loss = 0.1179033683097743
Trained batch 94 in epoch 0, gen_loss = 0.69501205337675, disc_loss = 0.1173217271895785
Trained batch 95 in epoch 0, gen_loss = 0.6932265792662898, disc_loss = 0.11827956252576162
Trained batch 96 in epoch 0, gen_loss = 0.6958627415072057, disc_loss = 0.12157816666456842
Trained batch 97 in epoch 0, gen_loss = 0.6944215483203227, disc_loss = 0.12258599048518405
Trained batch 98 in epoch 0, gen_loss = 0.6936548102383662, disc_loss = 0.12211058510824888
Trained batch 99 in epoch 0, gen_loss = 0.6942036345601081, disc_loss = 0.12203090537339449
Trained batch 100 in epoch 0, gen_loss = 0.6942129651508709, disc_loss = 0.12154930354197427
Trained batch 101 in epoch 0, gen_loss = 0.6942690654712564, disc_loss = 0.12080374677829883
Trained batch 102 in epoch 0, gen_loss = 0.6949770540288351, disc_loss = 0.12010412703006013
Trained batch 103 in epoch 0, gen_loss = 0.695457940777907, disc_loss = 0.11945954978895876
Trained batch 104 in epoch 0, gen_loss = 0.695206979626701, disc_loss = 0.11864483083287874
Trained batch 105 in epoch 0, gen_loss = 0.6954702389127804, disc_loss = 0.11793053712484972
Trained batch 106 in epoch 0, gen_loss = 0.69548050794646, disc_loss = 0.1173670931118671
Trained batch 107 in epoch 0, gen_loss = 0.6955379686421819, disc_loss = 0.11658928639910839
Trained batch 108 in epoch 0, gen_loss = 0.6958745266866246, disc_loss = 0.11578458345948009
Trained batch 109 in epoch 0, gen_loss = 0.6961088714274493, disc_loss = 0.11520989073271101
Trained batch 110 in epoch 0, gen_loss = 0.6976709583321133, disc_loss = 0.11526552268916422
Trained batch 111 in epoch 0, gen_loss = 0.6970764076603311, disc_loss = 0.11560579878278077
Trained batch 112 in epoch 0, gen_loss = 0.6977543965377638, disc_loss = 0.11515508667953246
Trained batch 113 in epoch 0, gen_loss = 0.6984729691032778, disc_loss = 0.11490682639965885
Trained batch 114 in epoch 0, gen_loss = 0.6972923804884371, disc_loss = 0.1155890424290429
Trained batch 115 in epoch 0, gen_loss = 0.6984972123955858, disc_loss = 0.11521720484798324
Trained batch 116 in epoch 0, gen_loss = 0.6991918456350636, disc_loss = 0.11685234419683106
Trained batch 117 in epoch 0, gen_loss = 0.698306147577399, disc_loss = 0.11885928081632671
Trained batch 118 in epoch 0, gen_loss = 0.6976248088504086, disc_loss = 0.11888668839545811
Trained batch 119 in epoch 0, gen_loss = 0.6977349149684111, disc_loss = 0.11948220627382397
Trained batch 120 in epoch 0, gen_loss = 0.696337836094139, disc_loss = 0.12008786432383474
Trained batch 121 in epoch 0, gen_loss = 0.6958464533090591, disc_loss = 0.12030777649679145
Trained batch 122 in epoch 0, gen_loss = 0.696012440978027, disc_loss = 0.12065825650725907
Trained batch 123 in epoch 0, gen_loss = 0.6951780999379773, disc_loss = 0.12054515326575886
Trained batch 124 in epoch 0, gen_loss = 0.6943862369060516, disc_loss = 0.12083048686385155
Trained batch 125 in epoch 0, gen_loss = 0.6947740266720454, disc_loss = 0.12049654844616141
Trained batch 126 in epoch 0, gen_loss = 0.6952124315453326, disc_loss = 0.12024273773229967
Trained batch 127 in epoch 0, gen_loss = 0.6944179295096546, disc_loss = 0.12033056360087357
Trained batch 128 in epoch 0, gen_loss = 0.6940255010312841, disc_loss = 0.1201835386455059
Trained batch 129 in epoch 0, gen_loss = 0.6949309773170032, disc_loss = 0.1204168254079727
Trained batch 130 in epoch 0, gen_loss = 0.6942762279783496, disc_loss = 0.12060893762088915
Trained batch 131 in epoch 0, gen_loss = 0.6937794068997557, disc_loss = 0.12075857160556497
Trained batch 132 in epoch 0, gen_loss = 0.6947389722318578, disc_loss = 0.12120178764812033
Trained batch 133 in epoch 0, gen_loss = 0.6940563381163042, disc_loss = 0.12166251528507738
Trained batch 134 in epoch 0, gen_loss = 0.694050880935457, disc_loss = 0.12161532273447072
Trained batch 135 in epoch 0, gen_loss = 0.693718005410012, disc_loss = 0.12174272030482397
Trained batch 136 in epoch 0, gen_loss = 0.6932836177140257, disc_loss = 0.1215529652026883
Trained batch 137 in epoch 0, gen_loss = 0.6926222130440284, disc_loss = 0.12133451678074789
Trained batch 138 in epoch 0, gen_loss = 0.6920331787291191, disc_loss = 0.12110381082986756
Trained batch 139 in epoch 0, gen_loss = 0.6926634675690106, disc_loss = 0.1219152739803706
Trained batch 140 in epoch 0, gen_loss = 0.691392755888878, disc_loss = 0.12500884893832478
Trained batch 141 in epoch 0, gen_loss = 0.6911197172504076, disc_loss = 0.12459272663043418
Trained batch 142 in epoch 0, gen_loss = 0.6912204387721482, disc_loss = 0.12482120213912917
Trained batch 143 in epoch 0, gen_loss = 0.6909016761928797, disc_loss = 0.12479489009516935
Trained batch 144 in epoch 0, gen_loss = 0.6904085210685073, disc_loss = 0.12473925277590751
Trained batch 145 in epoch 0, gen_loss = 0.6903472753012017, disc_loss = 0.12479384526712438
Trained batch 146 in epoch 0, gen_loss = 0.6896833682141337, disc_loss = 0.12474354723987936
Trained batch 147 in epoch 0, gen_loss = 0.6887443663703429, disc_loss = 0.12485719872386875
Trained batch 148 in epoch 0, gen_loss = 0.6890315603489844, disc_loss = 0.12539158648992546
Trained batch 149 in epoch 0, gen_loss = 0.6883348180850347, disc_loss = 0.126299587264657
Trained batch 150 in epoch 0, gen_loss = 0.6886243537956516, disc_loss = 0.1265395140361707
Trained batch 151 in epoch 0, gen_loss = 0.6884149816867552, disc_loss = 0.12628115162155346
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6371238827705383, disc_loss = 0.10201473534107208
Trained batch 1 in epoch 1, gen_loss = 0.6357817351818085, disc_loss = 0.09930172190070152
Trained batch 2 in epoch 1, gen_loss = 0.6639467279116312, disc_loss = 0.1315559521317482
Trained batch 3 in epoch 1, gen_loss = 0.6364443898200989, disc_loss = 0.1387674305588007
Trained batch 4 in epoch 1, gen_loss = 0.6213763236999512, disc_loss = 0.13842750638723372
Trained batch 5 in epoch 1, gen_loss = 0.6011975904305776, disc_loss = 0.1551683209836483
Trained batch 6 in epoch 1, gen_loss = 0.6335218719073704, disc_loss = 0.17138693694557464
Trained batch 7 in epoch 1, gen_loss = 0.6239830404520035, disc_loss = 0.17022750992327929
Trained batch 8 in epoch 1, gen_loss = 0.6168985631730821, disc_loss = 0.16436946309275097
Trained batch 9 in epoch 1, gen_loss = 0.6046232581138611, disc_loss = 0.16862314715981483
Trained batch 10 in epoch 1, gen_loss = 0.610110039060766, disc_loss = 0.16555771841244263
Trained batch 11 in epoch 1, gen_loss = 0.6097317238648733, disc_loss = 0.16097044944763184
Trained batch 12 in epoch 1, gen_loss = 0.6044803995352525, disc_loss = 0.1571059272839473
Trained batch 13 in epoch 1, gen_loss = 0.600991530077798, disc_loss = 0.15643755878720964
Trained batch 14 in epoch 1, gen_loss = 0.6214787562688192, disc_loss = 0.17200876077016194
Trained batch 15 in epoch 1, gen_loss = 0.6171121634542942, disc_loss = 0.17175019159913063
Trained batch 16 in epoch 1, gen_loss = 0.6132898050196031, disc_loss = 0.17052440082325654
Trained batch 17 in epoch 1, gen_loss = 0.6107228861914741, disc_loss = 0.1713698903719584
Trained batch 18 in epoch 1, gen_loss = 0.613872041827754, disc_loss = 0.16945284212890424
Trained batch 19 in epoch 1, gen_loss = 0.6138207674026489, disc_loss = 0.1649776019155979
Trained batch 20 in epoch 1, gen_loss = 0.6155191915375846, disc_loss = 0.1630970062244506
Trained batch 21 in epoch 1, gen_loss = 0.6227923848412253, disc_loss = 0.1698724322698333
Trained batch 22 in epoch 1, gen_loss = 0.6219989009525465, disc_loss = 0.16849679078744806
Trained batch 23 in epoch 1, gen_loss = 0.619282086690267, disc_loss = 0.16709406363467375
Trained batch 24 in epoch 1, gen_loss = 0.6203464221954346, disc_loss = 0.1700141954421997
Trained batch 25 in epoch 1, gen_loss = 0.6149734545212525, disc_loss = 0.1753566310955928
Trained batch 26 in epoch 1, gen_loss = 0.6164918751628311, disc_loss = 0.17417921732973168
Trained batch 27 in epoch 1, gen_loss = 0.6171531176992825, disc_loss = 0.17306093871593475
Trained batch 28 in epoch 1, gen_loss = 0.6151460953827562, disc_loss = 0.1723346972259982
Trained batch 29 in epoch 1, gen_loss = 0.6161585777997971, disc_loss = 0.17098339001337687
Trained batch 30 in epoch 1, gen_loss = 0.6140985133186463, disc_loss = 0.17102103560201584
Trained batch 31 in epoch 1, gen_loss = 0.6152833579108119, disc_loss = 0.17049731221050024
Trained batch 32 in epoch 1, gen_loss = 0.6152588824431101, disc_loss = 0.17005733513470853
Trained batch 33 in epoch 1, gen_loss = 0.6166361421346664, disc_loss = 0.1690970935365733
Trained batch 34 in epoch 1, gen_loss = 0.6136733455317361, disc_loss = 0.17042281244482313
Trained batch 35 in epoch 1, gen_loss = 0.6138175088498328, disc_loss = 0.1706011692682902
Trained batch 36 in epoch 1, gen_loss = 0.6108583864328023, disc_loss = 0.17210201153884064
Trained batch 37 in epoch 1, gen_loss = 0.6079616836811367, disc_loss = 0.17549023424324237
Trained batch 38 in epoch 1, gen_loss = 0.6095401025735415, disc_loss = 0.177240924957471
Trained batch 39 in epoch 1, gen_loss = 0.6074277438223362, disc_loss = 0.17783351689577104
Trained batch 40 in epoch 1, gen_loss = 0.6043090107964306, disc_loss = 0.1812931873449465
Trained batch 41 in epoch 1, gen_loss = 0.6041344986075446, disc_loss = 0.18126776530629113
Trained batch 42 in epoch 1, gen_loss = 0.6034962174504303, disc_loss = 0.18155918183714845
Trained batch 43 in epoch 1, gen_loss = 0.6012476669116453, disc_loss = 0.18146833371032367
Trained batch 44 in epoch 1, gen_loss = 0.5993551664882236, disc_loss = 0.1806324902507994
Trained batch 45 in epoch 1, gen_loss = 0.5980713963508606, disc_loss = 0.17970888608175775
Trained batch 46 in epoch 1, gen_loss = 0.5961938348222287, disc_loss = 0.17883903422254196
Trained batch 47 in epoch 1, gen_loss = 0.5946823048094908, disc_loss = 0.17776726807157198
Trained batch 48 in epoch 1, gen_loss = 0.5947219437482406, disc_loss = 0.17650664491312845
Trained batch 49 in epoch 1, gen_loss = 0.5958074951171874, disc_loss = 0.1772969526052475
Trained batch 50 in epoch 1, gen_loss = 0.5940464548036164, disc_loss = 0.18246305865399978
Trained batch 51 in epoch 1, gen_loss = 0.5934116427715008, disc_loss = 0.1821189453968635
Trained batch 52 in epoch 1, gen_loss = 0.5931459957698606, disc_loss = 0.18178245453339703
Trained batch 53 in epoch 1, gen_loss = 0.5948301023907132, disc_loss = 0.18023958029570403
Trained batch 54 in epoch 1, gen_loss = 0.5945773774927313, disc_loss = 0.17849558022889225
Trained batch 55 in epoch 1, gen_loss = 0.594783501965659, disc_loss = 0.17696173728576728
Trained batch 56 in epoch 1, gen_loss = 0.5951632198534513, disc_loss = 0.17562422901391983
Trained batch 57 in epoch 1, gen_loss = 0.5951703231910179, disc_loss = 0.17442485009287967
Trained batch 58 in epoch 1, gen_loss = 0.5967141662613821, disc_loss = 0.17316740435563913
Trained batch 59 in epoch 1, gen_loss = 0.5950855195522309, disc_loss = 0.17501738804082076
Trained batch 60 in epoch 1, gen_loss = 0.5975864725034745, disc_loss = 0.17711928621178769
Trained batch 61 in epoch 1, gen_loss = 0.5982154319363255, disc_loss = 0.1757972242851411
Trained batch 62 in epoch 1, gen_loss = 0.595699029309409, disc_loss = 0.17701839762074606
Trained batch 63 in epoch 1, gen_loss = 0.5957500161603093, disc_loss = 0.17707135761156678
Trained batch 64 in epoch 1, gen_loss = 0.5961918730002184, disc_loss = 0.17775595394464638
Trained batch 65 in epoch 1, gen_loss = 0.5957143667972449, disc_loss = 0.17811965648875092
Trained batch 66 in epoch 1, gen_loss = 0.5952376634327333, disc_loss = 0.17820078646069143
Trained batch 67 in epoch 1, gen_loss = 0.5947144899298163, disc_loss = 0.17805999539354267
Trained batch 68 in epoch 1, gen_loss = 0.5949742508971173, disc_loss = 0.17747871491356174
Trained batch 69 in epoch 1, gen_loss = 0.5953396243708474, disc_loss = 0.17740296402147837
Trained batch 70 in epoch 1, gen_loss = 0.592976666252378, disc_loss = 0.17836506328952145
Trained batch 71 in epoch 1, gen_loss = 0.5924822741912471, disc_loss = 0.17799971045719254
Trained batch 72 in epoch 1, gen_loss = 0.5933326568505536, disc_loss = 0.1770003178756531
Trained batch 73 in epoch 1, gen_loss = 0.592836702594886, disc_loss = 0.17574431847881627
Trained batch 74 in epoch 1, gen_loss = 0.5929718116919199, disc_loss = 0.1746507015824318
Trained batch 75 in epoch 1, gen_loss = 0.5928807576235972, disc_loss = 0.1740251313894987
Trained batch 76 in epoch 1, gen_loss = 0.5919508620516046, disc_loss = 0.1735341791789253
Trained batch 77 in epoch 1, gen_loss = 0.5924523285566232, disc_loss = 0.17361588499102837
Trained batch 78 in epoch 1, gen_loss = 0.5910366275642491, disc_loss = 0.1779387969570824
Trained batch 79 in epoch 1, gen_loss = 0.5908609852194786, disc_loss = 0.17754371417686343
Trained batch 80 in epoch 1, gen_loss = 0.5935663676556245, disc_loss = 0.18110351862362872
Trained batch 81 in epoch 1, gen_loss = 0.5917192842902207, disc_loss = 0.1839199203361825
Trained batch 82 in epoch 1, gen_loss = 0.5907716348946813, disc_loss = 0.18629314373415637
Trained batch 83 in epoch 1, gen_loss = 0.5912915468215942, disc_loss = 0.1928096441108556
Trained batch 84 in epoch 1, gen_loss = 0.5920498048557955, disc_loss = 0.1955288069213138
Trained batch 85 in epoch 1, gen_loss = 0.5910224297712016, disc_loss = 0.19611216934267864
Trained batch 86 in epoch 1, gen_loss = 0.5909377089862166, disc_loss = 0.19645348028547463
Trained batch 87 in epoch 1, gen_loss = 0.5900202190334146, disc_loss = 0.19673032660714604
Trained batch 88 in epoch 1, gen_loss = 0.5893533209736428, disc_loss = 0.19693308507793406
Trained batch 89 in epoch 1, gen_loss = 0.5885472529464297, disc_loss = 0.19709964998894267
Trained batch 90 in epoch 1, gen_loss = 0.5886308734233563, disc_loss = 0.19707974259342467
Trained batch 91 in epoch 1, gen_loss = 0.5875623184053794, disc_loss = 0.19718953764632993
Trained batch 92 in epoch 1, gen_loss = 0.586712884326135, disc_loss = 0.19746550877568542
Trained batch 93 in epoch 1, gen_loss = 0.5851395450373913, disc_loss = 0.1977157599906972
Trained batch 94 in epoch 1, gen_loss = 0.5838187057720987, disc_loss = 0.1978467785214123
Trained batch 95 in epoch 1, gen_loss = 0.5827947122355303, disc_loss = 0.19793865247629583
Trained batch 96 in epoch 1, gen_loss = 0.5821070419144385, disc_loss = 0.19791168473737755
Trained batch 97 in epoch 1, gen_loss = 0.5813359295835301, disc_loss = 0.19792549076433086
Trained batch 98 in epoch 1, gen_loss = 0.580582158132033, disc_loss = 0.19796906644948806
Trained batch 99 in epoch 1, gen_loss = 0.5795434600114823, disc_loss = 0.19806633122265338
Trained batch 100 in epoch 1, gen_loss = 0.5790000628716875, disc_loss = 0.19789991173708793
Trained batch 101 in epoch 1, gen_loss = 0.5786465979089924, disc_loss = 0.19777309083763292
Trained batch 102 in epoch 1, gen_loss = 0.5779401740981537, disc_loss = 0.19750267129789278
Trained batch 103 in epoch 1, gen_loss = 0.5778407821288476, disc_loss = 0.19703086830962163
Trained batch 104 in epoch 1, gen_loss = 0.5769235480399358, disc_loss = 0.19683385058527902
Trained batch 105 in epoch 1, gen_loss = 0.5762664771304941, disc_loss = 0.19661504374641292
Trained batch 106 in epoch 1, gen_loss = 0.5755710317709736, disc_loss = 0.19698231068448485
Trained batch 107 in epoch 1, gen_loss = 0.5759335546581833, disc_loss = 0.198374400191285
Trained batch 108 in epoch 1, gen_loss = 0.5745308844868197, disc_loss = 0.198843414562011
Trained batch 109 in epoch 1, gen_loss = 0.5739080019972541, disc_loss = 0.19887791485948997
Trained batch 110 in epoch 1, gen_loss = 0.5734062342493383, disc_loss = 0.19898904920429797
Trained batch 111 in epoch 1, gen_loss = 0.5723931813346488, disc_loss = 0.19905681049983417
Trained batch 112 in epoch 1, gen_loss = 0.5717228479617464, disc_loss = 0.19896672910029908
Trained batch 113 in epoch 1, gen_loss = 0.5719634234382395, disc_loss = 0.19886407406445136
Trained batch 114 in epoch 1, gen_loss = 0.571542748938436, disc_loss = 0.1988302779586419
Trained batch 115 in epoch 1, gen_loss = 0.5712986144012419, disc_loss = 0.199147112860248
Trained batch 116 in epoch 1, gen_loss = 0.570158952067041, disc_loss = 0.1994464142072914
Trained batch 117 in epoch 1, gen_loss = 0.5695380730144048, disc_loss = 0.19933262170623925
Trained batch 118 in epoch 1, gen_loss = 0.5687497092896149, disc_loss = 0.1990829089484295
Trained batch 119 in epoch 1, gen_loss = 0.5682403072714806, disc_loss = 0.19876268450170756
Trained batch 120 in epoch 1, gen_loss = 0.5681926465231525, disc_loss = 0.19849167930439485
Trained batch 121 in epoch 1, gen_loss = 0.5675574934384862, disc_loss = 0.19818916556532265
Trained batch 122 in epoch 1, gen_loss = 0.5670514390235994, disc_loss = 0.1978677350694571
Trained batch 123 in epoch 1, gen_loss = 0.5668732420571388, disc_loss = 0.19752365801363223
Trained batch 124 in epoch 1, gen_loss = 0.5659968616962433, disc_loss = 0.19743897050619125
Trained batch 125 in epoch 1, gen_loss = 0.566270878154134, disc_loss = 0.19716704406199
Trained batch 126 in epoch 1, gen_loss = 0.5656077085048195, disc_loss = 0.19691560182749757
Trained batch 127 in epoch 1, gen_loss = 0.5654550998006016, disc_loss = 0.19646073988405988
Trained batch 128 in epoch 1, gen_loss = 0.56494672330775, disc_loss = 0.19600957972827807
Trained batch 129 in epoch 1, gen_loss = 0.5648239312263635, disc_loss = 0.19556222529365466
Trained batch 130 in epoch 1, gen_loss = 0.5649270795228827, disc_loss = 0.19576223757658295
Trained batch 131 in epoch 1, gen_loss = 0.5639825914845322, disc_loss = 0.19705472305191285
Trained batch 132 in epoch 1, gen_loss = 0.5636032371592701, disc_loss = 0.19680953591613842
Trained batch 133 in epoch 1, gen_loss = 0.563319067456829, disc_loss = 0.19718122398897783
Trained batch 134 in epoch 1, gen_loss = 0.5623650899639836, disc_loss = 0.19731883809522346
Trained batch 135 in epoch 1, gen_loss = 0.5615694807732806, disc_loss = 0.1973840353791328
Trained batch 136 in epoch 1, gen_loss = 0.561009016350238, disc_loss = 0.1974528097432025
Trained batch 137 in epoch 1, gen_loss = 0.5606854717800582, disc_loss = 0.19711435807571895
Trained batch 138 in epoch 1, gen_loss = 0.5601413264977846, disc_loss = 0.19682985989095494
Trained batch 139 in epoch 1, gen_loss = 0.5596151984163693, disc_loss = 0.1966028027768646
Trained batch 140 in epoch 1, gen_loss = 0.5598497156133043, disc_loss = 0.19635513377316455
Trained batch 141 in epoch 1, gen_loss = 0.5596657708077364, disc_loss = 0.19582693667059214
Trained batch 142 in epoch 1, gen_loss = 0.5591285462146038, disc_loss = 0.1954787835166171
Trained batch 143 in epoch 1, gen_loss = 0.5592277824050851, disc_loss = 0.194852897276481
Trained batch 144 in epoch 1, gen_loss = 0.5590882753503734, disc_loss = 0.19451561302974307
Trained batch 145 in epoch 1, gen_loss = 0.5590064856287551, disc_loss = 0.19386661154766605
Trained batch 146 in epoch 1, gen_loss = 0.5588807273073261, disc_loss = 0.1937030092591331
Trained batch 147 in epoch 1, gen_loss = 0.5605354599050574, disc_loss = 0.19445928538570534
Trained batch 148 in epoch 1, gen_loss = 0.5599432771637936, disc_loss = 0.19616488132300794
Trained batch 149 in epoch 1, gen_loss = 0.5596925334135692, disc_loss = 0.19589804222186408
Trained batch 150 in epoch 1, gen_loss = 0.5595152255715123, disc_loss = 0.19603264775891968
Trained batch 151 in epoch 1, gen_loss = 0.5592453271934861, disc_loss = 0.19617194515701972
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.47121548652648926, disc_loss = 0.2080262005329132
Trained batch 1 in epoch 2, gen_loss = 0.48975974321365356, disc_loss = 0.18825124949216843
Trained batch 2 in epoch 2, gen_loss = 0.49359023571014404, disc_loss = 0.18027536571025848
Trained batch 3 in epoch 2, gen_loss = 0.49942170083522797, disc_loss = 0.16897478699684143
Trained batch 4 in epoch 2, gen_loss = 0.5009716510772705, disc_loss = 0.15999746918678284
Trained batch 5 in epoch 2, gen_loss = 0.49679501354694366, disc_loss = 0.15788597613573074
Trained batch 6 in epoch 2, gen_loss = 0.4863459425313132, disc_loss = 0.15794530723776137
Trained batch 7 in epoch 2, gen_loss = 0.48663492500782013, disc_loss = 0.15624651685357094
Trained batch 8 in epoch 2, gen_loss = 0.5013569460974799, disc_loss = 0.16239459978209603
Trained batch 9 in epoch 2, gen_loss = 0.4930275946855545, disc_loss = 0.17423457205295562
Trained batch 10 in epoch 2, gen_loss = 0.4999486668543382, disc_loss = 0.17567446556958285
Trained batch 11 in epoch 2, gen_loss = 0.49773112187782925, disc_loss = 0.17497403919696808
Trained batch 12 in epoch 2, gen_loss = 0.4934641741789304, disc_loss = 0.1729114708992151
Trained batch 13 in epoch 2, gen_loss = 0.49692956251757486, disc_loss = 0.17066983985049383
Trained batch 14 in epoch 2, gen_loss = 0.49906581044197085, disc_loss = 0.1680838445822398
Trained batch 15 in epoch 2, gen_loss = 0.5114794578403234, disc_loss = 0.1691716630011797
Trained batch 16 in epoch 2, gen_loss = 0.5073817319729749, disc_loss = 0.17443248980185566
Trained batch 17 in epoch 2, gen_loss = 0.5061159216695361, disc_loss = 0.17174084650145638
Trained batch 18 in epoch 2, gen_loss = 0.5109665284031316, disc_loss = 0.17715975485349955
Trained batch 19 in epoch 2, gen_loss = 0.50806445479393, disc_loss = 0.18151914775371553
Trained batch 20 in epoch 2, gen_loss = 0.5049265396027338, disc_loss = 0.18062402946608408
Trained batch 21 in epoch 2, gen_loss = 0.5077523643320258, disc_loss = 0.1811948079954494
Trained batch 22 in epoch 2, gen_loss = 0.5053125049756921, disc_loss = 0.18056711230588995
Trained batch 23 in epoch 2, gen_loss = 0.5029388169447581, disc_loss = 0.1789733897894621
Trained batch 24 in epoch 2, gen_loss = 0.5043099665641785, disc_loss = 0.1753681942820549
Trained batch 25 in epoch 2, gen_loss = 0.503776130767969, disc_loss = 0.17372331453057435
Trained batch 26 in epoch 2, gen_loss = 0.5068842989427073, disc_loss = 0.172244599295987
Trained batch 27 in epoch 2, gen_loss = 0.5073599772793906, disc_loss = 0.17043390098427022
Trained batch 28 in epoch 2, gen_loss = 0.5098379809280922, disc_loss = 0.1678392956482953
Trained batch 29 in epoch 2, gen_loss = 0.5139944553375244, disc_loss = 0.16853170866767567
Trained batch 30 in epoch 2, gen_loss = 0.5125479227112185, disc_loss = 0.17027776207654707
Trained batch 31 in epoch 2, gen_loss = 0.5136784622445703, disc_loss = 0.1689790424425155
Trained batch 32 in epoch 2, gen_loss = 0.5178129067926696, disc_loss = 0.17014963405601907
Trained batch 33 in epoch 2, gen_loss = 0.5163667491253685, disc_loss = 0.17052957831936724
Trained batch 34 in epoch 2, gen_loss = 0.5146410363061088, disc_loss = 0.17044202366045544
Trained batch 35 in epoch 2, gen_loss = 0.5213839709758759, disc_loss = 0.1762807694160276
Trained batch 36 in epoch 2, gen_loss = 0.5192117094993591, disc_loss = 0.17698040906641935
Trained batch 37 in epoch 2, gen_loss = 0.5160143077373505, disc_loss = 0.17741302381220617
Trained batch 38 in epoch 2, gen_loss = 0.516774961581597, disc_loss = 0.1774295367873632
Trained batch 39 in epoch 2, gen_loss = 0.5166313171386718, disc_loss = 0.17738030273467303
Trained batch 40 in epoch 2, gen_loss = 0.5155507028102875, disc_loss = 0.17700258388025006
Trained batch 41 in epoch 2, gen_loss = 0.5159952746970313, disc_loss = 0.1761799133604481
Trained batch 42 in epoch 2, gen_loss = 0.5150736300058143, disc_loss = 0.17527839905300804
Trained batch 43 in epoch 2, gen_loss = 0.5163095031272281, disc_loss = 0.17442184635861355
Trained batch 44 in epoch 2, gen_loss = 0.5169987221558888, disc_loss = 0.17286469257540174
Trained batch 45 in epoch 2, gen_loss = 0.5158563560765722, disc_loss = 0.1716770055177419
Trained batch 46 in epoch 2, gen_loss = 0.5184729562160817, disc_loss = 0.16968849491565785
Trained batch 47 in epoch 2, gen_loss = 0.520649304613471, disc_loss = 0.1676195686062177
Trained batch 48 in epoch 2, gen_loss = 0.518814600852071, disc_loss = 0.1719597267861269
Trained batch 49 in epoch 2, gen_loss = 0.5215323549509049, disc_loss = 0.17310537785291671
Trained batch 50 in epoch 2, gen_loss = 0.5199397632888719, disc_loss = 0.173391187600061
Trained batch 51 in epoch 2, gen_loss = 0.5192652849050668, disc_loss = 0.17287015313139328
Trained batch 52 in epoch 2, gen_loss = 0.5200266230781123, disc_loss = 0.1728923497897274
Trained batch 53 in epoch 2, gen_loss = 0.5197188048451035, disc_loss = 0.17133287906094832
Trained batch 54 in epoch 2, gen_loss = 0.5182626702568748, disc_loss = 0.17083803943612358
Trained batch 55 in epoch 2, gen_loss = 0.520610012114048, disc_loss = 0.17090080585330725
Trained batch 56 in epoch 2, gen_loss = 0.520823759990826, disc_loss = 0.16937463155441118
Trained batch 57 in epoch 2, gen_loss = 0.5200543886628645, disc_loss = 0.16795399373975292
Trained batch 58 in epoch 2, gen_loss = 0.5223815026929823, disc_loss = 0.16721094323922012
Trained batch 59 in epoch 2, gen_loss = 0.5227695415417354, disc_loss = 0.1652776272346576
Trained batch 60 in epoch 2, gen_loss = 0.5222867551397105, disc_loss = 0.16441909101654273
Trained batch 61 in epoch 2, gen_loss = 0.5262901244624969, disc_loss = 0.16413175542989084
Trained batch 62 in epoch 2, gen_loss = 0.5258742987163483, disc_loss = 0.16405304474016977
Trained batch 63 in epoch 2, gen_loss = 0.5272192163392901, disc_loss = 0.16469561855774373
Trained batch 64 in epoch 2, gen_loss = 0.5252796397759364, disc_loss = 0.16694401995493816
Trained batch 65 in epoch 2, gen_loss = 0.5261417857625268, disc_loss = 0.16871848329901695
Trained batch 66 in epoch 2, gen_loss = 0.5255759104863921, disc_loss = 0.16896852572907262
Trained batch 67 in epoch 2, gen_loss = 0.5246055016622824, disc_loss = 0.16913374809219556
Trained batch 68 in epoch 2, gen_loss = 0.526739697093549, disc_loss = 0.1702709011193635
Trained batch 69 in epoch 2, gen_loss = 0.5267003029584885, disc_loss = 0.1699580862053803
Trained batch 70 in epoch 2, gen_loss = 0.525475582606356, disc_loss = 0.17003457279692233
Trained batch 71 in epoch 2, gen_loss = 0.5257798971401321, disc_loss = 0.17010707998027405
Trained batch 72 in epoch 2, gen_loss = 0.5247073818559516, disc_loss = 0.1694391846452674
Trained batch 73 in epoch 2, gen_loss = 0.5243854047478856, disc_loss = 0.16880246141069644
Trained batch 74 in epoch 2, gen_loss = 0.5252468832333883, disc_loss = 0.16876460860172907
Trained batch 75 in epoch 2, gen_loss = 0.5248627333264602, disc_loss = 0.16832878724916986
Trained batch 76 in epoch 2, gen_loss = 0.5252948527212267, disc_loss = 0.16740011830221524
Trained batch 77 in epoch 2, gen_loss = 0.5269157519707313, disc_loss = 0.16720236236086258
Trained batch 78 in epoch 2, gen_loss = 0.5251531080354618, disc_loss = 0.1677387506712841
Trained batch 79 in epoch 2, gen_loss = 0.5260419808328152, disc_loss = 0.16880080765113234
Trained batch 80 in epoch 2, gen_loss = 0.5253167100894598, disc_loss = 0.16995086079394375
Trained batch 81 in epoch 2, gen_loss = 0.5259366965875393, disc_loss = 0.16982672790565143
Trained batch 82 in epoch 2, gen_loss = 0.5259594910116081, disc_loss = 0.1693213907889573
Trained batch 83 in epoch 2, gen_loss = 0.5256253381570181, disc_loss = 0.1686765681952238
Trained batch 84 in epoch 2, gen_loss = 0.5254886662258821, disc_loss = 0.16791240125894547
Trained batch 85 in epoch 2, gen_loss = 0.5261100378147391, disc_loss = 0.16764390425280082
Trained batch 86 in epoch 2, gen_loss = 0.5257164534481092, disc_loss = 0.16791211693793878
Trained batch 87 in epoch 2, gen_loss = 0.5268361981619488, disc_loss = 0.1676922273737463
Trained batch 88 in epoch 2, gen_loss = 0.5273238688372495, disc_loss = 0.16700546426719495
Trained batch 89 in epoch 2, gen_loss = 0.5269855168130663, disc_loss = 0.1665606298380428
Trained batch 90 in epoch 2, gen_loss = 0.5293934004647392, disc_loss = 0.16753081191372085
Trained batch 91 in epoch 2, gen_loss = 0.5282646890567697, disc_loss = 0.16775214267165764
Trained batch 92 in epoch 2, gen_loss = 0.5278490884329683, disc_loss = 0.16759252660377053
Trained batch 93 in epoch 2, gen_loss = 0.5276930078547052, disc_loss = 0.167827918174419
Trained batch 94 in epoch 2, gen_loss = 0.5267117274434943, disc_loss = 0.1682801227820547
Trained batch 95 in epoch 2, gen_loss = 0.5271336659789085, disc_loss = 0.16791836824268103
Trained batch 96 in epoch 2, gen_loss = 0.5267655059848864, disc_loss = 0.1677625634006618
Trained batch 97 in epoch 2, gen_loss = 0.5264200102918002, disc_loss = 0.1674914861820182
Trained batch 98 in epoch 2, gen_loss = 0.5266770970339727, disc_loss = 0.1675850801696681
Trained batch 99 in epoch 2, gen_loss = 0.525739241540432, disc_loss = 0.16849650755524637
Trained batch 100 in epoch 2, gen_loss = 0.5263659526215921, disc_loss = 0.1682492838342591
Trained batch 101 in epoch 2, gen_loss = 0.5267694776549059, disc_loss = 0.16764609018961588
Trained batch 102 in epoch 2, gen_loss = 0.5268414353282707, disc_loss = 0.167006971983655
Trained batch 103 in epoch 2, gen_loss = 0.526778728629534, disc_loss = 0.16688576419479573
Trained batch 104 in epoch 2, gen_loss = 0.5278365211827415, disc_loss = 0.16687383673020773
Trained batch 105 in epoch 2, gen_loss = 0.5279872510230766, disc_loss = 0.16613536278875368
Trained batch 106 in epoch 2, gen_loss = 0.5276324208651748, disc_loss = 0.16544161388807208
Trained batch 107 in epoch 2, gen_loss = 0.5282176429474795, disc_loss = 0.165075843118959
Trained batch 108 in epoch 2, gen_loss = 0.5277223696402453, disc_loss = 0.16436672983092998
Trained batch 109 in epoch 2, gen_loss = 0.5278380502354015, disc_loss = 0.16360441866246136
Trained batch 110 in epoch 2, gen_loss = 0.529457282375645, disc_loss = 0.16340094818188264
Trained batch 111 in epoch 2, gen_loss = 0.5287809861557824, disc_loss = 0.16429951587425812
Trained batch 112 in epoch 2, gen_loss = 0.5288499493514542, disc_loss = 0.1638372665749187
Trained batch 113 in epoch 2, gen_loss = 0.5302529397763704, disc_loss = 0.16413669157446475
Trained batch 114 in epoch 2, gen_loss = 0.5290353191935497, disc_loss = 0.1644033001816791
Trained batch 115 in epoch 2, gen_loss = 0.5289565055020924, disc_loss = 0.16377849626386987
Trained batch 116 in epoch 2, gen_loss = 0.5295754907987057, disc_loss = 0.16293144480794922
Trained batch 117 in epoch 2, gen_loss = 0.5302951692019479, disc_loss = 0.16183549304634837
Trained batch 118 in epoch 2, gen_loss = 0.5311723644493007, disc_loss = 0.1606519375653828
Trained batch 119 in epoch 2, gen_loss = 0.5319031265874704, disc_loss = 0.15955381747335196
Trained batch 120 in epoch 2, gen_loss = 0.533410775021088, disc_loss = 0.15835110762364363
Trained batch 121 in epoch 2, gen_loss = 0.5343278091950495, disc_loss = 0.15732155394450317
Trained batch 122 in epoch 2, gen_loss = 0.5361829014813028, disc_loss = 0.15717910432324902
Trained batch 123 in epoch 2, gen_loss = 0.5356658269320765, disc_loss = 0.160077168778967
Trained batch 124 in epoch 2, gen_loss = 0.5362436289787292, disc_loss = 0.1592839597091079
Trained batch 125 in epoch 2, gen_loss = 0.5372444736579108, disc_loss = 0.1599529978878323
Trained batch 126 in epoch 2, gen_loss = 0.5365316220155851, disc_loss = 0.16037560092270609
Trained batch 127 in epoch 2, gen_loss = 0.5362480254843831, disc_loss = 0.1601759029654204
Trained batch 128 in epoch 2, gen_loss = 0.536521639934806, disc_loss = 0.1602112681698776
Trained batch 129 in epoch 2, gen_loss = 0.5362559744944939, disc_loss = 0.1599709690405199
Trained batch 130 in epoch 2, gen_loss = 0.5358614443822671, disc_loss = 0.16012220797733268
Trained batch 131 in epoch 2, gen_loss = 0.5361290808879968, disc_loss = 0.15969499197054768
Trained batch 132 in epoch 2, gen_loss = 0.5364325682919725, disc_loss = 0.15968136373851308
Trained batch 133 in epoch 2, gen_loss = 0.5367280249275378, disc_loss = 0.1588427677069471
Trained batch 134 in epoch 2, gen_loss = 0.5361220655617891, disc_loss = 0.15873092205298167
Trained batch 135 in epoch 2, gen_loss = 0.536429205799804, disc_loss = 0.15869951206396388
Trained batch 136 in epoch 2, gen_loss = 0.5359516796404428, disc_loss = 0.15869334189860274
Trained batch 137 in epoch 2, gen_loss = 0.5356209554534027, disc_loss = 0.1586890181971957
Trained batch 138 in epoch 2, gen_loss = 0.535520770995737, disc_loss = 0.15864626668634818
Trained batch 139 in epoch 2, gen_loss = 0.5353858832802091, disc_loss = 0.1582565712276846
Trained batch 140 in epoch 2, gen_loss = 0.536350557990108, disc_loss = 0.15874792975604746
Trained batch 141 in epoch 2, gen_loss = 0.536089021974886, disc_loss = 0.1594053503899822
Trained batch 142 in epoch 2, gen_loss = 0.5361400700949289, disc_loss = 0.1587691167108975
Trained batch 143 in epoch 2, gen_loss = 0.537346001714468, disc_loss = 0.15888451129689607
Trained batch 144 in epoch 2, gen_loss = 0.5376506871190564, disc_loss = 0.1584654107882545
Trained batch 145 in epoch 2, gen_loss = 0.5378653211136387, disc_loss = 0.15773090995108224
Trained batch 146 in epoch 2, gen_loss = 0.5384633038319698, disc_loss = 0.15721158348150602
Trained batch 147 in epoch 2, gen_loss = 0.538868355992678, disc_loss = 0.15631212751582466
Trained batch 148 in epoch 2, gen_loss = 0.5387791767216369, disc_loss = 0.15593723827135442
Trained batch 149 in epoch 2, gen_loss = 0.5396296310424805, disc_loss = 0.15544212728117904
Trained batch 150 in epoch 2, gen_loss = 0.5396367295688351, disc_loss = 0.1549943717048559
Trained batch 151 in epoch 2, gen_loss = 0.5408193743542621, disc_loss = 0.15455141564904662
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4173974394798279, disc_loss = 0.48764485120773315
Trained batch 1 in epoch 3, gen_loss = 0.5517536103725433, disc_loss = 0.30183956399559975
Trained batch 2 in epoch 3, gen_loss = 0.5380035837491354, disc_loss = 0.23669431110223135
Trained batch 3 in epoch 3, gen_loss = 0.5306781679391861, disc_loss = 0.2167058102786541
Trained batch 4 in epoch 3, gen_loss = 0.5505976676940918, disc_loss = 0.21522476077079772
Trained batch 5 in epoch 3, gen_loss = 0.5272070864836375, disc_loss = 0.20829475919405618
Trained batch 6 in epoch 3, gen_loss = 0.5309399962425232, disc_loss = 0.20080456563404628
Trained batch 7 in epoch 3, gen_loss = 0.5383287519216537, disc_loss = 0.19841553270816803
Trained batch 8 in epoch 3, gen_loss = 0.5353096591101753, disc_loss = 0.19415364331669277
Trained batch 9 in epoch 3, gen_loss = 0.5269157350063324, disc_loss = 0.19008842259645461
Trained batch 10 in epoch 3, gen_loss = 0.5340069153092124, disc_loss = 0.1809163208712231
Trained batch 11 in epoch 3, gen_loss = 0.5383666406075159, disc_loss = 0.17475997532407442
Trained batch 12 in epoch 3, gen_loss = 0.5294920343619126, disc_loss = 0.1841238817343345
Trained batch 13 in epoch 3, gen_loss = 0.5425766408443451, disc_loss = 0.17915269466383116
Trained batch 14 in epoch 3, gen_loss = 0.5416770696640014, disc_loss = 0.17316518227259317
Trained batch 15 in epoch 3, gen_loss = 0.5375012215226889, disc_loss = 0.17238425835967064
Trained batch 16 in epoch 3, gen_loss = 0.5438714185181786, disc_loss = 0.1738877112374586
Trained batch 17 in epoch 3, gen_loss = 0.5482704954014884, disc_loss = 0.1653684520473083
Trained batch 18 in epoch 3, gen_loss = 0.546865198173021, disc_loss = 0.1661583657719587
Trained batch 19 in epoch 3, gen_loss = 0.5493908897042274, disc_loss = 0.15990952607244252
Trained batch 20 in epoch 3, gen_loss = 0.5532756433600471, disc_loss = 0.15482711827471143
Trained batch 21 in epoch 3, gen_loss = 0.5498471287163821, disc_loss = 0.15574541450901466
Trained batch 22 in epoch 3, gen_loss = 0.5520629520001619, disc_loss = 0.15772104230911835
Trained batch 23 in epoch 3, gen_loss = 0.5524733339746793, disc_loss = 0.15534088046600422
Trained batch 24 in epoch 3, gen_loss = 0.5573871827125549, disc_loss = 0.1504049825668335
Trained batch 25 in epoch 3, gen_loss = 0.5557801196208367, disc_loss = 0.14696836270965064
Trained batch 26 in epoch 3, gen_loss = 0.5590250227186415, disc_loss = 0.144081709837472
Trained batch 27 in epoch 3, gen_loss = 0.5568059597696576, disc_loss = 0.14178061272416795
Trained batch 28 in epoch 3, gen_loss = 0.5560449526227754, disc_loss = 0.1400170346786236
Trained batch 29 in epoch 3, gen_loss = 0.5564402898152669, disc_loss = 0.13852846349279085
Trained batch 30 in epoch 3, gen_loss = 0.555658096267331, disc_loss = 0.13634081208898174
Trained batch 31 in epoch 3, gen_loss = 0.5578134655952454, disc_loss = 0.1345814112573862
Trained batch 32 in epoch 3, gen_loss = 0.560422192920338, disc_loss = 0.13120588637662656
Trained batch 33 in epoch 3, gen_loss = 0.5564103494672215, disc_loss = 0.13272217551574989
Trained batch 34 in epoch 3, gen_loss = 0.5594209892409189, disc_loss = 0.13565576608691896
Trained batch 35 in epoch 3, gen_loss = 0.5552594024274085, disc_loss = 0.1367740827716059
Trained batch 36 in epoch 3, gen_loss = 0.5569107411680995, disc_loss = 0.1347079126013292
Trained batch 37 in epoch 3, gen_loss = 0.5549936608264321, disc_loss = 0.13457555853222547
Trained batch 38 in epoch 3, gen_loss = 0.5561850437751183, disc_loss = 0.13617006421853334
Trained batch 39 in epoch 3, gen_loss = 0.555699160695076, disc_loss = 0.1379852754995227
Trained batch 40 in epoch 3, gen_loss = 0.5571211692763538, disc_loss = 0.1412896868295786
Trained batch 41 in epoch 3, gen_loss = 0.5558203756809235, disc_loss = 0.14275463865626425
Trained batch 42 in epoch 3, gen_loss = 0.5553066785945449, disc_loss = 0.14331037516510764
Trained batch 43 in epoch 3, gen_loss = 0.559158971363848, disc_loss = 0.14412682384929873
Trained batch 44 in epoch 3, gen_loss = 0.5578594658109877, disc_loss = 0.14663369605938595
Trained batch 45 in epoch 3, gen_loss = 0.5591107930826105, disc_loss = 0.14749723300337791
Trained batch 46 in epoch 3, gen_loss = 0.5578952304860378, disc_loss = 0.1477848673437504
Trained batch 47 in epoch 3, gen_loss = 0.5562388102213541, disc_loss = 0.14847403593982259
Trained batch 48 in epoch 3, gen_loss = 0.5559235969368292, disc_loss = 0.14838791091223152
Trained batch 49 in epoch 3, gen_loss = 0.554540097117424, disc_loss = 0.14814150497317313
Trained batch 50 in epoch 3, gen_loss = 0.5560303593383116, disc_loss = 0.14600623997987486
Trained batch 51 in epoch 3, gen_loss = 0.5555955016842256, disc_loss = 0.14718768143883118
Trained batch 52 in epoch 3, gen_loss = 0.5595696068034982, disc_loss = 0.15181753011244647
Trained batch 53 in epoch 3, gen_loss = 0.5572436010396039, disc_loss = 0.1541762856973542
Trained batch 54 in epoch 3, gen_loss = 0.5565798618576744, disc_loss = 0.1537289248271422
Trained batch 55 in epoch 3, gen_loss = 0.5561319121292659, disc_loss = 0.15376946915473258
Trained batch 56 in epoch 3, gen_loss = 0.5543392896652222, disc_loss = 0.15373389945741286
Trained batch 57 in epoch 3, gen_loss = 0.552762409222537, disc_loss = 0.15347690315082155
Trained batch 58 in epoch 3, gen_loss = 0.5524770763971038, disc_loss = 0.15320451330330412
Trained batch 59 in epoch 3, gen_loss = 0.5514434839288394, disc_loss = 0.15321566586693128
Trained batch 60 in epoch 3, gen_loss = 0.5499576188501765, disc_loss = 0.15297804479716254
Trained batch 61 in epoch 3, gen_loss = 0.5501150964729248, disc_loss = 0.15251584062653203
Trained batch 62 in epoch 3, gen_loss = 0.5497419081983113, disc_loss = 0.15175496254648482
Trained batch 63 in epoch 3, gen_loss = 0.5496594761498272, disc_loss = 0.15108918491750956
Trained batch 64 in epoch 3, gen_loss = 0.5490694224834443, disc_loss = 0.149616976082325
Trained batch 65 in epoch 3, gen_loss = 0.5484404758070455, disc_loss = 0.1490026396332365
Trained batch 66 in epoch 3, gen_loss = 0.5505009511513497, disc_loss = 0.1507879927087186
Trained batch 67 in epoch 3, gen_loss = 0.5484461731770459, disc_loss = 0.1539442017674446
Trained batch 68 in epoch 3, gen_loss = 0.5487319153288136, disc_loss = 0.15401588682679163
Trained batch 69 in epoch 3, gen_loss = 0.5485459889684404, disc_loss = 0.15358711864267077
Trained batch 70 in epoch 3, gen_loss = 0.5467259967830819, disc_loss = 0.15412537480743838
Trained batch 71 in epoch 3, gen_loss = 0.547464938627349, disc_loss = 0.15394369616276687
Trained batch 72 in epoch 3, gen_loss = 0.5475421172298797, disc_loss = 0.1532253401532565
Trained batch 73 in epoch 3, gen_loss = 0.5477617769627958, disc_loss = 0.15229188187702283
Trained batch 74 in epoch 3, gen_loss = 0.5472682571411133, disc_loss = 0.1519075106581052
Trained batch 75 in epoch 3, gen_loss = 0.5463148324113143, disc_loss = 0.15169858197240452
Trained batch 76 in epoch 3, gen_loss = 0.5459598767292964, disc_loss = 0.1515222094082213
Trained batch 77 in epoch 3, gen_loss = 0.5452691446512173, disc_loss = 0.15158564282151368
Trained batch 78 in epoch 3, gen_loss = 0.5454447578780258, disc_loss = 0.15103839356688004
Trained batch 79 in epoch 3, gen_loss = 0.5446923315525055, disc_loss = 0.15063913855701686
Trained batch 80 in epoch 3, gen_loss = 0.5448497931162516, disc_loss = 0.14976382476312142
Trained batch 81 in epoch 3, gen_loss = 0.5449153599215717, disc_loss = 0.14887048594835328
Trained batch 82 in epoch 3, gen_loss = 0.547626317265522, disc_loss = 0.1483273050153112
Trained batch 83 in epoch 3, gen_loss = 0.5478303602763585, disc_loss = 0.1473133879758063
Trained batch 84 in epoch 3, gen_loss = 0.5471892840722028, disc_loss = 0.14619480941225502
Trained batch 85 in epoch 3, gen_loss = 0.548443537118823, disc_loss = 0.14476377148787642
Trained batch 86 in epoch 3, gen_loss = 0.5489717358830332, disc_loss = 0.14366885809891525
Trained batch 87 in epoch 3, gen_loss = 0.5486783866177906, disc_loss = 0.14283171418884938
Trained batch 88 in epoch 3, gen_loss = 0.5489408795753222, disc_loss = 0.14328826800658462
Trained batch 89 in epoch 3, gen_loss = 0.5487523231241438, disc_loss = 0.14342700031896433
Trained batch 90 in epoch 3, gen_loss = 0.548290478004204, disc_loss = 0.14353803066270693
Trained batch 91 in epoch 3, gen_loss = 0.5480362410130708, disc_loss = 0.14445264074627473
Trained batch 92 in epoch 3, gen_loss = 0.5474754632801138, disc_loss = 0.14412901794878386
Trained batch 93 in epoch 3, gen_loss = 0.5480728596448898, disc_loss = 0.14347756871993236
Trained batch 94 in epoch 3, gen_loss = 0.5489007858853591, disc_loss = 0.14284453388107451
Trained batch 95 in epoch 3, gen_loss = 0.5523779041444262, disc_loss = 0.14301141409669071
Trained batch 96 in epoch 3, gen_loss = 0.5525889995786333, disc_loss = 0.14189753727507345
Trained batch 97 in epoch 3, gen_loss = 0.5516178170028998, disc_loss = 0.14269331500542407
Trained batch 98 in epoch 3, gen_loss = 0.5515558310229369, disc_loss = 0.1420423352357113
Trained batch 99 in epoch 3, gen_loss = 0.5539231371879577, disc_loss = 0.14276061564683915
Trained batch 100 in epoch 3, gen_loss = 0.5547709099136957, disc_loss = 0.14176702064157712
Trained batch 101 in epoch 3, gen_loss = 0.5528291884590598, disc_loss = 0.1429530353668858
Trained batch 102 in epoch 3, gen_loss = 0.5523559873543896, disc_loss = 0.14250626516284295
Trained batch 103 in epoch 3, gen_loss = 0.5530501237282386, disc_loss = 0.14238325040787458
Trained batch 104 in epoch 3, gen_loss = 0.5523236087390355, disc_loss = 0.14223971899066654
Trained batch 105 in epoch 3, gen_loss = 0.5521212833107643, disc_loss = 0.1423022470806005
Trained batch 106 in epoch 3, gen_loss = 0.552936399651465, disc_loss = 0.14230299197903304
Trained batch 107 in epoch 3, gen_loss = 0.5524112366967731, disc_loss = 0.1417403365312903
Trained batch 108 in epoch 3, gen_loss = 0.5507714163272752, disc_loss = 0.14315522188713792
Trained batch 109 in epoch 3, gen_loss = 0.5519516424699263, disc_loss = 0.14392006769776344
Trained batch 110 in epoch 3, gen_loss = 0.5528104251569456, disc_loss = 0.14302030574899535
Trained batch 111 in epoch 3, gen_loss = 0.552117217864309, disc_loss = 0.14325578304539835
Trained batch 112 in epoch 3, gen_loss = 0.5514855595816553, disc_loss = 0.14333999981131174
Trained batch 113 in epoch 3, gen_loss = 0.5521291619852969, disc_loss = 0.1453602905466891
Trained batch 114 in epoch 3, gen_loss = 0.5515461110550425, disc_loss = 0.14616593284451443
Trained batch 115 in epoch 3, gen_loss = 0.5508699350315949, disc_loss = 0.14654614577262565
Trained batch 116 in epoch 3, gen_loss = 0.5512300612580063, disc_loss = 0.14668286464407912
Trained batch 117 in epoch 3, gen_loss = 0.5504652021800057, disc_loss = 0.14681797417796263
Trained batch 118 in epoch 3, gen_loss = 0.5502203980914685, disc_loss = 0.14682923351265803
Trained batch 119 in epoch 3, gen_loss = 0.5493181099494299, disc_loss = 0.14707077698161206
Trained batch 120 in epoch 3, gen_loss = 0.5494721315123818, disc_loss = 0.14686034576705664
Trained batch 121 in epoch 3, gen_loss = 0.5493020708443689, disc_loss = 0.14657847277942251
Trained batch 122 in epoch 3, gen_loss = 0.5488391877189884, disc_loss = 0.1460670870615215
Trained batch 123 in epoch 3, gen_loss = 0.5491257805016733, disc_loss = 0.1456270125964957
Trained batch 124 in epoch 3, gen_loss = 0.5501218643188477, disc_loss = 0.1456855805516243
Trained batch 125 in epoch 3, gen_loss = 0.5496769195038175, disc_loss = 0.1459515109539978
Trained batch 126 in epoch 3, gen_loss = 0.5494739983494826, disc_loss = 0.14571147247796923
Trained batch 127 in epoch 3, gen_loss = 0.5510313978884369, disc_loss = 0.1451168501516804
Trained batch 128 in epoch 3, gen_loss = 0.5507171322671018, disc_loss = 0.14477203243462614
Trained batch 129 in epoch 3, gen_loss = 0.5504195316479756, disc_loss = 0.1441286635513489
Trained batch 130 in epoch 3, gen_loss = 0.5510790586926555, disc_loss = 0.14350643270570812
Trained batch 131 in epoch 3, gen_loss = 0.5506072394324072, disc_loss = 0.143215449526906
Trained batch 132 in epoch 3, gen_loss = 0.5504215630821716, disc_loss = 0.14300447114204107
Trained batch 133 in epoch 3, gen_loss = 0.5496359865612058, disc_loss = 0.14320402753664485
Trained batch 134 in epoch 3, gen_loss = 0.550864158515577, disc_loss = 0.1449056245110653
Trained batch 135 in epoch 3, gen_loss = 0.5502959597198402, disc_loss = 0.14483321704627836
Trained batch 136 in epoch 3, gen_loss = 0.5500978677377214, disc_loss = 0.14432892937512293
Trained batch 137 in epoch 3, gen_loss = 0.5502819559280423, disc_loss = 0.14353653329654018
Trained batch 138 in epoch 3, gen_loss = 0.5498670847724667, disc_loss = 0.14354852822830352
Trained batch 139 in epoch 3, gen_loss = 0.5498561295015472, disc_loss = 0.1445799839815923
Trained batch 140 in epoch 3, gen_loss = 0.5496386177573643, disc_loss = 0.14452492065252143
Trained batch 141 in epoch 3, gen_loss = 0.5487493501162864, disc_loss = 0.1451409360997274
Trained batch 142 in epoch 3, gen_loss = 0.550290703148275, disc_loss = 0.14739640885508143
Trained batch 143 in epoch 3, gen_loss = 0.5493279583752155, disc_loss = 0.14764234118370545
Trained batch 144 in epoch 3, gen_loss = 0.5480852079802546, disc_loss = 0.1480953272560547
Trained batch 145 in epoch 3, gen_loss = 0.5475927393322122, disc_loss = 0.1482905135681368
Trained batch 146 in epoch 3, gen_loss = 0.5474940589090593, disc_loss = 0.14847702107259206
Trained batch 147 in epoch 3, gen_loss = 0.5467978117836488, disc_loss = 0.1485316834437686
Trained batch 148 in epoch 3, gen_loss = 0.5466522040383127, disc_loss = 0.1480680208578206
Trained batch 149 in epoch 3, gen_loss = 0.5460295313596726, disc_loss = 0.14823169137040773
Trained batch 150 in epoch 3, gen_loss = 0.5462436989837924, disc_loss = 0.1487011807347765
Trained batch 151 in epoch 3, gen_loss = 0.5455754532625801, disc_loss = 0.14905617038082136
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.5098615884780884, disc_loss = 0.11809076368808746
Trained batch 1 in epoch 4, gen_loss = 0.5275396108627319, disc_loss = 0.12582308799028397
Trained batch 2 in epoch 4, gen_loss = 0.5232242941856384, disc_loss = 0.12505859384934107
Trained batch 3 in epoch 4, gen_loss = 0.5264952331781387, disc_loss = 0.12933390401303768
Trained batch 4 in epoch 4, gen_loss = 0.5293476819992066, disc_loss = 0.12374917417764664
Trained batch 5 in epoch 4, gen_loss = 0.5161163210868835, disc_loss = 0.13211707646648088
Trained batch 6 in epoch 4, gen_loss = 0.5011753737926483, disc_loss = 0.14329693892172404
Trained batch 7 in epoch 4, gen_loss = 0.5099852494895458, disc_loss = 0.15110539365559816
Trained batch 8 in epoch 4, gen_loss = 0.5038333700762855, disc_loss = 0.15129615283674663
Trained batch 9 in epoch 4, gen_loss = 0.49440962076187134, disc_loss = 0.15411678180098534
Trained batch 10 in epoch 4, gen_loss = 0.4992185180837458, disc_loss = 0.1502210802652619
Trained batch 11 in epoch 4, gen_loss = 0.5025941133499146, disc_loss = 0.14632593095302582
Trained batch 12 in epoch 4, gen_loss = 0.4986461423910581, disc_loss = 0.14437542167993692
Trained batch 13 in epoch 4, gen_loss = 0.4932319202593395, disc_loss = 0.14287340162055834
Trained batch 14 in epoch 4, gen_loss = 0.5014727930227916, disc_loss = 0.1402288739879926
Trained batch 15 in epoch 4, gen_loss = 0.5019132103770971, disc_loss = 0.1349996062926948
Trained batch 16 in epoch 4, gen_loss = 0.5039364117033341, disc_loss = 0.13102753372753367
Trained batch 17 in epoch 4, gen_loss = 0.5120474348465601, disc_loss = 0.12917501603563628
Trained batch 18 in epoch 4, gen_loss = 0.5079024339977064, disc_loss = 0.133207437631331
Trained batch 19 in epoch 4, gen_loss = 0.5144623994827271, disc_loss = 0.13846552036702633
Trained batch 20 in epoch 4, gen_loss = 0.5109827220439911, disc_loss = 0.1396339319291569
Trained batch 21 in epoch 4, gen_loss = 0.5129277259111404, disc_loss = 0.14042050154371696
Trained batch 22 in epoch 4, gen_loss = 0.5163086199242136, disc_loss = 0.13793253607076147
Trained batch 23 in epoch 4, gen_loss = 0.5133574505647024, disc_loss = 0.14069278010477623
Trained batch 24 in epoch 4, gen_loss = 0.5141417288780212, disc_loss = 0.14010864108800888
Trained batch 25 in epoch 4, gen_loss = 0.5178180497426254, disc_loss = 0.13919089677242133
Trained batch 26 in epoch 4, gen_loss = 0.5171621309386359, disc_loss = 0.13769054937141914
Trained batch 27 in epoch 4, gen_loss = 0.5187119309391294, disc_loss = 0.13489964231848717
Trained batch 28 in epoch 4, gen_loss = 0.521168867061878, disc_loss = 0.13298046743047648
Trained batch 29 in epoch 4, gen_loss = 0.5243714471658071, disc_loss = 0.13081591054797173
Trained batch 30 in epoch 4, gen_loss = 0.5200938274783473, disc_loss = 0.1338488000535196
Trained batch 31 in epoch 4, gen_loss = 0.5243142228573561, disc_loss = 0.13596216519363225
Trained batch 32 in epoch 4, gen_loss = 0.5245395230524468, disc_loss = 0.13395757228136063
Trained batch 33 in epoch 4, gen_loss = 0.5227728380876429, disc_loss = 0.1332711292540326
Trained batch 34 in epoch 4, gen_loss = 0.5274127994264876, disc_loss = 0.13635594972542353
Trained batch 35 in epoch 4, gen_loss = 0.5235875712500678, disc_loss = 0.1406724498503738
Trained batch 36 in epoch 4, gen_loss = 0.5219052288983319, disc_loss = 0.13965371492746714
Trained batch 37 in epoch 4, gen_loss = 0.5255980005389765, disc_loss = 0.14132915594075857
Trained batch 38 in epoch 4, gen_loss = 0.5240586048517472, disc_loss = 0.1411557931166429
Trained batch 39 in epoch 4, gen_loss = 0.5235918328166008, disc_loss = 0.13947359342128038
Trained batch 40 in epoch 4, gen_loss = 0.5247160676049023, disc_loss = 0.13845920217473331
Trained batch 41 in epoch 4, gen_loss = 0.5222346293074744, disc_loss = 0.13861659683641933
Trained batch 42 in epoch 4, gen_loss = 0.5211742873801741, disc_loss = 0.1388940452489742
Trained batch 43 in epoch 4, gen_loss = 0.5233396799726919, disc_loss = 0.13971736942502586
Trained batch 44 in epoch 4, gen_loss = 0.5221471461984847, disc_loss = 0.13932365394300886
Trained batch 45 in epoch 4, gen_loss = 0.5211324017980824, disc_loss = 0.1407079426166804
Trained batch 46 in epoch 4, gen_loss = 0.5225906346706634, disc_loss = 0.14272392287533334
Trained batch 47 in epoch 4, gen_loss = 0.5204692215969166, disc_loss = 0.1440876453804473
Trained batch 48 in epoch 4, gen_loss = 0.5199273465847483, disc_loss = 0.14471733615714677
Trained batch 49 in epoch 4, gen_loss = 0.5206888300180436, disc_loss = 0.1444604341685772
Trained batch 50 in epoch 4, gen_loss = 0.5199776969703973, disc_loss = 0.14393065825981252
Trained batch 51 in epoch 4, gen_loss = 0.51957868039608, disc_loss = 0.1430516426379864
Trained batch 52 in epoch 4, gen_loss = 0.5198029380924297, disc_loss = 0.14250525494791427
Trained batch 53 in epoch 4, gen_loss = 0.5179523974657059, disc_loss = 0.14290773647802849
Trained batch 54 in epoch 4, gen_loss = 0.5196070730686188, disc_loss = 0.1427370857108723
Trained batch 55 in epoch 4, gen_loss = 0.5179813514862742, disc_loss = 0.1414909643520202
Trained batch 56 in epoch 4, gen_loss = 0.516475730820706, disc_loss = 0.1418671123029893
Trained batch 57 in epoch 4, gen_loss = 0.5189306540735836, disc_loss = 0.14380559492213973
Trained batch 58 in epoch 4, gen_loss = 0.5177991758968871, disc_loss = 0.14358594571634875
Trained batch 59 in epoch 4, gen_loss = 0.5167461449901263, disc_loss = 0.14376639065643151
Trained batch 60 in epoch 4, gen_loss = 0.5163121922094314, disc_loss = 0.14379656278207653
Trained batch 61 in epoch 4, gen_loss = 0.5168969088023708, disc_loss = 0.14320004959740945
Trained batch 62 in epoch 4, gen_loss = 0.5167201922999488, disc_loss = 0.14290408080532438
Trained batch 63 in epoch 4, gen_loss = 0.5160868521779776, disc_loss = 0.14264520932920277
Trained batch 64 in epoch 4, gen_loss = 0.5173868674498338, disc_loss = 0.1411192346077699
Trained batch 65 in epoch 4, gen_loss = 0.5168881158937108, disc_loss = 0.14074699129119064
Trained batch 66 in epoch 4, gen_loss = 0.5174509584903717, disc_loss = 0.14027355500121616
Trained batch 67 in epoch 4, gen_loss = 0.5185338955591706, disc_loss = 0.13914825219441862
Trained batch 68 in epoch 4, gen_loss = 0.5210190350594728, disc_loss = 0.1374572629675917
Trained batch 69 in epoch 4, gen_loss = 0.5222613049404962, disc_loss = 0.13594611875180687
Trained batch 70 in epoch 4, gen_loss = 0.5262072149296881, disc_loss = 0.1347144155067877
Trained batch 71 in epoch 4, gen_loss = 0.5279556260340743, disc_loss = 0.13327585535848308
Trained batch 72 in epoch 4, gen_loss = 0.526780854757518, disc_loss = 0.13483220994574566
Trained batch 73 in epoch 4, gen_loss = 0.5297118727419827, disc_loss = 0.1368091098611822
Trained batch 74 in epoch 4, gen_loss = 0.529018292427063, disc_loss = 0.1360721076776584
Trained batch 75 in epoch 4, gen_loss = 0.5284805838998995, disc_loss = 0.1361199883302968
Trained batch 76 in epoch 4, gen_loss = 0.5307485693460935, disc_loss = 0.1372484577601993
Trained batch 77 in epoch 4, gen_loss = 0.5302624652783076, disc_loss = 0.13735449593514204
Trained batch 78 in epoch 4, gen_loss = 0.5308697182166425, disc_loss = 0.13736255686211435
Trained batch 79 in epoch 4, gen_loss = 0.5304889474064112, disc_loss = 0.13671753474045545
Trained batch 80 in epoch 4, gen_loss = 0.5295894620595155, disc_loss = 0.1370616149801163
Trained batch 81 in epoch 4, gen_loss = 0.5298791684028579, disc_loss = 0.13727885623258063
Trained batch 82 in epoch 4, gen_loss = 0.5302917350487537, disc_loss = 0.1362868693533791
Trained batch 83 in epoch 4, gen_loss = 0.5287961275095031, disc_loss = 0.13728526010665865
Trained batch 84 in epoch 4, gen_loss = 0.5307669341564178, disc_loss = 0.1376126067384201
Trained batch 85 in epoch 4, gen_loss = 0.5298851915570193, disc_loss = 0.13790236281360999
Trained batch 86 in epoch 4, gen_loss = 0.5289192096940403, disc_loss = 0.13817472282754278
Trained batch 87 in epoch 4, gen_loss = 0.5291010825471445, disc_loss = 0.1389548193282363
Trained batch 88 in epoch 4, gen_loss = 0.5292550780799952, disc_loss = 0.13878959138992797
Trained batch 89 in epoch 4, gen_loss = 0.5281597034798728, disc_loss = 0.13896541866577333
Trained batch 90 in epoch 4, gen_loss = 0.5277334202776899, disc_loss = 0.1392127033732422
Trained batch 91 in epoch 4, gen_loss = 0.527266561013201, disc_loss = 0.13941616311912303
Trained batch 92 in epoch 4, gen_loss = 0.5270422027316145, disc_loss = 0.13896659335061426
Trained batch 93 in epoch 4, gen_loss = 0.5268647743666426, disc_loss = 0.13929180101432065
Trained batch 94 in epoch 4, gen_loss = 0.5258789457772908, disc_loss = 0.13990353312539427
Trained batch 95 in epoch 4, gen_loss = 0.5254606033364931, disc_loss = 0.13973031936135763
Trained batch 96 in epoch 4, gen_loss = 0.5265591759042642, disc_loss = 0.13965384352990648
Trained batch 97 in epoch 4, gen_loss = 0.5251160118044639, disc_loss = 0.14004366934223442
Trained batch 98 in epoch 4, gen_loss = 0.5256372328960535, disc_loss = 0.1392340941373447
Trained batch 99 in epoch 4, gen_loss = 0.5250349217653274, disc_loss = 0.13896813934668897
Trained batch 100 in epoch 4, gen_loss = 0.5261981611204619, disc_loss = 0.1394965610844959
Trained batch 101 in epoch 4, gen_loss = 0.524973672394659, disc_loss = 0.14008986487911612
Trained batch 102 in epoch 4, gen_loss = 0.5253190901672956, disc_loss = 0.1396177261163598
Trained batch 103 in epoch 4, gen_loss = 0.5270956107057058, disc_loss = 0.1390145959583326
Trained batch 104 in epoch 4, gen_loss = 0.5263573203768049, disc_loss = 0.13961958500246208
Trained batch 105 in epoch 4, gen_loss = 0.5267981065894073, disc_loss = 0.13907283289744607
Trained batch 106 in epoch 4, gen_loss = 0.5276195601882222, disc_loss = 0.13917843661506044
Trained batch 107 in epoch 4, gen_loss = 0.5264584383478871, disc_loss = 0.13983075056845942
Trained batch 108 in epoch 4, gen_loss = 0.5266367645438658, disc_loss = 0.13980259108912507
Trained batch 109 in epoch 4, gen_loss = 0.5269963990558277, disc_loss = 0.1405946551229466
Trained batch 110 in epoch 4, gen_loss = 0.5260315698546332, disc_loss = 0.1415178794413805
Trained batch 111 in epoch 4, gen_loss = 0.5260176828929356, disc_loss = 0.1414080481543871
Trained batch 112 in epoch 4, gen_loss = 0.5255547883236302, disc_loss = 0.1413348493685501
Trained batch 113 in epoch 4, gen_loss = 0.5253979877421731, disc_loss = 0.14112214637887582
Trained batch 114 in epoch 4, gen_loss = 0.5253956753274669, disc_loss = 0.14061918386622616
Trained batch 115 in epoch 4, gen_loss = 0.5252536350283129, disc_loss = 0.1402192342994285
Trained batch 116 in epoch 4, gen_loss = 0.5252326161433489, disc_loss = 0.14054869877922738
Trained batch 117 in epoch 4, gen_loss = 0.5251112292378636, disc_loss = 0.14044878604995498
Trained batch 118 in epoch 4, gen_loss = 0.5247309986783677, disc_loss = 0.1405070984908262
Trained batch 119 in epoch 4, gen_loss = 0.5249018790821235, disc_loss = 0.14051515210109453
Trained batch 120 in epoch 4, gen_loss = 0.5243688375989267, disc_loss = 0.140538895533474
Trained batch 121 in epoch 4, gen_loss = 0.5258706507624172, disc_loss = 0.14027480058921654
Trained batch 122 in epoch 4, gen_loss = 0.5257324898630623, disc_loss = 0.13977222773057174
Trained batch 123 in epoch 4, gen_loss = 0.5254807025194168, disc_loss = 0.13910163826339186
Trained batch 124 in epoch 4, gen_loss = 0.5249645669460297, disc_loss = 0.1395970505028963
Trained batch 125 in epoch 4, gen_loss = 0.5265442348188825, disc_loss = 0.13980099365174298
Trained batch 126 in epoch 4, gen_loss = 0.5267635722329297, disc_loss = 0.13894091383737373
Trained batch 127 in epoch 4, gen_loss = 0.5262246408965439, disc_loss = 0.13926517662184779
Trained batch 128 in epoch 4, gen_loss = 0.5278877109982246, disc_loss = 0.13959116588325002
Trained batch 129 in epoch 4, gen_loss = 0.529431855907807, disc_loss = 0.1387576366846378
Trained batch 130 in epoch 4, gen_loss = 0.5289585451588376, disc_loss = 0.1395466430041626
Trained batch 131 in epoch 4, gen_loss = 0.5299022105155569, disc_loss = 0.1388654247152083
Trained batch 132 in epoch 4, gen_loss = 0.5299934850151378, disc_loss = 0.1385142319184497
Trained batch 133 in epoch 4, gen_loss = 0.53060412473643, disc_loss = 0.13797082779790037
Trained batch 134 in epoch 4, gen_loss = 0.5310306251049042, disc_loss = 0.13735885424194513
Trained batch 135 in epoch 4, gen_loss = 0.531440140789046, disc_loss = 0.13710576134240804
Trained batch 136 in epoch 4, gen_loss = 0.5309058962947261, disc_loss = 0.13745728050814057
Trained batch 137 in epoch 4, gen_loss = 0.5313137730826503, disc_loss = 0.13725994735200336
Trained batch 138 in epoch 4, gen_loss = 0.5310083331821633, disc_loss = 0.1373877335848997
Trained batch 139 in epoch 4, gen_loss = 0.5307545293654714, disc_loss = 0.13710404126239675
Trained batch 140 in epoch 4, gen_loss = 0.5322046057975038, disc_loss = 0.13663044384290987
Trained batch 141 in epoch 4, gen_loss = 0.5332249619171653, disc_loss = 0.13584803894791805
Trained batch 142 in epoch 4, gen_loss = 0.5341694290404553, disc_loss = 0.13515143297039545
Trained batch 143 in epoch 4, gen_loss = 0.5338874945624007, disc_loss = 0.13506815792061388
Trained batch 144 in epoch 4, gen_loss = 0.5345001810583575, disc_loss = 0.13446386071114705
Trained batch 145 in epoch 4, gen_loss = 0.5350813439039335, disc_loss = 0.13378511583560135
Trained batch 146 in epoch 4, gen_loss = 0.5368694640746733, disc_loss = 0.13315956312276067
Trained batch 147 in epoch 4, gen_loss = 0.5365374863550469, disc_loss = 0.13264172033381624
Trained batch 148 in epoch 4, gen_loss = 0.5369411324894668, disc_loss = 0.13189709181553566
Trained batch 149 in epoch 4, gen_loss = 0.5388453223307927, disc_loss = 0.13168078407645226
Trained batch 150 in epoch 4, gen_loss = 0.5384372439210778, disc_loss = 0.13214737675245233
Trained batch 151 in epoch 4, gen_loss = 0.5382233538517827, disc_loss = 0.1318874412559365
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.670813798904419, disc_loss = 0.23957031965255737
Trained batch 1 in epoch 5, gen_loss = 0.5909283459186554, disc_loss = 0.15992741286754608
Trained batch 2 in epoch 5, gen_loss = 0.5818155805269877, disc_loss = 0.12015377481778462
Trained batch 3 in epoch 5, gen_loss = 0.5840843468904495, disc_loss = 0.09414820279926062
Trained batch 4 in epoch 5, gen_loss = 0.5852959871292114, disc_loss = 0.07796979565173387
Trained batch 5 in epoch 5, gen_loss = 0.5887458225091299, disc_loss = 0.06833943926418821
Trained batch 6 in epoch 5, gen_loss = 0.5909579907144819, disc_loss = 0.06042626579957349
Trained batch 7 in epoch 5, gen_loss = 0.5882621556520462, disc_loss = 0.059114037780091166
Trained batch 8 in epoch 5, gen_loss = 0.5832019382052951, disc_loss = 0.056161952308482595
Trained batch 9 in epoch 5, gen_loss = 0.5827497899532318, disc_loss = 0.05647085290402174
Trained batch 10 in epoch 5, gen_loss = 0.5768143534660339, disc_loss = 0.060150982134721497
Trained batch 11 in epoch 5, gen_loss = 0.5875556220610937, disc_loss = 0.06197081863259276
Trained batch 12 in epoch 5, gen_loss = 0.5927422780257005, disc_loss = 0.058761997148394585
Trained batch 13 in epoch 5, gen_loss = 0.5864325038024357, disc_loss = 0.0629879240212696
Trained batch 14 in epoch 5, gen_loss = 0.5802524209022522, disc_loss = 0.06496028589705626
Trained batch 15 in epoch 5, gen_loss = 0.6060144789516926, disc_loss = 0.09162757627200335
Trained batch 16 in epoch 5, gen_loss = 0.5942641969989327, disc_loss = 0.1098634695962948
Trained batch 17 in epoch 5, gen_loss = 0.592002711362309, disc_loss = 0.10653586199300157
Trained batch 18 in epoch 5, gen_loss = 0.5914008915424347, disc_loss = 0.1065678679825444
Trained batch 19 in epoch 5, gen_loss = 0.5866062730550766, disc_loss = 0.10762574868276716
Trained batch 20 in epoch 5, gen_loss = 0.5797842783587319, disc_loss = 0.1066247598223743
Trained batch 21 in epoch 5, gen_loss = 0.5755818255923011, disc_loss = 0.10662553874267773
Trained batch 22 in epoch 5, gen_loss = 0.5739342064961143, disc_loss = 0.10722221409820992
Trained batch 23 in epoch 5, gen_loss = 0.5700619406998158, disc_loss = 0.10836959917408724
Trained batch 24 in epoch 5, gen_loss = 0.5714553797245026, disc_loss = 0.10825289376080036
Trained batch 25 in epoch 5, gen_loss = 0.5715159280942037, disc_loss = 0.1064621600537346
Trained batch 26 in epoch 5, gen_loss = 0.5700347589121925, disc_loss = 0.10459711050821675
Trained batch 27 in epoch 5, gen_loss = 0.5675703084894589, disc_loss = 0.10574139182322792
Trained batch 28 in epoch 5, gen_loss = 0.5690781093876938, disc_loss = 0.10469121492371478
Trained batch 29 in epoch 5, gen_loss = 0.5666798611481985, disc_loss = 0.10493142437189817
Trained batch 30 in epoch 5, gen_loss = 0.5647039759543634, disc_loss = 0.10495824084406899
Trained batch 31 in epoch 5, gen_loss = 0.5663041416555643, disc_loss = 0.10520726238610223
Trained batch 32 in epoch 5, gen_loss = 0.5611974515698173, disc_loss = 0.10782688161866232
Trained batch 33 in epoch 5, gen_loss = 0.5617367809309679, disc_loss = 0.10891980486100211
Trained batch 34 in epoch 5, gen_loss = 0.5623237618378231, disc_loss = 0.1087067178849663
Trained batch 35 in epoch 5, gen_loss = 0.5612726286053658, disc_loss = 0.10889257061191732
Trained batch 36 in epoch 5, gen_loss = 0.560179823959196, disc_loss = 0.10862216096673463
Trained batch 37 in epoch 5, gen_loss = 0.5612683821665613, disc_loss = 0.10831991823292092
Trained batch 38 in epoch 5, gen_loss = 0.5600421757270129, disc_loss = 0.10815432022970456
Trained batch 39 in epoch 5, gen_loss = 0.5606660299003124, disc_loss = 0.1072857015300542
Trained batch 40 in epoch 5, gen_loss = 0.5621816857558924, disc_loss = 0.10650634915545219
Trained batch 41 in epoch 5, gen_loss = 0.5632073886337734, disc_loss = 0.10446344679664998
Trained batch 42 in epoch 5, gen_loss = 0.5614097582739453, disc_loss = 0.10388107589164446
Trained batch 43 in epoch 5, gen_loss = 0.5663536292585459, disc_loss = 0.10312394992533055
Trained batch 44 in epoch 5, gen_loss = 0.5695065955320994, disc_loss = 0.10198013409972191
Trained batch 45 in epoch 5, gen_loss = 0.5674252898796744, disc_loss = 0.10228694011659725
Trained batch 46 in epoch 5, gen_loss = 0.5650971145071881, disc_loss = 0.1016310970992484
Trained batch 47 in epoch 5, gen_loss = 0.5682790509114662, disc_loss = 0.1008257238039126
Trained batch 48 in epoch 5, gen_loss = 0.5694184698620621, disc_loss = 0.09943887051575039
Trained batch 49 in epoch 5, gen_loss = 0.5693921929597855, disc_loss = 0.09781299576163292
Trained batch 50 in epoch 5, gen_loss = 0.5714055971772063, disc_loss = 0.09644494790072534
Trained batch 51 in epoch 5, gen_loss = 0.5719228862569883, disc_loss = 0.09511038875923707
Trained batch 52 in epoch 5, gen_loss = 0.5735295937871033, disc_loss = 0.09359210355312757
Trained batch 53 in epoch 5, gen_loss = 0.5757065034574933, disc_loss = 0.09209188082496877
Trained batch 54 in epoch 5, gen_loss = 0.5762342295863412, disc_loss = 0.09134503448890015
Trained batch 55 in epoch 5, gen_loss = 0.5769015587866306, disc_loss = 0.0908751902336787
Trained batch 56 in epoch 5, gen_loss = 0.5757726739373124, disc_loss = 0.0906366213927405
Trained batch 57 in epoch 5, gen_loss = 0.5776818183989361, disc_loss = 0.09010497867611461
Trained batch 58 in epoch 5, gen_loss = 0.5777726097632263, disc_loss = 0.08874522466843916
Trained batch 59 in epoch 5, gen_loss = 0.5758601551254591, disc_loss = 0.0896045591837416
Trained batch 60 in epoch 5, gen_loss = 0.5761989320887894, disc_loss = 0.08995185781758828
Trained batch 61 in epoch 5, gen_loss = 0.5758246361247955, disc_loss = 0.08921009946554419
Trained batch 62 in epoch 5, gen_loss = 0.5746695536469656, disc_loss = 0.08920680502400039
Trained batch 63 in epoch 5, gen_loss = 0.5758666167967021, disc_loss = 0.08948777669866104
Trained batch 64 in epoch 5, gen_loss = 0.5746381388260768, disc_loss = 0.08938711350067303
Trained batch 65 in epoch 5, gen_loss = 0.5744866615895069, disc_loss = 0.08889101362420303
Trained batch 66 in epoch 5, gen_loss = 0.5748027887806963, disc_loss = 0.08886413194183539
Trained batch 67 in epoch 5, gen_loss = 0.5723146980299669, disc_loss = 0.08990380700732417
Trained batch 68 in epoch 5, gen_loss = 0.571188720672027, disc_loss = 0.09053715767905764
Trained batch 69 in epoch 5, gen_loss = 0.5711035136665616, disc_loss = 0.09020606456324458
Trained batch 70 in epoch 5, gen_loss = 0.5706637060978044, disc_loss = 0.0897872325846217
Trained batch 71 in epoch 5, gen_loss = 0.5726825383802255, disc_loss = 0.08873030468304124
Trained batch 72 in epoch 5, gen_loss = 0.5722806327147026, disc_loss = 0.08804243019692702
Trained batch 73 in epoch 5, gen_loss = 0.5727586001157761, disc_loss = 0.0869503646359049
Trained batch 74 in epoch 5, gen_loss = 0.5734578295548757, disc_loss = 0.0859219924112161
Trained batch 75 in epoch 5, gen_loss = 0.574508549743577, disc_loss = 0.08491027236327921
Trained batch 76 in epoch 5, gen_loss = 0.5751284945320774, disc_loss = 0.08407519635587156
Trained batch 77 in epoch 5, gen_loss = 0.5742800636933401, disc_loss = 0.08346607339066955
Trained batch 78 in epoch 5, gen_loss = 0.5756721590893178, disc_loss = 0.08256344262604849
Trained batch 79 in epoch 5, gen_loss = 0.5786465022712945, disc_loss = 0.08234394501196221
Trained batch 80 in epoch 5, gen_loss = 0.5783497783136956, disc_loss = 0.08272707491055314
Trained batch 81 in epoch 5, gen_loss = 0.5799223646158125, disc_loss = 0.08357863247439992
Trained batch 82 in epoch 5, gen_loss = 0.5780810534235943, disc_loss = 0.08710949976805103
Trained batch 83 in epoch 5, gen_loss = 0.5783180849892753, disc_loss = 0.08839167167787396
Trained batch 84 in epoch 5, gen_loss = 0.5772848809466643, disc_loss = 0.08878415149143513
Trained batch 85 in epoch 5, gen_loss = 0.5768873081650845, disc_loss = 0.08932763278527661
Trained batch 86 in epoch 5, gen_loss = 0.5754836414052152, disc_loss = 0.08954488932444103
Trained batch 87 in epoch 5, gen_loss = 0.5749883448535745, disc_loss = 0.0900798791447993
Trained batch 88 in epoch 5, gen_loss = 0.5737018022644386, disc_loss = 0.09081409880996086
Trained batch 89 in epoch 5, gen_loss = 0.5743967844380273, disc_loss = 0.09349412281687061
Trained batch 90 in epoch 5, gen_loss = 0.5721919110843113, disc_loss = 0.09512104283363282
Trained batch 91 in epoch 5, gen_loss = 0.5714510322912879, disc_loss = 0.0953728669302781
Trained batch 92 in epoch 5, gen_loss = 0.5718976477141021, disc_loss = 0.09542127291081093
Trained batch 93 in epoch 5, gen_loss = 0.5726567278517053, disc_loss = 0.09481486155988371
Trained batch 94 in epoch 5, gen_loss = 0.5714184801829488, disc_loss = 0.09550466648253955
Trained batch 95 in epoch 5, gen_loss = 0.5710400097693006, disc_loss = 0.09509188896239114
Trained batch 96 in epoch 5, gen_loss = 0.571977263566145, disc_loss = 0.09481248702162627
Trained batch 97 in epoch 5, gen_loss = 0.5708585402795247, disc_loss = 0.0949083851479298
Trained batch 98 in epoch 5, gen_loss = 0.5699634741653096, disc_loss = 0.09511353170518021
Trained batch 99 in epoch 5, gen_loss = 0.5695466122031212, disc_loss = 0.09494132046587765
Trained batch 100 in epoch 5, gen_loss = 0.5683306470365808, disc_loss = 0.09521318622634257
Trained batch 101 in epoch 5, gen_loss = 0.5683552555593789, disc_loss = 0.09591538463627883
Trained batch 102 in epoch 5, gen_loss = 0.5675549646025723, disc_loss = 0.0963277237091973
Trained batch 103 in epoch 5, gen_loss = 0.5673417718364642, disc_loss = 0.09641303663822608
Trained batch 104 in epoch 5, gen_loss = 0.568150304044996, disc_loss = 0.09750890913641169
Trained batch 105 in epoch 5, gen_loss = 0.5668482864802739, disc_loss = 0.0984605703731331
Trained batch 106 in epoch 5, gen_loss = 0.5662117483459901, disc_loss = 0.09896906413938676
Trained batch 107 in epoch 5, gen_loss = 0.5653712283130046, disc_loss = 0.098650366662898
Trained batch 108 in epoch 5, gen_loss = 0.5641447702132234, disc_loss = 0.09913836861319772
Trained batch 109 in epoch 5, gen_loss = 0.5650743481787768, disc_loss = 0.10043140803040429
Trained batch 110 in epoch 5, gen_loss = 0.5636683071518803, disc_loss = 0.10116080205619067
Trained batch 111 in epoch 5, gen_loss = 0.5630437758352075, disc_loss = 0.10186433716444299
Trained batch 112 in epoch 5, gen_loss = 0.5621987786968198, disc_loss = 0.10200053174048662
Trained batch 113 in epoch 5, gen_loss = 0.5616902682864875, disc_loss = 0.10213454646924347
Trained batch 114 in epoch 5, gen_loss = 0.561626078253207, disc_loss = 0.10191251289747331
Trained batch 115 in epoch 5, gen_loss = 0.5616616396040752, disc_loss = 0.10157048943902142
Trained batch 116 in epoch 5, gen_loss = 0.5612428336061983, disc_loss = 0.10174621569199695
Trained batch 117 in epoch 5, gen_loss = 0.5611968570846623, disc_loss = 0.10237553744908359
Trained batch 118 in epoch 5, gen_loss = 0.5612648179551133, disc_loss = 0.1020001747230647
Trained batch 119 in epoch 5, gen_loss = 0.559995764742295, disc_loss = 0.10340112057359269
Trained batch 120 in epoch 5, gen_loss = 0.5605268175444327, disc_loss = 0.10419303161084406
Trained batch 121 in epoch 5, gen_loss = 0.560175365844711, disc_loss = 0.10385116294301192
Trained batch 122 in epoch 5, gen_loss = 0.5592446160025712, disc_loss = 0.10429940845938475
Trained batch 123 in epoch 5, gen_loss = 0.5597437300509022, disc_loss = 0.10495398164306197
Trained batch 124 in epoch 5, gen_loss = 0.5587899498939514, disc_loss = 0.10549010045081376
Trained batch 125 in epoch 5, gen_loss = 0.5584066354093098, disc_loss = 0.10543104451120136
Trained batch 126 in epoch 5, gen_loss = 0.55832451347291, disc_loss = 0.10543526891677633
Trained batch 127 in epoch 5, gen_loss = 0.5573803894221783, disc_loss = 0.10537291377113434
Trained batch 128 in epoch 5, gen_loss = 0.5567632994448491, disc_loss = 0.10525190201407486
Trained batch 129 in epoch 5, gen_loss = 0.5567458489766488, disc_loss = 0.10507959867469394
Trained batch 130 in epoch 5, gen_loss = 0.5566560646504847, disc_loss = 0.10466195148849533
Trained batch 131 in epoch 5, gen_loss = 0.5570207886172064, disc_loss = 0.10449320462419454
Trained batch 132 in epoch 5, gen_loss = 0.5563194182582367, disc_loss = 0.10480869500512692
Trained batch 133 in epoch 5, gen_loss = 0.5560906516082251, disc_loss = 0.10486833940941229
Trained batch 134 in epoch 5, gen_loss = 0.5567101262233876, disc_loss = 0.10477724103601994
Trained batch 135 in epoch 5, gen_loss = 0.5564026872024816, disc_loss = 0.10437470855985713
Trained batch 136 in epoch 5, gen_loss = 0.5559310767337353, disc_loss = 0.10430415247288281
Trained batch 137 in epoch 5, gen_loss = 0.5553905901269637, disc_loss = 0.10460654204117431
Trained batch 138 in epoch 5, gen_loss = 0.5556866322918762, disc_loss = 0.10481675859647903
Trained batch 139 in epoch 5, gen_loss = 0.5549698968018805, disc_loss = 0.10524801250680217
Trained batch 140 in epoch 5, gen_loss = 0.5552623840511268, disc_loss = 0.10564301190039156
Trained batch 141 in epoch 5, gen_loss = 0.5548911067381711, disc_loss = 0.1055152993452486
Trained batch 142 in epoch 5, gen_loss = 0.5546039040688868, disc_loss = 0.10517934752120213
Trained batch 143 in epoch 5, gen_loss = 0.55399992937843, disc_loss = 0.10563035460007894
Trained batch 144 in epoch 5, gen_loss = 0.5541761044798226, disc_loss = 0.10638925932219316
Trained batch 145 in epoch 5, gen_loss = 0.5547333657741547, disc_loss = 0.1059874264357535
Trained batch 146 in epoch 5, gen_loss = 0.5538462712651208, disc_loss = 0.10634347328244625
Trained batch 147 in epoch 5, gen_loss = 0.5535342632918745, disc_loss = 0.10624993137537024
Trained batch 148 in epoch 5, gen_loss = 0.554647013245013, disc_loss = 0.10923391228679243
Trained batch 149 in epoch 5, gen_loss = 0.5533264784018198, disc_loss = 0.11006785758460562
Trained batch 150 in epoch 5, gen_loss = 0.5530675843061991, disc_loss = 0.10975065332103447
Trained batch 151 in epoch 5, gen_loss = 0.5527618107827086, disc_loss = 0.10955189808737487
Testing Epoch 5

Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.5121249556541443, disc_loss = 0.1422688066959381
Trained batch 1 in epoch 6, gen_loss = 0.47933879494667053, disc_loss = 0.1447368860244751
Trained batch 2 in epoch 6, gen_loss = 0.47857052087783813, disc_loss = 0.1407126635313034
Trained batch 3 in epoch 6, gen_loss = 0.4803585410118103, disc_loss = 0.13030296005308628
Trained batch 4 in epoch 6, gen_loss = 0.49309918880462644, disc_loss = 0.12164227217435837
Trained batch 5 in epoch 6, gen_loss = 0.4975588619709015, disc_loss = 0.1178315890332063
Trained batch 6 in epoch 6, gen_loss = 0.5090128864560809, disc_loss = 0.1088698250906808
Trained batch 7 in epoch 6, gen_loss = 0.5056378245353699, disc_loss = 0.10853409208357334
Trained batch 8 in epoch 6, gen_loss = 0.5093631678157382, disc_loss = 0.1001127916905615
Trained batch 9 in epoch 6, gen_loss = 0.5102548599243164, disc_loss = 0.09548740163445472
Trained batch 10 in epoch 6, gen_loss = 0.5108390342105519, disc_loss = 0.09353176097978246
Trained batch 11 in epoch 6, gen_loss = 0.5092608804504076, disc_loss = 0.09666871341566245
Trained batch 12 in epoch 6, gen_loss = 0.5095575107977941, disc_loss = 0.09961465402291371
Trained batch 13 in epoch 6, gen_loss = 0.5068824014493397, disc_loss = 0.09940715400235993
Trained batch 14 in epoch 6, gen_loss = 0.5069924970467885, disc_loss = 0.09806747684876124
Trained batch 15 in epoch 6, gen_loss = 0.5056840758770704, disc_loss = 0.09646037919446826
Trained batch 16 in epoch 6, gen_loss = 0.5141306326669806, disc_loss = 0.09653052687644958
Trained batch 17 in epoch 6, gen_loss = 0.5109820597701602, disc_loss = 0.09780292958021164
Trained batch 18 in epoch 6, gen_loss = 0.5138794215101945, disc_loss = 0.09682406053731316
Trained batch 19 in epoch 6, gen_loss = 0.5167451083660126, disc_loss = 0.09429252464324236
Trained batch 20 in epoch 6, gen_loss = 0.5167191653024583, disc_loss = 0.09303120860741251
Trained batch 21 in epoch 6, gen_loss = 0.5173528329892592, disc_loss = 0.09267774850807407
Trained batch 22 in epoch 6, gen_loss = 0.5199060621468917, disc_loss = 0.09475174044137416
Trained batch 23 in epoch 6, gen_loss = 0.5202920883893967, disc_loss = 0.0963957509957254
Trained batch 24 in epoch 6, gen_loss = 0.5216114330291748, disc_loss = 0.09861443296074868
Trained batch 25 in epoch 6, gen_loss = 0.5256220744206355, disc_loss = 0.09925233816298154
Trained batch 26 in epoch 6, gen_loss = 0.5291224166199013, disc_loss = 0.0972430688087587
Trained batch 27 in epoch 6, gen_loss = 0.5295093506574631, disc_loss = 0.09713286999613047
Trained batch 28 in epoch 6, gen_loss = 0.5311060712255281, disc_loss = 0.09659500946772509
Trained batch 29 in epoch 6, gen_loss = 0.5300425092379252, disc_loss = 0.09775615396598974
Trained batch 30 in epoch 6, gen_loss = 0.529139026518791, disc_loss = 0.09778187892610027
Trained batch 31 in epoch 6, gen_loss = 0.5320932231843472, disc_loss = 0.09566742565948516
Trained batch 32 in epoch 6, gen_loss = 0.536499514724269, disc_loss = 0.09614952777822812
Trained batch 33 in epoch 6, gen_loss = 0.5333026621271583, disc_loss = 0.09877970738007742
Trained batch 34 in epoch 6, gen_loss = 0.5328680046967098, disc_loss = 0.09805882839219911
Trained batch 35 in epoch 6, gen_loss = 0.5353685211804178, disc_loss = 0.09656837820592853
Trained batch 36 in epoch 6, gen_loss = 0.5338147459803401, disc_loss = 0.09647757992953868
Trained batch 37 in epoch 6, gen_loss = 0.5386953636219627, disc_loss = 0.10003052622471985
Trained batch 38 in epoch 6, gen_loss = 0.5346711889291421, disc_loss = 0.10148573351594117
Trained batch 39 in epoch 6, gen_loss = 0.532062204927206, disc_loss = 0.10230336645618081
Trained batch 40 in epoch 6, gen_loss = 0.5353548228740692, disc_loss = 0.10807754362865192
Trained batch 41 in epoch 6, gen_loss = 0.5340663939714432, disc_loss = 0.10817833040796575
Trained batch 42 in epoch 6, gen_loss = 0.5311057297296302, disc_loss = 0.11157881182640098
Trained batch 43 in epoch 6, gen_loss = 0.531334207139232, disc_loss = 0.11238880396227945
Trained batch 44 in epoch 6, gen_loss = 0.5306944588820139, disc_loss = 0.11170802786946296
Trained batch 45 in epoch 6, gen_loss = 0.5309402975051299, disc_loss = 0.11148226722750974
Trained batch 46 in epoch 6, gen_loss = 0.5295375160714413, disc_loss = 0.1127915288064074
Trained batch 47 in epoch 6, gen_loss = 0.5310217992713054, disc_loss = 0.11437481308045487
Trained batch 48 in epoch 6, gen_loss = 0.5286817100583291, disc_loss = 0.11551167777910525
Trained batch 49 in epoch 6, gen_loss = 0.5285433232784271, disc_loss = 0.11473761148750782
Trained batch 50 in epoch 6, gen_loss = 0.5296623110771179, disc_loss = 0.11552385993155778
Trained batch 51 in epoch 6, gen_loss = 0.529739532333154, disc_loss = 0.11562622632258214
Trained batch 52 in epoch 6, gen_loss = 0.52838811334574, disc_loss = 0.11574484639853802
Trained batch 53 in epoch 6, gen_loss = 0.5304869700361181, disc_loss = 0.11483482706050079
Trained batch 54 in epoch 6, gen_loss = 0.5310153180902655, disc_loss = 0.11393982070413503
Trained batch 55 in epoch 6, gen_loss = 0.5296465983348233, disc_loss = 0.11375585298186966
Trained batch 56 in epoch 6, gen_loss = 0.5328887193872217, disc_loss = 0.11426734185793944
Trained batch 57 in epoch 6, gen_loss = 0.5326501937775776, disc_loss = 0.11333449473925705
Trained batch 58 in epoch 6, gen_loss = 0.5315783594624471, disc_loss = 0.11516229461057712
Trained batch 59 in epoch 6, gen_loss = 0.5328829343120257, disc_loss = 0.11531892201552789
Trained batch 60 in epoch 6, gen_loss = 0.5317516023995447, disc_loss = 0.11491435625758327
Trained batch 61 in epoch 6, gen_loss = 0.531859379622244, disc_loss = 0.11401470269887679
Trained batch 62 in epoch 6, gen_loss = 0.5337803335416884, disc_loss = 0.11312111609038852
Trained batch 63 in epoch 6, gen_loss = 0.5350442817434669, disc_loss = 0.11254529817961156
Trained batch 64 in epoch 6, gen_loss = 0.5343395453232985, disc_loss = 0.11208529678674845
Trained batch 65 in epoch 6, gen_loss = 0.5340828660762671, disc_loss = 0.11096820686802719
Trained batch 66 in epoch 6, gen_loss = 0.5340931371076784, disc_loss = 0.11005950235386393
Trained batch 67 in epoch 6, gen_loss = 0.5349469631910324, disc_loss = 0.10957392672186389
Trained batch 68 in epoch 6, gen_loss = 0.534854619399361, disc_loss = 0.10996387396817622
Trained batch 69 in epoch 6, gen_loss = 0.5349799454212188, disc_loss = 0.10916698101375784
Trained batch 70 in epoch 6, gen_loss = 0.5356481537012987, disc_loss = 0.1082082642635829
Trained batch 71 in epoch 6, gen_loss = 0.5359123407138718, disc_loss = 0.10735054893626107
Trained batch 72 in epoch 6, gen_loss = 0.5359944015333097, disc_loss = 0.10671473212846339
Trained batch 73 in epoch 6, gen_loss = 0.5377361339491766, disc_loss = 0.10593385672247088
Trained batch 74 in epoch 6, gen_loss = 0.539697241783142, disc_loss = 0.10473309700687726
Trained batch 75 in epoch 6, gen_loss = 0.5391348592544857, disc_loss = 0.10478127193882276
Trained batch 76 in epoch 6, gen_loss = 0.5411520553873731, disc_loss = 0.10395386844099343
Trained batch 77 in epoch 6, gen_loss = 0.5432052474755508, disc_loss = 0.10297086947143842
Trained batch 78 in epoch 6, gen_loss = 0.5441715762585024, disc_loss = 0.10184996279215888
Trained batch 79 in epoch 6, gen_loss = 0.5450882747769356, disc_loss = 0.10115907933795824
Trained batch 80 in epoch 6, gen_loss = 0.5467659750102479, disc_loss = 0.10011130331061137
Trained batch 81 in epoch 6, gen_loss = 0.5474770388952116, disc_loss = 0.09910021689379724
Trained batch 82 in epoch 6, gen_loss = 0.5483429927423776, disc_loss = 0.09853230294468532
Trained batch 83 in epoch 6, gen_loss = 0.5471899459759394, disc_loss = 0.09872126006077797
Trained batch 84 in epoch 6, gen_loss = 0.5481804714483374, disc_loss = 0.0996455910779974
Trained batch 85 in epoch 6, gen_loss = 0.5472697719585063, disc_loss = 0.09899778775654214
Trained batch 86 in epoch 6, gen_loss = 0.5459009967316156, disc_loss = 0.10014563446714618
Trained batch 87 in epoch 6, gen_loss = 0.5504083989018743, disc_loss = 0.1071039931742813
Trained batch 88 in epoch 6, gen_loss = 0.5490896115812023, disc_loss = 0.1095550035890401
Trained batch 89 in epoch 6, gen_loss = 0.5482438160313501, disc_loss = 0.11086098939801256
Trained batch 90 in epoch 6, gen_loss = 0.5483080522044674, disc_loss = 0.11146349917360387
Trained batch 91 in epoch 6, gen_loss = 0.5473384031135103, disc_loss = 0.11202980001942943
Trained batch 92 in epoch 6, gen_loss = 0.5467385297180504, disc_loss = 0.11284463771528774
Trained batch 93 in epoch 6, gen_loss = 0.5457136396397936, disc_loss = 0.11333302241016893
Trained batch 94 in epoch 6, gen_loss = 0.5452416576837239, disc_loss = 0.11373614016920328
Trained batch 95 in epoch 6, gen_loss = 0.5448855298260847, disc_loss = 0.11385481857966322
Trained batch 96 in epoch 6, gen_loss = 0.5440091595207293, disc_loss = 0.11407262738794088
Trained batch 97 in epoch 6, gen_loss = 0.5436822163815401, disc_loss = 0.11392685062993242
Trained batch 98 in epoch 6, gen_loss = 0.5440622760791971, disc_loss = 0.11336793997936477
Trained batch 99 in epoch 6, gen_loss = 0.5438182866573333, disc_loss = 0.11330135180614889
Trained batch 100 in epoch 6, gen_loss = 0.5426556727673748, disc_loss = 0.11363201919426717
Trained batch 101 in epoch 6, gen_loss = 0.5426849214469686, disc_loss = 0.11338214370805551
Trained batch 102 in epoch 6, gen_loss = 0.5417884811035638, disc_loss = 0.11332333188286974
Trained batch 103 in epoch 6, gen_loss = 0.5411233248618933, disc_loss = 0.11310584197501437
Trained batch 104 in epoch 6, gen_loss = 0.5405180394649506, disc_loss = 0.11245675313153437
Trained batch 105 in epoch 6, gen_loss = 0.540667713531908, disc_loss = 0.11256254505682385
Trained batch 106 in epoch 6, gen_loss = 0.5404132679801121, disc_loss = 0.11240689184029247
Trained batch 107 in epoch 6, gen_loss = 0.540002516022435, disc_loss = 0.11210213324779437
Trained batch 108 in epoch 6, gen_loss = 0.5400728938776419, disc_loss = 0.11176126100840646
Trained batch 109 in epoch 6, gen_loss = 0.5390163432468068, disc_loss = 0.11178408345546234
Trained batch 110 in epoch 6, gen_loss = 0.5382954276896812, disc_loss = 0.11141020542027445
Trained batch 111 in epoch 6, gen_loss = 0.5388622930539506, disc_loss = 0.11146947361495611
Trained batch 112 in epoch 6, gen_loss = 0.538877656238269, disc_loss = 0.1110334069904896
Trained batch 113 in epoch 6, gen_loss = 0.5393964080956944, disc_loss = 0.11035700840875506
Trained batch 114 in epoch 6, gen_loss = 0.5399302770262179, disc_loss = 0.11002131861675045
Trained batch 115 in epoch 6, gen_loss = 0.5395627648665987, disc_loss = 0.10974705372615878
Trained batch 116 in epoch 6, gen_loss = 0.5398183342738029, disc_loss = 0.10914707654275191
Trained batch 117 in epoch 6, gen_loss = 0.5409025140738083, disc_loss = 0.10933569956854997
Trained batch 118 in epoch 6, gen_loss = 0.5407649934792719, disc_loss = 0.1092558904402271
Trained batch 119 in epoch 6, gen_loss = 0.5417653088768323, disc_loss = 0.10954071152179191
Trained batch 120 in epoch 6, gen_loss = 0.5407412510272885, disc_loss = 0.11035136317387839
Trained batch 121 in epoch 6, gen_loss = 0.5415208750083799, disc_loss = 0.10994126891228752
Trained batch 122 in epoch 6, gen_loss = 0.542011264863053, disc_loss = 0.11010701578049882
Trained batch 123 in epoch 6, gen_loss = 0.541144632764401, disc_loss = 0.10988701554766346
Trained batch 124 in epoch 6, gen_loss = 0.5405227429866791, disc_loss = 0.10979551213234663
Trained batch 125 in epoch 6, gen_loss = 0.5407908357798107, disc_loss = 0.11016789474154985
Trained batch 126 in epoch 6, gen_loss = 0.5401024567329977, disc_loss = 0.1100456361387541
Trained batch 127 in epoch 6, gen_loss = 0.5411121968645602, disc_loss = 0.10948937819193816
Trained batch 128 in epoch 6, gen_loss = 0.5411233530026074, disc_loss = 0.10912172024881886
Trained batch 129 in epoch 6, gen_loss = 0.5414891951359235, disc_loss = 0.1087713876237663
Trained batch 130 in epoch 6, gen_loss = 0.5411430576830419, disc_loss = 0.10850743832109311
Trained batch 131 in epoch 6, gen_loss = 0.5409119108861143, disc_loss = 0.10838766956955871
Trained batch 132 in epoch 6, gen_loss = 0.542010428986155, disc_loss = 0.10793078079455554
Trained batch 133 in epoch 6, gen_loss = 0.5413113163033528, disc_loss = 0.1080535604590689
Trained batch 134 in epoch 6, gen_loss = 0.5437835187823684, disc_loss = 0.10898851784705012
Trained batch 135 in epoch 6, gen_loss = 0.5441869543317486, disc_loss = 0.11074590452207143
Trained batch 136 in epoch 6, gen_loss = 0.5438045385110117, disc_loss = 0.11296808642817892
Trained batch 137 in epoch 6, gen_loss = 0.5445985629938651, disc_loss = 0.11373050607389946
Trained batch 138 in epoch 6, gen_loss = 0.545099301303891, disc_loss = 0.11401420573724046
Trained batch 139 in epoch 6, gen_loss = 0.5453209297997611, disc_loss = 0.11413605616960143
Trained batch 140 in epoch 6, gen_loss = 0.5454067515988722, disc_loss = 0.11375338454063691
Trained batch 141 in epoch 6, gen_loss = 0.5462086158739009, disc_loss = 0.11336138605100798
Trained batch 142 in epoch 6, gen_loss = 0.5459103855219755, disc_loss = 0.11308407243601717
Trained batch 143 in epoch 6, gen_loss = 0.5457302398151822, disc_loss = 0.11307763134310436
Trained batch 144 in epoch 6, gen_loss = 0.5459026196907306, disc_loss = 0.11284960849403307
Trained batch 145 in epoch 6, gen_loss = 0.545844455696132, disc_loss = 0.11288766314798634
Trained batch 146 in epoch 6, gen_loss = 0.5453675892077335, disc_loss = 0.11284296287439105
Trained batch 147 in epoch 6, gen_loss = 0.545575929251877, disc_loss = 0.11238105531555374
Trained batch 148 in epoch 6, gen_loss = 0.5466669209851515, disc_loss = 0.11214797105640173
Trained batch 149 in epoch 6, gen_loss = 0.546289330124855, disc_loss = 0.11219672001277407
Trained batch 150 in epoch 6, gen_loss = 0.5459166038904758, disc_loss = 0.11188782408019367
Trained batch 151 in epoch 6, gen_loss = 0.5461735631290235, disc_loss = 0.11194487800208949
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.5039536952972412, disc_loss = 0.03754774108529091
Trained batch 1 in epoch 7, gen_loss = 0.5052030384540558, disc_loss = 0.06632175110280514
Trained batch 2 in epoch 7, gen_loss = 0.5785173376401266, disc_loss = 0.09063783660531044
Trained batch 3 in epoch 7, gen_loss = 0.5800436735153198, disc_loss = 0.07235521217808127
Trained batch 4 in epoch 7, gen_loss = 0.5518912851810456, disc_loss = 0.11412242166697979
Trained batch 5 in epoch 7, gen_loss = 0.5460798591375351, disc_loss = 0.10202254572262366
Trained batch 6 in epoch 7, gen_loss = 0.5370198615959713, disc_loss = 0.10075247793325356
Trained batch 7 in epoch 7, gen_loss = 0.5270154662430286, disc_loss = 0.10408027726225555
Trained batch 8 in epoch 7, gen_loss = 0.5360623233848147, disc_loss = 0.1082355435937643
Trained batch 9 in epoch 7, gen_loss = 0.549001756310463, disc_loss = 0.100601458363235
Trained batch 10 in epoch 7, gen_loss = 0.5640232048251412, disc_loss = 0.09370919757268646
Trained batch 11 in epoch 7, gen_loss = 0.5556405087312063, disc_loss = 0.10507982938239972
Trained batch 12 in epoch 7, gen_loss = 0.5547117453355056, disc_loss = 0.10947874389015712
Trained batch 13 in epoch 7, gen_loss = 0.5612789137022836, disc_loss = 0.1039457278592246
Trained batch 14 in epoch 7, gen_loss = 0.5558354258537292, disc_loss = 0.10378301242987314
Trained batch 15 in epoch 7, gen_loss = 0.5635851100087166, disc_loss = 0.09835404832847416
Trained batch 16 in epoch 7, gen_loss = 0.5645280585569494, disc_loss = 0.09461802682455848
Trained batch 17 in epoch 7, gen_loss = 0.5603537609179815, disc_loss = 0.09444191306829453
Trained batch 18 in epoch 7, gen_loss = 0.5581673587623396, disc_loss = 0.09658688855798621
Trained batch 19 in epoch 7, gen_loss = 0.5568486824631691, disc_loss = 0.09385811798274517
Trained batch 20 in epoch 7, gen_loss = 0.552912868204571, disc_loss = 0.09321010361115138
Trained batch 21 in epoch 7, gen_loss = 0.5569170198657296, disc_loss = 0.0932100923223929
Trained batch 22 in epoch 7, gen_loss = 0.5558720542036969, disc_loss = 0.09256371855735779
Trained batch 23 in epoch 7, gen_loss = 0.5529939370850722, disc_loss = 0.09392450749874115
Trained batch 24 in epoch 7, gen_loss = 0.5518589007854462, disc_loss = 0.09322686076164245
Trained batch 25 in epoch 7, gen_loss = 0.5488127321004868, disc_loss = 0.09259023631994541
Trained batch 26 in epoch 7, gen_loss = 0.5484160747792985, disc_loss = 0.09194179927861248
Trained batch 27 in epoch 7, gen_loss = 0.547142760029861, disc_loss = 0.09136542385177952
Trained batch 28 in epoch 7, gen_loss = 0.5483696265467282, disc_loss = 0.09094145894050598
Trained batch 29 in epoch 7, gen_loss = 0.547556671500206, disc_loss = 0.0902845174074173
Trained batch 30 in epoch 7, gen_loss = 0.5489478120880742, disc_loss = 0.088740955557554
Trained batch 31 in epoch 7, gen_loss = 0.5467934599146247, disc_loss = 0.08757790748495609
Trained batch 32 in epoch 7, gen_loss = 0.5435169212745897, disc_loss = 0.08947245697631981
Trained batch 33 in epoch 7, gen_loss = 0.5453017143642201, disc_loss = 0.093635927337934
Trained batch 34 in epoch 7, gen_loss = 0.5524483936173575, disc_loss = 0.09241953864693642
Trained batch 35 in epoch 7, gen_loss = 0.5500094931986597, disc_loss = 0.09419719864510828
Trained batch 36 in epoch 7, gen_loss = 0.5514559238343626, disc_loss = 0.09281844806832236
Trained batch 37 in epoch 7, gen_loss = 0.5534721510974985, disc_loss = 0.09323999168057191
Trained batch 38 in epoch 7, gen_loss = 0.5519058406352997, disc_loss = 0.09191773631251775
Trained batch 39 in epoch 7, gen_loss = 0.5519546933472157, disc_loss = 0.09016772443428636
Trained batch 40 in epoch 7, gen_loss = 0.5494303906836161, disc_loss = 0.09105634262285582
Trained batch 41 in epoch 7, gen_loss = 0.5552524910086677, disc_loss = 0.09354630227954615
Trained batch 42 in epoch 7, gen_loss = 0.5514212403186532, disc_loss = 0.09883527050531188
Trained batch 43 in epoch 7, gen_loss = 0.5548243251713839, disc_loss = 0.09828833278945902
Trained batch 44 in epoch 7, gen_loss = 0.5568993634647793, disc_loss = 0.09719823242889511
Trained batch 45 in epoch 7, gen_loss = 0.5571612728678662, disc_loss = 0.09624581443874733
Trained batch 46 in epoch 7, gen_loss = 0.5579230366869176, disc_loss = 0.09473199983860583
Trained batch 47 in epoch 7, gen_loss = 0.5569782840708891, disc_loss = 0.0942656947299838
Trained batch 48 in epoch 7, gen_loss = 0.5583127432939957, disc_loss = 0.09404688860688891
Trained batch 49 in epoch 7, gen_loss = 0.5573806226253509, disc_loss = 0.0937337489426136
Trained batch 50 in epoch 7, gen_loss = 0.559684789648243, disc_loss = 0.09230290397125132
Trained batch 51 in epoch 7, gen_loss = 0.55760396615817, disc_loss = 0.09366415885205452
Trained batch 52 in epoch 7, gen_loss = 0.5614213769165974, disc_loss = 0.09413384589946495
Trained batch 53 in epoch 7, gen_loss = 0.5628518246942096, disc_loss = 0.09336325277884801
Trained batch 54 in epoch 7, gen_loss = 0.5630304699594324, disc_loss = 0.09326275370337746
Trained batch 55 in epoch 7, gen_loss = 0.5600661896169186, disc_loss = 0.09613747256142753
Trained batch 56 in epoch 7, gen_loss = 0.5627073577621526, disc_loss = 0.09817011785088924
Trained batch 57 in epoch 7, gen_loss = 0.5639083143965952, disc_loss = 0.09762904895790692
Trained batch 58 in epoch 7, gen_loss = 0.5633995831012726, disc_loss = 0.09687974190307876
Trained batch 59 in epoch 7, gen_loss = 0.5617044925689697, disc_loss = 0.09659002249439558
Trained batch 60 in epoch 7, gen_loss = 0.5603813445958935, disc_loss = 0.09617286346486358
Trained batch 61 in epoch 7, gen_loss = 0.5596605496060464, disc_loss = 0.0967834593067246
Trained batch 62 in epoch 7, gen_loss = 0.559346571328148, disc_loss = 0.09689951605266994
Trained batch 63 in epoch 7, gen_loss = 0.5585614866577089, disc_loss = 0.09696903312578797
Trained batch 64 in epoch 7, gen_loss = 0.556611883181792, disc_loss = 0.09893833994865417
Trained batch 65 in epoch 7, gen_loss = 0.5599227055455699, disc_loss = 0.10077341262138251
Trained batch 66 in epoch 7, gen_loss = 0.5574493408203125, disc_loss = 0.10360902948166008
Trained batch 67 in epoch 7, gen_loss = 0.5576261834186667, disc_loss = 0.10324748484965633
Trained batch 68 in epoch 7, gen_loss = 0.5578674812247788, disc_loss = 0.10345730109923128
Trained batch 69 in epoch 7, gen_loss = 0.5578041017055512, disc_loss = 0.10301434110317911
Trained batch 70 in epoch 7, gen_loss = 0.556409886185552, disc_loss = 0.10406425647752386
Trained batch 71 in epoch 7, gen_loss = 0.5546267206470171, disc_loss = 0.10436308352897565
Trained batch 72 in epoch 7, gen_loss = 0.5551478250385964, disc_loss = 0.10392710760439912
Trained batch 73 in epoch 7, gen_loss = 0.5547733314939447, disc_loss = 0.1033056994547715
Trained batch 74 in epoch 7, gen_loss = 0.5537937593460083, disc_loss = 0.10399966557820638
Trained batch 75 in epoch 7, gen_loss = 0.5531044853361029, disc_loss = 0.10362323373556137
Trained batch 76 in epoch 7, gen_loss = 0.5535203984805516, disc_loss = 0.10287534048804989
Trained batch 77 in epoch 7, gen_loss = 0.5542376553400968, disc_loss = 0.1025934555591681
Trained batch 78 in epoch 7, gen_loss = 0.5535259454310695, disc_loss = 0.10230807318717619
Trained batch 79 in epoch 7, gen_loss = 0.5522157616913319, disc_loss = 0.10248487200587988
Trained batch 80 in epoch 7, gen_loss = 0.5548471484655215, disc_loss = 0.10424688495235679
Trained batch 81 in epoch 7, gen_loss = 0.5547509375141888, disc_loss = 0.10332688343961065
Trained batch 82 in epoch 7, gen_loss = 0.5529744032635746, disc_loss = 0.10544599987656238
Trained batch 83 in epoch 7, gen_loss = 0.5530872781361852, disc_loss = 0.10600442350620315
Trained batch 84 in epoch 7, gen_loss = 0.5522912803818197, disc_loss = 0.10679116161430584
Trained batch 85 in epoch 7, gen_loss = 0.5513704381016797, disc_loss = 0.10676338549616725
Trained batch 86 in epoch 7, gen_loss = 0.551119203197545, disc_loss = 0.10662719410383838
Trained batch 87 in epoch 7, gen_loss = 0.5521021420982751, disc_loss = 0.10707362800497901
Trained batch 88 in epoch 7, gen_loss = 0.5512135166130708, disc_loss = 0.10644233172361771
Trained batch 89 in epoch 7, gen_loss = 0.5503107809358173, disc_loss = 0.10659194211992952
Trained batch 90 in epoch 7, gen_loss = 0.5504193931490511, disc_loss = 0.10692403821663542
Trained batch 91 in epoch 7, gen_loss = 0.5499281024803286, disc_loss = 0.10675616857960173
Trained batch 92 in epoch 7, gen_loss = 0.549802376057512, disc_loss = 0.10669500376748782
Trained batch 93 in epoch 7, gen_loss = 0.5493321314137033, disc_loss = 0.10666072974972268
Trained batch 94 in epoch 7, gen_loss = 0.5489080344375811, disc_loss = 0.10700343882567004
Trained batch 95 in epoch 7, gen_loss = 0.5486867536480228, disc_loss = 0.10721082461532205
Trained batch 96 in epoch 7, gen_loss = 0.5471477480893282, disc_loss = 0.10790113156142923
Trained batch 97 in epoch 7, gen_loss = 0.5474297145799715, disc_loss = 0.10762648022144425
Trained batch 98 in epoch 7, gen_loss = 0.5480279799061593, disc_loss = 0.10681933499496392
Trained batch 99 in epoch 7, gen_loss = 0.5475183823704719, disc_loss = 0.10715761993080378
Trained batch 100 in epoch 7, gen_loss = 0.5466078245403743, disc_loss = 0.10747354695259935
Trained batch 101 in epoch 7, gen_loss = 0.5480995502542046, disc_loss = 0.10699885575940796
Trained batch 102 in epoch 7, gen_loss = 0.5474899784453864, disc_loss = 0.10690147795000123
Trained batch 103 in epoch 7, gen_loss = 0.5476287732330652, disc_loss = 0.10668127579041399
Trained batch 104 in epoch 7, gen_loss = 0.548239151920591, disc_loss = 0.1062708851482187
Trained batch 105 in epoch 7, gen_loss = 0.5482640505399344, disc_loss = 0.10569837847548835
Trained batch 106 in epoch 7, gen_loss = 0.5486855208873749, disc_loss = 0.1050060644188774
Trained batch 107 in epoch 7, gen_loss = 0.5494136625417957, disc_loss = 0.10427745019465133
Trained batch 108 in epoch 7, gen_loss = 0.5498964368203364, disc_loss = 0.10384957828994738
Trained batch 109 in epoch 7, gen_loss = 0.5502118519761345, disc_loss = 0.10355537914755669
Trained batch 110 in epoch 7, gen_loss = 0.5487689614832938, disc_loss = 0.10586572366321946
Trained batch 111 in epoch 7, gen_loss = 0.5495380282934222, disc_loss = 0.1063100888693173
Trained batch 112 in epoch 7, gen_loss = 0.548838000909417, disc_loss = 0.10615083761513233
Trained batch 113 in epoch 7, gen_loss = 0.5476722641472231, disc_loss = 0.1066942548444658
Trained batch 114 in epoch 7, gen_loss = 0.5475691414397695, disc_loss = 0.10670158858208553
Trained batch 115 in epoch 7, gen_loss = 0.5479875666827991, disc_loss = 0.10746474726254056
Trained batch 116 in epoch 7, gen_loss = 0.5471724832159841, disc_loss = 0.10728751302848005
Trained batch 117 in epoch 7, gen_loss = 0.5471916168423022, disc_loss = 0.10729563957616939
Trained batch 118 in epoch 7, gen_loss = 0.5476971924805841, disc_loss = 0.10711901880675505
Trained batch 119 in epoch 7, gen_loss = 0.5471609853208065, disc_loss = 0.10651477002538741
Trained batch 120 in epoch 7, gen_loss = 0.5467157822009946, disc_loss = 0.10624698849687399
Trained batch 121 in epoch 7, gen_loss = 0.5464103715341599, disc_loss = 0.10605892122219332
Trained batch 122 in epoch 7, gen_loss = 0.5464963089159833, disc_loss = 0.10650570483166512
Trained batch 123 in epoch 7, gen_loss = 0.5460628742171872, disc_loss = 0.10606844877944357
Trained batch 124 in epoch 7, gen_loss = 0.5450351278781891, disc_loss = 0.10620128439366817
Trained batch 125 in epoch 7, gen_loss = 0.5451732847898726, disc_loss = 0.10580247242949785
Trained batch 126 in epoch 7, gen_loss = 0.5466469730448535, disc_loss = 0.10644166821276578
Trained batch 127 in epoch 7, gen_loss = 0.5455538537353277, disc_loss = 0.10696671057667118
Trained batch 128 in epoch 7, gen_loss = 0.5447392546853354, disc_loss = 0.10699264495814031
Trained batch 129 in epoch 7, gen_loss = 0.5453212572978093, disc_loss = 0.1068798964843154
Trained batch 130 in epoch 7, gen_loss = 0.5448320876551038, disc_loss = 0.10666294366064417
Trained batch 131 in epoch 7, gen_loss = 0.5449700346498778, disc_loss = 0.10618828393688257
Trained batch 132 in epoch 7, gen_loss = 0.5455694368907383, disc_loss = 0.10560032928404503
Trained batch 133 in epoch 7, gen_loss = 0.5459627918343046, disc_loss = 0.10500395281323746
Trained batch 134 in epoch 7, gen_loss = 0.5456921361110828, disc_loss = 0.10479522706181915
Trained batch 135 in epoch 7, gen_loss = 0.5458270727711565, disc_loss = 0.10443899473723244
Trained batch 136 in epoch 7, gen_loss = 0.54605070430867, disc_loss = 0.10399878155576052
Trained batch 137 in epoch 7, gen_loss = 0.5458592724972877, disc_loss = 0.10374004566583081
Trained batch 138 in epoch 7, gen_loss = 0.5465760792759683, disc_loss = 0.10387936824088474
Trained batch 139 in epoch 7, gen_loss = 0.5454833984375, disc_loss = 0.10486058379922594
Trained batch 140 in epoch 7, gen_loss = 0.5452777663021223, disc_loss = 0.10464985436158823
Trained batch 141 in epoch 7, gen_loss = 0.545916306300902, disc_loss = 0.10517677822163407
Trained batch 142 in epoch 7, gen_loss = 0.545667115624968, disc_loss = 0.1047695917370436
Trained batch 143 in epoch 7, gen_loss = 0.5458000467883216, disc_loss = 0.10437181410897109
Trained batch 144 in epoch 7, gen_loss = 0.5458851238776897, disc_loss = 0.10432696255116627
Trained batch 145 in epoch 7, gen_loss = 0.545562844570369, disc_loss = 0.10432564390644636
Trained batch 146 in epoch 7, gen_loss = 0.5456533768550068, disc_loss = 0.10401225609540128
Trained batch 147 in epoch 7, gen_loss = 0.5458025275855451, disc_loss = 0.10375248829557283
Trained batch 148 in epoch 7, gen_loss = 0.5455173098000904, disc_loss = 0.1033755982132166
Trained batch 149 in epoch 7, gen_loss = 0.5470564409097036, disc_loss = 0.10309880629181861
Trained batch 150 in epoch 7, gen_loss = 0.5463058198524626, disc_loss = 0.1032169373915685
Trained batch 151 in epoch 7, gen_loss = 0.5462390353020868, disc_loss = 0.10282224014793571
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.6721595525741577, disc_loss = 0.07095824927091599
Trained batch 1 in epoch 8, gen_loss = 0.6089131832122803, disc_loss = 0.056452615186572075
Trained batch 2 in epoch 8, gen_loss = 0.5561793446540833, disc_loss = 0.08024699861804645
Trained batch 3 in epoch 8, gen_loss = 0.5971538722515106, disc_loss = 0.07272082287818193
Trained batch 4 in epoch 8, gen_loss = 0.5916168451309204, disc_loss = 0.06543340906500816
Trained batch 5 in epoch 8, gen_loss = 0.5922952691713969, disc_loss = 0.0598740316927433
Trained batch 6 in epoch 8, gen_loss = 0.5830890536308289, disc_loss = 0.06115004526717322
Trained batch 7 in epoch 8, gen_loss = 0.5813541784882545, disc_loss = 0.07072964403778315
Trained batch 8 in epoch 8, gen_loss = 0.5681880778736539, disc_loss = 0.09255742447243796
Trained batch 9 in epoch 8, gen_loss = 0.5759340167045593, disc_loss = 0.11116591766476631
Trained batch 10 in epoch 8, gen_loss = 0.5622630471532996, disc_loss = 0.11883662844246085
Trained batch 11 in epoch 8, gen_loss = 0.5569558963179588, disc_loss = 0.1224095094949007
Trained batch 12 in epoch 8, gen_loss = 0.5739425351986518, disc_loss = 0.1355824533563394
Trained batch 13 in epoch 8, gen_loss = 0.576393478683063, disc_loss = 0.12796919101050921
Trained batch 14 in epoch 8, gen_loss = 0.5697543084621429, disc_loss = 0.13071447362502417
Trained batch 15 in epoch 8, gen_loss = 0.5636029224842787, disc_loss = 0.1275170580483973
Trained batch 16 in epoch 8, gen_loss = 0.5619221592650694, disc_loss = 0.12478637476177777
Trained batch 17 in epoch 8, gen_loss = 0.5650274803241094, disc_loss = 0.1241049857603179
Trained batch 18 in epoch 8, gen_loss = 0.5622530908961045, disc_loss = 0.12750592043525294
Trained batch 19 in epoch 8, gen_loss = 0.5567714273929596, disc_loss = 0.1274821162223816
Trained batch 20 in epoch 8, gen_loss = 0.5624016977491832, disc_loss = 0.12499254445234935
Trained batch 21 in epoch 8, gen_loss = 0.5549403510310433, disc_loss = 0.12653676014054904
Trained batch 22 in epoch 8, gen_loss = 0.5587441221527432, disc_loss = 0.1308220359294311
Trained batch 23 in epoch 8, gen_loss = 0.5565226500233015, disc_loss = 0.12916256984074911
Trained batch 24 in epoch 8, gen_loss = 0.5533264100551605, disc_loss = 0.1278469318151474
Trained batch 25 in epoch 8, gen_loss = 0.5507218230229157, disc_loss = 0.1257725220460158
Trained batch 26 in epoch 8, gen_loss = 0.5480934138651248, disc_loss = 0.1238080025823028
Trained batch 27 in epoch 8, gen_loss = 0.5496846735477448, disc_loss = 0.12085942351924521
Trained batch 28 in epoch 8, gen_loss = 0.5491911707253292, disc_loss = 0.11838453956719103
Trained batch 29 in epoch 8, gen_loss = 0.5482308705647786, disc_loss = 0.11627330022553603
Trained batch 30 in epoch 8, gen_loss = 0.5456170487788415, disc_loss = 0.11522696443623112
Trained batch 31 in epoch 8, gen_loss = 0.5472913207486272, disc_loss = 0.11309768236242235
Trained batch 32 in epoch 8, gen_loss = 0.5505313340461615, disc_loss = 0.11131194019407938
Trained batch 33 in epoch 8, gen_loss = 0.5487400503719554, disc_loss = 0.1114985422395608
Trained batch 34 in epoch 8, gen_loss = 0.5496617657797677, disc_loss = 0.10957023214016642
Trained batch 35 in epoch 8, gen_loss = 0.5544536262750626, disc_loss = 0.11355788146870004
Trained batch 36 in epoch 8, gen_loss = 0.5495967494474875, disc_loss = 0.11576744078381641
Trained batch 37 in epoch 8, gen_loss = 0.5468470532643167, disc_loss = 0.11545010803169325
Trained batch 38 in epoch 8, gen_loss = 0.5477079733824118, disc_loss = 0.1158780496663008
Trained batch 39 in epoch 8, gen_loss = 0.5483940348029137, disc_loss = 0.113938317168504
Trained batch 40 in epoch 8, gen_loss = 0.5467835388532499, disc_loss = 0.11342522365654387
Trained batch 41 in epoch 8, gen_loss = 0.5481188765593937, disc_loss = 0.11242686983730112
Trained batch 42 in epoch 8, gen_loss = 0.5494440128636915, disc_loss = 0.11020283019819925
Trained batch 43 in epoch 8, gen_loss = 0.549293111671101, disc_loss = 0.10885891115123575
Trained batch 44 in epoch 8, gen_loss = 0.5495752652486166, disc_loss = 0.10818594959047105
Trained batch 45 in epoch 8, gen_loss = 0.5546382445356121, disc_loss = 0.11084341905687166
Trained batch 46 in epoch 8, gen_loss = 0.5539561725677328, disc_loss = 0.11044606946884318
Trained batch 47 in epoch 8, gen_loss = 0.5504541459182898, disc_loss = 0.11194008930275838
Trained batch 48 in epoch 8, gen_loss = 0.5521407139544584, disc_loss = 0.1140721114922543
Trained batch 49 in epoch 8, gen_loss = 0.5494723123311996, disc_loss = 0.1136047138273716
Trained batch 50 in epoch 8, gen_loss = 0.547531803448995, disc_loss = 0.11310878396034241
Trained batch 51 in epoch 8, gen_loss = 0.547270886026896, disc_loss = 0.11255199920672637
Trained batch 52 in epoch 8, gen_loss = 0.5461240781928008, disc_loss = 0.11194854271861743
Trained batch 53 in epoch 8, gen_loss = 0.5447275726883499, disc_loss = 0.1120746771770495
Trained batch 54 in epoch 8, gen_loss = 0.5451719630848277, disc_loss = 0.1128967210650444
Trained batch 55 in epoch 8, gen_loss = 0.5442515569073814, disc_loss = 0.11185465353940215
Trained batch 56 in epoch 8, gen_loss = 0.5440713292674014, disc_loss = 0.11088909097669418
Trained batch 57 in epoch 8, gen_loss = 0.5443003177642822, disc_loss = 0.11129193515356245
Trained batch 58 in epoch 8, gen_loss = 0.5431138817536629, disc_loss = 0.11123292621667102
Trained batch 59 in epoch 8, gen_loss = 0.5430231735110282, disc_loss = 0.1101976331944267
Trained batch 60 in epoch 8, gen_loss = 0.5451064661878054, disc_loss = 0.10901227477388303
Trained batch 61 in epoch 8, gen_loss = 0.5429408708887715, disc_loss = 0.10924500929972818
Trained batch 62 in epoch 8, gen_loss = 0.5427424978642237, disc_loss = 0.10912951170688584
Trained batch 63 in epoch 8, gen_loss = 0.5449871853925288, disc_loss = 0.10944795637624338
Trained batch 64 in epoch 8, gen_loss = 0.544048489515598, disc_loss = 0.11111787769656915
Trained batch 65 in epoch 8, gen_loss = 0.5448513550288749, disc_loss = 0.11318204354381922
Trained batch 66 in epoch 8, gen_loss = 0.5448468767884952, disc_loss = 0.11483554391941028
Trained batch 67 in epoch 8, gen_loss = 0.5439783702878391, disc_loss = 0.11606074151966501
Trained batch 68 in epoch 8, gen_loss = 0.5450932081194891, disc_loss = 0.11784851016557735
Trained batch 69 in epoch 8, gen_loss = 0.5449422359466553, disc_loss = 0.11771253948765141
Trained batch 70 in epoch 8, gen_loss = 0.5437390044541426, disc_loss = 0.11797815146790423
Trained batch 71 in epoch 8, gen_loss = 0.5464155504273044, disc_loss = 0.11887388929931654
Trained batch 72 in epoch 8, gen_loss = 0.5452964816191425, disc_loss = 0.11868096117491592
Trained batch 73 in epoch 8, gen_loss = 0.5441852429428616, disc_loss = 0.11791393095375718
Trained batch 74 in epoch 8, gen_loss = 0.5437332566579183, disc_loss = 0.11713407581051191
Trained batch 75 in epoch 8, gen_loss = 0.5429836739050714, disc_loss = 0.11702935167245175
Trained batch 76 in epoch 8, gen_loss = 0.5453819926683005, disc_loss = 0.11653847397341356
Trained batch 77 in epoch 8, gen_loss = 0.5461553740195739, disc_loss = 0.11545128676180656
Trained batch 78 in epoch 8, gen_loss = 0.544063661671892, disc_loss = 0.11693290984140167
Trained batch 79 in epoch 8, gen_loss = 0.5442007161676884, disc_loss = 0.11628303355537355
Trained batch 80 in epoch 8, gen_loss = 0.5460520548585021, disc_loss = 0.11708068695885164
Trained batch 81 in epoch 8, gen_loss = 0.5455230009265062, disc_loss = 0.11714809456067841
Trained batch 82 in epoch 8, gen_loss = 0.5445527215319944, disc_loss = 0.11713779443897397
Trained batch 83 in epoch 8, gen_loss = 0.5442093053743953, disc_loss = 0.11668509790407759
Trained batch 84 in epoch 8, gen_loss = 0.5441249928053687, disc_loss = 0.11576905728263014
Trained batch 85 in epoch 8, gen_loss = 0.5436392007179038, disc_loss = 0.11533442992976932
Trained batch 86 in epoch 8, gen_loss = 0.5439026612659981, disc_loss = 0.1152681424443064
Trained batch 87 in epoch 8, gen_loss = 0.5430394617671316, disc_loss = 0.11522850271483714
Trained batch 88 in epoch 8, gen_loss = 0.5432836771681068, disc_loss = 0.1145288474606664
Trained batch 89 in epoch 8, gen_loss = 0.5440898540947172, disc_loss = 0.11493289214041498
Trained batch 90 in epoch 8, gen_loss = 0.5433340645753421, disc_loss = 0.11499981336541228
Trained batch 91 in epoch 8, gen_loss = 0.5428013506790866, disc_loss = 0.11508576296593832
Trained batch 92 in epoch 8, gen_loss = 0.5435469358839015, disc_loss = 0.11428962748057099
Trained batch 93 in epoch 8, gen_loss = 0.5441372809892006, disc_loss = 0.11338138217700923
Trained batch 94 in epoch 8, gen_loss = 0.5442230321859058, disc_loss = 0.11251797344731657
Trained batch 95 in epoch 8, gen_loss = 0.5437606995304426, disc_loss = 0.11206787147481616
Trained batch 96 in epoch 8, gen_loss = 0.5444197974254176, disc_loss = 0.11109278418277342
Trained batch 97 in epoch 8, gen_loss = 0.54605698342226, disc_loss = 0.11173238055970595
Trained batch 98 in epoch 8, gen_loss = 0.5450183893695022, disc_loss = 0.11172054442718174
Trained batch 99 in epoch 8, gen_loss = 0.5441506114602089, disc_loss = 0.1116462573222816
Trained batch 100 in epoch 8, gen_loss = 0.5449045368350378, disc_loss = 0.1112500300612485
Trained batch 101 in epoch 8, gen_loss = 0.5458428155557782, disc_loss = 0.112167550342194
Trained batch 102 in epoch 8, gen_loss = 0.5453377791400095, disc_loss = 0.11215313008615693
Trained batch 103 in epoch 8, gen_loss = 0.5443946392490313, disc_loss = 0.11188946891790973
Trained batch 104 in epoch 8, gen_loss = 0.5447033121472313, disc_loss = 0.11256191033337798
Trained batch 105 in epoch 8, gen_loss = 0.5443385603292933, disc_loss = 0.11222237698241787
Trained batch 106 in epoch 8, gen_loss = 0.5435959827677111, disc_loss = 0.11208008590076014
Trained batch 107 in epoch 8, gen_loss = 0.543521583908134, disc_loss = 0.11167077856414297
Trained batch 108 in epoch 8, gen_loss = 0.5441290257720772, disc_loss = 0.11131609168006193
Trained batch 109 in epoch 8, gen_loss = 0.5436063362793488, disc_loss = 0.11079679217866877
Trained batch 110 in epoch 8, gen_loss = 0.5433159371217092, disc_loss = 0.11005832682791594
Trained batch 111 in epoch 8, gen_loss = 0.5445315675543887, disc_loss = 0.11073395528364927
Trained batch 112 in epoch 8, gen_loss = 0.5431064522899358, disc_loss = 0.11156621151727385
Trained batch 113 in epoch 8, gen_loss = 0.5430592996509451, disc_loss = 0.11084677796941578
Trained batch 114 in epoch 8, gen_loss = 0.5434137201827506, disc_loss = 0.11103195167430069
Trained batch 115 in epoch 8, gen_loss = 0.5425681659373743, disc_loss = 0.11108605256946437
Trained batch 116 in epoch 8, gen_loss = 0.5426577291427515, disc_loss = 0.11053013191837022
Trained batch 117 in epoch 8, gen_loss = 0.5435021128189765, disc_loss = 0.11005330668225632
Trained batch 118 in epoch 8, gen_loss = 0.543434309608796, disc_loss = 0.10979660858689737
Trained batch 119 in epoch 8, gen_loss = 0.5440244225164255, disc_loss = 0.10915492457958559
Trained batch 120 in epoch 8, gen_loss = 0.5441006838290159, disc_loss = 0.10850834035245348
Trained batch 121 in epoch 8, gen_loss = 0.5435551363425176, disc_loss = 0.10817316609633262
Trained batch 122 in epoch 8, gen_loss = 0.5436785732342945, disc_loss = 0.10806145284294598
Trained batch 123 in epoch 8, gen_loss = 0.5441985493225436, disc_loss = 0.10782366397700482
Trained batch 124 in epoch 8, gen_loss = 0.5429429931640625, disc_loss = 0.1083929992467165
Trained batch 125 in epoch 8, gen_loss = 0.5423556310789925, disc_loss = 0.1084604880195998
Trained batch 126 in epoch 8, gen_loss = 0.5417155597622939, disc_loss = 0.1082658737927206
Trained batch 127 in epoch 8, gen_loss = 0.5415383519139141, disc_loss = 0.108167738726479
Trained batch 128 in epoch 8, gen_loss = 0.541746166094329, disc_loss = 0.10764311783939831
Trained batch 129 in epoch 8, gen_loss = 0.5415400406489006, disc_loss = 0.1072319677959268
Trained batch 130 in epoch 8, gen_loss = 0.5425290067232292, disc_loss = 0.10784590831524088
Trained batch 131 in epoch 8, gen_loss = 0.5425704810203928, disc_loss = 0.1078776691927377
Trained batch 132 in epoch 8, gen_loss = 0.5421969390901408, disc_loss = 0.10772137737419821
Trained batch 133 in epoch 8, gen_loss = 0.5420145657080323, disc_loss = 0.10779111839330463
Trained batch 134 in epoch 8, gen_loss = 0.5419034840884032, disc_loss = 0.10807693541325905
Trained batch 135 in epoch 8, gen_loss = 0.5412458102492725, disc_loss = 0.1079757424098823
Trained batch 136 in epoch 8, gen_loss = 0.5409396062367153, disc_loss = 0.10758171460326135
Trained batch 137 in epoch 8, gen_loss = 0.5416713739218919, disc_loss = 0.10744852115116689
Trained batch 138 in epoch 8, gen_loss = 0.5426170673730563, disc_loss = 0.10679560746970794
Trained batch 139 in epoch 8, gen_loss = 0.5420447632670402, disc_loss = 0.10752818219895874
Trained batch 140 in epoch 8, gen_loss = 0.542655127902403, disc_loss = 0.1069227305921257
Trained batch 141 in epoch 8, gen_loss = 0.5428114413795336, disc_loss = 0.10635850568052749
Trained batch 142 in epoch 8, gen_loss = 0.5430545237931338, disc_loss = 0.10683871555578459
Trained batch 143 in epoch 8, gen_loss = 0.542377272206876, disc_loss = 0.10666731227603224
Trained batch 144 in epoch 8, gen_loss = 0.5422770119946578, disc_loss = 0.10624317038675835
Trained batch 145 in epoch 8, gen_loss = 0.5425813522649138, disc_loss = 0.10616401659503374
Trained batch 146 in epoch 8, gen_loss = 0.5426794150654151, disc_loss = 0.10588700891960234
Trained batch 147 in epoch 8, gen_loss = 0.5421793541392764, disc_loss = 0.10581181676605263
Trained batch 148 in epoch 8, gen_loss = 0.5428241935352351, disc_loss = 0.10541395160475833
Trained batch 149 in epoch 8, gen_loss = 0.5424663281440735, disc_loss = 0.10528569000462691
Trained batch 150 in epoch 8, gen_loss = 0.5426864016135007, disc_loss = 0.10488449903020006
Trained batch 151 in epoch 8, gen_loss = 0.5437505519703815, disc_loss = 0.1049569937106418
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.4674117863178253, disc_loss = 0.0959857702255249
Trained batch 1 in epoch 9, gen_loss = 0.4978029280900955, disc_loss = 0.06899229809641838
Trained batch 2 in epoch 9, gen_loss = 0.573773076136907, disc_loss = 0.06150058408578237
Trained batch 3 in epoch 9, gen_loss = 0.557684876024723, disc_loss = 0.06888271123170853
Trained batch 4 in epoch 9, gen_loss = 0.548561555147171, disc_loss = 0.0728409856557846
Trained batch 5 in epoch 9, gen_loss = 0.5573028574387232, disc_loss = 0.08643397937218349
Trained batch 6 in epoch 9, gen_loss = 0.5447905531951359, disc_loss = 0.0877732304590089
Trained batch 7 in epoch 9, gen_loss = 0.5525372810661793, disc_loss = 0.07948346203193069
Trained batch 8 in epoch 9, gen_loss = 0.5476524598068662, disc_loss = 0.08066265657544136
Trained batch 9 in epoch 9, gen_loss = 0.5528164654970169, disc_loss = 0.07643513604998589
Trained batch 10 in epoch 9, gen_loss = 0.545320294120095, disc_loss = 0.0764426826076074
Trained batch 11 in epoch 9, gen_loss = 0.5491312195857366, disc_loss = 0.07208499917760491
Trained batch 12 in epoch 9, gen_loss = 0.5684097134149991, disc_loss = 0.08510992719003788
Trained batch 13 in epoch 9, gen_loss = 0.5583014381783349, disc_loss = 0.09603974954890353
Trained batch 14 in epoch 9, gen_loss = 0.5549512247244517, disc_loss = 0.10076260653634866
Trained batch 15 in epoch 9, gen_loss = 0.5596691910177469, disc_loss = 0.11593713506590575
Trained batch 16 in epoch 9, gen_loss = 0.5606830102555892, disc_loss = 0.11251809393220089
Trained batch 17 in epoch 9, gen_loss = 0.5546488049957488, disc_loss = 0.11184035314040051
Trained batch 18 in epoch 9, gen_loss = 0.5492094833599893, disc_loss = 0.11039814264758636
Trained batch 19 in epoch 9, gen_loss = 0.5509895488619805, disc_loss = 0.11123479222878814
Trained batch 20 in epoch 9, gen_loss = 0.5510058332057226, disc_loss = 0.1091467992713054
Trained batch 21 in epoch 9, gen_loss = 0.5485777990384535, disc_loss = 0.1065588944845579
Trained batch 22 in epoch 9, gen_loss = 0.549199464528457, disc_loss = 0.10488006140550842
Trained batch 23 in epoch 9, gen_loss = 0.5480396971106529, disc_loss = 0.10644950275309384
Trained batch 24 in epoch 9, gen_loss = 0.5475765132904052, disc_loss = 0.10312935471534729
Trained batch 25 in epoch 9, gen_loss = 0.5432709249166342, disc_loss = 0.1028683793086272
Trained batch 26 in epoch 9, gen_loss = 0.5447655761683429, disc_loss = 0.10343067127245444
Trained batch 27 in epoch 9, gen_loss = 0.5459290168115071, disc_loss = 0.1010136426027332
Trained batch 28 in epoch 9, gen_loss = 0.5513022398126537, disc_loss = 0.1002229477824836
Trained batch 29 in epoch 9, gen_loss = 0.5509216090043386, disc_loss = 0.09898638973633449
Trained batch 30 in epoch 9, gen_loss = 0.5486332485752721, disc_loss = 0.09771237101766371
Trained batch 31 in epoch 9, gen_loss = 0.549417145550251, disc_loss = 0.0954212971846573
Trained batch 32 in epoch 9, gen_loss = 0.5525231253017079, disc_loss = 0.0933473315089941
Trained batch 33 in epoch 9, gen_loss = 0.5507874883273068, disc_loss = 0.09374518511707292
Trained batch 34 in epoch 9, gen_loss = 0.5483514521803174, disc_loss = 0.09446514286100864
Trained batch 35 in epoch 9, gen_loss = 0.5504952892661095, disc_loss = 0.09365608558679621
Trained batch 36 in epoch 9, gen_loss = 0.5485324126643103, disc_loss = 0.09383469814988407
Trained batch 37 in epoch 9, gen_loss = 0.5496299415826797, disc_loss = 0.09266685356238955
Trained batch 38 in epoch 9, gen_loss = 0.555544641537544, disc_loss = 0.09282471120166473
Trained batch 39 in epoch 9, gen_loss = 0.554322861880064, disc_loss = 0.09148463956080377
Trained batch 40 in epoch 9, gen_loss = 0.5516130807923108, disc_loss = 0.09315572801704813
Trained batch 41 in epoch 9, gen_loss = 0.5546219434056964, disc_loss = 0.09272409935614892
Trained batch 42 in epoch 9, gen_loss = 0.5560392626496249, disc_loss = 0.09254568706938
Trained batch 43 in epoch 9, gen_loss = 0.5537001930854537, disc_loss = 0.09385597870939157
Trained batch 44 in epoch 9, gen_loss = 0.5516395403279198, disc_loss = 0.09340968326561981
Trained batch 45 in epoch 9, gen_loss = 0.5544138285128967, disc_loss = 0.09186025627929231
Trained batch 46 in epoch 9, gen_loss = 0.5563774254727871, disc_loss = 0.09043989017447258
Trained batch 47 in epoch 9, gen_loss = 0.5552382587144772, disc_loss = 0.0897687302203849
Trained batch 48 in epoch 9, gen_loss = 0.5552493206092289, disc_loss = 0.08818700023907788
Trained batch 49 in epoch 9, gen_loss = 0.5570130366086959, disc_loss = 0.0871551501378417
Trained batch 50 in epoch 9, gen_loss = 0.5554680421071894, disc_loss = 0.08656598339039906
Trained batch 51 in epoch 9, gen_loss = 0.557169506756159, disc_loss = 0.08521433916086188
Trained batch 52 in epoch 9, gen_loss = 0.5580381745437406, disc_loss = 0.08426341003263896
Trained batch 53 in epoch 9, gen_loss = 0.5568707800573773, disc_loss = 0.08404005549986053
Trained batch 54 in epoch 9, gen_loss = 0.5560496563261206, disc_loss = 0.08477451865645973
Trained batch 55 in epoch 9, gen_loss = 0.5552149835441794, disc_loss = 0.08475638190949601
Trained batch 56 in epoch 9, gen_loss = 0.5544749587251429, disc_loss = 0.08366962715068407
Trained batch 57 in epoch 9, gen_loss = 0.5518312073987106, disc_loss = 0.0882641089566309
Trained batch 58 in epoch 9, gen_loss = 0.5557798238123878, disc_loss = 0.09067862818680578
Trained batch 59 in epoch 9, gen_loss = 0.5584008971850077, disc_loss = 0.09020387334749103
Trained batch 60 in epoch 9, gen_loss = 0.5570857593270598, disc_loss = 0.08993805764762104
Trained batch 61 in epoch 9, gen_loss = 0.5549973658015651, disc_loss = 0.09187546651810408
Trained batch 62 in epoch 9, gen_loss = 0.5570805418112922, disc_loss = 0.09131586075656944
Trained batch 63 in epoch 9, gen_loss = 0.5590128158219159, disc_loss = 0.09066410266677849
Trained batch 64 in epoch 9, gen_loss = 0.5588737510717832, disc_loss = 0.08949523913459136
Trained batch 65 in epoch 9, gen_loss = 0.5575921621286508, disc_loss = 0.08973502335279729
Trained batch 66 in epoch 9, gen_loss = 0.5577122146513924, disc_loss = 0.08921652410957795
Trained batch 67 in epoch 9, gen_loss = 0.5582913760753239, disc_loss = 0.08836019363747362
Trained batch 68 in epoch 9, gen_loss = 0.5591821502084318, disc_loss = 0.0882871709898978
Trained batch 69 in epoch 9, gen_loss = 0.5576707456793104, disc_loss = 0.08913739234475153
Trained batch 70 in epoch 9, gen_loss = 0.5576145094884953, disc_loss = 0.08914448999025872
Trained batch 71 in epoch 9, gen_loss = 0.557834138472875, disc_loss = 0.08870577446133313
Trained batch 72 in epoch 9, gen_loss = 0.557256086231911, disc_loss = 0.08897423413773514
Trained batch 73 in epoch 9, gen_loss = 0.5558476866902532, disc_loss = 0.08848107682943747
Trained batch 74 in epoch 9, gen_loss = 0.5543221604824066, disc_loss = 0.08773386454830567
Trained batch 75 in epoch 9, gen_loss = 0.5545471377278629, disc_loss = 0.08779994453499584
Trained batch 76 in epoch 9, gen_loss = 0.5552126498191388, disc_loss = 0.0872393474103762
Trained batch 77 in epoch 9, gen_loss = 0.5536536666063162, disc_loss = 0.08750035385720623
Trained batch 78 in epoch 9, gen_loss = 0.5532494142085691, disc_loss = 0.08673089842866116
Trained batch 79 in epoch 9, gen_loss = 0.554748623073101, disc_loss = 0.089657334855292
Trained batch 80 in epoch 9, gen_loss = 0.553440241166103, disc_loss = 0.09016760508817287
Trained batch 81 in epoch 9, gen_loss = 0.5523383566519109, disc_loss = 0.0912256737512241
Trained batch 82 in epoch 9, gen_loss = 0.5525447036846575, disc_loss = 0.09323280786040676
Trained batch 83 in epoch 9, gen_loss = 0.5517936412777219, disc_loss = 0.09376105086301409
Trained batch 84 in epoch 9, gen_loss = 0.5508482245837941, disc_loss = 0.09447787602377289
Trained batch 85 in epoch 9, gen_loss = 0.5506408741307813, disc_loss = 0.09509554458782077
Trained batch 86 in epoch 9, gen_loss = 0.5510195301867079, disc_loss = 0.09573124765536223
Trained batch 87 in epoch 9, gen_loss = 0.550989224829457, disc_loss = 0.09607811125037684
Trained batch 88 in epoch 9, gen_loss = 0.5507846956842402, disc_loss = 0.09593232081721673
Trained batch 89 in epoch 9, gen_loss = 0.5507436202632057, disc_loss = 0.09581422686783804
Trained batch 90 in epoch 9, gen_loss = 0.550523660340152, disc_loss = 0.09590221840151392
Trained batch 91 in epoch 9, gen_loss = 0.5490510360054348, disc_loss = 0.09628151872438258
Trained batch 92 in epoch 9, gen_loss = 0.5492829744533826, disc_loss = 0.09692339115445653
Trained batch 93 in epoch 9, gen_loss = 0.5485230018483832, disc_loss = 0.09651480889581937
Trained batch 94 in epoch 9, gen_loss = 0.548001186784945, disc_loss = 0.09650600337864537
Trained batch 95 in epoch 9, gen_loss = 0.5484223313008746, disc_loss = 0.09629155467458379
Trained batch 96 in epoch 9, gen_loss = 0.5491989860215138, disc_loss = 0.09553636738204772
Trained batch 97 in epoch 9, gen_loss = 0.5488357498329512, disc_loss = 0.09551995754127904
Trained batch 98 in epoch 9, gen_loss = 0.5485875639650557, disc_loss = 0.09531333369927274
Trained batch 99 in epoch 9, gen_loss = 0.5485148736834526, disc_loss = 0.09572795485146343
Trained batch 100 in epoch 9, gen_loss = 0.548471866562815, disc_loss = 0.09520871093552007
Trained batch 101 in epoch 9, gen_loss = 0.5489049346423617, disc_loss = 0.09447408495836106
Trained batch 102 in epoch 9, gen_loss = 0.5477360362566791, disc_loss = 0.09486061044362853
Trained batch 103 in epoch 9, gen_loss = 0.5489641877894218, disc_loss = 0.0952126524106671
Trained batch 104 in epoch 9, gen_loss = 0.5486163698491596, disc_loss = 0.09490779793510834
Trained batch 105 in epoch 9, gen_loss = 0.5475399114613263, disc_loss = 0.09479173785075545
Trained batch 106 in epoch 9, gen_loss = 0.5479163457857115, disc_loss = 0.094534152361486
Trained batch 107 in epoch 9, gen_loss = 0.5479900354036579, disc_loss = 0.09398625262461051
Trained batch 108 in epoch 9, gen_loss = 0.5487145762377923, disc_loss = 0.09347585700623212
Trained batch 109 in epoch 9, gen_loss = 0.5486771570010619, disc_loss = 0.09305398334664378
Trained batch 110 in epoch 9, gen_loss = 0.5498021935020481, disc_loss = 0.09263437374721507
Trained batch 111 in epoch 9, gen_loss = 0.5490677300840616, disc_loss = 0.09262581035727635
Trained batch 112 in epoch 9, gen_loss = 0.5494844446667527, disc_loss = 0.09243575166251543
Trained batch 113 in epoch 9, gen_loss = 0.5489412768368136, disc_loss = 0.09310766027652119
Trained batch 114 in epoch 9, gen_loss = 0.5496770462264186, disc_loss = 0.09254073300601348
Trained batch 115 in epoch 9, gen_loss = 0.5482915051538368, disc_loss = 0.09314988689208083
Trained batch 116 in epoch 9, gen_loss = 0.5489873455630409, disc_loss = 0.092716200173729
Trained batch 117 in epoch 9, gen_loss = 0.5497677232754432, disc_loss = 0.09263712806248312
Trained batch 118 in epoch 9, gen_loss = 0.5489072141026249, disc_loss = 0.09268579144469079
Trained batch 119 in epoch 9, gen_loss = 0.548810326308012, disc_loss = 0.09265171954563509
Trained batch 120 in epoch 9, gen_loss = 0.5492206760181868, disc_loss = 0.09259628258984197
Trained batch 121 in epoch 9, gen_loss = 0.5484953275958045, disc_loss = 0.09257999979356518
Trained batch 122 in epoch 9, gen_loss = 0.5484391012327458, disc_loss = 0.09208536082197254
Trained batch 123 in epoch 9, gen_loss = 0.5491026022261188, disc_loss = 0.09158565098750254
Trained batch 124 in epoch 9, gen_loss = 0.5493485305309296, disc_loss = 0.09105278760939836
Trained batch 125 in epoch 9, gen_loss = 0.5490003415043392, disc_loss = 0.09071014869573807
Trained batch 126 in epoch 9, gen_loss = 0.5493494288658533, disc_loss = 0.09087846381956433
Trained batch 127 in epoch 9, gen_loss = 0.5482630303595215, disc_loss = 0.09111840185505571
Trained batch 128 in epoch 9, gen_loss = 0.5481701768183893, disc_loss = 0.09087166846404936
Trained batch 129 in epoch 9, gen_loss = 0.5485061643215327, disc_loss = 0.09031048028085094
Trained batch 130 in epoch 9, gen_loss = 0.5489521897931136, disc_loss = 0.0898477473146929
Trained batch 131 in epoch 9, gen_loss = 0.5489900773673346, disc_loss = 0.08956344794679547
Trained batch 132 in epoch 9, gen_loss = 0.5499017133300466, disc_loss = 0.08944363608480171
Trained batch 133 in epoch 9, gen_loss = 0.5492632013203492, disc_loss = 0.08973237334875696
Trained batch 134 in epoch 9, gen_loss = 0.5493292232354482, disc_loss = 0.08924158413515047
Trained batch 135 in epoch 9, gen_loss = 0.5502916585434886, disc_loss = 0.08938860722735305
Trained batch 136 in epoch 9, gen_loss = 0.5499798192159973, disc_loss = 0.08915864504248339
Trained batch 137 in epoch 9, gen_loss = 0.5499699666448261, disc_loss = 0.08875385649583262
Trained batch 138 in epoch 9, gen_loss = 0.550273758258751, disc_loss = 0.09029959977718352
Trained batch 139 in epoch 9, gen_loss = 0.5496277076857431, disc_loss = 0.09107587496483964
Trained batch 140 in epoch 9, gen_loss = 0.5499129058621454, disc_loss = 0.09068972672210306
Trained batch 141 in epoch 9, gen_loss = 0.5505490122546612, disc_loss = 0.09085760278050119
Trained batch 142 in epoch 9, gen_loss = 0.5503585880452936, disc_loss = 0.09111579952409843
Trained batch 143 in epoch 9, gen_loss = 0.5501699828439288, disc_loss = 0.0907184497336857
Trained batch 144 in epoch 9, gen_loss = 0.5498884414804392, disc_loss = 0.09035930817882562
Trained batch 145 in epoch 9, gen_loss = 0.550581645475675, disc_loss = 0.0904217275076431
Trained batch 146 in epoch 9, gen_loss = 0.5505629327832436, disc_loss = 0.09037387294403347
Trained batch 147 in epoch 9, gen_loss = 0.5501110106706619, disc_loss = 0.09035520914413438
Trained batch 148 in epoch 9, gen_loss = 0.550203513379065, disc_loss = 0.08993094623863897
Trained batch 149 in epoch 9, gen_loss = 0.5510869872570038, disc_loss = 0.08962004628653328
Trained batch 150 in epoch 9, gen_loss = 0.5503271354350033, disc_loss = 0.08965426581658867
Trained batch 151 in epoch 9, gen_loss = 0.5505518036845484, disc_loss = 0.08927048644124481
Testing Epoch 9
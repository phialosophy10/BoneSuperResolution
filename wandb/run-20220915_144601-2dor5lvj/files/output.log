/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.7854267358779907, disc_loss = 0.6022229194641113
Trained batch 1 in epoch 0, gen_loss = 0.8321468234062195, disc_loss = 0.8862669467926025
Trained batch 2 in epoch 0, gen_loss = 0.770720362663269, disc_loss = 0.7443195482095083
Trained batch 3 in epoch 0, gen_loss = 0.7367369532585144, disc_loss = 0.6308880895376205
Trained batch 4 in epoch 0, gen_loss = 0.7059455990791321, disc_loss = 0.5469188630580902
Trained batch 5 in epoch 0, gen_loss = 0.6801445484161377, disc_loss = 0.49575963368018466
Trained batch 6 in epoch 0, gen_loss = 0.6552670087133136, disc_loss = 0.45109203457832336
Trained batch 7 in epoch 0, gen_loss = 0.6532580628991127, disc_loss = 0.41759465634822845
Trained batch 8 in epoch 0, gen_loss = 0.6547086834907532, disc_loss = 0.3933508876297209
Trained batch 9 in epoch 0, gen_loss = 0.6466542184352875, disc_loss = 0.37327367812395096
Trained batch 10 in epoch 0, gen_loss = 0.6458579897880554, disc_loss = 0.3625480844215913
Trained batch 11 in epoch 0, gen_loss = 0.6514304280281067, disc_loss = 0.35686346267660457
Trained batch 12 in epoch 0, gen_loss = 0.65337990797483, disc_loss = 0.34593696548388553
Trained batch 13 in epoch 0, gen_loss = 0.6483416514737266, disc_loss = 0.3356218636035919
Trained batch 14 in epoch 0, gen_loss = 0.6453216711680094, disc_loss = 0.3237880190213521
Trained batch 15 in epoch 0, gen_loss = 0.6439345628023148, disc_loss = 0.3129099365323782
Trained batch 16 in epoch 0, gen_loss = 0.6427336300120634, disc_loss = 0.30177784623468623
Trained batch 17 in epoch 0, gen_loss = 0.64625127447976, disc_loss = 0.2898283381428983
Trained batch 18 in epoch 0, gen_loss = 0.644316481916528, disc_loss = 0.2785513742189658
Trained batch 19 in epoch 0, gen_loss = 0.646080681681633, disc_loss = 0.2680100928992033
Trained batch 20 in epoch 0, gen_loss = 0.6456015706062317, disc_loss = 0.2597512020951226
Trained batch 21 in epoch 0, gen_loss = 0.6469991478053007, disc_loss = 0.2527270845391534
Trained batch 22 in epoch 0, gen_loss = 0.64951658508052, disc_loss = 0.2449338092752125
Trained batch 23 in epoch 0, gen_loss = 0.6514462977647781, disc_loss = 0.23742487809310356
Trained batch 24 in epoch 0, gen_loss = 0.65142897605896, disc_loss = 0.23312459796667098
Trained batch 25 in epoch 0, gen_loss = 0.6534791038586543, disc_loss = 0.2306872712304959
Trained batch 26 in epoch 0, gen_loss = 0.6589593931480691, disc_loss = 0.22673702543532406
Trained batch 27 in epoch 0, gen_loss = 0.6584672267947879, disc_loss = 0.22230390033551625
Trained batch 28 in epoch 0, gen_loss = 0.6622016943734268, disc_loss = 0.21684562055201367
Trained batch 29 in epoch 0, gen_loss = 0.6669872979323069, disc_loss = 0.21194043134649596
Trained batch 30 in epoch 0, gen_loss = 0.6708986586140048, disc_loss = 0.20695143986132838
Trained batch 31 in epoch 0, gen_loss = 0.6734285745769739, disc_loss = 0.2031743626575917
Trained batch 32 in epoch 0, gen_loss = 0.6769835443207712, disc_loss = 0.19869122044606644
Trained batch 33 in epoch 0, gen_loss = 0.6828748198116527, disc_loss = 0.19431267317165346
Trained batch 34 in epoch 0, gen_loss = 0.6866694790976388, disc_loss = 0.19013918776597297
Trained batch 35 in epoch 0, gen_loss = 0.6889773938390944, disc_loss = 0.18616107178645003
Trained batch 36 in epoch 0, gen_loss = 0.6899690434739396, disc_loss = 0.18237071111798286
Trained batch 37 in epoch 0, gen_loss = 0.6930935712237107, disc_loss = 0.17865937232579054
Trained batch 38 in epoch 0, gen_loss = 0.6944892330047412, disc_loss = 0.17517415271737638
Trained batch 39 in epoch 0, gen_loss = 0.6953179433941841, disc_loss = 0.17191960718482732
Trained batch 40 in epoch 0, gen_loss = 0.6971059805009423, disc_loss = 0.1692794350589194
Trained batch 41 in epoch 0, gen_loss = 0.6981889506181082, disc_loss = 0.16906459416661943
Trained batch 42 in epoch 0, gen_loss = 0.7005973513736281, disc_loss = 0.1750097302503364
Trained batch 43 in epoch 0, gen_loss = 0.7049686813896353, disc_loss = 0.17567389593882995
Trained batch 44 in epoch 0, gen_loss = 0.7083677901162042, disc_loss = 0.1733069724506802
Trained batch 45 in epoch 0, gen_loss = 0.7100499764732693, disc_loss = 0.17069133209145587
Trained batch 46 in epoch 0, gen_loss = 0.7113672279297037, disc_loss = 0.16789011308487425
Trained batch 47 in epoch 0, gen_loss = 0.7116787719229857, disc_loss = 0.1650085023526723
Trained batch 48 in epoch 0, gen_loss = 0.7114837668379959, disc_loss = 0.16225017534987052
Trained batch 49 in epoch 0, gen_loss = 0.7130102193355561, disc_loss = 0.15947946604341268
Trained batch 50 in epoch 0, gen_loss = 0.714417485629811, disc_loss = 0.15686214452280717
Trained batch 51 in epoch 0, gen_loss = 0.7142950537113043, disc_loss = 0.15433129729129946
Trained batch 52 in epoch 0, gen_loss = 0.7142669940894505, disc_loss = 0.15196035609070985
Trained batch 53 in epoch 0, gen_loss = 0.7147976447034765, disc_loss = 0.14966255157358116
Trained batch 54 in epoch 0, gen_loss = 0.7138959667899392, disc_loss = 0.1475311734459617
Trained batch 55 in epoch 0, gen_loss = 0.7148725699101176, disc_loss = 0.145437814494861
Trained batch 56 in epoch 0, gen_loss = 0.7145560456995379, disc_loss = 0.1435217773705198
Trained batch 57 in epoch 0, gen_loss = 0.7144991077225784, disc_loss = 0.14188222131081696
Trained batch 58 in epoch 0, gen_loss = 0.7135208511756639, disc_loss = 0.14045608176265734
Trained batch 59 in epoch 0, gen_loss = 0.7134361336628596, disc_loss = 0.13870379061748583
Trained batch 60 in epoch 0, gen_loss = 0.7131575531646853, disc_loss = 0.13719674651740027
Trained batch 61 in epoch 0, gen_loss = 0.7127457511040473, disc_loss = 0.1357521478447222
Trained batch 62 in epoch 0, gen_loss = 0.712515341857123, disc_loss = 0.13425151057659634
Trained batch 63 in epoch 0, gen_loss = 0.7140606306493282, disc_loss = 0.13296824222197756
Trained batch 64 in epoch 0, gen_loss = 0.7133320900110098, disc_loss = 0.13138013791579467
Trained batch 65 in epoch 0, gen_loss = 0.7120351899753917, disc_loss = 0.12992622025988318
Trained batch 66 in epoch 0, gen_loss = 0.7126364618984621, disc_loss = 0.12834124950997866
Trained batch 67 in epoch 0, gen_loss = 0.7136218977325103, disc_loss = 0.1268279255258248
Trained batch 68 in epoch 0, gen_loss = 0.713661241358605, disc_loss = 0.12528791977767495
Trained batch 69 in epoch 0, gen_loss = 0.7128840710435594, disc_loss = 0.12375411745160818
Trained batch 70 in epoch 0, gen_loss = 0.7132607077209043, disc_loss = 0.1222582485159518
Trained batch 71 in epoch 0, gen_loss = 0.7131775518258413, disc_loss = 0.120832117791805
Trained batch 72 in epoch 0, gen_loss = 0.713447872906515, disc_loss = 0.11946951766332535
Trained batch 73 in epoch 0, gen_loss = 0.7128939225866988, disc_loss = 0.11818173854939036
Trained batch 74 in epoch 0, gen_loss = 0.7117427579561869, disc_loss = 0.1168945632626613
Trained batch 75 in epoch 0, gen_loss = 0.7111398703173587, disc_loss = 0.11573551428553305
Trained batch 76 in epoch 0, gen_loss = 0.7112687152701539, disc_loss = 0.11457912222325027
Trained batch 77 in epoch 0, gen_loss = 0.7109769093684661, disc_loss = 0.11368998837394592
Trained batch 78 in epoch 0, gen_loss = 0.7094243304638923, disc_loss = 0.1131037600998637
Trained batch 79 in epoch 0, gen_loss = 0.7095275960862637, disc_loss = 0.11218472365289926
Trained batch 80 in epoch 0, gen_loss = 0.7100978581993668, disc_loss = 0.11136294947362241
Trained batch 81 in epoch 0, gen_loss = 0.7102156695796222, disc_loss = 0.11052728862297244
Trained batch 82 in epoch 0, gen_loss = 0.7111877791852836, disc_loss = 0.109516582395657
Trained batch 83 in epoch 0, gen_loss = 0.7109285706565494, disc_loss = 0.108547950762191
Trained batch 84 in epoch 0, gen_loss = 0.7108722897136912, disc_loss = 0.10778556700576754
Trained batch 85 in epoch 0, gen_loss = 0.7118203279583953, disc_loss = 0.10691090904955947
Trained batch 86 in epoch 0, gen_loss = 0.7112787338508957, disc_loss = 0.10595937670561774
Trained batch 87 in epoch 0, gen_loss = 0.7116891484368931, disc_loss = 0.10507165900939568
Trained batch 88 in epoch 0, gen_loss = 0.7121228729740957, disc_loss = 0.10422517859450217
Trained batch 89 in epoch 0, gen_loss = 0.711694473028183, disc_loss = 0.10328464398367537
Trained batch 90 in epoch 0, gen_loss = 0.7119229232871925, disc_loss = 0.10260525945533108
Trained batch 91 in epoch 0, gen_loss = 0.7122949523770291, disc_loss = 0.10193061198958236
Trained batch 92 in epoch 0, gen_loss = 0.7126642209227367, disc_loss = 0.10112476372911085
Trained batch 93 in epoch 0, gen_loss = 0.7128070085606677, disc_loss = 0.10023797364865845
Trained batch 94 in epoch 0, gen_loss = 0.7128581988184075, disc_loss = 0.09944196074808899
Trained batch 95 in epoch 0, gen_loss = 0.7129087075591087, disc_loss = 0.0986812655076695
Trained batch 96 in epoch 0, gen_loss = 0.7118673023489333, disc_loss = 0.09890493875388633
Trained batch 97 in epoch 0, gen_loss = 0.7129885523903127, disc_loss = 0.09887541726003496
Trained batch 98 in epoch 0, gen_loss = 0.7124637901180922, disc_loss = 0.09833080007346591
Trained batch 99 in epoch 0, gen_loss = 0.7121132844686509, disc_loss = 0.09767960255965591
Trained batch 100 in epoch 0, gen_loss = 0.7120768604892316, disc_loss = 0.09693376115053007
Trained batch 101 in epoch 0, gen_loss = 0.7117404429351583, disc_loss = 0.09620888385118223
Trained batch 102 in epoch 0, gen_loss = 0.7116228440432872, disc_loss = 0.0955516230857488
Trained batch 103 in epoch 0, gen_loss = 0.7111175020153706, disc_loss = 0.09494867483870341
Trained batch 104 in epoch 0, gen_loss = 0.7121135297275725, disc_loss = 0.09433546942614374
Trained batch 105 in epoch 0, gen_loss = 0.7124720255158982, disc_loss = 0.09364384504140548
Trained batch 106 in epoch 0, gen_loss = 0.7113036986823394, disc_loss = 0.09322006224054043
Trained batch 107 in epoch 0, gen_loss = 0.7119650526179208, disc_loss = 0.09266759262040809
Trained batch 108 in epoch 0, gen_loss = 0.7120625896191378, disc_loss = 0.09225757013357014
Trained batch 109 in epoch 0, gen_loss = 0.7126219126311215, disc_loss = 0.09172744720496914
Trained batch 110 in epoch 0, gen_loss = 0.7131888812726682, disc_loss = 0.0913432409970073
Trained batch 111 in epoch 0, gen_loss = 0.7125484075929437, disc_loss = 0.09126778655419392
Trained batch 112 in epoch 0, gen_loss = 0.714684981687934, disc_loss = 0.09222992651362334
Trained batch 113 in epoch 0, gen_loss = 0.7138029504240605, disc_loss = 0.09475452861372839
Trained batch 114 in epoch 0, gen_loss = 0.7149582360101783, disc_loss = 0.09464448907453081
Trained batch 115 in epoch 0, gen_loss = 0.7154892009907755, disc_loss = 0.09479842582267933
Trained batch 116 in epoch 0, gen_loss = 0.7156798437110379, disc_loss = 0.09447169214741796
Trained batch 117 in epoch 0, gen_loss = 0.7151227113554033, disc_loss = 0.09408898575831268
Trained batch 118 in epoch 0, gen_loss = 0.7145512089008043, disc_loss = 0.09365233822780497
Trained batch 119 in epoch 0, gen_loss = 0.7149511784315109, disc_loss = 0.09315667549769084
Trained batch 120 in epoch 0, gen_loss = 0.7160804133769895, disc_loss = 0.09272411213187147
Trained batch 121 in epoch 0, gen_loss = 0.7156000625891764, disc_loss = 0.09227035674037504
Trained batch 122 in epoch 0, gen_loss = 0.7159001875699051, disc_loss = 0.09182692964265986
Trained batch 123 in epoch 0, gen_loss = 0.7169230373636368, disc_loss = 0.09152841162417204
Trained batch 124 in epoch 0, gen_loss = 0.7169474492073059, disc_loss = 0.0913015842139721
Trained batch 125 in epoch 0, gen_loss = 0.7171770168675317, disc_loss = 0.09074387477622145
Trained batch 126 in epoch 0, gen_loss = 0.717357635028719, disc_loss = 0.09041235340744491
Trained batch 127 in epoch 0, gen_loss = 0.7166829821653664, disc_loss = 0.09082304753246717
Trained batch 128 in epoch 0, gen_loss = 0.7181018429209095, disc_loss = 0.09076309310950974
Trained batch 129 in epoch 0, gen_loss = 0.7182669359904069, disc_loss = 0.09034427034740265
Trained batch 130 in epoch 0, gen_loss = 0.7172151876769903, disc_loss = 0.09062226364062033
Trained batch 131 in epoch 0, gen_loss = 0.7176324616778981, disc_loss = 0.09043675460711573
Trained batch 132 in epoch 0, gen_loss = 0.717123726256808, disc_loss = 0.08993428180876531
Trained batch 133 in epoch 0, gen_loss = 0.7168511574837699, disc_loss = 0.08960913736095179
Trained batch 134 in epoch 0, gen_loss = 0.7171772303404631, disc_loss = 0.08989012034402953
Trained batch 135 in epoch 0, gen_loss = 0.7156239800593432, disc_loss = 0.09192668353481327
Trained batch 136 in epoch 0, gen_loss = 0.7158496506022711, disc_loss = 0.09225280857543006
Trained batch 137 in epoch 0, gen_loss = 0.7150996072568755, disc_loss = 0.09268278480116007
Trained batch 138 in epoch 0, gen_loss = 0.7145392234376866, disc_loss = 0.09262313578519032
Trained batch 139 in epoch 0, gen_loss = 0.7149759854589189, disc_loss = 0.09253087716975382
Trained batch 140 in epoch 0, gen_loss = 0.7144315940268496, disc_loss = 0.09241274197367912
Trained batch 141 in epoch 0, gen_loss = 0.7141915857791901, disc_loss = 0.09219132098828403
Trained batch 142 in epoch 0, gen_loss = 0.7144788466133438, disc_loss = 0.09174297309734604
Trained batch 143 in epoch 0, gen_loss = 0.7140587125387456, disc_loss = 0.09150008818445106
Trained batch 144 in epoch 0, gen_loss = 0.7142423280354204, disc_loss = 0.09114976070564369
Trained batch 145 in epoch 0, gen_loss = 0.7142446339130402, disc_loss = 0.09081370421774583
Trained batch 146 in epoch 0, gen_loss = 0.7141296308056838, disc_loss = 0.09103784464350363
Trained batch 147 in epoch 0, gen_loss = 0.7151772480558705, disc_loss = 0.0924223664694944
Trained batch 148 in epoch 0, gen_loss = 0.714258157966921, disc_loss = 0.09391830324026562
Trained batch 149 in epoch 0, gen_loss = 0.7144938635826111, disc_loss = 0.09394124018649261
Trained batch 150 in epoch 0, gen_loss = 0.714741554876037, disc_loss = 0.09364268608045893
Trained batch 151 in epoch 0, gen_loss = 0.7148621984218296, disc_loss = 0.09324599527998974
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.7470322847366333, disc_loss = 0.02770930528640747
Trained batch 1 in epoch 1, gen_loss = 0.6955573856830597, disc_loss = 0.029295386746525764
Trained batch 2 in epoch 1, gen_loss = 0.7043686111768087, disc_loss = 0.03139171625177065
Trained batch 3 in epoch 1, gen_loss = 0.711209312081337, disc_loss = 0.03338277619332075
Trained batch 4 in epoch 1, gen_loss = 0.6991586446762085, disc_loss = 0.036718543618917465
Trained batch 5 in epoch 1, gen_loss = 0.7116542756557465, disc_loss = 0.03547252248972654
Trained batch 6 in epoch 1, gen_loss = 0.7236352733203343, disc_loss = 0.0517987675432648
Trained batch 7 in epoch 1, gen_loss = 0.706859678030014, disc_loss = 0.09997393772937357
Trained batch 8 in epoch 1, gen_loss = 0.7002950575616624, disc_loss = 0.108676187073191
Trained batch 9 in epoch 1, gen_loss = 0.7020689666271209, disc_loss = 0.11709715444594622
Trained batch 10 in epoch 1, gen_loss = 0.6962637630375949, disc_loss = 0.1278609282929789
Trained batch 11 in epoch 1, gen_loss = 0.6829265654087067, disc_loss = 0.13588492091124257
Trained batch 12 in epoch 1, gen_loss = 0.6782888357455914, disc_loss = 0.13996376799276242
Trained batch 13 in epoch 1, gen_loss = 0.670595143522535, disc_loss = 0.14317552971520595
Trained batch 14 in epoch 1, gen_loss = 0.6698448101679484, disc_loss = 0.14542323562006157
Trained batch 15 in epoch 1, gen_loss = 0.674788311123848, disc_loss = 0.1443637890042737
Trained batch 16 in epoch 1, gen_loss = 0.6789199148907381, disc_loss = 0.13898342332857497
Trained batch 17 in epoch 1, gen_loss = 0.6799102789825864, disc_loss = 0.1330983287965258
Trained batch 18 in epoch 1, gen_loss = 0.6882030807043377, disc_loss = 0.12814045922928735
Trained batch 19 in epoch 1, gen_loss = 0.6938704460859298, disc_loss = 0.12249081921763719
Trained batch 20 in epoch 1, gen_loss = 0.6927417658624195, disc_loss = 0.1180982557347133
Trained batch 21 in epoch 1, gen_loss = 0.6934439621188424, disc_loss = 0.11383922935717485
Trained batch 22 in epoch 1, gen_loss = 0.6920235571653947, disc_loss = 0.11219117041353298
Trained batch 23 in epoch 1, gen_loss = 0.6952317158381144, disc_loss = 0.11018385113372157
Trained batch 24 in epoch 1, gen_loss = 0.697212553024292, disc_loss = 0.10776931758970022
Trained batch 25 in epoch 1, gen_loss = 0.6963024276953477, disc_loss = 0.10529576209731974
Trained batch 26 in epoch 1, gen_loss = 0.6993720310705679, disc_loss = 0.10212218081923546
Trained batch 27 in epoch 1, gen_loss = 0.7016495593956539, disc_loss = 0.1014563761584993
Trained batch 28 in epoch 1, gen_loss = 0.7050479856030695, disc_loss = 0.09988462459295988
Trained batch 29 in epoch 1, gen_loss = 0.7094024022420248, disc_loss = 0.0981257802185913
Trained batch 30 in epoch 1, gen_loss = 0.7092267563266139, disc_loss = 0.09576269128029385
Trained batch 31 in epoch 1, gen_loss = 0.706934554502368, disc_loss = 0.09539992045029067
Trained batch 32 in epoch 1, gen_loss = 0.7150557348222444, disc_loss = 0.09931972134632594
Trained batch 33 in epoch 1, gen_loss = 0.7113351506345412, disc_loss = 0.10028039759901516
Trained batch 34 in epoch 1, gen_loss = 0.7108141490391322, disc_loss = 0.09959358517080545
Trained batch 35 in epoch 1, gen_loss = 0.7126353598303266, disc_loss = 0.10299683846015897
Trained batch 36 in epoch 1, gen_loss = 0.7100947676478205, disc_loss = 0.11055717665098004
Trained batch 37 in epoch 1, gen_loss = 0.7060701627480356, disc_loss = 0.11262744731318794
Trained batch 38 in epoch 1, gen_loss = 0.7051097490848639, disc_loss = 0.11418532549093167
Trained batch 39 in epoch 1, gen_loss = 0.7034237369894981, disc_loss = 0.11553638007026165
Trained batch 40 in epoch 1, gen_loss = 0.7004941978105684, disc_loss = 0.116778792654414
Trained batch 41 in epoch 1, gen_loss = 0.6982693587030683, disc_loss = 0.11745354344713546
Trained batch 42 in epoch 1, gen_loss = 0.6965384621952855, disc_loss = 0.11783480529435152
Trained batch 43 in epoch 1, gen_loss = 0.6955844421278347, disc_loss = 0.1171351238365539
Trained batch 44 in epoch 1, gen_loss = 0.6996606906255086, disc_loss = 0.11630674209445716
Trained batch 45 in epoch 1, gen_loss = 0.6974930024665335, disc_loss = 0.11574672978452366
Trained batch 46 in epoch 1, gen_loss = 0.6957499384880066, disc_loss = 0.11437555677951017
Trained batch 47 in epoch 1, gen_loss = 0.6963641854623953, disc_loss = 0.11318421881878749
Trained batch 48 in epoch 1, gen_loss = 0.6969183780709092, disc_loss = 0.11263180925149699
Trained batch 49 in epoch 1, gen_loss = 0.6982459461688996, disc_loss = 0.11299302628263831
Trained batch 50 in epoch 1, gen_loss = 0.6953377887314441, disc_loss = 0.11681186267193042
Trained batch 51 in epoch 1, gen_loss = 0.6995435265394357, disc_loss = 0.1280282052914397
Trained batch 52 in epoch 1, gen_loss = 0.6965258413890623, disc_loss = 0.1294776731750594
Trained batch 53 in epoch 1, gen_loss = 0.6938104265265994, disc_loss = 0.1333518824885013
Trained batch 54 in epoch 1, gen_loss = 0.6919163400476629, disc_loss = 0.1359459093179215
Trained batch 55 in epoch 1, gen_loss = 0.6905737604413714, disc_loss = 0.13833615148905665
Trained batch 56 in epoch 1, gen_loss = 0.6881045939629538, disc_loss = 0.13911078862126983
Trained batch 57 in epoch 1, gen_loss = 0.685734119908563, disc_loss = 0.13995746617879848
Trained batch 58 in epoch 1, gen_loss = 0.6830089203381943, disc_loss = 0.14072549006885895
Trained batch 59 in epoch 1, gen_loss = 0.6809422800938288, disc_loss = 0.140826044154043
Trained batch 60 in epoch 1, gen_loss = 0.6803661018121437, disc_loss = 0.14051464424453308
Trained batch 61 in epoch 1, gen_loss = 0.679738542725963, disc_loss = 0.1403344483114779
Trained batch 62 in epoch 1, gen_loss = 0.6778454610279628, disc_loss = 0.1399410404117098
Trained batch 63 in epoch 1, gen_loss = 0.6775954393669963, disc_loss = 0.1391219554207055
Trained batch 64 in epoch 1, gen_loss = 0.677328231701484, disc_loss = 0.13866406213492155
Trained batch 65 in epoch 1, gen_loss = 0.6744280827767921, disc_loss = 0.1407300680170231
Trained batch 66 in epoch 1, gen_loss = 0.6763534038814146, disc_loss = 0.14323244514916814
Trained batch 67 in epoch 1, gen_loss = 0.6743724074433831, disc_loss = 0.14472615536685815
Trained batch 68 in epoch 1, gen_loss = 0.6729867371959962, disc_loss = 0.14481112224630255
Trained batch 69 in epoch 1, gen_loss = 0.672331976039069, disc_loss = 0.1449506533332169
Trained batch 70 in epoch 1, gen_loss = 0.6709494087058054, disc_loss = 0.14498901738404807
Trained batch 71 in epoch 1, gen_loss = 0.6697562005784776, disc_loss = 0.14450354691750059
Trained batch 72 in epoch 1, gen_loss = 0.6701232301045771, disc_loss = 0.14499763168445598
Trained batch 73 in epoch 1, gen_loss = 0.6676856742517369, disc_loss = 0.14942957565339432
Trained batch 74 in epoch 1, gen_loss = 0.6666537304719289, disc_loss = 0.15049904787292084
Trained batch 75 in epoch 1, gen_loss = 0.6665553721158128, disc_loss = 0.15236493674302964
Trained batch 76 in epoch 1, gen_loss = 0.6652214260070355, disc_loss = 0.15303019931322182
Trained batch 77 in epoch 1, gen_loss = 0.6639418475902997, disc_loss = 0.15374463284388185
Trained batch 78 in epoch 1, gen_loss = 0.6625343927099735, disc_loss = 0.15424743600048219
Trained batch 79 in epoch 1, gen_loss = 0.6612869653850794, disc_loss = 0.15446407966082915
Trained batch 80 in epoch 1, gen_loss = 0.6608711484773659, disc_loss = 0.154725583097725
Trained batch 81 in epoch 1, gen_loss = 0.659708535162414, disc_loss = 0.1542699849800911
Trained batch 82 in epoch 1, gen_loss = 0.6584399145051657, disc_loss = 0.15377620844372425
Trained batch 83 in epoch 1, gen_loss = 0.6588611982408024, disc_loss = 0.1536397200765177
Trained batch 84 in epoch 1, gen_loss = 0.657119348119287, disc_loss = 0.1534919022965957
Trained batch 85 in epoch 1, gen_loss = 0.6567032229761744, disc_loss = 0.15236211025567595
Trained batch 86 in epoch 1, gen_loss = 0.6576242210536167, disc_loss = 0.15169305426079308
Trained batch 87 in epoch 1, gen_loss = 0.6569140888750553, disc_loss = 0.1518872715003619
Trained batch 88 in epoch 1, gen_loss = 0.6574283279059978, disc_loss = 0.15081682925771797
Trained batch 89 in epoch 1, gen_loss = 0.6574773877859116, disc_loss = 0.14971932780204547
Trained batch 90 in epoch 1, gen_loss = 0.6584174603551298, disc_loss = 0.1486696772338761
Trained batch 91 in epoch 1, gen_loss = 0.6586712660348933, disc_loss = 0.14785448723958564
Trained batch 92 in epoch 1, gen_loss = 0.6580296841359907, disc_loss = 0.14717247852835283
Trained batch 93 in epoch 1, gen_loss = 0.6598745403771705, disc_loss = 0.14699649219302105
Trained batch 94 in epoch 1, gen_loss = 0.6578915357589722, disc_loss = 0.1480081052666432
Trained batch 95 in epoch 1, gen_loss = 0.6571137718856335, disc_loss = 0.1474436960318902
Trained batch 96 in epoch 1, gen_loss = 0.6583266393425539, disc_loss = 0.1482817430298814
Trained batch 97 in epoch 1, gen_loss = 0.6569772922262853, disc_loss = 0.1485419724497716
Trained batch 98 in epoch 1, gen_loss = 0.6573949046809264, disc_loss = 0.14756917339194603
Trained batch 99 in epoch 1, gen_loss = 0.6574564379453659, disc_loss = 0.14751019137911497
Trained batch 100 in epoch 1, gen_loss = 0.6558664287671004, disc_loss = 0.14779770760658648
Trained batch 101 in epoch 1, gen_loss = 0.6561823808679393, disc_loss = 0.148087378545646
Trained batch 102 in epoch 1, gen_loss = 0.655304135628117, disc_loss = 0.14828317521085727
Trained batch 103 in epoch 1, gen_loss = 0.6551717726083902, disc_loss = 0.1481184032656109
Trained batch 104 in epoch 1, gen_loss = 0.6559931675593058, disc_loss = 0.14787054582543316
Trained batch 105 in epoch 1, gen_loss = 0.6557363929613581, disc_loss = 0.1472000520026206
Trained batch 106 in epoch 1, gen_loss = 0.6551724421643765, disc_loss = 0.1466618635230393
Trained batch 107 in epoch 1, gen_loss = 0.6544879073346103, disc_loss = 0.14615681018093946
Trained batch 108 in epoch 1, gen_loss = 0.6544156626823845, disc_loss = 0.14551622559820568
Trained batch 109 in epoch 1, gen_loss = 0.6534603704105724, disc_loss = 0.14495792912996627
Trained batch 110 in epoch 1, gen_loss = 0.6536236400002832, disc_loss = 0.1444021389140068
Trained batch 111 in epoch 1, gen_loss = 0.6536250572119441, disc_loss = 0.14340627911068232
Trained batch 112 in epoch 1, gen_loss = 0.6545896751690755, disc_loss = 0.14246390627252054
Trained batch 113 in epoch 1, gen_loss = 0.6554235957170788, disc_loss = 0.1416079432278741
Trained batch 114 in epoch 1, gen_loss = 0.6568354368209839, disc_loss = 0.1410701495392815
Trained batch 115 in epoch 1, gen_loss = 0.6559198267500976, disc_loss = 0.14074017225507776
Trained batch 116 in epoch 1, gen_loss = 0.6564634747994251, disc_loss = 0.14023520226757497
Trained batch 117 in epoch 1, gen_loss = 0.6570509793394703, disc_loss = 0.13922818564667794
Trained batch 118 in epoch 1, gen_loss = 0.6559851740588661, disc_loss = 0.13879039699696943
Trained batch 119 in epoch 1, gen_loss = 0.6565662076075872, disc_loss = 0.138334089742663
Trained batch 120 in epoch 1, gen_loss = 0.6564073207949804, disc_loss = 0.13743452525366684
Trained batch 121 in epoch 1, gen_loss = 0.657138319289098, disc_loss = 0.1364527609214553
Trained batch 122 in epoch 1, gen_loss = 0.6569224140508388, disc_loss = 0.13597327834979547
Trained batch 123 in epoch 1, gen_loss = 0.656263840775336, disc_loss = 0.1353308235880949
Trained batch 124 in epoch 1, gen_loss = 0.655948660850525, disc_loss = 0.13525352079421282
Trained batch 125 in epoch 1, gen_loss = 0.6579509543048011, disc_loss = 0.1392887171490916
Trained batch 126 in epoch 1, gen_loss = 0.6567103121224351, disc_loss = 0.13973548768572217
Trained batch 127 in epoch 1, gen_loss = 0.6554179443046451, disc_loss = 0.1399750830096309
Trained batch 128 in epoch 1, gen_loss = 0.6547595225563345, disc_loss = 0.13988713002511005
Trained batch 129 in epoch 1, gen_loss = 0.6537387311458588, disc_loss = 0.14035843055552014
Trained batch 130 in epoch 1, gen_loss = 0.6529220715733884, disc_loss = 0.14110775423442362
Trained batch 131 in epoch 1, gen_loss = 0.6512706823872797, disc_loss = 0.1418334262121017
Trained batch 132 in epoch 1, gen_loss = 0.6501416198741224, disc_loss = 0.1420574204548073
Trained batch 133 in epoch 1, gen_loss = 0.6495245861918179, disc_loss = 0.14247947848582668
Trained batch 134 in epoch 1, gen_loss = 0.6486013882690006, disc_loss = 0.14286830519774446
Trained batch 135 in epoch 1, gen_loss = 0.6478057689964771, disc_loss = 0.1432015791275155
Trained batch 136 in epoch 1, gen_loss = 0.6472216742317172, disc_loss = 0.14329966462903868
Trained batch 137 in epoch 1, gen_loss = 0.646952139078707, disc_loss = 0.14324966748582496
Trained batch 138 in epoch 1, gen_loss = 0.6459696732407851, disc_loss = 0.1431347104459465
Trained batch 139 in epoch 1, gen_loss = 0.6457865325467927, disc_loss = 0.14301304589025676
Trained batch 140 in epoch 1, gen_loss = 0.6451033448919337, disc_loss = 0.14294575837090717
Trained batch 141 in epoch 1, gen_loss = 0.6437400732661637, disc_loss = 0.14318810891963438
Trained batch 142 in epoch 1, gen_loss = 0.6442818685428245, disc_loss = 0.14448201537158314
Trained batch 143 in epoch 1, gen_loss = 0.6427909740143352, disc_loss = 0.1465995790398059
Trained batch 144 in epoch 1, gen_loss = 0.6426536420295978, disc_loss = 0.1472660183456951
Trained batch 145 in epoch 1, gen_loss = 0.6419782087410966, disc_loss = 0.14713780485629424
Trained batch 146 in epoch 1, gen_loss = 0.6409626884930799, disc_loss = 0.14768577398111424
Trained batch 147 in epoch 1, gen_loss = 0.6403064548566535, disc_loss = 0.147781033930998
Trained batch 148 in epoch 1, gen_loss = 0.6397131711444599, disc_loss = 0.14775892027697507
Trained batch 149 in epoch 1, gen_loss = 0.638799666762352, disc_loss = 0.14788517619793615
Trained batch 150 in epoch 1, gen_loss = 0.6377302181247054, disc_loss = 0.14800000196285792
Trained batch 151 in epoch 1, gen_loss = 0.6369728142101514, disc_loss = 0.14809654844851283
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6159282922744751, disc_loss = 0.23628836870193481
Trained batch 1 in epoch 2, gen_loss = 0.5623860359191895, disc_loss = 0.27461859583854675
Trained batch 2 in epoch 2, gen_loss = 0.5713890790939331, disc_loss = 0.2582426369190216
Trained batch 3 in epoch 2, gen_loss = 0.5605999678373337, disc_loss = 0.2303439900279045
Trained batch 4 in epoch 2, gen_loss = 0.5488016366958618, disc_loss = 0.21620033979415892
Trained batch 5 in epoch 2, gen_loss = 0.547735333442688, disc_loss = 0.20355165749788284
Trained batch 6 in epoch 2, gen_loss = 0.552498289516994, disc_loss = 0.19514014678342
Trained batch 7 in epoch 2, gen_loss = 0.5524668321013451, disc_loss = 0.18876259587705135
Trained batch 8 in epoch 2, gen_loss = 0.549286941687266, disc_loss = 0.1837263604005178
Trained batch 9 in epoch 2, gen_loss = 0.5405731171369552, disc_loss = 0.17831092625856398
Trained batch 10 in epoch 2, gen_loss = 0.538086628372019, disc_loss = 0.17327691005034881
Trained batch 11 in epoch 2, gen_loss = 0.5479546214143435, disc_loss = 0.1693430549154679
Trained batch 12 in epoch 2, gen_loss = 0.5442257317212912, disc_loss = 0.1702398732304573
Trained batch 13 in epoch 2, gen_loss = 0.5534164160490036, disc_loss = 0.1753987175013338
Trained batch 14 in epoch 2, gen_loss = 0.5513711273670197, disc_loss = 0.17331829418738684
Trained batch 15 in epoch 2, gen_loss = 0.5484910514205694, disc_loss = 0.1726178857497871
Trained batch 16 in epoch 2, gen_loss = 0.5549483457032371, disc_loss = 0.1824988718418514
Trained batch 17 in epoch 2, gen_loss = 0.5517521417803235, disc_loss = 0.18121674201554722
Trained batch 18 in epoch 2, gen_loss = 0.5503825592367273, disc_loss = 0.18180777955996363
Trained batch 19 in epoch 2, gen_loss = 0.5538394048810005, disc_loss = 0.18305541016161442
Trained batch 20 in epoch 2, gen_loss = 0.5539108983107975, disc_loss = 0.17954721585625694
Trained batch 21 in epoch 2, gen_loss = 0.549646030772816, disc_loss = 0.17922850867564027
Trained batch 22 in epoch 2, gen_loss = 0.5482589110084202, disc_loss = 0.1778808958504511
Trained batch 23 in epoch 2, gen_loss = 0.5469271366794904, disc_loss = 0.17521866193662086
Trained batch 24 in epoch 2, gen_loss = 0.5486985397338867, disc_loss = 0.17357904106378555
Trained batch 25 in epoch 2, gen_loss = 0.5475386449923882, disc_loss = 0.17173433733674195
Trained batch 26 in epoch 2, gen_loss = 0.5493788962010984, disc_loss = 0.17015686438039498
Trained batch 27 in epoch 2, gen_loss = 0.5491100166525159, disc_loss = 0.16819636124585355
Trained batch 28 in epoch 2, gen_loss = 0.5475969561215105, disc_loss = 0.1667857701922285
Trained batch 29 in epoch 2, gen_loss = 0.5451252122720083, disc_loss = 0.16527142723401386
Trained batch 30 in epoch 2, gen_loss = 0.5508326176674135, disc_loss = 0.16377836802313406
Trained batch 31 in epoch 2, gen_loss = 0.5468905568122864, disc_loss = 0.16841639718040824
Trained batch 32 in epoch 2, gen_loss = 0.5488102580561782, disc_loss = 0.16966226561502976
Trained batch 33 in epoch 2, gen_loss = 0.5479549695463741, disc_loss = 0.16749392625163584
Trained batch 34 in epoch 2, gen_loss = 0.5459916625704084, disc_loss = 0.1668593725987843
Trained batch 35 in epoch 2, gen_loss = 0.5469247632556491, disc_loss = 0.16720501167906654
Trained batch 36 in epoch 2, gen_loss = 0.5452991909271961, disc_loss = 0.16555626489020683
Trained batch 37 in epoch 2, gen_loss = 0.5473096582450365, disc_loss = 0.1634373568782681
Trained batch 38 in epoch 2, gen_loss = 0.5470294302854782, disc_loss = 0.16155724475781122
Trained batch 39 in epoch 2, gen_loss = 0.5508167706429958, disc_loss = 0.1594176510348916
Trained batch 40 in epoch 2, gen_loss = 0.5509458133360234, disc_loss = 0.1574578854005511
Trained batch 41 in epoch 2, gen_loss = 0.5539784807534445, disc_loss = 0.15453075147455647
Trained batch 42 in epoch 2, gen_loss = 0.5569025839484015, disc_loss = 0.15138923654029535
Trained batch 43 in epoch 2, gen_loss = 0.5568813512271101, disc_loss = 0.15036551366475495
Trained batch 44 in epoch 2, gen_loss = 0.5646113786432478, disc_loss = 0.15451983528004753
Trained batch 45 in epoch 2, gen_loss = 0.5655860842570014, disc_loss = 0.1517424711390682
Trained batch 46 in epoch 2, gen_loss = 0.5624100762478849, disc_loss = 0.15458996990259657
Trained batch 47 in epoch 2, gen_loss = 0.5643821613242229, disc_loss = 0.1577040390111506
Trained batch 48 in epoch 2, gen_loss = 0.5638878181272623, disc_loss = 0.15758125620837116
Trained batch 49 in epoch 2, gen_loss = 0.5612744456529617, disc_loss = 0.15849925920367242
Trained batch 50 in epoch 2, gen_loss = 0.5597237208310295, disc_loss = 0.1587908059066417
Trained batch 51 in epoch 2, gen_loss = 0.5607314396363038, disc_loss = 0.15993424977820653
Trained batch 52 in epoch 2, gen_loss = 0.5607444385312638, disc_loss = 0.15931529439282868
Trained batch 53 in epoch 2, gen_loss = 0.5602481895022922, disc_loss = 0.1590487803849909
Trained batch 54 in epoch 2, gen_loss = 0.5603098576719111, disc_loss = 0.15995147729461842
Trained batch 55 in epoch 2, gen_loss = 0.5598540465746608, disc_loss = 0.15877349421914136
Trained batch 56 in epoch 2, gen_loss = 0.5585249259806516, disc_loss = 0.15806478824008974
Trained batch 57 in epoch 2, gen_loss = 0.5583308190107346, disc_loss = 0.15761643840835013
Trained batch 58 in epoch 2, gen_loss = 0.5575230944964845, disc_loss = 0.1569591737904791
Trained batch 59 in epoch 2, gen_loss = 0.5585741872588793, disc_loss = 0.1570783980190754
Trained batch 60 in epoch 2, gen_loss = 0.5577286985076841, disc_loss = 0.15638628944021757
Trained batch 61 in epoch 2, gen_loss = 0.5584206057171668, disc_loss = 0.15602013348571717
Trained batch 62 in epoch 2, gen_loss = 0.5576459334956275, disc_loss = 0.15635198402026343
Trained batch 63 in epoch 2, gen_loss = 0.5584209407679737, disc_loss = 0.1570996819064021
Trained batch 64 in epoch 2, gen_loss = 0.556492628959509, disc_loss = 0.1585794068299807
Trained batch 65 in epoch 2, gen_loss = 0.5565354340907299, disc_loss = 0.15852614130937692
Trained batch 66 in epoch 2, gen_loss = 0.55644639792727, disc_loss = 0.15824430135648643
Trained batch 67 in epoch 2, gen_loss = 0.5569317616960582, disc_loss = 0.15751822095583468
Trained batch 68 in epoch 2, gen_loss = 0.5571293342804563, disc_loss = 0.15639224864434506
Trained batch 69 in epoch 2, gen_loss = 0.5580100004162107, disc_loss = 0.1546345403684037
Trained batch 70 in epoch 2, gen_loss = 0.5572692386701074, disc_loss = 0.15421753549869632
Trained batch 71 in epoch 2, gen_loss = 0.5584567863908079, disc_loss = 0.1544576619958712
Trained batch 72 in epoch 2, gen_loss = 0.5578991440061021, disc_loss = 0.15370873601673402
Trained batch 73 in epoch 2, gen_loss = 0.5586798984456707, disc_loss = 0.1523474023450871
Trained batch 74 in epoch 2, gen_loss = 0.5587114989757538, disc_loss = 0.15141317213575045
Trained batch 75 in epoch 2, gen_loss = 0.5601407960057259, disc_loss = 0.14964253408834338
Trained batch 76 in epoch 2, gen_loss = 0.5604780629857794, disc_loss = 0.14864252993909569
Trained batch 77 in epoch 2, gen_loss = 0.5618674674859414, disc_loss = 0.14774963777894393
Trained batch 78 in epoch 2, gen_loss = 0.5618280047857309, disc_loss = 0.1475552894127897
Trained batch 79 in epoch 2, gen_loss = 0.564059792086482, disc_loss = 0.14794467820320278
Trained batch 80 in epoch 2, gen_loss = 0.5640542326885977, disc_loss = 0.14748133500509056
Trained batch 81 in epoch 2, gen_loss = 0.5650546249093079, disc_loss = 0.1463937924993111
Trained batch 82 in epoch 2, gen_loss = 0.5652066494326994, disc_loss = 0.14534474193421473
Trained batch 83 in epoch 2, gen_loss = 0.5659019602906137, disc_loss = 0.14413019653321021
Trained batch 84 in epoch 2, gen_loss = 0.5681037520661073, disc_loss = 0.1445468460154884
Trained batch 85 in epoch 2, gen_loss = 0.5668854498585989, disc_loss = 0.1442824052213583
Trained batch 86 in epoch 2, gen_loss = 0.5657898023210722, disc_loss = 0.1438353694761279
Trained batch 87 in epoch 2, gen_loss = 0.5677356191656806, disc_loss = 0.1465831625232981
Trained batch 88 in epoch 2, gen_loss = 0.5668520080239585, disc_loss = 0.14658825880104906
Trained batch 89 in epoch 2, gen_loss = 0.5653275512986713, disc_loss = 0.14670853790723615
Trained batch 90 in epoch 2, gen_loss = 0.5654840439885527, disc_loss = 0.14588463144724842
Trained batch 91 in epoch 2, gen_loss = 0.5648504615477894, disc_loss = 0.14523251024682238
Trained batch 92 in epoch 2, gen_loss = 0.5656257448016956, disc_loss = 0.14490767866773632
Trained batch 93 in epoch 2, gen_loss = 0.5642509970893251, disc_loss = 0.14606922423031102
Trained batch 94 in epoch 2, gen_loss = 0.5661115059727116, disc_loss = 0.14641170848749185
Trained batch 95 in epoch 2, gen_loss = 0.5657627970601121, disc_loss = 0.14616315262780213
Trained batch 96 in epoch 2, gen_loss = 0.565274615570442, disc_loss = 0.1457213158191172
Trained batch 97 in epoch 2, gen_loss = 0.5658063070506466, disc_loss = 0.14564843743811456
Trained batch 98 in epoch 2, gen_loss = 0.5658899681134657, disc_loss = 0.14461398540497428
Trained batch 99 in epoch 2, gen_loss = 0.5658884790539741, disc_loss = 0.14354956293478607
Trained batch 100 in epoch 2, gen_loss = 0.5659643709659576, disc_loss = 0.14278145601032394
Trained batch 101 in epoch 2, gen_loss = 0.5675673131264892, disc_loss = 0.14238061933029517
Trained batch 102 in epoch 2, gen_loss = 0.5676259083076588, disc_loss = 0.14192599023791772
Trained batch 103 in epoch 2, gen_loss = 0.5692122335044237, disc_loss = 0.1418588431731153
Trained batch 104 in epoch 2, gen_loss = 0.568837628194264, disc_loss = 0.14081649132782503
Trained batch 105 in epoch 2, gen_loss = 0.5674169842364654, disc_loss = 0.1415943678222456
Trained batch 106 in epoch 2, gen_loss = 0.569413768075337, disc_loss = 0.14162218770900062
Trained batch 107 in epoch 2, gen_loss = 0.569047461229342, disc_loss = 0.1408606114866281
Trained batch 108 in epoch 2, gen_loss = 0.5698495056104222, disc_loss = 0.13998041754810636
Trained batch 109 in epoch 2, gen_loss = 0.5697526582262733, disc_loss = 0.13956419346346097
Trained batch 110 in epoch 2, gen_loss = 0.5691636497372979, disc_loss = 0.13885537352043767
Trained batch 111 in epoch 2, gen_loss = 0.5698880704918078, disc_loss = 0.13785953465516546
Trained batch 112 in epoch 2, gen_loss = 0.5710177904209205, disc_loss = 0.13682165771590926
Trained batch 113 in epoch 2, gen_loss = 0.571037158370018, disc_loss = 0.136036366126255
Trained batch 114 in epoch 2, gen_loss = 0.5695833188036213, disc_loss = 0.13716598195226296
Trained batch 115 in epoch 2, gen_loss = 0.571208710557428, disc_loss = 0.1400582211349031
Trained batch 116 in epoch 2, gen_loss = 0.5709043906794654, disc_loss = 0.14000779278894776
Trained batch 117 in epoch 2, gen_loss = 0.5704171387320858, disc_loss = 0.14059277816470397
Trained batch 118 in epoch 2, gen_loss = 0.5704122283378569, disc_loss = 0.14065269452809287
Trained batch 119 in epoch 2, gen_loss = 0.5704728595912456, disc_loss = 0.1405274886948367
Trained batch 120 in epoch 2, gen_loss = 0.5700204768949304, disc_loss = 0.1402834232988929
Trained batch 121 in epoch 2, gen_loss = 0.5689974869372415, disc_loss = 0.13997225490872
Trained batch 122 in epoch 2, gen_loss = 0.569548576101055, disc_loss = 0.13962115695684907
Trained batch 123 in epoch 2, gen_loss = 0.5694225927995097, disc_loss = 0.1388860119566802
Trained batch 124 in epoch 2, gen_loss = 0.5693527338504791, disc_loss = 0.1383132860660553
Trained batch 125 in epoch 2, gen_loss = 0.5702866620960689, disc_loss = 0.1384766772389412
Trained batch 126 in epoch 2, gen_loss = 0.5705052001739112, disc_loss = 0.13760797408094086
Trained batch 127 in epoch 2, gen_loss = 0.5698924160096794, disc_loss = 0.13744909140223172
Trained batch 128 in epoch 2, gen_loss = 0.5703543731870577, disc_loss = 0.13683511453947816
Trained batch 129 in epoch 2, gen_loss = 0.571293879701541, disc_loss = 0.13607980590313673
Trained batch 130 in epoch 2, gen_loss = 0.5707867275212557, disc_loss = 0.13636378606937768
Trained batch 131 in epoch 2, gen_loss = 0.5717699421626149, disc_loss = 0.13770935745119597
Trained batch 132 in epoch 2, gen_loss = 0.5715937697349635, disc_loss = 0.13733998819121293
Trained batch 133 in epoch 2, gen_loss = 0.5712992915911461, disc_loss = 0.13708075078954893
Trained batch 134 in epoch 2, gen_loss = 0.5705099090381905, disc_loss = 0.13678127305099258
Trained batch 135 in epoch 2, gen_loss = 0.5709911069887526, disc_loss = 0.13651119631386416
Trained batch 136 in epoch 2, gen_loss = 0.5704475029976699, disc_loss = 0.13628496598098835
Trained batch 137 in epoch 2, gen_loss = 0.5705251436734545, disc_loss = 0.1360241919081064
Trained batch 138 in epoch 2, gen_loss = 0.5703413968892406, disc_loss = 0.13523871348433786
Trained batch 139 in epoch 2, gen_loss = 0.5698932317750794, disc_loss = 0.1345491649183844
Trained batch 140 in epoch 2, gen_loss = 0.5706635043553426, disc_loss = 0.13401768894218807
Trained batch 141 in epoch 2, gen_loss = 0.5713504042843698, disc_loss = 0.13317993312129672
Trained batch 142 in epoch 2, gen_loss = 0.5713948755414335, disc_loss = 0.13237440513147342
Trained batch 143 in epoch 2, gen_loss = 0.5713406650142537, disc_loss = 0.1315991264871425
Trained batch 144 in epoch 2, gen_loss = 0.571033374811041, disc_loss = 0.1310660719871521
Trained batch 145 in epoch 2, gen_loss = 0.5721705329336532, disc_loss = 0.13158051567534879
Trained batch 146 in epoch 2, gen_loss = 0.5710341646557763, disc_loss = 0.13199885676101764
Trained batch 147 in epoch 2, gen_loss = 0.571375427213875, disc_loss = 0.13156516814755426
Trained batch 148 in epoch 2, gen_loss = 0.5721629485987977, disc_loss = 0.13138466613404703
Trained batch 149 in epoch 2, gen_loss = 0.5713476272424062, disc_loss = 0.1318439041574796
Trained batch 150 in epoch 2, gen_loss = 0.5721686628480621, disc_loss = 0.1317033927566958
Trained batch 151 in epoch 2, gen_loss = 0.5721506515615865, disc_loss = 0.13134042551054767
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.5568512678146362, disc_loss = 0.07671907544136047
Trained batch 1 in epoch 3, gen_loss = 0.6313855350017548, disc_loss = 0.05643048323690891
Trained batch 2 in epoch 3, gen_loss = 0.6210935314496359, disc_loss = 0.043103683119018875
Trained batch 3 in epoch 3, gen_loss = 0.5868847891688347, disc_loss = 0.07082181284204125
Trained batch 4 in epoch 3, gen_loss = 0.6173068463802338, disc_loss = 0.13765570409595967
Trained batch 5 in epoch 3, gen_loss = 0.618238553404808, disc_loss = 0.13319804426282644
Trained batch 6 in epoch 3, gen_loss = 0.5985038493360791, disc_loss = 0.1292846386453935
Trained batch 7 in epoch 3, gen_loss = 0.5841273292899132, disc_loss = 0.12474636943079531
Trained batch 8 in epoch 3, gen_loss = 0.5845093131065369, disc_loss = 0.11832922800547546
Trained batch 9 in epoch 3, gen_loss = 0.5872293412685394, disc_loss = 0.11263888385146856
Trained batch 10 in epoch 3, gen_loss = 0.5775959708473899, disc_loss = 0.11116188408976252
Trained batch 11 in epoch 3, gen_loss = 0.5846264660358429, disc_loss = 0.11485353158786893
Trained batch 12 in epoch 3, gen_loss = 0.5745457708835602, disc_loss = 0.11784614550952728
Trained batch 13 in epoch 3, gen_loss = 0.5768659647021975, disc_loss = 0.11808744112827949
Trained batch 14 in epoch 3, gen_loss = 0.5736541052659353, disc_loss = 0.11638299164672693
Trained batch 15 in epoch 3, gen_loss = 0.5710802767425776, disc_loss = 0.11261867510620505
Trained batch 16 in epoch 3, gen_loss = 0.5712973913725685, disc_loss = 0.10857585872359135
Trained batch 17 in epoch 3, gen_loss = 0.5818947967555788, disc_loss = 0.10783217112637228
Trained batch 18 in epoch 3, gen_loss = 0.5819246094477805, disc_loss = 0.10299373163204444
Trained batch 19 in epoch 3, gen_loss = 0.5779186651110649, disc_loss = 0.10258762817829847
Trained batch 20 in epoch 3, gen_loss = 0.5795255658172426, disc_loss = 0.09851068400201343
Trained batch 21 in epoch 3, gen_loss = 0.5819730772213503, disc_loss = 0.09453768816522577
Trained batch 22 in epoch 3, gen_loss = 0.582288929949636, disc_loss = 0.09136748346297638
Trained batch 23 in epoch 3, gen_loss = 0.5856727473437786, disc_loss = 0.08860642920869093
Trained batch 24 in epoch 3, gen_loss = 0.5857166469097137, disc_loss = 0.08654423035681248
Trained batch 25 in epoch 3, gen_loss = 0.5819301295738953, disc_loss = 0.08617482971973144
Trained batch 26 in epoch 3, gen_loss = 0.5797727670934465, disc_loss = 0.08503871169631128
Trained batch 27 in epoch 3, gen_loss = 0.583143307694367, disc_loss = 0.08899231421362076
Trained batch 28 in epoch 3, gen_loss = 0.5804667236476109, disc_loss = 0.08725228102813506
Trained batch 29 in epoch 3, gen_loss = 0.575747749209404, disc_loss = 0.09163639266043902
Trained batch 30 in epoch 3, gen_loss = 0.5806946168022771, disc_loss = 0.09241602179263869
Trained batch 31 in epoch 3, gen_loss = 0.586351920850575, disc_loss = 0.09222510264953598
Trained batch 32 in epoch 3, gen_loss = 0.5834497980999224, disc_loss = 0.09244446066970174
Trained batch 33 in epoch 3, gen_loss = 0.5834947465097203, disc_loss = 0.09032367942306925
Trained batch 34 in epoch 3, gen_loss = 0.5861710573945726, disc_loss = 0.08834058434835503
Trained batch 35 in epoch 3, gen_loss = 0.5896500771244367, disc_loss = 0.08623125179049869
Trained batch 36 in epoch 3, gen_loss = 0.5910797723241754, disc_loss = 0.08424650316403524
Trained batch 37 in epoch 3, gen_loss = 0.5904792586439535, disc_loss = 0.08238850955508258
Trained batch 38 in epoch 3, gen_loss = 0.5898572107156118, disc_loss = 0.0813209772683107
Trained batch 39 in epoch 3, gen_loss = 0.5897509612143039, disc_loss = 0.08158781556412578
Trained batch 40 in epoch 3, gen_loss = 0.587955001650787, disc_loss = 0.0812816771610481
Trained batch 41 in epoch 3, gen_loss = 0.5902893521956035, disc_loss = 0.08116443694702216
Trained batch 42 in epoch 3, gen_loss = 0.5895627161791158, disc_loss = 0.08045654388707738
Trained batch 43 in epoch 3, gen_loss = 0.5903405201706019, disc_loss = 0.0793120692145418
Trained batch 44 in epoch 3, gen_loss = 0.5903157850106557, disc_loss = 0.07825033999979496
Trained batch 45 in epoch 3, gen_loss = 0.5896944721107897, disc_loss = 0.0771461691626388
Trained batch 46 in epoch 3, gen_loss = 0.5926287484929916, disc_loss = 0.07603531251562402
Trained batch 47 in epoch 3, gen_loss = 0.5925078708678484, disc_loss = 0.07481245700425158
Trained batch 48 in epoch 3, gen_loss = 0.5948228598857412, disc_loss = 0.07353903450147838
Trained batch 49 in epoch 3, gen_loss = 0.5954954785108566, disc_loss = 0.07227612024173141
Trained batch 50 in epoch 3, gen_loss = 0.5944292434290344, disc_loss = 0.07218427391832366
Trained batch 51 in epoch 3, gen_loss = 0.5981151077609795, disc_loss = 0.07450721661846799
Trained batch 52 in epoch 3, gen_loss = 0.5986752853078662, disc_loss = 0.07329323597884965
Trained batch 53 in epoch 3, gen_loss = 0.5993363917977722, disc_loss = 0.07327399435625584
Trained batch 54 in epoch 3, gen_loss = 0.5978475381027568, disc_loss = 0.07346518044783311
Trained batch 55 in epoch 3, gen_loss = 0.6002148331276008, disc_loss = 0.07321432989556342
Trained batch 56 in epoch 3, gen_loss = 0.6024019430603897, disc_loss = 0.07335055186494924
Trained batch 57 in epoch 3, gen_loss = 0.603257677164571, disc_loss = 0.07269688694063446
Trained batch 58 in epoch 3, gen_loss = 0.603665016970392, disc_loss = 0.07205021095667351
Trained batch 59 in epoch 3, gen_loss = 0.602359044055144, disc_loss = 0.07111452769798537
Trained batch 60 in epoch 3, gen_loss = 0.6017752978645388, disc_loss = 0.07030688426228332
Trained batch 61 in epoch 3, gen_loss = 0.6041499063853295, disc_loss = 0.06963144070018203
Trained batch 62 in epoch 3, gen_loss = 0.6059580298643263, disc_loss = 0.06872079064626069
Trained batch 63 in epoch 3, gen_loss = 0.6061551938764751, disc_loss = 0.06820767796307337
Trained batch 64 in epoch 3, gen_loss = 0.6070605456829071, disc_loss = 0.06731354902283504
Trained batch 65 in epoch 3, gen_loss = 0.6087923379558505, disc_loss = 0.06712487507893732
Trained batch 66 in epoch 3, gen_loss = 0.6087420329229155, disc_loss = 0.06627411256307986
Trained batch 67 in epoch 3, gen_loss = 0.6083775044364088, disc_loss = 0.06589612813995165
Trained batch 68 in epoch 3, gen_loss = 0.6100205221901769, disc_loss = 0.06516701306985773
Trained batch 69 in epoch 3, gen_loss = 0.6116435949291502, disc_loss = 0.06443387661129236
Trained batch 70 in epoch 3, gen_loss = 0.611724747318617, disc_loss = 0.06364668444008895
Trained batch 71 in epoch 3, gen_loss = 0.6111857953170935, disc_loss = 0.06316044838685128
Trained batch 72 in epoch 3, gen_loss = 0.6102312505245209, disc_loss = 0.06272170866188938
Trained batch 73 in epoch 3, gen_loss = 0.6116426937483452, disc_loss = 0.062120514141546714
Trained batch 74 in epoch 3, gen_loss = 0.6106309521198273, disc_loss = 0.061729528705279035
Trained batch 75 in epoch 3, gen_loss = 0.6117711267188976, disc_loss = 0.0614256247093803
Trained batch 76 in epoch 3, gen_loss = 0.6120524820569274, disc_loss = 0.06078296326487869
Trained batch 77 in epoch 3, gen_loss = 0.6117768803468118, disc_loss = 0.06027463515504049
Trained batch 78 in epoch 3, gen_loss = 0.6116255155847042, disc_loss = 0.05968942879876004
Trained batch 79 in epoch 3, gen_loss = 0.6122333373874426, disc_loss = 0.059048804873600605
Trained batch 80 in epoch 3, gen_loss = 0.6133146974039666, disc_loss = 0.058547261734435585
Trained batch 81 in epoch 3, gen_loss = 0.6133219741466569, disc_loss = 0.05839622225158098
Trained batch 82 in epoch 3, gen_loss = 0.6143907326531698, disc_loss = 0.05912646386458213
Trained batch 83 in epoch 3, gen_loss = 0.6149923570808911, disc_loss = 0.05871839732641265
Trained batch 84 in epoch 3, gen_loss = 0.6144702634390663, disc_loss = 0.05927398537888246
Trained batch 85 in epoch 3, gen_loss = 0.6134929397078448, disc_loss = 0.059457294123117316
Trained batch 86 in epoch 3, gen_loss = 0.6166434250343805, disc_loss = 0.06003271548569888
Trained batch 87 in epoch 3, gen_loss = 0.6184547235342589, disc_loss = 0.05958388987081972
Trained batch 88 in epoch 3, gen_loss = 0.6193113866147031, disc_loss = 0.059041143625221226
Trained batch 89 in epoch 3, gen_loss = 0.6189706984493467, disc_loss = 0.05891896460412277
Trained batch 90 in epoch 3, gen_loss = 0.6192813184890118, disc_loss = 0.05852162904505219
Trained batch 91 in epoch 3, gen_loss = 0.6197817724036134, disc_loss = 0.05797633748380062
Trained batch 92 in epoch 3, gen_loss = 0.6197846567118039, disc_loss = 0.05758027264708152
Trained batch 93 in epoch 3, gen_loss = 0.6213192359564153, disc_loss = 0.057471573719398136
Trained batch 94 in epoch 3, gen_loss = 0.6215717607422879, disc_loss = 0.056940977108713826
Trained batch 95 in epoch 3, gen_loss = 0.6203390741720796, disc_loss = 0.056809472996974364
Trained batch 96 in epoch 3, gen_loss = 0.6205720425266581, disc_loss = 0.056320092535203266
Trained batch 97 in epoch 3, gen_loss = 0.6205125563606924, disc_loss = 0.05602035067063205
Trained batch 98 in epoch 3, gen_loss = 0.6212054722838931, disc_loss = 0.05554654459572501
Trained batch 99 in epoch 3, gen_loss = 0.6206334856152534, disc_loss = 0.05521948494948447
Trained batch 100 in epoch 3, gen_loss = 0.6225433470589099, disc_loss = 0.05492537690898274
Trained batch 101 in epoch 3, gen_loss = 0.6233401248852412, disc_loss = 0.054509822105733206
Trained batch 102 in epoch 3, gen_loss = 0.6237971739282886, disc_loss = 0.054065970134315564
Trained batch 103 in epoch 3, gen_loss = 0.6235834185320598, disc_loss = 0.05360761454078154
Trained batch 104 in epoch 3, gen_loss = 0.6240260212194352, disc_loss = 0.05317042310766521
Trained batch 105 in epoch 3, gen_loss = 0.6237977504167916, disc_loss = 0.052736141336730345
Trained batch 106 in epoch 3, gen_loss = 0.6243387870142393, disc_loss = 0.05231580827124069
Trained batch 107 in epoch 3, gen_loss = 0.6247312661122393, disc_loss = 0.051908327520962944
Trained batch 108 in epoch 3, gen_loss = 0.6240604342123784, disc_loss = 0.051737106118966404
Trained batch 109 in epoch 3, gen_loss = 0.6246259811249646, disc_loss = 0.05243437000211667
Trained batch 110 in epoch 3, gen_loss = 0.6234948576033652, disc_loss = 0.052609224321303875
Trained batch 111 in epoch 3, gen_loss = 0.6225284279457161, disc_loss = 0.05257533002960762
Trained batch 112 in epoch 3, gen_loss = 0.6234375475782209, disc_loss = 0.05416016061007317
Trained batch 113 in epoch 3, gen_loss = 0.6231720933788701, disc_loss = 0.0538793876889701
Trained batch 114 in epoch 3, gen_loss = 0.6211725245351377, disc_loss = 0.055339522347987995
Trained batch 115 in epoch 3, gen_loss = 0.6216501999517967, disc_loss = 0.056143679507558455
Trained batch 116 in epoch 3, gen_loss = 0.6214355388258257, disc_loss = 0.05612436415723119
Trained batch 117 in epoch 3, gen_loss = 0.6207129162246898, disc_loss = 0.056256043657628915
Trained batch 118 in epoch 3, gen_loss = 0.6208154468977151, disc_loss = 0.05631924922648473
Trained batch 119 in epoch 3, gen_loss = 0.6211369161804517, disc_loss = 0.05742166000030314
Trained batch 120 in epoch 3, gen_loss = 0.6195861721826978, disc_loss = 0.059439487274243565
Trained batch 121 in epoch 3, gen_loss = 0.6196474476915891, disc_loss = 0.060440662038344584
Trained batch 122 in epoch 3, gen_loss = 0.6188567120854448, disc_loss = 0.060897323367284324
Trained batch 123 in epoch 3, gen_loss = 0.6173240117007687, disc_loss = 0.0625813432270661
Trained batch 124 in epoch 3, gen_loss = 0.6173180029392242, disc_loss = 0.06452047200128436
Trained batch 125 in epoch 3, gen_loss = 0.6163630880533703, disc_loss = 0.06531624230999677
Trained batch 126 in epoch 3, gen_loss = 0.6152438624637333, disc_loss = 0.06582032901960916
Trained batch 127 in epoch 3, gen_loss = 0.613805531989783, disc_loss = 0.06663838338499772
Trained batch 128 in epoch 3, gen_loss = 0.6131580328756525, disc_loss = 0.06724332014185398
Trained batch 129 in epoch 3, gen_loss = 0.6123613064105694, disc_loss = 0.06745232212930345
Trained batch 130 in epoch 3, gen_loss = 0.6113186988211771, disc_loss = 0.06750644790008664
Trained batch 131 in epoch 3, gen_loss = 0.6110308382547263, disc_loss = 0.0671795731036444
Trained batch 132 in epoch 3, gen_loss = 0.6109871434089833, disc_loss = 0.06698923137501106
Trained batch 133 in epoch 3, gen_loss = 0.6104682795147398, disc_loss = 0.06695822759448036
Trained batch 134 in epoch 3, gen_loss = 0.6108174659587718, disc_loss = 0.06655919195532246
Trained batch 135 in epoch 3, gen_loss = 0.6112817955367705, disc_loss = 0.06613847177461996
Trained batch 136 in epoch 3, gen_loss = 0.6103177281626819, disc_loss = 0.06631370233779732
Trained batch 137 in epoch 3, gen_loss = 0.6109090345925179, disc_loss = 0.06670289202863215
Trained batch 138 in epoch 3, gen_loss = 0.6095100690563806, disc_loss = 0.06774484143398113
Trained batch 139 in epoch 3, gen_loss = 0.6107049156512533, disc_loss = 0.06898326083152954
Trained batch 140 in epoch 3, gen_loss = 0.6102941291974792, disc_loss = 0.06885054691344605
Trained batch 141 in epoch 3, gen_loss = 0.6100860009310951, disc_loss = 0.06848735327858635
Trained batch 142 in epoch 3, gen_loss = 0.6095699115649803, disc_loss = 0.06839906796487374
Trained batch 143 in epoch 3, gen_loss = 0.6097685638815165, disc_loss = 0.06822420821926142
Trained batch 144 in epoch 3, gen_loss = 0.6096152426867649, disc_loss = 0.06802914239915794
Trained batch 145 in epoch 3, gen_loss = 0.6090712292145376, disc_loss = 0.0677835775941151
Trained batch 146 in epoch 3, gen_loss = 0.6085385811977646, disc_loss = 0.06778873827270403
Trained batch 147 in epoch 3, gen_loss = 0.6094159437595187, disc_loss = 0.06858409769719818
Trained batch 148 in epoch 3, gen_loss = 0.6088564285895969, disc_loss = 0.06853326462246728
Trained batch 149 in epoch 3, gen_loss = 0.6083449214696884, disc_loss = 0.06864190401819845
Trained batch 150 in epoch 3, gen_loss = 0.6083928459132744, disc_loss = 0.06972986225051102
Trained batch 151 in epoch 3, gen_loss = 0.6075408878295046, disc_loss = 0.07007898956132856
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.6696937084197998, disc_loss = 0.03842274844646454
Trained batch 1 in epoch 4, gen_loss = 0.6514480113983154, disc_loss = 0.0320335254073143
Trained batch 2 in epoch 4, gen_loss = 0.5941380063692728, disc_loss = 0.040879733860492706
Trained batch 3 in epoch 4, gen_loss = 0.601809024810791, disc_loss = 0.03514231834560633
Trained batch 4 in epoch 4, gen_loss = 0.6073642015457154, disc_loss = 0.042717204242944715
Trained batch 5 in epoch 4, gen_loss = 0.5792629271745682, disc_loss = 0.07181644005080064
Trained batch 6 in epoch 4, gen_loss = 0.5917581532682691, disc_loss = 0.08676868730357715
Trained batch 7 in epoch 4, gen_loss = 0.5787959434092045, disc_loss = 0.08934644190594554
Trained batch 8 in epoch 4, gen_loss = 0.5830823745992448, disc_loss = 0.08486967492434713
Trained batch 9 in epoch 4, gen_loss = 0.5849273473024368, disc_loss = 0.08083884231746197
Trained batch 10 in epoch 4, gen_loss = 0.573426135561683, disc_loss = 0.09028358994559808
Trained batch 11 in epoch 4, gen_loss = 0.5885961527625719, disc_loss = 0.10902576241642237
Trained batch 12 in epoch 4, gen_loss = 0.5866331435166873, disc_loss = 0.10479656177071425
Trained batch 13 in epoch 4, gen_loss = 0.5765800539936338, disc_loss = 0.11156431239630495
Trained batch 14 in epoch 4, gen_loss = 0.5824514925479889, disc_loss = 0.11888265187541644
Trained batch 15 in epoch 4, gen_loss = 0.582068232819438, disc_loss = 0.11400434235110879
Trained batch 16 in epoch 4, gen_loss = 0.5784538475906148, disc_loss = 0.11260329800493576
Trained batch 17 in epoch 4, gen_loss = 0.5810019291109509, disc_loss = 0.10939481978615125
Trained batch 18 in epoch 4, gen_loss = 0.5821442149187389, disc_loss = 0.10585453086777737
Trained batch 19 in epoch 4, gen_loss = 0.5847401842474937, disc_loss = 0.10108862128108739
Trained batch 20 in epoch 4, gen_loss = 0.5838351718017033, disc_loss = 0.09734051302075386
Trained batch 21 in epoch 4, gen_loss = 0.5884291218085722, disc_loss = 0.09465351582250812
Trained batch 22 in epoch 4, gen_loss = 0.5906150613142096, disc_loss = 0.09091246464168248
Trained batch 23 in epoch 4, gen_loss = 0.5890387656788031, disc_loss = 0.08886360062751919
Trained batch 24 in epoch 4, gen_loss = 0.5836599361896515, disc_loss = 0.0906675111874938
Trained batch 25 in epoch 4, gen_loss = 0.5920886729772274, disc_loss = 0.10160247404844715
Trained batch 26 in epoch 4, gen_loss = 0.5921042484265787, disc_loss = 0.10175276185489363
Trained batch 27 in epoch 4, gen_loss = 0.5868877874953407, disc_loss = 0.1029362060861396
Trained batch 28 in epoch 4, gen_loss = 0.5834245753699335, disc_loss = 0.10160578270282211
Trained batch 29 in epoch 4, gen_loss = 0.5848423888285955, disc_loss = 0.10138544958705703
Trained batch 30 in epoch 4, gen_loss = 0.5845145650448338, disc_loss = 0.09893181574560943
Trained batch 31 in epoch 4, gen_loss = 0.5860819993540645, disc_loss = 0.09628726448863745
Trained batch 32 in epoch 4, gen_loss = 0.5860391611402685, disc_loss = 0.09422676818388881
Trained batch 33 in epoch 4, gen_loss = 0.5844032527769313, disc_loss = 0.09426707127953277
Trained batch 34 in epoch 4, gen_loss = 0.5843676473413195, disc_loss = 0.0929321961743491
Trained batch 35 in epoch 4, gen_loss = 0.5830841801232762, disc_loss = 0.09148912390487061
Trained batch 36 in epoch 4, gen_loss = 0.5798292667479128, disc_loss = 0.09328986674144461
Trained batch 37 in epoch 4, gen_loss = 0.5839181189474306, disc_loss = 0.0997729804366827
Trained batch 38 in epoch 4, gen_loss = 0.5815766071661924, disc_loss = 0.09938855096697807
Trained batch 39 in epoch 4, gen_loss = 0.5790050283074379, disc_loss = 0.09985071318224073
Trained batch 40 in epoch 4, gen_loss = 0.5804284462114659, disc_loss = 0.0980813911230099
Trained batch 41 in epoch 4, gen_loss = 0.5817838382153284, disc_loss = 0.09660954755686578
Trained batch 42 in epoch 4, gen_loss = 0.5843888202378916, disc_loss = 0.09465356370390848
Trained batch 43 in epoch 4, gen_loss = 0.583419990810481, disc_loss = 0.09332977616312829
Trained batch 44 in epoch 4, gen_loss = 0.5854647186067369, disc_loss = 0.09145653061568737
Trained batch 45 in epoch 4, gen_loss = 0.5877114093821981, disc_loss = 0.08980931228269702
Trained batch 46 in epoch 4, gen_loss = 0.5893386678492769, disc_loss = 0.088075514248711
Trained batch 47 in epoch 4, gen_loss = 0.5891899938384692, disc_loss = 0.08642134132484595
Trained batch 48 in epoch 4, gen_loss = 0.5894315121125202, disc_loss = 0.08498208000495726
Trained batch 49 in epoch 4, gen_loss = 0.5896996414661407, disc_loss = 0.08346067290753126
Trained batch 50 in epoch 4, gen_loss = 0.5891704056777206, disc_loss = 0.08218812212055805
Trained batch 51 in epoch 4, gen_loss = 0.5918966715152447, disc_loss = 0.08083073590667202
Trained batch 52 in epoch 4, gen_loss = 0.5927833116279458, disc_loss = 0.07957807745573656
Trained batch 53 in epoch 4, gen_loss = 0.5913358231385549, disc_loss = 0.07915039670964082
Trained batch 54 in epoch 4, gen_loss = 0.5914537505670028, disc_loss = 0.07815068858590993
Trained batch 55 in epoch 4, gen_loss = 0.5918815732002258, disc_loss = 0.07712029027087348
Trained batch 56 in epoch 4, gen_loss = 0.5943127138572827, disc_loss = 0.07669956929850996
Trained batch 57 in epoch 4, gen_loss = 0.593949385758104, disc_loss = 0.07570800907781412
Trained batch 58 in epoch 4, gen_loss = 0.5933460077996981, disc_loss = 0.07546799569943194
Trained batch 59 in epoch 4, gen_loss = 0.5972094357013702, disc_loss = 0.07550096167251467
Trained batch 60 in epoch 4, gen_loss = 0.5983920273233633, disc_loss = 0.07446021589710088
Trained batch 61 in epoch 4, gen_loss = 0.5999185587129285, disc_loss = 0.07347662939179328
Trained batch 62 in epoch 4, gen_loss = 0.6017406781514486, disc_loss = 0.0724888446312102
Trained batch 63 in epoch 4, gen_loss = 0.6027006730437279, disc_loss = 0.07151703540876042
Trained batch 64 in epoch 4, gen_loss = 0.6028421255258414, disc_loss = 0.07051080834263793
Trained batch 65 in epoch 4, gen_loss = 0.6035321427114082, disc_loss = 0.06953243319312054
Trained batch 66 in epoch 4, gen_loss = 0.6040451313132671, disc_loss = 0.06856952710494177
Trained batch 67 in epoch 4, gen_loss = 0.6042261000941781, disc_loss = 0.06763481525430347
Trained batch 68 in epoch 4, gen_loss = 0.6044719823892566, disc_loss = 0.06672111466742944
Trained batch 69 in epoch 4, gen_loss = 0.6050804921558925, disc_loss = 0.06582927594759634
Trained batch 70 in epoch 4, gen_loss = 0.6059996275834634, disc_loss = 0.0649713125657028
Trained batch 71 in epoch 4, gen_loss = 0.6059933023320304, disc_loss = 0.0641262757514293
Trained batch 72 in epoch 4, gen_loss = 0.6064498783790901, disc_loss = 0.06331342734294394
Trained batch 73 in epoch 4, gen_loss = 0.6066893194172833, disc_loss = 0.06253557700688976
Trained batch 74 in epoch 4, gen_loss = 0.6070068335533142, disc_loss = 0.061787681200852
Trained batch 75 in epoch 4, gen_loss = 0.6072172530387577, disc_loss = 0.06106225333152045
Trained batch 76 in epoch 4, gen_loss = 0.6068430976434187, disc_loss = 0.06034449275655599
Trained batch 77 in epoch 4, gen_loss = 0.6064415917946742, disc_loss = 0.05963513929731189
Trained batch 78 in epoch 4, gen_loss = 0.6073058594631243, disc_loss = 0.05894540939951622
Trained batch 79 in epoch 4, gen_loss = 0.6074493281543255, disc_loss = 0.05837927558459342
Trained batch 80 in epoch 4, gen_loss = 0.6076086766925859, disc_loss = 0.05771909847303673
Trained batch 81 in epoch 4, gen_loss = 0.6080411592634712, disc_loss = 0.05708290082288951
Trained batch 82 in epoch 4, gen_loss = 0.6088878670370722, disc_loss = 0.05646830667034689
Trained batch 83 in epoch 4, gen_loss = 0.6091012564443407, disc_loss = 0.05584409136125552
Trained batch 84 in epoch 4, gen_loss = 0.6086450618856093, disc_loss = 0.05528207977357156
Trained batch 85 in epoch 4, gen_loss = 0.6090842568597128, disc_loss = 0.05470521030081219
Trained batch 86 in epoch 4, gen_loss = 0.6091408565126616, disc_loss = 0.05413878255191891
Trained batch 87 in epoch 4, gen_loss = 0.6090673465620388, disc_loss = 0.053577198414132
Trained batch 88 in epoch 4, gen_loss = 0.6099764791767249, disc_loss = 0.05303783987889464
Trained batch 89 in epoch 4, gen_loss = 0.6101729445987277, disc_loss = 0.05253434240197142
Trained batch 90 in epoch 4, gen_loss = 0.6093133157426185, disc_loss = 0.052841585098796495
Trained batch 91 in epoch 4, gen_loss = 0.6110987902983375, disc_loss = 0.05503613891525437
Trained batch 92 in epoch 4, gen_loss = 0.6105943008135724, disc_loss = 0.05490781147513659
Trained batch 93 in epoch 4, gen_loss = 0.6106857625727958, disc_loss = 0.054511387901816595
Trained batch 94 in epoch 4, gen_loss = 0.6113041720892254, disc_loss = 0.05405122664217886
Trained batch 95 in epoch 4, gen_loss = 0.6120777620623509, disc_loss = 0.05356835031125229
Trained batch 96 in epoch 4, gen_loss = 0.6129245198879045, disc_loss = 0.053079112120856024
Trained batch 97 in epoch 4, gen_loss = 0.6132398168651425, disc_loss = 0.05259389252572948
Trained batch 98 in epoch 4, gen_loss = 0.6133002867602338, disc_loss = 0.052122306097487005
Trained batch 99 in epoch 4, gen_loss = 0.6131211930513382, disc_loss = 0.051640675142407416
Trained batch 100 in epoch 4, gen_loss = 0.6126031385790004, disc_loss = 0.051238188372537644
Trained batch 101 in epoch 4, gen_loss = 0.6119057834148407, disc_loss = 0.05086520356217436
Trained batch 102 in epoch 4, gen_loss = 0.6126242303153844, disc_loss = 0.050432883139735867
Trained batch 103 in epoch 4, gen_loss = 0.6130439266562462, disc_loss = 0.05000497879854475
Trained batch 104 in epoch 4, gen_loss = 0.6126628870055789, disc_loss = 0.04978910059268985
Trained batch 105 in epoch 4, gen_loss = 0.6142069899810935, disc_loss = 0.049584757703584885
Trained batch 106 in epoch 4, gen_loss = 0.614397777018146, disc_loss = 0.04921085880982263
Trained batch 107 in epoch 4, gen_loss = 0.6135680206395961, disc_loss = 0.04933654750628328
Trained batch 108 in epoch 4, gen_loss = 0.6140264420334353, disc_loss = 0.04904650034673444
Trained batch 109 in epoch 4, gen_loss = 0.6146759006110105, disc_loss = 0.04912239386784759
Trained batch 110 in epoch 4, gen_loss = 0.6130255992348129, disc_loss = 0.052562857994826524
Trained batch 111 in epoch 4, gen_loss = 0.6129241175949574, disc_loss = 0.053258263564202935
Trained batch 112 in epoch 4, gen_loss = 0.6121982794947329, disc_loss = 0.05422807101621828
Trained batch 113 in epoch 4, gen_loss = 0.6109050862621843, disc_loss = 0.054615644174382874
Trained batch 114 in epoch 4, gen_loss = 0.611777012762816, disc_loss = 0.0549580415872776
Trained batch 115 in epoch 4, gen_loss = 0.6109162399481083, disc_loss = 0.05507413843036469
Trained batch 116 in epoch 4, gen_loss = 0.6115598663305625, disc_loss = 0.05485941102712327
Trained batch 117 in epoch 4, gen_loss = 0.6123322809146623, disc_loss = 0.05445726673213481
Trained batch 118 in epoch 4, gen_loss = 0.6127925665438676, disc_loss = 0.054066130684046934
Trained batch 119 in epoch 4, gen_loss = 0.6129889498154323, disc_loss = 0.05366488785560553
Trained batch 120 in epoch 4, gen_loss = 0.6135033610438513, disc_loss = 0.053266584007300374
Trained batch 121 in epoch 4, gen_loss = 0.6131047459899402, disc_loss = 0.05287363554244159
Trained batch 122 in epoch 4, gen_loss = 0.6128781103506321, disc_loss = 0.052478223100183456
Trained batch 123 in epoch 4, gen_loss = 0.6126806538912558, disc_loss = 0.052144750982763305
Trained batch 124 in epoch 4, gen_loss = 0.6125472383499145, disc_loss = 0.051783342596143485
Trained batch 125 in epoch 4, gen_loss = 0.6126053621844639, disc_loss = 0.051433799891836114
Trained batch 126 in epoch 4, gen_loss = 0.6124867576313769, disc_loss = 0.05112506015094247
Trained batch 127 in epoch 4, gen_loss = 0.6127598071470857, disc_loss = 0.050821137010643724
Trained batch 128 in epoch 4, gen_loss = 0.6133712659510531, disc_loss = 0.05051611504669106
Trained batch 129 in epoch 4, gen_loss = 0.6132663227044619, disc_loss = 0.05031905550366411
Trained batch 130 in epoch 4, gen_loss = 0.6135256021987391, disc_loss = 0.05000331355898662
Trained batch 131 in epoch 4, gen_loss = 0.6136161102489992, disc_loss = 0.049732937780914435
Trained batch 132 in epoch 4, gen_loss = 0.61355649887171, disc_loss = 0.049456601766379255
Trained batch 133 in epoch 4, gen_loss = 0.6147657410422368, disc_loss = 0.049196145900372246
Trained batch 134 in epoch 4, gen_loss = 0.6157570759455363, disc_loss = 0.04893443537531076
Trained batch 135 in epoch 4, gen_loss = 0.6158958024838391, disc_loss = 0.048626560930107886
Trained batch 136 in epoch 4, gen_loss = 0.6159928462801189, disc_loss = 0.0484320653847208
Trained batch 137 in epoch 4, gen_loss = 0.615857916465704, disc_loss = 0.04822334159246605
Trained batch 138 in epoch 4, gen_loss = 0.6147109516661802, disc_loss = 0.04849253115813724
Trained batch 139 in epoch 4, gen_loss = 0.6152561407004083, disc_loss = 0.04941711131084178
Trained batch 140 in epoch 4, gen_loss = 0.6143426339254312, disc_loss = 0.05000169483403154
Trained batch 141 in epoch 4, gen_loss = 0.614259626873782, disc_loss = 0.04989550066587161
Trained batch 142 in epoch 4, gen_loss = 0.6147472677114126, disc_loss = 0.04978098817352023
Trained batch 143 in epoch 4, gen_loss = 0.6142163551929924, disc_loss = 0.04968569102412504
Trained batch 144 in epoch 4, gen_loss = 0.6146965111124104, disc_loss = 0.04942893344780495
Trained batch 145 in epoch 4, gen_loss = 0.6145454524722818, disc_loss = 0.04918857191191756
Trained batch 146 in epoch 4, gen_loss = 0.6145378499209475, disc_loss = 0.049021746298032146
Trained batch 147 in epoch 4, gen_loss = 0.613426228431431, disc_loss = 0.04949849896208459
Trained batch 148 in epoch 4, gen_loss = 0.6146295804705396, disc_loss = 0.051621423590453276
Trained batch 149 in epoch 4, gen_loss = 0.6140278981129328, disc_loss = 0.052004105368008216
Trained batch 150 in epoch 4, gen_loss = 0.6132844147697979, disc_loss = 0.05318263599291345
Trained batch 151 in epoch 4, gen_loss = 0.6136020933719057, disc_loss = 0.055792830020532404
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.5461767911911011, disc_loss = 0.15709500014781952
Trained batch 1 in epoch 5, gen_loss = 0.472795695066452, disc_loss = 0.2755233719944954
Trained batch 2 in epoch 5, gen_loss = 0.5197917819023132, disc_loss = 0.3028732091188431
Trained batch 3 in epoch 5, gen_loss = 0.528971716761589, disc_loss = 0.3054779879748821
Trained batch 4 in epoch 5, gen_loss = 0.5148141324520111, disc_loss = 0.28775249421596527
Trained batch 5 in epoch 5, gen_loss = 0.502028688788414, disc_loss = 0.2775479679306348
Trained batch 6 in epoch 5, gen_loss = 0.49690450515065876, disc_loss = 0.26333571331841604
Trained batch 7 in epoch 5, gen_loss = 0.4936506599187851, disc_loss = 0.25268158316612244
Trained batch 8 in epoch 5, gen_loss = 0.49960288736555314, disc_loss = 0.24070893393622506
Trained batch 9 in epoch 5, gen_loss = 0.4954125463962555, disc_loss = 0.2308584123849869
Trained batch 10 in epoch 5, gen_loss = 0.4948512071912939, disc_loss = 0.22304962981830945
Trained batch 11 in epoch 5, gen_loss = 0.5047143772244453, disc_loss = 0.22574579219023386
Trained batch 12 in epoch 5, gen_loss = 0.5040469467639923, disc_loss = 0.2166055039717601
Trained batch 13 in epoch 5, gen_loss = 0.505221922482763, disc_loss = 0.21356407978704997
Trained batch 14 in epoch 5, gen_loss = 0.5141476571559906, disc_loss = 0.21345266501108806
Trained batch 15 in epoch 5, gen_loss = 0.5115233864635229, disc_loss = 0.20945021510124207
Trained batch 16 in epoch 5, gen_loss = 0.5104688318336711, disc_loss = 0.20378131550901077
Trained batch 17 in epoch 5, gen_loss = 0.5148753374814987, disc_loss = 0.19763412119613755
Trained batch 18 in epoch 5, gen_loss = 0.5106866940071708, disc_loss = 0.19459133987364016
Trained batch 19 in epoch 5, gen_loss = 0.5162551060318947, disc_loss = 0.19351137839257718
Trained batch 20 in epoch 5, gen_loss = 0.519046466974985, disc_loss = 0.1877830752304622
Trained batch 21 in epoch 5, gen_loss = 0.5174717862497676, disc_loss = 0.18602001734755255
Trained batch 22 in epoch 5, gen_loss = 0.5164306280405625, disc_loss = 0.1813148924190065
Trained batch 23 in epoch 5, gen_loss = 0.5158808417618275, disc_loss = 0.17606463252256313
Trained batch 24 in epoch 5, gen_loss = 0.5211961209774018, disc_loss = 0.17032657727599143
Trained batch 25 in epoch 5, gen_loss = 0.5206282264911212, disc_loss = 0.16564040158230525
Trained batch 26 in epoch 5, gen_loss = 0.5245403945446014, disc_loss = 0.16184209714885112
Trained batch 27 in epoch 5, gen_loss = 0.5290243231824466, disc_loss = 0.15644227310882083
Trained batch 28 in epoch 5, gen_loss = 0.5322571571530967, disc_loss = 0.15164839447443856
Trained batch 29 in epoch 5, gen_loss = 0.5325286457935969, disc_loss = 0.1473950209406515
Trained batch 30 in epoch 5, gen_loss = 0.5346880987767251, disc_loss = 0.14300360659798306
Trained batch 31 in epoch 5, gen_loss = 0.5362084871158004, disc_loss = 0.13877646348555572
Trained batch 32 in epoch 5, gen_loss = 0.5405714665398453, disc_loss = 0.13479034870750073
Trained batch 33 in epoch 5, gen_loss = 0.5422179935609593, disc_loss = 0.13106947852408185
Trained batch 34 in epoch 5, gen_loss = 0.5412639881883349, disc_loss = 0.12823200800589152
Trained batch 35 in epoch 5, gen_loss = 0.5429548662569788, disc_loss = 0.12521082866523
Trained batch 36 in epoch 5, gen_loss = 0.5458188677156294, disc_loss = 0.12207577886009538
Trained batch 37 in epoch 5, gen_loss = 0.54869728417773, disc_loss = 0.11908687107068927
Trained batch 38 in epoch 5, gen_loss = 0.550245463083952, disc_loss = 0.1161837379495876
Trained batch 39 in epoch 5, gen_loss = 0.5532285116612912, disc_loss = 0.11348966070218011
Trained batch 40 in epoch 5, gen_loss = 0.5560158919997331, disc_loss = 0.11089669834686125
Trained batch 41 in epoch 5, gen_loss = 0.5580345271598726, disc_loss = 0.10848295290599622
Trained batch 42 in epoch 5, gen_loss = 0.5598553800305655, disc_loss = 0.10620381129732312
Trained batch 43 in epoch 5, gen_loss = 0.5582064044746485, disc_loss = 0.10546202738557688
Trained batch 44 in epoch 5, gen_loss = 0.5627499494287703, disc_loss = 0.11005451133888629
Trained batch 45 in epoch 5, gen_loss = 0.5635811109905657, disc_loss = 0.10855818297916456
Trained batch 46 in epoch 5, gen_loss = 0.5606537803690484, disc_loss = 0.10966258750673621
Trained batch 47 in epoch 5, gen_loss = 0.5607384691635767, disc_loss = 0.11094307326129638
Trained batch 48 in epoch 5, gen_loss = 0.5602756933290132, disc_loss = 0.10944991346866804
Trained batch 49 in epoch 5, gen_loss = 0.5591122531890869, disc_loss = 0.10837320067919791
Trained batch 50 in epoch 5, gen_loss = 0.559910538149815, disc_loss = 0.10675616216316235
Trained batch 51 in epoch 5, gen_loss = 0.5613526541453141, disc_loss = 0.10508216456331027
Trained batch 52 in epoch 5, gen_loss = 0.5621014136188435, disc_loss = 0.10341858312944477
Trained batch 53 in epoch 5, gen_loss = 0.5627125336064233, disc_loss = 0.10196009489569675
Trained batch 54 in epoch 5, gen_loss = 0.5661487026648088, disc_loss = 0.10065293912352487
Trained batch 55 in epoch 5, gen_loss = 0.5666151355419841, disc_loss = 0.09922930332998346
Trained batch 56 in epoch 5, gen_loss = 0.5689420438649362, disc_loss = 0.09774198406784419
Trained batch 57 in epoch 5, gen_loss = 0.5712522566318512, disc_loss = 0.09619468961970816
Trained batch 58 in epoch 5, gen_loss = 0.5716574141534708, disc_loss = 0.09477509311163577
Trained batch 59 in epoch 5, gen_loss = 0.5729759007692337, disc_loss = 0.09331827941350639
Trained batch 60 in epoch 5, gen_loss = 0.5752049176419367, disc_loss = 0.09193984077113573
Trained batch 61 in epoch 5, gen_loss = 0.5771339679917982, disc_loss = 0.09138614407950832
Trained batch 62 in epoch 5, gen_loss = 0.5779030427100167, disc_loss = 0.09015869834120312
Trained batch 63 in epoch 5, gen_loss = 0.5777855226770043, disc_loss = 0.089317339414265
Trained batch 64 in epoch 5, gen_loss = 0.5786831149688134, disc_loss = 0.08821146694513468
Trained batch 65 in epoch 5, gen_loss = 0.5788986628705804, disc_loss = 0.08711198237583492
Trained batch 66 in epoch 5, gen_loss = 0.5807414855530013, disc_loss = 0.08643274037028427
Trained batch 67 in epoch 5, gen_loss = 0.5815682025516734, disc_loss = 0.08536592670990263
Trained batch 68 in epoch 5, gen_loss = 0.5800915826921877, disc_loss = 0.08444552909096946
Trained batch 69 in epoch 5, gen_loss = 0.5795687522206988, disc_loss = 0.08361819213522333
Trained batch 70 in epoch 5, gen_loss = 0.5821277138213037, disc_loss = 0.08364851014609907
Trained batch 71 in epoch 5, gen_loss = 0.5842813841170735, disc_loss = 0.08263703430485395
Trained batch 72 in epoch 5, gen_loss = 0.585192330896038, disc_loss = 0.08162377957152585
Trained batch 73 in epoch 5, gen_loss = 0.5862034301500063, disc_loss = 0.0806686805334647
Trained batch 74 in epoch 5, gen_loss = 0.5869254509607951, disc_loss = 0.07969424220422903
Trained batch 75 in epoch 5, gen_loss = 0.5874258483711042, disc_loss = 0.07877251601434852
Trained batch 76 in epoch 5, gen_loss = 0.5869902620067844, disc_loss = 0.07794837178299566
Trained batch 77 in epoch 5, gen_loss = 0.5866658634100205, disc_loss = 0.07752503916764489
Trained batch 78 in epoch 5, gen_loss = 0.5883284173434293, disc_loss = 0.07703898360221824
Trained batch 79 in epoch 5, gen_loss = 0.5901072070002555, disc_loss = 0.07624005094403401
Trained batch 80 in epoch 5, gen_loss = 0.5892668322280601, disc_loss = 0.07568229561280689
Trained batch 81 in epoch 5, gen_loss = 0.5904471787010751, disc_loss = 0.07484149414955116
Trained batch 82 in epoch 5, gen_loss = 0.5909562807485281, disc_loss = 0.07419880497527409
Trained batch 83 in epoch 5, gen_loss = 0.5910292878037408, disc_loss = 0.07348697627007607
Trained batch 84 in epoch 5, gen_loss = 0.5906330403159646, disc_loss = 0.07273786819594748
Trained batch 85 in epoch 5, gen_loss = 0.5904290890970896, disc_loss = 0.07196986850156167
Trained batch 86 in epoch 5, gen_loss = 0.5913942264414381, disc_loss = 0.07124816685722306
Trained batch 87 in epoch 5, gen_loss = 0.5917567962949927, disc_loss = 0.07050232729472389
Trained batch 88 in epoch 5, gen_loss = 0.5922280041019569, disc_loss = 0.06980052605543412
Trained batch 89 in epoch 5, gen_loss = 0.5921574023034838, disc_loss = 0.06915490832697187
Trained batch 90 in epoch 5, gen_loss = 0.593356429875552, disc_loss = 0.06855499509537777
Trained batch 91 in epoch 5, gen_loss = 0.5942837615375933, disc_loss = 0.06786273949799816
Trained batch 92 in epoch 5, gen_loss = 0.5939562660391613, disc_loss = 0.06726053399684769
Trained batch 93 in epoch 5, gen_loss = 0.594068113159626, disc_loss = 0.06662026392989495
Trained batch 94 in epoch 5, gen_loss = 0.5944376343174984, disc_loss = 0.06600214854176892
Trained batch 95 in epoch 5, gen_loss = 0.594984898964564, disc_loss = 0.06536455146366886
Trained batch 96 in epoch 5, gen_loss = 0.596023425613482, disc_loss = 0.06473626852630801
Trained batch 97 in epoch 5, gen_loss = 0.5968480170989523, disc_loss = 0.06417735966815784
Trained batch 98 in epoch 5, gen_loss = 0.5972625155641575, disc_loss = 0.0635799152654304
Trained batch 99 in epoch 5, gen_loss = 0.5969107353687286, disc_loss = 0.0632281268807128
Trained batch 100 in epoch 5, gen_loss = 0.5977207811752169, disc_loss = 0.06309416134482121
Trained batch 101 in epoch 5, gen_loss = 0.5983864530628803, disc_loss = 0.06255711532453549
Trained batch 102 in epoch 5, gen_loss = 0.598445519660283, disc_loss = 0.06211709469394053
Trained batch 103 in epoch 5, gen_loss = 0.5995415964951882, disc_loss = 0.061625898614203416
Trained batch 104 in epoch 5, gen_loss = 0.6003819397517614, disc_loss = 0.06110696105641269
Trained batch 105 in epoch 5, gen_loss = 0.6006226168488557, disc_loss = 0.06056999634371473
Trained batch 106 in epoch 5, gen_loss = 0.6014347354942393, disc_loss = 0.06004617441114839
Trained batch 107 in epoch 5, gen_loss = 0.6022622204489179, disc_loss = 0.05954553978086484
Trained batch 108 in epoch 5, gen_loss = 0.6021668293060513, disc_loss = 0.05903931287194201
Trained batch 109 in epoch 5, gen_loss = 0.6025145216421648, disc_loss = 0.05855090367099778
Trained batch 110 in epoch 5, gen_loss = 0.6015256130480552, disc_loss = 0.05869660901979686
Trained batch 111 in epoch 5, gen_loss = 0.6043866545494113, disc_loss = 0.061754681631490324
Trained batch 112 in epoch 5, gen_loss = 0.6050655570177905, disc_loss = 0.06138386257174137
Trained batch 113 in epoch 5, gen_loss = 0.6051112588560372, disc_loss = 0.06113615236245096
Trained batch 114 in epoch 5, gen_loss = 0.6054017707057621, disc_loss = 0.060690117210311735
Trained batch 115 in epoch 5, gen_loss = 0.6057496674615761, disc_loss = 0.060271290022526576
Trained batch 116 in epoch 5, gen_loss = 0.6052510532049032, disc_loss = 0.06031035509708728
Trained batch 117 in epoch 5, gen_loss = 0.6057687146683871, disc_loss = 0.059935130198659786
Trained batch 118 in epoch 5, gen_loss = 0.6062361530396116, disc_loss = 0.059639192636304794
Trained batch 119 in epoch 5, gen_loss = 0.6069806255400181, disc_loss = 0.05925199661481505
Trained batch 120 in epoch 5, gen_loss = 0.6075585920456027, disc_loss = 0.05881637893617153
Trained batch 121 in epoch 5, gen_loss = 0.6074911402385743, disc_loss = 0.058388433972617886
Trained batch 122 in epoch 5, gen_loss = 0.6075771855629557, disc_loss = 0.05804309874727595
Trained batch 123 in epoch 5, gen_loss = 0.6087689257917865, disc_loss = 0.05772723266929989
Trained batch 124 in epoch 5, gen_loss = 0.6094827854633331, disc_loss = 0.05731092931702733
Trained batch 125 in epoch 5, gen_loss = 0.6098091264092733, disc_loss = 0.05690106793513729
Trained batch 126 in epoch 5, gen_loss = 0.6100949867973178, disc_loss = 0.05649591785466929
Trained batch 127 in epoch 5, gen_loss = 0.6097426230553538, disc_loss = 0.056165541067457525
Trained batch 128 in epoch 5, gen_loss = 0.6086607683998669, disc_loss = 0.056355207707270864
Trained batch 129 in epoch 5, gen_loss = 0.6094260392280725, disc_loss = 0.05848726241562802
Trained batch 130 in epoch 5, gen_loss = 0.6097233648063572, disc_loss = 0.058504888044940376
Trained batch 131 in epoch 5, gen_loss = 0.6091755996599342, disc_loss = 0.05846144776495004
Trained batch 132 in epoch 5, gen_loss = 0.6077880422423657, disc_loss = 0.059053609900428614
Trained batch 133 in epoch 5, gen_loss = 0.6066731434704652, disc_loss = 0.05946999919989994
Trained batch 134 in epoch 5, gen_loss = 0.6072844339741601, disc_loss = 0.06223334999479078
Trained batch 135 in epoch 5, gen_loss = 0.6070597362430656, disc_loss = 0.06360948807217509
Trained batch 136 in epoch 5, gen_loss = 0.6057570000199506, disc_loss = 0.06456505249927405
Trained batch 137 in epoch 5, gen_loss = 0.6044382707796235, disc_loss = 0.0654206534921853
Trained batch 138 in epoch 5, gen_loss = 0.6036304351237181, disc_loss = 0.06613320968174141
Trained batch 139 in epoch 5, gen_loss = 0.6032141562019075, disc_loss = 0.06596247815593545
Trained batch 140 in epoch 5, gen_loss = 0.6029235576906948, disc_loss = 0.06580728145501187
Trained batch 141 in epoch 5, gen_loss = 0.6026757523207598, disc_loss = 0.06557325243254677
Trained batch 142 in epoch 5, gen_loss = 0.6027554486181352, disc_loss = 0.06523478425505173
Trained batch 143 in epoch 5, gen_loss = 0.6021468511058224, disc_loss = 0.06585776059202747
Trained batch 144 in epoch 5, gen_loss = 0.6024582546332787, disc_loss = 0.0680443584758403
Trained batch 145 in epoch 5, gen_loss = 0.6021295046969636, disc_loss = 0.0689514158772024
Trained batch 146 in epoch 5, gen_loss = 0.6014012684221981, disc_loss = 0.06916600818980206
Trained batch 147 in epoch 5, gen_loss = 0.6002781884493055, disc_loss = 0.06946733944759881
Trained batch 148 in epoch 5, gen_loss = 0.5995153238709341, disc_loss = 0.0695214048871808
Trained batch 149 in epoch 5, gen_loss = 0.5994417669375738, disc_loss = 0.0698081104302158
Trained batch 150 in epoch 5, gen_loss = 0.5982858398497499, disc_loss = 0.0699491943787808
Trained batch 151 in epoch 5, gen_loss = 0.5979713368180551, disc_loss = 0.0697159891500824
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.606185257434845, disc_loss = 0.02266438864171505
Trained batch 1 in epoch 6, gen_loss = 0.5862904489040375, disc_loss = 0.021040907129645348
Trained batch 2 in epoch 6, gen_loss = 0.5409791270891825, disc_loss = 0.0400474506119887
Trained batch 3 in epoch 6, gen_loss = 0.5774836093187332, disc_loss = 0.11730473767966032
Trained batch 4 in epoch 6, gen_loss = 0.5610461711883545, disc_loss = 0.11196509078145027
Trained batch 5 in epoch 6, gen_loss = 0.5722733537356058, disc_loss = 0.10440414460996787
Trained batch 6 in epoch 6, gen_loss = 0.5539306274482182, disc_loss = 0.12084773023213659
Trained batch 7 in epoch 6, gen_loss = 0.5603544749319553, disc_loss = 0.14358103508129716
Trained batch 8 in epoch 6, gen_loss = 0.56082969572809, disc_loss = 0.1560448362595505
Trained batch 9 in epoch 6, gen_loss = 0.5577092081308365, disc_loss = 0.15540906377136707
Trained batch 10 in epoch 6, gen_loss = 0.5424801978197965, disc_loss = 0.15623082254420628
Trained batch 11 in epoch 6, gen_loss = 0.5360273371140162, disc_loss = 0.1572546415651838
Trained batch 12 in epoch 6, gen_loss = 0.5300385676897489, disc_loss = 0.15923484730032775
Trained batch 13 in epoch 6, gen_loss = 0.5223361828497478, disc_loss = 0.16340199990996293
Trained batch 14 in epoch 6, gen_loss = 0.5167426208655039, disc_loss = 0.16356651609142622
Trained batch 15 in epoch 6, gen_loss = 0.5125371608883142, disc_loss = 0.16328542889095843
Trained batch 16 in epoch 6, gen_loss = 0.5150381274083081, disc_loss = 0.16343925739912427
Trained batch 17 in epoch 6, gen_loss = 0.5106782532400556, disc_loss = 0.1628857712364859
Trained batch 18 in epoch 6, gen_loss = 0.5154184652002234, disc_loss = 0.16302338889554926
Trained batch 19 in epoch 6, gen_loss = 0.5188959077000618, disc_loss = 0.1571163548156619
Trained batch 20 in epoch 6, gen_loss = 0.5164168661548978, disc_loss = 0.15497973720942224
Trained batch 21 in epoch 6, gen_loss = 0.5223085677081888, disc_loss = 0.15334153869612652
Trained batch 22 in epoch 6, gen_loss = 0.5185884444609933, disc_loss = 0.1545472587256328
Trained batch 23 in epoch 6, gen_loss = 0.5232280318935713, disc_loss = 0.16374199852968255
Trained batch 24 in epoch 6, gen_loss = 0.5211644816398621, disc_loss = 0.16174116656184195
Trained batch 25 in epoch 6, gen_loss = 0.5171705117592444, disc_loss = 0.1617789289985712
Trained batch 26 in epoch 6, gen_loss = 0.514506494557416, disc_loss = 0.16089189480300303
Trained batch 27 in epoch 6, gen_loss = 0.5159808950764793, disc_loss = 0.15961857765380824
Trained batch 28 in epoch 6, gen_loss = 0.5114928124279812, disc_loss = 0.16269756326901502
Trained batch 29 in epoch 6, gen_loss = 0.514261469244957, disc_loss = 0.16347762582202752
Trained batch 30 in epoch 6, gen_loss = 0.516279415738198, disc_loss = 0.16021668105836837
Trained batch 31 in epoch 6, gen_loss = 0.5139970127493143, disc_loss = 0.1604059241944924
Trained batch 32 in epoch 6, gen_loss = 0.517095867431525, disc_loss = 0.16211558347850136
Trained batch 33 in epoch 6, gen_loss = 0.5183175171122831, disc_loss = 0.15932176799020348
Trained batch 34 in epoch 6, gen_loss = 0.5176179834774562, disc_loss = 0.15655766502022744
Trained batch 35 in epoch 6, gen_loss = 0.5204126404391395, disc_loss = 0.15300295734778047
Trained batch 36 in epoch 6, gen_loss = 0.5227435005677713, disc_loss = 0.14933538804384502
Trained batch 37 in epoch 6, gen_loss = 0.5236350893974304, disc_loss = 0.14714427963879548
Trained batch 38 in epoch 6, gen_loss = 0.526516168545454, disc_loss = 0.14779581936697164
Trained batch 39 in epoch 6, gen_loss = 0.5264932364225388, disc_loss = 0.14599150088615714
Trained batch 40 in epoch 6, gen_loss = 0.5286073815531847, disc_loss = 0.1430895223577575
Trained batch 41 in epoch 6, gen_loss = 0.5290257206984929, disc_loss = 0.1407345858446899
Trained batch 42 in epoch 6, gen_loss = 0.5320709929909817, disc_loss = 0.1379485864538786
Trained batch 43 in epoch 6, gen_loss = 0.5346383506601508, disc_loss = 0.13501961491155354
Trained batch 44 in epoch 6, gen_loss = 0.5382008685006036, disc_loss = 0.13217049797789918
Trained batch 45 in epoch 6, gen_loss = 0.5415918101435122, disc_loss = 0.12952953364457126
Trained batch 46 in epoch 6, gen_loss = 0.5414537559164331, disc_loss = 0.1273652513095356
Trained batch 47 in epoch 6, gen_loss = 0.5449744996925195, disc_loss = 0.12493848030377801
Trained batch 48 in epoch 6, gen_loss = 0.5463609379165026, disc_loss = 0.1225818278344006
Trained batch 49 in epoch 6, gen_loss = 0.5476550436019898, disc_loss = 0.12028307486325503
Trained batch 50 in epoch 6, gen_loss = 0.549802743921093, disc_loss = 0.11893642229922846
Trained batch 51 in epoch 6, gen_loss = 0.5484410885434884, disc_loss = 0.11779860668600751
Trained batch 52 in epoch 6, gen_loss = 0.5504577356689381, disc_loss = 0.11569546863331266
Trained batch 53 in epoch 6, gen_loss = 0.55045060703048, disc_loss = 0.114253408767076
Trained batch 54 in epoch 6, gen_loss = 0.5508082232692025, disc_loss = 0.11335649311711843
Trained batch 55 in epoch 6, gen_loss = 0.5485930634396416, disc_loss = 0.11475605900964833
Trained batch 56 in epoch 6, gen_loss = 0.5515332985342595, disc_loss = 0.11789678021644552
Trained batch 57 in epoch 6, gen_loss = 0.5501291803244887, disc_loss = 0.11759978723069973
Trained batch 58 in epoch 6, gen_loss = 0.5492306371866646, disc_loss = 0.11668979942451342
Trained batch 59 in epoch 6, gen_loss = 0.5506095429261525, disc_loss = 0.1165214982892697
Trained batch 60 in epoch 6, gen_loss = 0.5506061657530362, disc_loss = 0.11516882531863988
Trained batch 61 in epoch 6, gen_loss = 0.5492957840042729, disc_loss = 0.11405271770162208
Trained batch 62 in epoch 6, gen_loss = 0.5505204058828808, disc_loss = 0.11243804700170008
Trained batch 63 in epoch 6, gen_loss = 0.5494992174208164, disc_loss = 0.11216035429242766
Trained batch 64 in epoch 6, gen_loss = 0.5511809495779184, disc_loss = 0.11062461038191732
Trained batch 65 in epoch 6, gen_loss = 0.5510529189398794, disc_loss = 0.10924264865532292
Trained batch 66 in epoch 6, gen_loss = 0.5524288433701244, disc_loss = 0.10788225366581064
Trained batch 67 in epoch 6, gen_loss = 0.5538298987290439, disc_loss = 0.10646104303818635
Trained batch 68 in epoch 6, gen_loss = 0.5556748284809832, disc_loss = 0.10506782584243278
Trained batch 69 in epoch 6, gen_loss = 0.5559057993548256, disc_loss = 0.10381764993736786
Trained batch 70 in epoch 6, gen_loss = 0.5573158297740238, disc_loss = 0.10246878473455427
Trained batch 71 in epoch 6, gen_loss = 0.5584959809978803, disc_loss = 0.10114444062087892
Trained batch 72 in epoch 6, gen_loss = 0.559909410672645, disc_loss = 0.09988089831392855
Trained batch 73 in epoch 6, gen_loss = 0.5611730435410062, disc_loss = 0.09862290152877166
Trained batch 74 in epoch 6, gen_loss = 0.561968088944753, disc_loss = 0.09750233545899391
Trained batch 75 in epoch 6, gen_loss = 0.563198626825684, disc_loss = 0.09642800821089431
Trained batch 76 in epoch 6, gen_loss = 0.5641973057350556, disc_loss = 0.09537521169170157
Trained batch 77 in epoch 6, gen_loss = 0.5626671398297335, disc_loss = 0.09639374290903409
Trained batch 78 in epoch 6, gen_loss = 0.5655295796032194, disc_loss = 0.09997385730849037
Trained batch 79 in epoch 6, gen_loss = 0.5652959302067757, disc_loss = 0.10029802238568664
Trained batch 80 in epoch 6, gen_loss = 0.5631692946693043, disc_loss = 0.10209557386460127
Trained batch 81 in epoch 6, gen_loss = 0.5635240877546915, disc_loss = 0.1016971296290072
Trained batch 82 in epoch 6, gen_loss = 0.5634694113788834, disc_loss = 0.10103012702192168
Trained batch 83 in epoch 6, gen_loss = 0.5625302419066429, disc_loss = 0.10085442147794224
Trained batch 84 in epoch 6, gen_loss = 0.5639835010556614, disc_loss = 0.1004703040508663
Trained batch 85 in epoch 6, gen_loss = 0.5627577467713245, disc_loss = 0.10047387834205183
Trained batch 86 in epoch 6, gen_loss = 0.5634052462276371, disc_loss = 0.10103577324028673
Trained batch 87 in epoch 6, gen_loss = 0.5635069307278503, disc_loss = 0.10020002841272137
Trained batch 88 in epoch 6, gen_loss = 0.5630255264512608, disc_loss = 0.09969395574893844
Trained batch 89 in epoch 6, gen_loss = 0.5642908900976181, disc_loss = 0.09992732662293646
Trained batch 90 in epoch 6, gen_loss = 0.5650078244916685, disc_loss = 0.09901013700189171
Trained batch 91 in epoch 6, gen_loss = 0.5648495895059212, disc_loss = 0.09869749414856019
Trained batch 92 in epoch 6, gen_loss = 0.5667961653201811, disc_loss = 0.09791689978972558
Trained batch 93 in epoch 6, gen_loss = 0.56811874565926, disc_loss = 0.09730185853674057
Trained batch 94 in epoch 6, gen_loss = 0.5681707586112775, disc_loss = 0.09671483937846986
Trained batch 95 in epoch 6, gen_loss = 0.5682748279844722, disc_loss = 0.09582260573127617
Trained batch 96 in epoch 6, gen_loss = 0.5688780371061305, disc_loss = 0.09519401953085181
Trained batch 97 in epoch 6, gen_loss = 0.5694852991371738, disc_loss = 0.09430929398810377
Trained batch 98 in epoch 6, gen_loss = 0.5693128376898139, disc_loss = 0.09360033770402272
Trained batch 99 in epoch 6, gen_loss = 0.5686874666810036, disc_loss = 0.09301145929843187
Trained batch 100 in epoch 6, gen_loss = 0.5697352977672426, disc_loss = 0.09222976970348028
Trained batch 101 in epoch 6, gen_loss = 0.5706592000582639, disc_loss = 0.09140903624139872
Trained batch 102 in epoch 6, gen_loss = 0.5706817811553918, disc_loss = 0.09064053930342197
Trained batch 103 in epoch 6, gen_loss = 0.5702197520205607, disc_loss = 0.09015501546673477
Trained batch 104 in epoch 6, gen_loss = 0.5711026841685886, disc_loss = 0.09030732468125366
Trained batch 105 in epoch 6, gen_loss = 0.5705306324756371, disc_loss = 0.09004952201514312
Trained batch 106 in epoch 6, gen_loss = 0.571828541076072, disc_loss = 0.0894302110074558
Trained batch 107 in epoch 6, gen_loss = 0.5727376603969822, disc_loss = 0.08866762264666182
Trained batch 108 in epoch 6, gen_loss = 0.5734219438985947, disc_loss = 0.08790234578004398
Trained batch 109 in epoch 6, gen_loss = 0.5738227678970858, disc_loss = 0.08715365740724586
Trained batch 110 in epoch 6, gen_loss = 0.5741004833767006, disc_loss = 0.0864101978824348
Trained batch 111 in epoch 6, gen_loss = 0.5743278496499572, disc_loss = 0.0856798404544991
Trained batch 112 in epoch 6, gen_loss = 0.5742541063675838, disc_loss = 0.08503373216969513
Trained batch 113 in epoch 6, gen_loss = 0.5742710339918471, disc_loss = 0.08433089381606694
Trained batch 114 in epoch 6, gen_loss = 0.5740054107230642, disc_loss = 0.0836780990757372
Trained batch 115 in epoch 6, gen_loss = 0.5744120142069357, disc_loss = 0.08301734734840434
Trained batch 116 in epoch 6, gen_loss = 0.5748541276169639, disc_loss = 0.08235048809940489
Trained batch 117 in epoch 6, gen_loss = 0.5749339236546371, disc_loss = 0.08172048625962461
Trained batch 118 in epoch 6, gen_loss = 0.5747152484264695, disc_loss = 0.08111633381516743
Trained batch 119 in epoch 6, gen_loss = 0.5756112329661847, disc_loss = 0.08051841283061852
Trained batch 120 in epoch 6, gen_loss = 0.5756655997973829, disc_loss = 0.07993200462126782
Trained batch 121 in epoch 6, gen_loss = 0.5760498093288453, disc_loss = 0.07932765645997934
Trained batch 122 in epoch 6, gen_loss = 0.5753143747163013, disc_loss = 0.07927507584596552
Trained batch 123 in epoch 6, gen_loss = 0.5769253832197958, disc_loss = 0.07954575113892075
Trained batch 124 in epoch 6, gen_loss = 0.5764372899532318, disc_loss = 0.07908321431279182
Trained batch 125 in epoch 6, gen_loss = 0.576651339729627, disc_loss = 0.07851537358429697
Trained batch 126 in epoch 6, gen_loss = 0.5771365524746301, disc_loss = 0.07795616821569251
Trained batch 127 in epoch 6, gen_loss = 0.5772222268860787, disc_loss = 0.07740066592668882
Trained batch 128 in epoch 6, gen_loss = 0.5771824729072955, disc_loss = 0.07696262145660414
Trained batch 129 in epoch 6, gen_loss = 0.577928735430424, disc_loss = 0.07682587924914865
Trained batch 130 in epoch 6, gen_loss = 0.5784363808067701, disc_loss = 0.07630195398281776
Trained batch 131 in epoch 6, gen_loss = 0.5781072854544177, disc_loss = 0.07622931856012931
Trained batch 132 in epoch 6, gen_loss = 0.5780641402965202, disc_loss = 0.07576531196307194
Trained batch 133 in epoch 6, gen_loss = 0.579209987129738, disc_loss = 0.0763888858578432
Trained batch 134 in epoch 6, gen_loss = 0.5785546020225242, disc_loss = 0.07619407446710048
Trained batch 135 in epoch 6, gen_loss = 0.5775605477392673, disc_loss = 0.07638772735235226
Trained batch 136 in epoch 6, gen_loss = 0.5785454470310768, disc_loss = 0.07701389311411738
Trained batch 137 in epoch 6, gen_loss = 0.5791223293197327, disc_loss = 0.07650657930829818
Trained batch 138 in epoch 6, gen_loss = 0.5797929221348797, disc_loss = 0.07603751405698361
Trained batch 139 in epoch 6, gen_loss = 0.5794626519083976, disc_loss = 0.07560807759208339
Trained batch 140 in epoch 6, gen_loss = 0.5794928050633018, disc_loss = 0.07512692811879072
Trained batch 141 in epoch 6, gen_loss = 0.5795024862171898, disc_loss = 0.07469756584483343
Trained batch 142 in epoch 6, gen_loss = 0.5796156823635101, disc_loss = 0.07425974484637275
Trained batch 143 in epoch 6, gen_loss = 0.580608421108789, disc_loss = 0.07390552353657161
Trained batch 144 in epoch 6, gen_loss = 0.5811246512265041, disc_loss = 0.07348396900142061
Trained batch 145 in epoch 6, gen_loss = 0.5810286572126493, disc_loss = 0.07309440125341285
Trained batch 146 in epoch 6, gen_loss = 0.581820617524945, disc_loss = 0.07271667351933564
Trained batch 147 in epoch 6, gen_loss = 0.5827721121746141, disc_loss = 0.07229954483792991
Trained batch 148 in epoch 6, gen_loss = 0.5834440046908872, disc_loss = 0.07184580285664673
Trained batch 149 in epoch 6, gen_loss = 0.5838474843899409, disc_loss = 0.0713915682490915
Trained batch 150 in epoch 6, gen_loss = 0.5840056674764645, disc_loss = 0.07097494770889941
Trained batch 151 in epoch 6, gen_loss = 0.5841011897121605, disc_loss = 0.07052867049596419
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.6534706354141235, disc_loss = 0.0035559050738811493
Trained batch 1 in epoch 7, gen_loss = 0.6198866963386536, disc_loss = 0.0034039425663650036
Trained batch 2 in epoch 7, gen_loss = 0.5935768882433573, disc_loss = 0.0061934832483530045
Trained batch 3 in epoch 7, gen_loss = 0.5818362385034561, disc_loss = 0.006119388504885137
Trained batch 4 in epoch 7, gen_loss = 0.5860421180725097, disc_loss = 0.006177758984267712
Trained batch 5 in epoch 7, gen_loss = 0.5888630747795105, disc_loss = 0.007980451763918003
Trained batch 6 in epoch 7, gen_loss = 0.5965676818575177, disc_loss = 0.008162308750408036
Trained batch 7 in epoch 7, gen_loss = 0.5905232131481171, disc_loss = 0.01068972423672676
Trained batch 8 in epoch 7, gen_loss = 0.5998713970184326, disc_loss = 0.012024049336711565
Trained batch 9 in epoch 7, gen_loss = 0.585507532954216, disc_loss = 0.020164026506245138
Trained batch 10 in epoch 7, gen_loss = 0.5999606603925879, disc_loss = 0.04472902027720755
Trained batch 11 in epoch 7, gen_loss = 0.6002259030938148, disc_loss = 0.04241552669554949
Trained batch 12 in epoch 7, gen_loss = 0.5867407482403976, disc_loss = 0.05672406892363842
Trained batch 13 in epoch 7, gen_loss = 0.5841109177895955, disc_loss = 0.07964860514870711
Trained batch 14 in epoch 7, gen_loss = 0.5786828696727753, disc_loss = 0.092076126486063
Trained batch 15 in epoch 7, gen_loss = 0.566874185577035, disc_loss = 0.10096471360884607
Trained batch 16 in epoch 7, gen_loss = 0.5585529506206512, disc_loss = 0.10722692288896617
Trained batch 17 in epoch 7, gen_loss = 0.5537310954597261, disc_loss = 0.11372673656377527
Trained batch 18 in epoch 7, gen_loss = 0.5503679247278916, disc_loss = 0.119138453155756
Trained batch 19 in epoch 7, gen_loss = 0.5423615977168084, disc_loss = 0.12542481031268835
Trained batch 20 in epoch 7, gen_loss = 0.5380297700564066, disc_loss = 0.13117079277123725
Trained batch 21 in epoch 7, gen_loss = 0.5310692922635512, disc_loss = 0.134766615757888
Trained batch 22 in epoch 7, gen_loss = 0.5278986925664155, disc_loss = 0.1370152175102545
Trained batch 23 in epoch 7, gen_loss = 0.5258898337682089, disc_loss = 0.13841726180786887
Trained batch 24 in epoch 7, gen_loss = 0.5205336928367614, disc_loss = 0.14024918720126153
Trained batch 25 in epoch 7, gen_loss = 0.5168272096377152, disc_loss = 0.1413278549623031
Trained batch 26 in epoch 7, gen_loss = 0.5135438100055412, disc_loss = 0.1432925676582036
Trained batch 27 in epoch 7, gen_loss = 0.510880745947361, disc_loss = 0.14329976947712048
Trained batch 28 in epoch 7, gen_loss = 0.5094912740690954, disc_loss = 0.14304545919956832
Trained batch 29 in epoch 7, gen_loss = 0.5067066301902136, disc_loss = 0.14274992980062962
Trained batch 30 in epoch 7, gen_loss = 0.506449677290455, disc_loss = 0.1419637000128146
Trained batch 31 in epoch 7, gen_loss = 0.5045189978554845, disc_loss = 0.14117666881065816
Trained batch 32 in epoch 7, gen_loss = 0.5100881520545844, disc_loss = 0.14683435891162266
Trained batch 33 in epoch 7, gen_loss = 0.5072771652656443, disc_loss = 0.14869481752462246
Trained batch 34 in epoch 7, gen_loss = 0.5070208830492837, disc_loss = 0.14759518557361195
Trained batch 35 in epoch 7, gen_loss = 0.5057796653774049, disc_loss = 0.1475645573809743
Trained batch 36 in epoch 7, gen_loss = 0.5045026919326266, disc_loss = 0.14667386914024483
Trained batch 37 in epoch 7, gen_loss = 0.5082589348680094, disc_loss = 0.14407847057047643
Trained batch 38 in epoch 7, gen_loss = 0.5052010050186744, disc_loss = 0.14733116920941916
Trained batch 39 in epoch 7, gen_loss = 0.5108209997415543, disc_loss = 0.15442973393946885
Trained batch 40 in epoch 7, gen_loss = 0.5123032709447349, disc_loss = 0.15425501600271319
Trained batch 41 in epoch 7, gen_loss = 0.5100689643905276, disc_loss = 0.15442313732845442
Trained batch 42 in epoch 7, gen_loss = 0.5092969093211862, disc_loss = 0.1539563278472701
Trained batch 43 in epoch 7, gen_loss = 0.5090167617255991, disc_loss = 0.15316007150845093
Trained batch 44 in epoch 7, gen_loss = 0.5076433334085676, disc_loss = 0.1520611047744751
Trained batch 45 in epoch 7, gen_loss = 0.5070574270642322, disc_loss = 0.15116102151248767
Trained batch 46 in epoch 7, gen_loss = 0.5075278903575654, disc_loss = 0.1511035850073429
Trained batch 47 in epoch 7, gen_loss = 0.5089074559509754, disc_loss = 0.14873366352791587
Trained batch 48 in epoch 7, gen_loss = 0.5104380748709854, disc_loss = 0.14637396461805519
Trained batch 49 in epoch 7, gen_loss = 0.5103488111495972, disc_loss = 0.14471695594489575
Trained batch 50 in epoch 7, gen_loss = 0.5130199474446914, disc_loss = 0.14339513105212473
Trained batch 51 in epoch 7, gen_loss = 0.5151380804868845, disc_loss = 0.14115654956549406
Trained batch 52 in epoch 7, gen_loss = 0.5146042710205294, disc_loss = 0.13970494108661166
Trained batch 53 in epoch 7, gen_loss = 0.5166146771775352, disc_loss = 0.13801524567383308
Trained batch 54 in epoch 7, gen_loss = 0.5181118851358241, disc_loss = 0.13590813800692558
Trained batch 55 in epoch 7, gen_loss = 0.5178019803549562, disc_loss = 0.13442120774249947
Trained batch 56 in epoch 7, gen_loss = 0.5206036018697839, disc_loss = 0.1324294425481767
Trained batch 57 in epoch 7, gen_loss = 0.523360809889333, disc_loss = 0.13079151732782865
Trained batch 58 in epoch 7, gen_loss = 0.5231800165216801, disc_loss = 0.12950522083220845
Trained batch 59 in epoch 7, gen_loss = 0.526466325422128, disc_loss = 0.12767991644019883
Trained batch 60 in epoch 7, gen_loss = 0.5287693978333082, disc_loss = 0.12591600631836986
Trained batch 61 in epoch 7, gen_loss = 0.5292847795832542, disc_loss = 0.12411350019336227
Trained batch 62 in epoch 7, gen_loss = 0.5295281055427733, disc_loss = 0.12284481911254781
Trained batch 63 in epoch 7, gen_loss = 0.5309392535127699, disc_loss = 0.1214091225847369
Trained batch 64 in epoch 7, gen_loss = 0.5330511858830085, disc_loss = 0.11966715685736674
Trained batch 65 in epoch 7, gen_loss = 0.5337918477528023, disc_loss = 0.11813543213418487
Trained batch 66 in epoch 7, gen_loss = 0.5367839883512525, disc_loss = 0.11662952834045265
Trained batch 67 in epoch 7, gen_loss = 0.538760166396113, disc_loss = 0.11513246183612329
Trained batch 68 in epoch 7, gen_loss = 0.5389303828495137, disc_loss = 0.11364733353527127
Trained batch 69 in epoch 7, gen_loss = 0.5381298324891499, disc_loss = 0.11278245790994593
Trained batch 70 in epoch 7, gen_loss = 0.540404886007309, disc_loss = 0.11144318915641224
Trained batch 71 in epoch 7, gen_loss = 0.5403227528764142, disc_loss = 0.11026648034910774
Trained batch 72 in epoch 7, gen_loss = 0.5404687985165478, disc_loss = 0.10988803591885388
Trained batch 73 in epoch 7, gen_loss = 0.5428928487204217, disc_loss = 0.11082418077952556
Trained batch 74 in epoch 7, gen_loss = 0.5442012703418732, disc_loss = 0.10943542319660385
Trained batch 75 in epoch 7, gen_loss = 0.5446437295330199, disc_loss = 0.10822787486923564
Trained batch 76 in epoch 7, gen_loss = 0.5449391382855254, disc_loss = 0.10728765069204685
Trained batch 77 in epoch 7, gen_loss = 0.5442105917594372, disc_loss = 0.10663629612789895
Trained batch 78 in epoch 7, gen_loss = 0.5469874056834209, disc_loss = 0.1068180541366433
Trained batch 79 in epoch 7, gen_loss = 0.5482704821974039, disc_loss = 0.10563463508733548
Trained batch 80 in epoch 7, gen_loss = 0.5492381552855173, disc_loss = 0.10448487879662419
Trained batch 81 in epoch 7, gen_loss = 0.5497304379213147, disc_loss = 0.10334036851915099
Trained batch 82 in epoch 7, gen_loss = 0.5495815352503076, disc_loss = 0.10224860781489546
Trained batch 83 in epoch 7, gen_loss = 0.5497483345014709, disc_loss = 0.10138962347437405
Trained batch 84 in epoch 7, gen_loss = 0.5514450266080744, disc_loss = 0.10052755994941381
Trained batch 85 in epoch 7, gen_loss = 0.5504535599503406, disc_loss = 0.10010838901169251
Trained batch 86 in epoch 7, gen_loss = 0.5525729234876304, disc_loss = 0.10021805688845871
Trained batch 87 in epoch 7, gen_loss = 0.5539003017951142, disc_loss = 0.09922206084857779
Trained batch 88 in epoch 7, gen_loss = 0.5550689673825596, disc_loss = 0.0983064643714284
Trained batch 89 in epoch 7, gen_loss = 0.5555938618050681, disc_loss = 0.09736622368606428
Trained batch 90 in epoch 7, gen_loss = 0.5561862872852074, disc_loss = 0.09636967110826256
Trained batch 91 in epoch 7, gen_loss = 0.5571450063067934, disc_loss = 0.09536814381388704
Trained batch 92 in epoch 7, gen_loss = 0.5574527930828833, disc_loss = 0.0944656025948784
Trained batch 93 in epoch 7, gen_loss = 0.5576396308680798, disc_loss = 0.09352659941849081
Trained batch 94 in epoch 7, gen_loss = 0.5572543617926146, disc_loss = 0.09265552369485561
Trained batch 95 in epoch 7, gen_loss = 0.5575020539884766, disc_loss = 0.09177099355050207
Trained batch 96 in epoch 7, gen_loss = 0.5577833815333769, disc_loss = 0.09093182355875976
Trained batch 97 in epoch 7, gen_loss = 0.5591060431027899, disc_loss = 0.09020010306385859
Trained batch 98 in epoch 7, gen_loss = 0.5597042010890113, disc_loss = 0.08936369512230158
Trained batch 99 in epoch 7, gen_loss = 0.5607158955931664, disc_loss = 0.08851763159502297
Trained batch 100 in epoch 7, gen_loss = 0.5600020938580579, disc_loss = 0.0880581179292559
Trained batch 101 in epoch 7, gen_loss = 0.5613348361323861, disc_loss = 0.08777719674467602
Trained batch 102 in epoch 7, gen_loss = 0.560759420533782, disc_loss = 0.0877598627940616
Trained batch 103 in epoch 7, gen_loss = 0.5620198920369148, disc_loss = 0.0879311258233009
Trained batch 104 in epoch 7, gen_loss = 0.5620682404154823, disc_loss = 0.08717079978170139
Trained batch 105 in epoch 7, gen_loss = 0.5621821728517424, disc_loss = 0.08663523024527954
Trained batch 106 in epoch 7, gen_loss = 0.5614886810289366, disc_loss = 0.08662291354647725
Trained batch 107 in epoch 7, gen_loss = 0.562643029347614, disc_loss = 0.08759877771673794
Trained batch 108 in epoch 7, gen_loss = 0.5624757811016993, disc_loss = 0.08711712366106723
Trained batch 109 in epoch 7, gen_loss = 0.5614398788322102, disc_loss = 0.08769552873193541
Trained batch 110 in epoch 7, gen_loss = 0.5631680714117514, disc_loss = 0.08995300507474993
Trained batch 111 in epoch 7, gen_loss = 0.5632729998656681, disc_loss = 0.0901659875068747
Trained batch 112 in epoch 7, gen_loss = 0.5621708085579155, disc_loss = 0.090598053401913
Trained batch 113 in epoch 7, gen_loss = 0.5616932304804785, disc_loss = 0.0904666259517207
Trained batch 114 in epoch 7, gen_loss = 0.5620069869186567, disc_loss = 0.09056772553645398
Trained batch 115 in epoch 7, gen_loss = 0.5622959843483465, disc_loss = 0.08999696171216282
Trained batch 116 in epoch 7, gen_loss = 0.5621761091244526, disc_loss = 0.08975914919462341
Trained batch 117 in epoch 7, gen_loss = 0.5615225520174382, disc_loss = 0.08941742190222998
Trained batch 118 in epoch 7, gen_loss = 0.5620540926436416, disc_loss = 0.08924816091380575
Trained batch 119 in epoch 7, gen_loss = 0.5612694323062897, disc_loss = 0.08916560603538529
Trained batch 120 in epoch 7, gen_loss = 0.5624174106219584, disc_loss = 0.08926449586398714
Trained batch 121 in epoch 7, gen_loss = 0.5611206434789251, disc_loss = 0.09033457647444161
Trained batch 122 in epoch 7, gen_loss = 0.5625316476434227, disc_loss = 0.0917334530494986
Trained batch 123 in epoch 7, gen_loss = 0.5632816312774536, disc_loss = 0.09132429145862378
Trained batch 124 in epoch 7, gen_loss = 0.5619001710414886, disc_loss = 0.09270422511920333
Trained batch 125 in epoch 7, gen_loss = 0.5615857217520003, disc_loss = 0.09263515897789999
Trained batch 126 in epoch 7, gen_loss = 0.5618347232266674, disc_loss = 0.09306841806735931
Trained batch 127 in epoch 7, gen_loss = 0.5605051575694233, disc_loss = 0.09375680191078573
Trained batch 128 in epoch 7, gen_loss = 0.5599768076294153, disc_loss = 0.0941093782316749
Trained batch 129 in epoch 7, gen_loss = 0.5607739322460614, disc_loss = 0.0945149595885036
Trained batch 130 in epoch 7, gen_loss = 0.5620042165272109, disc_loss = 0.09400359670212137
Trained batch 131 in epoch 7, gen_loss = 0.5626560772458712, disc_loss = 0.09340739469255575
Trained batch 132 in epoch 7, gen_loss = 0.5626111924648285, disc_loss = 0.09288326019589278
Trained batch 133 in epoch 7, gen_loss = 0.5621240999716431, disc_loss = 0.0922991643597219
Trained batch 134 in epoch 7, gen_loss = 0.5612748227737568, disc_loss = 0.09197066030637534
Trained batch 135 in epoch 7, gen_loss = 0.5616667106309358, disc_loss = 0.09138074945589966
Trained batch 136 in epoch 7, gen_loss = 0.562265660423432, disc_loss = 0.09095524260638295
Trained batch 137 in epoch 7, gen_loss = 0.56242686142956, disc_loss = 0.09035925022866306
Trained batch 138 in epoch 7, gen_loss = 0.5614769126442697, disc_loss = 0.09081767452210723
Trained batch 139 in epoch 7, gen_loss = 0.562722649531705, disc_loss = 0.09240495079263512
Trained batch 140 in epoch 7, gen_loss = 0.5621658271931588, disc_loss = 0.0926545758612771
Trained batch 141 in epoch 7, gen_loss = 0.5625749104459521, disc_loss = 0.09319747675826746
Trained batch 142 in epoch 7, gen_loss = 0.5613647232522497, disc_loss = 0.09419515672615254
Trained batch 143 in epoch 7, gen_loss = 0.5613386473721929, disc_loss = 0.09505328304173115
Trained batch 144 in epoch 7, gen_loss = 0.5611200739597452, disc_loss = 0.09512411536777328
Trained batch 145 in epoch 7, gen_loss = 0.5608469464191018, disc_loss = 0.09486726789786289
Trained batch 146 in epoch 7, gen_loss = 0.5595934782303921, disc_loss = 0.09675002428481266
Trained batch 147 in epoch 7, gen_loss = 0.5600921316324053, disc_loss = 0.09807250876218786
Trained batch 148 in epoch 7, gen_loss = 0.5600248225183295, disc_loss = 0.0992018889054506
Trained batch 149 in epoch 7, gen_loss = 0.559541753133138, disc_loss = 0.09943695769645274
Trained batch 150 in epoch 7, gen_loss = 0.5585833387264353, disc_loss = 0.09978457906326613
Trained batch 151 in epoch 7, gen_loss = 0.5581309460103512, disc_loss = 0.10019322147433597
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.48603126406669617, disc_loss = 0.11359769105911255
Trained batch 1 in epoch 8, gen_loss = 0.4738193154335022, disc_loss = 0.13276442140340805
Trained batch 2 in epoch 8, gen_loss = 0.49289266268412274, disc_loss = 0.12272192537784576
Trained batch 3 in epoch 8, gen_loss = 0.48545344173908234, disc_loss = 0.11889068596065044
Trained batch 4 in epoch 8, gen_loss = 0.4857815980911255, disc_loss = 0.11157503426074981
Trained batch 5 in epoch 8, gen_loss = 0.49280984203020733, disc_loss = 0.10696826875209808
Trained batch 6 in epoch 8, gen_loss = 0.48880998151642935, disc_loss = 0.10347289592027664
Trained batch 7 in epoch 8, gen_loss = 0.502706054598093, disc_loss = 0.09226054034661502
Trained batch 8 in epoch 8, gen_loss = 0.4896750483247969, disc_loss = 0.09839735997633801
Trained batch 9 in epoch 8, gen_loss = 0.5136743456125259, disc_loss = 0.11327462261542678
Trained batch 10 in epoch 8, gen_loss = 0.5160469873384996, disc_loss = 0.11176376578144052
Trained batch 11 in epoch 8, gen_loss = 0.505444847047329, disc_loss = 0.1270723056513816
Trained batch 12 in epoch 8, gen_loss = 0.5055948060292464, disc_loss = 0.12775965944792217
Trained batch 13 in epoch 8, gen_loss = 0.5117216642413821, disc_loss = 0.12999809846015914
Trained batch 14 in epoch 8, gen_loss = 0.5184747199217479, disc_loss = 0.12434749870250622
Trained batch 15 in epoch 8, gen_loss = 0.5143489670008421, disc_loss = 0.1251024191151373
Trained batch 16 in epoch 8, gen_loss = 0.5178807570653803, disc_loss = 0.12188752231133335
Trained batch 17 in epoch 8, gen_loss = 0.5239804370535744, disc_loss = 0.11786087969731954
Trained batch 18 in epoch 8, gen_loss = 0.5253957149229551, disc_loss = 0.11351334455570108
Trained batch 19 in epoch 8, gen_loss = 0.5269351556897164, disc_loss = 0.10911008701659738
Trained batch 20 in epoch 8, gen_loss = 0.5254812254792168, disc_loss = 0.10913439507463149
Trained batch 21 in epoch 8, gen_loss = 0.530470226298679, disc_loss = 0.1103890543718907
Trained batch 22 in epoch 8, gen_loss = 0.5333115601021311, disc_loss = 0.10621572577435037
Trained batch 23 in epoch 8, gen_loss = 0.534556869417429, disc_loss = 0.10257206376021107
Trained batch 24 in epoch 8, gen_loss = 0.5331546592712403, disc_loss = 0.09967531882226467
Trained batch 25 in epoch 8, gen_loss = 0.5311243213140048, disc_loss = 0.0998579475025718
Trained batch 26 in epoch 8, gen_loss = 0.5388218252747147, disc_loss = 0.10090827217532529
Trained batch 27 in epoch 8, gen_loss = 0.5447096100875309, disc_loss = 0.09834594173090798
Trained batch 28 in epoch 8, gen_loss = 0.5448156307483542, disc_loss = 0.09574198896258042
Trained batch 29 in epoch 8, gen_loss = 0.5430323759714762, disc_loss = 0.09504697515318791
Trained batch 30 in epoch 8, gen_loss = 0.5408932085960142, disc_loss = 0.09391131702690356
Trained batch 31 in epoch 8, gen_loss = 0.5467314384877682, disc_loss = 0.09507069358369336
Trained batch 32 in epoch 8, gen_loss = 0.5488805518005834, disc_loss = 0.09321290779520165
Trained batch 33 in epoch 8, gen_loss = 0.5494097804321962, disc_loss = 0.0908996824942091
Trained batch 34 in epoch 8, gen_loss = 0.554006268296923, disc_loss = 0.08879311052816255
Trained batch 35 in epoch 8, gen_loss = 0.5576563758982552, disc_loss = 0.0865706164493329
Trained batch 36 in epoch 8, gen_loss = 0.5608553290367126, disc_loss = 0.08438952442107571
Trained batch 37 in epoch 8, gen_loss = 0.5652263023351368, disc_loss = 0.08234074315987527
Trained batch 38 in epoch 8, gen_loss = 0.5643210288805839, disc_loss = 0.0806346494728365
Trained batch 39 in epoch 8, gen_loss = 0.5642968162894249, disc_loss = 0.07936134553747251
Trained batch 40 in epoch 8, gen_loss = 0.563080296283815, disc_loss = 0.07977617324170906
Trained batch 41 in epoch 8, gen_loss = 0.5637956573849633, disc_loss = 0.07952015608593467
Trained batch 42 in epoch 8, gen_loss = 0.566858101722806, disc_loss = 0.0799671410756229
Trained batch 43 in epoch 8, gen_loss = 0.5651924969120459, disc_loss = 0.07923380794553933
Trained batch 44 in epoch 8, gen_loss = 0.5668572909302182, disc_loss = 0.07769435363718205
Trained batch 45 in epoch 8, gen_loss = 0.5643910150165143, disc_loss = 0.07734742777867486
Trained batch 46 in epoch 8, gen_loss = 0.5664512990637028, disc_loss = 0.07733931472683524
Trained batch 47 in epoch 8, gen_loss = 0.5672292541712523, disc_loss = 0.0761477268630794
Trained batch 48 in epoch 8, gen_loss = 0.567296709941358, disc_loss = 0.07505166679810808
Trained batch 49 in epoch 8, gen_loss = 0.5657817047834396, disc_loss = 0.07439552058465779
Trained batch 50 in epoch 8, gen_loss = 0.5677519119253346, disc_loss = 0.07314470739962131
Trained batch 51 in epoch 8, gen_loss = 0.5667565470704665, disc_loss = 0.0728203761839093
Trained batch 52 in epoch 8, gen_loss = 0.5673830503562711, disc_loss = 0.07179755584846409
Trained batch 53 in epoch 8, gen_loss = 0.5718425970386576, disc_loss = 0.07180103557011872
Trained batch 54 in epoch 8, gen_loss = 0.5762575133280321, disc_loss = 0.07080664408647201
Trained batch 55 in epoch 8, gen_loss = 0.5780776201614312, disc_loss = 0.06976621199698586
Trained batch 56 in epoch 8, gen_loss = 0.5790771889059168, disc_loss = 0.06868754020941101
Trained batch 57 in epoch 8, gen_loss = 0.5808930289128731, disc_loss = 0.06758315340969069
Trained batch 58 in epoch 8, gen_loss = 0.5823118065373373, disc_loss = 0.06650236851172679
Trained batch 59 in epoch 8, gen_loss = 0.5838428303599358, disc_loss = 0.06545932826120407
Trained batch 60 in epoch 8, gen_loss = 0.5853902399539948, disc_loss = 0.0644728607253828
Trained batch 61 in epoch 8, gen_loss = 0.5859904668984874, disc_loss = 0.06349423749282235
Trained batch 62 in epoch 8, gen_loss = 0.5859425233470069, disc_loss = 0.0625303088140393
Trained batch 63 in epoch 8, gen_loss = 0.5859926925040781, disc_loss = 0.06161431811051443
Trained batch 64 in epoch 8, gen_loss = 0.5865669658550849, disc_loss = 0.060733881864983304
Trained batch 65 in epoch 8, gen_loss = 0.5868037943587159, disc_loss = 0.0598720383837424
Trained batch 66 in epoch 8, gen_loss = 0.5872234181681676, disc_loss = 0.05904726219474713
Trained batch 67 in epoch 8, gen_loss = 0.5878887838300537, disc_loss = 0.05823000163346639
Trained batch 68 in epoch 8, gen_loss = 0.5886033630889395, disc_loss = 0.057427289139857327
Trained batch 69 in epoch 8, gen_loss = 0.5892913294689995, disc_loss = 0.05664709705659854
Trained batch 70 in epoch 8, gen_loss = 0.5898404746827944, disc_loss = 0.05588641330849012
Trained batch 71 in epoch 8, gen_loss = 0.5891470217870342, disc_loss = 0.05517421266671994
Trained batch 72 in epoch 8, gen_loss = 0.5891424397083178, disc_loss = 0.0544682040408713
Trained batch 73 in epoch 8, gen_loss = 0.5895700418465847, disc_loss = 0.05378083362734902
Trained batch 74 in epoch 8, gen_loss = 0.5896346882979075, disc_loss = 0.05312352743931115
Trained batch 75 in epoch 8, gen_loss = 0.5893527696791449, disc_loss = 0.05256595691408668
Trained batch 76 in epoch 8, gen_loss = 0.5893296549072513, disc_loss = 0.05199830144244645
Trained batch 77 in epoch 8, gen_loss = 0.5896833382355862, disc_loss = 0.05143846377718429
Trained batch 78 in epoch 8, gen_loss = 0.5899609821506694, disc_loss = 0.05085864210725302
Trained batch 79 in epoch 8, gen_loss = 0.5910371784120798, disc_loss = 0.050306382440612654
Trained batch 80 in epoch 8, gen_loss = 0.5900307625164221, disc_loss = 0.049991532737665156
Trained batch 81 in epoch 8, gen_loss = 0.5915299708523402, disc_loss = 0.04953032710714402
Trained batch 82 in epoch 8, gen_loss = 0.5927451256527958, disc_loss = 0.04901032547286925
Trained batch 83 in epoch 8, gen_loss = 0.5937345450123152, disc_loss = 0.04851825802775454
Trained batch 84 in epoch 8, gen_loss = 0.5932131819865283, disc_loss = 0.04843557552872774
Trained batch 85 in epoch 8, gen_loss = 0.5918208242848862, disc_loss = 0.04942536533019657
Trained batch 86 in epoch 8, gen_loss = 0.5941086452582787, disc_loss = 0.05456399957478132
Trained batch 87 in epoch 8, gen_loss = 0.5946251512928442, disc_loss = 0.05635488766975785
Trained batch 88 in epoch 8, gen_loss = 0.5930081492059687, disc_loss = 0.0568966758097365
Trained batch 89 in epoch 8, gen_loss = 0.5913842055532668, disc_loss = 0.05850047068929093
Trained batch 90 in epoch 8, gen_loss = 0.5901586875155732, disc_loss = 0.059646202448325664
Trained batch 91 in epoch 8, gen_loss = 0.5891052727466044, disc_loss = 0.06082781547245205
Trained batch 92 in epoch 8, gen_loss = 0.5867267690038168, disc_loss = 0.06362624687983864
Trained batch 93 in epoch 8, gen_loss = 0.5867140410428352, disc_loss = 0.06585138795669487
Trained batch 94 in epoch 8, gen_loss = 0.5864657028725273, disc_loss = 0.0666189466382524
Trained batch 95 in epoch 8, gen_loss = 0.5852788953731457, disc_loss = 0.06749716227689835
Trained batch 96 in epoch 8, gen_loss = 0.583444761861231, disc_loss = 0.06845796935154681
Trained batch 97 in epoch 8, gen_loss = 0.5821493632939397, disc_loss = 0.06910304996251528
Trained batch 98 in epoch 8, gen_loss = 0.5818101107472121, disc_loss = 0.06907079298510169
Trained batch 99 in epoch 8, gen_loss = 0.5811726486682892, disc_loss = 0.06879163825185969
Trained batch 100 in epoch 8, gen_loss = 0.5797077665234557, disc_loss = 0.06906671808470077
Trained batch 101 in epoch 8, gen_loss = 0.5801451720443427, disc_loss = 0.06921256064464722
Trained batch 102 in epoch 8, gen_loss = 0.580248060735684, disc_loss = 0.06866300524013497
Trained batch 103 in epoch 8, gen_loss = 0.5791575026053649, disc_loss = 0.06843252582341218
Trained batch 104 in epoch 8, gen_loss = 0.5785460006623041, disc_loss = 0.06883058457724041
Trained batch 105 in epoch 8, gen_loss = 0.5798139853297539, disc_loss = 0.07074283114590524
Trained batch 106 in epoch 8, gen_loss = 0.5801236350959706, disc_loss = 0.07048453173217163
Trained batch 107 in epoch 8, gen_loss = 0.5794492463270823, disc_loss = 0.07067453942511713
Trained batch 108 in epoch 8, gen_loss = 0.5783546829442365, disc_loss = 0.07094361002710776
Trained batch 109 in epoch 8, gen_loss = 0.5776026368141174, disc_loss = 0.07232911903622814
Trained batch 110 in epoch 8, gen_loss = 0.5771284312815279, disc_loss = 0.07206876379823698
Trained batch 111 in epoch 8, gen_loss = 0.5756986561630454, disc_loss = 0.07229019387367382
Trained batch 112 in epoch 8, gen_loss = 0.5760192544059416, disc_loss = 0.07239741909696795
Trained batch 113 in epoch 8, gen_loss = 0.5754642392459669, disc_loss = 0.07194220309202935
Trained batch 114 in epoch 8, gen_loss = 0.5758182629295018, disc_loss = 0.0714840318865912
Trained batch 115 in epoch 8, gen_loss = 0.575573415591799, disc_loss = 0.07103161703482078
Trained batch 116 in epoch 8, gen_loss = 0.5757986607714596, disc_loss = 0.07051942159389901
Trained batch 117 in epoch 8, gen_loss = 0.5749321486485206, disc_loss = 0.070381425473034
Trained batch 118 in epoch 8, gen_loss = 0.5749248804665413, disc_loss = 0.07074477989422236
Trained batch 119 in epoch 8, gen_loss = 0.5744067125022412, disc_loss = 0.0705251654862271
Trained batch 120 in epoch 8, gen_loss = 0.5758283101330118, disc_loss = 0.07018601662894973
Trained batch 121 in epoch 8, gen_loss = 0.5763482307312918, disc_loss = 0.06971168880862352
Trained batch 122 in epoch 8, gen_loss = 0.5767759920620337, disc_loss = 0.06921154229780584
Trained batch 123 in epoch 8, gen_loss = 0.5774538961629714, disc_loss = 0.06872025493630057
Trained batch 124 in epoch 8, gen_loss = 0.5774931833744049, disc_loss = 0.06822341948188841
Trained batch 125 in epoch 8, gen_loss = 0.5765887688076685, disc_loss = 0.06801901798554888
Trained batch 126 in epoch 8, gen_loss = 0.5780985866944621, disc_loss = 0.0678139215969576
Trained batch 127 in epoch 8, gen_loss = 0.5787433511577547, disc_loss = 0.0673295895485353
Trained batch 128 in epoch 8, gen_loss = 0.5783397398253743, disc_loss = 0.06716734610765075
Trained batch 129 in epoch 8, gen_loss = 0.5790149711645567, disc_loss = 0.06672804749105125
Trained batch 130 in epoch 8, gen_loss = 0.5784954738070947, disc_loss = 0.06663136975662001
Trained batch 131 in epoch 8, gen_loss = 0.5795803526134202, disc_loss = 0.0675674929287087
Trained batch 132 in epoch 8, gen_loss = 0.5797621925970665, disc_loss = 0.06710939476427559
Trained batch 133 in epoch 8, gen_loss = 0.5795447666253617, disc_loss = 0.06677864453192356
Trained batch 134 in epoch 8, gen_loss = 0.5791018658214145, disc_loss = 0.06643906383499228
Trained batch 135 in epoch 8, gen_loss = 0.5793731484343024, disc_loss = 0.06604397949002519
Trained batch 136 in epoch 8, gen_loss = 0.5800529483461032, disc_loss = 0.06572280125522538
Trained batch 137 in epoch 8, gen_loss = 0.5808561228323674, disc_loss = 0.06529002541682913
Trained batch 138 in epoch 8, gen_loss = 0.5801589064460864, disc_loss = 0.0649554172225913
Trained batch 139 in epoch 8, gen_loss = 0.5804530935628074, disc_loss = 0.0645901427953504
Trained batch 140 in epoch 8, gen_loss = 0.579953927520319, disc_loss = 0.06437231597147142
Trained batch 141 in epoch 8, gen_loss = 0.5806299196162694, disc_loss = 0.064088209566634
Trained batch 142 in epoch 8, gen_loss = 0.5810400864461085, disc_loss = 0.06368602607301534
Trained batch 143 in epoch 8, gen_loss = 0.5811124054921998, disc_loss = 0.06329257298784796
Trained batch 144 in epoch 8, gen_loss = 0.5812194470701546, disc_loss = 0.06295674051607734
Trained batch 145 in epoch 8, gen_loss = 0.5808401516039078, disc_loss = 0.06264813791813763
Trained batch 146 in epoch 8, gen_loss = 0.5803842345873514, disc_loss = 0.062441994659412574
Trained batch 147 in epoch 8, gen_loss = 0.5813201561167434, disc_loss = 0.06273669126676396
Trained batch 148 in epoch 8, gen_loss = 0.5815882898817126, disc_loss = 0.06240600493936581
Trained batch 149 in epoch 8, gen_loss = 0.5816904171307882, disc_loss = 0.06211077500289927
Trained batch 150 in epoch 8, gen_loss = 0.5819806953929118, disc_loss = 0.0618170871112545
Trained batch 151 in epoch 8, gen_loss = 0.5818860299493137, disc_loss = 0.06150714968067692
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.6501601338386536, disc_loss = 0.007589852903038263
Trained batch 1 in epoch 9, gen_loss = 0.589357316493988, disc_loss = 0.013112061889842153
Trained batch 2 in epoch 9, gen_loss = 0.5890146891276041, disc_loss = 0.01492892966295282
Trained batch 3 in epoch 9, gen_loss = 0.6058220863342285, disc_loss = 0.014810834429226816
Trained batch 4 in epoch 9, gen_loss = 0.6226261734962464, disc_loss = 0.013015296123921872
Trained batch 5 in epoch 9, gen_loss = 0.6135159929593405, disc_loss = 0.012759079691022635
Trained batch 6 in epoch 9, gen_loss = 0.5906540070261274, disc_loss = 0.02944200818559953
Trained batch 7 in epoch 9, gen_loss = 0.6095069125294685, disc_loss = 0.06347377982456237
Trained batch 8 in epoch 9, gen_loss = 0.6263867219289144, disc_loss = 0.05949452488372723
Trained batch 9 in epoch 9, gen_loss = 0.6252936959266663, disc_loss = 0.05415516453795135
Trained batch 10 in epoch 9, gen_loss = 0.621062928980047, disc_loss = 0.05113296138800003
Trained batch 11 in epoch 9, gen_loss = 0.6199799279371897, disc_loss = 0.04866802284959704
Trained batch 12 in epoch 9, gen_loss = 0.6179049565241888, disc_loss = 0.0454219920703998
Trained batch 13 in epoch 9, gen_loss = 0.6124194136687687, disc_loss = 0.04286091548523733
Trained batch 14 in epoch 9, gen_loss = 0.6020309706528981, disc_loss = 0.042564899350206055
Trained batch 15 in epoch 9, gen_loss = 0.5960971359163523, disc_loss = 0.04484510014299303
Trained batch 16 in epoch 9, gen_loss = 0.6057085868190316, disc_loss = 0.05349057704648551
Trained batch 17 in epoch 9, gen_loss = 0.5954453812705146, disc_loss = 0.060774826858606606
Trained batch 18 in epoch 9, gen_loss = 0.5920977278759605, disc_loss = 0.06876464864533198
Trained batch 19 in epoch 9, gen_loss = 0.587118324637413, disc_loss = 0.06948280083015561
Trained batch 20 in epoch 9, gen_loss = 0.5804585871242341, disc_loss = 0.07195867961716085
Trained batch 21 in epoch 9, gen_loss = 0.576804824850776, disc_loss = 0.07628560210154815
Trained batch 22 in epoch 9, gen_loss = 0.5723544100056523, disc_loss = 0.0760623071666645
Trained batch 23 in epoch 9, gen_loss = 0.5742029870549837, disc_loss = 0.07415693439543247
Trained batch 24 in epoch 9, gen_loss = 0.5687688517570496, disc_loss = 0.07822799861431122
Trained batch 25 in epoch 9, gen_loss = 0.5728283868386195, disc_loss = 0.08419489917846826
Trained batch 26 in epoch 9, gen_loss = 0.5719150348945901, disc_loss = 0.08537220513379132
Trained batch 27 in epoch 9, gen_loss = 0.5669188180140087, disc_loss = 0.08448142771209989
Trained batch 28 in epoch 9, gen_loss = 0.5672513390409535, disc_loss = 0.08217751877061252
Trained batch 29 in epoch 9, gen_loss = 0.567017549276352, disc_loss = 0.08048800341784954
Trained batch 30 in epoch 9, gen_loss = 0.5643824271617397, disc_loss = 0.08022683702649609
Trained batch 31 in epoch 9, gen_loss = 0.5689975628629327, disc_loss = 0.0872714197030291
Trained batch 32 in epoch 9, gen_loss = 0.5717411483779098, disc_loss = 0.08485993059972922
Trained batch 33 in epoch 9, gen_loss = 0.5739742701544481, disc_loss = 0.08324342007365297
Trained batch 34 in epoch 9, gen_loss = 0.5727116218635014, disc_loss = 0.08237307247306619
Trained batch 35 in epoch 9, gen_loss = 0.5701291983326277, disc_loss = 0.0814104725399779
Trained batch 36 in epoch 9, gen_loss = 0.5717586238641996, disc_loss = 0.08243493690482669
Trained batch 37 in epoch 9, gen_loss = 0.5699954244651293, disc_loss = 0.08121531579251352
Trained batch 38 in epoch 9, gen_loss = 0.5735674324708108, disc_loss = 0.08080919874975315
Trained batch 39 in epoch 9, gen_loss = 0.5715991862118244, disc_loss = 0.07981096957810223
Trained batch 40 in epoch 9, gen_loss = 0.5727189030589127, disc_loss = 0.07816487157762778
Trained batch 41 in epoch 9, gen_loss = 0.5746497306085768, disc_loss = 0.07651772658296284
Trained batch 42 in epoch 9, gen_loss = 0.5755406417125879, disc_loss = 0.07491056727202133
Trained batch 43 in epoch 9, gen_loss = 0.576697785068642, disc_loss = 0.07338700928217308
Trained batch 44 in epoch 9, gen_loss = 0.5739289813571506, disc_loss = 0.07288435898307297
Trained batch 45 in epoch 9, gen_loss = 0.575156437314075, disc_loss = 0.07172134520647966
Trained batch 46 in epoch 9, gen_loss = 0.5734854904895134, disc_loss = 0.07141539440589383
Trained batch 47 in epoch 9, gen_loss = 0.5731134147693714, disc_loss = 0.07044413381178553
Trained batch 48 in epoch 9, gen_loss = 0.5702166916156302, disc_loss = 0.07081390983824219
Trained batch 49 in epoch 9, gen_loss = 0.5719657248258591, disc_loss = 0.07242024516686797
Trained batch 50 in epoch 9, gen_loss = 0.5747656232001734, disc_loss = 0.07134151844052124
Trained batch 51 in epoch 9, gen_loss = 0.5765235624634303, disc_loss = 0.07024075149988326
Trained batch 52 in epoch 9, gen_loss = 0.5764760695538431, disc_loss = 0.06930566763610772
Trained batch 53 in epoch 9, gen_loss = 0.5757724681386241, disc_loss = 0.06836389165578617
Trained batch 54 in epoch 9, gen_loss = 0.5790397551926699, disc_loss = 0.06746513039212335
Trained batch 55 in epoch 9, gen_loss = 0.580343923930611, disc_loss = 0.06647692103537597
Trained batch 56 in epoch 9, gen_loss = 0.5806313946581724, disc_loss = 0.06543777510523796
Trained batch 57 in epoch 9, gen_loss = 0.5811784210903891, disc_loss = 0.0646828780400342
Trained batch 58 in epoch 9, gen_loss = 0.5832939738944426, disc_loss = 0.06380394268465245
Trained batch 59 in epoch 9, gen_loss = 0.5831459914644559, disc_loss = 0.06298376594980558
Trained batch 60 in epoch 9, gen_loss = 0.5834161175079033, disc_loss = 0.06208017857775825
Trained batch 61 in epoch 9, gen_loss = 0.5830706439671978, disc_loss = 0.06133420992222044
Trained batch 62 in epoch 9, gen_loss = 0.5857051407533979, disc_loss = 0.060956806875765324
Trained batch 63 in epoch 9, gen_loss = 0.587163848336786, disc_loss = 0.06012989919690881
Trained batch 64 in epoch 9, gen_loss = 0.5879263093838325, disc_loss = 0.05931192928781876
Trained batch 65 in epoch 9, gen_loss = 0.5889645060806563, disc_loss = 0.058482384492614954
Trained batch 66 in epoch 9, gen_loss = 0.5894753626033441, disc_loss = 0.057672133738758846
Trained batch 67 in epoch 9, gen_loss = 0.5899509932188427, disc_loss = 0.056877387649900114
Trained batch 68 in epoch 9, gen_loss = 0.5896746736505757, disc_loss = 0.05610532855844476
Trained batch 69 in epoch 9, gen_loss = 0.5907157842602049, disc_loss = 0.05543643688184342
Trained batch 70 in epoch 9, gen_loss = 0.5902537523021161, disc_loss = 0.05481189482478084
Trained batch 71 in epoch 9, gen_loss = 0.5908621810376644, disc_loss = 0.054154772851486795
Trained batch 72 in epoch 9, gen_loss = 0.5908694108055063, disc_loss = 0.05349854131433347
Trained batch 73 in epoch 9, gen_loss = 0.5919139727547362, disc_loss = 0.052884814647227725
Trained batch 74 in epoch 9, gen_loss = 0.5924452133973439, disc_loss = 0.052333330688998106
Trained batch 75 in epoch 9, gen_loss = 0.5932136103510857, disc_loss = 0.05171576347263334
Trained batch 76 in epoch 9, gen_loss = 0.593207812541491, disc_loss = 0.051200463802420666
Trained batch 77 in epoch 9, gen_loss = 0.5930019544485288, disc_loss = 0.05064776574727148
Trained batch 78 in epoch 9, gen_loss = 0.5933004885534697, disc_loss = 0.05008304210179308
Trained batch 79 in epoch 9, gen_loss = 0.5955893334001303, disc_loss = 0.05003296203503851
Trained batch 80 in epoch 9, gen_loss = 0.5955977274311913, disc_loss = 0.04950991262290857
Trained batch 81 in epoch 9, gen_loss = 0.5973878164843816, disc_loss = 0.049083884189291514
Trained batch 82 in epoch 9, gen_loss = 0.5986768326845514, disc_loss = 0.04859457790840372
Trained batch 83 in epoch 9, gen_loss = 0.5989518978056454, disc_loss = 0.04808843562412741
Trained batch 84 in epoch 9, gen_loss = 0.599311129135244, disc_loss = 0.047615667539374795
Trained batch 85 in epoch 9, gen_loss = 0.5992903990107913, disc_loss = 0.04731345098454852
Trained batch 86 in epoch 9, gen_loss = 0.5990073382854462, disc_loss = 0.04692474681744887
Trained batch 87 in epoch 9, gen_loss = 0.6001258042048324, disc_loss = 0.04704917071715251
Trained batch 88 in epoch 9, gen_loss = 0.5978336612160287, disc_loss = 0.05120796318626387
Trained batch 89 in epoch 9, gen_loss = 0.5981863501999113, disc_loss = 0.051842346143287914
Trained batch 90 in epoch 9, gen_loss = 0.6003389322495722, disc_loss = 0.05263519518149014
Trained batch 91 in epoch 9, gen_loss = 0.6011425279404806, disc_loss = 0.05236140126109366
Trained batch 92 in epoch 9, gen_loss = 0.6009812954292503, disc_loss = 0.051896122692313085
Trained batch 93 in epoch 9, gen_loss = 0.6005689562001126, disc_loss = 0.051528173456701666
Trained batch 94 in epoch 9, gen_loss = 0.6003445346104471, disc_loss = 0.05111350413951042
Trained batch 95 in epoch 9, gen_loss = 0.6002979908759395, disc_loss = 0.050636866690183524
Trained batch 96 in epoch 9, gen_loss = 0.5997579635418567, disc_loss = 0.050211190310854116
Trained batch 97 in epoch 9, gen_loss = 0.5993801583440936, disc_loss = 0.04975893117763026
Trained batch 98 in epoch 9, gen_loss = 0.5998279973111972, disc_loss = 0.04930975964772656
Trained batch 99 in epoch 9, gen_loss = 0.6000056466460228, disc_loss = 0.04885357496328652
Trained batch 100 in epoch 9, gen_loss = 0.6001567212071749, disc_loss = 0.04840405179777801
Trained batch 101 in epoch 9, gen_loss = 0.6000735593192718, disc_loss = 0.047960985865096985
Trained batch 102 in epoch 9, gen_loss = 0.5999174826932185, disc_loss = 0.04752899660023598
Trained batch 103 in epoch 9, gen_loss = 0.5984005389305261, disc_loss = 0.048050811485154554
Trained batch 104 in epoch 9, gen_loss = 0.599699999037243, disc_loss = 0.04945693325384387
Trained batch 105 in epoch 9, gen_loss = 0.600785661418483, disc_loss = 0.049099391403186296
Trained batch 106 in epoch 9, gen_loss = 0.600907480048242, disc_loss = 0.04868417681264473
Trained batch 107 in epoch 9, gen_loss = 0.6004309063708341, disc_loss = 0.048302191997343605
Trained batch 108 in epoch 9, gen_loss = 0.6009291672925337, disc_loss = 0.047941499891682365
Trained batch 109 in epoch 9, gen_loss = 0.6012165584347465, disc_loss = 0.04754712086975236
Trained batch 110 in epoch 9, gen_loss = 0.6015354276777388, disc_loss = 0.04714479285443353
Trained batch 111 in epoch 9, gen_loss = 0.6013630516827106, disc_loss = 0.046746679824926626
Trained batch 112 in epoch 9, gen_loss = 0.6006010649478541, disc_loss = 0.04673639382647796
Trained batch 113 in epoch 9, gen_loss = 0.6016278449903455, disc_loss = 0.046430834767147246
Trained batch 114 in epoch 9, gen_loss = 0.6008160762164904, disc_loss = 0.04624546071635964
Trained batch 115 in epoch 9, gen_loss = 0.6019056886434555, disc_loss = 0.045976690002636794
Trained batch 116 in epoch 9, gen_loss = 0.6017871998314165, disc_loss = 0.04569447898847234
Trained batch 117 in epoch 9, gen_loss = 0.6014767395237745, disc_loss = 0.045352421919973095
Trained batch 118 in epoch 9, gen_loss = 0.6013534785318775, disc_loss = 0.045119107659796584
Trained batch 119 in epoch 9, gen_loss = 0.602657908697923, disc_loss = 0.04480488219802889
Trained batch 120 in epoch 9, gen_loss = 0.6037263264340803, disc_loss = 0.044482251862064004
Trained batch 121 in epoch 9, gen_loss = 0.6045272765589542, disc_loss = 0.044214330913239445
Trained batch 122 in epoch 9, gen_loss = 0.6047051994781184, disc_loss = 0.04389749167721749
Trained batch 123 in epoch 9, gen_loss = 0.6042235051431963, disc_loss = 0.0436523005294974
Trained batch 124 in epoch 9, gen_loss = 0.603127534866333, disc_loss = 0.04381280167587102
Trained batch 125 in epoch 9, gen_loss = 0.604090100242978, disc_loss = 0.04388442096145203
Trained batch 126 in epoch 9, gen_loss = 0.6045732967496857, disc_loss = 0.044334223877095916
Trained batch 127 in epoch 9, gen_loss = 0.6040973998606205, disc_loss = 0.044113124882642296
Trained batch 128 in epoch 9, gen_loss = 0.6032454801160235, disc_loss = 0.04426348329406203
Trained batch 129 in epoch 9, gen_loss = 0.6025413256425124, disc_loss = 0.04410902936763775
Trained batch 130 in epoch 9, gen_loss = 0.6013093172138884, disc_loss = 0.044307436468790616
Trained batch 131 in epoch 9, gen_loss = 0.602395622567697, disc_loss = 0.04584142400805528
Trained batch 132 in epoch 9, gen_loss = 0.6029145202242342, disc_loss = 0.04554170410190814
Trained batch 133 in epoch 9, gen_loss = 0.6033082377554765, disc_loss = 0.04527164277196653
Trained batch 134 in epoch 9, gen_loss = 0.6033801595369975, disc_loss = 0.04497931102739164
Trained batch 135 in epoch 9, gen_loss = 0.6032765569055781, disc_loss = 0.04468094670686268
Trained batch 136 in epoch 9, gen_loss = 0.6035789803866922, disc_loss = 0.04437431560686524
Trained batch 137 in epoch 9, gen_loss = 0.6037115381247755, disc_loss = 0.04406999144365714
Trained batch 138 in epoch 9, gen_loss = 0.6039871264704697, disc_loss = 0.04377397306082542
Trained batch 139 in epoch 9, gen_loss = 0.6044185340404511, disc_loss = 0.043476998859218186
Trained batch 140 in epoch 9, gen_loss = 0.6045563745160475, disc_loss = 0.04318455148963852
Trained batch 141 in epoch 9, gen_loss = 0.6045412924927724, disc_loss = 0.04289793266757378
Trained batch 142 in epoch 9, gen_loss = 0.604094872941504, disc_loss = 0.04262323599549701
Trained batch 143 in epoch 9, gen_loss = 0.6048160178793801, disc_loss = 0.04234959864859573
Trained batch 144 in epoch 9, gen_loss = 0.6049609332249082, disc_loss = 0.04209256504244845
Trained batch 145 in epoch 9, gen_loss = 0.603513025461811, disc_loss = 0.04442556675089753
Trained batch 146 in epoch 9, gen_loss = 0.6020790555444705, disc_loss = 0.04528349600605616
Trained batch 147 in epoch 9, gen_loss = 0.6019441467281934, disc_loss = 0.04619429515347489
Trained batch 148 in epoch 9, gen_loss = 0.6019680290014152, disc_loss = 0.04690686971474214
Trained batch 149 in epoch 9, gen_loss = 0.6019639927148819, disc_loss = 0.04694858117029071
Trained batch 150 in epoch 9, gen_loss = 0.6010701526079746, disc_loss = 0.047116596208552255
Trained batch 151 in epoch 9, gen_loss = 0.6000901237130165, disc_loss = 0.04733239783978972
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.7187870740890503, disc_loss = 0.07995383441448212
Trained batch 1 in epoch 10, gen_loss = 0.7023922801017761, disc_loss = 0.05388612672686577
Trained batch 2 in epoch 10, gen_loss = 0.648636261622111, disc_loss = 0.044219632943471275
Trained batch 3 in epoch 10, gen_loss = 0.6440533399581909, disc_loss = 0.037249892484396696
Trained batch 4 in epoch 10, gen_loss = 0.6343290090560914, disc_loss = 0.03574123866856098
Trained batch 5 in epoch 10, gen_loss = 0.6248123149077097, disc_loss = 0.03580038839330276
Trained batch 6 in epoch 10, gen_loss = 0.62648492200034, disc_loss = 0.03246584162116051
Trained batch 7 in epoch 10, gen_loss = 0.6367196142673492, disc_loss = 0.031479651341214776
Trained batch 8 in epoch 10, gen_loss = 0.621668365266588, disc_loss = 0.03243640292849806
Trained batch 9 in epoch 10, gen_loss = 0.6342830240726471, disc_loss = 0.03129880335181952
Trained batch 10 in epoch 10, gen_loss = 0.6405797275629911, disc_loss = 0.028938236604021353
Trained batch 11 in epoch 10, gen_loss = 0.6364343911409378, disc_loss = 0.027076028791877132
Trained batch 12 in epoch 10, gen_loss = 0.6329426948840802, disc_loss = 0.025486089253368285
Trained batch 13 in epoch 10, gen_loss = 0.631124986069543, disc_loss = 0.02391899180864649
Trained batch 14 in epoch 10, gen_loss = 0.6305601080258687, disc_loss = 0.02252627704292536
Trained batch 15 in epoch 10, gen_loss = 0.6276517175137997, disc_loss = 0.02281039353692904
Trained batch 16 in epoch 10, gen_loss = 0.627541580620934, disc_loss = 0.0218541760216741
Trained batch 17 in epoch 10, gen_loss = 0.625880112250646, disc_loss = 0.02115046191546652
Trained batch 18 in epoch 10, gen_loss = 0.61966430827191, disc_loss = 0.022016111173127826
Trained batch 19 in epoch 10, gen_loss = 0.6223908424377441, disc_loss = 0.021938738226890565
Trained batch 20 in epoch 10, gen_loss = 0.6248558674539838, disc_loss = 0.02142721104125182
Trained batch 21 in epoch 10, gen_loss = 0.6261400851336393, disc_loss = 0.02062500088306313
Trained batch 22 in epoch 10, gen_loss = 0.6266172606012096, disc_loss = 0.01995823817813526
Trained batch 23 in epoch 10, gen_loss = 0.6269206007321676, disc_loss = 0.019303407170809805
Trained batch 24 in epoch 10, gen_loss = 0.6259354782104493, disc_loss = 0.018739603459835052
Trained batch 25 in epoch 10, gen_loss = 0.623239700610821, disc_loss = 0.01839638605284003
Trained batch 26 in epoch 10, gen_loss = 0.6173941526148055, disc_loss = 0.020157844828510726
Trained batch 27 in epoch 10, gen_loss = 0.6220376970512527, disc_loss = 0.033782718337274024
Trained batch 28 in epoch 10, gen_loss = 0.6231260186639326, disc_loss = 0.03320553966251941
Trained batch 29 in epoch 10, gen_loss = 0.6209846605857213, disc_loss = 0.03281365406389038
Trained batch 30 in epoch 10, gen_loss = 0.6195625633962693, disc_loss = 0.032488675097063664
Trained batch 31 in epoch 10, gen_loss = 0.618091925047338, disc_loss = 0.03185112064238638
Trained batch 32 in epoch 10, gen_loss = 0.6171598714409452, disc_loss = 0.031160633954586403
Trained batch 33 in epoch 10, gen_loss = 0.6162222667652018, disc_loss = 0.030368493924684384
Trained batch 34 in epoch 10, gen_loss = 0.6153659386294229, disc_loss = 0.029752221916403088
Trained batch 35 in epoch 10, gen_loss = 0.6159255993035104, disc_loss = 0.02909560643860863
Trained batch 36 in epoch 10, gen_loss = 0.6147021224369874, disc_loss = 0.028518869415731042
Trained batch 37 in epoch 10, gen_loss = 0.614081640776835, disc_loss = 0.028090089878165407
Trained batch 38 in epoch 10, gen_loss = 0.6134492838994051, disc_loss = 0.027551557916479234
Trained batch 39 in epoch 10, gen_loss = 0.6125118844211102, disc_loss = 0.02696301389951259
Trained batch 40 in epoch 10, gen_loss = 0.611775403342596, disc_loss = 0.026582327535057942
Trained batch 41 in epoch 10, gen_loss = 0.6058379652954283, disc_loss = 0.0327884774610755
Trained batch 42 in epoch 10, gen_loss = 0.6071902458057847, disc_loss = 0.03913232127507759
Trained batch 43 in epoch 10, gen_loss = 0.6041327836838636, disc_loss = 0.03962272064844993
Trained batch 44 in epoch 10, gen_loss = 0.6042565080854628, disc_loss = 0.03913532327860594
Trained batch 45 in epoch 10, gen_loss = 0.6035468759744064, disc_loss = 0.03854373216871982
Trained batch 46 in epoch 10, gen_loss = 0.6030739482412947, disc_loss = 0.038038641907908816
Trained batch 47 in epoch 10, gen_loss = 0.6033478640019894, disc_loss = 0.0378717946781156
Trained batch 48 in epoch 10, gen_loss = 0.5993715439523969, disc_loss = 0.04304259458594784
Trained batch 49 in epoch 10, gen_loss = 0.5999950444698334, disc_loss = 0.04575200280174613
Trained batch 50 in epoch 10, gen_loss = 0.5984507284912408, disc_loss = 0.04622196879091801
Trained batch 51 in epoch 10, gen_loss = 0.5950837290057769, disc_loss = 0.048429162366888844
Trained batch 52 in epoch 10, gen_loss = 0.5934944799486196, disc_loss = 0.05198084624519326
Trained batch 53 in epoch 10, gen_loss = 0.5939343764826104, disc_loss = 0.05198906505204461
Trained batch 54 in epoch 10, gen_loss = 0.5904632698405873, disc_loss = 0.05880674481053244
Trained batch 55 in epoch 10, gen_loss = 0.5890130762542997, disc_loss = 0.05976196862424591
Trained batch 56 in epoch 10, gen_loss = 0.5888293835154751, disc_loss = 0.06068081570495116
Trained batch 57 in epoch 10, gen_loss = 0.5851730550157612, disc_loss = 0.062965235496261
Trained batch 58 in epoch 10, gen_loss = 0.5832345334150023, disc_loss = 0.0643425428987307
Trained batch 59 in epoch 10, gen_loss = 0.583984985947609, disc_loss = 0.06555240121670067
Trained batch 60 in epoch 10, gen_loss = 0.5865784717387841, disc_loss = 0.06535850995082836
Trained batch 61 in epoch 10, gen_loss = 0.5874081753915356, disc_loss = 0.06454180033817407
Trained batch 62 in epoch 10, gen_loss = 0.5880922627827477, disc_loss = 0.06365741762731757
Trained batch 63 in epoch 10, gen_loss = 0.5884275566786528, disc_loss = 0.06285712704993784
Trained batch 64 in epoch 10, gen_loss = 0.5886936215253976, disc_loss = 0.06201925171682468
Trained batch 65 in epoch 10, gen_loss = 0.5894967859441583, disc_loss = 0.06116962774346272
Trained batch 66 in epoch 10, gen_loss = 0.5895760664299353, disc_loss = 0.060340745972274845
Trained batch 67 in epoch 10, gen_loss = 0.5895960260840023, disc_loss = 0.0595100841806818
Trained batch 68 in epoch 10, gen_loss = 0.5900194256202035, disc_loss = 0.05870680184022564
Trained batch 69 in epoch 10, gen_loss = 0.588511968084744, disc_loss = 0.05814687989851726
Trained batch 70 in epoch 10, gen_loss = 0.5868608943173583, disc_loss = 0.05798478369128851
Trained batch 71 in epoch 10, gen_loss = 0.587841857638624, disc_loss = 0.057867833125379145
Trained batch 72 in epoch 10, gen_loss = 0.589274038190711, disc_loss = 0.05736051088722091
Trained batch 73 in epoch 10, gen_loss = 0.5883582774046305, disc_loss = 0.05701149317649873
Trained batch 74 in epoch 10, gen_loss = 0.5876331583658854, disc_loss = 0.05716287764099737
Trained batch 75 in epoch 10, gen_loss = 0.5892118748865629, disc_loss = 0.05990385609421585
Trained batch 76 in epoch 10, gen_loss = 0.5901193115618322, disc_loss = 0.05926658302339931
Trained batch 77 in epoch 10, gen_loss = 0.5884159016303527, disc_loss = 0.05976829775429975
Trained batch 78 in epoch 10, gen_loss = 0.5872313678264618, disc_loss = 0.06045828610835479
Trained batch 79 in epoch 10, gen_loss = 0.5876938957720995, disc_loss = 0.06109633531596046
Trained batch 80 in epoch 10, gen_loss = 0.5871766750459317, disc_loss = 0.06092050921942257
Trained batch 81 in epoch 10, gen_loss = 0.5878577832041717, disc_loss = 0.06076539005436821
Trained batch 82 in epoch 10, gen_loss = 0.5887467634965138, disc_loss = 0.06017454629146819
Trained batch 83 in epoch 10, gen_loss = 0.5886300138774372, disc_loss = 0.0596535282203972
Trained batch 84 in epoch 10, gen_loss = 0.5887689664083369, disc_loss = 0.05899624104392441
Trained batch 85 in epoch 10, gen_loss = 0.589349893289943, disc_loss = 0.05836450853006005
Trained batch 86 in epoch 10, gen_loss = 0.5897940503454756, disc_loss = 0.05778781783595767
Trained batch 87 in epoch 10, gen_loss = 0.5894794189794497, disc_loss = 0.05717680137339895
Trained batch 88 in epoch 10, gen_loss = 0.5887765700227758, disc_loss = 0.05667292504320235
Trained batch 89 in epoch 10, gen_loss = 0.5871050066418118, disc_loss = 0.05673176229983154
Trained batch 90 in epoch 10, gen_loss = 0.5872205377935054, disc_loss = 0.05754550388543406
Trained batch 91 in epoch 10, gen_loss = 0.5878493228684301, disc_loss = 0.05704577386369119
Trained batch 92 in epoch 10, gen_loss = 0.585577755846003, disc_loss = 0.060543616189651435
Trained batch 93 in epoch 10, gen_loss = 0.5846662071157009, disc_loss = 0.06096757002957562
Trained batch 94 in epoch 10, gen_loss = 0.5865973629449543, disc_loss = 0.062283585943575755
Trained batch 95 in epoch 10, gen_loss = 0.5868772957473993, disc_loss = 0.06190087424814313
Trained batch 96 in epoch 10, gen_loss = 0.5856619170031596, disc_loss = 0.062189891279108594
Trained batch 97 in epoch 10, gen_loss = 0.584673096939009, disc_loss = 0.062216444698884626
Trained batch 98 in epoch 10, gen_loss = 0.5832263779158544, disc_loss = 0.0633869355878407
Trained batch 99 in epoch 10, gen_loss = 0.5840753710269928, disc_loss = 0.06605523120379075
Trained batch 100 in epoch 10, gen_loss = 0.5828734412051664, disc_loss = 0.06678630850314725
Trained batch 101 in epoch 10, gen_loss = 0.5827376047770182, disc_loss = 0.06622022588271648
Trained batch 102 in epoch 10, gen_loss = 0.5827902057795848, disc_loss = 0.06569065664243857
Trained batch 103 in epoch 10, gen_loss = 0.5826067104935646, disc_loss = 0.06535251179593615
Trained batch 104 in epoch 10, gen_loss = 0.5815628920282636, disc_loss = 0.06523565322471161
Trained batch 105 in epoch 10, gen_loss = 0.580587977508329, disc_loss = 0.06558131088089761
Trained batch 106 in epoch 10, gen_loss = 0.5814693798528654, disc_loss = 0.06748819559003079
Trained batch 107 in epoch 10, gen_loss = 0.5812986890474955, disc_loss = 0.0672626288292964
Trained batch 108 in epoch 10, gen_loss = 0.5798823871743788, disc_loss = 0.06775467739218351
Trained batch 109 in epoch 10, gen_loss = 0.5794765299016779, disc_loss = 0.06739770999305289
Trained batch 110 in epoch 10, gen_loss = 0.579749431696024, disc_loss = 0.06768974298317623
Trained batch 111 in epoch 10, gen_loss = 0.5791765611086573, disc_loss = 0.06793858322739002
Trained batch 112 in epoch 10, gen_loss = 0.5792234191852333, disc_loss = 0.06818123582742316
Trained batch 113 in epoch 10, gen_loss = 0.5796550590741006, disc_loss = 0.0676364182604869
Trained batch 114 in epoch 10, gen_loss = 0.5783741728119228, disc_loss = 0.06859569331509588
Trained batch 115 in epoch 10, gen_loss = 0.5797339564767378, disc_loss = 0.06972117929775588
Trained batch 116 in epoch 10, gen_loss = 0.580507469482911, disc_loss = 0.0692881433846445
Trained batch 117 in epoch 10, gen_loss = 0.5801760417930151, disc_loss = 0.06878882822367537
Trained batch 118 in epoch 10, gen_loss = 0.5797427226515377, disc_loss = 0.06862980483232864
Trained batch 119 in epoch 10, gen_loss = 0.5785461589694023, disc_loss = 0.06884477367275395
Trained batch 120 in epoch 10, gen_loss = 0.5784206715497103, disc_loss = 0.06910245926196355
Trained batch 121 in epoch 10, gen_loss = 0.5771549004511755, disc_loss = 0.06916258544241247
Trained batch 122 in epoch 10, gen_loss = 0.5756054481839746, disc_loss = 0.07112658725544144
Trained batch 123 in epoch 10, gen_loss = 0.5754105698677802, disc_loss = 0.07136645767980465
Trained batch 124 in epoch 10, gen_loss = 0.5763910932540893, disc_loss = 0.07156943046115338
Trained batch 125 in epoch 10, gen_loss = 0.5756065235251472, disc_loss = 0.07147741393696162
Trained batch 126 in epoch 10, gen_loss = 0.5745711256199935, disc_loss = 0.0713204230405537
Trained batch 127 in epoch 10, gen_loss = 0.5757014057599008, disc_loss = 0.07159152998610807
Trained batch 128 in epoch 10, gen_loss = 0.5758660029071246, disc_loss = 0.07113755980051707
Trained batch 129 in epoch 10, gen_loss = 0.5759548962116241, disc_loss = 0.07077158506637296
Trained batch 130 in epoch 10, gen_loss = 0.5764421442992814, disc_loss = 0.07034006674119933
Trained batch 131 in epoch 10, gen_loss = 0.576996718843778, disc_loss = 0.06985490020032915
Trained batch 132 in epoch 10, gen_loss = 0.5770431214705446, disc_loss = 0.06935710292064438
Trained batch 133 in epoch 10, gen_loss = 0.5773666096267416, disc_loss = 0.06886467315715307
Trained batch 134 in epoch 10, gen_loss = 0.5774523112508986, disc_loss = 0.06838382659135041
Trained batch 135 in epoch 10, gen_loss = 0.57765181318802, disc_loss = 0.06794616570422317
Trained batch 136 in epoch 10, gen_loss = 0.5764909630274251, disc_loss = 0.06799413352171435
Trained batch 137 in epoch 10, gen_loss = 0.5763696220473967, disc_loss = 0.06780084304889475
Trained batch 138 in epoch 10, gen_loss = 0.5778240630094954, disc_loss = 0.0680979034267098
Trained batch 139 in epoch 10, gen_loss = 0.5787498576300485, disc_loss = 0.06769827300948757
Trained batch 140 in epoch 10, gen_loss = 0.5786051538819117, disc_loss = 0.06724968593210932
Trained batch 141 in epoch 10, gen_loss = 0.5782750282489079, disc_loss = 0.06687514160917153
Trained batch 142 in epoch 10, gen_loss = 0.5780167204516751, disc_loss = 0.06657776290915542
Trained batch 143 in epoch 10, gen_loss = 0.5769042248527209, disc_loss = 0.06709835308073606
Trained batch 144 in epoch 10, gen_loss = 0.578104278959077, disc_loss = 0.06814471156625398
Trained batch 145 in epoch 10, gen_loss = 0.577695468517199, disc_loss = 0.06804359400300436
Trained batch 146 in epoch 10, gen_loss = 0.576658706681258, disc_loss = 0.06848407219651909
Trained batch 147 in epoch 10, gen_loss = 0.5767911310131485, disc_loss = 0.06870680229071327
Trained batch 148 in epoch 10, gen_loss = 0.5763482259423941, disc_loss = 0.06860098349955558
Trained batch 149 in epoch 10, gen_loss = 0.5757337307929993, disc_loss = 0.06883649987168611
Trained batch 150 in epoch 10, gen_loss = 0.5763402415427151, disc_loss = 0.0696854593559162
Trained batch 151 in epoch 10, gen_loss = 0.5764996503528795, disc_loss = 0.06935255111526012
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.5044088959693909, disc_loss = 0.02375256083905697
Trained batch 1 in epoch 11, gen_loss = 0.5016699880361557, disc_loss = 0.050399101339280605
Trained batch 2 in epoch 11, gen_loss = 0.49774637818336487, disc_loss = 0.06147474981844425
Trained batch 3 in epoch 11, gen_loss = 0.5268817469477654, disc_loss = 0.06735028838738799
Trained batch 4 in epoch 11, gen_loss = 0.5583901584148407, disc_loss = 0.071846629306674
Trained batch 5 in epoch 11, gen_loss = 0.5405780772368113, disc_loss = 0.06982142757624388
Trained batch 6 in epoch 11, gen_loss = 0.558884492942265, disc_loss = 0.06130551200892244
Trained batch 7 in epoch 11, gen_loss = 0.5758562982082367, disc_loss = 0.05467113899067044
Trained batch 8 in epoch 11, gen_loss = 0.57866370677948, disc_loss = 0.04929773033493095
Trained batch 9 in epoch 11, gen_loss = 0.581180989742279, disc_loss = 0.04479659125208855
Trained batch 10 in epoch 11, gen_loss = 0.5878180915659125, disc_loss = 0.04143515948883512
Trained batch 11 in epoch 11, gen_loss = 0.5932671179374059, disc_loss = 0.03863479538510243
Trained batch 12 in epoch 11, gen_loss = 0.5941718449959388, disc_loss = 0.03629136157150452
Trained batch 13 in epoch 11, gen_loss = 0.5966444568974631, disc_loss = 0.03399010933935642
Trained batch 14 in epoch 11, gen_loss = 0.5971460461616516, disc_loss = 0.03198176259174943
Trained batch 15 in epoch 11, gen_loss = 0.6000602431595325, disc_loss = 0.030299711565021425
Trained batch 16 in epoch 11, gen_loss = 0.5999639069332796, disc_loss = 0.02904538273373071
Trained batch 17 in epoch 11, gen_loss = 0.5976909266577827, disc_loss = 0.02862349131868945
Trained batch 18 in epoch 11, gen_loss = 0.5935132095688268, disc_loss = 0.03031977383713973
Trained batch 19 in epoch 11, gen_loss = 0.5992276757955551, disc_loss = 0.03561602383852005
Trained batch 20 in epoch 11, gen_loss = 0.6010750617299762, disc_loss = 0.03425814459721247
Trained batch 21 in epoch 11, gen_loss = 0.596102541143244, disc_loss = 0.03476402773098512
Trained batch 22 in epoch 11, gen_loss = 0.588102919899899, disc_loss = 0.0368627636976864
Trained batch 23 in epoch 11, gen_loss = 0.5942306059102217, disc_loss = 0.04140854720026255
Trained batch 24 in epoch 11, gen_loss = 0.595955890417099, disc_loss = 0.03998284922912717
Trained batch 25 in epoch 11, gen_loss = 0.5900645198730322, disc_loss = 0.04634336885423041
Trained batch 26 in epoch 11, gen_loss = 0.588259470683557, disc_loss = 0.04632363345956913
Trained batch 27 in epoch 11, gen_loss = 0.5896436667868069, disc_loss = 0.051598445795077295
Trained batch 28 in epoch 11, gen_loss = 0.5834888415089969, disc_loss = 0.05907395290981593
Trained batch 29 in epoch 11, gen_loss = 0.5797013173500697, disc_loss = 0.06079960777424276
Trained batch 30 in epoch 11, gen_loss = 0.5805244859187834, disc_loss = 0.06629033688636075
Trained batch 31 in epoch 11, gen_loss = 0.5763220125809312, disc_loss = 0.07601150650589261
Trained batch 32 in epoch 11, gen_loss = 0.5729027453697089, disc_loss = 0.0826360869052058
Trained batch 33 in epoch 11, gen_loss = 0.5721761628108866, disc_loss = 0.08652313153588158
Trained batch 34 in epoch 11, gen_loss = 0.5719861107213157, disc_loss = 0.08976641905360988
Trained batch 35 in epoch 11, gen_loss = 0.569459528558784, disc_loss = 0.09210719966277894
Trained batch 36 in epoch 11, gen_loss = 0.5653058540176701, disc_loss = 0.09416827208337349
Trained batch 37 in epoch 11, gen_loss = 0.5659268396465402, disc_loss = 0.09457255067842964
Trained batch 38 in epoch 11, gen_loss = 0.5656079183786343, disc_loss = 0.09370844745530914
Trained batch 39 in epoch 11, gen_loss = 0.5636590741574764, disc_loss = 0.09320100947516038
Trained batch 40 in epoch 11, gen_loss = 0.5598534280207099, disc_loss = 0.09504645437047612
Trained batch 41 in epoch 11, gen_loss = 0.561421356740452, disc_loss = 0.09755994158885664
Trained batch 42 in epoch 11, gen_loss = 0.5629934328933095, disc_loss = 0.09699745555300006
Trained batch 43 in epoch 11, gen_loss = 0.5594870563257824, disc_loss = 0.0979259540009397
Trained batch 44 in epoch 11, gen_loss = 0.5550986422432793, disc_loss = 0.10121892302607496
Trained batch 45 in epoch 11, gen_loss = 0.5533210946165997, disc_loss = 0.10288121560386018
Trained batch 46 in epoch 11, gen_loss = 0.5533579004571793, disc_loss = 0.10380928322395429
Trained batch 47 in epoch 11, gen_loss = 0.5526453653971354, disc_loss = 0.10298745280791384
Trained batch 48 in epoch 11, gen_loss = 0.5548229704097826, disc_loss = 0.10130571506499332
Trained batch 49 in epoch 11, gen_loss = 0.5564895927906036, disc_loss = 0.09954155535437166
Trained batch 50 in epoch 11, gen_loss = 0.5562867919603983, disc_loss = 0.09789798256265474
Trained batch 51 in epoch 11, gen_loss = 0.5549734532833099, disc_loss = 0.0966630868273429
Trained batch 52 in epoch 11, gen_loss = 0.5534231454696296, disc_loss = 0.09613234501437477
Trained batch 53 in epoch 11, gen_loss = 0.5551861872275671, disc_loss = 0.09494240582851624
Trained batch 54 in epoch 11, gen_loss = 0.5524412669918753, disc_loss = 0.09607985941693187
Trained batch 55 in epoch 11, gen_loss = 0.5518407177712236, disc_loss = 0.0959305293675113
Trained batch 56 in epoch 11, gen_loss = 0.5558140523600996, disc_loss = 0.09514303885302261
Trained batch 57 in epoch 11, gen_loss = 0.5578072795580173, disc_loss = 0.09379563558493452
Trained batch 58 in epoch 11, gen_loss = 0.5588243305683136, disc_loss = 0.09237068766033497
Trained batch 59 in epoch 11, gen_loss = 0.5594387675325075, disc_loss = 0.09112087246806672
Trained batch 60 in epoch 11, gen_loss = 0.5599022512553168, disc_loss = 0.08974198776404144
Trained batch 61 in epoch 11, gen_loss = 0.5603402107954025, disc_loss = 0.08837261407696191
Trained batch 62 in epoch 11, gen_loss = 0.5618664409433093, disc_loss = 0.08706631682192285
Trained batch 63 in epoch 11, gen_loss = 0.563102254178375, disc_loss = 0.0858844327085535
Trained batch 64 in epoch 11, gen_loss = 0.5638522849633143, disc_loss = 0.0846530620725109
Trained batch 65 in epoch 11, gen_loss = 0.5640705828413819, disc_loss = 0.08345676046993697
Trained batch 66 in epoch 11, gen_loss = 0.5644049026183228, disc_loss = 0.08228435600176454
Trained batch 67 in epoch 11, gen_loss = 0.5645522242959808, disc_loss = 0.08115014429067206
Trained batch 68 in epoch 11, gen_loss = 0.565227471831916, disc_loss = 0.08002678827261148
Trained batch 69 in epoch 11, gen_loss = 0.566152212023735, disc_loss = 0.07893694983130055
Trained batch 70 in epoch 11, gen_loss = 0.5668213808200728, disc_loss = 0.07790211402535649
Trained batch 71 in epoch 11, gen_loss = 0.5669362267686261, disc_loss = 0.07693074776196024
Trained batch 72 in epoch 11, gen_loss = 0.5661678408106713, disc_loss = 0.07602465806579957
Trained batch 73 in epoch 11, gen_loss = 0.565756852159629, disc_loss = 0.07521439575892244
Trained batch 74 in epoch 11, gen_loss = 0.56794872879982, disc_loss = 0.07442162859564026
Trained batch 75 in epoch 11, gen_loss = 0.5667834874046477, disc_loss = 0.07408190467762515
Trained batch 76 in epoch 11, gen_loss = 0.5693314853426698, disc_loss = 0.07405895350936365
Trained batch 77 in epoch 11, gen_loss = 0.5704291573701761, disc_loss = 0.07326136331838103
Trained batch 78 in epoch 11, gen_loss = 0.5704443926298166, disc_loss = 0.07248005268010724
Trained batch 79 in epoch 11, gen_loss = 0.5698230553418397, disc_loss = 0.07168642676551826
Trained batch 80 in epoch 11, gen_loss = 0.5697996266830114, disc_loss = 0.07094551002560759
Trained batch 81 in epoch 11, gen_loss = 0.5694137241055326, disc_loss = 0.07019742708312483
Trained batch 82 in epoch 11, gen_loss = 0.5690861240208868, disc_loss = 0.06944033118099513
Trained batch 83 in epoch 11, gen_loss = 0.5683669635937327, disc_loss = 0.06915848276999202
Trained batch 84 in epoch 11, gen_loss = 0.5669623175088097, disc_loss = 0.06987381788408932
Trained batch 85 in epoch 11, gen_loss = 0.5689336737227995, disc_loss = 0.07225858853848348
Trained batch 86 in epoch 11, gen_loss = 0.5687009839490912, disc_loss = 0.0717054311796252
Trained batch 87 in epoch 11, gen_loss = 0.5671317299658601, disc_loss = 0.07125849734504962
Trained batch 88 in epoch 11, gen_loss = 0.5668658681130141, disc_loss = 0.07068046488474762
Trained batch 89 in epoch 11, gen_loss = 0.5645031578010983, disc_loss = 0.07158365097000367
Trained batch 90 in epoch 11, gen_loss = 0.565022158753741, disc_loss = 0.07330097680256425
Trained batch 91 in epoch 11, gen_loss = 0.5634270770394284, disc_loss = 0.07421305723508577
Trained batch 92 in epoch 11, gen_loss = 0.5628599486043376, disc_loss = 0.07515929475606929
Trained batch 93 in epoch 11, gen_loss = 0.5634889792888722, disc_loss = 0.07453398896440705
Trained batch 94 in epoch 11, gen_loss = 0.5627403849049618, disc_loss = 0.07439168662715115
Trained batch 95 in epoch 11, gen_loss = 0.5622794609516859, disc_loss = 0.07431382114009466
Trained batch 96 in epoch 11, gen_loss = 0.5629590891071201, disc_loss = 0.07496305657358668
Trained batch 97 in epoch 11, gen_loss = 0.561520514135458, disc_loss = 0.07570186548638252
Trained batch 98 in epoch 11, gen_loss = 0.562513461919746, disc_loss = 0.07578540934400275
Trained batch 99 in epoch 11, gen_loss = 0.5617003682255745, disc_loss = 0.07551836336497217
Trained batch 100 in epoch 11, gen_loss = 0.5608257303143492, disc_loss = 0.07543047202640388
Trained batch 101 in epoch 11, gen_loss = 0.5615369712605196, disc_loss = 0.07579762271751522
Trained batch 102 in epoch 11, gen_loss = 0.5612578345733938, disc_loss = 0.07533007008882547
Trained batch 103 in epoch 11, gen_loss = 0.5619280017339267, disc_loss = 0.07472651054670748
Trained batch 104 in epoch 11, gen_loss = 0.5607265483765375, disc_loss = 0.07584667096269272
Trained batch 105 in epoch 11, gen_loss = 0.561615230339878, disc_loss = 0.07607609789625232
Trained batch 106 in epoch 11, gen_loss = 0.5611776748550272, disc_loss = 0.0759860191224404
Trained batch 107 in epoch 11, gen_loss = 0.5618208839937493, disc_loss = 0.07560300875748335
Trained batch 108 in epoch 11, gen_loss = 0.5601415358005314, disc_loss = 0.07665229206392114
Trained batch 109 in epoch 11, gen_loss = 0.5595743214542216, disc_loss = 0.07656905692155389
Trained batch 110 in epoch 11, gen_loss = 0.5606740200304771, disc_loss = 0.07720956112769944
Trained batch 111 in epoch 11, gen_loss = 0.558976909411805, disc_loss = 0.07858659048049178
Trained batch 112 in epoch 11, gen_loss = 0.5586240027858093, disc_loss = 0.07925910918470637
Trained batch 113 in epoch 11, gen_loss = 0.5591692406880228, disc_loss = 0.07866164717186046
Trained batch 114 in epoch 11, gen_loss = 0.5599469672078672, disc_loss = 0.07846527299236344
Trained batch 115 in epoch 11, gen_loss = 0.5593191554834103, disc_loss = 0.07826744429847418
Trained batch 116 in epoch 11, gen_loss = 0.5591775713822781, disc_loss = 0.07780762932573755
Trained batch 117 in epoch 11, gen_loss = 0.5600387893490872, disc_loss = 0.07729903681566781
Trained batch 118 in epoch 11, gen_loss = 0.5615537877844161, disc_loss = 0.07684785157770795
Trained batch 119 in epoch 11, gen_loss = 0.5621642013390858, disc_loss = 0.07631912359114115
Trained batch 120 in epoch 11, gen_loss = 0.5616900270635431, disc_loss = 0.07629444133413356
Trained batch 121 in epoch 11, gen_loss = 0.5630412443739469, disc_loss = 0.07664298831454677
Trained batch 122 in epoch 11, gen_loss = 0.5625195212480498, disc_loss = 0.07642068735482853
Trained batch 123 in epoch 11, gen_loss = 0.5608429182921687, disc_loss = 0.07758939990608563
Trained batch 124 in epoch 11, gen_loss = 0.5618234362602234, disc_loss = 0.07950915673747659
Trained batch 125 in epoch 11, gen_loss = 0.5616317921214633, disc_loss = 0.07979208417606377
Trained batch 126 in epoch 11, gen_loss = 0.5609823524013279, disc_loss = 0.08062291612085981
Trained batch 127 in epoch 11, gen_loss = 0.5610989613924176, disc_loss = 0.08190902424757951
Trained batch 128 in epoch 11, gen_loss = 0.5603652145973471, disc_loss = 0.08272915094181202
Trained batch 129 in epoch 11, gen_loss = 0.5607755200220989, disc_loss = 0.08329417152831761
Trained batch 130 in epoch 11, gen_loss = 0.5609723008770979, disc_loss = 0.08345563093001265
Trained batch 131 in epoch 11, gen_loss = 0.5607304056033944, disc_loss = 0.08372764196599636
Trained batch 132 in epoch 11, gen_loss = 0.5601486043822497, disc_loss = 0.08363101785806448
Trained batch 133 in epoch 11, gen_loss = 0.5591481826198634, disc_loss = 0.08386955763658148
Trained batch 134 in epoch 11, gen_loss = 0.5598107346781978, disc_loss = 0.08435102566317827
Trained batch 135 in epoch 11, gen_loss = 0.5586592598873026, disc_loss = 0.08547491314889424
Trained batch 136 in epoch 11, gen_loss = 0.5583684505337346, disc_loss = 0.08549165560177317
Trained batch 137 in epoch 11, gen_loss = 0.5595868005268816, disc_loss = 0.08540731277384296
Trained batch 138 in epoch 11, gen_loss = 0.5600535453652307, disc_loss = 0.08485639396478696
Trained batch 139 in epoch 11, gen_loss = 0.5598794153758457, disc_loss = 0.084379002262306
Trained batch 140 in epoch 11, gen_loss = 0.5597684544028966, disc_loss = 0.08401866338763994
Trained batch 141 in epoch 11, gen_loss = 0.5587810945342964, disc_loss = 0.08481290356361006
Trained batch 142 in epoch 11, gen_loss = 0.5591242375907365, disc_loss = 0.08557181609664243
Trained batch 143 in epoch 11, gen_loss = 0.5590508307019869, disc_loss = 0.08532526154886
Trained batch 144 in epoch 11, gen_loss = 0.5585761325112705, disc_loss = 0.08555093980233731
Trained batch 145 in epoch 11, gen_loss = 0.5581132961462622, disc_loss = 0.0857978788466027
Trained batch 146 in epoch 11, gen_loss = 0.5574980049717183, disc_loss = 0.08594075795326407
Trained batch 147 in epoch 11, gen_loss = 0.557893189224037, disc_loss = 0.08597669636868444
Trained batch 148 in epoch 11, gen_loss = 0.5588730945683166, disc_loss = 0.08568340262098101
Trained batch 149 in epoch 11, gen_loss = 0.559300848642985, disc_loss = 0.08516178249071042
Trained batch 150 in epoch 11, gen_loss = 0.5597831950282419, disc_loss = 0.08464933141745282
Trained batch 151 in epoch 11, gen_loss = 0.5598031635347166, disc_loss = 0.08416419149695062
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.6336612105369568, disc_loss = 0.0103019829839468
Trained batch 1 in epoch 12, gen_loss = 0.5744069218635559, disc_loss = 0.011477217078208923
Trained batch 2 in epoch 12, gen_loss = 0.5751421650250753, disc_loss = 0.011046133314569792
Trained batch 3 in epoch 12, gen_loss = 0.572935551404953, disc_loss = 0.011612501693889499
Trained batch 4 in epoch 12, gen_loss = 0.5814671993255616, disc_loss = 0.012256351299583912
Trained batch 5 in epoch 12, gen_loss = 0.5655905604362488, disc_loss = 0.013885247676322857
Trained batch 6 in epoch 12, gen_loss = 0.5598415306636265, disc_loss = 0.015244787958051478
Trained batch 7 in epoch 12, gen_loss = 0.5769978910684586, disc_loss = 0.01820082461927086
Trained batch 8 in epoch 12, gen_loss = 0.5707658463054233, disc_loss = 0.019690216932859685
Trained batch 9 in epoch 12, gen_loss = 0.5629105508327484, disc_loss = 0.03457526983693242
Trained batch 10 in epoch 12, gen_loss = 0.5764977552674033, disc_loss = 0.06312942885878411
Trained batch 11 in epoch 12, gen_loss = 0.5742858697970709, disc_loss = 0.06075910362415016
Trained batch 12 in epoch 12, gen_loss = 0.562195748090744, disc_loss = 0.07220052419087061
Trained batch 13 in epoch 12, gen_loss = 0.5592048317193985, disc_loss = 0.07435444589438182
Trained batch 14 in epoch 12, gen_loss = 0.5540829400221506, disc_loss = 0.07860948797315359
Trained batch 15 in epoch 12, gen_loss = 0.5487918220460415, disc_loss = 0.08073075214633718
Trained batch 16 in epoch 12, gen_loss = 0.5469410629833446, disc_loss = 0.0846243150641813
Trained batch 17 in epoch 12, gen_loss = 0.5387647300958633, disc_loss = 0.08814870571303698
Trained batch 18 in epoch 12, gen_loss = 0.541386405104085, disc_loss = 0.08706177854420323
Trained batch 19 in epoch 12, gen_loss = 0.5361499294638634, disc_loss = 0.08843718585558236
Trained batch 20 in epoch 12, gen_loss = 0.5390322023913974, disc_loss = 0.08890083188279754
Trained batch 21 in epoch 12, gen_loss = 0.5372219261797991, disc_loss = 0.08739504662596366
Trained batch 22 in epoch 12, gen_loss = 0.5322709524113199, disc_loss = 0.09019286189552235
Trained batch 23 in epoch 12, gen_loss = 0.5385899717609087, disc_loss = 0.10047801308489095
Trained batch 24 in epoch 12, gen_loss = 0.5367646491527558, disc_loss = 0.10018369410187006
Trained batch 25 in epoch 12, gen_loss = 0.5391957702545019, disc_loss = 0.0976054365030275
Trained batch 26 in epoch 12, gen_loss = 0.5323956476317512, disc_loss = 0.10332424500612197
Trained batch 27 in epoch 12, gen_loss = 0.5323357901402882, disc_loss = 0.10855695821477898
Trained batch 28 in epoch 12, gen_loss = 0.5355735421180725, disc_loss = 0.10842909667127092
Trained batch 29 in epoch 12, gen_loss = 0.534244762857755, disc_loss = 0.10663289877896508
Trained batch 30 in epoch 12, gen_loss = 0.5324757983607631, disc_loss = 0.10653009268665506
Trained batch 31 in epoch 12, gen_loss = 0.5282797897234559, disc_loss = 0.10889509812113829
Trained batch 32 in epoch 12, gen_loss = 0.5305482591643478, disc_loss = 0.11113609128038991
Trained batch 33 in epoch 12, gen_loss = 0.5278295112006804, disc_loss = 0.11042260490905713
Trained batch 34 in epoch 12, gen_loss = 0.5308968484401703, disc_loss = 0.10875019284763507
Trained batch 35 in epoch 12, gen_loss = 0.5320912541614639, disc_loss = 0.10610791991671754
Trained batch 36 in epoch 12, gen_loss = 0.5315479547590822, disc_loss = 0.10393143125583192
Trained batch 37 in epoch 12, gen_loss = 0.5313064228547247, disc_loss = 0.10214769783870954
Trained batch 38 in epoch 12, gen_loss = 0.5295153344288851, disc_loss = 0.10142676362720056
Trained batch 39 in epoch 12, gen_loss = 0.5311155624687671, disc_loss = 0.1010528018930927
Trained batch 40 in epoch 12, gen_loss = 0.5299599199760251, disc_loss = 0.10073431656218884
Trained batch 41 in epoch 12, gen_loss = 0.5295906180427188, disc_loss = 0.10075692675032076
Trained batch 42 in epoch 12, gen_loss = 0.5310506903847982, disc_loss = 0.0988481504582735
Trained batch 43 in epoch 12, gen_loss = 0.5283826440572739, disc_loss = 0.10130740657702765
Trained batch 44 in epoch 12, gen_loss = 0.5300592846340604, disc_loss = 0.10294250073946185
Trained batch 45 in epoch 12, gen_loss = 0.5331412307594133, disc_loss = 0.1013289955444634
Trained batch 46 in epoch 12, gen_loss = 0.5322574510219249, disc_loss = 0.09996458648287869
Trained batch 47 in epoch 12, gen_loss = 0.5306328150133292, disc_loss = 0.10015211842255667
Trained batch 48 in epoch 12, gen_loss = 0.5327146637196444, disc_loss = 0.09914528515798096
Trained batch 49 in epoch 12, gen_loss = 0.5317735904455185, disc_loss = 0.09893237305805087
Trained batch 50 in epoch 12, gen_loss = 0.5354247157480202, disc_loss = 0.09735050729895924
Trained batch 51 in epoch 12, gen_loss = 0.5362106257906327, disc_loss = 0.09573588942965636
Trained batch 52 in epoch 12, gen_loss = 0.5339971319684442, disc_loss = 0.09992695325669253
Trained batch 53 in epoch 12, gen_loss = 0.5372491412692599, disc_loss = 0.10211815319403454
Trained batch 54 in epoch 12, gen_loss = 0.5395840666510842, disc_loss = 0.1008171445266767
Trained batch 55 in epoch 12, gen_loss = 0.5393919263567243, disc_loss = 0.09987404589940395
Trained batch 56 in epoch 12, gen_loss = 0.5378399130545164, disc_loss = 0.10052227418412242
Trained batch 57 in epoch 12, gen_loss = 0.5387112267058471, disc_loss = 0.09985893354590597
Trained batch 58 in epoch 12, gen_loss = 0.5386002068802461, disc_loss = 0.09904835606783123
Trained batch 59 in epoch 12, gen_loss = 0.535612993935744, disc_loss = 0.10012692927072446
Trained batch 60 in epoch 12, gen_loss = 0.536199195951712, disc_loss = 0.100307006633184
Trained batch 61 in epoch 12, gen_loss = 0.5387324234170299, disc_loss = 0.09940374294115652
Trained batch 62 in epoch 12, gen_loss = 0.5383980392463623, disc_loss = 0.09845540542451162
Trained batch 63 in epoch 12, gen_loss = 0.5369289456866682, disc_loss = 0.09917901828885078
Trained batch 64 in epoch 12, gen_loss = 0.5399424227384421, disc_loss = 0.10132304590481978
Trained batch 65 in epoch 12, gen_loss = 0.5408550207362031, disc_loss = 0.10051418236936584
Trained batch 66 in epoch 12, gen_loss = 0.5394430698743508, disc_loss = 0.1001732311030822
Trained batch 67 in epoch 12, gen_loss = 0.5382248439333018, disc_loss = 0.10089613031595945
Trained batch 68 in epoch 12, gen_loss = 0.5404062690078348, disc_loss = 0.10072324948682301
Trained batch 69 in epoch 12, gen_loss = 0.5410500530685697, disc_loss = 0.10031640194356442
Trained batch 70 in epoch 12, gen_loss = 0.5404052461536837, disc_loss = 0.09987653660732256
Trained batch 71 in epoch 12, gen_loss = 0.53965367252628, disc_loss = 0.09964761350096928
Trained batch 72 in epoch 12, gen_loss = 0.5390613442414427, disc_loss = 0.09974497745502485
Trained batch 73 in epoch 12, gen_loss = 0.5405807797167752, disc_loss = 0.10066322302697478
Trained batch 74 in epoch 12, gen_loss = 0.5413633318742116, disc_loss = 0.09954620738824209
Trained batch 75 in epoch 12, gen_loss = 0.5415302503265833, disc_loss = 0.09870654736694537
Trained batch 76 in epoch 12, gen_loss = 0.5404017803730903, disc_loss = 0.098286467713195
Trained batch 77 in epoch 12, gen_loss = 0.5403646135177368, disc_loss = 0.09748179541948514
Trained batch 78 in epoch 12, gen_loss = 0.539484359041045, disc_loss = 0.09720377133616918
Trained batch 79 in epoch 12, gen_loss = 0.5417920514941216, disc_loss = 0.09690290465950965
Trained batch 80 in epoch 12, gen_loss = 0.5438087589946794, disc_loss = 0.09594030439117808
Trained batch 81 in epoch 12, gen_loss = 0.5446842080209313, disc_loss = 0.09487418319303088
Trained batch 82 in epoch 12, gen_loss = 0.5450693957776909, disc_loss = 0.09391197958310325
Trained batch 83 in epoch 12, gen_loss = 0.5453017907483237, disc_loss = 0.09287802378336589
Trained batch 84 in epoch 12, gen_loss = 0.5455924062167897, disc_loss = 0.09185155802680289
Trained batch 85 in epoch 12, gen_loss = 0.546077219552772, disc_loss = 0.09084395265618209
Trained batch 86 in epoch 12, gen_loss = 0.5463662517481837, disc_loss = 0.0898736873052843
Trained batch 87 in epoch 12, gen_loss = 0.5459716326811097, disc_loss = 0.08918120283950967
Trained batch 88 in epoch 12, gen_loss = 0.5463320304838459, disc_loss = 0.08830008810134919
Trained batch 89 in epoch 12, gen_loss = 0.5463679360018836, disc_loss = 0.08751463732268247
Trained batch 90 in epoch 12, gen_loss = 0.546173448746021, disc_loss = 0.08700474834192422
Trained batch 91 in epoch 12, gen_loss = 0.5482157611328623, disc_loss = 0.08627946998255895
Trained batch 92 in epoch 12, gen_loss = 0.548697203718206, disc_loss = 0.08550598888447689
Trained batch 93 in epoch 12, gen_loss = 0.5501715921341105, disc_loss = 0.08470563049071488
Trained batch 94 in epoch 12, gen_loss = 0.5511009002986708, disc_loss = 0.08396250324715909
Trained batch 95 in epoch 12, gen_loss = 0.5512753973404566, disc_loss = 0.08324323440804922
Trained batch 96 in epoch 12, gen_loss = 0.5504790249559068, disc_loss = 0.08315234348542758
Trained batch 97 in epoch 12, gen_loss = 0.5518656348695561, disc_loss = 0.08315496634672948
Trained batch 98 in epoch 12, gen_loss = 0.5537410577138265, disc_loss = 0.0826459665255941
Trained batch 99 in epoch 12, gen_loss = 0.5545350623130798, disc_loss = 0.08188595818821341
Trained batch 100 in epoch 12, gen_loss = 0.5547186980153075, disc_loss = 0.0813244654483503
Trained batch 101 in epoch 12, gen_loss = 0.5540628479976281, disc_loss = 0.08116368097070531
Trained batch 102 in epoch 12, gen_loss = 0.5553409723402227, disc_loss = 0.08082070167727985
Trained batch 103 in epoch 12, gen_loss = 0.556343477505904, disc_loss = 0.08036482977555491
Trained batch 104 in epoch 12, gen_loss = 0.5569301633607774, disc_loss = 0.07975068183261014
Trained batch 105 in epoch 12, gen_loss = 0.5570533213750372, disc_loss = 0.07922071904242742
Trained batch 106 in epoch 12, gen_loss = 0.5554054797252762, disc_loss = 0.07968051477866335
Trained batch 107 in epoch 12, gen_loss = 0.554518036544323, disc_loss = 0.07959346263238264
Trained batch 108 in epoch 12, gen_loss = 0.5560075419211606, disc_loss = 0.08024716292243075
Trained batch 109 in epoch 12, gen_loss = 0.5553900249979713, disc_loss = 0.08077574152584104
Trained batch 110 in epoch 12, gen_loss = 0.5544244365112202, disc_loss = 0.08206911341849345
Trained batch 111 in epoch 12, gen_loss = 0.5549369281423944, disc_loss = 0.08235036099878405
Trained batch 112 in epoch 12, gen_loss = 0.5541933735387515, disc_loss = 0.08240119503415395
Trained batch 113 in epoch 12, gen_loss = 0.5536925946934181, disc_loss = 0.08216388010942753
Trained batch 114 in epoch 12, gen_loss = 0.5528534503086754, disc_loss = 0.08206914893715926
Trained batch 115 in epoch 12, gen_loss = 0.5532384065204653, disc_loss = 0.08265900711834046
Trained batch 116 in epoch 12, gen_loss = 0.5518714816142352, disc_loss = 0.08332538270813405
Trained batch 117 in epoch 12, gen_loss = 0.5515784737417253, disc_loss = 0.0841305951422112
Trained batch 118 in epoch 12, gen_loss = 0.552706381853889, disc_loss = 0.08398808010251206
Trained batch 119 in epoch 12, gen_loss = 0.5516502360502878, disc_loss = 0.08419477496063336
Trained batch 120 in epoch 12, gen_loss = 0.5519512143016847, disc_loss = 0.08389725090073775
Trained batch 121 in epoch 12, gen_loss = 0.5512789326613067, disc_loss = 0.08380566302641126
Trained batch 122 in epoch 12, gen_loss = 0.5524453007108797, disc_loss = 0.08358495458733381
Trained batch 123 in epoch 12, gen_loss = 0.5530491942359556, disc_loss = 0.08317996171348158
Trained batch 124 in epoch 12, gen_loss = 0.5531318230628968, disc_loss = 0.08268049526587129
Trained batch 125 in epoch 12, gen_loss = 0.5532035794523027, disc_loss = 0.08227121735745598
Trained batch 126 in epoch 12, gen_loss = 0.5526871826705031, disc_loss = 0.08252822649188515
Trained batch 127 in epoch 12, gen_loss = 0.5540507035329938, disc_loss = 0.08243962884080247
Trained batch 128 in epoch 12, gen_loss = 0.5547035955643469, disc_loss = 0.082124711588285
Trained batch 129 in epoch 12, gen_loss = 0.5552321392756242, disc_loss = 0.08157512982949042
Trained batch 130 in epoch 12, gen_loss = 0.5546142140417608, disc_loss = 0.0811494214510019
Trained batch 131 in epoch 12, gen_loss = 0.554473447077202, disc_loss = 0.08073501205989018
Trained batch 132 in epoch 12, gen_loss = 0.5539239972157586, disc_loss = 0.08078581975997054
Trained batch 133 in epoch 12, gen_loss = 0.5550281876948342, disc_loss = 0.08097489774852658
Trained batch 134 in epoch 12, gen_loss = 0.5556554758990252, disc_loss = 0.08050841007864586
Trained batch 135 in epoch 12, gen_loss = 0.5557271890780505, disc_loss = 0.07998743563246749
Trained batch 136 in epoch 12, gen_loss = 0.5560385476063637, disc_loss = 0.0795515514128454
Trained batch 137 in epoch 12, gen_loss = 0.5565163242644158, disc_loss = 0.07903220207241458
Trained batch 138 in epoch 12, gen_loss = 0.5570308197316506, disc_loss = 0.07850422188237631
Trained batch 139 in epoch 12, gen_loss = 0.5573884729828154, disc_loss = 0.07799164694401302
Trained batch 140 in epoch 12, gen_loss = 0.5577637616624224, disc_loss = 0.07756038586417517
Trained batch 141 in epoch 12, gen_loss = 0.5581135132782896, disc_loss = 0.07705818522970756
Trained batch 142 in epoch 12, gen_loss = 0.55854066310229, disc_loss = 0.07655654363399306
Trained batch 143 in epoch 12, gen_loss = 0.5589685837427775, disc_loss = 0.07606021959670922
Trained batch 144 in epoch 12, gen_loss = 0.5590149641036988, disc_loss = 0.07556863907917306
Trained batch 145 in epoch 12, gen_loss = 0.5589691286217676, disc_loss = 0.07509423382835437
Trained batch 146 in epoch 12, gen_loss = 0.5591207969756353, disc_loss = 0.07464101704052922
Trained batch 147 in epoch 12, gen_loss = 0.5598643808751493, disc_loss = 0.07435443092489967
Trained batch 148 in epoch 12, gen_loss = 0.5593421859229171, disc_loss = 0.07428287830978832
Trained batch 149 in epoch 12, gen_loss = 0.5600115807851156, disc_loss = 0.07399815630167722
Trained batch 150 in epoch 12, gen_loss = 0.5606447253006184, disc_loss = 0.07360107975931751
Trained batch 151 in epoch 12, gen_loss = 0.561365866739499, disc_loss = 0.07317427521277416
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.6396267414093018, disc_loss = 0.004751327447593212
Trained batch 1 in epoch 13, gen_loss = 0.62141352891922, disc_loss = 0.004511815961450338
Trained batch 2 in epoch 13, gen_loss = 0.6189326246579488, disc_loss = 0.0045653292909264565
Trained batch 3 in epoch 13, gen_loss = 0.6066527515649796, disc_loss = 0.006084438180550933
Trained batch 4 in epoch 13, gen_loss = 0.602165687084198, disc_loss = 0.005554158613085747
Trained batch 5 in epoch 13, gen_loss = 0.5921336313088735, disc_loss = 0.0057025321293622255
Trained batch 6 in epoch 13, gen_loss = 0.594887912273407, disc_loss = 0.005249749436708433
Trained batch 7 in epoch 13, gen_loss = 0.5906233340501785, disc_loss = 0.004991981462808326
Trained batch 8 in epoch 13, gen_loss = 0.5900646845499674, disc_loss = 0.004819271697973211
Trained batch 9 in epoch 13, gen_loss = 0.5910452902317047, disc_loss = 0.004918167018331587
Trained batch 10 in epoch 13, gen_loss = 0.5919690240513195, disc_loss = 0.004770002454857935
Trained batch 11 in epoch 13, gen_loss = 0.5932431270678838, disc_loss = 0.004817898889693121
Trained batch 12 in epoch 13, gen_loss = 0.591950421149914, disc_loss = 0.004848534599519693
Trained batch 13 in epoch 13, gen_loss = 0.5900944811957223, disc_loss = 0.004794186945738537
Trained batch 14 in epoch 13, gen_loss = 0.5920339186986288, disc_loss = 0.004837890931715568
Trained batch 15 in epoch 13, gen_loss = 0.598303347826004, disc_loss = 0.004931544535793364
Trained batch 16 in epoch 13, gen_loss = 0.59793380428763, disc_loss = 0.0052262802663094856
Trained batch 17 in epoch 13, gen_loss = 0.5952313774161868, disc_loss = 0.0074065554783576066
Trained batch 18 in epoch 13, gen_loss = 0.604175677424983, disc_loss = 0.009694911098401798
Trained batch 19 in epoch 13, gen_loss = 0.6109983533620834, disc_loss = 0.00988922007381916
Trained batch 20 in epoch 13, gen_loss = 0.6124866434506008, disc_loss = 0.009731883959223827
Trained batch 21 in epoch 13, gen_loss = 0.6102446724068035, disc_loss = 0.009700854160738263
Trained batch 22 in epoch 13, gen_loss = 0.6095846450847128, disc_loss = 0.009487636569563461
Trained batch 23 in epoch 13, gen_loss = 0.6077468519409498, disc_loss = 0.009393276510915408
Trained batch 24 in epoch 13, gen_loss = 0.6071649146080017, disc_loss = 0.009228126648813485
Trained batch 25 in epoch 13, gen_loss = 0.6071484020123115, disc_loss = 0.009295794235255856
Trained batch 26 in epoch 13, gen_loss = 0.6065920171914277, disc_loss = 0.009258631496103826
Trained batch 27 in epoch 13, gen_loss = 0.6041060558387211, disc_loss = 0.009190389054960437
Trained batch 28 in epoch 13, gen_loss = 0.6024596773344895, disc_loss = 0.009542688566805988
Trained batch 29 in epoch 13, gen_loss = 0.6010897676150004, disc_loss = 0.009440267054984967
Trained batch 30 in epoch 13, gen_loss = 0.601154500438321, disc_loss = 0.009723320513242675
Trained batch 31 in epoch 13, gen_loss = 0.6047446951270103, disc_loss = 0.0102245923189912
Trained batch 32 in epoch 13, gen_loss = 0.6065357309399229, disc_loss = 0.010343125795550419
Trained batch 33 in epoch 13, gen_loss = 0.6065072575036217, disc_loss = 0.01030738336746307
Trained batch 34 in epoch 13, gen_loss = 0.6058836306844438, disc_loss = 0.010337233250694616
Trained batch 35 in epoch 13, gen_loss = 0.604855928156111, disc_loss = 0.010141401137742732
Trained batch 36 in epoch 13, gen_loss = 0.6052678356299529, disc_loss = 0.009985869095937626
Trained batch 37 in epoch 13, gen_loss = 0.6042830771521518, disc_loss = 0.009850012101723175
Trained batch 38 in epoch 13, gen_loss = 0.6034199580168113, disc_loss = 0.009711020303746829
Trained batch 39 in epoch 13, gen_loss = 0.6026495188474655, disc_loss = 0.009612974419724196
Trained batch 40 in epoch 13, gen_loss = 0.6037205981045235, disc_loss = 0.009537689717168488
Trained batch 41 in epoch 13, gen_loss = 0.6041379301320939, disc_loss = 0.00946454906703106
Trained batch 42 in epoch 13, gen_loss = 0.6049816941106042, disc_loss = 0.00941563104171046
Trained batch 43 in epoch 13, gen_loss = 0.6049028716304086, disc_loss = 0.009305543911812658
Trained batch 44 in epoch 13, gen_loss = 0.60555409722858, disc_loss = 0.009187193370113771
Trained batch 45 in epoch 13, gen_loss = 0.6052980124950409, disc_loss = 0.009048313879326957
Trained batch 46 in epoch 13, gen_loss = 0.605221559392645, disc_loss = 0.008923318643281435
Trained batch 47 in epoch 13, gen_loss = 0.6044017486274242, disc_loss = 0.009081035047226274
Trained batch 48 in epoch 13, gen_loss = 0.6039545523877047, disc_loss = 0.009186432858434866
Trained batch 49 in epoch 13, gen_loss = 0.6035923981666564, disc_loss = 0.009124114327132702
Trained batch 50 in epoch 13, gen_loss = 0.6036075166627473, disc_loss = 0.00904125921136024
Trained batch 51 in epoch 13, gen_loss = 0.6031988950876089, disc_loss = 0.00894687356104931
Trained batch 52 in epoch 13, gen_loss = 0.6026815614610348, disc_loss = 0.008843981687260687
Trained batch 53 in epoch 13, gen_loss = 0.602988044420878, disc_loss = 0.00875971703445194
Trained batch 54 in epoch 13, gen_loss = 0.603091748194261, disc_loss = 0.008744409705766223
Trained batch 55 in epoch 13, gen_loss = 0.6044471455471856, disc_loss = 0.008895374726437564
Trained batch 56 in epoch 13, gen_loss = 0.6058870888592904, disc_loss = 0.008909122846824559
Trained batch 57 in epoch 13, gen_loss = 0.6063412016835706, disc_loss = 0.008949130797630241
Trained batch 58 in epoch 13, gen_loss = 0.6066701644558018, disc_loss = 0.008888472005788047
Trained batch 59 in epoch 13, gen_loss = 0.6061733812093735, disc_loss = 0.008816078778666754
Trained batch 60 in epoch 13, gen_loss = 0.6065794757155122, disc_loss = 0.008712128247516077
Trained batch 61 in epoch 13, gen_loss = 0.6076289165404535, disc_loss = 0.008708839560107838
Trained batch 62 in epoch 13, gen_loss = 0.6067654755380418, disc_loss = 0.008668822317665059
Trained batch 63 in epoch 13, gen_loss = 0.606361766345799, disc_loss = 0.008596525956818368
Trained batch 64 in epoch 13, gen_loss = 0.6056525725584764, disc_loss = 0.00852105634716841
Trained batch 65 in epoch 13, gen_loss = 0.6055720222718788, disc_loss = 0.008442649317933528
Trained batch 66 in epoch 13, gen_loss = 0.6054290826640912, disc_loss = 0.008351695150442755
Trained batch 67 in epoch 13, gen_loss = 0.605564361985992, disc_loss = 0.00826116609866457
Trained batch 68 in epoch 13, gen_loss = 0.6053369831347811, disc_loss = 0.00818386525793028
Trained batch 69 in epoch 13, gen_loss = 0.6052786324705396, disc_loss = 0.008119568681078299
Trained batch 70 in epoch 13, gen_loss = 0.6050783966628599, disc_loss = 0.008046500781603473
Trained batch 71 in epoch 13, gen_loss = 0.6052295747730467, disc_loss = 0.007966107918441089
Trained batch 72 in epoch 13, gen_loss = 0.6045986079189876, disc_loss = 0.007889710644209017
Trained batch 73 in epoch 13, gen_loss = 0.6044690278736321, disc_loss = 0.007810375955257867
Trained batch 74 in epoch 13, gen_loss = 0.6045425407091777, disc_loss = 0.007746249434227745
Trained batch 75 in epoch 13, gen_loss = 0.603820441584838, disc_loss = 0.007674903170769348
Trained batch 76 in epoch 13, gen_loss = 0.6035190658135847, disc_loss = 0.007604257158281935
Trained batch 77 in epoch 13, gen_loss = 0.6036086548597385, disc_loss = 0.007539770356976451
Trained batch 78 in epoch 13, gen_loss = 0.6035014745555346, disc_loss = 0.007477120475702082
Trained batch 79 in epoch 13, gen_loss = 0.6036049790680409, disc_loss = 0.007435609403182752
Trained batch 80 in epoch 13, gen_loss = 0.6032040398797871, disc_loss = 0.007377058316459075
Trained batch 81 in epoch 13, gen_loss = 0.6028763571890389, disc_loss = 0.007315140064215151
Trained batch 82 in epoch 13, gen_loss = 0.6030825986919632, disc_loss = 0.007251489576490888
Trained batch 83 in epoch 13, gen_loss = 0.6028397140048799, disc_loss = 0.007187205322441601
Trained batch 84 in epoch 13, gen_loss = 0.6027982305077946, disc_loss = 0.00712723416988464
Trained batch 85 in epoch 13, gen_loss = 0.6026851250681766, disc_loss = 0.007068771625284192
Trained batch 86 in epoch 13, gen_loss = 0.6019816748027144, disc_loss = 0.007039539874584853
Trained batch 87 in epoch 13, gen_loss = 0.6013804748654366, disc_loss = 0.006979762219337069
Trained batch 88 in epoch 13, gen_loss = 0.6010353913467922, disc_loss = 0.006939395205274726
Trained batch 89 in epoch 13, gen_loss = 0.6004442632198334, disc_loss = 0.006886738277454343
Trained batch 90 in epoch 13, gen_loss = 0.6004653166938614, disc_loss = 0.006833913513449031
Trained batch 91 in epoch 13, gen_loss = 0.6004773132179094, disc_loss = 0.006784773143210813
Trained batch 92 in epoch 13, gen_loss = 0.600609988294622, disc_loss = 0.00673489370233109
Trained batch 93 in epoch 13, gen_loss = 0.600538081311165, disc_loss = 0.006700688225038825
Trained batch 94 in epoch 13, gen_loss = 0.5998662823124936, disc_loss = 0.006663179926966366
Trained batch 95 in epoch 13, gen_loss = 0.5994594221313795, disc_loss = 0.006654470125795342
Trained batch 96 in epoch 13, gen_loss = 0.5991706245953274, disc_loss = 0.006639384549379963
Trained batch 97 in epoch 13, gen_loss = 0.5994039956404238, disc_loss = 0.0066634641238013095
Trained batch 98 in epoch 13, gen_loss = 0.6002522574530708, disc_loss = 0.006663123305623579
Trained batch 99 in epoch 13, gen_loss = 0.6004140639305114, disc_loss = 0.0066342415241524575
Trained batch 100 in epoch 13, gen_loss = 0.6002946206838777, disc_loss = 0.0065917289207256076
Trained batch 101 in epoch 13, gen_loss = 0.60019652633106, disc_loss = 0.006551439524628222
Trained batch 102 in epoch 13, gen_loss = 0.5998384015074054, disc_loss = 0.006522280281608545
Trained batch 103 in epoch 13, gen_loss = 0.5992647569913131, disc_loss = 0.0064806024176785005
Trained batch 104 in epoch 13, gen_loss = 0.5993282914161682, disc_loss = 0.006438256445385161
Trained batch 105 in epoch 13, gen_loss = 0.5992559886203622, disc_loss = 0.0063980639745252876
Trained batch 106 in epoch 13, gen_loss = 0.5988256145860548, disc_loss = 0.006381781001479548
Trained batch 107 in epoch 13, gen_loss = 0.5984164084549304, disc_loss = 0.006345105486818486
Trained batch 108 in epoch 13, gen_loss = 0.5980063277647036, disc_loss = 0.006313938412541916
Trained batch 109 in epoch 13, gen_loss = 0.5977697578343478, disc_loss = 0.006270946061704308
Trained batch 110 in epoch 13, gen_loss = 0.5970876292065457, disc_loss = 0.0062378825701622145
Trained batch 111 in epoch 13, gen_loss = 0.5968823661761624, disc_loss = 0.006200433366757352
Trained batch 112 in epoch 13, gen_loss = 0.5967581309048475, disc_loss = 0.006160080566820977
Trained batch 113 in epoch 13, gen_loss = 0.5969896342670709, disc_loss = 0.006120835283869191
Trained batch 114 in epoch 13, gen_loss = 0.5964271742364634, disc_loss = 0.006109446339795123
Trained batch 115 in epoch 13, gen_loss = 0.5956963115725024, disc_loss = 0.006075265054623115
Trained batch 116 in epoch 13, gen_loss = 0.5957244649911538, disc_loss = 0.006039285595512861
Trained batch 117 in epoch 13, gen_loss = 0.5952696785078211, disc_loss = 0.006019303611661229
Trained batch 118 in epoch 13, gen_loss = 0.5957383062659192, disc_loss = 0.006001646431875141
Trained batch 119 in epoch 13, gen_loss = 0.5958428497115771, disc_loss = 0.0059839531420342006
Trained batch 120 in epoch 13, gen_loss = 0.5959184790445753, disc_loss = 0.00595427974615985
Trained batch 121 in epoch 13, gen_loss = 0.5959346069664252, disc_loss = 0.0059281586026238495
Trained batch 122 in epoch 13, gen_loss = 0.5955481863603359, disc_loss = 0.005900634107240513
Trained batch 123 in epoch 13, gen_loss = 0.5952769638069214, disc_loss = 0.005876509220181634
Trained batch 124 in epoch 13, gen_loss = 0.595056743144989, disc_loss = 0.005896074700169265
Trained batch 125 in epoch 13, gen_loss = 0.5956103967295753, disc_loss = 0.005944000456356517
Trained batch 126 in epoch 13, gen_loss = 0.5961110915724687, disc_loss = 0.005940132718496611
Trained batch 127 in epoch 13, gen_loss = 0.5961252432316542, disc_loss = 0.0059150443548787734
Trained batch 128 in epoch 13, gen_loss = 0.5963534865268442, disc_loss = 0.0058980513474174824
Trained batch 129 in epoch 13, gen_loss = 0.5962527366784903, disc_loss = 0.005873176334604907
Trained batch 130 in epoch 13, gen_loss = 0.5958941469665702, disc_loss = 0.005847790864125633
Trained batch 131 in epoch 13, gen_loss = 0.5954509336840023, disc_loss = 0.005822722896206842
Trained batch 132 in epoch 13, gen_loss = 0.5953508001521117, disc_loss = 0.005792092865409988
Trained batch 133 in epoch 13, gen_loss = 0.59476322113578, disc_loss = 0.005766214852381164
Trained batch 134 in epoch 13, gen_loss = 0.595073726883641, disc_loss = 0.005737060304144742
Trained batch 135 in epoch 13, gen_loss = 0.5952317995183608, disc_loss = 0.005711909475126851
Trained batch 136 in epoch 13, gen_loss = 0.5952070055216768, disc_loss = 0.005684026376765738
Trained batch 137 in epoch 13, gen_loss = 0.5950248794279237, disc_loss = 0.0056576062528672965
Trained batch 138 in epoch 13, gen_loss = 0.5951019954338348, disc_loss = 0.005633447581413035
Trained batch 139 in epoch 13, gen_loss = 0.5946302141462053, disc_loss = 0.005740266580167892
Trained batch 140 in epoch 13, gen_loss = 0.5952233807414982, disc_loss = 0.005769044273955655
Trained batch 141 in epoch 13, gen_loss = 0.5961690977425642, disc_loss = 0.005801108804314961
Trained batch 142 in epoch 13, gen_loss = 0.5965602927274637, disc_loss = 0.005786896224941251
Trained batch 143 in epoch 13, gen_loss = 0.5965388371712632, disc_loss = 0.00576549869098623
Trained batch 144 in epoch 13, gen_loss = 0.5965983448357418, disc_loss = 0.005753063597587933
Trained batch 145 in epoch 13, gen_loss = 0.5964020037487762, disc_loss = 0.005736816917667293
Trained batch 146 in epoch 13, gen_loss = 0.5963749508468472, disc_loss = 0.00574168644063048
Trained batch 147 in epoch 13, gen_loss = 0.5966562238093969, disc_loss = 0.005719394107644975
Trained batch 148 in epoch 13, gen_loss = 0.5967599781567618, disc_loss = 0.005692811317948137
Trained batch 149 in epoch 13, gen_loss = 0.5968616505463918, disc_loss = 0.00566732637428989
Trained batch 150 in epoch 13, gen_loss = 0.5967855946907145, disc_loss = 0.005638718016797196
Trained batch 151 in epoch 13, gen_loss = 0.5964467968595656, disc_loss = 0.005611267542821895
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.5578453540802002, disc_loss = 0.0026581331621855497
Trained batch 1 in epoch 14, gen_loss = 0.5655612945556641, disc_loss = 0.0019608515431173146
Trained batch 2 in epoch 14, gen_loss = 0.5732277631759644, disc_loss = 0.0018069274180258315
Trained batch 3 in epoch 14, gen_loss = 0.5661913454532623, disc_loss = 0.001653851184528321
Trained batch 4 in epoch 14, gen_loss = 0.5626888275146484, disc_loss = 0.0016062926501035691
Trained batch 5 in epoch 14, gen_loss = 0.5738135576248169, disc_loss = 0.0015904901471609871
Trained batch 6 in epoch 14, gen_loss = 0.5701817274093628, disc_loss = 0.0015795096322628005
Trained batch 7 in epoch 14, gen_loss = 0.5737979039549828, disc_loss = 0.0015885882748989388
Trained batch 8 in epoch 14, gen_loss = 0.5677540765868293, disc_loss = 0.0018489639041945338
Trained batch 9 in epoch 14, gen_loss = 0.564889794588089, disc_loss = 0.0018183955224230885
Trained batch 10 in epoch 14, gen_loss = 0.5615855076096274, disc_loss = 0.0018451646690002897
Trained batch 11 in epoch 14, gen_loss = 0.5641978730758032, disc_loss = 0.0018537185969762504
Trained batch 12 in epoch 14, gen_loss = 0.5658031702041626, disc_loss = 0.0018253334744188648
Trained batch 13 in epoch 14, gen_loss = 0.5685725467545646, disc_loss = 0.0017902478076783673
Trained batch 14 in epoch 14, gen_loss = 0.567889662583669, disc_loss = 0.00188765749335289
Trained batch 15 in epoch 14, gen_loss = 0.5671963132917881, disc_loss = 0.0019023384666070342
Trained batch 16 in epoch 14, gen_loss = 0.5700094664798063, disc_loss = 0.001889962504398735
Trained batch 17 in epoch 14, gen_loss = 0.5714903838104672, disc_loss = 0.0018744730558763775
Trained batch 18 in epoch 14, gen_loss = 0.5723883415523329, disc_loss = 0.0018449550261721015
Trained batch 19 in epoch 14, gen_loss = 0.5729194134473801, disc_loss = 0.00182110785972327
Trained batch 20 in epoch 14, gen_loss = 0.5715751165435428, disc_loss = 0.0017943153645665873
Trained batch 21 in epoch 14, gen_loss = 0.5739207213575189, disc_loss = 0.0017746733184057202
Trained batch 22 in epoch 14, gen_loss = 0.5746274227681367, disc_loss = 0.0017555247911292574
Trained batch 23 in epoch 14, gen_loss = 0.572817807396253, disc_loss = 0.0017491406373058755
Trained batch 24 in epoch 14, gen_loss = 0.5728023290634155, disc_loss = 0.001723199924454093
Trained batch 25 in epoch 14, gen_loss = 0.5723338172985957, disc_loss = 0.0017056868662341284
Trained batch 26 in epoch 14, gen_loss = 0.5726184293075844, disc_loss = 0.0017041710153636006
Trained batch 27 in epoch 14, gen_loss = 0.5724542077098574, disc_loss = 0.0016937408030831388
Trained batch 28 in epoch 14, gen_loss = 0.5748384718237252, disc_loss = 0.001735604809725593
Trained batch 29 in epoch 14, gen_loss = 0.5743515968322754, disc_loss = 0.0017284205183386802
Trained batch 30 in epoch 14, gen_loss = 0.5762462289102616, disc_loss = 0.0017163515346305025
Trained batch 31 in epoch 14, gen_loss = 0.5760885421186686, disc_loss = 0.0017167432670248672
Trained batch 32 in epoch 14, gen_loss = 0.5753547368627606, disc_loss = 0.0017041849840263074
Trained batch 33 in epoch 14, gen_loss = 0.5743399034528172, disc_loss = 0.0017000911551911164
Trained batch 34 in epoch 14, gen_loss = 0.5735014149120876, disc_loss = 0.0017161727683352574
Trained batch 35 in epoch 14, gen_loss = 0.5749050279458364, disc_loss = 0.0017579702220650183
Trained batch 36 in epoch 14, gen_loss = 0.5752713068111522, disc_loss = 0.001788598025922437
Trained batch 37 in epoch 14, gen_loss = 0.576932640452134, disc_loss = 0.0017820528500076187
Trained batch 38 in epoch 14, gen_loss = 0.5780777992346348, disc_loss = 0.001795651886659937
Trained batch 39 in epoch 14, gen_loss = 0.5778673812747002, disc_loss = 0.0017902232008054852
Trained batch 40 in epoch 14, gen_loss = 0.5773377985489078, disc_loss = 0.0019597612185085693
Trained batch 41 in epoch 14, gen_loss = 0.5761812258334387, disc_loss = 0.002156540197098539
Trained batch 42 in epoch 14, gen_loss = 0.5785676767659742, disc_loss = 0.0023696718217675076
Trained batch 43 in epoch 14, gen_loss = 0.5812364383177324, disc_loss = 0.0027460727459666405
Trained batch 44 in epoch 14, gen_loss = 0.582186946603987, disc_loss = 0.0027330181768371
Trained batch 45 in epoch 14, gen_loss = 0.5825439354647761, disc_loss = 0.0027437320222025332
Trained batch 46 in epoch 14, gen_loss = 0.5828004035543888, disc_loss = 0.002744486922041533
Trained batch 47 in epoch 14, gen_loss = 0.5830026939511299, disc_loss = 0.0027471558617738387
Trained batch 48 in epoch 14, gen_loss = 0.5828180471245124, disc_loss = 0.0027284003076694756
Trained batch 49 in epoch 14, gen_loss = 0.5837279498577118, disc_loss = 0.0027305052266456188
Trained batch 50 in epoch 14, gen_loss = 0.5838323586127337, disc_loss = 0.0027156779884963352
Trained batch 51 in epoch 14, gen_loss = 0.5845228238747671, disc_loss = 0.0026969415955066392
Trained batch 52 in epoch 14, gen_loss = 0.5849198957659164, disc_loss = 0.002679768543391717
Trained batch 53 in epoch 14, gen_loss = 0.5862509586192943, disc_loss = 0.002670723429656829
Trained batch 54 in epoch 14, gen_loss = 0.5861653392965144, disc_loss = 0.002646398973989893
Trained batch 55 in epoch 14, gen_loss = 0.5855362447244781, disc_loss = 0.00263557796591028
Trained batch 56 in epoch 14, gen_loss = 0.5855020117341426, disc_loss = 0.0026196480071041407
Trained batch 57 in epoch 14, gen_loss = 0.5853820535643347, disc_loss = 0.002595104732759425
Trained batch 58 in epoch 14, gen_loss = 0.5852958640809787, disc_loss = 0.0025708268562300227
Trained batch 59 in epoch 14, gen_loss = 0.5848628590504329, disc_loss = 0.0025590407312847674
Trained batch 60 in epoch 14, gen_loss = 0.5846131571003648, disc_loss = 0.002542356334504534
Trained batch 61 in epoch 14, gen_loss = 0.584668917040671, disc_loss = 0.0025204112941038703
Trained batch 62 in epoch 14, gen_loss = 0.5837871384999108, disc_loss = 0.0025019305296212673
Trained batch 63 in epoch 14, gen_loss = 0.5843965904787183, disc_loss = 0.002510707172405091
Trained batch 64 in epoch 14, gen_loss = 0.5845769616273734, disc_loss = 0.0024942663587773075
Trained batch 65 in epoch 14, gen_loss = 0.5848963251619628, disc_loss = 0.002479819714966597
Trained batch 66 in epoch 14, gen_loss = 0.5853160806556246, disc_loss = 0.0024735200211906164
Trained batch 67 in epoch 14, gen_loss = 0.5855850305627374, disc_loss = 0.002462562670082073
Trained batch 68 in epoch 14, gen_loss = 0.5852193340011265, disc_loss = 0.0024440303255898366
Trained batch 69 in epoch 14, gen_loss = 0.5848057755402156, disc_loss = 0.00245767836458981
Trained batch 70 in epoch 14, gen_loss = 0.584349940360432, disc_loss = 0.002441022486071771
Trained batch 71 in epoch 14, gen_loss = 0.5837646308872435, disc_loss = 0.002427468862151727
Trained batch 72 in epoch 14, gen_loss = 0.5833354608653343, disc_loss = 0.0024386718295106333
Trained batch 73 in epoch 14, gen_loss = 0.5834146601122778, disc_loss = 0.0024396858549349614
Trained batch 74 in epoch 14, gen_loss = 0.584084198474884, disc_loss = 0.0024539320978025597
Trained batch 75 in epoch 14, gen_loss = 0.5844467972454271, disc_loss = 0.0024406993194899863
Trained batch 76 in epoch 14, gen_loss = 0.5840196617237934, disc_loss = 0.0024313809056826807
Trained batch 77 in epoch 14, gen_loss = 0.5843069545733623, disc_loss = 0.0024205387856524726
Trained batch 78 in epoch 14, gen_loss = 0.584664320643944, disc_loss = 0.0024056923384129813
Trained batch 79 in epoch 14, gen_loss = 0.5844361983239651, disc_loss = 0.002391650433128234
Trained batch 80 in epoch 14, gen_loss = 0.5846070058551835, disc_loss = 0.0023913219625728184
Trained batch 81 in epoch 14, gen_loss = 0.5840815901756287, disc_loss = 0.002377565705967022
Trained batch 82 in epoch 14, gen_loss = 0.5841368616345417, disc_loss = 0.002367508519126708
Trained batch 83 in epoch 14, gen_loss = 0.583794612969671, disc_loss = 0.0023574080246145882
Trained batch 84 in epoch 14, gen_loss = 0.5835837385233711, disc_loss = 0.0023438955931102527
Trained batch 85 in epoch 14, gen_loss = 0.5830150877320489, disc_loss = 0.002332162290681587
Trained batch 86 in epoch 14, gen_loss = 0.583531531109207, disc_loss = 0.002328761181547895
Trained batch 87 in epoch 14, gen_loss = 0.5832945467396216, disc_loss = 0.0023287726640277965
Trained batch 88 in epoch 14, gen_loss = 0.5830378793598561, disc_loss = 0.0023259102141882262
Trained batch 89 in epoch 14, gen_loss = 0.5828470759921603, disc_loss = 0.0023146808949402638
Trained batch 90 in epoch 14, gen_loss = 0.5825146934488318, disc_loss = 0.0023073031270242
Trained batch 91 in epoch 14, gen_loss = 0.5828692686298619, disc_loss = 0.0023046579065165765
Trained batch 92 in epoch 14, gen_loss = 0.5827293883087814, disc_loss = 0.0022908102080065715
Trained batch 93 in epoch 14, gen_loss = 0.5826532587091974, disc_loss = 0.002281592154449367
Trained batch 94 in epoch 14, gen_loss = 0.5827203041628788, disc_loss = 0.0022685427966184523
Trained batch 95 in epoch 14, gen_loss = 0.5824326854199171, disc_loss = 0.0022578438050307645
Trained batch 96 in epoch 14, gen_loss = 0.582768162501227, disc_loss = 0.002248366807405021
Trained batch 97 in epoch 14, gen_loss = 0.5834107143538338, disc_loss = 0.0022501539871362703
Trained batch 98 in epoch 14, gen_loss = 0.5836691296461857, disc_loss = 0.0022416456750678744
Trained batch 99 in epoch 14, gen_loss = 0.5837349706888199, disc_loss = 0.00224100019200705
Trained batch 100 in epoch 14, gen_loss = 0.5838631828232567, disc_loss = 0.0022357627530443934
Trained batch 101 in epoch 14, gen_loss = 0.5842583378156027, disc_loss = 0.0022258913480019305
Trained batch 102 in epoch 14, gen_loss = 0.5840868209172221, disc_loss = 0.0022142072687449965
Trained batch 103 in epoch 14, gen_loss = 0.5840821793446174, disc_loss = 0.0022043155197304888
Trained batch 104 in epoch 14, gen_loss = 0.5836321200643267, disc_loss = 0.0022100407319764295
Trained batch 105 in epoch 14, gen_loss = 0.5836710800539773, disc_loss = 0.002202123787939408
Trained batch 106 in epoch 14, gen_loss = 0.5839722847270075, disc_loss = 0.0021973564463589235
Trained batch 107 in epoch 14, gen_loss = 0.5841087500254313, disc_loss = 0.0021888728995152094
Trained batch 108 in epoch 14, gen_loss = 0.5837891353379696, disc_loss = 0.0021812189242230097
Trained batch 109 in epoch 14, gen_loss = 0.5838925751772794, disc_loss = 0.002172585206360302
Trained batch 110 in epoch 14, gen_loss = 0.5839128666095905, disc_loss = 0.0021691256462856457
Trained batch 111 in epoch 14, gen_loss = 0.5839118638208934, disc_loss = 0.0021657507251282887
Trained batch 112 in epoch 14, gen_loss = 0.5835974886354092, disc_loss = 0.0021565404320877473
Trained batch 113 in epoch 14, gen_loss = 0.5838243841079244, disc_loss = 0.002148984749638067
Trained batch 114 in epoch 14, gen_loss = 0.5843289007311282, disc_loss = 0.002144428988432755
Trained batch 115 in epoch 14, gen_loss = 0.5842797149871958, disc_loss = 0.0021363587142771176
Trained batch 116 in epoch 14, gen_loss = 0.584109985930288, disc_loss = 0.002127019427796332
Trained batch 117 in epoch 14, gen_loss = 0.5838733027547093, disc_loss = 0.0021206968793471867
Trained batch 118 in epoch 14, gen_loss = 0.5840844832548574, disc_loss = 0.0021138515640363223
Trained batch 119 in epoch 14, gen_loss = 0.5844184542695682, disc_loss = 0.0021084569627419112
Trained batch 120 in epoch 14, gen_loss = 0.5848615115339105, disc_loss = 0.002106288949235473
Trained batch 121 in epoch 14, gen_loss = 0.5846390729067755, disc_loss = 0.0021007500892337105
Trained batch 122 in epoch 14, gen_loss = 0.5847046210513851, disc_loss = 0.0020952492865271926
Trained batch 123 in epoch 14, gen_loss = 0.584835599507055, disc_loss = 0.0020882970655352
Trained batch 124 in epoch 14, gen_loss = 0.5846541028022766, disc_loss = 0.0020857911901548507
Trained batch 125 in epoch 14, gen_loss = 0.584748722731121, disc_loss = 0.0020807913868569785
Trained batch 126 in epoch 14, gen_loss = 0.5847967454767603, disc_loss = 0.002072506082816211
Trained batch 127 in epoch 14, gen_loss = 0.5845916750840843, disc_loss = 0.002066107058453781
Trained batch 128 in epoch 14, gen_loss = 0.5844426667967508, disc_loss = 0.0020607836145633295
Trained batch 129 in epoch 14, gen_loss = 0.5843910368589255, disc_loss = 0.0020533117474629903
Trained batch 130 in epoch 14, gen_loss = 0.5842965054148026, disc_loss = 0.002046417340970392
Trained batch 131 in epoch 14, gen_loss = 0.5840815644372593, disc_loss = 0.002038881997577846
Trained batch 132 in epoch 14, gen_loss = 0.5839618798485375, disc_loss = 0.0020306328280051624
Trained batch 133 in epoch 14, gen_loss = 0.5839775556059026, disc_loss = 0.002022181534201407
Trained batch 134 in epoch 14, gen_loss = 0.5842058367199368, disc_loss = 0.002015432183354817
Trained batch 135 in epoch 14, gen_loss = 0.5844376648173613, disc_loss = 0.0020099490040379085
Trained batch 136 in epoch 14, gen_loss = 0.5844334912126081, disc_loss = 0.0020041684637077317
Trained batch 137 in epoch 14, gen_loss = 0.5843346378077632, disc_loss = 0.001996740201940301
Trained batch 138 in epoch 14, gen_loss = 0.5841628454572005, disc_loss = 0.0019891535027435035
Trained batch 139 in epoch 14, gen_loss = 0.5843352841479438, disc_loss = 0.001982431784771117
Trained batch 140 in epoch 14, gen_loss = 0.5842939534931318, disc_loss = 0.001977433299427812
Trained batch 141 in epoch 14, gen_loss = 0.5839639679646828, disc_loss = 0.0019712885046495833
Trained batch 142 in epoch 14, gen_loss = 0.5837649723866603, disc_loss = 0.0019685287220677088
Trained batch 143 in epoch 14, gen_loss = 0.5838745199143887, disc_loss = 0.0019644204399406184
Trained batch 144 in epoch 14, gen_loss = 0.5841546342290681, disc_loss = 0.0019633988841790064
Trained batch 145 in epoch 14, gen_loss = 0.5840362020551342, disc_loss = 0.001957877726479089
Trained batch 146 in epoch 14, gen_loss = 0.5838870162866554, disc_loss = 0.0019514557856394827
Trained batch 147 in epoch 14, gen_loss = 0.5837129302121498, disc_loss = 0.0019445607440256689
Trained batch 148 in epoch 14, gen_loss = 0.5834005443041757, disc_loss = 0.0019404167018755771
Trained batch 149 in epoch 14, gen_loss = 0.5834222809473674, disc_loss = 0.0019352213533905644
Trained batch 150 in epoch 14, gen_loss = 0.583473017278886, disc_loss = 0.0019306640058990247
Trained batch 151 in epoch 14, gen_loss = 0.5833338103012035, disc_loss = 0.0019253078108273545
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.5874567031860352, disc_loss = 0.0012206153478473425
Trained batch 1 in epoch 15, gen_loss = 0.5708969235420227, disc_loss = 0.0010651639895513654
Trained batch 2 in epoch 15, gen_loss = 0.5749603708585104, disc_loss = 0.0010078032112990816
Trained batch 3 in epoch 15, gen_loss = 0.5761340409517288, disc_loss = 0.001286939048441127
Trained batch 4 in epoch 15, gen_loss = 0.5761913776397705, disc_loss = 0.0012374802958220244
Trained batch 5 in epoch 15, gen_loss = 0.5764395296573639, disc_loss = 0.0012095119842949014
Trained batch 6 in epoch 15, gen_loss = 0.579823911190033, disc_loss = 0.001200366033507245
Trained batch 7 in epoch 15, gen_loss = 0.5883737280964851, disc_loss = 0.0012402060820022598
Trained batch 8 in epoch 15, gen_loss = 0.5861802630954318, disc_loss = 0.0012038125423714519
Trained batch 9 in epoch 15, gen_loss = 0.5800595998764038, disc_loss = 0.0011965156998485326
Trained batch 10 in epoch 15, gen_loss = 0.5801058140668002, disc_loss = 0.0012842122338373554
Trained batch 11 in epoch 15, gen_loss = 0.5805234064658483, disc_loss = 0.0013049810465114813
Trained batch 12 in epoch 15, gen_loss = 0.5826765619791471, disc_loss = 0.0012891168186727625
Trained batch 13 in epoch 15, gen_loss = 0.5847431463854653, disc_loss = 0.0012815079452203853
Trained batch 14 in epoch 15, gen_loss = 0.5837555925051371, disc_loss = 0.0012895316040764252
Trained batch 15 in epoch 15, gen_loss = 0.5856902599334717, disc_loss = 0.0013069395208731294
Trained batch 16 in epoch 15, gen_loss = 0.5855289697647095, disc_loss = 0.0013308740111396594
Trained batch 17 in epoch 15, gen_loss = 0.5836871200137668, disc_loss = 0.001314217664508356
Trained batch 18 in epoch 15, gen_loss = 0.5845138932529249, disc_loss = 0.0013030343321397116
Trained batch 19 in epoch 15, gen_loss = 0.583872202038765, disc_loss = 0.0012934566708281635
Trained batch 20 in epoch 15, gen_loss = 0.5849098506427947, disc_loss = 0.0012819475571935375
Trained batch 21 in epoch 15, gen_loss = 0.5834901955994692, disc_loss = 0.0012689342627047815
Trained batch 22 in epoch 15, gen_loss = 0.5836714635724607, disc_loss = 0.001251957300827717
Trained batch 23 in epoch 15, gen_loss = 0.5828990116715431, disc_loss = 0.0012379603940644301
Trained batch 24 in epoch 15, gen_loss = 0.5835712265968322, disc_loss = 0.0012640625913627446
Trained batch 25 in epoch 15, gen_loss = 0.5843069576300107, disc_loss = 0.0012539483745618223
Trained batch 26 in epoch 15, gen_loss = 0.5848577839356882, disc_loss = 0.0012448124514237323
Trained batch 27 in epoch 15, gen_loss = 0.5854009879486901, disc_loss = 0.0012383242491133778
Trained batch 28 in epoch 15, gen_loss = 0.5851399549122515, disc_loss = 0.001230815186663049
Trained batch 29 in epoch 15, gen_loss = 0.5857431610425313, disc_loss = 0.0012287550974482049
Trained batch 30 in epoch 15, gen_loss = 0.5869365949784556, disc_loss = 0.0012256874263496889
Trained batch 31 in epoch 15, gen_loss = 0.5869758054614067, disc_loss = 0.001238830371221411
Trained batch 32 in epoch 15, gen_loss = 0.5883191372409011, disc_loss = 0.0012344949028567608
Trained batch 33 in epoch 15, gen_loss = 0.5888662671341616, disc_loss = 0.0012479664480505401
Trained batch 34 in epoch 15, gen_loss = 0.5888043114117214, disc_loss = 0.001242488092144153
Trained batch 35 in epoch 15, gen_loss = 0.5886711031198502, disc_loss = 0.001234635654125466
Trained batch 36 in epoch 15, gen_loss = 0.5887192970997578, disc_loss = 0.0012259021247233693
Trained batch 37 in epoch 15, gen_loss = 0.5892991894169858, disc_loss = 0.0012222464842795346
Trained batch 38 in epoch 15, gen_loss = 0.5892733580026871, disc_loss = 0.001223303253750484
Trained batch 39 in epoch 15, gen_loss = 0.5891584143042564, disc_loss = 0.001219307330029551
Trained batch 40 in epoch 15, gen_loss = 0.5888990861613576, disc_loss = 0.001212402421515435
Trained batch 41 in epoch 15, gen_loss = 0.5881052272660392, disc_loss = 0.0012108437048958703
Trained batch 42 in epoch 15, gen_loss = 0.588407157465469, disc_loss = 0.0012240176573720609
Trained batch 43 in epoch 15, gen_loss = 0.5879528373479843, disc_loss = 0.001230403922487643
Trained batch 44 in epoch 15, gen_loss = 0.5870542393790351, disc_loss = 0.0012330428244442576
Trained batch 45 in epoch 15, gen_loss = 0.5869057904119077, disc_loss = 0.0012290560167141098
Trained batch 46 in epoch 15, gen_loss = 0.5867773395903567, disc_loss = 0.0012301044437063344
Trained batch 47 in epoch 15, gen_loss = 0.5864590058724085, disc_loss = 0.0012249634928593878
Trained batch 48 in epoch 15, gen_loss = 0.5867179826814302, disc_loss = 0.0012244118284909244
Trained batch 49 in epoch 15, gen_loss = 0.5862292695045471, disc_loss = 0.0012183839711360632
Trained batch 50 in epoch 15, gen_loss = 0.5856597680671543, disc_loss = 0.0012117688356916986
Trained batch 51 in epoch 15, gen_loss = 0.5852541785973769, disc_loss = 0.0012042458357217794
Trained batch 52 in epoch 15, gen_loss = 0.5853318020982562, disc_loss = 0.0012017002698244913
Trained batch 53 in epoch 15, gen_loss = 0.5851342082023621, disc_loss = 0.0012010631358457936
Trained batch 54 in epoch 15, gen_loss = 0.5852328343824906, disc_loss = 0.0012006809723309495
Trained batch 55 in epoch 15, gen_loss = 0.5853047519922256, disc_loss = 0.001199264220693814
Trained batch 56 in epoch 15, gen_loss = 0.5849292110978511, disc_loss = 0.0011928921888108577
Trained batch 57 in epoch 15, gen_loss = 0.584874728630329, disc_loss = 0.0011950770537529525
Trained batch 58 in epoch 15, gen_loss = 0.5852577039750956, disc_loss = 0.0012051358373077997
Trained batch 59 in epoch 15, gen_loss = 0.5852655380964279, disc_loss = 0.0012053018377628177
Trained batch 60 in epoch 15, gen_loss = 0.5862339871828673, disc_loss = 0.00120416768544094
Trained batch 61 in epoch 15, gen_loss = 0.586074331114369, disc_loss = 0.0012102786981080089
Trained batch 62 in epoch 15, gen_loss = 0.5860146189492846, disc_loss = 0.0012088446704197734
Trained batch 63 in epoch 15, gen_loss = 0.5861329194158316, disc_loss = 0.0012068258747603977
Trained batch 64 in epoch 15, gen_loss = 0.5858435163131127, disc_loss = 0.0012024280668881076
Trained batch 65 in epoch 15, gen_loss = 0.586813309879014, disc_loss = 0.0012086904695906649
Trained batch 66 in epoch 15, gen_loss = 0.5866331013280954, disc_loss = 0.0012063251151494792
Trained batch 67 in epoch 15, gen_loss = 0.5866173567140803, disc_loss = 0.0012042919731945457
Trained batch 68 in epoch 15, gen_loss = 0.5867773294448853, disc_loss = 0.0012119752540509553
Trained batch 69 in epoch 15, gen_loss = 0.587010326555797, disc_loss = 0.0012132018937596252
Trained batch 70 in epoch 15, gen_loss = 0.5874500576878937, disc_loss = 0.0012103698222937298
Trained batch 71 in epoch 15, gen_loss = 0.587919768359926, disc_loss = 0.001211603791388269
Trained batch 72 in epoch 15, gen_loss = 0.5883871855801099, disc_loss = 0.001207572344231279
Trained batch 73 in epoch 15, gen_loss = 0.5889540008596472, disc_loss = 0.0012030802302163196
Trained batch 74 in epoch 15, gen_loss = 0.5897305504480997, disc_loss = 0.0012048596267898878
Trained batch 75 in epoch 15, gen_loss = 0.58973386570027, disc_loss = 0.001206101160373931
Trained batch 76 in epoch 15, gen_loss = 0.589729512666727, disc_loss = 0.0012034731100664124
Trained batch 77 in epoch 15, gen_loss = 0.5894102354844412, disc_loss = 0.0011988287278188344
Trained batch 78 in epoch 15, gen_loss = 0.5894724190989628, disc_loss = 0.0012003024774780379
Trained batch 79 in epoch 15, gen_loss = 0.5894092082977295, disc_loss = 0.001197048918402288
Trained batch 80 in epoch 15, gen_loss = 0.5894626261275492, disc_loss = 0.0011971812381949506
Trained batch 81 in epoch 15, gen_loss = 0.5899471197186447, disc_loss = 0.0011959972481879338
Trained batch 82 in epoch 15, gen_loss = 0.5902331378086504, disc_loss = 0.001195652863425932
Trained batch 83 in epoch 15, gen_loss = 0.5903217033261344, disc_loss = 0.0011942681878627766
Trained batch 84 in epoch 15, gen_loss = 0.5907213197034948, disc_loss = 0.0011971314656822121
Trained batch 85 in epoch 15, gen_loss = 0.5909669551738473, disc_loss = 0.0011968353700954034
Trained batch 86 in epoch 15, gen_loss = 0.590828352961047, disc_loss = 0.0011942534053152234
Trained batch 87 in epoch 15, gen_loss = 0.5907676646655257, disc_loss = 0.0011920847642944534
Trained batch 88 in epoch 15, gen_loss = 0.5907745019773419, disc_loss = 0.001189981842952456
Trained batch 89 in epoch 15, gen_loss = 0.5908789429399702, disc_loss = 0.001188107491341523
Trained batch 90 in epoch 15, gen_loss = 0.5910357498860621, disc_loss = 0.001186573217177743
Trained batch 91 in epoch 15, gen_loss = 0.5909465655036594, disc_loss = 0.0011855656902417136
Trained batch 92 in epoch 15, gen_loss = 0.5911150709275277, disc_loss = 0.0011858461238193497
Trained batch 93 in epoch 15, gen_loss = 0.5914522016302068, disc_loss = 0.0011869376405152156
Trained batch 94 in epoch 15, gen_loss = 0.5913859994787919, disc_loss = 0.0011903624546616093
Trained batch 95 in epoch 15, gen_loss = 0.5908927240719398, disc_loss = 0.0011920984064393754
Trained batch 96 in epoch 15, gen_loss = 0.5905967170430213, disc_loss = 0.0011920085322044637
Trained batch 97 in epoch 15, gen_loss = 0.5906312739362523, disc_loss = 0.0011899444834110613
Trained batch 98 in epoch 15, gen_loss = 0.5908742444683807, disc_loss = 0.0011912216367717418
Trained batch 99 in epoch 15, gen_loss = 0.5913648891448975, disc_loss = 0.0011936808220343665
Trained batch 100 in epoch 15, gen_loss = 0.5913800632599557, disc_loss = 0.0011930263717658818
Trained batch 101 in epoch 15, gen_loss = 0.5912225199680702, disc_loss = 0.0011919526612687418
Trained batch 102 in epoch 15, gen_loss = 0.5910265451496087, disc_loss = 0.001188887901450462
Trained batch 103 in epoch 15, gen_loss = 0.5915162104826707, disc_loss = 0.001188706730877479
Trained batch 104 in epoch 15, gen_loss = 0.5918030301729839, disc_loss = 0.001190112802820901
Trained batch 105 in epoch 15, gen_loss = 0.5918453245792749, disc_loss = 0.0011915588446119625
Trained batch 106 in epoch 15, gen_loss = 0.5922515286463443, disc_loss = 0.0011930988631515859
Trained batch 107 in epoch 15, gen_loss = 0.5924505343039831, disc_loss = 0.00119236432429817
Trained batch 108 in epoch 15, gen_loss = 0.5926533357812724, disc_loss = 0.0011900569875126516
Trained batch 109 in epoch 15, gen_loss = 0.5925393906506625, disc_loss = 0.0011875586155590348
Trained batch 110 in epoch 15, gen_loss = 0.5924336738414593, disc_loss = 0.001184436533000186
Trained batch 111 in epoch 15, gen_loss = 0.5923553630709648, disc_loss = 0.0011848334704284622
Trained batch 112 in epoch 15, gen_loss = 0.5923658118838757, disc_loss = 0.0011824646916248696
Trained batch 113 in epoch 15, gen_loss = 0.5921954747877622, disc_loss = 0.0011821989007825195
Trained batch 114 in epoch 15, gen_loss = 0.5927807372549306, disc_loss = 0.001186679559253642
Trained batch 115 in epoch 15, gen_loss = 0.5929783372015789, disc_loss = 0.0011883592017292012
Trained batch 116 in epoch 15, gen_loss = 0.5928268101480272, disc_loss = 0.0011877145197314138
Trained batch 117 in epoch 15, gen_loss = 0.593020731614808, disc_loss = 0.001186692473080041
Trained batch 118 in epoch 15, gen_loss = 0.593139005809271, disc_loss = 0.0011873384472960997
Trained batch 119 in epoch 15, gen_loss = 0.5930456086993218, disc_loss = 0.0011939184570413394
Trained batch 120 in epoch 15, gen_loss = 0.593215116291992, disc_loss = 0.0011927556195527253
Trained batch 121 in epoch 15, gen_loss = 0.5929898458426116, disc_loss = 0.0011928954918403178
Trained batch 122 in epoch 15, gen_loss = 0.5927446978848155, disc_loss = 0.0011919189516144495
Trained batch 123 in epoch 15, gen_loss = 0.5930698398620852, disc_loss = 0.0011949990289248226
Trained batch 124 in epoch 15, gen_loss = 0.5933980360031128, disc_loss = 0.0011935246805660426
Trained batch 125 in epoch 15, gen_loss = 0.5937103383124821, disc_loss = 0.0011943692534548483
Trained batch 126 in epoch 15, gen_loss = 0.5935704623620341, disc_loss = 0.0011925876519173443
Trained batch 127 in epoch 15, gen_loss = 0.5935296770185232, disc_loss = 0.0011937477825085807
Trained batch 128 in epoch 15, gen_loss = 0.5936744120693946, disc_loss = 0.001192939802986216
Trained batch 129 in epoch 15, gen_loss = 0.5936847182420584, disc_loss = 0.001191365338700752
Trained batch 130 in epoch 15, gen_loss = 0.5938057203329247, disc_loss = 0.0011898185937836026
Trained batch 131 in epoch 15, gen_loss = 0.5936449626178453, disc_loss = 0.001188797088230565
Trained batch 132 in epoch 15, gen_loss = 0.5934542852236813, disc_loss = 0.0011898043387765555
Trained batch 133 in epoch 15, gen_loss = 0.59317687598627, disc_loss = 0.001186964904833863
Trained batch 134 in epoch 15, gen_loss = 0.5931633803579542, disc_loss = 0.0011958108352566207
Trained batch 135 in epoch 15, gen_loss = 0.5932126873556305, disc_loss = 0.0011990425195750397
Trained batch 136 in epoch 15, gen_loss = 0.5936514304502167, disc_loss = 0.0012045709754469512
Trained batch 137 in epoch 15, gen_loss = 0.59349743179653, disc_loss = 0.0012043753134397168
Trained batch 138 in epoch 15, gen_loss = 0.5935356934293569, disc_loss = 0.001208434965153285
Trained batch 139 in epoch 15, gen_loss = 0.5934394768306187, disc_loss = 0.00120773360000125
Trained batch 140 in epoch 15, gen_loss = 0.5932662596939303, disc_loss = 0.0012091707689225251
Trained batch 141 in epoch 15, gen_loss = 0.5932652920904294, disc_loss = 0.00120678084941817
Trained batch 142 in epoch 15, gen_loss = 0.5935391546129347, disc_loss = 0.001205071914367951
Trained batch 143 in epoch 15, gen_loss = 0.5937849941353003, disc_loss = 0.0012036508043012065
Trained batch 144 in epoch 15, gen_loss = 0.5936217402589732, disc_loss = 0.0012022773687053344
Trained batch 145 in epoch 15, gen_loss = 0.593598095113284, disc_loss = 0.0012020723900617394
Trained batch 146 in epoch 15, gen_loss = 0.5939125414608287, disc_loss = 0.001201370955115425
Trained batch 147 in epoch 15, gen_loss = 0.593891091846131, disc_loss = 0.0012005915805521246
Trained batch 148 in epoch 15, gen_loss = 0.5936973322957955, disc_loss = 0.0012024385993675197
Trained batch 149 in epoch 15, gen_loss = 0.5934920577208201, disc_loss = 0.0012010465321751933
Trained batch 150 in epoch 15, gen_loss = 0.593598140391293, disc_loss = 0.0012016899772728515
Trained batch 151 in epoch 15, gen_loss = 0.5934906409759271, disc_loss = 0.0011999993301670703
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.5245977640151978, disc_loss = 0.0010830821702256799
Trained batch 1 in epoch 16, gen_loss = 0.5617349743843079, disc_loss = 0.001193104952108115
Trained batch 2 in epoch 16, gen_loss = 0.5834572116533915, disc_loss = 0.0018219143385067582
Trained batch 3 in epoch 16, gen_loss = 0.5787841230630875, disc_loss = 0.001660761219682172
Trained batch 4 in epoch 16, gen_loss = 0.5782566666603088, disc_loss = 0.0015367788029834629
Trained batch 5 in epoch 16, gen_loss = 0.5800138711929321, disc_loss = 0.0014606014786598582
Trained batch 6 in epoch 16, gen_loss = 0.5763067858559745, disc_loss = 0.001423602574504912
Trained batch 7 in epoch 16, gen_loss = 0.5809632986783981, disc_loss = 0.0014049328019609675
Trained batch 8 in epoch 16, gen_loss = 0.5805145766999986, disc_loss = 0.0013738312215233843
Trained batch 9 in epoch 16, gen_loss = 0.5839571714401245, disc_loss = 0.001342378999106586
Trained batch 10 in epoch 16, gen_loss = 0.585738637230613, disc_loss = 0.001317250584675507
Trained batch 11 in epoch 16, gen_loss = 0.5881151805321375, disc_loss = 0.00131545002417018
Trained batch 12 in epoch 16, gen_loss = 0.5884167001797602, disc_loss = 0.0012846076144621922
Trained batch 13 in epoch 16, gen_loss = 0.5868564333234515, disc_loss = 0.0012936448911204934
Trained batch 14 in epoch 16, gen_loss = 0.5852776288986206, disc_loss = 0.00126875559023271
Trained batch 15 in epoch 16, gen_loss = 0.589524544775486, disc_loss = 0.0014101557244430296
Trained batch 16 in epoch 16, gen_loss = 0.5914784529629875, disc_loss = 0.0014650514417820994
Trained batch 17 in epoch 16, gen_loss = 0.5930368469821082, disc_loss = 0.001487397485309177
Trained batch 18 in epoch 16, gen_loss = 0.5934942301950956, disc_loss = 0.0014629887514992764
Trained batch 19 in epoch 16, gen_loss = 0.5942215621471405, disc_loss = 0.0014328123565064744
Trained batch 20 in epoch 16, gen_loss = 0.5934260686238607, disc_loss = 0.0014035884163431113
Trained batch 21 in epoch 16, gen_loss = 0.5943546837026422, disc_loss = 0.0013780803684229877
Trained batch 22 in epoch 16, gen_loss = 0.5946538940719936, disc_loss = 0.001353523739532608
Trained batch 23 in epoch 16, gen_loss = 0.5953607733050982, disc_loss = 0.0013306840264704078
Trained batch 24 in epoch 16, gen_loss = 0.5952386689186097, disc_loss = 0.0013174960296601058
Trained batch 25 in epoch 16, gen_loss = 0.5945554581972269, disc_loss = 0.0013060326231285357
Trained batch 26 in epoch 16, gen_loss = 0.595511688126458, disc_loss = 0.001305748005742552
Trained batch 27 in epoch 16, gen_loss = 0.5959418181862149, disc_loss = 0.0012898613786092028
Trained batch 28 in epoch 16, gen_loss = 0.5954864210095899, disc_loss = 0.001269998002781308
Trained batch 29 in epoch 16, gen_loss = 0.5948228935400645, disc_loss = 0.0012563724691669147
Trained batch 30 in epoch 16, gen_loss = 0.5942373333438751, disc_loss = 0.0012392772534381479
Trained batch 31 in epoch 16, gen_loss = 0.5958216432482004, disc_loss = 0.0012353958190942649
Trained batch 32 in epoch 16, gen_loss = 0.5961730859496377, disc_loss = 0.0012235480949818862
Trained batch 33 in epoch 16, gen_loss = 0.5977123747853672, disc_loss = 0.001256016841473277
Trained batch 34 in epoch 16, gen_loss = 0.5975352508681161, disc_loss = 0.0012432889430783688
Trained batch 35 in epoch 16, gen_loss = 0.5986799548069636, disc_loss = 0.0012357116971139072
Trained batch 36 in epoch 16, gen_loss = 0.5989747466267766, disc_loss = 0.001226106345515094
Trained batch 37 in epoch 16, gen_loss = 0.5988841417588686, disc_loss = 0.0012130117730090493
Trained batch 38 in epoch 16, gen_loss = 0.598466830375867, disc_loss = 0.0012005043487685423
Trained batch 39 in epoch 16, gen_loss = 0.5979956045746804, disc_loss = 0.0011944571320782415
Trained batch 40 in epoch 16, gen_loss = 0.5988693891502008, disc_loss = 0.0011884440190908386
Trained batch 41 in epoch 16, gen_loss = 0.5985040536948613, disc_loss = 0.0011849916634327244
Trained batch 42 in epoch 16, gen_loss = 0.5983524752217669, disc_loss = 0.0011793418386734503
Trained batch 43 in epoch 16, gen_loss = 0.5979858528483998, disc_loss = 0.0011708759848261252
Trained batch 44 in epoch 16, gen_loss = 0.5976319207085503, disc_loss = 0.001163021988597595
Trained batch 45 in epoch 16, gen_loss = 0.5969878733158112, disc_loss = 0.001159153411762141
Trained batch 46 in epoch 16, gen_loss = 0.5970814963604542, disc_loss = 0.0011536827746857989
Trained batch 47 in epoch 16, gen_loss = 0.5963671108086904, disc_loss = 0.0011512717658964295
Trained batch 48 in epoch 16, gen_loss = 0.5968000682032838, disc_loss = 0.001152963764794475
Trained batch 49 in epoch 16, gen_loss = 0.5962044775485993, disc_loss = 0.0011470357584767044
Trained batch 50 in epoch 16, gen_loss = 0.5955192131154677, disc_loss = 0.0011510325107248682
Trained batch 51 in epoch 16, gen_loss = 0.5944744119277368, disc_loss = 0.001144887697032223
Trained batch 52 in epoch 16, gen_loss = 0.5953584830715971, disc_loss = 0.0011462220660727119
Trained batch 53 in epoch 16, gen_loss = 0.5944969720310636, disc_loss = 0.00114412498078309
Trained batch 54 in epoch 16, gen_loss = 0.5942880738865245, disc_loss = 0.0011422730273228478
Trained batch 55 in epoch 16, gen_loss = 0.5940531949911799, disc_loss = 0.0011369950984122365
Trained batch 56 in epoch 16, gen_loss = 0.5939880672254061, disc_loss = 0.0011325686814655598
Trained batch 57 in epoch 16, gen_loss = 0.5942517714253788, disc_loss = 0.001125962194456751
Trained batch 58 in epoch 16, gen_loss = 0.5940641993183201, disc_loss = 0.0011178490417709543
Trained batch 59 in epoch 16, gen_loss = 0.5940918107827504, disc_loss = 0.0011160308592176686
Trained batch 60 in epoch 16, gen_loss = 0.594275501907849, disc_loss = 0.0011107686164666761
Trained batch 61 in epoch 16, gen_loss = 0.594339047708819, disc_loss = 0.0011042698188835093
Trained batch 62 in epoch 16, gen_loss = 0.5933079076191735, disc_loss = 0.0011025096404380977
Trained batch 63 in epoch 16, gen_loss = 0.5935824867337942, disc_loss = 0.0011000619460901362
Trained batch 64 in epoch 16, gen_loss = 0.5935117446459257, disc_loss = 0.001093412647381998
Trained batch 65 in epoch 16, gen_loss = 0.5934369193785118, disc_loss = 0.0010900302052808304
Trained batch 66 in epoch 16, gen_loss = 0.5931990137740747, disc_loss = 0.0010862287703845928
Trained batch 67 in epoch 16, gen_loss = 0.5936139778179281, disc_loss = 0.0010852559935301542
Trained batch 68 in epoch 16, gen_loss = 0.5937884640002596, disc_loss = 0.0010812819042863946
Trained batch 69 in epoch 16, gen_loss = 0.593272453546524, disc_loss = 0.0010803425011025475
Trained batch 70 in epoch 16, gen_loss = 0.5937497909639923, disc_loss = 0.0010816057640600058
Trained batch 71 in epoch 16, gen_loss = 0.5935651055640645, disc_loss = 0.0010771064561494212
Trained batch 72 in epoch 16, gen_loss = 0.5933800845930021, disc_loss = 0.0010727228738737534
Trained batch 73 in epoch 16, gen_loss = 0.5928747275391141, disc_loss = 0.0010679822023391622
Trained batch 74 in epoch 16, gen_loss = 0.5925488686561584, disc_loss = 0.0010652468857976299
Trained batch 75 in epoch 16, gen_loss = 0.59222039031355, disc_loss = 0.0010662006166775857
Trained batch 76 in epoch 16, gen_loss = 0.591959028274982, disc_loss = 0.0010643292440694165
Trained batch 77 in epoch 16, gen_loss = 0.5920455853144327, disc_loss = 0.0010646513494579361
Trained batch 78 in epoch 16, gen_loss = 0.591888648799703, disc_loss = 0.001069658007796948
Trained batch 79 in epoch 16, gen_loss = 0.5918004028499126, disc_loss = 0.0010675544348487166
Trained batch 80 in epoch 16, gen_loss = 0.5919255938059018, disc_loss = 0.0010698161563652074
Trained batch 81 in epoch 16, gen_loss = 0.5922703343193706, disc_loss = 0.0010801738705883575
Trained batch 82 in epoch 16, gen_loss = 0.5919507404407823, disc_loss = 0.001076672484267907
Trained batch 83 in epoch 16, gen_loss = 0.5921487602449599, disc_loss = 0.0010802485811014083
Trained batch 84 in epoch 16, gen_loss = 0.592039765329922, disc_loss = 0.0010808694244855467
Trained batch 85 in epoch 16, gen_loss = 0.5918231654998868, disc_loss = 0.0010788529613163583
Trained batch 86 in epoch 16, gen_loss = 0.5917253343538306, disc_loss = 0.001077016268926405
Trained batch 87 in epoch 16, gen_loss = 0.5918027311563492, disc_loss = 0.001076849534001667
Trained batch 88 in epoch 16, gen_loss = 0.5917453297068563, disc_loss = 0.0010726889399183767
Trained batch 89 in epoch 16, gen_loss = 0.5914160172144572, disc_loss = 0.0010735698975622653
Trained batch 90 in epoch 16, gen_loss = 0.5915937541605352, disc_loss = 0.0010723151461026826
Trained batch 91 in epoch 16, gen_loss = 0.5917265220828678, disc_loss = 0.0010705836966340228
Trained batch 92 in epoch 16, gen_loss = 0.5920851986895326, disc_loss = 0.0010673465696664187
Trained batch 93 in epoch 16, gen_loss = 0.5923130467851111, disc_loss = 0.0010634834941308153
Trained batch 94 in epoch 16, gen_loss = 0.5921070983535365, disc_loss = 0.0010606805548856132
Trained batch 95 in epoch 16, gen_loss = 0.5922415181994438, disc_loss = 0.001059680866698424
Trained batch 96 in epoch 16, gen_loss = 0.5918250292846837, disc_loss = 0.0010564485630836606
Trained batch 97 in epoch 16, gen_loss = 0.591439928327288, disc_loss = 0.001055230199459142
Trained batch 98 in epoch 16, gen_loss = 0.5914126959714022, disc_loss = 0.0010533106379267392
Trained batch 99 in epoch 16, gen_loss = 0.5912937474250793, disc_loss = 0.001053802618989721
Trained batch 100 in epoch 16, gen_loss = 0.591694692573925, disc_loss = 0.0010517561654929109
Trained batch 101 in epoch 16, gen_loss = 0.5914257460949468, disc_loss = 0.0010515766237707187
Trained batch 102 in epoch 16, gen_loss = 0.5917616121977278, disc_loss = 0.0010500908755805814
Trained batch 103 in epoch 16, gen_loss = 0.5914941808352103, disc_loss = 0.001052927807345091
Trained batch 104 in epoch 16, gen_loss = 0.5914398715609596, disc_loss = 0.0010523609112992529
Trained batch 105 in epoch 16, gen_loss = 0.5917555352426925, disc_loss = 0.001050906963668377
Trained batch 106 in epoch 16, gen_loss = 0.591802668348651, disc_loss = 0.0010513782933154188
Trained batch 107 in epoch 16, gen_loss = 0.5918224498077675, disc_loss = 0.0010506268261923214
Trained batch 108 in epoch 16, gen_loss = 0.591530759400184, disc_loss = 0.0010472537053603714
Trained batch 109 in epoch 16, gen_loss = 0.5917402988130396, disc_loss = 0.0010481903355949642
Trained batch 110 in epoch 16, gen_loss = 0.5918721363351152, disc_loss = 0.001045344706817723
Trained batch 111 in epoch 16, gen_loss = 0.5914766485137599, disc_loss = 0.0010412845710691596
Trained batch 112 in epoch 16, gen_loss = 0.5913819850018595, disc_loss = 0.001037666461826096
Trained batch 113 in epoch 16, gen_loss = 0.591541877441239, disc_loss = 0.0010347576023553287
Trained batch 114 in epoch 16, gen_loss = 0.5916634554448335, disc_loss = 0.0010387752205133437
Trained batch 115 in epoch 16, gen_loss = 0.5916344143193344, disc_loss = 0.001036537311377068
Trained batch 116 in epoch 16, gen_loss = 0.5919030965902866, disc_loss = 0.001034199009434535
Trained batch 117 in epoch 16, gen_loss = 0.592248881267289, disc_loss = 0.0010332205240078018
Trained batch 118 in epoch 16, gen_loss = 0.5924916968626135, disc_loss = 0.0010326079537058953
Trained batch 119 in epoch 16, gen_loss = 0.5926610738039017, disc_loss = 0.001030081529461313
Trained batch 120 in epoch 16, gen_loss = 0.5926890136781803, disc_loss = 0.0010297981313091111
Trained batch 121 in epoch 16, gen_loss = 0.5926601007336476, disc_loss = 0.0010294715991266622
Trained batch 122 in epoch 16, gen_loss = 0.5926603422901495, disc_loss = 0.0010270556336556508
Trained batch 123 in epoch 16, gen_loss = 0.592506684122547, disc_loss = 0.0010269187689353261
Trained batch 124 in epoch 16, gen_loss = 0.5926359553337097, disc_loss = 0.0010254425308667122
Trained batch 125 in epoch 16, gen_loss = 0.592329437297488, disc_loss = 0.0010239042702966208
Trained batch 126 in epoch 16, gen_loss = 0.592183976192174, disc_loss = 0.0010216618850497222
Trained batch 127 in epoch 16, gen_loss = 0.5919835814274848, disc_loss = 0.0010184750622102001
Trained batch 128 in epoch 16, gen_loss = 0.5918109818946483, disc_loss = 0.0010170958938019335
Trained batch 129 in epoch 16, gen_loss = 0.591886640053529, disc_loss = 0.001017039272790918
Trained batch 130 in epoch 16, gen_loss = 0.5917691042405049, disc_loss = 0.0010150630615353015
Trained batch 131 in epoch 16, gen_loss = 0.5919546028881362, disc_loss = 0.0010144038405445772
Trained batch 132 in epoch 16, gen_loss = 0.5919008886903748, disc_loss = 0.0010133739429547038
Trained batch 133 in epoch 16, gen_loss = 0.5919104133968922, disc_loss = 0.0010114694770022449
Trained batch 134 in epoch 16, gen_loss = 0.5920287913746304, disc_loss = 0.0010098505562550768
Trained batch 135 in epoch 16, gen_loss = 0.5920483912615215, disc_loss = 0.0010087745981496375
Trained batch 136 in epoch 16, gen_loss = 0.5922919603159827, disc_loss = 0.001008365004591943
Trained batch 137 in epoch 16, gen_loss = 0.5921514159527378, disc_loss = 0.0010077552502954622
Trained batch 138 in epoch 16, gen_loss = 0.5920535999236347, disc_loss = 0.0010064081284686549
Trained batch 139 in epoch 16, gen_loss = 0.5919572485344751, disc_loss = 0.001005128859209695
Trained batch 140 in epoch 16, gen_loss = 0.5922222695452102, disc_loss = 0.0010045543412103297
Trained batch 141 in epoch 16, gen_loss = 0.5925108353856584, disc_loss = 0.0010032884429805769
Trained batch 142 in epoch 16, gen_loss = 0.5918044948077702, disc_loss = 0.001015487664714586
Trained batch 143 in epoch 16, gen_loss = 0.5917805718878905, disc_loss = 0.0010206433786758378
Trained batch 144 in epoch 16, gen_loss = 0.5917875314580983, disc_loss = 0.0010217726025890945
Trained batch 145 in epoch 16, gen_loss = 0.5915853332166803, disc_loss = 0.0010226520590886014
Trained batch 146 in epoch 16, gen_loss = 0.5913298620658667, disc_loss = 0.0010215984122846655
Trained batch 147 in epoch 16, gen_loss = 0.5913291118434958, disc_loss = 0.0010197868557313356
Trained batch 148 in epoch 16, gen_loss = 0.5912104245000238, disc_loss = 0.0010175783255125003
Trained batch 149 in epoch 16, gen_loss = 0.5912869354089101, disc_loss = 0.0010174625060365846
Trained batch 150 in epoch 16, gen_loss = 0.5911232300152053, disc_loss = 0.0010165557953751097
Trained batch 151 in epoch 16, gen_loss = 0.5907492469015875, disc_loss = 0.0010148610971028621
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.6219862699508667, disc_loss = 0.0007325296173803508
Trained batch 1 in epoch 17, gen_loss = 0.6133940517902374, disc_loss = 0.0007509690767619759
Trained batch 2 in epoch 17, gen_loss = 0.6298207839330038, disc_loss = 0.000914676250734677
Trained batch 3 in epoch 17, gen_loss = 0.6234192550182343, disc_loss = 0.0008828873542370275
Trained batch 4 in epoch 17, gen_loss = 0.6095848083496094, disc_loss = 0.0008801125455647707
Trained batch 5 in epoch 17, gen_loss = 0.6129849851131439, disc_loss = 0.0008828225545585155
Trained batch 6 in epoch 17, gen_loss = 0.602141831602369, disc_loss = 0.0008945186522656254
Trained batch 7 in epoch 17, gen_loss = 0.5989043638110161, disc_loss = 0.0009041661687660962
Trained batch 8 in epoch 17, gen_loss = 0.5960110690858629, disc_loss = 0.0009078032776920332
Trained batch 9 in epoch 17, gen_loss = 0.5918067336082459, disc_loss = 0.0009199065272696317
Trained batch 10 in epoch 17, gen_loss = 0.5913069898431952, disc_loss = 0.0009163578929887576
Trained batch 11 in epoch 17, gen_loss = 0.5891915609439214, disc_loss = 0.0008852807028839985
Trained batch 12 in epoch 17, gen_loss = 0.5869936347007751, disc_loss = 0.0008645043842709408
Trained batch 13 in epoch 17, gen_loss = 0.5847532451152802, disc_loss = 0.0008483459366418954
Trained batch 14 in epoch 17, gen_loss = 0.5820588032404582, disc_loss = 0.0008612815251884361
Trained batch 15 in epoch 17, gen_loss = 0.5820431038737297, disc_loss = 0.0008624823967693374
Trained batch 16 in epoch 17, gen_loss = 0.5825324093594271, disc_loss = 0.0008716495187186143
Trained batch 17 in epoch 17, gen_loss = 0.5829341842068566, disc_loss = 0.0008612744374355922
Trained batch 18 in epoch 17, gen_loss = 0.5824074745178223, disc_loss = 0.0008506228363043384
Trained batch 19 in epoch 17, gen_loss = 0.5818176805973053, disc_loss = 0.0008393123425776139
Trained batch 20 in epoch 17, gen_loss = 0.5828382287706647, disc_loss = 0.0008373319592681669
Trained batch 21 in epoch 17, gen_loss = 0.5837831659750505, disc_loss = 0.0008299276867712086
Trained batch 22 in epoch 17, gen_loss = 0.5840892403022103, disc_loss = 0.0008232080144807696
Trained batch 23 in epoch 17, gen_loss = 0.5833733355005583, disc_loss = 0.0008186593137603874
Trained batch 24 in epoch 17, gen_loss = 0.5836851000785828, disc_loss = 0.0008344785217195749
Trained batch 25 in epoch 17, gen_loss = 0.5841783147591811, disc_loss = 0.0008425119807585501
Trained batch 26 in epoch 17, gen_loss = 0.585059505921823, disc_loss = 0.0008400735203866605
Trained batch 27 in epoch 17, gen_loss = 0.5854821354150772, disc_loss = 0.0008396939083468169
Trained batch 28 in epoch 17, gen_loss = 0.5857004399957328, disc_loss = 0.00084830853076459
Trained batch 29 in epoch 17, gen_loss = 0.585678509871165, disc_loss = 0.0008597339852713049
Trained batch 30 in epoch 17, gen_loss = 0.5869293770482463, disc_loss = 0.000873609134296496
Trained batch 31 in epoch 17, gen_loss = 0.5878483969718218, disc_loss = 0.0008758653202676214
Trained batch 32 in epoch 17, gen_loss = 0.5883749741496462, disc_loss = 0.000870339789385484
Trained batch 33 in epoch 17, gen_loss = 0.5872697006253635, disc_loss = 0.0008633380759206108
Trained batch 34 in epoch 17, gen_loss = 0.5873394353049142, disc_loss = 0.0008617986725377185
Trained batch 35 in epoch 17, gen_loss = 0.5862434407075247, disc_loss = 0.0008571906881924304
Trained batch 36 in epoch 17, gen_loss = 0.5867101727305232, disc_loss = 0.0008564691572148051
Trained batch 37 in epoch 17, gen_loss = 0.5865109907953363, disc_loss = 0.0008566812949108058
Trained batch 38 in epoch 17, gen_loss = 0.5859842697779337, disc_loss = 0.0008533454204622943
Trained batch 39 in epoch 17, gen_loss = 0.5847472205758095, disc_loss = 0.0008466862273053266
Trained batch 40 in epoch 17, gen_loss = 0.5855869127482902, disc_loss = 0.0008416256381812073
Trained batch 41 in epoch 17, gen_loss = 0.5848149515333629, disc_loss = 0.0008378901139145629
Trained batch 42 in epoch 17, gen_loss = 0.5863397578860439, disc_loss = 0.0008382925460504932
Trained batch 43 in epoch 17, gen_loss = 0.5856307040561329, disc_loss = 0.0008362453676950695
Trained batch 44 in epoch 17, gen_loss = 0.5845881965425279, disc_loss = 0.0008419618954778545
Trained batch 45 in epoch 17, gen_loss = 0.584445393603781, disc_loss = 0.0008410847070120761
Trained batch 46 in epoch 17, gen_loss = 0.5844599300242485, disc_loss = 0.0008404105839795096
Trained batch 47 in epoch 17, gen_loss = 0.5843795165419579, disc_loss = 0.0008367002762194412
Trained batch 48 in epoch 17, gen_loss = 0.5853488408789342, disc_loss = 0.0008384102779649654
Trained batch 49 in epoch 17, gen_loss = 0.5851843297481537, disc_loss = 0.0008334474836010486
Trained batch 50 in epoch 17, gen_loss = 0.5852025034380894, disc_loss = 0.000828890884340759
Trained batch 51 in epoch 17, gen_loss = 0.5851149627795587, disc_loss = 0.000826014219245945
Trained batch 52 in epoch 17, gen_loss = 0.5856328662836326, disc_loss = 0.0008268739681093479
Trained batch 53 in epoch 17, gen_loss = 0.5856712714389518, disc_loss = 0.0008226592477445525
Trained batch 54 in epoch 17, gen_loss = 0.585807833888314, disc_loss = 0.000823074602521956
Trained batch 55 in epoch 17, gen_loss = 0.5860199130007199, disc_loss = 0.0008264774889019984
Trained batch 56 in epoch 17, gen_loss = 0.5855079366449725, disc_loss = 0.0008225877148409685
Trained batch 57 in epoch 17, gen_loss = 0.5856558947727598, disc_loss = 0.0008218647342111016
Trained batch 58 in epoch 17, gen_loss = 0.5861379019284653, disc_loss = 0.0008201272773430131
Trained batch 59 in epoch 17, gen_loss = 0.585845555861791, disc_loss = 0.000819285519537516
Trained batch 60 in epoch 17, gen_loss = 0.5864866893799578, disc_loss = 0.0008225680632348799
Trained batch 61 in epoch 17, gen_loss = 0.5864771931402145, disc_loss = 0.0008211566676055231
Trained batch 62 in epoch 17, gen_loss = 0.585735525403704, disc_loss = 0.0008188377444942793
Trained batch 63 in epoch 17, gen_loss = 0.5854311734437943, disc_loss = 0.0008175411439879099
Trained batch 64 in epoch 17, gen_loss = 0.5854355280215924, disc_loss = 0.0008227192581846163
Trained batch 65 in epoch 17, gen_loss = 0.5854992053725503, disc_loss = 0.0008198281566640644
Trained batch 66 in epoch 17, gen_loss = 0.5854391820395171, disc_loss = 0.0008164120667766946
Trained batch 67 in epoch 17, gen_loss = 0.5854663603446063, disc_loss = 0.0008143799204844981
Trained batch 68 in epoch 17, gen_loss = 0.5860329883686011, disc_loss = 0.0008125325793103464
Trained batch 69 in epoch 17, gen_loss = 0.5860472883496965, disc_loss = 0.0008106272517969566
Trained batch 70 in epoch 17, gen_loss = 0.5858698327776412, disc_loss = 0.0008122457591423267
Trained batch 71 in epoch 17, gen_loss = 0.5856401945153872, disc_loss = 0.0008106617937705272
Trained batch 72 in epoch 17, gen_loss = 0.5864973705108851, disc_loss = 0.0008214374929219995
Trained batch 73 in epoch 17, gen_loss = 0.5865757038464418, disc_loss = 0.0008258125847016738
Trained batch 74 in epoch 17, gen_loss = 0.5864805976549784, disc_loss = 0.0008234134417337676
Trained batch 75 in epoch 17, gen_loss = 0.5865282032050585, disc_loss = 0.0008201248389301135
Trained batch 76 in epoch 17, gen_loss = 0.5866278456403063, disc_loss = 0.0008192176275959165
Trained batch 77 in epoch 17, gen_loss = 0.5863566047106034, disc_loss = 0.0008169547602450714
Trained batch 78 in epoch 17, gen_loss = 0.5862434242345109, disc_loss = 0.0008189973776535237
Trained batch 79 in epoch 17, gen_loss = 0.5861645519733429, disc_loss = 0.0008195388225431088
Trained batch 80 in epoch 17, gen_loss = 0.5862367285622491, disc_loss = 0.0008185798162881882
Trained batch 81 in epoch 17, gen_loss = 0.5864186606756071, disc_loss = 0.0008167525030752053
Trained batch 82 in epoch 17, gen_loss = 0.586689370942403, disc_loss = 0.000816314577276493
Trained batch 83 in epoch 17, gen_loss = 0.5866410271042869, disc_loss = 0.0008144999897229441
Trained batch 84 in epoch 17, gen_loss = 0.5866100472562453, disc_loss = 0.0008152330109356519
Trained batch 85 in epoch 17, gen_loss = 0.5867249667644501, disc_loss = 0.0008179276652341752
Trained batch 86 in epoch 17, gen_loss = 0.5859961393235744, disc_loss = 0.0008199663582557663
Trained batch 87 in epoch 17, gen_loss = 0.5857548361474817, disc_loss = 0.0008184084898940372
Trained batch 88 in epoch 17, gen_loss = 0.5857206850909116, disc_loss = 0.0008166534904641716
Trained batch 89 in epoch 17, gen_loss = 0.585645858446757, disc_loss = 0.0008187885331507358
Trained batch 90 in epoch 17, gen_loss = 0.5859266689845494, disc_loss = 0.0008187466550485364
Trained batch 91 in epoch 17, gen_loss = 0.5857378335102744, disc_loss = 0.0008197945976660222
Trained batch 92 in epoch 17, gen_loss = 0.585209806119242, disc_loss = 0.000817804638626835
Trained batch 93 in epoch 17, gen_loss = 0.5856344699859619, disc_loss = 0.0008169853752677111
Trained batch 94 in epoch 17, gen_loss = 0.5854831406944676, disc_loss = 0.0008141582047468738
Trained batch 95 in epoch 17, gen_loss = 0.5857523661106825, disc_loss = 0.0008122980131399041
Trained batch 96 in epoch 17, gen_loss = 0.5857185745976635, disc_loss = 0.0008102886681204912
Trained batch 97 in epoch 17, gen_loss = 0.5854828527995518, disc_loss = 0.000809177913707776
Trained batch 98 in epoch 17, gen_loss = 0.5858647311576689, disc_loss = 0.0008198612321384552
Trained batch 99 in epoch 17, gen_loss = 0.5856068474054337, disc_loss = 0.0008195834880461916
Trained batch 100 in epoch 17, gen_loss = 0.5859144896563917, disc_loss = 0.0008189631389721417
Trained batch 101 in epoch 17, gen_loss = 0.5857252297448177, disc_loss = 0.0008187319845983796
Trained batch 102 in epoch 17, gen_loss = 0.585406924335702, disc_loss = 0.0008157957113546871
Trained batch 103 in epoch 17, gen_loss = 0.5853462431293267, disc_loss = 0.0008143647629857206
Trained batch 104 in epoch 17, gen_loss = 0.5850309264092218, disc_loss = 0.0008124779599408309
Trained batch 105 in epoch 17, gen_loss = 0.58486237953294, disc_loss = 0.0008107639282484943
Trained batch 106 in epoch 17, gen_loss = 0.5851839123485244, disc_loss = 0.0008098105236313472
Trained batch 107 in epoch 17, gen_loss = 0.5846253578309659, disc_loss = 0.0008098170823089917
Trained batch 108 in epoch 17, gen_loss = 0.5846573218293146, disc_loss = 0.0008102592535812511
Trained batch 109 in epoch 17, gen_loss = 0.5846138986674222, disc_loss = 0.0008092780407010154
Trained batch 110 in epoch 17, gen_loss = 0.5846400604591714, disc_loss = 0.0008072298563395938
Trained batch 111 in epoch 17, gen_loss = 0.584626530962331, disc_loss = 0.0008061105654633138
Trained batch 112 in epoch 17, gen_loss = 0.5846769292797662, disc_loss = 0.0008045507840136379
Trained batch 113 in epoch 17, gen_loss = 0.584805790269584, disc_loss = 0.0008036610374243505
Trained batch 114 in epoch 17, gen_loss = 0.5850628464118294, disc_loss = 0.0008027758697331276
Trained batch 115 in epoch 17, gen_loss = 0.585109521088929, disc_loss = 0.0008039009879776759
Trained batch 116 in epoch 17, gen_loss = 0.5850432433633723, disc_loss = 0.0008031972012339303
Trained batch 117 in epoch 17, gen_loss = 0.585030230930296, disc_loss = 0.0008018178173727592
Trained batch 118 in epoch 17, gen_loss = 0.5849949311809379, disc_loss = 0.0007996823038991948
Trained batch 119 in epoch 17, gen_loss = 0.5852852543195088, disc_loss = 0.0007997116001206451
Trained batch 120 in epoch 17, gen_loss = 0.5851289748160307, disc_loss = 0.0008003664989994207
Trained batch 121 in epoch 17, gen_loss = 0.5848119869583943, disc_loss = 0.0007989042639907938
Trained batch 122 in epoch 17, gen_loss = 0.5847309726040538, disc_loss = 0.0007976662302276165
Trained batch 123 in epoch 17, gen_loss = 0.584787112570578, disc_loss = 0.0007952036981042775
Trained batch 124 in epoch 17, gen_loss = 0.5845855069160462, disc_loss = 0.0007938718176446855
Trained batch 125 in epoch 17, gen_loss = 0.5848692877898141, disc_loss = 0.0007926881888933065
Trained batch 126 in epoch 17, gen_loss = 0.5849933065767363, disc_loss = 0.0007915024661209699
Trained batch 127 in epoch 17, gen_loss = 0.5847851787693799, disc_loss = 0.0007898276539890503
Trained batch 128 in epoch 17, gen_loss = 0.5847024515617726, disc_loss = 0.0007888701579230296
Trained batch 129 in epoch 17, gen_loss = 0.5846708458203536, disc_loss = 0.0007889528843896607
Trained batch 130 in epoch 17, gen_loss = 0.5842306782271116, disc_loss = 0.0007898436205191466
Trained batch 131 in epoch 17, gen_loss = 0.5839703837127397, disc_loss = 0.0007913587112191387
Trained batch 132 in epoch 17, gen_loss = 0.5837095523239079, disc_loss = 0.0007910736809358617
Trained batch 133 in epoch 17, gen_loss = 0.5838200338740847, disc_loss = 0.0007894738440909215
Trained batch 134 in epoch 17, gen_loss = 0.5836847777719851, disc_loss = 0.000789191799790219
Trained batch 135 in epoch 17, gen_loss = 0.5835495293140411, disc_loss = 0.0007877661893657847
Trained batch 136 in epoch 17, gen_loss = 0.5836080051686642, disc_loss = 0.0007865555417880308
Trained batch 137 in epoch 17, gen_loss = 0.583472306313722, disc_loss = 0.0007844935652152028
Trained batch 138 in epoch 17, gen_loss = 0.583448784814464, disc_loss = 0.0007833381888637547
Trained batch 139 in epoch 17, gen_loss = 0.5831317782402039, disc_loss = 0.0007818852784112096
Trained batch 140 in epoch 17, gen_loss = 0.5831229847373692, disc_loss = 0.0007812204830189969
Trained batch 141 in epoch 17, gen_loss = 0.5832547906418921, disc_loss = 0.0007799282714291673
Trained batch 142 in epoch 17, gen_loss = 0.5832476474188425, disc_loss = 0.0007799838273134734
Trained batch 143 in epoch 17, gen_loss = 0.5832409593794081, disc_loss = 0.0007783359311967312
Trained batch 144 in epoch 17, gen_loss = 0.5830165587622543, disc_loss = 0.0007770099661088195
Trained batch 145 in epoch 17, gen_loss = 0.5831678044306089, disc_loss = 0.0007755591957479052
Trained batch 146 in epoch 17, gen_loss = 0.58317688533238, disc_loss = 0.0007746255616847502
Trained batch 147 in epoch 17, gen_loss = 0.5832274129261842, disc_loss = 0.000773311619382553
Trained batch 148 in epoch 17, gen_loss = 0.5829544379407128, disc_loss = 0.0007730971267071846
Trained batch 149 in epoch 17, gen_loss = 0.583048152923584, disc_loss = 0.0007750253293973704
Trained batch 150 in epoch 17, gen_loss = 0.5829117412598718, disc_loss = 0.0007744465024821115
Trained batch 151 in epoch 17, gen_loss = 0.5831150910572002, disc_loss = 0.0007744468063097692
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.6176705360412598, disc_loss = 0.0006762436823919415
Trained batch 1 in epoch 18, gen_loss = 0.5890065431594849, disc_loss = 0.0005933349020779133
Trained batch 2 in epoch 18, gen_loss = 0.5887082815170288, disc_loss = 0.0005664865796764692
Trained batch 3 in epoch 18, gen_loss = 0.5800282955169678, disc_loss = 0.0006186453974805772
Trained batch 4 in epoch 18, gen_loss = 0.5743603229522705, disc_loss = 0.0006112268078140914
Trained batch 5 in epoch 18, gen_loss = 0.5724113682905833, disc_loss = 0.0006039650664509585
Trained batch 6 in epoch 18, gen_loss = 0.5775857227189201, disc_loss = 0.000628668099774846
Trained batch 7 in epoch 18, gen_loss = 0.5809530466794968, disc_loss = 0.0006255763437366113
Trained batch 8 in epoch 18, gen_loss = 0.5848619672987196, disc_loss = 0.00064154735688741
Trained batch 9 in epoch 18, gen_loss = 0.5816819429397583, disc_loss = 0.0006316229060757905
Trained batch 10 in epoch 18, gen_loss = 0.578719821843234, disc_loss = 0.000630070164334029
Trained batch 11 in epoch 18, gen_loss = 0.58169357975324, disc_loss = 0.0006443461801003044
Trained batch 12 in epoch 18, gen_loss = 0.581102036512815, disc_loss = 0.0006439382828270587
Trained batch 13 in epoch 18, gen_loss = 0.5810650544507163, disc_loss = 0.0006465178323976163
Trained batch 14 in epoch 18, gen_loss = 0.5806822379430135, disc_loss = 0.0006387357871669035
Trained batch 15 in epoch 18, gen_loss = 0.5808713808655739, disc_loss = 0.000636426942946855
Trained batch 16 in epoch 18, gen_loss = 0.5828660866793465, disc_loss = 0.0006453852539005525
Trained batch 17 in epoch 18, gen_loss = 0.5820607013172574, disc_loss = 0.00064338402201732
Trained batch 18 in epoch 18, gen_loss = 0.5818072369224147, disc_loss = 0.0006495786242579159
Trained batch 19 in epoch 18, gen_loss = 0.5823879420757294, disc_loss = 0.000652251992141828
Trained batch 20 in epoch 18, gen_loss = 0.5806357690266201, disc_loss = 0.0006488594836333678
Trained batch 21 in epoch 18, gen_loss = 0.5787849886850878, disc_loss = 0.0006473176287148486
Trained batch 22 in epoch 18, gen_loss = 0.5780540497406669, disc_loss = 0.0006456784473772606
Trained batch 23 in epoch 18, gen_loss = 0.5788358350594839, disc_loss = 0.0006607956577984927
Trained batch 24 in epoch 18, gen_loss = 0.5795881986618042, disc_loss = 0.0006594086345285177
Trained batch 25 in epoch 18, gen_loss = 0.5793561201829177, disc_loss = 0.000670360687833566
Trained batch 26 in epoch 18, gen_loss = 0.5782152436397694, disc_loss = 0.0006719420974453291
Trained batch 27 in epoch 18, gen_loss = 0.5790204682520458, disc_loss = 0.0006825345377105155
Trained batch 28 in epoch 18, gen_loss = 0.5795430150525324, disc_loss = 0.0006801497737138435
Trained batch 29 in epoch 18, gen_loss = 0.5785867730776469, disc_loss = 0.0006771591996463637
Trained batch 30 in epoch 18, gen_loss = 0.5783845243915435, disc_loss = 0.0006770202326738546
Trained batch 31 in epoch 18, gen_loss = 0.5792117118835449, disc_loss = 0.000678469288686756
Trained batch 32 in epoch 18, gen_loss = 0.5799692471822103, disc_loss = 0.0006784363614508148
Trained batch 33 in epoch 18, gen_loss = 0.5788042790749494, disc_loss = 0.0006735362454920131
Trained batch 34 in epoch 18, gen_loss = 0.5788596902574812, disc_loss = 0.0006706630611526115
Trained batch 35 in epoch 18, gen_loss = 0.5788983354965845, disc_loss = 0.0006684816649390592
Trained batch 36 in epoch 18, gen_loss = 0.5793648362159729, disc_loss = 0.0006654013083568094
Trained batch 37 in epoch 18, gen_loss = 0.5785288214683533, disc_loss = 0.0006622163621757768
Trained batch 38 in epoch 18, gen_loss = 0.5779954332571763, disc_loss = 0.0006630042335018516
Trained batch 39 in epoch 18, gen_loss = 0.5772360429167748, disc_loss = 0.0006636725869611837
Trained batch 40 in epoch 18, gen_loss = 0.5782384799747933, disc_loss = 0.0006654299213550985
Trained batch 41 in epoch 18, gen_loss = 0.5771613419055939, disc_loss = 0.0006644144208015254
Trained batch 42 in epoch 18, gen_loss = 0.5769110030906145, disc_loss = 0.0006609354438909958
Trained batch 43 in epoch 18, gen_loss = 0.5770613293756138, disc_loss = 0.0006582144123967737
Trained batch 44 in epoch 18, gen_loss = 0.5771489196353489, disc_loss = 0.0006605507029841343
Trained batch 45 in epoch 18, gen_loss = 0.5781224370002747, disc_loss = 0.0006626103359335305
Trained batch 46 in epoch 18, gen_loss = 0.5783007664883391, disc_loss = 0.0006599948379865035
Trained batch 47 in epoch 18, gen_loss = 0.5785845083494982, disc_loss = 0.0006585328058766512
Trained batch 48 in epoch 18, gen_loss = 0.5791452697345189, disc_loss = 0.0006598521769997113
Trained batch 49 in epoch 18, gen_loss = 0.5793907535076142, disc_loss = 0.000660037393681705
Trained batch 50 in epoch 18, gen_loss = 0.5794610404500774, disc_loss = 0.0006592541147826933
Trained batch 51 in epoch 18, gen_loss = 0.5794276560728366, disc_loss = 0.00065711379955666
Trained batch 52 in epoch 18, gen_loss = 0.5795395498005849, disc_loss = 0.0006630279470832562
Trained batch 53 in epoch 18, gen_loss = 0.5794910556740231, disc_loss = 0.0006620984145060733
Trained batch 54 in epoch 18, gen_loss = 0.5797417770732533, disc_loss = 0.0006611554587090557
Trained batch 55 in epoch 18, gen_loss = 0.5794829651713371, disc_loss = 0.0006589784274443186
Trained batch 56 in epoch 18, gen_loss = 0.5795610505237914, disc_loss = 0.000657498317754321
Trained batch 57 in epoch 18, gen_loss = 0.5784601322535811, disc_loss = 0.0006612964869669542
Trained batch 58 in epoch 18, gen_loss = 0.5796578374959654, disc_loss = 0.0006715210324342726
Trained batch 59 in epoch 18, gen_loss = 0.5795211166143417, disc_loss = 0.0006856046830459188
Trained batch 60 in epoch 18, gen_loss = 0.5793345912558133, disc_loss = 0.0006865293234128688
Trained batch 61 in epoch 18, gen_loss = 0.5793567261388225, disc_loss = 0.0006852403617343835
Trained batch 62 in epoch 18, gen_loss = 0.5793625210958814, disc_loss = 0.0006867821174969394
Trained batch 63 in epoch 18, gen_loss = 0.5793929938226938, disc_loss = 0.0006901297447257093
Trained batch 64 in epoch 18, gen_loss = 0.5789053146655743, disc_loss = 0.0006903191840347762
Trained batch 65 in epoch 18, gen_loss = 0.5786540174123013, disc_loss = 0.0006949804488668275
Trained batch 66 in epoch 18, gen_loss = 0.5793411358078914, disc_loss = 0.0006968400574900877
Trained batch 67 in epoch 18, gen_loss = 0.5789250065298641, disc_loss = 0.0006981192213168149
Trained batch 68 in epoch 18, gen_loss = 0.5788876725279767, disc_loss = 0.0006977786298206859
Trained batch 69 in epoch 18, gen_loss = 0.5788104849202292, disc_loss = 0.0006963048670773528
Trained batch 70 in epoch 18, gen_loss = 0.5782811918728789, disc_loss = 0.0006950141027451716
Trained batch 71 in epoch 18, gen_loss = 0.5782264628344111, disc_loss = 0.0006933773523390604
Trained batch 72 in epoch 18, gen_loss = 0.5779607010214296, disc_loss = 0.000693292124196887
Trained batch 73 in epoch 18, gen_loss = 0.5785527720644668, disc_loss = 0.0006944765973949452
Trained batch 74 in epoch 18, gen_loss = 0.5782702930768331, disc_loss = 0.0007075122906826436
Trained batch 75 in epoch 18, gen_loss = 0.5777192986325214, disc_loss = 0.0007393752679682189
Trained batch 76 in epoch 18, gen_loss = 0.5787921989118898, disc_loss = 0.0008210732590999793
Trained batch 77 in epoch 18, gen_loss = 0.5787313649287591, disc_loss = 0.0008518444799567357
Trained batch 78 in epoch 18, gen_loss = 0.5787580730039862, disc_loss = 0.0008629263132586604
Trained batch 79 in epoch 18, gen_loss = 0.5787927739322185, disc_loss = 0.0008834426385874395
Trained batch 80 in epoch 18, gen_loss = 0.5785328694331793, disc_loss = 0.0008865521903103792
Trained batch 81 in epoch 18, gen_loss = 0.5782631955495695, disc_loss = 0.0008940572414558563
Trained batch 82 in epoch 18, gen_loss = 0.5779254932001413, disc_loss = 0.0009003438789072076
Trained batch 83 in epoch 18, gen_loss = 0.5781594415505728, disc_loss = 0.0009082973916693369
Trained batch 84 in epoch 18, gen_loss = 0.5779208211337818, disc_loss = 0.0009148445165277842
Trained batch 85 in epoch 18, gen_loss = 0.5776764715826789, disc_loss = 0.0010117221546500142
Trained batch 86 in epoch 18, gen_loss = 0.5784822627045643, disc_loss = 0.001146404872161347
Trained batch 87 in epoch 18, gen_loss = 0.5794088752432303, disc_loss = 0.0011960550506377
Trained batch 88 in epoch 18, gen_loss = 0.5795526792494099, disc_loss = 0.0011988031616423991
Trained batch 89 in epoch 18, gen_loss = 0.5797935399744246, disc_loss = 0.0012081762083754357
Trained batch 90 in epoch 18, gen_loss = 0.5796537910188947, disc_loss = 0.0012159248037458203
Trained batch 91 in epoch 18, gen_loss = 0.5798427890176359, disc_loss = 0.0012160828533207837
Trained batch 92 in epoch 18, gen_loss = 0.5802351659344088, disc_loss = 0.0012149914957693107
Trained batch 93 in epoch 18, gen_loss = 0.5800008646985317, disc_loss = 0.0012148303144482618
Trained batch 94 in epoch 18, gen_loss = 0.5796428630226537, disc_loss = 0.0012106401030905546
Trained batch 95 in epoch 18, gen_loss = 0.5795224315176407, disc_loss = 0.0012057693996515202
Trained batch 96 in epoch 18, gen_loss = 0.5793172428288411, disc_loss = 0.0012004490342884104
Trained batch 97 in epoch 18, gen_loss = 0.5794351362452215, disc_loss = 0.0011970870189691838
Trained batch 98 in epoch 18, gen_loss = 0.5797767729470225, disc_loss = 0.0011966553777738502
Trained batch 99 in epoch 18, gen_loss = 0.5794405788183212, disc_loss = 0.0011925734503893182
Trained batch 100 in epoch 18, gen_loss = 0.579073954926859, disc_loss = 0.001189955411649466
Trained batch 101 in epoch 18, gen_loss = 0.5785434468119752, disc_loss = 0.0011868163636273832
Trained batch 102 in epoch 18, gen_loss = 0.5786777306528925, disc_loss = 0.0011918405924236529
Trained batch 103 in epoch 18, gen_loss = 0.5785904051019595, disc_loss = 0.001188883265198316
Trained batch 104 in epoch 18, gen_loss = 0.5786542744863601, disc_loss = 0.0011859046888449008
Trained batch 105 in epoch 18, gen_loss = 0.5786817675491549, disc_loss = 0.0011832651507575065
Trained batch 106 in epoch 18, gen_loss = 0.578692615032196, disc_loss = 0.0011785994811531887
Trained batch 107 in epoch 18, gen_loss = 0.578590836237978, disc_loss = 0.0011762799883770101
Trained batch 108 in epoch 18, gen_loss = 0.5784698681000175, disc_loss = 0.0011713036614760689
Trained batch 109 in epoch 18, gen_loss = 0.5785733353007924, disc_loss = 0.001167365568901666
Trained batch 110 in epoch 18, gen_loss = 0.5783087219203915, disc_loss = 0.0011632594878802094
Trained batch 111 in epoch 18, gen_loss = 0.5780255166547639, disc_loss = 0.001158604114087731
Trained batch 112 in epoch 18, gen_loss = 0.5781445967412628, disc_loss = 0.001155876597818152
Trained batch 113 in epoch 18, gen_loss = 0.5782774242392758, disc_loss = 0.0011590390104653412
Trained batch 114 in epoch 18, gen_loss = 0.5780166304629782, disc_loss = 0.001236255405187283
Trained batch 115 in epoch 18, gen_loss = 0.5789365655389326, disc_loss = 0.0013102166834367632
Trained batch 116 in epoch 18, gen_loss = 0.5794089879745092, disc_loss = 0.001350745677144036
Trained batch 117 in epoch 18, gen_loss = 0.5795708328990613, disc_loss = 0.0013607397243396331
Trained batch 118 in epoch 18, gen_loss = 0.5793899658347378, disc_loss = 0.0014442541106298816
Trained batch 119 in epoch 18, gen_loss = 0.5800957749287288, disc_loss = 0.0014957002917071805
Trained batch 120 in epoch 18, gen_loss = 0.580827337158613, disc_loss = 0.0015282573241909797
Trained batch 121 in epoch 18, gen_loss = 0.581090229456542, disc_loss = 0.001526921670731218
Trained batch 122 in epoch 18, gen_loss = 0.581215621979256, disc_loss = 0.0015371875871518037
Trained batch 123 in epoch 18, gen_loss = 0.5811633602265389, disc_loss = 0.0015354656441617877
Trained batch 124 in epoch 18, gen_loss = 0.5808762321472168, disc_loss = 0.0015363975744694472
Trained batch 125 in epoch 18, gen_loss = 0.5808222256009541, disc_loss = 0.001536096487793007
Trained batch 126 in epoch 18, gen_loss = 0.5806361798226364, disc_loss = 0.0015349093866791194
Trained batch 127 in epoch 18, gen_loss = 0.5808805101551116, disc_loss = 0.001534943104161357
Trained batch 128 in epoch 18, gen_loss = 0.5809099022732225, disc_loss = 0.0015365401753982485
Trained batch 129 in epoch 18, gen_loss = 0.5808417008473323, disc_loss = 0.0015324705557969328
Trained batch 130 in epoch 18, gen_loss = 0.5811742325775496, disc_loss = 0.001528031461097243
Trained batch 131 in epoch 18, gen_loss = 0.5811537206172943, disc_loss = 0.0015237358884681298
Trained batch 132 in epoch 18, gen_loss = 0.5809348256964433, disc_loss = 0.0015206073469454353
Trained batch 133 in epoch 18, gen_loss = 0.5808375451102186, disc_loss = 0.0015186442434961505
Trained batch 134 in epoch 18, gen_loss = 0.5806593859637225, disc_loss = 0.0015125510032737144
Trained batch 135 in epoch 18, gen_loss = 0.580803291324307, disc_loss = 0.001507818851250169
Trained batch 136 in epoch 18, gen_loss = 0.5803896715171146, disc_loss = 0.0015062724561328545
Trained batch 137 in epoch 18, gen_loss = 0.5804934112922006, disc_loss = 0.0015012880093822985
Trained batch 138 in epoch 18, gen_loss = 0.5805295208375231, disc_loss = 0.0014966474963258281
Trained batch 139 in epoch 18, gen_loss = 0.5800939704690661, disc_loss = 0.0014971430255432746
Trained batch 140 in epoch 18, gen_loss = 0.5796531130236091, disc_loss = 0.0014941871417223985
Trained batch 141 in epoch 18, gen_loss = 0.5796794056052893, disc_loss = 0.0014934554002510095
Trained batch 142 in epoch 18, gen_loss = 0.5799611706833739, disc_loss = 0.0014895684146029237
Trained batch 143 in epoch 18, gen_loss = 0.5798142146733072, disc_loss = 0.0014843048273986722
Trained batch 144 in epoch 18, gen_loss = 0.5797244080181779, disc_loss = 0.001482420010845466
Trained batch 145 in epoch 18, gen_loss = 0.5795093203244144, disc_loss = 0.0014797319380617509
Trained batch 146 in epoch 18, gen_loss = 0.5797305350400963, disc_loss = 0.0014757930941018118
Trained batch 147 in epoch 18, gen_loss = 0.5796787448831506, disc_loss = 0.0014719732870297456
Trained batch 148 in epoch 18, gen_loss = 0.5792974037612044, disc_loss = 0.0014677783333690174
Trained batch 149 in epoch 18, gen_loss = 0.5791463609536489, disc_loss = 0.001463178707053885
Trained batch 150 in epoch 18, gen_loss = 0.5788738834147422, disc_loss = 0.0014590759000691605
Trained batch 151 in epoch 18, gen_loss = 0.5788249989089213, disc_loss = 0.001454167540175963
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.615491509437561, disc_loss = 0.0006720372475683689
Trained batch 1 in epoch 19, gen_loss = 0.6020582020282745, disc_loss = 0.0006712537142448127
Trained batch 2 in epoch 19, gen_loss = 0.5781758824984232, disc_loss = 0.0007272332635087272
Trained batch 3 in epoch 19, gen_loss = 0.5786352455615997, disc_loss = 0.0007218857208499685
Trained batch 4 in epoch 19, gen_loss = 0.5707632780075074, disc_loss = 0.0007312631700187921
Trained batch 5 in epoch 19, gen_loss = 0.5689713557561239, disc_loss = 0.0007134233116327474
Trained batch 6 in epoch 19, gen_loss = 0.5667508159364972, disc_loss = 0.0007252872539018946
Trained batch 7 in epoch 19, gen_loss = 0.5739312469959259, disc_loss = 0.0007768998693791218
Trained batch 8 in epoch 19, gen_loss = 0.5732650227016873, disc_loss = 0.0008020260591163404
Trained batch 9 in epoch 19, gen_loss = 0.5730383634567261, disc_loss = 0.0008665122848469764
Trained batch 10 in epoch 19, gen_loss = 0.5699230595068498, disc_loss = 0.0009483369331891564
Trained batch 11 in epoch 19, gen_loss = 0.5679138650496801, disc_loss = 0.0009667383031531548
Trained batch 12 in epoch 19, gen_loss = 0.5678638632480915, disc_loss = 0.0009894163141815136
Trained batch 13 in epoch 19, gen_loss = 0.568322058234896, disc_loss = 0.001012837451915922
Trained batch 14 in epoch 19, gen_loss = 0.5694630781809489, disc_loss = 0.0011050274323982498
Trained batch 15 in epoch 19, gen_loss = 0.5757391601800919, disc_loss = 0.001353143776213983
Trained batch 16 in epoch 19, gen_loss = 0.5781628244063434, disc_loss = 0.0014603089657612145
Trained batch 17 in epoch 19, gen_loss = 0.5789793398645189, disc_loss = 0.0014534139675864328
Trained batch 18 in epoch 19, gen_loss = 0.5824114962628013, disc_loss = 0.0014499628726442001
Trained batch 19 in epoch 19, gen_loss = 0.5844999253749847, disc_loss = 0.0014161886385409162
Trained batch 20 in epoch 19, gen_loss = 0.5851172265552339, disc_loss = 0.0013835071890969716
Trained batch 21 in epoch 19, gen_loss = 0.5853149186481129, disc_loss = 0.0013477878608021208
Trained batch 22 in epoch 19, gen_loss = 0.584894351337267, disc_loss = 0.0013128534976757414
Trained batch 23 in epoch 19, gen_loss = 0.5872859979669253, disc_loss = 0.0013027478004611719
Trained batch 24 in epoch 19, gen_loss = 0.586093499660492, disc_loss = 0.0012812361074611544
Trained batch 25 in epoch 19, gen_loss = 0.5858840873608222, disc_loss = 0.001267531904606865
Trained batch 26 in epoch 19, gen_loss = 0.5847140374007048, disc_loss = 0.0012472900346404425
Trained batch 27 in epoch 19, gen_loss = 0.583566061088017, disc_loss = 0.0012326316417394473
Trained batch 28 in epoch 19, gen_loss = 0.5844154029056944, disc_loss = 0.001213435938678168
Trained batch 29 in epoch 19, gen_loss = 0.5847054402033488, disc_loss = 0.0012011818956428517
Trained batch 30 in epoch 19, gen_loss = 0.5824539026906413, disc_loss = 0.0011919523052300416
Trained batch 31 in epoch 19, gen_loss = 0.5821010041981936, disc_loss = 0.0011749449349736096
Trained batch 32 in epoch 19, gen_loss = 0.5811972581979, disc_loss = 0.0011598468056146169
Trained batch 33 in epoch 19, gen_loss = 0.5797979936880224, disc_loss = 0.001145933217177277
Trained batch 34 in epoch 19, gen_loss = 0.5797870670046125, disc_loss = 0.0011307638670716967
Trained batch 35 in epoch 19, gen_loss = 0.5788355039225684, disc_loss = 0.0011249879753449932
Trained batch 36 in epoch 19, gen_loss = 0.5803395928563299, disc_loss = 0.0011250046884162806
Trained batch 37 in epoch 19, gen_loss = 0.5808749418509634, disc_loss = 0.0011290910999952374
Trained batch 38 in epoch 19, gen_loss = 0.5808899601300558, disc_loss = 0.0011221059696533931
Trained batch 39 in epoch 19, gen_loss = 0.5814562171697617, disc_loss = 0.0011135923487017862
Trained batch 40 in epoch 19, gen_loss = 0.5809054345619388, disc_loss = 0.0011068493363492918
Trained batch 41 in epoch 19, gen_loss = 0.5803847483226231, disc_loss = 0.0011859442803099575
Trained batch 42 in epoch 19, gen_loss = 0.5839816775432852, disc_loss = 0.0013333423331184963
Trained batch 43 in epoch 19, gen_loss = 0.5862548554485495, disc_loss = 0.0013641526020364836
Trained batch 44 in epoch 19, gen_loss = 0.587241001923879, disc_loss = 0.0013653183912134006
Trained batch 45 in epoch 19, gen_loss = 0.5871046548304351, disc_loss = 0.0013751713647608362
Trained batch 46 in epoch 19, gen_loss = 0.5873504813681257, disc_loss = 0.0013726747141497091
Trained batch 47 in epoch 19, gen_loss = 0.5876508665581545, disc_loss = 0.0013657437678678737
Trained batch 48 in epoch 19, gen_loss = 0.5886833144693958, disc_loss = 0.0013624180823431484
Trained batch 49 in epoch 19, gen_loss = 0.5885755515098572, disc_loss = 0.0013519700570032
Trained batch 50 in epoch 19, gen_loss = 0.5895625820346907, disc_loss = 0.001361450385850142
Trained batch 51 in epoch 19, gen_loss = 0.5890915496991231, disc_loss = 0.0013886272387865644
Trained batch 52 in epoch 19, gen_loss = 0.5892354092507992, disc_loss = 0.0013856780781182198
Trained batch 53 in epoch 19, gen_loss = 0.5885398078847814, disc_loss = 0.0013832303898029582
Trained batch 54 in epoch 19, gen_loss = 0.5895489259199662, disc_loss = 0.0013768395726484332
Trained batch 55 in epoch 19, gen_loss = 0.5885370916553906, disc_loss = 0.0013682349370875663
Trained batch 56 in epoch 19, gen_loss = 0.5883396037837916, disc_loss = 0.0013728712720126567
Trained batch 57 in epoch 19, gen_loss = 0.5882391313026691, disc_loss = 0.0013672139320988208
Trained batch 58 in epoch 19, gen_loss = 0.5878657728938733, disc_loss = 0.001356551204650205
Trained batch 59 in epoch 19, gen_loss = 0.587082040309906, disc_loss = 0.0013486563577316702
Trained batch 60 in epoch 19, gen_loss = 0.5875579773402605, disc_loss = 0.001338378911776865
Trained batch 61 in epoch 19, gen_loss = 0.587660595293968, disc_loss = 0.0013309043978581266
Trained batch 62 in epoch 19, gen_loss = 0.5864947513928489, disc_loss = 0.0013289033372457775
Trained batch 63 in epoch 19, gen_loss = 0.5858506811782718, disc_loss = 0.001409551912729512
Trained batch 64 in epoch 19, gen_loss = 0.5876152515411377, disc_loss = 0.0014775319365211404
Trained batch 65 in epoch 19, gen_loss = 0.5880347996047048, disc_loss = 0.0015001959206225972
Trained batch 66 in epoch 19, gen_loss = 0.5885841134768813, disc_loss = 0.0015052327253758462
Trained batch 67 in epoch 19, gen_loss = 0.588729986373116, disc_loss = 0.0015035249251762733
Trained batch 68 in epoch 19, gen_loss = 0.5889406083286672, disc_loss = 0.0015007245398221025
Trained batch 69 in epoch 19, gen_loss = 0.5889221855572292, disc_loss = 0.0014917502645403146
Trained batch 70 in epoch 19, gen_loss = 0.5895382577264813, disc_loss = 0.0014882910681862226
Trained batch 71 in epoch 19, gen_loss = 0.589259098801348, disc_loss = 0.0014859858557530162
Trained batch 72 in epoch 19, gen_loss = 0.5893588947923216, disc_loss = 0.0014785267779450506
Trained batch 73 in epoch 19, gen_loss = 0.5889836002040554, disc_loss = 0.0014760915875887952
Trained batch 74 in epoch 19, gen_loss = 0.5894100761413574, disc_loss = 0.0014688268676400185
Trained batch 75 in epoch 19, gen_loss = 0.5891183944124925, disc_loss = 0.0014629526841944379
Trained batch 76 in epoch 19, gen_loss = 0.5895080752186961, disc_loss = 0.0014558391919202327
Trained batch 77 in epoch 19, gen_loss = 0.5893278129589863, disc_loss = 0.0014816776659781448
Trained batch 78 in epoch 19, gen_loss = 0.589569892309889, disc_loss = 0.001474882126049009
Trained batch 79 in epoch 19, gen_loss = 0.5900813519954682, disc_loss = 0.0014701290121593047
Trained batch 80 in epoch 19, gen_loss = 0.5902281572789322, disc_loss = 0.0014790687975933614
Trained batch 81 in epoch 19, gen_loss = 0.5915175581850657, disc_loss = 0.0015037963088749477
Trained batch 82 in epoch 19, gen_loss = 0.592013392821852, disc_loss = 0.0015074225017767265
Trained batch 83 in epoch 19, gen_loss = 0.5923618702661424, disc_loss = 0.0015073369937627355
Trained batch 84 in epoch 19, gen_loss = 0.5925062291762409, disc_loss = 0.001505539461504668
Trained batch 85 in epoch 19, gen_loss = 0.5918106679306474, disc_loss = 0.0014999905204519542
Trained batch 86 in epoch 19, gen_loss = 0.5915061824623196, disc_loss = 0.0014994577056428567
Trained batch 87 in epoch 19, gen_loss = 0.5910779738968069, disc_loss = 0.0014942538539550944
Trained batch 88 in epoch 19, gen_loss = 0.5905467466022192, disc_loss = 0.0014882468091313508
Trained batch 89 in epoch 19, gen_loss = 0.5903023587332832, disc_loss = 0.0014835575860666318
Trained batch 90 in epoch 19, gen_loss = 0.5899625217521584, disc_loss = 0.0014775212486990942
Trained batch 91 in epoch 19, gen_loss = 0.5893636915994727, disc_loss = 0.0014780339925377832
Trained batch 92 in epoch 19, gen_loss = 0.5890960513904531, disc_loss = 0.0014727689289507928
Trained batch 93 in epoch 19, gen_loss = 0.5887880147771632, disc_loss = 0.0014695626716971636
Trained batch 94 in epoch 19, gen_loss = 0.588487794524745, disc_loss = 0.0014667035245924797
Trained batch 95 in epoch 19, gen_loss = 0.5879569922884306, disc_loss = 0.0014587975947506493
Trained batch 96 in epoch 19, gen_loss = 0.5880751081348694, disc_loss = 0.0014548987016974727
Trained batch 97 in epoch 19, gen_loss = 0.5874901766679725, disc_loss = 0.0014488277891508247
Trained batch 98 in epoch 19, gen_loss = 0.5876879631870925, disc_loss = 0.0014445718249654152
Trained batch 99 in epoch 19, gen_loss = 0.5875143533945084, disc_loss = 0.0014408485352760182
Trained batch 100 in epoch 19, gen_loss = 0.5867137631567398, disc_loss = 0.0014377914750625812
Trained batch 101 in epoch 19, gen_loss = 0.5868344926366619, disc_loss = 0.0014352538929932623
Trained batch 102 in epoch 19, gen_loss = 0.5869326574131123, disc_loss = 0.0014340644289775597
Trained batch 103 in epoch 19, gen_loss = 0.5866714091255114, disc_loss = 0.0014419095974657326
Trained batch 104 in epoch 19, gen_loss = 0.586555924869719, disc_loss = 0.001458910739027141
Trained batch 105 in epoch 19, gen_loss = 0.5865620042917863, disc_loss = 0.0014688826955740674
Trained batch 106 in epoch 19, gen_loss = 0.5864159297720294, disc_loss = 0.0014687720952755727
Trained batch 107 in epoch 19, gen_loss = 0.5865521381298701, disc_loss = 0.0014890152621471013
Trained batch 108 in epoch 19, gen_loss = 0.5866560170409876, disc_loss = 0.0014922354320158174
Trained batch 109 in epoch 19, gen_loss = 0.5865631005980751, disc_loss = 0.0014951196017632768
Trained batch 110 in epoch 19, gen_loss = 0.586612717525379, disc_loss = 0.001501008040200382
Trained batch 111 in epoch 19, gen_loss = 0.5865939163735935, disc_loss = 0.0015091401900073314
Trained batch 112 in epoch 19, gen_loss = 0.5860860695881126, disc_loss = 0.001527687875178964
Trained batch 113 in epoch 19, gen_loss = 0.5845983833597418, disc_loss = 0.003800681541498195
Trained batch 114 in epoch 19, gen_loss = 0.5863924503326416, disc_loss = 0.010127413526440606
Trained batch 115 in epoch 19, gen_loss = 0.586332380771637, disc_loss = 0.012632843743756832
Trained batch 116 in epoch 19, gen_loss = 0.5851011342472501, disc_loss = 0.01697261974814499
Trained batch 117 in epoch 19, gen_loss = 0.5859233590505891, disc_loss = 0.028680963531014177
Trained batch 118 in epoch 19, gen_loss = 0.5858120357289034, disc_loss = 0.032885082123288494
Trained batch 119 in epoch 19, gen_loss = 0.5849374674260617, disc_loss = 0.0357757513668427
Trained batch 120 in epoch 19, gen_loss = 0.5839805433080216, disc_loss = 0.03959344487015758
Trained batch 121 in epoch 19, gen_loss = 0.5828595860082595, disc_loss = 0.041267595080693144
Trained batch 122 in epoch 19, gen_loss = 0.5814121646609732, disc_loss = 0.04283952857869321
Trained batch 123 in epoch 19, gen_loss = 0.5801415308829276, disc_loss = 0.04409591973272918
Trained batch 124 in epoch 19, gen_loss = 0.5788828110694886, disc_loss = 0.045316866631153974
Trained batch 125 in epoch 19, gen_loss = 0.5776731558735408, disc_loss = 0.04637086343635539
Trained batch 126 in epoch 19, gen_loss = 0.5763083175411374, disc_loss = 0.04737313783509422
Trained batch 127 in epoch 19, gen_loss = 0.5749683361500502, disc_loss = 0.04830800322315554
Trained batch 128 in epoch 19, gen_loss = 0.5736914020638133, disc_loss = 0.049173988339169916
Trained batch 129 in epoch 19, gen_loss = 0.572474439556782, disc_loss = 0.050027933253351455
Trained batch 130 in epoch 19, gen_loss = 0.5711394782739742, disc_loss = 0.05114229113967265
Trained batch 131 in epoch 19, gen_loss = 0.5697676832928802, disc_loss = 0.052180739058354506
Trained batch 132 in epoch 19, gen_loss = 0.5686148165312028, disc_loss = 0.053669597416559474
Trained batch 133 in epoch 19, gen_loss = 0.5676948959702877, disc_loss = 0.055168879338724316
Trained batch 134 in epoch 19, gen_loss = 0.5664986076178374, disc_loss = 0.05679284554466398
Trained batch 135 in epoch 19, gen_loss = 0.5654827908558004, disc_loss = 0.058285577546699
Trained batch 136 in epoch 19, gen_loss = 0.5642041690158148, disc_loss = 0.05953599566493496
Trained batch 137 in epoch 19, gen_loss = 0.5632373299719631, disc_loss = 0.060721040631229385
Trained batch 138 in epoch 19, gen_loss = 0.5620123415970973, disc_loss = 0.06177631663300914
Trained batch 139 in epoch 19, gen_loss = 0.561524697286742, disc_loss = 0.06260245867680558
Trained batch 140 in epoch 19, gen_loss = 0.5602714017773351, disc_loss = 0.06362790650901128
Trained batch 141 in epoch 19, gen_loss = 0.5596079566109349, disc_loss = 0.06466104026800218
Trained batch 142 in epoch 19, gen_loss = 0.5581602916850911, disc_loss = 0.06586184878418404
Trained batch 143 in epoch 19, gen_loss = 0.5574981259802977, disc_loss = 0.067170733478027
Trained batch 144 in epoch 19, gen_loss = 0.5572822731116722, disc_loss = 0.06716762708764973
Trained batch 145 in epoch 19, gen_loss = 0.5561276978417619, disc_loss = 0.06757213715790797
Trained batch 146 in epoch 19, gen_loss = 0.5551580665062885, disc_loss = 0.06800422791690965
Trained batch 147 in epoch 19, gen_loss = 0.5550681352615356, disc_loss = 0.06860491260453568
Trained batch 148 in epoch 19, gen_loss = 0.5541337152455477, disc_loss = 0.07092275345055761
Trained batch 149 in epoch 19, gen_loss = 0.5545708998044332, disc_loss = 0.07245440909833026
Trained batch 150 in epoch 19, gen_loss = 0.5539755750176133, disc_loss = 0.07311939274998604
Trained batch 151 in epoch 19, gen_loss = 0.5528793872187012, disc_loss = 0.07397849573087449
Testing Epoch 19
Training Epoch 20
Trained batch 0 in epoch 20, gen_loss = 0.5085175037384033, disc_loss = 0.2296973317861557
Trained batch 1 in epoch 20, gen_loss = 0.4709639698266983, disc_loss = 0.19185622781515121
Trained batch 2 in epoch 20, gen_loss = 0.45470115542411804, disc_loss = 0.17369363705317178
Trained batch 3 in epoch 20, gen_loss = 0.4486044570803642, disc_loss = 0.18434520810842514
Trained batch 4 in epoch 20, gen_loss = 0.4320515990257263, disc_loss = 0.18980591893196105
Trained batch 5 in epoch 20, gen_loss = 0.4402959942817688, disc_loss = 0.18769827236731848
Trained batch 6 in epoch 20, gen_loss = 0.439779064485005, disc_loss = 0.18655760799135482
Trained batch 7 in epoch 20, gen_loss = 0.4481462128460407, disc_loss = 0.18182924948632717
Trained batch 8 in epoch 20, gen_loss = 0.45097944802708095, disc_loss = 0.17084516916010115
Trained batch 9 in epoch 20, gen_loss = 0.46024349629878997, disc_loss = 0.16093602627515793
Trained batch 10 in epoch 20, gen_loss = 0.4573835026134144, disc_loss = 0.15675142813812604
Trained batch 11 in epoch 20, gen_loss = 0.4742058614889781, disc_loss = 0.16219525411725044
Trained batch 12 in epoch 20, gen_loss = 0.474869945874581, disc_loss = 0.15588396042585373
Trained batch 13 in epoch 20, gen_loss = 0.4713896321398871, disc_loss = 0.15675015162144387
Trained batch 14 in epoch 20, gen_loss = 0.4824115971724192, disc_loss = 0.16481400579214095
Trained batch 15 in epoch 20, gen_loss = 0.47941153310239315, disc_loss = 0.1624134057201445
Trained batch 16 in epoch 20, gen_loss = 0.4767143165363985, disc_loss = 0.16091577664894216
Trained batch 17 in epoch 20, gen_loss = 0.479855027463701, disc_loss = 0.16036545940571362
Trained batch 18 in epoch 20, gen_loss = 0.48076629795526205, disc_loss = 0.15515795036366112
Trained batch 19 in epoch 20, gen_loss = 0.4791226461529732, disc_loss = 0.1516404442489147
Trained batch 20 in epoch 20, gen_loss = 0.4844020023232415, disc_loss = 0.14646059115018165
Trained batch 21 in epoch 20, gen_loss = 0.4819514954631979, disc_loss = 0.14335359243506735
Trained batch 22 in epoch 20, gen_loss = 0.488532578167708, disc_loss = 0.1424422722471797
Trained batch 23 in epoch 20, gen_loss = 0.49110133325060207, disc_loss = 0.1372819672493885
Trained batch 24 in epoch 20, gen_loss = 0.4884622049331665, disc_loss = 0.13548064403235913
Trained batch 25 in epoch 20, gen_loss = 0.48694796516345096, disc_loss = 0.13674800950460708
Trained batch 26 in epoch 20, gen_loss = 0.4911177423265245, disc_loss = 0.13927811377302365
Trained batch 27 in epoch 20, gen_loss = 0.48897555470466614, disc_loss = 0.1403616932220757
Trained batch 28 in epoch 20, gen_loss = 0.49111782271286536, disc_loss = 0.1426290637845623
Trained batch 29 in epoch 20, gen_loss = 0.487924180428187, disc_loss = 0.14451581680526335
Trained batch 30 in epoch 20, gen_loss = 0.4889646345569241, disc_loss = 0.14524342209821747
Trained batch 31 in epoch 20, gen_loss = 0.49086992256343365, disc_loss = 0.14666303986450657
Trained batch 32 in epoch 20, gen_loss = 0.48989414085041394, disc_loss = 0.14604287159939608
Trained batch 33 in epoch 20, gen_loss = 0.4872274451396045, disc_loss = 0.14569479922818787
Trained batch 34 in epoch 20, gen_loss = 0.4911702445575169, disc_loss = 0.14592231634472097
Trained batch 35 in epoch 20, gen_loss = 0.48860472440719604, disc_loss = 0.1462645985496541
Trained batch 36 in epoch 20, gen_loss = 0.48633114147830653, disc_loss = 0.14735470465510278
Trained batch 37 in epoch 20, gen_loss = 0.48830498284415197, disc_loss = 0.15102956360696176
Trained batch 38 in epoch 20, gen_loss = 0.4881093807709523, disc_loss = 0.1520638816918318
Trained batch 39 in epoch 20, gen_loss = 0.4887323424220085, disc_loss = 0.15073184981010854
Trained batch 40 in epoch 20, gen_loss = 0.4866156359998191, disc_loss = 0.1519117345806302
Trained batch 41 in epoch 20, gen_loss = 0.4892913060528891, disc_loss = 0.15313254381042152
Trained batch 42 in epoch 20, gen_loss = 0.491706347742746, disc_loss = 0.15029200049507063
Trained batch 43 in epoch 20, gen_loss = 0.4920930577950044, disc_loss = 0.1475081087344072
Trained batch 44 in epoch 20, gen_loss = 0.4916837480333116, disc_loss = 0.14493053108453752
Trained batch 45 in epoch 20, gen_loss = 0.4927330975947173, disc_loss = 0.14241046745977973
Trained batch 46 in epoch 20, gen_loss = 0.4955875429701298, disc_loss = 0.14017608607227497
Trained batch 47 in epoch 20, gen_loss = 0.4983944408595562, disc_loss = 0.1377190756611526
Trained batch 48 in epoch 20, gen_loss = 0.5011113115719387, disc_loss = 0.13535080641051944
Trained batch 49 in epoch 20, gen_loss = 0.5041565263271331, disc_loss = 0.13280521234497428
Trained batch 50 in epoch 20, gen_loss = 0.5063500112178279, disc_loss = 0.13031086664391206
Trained batch 51 in epoch 20, gen_loss = 0.5082828035721412, disc_loss = 0.12788491771341517
Trained batch 52 in epoch 20, gen_loss = 0.5093754529953003, disc_loss = 0.1255838772510442
Trained batch 53 in epoch 20, gen_loss = 0.5116131967968411, disc_loss = 0.12333928300412716
Trained batch 54 in epoch 20, gen_loss = 0.5135498762130737, disc_loss = 0.12118763688274405
Trained batch 55 in epoch 20, gen_loss = 0.5137359542506081, disc_loss = 0.11961246383309897
Trained batch 56 in epoch 20, gen_loss = 0.5154576081978647, disc_loss = 0.11778515198251657
Trained batch 57 in epoch 20, gen_loss = 0.5190049163226423, disc_loss = 0.11637827754020691
Trained batch 58 in epoch 20, gen_loss = 0.5209149475825035, disc_loss = 0.11452189805301821
Trained batch 59 in epoch 20, gen_loss = 0.5219674915075302, disc_loss = 0.11284255923237652
Trained batch 60 in epoch 20, gen_loss = 0.5219365016358798, disc_loss = 0.11138785673977165
Trained batch 61 in epoch 20, gen_loss = 0.5226255088083206, disc_loss = 0.10986038790865531
Trained batch 62 in epoch 20, gen_loss = 0.5271941196350824, disc_loss = 0.10923045129323053
Trained batch 63 in epoch 20, gen_loss = 0.5295440796762705, disc_loss = 0.10793567143991822
Trained batch 64 in epoch 20, gen_loss = 0.530855629994319, disc_loss = 0.10637551884954939
Trained batch 65 in epoch 20, gen_loss = 0.5316393321210687, disc_loss = 0.10496080276612757
Trained batch 66 in epoch 20, gen_loss = 0.5329138369702581, disc_loss = 0.10348746182619413
Trained batch 67 in epoch 20, gen_loss = 0.5329734744394526, disc_loss = 0.10214086767861291
Trained batch 68 in epoch 20, gen_loss = 0.5331165453662043, disc_loss = 0.10076975646982159
Trained batch 69 in epoch 20, gen_loss = 0.5345468802111489, disc_loss = 0.099398779243763
Trained batch 70 in epoch 20, gen_loss = 0.5360999468346717, disc_loss = 0.0980638011332444
Trained batch 71 in epoch 20, gen_loss = 0.5370496859153112, disc_loss = 0.09676293978959115
Trained batch 72 in epoch 20, gen_loss = 0.5378565543318448, disc_loss = 0.09551918589548297
Trained batch 73 in epoch 20, gen_loss = 0.5384720797474319, disc_loss = 0.09428757427235109
Trained batch 74 in epoch 20, gen_loss = 0.5387652786572774, disc_loss = 0.09314108506465951
Trained batch 75 in epoch 20, gen_loss = 0.5388172833543075, disc_loss = 0.09206843099826456
Trained batch 76 in epoch 20, gen_loss = 0.5392440147214121, disc_loss = 0.0909659996713427
Trained batch 77 in epoch 20, gen_loss = 0.5401699237334423, disc_loss = 0.08985298568120179
Trained batch 78 in epoch 20, gen_loss = 0.5413074734844739, disc_loss = 0.08876428190807376
Trained batch 79 in epoch 20, gen_loss = 0.5425635635852813, disc_loss = 0.0877237172331661
Trained batch 80 in epoch 20, gen_loss = 0.5425080465681759, disc_loss = 0.08670121399156841
Trained batch 81 in epoch 20, gen_loss = 0.5428393301440448, disc_loss = 0.08568387001571132
Trained batch 82 in epoch 20, gen_loss = 0.5429527055786316, disc_loss = 0.08469701361427286
Trained batch 83 in epoch 20, gen_loss = 0.5433514955497923, disc_loss = 0.08384535112972594
Trained batch 84 in epoch 20, gen_loss = 0.5441942355212044, disc_loss = 0.0828993375906173
Trained batch 85 in epoch 20, gen_loss = 0.5449279359606809, disc_loss = 0.08202352930336844
Trained batch 86 in epoch 20, gen_loss = 0.546556825610413, disc_loss = 0.08117157854568
Trained batch 87 in epoch 20, gen_loss = 0.5482768734747713, disc_loss = 0.08032901002496312
Trained batch 88 in epoch 20, gen_loss = 0.5492225784933968, disc_loss = 0.07947311054894261
Trained batch 89 in epoch 20, gen_loss = 0.5494479954242706, disc_loss = 0.07868624052757191
Trained batch 90 in epoch 20, gen_loss = 0.549492651944632, disc_loss = 0.07808116463698693
Trained batch 91 in epoch 20, gen_loss = 0.5508908208297647, disc_loss = 0.07763324654154966
Trained batch 92 in epoch 20, gen_loss = 0.5527677952602346, disc_loss = 0.07694851182982006
Trained batch 93 in epoch 20, gen_loss = 0.5537872726612902, disc_loss = 0.07618971338911736
Trained batch 94 in epoch 20, gen_loss = 0.5545714127390008, disc_loss = 0.07544127920838563
Trained batch 95 in epoch 20, gen_loss = 0.5545749602218469, disc_loss = 0.07470633852062747
Trained batch 96 in epoch 20, gen_loss = 0.5546869875229511, disc_loss = 0.07396936993901954
Trained batch 97 in epoch 20, gen_loss = 0.5548691104869453, disc_loss = 0.0732653809887148
Trained batch 98 in epoch 20, gen_loss = 0.5548628484359895, disc_loss = 0.0725525398715164
Trained batch 99 in epoch 20, gen_loss = 0.5549771553277969, disc_loss = 0.07184875009814277
Trained batch 100 in epoch 20, gen_loss = 0.5553009569054783, disc_loss = 0.0712049784632123
Trained batch 101 in epoch 20, gen_loss = 0.5559225094084647, disc_loss = 0.07053231732125449
Trained batch 102 in epoch 20, gen_loss = 0.5562420475830152, disc_loss = 0.06988901207992101
Trained batch 103 in epoch 20, gen_loss = 0.5564081193162844, disc_loss = 0.06923431016912218
Trained batch 104 in epoch 20, gen_loss = 0.5565558717364356, disc_loss = 0.06859595552641189
Trained batch 105 in epoch 20, gen_loss = 0.556649385758166, disc_loss = 0.06796763694234509
Trained batch 106 in epoch 20, gen_loss = 0.5568207641628301, disc_loss = 0.0673525116077807
Trained batch 107 in epoch 20, gen_loss = 0.5567280114800842, disc_loss = 0.06674536175409297
Trained batch 108 in epoch 20, gen_loss = 0.5569569140399268, disc_loss = 0.06615092031286021
Trained batch 109 in epoch 20, gen_loss = 0.5569560581987555, disc_loss = 0.0655676843503236
Trained batch 110 in epoch 20, gen_loss = 0.5572110151385402, disc_loss = 0.06499499093367811
Trained batch 111 in epoch 20, gen_loss = 0.5574980229139328, disc_loss = 0.064434769890795
Trained batch 112 in epoch 20, gen_loss = 0.5576805087317408, disc_loss = 0.06388450500996272
Trained batch 113 in epoch 20, gen_loss = 0.5575191535447773, disc_loss = 0.06333935854695084
Trained batch 114 in epoch 20, gen_loss = 0.5570046440414761, disc_loss = 0.06282336264848709
Trained batch 115 in epoch 20, gen_loss = 0.5572813209788553, disc_loss = 0.06230531630090213
Trained batch 116 in epoch 20, gen_loss = 0.557459722726773, disc_loss = 0.06178883419762182
Trained batch 117 in epoch 20, gen_loss = 0.5580586391990467, disc_loss = 0.06127970386296511
Trained batch 118 in epoch 20, gen_loss = 0.5583882527191097, disc_loss = 0.06077968611718476
Trained batch 119 in epoch 20, gen_loss = 0.5580136989553769, disc_loss = 0.06029485160640131
Trained batch 120 in epoch 20, gen_loss = 0.5584517342985169, disc_loss = 0.05982296933489274
Trained batch 121 in epoch 20, gen_loss = 0.5587384627490747, disc_loss = 0.059350632112015224
Trained batch 122 in epoch 20, gen_loss = 0.5588003145000799, disc_loss = 0.058884819647736425
Trained batch 123 in epoch 20, gen_loss = 0.5587583982175396, disc_loss = 0.058426501244426735
Trained batch 124 in epoch 20, gen_loss = 0.5590667157173157, disc_loss = 0.05799081660062075
Trained batch 125 in epoch 20, gen_loss = 0.5591881748229738, disc_loss = 0.057545801241224305
Trained batch 126 in epoch 20, gen_loss = 0.5595064247687032, disc_loss = 0.05710805430146682
Trained batch 127 in epoch 20, gen_loss = 0.5595766128972173, disc_loss = 0.05667723022361315
Trained batch 128 in epoch 20, gen_loss = 0.5597761684609938, disc_loss = 0.056257108808495104
Trained batch 129 in epoch 20, gen_loss = 0.5601553981120769, disc_loss = 0.05584038966783107
Trained batch 130 in epoch 20, gen_loss = 0.5602977303148226, disc_loss = 0.05542471587661483
Trained batch 131 in epoch 20, gen_loss = 0.5605070572910886, disc_loss = 0.0550221527977776
Trained batch 132 in epoch 20, gen_loss = 0.560615080639832, disc_loss = 0.05462929995860064
Trained batch 133 in epoch 20, gen_loss = 0.5606452956128476, disc_loss = 0.05423718997809007
Trained batch 134 in epoch 20, gen_loss = 0.5612241427103678, disc_loss = 0.053848439890511884
Trained batch 135 in epoch 20, gen_loss = 0.5618067694937482, disc_loss = 0.05348858622549896
Trained batch 136 in epoch 20, gen_loss = 0.5621048586211935, disc_loss = 0.053110244160477264
Trained batch 137 in epoch 20, gen_loss = 0.5620840964973837, disc_loss = 0.052744393122206995
Trained batch 138 in epoch 20, gen_loss = 0.561820675143235, disc_loss = 0.05237639451436296
Trained batch 139 in epoch 20, gen_loss = 0.5617948659828731, disc_loss = 0.052013617163590556
Trained batch 140 in epoch 20, gen_loss = 0.5616937778520246, disc_loss = 0.051654297174846237
Trained batch 141 in epoch 20, gen_loss = 0.5615817325215944, disc_loss = 0.05130070229356085
Trained batch 142 in epoch 20, gen_loss = 0.5615598646910874, disc_loss = 0.050953338163663875
Trained batch 143 in epoch 20, gen_loss = 0.561709980169932, disc_loss = 0.05061183723996186
Trained batch 144 in epoch 20, gen_loss = 0.5617591224867722, disc_loss = 0.05027602819950673
Trained batch 145 in epoch 20, gen_loss = 0.5616790786997913, disc_loss = 0.04994171921782553
Trained batch 146 in epoch 20, gen_loss = 0.5618153230673602, disc_loss = 0.04961148486789443
Trained batch 147 in epoch 20, gen_loss = 0.5616389517043088, disc_loss = 0.04928608409859039
Trained batch 148 in epoch 20, gen_loss = 0.5618846588486793, disc_loss = 0.048966574309168745
Trained batch 149 in epoch 20, gen_loss = 0.5620916696389516, disc_loss = 0.04865268051934739
Trained batch 150 in epoch 20, gen_loss = 0.5621022803104476, disc_loss = 0.04833861928439347
Trained batch 151 in epoch 20, gen_loss = 0.5621969256746141, disc_loss = 0.04802793033549709
Testing Epoch 20
/work3/soeba/HALOS/utils.py:112: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axs = plt.subplots(batch_size, 4, figsize=(8,10))
Training Epoch 21
Trained batch 0 in epoch 21, gen_loss = 0.6069089770317078, disc_loss = 0.002221342409029603
Trained batch 1 in epoch 21, gen_loss = 0.6047457158565521, disc_loss = 0.0025511877611279488
Trained batch 2 in epoch 21, gen_loss = 0.5958980917930603, disc_loss = 0.0021272270241752267
Trained batch 3 in epoch 21, gen_loss = 0.5919286012649536, disc_loss = 0.001987004972761497
Trained batch 4 in epoch 21, gen_loss = 0.5868234634399414, disc_loss = 0.0019428695319220423
Trained batch 5 in epoch 21, gen_loss = 0.5796871980031332, disc_loss = 0.0018683846768302221
Trained batch 6 in epoch 21, gen_loss = 0.5776205999510629, disc_loss = 0.0018069555683593666
Trained batch 7 in epoch 21, gen_loss = 0.5777634307742119, disc_loss = 0.0017612296069273725
Trained batch 8 in epoch 21, gen_loss = 0.5787164039081998, disc_loss = 0.001700132089253101
Trained batch 9 in epoch 21, gen_loss = 0.5775376796722412, disc_loss = 0.0016449467395432294
Trained batch 10 in epoch 21, gen_loss = 0.573963696306402, disc_loss = 0.0023609691151333127
Trained batch 11 in epoch 21, gen_loss = 0.5761675933996836, disc_loss = 0.0023702750040683895
Trained batch 12 in epoch 21, gen_loss = 0.5755328948681171, disc_loss = 0.0023854112413783488
Trained batch 13 in epoch 21, gen_loss = 0.5741521162646157, disc_loss = 0.0023500334770817843
Trained batch 14 in epoch 21, gen_loss = 0.5764455238978068, disc_loss = 0.0023360388508687417
Trained batch 15 in epoch 21, gen_loss = 0.5771347507834435, disc_loss = 0.0023106692678993568
Trained batch 16 in epoch 21, gen_loss = 0.578495979309082, disc_loss = 0.002387887003886349
Trained batch 17 in epoch 21, gen_loss = 0.5795517497592502, disc_loss = 0.0024429282639175653
Trained batch 18 in epoch 21, gen_loss = 0.5783801141538119, disc_loss = 0.0024329313616219318
Trained batch 19 in epoch 21, gen_loss = 0.5780581563711167, disc_loss = 0.0023841206915676595
Trained batch 20 in epoch 21, gen_loss = 0.5748763879140218, disc_loss = 0.0023579130370524667
Trained batch 21 in epoch 21, gen_loss = 0.5768449848348444, disc_loss = 0.0023528805785727773
Trained batch 22 in epoch 21, gen_loss = 0.5769309867983279, disc_loss = 0.002329600068902516
Trained batch 23 in epoch 21, gen_loss = 0.5777716810504595, disc_loss = 0.002313653409752684
Trained batch 24 in epoch 21, gen_loss = 0.5783635210990906, disc_loss = 0.002268017022870481
Trained batch 25 in epoch 21, gen_loss = 0.579496674812757, disc_loss = 0.0022323426136818644
Trained batch 26 in epoch 21, gen_loss = 0.580345008108351, disc_loss = 0.002201271627132815
Trained batch 27 in epoch 21, gen_loss = 0.5794727291379657, disc_loss = 0.0021623360267507712
Trained batch 28 in epoch 21, gen_loss = 0.5801322583494515, disc_loss = 0.0021629599525175734
Trained batch 29 in epoch 21, gen_loss = 0.5817124247550964, disc_loss = 0.002143813269988944
Trained batch 30 in epoch 21, gen_loss = 0.5807150467749564, disc_loss = 0.0021153695490812104
Trained batch 31 in epoch 21, gen_loss = 0.5809377729892731, disc_loss = 0.0020823062222916633
Trained batch 32 in epoch 21, gen_loss = 0.5800219358819904, disc_loss = 0.002068251554825992
Trained batch 33 in epoch 21, gen_loss = 0.5795066531966714, disc_loss = 0.0020488412701524794
Trained batch 34 in epoch 21, gen_loss = 0.5795022538730077, disc_loss = 0.0020424486437280263
Trained batch 35 in epoch 21, gen_loss = 0.579716243677669, disc_loss = 0.0020390711045668772
Trained batch 36 in epoch 21, gen_loss = 0.5783945724770829, disc_loss = 0.002041265560389572
Trained batch 37 in epoch 21, gen_loss = 0.5782192490602794, disc_loss = 0.002022594642384272
Trained batch 38 in epoch 21, gen_loss = 0.5792972842852274, disc_loss = 0.0020116589670905317
Trained batch 39 in epoch 21, gen_loss = 0.5792369455099106, disc_loss = 0.0020049351354828105
Trained batch 40 in epoch 21, gen_loss = 0.5794235758665132, disc_loss = 0.0019894267415355256
Trained batch 41 in epoch 21, gen_loss = 0.5789576087679181, disc_loss = 0.0019695620811987845
Trained batch 42 in epoch 21, gen_loss = 0.5794238739235457, disc_loss = 0.0019541735798770258
Trained batch 43 in epoch 21, gen_loss = 0.580174592408267, disc_loss = 0.001941679971588945
Trained batch 44 in epoch 21, gen_loss = 0.5807332754135132, disc_loss = 0.0019331300062023931
Trained batch 45 in epoch 21, gen_loss = 0.5806078211120937, disc_loss = 0.0019261050189885757
Trained batch 46 in epoch 21, gen_loss = 0.580108311582119, disc_loss = 0.001906346556968353
Trained batch 47 in epoch 21, gen_loss = 0.5802780439456304, disc_loss = 0.0018945154758209053
Trained batch 48 in epoch 21, gen_loss = 0.5804823040962219, disc_loss = 0.0018966167105589897
Trained batch 49 in epoch 21, gen_loss = 0.5796553552150726, disc_loss = 0.001888779231812805
Trained batch 50 in epoch 21, gen_loss = 0.580117360049603, disc_loss = 0.0018800005668262933
Trained batch 51 in epoch 21, gen_loss = 0.5808587865187571, disc_loss = 0.0018761006716746264
Trained batch 52 in epoch 21, gen_loss = 0.5809219850684112, disc_loss = 0.0018632950410598292
Trained batch 53 in epoch 21, gen_loss = 0.5806448404435758, disc_loss = 0.0018502830902838872
Trained batch 54 in epoch 21, gen_loss = 0.5800421205433932, disc_loss = 0.0018322569783776998
Trained batch 55 in epoch 21, gen_loss = 0.5796384481447083, disc_loss = 0.0018196772413960258
Trained batch 56 in epoch 21, gen_loss = 0.5796931124570077, disc_loss = 0.0018107523394160364
Trained batch 57 in epoch 21, gen_loss = 0.5799271844584366, disc_loss = 0.0018121909876032893
Trained batch 58 in epoch 21, gen_loss = 0.5803700978473082, disc_loss = 0.001801842616444801
Trained batch 59 in epoch 21, gen_loss = 0.5806890438000362, disc_loss = 0.001792119670426473
Trained batch 60 in epoch 21, gen_loss = 0.5799139874880431, disc_loss = 0.001778220982084692
Trained batch 61 in epoch 21, gen_loss = 0.5794416319939398, disc_loss = 0.00176796990713375
Trained batch 62 in epoch 21, gen_loss = 0.5787921879026625, disc_loss = 0.0017683443230842905
Trained batch 63 in epoch 21, gen_loss = 0.5783446356654167, disc_loss = 0.0017605273505978403
Trained batch 64 in epoch 21, gen_loss = 0.5787859311470619, disc_loss = 0.0017532765766820656
Trained batch 65 in epoch 21, gen_loss = 0.5795170213236953, disc_loss = 0.0017623897389664005
Trained batch 66 in epoch 21, gen_loss = 0.5788954069365316, disc_loss = 0.0017596924592351625
Trained batch 67 in epoch 21, gen_loss = 0.5788630019215977, disc_loss = 0.0017824651534764974
Trained batch 68 in epoch 21, gen_loss = 0.5788891920145007, disc_loss = 0.0017897792901182413
Trained batch 69 in epoch 21, gen_loss = 0.5790987585272108, disc_loss = 0.001783891553558143
Trained batch 70 in epoch 21, gen_loss = 0.579738911608575, disc_loss = 0.0017849937676530803
Trained batch 71 in epoch 21, gen_loss = 0.5794107127520773, disc_loss = 0.0017729757196826136
Trained batch 72 in epoch 21, gen_loss = 0.579398512840271, disc_loss = 0.0017763703721830595
Trained batch 73 in epoch 21, gen_loss = 0.5794156016530218, disc_loss = 0.001789884439612915
Trained batch 74 in epoch 21, gen_loss = 0.5797189521789551, disc_loss = 0.0017913232425538202
Trained batch 75 in epoch 21, gen_loss = 0.580304387368654, disc_loss = 0.0017830923829215432
Trained batch 76 in epoch 21, gen_loss = 0.5808780193328857, disc_loss = 0.0017797558669714474
Trained batch 77 in epoch 21, gen_loss = 0.5810482104619344, disc_loss = 0.0017793193222202647
Trained batch 78 in epoch 21, gen_loss = 0.5811050285266924, disc_loss = 0.0017772693226785882
Trained batch 79 in epoch 21, gen_loss = 0.5804013922810555, disc_loss = 0.0017678587879345286
Trained batch 80 in epoch 21, gen_loss = 0.5808684237209367, disc_loss = 0.0017717013970580827
Trained batch 81 in epoch 21, gen_loss = 0.5810708200059286, disc_loss = 0.0017709614568469456
Trained batch 82 in epoch 21, gen_loss = 0.5807804142136171, disc_loss = 0.0017695957689590931
Trained batch 83 in epoch 21, gen_loss = 0.5811252679143634, disc_loss = 0.0018011764075795543
Trained batch 84 in epoch 21, gen_loss = 0.581205872928395, disc_loss = 0.0018022172913119635
Trained batch 85 in epoch 21, gen_loss = 0.5813107206377872, disc_loss = 0.001797047424059751
Trained batch 86 in epoch 21, gen_loss = 0.5816006132926064, disc_loss = 0.0018007569463291987
Trained batch 87 in epoch 21, gen_loss = 0.5815831375393, disc_loss = 0.0017939654955460521
Trained batch 88 in epoch 21, gen_loss = 0.5815760399518388, disc_loss = 0.0017875142211063106
Trained batch 89 in epoch 21, gen_loss = 0.5820146408345964, disc_loss = 0.0017920411288893472
Trained batch 90 in epoch 21, gen_loss = 0.58216026196113, disc_loss = 0.0018097103085972697
Trained batch 91 in epoch 21, gen_loss = 0.5815084330413652, disc_loss = 0.0019576590623372517
Trained batch 92 in epoch 21, gen_loss = 0.5840577015312769, disc_loss = 0.0020040478300733834
Trained batch 93 in epoch 21, gen_loss = 0.5861320020036495, disc_loss = 0.0020341073959184055
Trained batch 94 in epoch 21, gen_loss = 0.5874804477942618, disc_loss = 0.002037318452187863
Trained batch 95 in epoch 21, gen_loss = 0.5886304434388876, disc_loss = 0.002035625995025233
Trained batch 96 in epoch 21, gen_loss = 0.5882673662962373, disc_loss = 0.0021100417145566304
Trained batch 97 in epoch 21, gen_loss = 0.5882723751116772, disc_loss = 0.0021495763907370593
Trained batch 98 in epoch 21, gen_loss = 0.5885285692985611, disc_loss = 0.002165721261972618
Trained batch 99 in epoch 21, gen_loss = 0.5876662427186966, disc_loss = 0.002936680208076723
Trained batch 100 in epoch 21, gen_loss = 0.5896363122628467, disc_loss = 0.005467557268203374
Trained batch 101 in epoch 21, gen_loss = 0.5911802298882428, disc_loss = 0.005452782475485411
Trained batch 102 in epoch 21, gen_loss = 0.5919628125949971, disc_loss = 0.005476488644207457
Trained batch 103 in epoch 21, gen_loss = 0.5928641895835216, disc_loss = 0.00547446002747165
Trained batch 104 in epoch 21, gen_loss = 0.5935967757588341, disc_loss = 0.005452309092617638
Trained batch 105 in epoch 21, gen_loss = 0.5938391792324355, disc_loss = 0.005449770190335705
Trained batch 106 in epoch 21, gen_loss = 0.5945751126681533, disc_loss = 0.005431875191024008
Trained batch 107 in epoch 21, gen_loss = 0.5950605974153236, disc_loss = 0.005415296583561468
Trained batch 108 in epoch 21, gen_loss = 0.594797567490044, disc_loss = 0.005421983792100512
Trained batch 109 in epoch 21, gen_loss = 0.5940511015328493, disc_loss = 0.005517578849420798
Trained batch 110 in epoch 21, gen_loss = 0.594657968830418, disc_loss = 0.005547522974666208
Trained batch 111 in epoch 21, gen_loss = 0.5953295518245015, disc_loss = 0.005543155197041675
Trained batch 112 in epoch 21, gen_loss = 0.59529645727799, disc_loss = 0.005539190993063251
Trained batch 113 in epoch 21, gen_loss = 0.5953984187360395, disc_loss = 0.00553315370231295
Trained batch 114 in epoch 21, gen_loss = 0.5954070956810661, disc_loss = 0.005499461619689575
Trained batch 115 in epoch 21, gen_loss = 0.5954434095785536, disc_loss = 0.005475850999134529
Trained batch 116 in epoch 21, gen_loss = 0.5953315776637477, disc_loss = 0.005447191003666251
Trained batch 117 in epoch 21, gen_loss = 0.59489192952544, disc_loss = 0.00541872973800479
Trained batch 118 in epoch 21, gen_loss = 0.5947882267607361, disc_loss = 0.005395033645752755
Trained batch 119 in epoch 21, gen_loss = 0.5945145527521769, disc_loss = 0.005369923405911929
Trained batch 120 in epoch 21, gen_loss = 0.5945250992932596, disc_loss = 0.00534572531825147
Trained batch 121 in epoch 21, gen_loss = 0.5932419859483594, disc_loss = 0.0060662258913564936
Trained batch 122 in epoch 21, gen_loss = 0.5933175845359399, disc_loss = 0.006618380420216609
Trained batch 123 in epoch 21, gen_loss = 0.5930349036089836, disc_loss = 0.0067913734092144296
Trained batch 124 in epoch 21, gen_loss = 0.5926588752269745, disc_loss = 0.006989430154208094
Trained batch 125 in epoch 21, gen_loss = 0.5928739699579421, disc_loss = 0.006978497177543532
Trained batch 126 in epoch 21, gen_loss = 0.5932964933669473, disc_loss = 0.006967500122135695
Trained batch 127 in epoch 21, gen_loss = 0.5921124308370054, disc_loss = 0.007400606706596591
Trained batch 128 in epoch 21, gen_loss = 0.5924598057140675, disc_loss = 0.008551788255085
Trained batch 129 in epoch 21, gen_loss = 0.5923748002602504, disc_loss = 0.008622217513710404
Trained batch 130 in epoch 21, gen_loss = 0.5918595158416806, disc_loss = 0.009051416544261467
Trained batch 131 in epoch 21, gen_loss = 0.5906049435337385, disc_loss = 0.01036214511568136
Trained batch 132 in epoch 21, gen_loss = 0.5921949531350817, disc_loss = 0.01505410222247369
Trained batch 133 in epoch 21, gen_loss = 0.5921372973652028, disc_loss = 0.016108711700584154
Trained batch 134 in epoch 21, gen_loss = 0.5906775414943695, disc_loss = 0.01728866938372246
Trained batch 135 in epoch 21, gen_loss = 0.5896489149069085, disc_loss = 0.01776134649245411
Trained batch 136 in epoch 21, gen_loss = 0.5889014564726475, disc_loss = 0.018338599716853622
Trained batch 137 in epoch 21, gen_loss = 0.5880533661963283, disc_loss = 0.018774087384319526
Trained batch 138 in epoch 21, gen_loss = 0.587351611406683, disc_loss = 0.019126168893157713
Trained batch 139 in epoch 21, gen_loss = 0.586839369578021, disc_loss = 0.019181891935295424
Trained batch 140 in epoch 21, gen_loss = 0.586341512330035, disc_loss = 0.019237409344567184
Trained batch 141 in epoch 21, gen_loss = 0.5849964096092842, disc_loss = 0.019878636775489136
Trained batch 142 in epoch 21, gen_loss = 0.5859145369979885, disc_loss = 0.021157915455246853
Trained batch 143 in epoch 21, gen_loss = 0.5857630672140254, disc_loss = 0.02133107820999511
Trained batch 144 in epoch 21, gen_loss = 0.5854200122685268, disc_loss = 0.021395664012204083
Trained batch 145 in epoch 21, gen_loss = 0.5847817998226374, disc_loss = 0.021490230230209482
Trained batch 146 in epoch 21, gen_loss = 0.5842120408200894, disc_loss = 0.02153251446081883
Trained batch 147 in epoch 21, gen_loss = 0.5826899850287953, disc_loss = 0.022782160213446822
Trained batch 148 in epoch 21, gen_loss = 0.582728324920539, disc_loss = 0.023757616738123107
Trained batch 149 in epoch 21, gen_loss = 0.582216312289238, disc_loss = 0.024226076992927118
Trained batch 150 in epoch 21, gen_loss = 0.5830667873486778, disc_loss = 0.024521727576336843
Trained batch 151 in epoch 21, gen_loss = 0.5834631549292489, disc_loss = 0.024399959631218257
Testing Epoch 21
Training Epoch 22
Trained batch 0 in epoch 22, gen_loss = 0.5772297978401184, disc_loss = 0.01584671437740326
Trained batch 1 in epoch 22, gen_loss = 0.5499503314495087, disc_loss = 0.016236066818237305
Trained batch 2 in epoch 22, gen_loss = 0.5492936174074808, disc_loss = 0.01549910195171833
Trained batch 3 in epoch 22, gen_loss = 0.5605656504631042, disc_loss = 0.012481278274208307
Trained batch 4 in epoch 22, gen_loss = 0.5711776494979859, disc_loss = 0.011025761440396308
Trained batch 5 in epoch 22, gen_loss = 0.558766966064771, disc_loss = 0.011355339549481869
Trained batch 6 in epoch 22, gen_loss = 0.5579135460512978, disc_loss = 0.010627643138702427
Trained batch 7 in epoch 22, gen_loss = 0.5461424700915813, disc_loss = 0.02373927814187482
Trained batch 8 in epoch 22, gen_loss = 0.5532334347565969, disc_loss = 0.05266171678279837
Trained batch 9 in epoch 22, gen_loss = 0.5573424428701401, disc_loss = 0.048925625858828425
Trained batch 10 in epoch 22, gen_loss = 0.5597772137685255, disc_loss = 0.04517560968683525
Trained batch 11 in epoch 22, gen_loss = 0.5645816996693611, disc_loss = 0.04200136265717447
Trained batch 12 in epoch 22, gen_loss = 0.5687347719302545, disc_loss = 0.03916113633805743
Trained batch 13 in epoch 22, gen_loss = 0.5740492109741483, disc_loss = 0.036641220595421534
Trained batch 14 in epoch 22, gen_loss = 0.5742130060990651, disc_loss = 0.03485782186811169
Trained batch 15 in epoch 22, gen_loss = 0.5721278805285692, disc_loss = 0.034208006953122094
Trained batch 16 in epoch 22, gen_loss = 0.5696460236521328, disc_loss = 0.03372041346943554
Trained batch 17 in epoch 22, gen_loss = 0.5751364015870624, disc_loss = 0.03345823538903561
Trained batch 18 in epoch 22, gen_loss = 0.5761505161461077, disc_loss = 0.03231205960343543
Trained batch 19 in epoch 22, gen_loss = 0.5771156951785088, disc_loss = 0.030942724901251495
Trained batch 20 in epoch 22, gen_loss = 0.5796054587477729, disc_loss = 0.029733410171632255
Trained batch 21 in epoch 22, gen_loss = 0.5742920406840064, disc_loss = 0.03156852652318776
Trained batch 22 in epoch 22, gen_loss = 0.5795215769954349, disc_loss = 0.03627076289495048
Trained batch 23 in epoch 22, gen_loss = 0.5769928631683191, disc_loss = 0.03528370209581529
Trained batch 24 in epoch 22, gen_loss = 0.5776704347133637, disc_loss = 0.03439006576314568
Trained batch 25 in epoch 22, gen_loss = 0.5729229003190994, disc_loss = 0.03412143658631696
Trained batch 26 in epoch 22, gen_loss = 0.5748285750548044, disc_loss = 0.033852048304483844
Trained batch 27 in epoch 22, gen_loss = 0.5785854150141988, disc_loss = 0.03349780485898789
Trained batch 28 in epoch 22, gen_loss = 0.576386958360672, disc_loss = 0.033451649729676285
Trained batch 29 in epoch 22, gen_loss = 0.5761565536260604, disc_loss = 0.03316366382253667
Trained batch 30 in epoch 22, gen_loss = 0.5794387296322854, disc_loss = 0.03321715860417293
Trained batch 31 in epoch 22, gen_loss = 0.5816321903839707, disc_loss = 0.032326689251931384
Trained batch 32 in epoch 22, gen_loss = 0.581570694843928, disc_loss = 0.03170293865894729
Trained batch 33 in epoch 22, gen_loss = 0.5781120175824446, disc_loss = 0.03253183779580628
Trained batch 34 in epoch 22, gen_loss = 0.5802766365664346, disc_loss = 0.0349329037591815
Trained batch 35 in epoch 22, gen_loss = 0.5816815437542068, disc_loss = 0.03415130431919048
Trained batch 36 in epoch 22, gen_loss = 0.5815681420467995, disc_loss = 0.033437571953982115
Trained batch 37 in epoch 22, gen_loss = 0.5808241500666267, disc_loss = 0.03272295824105018
Trained batch 38 in epoch 22, gen_loss = 0.5817927007491772, disc_loss = 0.031961633161140174
Trained batch 39 in epoch 22, gen_loss = 0.5814802654087543, disc_loss = 0.0312213477329351
Trained batch 40 in epoch 22, gen_loss = 0.5810033642664189, disc_loss = 0.030573628490745294
Trained batch 41 in epoch 22, gen_loss = 0.5795823981364568, disc_loss = 0.030139051921044786
Trained batch 42 in epoch 22, gen_loss = 0.5762713059436443, disc_loss = 0.03229411276663805
Trained batch 43 in epoch 22, gen_loss = 0.5788380280137062, disc_loss = 0.033224590979939836
Trained batch 44 in epoch 22, gen_loss = 0.579800319009357, disc_loss = 0.03358060428872704
Trained batch 45 in epoch 22, gen_loss = 0.5800092680298764, disc_loss = 0.03309305256192127
Trained batch 46 in epoch 22, gen_loss = 0.5789133811250646, disc_loss = 0.032620028186430956
Trained batch 47 in epoch 22, gen_loss = 0.5783064570277929, disc_loss = 0.03221218622638844
Trained batch 48 in epoch 22, gen_loss = 0.5781640367848533, disc_loss = 0.03176779869221607
Trained batch 49 in epoch 22, gen_loss = 0.5751391631364823, disc_loss = 0.032725735967978835
Trained batch 50 in epoch 22, gen_loss = 0.5785447294805565, disc_loss = 0.03517112492894133
Trained batch 51 in epoch 22, gen_loss = 0.5807557042974693, disc_loss = 0.03462922434286716
Trained batch 52 in epoch 22, gen_loss = 0.5802970185594739, disc_loss = 0.03411100659835732
Trained batch 53 in epoch 22, gen_loss = 0.5777346508370506, disc_loss = 0.037144851586264044
Trained batch 54 in epoch 22, gen_loss = 0.5780353150584481, disc_loss = 0.03894960821860216
Trained batch 55 in epoch 22, gen_loss = 0.577811668493918, disc_loss = 0.03878095645424245
Trained batch 56 in epoch 22, gen_loss = 0.575447761698773, disc_loss = 0.039030319496401046
Trained batch 57 in epoch 22, gen_loss = 0.5725539372912769, disc_loss = 0.039992358270582964
Trained batch 58 in epoch 22, gen_loss = 0.57183360093731, disc_loss = 0.04147696860481875
Trained batch 59 in epoch 22, gen_loss = 0.5737503811717033, disc_loss = 0.041379380218374236
Trained batch 60 in epoch 22, gen_loss = 0.5752028407620602, disc_loss = 0.0408465539746475
Trained batch 61 in epoch 22, gen_loss = 0.5756890605534276, disc_loss = 0.040303886169567704
Trained batch 62 in epoch 22, gen_loss = 0.5761375659041934, disc_loss = 0.03974472170340873
Trained batch 63 in epoch 22, gen_loss = 0.5761048444546759, disc_loss = 0.03919798362039728
Trained batch 64 in epoch 22, gen_loss = 0.5758049070835114, disc_loss = 0.038626249209762764
Trained batch 65 in epoch 22, gen_loss = 0.5751193621844957, disc_loss = 0.03806767650089706
Trained batch 66 in epoch 22, gen_loss = 0.5751070722715178, disc_loss = 0.037527016049542866
Trained batch 67 in epoch 22, gen_loss = 0.574131673311486, disc_loss = 0.03702431297278963
Trained batch 68 in epoch 22, gen_loss = 0.5745507526224938, disc_loss = 0.03655381248825216
Trained batch 69 in epoch 22, gen_loss = 0.5747429588011332, disc_loss = 0.036061907358401056
Trained batch 70 in epoch 22, gen_loss = 0.5739191128334529, disc_loss = 0.03559223842367687
Trained batch 71 in epoch 22, gen_loss = 0.5746626137859292, disc_loss = 0.035136938934253216
Trained batch 72 in epoch 22, gen_loss = 0.5748312044633578, disc_loss = 0.03472851890247723
Trained batch 73 in epoch 22, gen_loss = 0.5725086726046897, disc_loss = 0.038282209955394976
Trained batch 74 in epoch 22, gen_loss = 0.5733678857485454, disc_loss = 0.04065813422047843
Trained batch 75 in epoch 22, gen_loss = 0.5743263489321658, disc_loss = 0.040785891247459835
Trained batch 76 in epoch 22, gen_loss = 0.5739867292441331, disc_loss = 0.04039009812729458
Trained batch 77 in epoch 22, gen_loss = 0.573094938045893, disc_loss = 0.04015741654737399
Trained batch 78 in epoch 22, gen_loss = 0.5715778854828847, disc_loss = 0.03997654743533864
Trained batch 79 in epoch 22, gen_loss = 0.569957148656249, disc_loss = 0.0400731205692864
Trained batch 80 in epoch 22, gen_loss = 0.5713009918913429, disc_loss = 0.042648894710891685
Trained batch 81 in epoch 22, gen_loss = 0.5715105166522468, disc_loss = 0.04220197284906512
Trained batch 82 in epoch 22, gen_loss = 0.5709273373506155, disc_loss = 0.041766699570433115
Trained batch 83 in epoch 22, gen_loss = 0.5705850780719802, disc_loss = 0.041344944885211246
Trained batch 84 in epoch 22, gen_loss = 0.5704640805721283, disc_loss = 0.04088658428997459
Trained batch 85 in epoch 22, gen_loss = 0.5706247843282167, disc_loss = 0.040435190327454705
Trained batch 86 in epoch 22, gen_loss = 0.5714552447028544, disc_loss = 0.03999902931411333
Trained batch 87 in epoch 22, gen_loss = 0.5710799995471131, disc_loss = 0.03957311735906511
Trained batch 88 in epoch 22, gen_loss = 0.5710459683048591, disc_loss = 0.03915476789985773
Trained batch 89 in epoch 22, gen_loss = 0.5709905356168747, disc_loss = 0.03873613402376779
Trained batch 90 in epoch 22, gen_loss = 0.5713825458353692, disc_loss = 0.038329461602248496
Trained batch 91 in epoch 22, gen_loss = 0.5715168296642925, disc_loss = 0.037930801728456885
Trained batch 92 in epoch 22, gen_loss = 0.5713193829982511, disc_loss = 0.03755472106258235
Trained batch 93 in epoch 22, gen_loss = 0.5713735308418882, disc_loss = 0.037197366252818956
Trained batch 94 in epoch 22, gen_loss = 0.5712347692564914, disc_loss = 0.0368263734026665
Trained batch 95 in epoch 22, gen_loss = 0.5709285410121083, disc_loss = 0.03646984342897971
Trained batch 96 in epoch 22, gen_loss = 0.5707276675504508, disc_loss = 0.03611456763752995
Trained batch 97 in epoch 22, gen_loss = 0.5706670196080694, disc_loss = 0.035783779323908825
Trained batch 98 in epoch 22, gen_loss = 0.5698765814304352, disc_loss = 0.035557623069517014
Trained batch 99 in epoch 22, gen_loss = 0.569769985973835, disc_loss = 0.035360689481021834
Trained batch 100 in epoch 22, gen_loss = 0.5708342197507915, disc_loss = 0.03512442198761803
Trained batch 101 in epoch 22, gen_loss = 0.5708386620470122, disc_loss = 0.03481904652960343
Trained batch 102 in epoch 22, gen_loss = 0.5703964433045063, disc_loss = 0.03479240796849747
Trained batch 103 in epoch 22, gen_loss = 0.569237876110352, disc_loss = 0.03517320650168516
Trained batch 104 in epoch 22, gen_loss = 0.5710266422657739, disc_loss = 0.03857637145445638
Trained batch 105 in epoch 22, gen_loss = 0.5715835350302031, disc_loss = 0.03828067409054745
Trained batch 106 in epoch 22, gen_loss = 0.5714039844330226, disc_loss = 0.03812905746647026
Trained batch 107 in epoch 22, gen_loss = 0.5713187679648399, disc_loss = 0.03792188355496533
Trained batch 108 in epoch 22, gen_loss = 0.571551336334386, disc_loss = 0.037606575595719074
Trained batch 109 in epoch 22, gen_loss = 0.5717177838087082, disc_loss = 0.03728946220997552
Trained batch 110 in epoch 22, gen_loss = 0.5720352264674934, disc_loss = 0.0370196055186711
Trained batch 111 in epoch 22, gen_loss = 0.5719993659960372, disc_loss = 0.036792430150463976
Trained batch 112 in epoch 22, gen_loss = 0.5703489442842197, disc_loss = 0.038078613172334706
Trained batch 113 in epoch 22, gen_loss = 0.5709684768266845, disc_loss = 0.039959926016244776
Trained batch 114 in epoch 22, gen_loss = 0.5694276306940161, disc_loss = 0.04065326010585641
Trained batch 115 in epoch 22, gen_loss = 0.5678994051855186, disc_loss = 0.04221362760792294
Trained batch 116 in epoch 22, gen_loss = 0.5680103681535802, disc_loss = 0.04411132326926718
Trained batch 117 in epoch 22, gen_loss = 0.5667538655511404, disc_loss = 0.044815451653587426
Trained batch 118 in epoch 22, gen_loss = 0.5668082395020653, disc_loss = 0.045178099829867924
Trained batch 119 in epoch 22, gen_loss = 0.5662166811525822, disc_loss = 0.04516862502496224
Trained batch 120 in epoch 22, gen_loss = 0.5647875178943981, disc_loss = 0.0458087588223621
Trained batch 121 in epoch 22, gen_loss = 0.5652471253129302, disc_loss = 0.04657997333417937
Trained batch 122 in epoch 22, gen_loss = 0.5647482692710752, disc_loss = 0.046651290219496724
Trained batch 123 in epoch 22, gen_loss = 0.5646350032860233, disc_loss = 0.046679315627590125
Trained batch 124 in epoch 22, gen_loss = 0.563423749923706, disc_loss = 0.04841860612202436
Trained batch 125 in epoch 22, gen_loss = 0.564134490868402, disc_loss = 0.049725427001249045
Trained batch 126 in epoch 22, gen_loss = 0.5637967196975168, disc_loss = 0.050032389875479394
Trained batch 127 in epoch 22, gen_loss = 0.5624810578301549, disc_loss = 0.05107284484711272
Trained batch 128 in epoch 22, gen_loss = 0.5619303135908851, disc_loss = 0.05150934524361275
Trained batch 129 in epoch 22, gen_loss = 0.5621177765039297, disc_loss = 0.05148422132479027
Trained batch 130 in epoch 22, gen_loss = 0.5614741958734644, disc_loss = 0.05202711765025209
Trained batch 131 in epoch 22, gen_loss = 0.5614927596215046, disc_loss = 0.05190761250912945
Trained batch 132 in epoch 22, gen_loss = 0.5608221991617877, disc_loss = 0.05224985958871789
Trained batch 133 in epoch 22, gen_loss = 0.5615999627469191, disc_loss = 0.052560839514463525
Trained batch 134 in epoch 22, gen_loss = 0.5600692002861588, disc_loss = 0.05422541619606178
Trained batch 135 in epoch 22, gen_loss = 0.560501345378511, disc_loss = 0.05485468148681855
Trained batch 136 in epoch 22, gen_loss = 0.5617134575426144, disc_loss = 0.054817905218721145
Trained batch 137 in epoch 22, gen_loss = 0.5619254155435424, disc_loss = 0.05452634454654206
Trained batch 138 in epoch 22, gen_loss = 0.5619578978998198, disc_loss = 0.054338553569467214
Trained batch 139 in epoch 22, gen_loss = 0.5612889609166554, disc_loss = 0.05431140691590761
Trained batch 140 in epoch 22, gen_loss = 0.5607405964364397, disc_loss = 0.0545033598888388
Trained batch 141 in epoch 22, gen_loss = 0.5601521138574036, disc_loss = 0.05475037333532565
Trained batch 142 in epoch 22, gen_loss = 0.5615218148364888, disc_loss = 0.055198871052719756
Trained batch 143 in epoch 22, gen_loss = 0.56212177955442, disc_loss = 0.05490717038709489
Trained batch 144 in epoch 22, gen_loss = 0.5623729775691855, disc_loss = 0.05458623731332221
Trained batch 145 in epoch 22, gen_loss = 0.5621166421126013, disc_loss = 0.05426399499155606
Trained batch 146 in epoch 22, gen_loss = 0.5619847235225496, disc_loss = 0.053962076229334736
Trained batch 147 in epoch 22, gen_loss = 0.5621535983440038, disc_loss = 0.053623078276900375
Trained batch 148 in epoch 22, gen_loss = 0.5622280712095683, disc_loss = 0.05328672394803381
Trained batch 149 in epoch 22, gen_loss = 0.562163298924764, disc_loss = 0.05295552282206093
Trained batch 150 in epoch 22, gen_loss = 0.562165504259779, disc_loss = 0.05264333937092012
Trained batch 151 in epoch 22, gen_loss = 0.5620418363495877, disc_loss = 0.05233981573301686
Testing Epoch 22
Training Epoch 23
Trained batch 0 in epoch 23, gen_loss = 0.42936742305755615, disc_loss = 0.10748735070228577
Trained batch 1 in epoch 23, gen_loss = 0.498165488243103, disc_loss = 0.09062236547470093
Trained batch 2 in epoch 23, gen_loss = 0.5609837373097738, disc_loss = 0.06573172410329182
Trained batch 3 in epoch 23, gen_loss = 0.5590766072273254, disc_loss = 0.05099177686497569
Trained batch 4 in epoch 23, gen_loss = 0.5398985326290131, disc_loss = 0.06028211526572704
Trained batch 5 in epoch 23, gen_loss = 0.5670302460590998, disc_loss = 0.07229192648082972
Trained batch 6 in epoch 23, gen_loss = 0.5866140425205231, disc_loss = 0.06302685929196221
Trained batch 7 in epoch 23, gen_loss = 0.5861040465533733, disc_loss = 0.056304247584193945
Trained batch 8 in epoch 23, gen_loss = 0.5825377338462405, disc_loss = 0.051137440320518285
Trained batch 9 in epoch 23, gen_loss = 0.582718113064766, disc_loss = 0.04646408180706203
Trained batch 10 in epoch 23, gen_loss = 0.5806322775103829, disc_loss = 0.04252226214686578
Trained batch 11 in epoch 23, gen_loss = 0.5840074792504311, disc_loss = 0.03932527941651642
Trained batch 12 in epoch 23, gen_loss = 0.5819113781818976, disc_loss = 0.036756088419889026
Trained batch 13 in epoch 23, gen_loss = 0.5823326855897903, disc_loss = 0.034314948317062645
Trained batch 14 in epoch 23, gen_loss = 0.5812927146752676, disc_loss = 0.03217433554430803
Trained batch 15 in epoch 23, gen_loss = 0.5828028973191977, disc_loss = 0.03031355437997263
Trained batch 16 in epoch 23, gen_loss = 0.5828300311284906, disc_loss = 0.028666429742075065
Trained batch 17 in epoch 23, gen_loss = 0.5831730018059412, disc_loss = 0.027238285065525107
Trained batch 18 in epoch 23, gen_loss = 0.5824147321675953, disc_loss = 0.02598678016741025
Trained batch 19 in epoch 23, gen_loss = 0.5802495464682579, disc_loss = 0.024849877192173152
Trained batch 20 in epoch 23, gen_loss = 0.5818880895773569, disc_loss = 0.023773799373191736
Trained batch 21 in epoch 23, gen_loss = 0.5815781260078604, disc_loss = 0.023087550367398017
Trained batch 22 in epoch 23, gen_loss = 0.5844844203928242, disc_loss = 0.02235624672966483
Trained batch 23 in epoch 23, gen_loss = 0.5884773048261801, disc_loss = 0.0215780044964049
Trained batch 24 in epoch 23, gen_loss = 0.5896393072605133, disc_loss = 0.02082451095804572
Trained batch 25 in epoch 23, gen_loss = 0.5890586891999612, disc_loss = 0.020087135588535324
Trained batch 26 in epoch 23, gen_loss = 0.5884703408788752, disc_loss = 0.019444494068415627
Trained batch 27 in epoch 23, gen_loss = 0.5882200758372035, disc_loss = 0.018813959164877554
Trained batch 28 in epoch 23, gen_loss = 0.5866729545182195, disc_loss = 0.018245174140059228
Trained batch 29 in epoch 23, gen_loss = 0.5845837046702703, disc_loss = 0.018383608393681545
Trained batch 30 in epoch 23, gen_loss = 0.5864546443185499, disc_loss = 0.018095460968212254
Trained batch 31 in epoch 23, gen_loss = 0.5847484013065696, disc_loss = 0.017959183584025595
Trained batch 32 in epoch 23, gen_loss = 0.586734472802191, disc_loss = 0.017768427736662103
Trained batch 33 in epoch 23, gen_loss = 0.5897320868337855, disc_loss = 0.017490970772033668
Trained batch 34 in epoch 23, gen_loss = 0.5898072285311563, disc_loss = 0.017056911092783723
Trained batch 35 in epoch 23, gen_loss = 0.5902988057997491, disc_loss = 0.016695999178207584
Trained batch 36 in epoch 23, gen_loss = 0.5895134492500408, disc_loss = 0.016417391333930397
Trained batch 37 in epoch 23, gen_loss = 0.5898857610790353, disc_loss = 0.016059382573554392
Trained batch 38 in epoch 23, gen_loss = 0.5897770623366038, disc_loss = 0.015696862611012198
Trained batch 39 in epoch 23, gen_loss = 0.5892918042838573, disc_loss = 0.015365138172637672
Trained batch 40 in epoch 23, gen_loss = 0.5886352113107356, disc_loss = 0.015042358736802892
Trained batch 41 in epoch 23, gen_loss = 0.5879926277058465, disc_loss = 0.014728380128785613
Trained batch 42 in epoch 23, gen_loss = 0.5875410389068515, disc_loss = 0.014444353524595499
Trained batch 43 in epoch 23, gen_loss = 0.5868950303305279, disc_loss = 0.014239963683807715
Trained batch 44 in epoch 23, gen_loss = 0.5865590155124665, disc_loss = 0.013970986536393563
Trained batch 45 in epoch 23, gen_loss = 0.5871420833079711, disc_loss = 0.013712633988293617
Trained batch 46 in epoch 23, gen_loss = 0.5875148627352207, disc_loss = 0.013484182975631444
Trained batch 47 in epoch 23, gen_loss = 0.5881440211087465, disc_loss = 0.013257381845808899
Trained batch 48 in epoch 23, gen_loss = 0.5882086042238741, disc_loss = 0.013025166210243288
Trained batch 49 in epoch 23, gen_loss = 0.5872797054052353, disc_loss = 0.01281333365943283
Trained batch 50 in epoch 23, gen_loss = 0.5864274157028572, disc_loss = 0.012617250333777537
Trained batch 51 in epoch 23, gen_loss = 0.5863007221084374, disc_loss = 0.012416797869194012
Trained batch 52 in epoch 23, gen_loss = 0.5863604326293154, disc_loss = 0.012206374096490865
Trained batch 53 in epoch 23, gen_loss = 0.5854052730180599, disc_loss = 0.012131680087703798
Trained batch 54 in epoch 23, gen_loss = 0.5849616142836485, disc_loss = 0.011949994288046252
Trained batch 55 in epoch 23, gen_loss = 0.5843285199786935, disc_loss = 0.011767395023655678
Trained batch 56 in epoch 23, gen_loss = 0.5838278349031482, disc_loss = 0.011613194879732634
Trained batch 57 in epoch 23, gen_loss = 0.5835688026814625, disc_loss = 0.011440442252807832
Trained batch 58 in epoch 23, gen_loss = 0.5831289609610024, disc_loss = 0.011269866524390498
Trained batch 59 in epoch 23, gen_loss = 0.5836461101969083, disc_loss = 0.011130533534257362
Trained batch 60 in epoch 23, gen_loss = 0.5838726695443763, disc_loss = 0.011006893586275763
Trained batch 61 in epoch 23, gen_loss = 0.5830091358192505, disc_loss = 0.0108867829455243
Trained batch 62 in epoch 23, gen_loss = 0.5818325749465397, disc_loss = 0.011329791005996485
Trained batch 63 in epoch 23, gen_loss = 0.5830626129172742, disc_loss = 0.011644994825473987
Trained batch 64 in epoch 23, gen_loss = 0.5836950682676756, disc_loss = 0.011606320323279271
Trained batch 65 in epoch 23, gen_loss = 0.5842494391130678, disc_loss = 0.011480746663768183
Trained batch 66 in epoch 23, gen_loss = 0.5839904738006307, disc_loss = 0.011346491797368474
Trained batch 67 in epoch 23, gen_loss = 0.584046767476727, disc_loss = 0.011266513816628824
Trained batch 68 in epoch 23, gen_loss = 0.5837043148020039, disc_loss = 0.011132430926343237
Trained batch 69 in epoch 23, gen_loss = 0.5828226749386106, disc_loss = 0.01101170731043177
Trained batch 70 in epoch 23, gen_loss = 0.5823309450921877, disc_loss = 0.010882715419144698
Trained batch 71 in epoch 23, gen_loss = 0.58191132835216, disc_loss = 0.01077770821737229
Trained batch 72 in epoch 23, gen_loss = 0.5821743595273527, disc_loss = 0.010659468535665576
Trained batch 73 in epoch 23, gen_loss = 0.5820076268266987, disc_loss = 0.010534595954546554
Trained batch 74 in epoch 23, gen_loss = 0.5820761597156525, disc_loss = 0.010412532755484184
Trained batch 75 in epoch 23, gen_loss = 0.5819581437267756, disc_loss = 0.010290459132336668
Trained batch 76 in epoch 23, gen_loss = 0.5823329149128554, disc_loss = 0.010238460292313973
Trained batch 77 in epoch 23, gen_loss = 0.5825326721637677, disc_loss = 0.010124217926297719
Trained batch 78 in epoch 23, gen_loss = 0.5822315189657332, disc_loss = 0.010021031809133725
Trained batch 79 in epoch 23, gen_loss = 0.5820384662598371, disc_loss = 0.009924610248708632
Trained batch 80 in epoch 23, gen_loss = 0.5819070556281526, disc_loss = 0.009835371910019514
Trained batch 81 in epoch 23, gen_loss = 0.5824323918034391, disc_loss = 0.009732034967405857
Trained batch 82 in epoch 23, gen_loss = 0.5823402250387583, disc_loss = 0.009639183919125023
Trained batch 83 in epoch 23, gen_loss = 0.5823506716461408, disc_loss = 0.009550017971334802
Trained batch 84 in epoch 23, gen_loss = 0.5824152830769034, disc_loss = 0.009457891663152944
Trained batch 85 in epoch 23, gen_loss = 0.5822070743455443, disc_loss = 0.009365479184347096
Trained batch 86 in epoch 23, gen_loss = 0.5817931797997705, disc_loss = 0.00927045325154503
Trained batch 87 in epoch 23, gen_loss = 0.5817418697882782, disc_loss = 0.009178133664218794
Trained batch 88 in epoch 23, gen_loss = 0.5813668313321103, disc_loss = 0.009091848313934012
Trained batch 89 in epoch 23, gen_loss = 0.5813999576701059, disc_loss = 0.009002538265970845
Trained batch 90 in epoch 23, gen_loss = 0.5810016449336167, disc_loss = 0.008925463607698515
Trained batch 91 in epoch 23, gen_loss = 0.5812075659632683, disc_loss = 0.008885614890301518
Trained batch 92 in epoch 23, gen_loss = 0.5807924658380529, disc_loss = 0.00883491878317649
Trained batch 93 in epoch 23, gen_loss = 0.5806509842897983, disc_loss = 0.008767366322609497
Trained batch 94 in epoch 23, gen_loss = 0.5800505653807991, disc_loss = 0.008693302770782459
Trained batch 95 in epoch 23, gen_loss = 0.5796831470603744, disc_loss = 0.008617615748031918
Trained batch 96 in epoch 23, gen_loss = 0.5803427914368737, disc_loss = 0.00854626211419356
Trained batch 97 in epoch 23, gen_loss = 0.5803396181792629, disc_loss = 0.008477181709390514
Trained batch 98 in epoch 23, gen_loss = 0.5807308997168685, disc_loss = 0.008428084522937283
Trained batch 99 in epoch 23, gen_loss = 0.5802428570389747, disc_loss = 0.008364008353091777
Trained batch 100 in epoch 23, gen_loss = 0.5798060784835627, disc_loss = 0.008307023969764757
Trained batch 101 in epoch 23, gen_loss = 0.5802832371463963, disc_loss = 0.008243773449851456
Trained batch 102 in epoch 23, gen_loss = 0.5802767545852846, disc_loss = 0.008178991887230173
Trained batch 103 in epoch 23, gen_loss = 0.5797787884680125, disc_loss = 0.008137605983602744
Trained batch 104 in epoch 23, gen_loss = 0.5789190056778136, disc_loss = 0.008080302912830597
Trained batch 105 in epoch 23, gen_loss = 0.5784445531525702, disc_loss = 0.008028731679209982
Trained batch 106 in epoch 23, gen_loss = 0.5783860229443167, disc_loss = 0.007975670802798644
Trained batch 107 in epoch 23, gen_loss = 0.5780652604169316, disc_loss = 0.008001755110281348
Trained batch 108 in epoch 23, gen_loss = 0.5786887863907245, disc_loss = 0.008008509726955666
Trained batch 109 in epoch 23, gen_loss = 0.5787406875328585, disc_loss = 0.00804906275589019
Trained batch 110 in epoch 23, gen_loss = 0.5796916632501928, disc_loss = 0.008063049431101562
Trained batch 111 in epoch 23, gen_loss = 0.5802259469138724, disc_loss = 0.00802323643334343
Trained batch 112 in epoch 23, gen_loss = 0.5807650113000279, disc_loss = 0.007972608575910594
Trained batch 113 in epoch 23, gen_loss = 0.5803960705535454, disc_loss = 0.007934790521271919
Trained batch 114 in epoch 23, gen_loss = 0.5799085759598276, disc_loss = 0.007915718772489092
Trained batch 115 in epoch 23, gen_loss = 0.579469591122249, disc_loss = 0.00793530706894295
Trained batch 116 in epoch 23, gen_loss = 0.5787826450462015, disc_loss = 0.008123096826876331
Trained batch 117 in epoch 23, gen_loss = 0.5797929733486499, disc_loss = 0.008382829174525657
Trained batch 118 in epoch 23, gen_loss = 0.5804405407745297, disc_loss = 0.008392481368128993
Trained batch 119 in epoch 23, gen_loss = 0.5809035142262776, disc_loss = 0.008351144757277022
Trained batch 120 in epoch 23, gen_loss = 0.5810172882947054, disc_loss = 0.00832178681888733
Trained batch 121 in epoch 23, gen_loss = 0.5813532149205443, disc_loss = 0.008285089951298643
Trained batch 122 in epoch 23, gen_loss = 0.5814790207196058, disc_loss = 0.008231768154584599
Trained batch 123 in epoch 23, gen_loss = 0.5819012311197096, disc_loss = 0.008179180338160105
Trained batch 124 in epoch 23, gen_loss = 0.5819260091781616, disc_loss = 0.008124327294528484
Trained batch 125 in epoch 23, gen_loss = 0.5818447451742869, disc_loss = 0.00806765919662125
Trained batch 126 in epoch 23, gen_loss = 0.5814514399513485, disc_loss = 0.008012302842277183
Trained batch 127 in epoch 23, gen_loss = 0.5809197123162448, disc_loss = 0.00795703331596087
Trained batch 128 in epoch 23, gen_loss = 0.5806057148201521, disc_loss = 0.007904715547717154
Trained batch 129 in epoch 23, gen_loss = 0.5806179385918837, disc_loss = 0.00785196673599645
Trained batch 130 in epoch 23, gen_loss = 0.5805716200639274, disc_loss = 0.007799839683122336
Trained batch 131 in epoch 23, gen_loss = 0.5804606734803228, disc_loss = 0.00774958176286115
Trained batch 132 in epoch 23, gen_loss = 0.5803078153079614, disc_loss = 0.007700119003446955
Trained batch 133 in epoch 23, gen_loss = 0.5803500111423322, disc_loss = 0.007649291810621299
Trained batch 134 in epoch 23, gen_loss = 0.5802183213057341, disc_loss = 0.007599188304609723
Trained batch 135 in epoch 23, gen_loss = 0.5803174030254868, disc_loss = 0.007550354868940571
Trained batch 136 in epoch 23, gen_loss = 0.5802090885865427, disc_loss = 0.007502607649436941
Trained batch 137 in epoch 23, gen_loss = 0.5800173667030059, disc_loss = 0.007457401443178347
Trained batch 138 in epoch 23, gen_loss = 0.5798966854596309, disc_loss = 0.007409974688952186
Trained batch 139 in epoch 23, gen_loss = 0.5797913836581366, disc_loss = 0.0073713517672981
Trained batch 140 in epoch 23, gen_loss = 0.5797126792001386, disc_loss = 0.007329915144071247
Trained batch 141 in epoch 23, gen_loss = 0.5792581120007475, disc_loss = 0.007285278538917519
Trained batch 142 in epoch 23, gen_loss = 0.5792651634949905, disc_loss = 0.007241216786954734
Trained batch 143 in epoch 23, gen_loss = 0.5796066092120277, disc_loss = 0.00719897748139273
Trained batch 144 in epoch 23, gen_loss = 0.579527249418456, disc_loss = 0.007157009946792547
Trained batch 145 in epoch 23, gen_loss = 0.5796519403588282, disc_loss = 0.007122554488588533
Trained batch 146 in epoch 23, gen_loss = 0.5795763211996376, disc_loss = 0.007079791142225114
Trained batch 147 in epoch 23, gen_loss = 0.5798253590190733, disc_loss = 0.007038118901373063
Trained batch 148 in epoch 23, gen_loss = 0.5796708300609716, disc_loss = 0.0070006052178999524
Trained batch 149 in epoch 23, gen_loss = 0.5796887413660685, disc_loss = 0.006962286526492487
Trained batch 150 in epoch 23, gen_loss = 0.5797717310734932, disc_loss = 0.006924100028233763
Trained batch 151 in epoch 23, gen_loss = 0.5795566392572302, disc_loss = 0.006885079827809118
Testing Epoch 23
Training Epoch 24
Trained batch 0 in epoch 24, gen_loss = 0.6094335317611694, disc_loss = 0.0009410750353708863
Trained batch 1 in epoch 24, gen_loss = 0.5968532264232635, disc_loss = 0.0008725024817977101
Trained batch 2 in epoch 24, gen_loss = 0.5972442030906677, disc_loss = 0.0008556230847413341
Trained batch 3 in epoch 24, gen_loss = 0.5896818786859512, disc_loss = 0.000897912512300536
Trained batch 4 in epoch 24, gen_loss = 0.5893857836723327, disc_loss = 0.000880742643494159
Trained batch 5 in epoch 24, gen_loss = 0.5848173201084137, disc_loss = 0.0009389798603175828
Trained batch 6 in epoch 24, gen_loss = 0.5786903415407453, disc_loss = 0.0009366482346584755
Trained batch 7 in epoch 24, gen_loss = 0.5758977234363556, disc_loss = 0.0009267238710890524
Trained batch 8 in epoch 24, gen_loss = 0.5733364025751749, disc_loss = 0.0009084202983002695
Trained batch 9 in epoch 24, gen_loss = 0.5745857715606689, disc_loss = 0.0009109231876209378
Trained batch 10 in epoch 24, gen_loss = 0.5732359777797352, disc_loss = 0.000899820106993006
Trained batch 11 in epoch 24, gen_loss = 0.5698630412419637, disc_loss = 0.0010629332634077098
Trained batch 12 in epoch 24, gen_loss = 0.5700745582580566, disc_loss = 0.0010811887153137762
Trained batch 13 in epoch 24, gen_loss = 0.5709774153573173, disc_loss = 0.0010653675043223692
Trained batch 14 in epoch 24, gen_loss = 0.5684240102767945, disc_loss = 0.0010532890485289196
Trained batch 15 in epoch 24, gen_loss = 0.5675684288144112, disc_loss = 0.0010852995947061572
Trained batch 16 in epoch 24, gen_loss = 0.568909063058741, disc_loss = 0.0010664677076206049
Trained batch 17 in epoch 24, gen_loss = 0.5704651839203305, disc_loss = 0.0010593212727043363
Trained batch 18 in epoch 24, gen_loss = 0.569525000296141, disc_loss = 0.0010553908803941387
Trained batch 19 in epoch 24, gen_loss = 0.5687668293714523, disc_loss = 0.0010466650506714358
Trained batch 20 in epoch 24, gen_loss = 0.5695981553622654, disc_loss = 0.0010490994429260137
Trained batch 21 in epoch 24, gen_loss = 0.5692095187577334, disc_loss = 0.001042160827306692
Trained batch 22 in epoch 24, gen_loss = 0.56899108575738, disc_loss = 0.0010397813622029903
Trained batch 23 in epoch 24, gen_loss = 0.5690389821926752, disc_loss = 0.0010302005393896252
Trained batch 24 in epoch 24, gen_loss = 0.5680187320709229, disc_loss = 0.0010646271705627441
Trained batch 25 in epoch 24, gen_loss = 0.5675173080884494, disc_loss = 0.00106976612453134
Trained batch 26 in epoch 24, gen_loss = 0.568568088390209, disc_loss = 0.0010651482670154008
Trained batch 27 in epoch 24, gen_loss = 0.5681132291044507, disc_loss = 0.0010534091312105634
Trained batch 28 in epoch 24, gen_loss = 0.5671754458854938, disc_loss = 0.0010412687351445443
Trained batch 29 in epoch 24, gen_loss = 0.5669146776199341, disc_loss = 0.0010496947312882792
Trained batch 30 in epoch 24, gen_loss = 0.5664339565461681, disc_loss = 0.0010433522721512182
Trained batch 31 in epoch 24, gen_loss = 0.5674149636179209, disc_loss = 0.001045931061526062
Trained batch 32 in epoch 24, gen_loss = 0.5667623227292841, disc_loss = 0.0010389220851445289
Trained batch 33 in epoch 24, gen_loss = 0.5662506450625027, disc_loss = 0.001031386388657505
Trained batch 34 in epoch 24, gen_loss = 0.5665926490511213, disc_loss = 0.0010282937670126556
Trained batch 35 in epoch 24, gen_loss = 0.5657517810662588, disc_loss = 0.0010276751903196175
Trained batch 36 in epoch 24, gen_loss = 0.5651169805913359, disc_loss = 0.0010206466131667431
Trained batch 37 in epoch 24, gen_loss = 0.5645776438085657, disc_loss = 0.0010189120228843468
Trained batch 38 in epoch 24, gen_loss = 0.5645158902192727, disc_loss = 0.00102333966582918
Trained batch 39 in epoch 24, gen_loss = 0.5650987237691879, disc_loss = 0.0010365668451413513
Trained batch 40 in epoch 24, gen_loss = 0.564619795578282, disc_loss = 0.0010353935081738887
Trained batch 41 in epoch 24, gen_loss = 0.5643454605624789, disc_loss = 0.00106612457394866
Trained batch 42 in epoch 24, gen_loss = 0.5644393590993659, disc_loss = 0.001066399556801243
Trained batch 43 in epoch 24, gen_loss = 0.5642395981333472, disc_loss = 0.0010572921283627775
Trained batch 44 in epoch 24, gen_loss = 0.5648726079199049, disc_loss = 0.0010524479361871879
Trained batch 45 in epoch 24, gen_loss = 0.5645126143227452, disc_loss = 0.0010467332157650558
Trained batch 46 in epoch 24, gen_loss = 0.5647473728403132, disc_loss = 0.0010429948266159664
Trained batch 47 in epoch 24, gen_loss = 0.5649856726328532, disc_loss = 0.001038399195143332
Trained batch 48 in epoch 24, gen_loss = 0.5644040302354463, disc_loss = 0.0010318313178853417
Trained batch 49 in epoch 24, gen_loss = 0.5640886235237121, disc_loss = 0.0010253184812609106
Trained batch 50 in epoch 24, gen_loss = 0.56394207945057, disc_loss = 0.00101892168829948
Trained batch 51 in epoch 24, gen_loss = 0.563969013782648, disc_loss = 0.0010121585946762934
Trained batch 52 in epoch 24, gen_loss = 0.5642579625237663, disc_loss = 0.0010125721126074357
Trained batch 53 in epoch 24, gen_loss = 0.5641322389796928, disc_loss = 0.001011032431119087
Trained batch 54 in epoch 24, gen_loss = 0.5639346827160229, disc_loss = 0.00101250520886176
Trained batch 55 in epoch 24, gen_loss = 0.563340034868036, disc_loss = 0.0010092798714010445
Trained batch 56 in epoch 24, gen_loss = 0.5630482131974739, disc_loss = 0.0010140585935707286
Trained batch 57 in epoch 24, gen_loss = 0.5631667324181261, disc_loss = 0.0010141127066413775
Trained batch 58 in epoch 24, gen_loss = 0.5627024870807842, disc_loss = 0.0010091985262125351
Trained batch 59 in epoch 24, gen_loss = 0.5628546059131623, disc_loss = 0.001005318106035702
Trained batch 60 in epoch 24, gen_loss = 0.5625452311312567, disc_loss = 0.0009986298544271315
Trained batch 61 in epoch 24, gen_loss = 0.5627665404350527, disc_loss = 0.0010056860835081147
Trained batch 62 in epoch 24, gen_loss = 0.5633973753641522, disc_loss = 0.0010081085243395396
Trained batch 63 in epoch 24, gen_loss = 0.5631402572616935, disc_loss = 0.0010172986494580982
Trained batch 64 in epoch 24, gen_loss = 0.5633036494255066, disc_loss = 0.0010216799009448061
Trained batch 65 in epoch 24, gen_loss = 0.5631606605919924, disc_loss = 0.0010206920904403721
Trained batch 66 in epoch 24, gen_loss = 0.5636095885020583, disc_loss = 0.0010190639869004155
Trained batch 67 in epoch 24, gen_loss = 0.5632588600411135, disc_loss = 0.0010155976419542532
Trained batch 68 in epoch 24, gen_loss = 0.5636514217957206, disc_loss = 0.0010138619573030999
Trained batch 69 in epoch 24, gen_loss = 0.5641193781580244, disc_loss = 0.0010127997449931822
Trained batch 70 in epoch 24, gen_loss = 0.5642607128116447, disc_loss = 0.001009476521137682
Trained batch 71 in epoch 24, gen_loss = 0.5642951784862412, disc_loss = 0.0010054656126562299
Trained batch 72 in epoch 24, gen_loss = 0.5644444268043727, disc_loss = 0.0010030050060316309
Trained batch 73 in epoch 24, gen_loss = 0.5645224105667423, disc_loss = 0.0010003324368389676
Trained batch 74 in epoch 24, gen_loss = 0.5649328327178955, disc_loss = 0.0009967791211480895
Trained batch 75 in epoch 24, gen_loss = 0.5645105525066978, disc_loss = 0.0009928836003190984
Trained batch 76 in epoch 24, gen_loss = 0.5641103255284297, disc_loss = 0.0009885063295119575
Trained batch 77 in epoch 24, gen_loss = 0.5641790872965103, disc_loss = 0.0009862261045222671
Trained batch 78 in epoch 24, gen_loss = 0.5639228850980348, disc_loss = 0.0009829058566814452
Trained batch 79 in epoch 24, gen_loss = 0.5636373147368431, disc_loss = 0.0009809668197704013
Trained batch 80 in epoch 24, gen_loss = 0.5633103310326, disc_loss = 0.0009791200849756506
Trained batch 81 in epoch 24, gen_loss = 0.563308959327093, disc_loss = 0.0009809125040192157
Trained batch 82 in epoch 24, gen_loss = 0.5634592864886824, disc_loss = 0.0009812936193803437
Trained batch 83 in epoch 24, gen_loss = 0.5633363532168525, disc_loss = 0.0009801471792993002
Trained batch 84 in epoch 24, gen_loss = 0.5630682559574351, disc_loss = 0.0009778871098259354
Trained batch 85 in epoch 24, gen_loss = 0.5628936214502468, disc_loss = 0.0009777304380698953
Trained batch 86 in epoch 24, gen_loss = 0.5634508578256628, disc_loss = 0.0009790648941764202
Trained batch 87 in epoch 24, gen_loss = 0.5637995715845715, disc_loss = 0.0009762726496608758
Trained batch 88 in epoch 24, gen_loss = 0.5638802995842495, disc_loss = 0.000973957746415242
Trained batch 89 in epoch 24, gen_loss = 0.5639104472266303, disc_loss = 0.0009737304515308804
Trained batch 90 in epoch 24, gen_loss = 0.5637279087370568, disc_loss = 0.0009718511943132258
Trained batch 91 in epoch 24, gen_loss = 0.5637512679981149, disc_loss = 0.000968932030525099
Trained batch 92 in epoch 24, gen_loss = 0.5643778392063674, disc_loss = 0.0009697398292251251
Trained batch 93 in epoch 24, gen_loss = 0.5645262535582197, disc_loss = 0.0009701046207176641
Trained batch 94 in epoch 24, gen_loss = 0.5646545799154984, disc_loss = 0.0009741630019178908
Trained batch 95 in epoch 24, gen_loss = 0.5633395438392957, disc_loss = 0.0018268402012229974
Trained batch 96 in epoch 24, gen_loss = 0.5658197415243719, disc_loss = 0.0023715504326319954
Trained batch 97 in epoch 24, gen_loss = 0.568181997659255, disc_loss = 0.0026160970678296394
Trained batch 98 in epoch 24, gen_loss = 0.569530163750504, disc_loss = 0.002616942430390139
Trained batch 99 in epoch 24, gen_loss = 0.5703744530677796, disc_loss = 0.0026345349225448443
Trained batch 100 in epoch 24, gen_loss = 0.5708428426544265, disc_loss = 0.0026367170220969413
Trained batch 101 in epoch 24, gen_loss = 0.5711252829607796, disc_loss = 0.0026576577705175928
Trained batch 102 in epoch 24, gen_loss = 0.5718586849934847, disc_loss = 0.002672120678414889
Trained batch 103 in epoch 24, gen_loss = 0.5721576357117066, disc_loss = 0.0026650316347233737
Trained batch 104 in epoch 24, gen_loss = 0.5723328170322236, disc_loss = 0.002653813464677937
Trained batch 105 in epoch 24, gen_loss = 0.5725880557636045, disc_loss = 0.0026513799933830873
Trained batch 106 in epoch 24, gen_loss = 0.5721335589328659, disc_loss = 0.002639655444322798
Trained batch 107 in epoch 24, gen_loss = 0.5718605463151578, disc_loss = 0.0026322684355330203
Trained batch 108 in epoch 24, gen_loss = 0.5715067167894556, disc_loss = 0.0026186966692917733
Trained batch 109 in epoch 24, gen_loss = 0.571543609012257, disc_loss = 0.0026145778665192087
Trained batch 110 in epoch 24, gen_loss = 0.5715203800716916, disc_loss = 0.0026018881089020485
Trained batch 111 in epoch 24, gen_loss = 0.5714320524462632, disc_loss = 0.002589545907540014
Trained batch 112 in epoch 24, gen_loss = 0.5713937488277402, disc_loss = 0.0025746664707136826
Trained batch 113 in epoch 24, gen_loss = 0.5719328773649115, disc_loss = 0.0025667537084429347
Trained batch 114 in epoch 24, gen_loss = 0.5720340459243111, disc_loss = 0.0025568951118696967
Trained batch 115 in epoch 24, gen_loss = 0.5721886219649479, disc_loss = 0.002542600138032616
Trained batch 116 in epoch 24, gen_loss = 0.5724931578350883, disc_loss = 0.002536111831680959
Trained batch 117 in epoch 24, gen_loss = 0.5725957387584751, disc_loss = 0.0025233656327808434
Trained batch 118 in epoch 24, gen_loss = 0.5726846792116886, disc_loss = 0.0025094649607722624
Trained batch 119 in epoch 24, gen_loss = 0.5728188857436181, disc_loss = 0.002497786256329467
Trained batch 120 in epoch 24, gen_loss = 0.5730654528318357, disc_loss = 0.0024838274487194198
Trained batch 121 in epoch 24, gen_loss = 0.573461713849521, disc_loss = 0.0024716123675194678
Trained batch 122 in epoch 24, gen_loss = 0.5730692414733453, disc_loss = 0.002461088436080249
Trained batch 123 in epoch 24, gen_loss = 0.5730727521642562, disc_loss = 0.0024500490783999165
Trained batch 124 in epoch 24, gen_loss = 0.5728229751586914, disc_loss = 0.0024365940261632203
Trained batch 125 in epoch 24, gen_loss = 0.5726748927245064, disc_loss = 0.0024265966346738712
Trained batch 126 in epoch 24, gen_loss = 0.5722674887011371, disc_loss = 0.0024128769644477413
Trained batch 127 in epoch 24, gen_loss = 0.5723555916920304, disc_loss = 0.0024055866010712634
Trained batch 128 in epoch 24, gen_loss = 0.5722537401110627, disc_loss = 0.002395621331701012
Trained batch 129 in epoch 24, gen_loss = 0.5721793238933269, disc_loss = 0.0023853147585983746
Trained batch 130 in epoch 24, gen_loss = 0.5720013803198137, disc_loss = 0.0023744534945492244
Trained batch 131 in epoch 24, gen_loss = 0.5718848429846041, disc_loss = 0.0023649834748181147
Trained batch 132 in epoch 24, gen_loss = 0.5716530003942045, disc_loss = 0.002353711668191884
Trained batch 133 in epoch 24, gen_loss = 0.5712125399219457, disc_loss = 0.0023429605965641564
Trained batch 134 in epoch 24, gen_loss = 0.5713961195062708, disc_loss = 0.002334377001453605
Trained batch 135 in epoch 24, gen_loss = 0.5711818749413771, disc_loss = 0.002324955415507943
Trained batch 136 in epoch 24, gen_loss = 0.571272146962855, disc_loss = 0.0023140555985244737
Trained batch 137 in epoch 24, gen_loss = 0.5714148270047229, disc_loss = 0.0023035360255575592
Trained batch 138 in epoch 24, gen_loss = 0.5715167007857948, disc_loss = 0.002293089835187621
Trained batch 139 in epoch 24, gen_loss = 0.5713986584118435, disc_loss = 0.0022844006889499724
Trained batch 140 in epoch 24, gen_loss = 0.57163161335262, disc_loss = 0.0022743773615278356
Trained batch 141 in epoch 24, gen_loss = 0.5715961002967727, disc_loss = 0.0022730258691885416
Trained batch 142 in epoch 24, gen_loss = 0.5715828733844357, disc_loss = 0.0022640726480216205
Trained batch 143 in epoch 24, gen_loss = 0.5710959790481461, disc_loss = 0.0022574056800092673
Trained batch 144 in epoch 24, gen_loss = 0.5710586268326332, disc_loss = 0.0022514629450723013
Trained batch 145 in epoch 24, gen_loss = 0.5714206752711779, disc_loss = 0.002243598407989189
Trained batch 146 in epoch 24, gen_loss = 0.5717486958114468, disc_loss = 0.002235585965412561
Trained batch 147 in epoch 24, gen_loss = 0.5716855658872707, disc_loss = 0.002229903474594844
Trained batch 148 in epoch 24, gen_loss = 0.5716769675280424, disc_loss = 0.0022342363161491166
Trained batch 149 in epoch 24, gen_loss = 0.571623246272405, disc_loss = 0.0022267654095776378
Trained batch 150 in epoch 24, gen_loss = 0.5715115137447585, disc_loss = 0.0022261270394376077
Trained batch 151 in epoch 24, gen_loss = 0.5714581067624845, disc_loss = 0.002218601954059283
Testing Epoch 24